{"2504.02799": {"publish_time": "2025-04-03", "title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence", "paper_summary": "Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u70ba AI \u9a45\u52d5\u7684\u5716\u50cf\u7406\u89e3\u63d0\u4f9b\u4e86\u4e00\u7a2e\u65b0\u7684\u7bc4\u4f8b\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u5728\u6c92\u6709\u7279\u5b9a\u4efb\u52d9\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u57f7\u884c\u4efb\u52d9\u3002\u9019\u7a2e\u9748\u6d3b\u6027\u5728\u91ab\u5b78\u9818\u57df\u5c24\u5176\u5177\u6709\u524d\u666f\uff0c\u56e0\u70ba\u8a72\u9818\u57df\u7f3a\u4e4f\u5c08\u5bb6\u6a19\u8a3b\u7684\u6578\u64da\u3002\u7136\u800c\uff0cVLM \u5728\u4ee5\u4ecb\u5165\u70ba\u91cd\u9ede\u7684\u9818\u57df\uff08\u5c24\u5176\u662f\u5916\u79d1\u624b\u8853\uff0c\u5176\u4e2d\u6c7a\u7b56\u5177\u6709\u4e3b\u89c0\u6027\uff0c\u81e8\u5e8a\u60c5\u6cc1\u4e5f\u591a\u8b8a\uff09\u7684\u5be6\u969b\u6548\u7528\u4ecd\u7136\u4e0d\u78ba\u5b9a\u3002\u5728\u9019\u88e1\uff0c\u6211\u5011\u91dd\u5c0d\u624b\u8853 AI \u4e2d\u7684 17 \u500b\u95dc\u9375\u8996\u89ba\u7406\u89e3\u4efb\u52d9\uff08\u5f9e\u89e3\u5256\u7d50\u69cb\u8b58\u5225\u5230\u6280\u80fd\u8a55\u4f30\uff09\uff0c\u4f7f\u7528\u6db5\u84cb\u8179\u8154\u93e1\u3001\u6a5f\u5668\u4eba\u548c\u958b\u653e\u624b\u8853\u7684 13 \u500b\u6578\u64da\u96c6\uff0c\u5c0d 11 \u500b\u6700\u5148\u9032\u7684 VLM \u9032\u884c\u4e86\u5168\u9762\u5206\u6790\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0cVLM \u5c55\u73fe\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6709\u6642\u5728\u8a13\u7df4\u74b0\u5883\u4e4b\u5916\u90e8\u7f72\u6642\uff0c\u5176\u8868\u73fe\u751a\u81f3\u512a\u65bc\u76e3\u7763\u6a21\u578b\u3002\u5728\u6e2c\u8a66\u671f\u9593\u52a0\u5165\u7bc4\u4f8b\u7684\u4e0a\u4e0b\u6587\u5b78\u7fd2\u5c07\u6027\u80fd\u63d0\u5347\u4e86\u4e09\u500d\uff0c\u9019\u8868\u660e\u9069\u61c9\u6027\u662f\u5176\u95dc\u9375\u512a\u52e2\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u9700\u8981\u7a7a\u9593\u6216\u6642\u9593\u63a8\u7406\u7684\u4efb\u52d9\u4ecd\u7136\u5f88\u56f0\u96e3\u3002\u9664\u4e86\u5916\u79d1\u624b\u8853\u4e4b\u5916\uff0c\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u9084\u63d0\u4f9b\u4e86\u95dc\u65bc VLM \u5728\u81e8\u5e8a\u548c\u66f4\u5ee3\u6cdb\u7684\u73fe\u5be6\u61c9\u7528\u4e2d\u61c9\u5c0d\u8907\u96dc\u548c\u52d5\u614b\u5834\u666f\u7684\u6f5b\u529b\u7684\u898b\u89e3\u3002\n", "author": "Anita Rau et.al.", "authors": "Anita Rau, Mark Endo, Josiah Aklilu, Jaewoo Heo, Khaled Saab, Alberto Paderno, Jeffrey Jopling, F. Christopher Holsinger, Serena Yeung-Levy", "id": "2504.02799v1", "paper_url": "http://arxiv.org/abs/2504.02799v1", "repo": "null"}}