{"2405.20974": {"publish_time": "2024-05-31", "title": "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales", "paper_summary": "Large language models (LLMs) often generate inaccurate or fabricated\ninformation and generally fail to indicate their confidence, which limits their\nbroader applications. Previous work elicits confidence from LLMs by direct or\nself-consistency prompting, or constructing specific datasets for supervised\nfinetuning. The prompting-based approaches have inferior performance, and the\ntraining-based approaches are limited to binary or inaccurate group-level\nconfidence estimates. In this work, we present the advanced SaySelf, a training\nframework that teaches LLMs to express more accurate fine-grained confidence\nestimates. In addition, beyond the confidence scores, SaySelf initiates the\nprocess of directing LLMs to produce self-reflective rationales that clearly\nidentify gaps in their parametric knowledge and explain their uncertainty. This\nis achieved by using an LLM to automatically summarize the uncertainties in\nspecific knowledge via natural language. The summarization is based on the\nanalysis of the inconsistency in multiple sampled reasoning chains, and the\nresulting data is utilized for supervised fine-tuning. Moreover, we utilize\nreinforcement learning with a meticulously crafted reward function to calibrate\nthe confidence estimates, motivating LLMs to deliver accurate, high-confidence\npredictions and to penalize overconfidence in erroneous outputs. Experimental\nresults in both in-distribution and out-of-distribution datasets demonstrate\nthe effectiveness of SaySelf in reducing the confidence calibration error and\nmaintaining the task performance. We show that the generated self-reflective\nrationales are reasonable and can further contribute to the calibration. The\ncode is made public at \\url{https://github.com/xu1868/SaySelf}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7d93\u5e38\u7522\u751f\u4e0d\u6e96\u78ba\u6216\u865b\u69cb\u7684\u8cc7\u8a0a\uff0c\u4e14\u901a\u5e38\u7121\u6cd5\u6307\u51fa\u5176\u4fe1\u5fc3\uff0c\u9019\u9650\u5236\u4e86\u5176\u5ee3\u6cdb\u7684\u61c9\u7528\u3002\u5148\u524d\u7684\u7814\u7a76\u900f\u904e\u76f4\u63a5\u6216\u81ea\u6211\u4e00\u81f4\u7684\u63d0\u793a\uff0c\u6216\u5efa\u69cb\u7279\u5b9a\u8cc7\u6599\u96c6\u4ee5\u9032\u884c\u76e3\u7763\u5f0f\u5fae\u8abf\uff0c\u5f9e LLM \u4e2d\u5f15\u51fa\u4fe1\u5fc3\u3002\u57fa\u65bc\u63d0\u793a\u7684\u65b9\u6cd5\u6548\u80fd\u8f03\u5dee\uff0c\u800c\u57fa\u65bc\u8a13\u7df4\u7684\u65b9\u6cd5\u5247\u50c5\u9650\u65bc\u4e8c\u5143\u6216\u4e0d\u6e96\u78ba\u7684\u7fa4\u7d44\u5c64\u7d1a\u4fe1\u5fc3\u4f30\u8a08\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u9032\u968e\u7684 SaySelf\uff0c\u9019\u662f\u4e00\u7a2e\u8a13\u7df4\u67b6\u69cb\uff0c\u7528\u65bc\u6559\u5c0e LLM \u8868\u9054\u66f4\u6e96\u78ba\u7684\u7d30\u7c92\u5ea6\u4fe1\u5fc3\u4f30\u8a08\u3002\u6b64\u5916\uff0c\u9664\u4e86\u4fe1\u5fc3\u5206\u6578\u4e4b\u5916\uff0cSaySelf \u9084\u555f\u52d5\u4e86\u5f15\u5c0e LLM \u7522\u751f\u81ea\u6211\u53cd\u7701\u7684\u4f9d\u64da\u7684\u7a0b\u5e8f\uff0c\u6e05\u695a\u5730\u627e\u51fa\u5176\u53c3\u6578\u77e5\u8b58\u4e2d\u7684\u5dee\u8ddd\u4e26\u89e3\u91cb\u5176\u4e0d\u78ba\u5b9a\u6027\u3002\u9019\u900f\u904e\u4f7f\u7528 LLM \u4ee5\u81ea\u7136\u8a9e\u8a00\u81ea\u52d5\u6458\u8981\u7279\u5b9a\u77e5\u8b58\u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\u4f86\u5be6\u73fe\u3002\u6458\u8981\u57fa\u65bc\u5c0d\u591a\u500b\u53d6\u6a23\u63a8\u7406\u93c8\u4e2d\u4e0d\u4e00\u81f4\u6027\u7684\u5206\u6790\uff0c\u800c\u7522\u751f\u7684\u8cc7\u6599\u7528\u65bc\u76e3\u7763\u5f0f\u5fae\u8abf\u3002\u6b64\u5916\uff0c\u6211\u5011\u5229\u7528\u7d93\u904e\u7cbe\u5fc3\u8a2d\u8a08\u7684\u734e\u52f5\u51fd\u6578\u9032\u884c\u5f37\u5316\u5b78\u7fd2\uff0c\u4ee5\u6821\u6e96\u4fe1\u5fc3\u4f30\u8a08\uff0c\u4fc3\u4f7f LLM \u63d0\u4f9b\u6e96\u78ba\u3001\u9ad8\u4fe1\u5fc3\u7684\u9810\u6e2c\uff0c\u4e26\u61f2\u7f70\u5c0d\u932f\u8aa4\u8f38\u51fa\u7684\u904e\u5ea6\u81ea\u4fe1\u3002\u7121\u8ad6\u662f\u5728\u5206\u4f48\u5167\u9084\u662f\u5206\u4f48\u5916\u8cc7\u6599\u96c6\u4e2d\u7684\u5be6\u9a57\u7d50\u679c\uff0c\u90fd\u8b49\u660e\u4e86 SaySelf \u5728\u6e1b\u5c11\u4fe1\u5fc3\u6821\u6e96\u8aa4\u5dee\u548c\u7dad\u6301\u4efb\u52d9\u6548\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u8b49\u660e\u4e86\u7522\u751f\u7684\u81ea\u6211\u53cd\u7701\u7684\u4f9d\u64da\u662f\u5408\u7406\u7684\uff0c\u4e26\u4e14\u53ef\u4ee5\u9032\u4e00\u6b65\u6709\u52a9\u65bc\u6821\u6e96\u3002\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc\\url{https://github.com/xu1868/SaySelf}\u3002", "author": "Tianyang Xu et.al.", "authors": "Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao", "id": "2405.20974v1", "paper_url": "http://arxiv.org/abs/2405.20974v1", "repo": "https://github.com/xu1868/sayself"}}