{"2407.10701": {"publish_time": "2024-07-15", "title": "DOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems", "paper_summary": "Recently, there has been a growing interest among large language model (LLM)\ndevelopers in LLM-based document reading systems, which enable users to upload\ntheir own documents and pose questions related to the document contents, going\nbeyond simple reading comprehension tasks. Consequently, these systems have\nbeen carefully designed to tackle challenges such as file parsing, metadata\nextraction, multi-modal information understanding and long-context reading.\nHowever, no current benchmark exists to evaluate their performance in such\nscenarios, where a raw file and questions are provided as input, and a\ncorresponding response is expected as output. In this paper, we introduce\nDocBench, a new benchmark designed to evaluate LLM-based document reading\nsystems. Our benchmark involves a meticulously crafted process, including the\nrecruitment of human annotators and the generation of synthetic questions. It\nincludes 229 real documents and 1,102 questions, spanning across five different\ndomains and four major types of questions. We evaluate both proprietary\nLLM-based systems accessible via web interfaces or APIs, and a parse-then-read\npipeline employing open-source LLMs. Our evaluations reveal noticeable gaps\nbetween existing LLM-based document reading systems and human performance,\nunderscoring the challenges of developing proficient systems. To summarize,\nDocBench aims to establish a standardized benchmark for evaluating LLM-based\ndocument reading systems under diverse real-world scenarios, thereby guiding\nfuture advancements in this research area.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5f00\u53d1\u4eba\u5458\u5bf9\u57fa\u4e8e LLM \u7684\u6587\u6863\u9605\u8bfb\u7cfb\u7edf\u8d8a\u6765\u8d8a\u611f\u5174\u8da3\uff0c\u8be5\u7cfb\u7edf\u4f7f\u7528\u6237\u80fd\u591f\u4e0a\u4f20\u81ea\u5df1\u7684\u6587\u6863\u5e76\u63d0\u51fa\u4e0e\u6587\u6863\u5185\u5bb9\u76f8\u5173\u7684\u95ee\u9898\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u9605\u8bfb\u7406\u89e3\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u7ecf\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\uff0c\u4ee5\u5e94\u5bf9\u8bf8\u5982\u6587\u4ef6\u89e3\u6790\u3001\u5143\u6570\u636e\u63d0\u53d6\u3001\u591a\u6a21\u5f0f\u4fe1\u606f\u7406\u89e3\u548c\u957f\u4e0a\u4e0b\u6587\u9605\u8bfb\u7b49\u6311\u6218\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u5b58\u5728\u57fa\u51c6\u6765\u8bc4\u4f30\u5b83\u4eec\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff08\u5176\u4e2d\u539f\u59cb\u6587\u4ef6\u548c\u95ee\u9898\u4f5c\u4e3a\u8f93\u5165\u63d0\u4f9b\uff0c\u5e76\u4e14\u9884\u671f\u76f8\u5e94\u7684\u54cd\u5e94\u4f5c\u4e3a\u8f93\u51fa\uff09\u7684\u6027\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 DocBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u65e8\u5728\u8bc4\u4f30\u57fa\u4e8e LLM \u7684\u6587\u6863\u9605\u8bfb\u7cfb\u7edf\u7684\u65b0\u57fa\u51c6\u3002\u6211\u4eec\u7684\u57fa\u51c6\u6d89\u53ca\u4e00\u4e2a\u7cbe\u5fc3\u5236\u4f5c\u7684\u8fc7\u7a0b\uff0c\u5305\u62ec\u62db\u52df\u4eba\u7c7b\u6ce8\u91ca\u5458\u548c\u751f\u6210\u5408\u6210\u95ee\u9898\u3002\u5b83\u5305\u62ec 229 \u4e2a\u771f\u5b9e\u6587\u6863\u548c 1,102 \u4e2a\u95ee\u9898\uff0c\u8de8\u8d8a\u4e94\u4e2a\u4e0d\u540c\u7684\u9886\u57df\u548c\u56db\u79cd\u4e3b\u8981\u7c7b\u578b\u7684\u200b\u200b\u95ee\u9898\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u53ef\u901a\u8fc7\u7f51\u7edc\u754c\u9762\u6216 API \u8bbf\u95ee\u7684\u4e13\u6709\u57fa\u4e8e LLM \u7684\u7cfb\u7edf\u4ee5\u53ca\u91c7\u7528\u5f00\u6e90 LLM \u7684\u89e3\u6790\u7136\u540e\u9605\u8bfb\u7ba1\u9053\u3002\u6211\u4eec\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u73b0\u6709\u7684\u57fa\u4e8e LLM \u7684\u6587\u6863\u9605\u8bfb\u7cfb\u7edf\u548c\u4eba\u7c7b\u8868\u73b0\u4e4b\u95f4\u7684\u663e\u7740\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u719f\u7ec3\u7cfb\u7edf\u7684\u6311\u6218\u3002\u603b\u4e4b\uff0cDocBench \u65e8\u5728\u4e3a\u8bc4\u4f30\u57fa\u4e8e LLM \u7684\u6587\u6863\u9605\u8bfb\u7cfb\u7edf\u5728\u5404\u79cd\u73b0\u5b9e\u573a\u666f\u4e0b\u7684\u6027\u80fd\u5efa\u7acb\u4e00\u4e2a\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u4ece\u800c\u6307\u5bfc\u8be5\u7814\u7a76\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u3002</paragraph>", "author": "Anni Zou et.al.", "authors": "Anni Zou, Wenhao Yu, Hongming Zhang, Kaixin Ma, Deng Cai, Zhuosheng Zhang, Hai Zhao, Dong Yu", "id": "2407.10701v1", "paper_url": "http://arxiv.org/abs/2407.10701v1", "repo": "null"}}