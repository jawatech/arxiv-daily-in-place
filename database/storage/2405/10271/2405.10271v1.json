{"2405.10271": {"publish_time": "2024-05-16", "title": "Automated Federated Learning via Informed Pruning", "paper_summary": "Federated learning (FL) represents a pivotal shift in machine learning (ML)\nas it enables collaborative training of local ML models coordinated by a\ncentral aggregator, all without the need to exchange local data. However, its\napplication on edge devices is hindered by limited computational capabilities\nand data communication challenges, compounded by the inherent complexity of\nDeep Learning (DL) models. Model pruning is identified as a key technique for\ncompressing DL models on devices with limited resources. Nonetheless,\nconventional pruning techniques typically rely on manually crafted heuristics\nand demand human expertise to achieve a balance between model size, speed, and\naccuracy, often resulting in sub-optimal solutions.\n  In this study, we introduce an automated federated learning approach\nutilizing informed pruning, called AutoFLIP, which dynamically prunes and\ncompresses DL models within both the local clients and the global server. It\nleverages a federated loss exploration phase to investigate model gradient\nbehavior across diverse datasets and losses, providing insights into parameter\nsignificance. Our experiments showcase notable enhancements in scenarios with\nstrong non-IID data, underscoring AutoFLIP's capacity to tackle computational\nconstraints and achieve superior global convergence.", "paper_summary_zh": "\u806f\u90a6\u5b78\u7fd2 (FL) \u4ee3\u8868\u6a5f\u5668\u5b78\u7fd2 (ML) \u7684\u95dc\u9375\u8f49\u8b8a\uff0c\u56e0\u70ba\u5b83\u80fd\u8b93\u7531\u4e2d\u592e\u805a\u5408\u5668\u5354\u8abf\u7684\u672c\u5730 ML \u6a21\u578b\u9032\u884c\u5354\u4f5c\u8a13\u7df4\uff0c\u800c\u7121\u9700\u4ea4\u63db\u672c\u5730\u6578\u64da\u3002\u7136\u800c\uff0c\u5176\u5728\u908a\u7de3\u88dd\u7f6e\u4e0a\u7684\u61c9\u7528\u53d7\u5230\u6709\u9650\u7684\u904b\u7b97\u80fd\u529b\u548c\u8cc7\u6599\u50b3\u8f38\u6311\u6230\u7684\u963b\u7919\uff0c\u800c\u6df1\u5ea6\u5b78\u7fd2 (DL) \u6a21\u578b\u7684\u5167\u5728\u8907\u96dc\u6027\u66f4\u8b93\u554f\u984c\u96ea\u4e0a\u52a0\u971c\u3002\u6a21\u578b\u526a\u679d\u88ab\u8996\u70ba\u5728\u8cc7\u6e90\u6709\u9650\u7684\u88dd\u7f6e\u4e0a\u58d3\u7e2e DL \u6a21\u578b\u7684\u4e00\u9805\u95dc\u9375\u6280\u8853\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u50b3\u7d71\u7684\u526a\u679d\u6280\u8853\u901a\u5e38\u4f9d\u8cf4\u65bc\u4eba\u5de5\u88fd\u4f5c\u7684\u555f\u767c\u6cd5\uff0c\u4e26\u9700\u8981\u4eba\u985e\u5c08\u5bb6\u624d\u80fd\u5728\u6a21\u578b\u5927\u5c0f\u3001\u901f\u5ea6\u548c\u6e96\u78ba\u6027\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\uff0c\u9019\u5e38\u5e38\u5c0e\u81f4\u6b21\u512a\u7684\u89e3\u6c7a\u65b9\u6848\u3002\n\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u81ea\u52d5\u5316\u7684\u806f\u90a6\u5b78\u7fd2\u65b9\u6cd5\uff0c\u5229\u7528\u7a31\u70ba AutoFLIP \u7684\u77e5\u60c5\u526a\u679d\uff0c\u5b83\u6703\u52d5\u614b\u526a\u679d\u4e26\u58d3\u7e2e\u672c\u5730\u7528\u6236\u7aef\u548c\u5168\u7403\u4f3a\u670d\u5668\u4e2d\u7684 DL \u6a21\u578b\u3002\u5b83\u5229\u7528\u806f\u90a6\u640d\u5931\u63a2\u7d22\u968e\u6bb5\u4f86\u63a2\u8a0e\u5404\u7a2e\u8cc7\u6599\u96c6\u548c\u640d\u5931\u4e2d\u7684\u6a21\u578b\u68af\u5ea6\u884c\u70ba\uff0c\u63d0\u4f9b\u5c0d\u53c3\u6578\u91cd\u8981\u6027\u7684\u898b\u89e3\u3002\u6211\u5011\u7684\u5be6\u9a57\u5c55\u793a\u4e86\u5728\u5177\u6709\u5f37\u975e IID \u8cc7\u6599\u7684\u60c5\u6cc1\u4e0b\u986f\u8457\u7684\u6539\u9032\uff0c\u7a81\u986f\u4e86 AutoFLIP \u8655\u7406\u904b\u7b97\u9650\u5236\u548c\u5be6\u73fe\u512a\u8d8a\u7684\u6574\u9ad4\u6536\u6582\u7684\u80fd\u529b\u3002", "author": "Christian Intern\u00f2 et.al.", "authors": "Christian Intern\u00f2, Elena Raponi, Niki van Stein, Thomas B\u00e4ck, Markus Olhofer, Yaochu Jin, Barbara Hammer", "id": "2405.10271v1", "paper_url": "http://arxiv.org/abs/2405.10271v1", "repo": "https://github.com/christianinterno/autoflip"}}