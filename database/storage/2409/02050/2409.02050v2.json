{"2409.02050": {"publish_time": "2024-09-03", "title": "Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model", "paper_summary": "Due to the inherent difficulty in modeling phonetic similarities across\ndifferent languages, code-switching speech recognition presents a formidable\nchallenge. This study proposes a Collaborative-MoE, a Mixture of Experts (MoE)\nmodel that leverages a collaborative mechanism among expert groups. Initially,\na preceding routing network explicitly learns Language Identification (LID)\ntasks and selects experts based on acquired LID weights. This process ensures\nrobust routing information to the MoE layer, mitigating interference from\ndiverse language domains on expert network parameter updates. The LID weights\nare also employed to facilitate inter-group collaboration, enabling the\nintegration of language-specific representations. Furthermore, within each\nlanguage expert group, a gating network operates unsupervised to foster\ncollaboration on attributes beyond language. Extensive experiments demonstrate\nthe efficacy of our approach, achieving significant performance enhancements\ncompared to alternative methods. Importantly, our method preserves the\nefficient inference capabilities characteristic of MoE models without\nnecessitating additional pre-training.", "paper_summary_zh": "\u7531\u65bc\u8de8\u8a9e\u8a00\u5efa\u6a21\u97f3\u76f8\u4f3c\u6027\u7684\u5167\u5728\u56f0\u96e3\uff0c\u4ee3\u78bc\u5207\u63db\u8a9e\u97f3\u8fa8\u8b58\u5448\u73fe\u51fa\u4e00\u500b\u8271\u9245\u7684\u6311\u6230\u3002\u672c\u7814\u7a76\u63d0\u51fa\u5354\u4f5c\u5f0f MoE\uff0c\u4e00\u7a2e\u5c08\u5bb6\u6df7\u5408 (MoE) \u6a21\u578b\uff0c\u8a72\u6a21\u578b\u5229\u7528\u5c08\u5bb6\u7fa4\u7d44\u4e4b\u9593\u7684\u5354\u4f5c\u6a5f\u5236\u3002\u6700\u521d\uff0c\u5148\u884c\u8def\u7531\u7db2\u8def\u660e\u78ba\u5b78\u7fd2\u8a9e\u8a00\u8fa8\u8b58 (LID) \u4efb\u52d9\uff0c\u4e26\u6839\u64da\u53d6\u5f97\u7684 LID \u6b0a\u91cd\u9078\u64c7\u5c08\u5bb6\u3002\u6b64\u7a0b\u5e8f\u78ba\u4fdd\u7a69\u5065\u7684\u8def\u7531\u8cc7\u8a0a\u50b3\u9001\u81f3 MoE \u5c64\uff0c\u6e1b\u8f15\u4f86\u81ea\u4e0d\u540c\u8a9e\u8a00\u9818\u57df\u7684\u5e72\u64fe\uff0c\u5f71\u97ff\u5c08\u5bb6\u7db2\u8def\u53c3\u6578\u66f4\u65b0\u3002LID \u6b0a\u91cd\u4e5f\u7528\u65bc\u4fc3\u9032\u7fa4\u7d44\u9593\u5354\u4f5c\uff0c\u8b93\u8a9e\u8a00\u7279\u5b9a\u8868\u793a\u5f97\u4ee5\u6574\u5408\u3002\u6b64\u5916\uff0c\u5728\u6bcf\u500b\u8a9e\u8a00\u5c08\u5bb6\u7fa4\u7d44\u4e2d\uff0c\u4e00\u500b\u9598\u63a7\u7db2\u8def\u6703\u5728\u6c92\u6709\u76e3\u7763\u7684\u60c5\u6cc1\u4e0b\u904b\u4f5c\uff0c\u4ee5\u4fc3\u9032\u8a9e\u8a00\u4ee5\u5916\u5c6c\u6027\u7684\u5354\u4f5c\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6548\u80fd\uff0c\u8207\u5176\u4ed6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u9054\u5230\u4e86\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u4fdd\u7559\u4e86 MoE \u6a21\u578b\u7279\u6709\u7684\u9ad8\u6548\u63a8\u8ad6\u80fd\u529b\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u9810\u8a13\u7df4\u3002", "author": "Hukai Huang et.al.", "authors": "Hukai Huang, Jiayan Lin, Kaidi Wang, Yishuang Li, Wenhao Guan, Lin Li, Qingyang Hong", "id": "2409.02050v2", "paper_url": "http://arxiv.org/abs/2409.02050v2", "repo": "null"}}