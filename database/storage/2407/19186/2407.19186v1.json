{"2407.19186": {"publish_time": "2024-07-27", "title": "Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation", "paper_summary": "Accurate nuclei segmentation is an essential foundation for various\napplications in computational pathology, including cancer diagnosis and\ntreatment planning. Even slight variations in nuclei representations can\nsignificantly impact these downstream tasks. However, achieving accurate\nsegmentation remains challenging due to factors like clustered nuclei, high\nintra-class variability in size and shape, resemblance to other cells, and\ncolor or contrast variations between nuclei and background. Despite the\nextensive utilization of Convolutional Neural Networks (CNNs) in medical image\nsegmentation, they may have trouble capturing long-range dependencies crucial\nfor accurate nuclei delineation. Transformers address this limitation but might\nmiss essential low-level features. To overcome these limitations, we utilized\nCNN-Transformer-based techniques for nuclei segmentation in H&E stained\nhistology images. In this work, we proposed two CNN-Transformer architectures,\nNuclei Hybrid Vision Transformer (NucleiHVT) and Channel Boosted Nuclei Hybrid\nVision Transformer (CB-NucleiHVT), that leverage the strengths of both CNNs and\nTransformers to effectively learn nuclei boundaries in multi-organ histology\nimages. The first architecture, NucleiHVT is inspired by the UNet architecture\nand incorporates the dual attention mechanism to capture both multi-level and\nmulti-scale context effectively. The CB-NucleiHVT network, on the other hand,\nutilizes the concept of channel boosting to learn diverse feature spaces,\nenhancing the model's ability to distinguish subtle variations in nuclei\ncharacteristics. Detailed evaluation of two medical image segmentation datasets\nshows that the proposed architectures outperform existing CNN-based,\nTransformer-based, and hybrid methods. The proposed networks demonstrated\neffective results both in terms of quantitative metrics, and qualitative visual\nassessment.", "paper_summary_zh": "\u7cbe\u78ba\u7684\u7d30\u80de\u6838\u5206\u5272\u662f\u8a08\u7b97\u75c5\u7406\u5b78\u4e2d\u5404\u7a2e\u61c9\u7528\uff08\u5305\u62ec\u764c\u75c7\u8a3a\u65b7\u548c\u6cbb\u7642\u898f\u5283\uff09\u7684\u57fa\u790e\u3002\u5373\u4f7f\u7d30\u80de\u6838\u8868\u73fe\u5f62\u5f0f\u6709\u8f15\u5fae\u8b8a\u5316\uff0c\u4e5f\u6703\u5c0d\u9019\u4e9b\u4e0b\u6e38\u4efb\u52d9\u7522\u751f\u91cd\u5927\u5f71\u97ff\u3002\u7136\u800c\uff0c\u7531\u65bc\u7d30\u80de\u6838\u805a\u96c6\u3001\u5927\u5c0f\u548c\u5f62\u72c0\u7684\u985e\u5167\u8b8a\u7570\u6027\u9ad8\u3001\u8207\u5176\u4ed6\u7d30\u80de\u76f8\u4f3c\u3001\u7d30\u80de\u6838\u8207\u80cc\u666f\u4e4b\u9593\u7684\u984f\u8272\u6216\u5c0d\u6bd4\u5ea6\u8b8a\u5316\u7b49\u56e0\u7d20\uff0c\u5be6\u73fe\u7cbe\u78ba\u5206\u5272\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5118\u7ba1\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u5728\u91ab\u5b78\u5f71\u50cf\u5206\u5272\u4e2d\u5f97\u5230\u5ee3\u6cdb\u61c9\u7528\uff0c\u4f46\u5b83\u5011\u53ef\u80fd\u96e3\u4ee5\u6355\u6349\u5c0d\u65bc\u7cbe\u78ba\u7d30\u80de\u6838\u63cf\u7e6a\u81f3\u95dc\u91cd\u8981\u7684\u9577\u7a0b\u4f9d\u8cf4\u6027\u3002Transformer \u89e3\u6c7a\u4e86\u9019\u500b\u9650\u5236\uff0c\u4f46\u53ef\u80fd\u6703\u932f\u904e\u5fc5\u8981\u7684\u4f4e\u968e\u7279\u5fb5\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u5229\u7528\u57fa\u65bc CNN-Transformer \u7684\u6280\u8853\u5c0d H&E \u67d3\u8272\u7684\u7d44\u7e54\u5b78\u5f71\u50cf\u9032\u884c\u7d30\u80de\u6838\u5206\u5272\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5169\u7a2e CNN-Transformer \u67b6\u69cb\uff0c\u5373\u7d30\u80de\u6838\u6df7\u5408\u8996\u89ba Transformer\uff08NucleiHVT\uff09\u548c\u901a\u9053\u589e\u5f37\u7d30\u80de\u6838\u6df7\u5408\u8996\u89ba Transformer\uff08CB-NucleiHVT\uff09\uff0c\u5b83\u5011\u5229\u7528 CNN \u548c Transformer \u7684\u512a\u52e2\u4f86\u6709\u6548\u5b78\u7fd2\u591a\u5668\u5b98\u7d44\u7e54\u5b78\u5f71\u50cf\u4e2d\u7684\u7d30\u80de\u6838\u908a\u754c\u3002\u7b2c\u4e00\u500b\u67b6\u69cb NucleiHVT \u53d7\u5230 UNet \u67b6\u69cb\u7684\u555f\u767c\uff0c\u4e26\u7d50\u5408\u96d9\u6ce8\u610f\u529b\u6a5f\u5236\u4f86\u6709\u6548\u6355\u6349\u591a\u5c64\u7d1a\u548c\u591a\u5c3a\u5ea6\u7684\u80cc\u666f\u3002\u53e6\u4e00\u65b9\u9762\uff0cCB-NucleiHVT \u7db2\u8def\u5229\u7528\u901a\u9053\u589e\u5f37\u7684\u6982\u5ff5\u4f86\u5b78\u7fd2\u4e0d\u540c\u7684\u7279\u5fb5\u7a7a\u9593\uff0c\u589e\u5f37\u6a21\u578b\u5340\u5206\u7d30\u80de\u6838\u7279\u5fb5\u7d30\u5fae\u8b8a\u5316\u7684\u80fd\u529b\u3002\u5c0d\u5169\u500b\u91ab\u5b78\u5f71\u50cf\u5206\u5272\u8cc7\u6599\u96c6\u7684\u8a73\u7d30\u8a55\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u512a\u65bc\u73fe\u6709\u7684\u57fa\u65bc CNN\u3001\u57fa\u65bc Transformer \u548c\u6df7\u5408\u65b9\u6cd5\u3002\u6240\u63d0\u51fa\u7684\u7db2\u8def\u5728\u91cf\u5316\u6307\u6a19\u548c\u5b9a\u6027\u8996\u89ba\u8a55\u4f30\u65b9\u9762\u90fd\u5c55\u793a\u4e86\u6709\u6548\u7d50\u679c\u3002", "author": "Zunaira Rauf et.al.", "authors": "Zunaira Rauf, Abdul Rehman Khan, Asifullah Khan", "id": "2407.19186v1", "paper_url": "http://arxiv.org/abs/2407.19186v1", "repo": "null"}}