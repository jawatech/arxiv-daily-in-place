{"2501.16673": {"publish_time": "2025-01-28", "title": "Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting", "paper_summary": "Large Language Models (LLMs) have reshaped natural language processing,\npowering applications from multi-hop retrieval and question answering to\nautonomous agent workflows. Yet, prompt engineering -- the task of crafting\ntextual inputs to effectively direct LLMs -- remains difficult and\nlabor-intensive, particularly for complex pipelines that combine multiple LLM\ncalls with functional operations like retrieval and data formatting. We\nintroduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering\n(APE) that extends textual gradient-based methods (such as Text-Grad) to\nmulti-component, potentially cyclic LLM architectures. Implemented within the\nAdalFlow library, LLM-AutoDiff treats each textual input as a trainable\nparameter and uses a frozen backward engine LLM to generate feedback-akin to\ntextual gradients -- that guide iterative prompt updates. Unlike prior\nsingle-node approaches, LLM-AutoDiff inherently accommodates functional nodes,\npreserves time-sequential behavior in repeated calls (e.g., multi-hop loops),\nand combats the \"lost-in-the-middle\" problem by isolating distinct sub-prompts\n(instructions, formats, or few-shot examples). It further boosts training\nefficiency by focusing on error-prone samples through selective gradient\ncomputation. Across diverse tasks, including single-step classification,\nmulti-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff\nconsistently outperforms existing textual gradient baselines in both accuracy\nand training cost. By unifying prompt optimization through a graph-centric\nlens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating\nLLM workflows - mirroring the transformative role that automatic\ndifferentiation libraries have long played in neural network research.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u7d93\u91cd\u5851\u81ea\u7136\u8a9e\u8a00\u8655\u7406\uff0c\u70ba\u5f9e\u591a\u8df3\u6aa2\u7d22\u548c\u554f\u7b54\u5230\u81ea\u4e3b\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7684\u61c9\u7528\u63d0\u4f9b\u52d5\u529b\u3002\u7136\u800c\uff0c\u63d0\u793a\u5de5\u7a0b\uff08\u88fd\u4f5c\u6587\u672c\u8f38\u5165\u4ee5\u6709\u6548\u5f15\u5c0e LLM \u7684\u4efb\u52d9\uff09\u4ecd\u7136\u56f0\u96e3\u4e14\u52de\u52d5\u5bc6\u96c6\uff0c\u5c24\u5176\u662f\u5c0d\u65bc\u5c07\u591a\u500b LLM \u547c\u53eb\u8207\u51fd\u6578\u64cd\u4f5c\uff08\u5982\u6aa2\u7d22\u548c\u6578\u64da\u683c\u5f0f\u5316\uff09\u7d50\u5408\u7684\u8907\u96dc\u7ba1\u9053\u3002\u6211\u5011\u4ecb\u7d39 LLM-AutoDiff\uff1a\u4e00\u500b\u7528\u65bc\u81ea\u52d5\u63d0\u793a\u5de5\u7a0b (APE) \u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5c07\u57fa\u65bc\u6587\u672c\u68af\u5ea6\u7684\u7684\u65b9\u6cd5\uff08\u4f8b\u5982 Text-Grad\uff09\u64f4\u5c55\u5230\u591a\u7d44\u6210\u90e8\u5206\u3001\u6f5b\u5728\u5faa\u74b0\u7684 LLM \u67b6\u69cb\u3002\u5728 AdalFlow \u5eab\u4e2d\u5be6\u65bd\uff0cLLM-AutoDiff \u5c07\u6bcf\u500b\u6587\u672c\u8f38\u5165\u8996\u70ba\u53ef\u8a13\u7df4\u53c3\u6578\uff0c\u4e26\u4f7f\u7528\u51cd\u7d50\u7684\u5f8c\u5411\u5f15\u64ce LLM \u4f86\u751f\u6210\u53cd\u994b\uff0c\u985e\u4f3c\u65bc\u6587\u672c\u68af\u5ea6\uff0c\u4ee5\u6307\u5c0e\u53cd\u8986\u63d0\u793a\u66f4\u65b0\u3002\u8207\u5148\u524d\u7684\u55ae\u7bc0\u9ede\u65b9\u6cd5\u4e0d\u540c\uff0cLLM-AutoDiff \u672c\u8cea\u4e0a\u9069\u61c9\u529f\u80fd\u7bc0\u9ede\uff0c\u5728\u91cd\u8907\u547c\u53eb\u4e2d\u4fdd\u7559\u6642\u9593\u9806\u5e8f\u884c\u70ba\uff08\u4f8b\u5982\uff0c\u591a\u8df3\u5faa\u74b0\uff09\uff0c\u4e26\u901a\u904e\u9694\u96e2\u4e0d\u540c\u7684\u5b50\u63d0\u793a\uff08\u6307\u4ee4\u3001\u683c\u5f0f\u6216\u5c11\u6578\u93e1\u982d\u793a\u4f8b\uff09\u4f86\u89e3\u6c7a\u300c\u8ff7\u5931\u5728\u4e2d\u9593\u300d\u7684\u554f\u984c\u3002\u5b83\u9032\u4e00\u6b65\u901a\u904e\u9078\u64c7\u6027\u68af\u5ea6\u8a08\u7b97\u5c08\u6ce8\u65bc\u5bb9\u6613\u51fa\u932f\u7684\u6a23\u672c\u4f86\u63d0\u9ad8\u8a13\u7df4\u6548\u7387\u3002\u5728\u5305\u62ec\u55ae\u6b65\u5206\u985e\u3001\u57fa\u65bc\u591a\u8df3\u6aa2\u7d22\u7684\u554f\u7b54\u548c\u4ee3\u7406\u9a45\u52d5\u7ba1\u9053\u5728\u5167\u7684\u5404\u7a2e\u4efb\u52d9\u4e2d\uff0cLLM-AutoDiff \u5728\u6e96\u78ba\u6027\u548c\u8a13\u7df4\u6210\u672c\u65b9\u9762\u59cb\u7d42\u512a\u65bc\u73fe\u6709\u7684\u6587\u672c\u68af\u5ea6\u57fa\u6e96\u3002\u901a\u904e\u4ee5\u5716\u5f62\u70ba\u4e2d\u5fc3\u7684\u8996\u89d2\u7d71\u4e00\u63d0\u793a\u512a\u5316\uff0cLLM-AutoDiff \u70ba\u64f4\u5c55\u548c\u81ea\u52d5\u5316 LLM \u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u4e00\u500b\u5f37\u5927\u7684\u65b0\u7bc4\u4f8b\uff0c\u53cd\u6620\u4e86\u81ea\u52d5\u5fae\u5206\u5eab\u9577\u671f\u5728\u795e\u7d93\u7db2\u8def\u7814\u7a76\u4e2d\u767c\u63ee\u7684\u8b8a\u9769\u6027\u4f5c\u7528\u3002", "author": "Li Yin et.al.", "authors": "Li Yin, Zhangyang Wang", "id": "2501.16673v1", "paper_url": "http://arxiv.org/abs/2501.16673v1", "repo": "https://github.com/sylphai-inc/adalflow"}}