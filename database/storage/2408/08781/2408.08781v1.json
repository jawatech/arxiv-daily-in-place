{"2408.08781": {"publish_time": "2024-08-16", "title": "Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions", "paper_summary": "LLMs-as-a-judge is a recently popularized method which replaces human\njudgements in task evaluation (Zheng et al. 2024) with automatic evaluation\nusing LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human\nFeedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have\nstrong alignment with human preferences when prompted for a quality judgement,\nsuch as the coherence of a text. While this seems beneficial, it is not clear\nwhether the assessments by an LLM-as-a-judge constitute only an evaluation\nbased on the instructions in the prompts, or reflect its preference for\nhigh-quality data similar to its fine-tune data. To investigate how much\ninfluence prompting the LLMs-as-a-judge has on the alignment of AI judgements\nto human judgements, we analyze prompts with increasing levels of instructions\nabout the target quality of an evaluation, for several LLMs-as-a-judge.\nFurther, we compare to a prompt-free method using model perplexity as a quality\nmeasure instead. We aggregate a taxonomy of quality criteria commonly used\nacross state-of-the-art evaluations with LLMs and provide this as a rigorous\nbenchmark of models as judges. Overall, we show that the LLMs-as-a-judge\nbenefit only little from highly detailed instructions in prompts and that\nperplexity can sometimes align better with human judgements than prompting,\nespecially on textual quality.", "paper_summary_zh": "LLM \u5373\u6cd5\u5b98\u662f\u4e00\u7a2e\u6700\u8fd1\u5f88\u6d41\u884c\u7684\u65b9\u6cd5\uff0c\u5b83\u7528 LLM \u81ea\u52d5\u8a55\u4f30\u53d6\u4ee3\u4e86\u4efb\u52d9\u8a55\u4f30\u4e2d\u7684\u4eba\u985e\u5224\u65b7\uff08\u912d\u7b49\u4eba\uff0c2024 \u5e74\uff09\u3002\u7531\u65bc\u5ee3\u6cdb\u4f7f\u7528 RLHF\uff08\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2\uff09\uff0c\u7576\u63d0\u793a\u9032\u884c\u54c1\u8cea\u5224\u65b7\u6642\uff0c\u4f8b\u5982\u6587\u672c\u7684\u9023\u8cab\u6027\uff0c\u9810\u671f\u50cf GPT4 \u548c Llama3 \u7b49\u6700\u5148\u9032\u7684 LLM \u8207\u4eba\u985e\u504f\u597d\u6709\u5f88\u5f37\u7684\u4e00\u81f4\u6027\u3002\u96d6\u7136\u9019\u770b\u8d77\u4f86\u6709\u76ca\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a LLM \u5373\u6cd5\u5b98\u7684\u8a55\u4f30\u662f\u5426\u50c5\u69cb\u6210\u57fa\u65bc\u63d0\u793a\u4e2d\u8aaa\u660e\u7684\u8a55\u4f30\uff0c\u9084\u662f\u53cd\u6620\u4e86\u5b83\u5c0d\u985e\u4f3c\u65bc\u5176\u5fae\u8abf\u8cc7\u6599\u7684\u9ad8\u54c1\u8cea\u8cc7\u6599\u7684\u504f\u597d\u3002\u70ba\u4e86\u8abf\u67e5\u63d0\u793a LLM \u5373\u6cd5\u5b98\u5c0d AI \u5224\u65b7\u8207\u4eba\u985e\u5224\u65b7\u7684\u4e00\u81f4\u6027\u6709\u591a\u5927\u5f71\u97ff\uff0c\u6211\u5011\u5206\u6790\u4e86\u91dd\u5c0d\u591a\u500b LLM \u5373\u6cd5\u5b98\uff0c\u5305\u542b\u8d8a\u4f86\u8d8a\u9ad8\u5c64\u7d1a\u7684\u8a55\u4f30\u76ee\u6a19\u54c1\u8cea\u8aaa\u660e\u7684\u63d0\u793a\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c07\u5176\u8207\u4e00\u7a2e\u7121\u63d0\u793a\u65b9\u6cd5\u9032\u884c\u6bd4\u8f03\uff0c\u8a72\u65b9\u6cd5\u4f7f\u7528\u6a21\u578b\u56f0\u60d1\u5ea6\u4f5c\u70ba\u54c1\u8cea\u8861\u91cf\u6a19\u6e96\u3002\u6211\u5011\u5f59\u7e3d\u4e86\u4e00\u500b\u5206\u985e\u6cd5\uff0c\u5176\u4e2d\u5305\u542b LLM \u6700\u5148\u9032\u8a55\u4f30\u4e2d\u5e38\u7528\u7684\u54c1\u8cea\u6a19\u6e96\uff0c\u4e26\u5c07\u5176\u4f5c\u70ba\u6a21\u578b\u4f5c\u70ba\u6cd5\u5b98\u7684\u56b4\u683c\u57fa\u6e96\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u8868\u660e LLM \u5373\u6cd5\u5b98\u50c5\u5f9e\u63d0\u793a\u4e2d\u975e\u5e38\u8a73\u7d30\u7684\u8aaa\u660e\u4e2d\u53d7\u76ca\u5f88\u5c11\uff0c\u4e26\u4e14\u56f0\u60d1\u5ea6\u6709\u6642\u53ef\u4ee5\u6bd4\u63d0\u793a\u66f4\u597d\u5730\u8207\u4eba\u985e\u5224\u65b7\u4fdd\u6301\u4e00\u81f4\uff0c\u7279\u5225\u662f\u5728\u6587\u5b57\u54c1\u8cea\u65b9\u9762\u3002", "author": "Bhuvanashree Murugadoss et.al.", "authors": "Bhuvanashree Murugadoss, Christian Poelitz, Ian Drosos, Vu Le, Nick McKenna, Carina Suzana Negreanu, Chris Parnin, Advait Sarkar", "id": "2408.08781v1", "paper_url": "http://arxiv.org/abs/2408.08781v1", "repo": "null"}}