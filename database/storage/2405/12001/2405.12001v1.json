{"2405.12001": {"publish_time": "2024-05-20", "title": "Scrutinize What We Ignore: Reining Task Representation Shift In Context-Based Offline Meta Reinforcement Learning", "paper_summary": "Offline meta reinforcement learning (OMRL) has emerged as a promising\napproach for interaction avoidance and strong generalization performance by\nleveraging pre-collected data and meta-learning techniques. Previous\ncontext-based approaches predominantly rely on the intuition that maximizing\nthe mutual information between the task and the task representation ($I(Z;M)$)\ncan lead to performance improvements. Despite achieving attractive results, the\ntheoretical justification of performance improvement for such intuition has\nbeen lacking. Motivated by the return discrepancy scheme in the model-based RL\nfield, we find that maximizing $I(Z;M)$ can be interpreted as consistently\nraising the lower bound of the expected return for a given policy conditioning\non the optimal task representation. However, this optimization process ignores\nthe task representation shift between two consecutive updates, which may lead\nto performance improvement collapse. To address this problem, we turn to use\nthe framework of performance difference bound to consider the impacts of task\nrepresentation shift explicitly. We demonstrate that by reining the task\nrepresentation shift, it is possible to achieve monotonic performance\nimprovements, thereby showcasing the advantage against previous approaches. To\nmake it practical, we design an easy yet highly effective algorithm RETRO\n(\\underline{RE}ining \\underline{T}ask \\underline{R}epresentation shift in\ncontext-based \\underline{O}ffline meta reinforcement learning) with only adding\none line of code compared to the backbone. Empirical results validate its\nstate-of-the-art (SOTA) asymptotic performance, training stability and\ntraining-time consumption on MuJoCo and MetaWorld benchmarks.", "paper_summary_zh": "\u96e2\u7dda\u5143\u589e\u5f37\u5b78\u7fd2 (OMRL) \u5df2\u6210\u70ba\u4e00\u7a2e\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u5b83\u900f\u904e\u5229\u7528\u9810\u5148\u6536\u96c6\u7684\u8cc7\u6599\u548c\u5143\u5b78\u7fd2\u6280\u8853\uff0c\u4f86\u907f\u514d\u4e92\u52d5\u4e26\u63d0\u5347\u5f37\u5927\u7684\u6cdb\u5316\u6548\u80fd\u3002\u5148\u524d\u7684\u57fa\u65bc\u8108\u7d61\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8cf4\u65bc\u4e00\u500b\u76f4\u89ba\uff0c\u5373\u6700\u5927\u5316\u4efb\u52d9\u8207\u4efb\u52d9\u8868\u793a\u4e4b\u9593\u7684\u4e92\u4fe1\u606f ($I(Z;M)$) \u53ef\u4ee5\u63d0\u5347\u6548\u80fd\u3002\u5118\u7ba1\u7372\u5f97\u4e86\u4ee4\u4eba\u6eff\u610f\u7684\u7d50\u679c\uff0c\u4f46\u5c0d\u65bc\u9019\u7a2e\u76f4\u89ba\u7684\u6548\u80fd\u63d0\u5347\uff0c\u537b\u7f3a\u4e4f\u7406\u8ad6\u4f9d\u64da\u3002\u5728\u57fa\u65bc\u6a21\u578b\u7684 RL \u9818\u57df\u7684\u56de\u5831\u5dee\u7570\u65b9\u6848\u7684\u555f\u767c\u4e0b\uff0c\u6211\u5011\u767c\u73fe\u6700\u5927\u5316 $I(Z;M)$ \u53ef\u4ee5\u89e3\u91cb\u70ba\u4e00\u81f4\u5730\u63d0\u9ad8\u7d66\u5b9a\u7b56\u7565\u5728\u6700\u4f73\u4efb\u52d9\u8868\u793a\u4e0a\u7684\u689d\u4ef6\u9810\u671f\u56de\u5831\u7684\u4e0b\u9650\u3002\u7136\u800c\uff0c\u9019\u500b\u6700\u4f73\u5316\u7a0b\u5e8f\u5ffd\u7565\u4e86\u5169\u500b\u9023\u7e8c\u66f4\u65b0\u4e4b\u9593\u7684\u4efb\u52d9\u8868\u793a\u8f49\u79fb\uff0c\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u6548\u80fd\u63d0\u5347\u5d29\u6f70\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u8f49\u800c\u4f7f\u7528\u6548\u80fd\u5dee\u7570\u754c\u9650\u7684\u67b6\u69cb\uff0c\u4f86\u660e\u78ba\u8003\u616e\u4efb\u52d9\u8868\u793a\u8f49\u79fb\u7684\u5f71\u97ff\u3002\u6211\u5011\u8b49\u660e\uff0c\u900f\u904e\u7d04\u675f\u4efb\u52d9\u8868\u793a\u8f49\u79fb\uff0c\u53ef\u4ee5\u5be6\u73fe\u55ae\u8abf\u7684\u6548\u80fd\u63d0\u5347\uff0c\u5f9e\u800c\u5c55\u793a\u51fa\u76f8\u8f03\u65bc\u5148\u524d\u65b9\u6cd5\u7684\u512a\u52e2\u3002\u70ba\u4e86\u4f7f\u5176\u66f4\u5be6\u7528\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u9ad8\u6548\u7387\u7684\u6f14\u7b97\u6cd5 RETRO\uff08\u5728\u57fa\u65bc\u8108\u7d61\u7684\u96e2\u7dda\u5143\u589e\u5f37\u5b78\u7fd2\u4e2d\u7d04\u675f\u4efb\u52d9\u8868\u793a\u8f49\u79fb\uff09\uff0c\u5b83\u8207\u4e3b\u5e79\u76f8\u6bd4\u53ea\u589e\u52a0\u4e86\u7a0b\u5f0f\u78bc\u7684\u4e00\u884c\u3002\u7d93\u9a57\u7d50\u679c\u9a57\u8b49\u4e86\u5176\u5728 MuJoCo \u548c MetaWorld \u57fa\u6e96\u4e0a\u7684\u6700\u5148\u9032 (SOTA) \u7684\u6f38\u8fd1\u6548\u80fd\u3001\u8a13\u7df4\u7a69\u5b9a\u6027\u548c\u8a13\u7df4\u6642\u9593\u6d88\u8017\u3002", "author": "Hai Zhang et.al.", "authors": "Hai Zhang, Boyuan Zheng, Anqi Guo, Tianying Ji, Pheng-Ann Heng, Junqiao Zhao, Lanqing Li", "id": "2405.12001v1", "paper_url": "http://arxiv.org/abs/2405.12001v1", "repo": "null"}}