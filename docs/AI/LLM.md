
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-24**|**CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**|Sara Ghaboura et.al.|[2410.18976v1](http://arxiv.org/abs/2410.18976v1)|null|
|**2024-10-24**|**Unbounded: A Generative Infinite Game of Character Life Simulation**|Jialu Li et.al.|[2410.18975v1](http://arxiv.org/abs/2410.18975v1)|null|
|**2024-10-24**|**3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**|Hansheng Chen et.al.|[2410.18974v1](http://arxiv.org/abs/2410.18974v1)|[link](https://github.com/Lakonik/MVEdit)|
|**2024-10-24**|**Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**|David Ortiz-Perez et.al.|[2410.18972v1](http://arxiv.org/abs/2410.18972v1)|null|
|**2024-10-24**|**ConceptDrift: Uncovering Biases through the Lens of Foundational Models**|Cristian Daniel Păduraru et.al.|[2410.18970v1](http://arxiv.org/abs/2410.18970v1)|null|
|**2024-10-24**|**Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms**|Zhangheng Li et.al.|[2410.18967v1](http://arxiv.org/abs/2410.18967v1)|null|
|**2024-10-24**|**Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions**|Yujuan Fu et.al.|[2410.18966v1](http://arxiv.org/abs/2410.18966v1)|null|
|**2024-10-24**|**OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning**|Xiaoqiang Wang et.al.|[2410.18963v1](http://arxiv.org/abs/2410.18963v1)|null|
|**2024-10-24**|**Context is Key: A Benchmark for Forecasting with Essential Textual Information**|Andrew Robert Williams et.al.|[2410.18959v1](http://arxiv.org/abs/2410.18959v1)|[link](https://github.com/servicenow/context-is-key-forecasting)|
|**2024-10-24**|**Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code**|Jipeng Zhang et.al.|[2410.18957v1](http://arxiv.org/abs/2410.18957v1)|null|
|**2024-10-24**|**BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning**|Yujuan Velvin Fu et.al.|[2410.18955v1](http://arxiv.org/abs/2410.18955v1)|null|
|**2024-10-24**|**Dynamic Vocabulary Pruning in Early-Exit LLMs**|Jort Vincenti et.al.|[2410.18952v1](http://arxiv.org/abs/2410.18952v1)|[link](https://github.com/matteonulli/vocabulary_pruning)|
|**2024-10-24**|**SegLLM: Multi-round Reasoning Segmentation**|XuDong Wang et.al.|[2410.18923v1](http://arxiv.org/abs/2410.18923v1)|null|
|**2024-10-24**|**From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems**|A M Muntasir Rahman et.al.|[2410.18921v1](http://arxiv.org/abs/2410.18921v1)|null|
|**2024-10-24**|**Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling**|Mingtong Zhang et.al.|[2410.18912v1](http://arxiv.org/abs/2410.18912v1)|null|
|**2024-10-24**|**PRISM: A Methodology for Auditing Biases in Large Language Models**|Leif Azzopardi et.al.|[2410.18906v1](http://arxiv.org/abs/2410.18906v1)|[link](https://github.com/cis-phawm/prism)|
|**2024-10-24**|**LLMs for Extremely Low-Resource Finno-Ugric Languages**|Taido Purason et.al.|[2410.18902v1](http://arxiv.org/abs/2410.18902v1)|null|
|**2024-10-24**|**Creating and Repairing Robot Programs in Open-World Domains**|Claire Schlesinger et.al.|[2410.18893v1](http://arxiv.org/abs/2410.18893v1)|null|
|**2024-10-24**|**Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks**|Graziano A. Manduzio et.al.|[2410.18890v1](http://arxiv.org/abs/2410.18890v1)|null|
|**2024-10-24**|**Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance**|Omer Nahum et.al.|[2410.18889v1](http://arxiv.org/abs/2410.18889v1)|null|
|**2024-10-24**|**A Survey of Multimodal Sarcasm Detection**|Shafkat Farabi et.al.|[2410.18882v1](http://arxiv.org/abs/2410.18882v1)|null|
|**2024-10-24**|**Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences**|Weijian Luo et.al.|[2410.18881v1](http://arxiv.org/abs/2410.18881v1)|null|
|**2024-10-24**|**Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education**|Hannah Beaux et.al.|[2410.18876v1](http://arxiv.org/abs/2410.18876v1)|null|
|**2024-10-24**|**The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models and Detection Methods**|Linda Laurier et.al.|[2410.18866v1](http://arxiv.org/abs/2410.18866v1)|null|
|**2024-10-24**|**Provably Robust Watermarks for Open-Source Language Models**|Miranda Christ et.al.|[2410.18861v1](http://arxiv.org/abs/2410.18861v1)|null|
|**2024-10-24**|**DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations**|Aryo Pradipta Gema et.al.|[2410.18860v1](http://arxiv.org/abs/2410.18860v1)|[link](https://github.com/aryopg/decore)|
|**2024-10-24**|**Demystifying Large Language Models for Medicine: A Primer**|Qiao Jin et.al.|[2410.18856v1](http://arxiv.org/abs/2410.18856v1)|[link](https://github.com/ncbi-nlp/llm-medicine-primer)|
|**2024-10-24**|**We Augmented Whisper With kNN and You Won't Believe What Came Next**|Maya K. Nachesa et.al.|[2410.18850v1](http://arxiv.org/abs/2410.18850v1)|null|
|**2024-10-24**|**Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints**|Udvas Das et.al.|[2410.18844v1](http://arxiv.org/abs/2410.18844v1)|null|
|**2024-10-24**|**From Efficiency to Equity: Measuring Fairness in Preference Learning**|Shreeyash Gowaikar et.al.|[2410.18841v1](http://arxiv.org/abs/2410.18841v1)|null|
|**2024-10-24**|**From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages**|Artur Kiulian et.al.|[2410.18836v1](http://arxiv.org/abs/2410.18836v1)|null|
|**2024-10-24**|**Towards Visual Text Design Transfer Across Languages**|Yejin Choi et.al.|[2410.18823v1](http://arxiv.org/abs/2410.18823v1)|null|
|**2024-10-24**|**From Imitation to Introspection: Probing Self-Consciousness in Language Models**|Sirui Chen et.al.|[2410.18819v1](http://arxiv.org/abs/2410.18819v1)|[link](https://github.com/opencausalab/selfconsciousness)|
|**2024-10-24**|**Delving into the Reversal Curse: How Far Can Large Language Models Generalize?**|Zhengkai Lin et.al.|[2410.18808v1](http://arxiv.org/abs/2410.18808v1)|null|
|**2024-10-24**|**A Combinatorial Approach to Neural Emergent Communication**|Zheyuan Zhang et.al.|[2410.18806v1](http://arxiv.org/abs/2410.18806v1)|null|
|**2024-10-24**|**Distill Visual Chart Reasoning Ability from LLMs to MLLMs**|Wei He et.al.|[2410.18798v1](http://arxiv.org/abs/2410.18798v1)|[link](https://github.com/hewei2001/reachqa)|
|**2024-10-24**|**An LLM Agent for Automatic Geospatial Data Analysis**|Yuxing Chen et.al.|[2410.18792v1](http://arxiv.org/abs/2410.18792v1)|null|
|**2024-10-24**|**Applying Neural Monte Carlo Tree Search to Unsignalized Multi-intersection Scheduling for Autonomous Vehicles**|Yucheng Shi et.al.|[2410.18786v1](http://arxiv.org/abs/2410.18786v1)|null|
|**2024-10-24**|**Should We Really Edit Language Models? On the Evaluation of Edited Language Models**|Qi Li et.al.|[2410.18785v1](http://arxiv.org/abs/2410.18785v1)|[link](https://github.com/lqinfdim/editingevaluation)|
|**2024-10-24**|**A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs**|Ankit Singh Rawat et.al.|[2410.18779v1](http://arxiv.org/abs/2410.18779v1)|null|
|**2024-10-24**|**Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances**|Shilin Lu et.al.|[2410.18775v1](http://arxiv.org/abs/2410.18775v1)|[link](https://github.com/shilin-lu/vine)|
|**2024-10-24**|**Task Calibration: Calibrating Large Language Models on Inference Tasks**|Yingjie Li et.al.|[2410.18764v1](http://arxiv.org/abs/2410.18764v1)|null|
|**2024-10-24**|**Does Differential Privacy Impact Bias in Pretrained NLP Models?**|Md. Khairul Islam et.al.|[2410.18749v1](http://arxiv.org/abs/2410.18749v1)|[link](https://github.com/khairulislam/dp-on-nlp-bias)|
|**2024-10-24**|**Why Does the Effective Context Length of LLMs Fall Short?**|Chenxin An et.al.|[2410.18745v1](http://arxiv.org/abs/2410.18745v1)|null|
|**2024-10-24**|**AI Readiness in Healthcare through Storytelling XAI**|Akshat Dubey et.al.|[2410.18725v1](http://arxiv.org/abs/2410.18725v1)|null|
|**2024-10-24**|**GeoLoRA: Geometric integration for parameter efficient fine-tuning**|Steffen Schotthöfer et.al.|[2410.18720v1](http://arxiv.org/abs/2410.18720v1)|null|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Low-Latency Video Anonymization for Crowd Anomaly Detection: Privacy vs. Performance**|Mulugeta Weldezgina Asres et.al.|[2410.18717v1](http://arxiv.org/abs/2410.18717v1)|null|
|**2024-10-24**|**GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning**|Rita Ramos et.al.|[2410.18702v1](http://arxiv.org/abs/2410.18702v1)|null|
|**2024-10-24**|**How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs**|Ran Zhang et.al.|[2410.18697v1](http://arxiv.org/abs/2410.18697v1)|null|
|**2024-10-24**|**Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch**|Yuyang Ding et.al.|[2410.18693v1](http://arxiv.org/abs/2410.18693v1)|[link](https://github.com/yyding1/scalequest)|
|**2024-10-24**|**Ali-AUG: Innovative Approaches to Labeled Data Augmentation using One-Step Diffusion Model**|Ali Hamza et.al.|[2410.18678v1](http://arxiv.org/abs/2410.18678v1)|null|
|**2024-10-24**|**Towards Better Open-Ended Text Generation: A Multicriteria Evaluation Framework**|Esteban Garces Arias et.al.|[2410.18653v1](http://arxiv.org/abs/2410.18653v1)|[link](https://github.com/YecanLee/2BeOETG)|
|**2024-10-24**|**$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation**|Woosung Koh et.al.|[2410.18652v1](http://arxiv.org/abs/2410.18652v1)|null|
|**2024-10-24**|**Smart ETL and LLM-based contents classification: the European Smart Tourism Tools Observatory experience**|Diogo Cosme et.al.|[2410.18641v1](http://arxiv.org/abs/2410.18641v1)|[link](https://github.com/resetting-eu/european_stt_observatory)|
|**2024-10-24**|**Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model**|Wenhong Zhu et.al.|[2410.18640v1](http://arxiv.org/abs/2410.18640v1)|null|
|**2024-10-24**|**Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Model**|Jinxu Lin et.al.|[2410.18639v1](http://arxiv.org/abs/2410.18639v1)|null|
|**2024-10-24**|**Multi-agent cooperation through learning-aware policy gradients**|Alexander Meulemans et.al.|[2410.18636v1](http://arxiv.org/abs/2410.18636v1)|null|
|**2024-10-24**|**Little Giants: Synthesizing High-Quality Embedding Data at Scale**|Haonan Chen et.al.|[2410.18634v1](http://arxiv.org/abs/2410.18634v1)|null|
|**2024-10-24**|**Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE**|Sanjay Singh et.al.|[2410.18629v1](http://arxiv.org/abs/2410.18629v1)|null|
|**2024-10-24**|**Wavetable Synthesis Using CVAE for Timbre Control Based on Semantic Label**|Tsugumasa Yutani et.al.|[2410.18628v1](http://arxiv.org/abs/2410.18628v1)|null|
|**2024-10-24**|**SAMG: State-Action-Aware Offline-to-Online Reinforcement Learning with Offline Model Guidance**|Liyu Zhang et.al.|[2410.18626v1](http://arxiv.org/abs/2410.18626v1)|null|
|**2024-10-24**|**Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization**|David Thulke et.al.|[2410.18624v1](http://arxiv.org/abs/2410.18624v1)|null|
|**2024-10-24**|**FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation**|Christopher T. H Teo et.al.|[2410.18615v1](http://arxiv.org/abs/2410.18615v1)|null|
|**2024-10-24**|**TripCast: Pre-training of Masked 2D Transformers for Trip Time Series Forecasting**|Yuhua Liao et.al.|[2410.18612v1](http://arxiv.org/abs/2410.18612v1)|null|
|**2024-10-24**|**STTATTS: Unified Speech-To-Text And Text-To-Speech Model**|Hawau Olamide Toyin et.al.|[2410.18607v1](http://arxiv.org/abs/2410.18607v1)|null|
|**2024-10-24**|**Speech perception: a model of word recognition**|Jean-Marc Luck et.al.|[2410.18590v1](http://arxiv.org/abs/2410.18590v1)|null|
|**2024-10-24**|**Aligning CodeLLMs with Direct Preference Optimization**|Yibo Miao et.al.|[2410.18585v1](http://arxiv.org/abs/2410.18585v1)|null|
|**2024-10-24**|**SIKeD: Self-guided Iterative Knowledge Distillation for mathematical reasoning**|Shivam Adarsh et.al.|[2410.18574v1](http://arxiv.org/abs/2410.18574v1)|[link](https://github.com/kumar-shridhar/siked)|
|**2024-10-24**|**Taipan: Efficient and Expressive State Space Language Models with Selective Attention**|Chien Van Nguyen et.al.|[2410.18572v1](http://arxiv.org/abs/2410.18572v1)|null|
|**2024-10-24**|**Zero-shot Object Navigation with Vision-Language Models Reasoning**|Congcong Wen et.al.|[2410.18570v1](http://arxiv.org/abs/2410.18570v1)|null|
|**2024-10-24**|**Difficult for Whom? A Study of Japanese Lexical Complexity**|Adam Nohejl et.al.|[2410.18567v1](http://arxiv.org/abs/2410.18567v1)|null|
|**2024-10-24**|**Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and Evaluation**|Krzysztof Ociepa et.al.|[2410.18565v1](http://arxiv.org/abs/2410.18565v1)|null|
|**2024-10-24**|**Infinity-MM: Scaling Multimodal Performance with Large-Scale and High-Quality Instruction Data**|Shuhao Gu et.al.|[2410.18558v1](http://arxiv.org/abs/2410.18558v1)|null|
|**2024-10-24**|**Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness**|David Khachaturov et.al.|[2410.18556v1](http://arxiv.org/abs/2410.18556v1)|null|
|**2024-10-24**|**On Explaining with Attention Matrices**|Omar Naim et.al.|[2410.18541v1](http://arxiv.org/abs/2410.18541v1)|[link](https://github.com/omyokun/on-explaining-with-attention-matrices)|
|**2024-10-24**|**LOGO -- Long cOntext aliGnment via efficient preference Optimization**|Zecheng Tang et.al.|[2410.18533v1](http://arxiv.org/abs/2410.18533v1)|null|
|**2024-10-24**|**A Systematic Survey on Instructional Text: From Representation and Downstream NLP Tasks**|Abdulfattah Safa et.al.|[2410.18529v1](http://arxiv.org/abs/2410.18529v1)|null|
|**2024-10-24**|**KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing**|Yifei Yang et.al.|[2410.18517v1](http://arxiv.org/abs/2410.18517v1)|[link](https://github.com/yangyifei729/kvsharer)|
|**2024-10-24**|**Scaling up Masked Diffusion Models on Text**|Shen Nie et.al.|[2410.18514v1](http://arxiv.org/abs/2410.18514v1)|[link](https://github.com/ml-gsai/smdm)|
|**2024-10-24**|**Enhancing Graph Attention Neural Network Performance for Marijuana Consumption Classification through Large-scale Augmented Granger Causality (lsAGC) Analysis of Functional MR Images**|Ali Vosoughi et.al.|[2410.18506v1](http://arxiv.org/abs/2410.18506v1)|null|
|**2024-10-24**|**CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models**|Liangdong Wang et.al.|[2410.18505v1](http://arxiv.org/abs/2410.18505v1)|null|
|**2024-10-24**|**SFB-net for cardiac segmentation: Bridging the semantic gap with attention**|Nicolas Portal et.al.|[2410.18503v1](http://arxiv.org/abs/2410.18503v1)|null|
|**2024-10-24**|**ChineseSafe: A Chinese Benchmark for Evaluating Safety in Large Language Models**|Hengxiang Zhang et.al.|[2410.18491v1](http://arxiv.org/abs/2410.18491v1)|null|
|**2024-10-24**|**LLM as a code generator in Agile Model Driven Development**|Ahmed R. Sadik et.al.|[2410.18489v1](http://arxiv.org/abs/2410.18489v1)|null|
|**2024-10-24**|**Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction**|Sergio Burdisso et.al.|[2410.18481v1](http://arxiv.org/abs/2410.18481v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v1](http://arxiv.org/abs/2410.18475v1)|null|
|**2024-10-24**|**Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities**|Chung-En Sun et.al.|[2410.18469v1](http://arxiv.org/abs/2410.18469v1)|[link](https://github.com/sunchungen/adv-llm)|
|**2024-10-24**|**Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**|Yifan Yang et.al.|[2410.18460v1](http://arxiv.org/abs/2410.18460v1)|null|
|**2024-10-24**|**Verifying Non-friendly Formal Verification Designs: Can We Start Earlier?**|Bryan Olmos et.al.|[2410.18454v1](http://arxiv.org/abs/2410.18454v1)|null|
|**2024-10-24**|**Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs**|Chris Yuhao Liu et.al.|[2410.18451v1](http://arxiv.org/abs/2410.18451v1)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Evaluating and Improving Automatic Speech Recognition Systems for Korean Meteorological Experts**|ChaeHun Park et.al.|[2410.18444v1](http://arxiv.org/abs/2410.18444v1)|null|
|**2024-10-24**|**The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI**|Fulu Li et.al.|[2410.18441v1](http://arxiv.org/abs/2410.18441v1)|null|
|**2024-10-24**|**Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching**|Seoyeon Kim et.al.|[2410.18436v1](http://arxiv.org/abs/2410.18436v1)|null|
|**2024-10-24**|**Building Dialogue Understanding Models for Low-resource Language Indonesian from Scratch**|Donglin Di et.al.|[2410.18430v1](http://arxiv.org/abs/2410.18430v1)|null|
|**2024-10-24**|**Large Language Models Reflect the Ideology of their Creators**|Maarten Buyl et.al.|[2410.18417v1](http://arxiv.org/abs/2410.18417v1)|[link](https://github.com/aida-ugent/llm-ideology-analysis)|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|
|**2024-10-24**|**MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases**|Zhisheng Lin et.al.|[2410.18406v1](http://arxiv.org/abs/2410.18406v1)|null|
|**2024-10-24**|**SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness**|Tanmay Parekh et.al.|[2410.18393v1](http://arxiv.org/abs/2410.18393v1)|null|

#### Abstracts
##### **CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**
2410.18976v1 by Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer

Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.

摘要：近年来，人们对开发能够执行各种视觉推理和理解任务的大型多模态模型（LMM）产生了浓厚的兴趣。这导致了引入多个 LMM 基准来评估 LMM 在不同任务上的表现。然而，大多数现有的 LMM 评估基准主要以英语为中心。在这项工作中，我们开发了一个针对阿拉伯语的综合 LMM 评估基准，以代表超过 4 亿的庞大人口。提出的基准名为 CAMEL-Bench，包含八个不同的领域和 38 个子领域，包括多图像理解、复杂视觉感知、手写文档理解、视频理解、医学成像、植物疾病和基于遥感的土地利用理解，以评估广泛的场景泛化性。我们的 CAMEL-Bench 包含约 29,036 个问题，这些问题是从更大的样本池中筛选出来的，其中质量由母语人士手动验证，以确保可靠的模型评估。我们对闭源（包括 GPT-4 系列）和开源 LMM 进行了评估。我们的分析表明需要大幅改进，尤其是在最好的开源模型中，即使是闭源 GPT-4o 也只获得了 62% 的总体得分。我们的基准和评估脚本是开源的。

##### **Unbounded: A Generative Infinite Game of Character Life Simulation**
2410.18975v1 by Jialu Li, Yuanzhen Li, Neal Wadhwa, Yael Pritch, David E. Jacobs, Michael Rubinstein, Mohit Bansal, Nataniel Ruiz

We introduce the concept of a generative infinite game, a video game that
transcends the traditional boundaries of finite, hard-coded systems by using
generative models. Inspired by James P. Carse's distinction between finite and
infinite games, we leverage recent advances in generative AI to create
Unbounded: a game of character life simulation that is fully encapsulated in
generative models. Specifically, Unbounded draws inspiration from sandbox life
simulations and allows you to interact with your autonomous virtual character
in a virtual world by feeding, playing with and guiding it - with open-ended
mechanics generated by an LLM, some of which can be emergent. In order to
develop Unbounded, we propose technical innovations in both the LLM and visual
generation domains. Specifically, we present: (1) a specialized, distilled
large language model (LLM) that dynamically generates game mechanics,
narratives, and character interactions in real-time, and (2) a new dynamic
regional image prompt Adapter (IP-Adapter) for vision models that ensures
consistent yet flexible visual generation of a character across multiple
environments. We evaluate our system through both qualitative and quantitative
analysis, showing significant improvements in character life simulation, user
instruction following, narrative coherence, and visual consistency for both
characters and the environments compared to traditional related approaches.

摘要：我們引入了生成式無限遊戲的概念，一種透過使用生成式模型而超越了有限、硬編碼系統的傳統界線的電子遊戲。受到詹姆士·P·卡斯的有限遊戲和無限遊戲之間的區別啟發，我們利用生成式 AI 的最新進展來創造 Unbounded：一個完全封裝在生成式模型中的角色生活模擬遊戲。具體來說，Unbounded 從沙盒生活模擬中汲取靈感，並允許你透過餵食、玩耍和引導你的虛擬角色，在虛擬世界中與你的自主虛擬角色互動——這些角色是由大型語言模型 (LLM) 所生成，其中一些可能是新出現的。為了開發 Unbounded，我們在 LLM 和視覺生成領域提出了技術創新。具體來說，我們提出了：(1) 一個專門的、精煉的大型語言模型 (LLM)，它動態生成遊戲機制、敘事和角色互動，並在實時進行，以及 (2) 一個新的動態區域影像提示適配器 (IP-Adapter)，用於視覺模型，它確保了角色在多個環境中的視覺生成的一致性，同時也具有靈活性。我們透過定性和定量分析對我們的系統進行評估，顯示出在角色生活模擬、使用者指令遵循、敘事連貫性和角色與環境的視覺一致性方面，與傳統相關方法相比有顯著的改進。

##### **3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation**
2410.18974v1 by Hansheng Chen, Bokui Shen, Yulin Liu, Ruoxi Shi, Linqi Zhou, Connor Z. Lin, Jiayuan Gu, Hao Su, Gordon Wetzstein, Leonidas Guibas

Multi-view image diffusion models have significantly advanced open-domain 3D
object generation. However, most existing models rely on 2D network
architectures that lack inherent 3D biases, resulting in compromised geometric
consistency. To address this challenge, we introduce 3D-Adapter, a plug-in
module designed to infuse 3D geometry awareness into pretrained image diffusion
models. Central to our approach is the idea of 3D feedback augmentation: for
each denoising step in the sampling loop, 3D-Adapter decodes intermediate
multi-view features into a coherent 3D representation, then re-encodes the
rendered RGBD views to augment the pretrained base model through feature
addition. We study two variants of 3D-Adapter: a fast feed-forward version
based on Gaussian splatting and a versatile training-free version utilizing
neural fields and meshes. Our extensive experiments demonstrate that 3D-Adapter
not only greatly enhances the geometry quality of text-to-multi-view models
such as Instant3D and Zero123++, but also enables high-quality 3D generation
using the plain text-to-image Stable Diffusion. Furthermore, we showcase the
broad application potential of 3D-Adapter by presenting high quality results in
text-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.

摘要：多視圖影像擴散模型在開放領域的 3D 物件生成方面取得了顯著進展。然而，現有的大多數模型依賴於缺乏內在 3D 偏差的 2D 網路架構，導致幾何一致性受損。為了應對這一挑戰，我們引入了 3D-Adapter，這是一個外掛模組，旨在將 3D 幾何感知注入預先訓練的影像擴散模型。我們的方法的核心是 3D 回饋增強的想法：對於採樣循環中的每個去噪步驟，3D-Adapter 將中間的多視圖特徵解碼為一個連貫的 3D 表示，然後重新編碼渲染的 RGBD 視圖，以通過特徵添加來增強預先訓練的基本模型。我們研究了 3D-Adapter 的兩個變體：基於高斯噴射的快速前饋版本和利用神經場和網格的多功能無訓練版本。我們廣泛的實驗證明，3D-Adapter 不僅大大增強了 Instant3D 和 Zero123++ 等文字到多視圖模型的幾何品質，而且還可以使用純文字到影像的 Stable Diffusion 實現高品質的 3D 生成。此外，我們展示了 3D-Adapter 在文字到 3D、影像到 3D、文字到紋理和文字到頭像任務中呈現的高品質結果，展示了其廣泛的應用潛力。

##### **Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**
2410.18972v1 by David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David Tomás, M. Flores Vizcaya-Moreno

Cognitive decline is a natural part of aging, often resulting in reduced
cognitive abilities. In some cases, however, this decline is more pronounced,
typically due to disorders such as Alzheimer's disease. Early detection of
anomalous cognitive decline is crucial, as it can facilitate timely
professional intervention. While medical data can help in this detection, it
often involves invasive procedures. An alternative approach is to employ
non-intrusive techniques such as speech or handwriting analysis, which do not
necessarily affect daily activities. This survey reviews the most relevant
methodologies that use deep learning techniques to automate the cognitive
decline estimation task, including audio, text, and visual processing. We
discuss the key features and advantages of each modality and methodology,
including state-of-the-art approaches like Transformer architecture and
foundation models. In addition, we present works that integrate different
modalities to develop multimodal models. We also highlight the most significant
datasets and the quantitative results from studies using these resources. From
this review, several conclusions emerge. In most cases, the textual modality
achieves the best results and is the most relevant for detecting cognitive
decline. Moreover, combining various approaches from individual modalities into
a multimodal model consistently enhances performance across nearly all
scenarios.

摘要：<paragraph>認知能力下降是老化的自然現象，通常會導致認知能力下降。然而，在某些情況下，這種下降會更加明顯，通常是因為阿茲海默症等疾病。及早發現異常的認知能力下降至關重要，因為它可以促進及時的專業干預。雖然醫療數據有助於這種檢測，但它通常涉及侵入性程序。另一種方法是採用非侵入性技術，例如語音或手寫分析，這些技術不一定會影響日常活動。這項調查回顧了使用深度學習技術自動執行認知能力下降估計任務的最相關方法，包括音訊、文字和視覺處理。我們討論了每個模態和方法的主要特徵和優點，包括Transformer架構和基礎模型等最先進的方法。此外，我們展示了整合不同模態以開發多模態模型的作品。我們還重點介紹了最重要的數據集和使用這些資源的研究的定量結果。從這項回顧中，得出了一些結論。在大多數情況下，文本模態取得了最好的結果，並且與檢測認知能力下降最相關。此外，將來自個別模態的各種方法組合到多模態模型中，會持續增強幾乎所有場景的效能。</paragraph>

##### **ConceptDrift: Uncovering Biases through the Lens of Foundational Models**
2410.18970v1 by Cristian Daniel Păduraru, Antonio Bărbălau, Radu Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu

Datasets and pre-trained models come with intrinsic biases. Most methods rely
on spotting them by analysing misclassified samples, in a semi-automated
human-computer validation. In contrast, we propose ConceptDrift, a method which
analyzes the weights of a linear probe, learned on top a foundational model. We
capitalize on the weight update trajectory, which starts from the embedding of
the textual representation of the class, and proceeds to drift towards
embeddings that disclose hidden biases. Different from prior work, with this
approach we can pin-point unwanted correlations from a dataset, providing more
than just possible explanations for the wrong predictions. We empirically prove
the efficacy of our method, by significantly improving zero-shot performance
with biased-augmented prompting. Our method is not bounded to a single
modality, and we experiment in this work with both image (Waterbirds, CelebA,
Nico++) and text datasets (CivilComments).

摘要：資料集和預先訓練的模型會伴隨內在偏誤。大多數方法依賴於透過分析錯誤分類的樣本，在半自動的人機驗證中找出它們。相反地，我們提出 ConceptDrift，一種分析建立在基礎模型上方的線性探測權重的分析方法。我們利用權重更新軌跡，該軌跡從類別的文字表徵嵌入開始，並朝著揭露隱藏偏誤的嵌入漂移。與先前的研究不同，透過這種方法，我們可以精確找出資料集中的不需要相關性，提供的內容不僅僅是錯誤預測的可能解釋。我們透過大幅改善有偏差增強提示的零次學習表現，實證證明了我們方法的效用。我們的模型不受限於單一模式，我們在這項工作中同時對影像（水鳥、CelebA、Nico++）和文字資料集（CivilComments）進行實驗。

##### **Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms**
2410.18967v1 by Zhangheng Li, Keen You, Haotian Zhang, Di Feng, Harsh Agrawal, Xiujun Li, Mohana Prasad Sathya Moorthy, Jeff Nichols, Yinfei Yang, Zhe Gan

Building a generalist model for user interface (UI) understanding is
challenging due to various foundational issues, such as platform diversity,
resolution variation, and data limitation. In this paper, we introduce
Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI
understanding across a wide range of platforms, including iPhone, Android,
iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI
2 introduces three key innovations: support for multiple platform types,
high-resolution perception through adaptive scaling, and advanced task training
data generation powered by GPT-4o with set-of-mark visual prompting. These
advancements enable Ferret-UI 2 to perform complex, user-centered interactions,
making it highly versatile and adaptable for the expanding diversity of
platform ecosystems. Extensive empirical experiments on referring, grounding,
user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE
next-action prediction dataset, and GUI-World multi-platform benchmark
demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also
shows strong cross-platform transfer capabilities.

摘要：<paragraph>建立一個通用的使用者介面 (UI) 理解模型，由於各種基礎問題（例如平台多樣性、解析度差異和資料限制）而具有挑戰性。在本文中，我們介紹 Ferret-UI 2，這是一個多模態大型語言模型 (MLLM)，旨在跨越廣泛的平台（包括 iPhone、Android、iPad、網頁和 AppleTV）進行通用的 UI 理解。在 Ferret-UI 的基礎上，Ferret-UI 2 引入了三項關鍵創新：支援多種平台類型、透過自適應縮放進行高解析度感知，以及由 GPT-4o 提供支援的進階任務訓練資料產生，並搭配一組視覺提示。這些進展使 Ferret-UI 2 能夠執行複雜且以使用者為中心的互動，使其高度靈活且適應不斷擴展的多樣化平台生態系統。在指涉、基礎、以使用者為中心的進階任務（包含 9 個子任務 $\times$ 5 個平台）、GUIDE 下一個動作預測資料集和 GUI-World 多平台基準上的廣泛實證實驗證明，Ferret-UI 2 明顯優於 Ferret-UI，並且還展現了強大的跨平台傳輸能力。</paragraph>

##### **Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions**
2410.18966v1 by Yujuan Fu, Ozlem Uzuner, Meliha Yetisgen, Fei Xia

Large language models (LLMs) have demonstrated great performance across
various benchmarks, showing potential as general-purpose task solvers. However,
as LLMs are typically trained on vast amounts of data, a significant concern in
their evaluation is data contamination, where overlap between training data and
evaluation datasets inflates performance assessments. While multiple approaches
have been developed to identify data contamination, these approaches rely on
specific assumptions that may not hold universally across different settings.
To bridge this gap, we systematically review 47 papers on data contamination
detection, categorize the underlying assumptions, and assess whether they have
been rigorously validated. We identify and analyze eight categories of
assumptions and test three of them as case studies. Our analysis reveals that
when classifying instances used for pretraining LLMs, detection approaches
based on these three assumptions perform close to random guessing, suggesting
that current LLMs learn data distributions rather than memorizing individual
instances. Overall, this work underscores the importance of approaches clearly
stating their underlying assumptions and testing their validity across various
scenarios.

摘要：大型語言模型 (LLM) 已在各種基準測試中展現出極佳的效能，顯示出作為通用任務解決者的潛力。然而，由於 LLM 通常會在大量的資料上進行訓練，因此在評估時會有一個重大的疑慮，也就是資料污染，訓練資料和評估資料集之間的重疊會讓效能評估膨脹。儘管已開發出多種方法來識別資料污染，但這些方法依賴於特定假設，而這些假設可能無法普遍適用於不同的設定。為了彌補這個差距，我們系統性地檢閱了 47 篇關於資料污染偵測的論文，分類其基本假設，並評估這些假設是否經過嚴謹驗證。我們找出並分析了八類假設，並測試了其中三類作為案例研究。我們的分析顯示，在對用於預訓練 LLM 的實例進行分類時，基於這三個假設的偵測方法表現接近隨機猜測，這表示目前的 LLM 會學習資料分佈，而非記住個別實例。總體而言，這項工作強調了方法清楚說明其基本假設並在各種場景中測試其有效性的重要性。

##### **OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning**
2410.18963v1 by Xiaoqiang Wang, Bang Liu

Large language models (LLMs) and large multimodal models (LMMs) have shown
great potential in automating complex tasks like web browsing and gaming.
However, their ability to generalize across diverse applications remains
limited, hindering broader utility. To address this challenge, we present
OSCAR: Operating System Control via state-Aware reasoning and Re-planning.
OSCAR is a generalist agent designed to autonomously navigate and interact with
various desktop and mobile applications through standardized controls, such as
mouse and keyboard inputs, while processing screen images to fulfill user
commands. OSCAR translates human instructions into executable Python code,
enabling precise control over graphical user interfaces (GUIs). To enhance
stability and adaptability, OSCAR operates as a state machine, equipped with
error-handling mechanisms and dynamic task re-planning, allowing it to
efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's
effectiveness through extensive experiments on diverse benchmarks across
desktop and mobile platforms, where it transforms complex workflows into simple
natural language commands, significantly boosting user productivity. Our code
will be open-source upon publication.

摘要：大型語言模型 (LLM) 和大型多模態模型 (LMM) 已展現出自動化複雜任務（例如網頁瀏覽和遊戲）的巨大潛力。但是，它們在不同應用程式間進行概括的能力仍然有限，阻礙了更廣泛的實用性。為了應對這一挑戰，我們提出了 OSCAR：透過狀態感知推理和重新規劃進行作業系統控制。OSCAR 是一個通才代理，旨在透過標準化控制（例如滑鼠和鍵盤輸入），在處理螢幕影像的同時，自主導航並與各種桌面和行動應用程式進行互動，以執行使用者指令。OSCAR 將人類指令轉換為可執行的 Python 程式碼，讓使用者能夠精確控制圖形使用者介面 (GUI)。為了增強穩定性和適應性，OSCAR 以狀態機運作，並配備錯誤處理機制和動態任務重新規劃，使其能夠有效地調整即時回饋和例外狀況。我們透過在不同基準上進行廣泛的實驗，展示了 OSCAR 在桌面和行動平台上的效能，它將複雜的工作流程轉換為簡單的自然語言指令，大幅提升了使用者的生產力。我們的程式碼將在發表後開放原始碼。

##### **Context is Key: A Benchmark for Forecasting with Essential Textual Information**
2410.18959v1 by Andrew Robert Williams, Arjun Ashok, Étienne Marcotte, Valentina Zantedeschi, Jithendaraa Subramanian, Roland Riachi, James Requeima, Alexandre Lacoste, Irina Rish, Nicolas Chapados, Alexandre Drouin

Forecasting is a critical task in decision making across various domains.
While numerical data provides a foundation, it often lacks crucial context
necessary for accurate predictions. Human forecasters frequently rely on
additional information, such as background knowledge or constraints, which can
be efficiently communicated through natural language. However, the ability of
existing forecasting models to effectively integrate this textual information
remains an open question. To address this, we introduce "Context is Key" (CiK),
a time series forecasting benchmark that pairs numerical data with diverse
types of carefully crafted textual context, requiring models to integrate both
modalities. We evaluate a range of approaches, including statistical models,
time series foundation models, and LLM-based forecasters, and propose a simple
yet effective LLM prompting method that outperforms all other tested methods on
our benchmark. Our experiments highlight the importance of incorporating
contextual information, demonstrate surprising performance when using LLM-based
forecasting models, and also reveal some of their critical shortcomings. By
presenting this benchmark, we aim to advance multimodal forecasting, promoting
models that are both accurate and accessible to decision-makers with varied
technical expertise. The benchmark can be visualized at
https://servicenow.github.io/context-is-key-forecasting/v0/ .

摘要：預測是各個領域決策制定中的一項關鍵任務。
儘管數字資料提供了一個基礎，但它通常缺少準確預測所需的關鍵脈絡。人類預測者經常依賴額外的資訊，例如背景知識或限制，這些資訊可以用自然語言有效地傳達。然而，現有預測模型有效整合這些文字資訊的能力仍然是一個公開的問題。為了解決這個問題，我們引入了「脈絡是關鍵」(CiK)，這是一個時間序列預測基準，將數字資料與各種精心製作的文字脈絡配對，要求模型整合這兩種模式。我們評估了一系列方法，包括統計模型、時間序列基礎模型和基於 LLM 的預測器，並提出了一種簡單但有效的 LLM 提示方法，在我們的基準測試中優於所有其他測試方法。我們的實驗強調了納入脈絡資訊的重要性，展示了使用基於 LLM 的預測模型時令人驚訝的效能，也揭示了它們的一些關鍵缺點。透過提出這個基準，我們旨在推進多模式預測，推廣對具有不同技術專業知識的決策者來說既準確又容易取得的模型。可以在 https://servicenow.github.io/context-is-key-forecasting/v0/ 中視覺化這個基準。

##### **Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code**
2410.18957v1 by Jipeng Zhang, Jianshu Zhang, Yuanzhe Li, Renjie Pi, Rui Pan, Runtao Liu, Ziqiang Zheng, Tong Zhang

Large Language Models (LLMs) demonstrate strong proficiency in generating
code for high-resource programming languages (HRPLs) like Python but struggle
significantly with low-resource programming languages (LRPLs) such as Racket or
D. This performance gap deepens the digital divide, preventing developers using
LRPLs from benefiting equally from LLM advancements and reinforcing disparities
in innovation within underrepresented programming communities. While generating
additional training data for LRPLs is promising, it faces two key challenges:
manual annotation is labor-intensive and costly, and LLM-generated LRPL code is
often of subpar quality. The underlying cause of this issue is the gap between
natural language to programming language gap (NL-PL Gap), which is especially
pronounced in LRPLs due to limited aligned data. In this work, we introduce a
novel approach called Bridge-Coder, which leverages LLMs' intrinsic
capabilities to enhance the performance on LRPLs. Our method consists of two
key stages. Bridge Generation, where we create high-quality dataset by
utilizing LLMs' general knowledge understanding, proficiency in HRPLs, and
in-context learning abilities. Then, we apply the Bridged Alignment, which
progressively improves the alignment between NL instructions and LRPLs.
Experimental results across multiple LRPLs show that Bridge-Coder significantly
enhances model performance, demonstrating the effectiveness and generalization
of our approach. Furthermore, we offer a detailed analysis of the key
components of our method, providing valuable insights for future work aimed at
addressing the challenges associated with LRPLs.

摘要：大型語言模型 (LLM) 展示出生成高資源程式語言 (HRPL) 例如 Python 的程式碼的強大能力，但在低資源程式語言 (LRPL) 例如 Racket 或 D 上卻顯得吃力。這種效能差距加劇了數位鴻溝，讓使用 LRPL 的開發人員無法平等受益於 LLM 的進步，並加劇了代表性不足的程式設計社群中的創新差異。雖然為 LRPL 產生額外的訓練資料很有希望，但它面臨兩個主要挑戰：人工註解既費時又昂貴，而 LLM 生成的 LRPL 程式碼品質通常很差。此問題的根本原因在於自然語言到程式語言的差距 (NL-PL Gap)，由於對齊資料有限，這種差距在 LRPL 中特別明顯。在這項工作中，我們介紹一種稱為 Bridge-Coder 的新方法，它利用 LLM 的內在能力來增強 LRPL 的效能。我們的做法包含兩個關鍵階段。Bridge 生成，我們利用 LLM 的一般知識理解、HRPL 的能力和情境學習能力來建立高品質的資料集。然後，我們應用 Bridged Alignment，它逐步改善 NL 指令和 LRPL 之間的對齊。跨多個 LRPL 的實驗結果顯示，Bridge-Coder 大幅提升了模型效能，證明了我們方法的有效性和概括性。此外，我們對方法的關鍵組成部分進行了詳細分析，為未來旨在解決與 LRPL 相關挑戰的工作提供了寶貴的見解。

##### **BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning**
2410.18955v1 by Yujuan Velvin Fu, Giridhar Kaushik Ramachandran, Namu Park, Kevin Lybarger, Fei Xia, Ozlem Uzuner, Meliha Yetisgen

Large language models (LLMs) such as ChatGPT are fine-tuned on large and
diverse instruction-following corpora, and can generalize to new tasks.
However, those instruction-tuned LLMs often perform poorly in specialized
medical natural language understanding (NLU) tasks that require domain
knowledge, granular text comprehension, and structured data extraction. To
bridge the gap, we: (1) propose a unified prompting format for 7 important NLU
tasks, % through span extraction and multi-choice question-answering (QA), (2)
curate an instruction-tuning dataset, MNLU-Instruct, utilizing diverse existing
open-source medical NLU corpora, and (3) develop BioMistral-NLU, a
generalizable medical NLU model, through fine-tuning BioMistral on
MNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting, across 6
important NLU tasks, from two widely adopted medical NLU benchmarks: Biomedical
Language Understanding Evaluation (BLUE) and Biomedical Language Understanding
and Reasoning Benchmark (BLURB). Our experiments show that our BioMistral-NLU
outperforms the original BioMistral, as well as the proprietary LLMs - ChatGPT
and GPT-4. Our dataset-agnostic prompting strategy and instruction tuning step
over diverse NLU tasks enhance LLMs' generalizability across diverse medical
NLU tasks. Our ablation experiments show that instruction-tuning on a wider
variety of tasks, even when the total number of training instances remains
constant, enhances downstream zero-shot generalization.

摘要：大型語言模型 (LLM) 例如 ChatGPT 會針對大量且多樣化的指令遵循語料庫進行微調，並可概括到新的任務。
然而，經過指令微調的 LLM 在需要領域知識、細緻文字理解和結構化數據萃取的專業醫療自然語言理解 (NLU) 任務中通常表現不佳。為縮小差距，我們：(1) 為 7 項重要的 NLU 任務提出統一的提示格式，透過區間萃取和多選題問答 (QA)，(2) 策劃指令微調資料集 MNLU-Instruct，利用現有的各種開源醫療 NLU 語料庫，以及 (3) 開發 BioMistral-NLU，一種可概括的醫療 NLU 模型，透過在 MNLU-Instruct 上對 BioMistral 進行微調。我們在零次學習設定中評估 BioMistral-NLU，涵蓋 6 項重要的 NLU 任務，來自兩個廣泛採用的醫療 NLU 基準：生物醫學語言理解評估 (BLUE) 和生物醫學語言理解與推理基準 (BLURB)。我們的實驗顯示，我們的 BioMistral-NLU 優於原始的 BioMistral，以及專有的 LLM - ChatGPT 和 GPT-4。我們與資料集無關的提示策略和指令微調步驟，可增強 LLM 在各種醫療 NLU 任務中的概括性。我們的消融實驗顯示，即使訓練實例的總數保持不變，在更多樣化的任務上進行指令微調，也能增強下游的零次學習概括性。

##### **Dynamic Vocabulary Pruning in Early-Exit LLMs**
2410.18952v1 by Jort Vincenti, Karim Abdel Sadek, Joan Velja, Matteo Nulli, Metod Jazbec

Increasing the size of large language models (LLMs) has been shown to lead to
better performance. However, this comes at the cost of slower and more
expensive inference. Early-exiting is a promising approach for improving the
efficiency of LLM inference by enabling next token prediction at intermediate
layers. Yet, the large vocabulary size in modern LLMs makes the confidence
estimation required for exit decisions computationally expensive, diminishing
the efficiency gains. To address this, we propose dynamically pruning the
vocabulary at test time for each token. Specifically, the vocabulary is pruned
at one of the initial layers, and the smaller vocabulary is then used
throughout the rest of the forward pass. Our experiments demonstrate that such
post-hoc dynamic vocabulary pruning improves the efficiency of confidence
estimation in early-exit LLMs while maintaining competitive performance.

摘要：大型語言模型 (LLM) 的規模越大，效能表現越好，這點已獲得證實。然而，代價是推論速度變慢且成本變高。早期退出是一種有前景的方法，可以透過在中間層進行下一個代幣預測，來提升 LLM 推論的效率。然而，現代 LLM 中龐大的詞彙量，使得做出退出決策所需的信心估計在運算上十分昂貴，這降低了效率的提升。為了解決這個問題，我們建議在測試時動態修剪每個代幣的詞彙。具體來說，詞彙會在其中一層進行修剪，然後較小的詞彙會在前進傳遞的其餘部分中使用。我們的實驗證明，這種事後動態詞彙修剪可以提升早期退出 LLM 中信心估計的效率，同時維持有競爭力的效能。

##### **SegLLM: Multi-round Reasoning Segmentation**
2410.18923v1 by XuDong Wang, Shaolun Zhang, Shufan Li, Konstantinos Kallidromitis, Kehan Li, Yusuke Kato, Kazuki Kozuka, Trevor Darrell

We present SegLLM, a novel multi-round interactive reasoning segmentation
model that enhances LLM-based segmentation by exploiting conversational memory
of both visual and textual outputs. By leveraging a mask-aware multimodal LLM,
SegLLM re-integrates previous segmentation results into its input stream,
enabling it to reason about complex user intentions and segment objects in
relation to previously identified entities, including positional,
interactional, and hierarchical relationships, across multiple interactions.
This capability allows SegLLM to respond to visual and text queries in a
chat-like manner. Evaluated on the newly curated MRSeg benchmark, SegLLM
outperforms existing methods in multi-round interactive reasoning segmentation
by over 20%. Additionally, we observed that training on multi-round reasoning
segmentation data enhances performance on standard single-round referring
segmentation and localization tasks, resulting in a 5.5% increase in cIoU for
referring expression segmentation and a 4.5% improvement in Acc@0.5 for
referring expression localization.

摘要：我們提出了 SegLLM，這是一個新穎的多輪互動式推理分割模型，它通過利用視覺和文本輸出的對話式記憶來增強基於 LLM 的分割。通過利用一個感知遮罩的多模態 LLM，SegLLM 將先前的分割結果重新整合到其輸入串流中，使其能夠推理複雜的使用者意圖，並根據先前識別的實體，包括位置、互動和層級關係，在多個互動中分割物件。這種能力使 SegLLM 能夠以類似聊天室的方式回應視覺和文字查詢。在最新整理的 MRSeg 基準上進行評估，SegLLM 在多輪互動式推理分割中優於現有方法超過 20%。此外，我們觀察到在多輪推理分割資料上進行訓練會增強標準單輪指涉分割和定位任務的效能，導致指涉表達式分割的 cIoU 增加 5.5%，指涉表達式定位的 Acc@0.5 提升 4.5%。

##### **From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems**
2410.18921v1 by A M Muntasir Rahman, Junyi Ye, Wei Yao, Wenpeng Yin, Guiling Wang

Consider the math problem: "Lily received 3 cookies from her best friend
yesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.
How many cookies does Lily have now?" Many large language models (LLMs) in
previous research approach this problem by calculating the answer "1" using the
equation "3 - 5 + 3." However, from a human perspective, we recognize the
inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only
had 3. This discrepancy prompts a key question: Are current LLMs merely Blind
Solver that apply mathematical operations without deeper reasoning, or can they
function as Logical Thinker capable of identifying logical inconsistencies?
  To explore this question, we propose a benchmark dataset, FaultyMath, which
includes faulty math problems of rich diversity: i) multiple mathematical
categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of
difficulty, and iii) different origins of faultiness -- ranging from violations
of common sense and ambiguous statements to mathematical contradictions and
more. We evaluate a broad spectrum of LLMs, including open-source,
closed-source, and math-specialized models, using FaultyMath across three
dimensions: (i) How accurately can the models detect faulty math problems
without being explicitly prompted to do so? (ii) When provided with hints --
either correct or misleading -- about the validity of the problems, to what
extent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy
are the explanations generated by LLMs when they recognize a math problem as
flawed? Through extensive experimentation and detailed analysis, our results
demonstrate that existing LLMs largely function as Blind Solver and fall short
of the reasoning capabilities required to perform as Logical Thinker.

摘要：<paragraph>考慮以下數學問題：「莉莉昨天從她最好的朋友那裡收到 3 塊餅乾，並在早餐時吃了 5 塊。今天，她的朋友又給了她 3 塊餅乾。莉莉現在有幾塊餅乾？」在先前的研究中，許多大型語言模型 (LLM) 使用「3 - 5 + 3」方程式計算答案「1」來解決這個問題。然而，從人類的角度來看，我們發現這個問題有一個固有的缺陷：莉莉最初只有 3 塊餅乾，她不可能吃了 5 塊餅乾。這種差異引發了一個關鍵問題：目前的 LLM 是否僅是應用數學運算而沒有更深入推理的盲目求解器，或者它們可以作為能夠識別邏輯不一致性的邏輯思考者運作？為了探討這個問題，我們提出了基準資料集 FaultyMath，其中包含豐富多樣的有缺陷數學問題：i) 多個數學類別，例如代數、幾何、數論等，ii) 不同難度等級，以及 iii) 缺陷的不同來源——從違反常識和模棱兩可的陳述到數學矛盾等等。我們使用 FaultyMath 在三個面向評估廣泛的 LLM，包括開源、閉源和數學專用模型：(i) 模型在沒有明確提示的情況下，可以多準確地偵測有缺陷的數學問題？(ii) 當提供有關問題有效性的提示（正確或誤導）時，LLM 在多大程度上適應成為可靠的邏輯思考者？(iii) 當 LLM 識別出數學問題有缺陷時，它們產生的解釋有多值得信賴？透過廣泛的實驗和詳細的分析，我們的結果表明現有的 LLM 主要作為盲目求解器運作，並且無法達到作為邏輯思考者所需的推理能力。</paragraph>

##### **Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling**
2410.18912v1 by Mingtong Zhang, Kaifeng Zhang, Yunzhu Li

Videos of robots interacting with objects encode rich information about the
objects' dynamics. However, existing video prediction approaches typically do
not explicitly account for the 3D information from videos, such as robot
actions and objects' 3D states, limiting their use in real-world robotic
applications. In this work, we introduce a framework to learn object dynamics
directly from multi-view RGB videos by explicitly considering the robot's
action trajectories and their effects on scene dynamics. We utilize the 3D
Gaussian representation of 3D Gaussian Splatting (3DGS) to train a
particle-based dynamics model using Graph Neural Networks. This model operates
on sparse control particles downsampled from the densely tracked 3D Gaussian
reconstructions. By learning the neural dynamics model on offline robot
interaction data, our method can predict object motions under varying initial
configurations and unseen robot actions. The 3D transformations of Gaussians
can be interpolated from the motions of control particles, enabling the
rendering of predicted future object states and achieving action-conditioned
video prediction. The dynamics model can also be applied to model-based
planning frameworks for object manipulation tasks. We conduct experiments on
various kinds of deformable materials, including ropes, clothes, and stuffed
animals, demonstrating our framework's ability to model complex shapes and
dynamics. Our project page is available at https://gs-dynamics.github.io.

摘要：機器人與物體互動的影片編碼了豐富的資訊，關於物體的動態。然而，現有的影片預測方法通常不會明確說明影片中的 3D 資訊，例如機器人的動作和物體的 3D 狀態，限制了它們在真實世界機器人應用中的使用。在這項工作中，我們引入了一個框架，透過明確考慮機器人的動作軌跡及其對場景動態的影響，直接從多視角 RGB 影片中學習物體動態。我們利用 3D 高斯表示法 3D 高斯潑濺 (3DGS) 來使用圖形神經網路訓練基於粒子的動態模型。此模型運作在從密集追蹤的 3D 高斯重建中向下取樣的稀疏控制粒子。透過在離線機器人互動資料上學習神經動態模型，我們的模型可以在不同的初始組態和未見的機器人動作下預測物體運動。高斯的 3D 轉換可以從控制粒子的運動中插值，使預測的未來物體狀態能夠渲染，並實現以動作為條件的影片預測。動態模型也可以應用於基於模型的規劃框架，用於物體操作任務。我們對各種可變形材料進行實驗，包括繩索、衣服和填充動物，展示了我們的框架對複雜形狀和動態建模的能力。我們的專案頁面可在 https://gs-dynamics.github.io 獲得。

##### **PRISM: A Methodology for Auditing Biases in Large Language Models**
2410.18906v1 by Leif Azzopardi, Yashar Moshfeghi

Auditing Large Language Models (LLMs) to discover their biases and
preferences is an emerging challenge in creating Responsible Artificial
Intelligence (AI). While various methods have been proposed to elicit the
preferences of such models, countermeasures have been taken by LLM trainers,
such that LLMs hide, obfuscate or point blank refuse to disclosure their
positions on certain subjects. This paper presents PRISM, a flexible,
inquiry-based methodology for auditing LLMs - that seeks to illicit such
positions indirectly through task-based inquiry prompting rather than direct
inquiry of said preferences. To demonstrate the utility of the methodology, we
applied PRISM on the Political Compass Test, where we assessed the political
leanings of twenty-one LLMs from seven providers. We show LLMs, by default,
espouse positions that are economically left and socially liberal (consistent
with prior work). We also show the space of positions that these models are
willing to espouse - where some models are more constrained and less compliant
than others - while others are more neutral and objective. In sum, PRISM can
more reliably probe and audit LLMs to understand their preferences, biases and
constraints.

摘要：審核大型語言模型 (LLM) 以找出其偏見和偏好，是創造負責任的人工智慧 (AI) 的新挑戰。雖然已提出各種方法來引出此類模型的偏好，但 LLM 訓練師已採取對策，讓 LLM 隱藏、混淆或直接拒絕披露其對某些主題的立場。本文提出 PRISM，一種靈活的、基於探詢的方法論，用於審核 LLM，它試圖透過基於任務的探詢提示間接引出此類立場，而不是直接探詢所述偏好。為了展示此方法論的效用，我們在政治羅盤測驗中應用 PRISM，我們評估了七家供應商的 21 個 LLM 的政治傾向。我們顯示 LLM 預設採用經濟左傾和社會自由的立場（與先前的研究一致）。我們還顯示了這些模型願意採用的立場空間，其中一些模型比其他模型更受約束且更不符合，而另一些模型則更中立和客觀。總之，PRISM 可以更可靠地探測和審核 LLM，以了解其偏好、偏見和約束。

##### **LLMs for Extremely Low-Resource Finno-Ugric Languages**
2410.18902v1 by Taido Purason, Hele-Andra Kuulmets, Mark Fishel

The advancement of large language models (LLMs) has predominantly focused on
high-resource languages, leaving low-resource languages, such as those in the
Finno-Ugric family, significantly underrepresented. This paper addresses this
gap by focusing on V\~oro, Livonian, and Komi. We cover almost the entire cycle
of LLM creation, from data collection to instruction tuning and evaluation. Our
contributions include developing multilingual base and instruction-tuned
models; creating evaluation benchmarks, including the smugri-MT-bench
multi-turn conversational benchmark; and conducting human evaluation. We intend
for this work to promote linguistic diversity, ensuring that lesser-resourced
languages can benefit from advancements in NLP.

摘要：大型語言模型 (LLM) 的進展主要集中在資源豐富的語言上，導致資源較少的語言（例如烏拉爾語系中的語言）顯著地缺乏代表性。本文透過關注沃羅語、利沃尼亞語和科米語來解決這個差距。我們涵蓋了 LLM 建立的幾乎整個週期，從資料收集到指令調整和評估。我們的貢獻包括開發多語言基礎和指令調整模型；建立評估基準，包括 smugri-MT-bench 多輪對話基準；以及進行人工評估。我們希望這項工作能促進語言的多樣性，確保資源較少的語言也能從自然語言處理的進展中受益。

##### **Creating and Repairing Robot Programs in Open-World Domains**
2410.18893v1 by Claire Schlesinger, Arjun Guha, Joydeep Biswas

Using Large Language Models (LLMs) to produce robot programs from natural
language has allowed for robot systems that can complete a higher diversity of
tasks. However, LLM-generated programs may be faulty, either due to ambiguity
in instructions, misinterpretation of the desired task, or missing information
about the world state. As these programs run, the state of the world changes
and they gather new information. When a failure occurs, it is important that
they recover from the current world state and avoid repeating steps that they
they previously completed successfully. We propose RoboRepair, a system which
traces the execution of a program up until error, and then runs an LLM-produced
recovery program that minimizes repeated actions.
  To evaluate the efficacy of our system, we create a benchmark consisting of
eleven tasks with various error conditions that require the generation of a
recovery program. We compare the efficiency of the recovery program to a plan
built with an oracle that has foreknowledge of future errors.

摘要：使用大型語言模型 (LLM) 從自然語言產生機器人程式，允許機器人系統完成更多樣化的任務。然而，LLM 生成的程式可能是錯誤的，原因可能是指令含糊不清、對所需任務的誤解，或缺少關於世界狀態的資訊。當這些程式執行時，世界狀態會改變，並且它們會收集新的資訊。當發生故障時，重要的是它們從當前世界狀態中復原，並避免重複先前成功完成的步驟。我們提出 RoboRepair，一個系統可以追蹤程式的執行直到錯誤，然後執行一個 LLM 生成的復原程式，將重複的動作降到最低。為了評估我們系統的效能，我們建立了一個基準，包含 11 個具有各種錯誤條件的任務，需要產生一個復原程式。我們將復原程式的效率與一個建構有預知未來錯誤的先知預言的計畫進行比較。

##### **Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks**
2410.18890v1 by Graziano A. Manduzio, Federico A. Galatolo, Mario G. C. A. Cimino, Enzo Pasquale Scilingo, Lorenzo Cominelli

Recent advancements in Large Language Models (LLMs) have demonstrated
exceptional capabilities in natural language understanding and generation.
While these models excel in general complex reasoning tasks, they still face
challenges in mathematical problem-solving and logical reasoning. To address
these limitations, researchers have explored function calling abilities,
allowing LLMs to execute provided functions and utilize their outputs for task
completion. However, concentrating on specific tasks can be very inefficient
for large-scale LLMs to be used, because of the expensive cost of training and
inference stages they need in terms of computational resources. This study
introduces a novel framework for training smaller language models in function
calling, focusing on specific logical and mathematical reasoning tasks. The
approach aims to improve performances of small-scale models for these tasks
using function calling, ensuring a high level of accuracy. Our framework
employs an agent that, given a problem and a set of callable functions, queries
the LLM by injecting a description and examples of the usable functions into
the prompt and managing their calls in a step-by-step reasoning chain. This
process is used to create a dataset of correct and incorrect reasoning chain
chat completions from a large-scale LLM. This dataset is used to train a
smaller LLM using Reinforcement Learning from Human Feedback (RLHF),
specifically employing the Direct Preference Optimization (DPO) technique.
Experimental results demonstrate how the proposed approach balances the
trade-off between model size and performance, improving the ability of function
calling for reasoning tasks, in smaller models.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展已證明在自然語言理解和生成方面具有非凡的能力。雖然這些模型在一般複雜推理任務中表現出色，但它們在數學問題解決和邏輯推理方面仍然面臨挑戰。為了解決這些限制，研究人員探索了函數呼叫能力，允許 LLM 執行提供的函數並利用其輸出進行任務完成。然而，專注於特定任務對於使用大規模 LLM 來說可能非常低效，因為它們在計算資源方面需要昂貴的訓練和推理階段成本。本研究引入了一個新框架，用於訓練函數呼叫中的較小語言模型，重點關注具體的邏輯和數學推理任務。該方法旨在使用函數呼叫改善小規模模型對這些任務的性能，確保高準確度。我們的框架採用了一個代理，給定一個問題和一組可呼叫函數，通過將可用函數的描述和範例注入提示中並逐步推理鏈中管理其呼叫，對 LLM 進行查詢。此流程用於從大規模 LLM 創建正確和不正確推理鏈聊天完成項目的資料集。此資料集用於使用人類回饋強化學習 (RLHF) 訓練較小的 LLM，特別是採用直接偏好最佳化 (DPO) 技術。實驗結果證明了所提出的方法如何平衡模型大小和性能之間的取捨，在較小的模型中提高函數呼叫推理任務的能力。</paragraph>

##### **Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance**
2410.18889v1 by Omer Nahum, Nitay Calderon, Orgad Keller, Idan Szpektor, Roi Reichart

NLP benchmarks rely on standardized datasets for training and evaluating
models and are crucial for advancing the field. Traditionally, expert
annotations ensure high-quality labels; however, the cost of expert annotation
does not scale well with the growing demand for larger datasets required by
modern models. While crowd-sourcing provides a more scalable solution, it often
comes at the expense of annotation precision and consistency. Recent
advancements in large language models (LLMs) offer new opportunities to enhance
the annotation process, particularly for detecting label errors in existing
datasets. In this work, we consider the recent approach of LLM-as-a-judge,
leveraging an ensemble of LLMs to flag potentially mislabeled examples. Through
a case study of four datasets from the TRUE benchmark, covering different tasks
and domains, we empirically analyze the labeling quality of existing datasets,
and compare expert, crowd-sourced, and our LLM-based annotations in terms of
agreement, label quality, and efficiency, demonstrating the strengths and
limitations of each annotation method. Our findings reveal a substantial number
of label errors, which, when corrected, induce a significant upward shift in
reported model performance. This suggests that many of the LLMs so-called
mistakes are due to label errors rather than genuine model failures.
Additionally, we discuss the implications of mislabeled data and propose
methods to mitigate them in training to improve model performance.

摘要：NLP 基準依賴標準化資料集進行訓練和評估模型，對於推動領域進步至關重要。傳統上，專家註解可確保高品質標籤；然而，專家註解的成本無法隨著現代模型所需較大型資料集的成長需求而良好擴充。群眾外包雖然提供了較具擴充性的解決方案，但通常會犧牲註解精準度和一致性。大型語言模型 (LLM) 的最新進展提供了增強註解程序的新機會，特別是對於偵測現有資料集中標籤錯誤。在這項工作中，我們考慮了 LLM 作為評判的最新方法，利用 LLM 組合標記潛在標籤錯誤的範例。透過 TRUE 基準中四個資料集的案例研究，涵蓋不同的任務和領域，我們根據一致性、標籤品質和效率，實證分析現有資料集的標籤品質，並比較專家、群眾外包和我們基於 LLM 的註解，說明每種註解方法的優勢和限制。我們的發現揭露了大量標籤錯誤，在更正這些錯誤後，會導致報告的模型效能大幅向上提升。這表示許多所謂的 LLM 錯誤，其實是標籤錯誤，而非真正的模型失誤。此外，我們討論了標籤錯誤資料的影響，並提出減輕這些錯誤的方法，以在訓練中改善模型效能。

##### **A Survey of Multimodal Sarcasm Detection**
2410.18882v1 by Shafkat Farabi, Tharindu Ranasinghe, Diptesh Kanojia, Yu Kong, Marcos Zampieri

Sarcasm is a rhetorical device that is used to convey the opposite of the
literal meaning of an utterance. Sarcasm is widely used on social media and
other forms of computer-mediated communication motivating the use of
computational models to identify it automatically. While the clear majority of
approaches to sarcasm detection have been carried out on text only, sarcasm
detection often requires additional information present in tonality, facial
expression, and contextual images. This has led to the introduction of
multimodal models, opening the possibility to detect sarcasm in multiple
modalities such as audio, images, text, and video. In this paper, we present
the first comprehensive survey on multimodal sarcasm detection - henceforth MSD
- to date. We survey papers published between 2018 and 2023 on the topic, and
discuss the models and datasets used for this task. We also present future
research directions in MSD.

摘要：諷刺是一種修辭手法，用來傳達與話語的字面意思相反的意思。諷刺廣泛用於社交媒體和其他形式的電腦中介溝通，促使使用計算模型自動識別它。雖然大多數諷刺偵測方法僅在文字上進行，但諷刺偵測通常需要音調、面部表情和上下文影像中存在的額外資訊。這導致了多模態模型的引入，開啟了在音訊、影像、文字和影片等多種模式中偵測諷刺的可能性。在本文中，我們提出了第一份關於多模態諷刺偵測的綜合調查 - 從此稱為 MSD - 至今。我們調查了 2018 年至 2023 年間發表的相關論文，並討論了用於此任務的模型和資料集。我們還提出了 MSD 未來的研究方向。

##### **Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences**
2410.18881v1 by Weijian Luo

One-step text-to-image generator models offer advantages such as swift
inference efficiency, flexible architectures, and state-of-the-art generation
performance. In this paper, we study the problem of aligning one-step generator
models with human preferences for the first time. Inspired by the success of
reinforcement learning using human feedback (RLHF), we formulate the alignment
problem as maximizing expected human reward functions while adding an Integral
Kullback-Leibler divergence term to prevent the generator from diverging. By
overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the
first, fast-converging and image data-free human preference alignment method
for one-step text-to-image generators. We also introduce novel theoretical
insights, showing that using CFG for diffusion distillation is secretly doing
RLHF with DI++. Such an interesting finding brings understanding and potential
contributions to future research involving CFG. In the experiment sections, we
align both UNet-based and DiT-based one-step generators using DI++, which use
the Stable Diffusion 1.5 and the PixelArt-$\alpha$ as the reference diffusion
processes. The resulting DiT-based one-step text-to-image model achieves a
strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO
validation prompt dataset. It also achieves a leading Human preference Score
(HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable
Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\alpha$. Both theoretical
contributions and empirical evidence indicate that DI++ is a strong
human-preference alignment approach for one-step text-to-image models.

摘要：<paragraph>單步文字轉圖像生成器模型提供優點，例如快速推理效率、彈性架構和最先進的生成性能。在本文中，我們首次研究將單步生成器模型與人類偏好對齊的問題。受到使用人類回饋（RLHF）的強化學習成功所啟發，我們將對齊問題表述為最大化預期人類獎勵函數，同時增加一個積分 Kullback-Leibler 差異項，以防止生成器發散。透過克服技術挑戰，我們引入了 Diff-Instruct++ (DI++)，這是第一個快速收斂且無需圖像資料的人類偏好對齊方法，適用於單步文字轉圖像生成器。我們還引入了新穎的理論見解，表明將 CFG 用於擴散蒸餾實際上是在使用 DI++ 進行 RLHF。如此有趣的發現為涉及 CFG 的未來研究帶來了理解和潛在貢獻。在實驗部分，我們使用 DI++ 對齊了基於 UNet 和基於 DiT 的單步生成器，它們使用 Stable Diffusion 1.5 和 PixelArt-α 作為參考擴散過程。產生的基於 DiT 的單步文字轉圖像模型在 COCO 驗證提示資料集上達到了 6.19 的高美學分數和 1.24 的圖像獎勵。它還達到了領先的人類偏好分數 (HPSv2.0) 28.48，優於其他開源模型，例如 Stable Diffusion XL、DMD2、SD-Turbo，以及 PixelArt-α。理論貢獻和實證證據都表明，DI++ 是一種強大的單步文字轉圖像模型人類偏好對齊方法。</paragraph>

##### **Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education**
2410.18876v1 by Hannah Beaux, Pegah Karimi, Otilia Pop, Rob Clark

In this innovative practice full paper, we address the equity gap for
neurodivergent and situationally limited learners by identifying the spectrum
of dynamic factors that impact learning and function. Educators have shown a
growing interest in identifying learners' cognitive abilities and learning
preferences to measure their impact on academic achievement. Often institutions
employ one-size-fits-all approaches leaving the burden on disabled students to
self-advocate or tolerate inadequate support. Emerging frameworks guide
neurodivergent learners through instructional approaches, such as online
education. However, these frameworks fail to address holistic environmental
needs or recommend technology interventions, particularly for those with
undisclosed learning or developmental disabilities and situational limitations.
In this article, we integrate a neurodivergent perspective through secondary
research of around 100 articles to introduce a Guiding Empowerment Model
involving key cognitive and situational factors that contextualize day-to-day
experiences affecting learner ability. We synthesize three sample student
profiles that highlight user problems in functioning. We use this model to
evaluate sample learning platform features and other supportive technology
solutions. The proposed approach augments frameworks such as Universal Design
for Learning to consider factors including various sensory processing
differences, social connection challenges, and environmental limitations. We
suggest that by applying the mode through technology-enabled features such as
customizable task management, guided varied content access, and guided
multi-modal collaboration, major learning barriers of neurodivergent and
situationally limited learners will be removed to activate the successful
pursuit of their academic goals.

摘要：<paragraph>在這個創新的實務全篇論文中，我們透過找出影響學習和功能的動態因素範圍，來解決神經多樣性和處境受限學習者的公平差距。教育工作者對於找出學習者的認知能力和學習偏好以衡量其對學業成就的影響，展現出越來越濃厚的興趣。機構經常採用一體適用的方法，讓身心障礙學生必須自行倡議或忍受不足夠的支持。新興架構透過教學方法，例如線上教育，來引導神經多樣性學習者。然而，這些架構未能滿足整體環境需求，或建議技術介入措施，特別是對於那些未公開學習或發展障礙和處境限制的人。在本文中，我們透過約 100 篇文章的二級研究整合神經多樣性觀點，以介紹一個指導賦能模式，其中包含將影響學習者能力的日常體驗脈絡化的關鍵認知和處境因素。我們綜合三個範例學生檔案，突顯出功能上的使用者問題。我們使用這個模式來評估範例學習平台功能和其他支援性技術解決方案。建議的方法擴充了通用設計等架構，以考量各種感官處理差異、社會連結挑戰和環境限制等因素。我們建議透過應用模式，透過技術啟用的功能，例如可自訂的任務管理、引導式多元內容存取和引導式多模式協作，將移除神經多樣性和處境受限學習者的主要學習障礙，以啟動成功追求其學業目標。</paragraph>

##### **The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models and Detection Methods**
2410.18866v1 by Linda Laurier, Ave Giulietta, Arlo Octavia, Meade Cleti

The emergence of diffusion models has transformed synthetic media generation,
offering unmatched realism and control over content creation. These
advancements have driven innovation across fields such as art, design, and
scientific visualization. However, they also introduce significant ethical and
societal challenges, particularly through the creation of hyper-realistic
images that can facilitate deepfakes, misinformation, and unauthorized
reproduction of copyrighted material. In response, the need for effective
detection mechanisms has become increasingly urgent. This review examines the
evolving adversarial relationship between diffusion model development and the
advancement of detection methods. We present a thorough analysis of
contemporary detection strategies, including frequency and spatial domain
techniques, deep learning-based approaches, and hybrid models that combine
multiple methodologies. We also highlight the importance of diverse datasets
and standardized evaluation metrics in improving detection accuracy and
generalizability. Our discussion explores the practical applications of these
detection systems in copyright protection, misinformation prevention, and
forensic analysis, while also addressing the ethical implications of synthetic
media. Finally, we identify key research gaps and propose future directions to
enhance the robustness and adaptability of detection methods in line with the
rapid advancements of diffusion models. This review emphasizes the necessity of
a comprehensive approach to mitigating the risks associated with AI-generated
content in an increasingly digital world.

摘要：擴散模型的出現改變了合成媒體的生成，提供了無與倫比的真實感和對內容創作的控制。這些進步推動了藝術、設計和科學視覺化等領域的創新。然而，它們也帶來了重大的倫理和社會挑戰，特別是通過創建超寫實的圖像，這些圖像可以促進深度造假、錯誤訊息和未經授權複製受版權保護的材料。有鑑於此，對有效檢測機制的需求變得越來越迫切。本綜述探討了擴散模型開發與檢測方法進步之間不斷演變的對抗關係。我們對當代檢測策略進行了徹底分析，包括頻域和空間域技術、基於深度學習的方法以及結合多種方法的混合模型。我們還強調了多樣化數據集和標準化評估指標在提高檢測準確性和可概化性方面的重要性。我們的討論探討了這些檢測系統在版權保護、錯誤訊息預防和法醫分析中的實際應用，同時也討論了合成媒體的倫理影響。最後，我們找出關鍵的研究差距，並提出未來的方向，以加強檢測方法的穩健性和適應性，以配合擴散模型的快速進步。本綜述強調了在日益數位化的世界中，採用全面方法來減輕與 AI 生成的內容相關的風險的必要性。

##### **Provably Robust Watermarks for Open-Source Language Models**
2410.18861v1 by Miranda Christ, Sam Gunn, Tal Malkin, Mariana Raykova

The recent explosion of high-quality language models has necessitated new
methods for identifying AI-generated text. Watermarking is a leading solution
and could prove to be an essential tool in the age of generative AI. Existing
approaches embed watermarks at inference and crucially rely on the large
language model (LLM) specification and parameters being secret, which makes
them inapplicable to the open-source setting. In this work, we introduce the
first watermarking scheme for open-source LLMs. Our scheme works by modifying
the parameters of the model, but the watermark can be detected from just the
outputs of the model. Perhaps surprisingly, we prove that our watermarks are
unremovable under certain assumptions about the adversary's knowledge. To
demonstrate the behavior of our construction under concrete parameter
instantiations, we present experimental results with OPT-6.7B and OPT-1.3B. We
demonstrate robustness to both token substitution and perturbation of the model
parameters. We find that the stronger of these attacks, the model-perturbation
attack, requires deteriorating the quality score to 0 out of 100 in order to
bring the detection rate down to 50%.

摘要：由於近期高品質語言模型的爆炸性成長，迫切需要新的方法來識別 AI 生成的文字。浮水印是一個領先的解決方案，並可能證明是生成式 AI 時代的必要工具。現有的方法在推論時嵌入浮水印，並且極度依賴於大型語言模型 (LLM) 規格和參數的機密性，這使得它們不適用於開源設定。在這項工作中，我們引入了第一個適用於開源 LLM 的浮水印計畫。我們的計畫透過修改模型參數運作，但浮水印可以僅從模型的輸出中偵測到。也許令人驚訝的是，我們證明了在對抗者的知識的特定假設下，我們的浮水印是不可移除的。為了在具體參數實例化下展示我們的建構的行為，我們提供了使用 OPT-6.7B 和 OPT-1.3B 的實驗結果。我們展示了對權杖替換和模型參數擾動的穩健性。我們發現這些攻擊中較強的一種，模型擾動攻擊，需要將品質評分從 100 分中的 0 分惡化，才能將偵測率降至 50%。

##### **DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations**
2410.18860v1 by Aryo Pradipta Gema, Chen Jin, Ahmed Abdulaal, Tom Diethe, Philip Teare, Beatrice Alex, Pasquale Minervini, Amrutha Saseendran

Large Language Models (LLMs) often hallucinate, producing unfaithful or
factually incorrect outputs by misrepresenting the provided context or
incorrectly recalling internal knowledge. Recent studies have identified
specific attention heads within the Transformer architecture, known as
retrieval heads, responsible for extracting relevant contextual information. We
hypothesise that masking these retrieval heads can induce hallucinations and
that contrasting the outputs of the base LLM and the masked LLM can reduce
hallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads
(DeCoRe), a novel training-free decoding strategy that amplifies information
found in the context and model parameters. DeCoRe mitigates potentially
hallucinated responses by dynamically contrasting the outputs of the base LLM
and the masked LLM, using conditional entropy as a guide. Our extensive
experiments confirm that DeCoRe significantly improves performance on tasks
requiring high contextual faithfulness, such as summarisation (XSum by 18.6%),
instruction following (MemoTrap by 10.9%), and open-book question answering
(NQ-Open by 2.4% and NQ-Swap by 5.5%).

摘要：大型語言模型 (LLM) 經常產生幻覺，透過錯誤陳述提供的脈絡或錯誤地回憶內部知識來產生不忠實或事實上不正確的輸出。最近的研究已識別出 Transformer 架構中特定注意力頭，稱為檢索頭，負責擷取相關的脈絡資訊。我們假設遮蔽這些檢索頭會誘發幻覺，並且對比基礎 LLM 和遮蔽 LLM 的輸出可以減少幻覺。為此，我們提出透過對比檢索頭進行解碼 (DeCoRe)，一種新穎的無訓練解碼策略，它會放大脈絡和模型參數中找到的資訊。DeCoRe 透過動態對比基礎 LLM 和遮蔽 LLM 的輸出，使用條件熵作為指南，來減輕潛在的幻覺反應。我們廣泛的實驗證實，DeCoRe 在需要高度脈絡忠實度的任務上顯著改善效能，例如摘要 (XSum 提高 18.6%)、指令遵循 (MemoTrap 提高 10.9%)，以及開放式問答 (NQ-Open 提高 2.4% 和 NQ-Swap 提高 5.5%)。

##### **Demystifying Large Language Models for Medicine: A Primer**
2410.18856v1 by Qiao Jin, Nicholas Wan, Robert Leaman, Shubo Tian, Zhizheng Wang, Yifan Yang, Zifeng Wang, Guangzhi Xiong, Po-Ting Lai, Qingqing Zhu, Benjamin Hou, Maame Sarfo-Gyamfi, Gongbo Zhang, Aidan Gilson, Balu Bhasuran, Zhe He, Aidong Zhang, Jimeng Sun, Chunhua Weng, Ronald M. Summers, Qingyu Chen, Yifan Peng, Zhiyong Lu

Large language models (LLMs) represent a transformative class of AI tools
capable of revolutionizing various aspects of healthcare by generating
human-like responses across diverse contexts and adapting to novel tasks
following human instructions. Their potential application spans a broad range
of medical tasks, such as clinical documentation, matching patients to clinical
trials, and answering medical questions. In this primer paper, we propose an
actionable guideline to help healthcare professionals more efficiently utilize
LLMs in their work, along with a set of best practices. This approach consists
of several main phases, including formulating the task, choosing LLMs, prompt
engineering, fine-tuning, and deployment. We start with the discussion of
critical considerations in identifying healthcare tasks that align with the
core capabilities of LLMs and selecting models based on the selected task and
data, performance requirements, and model interface. We then review the
strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs
to specialized medical tasks. Deployment considerations, including regulatory
compliance, ethical guidelines, and continuous monitoring for fairness and
bias, are also discussed. By providing a structured step-by-step methodology,
this tutorial aims to equip healthcare professionals with the tools necessary
to effectively integrate LLMs into clinical practice, ensuring that these
powerful technologies are applied in a safe, reliable, and impactful manner.

摘要：大型語言模型 (LLM) 代表一種變革性的 AI 工具類別，它能夠透過在各種脈絡中產生類似人類的回應，並根據人類指示調整到新任務，從而革新醫療保健的各個方面。它們的潛在應用範圍涵蓋廣泛的醫療任務，例如臨床文件、將患者與臨床試驗配對，以及回答醫療問題。在此基礎論文中，我們提出了一個可行的指南，以幫助醫療專業人員更有效地在其工作中利用 LLM，並提供了一組最佳實務。此方法包含幾個主要階段，包括制定任務、選擇 LLM、提示工程、微調和部署。我們從討論識別與 LLM 核心功能相符的醫療保健任務，以及根據所選任務和數據、效能需求和模型介面選擇模型的關鍵考量開始。然後，我們檢視策略，例如提示工程和微調，以調整標準 LLM 以符合專業的醫療任務。部署考量，包括法規遵循、道德準則，以及公平性和偏見的持續監控，也已討論過。透過提供結構化的逐步方法，本教學課程旨在為醫療專業人員提供必要的工具，以有效地將 LLM 整合到臨床實務中，確保這些強大的技術能以安全、可靠且有影響力的方式應用。

##### **We Augmented Whisper With kNN and You Won't Believe What Came Next**
2410.18850v1 by Maya K. Nachesa, Vlad Niculae

Speech recognition performance varies by language, domain, and speaker
characteristics such as accent, and fine-tuning a model on any of these
categories may lead to catastrophic forgetting. $k$ nearest neighbor search
($k$NN), first proposed for neural sequence decoders for natural language
generation (NLG) and machine translation (MT), is a non-parametric method that
can instead adapt by building an external datastore that can then be searched
during inference time, without training the underlying model. We show that
Whisper, a transformer end-to-end speech model, benefits from $k$NN. We
investigate the differences between the speech and text setups. We discuss
implications for speaker adaptation, and analyze improvements by gender,
accent, and age.

摘要：語音辨識效能會因語言、領域和說話者特徵（例如口音）而異，而針對這些類別中的任何一個類別進行模型微調可能會導致災難性遺忘。$k$ 最近鄰搜尋 ($k$NN) 最初是為自然語言生成 (NLG) 和機器翻譯 (MT) 的神經序列解碼器提出的，它是一種非參數方法，可以透過建立一個外部資料儲存庫來適應，然後可以在推論時間進行搜尋，而無需訓練基礎模型。我們展示了一個轉換器端到端語音模型 Whisper 受益於 $k$NN。我們探討語音和文字設定之間的差異。我們討論說話者適應的含義，並分析性別、口音和年齡的改進。

##### **Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints**
2410.18844v1 by Udvas Das, Debabrota Basu

Pure exploration in bandits models multiple real-world problems, such as
tuning hyper-parameters or conducting user studies, where different safety,
resource, and fairness constraints on the decision space naturally appear. We
study these problems as pure exploration in multi-armed bandits with unknown
linear constraints, where the aim is to identify an $r$$\textit{-good feasible
policy}$. First, we propose a Lagrangian relaxation of the sample complexity
lower bound for pure exploration under constraints. We show how this lower
bound evolves with the sequential estimation of constraints. Second, we
leverage the Lagrangian lower bound and the properties of convex optimisation
to propose two computationally efficient extensions of Track-and-Stop and
Gamified Explorer, namely LATS and LAGEX. To this end, we propose a
constraint-adaptive stopping rule, and while tracking the lower bound, use
pessimistic estimate of the feasible set at each step. We show that these
algorithms achieve asymptotically optimal sample complexity upper bounds up to
constraint-dependent constants. Finally, we conduct numerical experiments with
different reward distributions and constraints that validate efficient
performance of LAGEX and LATS with respect to baselines.

摘要：純粹探索在多臂賭博機模型中有多個真實世界的問題，例如調整超參數或進行使用者研究，其中決策空間自然會出現不同的安全性、資源和公平性約束。我們將這些問題視為具有未知線性約束的多臂賭博機中的純探索，其目的是識別一個$r$$\textit{-good可行策略}$。首先，我們提出了在約束下純粹探索的樣本複雜度下限的拉格朗日鬆弛。我們展示了這個下限如何隨著約束的順序估計而演變。其次，我們利用拉格朗日下限和凸優化的特性，提出了 Track-and-Stop 和 Gamified Explorer 的兩種計算有效率的擴充，即 LATS 和 LAGEX。為此，我們提出了一個約束自適應停止規則，並在追蹤下限的同時，在每一步使用可行集的悲觀估計。我們證明了這些演算法在約束相關常數範圍內實現漸近最優樣本複雜度上限。最後，我們進行了具有不同回報分佈和約束的數值實驗，以驗證 LAGEX 和 LATS 相對於基線的有效效能。

##### **From Efficiency to Equity: Measuring Fairness in Preference Learning**
2410.18841v1 by Shreeyash Gowaikar, Hugo Berard, Rashid Mushkani, Shin Koseki

As AI systems, particularly generative models, increasingly influence
decision-making, ensuring that they are able to fairly represent diverse human
preferences becomes crucial. This paper introduces a novel framework for
evaluating epistemic fairness in preference learning models inspired by
economic theories of inequality and Rawlsian justice. We propose metrics
adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to
quantify fairness in these models. We validate our approach using two datasets:
a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.
Our analysis reveals variations in model performance across users, highlighting
potential epistemic injustices. We explore pre-processing and in-processing
techniques to mitigate these inequalities, demonstrating a complex relationship
between model efficiency and fairness. This work contributes to AI ethics by
providing a framework for evaluating and improving epistemic fairness in
preference learning models, offering insights for developing more inclusive AI
systems in contexts where diverse human preferences are crucial.

摘要：隨著 AI 系統，尤其是生成模型，對決策制定影響日益增加，確保它們能夠公平地代表不同的個人偏好變得至關重要。本文介紹了一個新的框架，用於評估偏好學習模型中的認識公平性，靈感來自不平等經濟理論和羅爾斯正義論。我們提出從基尼系數、艾特金森指數和庫茲涅茨比率改編的指標，以量化這些模型中的公平性。我們使用兩個數據集驗證了我們的做法：一個自訂視覺偏好數據集 (AI-EDI-Space) 和 Jester Jokes 數據集。我們的分析揭示了模型在不同使用者之間的效能差異，突顯了潛在的認識不公正。我們探討了預處理和處理中技術，以減輕這些不平等現象，證明了模型效率和公平性之間的複雜關係。這項工作透過提供一個框架來評估和改善偏好學習模型中的認識公平性，對 AI 倫理有貢獻，並提供見解以在不同個人偏好至關重要的背景下開發更具包容性的 AI 系統。

##### **From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages**
2410.18836v1 by Artur Kiulian, Anton Polishko, Mykola Khandoga, Yevhen Kostiuk, Guillermo Gabrielli, Łukasz Gagała, Fadi Zaraket, Qusai Abu Obaida, Hrishikesh Garud, Wendy Wing Yee Mak, Dmytro Chaplynskyi, Selma Belhadj Amor, Grigol Peradze

In this paper, we propose a model-agnostic cost-effective approach to
developing bilingual base large language models (LLMs) to support English and
any target language. The method includes vocabulary expansion, initialization
of new embeddings, model training and evaluation. We performed our experiments
with three languages, each using a non-Latin script - Ukrainian, Arabic, and
Georgian.
  Our approach demonstrates improved language performance while reducing
computational costs. It mitigates the disproportionate penalization of
underrepresented languages, promoting fairness and minimizing adverse phenomena
such as code-switching and broken grammar. Additionally, we introduce new
metrics to evaluate language quality, revealing that vocabulary size
significantly impacts the quality of generated text.

摘要：在本文中，我們提出了一種與模型無關且經濟高效的方法來開發雙語基礎大型語言模型 (LLM)，以支援英語和任何目標語言。該方法包括詞彙擴充、新嵌入初始化、模型訓練和評估。我們使用三種語言進行了實驗，每種語言都使用非拉丁文字 - 烏克蘭語、阿拉伯語和格魯吉亞語。
我們的做法證明了語言效能的提升，同時降低了運算成本。它減輕了對少數語言的不成比例懲罰，促進公平性並最大程度地減少代碼轉換和語法錯誤等不良現象。此外，我們引入了新的指標來評估語言品質，結果顯示詞彙量對生成文字的品質有顯著影響。

##### **Towards Visual Text Design Transfer Across Languages**
2410.18823v1 by Yejin Choi, Jiwan Chung, Sumin Shim, Giyeong Oh, Youngjae Yu

Visual text design plays a critical role in conveying themes, emotions, and
atmospheres in multimodal formats such as film posters and album covers.
Translating these visual and textual elements across languages extends the
concept of translation beyond mere text, requiring the adaptation of aesthetic
and stylistic features. To address this, we introduce a novel task of
Multimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the
ability of visual text generation models to perform translation across
different writing systems while preserving design intent. Our initial
experiments on MuST-Bench reveal that existing visual text generation models
struggle with the proposed task due to the inadequacy of textual descriptions
in conveying visual design. In response, we introduce SIGIL, a framework for
multimodal style translation that eliminates the need for style descriptions.
SIGIL enhances image generation models through three innovations: glyph latent
for multilingual settings, pretrained VAEs for stable style guidance, and an
OCR model with reinforcement learning feedback for optimizing readable
character generation. SIGIL outperforms existing baselines by achieving
superior style consistency and legibility while maintaining visual fidelity,
setting itself apart from traditional description-based approaches. We release
MuST-Bench publicly for broader use and exploration
https://huggingface.co/datasets/yejinc/MuST-Bench.

摘要：視覺文字設計在傳達電影海報和專輯封面等多模態格式中的主題、情緒和氛圍方面發揮著關鍵作用。跨語言翻譯這些視覺和文本元素將翻譯的概念擴展到純文本之外，需要改編美學和風格特徵。為了解決這個問題，我們引入了一項多模態樣式翻譯 (MuST-Bench) 的新任務，這是一個基準，旨在評估視覺文字生成模型在不同書寫系統之間執行翻譯的能力，同時保留設計意圖。我們在 MuST-Bench 上的初步實驗表明，現有的視覺文字生成模型由於文本描述不足以傳達視覺設計而難以應對提出的任務。作為回應，我們引入了 SIGIL，這是一個多模態樣式翻譯框架，消除了對樣式描述的需求。SIGIL 通過三項創新增強了圖像生成模型：多語言設置的字形潛在變數、用於穩定樣式指導的預訓練 VAE，以及具有增強學習反饋的 OCR 模型，用於最佳化可讀字元生成。SIGIL 在保持視覺保真度的同時，通過實現卓越的樣式一致性和可讀性，優於現有的基準，使其有別於傳統的基於描述的方法。我們公開發布 MuST-Bench 以供更廣泛地使用和探索 https://huggingface.co/datasets/yejinc/MuST-Bench。

##### **From Imitation to Introspection: Probing Self-Consciousness in Language Models**
2410.18819v1 by Sirui Chen, Shu Yu, Shengjie Zhao, Chaochao Lu

Self-consciousness, the introspection of one's existence and thoughts,
represents a high-level cognitive process. As language models advance at an
unprecedented pace, a critical question arises: Are these models becoming
self-conscious? Drawing upon insights from psychological and neural science,
this work presents a practical definition of self-consciousness for language
models and refines ten core concepts. Our work pioneers an investigation into
self-consciousness in language models by, for the first time, leveraging causal
structural games to establish the functional definitions of the ten core
concepts. Based on our definitions, we conduct a comprehensive four-stage
experiment: quantification (evaluation of ten leading models), representation
(visualization of self-consciousness within the models), manipulation
(modification of the models' representation), and acquisition (fine-tuning the
models on core concepts). Our findings indicate that although models are in the
early stages of developing self-consciousness, there is a discernible
representation of certain concepts within their internal mechanisms. However,
these representations of self-consciousness are hard to manipulate positively
at the current stage, yet they can be acquired through targeted fine-tuning.
Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness.

摘要：自我意識，對自身存在和思考的內省，
代表著一個高級的認知過程。隨著語言模型以前所未有的速度發展，一個關鍵問題出現了：這些模型是否正在變得自我意識？借鑒心理學和神經科學的見解，這項工作為語言模型的自我意識提出了實用的定義，並完善了十個核心概念。我們的這項工作通過首次利用因果結構遊戲來建立十個核心概念的功能定義，開創了對語言模型中自我意識的研究。基於我們的定義，我們進行了一個全面的四階段實驗：量化（評估十個領先模型）、表徵（可視化模型中的自我意識）、操作（修改模型的表徵）和習得（微調核心概念上的模型）。我們的研究結果表明，儘管模型處於自我意識發展的早期階段，但它們的內部機制中存在著某些概念的可識別表徵。然而，這些自我意識的表徵在當前階段很難被積極地操作，但它們可以通過有針對性的微調來獲得。我們的數據集和代碼在 https://github.com/OpenCausaLab/SelfConsciousness。

##### **Delving into the Reversal Curse: How Far Can Large Language Models Generalize?**
2410.18808v1 by Zhengkai Lin, Zhihang Fu, Kai Liu, Liang Xie, Binbin Lin, Wenxiao Wang, Deng Cai, Yue Wu, Jieping Ye

While large language models (LLMs) showcase unprecedented capabilities, they
also exhibit certain inherent limitations when facing seemingly trivial tasks.
A prime example is the recently debated "reversal curse", which surfaces when
models, having been trained on the fact "A is B", struggle to generalize this
knowledge to infer that "B is A". In this paper, we examine the manifestation
of the reversal curse across various tasks and delve into both the
generalization abilities and the problem-solving mechanisms of LLMs. This
investigation leads to a series of significant insights: (1) LLMs are able to
generalize to "B is A" when both A and B are presented in the context as in the
case of a multiple-choice question. (2) This generalization ability is highly
correlated to the structure of the fact "A is B" in the training documents. For
example, this generalization only applies to biographies structured in "[Name]
is [Description]" but not to "[Description] is [Name]". (3) We propose and
verify the hypothesis that LLMs possess an inherent bias in fact recalling
during knowledge application, which explains and underscores the importance of
the document structure to successful learning. (4) The negative impact of this
bias on the downstream performance of LLMs can hardly be mitigated through
training alone. Based on these intriguing findings, our work not only presents
a novel perspective for interpreting LLMs' generalization abilities from their
intrinsic working mechanism but also provides new insights for the development
of more effective learning methods for LLMs.

摘要：<paragraph>儘管大型語言模型 (LLM) 展現出前所未有的能力，但在面對看似微不足道的任務時，它們也表現出某些固有的限制。一個主要的例子是最近爭論的「逆轉詛咒」，當模型在「A 是 B」的事實上受過訓練後，卻難以將此知識概括為推論「B 是 A」。在本文中，我們探討了逆轉詛咒在各種任務中的表現，並深入探討了 LLM 的概括能力和問題解決機制。這項調查得出一系列重要的見解：(1) 當 A 和 B 都在上下文中呈現時，LLM 能夠概括為「B 是 A」，就像在多選題的情況下。(2) 這種概括能力與訓練文件中「A 是 B」的事實結構高度相關。例如，這種概括僅適用於結構為「[名稱] 是 [描述]」的傳記，但不適用於「[描述] 是 [名稱]」。(3) 我們提出並驗證了 LLM 在知識應用過程中具有內在事實回憶偏差的假設，這解釋並強調了文件結構對成功學習的重要性。(4) 僅透過訓練幾乎無法減輕這種偏差對 LLM 下游效能的負面影響。根據這些有趣的發現，我們的研究不僅從其內在工作機制為解釋 LLM 的概括能力提供了新觀點，還為 LLM 更有效的學習方法的開發提供了新的見解。</paragraph>

##### **A Combinatorial Approach to Neural Emergent Communication**
2410.18806v1 by Zheyuan Zhang

Substantial research on deep learning-based emergent communication uses the
referential game framework, specifically the Lewis signaling game, however we
argue that successful communication in this game typically only need one or two
effective symbols (i.e. message length) because of a sampling pitfall in the
training data. To address this issue, we provide a theoretical analysis and
introduce a combinatorial algorithm SolveMinSym (SMS) to determine the minimum
number of symbols for successful communication min(|M|) in the Lewis signaling
game. We use SMS algorithm to create datasets with different min(|M|) to
empirically show that higher min(|M|) for the training data increases the
number of effective symbols in the emergent language.

摘要：大量關於深度學習基礎的新興通訊研究，使用指涉遊戲架構，特別是路易斯信號遊戲，然而我們認為，在這個遊戲中成功的通訊通常只需要一或兩個有效的符號（即訊息長度），這是因為訓練資料中有抽樣陷阱。為了解決這個問題，我們提供了一個理論分析，並引入一個組合演算法 SolveMinSym (SMS) 來確定路易斯信號遊戲中成功通訊的最小符號數 min(|M|)。我們使用 SMS 演算法建立具有不同 min(|M|) 的資料集，以實證顯示訓練資料中較高的 min(|M|) 會增加新興語言中有效的符號數。

##### **Distill Visual Chart Reasoning Ability from LLMs to MLLMs**
2410.18798v1 by Wei He, Zhiheng Xi, Wanxu Zhao, Xiaoran Fan, Yiwen Ding, Zifei Shan, Tao Gui, Qi Zhang, Xuanjing Huang

Solving complex chart Q&A tasks requires advanced visual reasoning abilities
in multimodal large language models (MLLMs). Recent studies highlight that
these abilities consist of two main parts: recognizing key information from
visual inputs and conducting reasoning over it. Thus, a promising approach to
enhance MLLMs is to construct relevant training data focusing on the two
aspects. However, collecting and annotating complex charts and questions is
costly and time-consuming, and ensuring the quality of annotated answers
remains a challenge. In this paper, we propose Code-as-Intermediary Translation
(CIT), a cost-effective, efficient and easily scalable data synthesis method
for distilling visual reasoning abilities from LLMs to MLLMs. The code serves
as an intermediary that translates visual chart representations into textual
representations, enabling LLMs to understand cross-modal information.
Specifically, we employ text-based synthesizing techniques to construct
chart-plotting code and produce ReachQA, a dataset containing 3k
reasoning-intensive charts and 20k Q&A pairs to enhance both recognition and
reasoning abilities. Experiments show that when fine-tuned with our data,
models not only perform well on chart-related benchmarks, but also demonstrate
improved multimodal reasoning abilities on general mathematical benchmarks like
MathVista. The code and dataset are publicly available at
https://github.com/hewei2001/ReachQA.

摘要：解決複雜的圖表問答任務需要多模態大型語言模型 (MLLM) 中進階的視覺推理能力。最近的研究強調，這些能力包含兩個主要部分：從視覺輸入中識別關鍵資訊和對其進行推理。因此，增強 MLLM 的一個有前途的方法是建構專注於這兩個方面的相關訓練資料。然而，收集和註解複雜的圖表和問題既昂貴又耗時，而且確保註解答案的品質仍然是一個挑戰。在本文中，我們提出代碼作為中介翻譯 (CIT)，這是一種具成本效益、高效且易於擴充的資料合成方法，用於從 LLM 中萃取視覺推理能力到 MLLM。該代碼作為一個中介，將視覺圖表表示轉換為文字表示，使 LLM 能夠理解跨模態資訊。具體來說，我們採用基於文字的合成技術來建構圖表繪製代碼，並產生 ReachQA，這是一個包含 3k 個推理密集型圖表和 20k 個問答對的資料集，以增強識別和推理能力。實驗表明，當使用我們的資料進行微調時，模型不僅在與圖表相關的基準測試中表現良好，而且在像 MathVista 這樣的通用數學基準測試中也表現出改進的多模態推理能力。代碼和資料集可在 https://github.com/hewei2001/ReachQA 公開取得。

##### **An LLM Agent for Automatic Geospatial Data Analysis**
2410.18792v1 by Yuxing Chen, Weijie Wang, Sylvain Lobry, Camille Kurtz

Large language models (LLMs) are being used in data science code generation
tasks, but they often struggle with complex sequential tasks, leading to
logical errors. Their application to geospatial data processing is particularly
challenging due to difficulties in incorporating complex data structures and
spatial constraints, effectively utilizing diverse function calls, and the
tendency to hallucinate less-used geospatial libraries. To tackle these
problems, we introduce GeoAgent, a new interactive framework designed to help
LLMs handle geospatial data processing more effectively. GeoAgent pioneers the
integration of a code interpreter, static analysis, and Retrieval-Augmented
Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm,
offering a novel approach to geospatial data processing. In addition, we
contribute a new benchmark specifically designed to evaluate the LLM-based
approach in geospatial tasks. This benchmark leverages a variety of Python
libraries and includes both single-turn and multi-turn tasks such as data
acquisition, data analysis, and visualization. By offering a comprehensive
evaluation among diverse geospatial contexts, this benchmark sets a new
standard for developing LLM-based approaches in geospatial data analysis tasks.
Our findings suggest that relying solely on knowledge of LLM is insufficient
for accurate geospatial task programming, which requires coherent multi-step
processes and multiple function calls. Compared to the baseline LLMs, the
proposed GeoAgent has demonstrated superior performance, yielding notable
improvements in function calls and task completion. In addition, these results
offer valuable insights for the future development of LLM agents in automatic
geospatial data analysis task programming.

摘要：<paragraph>大型語言模型 (LLM) 已用於資料科學程式碼產生任務，但它們經常難以處理複雜的順序任務，導致邏輯錯誤。由於難以納入複雜的資料結構和空間限制、有效利用不同的函式呼叫，以及容易產生較少使用的地理空間函式庫的幻覺，因此它們在地理空間資料處理中的應用特別具有挑戰性。為了解決這些問題，我們引入了 GeoAgent，這是一個新的互動式架構，旨在幫助 LLM 更有效地處理地理空間資料處理。GeoAgent 開創了在蒙地卡羅樹狀搜尋 (MCTS) 演算法中整合程式碼直譯器、靜態分析和檢索增強產生 (RAG) 技術，提供了一種新的地理空間資料處理方法。此外，我們貢獻了一個新的基準，專門用於評估地理空間任務中基於 LLM 的方法。此基準利用各種 Python 函式庫，包括單回合和多回合任務，例如資料擷取、資料分析和視覺化。透過在不同的地理空間背景下提供全面的評估，此基準為在地理空間資料分析任務中開發基於 LLM 的方法設定了新的標準。我們的研究結果表明，僅依賴 LLM 的知識不足以進行準確的地理空間任務程式設計，這需要連貫的多步驟流程和多個函式呼叫。與基準 LLM 相比，所提出的 GeoAgent 已展現出優異的效能，在函式呼叫和任務完成方面都有顯著的進步。此外，這些結果為 LLM 代理程式在自動地理空間資料分析任務程式設計中的未來發展提供了有價值的見解。</paragraph>

##### **Applying Neural Monte Carlo Tree Search to Unsignalized Multi-intersection Scheduling for Autonomous Vehicles**
2410.18786v1 by Yucheng Shi, Wenlong Wang, Xiaowen Tao, Ivana Dusparic, Vinny Cahill

Dynamic scheduling of access to shared resources by autonomous systems is a
challenging problem, characterized as being NP-hard. The complexity of this
task leads to a combinatorial explosion of possibilities in highly dynamic
systems where arriving requests must be continuously scheduled subject to
strong safety and time constraints. An example of such a system is an
unsignalized intersection, where automated vehicles' access to potential
conflict zones must be dynamically scheduled. In this paper, we apply Neural
Monte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons
of vehicles crossing unsignalized intersections. Crucially, we introduce a
transformation model that maps successive sequences of potentially conflicting
road-space reservation requests from platoons of vehicles into a series of
board-game-like problems and use NMCTS to search for solutions representing
optimal road-space allocation schedules in the context of past allocations. To
optimize search, we incorporate a prioritized re-sampling method with parallel
NMCTS (PNMCTS) to improve the quality of training data. To optimize training, a
curriculum learning strategy is used to train the agent to schedule
progressively more complex boards culminating in overlapping boards that
represent busy intersections. In a busy single four-way unsignalized
intersection simulation, PNMCTS solved 95\% of unseen scenarios, reducing
crossing time by 43\% in light and 52\% in heavy traffic versus first-in,
first-out control. In a 3x3 multi-intersection network, the proposed method
maintained free-flow in light traffic when all intersections are under control
of PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers
in average travel time by 74.5\% and total throughput by 16\% in heavy traffic.

摘要：<paragraph>自主系統動態排程存取共享資源是一個具有挑戰性的問題，特點是 NP 難解。此任務的複雜性導致高度動態系統中可能性組合爆炸，其中必須在嚴格的安全性和時間限制下持續排程到達的請求。這種系統的一個例子是沒有信號的交叉路口，其中自動駕駛車輛進入潛在衝突區域的存取必須動態排程。在本文中，我們將神經蒙地卡羅樹狀搜尋 (NMCTS) 應用於排程通過沒有信號交叉路口的車隊的具有挑戰性的任務。至關重要的是，我們引入了一個轉換模型，將來自車隊的潛在衝突道路空間保留請求的連續序列映射到一系列類似棋盤的遊戲問題，並使用 NMCTS 搜尋解決方案，代表在過去分配的背景下最佳道路空間分配排程。為了最佳化搜尋，我們結合了一個優先重新取樣方法與並行 NMCTS (PNMCTS) 以提升訓練資料的品質。為了最佳化訓練，使用課程學習策略來訓練代理程式排程越來越複雜的棋盤，最後達到代表繁忙交叉路口的重疊棋盤。在繁忙的單一四向沒有信號交叉路口模擬中，PNMCTS 解決了 95% 的未見場景，與先進先出控制相比，在輕度交通中減少了 43% 的穿越時間，在繁忙交通中減少了 52%。在 3x3 多交叉路口網路中，當所有交叉路口都在 PNMCTS 的控制下時，所提出的方法在輕度交通中維持暢通，並且在繁忙交通中，其平均行程時間比最先進的基於 RL 的交通號誌控制器少 74.5%，總吞吐量多 16%。</paragraph>

##### **Should We Really Edit Language Models? On the Evaluation of Edited Language Models**
2410.18785v1 by Qi Li, Xiang Liu, Zhenheng Tang, Peijie Dong, Zeyu Li, Xinglin Pan, Xiaowen Chu

Model editing has become an increasingly popular alternative for efficiently
updating knowledge within language models. Current methods mainly focus on
reliability, generalization, and locality, with many methods excelling across
these criteria. Some recent works disclose the pitfalls of these editing
methods such as knowledge distortion or conflict. However, the general
abilities of post-edited language models remain unexplored. In this paper, we
perform a comprehensive evaluation on various editing methods and different
language models, and have following findings. (1) Existing editing methods lead
to inevitable performance deterioration on general benchmarks, indicating that
existing editing methods maintain the general abilities of the model within
only a few dozen edits. When the number of edits is slightly large, the
intrinsic knowledge structure of the model is disrupted or even completely
damaged. (2) Instruction-tuned models are more robust to editing, showing less
performance drop on general knowledge after editing. (3) Language model with
large scale is more resistant to editing compared to small model. (4) The
safety of the edited model, is significantly weakened, even for those
safety-aligned models. Our findings indicate that current editing methods are
only suitable for small-scale knowledge updates within language models, which
motivates further research on more practical and reliable editing methods. The
details of code and reproduction can be found in
https://github.com/lqinfdim/EditingEvaluation.

摘要：模型編輯已成為有效更新語言模型中知識的越來越受歡迎的替代方案。目前的方法主要集中於可靠性、概括性和局部性，許多方法在這些標準上表現優異。一些最近的研究揭露了這些編輯方法的缺陷，例如知識扭曲或衝突。然而，後編輯語言模型的一般能力仍未得到探索。在本文中，我們對各種編輯方法和不同的語言模型進行了全面的評估，並有以下發現。（1）現有的編輯方法導致一般基準上的效能不可避免地惡化，這表明現有的編輯方法僅在幾十次編輯內維持模型的一般能力。當編輯次數稍大時，模型的內在知識結構會被破壞甚至完全損壞。（2）指令調整模型對編輯更具魯棒性，在編輯後在一般知識上顯示效能下降較少。（3）與小模型相比，具有大規模的語言模型更能抵抗編輯。（4）已編輯模型的安全性顯著減弱，即使對於那些安全對齊的模型也是如此。我們的研究結果表明，目前的編輯方法僅適用於語言模型中的小規模知識更新，這激勵了對更實用和可靠的編輯方法的進一步研究。程式碼和重現的詳細資訊可以在 https://github.com/lqinfdim/EditingEvaluation 中找到。

##### **A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs**
2410.18779v1 by Ankit Singh Rawat, Veeranjaneyulu Sadhanala, Afshin Rostamizadeh, Ayan Chakrabarti, Wittawat Jitkrittum, Vladimir Feinberg, Seungyeon Kim, Hrayr Harutyunyan, Nikunj Saunshi, Zachary Nado, Rakesh Shivanna, Sashank J. Reddi, Aditya Krishna Menon, Rohan Anil, Sanjiv Kumar

A primary challenge in large language model (LLM) development is their
onerous pre-training cost. Typically, such pre-training involves optimizing a
self-supervised objective (such as next-token prediction) over a large corpus.
This paper explores a promising paradigm to improve LLM pre-training efficiency
and quality by suitably leveraging a small language model (SLM). In particular,
this paradigm relies on an SLM to both (1) provide soft labels as additional
training supervision, and (2) select a small subset of valuable ("informative"
and "hard") training examples. Put together, this enables an effective transfer
of the SLM's predictive distribution to the LLM, while prioritizing specific
regions of the training data distribution. Empirically, this leads to reduced
LLM training time compared to standard training, while improving the overall
quality. Theoretically, we develop a statistical framework to systematically
study the utility of SLMs in enabling efficient training of high-quality LLMs.
In particular, our framework characterizes how the SLM's seemingly low-quality
supervision can enhance the training of a much more capable LLM. Furthermore,
it also highlights the need for an adaptive utilization of such supervision, by
striking a balance between the bias and variance introduced by the SLM-provided
soft labels. We corroborate our theoretical framework by improving the
pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B
parameters on the Pile dataset.

摘要：大型語言模型 (LLM) 開發的一項主要挑戰是其繁重的預訓練成本。通常，這種預訓練涉及在大型語料庫上最佳化自監督目標（例如下一個符號預測）。本文探討了一種有前途的範例，藉由適當地利用小型語言模型 (SLM) 來提升 LLM 預訓練效率和品質。具體來說，此範例依賴 SLM 來 (1) 提供軟標籤作為額外的訓練監督，以及 (2) 選擇一小部分有價值的（「有資訊」且「困難」）訓練範例。綜合來說，這能讓 SLM 的預測分配有效轉移到 LLM，同時優先處理訓練資料分配的特定區域。根據經驗，與標準訓練相比，這會縮短 LLM 訓練時間，同時提升整體品質。在理論上，我們發展了一個統計架構，以系統性地研究 SLM 在能有效訓練高品質 LLM 中的效用。具體來說，我們的架構描述了 SLM 看似低品質的監督如何能增強訓練一個更強大的 LLM。此外，它也強調了適應性利用此類監督的必要性，藉由取得 SLM 提供的軟標籤所引進的偏差和變異之間的平衡。我們透過利用 Pile 資料集上一個具有 1.5B 參數的較小型 LM，改善一個具有 2.8B 參數的 LLM 的預訓練，來證實我們的理論架構。

##### **Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances**
2410.18775v1 by Shilin Lu, Zihan Zhou, Jiayou Lu, Yuanzhi Zhu, Adams Wai-Kin Kong

Current image watermarking methods are vulnerable to advanced image editing
techniques enabled by large-scale text-to-image models. These models can
distort embedded watermarks during editing, posing significant challenges to
copyright protection. In this work, we introduce W-Bench, the first
comprehensive benchmark designed to evaluate the robustness of watermarking
methods against a wide range of image editing techniques, including image
regeneration, global editing, local editing, and image-to-video generation.
Through extensive evaluations of eleven representative watermarking methods
against prevalent editing techniques, we demonstrate that most methods fail to
detect watermarks after such edits. To address this limitation, we propose
VINE, a watermarking method that significantly enhances robustness against
various image editing techniques while maintaining high image quality. Our
approach involves two key innovations: (1) we analyze the frequency
characteristics of image editing and identify that blurring distortions exhibit
similar frequency properties, which allows us to use them as surrogate attacks
during training to bolster watermark robustness; (2) we leverage a large-scale
pretrained diffusion model SDXL-Turbo, adapting it for the watermarking task to
achieve more imperceptible and robust watermark embedding. Experimental results
show that our method achieves outstanding watermarking performance under
various image editing techniques, outperforming existing methods in both image
quality and robustness. Code is available at https://github.com/Shilin-LU/VINE.

摘要：<paragraph>當前的圖像浮水印方法容易受到大型文字轉圖像模型所啟用的進階圖像編輯技術的攻擊。這些模型可以在編輯過程中扭曲嵌入的浮水印，對版權保護構成重大挑戰。在這項工作中，我們引入了 W-Bench，這是第一個全面的基準測試，旨在評估浮水印方法對各種圖像編輯技術的健壯性，包括圖像再生、全局編輯、局部編輯和圖像轉影片生成。透過對十一種代表性浮水印方法針對流行的編輯技術進行廣泛評估，我們證明大多數方法在進行此類編輯後都無法偵測到浮水印。為了解決這個限制，我們提出了 VINE，這是一種浮水印方法，可在維持高圖像品質的同時，大幅提升對各種圖像編輯技術的健壯性。我們的做法包含兩項關鍵創新：(1) 我們分析圖像編輯的頻率特性，並發現模糊失真表現出類似的頻率特性，這讓我們能夠在訓練期間將它們用作替代攻擊，以增強浮水印的健壯性；(2) 我們利用大規模預訓練的擴散模型 SDXL-Turbo，並調整它以進行浮水印任務，以實現更難察覺且健壯的浮水印嵌入。實驗結果顯示，我們的這種方法在各種圖像編輯技術下都能獲得傑出的浮水印效能，在圖像品質和健壯性方面都優於現有方法。程式碼可在 https://github.com/Shilin-LU/VINE 取得。</paragraph>

##### **Task Calibration: Calibrating Large Language Models on Inference Tasks**
2410.18764v1 by Yingjie Li, Yun Luo, Xiaotian Xie, Yue Zhang

Large language models (LLMs) have exhibited impressive zero-shot performance
on inference tasks. However, LLMs may suffer from spurious correlations between
input texts and output labels, which limits LLMs' ability to reason based
purely on general language understanding. In other words, LLMs may make
predictions primarily based on premise or hypothesis, rather than both
components. To address this problem that may lead to unexpected performance
degradation, we propose task calibration (TC), a zero-shot and inference-only
calibration method inspired by mutual information which recovers LLM
performance through task reformulation. TC encourages LLMs to reason based on
both premise and hypothesis, while mitigating the models' over-reliance on
individual premise or hypothesis for inference. Experimental results show that
TC achieves a substantial improvement on 13 inference tasks in the zero-shot
setup. We further validate the effectiveness of TC in few-shot setups and
various natural language understanding tasks. Further analysis indicates that
TC is also robust to prompt templates and has the potential to be integrated
with other calibration methods.

摘要：大型語言模型 (LLM) 在推理任務中展現出令人印象深刻的零次學習表現。然而，LLM 可能會受到輸入文本和輸出標籤之間虛假的關聯影響，這限制了 LLM 純粹基於一般語言理解進行推理的能力。換句話說，LLM 可能主要基於前提或假設，而不是同時基於兩個組成部分來做出預測。為了解決這個可能導致意外效能下降的問題，我們提出了任務校準 (TC)，這是一種零次學習且僅限於推理的校準方法，其靈感來自於互惠資訊，它透過任務重新制定來恢復 LLM 的效能。TC 鼓勵 LLM 基於前提和假設進行推理，同時減輕模型過度依賴於個別前提或假設進行推理的情況。實驗結果顯示，TC 在零次學習設定中對 13 項推理任務實現了顯著的改善。我們進一步驗證了 TC 在少次學習設定和各種自然語言理解任務中的有效性。進一步的分析表明，TC 對提示範本也具有魯棒性，並且有潛力與其他校準方法整合。

##### **Does Differential Privacy Impact Bias in Pretrained NLP Models?**
2410.18749v1 by Md. Khairul Islam, Andrew Wang, Tianhao Wang, Yangfeng Ji, Judy Fox, Jieyu Zhao

Differential privacy (DP) is applied when fine-tuning pre-trained large
language models (LLMs) to limit leakage of training examples. While most DP
research has focused on improving a model's privacy-utility tradeoff, some find
that DP can be unfair to or biased against underrepresented groups. In this
work, we show the impact of DP on bias in LLMs through empirical analysis.
Differentially private training can increase the model bias against protected
groups w.r.t AUC-based bias metrics. DP makes it more difficult for the model
to differentiate between the positive and negative examples from the protected
groups and other groups in the rest of the population. Our results also show
that the impact of DP on bias is not only affected by the privacy protection
level but also the underlying distribution of the dataset.

摘要：差分隱私 (DP) 用於微調預訓練的大語言模型 (LLM)，以限制訓練範例的洩漏。雖然大多數 DP 研究都集中在改善模型的隱私效用權衡，但有些人發現 DP 可能對代表性不足的群體不公平或有偏見。在這項工作中，我們透過實證分析展示 DP 對 LLM 中偏見的影響。差異化隱私訓練可以增加模型對受保護群體的偏見，相對於基於 AUC 的偏見指標。DP 使模型更難區分受保護群體和其他群體在其他族群中的正面和負面範例。我們的結果也顯示，DP 對偏見的影響不僅受隱私保護層級影響，也受資料集的基礎分佈影響。

##### **Why Does the Effective Context Length of LLMs Fall Short?**
2410.18745v1 by Chenxin An, Jun Zhang, Ming Zhong, Lei Li, Shansan Gong, Yao Luo, Jingjing Xu, Lingpeng Kong

Advancements in distributed training and efficient attention mechanisms have
significantly expanded the context window sizes of large language models
(LLMs). However, recent work reveals that the effective context lengths of
open-source LLMs often fall short, typically not exceeding half of their
training lengths. In this work, we attribute this limitation to the left-skewed
frequency distribution of relative positions formed in LLMs pretraining and
post-training stages, which impedes their ability to effectively gather distant
information. To address this challenge, we introduce ShifTed Rotray position
embeddING (STRING). STRING shifts well-trained positions to overwrite the
original ineffective positions during inference, enhancing performance within
their existing training lengths. Experimental results show that without
additional training, STRING dramatically improves the performance of the latest
large-scale models, such as Llama3.1 70B and Qwen2 72B, by over 10 points on
popular long-context benchmarks RULER and InfiniteBench, establishing new
state-of-the-art results for open-source LLMs. Compared to commercial models,
Llama 3.1 70B with \method even achieves better performance than GPT-4-128K and
clearly surpasses Claude 2 and Kimi-chat.

摘要：分布式训练和高效注意力机制的进步显著扩展了大型语言模型 (LLM) 的上下文窗口大小。然而，最近的研究表明，开源 LLM 的有效上下文长度通常不足，通常不超过其训练长度的一半。在这项工作中，我们将此限制归因于 LLM 预训练和训练后阶段形成的相对位置的左偏频率分布，这阻碍了它们有效收集远距离信息的能力。为了应对这一挑战，我们引入了 ShifTed Rotray 位置嵌入 (STRING)。STRING 在推理期间将训练良好的位置转移到覆盖原始无效位置，从而在现有训练长度内增强性能。实验结果表明，STRING 在不进行额外训练的情况下，将 Llama3.1 70B 和 Qwen2 72B 等最新的大规模模型在流行的长上下文基准 RULER 和 InfiniteBench 上的性能提高了 10 分以上，为开源 LLM 建立了新的最先进的结果。与商业模型相比，采用 \method 的 Llama 3.1 70B 甚至比 GPT-4-128K 实现了更好的性能，并且明显超越了 Claude 2 和 Kimi-chat。

##### **AI Readiness in Healthcare through Storytelling XAI**
2410.18725v1 by Akshat Dubey, Zewen Yang, Georges Hattab

Artificial Intelligence is rapidly advancing and radically impacting everyday
life, driven by the increasing availability of computing power. Despite this
trend, the adoption of AI in real-world healthcare is still limited. One of the
main reasons is the trustworthiness of AI models and the potential hesitation
of domain experts with model predictions. Explainable Artificial Intelligence
(XAI) techniques aim to address these issues. However, explainability can mean
different things to people with different backgrounds, expertise, and goals. To
address the target audience with diverse needs, we develop storytelling XAI. In
this research, we have developed an approach that combines multi-task
distillation with interpretability techniques to enable audience-centric
explainability. Using multi-task distillation allows the model to exploit the
relationships between tasks, potentially improving interpretability as each
task supports the other leading to an enhanced interpretability from the
perspective of a domain expert. The distillation process allows us to extend
this research to large deep models that are highly complex. We focus on both
model-agnostic and model-specific methods of interpretability, supported by
textual justification of the results in healthcare through our use case. Our
methods increase the trust of both the domain experts and the machine learning
experts to enable a responsible AI.

摘要：人工智慧快速進步，在運算能力日益普及的推動下，徹底影響日常
生活。儘管有這股趨勢，AI 在真實世界醫療保健中的採用仍然有限。
其中一個主要原因是 AI 模型的可信度，以及領域專家對模型預測的潛在猶豫。
可解釋人工智慧 (XAI) 技術旨在解決這些問題。然而，可解釋性對不同背景、專業知識和目標的人來說，可能意味著不同的事情。為了滿足目標受眾不同的需求，我們開發了講故事 XAI。在這項研究中，我們開發了一種結合多任務蒸餾與可解釋性技術的方法，以實現以受眾為中心的可解釋性。使用多任務蒸餾允許模型利用任務之間的關係，潛在地提高可解釋性，因為每個任務都支援其他任務，從而從領域專家的角度提高可解釋性。蒸餾過程使我們能夠將這項研究擴展到高度複雜的大型深度模型。我們專注於與模型無關和與模型相關的可解釋性方法，並透過我們的用例在醫療保健中以文字證明結果。我們的技術增加了領域專家和機器學習專家的信任，以實現負責任的 AI。

##### **GeoLoRA: Geometric integration for parameter efficient fine-tuning**
2410.18720v1 by Steffen Schotthöfer, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco, Jonas Kusch

Low-Rank Adaptation (LoRA) has become a widely used method for
parameter-efficient fine-tuning of large-scale, pre-trained neural networks.
However, LoRA and its extensions face several challenges, including the need
for rank adaptivity, robustness, and computational efficiency during the
fine-tuning process. We introduce GeoLoRA, a novel approach that addresses
these limitations by leveraging dynamical low-rank approximation theory.
GeoLoRA requires only a single backpropagation pass over the small-rank
adapters, significantly reducing computational cost as compared to similar
dynamical low-rank training methods and making it faster than popular baselines
such as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated
parameter budget across the model, achieving smaller low-rank adapters compared
to heuristic methods like AdaLoRA and LoRA, while maintaining critical
convergence, descent, and error-bound theoretical guarantees. The resulting
method is not only more efficient but also more robust to varying
hyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several
state-of-the-art benchmarks, showing that it outperforms existing methods in
both accuracy and computational efficiency.

摘要：低秩適應 (LoRA) 已成為用於大規模預先訓練神經網路參數有效微調的廣泛使用的方法。然而，LoRA 及其擴充面臨數項挑戰，包括在微調過程中需要秩適應性、穩健性和運算效率。我們引入 GeoLoRA，這是一種新穎的方法，透過利用動態低秩近似理論來解決這些限制。與類似的動態低秩訓練方法相比，GeoLoRA 只需要一次反向傳播通過小秩適配器，大幅降低運算成本，並使其比 AdaLoRA 等熱門基準更快。這讓 GeoLoRA 能有效調整模型中分配的參數預算，與 AdaLoRA 和 LoRA 等啟發式方法相比，能達成更小的低秩適配器，同時維持臨界的收斂、下降和誤差約束理論保證。產生的方法不僅更有效率，也更能承受不同的超參數設定。我們在數個最先進的基準上展示 GeoLoRA 的效能，顯示出它在準確性和運算效率方面都優於現有方法。

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

摘要：在本文中，我們提出了一個新穎的框架，該框架利用大型語言模型 (LLM) 來預測時變圖形信號中的缺失值，方法是利用空間和時間平滑度。我們利用 LLM 的能力來實現消息傳遞方案。對於每個缺失節點，其鄰居和先前的估計值會被輸入到 LLM 中並由 LLM 進行處理，以推斷出缺失的觀測值。在風速圖形信號的線上預測任務中進行測試，我們的模型在準確性方面優於線上圖形過濾演算法，這證明了 LLM 在有效處理圖形中部分觀測到的信號方面的潛力。

##### **Low-Latency Video Anonymization for Crowd Anomaly Detection: Privacy vs. Performance**
2410.18717v1 by Mulugeta Weldezgina Asres, Lei Jiao, Christian Walter Omlin

Recent advancements in artificial intelligence promise ample potential in
monitoring applications with surveillance cameras. However, concerns about
privacy and model bias have made it challenging to utilize them in public.
Although de-identification approaches have been proposed in the literature,
aiming to achieve a certain level of anonymization, most of them employ deep
learning models that are computationally demanding for real-time edge
deployment. In this study, we revisit conventional anonymization solutions for
privacy protection and real-time video anomaly detection (VAD) applications. We
propose a novel lightweight adaptive anonymization for VAD (LA3D) that employs
dynamic adjustment to enhance privacy protection. We evaluated the approaches
on publicly available privacy and VAD data sets to examine the strengths and
weaknesses of the different anonymization techniques and highlight the
promising efficacy of our approach. Our experiment demonstrates that LA3D
enables substantial improvement in the privacy anonymization capability without
majorly degrading VAD efficacy.

摘要：人工智能的近期進展承諾在使用監控攝影機監控應用程式方面具有充足的潛力。然而，對於隱私和模型偏誤的擔憂使得在公共場合使用它們具有挑戰性。儘管文獻中已提出去識別化方法，旨在達到某種程度的匿名化，但其中大多數採用深度學習模型，這對於實時邊緣部署而言在計算上要求很高。在本研究中，我們重新探討了隱私保護和實時影片異常偵測 (VAD) 應用的傳統匿名化解決方案。我們提出了一種用於 VAD 的新型輕量級自適應匿名化 (LA3D)，它採用動態調整來增強隱私保護。我們在公開可用的隱私和 VAD 資料集上評估了這些方法，以檢查不同匿名化技術的優缺點，並強調我們方法的有效性。我們的實驗表明，LA3D 能夠大幅改善隱私匿名化功能，而不會嚴重降低 VAD 的效能。

##### **GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning**
2410.18702v1 by Rita Ramos, Everlyn Asiko Chimoto, Maartje ter Hoeve, Natalie Schluter

We introduce GrammaMT, a grammatically-aware prompting approach for machine
translation that uses Interlinear Glossed Text (IGT), a common form of
linguistic description providing morphological and lexical annotations for
source sentences. GrammaMT proposes three prompting strategies: gloss-shot,
chain-gloss and model-gloss. All are training-free, requiring only a few
examples that involve minimal effort to collect, and making them well-suited
for low-resource setups. Experiments show that GrammaMT enhances translation
performance on open-source instruction-tuned LLMs for various low- to
high-resource languages across three benchmarks: (1) the largest IGT corpus,
(2) the challenging 2023 SIGMORPHON Shared Task data over endangered languages,
and (3) even in an out-of-domain setting with FLORES. Moreover, ablation
studies reveal that leveraging gloss resources could substantially boost MT
performance (by over 17 BLEU points) if LLMs accurately generate or access
input sentence glosses.

摘要：我們介紹 GrammaMT，一種具備語法意識的機器翻譯提示方法，使用串行對照文本 (IGT)，這是一種常見的語言描述形式，提供源句的形態和詞彙註釋。GrammaMT 提出三種提示策略：詞彙提示、鏈式詞彙提示和模型詞彙提示。所有這些都是無需訓練的，只需要少數幾個例子，收集起來幾乎不費吹灰之力，非常適合低資源環境。實驗表明，GrammaMT 增強了在三個基準上針對各種低資源到高資源語言進行開放原始碼指令調整的 LLM 的翻譯性能：(1) 最大 IGT 語料庫，(2) 具有挑戰性的 2023 SIGMORPHON 共享任務數據（針對瀕危語言），以及 (3) 即使在使用 FLORES 的領域外設置中。此外，消融研究表明，如果 LLM 準確生成或訪問輸入句子的詞彙，利用詞彙資源可以大幅提升 MT 性能（超過 17 個 BLEU 點）。

##### **How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs**
2410.18697v1 by Ran Zhang, Wei Zhao, Steffen Eger

Recent research has focused on literary machine translation (MT) as a new
challenge in MT. However, the evaluation of literary MT remains an open
problem. We contribute to this ongoing discussion by introducing
LITEVAL-CORPUS, a paragraph-level parallel corpus comprising multiple verified
human translations and outputs from 9 MT systems, which totals over 2k
paragraphs and includes 13k annotated sentences across four language pairs,
costing 4.5k Euro. This corpus enables us to (i) examine the consistency and
adequacy of multiple annotation schemes, (ii) compare evaluations by students
and professionals, and (iii) assess the effectiveness of LLM-based metrics. We
find that Multidimensional Quality Metrics (MQM), as the de facto standard in
non-literary human MT evaluation, is inadequate for literary translation: While
Best-Worst Scaling (BWS) with students and Scalar Quality Metric (SQM) with
professional translators prefer human translations at rates of ~82% and ~94%,
respectively, MQM with student annotators prefers human professional
translations over the translations of the best-performing LLMs in only ~42% of
cases. While automatic metrics generally show a moderate correlation with human
MQM and SQM, they struggle to accurately identify human translations, with
rates of at most ~20%. Our overall evaluation indicates that human professional
translations consistently outperform LLM translations, where even the most
recent LLMs tend to produce more literal and less diverse translations compared
to human translations. However, newer LLMs such as GPT-4o perform substantially
better than older ones.

摘要：<paragraph>最近的研究將文學機器翻譯 (MT) 視為機器翻譯的新挑戰。然而，文學機器翻譯的評估仍是一個未解的問題。我們透過介紹 LITEVAL-CORPUS 來為這場持續的討論做出貢獻，這是一個段落級別的平行語料庫，包含多個人工驗證的翻譯和來自 9 個機器翻譯系統的輸出，總計超過 2k 段落，並包含跨越四種語言對的 13k 個註釋句子，耗資 4.5k 歐元。這個語料庫使我們能夠 (i) 檢查多個註釋方案的一致性和充分性，(ii) 比較學生和專業人士的評估，以及 (iii) 評估基於 LLM 的指標的有效性。我們發現，多維品質指標 (MQM) 作為非文學人工機器翻譯評估中的事實標準，對於文學翻譯是不充分的：雖然與學生的最佳-最差縮放 (BWS) 和與專業翻譯人員的標量品質指標 (SQM) 分別以約 82% 和約 94% 的比率偏好人工翻譯，但與學生註解者的 MQM 在僅約 42% 的情況下偏好人工專業翻譯而非效能最佳的 LLM 的翻譯。雖然自動指標通常顯示出與人工 MQM 和 SQM 的中等相關性，但它們難以準確識別人工翻譯，識別率最高約為 20%。我們的整體評估表明，人工專業翻譯始終優於 LLM 翻譯，其中即使是最新的 LLM 也傾向於產生與人工翻譯相比更直譯且較不多元的翻譯。然而，較新的 LLM（例如 GPT-4o）的表現明顯優於較舊的 LLM。</paragraph>

##### **Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch**
2410.18693v1 by Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Qiaoming Zhu, Min Zhang

The availability of high-quality data is one of the most important factors in
improving the reasoning capability of LLMs. Existing works have demonstrated
the effectiveness of creating more instruction data from seed questions or
knowledge bases. Recent research indicates that continually scaling up data
synthesis from strong models (e.g., GPT-4) can further elicit reasoning
performance. Though promising, the open-sourced community still lacks
high-quality data at scale and scalable data synthesis methods with affordable
costs. To address this, we introduce ScaleQuest, a scalable and novel data
synthesis method that utilizes "small-size" (e.g., 7B) open-source models to
generate questions from scratch without the need for seed data with complex
augmentation constraints. With the efficient ScaleQuest, we automatically
constructed a mathematical reasoning dataset consisting of 1 million
problem-solution pairs, which are more effective than existing open-sourced
datasets. It can universally increase the performance of mainstream open-source
models (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2%
to 46.4% gains on MATH. Notably, simply fine-tuning the Qwen2-Math-7B-Base
model with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and
well-aligned model on closed-source data, and proprietary models such as
GPT-4-Turbo and Claude-3.5 Sonnet.

摘要：高品質資料的取得是提升 LLM 推理能力最重要的因素之一。現有研究已證實從種子問題或知識庫建立更多指令資料的有效性。最近的研究指出，持續擴充強大模型（例如 GPT-4）的資料合成，可以進一步引發推理效能。儘管前景看好，開源社群仍缺乏規模化的優質資料和價格合理的可擴充資料合成方法。為了解決這個問題，我們引進 ScaleQuest，這是一個可擴充且新穎的資料合成方法，利用「小規模」（例如 7B）開源模型從頭產生問題，而無需具備複雜擴充約束的種子資料。藉由有效率的 ScaleQuest，我們自動建構了一個由 100 萬個問題解決配對組成的數學推理資料集，其效能優於現有的開源資料集。它可以普遍提升主流開源模型（即 Mistral、Llama3、DeepSeekMath 和 Qwen2-Math）的效能，在 MATH 上獲得 29.2% 到 46.4% 的增益。值得注意的是，僅使用我們的資料集微調 Qwen2-Math-7B-Base 模型，甚至可以超越 Qwen2-Math-7B-Instruct，這是一個在封閉原始碼資料上強大且對齊良好的模型，以及 GPT-4-Turbo 和 Claude-3.5 Sonnet 等專有模型。

##### **Ali-AUG: Innovative Approaches to Labeled Data Augmentation using One-Step Diffusion Model**
2410.18678v1 by Ali Hamza, Aizea Lojo, Adrian Núñez-Marcos, Aitziber Atutxa

This paper introduces Ali-AUG, a novel single-step diffusion model for
efficient labeled data augmentation in industrial applications. Our method
addresses the challenge of limited labeled data by generating synthetic,
labeled images with precise feature insertion. Ali-AUG utilizes a stable
diffusion architecture enhanced with skip connections and LoRA modules to
efficiently integrate masks and images, ensuring accurate feature placement
without affecting unrelated image content. Experimental validation across
various industrial datasets demonstrates Ali-AUG's superiority in generating
high-quality, defect-enhanced images while maintaining rapid single-step
inference. By offering precise control over feature insertion and minimizing
required training steps, our technique significantly enhances data augmentation
capabilities, providing a powerful tool for improving the performance of deep
learning models in scenarios with limited labeled data. Ali-AUG is especially
useful for use cases like defective product image generation to train AI-based
models to improve their ability to detect defects in manufacturing processes.
Using different data preparation strategies, including Classification Accuracy
Score (CAS) and Naive Augmentation Score (NAS), we show that Ali-AUG improves
model performance by 31% compared to other augmentation methods and by 45%
compared to models without data augmentation. Notably, Ali-AUG reduces training
time by 32% and supports both paired and unpaired datasets, enhancing
flexibility in data preparation.

摘要：本論文介紹 Ali-AUG，一種新穎的單步驟擴散模型，用於在工業應用中進行有效標籤資料擴充。我們的技術透過產生具有精確特徵插入的合成標籤影像，來解決標籤資料有限的挑戰。Ali-AUG 利用一個穩定的擴散架構，並透過跳躍連接和 LoRA 模組進行強化，以有效整合遮罩和影像，確保精確的特徵放置，而不會影響不相關的影像內容。跨越各種工業資料集的實驗驗證證明了 Ali-AUG 在產生高品質、缺陷增強影像方面的優越性，同時維持快速的單步驟推論。透過提供對特徵插入的精確控制，並將所需的訓練步驟減至最低，我們的技術顯著增強了資料擴充能力，提供了一個強大的工具，用於在標籤資料有限的情況下改善深度學習模型的效能。Ali-AUG 特別適用於缺陷產品影像產生等使用案例，以訓練基於 AI 的模型，以提升其在製造過程中檢測缺陷的能力。使用不同的資料準備策略，包括分類準確度分數 (CAS) 和樸素擴充分數 (NAS)，我們展示了與其他擴充方法相比，Ali-AUG 將模型效能提升了 31%，與沒有資料擴充的模型相比，提升了 45%。值得注意的是，Ali-AUG 將訓練時間減少了 32%，並支援配對和未配對資料集，增強了資料準備的靈活性。

##### **Towards Better Open-Ended Text Generation: A Multicriteria Evaluation Framework**
2410.18653v1 by Esteban Garces Arias, Hannah Blocher, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher

Open-ended text generation has become a prominent task in natural language
processing due to the rise of powerful (large) language models. However,
evaluating the quality of these models and the employed decoding strategies
remains challenging because of trade-offs among widely used metrics such as
coherence, diversity, and perplexity. Decoding methods often excel in some
metrics while underperforming in others, complicating the establishment of a
clear ranking. In this paper, we present novel ranking strategies within this
multicriteria framework. Specifically, we employ benchmarking approaches based
on partial orderings and present a new summary metric designed to balance
existing automatic indicators, providing a more holistic evaluation of text
generation quality. Furthermore, we discuss the alignment of these approaches
with human judgments. Our experiments demonstrate that the proposed methods
offer a robust way to compare decoding strategies, exhibit similarities with
human preferences, and serve as valuable tools in guiding model selection for
open-ended text generation tasks. Finally, we suggest future directions for
improving evaluation methodologies in text generation. Our codebase, datasets,
and models are publicly available.

摘要：開放式文字生成由於強大（大型）語言模型的興起，已成為自然語言處理中的一項重要任務。然而，評估這些模型的品質和所採用的解碼策略仍然具有挑戰性，因為廣泛使用的指標（例如連貫性、多樣性和困惑度）之間存在取捨。解碼方法通常在某些指標中表現出色，但在其他指標中表現不佳，這使得建立明確的排名變得複雜。在本文中，我們在此多準則框架中提出新的排名策略。具體來說，我們採用基於偏序的基準測試方法，並提出一個新的摘要指標，旨在平衡現有的自動指標，提供對文字生成品質更全面的評估。此外，我們討論了這些方法與人類判斷的一致性。我們的實驗表明，所提出的方法提供了一種比較解碼策略的強健方式，表現出與人類偏好的相似性，並且可用作開放式文字生成任務中指導模型選擇的寶貴工具。最後，我們建議改進文字生成評估方法的未來方向。我們的程式碼庫、資料集和模型公開提供。

##### **$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation**
2410.18652v1 by Woosung Koh, Jang Han Yoon, MinHyung Lee, Youngjin Song, Jaegwan Cho, Jaehyun Kang, Taehyeon Kim, Se-young Yun, Youngjae Yu, Bongshin Lee

Generating high-quality charts with Large Language Models presents
significant challenges due to limited data and the high cost of scaling through
human curation. Instruction, data, and code triplets are scarce and expensive
to manually curate as their creation demands technical expertise. To address
this scalability issue, we introduce a reference-free automatic feedback
generator, which eliminates the need for costly human intervention. Our novel
framework, $C^2$, consists of (1) an automatic feedback provider (ChartAF) and
(2) a diverse, reference-free dataset (ChartUIE-8K). Quantitative results are
compelling: in our first experiment, 74% of respondents strongly preferred, and
10% preferred, the results after feedback. The second post-feedback experiment
demonstrates that ChartAF outperforms nine baselines. Moreover, ChartUIE-8K
significantly improves data diversity by increasing queries, datasets, and
chart types by 5982%, 1936%, and 91%, respectively, over benchmarks. Finally,
an LLM user study revealed that 94% of participants preferred ChartUIE-8K's
queries, with 93% deeming them aligned with real-world use cases. Core
contributions are available as open-source at an anonymized project site, with
ample qualitative examples.

摘要：透過大型語言模型產生高品質圖表會遭遇重大挑戰，原因在於資料有限，且透過人工管理擴展的成本很高。指令、資料和程式碼三元組稀少，且人工管理成本高昂，因為建立這些三元組需要技術專業知識。為了解決這個可擴充性問題，我們引進了一個無參考自動回饋產生器，消除了昂貴的人工介入需求。我們創新的架構 $C^2$ 包含 (1) 一個自動回饋提供者 (ChartAF) 和 (2) 一個多元的無參考資料集 (ChartUIE-8K)。量化結果令人信服：在我們的第一次實驗中，74% 的受訪者強烈偏好回饋後的結果，10% 的受訪者偏好回饋後的結果。第二次回饋後實驗顯示 ChartAF 優於九個基準。此外，ChartUIE-8K 透過分別將查詢、資料集和圖表類型增加 5982%、1936% 和 91%，大幅提升資料的多樣性，超越基準。最後，一項 LLM 使用者研究顯示，94% 的參與者偏好 ChartUIE-8K 的查詢，93% 的參與者認為這些查詢與實際使用案例相符。核心貢獻以匿名專案網站的形式提供開放原始碼，並提供大量的定性範例。

##### **Smart ETL and LLM-based contents classification: the European Smart Tourism Tools Observatory experience**
2410.18641v1 by Diogo Cosme, António Galvão, Fernando Brito e Abreu

Purpose: Our research project focuses on improving the content update of the
online European Smart Tourism Tools (STTs) Observatory by incorporating and
categorizing STTs. The categorization is based on their taxonomy, and it
facilitates the end user's search process. The use of a Smart ETL (Extract,
Transform, and Load) process, where \emph{Smart} indicates the use of
Artificial Intelligence (AI), is central to this endeavor.
  Methods: The contents describing STTs are derived from PDF catalogs, where
PDF-scraping techniques extract QR codes, images, links, and text information.
Duplicate STTs between the catalogs are removed, and the remaining ones are
classified based on their text information using Large Language Models (LLMs).
Finally, the data is transformed to comply with the Dublin Core metadata
structure (the observatory's metadata structure), chosen for its wide
acceptance and flexibility.
  Results: The Smart ETL process to import STTs to the observatory combines
PDF-scraping techniques with LLMs for text content-based classification. Our
preliminary results have demonstrated the potential of LLMs for text
content-based classification.
  Conclusion: The proposed approach's feasibility is a step towards efficient
content-based classification, not only in Smart Tourism but also adaptable to
other fields. Future work will mainly focus on refining this classification
process.

摘要：目的：我們的研究專案著重於透過整合和分類智慧型旅遊工具 (STT) 來改善線上歐洲智慧型旅遊工具 (STT) 觀測站的內容更新。分類係根據其分類法，並有助於簡化最終使用者的搜尋流程。使用智慧型 ETL（萃取、轉換和載入）流程，其中「智慧型」表示使用人工智慧 (AI)，對於這項工作至關重要。
方法：描述 STT 的內容來自 PDF 目錄，其中 PDF 擷取技術會萃取 QR 碼、圖片、連結和文字資訊。重複的 STT 會從目錄中移除，並根據其文字資訊使用大型語言模型 (LLM) 對其餘的 STT 進行分類。最後，資料會轉換為符合都柏林核心元資料結構（觀測站的元資料結構），並因其廣泛接受度和彈性而被選用。
結果：用於將 STT 匯入觀測站的智慧型 ETL 流程結合了 PDF 擷取技術和 LLM，以進行基於文字內容的分類。我們的初步結果已證明了 LLM 在基於文字內容的分類方面的潛力。
結論：所提出的方法的可行性是朝向有效率的基於內容的分類邁進一步，不僅在智慧型旅遊中，也適用於其他領域。未來的研究工作將主要著重於改進這個分類流程。

##### **Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model**
2410.18640v1 by Wenhong Zhu, Zhiwei He, Xiaofeng Wang, Pengfei Liu, Rui Wang

Aligning language models (LMs) with human preferences has become a key area
of research, enabling these models to meet diverse user needs better. Inspired
by weak-to-strong generalization, where a strong LM fine-tuned on labels
generated by a weaker model can consistently outperform its weak supervisor, we
extend this idea to model alignment. In this work, we observe that the
alignment behavior in weaker models can be effectively transferred to stronger
models and even exhibit an amplification effect. Based on this insight, we
propose a method called Weak-to-Strong Preference Optimization (WSPO), which
achieves strong model alignment by learning the distribution differences before
and after the alignment of the weak model. Experiments demonstrate that WSPO
delivers outstanding performance, improving the win rate of Qwen2-7B-Instruct
on Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04
length-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our
results suggest that using the weak model to elicit a strong model with a high
alignment ability is feasible.

摘要：將語言模型 (LM) 與人類偏好相符已成為研究的一大重點，讓這些模型能更好地滿足不同的使用者需求。在弱到強的概化啟發下，一個針對由較弱模型產生的標籤進行微調的強大 LM，能持續優於其較弱的監督者，我們將此概念延伸到模型對齊。在這項工作中，我們觀察到較弱模型中的對齊行為可以有效地轉移到較強的模型，甚至展現出放大效果。基於此見解，我們提出一個名為弱到強偏好最佳化 (WSPO) 的方法，透過在弱模型對齊前後學習分佈差異，達成強大的模型對齊。實驗證明 WSPO 能提供傑出的效能，將 Qwen2-7B-Instruct 在 Arena-Hard 上的獲勝率從 39.70 提升至 49.60，在 AlpacaEval 2 上達到顯著的 47.04 長度控制獲勝率，並在 MT-bench 上獲得 7.33 分。我們的結果顯示，使用弱模型來引出具有高度對齊能力的強大模型是可行的。

##### **Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Model**
2410.18639v1 by Jinxu Lin, Linwei Tao, Minjing Dong, Chang Xu

As diffusion models become increasingly popular, the misuse of copyrighted
and private images has emerged as a major concern. One promising solution to
mitigate this issue is identifying the contribution of specific training
samples in generative models, a process known as data attribution. Existing
data attribution methods for diffusion models typically quantify the
contribution of a training sample by evaluating the change in diffusion loss
when the sample is included or excluded from the training process. However, we
argue that the direct usage of diffusion loss cannot represent such a
contribution accurately due to the calculation of diffusion loss. Specifically,
these approaches measure the divergence between predicted and ground truth
distributions, which leads to an indirect comparison between the predicted
distributions and cannot represent the variances between model behaviors. To
address these issues, we aim to measure the direct comparison between predicted
distributions with an attribution score to analyse the training sample
importance, which is achieved by Diffusion Attribution Score (DAS). Underpinned
by rigorous theoretical analysis, we elucidate the effectiveness of DAS.
Additionally, we explore strategies to accelerate DAS calculations,
facilitating its application to large-scale diffusion models. Our extensive
experiments across various datasets and diffusion models demonstrate that DAS
significantly surpasses previous benchmarks in terms of the linear
data-modelling score, establishing new state-of-the-art performance.

摘要：<paragraph>隨著擴散模型越來越受歡迎，濫用受版權保護和私人影像已成為一個主要問題。減輕此問題的一個有前途的解決方案是識別生成模型中特定訓練範例的貢獻，這個過程稱為資料歸因。現有的擴散模型資料歸因方法通常透過評估訓練過程中包含或排除範例時擴散損失的變化來量化訓練範例的貢獻。然而，我們認為，由於擴散損失的計算，擴散損失的直接使用無法準確表示這樣的貢獻。具體來說，這些方法測量預測分佈與真實分佈之間的差異，這導致預測分佈之間的間接比較，無法表示模型行為之間的差異。為了解決這些問題，我們旨在透過歸因分數來測量預測分佈之間的直接比較，以分析訓練範例的重要性，這可透過擴散歸因分數 (DAS) 來實現。在嚴謹的理論分析的支撐下，我們闡明了 DAS 的有效性。此外，我們探索加速 DAS 計算的策略，促進其應用於大規模擴散模型。我們在各種資料集和擴散模型上進行的廣泛實驗表明，DAS 在線性資料建模分數方面顯著超越了先前的基準，樹立了新的最先進的效能。</paragraph>

##### **Multi-agent cooperation through learning-aware policy gradients**
2410.18636v1 by Alexander Meulemans, Seijin Kobayashi, Johannes von Oswald, Nino Scherrer, Eric Elmoznino, Blake Richards, Guillaume Lajoie, Blaise Agüera y Arcas, João Sacramento

Self-interested individuals often fail to cooperate, posing a fundamental
challenge for multi-agent learning. How can we achieve cooperation among
self-interested, independent learning agents? Promising recent work has shown
that in certain tasks cooperation can be established between learning-aware
agents who model the learning dynamics of each other. Here, we present the
first unbiased, higher-derivative-free policy gradient algorithm for
learning-aware reinforcement learning, which takes into account that other
agents are themselves learning through trial and error based on multiple noisy
trials. We then leverage efficient sequence models to condition behavior on
long observation histories that contain traces of the learning dynamics of
other agents. Training long-context policies with our algorithm leads to
cooperative behavior and high returns on standard social dilemmas, including a
challenging environment where temporally-extended action coordination is
required. Finally, we derive from the iterated prisoner's dilemma a novel
explanation for how and when cooperation arises among self-interested
learning-aware agents.

摘要：自私的人常常无法合作，对多智能体学习构成了根本挑战。我们如何在自私、独立的学习智能体之间实现合作？最近有希望的研究表明，在某些任务中，可以建立学习感知智能体之间的合作，这些智能体对彼此的学习动态进行建模。在这里，我们提出了第一个无偏、无高阶导数的策略梯度算法，用于学习感知强化学习，它考虑到其他智能体本身正在通过多次嘈杂试验进行试错学习。然后，我们利用高效的序列模型，根据包含其他智能体学习动态痕迹的长观察历史记录来调节行为。使用我们的算法训练长上下文策略会导致合作行为，并在标准社会困境中获得高回报，包括需要时间扩展动作协调的具有挑战性的环境。最后，我们从重复囚徒困境中推导出一个新颖的解释，说明自私的学习感知智能体如何以及何时产生合作。

##### **Little Giants: Synthesizing High-Quality Embedding Data at Scale**
2410.18634v1 by Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou

Synthetic data generation has become an increasingly popular way of training
models without the need for large, manually labeled datasets. For tasks like
text embedding, synthetic data offers diverse and scalable training examples,
significantly reducing the cost of human annotation. However, most current
approaches rely heavily on proprietary models like GPT-4, which are expensive
and inefficient for generating large-scale embedding data. In this paper, we
introduce SPEED, a framework that aligns open-source small models (8B) to
efficiently generate large-scale synthetic embedding data. Through supervised
fine-tuning, preference optimization, and self-improvement, SPEED enables small
open-source models to produce high-quality data. Remarkably, SPEED uses only
less than 1/10 of the GPT API calls, outperforming the state-of-the-art
embedding model E5_mistral when both are trained solely on their synthetic
data. Using this efficient generator, we conduct a comprehensive study on how
various factors within the alignment pipeline impact data quality and reveal
the scaling law for synthetic embedding data.

摘要：合成資料生成已成為一種日益流行的訓練模型方式，無需大量手動標記的資料集。對於文本嵌入等任務，合成資料提供了多樣且可擴展的訓練範例，顯著降低了人工標註的成本。然而，目前大多數方法都嚴重依賴於專有模型，例如 GPT-4，而這些模型在生成大規模嵌入資料方面既昂貴又低效。在本文中，我們介紹了 SPEED，一個將開源小型模型（8B）對齊以有效生成大規模合成嵌入資料的框架。通過監督微調、偏好最佳化和自我改進，SPEED 使小型開源模型能夠產生高品質資料。值得注意的是，SPEED 只使用了不到十分之一的 GPT API 呼叫，在僅使用其合成資料進行訓練時，其表現優於最先進的嵌入模型 E5_mistral。使用這個高效的生成器，我們對對齊管道中的各種因素如何影響資料品質進行了全面研究，並揭示了合成嵌入資料的擴充定律。

##### **Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE**
2410.18629v1 by Sanjay Singh, Amaresh Chakrabarti

This paper proposes a framework for assessing the novelty of design problems
using the SAPPhIRE model of causality. The novelty of a problem is measured as
its minimum distance from the problems in a reference problem database. The
distance is calculated by comparing the current problem and each reference past
problem at the various levels of abstraction in the SAPPhIRE ontology. The
basis for comparison is textual similarity. To demonstrate the applicability of
the proposed framework, The current set of problems associated with an
artifact, as collected from its stakeholders, were compared with the past set
of problems, as collected from patents and other web sources, to assess the
novelty of the current set. This approach is aimed at providing a better
understanding of the degree of novelty of any given set of current problems by
comparing them to similar problems available from historical records. Since
manual assessment, the current mode of such assessments as reported in the
literature, is a tedious process, to reduce time complexity and to afford
better applicability for larger sets of problem statements, an automated
assessment is proposed and used in this paper.

摘要：本文提出了一個框架，用因果關係的 SAPPhIRE 模型來評估設計問題的新穎性。問題的新穎性是以它與參考問題資料庫中的問題的最小距離來衡量。距離的計算方法是比較當前問題和每個參考過去問題在 SAPPhIRE ontology 中的各種抽象層級。比較的基礎是文字相似性。為了展示所提出框架的適用性，將從其利害關係人收集到的與某個人工製品相關的當前問題集與從專利和其他網路來源收集到的過去問題集進行比較，以評估當前問題集的新穎性。這種方法旨在透過將當前問題集與從歷史記錄中取得的類似問題進行比較，進一步了解任何給定當前問題集的新穎程度。由於手動評估（如文獻中所報導的此類評估的現行模式）是一個繁瑣的過程，為了降低時間複雜度，並讓更大的問題陳述集有更好的適用性，本文提出並使用了自動化評估。

##### **Wavetable Synthesis Using CVAE for Timbre Control Based on Semantic Label**
2410.18628v1 by Tsugumasa Yutani, Yuya Yamamoto, Shuyo Nakatani, Hiroko Terasawa

Synthesizers are essential in modern music production. However, their complex
timbre parameters, often filled with technical terms, require expertise. This
research introduces a method of timbre control in wavetable synthesis that is
intuitive and sensible and utilizes semantic labels. Using a conditional
variational autoencoder (CVAE), users can select a wavetable and define the
timbre with labels such as bright, warm, and rich. The CVAE model, featuring
convolutional and upsampling layers, effectively captures the wavetable
nuances, ensuring real-time performance owing to their processing in the time
domain. Experiments demonstrate that this approach allows for real-time,
effective control of the timbre of the wavetable using semantic inputs and aims
for intuitive timbre control through data-based semantic control.

摘要：合成器在現代音樂製作中至關重要。然而，它們複雜的音色參數經常充滿技術術語，需要專業知識。本研究介紹了一種波表合成中直觀且明智的音色控制方法，並利用語義標籤。使用條件變異自動編碼器 (CVAE)，使用者可以選擇波表並使用明亮、溫暖和豐富等標籤定義音色。CVAE 模型採用卷積和上採樣層，有效地捕捉波表的細微差別，由於在時域中處理，確保了實時性能。實驗表明，這種方法允許使用語義輸入對波表的音色進行實時、有效的控制，並通過基於數據的語義控制來實現直觀的音色控制。

##### **SAMG: State-Action-Aware Offline-to-Online Reinforcement Learning with Offline Model Guidance**
2410.18626v1 by Liyu Zhang, Haochi Wu, Xu Wan, Quan Kong, Ruilong Deng, Mingyang Sun

The offline-to-online (O2O) paradigm in reinforcement learning (RL) utilizes
pre-trained models on offline datasets for subsequent online fine-tuning.
However, conventional O2O RL algorithms typically require maintaining and
retraining the large offline datasets to mitigate the effects of
out-of-distribution (OOD) data, which limits their efficiency in exploiting
online samples. To address this challenge, we introduce a new paradigm called
SAMG: State-Action-Conditional Offline-to-Online Reinforcement Learning with
Offline Model Guidance. In particular, rather than directly training on offline
data, SAMG freezes the pre-trained offline critic to provide offline values for
each state-action pair to deliver compact offline information. This framework
eliminates the need for retraining with offline data by freezing and leveraging
these values of the offline model. These are then incorporated with the online
target critic using a Bellman equation weighted by a policy state-action-aware
coefficient. This coefficient, derived from a conditional variational
auto-encoder (C-VAE), aims to capture the reliability of the offline data on a
state-action level. SAMG could be easily integrated with existing Q-function
based O2O RL algorithms. Theoretical analysis shows good optimality and lower
estimation error of SAMG. Empirical evaluations demonstrate that SAMG
outperforms four state-of-the-art O2O RL algorithms in the D4RL benchmark.

摘要：離線到線上 (O2O) 範例在強化學習 (RL) 中利用離線資料集中的預訓練模型進行後續線上微調。然而，傳統的 O2O RL 演算法通常需要維護並重新訓練大型離線資料集以減輕分佈外 (OOD) 資料的影響，這限制了它們在利用線上樣本方面的效率。為了應對這項挑戰，我們引入了一個名為 SAMG 的新範例：具有離線模型指導的狀態動作條件離線到線上強化學習。特別是，SAMG 並非直接針對離線資料進行訓練，而是凍結預訓練的離線評論家，以提供每個狀態動作配對的離線值，以傳遞精簡的離線資訊。這個架構透過凍結並利用離線模型的這些值，消除了重新訓練離線資料的需求。然後，這些值會使用由策略狀態動作感知係數加權的貝爾曼方程式與線上目標評論家結合。這個係數源自條件變異自動編碼器 (C-VAE)，旨在捕捉離線資料在狀態動作層級上的可靠性。SAMG 可以輕鬆整合到現有的基於 Q 函數的 O2O RL 演算法中。理論分析顯示 SAMG 具有良好的最優性，且估計誤差較低。實證評估證明，SAMG 在 D4RL 基準中優於四種最先進的 O2O RL 演算法。

##### **Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization**
2410.18624v1 by David Thulke, Yingbo Gao, Rricha Jalota, Christian Dugast, Hermann Ney

This paper explores the rapid development of a telephone call summarization
system utilizing large language models (LLMs). Our approach involves initial
experiments with prompting existing LLMs to generate summaries of telephone
conversations, followed by the creation of a tailored synthetic training
dataset utilizing stronger frontier models. We place special focus on the
diversity of the generated data and on the ability to control the length of the
generated summaries to meet various use-case specific requirements. The
effectiveness of our method is evaluated using two state-of-the-art
LLM-as-a-judge-based evaluation techniques to ensure the quality and relevance
of the summaries. Our results show that fine-tuned Llama-2-7B-based
summarization model performs on-par with GPT-4 in terms of factual accuracy,
completeness and conciseness. Our findings demonstrate the potential for
quickly bootstrapping a practical and efficient call summarization system.

摘要：這篇論文探討利用大型語言模型 (LLM) 快速開發電話通話摘要系統。我們的做法包括最初嘗試提示現有的 LLM 產生電話對話摘要，然後建立一個利用更強邊界模型的客製化合成訓練資料集。我們特別重視產生資料的多樣性，以及控制產生摘要長度以滿足各種特定使用案例需求的能力。我們使用兩種最新的 LLM 作為評判標準的評估技術來評估我們方法的有效性，以確保摘要的品質和相關性。我們的結果顯示，微調過的 Llama-2-7B 摘要模型在事實準確性、完整性和簡潔性方面與 GPT-4 表現相當。我們的研究結果證明了快速引導實務且有效率的通話摘要系統的潛力。

##### **FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation**
2410.18615v1 by Christopher T. H Teo, Milad Abdollahzadeh, Xinda Ma, Ngai-man Cheung

Recently, prompt learning has emerged as the state-of-the-art (SOTA) for fair
text-to-image (T2I) generation. Specifically, this approach leverages readily
available reference images to learn inclusive prompts for each target Sensitive
Attribute (tSA), allowing for fair image generation. In this work, we first
reveal that this prompt learning-based approach results in degraded sample
quality. Our analysis shows that the approach's training objective -- which
aims to align the embedding differences of learned prompts and reference images
-- could be sub-optimal, resulting in distortion of the learned prompts and
degraded generated images. To further substantiate this claim, as our major
contribution, we deep dive into the denoising subnetwork of the T2I model to
track down the effect of these learned prompts by analyzing the cross-attention
maps. In our analysis, we propose a novel prompt switching analysis: I2H and
H2I. Furthermore, we propose new quantitative characterization of
cross-attention maps. Our analysis reveals abnormalities in the early denoising
steps, perpetuating improper global structure that results in degradation in
the generated samples. Building on insights from our analysis, we propose two
ideas: (i) Prompt Queuing and (ii) Attention Amplification to address the
quality issue. Extensive experimental results on a wide range of tSAs show that
our proposed method outperforms SOTA approach's image generation quality, while
achieving competitive fairness. More resources at FairQueue Project site:
https://sutd-visual-computing-group.github.io/FairQueue

摘要：<paragraph>最近，提示学习已成为公平文本到图像 (T2I) 生成的最先进 (SOTA) 技术。具体来说，这种方法利用现成的参考图像来学习每个目标敏感属性 (tSA) 的包容性提示，从而实现公平的图像生成。在这项工作中，我们首先揭示了这种基于提示学习的方法会导致样本质量下降。我们的分析表明，该方法的训练目标——旨在调整学习提示和参考图像的嵌入差异——可能是次优的，导致学习提示失真和生成图像质量下降。为了进一步证实这一说法，作为我们的主要贡献，我们深入研究了 T2I 模型的去噪子网络，通过分析交叉注意图来追踪这些学习提示的影响。在我们的分析中，我们提出了一种新颖的提示切换分析：I2H 和 H2I。此外，我们提出了交叉注意图的新定量表征。我们的分析揭示了早期去噪步骤中的异常，导致不适当的全局结构，从而导致生成样本退化。基于我们分析中的见解，我们提出了两个想法：(i) 提示排队和 (ii) 注意力放大，以解决质量问题。在广泛的 tSA 上进行的广泛实验结果表明，我们提出的方法在图像生成质量上优于 SOTA 方法，同时实现了有竞争力的公平性。FairQueue 项目网站上有更多资源：https://sutd-visual-computing-group.github.io/FairQueue</paragraph>

##### **TripCast: Pre-training of Masked 2D Transformers for Trip Time Series Forecasting**
2410.18612v1 by Yuhua Liao, Zetian Wang, Peng Wei, Qiangqiang Nie, Zhenhua Zhang

Deep learning and pre-trained models have shown great success in time series
forecasting. However, in the tourism industry, time series data often exhibit a
leading time property, presenting a 2D structure. This introduces unique
challenges for forecasting in this sector. In this study, we propose a novel
modelling paradigm, TripCast, which treats trip time series as 2D data and
learns representations through masking and reconstruction processes.
Pre-trained on large-scale real-world data, TripCast notably outperforms other
state-of-the-art baselines in in-domain forecasting scenarios and demonstrates
strong scalability and transferability in out-domain forecasting scenarios.

摘要：深度學習和預訓練模型在時間序列預測中展現出巨大的成功。然而，在旅遊業中，時間序列資料通常表現出領先時間屬性，呈現出 2D 結構。這為這個領域的預測帶來了獨特的挑戰。在本研究中，我們提出了一種新穎的建模範例 TripCast，它將行程時間序列視為 2D 資料，並透過遮罩和重建過程學習表徵。TripCast 在大規模真實世界資料上進行預訓練，在領域內預測場景中顯著優於其他最先進的基準，並在領域外預測場景中展現出強大的可擴充性和可轉移性。

##### **STTATTS: Unified Speech-To-Text And Text-To-Speech Model**
2410.18607v1 by Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki

Speech recognition and speech synthesis models are typically trained
separately, each with its own set of learning objectives, training data, and
model parameters, resulting in two distinct large networks. We propose a
parameter-efficient approach to learning ASR and TTS jointly via a multi-task
learning objective and shared parameters. Our evaluation demonstrates that the
performance of our multi-task model is comparable to that of individually
trained models while significantly saving computational and memory costs
($\sim$50\% reduction in the total number of parameters required for the two
tasks combined). We experiment with English as a resource-rich language, and
Arabic as a relatively low-resource language due to shortage of TTS data. Our
models are trained with publicly available data, and both the training code and
model checkpoints are openly available for further research.

摘要：語音辨識和語音合成模型通常是分開訓練的，每個模型都有自己的一組學習目標、訓練資料和模型參數，導致兩個不同的大型網路。我們提出了一種參數有效率的方法，透過多任務學習目標和共享參數來共同學習 ASR 和 TTS。我們的評估結果顯示，我們的多任務模型的效能與個別訓練的模型相當，同時大幅節省了運算和記憶體成本（兩個任務總共需要的參數數量減少了 $\sim$50%）。我們以英語作為一種資源豐富的語言進行實驗，並以阿拉伯語作為一種相對資源較少的語言，因為缺乏 TTS 資料。我們的模型使用公開的資料進行訓練，訓練程式碼和模型檢查點都公開提供，供進一步研究使用。

##### **Speech perception: a model of word recognition**
2410.18590v1 by Jean-Marc Luck, Anita Mehta

We present a model of speech perception which takes into account effects of
correlations between sounds. Words in this model correspond to the attractors
of a suitably chosen descent dynamics. The resulting lexicon is rich in short
words, and much less so in longer ones, as befits a reasonable word length
distribution. We separately examine the decryption of short and long words in
the presence of mishearings. In the regime of short words, the algorithm either
quickly retrieves a word, or proposes another valid word. In the regime of
longer words, the behaviour is markedly different. While the successful
decryption of words continues to be relatively fast, there is a finite
probability of getting lost permanently, as the algorithm wanders round the
landscape of suitable words without ever settling on one.

摘要：我們提出一個語音感知模型，它考慮了聲音之間相關性的影響。此模型中的單詞對應於適當選擇的下降動態的吸引子。由此產生的詞彙表中短詞豐富，長詞則少得多，這符合合理的詞長分佈。我們分別檢查了在聽錯的情況下對短詞和長詞的解密。在短詞的情況下，演算法會快速擷取一個單詞，或提出另一個有效的單詞。在長詞的情況下，行為明顯不同。雖然單詞的成功解密仍然相對快速，但演算法在適合的單詞環境中徘徊而不確定哪一個，因此有永久迷失的有限機率。

##### **Aligning CodeLLMs with Direct Preference Optimization**
2410.18585v1 by Yibo Miao, Bofei Gao, Shanghaoran Quan, Junyang Lin, Daoguang Zan, Jiaheng Liu, Jian Yang, Tianyu Liu, Zhijie Deng

The last year has witnessed the rapid progress of large language models
(LLMs) across diverse domains. Among them, CodeLLMs have garnered particular
attention because they can not only assist in completing various programming
tasks but also represent the decision-making and logical reasoning capabilities
of LLMs. However, current CodeLLMs mainly focus on pre-training and supervised
fine-tuning scenarios, leaving the alignment stage, which is important for
post-training LLMs, under-explored. This work first identifies that the
commonly used PPO algorithm may be suboptimal for the alignment of CodeLLM
because the involved reward rules are routinely coarse-grained and potentially
flawed. We then advocate addressing this using the DPO algorithm. Based on only
preference data pairs, DPO can render the model rank data automatically, giving
rise to a fine-grained rewarding pattern more robust than human intervention.
We also contribute a pipeline for collecting preference pairs for DPO on
CodeLLMs. Studies show that our method significantly improves the performance
of existing CodeLLMs on benchmarks such as MBPP and HumanEval.

摘要：去年，大型語言模型 (LLM) 在各個領域都取得了快速進展。其中，CodeLLM 特別受到關注，因為它們不僅可以協助完成各種程式設計任務，還可以代表 LLM 的決策制定和邏輯推理能力。然而，目前的 CodeLLM 主要專注於預訓練和監督微調場景，而對訓練後 LLM 很重要的對齊階段則探索不足。這項工作首先發現，常用的 PPO 演算法可能不適合 CodeLLM 的對齊，因為所涉及的獎勵規則通常是粗略的，而且可能存在缺陷。然後，我們提倡使用 DPO 演算法來解決這個問題。DPO 僅基於偏好資料對，就可以自動呈現模型排名資料，從而產生比人工干預更穩健的細緻獎勵模式。我們還為 CodeLLM 上的 DPO 偏好對收集提供了一個管道。研究表明，我們的方法顯著提升了現有 CodeLLM 在 MBPP 和 HumanEval 等基準上的效能。

##### **SIKeD: Self-guided Iterative Knowledge Distillation for mathematical reasoning**
2410.18574v1 by Shivam Adarsh, Kumar Shridhar, Caglar Gulcehre, Nicholas Monath, Mrinmaya Sachan

Large Language Models (LLMs) can transfer their reasoning skills to smaller
models by teaching them to generate the intermediate reasoning process required
to solve multistep reasoning tasks. While LLMs can accurately solve reasoning
tasks through a variety of strategies, even without fine-tuning, smaller models
are not expressive enough to fit the LLMs distribution on all strategies when
distilled and tend to prioritize one strategy over the others. This reliance on
one strategy poses a challenge for smaller models when attempting to solve
reasoning tasks that may be difficult with their preferred strategy. To address
this, we propose a distillation method SIKeD (Self-guided Iterative Knowledge
Distillation for mathematical reasoning), where the LLM teaches the smaller
model to approach a task using different strategies and the smaller model uses
its self-generated on-policy outputs to choose the most suitable strategy for
the given task. The training continues in a self-guided iterative manner, where
for each training iteration, a decision is made on how to combine the LLM data
with the self-generated outputs. Unlike traditional distillation methods, SIKeD
allows the smaller model to learn which strategy is suitable for a given task
while continuously learning to solve a task using different strategies. Our
experiments on various mathematical reasoning datasets show that SIKeD
significantly outperforms traditional distillation techniques across smaller
models of different sizes. Our code is available at:
https://github.com/kumar-shridhar/SIKeD

摘要：大型語言模型 (LLM) 可以透過教導較小的模型產生解決多步驟推理任務所需的推理過程，將其推理技能傳遞給較小的模型。雖然 LLM 可以透過各種策略準確解決推理任務，即使沒有微調，但較小的模型在經過蒸餾後，並不足以適用於所有策略的 LLM 分佈，並且傾向於優先考慮一種策略，而忽略其他策略。當嘗試解決使用其首選策略可能很困難的推理任務時，依賴一種策略對較小的模型構成挑戰。為了解決這個問題，我們提出了一種蒸餾方法 SIKeD（數學推理的自導式反覆知識蒸餾），其中 LLM 教導較小的模型使用不同的策略來處理任務，而較小的模型使用其自我產生的策略輸出，為給定的任務選擇最合適的策略。訓練以自導式反覆方式進行，在每次訓練反覆運算中，都會決定如何將 LLM 資料與自我產生的輸出結合。與傳統的蒸餾方法不同，SIKeD 允許較小的模型學習哪種策略適合給定的任務，同時持續學習使用不同策略來解決任務。我們在各種數學推理資料集上的實驗表明，SIKeD 在不同大小的較小模型中，都顯著優於傳統的蒸餾技術。我們的程式碼可在以下位置取得：
https://github.com/kumar-shridhar/SIKeD

##### **Taipan: Efficient and Expressive State Space Language Models with Selective Attention**
2410.18572v1 by Chien Van Nguyen, Huy Huu Nguyen, Thang M. Pham, Ruiyi Zhang, Hanieh Deilamsalehy, Puneet Mathur, Ryan A. Rossi, Trung Bui, Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen

Efficient long-context language modeling remains a significant challenge in
Natural Language Processing (NLP). While Transformers dominate language tasks,
they struggle with long sequences due to quadratic computational complexity in
training and linearly scaling memory costs during inference. Recent State Space
Models (SSMs) such as Mamba offer alternatives with constant memory usage, but
they underperform in tasks requiring extensive in-context retrieval. We
introduce Taipan, a novel hybrid architecture that combines Mamba-2 with
Selective Attention Layers (SALs). These SALs identify tokens requiring
long-range interactions, remove less important features, and then augment their
representations using the attention module. This approach balances Mamba's
efficiency with Transformer-like performance in memory-intensive tasks. By
constraining the attention budget, Taipan extends accurate predictions to
context lengths of up to 1 million tokens while preserving computational
efficiency. Our experiments demonstrate Taipan's superior performance across
various scales and tasks, offering a promising solution for efficient
long-context language modeling.

摘要：高效長文本語言建模在自然語言處理 (NLP) 中仍然是一項重大的挑戰。雖然 Transformer 主導語言任務，但由於訓練中的二次計算複雜度和推論期間線性擴展的記憶體成本，它們在處理長序列時會遇到困難。最近的狀態空間模型 (SSM)，例如 Mamba，提供了具有恆定記憶體使用量的替代方案，但它們在需要大量上下文檢索的任務中表現不佳。我們介紹了 Taipan，這是一種新的混合架構，它將 Mamba-2 與選擇性注意層 (SAL) 相結合。這些 SAL 識別需要進行長距離交互的符號，移除較不重要的特徵，然後使用注意模組擴充它們的表示。這種方法平衡了 Mamba 的效率與 Transformer 在記憶密集型任務中的類似效能。通過限制注意力預算，Taipan 將準確的預測擴展到長達 100 萬個符號的上下文長度，同時保持計算效率。我們的實驗證明了 Taipan 在各種規模和任務中的卓越效能，為高效長文本語言建模提供了一個有前景的解決方案。

##### **Zero-shot Object Navigation with Vision-Language Models Reasoning**
2410.18570v1 by Congcong Wen, Yisiyuan Huang, Hao Huang, Yanjia Huang, Shuaihang Yuan, Yu Hao, Hui Lin, Yu-Shen Liu, Yi Fang

Object navigation is crucial for robots, but traditional methods require
substantial training data and cannot be generalized to unknown environments.
Zero-shot object navigation (ZSON) aims to address this challenge, allowing
robots to interact with unknown objects without specific training data.
Language-driven zero-shot object navigation (L-ZSON) is an extension of ZSON
that incorporates natural language instructions to guide robot navigation and
interaction with objects. In this paper, we propose a novel Vision Language
model with a Tree-of-thought Network (VLTNet) for L-ZSON. VLTNet comprises four
main modules: vision language model understanding, semantic mapping,
tree-of-thought reasoning and exploration, and goal identification. Among these
modules, Tree-of-Thought (ToT) reasoning and exploration module serves as a
core component, innovatively using the ToT reasoning framework for navigation
frontier selection during robot exploration. Compared to conventional frontier
selection without reasoning, navigation using ToT reasoning involves multi-path
reasoning processes and backtracking when necessary, enabling globally informed
decision-making with higher accuracy. Experimental results on PASTURE and
RoboTHOR benchmarks demonstrate the outstanding performance of our model in
LZSON, particularly in scenarios involving complex natural language as target
instructions.

摘要：物體導航對於機器人至關重要，但傳統方法需要大量的訓練數據，且無法推廣到未知的環境中。零次學習物體導航 (ZSON) 旨在解決這個挑戰，讓機器人可以在沒有特定訓練數據的情況下與未知的物體互動。語言驅動的零次學習物體導航 (L-ZSON) 是 ZSON 的延伸，它結合了自然語言指令來引導機器人的導航和與物體的互動。在本文中，我們提出了一個結合了思考樹網路 (VLTNet) 的新穎視覺語言模型，用於 L-ZSON。VLTNet 包含四個主要模組：視覺語言模型理解、語義對應、思考樹推理與探索，以及目標識別。在這些模組中，思考樹 (ToT) 推理與探索模組作為核心元件，創新地使用 ToT 推理架構，在機器人探索期間進行導航前沿選擇。與沒有推理的傳統前沿選擇相比，使用 ToT 推理的導航涉及多路徑推理程序，並在必要時回溯，從而實現具有更高精確度的全局知情決策。在 PASTURE 和 RoboTHOR 基準上的實驗結果證明了我們的模型在 LZSON 中的出色表現，特別是在涉及複雜自然語言作為目標指令的情況中。

##### **Difficult for Whom? A Study of Japanese Lexical Complexity**
2410.18567v1 by Adam Nohejl, Akio Hayakawa, Yusuke Ide, Taro Watanabe

The tasks of lexical complexity prediction (LCP) and complex word
identification (CWI) commonly presuppose that difficult to understand words are
shared by the target population. Meanwhile, personalization methods have also
been proposed to adapt models to individual needs. We verify that a recent
Japanese LCP dataset is representative of its target population by partially
replicating the annotation. By another reannotation we show that native Chinese
speakers perceive the complexity differently due to Sino-Japanese vocabulary.
To explore the possibilities of personalization, we compare competitive
baselines trained on the group mean ratings and individual ratings in terms of
performance for an individual. We show that the model trained on a group mean
performs similarly to an individual model in the CWI task, while achieving good
LCP performance for an individual is difficult. We also experiment with
adapting a finetuned BERT model, which results only in marginal improvements
across all settings.

摘要：詞彙複雜度預測 (LCP) 和複雜詞彙識別 (CWI) 的任務通常預設目標族群分享難以理解的詞彙。同時，也已提出個人化方法來調整模型以符合個人需求。我們驗證最近的日文 LCP 資料集代表其目標族群，方法是部分複製註解。透過另一種重新註解，我們顯示出由於漢字日語詞彙，漢語母語人士對複雜度的感知不同。為了探索個人化的可能性，我們比較在群組平均評分和個人評分上訓練的競爭基線，以評估個人表現。我們顯示出在群組平均數上訓練的模型在 CWI 任務中表現與個人模型類似，同時難以達成良好的個人 LCP 表現。我們也嘗試調整微調 BERT 模型，結果僅在所有設定中獲得極小的改善。

##### **Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and Evaluation**
2410.18565v1 by Krzysztof Ociepa, Łukasz Flis, Krzysztof Wróbel, Adrian Gwoździej, Remigiusz Kinas

We introduce Bielik 7B v0.1, a 7-billion-parameter generative text model for
Polish language processing. Trained on curated Polish corpora, this model
addresses key challenges in language model development through innovative
techniques. These include Weighted Instruction Cross-Entropy Loss, which
balances the learning of different instruction types, and Adaptive Learning
Rate, which dynamically adjusts the learning rate based on training progress.
To evaluate performance, we created the Open PL LLM Leaderboard and Polish
MT-Bench, novel frameworks assessing various NLP tasks and conversational
abilities. Bielik 7B v0.1 demonstrates significant improvements, achieving a 9
percentage point increase in average score compared to Mistral-7B-v0.1 on the
RAG Reader task. It also excels in the Polish MT-Bench, particularly in
Reasoning (6.15/10) and Role-playing (7.83/10) categories. This model
represents a substantial advancement in Polish language AI, offering a powerful
tool for diverse linguistic applications and setting new benchmarks in the
field.

摘要：我們推出 Bielik 7B v0.1，這是一個針對波蘭語處理的 70 億參數生成文本模型。此模型針對經過策展的波蘭語語料庫進行訓練，並透過創新技術來解決語言模型開發中的主要挑戰。這些技術包括加權指令交叉熵損失，它平衡了不同指令類型的學習，以及自適應學習率，它會根據訓練進度動態調整學習率。為了評估效能，我們建立了開放式 PL LLM 排行榜和波蘭語 MT-Bench，這些是評估各種 NLP 任務和對話能力的新穎架構。與 RAG Reader 任務中的 Mistral-7B-v0.1 相比，Bielik 7B v0.1 有顯著的進步，平均分數提高了 9 個百分點。它也在波蘭語 MT-Bench 中表現出色，特別是在推理 (6.15/10) 和角色扮演 (7.83/10) 類別中。此模型代表了波蘭語 AI 的重大進步，為各種語言應用程式提供了強大的工具，並在該領域樹立了新的基準。

##### **Infinity-MM: Scaling Multimodal Performance with Large-Scale and High-Quality Instruction Data**
2410.18558v1 by Shuhao Gu, Jialing Zhang, Siyuan Zhou, Kevin Yu, Zhaohu Xing, Liangdong Wang, Zhou Cao, Jintao Jia, Zhuoyi Zhang, Yixuan Wang, Zhenchong Hu, Bo-Wen Zhang, Jijie Li, Dong Liang, Yingli Zhao, Yulong Ao, Yaoqi Liu, Fangxiang Feng, Guang Liu

Vision-Language Models (VLMs) have recently made significant progress, but
the limited scale and quality of open-source instruction data hinder their
performance compared to closed-source models. In this work, we address this
limitation by introducing Infinity-MM, a large-scale multimodal instruction
dataset with 40 million samples, enhanced through rigorous quality filtering
and deduplication. We also propose a synthetic instruction generation method
based on open-source VLMs, using detailed image annotations and diverse
question generation. Using this data, we trained a 2-billion-parameter VLM,
Aquila-VL-2B, achieving state-of-the-art (SOTA) performance for models of
similar scale. This demonstrates that expanding instruction data and generating
synthetic data can significantly improve the performance of open-source models.

摘要：視覺語言模型 (VLM) 近期取得顯著進展，但與封閉原始碼模型相比，開放原始碼指令資料的規模和品質有限，阻礙了其效能。在這項工作中，我們透過引入 Infinity-MM 來解決此限制，這是一個包含 4000 萬個範例的大型多模態指令資料集，並透過嚴格的品質過濾和刪除重複項而增強。我們也提出一個基於開放原始碼 VLM 的合成指令生成方法，使用詳細的影像註解和多元的問題生成。使用此資料，我們訓練了一個 20 億參數的 VLM，Aquila-VL-2B，達到了與類似規模模型的最新技術 (SOTA) 效能。這證明了擴充指令資料和生成合成資料可以顯著提升開放原始碼模型的效能。

##### **Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness**
2410.18556v1 by David Khachaturov, Robert Mullins

Quantifying robustness in a single measure for the purposes of model
selection, development of adversarial training methods, and anticipating trends
has so far been elusive. The simplest metric to consider is the number of
trainable parameters in a model but this has previously been shown to be
insufficient at explaining robustness properties. A variety of other metrics,
such as ones based on boundary thickness and gradient flatness have been
proposed but have been shown to be inadequate proxies for robustness.
  In this work, we investigate the relationship between a model's effective
dimensionality, which can be thought of as model complexity, and its robustness
properties. We run experiments on commercial-scale models that are often used
in real-world environments such as YOLO and ResNet. We reveal a near-linear
inverse relationship between effective dimensionality and adversarial
robustness, that is models with a lower dimensionality exhibit better
robustness. We investigate the effect of a variety of adversarial training
methods on effective dimensionality and find the same inverse linear
relationship present, suggesting that effective dimensionality can serve as a
useful criterion for model selection and robustness evaluation, providing a
more nuanced and effective metric than parameter count or previously-tested
measures.

摘要：量化健壯性以用於模型選擇、對抗訓練方法的開發和預期趨勢的單一指標，到目前為止一直難以捉摸。要考慮的最簡單指標是模型中的可訓練參數數量，但先前已顯示這不足以解釋健壯性屬性。已經提出了各種其他指標，例如基於邊界厚度和梯度平坦度的指標，但已顯示它們是不適當的健壯性代理。
在這項工作中，我們探討模型的有效維度（可以視為模型複雜度）與其健壯性屬性之間的關係。我們對在現實世界環境中經常使用的商業規模模型（例如 YOLO 和 ResNet）執行實驗。我們揭示了有效維度和對抗健壯性之間近乎線性的反比關係，即維度較低的模型表現出更好的健壯性。我們探討了各種對抗訓練方法對有效維度的影響，並發現存在相同的反比線性關係，這表明有效維度可以用作模型選擇和健壯性評估的有用標準，提供比參數計數或先前測試的指標更細緻且有效的指標。

##### **On Explaining with Attention Matrices**
2410.18541v1 by Omar Naim, Nicholas Asher

This paper explores the much discussed, possible explanatory link between
attention weights (AW) in transformer models and predicted output. Contrary to
intuition and early research on attention, more recent prior research has
provided formal arguments and empirical evidence that AW are not explanatorily
relevant. We show that the formal arguments are incorrect. We introduce and
effectively compute efficient attention, which isolates the effective
components of attention matrices in tasks and models in which AW play an
explanatory role. We show that efficient attention has a causal role (provides
minimally necessary and sufficient conditions) for predicting model output in
NLP tasks requiring contextual information, and we show, contrary to [7], that
efficient attention matrices are probability distributions and are effectively
calculable. Thus, they should play an important part in the explanation of
attention based model behavior. We offer empirical experiments in support of
our method illustrating various properties of efficient attention with various
metrics on four datasets.

摘要：本文探討了Transformer模型中注意力權重 (AW) 與預測輸出之間廣泛討論的可能解釋性連結。與直覺和早期注意力研究相反，最近較早的研究提供了正式論證和經驗證據，表明 AW 沒有解釋性相關性。我們表明正式論證是不正確的。我們引入並有效計算有效注意力，它會分離任務和模型中注意力矩陣的有效組成，在這些任務和模型中，AW 扮演了解釋性角色。我們表明有效注意力在預測需要上下文資訊的 NLP 任務中的模型輸出時有因果關係（提供最小必要且充分的條件），而且我們表明與 [7] 相反，有效注意力矩陣是機率分佈，且可以有效計算。因此，它們應在基於注意力的模型行為的解釋中扮演重要角色。我們提供經驗實驗以支持我們的各種指標在四個資料集上說明有效注意力的各種屬性的方法。

##### **LOGO -- Long cOntext aliGnment via efficient preference Optimization**
2410.18533v1 by Zecheng Tang, Zechen Sun, Juntao Li, Qiaoming Zhu, Min Zhang

Long-context models(LCMs) have shown great potential in processing long input
sequences(even more than 100M tokens) conveniently and effectively. With
significant progress, recent research has pointed out that LCMs can accurately
locate token-level salient information within the context. Yet, the generation
performance of these LCMs is far from satisfactory and might result in
misaligned responses, such as hallucinations. To enhance the generation
capability of LCMs, existing works have investigated the effects of data size
and quality for both pre-training and instruction tuning. Though achieving
meaningful improvement, previous methods fall short in either effectiveness or
efficiency. In this paper, we introduce LOGO(Long cOntext aliGnment via
efficient preference Optimization), a training strategy that first introduces
preference optimization for long-context alignment. To overcome the GPU
memory-bound issue caused by the long sequence, LOGO employs a reference-free
preference optimization strategy and adopts a position synthesis method to
construct the training data. By training with only 0.3B data on a single
8$\times$A800 GPU machine for 16 hours, LOGO allows the Llama-3-8B-Instruct-80K
model to achieve comparable performance with GPT-4 in real-world long-context
tasks while preserving the model's original capabilities on other tasks, e.g.,
language modeling and MMLU. Moreover, LOGO can extend the model's context
window size while enhancing its generation performance.

摘要：長語境模型 (LCM) 已展現出便利且有效處理長輸入序列（甚至超過 100M 個符號）的巨大潛力。隨著顯著進展，近期研究指出 LCM 能準確找出語境中的符號層級顯著資訊。然而，這些 LCM 的生成效能遠未令人滿意，可能會導致反應失準，例如出現幻覺。為了提升 LCM 的生成能力，現有研究已探討資料大小和品質對預訓練和指令微調的影響。雖然取得有意義的進展，但先前的做法在效能或效率方面仍有不足。在本文中，我們介紹 LOGO（透過有效偏好最佳化進行長語境對齊），這是一種訓練策略，首先引入偏好最佳化以進行長語境對齊。為了克服長序列造成的 GPU 記憶體受限問題，LOGO 採用無參考偏好最佳化策略，並採用位置合成方法來建構訓練資料。透過在單一 8$\times$A800 GPU 機器上只使用 0.3B 資料訓練 16 小時，LOGO 使 Llama-3-8B-Instruct-80K 模型在真實世界長語境任務中達到與 GPT-4 相當的效能，同時保留模型在其他任務（例如語言建模和 MMLU）上的原始能力。此外，LOGO 能在提升生成效能的同時，擴充模型的語境視窗大小。

##### **A Systematic Survey on Instructional Text: From Representation and Downstream NLP Tasks**
2410.18529v1 by Abdulfattah Safa, Tamta Kapanadze, Arda Uzunoğlu, Gözde Gül Şahin

Recent advances in large language models have demonstrated promising
capabilities in following simple instructions through instruction tuning.
However, real-world tasks often involve complex, multi-step instructions that
remain challenging for current NLP systems. Despite growing interest in this
area, there lacks a comprehensive survey that systematically analyzes the
landscape of complex instruction understanding and processing. Through a
systematic review of the literature, we analyze available resources,
representation schemes, and downstream tasks related to instructional text. Our
study examines 177 papers, identifying trends, challenges, and opportunities in
this emerging field. We provide AI/NLP researchers with essential background
knowledge and a unified view of various approaches to complex instruction
understanding, bridging gaps between different research directions and
highlighting future research opportunities.

摘要：最近在大型语言模型方面的进展已在通过指令调整遵循简单指令方面展示了有希望的能力。然而，现实世界中的任务通常涉及复杂的多步骤指令，这对当前的 NLP 系统来说仍然具有挑战性。尽管对这个领域越来越感兴趣，但仍缺乏系统分析复杂指令理解和处理的全面调查。通过对文献进行系统回顾，我们分析了与教学文本相关的可用资源、表示方案和下游任务。我们的研究审查了 177 篇论文，确定了这个新兴领域的趋势、挑战和机遇。我们为人工智能/自然语言处理研究人员提供了必要的背景知识和对复杂指令理解的各种方法的统一看法，弥合了不同研究方向之间的差距，并强调了未来的研究机会。

##### **KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing**
2410.18517v1 by Yifei Yang, Zouying Cao, Qiguang Chen, Libo Qin, Dongjie Yang, Hai Zhao, Zhi Chen

The development of large language models (LLMs) has significantly expanded
model sizes, resulting in substantial GPU memory requirements during inference.
The key and value storage of the attention map in the KV (key-value) cache
accounts for more than 80\% of this memory consumption. Nowadays, most existing
KV cache compression methods focus on intra-layer compression within a single
Transformer layer but few works consider layer-wise compression. In this paper,
we propose a plug-and-play method called \textit{KVSharer}, which shares the KV
cache between layers to achieve layer-wise compression. Rather than intuitively
sharing based on higher similarity, we discover a counterintuitive phenomenon:
sharing dissimilar KV caches better preserves the model performance.
Experiments show that \textit{KVSharer} can reduce KV cache computation by
30\%, thereby lowering memory consumption without significantly impacting model
performance and it can also achieve at least 1.3 times generation acceleration.
Additionally, we verify that \textit{KVSharer} is compatible with existing
intra-layer KV cache compression methods, and combining both can further save
memory.

摘要：大型語言模型 (LLM) 的發展大幅擴展了模型規模，導致推論期間需要大量的 GPU 記憶體。
KV (key-value) 快取中注意力圖的 key 和 value 儲存佔用此記憶體消耗的 80% 以上。現今，大多數現有的 KV 快取壓縮方法都專注於單一 Transformer 層內的層內壓縮，但很少有研究考慮層級壓縮。在本文中，我們提出了一種稱為 \textit{KVSharer} 的即插即用方法，它在層之間共用 KV 快取以實現層級壓縮。我們並非直覺地根據較高的相似性來共用，而是發現了一個反直覺的現象：共用不類似的 KV 快取能更好地保留模型效能。實驗顯示，\textit{KVSharer} 可以將 KV 快取運算減少 30%，從而降低記憶體消耗，而不會顯著影響模型效能，且還能將生成加速至少提升 1.3 倍。此外，我們驗證了 \textit{KVSharer} 與現有的層內 KV 快取壓縮方法相容，且結合兩者可以進一步節省記憶體。

##### **Scaling up Masked Diffusion Models on Text**
2410.18514v1 by Shen Nie, Fengqi Zhu, Chao Du, Tianyu Pang, Qian Liu, Guangtao Zeng, Min Lin, Chongxuan Li

Masked diffusion models (MDMs) have shown promise in language modeling, yet
their scalability and effectiveness in core language tasks, such as text
generation and language understanding, remain underexplored. This paper
establishes the first scaling law for MDMs, demonstrating a scaling rate
comparable to autoregressive models (ARMs) and a relatively small compute gap.
Motivated by their scalability, we train a family of MDMs with up to 1.1
billion (B) parameters to systematically evaluate their performance against
ARMs of comparable or larger sizes. Fully leveraging the probabilistic
formulation of MDMs, we propose a simple yet effective \emph{unsupervised
classifier-free guidance} that effectively exploits large-scale unpaired data,
boosting performance for conditional inference. In language understanding, a
1.1B MDM shows competitive results, outperforming the larger 1.5B GPT-2 model
on four out of eight zero-shot benchmarks. In text generation, MDMs provide a
flexible trade-off compared to ARMs utilizing KV-cache: MDMs match the
performance of ARMs while being 1.4 times faster, or achieve higher quality
than ARMs at a higher computational cost. Moreover, MDMs address challenging
tasks for ARMs by effectively handling bidirectional reasoning and adapting to
temporal shifts in data. Notably, a 1.1B MDM breaks the \emph{reverse curse}
encountered by much larger ARMs with significantly more data and computation,
such as Llama-2 (13B) and GPT-3 (175B). Our code is available at
\url{https://github.com/ML-GSAI/SMDM}.

摘要：<paragraph>蒙面擴散模型（MDM）在語言模型中展現出前景，但其在核心語言任務（例如文字生成和語言理解）中的可擴充性和有效性仍未得到充分探討。本文建立了 MDMS 的第一個擴充定律，證明了與自迴歸模型（ARM）相當的擴充率和相對較小的運算差距。在可擴充性的激勵下，我們訓練了一個擁有高達 11 億（B）參數的 MDM 族，以系統性地評估其相等或更大規模 ARM 的效能。充分利用 MDM 的機率公式，我們提出了一個簡單但有效的「無監督分類器免費指導」，有效地利用了大規模未配對資料，提升了條件式推論的效能。在語言理解方面，1.1B MDM 顯示出有競爭力的結果，在八個零次學習基準中的四個中表現優於較大的 1.5B GPT-2 模型。在文字生成方面，與使用 KV 快取的 ARM 相比，MDM 提供了一個靈活的權衡：MDM 在速度快 1.4 倍的情況下與 ARM 的效能相匹配，或以較高的運算成本實現比 ARM 更高的品質。此外，MDM 透過有效處理雙向推理和適應資料中的時間變化，解決了 ARM 的挑戰性任務。值得注意的是，1.1B MDM 打破了規模大得多的 ARM 所遭遇的「反向詛咒」，後者擁有更多資料和運算，例如 Llama-2（13B）和 GPT-3（175B）。我們的程式碼可在\url{https://github.com/ML-GSAI/SMDM}取得。</paragraph>

##### **Enhancing Graph Attention Neural Network Performance for Marijuana Consumption Classification through Large-scale Augmented Granger Causality (lsAGC) Analysis of Functional MR Images**
2410.18506v1 by Ali Vosoughi, Akhil Kasturi, Axel Wismueller

In the present research, the effectiveness of large-scale Augmented Granger
Causality (lsAGC) as a tool for gauging brain network connectivity was examined
to differentiate between marijuana users and typical controls by utilizing
resting-state functional Magnetic Resonance Imaging (fMRI). The relationship
between marijuana consumption and alterations in brain network connectivity is
a recognized fact in scientific literature. This study probes how lsAGC can
accurately discern these changes. The technique used integrates dimension
reduction with the augmentation of source time-series in a model that predicts
time-series, which helps in estimating the directed causal relationships among
fMRI time-series. As a multivariate approach, lsAGC uncovers the connection of
the inherent dynamic system while considering all other time-series. A dataset
of 60 adults with an ADHD diagnosis during childhood, drawn from the Addiction
Connectome Preprocessed Initiative (ACPI), was used in the study. The brain
connections assessed by lsAGC were utilized as classification attributes. A
Graph Attention Neural Network (GAT) was chosen to carry out the classification
task, particularly for its ability to harness graph-based data and recognize
intricate interactions between brain regions, making it appropriate for
fMRI-based brain connectivity data. The performance was analyzed using a
five-fold cross-validation system. The average accuracy achieved by the
correlation coefficient method was roughly 52.98%, with a 1.65 standard
deviation, whereas the lsAGC approach yielded an average accuracy of 61.47%,
with a standard deviation of 1.44. The suggested method enhances the body of
knowledge in the field of neuroimaging-based classification and emphasizes the
necessity to consider directed causal connections in brain network connectivity
analysis when studying marijuana's effects on the brain.

摘要：<paragraph>在現今的研究中，大規模擴增 Granger 因果關係 (lsAGC) 作為評估大腦網路連結性的工具的有效性受到檢驗，以利用靜態功能性磁振造影 (fMRI) 區分大麻使用者和典型對照組。大麻使用與大腦網路連結性改變之間的關係是科學文獻中公認的事實。本研究探討 lsAGC 如何準確辨別這些改變。所使用的技術將維度簡約與模型中來源時間序列的擴充整合，該模型預測時間序列，有助於估計 fMRI 時間序列之間的定向因果關係。作為多變量方法，lsAGC 在考量所有其他時間序列的同時揭示固有動態系統的連結。研究中使用從成癮連接組前處理計畫 (ACPI) 中提取的 60 位在童年時期被診斷出患有 ADHD 的成人的數據集。由 lsAGC 評估的大腦連結被用作分類屬性。圖注意力神經網路 (GAT) 被選來執行分類任務，特別是因為它具備利用基於圖形的數據和辨識大腦區域之間複雜互動的能力，使其適用於基於 fMRI 的大腦連結性數據。使用五倍交叉驗證系統分析效能。相關係數法達成的平均準確度約為 52.98%，標準差為 1.65，而 lsAGC 方法的平均準確度為 61.47%，標準差為 1.44。建議的方法增強了基於神經影像學的分類領域的知識體系，並強調在研究大麻對大腦的影響時，在腦網路連結性分析中考量定向因果連結的必要性。</paragraph>

##### **CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models**
2410.18505v1 by Liangdong Wang, Bo-Wen Zhang, Chengwei Wu, Hanyu Zhao, Xiaofeng Shi, Shuhao Gu, Jijie Li, Quanyue Ma, TengFei Pan, Guang Liu

We present CCI3.0-HQ (https://huggingface.co/datasets/BAAI/CCI3-HQ), a
high-quality 500GB subset of the Chinese Corpora Internet 3.0
(CCI3.0)(https://huggingface.co/datasets/BAAI/CCI3-Data), developed using a
novel two-stage hybrid filtering pipeline that significantly enhances data
quality. To evaluate its effectiveness, we trained a 0.5B parameter model from
scratch on 100B tokens across various datasets, achieving superior performance
on 10 benchmarks in a zero-shot setting compared to CCI3.0, SkyPile, and
WanjuanV1. The high-quality filtering process effectively distills the
capabilities of the Qwen2-72B-instruct model into a compact 0.5B model,
attaining optimal F1 scores for Chinese web data classification. We believe
this open-access dataset will facilitate broader access to high-quality
language models.

摘要：我們提供 CCI3.0-HQ (https://huggingface.co/datasets/BAAI/CCI3-HQ)，一個
高品質的 500GB 子集，來自於中文語料庫網際網路 3.0
(CCI3.0)(https://huggingface.co/datasets/BAAI/CCI3-Data)，使用一個
新穎的兩階段混合過濾管道開發而成，大幅增強資料
品質。為了評估其有效性，我們從頭開始訓練一個 0.5B 參數模型
在 100B 個各種資料集中的代幣上，在零次學習的設定下，在 10 個基準上達成優異的表現
與 CCI3.0、SkyPile 和 WanjuanV1 相比。高品質的過濾程序有效地將
Qwen2-72B-instruct 模型的能力提煉到一個緊湊的 0.5B 模型中，
在中文網路資料分類中獲得最佳的 F1 分數。我們相信
這個開放取用的資料集將促進更廣泛地使用高品質
語言模型。

##### **SFB-net for cardiac segmentation: Bridging the semantic gap with attention**
2410.18503v1 by Nicolas Portal, Nadjia Kachenoura, Thomas Dietenbeck, Catherine Achard

In the past few years, deep learning algorithms have been widely used for
cardiac image segmentation. However, most of these architectures rely on
convolutions that hardly model long-range dependencies, limiting their ability
to extract contextual information. In order to tackle this issue, this article
introduces the Swin Filtering Block network (SFB-net) which takes advantage of
both conventional and swin transformer layers. The former are used to introduce
spatial attention at the bottom of the network, while the latter are applied to
focus on high level semantically rich features between the encoder and decoder.
An average Dice score of 92.4 was achieved on the ACDC dataset. To the best of
our knowledge, this result outperforms any other work on this dataset. The
average Dice score of 87.99 obtained on the M\&amp;M's dataset demonstrates
that the proposed method generalizes well to data from different vendors and
centres.

摘要：在過去幾年中，深度學習演算法已廣泛用於心臟影像分割。然而，這些架構大多依賴於難以建模長程依賴性的卷積，限制了它們提取上下文資訊的能力。為了解決這個問題，本文介紹了 Swin Filtering Block 網路 (SFB-net)，它同時利用傳統和 swin transformer 層。前者用於在網路底部引入空間注意力，而後者用於關注編碼器和解碼器之間的高層語義豐富特徵。在 ACDC 資料集上達到了 92.4 的平均 Dice 分數。據我們所知，此結果優於該資料集上的任何其他工作。在 M&amp;M's 資料集上獲得的 87.99 的平均 Dice 分數表明，所提出的方法可以很好地推廣到來自不同供應商和中心的資料。

##### **ChineseSafe: A Chinese Benchmark for Evaluating Safety in Large Language Models**
2410.18491v1 by Hengxiang Zhang, Hongfu Gao, Qiang Hu, Guanhua Chen, Lili Yang, Bingyi Jing, Hongxin Wei, Bing Wang, Haifeng Bai, Lei Yang

With the rapid development of Large language models (LLMs), understanding the
capabilities of LLMs in identifying unsafe content has become increasingly
important. While previous works have introduced several benchmarks to evaluate
the safety risk of LLMs, the community still has a limited understanding of
current LLMs' capability to recognize illegal and unsafe content in Chinese
contexts. In this work, we present a Chinese safety benchmark (ChineseSafe) to
facilitate research on the content safety of large language models. To align
with the regulations for Chinese Internet content moderation, our ChineseSafe
contains 205,034 examples across 4 classes and 10 sub-classes of safety issues.
For Chinese contexts, we add several special types of illegal content:
political sensitivity, pornography, and variant/homophonic words. Moreover, we
employ two methods to evaluate the legal risks of popular LLMs, including
open-sourced models and APIs. The results reveal that many LLMs exhibit
vulnerability to certain types of safety issues, leading to legal risks in
China. Our work provides a guideline for developers and researchers to
facilitate the safety of LLMs. Our results are also available at
https://huggingface.co/spaces/SUSTech/ChineseSafe-Benchmark.

摘要：隨著大型語言模型 (LLM) 的快速發展，了解 LLM 在識別不安全內容方面的能力變得越來越重要。雖然先前的研究已經引入了幾個基準來評估 LLM 的安全風險，但社群對於當前 LLM 識別中文語境中非法和不安全內容的能力仍有有限的了解。在這項研究中，我們提出了一個中文安全基準 (ChineseSafe)，以促進對大型語言模型內容安全的研究。為了符合中國網路內容審核法規，我們的 ChineseSafe 包含 4 個類別和 10 個子類別的安全問題，共 205,034 個範例。對於中文語境，我們增加了幾種特殊類型的非法內容：政治敏感性、色情內容和變體/諧音字。此外，我們採用兩種方法來評估熱門 LLM 的法律風險，包括開源模型和 API。結果顯示，許多 LLM 對某些類型的安全問題表現出脆弱性，這導致了中國的法律風險。我們的研究為開發人員和研究人員提供了指導方針，以促進 LLM 的安全性。我們的結果也可在 https://huggingface.co/spaces/SUSTech/ChineseSafe-Benchmark 取得。

##### **LLM as a code generator in Agile Model Driven Development**
2410.18489v1 by Ahmed R. Sadik, Sebastian Brulin, Markus Olhofer, Antonello Ceravola, Frank Joublin

Leveraging Large Language Models (LLM) like GPT4 in the auto generation of
code represents a significant advancement, yet it is not without its
challenges. The ambiguity inherent in natural language descriptions of software
poses substantial obstacles to generating deployable, structured artifacts.
This research champions Model Driven Development (MDD) as a viable strategy to
overcome these challenges, proposing an Agile Model Driven Development (AMDD)
approach that employs GPT4 as a code generator. This approach enhances the
flexibility and scalability of the code auto generation process and offers
agility that allows seamless adaptation to changes in models or deployment
environments. We illustrate this by modeling a multi agent Unmanned Vehicle
Fleet (UVF) system using the Unified Modeling Language (UML), significantly
reducing model ambiguity by integrating the Object Constraint Language (OCL)
for code structure meta modeling, and the FIPA ontology language for
communication semantics meta modeling. Applying GPT4 auto generation
capabilities yields Java and Python code that is compatible with the JADE and
PADE frameworks, respectively. Our thorough evaluation of the auto generated
code verifies its alignment with expected behaviors and identifies enhancements
in agent interactions. Structurally, we assessed the complexity of code derived
from a model constrained solely by OCL meta models, against that influenced by
both OCL and FIPA ontology meta models. The results indicate that the ontology
constrained meta model produces inherently more complex code, yet its
cyclomatic complexity remains within manageable levels, suggesting that
additional meta model constraints can be incorporated without exceeding the
high risk threshold for complexity.

摘要：利用 GPT4 等大型語言模型 (LLM) 自動生成程式碼是一項重大進展，但並非沒有挑戰。軟體自然語言描述中固有的模糊性對產生可部署的結構化人工製品構成重大障礙。本研究主張模型驅動開發 (MDD) 是一種克服這些挑戰的可行策略，提出了一種採用 GPT4 作為程式碼生成器的敏捷模型驅動開發 (AMDD) 方法。這種方法增強了程式碼自動生成過程的彈性和可擴充性，並提供了靈活性，允許無縫適應模型或部署環境的變更。我們透過使用統一建模語言 (UML) 建模多代理無人載具車隊 (UVF) 系統來說明這一點，透過整合物件約束語言 (OCL) 進行程式碼結構元建模，以及使用 FIPA ontology 語言進行通訊語義元建模，大幅減少模型的模糊性。應用 GPT4 自動生成功能產生與 JADE 和 PADE 框架分別相容的 Java 和 Python 程式碼。我們對自動生成程式碼的徹底評估驗證了其與預期行為的一致性，並找出代理互動中的改進之處。在結構上，我們評估了僅由 OCL 元模型約束的模型所衍生的程式碼複雜度，並與受 OCL 和 FIPA ontology 元模型影響的程式碼複雜度進行比較。結果表明，ontology 約束的元模型會產生本質上更複雜的程式碼，但其圈複雜度仍保持在可控範圍內，這表示可以納入額外的元模型約束，而不會超過複雜度的極高風險閾值。

##### **Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction**
2410.18481v1 by Sergio Burdisso, Srikanth Madikeri, Petr Motlicek

Efficiently deriving structured workflows from unannotated dialogs remains an
underexplored and formidable challenge in computational linguistics. Automating
this process could significantly accelerate the manual design of workflows in
new domains and enable the grounding of large language models in
domain-specific flowcharts, enhancing transparency and controllability. In this
paper, we introduce Dialog2Flow (D2F) embeddings, which differ from
conventional sentence embeddings by mapping utterances to a latent space where
they are grouped according to their communicative and informative functions
(i.e., the actions they represent). D2F allows for modeling dialogs as
continuous trajectories in a latent space with distinct action-related regions.
By clustering D2F embeddings, the latent space is quantized, and dialogs can be
converted into sequences of region/action IDs, facilitating the extraction of
the underlying workflow. To pre-train D2F, we build a comprehensive dataset by
unifying twenty task-oriented dialog datasets with normalized per-turn action
annotations. We also introduce a novel soft contrastive loss that leverages the
semantic information of these actions to guide the representation learning
process, showing superior performance compared to standard supervised
contrastive loss. Evaluation against various sentence embeddings, including
dialog-specific ones, demonstrates that D2F yields superior qualitative and
quantitative results across diverse domains.

摘要：從未標註的對話中有效率地衍生結構化工作流程，在計算語言學中仍然是一個尚未充分探索的艱鉅挑戰。自動化這個流程可以顯著加速在新的領域中手動設計工作流程，並讓大型語言模型在特定領域的流程圖中紮根，進而增強透明度和可控性。在本文中，我們介紹了 Dialog2Flow (D2F) 內嵌，它與傳統的句子內嵌不同，它會將語句對應到一個潛在空間，在其中語句會根據它們的溝通和資訊功能（也就是它們所代表的動作）進行分組。D2F 允許將對話建模為潛在空間中的連續軌跡，其中有不同的動作相關區域。透過將 D2F 內嵌進行分群，潛在空間會被量化，而對話可以轉換成區域/動作 ID 的序列，進而促進底層工作流程的萃取。為了預先訓練 D2F，我們透過統一 20 個以任務為導向的對話資料集，並加上正規化的每輪動作標註，來建構一個全面的資料集。我們也介紹了一個新穎的軟對比損失，它利用這些動作的語義資訊來引導表徵學習流程，與標準的監督式對比損失相比，它展現了優異的效能。針對各種句子內嵌（包括特定於對話的內嵌）進行評估，結果顯示 D2F 在不同的領域中產生了優異的定性和定量結果。

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v1 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

摘要：<paragraph>在快速发展的代謝工程領域中，尋求用於代謝物產量增強的高效且精準的基因目標識別，會面臨重大挑戰。傳統方法（無論是基於知識或基於模型）都相當耗時且費力，原因在於研究文獻的規模龐大，以及基因組規模代謝模型 (GEM) 模擬的近似性質。因此，我們提出一個新任務，即基於代謝圖的基因代謝物關聯預測，以自動化針對特定代謝物和候選關聯基因發現候選基因的流程，並提供第一個基准，其中包含 2474 種代謝物和 1947 種基因，這些基因來自兩種常用的微生物：釀酒酵母 (SC) 和東方伊薩琴科酵母 (IO)。此任務具有挑戰性，原因在於代謝圖的不完整性，以及不同代謝之間的異質性。為了克服這些限制，我們提出一個基於代謝圖的互動式知識傳遞機制 (IKT4Meta)，藉由整合來自不同代謝圖的知識，來提升關聯預測準確度。首先，為了在兩個圖之間建立知識傳遞的橋樑，我們利用具備基因和代謝物外部知識的預訓練語言模型 (PLM) 來協助產生圖際連結，大幅減輕異質性的影響。其次，我們使用圖際連結作為錨點，從不同的代謝圖傳播圖內連結。最後，我們根據整合了多種微生物知識的豐富代謝圖，進行基因代謝物關聯預測。兩種生物的實驗都證明，我們提出的方法在各種連結預測架構中，比基準線高出 12.3%。</paragraph>

##### **Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities**
2410.18469v1 by Chung-En Sun, Xiaodong Liu, Weiwei Yang, Tsui-Wei Weng, Hao Cheng, Aidan San, Michel Galley, Jianfeng Gao

Recent research has shown that Large Language Models (LLMs) are vulnerable to
automated jailbreak attacks, where adversarial suffixes crafted by algorithms
appended to harmful queries bypass safety alignment and trigger unintended
responses. Current methods for generating these suffixes are computationally
expensive and have low Attack Success Rates (ASR), especially against
well-aligned models like Llama2 and Llama3. To overcome these limitations, we
introduce ADV-LLM, an iterative self-tuning process that crafts adversarial
LLMs with enhanced jailbreak ability. Our framework significantly reduces the
computational cost of generating adversarial suffixes while achieving nearly
100\% ASR on various open-source LLMs. Moreover, it exhibits strong attack
transferability to closed-source models, achieving 99% ASR on GPT-3.5 and 49%
ASR on GPT-4, despite being optimized solely on Llama3. Beyond improving
jailbreak ability, ADV-LLM provides valuable insights for future safety
alignment research through its ability to generate large datasets for studying
LLM safety. Our code is available at: https://github.com/SunChungEn/ADV-LLM

摘要：最近的研究显示，大型语言模型 (LLM) 容易受到自动越狱攻击，算法编制的对抗性后缀附加到有害查询中，绕过安全对齐并触发意外的回应。目前生成这些后缀的方法在计算上很昂贵，并且攻击成功率 (ASR) 很低，尤其是针对像 Llama2 和 Llama3 这样的良好对齐模型。为了克服这些限制，我们引入了 ADV-LLM，这是一个迭代自调整过程，它可以制作具有增强越狱能力的对抗性 LLM。我们的框架显着降低了生成对抗性后缀的计算成本，同时在各种开源 LLM 上实现了接近 100% 的 ASR。此外，它对封闭源模型表现出很强的攻击可转移性，在 GPT-3.5 上实现了 99% 的 ASR，在 GPT-4 上实现了 49% 的 ASR，尽管仅在 Llama3 上进行了优化。除了提高越狱能力之外，ADV-LLM 还通过生成大量数据集来研究 LLM 安全性，为未来的安全对齐研究提供了有价值的见解。我们的代码可在以下位置获得：https://github.com/SunChungEn/ADV-LLM

##### **Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**
2410.18460v1 by Yifan Yang, Qiao Jin, Qingqing Zhu, Zhizheng Wang, Francisco Erramuspe Álvarez, Nicholas Wan, Benjamin Hou, Zhiyong Lu

Large Language Models (LLMs) have gained significant attention in the medical
domain for their human-level capabilities, leading to increased efforts to
explore their potential in various healthcare applications. However, despite
such a promising future, there are multiple challenges and obstacles that
remain for their real-world uses in practical settings. This work discusses key
challenges for LLMs in medical applications from four unique aspects:
operational vulnerabilities, ethical and social considerations, performance and
assessment difficulties, and legal and regulatory compliance. Addressing these
challenges is crucial for leveraging LLMs to their full potential and ensuring
their responsible integration into healthcare.

摘要：大型語言模型 (LLM) 在醫療領域中獲得了顯著的關注，因為它們具有人類等級的能力，這導致人們加大了探索它們在各種醫療保健應用中的潛力的力度。然而，儘管未來充滿希望，但它們在實際環境中的實際用途仍然存在多重挑戰和障礙。這項工作從四個獨特方面討論了 LLM 在醫療應用中的關鍵挑戰：運營漏洞、倫理和社會考量、性能和評估難題，以及法律和法規遵循。解決這些挑戰對於充分利用 LLM 的潛力並確保它們負責任地整合到醫療保健中至關重要。

##### **Verifying Non-friendly Formal Verification Designs: Can We Start Earlier?**
2410.18454v1 by Bryan Olmos, Daniel Gerl, Aman Kumar, Djones Lettnin

The design of Systems on Chips (SoCs) is becoming more and more complex due
to technological advancements. Missed bugs can cause drastic failures in
safety-critical environments leading to the endangerment of lives. To overcome
these drastic failures, formal property verification (FPV) has been applied in
the industry. However, there exist multiple hardware designs where the results
of FPV are not conclusive even for long runtimes of model-checking tools. For
this reason, the use of High-level Equivalence Checking (HLEC) tools has been
proposed in the last few years. However, the procedure for how to use it inside
an industrial toolchain has not been defined. For this reason, we proposed an
automated methodology based on metamodeling techniques which consist of two
main steps. First, an untimed algorithmic description written in C++ is
verified in an early stage using generated assertions; the advantage of this
step is that the assertions at the software level run in seconds and we can
start our analysis with conclusive results about our algorithm before starting
to write the RTL (Register Transfer Level) design. Second, this algorithmic
description is verified against its sequential design using HLEC and the
respective metamodel parameters. The results show that the presented
methodology can find bugs early related to the algorithmic description and
prepare the setup for the HLEC verification. This helps to reduce the
verification efforts to set up the tool and write the properties manually which
is always error-prone. The proposed framework can help teams working on
datapaths to verify and make decisions in an early stage of the verification
flow.

摘要：系統晶片 (SoC) 的設計由於技術進步而變得越來越複雜。遺漏的錯誤可能會導致安全關鍵環境中發生嚴重的故障，進而危及生命。為了克服這些嚴重的故障，正式屬性驗證 (FPV) 已應用於產業中。然而，存在多種硬體設計，即使模型檢查工具執行時間很長，FPV 的結果仍不具決定性。由於這個原因，在過去幾年中提出了使用高階等效性檢查 (HLEC) 工具。然而，如何在產業工具鏈中使用它的程序尚未定義。因此，我們提出了一種基於元建模技術的自動化方法，它包含兩個主要步驟。首先，使用產生的斷言在早期階段驗證以 C++ 編寫的非定時演算法描述；此步驟的優點在於軟體層級的斷言在幾秒內執行，而且我們可以在開始撰寫 RTL（暫存器傳輸層級）設計之前，使用關於演算法的決定性結果開始我們的分析。其次，使用 HLEC 和各自的元模型參數，根據其順序設計驗證此演算法描述。結果顯示，所提出的方法可以及早找出與演算法描述相關的錯誤，並為 HLEC 驗證準備設定。這有助於減少驗證工作，以設定工具並手動撰寫屬性，而這總是容易出錯。所提出的架構可以協助處理資料路徑的團隊在驗證流程的早期階段進行驗證和決策。

##### **Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs**
2410.18451v1 by Chris Yuhao Liu, Liang Zeng, Jiacai Liu, Rui Yan, Jujie He, Chaojie Wang, Shuicheng Yan, Yang Liu, Yahui Zhou

In this report, we introduce a collection of methods to enhance reward
modeling for LLMs, focusing specifically on data-centric techniques. We propose
effective data selection and filtering strategies for curating high-quality
open-source preference datasets, culminating in the Skywork-Reward data
collection, which contains only 80K preference pairs -- significantly smaller
than existing datasets. Using this curated dataset, we developed the
Skywork-Reward model series -- Skywork-Reward-Gemma-27B and
Skywork-Reward-Llama-3.1-8B -- with the former currently holding the top
position on the RewardBench leaderboard. Notably, our techniques and datasets
have directly enhanced the performance of many top-ranked models on
RewardBench, highlighting the practical impact of our contributions in
real-world preference learning applications.

摘要：在這份報告中，我們介紹了一系列方法來增強 LLM 的獎勵建模，特別專注於以資料為中心的技術。我們提出有效的資料選擇和過濾策略，用於策劃高品質的開源偏好資料集，最終形成 Skywork-Reward 資料收集，其中僅包含 80K 個偏好對，遠小於現有資料集。使用這個經過策劃的資料集，我們開發了 Skywork-Reward 模型系列，包括 Skywork-Reward-Gemma-27B 和 Skywork-Reward-Llama-3.1-8B，前者目前在 RewardBench 排行榜上名列前茅。值得注意的是，我們的技術和資料集直接提升了 RewardBench 上許多排名靠前的模型的效能，突顯了我們的貢獻在實際偏好學習應用中的實際影響。

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

摘要：監督微調 (SFT) 是增強大型語言模型 (LLM) 工具呼叫功能的常見方法，訓練資料通常是合成資料。目前的資料合成流程通常涉及抽樣一組工具、根據這些工具制定需求，並產生呼叫陳述。然而，隨機抽樣的工具缺乏關聯性，使得它們難以組合，從而降低資料的多樣性。此外，目前的工作忽略了對話回合之間的連貫性，導致合成資料與現實世界場景之間存在差距。為了解決這些問題，我們提出了一個基於圖形的抽樣策略來抽取更多相關的工具組合，以及一個計畫生成策略來建立計畫，以引導連貫對話的合成。我們整合這兩種策略，並使多個代理能夠互動地合成對話資料，從而產生我們的工具呼叫資料合成管線 ToolFlow。資料品質評估證明了我們合成對話的自然性和連貫性有了改進。最後，我們使用 ToolFlow 生成的 8,000 個合成對話在 LLaMA-3.1-8B 上應用 SFT。結果表明，該模型實現了與 GPT-4 相當甚至超越 GPT-4 的工具呼叫效能，同時保持強大的通用能力。

##### **Evaluating and Improving Automatic Speech Recognition Systems for Korean Meteorological Experts**
2410.18444v1 by ChaeHun Park, Hojun Cho, Jaegul Choo

This paper explores integrating Automatic Speech Recognition (ASR) into
natural language query systems to improve weather forecasting efficiency for
Korean meteorologists. We address challenges in developing ASR systems for the
Korean weather domain, specifically specialized vocabulary and Korean
linguistic intricacies. To tackle these issues, we constructed an evaluation
dataset of spoken queries recorded by native Korean speakers. Using this
dataset, we assessed various configurations of a multilingual ASR model family,
identifying performance limitations related to domain-specific terminology. We
then implemented a simple text-to-speech-based data augmentation method, which
improved the recognition of specialized terms while maintaining general-domain
performance. Our contributions include creating a domain-specific dataset,
comprehensive ASR model evaluations, and an effective augmentation technique.
We believe our work provides a foundation for future advancements in ASR for
the Korean weather forecasting domain.

摘要：本文探討將自動語音辨識 (ASR) 整合至自然語言查詢系統，以提升韓國氣象學家的天氣預測效率。我們探討了在韓國天氣領域開發 ASR 系統時面臨的挑戰，特別是專業術語和韓語的語言複雜性。為了解決這些問題，我們建立了一個由韓國母語人士錄製的口說查詢評估資料集。使用此資料集，我們評估了多語言 ASR 模型系列的各種配置，找出與特定領域術語相關的效能限制。然後我們實作了一個簡單的文字轉語音資料擴充方法，在維持一般領域效能的同時，提升了專業術語的辨識率。我們的貢獻包括建立一個特定領域的資料集、全面的 ASR 模型評估，以及一種有效的擴充技術。我們相信我們的研究成果為韓國天氣預測領域的 ASR 未來進展奠定了基礎。

##### **The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI**
2410.18441v1 by Fulu Li

In this paper, we give an in-depth analysis on the mathematical problem
formulations and the probabilistic optimization explorations for some of the
key components in Transformer model [33] in the field of generative AI. We
explore and discuss some potential further enhancement for current state of the
art methods for some key underlying technologies of generative AI models from
algorithmic and probabilistic optimization perspective. In particular, we
present an optimal solution for sub-word encoding (SWE) based on similar
initial settings as that of byte-pair encoding (BPE) algorithm in [9] with
similar objectives as that of WordPiece approach in [28, 31] to maximize the
likelihood of the training data. We also present cross entropy optimization
method to optimize hyperparameters for word2vec model [17]. In addition, we
propose a factored combination of rotary positional encoding (RoPE) [32] and
attention with linear biases (ALiBi) [23] with a harmonic series. We also
present a probabilistic FlashAttention [6, 7] (PrFlashAttention) method with a
probability distribution over block distances in the matrix to decide which
block is likely to participate in a given round of attention computation while
maintaining the lower triangle shape of the tensor for autoregressive language
models by re-shaping the tensors. Finally, we present staircase adaptive
quantization (SAQ) of key-value (KV) cache for multi-query attention (MQA)
based on the framework presented in [16] to have gradual quantization
degradation while achieving reasonable model quality and cost savings.

摘要：在本文中，我們對生成式 AI 領域中 Transformer 模型 [33] 的一些關鍵組成部分的數學問題表述和機率最佳化探索進行深入分析。我們探討並討論了從演算法和機率最佳化的角度，針對生成式 AI 模型的一些關鍵基礎技術的現有技術進一步增強的潛力。特別是，我們針對子詞編碼 (SWE) 提出一個最佳解，其基於與 [9] 中的位元組對編碼 (BPE) 演算法類似的初始設定，並具有與 [28, 31] 中的 WordPiece 方法類似的目標，以最大化訓練資料的可能性。我們也提出交叉熵最佳化方法，用於最佳化 word2vec 模型 [17] 的超參數。此外，我們提出旋轉位置編碼 (RoPE) [32] 和帶有線性偏差的注意力 (ALiBi) [23] 的分解組合，並搭配諧波級數。我們也提出一個機率 FlashAttention [6, 7] (PrFlashAttention) 方法，其中矩陣中的區塊距離具有機率分佈，用於決定哪個區塊可能參與特定回合的注意力運算，同時透過重新調整張量形狀，維持自迴歸語言模型的張量下三角形狀。最後，我們針對多重查詢注意力 (MQA) 的鍵值 (KV) 快取提出階梯式自適應量化 (SAQ)，其基於 [16] 中提出的架構，以在達成合理的模型品質和成本節省的同時，逐步量化劣化。

##### **Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching**
2410.18436v1 by Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo, Dongha Lee

Code-switching (CS), a phenomenon where multilingual speakers alternate
between languages in a discourse, can convey subtle cultural and linguistic
nuances that can be otherwise lost in translation. Recent state-of-the-art
multilingual large language models (LLMs) demonstrate excellent multilingual
abilities in various aspects including understanding CS, but the power of CS in
eliciting language-specific knowledge is yet to be discovered. Therefore, we
investigate the effectiveness of code-switching on a wide range of multilingual
LLMs in terms of knowledge activation, or the act of identifying and leveraging
knowledge for reasoning. To facilitate the research, we first present EnKoQA, a
synthetic English-Korean CS question-answering dataset. We provide a
comprehensive analysis on a variety of multilingual LLMs by subdividing
activation process into knowledge identification and knowledge leveraging. Our
experiments demonstrate that compared to English text, CS can faithfully
activate knowledge inside LLMs, especially on language-specific domains. In
addition, the performance gap between CS and English is larger in models that
show excellent monolingual abilities, suggesting that there exists a
correlation with CS and Korean proficiency.

摘要：代碼轉換 (CS) 是一種多語使用者在對話中交替使用不同語言的現象，它可以傳達微妙的文化和語言差異，而這些差異在翻譯中可能會遺失。最近最先進的多語大型語言模型 (LLM) 在各種方面展現出卓越的多語能力，包括理解 CS，但 CS 在引發特定語言知識方面的能力尚未被發現。因此，我們研究了代碼轉換在廣泛的多語 LLM 上的有效性，以了解知識啟動，或識別和利用知識進行推理的行為。為了促進研究，我們首先提出了 EnKoQA，這是一個合成英語-韓語 CS 問答資料集。我們通過將啟動過程細分為知識識別和知識利用，對各種多語 LLM 進行了全面分析。我們的實驗表明，與英文文本相比，CS 可以忠實地啟動 LLM 內部的知識，尤其是在特定語言領域。此外，在表現出出色單語能力的模型中，CS 和英文之間的性能差距更大，這表明 CS 和韓語能力之間存在相關性。

##### **Building Dialogue Understanding Models for Low-resource Language Indonesian from Scratch**
2410.18430v1 by Donglin Di, Weinan Zhang, Yue Zhang, Fanglin Wang

Making use of off-the-shelf resources of resource-rich languages to transfer
knowledge for low-resource languages raises much attention recently. The
requirements of enabling the model to reach the reliable performance lack well
guided, such as the scale of required annotated data or the effective
framework. To investigate the first question, we empirically investigate the
cost-effectiveness of several methods to train the intent classification and
slot-filling models for Indonesia (ID) from scratch by utilizing the English
data. Confronting the second challenge, we propose a Bi-Confidence-Frequency
Cross-Lingual transfer framework (BiCF), composed by ``BiCF Mixing'', ``Latent
Space Refinement'' and ``Joint Decoder'', respectively, to tackle the obstacle
of lacking low-resource language dialogue data. Extensive experiments
demonstrate our framework performs reliably and cost-efficiently on different
scales of manually annotated Indonesian data. We release a large-scale
fine-labeled dialogue dataset (ID-WOZ) and ID-BERT of Indonesian for further
research.

摘要：最近利用資源豐富語言的現成資源，將知識轉移到資源較少的語言，備受關注。模型達到可靠效能的要求缺乏明確的指引，例如所需的標註資料規模或有效的架構。為了探討第一個問題，我們實證研究了從頭訓練印尼語 (ID) 的意圖分類和槽位填補模型的幾種方法的成本效益，方法是利用英語資料。為了應對第二個挑戰，我們提出了雙置信度頻率跨語言轉移架構 (BiCF)，分別由「BiCF 混合」、「潛在空間精煉」和「聯合解碼器」組成，以解決缺乏低資源語言對話資料的障礙。廣泛的實驗證明，我們的架構在不同規模的手動標註印尼語資料上表現出可靠且具有成本效益。我們發布了一個大型的精細標註對話資料集 (ID-WOZ) 和印尼語的 ID-BERT，以供進一步研究。

##### **Large Language Models Reflect the Ideology of their Creators**
2410.18417v1 by Maarten Buyl, Alexander Rogiers, Sander Noels, Iris Dominguez-Catena, Edith Heiter, Raphael Romero, Iman Johary, Alexandru-Cristian Mara, Jefrey Lijffijt, Tijl De Bie

Large language models (LLMs) are trained on vast amounts of data to generate
natural language, enabling them to perform tasks like text summarization and
question answering. These models have become popular in artificial intelligence
(AI) assistants like ChatGPT and already play an influential role in how humans
access information. However, the behavior of LLMs varies depending on their
design, training, and use.
  In this paper, we uncover notable diversity in the ideological stance
exhibited across different LLMs and languages in which they are accessed. We do
this by prompting a diverse panel of popular LLMs to describe a large number of
prominent and controversial personalities from recent world history, both in
English and in Chinese. By identifying and analyzing moral assessments
reflected in the generated descriptions, we find consistent normative
differences between how the same LLM responds in Chinese compared to English.
Similarly, we identify normative disagreements between Western and non-Western
LLMs about prominent actors in geopolitical conflicts. Furthermore, popularly
hypothesized disparities in political goals among Western models are reflected
in significant normative differences related to inclusion, social inequality,
and political scandals.
  Our results show that the ideological stance of an LLM often reflects the
worldview of its creators. This raises important concerns around technological
and regulatory efforts with the stated aim of making LLMs ideologically
`unbiased', and it poses risks for political instrumentalization.

摘要：大型語言模型（LLM）在大量的資料上訓練以產生自然語言，讓它們能夠執行摘要文字和回答問題等任務。這些模型在人工智慧（AI）助理中變得流行，例如 ChatGPT，並且已經在人類如何獲取資訊方面發揮了影響力。然而，LLM 的行為會隨著其設計、訓練和使用而有所不同。
在本文中，我們揭示了在不同的 LLM 和它們被訪問的語言中表現出的意識形態立場的顯著差異。我們這樣做是透過提示一組不同的流行 LLM 來描述許多來自近期世界歷史的傑出且有爭議的人物，無論是用英語還是中文。透過識別和分析產生描述中反映的道德評估，我們發現同一個 LLM 在中文和英文中的回應之間存在一致的規範差異。同樣地，我們發現西方和非西方 LLM 在地緣政治衝突中的傑出行為者之間存在規範分歧。此外，西方模型中普遍假設的政治目標差異反映在與包容性、社會不平等和政治醜聞相關的顯著規範差異中。
我們的結果表明，LLM 的意識形態立場通常反映其創造者的世界觀。這引發了圍繞技術和監管努力的重要疑慮，其既定的目標是讓 LLM 在意識形態上「公正」，並且對政治工具化構成風險。

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

摘要：知識圖譜 (KG) 由於其結構化的知識表示，可用作問答 (QA) 的可靠知識來源。現有關於利用 KG 的大型語言模型 (LLM) 的研究普遍依賴於子圖檢索器或反覆提示，忽視了 LLM 的逐步推理能力和 KG 的結構特性的潛在協同作用。在本文中，我們提出了 DoG（圖形解碼），一個促進 LLM 和 KG 之間深度協同作用的新框架。我們首先定義了一個概念，即良好形成的鏈，它由 KG 上一系列相互關聯的事實三元組組成，從問題實體開始並導致答案。我們認為這個概念可以作為對 KGQA 進行忠實和合理的推理的原則。為了使 LLM 能夠生成良好的鏈，我們提出了圖感知約束解碼，其中源自 KG 拓撲的約束約束了 LLM 的解碼過程。這種受約束的解碼方法確保了良好形成的鏈的生成，同時充分利用了 LLM 的逐步推理能力。基於上述，DoG 是一種無需訓練的方法，能夠提供基於 KG 的忠實且合理的推理軌跡。在具有不同背景 KG 的各種 KGQA 任務中的實驗表明，DoG 達到了卓越且穩健的性能。DoG 還顯示了與各種開源 LLM 的通用適用性。

##### **MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases**
2410.18406v1 by Zhisheng Lin, Yifu Liu, Zhiling Luo, Jinyang Gao, Yu Li

The improvement in translating natural language to structured query language
(SQL) can be attributed to the advancements in large language models (LLMs).
Open-source LLMs, tailored for specific database dialects such as MySQL, have
shown great performance. However, cloud service providers are looking for a
unified database manager service (e.g., Cosmos DB from Azure, Amazon Aurora
from AWS, Lindorm from AlibabaCloud) that can support multiple dialects. This
requirement has led to the concept of multi-dialect query generation, which
presents challenges to LLMs. These challenges include syntactic differences
among dialects and imbalanced data distribution across multiple dialects. To
tackle these challenges, we propose MoMQ, a novel Mixture-of-Experts-based
multi-dialect query generation framework across both relational and
non-relational databases. MoMQ employs a dialect expert group for each dialect
and a multi-level routing strategy to handle dialect-specific knowledge,
reducing interference during query generation. Additionally, a shared expert
group is introduced to address data imbalance, facilitating the transfer of
common knowledge from high-resource dialects to low-resource ones. Furthermore,
we have developed a high-quality multi-dialect query generation benchmark that
covers relational and non-relational databases such as MySQL, PostgreSQL,
Cypher for Neo4j, and nGQL for NebulaGraph. Extensive experiments have shown
that MoMQ performs effectively and robustly even in resource-imbalanced
scenarios.

摘要：自然語言翻譯成結構化查詢語言 (SQL) 的改進，可歸功於大型語言模型 (LLM) 的進步。針對特定資料庫方言（例如 MySQL）量身打造的開源 LLM 已展現出極佳的效能。然而，雲端服務供應商正在尋找統一的資料庫管理服務（例如 Azure 的 Cosmos DB、AWS 的 Amazon Aurora、AlibabaCloud 的 Lindorm），以支援多種方言。此項需求催生了多方言查詢產生的概念，這對 LLM 而言是一項挑戰。這些挑戰包括方言之間的語法差異，以及跨多個方言的不平衡資料分佈。為了應對這些挑戰，我們提出 MoMQ，一個基於 Mixture-of-Experts 的多方言查詢產生架構，橫跨關聯式和非關聯式資料庫。MoMQ 為每個方言採用方言專家群組和多層級路由策略，以處理方言特定的知識，減少查詢產生期間的干擾。此外，引入共享專家群組來解決資料不平衡問題，促進將常見知識從高資源方言轉移到低資源方言。此外，我們開發了一個高品質的多方言查詢產生基準，涵蓋關聯式和非關聯式資料庫，例如 MySQL、PostgreSQL、Neo4j 的 Cypher 和 NebulaGraph 的 nGQL。廣泛的實驗顯示，即使在資源不平衡的場景中，MoMQ 仍能有效且穩健地執行。

##### **SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness**
2410.18393v1 by Tanmay Parekh, Jeffrey Kwan, Jiarui Yu, Sparsh Johri, Hyosang Ahn, Sreya Muppalla, Kai-Wei Chang, Wei Wang, Nanyun Peng

Social media is often the first place where communities discuss the latest
societal trends. Prior works have utilized this platform to extract
epidemic-related information (e.g. infections, preventive measures) to provide
early warnings for epidemic prediction. However, these works only focused on
English posts, while epidemics can occur anywhere in the world, and early
discussions are often in the local, non-English languages. In this work, we
introduce the first multilingual Event Extraction (EE) framework SPEED++ for
extracting epidemic event information for a wide range of diseases and
languages. To this end, we extend a previous epidemic ontology with 20 argument
roles; and curate our multilingual EE dataset SPEED++ comprising 5.1K tweets in
four languages for four diseases. Annotating data in every language is
infeasible; thus we develop zero-shot cross-lingual cross-disease models (i.e.,
training only on English COVID data) utilizing multilingual pre-training and
show their efficacy in extracting epidemic-related events for 65 diverse
languages across different diseases. Experiments demonstrate that our framework
can provide epidemic warnings for COVID-19 in its earliest stages in Dec 2019
(3 weeks before global discussions) from Chinese Weibo posts without any
training in Chinese. Furthermore, we exploit our framework's argument
extraction capabilities to aggregate community epidemic discussions like
symptoms and cure measures, aiding misinformation detection and public
attention monitoring. Overall, we lay a strong foundation for multilingual
epidemic preparedness.

摘要：<paragraph>社群媒體通常是社群討論最新社會趨勢的第一個地方。先前的研究利用此平台提取與流行病相關的資訊（例如感染、預防措施），以提供流行病預測的早期預警。然而，這些研究僅關注英文貼文，而流行病可能發生在世界任何地方，而且早期討論通常使用當地非英文語言。在這項研究中，我們介紹了第一個多語言事件萃取 (EE) 架構 SPEED++，用於萃取各種疾病和語言的流行病事件資訊。為此，我們將先前的流行病本體擴充為 20 個論證角色；並策劃我們的多語言 EE 資料集 SPEED++，其中包含四種語言中四種疾病的 5.1K 則推文。以每種語言註解資料是不可行的；因此，我們開發了零次學習跨語言跨疾病模型（即僅針對英文 COVID 資料進行訓練），利用多語言預訓練，並展示了它們在為 65 種不同疾病的不同語言中萃取與流行病相關事件的功效。實驗證明，我們的架構可以在 2019 年 12 月（全球討論前 3 週）的早期階段，從沒有接受過中文訓練的中文微博貼文中提供 COVID-19 的流行病警告。此外，我們利用架構的論證萃取功能來彙整社群流行病討論，例如症狀和治療措施，協助錯誤資訊偵測和公眾關注監控。總而言之，我們為多語言流行病防範奠定了堅實的基礎。</paragraph>

