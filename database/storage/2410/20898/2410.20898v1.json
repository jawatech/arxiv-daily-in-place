{"2410.20898": {"publish_time": "2024-10-28", "title": "Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models", "paper_summary": "In this paper, we introduce the Diff-Instruct*(DI*), a data-free approach for\nbuilding one-step text-to-image generative models that align with human\npreference while maintaining the ability to generate highly realistic images.\nWe frame human preference alignment as online reinforcement learning using\nhuman feedback (RLHF), where the goal is to maximize the reward function while\nregularizing the generator distribution to remain close to a reference\ndiffusion process. Unlike traditional RLHF approaches, which rely on the KL\ndivergence for regularization, we introduce a novel score-based divergence\nregularization, which leads to significantly better performances. Although the\ndirect calculation of this divergence remains intractable, we demonstrate that\nwe can efficiently compute its \\emph{gradient} by deriving an equivalent yet\ntractable loss function. Remarkably, with Stable Diffusion V1.5 as the\nreference diffusion model, DI* outperforms \\emph{all} previously leading models\nby a large margin. When using the 0.6B PixelArt-$\\alpha$ model as the reference\ndiffusion, DI* achieves a new record Aesthetic Score of 6.30 and an Image\nReward of 1.31 with only a single generation step, almost doubling the scores\nof the rest of the models with similar sizes. It also achieves an HPSv2 score\nof 28.70, establishing a new state-of-the-art benchmark. We also observe that\nDI* can improve the layout and enrich the colors of generated images.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 Diff-Instruct*(DI*)\uff0c\u9019\u662f\u4e00\u7a2e\u7121\u6578\u64da\u65b9\u6cd5\uff0c\u7528\u65bc\u69cb\u5efa\u8207\u4eba\u985e\u504f\u597d\u76f8\u7b26\u7684\u4e00\u6b65\u5f0f\u6587\u672c\u5230\u5716\u50cf\u751f\u6210\u6a21\u578b\uff0c\u540c\u6642\u4fdd\u6301\u751f\u6210\u9ad8\u5ea6\u903c\u771f\u5716\u50cf\u7684\u80fd\u529b\u3002\n\u6211\u5011\u5c07\u4eba\u985e\u504f\u597d\u5c0d\u9f4a\u69cb\u5efa\u70ba\u4f7f\u7528\u4eba\u985e\u56de\u994b\u7684\u7dda\u4e0a\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff0c\u76ee\u6a19\u662f\u6700\u5927\u5316\u734e\u52f5\u51fd\u6578\uff0c\u540c\u6642\u898f\u7bc4\u751f\u6210\u5668\u5206\u4f48\u4ee5\u4fdd\u6301\u63a5\u8fd1\u53c3\u8003\u64f4\u6563\u904e\u7a0b\u3002\u8207\u4f9d\u8cf4 KL \u6563\u5ea6\u9032\u884c\u898f\u7bc4\u5316\u7684\u50b3\u7d71 RLHF \u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u57fa\u65bc\u5206\u6578\u7684\u6563\u5ea6\u898f\u7bc4\u5316\uff0c\u9019\u5c0e\u81f4\u4e86\u986f\u8457\u66f4\u597d\u7684\u8868\u73fe\u3002\u5118\u7ba1\u9019\u7a2e\u6563\u5ea6\u7684\u76f4\u63a5\u8a08\u7b97\u4ecd\u7136\u96e3\u4ee5\u8655\u7406\uff0c\u4f46\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u53ef\u4ee5\u901a\u904e\u63a8\u5c0e\u4e00\u500b\u7b49\u6548\u4f46\u6613\u65bc\u8655\u7406\u7684\u640d\u5931\u51fd\u6578\u4f86\u6709\u6548\u5730\u8a08\u7b97\u5176\\emph{\u68af\u5ea6}\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4ee5 Stable Diffusion V1.5 \u4f5c\u70ba\u53c3\u8003\u64f4\u6563\u6a21\u578b\uff0cDI* \u4ee5\u5f88\u5927\u5e45\u5ea6\u512a\u65bc\\emph{\u6240\u6709}\u5148\u524d\u9818\u5148\u7684\u6a21\u578b\u3002\u7576\u4f7f\u7528 0.6B PixelArt-$\\alpha$ \u6a21\u578b\u4f5c\u70ba\u53c3\u8003\u64f4\u6563\u6642\uff0cDI* \u50c5\u901a\u904e\u55ae\u4e00\u751f\u6210\u6b65\u9a5f\u5c31\u9054\u5230\u4e86 6.30 \u7684\u7f8e\u5b78\u5206\u6578\u548c 1.31 \u7684\u5716\u50cf\u734e\u52f5\u7684\u65b0\u7d00\u9304\uff0c\u5e7e\u4e4e\u662f\u985e\u4f3c\u5927\u5c0f\u7684\u5176\u9918\u6a21\u578b\u5206\u6578\u7684\u5169\u500d\u3002\u5b83\u9084\u9054\u5230\u4e86 28.70 \u7684 HPSv2 \u5206\u6578\uff0c\u6a39\u7acb\u4e86\u65b0\u7684\u6700\u5148\u9032\u57fa\u6e96\u3002\u6211\u5011\u9084\u89c0\u5bdf\u5230\uff0cDI* \u53ef\u4ee5\u6539\u5584\u751f\u6210\u7684\u5716\u50cf\u7684\u4f48\u5c40\u4e26\u8c50\u5bcc\u5176\u8272\u5f69\u3002</paragraph>", "author": "Weijian Luo et.al.", "authors": "Weijian Luo, Colin Zhang, Debing Zhang, Zhengyang Geng", "id": "2410.20898v1", "paper_url": "http://arxiv.org/abs/2410.20898v1", "repo": "null"}}