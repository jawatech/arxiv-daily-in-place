{"2406.11682": {"publish_time": "2024-06-17", "title": "Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack", "paper_summary": "Large language models (LLMs) have been increasingly applied to various\ndomains, which triggers increasing concerns about LLMs' safety on specialized\ndomains, e.g. medicine. However, testing the domain-specific safety of LLMs is\nchallenging due to the lack of domain knowledge-driven attacks in existing\nbenchmarks. To bridge this gap, we propose a new task, knowledge-to-jailbreak,\nwhich aims to generate jailbreaks from domain knowledge to evaluate the safety\nof LLMs when applied to those domains. We collect a large-scale dataset with\n12,974 knowledge-jailbreak pairs and fine-tune a large language model as\njailbreak-generator, to produce domain knowledge-specific jailbreaks.\nExperiments on 13 domains and 8 target LLMs demonstrate the effectiveness of\njailbreak-generator in generating jailbreaks that are both relevant to the\ngiven knowledge and harmful to the target LLMs. We also apply our method to an\nout-of-domain knowledge base, showing that jailbreak-generator can generate\njailbreaks that are comparable in harmfulness to those crafted by human\nexperts. Data and code: https://github.com/THU-KEG/Knowledge-to-Jailbreak/.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5df2\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u5404\u79cd\u9886\u57df\uff0c\u8fd9\u5f15\u53d1\u4e86\u4eba\u4eec\u5bf9 LLM \u5728\u4e13\u4e1a\u9886\u57df\uff08\u4f8b\u5982\u533b\u5b66\uff09\u4e0a\u7684\u5b89\u5168\u6027\u65e5\u76ca\u62c5\u5fe7\u3002\u7136\u800c\uff0c\u7531\u4e8e\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u9a71\u52a8\u7684\u653b\u51fb\uff0c\u56e0\u6b64\u6d4b\u8bd5 LLM \u7684\u7279\u5b9a\u9886\u57df\u5b89\u5168\u6027\u5177\u6709\u6311\u6218\u6027\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u4efb\u52a1\uff0c\u5373\u77e5\u8bc6\u5230\u8d8a\u72f1\uff0c\u5176\u76ee\u7684\u662f\u4ece\u9886\u57df\u77e5\u8bc6\u4e2d\u751f\u6210\u8d8a\u72f1\uff0c\u4ee5\u8bc4\u4f30 LLM \u5e94\u7528\u4e8e\u8fd9\u4e9b\u9886\u57df\u65f6\u7684\u5b89\u5168\u6027\u3002\u6211\u4eec\u6536\u96c6\u4e86\u4e00\u4e2a\u5305\u542b 12,974 \u4e2a\u77e5\u8bc6\u8d8a\u72f1\u5bf9\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5e76\u5fae\u8c03\u4e86\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8d8a\u72f1\u751f\u6210\u5668\uff0c\u4ee5\u4ea7\u751f\u7279\u5b9a\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u8d8a\u72f1\u3002\u5728 13 \u4e2a\u9886\u57df\u548c 8 \u4e2a\u76ee\u6807 LLM \u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u4e86\u8d8a\u72f1\u751f\u6210\u5668\u5728\u751f\u6210\u4e0e\u7ed9\u5b9a\u77e5\u8bc6\u76f8\u5173\u4e14\u5bf9\u76ee\u6807 LLM \u6709\u5bb3\u7684\u8d8a\u72f1\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u8fd8\u5c06\u6211\u4eec\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u57df\u5916\u77e5\u8bc6\u5e93\uff0c\u8868\u660e\u8d8a\u72f1\u751f\u6210\u5668\u53ef\u4ee5\u751f\u6210\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5236\u4f5c\u7684\u8d8a\u72f1\u5728\u5371\u5bb3\u6027\u65b9\u9762\u76f8\u5f53\u7684\u8d8a\u72f1\u3002\u6570\u636e\u548c\u4ee3\u7801\uff1ahttps://github.com/THU-KEG/Knowledge-to-Jailbreak/\u3002", "author": "Shangqing Tu et.al.", "authors": "Shangqing Tu, Zhuoran Pan, Wenxuan Wang, Zhexin Zhang, Yuliang Sun, Jifan Yu, Hongning Wang, Lei Hou, Juanzi Li", "id": "2406.11682v1", "paper_url": "http://arxiv.org/abs/2406.11682v1", "repo": "https://github.com/thu-keg/knowledge-to-jailbreak"}}