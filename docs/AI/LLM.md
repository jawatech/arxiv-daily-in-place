
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-26**|**Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**|Yuexi Du et.al.|[2409.18119v1](http://arxiv.org/abs/2409.18119v1)|null|
|**2024-09-26**|**Open-World Evaluation for Retrieving Diverse Perspectives**|Hung-Ting Chen et.al.|[2409.18110v1](http://arxiv.org/abs/2409.18110v1)|null|
|**2024-09-26**|**Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats**|Lucia Gordon et.al.|[2409.18104v1](http://arxiv.org/abs/2409.18104v1)|[link](https://github.com/lgordon99/rhino-midden-detector)|
|**2024-09-26**|**AI-Powered Augmented Reality for Satellite Assembly, Integration and Test**|Alvaro Patricio et.al.|[2409.18101v1](http://arxiv.org/abs/2409.18101v1)|null|
|**2024-09-26**|**EfficientCrackNet: A Lightweight Model for Crack Segmentation**|Abid Hasan Zim et.al.|[2409.18099v1](http://arxiv.org/abs/2409.18099v1)|null|
|**2024-09-26**|**DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models**|Helin Cao et.al.|[2409.18092v1](http://arxiv.org/abs/2409.18092v1)|null|
|**2024-09-26**|**GSON: A Group-based Social Navigation Framework with Large Multimodal Model**|Shangyi Luo et.al.|[2409.18084v1](http://arxiv.org/abs/2409.18084v1)|null|
|**2024-09-26**|**SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language Models for Robotic Garment Manipulation**|Xin Li et.al.|[2409.18082v1](http://arxiv.org/abs/2409.18082v1)|null|
|**2024-09-26**|**Infer Human's Intentions Before Following Natural Language Instructions**|Yanming Wan et.al.|[2409.18073v1](http://arxiv.org/abs/2409.18073v1)|null|
|**2024-09-26**|**FreeEdit: Mask-free Reference-based Image Editing with Multi-modal Instruction**|Runze He et.al.|[2409.18071v1](http://arxiv.org/abs/2409.18071v1)|null|
|**2024-09-26**|**Visual Data Diagnosis and Debiasing with Concept Graphs**|Rwiddhi Chakraborty et.al.|[2409.18055v1](http://arxiv.org/abs/2409.18055v1)|null|
|**2024-09-26**|**DualAD: Dual-Layer Planning for Reasoning in Autonomous Driving**|Dingrui Wang et.al.|[2409.18053v1](http://arxiv.org/abs/2409.18053v1)|null|
|**2024-09-26**|**HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams**|Sanjay Oruganti et.al.|[2409.18047v1](http://arxiv.org/abs/2409.18047v1)|null|
|**2024-09-26**|**Unveiling the Role of Pretraining in Direct Speech Translation**|Belen Alastruey et.al.|[2409.18044v1](http://arxiv.org/abs/2409.18044v1)|null|
|**2024-09-26**|**EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions**|Kai Chen et.al.|[2409.18042v1](http://arxiv.org/abs/2409.18042v1)|null|
|**2024-09-26**|**Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective**|Yotam Wolf et.al.|[2409.18028v1](http://arxiv.org/abs/2409.18028v1)|null|
|**2024-09-26**|**An Adversarial Perspective on Machine Unlearning for AI Safety**|Jakub Łucki et.al.|[2409.18025v1](http://arxiv.org/abs/2409.18025v1)|null|
|**2024-09-26**|**DARE: Diverse Visual Question Answering with Robustness Evaluation**|Hannah Sterz et.al.|[2409.18023v1](http://arxiv.org/abs/2409.18023v1)|null|
|**2024-09-26**|**Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles**|Lewei He et.al.|[2409.18014v1](http://arxiv.org/abs/2409.18014v1)|null|
|**2024-09-26**|**Control Industrial Automation System with Large Language Models**|Yuchen Xia et.al.|[2409.18009v1](http://arxiv.org/abs/2409.18009v1)|[link](https://github.com/yuchenxia/llm4ias)|
|**2024-09-26**|**Multilingual Evaluation of Long Context Retrieval and Reasoning**|Ameeta Agrawal et.al.|[2409.18006v1](http://arxiv.org/abs/2409.18006v1)|null|
|**2024-09-26**|**Joint Localization and Planning using Diffusion**|L. Lao Beyer et.al.|[2409.17995v1](http://arxiv.org/abs/2409.17995v1)|null|
|**2024-09-26**|**CRoP: Context-wise Robust Static Human-Sensing Personalization**|Sawinder Kaur et.al.|[2409.17994v1](http://arxiv.org/abs/2409.17994v1)|null|
|**2024-09-26**|**Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models**|Georg Ahnert et.al.|[2409.17990v1](http://arxiv.org/abs/2409.17990v1)|[link](https://github.com/dess-mannheim/temporal-adapters)|
|**2024-09-26**|**HydraViT: Stacking Heads for a Scalable ViT**|Janek Haberer et.al.|[2409.17978v1](http://arxiv.org/abs/2409.17978v1)|null|
|**2024-09-26**|**BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search**|Linzhuang Sun et.al.|[2409.17972v1](http://arxiv.org/abs/2409.17972v1)|null|
|**2024-09-26**|**The Hard Positive Truth about Vision-Language Compositionality**|Amita Kamath et.al.|[2409.17958v1](http://arxiv.org/abs/2409.17958v1)|null|
|**2024-09-26**|**Enhancing elusive clues in knowledge learning by contrasting attention of language models**|Jian Gao et.al.|[2409.17954v1](http://arxiv.org/abs/2409.17954v1)|null|
|**2024-09-26**|**Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation**|Shuai Zhao et.al.|[2409.17946v1](http://arxiv.org/abs/2409.17946v1)|null|
|**2024-09-26**|**On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms**|Richard Yue et.al.|[2409.17943v1](http://arxiv.org/abs/2409.17943v1)|null|
|**2024-09-26**|**Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods**|Richard Yue et.al.|[2409.17939v1](http://arxiv.org/abs/2409.17939v1)|null|
|**2024-09-26**|**Intelligent Energy Management: Remaining Useful Life Prediction and Charging Automation System Comprised of Deep Learning and the Internet of Things**|Biplov Paneru et.al.|[2409.17931v1](http://arxiv.org/abs/2409.17931v1)|null|
|**2024-09-26**|**The Lou Dataset -- Exploring the Impact of Gender-Fair Language in German Text Classification**|Andreas Waldis et.al.|[2409.17929v1](http://arxiv.org/abs/2409.17929v1)|null|
|**2024-09-26**|**Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion**|Hengrui Gu et.al.|[2409.17928v1](http://arxiv.org/abs/2409.17928v1)|null|
|**2024-09-26**|**Navigation in a simplified Urban Flow through Deep Reinforcement Learning**|Federica Tonti et.al.|[2409.17922v1](http://arxiv.org/abs/2409.17922v1)|null|
|**2024-09-26**|**Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect**|Guokan Shang et.al.|[2409.17912v1](http://arxiv.org/abs/2409.17912v1)|null|
|**2024-09-26**|**Learning to Love Edge Cases in Formative Math Assessment: Using the AMMORE Dataset and Chain-of-Thought Prompting to Improve Grading Accuracy**|Owen Henkel et.al.|[2409.17904v1](http://arxiv.org/abs/2409.17904v1)|null|
|**2024-09-26**|**Revisiting Acoustic Similarity in Emotional Speech and Music via Self-Supervised Representations**|Yujia Sun et.al.|[2409.17899v1](http://arxiv.org/abs/2409.17899v1)|null|
|**2024-09-26**|**EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models**|Shaoxiong Ji et.al.|[2409.17892v1](http://arxiv.org/abs/2409.17892v1)|null|
|**2024-09-26**|**Why Companies "Democratise" Artificial Intelligence: The Case of Open Source Software Donations**|Cailean Osborne et.al.|[2409.17876v1](http://arxiv.org/abs/2409.17876v1)|null|
|**2024-09-26**|**DarkSAM: Fooling Segment Anything Model to Segment Nothing**|Ziqi Zhou et.al.|[2409.17874v1](http://arxiv.org/abs/2409.17874v1)|[link](https://github.com/cgcl-codes/darksam)|
|**2024-09-26**|**Efficient Arbitrary Precision Acceleration for Large Language Models on GPU Tensor Cores**|Shaobo Ma et.al.|[2409.17870v1](http://arxiv.org/abs/2409.17870v1)|null|
|**2024-09-26**|**A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios**|Christian Ganhör et.al.|[2409.17864v1](http://arxiv.org/abs/2409.17864v1)|null|
|**2024-09-26**|**Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models**|Hui-Po Wang et.al.|[2409.17836v1](http://arxiv.org/abs/2409.17836v1)|null|
|**2024-09-26**|**PEDRO: Parameter-Efficient Fine-tuning with Prompt DEpenDent Representation MOdification**|Tianfang Xie et.al.|[2409.17834v1](http://arxiv.org/abs/2409.17834v1)|null|
|**2024-09-26**|**BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text**|Siyan Wang et.al.|[2409.17827v1](http://arxiv.org/abs/2409.17827v1)|null|
|**2024-09-26**|**Inference-Time Language Model Alignment via Integrated Value Guidance**|Zhixuan Liu et.al.|[2409.17819v1](http://arxiv.org/abs/2409.17819v1)|null|
|**2024-09-26**|**DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**|Rabindra Khadka et.al.|[2409.17815v1](http://arxiv.org/abs/2409.17815v1)|null|
|**2024-09-26**|**Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness**|Jian Li et.al.|[2409.17791v1](http://arxiv.org/abs/2409.17791v1)|[link](https://github.com/lijian16/spo)|
|**2024-09-26**|**Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations**|Supriya Manna et.al.|[2409.17774v1](http://arxiv.org/abs/2409.17774v1)|null|
|**2024-09-26**|**Federated Learning under Attack: Improving Gradient Inversion for Batch of Images**|Luiz Leite et.al.|[2409.17767v1](http://arxiv.org/abs/2409.17767v1)|null|
|**2024-09-26**|**Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**|Evangelia Christodoulou et.al.|[2409.17763v1](http://arxiv.org/abs/2409.17763v1)|null|
|**2024-09-26**|**Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation**|Qin Wang et.al.|[2409.17757v1](http://arxiv.org/abs/2409.17757v1)|null|
|**2024-09-26**|**SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning**|Rimvydas Rubavicius et.al.|[2409.17755v1](http://arxiv.org/abs/2409.17755v1)|null|
|**2024-09-26**|**Byzantine-Robust Aggregation for Securing Decentralized Federated Learning**|Diego Cajaraville-Aboy et.al.|[2409.17754v1](http://arxiv.org/abs/2409.17754v1)|null|
|**2024-09-26**|**Are Transformers in Pre-trained LM A Good ASR Encoder? An Empirical Study**|Keyu An et.al.|[2409.17750v1](http://arxiv.org/abs/2409.17750v1)|null|
|**2024-09-26**|**Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Model**|Nilanjan Sinhababu et.al.|[2409.17745v1](http://arxiv.org/abs/2409.17745v1)|null|
|**2024-09-26**|**AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking**|Shiqi Sun et.al.|[2409.17728v1](http://arxiv.org/abs/2409.17728v1)|null|
|**2024-09-26**|**Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience**|Leonard Bärmann et.al.|[2409.17702v1](http://arxiv.org/abs/2409.17702v1)|null|
|**2024-09-26**|**MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks**|Giandomenico Cornacchia et.al.|[2409.17699v1](http://arxiv.org/abs/2409.17699v1)|null|
|**2024-09-26**|**MIO: A Foundation Model on Multimodal Tokens**|Zekun Wang et.al.|[2409.17692v1](http://arxiv.org/abs/2409.17692v1)|null|
|**2024-09-26**|**Efficient Bias Mitigation Without Privileged Information**|Mateo Espinosa Zarlenga et.al.|[2409.17691v1](http://arxiv.org/abs/2409.17691v1)|null|
|**2024-09-26**|**Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**|Yasaman Haghbin et.al.|[2409.17685v1](http://arxiv.org/abs/2409.17685v1)|null|
|**2024-09-26**|**Preserving logical and functional dependencies in synthetic tabular data**|Chaithra Umesh et.al.|[2409.17684v1](http://arxiv.org/abs/2409.17684v1)|[link](https://github.com/chaithra-u/dependency_preservation)|
|**2024-09-26**|**Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**|Natthanaphop Isaradech et.al.|[2409.17683v1](http://arxiv.org/abs/2409.17683v1)|null|
|**2024-09-26**|**Cross-lingual Human-Preference Alignment for Neural Machine Translation with Direct Quality Optimization**|Kaden Uhlig et.al.|[2409.17673v1](http://arxiv.org/abs/2409.17673v1)|null|
|**2024-09-26**|**Explanation Bottleneck Models**|Shin'ya Yamaguchi et.al.|[2409.17663v1](http://arxiv.org/abs/2409.17663v1)|[link](https://github.com/yshinya6/xbm)|
|**2024-09-26**|**A Fuzzy-based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy**|Xiaowei Jiang et.al.|[2409.17661v1](http://arxiv.org/abs/2409.17661v1)|null|
|**2024-09-26**|**Prototype based Masked Audio Model for Self-Supervised Learning of Sound Event Detection**|Pengfei Cai et.al.|[2409.17656v1](http://arxiv.org/abs/2409.17656v1)|[link](https://github.com/cai525/transformer4sed)|
|**2024-09-26**|**AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment**|Nan Sun et.al.|[2409.17655v1](http://arxiv.org/abs/2409.17655v1)|null|
|**2024-09-26**|**FactorSim: Generative Simulation via Factorized Representation**|Fan-Yun Sun et.al.|[2409.17652v1](http://arxiv.org/abs/2409.17652v1)|null|
|**2024-09-26**|**Digital Twin Ecosystem for Oncology Clinical Operations**|Himanshu Pandey et.al.|[2409.17650v1](http://arxiv.org/abs/2409.17650v1)|null|
|**2024-09-26**|**Efficient In-Domain Question Answering for Resource-Constrained Environments**|Isaac Chung et.al.|[2409.17648v1](http://arxiv.org/abs/2409.17648v1)|null|
|**2024-09-26**|**AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure**|Xi Chen et.al.|[2409.17642v1](http://arxiv.org/abs/2409.17642v1)|null|
|**2024-09-26**|**T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task**|Xindi Tong et.al.|[2409.17640v1](http://arxiv.org/abs/2409.17640v1)|null|
|**2024-09-26**|**P4Q: Learning to Prompt for Quantization in Visual-language Models**|Huixin Sun et.al.|[2409.17634v1](http://arxiv.org/abs/2409.17634v1)|null|
|**2024-09-26**|**Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs**|Yusong Wang et.al.|[2409.17622v1](http://arxiv.org/abs/2409.17622v1)|null|
|**2024-09-26**|**ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue**|Zhangpu Li et.al.|[2409.17610v1](http://arxiv.org/abs/2409.17610v1)|null|
|**2024-09-26**|**Dirichlet-Based Coarse-to-Fine Example Selection For Open-Set Annotation**|Ye-Wen Wang et.al.|[2409.17607v1](http://arxiv.org/abs/2409.17607v1)|null|
|**2024-09-26**|**Deep CLAS: Deep Contextual Listen, Attend and Spell**|Shifu Xiong et.al.|[2409.17603v1](http://arxiv.org/abs/2409.17603v1)|null|
|**2024-09-26**|**Open Digital Rights Enforcement Framework (ODRE): from descriptive to enforceable policies**|Andrea Cimmino et.al.|[2409.17602v1](http://arxiv.org/abs/2409.17602v1)|null|
|**2024-09-26**|**TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning**|Yuan Xun et.al.|[2409.17601v1](http://arxiv.org/abs/2409.17601v1)|null|
|**2024-09-26**|**Subjective and Objective Quality-of-Experience Evaluation Study for Live Video Streaming**|Zehao Zhu et.al.|[2409.17596v1](http://arxiv.org/abs/2409.17596v1)|null|
|**2024-09-26**|**DualCoTs: Dual Chain-of-Thoughts Prompting for Sentiment Lexicon Expansion of Idioms**|Fuqiang Niu et.al.|[2409.17588v1](http://arxiv.org/abs/2409.17588v1)|null|
|**2024-09-26**|**Let the Quantum Creep In: Designing Quantum Neural Network Models by Gradually Swapping Out Classical Components**|Peiyong Wang et.al.|[2409.17583v1](http://arxiv.org/abs/2409.17583v1)|[link](https://github.com/peiyong-addwater/let-the-quantum-creep-in)|
|**2024-09-26**|**A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**|Syed Affan Daimi et.al.|[2409.17581v1](http://arxiv.org/abs/2409.17581v1)|null|
|**2024-09-26**|**Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**|Zahra Sepasdar et.al.|[2409.17580v1](http://arxiv.org/abs/2409.17580v1)|null|
|**2024-09-26**|**Leveraging Annotator Disagreement for Text Classification**|Jin Xu et.al.|[2409.17577v1](http://arxiv.org/abs/2409.17577v1)|null|
|**2024-09-26**|**Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**|Owen Xingjian Zhang et.al.|[2409.17572v1](http://arxiv.org/abs/2409.17572v1)|null|
|**2024-09-26**|**Showing Many Labels in Multi-label Classification Models: An Empirical Study of Adversarial Examples**|Yujiang Liu et.al.|[2409.17568v1](http://arxiv.org/abs/2409.17568v1)|null|
|**2024-09-26**|**Pixel-Space Post-Training of Latent Diffusion Models**|Christina Zhang et.al.|[2409.17565v1](http://arxiv.org/abs/2409.17565v1)|null|
|**2024-09-26**|**Modulated Intervention Preference Optimization (MIPO): Keey the Easy, Refine the Difficult**|Cheolhun Jang et.al.|[2409.17545v1](http://arxiv.org/abs/2409.17545v1)|null|
|**2024-09-26**|**Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models**|Tongxuan Liu et.al.|[2409.17539v1](http://arxiv.org/abs/2409.17539v1)|null|
|**2024-09-26**|**On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy**|Saber Malekmohammadi et.al.|[2409.17538v1](http://arxiv.org/abs/2409.17538v1)|null|
|**2024-09-26**|**MUSE: Integrating Multi-Knowledge for Knowledge Graph Completion**|Pengjie Liu et.al.|[2409.17536v1](http://arxiv.org/abs/2409.17536v1)|null|
|**2024-09-26**|**Just say what you want: only-prompting self-rewarding online preference optimization**|Ruijie Xu et.al.|[2409.17534v1](http://arxiv.org/abs/2409.17534v1)|null|
|**2024-09-26**|**SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion**|Ming Dai et.al.|[2409.17531v1](http://arxiv.org/abs/2409.17531v1)|[link](https://github.com/dmmm1997/simvg)|
|**2024-09-26**|**Data Proportion Detection for Optimized Data Management for Large Language Models**|Hao Liang et.al.|[2409.17527v1](http://arxiv.org/abs/2409.17527v1)|[link](https://github.com/yangyajie0625/data_detection)|
|**2024-09-26**|**Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Integrating SGBM and Segmentation Models**|Yida Lin et.al.|[2409.17526v1](http://arxiv.org/abs/2409.17526v1)|null|
|**2024-09-26**|**When A Man Says He Is Pregnant: ERP Evidence for A Rational Account of Speaker-contextualized Language Comprehension**|Hanlin Wu et.al.|[2409.17525v1](http://arxiv.org/abs/2409.17525v1)|null|

#### Abstracts
##### **Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**
2409.18119v1 by Yuexi Du, John Onofrey, Nicha C. Dvornek

Contrastive Language-Image Pre-training (CLIP) shows promise in medical image
analysis but requires substantial data and computational resources. Due to
these restrictions, existing CLIP applications in medical imaging focus mainly
on modalities like chest X-rays that have abundant image-report data available,
leaving many other important modalities under-explored. Here, we propose the
first adaptation of the full CLIP model to mammography, which presents
significant challenges due to labeled data scarcity, high-resolution images
with small regions of interest, and data imbalance. We first develop a
specialized supervision framework for mammography that leverages its multi-view
nature. Furthermore, we design a symmetric local alignment module to better
focus on detailed features in high-resolution images. Lastly, we incorporate a
parameter-efficient fine-tuning approach for large language models pre-trained
with medical knowledge to address data limitations. Our multi-view and
multi-scale alignment (MaMA) method outperforms state-of-the-art baselines for
three different tasks on two large real-world mammography datasets, EMBED and
RSNA-Mammo, with only 52% model size compared with the largest baseline.

摘要：對比語言影像預訓練 (CLIP) 在醫學影像分析中展現潛力，但需要大量的資料和運算資源。由於這些限制，現有的 CLIP 在醫學影像中的應用主要集中在胸部 X 光等有豐富影像報告資料的模式，導致許多其他重要的模式未被充分探索。在此，我們提出將完整的 CLIP 模型首次適應於乳房攝影，由於標籤資料稀少、高解析度影像中感興趣區域較小，以及資料不平衡，這提出了重大的挑戰。我們首先開發了一個專門的監督架構用於乳房攝影，利用其多視圖的特性。此外，我們設計了一個對稱局部對齊模組，以更好地聚焦於高解析度影像中的詳細特徵。最後，我們結合了一個參數高效的微調方法，用於預先訓練具有醫學知識的大型語言模型，以解決資料限制。我們的多視圖和多尺度對齊 (MaMA) 方法在兩個大型真實世界乳房攝影資料集 EMBED 和 RSNA-Mammo 的三個不同任務中優於現有技術基線，而模型大小僅為最大基線的 52%。

##### **Open-World Evaluation for Retrieving Diverse Perspectives**
2409.18110v1 by Hung-Ting Chen, Eunsol Choi

We study retrieving a set of documents that covers various perspectives on a
complex and contentious question (e.g., will ChatGPT do more harm than good?).
We curate a Benchmark for Retrieval Diversity for Subjective questions (BERDS),
where each example consists of a question and diverse perspectives associated
with the question, sourced from survey questions and debate websites. On this
data, retrievers paired with a corpus are evaluated to surface a document set
that contains diverse perspectives. Our framing diverges from most retrieval
tasks in that document relevancy cannot be decided by simple string matches to
references. Instead, we build a language model based automatic evaluator that
decides whether each retrieved document contains a perspective. This allows us
to evaluate the performance of three different types of corpus (Wikipedia, web
snapshot, and corpus constructed on the fly with retrieved pages from the
search engine) paired with retrievers. Retrieving diverse documents remains
challenging, with the outputs from existing retrievers covering all
perspectives on only 33.74% of the examples. We further study the impact of
query expansion and diversity-focused reranking approaches and analyze
retriever sycophancy. Together, we lay the foundation for future studies in
retrieval diversity handling complex queries.

摘要：我們研究如何擷取一組文件，其中包含對一個複雜且有爭議問題的不同觀點（例如，ChatGPT 會造成更多傷害還是好處？）。
我們策劃了一個針對主觀問題的擷取多樣性基準（BERDS），其中每個範例包含一個問題和與該問題相關的不同觀點，這些觀點來自調查問題和辯論網站。在此資料上，與語料庫配對的擷取器會經過評估，以呈現包含不同觀點的文件集。我們的架構與大多數擷取任務不同，因為文件相關性無法透過簡單的字串比對來決定。相反地，我們建立了一個基於語言模型的自動評估器，用於決定每個擷取的文件是否包含某個觀點。這讓我們能夠評估與擷取器配對的三種類型語料庫（維基百科、網路快照，以及使用從搜尋引擎擷取的頁面即時建構的語料庫）的效能。擷取不同文件仍然具有挑戰性，現有擷取器的輸出僅涵蓋 33.74% 範例中的所有觀點。我們進一步研究查詢擴充和以多樣性為重點的重新排序方法的影響，並分析擷取器的阿諛奉承。總之，我們為未來在處理複雜查詢的多樣性擷取研究奠定了基礎。

##### **Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats**
2409.18104v1 by Lucia Gordon, Nikhil Behari, Samuel Collier, Elizabeth Bondi-Kelly, Jackson A. Killian, Catherine Ressijac, Peter Boucher, Andrew Davies, Milind Tambe

Much of Earth's charismatic megafauna is endangered by human activities,
particularly the rhino, which is at risk of extinction due to the poaching
crisis in Africa. Monitoring rhinos' movement is crucial to their protection
but has unfortunately proven difficult because rhinos are elusive. Therefore,
instead of tracking rhinos, we propose the novel approach of mapping communal
defecation sites, called middens, which give information about rhinos' spatial
behavior valuable to anti-poaching, management, and reintroduction efforts.
This paper provides the first-ever mapping of rhino midden locations by
building classifiers to detect them using remotely sensed thermal, RGB, and
LiDAR imagery in passive and active learning settings. As existing active
learning methods perform poorly due to the extreme class imbalance in our
dataset, we design MultimodAL, an active learning system employing a ranking
technique and multimodality to achieve competitive performance with passive
learning models with 94% fewer labels. Our methods could therefore save over 76
hours in labeling time when used on a similarly-sized dataset. Unexpectedly,
our midden map reveals that rhino middens are not randomly distributed
throughout the landscape; rather, they are clustered. Consequently, rangers
should be targeted at areas with high midden densities to strengthen
anti-poaching efforts, in line with UN Target 15.7.

摘要：地球上许多魅力十足的大型动物都因人类活动而面临灭绝的危险，尤其是犀牛，由于非洲盗猎危机，犀牛面临灭绝的风险。监测犀牛的活动对它们的保护至关重要，但不幸的是，由于犀牛难以捉摸，这已被证明是一项艰巨的任务。因此，我们没有追踪犀牛，而是提出了绘制公共排便地点（称为粪堆）的新颖方法，这些地点提供了有关犀牛空间行为的信息，这些信息对于反偷猎、管理和再引入工作非常有价值。本文通过构建分类器来检测它们，利用被动和主动学习设置中的遥感热成像、RGB 和 LiDAR 图像，提供了有史以来第一次犀牛粪堆位置的绘制。由于我们数据集中的极端类别不平衡，现有的主动学习方法表现不佳，因此我们设计了 MultimodAL，这是一种主动学习系统，采用排名技术和多模态来实现与被动学习模型具有竞争力的性能，标签减少了 94%。因此，当在类似大小的数据集上使用时，我们的方法可以节省超过 76 小时的标记时间。出乎意料的是，我们的粪堆地图显示犀牛粪堆并非随机分布在整个景观中；相反，它们是成簇分布的。因此，护林员应以粪堆密度高的地区为目标，以加强反偷猎工作，这符合联合国目标 15.7。

##### **AI-Powered Augmented Reality for Satellite Assembly, Integration and Test**
2409.18101v1 by Alvaro Patricio, Joao Valente, Atabak Dehban, Ines Cadilha, Daniel Reis, Rodrigo Ventura

The integration of Artificial Intelligence (AI) and Augmented Reality (AR) is
set to transform satellite Assembly, Integration, and Testing (AIT) processes
by enhancing precision, minimizing human error, and improving operational
efficiency in cleanroom environments. This paper presents a technical
description of the European Space Agency's (ESA) project "AI for AR in
Satellite AIT," which combines real-time computer vision and AR systems to
assist technicians during satellite assembly. Leveraging Microsoft HoloLens 2
as the AR interface, the system delivers context-aware instructions and
real-time feedback, tackling the complexities of object recognition and 6D pose
estimation in AIT workflows. All AI models demonstrated over 70% accuracy, with
the detection model exceeding 95% accuracy, indicating a high level of
performance and reliability. A key contribution of this work lies in the
effective use of synthetic data for training AI models in AR applications,
addressing the significant challenges of obtaining real-world datasets in
highly dynamic satellite environments, as well as the creation of the Segmented
Anything Model for Automatic Labelling (SAMAL), which facilitates the automatic
annotation of real data, achieving speeds up to 20 times faster than manual
human annotation. The findings demonstrate the efficacy of AI-driven AR systems
in automating critical satellite assembly tasks, setting a foundation for
future innovations in the space industry.

摘要：人工智慧（AI）與擴增實境（AR）的整合將徹底轉型衛星組裝、整合與測試（AIT）程序，藉由提升精準度、將人為錯誤降至最低，並提升潔淨室環境中的作業效率。本文提供歐洲太空總署（ESA）「衛星 AIT 中的 AR 人工智慧」專案的技術說明，該專案結合即時電腦視覺與 AR 系統，在衛星組裝過程中協助技術人員。系統運用 Microsoft HoloLens 2 作為 AR 介面，提供情境感知的指示與即時回饋，解決 AIT 工作流程中複雜的物件辨識與 6D 姿態估測問題。所有 AI 模型均展現出超過 70% 的準確度，其中偵測模型的準確度超過 95%，表示效能與可靠性極高。這項工作的關鍵貢獻在於有效利用合成資料訓練 AR 應用程式的 AI 模型，解決在高度動態的衛星環境中取得真實世界資料集的重大挑戰，以及建立用於自動標籤的分割任何模型（SAMAL），協助自動註解真實資料，速度比人工手動註解快達 20 倍。研究結果證明了 AI 驅動的 AR 系統在自動化關鍵衛星組裝任務方面的效能，為太空產業的未來創新奠定基礎。

##### **EfficientCrackNet: A Lightweight Model for Crack Segmentation**
2409.18099v1 by Abid Hasan Zim, Aquib Iqbal, Zaid Al-Huda, Asad Malik, Minoru Kuribayash

Crack detection, particularly from pavement images, presents a formidable
challenge in the domain of computer vision due to several inherent complexities
such as intensity inhomogeneity, intricate topologies, low contrast, and noisy
backgrounds. Automated crack detection is crucial for maintaining the
structural integrity of essential infrastructures, including buildings,
pavements, and bridges. Existing lightweight methods often face challenges
including computational inefficiency, complex crack patterns, and difficult
backgrounds, leading to inaccurate detection and impracticality for real-world
applications. To address these limitations, we propose EfficientCrackNet, a
lightweight hybrid model combining Convolutional Neural Networks (CNNs) and
transformers for precise crack segmentation. EfficientCrackNet integrates
depthwise separable convolutions (DSC) layers and MobileViT block to capture
both global and local features. The model employs an Edge Extraction Method
(EEM) and for efficient crack edge detection without pretraining, and
Ultra-Lightweight Subspace Attention Module (ULSAM) to enhance feature
extraction. Extensive experiments on three benchmark datasets Crack500,
DeepCrack, and GAPs384 demonstrate that EfficientCrackNet achieves superior
performance compared to existing lightweight models, while requiring only 0.26M
parameters, and 0.483 FLOPs (G). The proposed model offers an optimal balance
between accuracy and computational efficiency, outperforming state-of-the-art
lightweight models, and providing a robust and adaptable solution for
real-world crack segmentation.

摘要：裂縫檢測，特別是從路面影像中，由於幾個固有的複雜性，例如強度不均勻、複雜的拓撲結構、低對比度和有雜訊的背景，在電腦視覺領域中是一個艱鉅的挑戰。自動化裂縫檢測對於維持建築物、路面和橋樑等重要基礎設施的結構完整性至關重要。現有的輕量級方法通常面臨計算效率低、裂縫模式複雜和背景困難等挑戰，導致檢測不準確且不適用於實際應用。為了解決這些限制，我們提出了 EfficientCrackNet，這是一個輕量級混合模型，結合了卷積神經網路 (CNN) 和Transformer，以進行精確的裂縫分割。EfficientCrackNet 整合了深度可分離卷積 (DSC) 層和 MobileViT 塊，以擷取全局和局部特徵。該模型採用邊緣提取方法 (EEM) 和超輕量級子空間注意力模組 (ULSAM) 來增強特徵提取，而無需預訓練，以進行有效的裂縫邊緣檢測。在三個基準資料集 Crack500、DeepCrack 和 GAPs384 上進行的廣泛實驗表明，與現有的輕量級模型相比，EfficientCrackNet 達到了優異的性能，同時僅需要 0.26M 參數和 0.483 FLOPs (G)。所提出的模型在準確性和計算效率之間提供了最佳平衡，優於最先進的輕量級模型，並為實際裂縫分割提供了一個強大且適應性強的解決方案。

##### **DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models**
2409.18092v1 by Helin Cao, Sven Behnke

Perception systems play a crucial role in autonomous driving, incorporating
multiple sensors and corresponding computer vision algorithms. 3D LiDAR sensors
are widely used to capture sparse point clouds of the vehicle's surroundings.
However, such systems struggle to perceive occluded areas and gaps in the scene
due to the sparsity of these point clouds and their lack of semantics. To
address these challenges, Semantic Scene Completion (SSC) jointly predicts
unobserved geometry and semantics in the scene given raw LiDAR measurements,
aiming for a more complete scene representation. Building on promising results
of diffusion models in image generation and super-resolution tasks, we propose
their extension to SSC by implementing the noising and denoising diffusion
processes in the point and semantic spaces individually. To control the
generation, we employ semantic LiDAR point clouds as conditional input and
design local and global regularization losses to stabilize the denoising
process. We evaluate our approach on autonomous driving datasets and our
approach outperforms the state-of-the-art for SSC.

摘要：感知系統在自動駕駛中扮演著至關重要的角色，整合了多種感測器和對應的電腦視覺演算法。3D LiDAR 感測器廣泛用於擷取車輛周圍環境的稀疏點雲。然而，由於這些點雲的稀疏性和缺乏語意，此類系統難以感知場景中的遮擋區域和間隙。為了應對這些挑戰，語意場景完成 (SSC) 在給定原始 LiDAR 測量值的情況下，共同預測場景中未觀察到的幾何形狀和語意，旨在獲得更完整的場景表示。建立在擴散模型在影像生成和超解析度任務中令人滿意的結果上，我們提出將其擴展到 SSC，方法是在點和語意空間中分別實作加噪和去噪擴散過程。為了控制生成，我們採用語意 LiDAR 點雲作為條件輸入，並設計局部和全局正則化損失來穩定去噪過程。我們在自動駕駛資料集上評估我們的方法，我們的做法優於 SSC 的最新技術。

##### **GSON: A Group-based Social Navigation Framework with Large Multimodal Model**
2409.18084v1 by Shangyi Luo, Ji Zhu, Peng Sun, Yuhong Deng, Cunjun Yu, Anxing Xiao, Xueqian Wang

As the number of service robots and autonomous vehicles in human-centered
environments grows, their requirements go beyond simply navigating to a
destination. They must also take into account dynamic social contexts and
ensure respect and comfort for others in shared spaces, which poses significant
challenges for perception and planning. In this paper, we present a group-based
social navigation framework GSON to enable mobile robots to perceive and
exploit the social group of their surroundings by leveling the visual reasoning
capability of the Large Multimodal Model (LMM). For perception, we apply visual
prompting techniques to zero-shot extract the social relationship among
pedestrians and combine the result with a robust pedestrian detection and
tracking pipeline to alleviate the problem of low inference speed of the LMM.
Given the perception result, the planning system is designed to avoid
disrupting the current social structure. We adopt a social structure-based
mid-level planner as a bridge between global path planning and local motion
planning to preserve the global context and reactive response. The proposed
method is validated on real-world mobile robot navigation tasks involving
complex social structure understanding and reasoning. Experimental results
demonstrate the effectiveness of the system in these scenarios compared with
several baselines.

摘要：隨著以人為中心的環境中服務機器人和自動駕駛車輛的數量增加，它們的要求已超越了單純導航到目的地。它們還必須考慮動態的社交背景，並確保在共享空間中尊重和安慰他人，這對感知和規劃提出了重大挑戰。在本文中，我們提出了一個基於群組的社交導航框架 GSON，以使移動機器人能夠通過提升大型多模態模型 (LMM) 的視覺推理能力來感知和利用周圍環境中的社交群組。對於感知，我們將視覺提示技術應用於零次學習，以提取行人之間的社交關係，並將結果與強大的行人檢測和追蹤管道相結合，以緩解 LMM 推論速度低的問題。根據感知結果，規劃系統被設計為避免破壞當前的社交結構。我們採用基於社會結構的中級規劃器作為全局路徑規劃和局部運動規劃之間的橋樑，以保留全局背景和反應性響應。所提出的方法在涉及複雜社會結構理解和推理的真實世界移動機器人導航任務中得到驗證。實驗結果證明了該系統在這些場景中的有效性，並與幾個基線進行了比較。

##### **SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language Models for Robotic Garment Manipulation**
2409.18082v1 by Xin Li, Siyuan Huang, Qiaojun Yu, Zhengkai Jiang, Ce Hao, Yimeng Zhu, Hongsheng Li, Peng Gao, Cewu Lu

Automating garment manipulation poses a significant challenge for assistive
robotics due to the diverse and deformable nature of garments. Traditional
approaches typically require separate models for each garment type, which
limits scalability and adaptability. In contrast, this paper presents a unified
approach using vision-language models (VLMs) to improve keypoint prediction
across various garment categories. By interpreting both visual and semantic
information, our model enables robots to manage different garment states with a
single model. We created a large-scale synthetic dataset using advanced
simulation techniques, allowing scalable training without extensive real-world
data. Experimental results indicate that the VLM-based method significantly
enhances keypoint detection accuracy and task success rates, providing a more
flexible and general solution for robotic garment manipulation. In addition,
this research also underscores the potential of VLMs to unify various garment
manipulation tasks within a single framework, paving the way for broader
applications in home automation and assistive robotics for future.

摘要：自動化服飾操作對輔助機器人技術構成重大挑戰，因為服飾具有多樣且可變形的特性。傳統方法通常需要針對每種服飾類型建立獨立的模型，這限制了可擴充性和適應性。相反地，本文提出一個統一的方法，使用視覺語言模型 (VLM) 來改善各種服飾類別的關鍵點預測。透過解讀視覺和語義資訊，我們的模型讓機器人能夠使用單一模型來管理不同的服飾狀態。我們使用進階模擬技術建立了一個大型合成資料集，允許進行可擴充的訓練，而不需要大量的真實世界資料。實驗結果顯示，基於 VLM 的方法顯著提升了關鍵點偵測的準確度和任務成功率，為機器人服飾操作提供了更靈活且通用的解決方案。此外，這項研究也強調了 VLM 將各種服飾操作任務統一在單一架構中的潛力，為未來居家自動化和輔助機器人技術的廣泛應用鋪路。

##### **Infer Human's Intentions Before Following Natural Language Instructions**
2409.18073v1 by Yanming Wan, Yue Wu, Yiping Wang, Jiayuan Mao, Natasha Jaques

For AI agents to be helpful to humans, they should be able to follow natural
language instructions to complete everyday cooperative tasks in human
environments. However, real human instructions inherently possess ambiguity,
because the human speakers assume sufficient prior knowledge about their hidden
goals and intentions. Standard language grounding and planning methods fail to
address such ambiguities because they do not model human internal goals as
additional partially observable factors in the environment. We propose a new
framework, Follow Instructions with Social and Embodied Reasoning (FISER),
aiming for better natural language instruction following in collaborative
embodied tasks. Our framework makes explicit inferences about human goals and
intentions as intermediate reasoning steps. We implement a set of
Transformer-based models and evaluate them over a challenging benchmark,
HandMeThat. We empirically demonstrate that using social reasoning to
explicitly infer human intentions before making action plans surpasses purely
end-to-end approaches. We also compare our implementation with strong
baselines, including Chain of Thought prompting on the largest available
pre-trained language models, and find that FISER provides better performance on
the embodied social reasoning tasks under investigation, reaching the
state-of-the-art on HandMeThat.

摘要：為了讓 AI 代理人對人類有幫助，他們應該能夠遵循自然語言指令，在人類環境中完成日常合作任務。然而，真實的人類指令本質上具有模糊性，因為人類說話者假設有足夠的先備知識，了解他們的隱藏目標和意圖。標準的語言基礎和規劃方法無法解決這些模糊性，因為它們不會將人類內部目標建模為環境中額外的部分可觀察因素。我們提出一個新的架構，遵循具有社會和具身推理的指令 (FISER)，目標在於在協作具身任務中更好地遵循自然語言指令。我們的架構對人類目標和意圖進行明確的推論，作為中間推理步驟。我們實作一組基於 Transformer 的模型，並在具有挑戰性的基準 HandMeThat 上對其進行評估。我們憑經驗證明，在制定行動計畫之前，使用社會推理明確推論人類意圖優於純粹的端到端方法。我們也將我們的實作與強大的基準進行比較，包括對最大的可用預訓練語言模型進行思考鏈提示，並發現 FISER 在所研究的具身社會推理任務上提供了更好的效能，在 HandMeThat 上達到最先進的水平。

##### **FreeEdit: Mask-free Reference-based Image Editing with Multi-modal Instruction**
2409.18071v1 by Runze He, Kai Ma, Linjiang Huang, Shaofei Huang, Jialin Gao, Xiaoming Wei, Jiao Dai, Jizhong Han, Si Liu

Introducing user-specified visual concepts in image editing is highly
practical as these concepts convey the user's intent more precisely than
text-based descriptions. We propose FreeEdit, a novel approach for achieving
such reference-based image editing, which can accurately reproduce the visual
concept from the reference image based on user-friendly language instructions.
Our approach leverages the multi-modal instruction encoder to encode language
instructions to guide the editing process. This implicit way of locating the
editing area eliminates the need for manual editing masks. To enhance the
reconstruction of reference details, we introduce the Decoupled Residual
ReferAttention (DRRA) module. This module is designed to integrate fine-grained
reference features extracted by a detail extractor into the image editing
process in a residual way without interfering with the original self-attention.
Given that existing datasets are unsuitable for reference-based image editing
tasks, particularly due to the difficulty in constructing image triplets that
include a reference image, we curate a high-quality dataset, FreeBench, using a
newly developed twice-repainting scheme. FreeBench comprises the images before
and after editing, detailed editing instructions, as well as a reference image
that maintains the identity of the edited object, encompassing tasks such as
object addition, replacement, and deletion. By conducting phased training on
FreeBench followed by quality tuning, FreeEdit achieves high-quality zero-shot
editing through convenient language instructions. We conduct extensive
experiments to evaluate the effectiveness of FreeEdit across multiple task
types, demonstrating its superiority over existing methods. The code will be
available at: https://freeedit.github.io/.

摘要：<paragraph>在图像编辑中引入用户指定的视觉概念非常实用，因为这些概念比基于文本的描述更准确地传达了用户的意图。我们提出了 FreeEdit，这是一种实现基于参考的图像编辑的新方法，它可以根据用户友好的语言指令准确地从参考图像中复制视觉概念。我们的方法利用多模态指令编码器对语言指令进行编码，以指导编辑过程。这种定位编辑区域的隐式方式消除了对手动编辑蒙版的需求。为了增强参考细节的重建，我们引入了解耦残差参考注意力 (DRRA) 模块。该模块旨在以残差方式将细节提取器提取的细粒度参考特征集成到图像编辑过程中，而不会干扰原始自注意力。鉴于现有数据集不适用于基于参考的图像编辑任务，特别是由于难以构建包含参考图像的图像三元组，我们使用新开发的二次重绘方案整理了一个高质量数据集 FreeBench。FreeBench 包含编辑前后的图像、详细的编辑说明，以及一个保持编辑对象身份的参考图像，包括对象添加、替换和删除等任务。通过在 FreeBench 上进行阶段性训练，然后进行质量调整，FreeEdit 通过便捷的语言指令实现了高质量的零样本编辑。我们进行了广泛的实验来评估 FreeEdit 在多种任务类型中的有效性，证明了它优于现有方法。代码将在以下位置提供：https://freeedit.github.io/。</paragraph>

##### **Visual Data Diagnosis and Debiasing with Concept Graphs**
2409.18055v1 by Rwiddhi Chakraborty, Yinong Wang, Jialu Gao, Runkai Zheng, Cheng Zhang, Fernando De la Torre

The widespread success of deep learning models today is owed to the curation
of extensive datasets significant in size and complexity. However, such models
frequently pick up inherent biases in the data during the training process,
leading to unreliable predictions. Diagnosing and debiasing datasets is thus a
necessity to ensure reliable model performance. In this paper, we present
CONBIAS, a novel framework for diagnosing and mitigating Concept co-occurrence
Biases in visual datasets. CONBIAS represents visual datasets as knowledge
graphs of concepts, enabling meticulous analysis of spurious concept
co-occurrences to uncover concept imbalances across the whole dataset.
Moreover, we show that by employing a novel clique-based concept balancing
strategy, we can mitigate these imbalances, leading to enhanced performance on
downstream tasks. Extensive experiments show that data augmentation based on a
balanced concept distribution augmented by CONBIAS improves generalization
performance across multiple datasets compared to state-of-the-art methods. We
will make our code and data publicly available.

摘要：深度學習模型今日的廣泛成功歸功於策劃大量且複雜的資料集。然而，此類模型在訓練過程中經常會吸收資料中的內在偏差，導致預測不可靠。因此，診斷和消除資料集偏差是確保模型效能可靠的必要條件。本文提出 CONBIAS，一個診斷和減輕視覺資料集中概念共現偏差的新穎架構。CONBIAS 將視覺資料集表示為概念知識圖譜，能仔細分析虛假概念共現，以找出整個資料集中概念的不平衡。此外，我們展示透過採用新穎的基於派系的平衡概念策略，我們可以減輕這些不平衡，進而提升下游任務的效能。廣泛的實驗顯示，基於由 CONBIAS 增強的平衡概念分佈的資料擴充，與現有方法相比，改善了多個資料集的泛化效能。我們將公開我們的程式碼和資料。

##### **DualAD: Dual-Layer Planning for Reasoning in Autonomous Driving**
2409.18053v1 by Dingrui Wang, Marc Kaufeld, Johannes Betz

We present a novel autonomous driving framework, DualAD, designed to imitate
human reasoning during driving. DualAD comprises two layers: a rule-based
motion planner at the bottom layer that handles routine driving tasks requiring
minimal reasoning, and an upper layer featuring a rule-based text encoder that
converts driving scenarios from absolute states into text description. This
text is then processed by a large language model (LLM) to make driving
decisions. The upper layer intervenes in the bottom layer's decisions when
potential danger is detected, mimicking human reasoning in critical situations.
Closed-loop experiments demonstrate that DualAD, using a zero-shot pre-trained
model, significantly outperforms rule-based motion planners that lack reasoning
abilities. Our experiments also highlight the effectiveness of the text
encoder, which considerably enhances the model's scenario understanding.
Additionally, the integrated DualAD model improves with stronger LLMs,
indicating the framework's potential for further enhancement. We make code and
benchmarks publicly available.

摘要：我們提出了一個新穎的自動駕駛架構 DualAD，旨在模仿人類在駕駛過程中的推理。DualAD 包含兩層：底層的基於規則的運動規劃器，負責處理需要最少推理的例行駕駛任務，以及上層的基於規則的文本編碼器，將駕駛場景從絕對狀態轉換為文本描述。然後，大型語言模型 (LLM) 處理此文本以做出駕駛決策。當檢測到潛在危險時，上層會干預底層的決策，模擬人類在危急情況下的推理。閉環實驗表明，使用零次學習預訓練模型的 DualAD 明顯優於缺乏推理能力的基於規則的運動規劃器。我們的實驗還突出了文本編碼器的有效性，它顯著增強了模型的場景理解。此外，集成的 DualAD 模型隨著 LLM 的增強而改進，表明該框架具有進一步增強的潛力。我們公開提供代碼和基準。

##### **HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams**
2409.18047v1 by Sanjay Oruganti, Sergei Nirenburg, Marjorie McShane, Jesse English, Michael K. Roberts, Christian Arndt

This paper presents a novel approach to multi-robot planning and
collaboration. We demonstrate a cognitive strategy for robots in human-robot
teams that incorporates metacognition, natural language communication, and
explainability. The system is embodied using the HARMONIC architecture that
flexibly integrates cognitive and control capabilities across the team. We
evaluate our approach through simulation experiments involving a joint search
task by a team of heterogeneous robots (a UGV and a drone) and a human. We
detail the system's handling of complex, real-world scenarios, effective action
coordination between robots with different capabilities, and natural
human-robot communication. This work demonstrates that the robots' ability to
reason about plans, goals, and attitudes, and to provide explanations for
actions and decisions are essential prerequisites for realistic human-robot
teaming.

摘要：本文提出了一種多機器人規劃和協作的新方法。我們展示了人類機器人團隊中機器人的認知策略，其中包含元認知、自然語言溝通和可解釋性。該系統使用 HARMONIC 架構，靈活地整合了整個團隊的認知和控制能力。我們通過模擬實驗評估了我們的方法，其中涉及由異構機器人（UGV 和無人機）和人類組成的團隊進行的聯合搜索任務。我們詳細說明了系統處理複雜的現實世界場景、具有不同能力的機器人之間的有效動作協調以及自然的人機溝通。這項工作表明，機器人推理計劃、目標和態度以及對行動和決策提供解釋的能力是實現現實的人機團隊合作的基本先決條件。

##### **Unveiling the Role of Pretraining in Direct Speech Translation**
2409.18044v1 by Belen Alastruey, Gerard I. Gállego, Marta R. Costa-jussà

Direct speech-to-text translation systems encounter an important drawback in
data scarcity. A common solution consists on pretraining the encoder on
automatic speech recognition, hence losing efficiency in the training process.
In this study, we compare the training dynamics of a system using a pretrained
encoder, the conventional approach, and one trained from scratch. We observe
that, throughout the training, the randomly initialized model struggles to
incorporate information from the speech inputs for its predictions. Hence, we
hypothesize that this issue stems from the difficulty of effectively training
an encoder for direct speech translation. While a model trained from scratch
needs to learn acoustic and semantic modeling simultaneously, a pretrained one
can just focus on the latter. Based on these findings, we propose a subtle
change in the decoder cross-attention to integrate source information from
earlier steps in training. We show that with this change, the model trained
from scratch can achieve comparable performance to the pretrained one, while
reducing the training time.

摘要：直接语音轉文字翻譯系統在資料稀少性方面會遇到一個重要的缺點。一個常見的解決方案是預訓練編碼器進行自動語音辨識，因此在訓練過程中會失去效率。在本研究中，我們比較了使用預訓練編碼器、傳統方法和從頭開始訓練的系統的訓練動態。我們觀察到，在整個訓練過程中，隨機初始化的模型難以將語音輸入的資訊納入其預測中。因此，我們假設這個問題源於有效訓練直接語音翻譯編碼器的困難。雖然從頭開始訓練的模型需要同時學習音訊和語義建模，但預訓練的模型只能專注於後者。基於這些發現，我們提出了一個在解碼器交叉注意力的細微變化，以整合訓練早期步驟中的來源資訊。我們表明，有了這個改變，從頭開始訓練的模型可以達到與預訓練模型相當的效能，同時縮短訓練時間。

##### **EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions**
2409.18042v1 by Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang, Yi Zhu, Yihan Zeng, Kuo Yang, Dingdong Wang, Kun Xiang, Haoyuan Li, Haoli Bai, Jianhua Han, Xiaohui Li, Weike Jin, Nian Xie, Yu Zhang, James T. Kwok, Hengshuang Zhao, Xiaodan Liang, Dit-Yan Yeung, Xiao Chen, Zhenguo Li, Wei Zhang, Qun Liu, Lanqing Hong, Lu Hou, Hang Xu

GPT-4o, an omni-modal model that enables vocal conversations with diverse
emotions and tones, marks a milestone for omni-modal foundation models.
However, empowering Large Language Models to perceive and generate images,
texts, and speeches end-to-end with publicly available data remains challenging
in the open-source community. Existing vision-language models rely on external
tools for the speech processing, while speech-language models still suffer from
limited or even without vision-understanding abilities. To address this gap, we
propose EMOVA (EMotionally Omni-present Voice Assistant), to enable Large
Language Models with end-to-end speech capabilities while maintaining the
leading vision-language performance. With a semantic-acoustic disentangled
speech tokenizer, we notice surprisingly that omni-modal alignment can further
enhance vision-language and speech abilities compared with the corresponding
bi-modal aligned counterparts. Moreover, a lightweight style module is proposed
for flexible speech style controls (e.g., emotions and pitches). For the first
time, EMOVA achieves state-of-the-art performance on both the vision-language
and speech benchmarks, and meanwhile, supporting omni-modal spoken dialogue
with vivid emotions.

摘要：GPT-4o 是一個全模態模型，能以不同的情緒和語調進行語音對話，標誌著全模態基礎模型的里程碑。
然而，在開放原始碼社群中，賦予大型語言模型感知和生成圖像、文字和語音的能力，並使用公開資料進行端對端處理，仍然具有挑戰性。現有的視覺語言模型依賴於外部工具進行語音處理，而語音語言模型仍然缺乏或甚至沒有視覺理解能力。為了解決這個差距，我們提出了 EMOVA（情感全方位語音助理），讓大型語言模型具備端對端語音功能，同時保持領先的視覺語言效能。透過語義聲學分離的語音分詞器，我們驚訝地發現，與對應的雙模態對應項目相比，全模態對齊可以進一步增強視覺語言和語音能力。此外，我們還提出了一個輕量級樣式模組，用於靈活的語音樣式控制（例如，情緒和音高）。EMOVA 首次在視覺語言和語音基準測試中都達到了最先進的效能，同時支援具有生動情緒的全模態口語對話。

##### **Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective**
2409.18028v1 by Yotam Wolf, Binyamin Rothberg, Dorin Shteyman, Amnon Shashua

A common practice in large language model (LLM) usage for complex analytical
tasks such as code generation, is to sample a solution for the entire task
within the model's context window. Previous works have shown that subtask
decomposition within the model's context (chain of thought), is beneficial for
solving such tasks. In this work, we point a limitation of LLMs' ability to
perform several sub-tasks within the same context window - an in-context
hardness of composition, pointing to an advantage for distributing a decomposed
problem in a multi-agent system of LLMs. The hardness of composition is
quantified by a generation complexity metric, i.e., the number of LLM
generations required to sample at least one correct solution. We find a gap
between the generation complexity of solving a compositional problem within the
same context relative to distributing it among multiple agents, that increases
exponentially with the solution's length. We prove our results theoretically
and demonstrate them empirically.

摘要：大型語言模型 (LLM) 在複雜分析任務（例如程式碼生成）中的常見做法，是在模型的內容視窗中為整個任務抽樣一個解。先前的研究表明，模型內容（思考鏈）中的子任務分解，有助於解決此類任務。在這項工作中，我們指出 LLM 在同一內容視窗中執行多個子任務的能力限制，也就是內容組成的難度，指出將分解的問題分配給 LLM 的多代理系統的優點。組成的難度由生成複雜度量化，也就是抽取至少一個正確解所需的 LLM 生成次數。我們發現，在同一內容中解決組合問題的生成複雜度與將其分配給多個代理之間存在差距，而這個差距會隨著解的長度呈指數增加。我們從理論上證明我們的結果，並以經驗證明它們。

##### **An Adversarial Perspective on Machine Unlearning for AI Safety**
2409.18025v1 by Jakub Łucki, Boyi Wei, Yangsibo Huang, Peter Henderson, Florian Tramèr, Javier Rando

Large language models are finetuned to refuse questions about hazardous
knowledge, but these protections can often be bypassed. Unlearning methods aim
at completely removing hazardous capabilities from models and make them
inaccessible to adversaries. This work challenges the fundamental differences
between unlearning and traditional safety post-training from an adversarial
perspective. We demonstrate that existing jailbreak methods, previously
reported as ineffective against unlearning, can be successful when applied
carefully. Furthermore, we develop a variety of adaptive methods that recover
most supposedly unlearned capabilities. For instance, we show that finetuning
on 10 unrelated examples or removing specific directions in the activation
space can recover most hazardous capabilities for models edited with RMU, a
state-of-the-art unlearning method. Our findings challenge the robustness of
current unlearning approaches and question their advantages over safety
training.

摘要：大型語言模型經過微調，以拒絕有關危險知識的問題，但這些保護措施通常可以被繞過。遺忘方法旨在從模型中完全移除危險的能力，並讓對手無法使用。這項工作從對抗的角度挑戰了遺忘和傳統安全訓練後處理之間的根本差異。我們證明了現有的越獄方法，以前被報導對遺忘無效，在小心應用時可以成功。此外，我們開發了各種適應性方法，以恢復大多數假設已遺忘的能力。例如，我們展示了在 10 個不相關的範例上進行微調或移除激活空間中的特定方向，可以恢復使用 RMU（一種最先進的遺忘方法）編輯的模型的大部分危險能力。我們的發現挑戰了當前遺忘方法的穩健性，並質疑它們相對於安全訓練的優勢。

##### **DARE: Diverse Visual Question Answering with Robustness Evaluation**
2409.18023v1 by Hannah Sterz, Jonas Pfeiffer, Ivan Vulić

Vision Language Models (VLMs) extend remarkable capabilities of text-only
large language models and vision-only models, and are able to learn from and
process multi-modal vision-text input. While modern VLMs perform well on a
number of standard image classification and image-text matching tasks, they
still struggle with a number of crucial vision-language (VL) reasoning
abilities such as counting and spatial reasoning. Moreover, while they might be
very brittle to small variations in instructions and/or evaluation protocols,
existing benchmarks fail to evaluate their robustness (or rather the lack of
it). In order to couple challenging VL scenarios with comprehensive robustness
evaluation, we introduce DARE, Diverse Visual Question Answering with
Robustness Evaluation, a carefully created and curated multiple-choice VQA
benchmark. DARE evaluates VLM performance on five diverse categories and
includes four robustness-oriented evaluations based on the variations of:
prompts, the subsets of answer options, the output format and the number of
correct answers. Among a spectrum of other findings, we report that
state-of-the-art VLMs still struggle with questions in most categories and are
unable to consistently deliver their peak performance across the tested
robustness evaluations. The worst case performance across the subsets of
options is up to 34% below the performance in the standard case. The robustness
of the open-source VLMs such as LLaVA 1.6 and Idefics2 cannot match the
closed-source models such as GPT-4 and Gemini, but even the latter remain very
brittle to different variations.

摘要：視覺語言模型 (VLM) 擴展了純文字大型語言模型和純視覺模型的顯著能力，並且能夠從多模態視覺文字輸入中學習和處理。雖然現代 VLM 在許多標準圖像分類和圖像文字匹配任務上表現良好，但它們在許多關鍵的視覺語言 (VL) 推理能力上仍存在困難，例如計數和空間推理。此外，雖然它們可能對指令和/或評估協議的微小變化非常脆弱，但現有的基準未能評估其健壯性（或更確切地說，缺乏健壯性）。為了將具有挑戰性的 VL 場景與全面的健壯性評估相結合，我們引入了 DARE，一種多選題 VQA 基準，具有健壯性評估，經過仔細創建和策劃。DARE 評估了 VLM 在五個不同類別上的表現，並包括四項基於以下變化的健壯性導向評估：提示、答案選項的子集、輸出格式和正確答案的數量。在其他一系列發現中，我們報告說，最先進的 VLM 仍然難以應對大多數類別中的問題，並且無法在測試的健壯性評估中持續提供其峰值效能。選項子集中的最差情況效能比標準情況下的效能低 34%。LLaVA 1.6 和 Idefics2 等開源 VLM 的健壯性無法與 GPT-4 和 Gemini 等閉源模型相匹配，但即使是後者對不同的變化仍然非常脆弱。

##### **Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles**
2409.18014v1 by Lewei He, Tianyu Shi, Pengran Huang, Bingzhi Chen, Qianglong Chen, Jiahui Pan

Large language models (LLMs) with long-context processing are still
challenging because of their implementation complexity, training efficiency and
data sparsity. To address this issue, a new paradigm named Online Long-context
Processing (OLP) is proposed when we process a document of unlimited length,
which typically occurs in the information reception and organization of diverse
streaming media such as automated news reporting, live e-commerce, and viral
short videos. Moreover, a dilemma was often encountered when we tried to select
the most suitable LLM from a large number of LLMs amidst explosive growth
aiming for outstanding performance, affordable prices, and short response
delays. In view of this, we also develop Role Reinforcement Learning (Role-RL)
to automatically deploy different LLMs in their respective roles within the OLP
pipeline according to their actual performance. Extensive experiments are
conducted on our OLP-MINI dataset and it is found that OLP with Role-RL
framework achieves OLP benchmark with an average recall rate of 93.2% and the
LLM cost saved by 79.4%. The code and dataset are publicly available at:
https://anonymous.4open.science/r/Role-RL.

摘要：大型語言模型 (LLM) 具有長語境處理能力，但由於其複雜的實作、訓練效率和資料稀疏性，仍面臨挑戰。為了解決這個問題，當我們處理長度不限的文件時，提出了一種名為線上長語境處理 (OLP) 的新範例，這通常發生在自動化新聞報導、直播電子商務和病毒式短影片等各種串流媒體的資訊接收和組織中。此外，在爆炸性的成長中，我們嘗試從大量的 LLM 中選擇最合適的 LLM 時，經常會遇到兩難的局面，目標是追求傑出的效能、負擔得起的價格和短暫的回應延遲。有鑑於此，我們也開發了角色強化學習 (Role-RL) 以根據其實際效能，在 OLP 管線中自動部署不同的 LLM 到各自的角色中。在我們的 OLP-MINI 資料集上進行了廣泛的實驗，發現採用角色強化學習架構的 OLP 達到了 OLP 評量標準，平均召回率為 93.2%，且 LLM 成本節省了 79.4%。程式碼和資料集已公開於：https://anonymous.4open.science/r/Role-RL。

##### **Control Industrial Automation System with Large Language Models**
2409.18009v1 by Yuchen Xia, Nasser Jazdi, Jize Zhang, Chaitanya Shah, Michael Weyrich

Traditional industrial automation systems require specialized expertise to
operate and complex reprogramming to adapt to new processes. Large language
models offer the intelligence to make them more flexible and easier to use.
However, LLMs' application in industrial settings is underexplored. This paper
introduces a framework for integrating LLMs to achieve end-to-end control of
industrial automation systems. At the core of the framework are an agent system
designed for industrial tasks, a structured prompting method, and an
event-driven information modeling mechanism that provides real-time data for
LLM inference. The framework supplies LLMs with real-time events on different
context semantic levels, allowing them to interpret the information, generate
production plans, and control operations on the automation system. It also
supports structured dataset creation for fine-tuning on this downstream
application of LLMs. Our contribution includes a formal system design,
proof-of-concept implementation, and a method for generating task-specific
datasets for LLM fine-tuning and testing. This approach enables a more adaptive
automation system that can respond to spontaneous events, while allowing easier
operation and configuration through natural language for more intuitive
human-machine interaction. We provide demo videos and detailed data on GitHub:
https://github.com/YuchenXia/LLM4IAS

摘要：傳統的工業自動化系統需要專業的知識才能操作和複雜的重新編程才能適應新的程序。大型語言模型提供了智慧，讓它們更靈活且更容易使用。然而，LLM 在工業環境中的應用尚未被充分探索。本文介紹了一個整合 LLM 以實現工業自動化系統端到端控制的框架。該框架的核心是一個專為工業任務設計的代理系統、一個結構化的提示方法，以及一個提供 LLM 推論的即時數據的事件驅動訊息建模機制。該框架為 LLM 提供不同語境語義層級的即時事件，讓它們能夠詮釋訊息、產生生產計畫，並控制自動化系統上的操作。它還支援結構化資料集建立，以便對 LLM 的下游應用進行微調。我們的貢獻包括一個正式的系統設計、概念驗證實作，以及一個為 LLM 微調和測試產生特定任務資料集的方法。這種方法能實現一個更具適應性的自動化系統，能夠回應自發事件，同時透過自然語言讓操作和組態更容易，以實現更直覺的人機互動。我們在 GitHub 上提供示範影片和詳細資料：https://github.com/YuchenXia/LLM4IAS

##### **Multilingual Evaluation of Long Context Retrieval and Reasoning**
2409.18006v1 by Ameeta Agrawal, Andy Dang, Sina Bagheri Nezhad, Rhitabrat Pokharel, Russell Scheinberg

Recent large language models (LLMs) demonstrate impressive capabilities in
handling long contexts, some exhibiting near-perfect recall on synthetic
retrieval tasks. However, these evaluations have mainly focused on English text
and involved a single target sentence within lengthy contexts. Our work
investigates how LLM performance generalizes to multilingual settings with
multiple hidden target sentences. We comprehensively evaluate several
long-context LLMs on retrieval and reasoning tasks across five languages:
English, Vietnamese, Indonesian, Swahili, and Somali. These languages share the
Latin script but belong to distinct language families and resource levels. Our
analysis reveals a significant performance gap between languages. The
best-performing models such as Gemini-1.5 and GPT-4o, achieve around 96%
accuracy in English to around 36% in Somali with a single target sentence.
However, this accuracy drops to 40% in English and 0% in Somali when dealing
with three target sentences. Our findings highlight the challenges long-context
LLMs face when processing longer contexts, an increase in the number of target
sentences, or languages of lower resource levels.

摘要：近期的大型语言模型（LLM）在处理长文本语境方面表现出了令人印象深刻的能力，有些模型在合成式检索任务中表现出近乎完美的召回率。然而，这些评估主要集中在英文文本上，并且在冗长的语境中只涉及一个目标句子。我们的研究调查了 LLM 性能如何推广到具有多个隐藏目标句子的多语言设置。我们对五种语言（英语、越南语、印度尼西亚语、斯瓦希里语和索马里语）的几个长文本语境 LLM 进行了全面的检索和推理任务评估。这些语言共享拉丁字母，但属于不同的语系和资源级别。我们的分析揭示了语言之间的显着性能差距。表现最好的模型（如 Gemini-1.5 和 GPT-4o）在英语中的准确率约为 96%，在索马里语中为 36%，只有一个目标句子。然而，在处理三个目标句子时，英语的准确率下降到 40%，索马里语下降到 0%。我们的研究结果突出了长文本语境 LLM 在处理更长的语境、目标句子的数量增加或资源级别较低的语言时面临的挑战。

##### **Joint Localization and Planning using Diffusion**
2409.17995v1 by L. Lao Beyer, S. Karaman

Diffusion models have been successfully applied to robotics problems such as
manipulation and vehicle path planning. In this work, we explore their
application to end-to-end navigation -- including both perception and planning
-- by considering the problem of jointly performing global localization and
path planning in known but arbitrary 2D environments. In particular, we
introduce a diffusion model which produces collision-free paths in a global
reference frame given an egocentric LIDAR scan, an arbitrary map, and a desired
goal position. To this end, we implement diffusion in the space of paths in
SE(2), and describe how to condition the denoising process on both obstacles
and sensor observations. In our evaluation, we show that the proposed
conditioning techniques enable generalization to realistic maps of considerably
different appearance than the training environment, demonstrate our model's
ability to accurately describe ambiguous solutions, and run extensive
simulation experiments showcasing our model's use as a real-time, end-to-end
localization and planning stack.

摘要：擴散模型已成功應用於機器人問題，例如操作和車輛路徑規劃。在這項工作中，我們探討其應用於端到端導航——包括感知和規劃——方法是考慮在已知但任意的 2D 環境中同時執行全局定位和路徑規劃的問題。特別是，我們引入了一個擴散模型，該模型根據自我中心的 LIDAR 掃描、任意地圖和所需的目標位置在全局參考系中產生無碰撞路徑。為此，我們在 SE(2) 路徑空間中實作擴散，並描述如何根據障礙物和感測器觀測對去噪過程進行條件設定。在我們的評估中，我們展示了所提出的條件設定技術能夠推廣到與訓練環境外觀截然不同的真實地圖，展示了我們的模型準確描述模糊解的能力，並執行廣泛的模擬實驗，展示了我們的模型作為實時、端到端定位和規劃堆疊的用途。

##### **CRoP: Context-wise Robust Static Human-Sensing Personalization**
2409.17994v1 by Sawinder Kaur, Avery Gump, Jingyu Xin, Yi Xiao, Harshit Sharma, Nina R Benway, Jonathan L Preston, Asif Salekin

The advancement in deep learning and internet-of-things have led to diverse
human sensing applications. However, distinct patterns in human sensing,
influenced by various factors or contexts, challenge generic neural network
model's performance due to natural distribution shifts. To address this,
personalization tailors models to individual users. Yet most personalization
studies overlook intra-user heterogeneity across contexts in sensory data,
limiting intra-user generalizability. This limitation is especially critical in
clinical applications, where limited data availability hampers both
generalizability and personalization. Notably, intra-user sensing attributes
are expected to change due to external factors such as treatment progression,
further complicating the challenges.This work introduces CRoP, a novel static
personalization approach using an off-the-shelf pre-trained model and pruning
to optimize personalization and generalization. CRoP shows superior
personalization effectiveness and intra-user robustness across four
human-sensing datasets, including two from real-world health domains,
highlighting its practical and social impact. Additionally, to support CRoP's
generalization ability and design choices, we provide empirical justification
through gradient inner product analysis, ablation studies, and comparisons
against state-of-the-art baselines.

摘要：深度學習和物聯網的進步帶來了多樣化的人體感測應用。然而，受各種因素或情境影響的人體感測中的不同模式，會因自然分佈轉移而對通用神經網路模型的效能提出挑戰。為了解決這個問題，個人化會根據個別使用者調整模型。然而，大多數的個人化研究都忽略了感測資料中跨情境、使用者內部的異質性，這限制了使用者內部的可概化性。在臨床應用中，這個限制尤其重要，因為有限的資料可用性會阻礙可概化性和個人化。值得注意的是，使用者內部的感測屬性預期會因外部因素（例如治療進程）而改變，這進一步複雜化了這些挑戰。這項工作引入了 CRoP，這是一種使用現成的預訓練模型和剪枝來最佳化個人化和概化的新型靜態個人化方法。CRoP 在四個人體感測資料集（包括兩個來自真實世界健康領域的資料集）中展現出卓越的個人化效果和使用者內部穩健性，突顯了它的實用性和社會影響。此外，為了支援 CRoP 的概化能力和設計選擇，我們透過梯度內積分析、消融研究和與最新基準的比較，提供了經驗依據。

##### **Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models**
2409.17990v1 by Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier

This paper proposes temporally aligned Large Language Models (LLMs) as a tool
for longitudinal analysis of social media data. We fine-tune Temporal Adapters
for Llama 3 8B on full timelines from a panel of British Twitter users, and
extract longitudinal aggregates of emotions and attitudes with established
questionnaires. We validate our estimates against representative British survey
data and find strong positive, significant correlations for several collective
emotions. The obtained estimates are robust across multiple training seeds and
prompt formulations, and in line with collective emotions extracted using a
traditional classification model trained on labeled data. To the best of our
knowledge, this is the first work to extend the analysis of affect in LLMs to a
longitudinal setting through Temporal Adapters. Our work enables new approaches
towards the longitudinal analysis of social media data.

摘要：本文提出了時序對齊的大語言模型 (LLM)，作為進行社群媒體資料縱向分析的工具。我們針對來自英國 Twitter 使用者小組的完整時間軸，微調了 Llama 3 8B 的時序適配器，並透過既定的問卷，提取情緒和態度的縱向彙總。我們根據具有代表性的英國調查資料驗證我們的估計，並發現了多種集體情緒的強正相關性。獲得的估計值在多個訓練種子和提示公式中都是穩健的，並且與使用針對標籤資料訓練的傳統分類模型提取的集體情緒一致。據我們所知，這是第一個透過時序適配器將 LLM 中的情感分析延伸到縱向設定的研究。我們的研究成果促成了社群媒體資料縱向分析的新方法。

##### **HydraViT: Stacking Heads for a Scalable ViT**
2409.17978v1 by Janek Haberer, Ali Hojjat, Olaf Landsiedel

The architecture of Vision Transformers (ViTs), particularly the Multi-head
Attention (MHA) mechanism, imposes substantial hardware demands. Deploying ViTs
on devices with varying constraints, such as mobile phones, requires multiple
models of different sizes. However, this approach has limitations, such as
training and storing each required model separately. This paper introduces
HydraViT, a novel approach that addresses these limitations by stacking
attention heads to achieve a scalable ViT. By repeatedly changing the size of
the embedded dimensions throughout each layer and their corresponding number of
attention heads in MHA during training, HydraViT induces multiple subnetworks.
Thereby, HydraViT achieves adaptability across a wide spectrum of hardware
environments while maintaining performance. Our experimental results
demonstrate the efficacy of HydraViT in achieving a scalable ViT with up to 10
subnetworks, covering a wide range of resource constraints. HydraViT achieves
up to 5 p.p. more accuracy with the same GMACs and up to 7 p.p. more accuracy
with the same throughput on ImageNet-1K compared to the baselines, making it an
effective solution for scenarios where hardware availability is diverse or
varies over time. Source code available at https://github.com/ds-kiel/HydraViT.

摘要：視覺Transformer (ViT) 的架構，特別是多頭注意力 (MHA) 機制，會產生大量的硬體需求。在具有不同限制的裝置上部署 ViT，例如手機，需要不同大小的多個模型。然而，這種方法有其限制，例如分別訓練和儲存每個所需的模型。本文介紹 HydraViT，這是一種新穎的方法，透過堆疊注意力頭部來解決這些限制，以達成可擴充的 ViT。透過在訓練期間重複變更每個層中的嵌入維度大小，以及它們在 MHA 中對應的注意力頭部數量，HydraViT 會誘發多個子網路。因此，HydraViT 在維持效能的同時，在廣泛的硬體環境中達成適應性。我們的實驗結果證明了 HydraViT 在達成可擴充的 ViT 中的效力，最多可達 10 個子網路，涵蓋了廣泛的資源限制。與基準相比，HydraViT 在 ImageNet-1K 上以相同的 GMAC 達到高達 5 p.p. 的準確度，以及以相同的處理量達到高達 7 p.p. 的準確度，使其成為硬體可用性多樣或隨著時間而變化的場景的有效解決方案。原始程式碼可於 https://github.com/ds-kiel/HydraViT 取得。

##### **BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search**
2409.17972v1 by Linzhuang Sun, Hao Liang, Wentao Zhang

Large Language Models (LLMs) have exhibited exceptional performance across a
broad range of tasks and domains. However, they still encounter difficulties in
solving mathematical problems due to the rigorous and logical nature of
mathematics. Previous studies have employed techniques such as supervised
fine-tuning (SFT), prompt engineering, and search-based methods to improve the
mathematical problem-solving abilities of LLMs. Despite these efforts, their
performance remains suboptimal and demands substantial computational resources.
To address this issue, we propose a novel approach, BEATS, to enhance
mathematical problem-solving abilities. Our method leverages newly designed
prompts that guide the model to iteratively rewrite, advance by one step, and
generate answers based on previous steps. Additionally, we introduce a new
back-verification technique that uses LLMs to validate the correctness of the
generated answers. Furthermore, we employ a pruning tree search to optimize
search time while achieving strong performance. Notably, our method improves
Qwen2-7b-Instruct's score from 36.94 to 61.52, outperforming GPT4's 42.5 on the
MATH benchmark.

摘要：大型語言模型 (LLM) 在廣泛的任務和領域中展現出卓越的效能。然而，由於數學的嚴謹性和邏輯性，它們在解決數學問題時仍會遇到困難。先前的研究採用了監督微調 (SFT)、提示工程和基於搜尋的方法等技術來提升 LLM 的數學問題解決能力。儘管付出了這些努力，它們的效能仍然未達最佳，且需要大量的運算資源。為了解決這個問題，我們提出了一種新方法 BEATS 來增強數學問題解決能力。我們的這種方法利用新設計的提示，引導模型反覆重寫、推進一步，並根據先前的步驟產生答案。此外，我們還引入了一種新的後驗證技術，它使用 LLM 來驗證所產生答案的正確性。而且，我們採用剪枝樹搜尋來最佳化搜尋時間，同時達成強大的效能。值得注意的是，我們的這種方法將 Qwen2-7b-Instruct 的分數從 36.94 提升到 61.52，在 MATH 基準上優於 GPT4 的 42.5。

##### **The Hard Positive Truth about Vision-Language Compositionality**
2409.17958v1 by Amita Kamath, Cheng-Yu Hsieh, Kai-Wei Chang, Ranjay Krishna

Several benchmarks have concluded that our best vision-language models (e.g.,
CLIP) are lacking in compositionality. Given an image, these benchmarks probe a
model's ability to identify its associated caption amongst a set of
compositional distractors. In response, a surge of recent proposals show
improvements by finetuning CLIP with distractors as hard negatives. Our
investigations reveal that these improvements have, in fact, been significantly
overstated -- because existing benchmarks do not probe whether finetuned
vision-language models remain invariant to hard positives. By curating an
evaluation dataset with 112,382 hard negatives and hard positives, we uncover
that including hard positives decreases CLIP's performance by 12.9%, while
humans perform effortlessly at 99%. CLIP finetuned with hard negatives results
in an even larger decrease, up to 38.7%. With this finding, we then produce a
1,775,259 image-text training set with both hard negative and hard positive
captions. By training with both, we see improvements on existing benchmarks
while simultaneously improving performance on hard positives, indicating a more
robust improvement in compositionality. Our work suggests the need for future
research to rigorously test and improve CLIP's understanding of semantic
relationships between related "positive" concepts.

摘要：多項基準已得出結論，我們的最佳視覺語言模型 (例如 CLIP) 缺乏組成性。給定一張圖像，這些基準會探討模型在組成式干擾項中識別其關聯標題的能力。作為回應，最近的一系列提案顯示，通過使用干擾項作為硬負例對 CLIP 進行微調可以改善模型。我們的調查顯示，這些改進實際上已被大幅誇大——因為現有的基準並未探討經過微調的視覺語言模型是否對硬正例保持不變。通過策劃一個包含 112,382 個硬負例和硬正例的評估資料集，我們發現包含硬正例會使 CLIP 的效能降低 12.9%，而人類則毫不費力地達到了 99%。使用硬負例微調的 CLIP 導致效能下降幅度更大，最高達 38.7%。有了這個發現，我們接著製作了一個包含硬負例和硬正例標題的 1,775,259 張圖像文字訓練集。通過同時使用這兩個標題進行訓練，我們看到現有基準有所改善，同時也改善了對硬正例的效能，這表示組成性有了更顯著的改善。我們的研究表明，未來需要進行嚴謹的測試和改進，以了解 CLIP 對相關「正向」概念之間語義關係的理解。

##### **Enhancing elusive clues in knowledge learning by contrasting attention of language models**
2409.17954v1 by Jian Gao, Xiao Zhang, Ji Wu, Miao Li

Causal language models acquire vast amount of knowledge from general text
corpus during pretraining, but the efficiency of knowledge learning is known to
be unsatisfactory, especially when learning from knowledge-dense and
small-sized corpora. The deficiency can come from long-distance dependencies
which are hard to capture by language models, and overfitting to co-occurrence
patterns and distracting clues in the training text. To address these issues,
the paper proposes a method to enhance knowledge learning during language model
pretraining, by enhancing elusive but important clues in text discovered by the
language model themselves. We found that larger language models pay more
attention to non-obvious but important clues, which are often overlooked by
smaller language models. Therefore, we can identify these clues by contrasting
the attention weights of large and small language models. We use the identified
clues as a guide to perform token-dropout data augmentation on the training
text, and observed a significant boost in both small and large models'
performance in fact memorization. This shows that the behavior contrast between
more and less-performant language models contains important clues for knowledge
learning, and it can be ``amplified" for a straight-forward improvement in
knowledge learning efficiency.

摘要：因果語言模型在預訓練期間從一般文字語料庫中獲取大量的知識，但已知知識學習的效率並不令人滿意，特別是在從知識密集且小型的語料庫中學習時。這種不足可能來自長距離依賴關係，語言模型難以捕捉，以及過度擬合訓練文本中的共現模式和令人分心的線索。為了解決這些問題，本文提出了一種方法來增強語言模型預訓練期間的知識學習，方法是增強語言模型本身發現的文本中難以捉摸但重要的線索。我們發現，較大的語言模型會更多地關注不顯眼但重要的線索，而這些線索通常會被較小的語言模型所忽略。因此，我們可以通過對比大小語言模型的注意力權重來識別這些線索。我們使用識別出的線索作為指南，對訓練文本執行權杖中斷數據擴充，並觀察到大小模型在事實記憶中的性能都有顯著提升。這表明，性能較高和較低的語言模型之間的行為對比包含了知識學習的重要線索，並且可以「放大」以直接提高知識學習效率。

##### **Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation**
2409.17946v1 by Shuai Zhao, Leilei Gan, Zhongliang Guo, Xiaobao Wu, Luwei Xiao, Xiaoyu Xu, Cong-Duy Nguyen, Luu Anh Tuan

Despite being widely applied due to their exceptional capabilities, Large
Language Models (LLMs) have been proven to be vulnerable to backdoor attacks.
These attacks introduce targeted vulnerabilities into LLMs by poisoning
training samples and full-parameter fine-tuning. However, this kind of backdoor
attack is limited since they require significant computational resources,
especially as the size of LLMs increases. Besides, parameter-efficient
fine-tuning (PEFT) offers an alternative but the restricted parameter updating
may impede the alignment of triggers with target labels. In this study, we
first verify that backdoor attacks with PEFT may encounter challenges in
achieving feasible performance. To address these issues and improve the
effectiveness of backdoor attacks with PEFT, we propose a novel backdoor attack
algorithm from weak to strong based on contrastive knowledge distillation
(W2SAttack). Specifically, we poison small-scale language models through
full-parameter fine-tuning to serve as the teacher model. The teacher model
then covertly transfers the backdoor to the large-scale student model through
contrastive knowledge distillation, which employs PEFT. Theoretical analysis
reveals that W2SAttack has the potential to augment the effectiveness of
backdoor attacks. We demonstrate the superior performance of W2SAttack on
classification tasks across four language models, four backdoor attack
algorithms, and two different architectures of teacher models. Experimental
results indicate success rates close to 100% for backdoor attacks targeting
PEFT.

摘要：儘管大型語言模型 (LLM) 因其卓越的能力而廣泛應用，但已證實它們容易受到後門攻擊。
這些攻擊透過毒害訓練樣本和全參數微調，將目標漏洞引入 LLM。
然而，這種後門攻擊受到限制，因為它們需要大量的計算資源，特別是當 LLM 的規模增加時。
此外，參數有效微調 (PEFT) 提供了一個替代方案，但受限的參數更新可能會阻礙觸發器與目標標籤的對齊。
在本研究中，我們首先驗證使用 PEFT 的後門攻擊在達成可行效能方面可能會遇到挑戰。
為了解決這些問題並提高使用 PEFT 的後門攻擊的有效性，我們提出了一種基於對比知識蒸餾 (W2SAttack) 的新穎後門攻擊演算法，從弱到強。
具體來說，我們透過全參數微調毒害小規模語言模型，作為教師模型。
然後，教師模型透過採用 PEFT 的對比知識蒸餾，將後門隱蔽地轉移到大型學生模型。
理論分析顯示，W2SAttack 有可能提升後門攻擊的有效性。
我們在四個語言模型、四個後門攻擊演算法和兩種不同的教師模型架構上，展示了 W2SAttack 在分類任務上的優異效能。
實驗結果表明，針對 PEFT 的後門攻擊的成功率接近 100%。

##### **On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms**
2409.17943v1 by Richard Yue, John E. Ortega, Kenneth Ward Church

The typical workflow for a professional translator to translate a document
from its source language (SL) to a target language (TL) is not always focused
on what many language models in natural language processing (NLP) do - predict
the next word in a series of words. While high-resource languages like English
and French are reported to achieve near human parity using common metrics for
measurement such as BLEU and COMET, we find that an important step is being
missed: the translation of technical terms, specifically acronyms. Some
state-of-the art machine translation systems like Google Translate which are
publicly available can be erroneous when dealing with acronyms - as much as 50%
in our findings. This article addresses acronym disambiguation for MT systems
by proposing an additional step to the SL-TL (FR-EN) translation workflow where
we first offer a new acronym corpus for public consumption and then experiment
with a search-based thresholding algorithm that achieves nearly 10% increase
when compared to Google Translate and OpusMT.

摘要：專業翻譯人員將文件從原始語言 (SL) 翻譯成目標語言 (TL) 的典型工作流程，並非總是專注於自然語言處理 (NLP) 中許多語言模型所執行的動作，即預測一系列字詞中的下一個字詞。雖然已報告使用常見測量指標（例如 BLEU 和 COMET）的高資源語言（例如英語和法語）可達到接近人類同等程度，但我們發現遺漏了一個重要的步驟：技術術語的翻譯，特別是縮寫。一些最先進的機器翻譯系統（例如 Google Translate）可供公眾使用，但在處理縮寫時可能會出現錯誤，根據我們的研究結果，高達 50%。本文透過建議在 SL-TL (FR-EN) 翻譯工作流程中新增一個步驟，來探討機器翻譯系統的縮寫消歧，首先我們提供一個新的縮寫語料庫供公眾使用，然後實驗一種基於搜尋的閾值演算法，與 Google Translate 和 OpusMT 相比，可提升近 10%。

##### **Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods**
2409.17939v1 by Richard Yue, John E. Ortega

Translation memories (TMs) are the backbone for professional translation
tools called computer-aided translation (CAT) tools. In order to perform a
translation using a CAT tool, a translator uses the TM to gather translations
similar to the desired segment to translate (s'). Many CAT tools offer a
fuzzy-match algorithm to locate segments (s) in the TM that are close in
distance to s'. After locating two similar segments, the CAT tool will present
parallel segments (s, t) that contain one segment in the source language along
with its translation in the target language. Additionally, CAT tools contain
fuzzy-match repair (FMR) techniques that will automatically use the parallel
segments from the TM to create new TM entries containing a modified version of
the original with the idea in mind that it will be the translation of s'. Most
FMR techniques use machine translation as a way of "repairing" those words that
have to be modified. In this article, we show that for a large part of those
words which are anchored, we can use other techniques that are based on machine
learning approaches such as Word2Vec. BERT, and even ChatGPT. Specifically, we
show that for anchored words that follow the continuous bag-of-words (CBOW)
paradigm, Word2Vec, BERT, and GPT-4 can be used to achieve similar and, for
some cases, better results than neural machine translation for translating
anchored words from French to English.

摘要：翻譯記憶體 (TM) 是稱為電腦輔助翻譯 (CAT) 工具的專業翻譯工具的骨幹。為了使用 CAT 工具進行翻譯，翻譯人員使用 TM 來收集與要翻譯的目標片段 (s') 相似的翻譯。許多 CAT 工具提供模糊比對演算法，用於在 TM 中找出與 s' 距離相近的片段 (s)。在找到兩個相似的片段後，CAT 工具會顯示平行片段 (s, t)，其中包含原始語言中的片段及其在目標語言中的翻譯。此外，CAT 工具包含模糊比對修復 (FMR) 技術，該技術將自動使用 TM 中的平行片段，建立包含原始版本修改版本的新 TM 項目，並考慮到它將是 s' 的翻譯。大多數 FMR 技術使用機器翻譯來「修復」必須修改的那些字詞。在本文中，我們展示對於那些錨定的字詞的大部分，我們可以使用其他基於機器學習方法的技術，例如 Word2Vec、BERT，甚至 ChatGPT。具體來說，我們展示對於遵循連續詞袋 (CBOW) 典範的錨定字詞，Word2Vec、BERT 和 GPT-4 可用於達成與神經機器翻譯類似的結果，在某些情況下，甚至可以達成更好的結果，用於將錨定字詞從法語翻譯成英語。

##### **Intelligent Energy Management: Remaining Useful Life Prediction and Charging Automation System Comprised of Deep Learning and the Internet of Things**
2409.17931v1 by Biplov Paneru, Bishwash Paneru, DP Sharma Mainali

Remaining Useful Life (RUL) of battery is an important parameter to know the
battery's remaining life and need for recharge. The goal of this research
project is to develop machine learning-based models for the battery RUL
dataset. Different ML models are developed to classify the RUL of the vehicle,
and the IoT (Internet of Things) concept is simulated for automating the
charging system and managing any faults aligning. The graphs plotted depict the
relationship between various vehicle parameters using the Blynk IoT platform.
Results show that the catboost, Multi-Layer Perceptron (MLP), Gated Recurrent
Unit (GRU), and hybrid model developed could classify RUL into three classes
with 99% more accuracy. The data is fed using the tkinter GUI for simulating
artificial intelligence (AI)-based charging, and with a pyserial backend, data
can be entered into the Esp-32 microcontroller for making charge discharge
possible with the model's predictions. Also, with an IoT system, the charging
can be disconnected, monitored, and analyzed for automation. The results show
that an accuracy of 99% can be obtained on models MLP, catboost model and
similar accuracy on GRU model can be obtained, and finally relay-based
triggering can be made by prediction through the model used for automating the
charging and energy-saving mechanism. By showcasing an exemplary Blynk
platform-based monitoring and automation phenomenon, we further present
innovative ways of monitoring parameters and automating the system.

摘要：電池的剩餘使用壽命 (RUL) 是了解電池剩餘壽命和充電需求的重要參數。本研究專案的目標是針對電池 RUL 資料集開發基於機器學習的模型。開發不同的 ML 模型來分類車輛的 RUL，並模擬物聯網 (IoT) 概念以自動化充電系統並管理任何故障對齊。繪製的圖表描繪了使用 Blynk IoT 平台的各種車輛參數之間的關係。結果顯示，開發的 catboost、多層感知器 (MLP)、門控遞迴單元 (GRU) 和混合模型可以將 RUL 分為三類，準確度高達 99%。資料使用 tkinter GUI 輸入，用於模擬基於人工智慧 (AI) 的充電，並透過 pyserial 後端，可以將資料輸入到 Esp-32 微控制器，以使用模型的預測進行充電放電。此外，透過 IoT 系統，可以斷開連接、監控和分析充電以進行自動化。結果顯示，可以在 MLP、catboost 模型上獲得 99% 的準確度，並且可以在 GRU 模型上獲得類似的準確度，最後可以透過用於自動化充電和節能機制的模型預測來進行基於繼電器的觸發。透過展示一個範例性的基於 Blynk 平台的監控和自動化現象，我們進一步展示了監控參數和自動化系統的創新方法。

##### **The Lou Dataset -- Exploring the Impact of Gender-Fair Language in German Text Classification**
2409.17929v1 by Andreas Waldis, Joel Birrer, Anne Lauscher, Iryna Gurevych

Gender-fair language, an evolving German linguistic variation, fosters
inclusion by addressing all genders or using neutral forms. Nevertheless, there
is a significant lack of resources to assess the impact of this linguistic
shift on classification using language models (LMs), which are probably not
trained on such variations. To address this gap, we present Lou, the first
dataset featuring high-quality reformulations for German text classification
covering seven tasks, like stance detection and toxicity classification.
Evaluating 16 mono- and multi-lingual LMs on Lou shows that gender-fair
language substantially impacts predictions by flipping labels, reducing
certainty, and altering attention patterns. However, existing evaluations
remain valid, as LM rankings of original and reformulated instances do not
significantly differ. While we offer initial insights on the effect on German
text classification, the findings likely apply to other languages, as
consistent patterns were observed in multi-lingual and English LMs.

摘要：性別友善語言，一種不斷演化的德語語言變體，通過針對所有性別或使用中性形式來促進包容性。儘管如此，在使用語言模型 (LM) 對這種語言轉變的影響進行評估時，仍然嚴重缺乏資源，而這些模型可能並未針對此類變體進行訓練。為了解決這一差距，我們提出了 Lou，這是第一個針對德語文本分類提供高品質重新表述功能的數據集，涵蓋立場檢測和毒性分類等七項任務。對 Lou 進行 16 種單語和多語言 LM 的評估表明，性別友善語言通過翻轉標籤、降低確定性和改變注意力模式，對預測產生了重大影響。然而，現有的評估仍然有效，因為原始和重新表述實例的 LM 排名沒有顯著差異。雖然我們對德語文本分類的影響提供了初步見解，但這些發現可能適用於其他語言，因為在多語言和英語 LM 中觀察到了相似的模式。

##### **Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion**
2409.17928v1 by Hengrui Gu, Kaixiong Zhou, Yili Wang, Ruobing Wang, Xin Wang

During pre-training, the Text-to-Image (T2I) diffusion models encode factual
knowledge into their parameters. These parameterized facts enable realistic
image generation, but they may become obsolete over time, thereby
misrepresenting the current state of the world. Knowledge editing techniques
aim to update model knowledge in a targeted way. However, facing the dual
challenges posed by inadequate editing datasets and unreliable evaluation
criterion, the development of T2I knowledge editing encounter difficulties in
effectively generalizing injected knowledge. In this work, we design a T2I
knowledge editing framework by comprehensively spanning on three phases: First,
we curate a dataset \textbf{CAKE}, comprising paraphrase and multi-object test,
to enable more fine-grained assessment on knowledge generalization. Second, we
propose a novel criterion, \textbf{adaptive CLIP threshold}, to effectively
filter out false successful images under the current criterion and achieve
reliable editing evaluation. Finally, we introduce \textbf{MPE}, a simple but
effective approach for T2I knowledge editing. Instead of tuning parameters, MPE
precisely recognizes and edits the outdated part of the conditioning
text-prompt to accommodate the up-to-date knowledge. A straightforward
implementation of MPE (Based on in-context learning) exhibits better overall
performance than previous model editors. We hope these efforts can further
promote faithful evaluation of T2I knowledge editing methods.

摘要：<paragraph>在預訓練期間，文字轉圖像 (T2I) 擴散模型將事實知識編碼到其參數中。這些參數化事實能產生逼真的圖像，但它們可能會隨著時間變得過時，從而錯誤地表示世界的當前狀態。知識編輯技術旨在以有針對性的方式更新模型知識。然而，面對不充分的編輯資料集和不可靠的評估標準所帶來的雙重挑戰，T2I 知識編輯的開發在有效概括注入知識方面遇到困難。在這項工作中，我們設計了一個 T2I 知識編輯框架，全面涵蓋三個階段：首先，我們策劃了一個資料集 \textbf{CAKE}，包含同義詞改寫和多物件測試，以對知識概括進行更細緻的評估。其次，我們提出了一個新的標準，\textbf{適應性 CLIP 閥值}，以在當前標準下有效地過濾掉錯誤的成功圖像，並實現可靠的編輯評估。最後，我們介紹了 \textbf{MPE}，一種簡單但有效的 T2I 知識編輯方法。MPE 不調整參數，而是精確地識別和編輯條件文字提示的過時部分，以容納最新的知識。MPE 的一個簡單實現（基於情境學習）表現出比以前模型編輯器更好的整體性能。我們希望這些努力能進一步促進對 T2I 知識編輯方法的忠實評估。</paragraph>

##### **Navigation in a simplified Urban Flow through Deep Reinforcement Learning**
2409.17922v1 by Federica Tonti, Jean Rabault, Ricardo Vinuesa

The increasing number of unmanned aerial vehicles (UAVs) in urban
environments requires a strategy to minimize their environmental impact, both
in terms of energy efficiency and noise reduction. In order to reduce these
concerns, novel strategies for developing prediction models and optimization of
flight planning, for instance through deep reinforcement learning (DRL), are
needed. Our goal is to develop DRL algorithms capable of enabling the
autonomous navigation of UAVs in urban environments, taking into account the
presence of buildings and other UAVs, optimizing the trajectories in order to
reduce both energetic consumption and noise. This is achieved using fluid-flow
simulations which represent the environment in which UAVs navigate and training
the UAV as an agent interacting with an urban environment. In this work, we
consider a domain domain represented by a two-dimensional flow field with
obstacles, ideally representing buildings, extracted from a three-dimensional
high-fidelity numerical simulation. The presented methodology, using PPO+LSTM
cells, was validated by reproducing a simple but fundamental problem in
navigation, namely the Zermelo's problem, which deals with a vessel navigating
in a turbulent flow, travelling from a starting point to a target location,
optimizing the trajectory. The current method shows a significant improvement
with respect to both a simple PPO and a TD3 algorithm, with a success rate (SR)
of the PPO+LSTM trained policy of 98.7%, and a crash rate (CR) of 0.1%,
outperforming both PPO (SR = 75.6%, CR=18.6%) and TD3 (SR=77.4% and CR=14.5%).
This is the first step towards DRL strategies which will guide UAVs in a
three-dimensional flow field using real-time signals, making the navigation
efficient in terms of flight time and avoiding damages to the vehicle.

摘要：隨著城市環境中無人機（UAV）數量的不斷增加，需要一種策略來最大程度地減少其環境影響，無論是在能源效率還是降噪方面。為了減少這些問題，需要採用新的策略來開發預測模型和優化飛行規劃，例如通過深度強化學習（DRL）。我們的目標是開發 DRL 演算法，使無人機能夠在城市環境中自主導航，同時考慮建築物和其他無人機的存在，優化軌跡以減少能量消耗和噪音。這是通過使用流體流動模擬來實現的，該模擬表示無人機導航的環境，並將無人機訓練為與城市環境交互的代理。在這項工作中，我們考慮了一個由具有障礙物的二維流場表示的域，這些障礙物理想地表示建築物，並從三維高保真數值模擬中提取。使用 PPO+LSTM 單元的所提出的方法通過重現導航中一個簡單但基本的難題得到了驗證，即 Zermelo 問題，該問題涉及在湍流中航行的船隻，從起點行駛到目標位置，優化軌跡。與簡單的 PPO 和 TD3 演算法相比，當前方法顯示出顯著的改進，PPO+LSTM 訓練策略的成功率 (SR) 為 98.7%，崩潰率 (CR) 為 0.1%，優於 PPO（SR = 75.6%，CR=18.6%）和 TD3（SR=77.4% 和 CR=14.5%）。這是朝著 DRL 策略邁出的第一步，該策略將使用實時訊號引導無人機在三維流場中，從而使導航在飛行時間方面變得高效，並避免對車輛造成損壞。

##### **Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect**
2409.17912v1 by Guokan Shang, Hadi Abdine, Yousef Khoubrane, Amr Mohamed, Yassine Abbahaddou, Sofiane Ennadir, Imane Momayiz, Xuguang Ren, Eric Moulines, Preslav Nakov, Michalis Vazirgiannis, Eric Xing

We introduce Atlas-Chat, the first-ever collection of large language models
specifically developed for dialectal Arabic. Focusing on Moroccan Arabic, also
known as Darija, we construct our instruction dataset by consolidating existing
Darija language resources, creating novel datasets both manually and
synthetically, and translating English instructions with stringent quality
control. Atlas-Chat-9B and 2B models, fine-tuned on the dataset, exhibit
superior ability in following Darija instructions and performing standard NLP
tasks. Notably, our models outperform both state-of-the-art and
Arabic-specialized LLMs like LLaMa, Jais, and AceGPT, e.g., achieving a 13%
performance boost over a larger 13B model on DarijaMMLU, in our newly
introduced evaluation suite for Darija covering both discriminative and
generative tasks. Furthermore, we perform an experimental analysis of various
fine-tuning strategies and base model choices to determine optimal
configurations. All our resources are publicly accessible, and we believe our
work offers comprehensive design methodologies of instruction-tuning for
low-resource language variants, which are often neglected in favor of data-rich
languages by contemporary LLMs.

摘要：我們介紹 Atlas-Chat，這是第一個專門為阿拉伯方言開發的大型語言模型集合。專注於摩洛哥阿拉伯語，也稱為 Darija，我們通過整合現有的 Darija 語言資源、手動和合成方式建立新穎的資料集，並在嚴格的品質控管下翻譯英文說明來建構我們的說明資料集。針對資料集進行微調的 Atlas-Chat-9B 和 2B 模型，在遵循 Darija 說明和執行標準 NLP 任務方面展現出卓越的能力。值得注意的是，我們的模型優於最先進和專精於阿拉伯語的 LLM，例如 LLaMa、Jais 和 AceGPT，例如在我們新推出的 Darija 評量套件中，在 DarijaMMLU 上比一個更大的 13B 模型提升了 13% 的效能，涵蓋區分性和生成性任務。此外，我們對各種微調策略和基礎模型選擇進行實驗分析，以確定最佳配置。我們所有的資源都可以公開取得，我們相信我們的成果提供了低資源語言變體的說明微調的全面設計方法，這些變體通常被當代 LLM 忽略，轉而採用資料豐富的語言。

##### **Learning to Love Edge Cases in Formative Math Assessment: Using the AMMORE Dataset and Chain-of-Thought Prompting to Improve Grading Accuracy**
2409.17904v1 by Owen Henkel, Hannah Horne-Robinson, Maria Dyshel, Nabil Ch, Baptiste Moreau-Pernet, Ralph Abood

This paper introduces AMMORE, a new dataset of 53,000 math open-response
question-answer pairs from Rori, a learning platform used by students in
several African countries and conducts two experiments to evaluate the use of
large language models (LLM) for grading particularly challenging student
answers. The AMMORE dataset enables various potential analyses and provides an
important resource for researching student math acquisition in understudied,
real-world, educational contexts. In experiment 1 we use a variety of
LLM-driven approaches, including zero-shot, few-shot, and chain-of-thought
prompting, to grade the 1% of student answers that a rule-based classifier
fails to grade accurately. We find that the best-performing approach --
chain-of-thought prompting -- accurately scored 92% of these edge cases,
effectively boosting the overall accuracy of the grading from 98.7% to 99.9%.
In experiment 2, we aim to better understand the consequential validity of the
improved grading accuracy, by passing grades generated by the best-performing
LLM-based approach to a Bayesian Knowledge Tracing (BKT) model, which estimated
student mastery of specific lessons. We find that relatively modest
improvements in model accuracy at the individual question level can lead to
significant changes in the estimation of student mastery. Where the rules-based
classifier currently used to grade student, answers misclassified the mastery
status of 6.9% of students across their completed lessons, using the LLM
chain-of-thought approach this misclassification rate was reduced to 2.6% of
students. Taken together, these findings suggest that LLMs could be a valuable
tool for grading open-response questions in K-12 mathematics education,
potentially enabling encouraging wider adoption of open-ended questions in
formative assessment.

摘要：本論文介紹了 AMMORE，這是一個包含 53,000 個數學開放式問答配對的新資料集，這些資料集來自 Rori，這是幾個非洲國家的學生所使用的學習平台，並進行了兩項實驗來評估使用大型語言模型 (LLM) 來評分特別具有挑戰性的學生答案。AMMORE 資料集啟用了各種潛在分析，並提供了研究學生數學能力在未被充分研究的現實世界教育環境中的重要資源。在實驗 1 中，我們使用各種 LLM 驅動的方法，包括零次學習、少次學習和思考鏈提示，來評分規則式分類器無法準確評分的 1% 學生答案。我們發現，表現最好的方法——思考鏈提示——準確地評分了這些邊緣案例的 92%，有效地將評分的整體準確度從 98.7% 提升至 99.9%。在實驗 2 中，我們旨在通過將表現最好的基於 LLM 的方法產生的成績傳遞給貝氏知識追蹤 (BKT) 模型，來更好地了解改進的評分準確性的後果有效性，該模型估計了學生對特定課程的掌握程度。我們發現，在個別問題層面上模型準確度的相對適度的改進可能會導致學生掌握程度估計的顯著變化。目前用於評分學生的基於規則的分類器錯誤地分類了學生在完成課程中的 6.9% 的掌握狀態，使用 LLM 思考鏈方法將此錯誤分類率降低至 2.6% 的學生。綜上所述，這些發現表明 LLM 可能是 K-12 數學教育中評分開放式問題的寶貴工具，有可能促進在形成性評估中更廣泛地採用開放式問題。

##### **Revisiting Acoustic Similarity in Emotional Speech and Music via Self-Supervised Representations**
2409.17899v1 by Yujia Sun, Zeyu Zhao, Korin Richmond, Yuanchao Li

Emotion recognition from speech and music shares similarities due to their
acoustic overlap, which has led to interest in transferring knowledge between
these domains. However, the shared acoustic cues between speech and music,
particularly those encoded by Self-Supervised Learning (SSL) models, remain
largely unexplored, given the fact that SSL models for speech and music have
rarely been applied in cross-domain research. In this work, we revisit the
acoustic similarity between emotion speech and music, starting with an analysis
of the layerwise behavior of SSL models for Speech Emotion Recognition (SER)
and Music Emotion Recognition (MER). Furthermore, we perform cross-domain
adaptation by comparing several approaches in a two-stage fine-tuning process,
examining effective ways to utilize music for SER and speech for MER. Lastly,
we explore the acoustic similarities between emotional speech and music using
Frechet audio distance for individual emotions, uncovering the issue of emotion
bias in both speech and music SSL models. Our findings reveal that while speech
and music SSL models do capture shared acoustic features, their behaviors can
vary depending on different emotions due to their training strategies and
domain-specificities. Additionally, parameter-efficient fine-tuning can enhance
SER and MER performance by leveraging knowledge from each other. This study
provides new insights into the acoustic similarity between emotional speech and
music, and highlights the potential for cross-domain generalization to improve
SER and MER systems.

摘要：由於語音和音樂在聲學上重疊，因此情緒辨識具有相似性，這導致了在這些領域之間轉移知識的興趣。然而，語音和音樂之間共享的聲學提示，特別是通過自我監督學習 (SSL) 模型編碼的那些，仍然在很大程度上未被探索，因為用於語音和音樂的 SSL 模型很少應用於跨領域研究。在這項工作中，我們重新審視了情緒語音和音樂之間的聲學相似性，從分析用於語音情緒辨識 (SER) 和音樂情緒辨識 (MER) 的 SSL 模型的逐層行為開始。此外，我們通過在兩階段微調過程中比較幾種方法來執行跨領域適應，探討了利用音樂進行 SER 和利用語音進行 MER 的有效方法。最後，我們使用個別情緒的 Frechet 音頻距離來探索情緒語音和音樂之間的聲學相似性，揭示了語音和音樂 SSL 模型中情緒偏差的問題。我們的研究結果表明，雖然語音和音樂 SSL 模型確實捕捉到了共享的聲學特徵，但由於它們的訓練策略和特定領域，它們的行為可能會因不同的情緒而異。此外，參數高效的微調可以通過利用彼此的知識來增強 SER 和 MER 的性能。這項研究提供了對情緒語音和音樂之間聲學相似性的新見解，並強調了跨領域概括以改進 SER 和 MER 系統的潛力。

##### **EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models**
2409.17892v1 by Shaoxiong Ji, Zihao Li, Indraneil Paul, Jaakko Paavola, Peiqin Lin, Pinzhen Chen, Dayyán O'Brien, Hengyu Luo, Hinrich Schütze, Jörg Tiedemann, Barry Haddow

In this work, we introduce EMMA-500, a large-scale multilingual language
model continue-trained on texts across 546 languages designed for enhanced
multilingual performance, focusing on improving language coverage for
low-resource languages. To facilitate continual pre-training, we compile the
MaLA corpus, a comprehensive multilingual dataset enriched with curated
datasets across diverse domains. Leveraging this corpus, we conduct extensive
continual pre-training of the Llama 2 7B model, resulting in EMMA-500, which
demonstrates robust performance across a wide collection of benchmarks,
including a comprehensive set of multilingual tasks and PolyWrite, an
open-ended generation benchmark developed in this study. Our results highlight
the effectiveness of continual pre-training in expanding large language models'
language capacity, particularly for underrepresented languages, demonstrating
significant gains in cross-lingual transfer, task generalization, and language
adaptability.

摘要：在這項工作中，我們介紹了 EMMA-500，這是一個經過 546 種語言訓練的大型多語言語言模型，專注於改善語言覆蓋範圍，以提升多語言效能，特別是低資源語言。為了促進持續預訓練，我們編譯了 MaLA 語料庫，這是一個全面的多語言資料集，其中包含了來自不同領域的策展資料集。利用這個語料庫，我們對 Llama 2 7B 模型進行廣泛的持續預訓練，產生了 EMMA-500，它在廣泛的基準集合中展示了強大的效能，包括一組全面的多語言任務和 PolyWrite，這是本研究中開發的開放式生成基準。我們的結果突顯了持續預訓練在擴展大型語言模型語言能力方面的有效性，特別是對於代表性不足的語言，證明了跨語言轉移、任務概化和語言適應性的顯著進步。

##### **Why Companies "Democratise" Artificial Intelligence: The Case of Open Source Software Donations**
2409.17876v1 by Cailean Osborne

Companies claim to "democratise" artificial intelligence (AI) when they
donate AI open source software (OSS) to non-profit foundations or release AI
models, among others, but what does this term mean and why do they do it? As
the impact of AI on society and the economy grows, understanding the commercial
incentives behind AI democratisation efforts is crucial for ensuring these
efforts serve broader interests beyond commercial agendas. Towards this end,
this study employs a mixed-methods approach to investigate commercial
incentives for 43 AI OSS donations to the Linux Foundation. It makes
contributions to both research and practice. It contributes a taxonomy of both
individual and organisational social, economic, and technological incentives
for AI democratisation. In particular, it highlights the role of democratising
the governance and control rights of an OSS project (i.e., from one company to
open governance) as a structural enabler for downstream goals, such as
attracting external contributors, reducing development costs, and influencing
industry standards, among others. Furthermore, OSS donations are often
championed by individual developers within companies, highlighting the
importance of the bottom-up incentives for AI democratisation. The taxonomy
provides a framework and toolkit for discerning incentives for other AI
democratisation efforts, such as the release of AI models. The paper concludes
with a discussion of future research directions.

摘要：<paragraph>公司聲稱「民主化」人工智慧 (AI)，當他們向非營利基金會捐贈 AI 開源軟體 (OSS) 或釋出 AI 模型時，但這個術語是什麼意思，他們為什麼這麼做？隨著 AI 對社會和經濟的影響越來越大，了解 AI 民主化努力背後的商業誘因對於確保這些努力服務於商業議程以外的更廣泛利益至關重要。為此，本研究採用混合方法來調查 Linux 基金會 43 個 AI OSS 捐贈的商業誘因。它對研究和實務都有所貢獻。它提供了一個分類法，包括個人和組織的社會、經濟和技術誘因，以實現 AI 民主化。特別是，它強調了民主化 OSS 專案治理和控制權（即從一家公司到開放治理）在吸引外部貢獻者、降低開發成本和影響產業標準等下游目標中作為結構性推動者的作用。此外，OSS 捐贈通常由公司內的個別開發人員大力支持，強調了自下而上誘因對 AI 民主化的重要性。該分類法提供了一個框架和工具包，用於辨別其他 AI 民主化努力的誘因，例如釋出 AI 模型。本文最後討論了未來的研究方向。</paragraph>

##### **DarkSAM: Fooling Segment Anything Model to Segment Nothing**
2409.17874v1 by Ziqi Zhou, Yufei Song, Minghui Li, Shengshan Hu, Xianlong Wang, Leo Yu Zhang, Dezhong Yao, Hai Jin

Segment Anything Model (SAM) has recently gained much attention for its
outstanding generalization to unseen data and tasks. Despite its promising
prospect, the vulnerabilities of SAM, especially to universal adversarial
perturbation (UAP) have not been thoroughly investigated yet. In this paper, we
propose DarkSAM, the first prompt-free universal attack framework against SAM,
including a semantic decoupling-based spatial attack and a texture
distortion-based frequency attack. We first divide the output of SAM into
foreground and background. Then, we design a shadow target strategy to obtain
the semantic blueprint of the image as the attack target. DarkSAM is dedicated
to fooling SAM by extracting and destroying crucial object features from images
in both spatial and frequency domains. In the spatial domain, we disrupt the
semantics of both the foreground and background in the image to confuse SAM. In
the frequency domain, we further enhance the attack effectiveness by distorting
the high-frequency components (i.e., texture information) of the image.
Consequently, with a single UAP, DarkSAM renders SAM incapable of segmenting
objects across diverse images with varying prompts. Experimental results on
four datasets for SAM and its two variant models demonstrate the powerful
attack capability and transferability of DarkSAM.

摘要：分段任何模型 (SAM) 近期因其对未见数据和任务的出色泛化而备受关注。尽管其前景光明，但 SAM 的漏洞，尤其是对通用对抗扰动 (UAP) 的漏洞尚未得到彻底调查。在本文中，我们提出了 DarkSAM，这是针对 SAM 的第一个无提示通用攻击框架，包括基于语义解耦的空间攻击和基于纹理失真的频率攻击。我们首先将 SAM 的输出划分为前景和背景。然后，我们设计了一个阴影目标策略来获得图像的语义蓝图作为攻击目标。DarkSAM 致力于通过从图像中提取和破坏空间和频率域中的关键对象特征来欺骗 SAM。在空间域中，我们破坏图像中前景和背景的语义以混淆 SAM。在频率域中，我们通过扭曲图像的高频分量（即纹理信息）进一步增强攻击效果。因此，通过一个 UAP，DarkSAM 使 SAM 无法对具有不同提示的各种图像进行分割。在针对 SAM 及其两个变体模型的四个数据集上的实验结果证明了 DarkSAM 的强大攻击能力和可迁移性。

##### **Efficient Arbitrary Precision Acceleration for Large Language Models on GPU Tensor Cores**
2409.17870v1 by Shaobo Ma, Chao Fang, Haikuo Shao, Zhongfeng Wang

Large language models (LLMs) have been widely applied but face challenges in
efficient inference. While quantization methods reduce computational demands,
ultra-low bit quantization with arbitrary precision is hindered by limited GPU
Tensor Core support and inefficient memory management, leading to suboptimal
acceleration. To address these challenges, we propose a comprehensive
acceleration scheme for arbitrary precision LLMs. At its core, we introduce a
novel bipolar-INT data format that facilitates parallel computing and supports
symmetric quantization, effectively reducing data redundancy. Building on this,
we implement an arbitrary precision matrix multiplication scheme that
decomposes and recovers matrices at the bit level, enabling flexible precision
while maximizing GPU Tensor Core utilization. Furthermore, we develop an
efficient matrix preprocessing method that optimizes data layout for subsequent
computations. Finally, we design a data recovery-oriented memory management
system that strategically utilizes fast shared memory, significantly enhancing
kernel execution speed and minimizing memory access latency. Experimental
results demonstrate our approach's effectiveness, with up to 13\times speedup
in matrix multiplication compared to NVIDIA's CUTLASS. When integrated into
LLMs, we achieve up to 6.7\times inference acceleration. These improvements
significantly enhance LLM inference efficiency, enabling broader and more
responsive applications of LLMs.

摘要：大型語言模型 (LLM) 已廣泛應用，但在高效推理方面面臨挑戰。雖然量化方法可以減少計算需求，但任意精度的超低位元量化受到 GPU Tensor Core 支援有限和記憶體管理效率低下的阻礙，導致加速效果不佳。為了應對這些挑戰，我們提出了一種針對任意精度 LLM 的全面加速方案。其核心是，我們引入一種新穎的雙極 INT 資料格式，它促進平行運算並支援對稱量化，有效地減少了資料冗餘。在此基礎上，我們實作了一種任意精度矩陣乘法方案，它在位元層級分解和恢復矩陣，同時實現靈活的精度並最大化 GPU Tensor Core 的利用率。此外，我們開發了一種高效的矩陣預處理方法，它會針對後續運算最佳化資料配置。最後，我們設計了一個以資料復原為導向的記憶體管理系統，它策略性地利用快速的共享記憶體，顯著地提高了核心執行速度並將記憶體存取延遲降到最低。實驗結果證明了我們方法的有效性，與 NVIDIA 的 CUTLASS 相比，矩陣乘法速度提升了 13 倍。當整合到 LLM 中時，我們實現了高達 6.7 倍的推理加速。這些改進顯著提升了 LLM 推理效率，讓 LLM 能有更廣泛且更靈敏的應用。

##### **A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios**
2409.17864v1 by Christian Ganhör, Marta Moscati, Anna Hausberger, Shah Nawaz, Markus Schedl

Most recommender systems adopt collaborative filtering (CF) and provide
recommendations based on past collective interactions. Therefore, the
performance of CF algorithms degrades when few or no interactions are
available, a scenario referred to as cold-start. To address this issue,
previous work relies on models leveraging both collaborative data and side
information on the users or items. Similar to multimodal learning, these models
aim at combining collaborative and content representations in a shared
embedding space. In this work we propose a novel technique for multimodal
recommendation, relying on a multimodal Single-Branch embedding network for
Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction
data as well as multimodal side information using the same single-branch
embedding network on different modalities. This makes SiBraR effective in
scenarios of missing modality, including cold start. Our extensive experiments
on large-scale recommendation datasets from three different recommendation
domains (music, movie, and e-commerce) and providing multimodal content
information (audio, text, image, labels, and interactions) show that SiBraR
significantly outperforms CF as well as state-of-the-art content-based RSs in
cold-start scenarios, and is competitive in warm scenarios. We show that
SiBraR's recommendations are accurate in missing modality scenarios, and that
the model is able to map different modalities to the same region of the shared
embedding space, hence reducing the modality gap.

摘要：大多數推薦系統採用協同過濾（CF），並根據過去的集體互動提供建議。因此，當互動很少或根本沒有互動時，CF 演算法的效能會下降，這種情況稱為冷啟動。為了解決這個問題，先前的研究依賴於利用協同資料和使用者或項目側邊資訊的模型。與多模態學習類似，這些模型旨在將協同和內容表示結合在共享嵌入空間中。在這項研究中，我們提出了一種多模態推薦的新技術，依賴於用於推薦的多模態單分支嵌入網路（SiBraR）。SiBraR 利用權重共享，使用相同的單分支嵌入網路對不同模態的互動資料和多模態側邊資訊進行編碼。這使得 SiBraR 在遺失模態的情況下（包括冷啟動）有效。我們針對來自三個不同推薦領域（音樂、電影和電子商務）的大規模推薦資料集進行的廣泛實驗，並提供多模態內容資訊（音訊、文字、影像、標籤和互動），顯示 SiBraR 在冷啟動情況下顯著優於 CF 以及最先進的基於內容的 RS，並且在熱啟動情況下具有競爭力。我們展示了 SiBraR 的推薦在遺失模態情況下是準確的，並且該模型能夠將不同的模態對應到共享嵌入空間的相同區域，從而縮小模態差距。

##### **Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models**
2409.17836v1 by Hui-Po Wang, Mario Fritz

Despite the widespread use of statistical prior models in various fields,
such models for neural network gradients have long been overlooked. The
inherent challenge stems from their high-dimensional structures and complex
interdependencies, which complicate effective modeling. In this work, we
demonstrate the potential of large language models (LLMs) to act as gradient
priors in a zero-shot setting. We examine the property by considering lossless
gradient compression -- a critical application in distributed learning -- that
depends heavily on precise probability modeling. To achieve this, we introduce
LM-GC, a novel method that integrates LLMs with arithmetic coding. Our
technique converts plain gradients into text-like formats, enhancing token
efficiency by up to 38 times compared to their plain representations. We ensure
that this data conversion maintains a close alignment with the structure of
plain gradients and the symbols commonly recognized by LLMs. Our experiments
indicate that LM-GC surpasses existing state-of-the-art lossless compression
methods, improving compression rates by 10\% up to 17.2\% across various
datasets and architectures. Additionally, our approach shows promising
compatibility with lossy compression techniques such as quantization and
sparsification. These findings highlight the significant potential of LLMs as a
model for effectively handling gradients. We will release the source code upon
publication.

摘要：儘管統計先驗模型在各個領域廣泛使用，
但長期以來，神經網路梯度的模型卻一直被忽略。其固有的挑戰在於它們的高維度結構和複雜的相互依賴性，這使得有效的建模變得複雜。在這項工作中，我們展示了大型語言模型 (LLM) 在零次學習中作為梯度先驗的潛力。我們透過考慮無失真梯度壓縮來檢驗此特性，無失真梯度壓縮是分佈式學習中的一項關鍵應用，它高度依賴於精確的機率建模。為此，我們引入了 LM-GC，這是一種將 LLM 與算術編碼整合起來的新方法。我們的技術將純粹的梯度轉換成類文字的格式，與其純粹的表示相比，將代碼效率提高了 38 倍。我們確保此資料轉換與純粹梯度的結構和 LLM 常識別的符號保持緊密的一致性。我們的實驗表明，LM-GC 超越了現有的最先進無失真壓縮方法，在各種資料集和架構中將壓縮率提高了 10% 至 17.2%。此外，我們的做法顯示出與有損壓縮技術（例如量化和稀疏化）有望相容。這些發現突顯了 LLM 作為有效處理梯度的模型的顯著潛力。我們將在發表後釋出原始碼。

##### **PEDRO: Parameter-Efficient Fine-tuning with Prompt DEpenDent Representation MOdification**
2409.17834v1 by Tianfang Xie, Tianjing Li, Wei Zhu, Wei Han, Yi Zhao

Due to their substantial sizes, large language models (LLMs) are typically
deployed within a single-backbone multi-tenant framework. In this setup, a
single instance of an LLM backbone must cater to multiple users or tasks
through the application of various parameter-efficient fine-tuning (PEFT)
models. Despite the availability of numerous effective PEFT techniques such as
LoRA, there remains a need for a PEFT approach that achieves both high
efficiency during inference and competitive performance on downstream tasks. In
this research, we introduce a new and straightforward PEFT methodology named
\underline{P}rompt D\underline{E}pen\underline{D}ent \underline{R}epresentation
M\underline{O}dification (PEDRO). The proposed method involves integrating a
lightweight vector generator into each Transformer layer, which generates
vectors contingent upon the input prompts. These vectors then modify the hidden
representations created by the LLM through a dot product operation, thereby
influencing the semantic output and generated content of the model. Extensive
experimentation across a variety of tasks indicates that: (a) PEDRO surpasses
recent PEFT benchmarks when using a similar number of tunable parameters. (b)
Under the single-backbone multi-tenant deployment model, PEDRO exhibits
superior efficiency compared to LoRA, indicating significant industrial
potential.

摘要：由於大型語言模型 (LLM) 規模龐大，因此通常會部署在單一主幹多租戶架構中。在這種架構中，LLM 主幹的單一執行個體必須透過應用各種參數有效微調 (PEFT) 模型來滿足多個使用者或任務。儘管有許多有效的 PEFT 技術可用，例如 LoRA，但仍需要一種 PEFT 方法，既能在推理過程中實現高效率，又能在下游任務中展現競爭力。在本研究中，我們引入了一種新的、直接的 PEFT 方法，稱為提示依賴表示修改 (PEDRO)。所提出的方法涉及將輕量級向量產生器整合到每個 Transformer 層中，該產生器會根據輸入提示產生向量。然後，這些向量透過點積運算修改 LLM 所建立的隱藏表示，從而影響模型的語義輸出和產生的內容。透過各種任務的大量實驗，結果顯示：(a) PEDRO 在使用類似數量可調整參數時，超越了最近的 PEFT 基準。(b) 在單一主幹多租戶部署模式下，PEDRO 展現出優於 LoRA 的效率，顯示出顯著的產業潛力。

##### **BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text**
2409.17827v1 by Siyan Wang, Bradford Levy

Many of the recent breakthroughs in language modeling have resulted from
scaling effectively the same model architecture to larger datasets. In this
vein, recent work has highlighted performance gains from increasing training
dataset size and quality, suggesting a need for novel sources of large-scale
datasets. In this work, we introduce BeanCounter, a public dataset consisting
of more than 159B tokens extracted from businesses' disclosures. We show that
this data is indeed novel: less than 0.1% of BeanCounter appears in Common
Crawl-based datasets and it is an order of magnitude larger than datasets
relying on similar sources. Given the data's provenance, we hypothesize that
BeanCounter is comparatively more factual and less toxic than web-based
datasets. Exploring this hypothesis, we find that many demographic identities
occur with similar prevalence in BeanCounter but with significantly less toxic
context relative to other datasets. To demonstrate the utility of BeanCounter,
we evaluate and compare two LLMs continually pre-trained on BeanCounter with
their base models. We find an 18-33% reduction in toxic generation and improved
performance within the finance domain for the continually pretrained models.
Collectively, our work suggests that BeanCounter is a novel source of
low-toxicity and high-quality domain-specific data with sufficient scale to
train multi-billion parameter LLMs.

摘要：最近语言模型的许多突破，都是源自于将相同的模型架构有效地扩展到更大的数据集。在这个方面，最近的研究强调了通过增加训练数据集的大小和质量而获得的性能提升，这表明需要新的、大规模数据集来源。在这项工作中，我们介绍了 BeanCounter，这是一个公共数据集，包含从企业披露中提取的超过 1590 亿个标记。我们表明，这些数据确实是新颖的：不到 0.1% 的 BeanCounter 出现在基于 Common Crawl 的数据集中，并且它的数量级比依赖于类似来源的数据集大一个数量级。鉴于数据的来源，我们假设 BeanCounter 相对而言比基于 Web 的数据集更具事实性，且毒性更小。在探索这一假设时，我们发现许多人口统计标识在 BeanCounter 中出现的频率相似，但与其他数据集相比，其毒性语境明显较少。为了证明 BeanCounter 的效用，我们评估并比较了两个在 BeanCounter 上持续预训练的 LLM 及其基础模型。我们发现，持续预训练的模型的毒性生成减少了 18-33%，并且在金融领域的性能得到了提升。总的来说，我们的工作表明 BeanCounter 是一个新的、低毒性和高质量的特定领域数据源，其规模足以训练数十亿参数的 LLM。

##### **Inference-Time Language Model Alignment via Integrated Value Guidance**
2409.17819v1 by Zhixuan Liu, Zhanhui Zhou, Yuanfu Wang, Chao Yang, Yu Qiao

Large language models are typically fine-tuned to align with human
preferences, but tuning large models is computationally intensive and complex.
In this work, we introduce $\textit{Integrated Value Guidance}$ (IVG), a method
that uses implicit and explicit value functions to guide language model
decoding at token and chunk-level respectively, efficiently aligning large
language models purely at inference time. This approach circumvents the
complexities of direct fine-tuning and outperforms traditional methods.
Empirically, we demonstrate the versatility of IVG across various tasks. In
controlled sentiment generation and summarization tasks, our method
significantly improves the alignment of large models using inference-time
guidance from $\texttt{gpt2}$-based value functions. Moreover, in a more
challenging instruction-following benchmark AlpacaEval 2.0, we show that both
specifically tuned and off-the-shelf value functions greatly improve the
length-controlled win rates of large models against $\texttt{gpt-4-turbo}$
(e.g., $19.51\% \rightarrow 26.51\%$ for $\texttt{Mistral-7B-Instruct-v0.2}$
and $25.58\% \rightarrow 33.75\%$ for $\texttt{Mixtral-8x7B-Instruct-v0.1}$
with Tulu guidance).

摘要：大型語言模型通常經過微調以符合人類偏好，但調整大型模型在計算上很密集且複雜。在這項工作中，我們介紹了「整合價值引導」(IVG)，一種使用隱式和顯式價值函數來分別在符號和區塊層級引導語言模型解碼的方法，有效地在純粹的推論時間調整大型語言模型。這種方法避開了直接微調的複雜性，並且優於傳統方法。根據經驗，我們展示了 IVG 在各種任務中的多功能性。在受控情緒生成和摘要任務中，我們的方法使用基於 gpt2 的價值函數的推論時間引導，顯著改善了大型模型的對齊。此外，在更具挑戰性的指令遵循基準 AlpacaEval 2.0 中，我們表明專門調整和現成的價值函數都大大提高了大型模型對 gpt-4-turbo 的長度控制勝率（例如，Mistral-7B-Instruct-v0.2 為 19.51% → 26.51%，Mixtral-8x7B-Instruct-v0.1 使用 Tulu 指導為 25.58% → 33.75%）。

##### **DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**
2409.17815v1 by Rabindra Khadka, Pedro G Lind, Anis Yazidi, Asma Belhadi

Electroencephalography (EEG) data provides a non-invasive method for
researchers and clinicians to observe brain activity in real time. The
integration of deep learning techniques with EEG data has significantly
improved the ability to identify meaningful patterns, leading to valuable
insights for both clinical and research purposes. However, most of the
frameworks so far, designed for EEG data analysis, are either too focused on
pre-processing or in deep learning methods per, making their use for both
clinician and developer communities problematic. Moreover, critical issues such
as ethical considerations, biases, uncertainties, and the limitations inherent
in AI models for EEG data analysis are frequently overlooked, posing challenges
to the responsible implementation of these technologies. In this paper, we
introduce a comprehensive deep learning framework tailored for EEG data
processing, model training and report generation. While constructed in way to
be adapted and developed further by AI developers, it enables to report,
through model cards, the outcome and specific information of use for both
developers and clinicians. In this way, we discuss how this framework can, in
the future, provide clinical researchers and developers with the tools needed
to create transparent and accountable AI models for EEG data analysis and
diagnosis.

摘要：腦電圖 (EEG) 數據提供了一種非侵入式方法，讓研究人員和臨床醫生可以即時觀察大腦活動。深度學習技術與腦電圖數據的整合，顯著提升了識別有意義模式的能力，進而產生了有價值的見解，可用於臨床和研究目的。然而，到目前為止，大多數專門設計用於腦電圖數據分析的架構，都過於專注於預處理或深度學習方法，導致臨床醫生和開發人員社群難以使用。此外，腦電圖數據分析中的人工智慧模型固有的倫理考量、偏見、不確定性和限制等關鍵問題，經常被忽略，對這些技術的負責任實作構成了挑戰。在本文中，我們介紹了一個專為腦電圖數據處理、模型訓練和報告產生的綜合性深度學習架構。這個架構的建構方式，讓人工智慧開發人員可以進一步調整和開發，並能透過模型卡報告結果和特定資訊，供開發人員和臨床醫生使用。透過這種方式，我們探討這個架構在未來如何能為臨床研究人員和開發人員提供必要的工具，以建立透明且負責任的人工智慧模型，用於腦電圖數據分析和診斷。

##### **Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness**
2409.17791v1 by Jian Li, Haojing Huang, Yujia Zhang, Pengfei Xu, Xi Chen, Rui Song, Lida Shi, Jingwen Wang, Hao Xu

Recently, there has been significant interest in replacing the reward model
in Reinforcement Learning with Human Feedback (RLHF) methods for Large Language
Models (LLMs), such as Direct Preference Optimization (DPO) and its variants.
These approaches commonly use a binary cross-entropy mechanism on pairwise
samples, i.e., minimizing and maximizing the loss based on preferred or
dis-preferred responses, respectively. However, while this training strategy
omits the reward model, it also overlooks the varying preference degrees within
different responses. We hypothesize that this is a key factor hindering LLMs
from sufficiently understanding human preferences. To address this problem, we
propose a novel Self-supervised Preference Optimization (SPO) framework, which
constructs a self-supervised preference degree loss combined with the alignment
loss, thereby helping LLMs improve their ability to understand the degree of
preference. Extensive experiments are conducted on two widely used datasets of
different tasks. The results demonstrate that SPO can be seamlessly integrated
with existing preference optimization methods and significantly boost their
performance to achieve state-of-the-art performance. We also conduct detailed
analyses to offer comprehensive insights into SPO, which verifies its
effectiveness. The code is available at https://github.com/lijian16/SPO.

摘要：最近，人们对用人类反馈（RLHF）方法取代强化学习中的奖励模型产生了浓厚的兴趣，例如直接偏好优化（DPO）及其变体。这些方法通常对成对样本使用二元交叉熵机制，即根据偏好或非偏好响应分别最小化和最大化损失。然而，虽然这种训练策略省略了奖励模型，但它也忽略了不同响应中的不同偏好程度。我们假设这是阻碍 LLM 充分理解人类偏好的一个关键因素。为了解决这个问题，我们提出了一种新颖的自监督偏好优化（SPO）框架，该框架构建了一个自监督偏好程度损失，并与对齐损失相结合，从而帮助 LLM 提高其理解偏好程度的能力。在两个广泛使用的数据集上进行了针对不同任务的广泛实验。结果表明，SPO 可以与现有的偏好优化方法无缝集成，并显著提升其性能以达到最先进的性能。我们还进行了详细的分析，以提供对 SPO 的全面见解，验证了其有效性。代码可在 https://github.com/lijian16/SPO 获得。

##### **Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations**
2409.17774v1 by Supriya Manna, Niladri Sett

Faithfulness is arguably the most critical metric to assess the reliability
of explainable AI. In NLP, current methods for faithfulness evaluation are
fraught with discrepancies and biases, often failing to capture the true
reasoning of models. We introduce Adversarial Sensitivity as a novel approach
to faithfulness evaluation, focusing on the explainer's response when the model
is under adversarial attack. Our method accounts for the faithfulness of
explainers by capturing sensitivity to adversarial input changes. This work
addresses significant limitations in existing evaluation techniques, and
furthermore, quantifies faithfulness from a crucial yet underexplored paradigm.

摘要：忠實度可以說是評估可解釋 AI 可靠性的最重要指標。在 NLP 中，當前用於評估忠實度的各種方法充斥著差異和偏見，常常無法捕捉到模型的真正推理。我們引入了對抗敏感度，作為忠實度評估的一種新方法，重點關注模型在對抗攻擊下的解釋器的反應。我們的這種方法透過捕捉對抗輸入變化的敏感度來考量解釋器的忠實度。這項工作解決了現有評估技術的重大限制，此外，還從一個至關重要但尚未充分探索的範例量化了忠實度。

##### **Federated Learning under Attack: Improving Gradient Inversion for Batch of Images**
2409.17767v1 by Luiz Leite, Yuri Santo, Bruno L. Dalmazo, André Riker

Federated Learning (FL) has emerged as a machine learning approach able to
preserve the privacy of user's data. Applying FL, clients train machine
learning models on a local dataset and a central server aggregates the learned
parameters coming from the clients, training a global machine learning model
without sharing user's data. However, the state-of-the-art shows several
approaches to promote attacks on FL systems. For instance, inverting or leaking
gradient attacks can find, with high precision, the local dataset used during
the training phase of the FL. This paper presents an approach, called Deep
Leakage from Gradients with Feedback Blending (DLG-FB), which is able to
improve the inverting gradient attack, considering the spatial correlation that
typically exists in batches of images. The performed evaluation shows an
improvement of 19.18% and 48,82% in terms of attack success rate and the number
of iterations per attacked image, respectively.

摘要：聯合學習 (FL) 已成為一種機器學習方法，能夠保護使用者資料的隱私。應用 FL，客戶端會在本地資料集上訓練機器學習模型，而中央伺服器會彙總來自客戶端的已學習參數，訓練全球機器學習模型，而不會分享使用者的資料。然而，最先進的技術展示了數種促進攻擊 FL 系統的方法。例如，反轉或洩漏梯度攻擊可以非常精確地找出 FL 訓練階段中使用的本地資料集。本文提出了一種方法，稱為具有回饋混合的梯度深度洩漏 (DLG-FB)，它能夠改善反轉梯度攻擊，考慮到影像批次中通常存在的空間關聯性。執行評估顯示，在攻擊成功率和每個攻擊影像的迭代次數方面，分別改善了 19.18% 和 48,82%。

##### **Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**
2409.17763v1 by Evangelia Christodoulou, Annika Reinke, Rola Houhou, Piotr Kalinowski, Selen Erkan, Carole H. Sudre, Ninon Burgos, Sofiène Boutaj, Sophie Loizillon, Maëlys Solal, Nicola Rieke, Veronika Cheplygina, Michela Antonelli, Leon D. Mayer, Minu D. Tizabi, M. Jorge Cardoso, Amber Simpson, Paul F. Jäger, Annette Kopp-Schneider, Gaël Varoquaux, Olivier Colliot, Lena Maier-Hein

Medical imaging is spearheading the AI transformation of healthcare.
Performance reporting is key to determine which methods should be translated
into clinical practice. Frequently, broad conclusions are simply derived from
mean performance values. In this paper, we argue that this common practice is
often a misleading simplification as it ignores performance variability. Our
contribution is threefold. (1) Analyzing all MICCAI segmentation papers (n =
221) published in 2023, we first observe that more than 50\% of papers do not
assess performance variability at all. Moreover, only one (0.5\%) paper
reported confidence intervals (CIs) for model performance. (2) To address the
reporting bottleneck, we show that the unreported standard deviation (SD) in
segmentation papers can be approximated by a second-order polynomial function
of the mean Dice similarity coefficient (DSC). Based on external validation
data from 56 previous MICCAI challenges, we demonstrate that this approximation
can accurately reconstruct the CI of a method using information provided in
publications. (3) Finally, we reconstructed 95\% CIs around the mean DSC of
MICCAI 2023 segmentation papers. The median CI width was 0.03 which is three
times larger than the median performance gap between the first and second
ranked method. For more than 60\% of papers, the mean performance of the
second-ranked method was within the CI of the first-ranked method. We conclude
that current publications typically do not provide sufficient evidence to
support which models could potentially be translated into clinical practice.

摘要：醫療影像正帶領 AI 轉型醫療保健。
效能報告是決定哪些方法應轉譯至臨床實務的關鍵。通常，廣泛的結論僅來自於平均效能值。在這篇論文中，我們主張這個常見的實務通常是誤導性的簡化，因為它忽略了效能變異性。我們的貢獻有三方面。(1) 分析所有 2023 年發表的 MICCAI 分割論文 (n = 221)，我們首先觀察到超過 50% 的論文完全沒有評估效能變異性。此外，僅有一篇 (0.5%) 論文報告了模型效能的信賴區間 (CI)。(2) 為了解決報告瓶頸，我們顯示分割論文中未報告的標準差 (SD) 可以近似為平均 Dice 相似係數 (DSC) 的二階多項式函數。根據來自 56 個先前 MICCAI 挑戰的外部驗證資料，我們證明此近似值可以使用出版品中提供的資訊準確地重建方法的 CI。(3) 最後，我們在 MICCAI 2023 分割論文的平均 DSC 周圍重建了 95% CI。中位數 CI 寬度為 0.03，是第一名和第二名方法之間的中位數效能差距的三倍。對於超過 60% 的論文，第二名方法的平均效能落在第一名方法的 CI 內。我們得出結論，目前的出版品通常沒有提供足夠的證據來支持哪些模型有可能轉譯至臨床實務。

##### **Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation**
2409.17757v1 by Qin Wang, Jianzhou Feng, Yiming Xu

Manifestly and logically displaying the line of reasoning from evidence to
answer is significant to explainable question answering (QA). The entailment
tree exhibits the lines structurally, which is different from the
self-explanation principle in large-scale language models. Existing methods
rarely consider the semantic association of sentences between and within
hierarchies within the tree structure, which is prone to apparent mistakes in
combinations. In this work, we propose an architecture of integrating the
Hierarchical Semantics of sentences under the framework of Controller-Generator
(HiSCG) to explain answers. The HiSCG designs a hierarchical mapping between
hypotheses and facts, discriminates the facts involved in tree constructions,
and optimizes single-step entailments. To the best of our knowledge, We are the
first to notice hierarchical semantics of sentences between the same layer and
adjacent layers to yield improvements. The proposed method achieves comparable
performance on all three settings of the EntailmentBank dataset. The
generalization results on two out-of-domain datasets also demonstrate the
effectiveness of our method.

摘要：明確且有條理地展示證據到答案的推理過程，對於可解釋問題解答 (QA) 來說非常重要。蘊涵樹以結構化的方式展示這些過程，這不同於大型語言模型中的自我解釋原則。現有方法很少考慮樹狀結構中層級之間和層級內的句子語義關聯，這很容易導致組合中的明顯錯誤。在這項工作中，我們提出了一種架構，將句子層級語義整合到控制器生成器 (HiSCG) 架構中，以解釋答案。HiSCG 設計了一個假設和事實之間的層級對應，區分樹狀結構中涉及的事實，並最佳化單步蘊涵。據我們所知，我們是第一個注意到同一層級和相鄰層級之間句子的層級語義，以產生改進。所提出的方法在 EntailmentBank 資料集的所有三種設定中都達到了相當的效能。在兩個領域外資料集上的概化結果也證明了我們方法的有效性。

##### **SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning**
2409.17755v1 by Rimvydas Rubavicius, Peter David Fagan, Alex Lascarides, Subramanian Ramamoorthy

This paper addresses a challenging interactive task learning scenario we call
rearrangement under unawareness: to manipulate a rigid-body environment in a
context where the robot is unaware of a concept that's key to solving the
instructed task. We propose SECURE, an interactive task learning framework
designed to solve such problems by fixing a deficient domain model using
embodied conversation. Through dialogue, the robot discovers and then learns to
exploit unforeseen possibilities. Using SECURE, the robot not only learns from
the user's corrective feedback when it makes a mistake, but it also learns to
make strategic dialogue decisions for revealing useful evidence about novel
concepts for solving the instructed task. Together, these abilities allow the
robot to generalise to subsequent tasks using newly acquired knowledge. We
demonstrate that a robot that is semantics-aware -- that is, it exploits the
logical consequences of both sentence and discourse semantics in the learning
and inference process -- learns to solve rearrangement under unawareness more
effectively than a robot that lacks such capabilities.

摘要：這篇論文探討了一個我們稱之為在不知情狀態下重新排列的具有挑戰性的互動式任務學習場景：在機器人不知道解決指示任務的關鍵概念的情況下操作剛體環境。我們提出 SECURE，一個互動式任務學習框架，旨在透過具體對話來修復有缺陷的領域模型，進而解決此類問題。透過對話，機器人發現並學會利用無法預見的可能性。透過使用 SECURE，機器人不僅可以從使用者在它犯錯時的糾正回饋中學習，它也學會對揭露有關解決指示任務的新概念的有用證據做出策略性對話決策。這些能力加起來，讓機器人能夠使用新獲得的知識推廣到後續任務。我們證明了一個語義感知的機器人，也就是說，它利用句子和語篇語義在學習和推理過程中產生的邏輯後果，學會在不知情狀態下比缺乏這種能力的機器人更有效地解決重新排列。

##### **Byzantine-Robust Aggregation for Securing Decentralized Federated Learning**
2409.17754v1 by Diego Cajaraville-Aboy, Ana Fernández-Vilas, Rebeca P. Díaz-Redondo, Manuel Fernández-Veiga

Federated Learning (FL) emerges as a distributed machine learning approach
that addresses privacy concerns by training AI models locally on devices.
Decentralized Federated Learning (DFL) extends the FL paradigm by eliminating
the central server, thereby enhancing scalability and robustness through the
avoidance of a single point of failure. However, DFL faces significant
challenges in optimizing security, as most Byzantine-robust algorithms proposed
in the literature are designed for centralized scenarios. In this paper, we
present a novel Byzantine-robust aggregation algorithm to enhance the security
of Decentralized Federated Learning environments, coined WFAgg. This proposal
handles the adverse conditions and strength robustness of dynamic decentralized
topologies at the same time by employing multiple filters to identify and
mitigate Byzantine attacks. Experimental results demonstrate the effectiveness
of the proposed algorithm in maintaining model accuracy and convergence in the
presence of various Byzantine attack scenarios, outperforming state-of-the-art
centralized Byzantine-robust aggregation schemes (such as Multi-Krum or
Clustering). These algorithms are evaluated on an IID image classification
problem in both centralized and decentralized scenarios.

摘要：聯邦學習 (FL) 作為一種分散式機器學習方法浮現，它透過在裝置上訓練 AI 模型來解決隱私問題。分散式聯邦學習 (DFL) 透過消除中央伺服器來擴充 FL 典範，進而透過避免單點故障來增強可擴充性和穩健性。然而，DFL 在最佳化安全性方面面臨重大挑戰，因為文獻中提出的多數拜占庭容錯演算法都是為集中式場景設計。在本文中，我們提出了一種新穎的拜占庭容錯聚合演算法，以增強分散式聯邦學習環境的安全性，並將其命名為 WFAgg。此提案同時處理不利的條件和動態分散式拓撲的強度穩健性，方法是採用多重篩選器來識別和減輕拜占庭攻擊。實驗結果證明了所提出的演算法在各種拜占庭攻擊場景中維持模型準確度和收斂性的有效性，優於最先進的集中式拜占庭容錯聚合方案（例如 Multi-Krum 或 Clustering）。這些演算法在集中式和分散式場景中針對 IID 影像分類問題進行評估。

##### **Are Transformers in Pre-trained LM A Good ASR Encoder? An Empirical Study**
2409.17750v1 by Keyu An, Shiliang Zhang, Zhijie Yan

In this study, we delve into the efficacy of transformers within pre-trained
language models (PLMs) when repurposed as encoders for Automatic Speech
Recognition (ASR). Our underlying hypothesis posits that, despite being
initially trained on text-based corpora, these transformers possess a
remarkable capacity to extract effective features from the input sequence. This
inherent capability, we argue, is transferrable to speech data, thereby
augmenting the acoustic modeling ability of ASR. Through rigorous empirical
analysis, our findings reveal a notable improvement in Character Error Rate
(CER) and Word Error Rate (WER) across diverse ASR tasks when transformers from
pre-trained LMs are incorporated. Particularly, they serve as an advantageous
starting point for initializing ASR encoders. Furthermore, we uncover that
these transformers, when integrated into a well-established ASR encoder, can
significantly boost performance, especially in scenarios where profound
semantic comprehension is pivotal. This underscores the potential of leveraging
the semantic prowess embedded within pre-trained transformers to advance ASR
systems' capabilities.

摘要：在這項研究中，我們深入探討了在將預訓練語言模型 (PLM) 中的Transformer重新用作自動語音辨識 (ASR) 編碼器時，這些Transformer的效能。我們的基本假設假設，儘管最初是在基於文字的語料庫上訓練，但這些Transformer具備從輸入序列中提取有效特徵的非凡能力。我們認為，這種內在能力可以轉移到語音資料，從而增強 ASR 的聲學建模能力。透過嚴謹的實證分析，我們的研究結果顯示，當將來自預訓練 LM 的Transformer納入時，各種 ASR 任務的字元錯誤率 (CER) 和字詞錯誤率 (WER) 都顯著改善。特別是，它們作為初始化 ASR 編碼器的有利起點。此外，我們發現，當這些Transformer整合到一個完善的 ASR 編碼器中時，可以顯著提升效能，特別是在深刻語義理解至關重要的場景中。這強調了利用預訓練Transformer中嵌入的語義能力來提升 ASR 系統功能的潛力。

##### **Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Model**
2409.17745v1 by Nilanjan Sinhababu, Andrew Parry, Debasis Ganguly, Debasis Samanta, Pabitra Mitra

A supervised ranking model, despite its advantage of being effective, usually
involves complex processing - typically multiple stages of task-specific
pre-training and fine-tuning. This has motivated researchers to explore simpler
pipelines leveraging large language models (LLMs) that are capable of working
in a zero-shot manner. However, since zero-shot inference does not make use of
a training set of pairs of queries and their relevant documents, its
performance is mostly worse than that of supervised models, which are trained
on such example pairs. Motivated by the existing findings that training
examples generally improve zero-shot performance, in our work, we explore if
this also applies to ranking models. More specifically, given a query and a
pair of documents, the preference prediction task is improved by augmenting
examples of preferences for similar queries from a training set. Our proposed
pairwise few-shot ranker demonstrates consistent improvements over the
zero-shot baseline on both in-domain (TREC DL) and out-domain (BEIR subset)
retrieval benchmarks. Our method also achieves a close performance to that of a
supervised model without requiring any complex training pipeline.

摘要：儘管監督式排名模型具有有效性的優勢，但通常涉及複雜的處理程序 - 通常是特定任務的預先訓練和微調的多個階段。這促使研究人員探索利用大型語言模型 (LLM) 的更簡單管道，這些模型能夠以零次學習的方式工作。然而，由於零次學習推論並未利用查詢對及其相關文件組成的訓練集，因此其效能通常比監督式模型差，而監督式模型是在此類範例對上訓練的。受到現有發現的啟發，即訓練範例通常會改善零次學習效能，在我們的研究中，我們探討這是否也適用於排名模型。更具體地說，給定一個查詢和一對文件，偏好預測任務會透過擴充訓練集中類似查詢的偏好範例而得到改善。我們提出的成對少次學習排名器在領域內 (TREC DL) 和領域外 (BEIR 子集) 擷取基準上都顯示出相較於零次學習基準的一致性改善。我們的方法也達到了與監督式模型接近的效能，而不需要任何複雜的訓練管道。

##### **AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking**
2409.17728v1 by Shiqi Sun, Yantao Lu, Ning Liu, Bo Jiang, JinChao Chen, Ying Zhang

Camera-LiDAR fusion models significantly enhance perception performance in
autonomous driving. The fusion mechanism leverages the strengths of each
modality while minimizing their weaknesses. Moreover, in practice, camera-LiDAR
fusion models utilize pre-trained backbones for efficient training. However, we
argue that directly loading single-modal pre-trained camera and LiDAR backbones
into camera-LiDAR fusion models introduces similar feature redundancy across
modalities due to the nature of the fusion mechanism. Unfortunately, existing
pruning methods are developed explicitly for single-modal models, and thus,
they struggle to effectively identify these specific redundant parameters in
camera-LiDAR fusion models. In this paper, to address the issue above on
camera-LiDAR fusion models, we propose a novelty pruning framework Alternative
Modality Masking Pruning (AlterMOMA), which employs alternative masking on each
modality and identifies the redundant parameters. Specifically, when one
modality parameters are masked (deactivated), the absence of features from the
masked backbone compels the model to reactivate previous redundant features of
the other modality backbone. Therefore, these redundant features and relevant
redundant parameters can be identified via the reactivation process. The
redundant parameters can be pruned by our proposed importance score evaluation
function, Alternative Evaluation (AlterEva), which is based on the observation
of the loss changes when certain modality parameters are activated and
deactivated. Extensive experiments on the nuScene and KITTI datasets
encompassing diverse tasks, baseline models, and pruning algorithms showcase
that AlterMOMA outperforms existing pruning methods, attaining state-of-the-art
performance.

摘要：<paragraph>相機-LiDAR 融合模型大幅提升了自動駕駛中的感知表現。融合機制利用了各個模式的優勢，同時將其弱點降到最低。此外，在實務中，相機-LiDAR 融合模型利用預先訓練的骨幹網路進行有效率的訓練。然而，我們主張直接將單一模式預先訓練的相機和 LiDAR 骨幹網路載入相機-LiDAR 融合模型，由於融合機制的本質，會在各個模式中引入類似的特徵冗餘。遺憾的是，現有的剪枝方法是明確為單一模式模型開發，因此它們難以有效辨識相機-LiDAR 融合模型中的這些特定冗餘參數。在本文中，為了解決相機-LiDAR 融合模型上述的問題，我們提出了一種創新的剪枝架構，稱為交替模式遮罩剪枝法 (AlterMOMA)，它在每個模式上採用交替遮罩並辨識出冗餘參數。具體來說，當一個模式參數被遮罩（停用）時，來自遮罩骨幹網路的特徵不存在，迫使模型重新啟用另一個模式骨幹網路中先前的冗餘特徵。因此，這些冗餘特徵和相關的冗餘參數可以透過重新啟用程序進行辨識。冗餘參數可以透過我們提出的重要性評分評估函數，也就是交替評估 (AlterEva) 進行剪枝，這個函數是基於當特定模式參數被啟用和停用時，損失變化的觀察。在涵蓋各種任務、基準模型和剪枝演算法的 nuScene 和 KITTI 資料集上進行的廣泛實驗，展示了 AlterMOMA 優於現有的剪枝方法，達到了最先進的表現。</paragraph>

##### **Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience**
2409.17702v1 by Leonard Bärmann, Chad DeChant, Joana Plewnia, Fabian Peller-Konrad, Daniel Bauer, Tamim Asfour, Alex Waibel

Verbalization of robot experience, i.e., summarization of and question
answering about a robot's past, is a crucial ability for improving human-robot
interaction. Previous works applied rule-based systems or fine-tuned deep
models to verbalize short (several-minute-long) streams of episodic data,
limiting generalization and transferability. In our work, we apply large
pretrained models to tackle this task with zero or few examples, and
specifically focus on verbalizing life-long experiences. For this, we derive a
tree-like data structure from episodic memory (EM), with lower levels
representing raw perception and proprioception data, and higher levels
abstracting events to natural language concepts. Given such a hierarchical
representation built from the experience stream, we apply a large language
model as an agent to interactively search the EM given a user's query,
dynamically expanding (initially collapsed) tree nodes to find the relevant
information. The approach keeps computational costs low even when scaling to
months of robot experience data. We evaluate our method on simulated household
robot data, human egocentric videos, and real-world robot recordings,
demonstrating its flexibility and scalability.

摘要：機器人經驗的口頭表達，即總結和回答機器人過去的提問，是提升人機互動的一項關鍵能力。先前的研究應用基於規則的系統或微調深度模型來口頭表達簡短（數分鐘長的）情節資料串流，限制了概括性和可轉移性。在我們的研究中，我們應用大型預訓練模型來處理這個任務，範例為零或少數，特別專注於口頭表達終生的經驗。為此，我們從情節記憶（EM）中推導出樹狀資料結構，較低層級表示原始感知和本體感覺資料，而較高層級則將事件抽象為自然語言概念。給定從經驗串流建構的此類階層式表示，我們應用大型語言模型作為代理，根據使用者的查詢互動式搜尋 EM，動態展開（最初摺疊）樹狀節點以找出相關資訊。即使擴充到數個月的機器人經驗資料，這種方法也能維持低運算成本。我們在模擬家用機器人資料、人類自我中心影片和真實世界的機器人記錄中評估我們的模型，證明了它的靈活性和可擴充性。

##### **MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks**
2409.17699v1 by Giandomenico Cornacchia, Giulio Zizzo, Kieran Fraser, Muhammad Zaid Hamed, Ambrish Rawat, Mark Purcell

The proliferation of Large Language Models (LLMs) in diverse applications
underscores the pressing need for robust security measures to thwart potential
jailbreak attacks. These attacks exploit vulnerabilities within LLMs, endanger
data integrity and user privacy. Guardrails serve as crucial protective
mechanisms against such threats, but existing models often fall short in terms
of both detection accuracy, and computational efficiency. This paper advocates
for the significance of jailbreak attack prevention on LLMs, and emphasises the
role of input guardrails in safeguarding these models. We introduce MoJE
(Mixture of Jailbreak Expert), a novel guardrail architecture designed to
surpass current limitations in existing state-of-the-art guardrails. By
employing simple linguistic statistical techniques, MoJE excels in detecting
jailbreak attacks while maintaining minimal computational overhead during model
inference. Through rigorous experimentation, MoJE demonstrates superior
performance capable of detecting 90% of the attacks without compromising benign
prompts, enhancing LLMs security against jailbreak attacks.

摘要：大型語言模型 (LLM) 在各種應用中激增，這凸顯了對強大安全措施的迫切需求，以阻止潛在的越獄攻擊。這些攻擊會利用 LLM 中的漏洞，危害資料完整性和使用者隱私。防護措施可作為對抗此類威脅的關鍵保護機制，但現有模型在偵測準確性和運算效率方面往往不足。本文主張在 LLM 上預防越獄攻擊的重要性，並強調輸入防護措施在保護這些模型中的作用。我們介紹了 MoJE（越獄專家混合），這是一種新穎的防護措施架構，旨在超越現有最先進防護措施中的當前限制。透過採用簡單的語言統計技術，MoJE 在偵測越獄攻擊方面表現出色，同時在模型推論期間保持最小的運算負擔。透過嚴謹的實驗，MoJE 展示了優異的效能，能夠偵測 90% 的攻擊，而不會影響良性的提示，增強 LLM 對越獄攻擊的安全性。

##### **MIO: A Foundation Model on Multimodal Tokens**
2409.17692v1 by Zekun Wang, King Zhu, Chunpu Xu, Wangchunshu Zhou, Jiaheng Liu, Yibo Zhang, Jiashuo Wang, Ning Shi, Siyu Li, Yizhi Li, Haoran Que, Zhaoxiang Zhang, Yuanxing Zhang, Ge Zhang, Ke Xu, Jie Fu, Wenhao Huang

In this paper, we introduce MIO, a novel foundation model built on multimodal
tokens, capable of understanding and generating speech, text, images, and
videos in an end-to-end, autoregressive manner. While the emergence of large
language models (LLMs) and multimodal large language models (MM-LLMs) propels
advancements in artificial general intelligence through their versatile
capabilities, they still lack true any-to-any understanding and generation.
Recently, the release of GPT-4o has showcased the remarkable potential of
any-to-any LLMs for complex real-world tasks, enabling omnidirectional input
and output across images, speech, and text. However, it is closed-source and
does not support the generation of multimodal interleaved sequences. To address
this gap, we present MIO, which is trained on a mixture of discrete tokens
across four modalities using causal multimodal modeling. MIO undergoes a
four-stage training process: (1) alignment pre-training, (2) interleaved
pre-training, (3) speech-enhanced pre-training, and (4) comprehensive
supervised fine-tuning on diverse textual, visual, and speech tasks. Our
experimental results indicate that MIO exhibits competitive, and in some cases
superior, performance compared to previous dual-modal baselines, any-to-any
model baselines, and even modality-specific baselines. Moreover, MIO
demonstrates advanced capabilities inherent to its any-to-any feature, such as
interleaved video-text generation, chain-of-visual-thought reasoning, visual
guideline generation, instructional image editing, etc.

摘要：<paragraph>在本文中，我們介紹 MIO，這是一個建立在多模態代碼的新型基礎模型，能夠以端到端、自迴歸的方式理解和生成語音、文字、圖像和影片。儘管大型語言模型 (LLM) 和多模態大型語言模型 (MM-LLM) 的出現透過其多功能能力推動了人工通用智慧的進步，但它們仍然缺乏真正的任何到任何理解和生成。最近，GPT-4o 的發布展示了任何到任何 LLM 在複雜的真實世界任務中的顯著潛力，實現了跨圖像、語音和文字的全方位輸入和輸出。然而，它是閉源的，不支持生成多模態交錯序列。為了解決這個差距，我們提出了 MIO，它使用因果多模態建模在四種模態中訓練離散代碼的混合。MIO 經歷了四階段訓練過程：(1) 對齊預訓練，(2) 交錯預訓練，(3) 語音增強預訓練，以及 (4) 在不同的文本、視覺和語音任務上進行綜合監督微調。我們的實驗結果表明，與先前的雙模態基線、任何到任何模型基線，甚至特定於模態的基線相比，MIO 表現出具有競爭力，在某些情況下表現出更優越的效能。此外，MIO 展示了其任何到任何功能固有的先進能力，例如交錯視訊文字生成、視覺思考推理鏈、視覺準則生成、教學圖像編輯等。</paragraph>

##### **Efficient Bias Mitigation Without Privileged Information**
2409.17691v1 by Mateo Espinosa Zarlenga, Swami Sankaranarayanan, Jerone T. A. Andrews, Zohreh Shams, Mateja Jamnik, Alice Xiang

Deep neural networks trained via empirical risk minimisation often exhibit
significant performance disparities across groups, particularly when group and
task labels are spuriously correlated (e.g., "grassy background" and "cows").
Existing bias mitigation methods that aim to address this issue often either
rely on group labels for training or validation, or require an extensive
hyperparameter search. Such data and computational requirements hinder the
practical deployment of these methods, especially when datasets are too large
to be group-annotated, computational resources are limited, and models are
trained through already complex pipelines. In this paper, we propose Targeted
Augmentations for Bias Mitigation (TAB), a simple hyperparameter-free framework
that leverages the entire training history of a helper model to identify
spurious samples, and generate a group-balanced training set from which a
robust model can be trained. We show that TAB improves worst-group performance
without any group information or model selection, outperforming existing
methods while maintaining overall accuracy.

摘要：透過經驗風險最小化訓練的深度神經網路通常展現出不同群組之間的顯著效能差異，特別是在群組和任務標籤具有虛假相關性（例如「草地背景」和「牛」）時。現有的偏差緩解方法旨在解決此問題，通常依賴群組標籤進行訓練或驗證，或需要廣泛的超參數搜尋。此類資料和計算需求阻礙了這些方法的實際部署，特別是在資料集太大而無法群組註解、計算資源有限，且模型透過已經複雜的管道進行訓練時。在本文中，我們提出用於偏差緩解的目標擴充（TAB），這是一個簡單的無超參數架構，利用輔助模型的整個訓練歷程來識別虛假樣本，並從中產生一個群組平衡的訓練集，進而訓練出穩健的模型。我們展示了 TAB 在沒有任何群組資訊或模型選擇的情況下改善最差群組效能，在維持整體準確度的同時，優於現有方法。

##### **Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**
2409.17685v1 by Yasaman Haghbin, Hadi Moradi, Reshad Hosseini

One of the growing trends in machine learning is the use of data generation
techniques, since the performance of machine learning models is dependent on
the quantity of the training dataset. However, in many medical applications,
collecting large datasets is challenging due to resource constraints, which
leads to overfitting and poor generalization. This paper introduces a novel
method, Artificial Data Point Generation in Clustered Latent Space (AGCL),
designed to enhance classification performance on small medical datasets
through synthetic data generation. The AGCL framework involves feature
extraction, K-means clustering, cluster evaluation based on a class separation
metric, and the generation of synthetic data points from clusters with distinct
class representations. This method was applied to Parkinson's disease
screening, utilizing facial expression data, and evaluated across multiple
machine learning classifiers. Experimental results demonstrate that AGCL
significantly improves classification accuracy compared to baseline, GN and
kNNMTD. AGCL achieved the highest overall test accuracy of 83.33% and
cross-validation accuracy of 90.90% in majority voting over different emotions,
confirming its effectiveness in augmenting small datasets.

摘要：機器學習中日益增長的趨勢之一是使用資料產生技術，因為機器學習模型的效能取決於訓練資料集的數量。然而，在許多醫學應用中，由於資源限制，收集大型資料集具有挑戰性，這會導致過度擬合和不良的泛化。本文介紹了一種新方法，即叢集潛在空間中的人工資料點產生（AGCL），旨在透過合成資料產生來增強小型醫學資料集上的分類效能。AGCL 框架涉及特徵萃取、K 平均叢集、基於類別分離度量標準的叢集評估，以及從具有不同類別表示的叢集中產生合成資料點。此方法應用於帕金森氏症篩檢，利用面部表情資料，並在多個機器學習分類器中進行評估。實驗結果表明，與基線、GN 和 kNNMTD 相比，AGCL 大幅提升了分類準確度。在對不同情緒進行多數決投票時，AGCL 達到了最高的整體測試準確度 83.33% 和交叉驗證準確度 90.90%，證實了其在擴充小型資料集方面的有效性。

##### **Preserving logical and functional dependencies in synthetic tabular data**
2409.17684v1 by Chaithra Umesh, Kristian Schultz, Manjunath Mahendra, Saparshi Bej, Olaf Wolkenhauer

Dependencies among attributes are a common aspect of tabular data. However,
whether existing tabular data generation algorithms preserve these dependencies
while generating synthetic data is yet to be explored. In addition to the
existing notion of functional dependencies, we introduce the notion of logical
dependencies among the attributes in this article. Moreover, we provide a
measure to quantify logical dependencies among attributes in tabular data.
Utilizing this measure, we compare several state-of-the-art synthetic data
generation algorithms and test their capability to preserve logical and
functional dependencies on several publicly available datasets. We demonstrate
that currently available synthetic tabular data generation algorithms do not
fully preserve functional dependencies when they generate synthetic datasets.
In addition, we also showed that some tabular synthetic data generation models
can preserve inter-attribute logical dependencies. Our review and comparison of
the state-of-the-art reveal research needs and opportunities to develop
task-specific synthetic tabular data generation models.

摘要：屬性之間的依存關係是表格資料的常見面向。然而，現有的表格資料生成演算法在生成合成資料時是否會保留這些依存關係，這一點尚未探討。除了現有的函數依存關係概念之外，我們在本文中引入了屬性之間的邏輯依存關係概念。此外，我們提供了一個衡量表格資料中屬性之間邏輯依存關係的指標。利用此指標，我們比較了幾種最先進的合成資料生成演算法，並測試它們在幾個公開可用的資料集上保留邏輯和函數依存關係的能力。我們證明，目前可用的合成表格資料生成演算法在生成合成資料集時並未完全保留函數依存關係。此外，我們還表明，某些表格合成資料生成模型可以保留屬性間的邏輯依存關係。我們對最先進技術的回顧和比較揭示了研究需求和機會，以開發特定任務的合成表格資料生成模型。

##### **Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**
2409.17683v1 by Natthanaphop Isaradech, Andrea Riedel, Wachiranun Sirikul, Markus Kreuzthaler, Stefan Schulz

Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.

摘要：**引言：**藥物處方通常以自由文本形式呈現，並包含兩種語言、當地品牌名稱，以及各種慣用格式和縮寫。大型語言模型 (LLM) 已展現出極佳的文本生成能力，能回應輸入提示。我們使用 ChatGPT 3.5 自動建構和擴充出院摘要中的藥物陳述，讓人類和機器更容易解讀。**方法：**命名實體辨識 (NER) 和文字擴充 (EX) 用於零次和少量提示策略的設定。100 個藥物陳述經過人工註解和整理。NER 的效能透過嚴格和部分比對進行衡量。對於 EX 任務，兩位專家透過評估原始陳述和擴充陳述之間的語義等效性來解讀結果。模型效能透過精確度、召回率和 F1 分數進行衡量。**結果：**對於 NER，效能最佳的提示在測試集中達到平均 F1 分數 0.94。對於 EX，少量提示在其他提示中展現出優異效能，平均 F1 分數為 0.87。**結論：**我們的研究證明，使用 ChatGPT 處理自由文本藥物陳述中的 NER 和 EX 任務具有良好的效能。與零次基準相比，少量提示方法可防止系統產生幻覺，這在處理與安全性相關的藥物資料時是不可接受的。

##### **Cross-lingual Human-Preference Alignment for Neural Machine Translation with Direct Quality Optimization**
2409.17673v1 by Kaden Uhlig, Joern Wuebker, Raphael Reinauer, John DeNero

Reinforcement Learning from Human Feedback (RLHF) and derivative techniques
like Direct Preference Optimization (DPO) are task-alignment algorithms used to
repurpose general, foundational models for specific tasks. We show that
applying task-alignment to neural machine translation (NMT) addresses an
existing task--data mismatch in NMT, leading to improvements across all
languages of a multilingual model, even when task-alignment is only applied to
a subset of those languages. We do so by introducing Direct Quality
Optimization (DQO), a variant of DPO leveraging a pre-trained translation
quality estimation model as a proxy for human preferences, and verify the
improvements with both automatic metrics and human evaluation.

摘要：人類回饋強化學習 (RLHF) 和衍生技術，例如直接偏好最佳化 (DPO)，是任務對齊演算法，用於將一般基礎模型重新用於特定任務。我們展示將任務對齊應用於神經機器翻譯 (NMT) 可解決 NMT 中現有的任務資料不匹配問題，進而提升多語言模型所有語言的表現，即使任務對齊只應用於這些語言的子集。我們透過引入直接品質最佳化 (DQO) 來達成此目標，DQO 是一種 DPO 變體，利用預先訓練的翻譯品質評估模型作為人類偏好的代理，並透過自動化指標和人類評量驗證這些改進。

##### **Explanation Bottleneck Models**
2409.17663v1 by Shin'ya Yamaguchi, Kosuke Nishida

Recent concept-based interpretable models have succeeded in providing
meaningful explanations by pre-defined concept sets. However, the dependency on
the pre-defined concepts restricts the application because of the limited
number of concepts for explanations. This paper proposes a novel interpretable
deep neural network called explanation bottleneck models (XBMs). XBMs generate
a text explanation from the input without pre-defined concepts and then predict
a final task prediction based on the generated explanation by leveraging
pre-trained vision-language encoder-decoder models. To achieve both the target
task performance and the explanation quality, we train XBMs through the target
task loss with the regularization penalizing the explanation decoder via the
distillation from the frozen pre-trained decoder. Our experiments, including a
comparison to state-of-the-art concept bottleneck models, confirm that XBMs
provide accurate and fluent natural language explanations without pre-defined
concept sets. Code will be available at https://github.com/yshinya6/xbm/.

摘要：最近的概念可解释模型已成功提供预定义概念集的含义解释。然而，对预定义概念的依赖性限制了应用程序，因为解释的概念数量有限。本文提出了一种新颖的可解释深度神经网络，称为解释瓶颈模型 (XBM)。XBM 从输入中生成文本解释，而无需预定义的概念，然后通过利用预训练的视觉语言编码器-解码器模型，基于生成的解释预测最终任务预测。为了实现目标任务性能和解释质量，我们通过目标任务损失训练 XBM，并通过从冻结预训练解码器中进行蒸馏来惩罚解释解码器的正则化。我们的实验，包括与最先进的概念瓶颈模型的比较，证实 XBM 在没有预定义概念集的情况下提供了准确且流畅的自然语言解释。代码将在 https://github.com/yshinya6/xbm/ 中提供。

##### **A Fuzzy-based Approach to Predict Human Interaction by Functional Near-Infrared Spectroscopy**
2409.17661v1 by Xiaowei Jiang, Liang Ou, Yanan Chen, Na Ao, Yu-Cheng Chang, Thomas Do, Chin-Teng Lin

The paper introduces a Fuzzy-based Attention (Fuzzy Attention Layer)
mechanism, a novel computational approach to enhance the interpretability and
efficacy of neural models in psychological research. The proposed Fuzzy
Attention Layer mechanism is integrated as a neural network layer within the
Transformer Encoder model to facilitate the analysis of complex psychological
phenomena through neural signals, such as those captured by functional
Near-Infrared Spectroscopy (fNIRS). By leveraging fuzzy logic, the Fuzzy
Attention Layer is capable of learning and identifying interpretable patterns
of neural activity. This capability addresses a significant challenge when
using Transformer: the lack of transparency in determining which specific brain
activities most contribute to particular predictions. Our experimental results
demonstrated on fNIRS data from subjects engaged in social interactions
involving handholding reveal that the Fuzzy Attention Layer not only learns
interpretable patterns of neural activity but also enhances model performance.
Additionally, the learned patterns provide deeper insights into the neural
correlates of interpersonal touch and emotional exchange. The application of
our model shows promising potential in deciphering the subtle complexities of
human social behaviors, thereby contributing significantly to the fields of
social neuroscience and psychological AI.

摘要：本文介紹了一種基於模糊的注意力（模糊注意力層）機制，這是一種新穎的計算方法，用於增強神經模型在心理研究中的可解釋性和有效性。提議的模糊注意力層機制作為神經網路層整合在 Transformer 編碼器模型中，以利於透過神經訊號（例如功能性近紅外線光譜 (fNIRS) 所捕捉到的訊號）分析複雜的心理現象。模糊注意力層透過利用模糊邏輯，能夠學習和識別可解釋的神經活動模式。這種能力應對了使用 Transformer 時的一項重大挑戰：缺乏透明度，無法確定哪些特定的大腦活動最有助於特定預測。我們的實驗結果顯示在參與牽手社交互動受試者的 fNIRS 資料中，模糊注意力層不僅學習了可解釋的神經活動模式，還增強了模型效能。此外，學習到的模式提供了更深入的見解，了解人際觸摸和情緒交流的神經相關性。我們的模型應用顯示了解密人類社會行為的細微複雜性的潛力，從而為社會神經科學和心理 AI 領域做出重大貢獻。

##### **Prototype based Masked Audio Model for Self-Supervised Learning of Sound Event Detection**
2409.17656v1 by Pengfei Cai, Yan Song, Nan Jiang, Qing Gu, Ian McLoughlin

A significant challenge in sound event detection (SED) is the effective
utilization of unlabeled data, given the limited availability of labeled data
due to high annotation costs. Semi-supervised algorithms rely on labeled data
to learn from unlabeled data, and the performance is constrained by the quality
and size of the former. In this paper, we introduce the Prototype based Masked
Audio Model~(PMAM) algorithm for self-supervised representation learning in
SED, to better exploit unlabeled data. Specifically, semantically rich
frame-level pseudo labels are constructed from a Gaussian mixture model (GMM)
based prototypical distribution modeling. These pseudo labels supervise the
learning of a Transformer-based masked audio model, in which binary
cross-entropy loss is employed instead of the widely used InfoNCE loss, to
provide independent loss contributions from different prototypes, which is
important in real scenarios in which multiple labels may apply to unsupervised
data frames. A final stage of fine-tuning with just a small amount of labeled
data yields a very high performing SED model. On like-for-like tests using the
DESED task, our method achieves a PSDS1 score of 62.5\%, surpassing current
state-of-the-art models and demonstrating the superiority of the proposed
technique.

摘要：聲音事件偵測 (SED) 中的一項重大挑戰是有效利用未標註資料，因為標註資料的取得受到標註成本高昂的限制。半監督演算法依賴標註資料從未標註資料中學習，而其效能受到前者的品質與規模所限制。在本文中，我們介紹基於原型遮罩音訊模型 (PMAM) 的演算法，用於 SED 中的自我監督表徵學習，以更好地利用未標註資料。具體來說，語義豐富的幀級偽標籤是由基於高斯混合模型 (GMM) 的原型分佈建模所建構的。這些偽標籤監督基於 Transformer 的遮罩音訊模型的學習，其中採用二元交叉熵損失，而非廣泛使用的 InfoNCE 損失，以提供來自不同原型的獨立損失貢獻，這在多個標籤可能套用於未監督資料幀的實際場景中非常重要。最後一個微調階段只使用少量標註資料，就能產生效能非常高的 SED 模型。在使用 DESED 任務進行的相同測試中，我們的模型在 PSDS1 得分達到 62.5%，超越了現行的最先進模型，並證明了所提出技術的優越性。

##### **AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment**
2409.17655v1 by Nan Sun, Bo Mao, Yongchang Li, Lumeng Ma, Di Guo, Huaping Liu

The increasing demand for intelligent assistants in human-populated
environments has motivated significant research in autonomous robotic systems.
Traditional service robots and virtual assistants, however, struggle with
real-world task execution due to their limited capacity for dynamic reasoning
and interaction, particularly when human collaboration is required. Recent
developments in Large Language Models have opened new avenues for improving
these systems, enabling more sophisticated reasoning and natural interaction
capabilities. In this paper, we introduce AssistantX, an LLM-powered proactive
assistant designed to operate autonomously in a physical office environment.
Unlike conventional service robots, AssistantX leverages a novel multi-agent
architecture, PPDR4X, which provides advanced inference capabilities and
comprehensive collaboration awareness. By effectively bridging the gap between
virtual operations and physical interactions, AssistantX demonstrates robust
performance in managing complex real-world scenarios. Our evaluation highlights
the architecture's effectiveness, showing that AssistantX can respond to clear
instructions, actively retrieve supplementary information from memory, and
proactively seek collaboration from team members to ensure successful task
completion. More details and videos can be found at
https://assistantx-agent.github.io/AssistantX/.

摘要：在人員密集的環境中對智慧助理的需求日益增長，這激勵了對自主機器人系統進行大量的研究。然而，傳統的服務機器人和虛擬助理由於其動態推理和互動能力有限，在執行現實世界的任務時會遇到困難，特別是在需要人類協作時。最近大型語言模型的發展為改進這些系統開闢了新的途徑，實現了更精密的推理和自然互動能力。在本文中，我們介紹了 AssistantX，這是一個由 LLM 驅動的積極主動助理，旨在在物理辦公室環境中自主運作。與傳統的服務機器人不同，AssistantX 利用了一種新穎的多代理架構 PPDR4X，它提供了先進的推理能力和全面的協作意識。通過有效地彌合虛擬操作和物理互動之間的差距，AssistantX 在管理複雜的現實世界場景中展示了強大的性能。我們的評估突出了該架構的有效性，表明 AssistantX 可以響應明確的指令，主動從記憶體中檢索補充資訊，並主動尋求團隊成員的協作，以確保任務成功完成。更多詳細資訊和影片可以在 https://assistantx-agent.github.io/AssistantX/ 找到。

##### **FactorSim: Generative Simulation via Factorized Representation**
2409.17652v1 by Fan-Yun Sun, S. I. Harini, Angela Yi, Yihan Zhou, Alex Zook, Jonathan Tremblay, Logan Cross, Jiajun Wu, Nick Haber

Generating simulations to train intelligent agents in game-playing and
robotics from natural language input, from user input or task documentation,
remains an open-ended challenge. Existing approaches focus on parts of this
challenge, such as generating reward functions or task hyperparameters. Unlike
previous work, we introduce FACTORSIM that generates full simulations in code
from language input that can be used to train agents. Exploiting the structural
modularity specific to coded simulations, we propose to use a factored
partially observable Markov decision process representation that allows us to
reduce context dependence during each step of the generation. For evaluation,
we introduce a generative simulation benchmark that assesses the generated
simulation code's accuracy and effectiveness in facilitating zero-shot
transfers in reinforcement learning settings. We show that FACTORSIM
outperforms existing methods in generating simulations regarding prompt
alignment (e.g., accuracy), zero-shot transfer abilities, and human evaluation.
We also demonstrate its effectiveness in generating robotic tasks.

摘要：從自然語言輸入（來自使用者輸入或任務文件）產生模擬，以訓練遊戲和機器人中的智慧代理，這仍然是一個開放式的挑戰。現有方法專注於此挑戰的一部分，例如產生獎勵函數或任務超參數。與先前的研究不同，我們引入了 FACTORSIM，它從可用於訓練代理的語言輸入中產生代碼中的完整模擬。利用特定於編碼模擬的結構模組化，我們建議使用分層的部分可觀察馬可夫決策過程表示，這允許我們在生成的每個步驟中減少背景依賴性。為了評估，我們引入了一個生成式模擬基準，用於評估生成的模擬代碼在促進強化學習設定中的零次學習轉移方面的準確性和有效性。我們表明 FACTORSIM 在產生模擬方面優於現有方法，包括提示對齊（例如，準確性）、零次學習轉移能力和人類評估。我們還展示了它在產生機器人任務方面的有效性。

##### **Digital Twin Ecosystem for Oncology Clinical Operations**
2409.17650v1 by Himanshu Pandey, Akhil Amod, Shivang, Kshitij Jaggi, Ruchi Garg, Abheet Jain, Vinayak Tantia

Artificial Intelligence (AI) and Large Language Models (LLMs) hold
significant promise in revolutionizing healthcare, especially in clinical
applications. Simultaneously, Digital Twin technology, which models and
simulates complex systems, has gained traction in enhancing patient care.
However, despite the advances in experimental clinical settings, the potential
of AI and digital twins to streamline clinical operations remains largely
untapped. This paper introduces a novel digital twin framework specifically
designed to enhance oncology clinical operations. We propose the integration of
multiple specialized digital twins, such as the Medical Necessity Twin, Care
Navigator Twin, and Clinical History Twin, to enhance workflow efficiency and
personalize care for each patient based on their unique data. Furthermore, by
synthesizing multiple data sources and aligning them with the National
Comprehensive Cancer Network (NCCN) guidelines, we create a dynamic Cancer Care
Path, a continuously evolving knowledge base that enables these digital twins
to provide precise, tailored clinical recommendations.

摘要：人工智慧 (AI) 和大型語言模型 (LLM) 在醫療保健領域中，特別是在臨床應用中，具有顯著的變革前景。同時，用於模擬和建模複雜系統的數位孿生技術，在增強患者照護方面也獲得了關注。然而，儘管在實驗性臨床環境中取得進展，AI 和數位孿生在簡化臨床運作方面的潛力仍未得到充分發揮。本文介紹了一個專門設計用於增強腫瘤學臨床運作的新型數位孿生架構。我們建議整合多個專業數位孿生，例如醫療必要性孿生、照護領航員孿生和臨床病史孿生，以提高工作流程效率，並根據每個患者的獨特資料為其提供個人化照護。此外，透過綜合多個資料來源並將其與國家綜合癌症網路 (NCCN) 指南相符，我們建立了一個動態癌症照護路徑，一個持續發展的知識庫，使這些數位孿生能夠提供精確且客製化的臨床建議。

##### **Efficient In-Domain Question Answering for Resource-Constrained Environments**
2409.17648v1 by Isaac Chung, Phat Vo, Arman Kizilkale, Aaron Reite

Retrieval Augmented Generation (RAG) is a common method for integrating
external knowledge into pretrained Large Language Models (LLMs) to enhance
accuracy and relevancy in question answering (QA) tasks. However, prompt
engineering and resource efficiency remain significant bottlenecks in
developing optimal and robust RAG solutions for real-world QA applications.
Recent studies have shown success in using fine tuning to address these
problems; in particular, Retrieval Augmented Fine Tuning (RAFT) applied to
smaller 7B models has demonstrated superior performance compared to RAG setups
with much larger models such as GPT-3.5. The combination of RAFT with
parameter-efficient fine tuning (PEFT) techniques, such as Low-Rank Adaptation
(LoRA), promises an even more efficient solution, yet remains an unexplored
area. In this work, we combine RAFT with LoRA to reduce fine tuning and storage
requirements and gain faster inference times while maintaining comparable RAG
performance. This results in a more compute-efficient RAFT, or CRAFT, which is
particularly useful for knowledge-intensive QA tasks in resource-constrained
environments where internet access may be restricted and hardware resources
limited.

摘要：撷取增强生成（RAG）是一种将外部知识整合到预先训练的大语言模型（LLM）的常见方法，以提升问答（QA）任务中的准确性和关联性。然而，提示工程和资源效率仍然是开发适用于真实世界 QA 应用的最佳健壮 RAG 解决方案的重大瓶颈。最近的研究显示，使用微调来解决这些问题已获得成功；特别是，应用于较小 7B 模型的撷取增强微调 (RAFT) 已展示出优于采用 GPT-3.5 等更大模型的 RAG 设置的性能。RAFT 与参数高效微调（PEFT）技术（例如低秩自适应 (LoRA)）的结合有望提供更高效的解决方案，但仍是一个尚未探索的领域。在这项工作中，我们将 RAFT 与 LoRA 相结合以减少微调和存储需求，并在保持可比较 RAG 性能的同时获得更快的推理时间。这产生了一种更具计算效率的 RAFT，或 CRAFT，它特别适用于资源受限环境中的知识密集型 QA 任务，在该环境中互联网访问可能受到限制，并且硬件资源有限。

##### **AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure**
2409.17642v1 by Xi Chen, Zhiyang Zhang, Fangkai Yang, Xiaoting Qin, Chao Du, Xi Cheng, Hangxin Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Large language model (LLM)-based AI delegates are increasingly utilized to
act on behalf of users, assisting them with a wide range of tasks through
conversational interfaces. Despite their advantages, concerns arise regarding
the potential risk of privacy leaks, particularly in scenarios involving social
interactions. While existing research has focused on protecting privacy by
limiting the access of AI delegates to sensitive user information, many social
scenarios require disclosing private details to achieve desired outcomes,
necessitating a balance between privacy protection and disclosure. To address
this challenge, we conduct a pilot study to investigate user preferences for AI
delegates across various social relations and task scenarios, and then propose
a novel AI delegate system that enables privacy-conscious self-disclosure. Our
user study demonstrates that the proposed AI delegate strategically protects
privacy, pioneering its use in diverse and dynamic social interactions.

摘要：大型語言模型 (LLM) 為基礎的 AI 委派者日益被用於代表使用者，透過對話式介面協助他們執行各式各樣的任務。儘管有這些優點，但仍有隱私外洩的潛在風險，特別是在涉及社交互動的情況下。現有的研究著重於透過限制 AI 委派者存取使用者的敏感資訊來保護隱私，但許多社交情境需要揭露私人細節才能達成預期的結果，這使得隱私保護與揭露之間必須取得平衡。為了應對這項挑戰，我們進行一項試驗研究，調查使用者在各種社交關係與任務情境中對 AI 委派者的偏好，然後提出一個新穎的 AI 委派者系統，讓使用者在注重隱私的情況下自我揭露。我們的使用者研究顯示，所提出的 AI 委派者策略性地保護隱私，率先在多元且動態的社交互動中使用。

##### **T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task**
2409.17640v1 by Xindi Tong, Yujin Zhu, Shijian Fan, Liang Xu

Long text summarization, gradually being essential for efficiently processing
large volumes of information, stays challenging for Large Language Models
(LLMs) such as GPT and LLaMA families because of the insufficient open-sourced
training datasets and the high requirement of contextual details dealing. To
address the issue, we design a novel zero-shot transfer learning framework,
abbreviated as T3, to iteratively training a baseline LLM on an assistant task
for the target task, where the former should own richer data resources and
share structural or semantic similarity with the latter. In practice, T3 is
approached to deal with the long text summarization task by utilizing question
answering as the assistant task, and further validated its effectiveness on the
BBC summary, NarraSum, FairytaleQA, and NLQuAD datasets, with up to nearly 14%
improvement in ROUGE, 35% improvement in BLEU, and 16% improvement in Factscore
compared to three baseline LLMs, demonstrating its potential for more
assistant-target task combinations.

摘要：長文摘要逐漸成為有效處理大量資訊的必要條件，對於 GPT 和 LLaMA 家族等大型語言模型 (LLM) 來說仍然是一項挑戰，因為開放原始碼訓練資料集不足，而且需要處理大量脈絡細節。為了解決這個問題，我們設計了一個新穎的零次方轉移學習架構，簡稱為 T3，用於在輔助任務上反覆訓練基準 LLM 以執行目標任務，其中前者應該擁有更豐富的資料資源，並且與後者共享結構或語義相似性。在實務上，T3 透過利用問題解答作為輔助任務來處理長文摘要任務，並進一步驗證其在 BBC summary、NarraSum、FairytaleQA 和 NLQuAD 資料集上的有效性，與三個基準 LLM 相比，ROUGE 提升了近 14%、BLEU 提升了 35%，Factscore 提升了 16%，顯示其在更多輔助目標任務組合中的潛力。

##### **P4Q: Learning to Prompt for Quantization in Visual-language Models**
2409.17634v1 by Huixin Sun, Runqi Wang, Yanjing Li, Xianbin Cao, Xiaolong Jiang, Yao Hu, Baochang Zhang

Large-scale pre-trained Vision-Language Models (VLMs) have gained prominence
in various visual and multimodal tasks, yet the deployment of VLMs on
downstream application platforms remains challenging due to their prohibitive
requirements of training samples and computing resources. Fine-tuning and
quantization of VLMs can substantially reduce the sample and computation costs,
which are in urgent need. There are two prevailing paradigms in quantization,
Quantization-Aware Training (QAT) can effectively quantize large-scale VLMs but
incur a huge training cost, while low-bit Post-Training Quantization (PTQ)
suffers from a notable performance drop. We propose a method that balances
fine-tuning and quantization named ``Prompt for Quantization'' (P4Q), in which
we design a lightweight architecture to leverage contrastive loss supervision
to enhance the recognition performance of a PTQ model. Our method can
effectively reduce the gap between image features and text features caused by
low-bit quantization, based on learnable prompts to reorganize textual
representations and a low-bit adapter to realign the distributions of image and
text features. We also introduce a distillation loss based on cosine similarity
predictions to distill the quantized model using a full-precision teacher.
Extensive experimental results demonstrate that our P4Q method outperforms
prior arts, even achieving comparable results to its full-precision
counterparts. For instance, our 8-bit P4Q can theoretically compress the
CLIP-ViT/B-32 by 4 $\times$ while achieving 66.94\% Top-1 accuracy,
outperforming the learnable prompt fine-tuned full-precision model by 2.24\%
with negligible additional parameters on the ImageNet dataset.

摘要：<paragraph>大規模預訓練的視覺語言模型 (VLM) 在各種視覺和多模態任務中獲得顯著地位，但由於訓練樣本和運算資源的限制要求，將 VLM 部署在下游應用程式平台上仍然具有挑戰性。VLM 的微調和量化可以大幅減少樣本和運算成本，這是一個迫切需求。量化有兩種盛行的典範，量化感知訓練 (QAT) 可以有效量化大規模 VLM，但會產生巨大的訓練成本，而低位元後訓練量化 (PTQ) 則會導致顯著的效能下降。我們提出了一種平衡微調和量化的方法，稱為「量化提示」(P4Q)，我們在其中設計了一個輕量級架構，利用對比損失監督來增強 PTQ 模型的辨識效能。我們的模型可以有效減少低位元量化造成的影像特徵和文字特徵之間的差距，基於可學習提示來重新組織文字表徵，並使用低位元適配器重新調整影像和文字特徵的分布。我們還引入了一個基於餘弦相似性預測的蒸餾損失，以使用全精度教師來蒸餾量化模型。廣泛的實驗結果證明，我們的 P4Q 方法優於先前的技術，甚至可以達到與其全精度對應項相當的結果。例如，我們的 8 位元 P4Q 理論上可以將 CLIP-ViT/B-32 壓縮 4 倍，同時達到 66.94% 的 Top-1 準確率，在 ImageNet 資料集上以極少的額外參數優於可學習提示微調的全精度模型 2.24%。</paragraph>

##### **Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs**
2409.17622v1 by Yusong Wang, Chaoran Cheng, Shaoning Li, Yuxuan Ren, Bin Shao, Ge Liu, Pheng-Ann Heng, Nanning Zheng

Geometric graph neural networks (GNNs) have emerged as powerful tools for
modeling molecular geometry. However, they encounter limitations in effectively
capturing long-range interactions in large molecular systems. To address this
challenge, we introduce Neural P$^3$M, a versatile enhancer of geometric GNNs
to expand the scope of their capabilities by incorporating mesh points
alongside atoms and reimaging traditional mathematical operations in a
trainable manner. Neural P$^3$M exhibits flexibility across a wide range of
molecular systems and demonstrates remarkable accuracy in predicting energies
and forces, outperforming on benchmarks such as the MD22 dataset. It also
achieves an average improvement of 22% on the OE62 dataset while integrating
with various architectures.

摘要：幾何圖形神經網路 (GNN) 已成為用於建模分子幾何形狀的強大工具。然而，它們在有效捕捉大型分子系統中的長程交互作用方面遇到限制。為了應對這一挑戰，我們引入了 Neural P$^3$M，這是一種幾何 GNN 的多功能增強器，通過整合網格點和原子，並以可訓練的方式重新構想傳統數學運算，來擴展其功能範圍。Neural P$^3$M 在廣泛的分子系統中表現出靈活性，並在預測能量和力方面表現出顯著的準確性，在 MD22 資料集等基準測試中表現優異。它還與各種架構整合，在 OE62 資料集上實現了平均 22% 的改進。

##### **ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue**
2409.17610v1 by Zhangpu Li, Changhong Zou, Suxue Ma, Zhicheng Yang, Chen Du, Youbao Tang, Zhenjie Cao, Ning Zhang, Jui-Hsin Lai, Ruei-Sung Lin, Yuan Ni, Xingzhi Sun, Jing Xiao, Kai Zhang, Mei Han

The rocketing prosperity of large language models (LLMs) in recent years has
boosted the prevalence of vision-language models (VLMs) in the medical sector.
In our online medical consultation scenario, a doctor responds to the texts and
images provided by a patient in multiple rounds to diagnose her/his health
condition, forming a multi-turn multimodal medical dialogue format. Unlike
high-quality images captured by professional equipment in traditional medical
visual question answering (Med-VQA), the images in our case are taken by
patients' mobile phones. These images have poor quality control, with issues
such as excessive background elements and the lesion area being significantly
off-center, leading to degradation of vision-language alignment in the model
training phase. In this paper, we propose ZALM3, a Zero-shot strategy to
improve vision-language ALignment in Multi-turn Multimodal Medical dialogue.
Since we observe that the preceding text conversations before an image can
infer the regions of interest (RoIs) in the image, ZALM3 employs an LLM to
summarize the keywords from the preceding context and a visual grounding model
to extract the RoIs. The updated images eliminate unnecessary background noise
and provide more effective vision-language alignment. To better evaluate our
proposed method, we design a new subjective assessment metric for multi-turn
unimodal/multimodal medical dialogue to provide a fine-grained performance
comparison. Our experiments across three different clinical departments
remarkably demonstrate the efficacy of ZALM3 with statistical significance.

摘要：近年來，大型語言模型 (LLM) 的蓬勃發展，提升了視覺語言模型 (VLM) 在醫療領域的普及率。在我們的線上醫療諮詢情境中，醫生會針對病患提供的文字和影像，進行多輪回應以診斷其健康狀況，形成多輪次多模態醫療對話格式。與傳統醫學視覺問答 (Med-VQA) 中由專業設備所拍攝的高品質影像不同，我們案例中的影像是由病患的手機所拍攝。這些影像的品質控管不佳，存在背景元素過多、病灶區域明顯偏離中心等問題，導致模型訓練階段的視覺語言對齊度下降。在本文中，我們提出 ZALM3，一種零次學習策略，用於提升多輪次多模態醫療對話中的視覺語言對齊度。由於我們觀察到影像前的先前文字對話可以推論出影像中的感興趣區域 (RoI)，因此 ZALM3 採用 LLM 來總結先前脈絡中的關鍵字，並採用視覺基礎模型來擷取 RoI。更新後的影像消除了不必要的背景雜訊，並提供了更有效的視覺語言對齊度。為了更佳評估我們提出的方法，我們設計了一種新的主觀評量指標，用於多輪次單模態/多模態醫療對話，以提供細緻的效能比較。我們在三個不同的臨床科別中所進行的實驗，以統計顯著性顯著地證明了 ZALM3 的效能。

##### **Dirichlet-Based Coarse-to-Fine Example Selection For Open-Set Annotation**
2409.17607v1 by Ye-Wen Wang, Chen-Chen Zong, Ming-Kun Xie, Sheng-Jun Huang

Active learning (AL) has achieved great success by selecting the most
valuable examples from unlabeled data. However, they usually deteriorate in
real scenarios where open-set noise gets involved, which is studied as open-set
annotation (OSA). In this paper, we owe the deterioration to the unreliable
predictions arising from softmax-based translation invariance and propose a
Dirichlet-based Coarse-to-Fine Example Selection (DCFS) strategy accordingly.
Our method introduces simplex-based evidential deep learning (EDL) to break
translation invariance and distinguish known and unknown classes by considering
evidence-based data and distribution uncertainty simultaneously. Furthermore,
hard known-class examples are identified by model discrepancy generated from
two classifier heads, where we amplify and alleviate the model discrepancy
respectively for unknown and known classes. Finally, we combine the discrepancy
with uncertainties to form a two-stage strategy, selecting the most informative
examples from known classes. Extensive experiments on various openness ratio
datasets demonstrate that DCFS achieves state-of-art performance.

摘要：主動學習 (AL) 透過從未標記資料中選取最有價值的範例，取得了巨大的成功。然而，在開放式雜訊介入的實際場景中，它們通常會惡化，這被研究為開放式標註 (OSA)。在本文中，我們將惡化歸因於基於 softmax 的平移不變性所產生的不可靠預測，並據此提出基於 Dirichlet 的粗糙到精細範例選擇 (DCFS) 策略。我們的模型引入了基於單形的證據深度學習 (EDL) 來打破平移不變性，並透過同時考慮基於證據的資料和分佈不確定性來區分已知和未知類別。此外，透過兩個分類器頭部產生的模型差異來識別困難的已知類別範例，我們分別針對未知和已知類別放大和緩解模型差異。最後，我們將差異與不確定性結合起來，形成一個兩階段策略，從已知類別中選擇最有資訊的範例。在各種開放率資料集上進行的廣泛實驗證明，DCFS 達到了最先進的效能。

##### **Deep CLAS: Deep Contextual Listen, Attend and Spell**
2409.17603v1 by Shifu Xiong, Mengzhi Wang, Genshun Wan, Hang Chen, Jianqing Gao, Lirong Dai

Contextual-LAS (CLAS) has been shown effective in improving Automatic Speech
Recognition (ASR) of rare words. It relies on phrase-level contextual modeling
and attention-based relevance scoring without explicit contextual constraint
which lead to insufficient use of contextual information. In this work, we
propose deep CLAS to use contextual information better. We introduce bias loss
forcing model to focus on contextual information. The query of bias attention
is also enriched to improve the accuracy of the bias attention score. To get
fine-grained contextual information, we replace phrase-level encoding with
character-level encoding and encode contextual information with conformer
rather than LSTM. Moreover, we directly use the bias attention score to correct
the output probability distribution of the model. Experiments using the public
AISHELL-1 and AISHELL-NER. On AISHELL-1, compared to CLAS baselines, deep CLAS
obtains a 65.78% relative recall and a 53.49% relative F1-score increase in the
named entity recognition scene.

摘要：語境 LAS (CLAS) 已被證明可有效改善罕見字詞的自動語音辨識 (ASR)。它依賴於詞組層級的語境建模和基於注意力的相關性評分，而沒有明確的語境約束，這導致語境資訊使用不足。在這項工作中，我們提出深度 CLAS 以更好地使用語境資訊。我們引入偏差損失，迫使模型專注於語境資訊。偏差注意力的查詢也得到豐富，以提高偏差注意力評分的準確性。為了獲得細粒度的語境資訊，我們用字元層級編碼取代詞組層級編碼，並使用 Conformer 而不是 LSTM 編碼語境資訊。此外，我們直接使用偏差注意力評分來修正模型的輸出機率分佈。使用公開的 AISHELL-1 和 AISHELL-NER 進行的實驗。在 AISHELL-1 上，與 CLAS 基準相比，深度 CLAS 在命名實體辨識場景中獲得了 65.78% 的相對召回率和 53.49% 的相對 F1 分數增益。

##### **Open Digital Rights Enforcement Framework (ODRE): from descriptive to enforceable policies**
2409.17602v1 by Andrea Cimmino, Juan Cano-Benito, Raúl García-Castro

From centralised platforms to decentralised ecosystems, like Data Spaces,
sharing data has become a paramount challenge. For this reason, the definition
of data usage policies has become crucial in these domains, highlighting the
necessity of effective policy enforcement mechanisms. The Open Digital Rights
Language (ODRL) is a W3C standard ontology designed to describe data usage
policies, however, it lacks built-in enforcement capabilities, limiting its
practical application. This paper introduces the Open Digital Rights
Enforcement (ODRE) framework, whose goal is to provide ODRL with enforcement
capabilities. The ODRE framework proposes a novel approach to express ODRL
policies that integrates the descriptive ontology terms of ODRL with other
languages that allow behaviour specification, such as dynamic data handling or
function evaluation. The framework includes an enforcement algorithm for ODRL
policies and two open-source implementations in Python and Java. The ODRE
framework is also designed to support future extensions of ODRL to specific
domain scenarios. In addition, current limitations of ODRE, ODRL, and current
challenges are reported. Finally, to demonstrate the enforcement capabilities
of the implementations, their performance, and their extensibility features,
several experiments have been carried out with positive results.

摘要：<paragraph>從集中式平台到分散式生態系統，例如資料空間，資料分享已成為一項至關重要的挑戰。基於此原因，資料使用政策的定義在這些領域變得至關重要，強調了有效政策執行機制的必要性。開放數位權利語言 (ODRL) 是一個 W3C 標準本体，旨在描述資料使用政策，然而，它缺乏內建的執行能力，限制了其實際應用。本文介紹了開放數位權利執行 (ODRE) 框架，其目標是為 ODRL 提供執行能力。ODRE 框架提出了一種創新的方法來表達 ODRL 政策，它將 ODRL 的描述性本体術語與允許行為規範的其他語言（例如動態資料處理或函數評估）相結合。該框架包括一個用於 ODRL 政策的執行演算法，以及兩個使用 Python 和 Java 編寫的開源實作。ODRE 框架也設計為支援 ODRL 未來針對特定領域情境的擴充。此外，也回報了 ODRE、ODRL 目前的限制，以及當前挑戰。最後，為了展示實作的執行能力、效能和可擴充性功能，已經進行了多項實驗並獲得正面結果。</paragraph>

##### **TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning**
2409.17601v1 by Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao

Pre-trained large models for multimodal contrastive learning, such as CLIP,
have been widely recognized in the industry as highly susceptible to
data-poisoned backdoor attacks. This poses significant risks to downstream
model training. In response to such potential threats, finetuning offers a
simpler and more efficient defense choice compared to retraining large models
with augmented data. In the supervised learning domain, fine-tuning defense
strategies can achieve excellent defense performance. However, in the
unsupervised and semi-supervised domain, we find that when CLIP faces some
complex attack techniques, the existing fine-tuning defense strategy,
CleanCLIP, has some limitations on defense performance. The synonym
substitution of its text-augmentation is insufficient to enhance the text
feature space. To compensate for this weakness, we improve it by proposing a
fine-grained \textbf{T}ext \textbf{A}lignment \textbf{C}leaner (TA-Cleaner) to
cut off feature connections of backdoor triggers. We randomly select a few
samples for positive and negative subtext generation at each epoch of
CleanCLIP, and align the subtexts to the images to strengthen the text
self-supervision. We evaluate the effectiveness of our TA-Cleaner against six
attack algorithms and conduct comprehensive zero-shot classification tests on
ImageNet1K. Our experimental results demonstrate that TA-Cleaner achieves
state-of-the-art defensiveness among finetuning-based defense techniques. Even
when faced with the novel attack technique BadCLIP, our TA-Cleaner outperforms
CleanCLIP by reducing the ASR of Top-1 and Top-10 by 52.02\% and 63.88\%,
respectively.

摘要：<paragraph>預訓練的大型多模態對比學習模型，例如 CLIP，在業界被廣泛認為極易受到資料中毒後門攻擊。這對下游模型訓練構成重大風險。為了應對這些潛在威脅，與使用擴充資料重新訓練大型模型相比，微調提供了一個更簡單、更有效率的防禦選擇。在監督式學習領域，微調防禦策略可以實現出色的防禦效能。然而，在無監督和半監督領域，我們發現當 CLIP 面對一些複雜的攻擊技術時，現有的微調防禦策略 CleanCLIP 在防禦效能上有一些限制。其文字擴充的同義詞替換不足以增強文字特徵空間。為了彌補這個缺點，我們通過提出一個細粒度的**T**ext **A**lignment **C**leaner（TA-Cleaner）來改進它，以切斷後門觸發器的特徵連接。我們在 CleanCLIP 的每個時期隨機選擇一些樣本進行正負子文字生成，並將子文字與影像對齊以加強文字自我監督。我們針對六種攻擊演算法評估了我們的 TA-Cleaner 的有效性，並對 ImageNet1K 進行了全面的零次分類測試。我們的實驗結果表明，TA-Cleaner 在基於微調的防禦技術中實現了最先進的防禦能力。即使面對新穎的攻擊技術 BadCLIP，我們的 TA-Cleaner 也通過將 Top-1 和 Top-10 的 ASR 分別降低 52.02% 和 63.88% 而優於 CleanCLIP。</paragraph>

##### **Subjective and Objective Quality-of-Experience Evaluation Study for Live Video Streaming**
2409.17596v1 by Zehao Zhu, Wei Sun, Jun Jia, Wei Wu, Sibin Deng, Kai Li, Ying Chen, Xiongkuo Min, Jia Wang, Guangtao Zhai

In recent years, live video streaming has gained widespread popularity across
various social media platforms. Quality of experience (QoE), which reflects
end-users' satisfaction and overall experience, plays a critical role for media
service providers to optimize large-scale live compression and transmission
strategies to achieve perceptually optimal rate-distortion trade-off. Although
many QoE metrics for video-on-demand (VoD) have been proposed, there remain
significant challenges in developing QoE metrics for live video streaming. To
bridge this gap, we conduct a comprehensive study of subjective and objective
QoE evaluations for live video streaming. For the subjective QoE study, we
introduce the first live video streaming QoE dataset, TaoLive QoE, which
consists of $42$ source videos collected from real live broadcasts and $1,155$
corresponding distorted ones degraded due to a variety of streaming
distortions, including conventional streaming distortions such as compression,
stalling, as well as live streaming-specific distortions like frame skipping,
variable frame rate, etc. Subsequently, a human study was conducted to derive
subjective QoE scores of videos in the TaoLive QoE dataset. For the objective
QoE study, we benchmark existing QoE models on the TaoLive QoE dataset as well
as publicly available QoE datasets for VoD scenarios, highlighting that current
models struggle to accurately assess video QoE, particularly for live content.
Hence, we propose an end-to-end QoE evaluation model, Tao-QoE, which integrates
multi-scale semantic features and optical flow-based motion features to
predicting a retrospective QoE score, eliminating reliance on statistical
quality of service (QoS) features.

摘要：<paragraph>近年來，直播影片串流在各種社群媒體平台上獲得廣泛的歡迎。體驗品質 (QoE) 反映了最終使用者的滿意度和整體體驗，對於媒體服務供應商來說扮演了重要的角色，以最佳化大規模的直播壓縮和傳輸策略，以達成在感官上最佳的速率失真權衡。儘管已經提出了許多針對視訊隨選 (VoD) 的 QoE 指標，但對於直播影片串流的 QoE 指標的開發仍有重大的挑戰。為了彌補這個差距，我們對直播影片串流的主觀和客觀 QoE 評量進行了一項全面的研究。對於主觀 QoE 研究，我們引入了第一個直播影片串流 QoE 資料集，TaoLive QoE，其中包含從真實直播中收集的 $42$ 個來源影片和 $1,155$ 個對應的失真影片，這些影片是由於各種串流失真而降低的，包括傳統的串流失真（例如壓縮、停頓），以及直播特定失真（例如跳格、可變幀率等）。隨後，進行了一項人體研究，以得出 TaoLive QoE 資料集中影片的主觀 QoE 分數。對於客觀 QoE 研究，我們在 TaoLive QoE 資料集以及公開可用的 VoD 場景 QoE 資料集上對現有的 QoE 模型進行基準測試，強調目前的模型難以準確評估影片 QoE，特別是對於直播內容。因此，我們提出了一個端對端的 QoE 評量模型 Tao-QoE，它整合了多尺度的語意特徵和基於光流的運動特徵，以預測回顧性的 QoE 分數，消除了對服務品質 (QoS) 統計特徵的依賴。</paragraph>

##### **DualCoTs: Dual Chain-of-Thoughts Prompting for Sentiment Lexicon Expansion of Idioms**
2409.17588v1 by Fuqiang Niu, Minghuan Tan, Bowen Zhang, Min Yang, Ruifeng Xu

Idioms represent a ubiquitous vehicle for conveying sentiments in the realm
of everyday discourse, rendering the nuanced analysis of idiom sentiment
crucial for a comprehensive understanding of emotional expression within
real-world texts. Nevertheless, the existing corpora dedicated to idiom
sentiment analysis considerably limit research in text sentiment analysis. In
this paper, we propose an innovative approach to automatically expand the
sentiment lexicon for idioms, leveraging the capabilities of large language
models through the application of Chain-of-Thought prompting. To demonstrate
the effectiveness of this approach, we integrate multiple existing resources
and construct an emotional idiom lexicon expansion dataset (called EmoIdiomE),
which encompasses a comprehensive repository of Chinese and English idioms.
Then we designed the Dual Chain-of-Thoughts (DualCoTs) method, which combines
insights from linguistics and psycholinguistics, to demonstrate the
effectiveness of using large models to automatically expand the sentiment
lexicon for idioms. Experiments show that DualCoTs is effective in idioms
sentiment lexicon expansion in both Chinese and English. For reproducibility,
we will release the data and code upon acceptance.

摘要：慣用語是傳達日常話語中情感的普遍載體，對慣用語情感的細緻分析對於全面理解現實世界文本中的情感表達至關重要。儘管如此，現有的慣用語情感分析語料庫極大地限制了文本情感分析的研究。在本文中，我們提出了一種創新的方法來自動擴展慣用語的情感詞彙，通過應用思想鏈提示利用大型語言模型的能力。為了證明這種方法的有效性，我們整合了多種現有資源，構建了一個情感慣用語詞彙擴展數據集（稱為 EmoIdiomE），其中包含了一個全面的中文和英文慣用語庫。然後，我們設計了雙重思想鏈（DualCoTs）方法，它結合了語言學和心理語言學的見解，以證明使用大型模型自動擴展慣用語情感詞彙的有效性。實驗表明，DualCoTs 在中英文慣用語情感詞彙擴展中都是有效的。為了可重複性，我們將在被接受後發布數據和代碼。

##### **Let the Quantum Creep In: Designing Quantum Neural Network Models by Gradually Swapping Out Classical Components**
2409.17583v1 by Peiyong Wang, Casey. R. Myers, Lloyd C. L. Hollenberg, Udaya Parampalli

Artificial Intelligence (AI), with its multiplier effect and wide
applications in multiple areas, could potentially be an important application
of quantum computing. Since modern AI systems are often built on neural
networks, the design of quantum neural networks becomes a key challenge in
integrating quantum computing into AI. To provide a more fine-grained
characterisation of the impact of quantum components on the performance of
neural networks, we propose a framework where classical neural network layers
are gradually replaced by quantum layers that have the same type of input and
output while keeping the flow of information between layers unchanged,
different from most current research in quantum neural network, which favours
an end-to-end quantum model. We start with a simple three-layer classical
neural network without any normalisation layers or activation functions, and
gradually change the classical layers to the corresponding quantum versions. We
conduct numerical experiments on image classification datasets such as the
MNIST, FashionMNIST and CIFAR-10 datasets to demonstrate the change of
performance brought by the systematic introduction of quantum components.
Through this framework, our research sheds new light on the design of future
quantum neural network models where it could be more favourable to search for
methods and frameworks that harness the advantages from both the classical and
quantum worlds.

摘要：人工智慧（AI）具有乘數效應，並在多個領域廣泛應用，潛在可能成為量子運算的重要應用。由於現代 AI 系統通常建立於神經網路，量子神經網路的設計成為整合量子運算至 AI 的關鍵挑戰。為了更細緻地描述量子元件對神經網路效能的影響，我們提出一個架構，其中古典神經網路層逐漸被量子層取代，而量子層具有相同類型的輸入和輸出，同時保持層間資訊流動不變，這有別於大多數現今偏好端到端量子模型的量子神經網路研究。我們從一個簡單的三層古典神經網路開始，不含任何正規化層或啟用函數，並逐漸將古典層改為對應的量子版本。我們對 MNIST、FashionMNIST 和 CIFAR-10 等影像分類資料集進行數值實驗，以展示系統導入量子元件所帶來的效能變化。透過這個架構，我們的研究為未來量子神經網路模型的設計開啟新視野，其中尋找結合古典世界和量子世界優勢的方法和架構可能更為有利。

##### **A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**
2409.17581v1 by Syed Affan Daimi, Asma Iqbal

The number of companies listed on the NYSE has been growing exponentially,
creating a significant challenge for market analysts, traders, and stockholders
who must monitor and assess the performance and strategic shifts of a large
number of companies regularly. There is an increasing need for a fast,
cost-effective, and comprehensive method to evaluate the performance and detect
and compare many companies' strategy changes efficiently. We propose a novel
data-driven approach that leverages large language models (LLMs) to
systematically analyze and rate the performance of companies based on their SEC
10-K filings. These filings, which provide detailed annual reports on a
company's financial performance and strategic direction, serve as a rich source
of data for evaluating various aspects of corporate health, including
confidence, environmental sustainability, innovation, and workforce management.
We also introduce an automated system for extracting and preprocessing 10-K
filings. This system accurately identifies and segments the required sections
as outlined by the SEC, while also isolating key textual content that contains
critical information about the company. This curated data is then fed into
Cohere's Command-R+ LLM to generate quantitative ratings across various
performance metrics. These ratings are subsequently processed and visualized to
provide actionable insights. The proposed scheme is then implemented on an
interactive GUI as a no-code solution for running the data pipeline and
creating the visualizations. The application showcases the rating results and
provides year-on-year comparisons of company performance.

摘要：紐約證券交易所上市的公司數量呈指數成長，對必須定期監控和評估大量公司績效和策略轉變的市場分析師、交易員和股東來說，這是一個重大的挑戰。對於一種快速、具成本效益且全面的方法，有越來越高的需求，以評估績效並有效地偵測和比較許多公司的策略變化。我們提出一個新穎的資料驅動方法，利用大型語言模型 (LLM) 來系統性地分析和評比公司的績效，其基礎是公司的美國證券交易委員會 (SEC) 10-K 檔。這些申報提供公司財務績效和策略方向的詳細年度報告，作為評估公司健全程度各個面向的豐富資料來源，包括信心、環境永續性、創新和員工管理。我們也導入一個自動化系統，用於擷取和預處理 10-K 申報。此系統精確地識別和區隔美國證券交易委員會所概述的必要部分，同時也孤立包含公司關鍵資訊的文字內容。接著將這些整理過的資料輸入 Cohere 的 Command-R+ LLM，以產生各種績效指標的量化評分。接著處理和視覺化這些評分，以提供可行的見解。然後在互動式 GUI 上實作建議的架構，作為執行資料管線和建立視覺化的無程式碼解決方案。此應用程式展示評分結果，並提供公司績效的年對年比較。

##### **Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**
2409.17580v1 by Zahra Sepasdar, Sushant Gautam, Cise Midoglu, Michael A. Riegler, Pål Halvorsen

Extracting meaningful insights from large and complex datasets poses
significant challenges, particularly in ensuring the accuracy and relevance of
retrieved information. Traditional data retrieval methods such as sequential
search and index-based retrieval often fail when handling intricate and
interconnected data structures, resulting in incomplete or misleading outputs.
To overcome these limitations, we introduce Structured-GraphRAG, a versatile
framework designed to enhance information retrieval across structured datasets
in natural language queries. Structured-GraphRAG utilizes multiple knowledge
graphs, which represent data in a structured format and capture complex
relationships between entities, enabling a more nuanced and comprehensive
retrieval of information. This graph-based approach reduces the risk of errors
in language model outputs by grounding responses in a structured format,
thereby enhancing the reliability of results. We demonstrate the effectiveness
of Structured-GraphRAG by comparing its performance with that of a recently
published method using traditional retrieval-augmented generation. Our findings
show that Structured-GraphRAG significantly improves query processing
efficiency and reduces response times. While our case study focuses on soccer
data, the framework's design is broadly applicable, offering a powerful tool
for data analysis and enhancing language model applications across various
structured domains.

摘要：從龐大且複雜的資料集中萃取出有意義的見解會帶來顯著的挑戰，特別是在確保擷取資訊的準確性和相關性方面。傳統的資料擷取方法，例如順序搜尋和基於索引的擷取，在處理複雜且相互連結的資料結構時，常常會失敗，導致不完整或誤導性的輸出。為了克服這些限制，我們引入了結構化圖形 RAG，這是一個通用框架，旨在增強自然語言查詢中結構化資料集的資訊擷取。結構化圖形 RAG 利用多個知識圖形，它們以結構化格式表示資料，並擷取實體之間的複雜關係，從而實現更細緻且全面的資訊擷取。這種基於圖形的做法透過以結構化格式為基礎回應，降低語言模型輸出中出現錯誤的風險，從而提高結果的可靠性。我們透過將結構化圖形 RAG 的效能與最近發表的傳統擷取增強生成方法進行比較，來證明其有效性。我們的研究結果顯示，結構化圖形 RAG 大幅提升了查詢處理效率，並縮短了回應時間。雖然我們的案例研究專注於足球資料，但這個架構的設計具有廣泛的適用性，提供了一個強大的資料分析工具，並增強了各種結構化領域的語言模型應用。

##### **Leveraging Annotator Disagreement for Text Classification**
2409.17577v1 by Jin Xu, Mariët Theune, Daniel Braun

It is common practice in text classification to only use one majority label
for model training even if a dataset has been annotated by multiple annotators.
Doing so can remove valuable nuances and diverse perspectives inherent in the
annotators' assessments. This paper proposes and compares three different
strategies to leverage annotator disagreement for text classification: a
probability-based multi-label method, an ensemble system, and instruction
tuning. All three approaches are evaluated on the tasks of hate speech and
abusive conversation detection, which inherently entail a high degree of
subjectivity. Moreover, to evaluate the effectiveness of embracing annotation
disagreements for model training, we conduct an online survey that compares the
performance of the multi-label model against a baseline model, which is trained
with the majority label.
  The results show that in hate speech detection, the multi-label method
outperforms the other two approaches, while in abusive conversation detection,
instruction tuning achieves the best performance. The results of the survey
also show that the outputs from the multi-label models are considered a better
representation of the texts than the single-label model.

摘要：在文本分类中，即使数据集是由多个注释者注释的，也只使用一个多数标签进行模型训练是普遍做法。这样做会去除注释者评估中固有的有价值的细微差别和不同的观点。本文提出了三种不同的策略来利用注释者分歧进行文本分类，并对它们进行了比较：基于概率的多标签方法、集成系统和指令微调。所有这三种方法都在仇恨言论和辱骂性对话检测任务上进行了评估，这些任务本质上需要高度的主观性。此外，为了评估在模型训练中接纳注释分歧的有效性，我们进行了一项在线调查，比较了多标签模型与使用多数标签训练的基线模型的性能。结果表明，在仇恨言论检测中，多标签方法优于其他两种方法，而在辱骂性对话检测中，指令微调实现了最佳性能。调查结果还表明，多标签模型的输出被认为比单标签模型更好地代表了文本。

##### **Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**
2409.17572v1 by Owen Xingjian Zhang, Shuyao Zhou, Jiayi Geng, Yuhan Liu, Sunny Xun Liu

In response to the increasing mental health challenges faced by college
students, we sought to understand their perspectives on how AI applications,
particularly Large Language Models (LLMs), can be leveraged to enhance their
mental well-being. Through pilot interviews with ten diverse students, we
explored their opinions on the use of LLMs across five fictional scenarios:
General Information Inquiry, Initial Screening, Reshaping Patient-Expert
Dynamics, Long-term Care, and Follow-up Care. Our findings revealed that
students' acceptance of LLMs varied by scenario, with participants highlighting
both potential benefits, such as proactive engagement and personalized
follow-up care, and concerns, including limitations in training data and
emotional support. These insights inform how AI technology should be designed
and implemented to effectively support and enhance students' mental well-being,
particularly in scenarios where LLMs can complement traditional methods, while
maintaining empathy and respecting individual preferences.

摘要：為了回應大學生面臨日益增加的心理健康挑戰，我們試圖了解他們對 AI 應用程式的觀點，特別是大型語言模型 (LLM) 如何能提升他們的心理健康。透過對十位不同學生的試點訪談，我們探討了他們對 LLM 在五個虛構情境中的使用意見：一般資訊詢問、初步篩選、重塑患者與專家的互動模式、長期照護和後續照護。我們的研究結果顯示，學生對 LLM 的接受度因情境而異，參與者強調了潛在的好處，例如主動參與和個人化的後續照護，以及疑慮，包括訓練資料和情緒支持的限制。這些見解說明了 AI 技術應如何設計和實施，以有效支援和提升學生的心理健康，特別是在 LLM 能補充傳統方法的情境中，同時保持同理心並尊重個人偏好。

##### **Showing Many Labels in Multi-label Classification Models: An Empirical Study of Adversarial Examples**
2409.17568v1 by Yujiang Liu, Wenjian Luo, Zhijian Chen, Muhammad Luqman Naseem

With the rapid development of Deep Neural Networks (DNNs), they have been
applied in numerous fields. However, research indicates that DNNs are
susceptible to adversarial examples, and this is equally true in the
multi-label domain. To further investigate multi-label adversarial examples, we
introduce a novel type of attacks, termed "Showing Many Labels". The objective
of this attack is to maximize the number of labels included in the classifier's
prediction results. In our experiments, we select nine attack algorithms and
evaluate their performance under "Showing Many Labels". Eight of the attack
algorithms were adapted from the multi-class environment to the multi-label
environment, while the remaining one was specifically designed for the
multi-label environment. We choose ML-LIW and ML-GCN as target models and train
them on four popular multi-label datasets: VOC2007, VOC2012, NUS-WIDE, and
COCO. We record the success rate of each algorithm when it shows the expected
number of labels in eight different scenarios. Experimental results indicate
that under the "Showing Many Labels", iterative attacks perform significantly
better than one-step attacks. Moreover, it is possible to show all labels in
the dataset.

摘要：隨著深度神經網路 (DNN) 的快速發展，它們已被應用於許多領域。然而，研究表明 DNN 容易受到對抗性範例的影響，這在多標籤領域中也是如此。為了進一步研究多標籤對抗性範例，我們引入了一種類型的攻擊，稱為「顯示許多標籤」。此攻擊的目標是最大化分類器預測結果中包含的標籤數量。在我們的實驗中，我們選擇了九種攻擊演算法，並評估它們在「顯示許多標籤」下的表現。其中八種攻擊演算法從多類別環境改編為多標籤環境，而剩下的則專門設計用於多標籤環境。我們選擇 ML-LIW 和 ML-GCN 作為目標模型，並在四個流行的多標籤資料集上訓練它們：VOC2007、VOC2012、NUS-WIDE 和 COCO。我們記錄了每個演算法在八種不同情況下顯示預期標籤數量時的成功率。實驗結果表明，在「顯示許多標籤」下，迭代攻擊的表現顯著優於單步攻擊。此外，顯示資料集中所有標籤是可能的。

##### **Pixel-Space Post-Training of Latent Diffusion Models**
2409.17565v1 by Christina Zhang, Simran Motwani, Matthew Yu, Ji Hou, Felix Juefei-Xu, Sam Tsai, Peter Vajda, Zijian He, Jialiang Wang

Latent diffusion models (LDMs) have made significant advancements in the
field of image generation in recent years. One major advantage of LDMs is their
ability to operate in a compressed latent space, allowing for more efficient
training and deployment. However, despite these advantages, challenges with
LDMs still remain. For example, it has been observed that LDMs often generate
high-frequency details and complex compositions imperfectly. We hypothesize
that one reason for these flaws is due to the fact that all pre- and
post-training of LDMs are done in latent space, which is typically $8 \times 8$
lower spatial-resolution than the output images. To address this issue, we
propose adding pixel-space supervision in the post-training process to better
preserve high-frequency details. Experimentally, we show that adding a
pixel-space objective significantly improves both supervised quality
fine-tuning and preference-based post-training by a large margin on a
state-of-the-art DiT transformer and U-Net diffusion models in both visual
quality and visual flaw metrics, while maintaining the same text alignment
quality.

摘要：潛在擴散模型 (LDM) 近年來在影像生成領域取得顯著進展。LDM 的一大優勢是它們能夠在壓縮潛在空間中運作，從而實現更有效率的訓練和部署。然而，儘管有這些優勢，LDM 仍存在挑戰。例如，人們觀察到 LDM 經常不完美地生成高頻率細節和複雜的組合。我們假設這些缺陷的一個原因是，LDM 的所有訓練前和訓練後都是在潛在空間中完成的，而潛在空間通常比輸出影像的空間解析度低 $8 \times 8$。為了解決這個問題，我們建議在訓練後過程中加入像素空間監督，以更好地保留高頻率細節。在實驗中，我們表明加入像素空間目標顯著改善了監督式品質微調和基於偏好的訓練後，在最先進的 DiT Transformer 和 U-Net 擴散模型中，在視覺品質和視覺缺陷指標上都有大幅進步，同時維持相同的文字對齊品質。

##### **Modulated Intervention Preference Optimization (MIPO): Keey the Easy, Refine the Difficult**
2409.17545v1 by Cheolhun Jang

Preference optimization methods typically begin training with a well-trained
SFT model as a reference model. In RLHF and DPO, a regularization term is used
during the preference optimization process to prevent the policy model from
deviating too far from the reference model's distribution, thereby avoiding the
generation of anomalous responses. When the reference model is already
well-aligned with the given data or only requires slight adjustments, this
approach can produce a well-aligned model. However, if the reference model is
not aligned with the given data and requires significant deviation from its
current state, a regularization term may actually hinder the model alignment.
In this study, we propose \textbf{Modulated Intervention Preference
Optimization (MIPO)} to address this issue. MIPO modulates the degree of
intervention from the reference model based on how well the given data is
aligned with it. If the data is well-aligned, the intervention is increased to
prevent the policy model from diverging significantly from reference model.
Conversely, if the alignment is poor, the interference is reduced to facilitate
more extensive training. We compare the performance of MIPO and DPO using
Mistral-7B and Llama3-8B in Alpaca Eval 2.0 and MT-Bench. The experimental
results demonstrate that MIPO consistently outperforms DPO across various
evaluation scenarios.

摘要：偏好优化方法通常以训练有素的 SFT 模型作为参考模型来开始训练。在 RLHF 和 DPO 中，在偏好优化过程中使用正则化项来防止策略模型偏离参考模型的分布太远，从而避免生成异常响应。当参考模型已经与给定数据很好地对齐或只需要微调时，这种方法可以生成一个很好地对齐的模型。然而，如果参考模型与给定数据不一致，并且需要与其当前状态有较大偏差，那么正则化项实际上可能会阻碍模型对齐。在这项研究中，我们提出了**调制干预偏好优化 (MIPO)** 来解决这个问题。MIPO 根据给定数据与其对齐的程度来调节参考模型的干预程度。如果数据对齐良好，则增加干预以防止策略模型与参考模型显着偏离。相反，如果对齐较差，则减少干扰以促进更广泛的训练。我们使用 Alpaca Eval 2.0 和 MT-Bench 中的 Mistral-7B 和 Llama3-8B 比较了 MIPO 和 DPO 的性能。实验结果表明，在各种评估场景中，MIPO 的表现始终优于 DPO。

##### **Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models**
2409.17539v1 by Tongxuan Liu, Wenjiang Xu, Weizhe Huang, Xingyu Wang, Jiaxing Wang, Hailong Yang, Jing Li

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks but their performance in complex logical reasoning tasks remains
unsatisfactory. Although some prompting methods, such as Chain-of-Thought, can
improve the reasoning ability of LLMs to some extent, they suffer from an
unfaithful issue where derived conclusions may not align with the generated
reasoning chain. To address this issue, some studies employ the approach of
propositional logic to further enhance logical reasoning abilities of LLMs.
However, the potential omissions in the extraction of logical expressions in
these methods can cause information loss in the logical reasoning process,
thereby generating incorrect results. To this end, we propose Logic-of-Thought
(LoT) prompting which employs propositional logic to generate expanded logical
information from input context, and utilizes the generated logical information
as an additional augmentation to the input prompts, thereby enhancing the
capability of logical reasoning. The LoT is orthogonal to existing prompting
methods and can be seamlessly integrated with them. Extensive experiments
demonstrate that LoT boosts the performance of various prompting methods with a
striking margin across five logical reasoning tasks. In particular, the LoT
enhances Chain-of-Thought's performance on the ReClor dataset by +4.35%;
moreover, it improves Chain-of-Thought with Self-Consistency's performance on
LogiQA by +5%; additionally, it boosts performance of Tree-of-Thoughts on
ProofWriter dataset by +8%.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的能力，但它們在複雜邏輯推理任務中的表現仍不盡理想。儘管某些提示方法（例如思想鏈）可以在某種程度上改善 LLM 的推理能力，但它們存在一個不忠實的問題，即推導出的結論可能與生成的推理鏈不一致。為了解決這個問題，一些研究採用命題邏輯的方法來進一步增強 LLM 的邏輯推理能力。然而，這些方法在提取邏輯表達式時潛在的遺漏可能會導致邏輯推理過程中資訊遺失，從而產生不正確的結果。為此，我們提出了思想邏輯 (LoT) 提示，它採用命題邏輯從輸入上下文生成擴充的邏輯資訊，並將生成的邏輯資訊作為輸入提示的額外擴充，從而增強邏輯推理的能力。LoT 與現有的提示方法正交，並且可以與它們無縫整合。大量的實驗表明，LoT 以顯著的幅度提升了各種提示方法在五項邏輯推理任務中的表現。特別是，LoT 將思想鏈在 ReClor 資料集上的表現提升了 +4.35%；此外，它將具有自洽性的思想鏈在 LogiQA 上的表現提升了 +5%；此外，它將思想樹在 ProofWriter 資料集上的表現提升了 +8%。

##### **On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy**
2409.17538v1 by Saber Malekmohammadi, Golnoosh Farnadi

A significant approach in natural language processing involves large-scale
pre-training on general domain data followed by adaptation to specific tasks or
domains. As models grow in size, full fine-tuning all parameters becomes
increasingly impractical. To address this, some methods for low-rank task
adaptation of language models have been proposed, e.g. LoRA and FLoRA. These
methods keep the pre-trained model weights fixed and incorporate trainable
low-rank decomposition matrices into some layers of the transformer
architecture, called adapters. This approach significantly reduces the number
of trainable parameters required for downstream tasks compared to full
fine-tuning all parameters. In this work, we look at low-rank adaptation from
the lens of data privacy. We show theoretically that the low-rank adaptation
used in LoRA and FLoRA is equivalent to injecting some random noise into the
batch gradients w.r.t the adapter parameters coming from their full
fine-tuning, and we quantify the variance of the injected noise. By
establishing a Berry-Esseen type bound on the total variation distance between
the noise distribution and a Gaussian distribution with the same variance, we
show that the dynamics of LoRA and FLoRA are very close to differentially
private full fine-tuning the adapters, which suggests that low-rank adaptation
implicitly provides privacy w.r.t the fine-tuning data. Finally, using
Johnson-Lindenstrauss lemma, we show that when augmented with gradient
clipping, low-rank adaptation is almost equivalent to differentially private
full fine-tuning adapters with a fixed noise scale.

摘要：自然語言處理中的一個重要方法涉及在一般領域資料上進行大規模預訓練，然後再適應特定任務或領域。隨著模型規模的擴大，對所有參數進行完全微調變得越來越不切實際。為了解決這個問題，已經提出了一些用於語言模型低階任務適應的方法，例如 LoRA 和 FLoRA。這些方法保持預訓練模型權重固定，並將可訓練的低階分解矩陣整合到Transformer架構的某些層中，稱為適配器。與對所有參數進行完全微調相比，這種方法顯著減少了下游任務所需的訓練參數數量。在這項工作中，我們從資料隱私的角度來看低階適應。我們從理論上證明了 LoRA 和 FLoRA 中使用的低階適應等於將一些隨機雜訊注入到來自它們完全微調的適配器參數的批次梯度中，並且我們量化了注入雜訊的變異數。通過在雜訊分佈和具有相同變異數的高斯分佈之間建立貝瑞-艾森型界限，我們表明 LoRA 和 FLoRA 的動態非常接近於差分私有完全微調適配器，這表明低階適應隱含地提供了微調資料的隱私。最後，使用 Johnson-Lindenstrauss 引理，我們表明在梯度裁剪的增強下，低階適應幾乎等於具有固定雜訊比例的差分私有完全微調適配器。

##### **MUSE: Integrating Multi-Knowledge for Knowledge Graph Completion**
2409.17536v1 by Pengjie Liu

Knowledge Graph Completion (KGC) aims to predict the missing [relation] part
of (head entity)--[relation]->(tail entity) triplet. Most existing KGC methods
focus on single features (e.g., relation types) or sub-graph aggregation.
However, they do not fully explore the Knowledge Graph (KG) features and
neglect the guidance of external semantic knowledge. To address these
shortcomings, we propose a knowledge-aware reasoning model (MUSE), which
designs a novel multi-knowledge representation learning mechanism for missing
relation prediction. Our model develops a tailored embedding space through
three parallel components: 1) Prior Knowledge Learning for enhancing the
triplets' semantic representation by fine-tuning BERT; 2) Context Message
Passing for enhancing the context messages of KG; 3) Relational Path
Aggregation for enhancing the path representation from the head entity to the
tail entity. The experimental results show that MUSE significantly outperforms
other baselines on four public datasets, achieving over 5.50% H@1 improvement
and 4.20% MRR improvement on the NELL995 dataset. The code and datasets will be
released via https://github.com/SUSTech-TP/ADMA2024-MUSE.git.

摘要：知識圖譜補全 (KGC) 旨在預測 (頭部實體)--[關係]->(尾部實體) 三元組中遺失的 [關係] 部分。大多數現有的 KGC 方法側重於單一特徵 (例如，關係類型) 或子圖聚合。但是，它們並未充分探索知識圖譜 (KG) 特徵，並忽略了外部語義知識的指導。為了解決這些缺點，我們提出了一個知識感知推理模型 (MUSE)，它為遺失關係預測設計了一個新穎的多知識表示學習機制。我們的模型通過三個並行組件開發了一個定制的嵌入空間：1) 先驗知識學習，通過微調 BERT 來增強三元組的語義表示；2) 上下文訊息傳遞，用於增強 KG 的上下文訊息；3) 關係路徑聚合，用於增強從頭部實體到尾部實體的路徑表示。實驗結果表明，MUSE 在四個公開數據集上顯著優於其他基準，在 NELL995 數據集上實現了超過 5.50% 的 H@1 改進和 4.20% 的 MRR 改進。代碼和數據集將通過 https://github.com/SUSTech-TP/ADMA2024-MUSE.git 發布。

##### **Just say what you want: only-prompting self-rewarding online preference optimization**
2409.17534v1 by Ruijie Xu, Zhihan Liu, Yongfei Liu, Shipeng Yan, Zhaoran Wang, Zhi Zhang, Xuming He

We address the challenge of online Reinforcement Learning from Human Feedback
(RLHF) with a focus on self-rewarding alignment methods. In online RLHF,
obtaining feedback requires interaction with the environment, which can be
costly when using additional reward models or the GPT-4 API. Current
self-rewarding approaches rely heavily on the discriminator's judgment
capabilities, which are effective for large-scale models but challenging to
transfer to smaller ones. To address these limitations, we propose a novel,
only-prompting self-rewarding online algorithm that generates preference
datasets without relying on judgment capabilities. Additionally, we employ
fine-grained arithmetic control over the optimality gap between positive and
negative examples, generating more hard negatives in the later stages of
training to help the model better capture subtle human preferences. Finally, we
conduct extensive experiments on two base models, Mistral-7B and
Mistral-Instruct-7B, which significantly bootstrap the performance of the
reference model, achieving 34.5% in the Length-controlled Win Rates of
AlpacaEval 2.0.

摘要：我們透過專注於自獎勵對齊方法，來解決人類回饋線上強化學習 (RLHF) 的挑戰。在線上 RLHF 中，取得回饋需要與環境互動，這在使用額外的獎勵模型或 GPT-4 API 時可能會很昂貴。目前的自獎勵方法嚴重依賴判別器的判斷能力，這對於大型模型來說很有效，但對於較小的模型來說卻很難轉移。為了解決這些限制，我們提出了一種新穎的、僅提示自獎勵線上演算法，它會產生偏好資料集，而不依賴判斷能力。此外，我們採用細緻的算術控制來控制正負範例之間的最佳化差距，在訓練的後續階段產生更多困難的負面範例，以幫助模型更好地捕捉細微的人類偏好。最後，我們在兩個基礎模型 Mistral-7B 和 Mistral-Instruct-7B 上進行了廣泛的實驗，這顯著地引導了參考模型的效能，在 AlpacaEval 2.0 的長度控制勝率中達到 34.5%。

##### **SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion**
2409.17531v1 by Ming Dai, Lingfeng Yang, Yihao Xu, Zhenhua Feng, Wankou Yang

Visual grounding is a common vision task that involves grounding descriptive
sentences to the corresponding regions of an image. Most existing methods use
independent image-text encoding and apply complex hand-crafted modules or
encoder-decoder architectures for modal interaction and query reasoning.
However, their performance significantly drops when dealing with complex
textual expressions. This is because the former paradigm only utilizes limited
downstream data to fit the multi-modal feature fusion. Therefore, it is only
effective when the textual expressions are relatively simple. In contrast,
given the wide diversity of textual expressions and the uniqueness of
downstream training data, the existing fusion module, which extracts multimodal
content from a visual-linguistic context, has not been fully investigated. In
this paper, we present a simple yet robust transformer-based framework, SimVG,
for visual grounding. Specifically, we decouple visual-linguistic feature
fusion from downstream tasks by leveraging existing multimodal pre-trained
models and incorporating additional object tokens to facilitate deep
integration of downstream and pre-training tasks. Furthermore, we design a
dynamic weight-balance distillation method in the multi-branch synchronous
learning process to enhance the representation capability of the simpler
branch. This branch only consists of a lightweight MLP, which simplifies the
structure and improves reasoning speed. Experiments on six widely used VG
datasets, i.e., RefCOCO/+/g, ReferIt, Flickr30K, and GRefCOCO, demonstrate the
superiority of SimVG. Finally, the proposed method not only achieves
improvements in efficiency and convergence speed but also attains new
state-of-the-art performance on these benchmarks. Codes and models will be
available at \url{https://github.com/Dmmm1997/SimVG}.

摘要：視覺基礎是一個常見的視覺任務，它涉及將描述性句子基礎化到圖像的對應區域。大多數現有方法使用獨立的圖像文本編碼，並應用複雜的手工模組或編碼器解碼器架構，以進行模態互動和查詢推理。然而，在處理複雜的文本表達時，它們的效能會顯著下降。這是因為前一種範例僅利用有限的下游資料來配合多模態特徵融合。因此，只有在文本表達相對簡單時才有效。相反地，鑑於文本表達的多樣性以及下游訓練資料的獨特性，現有的融合模組（從視覺語言環境中提取多模態內容）尚未得到充分研究。在本文中，我們提出了一個基於轉換器的簡單但強大的框架 SimVG，用於視覺基礎。具體來說，我們通過利用現有的多模態預訓練模型並加入額外的物件標記來解耦視覺語言特徵融合和下游任務，以促進下游和預訓練任務的深度整合。此外，我們在多分支同步學習過程中設計了一個動態權重平衡蒸餾方法，以增強較簡單分支的表示能力。此分支僅包含一個輕量級 MLP，它簡化了結構並提高了推理速度。在六個廣泛使用的 VG 資料集（即 RefCOCO/+/g、ReferIt、Flickr30K 和 GRefCOCO）上的實驗證明了 SimVG 的優越性。最後，所提出的方法不僅在效率和收斂速度方面取得了改進，而且在這些基準上還達到了新的最先進效能。程式碼和模型將在 \url{https://github.com/Dmmm1997/SimVG} 提供。

##### **Data Proportion Detection for Optimized Data Management for Large Language Models**
2409.17527v1 by Hao Liang, Keshi Zhao, Yajie Yang, Bin Cui, Guosheng Dong, Zenan Zhou, Wentao Zhang

Large language models (LLMs) have demonstrated exceptional performance across
a wide range of tasks and domains, with data preparation playing a critical
role in achieving these results. Pre-training data typically combines
information from multiple domains. To maximize performance when integrating
data from various domains, determining the optimal data proportion is
essential. However, state-of-the-art (SOTA) LLMs rarely disclose details about
their pre-training data, making it difficult for researchers to identify ideal
data proportions. In this paper, we introduce a new topic, \textit{data
proportion detection}, which enables the automatic estimation of pre-training
data proportions by analyzing the generated outputs of LLMs. We provide
rigorous theoretical proofs, practical algorithms, and preliminary experimental
results for data proportion detection. Based on these findings, we offer
valuable insights into the challenges and future directions for effective data
proportion detection and data management.

摘要：大型語言模型 (LLM) 在廣泛的任務和領域中展現出非凡的效能，而資料準備在達成這些結果中扮演關鍵角色。預訓練資料通常結合來自多個領域的資訊。為了在整合來自不同領域的資料時最大化效能，決定最佳資料比例至關重要。然而，最先進 (SOTA) 的 LLM 鮮少揭露其預訓練資料的詳細資訊，這讓研究人員難以找出理想的資料比例。在本文中，我們介紹了一個新主題「資料比例偵測」，它能透過分析 LLM 生成的輸出自動估計預訓練資料的比例。我們提供了嚴謹的理論證明、實用的演算法，以及資料比例偵測的初步實驗結果。根據這些發現，我們提供了寶貴的見解，說明有效資料比例偵測和資料管理的挑戰和未來方向。

##### **Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Integrating SGBM and Segmentation Models**
2409.17526v1 by Yida Lin, Bing Xue, Mengjie Zhang, Sam Schofield, Richard Green

Manual pruning of radiata pine trees presents significant safety risks due to
their substantial height and the challenging terrains in which they thrive. To
address these risks, this research proposes the development of a drone-based
pruning system equipped with specialized pruning tools and a stereo vision
camera, enabling precise detection and trimming of branches. Deep learning
algorithms, including YOLO and Mask R-CNN, are employed to ensure accurate
branch detection, while the Semi-Global Matching algorithm is integrated to
provide reliable distance estimation. The synergy between these techniques
facilitates the precise identification of branch locations and enables
efficient, targeted pruning. Experimental results demonstrate that the combined
implementation of YOLO and SGBM enables the drone to accurately detect branches
and measure their distances from the drone. This research not only improves the
safety and efficiency of pruning operations but also makes a significant
contribution to the advancement of drone technology in the automation of
agricultural and forestry practices, laying a foundational framework for
further innovations in environmental management.

摘要：人工修剪輻射松樹由於其高度和生長的地形具有挑戰性，因此存在重大的安全風險。為了應對這些風險，本研究提出開發一種基於無人機的修剪系統，配備專用修剪工具和立體視覺相機，實現精確的樹枝檢測和修剪。採用深度學習演算法，包括 YOLO 和 Mask R-CNN，以確保準確的樹枝檢測，同時整合半全局匹配演算法以提供可靠的距離估計。這些技術之間的協同作用有助於精確識別樹枝位置，並實現高效、有針對性的修剪。實驗結果表明，YOLO 和 SGBM 的結合實作使無人機能夠準確檢測樹枝並測量它們與無人機的距離。本研究不僅提高了修剪作業的安全性與效率，而且對農業和林業實務自動化中的無人機技術進步做出了重大貢獻，為環境管理的進一步創新奠定了基礎架構。

##### **When A Man Says He Is Pregnant: ERP Evidence for A Rational Account of Speaker-contextualized Language Comprehension**
2409.17525v1 by Hanlin Wu, Zhenguang G. Cai

Spoken language is often, if not always, understood in a context that
includes the identities of speakers. For instance, we can easily make sense of
an utterance such as "I'm going to have a manicure this weekend" or "The first
time I got pregnant I had a hard time" when the utterance is spoken by a woman,
but it would be harder to understand when it is spoken by a man. Previous
event-related potential (ERP) studies have shown mixed results regarding the
neurophysiological responses to such speaker-mismatched utterances, with some
reporting an N400 effect and others a P600 effect. In an experiment involving
64 participants, we showed that these different ERP effects reflect distinct
cognitive processes employed to resolve the speaker-message mismatch. When
possible, the message is integrated with the speaker context to arrive at an
interpretation, as in the case of violations of social stereotypes (e.g., men
getting a manicure), resulting in an N400 effect. However, when such
integration is impossible due to violations of biological knowledge (e.g., men
getting pregnant), listeners engage in an error correction process to revise
either the perceived utterance or the speaker context, resulting in a P600
effect. Additionally, we found that the social N400 effect decreased as a
function of the listener's personality trait of openness, while the biological
P600 effect remained robust. Our findings help to reconcile the empirical
inconsistencies in the literature and provide a rational account of
speaker-contextualized language comprehension.

摘要：口語通常（如果不是總是）在包含說話者身分的脈絡中被理解。例如，當一個女人說出「我這個週末要去做指甲」或「我第一次懷孕時很辛苦」時，我們可以輕易理解這句話的意思，但如果這句話是由一個男人說出的，理解起來就會比較困難。先前與事件相關的電位 (ERP) 研究顯示，對於這種說話者與訊息不符的語句，神經生理反應的結果好壞參半，有些研究報告了 N400 效應，而另一些則報告了 P600 效應。在一個包含 64 名參與者的實驗中，我們發現這些不同的 ERP 效應反映了不同的認知過程，用於解決說話者與訊息不符的問題。若有可能，訊息會與說話者的脈絡整合，以得出一個詮釋，就像違反社會刻板印象的情況（例如，男人去做指甲），導致 N400 效應。然而，當這種整合由於違反生物知識（例如，男人懷孕）而不可能時，聽眾會進行錯誤修正過程，以修改感知到的語句或說話者的脈絡，導致 P600 效應。此外，我們發現社會 N400 效應會隨著聽眾的人格特質開放性而降低，而生物 P600 效應則保持強勁。我們的發現有助於調和文獻中的經驗不一致性，並對說話者脈絡化的語言理解提供一個合理的說明。

