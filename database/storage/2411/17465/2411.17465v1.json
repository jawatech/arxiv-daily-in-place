{"2411.17465": {"publish_time": "2024-11-26", "title": "ShowUI: One Vision-Language-Action Model for GUI Visual Agent", "paper_summary": "Building Graphical User Interface (GUI) assistants holds significant promise\nfor enhancing human workflow productivity. While most agents are\nlanguage-based, relying on closed-source API with text-rich meta-information\n(e.g., HTML or accessibility tree), they show limitations in perceiving UI\nvisuals as humans do, highlighting the need for GUI visual agents. In this\nwork, we develop a vision-language-action model in digital world, namely\nShowUI, which features the following innovations: (i) UI-Guided Visual Token\nSelection to reduce computational costs by formulating screenshots as an UI\nconnected graph, adaptively identifying their redundant relationship and serve\nas the criteria for token selection during self-attention blocks; (ii)\nInterleaved Vision-Language-Action Streaming that flexibly unifies diverse\nneeds within GUI tasks, enabling effective management of visual-action history\nin navigation or pairing multi-turn query-action sequences per screenshot to\nenhance training efficiency; (iii) Small-scale High-quality GUI\nInstruction-following Datasets by careful data curation and employing a\nresampling strategy to address significant data type imbalances. With above\ncomponents, ShowUI, a lightweight 2B model using 256K data, achieves a strong\n75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection\nfurther reduces 33% of redundant visual tokens during training and speeds up\nthe performance by 1.4x. Navigation experiments across web Mind2Web, mobile\nAITW, and online MiniWob environments further underscore the effectiveness and\npotential of our model in advancing GUI visual agents. The models are available\nat https://github.com/showlab/ShowUI.", "paper_summary_zh": "<paragraph>\u5efa\u69cb\u5716\u5f62\u4f7f\u7528\u8005\u4ecb\u9762 (GUI) \u52a9\u7406\u6975\u6709\u671b\u63d0\u5347\u4eba\u985e\u5de5\u4f5c\u6d41\u7a0b\u7684\u751f\u7522\u529b\u3002\u96d6\u7136\u5927\u591a\u6578\u4ee3\u7406\u90fd\u662f\u57fa\u65bc\u8a9e\u8a00\uff0c\u4ef0\u8cf4\u5177\u6709\u8c50\u5bcc\u6587\u5b57\u5143\u8cc7\u8a0a\u5c01\u9589\u539f\u59cb\u78bc API\uff08\u4f8b\u5982 HTML \u6216\u7121\u969c\u7919\u6a39\uff09\uff0c\u4f46\u5b83\u5011\u5728\u611f\u77e5\u4f7f\u7528\u8005\u4ecb\u9762\u8996\u89ba\u6548\u679c\u65b9\u9762\u986f\u793a\u51fa\u9650\u5236\uff0c\u9019\u51f8\u986f\u4e86\u5c0d GUI \u8996\u89ba\u4ee3\u7406\u7684\u9700\u6c42\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5728\u6578\u4f4d\u4e16\u754c\u4e2d\u958b\u767c\u4e86\u4e00\u500b\u8996\u89ba\u8a9e\u8a00\u52d5\u4f5c\u6a21\u578b\uff0c\u5373 ShowUI\uff0c\u5176\u5177\u6709\u4ee5\u4e0b\u5275\u65b0\u529f\u80fd\uff1a(i) UI \u5f15\u5c0e\u8996\u89ba\u4ee3\u5e63\u9078\u64c7\uff0c\u900f\u904e\u5c07\u87a2\u5e55\u622a\u5716\u8868\u8ff0\u70ba UI \u9023\u63a5\u5716\uff0c\u81ea\u9069\u61c9\u5730\u8b58\u5225\u5176\u5197\u9918\u95dc\u4fc2\uff0c\u4e26\u4f5c\u70ba\u81ea\u6ce8\u610f\u529b\u5340\u584a\u4e2d\u4ee3\u5e63\u9078\u64c7\u7684\u6e96\u5247\uff0c\u4ee5\u964d\u4f4e\u904b\u7b97\u6210\u672c\uff1b(ii) \u4ea4\u932f\u8996\u89ba\u8a9e\u8a00\u52d5\u4f5c\u4e32\u6d41\uff0c\u9748\u6d3b\u5730\u7d71\u4e00 GUI \u4efb\u52d9\u4e2d\u7684\u5404\u7a2e\u9700\u6c42\uff0c\u5728\u5c0e\u89bd\u4e2d\u6709\u6548\u7ba1\u7406\u8996\u89ba\u52d5\u4f5c\u6b77\u7a0b\uff0c\u6216\u914d\u5c0d\u6bcf\u500b\u87a2\u5e55\u622a\u5716\u7684\u591a\u8f2a\u67e5\u8a62\u52d5\u4f5c\u5e8f\u5217\uff0c\u4ee5\u63d0\u5347\u8a13\u7df4\u6548\u7387\uff1b(iii) \u5c0f\u898f\u6a21\u9ad8\u54c1\u8cea GUI \u6307\u4ee4\u9075\u5faa\u8cc7\u6599\u96c6\uff0c\u900f\u904e\u4ed4\u7d30\u7684\u8cc7\u6599\u6574\u7406\u548c\u63a1\u7528\u518d\u62bd\u6a23\u7b56\u7565\uff0c\u4f86\u89e3\u6c7a\u986f\u8457\u7684\u8cc7\u6599\u985e\u578b\u4e0d\u5e73\u8861\u3002ShowUI \u662f\u4e00\u500b\u4f7f\u7528 256K \u8cc7\u6599\u7684\u8f15\u91cf\u7d1a 2B \u6a21\u578b\uff0c\u5177\u5099\u4e0a\u8ff0\u7d44\u6210\u90e8\u5206\uff0c\u5728\u96f6\u6b21\u65b9\u87a2\u5e55\u622a\u5716\u63a5\u5730\u4e2d\u9054\u5230\u5f37\u52c1\u7684 75.1% \u7cbe\u78ba\u5ea6\u3002\u5176 UI \u5f15\u5c0e\u4ee3\u5e63\u9078\u64c7\u9032\u4e00\u6b65\u6e1b\u5c11\u4e86\u8a13\u7df4\u671f\u9593 33% \u7684\u5197\u9918\u8996\u89ba\u4ee3\u5e63\uff0c\u4e26\u5c07\u6548\u80fd\u63d0\u5347\u4e86 1.4 \u500d\u3002\u8de8\u7db2\u8def Mind2Web\u3001\u884c\u52d5 AITW \u548c\u7dda\u4e0a MiniWob \u74b0\u5883\u7684\u5c0e\u89bd\u5be6\u9a57\u9032\u4e00\u6b65\u5f37\u8abf\u4e86\u6211\u5011\u7684\u6a21\u578b\u5728\u63a8\u9032 GUI \u8996\u89ba\u4ee3\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6f5b\u529b\u3002\u9019\u4e9b\u6a21\u578b\u53ef\u5728 https://github.com/showlab/ShowUI \u53d6\u5f97\u3002</paragraph>", "author": "Kevin Qinghong Lin et.al.", "authors": "Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou", "id": "2411.17465v1", "paper_url": "http://arxiv.org/abs/2411.17465v1", "repo": "https://github.com/showlab/showui"}}