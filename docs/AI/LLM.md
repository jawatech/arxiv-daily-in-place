
### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-29**|**Stylus: Automatic Adapter Selection for Diffusion Models**|Michael Luo et.al.|[2404.18928v1](http://arxiv.org/abs/2404.18928v1)|null|
|**2024-04-29**|**Holmes: Benchmark the Linguistic Competence of Language Models**|Andreas Waldis et.al.|[2404.18923v1](http://arxiv.org/abs/2404.18923v1)|null|
|**2024-04-29**|**DPO Meets PPO: Reinforced Token Optimization for RLHF**|Han Zhong et.al.|[2404.18922v1](http://arxiv.org/abs/2404.18922v1)|null|
|**2024-04-29**|**Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**|Fangcheng Liu et.al.|[2404.18911v1](http://arxiv.org/abs/2404.18911v1)|null|
|**2024-04-29**|**IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**|Kebin Wu et.al.|[2404.18891v1](http://arxiv.org/abs/2404.18891v1)|null|
|**2024-04-29**|**A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**|Yiyuan Yang et.al.|[2404.18886v1](http://arxiv.org/abs/2404.18886v1)|null|
|**2024-04-29**|**Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**|Aman Saini et.al.|[2404.18880v1](http://arxiv.org/abs/2404.18880v1)|null|
|**2024-04-29**|**OpenStreetView-5M: The Many Roads to Global Visual Geolocation**|Guillaume Astruc et.al.|[2404.18873v1](http://arxiv.org/abs/2404.18873v1)|[link](https://github.com/gastruc/osv5m)|
|**2024-04-29**|**More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**|Aaron J. Li et.al.|[2404.18870v1](http://arxiv.org/abs/2404.18870v1)|[link](https://github.com/aaron-jx-li/rlhf-trustworthiness)|
|**2024-04-29**|**Truth-value judgment in language models: belief directions are context sensitive**|Stefan F. Schouten et.al.|[2404.18865v1](http://arxiv.org/abs/2404.18865v1)|null|
|**2024-04-29**|**Performance-Aligned LLMs for Generating Fast Code**|Daniel Nichols et.al.|[2404.18864v1](http://arxiv.org/abs/2404.18864v1)|null|
|**2024-04-29**|**A Comprehensive Rubric for Annotating Pathological Speech**|Mario Corrales-Astorgano et.al.|[2404.18851v1](http://arxiv.org/abs/2404.18851v1)|null|
|**2024-04-29**|**FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**|Yuxuan Yan et.al.|[2404.18848v2](http://arxiv.org/abs/2404.18848v2)|null|
|**2024-04-29**|**It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**|Petter Mæhlum et.al.|[2404.18832v1](http://arxiv.org/abs/2404.18832v1)|null|
|**2024-04-29**|**Harmonic Machine Learning Models are Robust**|Nicholas S. Kersting et.al.|[2404.18825v1](http://arxiv.org/abs/2404.18825v1)|null|
|**2024-04-29**|**Benchmarking Benchmark Leakage in Large Language Models**|Ruijie Xu et.al.|[2404.18824v1](http://arxiv.org/abs/2404.18824v1)|[link](https://github.com/gair-nlp/benbench)|
|**2024-04-29**|**Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**|Seyed Soroush Karimi Madahi et.al.|[2404.18821v2](http://arxiv.org/abs/2404.18821v2)|null|
|**2024-04-29**|**Unknown Script: Impact of Script on Cross-Lingual Transfer**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18810v1](http://arxiv.org/abs/2404.18810v1)|null|
|**2024-04-29**|**Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**|Pat Verga et.al.|[2404.18796v1](http://arxiv.org/abs/2404.18796v1)|null|
|**2024-04-29**|**Certification of Speaker Recognition Models to Additive Perturbations**|Dmitrii Korzh et.al.|[2404.18791v1](http://arxiv.org/abs/2404.18791v1)|null|
|**2024-04-29**|**Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**|Tessa Masis et.al.|[2404.18784v1](http://arxiv.org/abs/2404.18784v1)|null|
|**2024-04-29**|**Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**|Gustaw Opiełka et.al.|[2404.18772v1](http://arxiv.org/abs/2404.18772v1)|[link](https://github.com/gucioopielka/saliency-semantic-rsa)|
|**2024-04-29**|**PECC: Problem Extraction and Coding Challenges**|Patrick Haller et.al.|[2404.18766v1](http://arxiv.org/abs/2404.18766v1)|[link](https://github.com/hallerpatrick/pecc)|
|**2024-04-29**|**Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**|Juraj Vladika et.al.|[2404.18759v1](http://arxiv.org/abs/2404.18759v1)|null|
|**2024-04-29**|**Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**|Shanle Yao et.al.|[2404.18747v1](http://arxiv.org/abs/2404.18747v1)|null|
|**2024-04-29**|**Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**|Artem Abzaliev et.al.|[2404.18739v1](http://arxiv.org/abs/2404.18739v1)|null|
|**2024-04-29**|**The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18726v1](http://arxiv.org/abs/2404.18726v1)|[link](https://github.com/cltl/reddit_topic)|
|**2024-04-29**|**Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**|Solène Tarride et.al.|[2404.18722v1](http://arxiv.org/abs/2404.18722v1)|null|
|**2024-04-29**|**Iconic Gesture Semantics**|Andy Lücking et.al.|[2404.18708v1](http://arxiv.org/abs/2404.18708v1)|null|
|**2024-04-29**|**Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**|Sidharth Ranjan et.al.|[2404.18684v1](http://arxiv.org/abs/2404.18684v1)|null|
|**2024-04-29**|**Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**|Paul Cibier et.al.|[2404.18672v1](http://arxiv.org/abs/2404.18672v1)|null|
|**2024-04-29**|**Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**|Yifei Gao et.al.|[2404.18669v1](http://arxiv.org/abs/2404.18669v1)|null|
|**2024-04-29**|**Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**|Haeun Yu et.al.|[2404.18655v1](http://arxiv.org/abs/2404.18655v1)|null|
|**2024-04-29**|**Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**|Konstantinos Tsigos et.al.|[2404.18649v1](http://arxiv.org/abs/2404.18649v1)|null|
|**2024-04-29**|**Reinforcement Learning Problem Solving with Large Language Models**|Sina Gholamian et.al.|[2404.18638v1](http://arxiv.org/abs/2404.18638v1)|null|
|**2024-04-29**|**Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**|Letitia Parcalabescu et.al.|[2404.18624v1](http://arxiv.org/abs/2404.18624v1)|null|
|**2024-04-29**|**The SAMER Arabic Text Simplification Corpus**|Bashar Alhafni et.al.|[2404.18615v1](http://arxiv.org/abs/2404.18615v1)|null|
|**2024-04-29**|**CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**|Xiangyu Liang et.al.|[2404.18604v1](http://arxiv.org/abs/2404.18604v1)|null|
|**2024-04-29**|**FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**|Wei Zhou et.al.|[2404.18585v1](http://arxiv.org/abs/2404.18585v1)|null|
|**2024-04-29**|**Analyzing Semantic Change through Lexical Replacements**|Francesco Periti et.al.|[2404.18570v1](http://arxiv.org/abs/2404.18570v1)|[link](https://github.com/changeiskey/asc-lr)|
|**2024-04-29**|**Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**|Wen-Yu Chang et.al.|[2404.18564v1](http://arxiv.org/abs/2404.18564v1)|null|
|**2024-04-29**|**LangBiTe: A Platform for Testing Bias in Large Language Models**|Sergio Morales et.al.|[2404.18558v1](http://arxiv.org/abs/2404.18558v1)|null|
|**2024-04-29**|**Can GPT-4 do L2 analytic assessment?**|Stefano Bannò et.al.|[2404.18557v1](http://arxiv.org/abs/2404.18557v1)|null|
|**2024-04-29**|**Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**|Gareth Davies et.al.|[2404.18553v1](http://arxiv.org/abs/2404.18553v1)|null|
|**2024-04-29**|**SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**|Manos Schinas et.al.|[2404.18552v1](http://arxiv.org/abs/2404.18552v1)|[link](https://github.com/mever-team/sidbench)|
|**2024-04-29**|**Time Machine GPT**|Felix Drinkall et.al.|[2404.18543v1](http://arxiv.org/abs/2404.18543v1)|null|
|**2024-04-29**|**Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**|Chuni Liu et.al.|[2404.18539v1](http://arxiv.org/abs/2404.18539v1)|[link](https://github.com/clovermini/skea_topo)|
|**2024-04-29**|**Evaluating and Mitigating Linguistic Discrimination in Large Language Models**|Guoliang Dong et.al.|[2404.18534v1](http://arxiv.org/abs/2404.18534v1)|null|
|**2024-04-29**|**Evaluating Concept-based Explanations of Language Models: A Study on Faithfulness and Readability**|Meng Li et.al.|[2404.18533v2](http://arxiv.org/abs/2404.18533v2)|[link](https://github.com/hr-jin/concept-explaination-evaluation)|
|**2024-04-29**|**MileBench: Benchmarking MLLMs in Long Context**|Dingjie Song et.al.|[2404.18532v1](http://arxiv.org/abs/2404.18532v1)|null|
|**2024-04-29**|**A Framework to Model ML Engineering Processes**|Sergio Morales et.al.|[2404.18531v1](http://arxiv.org/abs/2404.18531v1)|null|
|**2024-04-29**|**Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**|Weike Peng et.al.|[2404.18527v1](http://arxiv.org/abs/2404.18527v1)|null|
|**2024-04-29**|**On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**|Usevalad Milasheuski. Luca Barbieri et.al.|[2404.18519v1](http://arxiv.org/abs/2404.18519v1)|null|
|**2024-04-29**|**From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**|Jiangfeng Liu et.al.|[2404.18518v1](http://arxiv.org/abs/2404.18518v1)|null|
|**2024-04-29**|**Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**|Dana Roemling et.al.|[2404.18510v1](http://arxiv.org/abs/2404.18510v1)|null|
|**2024-04-29**|**Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**|Mark Schöne et.al.|[2404.18508v1](http://arxiv.org/abs/2404.18508v1)|null|
|**2024-04-29**|**ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**|Yupeng Cao et.al.|[2404.18470v1](http://arxiv.org/abs/2404.18470v1)|null|
|**2024-04-29**|**HFT: Half Fine-Tuning for Large Language Models**|Tingfeng Hui et.al.|[2404.18466v1](http://arxiv.org/abs/2404.18466v1)|null|
|**2024-04-29**|**M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**|Zijian Zhang et.al.|[2404.18465v1](http://arxiv.org/abs/2404.18465v1)|[link](https://github.com/applied-machine-learning-lab/m3oe)|
|**2024-04-29**|**Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**|Utkarsh Agarwal et.al.|[2404.18460v1](http://arxiv.org/abs/2404.18460v1)|null|
|**2024-04-29**|**U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**|Song Mei et.al.|[2404.18444v1](http://arxiv.org/abs/2404.18444v1)|null|
|**2024-04-29**|**BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**|Ran Xu et.al.|[2404.18443v1](http://arxiv.org/abs/2404.18443v1)|[link](https://github.com/ritaranx/bmretriever)|
|**2024-04-29**|**Unsupervised Dynamics Prediction with Object-Centric Kinematics**|Yeon-Ji Song et.al.|[2404.18423v1](http://arxiv.org/abs/2404.18423v1)|null|
|**2024-04-29**|**Capabilities of Gemini Models in Medicine**|Khaled Saab et.al.|[2404.18416v1](http://arxiv.org/abs/2404.18416v1)|null|
|**2024-04-29**|**3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**|Xinyu Ma et.al.|[2404.18413v1](http://arxiv.org/abs/2404.18413v1)|[link](https://github.com/maxylee/3am)|
|**2024-04-29**|**Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**|Bowen Xu et.al.|[2404.18410v1](http://arxiv.org/abs/2404.18410v1)|null|
|**2024-04-29**|**LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**|Parshin Shojaee et.al.|[2404.18400v1](http://arxiv.org/abs/2404.18400v1)|[link](https://github.com/deep-symbolic-mathematics/llm-sr)|
|**2024-04-29**|**MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**|Xiang Li et.al.|[2404.18398v1](http://arxiv.org/abs/2404.18398v1)|null|
|**2024-04-29**|**Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**|Yixuan Li et.al.|[2404.18385v2](http://arxiv.org/abs/2404.18385v2)|null|
|**2024-04-29**|**Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**|Jordan Meadows et.al.|[2404.18384v1](http://arxiv.org/abs/2404.18384v1)|null|
|**2024-04-29**|**QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**|Tomoki Fukuma et.al.|[2404.18371v1](http://arxiv.org/abs/2404.18371v1)|null|
|**2024-04-29**|**FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**|Wei Li et.al.|[2404.18359v1](http://arxiv.org/abs/2404.18359v1)|null|
|**2024-04-29**|**Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**|Norbert Tihanyi et.al.|[2404.18353v1](http://arxiv.org/abs/2404.18353v1)|null|
|**2024-04-29**|**Post-hoc and manifold explanations analysis of facial expression data based on deep learning**|Yang Xiao et.al.|[2404.18352v1](http://arxiv.org/abs/2404.18352v1)|[link](https://github.com/nkushaw/psychoinformatics)|
|**2024-04-28**|**Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**|Hamdi Friji et.al.|[2404.18328v1](http://arxiv.org/abs/2404.18328v1)|null|
|**2024-04-28**|**SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**|Amir Samadi et.al.|[2404.18326v1](http://arxiv.org/abs/2404.18326v1)|[link](https://github.com/amir-samadi/safe-rl)|
|**2024-04-28**|**Towards Real-time Learning in Large Language Models: A Critical Review**|Mladjan Jovanovic et.al.|[2404.18311v2](http://arxiv.org/abs/2404.18311v2)|null|
|**2024-04-28**|**Retrieval-Oriented Knowledge for Click-Through Rate Prediction**|Huanshuo Liu et.al.|[2404.18304v1](http://arxiv.org/abs/2404.18304v1)|null|
|**2024-04-28**|**Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**|Zoi Lygizou et.al.|[2404.18296v1](http://arxiv.org/abs/2404.18296v1)|null|
|**2024-04-28**|**Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**|David Ifeoluwa Adelani et.al.|[2404.18286v2](http://arxiv.org/abs/2404.18286v2)|null|
|**2024-04-28**|**Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**|Malur Narayan et.al.|[2404.18276v1](http://arxiv.org/abs/2404.18276v1)|null|
|**2024-04-28**|**Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**|Qi Zhu et.al.|[2404.18271v1](http://arxiv.org/abs/2404.18271v1)|null|
|**2024-04-28**|**Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**|Aman Kumar et.al.|[2404.18270v1](http://arxiv.org/abs/2404.18270v1)|null|
|**2024-04-28**|**Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**|Pin-Jie Lin et.al.|[2404.18264v1](http://arxiv.org/abs/2404.18264v1)|null|
|**2024-04-28**|**Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**|Atharva Naik et.al.|[2404.18262v1](http://arxiv.org/abs/2404.18262v1)|null|
|**2024-04-28**|**Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**|Nilo Pedrazzini et.al.|[2404.18257v1](http://arxiv.org/abs/2404.18257v1)|null|
|**2024-04-28**|**PatentGPT: A Large Language Model for Intellectual Property**|Zilong Bai et.al.|[2404.18255v2](http://arxiv.org/abs/2404.18255v2)|null|
|**2024-04-28**|**LEGENT: Open Platform for Embodied Agents**|Zhili Cheng et.al.|[2404.18243v1](http://arxiv.org/abs/2404.18243v1)|null|
|**2024-04-28**|**SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**|Jinghan Jia et.al.|[2404.18239v1](http://arxiv.org/abs/2404.18239v1)|[link](https://github.com/optml-group/soul)|
|**2024-04-28**|**From Persona to Personalization: A Survey on Role-Playing Language Agents**|Jiangjie Chen et.al.|[2404.18231v1](http://arxiv.org/abs/2404.18231v1)|null|
|**2024-04-28**|**TextGram: Towards a better domain-adaptive pretraining**|Sharayu Hiwarkhedkar et.al.|[2404.18228v1](http://arxiv.org/abs/2404.18228v1)|null|
|**2024-04-28**|**L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**|Saloni Mittal et.al.|[2404.18216v1](http://arxiv.org/abs/2404.18216v1)|[link](https://github.com/l3cube-pune/MarathiNLP)|
|**2024-04-28**|**Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**|Zeyu Hu et.al.|[2404.18214v1](http://arxiv.org/abs/2404.18214v1)|null|
|**2024-04-28**|**S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**|Guanchun Wang et.al.|[2404.18213v1](http://arxiv.org/abs/2404.18213v1)|null|
|**2024-04-28**|**Paint by Inpaint: Learning to Add Image Objects by Removing Them First**|Navve Wasserman et.al.|[2404.18212v1](http://arxiv.org/abs/2404.18212v1)|null|
|**2024-04-28**|**LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**|Zicheng Zhang et.al.|[2404.18203v1](http://arxiv.org/abs/2404.18203v1)|null|
|**2024-04-28**|**WorldGPT: Empowering LLM as Multimodal World Model**|Zhiqi Ge et.al.|[2404.18202v1](http://arxiv.org/abs/2404.18202v1)|[link](https://github.com/dcdmllm/worldgpt)|
|**2024-04-28**|**Exploring the Robustness of In-Context Learning with Noisy Labels**|Chen Cheng et.al.|[2404.18191v1](http://arxiv.org/abs/2404.18191v1)|[link](https://github.com/inezyu0928/in-context-learning)|
|**2024-04-28**|**Ranked List Truncation for Large Language Model-based Re-Ranking**|Chuan Meng et.al.|[2404.18185v1](http://arxiv.org/abs/2404.18185v1)|[link](https://github.com/chuanmeng/rlt4reranking)|
|**2024-04-28**|**EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**|Comfort Eseohen Ilevbare et.al.|[2404.18180v1](http://arxiv.org/abs/2404.18180v1)|null|

#### Abstracts
##### **Stylus: Automatic Adapter Selection for Diffusion Models**
2404.18928v1 by Michael Luo,Justin Wong,Brandon Trabucco,Yanping Huang,Joseph E. Gonzalez,Zhifeng Chen,Ruslan Salakhutdinov,Ion Stoica

Beyond scaling base models with more data or parameters, fine-tuned adapters
provide an alternative way to generate high fidelity, custom images at reduced
costs. As such, adapters have been widely adopted by open-source communities,
accumulating a database of over 100K adapters-most of which are highly
customized with insufficient descriptions. This paper explores the problem of
matching the prompt to a set of relevant adapters, built on recent work that
highlight the performance gains of composing adapters. We introduce Stylus,
which efficiently selects and automatically composes task-specific adapters
based on a prompt's keywords. Stylus outlines a three-stage approach that first
summarizes adapters with improved descriptions and embeddings, retrieves
relevant adapters, and then further assembles adapters based on prompts'
keywords by checking how well they fit the prompt. To evaluate Stylus, we
developed StylusDocs, a curated dataset featuring 75K adapters with
pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
preferred, with humans and multimodal models as evaluators, over the base
model. See stylus-diffusion.github.io for more.

摘要：除了使用更多資料或參數調整基礎模型外，微調適配器提供了一種以較低的成本產生高保真自訂影像的替代方法。因此，適配器已被開源社群廣泛採用，累積了一個超過 100K 個適配器的資料庫，其中大部分都經過高度自訂，且描述不足。本文探討了將提示與一組相關適配器配對的問題，並建立在最近強調組成適配器效能提升的研究之上。我們引入了 Stylus，它能根據提示的關鍵字有效地選擇並自動組成特定於任務的適配器。Stylus 概述了一個三階段方法，首先使用改良的描述和嵌入來總結適配器，擷取相關適配器，然後根據提示的關鍵字進一步組裝適配器，方法是檢查它們與提示的吻合程度。為了評估 Stylus，我們開發了 StylusDocs，這是一個經過整理的資料集，包含 75K 個具有預先計算適配器嵌入的適配器。在我們對流行的 Stable Diffusion 檢查點進行的評估中，Stylus 達到了更高的 CLIP-FID Pareto 效率，並且在人類和多模態模型作為評估者的情況下，它的偏好度是基礎模型的兩倍。請參閱 stylus-diffusion.github.io 以了解更多資訊。

##### **Holmes: Benchmark the Linguistic Competence of Language Models**
2404.18923v1 by Andreas Waldis,Yotam Perlitz,Leshem Choshen,Yufang Hou,Iryna Gurevych

We introduce Holmes, a benchmark to assess the linguistic competence of
language models (LMs) - their ability to grasp linguistic phenomena. Unlike
prior prompting-based evaluations, Holmes assesses the linguistic competence of
LMs via their internal representations using classifier-based probing. In doing
so, we disentangle specific phenomena (e.g., part-of-speech of words) from
other cognitive abilities, like following textual instructions, and meet recent
calls to assess LMs' linguistic competence in isolation. Composing Holmes, we
review over 250 probing studies and feature more than 200 datasets to assess
syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing
over 50 LMs reveals that, aligned with known trends, their linguistic
competence correlates with model size. However, surprisingly, model
architecture and instruction tuning also significantly influence performance,
particularly in morphology and syntax. Finally, we propose FlashHolmes, a
streamlined version of Holmes designed to lower the high computation load while
maintaining high-ranking precision.

摘要：我們推出 Holmes，一個評估語言模型（LM）語言能力的基準，也就是它們掌握語言現象的能力。與先前的提示式評估不同，Holmes 透過使用基於分類器的探測，評估 LM 的內部表徵語言能力。在這樣做的過程中，我們將特定現象（例如字詞的詞性）從其他認知能力（例如遵循文字說明）中分離出來，並滿足最近評估 LM 語言能力的獨立要求。在編寫 Holmes 時，我們回顧了超過 250 項探測研究，並使用超過 200 個資料集來評估句法、形態、語意、推理和語篇現象。分析超過 50 個 LM 後發現，它們的語言能力與已知的趨勢一致，與模型大小相關。然而，令人驚訝的是，模型架構和說明調整也會顯著影響效能，特別是在形態和句法方面。最後，我們提出 FlashHolmes，一個簡化的 Holmes 版本，旨在降低高運算負載，同時維持高排名精度。

##### **DPO Meets PPO: Reinforced Token Optimization for RLHF**
2404.18922v1 by Han Zhong,Guhao Feng,Wei Xiong,Li Zhao,Di He,Jiang Bian,Liwei Wang

In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
Proximal Policy Optimization (PPO) is employed to learn from sparse,
sentence-level rewards -- a challenging scenario in traditional deep
reinforcement learning. Despite the great successes of PPO in the alignment of
state-of-the-art closed-source large language models (LLMs), its open-source
implementation is still largely sub-optimal, as widely reported by numerous
research studies. To address these issues, we introduce a framework that models
RLHF problems as a Markov decision process (MDP), enabling the capture of
fine-grained token-wise information. Furthermore, we provide theoretical
insights that demonstrate the superiority of our MDP framework over the
previous sentence-level bandit formulation. Under this framework, we introduce
an algorithm, dubbed as Reinforced Token Optimization (\texttt{RTO}), which
learns the token-wise reward function from preference data and performs policy
optimization based on this learned token-wise reward signal. Theoretically,
\texttt{RTO} is proven to have the capability of finding the near-optimal
policy sample-efficiently. For its practical implementation, \texttt{RTO}
innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
originally derived from sparse sentence rewards, surprisingly provides us with
a token-wise characterization of response quality, which is seamlessly
incorporated into our subsequent PPO training stage. Extensive real-world
alignment experiments verify the effectiveness of the proposed approach.

摘要：<paragraph>在經典的人類回饋強化學習 (RLHF) 架構中，
採用近端策略最佳化 (PPO) 從稀疏的句子級別獎勵中學習——這是傳統深度強化學習中具有挑戰性的場景。儘管 PPO 在對齊最先進的閉源大型語言模型 (LLM) 方面取得了巨大成功，但其開源實作在很大程度上仍未達到最佳狀態，正如許多研究報告中所廣泛報導的那樣。為了解決這些問題，我們引入了一個框架，將 RLHF 問題建模為馬可夫決策過程 (MDP)，從而能夠擷取細粒度的標記資訊。此外，我們提供了理論見解，證明了我們的 MDP 框架優於先前的句子級別賭徒公式。在這個框架下，我們引入了一個演算法，稱為強化標記最佳化 (\texttt{RTO})，它從偏好數據中學習標記級別的獎勵函數，並基於這個學習到的標記級別獎勵訊號執行策略最佳化。在理論上，\texttt{RTO} 被證明具有近乎最佳策略樣本高效地尋找的能力。對於其實際實作，\texttt{RTO} 創新地整合了直接偏好最佳化 (DPO) 和 PPO。DPO 最初來自稀疏的句子獎勵，令人驚訝的是，它為我們提供了對應答品質的標記級別表徵，這無縫地整合到我們後續的 PPO 訓練階段。廣泛的真實世界對齊實驗驗證了所提出方法的有效性。</paragraph>

##### **Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**
2404.18911v1 by Fangcheng Liu,Yehui Tang,Zhenhua Liu,Yunsheng Ni,Kai Han,Yunhe Wang

Speculative decoding has demonstrated its effectiveness in accelerating the
inference of large language models while maintaining a consistent sampling
distribution. However, the conventional approach of training a separate draft
model to achieve a satisfactory token acceptance rate can be costly. Drawing
inspiration from early exiting, we propose a novel self-speculative decoding
framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
self-draft model, with the remaining layers serving as the larger target model.
We train a lightweight and efficient adapter module on top of the sub-network
to bridge the gap between the sub-network and the full model's representation
ability. It is noteworthy that the inference latency of the self-draft model
may no longer be negligible compared to the large model, necessitating
strategies to increase the token acceptance rate while minimizing the drafting
steps of the small model. To address this challenge, we introduce an additional
early exiting mechanism for generating draft tokens. Specifically, we halt the
small model's subsequent prediction during the drafting phase once the
confidence level for the current token falls below a certain threshold.
Extensive experiments on the Spec-Bench demonstrate the effectiveness of
Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
$1.68\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
parameters (67M compared to 591M). The code for Kangaroo is available at
https://github.com/Equationliu/Kangaroo.

摘要：<paragraph>推測性解碼在加速大型語言模型的推論時已展現其效能，同時維持一致的抽樣分佈。然而，採用傳統方法訓練一個獨立的草稿模型，以達成令人滿意的權杖接受率，可能會很昂貴。從早期退出中汲取靈感，我們提出一個新穎的自推測解碼架構「袋鼠」，它使用一個固定的淺層子網路作為自草稿模型，其餘的層則作為較大的目標模型。我們在子網路的頂部訓練一個輕量且高效的適配器模組，以彌補子網路和完整模型的表示能力之間的差距。值得注意的是，與大型模型相比，自草稿模型的推論延遲可能不再可以忽略不計，因此需要策略來增加權杖接受率，同時將小型模型的起草步驟減至最低。為了應對這個挑戰，我們引入一個額外的早期退出機制來產生草稿權杖。具體來說，一旦當前權杖的信心水準低於某個閾值，我們就會在起草階段停止小型模型後續的預測。在 Spec-Bench 上進行的廣泛實驗證明了袋鼠的效能。在單一序列驗證下，袋鼠在 Spec-Bench 上實現了高達 1.68 倍的加速，超越了美杜莎 1，額外參數減少了 88.7%（6700 萬，相比於 5.91 億）。袋鼠的程式碼可以在 https://github.com/Equationliu/Kangaroo 取得。</paragraph>

##### **IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**
2404.18891v1 by Kebin Wu,Wenbin Li,Xiaofei Xiao

The scarcity of labeled data in real-world scenarios is a critical bottleneck
of deep learning's effectiveness. Semi-supervised semantic segmentation has
been a typical solution to achieve a desirable tradeoff between annotation cost
and segmentation performance. However, previous approaches, whether based on
consistency regularization or self-training, tend to neglect the contextual
knowledge embedded within inter-pixel relations. This negligence leads to
suboptimal performance and limited generalization. In this paper, we propose a
novel approach IPixMatch designed to mine the neglected but valuable
Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch
is constructed as an extension of the standard teacher-student network,
incorporating additional loss terms to capture inter-pixel relations. It shines
in low-data regimes by efficiently leveraging the limited labeled data and
extracting maximum utility from the available unlabeled data. Furthermore,
IPixMatch can be integrated seamlessly into most teacher-student frameworks
without the need of model modification or adding additional components. Our
straightforward IPixMatch method demonstrates consistent performance
improvements across various benchmark datasets under different partitioning
protocols.

摘要：在實際場景中標記資料的稀少性是深度學習有效性的關鍵瓶頸。半監督語意分割一直是實現標註成本和分割性能之間理想折衷的典型解決方案。然而，先前的做法，無論是基於一致性正則化還是自訓練，都傾向於忽略像素間關係中嵌入的上下文知識。這種疏忽導致次優的性能和有限的泛化。在本文中，我們提出了一種新方法 IPixMatch，旨在挖掘半監督學習中被忽視但有價值的像素間訊息。具體來說，IPixMatch 被構造為標準師生網路的延伸，加入額外的損失項來捕捉像素間關係。它通過有效利用有限的標記資料和從可用的未標記資料中提取最大效用，在低資料模式下表現出色。此外，IPixMatch 可以無縫整合到大多數師生框架中，無需修改模型或添加額外組件。我們簡潔的 IPixMatch 方法在不同的分割協議下，在各種基準資料集上展示了一致的性能改進。

##### **A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**
2404.18886v1 by Yiyuan Yang,Ming Jin,Haomin Wen,Chaoli Zhang,Yuxuan Liang,Lintao Ma,Yi Wang,Chenghao Liu,Bin Yang,Zenglin Xu,Jiang Bian,Shirui Pan,Qingsong Wen

The study of time series data is crucial for understanding trends and
anomalies over time, enabling predictive insights across various sectors.
Spatio-temporal data, on the other hand, is vital for analyzing phenomena in
both space and time, providing a dynamic perspective on complex system
interactions. Recently, diffusion models have seen widespread application in
time series and spatio-temporal data mining. Not only do they enhance the
generative and inferential capabilities for sequential and temporal data, but
they also extend to other downstream tasks. In this survey, we comprehensively
and thoroughly review the use of diffusion models in time series and
spatio-temporal data, categorizing them by model category, task type, data
modality, and practical application domain. In detail, we categorize diffusion
models into unconditioned and conditioned types and discuss time series data
and spatio-temporal data separately. Unconditioned models, which operate
unsupervised, are subdivided into probability-based and score-based models,
serving predictive and generative tasks such as forecasting, anomaly detection,
classification, and imputation. Conditioned models, on the other hand, utilize
extra information to enhance performance and are similarly divided for both
predictive and generative tasks. Our survey extensively covers their
application in various fields, including healthcare, recommendation, climate,
energy, audio, and transportation, providing a foundational understanding of
how these models analyze and generate data. Through this structured overview,
we aim to provide researchers and practitioners with a comprehensive
understanding of diffusion models for time series and spatio-temporal data
analysis, aiming to direct future innovations and applications by addressing
traditional challenges and exploring innovative solutions within the diffusion
model framework.

摘要：時序資料的研究對於理解趨勢和時間異常至關重要，能讓各個產業獲得預測洞見。另一方面，時空資料對於分析時空中的現象至關重要，能提供複雜系統互動的動態觀點。最近，擴散模型在時序和時空資料探勘中獲得廣泛應用。它們不僅增強了序列和時間資料的生成和推論能力，也延伸到其他下游任務。在這項調查中，我們全面且徹底地檢視了擴散模型在時序和時空資料中的使用，並根據模型類別、任務類型、資料模式和實際應用領域對其進行分類。詳細來說，我們將擴散模型分類為無條件和有條件類型，並分別討論時序資料和時空資料。無條件模型以非監督方式運作，細分為基於機率和基於分數的模型，用於預測和生成任務，例如預測、異常偵測、分類和插補。另一方面，有條件模型利用額外資訊來增強效能，並同樣分為預測和生成任務。我們的調查廣泛涵蓋了它們在醫療保健、推薦、氣候、能源、音訊和運輸等各種領域的應用，提供了這些模型如何分析和生成資料的基本理解。透過這個結構化的概述，我們旨在讓研究人員和實務工作者全面了解時序和時空資料分析的擴散模型，目標是透過解決傳統挑戰和探索擴散模型架構內的創新解決方案，引導未來的創新和應用。

##### **Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**
2404.18880v1 by Aman Saini,Artem Chernodub,Vipul Raheja,Vivek Kulkarni

We introduce Spivavtor, a dataset, and instruction-tuned models for text
editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused
adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor
performs text editing tasks by following instructions in Ukrainian. This paper
describes the details of the Spivavtor-Instruct dataset and Spivavtor models.
We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as
Grammatical Error Correction (GEC), Text Simplification, Coherence, and
Paraphrasing, and demonstrate its superior performance on all of them. We
publicly release our best-performing models and data as resources to the
community to advance further research in this space.

摘要：我們介紹 Spivavtor，一個專注於烏克蘭語的資料集和指令調整模型，用於文字編輯。Spivavtor 是僅限英文的 CoEdIT 模型的烏克蘭語重點改編。類似於 CoEdIT，Spivavtor 透過遵循烏克蘭語的指令來執行文字編輯任務。本文說明 Spivavtor-Instruct 資料集和 Spivavtor 模型的詳細資訊。我們在各種烏克蘭語文字編輯任務中評估 Spivavtor，例如語法錯誤修正 (GEC)、文字簡化、一致性，以及同義詞替換，並證明其在所有任務中的優異表現。我們公開發布我們效能最佳的模型和資料，作為資源提供給社群，以推進此領域的進一步研究。

##### **OpenStreetView-5M: The Many Roads to Global Visual Geolocation**
2404.18873v1 by Guillaume Astruc,Nicolas Dufour,Ioannis Siglidis,Constantin Aronssohn,Nacim Bouia,Stephanie Fu,Romain Loiseau,Van Nguyen Nguyen,Charles Raude,Elliot Vincent,Lintao XU,Hongyu Zhou,Loic Landrieu

Determining the location of an image anywhere on Earth is a complex visual
task, which makes it particularly relevant for evaluating computer vision
algorithms. Yet, the absence of standard, large-scale, open-access datasets
with reliably localizable images has limited its potential. To address this
issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset
comprising over 5.1 million geo-referenced street view images, covering 225
countries and territories. In contrast to existing benchmarks, we enforce a
strict train/test separation, allowing us to evaluate the relevance of learned
geographical features beyond mere memorization. To demonstrate the utility of
our dataset, we conduct an extensive benchmark of various state-of-the-art
image encoders, spatial representations, and training strategies. All
associated codes and models can be found at https://github.com/gastruc/osv5m.

摘要：確定地球上任何地方的影像位置是一項複雜的視覺任務，這使得它特別適用於評估電腦視覺演算法。然而，缺乏標準、大規模、開放存取的資料集，其中包含可靠的可定位影像，限制了其潛力。為了解決這個問題，我們引入了 OpenStreetView-5M，一個大規模、開放存取的資料集，包含超過 510 萬張地理參照街景影像，涵蓋 225 個國家和地區。與現有的基準測試相比，我們強制執行嚴格的訓練/測試分離，讓我們能夠評估已學習地理特徵與單純記憶之間的關聯性。為了展示我們資料集的效用，我們對各種最先進的影像編碼器、空間表示和訓練策略進行了廣泛的基準測試。所有相關程式碼和模型都可以在 https://github.com/gastruc/osv5m 找到。

##### **More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**
2404.18870v1 by Aaron J. Li,Satyapriya Krishna,Himabindu Lakkaraju

The surge in Large Language Models (LLMs) development has led to improved
performance on cognitive tasks as well as an urgent need to align these models
with human values in order to safely exploit their power. Despite the
effectiveness of preference learning algorithms like Reinforcement Learning
From Human Feedback (RLHF) in aligning human preferences, their assumed
improvements on model trustworthiness haven't been thoroughly testified. Toward
this end, this study investigates how models that have been aligned with
general-purpose preference data on helpfulness and harmlessness perform across
five trustworthiness verticals: toxicity, stereotypical bias, machine ethics,
truthfulness, and privacy. For model alignment, we focus on three widely used
RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO),
and Direct Preference Optimization (DPO). Through extensive empirical
investigations, we discover that the improvement in trustworthiness by RLHF is
far from guaranteed, and there exists a complex interplay between preference
data, alignment algorithms, and specific trustworthiness aspects. Together, our
results underscore the need for more nuanced approaches for model alignment. By
shedding light on the intricate dynamics of these components within model
alignment, we hope this research will guide the community towards developing
language models that are both capable and trustworthy.

摘要：大型語言模型 (LLM) 的發展激增已導致認知任務的效能提升，以及迫切需要將這些模型與人類價值觀一致，以安全地利用其力量。儘管偏好學習演算法（例如人類回饋強化學習 (RLHF)）在調整人類偏好方面很有效，但其假設的模型可信度提升並未得到徹底驗證。為此，本研究探討了已根據對有益性和無害性的通用偏好資料調整的模型，如何在五個可信度垂直領域（毒性、刻板印象偏見、機器倫理、真實性和隱私）中表現。對於模型調整，我們專注於三種廣泛使用的 RLHF 變體：監督微調 (SFT)、近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO)。透過廣泛的實證調查，我們發現 RLHF 對可信度的提升並非有保證的，並且偏好資料、調整演算法和特定可信度面向之間存在複雜的交互作用。我們的結果共同強調了對模型調整需要更細緻方法的必要性。透過闡明模型調整中這些組成部分的複雜動態，我們希望這項研究將引導社群朝著開發既有能力又可信賴的語言模型邁進。

##### **Truth-value judgment in language models: belief directions are context sensitive**
2404.18865v1 by Stefan F. Schouten,Peter Bloem,Ilia Markov,Piek Vossen

Recent work has demonstrated that the latent spaces of large language models
(LLMs) contain directions predictive of the truth of sentences. Multiple
methods recover such directions and build probes that are described as getting
at a model's "knowledge" or "beliefs". We investigate this phenomenon, looking
closely at the impact of context on the probes. Our experiments establish where
in the LLM the probe's predictions can be described as being conditional on the
preceding (related) sentences. Specifically, we quantify the responsiveness of
the probes to the presence of (negated) supporting and contradicting sentences,
and score the probes on their consistency. We also perform a causal
intervention experiment, investigating whether moving the representation of a
premise along these belief directions influences the position of the hypothesis
along that same direction. We find that the probes we test are generally
context sensitive, but that contexts which should not affect the truth often
still impact the probe outputs. Our experiments show that the type of errors
depend on the layer, the (type of) model, and the kind of data. Finally, our
results suggest that belief directions are (one of the) causal mediators in the
inference process that incorporates in-context information.

摘要：最近的研究表明，大型语言模型 (LLM) 的潜在空间包含预测句子真实性的方向。多种方法恢复了这些方向，并构建了探针，这些探针被描述为获取模型的“知识”或“信念”。我们调查了这种现象，仔细研究了上下文对探针的影响。我们的实验确定了 LLM 中探针的预测可以被描述为以先行（相关）句子为条件的位置。具体来说，我们量化了探针对（否定）支持和矛盾句子的存在做出反应的能力，并根据其一致性对探针进行评分。我们还执行了因果干预实验，调查了沿这些信念方向移动前提表示是否会影响沿相同方向的假设位置。我们发现我们测试的探针通常对上下文敏感，但那些不应该影响真实性的上下文通常仍然会影响探针输出。我们的实验表明，错误类型取决于层、模型（类型）和数据类型。最后，我们的结果表明，信念方向是推理过程中包含上下文信息的原因中介（之一）。

##### **Performance-Aligned LLMs for Generating Fast Code**
2404.18864v1 by Daniel Nichols,Pranav Polasam,Harshitha Menon,Aniruddha Marathe,Todd Gamblin,Abhinav Bhatele

Optimizing scientific software is a difficult task because codebases are
often large and complex, and performance can depend upon several factors
including the algorithm, its implementation, and hardware among others. Causes
of poor performance can originate from disparate sources and be difficult to
diagnose. Recent years have seen a multitude of work that use large language
models (LLMs) to assist in software development tasks. However, these tools are
trained to model the distribution of code as text, and are not specifically
designed to understand performance aspects of code. In this work, we introduce
a reinforcement learning based methodology to align the outputs of code LLMs
with performance. This allows us to build upon the current code modeling
capabilities of LLMs and extend them to generate better performing code. We
demonstrate that our fine-tuned model improves the expected speedup of
generated code over base models for a set of benchmark tasks from 0.9 to 1.6
for serial code and 1.9 to 4.5 for OpenMP code.

摘要：優化科學軟體是一項困難的任務，因為程式碼庫通常龐大且複雜，而且效能可能取決於演算法、實作和硬體等多項因素。效能不佳的原因可能來自不同的來源，且難以診斷。近年來，許多研究使用大型語言模型 (LLM) 來協助軟體開發任務。然而，這些工具經過訓練，可以將程式碼的分布建模為文字，但並未特別設計為了解程式碼的效能面向。在這項研究中，我們引進一種基於強化學習的方法，以將程式碼 LLM 的輸出與效能對齊。這使我們能夠建立在 LLM 目前程式碼建模功能的基礎上，並將其擴充為產生效能更好的程式碼。我們證明，我們微調過的模型改善了生成程式碼的預期加速，對於一組基準任務，序列程式碼從 0.9 到 1.6，OpenMP 程式碼從 1.9 到 4.5，都優於基礎模型。

##### **A Comprehensive Rubric for Annotating Pathological Speech**
2404.18851v1 by Mario Corrales-Astorgano,David Escudero-Mancebo,Lourdes Aguilar,Valle Flores-Lucas,Valentín Cardeñoso-Payo,Carlos Vivaracho-Pascual,César González-Ferreras

Rubrics are a commonly used tool for labeling voice corpora in speech quality
assessment, although their application in the context of pathological speech
remains relatively limited. In this study, we introduce a comprehensive rubric
based on various dimensions of speech quality, including phonetics, fluency,
and prosody. The objective is to establish standardized criteria for
identifying errors within the speech of individuals with Down syndrome, thereby
enabling the development of automated assessment systems. To achieve this
objective, we utilized the Prautocal corpus. To assess the quality of
annotations using our rubric, two experiments were conducted, focusing on
phonetics and fluency. For phonetic evaluation, we employed the Goodness of
Pronunciation (GoP) metric, utilizing automatic segmentation systems and
correlating the results with evaluations conducted by a specialized speech
therapist. While the obtained correlation values were not notably high, a
positive trend was observed. In terms of fluency assessment, deep learning
models like wav2vec were used to extract audio features, and we employed an SVM
classifier trained on a corpus focused on identifying fluency issues to
categorize Prautocal corpus samples. The outcomes highlight the complexities of
evaluating such phenomena, with variability depending on the specific type of
disfluency detected.

摘要：評分標準是標示語音語料庫中語音品質評估的常用工具，儘管其在病態語音脈絡中的應用仍相對有限。在本研究中，我們引入了一個基於語音品質各個面向的綜合性評分標準，包括語音學、流暢度和韻律。目標是為辨識唐氏症患者語音中的錯誤建立標準化準則，進而能開發出自動化評估系統。為了達成此目標，我們利用了 Prautocal 語料庫。為了評估使用我們評分標準的註解品質，進行了兩項實驗，專注於語音學和流暢度。對於語音學評估，我們採用了發音優劣 (GoP) 指標，利用自動分段系統並將結果與專科語言治療師進行的評估結果進行比對。雖然獲得的相關性值並未特別高，但觀察到正向趨勢。在流暢度評估方面，我們使用深度學習模型（例如 wav2vec）來萃取音訊特徵，並採用在專注於辨識流暢度問題的語料庫上訓練的 SVM 分類器來分類 Prautocal 語料庫樣本。結果突顯了評估此類現象的複雜性，變異性取決於所偵測到的特定類型的不流暢。

##### **FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**
2404.18848v2 by Yuxuan Yan,Shunpu Tang,Zhiguo Shi,Qianqian Yang

Pre-trained Language Models (PLMs) have shown excellent performance on
various downstream tasks after fine-tuning. Nevertheless, the escalating
concerns surrounding user privacy have posed significant challenges to
centralized training reliant on extensive data collection. Federated learning,
which only requires training on the clients and aggregates weights on the
server without sharing data, has emerged as a solution. However, the
substantial parameter size of PLMs places a significant burden on the
computational resources of client devices, while also leading to costly
communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into
federated learning can effectively address this problem. However, we observe
that the non-IID data in federated learning leads to a gap in performance
between the PEFT method and full parameter fine-tuning(FFT). To overcome this,
we propose FeDeRA, an improvement over the Low-Rank Adaption(LoRA) method in
federated learning. FeDeRA uses the same adapter module as LoRA. However, the
difference lies in FeDeRA's initialization of the adapter module by performing
Singular Value Decomposition (SVD) on the pre-trained matrix and selecting its
principal components. We conducted extensive experiments, using RoBERTa and
DeBERTaV3, on six datasets, comparing the methods including FFT and the other
three different PEFT methods. FeDeRA outperforms all other PEFT methods and is
comparable to or even surpasses the performance of FFT method. We also deployed
federated learning on Jetson AGX Orin and compared the time required by
different methods to achieve the target accuracy on specific tasks. Compared to
FFT, FeDeRA reduces the training time by 95.9\%, 97.9\%, 96.9\% and 97.3\%,
96.5\%, 96.5\% respectively on three tasks using RoBERTa and DeBERTaV3. The
overall experiments indicate that FeDeRA achieves good performance while also
maintaining efficiency.

摘要：<paragraph>預訓練語言模型 (PLM) 在微調後於各種下游任務中展現出極佳的效能。然而，與使用者隱私相關的疑慮不斷升高，對依賴廣泛資料收集的集中式訓練構成了重大挑戰。聯邦式學習僅需在用戶端進行訓練，並在伺服器上彙總權重，而無需分享資料，這已成為一種解決方案。然而，PLM 的參數規模龐大，對用戶端裝置的運算資源造成顯著負擔，同時也導致高昂的通訊費用。將參數有效微調 (PEFT) 引入聯邦式學習可以有效地解決這個問題。然而，我們觀察到聯邦式學習中的非獨立同分布 (non-IID) 資料導致 PEFT 方法與全參數微調 (FFT) 之間的效能差距。為了克服這個問題，我們提出了 FeDeRA，這是聯邦式學習中低秩適應 (LoRA) 方法的改進版本。FeDeRA 使用與 LoRA 相同的適配器模組。然而，FeDeRA 的差異在於它透過對預訓練矩陣執行奇異值分解 (SVD) 並選取其主成分來初始化適配器模組。我們使用 RoBERTa 和 DeBERTaV3 對六個資料集進行了廣泛的實驗，比較了包括 FFT 和其他三種不同 PEFT 方法在內的方法。FeDeRA 的表現優於所有其他 PEFT 方法，並且與 FFT 方法的效能相當甚至超越。我們還在 Jetson AGX Orin 上部署了聯邦式學習，並比較了不同方法在特定任務上達到目標準確度所需的時間。與 FFT 相比，FeDeRA 使用 RoBERTa 和 DeBERTaV3 在三個任務上分別將訓練時間縮短了 95.9%、97.9%、96.9% 和 97.3%、96.5%、96.5%。整體實驗結果表明，FeDeRA 在維持效率的同時也達到了良好的效能。</paragraph>

##### **It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**
2404.18832v1 by Petter Mæhlum,David Samuel,Rebecka Maria Norman,Elma Jelin,Øyvind Andresen Bjertnæs,Lilja Øvrelid,Erik Velldal

Sentiment analysis is an important tool for aggregating patient voices, in
order to provide targeted improvements in healthcare services. A prerequisite
for this is the availability of in-domain data annotated for sentiment. This
article documents an effort to add sentiment annotations to free-text comments
in patient surveys collected by the Norwegian Institute of Public Health
(NIPH). However, annotation can be a time-consuming and resource-intensive
process, particularly when it requires domain expertise. We therefore also
evaluate a possible alternative to human annotation, using large language
models (LLMs) as annotators. We perform an extensive evaluation of the approach
for two openly available pretrained LLMs for Norwegian, experimenting with
different configurations of prompts and in-context learning, comparing their
performance to human annotators. We find that even for zero-shot runs, models
perform well above the baseline for binary sentiment, but still cannot compete
with human annotators on the full dataset.

摘要：情感分析是彙整病患聲音的重要工具，用於提供醫療服務的目標改善。這項工作的先決條件是取得已針對情緒標記的領域內資料。本文記錄一項工作，將情緒標記新增至挪威公共衛生研究所 (NIPH) 所收集的病患調查中的自由文字評論。然而，標記可能是一個耗時且耗費資源的程序，特別是在需要領域專業知識時。因此，我們也評估了人工標記的可能替代方案，使用大型語言模型 (LLM) 作為標記員。我們對兩種公開可取得的挪威語預先訓練 LLM 執行廣泛的評估，針對提示和情境中學習的不同組態進行實驗，並將其效能與人工標記員進行比較。我們發現，即使對於零次學習，模型在二元情緒的基準上表現良好，但仍無法在完整資料集上與人工標記員競爭。

##### **Harmonic Machine Learning Models are Robust**
2404.18825v1 by Nicholas S. Kersting,Yi Li,Aman Mohanty,Oyindamola Obisesan,Raphael Okochu

We introduce Harmonic Robustness, a powerful and intuitive method to test the
robustness of any machine-learning model either during training or in black-box
real-time inference monitoring without ground-truth labels. It is based on
functional deviation from the harmonic mean value property, indicating
instability and lack of explainability. We show implementation examples in
low-dimensional trees and feedforward NNs, where the method reliably identifies
overfitting, as well as in more complex high-dimensional models such as
ResNet-50 and Vision Transformer where it efficiently measures adversarial
vulnerability across image classes.

摘要：我們引入了諧波穩健性，這是一種強大且直觀的方法，可用於在訓練期間或在黑盒實時推理監控中測試任何機器學習模型的穩健性，而無需使用真實標籤。它是基於與諧波平均值屬性的函數偏差，表示不穩定性和缺乏可解釋性。我們展示了低維樹和前饋 NNs 中的實作範例，其中該方法可靠地識別過度擬合，以及在更複雜的高維模型中，例如 ResNet-50 和 Vision Transformer，其中它有效地衡量了跨影像類別的對抗性脆弱性。

##### **Benchmarking Benchmark Leakage in Large Language Models**
2404.18824v1 by Ruijie Xu,Zengzhi Wang,Run-Ze Fan,Pengfei Liu

Amid the expanding use of pre-training data, the phenomenon of benchmark
dataset leakage has become increasingly prominent, exacerbated by opaque
training processes and the often undisclosed inclusion of supervised data in
contemporary Large Language Models (LLMs). This issue skews benchmark
effectiveness and fosters potentially unfair comparisons, impeding the field's
healthy development. To address this, we introduce a detection pipeline
utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
gauge a model's prediction precision on benchmark, to identify potential data
leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
reveal substantial instances of training even test set misuse, resulting in
potentially unfair comparisons. These findings prompt us to offer several
recommendations regarding model documentation, benchmark setup, and future
evaluations. Notably, we propose the "Benchmark Transparency Card" to encourage
clear documentation of benchmark utilization, promoting transparency and
healthy developments of LLMs. we have made our leaderboard, pipeline
implementation, and model predictions publicly available, fostering future
research.

摘要：隨著預訓練資料使用的擴展，基準資料集外洩現象變得越來越明顯，原因在於訓練過程不透明，以及當代大型語言模型 (LLM) 中經常不公開包含監督資料。此問題會扭曲基準效能，並助長潛在不公平的比較，阻礙該領域的健康發展。為了解決此問題，我們引進一個偵測管道，利用困惑度和 N-gram 精確度這兩個簡單且可擴充的指標，來衡量模型在基準上的預測精確度，以找出潛在的資料外洩。透過在數學推理的背景下分析 31 個 LLM，我們揭露了訓練集甚至測試集被濫用的大量案例，導致潛在不公平的比較。這些發現促使我們提出關於模型文件、基準設定和未來評估的幾項建議。值得注意的是，我們提出「基準透明度卡」，以鼓勵清楚記錄基準使用情況，促進透明度和 LLM 的健康發展。我們已公開我們的排行榜、管道實作和模型預測，以促進未來的研究。

##### **Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**
2404.18821v2 by Seyed Soroush Karimi Madahi,Gargya Gokhale,Marie-Sophie Verwee,Bert Claessens,Chris Develder

A continuous rise in the penetration of renewable energy sources, along with
the use of the single imbalance pricing, provides a new opportunity for balance
responsible parties to reduce their cost through energy arbitrage in the
imbalance settlement mechanism. Model-free reinforcement learning (RL) methods
are an appropriate choice for solving the energy arbitrage problem due to their
outstanding performance in solving complex stochastic sequential problems.
However, RL is rarely deployed in real-world applications since its learned
policy does not necessarily guarantee safety during the execution phase. In
this paper, we propose a new RL-based control framework for batteries to obtain
a safe energy arbitrage strategy in the imbalance settlement mechanism. In our
proposed control framework, the agent initially aims to optimize the arbitrage
revenue. Subsequently, in the post-processing step, we correct (constrain) the
learned policy following a knowledge distillation process based on properties
that follow human intuition. Our post-processing step is a generic method and
is not restricted to the energy arbitrage domain. We use the Belgian imbalance
price of 2023 to evaluate the performance of our proposed framework.
Furthermore, we deploy our proposed control framework on a real battery to show
its capability in the real world.

摘要：隨著可再生能源滲透率持續上升，加上單一失衡定價的使用，為平衡責任方提供了一個新的機會，讓他們能透過失衡結算機制中的能源套利來降低成本。無模型強化學習 (RL) 方法非常適合解決能源套利問題，因為它們在解決複雜隨機序列問題方面表現出色。然而，由於 RL 學到的策略並非一定能保證執行階段的安全性，因此它很少部署在實際應用中。在本文中，我們提出一個新的基於 RL 的電池控制架構，以在失衡結算機制中獲得安全的能源套利策略。在我們提出的控制架構中，代理最初旨在優化套利收入。隨後，在後處理步驟中，我們根據遵循人類直覺的屬性，透過知識蒸餾過程更正（約束）已學習的策略。我們的後處理步驟是一種通用方法，並不限於能源套利領域。我們使用 2023 年的比利時失衡價格來評估我們提出的架構的性能。此外，我們將我們提出的控制架構部署在真實電池上，以展示其在現實世界中的能力。

##### **Unknown Script: Impact of Script on Cross-Lingual Transfer**
2404.18810v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Cross-lingual transfer has become an effective way of transferring knowledge
between languages. In this paper, we explore an often-overlooked aspect in this
domain: the influence of the source language of the base language model on
transfer performance. We conduct a series of experiments to determine the
effect of the script and tokenizer used in the pre-trained model on the
performance of the downstream task. Our findings reveal the importance of the
tokenizer as a stronger factor than the sharing of the script, the language
typology match, and the model size.

摘要：跨語言轉移已成為在語言之間傳遞知識的有效方式。在本文中，我們探討了這個領域中經常被忽略的一個方面：基礎語言模型的源語言對轉移效能的影響。我們進行了一系列實驗，以確定預訓練模型中使用的腳本和分詞器對下游任務效能的影響。我們的研究結果揭示了分詞器作為比腳本共享、語言類型匹配和模型大小更強大的因素的重要性。

##### **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**
2404.18796v1 by Pat Verga,Sebastian Hofstatter,Sophia Althammer,Yixuan Su,Aleksandra Piktus,Arkady Arkhangorodsky,Minjie Xu,Naomi White,Patrick Lewis

As Large Language Models (LLMs) have become more advanced, they have outpaced
our abilities to accurately evaluate their quality. Not only is finding data to
adequately probe particular model properties difficult, but evaluating the
correctness of a model's freeform generation alone is a challenge. To address
this, many evaluations now rely on using LLMs themselves as judges to score the
quality of outputs from other LLMs. Evaluations most commonly use a single
large model like GPT4. While this method has grown in popularity, it is costly,
has been shown to introduce intramodel bias, and in this work, we find that
very large models are often unnecessary. We propose instead to evaluate models
using a Panel of LLm evaluators (PoLL). Across three distinct judge settings
and spanning six different datasets, we find that using a PoLL composed of a
larger number of smaller models outperforms a single large judge, exhibits less
intra-model bias due to its composition of disjoint model families, and does so
while being over seven times less expensive.

摘要：隨著大型語言模型 (LLM) 變得越來越先進，它們已經超越了我們準確評估其品質的能力。不僅難以找到資料來充分探測特定模型屬性，單獨評估模型自由形式生成的正確性也是一項挑戰。為了解決這個問題，許多評估現在依賴於使用 LLM 本身作為評審員來評分來自其他 LLM 的輸出的品質。評估最常使用單一的大型模型，例如 GPT4。雖然這種方法越來越受歡迎，但它成本高昂，已被證明會引入模型內部偏見，而且在這項工作中，我們發現非常大的模型通常是不必要的。我們建議改用 LLM 評估小組 (PoLL) 來評估模型。在三個不同的評審員設置和六個不同的資料集範圍內，我們發現使用由較多較小的模型組成的 PoLL 優於單一的大型評審員，由於其由不相交的模型系列組成，因此表現出較少的模型內部偏見，而且成本不到七分之一。

##### **Certification of Speaker Recognition Models to Additive Perturbations**
2404.18791v1 by Dmitrii Korzh,Elvir Karimov,Mikhail Pautov,Oleg Y. Rogov,Ivan Oseledets

Speaker recognition technology is applied in various tasks ranging from
personal virtual assistants to secure access systems. However, the robustness
of these systems against adversarial attacks, particularly to additive
perturbations, remains a significant challenge. In this paper, we pioneer
applying robustness certification techniques to speaker recognition, originally
developed for the image domain. In our work, we cover this gap by transferring
and improving randomized smoothing certification techniques against
norm-bounded additive perturbations for classification and few-shot learning
tasks to speaker recognition. We demonstrate the effectiveness of these methods
on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve
voice-biometry robustness, establish a new certification benchmark, and
accelerate research of certification methods in the audio domain.

摘要：語音辨識技術應用於各種任務，從個人虛擬助理到安全存取系統。然而，這些系統對抗攻擊的穩健性，特別是對加性擾動，仍然是一項重大挑戰。在本文中，我們率先將為影像領域開發的穩健性驗證技術應用於語音辨識。在我們的研究中，我們透過將針對分類和少量學習任務的範數約束加性擾動的隨機平滑驗證技術轉移並加以改進，來填補這個空白。我們在多個模型上證明了這些方法在 VoxCeleb 1 和 2 資料集上的有效性。我們預期這項研究將提升語音生物辨識的穩健性，建立新的驗證基準，並加速音訊領域驗證方法的研究。

##### **Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**
2404.18784v1 by Tessa Masis,Brendan O'Connor

Geo-entity linking is the task of linking a location mention to the
real-world geographic location. In this paper we explore the challenging task
of geo-entity linking for noisy, multilingual social media data. There are few
open-source multilingual geo-entity linking tools available and existing ones
are often rule-based, which break easily in social media settings, or
LLM-based, which are too expensive for large-scale datasets. We present a
method which represents real-world locations as averaged embeddings from
labeled user-input location names and allows for selective prediction via an
interpretable confidence score. We show that our approach improves geo-entity
linking on a global and multilingual social media dataset, and discuss progress
and problems with evaluating at different geographic granularities.

摘要：地理實體連結是將位置提及連結到現實世界中的地理位置的任務。在本文中，我們探討了針對嘈雜、多語言社群媒體資料進行地理實體連結的挑戰性任務。有少數開放原始碼的多語言地理實體連結工具可用，而現有的工具通常是基於規則的，在社群媒體設定中容易中斷，或基於 LLM，這對於大規模資料集來說太昂貴了。我們提出一個方法，將現實世界中的位置表示為標籤使用者輸入位置名稱的平均嵌入，並允許透過可解釋的信心分數進行選擇性預測。我們表明，我們的做法改善了全球和多語言社群媒體資料集上的地理實體連結，並討論了在不同地理粒度下評估的進展和問題。

##### **Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**
2404.18772v1 by Gustaw Opiełka,Jessica Loke,Steven Scholte

Deep learning algorithms lack human-interpretable accounts of how they
transform raw visual input into a robust semantic understanding, which impedes
comparisons between different architectures, training objectives, and the human
brain. In this work, we take inspiration from neuroscience and employ
representational approaches to shed light on how neural networks encode
information at low (visual saliency) and high (semantic similarity) levels of
abstraction. Moreover, we introduce a custom image dataset where we
systematically manipulate salient and semantic information. We find that
ResNets are more sensitive to saliency information than ViTs, when trained with
object classification objectives. We uncover that networks suppress saliency in
early layers, a process enhanced by natural language supervision (CLIP) in
ResNets. CLIP also enhances semantic encoding in both architectures. Finally,
we show that semantic encoding is a key factor in aligning AI with human visual
perception, while saliency suppression is a non-brain-like strategy.

摘要：深度学习算法缺乏人类可解释的说明，说明它们如何将原始视觉输入转化为稳健的语义理解，这阻碍了不同架构、训练目标和人脑之间的比较。在这项工作中，我们从神经科学中汲取灵感，并采用表征方法来阐明神经网络如何在低（视觉显着性）和高（语义相似性）抽象层级对信息进行编码。此外，我们引入了一个自定义图像数据集，其中我们系统地处理显着和语义信息。我们发现，当使用目标分类目标进行训练时，ResNet 对显着性信息比 ViT 更敏感。我们发现网络在早期层中抑制显着性，这一过程在 ResNet 中通过自然语言监督 (CLIP) 得到增强。CLIP 还可以增强两种架构中的语义编码。最后，我们表明语义编码是使人工智能与人类视觉感知保持一致的关键因素，而显着性抑制是一种非类脑策略。

##### **PECC: Problem Extraction and Coding Challenges**
2404.18766v1 by Patrick Haller,Jonas Golde,Alan Akbik

Recent advancements in large language models (LLMs) have showcased their
exceptional abilities across various tasks, such as code generation,
problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation,
yet the extent to which LLMs can understand prose-style tasks, identify the
underlying problems, and then generate appropriate code solutions is still
unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived
from Advent Of Code (AoC) challenges and Project Euler, including 2396
problems. Unlike conventional benchmarks, PECC requires LLMs to interpret
narrative-embedded problems, extract requirements, and generate executable
code. A key feature of our dataset is the complexity added by natural language
prompting in chat-based evaluations, mirroring real-world instruction
ambiguities. Results show varying model performance between narrative and
neutral problems, with specific challenges in the Euler math-based subset with
GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler
problems. By probing the limits of LLMs' capabilities, our benchmark provides a
framework to monitor and assess the subsequent progress of LLMs as a universal
problem solver.

摘要：大型語言模型 (LLM) 的最新進展展示了它們在各種任務中的卓越能力，例如程式碼生成、問題解決和推理。現有的基準會孤立地評估任務，但 LLM 在何種程度上能理解散文式任務、找出潛在問題，然後產生適當的程式碼解決方案，這方面仍未被探討。為了彌補這個差距，我們引入了 PECC，一個從 Advent Of Code (AoC) 挑戰和歐拉計畫衍生的新基準，其中包含 2396 個問題。與傳統基準不同，PECC 要求 LLM 解釋嵌入式敘述的問題、提取需求，並產生可執行的程式碼。我們資料集的一個關鍵特徵是，在基於聊天的評估中，自然語言提示增加了複雜性，反映了現實世界的指令模糊性。結果顯示，敘述和中立問題之間的模型效能不同，歐拉數學子集中有具體的挑戰，其中 GPT-3.5-Turbo 通過 50% 的 AoC 挑戰，但在歐拉問題中只有 8%。通過探討 LLM 能力的極限，我們的基準提供了一個架構，用於監控和評估 LLM 作為通用問題解決者的後續進展。

##### **Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**
2404.18759v1 by Juraj Vladika,Stephen Meisenbacher,Martina Preis,Alexandra Klymenko,Florian Matthes

In recent years, the field of Legal Tech has risen in prevalence, as the
Natural Language Processing (NLP) and legal disciplines have combined forces to
digitalize legal processes. Amidst the steady flow of research solutions
stemming from the NLP domain, the study of use cases has fallen behind, leading
to a number of innovative technical methods without a place in practice. In
this work, we aim to build a structured overview of Legal Tech use cases,
grounded in NLP literature, but also supplemented by voices from legal practice
in Germany. Based upon a Systematic Literature Review, we identify seven
categories of NLP technologies for the legal domain, which are then studied in
juxtaposition to 22 legal use cases. In the investigation of these use cases,
we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
potential concerns of digitally transforming the legal domain.

摘要：近年來，法律科技領域的盛行度日益提高，因為自然語言處理 (NLP) 和法律學科已結合力量，將法律程序數位化。在源自 NLP 領域的穩定研究解決方案中，使用案例的研究落後了，導致許多創新的技術方法在實務上無用武之地。在這項工作中，我們旨在建立一個結構化的法律科技使用案例概觀，其基礎在於 NLP 文獻，但也補充了來自德國法律實務的聲音。根據系統化文獻回顧，我們識別出七類適用於法律領域的 NLP 技術，然後與 22 個法律使用案例並置研究。在調查這些使用案例時，我們找出 15 個倫理、法律和社會面向 (ELSA)，揭露了對數位轉型法律領域的潛在疑慮。

##### **Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**
2404.18747v1 by Shanle Yao,Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi

Video Anomaly Detection (VAD) identifies unusual activities in video streams,
a key technology with broad applications ranging from surveillance to
healthcare. Tackling VAD in real-life settings poses significant challenges due
to the dynamic nature of human actions, environmental variations, and domain
shifts. Many research initiatives neglect these complexities, often
concentrating on traditional testing methods that fail to account for
performance on unseen datasets, creating a gap between theoretical models and
their real-world utility. Online learning is a potential strategy to mitigate
this issue by allowing models to adapt to new information continuously. This
paper assesses how well current VAD algorithms can adjust to real-life
conditions through an online learning framework, particularly those based on
pose analysis, for their efficiency and privacy advantages. Our proposed
framework enables continuous model updates with streaming data from novel
environments, thus mirroring actual world challenges and evaluating the models'
ability to adapt in real-time while maintaining accuracy. We investigate three
state-of-the-art models in this setting, focusing on their adaptability across
different domains. Our findings indicate that, even under the most challenging
conditions, our online learning approach allows a model to preserve 89.39% of
its original effectiveness compared to its offline-trained counterpart in a
specific target domain.

摘要：影片異常偵測 (VAD) 可識別影片串流中的異常活動，
這項關鍵技術的應用範圍廣泛，從監視到醫療保健。在現實生活中處理 VAD 時會面臨重大挑戰，
因為人類動作具有動態性質，環境會產生變化，而且領域會轉移。許多研究計畫忽略了這些複雜性，
通常專注於傳統的測試方法，這些方法無法考量在未見過的資料集上的效能，造成理論模型與
實際效用之間的落差。線上學習是一種潛在策略，可透過讓模型持續適應新資訊來緩解此問題。這
篇論文評估了目前的 VAD 演算法在線上學習架構中適應現實生活狀況的程度，特別是那些基於姿勢分析的演算法，
因為它們具有效率和隱私優勢。我們提出的架構能使用來自新環境的串流資料持續更新模型，
因此能反映實際世界的挑戰，並評估模型在維持準確度的同時適應即時狀況的能力。我們針對此設定探討了三種最先進的模型，
重點關注它們在不同領域中的適應性。我們的研究結果顯示，即使在最具挑戰性的條件下，我們的線上學習方法仍能讓模型保留 89.39%
的原始效能，與在特定目標領域中經過離線訓練的對應模型相比。

##### **Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**
2404.18739v1 by Artem Abzaliev,Humberto Pérez Espinosa,Rada Mihalcea

Similar to humans, animals make extensive use of verbal and non-verbal forms
of communication, including a large range of audio signals. In this paper, we
address dog vocalizations and explore the use of self-supervised speech
representation models pre-trained on human speech to address dog bark
classification tasks that find parallels in human-centered tasks in speech
recognition. We specifically address four tasks: dog recognition, breed
identification, gender classification, and context grounding. We show that
using speech embedding representations significantly improves over simpler
classification baselines. Further, we also find that models pre-trained on
large human speech acoustics can provide additional performance boosts on
several tasks.

摘要：與人類類似，動物廣泛使用言語和非言語的溝通形式，包括廣泛的音訊訊號。在本文中，我們探討狗的發聲，並探索使用在人類語音上預先訓練的自監督式語音表示模型，來處理狗吠聲分類任務，這些任務與以人類為中心的語音辨識任務有相似之處。我們特別探討四項任務：狗的辨識、品種辨識、性別分類和情境依據。我們證明使用語音嵌入表示法顯著優於較簡單的分類基準。此外，我們也發現預先在大量人類語音聲學上訓練的模型可以在多項任務中提供額外的效能提升。

##### **The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**
2404.18726v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Toxic language remains an ongoing challenge on social media platforms,
presenting significant issues for users and communities. This paper provides a
cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We
collect 1.5 million comment threads from 481 communities in six languages:
English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as
Culture, Politics, and News. We thoroughly analyze how toxicity spikes within
different communities in relation to specific topics. We observe consistent
patterns of increased toxicity across languages for certain topics, while also
noting significant variations within specific language communities.

摘要：有毒言論在社群媒體平台上持續成為一項挑戰，
對使用者和社群造成重大問題。本文提供
Reddit 對話中跨主題和跨語言的毒性分析。我們
從六種語言的 481 個社群收集了 150 萬個留言串：
英文、德文、西班牙文、土耳其文、阿拉伯文和荷蘭文，涵蓋 80 個主題，例如
文化、政治和新聞。我們徹底分析了毒性如何在
不同社群內與特定主題相關聯而激增。我們觀察到
特定主題在各語言中毒性增加的一致模式，同時也
注意到特定語言社群內的顯著差異。

##### **Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**
2404.18722v1 by Solène Tarride,Yoann Schneider,Marie Generali-Lince,Mélodie Boillet,Bastien Abadie,Christopher Kermorvant

PyLaia is one of the most popular open-source software for Automatic Text
Recognition (ATR), delivering strong performance in terms of speed and
accuracy. In this paper, we outline our recent contributions to the PyLaia
library, focusing on the incorporation of reliable confidence scores and the
integration of statistical language modeling during decoding. Our
implementation provides an easy way to combine PyLaia with n-grams language
models at different levels. One of the highlights of this work is that language
models are completely auto-tuned: they can be built and used easily without any
expert knowledge, and without requiring any additional data. To demonstrate the
significance of our contribution, we evaluate PyLaia's performance on twelve
datasets, both with and without language modelling. The results show that
decoding with small language models improves the Word Error Rate by 13% and the
Character Error Rate by 12% in average. Additionally, we conduct an analysis of
confidence scores and highlight the importance of calibration techniques. Our
implementation is publicly available in the official PyLaia repository at
https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are
released on Hugging Face.

摘要：PyLaia 是最受歡迎的自動文字辨識 (ATR) 開源軟體之一，在速度和準確性方面表現出色。在本文中，我們概述了我們對 PyLaia 程式庫的最新貢獻，重點在於整合可靠的信心分數和在解碼期間整合統計語言模型。我們的實作提供了一個簡單的方法，可以在不同層級將 PyLaia 與 n-grams 語言模型結合。這項工作的亮點之一是語言模型完全自動調整：它們可以輕鬆建置和使用，無需任何專家知識，也不需要任何額外資料。為了證明我們貢獻的重要性，我們在十二個資料集上評估 PyLaia 的效能，有語言模型和沒有語言模型的都有。結果顯示，使用小型語言模型進行解碼，平均可將字元錯誤率降低 13%，將字元錯誤率降低 12%。此外，我們對信心分數進行分析，並強調校準技術的重要性。我們的實作已公開在 https://gitlab.teklia.com/atr/pylaia 的官方 PyLaia 儲存庫中，並且在 Hugging Face 上發布了十二個開源模型。

##### **Iconic Gesture Semantics**
2404.18708v1 by Andy Lücking,Alexander Henlein,Alexander Mehler

The "meaning" of an iconic gesture is conditioned on its informational
evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic
level that can interact with verbal content. Interaction is either vacuous or
regimented by usual lexicon-driven inferences. Informational evaluation is
spelled out as extended exemplification (extemplification) in terms of
perceptual classification of a gesture's visual iconic model. The iconic model
is derived from Frege/Montague-like truth-functional evaluation of a gesture's
form within spatially extended domains. We further argue that the perceptual
classification of instances of visual communication requires a notion of
meaning different from Frege/Montague frameworks. Therefore, a heuristic for
gesture interpretation is provided that can guide the working semanticist. In
sum, an iconic gesture semantics is introduced which covers the full range from
kinematic gesture representations over model-theoretic evaluation to
inferential interpretation in dynamic semantic frameworks.

摘要：手勢的「意義」取決於它所傳達的資訊。只有資訊評估才能將手勢提升到一個準語言層級，以與口語內容互動。互動要不是空洞無物，就是由慣常的詞彙驅動的推論所規範。資訊評估被拼寫成手勢視覺標誌模型的感知分類中的延伸範例（範例化）。標誌模型源自於在空間延伸域中對手勢形式的弗雷格/蒙塔古式的真值函數評估。我們進一步論證，視覺溝通實例的感知分類需要一個與弗雷格/蒙塔古框架不同的意義概念。因此，提供了一個手勢詮釋的啟發式方法，可以指導工作語義學家。總而言之，引入了一個標誌手勢語義，涵蓋了從運動手勢表示到模型理論評估再到動態語義框架中的推論詮釋的完整範圍。

##### **Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**
2404.18684v1 by Sidharth Ranjan,Titus von der Malsburg

Dependency length minimization is a universally observed quantitative
property of natural languages. However, the extent of dependency length
minimization, and the cognitive mechanisms through which the language processor
achieves this minimization remain unclear. This research offers mechanistic
insights by postulating that moving a short preverbal constituent next to the
main verb explains preverbal constituent ordering decisions better than global
minimization of dependency length in SOV languages. This approach constitutes a
least-effort strategy because it's just one operation but simultaneously
reduces the length of all preverbal dependencies linked to the main verb. We
corroborate this strategy using large-scale corpus evidence across all seven
SOV languages that are prominently represented in the Universal Dependency
Treebank. These findings align with the concept of bounded rationality, where
decision-making is influenced by 'quick-yet-economical' heuristics rather than
exhaustive searches for optimal solutions. Overall, this work sheds light on
the role of bounded rationality in linguistic decision-making and language
evolution.

摘要：依存長度最小化是自然語言普遍觀察到的量化特性。然而，依存長度最小化的程度，以及語言處理器透過哪些認知機制來達成此最小化仍不清楚。本研究透過假設將短的主事詞成分移動到主要動詞旁邊，比 SOV 語言中依存長度的整體最小化更能解釋主事詞成分的排序決策，提供了機制見解。此方法構成一種最省力的策略，因為它只是一個操作，但同時減少了連結到主要動詞的所有主事詞依存項的長度。我們使用 Universal Dependency Treebank 中顯著呈現的所有七種 SOV 語言的大規模語料庫證據來驗證此策略。這些發現與受限理性的概念一致，其中決策會受到「快速且經濟」的啟發式影響，而不是對最佳解進行窮舉搜尋。總體而言，這項工作闡明了受限理性在語言決策和語言演化中的角色。

##### **Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**
2404.18672v1 by Paul Cibier,Jean-Guy Mailly

Various approaches have been proposed for providing efficient computational
approaches for abstract argumentation. Among them, neural networks have
permitted to solve various decision problems, notably related to arguments
(credulous or skeptical) acceptability. In this work, we push further this
study in various ways. First, relying on the state-of-the-art approach AFGCN,
we show how we can improve the performances of the Graph Convolutional Networks
(GCNs) regarding both runtime and accuracy. Then, we show that it is possible
to improve even more the efficiency of the approach by modifying the
architecture of the network, using Graph Attention Networks (GATs) instead.

摘要：各種方法已被提出，用於提供抽象論證的有效計算方法。其中，神經網路已被允許解決各種決策問題，特別是與論證（輕信或懷疑）的可接受性相關的問題。在這項工作中，我們以各種方式進一步推進這項研究。首先，依賴於最先進的方法 AFGCN，我們展示了如何提高圖形卷積網路 (GCN) 在執行時間和準確性方面的效能。然後，我們展示了透過修改網路架構，改用圖形注意力網路 (GAT) 甚至可以進一步提高方法的效率。

##### **Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**
2404.18669v1 by Yifei Gao,Jie Ou,Lei Wang,Jun Cheng

Recent developments in neural rendering techniques have greatly enhanced the
rendering of photo-realistic 3D scenes across both academic and commercial
fields. The latest method, known as 3D Gaussian Splatting (3D-GS), has set new
benchmarks for rendering quality and speed. Nevertheless, the limitations of
3D-GS become pronounced in synthesizing new viewpoints, especially for views
that greatly deviate from those seen during training. Additionally, issues such
as dilation and aliasing arise when zooming in or out. These challenges can all
be traced back to a single underlying issue: insufficient sampling. In our
paper, we present a bootstrapping method that significantly addresses this
problem. This approach employs a diffusion model to enhance the rendering of
novel views using trained 3D-GS, thereby streamlining the training process. Our
results indicate that bootstrapping effectively reduces artifacts, as well as
clear enhancements on the evaluation metrics. Furthermore, we show that our
method is versatile and can be easily integrated, allowing various 3D
reconstruction projects to benefit from our approach.

摘要：神經渲染技術的最新進展大幅提升了學術和商業領域中逼真 3D 場景的渲染。最新的方法稱為 3D 高斯潑濺 (3D-GS)，已為渲染品質和速度樹立新的基準。然而，3D-GS 的限制在合成新視點時變得明顯，特別是對於與訓練期間所見視點有很大差異的視圖。此外，在放大或縮小時會出現膨脹和混疊等問題。這些挑戰都可以追溯到一個根本問題：採樣不足。在我們的論文中，我們提出了一種自舉法，可以顯著解決這個問題。這種方法採用擴散模型來增強使用訓練過的 3D-GS 渲染新視圖，從而簡化訓練過程。我們的結果表明，自舉法有效減少了人工製品，並在評估指標上顯著提升。此外，我們證明了我們的方法是多功能的，可以輕鬆整合，讓各種 3D 重建專案都能受益於我們的方法。

##### **Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**
2404.18655v1 by Haeun Yu,Pepa Atanasova,Isabelle Augenstein

Language Models (LMs) acquire parametric knowledge from their training
process, embedding it within their weights. The increasing scalability of LMs,
however, poses significant challenges for understanding a model's inner
workings and further for updating or correcting this embedded knowledge without
the significant cost of retraining. This underscores the importance of
unveiling exactly what knowledge is stored and its association with specific
model components. Instance Attribution (IA) and Neuron Attribution (NA) offer
insights into this training-acquired knowledge, though they have not been
compared systematically. Our study introduces a novel evaluation framework to
quantify and compare the knowledge revealed by IA and NA. To align the results
of the methods we introduce the attribution method NA-Instances to apply NA for
retrieving influential training instances, and IA-Neurons to discover important
neurons of influential instances discovered by IA. We further propose a
comprehensive list of faithfulness tests to evaluate the comprehensiveness and
sufficiency of the explanations provided by both methods. Through extensive
experiments and analysis, we demonstrate that NA generally reveals more diverse
and comprehensive information regarding the LM's parametric knowledge compared
to IA. Nevertheless, IA provides unique and valuable insights into the LM's
parametric knowledge, which are not revealed by NA. Our findings further
suggest the potential of a synergistic approach of combining the diverse
findings of IA and NA for a more holistic understanding of an LM's parametric
knowledge.

摘要：語言模型 (LM) 從其訓練過程中獲取參數知識，並將其嵌入其權重中。然而，LM 的可擴充性不斷提高，對理解模型的內部運作以及進一步更新或修正此嵌入式知識提出了重大挑戰，而無需付出重新訓練的巨大成本。這強調了準確揭示儲存了哪些知識及其與特定模型組件的關聯的重要性。實例歸因 (IA) 和神經元歸因 (NA) 提供了對此訓練獲取的知識的見解，儘管它們尚未經過系統地比較。我們的研究引入了一個新穎的評估框架，以量化和比較 IA 和 NA 揭示的知識。為了使方法的結果保持一致，我們引入了歸因方法 NA-Instances，以應用 NA 來檢索有影響力的訓練實例，以及 IA-Neurons 來發現 IA 發現的有影響力的實例的重要神經元。我們進一步提出了全面的忠實度測試清單，以評估這兩種方法提供的解釋的全面性和充分性。通過廣泛的實驗和分析，我們證明 NA 通常揭示了與 IA 相比更多樣化和全面的有關 LM 參數知識的信息。儘管如此，IA 仍提供對 LM 參數知識的獨特且有價值的見解，而這些見解並未由 NA 揭示。我們的研究結果進一步表明了結合 IA 和 NA 的不同發現以更全面地理解 LM 的參數知識的協同方法的潛力。

##### **Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**
2404.18649v1 by Konstantinos Tsigos,Evlampios Apostolidis,Spyridon Baxevanakis,Symeon Papadopoulos,Vasileios Mezaris

In this paper we propose a new framework for evaluating the performance of
explanation methods on the decisions of a deepfake detector. This framework
assesses the ability of an explanation method to spot the regions of a fake
image with the biggest influence on the decision of the deepfake detector, by
examining the extent to which these regions can be modified through a set of
adversarial attacks, in order to flip the detector's prediction or reduce its
initial prediction; we anticipate a larger drop in deepfake detection accuracy
and prediction, for methods that spot these regions more accurately. Based on
this framework, we conduct a comparative study using a state-of-the-art model
for deepfake detection that has been trained on the FaceForensics++ dataset,
and five explanation methods from the literature. The findings of our
quantitative and qualitative evaluations document the advanced performance of
the LIME explanation method against the other compared ones, and indicate this
method as the most appropriate for explaining the decisions of the utilized
deepfake detector.

摘要：在本文中，我们提出一个新的框架，用于评估解释方法在深度伪造检测器决策上的性能。此框架评估解释方法识别深度伪造检测器决策中影响最大的伪造图像区域的能力，通过检查这些区域可以通过一组对抗性攻击进行修改的程度，以翻转检测器的预测或降低其初始预测；我们预计对于更准确地识别这些区域的方法，深度伪造检测准确性和预测的下降幅度更大。基于此框架，我们使用一个最先进的模型进行比较研究，用于深度伪造检测，该模型已在 FaceForensics++ 数据集上进行训练，并从文献中使用五种解释方法。我们的定量和定性评估结果证明了 LIME 解释方法相对于其他比较方法的先进性能，并表明此方法最适合解释所利用的深度伪造检测器的决策。

##### **Reinforcement Learning Problem Solving with Large Language Models**
2404.18638v1 by Sina Gholamian,Domingo Huh

Large Language Models (LLMs) encapsulate an extensive amount of world
knowledge, and this has enabled their application in various domains to improve
the performance of a variety of Natural Language Processing (NLP) tasks. This
has also facilitated a more accessible paradigm of conversation-based
interactions between humans and AI systems to solve intended problems. However,
one interesting avenue that shows untapped potential is the use of LLMs as
Reinforcement Learning (RL) agents to enable conversational RL problem solving.
Therefore, in this study, we explore the concept of formulating Markov Decision
Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can
be iteratively prompted to learn and optimize policies for specific RL tasks.
In addition, we leverage the introduced prompting technique for episode
simulation and Q-Learning, facilitated by LLMs. We then show the practicality
of our approach through two detailed case studies for "Research Scientist" and
"Legal Matter Intake" workflows.

摘要：大型語言模型 (LLM) 囊括了大量的世界知識，這使得它們能夠應用於各種領域，以改善各種自然語言處理 (NLP) 任務的執行。這也促成了一種更易於使用的對話式互動範例，在人類和 AI 系統之間解決預期的問題。然而，一個顯示出未開發潛力的有趣途徑是將 LLM 用作強化學習 (RL) 代理，以實現對話式 RL 問題解決。因此，在本研究中，我們探討了將基於馬可夫決策過程的 RL 問題制定為 LLM 提示任務的概念。我們展示了如何反覆提示 LLM 以學習和最佳化特定 RL 任務的政策。此外，我們利用引入的提示技術進行情節模擬和 Q 學習，由 LLM 促成。然後，我們通過兩個詳細的案例研究展示了我們方法的實用性，分別針對「研究科學家」和「法律事務處理」工作流程。

##### **Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**
2404.18624v1 by Letitia Parcalabescu,Anette Frank

Vision and language models (VLMs) are currently the most generally performant
architectures on multimodal tasks. Next to their predictions, they can also
produce explanations, either in post-hoc or CoT settings. However, it is not
clear how much they use the vision and text modalities when generating
predictions or explanations. In this work, we investigate if VLMs rely on
modalities differently when generating explanations as opposed to when they
provide answers. We also evaluate the self-consistency of VLM decoders in both
post-hoc and CoT explanation settings, by extending existing tests and measures
to VLM decoders. We find that VLMs are less self-consistent than LLMs. The text
contributions in VL decoders are much larger than the image contributions
across all measured tasks. And the contributions of the image are significantly
larger for explanation generations than for answer generation. This difference
is even larger in CoT compared to the post-hoc explanation setting. We also
provide an up-to-date benchmarking of state-of-the-art VL decoders on the VALSE
benchmark, which to date focused only on VL encoders. We find that VL decoders
are still struggling with most phenomena tested by VALSE.

摘要：視覺和語言模型 (VLM) 目前是多模態任務上效能最普遍的架構。除了預測之外，它們還能產生解釋，無論是在事後或 CoT 設定中。然而，目前尚不清楚它們在產生預測或解釋時，使用了多少視覺和文字模態。在這項研究中，我們探討 VLM 在產生解釋時是否與在提供答案時，對模態有不同的依賴。我們也透過將現有測試和測量延伸至 VLM 解碼器，評估 VLM 解碼器在事後和 CoT 解釋設定中的自我一致性。我們發現 VLM 的自我一致性低於 LLM。在所有測量任務中，VLM 解碼器中的文字貢獻都遠大於影像貢獻。而影像的貢獻在產生解釋時，明顯大於產生答案時。這種差異在 CoT 中，甚至比在事後解釋設定中更大。我們也提供 VALSE 基準上最先進的 VLM 解碼器的最新基準測試，該基準迄今只專注於 VLM 編碼器。我們發現 VLM 解碼器仍難以應付 VALSE 測試的大部分現象。

##### **The SAMER Arabic Text Simplification Corpus**
2404.18615v1 by Bashar Alhafni,Reem Hazim,Juan Piñeros Liberato,Muhamed Al Khalil,Nizar Habash

We present the SAMER Corpus, the first manually annotated Arabic parallel
corpus for text simplification targeting school-aged learners. Our corpus
comprises texts of 159K words selected from 15 publicly available Arabic
fiction novels most of which were published between 1865 and 1955. Our corpus
includes readability level annotations at both the document and word levels, as
well as two simplified parallel versions for each text targeting learners at
two different readability levels. We describe the corpus selection process, and
outline the guidelines we followed to create the annotations and ensure their
quality. Our corpus is publicly available to support and encourage research on
Arabic text simplification, Arabic automatic readability assessment, and the
development of Arabic pedagogical language technologies.

摘要：我們提出 SAMER 語料庫，這是第一個針對學齡學習者進行文字簡化的阿拉伯語平行語料庫。我們的語料庫包含從 15 部公開的阿拉伯語小說中選出的 159K 個單字文本，其中大部分於 1865 年至 1955 年間出版。我們的語料庫包含文件和單字層級的可讀性標註，以及針對兩個不同可讀性層級的學習者，為每個文本提供兩個簡化的平行版本。我們描述語料庫的選取過程，並概述我們遵循的準則，以建立標註並確保其品質。我們的語料庫公開可用，以支持和鼓勵阿拉伯語文字簡化、阿拉伯語自動可讀性評估以及阿拉伯語教學語言技術的發展。

##### **CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**
2404.18604v1 by Xiangyu Liang,Wenlin Zhuang,Tianyong Wang,Guangxing Geng,Guangyue Geng,Haifeng Xia,Siyu Xia

Speech-driven 3D facial animation technology has been developed for years,
but its practical application still lacks expectations. The main challenges lie
in data limitations, lip alignment, and the naturalness of facial expressions.
Although lip alignment has seen many related studies, existing methods struggle
to synthesize natural and realistic expressions, resulting in a mechanical and
stiff appearance of facial animations. Even with some research extracting
emotional features from speech, the randomness of facial movements limits the
effective expression of emotions. To address this issue, this paper proposes a
method called CSTalk (Correlation Supervised) that models the correlations
among different regions of facial movements and supervises the training of the
generative model to generate realistic expressions that conform to human facial
motion patterns. To generate more intricate animations, we employ a rich set of
control parameters based on the metahuman character model and capture a dataset
for five different emotions. We train a generative network using an autoencoder
structure and input an emotion embedding vector to achieve the generation of
user-control expressions. Experimental results demonstrate that our method
outperforms existing state-of-the-art methods.

摘要：語音驅動 3D 臉部動畫技術已經發展多年，
但其實際應用仍未達到預期。主要的挑戰在於數據限制、嘴唇對齊和臉部表情的自然性。
儘管嘴唇對齊已經有許多相關研究，現有方法仍難以合成自然且逼真的表情，導致臉部動畫呈現機械且僵硬的外觀。即使有些研究從語音中萃取情緒特徵，臉部動作的隨機性仍限制了情緒的有效表達。為了解決這個問題，本文提出一個稱為 CSTalk（相關監督）的方法，它建構臉部動作不同區域之間的關聯性，並監督生成模型的訓練，以生成符合人類臉部動作模式的逼真表情。為了產生更複雜的動畫，我們採用基於元人類角色模型的豐富控制參數集，並擷取一個包含五種不同情緒的資料集。我們使用自動編碼器結構訓練一個生成網路，並輸入情緒嵌入向量，以產生使用者控制的表情。實驗結果證明，我們的模型優於現有的最先進方法。

##### **FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**
2404.18585v1 by Wei Zhou,Mohsen Mesgar,Heike Adel,Annemarie Friedrich

Table Question Answering (TQA) aims at composing an answer to a question
based on tabular data. While prior research has shown that TQA models lack
robustness, understanding the underlying cause and nature of this issue remains
predominantly unclear, posing a significant obstacle to the development of
robust TQA systems. In this paper, we formalize three major desiderata for a
fine-grained evaluation of robustness of TQA systems. They should (i) answer
questions regardless of alterations in table structure, (ii) base their
responses on the content of relevant cells rather than on biases, and (iii)
demonstrate robust numerical reasoning capabilities. To investigate these
aspects, we create and publish a novel TQA evaluation benchmark in English. Our
extensive experimental analysis reveals that none of the examined
state-of-the-art TQA systems consistently excels in these three aspects. Our
benchmark is a crucial instrument for monitoring the behavior of TQA systems
and paves the way for the development of robust TQA systems. We release our
benchmark publicly.

摘要：表格問答 (TQA) 的目標是根據表格資料撰寫問題的答案。儘管先前的研究顯示 TQA 模型缺乏穩健性，但了解此問題的根本原因和性質仍不明確，這對穩健 TQA 系統的開發構成重大障礙。在本文中，我們正式制定了 TQA 系統穩健性的細粒度評估的三個主要條件。它們應該 (i) 不論表格結構如何變更都能回答問題，(ii) 將回應建立在相關儲存格的內容上，而不是偏見，以及 (iii) 展現穩健的數值推理能力。為了探討這些方面，我們建立並發布了一個創新的英文 TQA 評估基準。我們廣泛的實驗分析顯示，沒有任何已檢查過的最新 TQA 系統在這些三個方面都持續表現出色。我們的基準是監控 TQA 系統行為的關鍵工具，並為穩健 TQA 系統的開發鋪路。我們公開發布我們的基準。

##### **Analyzing Semantic Change through Lexical Replacements**
2404.18570v1 by Francesco Periti,Pierluigi Cassotti,Haim Dubossarsky,Nina Tahmasebi

Modern language models are capable of contextualizing words based on their
surrounding context. However, this capability is often compromised due to
semantic change that leads to words being used in new, unexpected contexts not
encountered during pre-training. In this paper, we model \textit{semantic
change} by studying the effect of unexpected contexts introduced by
\textit{lexical replacements}. We propose a \textit{replacement schema} where a
target word is substituted with lexical replacements of varying relatedness,
thus simulating different kinds of semantic change. Furthermore, we leverage
the replacement schema as a basis for a novel \textit{interpretable} model for
semantic change. We are also the first to evaluate the use of LLaMa for
semantic change detection.

摘要：現代語言模型能夠根據單字周圍的語境，對單字進行語境化。然而，由於語義變遷，導致單字被用於新的、預料之外的語境中，而這些語境在預訓練期間並未遭遇，因此這種能力常常受到影響。在本文中，我們透過研究由「詞彙替換」引入的意外語境之影響，對「語義變遷」進行建模。我們提出一個「替換模式」，其中目標單字會被相關性不同的詞彙替換所取代，從而模擬出不同類型的語義變遷。此外，我們利用替換模式作為語義變遷的新穎「可解釋」模型的基礎。我們也是第一個評估使用 LLaMa 進行語義變遷偵測的人。

##### **Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**
2404.18564v1 by Wen-Yu Chang,Yun-Nung Chen

Recent research in dialogue systems and corpora has focused on two main
categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD
systems help users accomplish specific tasks, while open-domain systems aim to
create engaging conversations. However, in real-world scenarios, user intents
are often revealed during interactions. A recent study introduced SalesBot,
which simulates dialogues transitioning from chit-chat to task-oriented
scenarios to train sales agents. Unfortunately, the initial data lacked smooth
transitions and coherent long-turn dialogues, resulting in poor naturalness in
sales-customer interactions. To address these issues, this paper presents
SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from
large language models (LLMs) through strategic prompting. Additionally, we
introduce a novel model called SalesAgent, trained on salesperson's
interactions, using chain-of-thought (CoT) reasoning. This model excels in
transitioning topics, understanding user intents, and selecting appropriate
strategies. Experiments using diverse user simulations validate the
effectiveness of our method in controlling dialogue strategies in LLMs.
Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,
facilitating better model learning for sales-customer interactions.

摘要：對話系統和語料庫的最新研究主要集中在兩個類別：任務導向 (TOD) 對話和開放領域（閒聊）對話。TOD 系統幫助使用者完成特定任務，而開放領域系統旨在建立引人入勝的對話。然而，在現實世界的場景中，使用者意圖通常在互動過程中被揭示。最近的一項研究引入了 SalesBot，它模擬了從閒聊到任務導向場景過渡的對話，以訓練銷售人員。不幸的是，初始資料缺乏平滑的過渡和連貫的長輪對話，導致銷售人員與客戶互動的自然度不佳。為了解決這些問題，本文提出了 SalesBot 2.0，一個經過改善的資料集。它透過策略性提示，利用來自大型語言模型 (LLM) 的常識知識。此外，我們引入了稱為 SalesAgent 的新模型，它使用思考鏈 (CoT) 推理，根據銷售人員的互動進行訓練。此模型擅長轉換主題、理解使用者意圖和選擇適當的策略。使用不同使用者模擬的實驗驗證了我們的方法在控制 LLM 中的對話策略方面的有效性。此外，SalesBot 2.0 增強了連貫性並減少了攻擊性，促進了銷售人員與客戶互動的更好模型學習。

##### **LangBiTe: A Platform for Testing Bias in Large Language Models**
2404.18558v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The integration of Large Language Models (LLMs) into various software
applications raises concerns about their potential biases. Typically, those
models are trained on a vast amount of data scrapped from forums, websites,
social media and other internet sources, which may instill harmful and
discriminating behavior into the model. To address this issue, we present
LangBiTe, a testing platform to systematically assess the presence of biases
within an LLM. LangBiTe enables development teams to tailor their test
scenarios, and automatically generate and execute the test cases according to a
set of user-defined ethical requirements. Each test consists of a prompt fed
into the LLM and a corresponding test oracle that scrutinizes the LLM's
response for the identification of biases. LangBite provides users with the
bias evaluation of LLMs, and end-to-end traceability between the initial
ethical requirements and the insights obtained.

摘要：大型語言模型 (LLM) 整合到各種軟體應用程式中，讓人們開始擔心它們潛在的偏見。通常，這些模型是針對從論壇、網站、社群媒體和其他網路來源擷取的大量資料進行訓練，這可能會在模型中灌輸有害且有歧視性的行為。為了解決這個問題，我們提出了 LangBiTe，一個用於系統性評估 LLM 中偏見存在的測試平台。LangBiTe 能讓開發團隊客製化他們的測試情境，並根據一組使用者定義的道德要求自動產生和執行測試案例。每個測試都包含一個提供給 LLM 的提示，以及一個對應的測試預言，用於仔細審查 LLM 的回應，以找出偏見。LangBiTe 為使用者提供 LLM 的偏見評估，以及初始道德要求和獲得的見解之間的端到端可追溯性。

##### **Can GPT-4 do L2 analytic assessment?**
2404.18557v1 by Stefano Bannò,Hari Krishna Vydana,Kate M. Knill,Mark J. F. Gales

Automated essay scoring (AES) to evaluate second language (L2) proficiency
has been a firmly established technology used in educational contexts for
decades. Although holistic scoring has seen advancements in AES that match or
even exceed human performance, analytic scoring still encounters issues as it
inherits flaws and shortcomings from the human scoring process. The recent
introduction of large language models presents new opportunities for automating
the evaluation of specific aspects of L2 writing proficiency. In this paper, we
perform a series of experiments using GPT-4 in a zero-shot fashion on a
publicly available dataset annotated with holistic scores based on the Common
European Framework of Reference and aim to extract detailed information about
their underlying analytic components. We observe significant correlations
between the automatically predicted analytic scores and multiple features
associated with the individual proficiency components.

摘要：自動化論文評分 (AES) 用於評估第二語言 (L2) 能力，這項技術已在教育環境中穩固確立並使用數十年。儘管整體評分在 AES 中已取得進展，可以達到或甚至超越人類表現，但分析評分仍會遇到問題，因為它繼承了人類評分過程中的缺陷和缺點。近期導入的大語言模型為自動化評估 L2 寫作能力的特定面向提供了新的契機。在本文中，我們使用 GPT-4 在公開可用的資料集上進行一系列零次學習實驗，該資料集根據歐洲共同參考架構標註了整體評分，並旨在萃取其底層分析組成的詳細資訊。我們觀察到自動預測的分析評分與個人能力組成相關的許多特徵之間存在顯著相關性。

##### **Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**
2404.18553v1 by Gareth Davies

Autoregressive Recurrent Neural Networks are widely employed in time-series
forecasting tasks, demonstrating effectiveness in univariate and certain
multivariate scenarios. However, their inherent structure does not readily
accommodate the integration of future, time-dependent covariates. A proposed
solution, outlined by Salinas et al 2019, suggests forecasting both covariates
and the target variable in a multivariate framework. In this study, we
conducted comprehensive tests on publicly available time-series datasets,
artificially introducing highly correlated covariates to future time-step
values. Our evaluation aimed to assess the performance of an LSTM network when
considering these covariates and compare it against a univariate baseline. As
part of this study we introduce a novel approach using seasonal time segments
in combination with an RNN architecture, which is both simple and extremely
effective over long forecast horizons with comparable performance to many state
of the art architectures. Our findings from the results of more than 120 models
reveal that under certain conditions jointly training covariates with target
variables can improve overall performance of the model, but often there exists
a significant performance disparity between multivariate and univariate
predictions. Surprisingly, even when provided with covariates informing the
network about future target values, multivariate predictions exhibited inferior
performance. In essence, compelling the network to predict multiple values can
prove detrimental to model performance, even in the presence of informative
covariates. These results suggest that LSTM architectures may not be suitable
for forecasting tasks where predicting covariates would typically be expected
to enhance model accuracy.

摘要：自回归遞迴神經網路廣泛應用於時間序列預測任務，證明了在單變量和某些多變量場景中的有效性。然而，它們的內在結構並未輕易適應未來與時間相關的協變量整合。Salinas 等人在 2019 年概述的建議解決方案，建議在多變量架構中預測協變量和目標變數。在本研究中，我們對公開的時間序列資料集進行了全面的測試，人為地將高度相關的協變量引入未來的時間步長值。我們的評估旨在評估在考慮這些協變量時 LSTM 網路的效能，並將其與單變量基準進行比較。作為本研究的一部分，我們介紹了一種新穎的方法，結合季節性時間區段和 RNN 架構，這在長預測範圍內既簡單又極具效能，且效能可與許多最先進的架構相媲美。我們從超過 120 個模型的結果中發現，在某些條件下，共同訓練協變量和目標變數可以改善模型的整體效能，但多變量和單變量預測之間常常存在顯著的效能差異。令人驚訝的是，即使提供了告知網路有關未來目標值的協變量，多變量預測仍表現出較差的效能。從本質上來說，強迫網路預測多個值可能會損害模型效能，即使在存在有意義的協變量的情況下也是如此。這些結果表明，LSTM 架構可能不適合預測任務，在預測任務中，通常預期預測協變量會提高模型準確度。

##### **SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**
2404.18552v1 by Manos Schinas,Symeon Papadopoulos

The generative AI technology offers an increasing variety of tools for
generating entirely synthetic images that are increasingly indistinguishable
from real ones. Unlike methods that alter portions of an image, the creation of
completely synthetic images presents a unique challenge and several Synthetic
Image Detection (SID) methods have recently appeared to tackle it. Yet, there
is often a large gap between experimental results on benchmark datasets and the
performance of methods in the wild. To better address the evaluation needs of
SID and help close this gap, this paper introduces a benchmarking framework
that integrates several state-of-the-art SID models. Our selection of
integrated models was based on the utilization of varied input features, and
different network architectures, aiming to encompass a broad spectrum of
techniques. The framework leverages recent datasets with a diverse set of
generative models, high level of photo-realism and resolution, reflecting the
rapid improvements in image synthesis technology. Additionally, the framework
enables the study of how image transformations, common in assets shared online,
such as JPEG compression, affect detection performance. SIDBench is available
on https://github.com/mever-team/sidbench and is designed in a modular manner
to enable easy inclusion of new datasets and SID models.

摘要：生成式 AI 技術提供越來越多樣化的工具，用於生成完全合成的影像，這些影像與真實影像越來越難以區分。與改變影像部分的方法不同，完全合成影像的建立提出了獨特的挑戰，最近出現了多種合成影像偵測 (SID) 方法來解決這個問題。然而，基準資料集上的實驗結果與方法在實際應用中的效能之間，常常有很大的差距。為了更好地滿足 SID 的評估需求，並幫助縮小這個差距，本文介紹了一個基準架構，整合了多個最先進的 SID 模型。我們整合模型的選擇，是基於使用不同的輸入特徵和不同的網路架構，旨在涵蓋廣泛的技術。這個架構利用了具有多樣化生成模型、高水準寫實主義和解析度的最新資料集，反映了影像合成技術的快速進步。此外，這個架構可以研究影像轉換（例如 JPEG 壓縮）如何影響偵測效能，而影像轉換在網路上分享的資產中很常見。SIDBench 可在 https://github.com/mever-team/sidbench 取得，並以模組化方式設計，以便輕鬆納入新的資料集和 SID 模型。

##### **Time Machine GPT**
2404.18543v1 by Felix Drinkall,Eghbal Rahimikia,Janet B. Pierrehumbert,Stefan Zohren

Large language models (LLMs) are often trained on extensive, temporally
indiscriminate text corpora, reflecting the lack of datasets with temporal
metadata. This approach is not aligned with the evolving nature of language.
Conventional methods for creating temporally adapted language models often
depend on further pre-training static models on time-specific data. This paper
presents a new approach: a series of point-in-time LLMs called Time Machine GPT
(TiMaGPT), specifically designed to be nonprognosticative. This ensures they
remain uninformed about future factual information and linguistic changes. This
strategy is beneficial for understanding language evolution and is of critical
importance when applying models in dynamic contexts, such as time-series
forecasting, where foresight of future information can prove problematic. We
provide access to both the models and training datasets.

摘要：大型語言模型（LLM）通常在廣泛的、時間上不加區分的文本語料庫上進行訓練，反映了缺乏具有時間元數據的數據集。這種方法與語言演化的本質不符。用於創建時間適應語言模型的傳統方法通常依賴於在特定時間數據上進一步預訓練靜態模型。本文提出了一種新方法：一系列稱為時光機 GPT（TiMaGPT）的特定時間 LLM，專門設計為非預測性的。這確保了它們對未來的實際信息和語言變化保持不知情。這種策略有助於理解語言演化，並且在動態環境中應用模型時至關重要，例如時間序列預測，其中對未來信息的預見可能會帶來問題。我們提供對模型和訓練數據集的訪問權限。

##### **Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**
2404.18539v1 by Chuni Liu,Boyuan Ma,Xiaojuan Ban,Yujie Xie,Hao Wang,Weihua Xue,Jingchao Ma,Ke Xu

Topological consistency plays a crucial role in the task of boundary
segmentation for reticular images, such as cell membrane segmentation in neuron
electron microscopic images, grain boundary segmentation in material
microscopic images and road segmentation in aerial images. In these fields,
topological changes in segmentation results have a serious impact on the
downstream tasks, which can even exceed the misalignment of the boundary
itself. To enhance the topology accuracy in segmentation results, we propose
the Skea-Topo Aware loss, which is a novel loss function that takes into
account the shape of each object and topological significance of the pixels. It
consists of two components. First, the skeleton-aware weighted loss improves
the segmentation accuracy by better modeling the object geometry with
skeletons. Second, a boundary rectified term effectively identifies and
emphasizes topological critical pixels in the prediction errors using both
foreground and background skeletons in the ground truth and predictions.
Experiments prove that our method improves topological consistency by up to 7
points in VI compared to 13 state-of-art methods, based on objective and
subjective assessments across three different boundary segmentation datasets.
The code is available at https://github.com/clovermini/Skea_topo.

摘要：拓撲一致性在網狀影像的邊界分割任務中扮演重要的角色，例如神經元電子顯微影像中的細胞膜分割、材料顯微影像中的晶界分割以及航照影像中的道路分割。在這些領域中，分割結果的拓撲變化對下游任務有嚴重的影響，甚至會超過邊界本身的不對齊。為了提高分割結果的拓撲精度，我們提出 Skea-Topo Aware 損失，這是一種新穎的損失函數，考慮了每個物體的形狀和像素的拓撲意義。它包含兩個組成部分。首先，骨架感知加權損失透過使用骨架更好地建模物體幾何，來提高分割精度。其次，一個邊界校正項有效地識別並強調預測誤差中的拓撲臨界像素，使用真實值和預測中的前景和背景骨架。實驗證明，與 13 種最先進的方法相比，我們的模型在 VI 中將拓撲一致性提高了 7 個百分點，這是基於三個不同的邊界分割資料集的客觀和主觀評估。程式碼可在 https://github.com/clovermini/Skea_topo 取得。

##### **Evaluating and Mitigating Linguistic Discrimination in Large Language Models**
2404.18534v1 by Guoliang Dong,Haoyu Wang,Jun Sun,Xinyu Wang

By training on text in various languages, large language models (LLMs)
typically possess multilingual support and demonstrate remarkable capabilities
in solving tasks described in different languages. However, LLMs can exhibit
linguistic discrimination due to the uneven distribution of training data
across languages. That is, LLMs are hard to keep the consistency of responses
when faced with the same task but depicted in different languages.
  In this study, we first explore the consistency in the LLMs' outputs
responding to queries in various languages from two aspects: safety and
quality. We conduct this analysis with two datasets (AdvBench and NQ) based on
four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results
show that LLMs exhibit stronger human alignment capabilities with queries in
English, French, Russian, and Spanish (only 1.04\% of harmful queries
successfully jailbreak on average) compared to queries in Bengali, Georgian,
Nepali and Maithili (27.7\% of harmful queries jailbreak successfully on
average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs
tend to produce responses with a higher quality (with 0.1494 $F_1$ score on
average) compared to the other languages. Upon these findings, we propose
LDFighter, a similarity-based voting, to mitigate the linguistic discrimination
in LLMs. LDFighter ensures consistent service for different language speakers.
We evaluate LDFighter with both benign queries and harmful queries. The results
show that LDFighter not only significantly reduces the jailbreak success rate
but also improve the response quality on average, demonstrating its
effectiveness.

摘要：<paragraph>透過訓練各種語言的文字，大型語言模型 (LLM)
通常具備多語言支援，並展現出解決以不同語言描述任務的卓越能力。然而，LLM 可能會因訓練資料在不同語言間分佈不均而出現語言歧視。也就是說，LLM 在面對相同任務，但以不同語言描述時，難以維持回應的一致性。
在本研究中，我們首先從安全性和品質兩個面向探討 LLM 回應不同語言查詢時輸出的相容性。我們使用四個 LLM (Llama2-13b、Gemma-7b、GPT-3.5-turbo 和 Gemini-pro) 基於兩個資料集 (AdvBench 和 NQ) 進行此分析。結果顯示，LLM 對英語、法語、俄語和西班牙語查詢展現出更強的人類對齊能力（平均只有 1.04% 的有害查詢成功逃獄），相較於孟加拉語、喬治亞語、尼泊爾語和邁蒂利語（平均有 27.7% 的有害查詢成功逃獄）。此外，對於英語、丹麥語、捷克語和斯洛維尼亞語查詢，LLM 傾向產生品質較高的回應（平均 F1 分數為 0.1494），相較於其他語言。根據這些發現，我們提出基於相似性的投票機制 LDFighter，以減輕 LLM 中的語言歧視。LDFighter 確保對不同語言使用者提供一致的服務。我們使用良性查詢和有害查詢評估 LDFighter。結果顯示，LDFighter 不僅顯著降低逃獄成功率，也平均改善了回應品質，證明其有效性。</paragraph>

##### **Evaluating Concept-based Explanations of Language Models: A Study on Faithfulness and Readability**
2404.18533v2 by Meng Li,Haoran Jin,Ruixuan Huang,Zhihao Xu,Defu Lian,Zijia Lin,Di Zhang,Xiting Wang

Despite the surprisingly high intelligence exhibited by Large Language Models
(LLMs), we are somehow intimidated to fully deploy them into real-life
applications considering their black-box nature. Concept-based explanations
arise as a promising avenue for explaining what the LLMs have learned, making
them more transparent to humans. However, current evaluations for concepts tend
to be heuristic and non-deterministic, e.g. case study or human evaluation,
hindering the development of the field. To bridge the gap, we approach
concept-based explanation evaluation via faithfulness and readability. We first
introduce a formal definition of concept generalizable to diverse concept-based
explanations. Based on this, we quantify faithfulness via the difference in the
output upon perturbation. We then provide an automatic measure for readability,
by measuring the coherence of patterns that maximally activate a concept. This
measure serves as a cost-effective and reliable substitute for human
evaluation. Finally, based on measurement theory, we describe a meta-evaluation
method for evaluating the above measures via reliability and validity, which
can be generalized to other tasks as well. Extensive experimental analysis has
been conducted to validate and inform the selection of concept evaluation
measures.

摘要：儘管大型語言模型 (LLM) 展現出驚人的高智慧，但我們在將它們全面部署到實際應用中時，仍會因其黑箱性質而感到有些恐懼。基於概念的解釋作為一種有前途的方法，能說明 LLM 學到了什麼，讓它們對人類來說更透明。然而，目前對概念的評估往往是啟發式的且非確定性的，例如案例研究或人工評估，這阻礙了該領域的發展。為了彌補這一差距，我們透過保真度和可讀性來評估基於概念的解釋。我們首先對可概括至各種基於概念的解釋的概念提出正式定義。基於此，我們透過擾動後的輸出差異來量化保真度。接著，我們透過測量最大程度激發概念的模式的相干性，提供可讀性的自動化測量。此測量值可用作人工評估的經濟實惠且可靠的替代方案。最後，基於測量理論，我們描述一種透過信度和效度評估上述測量值的元評估方法，此方法也可概括至其他任務。已進行廣泛的實驗分析，以驗證和說明概念評估測量值的選擇。

##### **MileBench: Benchmarking MLLMs in Long Context**
2404.18532v1 by Dingjie Song,Shunian Chen,Guiming Hardy Chen,Fei Yu,Xiang Wan,Benyou Wang

Despite the advancements and impressive performance of Multimodal Large
Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
long-context, and multi-image tasks is unclear due to the benchmarks' limited
scope. Existing benchmarks often focus on single-image and short-text samples,
and when assessing multi-image tasks, they either limit the image count or
focus on specific task (e.g time-series captioning), potentially obscuring the
performance challenges of MLLMs. To address these limitations, we introduce
MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
capabilities of MLLMs. This benchmark comprises not only multimodal long
contexts, but also multiple tasks requiring both comprehension and generation.
We establish two distinct evaluation sets, diagnostic and realistic, to
systematically assess MLLMs' long-context adaptation capacity and their ability
to complete tasks in long-context scenarios. Our experimental results, obtained
from testing 20 models, revealed that while the closed-source GPT-4(Vision) and
Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context
situations. Interestingly, the performance gap tends to widen with an increase
in the number of images. We strongly encourage an intensification of research
efforts towards enhancing MLLMs' long-context capabilities, especially in
scenarios involving multiple images.

摘要：儘管多模態大型語言模型 (MLLM) 在基準上取得進展並有令人印象深刻的表現，但由於基準的範圍有限，它們在現實世界、長語境和多圖像任務中的有效性仍不清楚。現有的基準通常側重於單一圖像和短文字範本，並且在評估多圖像任務時，它們會限制圖像數量或專注於特定任務（例如時間序列字幕），這可能會模糊 MLLM 的效能挑戰。為了解決這些限制，我們引入了 MileBench，這是一個先驅基準，旨在測試 MLLM 的多模態長語境能力。此基準不僅包含多模態長語境，還包含需要理解和生成的各種任務。我們建立了兩個不同的評估集，診斷性和現實性，以系統性地評估 MLLM 的長語境適應能力及其在長語境場景中完成任務的能力。我們從測試 20 個模型中獲得的實驗結果顯示，雖然閉源的 GPT-4(Vision) 和 Gemini 1.5 優於其他模型，但大多數開源 MLLM 在長語境情況下都難以應付。有趣的是，效能差距會隨著圖像數量的增加而擴大。我們強烈鼓勵加強研究工作，以增強 MLLM 的長語境能力，特別是在涉及多張圖像的場景中。

##### **A Framework to Model ML Engineering Processes**
2404.18531v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The development of Machine Learning (ML) based systems is complex and
requires multidisciplinary teams with diverse skill sets. This may lead to
communication issues or misapplication of best practices. Process models can
alleviate these challenges by standardizing task orchestration, providing a
common language to facilitate communication, and nurturing a collaborative
environment. Unfortunately, current process modeling languages are not suitable
for describing the development of such systems. In this paper, we introduce a
framework for modeling ML-based software development processes, built around a
domain-specific language and derived from an analysis of scientific and gray
literature. A supporting toolkit is also available.

摘要：機器學習 (ML) 為基礎的系統開發複雜，需要具備多元技能的多元學科團隊。這可能會導致溝通問題或最佳實務的誤用。流程模型可透過標準化任務編排、提供促進溝通的共同語言，以及培育協作環境來緩解這些挑戰。不幸的是，當前的流程建模語言並不適合用來描述此類系統的開發。在本文中，我們將介紹一個建模 ML 為基礎的軟體開發流程的架構，此架構建立於特定領域的語言，並衍生自科學和灰色文獻的分析。同時也提供一個支援工具包。

##### **Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**
2404.18527v1 by Weike Peng,Jiaxin Gao,Yuntian Chen,Shengwei Wang

Machine learning algorithms emerge as a promising approach in energy fields,
but its practical is hindered by data barriers, stemming from high collection
costs and privacy concerns. This study introduces a novel federated learning
(FL) framework based on XGBoost models, enabling safe collaborative modeling
with accessible yet concealed data from multiple parties. Hyperparameter tuning
of the models is achieved through Bayesian Optimization. To ascertain the
merits of the proposed FL-XGBoost method, a comparative analysis is conducted
between separate and centralized models to address a classical binary
classification problem in geoenergy sector. The results reveal that the
proposed FL framework strikes an optimal balance between privacy and accuracy.
FL models demonstrate superior accuracy and generalization capabilities
compared to separate models, particularly for participants with limited data or
low correlation features and offers significant privacy benefits compared to
centralized model. The aggregated optimization approach within the FL agreement
proves effective in tuning hyperparameters. This study opens new avenues for
assessing unconventional reservoirs through collaborative and
privacy-preserving FL techniques.

摘要：機器學習演算法在能源領域中浮現為一種有前景的方法，
但其實務受限於資料障礙，源自於高昂的收集成本和隱私疑慮。本研究介紹一種基於 XGBoost 模型的新型聯邦學習 (FL) 架構，讓多方能透過可存取但隱藏的資料進行安全的協作建模。模型的超參數調整是透過貝氏最佳化來達成。為了確定所提議的 FL-XGBoost 方法的優點，在個別和集中式模型之間進行比較分析，以解決地熱能領域中的經典二元分類問題。結果顯示，所提議的 FL 架構在隱私和準確性之間取得最佳平衡。與個別模型相比，FL 模型展現出優異的準確性和泛化能力，特別是對於資料有限或低關聯性特徵的參與者，而且與集中式模型相比，它提供了顯著的隱私優勢。FL 協議中的聚合最佳化方法證明在調整超參數方面有效。本研究為透過協作和保護隱私的 FL 技術評估非常規儲層開啟了新途徑。

##### **On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**
2404.18519v1 by Usevalad Milasheuski. Luca Barbieri,Bernardo Camajori Tedeschini,Monica Nicoli,Stefano Savazzi

Federated Learning (FL) allows multiple privacy-sensitive applications to
leverage their dataset for a global model construction without any disclosure
of the information. One of those domains is healthcare, where groups of silos
collaborate in order to generate a global predictor with improved accuracy and
generalization. However, the inherent challenge lies in the high heterogeneity
of medical data, necessitating sophisticated techniques for assessment and
compensation. This paper presents a comprehensive exploration of the
mathematical formalization and taxonomy of heterogeneity within FL
environments, focusing on the intricacies of medical data. In particular, we
address the evaluation and comparison of the most popular FL algorithms with
respect to their ability to cope with quantity-based, feature and label
distribution-based heterogeneity. The goal is to provide a quantitative
evaluation of the impact of data heterogeneity in FL systems for healthcare
networks as well as a guideline on FL algorithm selection. Our research extends
beyond existing studies by benchmarking seven of the most common FL algorithms
against the unique challenges posed by medical data use cases. The paper
targets the prediction of the risk of stroke recurrence through a set of
tabular clinical reports collected by different federated hospital silos: data
heterogeneity frequently encountered in this scenario and its impact on FL
performance are discussed.

摘要：聯合式學習 (FL) 允許多個注重隱私的應用程式利用其資料集來建構全球模型，而無需揭露任何資訊。其中一個領域是醫療保健，其中孤島群組會進行協作，以產生具有改良準確度和概括性的全球預測器。然而，內在挑戰在於醫療資料的高度異質性，這需要採用複雜的技術來進行評估和補償。本文對 FL 環境中的異質性進行全面的探討，並對其數學形式化和分類進行探討，重點在於醫療資料的複雜性。特別是，我們針對最受歡迎的 FL 演算法進行評估和比較，以了解其因應基於數量、特徵和標籤分佈的異質性的能力。目標是針對 FL 系統在醫療保健網路中的資料異質性影響提供量化評估，以及 FL 演算法選擇的指南。我們的研究延伸到現有研究，針對醫療資料使用案例所帶來的獨特挑戰，對七種最常見的 FL 演算法進行基準測試。本文目標是透過一組由不同聯合醫院孤島收集的表格臨床報告，來預測中風復發風險：此情境中經常遇到的資料異質性及其對 FL 效能的影響會在本文中進行探討。

##### **From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**
2404.18518v1 by Jiangfeng Liu,Ziyi Wang,Jing Xie,Lei Pei

Generative large-scale language models create the fifth paradigm of
scientific research, organically combine data science and computational
intelligence, transform the research paradigm of natural language processing
and multimodal information processing, promote the new trend of AI-enabled
social science research, and provide new ideas for digital humanities research
and application. This article profoundly explores the application of
large-scale language models in digital humanities research, revealing their
significant potential in ancient book protection, intelligent processing, and
academic innovation. The article first outlines the importance of ancient book
resources and the necessity of digital preservation, followed by a detailed
introduction to developing large-scale language models, such as ChatGPT, and
their applications in document management, content understanding, and
cross-cultural research. Through specific cases, the article demonstrates how
AI can assist in the organization, classification, and content generation of
ancient books. Then, it explores the prospects of AI applications in artistic
innovation and cultural heritage preservation. Finally, the article explores
the challenges and opportunities in the interaction of technology, information,
and society in the digital humanities triggered by AI technologies.

摘要：生成式大規模語言模型創造了科學研究的第五個範式，有機地結合了數據科學和計算智能，轉變了自然語言處理和多模態資訊處理的研究範式，推動了人工智能賦能社會科學研究的新趨勢，並為數位人文研究和應用提供了新思路。本文深入探討了大規模語言模型在數位人文研究中的應用，揭示了其在古籍保護、智慧處理和學術創新方面的巨大潛力。文章首先闡述了古籍資源的重要性以及數位保存的必要性，接著詳細介紹了 ChatGPT 等大規模語言模型的發展及其在文件管理、內容理解和跨文化研究中的應用。文章通過具體案例展示了人工智能如何協助古籍的整理、分類和內容生成。然後探討了人工智能在藝術創新和文化遺產保護中的應用前景。最後，文章探討了人工智能技術引發的數位人文領域中技術、資訊和社會互動的挑戰和機遇。

##### **Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**
2404.18510v1 by Dana Roemling,Yves Scherrer,Aleksandra Miletic

Forensic authorship profiling uses linguistic markers to infer
characteristics about an author of a text. This task is paralleled in dialect
classification, where a prediction is made about the linguistic variety of a
text based on the text itself. While there have been significant advances in
the last years in variety classification (Jauhiainen et al., 2019) and
state-of-the-art approaches reach accuracies of up to 100% depending on the
similarity of varieties and the scope of prediction (e.g., Milne et al., 2012;
Blodgett et al., 2017), forensic linguistics rarely relies on these approaches
due to their lack of transparency (see Nini, 2023), amongst other reasons. In
this paper we therefore explore explainability of machine learning approaches
considering the forensic context. We focus on variety classification as a means
of geolinguistic profiling of unknown texts. For this we work with an approach
proposed by Xie et al. (2024) to extract the lexical items most relevant to the
variety classifications. We find that the extracted lexical features are indeed
representative of their respective varieties and note that the trained models
also rely on place names for classifications.

摘要：法醫作者側寫使用語言標記來推斷文本作者的特徵。此任務與方言分類類似，其中根據文本本身對文本的語言變體進行預測。儘管近年來方言分類（Jauhiainen 等人，2019 年）取得了重大進展，並且最先進的方法根據變體的相似性和預測範圍（例如 Milne 等人，2012 年；Blodgett 等人，2017 年）達到了高達 100% 的準確率，但法醫語言學由於缺乏透明度（見 Nini，2023 年）等原因，很少依賴這些方法。因此，在本文中，我們探討了考慮法醫背景的機器學習方法的可解釋性。我們專注於方言分類作為未知文本的地理語言側寫手段。為此，我們採用 Xie 等人（2024 年）提出的方法來提取與方言分類最相關的詞彙項目。我們發現提取的詞彙特徵確實代表了它們各自的變體，並注意到訓練後的模型在分類中也依賴於地名。

##### **Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**
2404.18508v1 by Mark Schöne,Neeraj Mohan Sushma,Jingyue Zhuge,Christian Mayr,Anand Subramoney,David Kappel

Event-based sensors are well suited for real-time processing due to their
fast response times and encoding of the sensory data as successive temporal
differences. These and other valuable properties, such as a high dynamic range,
are suppressed when the data is converted to a frame-based format. However,
most current methods either collapse events into frames or cannot scale up when
processing the event data directly event-by-event. In this work, we address the
key challenges of scaling up event-by-event modeling of the long event streams
emitted by such sensors, which is a particularly relevant problem for
neuromorphic computing. While prior methods can process up to a few thousand
time steps, our model, based on modern recurrent deep state-space models,
scales to event streams of millions of events for both training and
inference.We leverage their stable parameterization for learning long-range
dependencies, parallelizability along the sequence dimension, and their ability
to integrate asynchronous events effectively to scale them up to long event
streams.We further augment these with novel event-centric techniques enabling
our model to match or beat the state-of-the-art performance on several event
stream benchmarks. In the Spiking Speech Commands task, we improve
state-of-the-art by a large margin of 6.6% to 87.1%. On the DVS128-Gestures
dataset, we achieve competitive results without using frames or convolutional
neural networks. Our work demonstrates, for the first time, that it is possible
to use fully event-based processing with purely recurrent networks to achieve
state-of-the-art task performance in several event-based benchmarks.

摘要：<paragraph>由於事件驅動感測器的快速反應時間，以及將感測資料編碼為連續時間差，因此非常適合用於即時處理。當資料轉換成基於幀的格式時，這些有價值的特性（例如高動態範圍）會被抑制。然而，目前大多數方法會將事件壓縮成幀，或者在直接逐事件處理事件資料時無法擴充。在這項工作中，我們解決了逐事件擴充事件串流建模的主要挑戰，這些串流由此類感測器發射，這對神經形態運算來說是一個特別相關的問題。雖然先前的做法可以處理數千個時間步驟，但我們的模型基於現代遞迴深度狀態空間模型，可以擴充到數百萬個事件的事件串流，用於訓練和推論。我們利用其穩定的參數化來學習長程依賴關係、序列維度的平行化，以及整合非同步事件的能力，有效地將其擴充到長事件串流。我們進一步使用新穎的以事件為中心的技術來擴充這些技術，使我們的模型能夠在多個事件串流基準測試中匹配或超越最先進的效能。在 Spiking Speech Commands 任務中，我們將最先進的技術大幅提升了 6.6%，達到 87.1%。在 DVS128-Gestures 資料集上，我們在不使用幀或卷積神經網路的情況下，達到了有競爭力的結果。我們的研究首次證明，可以使用純遞迴網路進行完全基於事件的處理，在多個基於事件的基準測試中實現最先進的任務效能。</paragraph>

##### **ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**
2404.18470v1 by Yupeng Cao,Zhi Chen,Qingyun Pei,Prashant Kumar,K. P. Subbalakshmi,Papa Momar Ndiaye

In the realm of financial analytics, leveraging unstructured data, such as
earnings conference calls (ECCs), to forecast stock performance is a critical
challenge that has attracted both academics and investors. While previous
studies have used deep learning-based models to obtain a general view of ECCs,
they often fail to capture detailed, complex information. Our study introduces
a novel framework: \textbf{ECC Analyzer}, combining Large Language Models
(LLMs) and multi-modal techniques to extract richer, more predictive insights.
The model begins by summarizing the transcript's structure and analyzing the
speakers' mode and confidence level by detecting variations in tone and pitch
for audio. This analysis helps investors form an overview perception of the
ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based
methods to meticulously extract the focuses that have a significant impact on
stock performance from an expert's perspective, providing a more targeted
analysis. The model goes a step further by enriching these extracted focuses
with additional layers of analysis, such as sentiment and audio segment
features. By integrating these insights, the ECC Analyzer performs multi-task
predictions of stock performance, including volatility, value-at-risk (VaR),
and return for different intervals. The results show that our model outperforms
traditional analytic benchmarks, confirming the effectiveness of using advanced
LLM techniques in financial analytics.

摘要：<paragraph>在金融分析领域，利用非结构化数据（例如收益电话会议 (ECC)）来预测股票表现是一项关键挑战，它吸引了学术界和投资者的关注。虽然以前的研究已经使用基于深度学习的模型来获得 ECC 的一般视图，但它们常常无法捕捉到详细、复杂的信息。我们的研究引入了一个新框架：**ECC 分析器**，它结合了大型语言模型 (LLM) 和多模态技术来提取更丰富、更具预测性的见解。该模型首先总结成绩单的结构，并通过检测音频中的音调和音高变化来分析说话者的模式和信心水平。此分析有助于投资者形成对 ECC 的概览感知。此外，此模型使用基于检索增强生成 (RAG) 的方法，从专家的角度细致地提取对股票表现有重大影响的重点，从而提供更有针对性的分析。该模型通过用额外的分析层（例如情绪和音频片段特征）来丰富这些提取的重点，从而更进一步。通过整合这些见解，ECC 分析器对股票表现进行多任务预测，包括波动性、风险价值 (VaR) 以及不同间隔的回报。结果表明，我们的模型优于传统的分析基准，证实了在金融分析中使用高级 LLM 技术的有效性。</paragraph>

##### **HFT: Half Fine-Tuning for Large Language Models**
2404.18466v1 by Tingfeng Hui,Zhenyu Zhang,Shuohuan Wang,Weiran Xu,Yu Sun,Hua Wu

Large language models (LLMs) with one or more fine-tuning phases have become
a necessary step to unlock various capabilities, enabling LLMs to follow
natural language instructions or align with human preferences. However, it
carries the risk of catastrophic forgetting during sequential training, the
parametric knowledge or the ability learned in previous stages may be
overwhelmed by incoming training data. In this paper, we find that by regularly
resetting partial parameters, LLMs can restore some of the original knowledge.
Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute
for full fine-tuning (FFT), to mitigate the forgetting issues, where half of
the parameters are selected to learn new tasks while the other half are frozen
to remain previous knowledge. We provide a feasibility analysis from the
perspective of optimization and interpret the parameter selection operation as
a regularization term. Without changing the model architecture, HFT could be
seamlessly integrated into existing fine-tuning frameworks. Extensive
experiments and analysis on supervised fine-tuning, direct preference
optimization, and continual learning consistently demonstrate the
effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not
only significantly alleviates the forgetting problem, but also achieves the
best performance in a series of downstream benchmarks, with an approximately
30% reduction in training time.

摘要：大型語言模型 (LLM) 經過一個或多個微調階段已成為解鎖各種功能的必要步驟，使 LLM 能夠遵循自然語言指令或與人類偏好保持一致。然而，它在順序訓練期間會帶來災難性遺忘的風險，在先前階段中學習到的參數知識或能力可能會被輸入的訓練資料淹沒。在本文中，我們發現通過定期重置部分參數，LLM 可以恢復一些原始知識。受此啟發，我們為 LLM 引入了半微調 (HFT)，作為完全微調 (FFT) 的替代方案，以減輕遺忘問題，其中一半參數被選中學習新任務，而另一半被凍結以保留先前的知識。我們從優化的角度提供了可行性分析，並將參數選擇操作解釋為正則化項。在不改變模型架構的情況下，HFT 可以無縫整合到現有的微調框架中。對監督式微調、直接偏好優化和持續學習的廣泛實驗和分析一致地證明了 HFT 的有效性、穩健性和效率。與 FFT 相比，HFT 不僅顯著緩解了遺忘問題，而且在系列下游基準測試中取得了最佳性能，訓練時間減少了大約 30%。

##### **M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**
2404.18465v1 by Zijian Zhang,Shuchang Liu,Jiaao Yu,Qingpeng Cai,Xiangyu Zhao,Chunxu Zhang,Ziru Liu,Qidong Liu,Hongwei Zhao,Lantao Hu,Peng Jiang,Kun Gai

Multi-domain recommendation and multi-task recommendation have demonstrated
their effectiveness in leveraging common information from different domains and
objectives for comprehensive user modeling. Nonetheless, the practical
recommendation usually faces multiple domains and tasks simultaneously, which
cannot be well-addressed by current methods. To this end, we introduce M3oE, an
adaptive multi-domain multi-task mixture-of-experts recommendation framework.
M3oE integrates multi-domain information, maps knowledge across domains and
tasks, and optimizes multiple objectives. We leverage three mixture-of-experts
modules to learn common, domain-aspect, and task-aspect user preferences
respectively to address the complex dependencies among multiple domains and
tasks in a disentangled manner. Additionally, we design a two-level fusion
mechanism for precise control over feature extraction and fusion across diverse
domains and tasks. The framework's adaptability is further enhanced by applying
AutoML technique, which allows dynamic structure optimization. To the best of
the authors' knowledge, our M3oE is the first effort to solve multi-domain
multi-task recommendation self-adaptively. Extensive experiments on two
benchmark datasets against diverse baselines demonstrate M3oE's superior
performance. The implementation code is available to ensure reproducibility.

摘要：多領域推薦和多任務推薦已證明其在利用來自不同領域和目標的共同資訊以進行全面使用者建模方面的有效性。儘管如此，實務上的推薦通常同時面臨多個領域和任務，而這無法透過目前的方法妥善解決。為此，我們引入了 M3oE，一個自適應的多領域多任務混合專家推薦架構。M3oE 整合了多領域資訊，跨領域和任務對知識進行對應，並最佳化多重目標。我們利用三個混合專家模組分別學習共同的、領域面向的和任務面向的使用者偏好，以解開多個領域和任務之間的複雜依存關係。此外，我們設計了一個兩層融合機制，以精準控制跨越不同領域和任務的功能萃取和融合。透過應用 AutoML 技術，進一步強化了架構的自適應能力，允許動態結構最佳化。根據作者的了解，我們的 M3oE 是第一個自適應解決多領域多任務推薦的嘗試。針對兩個基準資料集進行的大量實驗，與各種基線相比，證明了 M3oE 的優異效能。實作程式碼可用，以確保可重製性。

##### **Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**
2404.18460v1 by Utkarsh Agarwal,Kumar Tanmay,Aditi Khandelwal,Monojit Choudhury

Ethical reasoning is a crucial skill for Large Language Models (LLMs).
However, moral values are not universal, but rather influenced by language and
culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and
Llama2-70B-Chat -- perform ethical reasoning in different languages and if
their moral judgement depend on the language in which they are prompted. We
extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a
multilingual setup following their framework of probing LLMs with ethical
dilemmas and policies from three branches of normative ethics: deontology,
virtue, and consequentialism. We experiment with six languages: English,
Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most
consistent and unbiased ethical reasoner across languages, while ChatGPT and
Llama2-70B-Chat show significant moral value bias when we move to languages
other than English. Interestingly, the nature of this bias significantly vary
across languages for all LLMs, including GPT-4.

摘要：倫理推理是大語言模型 (LLM) 的一項關鍵技能。
然而，道德價值觀並非普遍，而是受語言和
文化影響。本文探討了三個著名的 LLM -- GPT-4、ChatGPT 和
Llama2-70B-Chat -- 如何在不同的語言中進行倫理推理，以及它們的道德判斷是否取決於提示它們的語言。我們擴展了 Rao 等人 (2023) 對 LLM 的倫理推理研究，採用他們的探測框架，使用來自規範倫理學三個分支的倫理困境和政策對 LLM 進行探測：義務論、美德論和後果論。我們使用六種語言進行實驗：英語、
西班牙語、俄語、中文、印地語和斯瓦希里語。我們發現 GPT-4 是跨語言最一致、最公正的倫理推理者，而 ChatGPT 和 Llama2-70B-Chat 在我們轉向英語以外的語言時表現出顯著的道德價值觀偏差。有趣的是，這種偏差的性質對於所有 LLM，包括 GPT-4，在不同語言中差異很大。

##### **U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**
2404.18444v1 by Song Mei

U-Nets are among the most widely used architectures in computer vision,
renowned for their exceptional performance in applications such as image
segmentation, denoising, and diffusion modeling. However, a theoretical
explanation of the U-Net architecture design has not yet been fully
established.
  This paper introduces a novel interpretation of the U-Net architecture by
studying certain generative hierarchical models, which are tree-structured
graphical models extensively utilized in both language and image domains. With
their encoder-decoder structure, long skip connections, and pooling and
up-sampling layers, we demonstrate how U-Nets can naturally implement the
belief propagation denoising algorithm in such generative hierarchical models,
thereby efficiently approximating the denoising functions. This leads to an
efficient sample complexity bound for learning the denoising function using
U-Nets within these models. Additionally, we discuss the broader implications
of these findings for diffusion models in generative hierarchical models. We
also demonstrate that the conventional architecture of convolutional neural
networks (ConvNets) is ideally suited for classification tasks within these
models. This offers a unified view of the roles of ConvNets and U-Nets,
highlighting the versatility of generative hierarchical models in modeling
complex data distributions across language and image domains.

摘要：U-Net 是電腦視覺中最廣泛使用的架構之一，
以其在影像分割、去噪和擴散模型等應用中表現出色而聞名。然而，對於 U-Net 架構設計的理論解釋尚未完全建立。
本文透過研究某些生成階層模型，提出對 U-Net 架構的新穎詮釋，這些模型是廣泛用於語言和影像領域的樹狀結構圖形模型。透過其編碼器-解碼器結構、長跳躍連接，以及池化和上採樣層，我們展示了 U-Net 如何在這些生成階層模型中自然地實作信念傳播去噪演算法，從而有效逼近去噪函數。這導致了在這些模型中使用 U-Net 學習去噪函數的有效樣本複雜度界限。此外，我們討論了這些發現對生成階層模型中擴散模型的更廣泛影響。我們還展示了卷積神經網路 (ConvNet) 的傳統架構非常適合這些模型中的分類任務。這提供了一個統一的觀點來看待 ConvNet 和 U-Net 的角色，突顯了生成階層模型在語言和影像領域中對複雜資料分佈建模的多功能性。

##### **BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**
2404.18443v1 by Ran Xu,Wenqi Shi,Yue Yu,Yuchen Zhuang,Yanqiao Zhu,May D. Wang,Joyce C. Ho,Chao Zhang,Carl Yang

Developing effective biomedical retrieval models is important for excelling
at knowledge-intensive biomedical tasks but still challenging due to the
deficiency of sufficient publicly annotated biomedical data and computational
resources. We present BMRetriever, a series of dense retrievers for enhancing
biomedical retrieval via unsupervised pre-training on large biomedical corpora,
followed by instruction fine-tuning on a combination of labeled datasets and
synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify
BMRetriever's efficacy on various biomedical applications. BMRetriever also
exhibits strong parameter efficiency, with the 410M variant outperforming
baselines up to 11.7 times larger, and the 2B variant matching the performance
of models with over 5B parameters. The training data and model checkpoints are
released at \url{https://huggingface.co/BMRetriever} to ensure transparency,
reproducibility, and application to new domains.

摘要：開發有效的生物醫學檢索模型對於在知識密集型生物醫學任務中表現出色非常重要，但由於缺乏足夠的公開標註生物醫學數據和計算資源，這仍然具有挑戰性。我們提出了 BMRetriever，這是一系列用於通過在大型生物醫學語料庫上進行無監督預訓練來增強生物醫學檢索的密集檢索器，然後在標籤數據集和合成對的組合上進行指令微調。在 11 個數據集上的 5 個生物醫學任務上的實驗驗證了 BMRetriever 在各種生物醫學應用中的功效。BMRetriever 還表現出強大的參數效率，其中 410M 變體的效能比基線高出 11.7 倍，而 2B 變體則與超過 5B 參數的模型的效能相匹配。訓練數據和模型檢查點在 \url{https://huggingface.co/BMRetriever} 發布，以確保透明度、可複製性和對新領域的應用。

##### **Unsupervised Dynamics Prediction with Object-Centric Kinematics**
2404.18423v1 by Yeon-Ji Song,Suhyung Choi,Jaein Kim,Jin-Hwa Kim,Byoung-Tak Zhang

Human perception involves discerning complex multi-object scenes into
time-static object appearance (\ie, size, shape, color) and time-varying object
motion (\ie, location, velocity, acceleration). This innate ability to
unconsciously understand the environment is the motivation behind the success
of dynamics modeling. Object-centric representations have emerged as a
promising tool for dynamics prediction, yet they primarily focus on the
objects' appearance, often overlooking other crucial attributes. In this paper,
we propose Object-Centric Kinematics (OCK), a framework for dynamics prediction
leveraging object-centric representations. Our model utilizes a novel component
named object kinematics, which comprises low-level structured states of
objects' position, velocity, and acceleration. The object kinematics are
obtained via either implicit or explicit approaches, enabling comprehensive
spatiotemporal object reasoning, and integrated through various transformer
mechanisms, facilitating effective object-centric dynamics modeling. Our model
demonstrates superior performance when handling objects and backgrounds in
complex scenes characterized by a wide range of object attributes and dynamic
movements. Moreover, our model demonstrates generalization capabilities across
diverse synthetic environments, highlighting its potential for broad
applicability in vision-related tasks.

摘要：人類感知涉及將複雜的多物件場景辨別為時間靜態物件外觀（即大小、形狀、顏色）和時間變異物件運動（即位置、速度、加速度）。這種無意識理解環境的本能能力是動力學建模成功的背後動機。以物件為中心的表示已成為動力學預測的有前途工具，但它們主要關注物件的外觀，常常忽略其他關鍵屬性。在本文中，我們提出以物件為中心的運動學 (OCK)，一個利用以物件為中心的表示進行動力學預測的框架。我們的模型利用一個名為物件運動學的新元件，它包含物件位置、速度和加速度的低階結構狀態。物件運動學是透過內隱或外顯方法取得，能進行全面的時空物件推理，並透過各種轉換機制整合，促進有效的以物件為中心的動力學建模。我們的模型在處理複雜場景中的物件和背景時表現出優異的效能，這些場景的特徵是具有廣泛的物件屬性和動態運動。此外，我們的模型展示了在不同合成環境中的泛化能力，突顯其在與視覺相關任務中廣泛應用的潛力。

##### **Capabilities of Gemini Models in Medicine**
2404.18416v1 by Khaled Saab,Tao Tu,Wei-Hung Weng,Ryutaro Tanno,David Stutz,Ellery Wulczyn,Fan Zhang,Tim Strother,Chunjong Park,Elahe Vedadi,Juanma Zambrano Chaves,Szu-Yeu Hu,Mike Schaekermann,Aishwarya Kamath,Yong Cheng,David G. T. Barrett,Cathy Cheung,Basil Mustafa,Anil Palepu,Daniel McDuff,Le Hou,Tomer Golany,Luyang Liu,Jean-baptiste Alayrac,Neil Houlsby,Nenad Tomasev,Jan Freyberg,Charles Lau,Jonas Kemp,Jeremy Lai,Shekoofeh Azizi,Kimberly Kanada,SiWai Man,Kavita Kulkarni,Ruoxi Sun,Siamak Shakeri,Luheng He,Ben Caine,Albert Webson,Natasha Latysheva,Melvin Johnson,Philip Mansfield,Jian Lu,Ehud Rivlin,Jesper Anderson,Bradley Green,Renee Wong,Jonathan Krause,Jonathon Shlens,Ewa Dominowska,S. M. Ali Eslami,Claire Cui,Oriol Vinyals,Koray Kavukcuoglu,James Manyika,Jeff Dean,Demis Hassabis,Yossi Matias,Dale Webster,Joelle Barral,Greg Corrado,Christopher Semturs,S. Sara Mahdavi,Juraj Gottweis,Alan Karthikesalingam,Vivek Natarajan

Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.

摘要：<paragraph>在各種醫療應用中追求卓越對 AI 來說構成相當大的挑戰，需要進階推理、取得最新醫療知識，以及理解複雜的多模態資料。Gemini 模型具備強大的多模態和長文脈推理一般能力，在醫學領域提供令人興奮的可能性。在 Gemini 的這些核心優勢基礎上，我們推出 Med-Gemini，一個專精於醫學的高度強大多模態模型系列，具備無縫使用網路搜尋的能力，並能使用自訂編碼器有效調整為新模態。我們在 14 個醫療基準上評估 Med-Gemini，在其中 10 個基準上建立新的最先進 (SoTA) 效能，並在每個可進行直接比較的基準上超越 GPT-4 模型系列，往往差距甚大。在熱門的 MedQA (USMLE) 基準上，我們效能表現最佳的 Med-Gemini 模型使用新穎的不確定性引導搜尋策略，達成 91.1% 精確度的 SoTA 效能。在 7 個多模態基準上，包括 NEJM 影像挑戰和 MMMU（健康與醫學），Med-Gemini 比 GPT-4V 提升了平均相對邊際 44.5%。我們透過在從去識別化長篇健康記錄和醫學影片問答中搜尋針頭的 SoTA 效能，證明了 Med-Gemini 的長文脈能力的有效性，超越了僅使用文內學習的先前客製化方法。最後，Med-Gemini 的效能顯示出真實世界的效用，在醫療文字摘要等任務上超越人類專家，同時也展現出多模態醫療對話、醫學研究和教育的潛力。綜上所述，我們的結果提供了 Med-Gemini 潛力的有力證據，儘管在這個安全至上的領域進行實際部署之前，進一步的嚴謹評估將至關重要。</paragraph>

##### **3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**
2404.18413v1 by Xinyu Ma,Xuebo Liu,Derek F. Wong,Jun Rao,Bei Li,Liang Ding,Lidia S. Chao,Dacheng Tao,Min Zhang

Multimodal machine translation (MMT) is a challenging task that seeks to
improve translation quality by incorporating visual information. However,
recent studies have indicated that the visual information provided by existing
MMT datasets is insufficient, causing models to disregard it and overestimate
their capabilities. This issue presents a significant obstacle to the
development of MMT research. This paper presents a novel solution to this issue
by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel
sentence pairs in English and Chinese, each with corresponding images. Our
dataset is specifically designed to include more ambiguity and a greater
variety of both captions and images than other MMT datasets. We utilize a word
sense disambiguation model to select ambiguous data from vision-and-language
datasets, resulting in a more challenging dataset. We further benchmark several
state-of-the-art MMT models on our proposed dataset. Experimental results show
that MMT models trained on our dataset exhibit a greater ability to exploit
visual information than those trained on other MMT datasets. Our work provides
a valuable resource for researchers in the field of multimodal learning and
encourages further exploration in this area. The data, code and scripts are
freely available at https://github.com/MaxyLee/3AM.

摘要：多模態機器翻譯 (MMT) 是一項具有挑戰性的任務，旨在通過納入視覺資訊來提升翻譯品質。然而，最近的研究指出，現有 MMT 資料集提供的視覺資訊不足，導致模型忽略視覺資訊並高估其功能。這個問題對 MMT 研究的發展造成重大的阻礙。本文提出一個創新的解決方案來解決這個問題，引入了 3AM，一個包含 26,000 對英文和中文平行句子的含糊感知 MMT 資料集，每個句子都搭配對應的圖片。我們的資料集特別設計為包含更多含糊性和更多元的標題和圖片，勝過其他 MMT 資料集。我們利用詞彙意義消歧模型從視覺和語言資料集中選取含糊的資料，產生更具挑戰性的資料集。我們進一步在我們提出的資料集上對幾個最先進的 MMT 模型進行基準測試。實驗結果顯示，在我們的資料集上訓練的 MMT 模型展現出比在其他 MMT 資料集上訓練的模型更強大的利用視覺資訊的能力。我們的研究為多模態學習領域的研究人員提供寶貴的資源，並鼓勵進一步探索這個領域。資料、程式碼和指令碼可於 https://github.com/MaxyLee/3AM 免費取得。

##### **Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**
2404.18410v1 by Bowen Xu,Shaoyu Wu,Kai Liu,Lulu Hu

With the proliferation of large language models (LLMs), the comprehensive
alignment of such models across multiple tasks has emerged as a critical area
of research. Existing alignment methodologies primarily address single task,
such as multi-turn dialogue, coding, mathematical problem-solving, and tool
usage. However, AI-driven products that leverage language models usually
necessitate a fusion of these abilities to function effectively in real-world
scenarios. Moreover, the considerable computational resources required for
proper alignment of LLMs underscore the need for a more robust, efficient, and
encompassing approach to multi-task alignment, ensuring improved generative
performance. In response to these challenges, we introduce a novel technique
termed Mixture-of-Instructions (MoI), which employs a strategy of instruction
concatenation combined with diverse system prompts to boost the alignment
efficiency of language models. We have also compiled a diverse set of seven
benchmark datasets to rigorously evaluate the alignment efficacy of the
MoI-enhanced language model. Our methodology was applied to the open-source
Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This
enhanced model demonstrates significant advancements in generative capabilities
across coding, mathematics, and tool use tasks.

摘要：隨著大型語言模型 (LLM) 的激增，跨多項任務的這種模型的全面對齊已成為研究的一個關鍵領域。現有的對齊方法主要針對單一任務，例如多輪對話、編碼、數學問題解決和工具使用。然而，利用語言模型的人工智慧驅動產品通常需要融合這些能力才能在現實世界場景中有效運行。此外，適當對齊 LLM 所需的大量計算資源強調了對多任務對齊採用更強健、更有效率且更全面的方法的需求，以確保更好的生成性能。為了應對這些挑戰，我們引入了一種稱為指令混合 (MoI) 的新技術，它採用指令串接策略，結合多樣化的系統提示，以提高語言模型的對齊效率。我們還編制了一組由七個基準數據集組成的多樣化數據集，以嚴格評估增強 MoI 的語言模型的對齊效果。我們的技術應用於開源的 Qwen-7B-chat 模型，最終開發出 Qwen-SFT-MoI。這個增強的模型在編碼、數學和工具使用任務中展示了生成能力方面的顯著進步。

##### **LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**
2404.18400v1 by Parshin Shojaee,Kazem Meidani,Shashank Gupta,Amir Barati Farimani,Chandan K Reddy

Mathematical equations have been unreasonably effective in describing complex
natural phenomena across various scientific disciplines. However, discovering
such insightful equations from data presents significant challenges due to the
necessity of navigating extremely high-dimensional combinatorial and nonlinear
hypothesis spaces. Traditional methods of equation discovery largely focus on
extracting equations from data alone, often neglecting the rich domain-specific
prior knowledge that scientists typically depend on. To bridge this gap, we
introduce LLM-SR, a novel approach that leverages the extensive scientific
knowledge and robust code generation capabilities of Large Language Models
(LLMs) to discover scientific equations from data in an efficient manner.
Specifically, LLM-SR treats equations as programs with mathematical operators
and combines LLMs' scientific priors with evolutionary search over equation
programs. The LLM iteratively proposes new equation skeletons, drawing from its
physical understanding, which are then optimized against data to estimate
skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse
scientific domains, where it discovers physically accurate equations that
provide significantly better fits to in-domain and out-of-domain data compared
to the well-established equation discovery baselines

摘要：數學方程式在描述各種科學領域中複雜的自然現象方面一直異常有效。然而，由於必須在極高維度的組合和非線性假設空間中導航，從資料中發現此類有見地的方程式會帶來重大挑戰。傳統的方程式發現方法主要集中在僅從資料中提取方程式，通常忽略科學家通常依賴的豐富領域特定先驗知識。為了彌補這一差距，我們引入了 LLM-SR，這是一種新穎的方法，它利用大型語言模型 (LLM) 廣泛的科學知識和強大的程式碼生成能力，以有效的方式從資料中發現科學方程式。具體來說，LLM-SR 將方程式視為具有數學運算符的程式，並將 LLM 的科學先驗與對方程式程式的演化搜尋相結合。LLM 反覆提出新的方程式架構，從其物理理解中汲取，然後根據資料進行最佳化以估計架構參數。我們在三個不同的科學領域展示了 LLM-SR 的有效性，它發現了物理上準確的方程式，與公認的方程式發現基準相比，這些方程式對域內和域外資料提供了顯著更好的擬合。

##### **MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**
2404.18398v1 by Xiang Li,Zhi-Qi Cheng,Jun-Yan He,Xiaojiang Peng,Alexander G. Hauptmann

Emotional Text-to-Speech (E-TTS) synthesis has gained significant attention
in recent years due to its potential to enhance human-computer interaction.
However, current E-TTS approaches often struggle to capture the complexity of
human emotions, primarily relying on oversimplified emotional labels or
single-modality inputs. To address these limitations, we propose the Multimodal
Emotional Text-to-Speech System (MM-TTS), a unified framework that leverages
emotional cues from multiple modalities to generate highly expressive and
emotionally resonant speech. MM-TTS consists of two key components: (1) the
Emotion Prompt Alignment Module (EP-Align), which employs contrastive learning
to align emotional features across text, audio, and visual modalities, ensuring
a coherent fusion of multimodal information; and (2) the Emotion
Embedding-Induced TTS (EMI-TTS), which integrates the aligned emotional
embeddings with state-of-the-art TTS models to synthesize speech that
accurately reflects the intended emotions. Extensive evaluations across diverse
datasets demonstrate the superior performance of MM-TTS compared to traditional
E-TTS models. Objective metrics, including Word Error Rate (WER) and Character
Error Rate (CER), show significant improvements on ESD dataset, with MM-TTS
achieving scores of 7.35% and 3.07%, respectively. Subjective assessments
further validate that MM-TTS generates speech with emotional fidelity and
naturalness comparable to human speech. Our code and pre-trained models are
publicly available at https://anonymous.4open.science/r/MMTTS-D214

摘要：情感文本轉語音 (E-TTS) 合成近年來備受關注，原因在於它有潛力增強人機互動。然而，現有的 E-TTS 方法通常難以捕捉人類情緒的複雜性，主要依賴過於簡化的情緒標籤或單一模式輸入。為了解決這些限制，我們提出了多模態情感文本轉語音系統 (MM-TTS)，這是一個統一的架構，它利用來自多種模式的情感線索來產生高度表達力和情感共鳴的語音。MM-TTS 包含兩個關鍵組成部分：(1) 情緒提示對齊模組 (EP-Align)，它採用對比學習來對齊文本、音訊和視覺模式中的情緒特徵，確保多模態資訊的融合一致；(2) 情緒嵌入誘導 TTS (EMI-TTS)，它將對齊的情緒嵌入與最先進的 TTS 模型整合，以合成準確反映預期情緒的語音。跨越不同資料集的廣泛評估顯示，與傳統 E-TTS 模型相比，MM-TTS 具有卓越的效能。客觀指標，包括字元錯誤率 (WER) 和字元錯誤率 (CER)，在 ESD 資料集上顯示出顯著改善，MM-TTS 分別達到 7.35% 和 3.07% 的得分。主觀評估進一步驗證 MM-TTS 產生的語音具有與人類語音相當的情緒保真度和自然度。我們的程式碼和預先訓練的模型已在 https://anonymous.4open.science/r/MMTTS-D214 公開。

##### **Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**
2404.18385v2 by Yixuan Li,Dan C. Baciu,Marcos Novak,George Legrady

Over the past year, the emergence of advanced text-to-image Generative AI
models has significantly impacted the art world, challenging traditional
notions of creativity and the role of artists. This study explores how artists
interact with these technologies, using a 5P model (Purpose, People, Process,
Product, and Press) based on Rhodes' creativity framework to compare the
artistic processes behind Conceptual Art and Image Generative AI. To exemplify
this framework, a practical case study titled "Equivalence", a multi-screen
interactive installation that converts users' speech input into continuously
evolving paintings developed based on Stable Diffusion and NLP algorithms, was
developed. Through comprehensive analysis and the case study, this work aims to
broaden our understanding of artists' roles and foster a deeper appreciation
for the creative aspects inherent in artwork created with Image Generative AI.

摘要：在過去一年中，先進文字轉圖像生成式 AI 模型的出現對藝術界產生了重大影響，挑戰了傳統的創造力概念和藝術家的角色。本研究探討藝術家如何與這些技術互動，使用基於 Rhodes 創造力框架的 5P 模型（目的、人、過程、產品和新聞）來比較概念藝術和圖像生成式 AI 背後的藝術過程。為了說明這個框架，開發了一個名為「等價」的實用案例研究，這是一個多螢幕互動式裝置，可以將使用者的語音輸入轉換為持續演化的繪畫，這些繪畫是基於 Stable Diffusion 和 NLP 演算法開發的。透過全面的分析和案例研究，這項工作旨在擴展我們對藝術家角色的理解，並培養對使用圖像生成式 AI 創作的藝術作品中固有的創造性方面的更深入的欣賞。

##### **Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**
2404.18384v1 by Jordan Meadows,Tamsin James,Andre Freitas

Language models can hallucinate when performing complex and detailed
mathematical reasoning. Physics provides a rich domain for assessing
mathematical reasoning capabilities where physical context imbues the use of
symbols which needs to satisfy complex semantics (\textit{e.g.,} units,
tensorial order), leading to instances where inference may be algebraically
coherent, yet unphysical. In this work, we assess the ability of Language
Models (LMs) to perform fine-grained mathematical and physical reasoning using
a curated dataset encompassing multiple notations and Physics subdomains. We
improve zero-shot scores using synthetic in-context examples, and demonstrate
non-linear degradation of derivation quality with perturbation strength via the
progressive omission of supporting premises. We find that the models'
mathematical reasoning is not physics-informed in this setting, where physical
context is predominantly ignored in favour of reverse-engineering solutions.

摘要：語言模型在執行複雜且詳細的數學推理時可能會出現幻覺。物理學提供了一個豐富的領域，可以用於評估數學推理能力，其中物理背景賦予了符號的使用，這些符號需要滿足複雜的語義（例如，單位、張量順序），導致推理在代數上可能是一致的，但卻不符合物理。在這項工作中，我們評估語言模型 (LM) 使用精心策劃的涵蓋多種符號和物理子領域的資料集執行細緻的數學和物理推理的能力。我們使用合成的上下文範例改進了零次學習分數，並通過逐步省略支持前提來證明了推導品質會隨著擾動強度呈非線性下降。我們發現，在這種情況下，模型的數學推理並未納入物理資訊，因為物理背景主要被忽略，而有利於逆向工程解決方案。

##### **QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**
2404.18371v1 by Tomoki Fukuma,Koki Noda,Toshihide Ubukata Kousuke Hoso,Yoshiharu Ichikawa,Kyosuke Kambe,Yu Masubuch,Fujio Toriumi

The proliferation of social media has led to information overload and
increased interest in opinion mining. We propose "Question-Answering Network
Analysis" (QANA), a novel opinion mining framework that utilizes Large Language
Models (LLMs) to generate questions from users' comments, constructs a
bipartite graph based on the comments' answerability to the questions, and
applies centrality measures to examine the importance of opinions. We
investigate the impact of question generation styles, LLM selections, and the
choice of embedding model on the quality of the constructed QA networks by
comparing them with annotated Key Point Analysis datasets. QANA achieves
comparable performance to previous state-of-the-art supervised models in a
zero-shot manner for Key Point Matching task, also reducing the computational
cost from quadratic to linear. For Key Point Generation, questions with high
PageRank or degree centrality align well with manually annotated key points.
Notably, QANA enables analysts to assess the importance of key points from
various aspects according to their selection of centrality measure. QANA's
primary contribution lies in its flexibility to extract key points from a wide
range of perspectives, which enhances the quality and impartiality of opinion
mining.

摘要：社群媒體的蓬勃發展導致資訊過載，並提高了對意見探勘的興趣。我們提出「問答網路分析」(QANA)，這是一個新穎的意見探勘架構，它利用大型語言模型 (LLM) 從使用者的留言中產生問題，根據留言對問題的可回答性建構一個二部圖，並應用中心性測量來檢視意見的重要性。我們透過將問答網路分析與註解關鍵點分析資料集進行比較，探討問題產生風格、LLM 選擇以及嵌入模型的選擇對建構的問答網路品質的影響。QANA 在關鍵點比對任務中以零次學習的方式，達到與先前的最先進監督模型相當的效能，同時將運算成本從二次方降低到一次方。對於關鍵點產生，具有高 PageRank 或度中心性的問題與手動註解的關鍵點非常吻合。值得注意的是，QANA 讓分析師能夠根據他們選擇的中心性測量，從各種面向評估關鍵點的重要性。QANA 最主要的貢獻在於它能從廣泛的觀點中提取關鍵點的靈活性，這提升了意見探勘的品質和公正性。

##### **FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**
2404.18359v1 by Wei Li,Ren Ma,Jiang Wu,Chenya Gu,Jiahui Peng,Jinyang Len,Songyang Zhang,Hang Yan,Dahua Lin,Conghui He

In the burgeoning field of large language models (LLMs), the assessment of
fundamental knowledge remains a critical challenge, particularly for models
tailored to Chinese language and culture. This paper introduces FoundaBench, a
pioneering benchmark designed to rigorously evaluate the fundamental knowledge
capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354
multiple-choice questions across common sense and K-12 educational subjects,
meticulously curated to reflect the breadth and depth of everyday and academic
knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using
FoundaBench, employing both traditional assessment methods and our CircularEval
protocol to mitigate potential biases in model responses. Our results highlight
the superior performance of models pre-trained on Chinese corpora, and reveal a
significant disparity between models' reasoning and memory recall capabilities.
The insights gleaned from FoundaBench evaluations set a new standard for
understanding the fundamental knowledge of LLMs, providing a robust framework
for future advancements in the field.

摘要：在蓬勃發展的大語言模型（LLM）領域中，基礎知識的評估仍然是一項嚴峻的挑戰，特別是針對專門針對中文語言和文化的模型。本文介紹了 FoundaBench，這是一個開創性的基準，旨在嚴格評估中文 LLM 的基礎知識能力。FoundaBench 涵蓋了 3354 個多元化的多選題，涵蓋常識和 K-12 教育科目，經過精心策劃以反映日常和學術知識的廣度和深度。我們使用 FoundaBench 對 12 個最先進的 LLM 進行了廣泛的評估，採用傳統評估方法和我們的 CircularEval 協議來減輕模型回應中潛在的偏差。我們的結果突出了在中文語料庫上預先訓練的模型的卓越性能，並揭示了模型的推理和記憶召回能力之間的顯著差異。從 FoundaBench 評估中獲得的見解為理解 LLM 的基礎知識設定了新的標準，為該領域未來的進步提供了強大的框架。

##### **Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**
2404.18353v1 by Norbert Tihanyi,Tamas Bisztray,Mohamed Amine Ferrag,Ridhi Jain,Lucas C. Cordeiro

This study provides a comparative analysis of state-of-the-art large language
models (LLMs), analyzing how likely they generate vulnerabilities when writing
simple C programs using a neutral zero-shot prompt. We address a significant
gap in the literature concerning the security properties of code produced by
these models without specific directives. N. Tihanyi et al. introduced the
FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs,
with over 51.24% identified as vulnerable. We expand that work by introducing
the FormAI-v2 dataset comprising 265,000 compilable C programs generated using
various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's
GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13
billion-parameter CodeLLama2 and various other compact models. Each program in
the dataset is labelled based on the vulnerabilities detected in its source
code through formal verification using the Efficient SMT-based Context-Bounded
Model Checker (ESBMC). This technique eliminates false positives by delivering
a counterexample and ensures the exclusion of false negatives by completing the
verification process. Our study reveals that at least 63.47% of the generated
programs are vulnerable. The differences between the models are minor, as they
all display similar coding errors with slight variations. Our research
highlights that while LLMs offer promising capabilities for code generation,
deploying their output in a production environment requires risk assessment and
validation.

摘要：本研究對最先進的大型語言模型 (LLM) 進行比較分析，分析它們在使用中立零次提示編寫簡單 C 程式時產生漏洞的可能性。我們解決了關於這些模型在沒有具體指令的情況下產生的程式碼的安全性屬性的文獻中的重大空白。N. Tihanyi 等人在 PROMISE '23 上介紹了 FormAI 資料集，其中包含 112,000 個 GPT-3.5 生成的 C 程式，其中超過 51.24% 被標識為有漏洞。我們通過引入 FormAI-v2 資料集來擴展這項工作，該資料集包含使用各種 LLM 生成的 265,000 個可編譯 C 程式，包括 Google 的 GEMINI-pro、OpenAI 的 GPT-4 和 TII 的 1800 億參數 Falcon 等強大模型，以及 Meta 的專業 130 億參數 CodeLLama2 和各種其他精簡模型。資料集中的每個程式都根據使用基於高效 SMT 的上下文約束模型檢查器 (ESBMC) 的形式驗證在其原始程式碼中檢測到的漏洞進行標記。此技術通過提供反例來消除假陽性，並通過完成驗證過程來確保排除假陰性。我們的研究表明，至少 63.47% 的生成程式是有漏洞的。這些模型之間的差異很小，因為它們都顯示出類似的編碼錯誤，只有很小的變化。我們的研究強調，儘管 LLM 為程式碼生成提供了有希望的能力，但在生產環境中部署其輸出需要風險評估和驗證。

##### **Post-hoc and manifold explanations analysis of facial expression data based on deep learning**
2404.18352v1 by Yang Xiao

The complex information processing system of humans generates a lot of
objective and subjective evaluations, making the exploration of human cognitive
products of great cutting-edge theoretical value. In recent years, deep
learning technologies, which are inspired by biological brain mechanisms, have
made significant strides in the application of psychological or cognitive
scientific research, particularly in the memorization and recognition of facial
data. This paper investigates through experimental research how neural networks
process and store facial expression data and associate these data with a range
of psychological attributes produced by humans. Researchers utilized deep
learning model VGG16, demonstrating that neural networks can learn and
reproduce key features of facial data, thereby storing image memories.
Moreover, the experimental results reveal the potential of deep learning models
in understanding human emotions and cognitive processes and establish a
manifold visualization interpretation of cognitive products or psychological
attributes from a non-Euclidean space perspective, offering new insights into
enhancing the explainability of AI. This study not only advances the
application of AI technology in the field of psychology but also provides a new
psychological theoretical understanding the information processing of the AI.
The code is available in here: https://github.com/NKUShaw/Psychoinformatics.

摘要：人類複雜的資訊處理系統會產生大量的客觀與主觀評估，使得對於人類認知產物的探討具有極大的前沿理論價值。近年來，受到生物腦機制啟發的深度學習技術在心理或認知科學研究的應用上有了顯著的進展，特別是在臉部資料的記憶與辨識上。本論文透過實驗研究探討神經網路如何處理與儲存臉部表情資料，並將這些資料與人類產生的各種心理屬性聯繫起來。研究者利用深度學習模型 VGG16，驗證神經網路可以學習與重現臉部資料的關鍵特徵，進而儲存影像記憶。此外，實驗結果揭示了深度學習模型在理解人類情緒與認知歷程的潛力，並從非歐幾何空間的角度建立認知產物或心理屬性的流形視覺化詮釋，為提升 AI 的可解釋性提供了新的見解。本研究不僅推進了 AI 技術在心理學領域的應用，也為 AI 的資訊處理提供了新的心理學理論理解。程式碼可於此處取得：https://github.com/NKUShaw/Psychoinformatics。

##### **Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**
2404.18328v1 by Hamdi Friji,Ioannis Mavromatis,Adrian Sanchez-Mompo,Pietro Carnelli,Alexis Olivereau,Aftab Khan

With the ever-increasing reliance on digital networks for various aspects of
modern life, ensuring their security has become a critical challenge. Intrusion
Detection Systems play a crucial role in ensuring network security, actively
identifying and mitigating malicious behaviours. However, the relentless
advancement of cyber-threats has rendered traditional/classical approaches
insufficient in addressing the sophistication and complexity of attacks. This
paper proposes a novel 3-stage intrusion detection system inspired by a
simplified version of the Lockheed Martin cyber kill chain to detect advanced
multi-step attacks. The proposed approach consists of three models, each
responsible for detecting a group of attacks with common characteristics. The
detection outcome of the first two stages is used to conduct a feasibility
study on the possibility of predicting attacks in the third stage. Using the
ToN IoT dataset, we achieved an average of 94% F1-Score among different stages,
outperforming the benchmark approaches based on Random-forest model. Finally,
we comment on the feasibility of this approach to be integrated in a real-world
system and propose various possible future work.

摘要：隨著現代生活各方面對數位網路的依賴與日俱增，確保其安全性已成為一項重大的挑戰。入侵偵測系統在確保網路安全方面扮演著至關重要的角色，主動識別和減輕惡意行為。然而，網路威脅的無情進展使得傳統/古典方法無法應對攻擊的複雜性和精密性。本文提出了一種新穎的三階段入侵偵測系統，其靈感來自洛克希德馬丁網路殺戮鏈的簡化版本，用於偵測進階的多步驟攻擊。所提出的方法包含三個模型，每個模型負責偵測具備共同特徵的一組攻擊。前兩個階段的偵測結果用於對第三階段預測攻擊的可能性進行可行性研究。使用 ToN IoT 資料集，我們在不同階段達到了平均 94% 的 F1 分數，優於基於隨機森林模型的基準方法。最後，我們評論了這種方法整合到實際系統中的可行性，並提出了各種可能的未來工作。

##### **SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**
2404.18326v1 by Amir Samadi,Konstantinos Koufos,Kurt Debattista,Mehrdad Dianati

While Deep Reinforcement Learning (DRL) has emerged as a promising solution
for intricate control tasks, the lack of explainability of the learned policies
impedes its uptake in safety-critical applications, such as automated driving
systems (ADS). Counterfactual (CF) explanations have recently gained prominence
for their ability to interpret black-box Deep Learning (DL) models. CF examples
are associated with minimal changes in the input, resulting in a complementary
output by the DL model. Finding such alternations, particularly for
high-dimensional visual inputs, poses significant challenges. Besides, the
temporal dependency introduced by the reliance of the DRL agent action on a
history of past state observations further complicates the generation of CF
examples. To address these challenges, we propose using a saliency map to
identify the most influential input pixels across the sequence of past observed
states by the agent. Then, we feed this map to a deep generative model,
enabling the generation of plausible CFs with constrained modifications centred
on the salient regions. We evaluate the effectiveness of our framework in
diverse domains, including ADS, Atari Pong, Pacman and space-invaders games,
using traditional performance metrics such as validity, proximity and sparsity.
Experimental results demonstrate that this framework generates more informative
and plausible CFs than the state-of-the-art for a wide range of environments
and DRL agents. In order to foster research in this area, we have made our
datasets and codes publicly available at
https://github.com/Amir-Samadi/SAFE-RL.

摘要：儘管深度強化學習 (DRL) 已成為解決複雜控制任務的潛在解決方案，但學習政策缺乏可解釋性，阻礙其在安全關鍵應用程式中的採用，例如自動駕駛系統 (ADS)。反事實 (CF) 解釋最近因其解釋黑盒深度學習 (DL) 模型的能力而聲名大噪。CF 樣本與輸入的最小變更相關聯，導致 DL 模型產生互補輸出。尋找這種交替變化，特別是對於高維度視覺輸入，會造成重大挑戰。此外，DRL 代理動作依賴於過去狀態觀察的歷史所引入的時間依賴性，進一步複雜化了 CF 範例的產生。為了應對這些挑戰，我們建議使用顯著性地圖來識別代理在過去觀察狀態序列中影響力最大的輸入像素。然後，我們將此地圖饋入深度生成模型，能夠產生以顯著區域為中心的受限修改的合理 CF。我們使用傳統效能指標（例如有效性、接近性和稀疏性）評估我們架構在各種領域（包括 ADS、Atari Pong、吃豆人和太空侵略者遊戲）中的有效性。實驗結果表明，對於廣泛的環境和 DRL 代理，此架構產生的 CF 比最先進的技術更具資訊性和合理性。為了促進這方面的研究，我們已將我們的資料集和程式碼公開於 https://github.com/Amir-Samadi/SAFE-RL。

##### **Towards Real-time Learning in Large Language Models: A Critical Review**
2404.18311v2 by Mladjan Jovanovic,Peter Voss

Real-time learning concerns the ability of learning systems to acquire
knowledge over time, enabling their adaptation and generalization to novel
tasks. It is a critical ability for intelligent, real-world systems, especially
when data may be insufficient or difficult to obtain. This review provides a
comprehensive analysis of real-time learning in Large Language Models. It
synthesizes the state-of-the-art real-time learning paradigms, including
continual learning, meta-learning, parameter-efficient learning, and
mixture-of-experts learning. We demonstrate their utility for real-time
learning by describing specific achievements from these related topics and
their critical factors. Finally, the paper highlights current problems and
challenges for future research in the field. By consolidating the latest
relevant research developments, this review offers a comprehensive
understanding of real-time learning and its implications for designing and
developing LLM-based learning systems addressing real-world problems.

摘要：實時學習涉及學習系統隨著時間推移獲取知識的能力，使其適應和推廣到新任務。對於智慧的現實世界系統而言，這是一種至關重要的能力，尤其是在資料可能不足或難以取得時。本評論提供了對大型語言模型中實時學習的全面分析。它綜合了最先進的實時學習範例，包括持續學習、元學習、參數有效學習和專家混合學習。我們透過描述這些相關主題的具體成就及其關鍵因素，展示了它們在實時學習中的效用。最後，本文重點介紹了該領域未來研究的當前問題和挑戰。透過整合最新的相關研究進展，本評論提供了對實時學習及其對設計和開發解決現實世界問題的 LLM 基於學習系統的影響的全面理解。

##### **Retrieval-Oriented Knowledge for Click-Through Rate Prediction**
2404.18304v1 by Huanshuo Liu,Bo Chen,Menghui Zhu,Jianghao Lin,Jiarui Qin,Yang Yang,Hao Zhang,Ruiming Tang

Click-through rate (CTR) prediction plays an important role in personalized
recommendations. Recently, sample-level retrieval-based models (e.g., RIM) have
achieved remarkable performance by retrieving and aggregating relevant samples.
However, their inefficiency at the inference stage makes them impractical for
industrial applications. To overcome this issue, this paper proposes a
universal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.
Specifically, a knowledge base, consisting of a retrieval-oriented embedding
layer and a knowledge encoder, is designed to preserve and imitate the
retrieved & aggregated representations in a decomposition-reconstruction
paradigm. Knowledge distillation and contrastive learning methods are utilized
to optimize the knowledge base, and the learned retrieval-enhanced
representations can be integrated with arbitrary CTR models in both
instance-wise and feature-wise manners. Extensive experiments on three
large-scale datasets show that ROK achieves competitive performance with the
retrieval-based CTR models while reserving superior inference efficiency and
model compatibility.

摘要：點擊率 (CTR) 預測在個人化推薦中扮演著重要的角色。最近，基於樣本層級檢索的模型（例如 RIM）透過檢索和彙總相關樣本，達到了顯著的效能。然而，它們在推論階段的低效率，使得它們不切實際地應用在產業應用中。為了克服這個問題，這篇論文提出了一個通用的即插即用檢索導向知識 (ROK) 架構。具體來說，一個由檢索導向嵌入層和知識編碼器組成的知識庫，被設計用來在分解重建範例中保留和模仿檢索和彙總的表示。知識萃取和對比學習方法被用來最佳化知識庫，而學習到的檢索增強表示可以整合到任意的 CTR 模型中，無論是基於實例或基於特徵的方式。在三個大規模資料集上的廣泛實驗顯示，ROK 達到了與基於檢索的 CTR 模型相媲美的效能，同時保留了優異的推論效率和模型相容性。

##### **Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**
2404.18296v1 by Zoi Lygizou,Dimitris Kalles

Recent work on decentralized computational trust models for open Multi Agent
Systems has resulted in the development of CA, a biologically inspired model
which focuses on the trustee's perspective. This new model addresses a serious
unresolved problem in existing trust and reputation models, namely the
inability to handle constantly changing behaviors and agents' continuous entry
and exit from the system. In previous work, we compared CA to FIRE, a
well-known trust and reputation model, and found that CA is superior when the
trustor population changes, whereas FIRE is more resilient to the trustee
population changes. Thus, in this paper, we investigate how the trustors can
detect the presence of several dynamic factors in their environment and then
decide which trust model to employ in order to maximize utility. We frame this
problem as a machine learning problem in a partially observable environment,
where the presence of several dynamic factors is not known to the trustor and
we describe how an adaptable trustor can rely on a few measurable features so
as to assess the current state of the environment and then use Deep Q Learning
(DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt
to a changing environment. We ran a series of simulation experiments to compare
the performance of the adaptable trustor with the performance of trustors using
only one model (FIRE or CA) and we show that an adaptable agent is indeed
capable of learning when to use each model and, thus, perform consistently in
dynamic environments.

摘要：最近關於開放多重代理系統的去中心化計算信任模型的研究，導致了 CA 的開發，這是一個以受託人的觀點為主的生物靈感模型。這個新模型解決了現有信任和聲譽模型中一個嚴重的未解決問題，即無法處理不斷變化的行為以及代理人持續進出系統。在先前的研究中，我們將 CA 與 FIRE（一個著名的信任和聲譽模型）進行比較，並發現當信任者群體發生變化時，CA 優於 FIRE，而 FIRE 對受託人群體的變化更有彈性。因此，在本文中，我們研究了信任者如何偵測其環境中幾個動態因素的存在，然後決定採用哪個信任模型以最大化效用。我們將這個問題構建為在部分可觀察環境中的機器學習問題，其中信任者不知道幾個動態因素的存在，並且我們描述了一個適應性信任者如何依賴一些可測量的特徵來評估環境的當前狀態，然後在單一代理強化學習設置中使用深度 Q 學習 (DQN) 來學習如何適應不斷變化的環境。我們進行了一系列模擬實驗，以比較適應性信任者的效能與僅使用一個模型（FIRE 或 CA）的信任者的效能，並且我們表明，一個適應性代理確實有能力學習何時使用每一個模型，因此，在動態環境中表現一致。

##### **Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**
2404.18286v2 by David Ifeoluwa Adelani,A. Seza Doğruöz,André Coneglian,Atul Kr. Ojha

Large Language Models are transforming NLP for a variety of tasks. However,
how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
In line with the goals of the AmericasNLP workshop, we focus on 12 LRLs from
Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
reasons behind this failure and provide an error analysis through examples
observed in our data set.

摘要：大型語言模型正在為各種任務轉換 NLP。然而，LLM 如何為低資源語言 (LRL) 執行 NLP 任務的探索較少。根據 AmericasNLP 工作坊的目標，我們專注於來自巴西的 12 個 LRL、來自非洲的 2 個 LRL 和 2 個高資源語言 (HRL)（例如英語和巴西葡萄牙語）。我們的結果表明，與 HRL 相比，LLM 對 LRL 的詞性 (POS) 標記執行得較差。我們解釋了這種失敗背後的原因，並通過在我們的數據集中觀察到的範例提供錯誤分析。

##### **Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**
2404.18276v1 by Malur Narayan,John Pasmore,Elton Sampaio,Vijay Raghavan,Gabriella Waters

The burgeoning influence of Large Language Models (LLMs) in shaping public
discourse and decision-making underscores the imperative to address inherent
biases within these AI systems. In the wake of AI's expansive integration
across sectors, addressing racial bias in LLMs has never been more critical.
This paper introduces a novel framework called Comprehensive Bias
Neutralization Framework (CBNF) which embodies an innovative approach to
quantifying and mitigating biases within LLMs. Our framework combines the Large
Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)]
and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)]
methodologies to create a new metric called Bias Intelligence Quotient
(BiQ)which detects, measures, and mitigates racial bias in LLMs without
reliance on demographic annotations.
  By introducing a new metric called BiQ that enhances LLMBI with additional
fairness metrics, CBNF offers a multi-dimensional metric for bias assessment,
underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et
al., 2021]. This paper presents a detailed analysis of Latimer AI (a language
model incrementally trained on black history and culture) in comparison to
ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural,
and gender biases through targeted training and refined bias mitigation
strategies [Latimer & Bender, 2023].

摘要：大型語言模型 (LLM) 在塑造公眾話語和決策方面的影響力與日俱增，這凸顯了解決這些 AI 系統內部固有偏見的必要性。隨著 AI 在各個領域的廣泛整合，解決 LLM 中的種族偏見比以往任何時候都更為關鍵。本文介紹了一個名為全面偏見中和框架 (CBNF) 的新框架，它體現了量化和減輕 LLM 中偏見的創新方法。我們的框架結合了大型語言模型偏見指數 (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)] 和無人口統計數據的偏見移除 (BLIND) [Orgad, H., Belinkov, Y. (2023)] 方法來創建一個名為偏見智商 (BiQ) 的新指標，它可以在不依賴人口統計註釋的情況下檢測、衡量和減輕 LLM 中的種族偏見。
通過引入一個名為 BiQ 的新指標，它使用額外的公平性指標增強了 LLMBI，CBNF 提供了一個多維度的偏見評估指標，強調了對 AI 中公平性採取細緻方法的必要性 [Mehrabi 等人，2021]。本文詳細分析了 Latimer AI（一個逐步接受黑人歷史和文化訓練的語言模型），並將其與 ChatGPT 3.5 進行比較，說明了 Latimer AI 通過目標訓練和改進的偏見緩解策略在檢測種族、文化和性別偏見方面的功效 [Latimer & Bender, 2023]。

##### **Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**
2404.18271v1 by Qi Zhu,Da Zheng,Xiang Song,Shichang Zhang,Bowen Jin,Yizhou Sun,George Karypis

Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.

摘要：<paragraph>文本豐富的圖表，在節點和邊緣上展示豐富的文字資訊，在廣泛的現實世界業務應用中很普遍。大型語言模型 (LLM) 已展現出在理解文本方面的卓越能力，這也為在文本豐富的圖表中進行更具表現力的建模引入了可能性。儘管有這些能力，但有效地將 LLM 應用於圖表上的表示學習仍然存在重大挑戰。最近，LLM 的參數高效微調方法已實現了有效的新任務泛化，同時將時間和記憶體消耗降至最低。受此啟發，我們引入了圖感知參數高效微調 - GPEFT，這是一種在文本豐富的圖表上使用 LLM 進行高效圖表示學習的新方法。具體來說，我們利用圖神經網路 (GNN) 將來自鄰近節點的結構資訊編碼成圖提示。然後將此提示插入文本序列的開頭。為了提高圖提示的品質，我們預先訓練了 GNN，以協助凍結的 LLM 預測節點文字中的下一個標記。與現有的聯合 GNN 和 LM 相比，我們的模型直接從大型語言模型中產生節點嵌入，且微調成本可負擔。我們透過在 8 個不同的文本豐富圖表上進行的全面實驗驗證了我們的做法，觀察到連結預測評估中 hit@1 和平均倒數排名 (MRR) 的平均改進為 2%。我們的結果證明了我們模型的功效和效率，表明它可以與各種大型語言模型順利整合，包括 OPT、LLaMA 和 Falcon。</paragraph>

##### **Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**
2404.18270v1 by Aman Kumar

Error Detection and Correction Codes (ECCs) are often used in digital designs
to protect data integrity. Especially in safety-critical systems such as
automotive electronics, ECCs are widely used and the verification of such
complex logic becomes more critical considering the ISO 26262 safety standards.
Exhaustive verification of ECC using formal methods has been a challenge given
the high number of data bits to protect. As an example, for an ECC of 128 data
bits with a possibility to detect up to four-bit errors, the combination of bit
errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast
analysis space often leads to bounded proof results. Moreover, the complexity
and state-space increase further if the ECC has sequential encoding and
decoding stages. To overcome such problems and sign-off the design with
confidence within reasonable proof time, we present a pragmatic formal
verification approach of complex ECC cores with several complexity reduction
techniques and know-how that were learnt during the course of verification. We
discuss using the linearity of the syndrome generator as a helper assertion,
using the abstract model as glue logic to compare the RTL with the sequential
version of the circuit, k-induction-based model checking and using mathematical
relations captured as properties to simplify the verification in order to get
an unbounded proof result within 24 hours of proof runtime.

摘要：錯誤偵測與修正碼 (ECC) 常用於數位設計中以保護資料完整性。特別是在汽車電子等安全關鍵系統中，ECC 被廣泛使用，而驗證這種複雜邏輯在考量 ISO 26262 安全標準時變得更加重要。由於需要保護的大量資料位元，使用形式化方法對 ECC 進行徹底驗證一直是一項挑戰。舉例來說，對於一個 128 資料位元的 ECC，且可能偵測到四位元錯誤，位元錯誤的組合由 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7 給出。這個龐大的分析空間經常導致有界證明結果。此外，如果 ECC 具有循序編碼和解碼階段，則複雜度和狀態空間會進一步增加。為了克服這些問題，並在合理的證明時間內自信地簽核設計，我們提出了一個實用的形式化驗證方法，其中包含了在驗證過程中學到的數個複雜度降低技術和訣竅。我們討論使用症候群產生器的線性作為輔助斷言、使用抽象模型作為膠水邏輯來比較 RTL 與電路的循序版本、基於 k 歸納的模型檢查，以及使用捕獲為屬性的數學關係來簡化驗證，以便在 24 小時的證明執行時間內獲得無界證明結果。

##### **Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**
2404.18264v1 by Pin-Jie Lin,Merel Scholman,Muhammed Saeed,Vera Demberg

Nigerian Pidgin is an English-derived contact language and is traditionally
an oral language, spoken by approximately 100 million people. No orthographic
standard has yet been adopted, and thus the few available Pidgin datasets that
exist are characterised by noise in the form of orthographic variations. This
contributes to under-performance of models in critical NLP tasks. The current
work is the first to describe various types of orthographic variations commonly
found in Nigerian Pidgin texts, and model this orthographic variation. The
variations identified in the dataset form the basis of a phonetic-theoretic
framework for word editing, which is used to generate orthographic variations
to augment training data. We test the effect of this data augmentation on two
critical NLP tasks: machine translation and sentiment analysis. The proposed
variation generation framework augments the training data with new orthographic
variants which are relevant for the test set but did not occur in the training
set originally. Our results demonstrate the positive effect of augmenting the
training data with a combination of real texts from other corpora as well as
synthesized orthographic variation, resulting in performance improvements of
2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.

摘要：奈及利亞皮欽語是一種源自英語的接觸語言，傳統上是一種口語，約有 1 億人使用。尚未採用正字法標準，因此現有的少數皮欽語資料集的特徵是正字法變異形式的雜訊。這會導致模型在關鍵的 NLP 任務中表現不佳。目前的工作首次描述了在奈及利亞皮欽語文本中常見的各種正字法變異類型，並對此正字法變異進行建模。在資料集中識別出的變異形成了詞彙編輯的語音理論架構的基礎，該架構用於產生正字法變異以擴充訓練資料。我們在兩個關鍵的 NLP 任務（機器翻譯和情緒分析）上測試了此資料擴充的效果。所提出的變異產生架構使用與測試集相關但最初未出現在訓練集中的新正字法變異來擴充訓練資料。我們的結果證明了使用來自其他語料庫的真實文本以及合成的正字法變異的組合來擴充訓練資料的積極效果，從而在情緒分析中將效能提升了 2.1 個百分點，在翻譯成英語時將 BLEU 分數提升了 1.4 個百分點。

##### **Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**
2404.18262v1 by Atharva Naik,Jessica Ruhan Yin,Anusha Kamath,Qianou Ma,Sherry Tongshuang Wu,Charles Murray,Christopher Bogart,Majd Sakr,Carolyn P. Rose

An advantage of Large Language Models (LLMs) is their contextualization
capability - providing different responses based on student inputs like
solution strategy or prior discussion, to potentially better engage students
than standard feedback. We present a design and evaluation of a
proof-of-concept LLM application to offer students dynamic and contextualized
feedback. Specifically, we augment an Online Programming Exercise bot for a
college-level Cloud Computing course with ChatGPT, which offers students
contextualized reflection triggers during a collaborative query optimization
task in database design. We demonstrate that LLMs can be used to generate
highly situated reflection triggers that incorporate details of the
collaborative discussion happening in context. We discuss in depth the
exploration of the design space of the triggers and their correspondence with
the learning objectives as well as the impact on student learning in a pilot
study with 34 students.

摘要：大型語言模型 (LLM) 的一個優點是其脈絡化能力 - 根據學生的輸入提供不同的回應，例如解決策略或先前的討論，以潛在地比標準回饋更能吸引學生。我們提出一個概念驗證 LLM 應用程式的設計和評估，以提供學生動態且脈絡化的回饋。具體來說，我們為大學雲端運算課程擴充了一個線上程式練習機器人，並搭配 ChatGPT，在資料庫設計的協作式查詢最佳化任務中，為學生提供脈絡化的反思觸發。我們證明 LLM 可用於產生高度情境化的反思觸發，其中包含在脈絡中發生的協作討論的細節。我們深入討論觸發的設計空間探索及其與學習目標的對應關係，以及在有 34 名學生的試驗研究中對學生學習的影響。

##### **Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**
2404.18257v1 by Nilo Pedrazzini

Languages can encode temporal subordination lexically, via subordinating
conjunctions, and morphologically, by marking the relation on the predicate.
Systematic cross-linguistic variation among the former can be studied using
well-established token-based typological approaches to token-aligned parallel
corpora. Variation among different morphological means is instead much harder
to tackle and therefore more poorly understood, despite being predominant in
several language groups. This paper explores variation in the expression of
generic temporal subordination ('when'-clauses) among the languages of Latin
America and the Caribbean, where morphological marking is particularly common.
It presents probabilistic semantic maps computed on the basis of the languages
of the region, thus avoiding bias towards the many world's languages that
exclusively use lexified connectors, incorporating associations between
character $n$-grams and English $when$. The approach allows capturing
morphological clause-linkage devices in addition to lexified connectors, paving
the way for larger-scale, strategy-agnostic analyses of typological variation
in temporal subordination.

摘要：語言可以透過從屬連接詞在詞彙上編碼時間從屬，並透過在謂詞上標記關係在形態上編碼時間從屬。前者的系統性跨語言變異可以使用建立良好的基於標記的類型學方法來研究標記對齊的平行語料庫。儘管在幾個語言組中佔主導地位，但不同形態手段之間的變異卻難以應對，因此理解得較差。本文探討了拉丁美洲和加勒比海語言中一般時間從屬（「when」從句）表達方式的變異，在這些語言中，形態標記特別常見。它呈現了根據該地區的語言計算出的概率語義地圖，從而避免了對世界上許多僅使用詞彙化連接詞的語言的偏見，並結合了字元 $n$-grams 和英文 $when$ 之間的關聯。這種方法允許捕捉詞彙化連接詞之外的形態從句連結裝置，為時間從屬中類型學變異的大規模、與策略無關的分析鋪平了道路。

##### **PatentGPT: A Large Language Model for Intellectual Property**
2404.18255v2 by Zilong Bai,Ruiji Zhang,Linqing Chen,Qijun Cai,Yuan Zhong,Cong Wang,Yan Fang,Jie Fang,Jing Sun,Weikuan Wang,Lizhi Zhou,Haoran Hua,Tian Qiu,Chaochao Wang,Cheng Sun,Jianping Lu,Yixin Wang,Yubin Xia,Meng Hu,Haowen Liu,Peng Xu,Licong Xu,Fu Bian,Xiaolong Gu,Lisha Zhang,Weilei Wang,Changyang Tu

In recent years, large language models have attracted significant attention
due to their exceptional performance across a multitude of natural language
process tasks, and have been widely applied in various fields. However, the
application of large language models in the Intellectual Property (IP) space is
challenging due to the strong need for specialized knowledge, privacy
protection, processing of extremely long text in this field. In this technical
report, we present for the first time a low-cost, standardized procedure for
training IP-oriented LLMs, meeting the unique requirements of the IP domain.
Using this standard process, we have trained the PatentGPT series models based
on open-source pretrained models. By evaluating them on the open-source
IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4,
indicating the effectiveness of the proposed training procedure and the
expertise of the PatentGPT models in the IP demain. What is impressive is that
our model significantly outperformed GPT-4 on the 2019 China Patent Agent
Qualification Examination by achieving a score of 65, reaching the level of
human experts. Additionally, the PatentGPT model, which utilizes the SMoE
architecture, achieves performance comparable to that of GPT-4 in the IP domain
and demonstrates a better cost-performance ratio on long-text tasks,
potentially serving as an alternative to GPT-4 within the IP domain.

摘要：近年来，大型语言模型因其在众多自然语言处理任务中表现出的卓越性能而备受关注，并已广泛应用于各个领域。然而，大型语言模型在知识产权 (IP) 领域的应用面临挑战，因为该领域对专业知识、隐私保护和处理超长文本有很强的需求。在本技术报告中，我们首次提出了一种低成本、标准化的 IP 导向 LLM 训练程序，以满足 IP 领域的独特要求。使用此标准流程，我们基于开源预训练模型训练了 PatentGPT 系列模型。通过在开源 IP 导向基准 MOZIP 上对其进行评估，我们的特定领域 LLM 优于 GPT-4，表明所提出的训练程序的有效性以及 PatentGPT 模型在 IP 领域的专业知识。令人印象深刻的是，我们的模型在 2019 年中国专利代理人资格考试中以 65 分的成绩显着优于 GPT-4，达到人类专家的水平。此外，利用 SMoE 架构的 PatentGPT 模型在 IP 领域实现了与 GPT-4 相当的性能，并在长文本任务中展示出更好的性价比，有可能在 IP 领域内替代 GPT-4。

##### **LEGENT: Open Platform for Embodied Agents**
2404.18243v1 by Zhili Cheng,Zhitong Wang,Jinyi Hu,Shengding Hu,An Liu,Yuge Tu,Pengkai Li,Lei Shi,Zhiyuan Liu,Maosong Sun

Despite advancements in Large Language Models (LLMs) and Large Multimodal
Models (LMMs), their integration into language-grounded, human-like embodied
agents remains incomplete, hindering complex real-life task performance in
physical environments. Existing integrations often feature limited open
sourcing, challenging collective progress in this field. We introduce LEGENT,
an open, scalable platform for developing embodied agents using LLMs and LMMs.
LEGENT offers a dual approach: a rich, interactive 3D environment with
communicable and actionable agents, paired with a user-friendly interface, and
a sophisticated data generation pipeline utilizing advanced algorithms to
exploit supervision from simulated worlds at scale. In our experiments, an
embryonic vision-language-action model trained on LEGENT-generated data
surpasses GPT-4V in embodied tasks, showcasing promising generalization
capabilities.

摘要：儘管大型語言模型 (LLM) 和大型多模態模型 (LMM) 有所進展，但它們整合到以語言為基礎、 類似人類的具身代理人中仍不完整，阻礙了在物理環境中進行複雜的現實生活任務執行。現有的整合通常具有有限的開放原始碼，對這個領域的集體進展構成挑戰。我們引入了 LEGENT，這是一個開放的、可擴充的平台，可用於使用 LLM 和 LMM 開發具身代理人。LEGENT 提供了雙重方法：一個豐富的互動式 3D 環境，其中包含可溝通且可操作的代理人，並配備一個使用者友善的介面，以及一個精密的資料產生管道，利用先進的演算法來大規模利用模擬世界的監督。在我們的實驗中，一個訓練於 LEGENT 生成的資料上的胚胎視覺語言動作模型超越了 GPT-4V 在具身任務中的表現，展示了有希望的泛化能力。

##### **SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**
2404.18239v1 by Jinghan Jia,Yihua Zhang,Yimeng Zhang,Jiancheng Liu,Bharat Runwal,James Diffenderfer,Bhavya Kailkhura,Sijia Liu

Large Language Models (LLMs) have highlighted the necessity of effective
unlearning mechanisms to comply with data regulations and ethical AI practices.
LLM unlearning aims at removing undesired data influences and associated model
capabilities without compromising utility out of the scope of unlearning. While
interest in studying LLM unlearning is growing,the impact of the optimizer
choice for LLM unlearning remains under-explored. In this work, we shed light
on the significance of optimizer selection in LLM unlearning for the first
time, establishing a clear connection between {second-order optimization} and
influence unlearning (a classical approach using influence functions to update
the model for data influence removal). This insight propels us to develop a
second-order unlearning framework, termed SOUL, built upon the second-order
clipped stochastic optimization (Sophia)-based LLM training method. SOUL
extends the static, one-shot model update using influence unlearning to a
dynamic, iterative unlearning process. Our extensive experiments show that SOUL
consistently outperforms conventional first-order methods across various
unlearning tasks, models, and metrics, suggesting the promise of second-order
optimization in providing a scalable and easily implementable solution for LLM
unlearning.

摘要：大型語言模型 (LLM) 強調了有效遺忘機制的必要性，以遵守資料法規和符合道德的 AI 實務。LLM 遺忘旨在移除不需要的資料影響和相關的模型能力，同時不損及遺忘範圍外的效用。儘管研究 LLM 遺忘的興趣與日俱增，但針對 LLM 遺忘進行最佳化選擇的影響仍未獲得充分探討。在這項研究中，我們首次闡明了最佳化選擇在 LLM 遺忘中的重要性，建立了 {二階最佳化} 與影響遺忘（一種使用影響函數更新模型以移除資料影響的傳統方法）之間的明確關聯。這項見解促使我們開發了一個二階遺忘架構，稱為 SOUL，它建立在二階裁切隨機最佳化 (Sophia) 為基礎的 LLM 訓練方法之上。SOUL 將使用影響遺忘的靜態、一次性模型更新延伸到動態、反覆的遺忘程序。我們的廣泛實驗顯示，SOUL 在各種遺忘任務、模型和指標中始終優於傳統的一階方法，這表明二階最佳化有望提供可擴充且易於實作的 LLM 遺忘解決方案。

##### **From Persona to Personalization: A Survey on Role-Playing Language Agents**
2404.18231v1 by Jiangjie Chen,Xintao Wang,Rui Xu,Siyu Yuan,Yikai Zhang,Wei Shi,Jian Xie,Shuang Li,Ruihan Yang,Tinghui Zhu,Aili Chen,Nianqi Li,Lida Chen,Caiyu Hu,Siye Wu,Scott Ren,Ziquan Fu,Yanghua Xiao

Recent advancements in large language models (LLMs) have significantly
boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
systems designed to simulate assigned personas. By harnessing multiple advanced
abilities of LLMs, including in-context learning, instruction following, and
social intelligence, RPLAs achieve a remarkable sense of human likeness and
vivid role-playing performance. RPLAs can mimic a wide range of personas,
ranging from historical figures and fictional characters to real-life
individuals. Consequently, they have catalyzed numerous AI applications, such
as emotional companions, interactive video games, personalized assistants and
copilots, and digital clones. In this paper, we conduct a comprehensive survey
of this field, illustrating the evolution and recent progress in RPLAs
integrating with cutting-edge LLM technologies. We categorize personas into
three types: 1) Demographic Persona, which leverages statistical stereotypes;
2) Character Persona, focused on well-established figures; and 3)
Individualized Persona, customized through ongoing user interactions for
personalized services. We begin by presenting a comprehensive overview of
current methodologies for RPLAs, followed by the details for each persona type,
covering corresponding data sourcing, agent construction, and evaluation.
Afterward, we discuss the fundamental risks, existing limitations, and future
prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
applications, which reflects practical user demands that shape and drive RPLA
research. Through this work, we aim to establish a clear taxonomy of RPLA
research and applications, and facilitate future research in this critical and
ever-evolving field, and pave the way for a future where humans and RPLAs
coexist in harmony.

摘要：<paragraph>大型語言模型 (LLM) 的近期進展顯著提升了角色扮演語言代理 (RPLA) 的興起，也就是說，專門設計來模擬指定角色的 AI 系統。透過運用 LLM 的多種進階能力，包括情境學習、指令遵循和社交智能，RPLA 達到了顯著的人類相似度和生動的角色扮演表現。RPLA 可以模擬各種各樣的角色，從歷史人物和虛構角色到現實生活中的個人。因此，它們催化了許多 AI 應用程式，例如情緒伴侶、互動式電子遊戲、個人化助理和副駕駛，以及數位分身。在本文中，我們對此領域進行了全面的調查，說明了 RPLA 與尖端 LLM 技術整合的演進和近期進展。我們將角色分為三種類型：1) 人口角色，利用統計刻板印象；2) 角色角色，專注於知名人物；3) 個人化角色，透過持續的使用者互動進行客製化，以提供個人化服務。我們首先提出 RPLA 的當前方法的全面概述，然後說明每種類型的角色，涵蓋對應的資料來源、代理建構和評估。之後，我們討論 RPLA 的基本風險、現有限制和未來前景。此外，我們簡要回顧了 AI 應用程式中的 RPLA，反映了形塑和推動 RPLA 研究的實際使用者需求。透過這項工作，我們旨在建立 RPLA 研究和應用程式的明確分類法，並促進這個關鍵且不斷演進的領域的未來研究，並為人類與 RPLA 和諧共存的未來鋪路。</paragraph>

##### **TextGram: Towards a better domain-adaptive pretraining**
2404.18228v1 by Sharayu Hiwarkhedkar,Saloni Mittal,Vidula Magdum,Omkar Dhekane,Raviraj Joshi,Geetanjali Kale,Arnav Ladkat

For green AI, it is crucial to measure and reduce the carbon footprint
emitted during the training of large language models. In NLP, performing
pre-training on Transformer models requires significant computational
resources. This pre-training involves using a large amount of text data to gain
prior knowledge for performing downstream tasks. Thus, it is important that we
select the correct data in the form of domain-specific data from this vast
corpus to achieve optimum results aligned with our domain-specific tasks. While
training on large unsupervised data is expensive, it can be optimized by
performing a data selection step before pretraining. Selecting important data
reduces the space overhead and the substantial amount of time required to
pre-train the model while maintaining constant accuracy. We investigate the
existing selection strategies and propose our own domain-adaptive data
selection method - TextGram - that effectively selects essential data from
large corpora. We compare and evaluate the results of finetuned models for text
classification task with and without data selection. We show that the proposed
strategy works better compared to other selection methods.

摘要：對於綠色 AI 而言，衡量和減少大型語言模型訓練過程中排放的碳足跡至關重要。在 NLP 中，在 Transformer 模型上執行預訓練需要大量的計算資源。此預訓練涉及使用大量的文本資料來獲取執行下游任務的先驗知識。因此，從這個龐大的語料庫中選擇正確的資料，以特定領域的資料形式來達成與特定領域任務相符的最佳結果，這一點非常重要。雖然在大量非監督資料上進行訓練很昂貴，但可以在預訓練前執行資料選擇步驟來進行最佳化。選擇重要的資料可以減少空間開銷以及預訓練模型所需的大量時間，同時維持不變的準確度。我們探討現有的選擇策略，並提出我們自己的領域自適應資料選擇方法，也就是 TextGram，它能有效地從大型語料庫中選擇必要的資料。我們比較和評估微調模型在有和沒有資料選擇的文本分類任務中的結果。我們證明，與其他選擇方法相比，所提出的策略表現得更好。

##### **L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**
2404.18216v1 by Saloni Mittal,Vidula Magdum,Omkar Dhekane,Sharayu Hiwarkhedkar,Raviraj Joshi

The availability of text or topic classification datasets in the low-resource
Marathi language is limited, typically consisting of fewer than 4 target
labels, with some achieving nearly perfect accuracy. In this work, we introduce
L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
headlines and articles. This corpus stands out as the largest supervised
Marathi Corpus, containing over 1.05L records classified into a diverse range
of 12 categories. To accommodate different document lengths, MahaNews comprises
three supervised datasets specifically designed for short text, long documents,
and medium paragraphs. The consistent labeling across these datasets
facilitates document length-based analysis. We provide detailed data statistics
and baseline results on these datasets using state-of-the-art pre-trained BERT
models. We conduct a comparative analysis between monolingual and multilingual
BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
model outperforms all others on every dataset. These resources also serve as
Marathi topic classification datasets or models and are publicly available at
https://github.com/l3cube-pune/MarathiNLP .

摘要：在低資源馬拉地語中，文本或主題分類資料集的可用性有限，通常包含少於 4 個目標標籤，有些標籤的準確度接近完美。在這項工作中，我們引入了 L3Cube-MahaNews，一個專注於新聞標題和文章的馬拉地語文本分類語料庫。這個語料庫是最大的監督式馬拉地語語料庫，包含超過 1.05L 條記錄，分類為 12 個不同的類別。為了容納不同的文件長度，MahaNews 包含三個特別針對短文本、長文件和中等段落設計的監督式資料集。這些資料集之間的一致標籤有助於基於文件長度的分析。我們使用最先進的預訓練 BERT 模型，提供這些資料集的詳細資料統計和基準結果。我們對單語和多語 BERT 模型（包括 MahaBERT、IndicBERT 和 MuRIL）進行了比較分析。單語 MahaBERT 模型在每個資料集上的表現都優於其他模型。這些資源也可用作馬拉地語主題分類資料集或模型，並在 https://github.com/l3cube-pune/MarathiNLP 上公開提供。

##### **Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**
2404.18214v1 by Zeyu Hu,Yuzhi Xiao,Tao Huang,Xuanrong Huo

Sequential recommendation is one of the important branches of recommender
system, aiming to achieve personalized recommended items for the future through
the analysis and prediction of users' ordered historical interactive behaviors.
However, along with the growth of the user volume and the increasingly rich
behavioral information, how to understand and disentangle the user's
interactive multi-intention effectively also poses challenges to behavior
prediction and sequential recommendation. In light of these challenges, we
propose a Contrastive Learning sequential recommendation method based on
Multi-Intention Disentanglement (MIDCL). In our work, intentions are recognized
as dynamic and diverse, and user behaviors are often driven by current
multi-intentions, which means that the model needs to not only mine the most
relevant implicit intention for each user, but also impair the influence from
irrelevant intentions. Therefore, we choose Variational Auto-Encoder (VAE) to
realize the disentanglement of users' multi-intentions, and propose two types
of contrastive learning paradigms for finding the most relevant user's
interactive intention, and maximizing the mutual information of positive sample
pairs, respectively. Experimental results show that MIDCL not only has
significant superiority over most existing baseline methods, but also brings a
more interpretable case to the research about intention-based prediction and
recommendation.

摘要：序貫推薦是推薦系統中重要的分支之一，旨在透過分析和預測使用者已排序的歷史互動行為，為未來達成個人化的推薦項目。然而，隨著使用者數量成長和行為資訊日益豐富，如何理解和有效解開使用者的互動多意圖也對行為預測和序貫推薦構成挑戰。有鑑於這些挑戰，我們提出基於多意圖解開（MIDCL）的對比學習序貫推薦方法。在我們的研究中，意圖被視為動態且多樣，而使用者行為通常是由當前的多重意圖驅動，這表示模型不僅需要針對每位使用者挖掘最相關的隱含意圖，還要損害不相關意圖的影響。因此，我們選擇變異自動編碼器（VAE）來實現使用者多重意圖的解開，並提出兩種對比學習範例，分別用於找出最相關使用者的互動意圖，以及最大化正樣本對的互資訊。實驗結果顯示，MIDCL 不僅顯著優於現有的大多數基準方法，也為基於意圖的預測和推薦的研究帶來更具可解釋性的案例。

##### **S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**
2404.18213v1 by Guanchun Wang,Xiangrong Zhang,Zelin Peng,Tianyang Zhang,Xiuping Jia,Licheng Jiao

Land cover analysis using hyperspectral images (HSI) remains an open problem
due to their low spatial resolution and complex spectral information. Recent
studies are primarily dedicated to designing Transformer-based architectures
for spatial-spectral long-range dependencies modeling, which is computationally
expensive with quadratic complexity. Selective structured state space model
(Mamba), which is efficient for modeling long-range dependencies with linear
complexity, has recently shown promising progress. However, its potential in
hyperspectral image processing that requires handling numerous spectral bands
has not yet been explored. In this paper, we innovatively propose S$^2$Mamba, a
spatial-spectral state space model for hyperspectral image classification, to
excavate spatial-spectral contextual features, resulting in more efficient and
accurate land cover analysis. In S$^2$Mamba, two selective structured state
space models through different dimensions are designed for feature extraction,
one for spatial, and the other for spectral, along with a spatial-spectral
mixture gate for optimal fusion. More specifically, S$^2$Mamba first captures
spatial contextual relations by interacting each pixel with its adjacent
through a Patch Cross Scanning module and then explores semantic information
from continuous spectral bands through a Bi-directional Spectral Scanning
module. Considering the distinct expertise of the two attributes in homogenous
and complicated texture scenes, we realize the Spatial-spectral Mixture Gate by
a group of learnable matrices, allowing for the adaptive incorporation of
representations learned across different dimensions. Extensive experiments
conducted on HSI classification benchmarks demonstrate the superiority and
prospect of S$^2$Mamba. The code will be available at:
https://github.com/PURE-melo/S2Mamba.

摘要：使用高光谱图像 (HSI) 进行土地覆盖分析仍然是一个开放性问题，因为它们的空间分辨率低且光谱信息复杂。最近的研究主要致力于设计基于 Transformer 的架构，用于建模时空光谱长程依赖性，这在计算上很昂贵，具有二次复杂度。选择性结构化状态空间模型 (Mamba) 对于使用线性复杂度建模长程依赖性很有效，最近显示出了有希望的进展。然而，其在需要处理大量光谱波段的高光谱图像处理中的潜力尚未得到探索。在本文中，我们创新性地提出了 S$^2$Mamba，一种用于高光谱图像分类的时空状态空间模型，以挖掘时空光谱上下文特征，从而实现更高效、更准确的土地覆盖分析。在 S$^2$Mamba 中，通过不同的维度设计了两个选择性结构化状态空间模型用于特征提取，一个用于空间，另一个用于光谱，以及一个用于优化融合的时空光谱混合门。更具体地说，S$^2$Mamba 首先通过 Patch Cross Scanning 模块使每个像素与其相邻像素交互，从而捕获空间上下文关系，然后通过双向光谱扫描模块探索来自连续光谱波段的语义信息。考虑到两种属性在同质和复杂纹理场景中的不同专业知识，我们通过一组可学习的矩阵实现了时空混合门，从而允许自适应地合并跨不同维度学习的表示。在 HSI 分类基准上进行的广泛实验证明了 S$^2$Mamba 的优越性和前景。代码将在以下位置提供：https://github.com/PURE-melo/S2Mamba。

##### **Paint by Inpaint: Learning to Add Image Objects by Removing Them First**
2404.18212v1 by Navve Wasserman,Noam Rotstein,Roy Ganz,Ron Kimmel

Image editing has advanced significantly with the introduction of
text-conditioned diffusion models. Despite this progress, seamlessly adding
objects to images based on textual instructions without requiring user-provided
input masks remains a challenge. We address this by leveraging the insight that
removing objects (Inpaint) is significantly simpler than its inverse process of
adding them (Paint), attributed to the utilization of segmentation mask
datasets alongside inpainting models that inpaint within these masks.
Capitalizing on this realization, by implementing an automated and extensive
pipeline, we curate a filtered large-scale image dataset containing pairs of
images and their corresponding object-removed versions. Using these pairs, we
train a diffusion model to inverse the inpainting process, effectively adding
objects into images. Unlike other editing datasets, ours features natural
target images instead of synthetic ones; moreover, it maintains consistency
between source and target by construction. Additionally, we utilize a large
Vision-Language Model to provide detailed descriptions of the removed objects
and a Large Language Model to convert these descriptions into diverse,
natural-language instructions. We show that the trained model surpasses
existing ones both qualitatively and quantitatively, and release the
large-scale dataset alongside the trained models for the community.

摘要：隨著文字條件擴散模型的引入，影像編輯已大幅進展。儘管有此進展，根據文字說明無縫地將物件新增至影像中，且不需要使用者提供的輸入遮罩，仍是一項挑戰。我們透過利用以下見解來解決此問題：移除物件（Inpaint）顯著地比其反向新增過程（Paint）來得簡單，這要歸功於利用分割遮罩資料集以及在這些遮罩內進行 Inpaint 的 Inpaint 模型。透過實作自動且廣泛的管線，我們利用此認知，策劃一個經過濾的大規模影像資料集，其中包含一對影像及其對應的移除物件版本。使用這些配對，我們訓練一個擴散模型來反轉 Inpaint 程序，有效地將物件新增至影像中。與其他編輯資料集不同，我們的資料集採用自然目標影像，而非合成影像；此外，它透過建構來維持來源和目標之間的一致性。此外，我們利用一個大型視覺語言模型來提供移除物件的詳細描述，並利用一個大型語言模型將這些描述轉換為多樣化、自然的語言說明。我們證明訓練好的模型在質量和數量上都超越現有的模型，並為社群釋出大型資料集以及訓練好的模型。

##### **LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**
2404.18203v1 by Zicheng Zhang,Haoning Wu,Yingjie Zhou,Chunyi Li,Wei Sun,Chaofeng Chen,Xiongkuo Min,Xiaohong Liu,Weisi Lin,Guangtao Zhai

Although large multi-modality models (LMMs) have seen extensive exploration
and application in various quality assessment studies, their integration into
Point Cloud Quality Assessment (PCQA) remains unexplored. Given LMMs'
exceptional performance and robustness in low-level vision and quality
assessment tasks, this study aims to investigate the feasibility of imparting
PCQA knowledge to LMMs through text supervision. To achieve this, we transform
quality labels into textual descriptions during the fine-tuning phase, enabling
LMMs to derive quality rating logits from 2D projections of point clouds. To
compensate for the loss of perception in the 3D domain, structural features are
extracted as well. These quality logits and structural features are then
combined and regressed into quality scores. Our experimental results affirm the
effectiveness of our approach, showcasing a novel integration of LMMs into PCQA
that enhances model understanding and assessment accuracy. We hope our
contributions can inspire subsequent investigations into the fusion of LMMs
with PCQA, fostering advancements in 3D visual quality analysis and beyond.

摘要：儘管大型多模態模型 (LMM) 已在各種品質評估研究中廣泛探討和應用，但它們與點雲品質評估 (PCQA) 的整合仍未開發。鑑於 LMM 在低階視覺和品質評估任務中的卓越效能和穩健性，本研究旨在探討透過文字監督將 PCQA 知識傳授給 LMM 的可行性。為達成此目的，我們在微調階段將品質標籤轉換為文字說明，讓 LMM 能從點雲的 2D 投影中推導出品質評分對數。為了彌補在 3D 領域中感知力的損失，也萃取了結構特徵。這些品質對數和結構特徵隨後會組合並回歸到品質分數中。我們的實驗結果肯定了我們方法的有效性，展示了 LMM 與 PCQA 的創新整合，可增強模型理解和評估準確度。我們希望我們的貢獻能激勵後續對 LMM 與 PCQA 融合的研究，促進 3D 視覺品質分析及其他領域的進展。

##### **WorldGPT: Empowering LLM as Multimodal World Model**
2404.18202v1 by Zhiqi Ge,Hongzhe Huang,Mingze Zhou,Juncheng Li,Guoming Wang,Siliang Tang,Yueting Zhuang

World models are progressively being employed across diverse fields,
extending from basic environment simulation to complex scenario construction.
However, existing models are mainly trained on domain-specific states and
actions, and confined to single-modality state representations. In this paper,
We introduce WorldGPT, a generalist world model built upon Multimodal Large
Language Model (MLLM). WorldGPT acquires an understanding of world dynamics
through analyzing millions of videos across various domains. To further enhance
WorldGPT's capability in specialized scenarios and long-term tasks, we have
integrated it with a novel cognitive architecture that combines memory
offloading, knowledge retrieval, and context reflection. As for evaluation, we
build WorldNet, a multimodal state transition prediction benchmark encompassing
varied real-life scenarios. Conducting evaluations on WorldNet directly
demonstrates WorldGPT's capability to accurately model state transition
patterns, affirming its effectiveness in understanding and predicting the
dynamics of complex scenarios. We further explore WorldGPT's emerging potential
in serving as a world simulator, helping multimodal agents generalize to
unfamiliar domains through efficiently synthesising multimodal instruction
instances which are proved to be as reliable as authentic data for fine-tuning
purposes. The project is available on
\url{https://github.com/DCDmllm/WorldGPT}.

摘要：世界模型正逐漸應用於各個領域，
從基本的環境模擬延伸到複雜的場景建構。
然而，現有的模型主要訓練於特定領域的狀態和
動作，並侷限於單一模式的狀態表示。在本文中，
我們介紹 WorldGPT，一個建立在多模態大型
語言模型 (MLLM) 上的泛用世界模型。WorldGPT 通過
分析來自不同領域的數百萬個影片，獲得對世界動態的理解。為了進一步增強
WorldGPT 在特定場景和長期任務中的能力，我們已
將其與一種新穎的認知架構整合在一起，該架構結合了記憶
卸載、知識檢索和上下文反思。至於評估，我們
建構了 WorldNet，一個包含各種真實生活場景的多模態狀態轉換預測基準。在 WorldNet 上進行評估直接
證明了 WorldGPT 準確建模狀態轉換
模式的能力，肯定了其在理解和預測複雜場景動態方面的有效性。我們進一步探索了 WorldGPT 作為世界模擬器的潛力，幫助多模態代理概括到
不熟悉的領域，通過有效地綜合多模態指令
實例，這些實例被證明與用於微調的真實數據一樣可靠
目的。該專案可在
\url{https://github.com/DCDmllm/WorldGPT} 上取得。

##### **Exploring the Robustness of In-Context Learning with Noisy Labels**
2404.18191v1 by Chen Cheng,Xinzhi Yu,Haodong Wen,Jinsong Sun,Guanzhang Yue,Yihao Zhang,Zeming Wei

Recently, the mysterious In-Context Learning (ICL) ability exhibited by
Transformer architectures, especially in large language models (LLMs), has
sparked significant research interest. However, the resilience of Transformers'
in-context learning capabilities in the presence of noisy samples, prevalent in
both training corpora and prompt demonstrations, remains underexplored. In this
paper, inspired by prior research that studies ICL ability using simple
function classes, we take a closer look at this problem by investigating the
robustness of Transformers against noisy labels. Specifically, we first conduct
a thorough evaluation and analysis of the robustness of Transformers against
noisy labels during in-context learning and show that they exhibit notable
resilience against diverse types of noise in demonstration labels. Furthermore,
we delve deeper into this problem by exploring whether introducing noise into
the training set, akin to a form of data augmentation, enhances such robustness
during inference, and find that such noise can indeed improve the robustness of
ICL. Overall, our fruitful analysis and findings provide a comprehensive
understanding of the resilience of Transformer models against label noises
during ICL and provide valuable insights into the research on Transformers in
natural language processing. Our code is available at
https://github.com/InezYu0928/in-context-learning.

摘要：最近，变压器架构所展现的神秘的上下文学习 (ICL) 能力，尤其是在大型语言模型 (LLM) 中，引起了重大的研究兴趣。然而，变压器在嘈杂样本（在训练语料库和提示演示中普遍存在）存在的情况下，其上下文学习能力的弹性仍然未得到充分探索。在本文中，受先前研究的启发，该研究使用简单的函数类研究了 ICL 能力，我们通过调查变压器对噪声标签的鲁棒性来仔细研究这个问题。具体来说，我们首先对变压器在上下文学习过程中对噪声标签的鲁棒性进行彻底的评估和分析，并表明它们对演示标签中不同类型的噪声表现出显着的弹性。此外，我们通过探索将噪声引入训练集（类似于一种数据增强）是否会增强推理过程中的这种鲁棒性来深入研究这个问题，并发现这种噪声确实可以提高 ICL 的鲁棒性。总体而言，我们富有成效的分析和发现提供了对变压器模型在 ICL 期间对标签噪声的弹性的全面理解，并为自然语言处理中变压器的研究提供了有价值的见解。我们的代码可在 https://github.com/InezYu0928/in-context-learning 获得。

##### **Ranked List Truncation for Large Language Model-based Re-Ranking**
2404.18185v1 by Chuan Meng,Negar Arabzadeh,Arian Askari,Mohammad Aliannejadi,Maarten de Rijke

We study ranked list truncation (RLT) from a novel "retrieve-then-re-rank"
perspective, where we optimize re-ranking by truncating the retrieved list
(i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
improve re-ranking efficiency by sending variable-length candidate lists to a
re-ranker on a per-query basis. It also has the potential to improve re-ranking
effectiveness. Despite its importance, there is limited research into applying
RLT methods to this new perspective. To address this research gap, we reproduce
existing RLT methods in the context of re-ranking, especially newly emerged
large language model (LLM)-based re-ranking. In particular, we examine to what
extent established findings on RLT for retrieval are generalizable to the
"retrieve-then-re-rank" setup from three perspectives: (i) assessing RLT
methods in the context of LLM-based re-ranking with lexical first-stage
retrieval, (ii) investigating the impact of different types of first-stage
retrievers on RLT methods, and (iii) investigating the impact of different
types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
context of re-ranking.

摘要：<paragraph>我們從新穎的「先擷取後重新排序」觀點研究排序清單截斷 (RLT)，我們透過截斷擷取的清單（即，修剪重新排序的候選名單）來最佳化重新排序。RLT 對於重新排序至關重要，因為它能透過根據每個查詢將長度可變的候選清單傳送給重新排序器，來提升重新排序的效率。它也有潛力提升重新排序的效能。儘管 RLT 很重要，但將 RLT 方法應用於此新觀點的研究卻很有限。為了解決這個研究缺口，我們在重新排序的脈絡中複製現有的 RLT 方法，特別是新興的大語言模型 (LLM) 為基礎的重新排序。特別地，我們探討了既有的 RLT 擷取結果在多大程度上能概括到「先擷取後重新排序」的設定，並從三個觀點進行探討：(i) 在基於 LLM 的重新排序中評估 RLT 方法，並搭配詞彙第一階段擷取，(ii) 調查不同類型的第一階段擷取器對 RLT 方法的影響，以及 (iii) 調查不同類型的重新排序器對 RLT 方法的影響。我們在 TREC 2019 和 2020 深度學習軌道上執行實驗，調查了 8 種 RLT 方法，這些方法包含了涉及 3 個擷取器和 2 個重新排序器的管線。我們在重新排序的脈絡中獲得了對 RLT 方法的新見解。</paragraph>

##### **EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**
2404.18180v1 by Comfort Eseohen Ilevbare,Jesujoba O. Alabi,David Ifeoluwa Adelani,Firdous Damilola Bakare,Oluwatoyin Bunmi Abiola,Oluwaseyi Adesina Adeyemo

Nigerians have a notable online presence and actively discuss political and
topical matters. This was particularly evident throughout the 2023 general
election, where Twitter was used for campaigning, fact-checking and
verification, and even positive and negative discourse. However, little or none
has been done in the detection of abusive language and hate speech in Nigeria.
In this paper, we curated code-switched Twitter data directed at three
musketeers of the governorship election on the most populous and economically
vibrant state in Nigeria; Lagos state, with the view to detect offensive speech
in political discussions. We developed EkoHate -- an abusive language and hate
speech dataset for political discussions between the three candidates and their
followers using a binary (normal vs offensive) and fine-grained four-label
annotation scheme. We analysed our dataset and provided an empirical evaluation
of state-of-the-art methods across both supervised and cross-lingual transfer
learning settings. In the supervised setting, our evaluation results in both
binary and four-label annotation schemes show that we can achieve 95.1 and 70.3
F1 points respectively. Furthermore, we show that our dataset adequately
transfers very well to three publicly available offensive datasets (OLID,
HateUS2020, and FountaHate), generalizing to political discussions in other
regions like the US.

摘要：尼日利亞人具有顯著的網路存在，並且積極討論政治和時事話題。這在 2023 年大選期間特別明顯，當時推特被用於競選、查核事實和驗證，甚至正面和負面的討論。然而，在尼日利亞幾乎沒有或根本沒有人檢測到網路霸凌和仇恨言論。在本文中，我們整理了針對尼日利亞人口最多、經濟最活躍的拉哥斯州州長選舉的三位候選人的程式碼轉換推特資料，目的是檢測政治討論中的攻擊性言論。我們開發了 EkoHate，一個針對三位候選人及其追隨者之間的政治討論的網路霸凌和仇恨言論資料集，使用二元（正常與攻擊性）和細粒度四標籤註解方案。我們分析了我們的資料集，並對監督式和跨語言轉移學習設定中的最先進方法提供了經驗評估。在監督式設定中，我們的評估結果在二元和四標籤註解方案中顯示，我們分別可以達到 95.1 和 70.3 的 F1 點數。此外，我們證明我們的資料集充分轉移到三個公開可用的攻擊性資料集（OLID、HateUS2020 和 FountaHate），並推廣到其他地區（如美國）的政治討論。

