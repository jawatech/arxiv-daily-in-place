{"2412.02259": {"publish_time": "2024-12-03", "title": "VideoGen-of-Thought: A Collaborative Framework for Multi-Shot Video Generation", "paper_summary": "Current video generation models excel at generating short clips but still\nstruggle with creating multi-shot, movie-like videos. Existing models trained\non large-scale data on the back of rich computational resources are\nunsurprisingly inadequate for maintaining a logical storyline and visual\nconsistency across multiple shots of a cohesive script since they are often\ntrained with a single-shot objective. To this end, we propose\nVideoGen-of-Thought (VGoT), a collaborative and training-free architecture\ndesigned specifically for multi-shot video generation. VGoT is designed with\nthree goals in mind as follows. Multi-Shot Video Generation: We divide the\nvideo generation process into a structured, modular sequence, including (1)\nScript Generation, which translates a curt story into detailed prompts for each\nshot; (2) Keyframe Generation, responsible for creating visually consistent\nkeyframes faithful to character portrayals; and (3) Shot-Level Video\nGeneration, which transforms information from scripts and keyframes into shots;\n(4) Smoothing Mechanism that ensures a consistent multi-shot output. Reasonable\nNarrative Design: Inspired by cinematic scriptwriting, our prompt generation\napproach spans five key domains, ensuring logical consistency, character\ndevelopment, and narrative flow across the entire video. Cross-Shot\nConsistency: We ensure temporal and identity consistency by leveraging\nidentity-preserving (IP) embeddings across shots, which are automatically\ncreated from the narrative. Additionally, we incorporate a cross-shot smoothing\nmechanism, which integrates a reset boundary that effectively combines latent\nfeatures from adjacent shots, resulting in smooth transitions and maintaining\nvisual coherence throughout the video. Our experiments demonstrate that VGoT\nsurpasses existing video generation methods in producing high-quality,\ncoherent, multi-shot videos.", "paper_summary_zh": "<paragraph>\u7576\u524d\u7684\u5f71\u7247\u751f\u6210\u6a21\u578b\u64c5\u9577\u751f\u6210\u77ed\u7247\u6bb5\uff0c\u4f46\u4ecd\u96e3\u4ee5\u88fd\u4f5c\u591a\u93e1\u982d\u3001\u96fb\u5f71\u822c\u7684\u5f71\u7247\u3002\u73fe\u6709\u7684\u6a21\u578b\u5728\u5927\u91cf\u7684\u8cc7\u6599\u8a13\u7df4\u4e0b\uff0c\u4ef0\u8cf4\u65bc\u8c50\u5bcc\u7684\u904b\u7b97\u8cc7\u6e90\uff0c\u4e0d\u8db3\u4ee5\u7dad\u6301\u908f\u8f2f\u6545\u4e8b\u7dda\u548c\u8996\u89ba\u4e00\u81f4\u6027\u8cab\u7a7f\u65bc\u4e00\u500b\u9023\u8cab\u5287\u672c\u7684\u591a\u500b\u93e1\u982d\u4e2d\uff0c\u56e0\u70ba\u5b83\u5011\u901a\u5e38\u662f\u4f7f\u7528\u55ae\u93e1\u982d\u76ee\u6a19\u8a13\u7df4\u7684\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa VideoGen-of-Thought (VGoT)\uff0c\u4e00\u7a2e\u5c08\u9580\u70ba\u591a\u93e1\u982d\u5f71\u7247\u751f\u6210\u8a2d\u8a08\u7684\u5354\u4f5c\u5f0f\u4e14\u7121\u9700\u8a13\u7df4\u7684\u67b6\u69cb\u3002VGoT \u7684\u8a2d\u8a08\u8003\u91cf\u4e86\u4ee5\u4e0b\u4e09\u500b\u76ee\u6a19\u3002\u591a\u93e1\u982d\u5f71\u7247\u751f\u6210\uff1a\u6211\u5011\u5c07\u5f71\u7247\u751f\u6210\u904e\u7a0b\u5283\u5206\u70ba\u4e00\u500b\u7d50\u69cb\u5316\u7684\u6a21\u7d44\u5316\u9806\u5e8f\uff0c\u5305\u62ec\uff1a(1) \u5287\u672c\u751f\u6210\uff0c\u5c07\u7c21\u77ed\u7684\u6545\u4e8b\u8f49\u63db\u70ba\u6bcf\u500b\u93e1\u982d\u7684\u8a73\u7d30\u63d0\u793a\uff1b(2) \u95dc\u9375\u5f71\u683c\u751f\u6210\uff0c\u8ca0\u8cac\u88fd\u4f5c\u8996\u89ba\u4e00\u81f4\u4e14\u5fe0\u65bc\u89d2\u8272\u63cf\u7e6a\u7684\u95dc\u9375\u5f71\u683c\uff1b(3) \u93e1\u982d\u7d1a\u5f71\u7247\u751f\u6210\uff0c\u5c07\u8173\u672c\u548c\u95dc\u9375\u5f71\u683c\u4e2d\u7684\u8cc7\u8a0a\u8f49\u63db\u70ba\u93e1\u982d\uff1b(4) \u5e73\u6ed1\u6a5f\u5236\uff0c\u78ba\u4fdd\u4e00\u81f4\u7684\u591a\u93e1\u982d\u8f38\u51fa\u3002\u5408\u7406\u7684\u6558\u4e8b\u8a2d\u8a08\uff1a\u6211\u5011\u7684\u63d0\u793a\u751f\u6210\u65b9\u6cd5\u53d7\u5230\u96fb\u5f71\u5287\u672c\u5beb\u4f5c\u7684\u555f\u767c\uff0c\u6db5\u84cb\u4e86\u4e94\u500b\u95dc\u9375\u9818\u57df\uff0c\u78ba\u4fdd\u6574\u500b\u5f71\u7247\u7684\u908f\u8f2f\u4e00\u81f4\u6027\u3001\u89d2\u8272\u767c\u5c55\u548c\u6558\u4e8b\u6d41\u66a2\u3002\u8de8\u93e1\u982d\u4e00\u81f4\u6027\uff1a\u6211\u5011\u900f\u904e\u93e1\u982d\u9593\u7684\u6046\u7b49\u6027\u4fdd\u7559 (IP) \u5d4c\u5165\u4f86\u78ba\u4fdd\u6642\u9593\u548c\u8eab\u5206\u4e00\u81f4\u6027\uff0c\u9019\u4e9b\u5d4c\u5165\u6703\u81ea\u52d5\u5f9e\u6558\u4e8b\u4e2d\u5efa\u7acb\u3002\u6b64\u5916\uff0c\u6211\u5011\u7d0d\u5165\u4e00\u500b\u8de8\u93e1\u982d\u5e73\u6ed1\u6a5f\u5236\uff0c\u6574\u5408\u4e00\u500b\u91cd\u7f6e\u908a\u754c\uff0c\u6709\u6548\u5730\u7d50\u5408\u76f8\u9130\u93e1\u982d\u7684\u6f5b\u5728\u7279\u5fb5\uff0c\u7522\u751f\u5e73\u6ed1\u7684\u904e\u6e21\u4e26\u5728\u6574\u500b\u5f71\u7247\u4e2d\u7dad\u6301\u8996\u89ba\u4e00\u81f4\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0cVGoT \u5728\u88fd\u4f5c\u9ad8\u54c1\u8cea\u3001\u9023\u8cab\u3001\u591a\u93e1\u982d\u5f71\u7247\u65b9\u9762\u8d85\u8d8a\u4e86\u73fe\u6709\u7684\u5f71\u7247\u751f\u6210\u65b9\u6cd5\u3002</paragraph>", "author": "Mingzhe Zheng et.al.", "authors": "Mingzhe Zheng, Yongqi Xu, Haojian Huang, Xuran Ma, Yexin Liu, Wenjie Shu, Yatian Pang, Feilong Tang, Qifeng Chen, Harry Yang, Ser-Nam Lim", "id": "2412.02259v1", "paper_url": "http://arxiv.org/abs/2412.02259v1", "repo": "null"}}