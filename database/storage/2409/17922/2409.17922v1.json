{"2409.17922": {"publish_time": "2024-09-26", "title": "Navigation in a simplified Urban Flow through Deep Reinforcement Learning", "paper_summary": "The increasing number of unmanned aerial vehicles (UAVs) in urban\nenvironments requires a strategy to minimize their environmental impact, both\nin terms of energy efficiency and noise reduction. In order to reduce these\nconcerns, novel strategies for developing prediction models and optimization of\nflight planning, for instance through deep reinforcement learning (DRL), are\nneeded. Our goal is to develop DRL algorithms capable of enabling the\nautonomous navigation of UAVs in urban environments, taking into account the\npresence of buildings and other UAVs, optimizing the trajectories in order to\nreduce both energetic consumption and noise. This is achieved using fluid-flow\nsimulations which represent the environment in which UAVs navigate and training\nthe UAV as an agent interacting with an urban environment. In this work, we\nconsider a domain domain represented by a two-dimensional flow field with\nobstacles, ideally representing buildings, extracted from a three-dimensional\nhigh-fidelity numerical simulation. The presented methodology, using PPO+LSTM\ncells, was validated by reproducing a simple but fundamental problem in\nnavigation, namely the Zermelo's problem, which deals with a vessel navigating\nin a turbulent flow, travelling from a starting point to a target location,\noptimizing the trajectory. The current method shows a significant improvement\nwith respect to both a simple PPO and a TD3 algorithm, with a success rate (SR)\nof the PPO+LSTM trained policy of 98.7%, and a crash rate (CR) of 0.1%,\noutperforming both PPO (SR = 75.6%, CR=18.6%) and TD3 (SR=77.4% and CR=14.5%).\nThis is the first step towards DRL strategies which will guide UAVs in a\nthree-dimensional flow field using real-time signals, making the navigation\nefficient in terms of flight time and avoiding damages to the vehicle.", "paper_summary_zh": "\u96a8\u8457\u57ce\u5e02\u74b0\u5883\u4e2d\u7121\u4eba\u6a5f\uff08UAV\uff09\u6578\u91cf\u7684\u4e0d\u65b7\u589e\u52a0\uff0c\u9700\u8981\u4e00\u7a2e\u7b56\u7565\u4f86\u6700\u5927\u7a0b\u5ea6\u5730\u6e1b\u5c11\u5176\u74b0\u5883\u5f71\u97ff\uff0c\u7121\u8ad6\u662f\u5728\u80fd\u6e90\u6548\u7387\u9084\u662f\u964d\u566a\u65b9\u9762\u3002\u70ba\u4e86\u6e1b\u5c11\u9019\u4e9b\u554f\u984c\uff0c\u9700\u8981\u63a1\u7528\u65b0\u7684\u7b56\u7565\u4f86\u958b\u767c\u9810\u6e2c\u6a21\u578b\u548c\u512a\u5316\u98db\u884c\u898f\u5283\uff0c\u4f8b\u5982\u901a\u904e\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2\uff08DRL\uff09\u3002\u6211\u5011\u7684\u76ee\u6a19\u662f\u958b\u767c DRL \u6f14\u7b97\u6cd5\uff0c\u4f7f\u7121\u4eba\u6a5f\u80fd\u5920\u5728\u57ce\u5e02\u74b0\u5883\u4e2d\u81ea\u4e3b\u5c0e\u822a\uff0c\u540c\u6642\u8003\u616e\u5efa\u7bc9\u7269\u548c\u5176\u4ed6\u7121\u4eba\u6a5f\u7684\u5b58\u5728\uff0c\u512a\u5316\u8ecc\u8de1\u4ee5\u6e1b\u5c11\u80fd\u91cf\u6d88\u8017\u548c\u566a\u97f3\u3002\u9019\u662f\u901a\u904e\u4f7f\u7528\u6d41\u9ad4\u6d41\u52d5\u6a21\u64ec\u4f86\u5be6\u73fe\u7684\uff0c\u8a72\u6a21\u64ec\u8868\u793a\u7121\u4eba\u6a5f\u5c0e\u822a\u7684\u74b0\u5883\uff0c\u4e26\u5c07\u7121\u4eba\u6a5f\u8a13\u7df4\u70ba\u8207\u57ce\u5e02\u74b0\u5883\u4ea4\u4e92\u7684\u4ee3\u7406\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8003\u616e\u4e86\u4e00\u500b\u7531\u5177\u6709\u969c\u7919\u7269\u7684\u4e8c\u7dad\u6d41\u5834\u8868\u793a\u7684\u57df\uff0c\u9019\u4e9b\u969c\u7919\u7269\u7406\u60f3\u5730\u8868\u793a\u5efa\u7bc9\u7269\uff0c\u4e26\u5f9e\u4e09\u7dad\u9ad8\u4fdd\u771f\u6578\u503c\u6a21\u64ec\u4e2d\u63d0\u53d6\u3002\u4f7f\u7528 PPO+LSTM \u55ae\u5143\u7684\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u904e\u91cd\u73fe\u5c0e\u822a\u4e2d\u4e00\u500b\u7c21\u55ae\u4f46\u57fa\u672c\u7684\u96e3\u984c\u5f97\u5230\u4e86\u9a57\u8b49\uff0c\u5373 Zermelo \u554f\u984c\uff0c\u8a72\u554f\u984c\u6d89\u53ca\u5728\u6e4d\u6d41\u4e2d\u822a\u884c\u7684\u8239\u96bb\uff0c\u5f9e\u8d77\u9ede\u884c\u99db\u5230\u76ee\u6a19\u4f4d\u7f6e\uff0c\u512a\u5316\u8ecc\u8de1\u3002\u8207\u7c21\u55ae\u7684 PPO \u548c TD3 \u6f14\u7b97\u6cd5\u76f8\u6bd4\uff0c\u7576\u524d\u65b9\u6cd5\u986f\u793a\u51fa\u986f\u8457\u7684\u6539\u9032\uff0cPPO+LSTM \u8a13\u7df4\u7b56\u7565\u7684\u6210\u529f\u7387 (SR) \u70ba 98.7%\uff0c\u5d29\u6f70\u7387 (CR) \u70ba 0.1%\uff0c\u512a\u65bc PPO\uff08SR = 75.6%\uff0cCR=18.6%\uff09\u548c TD3\uff08SR=77.4% \u548c CR=14.5%\uff09\u3002\u9019\u662f\u671d\u8457 DRL \u7b56\u7565\u9081\u51fa\u7684\u7b2c\u4e00\u6b65\uff0c\u8a72\u7b56\u7565\u5c07\u4f7f\u7528\u5be6\u6642\u8a0a\u865f\u5f15\u5c0e\u7121\u4eba\u6a5f\u5728\u4e09\u7dad\u6d41\u5834\u4e2d\uff0c\u5f9e\u800c\u4f7f\u5c0e\u822a\u5728\u98db\u884c\u6642\u9593\u65b9\u9762\u8b8a\u5f97\u9ad8\u6548\uff0c\u4e26\u907f\u514d\u5c0d\u8eca\u8f1b\u9020\u6210\u640d\u58de\u3002", "author": "Federica Tonti et.al.", "authors": "Federica Tonti, Jean Rabault, Ricardo Vinuesa", "id": "2409.17922v1", "paper_url": "http://arxiv.org/abs/2409.17922v1", "repo": "null"}}