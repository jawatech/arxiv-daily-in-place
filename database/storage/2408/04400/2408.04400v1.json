{"2408.04400": {"publish_time": "2024-08-08", "title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization", "paper_summary": "This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.", "paper_summary_zh": "<paragraph>\u9019\u7bc7\u8ad6\u6587\u63a2\u8a0e\u4e86\u5716\u5f62\u6a5f\u5668\u5b78\u7fd2\u4e2d\u975e\u5206\u4f48 (OOD) \u6982\u5316\u7684\u6311\u6230\uff0c\u9019\u662f\u4e00\u500b\u5feb\u901f\u767c\u5c55\u7684\u9818\u57df\uff0c\u4f46\u537b\u5728\u61c9\u5c0d\u4f86\u6e90\u548c\u76ee\u6a19\u8cc7\u6599\u5206\u4f48\u4e4b\u9593\u7684\u5dee\u7570\u4e0a\u9047\u5230\u56f0\u96e3\u3002\u50b3\u7d71\u7684\u5716\u5f62\u5b78\u7fd2\u6f14\u7b97\u6cd5\u57fa\u65bc\u8a13\u7df4\u8cc7\u6599\u548c\u6e2c\u8a66\u8cc7\u6599\u4e4b\u9593\u5747\u52fb\u5206\u4f48\u7684\u5047\u8a2d\uff0c\u4f46\u5728\u9019\u500b\u5047\u8a2d\u5931\u6548\u7684\u5be6\u969b\u60c5\u6cc1\u4e2d\u6703\u51fa\u73fe\u554f\u984c\uff0c\u5c0e\u81f4\u6b21\u4f73\u6548\u80fd\u3002\u9020\u6210\u9019\u7a2e\u6b21\u4f73\u6548\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\u662f\u900f\u904e\u96a8\u6a5f\u68af\u5ea6\u4e0b\u964d (SGD) \u8a13\u7df4\u7684\u795e\u7d93\u7db2\u8def\u56fa\u6709\u7684\u7c21\u5316\u504f\u5dee\uff0c\u5b83\u504f\u597d\u8f03\u7c21\u55ae\u7684\u7279\u5fb5\uff0c\u800c\u975e\u66f4\u8907\u96dc\u4f46\u9810\u6e2c\u80fd\u529b\u76f8\u540c\u6216\u66f4\u9ad8\u7684\u7279\u5fb5\u3002\u9019\u7a2e\u504f\u5dee\u6703\u5c0e\u81f4\u4f9d\u8cf4\u865b\u5047\u76f8\u95dc\u6027\uff0c\u5c0d\u5404\u7a2e\u4efb\u52d9\uff08\u4f8b\u5982\u5f71\u50cf\u8fa8\u8b58\u3001\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u548c\u5716\u5f62\u5206\u985e\uff09\u7684 OOD \u6548\u80fd\u7522\u751f\u8ca0\u9762\u5f71\u97ff\u3002\u76ee\u524d\u7684\u6280\u8853\u65b9\u6cd5\uff0c\u5305\u62ec\u5b50\u5716\u6df7\u5408\u548c\u8cc7\u8a0a\u74f6\u9838\u65b9\u6cd5\uff0c\u5df2\u53d6\u5f97\u90e8\u5206\u6210\u529f\uff0c\u4f46\u4ecd\u96e3\u4ee5\u514b\u670d\u7c21\u5316\u504f\u5dee\uff0c\u800c\u4e14\u5e38\u5e38\u6703\u5f37\u5316\u865b\u5047\u76f8\u95dc\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 DIVE\uff0c\u8a13\u7df4\u4e00\u7d44\u6a21\u578b\u4ee5\u95dc\u6ce8\u6240\u6709\u6a19\u7c64\u9810\u6e2c\u5b50\u5716\uff0c\u65b9\u6cd5\u662f\u9f13\u52f5\u6a21\u578b\u5728\u5b50\u5716\u906e\u7f69\u4e0a\u4fc3\u9032\u5dee\u7570\uff0c\u9019\u907f\u958b\u4e86\u6a21\u578b\u50c5\u95dc\u6ce8\u5c0d\u61c9\u65bc\u7c21\u55ae\u7d50\u69cb\u6a21\u5f0f\u7684\u5b50\u5716\u7684\u9650\u5236\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63a1\u7528\u4e00\u500b\u6b63\u898f\u5316\u5668\u4f86\u61f2\u7f70\u6a21\u578b\u4e4b\u9593\u63d0\u53d6\u7684\u5b50\u5716\u4e2d\u7684\u91cd\u758a\uff0c\u5f9e\u800c\u9f13\u52f5\u4e0d\u540c\u7684\u6a21\u578b\u5c08\u6ce8\u65bc\u4e0d\u540c\u7684\u7d50\u69cb\u6a21\u5f0f\u3002\u900f\u904e\u9a57\u8b49\u6e96\u78ba\u5ea6\uff0c\u53ef\u4ee5\u9078\u64c7\u6a21\u578b\u4ee5\u7372\u5f97\u7a69\u5065\u7684 OOD \u6548\u80fd\u3002\u6211\u5011\u7684\u505a\u6cd5\u5728 GOOD \u57fa\u6e96\u4e2d\u7684\u56db\u500b\u8cc7\u6599\u96c6\u548c DrugOOD \u57fa\u6e96\u4e2d\u7684\u5176\u4e2d\u4e00\u500b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u6e2c\u8a66\uff0c\u7d50\u679c\u986f\u793a\u51fa\u6bd4\u73fe\u6709\u65b9\u6cd5\u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u6709\u6548\u5730\u89e3\u6c7a\u4e86\u7c21\u5316\u504f\u5dee\uff0c\u4e26\u589e\u5f37\u4e86\u5716\u5f62\u6a5f\u5668\u5b78\u7fd2\u4e2d\u7684\u6982\u5316\u80fd\u529b\u3002</paragraph>", "author": "Xin Sun et.al.", "authors": "Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang", "id": "2408.04400v1", "paper_url": "http://arxiv.org/abs/2408.04400v1", "repo": "null"}}