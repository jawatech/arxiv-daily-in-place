{"2409.09628": {"publish_time": "2024-09-15", "title": "Can Large Language Models Grasp Event Signals? Exploring Pure Zero-Shot Event-based Recognition", "paper_summary": "Recent advancements in event-based zero-shot object recognition have\ndemonstrated promising results. However, these methods heavily depend on\nextensive training and are inherently constrained by the characteristics of\nCLIP. To the best of our knowledge, this research is the first study to explore\nthe understanding capabilities of large language models (LLMs) for event-based\nvisual content. We demonstrate that LLMs can achieve event-based object\nrecognition without additional training or fine-tuning in conjunction with\nCLIP, effectively enabling pure zero-shot event-based recognition.\nParticularly, we evaluate the ability of GPT-4o / 4turbo and two other\nopen-source LLMs to directly recognize event-based visual content. Extensive\nexperiments are conducted across three benchmark datasets, systematically\nassessing the recognition accuracy of these models. The results show that LLMs,\nespecially when enhanced with well-designed prompts, significantly improve\nevent-based zero-shot recognition performance. Notably, GPT-4o outperforms the\ncompared models and exceeds the recognition accuracy of state-of-the-art\nevent-based zero-shot methods on N-ImageNet by five orders of magnitude. The\nimplementation of this paper is available at\n\\url{https://github.com/ChrisYu-Zz/Pure-event-based-recognition-based-LLM}.", "paper_summary_zh": "\u6700\u8fd1\u5728\u57fa\u4e8e\u4e8b\u4ef6\u7684\u96f6\u6837\u672c\u7269\u4f53\u8bc6\u522b\u65b9\u9762\u53d6\u5f97\u7684\u8fdb\u5c55\u5c55\u793a\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u4e8e\u5e7f\u6cdb\u7684\u8bad\u7ec3\uff0c\u5e76\u4e14\u672c\u8d28\u4e0a\u53d7\u5230 CLIP \u7279\u6027\u7684\u9650\u5236\u3002\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u9879\u7814\u7a76\u662f\u7b2c\u4e00\u4e2a\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5bf9\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c6\u89c9\u5185\u5bb9\u7684\u7406\u89e3\u80fd\u529b\u7684\u7814\u7a76\u3002\u6211\u4eec\u8bc1\u660e\uff0cLLM \u53ef\u4ee5\u5b9e\u73b0\u57fa\u4e8e\u4e8b\u4ef6\u7684\u7269\u4f53\u8bc6\u522b\uff0c\u800c\u65e0\u9700\u989d\u5916\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u540c\u65f6\u7ed3\u5408 CLIP\uff0c\u4ece\u800c\u6709\u6548\u5730\u5b9e\u73b0\u7eaf\u96f6\u6837\u672c\u57fa\u4e8e\u4e8b\u4ef6\u7684\u8bc6\u522b\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86 GPT-4o / 4turbo \u548c\u5176\u4ed6\u4e24\u4e2a\u5f00\u6e90 LLM \u76f4\u63a5\u8bc6\u522b\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c6\u89c9\u5185\u5bb9\u7684\u80fd\u529b\u3002\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u6a21\u578b\u7684\u8bc6\u522b\u51c6\u786e\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0cLLM\uff0c\u5c24\u5176\u662f\u5728\u7ecf\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u589e\u5f3a\u540e\uff0c\u663e\u7740\u63d0\u9ad8\u4e86\u57fa\u4e8e\u4e8b\u4ef6\u7684\u96f6\u6837\u672c\u8bc6\u522b\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGPT-4o \u4f18\u4e8e\u6bd4\u8f83\u6a21\u578b\uff0c\u5e76\u4e14\u5728 N-ImageNet \u4e0a\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u4e8b\u4ef6\u7684\u96f6\u6837\u672c\u65b9\u6cd5\u7684\u8bc6\u522b\u51c6\u786e\u6027\u4e94\u4e2a\u6570\u91cf\u7ea7\u3002\u672c\u6587\u7684\u5b9e\u73b0\u53ef\u5728 \\url{https://github.com/ChrisYu-Zz/Pure-event-based-recognition-based-LLM} \u4e2d\u627e\u5230\u3002", "author": "Zongyou Yu et.al.", "authors": "Zongyou Yu, Qiang Qu, Xiaoming Chen, Chen Wang", "id": "2409.09628v1", "paper_url": "http://arxiv.org/abs/2409.09628v1", "repo": "https://github.com/chrisyu-zz/pure-event-based-recognition-based-llm"}}