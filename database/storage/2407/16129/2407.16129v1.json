{"2407.16129": {"publish_time": "2024-07-23", "title": "FoRA: Low-Rank Adaptation Model beyond Multimodal Siamese Network", "paper_summary": "Multimodal object detection offers a promising prospect to facilitate robust\ndetection in various visual conditions. However, existing two-stream backbone\nnetworks are challenged by complex fusion and substantial parameter increments.\nThis is primarily due to large data distribution biases of multimodal\nhomogeneous information. In this paper, we propose a novel multimodal object\ndetector, named Low-rank Modal Adaptors (LMA) with a shared backbone. The\nshared parameters enhance the consistency of homogeneous information, while\nlightweight modal adaptors focus on modality unique features. Furthermore, we\ndesign an adaptive rank allocation strategy to adapt to the varying\nheterogeneity at different feature levels. When applied to two multimodal\nobject detection datasets, experiments validate the effectiveness of our\nmethod. Notably, on DroneVehicle, LMA attains a 10.4% accuracy improvement over\nthe state-of-the-art method with a 149M-parameters reduction. The code is\navailable at https://github.com/zyszxhy/FoRA.\n  Our work was submitted to ACM MM in April 2024, but was rejected. We will\ncontinue to refine our work and paper writing next, mainly including proof of\ntheory and multi-task applications of FoRA.", "paper_summary_zh": "\u591a\u6a21\u6001\u7269\u4f53\u68c0\u6d4b\u4e3a\u5728\u5404\u79cd\u89c6\u89c9\u6761\u4ef6\u4e0b\u4fc3\u8fdb\u7a33\u5065\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u524d\u666f\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u53cc\u6d41\u9aa8\u5e72\u7f51\u7edc\u9762\u4e34\u7740\u590d\u6742\u7684\u878d\u5408\u548c\u5927\u91cf\u7684\u53c2\u6570\u589e\u91cf\u3002\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u591a\u6a21\u6001\u540c\u8d28\u4fe1\u606f\u7684\u5de8\u5927\u6570\u636e\u5206\u5e03\u504f\u5dee\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u7269\u4f53\u68c0\u6d4b\u5668\uff0c\u540d\u4e3a\u4f4e\u79e9\u6a21\u6001\u9002\u914d\u5668\uff08LMA\uff09\uff0c\u5b83\u5177\u6709\u5171\u4eab\u7684\u9aa8\u5e72\u3002\u5171\u4eab\u53c2\u6570\u589e\u5f3a\u4e86\u540c\u8d28\u4fe1\u606f\u7684\u7a20\u5bc6\u6027\uff0c\u800c\u8f7b\u91cf\u7ea7\u6a21\u6001\u9002\u914d\u5668\u5219\u4e13\u6ce8\u4e8e\u6a21\u6001\u7684\u72ec\u7279\u7279\u5f81\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u79e9\u5206\u914d\u7b56\u7565\u6765\u9002\u5e94\u4e0d\u540c\u7279\u5f81\u7ea7\u522b\u4e0a\u7684\u4e0d\u540c\u5f02\u8d28\u6027\u3002\u5f53\u5e94\u7528\u4e8e\u4e24\u4e2a\u591a\u6a21\u6001\u7269\u4f53\u68c0\u6d4b\u6570\u636e\u96c6\u65f6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 DroneVehicle \u4e0a\uff0cLMA \u5728\u51cf\u5c11 149M \u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86 10.4% \u7684\u51c6\u786e\u5ea6\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/zyszxhy/FoRA \u83b7\u5f97\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u5df2\u4e8e 2024 \u5e74 4 \u6708\u63d0\u4ea4\u81f3 ACM MM\uff0c\u4f46\u88ab\u62d2\u3002\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u7ee7\u7eed\u5b8c\u5584\u6211\u4eec\u7684\u5de5\u4f5c\u548c\u8bba\u6587\u5199\u4f5c\uff0c\u4e3b\u8981\u5305\u62ec FoRA \u7684\u7406\u8bba\u8bc1\u660e\u548c\u591a\u4efb\u52a1\u5e94\u7528\u3002", "author": "Weiying Xie et.al.", "authors": "Weiying Xie, Yusi Zhang, Tianlin Hui, Jiaqing Zhang, Jie Lei, Yunsong Li", "id": "2407.16129v1", "paper_url": "http://arxiv.org/abs/2407.16129v1", "repo": "https://github.com/zyszxhy/fora"}}