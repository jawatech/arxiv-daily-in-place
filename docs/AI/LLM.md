
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-03**|**Metadata Conditioning Accelerates Language Model Pre-training**|Tianyu Gao et.al.|[2501.01956v1](http://arxiv.org/abs/2501.01956v1)|null|
|**2025-01-03**|**MADGEN -- Mass-Spec attends to De Novo Molecular generation**|Yinkai Wang et.al.|[2501.01950v1](http://arxiv.org/abs/2501.01950v1)|null|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v1](http://arxiv.org/abs/2501.01945v1)|null|
|**2025-01-03**|**Abstractive Text Summarization for Contemporary Sanskrit Prose: Issues and Challenges**|Shagun Sinha et.al.|[2501.01933v1](http://arxiv.org/abs/2501.01933v1)|null|
|**2025-01-03**|**Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding**|Jiaming Li et.al.|[2501.01926v1](http://arxiv.org/abs/2501.01926v1)|null|
|**2025-01-03**|**Mingling with the Good to Backdoor Federated Learning**|Nuno Neves et.al.|[2501.01913v1](http://arxiv.org/abs/2501.01913v1)|null|
|**2025-01-03**|**Virgo: A Preliminary Exploration on Reproducing o1-like MLLM**|Yifan Du et.al.|[2501.01904v1](http://arxiv.org/abs/2501.01904v1)|null|
|**2025-01-03**|**QuArch: A Question-Answering Dataset for AI Agents in Computer Architecture**|Shvetank Prakash et.al.|[2501.01892v1](http://arxiv.org/abs/2501.01892v1)|null|
|**2025-01-03**|**Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions**|Rachneet Sachdeva et.al.|[2501.01872v1](http://arxiv.org/abs/2501.01872v1)|null|
|**2025-01-03**|**LCFed: An Efficient Clustered Federated Learning Framework for Heterogeneous Data**|Yuxin Zhang et.al.|[2501.01850v1](http://arxiv.org/abs/2501.01850v1)|null|
|**2025-01-03**|**Multi-Agent Conversational Online Learning for Adaptive LLM Response Identification**|Xiangxiang Dai et.al.|[2501.01849v1](http://arxiv.org/abs/2501.01849v1)|null|
|**2025-01-03**|**ASKCOS: an open source software suite for synthesis planning**|Zhengkai Tu et.al.|[2501.01835v1](http://arxiv.org/abs/2501.01835v1)|null|
|**2025-01-03**|**MoColl: Agent-Based Specific and General Model Collaboration for Image Captioning**|Pu Yang et.al.|[2501.01834v1](http://arxiv.org/abs/2501.01834v1)|null|
|**2025-01-03**|**Time Series Language Model for Descriptive Caption Generation**|Mohamed Trabelsi et.al.|[2501.01832v1](http://arxiv.org/abs/2501.01832v1)|null|
|**2025-01-03**|**Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models**|Yanjiang Liu et.al.|[2501.01830v1](http://arxiv.org/abs/2501.01830v1)|null|
|**2025-01-03**|**The Proof is in the Almond Cookies**|Remi van Trijp et.al.|[2501.01827v1](http://arxiv.org/abs/2501.01827v1)|null|
|**2025-01-03**|**SDPO: Segment-Level Direct Preference Optimization for Social Agents**|Aobo Kong et.al.|[2501.01821v1](http://arxiv.org/abs/2501.01821v1)|[link](https://github.com/alibabaresearch/damo-convai)|
|**2025-01-03**|**End-to-End Long Document Summarization using Gradient Caching**|Rohit Saxena et.al.|[2501.01805v1](http://arxiv.org/abs/2501.01805v1)|null|
|**2025-01-03**|**BERT4MIMO: A Foundation Model using BERT Architecture for Massive MIMO Channel State Information Prediction**|Ferhat Ozgur Catak et.al.|[2501.01802v1](http://arxiv.org/abs/2501.01802v1)|null|
|**2025-01-03**|**Reading Between the Lines: A dataset and a study on why some texts are tougher than others**|Nouran Khallaf et.al.|[2501.01796v1](http://arxiv.org/abs/2501.01796v1)|null|
|**2025-01-03**|**Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation**|Mohammad Khalil et.al.|[2501.01793v1](http://arxiv.org/abs/2501.01793v1)|null|
|**2025-01-03**|**Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms**|Qinyi Liu et.al.|[2501.01785v1](http://arxiv.org/abs/2501.01785v1)|null|
|**2025-01-03**|**Quantifying A Firm's AI Engagement: Constructing Objective, Data-Driven, AI Stock Indices Using 10-K Filings**|Lennart Ante et.al.|[2501.01763v1](http://arxiv.org/abs/2501.01763v1)|null|
|**2025-01-03**|**Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation**|Kangcheng Luo et.al.|[2501.01743v1](http://arxiv.org/abs/2501.01743v1)|null|
|**2025-01-03**|**How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models**|Simone Corbo et.al.|[2501.01741v1](http://arxiv.org/abs/2501.01741v1)|null|
|**2025-01-03**|**Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item Detection under Noisy Annotations**|Ruikang Chen et.al.|[2501.01733v1](http://arxiv.org/abs/2501.01733v1)|null|
|**2025-01-03**|**LLMs & Legal Aid: Understanding Legal Needs Exhibited Through User Queries**|Michal Kuk et.al.|[2501.01711v1](http://arxiv.org/abs/2501.01711v1)|null|
|**2025-01-03**|**MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders**|Jiajun Cao et.al.|[2501.01709v1](http://arxiv.org/abs/2501.01709v1)|null|
|**2025-01-03**|**The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters**|Chulun Zhou et.al.|[2501.01705v1](http://arxiv.org/abs/2501.01705v1)|null|
|**2025-01-03**|**AgentRefine: Enhancing Agent Generalization through Refinement Tuning**|Dayuan Fu et.al.|[2501.01702v1](http://arxiv.org/abs/2501.01702v1)|null|
|**2025-01-03**|**VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer for Video-based Remote Physiological Measurement**|Jiachen Li et.al.|[2501.01691v1](http://arxiv.org/abs/2501.01691v1)|null|
|**2025-01-03**|**Adaptive Few-shot Prompting for Machine Translation with Pre-trained Language Models**|Lei Tang et.al.|[2501.01679v1](http://arxiv.org/abs/2501.01679v1)|null|
|**2025-01-03**|**CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis**|Bohan Zhang et.al.|[2501.01668v1](http://arxiv.org/abs/2501.01668v1)|null|
|**2025-01-03**|**BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction**|Alaeddine Diaf et.al.|[2501.01664v1](http://arxiv.org/abs/2501.01664v1)|null|
|**2025-01-03**|**EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**|Wang Lituan et.al.|[2501.01658v1](http://arxiv.org/abs/2501.01658v1)|null|
|**2025-01-03**|**MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments**|Cai Yin et.al.|[2501.01652v1](http://arxiv.org/abs/2501.01652v1)|null|
|**2025-01-03**|**AVATAR: Adversarial Autoencoders with Autoregressive Refinement for Time Series Generation**|MohammadReza EskandariNasab et.al.|[2501.01649v1](http://arxiv.org/abs/2501.01649v1)|null|
|**2025-01-03**|**HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding**|Heqing Zou et.al.|[2501.01645v1](http://arxiv.org/abs/2501.01645v1)|null|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|null|
|**2025-01-03**|**A non-ergodic framework for understanding emergent capabilities in Large Language Models**|Javier Marin et.al.|[2501.01638v1](http://arxiv.org/abs/2501.01638v1)|null|
|**2025-01-03**|**Crossing Language Borders: A Pipeline for Indonesian Manhwa Translation**|Nithyasri Narasimhan et.al.|[2501.01629v1](http://arxiv.org/abs/2501.01629v1)|null|
|**2025-01-03**|**ICPC: In-context Prompt Compression with Faster Inference**|Ziyang Yu et.al.|[2501.01625v1](http://arxiv.org/abs/2501.01625v1)|null|
|**2025-01-03**|**Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**|Yun Zhu et.al.|[2501.01618v1](http://arxiv.org/abs/2501.01618v1)|null|
|**2025-01-03**|**Google is all you need: Semi-Supervised Transfer Learning Strategy For Light Multimodal Multi-Task Classification Model**|Haixu Liu et.al.|[2501.01611v1](http://arxiv.org/abs/2501.01611v1)|null|
|**2025-01-03**|**Prism: Mining Task-aware Domains in Non-i.i.d. IMU Data for Flexible User Perception**|Yunzhe Li et.al.|[2501.01598v1](http://arxiv.org/abs/2501.01598v1)|null|
|**2025-01-03**|**PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**|Jingoo Lee et.al.|[2501.01594v1](http://arxiv.org/abs/2501.01594v1)|null|
|**2025-01-03**|**(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges**|Mohamed Hisham Abdellatif et.al.|[2501.01588v1](http://arxiv.org/abs/2501.01588v1)|null|
|**2025-01-02**|**Constructing and explaining machine learning models for chemistry: example of the exploration and design of boron-based Lewis acids**|Juliette Fenogli et.al.|[2501.01576v1](http://arxiv.org/abs/2501.01576v1)|null|
|**2025-01-02**|**Predicting the Performance of Black-box LLMs through Self-Queries**|Dylan Sam et.al.|[2501.01558v1](http://arxiv.org/abs/2501.01558v1)|null|
|**2025-01-02**|**Many of Your DPOs are Secretly One: Attempting Unification Through Mutual Information**|Rasul Tutnov et.al.|[2501.01544v1](http://arxiv.org/abs/2501.01544v1)|null|
|**2025-01-02**|**BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery**|Kanishk Gandhi et.al.|[2501.01540v1](http://arxiv.org/abs/2501.01540v1)|null|
|**2025-01-02**|**Improving Robustness Estimates in Natural Language Explainable AI though Synonymity Weighted Similarity Measures**|Christopher Burger et.al.|[2501.01516v1](http://arxiv.org/abs/2501.01516v1)|null|
|**2025-01-02**|**DiagrammaticLearning: A Graphical Language for Compositional Training Regimes**|Mason Lary et.al.|[2501.01515v1](http://arxiv.org/abs/2501.01515v1)|null|
|**2025-01-02**|**AI-Enabled Operations at Fermi Complex: Multivariate Time Series Prediction for Outage Prediction and Diagnosis**|Milan Jain et.al.|[2501.01509v1](http://arxiv.org/abs/2501.01509v1)|null|
|**2025-01-02**|**ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST**|Ved G. Shah et.al.|[2501.01496v1](http://arxiv.org/abs/2501.01496v1)|null|
|**2025-01-02**|**Unifying Specialized Visual Encoders for Video Language Models**|Jihoon Chung et.al.|[2501.01426v1](http://arxiv.org/abs/2501.01426v1)|[link](https://github.com/princetonvisualai/merv)|
|**2025-01-02**|**Object-level Visual Prompts for Compositional Image Generation**|Gaurav Parmar et.al.|[2501.01424v1](http://arxiv.org/abs/2501.01424v1)|null|
|**2025-01-02**|**Multi-Modal Video Feature Extraction for Popularity Prediction**|Haixu Liu et.al.|[2501.01422v1](http://arxiv.org/abs/2501.01422v1)|null|
|**2025-01-02**|**On Unifying Video Generation and Camera Pose Estimation**|Chun-Hao Paul Huang et.al.|[2501.01409v1](http://arxiv.org/abs/2501.01409v1)|null|
|**2025-01-02**|**A Unified Hyperparameter Optimization Pipeline for Transformer-Based Time Series Forecasting Models**|Jingjing Xu et.al.|[2501.01394v1](http://arxiv.org/abs/2501.01394v1)|[link](https://github.com/jingjing-unilu/HPO_transformer_time_series)|
|**2025-01-02**|**OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios**|Xize Cheng et.al.|[2501.01384v1](http://arxiv.org/abs/2501.01384v1)|null|
|**2025-01-02**|**Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**|Yucheng Zhou et.al.|[2501.01377v1](http://arxiv.org/abs/2501.01377v1)|null|
|**2025-01-02**|**ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**|Neda Tavakoli et.al.|[2501.01372v1](http://arxiv.org/abs/2501.01372v1)|[link](https://github.com/nedatavakoli/scarnet)|
|**2025-01-02**|**ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding**|Austin T. Wang et.al.|[2501.01366v1](http://arxiv.org/abs/2501.01366v1)|null|
|**2025-01-02**|**Rethinking Relation Extraction: Beyond Shortcuts to Generalization with a Debiased Benchmark**|Liang He et.al.|[2501.01349v1](http://arxiv.org/abs/2501.01349v1)|null|
|**2025-01-02**|**AdaptVC: High Quality Voice Conversion with Adaptive Learning**|Jaehun Kim et.al.|[2501.01347v2](http://arxiv.org/abs/2501.01347v2)|null|
|**2025-01-02**|**Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability**|Dong Shu et.al.|[2501.01346v1](http://arxiv.org/abs/2501.01346v1)|null|
|**2025-01-02**|**DeepFilter: An Instrumental Baseline for Accurate and Efficient Process Monitoring**|Hao Wang et.al.|[2501.01342v1](http://arxiv.org/abs/2501.01342v1)|null|
|**2025-01-02**|**Aligning Large Language Models for Faithful Integrity Against Opposing Argument**|Yong Zhao et.al.|[2501.01336v1](http://arxiv.org/abs/2501.01336v1)|[link](https://github.com/zhaoy777/afice)|
|**2025-01-02**|**CySecBench: Generative AI-based CyberSecurity-focused Prompt Dataset for Benchmarking Large Language Models**|Johan Wahréus et.al.|[2501.01335v1](http://arxiv.org/abs/2501.01335v1)|[link](https://github.com/cysecbench/dataset)|
|**2025-01-02**|**Decoding Knowledge in Large Language Models: A Framework for Categorization and Comprehension**|Yanbo Fang et.al.|[2501.01332v1](http://arxiv.org/abs/2501.01332v1)|null|
|**2025-01-02**|**The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation**|Shuzheng Gao et.al.|[2501.01329v1](http://arxiv.org/abs/2501.01329v1)|null|
|**2025-01-02**|**Understanding Difficult-to-learn Examples in Contrastive Learning: A Theoretical Framework for Spectral Contrastive Learning**|Yi-Ge Zhang et.al.|[2501.01317v1](http://arxiv.org/abs/2501.01317v1)|null|
|**2025-01-02**|**Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**|Bohang Sun et.al.|[2501.01311v1](http://arxiv.org/abs/2501.01311v1)|null|
|**2025-01-02**|**Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking**|Xiaoxue Cheng et.al.|[2501.01306v2](http://arxiv.org/abs/2501.01306v2)|null|
|**2025-01-02**|**Large Language Models for Mental Health Diagnostic Assessments: Exploring The Potential of Large Language Models for Assisting with Mental Health Diagnostic Assessments -- The Depression and Anxiety Case**|Kaushik Roy et.al.|[2501.01305v1](http://arxiv.org/abs/2501.01305v1)|null|
|**2025-01-02**|**LEO-Split: A Semi-Supervised Split Learning Framework over LEO Satellite Networks**|Zheng Lin et.al.|[2501.01293v1](http://arxiv.org/abs/2501.01293v1)|null|
|**2025-01-02**|**Change Detection-Based Procedures for Piecewise Stationary MABs: A Modular Approach**|Yu-Han Huang et.al.|[2501.01291v1](http://arxiv.org/abs/2501.01291v1)|null|
|**2025-01-02**|**ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark**|Vaskar Nath et.al.|[2501.01290v1](http://arxiv.org/abs/2501.01290v1)|null|
|**2025-01-02**|**Drift2Matrix: Kernel-Induced Self Representation for Concept Drift Adaptation in Co-evolving Time Series**|Kunpeng Xu et.al.|[2501.01480v1](http://arxiv.org/abs/2501.01480v1)|null|
|**2025-01-02**|**NeutraSum: A Language Model can help a Balanced Media Diet by Neutralizing News Summaries**|Xi Luo et.al.|[2501.01284v1](http://arxiv.org/abs/2501.01284v1)|null|
|**2025-01-02**|**CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries**|Shudong Liu et.al.|[2501.01282v1](http://arxiv.org/abs/2501.01282v1)|null|
|**2025-01-02**|**Does a Large Language Model Really Speak in Human-Like Language?**|Mose Park et.al.|[2501.01273v1](http://arxiv.org/abs/2501.01273v1)|null|
|**2025-01-02**|**ProgCo: Program Helps Self-Correction of Large Language Models**|Xiaoshuai Song et.al.|[2501.01264v1](http://arxiv.org/abs/2501.01264v1)|null|
|**2025-01-02**|**Stealthy Backdoor Attack to Real-world Models in Android Apps**|Jiali Wei et.al.|[2501.01263v1](http://arxiv.org/abs/2501.01263v1)|null|
|**2025-01-02**|**CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings**|Shanghaoran Quan et.al.|[2501.01257v2](http://arxiv.org/abs/2501.01257v2)|null|
|**2025-01-02**|**Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably detect hate speech in reader comments of German online newspapers?**|Manuel Weber et.al.|[2501.01256v1](http://arxiv.org/abs/2501.01256v1)|null|
|**2025-01-02**|**Large Language Model-Enhanced Symbolic Reasoning for Knowledge Base Completion**|Qiyuan He et.al.|[2501.01246v1](http://arxiv.org/abs/2501.01246v1)|null|
|**2025-01-02**|**Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants**|Lixiong Qin et.al.|[2501.01243v1](http://arxiv.org/abs/2501.01243v1)|null|
|**2025-01-02**|**An Efficient Attention Mechanism for Sequential Recommendation Tasks: HydraRec**|Uzma Mushtaque et.al.|[2501.01242v1](http://arxiv.org/abs/2501.01242v1)|null|
|**2025-01-02**|**Automated Self-Refinement and Self-Correction for LLM-based Product Attribute Value Extraction**|Alexander Brinkmann et.al.|[2501.01237v1](http://arxiv.org/abs/2501.01237v1)|[link](https://github.com/wbsg-uni-mannheim/selfrefinement4extractgpt)|
|**2025-01-02**|**Enhancing Reasoning through Process Supervision with Monte Carlo Tree Search**|Shuangtao Li et.al.|[2501.01478v1](http://arxiv.org/abs/2501.01478v1)|null|
|**2025-01-02**|**A redescription mining framework for post-hoc explaining and relating deep learning models**|Matej Mihelčić et.al.|[2501.01209v1](http://arxiv.org/abs/2501.01209v1)|null|
|**2025-01-02**|**Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects**|Abdullah Mushtaq et.al.|[2501.01205v1](http://arxiv.org/abs/2501.01205v1)|null|
|**2025-01-02**|**Data Augmentation Techniques for Chinese Disease Name Normalization**|Wenqian Cui et.al.|[2501.01195v1](http://arxiv.org/abs/2501.01195v1)|[link](https://github.com/dreamtheater123/disease_name_dataset)|
|**2025-01-02**|**Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets**|Mahdi Zakizadeh et.al.|[2501.01168v1](http://arxiv.org/abs/2501.01168v1)|null|
|**2025-01-02**|**Leveraging Full Dependency Parsing Graph Information For Biomedical Event Extraction**|Farshad Noravesh et.al.|[2501.01158v1](http://arxiv.org/abs/2501.01158v1)|null|
|**2025-01-02**|**TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions**|Vriksha Srihari et.al.|[2501.01156v1](http://arxiv.org/abs/2501.01156v1)|null|
|**2025-01-02**|**A3: Android Agent Arena for Mobile GUI Agents**|Yuxiang Chai et.al.|[2501.01149v1](http://arxiv.org/abs/2501.01149v1)|null|
|**2025-01-02**|**BlockDialect: Block-wise Fine-grained Mixed Format for Energy-Efficient LLM Inference**|Wonsuk Jang et.al.|[2501.01144v2](http://arxiv.org/abs/2501.01144v2)|null|

#### Abstracts
##### **Metadata Conditioning Accelerates Language Model Pre-training**
2501.01956v1 by Tianyu Gao, Alexander Wettig, Luxi He, Yihe Dong, Sadhika Malladi, Danqi Chen

The vast diversity of styles, domains, and quality levels present in language
model pre-training corpora is essential in developing general model
capabilities, but efficiently learning and deploying the correct behaviors
exemplified in each of these heterogeneous data sources is challenging. To
address this, we propose a new method, termed Metadata Conditioning then
Cooldown (MeCo), to incorporate additional learning cues during pre-training.
MeCo first provides metadata (e.g., URLs like en.wikipedia.org) alongside the
text during training and later uses a cooldown phase with only the standard
text, thereby enabling the model to function normally even without metadata.
MeCo significantly accelerates pre-training across different model scales (600M
to 8B parameters) and training sources (C4, RefinedWeb, and DCLM). For
instance, a 1.6B language model trained with MeCo matches the downstream task
performance of standard pre-training while using 33% less data. Additionally,
MeCo enables us to steer language models by conditioning the inference prompt
on either real or fabricated metadata that encodes the desired properties of
the output: for example, prepending wikipedia.org to reduce harmful generations
or factquizmaster.com (fabricated) to improve common knowledge task
performance. We also demonstrate that MeCo is compatible with different types
of metadata, such as model-generated topics. MeCo is remarkably simple, adds no
computational overhead, and demonstrates promise in producing more capable and
steerable language models.

摘要：語言模型預訓練語料庫中風格、領域和品質層級的多樣性對於開發一般模型能力至關重要，但有效率地學習並部署在這些異質性資料來源中呈現的正確行為是一項挑戰。為了解決這個問題，我們提出了一種新方法，稱為「後置冷卻的元資料條件化」（MeCo），以在預訓練期間納入額外的學習提示。MeCo 首先在訓練期間提供元資料（例如網址，如 en.wikipedia.org）和文字，然後在只有標準文字的冷卻階段使用，從而讓模型即使沒有元資料也能正常運作。MeCo 大幅加速了不同模型規模（600M 到 8B 參數）和訓練來源（C4、RefinedWeb 和 DCLM）的預訓練。例如，使用 MeCo 訓練的 1.6B 語言模型在使用少 33% 資料的情況下，與標準預訓練的下游任務效能相符。此外，MeCo 讓我們能夠透過對推論提示進行條件化，以編碼輸出所需屬性的真實或虛構元資料來引導語言模型：例如，在前面加上 wikipedia.org 以減少有害的生成，或加上 factquizmaster.com（虛構）以改善一般知識任務效能。我們也證明 MeCo 與不同類型的元資料相容，例如模型產生的主題。MeCo 非常簡單，不會增加運算負擔，並證明了在產生更有能力且可引導的語言模型方面很有前景。

##### **MADGEN -- Mass-Spec attends to De Novo Molecular generation**
2501.01950v1 by Yinkai Wang, Xiaohui Chen, Liping Liu, Soha Hassoun

The annotation (assigning structural chemical identities) of MS/MS spectra
remains a significant challenge due to the enormous molecular diversity in
biological samples and the limited scope of reference databases. Currently, the
vast majority of spectral measurements remain in the "dark chemical space"
without structural annotations. To improve annotation, we propose MADGEN
(Mass-spec Attends to De Novo Molecular GENeration), a scaffold-based method
for de novo molecular structure generation guided by mass spectrometry data.
MADGEN operates in two stages: scaffold retrieval and spectra-conditioned
molecular generation starting with the scaffold. In the first stage, given an
MS/MS spectrum, we formulate scaffold retrieval as a ranking problem and employ
contrastive learning to align mass spectra with candidate molecular scaffolds.
In the second stage, starting from the retrieved scaffold, we employ the MS/MS
spectrum to guide an attention-based generative model to generate the final
molecule. Our approach constrains the molecular generation search space,
reducing its complexity and improving generation accuracy. We evaluate MADGEN
on three datasets (NIST23, CANOPUS, and MassSpecGym) and evaluate MADGEN's
performance with a predictive scaffold retriever and with an oracle retriever.
We demonstrate the effectiveness of using attention to integrate spectral
information throughout the generation process to achieve strong results with
the oracle retriever.

摘要：質譜儀 (MS/MS) 光譜的註解（賦予結構化學身分）由於生物樣本中龐大的分子多樣性和參考資料庫的範圍有限，因此仍然是一項重大的挑戰。目前，絕大多數的光譜測量仍處於「黑暗化學空間」，沒有結構註解。為了改善註解，我們提出 MADGEN（質譜關注從頭分子產生），這是一種基於支架的從頭分子結構產生方法，由質譜儀數據引導。MADGEN 分兩個階段進行：支架檢索和以光譜為條件的分子產生，從支架開始。在第一階段，給定一個 MS/MS 光譜，我們將支架檢索制定為一個排名問題，並採用對比學習將質譜與候選分子支架對齊。在第二階段，從檢索到的支架開始，我們使用 MS/MS 光譜來引導基於注意力的生成模型，以產生最終分子。我們的做法約束了分子產生搜尋空間，降低了其複雜性並提高了產生準確度。我們在三個資料集（NIST23、CANOPUS 和 MassSpecGym）上評估 MADGEN，並使用預測支架檢索器和預言機檢索器評估 MADGEN 的效能。我們展示了在整個產生過程中使用注意力整合光譜資訊的有效性，以使用預言機檢索器取得強勁的結果。

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v1 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

摘要：冷啟動問題是推薦系統中長久以來的挑戰之一，專注於準確建模新使用者或互動有限的使用者或項目，以提供更好的推薦。由於網路平台的多樣化以及使用者和項目的指數級增長，冷啟動推薦 (CSR) 的重要性變得越來越明顯。同時，大型語言模型 (LLM) 已取得巨大的成功，並具備建模使用者和項目資訊的強大能力，為冷啟動推薦提供了新的潛力。然而，CSR 的研究社群仍然缺乏對此領域的全面回顧和反思。基於此，在本文中，我們站在大型語言模型的時代背景下，對 CSR 的路線圖、相關文獻和未來方向進行了全面的回顧和討論。具體來說，我們探討了現有 CSR 如何利用資訊的發展路徑，從內容特徵、圖形關係和領域資訊，到大型語言模型所擁有的世界知識，旨在為研究和產業社群在 CSR 上提供新的見解。冷啟動推薦的相關資源已收集並持續更新，供社群在 https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation 中使用。

##### **Abstractive Text Summarization for Contemporary Sanskrit Prose: Issues and Challenges**
2501.01933v1 by Shagun Sinha

This thesis presents Abstractive Text Summarization models for contemporary
Sanskrit prose. The first chapter, titled Introduction, presents the motivation
behind this work, the research questions, and the conceptual framework.
Sanskrit is a low-resource inflectional language. The key research question
that this thesis investigates is what the challenges in developing an
abstractive TS for Sanskrit. To answer the key research questions,
sub-questions based on four different themes have been posed in this work. The
second chapter, Literature Review, surveys the previous works done. The third
chapter, data preparation, answers the remaining three questions from the third
theme. It reports the data collection and preprocessing challenges for both
language model and summarization model trainings. The fourth chapter reports
the training and inference of models and the results obtained therein. This
research has initiated a pipeline for Sanskrit abstractive text summarization
and has reported the challenges faced at every stage of the development. The
research questions based on every theme have been answered to answer the key
research question.

摘要：本論文提出當代梵文散文之抽象文字摘要模型。第一章為緒論，說明本研究的動機、研究問題和概念架構。梵文是一種低資源的屈折語。本論文探討的主要研究問題是開發梵文抽象文字摘要的挑戰。為了回答主要的研究問題，本研究提出了基於四個不同主題的子問題。第二章文獻回顧，探討之前完成的研究。第三章資料準備，回答了第三個主題中剩下的三個問題。它報告了語言模型和摘要模型訓練的資料收集和預處理挑戰。第四章報告模型的訓練和推論，以及獲得的結果。本研究啟動了梵文抽象文字摘要的管道，並報告了開發過程中每個階段面臨的挑戰。基於每個主題的研究問題都已回答，以回答主要的研究問題。

##### **Mitigating Hallucination for Large Vision Language Model by Inter-Modality Correlation Calibration Decoding**
2501.01926v1 by Jiaming Li, Jiacheng Zhang, Zequn Jie, Lin Ma, Guanbin Li

Large vision-language models (LVLMs) have shown remarkable capabilities in
visual-language understanding for downstream multi-modal tasks. Despite their
success, LVLMs still suffer from generating hallucinations in complex
generation tasks, leading to inconsistencies between visual inputs and
generated content. To address this issue, some approaches have introduced
inference-time interventions, such as contrastive decoding and attention
rectification, to reduce overreliance on language priors. However, these
approaches overlook hallucinations stemming from spurious inter-modality
correlations. In this paper, we propose an Inter-Modality Correlation
Calibration Decoding (IMCCD) method to mitigate hallucinations in LVLMs in a
training-free manner. In this method, we design a Cross-Modal Value-Enhanced
Decoding(CMVED) module to alleviate hallucination by a novel contrastive
decoding mechanism. During the estimation of distorted distribution, CMVED
masks the value vectors associated with significant cross-modal attention
weights, which address both uni-modality overreliance and misleading
inter-modality correlations. Additionally, a Content-Driven Attention
Refinement(CDAR) module refines cross-modal attention weights, guiding LVLMs to
focus on important visual content. Experimental results on diverse
hallucination benchmarks validate the superiority of our method over existing
state-of-the-art techniques in reducing hallucinations in LVLM text generation.
Our code will be available at https://github.com/lijm48/IMCCD.

摘要：大型視覺語言模型 (LVLMs) 已在視覺語言理解中展現出非凡的能力，可用於下游多模式任務。儘管它們很成功，但 LVLMs 在複雜的生成任務中仍然會產生幻覺，導致視覺輸入和生成內容之間出現不一致。為了解決這個問題，一些方法引入了推理時間干預，例如對比解碼和注意力校正，以減少對語言先驗的過度依賴。然而，這些方法忽視了源自虛假模態間關聯的幻覺。在本文中，我們提出了一種模態間關聯校正解碼 (IMCCD) 方法，以在不需訓練的情況下減輕 LVLMs 中的幻覺。在此方法中，我們設計了一個跨模態值增強解碼 (CMVED) 模組，透過一種新穎的對比解碼機制來減輕幻覺。在失真分佈的估計過程中，CMVED 會遮蔽與顯著跨模態注意力權重相關的值向量，這可以解決單一模態過度依賴和誤導性的模態間關聯。此外，內容驅動注意力精煉 (CDAR) 模組會精煉跨模態注意力權重，引導 LVLMs 專注於重要的視覺內容。在各種幻覺基準上的實驗結果驗證了我們的方法優於現有最先進技術，可以減少 LVLM 文本生成中的幻覺。我們的程式碼將在 https://github.com/lijm48/IMCCD 中提供。

##### **Mingling with the Good to Backdoor Federated Learning**
2501.01913v1 by Nuno Neves

Federated learning (FL) is a decentralized machine learning technique that
allows multiple entities to jointly train a model while preserving dataset
privacy. However, its distributed nature has raised various security concerns,
which have been addressed by increasingly sophisticated defenses. These
protections utilize a range of data sources and metrics to, for example, filter
out malicious model updates, ensuring that the impact of attacks is minimized
or eliminated.
  This paper explores the feasibility of designing a generic attack method
capable of installing backdoors in FL while evading a diverse array of
defenses. Specifically, we focus on an attacker strategy called MIGO, which
aims to produce model updates that subtly blend with legitimate ones. The
resulting effect is a gradual integration of a backdoor into the global model,
often ensuring its persistence long after the attack concludes, while
generating enough ambiguity to hinder the effectiveness of defenses.
  MIGO was employed to implant three types of backdoors across five datasets
and different model architectures. The results demonstrate the significant
threat posed by these backdoors, as MIGO consistently achieved exceptionally
high backdoor accuracy (exceeding 90%) while maintaining the utility of the
main task. Moreover, MIGO exhibited strong evasion capabilities against ten
defenses, including several state-of-the-art methods. When compared to four
other attack strategies, MIGO consistently outperformed them across most
configurations. Notably, even in extreme scenarios where the attacker controls
just 0.1% of the clients, the results indicate that successful backdoor
insertion is possible if the attacker can persist for a sufficient number of
rounds.

摘要：<paragraph>聯邦學習 (FL) 是一種分散式機器學習技術，允許多個實體在保護資料集隱私的同時，共同訓練模型。然而，其分散式特性引發了各種安全問題，而越來越精密的防禦措施已解決了這些問題。這些防護利用各種資料來源和指標，例如，過濾惡意模型更新，以確保攻擊的影響最小化或消除。
本文探討了設計一種通用攻擊方法的可行性，該方法能夠在迴避各種防禦的同時在 FL 中安裝後門。具體來說，我們專注於一種稱為 MIGO 的攻擊策略，其目的是產生與合法更新巧妙融合的模型更新。由此產生的效果是逐漸將後門整合到全局模型中，通常確保其在攻擊結束後長時間持續存在，同時產生足夠的模糊性來阻礙防禦的有效性。
MIGO 被用於在五個資料集和不同的模型架構中植入三種類型的後門。結果證明了這些後門構成的重大威脅，因為 MIGO 持續實現極高的後門準確度（超過 90%），同時保持主任務的效用。此外，MIGO 對十種防禦措施表現出強大的規避能力，包括幾種最先進的方法。與其他四種攻擊策略相比，MIGO 在大多數配置中持續優於它們。值得注意的是，即使在極端情況下，攻擊者只控制 0.1% 的用戶端，結果表明，如果攻擊者可以持續進行足夠數量的回合，則可以成功插入後門。</paragraph>

##### **Virgo: A Preliminary Exploration on Reproducing o1-like MLLM**
2501.01904v1 by Yifan Du, Zikang Liu, Yifan Li, Wayne Xin Zhao, Yuqi Huo, Bingning Wang, Weipeng Chen, Zheng Liu, Zhongyuan Wang, Ji-Rong Wen

Recently, slow-thinking reasoning systems, built upon large language models
(LLMs), have garnered widespread attention by scaling the thinking time during
inference. There is also growing interest in adapting this capability to
multimodal large language models (MLLMs). Given that MLLMs handle more complex
data semantics across different modalities, it is intuitively more challenging
to implement multimodal slow-thinking systems.
  To address this issue, in this paper, we explore a straightforward approach
by fine-tuning a capable MLLM with a small amount of textual long-form thought
data, resulting in a multimodal slow-thinking system, Virgo (Visual reasoning
with long thought). We find that these long-form reasoning processes, expressed
in natural language, can be effectively transferred to MLLMs. Moreover, it
seems that such textual reasoning data can be even more effective than visual
reasoning data in eliciting the slow-thinking capacities of MLLMs. While this
work is preliminary, it demonstrates that slow-thinking capacities are
fundamentally associated with the language model component, which can be
transferred across modalities or domains. This finding can be leveraged to
guide the development of more powerful slow-thinking reasoning systems. We
release our resources at https://github.com/RUCAIBox/Virgo.

摘要：<paragraph>最近，建立在大型语言模型 (LLM) 上的慢思考推理系统通过在推理期间扩展思考时间而引起了广泛关注。人们也越来越有兴趣将这种能力应用于多模态大型语言模型 (MLLM)。鉴于 MLLM 处理不同模态下的更复杂的数据语义，直观上来说，实现多模态慢思考系统更具挑战性。
为了解决这个问题，在本文中，我们探索了一种直接的方法，通过微调一个有能力的 MLLM，并使用少量文本长形式思想数据，从而产生了一个多模态慢思考系统 Virgo（具有长期思考能力的视觉推理）。我们发现，这些用自然语言表达的长形式推理过程可以有效地转移到 MLLM。此外，似乎此类文本推理数据在引发 MLLM 的慢思考能力方面甚至比视觉推理数据更有效。虽然这项工作是初步的，但它表明慢思考能力从根本上与语言模型组件相关，该组件可以在不同模态或领域之间转移。这一发现可以用来指导开发更强大的慢思考推理系统。我们在 https://github.com/RUCAIBox/Virgo 上发布了我们的资源。</paragraph>

##### **QuArch: A Question-Answering Dataset for AI Agents in Computer Architecture**
2501.01892v1 by Shvetank Prakash, Andrew Cheng, Jason Yik, Arya Tschand, Radhika Ghosal, Ikechukwu Uchendu, Jessica Quaye, Jeffrey Ma, Shreyas Grampurohit, Sofia Giannuzzi, Arnav Balyan, Fin Amin, Aadya Pipersenia, Yash Choudhary, Ankita Nayak, Amir Yazdanbakhsh, Vijay Janapa Reddi

We introduce QuArch, a dataset of 1500 human-validated question-answer pairs
designed to evaluate and enhance language models' understanding of computer
architecture. The dataset covers areas including processor design, memory
systems, and performance optimization. Our analysis highlights a significant
performance gap: the best closed-source model achieves 84% accuracy, while the
top small open-source model reaches 72%. We observe notable struggles in memory
systems, interconnection networks, and benchmarking. Fine-tuning with QuArch
improves small model accuracy by up to 8%, establishing a foundation for
advancing AI-driven computer architecture research. The dataset and leaderboard
are at https://harvard-edge.github.io/QuArch/.

摘要：我們介紹 QuArch，一個由 1500 個人類驗證的問題-答案組成的資料集，旨在評估和增強語言模型對電腦架構的理解。該資料集涵蓋處理器設計、記憶體系統和效能最佳化等領域。我們的分析強調了一個顯著的效能差距：最佳閉源模型達到 84% 的準確度，而頂尖的小型開源模型則達到 72%。我們觀察到在記憶體系統、互連網路和基準測試中存在顯著的困難。使用 QuArch 進行微調可將小型模型的準確度提高多達 8%，為推進 AI 驅動的電腦架構研究奠定基礎。資料集和排行榜位於 https://harvard-edge.github.io/QuArch/。

##### **Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions**
2501.01872v1 by Rachneet Sachdeva, Rima Hazra, Iryna Gurevych

Despite significant efforts to align large language models with human values
and ethical guidelines, these models remain susceptible to sophisticated
jailbreak attacks that exploit their reasoning capabilities. Traditional safety
mechanisms often focus on detecting explicit malicious intent, leaving deeper
vulnerabilities unaddressed. In this work, we introduce a jailbreak technique,
POATE (Polar Opposite query generation, Adversarial Template construction, and
Elaboration), which leverages contrastive reasoning to elicit unethical
responses. POATE generates prompts with semantically opposite intents and
combines them with adversarial templates to subtly direct models toward
producing harmful responses. We conduct extensive evaluations across six
diverse language model families of varying parameter sizes, including LLaMA3,
Gemma2, Phi3, and GPT-4, to demonstrate the robustness of the attack, achieving
significantly higher attack success rates (~44%) compared to existing methods.
We evaluate our proposed attack against seven safety defenses, revealing their
limitations in addressing reasoning-based vulnerabilities. To counteract this,
we propose a defense strategy that improves reasoning robustness through
chain-of-thought prompting and reverse thinking, mitigating reasoning-driven
adversarial exploits.

摘要：儘管已經為將大型語言模型與人類價值觀和道德準則對齊做出重大努力，這些模型仍然容易受到複雜的越獄攻擊，這些攻擊利用了它們的推理能力。傳統的安全機制通常著重於偵測明確的惡意意圖，而未處理更深層的漏洞。在這項工作中，我們介紹了一種越獄技術 POATE（極相反查詢產生、對抗範本建構和闡述），它利用對比推理來引發不道德的回應。POATE 產生具有語義相反意圖的提示，並將它們與對抗範本結合，以巧妙地引導模型產生有害的回應。我們對六個不同語言模型系列進行廣泛評估，這些系列具有不同的參數大小，包括 LLaMA3、Gemma2、Phi3 和 GPT-4，以證明攻擊的穩健性，與現有方法相比，攻擊成功率顯著提高（約 44%）。我們針對七種安全防禦評估我們提出的攻擊，揭示它們在解決基於推理的漏洞方面的局限性。為了解決這個問題，我們提出了一種防禦策略，透過思想鏈提示和逆向思考來提高推理的穩健性，從而減輕由推理驅動的對抗性攻擊。

##### **LCFed: An Efficient Clustered Federated Learning Framework for Heterogeneous Data**
2501.01850v1 by Yuxin Zhang, Haoyu Chen, Zheng Lin, Zhe Chen, Jin Zhao

Clustered federated learning (CFL) addresses the performance challenges posed
by data heterogeneity in federated learning (FL) by organizing edge devices
with similar data distributions into clusters, enabling collaborative model
training tailored to each group. However, existing CFL approaches strictly
limit knowledge sharing to within clusters, lacking the integration of global
knowledge with intra-cluster training, which leads to suboptimal performance.
Moreover, traditional clustering methods incur significant computational
overhead, especially as the number of edge devices increases. In this paper, we
propose LCFed, an efficient CFL framework to combat these challenges. By
leveraging model partitioning and adopting distinct aggregation strategies for
each sub-model, LCFed effectively incorporates global knowledge into
intra-cluster co-training, achieving optimal training performance.
Additionally, LCFed customizes a computationally efficient model similarity
measurement method based on low-rank models, enabling real-time cluster updates
with minimal computational overhead. Extensive experiments show that LCFed
outperforms state-of-the-art benchmarks in both test accuracy and clustering
computational efficiency.

摘要：群集联邦学习 (CFL) 透过将具有相似资料分布的边缘装置组织成群集，来解决联邦学习 (FL) 中资料异质性所造成的效能挑战，进而针对每个群组进行协作模型训练。然而，现有的 CFL 方法严格限制知识分享在群集内，缺乏将全球知识与群集内训练整合，这导致次佳的效能。此外，传统的群集方法会产生大量的计算开销，特别是当边缘装置数量增加时。在本文中，我们提出 LCFed，一个有效率的 CFL 架构来对抗这些挑战。透过利用模型分割并针对每个子模型采用不同的聚合策略，LCFed 有效地将全球知识纳入群集内共同训练，达成最佳的训练效能。此外，LCFed 根据低阶模型定制一个计算上有效率的模型相似性度量方法，以最少的计算开销启用即时群集更新。大量的实验显示，LCFed 在测试准确度和群集计算效率方面都优于最先进的基准。

##### **Multi-Agent Conversational Online Learning for Adaptive LLM Response Identification**
2501.01849v1 by Xiangxiang Dai, Yuejin Xie, Maoli Liu, Xuchuang Wang, Zhuohua Li, Huanyu Wang, John C. S. Lui

The remarkable generative capability of large language models (LLMs) has
sparked a growing interest in automatically generating responses for different
applications. Given the dynamic nature of user preferences and the uncertainty
of LLM response performance, it is crucial to design efficient online learning
algorithms to identify optimal LLM responses (i.e., high-quality responses that
also meet user preferences). Most existing online algorithms adopt a
centralized approach and fail to leverage explicit user preferences for more
efficient and personalized LLM response identification. In contrast, this paper
introduces \textit{MACO} (\underline{M}ulti-\underline{A}gent
\underline{C}onversational \underline{O}nline Learning for Adaptive LLM
Response Identification): 1) The online LLM response identification process is
accelerated by multiple local agents (such as smartphones), while enhancing
data privacy; 2) A novel conversational mechanism is proposed to adaptively
conduct conversations for soliciting user preferences (e.g., a preference for a
humorous tone over a serious one in generated responses), so to minimize
uncertainty in preference estimation. Our theoretical analysis demonstrates
that \cadi\ is near-optimal regarding cumulative regret. Additionally, \cadi\
offers reduced communication costs and computational complexity by eliminating
the traditional, computing-intensive ``G-optimal design" found in previous
works. Extensive experiments with the open LLM \textit{Llama}, coupled with two
different embedding models from Google and OpenAI for text vector
representation, demonstrate that \cadi\ significantly outperforms the current
state-of-the-art in online LLM response identification.

摘要：大型語言模型 (LLM) 顯著的生成能力已引發人們對自動生成不同應用程式回應的興趣。鑑於使用者偏好的動態性質和 LLM 回應效能的不確定性，設計有效的線上學習演算法以識別最佳 LLM 回應（即高品質且符合使用者偏好的回應）至關重要。大多數現有的線上演算法採用集中式方法，無法利用明確的使用者偏好來更有效率且個人化地識別 LLM 回應。相反地，本文介紹了 \textit{MACO}（多主體對話式線上學習，用於自適應 LLM 回應識別）：1）多個區域主體（例如智慧型手機）加速了線上 LLM 回應識別程序，同時增強資料隱私；2）提出了一種新穎的對話機制，用於自適應地進行對話以徵詢使用者偏好（例如，生成回應時偏好幽默的語氣而非嚴肅的語氣），以最大程度地降低偏好估計中的不確定性。我們的理論分析表明，\cadi\ 在累積後悔方面近乎最佳。此外，\cadi\ 透過消除先前作品中發現的傳統運算密集型「G 最佳設計」來降低通訊成本和運算複雜度。與 Google 和 OpenAI 的兩個不同的嵌入模型結合使用開放 LLM \textit{Llama} 進行的廣泛實驗，用於文字向量的表示，證明 \cadi\ 在線上 LLM 回應識別方面顯著優於目前的技術水準。

##### **ASKCOS: an open source software suite for synthesis planning**
2501.01835v1 by Zhengkai Tu, Sourabh J. Choure, Mun Hong Fong, Jihye Roh, Itai Levin, Kevin Yu, Joonyoung F. Joung, Nathan Morgan, Shih-Cheng Li, Xiaoqi Sun, Huiqian Lin, Mark Murnin, Jordan P. Liles, Thomas J. Struble, Michael E. Fortunato, Mengjie Liu, William H. Green, Klavs F. Jensen, Connor W. Coley

The advancement of machine learning and the availability of large-scale
reaction datasets have accelerated the development of data-driven models for
computer-aided synthesis planning (CASP) in the past decade. Here, we detail
the newest version of ASKCOS, an open source software suite for synthesis
planning that makes available several research advances in a freely available,
practical tool. Four one-step retrosynthesis models form the basis of both
interactive planning and automatic planning modes. Retrosynthetic planning is
complemented by other modules for feasibility assessment and pathway
evaluation, including reaction condition recommendation, reaction outcome
prediction, and auxiliary capabilities such as solubility prediction and
quantum mechanical descriptor prediction. ASKCOS has assisted hundreds of
medicinal, synthetic, and process chemists in their day-to-day tasks,
complementing expert decision making. It is our belief that CASP tools like
ASKCOS are an important part of modern chemistry research, and that they offer
ever-increasing utility and accessibility.

摘要：機器學習的進展和大型反應資料集的可用性加速了過去十年中用於電腦輔助合成規劃 (CASP) 的資料驅動模型的開發。在此，我們詳細介紹了 ASKCOS 的最新版本，ASKCOS 是一個用於合成規劃的開源軟體套件，它在一個免費提供的實用工具中提供了多項研究進展。四個單步逆合成模型構成了互動式規劃和自動規劃模式的基礎。逆合成規劃由其他模組補充，這些模組用於可行性評估和路徑評估，包括反應條件建議、反應結果預測，以及溶解度預測和量子力學描述符預測等輔助功能。ASKCOS 已協助數百位藥物、合成和製程化學家完成其日常任務，並補充專家決策制定。我們相信像 ASKCOS 這樣的 CASP 工具是現代化學研究的重要組成部分，並且它們提供了日益增長且易於使用的工具。

##### **MoColl: Agent-Based Specific and General Model Collaboration for Image Captioning**
2501.01834v1 by Pu Yang, Bin Dong

Image captioning is a critical task at the intersection of computer vision
and natural language processing, with wide-ranging applications across various
domains. For complex tasks such as diagnostic report generation, deep learning
models require not only domain-specific image-caption datasets but also the
incorporation of relevant general knowledge to provide contextual accuracy.
Existing approaches exhibit inherent limitations: specialized models excel in
capturing domain-specific details but lack generalization, while
vision-language models (VLMs) built on large language models (LLMs) leverage
general knowledge but struggle with domain-specific adaptation. To address
these limitations, this paper proposes a novel agent-enhanced model
collaboration framework, which we called \textbf{MoColl}, designed to
effectively integrate domain-specific and general knowledge. Specifically, our
approach is to decompose complex image captioning tasks into a series of
interconnected question-answer subtasks. A trainable visual question answering
(VQA) model is employed as a specialized tool to focus on domain-specific
visual analysis, answering task-specific questions based on image content.
Concurrently, an LLM-based agent with general knowledge formulates these
questions and synthesizes the resulting question-answer pairs into coherent
captions. Beyond its role in leveraging the VQA model, the agent further guides
its training to enhance its domain-specific capabilities. Experimental results
on radiology report generation validate the effectiveness of the proposed
framework, demonstrating significant improvements in the quality of generated
reports.

摘要：影像標題是電腦視覺與自然語言處理的交叉領域中一項重要的任務，在各個領域中都有廣泛的應用。對於診斷報告生成等複雜任務，深度學習模型不僅需要特定領域的影像標題資料集，還需要納入相關的常識，以提供背景的準確性。現有的方法呈現出固有的限制：專門的模型擅長擷取特定領域的細節，但缺乏概括性，而建立在大型語言模型 (LLM) 上的視覺語言模型 (VLM) 則利用了常識，但難以適應特定領域。為了解決這些限制，本文提出了一個新穎的代理增強模型協作架構，我們稱之為 \textbf{MoColl}，旨在有效整合特定領域和一般知識。具體來說，我們的方法是將複雜的影像標題任務分解成一系列相互連接的問題解答子任務。可訓練的視覺問答 (VQA) 模型被用作專門工具，專注於特定領域的視覺分析，根據影像內容回答特定任務的問題。同時，具備一般知識的 LLM 基礎代理會制定這些問題，並將產生的問題解答配對綜合成連貫的標題。除了在利用 VQA 模型中發揮作用之外，代理進一步指導其訓練，以增強其特定領域的能力。放射學報告生成的實驗結果驗證了所提出架構的有效性，證明了生成報告品質的顯著提升。

##### **Time Series Language Model for Descriptive Caption Generation**
2501.01832v1 by Mohamed Trabelsi, Aidan Boyd, Jin Cao, Huseyin Uzunalioglu

The automatic generation of representative natural language descriptions for
observable patterns in time series data enhances interpretability, simplifies
analysis and increases cross-domain utility of temporal data. While pre-trained
foundation models have made considerable progress in natural language
processing (NLP) and computer vision (CV), their application to time series
analysis has been hindered by data scarcity. Although several large language
model (LLM)-based methods have been proposed for time series forecasting, time
series captioning is under-explored in the context of LLMs. In this paper, we
introduce TSLM, a novel time series language model designed specifically for
time series captioning. TSLM operates as an encoder-decoder model, leveraging
both text prompts and time series data representations to capture subtle
temporal patterns across multiple phases and generate precise textual
descriptions of time series inputs. TSLM addresses the data scarcity problem in
time series captioning by first leveraging an in-context prompting synthetic
data generation, and second denoising the generated data via a novel
cross-modal dense retrieval scoring applied to time series-caption pairs.
Experimental findings on various time series captioning datasets demonstrate
that TSLM outperforms existing state-of-the-art approaches from multiple data
modalities by a significant margin.

摘要：時間序列資料中可觀察模式的自動產生具代表性的自然語言描述，增強了解能力，簡化分析，並增加時間資料的跨領域效用。儘管預先訓練好的基礎模型在自然語言處理 (NLP) 和電腦視覺 (CV) 方面取得相當大的進展，但由於資料稀少，其應用於時間序列分析受到阻礙。儘管已提出多種基於大型語言模型 (LLM) 的時間序列預測方法，但時間序列標題在 LLM 的背景下仍未充分探索。在本文中，我們介紹 TSLM，這是一種專門設計用於時間序列標題的新型時間序列語言模型。TSLM 以編碼器-解碼器模型運作，利用文字提示和時間序列資料表示來捕捉多個階段的細微時間模式，並產生時間序列輸入的精確文字描述。TSLM 透過首先利用情境提示式合成資料產生，以及其次透過應用於時間序列-標題對的新型跨模態密集檢索評分來對產生的資料進行去噪，解決時間序列標題中的資料稀少問題。在各種時間序列標題資料集上的實驗結果顯示，TSLM 在多種資料模式中大幅優於現有最先進的方法。

##### **Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models**
2501.01830v1 by Yanjiang Liu, Shuhen Zhou, Yaojie Lu, Huijia Zhu, Weiqiang Wang, Hongyu Lin, Ben He, Xianpei Han, Le Sun

Automated red-teaming has become a crucial approach for uncovering
vulnerabilities in large language models (LLMs). However, most existing methods
focus on isolated safety flaws, limiting their ability to adapt to dynamic
defenses and uncover complex vulnerabilities efficiently. To address this
challenge, we propose Auto-RT, a reinforcement learning framework that
automatically explores and optimizes complex attack strategies to effectively
uncover security vulnerabilities through malicious queries. Specifically, we
introduce two key mechanisms to reduce exploration complexity and improve
strategy optimization: 1) Early-terminated Exploration, which accelerate
exploration by focusing on high-potential attack strategies; and 2) Progressive
Reward Tracking algorithm with intermediate downgrade models, which dynamically
refine the search trajectory toward successful vulnerability exploitation.
Extensive experiments across diverse LLMs demonstrate that, by significantly
improving exploration efficiency and automatically optimizing attack
strategies, Auto-RT detects a boarder range of vulnerabilities, achieving a
faster detection speed and 16.63\% higher success rates compared to existing
methods.

摘要：自動化紅隊行動已成為揭露大型語言模型 (LLM) 中漏洞的關鍵方法。然而，現有的方法大多著重於孤立的安全漏洞，這限制了它們適應動態防禦和有效揭露複雜漏洞的能力。為了應對這個挑戰，我們提出了 Auto-RT，一種強化學習框架，它自動探索和最佳化複雜的攻擊策略，以透過惡意查詢有效揭露安全漏洞。具體而言，我們引入了兩種關鍵機制來降低探索複雜度並改善策略最佳化：1) 提早終止探索，它透過專注於高潛力的攻擊策略來加速探索；以及 2) 具有中間降級模型的漸進式獎勵追蹤演算法，它動態地調整搜尋軌跡，朝向成功的漏洞利用。跨不同 LLM 的廣泛實驗證明，透過顯著改善探索效率和自動最佳化攻擊策略，Auto-RT 偵測到更廣泛的漏洞，與現有方法相比，達到了更快的偵測速度和高出 16.63% 的成功率。

##### **The Proof is in the Almond Cookies**
2501.01827v1 by Remi van Trijp, Katrien Beuls, Paul Van Eecke

This paper presents a case study on how to process cooking recipes (and more
generally, how-to instructions) in a way that makes it possible for a robot or
artificial cooking assistant to support human chefs in the kitchen. Such AI
assistants would be of great benefit to society, as they can help to sustain
the autonomy of aging adults or people with a physical impairment, or they may
reduce the stress in a professional kitchen. We propose a novel approach to
computational recipe understanding that mimics the human sense-making process,
which is narrative-based. Using an English recipe for almond crescent cookies
as illustration, we show how recipes can be modelled as rich narrative
structures by integrating various knowledge sources such as language
processing, ontologies, and mental simulation. We show how such narrative
structures can be used for (a) dealing with the challenges of recipe language,
such as zero anaphora, (b) optimizing a robot's planning process, (c) measuring
how well an AI system understands its current tasks, and (d) allowing recipe
annotations to become language-independent.

摘要：本文介紹了一個案例研究，探討如何處理烹飪食譜（更廣義地說，如何操作說明），讓機器人或人工烹飪助理可以在廚房協助人類廚師。此類人工智慧助理對社會有極大的好處，因為它們可以幫助維持年長者或身體障礙者的自主性，或減輕專業廚房的壓力。我們提出了一個新穎的計算食譜理解方法，模擬人類基於敘事的理解過程。我們以英文杏仁新月餅乾食譜為例，說明如何將食譜建模為豐富的敘事結構，方法是整合語言處理、本体和心智模擬等各種知識來源。我們說明如何使用此類敘事結構來：(a) 應對食譜語言的挑戰，例如零代名詞；(b) 優化機器人的規劃流程；(c) 衡量人工智慧系統了解其當前任務的程度；以及 (d) 讓食譜註解與語言無關。

##### **SDPO: Segment-Level Direct Preference Optimization for Social Agents**
2501.01821v1 by Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang

Social agents powered by large language models (LLMs) can simulate human
social behaviors but fall short in handling complex goal-oriented social
dialogues. Direct Preference Optimization (DPO) has proven effective in
aligning LLM behavior with human preferences across a variety of agent tasks.
Existing DPO-based approaches for multi-turn interactions are divided into
turn-level and session-level methods. The turn-level method is overly
fine-grained, focusing exclusively on individual turns, while session-level
methods are too coarse-grained, often introducing training noise. To address
these limitations, we propose Segment-Level Direct Preference Optimization
(SDPO), which focuses on specific key segments within interactions to optimize
multi-turn agent behavior while minimizing training noise. Evaluations on the
SOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform
both existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring
SDPO's potential to advance the social intelligence of LLM-based agents. We
release our code and data at
https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO.

摘要：大型語言模型（LLM）驅動的社交代理可以模擬人類社交行為，但在處理複雜目標導向的社交對話時卻力有未逮。直接偏好最佳化（DPO）已被證明能有效地將 LLM 行為與人類偏好對齊，適用於各種代理任務。現有的基於 DPO 的多輪互動方法分為輪次級別和會話級別方法。輪次級別方法過於細緻，僅專注於個別輪次，而會話級別方法則過於粗略，通常會引入訓練噪音。為了解決這些限制，我們提出了區段級別直接偏好最佳化（SDPO），它專注於互動中的特定關鍵區段，以最佳化多輪代理行為，同時最小化訓練噪音。在 SOTOPIA 基準上的評估表明，經過 SDPO 調整的代理始終優於現有的基於 DPO 的方法和 GPT-4o 等專有 LLM，這凸顯了 SDPO 在提升基於 LLM 的代理的社交智能方面的潛力。我們在 https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO 上發布我們的程式碼和資料。

##### **End-to-End Long Document Summarization using Gradient Caching**
2501.01805v1 by Rohit Saxena, Hao Tang, Frank Keller

Training transformer-based encoder-decoder models for long document
summarization poses a significant challenge due to the quadratic memory
consumption during training. Several approaches have been proposed to extend
the input length at test time, but training with these approaches is still
difficult, requiring truncation of input documents and causing a mismatch
between training and test conditions. In this work, we propose CachED (Gradient
$\textbf{Cach}$ing for $\textbf{E}$ncoder-$\textbf{D}$ecoder models), an
approach that enables end-to-end training of existing transformer-based
encoder-decoder models, using the entire document without truncation.
Specifically, we apply non-overlapping sliding windows to input documents,
followed by fusion in decoder. During backpropagation, the gradients are cached
at the decoder and are passed through the encoder in chunks by re-computing the
hidden vectors, similar to gradient checkpointing. In the experiments on long
document summarization, we extend BART to CachED BART, processing more than
500K tokens during training and achieving superior performance without using
any additional parameters.

摘要：<paragraph>針對長篇文件摘要訓練基於轉換器的編碼器-解碼器模型，由於訓練期間二次記憶體消耗，因此構成重大挑戰。已提出多種方法來擴充測試期間的輸入長度，但使用這些方法訓練仍然困難，需要截斷輸入文件，並導致訓練和測試條件不匹配。在這項工作中，我們提出 CachED（編碼器-解碼器模型的梯度快取），一種方法，能使用整個文件而不進行截斷，對現有的基於轉換器的編碼器-解碼器模型進行端到端訓練。具體來說，我們將不重疊的滑動視窗套用在輸入文件，然後在解碼器中進行融合。在反向傳播期間，梯度會快取在解碼器中，並透過重新計算隱藏向量，分批傳遞到編碼器中，類似於梯度檢查點。在長篇文件摘要的實驗中，我們將 BART 延伸到 CachED BART，在訓練期間處理超過 50 萬個符號，並在不使用任何額外參數的情況下，達成卓越的效能。</paragraph>

##### **BERT4MIMO: A Foundation Model using BERT Architecture for Massive MIMO Channel State Information Prediction**
2501.01802v1 by Ferhat Ozgur Catak, Murat Kuzlu, Umit Cali

Massive MIMO (Multiple-Input Multiple-Output) is an advanced wireless
communication technology, using a large number of antennas to improve the
overall performance of the communication system in terms of capacity, spectral,
and energy efficiency. The performance of MIMO systems is highly dependent on
the quality of channel state information (CSI). Predicting CSI is, therefore,
essential for improving communication system performance, particularly in MIMO
systems, since it represents key characteristics of a wireless channel,
including propagation, fading, scattering, and path loss. This study proposes a
foundation model inspired by BERT, called BERT4MIMO, which is specifically
designed to process high-dimensional CSI data from massive MIMO systems.
BERT4MIMO offers superior performance in reconstructing CSI under varying
mobility scenarios and channel conditions through deep learning and attention
mechanisms. The experimental results demonstrate the effectiveness of BERT4MIMO
in a variety of wireless environments.

摘要：大規模 MIMO（多輸入多輸出）是一種先進的無線通訊技術，使用大量的接收器來提升通訊系統在容量、頻譜和能源效率方面的整體效能。MIMO 系統的效能高度依賴於信道狀態資訊（CSI）的品質。因此，預測 CSI 對於提升通訊系統效能至關重要，特別是在 MIMO 系統中，因為它代表了無線信道的關鍵特性，包括傳播、衰落、散射和路徑損耗。本研究提出了一個受 BERT 啟發的基礎模型，稱為 BERT4MIMO，它專門設計用於處理來自大規模 MIMO 系統的高維度 CSI 資料。BERT4MIMO 透過深度學習和注意力機制，在不同的移動場景和信道條件下提供重建 CSI 的卓越效能。實驗結果證明了 BERT4MIMO 在各種無線環境中的有效性。

##### **Reading Between the Lines: A dataset and a study on why some texts are tougher than others**
2501.01796v1 by Nouran Khallaf, Carlo Eugeni, Serge Sharoff

Our research aims at better understanding what makes a text difficult to read
for specific audiences with intellectual disabilities, more specifically,
people who have limitations in cognitive functioning, such as reading and
understanding skills, an IQ below 70, and challenges in conceptual domains. We
introduce a scheme for the annotation of difficulties which is based on
empirical research in psychology as well as on research in translation studies.
The paper describes the annotated dataset, primarily derived from the parallel
texts (standard English and Easy to Read English translations) made available
online. we fine-tuned four different pre-trained transformer models to perform
the task of multiclass classification to predict the strategies required for
simplification. We also investigate the possibility to interpret the decisions
of this language model when it is aimed at predicting the difficulty of
sentences. The resources are available from
https://github.com/Nouran-Khallaf/why-tough

摘要：我們的研究旨在更深入地了解哪些因素會讓特定心智障礙受眾難以閱讀文本，更具體地來說，是那些在認知功能上有所限制的人，例如閱讀和理解能力，智商低於 70，以及概念領域的挑戰。我們引入了一個困難註解方案，該方案基於心理學的實證研究以及翻譯研究。本文描述了註解數據集，主要來自於線上提供的平行文本（標準英語和易讀英語翻譯）。我們微調了四個不同的預訓練Transformer模型，以執行多類別分類任務，以預測簡化所需的策略。我們還探討了解釋此語言模型在預測句子難度時的決策的可能性。資源可從 https://github.com/Nouran-Khallaf/why-tough 取得

##### **Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation**
2501.01793v1 by Mohammad Khalil, Farhad Vadiee, Ronas Shakya, Qinyi Liu

In this study, we explore the growing potential of AI and deep learning
technologies, particularly Generative Adversarial Networks (GANs) and Large
Language Models (LLMs), for generating synthetic tabular data. Access to
quality students data is critical for advancing learning analytics, but privacy
concerns and stricter data protection regulations worldwide limit their
availability and usage. Synthetic data offers a promising alternative. We
investigate whether synthetic data can be leveraged to create artificial
students for serving learning analytics models. Using the popular GAN model
CTGAN and three LLMs- GPT2, DistilGPT2, and DialoGPT, we generate synthetic
tabular student data. Our results demonstrate the strong potential of these
methods to produce high-quality synthetic datasets that resemble real students
data. To validate our findings, we apply a comprehensive set of utility
evaluation metrics to assess the statistical and predictive performance of the
synthetic data and compare the different generator models used, specially the
performance of LLMs. Our study aims to provide the learning analytics community
with valuable insights into the use of synthetic data, laying the groundwork
for expanding the field methodological toolbox with new innovative approaches
for learning analytics data generation.

摘要：在這項研究中，我們探討了 AI 和深度學習技術的潛力，特別是生成式對抗網路 (GAN) 和大型語言模型 (LLM)，用於生成合成表格資料。取得高品質的學生資料對於推進學習分析至關重要，但隱私問題和全球更嚴格的資料保護法規限制了資料的取得和使用。合成資料提供了一個有前途的替代方案。我們探討是否可以利用合成資料為學習分析模型建立人工學生。使用流行的 GAN 模型 CTGAN 和三個 LLM，GPT2、DistilGPT2 和 DialoGPT，我們生成了合成表格學生資料。我們的結果證明了這些方法具有產生高品質合成資料集的強大潛力，這些資料集類似於真實學生的資料。為了驗證我們的發現，我們應用了一套全面的效用評估指標來評估合成資料的統計和預測效能，並比較了所使用的不同生成器模型，特別是 LLM 的效能。我們的研究旨在為學習分析社群提供有關使用合成資料的寶貴見解，為擴展領域方法論工具箱奠定基礎，並提供用於學習分析資料生成的創新方法。

##### **Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms**
2501.01785v1 by Qinyi Liu, Oscar Deho, Farhad Vadiee, Mohammad Khalil, Srecko Joksimovic, George Siemens

The increasing use of machine learning in learning analytics (LA) has raised
significant concerns around algorithmic fairness and privacy. Synthetic data
has emerged as a dual-purpose tool, enhancing privacy and improving fairness in
LA models. However, prior research suggests an inverse relationship between
fairness and privacy, making it challenging to optimize both. This study
investigates which synthetic data generators can best balance privacy and
fairness, and whether pre-processing fairness algorithms, typically applied to
real datasets, are effective on synthetic data. Our results highlight that the
DEbiasing CAusal Fairness (DECAF) algorithm achieves the best balance between
privacy and fairness. However, DECAF suffers in utility, as reflected in its
predictive accuracy. Notably, we found that applying pre-processing fairness
algorithms to synthetic data improves fairness even more than when applied to
real data. These findings suggest that combining synthetic data generation with
fairness pre-processing offers a promising approach to creating fairer LA
models.

摘要：機器學習在學習分析 (LA) 中的應用日益增加，對演算法公平性和隱私提出了重大疑慮。合成資料已成為一種雙重用途的工具，增強了隱私並改善了 LA 模型的公平性。然而，先前的研究表明公平性和隱私之間存在反比關係，這使得同時優化兩者具有挑戰性。本研究探討了哪些合成資料產生器可以最好地平衡隱私和公平性，以及通常應用於實際資料集的預處理公平性演算法是否對合成資料有效。我們的結果強調，DEbiasing CAusal Fairness (DECAF) 演算法在隱私和公平性之間取得了最佳平衡。然而，DECAF 在效用方面有所不足，這反映在其預測準確度上。值得注意的是，我們發現將預處理公平性演算法應用於合成資料比應用於實際資料時更能改善公平性。這些發現表明，將合成資料產生與公平性預處理結合起來，提供了一種很有前途的方法來建立更公平的 LA 模型。

##### **Quantifying A Firm's AI Engagement: Constructing Objective, Data-Driven, AI Stock Indices Using 10-K Filings**
2501.01763v1 by Lennart Ante, Aman Saggu

Following an analysis of existing AI-related exchange-traded funds (ETFs), we
reveal the selection criteria for determining which stocks qualify as
AI-related are often opaque and rely on vague phrases and subjective judgments.
This paper proposes a new, objective, data-driven approach using natural
language processing (NLP) techniques to classify AI stocks by analyzing annual
10-K filings from 3,395 NASDAQ-listed firms between 2011 and 2023. This
analysis quantifies each company's engagement with AI through binary indicators
and weighted AI scores based on the frequency and context of AI-related terms.
Using these metrics, we construct four AI stock indices-the Equally Weighted AI
Index (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI
Indices (TAII05 and TAII5X)-offering different perspectives on AI investment.
We validate our methodology through an event study on the launch of OpenAI's
ChatGPT, demonstrating that companies with higher AI engagement saw
significantly greater positive abnormal returns, with analyses supporting the
predictive power of our AI measures. Our indices perform on par with or surpass
14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return
profiles, market responsiveness, and overall performance, achieving higher
average daily returns and risk-adjusted metrics without increased volatility.
These results suggest our NLP-based approach offers a reliable,
market-responsive, and cost-effective alternative to existing AI-related ETF
products. Our innovative methodology can also guide investors, asset managers,
and policymakers in using corporate data to construct other thematic
portfolios, contributing to a more transparent, data-driven, and competitive
approach.

摘要：<paragraph>在分析了現有的與 AI 相關的交易所交易基金 (ETF) 之後，我們
揭示了用於確定哪些股票符合 AI 相關性的選擇標準通常是不透明的，並且依賴於模糊的短語和主觀判斷。
本文提出了一種新的、客觀的、數據驅動的方法，使用自然
語言處理 (NLP) 技術通過分析 2011 年至 2023 年間 3,395 家納斯達克上市公司的年度
10-K 申報文件來對 AI 股票進行分類。此
分析通過二元指標和基於 AI 相關術語的頻率和語境的加權 AI 分數對每家公司的 AI 參與度進行量化。
使用這些指標，我們構建了四個 AI 股票指數——等權重 AI 指數 (AII)、規模加權 AI 指數 (SAII) 和兩個時間折現 AI 指數 (TAII05 和 TAII5X)——提供了對 AI 投資的不同觀點。
我們通過對 OpenAI 的 ChatGPT 推出事件的研究驗證了我們的研究方法，證明了 AI 參與度較高的公司獲得了顯著更高的異常正回報，分析支持了我們的 AI 衡量指標的預測能力。我們的指數在風險回報
概況、市場反應能力和整體表現方面與 14 個現有的 AI 主題 ETF 和納斯達克綜合指數表現相當或超越，實現了更高的平均每日回報和風險調整指標，而沒有增加波動性。
這些結果表明，我們基於 NLP 的方法為現有的與 AI 相關的 ETF 產品提供了一個可靠、對市場反應靈敏且具有成本效益的替代方案。我們創新的方法還可以指導投資者、資產管理者和政策制定者使用公司數據構建其他主題
投資組合，從而促進更透明、更數據驅動和更具競爭力的方法。</paragraph>

##### **Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation**
2501.01743v1 by Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng

Legal articles often include vague concepts to adapt to the ever-changing
society. Providing detailed interpretations of these concepts is a critical
task for legal practitioners, which requires meticulous and professional
annotations by legal experts, admittedly time-consuming and expensive to
collect at scale. In this paper, we introduce a novel retrieval-augmented
generation framework, ATRI, for AuTomatically Retrieving relevant information
from past judicial precedents and Interpreting vague legal concepts. We further
propose a new benchmark, Legal Concept Entailment, to automate the evaluation
of generated concept interpretations without expert involvement. Automatic
evaluations indicate that our generated interpretations can effectively assist
large language models (LLMs) in understanding vague legal concepts.
Multi-faceted evaluations by legal experts indicate that the quality of our
concept interpretations is comparable to those written by human experts. Our
work has strong implications for leveraging LLMs to support legal practitioners
in interpreting vague legal concepts and beyond.

摘要：法律條文通常包含模糊的概念以適應瞬息萬變的社會。對這些概念提供詳細的解釋是法律從業人員的一項重要任務，這需要法律專家仔細且專業地註解，而且公認收集起來既費時又昂貴。在本文中，我們介紹了一個新穎的檢索增強生成框架 ATRI，用於自動檢索過去司法判例中的相關資訊，並解釋模糊的法律概念。我們進一步提出一個新的基準，法律概念蘊涵，以自動化評估產生的概念解釋，而無需專家參與。自動評估表明，我們產生的解釋可以有效地協助大型語言模型 (LLM) 理解模糊的法律概念。法律專家進行的多方面評估表明，我們概念解釋的品質可與人類專家所寫的相媲美。我們的研究對於利用 LLM 來協助法律從業人員解釋模糊的法律概念以及更廣泛的應用具有重要的意義。

##### **How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models**
2501.01741v1 by Simone Corbo, Luca Bancale, Valeria De Gennaro, Livia Lestingi, Vincenzo Scotti, Matteo Camilli

Language is a deep-rooted means of perpetration of stereotypes and
discrimination. Large Language Models (LLMs), now a pervasive technology in our
everyday lives, can cause extensive harm when prone to generating toxic
responses. The standard way to address this issue is to align the LLM, which,
however, dampens the issue without constituting a definitive solution.
Therefore, testing LLM even after alignment efforts remains crucial for
detecting any residual deviations with respect to ethical standards. We present
EvoTox, an automated testing framework for LLMs' inclination to toxicity,
providing a way to quantitatively assess how much LLMs can be pushed towards
toxic responses even in the presence of alignment. The framework adopts an
iterative evolution strategy that exploits the interplay between two LLMs, the
System Under Test (SUT) and the Prompt Generator steering SUT responses toward
higher toxicity. The toxicity level is assessed by an automated oracle based on
an existing toxicity classifier. We conduct a quantitative and qualitative
empirical evaluation using four state-of-the-art LLMs as evaluation subjects
having increasing complexity (7-13 billion parameters). Our quantitative
evaluation assesses the cost-effectiveness of four alternative versions of
EvoTox against existing baseline methods, based on random search, curated
datasets of toxic prompts, and adversarial attacks. Our qualitative assessment
engages human evaluators to rate the fluency of the generated prompts and the
perceived toxicity of the responses collected during the testing sessions.
Results indicate that the effectiveness, in terms of detected toxicity level,
is significantly higher than the selected baseline methods (effect size up to
1.0 against random search and up to 0.99 against adversarial attacks).
Furthermore, EvoTox yields a limited cost overhead (from 22% to 35% on
average).

摘要：語言是一種根深蒂固的刻板印象和歧視的傳播手段。大型語言模型 (LLM) 現已成為我們日常生活中普遍存在的技術，當它們容易產生有害的回應時，可能會造成廣泛的傷害。解決此問題的標準方法是調整 LLM，然而，這只會緩解問題，並未構成明確的解決方案。因此，即使在調整工作之後，測試 LLM 對於檢測任何相對於道德標準的殘餘偏差仍然至關重要。我們提出 EvoTox，這是一個用於測試 LLM 傾向於毒性的自動化測試框架，它提供了一種定量評估 LLM 在調整的情況下，如何被推向有毒反應的方法。該框架採用了一種迭代演化策略，利用兩個 LLM 之間的交互作用，即被測系統 (SUT) 和提示生成器，引導 SUT 反應走向更高的毒性。毒性級別由基於現有毒性分類器的自動化預言機評估。我們使用四個最先進的 LLM 作為評估對象，進行定量和定性實證評估，這些 LLM 具有越來越高的複雜性（7-130 億個參數）。我們的定量評估根據隨機搜索、有毒提示的策劃數據集和對抗性攻擊，評估了 EvoTox 四個替代版本的成本效益，相對於現有的基線方法。我們的定量評估聘請人類評估員，對在測試過程中收集到的提示的流暢性和反應的感知毒性進行評分。結果表明，在檢測到的毒性水平方面，其有效性顯著高於所選的基線方法（對隨機搜索的效果大小高達 1.0，對對抗性攻擊的效果大小高達 0.99）。此外，EvoTox 產生的成本開銷有限（平均為 22% 至 35%）。

##### **Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item Detection under Noisy Annotations**
2501.01733v1 by Ruikang Chen, Yan Yan, Jing-Hao Xue, Yang Lu, Hanzi Wang

Automatic X-ray prohibited item detection is vital for public safety.
Existing deep learning-based methods all assume that the annotations of
training X-ray images are correct. However, obtaining correct annotations is
extremely hard if not impossible for large-scale X-ray images, where item
overlapping is ubiquitous.As a result, X-ray images are easily contaminated
with noisy annotations, leading to performance deterioration of existing
methods.In this paper, we address the challenging problem of training a robust
prohibited item detector under noisy annotations (including both category noise
and bounding box noise) from a novel perspective of data augmentation, and
propose an effective label-aware mixed patch paste augmentation method
(Mix-Paste). Specifically, for each item patch, we mix several item patches
with the same category label from different images and replace the original
patch in the image with the mixed patch. In this way, the probability of
containing the correct prohibited item within the generated image is increased.
Meanwhile, the mixing process mimics item overlapping, enabling the model to
learn the characteristics of X-ray images. Moreover, we design an item-based
large-loss suppression (LLS) strategy to suppress the large losses
corresponding to potentially positive predictions of additional items due to
the mixing operation. We show the superiority of our method on X-ray datasets
under noisy annotations. In addition, we evaluate our method on the noisy
MS-COCO dataset to showcase its generalization ability. These results clearly
indicate the great potential of data augmentation to handle noise annotations.
The source code is released at https://github.com/wscds/Mix-Paste.

摘要：自動 X 光違禁品檢測對於公共安全至關重要。
現有的深度學習方法都假設訓練 X 光影像的註解是正確的。然而，對於大型 X 光影像來說，取得正確的註解極為困難，甚至是不可能的，因為影像中物品重疊的情況普遍存在。因此，X 光影像很容易受到雜訊註解的汙染，導致現有方法的效能下降。在本文中，我們從資料擴充的新觀點來解決在雜訊註解（包括類別雜訊和邊界框雜訊）下訓練強健的違禁品偵測器的挑戰性問題，並提出一個有效的標籤感知混合貼片貼上擴充方法（Mix-Paste）。具體來說，對於每個物品貼片，我們將來自不同影像的幾個具有相同類別標籤的物品貼片混合在一起，並用混合貼片取代影像中的原始貼片。這樣一來，在生成的影像中包含正確違禁品的機率就增加了。同時，混合過程模擬了物品重疊，使模型能夠學習 X 光影像的特性。此外，我們設計了一個基於物品的大損失抑制（LLS）策略，以抑制由於混合操作而導致的額外物品的潛在正向預測所對應的大損失。我們在雜訊註解下的 X 光資料集上展示了我們方法的優越性。此外，我們在雜訊 MS-COCO 資料集上評估我們的模型，以展示其泛化能力。這些結果清楚地表明了資料擴充在處理雜訊註解方面有很大的潛力。原始程式碼發佈於 https://github.com/wscds/Mix-Paste。

##### **LLMs & Legal Aid: Understanding Legal Needs Exhibited Through User Queries**
2501.01711v1 by Michal Kuk, Jakub Harasta

The paper presents a preliminary analysis of an experiment conducted by Frank
Bold, a Czech expert group, to explore user interactions with GPT-4 for
addressing legal queries. Between May 3, 2023, and July 25, 2023, 1,252 users
submitted 3,847 queries. Unlike studies that primarily focus on the accuracy,
factuality, or hallucination tendencies of large language models (LLMs), our
analysis focuses on the user query dimension of the interaction. Using GPT-4o
for zero-shot classification, we categorized queries on (1) whether users
provided factual information about their issue (29.95%) or not (70.05%), (2)
whether they sought legal information (64.93%) or advice on the course of
action (35.07\%), and (3) whether they imposed requirements to shape or control
the model's answer (28.57%) or not (71.43%). We provide both quantitative and
qualitative insight into user needs and contribute to a better understanding of
user engagement with LLMs.

摘要：這篇論文提出了由捷克專家小組 Frank Bold 進行的一項實驗的初步分析，以探討使用者與 GPT-4 的互動，以解決法律問題。在 2023 年 5 月 3 日至 2023 年 7 月 25 日之間，1,252 位使用者提交了 3,847 個查詢。與主要關注大型語言模型 (LLM) 的準確性、事實性或幻覺傾向的研究不同，我們的分析集中在互動的使用者查詢面向。使用 GPT-4o 進行零次分級，我們對查詢進行分類：(1) 使用者是否提供有關其問題的事實資訊 (29.95%) 或沒有 (70.05%)，(2) 他們是否尋求法律資訊 (64.93%) 或行動方針建議 (35.07%)，以及 (3) 他們是否施加要求來塑造或控制模型的答案 (28.57%) 或沒有 (71.43%)。我們提供使用者需求的量化和質化見解，並有助於更深入了解使用者與 LLM 的互動。

##### **MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders**
2501.01709v1 by Jiajun Cao, Yuan Zhang, Tao Huang, Ming Lu, Qizhe Zhang, Ruichuan An, Ningning MA, Shanghang Zhang

Visual encoders are fundamental components in vision-language models (VLMs),
each showcasing unique strengths derived from various pre-trained visual
foundation models. To leverage the various capabilities of these encoders,
recent studies incorporate multiple encoders within a single VLM, leading to a
considerable increase in computational cost. In this paper, we present
Mixture-of-Visual-Encoder Knowledge Distillation (MoVE-KD), a novel framework
that distills the unique proficiencies of multiple vision encoders into a
single, efficient encoder model. Specifically, to mitigate conflicts and retain
the unique characteristics of each teacher encoder, we employ low-rank
adaptation (LoRA) and mixture-of-experts (MoEs) to selectively activate
specialized knowledge based on input features, enhancing both adaptability and
efficiency. To regularize the KD process and enhance performance, we propose an
attention-based distillation strategy that adaptively weighs the different
visual encoders and emphasizes valuable visual tokens, reducing the burden of
replicating comprehensive but distinct features from multiple teachers.
Comprehensive experiments on popular VLMs, such as LLaVA and LLaVA-NeXT,
validate the effectiveness of our method. The code will be released.

摘要：視覺編碼器是視覺語言模型 (VLM) 中的基本組成部分，
每個編碼器都展示了源自各種預先訓練的視覺
基礎模型的獨特優勢。為了利用這些編碼器的各種功能，
最近的研究在單一 VLM 中納入了多個編碼器，導致計算成本大幅增加。在本文中，我們提出
混合視覺編碼器知識萃取 (MoVE-KD)，一種新穎的架構
它將多個視覺編碼器的獨特能力萃取到一個
單一、高效的編碼器模型中。具體來說，為了緩解衝突並保留
每個教師編碼器的獨特特徵，我們採用低秩
適應 (LoRA) 和專家混合 (MoE) 來選擇性地根據輸入特徵啟動
專業知識，從而提高適應性和
效率。為了規範 KD 程序並增強性能，我們提出了一種
基於注意力的萃取策略，它自適應地權衡不同的
視覺編碼器並強調有價值的視覺代幣，減輕了
複製來自多個教師的全面但不同的特徵的負擔。
對流行的 VLM（例如 LLaVA 和 LLaVA-NeXT）進行的全面實驗，
驗證了我們方法的有效性。代碼將會發布。

##### **The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters**
2501.01705v1 by Chulun Zhou, Qiujing Wang, Mo Yu, Xiaoqian Yue, Rui Lu, Jiangnan Li, Yifan Zhou, Shunchi Zhang, Jie Zhou, Wai Lam

Theory-of-Mind (ToM) is a fundamental psychological capability that allows
humans to understand and interpret the mental states of others. Humans infer
others' thoughts by integrating causal cues and indirect clues from broad
contextual information, often derived from past interactions. In other words,
human ToM heavily relies on the understanding about the backgrounds and life
stories of others. Unfortunately, this aspect is largely overlooked in existing
benchmarks for evaluating machines' ToM capabilities, due to their usage of
short narratives without global backgrounds. In this paper, we verify the
importance of understanding long personal backgrounds in ToM and assess the
performance of LLMs in such realistic evaluation scenarios. To achieve this, we
introduce a novel benchmark, CharToM-QA, comprising 1,035 ToM questions based
on characters from classic novels. Our human study reveals a significant
disparity in performance: the same group of educated participants performs
dramatically better when they have read the novels compared to when they have
not. In parallel, our experiments on state-of-the-art LLMs, including the very
recent o1 model, show that LLMs still perform notably worse than humans,
despite that they have seen these stories during pre-training. This highlights
the limitations of current LLMs in capturing the nuanced contextual information
required for ToM reasoning.

摘要：心智理論 (ToM) 是一種基本的心理能力，它使人類能夠理解和詮釋他人的心理狀態。人類透過整合來自廣泛背景資訊的因果線索和間接線索來推論他人的想法，這些資訊通常來自於過去的互動。換句話說，人類的心智理論在很大程度上依賴於對他人背景和人生故事的理解。不幸的是，由於現有的機器心智理論能力評估基準使用沒有全球背景的短篇敘事，因此在很大程度上忽視了這個面向。在本文中，我們驗證了在心智理論中理解長篇個人背景的重要性，並評估大型語言模型 (LLM) 在這種逼真的評估情境中的表現。為此，我們引入了一個新的基準 CharToM-QA，它包含 1,035 個基於經典小說角色的心智理論問題。我們的人類研究揭示了顯著的表現差異：同一群受過教育的參與者在讀過小說後表現顯著優於沒有讀過小說的情況。同時，我們對包括最近的 o1 模型在內的最新大型語言模型進行的實驗表明，儘管大型語言模型在預訓練期間看過這些故事，但它們的表現仍然明顯低於人類。這突顯了當前大型語言模型在捕捉心智理論推理所需細微背景資訊方面的局限性。

##### **AgentRefine: Enhancing Agent Generalization through Refinement Tuning**
2501.01702v1 by Dayuan Fu, Keqing He, Yejie Wang, Wentao Hong, Zhuoma Gongque, Weihao Zeng, Wei Wang, Jingang Wang, Xunliang Cai, Weiran Xu

Large Language Model (LLM) based agents have proved their ability to perform
complex tasks like humans. However, there is still a large gap between
open-sourced LLMs and commercial models like the GPT series. In this paper, we
focus on improving the agent generalization capabilities of LLMs via
instruction tuning. We first observe that the existing agent training corpus
exhibits satisfactory results on held-in evaluation sets but fails to
generalize to held-out sets. These agent-tuning works face severe formatting
errors and are frequently stuck in the same mistake for a long while. We
analyze that the poor generalization ability comes from overfitting to several
manual agent environments and a lack of adaptation to new situations. They
struggle with the wrong action steps and can not learn from the experience but
just memorize existing observation-action relations. Inspired by the insight,
we propose a novel AgentRefine framework for agent-tuning. The core idea is to
enable the model to learn to correct its mistakes via observation in the
trajectory. Specifically, we propose an agent synthesis framework to encompass
a diverse array of environments and tasks and prompt a strong LLM to refine its
error action according to the environment feedback. AgentRefine significantly
outperforms state-of-the-art agent-tuning work in terms of generalization
ability on diverse agent tasks. It also has better robustness facing
perturbation and can generate diversified thought in inference. Our findings
establish the correlation between agent generalization and self-refinement and
provide a new paradigm for future research.

摘要：<paragraph>大型語言模型 (LLM) 基礎代理已證明它們具備執行人類般複雜任務的能力。然而，開源 LLM 與 GPT 系列等商業模型之間仍存在很大差距。在本文中，我們專注於透過指令調整來改善 LLM 的代理概化能力。我們首先觀察到現有的代理訓練語料庫在保留評估集中展現出令人滿意的結果，但無法概化到保留集中。這些代理調整工作面臨嚴重的格式化錯誤，而且經常長時間陷入相同的錯誤中。我們分析出概化能力差來自於過度擬合到幾個手動代理環境，以及缺乏對新情況的適應能力。它們與錯誤的行動步驟作鬥爭，無法從經驗中學習，只能記住現有的觀察行動關係。受此見解啟發，我們提出了用於代理調整的新型 AgentRefine 框架。核心思想是讓模型能夠透過在軌跡中觀察來學習糾正其錯誤。具體來說，我們提出了一個代理合成框架，以涵蓋各種環境和任務，並提示強大的 LLM 根據環境反饋調整其錯誤動作。AgentRefine 在各種代理任務上的概化能力方面顯著優於最先進的代理調整工作。它在面對擾動時也具有更好的魯棒性，並且可以在推理中產生多樣化的思考。我們的研究結果建立了代理概化和自我精進之間的關聯，並為未來的研究提供了新的範例。</paragraph>

##### **VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer for Video-based Remote Physiological Measurement**
2501.01691v1 by Jiachen Li, Shisheng Guo, Longzhen Tang, Cuolong Cui, Lingjiang Kong, Xiaobo Yang

Remote physiological signal measurement based on facial videos, also known as
remote photoplethysmography (rPPG), involves predicting changes in facial
vascular blood flow from facial videos. While most deep learning-based methods
have achieved good results, they often struggle to balance performance across
small and large-scale datasets due to the inherent limitations of convolutional
neural networks (CNNs) and Transformer. In this paper, we introduce VidFormer,
a novel end-to-end framework that integrates 3-Dimension Convolutional Neural
Network (3DCNN) and Transformer models for rPPG tasks. Initially, we conduct an
analysis of the traditional skin reflection model and subsequently introduce an
enhanced model for the reconstruction of rPPG signals. Based on this improved
model, VidFormer utilizes 3DCNN and Transformer to extract local and global
features from input data, respectively. To enhance the spatiotemporal feature
extraction capabilities of VidFormer, we incorporate temporal-spatial attention
mechanisms tailored for both 3DCNN and Transformer. Additionally, we design a
module to facilitate information exchange and fusion between the 3DCNN and
Transformer. Our evaluation on five publicly available datasets demonstrates
that VidFormer outperforms current state-of-the-art (SOTA) methods. Finally, we
discuss the essential roles of each VidFormer module and examine the effects of
ethnicity, makeup, and exercise on its performance.

摘要：基於面部影片的遠端生理訊號測量，也稱為遠端光電容積描記法 (rPPG)，涉及從面部影片預測面部血管血流的變化。雖然大多數基於深度學習的方法都獲得了良好的結果，但由於卷積神經網路 (CNN) 和 Transformer 的固有限制，它們通常難以平衡小規模和大型資料集的效能。在本文中，我們介紹 VidFormer，這是一個整合 3D 卷積神經網路 (3DCNN) 和 Transformer 模型以進行 rPPG 任務的新型端對端架構。最初，我們對傳統的皮膚反射模型進行分析，隨後引入一個增強模型來重建 rPPG 訊號。基於這個改進的模型，VidFormer 分別利用 3DCNN 和 Transformer 從輸入資料中提取局部和全域特徵。為了增強 VidFormer 的時空特徵提取能力，我們結合了專門針對 3DCNN 和 Transformer 設計的時空注意力機制。此外，我們設計了一個模組來促進 3DCNN 和 Transformer 之間的資訊交換和融合。我們對五個公開可用的資料集的評估表明，VidFormer 優於目前的最新技術 (SOTA) 方法。最後，我們討論了 VidFormer 各個模組的基本作用，並探討了種族、化妝和運動對其效能的影響。

##### **Adaptive Few-shot Prompting for Machine Translation with Pre-trained Language Models**
2501.01679v1 by Lei Tang, Jinghui Qin, Wenxuan Ye, Hao Tan, Zhijing Yang

Recently, Large language models (LLMs) with in-context learning have
demonstrated remarkable potential in handling neural machine translation.
However, existing evidence shows that LLMs are prompt-sensitive and it is
sub-optimal to apply the fixed prompt to any input for downstream machine
translation tasks. To address this issue, we propose an adaptive few-shot
prompting (AFSP) framework to automatically select suitable translation
demonstrations for various source input sentences to further elicit the
translation capability of an LLM for better machine translation. First, we
build a translation demonstration retrieval module based on LLM's embedding to
retrieve top-k semantic-similar translation demonstrations from aligned
parallel translation corpus. Rather than using other embedding models for
semantic demonstration retrieval, we build a hybrid demonstration retrieval
module based on the embedding layer of the deployed LLM to build better input
representation for retrieving more semantic-related translation demonstrations.
Then, to ensure better semantic consistency between source inputs and target
outputs, we force the deployed LLM itself to generate multiple output
candidates in the target language with the help of translation demonstrations
and rerank these candidates. Besides, to better evaluate the effectiveness of
our AFSP framework on the latest language and extend the research boundary of
neural machine translation, we construct a high-quality diplomatic
Chinese-English parallel dataset that consists of 5,528 parallel
Chinese-English sentences. Finally, extensive experiments on the proposed
diplomatic Chinese-English parallel dataset and the United Nations Parallel
Corpus (Chinese-English part) show the effectiveness and superiority of our
proposed AFSP.

摘要：<paragraph>最近，具有情境学习功能的大型语言模型 (LLM) 在处理神经机器翻译方面展现出了非凡的潜力。然而，现有证据表明，LLM 对提示语很敏感，将固定的提示语应用于下游机器翻译任务并不是最优的。为了解决这个问题，我们提出了一种自适应少样本提示 (AFSP) 框架，用于自动为各种源输入句子选择合适的翻译示例，以进一步激发 LLM 的翻译能力，从而实现更好的机器翻译。首先，我们基于 LLM 的嵌入构建了一个翻译示例检索模块，从对齐的平行翻译语料库中检索前 k 个语义相似的翻译示例。我们并没有使用其他嵌入模型进行语义示例检索，而是基于已部署 LLM 的嵌入层构建了一个混合示例检索模块，以构建更好的输入表示，用于检索更多语义相关的翻译示例。然后，为了确保源输入和目标输出之间更好的语义一致性，我们强制已部署的 LLM 本身在翻译示例的帮助下生成多种目标语言的输出候选，并对这些候选进行重新排序。此外，为了更好地评估我们的 AFSP 框架在最新语言上的有效性，并扩展神经机器翻译的研究边界，我们构建了一个高质量的外交汉英平行数据集，其中包含 5,528 个平行的汉英句子。最后，在所提出的外交汉英平行数据集和联合国平行语料库（汉英部分）上进行的广泛实验表明了我们提出的 AFSP 的有效性和优越性。</paragraph>

##### **CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis**
2501.01668v1 by Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang

Current inference scaling methods, such as Self-consistency and Best-of-N,
have proven effective in improving the accuracy of LLMs on complex reasoning
tasks. However, these methods rely heavily on the quality of candidate
responses and are unable to produce correct answers when all candidates are
incorrect. In this paper, we propose a novel inference scaling strategy,
CoT-based Synthesizer, which leverages CoT reasoning to synthesize superior
answers by analyzing complementary information from multiple candidate
responses, even when all candidate responses are flawed. To enable a
lightweight and cost-effective implementation, we introduce an automated data
generation pipeline that creates diverse training data. This allows smaller
LLMs trained on this data to improve the inference accuracy of larger models,
including API-based LLMs. Experimental results across four benchmark datasets
with seven policy models demonstrate that our method significantly enhances
performance, with gains of 11.8% for Llama3-8B and 10.3% for GPT-4o on the MATH
dataset. The corresponding training data and code are publicly available on
https://github.com/RUCKBReasoning/CoT-based-Synthesizer.

摘要：目前的推論擴充方法（例如自洽性和最佳 N）已被證明有效提升大型語言模型在複雜推理任務中的準確性。然而，這些方法極度依賴候選回應的品質，且當所有候選回應皆不正確時，無法產生正確的答案。在本文中，我們提出一個新穎的推論擴充策略，基於 CoT 的合成器，它利用 CoT 推理來分析來自多個候選回應的互補資訊，即使所有候選回應都有缺陷，也能合成出優異的答案。為了實現輕量且具成本效益的實作，我們引入一個自動化資料產生管線，用來建立多樣化的訓練資料。這允許在這些資料上訓練的小型語言模型提升大型模型（包括基於 API 的大型語言模型）的推論準確性。在四個基準資料集上，使用七個策略模型進行的實驗結果顯示，我們的模型顯著提升了效能，在 MATH 資料集上，Llama3-8B 獲得 11.8% 的提升，而 GPT-4o 獲得 10.3% 的提升。對應的訓練資料和程式碼已公開於 https://github.com/RUCKBReasoning/CoT-based-Synthesizer。

##### **BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction**
2501.01664v1 by Alaeddine Diaf, Abdelaziz Amara Korba, Nour Elislem Karabadji, Yacine Ghamri-Doudane

The integration of Internet of Things (IoT) technology in various domains has
led to operational advancements, but it has also introduced new vulnerabilities
to cybersecurity threats, as evidenced by recent widespread cyberattacks on IoT
devices. Intrusion detection systems are often reactive, triggered by specific
patterns or anomalies observed within the network. To address this challenge,
this work proposes a proactive approach to anticipate and preemptively mitigate
malicious activities, aiming to prevent potential damage before it occurs. This
paper proposes an innovative intrusion prediction framework empowered by
Pre-trained Large Language Models (LLMs). The framework incorporates two LLMs:
a fine-tuned Bidirectional and AutoRegressive Transformers (BART) model for
predicting network traffic and a fine-tuned Bidirectional Encoder
Representations from Transformers (BERT) model for evaluating the predicted
traffic. By harnessing the bidirectional capabilities of BART the framework
then identifies malicious packets among these predictions. Evaluated using the
CICIoT2023 IoT attack dataset, our framework showcases a notable enhancement in
predictive performance, attaining an impressive 98% overall accuracy, providing
a powerful response to the cybersecurity challenges that confront IoT networks.

摘要：物联网 (IoT) 技术在各个领域的整合带来了运营上的进步，但也引入了新的网络安全威胁漏洞，最近针对物联网设备的广泛网络攻击就是明证。入侵检测系统通常是反应式的，由网络中观察到的特定模式或异常触发。为了应对这一挑战，这项工作提出了一种主动方法来预测和先发制人地减轻恶意活动，旨在在潜在损害发生之前加以预防。本文提出了一种创新的入侵预测框架，由预训练的大语言模型 (LLM) 赋能。该框架包含两个 LLM：一个经过微调的双向和自回归转换器 (BART) 模型，用于预测网络流量，以及一个经过微调的来自转换器的双向编码器表示 (BERT) 模型，用于评估预测的流量。通过利用 BART 的双向能力，该框架随后在这些预测中识别出恶意数据包。使用 CICIoT2023 物联网攻击数据集进行评估，我们的框架展示了预测性能的显着提升，总体准确率达到令人印象深刻的 98%，为物联网网络面临的网络安全挑战提供了有力的应对措施。

##### **EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**
2501.01658v1 by Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi

Weakly-supervised medical image segmentation is gaining traction as it
requires only rough annotations rather than accurate pixel-to-pixel labels,
thereby reducing the workload for specialists. Although some progress has been
made, there is still a considerable performance gap between the label-efficient
methods and fully-supervised one, which can be attributed to the uncertainty
nature of these weak labels. To address this issue, we propose a novel weak
annotation method coupled with its learning framework EAUWSeg to eliminate the
annotation uncertainty. Specifically, we first propose the Bounded Polygon
Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the
tailored learning mechanism that explicitly treat bounded polygons as two
separated annotations is proposed to learn invariant feature by providing
adversarial supervision signal for model training. Subsequently, a
confidence-auxiliary consistency learner incorporates with a
classification-guided confidence generator is designed to provide reliable
supervision signal for pixels in uncertain region by leveraging the feature
presentation consistency across pixels within the same category as well as
class-specific information encapsulated in bounded polygons annotation.
Experimental results demonstrate that EAUWSeg outperforms existing
weakly-supervised segmentation methods. Furthermore, compared to
fully-supervised counterparts, the proposed method not only delivers superior
performance but also costs much less annotation workload. This underscores the
superiority and effectiveness of our approach.

摘要：弱监督医学影像分割正获得关注，因为它只需要粗略的注释，而不是精确的像素到像素标签，从而减少了专家的工作量。尽管取得了一些进展，但在标签高效方法和完全监督方法之间仍然存在相当大的性能差距，这可归因于这些弱标签的不确定性。为了解决这个问题，我们提出了一种新的弱注释方法，并结合其学习框架 EAUWSeg 来消除注释的不确定性。具体来说，我们首先通过简单地为病灶标记两个多边形来提出有界多边形注释 (BPAnno)。然后，提出了将有界多边形明确地视为两个分离注释的定制学习机制，以通过为模型训练提供对抗性监督信号来学习不变特征。随后，置信辅助一致性学习器与分类引导置信度生成器结合设计，以通过利用同一类别内像素的特征表示一致性以及有界多边形注释中封装的特定于类的信息，为不确定区域中的像素提供可靠的监督信号。实验结果表明，EAUWSeg 优于现有的弱监督分割方法。此外，与完全监督的对应方法相比，所提出的方法不仅提供了卓越的性能，而且注释工作量也大大减少。这突出了我们方法的优越性和有效性。

##### **MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments**
2501.01652v1 by Cai Yin, Gu Zhouhong, Du Zhaohan, Ye Zheyu, Cao Shaosheng, Xu Yiqian, Feng Hongwei, Chen Ping

Large Language Models (LLMs) have shown remarkable capabilities in
environmental perception, reasoning-based decision-making, and simulating
complex human behaviors, particularly in interactive role-playing contexts.
This paper introduces the Multiverse Interactive Role-play Ability General
Evaluation (MIRAGE), a comprehensive framework designed to assess LLMs'
proficiency in portraying advanced human behaviors through murder mystery
games. MIRAGE features eight intricately crafted scripts encompassing diverse
themes and styles, providing a rich simulation. To evaluate LLMs' performance,
MIRAGE employs four distinct methods: the Trust Inclination Index (TII) to
measure dynamics of trust and suspicion, the Clue Investigation Capability
(CIC) to measure LLMs' capability of conducting information, the Interactivity
Capability Index (ICI) to assess role-playing capabilities and the Script
Compliance Index (SCI) to assess LLMs' capability of understanding and
following instructions. Our experiments indicate that even popular models like
GPT-4 face significant challenges in navigating the complexities presented by
the MIRAGE. The datasets and simulation codes are available in
\href{https://github.com/lime728/MIRAGE}{github}.

摘要：大型語言模型 (LLM) 在環境感知、基於推理的決策制定和模擬複雜的人類行為方面展現出卓越的能力，尤其是在互動角色扮演的情境中。本文介紹了多元互動角色扮演能力通用評估 (MIRAGE)，這是一個全面的架構，旨在透過謀殺謎團遊戲來評估 LLM 在描繪進階人類行為方面的能力。MIRAGE 具備八個精心製作的腳本，涵蓋多元的主題和風格，提供豐富的模擬。為了評估 LLM 的表現，MIRAGE 採用四種不同的方法：信任傾向指數 (TII) 來衡量信任和懷疑的動態，線索調查能力 (CIC) 來衡量 LLM 進行資訊的能力，互動能力指數 (ICI) 來評估角色扮演能力，以及腳本遵循指數 (SCI) 來評估 LLM 理解和遵循指示的能力。我們的實驗指出，即使是像 GPT-4 這樣熱門的模型，在應對 MIRAGE 所呈現的複雜性時，也面臨著重大的挑戰。資料集和模擬程式碼可在 \href{https://github.com/lime728/MIRAGE}{github} 中取得。

##### **AVATAR: Adversarial Autoencoders with Autoregressive Refinement for Time Series Generation**
2501.01649v1 by MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi

Data augmentation can significantly enhance the performance of machine
learning tasks by addressing data scarcity and improving generalization.
However, generating time series data presents unique challenges. A model must
not only learn a probability distribution that reflects the real data
distribution but also capture the conditional distribution at each time step to
preserve the inherent temporal dependencies. To address these challenges, we
introduce AVATAR, a framework that combines Adversarial Autoencoders (AAE) with
Autoregressive Learning to achieve both objectives. Specifically, our technique
integrates the autoencoder with a supervisor and introduces a novel supervised
loss to assist the decoder in learning the temporal dynamics of time series
data. Additionally, we propose another innovative loss function, termed
distribution loss, to guide the encoder in more efficiently aligning the
aggregated posterior of the autoencoder's latent representation with a prior
Gaussian distribution. Furthermore, our framework employs a joint training
mechanism to simultaneously train all networks using a combined loss, thereby
fulfilling the dual objectives of time series generation. We evaluate our
technique across a variety of time series datasets with diverse
characteristics. Our experiments demonstrate significant improvements in both
the quality and practical utility of the generated data, as assessed by various
qualitative and quantitative metrics.

摘要：資料增強可藉由解決資料稀少和改善概化來顯著提升機器學習任務的效能。
然而，產生時間序列資料會產生獨特的挑戰。模型不僅必須學習反映真實資料分佈的機率分佈，還必須擷取每個時間步驟的條件式分佈，以保留內在時間依賴性。為了應對這些挑戰，我們引進 AVATAR，一個結合對抗式自動編碼器 (AAE) 和自迴歸學習的架構，以達成這兩個目標。具體來說，我們的技術將自動編碼器與監督器整合，並引入一種新穎的監督損失，以協助解碼器學習時間序列資料的時間動態。此外，我們提出另一種創新的損失函數，稱為分佈損失，以引導編碼器更有效率地將自動編碼器潛在表徵的彙總後驗與先驗高斯分佈對齊。此外，我們的架構採用聯合訓練機制，以使用組合損失同時訓練所有網路，從而達成時間序列產生的雙重目標。我們在各種具有不同特徵的時間序列資料集上評估我們的技術。我們的實驗證明，在各種定性和定量指標的評估下，產生的資料品質和實用性都有顯著的提升。

##### **HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding**
2501.01645v1 by Heqing Zou, Tianze Luo, Guiyang Xie, Victor, Zhang, Fengmao Lv, Guangcong Wang, Junyang Chen, Zhuochen Wang, Hansheng Zhang, Huaijian Zhang

Multimodal large language models have become a popular topic in deep visual
understanding due to many promising real-world applications. However, hour-long
video understanding, spanning over one hour and containing tens of thousands of
visual frames, remains under-explored because of 1) challenging long-term video
analyses, 2) inefficient large-model approaches, and 3) lack of large-scale
benchmark datasets. Among them, in this paper, we focus on building a
large-scale hour-long long video benchmark, HLV-1K, designed to evaluate long
video understanding models. HLV-1K comprises 1009 hour-long videos with 14,847
high-quality question answering (QA) and multi-choice question asnwering (MCQA)
pairs with time-aware query and diverse annotations, covering frame-level,
within-event-level, cross-event-level, and long-term reasoning tasks. We
evaluate our benchmark using existing state-of-the-art methods and demonstrate
its value for testing deep long video understanding capabilities at different
levels and for various tasks. This includes promoting future long video
understanding tasks at a granular level, such as deep understanding of long
live videos, meeting recordings, and movies.

摘要：多模态大型语言模型由于许多有前景的实际应用，已成为深度视觉理解中的热门话题。然而，长达一小时、跨越一个小时并包含数万个视觉帧的视频理解仍然未得到充分探索，原因有 1）具有挑战性的长期视频分析，2）低效的大模型方法，以及 3）缺乏大规模基准数据集。其中，在本文中，我们专注于构建一个大规模的小时级长视频基准 HLV-1K，旨在评估长视频理解模型。HLV-1K 包含 1009 个小时长的视频，其中有 14,847 个高质量的问答 (QA) 和多项选择问答 (MCQA) 对，带有时间感知查询和多样化的注释，涵盖帧级、事件内级、跨事件级和长期推理任务。我们使用现有的最先进方法评估我们的基准，并展示了其在不同级别和各种任务中测试深度长视频理解能力的价值。这包括在细粒度级别促进未来的长视频理解任务，例如深入理解长直播视频、会议记录和电影。

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

摘要：生物医学知識圖譜 (BKG) 整合多樣化的資料集，以闡明生物醫學領域內的複雜關係。在這些圖譜上進行有效的連結預測，可以發現有價值的連結，例如潛在的新藥物-疾病關係。我們引入了一種新穎的多模態方法，它將來自專用語言模型 (LM) 的嵌入與圖形對比學習 (GCL) 統一起來，以增強實體內關係，同時採用知識圖形嵌入 (KGE) 模型來捕捉實體間關係，以進行有效的連結預測。為了解決現有 BKG 中的限制，我們提出了 PrimeKG++，這是一個豐富的知識圖形，它結合了多模態數據，包括每種類型實體的生物序列和文字描述。通過在統一表示中結合語義和關係資訊，我們的做法展示了強大的概括性，即使對於未見節點也能進行準確的連結預測。在 PrimeKG++ 和 DrugBank 藥物-標靶交互作用資料集上的實驗結果證明了我們的方法在各種生物醫學資料集中的有效性和穩健性。我們的原始碼、預訓練模型和資料可在 https://github.com/HySonLab/BioMedKG 公開取得。

##### **A non-ergodic framework for understanding emergent capabilities in Large Language Models**
2501.01638v1 by Javier Marin

Large language models have emergent capabilities that come unexpectedly at
scale, but we need a theoretical framework to explain why and how they emerge.
We prove that language models are actually non-ergodic systems while providing
a mathematical framework based on Stuart Kauffman's theory of the adjacent
possible (TAP) to explain capability emergence. Our resource-constrained TAP
equation demonstrates how architectural, training, and contextual constraints
interact to shape model capabilities through phase transitions in semantic
space. We prove through experiments with three different language models that
capacities emerge through discrete transitions guided by constraint
interactions and path-dependent exploration. This framework provides a
theoretical basis for understanding emergence in language models and guides the
development of architectures that can guide capability emergence.

摘要：大型語言模型具有在規模上意外出現的新興能力，但我們需要一個理論框架來解釋它們為何以及如何出現。我們證明語言模型實際上是非遍历系統，同時提供一個基於 Stuart Kauffman 的相鄰可能理論 (TAP) 的數學框架來解釋能力的出現。我們受資源限制的 TAP 方程式展示了架構、訓練和上下文限制如何透過語義空間中的相變來交互形塑模型能力。我們透過三個不同的語言模型的實驗證明，能力會透過受限制交互作用和路徑依賴探索引導的離散轉換而出現。這個框架提供了一個理解語言模型中出現的理論基礎，並指導可以引導能力出現的架構的發展。

##### **Crossing Language Borders: A Pipeline for Indonesian Manhwa Translation**
2501.01629v1 by Nithyasri Narasimhan, Sagarika Singh

In this project, we develop a practical and efficient solution for automating
the Manhwa translation from Indonesian to English. Our approach combines
computer vision, text recognition, and natural language processing techniques
to streamline the traditionally manual process of Manhwa(Korean comics)
translation. The pipeline includes fine-tuned YOLOv5xu for speech bubble
detection, Tesseract for OCR and fine-tuned MarianMT for machine translation.
By automating these steps, we aim to make Manhwa more accessible to a global
audience while saving time and effort compared to manual translation methods.
While most Manhwa translation efforts focus on Japanese-to-English, we focus on
Indonesian-to-English translation to address the challenges of working with
low-resource languages. Our model shows good results at each step and was able
to translate from Indonesian to English efficiently.

摘要：在這個專案中，我們開發了一個實用且有效率的解決方案，用於自動化印尼文轉換成英文的漫畫翻譯。我們的做法結合了電腦視覺、文字辨識和自然語言處理技術，以簡化漫畫（韓國漫畫）翻譯的傳統手動流程。此管道包含針對對話框偵測進行微調的 YOLOv5xu、針對 OCR 的 Tesseract 以及針對機器翻譯進行微調的 MarianMT。透過自動化這些步驟，我們希望讓漫畫更易於全球觀眾使用，同時與手動翻譯方法相比，節省時間和精力。雖然大多數漫畫翻譯工作都專注於日文轉換成英文，但我們專注於印尼文轉換成英文翻譯，以解決使用低資源語言時所面臨的挑戰。我們的模型在每個步驟都展現出良好的結果，並且能夠有效率地從印尼文翻譯成英文。

##### **ICPC: In-context Prompt Compression with Faster Inference**
2501.01625v1 by Ziyang Yu, Yuyu Liu

Despite the recent success of Large Language Models (LLMs), it remains
challenging to feed LLMs with long prompts due to the fixed size of LLM inputs.
As a remedy, prompt compression becomes a promising solution by removing
redundant tokens in the prompt. However, using LLM in the existing works
requires additional computation resources and leads to memory overheads. To
address it, we propose ICPC (In-context Prompt Compression), a novel and
scalable prompt compression method that adaptively reduces the prompt length.
The key idea of ICPC is to calculate the probability of each word appearing in
the prompt using encoders and calculate information carried by each word
through the information function, which effectively reduces the information
loss during prompt compression and increases the speed of compression.
Empirically, we demonstrate that ICPC can effectively compress long texts of
different categories and thus achieve better performance and speed on different
types of NLP tasks.

摘要：儘管大型語言模型 (LLM) 近期獲得成功，但由於 LLM 輸入具有固定大小，因此要以長提示輸入 LLM 仍然具有挑戰性。作為補救措施，提示壓縮透過移除提示中重複的符號，成為一個有前途的解決方案。然而，在現有作品中使用 LLM 需要額外的運算資源，並導致記憶體負擔過重。為了解決這個問題，我們提出 ICPC（語境提示壓縮），這是一種新穎且可擴充的提示壓縮方法，可以自適應地縮短提示長度。ICPC 的關鍵思想是使用編碼器計算每個字出現在提示中的機率，並透過資訊函數計算每個字所承載的資訊，這會在提示壓縮過程中有效地減少資訊損失，並提高壓縮速度。根據經驗，我們證明 ICPC 可以有效壓縮不同類別的長文字，因此在不同類型的 NLP 任務上獲得更好的效能和速度。

##### **Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**
2501.01618v1 by Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang

Medical image segmentation demands the aggregation of global and local
feature representations, posing a challenge for current methodologies in
handling both long-range and short-range feature interactions. Recently, vision
mamba (ViM) models have emerged as promising solutions for addressing model
complexities by excelling in long-range feature iterations with linear
complexity. However, existing ViM approaches overlook the importance of
preserving short-range local dependencies by directly flattening spatial tokens
and are constrained by fixed scanning patterns that limit the capture of
dynamic spatial context information. To address these challenges, we introduce
a simple yet effective method named context clustering ViM (CCViM), which
incorporates a context clustering module within the existing ViM models to
segment image tokens into distinct windows for adaptable local clustering. Our
method effectively combines long-range and short-range feature interactions,
thereby enhancing spatial contextual representations for medical image
segmentation tasks. Extensive experimental evaluations on diverse public
datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the
superior performance of our method compared to current state-of-the-art
methods. Our code can be found at https://github.com/zymissy/CCViM.

摘要：醫療影像分割需要聚合全局和局部特徵表示，對當前方法處理長程和短程特徵交互構成挑戰。最近，視覺曼巴 (ViM) 模型已成為解決模型複雜性的有前途的解決方案，它在線性複雜度下擅長長程特徵迭代。然而，現有的 ViM 方法忽視了透過直接壓平空間標記來保留短程局部依賴性的重要性，並且受到限制的掃描模式的約束，這會限制動態空間背景資訊的擷取。為了解決這些挑戰，我們引入了一種名為背景聚類 ViM (CCViM) 的簡單但有效的方法，它在現有的 ViM 模型中加入了一個背景聚類模組，將影像標記分割成不同的視窗，以進行適應性局部聚類。我們的模型有效地結合了長程和短程特徵交互，從而增強了用於醫療影像分割任務的空間背景表示。在各種公開資料集（即 Kumar、CPM17、ISIC17、ISIC18 和 Synapse）上進行的廣泛實驗評估證明了我們的方法與當前最先進方法相比具有卓越的效能。我們的程式碼可以在 https://github.com/zymissy/CCViM 找到。

##### **Google is all you need: Semi-Supervised Transfer Learning Strategy For Light Multimodal Multi-Task Classification Model**
2501.01611v1 by Haixu Liu, Penghao Jiang, Zerui Tao

As the volume of digital image data increases, the effectiveness of image
classification intensifies. This study introduces a robust multi-label
classification system designed to assign multiple labels to a single image,
addressing the complexity of images that may be associated with multiple
categories (ranging from 1 to 19, excluding 12). We propose a multi-modal
classifier that merges advanced image recognition algorithms with Natural
Language Processing (NLP) models, incorporating a fusion module to integrate
these distinct modalities. The purpose of integrating textual data is to
enhance the accuracy of label prediction by providing contextual understanding
that visual analysis alone cannot fully capture. Our proposed classification
model combines Convolutional Neural Networks (CNN) for image processing with
NLP techniques for analyzing textual description (i.e., captions). This
approach includes rigorous training and validation phases, with each model
component verified and analyzed through ablation experiments. Preliminary
results demonstrate the classifier's accuracy and efficiency, highlighting its
potential as an automatic image-labeling system.

摘要：隨著數位影像資料量增加，影像分類的有效性也隨之提升。本研究提出一個健全的多標籤分類系統，旨在為單一影像分配多個標籤，以解決可能與多個類別（範圍從 1 到 19，不包括 12）相關的影像複雜性。我們提出一個多模式分類器，將進階影像辨識演算法與自然語言處理（NLP）模型合併，並結合一個融合模組來整合這些不同的模式。整合文字資料的目的是透過提供視覺分析無法完全捕捉的脈絡理解，來提升標籤預測的準確度。我們提出的分類模型結合了用於影像處理的卷積神經網路（CNN）和用於分析文字描述（即標題）的 NLP 技術。此方法包含嚴格的訓練和驗證階段，並透過消融實驗驗證和分析每個模型元件。初步結果證明了分類器的準確性和效率，突顯其作為自動影像標籤系統的潛力。

##### **Prism: Mining Task-aware Domains in Non-i.i.d. IMU Data for Flexible User Perception**
2501.01598v1 by Yunzhe Li, Facheng Hu, Hongzi Zhu, Quan Liu, Xiaoke Zhao, Jiangang Shen, Shan Chang, Minyi Guo

A wide range of user perception applications leverage inertial measurement
unit (IMU) data for online prediction. However, restricted by the non-i.i.d.
nature of IMU data collected from mobile devices, most systems work well only
in a controlled setting (e.g., for a specific user in particular postures),
limiting application scenarios. To achieve uncontrolled online prediction on
mobile devices, referred to as the flexible user perception (FUP) problem, is
attractive but hard. In this paper, we propose a novel scheme, called Prism,
which can obtain high FUP accuracy on mobile devices. The core of Prism is to
discover task-aware domains embedded in IMU dataset, and to train a
domain-aware model on each identified domain. To this end, we design an
expectation-maximization (EM) algorithm to estimate latent domains with respect
to the specific downstream perception task. Finally, the best-fit model can be
automatically selected for use by comparing the test sample and all identified
domains in the feature space. We implement Prism on various mobile devices and
conduct extensive experiments. Results demonstrate that Prism can achieve the
best FUP performance with a low latency.

摘要：各種使用者感知應用程式利用慣性測量單元 (IMU) 資料進行線上預測。然而，由於從行動裝置收集的 IMU 資料具有非獨立同分布的特性，因此大多數系統僅在受控環境下運作良好（例如，針對特定姿勢的特定使用者），這限制了應用情境。要達成行動裝置上的非受控線上預測，也就是所謂的彈性使用者感知 (FUP) 問題，具有吸引力，但卻很困難。在本文中，我們提出一個名為 Prism 的新穎架構，它可以在行動裝置上獲得高 FUP 準確度。Prism 的核心是找出嵌入在 IMU 資料集中的與任務相關的領域，並在每個已識別的領域上訓練一個與領域相關的模型。為此，我們設計了一個期望最大化 (EM) 演算法來估計與特定下游感知任務相關的潛在領域。最後，可以透過比較測試樣本和特徵空間中所有已識別的領域，自動選擇最合適的模型供使用。我們在各種行動裝置上實作 Prism，並進行廣泛的實驗。結果證明，Prism 可以以低延遲達成最佳 FUP 效能。

##### **PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**
2501.01594v1 by Jingoo Lee, Kyungho Lim, Young-Chul Jung, Byung-Hoon Kim

Recent advances in large language models (LLMs) have accelerated the
development of conversational agents capable of generating human-like
responses. Since psychiatric assessments typically involve complex
conversational interactions between psychiatrists and patients, there is
growing interest in developing LLM-based psychiatric assessment conversational
agents (PACAs) that aim to simulate the role of psychiatrists in clinical
evaluations. However, standardized methods for benchmarking the clinical
appropriateness of PACAs' interaction with patients still remain underexplored.
Here, we propose PSYCHE, a novel framework designed to enable the 1) clinically
relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation
of PACAs. This is achieved by simulating psychiatric patients based on a
multi-faceted psychiatric construct that defines the simulated patients'
profiles, histories, and behaviors, which PACAs are expected to assess. We
validate the effectiveness of PSYCHE through a study with 10 board-certified
psychiatrists, supported by an in-depth analysis of the simulated patient
utterances.

摘要：大型語言模型 (LLM) 的最新進展加速了會話代理的開發，這些代理能夠產生類似人類的回應。由於精神科評估通常涉及精神科醫師和患者之間複雜的會話互動，因此對於開發基於 LLM 的精神科評估會話代理 (PACA) 的興趣與日俱增，這些代理旨在模擬精神科醫師在臨床評估中的角色。然而，用於評量 PACA 與患者互動的臨床適當性的標準化方法仍未被充分探討。在此，我們提出 PSYCHE，一個新穎的框架，旨在實現 1) 臨床相關、2) 道德安全、3) 成本效益，以及 4) PACA 的定量評估。這是透過模擬基於多面向精神科建構的精神科患者來實現的，該建構定義了模擬患者的個人資料、病史和行為，而 PACA 預計會評估這些內容。我們透過一項有 10 位經認證的精神科醫師參與的研究驗證了 PSYCHE 的有效性，並輔以對模擬患者話語的深入分析。

##### **(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges**
2501.01588v1 by Mohamed Hisham Abdellatif

Large Language Models (LLMs) have become essential tools across various
domains due to their impressive capabilities in understanding and generating
human-like text. The ability to accurately answer multiple-choice questions
(MCQs) holds significant value in education, particularly in automated tutoring
systems and assessment platforms. However, adapting LLMs to handle MCQ tasks
effectively remains challenging due to the hallucinations and unclear prompts.
This work explores the potential of Microsoft's PHI-3\cite{Abdin2024}, a
compact yet efficient LLM, for MCQ answering. Our contributions include
fine-tuning the model on the TruthfulQA dataset, designing optimized prompts to
enhance model performance, and evaluating using perplexity and traditional
metrics like accuracy and F1 score. Results show a remarkable improvement in
PHI-3.5's MCQ handling post-fine-tuning, with perplexity decreasing from 4.68
to 2.27, and accuracy rising from 62\% to 90.8\%. This research underlines the
importance of efficient models in adaptive learning systems and educational
assessments, paving the way for broader integration into the classroom,
particularly in fields like test preparation, student feedback, and
personalized learning.

摘要：大型語言模型 (LLM) 由於其在理解和生成類人文本方面的驚人能力，已成為各種領域的必備工具。準確回答多選題 (MCQ) 的能力在教育中具有重要價值，尤其是在自動化輔導系統和評估平台中。然而，由於幻覺和提示不明確，使 LLM 適應 MCQ 任務仍然具有挑戰性。這項工作探討了微軟的 PHI-3\cite{Abdin2024} 的潛力，這是一個緊湊但高效的 LLM，用於 MCQ 回答。我們的貢獻包括在 TruthfulQA 資料集上微調模型，設計最佳提示以增強模型效能，並使用困惑度和傳統指標（如準確度和 F1 分數）進行評估。結果顯示，PHI-3.5 在微調後的 MCQ 處理方面有顯著改善，困惑度從 4.68 降低到 2.27，準確度從 62% 提高到 90.8%。這項研究強調了高效模型在適應性學習系統和教育評估中的重要性，為更廣泛地整合到課堂中鋪平了道路，特別是在考試準備、學生回饋和個人化學習等領域。

##### **Constructing and explaining machine learning models for chemistry: example of the exploration and design of boron-based Lewis acids**
2501.01576v1 by Juliette Fenogli, Laurence Grimaud, Rodolphe Vuilleumier

The integration of machine learning (ML) into chemistry offers transformative
potential in the design of molecules. However, the focus has often been on
creating highly efficient predictive models, sometimes at the expense of
interpretability. We leverage explainable AI techniques to explore the design
of boron-based Lewis acids, which play a pivotal role in organic reactions.
Using Fluoride Ion Affinity as a proxy for Lewis acidity, we developed
interpretable ML models based on chemically meaningful descriptors, including
ab initio features and substituent-based parameters. By constraining the
chemical space to well-defined molecular scaffolds, we achieved highly accurate
predictions, surpassing conventional black-box deep learning models in low-data
regime. Interpretability analyses of the models unraveled the origin of Lewis
acidity in these compounds and identified actionable levers to modulate it.
This work bridges ML and chemist's way of thinking, demonstrating how
explainable models can inspire molecular design and enhance scientific
understanding of chemical reactivity.

摘要：機器學習 (ML) 整合到化學中，在分子設計方面提供了變革潛力。然而，重點往往放在建立高效率的預測模型，有時會犧牲可解釋性。我們利用可解釋的 AI 技術來探索硼基路易斯酸的設計，這些酸在有機反應中扮演著關鍵角色。使用氟離子親和力作為路易斯酸度的代理，我們根據化學上有意義的描述符開發了可解釋的 ML 模型，包括從頭算特徵和取代基參數。透過將化學空間限制在定義良好的分子支架中，我們實現了高度準確的預測，在低資料模式中超越了傳統的黑箱深度學習模型。對模型的可解釋性分析揭示了這些化合物中路易斯酸度的來源，並找出可行的槓桿來調整它。這項工作聯繫了 ML 和化學家的思維方式，展示了可解釋模型如何激勵分子設計，並增強對化學反應性的科學理解。

##### **Predicting the Performance of Black-box LLMs through Self-Queries**
2501.01558v1 by Dylan Sam, Marc Finzi, J. Zico Kolter

As large language models (LLMs) are increasingly relied on in AI systems,
predicting when they make mistakes is crucial. While a great deal of work in
the field uses internal representations to interpret model behavior, these
representations are inaccessible when given solely black-box access through an
API. In this paper, we extract features of LLMs in a black-box manner by using
follow-up prompts and taking the probabilities of different responses as
representations to train reliable predictors of model behavior. We demonstrate
that training a linear model on these low-dimensional representations produces
reliable and generalizable predictors of model performance at the instance
level (e.g., if a particular generation correctly answers a question).
Remarkably, these can often outperform white-box linear predictors that operate
over a model's hidden state or the full distribution over its vocabulary. In
addition, we demonstrate that these extracted features can be used to evaluate
more nuanced aspects of a language model's state. For instance, they can be
used to distinguish between a clean version of GPT-4o-mini and a version that
has been influenced via an adversarial system prompt that answers
question-answering tasks incorrectly or introduces bugs into generated code.
Furthermore, they can reliably distinguish between different model
architectures and sizes, enabling the detection of misrepresented models
provided through an API (e.g., identifying if GPT-3.5 is supplied instead of
GPT-4o-mini).

摘要：隨著大型語言模型 (LLM) 在 AI 系統中越來越受重視，預測它們何時會犯錯至關重要。雖然該領域的大量工作使用內部表示來詮釋模型行為，但當僅通過 API 授予黑盒存取權時，這些表示是無法存取的。在本文中，我們使用後續提示並將不同回應的機率作為表示，以黑盒方式萃取 LLM 的特徵，以訓練可靠的模型行為預測器。我們證明在這些低維度表示上訓練線性模型會產生可靠且可概化的模型效能預測器，在個體層級（例如，特定生成是否正確回答問題）。值得注意的是，這些通常可以優於在模型的隱藏狀態或其詞彙的完整分配上運作的白盒線性預測器。此外，我們證明這些萃取的特徵可用於評估語言模型狀態的更多細微面向。例如，它們可用於區分 GPT-4o-mini 的乾淨版本和透過對抗式系統提示影響的版本，該提示會錯誤回答問答任務或在生成的程式碼中引入錯誤。此外，它們可以可靠地區分不同的模型架構和大小，從而能夠偵測透過 API 提供的失真模型（例如，識別是否提供 GPT-3.5 而不是 GPT-4o-mini）。

##### **Many of Your DPOs are Secretly One: Attempting Unification Through Mutual Information**
2501.01544v1 by Rasul Tutnov, Antoine Grosnit, Haitham Bou-Ammar

Post-alignment of large language models (LLMs) is critical in improving their
utility, safety, and alignment with human intentions. Direct preference
optimisation (DPO) has become one of the most widely used algorithms for
achieving this alignment, given its ability to optimise models based on human
feedback directly. However, the vast number of DPO variants in the literature
has made it increasingly difficult for researchers to navigate and fully grasp
the connections between these approaches. This paper introduces a unifying
framework inspired by mutual information, which proposes a new loss function
with flexible priors. By carefully specifying these priors, we demonstrate that
many existing algorithms, such as SimPO, TDPO, SparsePO, and others, can be
derived from our framework. This unification offers a clearer and more
structured approach, allowing researchers to understand the relationships
between different DPO variants better. We aim to simplify the landscape of DPO
algorithms, making it easier for the research community to gain insights and
foster further advancements in LLM alignment. Ultimately, we hope our framework
can be a foundation for developing more robust and interpretable alignment
techniques.

摘要：大型語言模型 (LLM) 的後對齊對於改善它們的效用、安全性以及與人類意圖的對齊至關重要。直接偏好最佳化 (DPO) 已成為實現此對齊最廣泛使用的演算法之一，因為它能夠根據人類的回饋直接最佳化模型。然而，文獻中大量的 DPO 變體使得研究人員越來越難以瀏覽和完全掌握這些方法之間的關聯。本文介紹了一個受互信息啟發的統一框架，提出了一個具有靈活先驗的新損失函數。透過仔細指定這些先驗，我們證明了許多現有演算法，例如 SimPO、TDPO、SparsePO 等，都可以從我們的框架中推導出來。這種統一提供了一個更清晰、更結構化的方法，讓研究人員能夠更深入地了解不同 DPO 變體之間的關係。我們的目標是簡化 DPO 演算法的格局，讓研究社群更容易獲得見解，並促進 LLM 對齊的進一步發展。最終，我們希望我們的框架可以作為開發更穩健且可解釋的對齊技術的基礎。

##### **BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery**
2501.01540v1 by Kanishk Gandhi, Michael Y. Li, Lyle Goodyear, Louise Li, Aditi Bhaskar, Mohammed Zaman, Noah D. Goodman

Understanding the world and explaining it with scientific theories is a
central aspiration of artificial intelligence research. Proposing theories,
designing experiments to test them, and then revising them based on data are
fundamental to scientific discovery. Despite the significant promise of
LLM-based scientific agents, no benchmarks systematically test LLM's ability to
propose scientific models, collect experimental data, and revise them in light
of new data. We introduce BoxingGym, a benchmark with 10 environments for
systematically evaluating both experimental design (e.g. collecting data to
test a scientific theory) and model discovery (e.g. proposing and revising
scientific theories). To enable tractable and quantitative evaluation, we
implement each environment as a generative probabilistic model with which a
scientific agent can run interactive experiments. These probabilistic models
are drawn from various real-world scientific domains ranging from psychology to
ecology. To quantitatively evaluate a scientific agent's ability to collect
informative experimental data, we compute the expected information gain (EIG),
an information-theoretic quantity which measures how much an experiment reduces
uncertainty about the parameters of a generative model. A good scientific
theory is a concise and predictive explanation. Therefore, to quantitatively
evaluate model discovery, we ask a scientific agent to explain their model and
then assess whether this explanation enables another scientific agent to make
reliable predictions about this environment. In addition to this
explanation-based evaluation, we compute standard model evaluation metrics such
as prediction errors. We find that current LLMs, such as GPT-4o, struggle with
both experimental design and model discovery. We find that augmenting the
LLM-based agent with an explicit statistical model does not reliably improve
these results.

摘要：<paragraph>理解世界并用科学理论解释世界是人工智能研究的核心追求。提出理论、设计实验来测试它们，然后根据数据修改它们是科学发现的基础。尽管基于 LLM 的科学代理具有显著的前景，但没有基准系统地测试 LLM 提出科学模型、收集实验数据以及根据新数据修改它们的能力。我们引入了 BoxingGym，这是一个包含 10 个环境的基准，用于系统地评估实验设计（例如收集数据来测试科学理论）和模型发现（例如提出和修改科学理论）。为了实现易处理和定量的评估，我们将每个环境实现为一个生成概率模型，科学代理可以使用该模型运行交互式实验。这些概率模型取自从心理学到生态学的各种现实世界科学领域。为了定量评估科学代理收集信息性实验数据的能力，我们计算期望信息增益 (EIG)，这是一个信息论量，用于衡量实验在多大程度上减少了对生成模型参数的不确定性。一个好的科学理论是一个简洁且具有预测性的解释。因此，为了定量评估模型发现，我们要求科学代理解释他们的模型，然后评估这种解释是否使另一个科学代理能够对该环境做出可靠的预测。除了这种基于解释的评估之外，我们还计算标准模型评估指标，例如预测误差。我们发现，当前的 LLM（例如 GPT-4o）在实验设计和模型发现方面都存在困难。我们发现，用显式统计模型增强基于 LLM 的代理并不能可靠地改善这些结果。</paragraph>

##### **Improving Robustness Estimates in Natural Language Explainable AI though Synonymity Weighted Similarity Measures**
2501.01516v1 by Christopher Burger

Explainable AI (XAI) has seen a surge in recent interest with the
proliferation of powerful but intractable black-box models. Moreover, XAI has
come under fire for techniques that may not offer reliable explanations. As
many of the methods in XAI are themselves models, adversarial examples have
been prominent in the literature surrounding the effectiveness of XAI, with the
objective of these examples being to alter the explanation while maintaining
the output of the original model. For explanations in natural language, it is
natural to use measures found in the domain of information retrieval for use
with ranked lists to guide the adversarial XAI process. We show that the
standard implementation of these measures are poorly suited for the comparison
of explanations in adversarial XAI and amend them by using information that is
discarded, the synonymity of perturbed words. This synonymity weighting
produces more accurate estimates of the actual weakness of XAI methods to
adversarial examples.

摘要：可解釋 AI (XAI) 隨著功能強大但難以處理的黑盒模型的激增，在近期引起了廣泛的興趣。此外，XAI 也因為可能無法提供可靠解釋的技術而受到抨擊。由於 XAI 中的許多方法本身就是模型，因此對抗範例在 XAI 有效性相關文獻中備受關注，這些範例的目標是改變解釋，同時維持原始模型的輸出。對於自然語言中的解釋，使用資訊檢索領域中用於引導對抗 XAI 程序的已排序清單中找到的測量值是很自然的。我們表明，這些測量值的標準實作並不適合用於對抗 XAI 中的解釋比較，並透過使用被捨棄的資訊（擾動字詞的同義性）來修改它們。這種同義性加權產生了更準確的 XAI 方法對抗範例實際弱點估計。

##### **DiagrammaticLearning: A Graphical Language for Compositional Training Regimes**
2501.01515v1 by Mason Lary, Richard Samuelson, Alexander Wilentz, Alina Zare, Matthew Klawonn, James P. Fairbanks

Motivated by deep learning regimes with multiple interacting yet distinct
model components, we introduce learning diagrams, graphical depictions of
training setups that capture parameterized learning as data rather than code. A
learning diagram compiles to a unique loss function on which component models
are trained. The result of training on this loss is a collection of models
whose predictions ``agree" with one another. We show that a number of popular
learning setups such as few-shot multi-task learning, knowledge distillation,
and multi-modal learning can be depicted as learning diagrams. We further
implement learning diagrams in a library that allows users to build diagrams of
PyTorch and Flux.jl models. By implementing some classic machine learning use
cases, we demonstrate how learning diagrams allow practitioners to build
complicated models as compositions of smaller components, identify
relationships between workflows, and manipulate models during or after
training. Leveraging a category theoretic framework, we introduce a rigorous
semantics for learning diagrams that puts such operations on a firm
mathematical foundation.

摘要：受具有多个相互作用但不同的模型组件的深度学习机制启发，我们引入了学习图，这是训练设置的图形描述，它将参数化学习捕获为数据而不是代码。学习图编译成一个独特的损失函数，组件模型在该函数上进行训练。在该损失上进行训练的结果是一组模型，它们的预测相互“一致”。我们表明，许多流行的学习设置，例如少样本多任务学习、知识蒸馏和多模态学习，都可以描述为学习图。我们还在一个库中进一步实现了学习图，该库允许用户构建 PyTorch 和 Flux.jl 模型的图。通过实现一些经典的机器学习用例，我们展示了学习图如何允许从业者将复杂的模型构建为较小组件的组合，识别工作流之间的关系，并在训练期间或训练后操作模型。利用范畴论框架，我们为学习图引入了一个严格的语义，为这些操作奠定了坚实的数学基础。

##### **AI-Enabled Operations at Fermi Complex: Multivariate Time Series Prediction for Outage Prediction and Diagnosis**
2501.01509v1 by Milan Jain, Burcu O. Mutlu, Caleb Stam, Jan Strube, Brian A. Schupbach, Jason M. St. John, William A. Pellico

The Main Control Room of the Fermilab accelerator complex continuously
gathers extensive time-series data from thousands of sensors monitoring the
beam. However, unplanned events such as trips or voltage fluctuations often
result in beam outages, causing operational downtime. This downtime not only
consumes operator effort in diagnosing and addressing the issue but also leads
to unnecessary energy consumption by idle machines awaiting beam restoration.
The current threshold-based alarm system is reactive and faces challenges
including frequent false alarms and inconsistent outage-cause labeling. To
address these limitations, we propose an AI-enabled framework that leverages
predictive analytics and automated labeling. Using data from $2,703$ Linac
devices and $80$ operator-labeled outages, we evaluate state-of-the-art deep
learning architectures, including recurrent, attention-based, and linear
models, for beam outage prediction. Additionally, we assess a Random
Forest-based labeling system for providing consistent, confidence-scored outage
annotations. Our findings highlight the strengths and weaknesses of these
architectures for beam outage prediction and identify critical gaps that must
be addressed to fully harness AI for transitioning downtime handling from
reactive to predictive, ultimately reducing downtime and improving
decision-making in accelerator management.

摘要：費米實驗室加速器大樓的主控室持續
從監控光束的數千個感測器中收集大量的時序資料。然而，
例如跳電或電壓波動等意外事件通常
會導致光束中斷，造成運作停機。這段停機時間不僅
消耗操作員診斷和解決問題的精力，同時也會導致
閒置機器在等待光束復原時不必要的能源消耗。
目前的基於閾值的警報系統是被動的，且面臨挑戰
包括頻繁的誤報和不一致的中斷原因標籤。為了
解決這些限制，我們提出一個利用
預測分析和自動標籤的人工智慧框架。使用來自 $2,703$ 個直線加速器
裝置和 $80$ 個操作員標籤中斷的資料，我們評估最先進的深度
學習架構，包括遞迴、基於注意力的，以及線性
光束中斷預測模型。此外，我們評估一個基於隨機
森林的標籤系統，以提供一致、有信心評分的停電
註解。我們的發現強調了這些
架構在光束中斷預測上的優缺點，並找出必須
解決的關鍵差距，以充分利用人工智慧，將停機處理從
被動轉變為預測，最終減少停機時間並改善
加速器管理中的決策制定。

##### **ORACLE: A Real-Time, Hierarchical, Deep-Learning Photometric Classifier for the LSST**
2501.01496v1 by Ved G. Shah, Alex Gagliano, Konstantin Malanchev, Gautham Narayan, The LSST Dark Energy Science Collaboration

We present ORACLE, the first hierarchical deep-learning model for real-time,
context-aware classification of transient and variable astrophysical phenomena.
ORACLE is a recurrent neural network with Gated Recurrent Units (GRUs), and has
been trained using a custom hierarchical cross-entropy loss function to provide
high-confidence classifications along an observationally-driven taxonomy with
as little as a single photometric observation. Contextual information for each
object, including host galaxy photometric redshift, offset, ellipticity and
brightness, is concatenated to the light curve embedding and used to make a
final prediction. Training on $\sim$0.5M events from the Extended LSST
Astronomical Time-Series Classification Challenge, we achieve a top-level
(Transient vs Variable) macro-averaged precision of 0.96 using only 1 day of
photometric observations after the first detection in addition to contextual
information, for each event; this increases to $>$0.99 once 64 days of the
light curve has been obtained, and 0.83 at 1024 days after first detection for
19-way classification (including supernova sub-types, active galactic nuclei,
variable stars, microlensing events, and kilonovae). We also compare ORACLE
with other state-of-the-art classifiers and report comparable performance for
the 19-way classification task, in addition to delivering accurate top-level
classifications much earlier. The code and model weights used in this work are
publicly available at our associated GitHub repository
(https://github.com/uiucsn/ELAsTiCC-Classification).

摘要：<paragraph>我們提出 ORACLE，這是第一個用於瞬變和可變天體物理現象的即時、基於背景的分類的分層深度學習模型。ORACLE 是具有門控循環單元 (GRU) 的循環神經網路，並使用自訂分層交叉熵損失函數進行訓練，以提供高信心的分類，並使用觀測驅動分類法，只需一次光度觀測即可。每個物體的背景資訊，包括主星系的測光紅移、偏移、橢圓率和亮度，會串接至光度曲線嵌入，並用於進行最終預測。在擴展的 LSST 天文時間序列分類挑戰中訓練約 0.5M 個事件，我們在首次偵測後僅使用 1 天的光度觀測加上背景資訊，便達到了 0.96 的頂層（瞬變與可變）巨觀平均精度，對於每個事件；一旦獲得 64 天的光度曲線，就會增加到 >0.99，在首次偵測後 1024 天，19 向分類（包括超新星子類型、活動星系核、變星、微透鏡事件和千新星）的精度為 0.83。我們還將 ORACLE 與其他最先進的分類器進行比較，並報告 19 向分類任務的效能相當，此外還可更早提供準確的頂層分類。本研究中使用的程式碼和模型權重在我們相關的 GitHub 儲存庫 (https://github.com/uiucsn/ELAsTiCC-Classification) 中公開提供。</paragraph>

##### **Unifying Specialized Visual Encoders for Video Language Models**
2501.01426v1 by Jihoon Chung, Tyler Zhu, Max Gonzalez Saez-Diez, Juan Carlos Niebles, Honglu Zhou, Olga Russakovsky

The recent advent of Large Language Models (LLMs) has ushered sophisticated
reasoning capabilities into the realm of video through Video Large Language
Models (VideoLLMs). However, VideoLLMs currently rely on a single vision
encoder for all of their visual processing, which limits the amount and type of
visual information that can be conveyed to the LLM. Our method, MERV,
Multi-Encoder Representation of Videos, instead leverages multiple frozen
visual encoders to create a unified representation of a video, providing the
VideoLLM with a comprehensive set of specialized visual knowledge.
Spatio-temporally aligning the features from each encoder allows us to tackle a
wider range of open-ended and multiple-choice video understanding questions and
outperform prior state-of-the-art works. MERV is up to 3.7% better in accuracy
than Video-LLaVA across the standard suite video understanding benchmarks,
while also having a better Video-ChatGPT score. We also improve upon SeViLA,
the previous best on zero-shot Perception Test accuracy, by 2.2%. MERV
introduces minimal extra parameters and trains faster than equivalent
single-encoder methods while parallelizing the visual processing. Finally, we
provide qualitative evidence that MERV successfully captures domain knowledge
from each of its encoders. Our results offer promising directions in utilizing
multiple vision encoders for comprehensive video understanding.

摘要：大型語言模型 (LLM) 近期問世，透過影片大型語言模型 (VideoLLM) 將精密的推理能力引進影片領域。然而，VideoLLM 目前依賴單一視覺編碼器處理所有視覺，這限制了傳達給 LLM 的視覺資訊量和類型。我們的 MERV 方法，影片的多編碼器表徵，改用多個凍結的視覺編碼器來建立影片的統一表徵，為 VideoLLM 提供一套全面的專業視覺知識。透過空間時間對齊每個編碼器的特徵，讓我們能夠處理更廣泛的開放式和多選項影片理解問題，並超越先前的最先進技術。在標準套件影片理解基準上，MERV 的準確度比 Video-LLaVA 高達 3.7%，同時也有更好的 Video-ChatGPT 分數。我們也改進了 SeViLA，在零次學習感知測試準確度上，比前一個最佳方法高出 2.2%。MERV 引入最小的額外參數，並比等效的單一編碼器方法訓練得更快，同時並行處理視覺。最後，我們提供定性的證據，證明 MERV 成功從每個編碼器擷取領域知識。我們的結果為利用多個視覺編碼器進行全面的影片理解提供了有前景的方向。

##### **Object-level Visual Prompts for Compositional Image Generation**
2501.01424v1 by Gaurav Parmar, Or Patashnik, Kuan-Chieh Wang, Daniil Ostashev, Srinivasa Narasimhan, Jun-Yan Zhu, Daniel Cohen-Or, Kfir Aberman

We introduce a method for composing object-level visual prompts within a
text-to-image diffusion model. Our approach addresses the task of generating
semantically coherent compositions across diverse scenes and styles, similar to
the versatility and expressiveness offered by text prompts. A key challenge in
this task is to preserve the identity of the objects depicted in the input
visual prompts, while also generating diverse compositions across different
images. To address this challenge, we introduce a new KV-mixed cross-attention
mechanism, in which keys and values are learned from distinct visual
representations. The keys are derived from an encoder with a small bottleneck
for layout control, whereas the values come from a larger bottleneck encoder
that captures fine-grained appearance details. By mixing keys and values from
these complementary sources, our model preserves the identity of the visual
prompts while supporting flexible variations in object arrangement, pose, and
composition. During inference, we further propose object-level compositional
guidance to improve the method's identity preservation and layout correctness.
Results show that our technique produces diverse scene compositions that
preserve the unique characteristics of each visual prompt, expanding the
creative potential of text-to-image generation.

摘要：我們提出了一種在文本到影像擴散模型中組成物件層級視覺提示的方法。我們的做法處理在不同的場景和風格中產生語意連貫的組合任務，類似於文字提示所提供的多樣性和表現力。此任務中的關鍵挑戰是保留輸入視覺提示中所描繪物件的身份，同時在不同的影像中產生多樣化的組合。為了應對此挑戰，我們引入了一種新的 KV 混合交叉注意機制，其中鍵和值從不同的視覺表示中學習。鍵源自具有小型瓶頸的編碼器，用於布局控制，而值則來自擷取細緻外觀細節的較大型瓶頸編碼器。透過混合來自這些互補來源的鍵和值，我們的模型保留了視覺提示的身份，同時支援物件排列、姿勢和組合的靈活變化。在推理期間，我們進一步提出物件層級的組合指導，以改善方法的身份保留和布局正確性。結果顯示我們的技術產生了多樣的場景組合，保留了每個視覺提示的獨特特徵，擴展了文字到影像生成的創意潛力。

##### **Multi-Modal Video Feature Extraction for Popularity Prediction**
2501.01422v1 by Haixu Liu, Wenning Wang, Haoxiang Zheng, Penghao Jiang, Qirui Wang, Ruiqing Yan, Qiuzhuang Sun

This work aims to predict the popularity of short videos using the videos
themselves and their related features. Popularity is measured by four key
engagement metrics: view count, like count, comment count, and share count.
This study employs video classification models with different architectures and
training methods as backbone networks to extract video modality features.
Meanwhile, the cleaned video captions are incorporated into a carefully
designed prompt framework, along with the video, as input for video-to-text
generation models, which generate detailed text-based video content
understanding. These texts are then encoded into vectors using a pre-trained
BERT model. Based on the six sets of vectors mentioned above, a neural network
is trained for each of the four prediction metrics. Moreover, the study
conducts data mining and feature engineering based on the video and tabular
data, constructing practical features such as the total frequency of hashtag
appearances, the total frequency of mention appearances, video duration, frame
count, frame rate, and total time online. Multiple machine learning models are
trained, and the most stable model, XGBoost, is selected. Finally, the
predictions from the neural network and XGBoost models are averaged to obtain
the final result.

摘要：本研究旨在利用影片本身及其相關功能來預測短影片的熱門程度。熱門程度由四個關鍵參與指標衡量：觀看次數、按讚次數、留言次數和分享次數。本研究採用具有不同架構和訓練方法的影片分類模型作為主幹網路，以萃取影片形式特徵。同時，將整理後的影片字幕與影片一起納入精心設計的提示架構中，作為影片到文字生成模型的輸入，以產生詳細的文字化影片內容理解。然後，使用預先訓練的 BERT 模型將這些文字編碼成向量。根據上述六組向量，針對四個預測指標中的每一個訓練一個神經網路。此外，本研究根據影片和表格資料進行資料探勘和特徵工程，建構實用的特徵，例如標籤出現的總頻率、提及出現的總頻率、影片長度、影格數、影格率和線上總時間。訓練多個機器學習模型，並選出最穩定的模型 XGBoost。最後，將神經網路和 XGBoost 模型的預測結果取平均值，以取得最終結果。

##### **On Unifying Video Generation and Camera Pose Estimation**
2501.01409v1 by Chun-Hao Paul Huang, Jae Shin Yoon, Hyeonho Jeong, Niloy Mitra, Duygu Ceylan

Inspired by the emergent 3D capabilities in image generators, we explore
whether video generators similarly exhibit 3D awareness. Using
structure-from-motion (SfM) as a benchmark for 3D tasks, we investigate if
intermediate features from OpenSora, a video generation model, can support
camera pose estimation. We first examine native 3D awareness in video
generation features by routing raw intermediate outputs to SfM-prediction
modules like DUSt3R. Then, we explore the impact of fine-tuning on camera pose
estimation to enhance 3D awareness. Results indicate that while video generator
features have limited inherent 3D awareness, task-specific supervision
significantly boosts their accuracy for camera pose estimation, resulting in
competitive performance. The proposed unified model, named JOG3R, produces
camera pose estimates with competitive quality without degrading video
generation quality.

摘要：受图像生成器中新兴的 3D 功能启发，我们探索视频生成器是否同样表现出 3D 感知。使用运动结构 (SfM) 作为 3D 任务的基准，我们研究视频生成模型 OpenSora 中的中间特征是否可以支持相机位姿估计。我们首先通过将原始中间输出路由到 SfM 预测模块（如 DUSt3R）来检查视频生成特征中的原生 3D 感知。然后，我们探索微调对相机位姿估计的影响，以增强 3D 感知。结果表明，虽然视频生成器特征具有有限的固有 3D 感知，但特定于任务的监督极大地提高了它们在相机位姿估计方面的准确性，从而产生了具有竞争力的性能。所提出的统一模型 JOG3R 产生了具有竞争质量的相机位姿估计，而不会降低视频生成质量。

##### **A Unified Hyperparameter Optimization Pipeline for Transformer-Based Time Series Forecasting Models**
2501.01394v1 by Jingjing Xu, Caesar Wu, Yuan-Fang Li, Grégoire Danoy, Pascal Bouvry

Transformer-based models for time series forecasting (TSF) have attracted
significant attention in recent years due to their effectiveness and
versatility. However, these models often require extensive hyperparameter
optimization (HPO) to achieve the best possible performance, and a unified
pipeline for HPO in transformer-based TSF remains lacking. In this paper, we
present one such pipeline and conduct extensive experiments on several
state-of-the-art (SOTA) transformer-based TSF models. These experiments are
conducted on standard benchmark datasets to evaluate and compare the
performance of different models, generating practical insights and examples.
Our pipeline is generalizable beyond transformer-based architectures and can be
applied to other SOTA models, such as Mamba and TimeMixer, as demonstrated in
our experiments. The goal of this work is to provide valuable guidance to both
industry practitioners and academic researchers in efficiently identifying
optimal hyperparameters suited to their specific domain applications. The code
and complete experimental results are available on GitHub.

摘要：基於Transformer的時序預測 (TSF) 模型近年來因其有效性和多功能性而備受關注。然而，這些模型通常需要廣泛的超參數最佳化 (HPO) 才能達到最佳效能，而基於Transformer的 TSF 中的統一 HPO 管線仍然不足。在本文中，我們提出了一個這樣的管線，並對幾個最先進 (SOTA) 的基於Transformer的 TSF 模型進行廣泛的實驗。這些實驗是在標準基準資料集上進行的，以評估和比較不同模型的效能，產生實用的見解和範例。我們的管線可以推廣到基於Transformer的架構之外，並可以應用於其他 SOTA 模型，例如 Mamba 和 TimeMixer，正如我們的實驗中所示。這項工作的目標是為產業從業者和學術研究人員提供有價值的指導，以有效找出適合其特定領域應用程式的最佳超參數。程式碼和完整的實驗結果可在 GitHub 上取得。

##### **OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios**
2501.01384v1 by Xize Cheng, Dongjie Fu, Xiaoda Yang, Minghui Fang, Ruofan Hu, Jingyu Lu, Bai Jionghao, Zehan Wang, Shengpeng Ji, Rongjie Huang, Linjun Li, Yu Chen, Tao Jin, Zhou Zhao

With the rapid development of large language models, researchers have created
increasingly advanced spoken dialogue systems that can naturally converse with
humans. However, these systems still struggle to handle the full complexity of
real-world conversations, including audio events, musical contexts, and
emotional expressions, mainly because current dialogue datasets are constrained
in both scale and scenario diversity. In this paper, we propose leveraging
synthetic data to enhance the dialogue models across diverse scenarios. We
introduce ShareChatX, the first comprehensive, large-scale dataset for spoken
dialogue that spans diverse scenarios. Based on this dataset, we introduce
OmniChat, a multi-turn dialogue system with a heterogeneous feature fusion
module, designed to optimize feature selection in different dialogue contexts.
In addition, we explored critical aspects of training dialogue systems using
synthetic data. Through comprehensive experimentation, we determined the ideal
balance between synthetic and real data, achieving state-of-the-art results on
the real-world dialogue dataset DailyTalk. We also highlight the crucial
importance of synthetic data in tackling diverse, complex dialogue scenarios,
especially those involving audio and music. For more details, please visit our
demo page at \url{https://sharechatx.github.io/}.

摘要：隨著大型語言模型的快速發展，研究人員已建立了越來越先進的口語對話系統，能自然地與人類對話。然而，這些系統仍然難以處理現實世界對話的全部複雜性，包括音訊事件、音樂背景和情緒表達，這主要是因為目前的對話資料集在規模和場景多樣性上受到限制。在本文中，我們建議利用合成資料來增強各種場景中的對話模型。我們介紹 ShareChatX，這是第一個針對口語對話的全面、大規模資料集，涵蓋各種場景。根據此資料集，我們引入了 OmniChat，這是一個具有異質特徵融合模組的多回合對話系統，旨在最佳化不同對話情境中的特徵選擇。此外，我們探討了使用合成資料訓練對話系統的重要面向。透過全面的實驗，我們確定了合成資料和真實資料之間的理想平衡，在現實世界對話資料集 DailyTalk 上取得了最先進的成果。我們也強調了合成資料在處理多樣化、複雜的對話場景（特別是涉及音訊和音樂的場景）方面至關重要。如需更多詳細資訊，請前往我們的示範頁面：\url{https://sharechatx.github.io/}。

##### **Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**
2501.01377v1 by Yucheng Zhou, Lingran Song, Jianbing Shen

Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate
extensive medical knowledge, demonstrate excellent capabilities in
understanding medical images and responding to human queries based on these
images. However, there remain challenges in visual localization in medical
images, which is crucial for abnormality detection and interpretation. To
address these issues, we propose a novel UMed-LVLM designed with Unveiling
Medical abnormalities. Specifically, we collect a Medical Abnormalities
Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM
training. To collect MAU dataset, we propose a prompt method utilizing the
GPT-4V to generate diagnoses based on identified abnormal areas in medical
images. Moreover, the two-stage training method includes Abnormal-Aware
Instruction Tuning and Abnormal-Aware Rewarding, comprising Abnormal
Localization Rewarding and Vision Relevance Rewarding. Experimental results
demonstrate that our UMed-LVLM surpasses existing Med-LVLMs in identifying and
understanding medical abnormality. In addition, this work shows that enhancing
the abnormality detection capabilities of Med-LVLMs significantly improves
their understanding of medical images and generalization capability.

摘要：現有的醫療大型視覺語言模型 (Med-LVLMs) 封裝了廣泛的醫療知識，在理解醫療影像和根據這些影像回應人類查詢方面表現出色的能力。然而，在醫療影像中進行視覺定位仍存在挑戰，這對於異常偵測和解讀至關重要。為了解決這些問題，我們提出了一種新穎的 UMed-LVLM，其設計用於揭示醫療異常。具體來說，我們收集了一個醫療異常揭示 (MAU) 資料集，並為 UMed-LVLM 訓練提出了一個兩階段訓練方法。為了收集 MAU 資料集，我們提出了一種提示方法，利用 GPT-4V 根據醫療影像中識別出的異常區域生成診斷。此外，兩階段訓練方法包括異常感知指導調整和異常感知獎勵，包括異常定位獎勵和視覺相關性獎勵。實驗結果表明，我們的 UMed-LVLM 在識別和理解醫療異常方面優於現有的 Med-LVLMs。此外，這項工作表明，增強 Med-LVLMs 的異常偵測能力可以顯著提升它們對醫療影像的理解和泛化能力。

##### **ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**
2501.01372v1 by Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago López-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim

Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.

摘要：<paragraph>背景：延迟钆增强（LGE）成像用于评估心肌纤维化和瘢痕的黄金标准，左心室 (LV) LGE 范围预测重大的心脏不良事件 (MACE)。尽管其重要性，但基于 LGE 的常规 LV 瘢痕量化受到劳动密集型手动分割和观察者间差异的阻碍。方法：我们提出 ScarNet，一种混合模型，它将来自医学分割任何模型 (MedSAM) 的基于 Transformer 的编码器与基于卷积的 U-Net 解码器相结合，并通过定制的注意力块进行增强。ScarNet 在 552 例缺血性心肌病患者上接受训练，这些患者的心肌和瘢痕边界由专家分割，并在 184 例单独患者上进行测试。结果：ScarNet 在 184 例测试患者中实现了稳健的瘢痕分割，产生 0.912 的中值 Dice 得分（IQR：0.863--0.944），明显优于 MedSAM（中值 Dice = 0.046，IQR：0.043--0.047）和 nnU-Net（中值 Dice = 0.638，IQR：0.604--0.661）。与 MedSAM（偏差：-13.31%，CoV：130.3%）和 nnU-Net（偏差：-2.46%，CoV：20.3%）相比，ScarNet 表现出较低的偏差（-0.63%）和变异系数（4.3%）。在带有噪声扰动的蒙特卡罗模拟中，ScarNet 实现了明显高于 MedSAM（0.048 ± 0.112，CoV = 233.3%）和 nnU-Net（0.615 ± 0.537，CoV = 28.7%）的瘢痕 Dice（0.892 ± 0.053，CoV = 5.9%）。结论：ScarNet 在准确分割 LGE 图像中的心肌和瘢痕边界方面优于 MedSAM 和 nnU-Net。该模型在不同的图像质量和瘢痕模式下表现出稳健的性能。</paragraph>

##### **ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding**
2501.01366v1 by Austin T. Wang, ZeMing Gong, Angel X. Chang

3D visual grounding (3DVG) involves localizing entities in a 3D scene
referred to by natural language text. Such models are useful for embodied AI
and scene retrieval applications, which involve searching for objects or
patterns using natural language descriptions. While recent works have focused
on LLM-based scaling of 3DVG datasets, these datasets do not capture the full
range of potential prompts which could be specified in the English language. To
ensure that we are scaling up and testing against a useful and representative
set of prompts, we propose a framework for linguistically analyzing 3DVG
prompts and introduce Visual Grounding with Diverse Language in 3D (ViGiL3D), a
diagnostic dataset for evaluating visual grounding methods against a diverse
set of language patterns. We evaluate existing open-vocabulary 3DVG methods to
demonstrate that these methods are not yet proficient in understanding and
identifying the targets of more challenging, out-of-distribution prompts,
toward real-world applications.

摘要：3D 視覺接地 (3DVG) 涉及將自然語言文字所指的實體定位在 3D 場景中。此類模型對於具身 AI 和場景擷取應用程式很有用，其中涉及使用自然語言描述來搜尋物件或模式。儘管最近的工作重點在於 3DVG 資料集的 LLM 擴充，但這些資料集並未擷取到可以用英語指定的潛在提示的完整範圍。為了確保我們正在擴充並針對一組有用且具代表性的提示進行測試，我們提出了一個用於語言分析 3DVG 提示的框架，並引入了 3D 中具有多樣化語言的視覺接地 (ViGiL3D)，這是一個用於針對多樣化的語言模式評估視覺接地方法的診斷資料集。我們評估現有的開放式詞彙 3DVG 方法，以證明這些方法在理解和識別更具挑戰性、超出分佈提示的目標方面還不夠熟練，朝向實際應用邁進。

##### **Rethinking Relation Extraction: Beyond Shortcuts to Generalization with a Debiased Benchmark**
2501.01349v1 by Liang He, Yougang Chu, Zhen Wu, Jianbing Zhang, Xinyu Dai, Jiajun Chen

Benchmarks are crucial for evaluating machine learning algorithm performance,
facilitating comparison and identifying superior solutions. However, biases
within datasets can lead models to learn shortcut patterns, resulting in
inaccurate assessments and hindering real-world applicability. This paper
addresses the issue of entity bias in relation extraction tasks, where models
tend to rely on entity mentions rather than context. We propose a debiased
relation extraction benchmark DREB that breaks the pseudo-correlation between
entity mentions and relation types through entity replacement. DREB utilizes
Bias Evaluator and PPL Evaluator to ensure low bias and high naturalness,
providing a reliable and accurate assessment of model generalization in entity
bias scenarios. To establish a new baseline on DREB, we introduce MixDebias, a
debiasing method combining data-level and model training-level techniques.
MixDebias effectively improves model performance on DREB while maintaining
performance on the original dataset. Extensive experiments demonstrate the
effectiveness and robustness of MixDebias compared to existing methods,
highlighting its potential for improving the generalization ability of relation
extraction models. We will release DREB and MixDebias publicly.

摘要：基準測試對於評估機器學習演算法效能至關重要，
有助於比較並找出優越的解決方案。然而，資料集中的偏差
會導致模型學習捷徑模式，造成評估不準確並阻礙實際應用。本文
探討實體偏差在關係抽取任務中的問題，其中模型傾向於依賴實體提及，而非內容。我們提出一個去偏關係抽取基準 DREB，透過實體替換打破實體提及與關係類型之間的偽相關性。DREB 利用偏差評估器和 PPL 評估器來確保低偏差和高自然度，提供對實體偏差場景中模型概括性的可靠且準確的評估。為了在 DREB 上建立新的基準，我們引入了 MixDebias，一種結合資料層級和模型訓練層級技術的去偏方法。MixDebias 有效地改善了模型在 DREB 上的效能，同時維持在原始資料集上的效能。廣泛的實驗證明了 MixDebias 與現有方法相比的有效性和穩健性，突顯了其在改善關係抽取模型概括能力方面的潛力。我們將公開發布 DREB 和 MixDebias。

##### **AdaptVC: High Quality Voice Conversion with Adaptive Learning**
2501.01347v2 by Jaehun Kim, Ji-Hoon Kim, Yeunju Choi, Tan Dat Nguyen, Seongkyu Mun, Joon Son Chung

The goal of voice conversion is to transform the speech of a source speaker
to sound like that of a reference speaker while preserving the original
content. A key challenge is to extract disentangled linguistic content from the
source and voice style from the reference. While existing approaches leverage
various methods to isolate the two, a generalization still requires further
attention, especially for robustness in zero-shot scenarios. In this paper, we
achieve successful disentanglement of content and speaker features by tuning
self-supervised speech features with adapters. The adapters are trained to
dynamically encode nuanced features from rich self-supervised features, and the
decoder fuses them to produce speech that accurately resembles the reference
with minimal loss of content. Moreover, we leverage a conditional flow matching
decoder with cross-attention speaker conditioning to further boost the
synthesis quality and efficiency. Subjective and objective evaluations in a
zero-shot scenario demonstrate that the proposed method outperforms existing
models in speech quality and similarity to the reference speech.

摘要：語音轉換的目標是將來源說話者的語音轉換成參考說話者，同時保留原始內容。一項關鍵挑戰是從來源中提取分離的語言內容，以及從參考中提取語音風格。雖然現有方法利用各種方法來隔離這兩者，但一般化仍然需要進一步關注，特別是在零次學習場景中的穩健性。在本文中，我們通過使用適配器調整自監督語音特徵，成功地將內容和說話者特徵解開。適配器經過訓練，可以從豐富的自監督特徵中動態編碼細微特徵，解碼器將它們融合起來產生語音，該語音準確地類似於參考，且內容損失最小。此外，我們利用具有跨注意力說話者條件的條件流匹配解碼器進一步提高合成品質和效率。在零次學習場景中的主觀和客觀評估表明，所提出的方法在語音品質和與參考語音的相似性方面優於現有模型。

##### **Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability**
2501.01346v1 by Dong Shu, Haiyan Zhao, Jingyu Hu, Weiru Liu, Lu Cheng, Mengnan Du

Large Vision-Language Models (LVLMs) have demonstrated remarkable
capabilities in processing both visual and textual information. However, the
critical challenge of alignment between visual and linguistic representations
is not fully understood. This survey presents a comprehensive examination of
alignment and misalignment in LVLMs through an explainability lens. We first
examine the fundamentals of alignment, exploring its representational and
behavioral aspects, training methodologies, and theoretical foundations. We
then analyze misalignment phenomena across three semantic levels: object,
attribute, and relational misalignment. Our investigation reveals that
misalignment emerges from challenges at multiple levels: the data level, the
model level, and the inference level. We provide a comprehensive review of
existing mitigation strategies, categorizing them into parameter-frozen and
parameter-tuning approaches. Finally, we outline promising future research
directions, emphasizing the need for standardized evaluation protocols and
in-depth explainability studies.

摘要：大型視覺語言模型 (LVLMs) 在處理視覺和文字資訊方面展現出非凡的能力。然而，視覺和語言表徵之間對齊的關鍵挑戰尚未完全了解。本調查透過可解釋性的觀點，對 LVLMs 中的對齊和失衡進行全面檢視。我們首先檢視對齊的基本原理，探討其表徵和行為面向、訓練方法和理論基礎。接著，我們在三個語義層面分析失衡現象：物件失衡、屬性失衡和關係失衡。我們的調查顯示，失衡源自於多個層面的挑戰：資料層面、模型層面和推論層面。我們提供現有緩解策略的全面回顧，將它們分類為參數凍結和參數調整方法。最後，我們概述有前景的未來研究方向，強調標準化評估協定和深入可解釋性研究的必要性。

##### **DeepFilter: An Instrumental Baseline for Accurate and Efficient Process Monitoring**
2501.01342v1 by Hao Wang, Zhichao Chen, Licheng Pan, Xiaoyu Jiang, Yichen Song, Qunshan He, Xinggao Liu

Effective process monitoring is increasingly vital in industrial automation
for ensuring operational safety, necessitating both high accuracy and
efficiency. Although Transformers have demonstrated success in various fields,
their canonical form based on the self-attention mechanism is inadequate for
process monitoring due to two primary limitations: (1) the step-wise
correlations captured by self-attention mechanism are difficult to capture
discriminative patterns in monitoring logs due to the lacking semantics of each
step, thus compromising accuracy; (2) the quadratic computational complexity of
self-attention hampers efficiency. To address these issues, we propose
DeepFilter, a Transformer-style framework for process monitoring. The core
innovation is an efficient filtering layer that excel capturing long-term and
periodic patterns with reduced complexity. Equipping with the global filtering
layer, DeepFilter enhances both accuracy and efficiency, meeting the stringent
demands of process monitoring. Experimental results on real-world process
monitoring datasets validate DeepFilter's superiority in terms of accuracy and
efficiency compared to existing state-of-the-art models.

摘要：有效製程監控在工業自動化中日益重要，用於確保作業安全，需要高準確度和效率。儘管 Transformer 已在各領域證明其成功，但其基於自我注意機制的標準形式由於兩個主要限制而不足以進行製程監控：(1) 自我注意機制所擷取的逐步關聯性難以擷取監控記錄中的區分模式，因為每個步驟缺乏語意，因此會影響準確度；(2) 自我注意的二次運算複雜度會阻礙效率。為了解決這些問題，我們提出了 DeepFilter，這是一個用於製程監控的 Transformer 風格架構。其核心創新是一個高效的過濾層，其優點是可以降低複雜度，並擷取長期和週期性模式。透過配備全球過濾層，DeepFilter 可同時提升準確度和效率，以滿足製程監控的嚴格要求。在真實世界的製程監控資料集上的實驗結果驗證了 DeepFilter 在準確度和效率方面優於現有最先進模型的優越性。

##### **Aligning Large Language Models for Faithful Integrity Against Opposing Argument**
2501.01336v1 by Yong Zhao, Yang Deng, See-Kiong Ng, Tat-Seng Chua

Large Language Models (LLMs) have demonstrated impressive capabilities in
complex reasoning tasks. However, they can be easily misled by unfaithful
arguments during conversations, even when their original statements are
correct. To this end, we investigate the problem of maintaining faithful
integrity in LLMs. This involves ensuring that LLMs adhere to their faithful
statements in the face of opposing arguments and are able to correct their
incorrect statements when presented with faithful arguments. In this work, we
propose a novel framework, named Alignment for Faithful Integrity with
Confidence Estimation (AFICE), which aims to align the LLM responses with
faithful integrity. Specifically, AFICE first designs a Bilateral Confidence
Estimation (BCE) approach for estimating the uncertainty of each response
generated by the LLM given a specific context, which simultaneously estimate
the model's confidence to the question based on the internal states during
decoding as well as to the answer based on cumulative probability ratios. With
the BCE, we construct a conversational preference dataset composed of context,
original statement, and argument, which is adopted for aligning the LLM for
faithful integrity using Direct Preference Optimization (DPO). Extensive
experimental results on a wide range of benchmarks demonstrate significant
improvements in the LLM's ability to maintain faithful responses when
encountering opposing arguments, ensuring both the practical utility and
trustworthiness of LLMs in complex interactive settings. Code and data will be
released via https://github.com/zhaoy777/AFICE.git

摘要：大型語言模型 (LLM) 在複雜推理任務中展現出令人印象深刻的能力。然而，即使它們的原始陳述正確，它們也可能在對話中輕易被不忠實的論點誤導。為此，我們研究了在 LLM 中維持忠實性的問題。這包括確保 LLM 在面對反對論點時堅持其忠實陳述，並能夠在提出忠實論點時糾正其不正確的陳述。在這項工作中，我們提出了一個名為「具有信心估計的忠實整合對齊」(AFICE) 的新框架，旨在將 LLM 回應與忠實整合保持一致。具體來說，AFICE 首先設計了一個雙邊信心估計 (BCE) 方法，用於估計 LLM 在特定背景下產生的每個回應的不確定性，它同時估計模型在解碼過程中基於內部狀態對問題的信心，以及基於累積機率比對答案的信心。有了 BCE，我們構建了一個對話偏好資料集，其中包含背景、原始陳述和論點，它被用於使用直接偏好最佳化 (DPO) 來調整 LLM 以獲得忠實的整合。在廣泛基準上的大量實驗結果證明，在遇到反對論點時，LLM 維持忠實回應的能力有顯著的提升，確保了 LLM 在複雜互動設定中的實用性和可信度。程式碼和資料將透過 https://github.com/zhaoy777/AFICE.git 發布

##### **CySecBench: Generative AI-based CyberSecurity-focused Prompt Dataset for Benchmarking Large Language Models**
2501.01335v1 by Johan Wahréus, Ahmed Mohamed Hussain, Panos Papadimitratos

Numerous studies have investigated methods for jailbreaking Large Language
Models (LLMs) to generate harmful content. Typically, these methods are
evaluated using datasets of malicious prompts designed to bypass security
policies established by LLM providers. However, the generally broad scope and
open-ended nature of existing datasets can complicate the assessment of
jailbreaking effectiveness, particularly in specific domains, notably
cybersecurity. To address this issue, we present and publicly release
CySecBench, a comprehensive dataset containing 12662 prompts specifically
designed to evaluate jailbreaking techniques in the cybersecurity domain. The
dataset is organized into 10 distinct attack-type categories, featuring
close-ended prompts to enable a more consistent and accurate assessment of
jailbreaking attempts. Furthermore, we detail our methodology for dataset
generation and filtration, which can be adapted to create similar datasets in
other domains. To demonstrate the utility of CySecBench, we propose and
evaluate a jailbreaking approach based on prompt obfuscation. Our experimental
results show that this method successfully elicits harmful content from
commercial black-box LLMs, achieving Success Rates (SRs) of 65% with ChatGPT
and 88% with Gemini; in contrast, Claude demonstrated greater resilience with a
jailbreaking SR of 17%. Compared to existing benchmark approaches, our method
shows superior performance, highlighting the value of domain-specific
evaluation datasets for assessing LLM security measures. Moreover, when
evaluated using prompts from a widely used dataset (i.e., AdvBench), it
achieved an SR of 78.5%, higher than the state-of-the-art methods.

摘要：<paragraph>許多研究探討了越獄大型語言模型 (LLM) 以產生有害內容的方法。通常，這些方法使用惡意提示的資料集進行評估，這些提示旨在繞過 LLM 提供者建立的安全政策。然而，現有資料集的廣泛範圍和開放式性質通常會使越獄有效性的評估變得複雜，特別是在特定領域，尤其是網路安全。為了解決這個問題，我們提出並公開發布 CySecBench，這是一個全面的資料集，包含 12662 個提示，專門用於評估網路安全領域的越獄技術。該資料集組織成 10 個不同的攻擊類型類別，採用封閉式提示，以便對越獄嘗試進行更一致且準確的評估。此外，我們詳細說明了我們的資料集生成和過濾方法，該方法可以調整以在其他領域建立類似的資料集。為了展示 CySecBench 的效用，我們提出並評估了一種基於提示混淆的越獄方法。我們的實驗結果顯示，此方法成功地從商業黑盒 LLM 獲取有害內容，在 ChatGPT 中達到 65% 的成功率 (SR)，在 Gemini 中達到 88%；相比之下，Claude 以 17% 的越獄 SR 表現出更大的韌性。與現有的基準方法相比，我們的模型顯示出優異的性能，突顯了特定領域評估資料集對於評估 LLM 安全措施的價值。此外，當使用來自廣泛使用資料集 (即 AdvBench) 的提示進行評估時，它達到了 78.5% 的 SR，高於最先進的方法。</paragraph>

##### **Decoding Knowledge in Large Language Models: A Framework for Categorization and Comprehension**
2501.01332v1 by Yanbo Fang, Ruixiang Tang

Understanding how large language models (LLMs) acquire, retain, and apply
knowledge remains an open challenge. This paper introduces a novel framework,
K-(CSA)^2, which categorizes LLM knowledge along two dimensions: correctness
and confidence. The framework defines six categories of knowledge, ranging from
highly confident correctness to confidently held misconceptions, enabling a
nuanced evaluation of model comprehension beyond binary accuracy. Using this
framework, we demonstrate how techniques like chain-of-thought prompting and
reinforcement learning with human feedback fundamentally alter the knowledge
structures of internal (pre-trained) and external (context-dependent) knowledge
in LLMs. CoT particularly enhances base model performance and shows synergistic
benefits when applied to aligned LLMs. Moreover, our layer-wise analysis
reveals that higher layers in LLMs encode more high-confidence knowledge, while
low-confidence knowledge tends to emerge in middle-to-lower layers.

摘要：了解大型語言模型 (LLM) 如何獲取、保留和應用知識仍然是一項公開挑戰。本文介紹了一個新框架 K-(CSA)^2，它將 LLM 知識分為兩個面向：正確性和信心。該框架定義了六類知識，範圍從高度自信的正確性到自信地堅持錯誤觀念，從而能夠對模型理解進行細緻的評估，而不仅仅是二元準確性。使用此框架，我們展示了像思考鏈提示和帶有人類回饋的強化學習這樣的技術如何從根本上改變 LLM 中內部（預訓練）和外部（上下文相關）知識的知識結構。CoT 特別增強了基礎模型的性能，並在應用於對齊的 LLM 時顯示出協同效應。此外，我們的逐層分析表明，LLM 中的較高層編碼了更多的高信心知識，而低信心知識則傾向於出現在中低層。

##### **The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation**
2501.01329v1 by Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiaoqian Jiao, Chun Yong Chong, Shan Gao, Michael Lyu

Test cases are essential for validating the reliability and quality of
software applications. Recent studies have demonstrated the capability of Large
Language Models (LLMs) to generate useful test cases for given source code.
However, the existing work primarily relies on human-written plain prompts,
which often leads to suboptimal results since the performance of LLMs can be
highly influenced by the prompts. Moreover, these approaches use the same
prompt for all LLMs, overlooking the fact that different LLMs might be best
suited to different prompts. Given the wide variety of possible prompt
formulations, automatically discovering the optimal prompt for each LLM
presents a significant challenge. Although there are methods on automated
prompt optimization in the natural language processing field, they are hard to
produce effective prompts for the test case generation task. First, the methods
iteratively optimize prompts by simply combining and mutating existing ones
without proper guidance, resulting in prompts that lack diversity and tend to
repeat the same errors in the generated test cases. Second, the prompts are
generally lack of domain contextual knowledge, limiting LLMs' performance in
the task.

摘要：測試案例對於驗證軟體應用的可靠性和品質至關重要。最近的研究已證明大型語言模型 (LLM) 能夠為給定的原始碼產生有用的測試案例。然而，現有的工作主要依賴人工撰寫的簡單提示，這通常會導致次佳的結果，因為 LLM 的效能可能會受到提示的極大影響。此外，這些方法對所有 LLM 使用相同的提示，忽略了不同的 LLM 可能最適合不同的提示這個事實。考量到各種可能的提示表述，自動找出每個 LLM 的最佳提示是一項重大的挑戰。儘管自然語言處理領域有自動提示最佳化的方式，但它們難以產生有效的提示以進行測試案例產生任務。首先，這些方法透過簡單地組合和改變現有的提示，在沒有適當指導的情況下反覆最佳化提示，導致提示缺乏多樣性，並且傾向於在產生的測試案例中重複相同的錯誤。其次，提示通常缺乏領域脈絡知識，這會限制 LLM 在任務中的效能。

##### **Understanding Difficult-to-learn Examples in Contrastive Learning: A Theoretical Framework for Spectral Contrastive Learning**
2501.01317v1 by Yi-Ge Zhang, Jingyi Cui, Qiran Li, Yisen Wang

Unsupervised contrastive learning has shown significant performance
improvements in recent years, often approaching or even rivaling supervised
learning in various tasks. However, its learning mechanism is fundamentally
different from that of supervised learning. Previous works have shown that
difficult-to-learn examples (well-recognized in supervised learning as examples
around the decision boundary), which are essential in supervised learning,
contribute minimally in unsupervised settings. In this paper, perhaps
surprisingly, we find that the direct removal of difficult-to-learn examples,
although reduces the sample size, can boost the downstream classification
performance of contrastive learning. To uncover the reasons behind this, we
develop a theoretical framework modeling the similarity between different pairs
of samples. Guided by this theoretical framework, we conduct a thorough
theoretical analysis revealing that the presence of difficult-to-learn examples
negatively affects the generalization of contrastive learning. Furthermore, we
demonstrate that the removal of these examples, and techniques such as margin
tuning and temperature scaling can enhance its generalization bounds, thereby
improving performance. Empirically, we propose a simple and efficient mechanism
for selecting difficult-to-learn examples and validate the effectiveness of the
aforementioned methods, which substantiates the reliability of our proposed
theoretical framework.

摘要：無監督對比學習在近年來展現出顯著的效能提升，通常接近甚至與各種任務中的監督式學習相匹敵。然而，其學習機制與監督式學習有根本上的不同。先前的研究已顯示，難以學習的範例（在監督式學習中公認為決策邊界附近的範例），在監督式學習中至關重要，但在無監督式設定中貢獻甚微。在本文中，或許令人驚訝的是，我們發現難以學習的範例直接移除，儘管會減少樣本大小，但能提升對比學習的下游分類效能。為了找出背後的原因，我們建構了一個理論架構，對不同範例對之間的相似性進行建模。在這個理論架構的指導下，我們進行了徹底的理論分析，揭示了難以學習的範例的存在對比學習的泛化產生負面影響。此外，我們證明了移除這些範例，以及邊界調整和溫度調整等技術，可以增強其泛化界限，進而提升效能。在經驗上，我們提出了一個簡單且有效的機制來選擇難以學習的範例，並驗證了上述方法的有效性，這證實了我們提出的理論架構的可靠性。

##### **Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**
2501.01311v1 by Bohang Sun, Pietro Liò

In this study, we introduce the Multi-Head Explainer (MHEX), a versatile and
modular framework that enhances both the explainability and accuracy of
Convolutional Neural Networks (CNNs) and Transformer-based models. MHEX
consists of three core components: an Attention Gate that dynamically
highlights task-relevant features, Deep Supervision that guides early layers to
capture fine-grained details pertinent to the target class, and an Equivalent
Matrix that unifies refined local and global representations to generate
comprehensive saliency maps. Our approach demonstrates superior compatibility,
enabling effortless integration into existing residual networks like ResNet and
Transformer architectures such as BERT with minimal modifications. Extensive
experiments on benchmark datasets in medical imaging and text classification
show that MHEX not only improves classification accuracy but also produces
highly interpretable and detailed saliency scores.

摘要：在這項研究中，我們引入了多頭解釋器 (MHEX)，一個多功能且模組化的架構，用於增強卷積神經網路 (CNN) 和 Transformer 為基礎的模型的可解釋性和準確性。MHEX 包含三個核心元件：一個動態突顯與任務相關特徵的注意力閘門、引導早期層捕捉與目標類別相關的細緻細節的深度監督，以及一個統一精緻的局部和全局表示以產生全面的顯著性圖的等效矩陣。我們的做法展現出優異的相容性，讓 ResNet 等現有的殘差網路和 BERT 等 Transformer 架構能夠輕鬆整合，而且修改幅度極小。在醫學影像和文字分類的基準資料集上進行的廣泛實驗顯示，MHEX 不僅能提升分類準確性，還能產生高度可解釋且詳細的顯著性分數。

##### **Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking**
2501.01306v2 by Xiaoxue Cheng, Junyi Li, Wayne Xin Zhao, Ji-Rong Wen

Large language models (LLMs) demonstrate exceptional capabilities, yet still
face the hallucination issue. Typical text generation approaches adopt an
auto-regressive generation without deliberate reasoning, which often results in
untrustworthy and factually inaccurate responses. In this paper, we propose
HaluSearch, a novel framework that incorporates tree search-based algorithms
(e.g. MCTS) to enable an explicit slow thinking generation process for
mitigating hallucinations of LLMs during inference. Specifically, HaluSearch
frames text generation as a step-by-step reasoning process, using a
self-evaluation reward model to score each generation step and guide the tree
search towards the most reliable generation pathway for fully exploiting the
internal knowledge of LLMs. To balance efficiency and quality, we introduce a
hierarchical thinking system switch mechanism inspired by the dual process
theory in cognitive science, which dynamically alternates between fast and slow
thinking modes at both the instance and step levels, adapting to the complexity
of questions and reasoning states. We conduct extensive experiments on both
English and Chinese datasets and the results show that our approach
significantly outperforms baseline approaches.

摘要：大型語言模型 (LLM) 表現出非凡的能力，但仍面臨幻覺問題。典型的文字生成方法採用自動迴歸生成，沒有經過深思熟慮的推理，這通常會導致不可信和事實不正確的回應。在本文中，我們提出 HaluSearch，這是一個新的框架，它結合了基於樹狀搜尋的演算法（例如 MCTS），以啟用明確的慢速思考生成過程，以減輕 LLM 在推理期間的幻覺。具體來說，HaluSearch 將文字生成設定為一個逐步的推理過程，使用自我評估獎勵模型為每個生成步驟評分，並引導樹狀搜尋朝向最可靠的生成路徑，以充分利用 LLM 的內部知識。為了平衡效率和品質，我們引入了一個階層式思考系統切換機制，其靈感來自認知科學中的雙重過程理論，它在例項和步驟層級中動態交替快思考模式和慢思考模式，以適應問題和推理狀態的複雜性。我們對英語和中文資料集進行了廣泛的實驗，結果表明，我們的做法顯著優於基準方法。

##### **Large Language Models for Mental Health Diagnostic Assessments: Exploring The Potential of Large Language Models for Assisting with Mental Health Diagnostic Assessments -- The Depression and Anxiety Case**
2501.01305v1 by Kaushik Roy, Harshul Surana, Darssan Eswaramoorthi, Yuxin Zi, Vedant Palit, Ritvik Garimella, Amit Sheth

Large language models (LLMs) are increasingly attracting the attention of
healthcare professionals for their potential to assist in diagnostic
assessments, which could alleviate the strain on the healthcare system caused
by a high patient load and a shortage of providers. For LLMs to be effective in
supporting diagnostic assessments, it is essential that they closely replicate
the standard diagnostic procedures used by clinicians. In this paper, we
specifically examine the diagnostic assessment processes described in the
Patient Health Questionnaire-9 (PHQ-9) for major depressive disorder (MDD) and
the Generalized Anxiety Disorder-7 (GAD-7) questionnaire for generalized
anxiety disorder (GAD). We investigate various prompting and fine-tuning
techniques to guide both proprietary and open-source LLMs in adhering to these
processes, and we evaluate the agreement between LLM-generated diagnostic
outcomes and expert-validated ground truth. For fine-tuning, we utilize the
Mentalllama and Llama models, while for prompting, we experiment with
proprietary models like GPT-3.5 and GPT-4o, as well as open-source models such
as llama-3.1-8b and mixtral-8x7b.

摘要：大型語言模型（LLM）越來越受到醫療保健專業人士的關注，因為它們有可能協助診斷評估，這可以減輕由高患者負擔和提供者短缺造成的醫療保健系統壓力。對於 LLM 在支持診斷評估方面能發揮作用，至關重要的是它們必須嚴格複製臨床醫生使用的標準診斷程序。在本文中，我們特別檢查了主要憂鬱症（MDD）的患者健康問卷-9（PHQ-9）和廣泛性焦慮症（GAD）的廣泛性焦慮症-7（GAD-7）問卷中描述的診斷評估程序。我們研究了各種提示和微調技術，以指導專有和開源 LLM 遵循這些程序，並且我們評估了 LLM 生成的診斷結果與專家驗證的地面真實性之間的一致性。對於微調，我們利用了 Mentalllama 和 Llama 模型，而對於提示，我們嘗試了專有模型，如 GPT-3.5 和 GPT-4o，以及開源模型，如 llama-3.1-8b 和 mixtral-8x7b。

##### **LEO-Split: A Semi-Supervised Split Learning Framework over LEO Satellite Networks**
2501.01293v1 by Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Cong Wu, Xianhao Chen, Yue Gao, Jun Luo

Recently, the increasing deployment of LEO satellite systems has enabled
various space analytics (e.g., crop and climate monitoring), which heavily
relies on the advancements in deep learning (DL). However, the intermittent
connectivity between LEO satellites and ground station (GS) significantly
hinders the timely transmission of raw data to GS for centralized learning,
while the scaled-up DL models hamper distributed learning on
resource-constrained LEO satellites. Though split learning (SL) can be a
potential solution to these problems by partitioning a model and offloading
primary training workload to GS, the labor-intensive labeling process remains
an obstacle, with intermittent connectivity and data heterogeneity being other
challenges. In this paper, we propose LEO-Split, a semi-supervised (SS) SL
design tailored for satellite networks to combat these challenges. Leveraging
SS learning to handle (labeled) data scarcity, we construct an auxiliary model
to tackle the training failure of the satellite-GS non-contact time. Moreover,
we propose a pseudo-labeling algorithm to rectify data imbalances across
satellites. Lastly, an adaptive activation interpolation scheme is devised to
prevent the overfitting of server-side sub-model training at GS. Extensive
experiments with real-world LEO satellite traces (e.g., Starlink) demonstrate
that our LEO-Split framework achieves superior performance compared to
state-ofthe-art benchmarks.

摘要：<paragraph>最近，LEO 卫星系统的日益部署已启用各种空间分析（例如，作物和气候监测），这在很大程度上依赖于深度学习 (DL) 的进步。然而，LEO 卫星和地面站 (GS) 之间的间歇连接极大地阻碍了原始数据及时传输到 GS 以进行集中学习，而规模扩大的 DL 模型阻碍了对资源受限的 LEO 卫星进行分布式学习。尽管拆分学习 (SL) 可以通过对模型进行分区并将主要训练工作负载卸载到 GS 来解决这些问题，但劳动密集型的标记过程仍然是一个障碍，间歇连接和数据异构性是其他挑战。在本文中，我们提出了 LEO-Split，这是一种针对卫星网络定制的半监督 (SS) SL 设计，以应对这些挑战。利用 SS 学习来处理（标记的）数据稀缺性，我们构建了一个辅助模型来解决卫星-GS 非接触时间的训练失败问题。此外，我们提出了一种伪标记算法来纠正卫星之间的数据不平衡。最后，设计了一种自适应激活插值方案，以防止 GS 中服务器端子模型训练过度拟合。使用真实世界的 LEO 卫星轨迹（例如，Starlink）进行的广泛实验表明，与最先进的基准相比，我们的 LEO-Split 框架实现了卓越的性能。</paragraph>

##### **Change Detection-Based Procedures for Piecewise Stationary MABs: A Modular Approach**
2501.01291v1 by Yu-Han Huang, Argyrios Gerogiannis, Subhonmesh Bose, Venugopal V. Veeravalli

Conventional Multi-Armed Bandit (MAB) algorithms are designed for stationary
environments, where the reward distributions associated with the arms do not
change with time. In many applications, however, the environment is more
accurately modeled as being nonstationary. In this work, piecewise stationary
MAB (PS-MAB) environments are investigated, in which the reward distributions
associated with a subset of the arms change at some change-points and remain
stationary between change-points. Our focus is on the asymptotic analysis of
PS-MABs, for which practical algorithms based on change detection (CD) have
been previously proposed. Our goal is to modularize the design and analysis of
such CD-based Bandit (CDB) procedures. To this end, we identify the
requirements for stationary bandit algorithms and change detectors in a CDB
procedure that are needed for the modularization. We assume that the rewards
are sub-Gaussian. Under this assumption and a condition on the separation of
the change-points, we show that the analysis of CDB procedures can indeed be
modularized, so that regret bounds can be obtained in a unified manner for
various combinations of change detectors and bandit algorithms. Through this
analysis, we develop new modular CDB procedures that are order-optimal. We
compare the performance of our modular CDB procedures with various other
methods in simulations.

摘要：傳統的多臂老虎機 (MAB) 演算法是為靜態環境所設計，其中與手臂相關的獎勵分佈不會隨著時間而改變。然而，在許多應用中，環境更精確地被建模為非靜態的。在這項工作中，研究了分段靜態 MAB (PS-MAB) 環境，其中與手臂子集相關的獎勵分佈在某些變動點發生變化，並在變動點之間保持靜態。我們的重點在於 PS-MAB 的漸近分析，其中先前已提出基於變動偵測 (CD) 的實用演算法。我們的目標是將此類基於 CD 的老虎機 (CDB) 程序的設計和分析模組化。為此，我們在 CDB 程序中找出模組化所需的靜態老虎機演算法和變動偵測器的需求。我們假設獎勵是次高斯分佈的。在此假設和變動點分離的條件下，我們證明 CDB 程序的分析確實可以模組化，因此可以統一的方式為變動偵測器和老虎機演算法的各種組合取得遺憾界限。透過此分析，我們開發了新的模組化 CDB 程序，其為次佳。我們在模擬中將我們的模組化 CDB 程序的效能與其他各種方法進行比較。

##### **ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark**
2501.01290v1 by Vaskar Nath, Pranav Raja, Claire Yoon, Sean Hendryx

Despite recent advances in AI, the development of systems capable of
executing complex, multi-step reasoning tasks involving multiple tools remains
a significant challenge. Current benchmarks fall short in capturing the
real-world complexity of tool-use reasoning, where verifying the correctness of
not only the final answer but also the intermediate steps is important for
evaluation, development, and identifying failures during inference time. To
bridge this gap, we introduce ToolComp, a comprehensive benchmark designed to
evaluate multi-step tool-use reasoning. ToolComp is developed through a
collaboration between models and human annotators, featuring
human-edited/verified prompts, final answers, and process supervision labels,
allowing for the evaluation of both final outcomes and intermediate reasoning.
Evaluation across six different model families demonstrates the challenging
nature of our dataset, with the majority of models achieving less than 50%
accuracy. Additionally, we generate synthetic training data to compare the
performance of outcome-supervised reward models (ORMs) with process-supervised
reward models (PRMs) to assess their ability to improve complex tool-use
reasoning as evaluated by ToolComp. Our results show that PRMs generalize
significantly better than ORMs, achieving a 19% and 11% improvement in rank@1
accuracy for ranking base and fine-tuned model trajectories, respectively.
These findings highlight the critical role of process supervision in both the
evaluation and training of AI models, paving the way for more robust and
capable systems in complex, multi-step tool-use tasks.

摘要：儘管 AI 近期有長足進展，但開發能夠執行複雜、多步驟推理任務，且涉及多種工具的系統，仍然是一項重大挑戰。目前的基準在捕捉工具使用推理的真實世界複雜性方面有所不足，其中驗證不僅最終答案，還驗證中間步驟的正確性，對於評估、開發和在推理期間識別失敗非常重要。為了彌補這一差距，我們引入了 ToolComp，一個旨在評估多步驟工具使用推理的綜合基準。ToolComp 是在模型和人類註解者的協作下開發的，具有經過人為編輯/驗證的提示、最終答案和流程監督標籤，允許評估最終結果和中間推理。在六個不同的模型系列中進行的評估證明了我們資料集的挑戰性，大多數模型的準確度低於 50%。此外，我們生成了合成訓練資料，以比較結果監督獎勵模型 (ORM) 與流程監督獎勵模型 (PRM) 的效能，以評估它們提升 ToolComp 評估的複雜工具使用推理的能力。我們的結果顯示，PRM 的泛化效果顯著優於 ORM，在基本和微調模型軌跡的排名@1 準確度方面分別提升了 19% 和 11%。這些發現突顯了流程監督在 AI 模型評估和訓練中的關鍵作用，為在複雜、多步驟工具使用任務中建立更強健且更強大的系統鋪平了道路。

##### **Drift2Matrix: Kernel-Induced Self Representation for Concept Drift Adaptation in Co-evolving Time Series**
2501.01480v1 by Kunpeng Xu, Lifei Chen, Shengrui Wang

In the realm of time series analysis, tackling the phenomenon of concept
drift poses a significant challenge. Concept drift -- characterized by the
evolving statistical properties of time series data, affects the reliability
and accuracy of conventional analysis models. This is particularly evident in
co-evolving scenarios where interactions among variables are crucial. This
paper presents Drift2Matrix, a novel framework that leverages kernel-induced
self-representation for adaptive responses to concept drift in time series.
Drift2Matrix employs a kernel-based learning mechanism to generate a
representation matrix, encapsulating the inherent dynamics of co-evolving time
series. This matrix serves as a key tool for identification and adaptation to
concept drift by observing its temporal variations. Furthermore, Drift2Matrix
effectively identifies prevailing patterns and offers insights into emerging
trends through pattern evolution analysis. Our empirical evaluation of
Drift2Matrix across various datasets demonstrates its effectiveness in handling
the complexities of concept drift. This approach introduces a novel perspective
in the theoretical domain of co-evolving time series analysis, enhancing
adaptability and accuracy in the face of dynamic data environments.

摘要：在時間序列分析領域中，應對概念漂移現象是一個重大的挑戰。概念漂移——其特徵在於時間序列數據的統計特性不斷演化，會影響傳統分析模型的可靠性和準確性。這在交互變量之間的交互作用至關重要的共同演化場景中尤其明顯。本文提出了 Drift2Matrix，這是一個新穎的框架，它利用核誘導自表示來適應時間序列中的概念漂移。Drift2Matrix 採用基於核的學習機制來生成一個表示矩陣，封裝共同演化時間序列的內在動態。這個矩陣作為一個關鍵工具，通過觀察其時間變化來識別和適應概念漂移。此外，Drift2Matrix 有效地識別出普遍模式，並通過模式演化分析提供對新興趨勢的見解。我們對 Drift2Matrix 在各種數據集上的實證評估證明了它在處理概念漂移的複雜性方面的有效性。這種方法在共同演化時間序列分析的理論領域中引入了一個新穎的觀點，增強了在動態數據環境中適應性和準確性。

##### **NeutraSum: A Language Model can help a Balanced Media Diet by Neutralizing News Summaries**
2501.01284v1 by Xi Luo, Junjie Liu, Sirong Wu, Yuhui Deng

Media bias in news articles arises from the political polarisation of media
outlets, which can reinforce societal stereotypes and beliefs. Reporting on the
same event often varies significantly between outlets, reflecting their
political leanings through polarised language and focus. Although previous
studies have attempted to generate bias-free summaries from multiperspective
news articles, they have not effectively addressed the challenge of mitigating
inherent media bias. To address this gap, we propose \textbf{NeutraSum}, a
novel framework that integrates two neutrality losses to adjust the semantic
space of generated summaries, thus minimising media bias. These losses,
designed to balance the semantic distances across polarised inputs and ensure
alignment with expert-written summaries, guide the generation of neutral and
factually rich summaries. To evaluate media bias, we employ the political
compass test, which maps political leanings based on economic and social
dimensions. Experimental results on the Allsides dataset demonstrate that
NeutraSum not only improves summarisation performance but also achieves
significant reductions in media bias, offering a promising approach for neutral
news summarisation.

摘要：媒體偏見在新聞文章中源自媒體機構的政治兩極分化，這可能會強化社會刻板印象和信念。對於同一事件的報導通常在各個媒體機構間有顯著差異，反映出他們透過兩極化的語言和焦點來表達政治傾向。儘管先前的研究已嘗試從多觀點新聞文章中產生無偏見的摘要，但它們並未有效解決減輕固有媒體偏見的挑戰。為了解決這個差距，我們提出了 \textbf{NeutraSum}，一個整合了兩個中立性損失以調整生成摘要的語義空間的新框架，從而最大程度地減少媒體偏見。這些損失旨在平衡兩極化輸入之間的語義距離，並確保與專家撰寫的摘要保持一致，指導生成中立且內容豐富的摘要。為了評估媒體偏見，我們採用了政治羅盤測試，該測試根據經濟和社會層面來描繪政治傾向。在 Allsides 資料集上的實驗結果表明，NeutraSum 不僅提高了摘要性能，還顯著減少了媒體偏見，為中立新聞摘要提供了一種有前景的方法。

##### **CultureVLM: Characterizing and Improving Cultural Understanding of Vision-Language Models for over 100 Countries**
2501.01282v1 by Shudong Liu, Yiqiao Jin, Cheng Li, Derek F. Wong, Qingsong Wen, Lichao Sun, Haipeng Chen, Xing Xie, Jindong Wang

Vision-language models (VLMs) have advanced human-AI interaction but struggle
with cultural understanding, often misinterpreting symbols, gestures, and
artifacts due to biases in predominantly Western-centric training data. In this
paper, we construct CultureVerse, a large-scale multimodal benchmark covering
19, 682 cultural concepts, 188 countries/regions, 15 cultural concepts, and 3
question types, with the aim of characterizing and improving VLMs'
multicultural understanding capabilities. Then, we propose CultureVLM, a series
of VLMs fine-tuned on our dataset to achieve significant performance
improvement in cultural understanding. Our evaluation of 16 models reveals
significant disparities, with a stronger performance in Western concepts and
weaker results in African and Asian contexts. Fine-tuning on our CultureVerse
enhances cultural perception, demonstrating cross-cultural, cross-continent,
and cross-dataset generalization without sacrificing performance on models'
general VLM benchmarks. We further present insights on cultural generalization
and forgetting. We hope that this work could lay the foundation for more
equitable and culturally aware multimodal AI systems.

摘要：視覺語言模型 (VLM) 促進了人類與人工智慧的互動，但卻在文化理解方面遇到困難，由於以西方為主的訓練資料中的偏見，常常誤解符號、手勢和文物。在本文中，我們建構了 CultureVerse，一個涵蓋 19,682 個文化概念、188 個國家/地區、15 個文化概念和 3 種問題類型的大規模多模態基準，目的是描述和改善 VLM 的多元文化理解能力。然後，我們提出了 CultureVLM，這是一系列針對我們的資料集進行微調的 VLM，以在文化理解方面實現顯著的效能提升。我們對 16 個模型的評估顯示出顯著的差異，在西方概念中表現較佳，而在非洲和亞洲背景中的結果較差。針對我們的 CultureVerse 進行微調可以增強文化認知，展示跨文化、跨洲和跨資料集的概化，而不會犧牲模型在一般 VLM 基準上的效能。我們進一步提出了關於文化概化和遺忘的見解。我們希望這項工作可以為更公平且具有文化意識的多模態人工智慧系統奠定基礎。

##### **Does a Large Language Model Really Speak in Human-Like Language?**
2501.01273v1 by Mose Park, Yunjin Choi, Jong-June Jeon

Large Language Models (LLMs) have recently emerged, attracting considerable
attention due to their ability to generate highly natural, human-like text.
This study compares the latent community structures of LLM-generated text and
human-written text within a hypothesis testing procedure. Specifically, we
analyze three text sets: original human-written texts ($\mathcal{O}$), their
LLM-paraphrased versions ($\mathcal{G}$), and a twice-paraphrased set
($\mathcal{S}$) derived from $\mathcal{G}$. Our analysis addresses two key
questions: (1) Is the difference in latent community structures between
$\mathcal{O}$ and $\mathcal{G}$ the same as that between $\mathcal{G}$ and
$\mathcal{S}$? (2) Does $\mathcal{G}$ become more similar to $\mathcal{O}$ as
the LLM parameter controlling text variability is adjusted? The first question
is based on the assumption that if LLM-generated text truly resembles human
language, then the gap between the pair ($\mathcal{O}$, $\mathcal{G}$) should
be similar to that between the pair ($\mathcal{G}$, $\mathcal{S}$), as both
pairs consist of an original text and its paraphrase. The second question
examines whether the degree of similarity between LLM-generated and human text
varies with changes in the breadth of text generation. To address these
questions, we propose a statistical hypothesis testing framework that leverages
the fact that each text has corresponding parts across all datasets due to
their paraphrasing relationship. This relationship enables the mapping of one
dataset's relative position to another, allowing two datasets to be mapped to a
third dataset. As a result, both mapped datasets can be quantified with respect
to the space characterized by the third dataset, facilitating a direct
comparison between them. Our results indicate that GPT-generated text remains
distinct from human-authored text.

摘要：大型語言模型 (LLM) 最近浮出檯面，由於它們生成高度自然、類似人類文字的能力而備受關注。本研究比較了 LLM 生成的文字和人類撰寫的文字在假設檢定程序中的潛在社群結構。具體來說，我們分析了三組文字：原始的人類撰寫文字（$\mathcal{O}$）、它們的 LLM 釋義版本（$\mathcal{G}$）以及從 $\mathcal{G}$ 衍生的二次釋義組（$\mathcal{S}$）。我們的分析探討了兩個關鍵問題：(1) $\mathcal{O}$ 和 $\mathcal{G}$ 之間潛在社群結構的差異是否與 $\mathcal{G}$ 和 $\mathcal{S}$ 之間的差異相同？(2) 隨著控制文字變異性的 LLM 參數進行調整，$\mathcal{G}$ 是否會變得更類似於 $\mathcal{O}$？第一個問題基於以下假設：如果 LLM 生成的文字確實類似於人類語言，那麼成對（$\mathcal{O}$，$\mathcal{G}$）之間的差距應該類似於成對（$\mathcal{G}$，$\mathcal{S}$）之間的差距，因為這兩對都包含原始文字及其釋義。第二個問題探討 LLM 生成的文字和人類文字之間的相似度是否會隨著文字生成廣度的變化而變化。為了探討這些問題，我們提出了一個統計假設檢定架構，利用了每個文字在所有資料集之間都有對應部分的事實，因為它們之間存在釋義關係。這種關係使得一個資料集的相對位置可以對應到另一個資料集，從而允許兩個資料集對應到第三個資料集。因此，這兩個對應的資料集都可以根據第三個資料集的特徵空間進行量化，從而便於在它們之間進行直接比較。我們的結果表明，GPT 生成的文字仍然有別於人類撰寫的文字。

##### **ProgCo: Program Helps Self-Correction of Large Language Models**
2501.01264v1 by Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng

Self-Correction aims to enable large language models (LLMs) to self-verify
and self-refine their initial responses without external feedback. However,
LLMs often fail to effectively self-verify and generate correct feedback,
further misleading refinement and leading to the failure of self-correction,
especially in complex reasoning tasks. In this paper, we propose Program-driven
Self-Correction (ProgCo). First, program-driven verification (ProgVe) achieves
complex verification logic and extensive validation through self-generated,
self-executing verification pseudo-programs. Then, program-driven refinement
(ProgRe) receives feedback from ProgVe, conducts dual reflection and refinement
on both responses and verification programs to mitigate misleading of incorrect
feedback in complex reasoning tasks. Experiments on three instruction-following
and mathematical benchmarks indicate that ProgCo achieves effective
self-correction, and can be further enhance performance when combined with real
program tools.

摘要：自我修正旨在讓大型語言模型 (LLM) 能自我驗證和自我修正其初始回應，而無需外部回饋。然而，LLM 經常無法有效自我驗證並產生正確的回饋，進一步誤導修正並導致自我修正失敗，特別是在複雜的推理任務中。在本文中，我們提出程式驅動的自我修正 (ProgCo)。首先，程式驅動驗證 (ProgVe) 透過自我產生的、自我執行的驗證偽程式，實現複雜的驗證邏輯和廣泛的驗證。然後，程式驅動修正 (ProgRe) 接收 ProgVe 的回饋，對回應和驗證程式進行雙重反思和修正，以減輕錯誤回饋在複雜推理任務中的誤導。在三個指令遵循和數學基準上的實驗表明，ProgCo 達到了有效的自我修正，並且與真實的程式工具結合使用時，可以進一步提升效能。

##### **Stealthy Backdoor Attack to Real-world Models in Android Apps**
2501.01263v1 by Jiali Wei, Ming Fan, Xicheng Zhang, Wenjing Jiao, Haijun Wang, Ting Liu

Powered by their superior performance, deep neural networks (DNNs) have found
widespread applications across various domains. Many deep learning (DL) models
are now embedded in mobile apps, making them more accessible to end users
through on-device DL. However, deploying on-device DL to users' smartphones
simultaneously introduces several security threats. One primary threat is
backdoor attacks. Extensive research has explored backdoor attacks for several
years and has proposed numerous attack approaches. However, few studies have
investigated backdoor attacks on DL models deployed in the real world, or they
have shown obvious deficiencies in effectiveness and stealthiness. In this
work, we explore more effective and stealthy backdoor attacks on real-world DL
models extracted from mobile apps. Our main justification is that imperceptible
and sample-specific backdoor triggers generated by DNN-based steganography can
enhance the efficacy of backdoor attacks on real-world models. We first confirm
the effectiveness of steganography-based backdoor attacks on four
state-of-the-art DNN models. Subsequently, we systematically evaluate and
analyze the stealthiness of the attacks to ensure they are difficult to
perceive. Finally, we implement the backdoor attacks on real-world models and
compare our approach with three baseline methods. We collect 38,387 mobile
apps, extract 89 DL models from them, and analyze these models to obtain the
prerequisite model information for the attacks. After identifying the target
models, our approach achieves an average of 12.50% higher attack success rate
than DeepPayload while better maintaining the normal performance of the models.
Extensive experimental results demonstrate that our method enables more
effective, robust, and stealthy backdoor attacks on real-world models.

摘要：<paragraph>深度神经網路（DNN）憑藉其卓越的效能，已廣泛應用於各個領域。許多深度學習（DL）模型現已內嵌於行動應用程式中，讓使用者透過裝置上的 DL 更容易取得這些模型。然而，將裝置上的 DL 部署到使用者的智慧型手機中，同時也引入了多項安全威脅。其中一項主要威脅就是後門攻擊。多年來，針對後門攻擊已進行了廣泛的研究，並提出了許多攻擊方法。然而，鮮少有研究探討部署於真實世界中的 DL 模型所遭受的後門攻擊，或是在有效性和隱匿性方面顯示出明顯的缺陷。在這項工作中，我們探討了針對從行動應用程式中萃取的真實世界 DL 模型，更有效且隱匿的後門攻擊。我們的論點主要是，基於 DNN 隱寫術所產生的難以察覺且特定於樣本的後門觸發器，可以提升後門攻擊對真實世界模型的效力。我們首先確認了基於隱寫術的後門攻擊對四種最先進的 DNN 模型的有效性。接著，我們系統性地評估和分析攻擊的隱匿性，以確保它們難以察覺。最後，我們在真實世界模型上實作後門攻擊，並將我們的做法與三種基準方法進行比較。我們收集了 38,387 個行動應用程式，從中萃取了 89 個 DL 模型，並分析這些模型以取得攻擊所需的模型資訊。在找出目標模型後，我們的做法比 DeepPayload 達到了平均高出 12.50% 的攻擊成功率，同時更能維持模型的正常效能。廣泛的實驗結果證明，我們的做法讓後門攻擊對真實世界模型更有效、更強健且更隱匿。</paragraph>

##### **CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings**
2501.01257v2 by Shanghaoran Quan, Jiaxi Yang, Bowen Yu, Bo Zheng, Dayiheng Liu, An Yang, Xuancheng Ren, Bofei Gao, Yibo Miao, Yunlong Feng, Zekun Wang, Jian Yang, Zeyu Cui, Yang Fan, Yichang Zhang, Binyuan Hui, Junyang Lin

With the increasing code reasoning capabilities of existing large language
models (LLMs) and breakthroughs in reasoning models like OpenAI o1 and o3,
there is a growing need to develop more challenging and comprehensive
benchmarks that effectively test their sophisticated competition-level coding
abilities. Existing benchmarks, like LiveCodeBench and USACO, fall short due to
the unavailability of private test cases, lack of support for special judges,
and misaligned execution environments. To bridge this gap, we introduce
CodeElo, a standardized competition-level code generation benchmark that
effectively addresses all these challenges for the first time. CodeElo
benchmark is mainly based on the official CodeForces platform and tries to
align with the platform as much as possible. We compile the recent six months
of contest problems on CodeForces with detailed information such as contest
divisions, problem difficulty ratings, and problem algorithm tags. We introduce
a unique judging method in which problems are submitted directly to the
platform and develop a reliable Elo rating calculation system that aligns with
the platform and is comparable with human participants but has lower variance.
By testing on our CodeElo, we provide the Elo ratings of 30 existing popular
open-source and 3 proprietary LLMs for the first time. The results show that
o1-mini and QwQ-32B-Preview stand out significantly, achieving Elo ratings of
1578 and 1261, respectively, while other models struggle even with the easiest
problems, placing in the lowest 25 percent among all human participants.
Detailed analysis experiments are also conducted to provide insights into
performance across algorithms and comparisons between using C++ and Python,
which can suggest directions for future studies.

摘要：<paragraph>隨著現有大語言模型 (LLM) 的程式碼推理能力不斷提升，以及 OpenAI o1 和 o3 等推理模型的突破，越來越需要開發更具挑戰性和全面性的基準，以有效測試其複雜的競賽級程式編碼能力。現有的基準，例如 LiveCodeBench 和 USACO，由於缺乏私人測試案例、缺乏對特殊評審的支持以及執行環境不一致，因此無法達到要求。為了彌補這一差距，我們引入了 CodeElo，這是一個標準化的競賽級程式碼生成基準，首次有效地應對了所有這些挑戰。CodeElo 基準主要基於官方的 CodeForces 平台，並盡可能與該平台保持一致。我們編譯了 CodeForces 近六個月的競賽題目，並附有詳細資訊，例如競賽組別、題目難度評級和題目演算法標籤。我們引入了一種獨特的評審方法，其中題目直接提交到平台，並開發了一個可靠的 Elo 評分計算系統，該系統與平台保持一致，並且可以與人類參與者相比較，但變異性較低。通過在我們的 CodeElo 上進行測試，我們首次提供了 30 個現有流行開源和 3 個專有 LLM 的 Elo 評分。結果表明，o1-mini 和 QwQ-32B-Preview 顯著脫穎而出，分別獲得了 1578 和 1261 的 Elo 評分，而其他模型甚至在最簡單的題目上也難以應對，在所有人類參與者中排名最低的 25%。還進行了詳細的分析實驗，以深入了解演算法的效能，以及使用 C++ 和 Python 之間的比較，這可以為未來的研究提供方向。</paragraph>

##### **Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably detect hate speech in reader comments of German online newspapers?**
2501.01256v1 by Manuel Weber, Moritz Huber, Maximilian Auch, Alexander Döschl, Max-Emanuel Keller, Peter Mandl

In recent years, toxic content and hate speech have become widespread
phenomena on the internet. Moderators of online newspapers and forums are now
required, partly due to legal regulations, to carefully review and, if
necessary, delete reader comments. This is a labor-intensive process. Some
providers of large language models already offer solutions for automated hate
speech detection or the identification of toxic content. These include GPT-4o
from OpenAI, Jigsaw's (Google) Perspective API, and OpenAI's Moderation API.
Based on the selected German test dataset HOCON34k, which was specifically
created for developing tools to detect hate speech in reader comments of online
newspapers, these solutions are compared with each other and against the
HOCON34k baseline. The test dataset contains 1,592 annotated text samples. For
GPT-4o, three different promptings are used, employing a Zero-Shot, One-Shot,
and Few-Shot approach. The results of the experiments demonstrate that GPT-4o
outperforms both the Perspective API and the Moderation API, and exceeds the
HOCON34k baseline by approximately 5 percentage points, as measured by a
combined metric of MCC and F2-score.

摘要：近年來，網路上的有毒內容和仇恨言論已成為普遍現象。線上報紙和論壇的管理員現在必須仔細審查讀者留言，並在必要時刪除，這部分是基於法規要求。這是一個勞力密集的程序。一些大型語言模型的提供者已提供自動仇恨言論偵測或有毒內容識別的解決方案。這些解決方案包括 OpenAI 的 GPT-4o、Jigsaw（Google）的 Perspective API，以及 OpenAI 的 Moderation API。基於專門為開發用於偵測線上報紙讀者留言中仇恨言論的工具而建立的德語測試資料集 HOCON34k，這些解決方案彼此之間以及與 HOCON34k 基準進行比較。測試資料集包含 1,592 個註解文字範例。對於 GPT-4o，使用了三種不同的提示，採用零次學習、一次學習和少次學習方法。實驗結果顯示，GPT-4o 的表現優於 Perspective API 和 Moderation API，並且比 HOCON34k 基準高出約 5 個百分點，這是根據 MCC 和 F2 分數的綜合指標測量的。

##### **Large Language Model-Enhanced Symbolic Reasoning for Knowledge Base Completion**
2501.01246v1 by Qiyuan He, Jianfei Yu, Wenya Wang

Integrating large language models (LLMs) with rule-based reasoning offers a
powerful solution for improving the flexibility and reliability of Knowledge
Base Completion (KBC). Traditional rule-based KBC methods offer verifiable
reasoning yet lack flexibility, while LLMs provide strong semantic
understanding yet suffer from hallucinations. With the aim of combining LLMs'
understanding capability with the logical and rigor of rule-based approaches,
we propose a novel framework consisting of a Subgraph Extractor, an LLM
Proposer, and a Rule Reasoner. The Subgraph Extractor first samples subgraphs
from the KB. Then, the LLM uses these subgraphs to propose diverse and
meaningful rules that are helpful for inferring missing facts. To effectively
avoid hallucination in LLMs' generations, these proposed rules are further
refined by a Rule Reasoner to pinpoint the most significant rules in the KB for
Knowledge Base Completion. Our approach offers several key benefits: the
utilization of LLMs to enhance the richness and diversity of the proposed rules
and the integration with rule-based reasoning to improve reliability. Our
method also demonstrates strong performance across diverse KB datasets,
highlighting the robustness and generalizability of the proposed framework.

摘要：將大型語言模型 (LLM) 與基於規則的推理整合，提供了一個強大的解決方案，用於提升知識庫完成 (KBC) 的彈性和可靠性。傳統的基於規則的 KBC 方法提供可驗證的推理，但缺乏彈性，而 LLM 提供強大的語義理解，但會產生幻覺。為了結合 LLM 的理解能力與基於規則方法的邏輯和嚴謹性，我們提出了一個創新的架構，包含一個子圖萃取器、一個 LLM 建議器和一個規則推理器。子圖萃取器首先從 KB 中取樣子圖。然後，LLM 使用這些子圖提出多樣且有意義的規則，有助於推論出遺失的事實。為了有效避免 LLM 生成中的幻覺，這些提出的規則會進一步由規則推理器提煉，以找出 KB 中對知識庫完成最重要的規則。我們的做法提供了幾個關鍵的好處：利用 LLM 來加強所提出規則的豐富性和多樣性，以及與基於規則的推理整合以提升可靠性。我們的做法也展現出在各種 KB 資料集中的強勁效能，突顯了所提出架構的穩健性和概括性。

##### **Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants**
2501.01243v1 by Lixiong Qin, Shilong Ou, Miaoxuan Zhang, Jiangning Wei, Yuhang Zhang, Xiaoshuai Song, Yuchen Liu, Mei Wang, Weiran Xu

Faces and humans are crucial elements in social interaction and are widely
included in everyday photos and videos. Therefore, a deep understanding of
faces and humans will enable multi-modal assistants to achieve improved
response quality and broadened application scope. Currently, the multi-modal
assistant community lacks a comprehensive and scientific evaluation of face and
human understanding abilities. In this paper, we first propose a hierarchical
ability taxonomy that includes three levels of abilities. Then, based on this
taxonomy, we collect images and annotations from publicly available datasets in
the face and human community and build a semi-automatic data pipeline to
produce problems for the new benchmark. Finally, the obtained Face-Human-Bench
comprises a development set with 900 problems and a test set with 1800
problems, supporting both English and Chinese. We conduct evaluations over 25
mainstream multi-modal large language models (MLLMs) with our Face-Human-Bench,
focusing on the correlation between abilities, the impact of the relative
position of targets on performance, and the impact of Chain of Thought (CoT)
prompting on performance. Moreover, inspired by multi-modal agents, we also
explore which abilities of MLLMs need to be supplemented by specialist models.

摘要：臉部和人類是社交互動中至關重要的元素，並廣泛包含在日常照片和影片中。因此，對臉部和人類的深入了解將使多模態助理能夠獲得更好的回應品質和更廣泛的應用範圍。目前，多模態助理社群缺乏對臉部和人類理解能力的全面且科學的評估。在本文中，我們首先提出一個分層能力分類法，其中包含三級能力。然後，基於此分類法，我們從人臉和人類社群中公開可用的資料集收集影像和註解，並建立一個半自動化資料管道，以產生新基準的問題。最後，獲得的 Face-Human-Bench 包含一個有 900 個問題的開發集和一個有 1800 個問題的測試集，同時支援英文和中文。我們使用我們的 Face-Human-Bench 對 25 個主流多模態大型語言模型 (MLLM) 進行評估，重點關注能力之間的關聯性、目標的相對位置對效能的影響，以及思考鏈 (CoT) 提示對效能的影響。此外，受到多模態代理的啟發，我們也探討了哪些 MLLM 的能力需要由專家模型補充。

##### **An Efficient Attention Mechanism for Sequential Recommendation Tasks: HydraRec**
2501.01242v1 by Uzma Mushtaque

Transformer based models are increasingly being used in various domains
including recommender systems (RS). Pretrained transformer models such as BERT
have shown good performance at language modelling. With the greater ability to
model sequential tasks, variants of Encoder-only models (like BERT4Rec, SASRec
etc.) have found success in sequential RS problems. Computing dot-product
attention in traditional transformer models has quadratic complexity in
sequence length. This is a bigger problem with RS because unlike language
models, new items are added to the catalogue every day. User buying history is
a dynamic sequence which depends on multiple factors. Recently, various linear
attention models have tried to solve this problem by making the model linear in
sequence length (token dimensions). Hydra attention is one such linear
complexity model proposed for vision transformers which reduces the complexity
of attention for both the number of tokens as well as model embedding
dimensions. Building on the idea of Hydra attention, we introduce an efficient
Transformer based Sequential RS (HydraRec) which significantly improves
theoretical complexity of computing attention for longer sequences and bigger
datasets while preserving the temporal context. Extensive experiments are
conducted to evaluate other linear transformer-based RS models and compared
with HydraRec across various evaluation metrics. HydraRec outperforms other
linear attention-based models as well as dot-product based attention models
when used with causal masking for sequential recommendation next item
prediction tasks. For bi-directional models its performance is comparable to
the BERT4Rec model with an improvement in running time.

摘要：<paragraph>基於 Transformer 的模型愈來愈多地用於各種領域，包括推薦系統 (RS)。預訓練的 Transformer 模型，例如 BERT，已在語言建模方面展現出良好的效能。隨著對序列任務建模能力的提升，僅編碼器模型的變體（例如 BERT4Rec、SASRec 等）已在序列 RS 問題中獲得成功。在傳統 Transformer 模型中計算點積注意力時，其序列長度具有二次複雜度。這對於 RS 來說是一個更大的問題，因為與語言模型不同，每天都會有新的項目新增到目錄中。使用者的購買記錄是一個動態序列，取決於多重因素。最近，各種線性注意力模型已嘗試通過使模型在序列長度（標記維度）中線性化來解決此問題。Hydra 注意力是一種針對視覺 Transformer 提出、具有此類線性複雜度的模型，它降低了對標記數量和模型嵌入維度的注意力的複雜度。基於 Hydra 注意力的概念，我們引入了一個高效的基於 Transformer 的序列 RS（HydraRec），它顯著改善了計算較長序列和較大資料集注意力的理論複雜度，同時保留了時間脈絡。我們進行了廣泛的實驗，以評估其他基於線性 Transformer 的 RS 模型，並在各種評估指標中將其與 HydraRec 進行了比較。在用於序列推薦下一個項目預測任務的因果遮罩時，HydraRec 優於其他基於線性注意力的模型以及基於點積的注意力模型。對於雙向模型，其效能可與 BERT4Rec 模型相媲美，同時縮短了執行時間。</paragraph>

##### **Automated Self-Refinement and Self-Correction for LLM-based Product Attribute Value Extraction**
2501.01237v1 by Alexander Brinkmann, Christian Bizer

Structured product data, in the form of attribute-value pairs, is essential
for e-commerce platforms to support features such as faceted product search and
attribute-based product comparison. However, vendors often provide unstructured
product descriptions, making attribute value extraction necessary to ensure
data consistency and usability. Large language models (LLMs) have demonstrated
their potential for product attribute value extraction in few-shot scenarios.
Recent research has shown that self-refinement techniques can improve the
performance of LLMs on tasks such as code generation and text-to-SQL
translation. For other tasks, the application of these techniques has resulted
in increased costs due to processing additional tokens, without achieving any
improvement in performance. This paper investigates applying two
self-refinement techniques, error-based prompt rewriting and self-correction,
to the product attribute value extraction task. The self-refinement techniques
are evaluated across zero-shot, few-shot in-context learning, and fine-tuning
scenarios using GPT-4o. The experiments show that both self-refinement
techniques have only a marginal impact on the model's performance across the
different scenarios, while significantly increasing processing costs. For
scenarios with training data, fine-tuning yields the highest performance, while
the ramp-up costs of fine-tuning are balanced out as the amount of product
descriptions increases.

摘要：結構化產品資料，以屬性值對的形式，對於電子商務平台支援多面向產品搜尋和基於屬性的產品比較等功能至關重要。然而，供應商通常提供非結構化的產品描述，這使得屬性值萃取對於確保資料一致性和可用性變得必要。大型語言模型 (LLM) 已展現出其在少量範例場景中進行產品屬性值萃取的潛力。最近的研究表明，自我精進技術可以提升 LLM 在程式碼產生和文字轉 SQL 翻譯等任務上的效能。對於其他任務，這些技術的應用會因處理額外的符號而導致成本增加，而並未提升效能。本文探討將兩種自我精進技術，即基於錯誤的提示重寫和自我修正，應用於產品屬性值萃取任務。自我精進技術在 GPT-4o 上使用零次學習、少量範例情境學習和微調情境進行評估。實驗顯示，兩種自我精進技術對於模型在不同情境下的效能只有邊際影響，同時大幅增加了處理成本。對於有訓練資料的情境，微調會產生最高的效能，而微調的啟動成本會隨著產品描述的數量增加而達到平衡。

##### **Enhancing Reasoning through Process Supervision with Monte Carlo Tree Search**
2501.01478v1 by Shuangtao Li, Shuaihao Dong, Kexin Luan, Xinhan Di, Chaofan Ding

Large language models (LLMs) have demonstrated their remarkable capacity
across a variety of tasks. However, reasoning remains a challenge for LLMs. To
improve LLMs' reasoning ability, process supervision has proven to be better
than outcome supervision. In this work, we study using Monte Carlo Tree Search
(MCTS) to generate process supervision data with LLMs themselves for training
them. We sample reasoning steps with an LLM and assign each step a score that
captures its "relative correctness," and the LLM is then trained by minimizing
weighted log-likelihood of generating the reasoning steps. This
generate-then-train process is repeated iteratively until convergence.Our
experimental results demonstrate that the proposed methods considerably improve
the performance of LLMs on two mathematical reasoning datasets. Furthermore,
models trained on one dataset also exhibit improved performance on the other,
showing the transferability of the enhanced reasoning ability.

摘要：大型語言模型 (LLM) 已展現其在各種任務上的驚人能力。然而，推理對於 LLM 來說仍然是一個挑戰。為了提升 LLM 的推理能力，處理監督已被證明優於結果監督。在這項工作中，我們研究使用蒙地卡羅樹狀搜尋 (MCTS) 為 LLM 本身生成處理監督資料以進行訓練。我們使用 LLM 取樣推理步驟，並為每個步驟指定一個分數，以捕捉其「相對正確性」，然後訓練 LLM 以最小化生成推理步驟的加權對數似然。這個生成然後訓練的過程會重複執行，直到收斂。我們的實驗結果表明，所提出的方法顯著提升了 LLM 在兩個數學推理資料集上的效能。此外，在一個資料集上訓練的模型在另一個資料集上也表現出進步的效能，顯示增強推理能力的可轉移性。

##### **A redescription mining framework for post-hoc explaining and relating deep learning models**
2501.01209v1 by Matej Mihelčić, Ivan Grubišić, Miha Keber

Deep learning models (DLMs) achieve increasingly high performance both on
structured and unstructured data. They significantly extended applicability of
machine learning to various domains. Their success in making predictions,
detecting patterns and generating new data made significant impact on science
and industry. Despite these accomplishments, DLMs are difficult to explain
because of their enormous size. In this work, we propose a novel framework for
post-hoc explaining and relating DLMs using redescriptions. The framework
allows cohort analysis of arbitrary DLMs by identifying statistically
significant redescriptions of neuron activations. It allows coupling neurons to
a set of target labels or sets of descriptive attributes, relating layers
within a single DLM or associating different DLMs. The proposed framework is
independent of the artificial neural network architecture and can work with
more complex target labels (e.g. multi-label or multi-target scenario).
Additionally, it can emulate both pedagogical and decompositional approach to
rule extraction. The aforementioned properties of the proposed framework can
increase explainability and interpretability of arbitrary DLMs by providing
different information compared to existing explainable-AI approaches.

摘要：深度學習模型 (DLM) 在結構化和非結構化資料上都獲得越來越高的效能。它們顯著地將機器學習的應用範圍擴展到各種領域。它們在進行預測、偵測模式和產生新資料方面的成功，對科學和產業產生了重大的影響。儘管有這些成就，但 DLM 很難解釋，因為它們的規模龐大。在這項工作中，我們提出了一個新的架構，用於使用重新描述來事後解釋和關聯 DLM。該框架允許通過識別神經元激活的統計顯著重新描述，對任意 DLM 進行群體分析。它允許將神經元與一組目標標籤或一組描述性屬性相結合，關聯單個 DLM 中的層或關聯不同的 DLM。所提出的框架獨立於人工神經網路架構，並且可以處理更複雜的目標標籤（例如多標籤或多目標場景）。此外，它可以模擬教學和分解方法來進行規則提取。與現有的可解釋 AI 方法相比，所提出的框架的上述特性可以通過提供不同的資訊來提高任意 DLM 的可解釋性和可詮釋性。

##### **Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects**
2501.01205v1 by Abdullah Mushtaq, Muhammad Rafay Naeem, Ibrahim Ghaznavi, Muhammad Imran Taj, Imran Hashmi, Junaid Qadir

Multi-Agent Large Language Models (LLMs) are gaining significant attention
for their ability to harness collective intelligence in complex
problem-solving, decision-making, and planning tasks. This aligns with the
concept of the wisdom of crowds, where diverse agents contribute collectively
to generating effective solutions, making it particularly suitable for
educational settings. Senior design projects, also known as capstone or final
year projects, are pivotal in engineering education as they integrate
theoretical knowledge with practical application, fostering critical thinking,
teamwork, and real-world problem-solving skills. In this paper, we explore the
use of Multi-Agent LLMs in supporting these senior design projects undertaken
by engineering students, which often involve multidisciplinary considerations
and conflicting objectives, such as optimizing technical performance while
addressing ethical, social, and environmental concerns. We propose a framework
where distinct LLM agents represent different expert perspectives, such as
problem formulation agents, system complexity agents, societal and ethical
agents, or project managers, thus facilitating a holistic problem-solving
approach. This implementation leverages standard multi-agent system (MAS)
concepts such as coordination, cooperation, and negotiation, incorporating
prompt engineering to develop diverse personas for each agent. These agents
engage in rich, collaborative dialogues to simulate human engineering teams,
guided by principles from swarm AI to efficiently balance individual
contributions towards a unified solution. We adapt these techniques to create a
collaboration structure for LLM agents, encouraging interdisciplinary reasoning
and negotiation similar to real-world senior design projects. To assess the
efficacy of this framework, we collected six proposals of engineering and
computer science of...

摘要：多代理大型語言模型 (LLM) 因其在複雜問題解決、決策制定和規劃任務中利用集體智慧的能力而備受關注。這與集體智慧的概念相一致，其中不同的代理集體貢獻於產生有效的解決方案，使其特別適用於教育環境。高級設計專題，也稱為頂點或最後一年專題，在工程教育中至關重要，因為它們將理論知識與實際應用相結合，培養批判性思維、團隊合作和現實世界問題解決技能。在本文中，我們探討了多代理 LLM 在支持工程學生承擔的高級設計專題中的應用，這些專題通常涉及多學科考慮因素和相互衝突的目標，例如在解決道德、社會和環境問題的同時優化技術性能。我們提出了一個框架，其中不同的 LLM 代理代表不同的專家觀點，例如問題表述代理、系統複雜性代理、社會和道德代理或專案經理，從而促進全面的問題解決方法。此實作利用標準多代理系統 (MAS) 概念，例如協調、合作和協商，並結合提示工程來為每個代理開發不同的角色。這些代理參與豐富的協作對話，以模擬人類工程團隊，並遵循群體 AI 的原則，以有效平衡個人貢獻，朝向統一的解決方案。我們採用這些技術為 LLM 代理建立協作結構，鼓勵跨學科推理和協商，類似於現實世界的高級設計專題。為了評估此架構的效能，我們收集了六個工程和電腦科學的提案......

##### **Data Augmentation Techniques for Chinese Disease Name Normalization**
2501.01195v1 by Wenqian Cui, Xiangling Fu, Shaohui Liu, Mingjun Gu, Xien Liu, Ji Wu, Irwin King

Disease name normalization is an important task in the medical domain. It
classifies disease names written in various formats into standardized names,
serving as a fundamental component in smart healthcare systems for various
disease-related functions. Nevertheless, the most significant obstacle to
existing disease name normalization systems is the severe shortage of training
data. Consequently, we present a novel data augmentation approach that includes
a series of data augmentation techniques and some supporting modules to help
mitigate the problem. Through extensive experimentation, we illustrate that our
proposed approach exhibits significant performance improvements across various
baseline models and training objectives, particularly in scenarios with limited
training data

摘要：疾病名稱正規化是醫學領域中一項重要的任務。它將以各種格式書寫的疾病名稱分類為標準化名稱，作為智慧醫療系統中各種疾病相關功能的基本組成部分。然而，現有疾病名稱正規化系統最顯著的障礙是訓練資料嚴重短缺。因此，我們提出了一種新穎的資料擴充方法，其中包括一系列資料擴充技術和一些輔助模組，以幫助減輕這個問題。透過廣泛的實驗，我們說明我們提出的方法在各種基線模型和訓練目標中展現出顯著的效能提升，特別是在訓練資料有限的情況下

##### **Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets**
2501.01168v1 by Mahdi Zakizadeh, Mohammad Taher Pilehvar

The multifaceted challenge of accurately measuring gender stereotypical bias
in language models is akin to discerning different segments of a broader,
unseen entity. This short paper primarily focuses on intrinsic bias mitigation
and measurement strategies for language models, building on prior research that
demonstrates a lack of correlation between intrinsic and extrinsic approaches.
We delve deeper into intrinsic measurements, identifying inconsistencies and
suggesting that these benchmarks may reflect different facets of gender
stereotype. Our methodology involves analyzing data distributions across
datasets and integrating gender stereotype components informed by social
psychology. By adjusting the distribution of two datasets, we achieve a better
alignment of outcomes. Our findings underscore the complexity of gender
stereotyping in language models and point to new directions for developing more
refined techniques to detect and reduce bias.

摘要：準確衡量語言模型中的性別刻板印象偏見這項多面向的挑戰，就像辨識更廣泛、未見實體的不同區段。這篇簡短的論文主要關注語言模型的內在偏見減緩和衡量策略，建立在先前的研究基礎上，證明內在和外在方法之間缺乏相關性。我們更深入地探討內在衡量，找出不一致之處，並提出這些基準可能反映性別刻板印象的不同面向。我們的做法包括分析資料集中的資料分佈，並整合社會心理學所提供的性別刻板印象組成。透過調整兩個資料集的分佈，我們獲得更一致的結果。我們的發現強調語言模型中性別刻板印象的複雜性，並指出開發更精緻的技術以偵測和減少偏見的新方向。

##### **Leveraging Full Dependency Parsing Graph Information For Biomedical Event Extraction**
2501.01158v1 by Farshad Noravesh, Reza Haffari, Ong Huey Fang, Layki Soon, Sailaja Rajalana, Arghya Pal

Many models are proposed in the literature on biomedical event
extraction(BEE). Some of them use the shortest dependency path(SDP) information
to represent the argument classification task. There is an issue with this
representation since even missing one word from the dependency parsing graph
may totally change the final prediction. To this end, the full adjacency matrix
of the dependency graph is used to embed individual tokens using a graph
convolutional network(GCN). An ablation study is also done to show the effect
of the dependency graph on the overall performance. The results show a
significant improvement when dependency graph information is used. The proposed
model slightly outperforms state-of-the-art models on BEE over different
datasets.

摘要：許多模型在生物醫學事件萃取（BEE）文獻中被提出。其中一些使用最短依存路徑（SDP）資訊來表示論證分類任務。這個表示存在一個問題，因為即使從依存解析圖中遺漏一個字，也可能完全改變最終預測。為此，依存圖的完整鄰接矩陣用於使用圖形卷積網路（GCN）嵌入個別符號。還進行了一項消融研究，以顯示依存圖對整體效能的影響。結果顯示，當使用依存圖資訊時，有顯著的改善。所提出的模型在 BEE 上略勝過不同資料集上的最新模型。

##### **TexAVi: Generating Stereoscopic VR Video Clips from Text Descriptions**
2501.01156v1 by Vriksha Srihari, R. Bhavya, Shruti Jayaraman, V. Mary Anita Rajam

While generative models such as text-to-image, large language models and
text-to-video have seen significant progress, the extension to
text-to-virtual-reality remains largely unexplored, due to a deficit in
training data and the complexity of achieving realistic depth and motion in
virtual environments. This paper proposes an approach to coalesce existing
generative systems to form a stereoscopic virtual reality video from text.
  Carried out in three main stages, we start with a base text-to-image model
that captures context from an input text. We then employ Stable Diffusion on
the rudimentary image produced, to generate frames with enhanced realism and
overall quality. These frames are processed with depth estimation algorithms to
create left-eye and right-eye views, which are stitched side-by-side to create
an immersive viewing experience. Such systems would be highly beneficial in
virtual reality production, since filming and scene building often require
extensive hours of work and post-production effort.
  We utilize image evaluation techniques, specifically Fr\'echet Inception
Distance and CLIP Score, to assess the visual quality of frames produced for
the video. These quantitative measures establish the proficiency of the
proposed method.
  Our work highlights the exciting possibilities of using natural
language-driven graphics in fields like virtual reality simulations.

摘要：<paragraph>儘管生成模型（例如文字轉圖像、大型語言模型和文字轉影片）已取得顯著進展，但文字轉虛擬實境擴充仍未廣泛探索，原因在於訓練資料不足，以及在虛擬環境中實現逼真深度和動作的複雜性。本文提出了一種方法，將現有的生成系統合併，以從文字形成立體虛擬實境影片。
  分為三個主要階段進行，我們從基礎文字轉圖像模型開始，該模型會擷取輸入文字的內容。然後，我們在產生的基本圖像上使用 Stable Diffusion，以生成具有增強真實感和整體品質的畫面。這些畫面會使用深度估計演算法進行處理，以建立左眼和右眼的視圖，並將其並排縫合，以創造身歷其境的觀看體驗。此類系統在虛擬實境製作中將非常有益，因為拍攝和場景建置通常需要大量工時和後製工作。
  我們利用圖像評估技術，特別是 Fr\'echet Inception Distance 和 CLIP Score，來評估為影片產生的畫面的視覺品質。這些量化措施確立了所提出方法的熟練度。
  我們的研究突顯了在虛擬實境模擬等領域使用自然語言驅動圖形的令人興奮的可能性。</paragraph>

##### **A3: Android Agent Arena for Mobile GUI Agents**
2501.01149v1 by Yuxiang Chai, Hanhao Li, Jiayu Zhang, Liang Liu, Guozhi Wang, Shuai Ren, Siyuan Huang, Hongsheng Li

AI agents have become increasingly prevalent in recent years, driven by
significant advancements in the field of large language models (LLMs). Mobile
GUI agents, a subset of AI agents, are designed to autonomously perform tasks
on mobile devices. While numerous studies have introduced agents, datasets, and
benchmarks to advance mobile GUI agent research, many existing datasets focus
on static frame evaluations and fail to provide a comprehensive platform for
assessing performance on real-world, in-the-wild tasks. To address this gap, we
present Android Agent Arena (A3), a novel evaluation platform. Unlike existing
in-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as
real-time online information retrieval and operational instructions; (2) a
larger, more flexible action space, enabling compatibility with agents trained
on any dataset; and (3) automated business-level LLM-based evaluation process.
A3 includes 21 widely used general third-party apps and 201 tasks
representative of common user scenarios, providing a robust foundation for
evaluating mobile GUI agents in real-world situations and a new autonomous
evaluation process for less human labor and coding expertise. The project is
available at \url{https://yuxiangchai.github.io/Android-Agent-Arena/}.

摘要：近年來，由於大型語言模型 (LLM) 領域的重大進展，AI 代理變得越來越普遍。行動 GUI 代理是 AI 代理的子集，旨在自動執行行動裝置上的任務。雖然許多研究已經引進代理、資料集和基準測試來推動行動 GUI 代理研究，但許多現有的資料集都專注於靜態框架評估，而且無法提供一個全面的平台來評估實際的野外任務效能。為了解決這個差距，我們提出 Android Agent Arena (A3)，一個新穎的評估平台。與現有的野外系統不同，A3 提供：(1) 有意義且實用的任務，例如即時線上資訊檢索和操作說明；(2) 一個更大、更靈活的動作空間，讓與在任何資料集上訓練的代理相容；以及 (3) 自動化業務層級 LLM 評估流程。A3 包含 21 個廣泛使用的通用第三方應用程式和 201 個代表常見使用者情境的任務，為評估實際情況下的行動 GUI 代理提供穩固的基礎，以及一個新的自動評估流程，以減少人力和編碼專業知識。該專案可在以下網址取得：\url{https://yuxiangchai.github.io/Android-Agent-Arena/}。

##### **BlockDialect: Block-wise Fine-grained Mixed Format for Energy-Efficient LLM Inference**
2501.01144v2 by Wonsuk Jang, Thierry Tambe

Large Language Models (LLMs) have achieved remarkable success, but their
increasing size poses significant challenges in memory usage and computational
costs. Quantizing both weights and activations can address these issues, with
fine-grained block-wise quantization emerging as a promising hardware-supported
solution to mitigate outliers. However, existing methods struggle to capture
nuanced block data distributions. To address this, we propose BlockDialect, a
block-wise fine-grained mixed format technique that assigns a per-block optimal
number format from formatbook for better data representation. Additionally, we
introduce DialectFP4, a formatbook of FP4 variants (akin to dialects) that
adapt to diverse data distributions. To leverage this efficiently, we propose a
two-stage approach for online DialectFP4 activation quantization. Importantly,
DialectFP4 ensures hardware efficiency by selecting representable values as
scaled integers compatible with low-precision integer arithmetic. BlockDialect
achieves 11.83% (7.56%) accuracy gain on the LLaMA3-8B (LLaMA2-7B) model
compared to MXFP4 format with lower bit usage per data, while being only 5.46%
(2.65%) below full precision even when quantizing full-path matrix
multiplication. Focusing on how to represent over how to scale, our work
presents a promising path for energy-efficient LLM inference.

摘要：大型語言模型 (LLM) 已取得顯著成功，但其規模不斷擴大，對記憶體使用和運算成本構成重大挑戰。量化權重和激活可以解決這些問題，其中細粒度區塊量化作為一種有前景的硬體支援解決方案，用於減輕異常值。然而，現有方法難以捕捉細微的區塊資料分佈。為了解決這個問題，我們提出了 BlockDialect，這是一種區塊式細粒度混合格式技術，它為每個區塊分配一個來自格式簿的最佳數字格式，以獲得更好的資料表示。此外，我們引入了 DialectFP4，這是一個 FP4 變體（類似於方言）的格式簿，可以適應不同的資料分佈。為了有效利用這一點，我們提出了一個用於線上 DialectFP4 激活量化的兩階段方法。重要的是，DialectFP4 通過選擇可表示的值作為與低精度整數運算相容的縮放整數，來確保硬體效率。與每個資料使用較低位元數的 MXFP4 格式相比，BlockDialect 在 LLaMA3-8B (LLaMA2-7B) 模型上實現了 11.83% (7.56%) 的準確度提升，即使在量化全路徑矩陣乘法時，也僅比全精度低 5.46% (2.65%)。我們的研究重點關注如何表示而不是如何縮放，為節能 LLM 推論提供了一條有前景的途徑。

