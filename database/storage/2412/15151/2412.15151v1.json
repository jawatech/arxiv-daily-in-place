{"2412.15151": {"publish_time": "2024-12-19", "title": "Language Models as Continuous Self-Evolving Data Engineers", "paper_summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities on\nvarious tasks, while the further evolvement is limited to the lack of\nhigh-quality training data. In addition, traditional training approaches rely\ntoo much on expert-labeled data, setting an upper limit on the performance of\nLLMs. To address this issue, we propose a novel paradigm that enables LLMs to\ntrain itself by autonomously generating, cleaning, reviewing, and annotating\ndata with preference information, named LANCE. Our approach demonstrates that\nLLMs can serve as continuous self-evolving data engineers, significantly\nreducing the time and cost of the post-training data construction process.\nThrough iterative fine-tuning on different variants of the Qwen2, we validate\nthe effectiveness of LANCE across various tasks, showing that it can\ncontinuously improve model performance and maintain high-quality data\ngeneration. Across eight benchmark dimensions, LANCE resulted in an average\nscore enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This\ntraining paradigm with autonomous data construction not only reduces the\nreliance on human experts or external models but also ensures that the data\naligns with human values and preferences, paving the way for the development of\nfuture superintelligent systems that can exceed human capabilities.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u80fd\u529b\uff0c\u800c\u9032\u4e00\u6b65\u7684\u6f14\u9032\u5247\u53d7\u5230\u7f3a\u4e4f\u9ad8\u54c1\u8cea\u8a13\u7df4\u8cc7\u6599\u7684\u9650\u5236\u3002\u6b64\u5916\uff0c\u50b3\u7d71\u7684\u8a13\u7df4\u65b9\u6cd5\u904e\u5ea6\u4f9d\u8cf4\u5c08\u5bb6\u6a19\u8a18\u7684\u8cc7\u6599\uff0c\u70ba LLM \u7684\u6548\u80fd\u8a2d\u5b9a\u4e86\u4e0a\u9650\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5275\u65b0\u7684\u7bc4\u4f8b\uff0c\u8b93 LLM \u80fd\u5920\u900f\u904e\u81ea\u4e3b\u7522\u751f\u3001\u6e05\u7406\u3001\u5be9\u95b1\u548c\u8a3b\u89e3\u5e36\u6709\u504f\u597d\u8cc7\u8a0a\u7684\u8cc7\u6599\u4f86\u8a13\u7df4\u81ea\u5df1\uff0c\u7a31\u70ba LANCE\u3002\u6211\u5011\u7684\u505a\u6cd5\u8b49\u660e\u4e86 LLM \u53ef\u4ee5\u4f5c\u70ba\u6301\u7e8c\u81ea\u6211\u6f14\u9032\u7684\u8cc7\u6599\u5de5\u7a0b\u5e2b\uff0c\u5927\u5e45\u6e1b\u5c11\u8a13\u7df4\u5f8c\u8cc7\u6599\u5efa\u69cb\u7a0b\u5e8f\u7684\u6642\u9593\u548c\u6210\u672c\u3002\u900f\u904e\u5728 Qwen2 \u7684\u4e0d\u540c\u8b8a\u9ad4\u4e0a\u9032\u884c\u53cd\u8986\u5fae\u8abf\uff0c\u6211\u5011\u9a57\u8b49\u4e86 LANCE \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7684\u6709\u6548\u6027\uff0c\u986f\u793a\u5b83\u53ef\u4ee5\u6301\u7e8c\u6539\u5584\u6a21\u578b\u6548\u80fd\u4e26\u7dad\u6301\u9ad8\u54c1\u8cea\u7684\u8cc7\u6599\u7522\u751f\u3002\u5728\u516b\u500b\u57fa\u6e96\u7dad\u5ea6\u4e2d\uff0cLANCE \u8b93 Qwen2-7B \u7684\u5e73\u5747\u5206\u6578\u63d0\u5347\u4e86 3.36\uff0c\u800c Qwen2-7B-Instruct \u5247\u63d0\u5347\u4e86 2.70\u3002\u9019\u7a2e\u5177\u6709\u81ea\u4e3b\u8cc7\u6599\u5efa\u69cb\u7684\u8a13\u7df4\u7bc4\u4f8b\u4e0d\u50c5\u6e1b\u5c11\u4e86\u5c0d\u4eba\u985e\u5c08\u5bb6\u6216\u5916\u90e8\u6a21\u578b\u7684\u4f9d\u8cf4\uff0c\u9084\u80fd\u78ba\u4fdd\u8cc7\u6599\u7b26\u5408\u4eba\u985e\u7684\u50f9\u503c\u89c0\u548c\u504f\u597d\uff0c\u70ba\u958b\u767c\u672a\u4f86\u80fd\u5920\u8d85\u8d8a\u4eba\u985e\u80fd\u529b\u7684\u8d85\u7d1a\u667a\u6167\u7cfb\u7d71\u92ea\u8def\u3002", "author": "Peidong Wang et.al.", "authors": "Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang", "id": "2412.15151v1", "paper_url": "http://arxiv.org/abs/2412.15151v1", "repo": "null"}}