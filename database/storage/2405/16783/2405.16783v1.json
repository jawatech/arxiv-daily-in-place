{"2405.16783": {"publish_time": "2024-05-27", "title": "TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models", "paper_summary": "One key challenge in backdoor attacks against large foundation models is the\nresource limits. Backdoor attacks usually require retraining the target model,\nwhich is impractical for very large foundation models. Existing backdoor\nattacks are mainly designed for supervised classifiers or small foundation\nmodels (e.g., BERT). None of these attacks has successfully compromised a very\nlarge foundation model, such as Llama-3-70B, especially with limited\ncomputational resources. In this paper, we propose TrojFM, a novel backdoor\nattack tailored for very large foundation models. Our primary technical\ncontribution is the development of a novel backdoor injection method. This\nmethod forces a backdoored model to generate similar hidden representations for\npoisoned inputs regardless of their actual semantics. Our approach injects such\nbackdoors by fine-tuning only a very small proportion of model parameters. This\nenables TrojFM to efficiently launch downstream task-agnostic backdoor attacks\nagainst very large foundation models under limited computational resources.\nMoreover, we optimize the fine-tuning process with our customized QLoRA\ntechnique, enabling launching our attack via only~\\textit{one A100 GPU}.\nFurthermore, we design a new trigger injection method to ensure our attack\nstealthiness. Through extensive experiments, we first demonstrate that TrojFM\ncan launch effective backdoor attacks against widely used large GPT-style\nmodels without jeopardizing their normal functionalities (and outperforming\nexisting attacks on BERT-style models). Furthermore, we show that TrojFM is\nresilient to SOTA defenses and is insensitive to changes in key\nhyper-parameters. Finally, we conduct a resource analysis to quantify that our\nmethod can significantly save computational and memory costs compared to\nexisting backdoor attacks.", "paper_summary_zh": "<paragraph>\u91dd\u5c0d\u5927\u578b\u57fa\u790e\u6a21\u578b\u7684\u5f8c\u9580\u653b\u64ca\u4e2d\uff0c\u4e00\u500b\u4e3b\u8981\u7684\u6311\u6230\u5728\u65bc\u8cc7\u6e90\u9650\u5236\u3002\u5f8c\u9580\u653b\u64ca\u901a\u5e38\u9700\u8981\u91cd\u65b0\u8a13\u7df4\u76ee\u6a19\u6a21\u578b\uff0c\u800c\u9019\u5c0d\u65bc\u975e\u5e38\u5927\u578b\u7684\u57fa\u790e\u6a21\u578b\u4f86\u8aaa\u662f\u4e0d\u5207\u5be6\u969b\u7684\u3002\u73fe\u6709\u7684\u5f8c\u9580\u653b\u64ca\u4e3b\u8981\u8a2d\u8a08\u7528\u65bc\u76e3\u7763\u5206\u985e\u5668\u6216\u5c0f\u578b\u57fa\u790e\u6a21\u578b\uff08\u4f8b\u5982 BERT\uff09\u3002\u9019\u4e9b\u653b\u64ca\u90fd\u6c92\u6709\u6210\u529f\u5165\u4fb5\u904e\u975e\u5e38\u5927\u578b\u7684\u57fa\u790e\u6a21\u578b\uff0c\u4f8b\u5982 Llama-3-70B\uff0c\u7279\u5225\u662f\u5728\u8a08\u7b97\u8cc7\u6e90\u6709\u9650\u7684\u60c5\u6cc1\u4e0b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 TrojFM\uff0c\u4e00\u7a2e\u91dd\u5c0d\u975e\u5e38\u5927\u578b\u57fa\u790e\u6a21\u578b\u91cf\u8eab\u6253\u9020\u7684\u65b0\u578b\u5f8c\u9580\u653b\u64ca\u3002\u6211\u5011\u7684\u4e3b\u8981\u6280\u8853\u8ca2\u737b\u662f\u958b\u767c\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5f8c\u9580\u6ce8\u5165\u65b9\u6cd5\u3002\u9019\u7a2e\u65b9\u6cd5\u8feb\u4f7f\u5f8c\u9580\u6a21\u578b\u70ba\u4e2d\u6bd2\u8f38\u5165\u751f\u6210\u76f8\u4f3c\u7684\u96b1\u85cf\u8868\u793a\uff0c\u800c\u4e0d\u7ba1\u5b83\u5011\u7684\u5be6\u969b\u8a9e\u7fa9\u5982\u4f55\u3002\u6211\u5011\u7684\u505a\u6cd5\u662f\u901a\u904e\u5fae\u8abf\u6a21\u578b\u53c3\u6578\u4e2d\u975e\u5e38\u5c0f\u7684\u4e00\u90e8\u5206\u4f86\u6ce8\u5165\u9019\u6a23\u7684\u5f8c\u9580\u3002\u9019\u4f7f\u5f97 TrojFM \u80fd\u5920\u5728\u6709\u9650\u7684\u8a08\u7b97\u8cc7\u6e90\u4e0b\uff0c\u6709\u6548\u5730\u5c0d\u975e\u5e38\u5927\u578b\u7684\u57fa\u790e\u6a21\u578b\u767c\u8d77\u8207\u4e0b\u6e38\u4efb\u52d9\u7121\u95dc\u7684\u5f8c\u9580\u653b\u64ca\u3002\u6b64\u5916\uff0c\u6211\u5011\u4f7f\u7528\u81ea\u5b9a\u7fa9\u7684 QLoRA \u6280\u8853\u512a\u5316\u4e86\u5fae\u8abf\u904e\u7a0b\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u50c5\u901a\u904e~\\textit{\u4e00\u500b A100 GPU}\u4f86\u767c\u8d77\u653b\u64ca\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u7a2e\u65b0\u7684\u89f8\u767c\u6ce8\u5165\u65b9\u6cd5\u4f86\u78ba\u4fdd\u6211\u5011\u7684\u653b\u64ca\u5177\u5099\u96b1\u853d\u6027\u3002\u901a\u904e\u5927\u91cf\u7684\u5be6\u9a57\uff0c\u6211\u5011\u9996\u5148\u8b49\u660e\u4e86 TrojFM \u80fd\u5920\u5c0d\u5ee3\u6cdb\u4f7f\u7528\u7684 GPT \u98a8\u683c\u7684\u5927\u578b\u6a21\u578b\u767c\u8d77\u6709\u6548\u7684\u5f8c\u9580\u653b\u64ca\uff0c\u800c\u4e0d\u6703\u640d\u5bb3\u5b83\u5011\u7684\u6b63\u5e38\u529f\u80fd\uff08\u4e26\u4e14\u512a\u65bc\u5c0d BERT \u98a8\u683c\u6a21\u578b\u7684\u73fe\u6709\u653b\u64ca\uff09\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e TrojFM \u5c0d SOTA \u9632\u79a6\u5177\u6709\u5f48\u6027\uff0c\u4e26\u4e14\u5c0d\u95dc\u9375\u8d85\u53c3\u6578\u7684\u8b8a\u5316\u4e0d\u654f\u611f\u3002\u6700\u5f8c\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u8cc7\u6e90\u5206\u6790\uff0c\u4ee5\u91cf\u5316\u8207\u73fe\u6709\u7684\u5f8c\u9580\u653b\u64ca\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u53ef\u4ee5\u986f\u8457\u7bc0\u7701\u8a08\u7b97\u548c\u8a18\u61b6\u9ad4\u6210\u672c\u3002</paragraph>", "author": "Yuzhou. Nie et.al.", "authors": "Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Michael J. De Lucia, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song", "id": "2405.16783v1", "paper_url": "http://arxiv.org/abs/2405.16783v1", "repo": "null"}}