
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-16**|**Does Refusal Training in LLMs Generalize to the Past Tense?**|Maksym Andriushchenko et.al.|[2407.11969v1](http://arxiv.org/abs/2407.11969v1)|[link](https://github.com/tml-epfl/llm-past-tense)|
|**2024-07-16**|**Efficient Training with Denoised Neural Weights**|Yifan Gong et.al.|[2407.11966v1](http://arxiv.org/abs/2407.11966v1)|null|
|**2024-07-16**|**NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**|Mo Li et.al.|[2407.11963v1](http://arxiv.org/abs/2407.11963v1)|[link](https://github.com/open-compass/opencompass)|
|**2024-07-16**|**Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**|Jaehyeok Kim et.al.|[2407.11962v1](http://arxiv.org/abs/2407.11962v1)|null|
|**2024-07-16**|**Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation**|Congbo Ma et.al.|[2407.11948v1](http://arxiv.org/abs/2407.11948v1)|null|
|**2024-07-16**|**Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering**|Rachneet Sachdeva et.al.|[2407.11930v1](http://arxiv.org/abs/2407.11930v1)|[link](https://github.com/ukplab/arxiv2024-lfqa-hallucination)|
|**2024-07-16**|**Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach**|Tanvir Hossain et.al.|[2407.11928v1](http://arxiv.org/abs/2407.11928v1)|null|
|**2024-07-16**|**What's Wrong? Refining Meeting Summaries with LLM Feedback**|Frederic Kirstein et.al.|[2407.11919v1](http://arxiv.org/abs/2407.11919v1)|null|
|**2024-07-16**|**Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task**|Bosong Ding et.al.|[2407.11915v1](http://arxiv.org/abs/2407.11915v1)|[link](https://github.com/dingdingding60/humanoids2024hri)|
|**2024-07-16**|**Bridging Weighted First Order Model Counting and Graph Polynomials**|Qipeng Kuang et.al.|[2407.11877v1](http://arxiv.org/abs/2407.11877v1)|[link](https://github.com/l2l7l9p/polynomials-for-wfomc)|
|**2024-07-16**|**Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction**|Tiziano Labruna et.al.|[2407.11857v1](http://arxiv.org/abs/2407.11857v1)|null|
|**2024-07-16**|**Scaling Sign Language Translation**|Biao Zhang et.al.|[2407.11855v1](http://arxiv.org/abs/2407.11855v1)|null|
|**2024-07-16**|**Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection**|Gaetan Lopez Latouche et.al.|[2407.11854v1](http://arxiv.org/abs/2407.11854v1)|null|
|**2024-07-16**|**Schema Matching with Large Language Models: an Experimental Study**|Marcel Parciak et.al.|[2407.11852v1](http://arxiv.org/abs/2407.11852v1)|[link](https://github.com/uhasselt-dsi-data-systems-lab/code-schema-matching-llms-artefacs)|
|**2024-07-16**|**Variational Randomized Smoothing for Sample-Wise Adversarial Robustness**|Ryo Hase et.al.|[2407.11844v1](http://arxiv.org/abs/2407.11844v1)|null|
|**2024-07-16**|**InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback**|Haishuo Fang et.al.|[2407.11843v1](http://arxiv.org/abs/2407.11843v1)|null|
|**2024-07-16**|**LoFTI: Localization and Factuality Transfer to Indian Locales**|Sona Elza Simon et.al.|[2407.11833v1](http://arxiv.org/abs/2407.11833v1)|[link](https://github.com/csalt-research/lofti)|
|**2024-07-16**|**Personalized Conversational Travel Assistant powered by Generative AI**|Alexio Cassani et.al.|[2407.11830v1](http://arxiv.org/abs/2407.11830v1)|null|
|**2024-07-16**|**GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**|Kyle Hamilton et.al.|[2407.11827v1](http://arxiv.org/abs/2407.11827v1)|null|
|**2024-07-16**|**The Future of Data Science Education**|Brian Wright et.al.|[2407.11824v1](http://arxiv.org/abs/2407.11824v1)|null|
|**2024-07-16**|**Invariant Consistency for Knowledge Distillation**|Nikolaos Giakoumoglou et.al.|[2407.11802v1](http://arxiv.org/abs/2407.11802v1)|null|
|**2024-07-16**|**PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation**|Branden Butler et.al.|[2407.11798v1](http://arxiv.org/abs/2407.11798v1)|null|
|**2024-07-16**|**Characterizing and Understanding HGNN Training on GPUs**|Dengke Han et.al.|[2407.11790v1](http://arxiv.org/abs/2407.11790v1)|null|
|**2024-07-16**|**Large Language Models as Misleading Assistants in Conversation**|Betty Li Hou et.al.|[2407.11789v1](http://arxiv.org/abs/2407.11789v1)|null|
|**2024-07-16**|**Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development**|Daoyuan Chen et.al.|[2407.11784v1](http://arxiv.org/abs/2407.11784v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-07-16**|**SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models**|Xinbo Wu et.al.|[2407.11780v1](http://arxiv.org/abs/2407.11780v1)|null|
|**2024-07-16**|**Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text**|Seyedeh Fatemeh Ebrahimi et.al.|[2407.11774v1](http://arxiv.org/abs/2407.11774v1)|null|
|**2024-07-16**|**Educational Personalized Learning Path Planning with Large Language Models**|Chee Ng et.al.|[2407.11773v1](http://arxiv.org/abs/2407.11773v1)|null|
|**2024-07-16**|**XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach**|Truong Thanh Hung Nguyen et.al.|[2407.11771v1](http://arxiv.org/abs/2407.11771v1)|null|
|**2024-07-16**|**Robust Utility-Preserving Text Anonymization Based on Large Language Models**|Tianyu Yang et.al.|[2407.11770v1](http://arxiv.org/abs/2407.11770v1)|[link](https://github.com/ukplab/arxiv2024-rupta)|
|**2024-07-16**|**Vectoring Languages**|Joseph Chen et.al.|[2407.11766v1](http://arxiv.org/abs/2407.11766v1)|null|
|**2024-07-16**|**A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection**|Pandiyaraju V et.al.|[2407.11753v1](http://arxiv.org/abs/2407.11753v1)|null|
|**2024-07-16**|**Universal Sound Separation with Self-Supervised Audio Masked Autoencoder**|Junqi Zhao et.al.|[2407.11745v1](http://arxiv.org/abs/2407.11745v1)|null|
|**2024-07-16**|**How Are LLMs Mitigating Stereotyping Harms? Learning from Search Engine Studies**|Alina Leidinger et.al.|[2407.11733v1](http://arxiv.org/abs/2407.11733v1)|null|
|**2024-07-16**|**NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks**|Alberto Pirillo et.al.|[2407.11698v1](http://arxiv.org/abs/2407.11698v1)|null|
|**2024-07-16**|**CCoE: A Compact LLM with Collaboration of Experts**|Shaomang Huang et.al.|[2407.11686v2](http://arxiv.org/abs/2407.11686v2)|null|
|**2024-07-16**|**MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models**|Hongrong Cheng et.al.|[2407.11681v1](http://arxiv.org/abs/2407.11681v1)|null|
|**2024-07-16**|**SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation**|Yanis Lalou et.al.|[2407.11676v1](http://arxiv.org/abs/2407.11676v1)|[link](https://github.com/scikit-adaptation/skada-bench)|
|**2024-07-16**|**ECoh: Turn-level Coherence Evaluation for Multilingual Dialogues**|John Mendonça et.al.|[2407.11660v1](http://arxiv.org/abs/2407.11660v1)|null|
|**2024-07-16**|**R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models**|Aladin Djuhera et.al.|[2407.11654v1](http://arxiv.org/abs/2407.11654v1)|null|
|**2024-07-16**|**CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**|Sunny Gupta et.al.|[2407.11652v1](http://arxiv.org/abs/2407.11652v1)|null|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Rethinking Fair Graph Neural Networks from Re-balancing**|Zhixun Li et.al.|[2407.11624v1](http://arxiv.org/abs/2407.11624v1)|[link](https://github.com/zhixunlee/fairgb)|
|**2024-07-16**|**Graph Dimension Attention Networks for Enterprise Credit Assessment**|Shaopeng Wei et.al.|[2407.11615v1](http://arxiv.org/abs/2407.11615v1)|null|
|**2024-07-16**|**Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project**|David Moats et.al.|[2407.11613v1](http://arxiv.org/abs/2407.11613v1)|null|
|**2024-07-16**|**Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift**|Navid Hashemi et.al.|[2407.11609v1](http://arxiv.org/abs/2407.11609v1)|null|
|**2024-07-16**|**The Foundations of Tokenization: Statistical and Computational Concerns**|Juan Luis Gastaldi et.al.|[2407.11606v1](http://arxiv.org/abs/2407.11606v1)|null|
|**2024-07-16**|**Enhancing TinyML Security: Study of Adversarial Attack Transferability**|Parin Shah et.al.|[2407.11599v1](http://arxiv.org/abs/2407.11599v1)|null|
|**2024-07-16**|**DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**|Guillermo Jimenez-Perez et.al.|[2407.11594v1](http://arxiv.org/abs/2407.11594v1)|null|
|**2024-07-16**|**AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization**|Anum Afzal et.al.|[2407.11591v1](http://arxiv.org/abs/2407.11591v1)|null|
|**2024-07-16**|**QVD: Post-training Quantization for Video Diffusion Models**|Shilong Tian et.al.|[2407.11585v2](http://arxiv.org/abs/2407.11585v2)|null|
|**2024-07-16**|**Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**|Naif Alkhunaizi et.al.|[2407.11573v1](http://arxiv.org/abs/2407.11573v1)|null|
|**2024-07-16**|**TGIF: Text-Guided Inpainting Forgery Dataset**|Hannes Mareen et.al.|[2407.11566v1](http://arxiv.org/abs/2407.11566v1)|[link](https://github.com/idlabmedia/tgif-dataset)|
|**2024-07-16**|**Self-Guided Generation of Minority Samples Using Diffusion Models**|Soobin Um et.al.|[2407.11555v1](http://arxiv.org/abs/2407.11555v1)|[link](https://github.com/soobin-um/sg-minority)|
|**2024-07-16**|**Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction**|Zihan Tang et.al.|[2407.11553v1](http://arxiv.org/abs/2407.11553v1)|null|
|**2024-07-16**|**Optimizing KV Cache Eviction in LLMs: Adaptive Allocation for Enhanced Budget Utilization**|Yuan Feng et.al.|[2407.11550v1](http://arxiv.org/abs/2407.11550v1)|null|
|**2024-07-16**|**How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models**|Yin Jou Huang et.al.|[2407.11549v1](http://arxiv.org/abs/2407.11549v1)|null|
|**2024-07-16**|**AEMIM: Adversarial Examples Meet Masked Image Modeling**|Wenzhao Xiang et.al.|[2407.11537v1](http://arxiv.org/abs/2407.11537v1)|null|
|**2024-07-16**|**Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**|Qimin Yang et.al.|[2407.11536v1](http://arxiv.org/abs/2407.11536v1)|null|
|**2024-07-16**|**LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices**|Jung Hyun Lee et.al.|[2407.11534v1](http://arxiv.org/abs/2407.11534v1)|[link](https://github.com/onliwad101/flexround_lrq)|
|**2024-07-16**|**Reasoning with Large Language Models, a Survey**|Aske Plaat et.al.|[2407.11511v1](http://arxiv.org/abs/2407.11511v1)|null|
|**2024-07-16**|**Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era**|Lei Ren et.al.|[2407.11501v1](http://arxiv.org/abs/2407.11501v1)|null|
|**2024-07-16**|**An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data**|Niamh Belton et.al.|[2407.11500v1](http://arxiv.org/abs/2407.11500v1)|[link](https://github.com/niamhbelton/ss-fewsome_disease_severity_knee_osteoarthritis)|
|**2024-07-16**|**MMSD-Net: Towards Multi-modal Stuttering Detection**|Liangyu Nie et.al.|[2407.11492v1](http://arxiv.org/abs/2407.11492v1)|null|
|**2024-07-16**|**A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments**|Junlin Lu et.al.|[2407.11489v1](http://arxiv.org/abs/2407.11489v1)|null|
|**2024-07-16**|**Scientific QA System with Verifiable Answers**|Adela Ljajić et.al.|[2407.11485v1](http://arxiv.org/abs/2407.11485v1)|null|
|**2024-07-16**|**The Oscars of AI Theater: A Survey on Role-Playing with Language Models**|Nuo Chen et.al.|[2407.11484v2](http://arxiv.org/abs/2407.11484v2)|[link](https://github.com/nuochenpku/awesome-role-play-papers)|
|**2024-07-16**|**Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**|Jiarong Chen et.al.|[2407.11481v1](http://arxiv.org/abs/2407.11481v1)|[link](https://github.com/chenjiar3/mcma)|
|**2024-07-16**|**AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models**|Lei Ren et.al.|[2407.11480v1](http://arxiv.org/abs/2407.11480v1)|null|
|**2024-07-16**|**XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More**|Xiaochuan Gou et.al.|[2407.11477v1](http://arxiv.org/abs/2407.11477v1)|null|
|**2024-07-16**|**DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems**|Kaibo He et.al.|[2407.11472v1](http://arxiv.org/abs/2407.11472v1)|null|
|**2024-07-16**|**Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models**|Jiasheng Zheng et.al.|[2407.11470v1](http://arxiv.org/abs/2407.11470v1)|[link](https://github.com/jszheng21/race)|
|**2024-07-16**|**Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis**|Zhipeng He et.al.|[2407.11463v1](http://arxiv.org/abs/2407.11463v1)|[link](https://github.com/zhipenghe/imperceptibility-of-tabular-adversarial-attack)|
|**2024-07-16**|**Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights**|Shunqi Mao et.al.|[2407.11449v1](http://arxiv.org/abs/2407.11449v1)|null|
|**2024-07-16**|**EARN Fairness: Explaining, Asking, Reviewing and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders**|Lin Luo et.al.|[2407.11442v1](http://arxiv.org/abs/2407.11442v1)|null|
|**2024-07-16**|**Repurformer: Transformers for Repurposing-Aware Molecule Generation**|Changhun Lee et.al.|[2407.11439v1](http://arxiv.org/abs/2407.11439v1)|null|
|**2024-07-16**|**Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild**|Niloofar Mireshghallah et.al.|[2407.11438v1](http://arxiv.org/abs/2407.11438v1)|null|
|**2024-07-16**|**Generally-Occurring Model Change for Robust Counterfactual Explanations**|Ao Xu et.al.|[2407.11426v1](http://arxiv.org/abs/2407.11426v1)|null|
|**2024-07-16**|**States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly**|Junhao Chen et.al.|[2407.11421v1](http://arxiv.org/abs/2407.11421v1)|null|
|**2024-07-16**|**LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data**|Liana Patel et.al.|[2407.11418v1](http://arxiv.org/abs/2407.11418v1)|[link](https://github.com/stanford-futuredata/lotus)|
|**2024-07-16**|**SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions**|Shicheng Liu et.al.|[2407.11417v1](http://arxiv.org/abs/2407.11417v1)|null|
|**2024-07-16**|**Representation Bias in Political Sample Simulations with Large Language Models**|Weihong Qi et.al.|[2407.11409v1](http://arxiv.org/abs/2407.11409v1)|null|
|**2024-07-16**|**Revisiting the Impact of Pursuing Modularity for Code Generation**|Deokyeong Kang et.al.|[2407.11406v1](http://arxiv.org/abs/2407.11406v1)|null|
|**2024-07-16**|**DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation**|Jiwook Kim et.al.|[2407.11394v1](http://arxiv.org/abs/2407.11394v1)|[link](https://github.com/kaist-cvml-lab/DreamCatalyst)|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v1](http://arxiv.org/abs/2407.11393v1)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-16**|**InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains**|Yinzhu Quan et.al.|[2407.11384v1](http://arxiv.org/abs/2407.11384v1)|null|
|**2024-07-16**|**Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts**|Jianhao Li et.al.|[2407.11382v2](http://arxiv.org/abs/2407.11382v2)|null|
|**2024-07-16**|**Reliable Reasoning Beyond Natural Language**|Nasim Borazjanizadeh et.al.|[2407.11373v1](http://arxiv.org/abs/2407.11373v1)|null|
|**2024-07-16**|**Estimating Agreement by Chance for Sequence Annotation**|Diya Li et.al.|[2407.11371v1](http://arxiv.org/abs/2407.11371v1)|null|
|**2024-07-16**|**A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora**|Kentaro Onda et.al.|[2407.11370v1](http://arxiv.org/abs/2407.11370v1)|null|
|**2024-07-16**|**Ancient Korean Archive Translation: Comparison Analysis on Statistical phrase alignment, LLM in-context learning, and inter-methodological approach**|Sojung Lucia Kim et.al.|[2407.11368v1](http://arxiv.org/abs/2407.11368v1)|null|
|**2024-07-16**|**Feature Inference Attack on Shapley Values**|Xinjian Luo et.al.|[2407.11359v1](http://arxiv.org/abs/2407.11359v1)|null|
|**2024-07-16**|**Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models**|Matthew Perez et.al.|[2407.11345v1](http://arxiv.org/abs/2407.11345v1)|null|
|**2024-07-16**|**COMET: "Cone of experience" enhanced large multimodal model for mathematical problem generation**|Sannyuya Liu et.al.|[2407.11315v1](http://arxiv.org/abs/2407.11315v1)|null|
|**2024-07-16**|**Large Vision-Language Models as Emotion Recognizers in Context Awareness**|Yuxuan Lei et.al.|[2407.11300v1](http://arxiv.org/abs/2407.11300v1)|null|
|**2024-07-16**|**Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems**|Yaşar Utku Alçalar et.al.|[2407.11288v1](http://arxiv.org/abs/2407.11288v1)|null|
|**2024-07-15**|**CLAMS: A System for Zero-Shot Model Selection for Clustering**|Prabhant Singh et.al.|[2407.11286v1](http://arxiv.org/abs/2407.11286v1)|null|
|**2024-07-15**|**Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models**|Qingcheng Zeng et.al.|[2407.11282v2](http://arxiv.org/abs/2407.11282v2)|[link](https://github.com/qcznlp/uncertainty_attack)|
|**2024-07-15**|**Quality Scalable Quantization Methodology for Deep Learning on Edge**|Salman Abdul Khaliq et.al.|[2407.11260v1](http://arxiv.org/abs/2407.11260v1)|null|
|**2024-07-15**|**Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation**|Chung Park et.al.|[2407.11245v1](http://arxiv.org/abs/2407.11245v1)|[link](https://github.com/cpark88/syncrec)|

#### Abstracts
##### **Does Refusal Training in LLMs Generalize to the Past Tense?**
2407.11969v1 by Maksym Andriushchenko, Nicolas Flammarion

Refusal training is widely used to prevent LLMs from generating harmful,
undesirable, or illegal outputs. We reveal a curious generalization gap in the
current refusal training approaches: simply reformulating a harmful request in
the past tense (e.g., "How to make a Molotov cocktail?" to "How did people make
a Molotov cocktail?") is often sufficient to jailbreak many state-of-the-art
LLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo,
Gemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a
reformulation model. For example, the success rate of this simple attack on
GPT-4o increases from 1% using direct requests to 88% using 20 past tense
reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a
jailbreak judge. Interestingly, we also find that reformulations in the future
tense are less effective, suggesting that refusal guardrails tend to consider
past historical questions more benign than hypothetical future questions.
Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending
against past reformulations is feasible when past tense examples are explicitly
included in the fine-tuning data. Overall, our findings highlight that the
widely used alignment techniques -- such as SFT, RLHF, and adversarial training
-- employed to align the studied models can be brittle and do not always
generalize as intended. We provide code and jailbreak artifacts at
https://github.com/tml-epfl/llm-past-tense.

摘要：拒絕訓練被廣泛用於防止 LLM 產生有害、不受歡迎或非法的輸出。我們揭示了當前拒絕訓練方法中一個奇怪的概括差距：僅僅用過去式重新表述一個有害的請求（例如，「如何製作莫洛托夫雞尾酒？」改為「人們是如何製作莫洛托夫雞尾酒的？」）通常足以讓許多最先進的 LLM 越獄。我們使用 GPT-3.5 Turbo 作為重新表述模型，系統性地評估了這種方法在 Llama-3 8B、GPT-3.5 Turbo、Gemma-2 9B、Phi-3-Mini、GPT-4o 和 R2D2 模型上的效果。例如，這種簡單攻擊在 GPT-4o 上的成功率從使用直接請求時的 1% 增加到使用 20 次過去式重新表述嘗試對來自 JailbreakBench 的有害請求時為 88%，而 GPT-4 則作為越獄評判。有趣的是，我們還發現，未來時態的重新表述效果較差，這表明拒絕防護措施傾向於將過去的歷史問題視為比假設的未來問題更良性。此外，我們對微調 GPT-3.5 Turbo 的實驗表明，在微調數據中明確包含過去時態的示例時，可以防禦過去的重新表述。總的來說，我們的發現強調了廣泛使用的對齊技術——例如 SFT、RLHF 和對抗訓練——用於對齊所研究的模型可能是脆弱的，並且並不總是按預期的那樣概括。我們在 https://github.com/tml-epfl/llm-past-tense 提供代碼和越獄工件。

##### **Efficient Training with Denoised Neural Weights**
2407.11966v1 by Yifan Gong, Zheng Zhan, Yanyu Li, Yerlan Idelbayev, Andrey Zharkov, Kfir Aberman, Sergey Tulyakov, Yanzhi Wang, Jian Ren

Good weight initialization serves as an effective measure to reduce the
training cost of a deep neural network (DNN) model. The choice of how to
initialize parameters is challenging and may require manual tuning, which can
be time-consuming and prone to human error. To overcome such limitations, this
work takes a novel step towards building a weight generator to synthesize the
neural weights for initialization. We use the image-to-image translation task
with generative adversarial networks (GANs) as an example due to the ease of
collecting model weights spanning a wide range. Specifically, we first collect
a dataset with various image editing concepts and their corresponding trained
weights, which are later used for the training of the weight generator. To
address the different characteristics among layers and the substantial number
of weights to be predicted, we divide the weights into equal-sized blocks and
assign each block an index. Subsequently, a diffusion model is trained with
such a dataset using both text conditions of the concept and the block indexes.
By initializing the image translation model with the denoised weights predicted
by our diffusion model, the training requires only 43.3 seconds. Compared to
training from scratch (i.e., Pix2pix), we achieve a 15x training time
acceleration for a new concept while obtaining even better image generation
quality.

摘要：良好的權重初始化是減少深度神經網路 (DNN) 模型訓練成本的有效措施。如何初始化參數的選擇具有挑戰性，且可能需要手動調整，這可能會花費大量時間且容易出錯。為了克服這些限制，這項工作採取了一個創新的步驟，朝著建立一個權重生成器來合成初始化的神經權重邁進。我們以使用生成對抗網路 (GAN) 的影像轉影像轉換任務為例，因為收集涵蓋廣泛範圍的模型權重很簡單。具體來說，我們首先收集一個包含各種影像編輯概念及其對應訓練權重的資料集，這些權重稍後用於訓練權重生成器。為了應對層之間的不同特性和大量的待預測權重，我們將權重分成大小相等的區塊，並為每個區塊指定一個索引。隨後，使用包含概念文字條件和區塊索引的資料集，訓練一個擴散模型。透過使用我們的擴散模型預測的去噪權重初始化影像轉換模型，訓練僅需 43.3 秒。與從頭開始訓練 (即 Pix2pix) 相比，我們為一個新概念實現了 15 倍的訓練時間加速，同時獲得更好的影像生成品質。

##### **NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**
2407.11963v1 by Mo Li, Songyang Zhang, Yunxin Liu, Kai Chen

In evaluating the long-context capabilities of large language models (LLMs),
identifying content relevant to a user's query from original long documents is
a crucial prerequisite for any LLM to answer questions based on long text. We
present NeedleBench, a framework consisting of a series of progressively more
challenging tasks for assessing bilingual long-context capabilities, spanning
multiple length intervals (4k, 8k, 32k, 128k, 200k, 1000k, and beyond) and
different depth ranges, allowing the strategic insertion of critical data
points in different text depth zones to rigorously test the retrieval and
reasoning capabilities of models in diverse contexts. We use the NeedleBench
framework to assess how well the leading open-source models can identify key
information relevant to the question and apply that information to reasoning in
bilingual long texts. Furthermore, we propose the Ancestral Trace Challenge
(ATC) to mimic the complexity of logical reasoning challenges that are likely
to be present in real-world long-context tasks, providing a simple method for
evaluating LLMs in dealing with complex long-context situations. Our results
suggest that current LLMs have significant room for improvement in practical
long-context applications, as they struggle with the complexity of logical
reasoning challenges that are likely to be present in real-world long-context
tasks. All codes and resources are available at OpenCompass:
https://github.com/open-compass/opencompass.

摘要：<paragraph>在評估大型語言模型 (LLM) 的長語境能力時，從原始長篇文件中辨識與使用者查詢相關的內容是任何 LLM 根據長文回答問題的必要先決條件。我們提出 NeedleBench，一個由一系列難度逐漸增加的任務組成的架構，用於評估雙語長語境能力，涵蓋多個長度區間（4k、8k、32k、128k、200k、1000k，以及更多）和不同的深度範圍，允許在不同的文字深度區域策略性地插入關鍵資料點，以嚴格測試模型在不同語境中的檢索和推理能力。我們使用 NeedleBench 架構來評估領先的開源模型在辨識與問題相關的關鍵資訊，以及將該資訊應用於雙語長文中推理的能力。此外，我們提出祖先追蹤挑戰 (ATC)，模擬在現實世界長語境任務中可能存在的邏輯推理挑戰的複雜性，提供一個簡單的方法來評估 LLM 在處理複雜長語境情況時的表現。我們的結果表明，目前的 LLM 在實際長語境應用中仍有很大的改進空間，因為它們難以應付現實世界長語境任務中可能存在的邏輯推理挑戰的複雜性。所有程式碼和資源都可以在 OpenCompass 取得：https://github.com/open-compass/opencompass。</paragraph>

##### **Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**
2407.11962v1 by Jaehyeok Kim, Dongyoon Wee, Dan Xu

This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.

摘要：<paragraph>本文介绍了面向运动的合成神经辐射场 (MoCo-NeRF)，这是一个旨在通过新颖的非刚性运动建模方法执行单眼人类视频的自由视点渲染的框架。在动态着装的人类的背景下，复杂的布料动态会产生非刚性运动，这些运动本质上不同于骨骼关节，并且对渲染质量至关重要。传统方法将非刚性运动建模为空间 (3D) 偏差以及骨骼变换。然而，由于其学习复杂度高且没有直接监督，因此要达到最佳质量既耗时又具有挑战性。为了解决这个问题，我们提出了一种新颖的方法，将非刚性运动建模为辐射残差场，以受益于渲染中更直接的颜色监督，并将刚性辐射场用作先验来降低学习过程的复杂性。我们的方法利用单一的多分辨率哈希编码 (MHE) 来同时从刚性骨骼运动中学习规范的 T 姿势表示，以及用于非刚性运动的辐射残差场。此外，为了进一步提高训练效率和可用性，我们扩展了 MoCo-NeRF 以支持在单个框架内同时训练多个主体，这要归功于我们用于建模非刚性运动的有效设计。除了多个局部 MHE 之外，这种可扩展性是通过集成全局 MHE 和可学习的身份代码实现的。我们在 ZJU-MoCap 和 MonoCap 上展示了广泛的结果，清楚地展示了在单主体和多主体设置中都达到最先进的性能。代码和模型将在项目页面公开：https://stevejaehyeok.github.io/publications/moco-nerf。</paragraph>

##### **Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation**
2407.11948v1 by Congbo Ma, Wei Emma Zhang, Dileepa Pitawela, Haojie Zhuang, Yanfeng Shu

The utilization of Transformer-based models prospers the growth of
multi-document summarization (MDS). Given the huge impact and widespread
adoption of Transformer-based models in various natural language processing
tasks, investigating their performance and behaviors in the context of MDS
becomes crucial for advancing the field and enhancing the quality of summary.
To thoroughly examine the behaviours of Transformer-based MDS models, this
paper presents five empirical studies on (1) measuring the impact of document
boundary separators quantitatively; (2) exploring the effectiveness of
different mainstream Transformer structures; (3) examining the sensitivity of
the encoder and decoder; (4) discussing different training strategies; and (5)
discovering the repetition in a summary generation. The experimental results on
prevalent MDS datasets and eleven evaluation metrics show the influence of
document boundary separators, the granularity of different level features and
different model training strategies. The results also reveal that the decoder
exhibits greater sensitivity to noises compared to the encoder. This
underscores the important role played by the decoder, suggesting a potential
direction for future research in MDS. Furthermore, the experimental results
indicate that the repetition problem in the generated summaries has
correlations with the high uncertainty scores.

摘要：<paragraph>基於 Transformer 的模型運用蓬勃發展了多文件摘要 (MDS) 的成長。由於基於 Transformer 的模型在各種自然語言處理任務中具有巨大的影響力和廣泛的採用，因此研究它們在 MDS 背景下的效能和行為對於推動該領域和提升摘要品質至關重要。為了徹底檢驗基於 Transformer 的 MDS 模型的行為，本文針對 (1) 定量測量文件邊界分隔符的影響；(2) 探討不同主流 Transformer 結構的有效性；(3) 檢驗編碼器和解碼器的敏感性；(4) 討論不同的訓練策略；以及 (5) 發現摘要生成中的重複性，提出了五項實證研究。在流行的 MDS 資料集和 11 項評估指標上的實驗結果顯示了文件邊界分隔符、不同層級特徵的粒度和不同模型訓練策略的影響。結果還揭示，與編碼器相比，解碼器對雜訊表現出更大的敏感性。這強調了解碼器所扮演的重要角色，為 MDS 未來的研究指出了潛在的方向。此外，實驗結果表明，生成的摘要中重複出現的問題與高不確定性分數有關。</paragraph>

##### **Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering**
2407.11930v1 by Rachneet Sachdeva, Yixiao Song, Mohit Iyyer, Iryna Gurevych

Long-form question answering (LFQA) aims to provide thorough and in-depth
answers to complex questions, enhancing comprehension. However, such detailed
responses are prone to hallucinations and factual inconsistencies, challenging
their faithful evaluation. This work introduces HaluQuestQA, the first
hallucination dataset with localized error annotations for human-written and
model-generated LFQA answers. HaluQuestQA comprises 698 QA pairs with 4.7k
span-level error annotations for five different error types by expert
annotators, along with preference judgments. Using our collected data, we
thoroughly analyze the shortcomings of long-form answers and find that they
lack comprehensiveness and provide unhelpful references. We train an automatic
feedback model on this dataset that predicts error spans with incomplete
information and provides associated explanations. Finally, we propose a
prompt-based approach, Error-informed refinement, that uses signals from the
learned feedback model to refine generated answers, which we show reduces
hallucination and improves answer quality. Furthermore, humans find answers
generated by our approach comprehensive and highly prefer them (84%) over the
baseline answers.

摘要：長篇問答 (LFQA) 旨在提供對複雜問題的全面深入的答案，以增強理解力。然而，如此詳細的回應容易出現幻覺和事實不符，對其忠實的評估構成挑戰。這項工作引入了 HaluQuestQA，這是第一個具有針對人類撰寫和模型生成的 LFQA 答案的局部錯誤註解的幻覺數據集。HaluQuestQA 包含 698 個 QA 對，其中包含由專家註解者針對五種不同錯誤類型進行的 4.7k 個跨度級別錯誤註解，以及偏好判斷。利用我們收集的數據，我們徹底分析了長篇答案的缺點，發現它們缺乏全面性，並且提供的參考沒有幫助。我們在這個數據集上訓練了一個自動回饋模型，它可以預測具有不完整信息的錯誤跨度，並提供相關解釋。最後，我們提出了一種基於提示的方法，即錯誤知情優化，它使用從學習的回饋模型中獲得的信號來優化生成的答案，我們展示了這減少了幻覺並提高了答案質量。此外，人類發現由我們的方法生成的答案全面，並且非常喜歡它們（84%）而不是基準答案。

##### **Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach**
2407.11928v1 by Tanvir Hossain, Khaled Mohammed Saifuddin, Muhammad Ifte Khairul Islam, Farhan Tanvir, Esra Akbas

Graph Neural Network (GNN) achieves great success for node-level and
graph-level tasks via encoding meaningful topological structures of networks in
various domains, ranging from social to biological networks. However, repeated
aggregation operations lead to excessive mixing of node representations,
particularly in dense regions with multiple GNN layers, resulting in nearly
indistinguishable embeddings. This phenomenon leads to the oversmoothing
problem that hampers downstream graph analytics tasks. To overcome this issue,
we propose a novel and flexible truss-based graph sparsification model that
prunes edges from dense regions of the graph. Pruning redundant edges in dense
regions helps to prevent the aggregation of excessive neighborhood information
during hierarchical message passing and pooling in GNN models. We then utilize
our sparsification model in the state-of-the-art baseline GNNs and pooling
models, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and
AdamGNN. Extensive experiments on different real-world datasets show that our
model significantly improves the performance of the baseline GNN models in the
graph classification task.

摘要：圖形神經網路 (GNN) 透過編碼各種領域中網路的意義拓撲結構，在節點層級和圖形層級任務中取得極佳的成功，從社交網路到生物網路皆有涉獵。然而，重複的聚集運算導致節點表示過度混合，特別是在具有多個 GNN 層的密集區域，導致嵌入式幾乎無法區分。這種現象導致過度平滑問題，阻礙下游圖形分析任務。為了克服這個問題，我們提出一個新穎且靈活的基於桁架的圖形稀疏化模型，可從圖形的密集區域修剪邊緣。修剪密集區域中多餘的邊緣有助於防止在 GNN 模型中進行階層式訊息傳遞和匯總期間過度鄰域資訊的聚集。然後，我們在最先進的基線 GNN 和匯總模型中使用我們的稀疏化模型，例如 GIN、SAGPool、GMT、DiffPool、MinCutPool、HGP-SL、DMonPool 和 AdamGNN。在不同真實世界資料集上進行的大量實驗表明，我們的模型顯著提高了基線 GNN 模型在圖形分類任務中的效能。

##### **What's Wrong? Refining Meeting Summaries with LLM Feedback**
2407.11919v1 by Frederic Kirstein, Terry Ruas, Bela Gipp

Meeting summarization has become a critical task since digital encounters
have become a common practice. Large language models (LLMs) show great
potential in summarization, offering enhanced coherence and context
understanding compared to traditional methods. However, they still struggle to
maintain relevance and avoid hallucination. We introduce a multi-LLM correction
approach for meeting summarization using a two-phase process that mimics the
human review process: mistake identification and summary refinement. We release
QMSum Mistake, a dataset of 200 automatically generated meeting summaries
annotated by humans on nine error types, including structural, omission, and
irrelevance errors. Our experiments show that these errors can be identified
with high accuracy by an LLM. We transform identified mistakes into actionable
feedback to improve the quality of a given summary measured by relevance,
informativeness, conciseness, and coherence. This post-hoc refinement
effectively improves summary quality by leveraging multiple LLMs to validate
output quality. Our multi-LLM approach for meeting summarization shows
potential for similar complex text generation tasks requiring robustness,
action planning, and discussion towards a goal.

摘要：會議摘要已成為一項關鍵任務，因為數位會議已成為一種常見的實務。大型語言模型 (LLM) 在摘要方面展現了極大的潛力，與傳統方法相比，它提供了增強的一致性和脈絡理解。然而，它們仍然難以維持相關性並避免產生幻覺。我們針對會議摘要推出了一種多 LLM 修正方法，該方法使用一個兩階段流程來模擬人類審查流程：錯誤辨識和摘要精煉。我們發布了 QMSum Mistake，這是一個包含 200 個自動產生的會議摘要的資料集，由人類針對九種類型的錯誤進行註解，包括結構、遺漏和不相關的錯誤。我們的實驗顯示，這些錯誤可以由 LLM 以高準確度辨識出來。我們將辨識出的錯誤轉換為可行的回饋，以改善摘要的品質，這些品質由相關性、資訊性、簡潔性和一致性來衡量。這種事後精煉有效地改善了摘要品質，方法是利用多個 LLM 來驗證輸出品質。我們在會議摘要方面採用的多 LLM 方法，顯示了在需要穩健性、行動規劃和朝向目標討論的類似複雜文字生成任務中具有潛力。

##### **Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task**
2407.11915v1 by Bosong Ding, Murat Kirtay, Giacomo Spigler

Head movements are crucial for social human-human interaction. They can
transmit important cues (e.g., joint attention, speaker detection) that cannot
be achieved with verbal interaction alone. This advantage also holds for
human-robot interaction. Even though modeling human motions through generative
AI models has become an active research area within robotics in recent years,
the use of these methods for producing head movements in human-robot
interaction remains underexplored. In this work, we employed a generative AI
pipeline to produce human-like head movements for a Nao humanoid robot. In
addition, we tested the system on a real-time active-speaker tracking task in a
group conversation setting. Overall, the results show that the Nao robot
successfully imitates human head movements in a natural manner while actively
tracking the speakers during the conversation. Code and data from this study
are available at https://github.com/dingdingding60/Humanoids2024HRI

摘要：頭部動作對於人類之間的社交互動至關重要。它們可以傳達重要的線索（例如，共同關注、說話者偵測），而僅靠口語互動無法達成。這種優勢也適用於人機互動。儘管近年來透過生成式 AI 模型模擬人類動作已成為機器人領域中的活躍研究領域，但這些方法用於產生人機互動中的頭部動作仍未充分探討。在這項研究中，我們採用生成式 AI 管線為 Nao 類人機器人產生類似人類的頭部動作。此外，我們在群組對話設定中對一個即時主動說話者追蹤任務測試了這個系統。整體而言，結果顯示 Nao 機器人在對話期間主動追蹤說話者的同時，成功以自然的方式模仿人類的頭部動作。本研究的程式碼和資料可在 https://github.com/dingdingding60/Humanoids2024HRI 取得

##### **Bridging Weighted First Order Model Counting and Graph Polynomials**
2407.11877v1 by Qipeng Kuang, Ondřej Kuželka, Yuanhong Wang, Yuyi Wang

The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the
weighted sum of models of a given first-order logic sentence over a given
domain. It can be solved in time polynomial in the domain size for sentences
from the two-variable fragment with counting quantifiers, known as $C^2$. This
polynomial-time complexity is also retained when extending $C^2$ by one of the
following axioms: linear order axiom, tree axiom, forest axiom, directed
acyclic graph axiom or connectedness axiom. An interesting question remains as
to which other axioms can be added to the first-order sentences in this way. We
provide a new perspective on this problem by associating WFOMC with graph
polynomials. Using WFOMC, we define Weak Connectedness Polynomial and Strong
Connectedness Polynomials for first-order logic sentences. It turns out that
these polynomials have the following interesting properties. First, they can be
computed in polynomial time in the domain size for sentences from $C^2$.
Second, we can use them to solve WFOMC with all of the existing axioms known to
be tractable as well as with new ones such as bipartiteness, strong
connectedness, being a spanning subgraph, having $k$ connected components, etc.
Third, the well-known Tutte polynomial can be recovered as a special case of
the Weak Connectedness Polynomial, and the Strict and Non-Strict Directed
Chromatic Polynomials can be recovered from the Strong Connectedness
Polynomials, which allows us to show that these important graph polynomials can
be computed in time polynomial in the number of vertices for any graph that can
be encoded by a fixed $C^2$ sentence and a conjunction of an arbitrary number
of ground unary literals.

摘要：加權一階模型計算問題 (WFOMC) 要求計算給定一階邏輯句子在給定網域上的模型的加權總和。對於具有計數量詞的二變數片段（稱為 $C^2$）中的句子，可以在多項式時間內解決此問題。當通過以下公理之一來擴充 $C^2$ 時，此多項式時間複雜度也會保留：線性序公理、樹公理、森林公理、有向無環圖公理或連通公理。一個有趣的問題仍然是哪些其他公理可以這樣添加到一階句子中。我們通過將 WFOMC 與圖多項式關聯起來，對這個問題提供了新的觀點。使用 WFOMC，我們定義了一階邏輯句子的弱連通多項式和強連通多項式。結果證明，這些多項式具有以下有趣的性質。首先，它們可以在 $C^2$ 句子中多項式時間內計算網域大小。其次，我們可以使用它們來解決 WFOMC，其中包括所有已知易於處理的公理以及新的公理，例如二分性、強連通性、作為生成子圖、具有 $k$ 個連通組件等。第三，眾所周知的 Tutte 多項式可以作為弱連通多項式的特例恢復，而嚴格和非嚴格有向色多項式可以從強連通多項式中恢復，這讓我們可以證明這些重要的圖多項式可以在多項式時間內計算任何圖的頂點數，該圖可以用固定的 $C^2$ 句子和任意數量的基本一元文字的合取來編碼。

##### **Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction**
2407.11857v1 by Tiziano Labruna, Bernardo Magnini

Task-oriented dialogues must maintain consistency both within the dialogue
itself, ensuring logical coherence across turns, and with the conversational
domain, accurately reflecting external knowledge. We propose to conceptualize
dialogue consistency as a Constraint Satisfaction Problem (CSP), wherein
variables represent segments of the dialogue referencing the conversational
domain, and constraints among variables reflect dialogue properties, including
linguistic, conversational, and domain-based aspects. To demonstrate the
feasibility of the approach, we utilize a CSP solver to detect inconsistencies
in dialogues re-lexicalized by an LLM. Our findings indicate that: (i) CSP is
effective to detect dialogue inconsistencies; and (ii) consistent dialogue
re-lexicalization is challenging for state-of-the-art LLMs, achieving only a
0.15 accuracy rate when compared to a CSP solver. Furthermore, through an
ablation study, we reveal that constraints derived from domain knowledge pose
the greatest difficulty in being respected. We argue that CSP captures core
properties of dialogue consistency that have been poorly considered by
approaches based on component pipelines.

摘要：任務導向對話必須在對話本身中保持一致性，確保輪流的邏輯連貫性，並與對話領域一致，準確反映外部知識。我們建議將對話一致性概念化為約束滿足問題 (CSP)，其中變數代表對話中參考對話領域的區段，而變數之間的約束反映對話屬性，包括語言、對話和基於領域的方面。為了證明這種方法的可行性，我們利用 CSP 求解器來檢測 LLM 重新詞彙化的對話中的不一致性。我們的研究結果表明：(i) CSP 可有效檢測對話不一致性；(ii) 對於最先進的 LLM 來說，一致的對話重新詞彙化具有挑戰性，與 CSP 求解器相比，僅達到 0.15 的準確率。此外，通過消融研究，我們發現源自領域知識的約束最難被遵守。我們認為，CSP 捕捉了對話一致性的核心屬性，而基於組件管線的方法對此考慮不周。

##### **Scaling Sign Language Translation**
2407.11855v1 by Biao Zhang, Garrett Tanzer, Orhan Firat

Sign language translation (SLT) addresses the problem of translating
information from a sign language in video to a spoken language in text.
Existing studies, while showing progress, are often limited to narrow domains
and/or few sign languages and struggle with open-domain tasks. In this paper,
we push forward the frontier of SLT by scaling pretraining data, model size,
and number of translation directions. We perform large-scale SLT pretraining on
different data including 1) noisy multilingual YouTube SLT data, 2) parallel
text corpora, and 3) SLT data augmented by translating video captions to other
languages with off-the-shelf machine translation models. We unify different
pretraining tasks with task-specific prompts under the encoder-decoder
architecture, and initialize the SLT model with pretrained (m/By)T5 models
across model sizes. SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL
to 42 spoken languages) demonstrate the significance of data/model scaling and
cross-lingual cross-modal transfer, as well as the feasibility of zero-shot
SLT. We finetune the pretrained SLT models on 5 downstream open-domain SLT
benchmarks covering 5 sign languages. Experiments show substantial quality
improvements over the vanilla baselines, surpassing the previous
state-of-the-art (SOTA) by wide margins.

摘要：手語翻譯 (SLT) 解決了將影片中的手語資訊翻譯成文字中的口語問題。現有研究雖然顯示進展，但通常僅限於狹窄的領域和/或少數手語，且難以應付開放領域任務。在本文中，我們透過擴充預訓練資料、模型大小和翻譯方向數量，推動 SLT 的前沿。我們對不同資料執行大規模 SLT 預訓練，其中包括 1) 嘈雜的多語言 YouTube SLT 資料、2) 平行文字語料庫，以及 3) 透過使用現成的機器翻譯模型將影片字幕翻譯成其他語言而擴充的 SLT 資料。我們在編碼器-解碼器架構下，使用特定於任務的提示統一不同的預訓練任務，並使用跨模型大小的預訓練 (m/By)T5 模型初始化 SLT 模型。How2Sign 和 FLEURS-ASL#0 (ASL 到 42 種口語) 上的 SLT 預訓練結果證明了資料/模型擴充和跨語言跨模式轉移的重要性，以及零次學習 SLT 的可行性。我們微調預訓練的 SLT 模型，針對涵蓋 5 種手語的 5 個下游開放領域 SLT 評量標準進行微調。實驗顯示，與香草基線相比有顯著的品質提升，大幅超越先前的技術水準 (SOTA)。

##### **Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection**
2407.11854v1 by Gaetan Lopez Latouche, Marc-André Carbonneau, Ben Swanson

Grammatical Error Detection (GED) methods rely heavily on human annotated
error corpora. However, these annotations are unavailable in many low-resource
languages. In this paper, we investigate GED in this context. Leveraging the
zero-shot cross-lingual transfer capabilities of multilingual pre-trained
language models, we train a model using data from a diverse set of languages to
generate synthetic errors in other languages. These synthetic error corpora are
then used to train a GED model. Specifically we propose a two-stage fine-tuning
pipeline where the GED model is first fine-tuned on multilingual synthetic data
from target languages followed by fine-tuning on human-annotated GED corpora
from source languages. This approach outperforms current state-of-the-art
annotation-free GED methods. We also analyse the errors produced by our method
and other strong baselines, finding that our approach produces errors that are
more diverse and more similar to human errors.

摘要：語法錯誤偵測 (GED) 方法極度依賴人工標註的錯誤語料庫。然而，這些標註在許多低資源語言中並不可用。在本文中，我們研究此脈絡中的 GED。利用多語言預訓練語言模型的零次學習跨語言轉移能力，我們使用來自各種語言的資料訓練一個模型，以產生其他語言中的合成錯誤。這些合成錯誤語料庫接著用於訓練 GED 模型。具體來說，我們提出一個兩階段微調管道，其中 GED 模型首先針對目標語言的多語言合成資料進行微調，然後針對來源語言的人工標註 GED 語料庫進行微調。此方法優於目前最先進的無標註 GED 方法。我們也分析我們的模型和其他的強大基準所產生的錯誤，發現我們的模型所產生的錯誤更多元且更類似於人類的錯誤。

##### **Schema Matching with Large Language Models: an Experimental Study**
2407.11852v1 by Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

Large Language Models (LLMs) have shown useful applications in a variety of
tasks, including data wrangling. In this paper, we investigate the use of an
off-the-shelf LLM for schema matching. Our objective is to identify semantic
correspondences between elements of two relational schemas using only names and
descriptions. Using a newly created benchmark from the health domain, we
propose different so-called task scopes. These are methods for prompting the
LLM to do schema matching, which vary in the amount of context information
contained in the prompt. Using these task scopes we compare LLM-based schema
matching against a string similarity baseline, investigating matching quality,
verification effort, decisiveness, and complementarity of the approaches. We
find that matching quality suffers from a lack of context information, but also
from providing too much context information. In general, using newer LLM
versions increases decisiveness. We identify task scopes that have acceptable
verification effort and succeed in identifying a significant number of true
semantic matches. Our study shows that LLMs have potential in bootstrapping the
schema matching process and are able to assist data engineers in speeding up
this task solely based on schema element names and descriptions without the
need for data instances.

摘要：大型語言模型 (LLM) 已在各種任務中展現出有用的應用，包括資料整理。在本文中，我們探討現成 LLM 在架構比對中的用途。我們的目標是僅使用名稱和描述，找出兩個關聯式架構的元素之間的語意對應。使用從健康領域新建立的基準，我們提出不同的所謂任務範圍。這些方法是用於提示 LLM 進行架構比對，其包含在提示中的脈絡資訊量有所不同。使用這些任務範圍，我們將基於 LLM 的架構比對與字串相似性基準進行比較，探討比對品質、驗證工作、果斷性，以及方法的互補性。我們發現比對品質會受到脈絡資訊不足以及提供過多脈絡資訊的影響。一般來說，使用較新的 LLM 版本會增加果斷性。我們找出具有可接受驗證工作，並成功找出大量真實語意比對的任務範圍。我們的研究顯示，LLM 有助於引導架構比對流程，並且能夠協助資料工程師僅根據架構元素名稱和描述加速此任務，而不需要資料實例。

##### **Variational Randomized Smoothing for Sample-Wise Adversarial Robustness**
2407.11844v1 by Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons

Randomized smoothing is a defensive technique to achieve enhanced robustness
against adversarial examples which are small input perturbations that degrade
the performance of neural network models. Conventional randomized smoothing
adds random noise with a fixed noise level for every input sample to smooth out
adversarial perturbations. This paper proposes a new variational framework that
uses a per-sample noise level suitable for each input by introducing a noise
level selector. Our experimental results demonstrate enhancement of empirical
robustness against adversarial attacks. We also provide and analyze the
certified robustness for our sample-wise smoothing method.

摘要：隨機平滑是一種防禦技術，用於增強對抗範例的魯棒性，而對抗範例是對神經網路模型的效能造成損害的小型輸入擾動。傳統隨機平滑會針對每個輸入樣本加入固定雜訊層級的隨機雜訊，以平滑對抗擾動。本文提出一個新的變分架構，透過引入雜訊層級選擇器，使用適合每個輸入的每個樣本雜訊層級。我們的實驗結果證明了對抗攻擊的經驗魯棒性得到增強。我們也提供並分析了我們樣本平滑方法的認證魯棒性。

##### **InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback**
2407.11843v1 by Haishuo Fang, Xiaodan Zhu, Iryna Gurevych

A crucial requirement for deploying LLM-based agents in real-life
applications is robustness against risky or irreversible mistakes. However,
existing research lacks a focus on the preemptive evaluation of reasoning
trajectories performed by LLM agents, leading to a gap in ensuring safe and
reliable operations. To explore better solutions, this paper introduces
InferAct, a novel approach that leverages the Theory-of-Mind capability of LLMs
to proactively detect potential errors before critical actions are executed
(e.g., "buy-now" in automatic online trading or web shopping). InferAct is also
capable of integrating human feedback to prevent irreversible risks and enhance
the actor agent's decision-making process. Experiments on three widely used
tasks demonstrate the effectiveness of InferAct. The proposed solution presents
a novel approach and concrete contributions toward developing LLM agents that
can be safely deployed in different environments involving critical
decision-making.

摘要：部署基於 LLM 的代理至實際應用時，關鍵需求之一是能抵禦風險或不可逆轉的錯誤。然而，現有研究缺乏對 LLM 代理執行推理軌跡的先制評估的重點，導致確保安全和可靠運作存在差距。為了探索更好的解決方案，本文介紹 InferAct，這是一種新穎的方法，它利用 LLM 的心智理論能力在執行關鍵動作之前主動偵測潛在錯誤（例如，自動線上交易或網路購物的「立即購買」）。InferAct 也能整合人類回饋以防止不可逆轉的風險，並增強行為代理的決策過程。在三個廣泛使用的任務上進行的實驗證明了 InferAct 的有效性。所提出的解決方案呈現出一種新穎的方法，並為開發 LLM 代理做出具體貢獻，這些代理能安全地部署在涉及關鍵決策的不同環境中。

##### **LoFTI: Localization and Factuality Transfer to Indian Locales**
2407.11833v1 by Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi

Large language models (LLMs) encode vast amounts of world knowledge acquired
via training on large web-scale datasets crawled from the internet. However,
these datasets typically exhibit a geographical bias towards English-speaking
Western countries. This results in LLMs producing biased or hallucinated
responses to queries that require answers localized to other geographical
regions. In this work, we introduce a new benchmark named LoFTI (Localization
and Factuality Transfer to Indian Locales) that can be used to evaluate an
LLM's localization and factual text transfer capabilities. LoFTI consists of
factual statements about entities in source and target locations; the source
locations are spread across the globe and the target locations are all within
India with varying degrees of hyperlocality (country, states, cities). The
entities span a wide variety of categories. We use LoFTI to evaluate Mixtral,
GPT-4 and two other Mixtral-based approaches well-suited to the task of
localized factual transfer. We demonstrate that LoFTI is a high-quality
evaluation benchmark and all the models, including GPT-4, produce skewed
results across varying levels of hyperlocality.

摘要：大型語言模型 (LLM) 編碼了大量世界知識，這些知識是透過訓練大型網路規模資料集（從網際網路爬取）而獲得的。然而，這些資料集通常會對英語系西方國家表現出地理偏見。這導致 LLM 對需要將答案在地理區域本地化的查詢產生有偏見或虛構的回應。在這項工作中，我們引入了一個名為 LoFTI（本地化和事實傳輸到印度本地）的新基準，可用於評估 LLM 的本地化和事實文本傳輸能力。LoFTI 包含關於來源和目標位置實體的事實陳述；來源位置遍布全球，而目標位置均在印度境內，具有不同程度的超地方性（國家、州、城市）。實體涵蓋了廣泛的類別。我們使用 LoFTI 來評估 Mixtral、GPT-4 和其他兩種非常適合於本地化事實傳輸任務的基於 Mixtral 的方法。我們證明 LoFTI 是個高品質的評估基準，包括 GPT-4 在內的所有模型在不同層級的超地方性中都產生了偏斜的結果。

##### **Personalized Conversational Travel Assistant powered by Generative AI**
2407.11830v1 by Alexio Cassani, Michele Ruberl, Antonio Salis, Giacomo Giannese, Gianluca Boanelli

The Tourism and Destination Management Organization (DMO) industry is rapidly
evolving to adapt to new technologies and traveler expectations. Generative
Artificial Intelligence (AI) offers an astonishing and innovative opportunity
to enhance the tourism experience by providing personalized, interactive and
engaging assistance. In this article, we propose a generative AI-based chatbot
for tourism assistance. The chatbot leverages AI ability to generate realistic
and creative texts, adopting the friendly persona of the well-known Italian
all-knowledgeable aunties, to provide tourists with personalized information,
tailored and dynamic pre, during and post recommendations and trip plans and
personalized itineraries, using both text and voice commands, and supporting
different languages to satisfy Italian and foreign tourists expectations. This
work is under development in the Molise CTE research project, funded by the
Italian Minister of the Economic Growth (MIMIT), with the aim to leverage the
best emerging technologies available, such as Cloud and AI to produce state of
the art solutions in the Smart City environment.

摘要：旅遊和目的地管理組織 (DMO) 產業快速演進，以適應新科技和旅客期望。生成式人工智慧 (AI) 提供驚人的創新機會，透過提供個人化、互動且引人入勝的協助，來提升旅遊體驗。在本文中，我們提出一個用於旅遊協助的生成式 AI 聊天機器人。聊天機器人利用 AI 產生逼真且具創意的文字，採用著名的義大利萬事通阿姨的友善角色，使用文字和語音指令為旅客提供個人化資訊、量身打造且動態的旅遊建議和行程規劃，以及個人化行程，並支援多國語言以滿足義大利和外國旅客的期望。此項工作目前在由義大利經濟成長部 (MIMIT) 資助的 Molise CTE 研究計畫中進行，目標是利用雲端和 AI 等最佳新興科技，在智慧城市環境中產生最先進的解決方案。

##### **GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**
2407.11827v1 by Kyle Hamilton, Luca Longo, Bojan Bozic

While the use of machine learning for the detection of propaganda techniques
in text has garnered considerable attention, most approaches focus on
"black-box" solutions with opaque inner workings. Interpretable approaches
provide a solution, however, they depend on careful feature engineering and
costly expert annotated data. Additionally, language features specific to
propagandistic text are generally the focus of rhetoricians or linguists, and
there is no data set labeled with such features suitable for machine learning.
This study codifies 22 rhetorical and linguistic features identified in
literature related to the language of persuasion for the purpose of annotating
an existing data set labeled with propaganda techniques. To help human experts
annotate natural language sentences with these features, RhetAnn, a web
application, was specifically designed to minimize an otherwise considerable
mental effort. Finally, a small set of annotated data was used to fine-tune
GPT-3.5, a generative large language model (LLM), to annotate the remaining
data while optimizing for financial cost and classification accuracy. This
study demonstrates how combining a small number of human annotated examples
with GPT can be an effective strategy for scaling the annotation process at a
fraction of the cost of traditional annotation relying solely on human experts.
The results are on par with the best performing model at the time of writing,
namely GPT-4, at 10x less the cost. Our contribution is a set of features,
their properties, definitions, and examples in a machine-readable format, along
with the code for RhetAnn and the GPT prompts and fine-tuning procedures for
advancing state-of-the-art interpretable propaganda technique detection.

摘要：<paragraph>儘管使用機器學習來偵測宣傳技巧在文本中已獲得相當的關注，但大多數方法都專注於具有不透明內部運作的「黑盒子」解決方案。可解釋的方法提供了解決方案，然而，它們依賴於仔細的特徵工程和昂貴的專家註釋資料。此外，宣傳性文本的特定語言特徵通常是修辭學家或語言學家的關注焦點，並且沒有標記有此類特徵的資料集適合機器學習。本研究將出現在與說服語言相關的文獻中識別出的 22 個修辭和語言特徵編纂成法典，目的是為標記有宣傳技巧的現有資料集。為了幫助人類專家使用這些特徵註釋自然語言句子，專門設計了網路應用程式 RhetAnn，以最大程度地減少原本相當大的心智負擔。最後，使用一小組註釋資料微調了生成式大型語言模型 (LLM) GPT-3.5，以註釋剩餘資料，同時針對財務成本和分類準確度進行最佳化。本研究展示了將少數人類註釋範例與 GPT 結合如何成為以傳統僅依賴人類專家的註釋成本的一小部分來擴展註釋程序的有效策略。在撰寫本文時，結果與當時表現最佳的模型 GPT-4 相當，成本卻低了 10 倍。我們的貢獻是一組特徵、它們的屬性、定義和範例，採用機器可讀格式，以及 RhetAnn 的程式碼和 GPT 提示和微調程序，用於推進最先進的可解釋宣傳技巧偵測。</paragraph>

##### **The Future of Data Science Education**
2407.11824v1 by Brian Wright, Peter Alonzi, Ali Riveria

The definition of Data Science is a hotly debated topic. For many, the
definition is a simple shortcut to Artificial Intelligence or Machine Learning.
However, there is far more depth and nuance to the field of Data Science than a
simple shortcut can provide. The School of Data Science at the University of
Virginia has developed a novel model for the definition of Data Science. This
model is based on identifying a unified understanding of the data work done
across all areas of Data Science. It represents a generational leap forward in
how we understand and teach Data Science. In this paper we will present the
core features of the model and explain how it unifies various concepts going
far beyond the analytics component of AI. From this foundation we will present
our Undergraduate Major curriculum in Data Science and demonstrate how it
prepares students to be well-rounded Data Science team members and leaders. The
paper will conclude with an in-depth overview of the Foundations of Data
Science course designed to introduce students to the field while also
implementing proven STEM oriented pedagogical methods. These include, for
example, specifications grading, active learning lectures, guest lectures from
industry experts and weekly gamification labs.

摘要：數據科學的定義是一個熱門的爭論話題。對許多人來說，這個定義是通往人工智慧或機器學習的捷徑。然而，數據科學領域的深度和細微差別遠遠超過一個簡單的捷徑所能提供的。維吉尼亞大學的數據科學學院為數據科學的定義開發了一個新模型。這個模型基於對數據科學所有領域所做的數據工作的統一理解。它代表了我們理解和教授數據科學方式的一代飛躍。在本文中，我們將介紹該模型的核心特徵，並解釋它如何統一各種概念，遠遠超出了 AI 的分析組成部分。從這個基礎上，我們將介紹我們的數據科學本科專業課程，並展示它如何讓學生做好準備，成為全面發展的數據科學團隊成員和領導者。本文將以對數據科學基礎課程的深入概述作為結尾，該課程旨在向學生介紹該領域，同時也實施經過驗證的 STEM 導向教學方法。例如，這些方法包括規範評分、主動學習講座、來自行業專家的客座講座和每週的遊戲化實驗室。

##### **Invariant Consistency for Knowledge Distillation**
2407.11802v1 by Nikolaos Giakoumoglou, Tania Stathaki

Knowledge distillation (KD) involves transferring the knowledge from one
neural network to another, often from a larger, well-trained model (teacher) to
a smaller, more efficient model (student). Traditional KD methods minimize the
Kullback-Leibler (KL) divergence between the probabilistic outputs of the
teacher and student networks. However, this approach often overlooks crucial
structural knowledge embedded within the teacher's network. In this paper, we
introduce Invariant Consistency Distillation (ICD), a novel methodology
designed to enhance KD by ensuring that the student model's representations are
consistent with those of the teacher. Our approach combines contrastive
learning with an explicit invariance penalty, capturing significantly more
information from the teacher's representation of the data. Our results on
CIFAR-100 demonstrate that ICD outperforms traditional KD techniques and
surpasses 13 state-of-the-art methods. In some cases, the student model even
exceeds the teacher model in terms of accuracy. Furthermore, we successfully
transfer our method to other datasets, including Tiny ImageNet and STL-10. The
code will be made public soon.

摘要：知識蒸餾 (KD) 涉及將知識從一個神經網路轉移到另一個神經網路，通常從一個較大、訓練良好的模型（教師）轉移到一個較小、更有效率的模型（學生）。傳統的 KD 方法將教師和學生網路的機率輸出之間的 Kullback-Leibler (KL) 差異最小化。然而，這種方法通常忽略了教師網路中嵌入的關鍵結構知識。在本文中，我們引入了不變一致性蒸餾 (ICD)，這是一種新穎的方法，旨在透過確保學生模型的表徵與教師的表徵一致來增強 KD。我們的做法結合了對比學習與明確的不變罰則，從教師對資料的表徵中擷取更多資訊。我們在 CIFAR-100 上的結果證明，ICD 優於傳統的 KD 技術，並超越了 13 種最先進的方法。在某些情況下，學生模型甚至在準確度方面超過了教師模型。此外，我們成功地將我們的模型轉移到其他資料集，包括 Tiny ImageNet 和 STL-10。程式碼將很快公開。

##### **PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation**
2407.11798v1 by Branden Butler, Sixing Yu, Arya Mazaheri, Ali Jannesari

Inference of Large Language Models (LLMs) across computer clusters has become
a focal point of research in recent times, with many acceleration techniques
taking inspiration from CPU speculative execution. These techniques reduce
bottlenecks associated with memory bandwidth, but also increase end-to-end
latency per inference run, requiring high speculation acceptance rates to
improve performance. Combined with a variable rate of acceptance across tasks,
speculative inference techniques can result in reduced performance.
Additionally, pipeline-parallel designs require many user requests to maintain
maximum utilization. As a remedy, we propose PipeInfer, a pipelined speculative
acceleration technique to reduce inter-token latency and improve system
utilization for single-request scenarios while also improving tolerance to low
speculation acceptance rates and low-bandwidth interconnects. PipeInfer
exhibits up to a 2.15$\times$ improvement in generation speed over standard
speculative inference. PipeInfer achieves its improvement through Continuous
Asynchronous Speculation and Early Inference Cancellation, the former improving
latency and generation speed by running single-token inference simultaneously
with several speculative runs, while the latter improves speed and latency by
skipping the computation of invalidated runs, even in the middle of inference.

摘要：近來，大型語言模型 (LLM) 在電腦叢集中的推論已成為研究的重點，許多加速技術從 CPU 推測執行中汲取靈感。這些技術減少了與記憶體頻寬相關的瓶頸，但也增加了每個推論運行的端到端延遲，需要很高的推測接受率才能提升效能。結合跨任務的可變接受率，推測推論技術可能會導致效能下降。此外，管線平行設計需要許多使用者要求才能維持最大的使用率。作為補救措施，我們提出 PipeInfer，一種管線推測加速技術，用於減少代幣間延遲並改善單一要求場景的系統使用率，同時也提高對低推測接受率和低頻寬互連的容忍度。與標準推測推論相比，PipeInfer 在產生速度上展現出高達 2.15 倍的進步。PipeInfer 透過連續非同步推測和早期推論取消來達成進步，前者透過同時執行單一代幣推論和多個推測運行來改善延遲和產生速度，而後者透過略過無效運行的計算（即使是在推論過程中）來改善速度和延遲。

##### **Characterizing and Understanding HGNN Training on GPUs**
2407.11790v1 by Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Ninghui Sun

Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.

摘要：由於異質圖神經網路 (HGNN) 具有卓越的異質圖形數據表示能力，因此已廣泛應用於許多重要的真實世界領域，例如推薦系統和醫療分析。在實際應用之前，通過廣泛的訓練來識別針對特定任務調整的最佳 HGNN 模型參數是一個耗時且昂貴的過程。為了提高 HGNN 訓練的效率，必須描述和分析訓練過程中的執行語義和模式，以識別效能瓶頸。在本研究中，我們對兩個主流的 HGNN 訓練場景（包括單 GPU 和多 GPU 分散式訓練）進行深入的量化和分析。根據描述結果，我們揭示了不同 HGNN 訓練場景中的效能瓶頸及其根本原因，並從軟體和硬體的角度提供了最佳化指南。

##### **Large Language Models as Misleading Assistants in Conversation**
2407.11789v1 by Betty Li Hou, Kejian Shi, Jason Phang, James Aung, Steven Adler, Rosie Campbell

Large Language Models (LLMs) are able to provide assistance on a wide range
of information-seeking tasks. However, model outputs may be misleading, whether
unintentionally or in cases of intentional deception. We investigate the
ability of LLMs to be deceptive in the context of providing assistance on a
reading comprehension task, using LLMs as proxies for human users. We compare
outcomes of (1) when the model is prompted to provide truthful assistance, (2)
when it is prompted to be subtly misleading, and (3) when it is prompted to
argue for an incorrect answer. Our experiments show that GPT-4 can effectively
mislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up
to a 23% drop in accuracy on the task compared to when a truthful assistant is
used. We also find that providing the user model with additional context from
the passage partially mitigates the influence of the deceptive model. This work
highlights the ability of LLMs to produce misleading information and the
effects this may have in real-world situations.

摘要：大型語言模型 (LLM) 能夠在各種資訊搜尋任務中提供協助。然而，模型的輸出可能具有誤導性，無論是無意的或是有意欺騙。我們調查了 LLM 在閱讀理解任務中提供協助時具有欺騙性的能力，使用 LLM 作為人類使用者的代理。我們比較了 (1) 當模型被提示提供真實協助、(2) 當它被提示進行微妙的誤導、以及 (3) 當它被提示為錯誤答案辯護的結果。我們的實驗表明，GPT-4 可以有效地誤導 GPT-3.5-Turbo 和 GPT-4，與使用真實助理相比，具有欺騙性的助理導致任務準確度下降多達 23%。我們還發現，為使用者模型提供來自段落的額外背景，可以部分減輕欺騙性模型的影響。這項工作突顯了 LLM 產生誤導性資訊的能力，以及這可能在現實世界中產生的影響。

##### **Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development**
2407.11784v1 by Daoyuan Chen, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou

The emergence of large-scale multi-modal generative models has drastically
advanced artificial intelligence, introducing unprecedented levels of
performance and functionality. However, optimizing these models remains
challenging due to historically isolated paths of model-centric and
data-centric developments, leading to suboptimal outcomes and inefficient
resource utilization. In response, we present a novel sandbox suite tailored
for integrated data-model co-development. This sandbox provides a comprehensive
experimental platform, enabling rapid iteration and insight-driven refinement
of both data and models. Our proposed "Probe-Analyze-Refine" workflow,
validated through applications on state-of-the-art LLaVA-like and DiT based
models, yields significant performance boosts, such as topping the VBench
leaderboard. We also uncover fruitful insights gleaned from exhaustive
benchmarks, shedding light on the critical interplay between data quality,
diversity, and model behavior. With the hope of fostering deeper understanding
and future progress in multi-modal data and generative modeling, our codes,
datasets, and models are maintained and accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md.

摘要：隨著大規模多模態生成模型的出現，大幅提升了人工智慧，並導入了前所未有的效能和功能層級。然而，由於模型中心和資料中心發展路徑長期以來各自獨立，導致次佳結果和資源利用率低落，因此最佳化這些模型仍然具有挑戰性。為了解決這個問題，我們提出一個針對整合資料模型共同開發量身打造的新沙盒套件。這個沙盒提供了一個全面的實驗平台，能快速反覆運算，並根據深入洞察改進資料和模型。我們提出的「探測分析精進」工作流程，已通過應用於最先進的 LLaVA 類似模型和基於 DiT 的模型獲得驗證，可大幅提升效能，例如登上 VBench 排行榜首位。我們也從詳盡的基準測試中發現有用的深入洞察，闡明了資料品質、多樣性和模型行為之間的關鍵交互作用。為了促進對多模態資料和生成模型的更深入理解和未來進展，我們的程式碼、資料集和模型均已維護並可於 https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md 取得。

##### **SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models**
2407.11780v1 by Xinbo Wu, Max Hartman, Vidhata Arjun Jayaraman, Lav R. Varshney

Large language models (LLMs) have exhibited impressive capabilities in
various domains, particularly in general language understanding. However these
models, trained on massive text data, may not be finely optimized for specific
tasks triggered by instructions. Continual instruction tuning is crucial to
adapt LLMs to evolving tasks and domains, ensuring their effectiveness and
relevance across a wide range of applications. In the context of continual
instruction tuning, where models are sequentially trained on different tasks,
catastrophic forgetting can occur, leading to performance degradation on
previously learned tasks. This work addresses the catastrophic forgetting in
continual instruction learning for LLMs through a switching mechanism for
routing computations to parameter-efficient tuned models. We demonstrate the
effectiveness of our method through experiments on continual instruction tuning
of different natural language generation tasks.

摘要：大型語言模型 (LLM) 在各種領域中展示了令人印象深刻的能力，特別是在一般語言理解方面。然而，這些在大量文字資料上訓練的模型可能無法針對由指令觸發的特定任務進行精細最佳化。持續的指令調整對於讓 LLM 適應不斷變化的任務和領域至關重要，確保它們在廣泛的應用中都能發揮效用和相關性。在持續指令調整的背景下，模型會依序在不同的任務上進行訓練，此時可能會發生災難性遺忘，導致先前學習的任務效能下降。這項工作透過切換機制來解決 LLM 持續指令學習中的災難性遺忘，將運算路由到參數效率最佳化的調整模型。我們透過針對不同自然語言產生任務的持續指令調整進行實驗，來證明我們的方法有效。

##### **Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text**
2407.11774v1 by Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani, Arian Qazvini, Pouya Sadeghi, Zeinab Sadat Taghavi, Hossein Sameti

Detecting Machine-Generated Text (MGT) has emerged as a significant area of
study within Natural Language Processing. While language models generate text,
they often leave discernible traces, which can be scrutinized using either
traditional feature-based methods or more advanced neural language models. In
this research, we explore the effectiveness of fine-tuning a RoBERTa-base
transformer, a powerful neural architecture, to address MGT detection as a
binary classification task. Focusing specifically on Subtask A
(Monolingual-English) within the SemEval-2024 competition framework, our
proposed system achieves an accuracy of 78.9% on the test dataset, positioning
us at 57th among participants. Our study addresses this challenge while
considering the limited hardware resources, resulting in a system that excels
at identifying human-written texts but encounters challenges in accurately
discerning MGTs.

摘要：機器產生的文字（MGT）偵測已成為自然語言處理中一個重要的研究領域。雖然語言模型會產生文字，但它們通常會留下可辨識的痕跡，可以使用傳統的基於特徵的方法或更先進的神經語言模型來檢視這些痕跡。在這項研究中，我們探討了微調 RoBERTa-base 轉換器（一種強大的神經架構）來處理 MGT 偵測作為二元分類任務的有效性。特別專注於 SemEval-2024 競賽架構中的子任務 A（單語英語），我們提出的系統在測試資料集上達到了 78.9% 的準確度，在參與者中排名第 57 位。我們的研究在考慮有限硬體資源的同時應對了這一挑戰，從而產生了一個在識別人類撰寫的文字方面表現出色，但在準確辨別 MGT 方面遇到挑戰的系統。

##### **Educational Personalized Learning Path Planning with Large Language Models**
2407.11773v1 by Chee Ng, Yuen Fung

Educational Personalized Learning Path Planning (PLPP) aims to tailor
learning experiences to individual learners' needs, enhancing learning
efficiency and engagement. Despite its potential, traditional PLPP systems
often lack adaptability, interactivity, and transparency. This paper proposes a
novel approach integrating Large Language Models (LLMs) with prompt engineering
to address these challenges. By designing prompts that incorporate
learner-specific information, our method guides LLMs like LLama-2-70B and GPT-4
to generate personalized, coherent, and pedagogically sound learning paths. We
conducted experiments comparing our method with a baseline approach across
various metrics, including accuracy, user satisfaction, and the quality of
learning paths. The results show significant improvements in all areas,
particularly with GPT-4, demonstrating the effectiveness of prompt engineering
in enhancing PLPP. Additional long-term impact analysis further validates our
method's potential to improve learner performance and retention. This research
highlights the promise of LLMs and prompt engineering in advancing personalized
education.

摘要：教育個人化學習路徑規劃 (PLPP) 旨在根據個別學習者的需求量身打造學習體驗，提升學習效率和參與度。儘管 PLPP 系統具有潛力，但傳統的 PLPP 系統通常缺乏適應性、互動性和透明度。本文提出了一種創新的方法，將大型語言模型 (LLM) 與提示工程相結合，以應對這些挑戰。通過設計包含學習者特定資訊的提示，我們的模型引導 LLM（例如 LLama-2-70B 和 GPT-4）生成個性化、連貫且具有教學意義的學習路徑。我們進行了實驗，在準確度、使用者滿意度和學習路徑品質等各種指標上，比較了我們的方法與基線方法。結果顯示在所有領域都有顯著的進步，特別是 GPT-4，這證明了提示工程在增強 PLPP 中的有效性。進一步的長期影響分析進一步驗證了我們的方法在改善學習者表現和保留方面的潛力。本研究強調了 LLM 和提示工程在促進個人化教育方面的潛力。

##### **XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach**
2407.11771v1 by Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Hung Cao

Recent advancements in deep learning have significantly improved visual
quality inspection and predictive maintenance within industrial settings.
However, deploying these technologies on low-resource edge devices poses
substantial challenges due to their high computational demands and the inherent
complexity of Explainable AI (XAI) methods. This paper addresses these
challenges by introducing a novel XAI-integrated Visual Quality Inspection
framework that optimizes the deployment of semantic segmentation models on
low-resource edge devices. Our framework incorporates XAI and the Large Vision
Language Model to deliver human-centered interpretability through visual and
textual explanations to end-users. This is crucial for end-user trust and model
interpretability. We outline a comprehensive methodology consisting of six
fundamental modules: base model fine-tuning, XAI-based explanation generation,
evaluation of XAI approaches, XAI-guided data augmentation, development of an
edge-compatible model, and the generation of understandable visual and textual
explanations. Through XAI-guided data augmentation, the enhanced model
incorporating domain expert knowledge with visual and textual explanations is
successfully deployed on mobile devices to support end-users in real-world
scenarios. Experimental results showcase the effectiveness of the proposed
framework, with the mobile model achieving competitive accuracy while
significantly reducing model size. This approach paves the way for the broader
adoption of reliable and interpretable AI tools in critical industrial
applications, where decisions must be both rapid and justifiable.

摘要：深度學習的最新進展顯著改善了工業環境中的視覺品質檢測和預測性維護。
然而，由於高計算需求和可解釋 AI (XAI) 方法的固有複雜性，在低資源邊緣裝置上部署這些技術會帶來相當大的挑戰。本文透過引入一個新穎的 XAI 整合視覺品質檢測架構來解決這些挑戰，該架構最佳化了語意分割模型在低資源邊緣裝置上的部署。我們的架構整合了 XAI 和大型視覺語言模型，透過視覺和文字說明提供以人為中心的詮釋，讓最終使用者理解。這對於最終使用者的信任和模型詮釋至關重要。我們概述了一個全面的方法論，包含六個基本模組：基礎模型微調、基於 XAI 的說明產生、XAI 方法評估、XAI 引導資料擴充、邊緣相容模型開發，以及產生可理解的視覺和文字說明。透過 XAI 引導的資料擴充，結合領域專家知識以及視覺和文字說明的增強模型已成功部署在行動裝置上，以支援最終使用者在真實世界的場景中。實驗結果展示了所提出架構的有效性，行動模型在顯著減少模型大小的同時，達到了競爭力的準確度。此方法為在關鍵工業應用中更廣泛採用可靠且可解釋的 AI 工具鋪路，在這些應用中，決策必須快速且合理。

##### **Robust Utility-Preserving Text Anonymization Based on Large Language Models**
2407.11770v1 by Tianyu Yang, Xiaodan Zhu, Iryna Gurevych

Text anonymization is crucial for sharing sensitive data while maintaining
privacy. Existing techniques face the emerging challenges of re-identification
attack ability of Large Language Models (LLMs), which have shown advanced
capability in memorizing detailed information and patterns as well as
connecting disparate pieces of information. In defending against LLM-based
re-identification attacks, anonymization could jeopardize the utility of the
resulting anonymized data in downstream tasks -- the trade-off between privacy
and data utility requires deeper understanding within the context of LLMs. This
paper proposes a framework composed of three LLM-based components -- a privacy
evaluator, a utility evaluator, and an optimization component, which work
collaboratively to perform anonymization. To provide a practical model for
large-scale and real-time environments, we distill the anonymization
capabilities into a lightweight model using Direct Preference Optimization
(DPO). Extensive experiments demonstrate that the proposed models outperform
baseline models, showing robustness in reducing the risk of re-identification
while preserving greater data utility in downstream tasks. Our code and dataset
are available at https://github.com/UKPLab/arxiv2024-rupta.

摘要：文字匿名化對於在維護隱私的同時共享敏感資料至關重要。現有技術面臨著大型語言模型 (LLM) 重新識別攻擊能力的新挑戰，LLM 在記憶詳細資訊和模式以及連接不同資訊方面展現了進階功能。在防禦基於 LLM 的重新識別攻擊時，匿名化可能會危害匿名化資料在下游任務中的效用 —— 隱私和資料效用之間的權衡需要在 LLM 的背景下深入理解。本文提出了一個由三個基於 LLM 的組成部分組成的框架 —— 一個隱私評估器、一個效用評估器和一個最佳化組成部分，它們協同工作以執行匿名化。為了為大規模和實時環境提供一個實用的模型，我們使用直接偏好最佳化 (DPO) 將匿名化功能提煉成一個輕量級模型。大量的實驗表明，所提出的模型優於基準模型，在降低重新識別風險的同時，展現出在保留下游任務中更大資料效用方面的穩健性。我們的程式碼和資料集可在 https://github.com/UKPLab/arxiv2024-rupta 取得。

##### **Vectoring Languages**
2407.11766v1 by Joseph Chen

Recent breakthroughs in large language models (LLM) have stirred up global
attention, and the research has been accelerating non-stop since then.
Philosophers and psychologists have also been researching the structure of
language for decades, but they are having a hard time finding a theory that
directly benefits from the breakthroughs of LLMs. In this article, we propose a
novel structure of language that reflects well on the mechanisms behind
language models and go on to show that this structure is also better at
capturing the diverse nature of language compared to previous methods. An
analogy of linear algebra is adapted to strengthen the basis of this
perspective. We further argue about the difference between this perspective and
the design philosophy for current language models. Lastly, we discuss how this
perspective can lead us to research directions that may accelerate the
improvements of science fastest.

摘要：近期大型語言模型 (LLM) 的突破性進展引起了全球關注，而相關的研究也自此持續加速。
哲學家和心理學家數十年來也一直在研究語言結構，但他們很難找到一種理論，能直接從 LLM 的突破中受益。在本文中，我們提出了一種新穎的語言結構，可以很好地反映語言模型背後的機制，並進一步表明，與先前的語言模型相比，這種結構更能捕捉語言的多樣性。線性代數的類比被用來強化這種觀點的基礎。我們進一步論述了這種觀點與當前語言模型的設計理念之間的差異。最後，我們討論了這種觀點如何引領我們進行研究，以最快速度促進科學的進步。

##### **A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection**
2407.11753v1 by Pandiyaraju V, Shravan Venkatraman, Abeshek A, Pavan Kumar S, Aravintakshan S A, Senthil Kumar A M, Kannan A

Farmers face various challenges when it comes to identifying diseases in rice
leaves during their early stages of growth, which is a major reason for poor
produce. Therefore, early and accurate disease identification is important in
agriculture to avoid crop loss and improve cultivation. In this research, we
propose a novel hybrid deep learning (DL) classifier designed by extending the
Squeeze-and-Excitation network architecture with a channel attention mechanism
and the Swish ReLU activation function. The channel attention mechanism in our
proposed model identifies the most important feature channels required for
classification during feature extraction and selection. The dying ReLU problem
is mitigated by utilizing the Swish ReLU activation function, and the
Squeeze-andExcitation blocks improve information propagation and cross-channel
interaction. Upon evaluation, our model achieved a high F1-score of 99.76% and
an accuracy of 99.74%, surpassing the performance of existing models. These
outcomes demonstrate the potential of state-of-the-art DL techniques in
agriculture, contributing to the advancement of more efficient and reliable
disease detection systems.

摘要：在水稻生長初期，農民在辨識稻葉疾病時面臨各種挑戰，這是造成產量不佳的主要原因。因此，在農業中及早準確地辨識疾病對於避免作物損失和改善耕作至關重要。在本研究中，我們提出了一種新穎的混合深度學習 (DL) 分類器，其設計方式為擴充 Squeeze-and-Excitation 網路架構，並搭配通道注意力機制和 Swish ReLU 啟用函數。我們提出的模型中的通道注意力機制會在特徵萃取和選擇期間找出分類所需最重要的特徵通道。透過使用 Swish ReLU 啟用函數，可以減輕 ReLU 問題，而 Squeeze-and-Excitation 區塊則可以改善資訊傳遞和跨通道互動。在評估時，我們的模型達到了 99.76% 的高 F1 分數和 99.74% 的準確率，超越了現有模型的效能。這些結果證明了最先進的 DL 技術在農業中的潛力，有助於推動更有效率且可靠的疾病偵測系統。

##### **Universal Sound Separation with Self-Supervised Audio Masked Autoencoder**
2407.11745v1 by Junqi Zhao, Xubo Liu, Jinzheng Zhao, Yi Yuan, Qiuqiang Kong, Mark D. Plumbley, Wenwu Wang

Universal sound separation (USS) is a task of separating mixtures of
arbitrary sound sources. Typically, universal separation models are trained
from scratch in a supervised manner, using labeled data. Self-supervised
learning (SSL) is an emerging deep learning approach that leverages unlabeled
data to obtain task-agnostic representations, which can benefit many downstream
tasks. In this paper, we propose integrating a self-supervised pre-trained
model, namely the audio masked autoencoder (A-MAE), into a universal sound
separation system to enhance its separation performance. We employ two
strategies to utilize SSL embeddings: freezing or updating the parameters of
A-MAE during fine-tuning. The SSL embeddings are concatenated with the
short-time Fourier transform (STFT) to serve as input features for the
separation model. We evaluate our methods on the AudioSet dataset, and the
experimental results indicate that the proposed methods successfully enhance
the separation performance of a state-of-the-art ResUNet-based USS model.

摘要：通用聲音分離 (USS) 是一項將任意音源的混合物分開的任務。通常，通用分離模型會使用標籤資料以監督的方式從頭開始訓練。自監督學習 (SSL) 是一種新興的深度學習方法，它利用未標籤的資料來取得與任務無關的表示，這可以讓許多下游任務受益。在本文中，我們建議將自監督預訓練模型（即音訊遮罩自動編碼器 (A-MAE)）整合到通用聲音分離系統中，以增強其分離效能。我們採用兩種策略來利用 SSL 嵌入：在微調過程中凍結或更新 A-MAE 的參數。SSL 嵌入與短時距傅立葉轉換 (STFT) 連接，作為分離模型的輸入特徵。我們在 AudioSet 資料集上評估我們的模型，實驗結果表明，所提出的方法成功地增強了最先進的基於 ResUNet 的 USS 模型的分離效能。

##### **How Are LLMs Mitigating Stereotyping Harms? Learning from Search Engine Studies**
2407.11733v1 by Alina Leidinger, Richard Rogers

With the widespread availability of LLMs since the release of ChatGPT and
increased public scrutiny, commercial model development appears to have focused
their efforts on 'safety' training concerning legal liabilities at the expense
of social impact evaluation. This mimics a similar trend which we could observe
for search engine autocompletion some years prior. We draw on scholarship from
NLP and search engine auditing and present a novel evaluation task in the style
of autocompletion prompts to assess stereotyping in LLMs. We assess LLMs by
using four metrics, namely refusal rates, toxicity, sentiment and regard, with
and without safety system prompts. Our findings indicate an improvement to
stereotyping outputs with the system prompt, but overall a lack of attention by
LLMs under study to certain harms classified as toxic, particularly for prompts
about peoples/ethnicities and sexual orientation. Mentions of intersectional
identities trigger a disproportionate amount of stereotyping. Finally, we
discuss the implications of these findings about stereotyping harms in light of
the coming intermingling of LLMs and search and the choice of stereotyping
mitigation policy to adopt. We address model builders, academics, NLP
practitioners and policy makers, calling for accountability and awareness
concerning stereotyping harms, be it for training data curation, leader board
design and usage, or social impact measurement.

摘要：隨著 ChatGPT 發布後 LLM 廣泛可用以及公眾的審查增加，商業模型開發似乎將其重點放在「安全」訓練上，以應對法律責任，而犧牲了社會影響評估。這模仿了我們幾年前在搜尋引擎自動完成中觀察到的類似趨勢。我們利用 NLP 和搜尋引擎稽核的學術研究，並提出以自動完成提示的風格進行的新穎評估任務，以評估 LLM 中的刻板印象。我們使用四個指標（拒絕率、毒性、情緒和重視）評估 LLM，並使用和不使用安全系統提示。我們的研究結果表明，系統提示改進了刻板印象輸出，但總體而言，研究中的 LLM 對於某些被歸類為有毒的傷害缺乏關注，特別是關於人/種族和性取向的提示。交叉身分的提及會引發不成比例的刻板印象。最後，我們根據 LLM 和搜尋即將交織以及選擇要採用的刻板印象緩解政策，討論這些關於刻板印象傷害的發現的影響。我們呼籲模型建構者、學者、NLP 從業者和政策制定者，對刻板印象傷害負責並提高認識，無論是針對訓練資料策展、排行榜設計和使用，還是社會影響衡量。

##### **NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks**
2407.11698v1 by Alberto Pirillo, Luca Colombo, Manuel Roveri

Quantization has become increasingly pivotal in addressing the steadily
increasing computational and memory requirements of Deep Neural Networks
(DNNs). By reducing the number of bits used to represent weights and
activations (typically from 32-bit floating-point to 16-bit or 8-bit integers),
quantization reduces the memory footprint, energy consumption, and execution
time of DNN models. However, traditional quantization methods typically focus
on the inference of DNNs, while the training process still relies on
floating-point operations. To date, only one work in the literature has
addressed integer-only training for Multi-Layer Perceptron (MLP) architectures.
This work introduces NITRO-D, a new framework for training arbitrarily deep
integer-only Convolutional Neural Networks (CNNs) that operate entirely< in the
integer-only domain for both training and inference. NITRO-D is the first
framework in the literature enabling the training of integer-only CNNs without
the need to introduce a quantization scheme. Specifically, NITRO-D introduces a
novel architecture integrating multiple integer local-loss blocks, which
include the proposed NITRO Scaling Layer and the NITRO-ReLU activation
function. Additionally, it introduces a novel integer-only learning algorithm
derived from Local Error Signals (LES), utilizing IntegerSGD, an optimizer
specifically designed to operate in an integer-only context. NITRO-D is
implemented in an open-source Python library. Extensive experimental
evaluations demonstrate its effectiveness across several state-of-the-art image
recognition datasets. Results show significant performance improvements from
2.47% to 5.96% for integer-only MLP architectures over the state-of-the-art
solution, and the capability of training integer-only CNN architectures with
minimal accuracy degradation from -0.15% to -4.22% compared to floating-point
LES.

摘要：<paragraph>量化在解决深度神经网络 (DNN) 不断增加的计算和存储需求方面变得愈发关键。通过减少用于表示权重和激活的位数（通常从 32 位浮点数减少到 16 位或 8 位整数），量化可以减少 DNN 模型的存储空间、能耗和执行时间。但是，传统的量化方法通常专注于 DNN 的推理，而训练过程仍然依赖于浮点运算。迄今为止，文献中只有一项工作解决了多层感知器 (MLP) 架构的仅整数训练。这项工作介绍了 NITRO-D，这是一个用于训练任意深度仅整数卷积神经网络 (CNN) 的新框架，该框架在训练和推理中完全在仅整数域中运行。NITRO-D 是文献中第一个能够在不引入量化方案的情况下训练仅整数 CNN 的框架。具体来说，NITRO-D 引入了一种新颖的架构，集成了多个整数局部损失块，其中包括提出的 NITRO 缩放层和 NITRO-ReLU 激活函数。此外，它还引入了一种新颖的仅整数学习算法，该算法源自局部误差信号 (LES)，并利用 IntegerSGD（一种专门设计为在仅整数上下文中运行的优化器）。NITRO-D 在一个开源 Python 库中实现。广泛的实验评估证明了它在几个最先进的图像识别数据集上的有效性。结果显示，仅整数 MLP 架构的性能从 2.47% 到 5.96% 明显提高，超过了最先进的解决方案，并且能够训练仅整数 CNN 架构，与浮点 LES 相比，精度下降幅度从 -0.15% 到 -4.22%。</paragraph>

##### **CCoE: A Compact LLM with Collaboration of Experts**
2407.11686v2 by Shaomang Huang, Jianfeng Pan, Hanzhong Zheng

In the domain of Large Language Model (LLM), LLMs demonstrate significant
capabilities in natural language understanding and generation. With the growing
needs of applying LLMs on various domains, it is a research question that how
to efficiently train and build a model that has expertise in different domains
but with a low training cost. We propose CCoE architecture, a framework of
easily coupling multiple strong domain experts together to fuse into a big LLM,
provides a collective way of utilizing the different domain expert LLMs.
Besides, training a large collaborative of multiple expert LLMs requires a high
requirements on training sources. CCoE bypasses this problem through isolating
other experts and train each expert separately. The design of CCoE assembles
multiple expert LLMs through the CoE (Collaboration of Experts) layer. Each CoE
layer could have one or more expert LLMs. Expert LLMs have different number of
layers and have been well-trained for different domain tasks. Each expert is
fine-tuned to be able to achieve the comparable results with SOTA domain LLMs.
We start from 5 experts in the domain of Code, Math, Law, text-to-SQL and
Medical. The results indicate that our CCoE framework can easily and
efficiently boost nearly 10%-20% performance on original base model in
different domains but using less resources on training, as well as inference.

摘要：在大語言模型 (LLM) 領域中，LLM 在自然語言理解和生成方面展現出顯著的能力。隨著在各個領域應用 LLM 的需求日益增加，如何有效訓練和建立一個在不同領域中具備專業知識，但訓練成本卻很低的模型，成為一個研究課題。我們提出 CCoE 架構，一個將多個強大的領域專家輕鬆結合在一起以融合成一個大型 LLM 的框架，提供一種共同利用不同領域專家 LLM 的方式。此外，訓練多個專家 LLM 的大型協作需要對訓練來源有很高的要求。CCoE 通過隔離其他專家並分別訓練每個專家來繞過這個問題。CCoE 的設計通過 CoE（專家協作）層組合多個專家 LLM。每個 CoE 層可以有一個或多個專家 LLM。專家 LLM 具有不同的層數，並且已經針對不同的領域任務進行了很好的訓練。每個專家都經過微調，能夠達到與 SOTA 領域 LLM 相當的結果。我們從程式碼、數學、法律、文字轉 SQL 和醫學領域的 5 位專家開始。結果表明，我們的 CCoE 框架可以輕鬆、有效地提升不同領域中原始基礎模型近 10%-20% 的效能，但訓練和推理使用的資源更少。

##### **MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models**
2407.11681v1 by Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi

As Large Language Models (LLMs) grow dramatically in size, there is an
increasing trend in compressing and speeding up these models. Previous studies
have highlighted the usefulness of gradients for importance scoring in neural
network compressing, especially in pruning medium-size networks. However, the
substantial memory requirements involved in calculating gradients with
backpropagation impede the utilization of gradients in guiding LLM pruning. As
a result, most pruning strategies for LLMs rely on gradient-free criteria, such
as weight magnitudes or a mix of magnitudes and activations. In this paper, we
devise a hybrid pruning criterion, which appropriately integrates magnitude,
activation, and gradient to capitalize on feature map sensitivity for pruning
LLMs. To overcome memory requirement barriers, we estimate gradients using only
forward passes. Based on this, we propose a Memory-effIcieNt structured prunIng
procedure for LLMs (MINI-LLM) to remove no-critical channels and
multi-attention heads. Experimental results demonstrate the superior
performance of MINI-LLM over existing gradient-free methods on three LLMs:
LLaMA, BLOOM, and OPT across various downstream tasks (classification,
multiple-choice, and generation), while MINI-LLM maintains a GPU memory
footprint akin to gradient-free methods.

摘要：随着大语言模型 (LLM) 规模的急剧增长，压缩和加速这些模型的趋势也在不断增加。先前的研究强调了梯度在神经网络压缩中用于重要性评分的实用性，尤其是在修剪中等规模的网络中。然而，使用反向传播计算梯度所涉及的大量内存需求阻碍了梯度在指导 LLM 修剪中的利用。因此，大多数 LLM 的修剪策略依赖于无梯度的标准，例如权重大小或大小和激活的混合。在本文中，我们设计了一个混合修剪标准，该标准适当地集成了大小、激活和梯度，以利用特征图敏感性来修剪 LLM。为了克服内存需求障碍，我们仅使用前向传递来估计梯度。基于此，我们提出了用于 LLM 的内存高效结构化修剪程序 (MINI-LLM)，以删除非关键通道和多头注意力。实验结果表明，在三个 LLM（LLaMA、BLOOM 和 OPT）上，MINI-LLM 在各种下游任务（分类、多项选择和生成）上优于现有的无梯度方法，而 MINI-LLM 保持了与无梯度方法类似的 GPU 内存占用空间。

##### **SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation**
2407.11676v1 by Yanis Lalou, Théo Gnassounou, Antoine Collas, Antoine de Mathelin, Oleksii Kachaiev, Ambroise Odonnat, Alexandre Gramfort, Thomas Moreau, Rémi Flamary

Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a
labeled source domain to perform well on an unlabeled target domain with some
data distribution shift. While many methods have been proposed in the
literature, fair and realistic evaluation remains an open question,
particularly due to methodological difficulties in selecting hyperparameters in
the unsupervised setting. With SKADA-Bench, we propose a framework to evaluate
DA methods and present a fair evaluation of existing shallow algorithms,
including reweighting, mapping, and subspace alignment. Realistic
hyperparameter selection is performed with nested cross-validation and various
unsupervised model selection scores, on both simulated datasets with controlled
shifts and real-world datasets across diverse modalities, such as images, text,
biomedical, and tabular data with specific feature extraction. Our benchmark
highlights the importance of realistic validation and provides practical
guidance for real-life applications, with key insights into the choice and
impact of model selection approaches. SKADA-Bench is open-source, reproducible,
and can be easily extended with novel DA methods, datasets, and model selection
criteria without requiring re-evaluating competitors. SKADA-Bench is available
on GitHub at https://github.com/scikit-adaptation/skada-bench.

摘要：無監督域適應 (DA) 是將在標籤來源域上訓練的模型調整為在具有某些資料分佈轉移的未標籤目標域上表現良好。雖然文獻中已提出許多方法，但公平且現實的評估仍然是一個公開的問題，特別是因為在無監督環境中選擇超參數的方法論困難。有了 SKADA-Bench，我們提出了一個評估 DA 方法的架構，並對現有的淺層演算法進行公平的評估，包括重新加權、對應和子空間對齊。在模擬資料集（具有受控轉移）和跨不同模式（例如影像、文字、生物醫學和具有特定特徵萃取的表格資料）的真實世界資料集上，使用嵌套交叉驗證和各種無監督模型選擇評分來執行現實的超參數選擇。我們的基準強調了現實驗證的重要性，並為實際應用提供實用的指導，深入了解模型選擇方法的選擇和影響。SKADA-Bench 是開源的、可複製的，並且可以輕鬆地擴充新的 DA 方法、資料集和模型選擇標準，而不需要重新評估競爭者。SKADA-Bench 可在 GitHub 上的 https://github.com/scikit-adaptation/skada-bench 取得。

##### **ECoh: Turn-level Coherence Evaluation for Multilingual Dialogues**
2407.11660v1 by John Mendonça, Isabel Trancoso, Alon Lavie

Despite being heralded as the new standard for dialogue evaluation, the
closed-source nature of GPT-4 poses challenges for the community. Motivated by
the need for lightweight, open source, and multilingual dialogue evaluators,
this paper introduces GenResCoh (Generated Responses targeting Coherence).
GenResCoh is a novel LLM generated dataset comprising over 130k negative and
positive responses and accompanying explanations seeded from XDailyDialog and
XPersona covering English, French, German, Italian, and Chinese. Leveraging
GenResCoh, we propose ECoh (Evaluation of Coherence), a family of evaluators
trained to assess response coherence across multiple languages. Experimental
results demonstrate that ECoh achieves multilingual detection capabilities
superior to the teacher model (GPT-3.5-Turbo) on GenResCoh, despite being based
on a much smaller architecture. Furthermore, the explanations provided by ECoh
closely align in terms of quality with those generated by the teacher model.

摘要：儘管被宣傳為對話評估的新標準，但 GPT-4 的封閉原始碼特性對社群來說是個挑戰。基於對輕量化、開放原始碼和多語言對話評估器的需求，本文介紹了 GenResCoh（針對相干性的生成回應）。GenResCoh 是一個新穎的 LLM 生成資料集，包含超過 13 萬個負面和正面回應，以及來自 XDailyDialog 和 XPersona 的相關說明，涵蓋英語、法語、德語、義大利語和中文。利用 GenResCoh，我們提出了 ECoh（相干性評估），一個評估器家族，經過訓練可以評估多種語言的回應相干性。實驗結果表明，儘管基於一個小得多的架構，但 ECoh 在 GenResCoh 上達到了多語言偵測能力，優於教師模型 (GPT-3.5-Turbo)。此外，ECoh 提供的說明在品質上與教師模型生成的說明非常接近。

##### **R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models**
2407.11654v1 by Aladin Djuhera, Vlad C. Andrei, Xinyang Li, Ullrich J. Mönich, Holger Boche, Walid Saad

Split federated learning (SFL) is a compute-efficient paradigm in distributed
machine learning (ML), where components of large ML models are outsourced to
remote servers. A significant challenge in SFL, particularly when deployed over
wireless channels, is the susceptibility of transmitted model parameters to
adversarial jamming that could jeopardize the learning process. This is
particularly pronounced for word embedding parameters in large language models
(LLMs), which are crucial for language understanding. In this paper, rigorous
insights are provided into the influence of jamming LLM word embeddings in SFL
by deriving an expression for the ML training loss divergence and showing that
it is upper-bounded by the mean squared error (MSE). Based on this analysis, a
physical layer framework is developed for resilient SFL with LLMs (R-SFLLM)
over wireless networks. R-SFLLM leverages wireless sensing data to gather
information on the jamming directions-of-arrival (DoAs) for the purpose of
devising a novel, sensing-assisted anti-jamming strategy while jointly
optimizing beamforming, user scheduling, and resource allocation. Extensive
experiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,
achieving close-to-baseline performance across various natural language
processing (NLP) tasks and datasets. The proposed methodology further
introduces an adversarial training component, where controlled noise exposure
significantly enhances the LLM's resilience to perturbed parameters during
training. The results show that more noise-sensitive models, such as RoBERTa,
benefit from this feature, especially when resource allocation is unfair. It is
also shown that worst-case jamming in particular translates into worst-case
model outcomes, thereby necessitating the need for jamming-resilient SFL
protocols.

摘要：分割联邦學習 (SFL) 是一種在分散式機器學習 (ML) 中計算效率高的範例，其中大型 ML 模型的組成會外包到遠端伺服器。SFL 中的一項重大挑戰，特別是在無線頻道上部署時，在於傳輸的模型參數容易受到對抗性干擾，可能會危及學習過程。這對於大型語言模型 (LLM) 中的詞嵌入參數來說尤其明顯，這些參數對於語言理解至關重要。在本文中，透過推導 ML 訓練損失差異的表達式，並證明它以上限均方誤差 (MSE) 為界，深入探討了干擾 SFL 中的 LLM 詞嵌入的影響。根據此分析，開發了一個用於無線網路上的彈性 SFL 與 LLM (R-SFLLM) 的物理層架構。R-SFLLM 利用無線感測資料來收集干擾到來方向 (DoA) 的資訊，目的是設計一種新穎的感測輔助抗干擾策略，同時最佳化波束成形、使用者排程和資源分配。使用 BERT 和 RoBERTa 模型進行的廣泛實驗證明了 R-SFLLM 的有效性，在各種自然語言處理 (NLP) 任務和資料集上實現了接近基線的效能。所提出的方法進一步引入了對抗訓練組成，其中受控的雜訊暴露會在訓練期間顯著增強 LLM 對擾動參數的彈性。結果表明，對雜訊更敏感的模型（例如 RoBERTa）受益於此功能，特別是在資源分配不公平的情況下。它也表明，最壞情況下的干擾特別會轉化為最壞情況下的模型結果，因此需要防干擾 SFL 協定。

##### **CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**
2407.11652v1 by Sunny Gupta, Amit Sethi

Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.

摘要：联邦学习 (FL) 提供了一种在分散式数据上训练模型的隐私保护方法。它在医疗保健中的潜力很大，但由于医疗图像数据中存在跨客户端差异，因此带来了挑战，而有限的注释加剧了这一问题。本文介绍了跨客户端差异自适应联邦学习 (CCVA-FL) 来解决这些问题。CCVA-FL 旨在通过将图像转换为公共特征空间来最小化跨客户端差异。它涉及从每个客户端注释图像子集的专家注释，然后选择数据复杂性最低的客户端作为目标。然后使用基于目标客户端注释图像的可扩展扩散模型与 Transformer (DiT) 生成合成医学图像。这些合成图像捕捉了多样性并代表了原始数据，与其他客户端共享。然后，每个客户端使用图像到图像翻译将其本地图像转换为目标图像空间。翻译后的图像随后在联邦学习设置中用于开发服务器模型。我们的结果表明，CCVA-FL 通过有效解决跨客户端的数据分布差异在不损害隐私的情况下优于香草联邦平均。

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

摘要：近期，大型语言模型 (LLM) 在各种资料探勘任务中展现出极大的潜力，例如知识问答、数学推理和常识推理。然而，LLM 在时间事件预测方面的推理能力尚未被充分探索。为了系统性地调查其在时间事件预测方面的能力，我们对基于 LLM 的时间事件预测方法进行了全面的评估。由于缺乏同时包含图表和文本资料的高品质数据集，我们首先构建了一个名为 MidEast-TE-mini 的基准数据集。基于此数据集，我们设计了一系列基线方法，其特点是各种输入格式和检索增强生成 (RAG) 模块。从广泛的实验中，我们发现直接将原始文本整合到 LLM 的输入中并不会增强零次学习外推性能。相比之下，在特定复杂事件中纳入原始文本并微调 LLM 会显著提高性能。此外，通过检索模块的增强，LLM 可以有效地捕捉隐藏在历史事件中的时间关系模式。同时，诸如流行度偏差和长尾问题等问题仍然存在于 LLM 中，尤其是在基于 RAG 的方法中。这些发现不仅加深了我们对基于 LLM 的事件预测方法的理解，还突出了几个有前景的研究方向。我们认为，这项全面的评估，连同已确定的研究机会，将极大地促进通过 LLM 进行时间事件预测的未来研究。

##### **Rethinking Fair Graph Neural Networks from Re-balancing**
2407.11624v1 by Zhixun Li, Yushun Dong, Qiang Liu, Jeffrey Xu Yu

Driven by the powerful representation ability of Graph Neural Networks
(GNNs), plentiful GNN models have been widely deployed in many real-world
applications. Nevertheless, due to distribution disparities between different
demographic groups, fairness in high-stake decision-making systems is receiving
increasing attention. Although lots of recent works devoted to improving the
fairness of GNNs and achieved considerable success, they all require
significant architectural changes or additional loss functions requiring more
hyper-parameter tuning. Surprisingly, we find that simple re-balancing methods
can easily match or surpass existing fair GNN methods. We claim that the
imbalance across different demographic groups is a significant source of
unfairness, resulting in imbalanced contributions from each group to the
parameters updating. However, these simple re-balancing methods have their own
shortcomings during training. In this paper, we propose FairGB, Fair Graph
Neural Network via re-Balancing, which mitigates the unfairness of GNNs by
group balancing. Technically, FairGB consists of two modules: counterfactual
node mixup and contribution alignment loss. Firstly, we select counterfactual
pairs across inter-domain and inter-class, and interpolate the ego-networks to
generate new samples. Guided by analysis, we can reveal the debiasing mechanism
of our model by the causal view and prove that our strategy can make sensitive
attributes statistically independent from target labels. Secondly, we reweigh
the contribution of each group according to gradients. By combining these two
modules, they can mutually promote each other. Experimental results on
benchmark datasets show that our method can achieve state-of-the-art results
concerning both utility and fairness metrics. Code is available at
https://github.com/ZhixunLEE/FairGB.

摘要：<paragraph>在图神经网络 (GNN) 强大的表示能力的推动下，大量的 GNN 模型已广泛部署在许多实际应用中。然而，由于不同人口群体之间的分布差异，高风险决策系统中的公平性正受到越来越多的关注。尽管最近有许多致力于提高 GNN 公平性的工作并取得了相当大的成功，但它们都需要大量的架构更改或附加损失函数，需要更多超参数调整。令人惊讶的是，我们发现简单的重新平衡方法可以轻松匹配或超越现有的公平 GNN 方法。我们声称，不同人口群体之间的不平衡是造成不公平的一个重要根源，导致每个群体对参数更新的贡献不平衡。然而，这些简单的重新平衡方法在训练过程中有其自身的缺点。在本文中，我们提出了 FairGB，即通过重新平衡实现公平图神经网络，它通过组平衡来减轻 GNN 的不公平性。从技术上讲，FairGB 由两个模块组成：反事实节点混合和贡献对齐损失。首先，我们在域间和类间选择反事实对，并插值自我网络以生成新样本。在分析的指导下，我们可以通过因果视图揭示我们模型的去偏机制，并证明我们的策略可以使敏感属性在统计上独立于目标标签。其次，我们根据梯度重新权衡每个组的贡献。通过结合这两个模块，它们可以相互促进。基准数据集上的实验结果表明，我们的方法可以实现有关效用和公平性指标的最先进结果。代码可在 https://github.com/ZhixunLEE/FairGB 获得。</paragraph>

##### **Graph Dimension Attention Networks for Enterprise Credit Assessment**
2407.11615v1 by Shaopeng Wei, Beni Egressy, Xingyan Chen, Yu Zhao, Fuzhen Zhuang, Roger Wattenhofer, Gang Kou

Enterprise credit assessment is critical for evaluating financial risk, and
Graph Neural Networks (GNNs), with their advanced capability to model
inter-entity relationships, are a natural tool to get a deeper understanding of
these financial networks. However, existing GNN-based methodologies
predominantly emphasize entity-level attention mechanisms for contagion risk
aggregation, often overlooking the heterogeneous importance of different
feature dimensions, thus falling short in adequately modeling credit risk
levels. To address this issue, we propose a novel architecture named Graph
Dimension Attention Network (GDAN), which incorporates a dimension-level
attention mechanism to capture fine-grained risk-related characteristics.
Furthermore, we explore the interpretability of the GNN-based method in
financial scenarios and propose a simple but effective data-centric explainer
for GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability
by quantifying distribution shifts during the message-passing process.
Moreover, we collected a real-world, multi-source Enterprise Credit Assessment
Dataset (ECAD) and have made it accessible to the research community since
high-quality datasets are lacking in this field. Extensive experiments
conducted on ECAD demonstrate the effectiveness of our methods. In addition, we
ran GDAN on the well-known datasets SMEsD and DBLP, also with excellent
results.

摘要：企業信用評估對於評估財務風險至關重要，圖形神經網路 (GNN) 具有建模實體間關係的先進能力，是深入了解這些金融網路的自然工具。然而，現有的基於 GNN 的方法主要強調實體層級的關注機制，用於傳染風險彙總，常常忽略不同特徵維度的異質重要性，因此在充分建模信用風險層級方面有所不足。為了解決這個問題，我們提出一個名為圖形維度關注網路 (GDAN) 的新架構，它結合了維度層級的關注機制來捕捉細緻的風險相關特徵。此外，我們探討了基於 GNN 的方法在財務情境中的可解釋性，並為 GDAN 提出了一個簡單但有效的以資料為中心的解釋器，稱為 GDAN-DistShift。DistShift 透過量化訊息傳遞過程中的分佈轉移，提供邊緣層級的可解釋性。此外，我們收集了一個真實世界的多來源企業信用評估資料集 (ECAD)，並已提供給研究社群，因為這個領域缺乏高品質的資料集。在 ECAD 上進行的廣泛實驗證明了我們方法的有效性。此外，我們在著名的資料集 SMEsD 和 DBLP 上執行了 GDAN，也獲得了極佳的結果。

##### **Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project**
2407.11613v1 by David Moats, Chandrima Ganguly

This commentary piece reviews the recent Open AI Democratic Inputs programme,
which funded 10 teams to design procedures for public participation in
generative AI. While applauding the technical innovations in these projects, we
identify several shared assumptions including the generality of LLMs,
extracting abstract values, soliciting solutions not problems and equating
participation with democracy. We call instead for AI participation which
involves specific communities and use cases and solicits concrete problems to
be remedied. We also find it important that these communities have a stake in
the outcome, including ownership of data or models.

摘要：這篇評論文章回顧了最近的 Open AI 民主輸入計畫，
該計畫資助了 10 個團隊，以設計公眾參與生成式 AI 的程序。雖然讚賞這些專案中的技術創新，我們
找出幾個共同的假設，包括 LLM 的普遍性，
提取抽象價值，徵求解決方案而非問題，以及將參與等同於民主。我們呼籲以 AI 參與取而代之，
其中涉及特定社群和使用案例，並徵求具體問題以獲得補救。我們也發現這些社群在成果中具有利害關係非常重要，包括資料或模型的所有權。

##### **Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift**
2407.11609v1 by Navid Hashemi, Lars Lindemann, Jyotirmoy V. Deshmukh

Reachability analysis is a popular method to give safety guarantees for
stochastic cyber-physical systems (SCPSs) that takes in a symbolic description
of the system dynamics and uses set-propagation methods to compute an
overapproximation of the set of reachable states over a bounded time horizon.
In this paper, we investigate the problem of performing reachability analysis
for an SCPS that does not have a symbolic description of the dynamics, but
instead is described using a digital twin model that can be simulated to
generate system trajectories. An important challenge is that the simulator
implicitly models a probability distribution over the set of trajectories of
the SCPS; however, it is typical to have a sim2real gap, i.e., the actual
distribution of the trajectories in a deployment setting may be shifted from
the distribution assumed by the simulator. We thus propose a statistical
reachability analysis technique that, given a user-provided threshold
$1-\epsilon$, provides a set that guarantees that any reachable state during
deployment lies in this set with probability not smaller than this threshold.
Our method is based on three main steps: (1) learning a deterministic surrogate
model from sampled trajectories, (2) conducting reachability analysis over the
surrogate model, and (3) employing {\em robust conformal inference} using an
additional set of sampled trajectories to quantify the surrogate model's
distribution shift with respect to the deployed SCPS. To counter conservatism
in reachable sets, we propose a novel method to train surrogate models that
minimizes a quantile loss term (instead of the usual mean squared loss), and a
new method that provides tighter guarantees using conformal inference using a
normalized surrogate error. We demonstrate the effectiveness of our technique
on various case studies.

摘要：可達性分析是一種流行的方法，用於對隨機網路物理系統 (SCPS) 提供安全保證，它採用系統動態的符號描述，並使用集合傳播方法計算出在有界時間範圍內可達狀態集合的過度近似。在本文中，我們探討了對沒有動態符號描述的 SCPS 執行可達性分析的問題，而是使用可以模擬以生成系統軌跡的數位雙胞胎模型進行描述。一個重要的挑戰是，模擬器隱式地對 SCPS 軌跡集合建模機率分佈；然而，通常會有 sim2real 差距，即，部署設定中軌跡的實際分佈可能會偏離模擬器假設的分佈。因此，我們提出了一種統計可達性分析技術，給定使用者提供的閾值 $1-\epsilon$，提供一個集合，保證部署期間的任何可達狀態都位於此集合中，機率不小於此閾值。我們的技術基於三個主要步驟：(1) 從採樣軌跡學習確定性替代模型，(2) 對替代模型進行可達性分析，以及 (3) 使用另一組採樣軌跡採用「穩健共形推論」來量化替代模型相對於已部署 SCPS 的分佈轉移。為了應對可達集合中的保守主義，我們提出了一種新方法來訓練替代模型，以最小化分位數損失項（而不是通常的均方損失），以及一種使用共形推論的新方法，使用正規化的替代誤差提供更嚴格的保證。我們在各種案例研究中展示了我們技術的有效性。

##### **The Foundations of Tokenization: Statistical and Computational Concerns**
2407.11606v1 by Juan Luis Gastaldi, John Terilla, Luca Malagutti, Brian DuSell, Tim Vieira, Ryan Cotterell

Tokenization - the practice of converting strings of characters over an
alphabet into sequences of tokens over a vocabulary - is a critical yet
under-theorized step in the NLP pipeline. Notably, it remains the only major
step not fully integrated into widely used end-to-end neural models. This paper
aims to address this theoretical gap by laying the foundations of tokenization
from a formal perspective. By articulating and extending basic properties about
the category of stochastic maps, we propose a unified framework for
representing and analyzing tokenizer models. This framework allows us to
establish general conditions for the use of tokenizers. In particular, we
formally establish the necessary and sufficient conditions for a tokenizer
model to preserve the consistency of statistical estimators. Additionally, we
discuss statistical and computational concerns crucial for the design and
implementation of tokenizer models. The framework and results advanced in this
paper represent a step toward a robust theoretical foundation for neural
language modeling.

摘要：分詞 - 將字母表上的字元串轉換為詞彙上的符號序列的做法 - 是 NLP 管線中一個關鍵但理論化不足的步驟。值得注意的是，它仍然是唯一一個尚未完全整合到廣泛使用的端到端神經模型中的主要步驟。本文旨在通過從形式的角度奠定分詞的基礎來解決這個理論差距。通過闡述和擴展關於隨機映射類別的基本屬性，我們提出了用於表示和分析分詞器模型的統一框架。這個框架讓我們能夠為分詞器的使用建立一般條件。特別是，我們正式建立了分詞器模型保持統計估計器一致性的必要和充分條件。此外，我們討論了對分詞器模型的設計和實作至關重要的統計和計算問題。本文提出的框架和結果代表了朝向穩健的神經語言模型理論基礎邁出的一步。

##### **Enhancing TinyML Security: Study of Adversarial Attack Transferability**
2407.11599v1 by Parin Shah, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar

The recent strides in artificial intelligence (AI) and machine learning (ML)
have propelled the rise of TinyML, a paradigm enabling AI computations at the
edge without dependence on cloud connections. While TinyML offers real-time
data analysis and swift responses critical for diverse applications, its
devices' intrinsic resource limitations expose them to security risks. This
research delves into the adversarial vulnerabilities of AI models on
resource-constrained embedded hardware, with a focus on Model Extraction and
Evasion Attacks. Our findings reveal that adversarial attacks from powerful
host machines could be transferred to smaller, less secure devices like ESP32
and Raspberry Pi. This illustrates that adversarial attacks could be extended
to tiny devices, underscoring vulnerabilities, and emphasizing the necessity
for reinforced security measures in TinyML deployments. This exploration
enhances the comprehension of security challenges in TinyML and offers insights
for safeguarding sensitive data and ensuring device dependability in AI-powered
edge computing settings.

摘要：最近在人工智慧（AI）和機器學習（ML）的進展，推動了 TinyML 的崛起，這是一個在邊緣進行 AI 計算的範例，不需要依賴雲端連線。儘管 TinyML 提供了即時資料分析和快速回應，這對各種應用程式來說至關重要，但其裝置內在的資源限制使它們面臨安全風險。這項研究探討了在資源受限的嵌入式硬體上，AI 模型的對抗性漏洞，重點在於模型萃取和規避攻擊。我們的研究結果顯示，強大的主機電腦的對抗性攻擊可以轉移到較小、安全性較低的裝置，例如 ESP32 和 Raspberry Pi。這說明了對抗性攻擊可以擴展到微型裝置，凸顯了漏洞，並強調在 TinyML 部署中強化安全措施的必要性。這項探討增強了對 TinyML 安全挑戰的理解，並提供了見解，用於保護敏感資料，並確保在 AI 驅動的邊緣運算設定中裝置的可靠性。

##### **DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**
2407.11594v1 by Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi

Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.

摘要：擴散模型 (DM) 已成為各種任務中強大的基礎模型，特別是合成影像生成。然而，它們在訓練中對大型標註資料集的要求限制了它們在醫療影像中的應用，而醫療影像的資料集通常較小且標註稀疏。我們引入了 DiNO-Diffusion，這是一種用於訓練條件生成過程的潛在擴散模型 (LDM) 的自監督方法，該過程基於從 DiNO 中提取的影像嵌入。透過消除對標註的依賴，我們的訓練利用了來自公共胸部 X 光 (CXR) 資料集的超過 868k 張未標註影像。儘管是自監督的，但 DiNO-Diffusion 顯示出全面的流形覆蓋，FID 分數低至 4.7，並且在評估下游任務時出現了新興的屬性。它可用於從小型資料庫生成語義多樣的合成資料集，在用於資料擴充時，分類效能提升幅度高達 20% AUC。影像是在 DiNO 嵌入流形上使用不同的取樣策略生成的，並使用真實影像作為起點。結果顯示，DiNO-Diffusion 可以促進從有限的真實資料中靈活訓練下游 AI 模型的大型資料集的建立，同時也具有隱私保護的潛力。此外，DiNO-Diffusion 在評估肺葉分割時展示了高達 84.4% 的 Dice 分數的零次學習分割效能。這證明了良好的 CXR 影像解剖對齊，類似於在香草 DM 上使用文字描述符進行分割。最後，DiNO-Diffusion 可以輕鬆適應其他醫療影像方式或最先進的擴散模型，為醫療影像的大規模、多領域影像生成管道開啟了大門。

##### **AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization**
2407.11591v1 by Anum Afzal, Ribin Chalumattu, Florian Matthes, Laura Mascarell Espuny

Despite the advances in the abstractive summarization task using Large
Language Models (LLM), there is a lack of research that asses their abilities
to easily adapt to different domains. We evaluate the domain adaptation
abilities of a wide range of LLMs on the summarization task across various
domains in both fine-tuning and in-context learning settings. We also present
AdaptEval, the first domain adaptation evaluation suite. AdaptEval includes a
domain benchmark and a set of metrics to facilitate the analysis of domain
adaptation. Our results demonstrate that LLMs exhibit comparable performance in
the in-context learning setting, regardless of their parameter scale.

摘要：儘管使用大型語言模型 (LLM) 在抽象摘要任務中取得進展，但缺乏研究評估其輕鬆適應不同領域的能力。我們評估了各種 LLM 在摘要任務中對不同領域的領域適應能力，包括微調和情境學習設定。我們還提出了 AdaptEval，這是第一個領域適應評估套件。AdaptEval 包含一個領域基準和一組指標，以利於分析領域適應。我們的結果表明，無論 LLM 的參數規模如何，它們在情境學習設定中都表現出相當的效能。

##### **QVD: Post-training Quantization for Video Diffusion Models**
2407.11585v2 by Shilong Tian, Hong Chen, Chengtao Lv, Yu Liu, Jinyang Guo, Xianglong Liu, Shengxi Li, Hao Yang, Tao Xie

Recently, video diffusion models (VDMs) have garnered significant attention
due to their notable advancements in generating coherent and realistic video
content. However, processing multiple frame features concurrently, coupled with
the considerable model size, results in high latency and extensive memory
consumption, hindering their broader application. Post-training quantization
(PTQ) is an effective technique to reduce memory footprint and improve
computational efficiency. Unlike image diffusion, we observe that the temporal
features, which are integrated into all frame features, exhibit pronounced
skewness. Furthermore, we investigate significant inter-channel disparities and
asymmetries in the activation of video diffusion models, resulting in low
coverage of quantization levels by individual channels and increasing the
challenge of quantization. To address these issues, we introduce the first PTQ
strategy tailored for video diffusion models, dubbed QVD. Specifically, we
propose the High Temporal Discriminability Quantization (HTDQ) method, designed
for temporal features, which retains the high discriminability of quantized
features, providing precise temporal guidance for all video frames. In
addition, we present the Scattered Channel Range Integration (SCRI) method
which aims to improve the coverage of quantization levels across individual
channels. Experimental validations across various models, datasets, and
bit-width settings demonstrate the effectiveness of our QVD in terms of diverse
metrics. In particular, we achieve near-lossless performance degradation on
W8A8, outperforming the current methods by 205.12 in FVD.

摘要：<paragraph>近期，影片扩散模型 (VDM) 因其在生成连贯且逼真的影片内容方面取得显著进展而备受关注。然而，同时处理多个帧特征，加上模型规模庞大，导致延迟高且内存消耗大，阻碍了其更广泛的应用。训练后量化 (PTQ) 是一种有效的技术，可减少内存占用并提高计算效率。与图像扩散不同，我们观察到整合到所有帧特征中的时间特征表现出明显的偏度。此外，我们调查了影片扩散模型激活中的显著的通道间差异和不对称性，导致各个通道的量化级别覆盖率低，增加了量化的难度。为了解决这些问题，我们引入了第一个专为影片扩散模型量身定制的 PTQ 策略，称为 QVD。具体来说，我们提出了针对时间特征设计的高时间可辨别性量化 (HTDQ) 方法，它保留了量化特征的高可辨别性，为所有影片帧提供精确的时间指导。此外，我们提出了分散通道范围整合 (SCRI) 方法，旨在提高各个通道的量化级别覆盖率。跨越各种模型、数据集和位宽设置的实验验证证明了我们的 QVD 在各种指标方面的有效性。特别是，我们在 W8A8 上实现了接近无损的性能下降，在 FVD 中比当前方法高出 205.12。</paragraph>

##### **Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**
2407.11573v1 by Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer, Karthik Nandakumar

With the advent of large pre-trained transformer models, fine-tuning these
models for various downstream tasks is a critical problem. Paucity of training
data, the existence of data silos, and stringent privacy constraints exacerbate
this fine-tuning problem in the medical imaging domain, creating a strong need
for algorithms that enable collaborative fine-tuning of pre-trained models.
Moreover, the large size of these models necessitates the use of
parameter-efficient fine-tuning (PEFT) to reduce the communication burden in
federated learning. In this work, we systematically investigate various
federated PEFT strategies for adapting a Vision Transformer (ViT) model
(pre-trained on a large natural image dataset) for medical image
classification. Apart from evaluating known PEFT techniques, we introduce new
federated variants of PEFT algorithms such as visual prompt tuning (VPT),
low-rank decomposition of visual prompts, stochastic block attention
fine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.
Moreover, we perform a thorough empirical analysis to identify the optimal PEFT
method for the federated setting and understand the impact of data distribution
on federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key
insight of this study is that while most federated PEFT methods work well for
in-domain transfer, there is a substantial accuracy vs. efficiency trade-off
when dealing with OOD and non-IID scenarios, which is commonly the case in
medical imaging. Specifically, every order of magnitude reduction in
fine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the
initial model choice is crucial for federated PEFT. It is preferable to use
medical foundation models learned from in-domain medical image data (if
available) rather than general vision models.

摘要：<paragraph>隨著大型預訓練轉換器模型的出現，針對各種下游任務微調這些模型是一個關鍵問題。訓練資料的稀缺性、資料孤島的存在以及嚴格的隱私限制會加劇醫療影像領域中的微調問題，這對能讓預訓練模型進行協作微調的演算法產生了強烈需求。此外，這些模型的龐大規模需要使用參數有效微調 (PEFT) 來降低聯合學習中的通訊負擔。在這項工作中，我們系統性地探討了各種聯合 PEFT 策略，以調整視覺轉換器 (ViT) 模型（在大型自然影像資料集上預先訓練）以進行醫療影像分類。除了評估已知的 PEFT 技術外，我們還引入了 PEFT 演算法的新聯合變體，例如視覺提示調整 (VPT)、視覺提示的低秩分解、隨機區塊注意力微調，以及低秩適應 (LoRA)+VPT 等混合 PEFT 方法。此外，我們進行了徹底的經驗分析，以找出聯合設定的最佳 PEFT 方法，並了解資料分佈對聯合 PEFT 的影響，特別是對於領域外 (OOD) 和非獨立同分佈 (non-IID) 資料。這項研究的主要見解是，儘管大多數聯合 PEFT 方法都適用於領域內轉移，但在處理 OOD 和非獨立同分佈場景時，會有大幅的準確度與效率折衷，這通常是醫療影像中的情況。具體來說，微調/交換參數的每個數量級減少都可能導致準確度下降 4%。因此，初始模型的選擇對於聯合 PEFT 至關重要。最好使用從領域內醫學影像資料（如果有的話）學習的醫學基礎模型，而不是一般視覺模型。</paragraph>

##### **TGIF: Text-Guided Inpainting Forgery Dataset**
2407.11566v1 by Hannes Mareen, Dimitrios Karageorgiou, Glenn Van Wallendael, Peter Lambert, Symeon Papadopoulos

Digital image manipulation has become increasingly accessible and realistic
with the advent of generative AI technologies. Recent developments allow for
text-guided inpainting, making sophisticated image edits possible with minimal
effort. This poses new challenges for digital media forensics. For example,
diffusion model-based approaches could either splice the inpainted region into
the original image, or regenerate the entire image. In the latter case,
traditional image forgery localization (IFL) methods typically fail. This paper
introduces the Text-Guided Inpainting Forgery (TGIF) dataset, a comprehensive
collection of images designed to support the training and evaluation of image
forgery localization and synthetic image detection (SID) methods. The TGIF
dataset includes approximately 80k forged images, originating from popular
open-source and commercial methods; SD2, SDXL, and Adobe Firefly. Using this
data, we benchmark several state-of-the-art IFL and SID methods. Whereas
traditional IFL methods can detect spliced images, they fail to detect
regenerated inpainted images. Moreover, traditional SID may detect the
regenerated inpainted images to be fake, but cannot localize the inpainted
area. Finally, both types of methods fail when exposed to stronger compression,
while they are less robust to modern compression algorithms, such as WEBP. As
such, this work demonstrates the inefficiency of state-of-the-art detectors on
local manipulations performed by modern generative approaches, and aspires to
help with the development of more capable IFL and SID methods. The dataset can
be downloaded at https://github.com/IDLabMedia/tgif-dataset.

摘要：數位影像處理隨著生成式 AI 技術的出現，變得越來越容易取得且逼真。最近的發展允許文字引導的填補，讓複雜的影像編輯變得輕而易舉。這為數位媒體鑑識帶來了新的挑戰。例如，基於擴散模型的方法可以將填補區域拼接至原始影像，或重新產生整張影像。在後者的情況下，傳統的影像偽造定位 (IFL) 方法通常會失敗。本文介紹了文字引導填補偽造 (TGIF) 資料集，這是一個全面的影像集合，旨在支援影像偽造定位和合成影像偵測 (SID) 方法的訓練和評估。TGIF 資料集包含約 80k 張偽造影像，源自於熱門的開源和商業方法；SD2、SDXL 和 Adobe Firefly。使用這些資料，我們評定了數種最先進的 IFL 和 SID 方法。雖然傳統的 IFL 方法可以偵測拼接影像，但無法偵測重新產生的填補影像。此外，傳統的 SID 雖然可以偵測重新產生的填補影像為假，但無法定位填補區域。最後，這兩種方法在遇到較強的壓縮時都會失敗，而它們對現代壓縮演算法（例如 WEBP）的魯棒性較差。因此，這項研究證明了最先進的偵測器對於現代生成方法執行的局部處理的效率低下，並希望有助於開發更強大的 IFL 和 SID 方法。該資料集可於 https://github.com/IDLabMedia/tgif-dataset 下載。

##### **Self-Guided Generation of Minority Samples Using Diffusion Models**
2407.11555v1 by Soobin Um, Jong Chul Ye

We present a novel approach for generating minority samples that live on
low-density regions of a data manifold. Our framework is built upon diffusion
models, leveraging the principle of guided sampling that incorporates an
arbitrary energy-based guidance during inference time. The key defining feature
of our sampler lies in its \emph{self-contained} nature, \ie, implementable
solely with a pretrained model. This distinguishes our sampler from existing
techniques that require expensive additional components (like external
classifiers) for minority generation. Specifically, we first estimate the
likelihood of features within an intermediate latent sample by evaluating a
reconstruction loss w.r.t. its posterior mean. The generation then proceeds
with the minimization of the estimated likelihood, thereby encouraging the
emergence of minority features in the latent samples of subsequent timesteps.
To further improve the performance of our sampler, we provide several
time-scheduling techniques that properly manage the influence of guidance over
inference steps. Experiments on benchmark real datasets demonstrate that our
approach can greatly improve the capability of creating realistic
low-likelihood minority instances over the existing techniques without the
reliance on costly additional elements. Code is available at
\url{https://github.com/soobin-um/sg-minority}.

摘要：我們提出了一種新的方法來產生少數樣本，這些樣本存在於資料流形中的低密度區域。我們的架構建立在擴散模型上，利用了引導取樣的原理，該原理在推論時間內包含了基於任意能量的引導。我們的取樣器的關鍵定義特徵在於其「自我封閉」的本質，也就是說，僅使用預訓練模型就能實現。這使得我們的取樣器有別於現有的技術，後者需要昂貴的額外組件（如外部分類器）來產生少數。具體來說，我們首先透過評估重建損失相對於其後驗平均值來估計中間潛在樣本中特徵的可能性。然後，生成會隨著估計可能性的最小化而進行，從而促進少數特徵在後續時間步長的潛在樣本中出現。為了進一步提高我們取樣器的效能，我們提供了幾種時間排程技術，這些技術可以適當地管理引導對推論步驟的影響。基準真實資料集上的實驗表明，與現有技術相比，我們的做法可以大幅提高建立逼真的低可能性少數個體的能力，而無需依賴昂貴的額外元素。程式碼可在 https://github.com/soobin-um/sg-minority 取得。

##### **Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction**
2407.11553v1 by Zihan Tang, Tianyao Ji, Wenhu Tang

As modern power systems continue to evolve, accurate power load forecasting
remains a critical issue. The phase space reconstruction method can effectively
retain the chaotic characteristics of power load from a system dynamics
perspective and thus is a promising knowledge-based preprocessing method for
power load forecasting. However, limited by its fundamental theory, there is
still a gap in implementing a multi-step forecasting scheme in current studies.
To bridge this gap, this study proposes a novel multi-step forecasting approach
by integrating the PSR with neural networks. Firstly, the useful features in
the phase trajectory obtained from the preprocessing of PSR are discussed in
detail. Through mathematical derivation, the equivalent characterization of the
PSR and another time series preprocessing method, patch segmentation, is
demonstrated for the first time. Based on this prior knowledge, an image-based
modeling perspective with the global and local feature extraction strategy is
introduced. Subsequently, a novel deep learning model, namely PSR-GALIEN, is
designed for end-to-end processing, in which the Transformer Encoder and
2D-convolutional neural networks are employed for the extraction of the global
and local patterns in the image, and a multi-layer perception based predictor
is used for the efficient correlation modeling. Then, extensive experiments are
conducted on five real-world benchmark datasets to verify the effectiveness as
well as to have an insight into the detailed properties. The results show that,
comparing it with six state-of-the-art deep learning models, the forecasting
performance of PSR-GALIEN consistently surpasses these baselines, which
achieves superior accuracy in both intra-day and day-ahead forecasting
scenarios. At the same time, a visualization-based method is proposed to
explain the attributions of the forecasting results.

摘要：隨著現代電力系統持續演進，準確的電力負載預測仍為一項關鍵議題。相空間重建法能有效保留電力負載自系統動力學觀點的混沌特性，因此成為電力負載預測中極具前景的知識型前處理方法。然而，受限於其基礎理論，現行研究仍存在無法實作多步驟預測機制的缺口。為彌補此缺口，本研究提出結合相空間重建法與神經網路的創新多步驟預測方法。首先，詳細探討自相空間重建法前處理所得相軌跡中的有用特徵。透過數學推導，首次證明相空間重建法與另一時序前處理方法——區塊分割——的等價特性。基於此先備知識，引入具備全域與局部特徵萃取策略的影像化建模觀點。隨後，設計創新的深度學習模型 PSR-GALIEN 以進行端對端處理，其中採用 Transformer 編碼器與 2D 捲積神經網路萃取影像中的全域與局部模式，並使用基於多層感知器的預測器進行有效率的關聯性建模。接著，在五個真實世界基準資料集上進行廣泛的實驗，以驗證其有效性並深入了解其詳細特性。結果顯示，與六種最先進的深度學習模型相比較，PSR-GALIEN 的預測效能始終超越這些基準，在日內與日後預測情境中均達到優異的準確度。同時，提出基於視覺化的方法來解釋預測結果的歸因。

##### **Optimizing KV Cache Eviction in LLMs: Adaptive Allocation for Enhanced Budget Utilization**
2407.11550v1 by Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, S. Kevin Zhou

Large Language Models have excelled in various fields but encounter
efficiency limitations due to the extensive KV cache required for long
sequences inference. Many efforts try to evict non-critical cache elements
during runtime, thereby reducing cache size within a given memory budget while
preserving generation quality. Our reexamination of their underlying principles
discerns that prevailing strategies essentially aim to minimize an upper bound
of eviction loss within a specific budget allocation. However, we observe that
the current practice of uniformly allocating budgets across different attention
heads during the eviction procedure tends to degrade the quality of generation
posten-eviction. In light of these findings, we propose a simple yet effective
adaptive allocation algorithm that not only theoretically ensures its loss
upper bound does not exceed that of previous uniform allocation methods, but
also effectively aligns with the characteristics of the self-attention
mechanism, thus practically reducing the upper bound. Further, integrating this
algorithm with two of the most advanced methods yields Ada-SnapKV and
Ada-Pyramid. Extensive experimental validation across 16 datasets and the
Needle-in-a-Haystack test confirm that Ada-SnapKV and Ada-Pyramid achieve
further enhancements, establishing new benchmarks in state-of-the-art
performance.

摘要：大型語言模型在各種領域表現出色，但由於長序列推論需要大量的 KV 快取，因此會遇到效率限制。許多方法嘗試在執行期間驅逐非關鍵快取元素，從而在給定的記憶體預算中減少快取大小，同時保持生成品質。我們重新審視其基本原則，發現普遍的策略基本上旨在最小化特定預算分配中的驅逐損失的上限。然而，我們觀察到在驅逐過程中將預算均勻分配給不同注意力層的現行做法往往會降低驅逐後的生成品質。根據這些發現，我們提出一個簡單但有效的自適應分配演算法，它不僅在理論上確保其損失上限不超過先前的均勻分配方法，而且有效地符合自注意力機制的特性，從而實際上降低了上限。此外，將此演算法與兩種最先進的方法整合，產生 Ada-SnapKV 和 Ada-Pyramid。在 16 個資料集和 Needle-in-a-Haystack 測試中的廣泛實驗驗證證實，Ada-SnapKV 和 Ada-Pyramid 進一步提升，在最先進的效能中建立新的基準。

##### **How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models**
2407.11549v1 by Yin Jou Huang, Rafik Hadfi

Psychological evidence reveals the influence of personality traits on
decision-making. For instance, agreeableness is generally associated with
positive outcomes in negotiations, whereas neuroticism is often linked to less
favorable outcomes. This paper introduces a simulation framework centered on
Large Language Model (LLM) agents endowed with synthesized personality traits.
The agents negotiate within bargaining domains and possess customizable
personalities and objectives. The experimental results show that the behavioral
tendencies of LLM-based simulations could reproduce behavioral patterns
observed in human negotiations. The contribution is twofold. First, we propose
a simulation methodology that investigates the alignment between the linguistic
and economic capabilities of LLM agents. Secondly, we offer empirical insights
into the strategic impact of Big-Five personality traits on the outcomes of
bilateral negotiations. We also provide a case study based on synthesized
bargaining dialogues to reveal intriguing behaviors, including deceitful and
compromising behaviors.

摘要：心理學證據揭示了人格特質對決策的影響。例如，宜人性通常與談判中的積極結果有關，而神經質則經常與較不理想的結果有關。本文介紹了一個模擬架構，該架構以具有綜合人格特質的大語言模型 (LLM) 代理為中心。代理在議價領域內進行談判，並擁有可自訂的人格和目標。實驗結果表明，基於 LLM 的模擬的行為傾向可以重現人類談判中觀察到的行為模式。貢獻有兩個方面。首先，我們提出了一種模擬方法，該方法研究了 LLM 代理的語言和經濟能力之間的一致性。其次，我們提供了關於大五人格特質對雙邊談判結果的策略性影響的實證見解。我們還提供了一個基於綜合議價對話的案例研究，以揭示有趣的行為，包括欺騙和妥協行為。

##### **AEMIM: Adversarial Examples Meet Masked Image Modeling**
2407.11537v1 by Wenzhao Xiang, Chang Liu, Hang Su, Hongyang Yu

Masked image modeling (MIM) has gained significant traction for its
remarkable prowess in representation learning. As an alternative to the
traditional approach, the reconstruction from corrupted images has recently
emerged as a promising pretext task. However, the regular corrupted images are
generated using generic generators, often lacking relevance to the specific
reconstruction task involved in pre-training. Hence, reconstruction from
regular corrupted images cannot ensure the difficulty of the pretext task,
potentially leading to a performance decline. Moreover, generating corrupted
images might introduce an extra generator, resulting in a notable computational
burden. To address these issues, we propose to incorporate adversarial examples
into masked image modeling, as the new reconstruction targets. Adversarial
examples, generated online using only the trained models, can directly aim to
disrupt tasks associated with pre-training. Therefore, the incorporation not
only elevates the level of challenge in reconstruction but also enhances
efficiency, contributing to the acquisition of superior representations by the
model. In particular, we introduce a novel auxiliary pretext task that
reconstructs the adversarial examples corresponding to the original images. We
also devise an innovative adversarial attack to craft more suitable adversarial
examples for MIM pre-training. It is noted that our method is not restricted to
specific model architectures and MIM strategies, rendering it an adaptable
plug-in capable of enhancing all MIM methods. Experimental findings
substantiate the remarkable capability of our approach in amplifying the
generalization and robustness of existing MIM methods. Notably, our method
surpasses the performance of baselines on various tasks, including ImageNet,
its variants, and other downstream tasks.

摘要：<paragraph>遮罩影像模型 (MIM) 因其在表徵學習上的顯著能力而獲得極大的關注。作為傳統方法的替代方案，從損壞影像中重建最近已成為一項有前景的預設任務。然而，一般的損壞影像使用通用產生器產生，通常缺乏與預訓練中涉及的特定重建任務相關性。因此，從一般損壞影像進行重建無法確保預設任務的難度，可能會導致效能下降。此外，產生損壞影像可能會引入額外的產生器，導致顯著的運算負擔。為了解決這些問題，我們建議將對抗範例納入遮罩影像模型，作為新的重建目標。對抗範例僅使用訓練過的模型線上產生，可以直接針對與預訓練相關的任務進行破壞。因此，這種納入不僅提升了重建的挑戰難度，還提高了效率，有助於模型獲得更優越的表徵。特別是，我們引入了一項新穎的輔助預設任務，用來重建對應於原始影像的對抗範例。我們還設計了一種創新的對抗攻擊，用於為 MIM 預訓練製作更合適的對抗範例。請注意，我們的方法不受特定模型架構和 MIM 策略的限制，使其成為一種適應性外掛程式，能夠增強所有 MIM 方法。實驗結果證實了我們的方法在擴大現有 MIM 方法的泛化能力和穩健性方面的顯著能力。值得注意的是，我們的方法在各種任務上的效能都超越了基線，包括 ImageNet、其變體和其他下游任務。</paragraph>

##### **Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**
2407.11536v1 by Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan

Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.

摘要：大型語言模型 (LLM) 已廣泛應用於各種專業領域。通過使用特定領域的問答資料集微調模型，這些模型的專業領域知識和問答能力已顯著提升，例如，使用醫生-患者問答資料進行微調的醫療專業 LLM 展現出非凡的疾病診斷能力。然而，我們觀察到，儘管特定領域知識有所提升，但醫療 LLM 在長語境理解方面的表現卻大幅下降，尤其是與具有類似參數的一般語言模型相比。本研究的目的是探討醫療 LLM 在理解長語境方面的表現下降現象。我們設計了一系列實驗，對所有模型進行開放式專業知識考試，以評估它們閱讀長語境的理解能力。通過調整微調過程中一般資料和醫療資料的比例和數量，我們可以確定最佳資料組合，以優化專業模型，並在長語境表現和特定領域知識之間取得平衡。

##### **LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices**
2407.11534v1 by Jung Hyun Lee, Jeonghoon Kim, June Yong Yang, Se Jung Kwon, Eunho Yang, Kang Min Yoo, Dongsoo Lee

With the commercialization of large language models (LLMs), weight-activation
quantization has emerged to compress and accelerate LLMs, achieving high
throughput while reducing inference costs. However, existing post-training
quantization (PTQ) techniques for quantizing weights and activations of LLMs
still suffer from non-negligible accuracy drops, especially on massive
multitask language understanding. To address this issue, we propose Low-Rank
Quantization (LRQ) $-$ a simple yet effective post-training weight quantization
method for LLMs that reconstructs the outputs of an intermediate Transformer
block by leveraging low-rank weight-scaling matrices, replacing the
conventional full weight-scaling matrices that entail as many learnable scales
as their associated weights. Thanks to parameter sharing via low-rank
structure, LRQ only needs to learn significantly fewer parameters while
enabling the individual scaling of weights, thus boosting the generalization
capability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ
works under (i) $8$-bit weight and per-tensor activation quantization, (ii)
$4$-bit weight and $8$-bit per-token activation quantization, and (iii) low-bit
weight-only quantization schemes. Our code is available at
\url{https://github.com/onliwad101/FlexRound_LRQ} to inspire LLM researchers
and engineers.

摘要：隨著大型語言模型（LLM）商業化，權重活化量化應運而生，用於壓縮和加速 LLM，在降低推理成本的同時實現高吞吐量。然而，現有的 LLM 權重和活化量化的訓練後量化（PTQ）技術仍然會導致非可忽略的準確度下降，特別是在大規模多任務語言理解上。為了解決這個問題，我們提出了低秩量化（LRQ）$-$一種簡單但有效的 LLM 訓練後權重量化方法，它通過利用低秩權重縮放矩陣來重建中間 Transformer 塊的輸出，取代了包含與其關聯權重一樣多可學習縮放的傳統全權重縮放矩陣。由於通過低秩結構共享參數，LRQ 只需學習顯著更少的參數，同時啟用權重的個別縮放，從而提升量化 LLM 的泛化能力。我們展示了 LRQ 在以下情況下優於先前的 LLM PTQ 工作：(i) 8 位元權重和每個張量活化量化，(ii) 4 位元權重和 8 位元每個符號活化量化，以及 (iii) 低位元僅權重量化方案。我們的程式碼可在 \url{https://github.com/onliwad101/FlexRound_LRQ} 取得，以啟發 LLM 研究人員和工程師。

##### **Reasoning with Large Language Models, a Survey**
2407.11511v1 by Aske Plaat, Annie Wong, Suzan Verberne, Joost Broekens, Niki van Stein, Thomas Back

Scaling up language models to billions of parameters has opened up
possibilities for in-context learning, allowing instruction tuning and few-shot
learning on tasks that the model was not specifically trained for. This has
achieved breakthrough performance on language tasks such as translation,
summarization, and question-answering. Furthermore, in addition to these
associative "System 1" tasks, recent advances in Chain-of-thought prompt
learning have demonstrated strong "System 2" reasoning abilities, answering a
question in the field of artificial general intelligence whether LLMs can
reason. The field started with the question whether LLMs can solve grade school
math word problems. This paper reviews the rapidly expanding field of
prompt-based reasoning with LLMs. Our taxonomy identifies different ways to
generate, evaluate, and control multi-step reasoning. We provide an in-depth
coverage of core approaches and open problems, and we propose a research agenda
for the near future. Finally, we highlight the relation between reasoning and
prompt-based learning, and we discuss the relation between reasoning,
sequential decision processes, and reinforcement learning. We find that
self-improvement, self-reflection, and some metacognitive abilities of the
reasoning processes are possible through the judicious use of prompts. True
self-improvement and self-reasoning, to go from reasoning with LLMs to
reasoning by LLMs, remains future work.

摘要：<paragraph>將語言模型擴展到數十億個參數開啟了情境學習的可能性，允許對模型未經特別訓練的任務進行指令調整和少量學習。這在翻譯、摘要和問答等語言任務上實現了突破性的表現。此外，除了這些聯想式的「系統 1」任務之外，思考鏈提示學習的最新進展展示了強大的「系統 2」推理能力，回答了人工通用智慧領域中 LLM 是否可以推理的問題。該領域始於 LLM 是否能解決小學數學文字題的問題。本文回顧了 LLM 提示式推理快速擴展的領域。我們的分類法識別了生成、評估和控制多步驟推理的不同方法。我們深入探討了核心方法和開放性問題，並提出了近期研究議程。最後，我們強調了推理和提示式學習之間的關係，並討論了推理、序列決策過程和強化學習之間的關係。我們發現，通過明智地使用提示，推理過程的自完善、自我反思和一些元認知能力是可能的。真正的自我完善和自我推理，從使用 LLM 推理轉變為由 LLM 推理，仍然是未來的研究工作。</paragraph>

##### **Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era**
2407.11501v1 by Lei Ren, Haiteng Wang, Yuanjun Laili

Industrial Multivariate Time Series (MTS) is a critical view of the
industrial field for people to understand the state of machines. However, due
to data collection difficulty and privacy concerns, available data for building
industrial intelligence and industrial large models is far from sufficient.
Therefore, industrial time series data generation is of great importance.
Existing research usually applies Generative Adversarial Networks (GANs) to
generate MTS. However, GANs suffer from unstable training process due to the
joint training of the generator and discriminator. This paper proposes a
temporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for
MTS generation. It aims to better handle the complex temporal dependencies and
dynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean
Discrepancy (Ada-MMD) method has been proposed for the controlled generation of
MTS, which does not require a classifier to control the generation. It improves
the condition consistency of the diffusion model. Moreover, a Temporal
Decomposition Reconstruction UNet (TDR-UNet) is established to capture complex
temporal patterns and further improve the quality of the synthetic time series.
Comprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that
the proposed Diff-MTS performs substantially better in terms of diversity,
fidelity, and utility compared with GAN-based methods. These results show that
Diff-MTS facilitates the generation of industrial data, contributing to
intelligent maintenance and the construction of industrial large models.

摘要：工業多元時間序列 (MTS) 是工業領域中關鍵的觀點，讓人們了解機器狀態。然而，由於資料收集困難和隱私問題，可用於建立工業智慧和工業大型模型的資料遠遠不足。因此，工業時間序列資料生成非常重要。現有研究通常應用生成對抗網路 (GAN) 來產生 MTS。然而，由於生成器和鑑別器的聯合訓練，GAN 訓練過程不穩定。本文提出了一個時間增強條件適應擴散模型，稱為 Diff-MTS，用於 MTS 生成。它旨在更好地處理 MTS 資料的複雜時間依賴性和動態性。具體來說，提出了一個條件適應最大均值差異 (Ada-MMD) 方法，用於受控生成 MTS，它不需要分類器來控制生成。它改進了擴散模型的條件一致性。此外，建立了一個時間分解重建 UNet (TDR-UNet) 來捕捉複雜的時間模式，並進一步提高合成時間序列的品質。在 C-MAPSS 和 FEMTO 資料集上的綜合實驗表明，與基於 GAN 的方法相比，所提出的 Diff-MTS 在多樣性、保真度和效用方面表現得顯著更好。這些結果表明，Diff-MTS 促進了工業資料的生成，有助於智慧維護和工業大型模型的構建。

##### **An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data**
2407.11500v1 by Niamh Belton, Aonghus Lawlor, Kathleen M. Curran

The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)
ordinal grading systems has been a subject of on-going debate and concern.
Existing automated solutions are trained to emulate these imperfect systems,
whilst also being reliant on large annotated databases for fully-supervised
training. This work proposes a three stage approach for automated continuous
grading of knee OA that is built upon the principles of Anomaly Detection (AD);
learning a robust representation of healthy knee X-rays and grading disease
severity based on its distance to the centre of normality. In the first stage,
SS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'
representation, requiring only examples of healthy subjects and <3% of the
labels that existing methods require. In the second stage, this model is used
to pseudo label a subset of unlabelled data as 'normal' or 'anomalous',
followed by denoising of pseudo labels with CLIP. The final stage involves
retraining on labelled and pseudo labelled data using the proposed Dual Centre
Representation Learning (DCRL) which learns the centres of two representation
spaces; normal and anomalous. Disease severity is then graded based on the
distance to the learned centres. The proposed methodology outperforms existing
techniques by margins of up to 24% in terms of OA detection and the disease
severity scores correlate with the Kellgren-Lawrence grading system at the same
level as human expert performance. Code available at
https://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.

摘要：現有膝骨關節炎 (OA)
序數分級系統的診斷準確度和主觀性一直是持續爭論和關注的主題。
現有的自動化解決方案經過訓練以模擬這些不完美的系統，
同時也依賴於大型註釋資料庫進行完全監督的
訓練。這項工作提出了一個三階段方法，用於膝骨關節炎的自動連續
分級，該方法建立在異常檢測 (AD) 的原理之上；
學習健康膝蓋 X 光片的穩健表現，並根據其與常態中心的距離對疾病
嚴重程度進行分級。在第一階段，
SS-FewSOME 被提出，這是一種自監督 AD 技術，它學習「正常」
表現，只需要健康受試者的範例和 <3% 現有方法所需的
標籤。在第二階段，此模型用於將未標記資料的子集偽標記為「正常」或「異常」，
接著使用 CLIP 對偽標籤進行去雜訊。最後的階段涉及
使用提出的雙中心表示學習 (DCRL) 對標記和偽標記資料進行重新訓練，該學習學習兩個表示
空間的中心；正常和異常。然後根據
學習中心之間的距離對疾病嚴重程度進行分級。所提出的方法在 OA 檢測方面比現有
技術高出 24%，並且疾病
嚴重程度得分與 Kellgren-Lawrence 分級系統相關，與人類專家表現相同
等級。程式碼可在
https://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis 取得。

##### **MMSD-Net: Towards Multi-modal Stuttering Detection**
2407.11492v1 by Liangyu Nie, Sudarsana Reddy Kadiri, Ruchit Agrawal

Stuttering is a common speech impediment that is caused by irregular
disruptions in speech production, affecting over 70 million people across the
world. Standard automatic speech processing tools do not take speech ailments
into account and are thereby not able to generate meaningful results when
presented with stuttered speech as input. The automatic detection of stuttering
is an integral step towards building efficient, context-aware speech processing
systems. While previous approaches explore both statistical and neural
approaches for stuttering detection, all of these methods are uni-modal in
nature. This paper presents MMSD-Net, the first multi-modal neural framework
for stuttering detection. Experiments and results demonstrate that
incorporating the visual signal significantly aids stuttering detection, and
our model yields an improvement of 2-17% in the F1-score over existing
state-of-the-art uni-modal approaches.

摘要：口吃是一种常见的言语障碍，是由言语产生中的不规则中断所引起的，影响了全球超过 7000 万人。标准的自动语音处理工具不会考虑言语障碍，因此在输入口吃语音时无法生成有意义的结果。口吃的自动检测是构建高效且具有情境感知的语音处理系统中不可或缺的一步。虽然先前的做法探索了统计和神经方法来进行口吃检测，但所有这些方法本质上都是单模态的。本文提出了 MMSD-Net，这是第一个用于口吃检测的多模态神经框架。实验和结果表明，结合视觉信号可以极大地帮助口吃检测，并且我们的模型在 F1 分数上比现有的最先进的单模态方法提高了 2-17%。

##### **A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments**
2407.11489v1 by Junlin Lu, Patrick Mannion, Karl Mason

Effective residential appliance scheduling is crucial for sustainable living.
While multi-objective reinforcement learning (MORL) has proven effective in
balancing user preferences in appliance scheduling, traditional MORL struggles
with limited data in non-stationary residential settings characterized by
renewable generation variations. Significant context shifts that can invalidate
previously learned policies. To address these challenges, we extend
state-of-the-art MORL algorithms with the meta-learning paradigm, enabling
rapid, few-shot adaptation to shifting contexts. Additionally, we employ an
auto-encoder (AE)-based unsupervised method to detect environment context
changes. We have also developed a residential energy environment to evaluate
our method using real-world data from London residential settings. This study
not only assesses the application of MORL in residential appliance scheduling
but also underscores the effectiveness of meta-learning in energy management.
Our top-performing method significantly surpasses the best baseline, while the
trained model saves 3.28% on electricity bills, a 2.74% increase in user
comfort, and a 5.9% improvement in expected utility. Additionally, it reduces
the sparsity of solutions by 62.44%. Remarkably, these gains were accomplished
using 96.71% less training data and 61.1% fewer training steps.

摘要：有效住宅設備排程對於永續生活至關重要。
雖然多目標增強學習 (MORL) 已被證明能有效平衡設備排程中的使用者偏好，但傳統 MORL 在以再生能源變化為特徵的非靜止住宅環境中，會因資料有限而遇到困難。重大的情境轉變可能會使先前學習的政策失效。為了應對這些挑戰，我們使用元學習範例來擴充最先進的 MORL 演算法，實現快速、少量適應變化的情境。此外，我們採用基於自動編碼器 (AE) 的非監督式方法來偵測環境情境變化。我們還開發了一個住宅能源環境，使用來自倫敦住宅環境的真實世界資料來評估我們的做法。本研究不僅評估 MORL 在住宅設備排程中的應用，也強調了元學習在能源管理中的有效性。我們效能最佳的方法顯著超越最佳基準，而訓練後的模型可節省 3.28% 的電費、使用者舒適度提高 2.74%，預期效用改善 5.9%。此外，它還將解的稀疏性降低了 62.44%。值得注意的是，這些進展是使用少 96.71% 的訓練資料和少 61.1% 的訓練步驟所達成的。

##### **Scientific QA System with Verifiable Answers**
2407.11485v1 by Adela Ljajić, Miloš Košprdić, Bojana Bašaragin, Darija Medvecki, Lorenzo Cassano, Nikola Milošević

In this paper, we introduce the VerifAI project, a pioneering open-source
scientific question-answering system, designed to provide answers that are not
only referenced but also automatically vetted and verifiable. The components of
the system are (1) an Information Retrieval system combining semantic and
lexical search techniques over scientific papers (PubMed), (2) a
Retrieval-Augmented Generation (RAG) module using fine-tuned generative model
(Mistral 7B) and retrieved articles to generate claims with references to the
articles from which it was derived, and (3) a Verification engine, based on a
fine-tuned DeBERTa and XLM-RoBERTa models on Natural Language Inference task
using SciFACT dataset. The verification engine cross-checks the generated claim
and the article from which the claim was derived, verifying whether there may
have been any hallucinations in generating the claim. By leveraging the
Information Retrieval and RAG modules, Verif.ai excels in generating factual
information from a vast array of scientific sources. At the same time, the
Verification engine rigorously double-checks this output, ensuring its accuracy
and reliability. This dual-stage process plays a crucial role in acquiring and
confirming factual information, significantly enhancing the information
landscape. Our methodology could significantly enhance scientists'
productivity, concurrently fostering trust in applying generative language
models within scientific domains, where hallucinations and misinformation are
unacceptable.

摘要：在本文中，我們介紹了 VerifAI 計畫，這是一個開創性的開放原始碼科學問答系統，旨在提供不僅有參考依據，而且經過自動審查和驗證的答案。該系統的組成部分為：(1) 一個資訊檢索系統，結合語意和詞彙搜尋技術，用於科學論文(PubMed)；(2) 一個檢索增強生成 (RAG) 模組，使用微調生成模型 (Mistral 7B) 和檢索的文章，透過引述文章生成主張；(3) 一個驗證引擎，基於微調的 DeBERTa 和 XLM-RoBERTa 模型，使用 SciFACT 資料集進行自然語言推論任務。驗證引擎交叉比對產生的主張和主張衍生的文章，驗證在產生主張時是否出現任何幻覺。透過利用資訊檢索和 RAG 模組，Verif.ai 擅長從大量的科學來源產生事實資訊。同時，驗證引擎嚴格地對此輸出進行雙重檢查，確保其準確性和可靠性。這個雙階段流程在獲取和確認事實資訊中發揮關鍵作用，大幅提升資訊環境。我們的做法可以大幅提升科學家的生產力，同時促進在科學領域應用生成語言模型的信任，在該領域中幻覺和錯誤資訊是不可接受的。

##### **The Oscars of AI Theater: A Survey on Role-Playing with Language Models**
2407.11484v2 by Nuo Chen, Yang Deng, Jia Li

This survey explores the burgeoning field of role-playing with language
models, focusing on their development from early persona-based models to
advanced character-driven simulations facilitated by Large Language Models
(LLMs). Initially confined to simple persona consistency due to limited model
capabilities, role-playing tasks have now expanded to embrace complex character
portrayals involving character consistency, behavioral alignment, and overall
attractiveness. We provide a comprehensive taxonomy of the critical components
in designing these systems, including data, models and alignment, agent
architecture and evaluation. This survey not only outlines the current
methodologies and challenges, such as managing dynamic personal profiles and
achieving high-level persona consistency but also suggests avenues for future
research in improving the depth and realism of role-playing applications. The
goal is to guide future research by offering a structured overview of current
methodologies and identifying potential areas for improvement. Related
resources and papers are available at
https://github.com/nuochenpku/Awesome-Role-Play-Papers.

摘要：本調查探討了角色扮演與語言模型的新興領域，重點關注其從早期基於角色的模型發展到由大型語言模型 (LLM) 促成的進階角色驅動模擬。角色扮演任務最初僅限於簡單的角色一致性，因為模型功能有限，現在已擴展到包含角色一致性、行為對齊和整體吸引力的複雜角色描繪。我們提供了這些系統設計中關鍵組成的全面分類，包括資料、模型和對齊、代理架構和評估。本調查不僅概述了當前的方法和挑戰，例如管理動態個人檔案和實現高階角色一致性，還提出了改進角色扮演應用深度和真實性的未來研究途徑。目標是透過提供當前方法的結構化概觀和找出潛在的改進領域，來引導未來的研究。相關資源和論文可於 https://github.com/nuochenpku/Awesome-Role-Play-Papers 取得。

##### **Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**
2407.11481v1 by Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong

In the context of cardiovascular diseases (CVD) that exhibit an elevated
prevalence and mortality, the electrocardiogram (ECG) is a popular and standard
diagnostic tool for doctors, commonly utilizing a 12-lead configuration in
clinical practice. However, the 10 electrodes placed on the surface would cause
a lot of inconvenience and discomfort, while the rapidly advancing wearable
devices adopt the reduced-lead or single-lead ECG to reduce discomfort as a
solution in long-term monitoring. Since the single-lead ECG is a subset of
12-lead ECG, it provides insufficient cardiac health information and plays a
substandard role in real-world healthcare applications. Hence, it is necessary
to utilize signal generation technologies to reduce their clinical importance
gap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,
this study proposes a multi-channel masked autoencoder (MCMA) for this goal. In
the experimental results, the visualized results between the generated and real
signals can demonstrate the effectiveness of the proposed framework. At the
same time, this study introduces a comprehensive evaluation benchmark named
ECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level
evaluations, providing a holistic assessment of 12-lead ECG signals and
generative model. Further, the quantitative experimental results are as
follows, the mean square errors of 0.0178 and 0.0658, correlation coefficients
of 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with
two generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level
evaluation, achieving the state-of-the-art performance. The open-source code is
publicly available at \url{https://github.com/CHENJIAR3/MCMA}.

摘要：<paragraph>在表現出高盛行率和死亡率的心血管疾病 (CVD) 的情況下，心電圖 (ECG) 是一種醫生常用的標準診斷工具，在臨床實務中通常使用 12 導程組態。然而，放置在表面的 10 個電極會造成許多不便和不適，而快速進步的可穿戴式裝置採用減少導程或單導程 ECG 來降低不適，作為長期監測的解決方案。由於單導程 ECG 是 12 導程 ECG 的子集，它提供的健康資訊不足，在真實世界的醫療保健應用中扮演著次標準的角色。因此，有必要利用訊號產生技術來縮小其臨床重要性差距，方法是從真實的單導程 ECG 重建 12 導程 ECG。具體來說，本研究提出了一個多通道遮罩自動編碼器 (MCMA) 來達成此目標。在實驗結果中，生成的訊號與真實訊號之間的可視化結果可以證明所提出架構的有效性。同時，本研究引入了稱為 ECGGenEval 的綜合評估基準，涵蓋訊號層級、特徵層級和診斷層級評估，提供 12 導程 ECG 訊號和生成模型的整體評估。此外，定量的實驗結果如下，在訊號層級評估中，均方誤差為 0.0178 和 0.0658，相關係數為 0.7698 和 0.7237，在診斷層級評估中，兩個生成的 12 導程 ECG 的平均 F1 分數為 0.8319 和 0.7824，達到了最先進的效能。開放原始碼可以在 \url{https://github.com/CHENJIAR3/MCMA} 公開取得。</paragraph>

##### **AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models**
2407.11480v1 by Lei Ren, Haiteng Wang, Yang Tang, Chunhua Yang

With the remarkable success of generative models like ChatGPT, Artificial
Intelligence Generated Content (AIGC) is undergoing explosive development. Not
limited to text and images, generative models can generate industrial time
series data, addressing challenges such as the difficulty of data collection
and data annotation. Due to their outstanding generation ability, they have
been widely used in Internet of Things, metaverse, and cyber-physical-social
systems to enhance the efficiency of industrial production. In this paper, we
present a comprehensive overview of generative models for industrial time
series from deep generative models (DGMs) to large generative models (LGMs).
First, a DGM-based AIGC framework is proposed for industrial time series
generation. Within this framework, we survey advanced industrial DGMs and
present a multi-perspective categorization. Furthermore, we systematically
analyze the critical technologies required to construct industrial LGMs from
four aspects: large-scale industrial dataset, LGMs architecture for complex
industrial characteristics, self-supervised training for industrial time
series, and fine-tuning of industrial downstream tasks. Finally, we conclude
the challenges and future directions to enable the development of generative
models in industry.

摘要：隨著 ChatGPT 等生成式模型的顯著成功，人工智慧生成內容 (AIGC) 正經歷爆炸性的發展。生成式模型不僅限於文字和影像，還能生成工業時間序列資料，解決資料收集和資料標註的困難等挑戰。由於其出色的生成能力，已廣泛應用於物聯網、元宇宙和網路物理社會系統中，以提高工業生產的效率。在本文中，我們對工業時間序列的生成式模型進行了全面的概述，從深度生成式模型 (DGM) 到大型生成式模型 (LGM)。首先，提出了一個基於 DGM 的 AIGC 架構，用於生成工業時間序列。在這個架構中，我們調查了先進的工業 DGM，並提出了多角度分類。此外，我們從大型工業資料集、複雜工業特徵的 LGM 架構、工業時間序列的自監督訓練和工業下游任務的微調等四個方面，系統地分析了構建工業 LGM 所需的關鍵技術。最後，我們總結了挑戰和未來的方向，以促進生成式模型在工業中的發展。

##### **XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More**
2407.11477v1 by Xiaochuan Gou, Ziyue Li, Tian Lan, Junpeng Lin, Zhishuai Li, Bingyu Zhao, Chen Zhang, Di Wang, Xiangliang Zhang

Long-separated research has been conducted on two highly correlated tracks:
traffic and incidents. Traffic track witnesses complicating deep learning
models, e.g., to push the prediction a few percent more accurate, and the
incident track only studies the incidents alone, e.g., to infer the incident
risk. We, for the first time, spatiotemporally aligned the two tracks in a
large-scale region (16,972 traffic nodes) over the whole year of 2023: our
XTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,
lane occupancy, and average vehicle speed, and incidents, whose records are
spatiotemporally-aligned with traffic data, with seven different incident
classes. Additionally, each node includes detailed physical and policy-level
meta-attributes of lanes. Our data can revolutionalize traditional
traffic-related tasks towards higher interpretability and practice: instead of
traditional prediction or classification tasks, we conduct: (1) post-incident
traffic forecasting to quantify the impact of different incidents on traffic
indexes; (2) incident classification using traffic indexes to determine the
incidents types for precautions measures; (3) global causal analysis among the
traffic indexes, meta-attributes, and incidents to give high-level guidance of
the interrelations of various factors; (4) local causal analysis within road
nodes to examine how different incidents affect the road segments' relations.
The dataset is available at http://xaitraffic.github.io.

摘要：<paragraph>長期以來，針對兩個高度相關的軌道進行了分開的研究：
交通和事故。交通軌道見證了複雜的深度學習
模型，例如，將預測再提高幾個百分點的準確度，而
事故軌道僅研究單獨的事故，例如，推論事故
風險。我們首次在
大規模區域（16,972 個交通節點）中時空對齊了這兩個軌道
2023 年全年：我們的
XTraffic 數據集包括交通，即交通流量的時間序列索引，
車道占用率和平均車速，以及事故，其記錄與交通數據在時空中對齊，有七個不同的事故
類別。此外，每個節點都包含車道的詳細物理和政策級
元屬性。我們的數據可以徹底改變傳統的
與交通相關的任務，提高可解釋性和實踐性：而不是
傳統的預測或分類任務，我們進行：(1) 事後事故
交通預測，以量化不同事故對交通的影響
索引；(2) 使用交通索引的事故分類，以確定事故
預防措施的類型；(3) 交通索引之間的全局因果分析，
元屬性和事故，以提供各種因素相互關係的高級指導；(4) 道路內的局部因果分析
節點，以檢查不同事故如何影響道路路段的關係。
該數據集可在 http://xaitraffic.github.io 上獲得。</paragraph>

##### **DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems**
2407.11472v1 by Kaibo He, Chenhui Zuo, Chengtian Ma, Yanan Sui

Learning an effective policy to control high-dimensional, overactuated
systems is a significant challenge for deep reinforcement learning algorithms.
Such control scenarios are often observed in the neural control of vertebrate
musculoskeletal systems. The study of these control mechanisms will provide
insights into the control of high-dimensional, overactuated systems. The
coordination of actuators, known as muscle synergies in neuromechanics, is
considered a presumptive mechanism that simplifies the generation of motor
commands. The dynamical structure of a system is the basis of its function,
allowing us to derive a synergistic representation of actuators. Motivated by
this theory, we propose the Dynamical Synergistic Representation (DynSyn)
algorithm. DynSyn aims to generate synergistic representations from dynamical
structures and perform task-specific, state-dependent adaptation to the
representations to improve motor control. We demonstrate DynSyn's efficiency
across various tasks involving different musculoskeletal models, achieving
state-of-the-art sample efficiency and robustness compared to baseline
algorithms. DynSyn generates interpretable synergistic representations that
capture the essential features of dynamical structures and demonstrates
generalizability across diverse motor tasks.

摘要：學習一個有效策略來控制高維度、過度驅動的系統，對於深度強化學習演算法來說是一個重大的挑戰。
這種控制場景通常在脊椎動物肌肉骨骼系統的神經控制中觀察到。
對這些控制機制的探討，將提供對高維度、過度驅動系統控制的見解。
在神經力學中稱為肌肉協同作用的致動器協調，被認為是一種簡化運動指令產生的假設機制。
系統的動態結構是其功能的基礎，使我們能夠推導出致動器的協同表示。
受到這個理論的啟發，我們提出了動態協同表示 (DynSyn) 演算法。
DynSyn 旨在從動態結構中產生協同表示，並對表示執行特定於任務的狀態依賴性適應，以改善運動控制。
我們展示了 DynSyn 在涉及不同肌肉骨骼模型的各種任務中的效率，與基線演算法相比，達到了最先進的樣本效率和穩健性。
DynSyn 產生可解釋的協同表示，捕捉動態結構的本質特徵，並展示了跨不同運動任務的泛化性。

##### **Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models**
2407.11470v1 by Jiasheng Zheng, Boxi Cao, Zhengzhao Ma, Ruotong Pan, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun

In recent years, researchers have proposed numerous benchmarks to evaluate
the impressive coding capabilities of large language models (LLMs). However,
existing benchmarks primarily focus on assessing the correctness of code
generated by LLMs, while neglecting other critical dimensions that also
significantly impact code quality. Therefore, this paper proposes the RACE
benchmark, which comprehensively evaluates the quality of code generated by
LLMs across 4 dimensions: Readability, mAintainability, Correctness, and
Efficiency. Specifically, considering the demand-dependent nature of dimensions
beyond correctness, we design various types of user requirements for each
dimension to assess the model's ability to generate correct code that also
meets user demands. We evaluate 18 representative LLMs on RACE and find that:
1) the current LLMs' ability to generate high-quality code on demand does not
yet meet the requirements of software development; 2) readability serves as a
critical indicator of the overall quality of generated code; 3) most LLMs
exhibit an inherent preference for specific coding style. These findings can
help researchers gain a deeper understanding of the coding capabilities of
current LLMs and shed light on future directions for model improvement.

摘要：近年来，研究人员提出了许多基准来评估大型语言模型 (LLM) 令人印象深刻的编码能力。然而，现有的基准主要侧重于评估 LLM 生成的代码的正确性，而忽略了其他也显著影响代码质量的关键维度。因此，本文提出了 RACE 基准，它全面评估了 LLM 生成的代码在 4 个维度上的质量：可读性、可维护性、正确性和效率。具体来说，考虑到正确性之外的维度对需求的依赖性，我们为每个维度设计了不同类型的用户需求，以评估模型生成正确代码的能力，同时满足用户需求。我们在 RACE 上评估了 18 个具有代表性的 LLM，发现：1）当前 LLM 根据需求生成高质量代码的能力尚未达到软件开发的要求；2）可读性是生成代码整体质量的关键指标；3）大多数 LLM 对特定的编码风格表现出固有的偏好。这些发现可以帮助研究人员更深入地了解当前 LLM 的编码能力，并为模型改进的未来方向提供启示。

##### **Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis**
2407.11463v1 by Zhipeng He, Chun Ouyang, Laith Alzubaidi, Alistair Barros, Catarina Moreira

Adversarial attacks are a potential threat to machine learning models, as
they can cause the model to make incorrect predictions by introducing
imperceptible perturbations to the input data. While extensively studied in
unstructured data like images, their application to structured data like
tabular data presents unique challenges due to the heterogeneity and intricate
feature interdependencies of tabular data. Imperceptibility in tabular data
involves preserving data integrity while potentially causing misclassification,
underscoring the need for tailored imperceptibility criteria for tabular data.
However, there is currently a lack of standardised metrics for assessing
adversarial attacks specifically targeted at tabular data. To address this gap,
we derive a set of properties for evaluating the imperceptibility of
adversarial attacks on tabular data. These properties are defined to capture
seven perspectives of perturbed data: proximity to original inputs, sparsity of
alterations, deviation to datapoints in the original dataset, sensitivity of
altering sensitive features, immutability of perturbation, feasibility of
perturbed values and intricate feature interdepencies among tabular features.
Furthermore, we conduct both quantitative empirical evaluation and case-based
qualitative examples analysis for seven properties. The evaluation reveals a
trade-off between attack success and imperceptibility, particularly concerning
proximity, sensitivity, and deviation. Although no evaluated attacks can
achieve optimal effectiveness and imperceptibility simultaneously, unbounded
attacks prove to be more promised for tabular data in crafting imperceptible
adversarial examples. The study also highlights the limitation of evaluated
algorithms in controlling sparsity effectively. We suggest incorporating a
sparsity metric in future attack design to regulate the number of perturbed
features.

摘要：對抗攻擊對機器學習模型來說是一個潛在的威脅，因為它們會透過在輸入資料中引入難以察覺的擾動，導致模型做出不正確的預測。雖然在影像等非結構化資料中已廣泛研究，但由於表格資料的異質性和複雜的特性相互依賴性，將其應用於表格資料等結構化資料會帶來獨特的挑戰。表格資料中的難以察覺性涉及在潛在導致錯誤分類的同時，保持資料的完整性，這凸顯了為表格資料量身打造難以察覺性標準的必要性。然而，目前針對表格資料的對抗攻擊評估標準化指標仍有不足。為了解決這個差距，我們推導出一組用於評估表格資料對抗攻擊難以察覺性的屬性。這些屬性被定義為捕捉擾動資料的七個觀點：與原始輸入的接近程度、變動的稀疏性、與原始資料集中資料點的偏差、變動敏感特性的敏感性、擾動的不變性、擾動值的可能性，以及表格特性之間複雜的特性相互依賴性。此外，我們對七個屬性進行定量實證評估和基於案例的定性範例分析。評估結果揭示了攻擊成功與難以察覺性之間的權衡，特別是關於接近度、敏感性和偏差。儘管沒有評估的攻擊可以同時達到最佳的有效性和難以察覺性，但無界攻擊被證明在製作難以察覺的對抗範例方面對表格資料更有前景。研究還強調了評估演算法在有效控制稀疏性方面的限制。我們建議在未來的攻擊設計中納入稀疏性指標，以規範擾動特性的數量。

##### **Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights**
2407.11449v1 by Shunqi Mao, Chaoyi Zhang, Hang Su, Hwanjun Song, Igor Shalyminov, Weidong Cai

Contextualized Image Captioning (CIC) evolves traditional image captioning
into a more complex domain, necessitating the ability for multimodal reasoning.
It aims to generate image captions given specific contextual information. This
paper further introduces a novel domain of Controllable Contextualized Image
Captioning (Ctrl-CIC). Unlike CIC, which solely relies on broad context,
Ctrl-CIC accentuates a user-defined highlight, compelling the model to tailor
captions that resonate with the highlighted aspects of the context. We present
two approaches, Prompting-based Controller (P-Ctrl) and Recalibration-based
Controller (R-Ctrl), to generate focused captions. P-Ctrl conditions the model
generation on highlight by prepending captions with highlight-driven prefixes,
whereas R-Ctrl tunes the model to selectively recalibrate the encoder
embeddings for highlighted tokens. Additionally, we design a GPT-4V empowered
evaluator to assess the quality of the controlled captions alongside standard
assessment methods. Extensive experimental results demonstrate the efficient
and effective controllability of our method, charting a new direction in
achieving user-adaptive image captioning. Code is available at
https://github.com/ShunqiM/Ctrl-CIC .

摘要：语境图像描述 (CIC) 将传统图像描述演变为更复杂的领域，需要多模态推理的能力。它旨在根据特定的语境信息生成图像描述。本文进一步介绍了可控语境图像描述 (Ctrl-CIC) 的一个新领域。与仅依赖广泛语境的 CIC 不同，Ctrl-CIC 强调用户定义的重点，迫使模型定制与语境中突出方面产生共鸣的描述。我们提出了两种方法，基于提示的控制器 (P-Ctrl) 和基于重新校准的控制器 (R-Ctrl)，以生成重点描述。P-Ctrl 通过使用突出驱动的前缀来添加突出显示，对模型生成进行条件化，而 R-Ctrl 调整模型以选择性地重新校准突出标记的编码器嵌入。此外，我们设计了一个由 GPT-4V 驱动的评估器来评估受控描述的质量以及标准评估方法。广泛的实验结果证明了我们方法的高效和有效可控性，为实现用户自适应图像描述指明了一个新方向。代码可在 https://github.com/ShunqiM/Ctrl-CIC 获得。

##### **EARN Fairness: Explaining, Asking, Reviewing and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders**
2407.11442v1 by Lin Luo, Yuri Nakao, Mathieu Chollet, Hiroya Inakoshi, Simone Stumpf

Numerous fairness metrics have been proposed and employed by artificial
intelligence (AI) experts to quantitatively measure bias and define fairness in
AI models. Recognizing the need to accommodate stakeholders' diverse fairness
understandings, efforts are underway to solicit their input. However, conveying
AI fairness metrics to stakeholders without AI expertise, capturing their
personal preferences, and seeking a collective consensus remain challenging and
underexplored. To bridge this gap, we propose a new framework, EARN Fairness,
which facilitates collective metric decisions among stakeholders without
requiring AI expertise. The framework features an adaptable interactive system
and a stakeholder-centered EARN Fairness process to Explain fairness metrics,
Ask stakeholders' personal metric preferences, Review metrics collectively, and
Negotiate a consensus on metric selection. To gather empirical results, we
applied the framework to a credit rating scenario and conducted a user study
involving 18 decision subjects without AI knowledge. We identify their personal
metric preferences and their acceptable level of unfairness in individual
sessions. Subsequently, we uncovered how they reached metric consensus in team
sessions. Our work shows that the EARN Fairness framework enables stakeholders
to express personal preferences and reach consensus, providing practical
guidance for implementing human-centered AI fairness in high-risk contexts.
Through this approach, we aim to harmonize fairness expectations of diverse
stakeholders, fostering more equitable and inclusive AI fairness.

摘要：人工智能 (AI) 專家已提出並採用許多公平性指標，以量化衡量偏見並定義 AI 模型中的公平性。認識到需要適應利害關係人對公平性的不同理解，目前正努力徵求他們的意見。然而，向沒有 AI 專業知識的利害關係人傳達 AI 公平性指標、掌握他們的個人偏好，並尋求集體共識仍然具有挑戰性，且尚未充分探討。為了彌合這一差距，我們提出一個新的架構，EARN 公平性，它可以在不需 AI 專業知識的情況下，促進利害關係人之間的集體指標決策。該架構具有適應性互動系統，以及以利害關係人為中心的 EARN 公平性流程，用於說明公平性指標、詢問利害關係人的個人指標偏好、共同檢視指標，並協商指標選擇的共識。為了收集實證結果，我們將此架構應用於信用評分情境，並進行了一項使用者研究，其中包含 18 位沒有 AI 知識的決策主體。我們在個別會議中找出他們的個人指標偏好和他們可接受的不公平程度。隨後，我們揭露他們如何在團隊會議中達成指標共識。我們的研究顯示，EARN 公平性架構讓利害關係人能夠表達個人偏好並達成共識，為在高風險環境中實施以人為中心的 AI 公平性提供實務指導。透過此方法，我們旨在調和不同利害關係人的公平性期望，促進更公平且包容的 AI 公平性。

##### **Repurformer: Transformers for Repurposing-Aware Molecule Generation**
2407.11439v1 by Changhun Lee, Gyumin Lee

Generating as diverse molecules as possible with desired properties is
crucial for drug discovery research, which invokes many approaches based on
deep generative models today. Despite recent advancements in these models,
particularly in variational autoencoders (VAEs), generative adversarial
networks (GANs), Transformers, and diffusion models, a significant challenge
known as \textit{the sample bias problem} remains. This problem occurs when
generated molecules targeting the same protein tend to be structurally similar,
reducing the diversity of generation. To address this, we propose leveraging
multi-hop relationships among proteins and compounds. Our model, Repurformer,
integrates bi-directional pretraining with Fast Fourier Transform (FFT) and
low-pass filtering (LPF) to capture complex interactions and generate diverse
molecules. A series of experiments on BindingDB dataset confirm that
Repurformer successfully creates substitutes for anchor compounds that resemble
positive compounds, increasing diversity between the anchor and generated
compounds.

摘要：要生成具有所需属性的尽可能多樣化的分子對於藥物發現研究至關重要，這項研究採用了許多基於深度生成模型的方法。儘管這些模型最近有了進展，特別是在變分自編碼器 (VAE)、生成對抗網路 (GAN)、Transformer和擴散模型方面，但仍存在一個重大的挑戰，稱為「樣本偏差問題」。當針對同一蛋白質產生的分子在結構上傾向於相似時，就會發生這個問題，進而降低生成的樣本多樣性。為了解決這個問題，我們建議利用蛋白質和化合物之間的多跳關係。我們的模型 Repurformer 將雙向預訓練與快速傅立葉轉換 (FFT) 和低通濾波 (LPF) 整合在一起，以捕捉複雜的交互作用並生成多樣化的分子。一系列針對 BindingDB 資料集的實驗證實，Repurformer 成功地為錨定化合物創造了替代物，這些替代物類似於正向化合物，增加了錨定化合物和生成化合物之間的多樣性。

##### **Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild**
2407.11438v1 by Niloofar Mireshghallah, Maria Antoniak, Yash More, Yejin Choi, Golnoosh Farnadi

Measuring personal disclosures made in human-chatbot interactions can provide
a better understanding of users' AI literacy and facilitate privacy research
for large language models (LLMs). We run an extensive, fine-grained analysis on
the personal disclosures made by real users to commercial GPT models,
investigating the leakage of personally identifiable and sensitive information.
To understand the contexts in which users disclose to chatbots, we develop a
taxonomy of tasks and sensitive topics, based on qualitative and quantitative
analysis of naturally occurring conversations. We discuss these potential
privacy harms and observe that: (1) personally identifiable information (PII)
appears in unexpected contexts such as in translation or code editing (48% and
16% of the time, respectively) and (2) PII detection alone is insufficient to
capture the sensitive topics that are common in human-chatbot interactions,
such as detailed sexual preferences or specific drug use habits. We believe
that these high disclosure rates are of significant importance for researchers
and data curators, and we call for the design of appropriate nudging mechanisms
to help users moderate their interactions.

摘要：透過衡量人類與聊天機器人互動中所做的個人揭露，可以更了解使用者的 AI 素養，並促進大型語言模型 (LLM) 的隱私研究。我們對真實使用者對商業 GPT 模型所做的個人揭露進行廣泛的細緻分析，調查個人可識別和敏感資訊的洩漏。為了了解使用者在哪些情況下對聊天機器人揭露資訊，我們根據自然發生的對話進行定性和定量分析，制定了一套任務和敏感主題分類法。我們討論這些潛在的隱私危害，並觀察到：(1) 個人可識別資訊 (PII) 出現在意想不到的情況中，例如翻譯或程式碼編輯中 (分別為 48% 和 16% 的時間)，以及 (2) 僅 PII 偵測不足以掌握在人類與聊天機器人互動中常見的敏感主題，例如詳細的性偏好或特定的藥物使用習慣。我們相信這些高揭露率對研究人員和資料管理員來說非常重要，我們呼籲設計適當的推動機制來幫助使用者調節他們的互動。

##### **Generally-Occurring Model Change for Robust Counterfactual Explanations**
2407.11426v1 by Ao Xu, Tieru Wu

With the increasing impact of algorithmic decision-making on human lives, the
interpretability of models has become a critical issue in machine learning.
Counterfactual explanation is an important method in the field of interpretable
machine learning, which can not only help users understand why machine learning
models make specific decisions, but also help users understand how to change
these decisions. Naturally, it is an important task to study the robustness of
counterfactual explanation generation algorithms to model changes. Previous
literature has proposed the concept of Naturally-Occurring Model Change, which
has given us a deeper understanding of robustness to model change. In this
paper, we first further generalize the concept of Naturally-Occurring Model
Change, proposing a more general concept of model parameter changes,
Generally-Occurring Model Change, which has a wider range of applicability. We
also prove the corresponding probabilistic guarantees. In addition, we consider
a more specific problem, data set perturbation, and give relevant theoretical
results by combining optimization theory.

摘要：隨著演算法決策對人類生活產生越來越大的影響，模型的可解釋性已成為機器學習中的一個關鍵問題。反事實解釋是可解釋機器學習領域中的一種重要方法，它不僅可以幫助使用者了解機器學習模型做出特定決策的原因，還可以幫助使用者了解如何改變這些決策。自然地，研究反事實解釋生成演算法對模型變化的穩健性是一項重要的任務。先前的文獻提出了自然發生的模型變化的概念，這讓我們對模型變化的穩健性有了更深入的了解。在本文中，我們首先進一步概括自然發生的模型變化的概念，提出了一個更通用的模型參數變化的概念，即普遍發生的模型變化，它具有更廣泛的適用性。我們也證明了相應的機率保證。此外，我們考慮了一個更具體的問題，即資料集擾動，並透過結合最佳化理論給出相關的理論結果。

##### **States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly**
2407.11421v1 by Junhao Chen, Shengding Hu, Zhiyuan Liu, Maosong Sun

Large Language Models (LLMs) exhibit various emergent abilities. Among these
abilities, some might reveal the internal working mechanisms of models. In this
paper, we uncover a novel emergent capability in models: the intrinsic ability
to perform extended sequences of calculations without relying on
chain-of-thought step-by-step solutions. Remarkably, the most advanced models
can directly output the results of two-digit number additions with lengths
extending up to 15 addends. We hypothesize that the model emerges Implicit
Discrete State Representations (IDSRs) within its hidden states and performs
symbolic calculations internally. To test this hypothesis, we design a sequence
of experiments that look into the hidden states. Specifically, we first confirm
that IDSRs exist. Then, we provide interesting observations about the formation
of IDSRs from layer, digit, and sequence perspectives. Finally, we confirm that
models indeed use IDSRs to produce the final answers. However, we also discover
that these state representations are far from lossless in current open-sourced
models, leading to inaccuracies in their final performance. Our work presents a
novel exploration of LLMs' symbolic calculation abilities and the underlying
mechanisms.

摘要：大型語言模型 (LLM) 展現出各種新興的能力。在這些能力中，有些可能揭示了模型的內部工作機制。在本文中，我們發現了模型中一種新興的新能力：在不依賴於逐步的思維鏈解決方案的情況下執行擴展的計算序列的內在能力。值得注意的是，最先進的模型可以直接輸出兩位數加法的結果，長度長達 15 個加數。我們假設模型在其隱藏狀態中出現了隱含離散狀態表示 (IDSR)，並在內部執行符號計算。為了驗證這個假設，我們設計了一系列實驗來研究隱藏狀態。具體來說，我們首先確認 IDSR 確實存在。然後，我們提供了關於從層、數字和序列角度形成 IDSR 的有趣觀察。最後，我們確認模型確實使用 IDSR 來產生最終答案。然而，我們也發現這些狀態表示遠非當前開源模型中的無損失，導致其最終性能不準確。我們的研究展示了對 LLM 的符號計算能力和底層機制的探索。

##### **LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data**
2407.11418v1 by Liana Patel, Siddharth Jha, Carlos Guestrin, Matei Zaharia

The semantic capabilities of language models (LMs) have the potential to
enable rich analytics and reasoning over vast knowledge corpora. Unfortunately,
existing systems lack high-level abstractions to perform semantic queries at
scale. We introduce semantic operators, a declarative programming interface
that extends the relational model with composable AI-based operations for
semantic queries over datasets (e.g., sorting or aggregating records using
natural language criteria). Each operator can be implemented and optimized in
multiple ways, opening a rich space for execution plans similar to relational
operators. We implement our operators and several optimizations for them in
LOTUS, an open-source query engine with a Pandas-like API.
  We demonstrate LOTUS' effectiveness across a series of real applications,
including fact-checking, extreme multi-label classification, and search. We
find that LOTUS' programming model is highly expressive, capturing
state-of-the-art query pipelines with low development overhead. Specifically,
on the FEVER dataset, LOTUS' programs can reproduce FacTool, a recent
state-of-the-art fact-checking pipeline, in few lines of code, and implement a
new pipeline that improves accuracy by $9.5\%$, while offering $7-34\times$
lower execution time. In the extreme multi-label classification task on the
BioDEX dataset, LOTUS reproduces state-of-the art result quality with its join
operator, while providing an efficient algorithm that runs $800\times$ faster
than a naive join. In the search and ranking application, LOTUS allows a simple
composition of operators to achieve $5.9 - 49.4\%$ higher nDCG@10 than the
vanilla retriever and re-ranker, while also providing query efficiency, with
$1.67 - 10\times$ lower execution time than LM-based ranking methods used by
prior works. LOTUS is publicly available at
https://github.com/stanford-futuredata/lotus.

摘要：<paragraph>語言模型 (LM) 的語義功能有潛力能針對龐大的知識資料庫進行豐富的分析和推理。不幸的是，現有的系統缺乏高階抽象，無法大規模執行語義查詢。我們引入了語義運算子，這是一種宣告式程式設計介面，它擴充了關係模型，並透過語義查詢資料集（例如，使用自然語言準則對記錄進行排序或彙總）的 AI 為基礎運算進行組合。每個運算子都可以透過多種方式實作和最佳化，為類似於關係運算子的執行計畫開啟了豐富的空間。我們在 LOTUS 中實作了我們的運算子以及它們的若干最佳化，LOTUS 是一個開源查詢引擎，具有類似 Pandas 的 API。
我們透過一系列實際應用展示了 LOTUS 的效能，包括事實查核、極端多標籤分類和搜尋。我們發現 LOTUS 的程式設計模型極具表現力，可以擷取最先進的查詢管線，且開發成本低。特別是在 FEVER 資料集上，LOTUS 的程式可以用幾行程式碼複製 FacTool，這是一個最近最先進的事實查核管線，並實作一個新的管線，將準確率提高了 9.5%，同時執行時間降低了 7-34 倍。在 BioDEX 資料集上的極端多標籤分類任務中，LOTUS 使用其聯結運算子複製了最先進的結果品質，同時提供了一個高效的演算法，執行速度比單純聯結快了 800 倍。在搜尋和排名應用程式中，LOTUS 允許簡單地組合運算子，以實現比香草檢索器和重新排名器高 5.9 - 49.4% 的 nDCG@10，同時也提供查詢效率，執行時間比先前工作使用的基於 LM 的排名方法低 1.67 - 10 倍。LOTUS 已公開於 https://github.com/stanford-futuredata/lotus。</paragraph>

##### **SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions**
2407.11417v1 by Shicheng Liu, Sina J. Semnani, Harold Triedman, Jialiang Xu, Isaac Dan Zhao, Monica S. Lam

Recent work integrating Large Language Models (LLMs) has led to significant
improvements in the Knowledge Base Question Answering (KBQA) task. However, we
posit that existing KBQA datasets that either have simple questions, use
synthetically generated logical forms, or are based on small knowledge base
(KB) schemas, do not capture the true complexity of KBQA tasks.
  To address this, we introduce the SPINACH dataset, an expert-annotated KBQA
dataset collected from forum discussions on Wikidata's "Request a Query" forum
with 320 decontextualized question-SPARQL pairs. Much more complex than
existing datasets, SPINACH calls for strong KBQA systems that do not rely on
training data to learn the KB schema, but can dynamically explore large and
often incomplete schemas and reason about them.
  Along with the dataset, we introduce the SPINACH agent, a new KBQA approach
that mimics how a human expert would write SPARQLs for such challenging
questions. Experiments on existing datasets show SPINACH's capability in KBQA,
achieving a new state of the art on the QALD-7, QALD-9 Plus and QALD-10
datasets by 30.1%, 27.0%, and 10.0% in F1, respectively, and coming within 1.6%
of the fine-tuned LLaMA SOTA model on WikiWebQuestions. On our new SPINACH
dataset, SPINACH agent outperforms all baselines, including the best
GPT-4-based KBQA agent, by 38.1% in F1.

摘要：<paragraph>最近整合大型语言模型 (LLM) 的工作已大幅改善知识库问答 (KBQA) 任务。然而，我们认为现有的 KBQA 数据集要么有简单的问题，要么使用合成生成的逻辑形式，或者基于小型知识库 (KB) 架构，并未捕捉到 KBQA 任务的真正复杂性。
为解决这个问题，我们引入了 SPINACH 数据集，这是一个从 Wikidata 的「请求查询」论坛上的论坛讨论中收集的专家注释 KBQA 数据集，其中有 320 个去语境化的 question-SPARQL 对。SPINACH 比现有数据集复杂得多，需要强大的 KBQA 系统，这些系统不依赖训练数据来学习 KB 架构，但可以动态探索大型且通常不完整的架构并对其进行推理。
除了数据集之外，我们还引入了 SPINACH agent，这是一种新的 KBQA 方法，它模仿人类专家如何为如此具有挑战性的问题编写 SPARQL。现有数据集上的实验显示了 SPINACH 在 KBQA 中的能力，在 QALD-7、QALD-9 Plus 和 QALD-10 数据集上分别以 F1 分别提高了 30.1%、27.0% 和 10.0%，并且在 WikiWebQuestions 上达到微调的 LLaMA SOTA 模型的 1.6%。在我们的新 SPINACH 数据集上，SPINACH agent 在 F1 上优于所有基准，包括基于 GPT-4 的最佳 KBQA agent，提高了 38.1%。</paragraph>

##### **Representation Bias in Political Sample Simulations with Large Language Models**
2407.11409v1 by Weihong Qi, Hanjia Lyu, Jiebo Luo

This study seeks to identify and quantify biases in simulating political
samples with Large Language Models, specifically focusing on vote choice and
public opinion. Using the GPT-3.5-Turbo model, we leverage data from the
American National Election Studies, German Longitudinal Election Study, Zuobiao
Dataset, and China Family Panel Studies to simulate voting behaviors and public
opinions. This methodology enables us to examine three types of representation
bias: disparities based on the the country's language, demographic groups, and
political regime types. The findings reveal that simulation performance is
generally better for vote choice than for public opinions, more accurate in
English-speaking countries, more effective in bipartisan systems than in
multi-partisan systems, and stronger in democratic settings than in
authoritarian regimes. These results contribute to enhancing our understanding
and developing strategies to mitigate biases in AI applications within the
field of computational social science.

摘要：本研究旨在識別和量化使用大型語言模型模擬政治樣本中的偏差，特別關注投票選擇和民意。使用 GPT-3.5-Turbo 模型，我們利用美國國家選舉研究、德國縱向選舉研究、座標數據集和中國家庭追蹤調查的數據來模擬投票行為和民意。這種方法使我們能夠檢查三種類型的代表性偏差：基於國家語言、人口群體和政治制度類型的差異。研究結果表明，模擬效能通常在投票選擇方面優於民意，在英語國家更準確，在兩黨制系統中比在多黨制系統中更有效，在民主環境中比在威權政權中更強。這些結果有助於加深我們對計算社會科學領域內人工智能應用偏差的理解，並制定策略來減輕偏差。

##### **Revisiting the Impact of Pursuing Modularity for Code Generation**
2407.11406v1 by Deokyeong Kang, Ki Jung Seo, Taeuk Kim

Modular programming, which aims to construct the final program by integrating
smaller, independent building blocks, has been regarded as a desirable practice
in software development. However, with the rise of recent code generation
agents built upon large language models (LLMs), a question emerges: is this
traditional practice equally effective for these new tools? In this work, we
assess the impact of modularity in code generation by introducing a novel
metric for its quantitative measurement. Surprisingly, unlike conventional
wisdom on the topic, we find that modularity is not a core factor for improving
the performance of code generation models. We also explore potential
explanations for why LLMs do not exhibit a preference for modular code compared
to non-modular code.

摘要：模組化程式設計旨在透過整合較小、獨立的建構區塊來建構最終程式，一直被視為軟體開發中理想的做法。然而，隨著建立於大型語言模型 (LLM) 的最新程式碼產生代理程式興起，一個問題浮現：這種傳統做法對於這些新工具是否同樣有效？在這項工作中，我們透過引進一種用於量化測量的新穎指標來評估模組化對程式碼產生的影響。令人驚訝的是，與該主題上的傳統智慧不同，我們發現模組化並非改善程式碼產生模型效能的核心因素。我們也探討了 LLM 與非模組化程式碼相比，為何不偏好模組化程式碼的潛在解釋。

##### **DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation**
2407.11394v1 by Jiwook Kim, Seonho Lee, Jaeyo Shin, Jiho Choi, Hyunjung Shim

Score distillation sampling (SDS) has emerged as an effective framework in
text-driven 3D editing tasks due to its inherent 3D consistency. However,
existing SDS-based 3D editing methods suffer from extensive training time and
lead to low-quality results, primarily because these methods deviate from the
sampling dynamics of diffusion models. In this paper, we propose DreamCatalyst,
a novel framework that interprets SDS-based editing as a diffusion reverse
process. Our objective function considers the sampling dynamics, thereby making
the optimization process of DreamCatalyst an approximation of the diffusion
reverse process in editing tasks. DreamCatalyst aims to reduce training time
and improve editing quality. DreamCatalyst presents two modes: (1) a faster
mode, which edits the NeRF scene in only about 25 minutes, and (2) a
high-quality mode, which produces superior results in less than 70 minutes.
Specifically, our high-quality mode outperforms current state-of-the-art NeRF
editing methods both in terms of speed and quality. See more extensive results
on our project page: https://dream-catalyst.github.io.

摘要：分數蒸餾採樣 (SDS) 由於其內在的 3D 一致性，已成為文字驅動 3D 編輯任務中一個有效的框架。然而，現有的基於 SDS 的 3D 編輯方法訓練時間長，且會產生低品質的結果，主要是因為這些方法偏離了擴散模型的採樣動態。在本文中，我們提出 DreamCatalyst，一個將基於 SDS 的編輯解釋為反向擴散過程的新穎框架。我們的目標函數考量了採樣動態，從而使 DreamCatalyst 的最佳化過程成為編輯任務中反向擴散過程的近似值。DreamCatalyst 旨在減少訓練時間並提升編輯品質。DreamCatalyst 提出兩種模式：(1) 一種較快的模式，僅在約 25 分鐘內編輯 NeRF 場景，以及 (2) 一種高品質模式，可在不到 70 分鐘內產生優異的結果。具體來說，我們的高品質模式在速度和品質方面都優於目前的 NeRF 編輯方法。在我們的專案頁面上查看更全面的結果：https://dream-catalyst.github.io。

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v1 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image--language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image--caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

摘要：可控图像字幕（CIC）旨在为图像生成自然语言描述，条件是根据最终用户提供的信息，例如感兴趣的区域、实体或事件。然而，可用的图像语言数据集主要包含描述图像整体的字幕，这使得它们无法有效训练 CIC 模型，而 CIC 模型有可能关注任何区域或关系子集。为了应对这一挑战，我们提出了一种新颖的、全自动的方法来使用基于现有与图像关联的字幕集构建的统一结构化语义表示来采样附加的、集中的和视觉接地的字幕。我们利用跨语言图形式语义形式主义——抽象意义表示（AMR）来对实体之间的所有可能的时空语义关系进行编码，而不仅仅是当前方法通常只关注的空间关系。我们使用这种结构化语义增强（SSA）框架来使用接地控制字幕增强现有的图像字幕数据集，从而增加其空间和语义多样性以及焦点覆盖范围。然后，我们开发了一个新模型 CIC-BART-SSA，该模型专门针对 CIC 任务定制，它从 SSA 多元化数据集获取其控制信号。我们通过实验证明，与 SOTA CIC 模型相比，CIC-BART-SSA 生成的字幕在多样性和文本质量方面更胜一筹，在可控性方面具有竞争力，而且重要的是，它最大程度地缩小了广泛和高度集中的受控字幕性能之间的差距，从而有效地推广到极具挑战性的高度集中的场景。代码可在 https://github.com/SamsungLabs/CIC-BART-SSA 获得。

##### **InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains**
2407.11384v1 by Yinzhu Quan, Zefang Liu

Supply chain management (SCM) involves coordinating the flow of goods,
information, and finances across various entities to deliver products
efficiently. Effective inventory management is crucial in today's volatile,
uncertain, complex, and ambiguous (VUCA) world. Previous research has
demonstrated the superiority of heuristic methods and reinforcement learning
applications in inventory management. However, the application of large
language models (LLMs) as autonomous agents in multi-agent systems for
inventory management remains underexplored. This study introduces a novel
approach using LLMs to manage multi-agent inventory systems. Leveraging their
zero-shot learning capabilities, our model, InvAgent, enhances resilience and
improves efficiency across the supply chain network. Our contributions include
utilizing LLMs for zero-shot learning to enable adaptive and informed
decision-making without prior training, providing significant explainability
and clarity through Chain-of-Thought (CoT), and demonstrating dynamic
adaptability to varying demand scenarios while minimizing costs and avoiding
stockouts. Extensive evaluations across different scenarios highlight the
efficiency of our model in SCM.

摘要：供應鏈管理 (SCM) 包含協調貨物、資訊和資金在各種實體之間的流動，以有效率地交付產品。在現今易變、不確定、複雜且模糊 (VUCA) 的世界中，有效的庫存管理至關重要。先前的研究已證明啟發式方法和強化學習應用在庫存管理中的優越性。然而，將大型語言模型 (LLM) 作為多主體系統中用於庫存管理的自主代理人的應用仍未被充分探討。本研究提出了一種使用 LLM 來管理多主體庫存系統的新方法。我們的模型 InvAgent 透過運用其零次學習能力，增強了復原力並提升了整個供應鏈網路的效率。我們的貢獻包括利用 LLM 進行零次學習，以在沒有事先訓練的情況下啟用適應性和明智的決策制定，透過思考鏈 (CoT) 提供顯著的可解釋性和清晰度，並展示對不同需求情境的動態適應能力，同時將成本降至最低並避免缺貨。在不同情境中的廣泛評估突顯了我們的模型在 SCM 中的效率。

##### **Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts**
2407.11382v2 by Jianhao Li, Tianyu Sun, Zhongdao Wang, Enze Xie, Bailan Feng, Hongbo Zhang, Ze Yuan, Ke Xu, Jiaheng Liu, Ping Luo

This paper proposes an algorithm for automatically labeling 3D objects from
2D point or box prompts, especially focusing on applications in autonomous
driving. Unlike previous arts, our auto-labeler predicts 3D shapes instead of
bounding boxes and does not require training on a specific dataset. We propose
a Segment, Lift, and Fit (SLF) paradigm to achieve this goal. Firstly, we
segment high-quality instance masks from the prompts using the Segment Anything
Model (SAM) and transform the remaining problem into predicting 3D shapes from
given 2D masks. Due to the ill-posed nature of this problem, it presents a
significant challenge as multiple 3D shapes can project into an identical mask.
To tackle this issue, we then lift 2D masks to 3D forms and employ gradient
descent to adjust their poses and shapes until the projections fit the masks
and the surfaces conform to surrounding LiDAR points. Notably, since we do not
train on a specific dataset, the SLF auto-labeler does not overfit to biased
annotation patterns in the training set as other methods do. Thus, the
generalization ability across different datasets improves. Experimental results
on the KITTI dataset demonstrate that the SLF auto-labeler produces
high-quality bounding box annotations, achieving an AP@0.5 IoU of nearly 90\%.
Detectors trained with the generated pseudo-labels perform nearly as well as
those trained with actual ground-truth annotations. Furthermore, the SLF
auto-labeler shows promising results in detailed shape predictions, providing a
potential alternative for the occupancy annotation of dynamic objects.

摘要：<paragraph>這篇論文提出了一種演算法，用於自動標記 3D 物件，從 2D 點或方框提示，特別著重於自動駕駛的應用。與先前的技術不同，我們的自動標籤器預測 3D 形狀，而不是邊界方框，並且不需要針對特定資料集進行訓練。我們提出了一個分段、提升和擬合 (SLF) 的範例來達成這個目標。首先，我們使用 Segment Anything Model (SAM) 從提示中分段出高品質的實例遮罩，並將剩下的問題轉換為從給定的 2D 遮罩預測 3D 形狀。由於這個問題的性質不佳，因此它提出了重大的挑戰，因為多個 3D 形狀可以投影到一個相同的遮罩。為了解決這個問題，我們接著將 2D 遮罩提升到 3D 形式，並使用梯度下降來調整它們的姿勢和形狀，直到投影符合遮罩，並且表面符合周圍的 LiDAR 點。值得注意的是，由於我們沒有針對特定資料集進行訓練，因此 SLF 自動標籤器不會過度擬合訓練集中有偏差的註解模式，就像其他方法一樣。因此，跨不同資料集的泛化能力得到改善。在 KITTI 資料集上的實驗結果證明，SLF 自動標籤器產生了高品質的邊界方框註解，達到了將近 90% 的 AP@0.5 IoU。使用產生的偽標籤訓練的偵測器執行得幾乎和使用實際基本事實註解訓練的那些一樣好。此外，SLF 自動標籤器在詳細形狀預測中顯示出有希望的結果，為動態物體的佔用註解提供了潛在的替代方案。</paragraph>

##### **Reliable Reasoning Beyond Natural Language**
2407.11373v1 by Nasim Borazjanizadeh, Steven T. Piantadosi

Despite their linguistic competence, Large Language models (LLMs) often
exhibit limitations in their ability to reason reliably and flexibly. To
address this, we propose a neurosymbolic approach that prompts LLMs to extract
and encode all relevant information from a problem statement as logical code
statements, and then use a logic programming language (Prolog) to conduct the
iterative computations of explicit deductive reasoning. Our approach
significantly enhances the performance of LLMs on the standard mathematical
reasoning benchmark, GSM8k, and the Navigate dataset from the BIG-bench
dataset. Additionally, we introduce a novel dataset, the Non-Linear Reasoning
(NLR) dataset, consisting of 55 unique word problems that target the
shortcomings of the next token prediction paradigm of LLMs and require complex
non-linear reasoning but only basic arithmetic skills to solve. Our findings
demonstrate that the integration of Prolog enables LLMs to achieve high
performance on the NLR dataset, which even the most advanced language models
(including GPT4) fail to solve using text only.

摘要：儘管具備語言能力，大型語言模型 (LLM) 經常在可靠且靈活地推理的能力上展現出限制。為了解決此問題，我們提出了一種神經符號方法，提示 LLM 從問題陳述中提取和編碼所有相關資訊作為邏輯程式碼陳述，然後使用邏輯程式設計語言 (Prolog) 進行明確演繹推理的迭代運算。我們的做法顯著提升 LLM 在標準數學推理基準 GSM8k 和 BIG-bench 資料集中的 Navigate 資料集上的效能。此外，我們引進了一個新穎的資料集，非線性推理 (NLR) 資料集，包含 55 個獨特的文字題，針對 LLM 的下一個符號預測範例的缺點，需要複雜的非線性推理，但只需要基本的算術技巧就能解題。我們的發現證明，整合 Prolog 能讓 LLM 在 NLR 資料集上達成高效能，這甚至是進階的語言模型（包含 GPT4）都無法僅使用文字解題的。

##### **Estimating Agreement by Chance for Sequence Annotation**
2407.11371v1 by Diya Li, Carolyn Rosé, Ao Yuan, Chunxiao Zhou

In the field of natural language processing, correction of performance
assessment for chance agreement plays a crucial role in evaluating the
reliability of annotations. However, there is a notable dearth of research
focusing on chance correction for assessing the reliability of sequence
annotation tasks, despite their widespread prevalence in the field. To address
this gap, this paper introduces a novel model for generating random
annotations, which serves as the foundation for estimating chance agreement in
sequence annotation tasks. Utilizing the proposed randomization model and a
related comparison approach, we successfully derive the analytical form of the
distribution, enabling the computation of the probable location of each
annotated text segment and subsequent chance agreement estimation. Through a
combination simulation and corpus-based evaluation, we successfully assess its
applicability and validate its accuracy and efficacy.

摘要：在自然語言處理領域，修正機會一致性的表現評估在評估註釋的可信度方面扮演著至關重要的角色。然而，儘管序列註釋任務在該領域廣泛盛行，但專注於機會修正以評估序列註釋任務可信度的研究卻相當匱乏。為了解決這個差距，本文介紹了一個用於產生隨機註釋的新穎模型，作為在序列註釋任務中估計機會一致性的基礎。利用所提出的隨機化模型和相關的比較方法，我們成功地推導出分佈的解析形式，進而能計算每個註釋文本區段的可能位置和後續的機會一致性估計。透過結合模擬和基於語料庫的評估，我們成功地評估了其適用性，並驗證了其準確性和有效性。

##### **A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora**
2407.11370v1 by Kentaro Onda, Joonyong Park, Nobuaki Minematsu, Daisuke Saito

We propose a method of simulating the human process of foreign accentuation
using Generative Spoken Language Model (GSLM) only with native speech corpora.
When one listens to spoken words of a foreign language and repeats them, the
repeated speech is often with the accent of that listener's L1. This is said to
be because the spoken words are mentally represented as a sequence of
phonological units of the L1, and those units are used for oral reproduction.
We simulate this process by inputting speech of language A into GSLM of
language B to add B's accent onto the input speech. The process of running ASR
of the L1 for foreign input speech and giving the ASR result to TTS of the L1
can be viewed as a naive implementation of this approach. The results of our
experiments show that the synthesized accent of the output speech is highly
natural, compared to real samples of A generated by speakers whose L1 is B, and
that the degree of accentuation is controllable.

摘要：我們提出一個模擬人類外語發音過程的方法，僅使用生成式口語語言模型 (GSLM) 和母語語料庫。當有人聽到外語的口語並重複時，重複的語音通常帶有聽者的 L1 口音。據說這是因為口語在心智中被表徵為 L1 的音位單元序列，而這些單元用於口語再現。我們模擬這個過程，將語言 A 的語音輸入到語言 B 的 GSLM 中，將 B 的口音添加到輸入語音中。為外語輸入語音執行 L1 的 ASR，並將 ASR 結果提供給 L1 的 TTS 的過程，可以視為這種方法的幼稚實現。我們的實驗結果表明，與 L1 為 B 的講者產生的 A 的真實樣本相比，輸出語音的合成口音非常自然，並且口音程度是可以控制的。

##### **Ancient Korean Archive Translation: Comparison Analysis on Statistical phrase alignment, LLM in-context learning, and inter-methodological approach**
2407.11368v1 by Sojung Lucia Kim, Taehong Jang, Joonmo Ahn

This study aims to compare three methods for translating ancient texts with
sparse corpora: (1) the traditional statistical translation method of phrase
alignment, (2) in-context LLM learning, and (3) proposed inter methodological
approach - statistical machine translation method using sentence piece tokens
derived from unified set of source-target corpus. The performance of the
proposed approach in this study is 36.71 in BLEU score, surpassing the scores
of SOLAR-10.7B context learning and the best existing Seq2Seq model. Further
analysis and discussion are presented.

摘要：本研究旨在比較三種翻譯稀疏語料庫的古代文本的方法：(1) 傳統的統計翻譯方法的短語對齊，(2) 上下文 LLM 學習，以及 (3) 提出的方法論間方法 - 使用源目標語料庫統一集合中衍生的句子片段令牌的統計機器翻譯方法。本研究中提出的方法的 BLEU 分數表現為 36.71，超過了 SOLAR-10.7B 上下文學習和現有最佳 Seq2Seq 模型的分數。提供了進一步的分析和討論。

##### **Feature Inference Attack on Shapley Values**
2407.11359v1 by Xinjian Luo, Yangfan Jiang, Xiaokui Xiao

As a solution concept in cooperative game theory, Shapley value is highly
recognized in model interpretability studies and widely adopted by the leading
Machine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and
IBM. However, as the Shapley value-based model interpretability methods have
been thoroughly studied, few researchers consider the privacy risks incurred by
Shapley values, despite that interpretability and privacy are two foundations
of machine learning (ML) models.
  In this paper, we investigate the privacy risks of Shapley value-based model
interpretability methods using feature inference attacks: reconstructing the
private model inputs based on their Shapley value explanations. Specifically,
we present two adversaries. The first adversary can reconstruct the private
inputs by training an attack model based on an auxiliary dataset and black-box
access to the model interpretability services. The second adversary, even
without any background knowledge, can successfully reconstruct most of the
private features by exploiting the local linear correlations between the model
inputs and outputs. We perform the proposed attacks on the leading MLaaS
platforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The
experimental results demonstrate the vulnerability of the state-of-the-art
Shapley value-based model interpretability methods used in the leading MLaaS
platforms and highlight the significance and necessity of designing
privacy-preserving model interpretability methods in future studies. To our
best knowledge, this is also the first work that investigates the privacy risks
of Shapley values.

摘要：作為合作博弈論中的解決概念，Shapley 值在模型可解釋性研究中受到高度重視，並被 Google、Microsoft 和 IBM 等領先的機器學習即服務 (MLaaS) 供應商廣泛採用。然而，儘管基於 Shapley 值的模型可解釋性方法已得到深入研究，但很少有研究人員考慮 Shapley 值帶來的隱私風險，儘管可解釋性和隱私是機器學習 (ML) 模型的兩個基礎。在本文中，我們使用特徵推論攻擊來研究基於 Shapley 值的模型可解釋性方法的隱私風險：根據其 Shapley 值解釋重建私有模型輸入。具體來說，我們提出了兩個對手。第一個對手可以通過基於輔助數據集訓練攻擊模型並黑盒訪問模型可解釋性服務來重建私有輸入。第二個對手，即使沒有任何背景知識，也可以通過利用模型輸入和輸出之間的局部線性相關性成功重建大部分私有特徵。我們在領先的 MLaaS 平台（即 Google Cloud、Microsoft Azure 和 IBM aix360）上執行提議的攻擊。實驗結果證明了領先的 MLaaS 平台中使用的基於 Shapley 值的最新模型可解釋性方法的脆弱性，並強調了在未來的研究中設計隱私保護模型可解釋性方法的重要性與必要性。據我們所知，這也是第一個研究 Shapley 值的隱私風險的工作。

##### **Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models**
2407.11345v1 by Matthew Perez, Aneesha Sampath, Minxue Niu, Emily Mower Provost

Aphasia is a language disorder that can lead to speech errors known as
paraphasias, which involve the misuse, substitution, or invention of words.
Automatic paraphasia detection can help those with Aphasia by facilitating
clinical assessment and treatment planning options. However, most automatic
paraphasia detection works have focused solely on binary detection, which
involves recognizing only the presence or absence of a paraphasia. Multiclass
paraphasia detection represents an unexplored area of research that focuses on
identifying multiple types of paraphasias and where they occur in a given
speech segment. We present novel approaches that use a generative pretrained
transformer (GPT) to identify paraphasias from transcripts as well as two
end-to-end approaches that focus on modeling both automatic speech recognition
(ASR) and paraphasia classification as multiple sequences vs. a single
sequence. We demonstrate that a single sequence model outperforms GPT baselines
for multiclass paraphasia detection.

摘要：失語症是一種語言障礙，可能導致言語錯誤，稱為錯語症，其中涉及字詞的誤用、替換或創造。
自動錯語症偵測可以透過促進臨床評估和治療規劃選項，幫助失語症患者。
然而，大多數自動錯語症偵測工作僅專注於二元偵測，其中只涉及辨識錯語症的存在或不存在。
多類別錯語症偵測代表了一個尚未探索的研究領域，其專注於識別多種類型的錯語症，以及它們在特定語音片段中出現的位置。
我們提出使用生成式預訓練轉換器 (GPT) 的新方法，從轉錄中識別錯語症，以及兩種端對端方法，其專注於將自動語音辨識 (ASR) 和錯語症分類建模為多個序列與單一序列。
我們證明單一序列模型在多類別錯語症偵測方面優於 GPT 基準。

##### **COMET: "Cone of experience" enhanced large multimodal model for mathematical problem generation**
2407.11315v1 by Sannyuya Liu, Jintian Feng, Zongkai Yang, Yawei Luo, Qian Wan, Xiaoxuan Shen, Jianwen Sun

The automatic generation of high-quality mathematical problems is practically
valuable in many educational scenarios. Large multimodal model provides a novel
technical approach for the mathematical problem generation because of its wide
success in cross-modal data scenarios. However, the traditional method of
separating problem solving from problem generation and the mainstream
fine-tuning framework of monotonous data structure with homogeneous training
objectives limit the application of large multimodal model in mathematical
problem generation. Addressing these challenges, this paper proposes COMET, a
"Cone of Experience" enhanced large multimodal model for mathematical problem
generation. Firstly, from the perspective of mutual ability promotion and
application logic, we unify stem generation and problem solving into
mathematical problem generation. Secondly, a three-stage fine-turning framework
guided by the "Cone of Experience" is proposed. The framework divides the
fine-tuning data into symbolic experience, iconic experience, and direct
experience to draw parallels with experiences in the career growth of teachers.
Several fine-grained data construction and injection methods are designed in
this framework. Finally, we construct a Chinese multimodal mathematical problem
dataset to fill the vacancy of Chinese multimodal data in this field. Combined
with objective and subjective indicators, experiments on multiple datasets
fully verify the effectiveness of the proposed framework and model.

摘要：在許多教育場景中，自動產生高品質的數學題目在實務上很有價值。大型多模態模型在跨模態資料場景中取得廣泛的成功，為數學題目產生提供了一種新穎的技術方法。然而，傳統上將問題求解與問題產生分開的方法，以及主流微調框架使用單調資料結構搭配同質訓練目標，限制了大型多模態模型在數學題目產生中的應用。為了應對這些挑戰，本文提出了 COMET，一種「經驗錐體」增強大型多模態模型，用於數學題目產生。首先，從相互能力促進和應用邏輯的角度，我們將題幹產生和問題求解統一到數學題目產生中。其次，提出了一個由「經驗錐體」指導的三階段微調框架。該框架將微調資料分為符號經驗、圖像經驗和直接經驗，以與教師職業成長中的經驗相呼應。在此框架中設計了幾種細粒度的資料建構和注入方法。最後，我們建構了一個中文多模態數學題目資料集，以填補該領域中中文多模態資料的空白。結合客觀和主觀指標，在多個資料集上的實驗充分驗證了所提出的框架和模型的有效性。

##### **Large Vision-Language Models as Emotion Recognizers in Context Awareness**
2407.11300v1 by Yuxuan Lei, Dingkang Yang, Zhaoyu Chen, Jiawei Chen, Peng Zhai, Lihua Zhang

Context-aware emotion recognition (CAER) is a complex and significant task
that requires perceiving emotions from various contextual cues. Previous
approaches primarily focus on designing sophisticated architectures to extract
emotional cues from images. However, their knowledge is confined to specific
training datasets and may reflect the subjective emotional biases of the
annotators. Furthermore, acquiring large amounts of labeled data is often
challenging in real-world applications. In this paper, we systematically
explore the potential of leveraging Large Vision-Language Models (LVLMs) to
empower the CAER task from three paradigms: 1) We fine-tune LVLMs on two CAER
datasets, which is the most common way to transfer large models to downstream
tasks. 2) We design zero-shot and few-shot patterns to evaluate the performance
of LVLMs in scenarios with limited data or even completely unseen. In this
case, a training-free framework is proposed to fully exploit the In-Context
Learning (ICL) capabilities of LVLMs. Specifically, we develop an image
similarity-based ranking algorithm to retrieve examples; subsequently, the
instructions, retrieved examples, and the test example are combined to feed
LVLMs to obtain the corresponding sentiment judgment. 3) To leverage the rich
knowledge base of LVLMs, we incorporate Chain-of-Thought (CoT) into our
framework to enhance the model's reasoning ability and provide interpretable
results. Extensive experiments and analyses demonstrate that LVLMs achieve
competitive performance in the CAER task across different paradigms. Notably,
the superior performance in few-shot settings indicates the feasibility of
LVLMs for accomplishing specific tasks without extensive training.

摘要：情境感知情緒辨識 (CAER) 是一項複雜且重要的任務，需要從各種情境線索中感知情緒。先前的做法主要專注於設計精密架構，從影像中擷取情緒線索。然而，其知識僅限於特定訓練資料集，且可能反映標註者的主觀情緒偏見。此外，在真實世界應用中，取得大量的標籤資料通常具有挑戰性。在本文中，我們系統性地探討利用大型視覺語言模型 (LVLMs) 來強化 CAER 任務的三種範例：1) 我們對兩個 CAER 資料集微調 LVLMs，這是將大型模型轉移到下游任務最常見的方法。2) 我們設計零次學習和少量學習模式，以評估 LVLMs 在資料有限甚至完全未見的情況下的效能。在這種情況下，我們提出一個免訓練架構，以充分利用 LVLMs 的情境學習 (ICL) 能力。具體來說，我們開發一個基於影像相似度的排名演算法來擷取範例；隨後，將指示、擷取的範例和測試範例組合起來，提供給 LVLMs 以取得相應的情緒判斷。3) 為了利用 LVLMs 豐富的知識庫，我們將思考鏈 (CoT) 納入我們的架構中，以增強模型的推理能力並提供可解釋的結果。廣泛的實驗和分析證明，LVLMs 在不同的範例中實現了 CAER 任務的競爭效能。值得注意的是，在少量學習設定中的優異效能，表示 LVLMs 無需廣泛訓練即可完成特定任務的可行性。

##### **Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems**
2407.11288v1 by Yaşar Utku Alçalar, Mehmet Akçakaya

Diffusion models have emerged as powerful generative techniques for solving
inverse problems. Despite their success in a variety of inverse problems in
imaging, these models require many steps to converge, leading to slow inference
time. Recently, there has been a trend in diffusion models for employing
sophisticated noise schedules that involve more frequent iterations of
timesteps at lower noise levels, thereby improving image generation and
convergence speed. However, application of these ideas for solving inverse
problems with diffusion models remain challenging, as these noise schedules do
not perform well when using empirical tuning for the forward model
log-likelihood term weights. To tackle these challenges, we propose zero-shot
approximate posterior sampling (ZAPS) that leverages connections to zero-shot
physics-driven deep learning. ZAPS fixes the number of sampling steps, and uses
zero-shot training with a physics-guided loss function to learn log-likelihood
weights at each irregular timestep. We apply ZAPS to the recently proposed
diffusion posterior sampling method as baseline, though ZAPS can also be used
with other posterior sampling diffusion models. We further approximate the
Hessian of the logarithm of the prior using a diagonalization approach with
learnable diagonal entries for computational efficiency. These parameters are
optimized over a fixed number of epochs with a given computational budget. Our
results for various noisy inverse problems, including Gaussian and motion
deblurring, inpainting, and super-resolution show that ZAPS reduces inference
time, provides robustness to irregular noise schedules and improves
reconstruction quality. Code is available at https://github.com/ualcalar17/ZAPS

摘要：擴散模型已成為解決逆問題的強大生成技術。儘管它們在各種影像逆問題中取得成功，但這些模型需要許多步驟才能收斂，導致推論時間變慢。最近，擴散模型出現了一種趨勢，採用精密的雜訊時程，其中涉及在較低雜訊級別下對時間步長進行更頻繁的迭代，從而改善影像生成和收斂速度。然而，將這些想法應用於使用擴散模型解決逆問題仍然具有挑戰性，因為這些雜訊時程在使用經驗調整進行前向模型對數似然項權重時表現不佳。為了應對這些挑戰，我們提出了零次近似後驗抽樣 (ZAPS)，它利用了與零次物理驅動深度學習的聯繫。ZAPS 修復了抽樣步驟的數量，並使用具有物理指導損失函數的零次訓練來學習每個不規則時間步長的對數似然權重。我們將 ZAPS 應用於最近提出的擴散後驗抽樣方法作為基準，儘管 ZAPS 也可用於其他後驗抽樣擴散模型。我們進一步使用具有可學習對角線條目的對角化方法來近似先驗對數的 Hessian，以提高計算效率。這些參數在給定的計算預算下經過固定數量的 epoch 優化。我們對各種雜訊逆問題（包括高斯和運動去模糊、修復和超解析度）的結果表明，ZAPS 減少了推論時間，提供了對不規則雜訊時程的魯棒性，並提高了重建品質。程式碼可在 https://github.com/ualcalar17/ZAPS 取得

##### **CLAMS: A System for Zero-Shot Model Selection for Clustering**
2407.11286v1 by Prabhant Singh, Pieter Gijsbers, Murat Onur Yildirim, Elif Ceren Gok, Joaquin Vanschoren

We propose an AutoML system that enables model selection on clustering
problems by leveraging optimal transport-based dataset similarity. Our
objective is to establish a comprehensive AutoML pipeline for clustering
problems and provide recommendations for selecting the most suitable
algorithms, thus opening up a new area of AutoML beyond the traditional
supervised learning settings. We compare our results against multiple
clustering baselines and find that it outperforms all of them, hence
demonstrating the utility of similarity-based automated model selection for
solving clustering applications.

摘要：我們提出一個自動機器學習系統，它透過利用最佳傳輸基礎的資料集相似性，在分群問題上進行模型選擇。我們的目標是建立一個全面的自動機器學習管道，以解決分群問題，並提供建議，以選擇最合適的演算法，從而開啟一個超越傳統監督式學習設定的自動機器學習新領域。我們將我們的結果與多個分群基準進行比較，並發現它優於所有基準，因此證明了基於相似性的自動化模型選擇對於解決分群應用程式的效用。

##### **Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models**
2407.11282v2 by Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang

Large Language Models (LLMs) are employed across various high-stakes domains,
where the reliability of their outputs is crucial. One commonly used method to
assess the reliability of LLMs' responses is uncertainty estimation, which
gauges the likelihood of their answers being correct. While many studies focus
on improving the accuracy of uncertainty estimations for LLMs, our research
investigates the fragility of uncertainty estimation and explores potential
attacks. We demonstrate that an attacker can embed a backdoor in LLMs, which,
when activated by a specific trigger in the input, manipulates the model's
uncertainty without affecting the final output. Specifically, the proposed
backdoor attack method can alter an LLM's output probability distribution,
causing the probability distribution to converge towards an attacker-predefined
distribution while ensuring that the top-1 prediction remains unchanged. Our
experimental results demonstrate that this attack effectively undermines the
model's self-evaluation reliability in multiple-choice questions. For instance,
we achieved a 100 attack success rate (ASR) across three different triggering
strategies in four models. Further, we investigate whether this manipulation
generalizes across different prompts and domains. This work highlights a
significant threat to the reliability of LLMs and underscores the need for
future defenses against such attacks. The code is available at
https://github.com/qcznlp/uncertainty_attack.

摘要：大型語言模型 (LLM) 被用於各種高風險領域中，其中其輸出的可靠性至關重要。一種常用的方法來評估 LLM 回應的可靠性是不確定性估計，它衡量其答案正確的可能性。儘管許多研究專注於提高 LLM 不確定性估計的準確性，但我們的研究調查了不確定性估計的脆弱性並探索了潛在的攻擊。我們證明，攻擊者可以在 LLM 中嵌入後門，當輸入中的特定觸發器激活時，它會在不影響最終輸出的情況下操縱模型的不確定性。具體來說，所提出的後門攻擊方法可以改變 LLM 的輸出概率分佈，導致概率分佈朝著攻擊者預先定義的分佈收斂，同時確保 top-1 預測保持不變。我們的實驗結果表明，這種攻擊有效地破壞了模型在多選題中的自我評估可靠性。例如，我們在四個模型中的三種不同的觸發策略中實現了 100 的攻擊成功率 (ASR)。此外，我們研究了這種操縱是否在不同的提示和領域中得到推廣。這項工作強調了對 LLM 可靠性的重大威脅，並強調了未來需要對此類攻擊進行防禦。代碼可在 https://github.com/qcznlp/uncertainty_attack 中找到。

##### **Quality Scalable Quantization Methodology for Deep Learning on Edge**
2407.11260v1 by Salman Abdul Khaliq, Rehan Hafiz

Deep Learning Architectures employ heavy computations and bulk of the
computational energy is taken up by the convolution operations in the
Convolutional Neural Networks. The objective of our proposed work is to reduce
the energy consumption and size of CNN for using machine learning techniques in
edge computing on ubiquitous computing devices. We propose Systematic Quality
Scalable Design Methodology consisting of Quality Scalable Quantization on a
higher abstraction level and Quality Scalable Multipliers at lower abstraction
level. The first component consists of parameter compression where we
approximate representation of values in filters of deep learning models by
encoding in 3 bits. A shift and scale based on-chip decoding hardware is
proposed which can decode these 3-bit representations to recover approximate
filter values. The size of the DNN model is reduced this way and can be sent
over a communication channel to be decoded on the edge computing devices. This
way power is reduced by limiting data bits by approximation. In the second
component we propose a quality scalable multiplier which reduces the number of
partial products by converting numbers in canonic sign digit representations
and further approximating the number by reducing least significant bits. These
quantized CNNs provide almost same ac-curacy as network with original weights
with little or no fine-tuning. The hardware for the adaptive multipliers
utilize gate clocking for reducing energy consumption during multiplications.
The proposed methodology greatly reduces the memory and power requirements of
DNN models making it a feasible approach to deploy Deep Learning on edge
computing. The experiments done on LeNet and ConvNets show an increase upto 6%
of zeros and memory savings upto 82.4919% while keeping the accuracy near the
state of the art.

摘要：深度學習架構採用大量的運算，而大部分的運算能量都被卷積神經網路中的卷積運算所吸收。我們提出的工作目標是降低 CNN 的能耗和大小，以便在普適運算裝置上的邊緣運算中使用機器學習技術。我們提出系統化品質可擴充設計方法，其中包含較高抽象層級的品質可擴充量化和較低抽象層級的品質可擴充乘法器。第一個組件包含參數壓縮，其中我們透過 3 位元編碼來近似表示深度學習模型中濾波器的值。我們提出了一個基於位移和縮放的晶片解碼硬體，它可以解碼這些 3 位元表示以還原近似的濾波器值。DNN 模型的大小會以這種方式縮小，並且可以透過通訊管道傳送，以便在邊緣運算裝置上解碼。這種方式可透過近似來限制資料位元，進而降低功耗。在第二個組件中，我們提出了一個品質可擴充乘法器，它透過將數字轉換為正規符號位元表示，並進一步透過減少最低有效位元來近似數字，進而減少部分乘積的數量。這些量化的 CNN 提供幾乎與原始權重的網路相同的準確度，幾乎不需要微調。自適應乘法器的硬體利用閘極時脈來降低乘法運算中的能耗。所提出的方法大幅降低了 DNN 模型的記憶體和功耗需求，使其成為在邊緣運算中部署深度學習的可行方法。在 LeNet 和 ConvNets 上進行的實驗顯示，零的增加幅度高達 6%，記憶體節省幅度高達 82.4919%，同時將準確度維持在接近最先進的水平。

##### **Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation**
2407.11245v1 by Chung Park, Taesan Kim, Hyungjun Yoon, Junui Hong, Yelim Yu, Mincheol Cho, Minsung Choi, Jaegul Choo

Cross-Domain Sequential Recommendation (CDSR) improves recommendation
performance by utilizing information from multiple domains, which contrasts
with Single-Domain Sequential Recommendation (SDSR) that relies on a historical
interaction within a specific domain. However, CDSR may underperform compared
to the SDSR approach in certain domains due to negative transfer, which occurs
when there is a lack of relation between domains or different levels of data
sparsity. To address the issue of negative transfer, our proposed CDSR model
estimates the degree of negative transfer of each domain and adaptively assigns
it as a weight factor to the prediction loss, to control gradient flows through
domains with significant negative transfer. To this end, our model compares the
performance of a model trained on multiple domains (CDSR) with a model trained
solely on the specific domain (SDSR) to evaluate the negative transfer of each
domain using our asymmetric cooperative network. In addition, to facilitate the
transfer of valuable cues between the SDSR and CDSR tasks, we developed an
auxiliary loss that maximizes the mutual information between the representation
pairs from both tasks on a per-domain basis. This cooperative learning between
SDSR and CDSR tasks is similar to the collaborative dynamics between pacers and
runners in a marathon. Our model outperformed numerous previous works in
extensive experiments on two real-world industrial datasets across ten service
domains. We also have deployed our model in the recommendation system of our
personal assistant app service, resulting in 21.4% increase in click-through
rate compared to existing models, which is valuable to real-world business.

摘要：跨網域序列推薦 (CDSR) 透過利用多個網域中的資訊來提升推薦效能，這與依賴特定網域內歷史互動的單一網域序列推薦 (SDSR) 形成對比。然而，由於負面轉移，CDSR 在某些網域中可能表現不如 SDSR 方法，負面轉移發生在網域之間缺乏關聯或資料稀疏程度不同時。為了解決負面轉移的問題，我們提出的 CDSR 模型會估計每個網域的負面轉移程度，並將其自適應地指定為預測損失的權重因子，以控制透過具有顯著負面轉移的網域的梯度流。為此，我們的模型會比較在多個網域 (CDSR) 上訓練的模型與僅在特定網域 (SDSR) 上訓練的模型的效能，以使用我們的非對稱協作網路評估每個網域的負面轉移。此外，為了促進 SDSR 和 CDSR 任務之間有價值線索的轉移，我們開發了一個輔助損失，以最大化來自兩個任務的表示對在每個網域基礎上的互惠資訊。SDSR 和 CDSR 任務之間的這種協作學習類似於馬拉松比賽中配速員和跑者之間的協作動態。我們的模型在兩個真實世界產業資料集中的十個服務網域中，在廣泛的實驗中表現優於許多先前的作品。我們也已將我們的模型部署在我們的個人助理應用程式服務的推薦系統中，與現有模型相比，點擊率增加了 21.4%，這對於真實世界的業務來說是有價值的。

