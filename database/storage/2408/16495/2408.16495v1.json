{"2408.16495": {"publish_time": "2024-08-29", "title": "On-device AI: Quantization-aware Training of Transformers in Time-Series", "paper_summary": "Artificial Intelligence (AI) models for time-series in pervasive computing\nkeep getting larger and more complicated. The Transformer model is by far the\nmost compelling of these AI models. However, it is difficult to obtain the\ndesired performance when deploying such a massive model on a sensor device with\nlimited resources. My research focuses on optimizing the Transformer model for\ntime-series forecasting tasks. The optimized model will be deployed as hardware\naccelerators on embedded Field Programmable Gate Arrays (FPGAs). I will\ninvestigate the impact of applying Quantization-aware Training to the\nTransformer model to reduce its size and runtime memory footprint while\nmaximizing the advantages of FPGAs.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167\uff08AI\uff09\u6a21\u578b\u5728\u666e\u904d\u904b\u7b97\u4e2d\u7684\u6642\u9593\u5e8f\u5217\u6301\u7e8c\u8b8a\u5927\u4e14\u66f4\u8907\u96dc\u3002Transformer \u6a21\u578b\u662f\u76ee\u524d\u6700\u5f15\u4eba\u6ce8\u76ee\u7684 AI \u6a21\u578b\u3002\u7136\u800c\uff0c\u5728\u8cc7\u6e90\u6709\u9650\u7684\u611f\u6e2c\u5668\u88dd\u7f6e\u4e0a\u90e8\u7f72\u5982\u6b64\u9f90\u5927\u7684\u6a21\u578b\u6642\uff0c\u96e3\u4ee5\u7372\u5f97\u7406\u60f3\u7684\u6548\u80fd\u3002\u6211\u7684\u7814\u7a76\u91cd\u9ede\u5728\u65bc\u6700\u4f73\u5316 Transformer \u6a21\u578b\uff0c\u4ee5\u9032\u884c\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u4efb\u52d9\u3002\u6700\u4f73\u5316\u7684\u6a21\u578b\u5c07\u90e8\u7f72\u70ba\u5d4c\u5165\u5f0f\u73fe\u5834\u53ef\u7de8\u7a0b\u9598\u9663\u5217\uff08FPGA\uff09\u4e0a\u7684\u786c\u9ad4\u52a0\u901f\u5668\u3002\u6211\u5c07\u63a2\u8a0e\u5c07\u91cf\u5316\u611f\u77e5\u8a13\u7df4\u61c9\u7528\u65bc Transformer \u6a21\u578b\u7684\u5f71\u97ff\uff0c\u4ee5\u7e2e\u5c0f\u5176\u5927\u5c0f\u548c\u57f7\u884c\u6642\u671f\u8a18\u61b6\u9ad4\u4f54\u7528\u7a7a\u9593\uff0c\u540c\u6642\u6700\u5927\u5316 FPGA \u7684\u512a\u52e2\u3002", "author": "Tianheng Ling et.al.", "authors": "Tianheng Ling, Gregor Schiele", "id": "2408.16495v1", "paper_url": "http://arxiv.org/abs/2408.16495v1", "repo": "null"}}