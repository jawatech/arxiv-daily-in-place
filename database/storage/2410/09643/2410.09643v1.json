{"2410.09643": {"publish_time": "2024-10-12", "title": "Multimodal Physical Activity Forecasting in Free-Living Clinical Settings: Hunting Opportunities for Just-in-Time Interventions", "paper_summary": "Objective: This research aims to develop a lifestyle intervention system,\ncalled MoveSense, that forecasts a patient's activity behavior to allow for\nearly and personalized interventions in real-world clinical environments.\nMethods: We conducted two clinical studies involving 58 prediabetic veterans\nand 60 patients with obstructive sleep apnea to gather multimodal behavioral\ndata using wearable devices. We develop multimodal long short-term memory\n(LSTM) network models, which are capable of forecasting the number of step\ncounts of a patient up to 24 hours in advance by examining data from activity\nand engagement modalities. Furthermore, we design goal-based forecasting models\nto predict whether a person's next-day steps will be over a certain threshold.\nResults: Multimodal LSTM with early fusion achieves 33% and 37% lower mean\nabsolute errors than linear regression and ARIMA respectively on the\nprediabetes dataset. LSTM also outperforms linear regression and ARIMA with a\nmargin of 13% and 32% on the sleep dataset. Multimodal forecasting models also\nperform with 72% and 79% accuracy on the prediabetes dataset and sleep dataset\nrespectively on goal-based forecasting. Conclusion: Our experiments conclude\nthat multimodal LSTM models with early fusion are better than multimodal LSTM\nwith late fusion and unimodal LSTM models and also than ARIMA and linear\nregression models. Significance: We address an important and challenging task\nof time-series forecasting in uncontrolled environments. Effective forecasting\nof a person's physical activity can aid in designing adaptive behavioral\ninterventions to keep the user engaged and adherent to a prescribed routine.", "paper_summary_zh": "\u76ee\u6a19\uff1a\u672c\u7814\u7a76\u65e8\u5728\u958b\u767c\u4e00\u7a2e\u751f\u6d3b\u578b\u614b\u4ecb\u5165\u7cfb\u7d71\uff0c\u7a31\u70ba MoveSense\uff0c\u53ef\u9810\u6e2c\u75c5\u60a3\u7684\u6d3b\u52d5\u884c\u70ba\uff0c\u4ee5\u4fbf\u5728\u73fe\u5be6\u4e16\u754c\u7684\u81e8\u5e8a\u74b0\u5883\u4e2d\u9032\u884c\u65e9\u671f\u4e14\u500b\u4eba\u5316\u7684\u4ecb\u5165\u3002\n\u65b9\u6cd5\uff1a\u6211\u5011\u9032\u884c\u4e86\u5169\u9805\u81e8\u5e8a\u7814\u7a76\uff0c\u6d89\u53ca 58 \u4f4d\u7cd6\u5c3f\u75c5\u524d\u671f\u9000\u4f0d\u8ecd\u4eba\u548c 60 \u4f4d\u963b\u585e\u6027\u7761\u7720\u547c\u5438\u4e2d\u6b62\u75c7\u60a3\u8005\uff0c\u4ee5\u4f7f\u7528\u7a7f\u6234\u5f0f\u88dd\u7f6e\u6536\u96c6\u591a\u6a21\u5f0f\u884c\u70ba\u6578\u64da\u3002\u6211\u5011\u958b\u767c\u4e86\u591a\u6a21\u5f0f\u9577\u77ed\u671f\u8a18\u61b6 (LSTM) \u7db2\u8def\u6a21\u578b\uff0c\u5b83\u80fd\u5920\u900f\u904e\u6aa2\u67e5\u6d3b\u52d5\u548c\u53c3\u8207\u6a21\u5f0f\u7684\u6578\u64da\uff0c\u9810\u6e2c\u75c5\u60a3\u5728 24 \u5c0f\u6642\u5167\u8e0f\u51fa\u7684\u6b65\u6578\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u57fa\u65bc\u76ee\u6a19\u7684\u9810\u6e2c\u6a21\u578b\uff0c\u4ee5\u9810\u6e2c\u67d0\u4eba\u7684\u9694\u65e5\u6b65\u6578\u662f\u5426\u6703\u8d85\u904e\u67d0\u500b\u95be\u503c\u3002\n\u7d50\u679c\uff1a\u591a\u6a21\u5f0f LSTM \u8207\u65e9\u671f\u878d\u5408\u5728\u7cd6\u5c3f\u75c5\u524d\u671f\u6578\u64da\u96c6\u4e0a\u5be6\u73fe\u7684\u5e73\u5747\u7d55\u5c0d\u8aa4\u5dee\u6bd4\u7dda\u6027\u56de\u6b78\u548c ARIMA \u5206\u5225\u4f4e 33% \u548c 37%\u3002LSTM \u5728\u7761\u7720\u6578\u64da\u96c6\u4e0a\u4e5f\u4ee5 13% \u548c 32% \u7684\u5e45\u5ea6\u512a\u65bc\u7dda\u6027\u56de\u6b78\u548c ARIMA\u3002\u591a\u6a21\u5f0f\u9810\u6e2c\u6a21\u578b\u5728\u7cd6\u5c3f\u75c5\u524d\u671f\u6578\u64da\u96c6\u548c\u7761\u7720\u6578\u64da\u96c6\u4e0a\u4e5f\u5206\u5225\u4ee5 72% \u548c 79% \u7684\u6e96\u78ba\u5ea6\u57f7\u884c\u57fa\u65bc\u76ee\u6a19\u7684\u9810\u6e2c\u3002\u7d50\u8ad6\uff1a\u6211\u5011\u7684\u5be6\u9a57\u5f97\u51fa\u7d50\u8ad6\uff0c\u5177\u6709\u65e9\u671f\u878d\u5408\u7684\u591a\u6a21\u5f0f LSTM \u6a21\u578b\u6bd4\u5177\u6709\u5f8c\u671f\u878d\u5408\u7684\u591a\u6a21\u5f0f LSTM \u6a21\u578b\u548c\u55ae\u6a21\u5f0f LSTM \u6a21\u578b\u66f4\u597d\uff0c\u4e5f\u6bd4 ARIMA \u548c\u7dda\u6027\u56de\u6b78\u6a21\u578b\u66f4\u597d\u3002\u610f\u7fa9\uff1a\u6211\u5011\u89e3\u6c7a\u4e86\u5728\u4e0d\u53d7\u63a7\u74b0\u5883\u4e2d\u9032\u884c\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u7684\u4e00\u9805\u91cd\u8981\u4e14\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u6709\u6548\u9810\u6e2c\u500b\u4eba\u7684\u8eab\u9ad4\u6d3b\u52d5\u6709\u52a9\u65bc\u8a2d\u8a08\u9069\u61c9\u6027\u884c\u70ba\u4ecb\u5165\u63aa\u65bd\uff0c\u4ee5\u4fdd\u6301\u4f7f\u7528\u8005\u53c3\u8207\u4e26\u9075\u5b88\u898f\u5b9a\u7684\u4f8b\u884c\u516c\u4e8b\u3002", "author": "Abdullah Mamun et.al.", "authors": "Abdullah Mamun, Krista S. Leonard, Megan E. Petrov, Matthew P. Buman, Hassan Ghasemzadeh", "id": "2410.09643v1", "paper_url": "http://arxiv.org/abs/2410.09643v1", "repo": "https://github.com/ab9mamun/movesense"}}