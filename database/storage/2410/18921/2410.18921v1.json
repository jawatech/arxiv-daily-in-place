{"2410.18921": {"publish_time": "2024-10-24", "title": "From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems", "paper_summary": "Consider the math problem: \"Lily received 3 cookies from her best friend\nyesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.\nHow many cookies does Lily have now?\" Many large language models (LLMs) in\nprevious research approach this problem by calculating the answer \"1\" using the\nequation \"3 - 5 + 3.\" However, from a human perspective, we recognize the\ninherent flaw in this problem: Lily cannot eat 5 cookies if she initially only\nhad 3. This discrepancy prompts a key question: Are current LLMs merely Blind\nSolver that apply mathematical operations without deeper reasoning, or can they\nfunction as Logical Thinker capable of identifying logical inconsistencies?\n  To explore this question, we propose a benchmark dataset, FaultyMath, which\nincludes faulty math problems of rich diversity: i) multiple mathematical\ncategories, e.g., algebra, geometry, number theory, etc., ii) varying levels of\ndifficulty, and iii) different origins of faultiness -- ranging from violations\nof common sense and ambiguous statements to mathematical contradictions and\nmore. We evaluate a broad spectrum of LLMs, including open-source,\nclosed-source, and math-specialized models, using FaultyMath across three\ndimensions: (i) How accurately can the models detect faulty math problems\nwithout being explicitly prompted to do so? (ii) When provided with hints --\neither correct or misleading -- about the validity of the problems, to what\nextent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy\nare the explanations generated by LLMs when they recognize a math problem as\nflawed? Through extensive experimentation and detailed analysis, our results\ndemonstrate that existing LLMs largely function as Blind Solver and fall short\nof the reasoning capabilities required to perform as Logical Thinker.", "paper_summary_zh": "<paragraph>\u8003\u616e\u4ee5\u4e0b\u6578\u5b78\u554f\u984c\uff1a\u300c\u8389\u8389\u6628\u5929\u5f9e\u5979\u6700\u597d\u7684\u670b\u53cb\u90a3\u88e1\u6536\u5230 3 \u584a\u9905\u4e7e\uff0c\u4e26\u5728\u65e9\u9910\u6642\u5403\u4e86 5 \u584a\u3002\u4eca\u5929\uff0c\u5979\u7684\u670b\u53cb\u53c8\u7d66\u4e86\u5979 3 \u584a\u9905\u4e7e\u3002\u8389\u8389\u73fe\u5728\u6709\u5e7e\u584a\u9905\u4e7e\uff1f\u300d\u5728\u5148\u524d\u7684\u7814\u7a76\u4e2d\uff0c\u8a31\u591a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f7f\u7528\u300c3 - 5 + 3\u300d\u65b9\u7a0b\u5f0f\u8a08\u7b97\u7b54\u6848\u300c1\u300d\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u7136\u800c\uff0c\u5f9e\u4eba\u985e\u7684\u89d2\u5ea6\u4f86\u770b\uff0c\u6211\u5011\u767c\u73fe\u9019\u500b\u554f\u984c\u6709\u4e00\u500b\u56fa\u6709\u7684\u7f3a\u9677\uff1a\u8389\u8389\u6700\u521d\u53ea\u6709 3 \u584a\u9905\u4e7e\uff0c\u5979\u4e0d\u53ef\u80fd\u5403\u4e86 5 \u584a\u9905\u4e7e\u3002\u9019\u7a2e\u5dee\u7570\u5f15\u767c\u4e86\u4e00\u500b\u95dc\u9375\u554f\u984c\uff1a\u76ee\u524d\u7684 LLM \u662f\u5426\u50c5\u662f\u61c9\u7528\u6578\u5b78\u904b\u7b97\u800c\u6c92\u6709\u66f4\u6df1\u5165\u63a8\u7406\u7684\u76f2\u76ee\u6c42\u89e3\u5668\uff0c\u6216\u8005\u5b83\u5011\u53ef\u4ee5\u4f5c\u70ba\u80fd\u5920\u8b58\u5225\u908f\u8f2f\u4e0d\u4e00\u81f4\u6027\u7684\u908f\u8f2f\u601d\u8003\u8005\u904b\u4f5c\uff1f\u70ba\u4e86\u63a2\u8a0e\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u57fa\u6e96\u8cc7\u6599\u96c6 FaultyMath\uff0c\u5176\u4e2d\u5305\u542b\u8c50\u5bcc\u591a\u6a23\u7684\u6709\u7f3a\u9677\u6578\u5b78\u554f\u984c\uff1ai) \u591a\u500b\u6578\u5b78\u985e\u5225\uff0c\u4f8b\u5982\u4ee3\u6578\u3001\u5e7e\u4f55\u3001\u6578\u8ad6\u7b49\uff0cii) \u4e0d\u540c\u96e3\u5ea6\u7b49\u7d1a\uff0c\u4ee5\u53ca iii) \u7f3a\u9677\u7684\u4e0d\u540c\u4f86\u6e90\u2014\u2014\u5f9e\u9055\u53cd\u5e38\u8b58\u548c\u6a21\u68f1\u5169\u53ef\u7684\u9673\u8ff0\u5230\u6578\u5b78\u77db\u76fe\u7b49\u7b49\u3002\u6211\u5011\u4f7f\u7528 FaultyMath \u5728\u4e09\u500b\u9762\u5411\u8a55\u4f30\u5ee3\u6cdb\u7684 LLM\uff0c\u5305\u62ec\u958b\u6e90\u3001\u9589\u6e90\u548c\u6578\u5b78\u5c08\u7528\u6a21\u578b\uff1a(i) \u6a21\u578b\u5728\u6c92\u6709\u660e\u78ba\u63d0\u793a\u7684\u60c5\u6cc1\u4e0b\uff0c\u53ef\u4ee5\u591a\u6e96\u78ba\u5730\u5075\u6e2c\u6709\u7f3a\u9677\u7684\u6578\u5b78\u554f\u984c\uff1f(ii) \u7576\u63d0\u4f9b\u6709\u95dc\u554f\u984c\u6709\u6548\u6027\u7684\u63d0\u793a\uff08\u6b63\u78ba\u6216\u8aa4\u5c0e\uff09\u6642\uff0cLLM \u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u9069\u61c9\u6210\u70ba\u53ef\u9760\u7684\u908f\u8f2f\u601d\u8003\u8005\uff1f(iii) \u7576 LLM \u8b58\u5225\u51fa\u6578\u5b78\u554f\u984c\u6709\u7f3a\u9677\u6642\uff0c\u5b83\u5011\u7522\u751f\u7684\u89e3\u91cb\u6709\u591a\u503c\u5f97\u4fe1\u8cf4\uff1f\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\u548c\u8a73\u7d30\u7684\u5206\u6790\uff0c\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\u73fe\u6709\u7684 LLM \u4e3b\u8981\u4f5c\u70ba\u76f2\u76ee\u6c42\u89e3\u5668\u904b\u4f5c\uff0c\u4e26\u4e14\u7121\u6cd5\u9054\u5230\u4f5c\u70ba\u908f\u8f2f\u601d\u8003\u8005\u6240\u9700\u7684\u63a8\u7406\u80fd\u529b\u3002</paragraph>", "author": "A M Muntasir Rahman et.al.", "authors": "A M Muntasir Rahman, Junyi Ye, Wei Yao, Wenpeng Yin, Guiling Wang", "id": "2410.18921v1", "paper_url": "http://arxiv.org/abs/2410.18921v1", "repo": "null"}}