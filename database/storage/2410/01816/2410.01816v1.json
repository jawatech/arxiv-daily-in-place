{"2410.01816": {"publish_time": "2024-09-14", "title": "Automatic Scene Generation: State-of-the-Art Techniques, Models, Datasets, Challenges, and Future Prospects", "paper_summary": "Automatic scene generation is an essential area of research with applications\nin robotics, recreation, visual representation, training and simulation,\neducation, and more. This survey provides a comprehensive review of the current\nstate-of-the-arts in automatic scene generation, focusing on techniques that\nleverage machine learning, deep learning, embedded systems, and natural\nlanguage processing (NLP). We categorize the models into four main types:\nVariational Autoencoders (VAEs), Generative Adversarial Networks (GANs),\nTransformers, and Diffusion Models. Each category is explored in detail,\ndiscussing various sub-models and their contributions to the field.\n  We also review the most commonly used datasets, such as COCO-Stuff, Visual\nGenome, and MS-COCO, which are critical for training and evaluating these\nmodels. Methodologies for scene generation are examined, including image-to-3D\nconversion, text-to-3D generation, UI/layout design, graph-based methods, and\ninteractive scene generation. Evaluation metrics such as Frechet Inception\nDistance (FID), Kullback-Leibler (KL) Divergence, Inception Score (IS),\nIntersection over Union (IoU), and Mean Average Precision (mAP) are discussed\nin the context of their use in assessing model performance.\n  The survey identifies key challenges and limitations in the field, such as\nmaintaining realism, handling complex scenes with multiple objects, and\nensuring consistency in object relationships and spatial arrangements. By\nsummarizing recent advances and pinpointing areas for improvement, this survey\naims to provide a valuable resource for researchers and practitioners working\non automatic scene generation.", "paper_summary_zh": "\u81ea\u52d5\u5834\u666f\u751f\u6210\u662f\u7814\u7a76\u7684\u91cd\u8981\u9818\u57df\uff0c\u5176\u61c9\u7528\u5305\u62ec\u6a5f\u5668\u4eba\u6280\u8853\u3001\u5a1b\u6a02\u3001\u8996\u89ba\u8868\u793a\u3001\u8a13\u7df4\u8207\u6a21\u64ec\u3001\u6559\u80b2\u7b49\u7b49\u3002\u9019\u9805\u8abf\u67e5\u5168\u9762\u56de\u9867\u4e86\u81ea\u52d5\u5834\u666f\u751f\u6210\u4e2d\u7576\u524d\u6700\u5148\u9032\u7684\u6280\u8853\uff0c\u91cd\u9ede\u5728\u65bc\u5229\u7528\u6a5f\u5668\u5b78\u7fd2\u3001\u6df1\u5ea6\u5b78\u7fd2\u3001\u5d4c\u5165\u5f0f\u7cfb\u7d71\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7684\u6280\u8853\u3002\u6211\u5011\u5c07\u6a21\u578b\u5206\u985e\u70ba\u56db\u7a2e\u985e\u578b\uff1a\u8b8a\u7570\u81ea\u52d5\u7de8\u78bc\u5668 (VAE)\u3001\u751f\u6210\u5c0d\u6297\u7db2\u8def (GAN)\u3001Transformer \u548c\u64f4\u6563\u6a21\u578b\u3002\u6211\u5011\u8a73\u7d30\u63a2\u8a0e\u4e86\u6bcf\u500b\u985e\u5225\uff0c\u8a0e\u8ad6\u4e86\u5404\u7a2e\u5b50\u6a21\u578b\u53ca\u5176\u5c0d\u8a72\u9818\u57df\u7684\u8ca2\u737b\u3002\n  \u6211\u5011\u4e5f\u56de\u9867\u4e86\u6700\u5e38\u4f7f\u7528\u7684\u8cc7\u6599\u96c6\uff0c\u4f8b\u5982 COCO-Stuff\u3001Visual Genome \u548c MS-COCO\uff0c\u9019\u4e9b\u8cc7\u6599\u96c6\u5c0d\u65bc\u8a13\u7df4\u548c\u8a55\u4f30\u9019\u4e9b\u6a21\u578b\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u6aa2\u8996\u4e86\u5834\u666f\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5f71\u50cf\u8f49 3D\u3001\u6587\u5b57\u8f49 3D \u751f\u6210\u3001UI/\u7248\u9762\u8a2d\u8a08\u3001\u57fa\u65bc\u5716\u5f62\u7684\u6a21\u578b\u548c\u4e92\u52d5\u5f0f\u5834\u666f\u751f\u6210\u3002\u6211\u5011\u5728\u8a55\u4f30\u6a21\u578b\u6548\u80fd\u7684\u8108\u7d61\u4e2d\u8a0e\u8ad6\u4e86\u8a55\u4f30\u6307\u6a19\uff0c\u4f8b\u5982 Fr\u00e9chet \u8d77\u59cb\u8ddd\u96e2 (FID)\u3001Kullback-Leibler (KL) \u5dee\u7570\u3001\u8d77\u59cb\u5206\u6578 (IS)\u3001\u4ea4\u96c6\u6bd4\u806f\u96c6 (IoU) \u548c\u5e73\u5747\u6e96\u78ba\u7387 (mAP)\u3002\n  \u9019\u9805\u8abf\u67e5\u627e\u51fa\u8a72\u9818\u57df\u7684\u4e3b\u8981\u6311\u6230\u548c\u9650\u5236\uff0c\u4f8b\u5982\u7dad\u6301\u771f\u5be6\u6027\u3001\u8655\u7406\u5305\u542b\u591a\u500b\u7269\u4ef6\u7684\u8907\u96dc\u5834\u666f\uff0c\u4ee5\u53ca\u78ba\u4fdd\u7269\u4ef6\u95dc\u4fc2\u548c\u7a7a\u9593\u914d\u7f6e\u7684\u4e00\u81f4\u6027\u3002\u900f\u904e\u7e3d\u7d50\u6700\u8fd1\u7684\u9032\u5c55\u4e26\u627e\u51fa\u9700\u8981\u6539\u9032\u7684\u5730\u65b9\uff0c\u9019\u9805\u8abf\u67e5\u65e8\u5728\u70ba\u5f9e\u4e8b\u81ea\u52d5\u5834\u666f\u751f\u6210\u7684\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u4eba\u54e1\u63d0\u4f9b\u5bf6\u8cb4\u7684\u8cc7\u6e90\u3002", "author": "Awal Ahmed Fime et.al.", "authors": "Awal Ahmed Fime, Saifuddin Mahmud, Arpita Das, Md. Sunzidul Islam, Hong-Hoon Kim", "id": "2410.01816v1", "paper_url": "http://arxiv.org/abs/2410.01816v1", "repo": "null"}}