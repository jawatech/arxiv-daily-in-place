{"2502.02153": {"publish_time": "2025-02-04", "title": "Vulnerability Mitigation for Safety-Aligned Language Models via Debiasing", "paper_summary": "Safety alignment is an essential research topic for real-world AI\napplications. Despite the multifaceted nature of safety and trustworthiness in\nAI, current safety alignment methods often focus on a comprehensive notion of\nsafety. By carefully assessing models from the existing safety-alignment\nmethods, we found that, while they generally improved overall safety\nperformance, they failed to ensure safety in specific categories. Our study\nfirst identified the difficulty of eliminating such vulnerabilities without\nsacrificing the model's helpfulness. We observed that, while smaller KL penalty\nparameters, increased training iterations, and dataset cleansing can enhance\nsafety, they do not necessarily improve the trade-off between safety and\nhelpfulness. We discovered that safety alignment could even induce undesired\neffects and result in a model that prefers generating negative tokens leading\nto rejective responses, regardless of the input context. To address this, we\nintroduced a learning-free method, Token-level Safety-Debiased Inference\n(TSDI), to estimate and correct this bias during the generation process using\nrandomly constructed prompts. Our experiments demonstrated that our method\ncould enhance the model's helpfulness while maintaining safety, thus improving\nthe trade-off Pareto-front.", "paper_summary_zh": "\u5b89\u5168\u6821\u6e96\u662f\u771f\u5be6\u4e16\u754c AI \u61c9\u7528\u4e2d\u4e00\u500b\u91cd\u8981\u7684\u7814\u7a76\u4e3b\u984c\u3002\u5118\u7ba1 AI \u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u8cf4\u6027\u5177\u6709\u591a\u65b9\u9762\u7684\u6027\u8cea\uff0c\u4f46\u7576\u524d\u7684\u5b89\u5168\u6821\u6e96\u65b9\u6cd5\u901a\u5e38\u5074\u91cd\u65bc\u5168\u9762\u7684\u5b89\u5168\u6982\u5ff5\u3002\u901a\u904e\u4ed4\u7d30\u8a55\u4f30\u73fe\u6709\u5b89\u5168\u6821\u6e96\u65b9\u6cd5\u4e2d\u7684\u6a21\u578b\uff0c\u6211\u5011\u767c\u73fe\uff0c\u5118\u7ba1\u5b83\u5011\u666e\u904d\u6539\u5584\u4e86\u6574\u9ad4\u5b89\u5168\u6027\u80fd\uff0c\u4f46\u5b83\u5011\u672a\u80fd\u78ba\u4fdd\u7279\u5b9a\u985e\u5225\u4e2d\u7684\u5b89\u5168\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u9996\u5148\u78ba\u5b9a\u4e86\u5728\u4e0d\u72a7\u7272\u6a21\u578b\u7684\u5e6b\u52a9\u4e0b\u6d88\u9664\u6b64\u985e\u6f0f\u6d1e\u7684\u96e3\u5ea6\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u5118\u7ba1\u8f03\u5c0f\u7684 KL \u61f2\u7f70\u53c3\u6578\u3001\u589e\u52a0\u7684\u8a13\u7df4\u8fed\u4ee3\u548c\u8cc7\u6599\u96c6\u6e05\u7406\u53ef\u4ee5\u589e\u5f37\u5b89\u5168\u6027\uff0c\u4f46\u5b83\u5011\u4e0d\u4e00\u5b9a\u80fd\u6539\u5584\u5b89\u5168\u6027\u548c\u5e6b\u52a9\u4e4b\u9593\u7684\u6b0a\u8861\u3002\u6211\u5011\u767c\u73fe\uff0c\u5b89\u5168\u6821\u6e96\u751a\u81f3\u6703\u8a98\u767c\u4e0d\u826f\u5f71\u97ff\uff0c\u4e26\u5c0e\u81f4\u6a21\u578b\u504f\u597d\u7522\u751f\u8ca0\u9762\u4ee3\u5e63\uff0c\u5f9e\u800c\u5c0e\u81f4\u62d2\u7d55\u56de\u61c9\uff0c\u800c\u4e0d\u7ba1\u8f38\u5165\u5167\u5bb9\u5982\u4f55\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u7121\u5b78\u7fd2\u65b9\u6cd5\uff0c\u5373\u4ee3\u5e63\u7d1a\u5225\u5b89\u5168\u53bb\u504f\u5dee\u63a8\u8ad6 (TSDI)\uff0c\u4ee5\u5728\u751f\u6210\u904e\u7a0b\u4e2d\u4f7f\u7528\u96a8\u6a5f\u69cb\u9020\u7684\u63d0\u793a\u4f86\u4f30\u8a08\u548c\u7cfe\u6b63\u9019\u7a2e\u504f\u5dee\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u6642\u589e\u5f37\u6a21\u578b\u7684\u5e6b\u52a9\uff0c\u5f9e\u800c\u6539\u5584\u6b0a\u8861\u5e15\u7d2f\u6258\u524d\u7de3\u3002", "author": "Thien Q. Tran et.al.", "authors": "Thien Q. Tran, Akifumi Wachi, Rei Sato, Takumi Tanabe, Youhei Akimoto", "id": "2502.02153v1", "paper_url": "http://arxiv.org/abs/2502.02153v1", "repo": "null"}}