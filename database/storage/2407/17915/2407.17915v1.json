{"2407.17915": {"publish_time": "2024-07-25", "title": "The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models", "paper_summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir power comes with significant security considerations. While extensive\nresearch has been conducted on the safety of LLMs in chat mode, the security\nimplications of their function calling feature have been largely overlooked.\nThis paper uncovers a critical vulnerability in the function calling process of\nLLMs, introducing a novel \"jailbreak function\" attack method that exploits\nalignment discrepancies, user coercion, and the absence of rigorous safety\nfilters. Our empirical study, conducted on six state-of-the-art LLMs including\nGPT-4o, Claude-3.5-Sonnet, and Gemini-1.5-pro, reveals an alarming average\nsuccess rate of over 90\\% for this attack. We provide a comprehensive analysis\nof why function calls are susceptible to such attacks and propose defensive\nstrategies, including the use of defensive prompts. Our findings highlight the\nurgent need for enhanced security measures in the function calling capabilities\nof LLMs, contributing to the field of AI safety by identifying a previously\nunexplored risk, designing an effective attack method, and suggesting practical\ndefensive measures. Our code is available at\nhttps://github.com/wooozihui/jailbreakfunction.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u793a\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5176\u80fd\u529b\u4f34\u96a8\u8457\u91cd\u5927\u7684\u5b89\u5168\u8003\u91cf\u3002\u5118\u7ba1\u5df2\u5c0d\u804a\u5929\u6a21\u5f0f\u4e2d LLM \u7684\u5b89\u5168\u6027\u9032\u884c\u5ee3\u6cdb\u7684\u7814\u7a76\uff0c\u4f46\u5176\u51fd\u6578\u547c\u53eb\u529f\u80fd\u7684\u5b89\u5168\u5f71\u97ff\u537b\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u88ab\u5ffd\u8996\u3002\u672c\u6587\u63ed\u9732\u4e86 LLM \u51fd\u6578\u547c\u53eb\u904e\u7a0b\u4e2d\u7684\u4e00\u500b\u91cd\u5927\u6f0f\u6d1e\uff0c\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u300c\u8d8a\u7344\u51fd\u6578\u300d\u653b\u64ca\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u5229\u7528\u5c0d\u9f4a\u5dee\u7570\u3001\u4f7f\u7528\u8005\u5f37\u5236\u548c\u7f3a\u4e4f\u56b4\u683c\u7684\u5b89\u5168\u904e\u6ffe\u5668\u3002\u6211\u5011\u91dd\u5c0d\u516d\u7a2e\u6700\u5148\u9032\u7684 LLM\uff08\u5305\u62ec GPT-4o\u3001Claude-3.5-Sonnet \u548c Gemini-1.5-pro\uff09\u9032\u884c\u7684\u5be6\u8b49\u7814\u7a76\u986f\u793a\uff0c\u9019\u7a2e\u653b\u64ca\u7684\u5e73\u5747\u6210\u529f\u7387\u9ad8\u9054 90%\uff0c\u4ee4\u4eba\u582a\u6182\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u51fd\u6578\u547c\u53eb\u5bb9\u6613\u53d7\u5230\u6b64\u985e\u653b\u64ca\u7684\u539f\u56e0\u7684\u5168\u9762\u5206\u6790\uff0c\u4e26\u63d0\u51fa\u4e86\u9632\u79a6\u7b56\u7565\uff0c\u5305\u62ec\u4f7f\u7528\u9632\u79a6\u63d0\u793a\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\u4e86\u8feb\u5207\u9700\u8981\u589e\u5f37 LLM \u51fd\u6578\u547c\u53eb\u529f\u80fd\u4e2d\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u901a\u904e\u8b58\u5225\u4ee5\u524d\u672a\u63a2\u7d22\u7684\u98a8\u96aa\u3001\u8a2d\u8a08\u6709\u6548\u7684\u653b\u64ca\u65b9\u6cd5\u548c\u5efa\u8b70\u5be6\u7528\u7684\u9632\u79a6\u63aa\u65bd\uff0c\u70ba AI \u5b89\u5168\u9818\u57df\u505a\u51fa\u8ca2\u737b\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/wooozihui/jailbreakfunction \u53d6\u5f97\u3002", "author": "Zihui Wu et.al.", "authors": "Zihui Wu, Haichang Gao, Jianping He, Ping Wang", "id": "2407.17915v1", "paper_url": "http://arxiv.org/abs/2407.17915v1", "repo": "https://github.com/wooozihui/jailbreakfunction"}}