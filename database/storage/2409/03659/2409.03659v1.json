{"2409.03659": {"publish_time": "2024-09-05", "title": "LLM-based multi-agent poetry generation in non-cooperative environments", "paper_summary": "Despite substantial progress of large language models (LLMs) for automatic\npoetry generation, the generated poetry lacks diversity while the training\nprocess differs greatly from human learning. Under the rationale that the\nlearning process of the poetry generation systems should be more human-like and\ntheir output more diverse and novel, we introduce a framework based on social\nlearning where we emphasize non-cooperative interactions besides cooperative\ninteractions to encourage diversity. Our experiments are the first attempt at\nLLM-based multi-agent systems in non-cooperative environments for poetry\ngeneration employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED\nagents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows\nthat our framework benefits the poetry generation process for TRAINING-BASED\nagents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity\nand a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams.\nThe generated poetry from TRAINING-BASED agents also exhibits group divergence\nin terms of lexicons, styles and semantics. PROMPTING-BASED agents in our\nframework also benefit from non-cooperative environments and a more diverse\nensemble of models with non-homogeneous agents has the potential to further\nenhance diversity, with an increase of 7.0-17.5 pp according to our\nexperiments. However, PROMPTING-BASED agents show a decrease in lexical\ndiversity over time and do not exhibit the group-based divergence intended in\nthe social network. Our paper argues for a paradigm shift in creative tasks\nsuch as automatic poetry generation to include social learning processes (via\nLLM-based agent modeling) similar to human interaction.", "paper_summary_zh": "<paragraph>\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u52d5\u8a69\u6b4c\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\uff0c\u4f46\u751f\u6210\u7684\u8a69\u6b4c\u7f3a\u4e4f\u591a\u6a23\u6027\uff0c\u800c\u8a13\u7df4\u904e\u7a0b\u8207\u4eba\u985e\u5b78\u7fd2\u6709\u5f88\u5927\u4e0d\u540c\u3002\u57fa\u65bc\u8a69\u6b4c\u751f\u6210\u7cfb\u7d71\u7684\u5b78\u7fd2\u904e\u7a0b\u61c9\u66f4\u50cf\u4eba\u985e\uff0c\u5176\u8f38\u51fa\u61c9\u66f4\u5177\u591a\u6a23\u6027\u548c\u65b0\u7a4e\u6027\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u57fa\u65bc\u793e\u6703\u5b78\u7fd2\u7684\u6846\u67b6\uff0c\u5728\u5176\u4e2d\u6211\u5011\u5f37\u8abf\u975e\u5408\u4f5c\u4e92\u52d5\uff0c\u9664\u4e86\u5408\u4f5c\u4e92\u52d5\u4ee5\u9f13\u52f5\u591a\u6a23\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u662f LLM \u70ba\u57fa\u790e\u7684\u591a\u4ee3\u7406\u7cfb\u7d71\u5728\u975e\u5408\u4f5c\u74b0\u5883\u4e2d\u751f\u6210\u8a69\u6b4c\u7684\u9996\u6b21\u5617\u8a66\uff0c\u63a1\u7528\u57fa\u65bc\u8a13\u7df4\u7684\u4ee3\u7406\uff08GPT-2\uff09\u548c\u57fa\u65bc\u63d0\u793a\u7684\u4ee3\u7406\uff08GPT-3 \u548c GPT-4\uff09\u3002\u6211\u5011\u6839\u64da 96k \u9996\u751f\u6210\u7684\u8a69\u6b4c\u9032\u884c\u8a55\u4f30\uff0c\u986f\u793a\u6211\u5011\u7684\u6846\u67b6\u6709\u5229\u65bc\u57fa\u65bc\u8a13\u7df4\u7684\u4ee3\u7406\u7684\u8a69\u6b4c\u751f\u6210\u904e\u7a0b\uff0c\u5c0e\u81f4 1) \u591a\u6a23\u6027\u589e\u52a0 3.0-3.7 \u500b\u767e\u5206\u9ede (pp)\uff0c\u6839\u64da\u4e0d\u540c\u7684\u65b0\u7a4e n-gram\uff0c\u65b0\u7a4e\u6027\u589e\u52a0 5.6-11.3 pp\u3002\u57fa\u65bc\u8a13\u7df4\u7684\u4ee3\u7406\u6240\u751f\u6210\u7684\u8a69\u6b4c\u5728\u8a5e\u5f59\u3001\u98a8\u683c\u548c\u8a9e\u7fa9\u65b9\u9762\u4e5f\u8868\u73fe\u51fa\u7fa4\u9ad4\u5dee\u7570\u3002\u6211\u5011\u6846\u67b6\u4e2d\u7684\u57fa\u65bc\u63d0\u793a\u7684\u4ee3\u7406\u4e5f\u53d7\u76ca\u65bc\u975e\u5408\u4f5c\u74b0\u5883\uff0c\u4e26\u4e14\u5177\u6709\u975e\u540c\u8cea\u4ee3\u7406\u7684\u591a\u6a23\u5316\u6a21\u578b\u96c6\u5408\u6709\u53ef\u80fd\u9032\u4e00\u6b65\u63d0\u9ad8\u591a\u6a23\u6027\uff0c\u6839\u64da\u6211\u5011\u7684\u5be6\u9a57\uff0c\u589e\u52a0\u4e86 7.0-17.5 pp\u3002\u7136\u800c\uff0c\u57fa\u65bc\u63d0\u793a\u7684\u4ee3\u7406\u6703\u96a8\u8457\u6642\u9593\u63a8\u79fb\u800c\u964d\u4f4e\u8a5e\u5f59\u591a\u6a23\u6027\uff0c\u4e26\u4e14\u4e0d\u6703\u8868\u73fe\u51fa\u793e\u4ea4\u7db2\u8def\u4e2d\u9810\u671f\u7684\u57fa\u65bc\u7fa4\u9ad4\u7684\u5dee\u7570\u3002\u6211\u5011\u7684\u8ad6\u6587\u4e3b\u5f35\u5728\u5275\u9020\u6027\u4efb\u52d9\uff08\u4f8b\u5982\u81ea\u52d5\u8a69\u6b4c\u751f\u6210\uff09\u4e2d\u9032\u884c\u5178\u7bc4\u8f49\u79fb\uff0c\u4ee5\u7d0d\u5165\u985e\u4f3c\u65bc\u4eba\u985e\u4e92\u52d5\u7684\u793e\u6703\u5b78\u7fd2\u904e\u7a0b\uff08\u901a\u904e\u57fa\u65bc LLM \u7684\u4ee3\u7406\u5efa\u6a21\uff09\u3002</paragraph>", "author": "Ran Zhang et.al.", "authors": "Ran Zhang, Steffen Eger", "id": "2409.03659v1", "paper_url": "http://arxiv.org/abs/2409.03659v1", "repo": "https://github.com/zhangr2021/Multiagent_poetry"}}