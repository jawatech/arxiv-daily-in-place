{"2407.09164": {"publish_time": "2024-07-12", "title": "TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs", "paper_summary": "Recently, code-oriented large language models (Code LLMs) have been widely\nand successfully used to simplify and facilitate code programming. With these\ntools, developers can easily generate desired complete functional codes based\non incomplete code and natural language prompts. However, a few pioneering\nworks revealed that these Code LLMs are also vulnerable, e.g., against backdoor\nand adversarial attacks. The former could induce LLMs to respond to triggers to\ninsert malicious code snippets by poisoning the training data or model\nparameters, while the latter can craft malicious adversarial input codes to\nreduce the quality of generated codes. However, both attack methods have\nunderlying limitations: backdoor attacks rely on controlling the model training\nprocess, while adversarial attacks struggle with fulfilling specific malicious\npurposes.\n  To inherit the advantages of both backdoor and adversarial attacks, this\npaper proposes a new attack paradigm, i.e., target-specific and adversarial\nprompt injection (TAPI), against Code LLMs. TAPI generates unreadable comments\ncontaining information about malicious instructions and hides them as triggers\nin the external source code. When users exploit Code LLMs to complete codes\ncontaining the trigger, the models will generate attacker-specified malicious\ncode snippets at specific locations. We evaluate our TAPI attack on four\nrepresentative LLMs under three representative malicious objectives and seven\ncases. The results show that our method is highly threatening (achieving an\nattack success rate of up to 89.3\\%) and stealthy (saving an average of 53.1\\%\nof tokens in the trigger design). In particular, we successfully attack some\nfamous deployed code completion integrated applications, including CodeGeex and\nGithub Copilot. This further confirms the realistic threat of our attack.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u9762\u5411\u4ee3\u7801\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u4ee3\u7801 LLM\uff09\u5df2\u88ab\u5e7f\u6cdb\u4e14\u6210\u529f\u5730\u7528\u4e8e\u7b80\u5316\u548c\u4fc3\u8fdb\u4ee3\u7801\u7f16\u7a0b\u3002\u501f\u52a9\u8fd9\u4e9b\u5de5\u5177\uff0c\u5f00\u53d1\u4eba\u5458\u53ef\u4ee5\u8f7b\u677e\u5730\u6839\u636e\u4e0d\u5b8c\u6574\u7684\u4ee3\u7801\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u751f\u6210\u6240\u9700\u7684\u5b8c\u6574\u529f\u80fd\u4ee3\u7801\u3002\u7136\u800c\uff0c\u4e00\u4e9b\u5f00\u521b\u6027\u7684\u5de5\u4f5c\u63ed\u793a\u4e86\u8fd9\u4e9b\u4ee3\u7801 LLM \u4e5f\u5b58\u5728\u6f0f\u6d1e\uff0c\u4f8b\u5982\uff0c\u9488\u5bf9\u540e\u95e8\u548c\u5bf9\u6297\u6027\u653b\u51fb\u3002\u524d\u8005\u53ef\u4ee5\u901a\u8fc7\u6bd2\u5316\u8bad\u7ec3\u6570\u636e\u6216\u6a21\u578b\u53c2\u6570\u6765\u8bf1\u4f7f LLM \u54cd\u5e94\u89e6\u53d1\u5668\u4ee5\u63d2\u5165\u6076\u610f\u4ee3\u7801\u7247\u6bb5\uff0c\u800c\u540e\u8005\u53ef\u4ee5\u5236\u4f5c\u6076\u610f\u7684\u5bf9\u6297\u6027\u8f93\u5165\u4ee3\u7801\u6765\u964d\u4f4e\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u3002\u7136\u800c\uff0c\u8fd9\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\u90fd\u6709\u6f5c\u5728\u7684\u9650\u5236\uff1a\u540e\u95e8\u653b\u51fb\u4f9d\u8d56\u4e8e\u63a7\u5236\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u800c\u5bf9\u6297\u6027\u653b\u51fb\u5219\u96be\u4ee5\u5b9e\u73b0\u7279\u5b9a\u7684\u6076\u610f\u76ee\u7684\u3002\n\u4e3a\u4e86\u7ee7\u627f\u540e\u95e8\u548c\u5bf9\u6297\u6027\u653b\u51fb\u7684\u4f18\u70b9\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u653b\u51fb\u8303\u4f8b\uff0c\u5373\u9488\u5bf9\u7279\u5b9a\u76ee\u6807\u7684\u5bf9\u6297\u6027\u63d0\u793a\u6ce8\u5165\uff08TAPI\uff09\uff0c\u9488\u5bf9\u4ee3\u7801 LLM\u3002TAPI \u751f\u6210\u4e86\u5305\u542b\u6709\u5173\u6076\u610f\u6307\u4ee4\u4fe1\u606f\u4e14\u4e0d\u53ef\u8bfb\u7684\u6ce8\u91ca\uff0c\u5e76\u5c06\u5b83\u4eec\u9690\u85cf\u4e3a\u5916\u90e8\u6e90\u4ee3\u7801\u4e2d\u7684\u89e6\u53d1\u5668\u3002\u5f53\u7528\u6237\u5229\u7528\u4ee3\u7801 LLM \u5b8c\u6210\u5305\u542b\u89e6\u53d1\u5668\u7684\u4ee3\u7801\u65f6\uff0c\u6a21\u578b\u5c06\u5728\u7279\u5b9a\u4f4d\u7f6e\u751f\u6210\u653b\u51fb\u8005\u6307\u5b9a\u7684\u6076\u610f\u4ee3\u7801\u7247\u6bb5\u3002\u6211\u4eec\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u6076\u610f\u76ee\u6807\u548c\u4e03\u4e2a\u6848\u4f8b\u4e0b\u5bf9\u56db\u4e2a\u4ee3\u8868\u6027 LLM \u8bc4\u4f30\u4e86\u6211\u4eec\u7684 TAPI \u653b\u51fb\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6781\u5177\u5a01\u80c1\u6027\uff08\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe 89.3%\uff09\u4e14\u9690\u853d\uff08\u5728\u89e6\u53d1\u5668\u8bbe\u8ba1\u4e2d\u5e73\u5747\u8282\u7701\u4e86 53.1% \u7684\u6807\u8bb0\uff09\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u6210\u529f\u653b\u51fb\u4e86\u4e00\u4e9b\u8457\u540d\u7684\u5df2\u90e8\u7f72\u4ee3\u7801\u5b8c\u6210\u96c6\u6210\u5e94\u7528\u7a0b\u5e8f\uff0c\u5305\u62ec CodeGeex \u548c Github Copilot\u3002\u8fd9\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u6211\u4eec\u653b\u51fb\u7684\u73b0\u5b9e\u5a01\u80c1\u3002</paragraph>", "author": "Yuchen Yang et.al.", "authors": "Yuchen Yang, Hongwei Yao, Bingrun Yang, Yiling He, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren", "id": "2407.09164v1", "paper_url": "http://arxiv.org/abs/2407.09164v1", "repo": "null"}}