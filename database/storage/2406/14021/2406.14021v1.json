{"2406.14021": {"publish_time": "2024-06-20", "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment", "paper_summary": "Recently there has been a surge of interest in extending the success of large\nlanguage models (LLMs) to graph modality, such as social networks and\nmolecules. As LLMs are predominantly trained with 1D text data, most existing\napproaches adopt a graph neural network to represent a graph as a series of\nnode tokens and feed these tokens to LLMs for graph-language alignment. Despite\nachieving some successes, existing approaches have overlooked the hierarchical\nstructures that are inherent in graph data. Especially, in molecular graphs,\nthe high-order structural information contains rich semantics of molecular\nfunctional groups, which encode crucial biochemical functionalities of the\nmolecules. We establish a simple benchmark showing that neglecting the\nhierarchical information in graph tokenization will lead to subpar\ngraph-language alignment and severe hallucination in generated outputs. To\naddress this problem, we propose a novel strategy called HIerarchical GrapH\nTokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that\nextracts and encodes the hierarchy of node, motif, and graph levels of\ninformative tokens to improve the graph perception of LLMs. HIGHT also adopts\nan augmented graph-language supervised fine-tuning dataset, enriched with the\nhierarchical graph information, to further enhance the graph-language\nalignment. Extensive experiments on 7 molecule-centric benchmarks confirm the\neffectiveness of HIGHT in reducing hallucination by 40%, as well as significant\nimprovements in various molecule-language downstream tasks.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u4eba\u4eec\u5bf9\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u6210\u529f\u6269\u5c55\u5230\u56fe\u6a21\u5f0f\uff08\u4f8b\u5982\u793e\u4ea4\u7f51\u7edc\u548c\u5206\u5b50\uff09\u4ea7\u751f\u4e86\u6d53\u539a\u7684\u5174\u8da3\u3002\u7531\u4e8e LLM \u4e3b\u8981\u4f7f\u7528\u4e00\u7ef4\u6587\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u6b64\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5c06\u56fe\u8868\u793a\u4e3a\u4e00\u7cfb\u5217\u8282\u70b9\u6807\u8bb0\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6807\u8bb0\u9988\u9001\u81f3 LLM \u4ee5\u8fdb\u884c\u56fe\u8bed\u8a00\u5bf9\u9f50\u3002\u5c3d\u7ba1\u53d6\u5f97\u4e86\u4e00\u4e9b\u6210\u529f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5374\u5ffd\u89c6\u4e86\u56fe\u6570\u636e\u4e2d\u56fa\u6709\u7684\u5c42\u6b21\u7ed3\u6784\u3002\u7279\u522b\u662f\u5728\u5206\u5b50\u56fe\u4e2d\uff0c\u9ad8\u9636\u7ed3\u6784\u4fe1\u606f\u5305\u542b\u4e30\u5bcc\u7684\u5206\u5b50\u5b98\u80fd\u56e2\u8bed\u4e49\uff0c\u5b83\u5bf9\u5206\u5b50\u7684\u5173\u952e\u751f\u5316\u529f\u80fd\u8fdb\u884c\u7f16\u7801\u3002\u6211\u4eec\u5efa\u7acb\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u51c6\uff0c\u8868\u660e\u5728\u56fe\u6807\u8bb0\u5316\u4e2d\u5ffd\u7565\u5c42\u6b21\u4fe1\u606f\u4f1a\u5bfc\u81f4\u6b21\u4f18\u7684\u56fe\u8bed\u8a00\u5bf9\u9f50\uff0c\u5e76\u5728\u751f\u6210\u7684\u8f93\u51fa\u4e2d\u51fa\u73b0\u4e25\u91cd\u7684\u5e7b\u89c9\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u5206\u5c42\u56fe\u6807\u8bb0\u5316 (HIGHT) \u7684\u65b0\u7b56\u7565\u3002HIGHT \u91c7\u7528\u5206\u5c42\u56fe\u6807\u8bb0\u5668\uff0c\u8be5\u6807\u8bb0\u5668\u63d0\u53d6\u548c\u7f16\u7801\u4fe1\u606f\u6807\u8bb0\u7684\u8282\u70b9\u3001\u4e3b\u9898\u548c\u56fe\u7ea7\u522b\u5c42\u6b21\u7ed3\u6784\uff0c\u4ee5\u6539\u5584 LLM \u7684\u56fe\u611f\u77e5\u3002HIGHT \u8fd8\u91c7\u7528\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u6269\u5145\u7684\u56fe\u8bed\u8a00\u76d1\u7763\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u5206\u5c42\u56fe\u4fe1\u606f\uff0c\u4ee5\u8fdb\u4e00\u6b65\u589e\u5f3a\u56fe\u8bed\u8a00\u5bf9\u9f50\u3002\u5728 7 \u4e2a\u4ee5\u5206\u5b50\u4e3a\u4e2d\u5fc3\u7684\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u5b9e\u4e86 HIGHT \u5728\u5c06\u5e7b\u89c9\u51cf\u5c11 40% \u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5728\u5404\u79cd\u5206\u5b50\u8bed\u8a00\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u6539\u8fdb\u3002</paragraph>", "author": "Yongqiang Chen et.al.", "authors": "Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian", "id": "2406.14021v1", "paper_url": "http://arxiv.org/abs/2406.14021v1", "repo": "null"}}