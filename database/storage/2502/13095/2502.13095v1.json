{"2502.13095": {"publish_time": "2025-02-18", "title": "Understanding and Rectifying Safety Perception Distortion in VLMs", "paper_summary": "Recent studies reveal that vision-language models (VLMs) become more\nsusceptible to harmful requests and jailbreak attacks after integrating the\nvision modality, exhibiting greater vulnerability than their text-only LLM\nbackbones. To uncover the root cause of this phenomenon, we conduct an in-depth\nanalysis and identify a key issue: multimodal inputs introduce an\nmodality-induced activation shift toward a \"safer\" direction compared to their\ntext-only counterparts, leading VLMs to systematically overestimate the safety\nof harmful inputs. We refer to this issue as safety perception distortion. To\nmitigate such distortion, we propose Activation Shift Disentanglement and\nCalibration (ShiftDC), a training-free method that decomposes and calibrates\nthe modality-induced activation shift to reduce the impact of modality on\nsafety. By isolating and removing the safety-relevant component, ShiftDC\nrestores the inherent safety alignment of the LLM backbone while preserving the\nvision-language capabilities of VLMs. Empirical results demonstrate that\nShiftDC significantly enhances alignment performance on safety benchmarks\nwithout impairing model utility.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u6574\u5408\u4e86\u89c6\u89c9\u6a21\u6001\u540e\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u66f4\u5bb9\u6613\u53d7\u5230\u6709\u5bb3\u8bf7\u6c42\u548c\u8d8a\u72f1\u653b\u51fb\uff0c\u8868\u73b0\u51fa\u6bd4\u5176\u4ec5\u6587\u672c\u7684 LLM \u4e3b\u5e72\u66f4\u5927\u7684\u6f0f\u6d1e\u3002\u4e3a\u4e86\u63ed\u793a\u8fd9\u79cd\u73b0\u8c61\u7684\u6839\u672c\u539f\u56e0\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u5e76\u786e\u5b9a\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4e0e\u4ec5\u6587\u672c\u7684\u5bf9\u5e94\u7269\u76f8\u6bd4\uff0c\u591a\u6a21\u6001\u8f93\u5165\u5f15\u5165\u4e86\u671d\u201c\u66f4\u5b89\u5168\u201d\u65b9\u5411\u7684\u6a21\u6001\u8bf1\u5bfc\u6fc0\u6d3b\u8f6c\u79fb\uff0c\u5bfc\u81f4 VLM \u7cfb\u7edf\u6027\u5730\u9ad8\u4f30\u6709\u5bb3\u8f93\u5165\u7684\u5b89\u5168\u6027\u3002\u6211\u4eec\u5c06\u6b64\u95ee\u9898\u79f0\u4e3a\u5b89\u5168\u611f\u77e5\u626d\u66f2\u3002\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u79cd\u626d\u66f2\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6fc0\u6d3b\u8f6c\u79fb\u89e3\u8026\u548c\u6821\u51c6 (ShiftDC)\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u89e3\u548c\u6821\u51c6\u6a21\u6001\u8bf1\u5bfc\u7684\u6fc0\u6d3b\u8f6c\u79fb\uff0c\u4ee5\u51cf\u5c11\u6a21\u6001\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u9694\u79bb\u548c\u79fb\u9664\u4e0e\u5b89\u5168\u6027\u76f8\u5173\u7684\u7ec4\u4ef6\uff0cShiftDC \u6062\u590d\u4e86 LLM \u4e3b\u5e72\u7684\u56fa\u6709\u5b89\u5168\u6027\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u7559\u4e86 VLM \u7684\u89c6\u89c9\u8bed\u8a00\u80fd\u529b\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cShiftDC \u5728\u4e0d\u635f\u5bb3\u6a21\u578b\u6548\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5b89\u5168\u57fa\u51c6\u4e0a\u7684\u5bf9\u9f50\u6027\u80fd\u3002", "author": "Xiaohan Zou et.al.", "authors": "Xiaohan Zou, Jian Kang, George Kesidis, Lu Lin", "id": "2502.13095v1", "paper_url": "http://arxiv.org/abs/2502.13095v1", "repo": "null"}}