{"2501.18062": {"publish_time": "2025-01-30", "title": "FinanceQA: A Benchmark for Evaluating Financial Analysis Capabilities of Large Language Models", "paper_summary": "FinanceQA is a testing suite that evaluates LLMs' performance on complex\nnumerical financial analysis tasks that mirror real-world investment work.\nDespite recent advances, current LLMs fail to meet the strict accuracy\nrequirements of financial institutions, with models failing approximately 60%\nof realistic tasks that mimic on-the-job analyses at hedge funds, private\nequity firms, investment banks, and other financial institutions. The primary\nchallenges include hand-spreading metrics, adhering to standard accounting and\ncorporate valuation conventions, and performing analysis under incomplete\ninformation - particularly in multi-step tasks requiring assumption generation.\nThis performance gap highlights the disconnect between existing LLM\ncapabilities and the demands of professional financial analysis that are\ninadequately tested by current testing architectures. Results show that\nhigher-quality training data is needed to support such tasks, which we\nexperiment with using OpenAI's fine-tuning API. FinanceQA is publicly released\nat [this https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA).", "paper_summary_zh": "FinanceQA \u662f\u4e00\u500b\u6e2c\u8a66\u5957\u4ef6\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u5728\u8907\u96dc\u6578\u503c\u8ca1\u52d9\u5206\u6790\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\uff0c\u9019\u4e9b\u4efb\u52d9\u53cd\u6620\u4e86\u771f\u5be6\u4e16\u754c\u7684\u6295\u8cc7\u5de5\u4f5c\u3002\u5118\u7ba1\u6700\u8fd1\u53d6\u5f97\u9032\u5c55\uff0c\u4f46\u76ee\u524d\u7684 LLM \u7121\u6cd5\u6eff\u8db3\u91d1\u878d\u6a5f\u69cb\u56b4\u683c\u7684\u6e96\u78ba\u6027\u8981\u6c42\uff0c\u6a21\u578b\u5728\u6a21\u64ec\u5c0d\u6c96\u57fa\u91d1\u3001\u79c1\u52df\u80a1\u6b0a\u516c\u53f8\u3001\u6295\u8cc7\u9280\u884c\u548c\u5176\u4ed6\u91d1\u878d\u6a5f\u69cb\u7684\u5be6\u969b\u5206\u6790\u4e2d\u7d04\u6709 60% \u7684\u4efb\u52d9\u5931\u6557\u3002\u4e3b\u8981\u7684\u6311\u6230\u5305\u62ec\u624b\u52d5\u50b3\u64ad\u6307\u6a19\u3001\u9075\u5b88\u6a19\u6e96\u6703\u8a08\u548c\u516c\u53f8\u4f30\u503c\u6163\u4f8b\uff0c\u4ee5\u53ca\u5728\u4e0d\u5b8c\u6574\u7684\u4fe1\u606f\u4e0b\u57f7\u884c\u5206\u6790\uff0c\u7279\u5225\u662f\u5728\u9700\u8981\u7522\u751f\u5047\u8a2d\u7684\u591a\u6b65\u9a5f\u4efb\u52d9\u4e2d\u3002\u9019\u7a2e\u6548\u80fd\u5dee\u8ddd\u7a81\u986f\u4e86\u73fe\u6709 LLM \u80fd\u529b\u8207\u5c08\u696d\u8ca1\u52d9\u5206\u6790\u9700\u6c42\u4e4b\u9593\u7684\u812b\u7bc0\uff0c\u800c\u76ee\u524d\u7684\u6e2c\u8a66\u67b6\u69cb\u4e26\u672a\u5145\u5206\u6e2c\u8a66\u9019\u4e9b\u9700\u6c42\u3002\u7d50\u679c\u986f\u793a\u9700\u8981\u66f4\u9ad8\u54c1\u8cea\u7684\u8a13\u7df4\u8cc7\u6599\u4f86\u652f\u63f4\u6b64\u985e\u4efb\u52d9\uff0c\u6211\u5011\u4f7f\u7528 OpenAI \u7684\u5fae\u8abf API \u9032\u884c\u5be6\u9a57\u3002FinanceQA \u5df2\u65bc [\u6b64 https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA) \u516c\u958b\u767c\u5e03\u3002", "author": "Spencer Mateega et.al.", "authors": "Spencer Mateega, Carlos Georgescu, Danny Tang", "id": "2501.18062v1", "paper_url": "http://arxiv.org/abs/2501.18062v1", "repo": "null"}}