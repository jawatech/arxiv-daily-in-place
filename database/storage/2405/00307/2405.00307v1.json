{"2405.00307": {"publish_time": "2024-05-01", "title": "Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition", "paper_summary": "Speech emotion recognition (SER) has garnered increasing attention due to its\nwide range of applications in various fields, including human-machine\ninteraction, virtual assistants, and mental health assistance. However,\nexisting SER methods often overlook the information gap between the\npre-training speech recognition task and the downstream SER task, resulting in\nsub-optimal performance. Moreover, current methods require much time for\nfine-tuning on each specific speech dataset, such as IEMOCAP, which limits\ntheir effectiveness in real-world scenarios with large-scale noisy data. To\naddress these issues, we propose an active learning (AL)-based fine-tuning\nframework for SER, called \\textsc{After}, that leverages task adaptation\npre-training (TAPT) and AL methods to enhance performance and efficiency.\nSpecifically, we first use TAPT to minimize the information gap between the\npre-training speech recognition task and the downstream speech emotion\nrecognition task. Then, AL methods are employed to iteratively select a subset\nof the most informative and diverse samples for fine-tuning, thereby reducing\ntime consumption. Experiments demonstrate that our proposed method\n\\textsc{After}, using only 20\\% of samples, improves accuracy by 8.45\\% and\nreduces time consumption by 79\\%. The additional extension of \\textsc{After}\nand ablation studies further confirm its effectiveness and applicability to\nvarious real-world scenarios. Our source code is available on Github for\nreproducibility. (https://github.com/Clearloveyuan/AFTER).", "paper_summary_zh": "", "author": "Dongyuan Li et.al.", "authors": "Dongyuan Li,Ying Zhang,Yusong Wang,Funakoshi Kataro,Manabu Okumura", "id": "2405.00307v1", "paper_url": "http://arxiv.org/abs/2405.00307v1", "repo": "https://github.com/clearloveyuan/after"}}