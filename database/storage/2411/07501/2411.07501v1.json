{"2411.07501": {"publish_time": "2024-11-12", "title": "LAUREL: Learned Augmented Residual Layer", "paper_summary": "One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.", "paper_summary_zh": "\u9ad8\u6548\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u7684\u6838\u5fc3\u652f\u67f1\u4e4b\u4e00\u662f\u67b6\u69cb\u6539\u9032\uff0c\u4f8b\u5982\u6b98\u5dee/\u8df3\u8e8d\u9023\u63a5\uff0c\u9019\u5df2\u5c0e\u81f4\u6a21\u578b\u6536\u6582\u6027\u548c\u54c1\u8cea\u986f\u8457\u63d0\u5347\u3002\u5f9e\u90a3\u6642\u8d77\uff0c\u6b98\u5dee\u9023\u63a5\u4e0d\u50c5\u5728\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4e5f\u5728\u57fa\u65bc\u8f49\u63db\u5668\u7684\u67b6\u69cb\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5f8c\u8005\u662f LLM \u7684\u9aa8\u5e79\u3002\n\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u300c\u5b78\u7fd2\u589e\u5f37\u6b98\u5dee\u5c64\u300d(LAuReL) -- \u6a19\u6e96\u6b98\u5dee\u9023\u63a5\u7684\u65b0\u7a4e\u6982\u62ec -- \u76ee\u6a19\u662f\u5728\u6a21\u578b\u54c1\u8cea\u548c\u4f54\u7528\u7a7a\u9593\u6307\u6a19\u4e0a\u90fd\u512a\u65bc\u5f8c\u8005\uff0c\u540c\u6642\u6210\u70ba\u5f8c\u8005\u7684\u539f\u4f4d\u66ff\u63db\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u4f7f\u7528 \\laurel \u53ef\u4ee5\u5e6b\u52a9\u63d0\u5347\u8996\u89ba\u548c\u8a9e\u8a00\u6a21\u578b\u7684\u6548\u80fd\u3002\u4f8b\u5982\uff0c\u5728 ResNet-50\u3001ImageNet 1K \u4efb\u52d9\u4e0a\uff0c\u5b83\u9054\u5230\u4e86\u589e\u52a0\u4e00\u5c64\u7684 $60\\%$ \u6536\u76ca\uff0c\u540c\u6642\u53ea\u589e\u52a0\u4e86 $0.003\\%$ \u7684\u53c3\u6578\uff0c\u4e26\u5728\u589e\u52a0 $2.6\\times$ \u66f4\u5c11\u53c3\u6578\u7684\u60c5\u6cc1\u4e0b\u8207\u5176\u5339\u914d\u3002", "author": "Gaurav Menghani et.al.", "authors": "Gaurav Menghani, Ravi Kumar, Sanjiv Kumar", "id": "2411.07501v1", "paper_url": "http://arxiv.org/abs/2411.07501v1", "repo": "null"}}