{"2405.20222": {"publish_time": "2024-05-30", "title": "MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model", "paper_summary": "We present MOFA-Video, an advanced controllable image animation method that\ngenerates video from the given image using various additional controllable\nsignals (such as human landmarks reference, manual trajectories, and another\neven provided video) or their combinations. This is different from previous\nmethods which only can work on a specific motion domain or show weak control\nabilities with diffusion prior. To achieve our goal, we design several\ndomain-aware motion field adapters (\\ie, MOFA-Adapters) to control the\ngenerated motions in the video generation pipeline. For MOFA-Adapters, we\nconsider the temporal motion consistency of the video and generate the dense\nmotion flow from the given sparse control conditions first, and then, the\nmulti-scale features of the given image are wrapped as a guided feature for\nstable video diffusion generation. We naively train two motion adapters for the\nmanual trajectories and the human landmarks individually since they both\ncontain sparse information about the control. After training, the MOFA-Adapters\nin different domains can also work together for more controllable video\ngeneration.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa MOFA-Video\uff0c\u4e00\u7a2e\u9032\u968e\u7684\u53ef\u63a7\u5f71\u50cf\u52d5\u756b\u65b9\u6cd5\uff0c\u5b83\u4f7f\u7528\u5404\u7a2e\u984d\u5916\u7684\u53ef\u63a7\u8a0a\u865f\uff08\u4f8b\u5982\u4eba\u985e\u5730\u6a19\u53c3\u8003\u3001\u624b\u52d5\u8ecc\u8de1\uff0c\u4ee5\u53ca\u53e6\u63d0\u4f9b\u7684\u4e00\u6bb5\u5f71\u7247\uff09\u6216\u5176\u7d44\u5408\uff0c\u5f9e\u7d66\u5b9a\u7684\u5f71\u50cf\u7522\u751f\u5f71\u7247\u3002\u9019\u8207\u5148\u524d\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u5f8c\u8005\u53ea\u80fd\u5728\u7279\u5b9a\u52d5\u4f5c\u9818\u57df\u4e2d\u904b\u4f5c\uff0c\u6216\u5728\u64f4\u6563\u4e4b\u524d\u5c55\u73fe\u51fa\u8f03\u5f31\u7684\u63a7\u5236\u80fd\u529b\u3002\u70ba\u4e86\u9054\u6210\u6211\u5011\u7684\u76ee\u6a19\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u5e7e\u500b\u9818\u57df\u611f\u77e5\u52d5\u4f5c\u5834\u9069\u914d\u5668\uff08\u5373 MOFA-Adapters\uff09\uff0c\u4ee5\u63a7\u5236\u5f71\u7247\u751f\u6210\u7ba1\u7dda\u4e2d\u7522\u751f\u7684\u52d5\u4f5c\u3002\u5c0d\u65bc MOFA-Adapters\uff0c\u6211\u5011\u8003\u616e\u5f71\u7247\u7684\u6642\u9593\u52d5\u4f5c\u4e00\u81f4\u6027\uff0c\u4e26\u9996\u5148\u5f9e\u7d66\u5b9a\u7684\u7a00\u758f\u63a7\u5236\u689d\u4ef6\u7522\u751f\u5bc6\u96c6\u52d5\u4f5c\u6d41\uff0c\u7136\u5f8c\uff0c\u7d66\u5b9a\u5f71\u50cf\u7684\u591a\u5c3a\u5ea6\u7279\u5fb5\u88ab\u5305\u88dd\u70ba\u5f15\u5c0e\u7279\u5fb5\uff0c\u7528\u65bc\u7a69\u5b9a\u7684\u5f71\u7247\u64f4\u6563\u751f\u6210\u3002\u6211\u5011\u5929\u771f\u5730\u8a13\u7df4\u4e86\u5169\u500b\u52d5\u4f5c\u9069\u914d\u5668\uff0c\u5206\u5225\u7528\u65bc\u624b\u52d5\u8ecc\u8de1\u548c\u4eba\u9ad4\u5730\u6a19\uff0c\u56e0\u70ba\u5b83\u5011\u90fd\u5305\u542b\u7a00\u758f\u7684\u63a7\u5236\u8cc7\u8a0a\u3002\u8a13\u7df4\u5f8c\uff0c\u4e0d\u540c\u9818\u57df\u7684 MOFA-Adapters \u4e5f\u53ef\u4ee5\u5354\u540c\u5de5\u4f5c\uff0c\u4ee5\u7522\u751f\u66f4\u591a\u53ef\u63a7\u7684\u5f71\u7247\u3002", "author": "Muyao Niu et.al.", "authors": "Muyao Niu, Xiaodong Cun, Xintao Wang, Yong Zhang, Ying Shan, Yinqiang Zheng", "id": "2405.20222v1", "paper_url": "http://arxiv.org/abs/2405.20222v1", "repo": "null"}}