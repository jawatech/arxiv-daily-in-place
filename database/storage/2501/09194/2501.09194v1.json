{"2501.09194": {"publish_time": "2025-01-15", "title": "Grounding Text-To-Image Diffusion Models For Controlled High-Quality Image Generation", "paper_summary": "Large-scale text-to-image (T2I) diffusion models have demonstrated an\noutstanding performance in synthesizing diverse high-quality visuals from\nnatural language text captions. Multiple layout-to-image models have been\ndeveloped to control the generation process by utilizing a broad array of\nlayouts such as segmentation maps, edges, and human keypoints. In this work, we\npresent ObjectDiffusion, a model that takes inspirations from the top\ncutting-edge image generative frameworks to seamlessly condition T2I models\nwith new bounding boxes capabilities. Specifically, we make substantial\nmodifications to the network architecture introduced in ContorlNet to integrate\nit with the condition processing and injection techniques proposed in GLIGEN.\nObjectDiffusion is initialized with pretraining parameters to leverage the\ngeneration knowledge obtained from training on large-scale datasets. We\nfine-tune ObjectDiffusion on the COCO2017 training dataset and evaluate it on\nthe COCO2017 validation dataset. Our model achieves an AP$_{50}$ of 46.6, an AR\nof 44.5, and a FID of 19.8 outperforming the current SOTA model trained on\nopen-source datasets in all of the three metrics. ObjectDiffusion demonstrates\na distinctive capability in synthesizing diverse, high-quality, high-fidelity\nimages that seamlessly conform to the semantic and spatial control layout.\nEvaluated in qualitative and quantitative tests, ObjectDiffusion exhibits\nremarkable grounding abilities on closed-set and open-set settings across a\nwide variety of contexts. The qualitative assessment verifies the ability of\nObjectDiffusion to generate multiple objects of different sizes and locations.", "paper_summary_zh": "<paragraph>\u5927\u578b\u6587\u672c\u5230\u56fe\u50cf (T2I) \u6269\u6563\u6a21\u578b\u5df2\u5c55\u793a\u51fa\u4ece\u81ea\u7136\u8bed\u8a00\u6587\u672c\u63cf\u8ff0\u4e2d\u5408\u6210\u5404\u79cd\u9ad8\u8d28\u91cf\u89c6\u89c9\u6548\u679c\u7684\u51fa\u8272\u6027\u80fd\u3002\u5df2\u5f00\u53d1\u51fa\u591a\u79cd\u5e03\u5c40\u5230\u56fe\u50cf\u6a21\u578b\uff0c\u901a\u8fc7\u5229\u7528\u5206\u5272\u56fe\u3001\u8fb9\u7f18\u548c\u4eba\u4f53\u5173\u952e\u70b9\u7b49\u5e7f\u6cdb\u7684\u5e03\u5c40\u6765\u63a7\u5236\u751f\u6210\u8fc7\u7a0b\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 ObjectDiffusion\uff0c\u8be5\u6a21\u578b\u4ece\u9876\u5c16\u7684\u56fe\u50cf\u751f\u6210\u6846\u67b6\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u4ee5\u65e0\u7f1d\u7684\u65b9\u5f0f\u4e3a T2I \u6a21\u578b\u63d0\u4f9b\u65b0\u7684\u8fb9\u754c\u6846\u529f\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5bf9 ContorlNet \u4e2d\u5f15\u5165\u7684\u7f51\u7edc\u67b6\u6784\u8fdb\u884c\u4e86\u5b9e\u8d28\u6027\u4fee\u6539\uff0c\u4ee5\u5c06\u5176\u4e0e GLIGEN \u4e2d\u63d0\u51fa\u7684\u6761\u4ef6\u5904\u7406\u548c\u6ce8\u5165\u6280\u672f\u96c6\u6210\u5728\u4e00\u8d77\u3002ObjectDiffusion \u4f7f\u7528\u9884\u8bad\u7ec3\u53c2\u6570\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u4ee5\u5229\u7528\u4ece\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u4e2d\u83b7\u5f97\u7684\u751f\u6210\u77e5\u8bc6\u3002\u6211\u4eec\u5728 COCO2017 \u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u5bf9 ObjectDiffusion \u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u5e76\u5728 COCO2017 \u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u5bf9\u5176\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u6211\u4eec\u7684\u6a21\u578b\u5728\u6240\u6709\u4e09\u4e2a\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u5728\u5f00\u6e90\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u5f53\u524d SOTA \u6a21\u578b\uff0c\u83b7\u5f97\u4e86 46.6 \u7684 AP$_{50}$\u300144.5 \u7684 AR \u548c 19.8 \u7684 FID\u3002ObjectDiffusion \u5c55\u793a\u4e86\u5408\u6210\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u3001\u9ad8\u4fdd\u771f\u56fe\u50cf\u7684\u72ec\u7279\u80fd\u529b\uff0c\u8fd9\u4e9b\u56fe\u50cf\u65e0\u7f1d\u7b26\u5408\u8bed\u4e49\u548c\u7a7a\u95f4\u63a7\u5236\u5e03\u5c40\u3002\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0cObjectDiffusion \u5728\u5404\u79cd\u80cc\u666f\u4e0b\u7684\u5c01\u95ed\u96c6\u548c\u5f00\u653e\u96c6\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u975e\u51e1\u7684\u57fa\u7840\u80fd\u529b\u3002\u5b9a\u6027\u8bc4\u4f30\u9a8c\u8bc1\u4e86 ObjectDiffusion \u751f\u6210\u4e0d\u540c\u5927\u5c0f\u548c\u4f4d\u7f6e\u7684\u591a\u4e2a\u5bf9\u8c61\u7684\u80fd\u529b\u3002</paragraph>", "author": "Ahmad S\u00fcleyman et.al.", "authors": "Ahmad S\u00fcleyman, G\u00f6ksel Biricik", "id": "2501.09194v1", "paper_url": "http://arxiv.org/abs/2501.09194v1", "repo": "null"}}