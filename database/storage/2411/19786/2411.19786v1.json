{"2411.19786": {"publish_time": "2024-11-29", "title": "MoTe: Learning Motion-Text Diffusion Model for Multiple Generation Tasks", "paper_summary": "Recently, human motion analysis has experienced great improvement due to\ninspiring generative models such as the denoising diffusion model and large\nlanguage model. While the existing approaches mainly focus on generating\nmotions with textual descriptions and overlook the reciprocal task. In this\npaper, we present~\\textbf{MoTe}, a unified multi-modal model that could handle\ndiverse tasks by learning the marginal, conditional, and joint distributions of\nmotion and text simultaneously. MoTe enables us to handle the paired\ntext-motion generation, motion captioning, and text-driven motion generation by\nsimply modifying the input context. Specifically, MoTe is composed of three\ncomponents: Motion Encoder-Decoder (MED), Text Encoder-Decoder (TED), and\nMoti-on-Text Diffusion Model (MTDM). In particular, MED and TED are trained for\nextracting latent embeddings, and subsequently reconstructing the motion\nsequences and textual descriptions from the extracted embeddings, respectively.\nMTDM, on the other hand, performs an iterative denoising process on the input\ncontext to handle diverse tasks. Experimental results on the benchmark datasets\ndemonstrate the superior performance of our proposed method on text-to-motion\ngeneration and competitive performance on motion captioning.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u7531\u65bc\u53bb\u566a\u64f4\u6563\u6a21\u578b\u548c\u5927\u8a9e\u8a00\u6a21\u578b\u7b49\u555f\u767c\u5f0f\u751f\u6210\u6a21\u578b\uff0c\u4eba\u985e\u52d5\u4f5c\u5206\u6790\u6709\u4e86\u5f88\u5927\u7684\u9032\u5c55\u3002\u96d6\u7136\u73fe\u6709\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u65bc\u751f\u6210\u5177\u6709\u6587\u672c\u63cf\u8ff0\u7684\u52d5\u4f5c\uff0c\u537b\u5ffd\u7565\u4e86\u5012\u7f6e\u4efb\u52d9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MoTe\uff0c\u9019\u662f\u4e00\u500b\u7d71\u4e00\u7684\u591a\u6a21\u614b\u6a21\u578b\uff0c\u5b83\u53ef\u4ee5\u901a\u904e\u540c\u6642\u5b78\u7fd2\u52d5\u4f5c\u548c\u6587\u672c\u7684\u908a\u969b\u3001\u689d\u4ef6\u548c\u806f\u5408\u5206\u4f48\u4f86\u8655\u7406\u5404\u7a2e\u4efb\u52d9\u3002MoTe \u4f7f\u6211\u5011\u80fd\u5920\u901a\u904e\u7c21\u55ae\u5730\u4fee\u6539\u8f38\u5165\u4e0a\u4e0b\u6587\u4f86\u8655\u7406\u914d\u5c0d\u7684\u6587\u672c\u904b\u52d5\u751f\u6210\u3001\u904b\u52d5\u5b57\u5e55\u548c\u6587\u672c\u9a45\u52d5\u904b\u52d5\u751f\u6210\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cMoTe \u7531\u4e09\u500b\u7d44\u6210\u90e8\u5206\u7d44\u6210\uff1a\u904b\u52d5\u7de8\u78bc\u5668-\u89e3\u78bc\u5668 (MED)\u3001\u6587\u672c\u7de8\u78bc\u5668-\u89e3\u78bc\u5668 (TED) \u548c\u6587\u672c\u904b\u52d5\u64f4\u6563\u6a21\u578b (MTDM)\u3002\u7279\u5225\u662f\uff0cMED \u548c TED \u88ab\u8a13\u7df4\u7528\u65bc\u63d0\u53d6\u6f5b\u5728\u5d4c\u5165\uff0c\u7136\u5f8c\u5206\u5225\u5f9e\u63d0\u53d6\u7684\u5d4c\u5165\u4e2d\u91cd\u5efa\u904b\u52d5\u5e8f\u5217\u548c\u6587\u672c\u63cf\u8ff0\u3002\u53e6\u4e00\u65b9\u9762\uff0cMTDM \u5c0d\u8f38\u5165\u4e0a\u4e0b\u6587\u57f7\u884c\u8fed\u4ee3\u53bb\u566a\u8655\u7406\u4ee5\u8655\u7406\u5404\u7a2e\u4efb\u52d9\u3002\u57fa\u6e96\u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6587\u672c\u5230\u52d5\u4f5c\u751f\u6210\u65b9\u9762\u7684\u512a\u7570\u6027\u80fd\u548c\u5728\u904b\u52d5\u5b57\u5e55\u65b9\u9762\u7684\u7af6\u722d\u6027\u80fd\u3002", "author": "Yiming Wu et.al.", "authors": "Yiming Wu, Wei Ji, Kecheng Zheng, Zicheng Wang, Dong Xu", "id": "2411.19786v1", "paper_url": "http://arxiv.org/abs/2411.19786v1", "repo": "null"}}