{"2405.17287": {"publish_time": "2024-05-27", "title": "Opinion-Guided Reinforcement Learning", "paper_summary": "Human guidance is often desired in reinforcement learning to improve the\nperformance of the learning agent. However, human insights are often mere\nopinions and educated guesses rather than well-formulated arguments. While\nopinions are subject to uncertainty, e.g., due to partial informedness or\nignorance about a problem, they also emerge earlier than hard evidence could be\nproduced. Thus, guiding reinforcement learning agents through opinions offers\nthe potential for more performant learning processes, but comes with the\nchallenge of modeling and managing opinions in a formal way. In this article,\nwe present a method to guide reinforcement learning agents through opinions. To\nthis end, we provide an end-to-end method to model and manage advisors'\nopinions. To assess the utility of the approach, we evaluate it with synthetic\nand human advisors, at different levels of uncertainty, and under multiple\nadvise strategies. Our results indicate that opinions, even if uncertain,\nimprove the performance of reinforcement learning agents, resulting in higher\nrewards, more efficient exploration, and a better reinforced policy. Although\nwe demonstrate our approach in a simplified topological running example, our\napproach is applicable to complex problems with higher dimensions as well.", "paper_summary_zh": "\u4eba\u985e\u7684\u6307\u5c0e\u5728\u5f37\u5316\u5b78\u7fd2\u4e2d\u901a\u5e38\u662f\u5fc5\u8981\u7684\uff0c\u4ee5\u63d0\u5347\u5b78\u7fd2\u4ee3\u7406\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u4eba\u985e\u7684\u898b\u89e3\u901a\u5e38\u53ea\u662f\u610f\u898b\u548c\u6709\u6839\u64da\u7684\u731c\u6e2c\uff0c\u800c\u975e\u7d93\u904e\u826f\u597d\u5efa\u69cb\u7684\u8ad6\u9ede\u3002\u96d6\u7136\u610f\u898b\u53ef\u80fd\u6703\u53d7\u5230\u4e0d\u78ba\u5b9a\u6027\u5f71\u97ff\uff0c\u4f8b\u5982\u7531\u65bc\u5c0d\u554f\u984c\u7684\u90e8\u5206\u4e86\u89e3\u6216\u7121\u77e5\uff0c\u4f46\u5b83\u5011\u4e5f\u6703\u6bd4\u96e3\u4ee5\u8b49\u660e\u7684\u8b49\u64da\u66f4\u65e9\u51fa\u73fe\u3002\u56e0\u6b64\uff0c\u900f\u904e\u610f\u898b\u4f86\u6307\u5c0e\u5f37\u5316\u5b78\u7fd2\u4ee3\u7406\u5177\u6709\u63d0\u4f9b\u66f4\u9ad8\u6548\u80fd\u5b78\u7fd2\u6d41\u7a0b\u7684\u6f5b\u529b\uff0c\u4f46\u540c\u6642\u4e5f\u4f34\u96a8\u8457\u4ee5\u6b63\u5f0f\u65b9\u5f0f\u5efa\u6a21\u548c\u7ba1\u7406\u610f\u898b\u7684\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u900f\u904e\u610f\u898b\u4f86\u6307\u5c0e\u5f37\u5316\u5b78\u7fd2\u4ee3\u7406\u7684\u65b9\u6cd5\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u500b\u7aef\u5230\u7aef\u7684\u65b9\u6cd5\u4f86\u5efa\u6a21\u548c\u7ba1\u7406\u9867\u554f\u7684\u610f\u898b\u3002\u70ba\u4e86\u8a55\u4f30\u6b64\u65b9\u6cd5\u7684\u6548\u7528\uff0c\u6211\u5011\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u4e0d\u78ba\u5b9a\u6027\u4e0b\uff0c\u4ee5\u53ca\u5728\u591a\u7a2e\u5efa\u8b70\u7b56\u7565\u4e0b\uff0c\u4f7f\u7528\u5408\u6210\u548c\u4eba\u985e\u9867\u554f\u5c0d\u5176\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u4e0d\u78ba\u5b9a\u7684\u610f\u898b\uff0c\u4e5f\u80fd\u63d0\u5347\u5f37\u5316\u5b78\u7fd2\u4ee3\u7406\u7684\u8868\u73fe\uff0c\u9032\u800c\u7372\u5f97\u66f4\u9ad8\u7684\u734e\u52f5\u3001\u66f4\u6709\u6548\u7684\u63a2\u7d22\u548c\u66f4\u5f37\u5316\u7684\u653f\u7b56\u3002\u5118\u7ba1\u6211\u5011\u5728\u4e00\u500b\u7c21\u5316\u7684\u62d3\u64b2\u57f7\u884c\u7bc4\u4f8b\u4e2d\u5c55\u793a\u4e86\u6211\u5011\u7684\u505a\u6cd5\uff0c\u4f46\u6211\u5011\u7684\u505a\u6cd5\u4e5f\u9069\u7528\u65bc\u5177\u6709\u66f4\u9ad8\u7dad\u5ea6\u7684\u8907\u96dc\u554f\u984c\u3002", "author": "Kyanna Dagenais et.al.", "authors": "Kyanna Dagenais, Istvan David", "id": "2405.17287v1", "paper_url": "http://arxiv.org/abs/2405.17287v1", "repo": "null"}}