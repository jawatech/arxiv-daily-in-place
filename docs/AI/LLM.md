
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-09**|**AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**|Jiaxi Cui et.al.|[2407.07094v1](http://arxiv.org/abs/2407.07094v1)|[link](https://github.com/pandavt/datatager)|
|**2024-07-09**|**FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**|Liqun Ma et.al.|[2407.07093v1](http://arxiv.org/abs/2407.07093v1)|[link](https://github.com/liqunma/fbi-llm)|
|**2024-07-09**|**Safe and Reliable Training of Learning-Based Aerospace Controllers**|Udayan Mandal et.al.|[2407.07088v1](http://arxiv.org/abs/2407.07088v1)|null|
|**2024-07-09**|**CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**|Tong Chen et.al.|[2407.07087v1](http://arxiv.org/abs/2407.07087v1)|null|
|**2024-07-09**|**Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**|Logan Cross et.al.|[2407.07086v1](http://arxiv.org/abs/2407.07086v1)|[link](https://github.com/locross93/hypothetical-minds)|
|**2024-07-09**|**Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**|Shaltiel Shmidman et.al.|[2407.07080v1](http://arxiv.org/abs/2407.07080v1)|null|
|**2024-07-09**|**ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**|Shaozhe Hao et.al.|[2407.07077v1](http://arxiv.org/abs/2407.07077v1)|[link](https://github.com/haoosz/conceptexpress)|
|**2024-07-09**|**Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**|Yung-Sung Chuang et.al.|[2407.07071v1](http://arxiv.org/abs/2407.07071v1)|[link](https://github.com/voidism/lookback-lens)|
|**2024-07-09**|**Prompting Techniques for Secure Code Generation: A Systematic Investigation**|Catherine Tony et.al.|[2407.07064v1](http://arxiv.org/abs/2407.07064v1)|null|
|**2024-07-09**|**Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**|Weize Chen et.al.|[2407.07061v1](http://arxiv.org/abs/2407.07061v1)|[link](https://github.com/openbmb/ioa)|
|**2024-07-09**|**CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**|Yangmin Li et.al.|[2407.07046v1](http://arxiv.org/abs/2407.07046v1)|null|
|**2024-07-09**|**Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**|Christian Riefolo et.al.|[2407.07045v1](http://arxiv.org/abs/2407.07045v1)|null|
|**2024-07-09**|**ProtoSAM - One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**|Yue Zhang et.al.|[2407.07035v1](http://arxiv.org/abs/2407.07035v1)|null|
|**2024-07-09**|**Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**|Daiqing Wu et.al.|[2407.07026v1](http://arxiv.org/abs/2407.07026v1)|null|
|**2024-07-09**|**Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**|Jeongseok Hyun et.al.|[2407.07024v1](http://arxiv.org/abs/2407.07024v1)|[link](https://github.com/hyunjs/stov-tal)|
|**2024-07-09**|**Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**|Haicheng Liao et.al.|[2407.07020v1](http://arxiv.org/abs/2407.07020v1)|null|
|**2024-07-09**|**Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**|Inwon Kang et.al.|[2407.07019v1](http://arxiv.org/abs/2407.07019v1)|null|
|**2024-07-09**|**End-To-End Causal Effect Estimation from Unstructured Natural Language Data**|Nikita Dhawan et.al.|[2407.07018v1](http://arxiv.org/abs/2407.07018v1)|null|
|**2024-07-09**|**Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning**|J. Crosbie et.al.|[2407.07011v1](http://arxiv.org/abs/2407.07011v1)|null|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-09**|**Empirical analysis of Biding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval**|Raphaël Tinarrage et.al.|[2407.07004v1](http://arxiv.org/abs/2407.07004v1)|null|
|**2024-07-09**|**Metron: Holistic Performance Evaluation Framework for LLM Inference Systems**|Amey Agrawal et.al.|[2407.07000v1](http://arxiv.org/abs/2407.07000v1)|[link](https://github.com/project-metron/metron)|
|**2024-07-09**|**Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective**|Yu-An Liu et.al.|[2407.06992v1](http://arxiv.org/abs/2407.06992v1)|[link](https://github.com/davion-liu/awesome-robustness-in-information-retrieval)|
|**2024-07-09**|**Segment-Based Interactive Machine Translation for Pre-trained Models**|Angel Navarro et.al.|[2407.06990v1](http://arxiv.org/abs/2407.06990v1)|null|
|**2024-07-09**|**PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods**|Yiying Wang et.al.|[2407.06985v1](http://arxiv.org/abs/2407.06985v1)|null|
|**2024-07-09**|**Can virtual staining for high-throughput screening generalize?**|Samuel Tonks et.al.|[2407.06979v1](http://arxiv.org/abs/2407.06979v1)|null|
|**2024-07-09**|**Advancing Manuscript Metadata: Work in Progress at the Jagiellonian University**|Luiz do Valle Miranda et.al.|[2407.06976v1](http://arxiv.org/abs/2407.06976v1)|null|
|**2024-07-09**|**Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models**|Yi-Cheng Lin et.al.|[2407.06957v1](http://arxiv.org/abs/2407.06957v1)|[link](https://github.com/dlion168/Listen-and-Speak-Fairly)|
|**2024-07-09**|**ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization**|Wai Man Si et.al.|[2407.06955v1](http://arxiv.org/abs/2407.06955v1)|null|
|**2024-07-09**|**Spanish TrOCR: Leveraging Transfer Learning for Language Adaptation**|Filipe Lauar et.al.|[2407.06950v1](http://arxiv.org/abs/2407.06950v1)|null|
|**2024-07-09**|**Self-Recognition in Language Models**|Tim R. Davidson et.al.|[2407.06946v1](http://arxiv.org/abs/2407.06946v1)|null|
|**2024-07-09**|**Raply: A profanity-mitigated rap generator**|Omar Manil Bendali et.al.|[2407.06941v1](http://arxiv.org/abs/2407.06941v1)|null|
|**2024-07-09**|**Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance**|Milapji Singh Gill et.al.|[2407.06930v1](http://arxiv.org/abs/2407.06930v1)|null|
|**2024-07-09**|**Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models**|Zara Siddique et.al.|[2407.06917v1](http://arxiv.org/abs/2407.06917v1)|null|
|**2024-07-09**|**Fine-grained large-scale content recommendations for MSX sellers**|Manpreet Singh et.al.|[2407.06910v1](http://arxiv.org/abs/2407.06910v1)|null|
|**2024-07-09**|**Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning**|Francisco Giral et.al.|[2407.06909v1](http://arxiv.org/abs/2407.06909v1)|null|
|**2024-07-09**|**Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models**|Flor Miriam Plaza-del-Arco et.al.|[2407.06908v1](http://arxiv.org/abs/2407.06908v1)|null|
|**2024-07-09**|**Hypergraph based Understanding for Document Semantic Entity Recognition**|Qiwei Li et.al.|[2407.06904v1](http://arxiv.org/abs/2407.06904v1)|null|
|**2024-07-09**|**Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective**|Shahana Ibrahim et.al.|[2407.06902v1](http://arxiv.org/abs/2407.06902v1)|null|
|**2024-07-09**|**Measuring Sustainability Intention of ESG Fund Disclosure using Few-Shot Learning**|Mayank Singh et.al.|[2407.06893v1](http://arxiv.org/abs/2407.06893v1)|null|
|**2024-07-09**|**Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI**|Yang Liu et.al.|[2407.06886v1](http://arxiv.org/abs/2407.06886v1)|[link](https://github.com/hcplab-sysu/embodied_ai_paper_list)|
|**2024-07-09**|**ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context**|Victoria R. Li et.al.|[2407.06866v1](http://arxiv.org/abs/2407.06866v1)|null|
|**2024-07-09**|**Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems**|Lorenzo Cassano et.al.|[2407.06862v1](http://arxiv.org/abs/2407.06862v1)|null|
|**2024-07-09**|**TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**|Jacob Thrasher et.al.|[2407.06852v1](http://arxiv.org/abs/2407.06852v1)|[link](https://github.com/jacob-thrasher/te-ssl)|
|**2024-07-09**|**Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders**|Jinseok Kim et.al.|[2407.06851v1](http://arxiv.org/abs/2407.06851v1)|[link](https://github.com/jwdanieljung/safe-embed)|
|**2024-07-09**|**TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data**|Lucas Correia et.al.|[2407.06849v1](http://arxiv.org/abs/2407.06849v1)|[link](https://github.com/lcs-crr/tevae)|
|**2024-07-09**|**VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**|Thanh-Dat Nguyen et.al.|[2407.06826v1](http://arxiv.org/abs/2407.06826v1)|null|
|**2024-07-09**|**Cue Point Estimation using Object Detection**|Giulia Argüello et.al.|[2407.06823v1](http://arxiv.org/abs/2407.06823v1)|[link](https://github.com/eth-disco/cue-detr)|
|**2024-07-09**|**Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy**|Zhenyu Guan et.al.|[2407.06813v1](http://arxiv.org/abs/2407.06813v1)|null|
|**2024-07-09**|**A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification**|Lu Zhang et.al.|[2407.06807v1](http://arxiv.org/abs/2407.06807v1)|null|
|**2024-07-09**|**Learn and Don't Forget: Adding a New Language to ASR Foundation Models**|Mengjie Qian et.al.|[2407.06800v1](http://arxiv.org/abs/2407.06800v1)|null|
|**2024-07-09**|**It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human**|Jakub Harasta et.al.|[2407.06798v1](http://arxiv.org/abs/2407.06798v1)|null|
|**2024-07-09**|**ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders**|Fotios Lygerakis et.al.|[2407.06797v1](http://arxiv.org/abs/2407.06797v1)|null|
|**2024-07-09**|**Towards physics-informed neural networks for landslide prediction**|Ashok Dahal et.al.|[2407.06785v1](http://arxiv.org/abs/2407.06785v1)|null|
|**2024-07-09**|**Fuzzy color model and clustering algorithm for color clustering problem**|Dae-Won Kim et.al.|[2407.06782v1](http://arxiv.org/abs/2407.06782v1)|null|
|**2024-07-09**|**Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions**|Wenxin Zhou et.al.|[2407.06779v1](http://arxiv.org/abs/2407.06779v1)|null|
|**2024-07-09**|**A BERT-based Empirical Study of Privacy Policies' Compliance with GDPR**|Lu Zhang et.al.|[2407.06778v1](http://arxiv.org/abs/2407.06778v1)|null|
|**2024-07-09**|**Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions**|Matteo Bortoletto et.al.|[2407.06762v1](http://arxiv.org/abs/2407.06762v1)|null|
|**2024-07-09**|**Threats and Defenses in Federated Learning Life Cycle: A Comprehensive Survey and Challenges**|Yanli Li et.al.|[2407.06754v1](http://arxiv.org/abs/2407.06754v1)|null|
|**2024-07-09**|**Positive-Unlabelled Learning for Improving Image-based Recommender System Explainability**|Álvaro Fernández-Campa-González et.al.|[2407.06740v1](http://arxiv.org/abs/2407.06740v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts**|Atilla Özgür et.al.|[2407.06718v1](http://arxiv.org/abs/2407.06718v1)|null|
|**2024-07-09**|**Consistent Document-Level Relation Extraction via Counterfactuals**|Ali Modarressi et.al.|[2407.06699v1](http://arxiv.org/abs/2407.06699v1)|null|
|**2024-07-09**|**Deep-Motion-Net: GNN-based volumetric organ shape reconstruction from single-view 2D projections**|Isuru Wijesinghe et.al.|[2407.06692v1](http://arxiv.org/abs/2407.06692v1)|null|
|**2024-07-09**|**A Predictive Model Based on Transformer with Statistical Feature Embedding in Manufacturing Sensor Dataset**|Gyeong Taek Lee et.al.|[2407.06682v1](http://arxiv.org/abs/2407.06682v1)|null|
|**2024-07-09**|**TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification**|Md Abrar Jahin et.al.|[2407.06658v1](http://arxiv.org/abs/2407.06658v1)|null|
|**2024-07-09**|**SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training**|Nan He et.al.|[2407.06654v1](http://arxiv.org/abs/2407.06654v1)|null|
|**2024-07-09**|**A Word Order Synchronization Metric for Evaluating Simultaneous Interpretation and Translation**|Mana Makinae et.al.|[2407.06650v1](http://arxiv.org/abs/2407.06650v1)|null|
|**2024-07-09**|**Entropy Law: The Story Behind Data Compression and LLM Performance**|Mingjia Yin et.al.|[2407.06645v1](http://arxiv.org/abs/2407.06645v1)|null|
|**2024-07-09**|**Reasoning about unpredicted change and explicit time**|Florence Dupin de Saint-Cyr et.al.|[2407.06622v1](http://arxiv.org/abs/2407.06622v1)|null|
|**2024-07-09**|**CEIA: CLIP-Based Event-Image Alignment for Open-World Event-Based Understanding**|Wenhao Xu et.al.|[2407.06611v1](http://arxiv.org/abs/2407.06611v1)|null|
|**2024-07-09**|**Tailored Design of Audio-Visual Speech Recognition Models using Branchformers**|David Gimeno-Gómez et.al.|[2407.06606v1](http://arxiv.org/abs/2407.06606v1)|[link](https://github.com/david-gimeno/tailored-avsr)|
|**2024-07-09**|**TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries**|Renjie Liang et.al.|[2407.06597v1](http://arxiv.org/abs/2407.06597v1)|[link](https://github.com/ranking-vmr/tvr-ranking)|
|**2024-07-09**|**Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)**|Yanlong Peng et.al.|[2407.06590v1](http://arxiv.org/abs/2407.06590v1)|null|
|**2024-07-09**|**Vision language models are blind**|Pooyan Rahmanzadehgervi et.al.|[2407.06581v1](http://arxiv.org/abs/2407.06581v1)|null|
|**2024-07-09**|**NoisyAG-News: A Benchmark for Addressing Instance-Dependent Noise in Text Classification**|Hongfei Huang et.al.|[2407.06579v1](http://arxiv.org/abs/2407.06579v1)|null|
|**2024-07-09**|**Virtual Personas for Language Models via an Anthology of Backstories**|Suhong Moon et.al.|[2407.06576v1](http://arxiv.org/abs/2407.06576v1)|[link](https://github.com/cannylab/anthology)|
|**2024-07-09**|**FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making**|Yangyang Yu et.al.|[2407.06567v1](http://arxiv.org/abs/2407.06567v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-09**|**TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**|Fanglin Dong et.al.|[2407.06560v1](http://arxiv.org/abs/2407.06560v1)|null|
|**2024-07-09**|**OffsetBias: Leveraging Debiased Data for Tuning Evaluators**|Junsoo Park et.al.|[2407.06551v1](http://arxiv.org/abs/2407.06551v1)|null|
|**2024-07-09**|**AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance**|Shouchang Guo et.al.|[2407.06549v1](http://arxiv.org/abs/2407.06549v1)|null|
|**2024-07-09**|**Deciphering Assamese Vowel Harmony with Featural InfoWaveGAN**|Sneha Ray Barman et.al.|[2407.06547v1](http://arxiv.org/abs/2407.06547v1)|null|
|**2024-07-09**|**LIONs: An Empirically Optimized Approach to Align Language Models**|Xiao Yu et.al.|[2407.06542v1](http://arxiv.org/abs/2407.06542v1)|null|
|**2024-07-09**|**General and Task-Oriented Video Segmentation**|Mu Chen et.al.|[2407.06540v1](http://arxiv.org/abs/2407.06540v1)|[link](https://github.com/kagawa588/gvseg)|
|**2024-07-09**|**Enhancing Low-Resource NMT with a Multilingual Encoder and Knowledge Distillation: A Case Study**|Aniruddha Roy et.al.|[2407.06538v1](http://arxiv.org/abs/2407.06538v1)|null|
|**2024-07-09**|**Efficient and Accurate Memorable Conversation Model using DPO based on sLLM**|Youngkyung Seo et.al.|[2407.06537v1](http://arxiv.org/abs/2407.06537v1)|null|
|**2024-07-09**|**LETS-C: Leveraging Language Embedding for Time Series Classification**|Rachneet Kaur et.al.|[2407.06533v1](http://arxiv.org/abs/2407.06533v1)|null|
|**2024-07-09**|**STORYSUMM: Evaluating Faithfulness in Story Summarization**|Melanie Subbiah et.al.|[2407.06501v1](http://arxiv.org/abs/2407.06501v1)|[link](https://github.com/melaniesubbiah/storysumm)|
|**2024-07-09**|**Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons**|Yongqi Leng et.al.|[2407.06488v1](http://arxiv.org/abs/2407.06488v1)|null|
|**2024-07-09**|**Optimal Decision Making Through Scenario Simulations Using Large Language Models**|Sumedh Rasal et.al.|[2407.06486v1](http://arxiv.org/abs/2407.06486v1)|null|
|**2024-07-09**|**CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community**|Yan Liu et.al.|[2407.06485v1](http://arxiv.org/abs/2407.06485v1)|null|
|**2024-07-09**|**Composable Interventions for Language Models**|Arinbjorn Kolbeinsson et.al.|[2407.06483v1](http://arxiv.org/abs/2407.06483v1)|[link](https://github.com/hartvigsen-group/composable-interventions)|
|**2024-07-09**|**Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on English Second Language Conversations**|Rena Gao et.al.|[2407.06479v1](http://arxiv.org/abs/2407.06479v1)|null|
|**2024-07-08**|**MUSE: Machine Unlearning Six-Way Evaluation for Language Models**|Weijia Shi et.al.|[2407.06460v1](http://arxiv.org/abs/2407.06460v1)|null|
|**2024-07-08**|**Exploiting Heterogeneity in Timescales for Sparse Recurrent Spiking Neural Networks for Energy-Efficient Edge Computing**|Biswadeep Chakraborty et.al.|[2407.06452v1](http://arxiv.org/abs/2407.06452v1)|null|
|**2024-07-08**|**Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment**|Qizhang Feng et.al.|[2407.06443v1](http://arxiv.org/abs/2407.06443v1)|null|
|**2024-07-08**|**A Single Transformer for Scalable Vision-Language Modeling**|Yangyi Chen et.al.|[2407.06438v1](http://arxiv.org/abs/2407.06438v1)|[link](https://github.com/yangyi-chen/solo)|

#### Abstracts
##### **AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**
2407.07094v1 by Jiaxi Cui, Wentao Zhang, Jing Tang, Xudong Tong, Zhenwei Zhang, Amie, Jing Wen, Rongsheng Wang, Pengfei Wu

The pervasive deployment of Large Language Models-LLMs in various sectors
often neglects the nuanced requirements of individuals and small organizations,
who benefit more from models precisely tailored to their specific business
contexts rather than those with broadly superior general capabilities. This
work introduces \textbf{AnyTaskTune}, a novel fine-tuning methodology coined as
\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on
a diverse array of domain-specific tasks. This method involves a meticulous
process to identify and define targeted sub-tasks within a domain, followed by
the creation of specialized enhancement datasets for fine-tuning, thereby
optimizing task-specific model performance. We conducted comprehensive
fine-tuning experiments not only in the legal domain for tasks such as keyword
extraction and sentence prediction but across over twenty different sub-tasks
derived from the domains of finance, healthcare, law, psychology, consumer
services, and human resources. To substantiate our approach and facilitate
community engagement, we will open-source these bilingual task datasets. Our
findings demonstrate that models fine-tuned using the \textbf{Task-Fine-Tune}
methodology not only achieve superior performance on these specific tasks but
also significantly outperform models with higher general capabilities in their
respective domains. Our work is publicly available at
\url{https://github.com/PandaVT/DataTager}.

摘要：各種產業中普遍部署大型語言模型 (LLM) 時，常常忽略個人和小型組織的細微需求，而這些對象較能從精準調整到其特定商業脈絡的模型中獲益，而非具備廣泛卓越一般能力的模型。本研究介紹一種新穎的微調方法，稱為「任務微調」(Task-Fine-Tune)，專門開發用於提升模型在各種特定領域任務上的效能。此方法包含一個細緻的程序，用於識別和定義領域內的目標子任務，然後建立專門的強化資料集進行微調，進而最佳化特定任務的模型效能。我們不僅在法律領域進行全面的微調實驗，針對關鍵字萃取和句子預測等任務，還涵蓋從金融、醫療保健、法律、心理學、消費者服務和人力資源等領域衍生的二十多個不同子任務。為了證實我們的做法並促進社群參與，我們將開放這些雙語任務資料集的原始碼。我們的研究結果顯示，使用「任務微調」方法微調的模型不僅在這些特定任務上達到卓越效能，而且在各自領域中也明顯優於具備較高一般能力的模型。我們的研究成果已於 https://github.com/PandaVT/DataTager 公開。

##### **FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**
2407.07093v1 by Liqun Ma, Mingjie Sun, Zhiqiang Shen

This work presents a Fully BInarized Large Language Model (FBI-LLM),
demonstrating for the first time how to train a large-scale binary language
model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to
match the performance of its full-precision counterparts (e.g., FP16 or BF16)
in transformer-based LLMs. It achieves this by employing an autoregressive
distillation (AD) loss with maintaining equivalent model dimensions (130M,
1.3B, 7B) and training data volume as regular LLM pretraining, while delivering
competitive results in terms of perplexity and task-specific effectiveness.
Intriguingly, by analyzing the training trajectory, we find that the pretrained
weight is not necessary for training binarized LLMs from scratch. This research
encourages a new computational framework and may facilitate the future design
of specialized hardware tailored for fully 1-bit LLMs. We make all models,
code, and training dataset fully accessible and transparent to support further
research (Code: https://github.com/LiqunMa/FBI-LLM. Model:
https://huggingface.co/LiqunMa/).

摘要：本研究提出了一個全二值化大型語言模型 (FBI-LLM)，首次展示如何從頭訓練一個大型二值語言模型（不是像 BitNet b1.58 那樣的局部二值或三值 LLM），以匹配其全精度對應項（例如，FP16 或 BF16）在基於Transformer的 LLM 中的性能。它通過採用自迴歸蒸餾 (AD) 損失來實現這一點，同時保持等效的模型維度（130M、1.3B、7B）和訓練數據量作為常規 LLM 預訓練，同時在困惑度和特定任務的有效性方面提供有競爭力的結果。有趣的是，通過分析訓練軌跡，我們發現預訓練權重對於從頭訓練二值化 LLM 並非必要。這項研究鼓勵新的計算框架，並可能促進專門針對全 1 位元 LLM 量身打造的硬體的未來設計。我們讓所有模型、程式碼和訓練資料集完全公開且透明，以支持進一步的研究（程式碼：https://github.com/LiqunMa/FBI-LLM。模型：https://huggingface.co/LiqunMa/）。

##### **Safe and Reliable Training of Learning-Based Aerospace Controllers**
2407.07088v1 by Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee Newell, Umberto Ravaioli, Baoluo Meng, Michael Durling, Kerianne Hobbs, Milan Ganai, Tobey Shim, Guy Katz, Clark Barrett

In recent years, deep reinforcement learning (DRL) approaches have generated
highly successful controllers for a myriad of complex domains. However, the
opaque nature of these models limits their applicability in aerospace systems
and safety-critical domains, in which a single mistake can have dire
consequences. In this paper, we present novel advancements in both the training
and verification of DRL controllers, which can help ensure their safe behavior.
We showcase a design-for-verification approach utilizing k-induction and
demonstrate its use in verifying liveness properties. In addition, we also give
a brief overview of neural Lyapunov Barrier certificates and summarize their
capabilities on a case study. Finally, we describe several other novel
reachability-based approaches which, despite failing to provide guarantees of
interest, could be effective for verification of other DRL systems, and could
be of further interest to the community.

摘要：近年來，深度強化學習 (DRL) 方法已產生了許多複雜領域的極為成功的控制器。然而，這些模型的不透明性質限制了它們在航空太空系統和安全關鍵領域中的應用性，在這些領域中，一個錯誤可能會導致可怕的後果。在本文中，我們展示了 DRL 控制器的訓練和驗證方面的最新進展，這有助於確保其安全行為。我們展示了一個利用 k 感應的設計驗證方法，並展示了它在驗證活性屬性中的用途。此外，我們還簡要概述了神經李亞普諾夫障礙證書，並總結了它們在案例研究中的能力。最後，我們描述了幾種其他新穎的可達性方法，儘管這些方法未能提供感興趣的保證，但它們對於驗證其他 DRL 系統可能是有效的，並且可能對社區進一步感興趣。

##### **CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**
2407.07087v1 by Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh

Evaluating the degree of reproduction of copyright-protected content by
language models (LMs) is of significant interest to the AI and legal
communities. Although both literal and non-literal similarities are considered
by courts when assessing the degree of reproduction, prior research has focused
only on literal similarities. To bridge this gap, we introduce CopyBench, a
benchmark designed to measure both literal and non-literal copying in LM
generations. Using copyrighted fiction books as text sources, we provide
automatic evaluation protocols to assess literal and non-literal copying,
balanced against the model utility in terms of the ability to recall facts from
the copyrighted works and generate fluent completions. We find that, although
literal copying is relatively rare, two types of non-literal copying -- event
copying and character copying -- occur even in models as small as 7B
parameters. Larger models demonstrate significantly more copying, with literal
copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3%
to 6.9% when comparing Llama3-8B and 70B models, respectively. We further
evaluate the effectiveness of current strategies for mitigating copying and
show that (1) training-time alignment can reduce literal copying but may
increase non-literal copying, and (2) current inference-time mitigation methods
primarily reduce literal but not non-literal copying.

摘要：評估語言模型 (LM) 複製受版權保護內容的程度，對 AI 和法律社群而言意義重大。儘管法院在評估複製程度時會考慮文字和非文字的相似性，但先前的研究僅關注文字相似性。為了彌補這個差距，我們引入了 CopyBench，一個基準測試，旨在衡量 LM 生成中的文字和非文字複製。使用受版權保護的小說書籍作為文本來源，我們提供了自動評估協定，以評估文字和非文字複製，並根據從受版權保護的作品中提取事實和產生流暢完成的能力，來衡量模型實用性。我們發現，儘管文字複製相對罕見，但即使在參數小至 7B 的模型中，也會發生兩種非文字複製——事件複製和角色複製。較大的模型顯示出顯著更多的複製，當比較 Llama3-8B 和 70B 模型時，文字複製率從 0.2% 增加到 10.5%，非文字複製從 2.3% 增加到 6.9%。我們進一步評估了當前減輕複製策略的有效性，並表明 (1) 訓練時間校準可以減少文字複製，但可能會增加非文字複製，以及 (2) 當前的推論時間減輕方法主要減少文字複製，但不會減少非文字複製。

##### **Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**
2407.07086v1 by Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber

Multi-agent reinforcement learning (MARL) methods struggle with the
non-stationarity of multi-agent systems and fail to adaptively learn online
when tested with novel agents. Here, we leverage large language models (LLMs)
to create an autonomous agent that can handle these challenges. Our agent,
Hypothetical Minds, consists of a cognitively-inspired architecture, featuring
modular components for perception, memory, and hierarchical planning over two
levels of abstraction. We introduce the Theory of Mind module that scaffolds
the high-level planning process by generating hypotheses about other agents'
strategies in natural language. It then evaluates and iteratively refines these
hypotheses by reinforcing hypotheses that make correct predictions about the
other agents' behavior. Hypothetical Minds significantly improves performance
over previous LLM-agent and RL baselines on a range of competitive, mixed
motive, and collaborative domains in the Melting Pot benchmark, including both
dyadic and population-based environments. Additionally, comparisons against
LLM-agent baselines and ablations reveal the importance of hypothesis
evaluation and refinement for succeeding on complex scenarios.

摘要：多智能體強化學習 (MARL) 方法難以應對多智能體系統的不穩定性，並且在使用新智能體進行測試時無法適應性地線上學習。在這裡，我們利用大型語言模型 (LLM) 來創建一個可以應對這些挑戰的自主智能體。我們的智能體 Hypothetical Minds 由認知啟發的架構組成，具有用於感知、記憶和分層規劃的模組化組件，涵蓋兩個抽象層級。我們引入了心智理論模組，該模組透過以自然語言生成關於其他智能體策略的假設，來支撐高階規劃流程。然後，它會評估並反覆優化這些假設，方法是強化對其他智能體行為做出正確預測的假設。在 Melting Pot 基準中的一系列競爭、混合動機和協作領域（包括二元和基於群體的環境），Hypothetical Minds 的效能顯著優於先前的 LLM 智能體和 RL 基準。此外，與 LLM 智能體基線和消融的比較顯示了假設評估和優化對於在複雜場景中取得成功的重要性。

##### **Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**
2407.07080v1 by Shaltiel Shmidman, Avi Shmidman, Amir DN Cohen, Moshe Koppel

Training large language models (LLMs) in low-resource languages such as
Hebrew poses unique challenges. In this paper, we introduce DictaLM2.0 and
DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a
substantial corpus of approximately 200 billion tokens in both Hebrew and
English. Adapting a pre-trained model to a new language involves specialized
techniques that differ significantly from training a model from scratch or
further training existing models on well-resourced languages such as English.
We outline these novel training methodologies, which facilitate effective
learning and adaptation to the linguistic properties of Hebrew. Additionally,
we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to
enhance its performance on task-specific instructions. To rigorously evaluate
our models, we introduce a new benchmark suite for Hebrew LLM evaluation,
covering a diverse set of tasks including Question Answering, Sentiment
Analysis, Winograd Schema Challenge, Translation, and Summarization. Our work
not only addresses the intricacies of training LLMs in low-resource languages
but also proposes a framework that can be leveraged for adapting other LLMs to
various non-English languages, contributing to the broader field of
multilingual NLP.

摘要：在希伯來語等低資源語言中訓練大型語言模型 (LLM) 會帶來獨特的挑戰。在本文中，我們介紹了 DictaLM2.0 和 DictaLM2.0-Instruct，這兩個 LLM 是從 Mistral 模型衍生的，並在包含約 2,000 億個希伯來語和英語詞彙的龐大語料庫中訓練。將預訓練模型適應到新語言涉及專業技術，這與從頭開始訓練模型或進一步訓練現有模型（例如英語等資源豐富的語言）有顯著不同。我們概述了這些新穎的訓練方法，有助於有效學習和適應希伯來語的語言特性。此外，我們針對全面的指導資料集微調 DictaLM2.0-Instruct，以提升其在特定任務指示上的效能。為了嚴格評估我們的模型，我們為希伯來語 LLM 評估引入了新的基準組，涵蓋了多樣化的任務集，包括問答、情緒分析、Winograd 模式挑戰、翻譯和摘要。我們的研究不僅解決了在低資源語言中訓練 LLM 的複雜性，還提出了可用於將其他 LLM 適應到各種非英語語言的架構，為多語言 NLP 的廣泛領域做出貢獻。

##### **ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**
2407.07077v1 by Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, Kwan-Yee K. Wong

While personalized text-to-image generation has enabled the learning of a
single concept from multiple images, a more practical yet challenging scenario
involves learning multiple concepts within a single image. However, existing
works tackling this scenario heavily rely on extensive human annotations. In
this paper, we introduce a novel task named Unsupervised Concept Extraction
(UCE) that considers an unsupervised setting without any human knowledge of the
concepts. Given an image that contains multiple concepts, the task aims to
extract and recreate individual concepts solely relying on the existing
knowledge from pretrained diffusion models. To achieve this, we present
ConceptExpress that tackles UCE by unleashing the inherent capabilities of
pretrained diffusion models in two aspects. Specifically, a concept
localization approach automatically locates and disentangles salient concepts
by leveraging spatial correspondence from diffusion self-attention; and based
on the lookup association between a concept and a conceptual token, a
concept-wise optimization process learns discriminative tokens that represent
each individual concept. Finally, we establish an evaluation protocol tailored
for the UCE task. Extensive experiments demonstrate that ConceptExpress is a
promising solution to the UCE task. Our code and data are available at:
https://github.com/haoosz/ConceptExpress

摘要：<paragraph>雖然個人化的文字轉圖像生成已能從多張圖像中學習單一概念，但更實際且具挑戰性的場景是學習單一圖像中的多個概念。然而，現有的處理此場景的作品極度依賴於大量的標註。在本文中，我們引入了一個名為無監督概念萃取 (UCE) 的新任務，它考慮了在沒有人類概念知識的情況下的無監督設定。給定包含多個概念的圖像，此任務旨在僅依賴於預訓練擴散模型的現有知識來萃取和重建個別概念。為達成此目的，我們提出了 ConceptExpress，它透過釋放預訓練擴散模型在兩個方面的固有能力來處理 UCE。具體來說，概念定位方法透過利用擴散自注意力中的空間對應自動定位和解開顯著概念；而基於概念和概念 token 之間的查詢關聯，概念優化程序會學習表示每個個別概念的區分 token。最後，我們建立了一個專門針對 UCE 任務的評估協定。廣泛的實驗證明 ConceptExpress 是 UCE 任務的有前途的解決方案。我們的程式碼和資料可在以下取得：https://github.com/haoosz/ConceptExpress</paragraph>

##### **Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**
2407.07071v1 by Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James Glass

When asked to summarize articles or answer questions given a passage, large
language models (LLMs) can hallucinate details and respond with unsubstantiated
answers that are inaccurate with respect to the input context. This paper
describes a simple approach for detecting such contextual hallucinations. We
hypothesize that contextual hallucinations are related to the extent to which
an LLM attends to information in the provided context versus its own
generations. Based on this intuition, we propose a simple hallucination
detection model whose input features are given by the ratio of attention
weights on the context versus newly generated tokens (for each attention head).
We find that a linear classifier based on these lookback ratio features is as
effective as a richer detector that utilizes the entire hidden states of an LLM
or a text-based entailment model. The lookback ratio-based detector -- Lookback
Lens -- is found to transfer across tasks and even models, allowing a detector
that is trained on a 7B model to be applied (without retraining) to a larger
13B model. We further apply this detector to mitigate contextual
hallucinations, and find that a simple classifier-guided decoding approach is
able to reduce the amount of hallucination, for example by 9.6% in the XSum
summarization task.

摘要：當要求大型語言模型 (LLM) 總結文章或回答給定段落的題目時，它們可能會產生幻覺細節，並以與輸入內容無關的不實答案回應。本論文描述了一種檢測此類語境幻覺的簡單方法。我們假設語境幻覺與 LLM 關注所提供語境中的資訊與其自身產生的資訊的程度有關。基於此直覺，我們提出了一個簡單的幻覺檢測模型，其輸入特徵由語境與新產生的權標 (對於每個注意力頭) 上的注意力權重比率給出。我們發現基於這些回顧比率特徵的線性分類器與利用 LLM 的整個隱藏狀態或基於文字的蘊涵模型的更豐富的檢測器一樣有效。發現基於回顧比率的檢測器——回顧鏡頭——可以跨任務甚至跨模型傳輸，允許在 7B 模型上訓練的檢測器應用於更大的 13B 模型 (無需重新訓練)。我們進一步應用此檢測器來減輕語境幻覺，並發現一個簡單的分類器引導的解碼方法能夠減少幻覺量，例如在 XSum 摘要任務中減少 9.6%。

##### **Prompting Techniques for Secure Code Generation: A Systematic Investigation**
2407.07064v1 by Catherine Tony, Nicolás E. Díaz Ferreyra, Markus Mutas, Salem Dhiff, Riccardo Scandariato

Large Language Models (LLMs) are gaining momentum in software development
with prompt-driven programming enabling developers to create code from natural
language (NL) instructions. However, studies have questioned their ability to
produce secure code and, thereby, the quality of prompt-generated software.
Alongside, various prompting techniques that carefully tailor prompts have
emerged to elicit optimal responses from LLMs. Still, the interplay between
such prompting strategies and secure code generation remains under-explored and
calls for further investigations. OBJECTIVE: In this study, we investigate the
impact of different prompting techniques on the security of code generated from
NL instructions by LLMs. METHOD: First we perform a systematic literature
review to identify the existing prompting techniques that can be used for code
generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,
and GPT-4 models for secure code generation. For this, we used an existing
dataset consisting of 150 NL security-relevant code-generation prompts.
RESULTS: Our work (i) classifies potential prompting techniques for code
generation (ii) adapts and evaluates a subset of the identified techniques for
secure code generation tasks and (iii) observes a reduction in security
weaknesses across the tested LLMs, especially after using an existing technique
called Recursive Criticism and Improvement (RCI), contributing valuable
insights to the ongoing discourse on LLM-generated code security.

摘要：大型語言模型 (LLM) 在軟體開發中獲得了動能，提示驅動程式讓開發人員能夠從自然語言 (NL) 指令建立程式碼。然而，研究質疑它們產生安全程式碼的能力，從而質疑提示產生的軟體品質。此外，出現了各種仔細調整提示的提示技術，從 LLM 引發最佳回應。儘管如此，這種提示策略與安全程式碼產生之間的交互作用仍然未被充分探討，並需要進一步調查。目標：在本研究中，我們調查了不同提示技術對 LLM 從 NL 指令產生的程式碼安全性的影響。方法：首先，我們執行系統性的文獻回顧，以找出可用於程式碼產生任務的現有提示技術。在 GPT-3、GPT-3.5 和 GPT-4 模型上評估這些技術的子集，以產生安全程式碼。為此，我們使用了一個現有的資料集，其中包含 150 個與 NL 安全相關的程式碼產生提示。結果：我們的研究 (i) 分類了程式碼產生的潛在提示技術 (ii) 調整並評估了一部分已識別的技術，以進行安全的程式碼產生任務，以及 (iii) 觀察到在測試的 LLM 中，特別是在使用現有的技術，稱為遞迴批評和改進 (RCI) 之後，安全性弱點減少，為 LLM 產生的程式碼安全性持續討論提供了有價值的見解。

##### **Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**
2407.07061v1 by Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun

The rapid advancement of large language models (LLMs) has paved the way for
the development of highly capable autonomous agents. However, existing
multi-agent frameworks often struggle with integrating diverse capable
third-party agents due to reliance on agents defined within their own
ecosystems. They also face challenges in simulating distributed environments,
as most frameworks are limited to single-device setups. Furthermore, these
frameworks often rely on hard-coded communication pipelines, limiting their
adaptability to dynamic task requirements. Inspired by the concept of the
Internet, we propose the Internet of Agents (IoA), a novel framework that
addresses these limitations by providing a flexible and scalable platform for
LLM-based multi-agent collaboration. IoA introduces an agent integration
protocol, an instant-messaging-like architecture design, and dynamic mechanisms
for agent teaming and conversation flow control. Through extensive experiments
on general assistant tasks, embodied AI tasks, and retrieval-augmented
generation benchmarks, we demonstrate that IoA consistently outperforms
state-of-the-art baselines, showcasing its ability to facilitate effective
collaboration among heterogeneous agents. IoA represents a step towards linking
diverse agents in an Internet-like environment, where agents can seamlessly
collaborate to achieve greater intelligence and capabilities. Our codebase has
been released at \url{https://github.com/OpenBMB/IoA}.

摘要：大型語言模型（LLM）的快速進展為高度智能自主代理的開發鋪平了道路。然而，現有的多代理框架通常難以整合多樣化的能力第三方代理，因為它們依賴於在它們自己的生態系統中定義的代理。它們在模擬分布式環境時也面臨挑戰，因為大多數框架僅限於單設備設置。此外，這些框架通常依賴於硬編碼通信管道，這限制了它們適應動態任務需求的能力。受互聯網概念的啟發，我們提出了代理互聯網 (IoA)，這是一個新穎的框架，通過提供一個靈活且可擴展的 LLM 驅動的多代理協作平台來解決這些限制。IoA 引入了代理集成協議、即時通訊類型的架構設計以及用於代理組隊和對話流控制的動態機制。通過對一般助理任務、具身 AI 任務和檢索增強生成基準的廣泛實驗，我們證明 IoA 持續優於最先進的基準，展示了它促進異構代理之間有效協作的能力。IoA 代表了在類互聯網環境中鏈接不同代理的一步，在這種環境中，代理可以無縫協作以實現更高的智能和能力。我們的代碼庫已發布在 \url{https://github.com/OpenBMB/IoA}。

##### **CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**
2407.07046v1 by Yangmin Li, Ruiqi Zhu, Wengen Li

Multimodal sentiment analysis is an active research area that combines
multiple data modalities, e.g., text, image and audio, to analyze human
emotions and benefits a variety of applications. Existing multimodal sentiment
analysis methods can be classified as modality interaction-based methods,
modality transformation-based methods and modality similarity-based methods.
However, most of these methods highly rely on the strong correlations between
modalities, and cannot fully uncover and utilize the correlations between
modalities to enhance sentiment analysis. Therefore, these methods usually
achieve bad performance for identifying the sentiment of multimodal data with
weak correlations. To address this issue, we proposed a two-stage
semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)
which consists pre-training stage and prediction stage. At the pre-training
stage, a modality correlation contrastive learning module is designed to
efficiently learn modality correlation coefficients between different
modalities. At the prediction stage, the learned correlation coefficients are
fused with modality representations to make the sentiment prediction. According
to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT
obviously surpasses state-of-the-art multimodal sentiment analysis methods.

摘要：多模态情感分析是一个活跃的研究领域，它结合了多种数据模式，例如文本、图像和音频，来分析人类情绪，并使各种应用程序受益。现有的多模态情感分析方法可以分为基于模态交互的方法、基于模态转换的方法和基于模态相似性的方法。然而，这些方法大多高度依赖于模态之间的强相关性，并且无法充分发现和利用模态之间的相关性来增强情感分析。因此，这些方法通常在识别弱相关性多模态数据的语义时表现不佳。为了解决这个问题，我们提出了一个两阶段的半监督模型，称为相关感知多模态转换器 (CorMulT)，它由预训练阶段和预测阶段组成。在预训练阶段，设计了一个模态相关对比学习模块，以有效地学习不同模态之间的模态相关系数。在预测阶段，学习到的相关系数与模态表示融合，以进行情感预测。根据流行的多模态数据集 CMU-MOSEI 上的实验，CorMulT 明显超越了最先进的多模态情感分析方法。

##### **Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**
2407.07045v1 by Christian Riefolo, Nicola Fanizzi, Claudia d'Amato

Tackling the problem of learning probabilistic classifiers from incomplete
data in the context of Knowledge Graphs expressed in Description Logics, we
describe an inductive approach based on learning simple belief networks.
Specifically, we consider a basic probabilistic model, a Naive Bayes
classifier, based on multivariate Bernoullis and its extension to a two-tier
network in which this classification model is connected to a lower layer
consisting of a mixture of Bernoullis. We show how such models can be converted
into (probabilistic) axioms (or rules) thus ensuring more interpretability.
Moreover they may be also initialized exploiting expert knowledge. We present
and discuss the outcomes of an empirical evaluation which aimed at testing the
effectiveness of the models on a number of random classification problems with
different ontologies.

摘要：針對在描述邏輯中表示的知識圖表中從不完整資料學習機率分類器的問題，我們描述一種基於學習簡單信念網路的歸納方法。具體來說，我們考慮一個基本的機率模型，一個樸素貝氏分類器，它基於多變量伯努利分布及其擴展到一個兩層網路，其中這個分類模型連接到由伯努利混合組成的下層。我們展示如何將這些模型轉換為（機率）公理（或規則），從而確保更高的可解釋性。此外，它們還可以利用專家知識進行初始化。我們提出並討論了實證評估的結果，其目的是測試這些模型在具有不同本體的多個隨機分類問題上的有效性。

##### **ProtoSAM - One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**
2407.07035v1 by Yue Zhang, Ziqiao Ma, Jialu Li, Yanyuan Qiao, Zun Wang, Joyce Chai, Qi Wu, Mohit Bansal, Parisa Kordjamshidi

Vision-and-Language Navigation (VLN) has gained increasing attention over
recent years and many approaches have emerged to advance their development. The
remarkable achievements of foundation models have shaped the challenges and
proposed methods for VLN research. In this survey, we provide a top-down review
that adopts a principled framework for embodied planning and reasoning, and
emphasizes the current methods and future opportunities leveraging foundation
models to address VLN challenges. We hope our in-depth discussions could
provide valuable resources and insights: on one hand, to milestone the progress
and explore opportunities and potential roles for foundation models in this
field, and on the other, to organize different challenges and solutions in VLN
to foundation model researchers.

摘要：視覺語言導航 (VLN) 近年來備受關注，許多方法也應運而生，以推進其發展。基礎模型的顯著成就塑造了 VLN 研究的挑戰和提出的方法。在這項調查中，我們提供了一項自上而下的回顧，採用了具體的框架進行具體規劃和推理，並強調了當前的方法和未來的機會，利用基礎模型來應對 VLN 挑戰。我們希望我們的深入討論能提供有價值的資源和見解：一方面，記錄進度並探索基礎模型在這一領域的機會和潛在作用，另一方面，組織 VLN 中不同的挑戰和解決方案，以供基礎模型研究人員參考。

##### **Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**
2407.07026v1 by Daiqing Wu, Dongbao Yang, Huawen Shen, Can Ma, Yu Zhou

With the proliferation of social media posts in recent years, the need to
detect sentiments in multimodal (image-text) content has grown rapidly. Since
posts are user-generated, the image and text from the same post can express
different or even contradictory sentiments, leading to potential
\textbf{sentiment discrepancy}. However, existing works mainly adopt a
single-branch fusion structure that primarily captures the consistent sentiment
between image and text. The ignorance or implicit modeling of discrepant
sentiment results in compromised unimodal encoding and limited performances. In
this paper, we propose a semantics Completion and Decomposition (CoDe) network
to resolve the above issue. In the semantics completion module, we complement
image and text representations with the semantics of the OCR text embedded in
the image, helping bridge the sentiment gap. In the semantics decomposition
module, we decompose image and text representations with exclusive projection
and contrastive learning, thereby explicitly capturing the discrepant sentiment
between modalities. Finally, we fuse image and text representations by
cross-attention and combine them with the learned discrepant sentiment for
final classification. Extensive experiments conducted on four multimodal
sentiment datasets demonstrate the superiority of CoDe against SOTA methods.

摘要：隨著近年來社群媒體貼文的激增，偵測多模態（圖像文字）內容的情緒的需求也迅速增長。由於貼文是由使用者產生的，來自同一個貼文的圖像和文字可能表達出不同甚至矛盾的情緒，導致潛在的**情緒差異**。然而，現有的作品主要採用單分支融合結構，主要擷取圖像和文字之間一致的情緒。對矛盾情緒的忽略或隱式建模導致受損的單模態編碼和有限的效能。在本文中，我們提出語義完成和分解 (CoDe) 網路來解決上述問題。在語義完成模組中，我們以嵌入在圖像中的 OCR 文字的語義來補充圖像和文字表示，有助於縮小情緒差距。在語義分解模組中，我們使用獨家投影和對比學習來分解圖像和文字表示，從而明確擷取模態之間的矛盾情緒。最後，我們透過交叉注意力融合圖像和文字表示，並將它們與學習到的矛盾情緒結合起來進行最終分類。在四個多模態情緒資料集上進行的廣泛實驗證明了 CoDe 優於 SOTA 方法。

##### **Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**
2407.07024v1 by Jeongseok Hyun, Su Ho Han, Hyolim Kang, Joon-Young Lee, Seon Joo Kim

The vocabulary size in temporal action localization (TAL) is constrained by
the scarcity of large-scale annotated datasets. To address this, recent works
incorporate powerful pre-trained vision-language models (VLMs), such as CLIP,
to perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on
extensive image/video-text pairs, existing OV-TAL methods still rely on small,
fully labeled TAL datasets for training an action localizer. In this paper, we
explore the scalability of self-training with unlabeled YouTube videos for
OV-TAL. Our self-training approach consists of two stages. First, a
class-agnostic action localizer is trained on a human-labeled TAL dataset and
used to generate pseudo-labels for unlabeled videos. Second, the large-scale
pseudo-labeled dataset is combined with the human-labeled dataset to train the
localizer. Extensive experiments demonstrate that leveraging web-scale videos
in self-training significantly enhances the generalizability of an action
localizer. Additionally, we highlighted issues with existing OV-TAL evaluation
schemes and proposed a new evaluation protocol. Code is released at
https://github.com/HYUNJS/STOV-TAL

摘要：時序動作定位 (TAL) 中的詞彙量受到大規模標註資料集稀少的限制。為了解決這個問題，最近的研究結合了強大的預訓練視覺語言模型 (VLM)，例如 CLIP，來執行開放詞彙 TAL (OV-TAL)。然而，與在大量的影像/影片-文字配對上訓練的 VLM 不同，現有的 OV-TAL 方法仍然依賴於小型、完全標註的 TAL 資料集來訓練動作定位器。在本文中，我們探討了使用未標註的 YouTube 影片進行自訓練在 OV-TAL 中的可擴充性。我們的自訓練方法包含兩個階段。首先，在人工標註的 TAL 資料集上訓練一個與類別無關的動作定位器，並用於為未標註的影片產生偽標籤。其次，將大規模的偽標籤資料集與人工標註的資料集結合起來訓練定位器。大量的實驗證明，在自訓練中利用網路規模的影片可以顯著增強動作定位器的泛化能力。此外，我們強調了現有 OV-TAL 評估方案的問題，並提出了一個新的評估協定。程式碼已發布於 https://github.com/HYUNJS/STOV-TAL

##### **Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**
2407.07020v1 by Haicheng Liao, Yongkang Li, Zhenning Li, Chengyue Wang, Chunlin Tian, Yuming Huang, Zilin Bian, Kaiqun Zhu, Guofa Li, Ziyuan Pu, Jia Hu, Zhiyong Cui, Chengzhong Xu

Accurately and safely predicting the trajectories of surrounding vehicles is
essential for fully realizing autonomous driving (AD). This paper presents the
Human-Like Trajectory Prediction model (HLTP++), which emulates human cognitive
processes to improve trajectory prediction in AD. HLTP++ incorporates a novel
teacher-student knowledge distillation framework. The "teacher" model equipped
with an adaptive visual sector, mimics the dynamic allocation of attention
human drivers exhibit based on factors like spatial orientation, proximity, and
driving speed. On the other hand, the "student" model focuses on real-time
interaction and human decision-making, drawing parallels to the human memory
storage mechanism. Furthermore, we improve the model's efficiency by
introducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for
faster and more precise predictions with fewer parameters. Evaluated using the
NGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance
compared to existing models, which reduces the predicted trajectory error with
over 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++
demonstrates strong adaptability in challenging environments with incomplete
input data. This marks a significant stride in the journey towards fully AD
systems.

摘要：準確且安全地預測周圍車輛的軌跡對於完全實現自動駕駛 (AD) 至關重要。本文提出類人軌跡預測模型 (HLTP++)，模擬人類認知過程以改善 AD 中的軌跡預測。HLTP++ 採用新穎的師生知識蒸餾框架。配備自適應視覺扇區的「教師」模型，模擬人類駕駛員根據空間方向、接近度和行駛速度等因素動態分配注意力。另一方面，「學生」模型專注於即時互動和人類決策，與人類記憶儲存機制形成對應。此外，我們通過引入新的傅立葉自適應尖峰神經網路 (FA-SNN) 來提高模型的效率，從而使用更少的參數進行更快速、更準確的預測。使用 NGSIM、HighD 和 MoCAD 基準進行評估，HLTP++ 表現出優於現有模型的卓越性能，在 NGSIM 資料集上將預測軌跡誤差降低了 11% 以上，在 HighD 資料集上降低了 25%。此外，HLTP++ 在輸入資料不完整的情況下表現出強大的適應性。這標誌著朝著完全 AD 系統邁出了重要的一步。

##### **Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**
2407.07019v1 by Inwon Kang, William Van Woensel, Oshani Seneviratne

We explore using Large Language Models (LLMs) to generate application code
that automates health insurance processes from text-based policies. We target
blockchain-based smart contracts as they offer immutability, verifiability,
scalability, and a trustless setting: any number of parties can use the smart
contracts, and they need not have previously established trust relationships
with each other. Our methodology generates outputs at increasing levels of
technical detail: (1) textual summaries, (2) declarative decision logic, and
(3) smart contract code with unit tests. We ascertain LLMs are good at the task
(1), and the structured output is useful to validate tasks (2) and (3).
Declarative languages (task 2) are often used to formalize healthcare policies,
but their execution on blockchain is non-trivial. Hence, task (3) attempts to
directly automate the process using smart contracts. To assess the LLM output,
we propose completeness, soundness, clarity, syntax, and functioning code as
metrics. Our evaluation employs three health insurance policies (scenarios)
with increasing difficulty from Medicare's official booklet. Our evaluation
uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our
findings confirm that LLMs perform quite well in generating textual summaries.
Although outputs from tasks (2)-(3) are useful starting points, they require
human oversight: in multiple cases, even "runnable" code will not yield sound
results; the popularity of the target language affects the output quality; and
more complex scenarios still seem a bridge too far. Nevertheless, our
experiments demonstrate the promise of LLMs for translating textual process
descriptions into smart contracts.

摘要：<paragraph>我們探討使用大型語言模型 (LLM) 來產生應用程式程式碼，以自動化基於文字政策的健康保險流程。我們以區塊鏈智慧合約為目標，因為它們提供不可變性、可驗證性、可擴充性，以及無需信任的設定：任何數量的參與方都可以使用智慧合約，而且他們不必事先建立彼此的信任關係。我們的做法會產生技術細節程度越來越高的輸出：(1) 文字摘要，(2) 宣告式決策邏輯，以及 (3) 具備單元測試的智慧合約程式碼。我們確定 LLM 擅長任務 (1)，而結構化輸出有助於驗證任務 (2) 和 (3)。宣告式語言 (任務 2) 通常用於將醫療保健政策形式化，但它們在區塊鏈上的執行並非易事。因此，任務 (3) 嘗試直接使用智慧合約自動化流程。為了評估 LLM 輸出，我們提出完整性、健全性、清晰性、語法和運作程式碼作為指標。我們的評估採用了三項醫療保險政策（場景），其難度從 Medicare 的官方手冊中逐漸增加。我們的評估使用 GPT-3.5 Turbo、GPT-3.5 Turbo 16K、GPT-4、GPT-4 Turbo 和 CodeLLaMA。我們的發現證實，LLM 在產生文字摘要方面表現得非常好。儘管任務 (2)-(3) 的輸出是有用的起點，但它們需要人工監督：在多種情況下，即使是「可執行」的程式碼也不會產生健全的結果；目標語言的普及程度會影響輸出品質；而且更複雜的場景似乎仍遙不可及。儘管如此，我們的實驗證明了 LLM 在將文字流程描述轉換為智慧合約方面的潛力。</paragraph>

##### **End-To-End Causal Effect Estimation from Unstructured Natural Language Data**
2407.07018v1 by Nikita Dhawan, Leonardo Cotta, Karen Ullrich, Rahul G. Krishnan, Chris J. Maddison

Knowing the effect of an intervention is critical for human decision-making,
but current approaches for causal effect estimation rely on manual data
collection and structuring, regardless of the causal assumptions. This
increases both the cost and time-to-completion for studies. We show how large,
diverse observational text data can be mined with large language models (LLMs)
to produce inexpensive causal effect estimates under appropriate causal
assumptions. We introduce NATURAL, a novel family of causal effect estimators
built with LLMs that operate over datasets of unstructured text. Our estimators
use LLM conditional distributions (over variables of interest, given the text
data) to assist in the computation of classical estimators of causal effect. We
overcome a number of technical challenges to realize this idea, such as
automating data curation and using LLMs to impute missing information. We
prepare six (two synthetic and four real) observational datasets, paired with
corresponding ground truth in the form of randomized trials, which we used to
systematically evaluate each step of our pipeline. NATURAL estimators
demonstrate remarkable performance, yielding causal effect estimates that fall
within 3 percentage points of their ground truth counterparts, including on
real-world Phase 3/4 clinical trials. Our results suggest that unstructured
text data is a rich source of causal effect information, and NATURAL is a first
step towards an automated pipeline to tap this resource.

摘要：了解干預措施的影響對於人類的決策至關重要，但當前的因果關係估計方法依賴於手動數據收集和結構化，而不管因果假設為何。這會增加研究的成本和完成時間。我們展示了如何使用大型語言模型 (LLM) 挖掘大量、多樣化的觀察性文本數據，以便在適當的因果假設下產生低成本的因果關係估計。我們介紹了 NATURAL，這是一個使用 LLM 建立的因果關係估計器的新系列，可以在非結構化文本的數據集上運作。我們的估計器使用 LLM 條件分佈（在給定文本數據的情況下，在感興趣的變量上）來協助計算因果關係的經典估計器。我們克服了許多技術挑戰來實現這個想法，例如自動化數據策展和使用 LLM 來輸入遺失的資訊。我們準備了六個（兩個合成和四個真實）觀察性數據集，並配有以隨機試驗形式對應的基本事實，我們用這些數據集系統地評估了我們管線的每一步。NATURAL 估計器表現出色，產生的因果關係估計值落在其基本事實對應值的 3 個百分點內，包括在現實世界的 3/4 期臨床試驗中。我們的結果表明，非結構化文本數據是因果關係資訊的豐富來源，而 NATURAL 是利用此資源的自動化管線的第一步。

##### **Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning**
2407.07011v1 by J. Crosbie, E. Shutova

Large language models (LLMs) have shown a remarkable ability to learn and
perform complex tasks through in-context learning (ICL). However, a
comprehensive understanding of its internal mechanisms is still lacking. This
paper explores the role of induction heads in a few-shot ICL setting. We
analyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract
pattern recognition and NLP tasks. Our results show that even a minimal
ablation of induction heads leads to ICL performance decreases of up to ~32%
for abstract pattern recognition tasks, bringing the performance close to
random. For NLP tasks, this ablation substantially decreases the model's
ability to benefit from examples, bringing few-shot ICL performance close to
that of zero-shot prompts. We further use attention knockout to disable
specific induction patterns, and present fine-grained evidence for the role
that the induction mechanism plays in ICL.

摘要：大型語言模型 (LLM) 已展現出透過情境學習 (ICL) 學習及執行複雜任務的卓越能力。然而，我們對其內部機制的全面理解仍有不足。本文探討了在少次數 ICL 設定中歸納頭部的作用。我們分析了兩個最先進的模型，即 Llama-3-8B 和 InternLM2-20B，針對抽象模式識別和 NLP 任務。我們的結果顯示，即使對歸納頭部進行最小的消融也會導致抽象模式識別任務的 ICL 效能降低多達 ~32%，使效能接近隨機。對於 NLP 任務，這種消融會大幅降低模型從範例中獲益的能力，使少次數 ICL 效能接近零次數提示。我們進一步使用注意力中斷來停用特定的歸納模式，並提出具體證據來說明歸納機制在 ICL 中所扮演的角色。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Empirical analysis of Biding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval**
2407.07004v1 by Raphaël Tinarrage, Henrique Ennes, Lucas E. Resck, Lucas T. Gomes, Jean R. Ponciano, Jorge Poco

Binding precedents (S\'umulas Vinculantes) constitute a juridical instrument
unique to the Brazilian legal system and whose objectives include the
protection of the Federal Supreme Court against repetitive demands. Studies of
the effectiveness of these instruments in decreasing the Court's exposure to
similar cases, however, indicate that they tend to fail in such a direction,
with some of the binding precedents seemingly creating new demands. We
empirically assess the legal impact of five binding precedents, 11, 14, 17, 26
and 37, at the highest court level through their effects on the legal subjects
they address. This analysis is only possible through the comparison of the
Court's ruling about the precedents' themes before they are created, which
means that these decisions should be detected through techniques of Similar
Case Retrieval. The contributions of this article are therefore twofold: on the
mathematical side, we compare the uses of different methods of Natural Language
Processing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval,
whereas on the legal side, we contrast the inefficiency of these binding
precedents with a set of hypotheses that may justify their repeated usage. We
observe that the deep learning models performed significantly worse in the
specific Similar Case Retrieval task and that the reasons for binding
precedents to fail in responding to repetitive demand are heterogeneous and
case-dependent, making it impossible to single out a specific cause.

摘要：約束性判例（S'umulas Vinculantes）構成巴西法律體系獨有的法律工具，其目標包括保護聯邦最高法院免於重複要求。然而，關於這些工具在減少法院面臨類似案件的風險方面的有效性的研究表明，它們往往無法朝著這個方向發展，其中一些約束性判例似乎會產生新的需求。我們通過約束性判例對法律主體的影響，對五個約束性判例（11、14、17、26 和 37）在最高法院層級的法律影響進行實證評估。這種分析只能通過比較法院在判例產生前對判例主題的裁決來進行，這意味著這些決定應通過類似案例檢索技術來檢測。因此，本文的貢獻有兩個方面：在數學方面，我們比較了使用不同的自然語言處理方法（TF-IDF、LSTM、BERT 和正規表示式）進行類似案例檢索，而在法律方面，我們將這些約束性判例的低效率與可能證明其重複使用的假設進行對比。我們觀察到，深度學習模型在特定的類似案例檢索任務中表現明顯較差，並且約束性判例無法回應重複需求的原因是異質且依賴於案例的，因此無法找出具體原因。

##### **Metron: Holistic Performance Evaluation Framework for LLM Inference Systems**
2407.07000v1 by Amey Agrawal, Anmol Agarwal, Nitin Kedia, Jayashree Mohan, Souvik Kundu, Nipun Kwatra, Ramachandran Ramjee, Alexey Tumanov

Serving large language models (LLMs) in production can incur substantial
costs, which has prompted recent advances in inference system optimizations.
Today, these systems are evaluated against conventional latency and throughput
metrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics
fail to fully capture the nuances of LLM inference, leading to an incomplete
assessment of user-facing performance crucial for real-time applications such
as chat and translation. In this paper, we first identify the pitfalls of
current performance metrics in evaluating LLM inference systems. We then
propose Metron, a comprehensive performance evaluation framework that includes
fluidity-index -- a novel metric designed to reflect the intricacies of the LLM
inference process and its impact on real-time user experience. Finally, we
evaluate various existing open-source platforms and model-as-a-service
offerings using Metron, discussing their strengths and weaknesses. Metron is
available at https://github.com/project-metron/metron.

摘要：在生產環境中提供大型語言模型 (LLM) 服務可能會產生可觀的成本，這促使最近的推理系統最佳化技術有了進展。今天，這些系統會針對傳統的延遲和吞吐量指標（例如 TTFT、TBT、標準化延遲和 TPOT）進行評估。然而，這些指標無法完全掌握 LLM 推論的細微差別，導致對使用者實際效能的評估不完整，這對於即時應用程式（例如聊天和翻譯）至關重要。在本文中，我們首先找出評估 LLM 推論系統時，目前效能指標的缺點。然後我們提出 Metron，一個全面的效能評估架構，其中包含流暢度指標，這是一個新穎的指標，用來反映 LLM 推論程序的複雜性及其對即時使用者體驗的影響。最後，我們使用 Metron 評估各種現有的開源平台和模型即服務產品，並討論其優缺點。Metron 可在 https://github.com/project-metron/metron 取得。

##### **Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective**
2407.06992v1 by Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng

Recent advances in neural information retrieval (IR) models have
significantly enhanced their effectiveness over various IR tasks. The
robustness of these models, essential for ensuring their reliability in
practice, has also garnered significant attention. With a wide array of
research on robust IR being proposed, we believe it is the opportune moment to
consolidate the current status, glean insights from existing methodologies, and
lay the groundwork for future development. We view the robustness of IR to be a
multifaceted concept, emphasizing its necessity against adversarial attacks,
out-of-distribution (OOD) scenarios and performance variance. With a focus on
adversarial and OOD robustness, we dissect robustness solutions for dense
retrieval models (DRMs) and neural ranking models (NRMs), respectively,
recognizing them as pivotal components of the neural IR pipeline. We provide an
in-depth discussion of existing methods, datasets, and evaluation metrics,
shedding light on challenges and future directions in the era of large language
models. To the best of our knowledge, this is the first comprehensive survey on
the robustness of neural IR models, and we will also be giving our first
tutorial presentation at SIGIR 2024
\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the
organization of existing work, we introduce a Benchmark for robust IR (BestIR),
a heterogeneous evaluation benchmark for robust neural information retrieval,
which is publicly available at \url{https://github.com/Davion-Liu/BestIR}. We
hope that this study provides useful clues for future research on the
robustness of IR models and helps to develop trustworthy search engines
\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.

摘要：近來神經資訊檢索 (IR) 模型的進展大幅提升了各種 IR 任務的成效。這些模型的穩健性對於確保其在實務上的可靠性至關重要，也因此備受關注。由於針對穩健 IR 的研究相當廣泛，我們認為現在正是整合目前狀況、從現有方法中汲取見解，並為未來發展奠定基礎的適當時機。我們將 IR 的穩健性視為一個多面向的概念，強調其在對抗攻擊、分布外 (OOD) 場景和效能變異中抵抗攻擊的必要性。我們專注於對抗和 OOD 穩健性，分別剖析了稠密檢索模型 (DRM) 和神經排序模型 (NRM) 的穩健性解決方案，並將其視為神經 IR 管線的關鍵組成部分。我們深入討論了現有方法、資料集和評估指標，並闡明了在大型語言模型時代的挑戰和未來方向。據我們所知，這是對神經 IR 模型的穩健性進行的首份全面調查，我們也將在 SIGIR 2024 上進行首次教學簡報 \url{https://sigir2024-robust-information-retrieval.github.io}。除了整理現有研究外，我們還推出了穩健 IR 基準 (BestIR)，這是一個針對穩健神經資訊檢索的異質評估基準，並公開於 \url{https://github.com/Davion-Liu/BestIR}。我們希望這項研究能為未來的神經 IR 模型穩健性研究提供有用的線索，並有助於開發值得信賴的搜尋引擎 \url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}。

##### **Segment-Based Interactive Machine Translation for Pre-trained Models**
2407.06990v1 by Angel Navarro, Francisco Casacuberta

Pre-trained large language models (LLM) are starting to be widely used in
many applications. In this work, we explore the use of these models in
interactive machine translation (IMT) environments. In particular, we have
chosen mBART (multilingual Bidirectional and Auto-Regressive Transformer) and
mT5 (multilingual Text-to-Text Transfer Transformer) as the LLMs to perform our
experiments. The system generates perfect translations interactively using the
feedback provided by the user at each iteration. The Neural Machine Translation
(NMT) model generates a preliminary hypothesis with the feedback, and the user
validates new correct segments and performs a word correction--repeating the
process until the sentence is correctly translated. We compared the performance
of mBART, mT5, and a state-of-the-art (SoTA) machine translation model on a
benchmark dataset regarding user effort, Word Stroke Ratio (WSR), Key Stroke
Ratio (KSR), and Mouse Action Ratio (MAR). The experimental results indicate
that mBART performed comparably with SoTA models, suggesting that it is a
viable option for this field of IMT. The implications of this finding extend to
the development of new machine translation models for interactive environments,
as it indicates that some novel pre-trained models exhibit SoTA performance in
this domain, highlighting the potential benefits of adapting these models to
specific needs.

摘要：<paragraph>預先訓練過的大型語言模型 (LLM) 開始在許多應用程式中廣泛使用。在這項工作中，我們探討在互動式機器翻譯 (IMT) 環境中使用這些模型。特別是，我們選擇 mBART（多語言雙向自迴歸轉換器）和 mT5（多語言文字轉文字傳輸轉換器）作為 LLM 來執行我們的實驗。系統使用使用者在每次反覆運算中提供的回饋，互動式地產生完美的翻譯。神經機器翻譯 (NMT) 模型使用回饋產生初步假設，使用者驗證新的正確區段並執行單字更正，重複這個程序，直到句子正確翻譯為止。我們比較了 mBART、mT5 和最先進 (SoTA) 機器翻譯模型在基準資料集中的效能，包括使用者工作量、單字筆劃比率 (WSR)、按鍵筆劃比率 (KSR) 和滑鼠動作比率 (MAR)。實驗結果顯示，mBART 的表現與 SoTA 模型相當，這表示它是 IMT 領域中可行的選項。這項發現的意義延伸到為互動式環境開發新的機器翻譯模型，因為這表示一些新穎的預先訓練模型在此領域展現出 SoTA 效能，突顯出將這些模型調整至特定需求的潛在好處。</paragraph>

##### **PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods**
2407.06985v1 by Yiying Wang, Xiaojing Li, Binzhu Wang, Yueyang Zhou, Han Ji, Hong Chen, Jinshi Zhang, Fei Yu, Zewei Zhao, Song Jin, Renji Gong, Wanqing Xu

In domain-specific applications, GPT-4, augmented with precise prompts or
Retrieval-Augmented Generation (RAG), shows notable potential but faces the
critical tri-lemma of performance, cost, and data privacy. High performance
requires sophisticated processing techniques, yet managing multiple agents
within a complex workflow often proves costly and challenging. To address this,
we introduce the PEER (Plan, Execute, Express, Review) multi-agent framework.
This systematizes domain-specific tasks by integrating precise question
decomposition, advanced information retrieval, comprehensive summarization, and
rigorous self-assessment. Given the concerns of cost and data privacy,
enterprises are shifting from proprietary models like GPT-4 to custom models,
striking a balance between cost, security, and performance. We developed
industrial practices leveraging online data and user feedback for efficient
model tuning. This study provides best practice guidelines for applying
multi-agent systems in domain-specific problem-solving and implementing
effective agent tuning strategies. Our empirical studies, particularly in the
financial question-answering domain, demonstrate that our approach achieves
95.0% of GPT-4's performance, while effectively managing costs and ensuring
data privacy.

摘要：在特定領域的應用中，GPT-4 搭配精準提示或檢索增強生成（RAG）展現了顯著的潛力，但面臨效能、成本和資料隱私的三難困境。高效能需要複雜的處理技術，然而在複雜的工作流程中管理多個代理通常既昂貴又具挑戰性。為了解決這個問題，我們引入了 PEER（計畫、執行、表達、檢閱）多代理架構。這個系統化了特定領域的任務，整合了精準問題分解、進階資訊檢索、全面摘要和嚴格的自我評估。考量到成本和資料隱私的疑慮，企業正從 GPT-4 等專有模型轉向自訂模型，在成本、安全性與效能之間取得平衡。我們開發了利用線上資料和使用者回饋的產業實務，以進行有效率的模型調整。本研究提供了在特定領域問題解決中應用多代理系統的最佳實務指南，並實施有效的代理調整策略。我們的實證研究，特別是在財務問答領域，證明了我們的方法達到了 GPT-4 效能的 95.0%，同時有效管理成本並確保資料隱私。

##### **Can virtual staining for high-throughput screening generalize?**
2407.06979v1 by Samuel Tonks, Cuong Nguyer, Steve Hood, Ryan Musso, Ceridwen Hopely, Steve Titus, Minh Doan, Iain Styles, Alexander Krull

The large volume and variety of imaging data from high-throughput screening
(HTS) in the pharmaceutical industry present an excellent resource for training
virtual staining models. However, the potential of models trained under one set
of experimental conditions to generalize to other conditions remains
underexplored. This study systematically investigates whether data from three
cell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic
conditions) commonly found in HTS can effectively train virtual staining models
to generalize across three typical HTS distribution shifts: unseen phenotypes,
unseen cell types, and the combination of both. Utilizing a dataset of 772,416
paired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we
evaluate the generalization capabilities of models across pixel-based,
instance-wise, and biological-feature-based levels. Our findings indicate that
training virtual nuclei and cytoplasm models on non-toxic condition samples not
only generalizes to toxic condition samples but leads to improved performance
across all evaluation levels compared to training on toxic condition samples.
Generalization to unseen cell types shows variability depending on the cell
type; models trained on ovarian or lung cell samples often perform well under
other conditions, while those trained on breast cell samples consistently show
poor generalization. Generalization to unseen cell types and phenotypes shows
good generalization across all levels of evaluation compared to addressing
unseen cell types alone. This study represents the first large-scale,
data-centric analysis of the generalization capability of virtual staining
models trained on diverse HTS datasets, providing valuable strategies for
experimental training data generation.

摘要：<paragraph>製藥產業中高通量篩選 (HTS) 產生的影像資料量大且種類繁多，是訓練虛擬染色模型的絕佳資源。然而，在特定實驗條件下訓練的模型對其他條件的泛化潛力仍未得到充分探索。本研究系統性地探討來自 HTS 中常見的三種類型細胞 (肺、卵巢和乳房) 和兩種表型 (毒性和非毒性條件) 的資料是否能有效訓練虛擬染色模型，以泛化到三個典型的 HTS 分布轉移：未見表型、未見細胞類型以及兩者的組合。我們利用 772,416 個配對的明視野、細胞質、細胞核和 DNA 損傷染色圖像的資料集，評估模型在基於像素、基於實例和基於生物特徵層級的泛化能力。我們的研究結果表明，在非毒性條件樣本上訓練虛擬細胞核和細胞質模型不僅能泛化到毒性條件樣本，而且與在毒性條件樣本上訓練相比，在所有評估層級上都能提升效能。泛化到未見細胞類型的表現因細胞類型而異；在卵巢或肺細胞樣本上訓練的模型通常在其他條件下表現良好，而那些在乳房細胞樣本上訓練的模型則始終表現出較差的泛化性。與僅針對未見細胞類型相比，泛化到未見細胞類型和表型的表現顯示出在所有評估層級上都有良好的泛化性。本研究代表了第一個針對在多樣化 HTS 資料集上訓練的虛擬染色模型的泛化能力進行的大規模、以資料為中心分析，為實驗訓練資料產生提供了有價值的策略。</paragraph>

##### **Advancing Manuscript Metadata: Work in Progress at the Jagiellonian University**
2407.06976v1 by Luiz do Valle Miranda, Krzysztof Kutt, Grzegorz J. Nalepa

As part of ongoing research projects, three Jagiellonian University units --
the Jagiellonian University Museum, the Jagiellonian University Archives, and
the Jagiellonian Library -- are collaborating to digitize cultural heritage
documents, describe them in detail, and then integrate these descriptions into
a linked data cloud. Achieving this goal requires, as a first step, the
development of a metadata model that, on the one hand, complies with existing
standards, on the other hand, allows interoperability with other systems, and
on the third, captures all the elements of description established by the
curators of the collections. In this paper, we present a report on the current
status of the work, in which we outline the most important requirements for the
data model under development and then make a detailed comparison with the two
standards that are the most relevant from the point of view of collections:
Europeana Data Model used in Europeana and Encoded Archival Description used in
Kalliope.

摘要：作為正在進行的研究計畫的一部分，三個亞捷隆大學單位——亞捷隆大學博物館、亞捷隆大學檔案館和亞捷隆圖書館——正在合作將文化遺產文件數位化、詳細描述它們，然後將這些描述整合到連結資料雲中。實現此目標需要，作為第一步，開發一個元資料模型，一方面，它符合現有標準，另一方面，它允許與其他系統互通，第三方面，它擷取由館藏策展人建立的所有描述元素。在本文中，我們提出了一份關於工作現況的報告，在報告中，我們概述了正在開發的資料模型最重要的需求，然後對從館藏觀點來看最相關的兩個標準進行詳細比較：歐洲資料模型用於 Europeana，編碼檔案描述用於 Kalliope。

##### **Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models**
2407.06957v1 by Yi-Cheng Lin, Tzu-Quan Lin, Chih-Kai Yang, Ke-Han Lu, Wei-Chih Chen, Chun-Yi Kuan, Hung-yi Lee

Speech Integrated Large Language Models (SILLMs) combine large language
models with speech perception to perform diverse tasks, such as emotion
recognition to speaker verification, demonstrating universal audio
understanding capability. However, these models may amplify biases present in
training data, potentially leading to biased access to information for
marginalized groups. This work introduces a curated spoken bias evaluation
toolkit and corresponding dataset. We evaluate gender bias in SILLMs across
four semantic-related tasks: speech-to-text translation (STT), spoken
coreference resolution (SCR), spoken sentence continuation (SSC), and spoken
question answering (SQA). Our analysis reveals that bias levels are
language-dependent and vary with different evaluation methods. Our findings
emphasize the necessity of employing multiple approaches to comprehensively
assess biases in SILLMs, providing insights for developing fairer SILLM
systems.

摘要：語音整合式大型語言模型 (SILLM) 結合大型語言模型與語音感知，以執行多樣化的任務，例如情緒辨識到說話者驗證，展示出通用的音訊理解能力。然而，這些模型可能會擴大訓練資料中存在的偏見，潛在導致弱勢群體無法公平取得資訊。這項工作引進一個經過整理的口語偏見評估工具包和對應的資料集。我們評估了四項語義相關任務中 SILLM 的性別偏見：語音轉文字翻譯 (STT)、口語共指解析 (SCR)、口語句子延續 (SSC) 和口語問答 (SQA)。我們的分析顯示，偏見程度取決於語言，並隨著不同的評估方法而有所不同。我們的研究結果強調採用多種方法來全面評估 SILLM 中的偏見，並為開發更公平的 SILLM 系統提供見解。

##### **ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization**
2407.06955v1 by Wai Man Si, Michael Backes, Yang Zhang

In-context learning (ICL) is a recent advancement in the capabilities of
large language models (LLMs). This feature allows users to perform a new task
without updating the model. Concretely, users can address tasks during the
inference time by conditioning on a few input-label pair demonstrations along
with the test input. It is different than the conventional fine-tuning paradigm
and offers more flexibility. However, this capability also introduces potential
issues. For example, users may use the model on any data without restriction,
such as performing tasks with improper or sensitive content, which might
violate the model policy or conflict with the model owner's interests. As a
model owner, it is crucial to establish a mechanism to control the model's
behavior under ICL, depending on the model owner's requirements for various
content. To this end, we introduce the concept of "applicability authorization"
tailored for LLMs, particularly for ICL behavior, and propose a simple
approach, ICLGuard. It is a fine-tuning framework designed to allow the model
owner to regulate ICL behavior on different data. ICLGuard preserves the
original LLM and fine-tunes only a minimal set of additional trainable
parameters to "guard" the LLM. Empirical results show that the guarded LLM can
deactivate its ICL ability on target data without affecting its ICL ability on
other data and its general functionality across all data.

摘要：情境學習 (ICL) 是大型語言模型 (LLM) 能力的最新進展。此功能允許使用者在不更新模型的情況下執行新任務。具體來說，使用者可以在推論時間透過對少數輸入標籤配對示範以及測試輸入進行條件化來處理任務。這與傳統的微調範例不同，並提供了更大的彈性。但是，此功能也引入了潛在問題。例如，使用者可能會在任何資料上使用模型而沒有限制，例如執行具有不當或敏感內容的任務，這可能會違反模型政策或與模型所有者的利益相衝突。作為模型所有者，建立一種機制來控制 ICL 下的模型行為至關重要，這取決於模型所有者對各種內容的要求。為此，我們引入了「適用性授權」的概念，專門針對 LLM，特別是 ICL 行為，並提出了一個簡單的方法，ICLGuard。這是一個微調框架，旨在允許模型所有者在不同資料上調整 ICL 行為。ICLGuard 保留原始 LLM，並且僅微調最小的可訓練參數集來「保護」LLM。經驗結果表明，受保護的 LLM 可以停用其在目標資料上的 ICL 能力，而不會影響其在其他資料上的 ICL 能力及其在所有資料上的一般功能。

##### **Spanish TrOCR: Leveraging Transfer Learning for Language Adaptation**
2407.06950v1 by Filipe Lauar, Valentin Laurent

This study explores the transfer learning capabilities of the TrOCR
architecture to Spanish. TrOCR is a transformer-based Optical Character
Recognition (OCR) model renowned for its state-of-the-art performance in
English benchmarks. Inspired by Li et al. assertion regarding its adaptability
to multilingual text recognition, we investigate two distinct approaches to
adapt the model to a new language: integrating an English TrOCR encoder with a
language specific decoder and train the model on this specific language, and
fine-tuning the English base TrOCR model on a new language data. Due to the
scarcity of publicly available datasets, we present a resource-efficient
pipeline for creating OCR datasets in any language, along with a comprehensive
benchmark of the different image generation methods employed with a focus on
Visual Rich Documents (VRDs). Additionally, we offer a comparative analysis of
the two approaches for the Spanish language, demonstrating that fine-tuning the
English TrOCR on Spanish yields superior recognition than the language specific
decoder for a fixed dataset size. We evaluate our model employing character and
word error rate metrics on a public available printed dataset, comparing the
performance against other open-source and cloud OCR spanish models. As far as
we know, these resources represent the best open-source model for OCR in
Spanish. The Spanish TrOCR models are publicly available on HuggingFace [20]
and the code to generate the dataset is available on Github [25].

摘要：本研究探討了 TrOCR 架構將轉移學習能力應用於西班牙語的可能性。TrOCR 是一種基於轉換器的光學字元辨識 (OCR) 模型，以其在英語基準測試中的先進效能而聞名。受到李等人關於其適應多語言文字辨識的論斷啟發，我們探討了兩種不同的方法來將模型調整到新語言：將英語 TrOCR 編碼器與特定語言的解碼器整合，並針對此特定語言訓練模型，以及針對新語言資料微調英語基礎 TrOCR 模型。由於公開可用的資料集稀少，我們提供了一個資源節省的管線，用於建立任何語言的 OCR 資料集，並全面評量所採用的不同影像產生方法，重點放在視覺豐富文件 (VRD) 上。此外，我們對西班牙語的兩種方法進行比較分析，證明針對西班牙語微調英語 TrOCR 所產生的辨識優於特定語言的解碼器，而資料集大小固定。我們使用字元和字詞錯誤率指標評估我們的模型，採用公開可用的印刷版資料集，並將效能與其他開源和雲端 OCR 西班牙語模型進行比較。據我們所知，這些資源代表了西班牙語 OCR 最佳的開源模型。西班牙語 TrOCR 模型已公開於 HuggingFace [20] 上，而產生資料集的程式碼則可在 Github [25] 上取得。

##### **Self-Recognition in Language Models**
2407.06946v1 by Tim R. Davidson, Viacheslav Surkov, Veniamin Veselovsky, Giuseppe Russo, Robert West, Caglar Gulcehre

A rapidly growing number of applications rely on a small set of closed-source
language models (LMs). This dependency might introduce novel security risks if
LMs develop self-recognition capabilities. Inspired by human identity
verification methods, we propose a novel approach for assessing
self-recognition in LMs using model-generated "security questions". Our test
can be externally administered to keep track of frontier models as it does not
require access to internal model parameters or output probabilities. We use our
test to examine self-recognition in ten of the most capable open- and
closed-source LMs currently publicly available. Our extensive experiments found
no empirical evidence of general or consistent self-recognition in any examined
LM. Instead, our results suggest that given a set of alternatives, LMs seek to
pick the "best" answer, regardless of its origin. Moreover, we find indications
that preferences about which models produce the best answers are consistent
across LMs. We additionally uncover novel insights on position bias
considerations for LMs in multiple-choice settings.

摘要：越來越多的應用程式依賴於一組封閉原始碼語言模型 (LM)。如果 LM 發展出自我識別能力，這種依賴性可能會帶來新的安全風險。受人類身分驗證方法的啟發，我們提出了一種新的方法，使用模型產生的「安全問題」來評估 LM 中的自我識別。我們的測試可以外部管理，以追蹤前沿模型，因為它不需要存取內部模型參數或輸出機率。我們使用我們的測試來檢驗目前公開可用的十個功能最強大的開放和封閉原始碼 LM 中的自我識別。我們廣泛的實驗在任何受檢的 LM 中都沒有發現一般或一致的自我識別的經驗證據。相反，我們的結果表明，在給定一組備選方案的情況下，LM 會試圖選擇「最佳」答案，無論其來源為何。此外，我們發現有跡象表明，關於哪個模型產生最佳答案的偏好是一致的。我們還揭示了在多選題設定中，LM 對位置偏差考量的見解。

##### **Raply: A profanity-mitigated rap generator**
2407.06941v1 by Omar Manil Bendali, Samir Ferroum, Ekaterina Kozachenko, Youssef Parviz, Hanna Shcharbakova, Anna Tokareva, Shemair Williams

The task of writing rap is challenging and involves producing complex rhyming
schemes, yet meaningful lyrics. In this work, we propose Raply, a fine-tuned
GPT-2 model capable of producing meaningful rhyming text in the style of rap.
In addition to its rhyming capabilities, the model is able to generate less
offensive content. It was achieved through the fine-tuning the model on a new
dataset Mitislurs, a profanity-mitigated corpus. We evaluate the output of the
model on two criteria: 1) rhyming based on the rhyme density metric; 2)
profanity content, using the list of profanities for the English language. To
our knowledge, this is the first attempt at profanity mitigation for rap lyrics
generation.

摘要：饒舌創作的任務充滿挑戰，需要產生複雜的押韻結構，卻又要有意義的歌詞。在這個作品中，我們提出 Raply，一個經過微調的 GPT-2 模型，能夠以饒舌風格產生有意義的押韻文字。除了押韻能力外，這個模型還能產生較不冒犯的內容。這是透過微調模型在一個新的資料集 Mitislurs 上達成的，Mitislurs 是個經過髒話緩解處理的語料庫。我們根據兩個標準評估模型的輸出：1) 基於押韻密度指標的押韻；2) 髒話內容，使用英語髒話清單。據我們所知，這是首次嘗試對饒舌歌詞生成進行髒話緩解。

##### **Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance**
2407.06930v1 by Milapji Singh Gill, Tom Westermann, Gernot Steindl, Felix Gehlhoff, Alexander Fay

In the following contribution, a method is introduced that integrates domain
expert-centric ontology design with the Cross-Industry Standard Process for
Data Mining (CRISP-DM). This approach aims to efficiently build an
application-specific ontology tailored to the corrective maintenance of
Cyber-Physical Systems (CPS). The proposed method is divided into three phases.
In phase one, ontology requirements are systematically specified, defining the
relevant knowledge scope. Accordingly, CPS life cycle data is contextualized in
phase two using domain-specific ontological artifacts. This formalized domain
knowledge is then utilized in the CRISP-DM to efficiently extract new insights
from the data. Finally, the newly developed data-driven model is employed to
populate and expand the ontology. Thus, information extracted from this model
is semantically annotated and aligned with the existing ontology in phase
three. The applicability of this method has been evaluated in an anomaly
detection case study for a modular process plant.

摘要：在以下貢獻中，引入了一種方法，將領域專家為中心的本体設計與資料探勘的跨產業標準程序 (CRISP-DM) 整合。此方法旨在有效建構一個特定於應用程式的本体，專門用於網路實體系統 (CPS) 的矯正維護。所提出的方法分為三個階段。在第一階段，本体需求經過系統性地指定，定義相關的知識範圍。相應地，CPS 生命週期資料在第二階段使用特定於領域的本体工件進行情境化。然後在 CRISP-DM 中利用這個形式化的領域知識，從資料中有效地萃取新的見解。最後，使用新開發的資料驅動模型來填充和擴展本体。因此，從此模型萃取的資訊在第三階段經過語義註解，並與現有的本体對齊。這種方法的適用性已在模組化程序工廠的異常偵測案例研究中獲得評估。

##### **Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models**
2407.06917v1 by Zara Siddique, Liam D. Turner, Luis Espinosa-Anke

Large language models (LLMs) have been shown to propagate and amplify harmful
stereotypes, particularly those that disproportionately affect marginalised
communities. To understand the effect of these stereotypes more
comprehensively, we introduce GlobalBias, a dataset of 876k sentences
incorporating 40 distinct gender-by-ethnicity groups alongside descriptors
typically used in bias literature, which enables us to study a broad set of
stereotypes from around the world. We use GlobalBias to directly probe a suite
of LMs via perplexity, which we use as a proxy to determine how certain
stereotypes are represented in the model's internal representations. Following
this, we generate character profiles based on given names and evaluate the
prevalence of stereotypes in model outputs. We find that the demographic groups
associated with various stereotypes remain consistent across model likelihoods
and model outputs. Furthermore, larger models consistently display higher
levels of stereotypical outputs, even when explicitly instructed not to.

摘要：大型語言模型 (LLM) 已被證明會傳播和放大有害刻板印象，特別是那些對邊緣化社群造成不公平影響的刻板印象。為了更全面地了解這些刻板印象的影響，我們引入了 GlobalBias，這是一個包含 876,000 個句子的資料集，結合了 40 個不同的性別與種族群體，以及偏誤文獻中通常使用的描述符，這讓我們得以研究來自世界各地的廣泛刻板印象。我們使用 GlobalBias 直接透過困惑度探測一組 LLM，我們使用困惑度作為代理來確定模型內部表徵中如何表徵某些刻板印象。在此之後，我們根據給定的姓名產生角色設定檔，並評估模型輸出中刻板印象的普遍性。我們發現與各種刻板印象相關的人口統計群體在模型可能性和模型輸出中保持一致。此外，即使明確指示不要這樣做，較大的模型也會持續顯示較高程度的刻板印象輸出。

##### **Fine-grained large-scale content recommendations for MSX sellers**
2407.06910v1 by Manpreet Singh, Ravdeep Pasricha, Ravi Prasad Kondapalli, Kiran R, Nitish Singh, Akshita Agarwalla, Manoj R, Manish Prabhakar, Laurent Boué

One of the most critical tasks of Microsoft sellers is to meticulously track
and nurture potential business opportunities through proactive engagement and
tailored solutions. Recommender systems play a central role to help sellers
achieve their goals. In this paper, we present a content recommendation model
which surfaces various types of content (technical documentation, comparison
with competitor products, customer success stories etc.) that sellers can share
with their customers or use for their own self-learning. The model operates at
the opportunity level which is the lowest possible granularity and the most
relevant one for sellers. It is based on semantic matching between metadata
from the contents and carefully selected attributes of the opportunities.
Considering the volume of seller-managed opportunities in organizations such as
Microsoft, we show how to perform efficient semantic matching over a very large
number of opportunity-content combinations. The main challenge is to ensure
that the top-5 relevant contents for each opportunity are recommended out of a
total of $\approx 40,000$ published contents. We achieve this target through an
extensive comparison of different model architectures and feature selection.
Finally, we further examine the quality of the recommendations in a
quantitative manner using a combination of human domain experts as well as by
using the recently proposed "LLM as a judge" framework.

摘要：微軟業務員最重要的任務之一，就是透過主動參與和量身打造的解決方案，仔細追蹤和培育潛在的商機。推薦系統扮演著核心角色，協助業務員達成目標。在本文中，我們提出一個內容推薦模型，提供各種類型的內容（技術文件、與競爭對手產品的比較、客戶成功案例等），業務員可以與客戶分享，或用於自學。此模型在商機層級運作，這是最低的可能粒度，也是與業務員最相關的層級。此模型基於內容的元資料與仔細挑選的商機屬性之間的語意比對。考量到像微軟這樣的組織中業務員管理的商機數量，我們展示如何對非常大量的商機內容組合執行有效的語意比對。主要的挑戰是確保針對每個商機推薦前 5 個相關內容，而總共有大約 40,000 個已發布的內容。我們透過廣泛比較不同的模型架構和特徵選擇，達成這個目標。最後，我們進一步以量化的方式檢視推薦的品質，使用人類領域專家與最近提出的「LLM 作為評審」架構的組合。

##### **Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning**
2407.06909v1 by Francisco Giral, Ignacio Gómez, Soledad Le Clainche

The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace
presents significant risks, including potential collisions, disruptions to air
traffic, and security threats. Ensuring the safe and efficient operation of
airspace, particularly in urban environments and near critical infrastructure,
necessitates effective methods to intercept unauthorized or non-cooperative
UAVs. This work addresses the critical need for robust, adaptive systems
capable of managing such threats through the use of Reinforcement Learning
(RL). We present a novel approach utilizing RL to train fixed-wing UAV pursuer
agents for intercepting dynamic evader targets. Our methodology explores both
model-based and model-free RL algorithms, specifically DreamerV3, Truncated
Quantile Critics (TQC), and Soft Actor-Critic (SAC). The training and
evaluation of these algorithms were conducted under diverse scenarios,
including unseen evasion strategies and environmental perturbations. Our
approach leverages high-fidelity flight dynamics simulations to create
realistic training environments. This research underscores the importance of
developing intelligent, adaptive control systems for UAV interception,
significantly contributing to the advancement of secure and efficient airspace
management. It demonstrates the potential of RL to train systems capable of
autonomously achieving these critical tasks.

摘要：無人機（UAV）在受控空域的擴散帶來顯著風險，包括潛在碰撞、空中交通中斷和安全威脅。確保空域安全且有效率地運作，特別是在市區環境和臨近關鍵基礎設施時，需要有效的方法來攔截未經授權或不合作的無人機。這項工作解決了對強健、適應性系統的關鍵需求，這些系統能夠透過使用強化學習（RL）來管理此類威脅。我們提出了一種利用 RL 訓練固定翼無人機追擊者代理以攔截動態規避目標的新方法。我們的做法探討了基於模型和無模型的 RL 演算法，特別是 DreamerV3、截斷分位數批評者（TQC）和 Soft Actor-Critic（SAC）。這些演算法的訓練和評估是在各種情況下進行的，包括未見的規避策略和環境擾動。我們的做法利用高保真飛行動力學模擬來建立逼真的訓練環境。這項研究強調了開發無人機攔截的智慧型適應性控制系統的重要性，對安全且有效率的空域管理的進展有顯著貢獻。它展示了 RL 訓練系統以自主達成這些關鍵任務的潛力。

##### **Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models**
2407.06908v1 by Flor Miriam Plaza-del-Arco, Amanda Cercas Curry, Susanna Paoli, Alba Curry, Dirk Hovy

Emotions play important epistemological and cognitive roles in our lives,
revealing our values and guiding our actions. Previous work has shown that LLMs
display biases in emotion attribution along gender lines. However, unlike
gender, which says little about our values, religion, as a socio-cultural
system, prescribes a set of beliefs and values for its followers. Religions,
therefore, cultivate certain emotions. Moreover, these rules are explicitly
laid out and interpreted by religious leaders. Using emotion attribution, we
explore how different religions are represented in LLMs. We find that: Major
religions in the US and European countries are represented with more nuance,
displaying a more shaded model of their beliefs. Eastern religions like
Hinduism and Buddhism are strongly stereotyped. Judaism and Islam are
stigmatized -- the models' refusal skyrocket. We ascribe these to cultural bias
in LLMs and the scarcity of NLP literature on religion. In the rare instances
where religion is discussed, it is often in the context of toxic language,
perpetuating the perception of these religions as inherently toxic. This
finding underscores the urgent need to address and rectify these biases. Our
research underscores the crucial role emotions play in our lives and how our
values influence them.

摘要：<paragraph>情緒在我們的生活中扮演重要的認識論和認知角色，
揭示我們的價值觀並指導我們的行動。先前的研究表明，LLM
在情緒歸因上表現出沿著性別界線的偏見。然而，不同於
性別，它對我們的價值觀幾乎沒有說明，宗教作為一個社會文化
體系，為其追隨者規定了一套信仰和價值觀。因此，宗教培養
某些情緒。此外，這些規則由宗教領袖明確制定和解釋。使用
情緒歸因，我們探討 LLM 中如何呈現不同的宗教。我們發現：
美國和歐洲國家的主要宗教以更多細微差別呈現，展示了他們
信仰的更具陰影的模型。印度教和佛教等東方宗教被強烈定型。
猶太教和伊斯蘭教受到污名化——模型的拒絕激增。我們將這些
歸因於 LLM 中的文化偏見和宗教方面的 NLP 文獻的稀缺性。
在極少數討論宗教的情況下，通常是在有毒語言的背景下，
使這些宗教被視為本質上具有毒性的觀念永久化。這一發現
強調了解決和糾正這些偏見的迫切需要。我們的研究強調了
情緒在我們生活中扮演的關鍵角色，以及我們的價值觀如何影響
它們。</paragraph>

##### **Hypergraph based Understanding for Document Semantic Entity Recognition**
2407.06904v1 by Qiwei Li, Zuchao Li, Ping Wang, Haojun Ai, Hai Zhao

Semantic entity recognition is an important task in the field of
visually-rich document understanding. It distinguishes the semantic types of
text by analyzing the position relationship between text nodes and the relation
between text content. The existing document understanding models mainly focus
on entity categories while ignoring the extraction of entity boundaries. We
build a novel hypergraph attention document semantic entity recognition
framework, HGA, which uses hypergraph attention to focus on entity boundaries
and entity categories at the same time. It can conduct a more detailed analysis
of the document text representation analyzed by the upstream model and achieves
a better performance of semantic information. We apply this method on the basis
of GraphLayoutLM to construct a new semantic entity recognition model
HGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that
our method can effectively improve the performance of semantic entity
recognition tasks based on the original model. The results of HGALayoutLM on
FUNSD and XFUND reach the new state-of-the-art results.

摘要：语义实体识别是视觉丰富文档理解领域中的一项重要任务。它通过分析文本节点之间的位置关系和文本内容之间的关系来区分文本的语义类型。现有的文档理解模型主要关注实体类别，而忽略了实体边界的提取。我们构建了一个新颖的超图注意力文档语义实体识别框架 HGA，它利用超图注意力同时关注实体边界和实体类别。它可以对上游模型分析的文档文本表示进行更详细的分析，并实现更好的语义信息性能。我们在 GraphLayoutLM 的基础上应用这种方法来构建新的语义实体识别模型 HGALayoutLM。我们在 FUNSD、CORD、XFUND 和 SROIE 上的实验结果表明，我们的方法可以有效提高基于原始模型的语义实体识别任务的性能。HGALayoutLM 在 FUNSD 和 XFUND 上的结果达到了新的最先进的结果。

##### **Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective**
2407.06902v1 by Shahana Ibrahim, Panagiotis A. Traganitis, Xiao Fu, Georgios B. Giannakis

One of the primary catalysts fueling advances in artificial intelligence (AI)
and machine learning (ML) is the availability of massive, curated datasets. A
commonly used technique to curate such massive datasets is crowdsourcing, where
data are dispatched to multiple annotators. The annotator-produced labels are
then fused to serve downstream learning and inference tasks. This annotation
process often creates noisy labels due to various reasons, such as the limited
expertise, or unreliability of annotators, among others. Therefore, a core
objective in crowdsourcing is to develop methods that effectively mitigate the
negative impact of such label noise on learning tasks. This feature article
introduces advances in learning from noisy crowdsourced labels. The focus is on
key crowdsourcing models and their methodological treatments, from classical
statistical models to recent deep learning-based approaches, emphasizing
analytical insights and algorithmic developments. In particular, this article
reviews the connections between signal processing (SP) theory and methods, such
as identifiability of tensor and nonnegative matrix factorization, and novel,
principled solutions of longstanding challenges in crowdsourcing -- showing how
SP perspectives drive the advancements of this field. Furthermore, this article
touches upon emerging topics that are critical for developing cutting-edge
AI/ML systems, such as crowdsourcing in reinforcement learning with human
feedback (RLHF) and direct preference optimization (DPO) that are key
techniques for fine-tuning large language models (LLMs).

摘要：人工智慧 (AI) 和機器學習 (ML) 進步的主要催化劑之一是大量整理好的資料集。整理如此龐大資料集的常用技術是眾包，其中資料會分派給多位註解者。然後將註解者產生的標籤融合，以服務於下游學習和推理任務。此註解程序通常會因為各種原因而產生雜訊標籤，例如註解者的專業知識有限或不可靠等。因此，眾包的核心目標是開發有效減輕此類標籤雜訊對學習任務的負面影響的方法。這篇特寫文章介紹了從雜訊眾包標籤中學習的進展。重點在於關鍵的眾包模型及其方法論處理，從經典統計模型到最近基於深度學習的方法，強調分析見解和演算法發展。特別是，本文回顧了訊號處理 (SP) 理論和方法之間的關聯，例如張量和非負矩陣分解的可識別性，以及眾包中長期挑戰的新穎原則性解決方案——展示 SP 觀點如何推動該領域的進展。此外，本文還觸及了對開發尖端 AI/ML 系統至關重要的新興主題，例如在具有人類回饋 (RLHF) 的強化學習中進行眾包，以及直接偏好最佳化 (DPO)，這是微調大型語言模型 (LLM) 的關鍵技術。

##### **Measuring Sustainability Intention of ESG Fund Disclosure using Few-Shot Learning**
2407.06893v1 by Mayank Singh, Nazia Nafis, Abhijeet Kumar, Mridul Mishra

Global sustainable fund universe encompasses open-end funds and
exchange-traded funds (ETF) that, by prospectus or other regulatory filings,
claim to focus on Environment, Social and Governance (ESG). Challengingly, the
claims can only be confirmed by examining the textual disclosures to check if
there is presence of intentionality and ESG focus on its investment strategy.
Currently, there is no regulation to enforce sustainability in ESG products
space. This paper proposes a unique method and system to classify and score the
fund prospectuses in the sustainable universe regarding specificity and
transparency of language. We aim to employ few-shot learners to identify
specific, ambiguous, and generic sustainable investment-related language.
Additionally, we construct a ratio metric to determine language score and
rating to rank products and quantify sustainability claims for US sustainable
universe. As a by-product, we publish manually annotated quality training
dataset on Hugging Face (ESG-Prospectus-Clarity-Category under cc-by-nc-sa-4.0)
of more than 1K ESG textual statements. The performance of the few-shot
finetuning approach is compared with zero-shot models e.g., Llama-13B, GPT 3.5
Turbo etc. We found that prompting large language models are not accurate for
domain specific tasks due to misalignment issues. The few-shot finetuning
techniques outperform zero-shot models by large margins of more than absolute
~30% in precision, recall and F1 metrics on completely unseen ESG languages
(test set). Overall, the paper attempts to establish a systematic and scalable
approach to measure and rate sustainability intention quantitatively for
sustainable funds using texts in prospectus. Regulatory bodies, investors, and
advisors may utilize the findings of this research to reduce cognitive load in
investigating or screening of ESG funds which accurately reflects the ESG
intention.

摘要：全球永續基金包含開放式基金和交易所買賣基金 (ETF)，根據公開說明書或其他法規文件，宣稱專注於環境、社會和公司治理 (ESG)。具有挑戰性的是，這些宣稱只能透過檢視文字揭露資訊來確認，以檢查投資策略中是否存在明確意圖和 ESG 重點。目前，沒有法規來強制執行 ESG 產品領域中的永續性。本文提出一個獨特的方法和系統來分類和評分永續領域中的基金公開說明書，針對語言的具體性和透明度。我們的目標是採用少樣本學習器來識別具體、模稜兩可和通用的永續投資相關語言。此外，我們建構一個比率指標來決定語言分數和評分，以對產品進行排名，並量化美國永續領域永續宣稱。作為附帶產品，我們在 Hugging Face（cc-by-nc-sa-4.0 下的 ESG-Prospectus-Clarity-Category）上發布超過 1K 份 ESG 文字聲明的經人工註解的高品質訓練資料集。將少樣本微調方法的效能與零樣本模型（例如 Llama-13B、GPT 3.5 Turbo 等）進行比較。我們發現，提示大型語言模型對於特定領域的任務並非準確，原因在於未對齊的問題。少樣本微調技術在完全未見過的 ESG 語言（測試集）上，在準確度、召回率和 F1 指標方面，比零樣本模型高出超過絕對 30% 的大幅差距。整體而言，本文嘗試建立一個系統化且可擴充的方法，使用公開說明書中的文字，來衡量和評分永續基金的永續意圖。法規機構、投資人和顧問可以利用這項研究的發現，來減少在調查或篩選 ESG 基金時的認知負擔，而這些基金準確反映了 ESG 意圖。

##### **Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI**
2407.06886v1 by Yang Liu, Weixing Chen, Yongjie Bai, Jingzhou Luo, Xinshuai Song, Kaixuan Jiang, Zhida Li, Ganlong Zhao, Junyi Lin, Guanbin Li, Wen Gao, Liang Lin

Embodied Artificial Intelligence (Embodied AI) is crucial for achieving
Artificial General Intelligence (AGI) and serves as a foundation for various
applications that bridge cyberspace and the physical world. Recently, the
emergence of Multi-modal Large Models (MLMs) and World Models (WMs) have
attracted significant attention due to their remarkable perception,
interaction, and reasoning capabilities, making them a promising architecture
for the brain of embodied agents. However, there is no comprehensive survey for
Embodied AI in the era of MLMs. In this survey, we give a comprehensive
exploration of the latest advancements in Embodied AI. Our analysis firstly
navigates through the forefront of representative works of embodied robots and
simulators, to fully understand the research focuses and their limitations.
Then, we analyze four main research targets: 1) embodied perception, 2)
embodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,
covering the state-of-the-art methods, essential paradigms, and comprehensive
datasets. Additionally, we explore the complexities of MLMs in virtual and real
embodied agents, highlighting their significance in facilitating interactions
in dynamic digital and physical environments. Finally, we summarize the
challenges and limitations of embodied AI and discuss their potential future
directions. We hope this survey will serve as a foundational reference for the
research community and inspire continued innovation. The associated project can
be found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.

摘要：具身人工智慧 (Embodied AI) 對於達成人工通用智慧 (AGI) 至關重要，並作為橋接網路空間和物理世界的各種應用程式基礎。最近，多模態大型模型 (MLM) 和世界模型 (WM) 的出現，由於其卓越的感知、互動和推理能力，而備受矚目，使其成為具身代理人腦部的有望架構。然而，在 MLM 時代，沒有針對具身 AI 的全面調查。在這項調查中，我們對具身 AI 的最新進展進行全面探討。我們的分析首先瀏覽具身機器人和模擬器的代表性作品的最前沿，以充分了解研究重點及其局限性。然後，我們分析四個主要研究目標：1) 具身感知，2) 具身互動，3) 具身代理人，以及 4) 模擬到真實適應，涵蓋最先進的方法、基本範例和全面的資料集。此外，我們探討了虛擬和真實具身代理人中 MLM 的複雜性，強調它們在促進動態數位和物理環境中的互動方面的重要性。最後，我們總結了具身 AI 的挑戰和限制，並討論它們潛在的未來方向。我們希望這項調查能作為研究社群的基本參考，並激勵持續創新。相關專案可以在 https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List 找到。

##### **ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context**
2407.06866v1 by Victoria R. Li, Yida Chen, Naomi Saphra

While the biases of language models in production are extensively documented,
the biases of their guardrails have been neglected. This paper studies how
contextual information about the user influences the likelihood of an LLM to
refuse to execute a request. By generating user biographies that offer
ideological and demographic information, we find a number of biases in
guardrail sensitivity on GPT-3.5. Younger, female, and Asian-American personas
are more likely to trigger a refusal guardrail when requesting censored or
illegal information. Guardrails are also sycophantic, refusing to comply with
requests for a political position the user is likely to disagree with. We find
that certain identity groups and seemingly innocuous information, e.g., sports
fandom, can elicit changes in guardrail sensitivity similar to direct
statements of political ideology. For each demographic category and even for
American football team fandom, we find that ChatGPT appears to infer a likely
political ideology and modify guardrail behavior accordingly.

摘要：儘管語言模型在生產中的偏差已廣泛記錄，
但其防護措施的偏差卻被忽略了。本文研究了關於使用者的背景資訊如何影響 LLM 拒絕執行請求的可能性。透過產生提供意識形態和人口統計資訊的使用者傳記，我們發現 GPT-3.5 防護措施敏感性存在許多偏差。年輕、女性和亞裔美國人的角色在要求審查或非法資訊時，更有可能觸發拒絕防護措施。防護措施也具有阿諛奉承的性質，拒絕遵守使用者可能不同意的政治立場的請求。我們發現某些身分群體和看似無害的資訊（例如體育迷）會引發防護措施敏感性的變化，類似於直接陳述政治意識形態。對於每個人口統計類別，甚至對於美式足球隊的球迷，我們發現 ChatGPT 似乎會推論出可能的政治意識形態，並相應地修改防護措施行為。

##### **Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems**
2407.06862v1 by Lorenzo Cassano, Jacopo D'Abramo, Siraj Munir, Stefano Ferretti

In this paper, we present a study of a Federated Learning (FL) system, based
on the use of decentralized architectures to ensure trust and increase
reliability. The system is based on the idea that the FL collaborators upload
the (ciphered) model parameters on the Inter-Planetary File System (IPFS) and
interact with a dedicated smart contract to track their behavior. Thank to this
smart contract, the phases of parameter updates are managed efficiently,
thereby strengthening data security. We have carried out an experimental study
that exploits two different methods of weight aggregation, i.e., a classic
averaging scheme and a federated proximal aggregation. The results confirm the
feasibility of the proposal.

摘要：在本文中，我們提出了一個聯合學習 (FL) 系統的研究，它基於分散式架構的使用，以確保信任並提高可靠性。該系統基於這樣的想法：FL 協作者將（密碼）模型參數上傳到星際檔案系統 (IPFS) 並與專用智慧合約互動以追蹤其行為。感謝這個智慧合約，參數更新階段得到有效管理，從而加強了資料安全性。我們進行了一項實驗研究，利用了兩種不同的權重聚合方法，即經典平均方案和聯合近端聚合。結果證實了該提案的可行性。

##### **TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**
2407.06852v1 by Jacob Thrasher, Alina Devkota, Ahmed Tafti, Binod Bhattarai, Prashnna Gyawali

Alzheimer's Dementia (AD) represents one of the most pressing challenges in
the field of neurodegenerative disorders, with its progression analysis being
crucial for understanding disease dynamics and developing targeted
interventions. Recent advancements in deep learning and various representation
learning strategies, including self-supervised learning (SSL), have shown
significant promise in enhancing medical image analysis, providing innovative
ways to extract meaningful patterns from complex data. Notably, the computer
vision literature has demonstrated that incorporating supervisory signals into
SSL can further augment model performance by guiding the learning process with
additional relevant information. However, the application of such supervisory
signals in the context of disease progression analysis remains largely
unexplored. This gap is particularly pronounced given the inherent challenges
of incorporating both event and time-to-event information into the learning
paradigm. Addressing this, we propose a novel framework, Time and Even-aware
SSL (TE-SSL), which integrates time-to-event and event data as supervisory
signals to refine the learning process. Our comparative analysis with existing
SSL-based methods in the downstream task of survival analysis shows superior
performance across standard metrics.

摘要：阿茲海默症失智症 (AD) 是神經退化性疾病領域中最迫切的挑戰之一，其進程分析對於了解疾病動態和開發目標性干預措施至關重要。深度學習和各種表示學習策略（包括自監督學習 (SSL)）的最新進展，已在增強醫學影像分析方面展現顯著前景，提供從複雜資料中提取有意義模式的創新方法。值得注意的是，電腦視覺文獻已證明將監督訊號納入 SSL 可以透過提供額外相關資訊來指導學習過程，進一步增強模型效能。然而，此類監督訊號在疾病進程分析中的應用仍未得到充分探討。由於將事件和事件時間資訊納入學習範例的固有挑戰，此差距特別明顯。針對此問題，我們提出一個創新的架構，時間和事件感知 SSL (TE-SSL)，它整合事件時間和事件資料作為監督訊號，以優化學習過程。我們在生存分析的下游任務中，對其與現有基於 SSL 的方法進行比較分析，顯示其在標準指標上的效能優異。

##### **Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders**
2407.06851v1 by Jinseok Kim, Jaewon Jung, Sangyeop Kim, Sohyung Park, Sungzoon Cho

Despite the impressive capabilities of Large Language Models (LLMs) in
various tasks, their vulnerability to unsafe prompts remains a critical issue.
These prompts can lead LLMs to generate responses on illegal or sensitive
topics, posing a significant threat to their safe and ethical use. Existing
approaches attempt to address this issue using classification models, but they
have several drawbacks. With the increasing complexity of unsafe prompts,
similarity search-based techniques that identify specific features of unsafe
prompts provide a more robust and effective solution to this evolving problem.
This paper investigates the potential of sentence encoders to distinguish safe
from unsafe prompts, and the ability to classify various unsafe prompts
according to a safety taxonomy. We introduce new pairwise datasets and the
Categorical Purity (CP) metric to measure this capability. Our findings reveal
both the effectiveness and limitations of existing sentence encoders, proposing
directions to improve sentence encoders to operate as more robust safety
detectors. Our code is available at https://github.com/JwdanielJung/Safe-Embed.

摘要：儘管大型語言模型 (LLM) 在各種任務中展現令人印象深刻的能力，但它們容易受到不安全提示的影響，這仍然是一個關鍵問題。這些提示可能會導致 LLM 對非法或敏感話題產生回應，對其安全和道德使用構成重大威脅。現有方法嘗試使用分類模型來解決這個問題，但它們有幾個缺點。隨著不安全提示的複雜性日益增加，基於相似性搜尋的技術可識別不安全提示的特定特徵，為這個不斷演變的問題提供了更強大且有效的解決方案。本文探討句子編碼器區分安全提示和不安全提示的潛力，以及根據安全分類法對各種不安全提示進行分類的能力。我們引入了新的成對資料集和分類純度 (CP) 指標來衡量此能力。我們的研究結果揭示了現有句子編碼器的有效性和限制，並提出改進句子編碼器以作為更強大的安全偵測器的方向。我們的程式碼可在 https://github.com/JwdanielJung/Safe-Embed 取得。

##### **TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data**
2407.06849v1 by Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna V. Kononova

As attention to recorded data grows in the realm of automotive testing and
manual evaluation reaches its limits, there is a growing need for automatic
online anomaly detection. This real-world data is complex in many ways and
requires the modelling of testee behaviour. To address this, we propose a
temporal variational autoencoder (TeVAE) that can detect anomalies with minimal
false positives when trained on unlabelled data. Our approach also avoids the
bypass phenomenon and introduces a new method to remap individual windows to a
continuous time series. Furthermore, we propose metrics to evaluate the
detection delay and root-cause capability of our approach and present results
from experiments on a real-world industrial data set. When properly configured,
TeVAE flags anomalies only 6% of the time wrongly and detects 65% of anomalies
present. It also has the potential to perform well with a smaller training and
validation subset but requires a more sophisticated threshold estimation
method.

摘要：隨著汽車測試領域中對記錄數據的重視不斷提高，手動評估已達到其極限，因此對自動線上異常偵測的需求也日益增加。這些真實世界的數據在許多方面都很複雜，需要對受測者的行為進行建模。為了解決這個問題，我們提出了一種時間變異自動編碼器 (TeVAE)，它可以在未標記數據上訓練時以最小的誤報率來偵測異常。我們的做法也避免了繞過現象，並引入了一種新的方法，將個別窗口重新映射到連續時間序列。此外，我們還提出了評估偵測延遲和根本原因能力的指標，並展示了在真實世界工業數據集上進行實驗的結果。在適當配置的情況下，TeVAE 僅有 6% 的時間錯誤標記異常，並偵測到 65% 的異常。它還有可能在較小的訓練和驗證子集上表現良好，但需要更精密的閾值估計方法。

##### **VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**
2407.06826v1 by Thanh-Dat Nguyen, Tung Do-Viet, Hung Nguyen-Duy, Tuan-Hai Luu, Hung Le, Bach Le, Patanamon, Thongtanunam

Businesses need to query visually rich documents (VRDs) like receipts,
medical records, and insurance forms to make decisions. Existing techniques for
extracting entities from VRDs struggle with new layouts or require extensive
pre-training data. We introduce VRDSynth, a program synthesis method to
automatically extract entity relations from multilingual VRDs without
pre-training data. To capture the complexity of VRD domain, we design a
domain-specific language (DSL) to capture spatial and textual relations to
describe the synthesized programs. Along with this, we also derive a new
synthesis algorithm utilizing frequent spatial relations, search space pruning,
and a combination of positive, negative, and exclusive programs to improve
coverage.
  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity
linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms
state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and
XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the
F1 score by 42% over LayoutXLM in English. To test the extensibility of the
model, we further improve VRDSynth with automated table recognition, creating
VRDSynth(Table), and compare it with extended versions of the pre-trained
models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these
baselines in 4 out of 8 languages and in average F1 score. VRDSynth also
significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for
LayoutXLM) while maintaining similar time efficiency.

摘要：<paragraph>企業需要查詢視覺豐富的文件 (VRD)，例如收據、醫療記錄和保險單據，才能做出決策。現有的技術用於從 VRD 中提取實體，會遇到新的版面問題，或者需要大量的預訓練數據。我們介紹 VRDSynth，這是一種程式合成方法，可以在沒有預訓練數據的情況下自動從多語言 VRD 中提取實體關係。為了捕捉 VRD 領域的複雜性，我們設計了一個特定領域語言 (DSL)，用於捕捉空間和文字關係，以描述合成的程式。除此之外，我們還推導出一個新的合成演算法，利用頻繁的空間關係、搜尋空間剪枝，以及正、負和排他程式的組合，以改善涵蓋範圍。
我們在 FUNSD 和 XFUND 基準上評估 VRDSynth，用於語義實體連結，包含 8 種語言的 1,592 個表單。VRDSynth 在 8 種語言中的 5、6 和 7 種語言中優於最先進的預訓練模型 (LayoutXLM、InfoXLMBase 和 XLMRobertaBase)，分別將英文中的 F1 分數提高了 42%，高於 LayoutXLM。為了測試模型的可擴充性，我們進一步改進 VRDSynth，採用自動化表格識別，建立 VRDSynth(Table)，並將其與預訓練模型 InfoXLM(Large) 和 XLMRoberta(Large) 的延伸版本進行比較。VRDSynth(Table) 在 8 種語言中的 4 種語言和平均 F1 分數中優於這些基準。VRDSynth 還顯著減少了記憶體使用量 (1M 和 380MB，而 LayoutXLM 為 1.48GB 和 3GB)，同時維持類似的時間效率。</paragraph>

##### **Cue Point Estimation using Object Detection**
2407.06823v1 by Giulia Argüello, Luca A. Lanzendörfer, Roger Wattenhofer

Cue points indicate possible temporal boundaries in a transition between two
pieces of music in DJ mixing and constitute a crucial element in autonomous DJ
systems as well as for live mixing. In this work, we present a novel method for
automatic cue point estimation, interpreted as a computer vision object
detection task. Our proposed system is based on a pre-trained object detection
transformer which we fine-tune on our novel cue point dataset. Our provided
dataset contains 21k manually annotated cue points from human experts as well
as metronome information for nearly 5k individual tracks, making this dataset
35x larger than the previously available cue point dataset. Unlike previous
methods, our approach does not require low-level musical information analysis,
while demonstrating increased precision in retrieving cue point positions.
Moreover, our proposed method demonstrates high adherence to phrasing, a type
of high-level music structure commonly emphasized in electronic dance music.
The code, model checkpoints, and dataset are made publicly available.

摘要：提示點表示 DJ 混音中兩段音樂之間可能的暫停時間，並構成自主 DJ 系統和現場混音的重要元素。在這項工作中，我們提出了一種自動提示點估計的新方法，它被解釋為電腦視覺物件偵測任務。我們提出的系統基於預先訓練的物件偵測轉換器，我們對我們新穎的提示點資料集進行微調。我們提供的資料集包含來自人類專家的 21k 個手動標記提示點，以及近 5k 個個別音軌的節拍器資訊，這使得此資料集比以前可用的提示點資料集大 35 倍。與先前的做法不同，我們的做法不需要低階音樂資訊分析，同時在擷取提示點位置時展現出更高的精確度。此外，我們提出的方法展現出高度符合樂句，這是一種電子舞曲中常見的高階音樂結構。程式碼、模型檢查點和資料集已公開提供。

##### **Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy**
2407.06813v1 by Zhenyu Guan, Xiangyu Kong, Fangwei Zhong, Yizhou Wang

Diplomacy is one of the most sophisticated activities in human society. The
complex interactions among multiple parties/ agents involve various abilities
like social reasoning, negotiation arts, and long-term strategy planning.
Previous AI agents surely have proved their capability of handling multi-step
games and larger action spaces on tasks involving multiple agents. However,
diplomacy involves a staggering magnitude of decision spaces, especially
considering the negotiation stage required. Recently, LLM agents have shown
their potential for extending the boundary of previous agents on a couple of
applications, however, it is still not enough to handle a very long planning
period in a complex multi-agent environment. Empowered with cutting-edge LLM
technology, we make the first stab to explore AI's upper bound towards a
human-like agent for such a highly comprehensive multi-agent mission by
combining three core and essential capabilities for stronger LLM-based societal
agents: 1) strategic planner with memory and reflection; 2) goal-oriented
negotiate with social reasoning; 3) augmenting memory by self-play games to
self-evolving without any human in the loop.

摘要：外交是人类社会中最复杂的活动之一。
多方/代理之间的复杂互动涉及各种能力，如社会推理、谈判艺术和长期战略规划。
先前的 AI 代理肯定已经证明了他们在涉及多个代理的任务中处理多步骤游戏和更大动作空间的能力。然而，外交涉及庞大的决策空间，尤其是考虑到所需的谈判阶段。最近，LLM 代理已经展示了他们在几个应用程序上扩展先前代理边界的潜力，然而，这仍然不足以在复杂的多代理环境中处理很长的规划期。借助尖端的 LLM 技术，我们首次尝试探索 AI 的上限，以实现针对如此全面多代理任务的人类代理，方法是结合三个核心和基本能力，以获得更强大的基于 LLM 的社会代理：1）具有记忆和反思的战略规划器；2）以社会推理为目标的谈判；3）通过自博弈来增强记忆，在没有人工干预的情况下自我进化。

##### **A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification**
2407.06807v1 by Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Ambra Demontis, Fabio Roli

Motivated by the superior performance of deep learning in many applications
including computer vision and natural language processing, several recent
studies have focused on applying deep neural network for devising future
generations of wireless networks. However, several recent works have pointed
out that imperceptible and carefully designed adversarial examples (attacks)
can significantly deteriorate the classification accuracy. In this paper, we
investigate a defense mechanism based on both training-time and run-time
defense techniques for protecting machine learning-based radio signal
(modulation) classification against adversarial attacks. The training-time
defense consists of adversarial training and label smoothing, while the
run-time defense employs a support vector machine-based neural rejection (NR).
Considering a white-box scenario and real datasets, we demonstrate that our
proposed techniques outperform existing state-of-the-art technologies.

摘要：受到深度學習在許多應用中展現的優異效能所激勵，包括電腦視覺和自然語言處理，最近有幾項研究專注於將深度神經網路應用於設計下一代無線網路。然而，最近有幾項研究指出，難以察覺且經過精心設計的對抗範例（攻擊）會大幅降低分類準確度。在本文中，我們探討一種防禦機制，它基於訓練時間和執行時間防禦技術，用於保護基於機器學習的無線電訊號（調變）分類，以抵禦對抗攻擊。訓練時間防禦包含對抗訓練和標籤平滑，而執行時間防禦則採用基於支持向量機的神經拒絕 (NR)。考量白盒情境和真實資料集，我們證明我們提出的技術優於現有的最先進技術。

##### **Learn and Don't Forget: Adding a New Language to ASR Foundation Models**
2407.06800v1 by Mengjie Qian, Siyuan Tang, Rao Ma, Kate M. Knill, Mark J. F. Gales

Foundation ASR models often support many languages, e.g. 100 languages in
Whisper. However, there has been limited work on integrating an additional,
typically low-resource, language, while maintaining performance on the original
language set. Fine-tuning, while simple, may degrade the accuracy of the
original set. We compare three approaches that exploit adaptation parameters:
soft language code tuning, train only the language code; soft prompt tuning,
train prepended tokens; and LoRA where a small set of additional parameters are
optimised. Elastic Weight Consolidation (EWC) offers an alternative compromise
with the potential to maintain performance in specific target languages.
Results show that direct fine-tuning yields the best performance for the new
language but degrades existing language capabilities. EWC can address this
issue for specific languages. If only adaptation parameters are used, the
language capabilities are maintained but at the cost of performance in the new
language.

摘要：基礎 ASR 模型通常支援多種語言，例如 Whisper 中的 100 種語言。然而，在整合額外的、通常是低資源的語言時，同時維持原始語言組的效能方面，一直有工作限制。微調雖然簡單，但可能會降低原始組的準確度。我們比較了利用適應參數的三種方法：軟語言代碼微調、僅訓練語言代碼；軟提示微調、訓練前置符號；以及 LoRA，其中最佳化了一小組額外的參數。彈性權重整合 (EWC) 提供了一種替代折衷方案，有潛力維持特定目標語言的效能。結果顯示，直接微調會為新語言產生最佳效能，但會降低現有語言的能力。EWC 可以解決特定語言的這個問題。如果只使用適應參數，語言能力會被維持，但代價是新語言的效能。

##### **It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human**
2407.06798v1 by Jakub Harasta, Tereza Novotná, Jaromir Savelka

Large Language Models (LLMs) enable a future in which certain types of legal
documents may be generated automatically. This has a great potential to
streamline legal processes, lower the cost of legal services, and dramatically
increase access to justice. While many researchers focus their efforts on
proposing and evaluating LLM-based applications supporting tasks in the legal
domain, there is a notable lack of investigations into how legal professionals
perceive content if they believe it has been generated by an LLM. Yet, this is
a critical point as over-reliance or unfounded skepticism may influence whether
such documents bring about appropriate legal consequences. This study is the
necessary analysis in the context of the ongoing transition towards mature
generative AI systems. Specifically, we examined whether the perception of
legal documents' by lawyers (n=75) varies based on their assumed origin
(human-crafted vs AI-generated). The participants evaluated the documents
focusing on their correctness and language quality. Our analysis revealed a
clear preference for documents perceived as crafted by a human over those
believed to be generated by AI. At the same time, most of the participants are
expecting the future in which documents will be generated automatically. These
findings could be leveraged by legal practitioners, policy makers and
legislators to implement and adopt legal document generation technology
responsibly, and to fuel the necessary discussions into how legal processes
should be updated to reflect the recent technological developments.

摘要：大型語言模型 (LLM) 使得未來某些類型的法律文件可以自動產生。這有很大的潛力可以簡化法律程序、降低法律服務的成本，並大幅增加取得正義的機會。儘管許多研究人員專注於提出和評估支援法律領域任務的基於 LLM 的應用程式，但是對於法律專業人士如何理解內容（如果他們相信該內容是由 LLM 產生的）卻鮮少有研究。然而，這是一個關鍵點，因為過度依賴或毫無根據的懷疑可能會影響這些文件是否帶來適當的法律後果。這項研究是在朝向成熟的生成式 AI 系統過渡的過程中必要的分析。具體來說，我們探討了律師 (n=75) 對法律文件的理解是否會根據他們假設的來源（人類製作與 AI 產生）而有所不同。參與者評估了文件，重點在於其正確性和語言品質。我們的分析顯示出明顯偏好人類製作的文件，而非相信是由 AI 產生的文件。同時，大多數參與者預期未來文件將會自動產生。這些發現可以被法律從業人員、政策制定者和立法者用來負責任地實施和採用法律文件產生技術，並推動必要的討論，說明法律程序應如何更新以反映最近的技術發展。

##### **ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders**
2407.06797v1 by Fotios Lygerakis, Elmar Rueckert

Traditional Variational Autoencoders (VAEs) are constrained by the
limitations of the Evidence Lower Bound (ELBO) formulation, particularly when
utilizing simplistic, non-analytic, or unknown prior distributions. These
limitations inhibit the VAE's ability to generate high-quality samples and
provide clear, interpretable latent representations. This work introduces the
Entropy Decomposed Variational Autoencoder (ED-VAE), a novel re-formulation of
the ELBO that explicitly includes entropy and cross-entropy components. This
reformulation significantly enhances model flexibility, allowing for the
integration of complex and non-standard priors. By providing more detailed
control over the encoding and regularization of latent spaces, ED-VAE not only
improves interpretability but also effectively captures the complex
interactions between latent variables and observed data, thus leading to better
generative performance.

摘要：傳統變異自動編碼器 (VAE) 受到證據下界 (ELBO) 公式的限制，特別是在使用簡化、非分析或未知先驗分佈時。這些限制會抑制 VAE 產生高品質樣本和提供清晰、可解釋的潛在表示的能力。這項工作引入了熵分解變異自動編碼器 (ED-VAE)，一種 ELBO 的新公式，其中明確包含熵和交叉熵組成。這種公式顯著增強了模型的靈活性，允許整合複雜且非標準的先驗。透過提供對潛在空間編碼和正則化的更詳細控制，ED-VAE 不僅提高了可解釋性，還能有效捕捉潛在變數和觀察資料之間的複雜互動，進而帶來更好的生成效能。

##### **Towards physics-informed neural networks for landslide prediction**
2407.06785v1 by Ashok Dahal, Luigi Lombardo

For decades, solutions to regional scale landslide prediction have mostly
relied on data-driven models, by definition, disconnected from the physics of
the failure mechanism. The success and spread of such tools came from the
ability to exploit proxy variables rather than explicit geotechnical ones, as
the latter are prohibitive to acquire over broad landscapes. Our work
implements a Physics Informed Neural Network (PINN) approach, thereby adding to
a standard data-driven architecture, an intermediate constraint to solve for
the permanent deformation typical of Newmark slope stability methods. This
translates into a neural network tasked with explicitly retrieving geotechnical
parameters from common proxy variables and then minimize a loss function with
respect to the available coseismic landside inventory. The results are very
promising, because our model not only produces excellent predictive performance
in the form of standard susceptibility output, but in the process, also
generates maps of the expected geotechnical properties at a regional scale.
Such architecture is therefore framed to tackle coseismic landslide prediction,
something that, if confirmed in other studies, could open up towards PINN-based
near-real-time predictions.

摘要：數十年來，區域規模的土石流預測解決方案大多依賴於資料驅動模型，根據定義，與破壞機制的物理性質無關。此類工具的成功和普及源於利用代理變數而非明確的岩土工程變數，因為後者在廣闊的景觀中難以獲取。我們的研究實作了物理資訊神經網路 (PINN) 方法，從而將標準資料驅動架構新增一個中間約束，以解決 Newmark 斜坡穩定性方法中典型的永久變形。這轉化為一個神經網路，負責從常見的代理變數中明確擷取岩土工程參數，然後針對可用的同震土石流清單最小化損失函數。結果非常有希望，因為我們的模型不僅以標準敏感性輸出形式產生出色的預測效能，而且在此過程中，還生成了區域規模預期岩土工程屬性的地圖。因此，此架構被設定為解決同震土石流預測，如果在其他研究中得到證實，這可能會開啟基於 PINN 的近乎即時預測。

##### **Fuzzy color model and clustering algorithm for color clustering problem**
2407.06782v1 by Dae-Won Kim, Kwang H. Lee

The research interest of this paper is focused on the efficient clustering
task for an arbitrary color data. In order to tackle this problem, we have
tried to model the inherent uncertainty and vagueness of color data using fuzzy
color model. By taking fuzzy approach to color modeling, we could make a soft
decision for the vague regions between neighboring colors. The proposed fuzzy
color model defined a three dimensional fuzzy color ball and color membership
computation method with two inter-color distances. With the fuzzy color model,
we developed a new fuzzy clustering algorithm for an efficient partition of
color data. Each fuzzy cluster set has a cluster prototype which is represented
by fuzzy color centroid.

摘要：本論文的研究重點在於任意色彩資料的有效分群任務。為了解決此問題，我們嘗試使用模糊色彩模型來模擬色彩資料的固有不確定性和模糊性。透過採用模糊方法進行色彩建模，我們可以對鄰近色彩之間的模糊區域做出軟性決策。所提出的模糊色彩模型定義了一個三維模糊色彩球和色彩成員資格運算方法，其中包含兩個色彩間距離。透過模糊色彩模型，我們開發了一種新的模糊分群演算法，用於有效分割色彩資料。每個模糊分群集都有一個分群原型，由模糊色彩質心表示。

##### **Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions**
2407.06779v1 by Wenxin Zhou, Thuy Hang Ngo

Our team participated in the BioASQ 2024 Task12b and Synergy tasks to build a
system that can answer biomedical questions by retrieving relevant articles and
snippets from the PubMed database and generating exact and ideal answers. We
propose a two-level information retrieval and question-answering system based
on pre-trained large language models (LLM), focused on LLM prompt engineering
and response post-processing. We construct prompts with in-context few-shot
examples and utilize post-processing techniques like resampling and malformed
response detection. We compare the performance of various pre-trained LLM
models on this challenge, including Mixtral, OpenAI GPT and Llama2. Our
best-performing system achieved 0.14 MAP score on document retrieval, 0.05 MAP
score on snippet retrieval, 0.96 F1 score for yes/no questions, 0.38 MRR score
for factoid questions and 0.50 F1 score for list questions in Task 12b.

摘要：我們的團隊參與了 BioASQ 2024 Task12b 和 Synergy 任務，建立一個系統，透過擷取 PubMed 資料庫中的相關文章和摘要，並產生精確且理想的答案，來回答生物醫學問題。我們提出一個基於預先訓練的大語言模型 (LLM) 的雙層資訊檢索和問答系統，專注於 LLM 提示工程和回應後處理。我們使用脈絡中的少次範例來建構提示，並利用重新取樣和畸形回應偵測等後處理技術。我們比較各種預先訓練的 LLM 模型在這個挑戰中的效能，包括 Mixtral、OpenAI GPT 和 Llama2。我們效能最佳的系統在文件檢索中達到 0.14 MAP 分數，在摘要檢索中達到 0.05 MAP 分數，在是非題中達到 0.96 F1 分數，在事實題中達到 0.38 MRR 分數，在 Task 12b 的列表題中達到 0.50 F1 分數。

##### **A BERT-based Empirical Study of Privacy Policies' Compliance with GDPR**
2407.06778v1 by Lu Zhang, Nabil Moukafih, Hamad Alamri, Gregory Epiphaniou, Carsten Maple

Since its implementation in May 2018, the General Data Protection Regulation
(GDPR) has prompted businesses to revisit and revise their data handling
practices to ensure compliance. The privacy policy, which serves as the primary
means of informing users about their privacy rights and the data practices of
companies, has been significantly updated by numerous businesses post-GDPR
implementation. However, many privacy policies remain packed with technical
jargon, lengthy explanations, and vague descriptions of data practices and user
rights. This makes it a challenging task for users and regulatory authorities
to manually verify the GDPR compliance of these privacy policies. In this
study, we aim to address the challenge of compliance analysis between GDPR
(Article 13) and privacy policies for 5G networks. We manually collected
privacy policies from almost 70 different 5G MNOs, and we utilized an automated
BERT-based model for classification. We show that an encouraging 51$\%$ of
companies demonstrate a strong adherence to GDPR. In addition, we present the
first study that provides current empirical evidence on the readability of
privacy policies for 5G network. we adopted readability analysis toolset that
incorporates various established readability metrics. The findings empirically
show that the readability of the majority of current privacy policies remains a
significant challenge. Hence, 5G providers need to invest considerable effort
into revising these documents to enhance both their utility and the overall
user experience.

摘要：自 2018 年 5 月實施以來，一般資料保護規範 (GDPR) 已促使企業重新檢視並修改其資料處理實務，以確保合規性。在 GDPR 實施後，許多企業已大幅更新隱私權政策，此政策作為告知使用者其隱私權利和公司資料實務的主要方式。然而，許多隱私權政策仍充斥著技術術語、冗長的說明和對資料實務和使用者權利的模糊描述。這使得使用者和監管機關難以手動驗證這些隱私權政策的 GDPR 合規性。在本研究中，我們旨在解決 GDPR（第 13 條）和 5G 網路的隱私權政策之間的合規性分析挑戰。我們手動收集了來自近 70 家不同的 5G MNO 的隱私權政策，並利用基於 BERT 的自動化模型進行分類。我們證明，51% 的公司表現出強烈遵守 GDPR。此外，我們提出了第一個針對 5G 網路隱私權政策的可讀性提供當前實證證據的研究。我們採用了包含各種既定可讀性指標的可讀性分析工具組。研究結果實證顯示，當前大多數隱私權政策的可讀性仍然是一項重大挑戰。因此，5G 供應商需要投入相當大的精力來修改這些文件，以提高其效用和整體使用者體驗。

##### **Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions**
2407.06762v1 by Matteo Bortoletto, Constantin Ruhdorfer, Lei Shi, Andreas Bulling

We propose MToMnet - a Theory of Mind (ToM) neural network for predicting
beliefs and their dynamics during human social interactions from multimodal
input. ToM is key for effective nonverbal human communication and
collaboration, yet, existing methods for belief modelling have not included
explicit ToM modelling or have typically been limited to one or two modalities.
MToMnet encodes contextual cues (scene videos and object locations) and
integrates them with person-specific cues (human gaze and body language) in a
separate MindNet for each person. Inspired by prior research on social
cognition and computational ToM, we propose three different MToMnet variants:
two involving fusion of latent representations and one involving re-ranking of
classification scores. We evaluate our approach on two challenging real-world
datasets, one focusing on belief prediction, while the other examining belief
dynamics prediction. Our results demonstrate that MToMnet surpasses existing
methods by a large margin while at the same time requiring a significantly
smaller number of parameters. Taken together, our method opens up a highly
promising direction for future work on artificial intelligent systems that can
robustly predict human beliefs from their non-verbal behaviour and, as such,
more effectively collaborate with humans.

摘要：我們提出 MToMnet - 一種心智理論 (ToM) 神經網路，用於根據多模式輸入預測人類社會互動期間的信念及其動態。ToM 是有效的人類非語言溝通和協作的關鍵，然而，現有的信念建模方法尚未包含明確的 ToM 建模，或者通常僅限於一或兩種模式。MToMnet 對背景線索（場景影片和物件位置）進行編碼，並將其與特定於個人的線索（人類注視和肢體語言）整合到每個人物的獨立 MindNet 中。受到先前關於社會認知和計算 ToM 的研究啟發，我們提出了三種不同的 MToMnet 變體：兩種涉及潛在表徵的融合，一種涉及分類分數的重新排名。我們在兩個具有挑戰性的真實世界資料集上評估我們的做法，一個專注於信念預測，而另一個則檢驗信念動態預測。我們的結果表明，MToMnet 在很大程度上超越了現有方法，同時需要顯著更少數量的參數。綜上所述，我們的做法為未來的人工智慧系統的工作開啟了一個極具前景的方向，這些系統可以根據人類的非語言行為穩健地預測人類信念，因此可以更有效地與人類合作。

##### **Threats and Defenses in Federated Learning Life Cycle: A Comprehensive Survey and Challenges**
2407.06754v1 by Yanli Li, Jifei Hu, Zhongliang Guo, Nan Yang, Huaming Chen, Dong Yuan, Weiping Ding

Federated Learning (FL) offers innovative solutions for privacy-preserving
collaborative machine learning (ML). Despite its promising potential, FL is
vulnerable to various attacks due to its distributed nature, affecting the
entire life cycle of FL services. These threats can harm the model's utility or
compromise participants' privacy, either directly or indirectly. In response,
numerous defense frameworks have been proposed, demonstrating effectiveness in
specific settings and scenarios. To provide a clear understanding of the
current research landscape, this paper reviews the most representative and
state-of-the-art threats and defense frameworks throughout the FL service life
cycle. We start by identifying FL threats that harm utility and privacy,
including those with potential or direct impacts. Then, we dive into the
defense frameworks, analyze the relationship between threats and defenses, and
compare the trade-offs among different defense strategies. Finally, we
summarize current research bottlenecks and offer insights into future research
directions to conclude this survey. We hope this survey sheds light on
trustworthy FL research and contributes to the FL community.

摘要：聯邦學習 (FL) 為注重隱私的協作機器學習 (ML) 提供創新解決方案。儘管 FL 具有令人期待的潛力，但由於其分散式特性，它容易受到各種攻擊，影響 FL 服務的整個生命週期。這些威脅可能會直接或間接損害模型的效用或危害參與者的隱私。為了解決這個問題，已經提出了許多防禦架構，證明了在特定設定和情境中的有效性。為了清楚了解當前的研究現況，本文回顧了整個 FL 服務生命週期中最具代表性和最先進的威脅和防禦架構。我們首先找出會損害效用和隱私的 FL 威脅，包括具有潛在或直接影響的威脅。接著，我們深入探討防禦架構，分析威脅和防禦之間的關係，並比較不同防禦策略之間的取捨。最後，我們總結目前的瓶頸，並提供對未來研究方向的見解，作為本調查的結論。我們希望這項調查能為值得信賴的 FL 研究帶來啟發，並對 FL 社群有所貢獻。

##### **Positive-Unlabelled Learning for Improving Image-based Recommender System Explainability**
2407.06740v1 by Álvaro Fernández-Campa-González, Jorge Paz-Ruza, Amparo Alonso-Betanzos, Bertha Guijarro-Berdiñas

Among the existing approaches for visual-based Recommender System (RS)
explainability, utilizing user-uploaded item images as efficient, trustable
explanations is a promising option. However, current models following this
paradigm assume that, for any user, all images uploaded by other users can be
considered negative training examples (i.e. bad explanatory images), an
inadvertedly naive labelling assumption that contradicts the rationale of the
approach. This work proposes a new explainer training pipeline by leveraging
Positive-Unlabelled (PU) Learning techniques to train image-based explainer
with refined subsets of reliable negative examples for each user selected
through a novel user-personalized, two-step, similarity-based PU Learning
algorithm. Computational experiments show this PU-based approach outperforms
the state-of-the-art non-PU method in six popular real-world datasets, proving
that an improvement of visual-based RS explainability can be achieved by
maximizing training data quality rather than increasing model complexity.

摘要：在基於視覺的推薦系統 (RS) 可解釋性現有方法中，利用使用者上傳的商品圖片作為有效且可信賴的解釋，是一個有前景的選擇。然而，遵循此範例的現有模型假設，對於任何使用者而言，其他使用者上傳的所有圖片都可以視為負面訓練範例（即不良的說明性圖片），這是一個無意間天真的標籤假設，與此方法的基本原理相矛盾。本研究提出了新的說明器訓練流程，透過利用正未標籤 (PU) 學習技術來訓練基於圖片的說明器，並透過新穎的使用者個人化、兩步驟、基於相似度的 PU 學習演算法，為每個使用者挑選可靠的負面範例的精緻子集。計算實驗顯示，此基於 PU 的方法在六個流行的真實世界資料集中優於最先進的非 PU 方法，證明透過最大化訓練資料品質，而非增加模型複雜度，可以提升基於視覺的 RS 可解釋性。

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

摘要：<paragraph>人類使用簡單的文字描述，豐富的連結和關係，來描述複雜的場景。雖然視覺語言的研究旨在開發具有組合理解能力的模型，但現有的數據集尚未反映這一點，這些數據集在很大程度上仍使用純文本來描述圖像。在這項工作中，我們提出了一種新的註釋策略，基於圖表的標題 (GBC)，它使用標籤圖表結構來描述圖像，其中包含各種類型的節點。GBC 中的節點是使用物體檢測和密集標題工具在第一階段創建的，以遞迴嵌套的方式發現和描述實體節點，並在第二階段使用新類型的節點突出顯示，從而將它們進一步連結在一起，實體之間的組合和關係。由於所有 GBC 節點都包含純文本描述，因此 GBC 保留了自然語言中的靈活性，但也可以在其邊緣編碼分層信息。我們證明了 GBC 可以使用現成的多模態 LLM 和開放詞彙檢測模型自動生成，通過構建一個新的數據集 GBC10M，收集了大約 10M CC12M 數據集圖像的 GBC 註釋。我們使用 GBC10M 來展示 GBC 發現的豐富節點標題，並使用 CLIP 訓練進行測量。我們表明，與其他數據集格式相比，使用 GBC 節點的註釋——特別是存儲在組合和關係節點中的註釋——會顯著提升下游模型的性能。為了進一步探索 GBC 提供的機會，我們還提出了一種新的注意機制，它可以利用整個 GBC 圖表，並通過鼓勵性的實驗結果展示了結合圖表結構的額外好處。我們的數據集發布在 \url{https://huggingface.co/graph-based-captions}。</paragraph>

##### **A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts**
2407.06718v1 by Atilla Özgür, Yılmaz Uygun

This study proposes a simple architecture for Enterprise application for
Large Language Models (LLMs) for role based security and NATO clearance levels.
Our proposal aims to address the limitations of current LLMs in handling
security and information access. The proposed architecture could be used while
utilizing Retrieval-Augmented Generation (RAG) and fine tuning of Mixture of
experts models (MoE). It could be used only with RAG, or only with MoE or with
both of them. Using roles and security clearance level of the user, documents
in RAG and experts in MoE are filtered. This way information leakage is
prevented.

摘要：本研究提出了一個大型語言模型 (LLM) 企業應用程式簡單架構，用於基於角色的安全性與北約許可權等級。
我們的提案旨在解決現有 LLM 在處理安全性與資訊存取上的限制。建議的架構可在使用檢索增強生成 (RAG) 和微調專家模型混合 (MoE) 時使用。它僅可與 RAG 或僅與 MoE 或同時與兩者一起使用。使用使用者的角色和安全許可權等級，會過濾 RAG 中的文件和 MoE 中的專家。這樣可以防止資訊外洩。

##### **Consistent Document-Level Relation Extraction via Counterfactuals**
2407.06699v1 by Ali Modarressi, Abdullatif Köksal, Hinrich Schütze

Many datasets have been developed to train and evaluate document-level
relation extraction (RE) models. Most of these are constructed using real-world
data. It has been shown that RE models trained on real-world data suffer from
factual biases. To evaluate and address this issue, we present CovEReD, a
counterfactual data generation approach for document-level relation extraction
datasets using entity replacement. We first demonstrate that models trained on
factual data exhibit inconsistent behavior: while they accurately extract
triples from factual data, they fail to extract the same triples after
counterfactual modification. This inconsistency suggests that models trained on
factual data rely on spurious signals such as specific entities and external
knowledge $\unicode{x2013}$ rather than on the input context $\unicode{x2013}$
to extract triples. We show that by generating document-level counterfactual
data with CovEReD and training models on them, consistency is maintained with
minimal impact on RE performance. We release our CovEReD pipeline as well as
Re-DocRED-CF, a dataset of counterfactual RE documents, to assist in evaluating
and addressing inconsistency in document-level RE.

摘要：許多資料集已被開發用於訓練和評估文件層級關係萃取 (RE) 模型。其中大多數是使用真實世界資料建構的。已顯示訓練於真實世界資料的 RE 模型會受到事實偏誤的影響。為了評估和解決這個問題，我們提出 CovEReD，這是一種用於文件層級關係萃取資料集的對事實資料生成方法，使用實體替換。我們首先證明訓練於事實資料的模型表現出不一致的行為：雖然它們準確地從事實資料萃取三元組，但在對事實進行修改後，它們無法萃取相同的元組。這種不一致性表明訓練於事實資料的模型依賴於虛假訊號，例如特定實體和外部知識 $\unicode{x2013}$ 而不是輸入內容 $\unicode{x2013}$ 來萃取三元組。我們表明，透過使用 CovEReD 生成文件層級對事實資料，並在它們上訓練模型，可以維持一致性，且對 RE 效能的影響很小。我們發布我們的 CovEReD 管線，以及 Re-DocRED-CF，一個對事實 RE 文件的資料集，以協助評估和解決文件層級 RE 中的不一致性。

##### **Deep-Motion-Net: GNN-based volumetric organ shape reconstruction from single-view 2D projections**
2407.06692v1 by Isuru Wijesinghe, Michael Nix, Arezoo Zakeri, Alireza Hokmabadi, Bashar Al-Qaisieh, Ali Gooya, Zeike A. Taylor

We propose Deep-Motion-Net: an end-to-end graph neural network (GNN)
architecture that enables 3D (volumetric) organ shape reconstruction from a
single in-treatment kV planar X-ray image acquired at any arbitrary projection
angle. Estimating and compensating for true anatomical motion during
radiotherapy is essential for improving the delivery of planned radiation dose
to target volumes while sparing organs-at-risk, and thereby improving the
therapeutic ratio. Achieving this using only limited imaging available during
irradiation and without the use of surrogate signals or invasive fiducial
markers is attractive. The proposed model learns the mesh regression from a
patient-specific template and deep features extracted from kV images at
arbitrary projection angles. A 2D-CNN encoder extracts image features, and four
feature pooling networks fuse these features to the 3D template organ mesh. A
ResNet-based graph attention network then deforms the feature-encoded mesh. The
model is trained using synthetically generated organ motion instances and
corresponding kV images. The latter is generated by deforming a reference CT
volume aligned with the template mesh, creating digitally reconstructed
radiographs (DRRs) at required projection angles, and DRR-to-kV style
transferring with a conditional CycleGAN model. The overall framework was
tested quantitatively on synthetic respiratory motion scenarios and
qualitatively on in-treatment images acquired over full scan series for liver
cancer patients. Overall mean prediction errors for synthetic motion test
datasets were 0.16$\pm$0.13 mm, 0.18$\pm$0.19 mm, 0.22$\pm$0.34 mm, and
0.12$\pm$0.11 mm. Mean peak prediction errors were 1.39 mm, 1.99 mm, 3.29 mm,
and 1.16 mm.

摘要：<paragraph>我們提出了 Deep-Motion-Net：一種端到端圖形神經網路 (GNN) 架構，它能從任意投影角度取得的單一治療中 kV 平面 X 光影像重建 3D（體積）器官形狀。在放射治療期間估計和補償真正的解剖運動對於改善將計畫的放射劑量傳遞到目標體積，同時保護風險器官，進而改善治療比率至關重要。僅使用在放射過程中可用的有限影像，且不使用替代訊號或侵入性標記，就能達成此目標，這是很有吸引力的。所提出的模型從特定於患者的範本和從 kV 影像中提取的深度特徵學習網格回歸。2D-CNN 編碼器提取影像特徵，而四個特徵池化網路將這些特徵融合到 3D 範本器官網格中。然後，基於 ResNet 的圖形注意力網路會變形特徵編碼網格。該模型使用合成產生的器官運動實例和對應的 kV 影像進行訓練。後者是透過變形與範本網格對齊的參考 CT 體積，在所需的投影角度建立數位重建放射線照片 (DRR)，並使用條件式 CycleGAN 模型將 DRR 轉換為 kV 樣式。整體架構在合成的呼吸運動場景中經過量化測試，並在肝癌患者的完整掃描系列中獲得的治療中影像中進行質化測試。合成運動測試資料集的整體平均預測誤差為 0.16$\pm$0.13 mm、0.18$\pm$0.19 mm、0.22$\pm$0.34 mm 和 0.12$\pm$0.11 mm。平均峰值預測誤差為 1.39 mm、1.99 mm、3.29 mm 和 1.16 mm。</paragraph>

##### **A Predictive Model Based on Transformer with Statistical Feature Embedding in Manufacturing Sensor Dataset**
2407.06682v1 by Gyeong Taek Lee, Oh-Ran Kwon

In the manufacturing process, sensor data collected from equipment is crucial
for building predictive models to manage processes and improve productivity.
However, in the field, it is challenging to gather sufficient data to build
robust models. This study proposes a novel predictive model based on the
Transformer, utilizing statistical feature embedding and window positional
encoding. Statistical features provide an effective representation of sensor
data, and the embedding enables the Transformer to learn both time- and
sensor-related information. Window positional encoding captures precise time
details from the feature embedding. The model's performance is evaluated in two
problems: fault detection and virtual metrology, showing superior results
compared to baseline models. This improvement is attributed to the efficient
use of parameters, which is particularly beneficial for sensor data that often
has limited sample sizes. The results support the model's applicability across
various manufacturing industries, demonstrating its potential for enhancing
process management and yield.

摘要：在製造過程中，從設備收集的感測器資料對於建立預測模型以管理流程和提升生產力至關重要。
然而，在實際應用中，要收集足夠的資料來建立穩健的模型是一項挑戰。本研究提出了一個基於 Transformer 的創新預測模型，利用統計特徵嵌入和視窗位置編碼。統計特徵提供了感測器資料的有效表示，而嵌入使 Transformer 能同時學習時間和感測器相關的資訊。視窗位置編碼從特徵嵌入中擷取精確的時間資訊。該模型的效能已在兩個問題中得到評估：故障偵測和虛擬量測，與基準模型相比，顯示出優異的結果。這種改進歸功於參數的有效使用，這對於經常有樣本數限制的感測器資料特別有益。結果支持了該模型在各種製造產業中的適用性，證明了它在增強流程管理和良率方面的潛力。

##### **TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification**
2407.06658v1 by Md Abrar Jahin, M. F. Mridha, Zeyar Aung, Nilanjan Dey, R. Simon Sherratt

Geomagnetic storms, caused by solar wind energy transfer to Earth's magnetic
field, can disrupt critical infrastructure like GPS, satellite communications,
and power grids. The disturbance storm-time (Dst) index measures storm
intensity. Despite advancements in empirical, physics-based, and
machine-learning models using real-time solar wind data, accurately forecasting
extreme geomagnetic events remains challenging due to noise and sensor
failures. This research introduces TriQXNet, a novel hybrid classical-quantum
neural network for Dst forecasting. Our model integrates classical and quantum
computing, conformal prediction, and explainable AI (XAI) within a hybrid
architecture. To ensure high-quality input data, we developed a comprehensive
preprocessing pipeline that included feature selection, normalization,
aggregation, and imputation. TriQXNet processes preprocessed solar wind data
from NASA's ACE and NOAA's DSCOVR satellites, predicting the Dst index for the
current hour and the next, providing vital advance notice to mitigate
geomagnetic storm impacts. TriQXNet outperforms 13 state-of-the-art hybrid
deep-learning models, achieving a root mean squared error of 9.27 nanoteslas
(nT). Rigorous evaluation through 10-fold cross-validated paired t-tests
confirmed its superior performance with 95% confidence. Conformal prediction
techniques provide quantifiable uncertainty, which is essential for operational
decisions, while XAI methods like ShapTime enhance interpretability.
Comparative analysis shows TriQXNet's superior forecasting accuracy, setting a
new level of expectations for geomagnetic storm prediction and highlighting the
potential of classical-quantum hybrid models in space weather forecasting.

摘要：地磁風暴是由太陽風能量傳遞至地球磁場所造成，可能會中斷 GPS、衛星通訊和電網等關鍵基礎設施。擾動風暴時間 (Dst) 指數用於測量風暴強度。儘管已經在使用即時太陽風資料的經驗、基於物理的和機器學習模型方面取得進展，但由於雜訊和感測器故障，精確預測極端地磁事件仍然具有挑戰性。本研究引入了 TriQXNet，這是一種用於 Dst 預測的新型混合古典量子神經網路。我們的模型在混合架構中整合了古典和量子運算、共形預測和可解釋 AI (XAI)。為了確保高品質的輸入資料，我們開發了一個全面的預處理管道，其中包括特徵選擇、正規化、聚合和估計。TriQXNet 處理來自 NASA 的 ACE 和 NOAA 的 DSCOVR 衛星的預處理太陽風資料，預測當前小時和下一個小時的 Dst 指數，提供重要的預先通知以減輕地磁風暴影響。TriQXNet 優於 13 種最先進的混合深度學習模型，均方根誤差達到 9.27 納特斯拉 (nT)。透過 10 倍交叉驗證配對 t 檢定進行的嚴格評估，以 95% 的信心確認其優異的效能。共形預測技術提供可量化的不確定性，這對於運作決策至關重要，而像 ShapTime 這樣的 XAI 方法則增強了可解釋性。比較分析顯示 TriQXNet 優異的預測準確度，為地磁風暴預測設定了新的期望水準，並突顯了古典量子混合模型在太空天氣預測中的潛力。

##### **SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training**
2407.06654v1 by Nan He, Weichen Xiong, Hanwen Liu, Yi Liao, Lei Ding, Kai Zhang, Guohua Tang, Xiao Han, Wei Yang

The effectiveness of large language models (LLMs) is often hindered by
duplicated data in their extensive pre-training datasets. Current approaches
primarily focus on detecting and removing duplicates, which risks the loss of
valuable information and neglects the varying degrees of duplication. To
address this, we propose a soft deduplication method that maintains dataset
integrity while selectively reducing the sampling weight of data with high
commonness. Central to our approach is the concept of "data commonness", a
metric we introduce to quantify the degree of duplication by measuring the
occurrence probabilities of samples using an n-gram model. Empirical analysis
shows that this method significantly improves training efficiency, achieving
comparable perplexity scores with at least a 26% reduction in required training
steps. Additionally, it enhances average few-shot downstream accuracy by 1.77%
when trained for an equivalent duration. Importantly, this approach
consistently improves performance, even on rigorously deduplicated datasets,
indicating its potential to complement existing methods and become a standard
pre-training process for LLMs.

摘要：大型語言模型 (LLM) 的效率通常會受到其廣泛預訓練資料集中的重複資料所影響。目前的做法主要著重於偵測並移除重複資料，這有遺失珍貴資訊的風險，而且忽略了不同程度的重複。為了解決這個問題，我們提出一個軟去重方法，它在維持資料集完整性的同時，選擇性地降低高度重複資料的抽樣權重。我們做法的核心是「資料重複性」的概念，我們引入了一個指標來量化重複程度，方法是使用 n-gram 模型來測量樣本的出現機率。實證分析顯示，這個方法顯著地提升了訓練效率，在所需的訓練步驟減少至少 26% 的情況下，達到了可比較的困惑度分數。此外，當訓練時間相當時，它將平均少次數 downstream 的準確度提升了 1.77%。重要的是，這個方法持續提升效能，即使是在經過嚴格去重的資料集上，這表示它有潛力補充現有方法，並成為 LLM 的標準預訓練程序。

##### **A Word Order Synchronization Metric for Evaluating Simultaneous Interpretation and Translation**
2407.06650v1 by Mana Makinae, Katsuhito Sudoh, Mararu Yamada, Satoshi Nakamura

Simultaneous interpretation (SI), the translation of one language to another
in real time, starts translation before the original speech has finished. Its
evaluation needs to consider both latency and quality. This trade-off is
challenging especially for distant word order language pairs such as English
and Japanese. To handle this word order gap, interpreters maintain the word
order of the source language as much as possible to keep up with original
language to minimize its latency while maintaining its quality, whereas in
translation reordering happens to keep fluency in the target language. This
means outputs synchronized with the source language are desirable based on the
real SI situation, and it's a key for further progress in computational SI and
simultaneous machine translation (SiMT). In this work, we propose an automatic
evaluation metric for SI and SiMT focusing on word order synchronization. Our
evaluation metric is based on rank correlation coefficients, leveraging
cross-lingual pre-trained language models. Our experimental results on
NAIST-SIC-Aligned and JNPC showed our metrics' effectiveness to measure word
order synchronization between source and target language.

摘要：同聲傳譯（SI）是將一種語言即時翻譯成另一種語言，在原始演講結束前就開始翻譯。其評估需要同時考慮延遲和品質。這種取捨對英語和日語等語序不同的語言對來說尤其具有挑戰性。為了處理這種語序差異，口譯員盡可能維持原始語言的語序，以跟上原始語言，同時維持品質，以將延遲降到最低；而翻譯則會重新排序，以維持目標語言的流暢性。這表示，基於實際的同聲傳譯情況，與原始語言同步的輸出是理想的，並且是進一步進展到計算同聲傳譯（SiMT）和同時機器翻譯（SiMT）的關鍵。在這項工作中，我們提出一個自動評量指標，用於評估同聲傳譯和同時機器翻譯，重點在於語序同步。我們的評量指標基於等級相關係數，利用跨語言預訓練的語言模型。我們在 NAIST-SIC-Aligned 和 JNPC 上的實驗結果顯示，我們的指標在衡量原始語言和目標語言之間的語序同步方面非常有效。

##### **Entropy Law: The Story Behind Data Compression and LLM Performance**
2407.06645v1 by Mingjia Yin, Chuhan Wu, Yufei Wang, Hao Wang, Wei Guo, Yasheng Wang, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen

Data is the cornerstone of large language models (LLMs), but not all data is
useful for model learning. Carefully selected data can better elicit the
capabilities of LLMs with much less computational overhead. Most methods
concentrate on evaluating the quality of individual samples in data selection,
while the combinatorial effects among samples are neglected. Even if each
sample is of perfect quality, their combinations may be suboptimal in teaching
LLMs due to their intrinsic homogeneity or contradiction. In this paper, we aim
to uncover the underlying relationships between LLM performance and data
selection. Inspired by the information compression nature of LLMs, we uncover
an ``entropy law'' that connects LLM performance with data compression ratio
and first-epoch training loss, which reflect the information redundancy of a
dataset and the mastery of inherent knowledge encoded in this dataset,
respectively. Through both theoretical deduction and empirical evaluation, we
find that model performance is negatively correlated to the compression ratio
of training data, which usually yields a lower training loss. Based on the
findings of the entropy law, we propose a quite efficient and universal data
selection method named \textbf{ZIP} for training LLMs, which aim to prioritize
data subsets exhibiting a low compression ratio. Based on a multi-stage
algorithm that selects diverse data in a greedy manner, we can obtain a good
data subset with satisfactory diversity. Extensive experiments have been
conducted to validate the entropy law and the superiority of ZIP across
different LLM backbones and alignment stages. We also present an interesting
application of entropy law that can detect potential performance risks at the
beginning of model training.

摘要：<paragraph>資料是大語言模型 (LLM) 的基石，但並非所有資料都對模型學習有幫助。仔細挑選的資料能以更少的運算開銷，更好地引發 LLM 的功能。大多數方法專注於評估資料選擇中個別範例的品質，而範例之間的組合效應則被忽略。即使每個範例的品質都完美無缺，它們的組合可能由於其內在的同質性或矛盾性，而無法以次佳的方式來訓練 LLM。在本文中，我們旨在揭示 LLM 效能與資料選擇之間的潛在關係。受到 LLM 的資訊壓縮特性的啟發，我們揭示了一個「熵律」，它將 LLM 效能與資料壓縮率和第一個時期的訓練損失聯繫起來，它們分別反映了資料集的資訊冗餘和對編碼在該資料集中固有知識的掌握。透過理論推論和經驗評估，我們發現模型效能與訓練資料的壓縮率呈負相關，這通常會產生較低的訓練損失。根據熵律的發現，我們提出了一個相當有效且通用的資料選擇方法，稱為 \textbf{ZIP}，用於訓練 LLM，其目標是優先處理表現出低壓縮率的資料子集。基於一個以貪婪的方式選擇多樣化資料的多階段演算法，我們可以獲得一個具有令人滿意多樣性的良好資料子集。已經進行了廣泛的實驗來驗證熵律和 ZIP 在不同 LLM 主幹和比對階段的優越性。我們還展示了熵律的一個有趣的應用，它可以在模型訓練開始時檢測潛在的效能風險。</paragraph>

##### **Reasoning about unpredicted change and explicit time**
2407.06622v1 by Florence Dupin de Saint-Cyr, Jérôme Lang

Reasoning about unpredicted change consists in explaining observations by
events; we propose here an approach for explaining time-stamped observations by
surprises, which are simple events consisting in the change of the truth value
of a fluent. A framework for dealing with surprises is defined. Minimal sets of
surprises are provided together with time intervals where each surprise has
occurred, and they are characterized from a model-based diagnosis point of
view. Then, a probabilistic approach of surprise minimisation is proposed.

摘要：推理未預測的變化包括以事件解釋觀察結果；我們在此提出一個方法，以驚奇來解釋帶時間戳記的觀察結果，而驚奇是簡單的事件，包括流暢的真值變化。定義了一個處理驚奇的框架。提供了驚奇的最小集合以及每個驚奇發生的時間間隔，並從基於模型的診斷觀點對它們進行了表徵。然後，提出了一個驚奇最小化的概率方法。

##### **CEIA: CLIP-Based Event-Image Alignment for Open-World Event-Based Understanding**
2407.06611v1 by Wenhao Xu, Wenming Weng, Yueyi Zhang, Zhiwei Xiong

We present CEIA, an effective framework for open-world event-based
understanding. Currently training a large event-text model still poses a huge
challenge due to the shortage of paired event-text data. In response to this
challenge, CEIA learns to align event and image data as an alternative instead
of directly aligning event and text data. Specifically, we leverage the rich
event-image datasets to learn an event embedding space aligned with the image
space of CLIP through contrastive learning. In this way, event and text data
are naturally aligned via using image data as a bridge. Particularly, CEIA
offers two distinct advantages. First, it allows us to take full advantage of
the existing event-image datasets to make up the shortage of large-scale
event-text datasets. Second, leveraging more training data, it also exhibits
the flexibility to boost performance, ensuring scalable capability. In
highlighting the versatility of our framework, we make extensive evaluations
through a diverse range of event-based multi-modal applications, such as object
recognition, event-image retrieval, event-text retrieval, and domain
adaptation. The outcomes demonstrate CEIA's distinct zero-shot superiority over
existing methods on these applications.

摘要：我們提出 CEIA，一個開放世界事件為基礎理解的有效框架。目前訓練一個大型事件文字模型仍然是一個巨大的挑戰，因為配對的事件文字資料短缺。為了應對這個挑戰，CEIA 學習將事件和影像資料對齊作為一種替代方案，而不是直接對齊事件和文字資料。具體來說，我們利用豐富的事件影像資料集，透過對比學習，學習一個與 CLIP 影像空間對齊的事件嵌入空間。以這種方式，事件和文字資料透過使用影像資料作為橋樑而自然對齊。特別是，CEIA 提供了兩個顯著的優點。首先，它讓我們能夠充分利用現有的事件影像資料集，以彌補大規模事件文字資料集的不足。其次，利用更多的訓練資料，它也展現了提升效能的靈活性，確保可擴充的能力。為了強調我們框架的多功能性，我們透過各種不同的事件為基礎多模態應用程式進行廣泛的評估，例如物件辨識、事件影像檢索、事件文字檢索和領域適應。結果證明 CEIA 在這些應用程式上比現有方法具有顯著的零次學習優勢。

##### **Tailored Design of Audio-Visual Speech Recognition Models using Branchformers**
2407.06606v1 by David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos

Recent advances in Audio-Visual Speech Recognition (AVSR) have led to
unprecedented achievements in the field, improving the robustness of this type
of system in adverse, noisy environments. In most cases, this task has been
addressed through the design of models composed of two independent encoders,
each dedicated to a specific modality. However, while recent works have
explored unified audio-visual encoders, determining the optimal cross-modal
architecture remains an ongoing challenge. Furthermore, such approaches often
rely on models comprising vast amounts of parameters and high computational
cost training processes. In this paper, we aim to bridge this research gap by
introducing a novel audio-visual framework. Our proposed method constitutes, to
the best of our knowledge, the first attempt to harness the flexibility and
interpretability offered by encoder architectures, such as the Branchformer, in
the design of parameter-efficient AVSR systems. To be more precise, the
proposed framework consists of two steps: first, estimating audio- and
video-only systems, and then designing a tailored audio-visual unified encoder
based on the layer-level branch scores provided by the modality-specific
models. Extensive experiments on English and Spanish AVSR benchmarks covering
multiple data conditions and scenarios demonstrated the effectiveness of our
proposed method. Results reflect how our tailored AVSR system is able to reach
state-of-the-art recognition rates while significantly reducing the model
complexity w.r.t. the prevalent approach in the field. Code and pre-trained
models are available at https://github.com/david-gimeno/tailored-avsr.

摘要：<paragraph>最近在視覺聽覺語音辨識 (AVSR) 的進展已在該領域中帶來空前的成就，改善了此類型系統在不利、吵雜環境中的穩健性。在多數情況下，此任務已透過設計由兩個獨立編碼器組成的模型來處理，每個編碼器專門處理特定模式。然而，儘管最近的研究已探討統一的視覺聽覺編碼器，但確定最佳的跨模式架構仍然是持續的挑戰。此外，此類方法通常依賴包含大量參數和高運算成本訓練程序的模型。在本文中，我們旨在透過引進一個新穎的視覺聽覺架構來彌合此研究差距。據我們所知，我們提出的方法構成首次嘗試利用編碼器架構（例如 Branchformer）提供的靈活性與可解釋性，來設計參數有效率的 AVSR 系統。更精確地說，提出的架構包含兩個步驟：首先，估計僅音訊和僅視訊的系統，然後根據特定於模式的模型提供的層級分支分數設計一個量身打造的視覺聽覺統一編碼器。在涵蓋多種資料條件和場景的英文和西班牙文 AVSR 基準上進行的廣泛實驗證明了我們提出的方法的有效性。結果反映出我們量身打造的 AVSR 系統如何能夠達到最先進的辨識率，同時顯著降低模型複雜度，相較於該領域中普遍採用的方法而言。程式碼和預先訓練的模型可在 https://github.com/david-gimeno/tailored-avsr 取得。</paragraph>

##### **TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries**
2407.06597v1 by Renjie Liang, Li Li, Chongzhi Zhang, Jing Wang, Xizhou Zhu, Aixin Sun

In this paper, we propose the task of \textit{Ranked Video Moment Retrieval}
(RVMR) to locate a ranked list of matching moments from a collection of videos,
through queries in natural language. Although a few related tasks have been
proposed and studied by CV, NLP, and IR communities, RVMR is the task that best
reflects the practical setting of moment search. To facilitate research in
RVMR, we develop the TVR-Ranking dataset, based on the raw videos and existing
moment annotations provided in the TVR dataset. Our key contribution is the
manual annotation of relevance levels for 94,442 query-moment pairs. We then
develop the $NDCG@K, IoU\geq \mu$ evaluation metric for this new task and
conduct experiments to evaluate three baseline models. Our experiments show
that the new RVMR task brings new challenges to existing models and we believe
this new dataset contributes to the research on multi-modality search. The
dataset is available at \url{https://github.com/Ranking-VMR/TVR-Ranking}

摘要：<paragraph>在本文中，我們提出了\textit{排名影片時刻檢索}
(RVMR) 的任務，以透過自然語言查詢，從影片集合中找出排名清單的匹配時刻。儘管 CV、NLP 和 IR 社群已提出並研究了一些相關任務，但 RVMR 是最能反映時刻搜尋實務設定的任務。為了促進 RVMR 的研究，我們開發了 TVR-Ranking 資料集，該資料集基於 TVR 資料集中提供的原始影片和現有時刻註解。我們的關鍵貢獻是為 94,442 個查詢時刻對手動註解相關性等級。然後我們為這個新任務開發了 $NDCG@K, IoU\geq \mu$ 評估指標，並進行實驗以評估三個基準模型。我們的實驗顯示，新的 RVMR 任務為現有模型帶來了新的挑戰，我們相信這個新資料集有助於多模態搜尋的研究。該資料集可在 \url{https://github.com/Ranking-VMR/TVR-Ranking} 取得</paragraph>

##### **Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)**
2407.06590v1 by Yanlong Peng, Zhigang Wang, Yisheng Zhang, Shengmin Zhang, Nan Cai, Fan Wu, Ming Chen

The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs)
is crucial for green manufacturing and sustainable development. The current
pre-programmed disassembly conducted by the Autonomous Mobile Manipulator
Robot(AMMR) struggles to meet the disassembly requirements in dynamic
environments, complex scenarios, and unstructured processes. In this paper, we
propose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI.
It detects the environmental state by leveraging a combination of multi-sensors
and neural predicates and then translates this information into a
quasi-symbolic space. In real-time, it identifies the optimal sequence of
action primitives through LLM-heuristic tree search, ensuring high-precision
execution of these primitives. Additionally, it employs positional speculative
sampling using intuitive networks and achieves the disassembly of various bolt
types with a meticulously designed end-effector. Importantly, BEAM-1 is a
continuously learning embodied intelligence system capable of subjective
reasoning like a human, and possessing intuition. A large number of real scene
experiments have proved that it can autonomously perceive, decide, and execute
to complete the continuous disassembly of bolts in multiple, multi-category,
and complex situations, with a success rate of 98.78%. This research attempts
to use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and
learning capabilities. BEAM-1 realizes the revolution of battery disassembly.
Its framework can be easily ported to any robotic system to realize different
application scenarios, which provides a ground-breaking idea for the design and
implementation of future embodied intelligent robotic systems.

摘要：<paragraph>高效拆解报废电动汽车电池（EOL-EVB）对于绿色制造和可持续发展至关重要。当前由自主移动机械手机器人（AMMR）执行的预编程拆解难以满足动态环境、复杂场景和非结构化流程中的拆解要求。在本文中，我们提出了一种基于神经符号 AI 的电池拆解 AMMR（BEAM-1）系统。它通过利用多传感器和神经谓词的组合来检测环境状态，然后将此信息转换为准符号空间。在实时中，它通过 LLM 启发式树搜索识别出最佳的动作基元序列，确保这些基元的执行高精度。此外，它使用直觉网络采用位置推测采样，并使用精心设计的末端执行器实现各种螺栓类型的拆解。重要的是，BEAM-1 是一个持续学习的具身智能系统，能够像人类一样进行主观推理，并具有直觉。大量真实场景实验表明，它可以在多重、多类别和复杂的情况下自主感知、决策和执行，以完成螺栓的连续拆解，成功率为 98.78%。本研究尝试使用神经符号 AI 为机器人提供真正的自主推理、规划和学习能力。BEAM-1 实现了电池拆解的革命。其框架可以轻松移植到任何机器人系统中以实现不同的应用场景，这为未来具身智能机器人系统的设计和实现提供了突破性的思路。</paragraph>

##### **Vision language models are blind**
2407.06581v1 by Pooyan Rahmanzadehgervi, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen

Large language models with vision capabilities (VLMs), e.g., GPT-4o and
Gemini 1.5 Pro are powering countless image-text applications and scoring high
on many vision-understanding benchmarks. Yet, we find that VLMs fail on 7
visual tasks absurdly easy to humans such as identifying (a) whether two
circles overlap; (b) whether two lines intersect; (c) which letter is being
circled in a word; and (d) counting the number of circles in a Olympic-like
logo. The shockingly poor performance of four state-of-the-art VLMs suggests
their vision is, at best, like of a person with myopia seeing fine details as
blurry, and at worst, like an intelligent person that is blind making educated
guesses. Code is available at: https://vlmsareblind.github.io/

摘要：具有視覺功能的大型語言模型 (VLM)，例如 GPT-4o 和 Gemini 1.5 Pro，為無數的影像文字應用程式提供動力，並在許多視覺理解基準測試中獲得高分。然而，我們發現 VLM 在 7 項對人類來說非常容易的視覺任務上失敗，例如識別：(a) 兩個圓圈是否重疊；(b) 兩條線是否相交；(c) 一個單字中被圈起來的是哪個字母；以及 (d) 計算奧運會標誌中圓圈的數量。四種最先進的 VLM 令人震驚的糟糕表現表明，它們的視覺能力充其量就像一個近視的人看到模糊的細節，最壞的情況就像一個聰明但失明的瞎子做出有根據的猜測。程式碼可在以下網址取得：https://vlmsareblind.github.io/

##### **NoisyAG-News: A Benchmark for Addressing Instance-Dependent Noise in Text Classification**
2407.06579v1 by Hongfei Huang, Tingting Liang, Xixi Sun, Zikang Jin, Yuyu Yin

Existing research on learning with noisy labels predominantly focuses on
synthetic label noise. Although synthetic noise possesses well-defined
structural properties, it often fails to accurately replicate real-world noise
patterns. In recent years, there has been a concerted effort to construct
generalizable and controllable instance-dependent noise datasets for image
classification, significantly advancing the development of noise-robust
learning in this area. However, studies on noisy label learning for text
classification remain scarce. To better understand label noise in real-world
text classification settings, we constructed the benchmark dataset NoisyAG-News
through manual annotation. Initially, we analyzed the annotated data to gather
observations about real-world noise. We qualitatively and quantitatively
demonstrated that real-world noisy labels adhere to instance-dependent
patterns. Subsequently, we conducted comprehensive learning experiments on
NoisyAG-News and its corresponding synthetic noise datasets using pre-trained
language models and noise-handling techniques. Our findings reveal that while
pre-trained models are resilient to synthetic noise, they struggle against
instance-dependent noise, with samples of varying confusion levels showing
inconsistent performance during training and testing. These real-world noise
patterns pose new, significant challenges, prompting a reevaluation of noisy
label handling methods. We hope that NoisyAG-News will facilitate the
development and evaluation of future solutions for learning with noisy labels.

摘要：現有關於帶有雜訊標籤學習的研究主要集中在
合成的標籤雜訊上。儘管合成的雜訊具有明確的
結構屬性，但它常常無法準確複製真實世界的雜訊
模式。近年來，人們一直在努力構建
可概括和可控的與實例相關的雜訊資料集，用於影像
分類，大幅推進了此領域中抗雜訊
學習的發展。然而，關於用於文字
分類的雜訊標籤學習的研究仍然很少。為了更深入地了解真實世界
文字分類設定中的標籤雜訊，我們透過手動註解構建了基準資料集 NoisyAG-News。最初，我們分析了已註解的資料，以收集
關於真實世界雜訊的觀察結果。我們定性和定量
證明了真實世界的雜訊標籤遵循與實例相關的
模式。隨後，我們對
NoisyAG-News 及其對應的合成雜訊資料集進行了全面的學習實驗，使用預先訓練好的
語言模型和雜訊處理技術。我們的研究結果顯示，雖然
預先訓練好的模型具有合成雜訊的韌性，但它們在與實例相關的雜訊中會遇到困難，在訓練和測試期間，混淆程度不同的樣本顯示出不一致的效能。這些真實世界的雜訊
模式帶來了新的重大挑戰，促使重新評估雜訊
標籤處理方法。我們希望 NoisyAG-News 將有助於
開發和評估未來使用雜訊標籤進行學習的解決方案。

##### **Virtual Personas for Language Models via an Anthology of Backstories**
2407.06576v1 by Suhong Moon, Marwa Abdulhai, Minwoo Kang, Joseph Suh, Widyadewi Soedarmadji, Eran Kohen Behar, David M. Chan

Large language models (LLMs) are trained from vast repositories of text
authored by millions of distinct authors, reflecting an enormous diversity of
human traits. While these models bear the potential to be used as
approximations of human subjects in behavioral studies, prior efforts have been
limited in steering model responses to match individual human users. In this
work, we introduce "Anthology", a method for conditioning LLMs to particular
virtual personas by harnessing open-ended life narratives, which we refer to as
"backstories." We show that our methodology enhances the consistency and
reliability of experimental outcomes while ensuring better representation of
diverse sub-populations. Across three nationally representative human surveys
conducted as part of Pew Research Center's American Trends Panel (ATP), we
demonstrate that Anthology achieves up to 18% improvement in matching the
response distributions of human respondents and 27% improvement in consistency
metrics. Our code and generated backstories are available at
https://github.com/CannyLab/anthology.

摘要：大型語言模型 (LLM) 接受由數百萬位不同作者撰寫的龐大文字資料庫訓練，反映了人類特質的極大差異。雖然這些模型有潛力用於行為研究中人類受試者的近似值，但先前的努力在引導模型反應以符合個別人類使用者方面受到限制。在這項工作中，我們引入了「選集」，一種通過利用開放式人生敘述（我們稱之為「背景故事」）來調整 LLM 以適應特定虛擬角色的方法。我們表明，我們的技術增強了實驗結果的一致性和可靠性，同時確保了對不同亞群的更好表現。在皮尤研究中心美國趨勢小組 (ATP) 的一環中進行的三項全國代表性人類調查中，我們證明選集在匹配人類受訪者的反應分佈方面取得了高達 18% 的改進，在一致性指標方面取得了 27% 的改進。我們的代碼和生成的背景故事可在 https://github.com/CannyLab/anthology 獲得。

##### **FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making**
2407.06567v1 by Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, Zhaozhuo Xu, Koduvayur Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie

Large language models (LLMs) have demonstrated notable potential in
conducting complex tasks and are increasingly utilized in various financial
applications. However, high-quality sequential financial investment
decision-making remains challenging. These tasks require multiple interactions
with a volatile environment for every decision, demanding sufficient
intelligence to maximize returns and manage risks. Although LLMs have been used
to develop agent systems that surpass human teams and yield impressive
investment returns, opportunities to enhance multi-sourced information
synthesis and optimize decision-making outcomes through timely experience
refinement remain unexplored. Here, we introduce the FinCon, an LLM-based
multi-agent framework with CONceptual verbal reinforcement tailored for diverse
FINancial tasks. Inspired by effective real-world investment firm
organizational structures, FinCon utilizes a manager-analyst communication
hierarchy. This structure allows for synchronized cross-functional agent
collaboration towards unified goals through natural language interactions and
equips each agent with greater memory capacity than humans. Additionally, a
risk-control component in FinCon enhances decision quality by episodically
initiating a self-critiquing mechanism to update systematic investment beliefs.
The conceptualized beliefs serve as verbal reinforcement for the future agent's
behavior and can be selectively propagated to the appropriate node that
requires knowledge updates. This feature significantly improves performance
while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon
demonstrates strong generalization capabilities in various financial tasks,
including single stock trading and portfolio management.

摘要：大型語言模型 (LLM) 在執行複雜任務方面已展現出顯著的潛力，並越來越多地用於各種金融應用中。然而，高品質的順序金融投資決策制定仍然具有挑戰性。這些任務要求在每次決策中與波動的環境進行多次互動，需要足夠的智慧才能最大化回報並管理風險。儘管 LLM 已被用於開發超越人類團隊並產生可觀投資回報的代理系統，但通過及時的經驗改進來增強多來源信息綜合和優化決策制定結果的機會仍然未被探索。在此，我們介紹 FinCon，一個基於 LLM 的多代理框架，具有針對不同金融任務量身定制的概念性語言強化。受現實世界投資公司組織結構的啟發，FinCon 利用經理人-分析師溝通層級。此結構允許同步跨職能代理協作，透過自然語言互動朝向統一目標，並為每個代理裝備比人類更大的記憶容量。此外，FinCon 中的風險控制組件透過定期啟動自我批判機制來更新系統性投資信念，進而提升決策品質。概念化的信念作為未來代理行為的語言強化，並且可以選擇性地傳播到需要知識更新的適當節點。此功能顯著提升效能，同時降低不必要的對等通訊成本。此外，FinCon 在各種金融任務中展現出強大的泛化能力，包括單一股票交易和投資組合管理。

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

摘要：近年来，自然语言处理 (NLP) 在各种人工智能 (AI) 应用中发挥了重要作用，例如聊天机器人、文本生成和语言翻译。大语言模型 (LLM) 的出现极大地提高了这些应用程序的性能，在语言理解和生成方面显示出惊人的结果。然而，它们仍然表现出一些缺点，例如幻觉和缺乏特定领域的知识，这些缺点会影响它们在现实世界中的任务中的表现。通过纳入知识图谱 (KG) 可以有效地减轻这些问题，知识图谱以结构化格式组织信息，以多功能且可解释的方式捕获实体之间的关系。同样，KG 的构建和验证提出了 LLM 可以帮助解决的挑战。LLM 和 KG 之间的互补关系导致了一种将这些技术相结合以实现可信结果的趋势。这项工作收集了 28 篇概述了 KG 驱动的 LLM、基于 LLM 的 KG 和 LLM-KG 混合方法的方法的论文。我们系统地分析和比较了这些方法，以提供一个全面的概述，重点介绍关键趋势、创新技术和共同挑战。这种综合将使该领域的新研究人员和那些寻求加深对如何有效地将 KG 和 LLM 相结合以增强 AI 应用能力的理解的人受益。

##### **TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**
2407.06560v1 by Fanglin Dong

Sepsis poses a major global health threat, accounting for millions of deaths
annually and significant economic costs. Accurate predictions of mortality risk
in sepsis patients facilitate the efficient allocation of medical resources,
thereby enhancing patient survival and quality of life. Through precise risk
assessments, healthcare facilities can effectively distribute intensive care
beds, medical equipment, and staff, ensuring high-risk patients receive timely
and appropriate care. Early identification and intervention significantly
decrease mortality rates and improve patient outcomes. Current methods
typically utilize only one type of data--either constant, temporal, or ICD
codes. This study introduces the Time-Constant KAN Integrated Network(TCKIN),
an innovative model that enhances the accuracy of sepsis mortality risk
predictions by integrating both temporal and constant data from electronic
health records and ICD codes. Validated against the MIMIC-III and MIMIC-IV
datasets, TCKIN surpasses existing machine learning and deep learning methods
in accuracy, sensitivity, and specificity. Notably, TCKIN achieved AUCs of
87.76% and 88.07%, demonstrating superior capability in identifying high-risk
patients. Additionally, TCKIN effectively combats the prevalent issue of data
imbalance in clinical settings, improving the detection of patients at elevated
risk of mortality and facilitating timely interventions. These results confirm
the model's effectiveness and its potential to transform patient management and
treatment optimization in clinical practice. With this advanced risk assessment
tool, healthcare providers can devise more tailored treatment plans, optimize
resource utilization, and ultimately enhance survival rates and quality of life
for sepsis patients.

摘要：<paragraph>敗血症構成全球主要的健康威脅，每年造成數百萬人死亡，並帶來龐大的經濟成本。準確預測敗血症患者的死亡風險，有助於有效分配醫療資源，從而提升患者存活率和生活品質。透過精確的風險評估，醫療機構可以有效分配加護病房病床、醫療設備和人員，確保高風險患者能及時獲得適當的照護。早期發現和介入可以顯著降低死亡率，並改善患者預後。目前的方法通常僅使用一種類型的資料，例如常數、時間或 ICD 編碼。本研究引入了時間常數 KAN 整合網路 (TCKIN)，這是一個創新的模型，透過整合電子健康紀錄和 ICD 編碼中的時間和常數資料，來提升敗血症死亡風險預測的準確性。在 MIMIC-III 和 MIMIC-IV 資料集驗證下，TCKIN 在準確性、敏感性和特異性方面都超越了現有的機器學習和深度學習方法。值得注意的是，TCKIN 達到了 87.76% 和 88.07% 的 AUC，顯示出優異的識別高風險患者能力。此外，TCKIN 有效地解決了臨床環境中普遍存在的資料不平衡問題，改善了對死亡風險較高的患者的檢測，並促進及時介入。這些結果證實了該模型的有效性，以及其在臨床實務中轉化患者管理和優化治療的潛力。有了這個進階的風險評估工具，醫療保健提供者可以制定更客製化的治療計畫，最佳化資源利用，並最終提升敗血症患者的存活率和生活品質。</paragraph>

##### **OffsetBias: Leveraging Debiased Data for Tuning Evaluators**
2407.06551v1 by Junsoo Park, Seungyeon Jwa, Meiying Ren, Daeyoung Kim, Sanghyuk Choi

Employing Large Language Models (LLMs) to assess the quality of generated
responses, such as prompting instruct-tuned models or fine-tuning judge models,
has become a widely adopted evaluation method. It is also known that such
evaluators are vulnerable to biases, such as favoring longer responses. While
it is important to overcome this problem, the specifics of these biases remain
under-explored. In this work, we qualitatively identify six types of biases
inherent in various judge models. We propose EvalBiasBench as a meta-evaluation
collection of hand-crafted test cases for each bias type. Additionally, we
present de-biasing dataset construction methods and the associated preference
dataset OffsetBias. Experimental results demonstrate that fine-tuning on our
dataset significantly enhances the robustness of judge models against biases
and improves performance across most evaluation scenarios. We release our
datasets and the fine-tuned judge model to public.

摘要：利用大型語言模型 (LLM) 來評估生成回應的品質，例如提示調整模型或微調評分模型，已成為廣泛採用的評估方法。眾所周知，此類評估器容易受到偏差的影響，例如偏好較長的回應。雖然克服這個問題很重要，但這些偏差的具體情況仍未得到充分探討。在這項工作中，我們定性地找出六種類型的偏差，這些偏差存在於各種評分模型中。我們提出 EvalBiasBench 作為針對每種類型偏差的手工製作測試案例的元評估集合。此外，我們提出去偏差資料集建構方法和相關偏好資料集 OffsetBias。實驗結果表明，在我們的資料集上進行微調可以顯著增強評分模型對偏差的穩健性，並在大多數評估場景中提升效能。我們將我們的資料集和微調後的評分模型發布給公眾。

##### **AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance**
2407.06549v1 by Shouchang Guo, Sonam Damani, Keng-hao Chang

Ads relevance models are crucial in determining the relevance between user
search queries and ad offers, often framed as a classification problem. The
complexity of modeling increases significantly with multiple ad types and
varying scenarios that exhibit both similarities and differences. In this work,
we introduce a novel multi-faceted attention model that performs task aware
feature combination and cross task interaction modeling. Our technique
formulates the feature combination problem as "language" modeling with
auto-regressive attentions across both feature and task dimensions.
Specifically, we introduce a new dimension of task ID encoding for task
representations, thereby enabling precise relevance modeling across diverse ad
scenarios with substantial improvement in generality capability for unseen
tasks. We demonstrate that our model not only effectively handles the increased
computational and maintenance demands as scenarios proliferate, but also
outperforms generalized DNN models and even task-specific models across a
spectrum of ad applications using a single unified model.

摘要：廣告相關性模型對於確定使用者搜尋查詢和廣告提供的相關性至關重要，通常被視為分類問題。隨著多種廣告類型和展現相似性和差異性的各種場景，建模的複雜性大幅增加。在這項工作中，我們引入了一個新穎的多面向注意力模型，它執行任務感知特徵組合和跨任務互動建模。我們的技術將特徵組合問題表述為「語言」建模，並在特徵和任務維度上進行自迴歸注意力。具體來說，我們為任務表示引入了任務 ID 編碼的新維度，從而能夠針對不同的廣告場景進行精確相關性建模，大幅提升對未見任務的概括能力。我們證明了我們的模型不僅能有效處理隨著場景激增而增加的運算和維護需求，而且還能使用單一統一模型在各種廣告應用中優於廣義 DNN 模型，甚至優於特定任務模型。

##### **Deciphering Assamese Vowel Harmony with Featural InfoWaveGAN**
2407.06547v1 by Sneha Ray Barman, Shakuntala Mahanta, Neeraj Kumar Sharma

Traditional approaches for understanding phonological learning have
predominantly relied on curated text data. Although insightful, such approaches
limit the knowledge captured in textual representations of the spoken language.
To overcome this limitation, we investigate the potential of the Featural
InfoWaveGAN model to learn iterative long-distance vowel harmony using raw
speech data. We focus on Assamese, a language known for its phonologically
regressive and word-bound vowel harmony. We demonstrate that the model is adept
at grasping the intricacies of Assamese phonotactics, particularly iterative
long-distance harmony with regressive directionality. It also produced
non-iterative illicit forms resembling speech errors during human language
acquisition. Our statistical analysis reveals a preference for a specific
[+high,+ATR] vowel as a trigger across novel items, indicative of feature
learning. More data and control could improve model proficiency, contrasting
the universality of learning.

摘要：傳統上，對於理解音韻學習的方法主要依賴於策展的文字資料。儘管有見解，但這種方法限制了在口語文字表述中擷取的知識。為了克服這個限制，我們探討了 Featural InfoWaveGAN 模型使用原始語音資料學習反覆長距離元音和諧的潛力。我們專注於阿薩姆語，一種以音韻回歸和以詞為界的元音和諧而聞名的語言。我們證明了該模型擅長掌握阿薩姆語音韻學的複雜性，特別是具有回歸方向性的反覆長距離和諧。它還產生了非反覆的非法形式，類似於人類語言習得過程中發生的言語錯誤。我們的統計分析揭示了對特定 [+high,+ATR] 元音作為觸發器的偏好，這表明特徵學習。更多資料和控制可以提高模型能力，對比學習的普遍性。

##### **LIONs: An Empirically Optimized Approach to Align Language Models**
2407.06542v1 by Xiao Yu, Qingyang Wu, Yu Li, Zhou Yu

Alignment is a crucial step to enhance the instruction-following and
conversational abilities of language models. Despite many recent work proposing
new algorithms, datasets, and training pipelines, there is a lack of
comprehensive studies measuring the impact of various design choices throughout
the whole training process. We first conduct a rigorous analysis over a
three-stage training pipeline consisting of supervised fine-tuning, offline
preference learning, and online preference learning. We have found that using
techniques like sequence packing, loss masking in SFT, increasing the
preference dataset size in DPO, and online DPO training can significantly
improve the performance of language models. We then train from Gemma-2b-base
and LLama-3-8b-base, and find that our best models exceed the performance of
the official instruct models tuned with closed-source data and algorithms. Our
code and models can be found at
https://github.com/Columbia-NLP-Lab/LionAlignment.

摘要：對齊是增強語言模型遵循指令和對話能力的關鍵步驟。儘管許多近期研究提出新的演算法、資料集和訓練管線，但仍缺乏衡量整個訓練過程中各種設計選擇影響的全面研究。我們首先對由監督微調、離線偏好學習和線上偏好學習組成的三階段訓練管線進行嚴謹的分析。我們發現使用序列封裝、SFT 中的損失遮蔽、增加 DPO 中的偏好資料集大小和線上 DPO 訓練等技術可以顯著提升語言模型的效能。接著我們從 Gemma-2b-base 和 LLama-3-8b-base 進行訓練，發現我們最好的模型超越了使用閉源資料和演算法微調的官方指令模型的效能。我們的程式碼和模型可以在 https://github.com/Columbia-NLP-Lab/LionAlignment 找到。

##### **General and Task-Oriented Video Segmentation**
2407.06540v1 by Mu Chen, Liulei Li, Wenguan Wang, Ruijie Quan, Yi Yang

We present GvSeg, a general video segmentation framework for addressing four
different video segmentation tasks (i.e., instance, semantic, panoptic, and
exemplar-guided) while maintaining an identical architectural design.
Currently, there is a trend towards developing general video segmentation
solutions that can be applied across multiple tasks. This streamlines research
endeavors and simplifies deployment. However, such a highly homogenized
framework in current design, where each element maintains uniformity, could
overlook the inherent diversity among different tasks and lead to suboptimal
performance. To tackle this, GvSeg: i) provides a holistic disentanglement and
modeling for segment targets, thoroughly examining them from the perspective of
appearance, position, and shape, and on this basis, ii) reformulates the query
initialization, matching and sampling strategies in alignment with the
task-specific requirement. These architecture-agnostic innovations empower
GvSeg to effectively address each unique task by accommodating the specific
properties that characterize them. Extensive experiments on seven gold-standard
benchmark datasets demonstrate that GvSeg surpasses all existing
specialized/general solutions by a significant margin on four different video
segmentation tasks.

摘要：我們提出 GvSeg，一個通用影片分割架構，用於處理四種不同的影片分割任務（即實例、語義、全景和範例引導），同時維持相同的架構設計。
目前，發展通用影片分割解決方案的趨勢正興起，這些解決方案可應用於多項任務。這簡化了研究工作並簡化了部署。然而，在目前的設計中，這種高度同質化的架構（其中每個元素都保持一致性）可能會忽略不同任務之間的固有差異性，並導致次佳效能。為了解決這個問題，GvSeg：i) 提供了一個整體的解開和建模，用於分割目標，從外觀、位置和形狀的角度徹底檢視它們，並在此基礎上，ii) 重新制定查詢初始化、匹配和取樣策略，以符合特定任務的要求。這些與架構無關的創新使 GvSeg 能夠通過適應它們的特徵來有效地解決每個獨特的任務。在七個黃金標準基準資料集上的大量實驗表明，GvSeg 在四種不同的影片分割任務上以顯著幅度超越所有現有的專用/通用解決方案。

##### **Enhancing Low-Resource NMT with a Multilingual Encoder and Knowledge Distillation: A Case Study**
2407.06538v1 by Aniruddha Roy, Pretam Ray, Ayush Maheshwari, Sudeshna Sarkar, Pawan Goyal

Neural Machine Translation (NMT) remains a formidable challenge, especially
when dealing with low-resource languages. Pre-trained sequence-to-sequence
(seq2seq) multi-lingual models, such as mBART-50, have demonstrated impressive
performance in various low-resource NMT tasks. However, their pre-training has
been confined to 50 languages, leaving out support for numerous low-resource
languages, particularly those spoken in the Indian subcontinent. Expanding
mBART-50's language support requires complex pre-training, risking performance
decline due to catastrophic forgetting. Considering these expanding challenges,
this paper explores a framework that leverages the benefits of a pre-trained
language model along with knowledge distillation in a seq2seq architecture to
facilitate translation for low-resource languages, including those not covered
by mBART-50. The proposed framework employs a multilingual encoder-based
seq2seq model as the foundational architecture and subsequently uses
complementary knowledge distillation techniques to mitigate the impact of
imbalanced training. Our framework is evaluated on three low-resource Indic
languages in four Indic-to-Indic directions, yielding significant BLEU-4 and
chrF improvements over baselines. Further, we conduct human evaluation to
confirm effectiveness of our approach. Our code is publicly available at
https://github.com/raypretam/Two-step-low-res-NMT.

摘要：神經機器翻譯 (NMT) 仍然是一項艱鉅的挑戰，特別是在處理低資源語言時。預訓練序列對序列 (seq2seq) 多語言模型（例如 mBART-50）已在各種低資源 NMT 任務中展現令人印象深刻的效能。然而，他們的預訓練僅限於 50 種語言，無法支援許多低資源語言，特別是印度次大陸所使用的語言。擴充 mBART-50 的語言支援需要複雜的預訓練，由於災難性遺忘，可能會導致效能下降。考量到這些擴充挑戰，本文探討一個架構，它利用預訓練語言模型的優點，以及 seq2seq 架構中的知識提煉，以促進低資源語言的翻譯，包括 mBART-50 未涵蓋的語言。建議的架構採用多語言編碼器為基礎的 seq2seq 模型作為基礎架構，然後使用補充知識提煉技術來減輕不平衡訓練的影響。我們的架構在四個印度語到印度語方向的三種低資源印度語言上進行評估，產生顯著的 BLEU-4 和 chrF 優化，超越基線。此外，我們進行人工評估，以確認我們方法的有效性。我們的程式碼可在 https://github.com/raypretam/Two-step-low-res-NMT 公開取得。

##### **Efficient and Accurate Memorable Conversation Model using DPO based on sLLM**
2407.06537v1 by Youngkyung Seo, Yoonseok Heo, Jun-Seok Koh, Du-Seoung Chang

In multi-session dialog system, it is essential to continuously update the
memory as the session progresses. Simply accumulating memory can make it
difficult to focus on the content of the conversation for inference due to the
limited input sentence size. Therefore, efficient and accurate conversation
model that is capable of managing memory to reflect the conversation history
continuously is necessary. This paper presents a conversation model that
efficiently manages memory as sessions progress and incorporates this into the
model to reflect the conversation history accurately with 3 methodologies: SFT,
DPO and DPO with SFT model. Our model using DPO algorithm shows an improvement
about 0.0591 of BERTScore in memory accuracy, and the rate of responses
reflecting the memory increased as well. Also, response generation performance
enhanced about 4.292 in fluency, 3.935 in coherence, and 2.896 in consistency.
This paper describes a training method that yields better performance than
models with more than twice the parameter size, even when the model size is
smaller. Thus, our model demonstrates efficiency not only in terms of accuracy
but also in resource utilization.

摘要：在多輪對話系統中，隨著對話的進行，持續更新記憶體至關重要。由於輸入句子的長度有限，簡單地累積記憶體會使得在推論時難以專注於對話內容。因此，需要一個有效且準確的對話模型，能夠管理記憶體以持續反映對話記錄。本文提出了一個對話模型，它能有效管理記憶體，隨著對話的進行，並透過 SFT、DPO 和結合 SFT 的 DPO 模型，將其整合到模型中，以準確反映對話記錄。使用 DPO 演算法的模型在記憶體準確度方面顯示出 BERT 分數提升了約 0.0591，並且反映記憶體的回應率也有所提升。此外，回應產生的流暢度提升了約 4.292、連貫性提升了 3.935、一致性提升了 2.896。本文描述了一種訓練方法，即使模型規模較小，也能產生比參數規模大兩倍以上的模型更好的效能。因此，我們的模型不僅在準確性方面展現了效率，在資源利用方面也展現了效率。

##### **LETS-C: Leveraging Language Embedding for Time Series Classification**
2407.06533v1 by Rachneet Kaur, Zhen Zeng, Tucker Balch, Manuela Veloso

Recent advancements in language modeling have shown promising results when
applied to time series data. In particular, fine-tuning pre-trained large
language models (LLMs) for time series classification tasks has achieved
state-of-the-art (SOTA) performance on standard benchmarks. However, these
LLM-based models have a significant drawback due to the large model size, with
the number of trainable parameters in the millions. In this paper, we propose
an alternative approach to leveraging the success of language modeling in the
time series domain. Instead of fine-tuning LLMs, we utilize a language
embedding model to embed time series and then pair the embeddings with a simple
classification head composed of convolutional neural networks (CNN) and
multilayer perceptron (MLP). We conducted extensive experiments on
well-established time series classification benchmark datasets. We demonstrated
LETS-C not only outperforms the current SOTA in classification accuracy but
also offers a lightweight solution, using only 14.5% of the trainable
parameters on average compared to the SOTA model. Our findings suggest that
leveraging language encoders to embed time series data, combined with a simple
yet effective classification head, offers a promising direction for achieving
high-performance time series classification while maintaining a lightweight
model architecture.

摘要：<paragraph>最近在语言建模方面的进步已在应用于时间序列数据时展现出可喜的成果。特别是，针对时间序列分类任务微调预训练的大型语言模型 (LLM) 已在标准基准测试中取得了最先进 (SOTA) 的性能。然而，这些基于 LLM 的模型由于模型规模庞大而存在一个显著的缺点，可训练参数的数量以百万计。在本文中，我们提出了一种替代方法，以利用语言建模在时间序列领域的成功。我们不微调 LLM，而是利用语言嵌入模型来嵌入时间序列，然后将嵌入与由卷积神经网络 (CNN) 和多层感知器 (MLP) 组成的一个简单分类头配对。我们在成熟的时间序列分类基准数据集上进行了广泛的实验。我们证明 LETS-C 不仅在分类准确度上优于当前的 SOTA，而且还提供了一个轻量级的解决方案，与 SOTA 模型相比，平均只使用了 14.5% 的可训练参数。我们的研究结果表明，利用语言编码器来嵌入时间序列数据，并结合一个简单但有效的分类头，为实现高性能时间序列分类同时保持轻量级的模型架构提供了一个有前景的方向。</paragraph>

##### **STORYSUMM: Evaluating Faithfulness in Story Summarization**
2407.06501v1 by Melanie Subbiah, Faisal Ladhak, Akankshya Mishra, Griffin Adams, Lydia B. Chilton, Kathleen McKeown

Human evaluation has been the gold standard for checking faithfulness in
abstractive summarization. However, with a challenging source domain like
narrative, multiple annotators can agree a summary is faithful, while missing
details that are obvious errors only once pointed out. We therefore introduce a
new dataset, STORYSUMM, comprising LLM summaries of short stories with
localized faithfulness labels and error explanations. This benchmark is for
evaluation methods, testing whether a given method can detect challenging
inconsistencies. Using this dataset, we first show that any one human
annotation protocol is likely to miss inconsistencies, and we advocate for
pursuing a range of methods when establishing ground truth for a summarization
dataset. We finally test recent automatic metrics and find that none of them
achieve more than 70% balanced accuracy on this task, demonstrating that it is
a challenging benchmark for future work in faithfulness evaluation.

摘要：人類評估一直是檢查抽象摘要中忠實度的黃金標準。然而，對於敘事等具有挑戰性的來源領域，多個註解者可能會同意摘要是忠實的，同時遺漏了明顯的錯誤細節，而只在指出後才會發現。因此，我們引入了一個新的資料集 STORYSUMM，其中包含具有局部忠實度標籤和錯誤說明的 LLM 短篇故事摘要。此基準適用於評估方法，測試給定方法是否可以檢測具有挑戰性的不一致性。使用此資料集，我們首先表明任何一種人類註解協定都可能遺漏不一致性，並且我們主張在為摘要資料集建立基本事實時採用一系列方法。我們最後測試了最近的自動化指標，發現沒有任何指標在此任務上達到 70% 以上的平衡準確度，這表明這是未來忠實度評估工作中具有挑戰性的基準。

##### **Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons**
2407.06488v1 by Yongqi Leng, Deyi Xiong

While large language models (LLMs) have demonstrated superior multi-task
capabilities, understanding the learning mechanisms behind this is still a
challenging problem. In this paper, we attempt to understand such mechanisms
from the perspective of neurons. Specifically, we detect task-sensitive neurons
in LLMs via gradient attribution on task-specific data. Through extensive
deactivation and fine-tuning experiments, we demonstrate that the detected
neurons are highly correlated with the given task, which we term as
task-specific neurons. With these identified task-specific neurons, we delve
into two common problems in multi-task learning and continuous learning:
Generalization and Catastrophic Forgetting. We find that the overlap of
task-specific neurons is strongly associated with generalization and
specialization across tasks. Interestingly, at certain layers of LLMs, there is
a high similarity in the parameters of different task-specific neurons, and
such similarity is highly correlated with the generalization performance.
Inspired by these findings, we propose a neuron-level continuous fine-tuning
method that only fine-tunes the current task-specific neurons during continuous
learning, and extensive experiments demonstrate the effectiveness of the
proposed method. Our study provides insights into the interpretability of LLMs
in multi-task learning.

摘要：儘管大型語言模型 (LLM) 已展現出卓越的多任務能力，但了解其背後的學習機制仍是一項艱鉅的任務。在本文中，我們嘗試從神經元的角度來了解此類機制。具體來說，我們透過任務特定資料上的梯度歸因來偵測 LLM 中的任務敏感神經元。透過廣泛的停用和微調實驗，我們證明了偵測到的神經元與所給任務高度相關，我們將其稱為任務特定神經元。透過這些已識別的任務特定神經元，我們深入探討了多任務學習和持續學習中的兩個常見問題：泛化和災難性遺忘。我們發現任務特定神經元的重疊與任務之間的泛化和專門化密切相關。有趣的是，在 LLM 的某些層中，不同任務特定神經元的參數具有高度相似性，而這種相似性與泛化效能高度相關。受這些發現啟發，我們提出了一種神經元層級的持續微調方法，該方法僅在持續學習期間微調當前任務特定神經元，而廣泛的實驗證明了所提出方法的有效性。我們的研究提供了對 LLM 在多任務學習中可解釋性的見解。

##### **Optimal Decision Making Through Scenario Simulations Using Large Language Models**
2407.06486v1 by Sumedh Rasal, EJ Hauer

The rapid evolution of Large Language Models (LLMs) has markedly expanded
their application across diverse domains, transforming how complex problems are
approached and solved. Initially conceived to predict subsequent words in
texts, these models have transcended their original design to comprehend and
respond to the underlying contexts of queries. Today, LLMs routinely perform
tasks that once seemed formidable, such as writing essays, poems, stories, and
even developing software code. As their capabilities continue to grow, so too
do the expectations of their performance in even more sophisticated domains.
  Despite these advancements, LLMs still encounter significant challenges,
particularly in scenarios requiring intricate decision-making, such as planning
trips or choosing among multiple viable options. These tasks often demand a
nuanced understanding of various outcomes and the ability to predict the
consequences of different choices, which are currently outside the typical
operational scope of LLMs.
  This paper proposes an innovative approach to bridge this capability gap. By
enabling LLMs to request multiple potential options and their respective
parameters from users, our system introduces a dynamic framework that
integrates an optimization function within the decision-making process. This
function is designed to analyze the provided options, simulate potential
outcomes, and determine the most advantageous solution based on a set of
predefined criteria. By harnessing this methodology, LLMs can offer tailored,
optimal solutions to complex, multi-variable problems, significantly enhancing
their utility and effectiveness in real-world applications. This approach not
only expands the functional envelope of LLMs but also paves the way for more
autonomous and intelligent systems capable of supporting sophisticated
decision-making tasks.

摘要：大型語言模型（LLM）快速演進，大幅擴展了它們在不同領域的應用，轉變了我們處理和解決複雜問題的方式。這些模型最初被構想為預測文字中的後續字詞，但已超越其原始設計，能夠理解並回應查詢的底層脈絡。如今，LLM 常執行曾經看似艱鉅的任務，例如撰寫文章、詩歌、故事，甚至開發軟體程式碼。隨著它們的能力持續增長，它們在更精密的領域中對其效能的期望也隨之提高。
儘管有這些進展，LLM 仍會遇到重大挑戰，特別是在需要複雜決策制定（例如規劃行程或在多個可行選項中進行選擇）的場景中。這些任務通常需要對各種結果有細微的了解，以及預測不同選擇後果的能力，這目前超出了 LLM 典型的運作範圍。
本文提出了一種創新的方法來彌合這種能力差距。透過讓 LLM 能夠向使用者請求多個潛在選項及其各自的參數，我們的系統引入了動態架構，在決策制定過程中整合了最佳化函數。此函數旨在分析提供的選項，模擬潛在結果，並根據一組預定義的標準確定最有利的解決方案。透過利用此方法，LLM 可以針對複雜的多變數問題提供量身打造的最佳解決方案，顯著提升它們在實際應用中的效用和有效性。這種方法不僅擴展了 LLM 的功能範圍，也為更自主和智慧的系統鋪路，這些系統能夠支援精密的決策制定任務。

##### **CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community**
2407.06485v1 by Yan Liu, Bin Guo, Nuo Li, Yasan Ding, Zhouyangzi Zhang, Zhiwen Yu

Artificial Intelligence of Things (AIoT) is an emerging frontier based on the
deep fusion of Internet of Things (IoT) and Artificial Intelligence (AI)
technologies. Although advanced deep learning techniques enhance the efficient
data processing and intelligent analysis of complex IoT data, they still suffer
from notable challenges when deployed to practical AIoT applications, such as
constrained resources, and diverse task requirements. Knowledge transfer is an
effective method to enhance learning performance by avoiding the exorbitant
costs associated with data recollection and model retraining. Notably, although
there are already some valuable and impressive surveys on transfer learning,
these surveys introduce approaches in a relatively isolated way and lack the
recent advances of various knowledge transfer techniques for AIoT field. This
survey endeavors to introduce a new concept of knowledge transfer, referred to
as Crowd Knowledge Transfer (CrowdTransfer), which aims to transfer prior
knowledge learned from a crowd of agents to reduce the training cost and as
well as improve the performance of the model in real-world complicated
scenarios. Particularly, we present four transfer modes from the perspective of
crowd intelligence, including derivation, sharing, evolution and fusion modes.
Building upon conventional transfer learning methods, we further delve into
advanced crowd knowledge transfer models from three perspectives for various
AIoT applications. Furthermore, we explore some applications of AIoT areas,
such as human activity recognition, urban computing, multi-robot system, and
smart factory. Finally, we discuss the open issues and outline future research
directions of knowledge transfer in AIoT community.

摘要：物聯網人工智慧（AIoT）是一個新興領域，基於物聯網（IoT）和人工智慧（AI）技術的深度融合。儘管先進的深度學習技術增強了複雜物聯網數據的高效資料處理和智慧分析，但它們在部署到實際 AIoT 應用程式時，仍會遇到顯著的挑戰，例如受限資源和多樣化的任務需求。知識轉移是一種有效的方法，可透過避免與資料收集和模型重新訓練相關的高昂成本，來增強學習效能。值得注意的是，儘管已經有一些關於遷移學習的寶貴且令人印象深刻的調查，但這些調查是以相對孤立的方式介紹方法，並且缺乏 AIoT 領域各種知識轉移技術的最新進展。本調查致力於引入一個新的知識轉移概念，稱為群眾知識轉移（CrowdTransfer），其目標是從一群代理中轉移先前的知識，以降低訓練成本，並提高模型在現實世界複雜場景中的效能。特別是，我們從群眾智慧的角度提出了四種轉移模式，包括衍生、共享、演化和融合模式。在傳統遷移學習方法的基礎上，我們進一步從三個角度深入探討先進的群眾知識轉移模型，以適用於各種 AIoT 應用程式。此外，我們探討了 AIoT 領域的一些應用，例如人類活動識別、城市運算、多機器人系統和智慧工廠。最後，我們討論了開放議題，並概述了 AIoT 社群中知識轉移的未來研究方向。

##### **Composable Interventions for Language Models**
2407.06483v1 by Arinbjorn Kolbeinsson, Kyle O'Brien, Tianjin Huang, Shanghua Gao, Shiwei Liu, Jonathan Richard Schwarz, Anurag Vaidya, Faisal Mahmood, Marinka Zitnik, Tianlong Chen, Thomas Hartvigsen

Test-time interventions for language models can enhance factual accuracy,
mitigate harmful outputs, and improve model efficiency without costly
retraining. But despite a flood of new methods, different types of
interventions are largely developing independently. In practice, multiple
interventions must be applied sequentially to the same model, yet we lack
standardized ways to study how interventions interact. We fill this gap by
introducing composable interventions, a framework to study the effects of using
multiple interventions on the same language models, featuring new metrics and a
unified codebase. Using our framework, we conduct extensive experiments and
compose popular methods from three emerging intervention categories --
Knowledge Editing, Model Compression, and Machine Unlearning. Our results from
310 different compositions uncover meaningful interactions: compression hinders
editing and unlearning, composing interventions hinges on their order of
application, and popular general-purpose metrics are inadequate for assessing
composability. Taken together, our findings showcase clear gaps in
composability, suggesting a need for new multi-objective interventions. All of
our code is public:
https://github.com/hartvigsen-group/composable-interventions.

摘要：測試時間干預對於語言模型可以增強事實準確性，
減輕有害輸出，並提高模型效率，而無需代價高昂的重新訓練。但儘管有大量的新方法，不同類型的
干預在很大程度上是獨立發展的。在實務上，必須對同一模型依序套用多種干預，但我們缺乏
標準化的方法來研究干預之間如何互動。我們透過引入可組合干預來填補這項空白，這是一個框架，用於研究在同一語言模型上使用多種干預的效果，具有新的指標和一個統一的程式碼庫。使用我們的框架，我們進行廣泛的實驗，並組合來自三個新興干預類別的熱門方法——知識編輯、模型壓縮和機器遺忘。我們的結果來自
310 個不同的組合，揭示有意義的互動：壓縮會阻礙編輯和遺忘，組合干預取決於它們的應用順序，而熱門的通用指標不足以評估可組合性。綜觀而言，我們的發現展示了可組合性中的明顯差距，表明需要新的多目標干預。我們的程式碼全部公開：
https://github.com/hartvigsen-group/composable-interventions。

##### **Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on English Second Language Conversations**
2407.06479v1 by Rena Gao, Carsten Roever, Jey Han Lau

We present an evaluation framework for interactive dialogue assessment in the
context of English as a Second Language (ESL) speakers. Our framework collects
dialogue-level interactivity labels (e.g., topic management; 4 labels in total)
and micro-level span features (e.g., backchannels; 17 features in total). Given
our annotated data, we study how the micro-level features influence the (higher
level) interactivity quality of ESL dialogues by constructing various machine
learning-based models. Our results demonstrate that certain micro-level
features strongly correlate with interactivity quality, like reference word
(e.g., she, her, he), revealing new insights about the interaction between
higher-level dialogue quality and lower-level linguistic signals. Our framework
also provides a means to assess ESL communication, which is useful for language
assessment.

摘要：我們提出一個互動對話評量架構，用於評估英語為第二語言 (ESL) 的講者。我們的架構收集對話層級互動標籤 (例如，主題管理；共 4 個標籤) 和微觀層級跨距特徵 (例如，反向通道；共 17 個特徵)。根據我們的註解資料，我們研究微觀層級特徵如何透過建構各種機器學習模型，影響 ESL 對話的 (較高層級) 互動品質。我們的結果顯示，某些微觀層級特徵與互動品質有很強的關聯性，例如參考詞 (例如，她、她、他)，揭露了更高層級對話品質與更低層級語言訊號之間的互動關係。我們的架構也提供了一種評量 ESL 溝通的方式，這對於語言評量很有用。

##### **MUSE: Machine Unlearning Six-Way Evaluation for Language Models**
2407.06460v1 by Weijia Shi, Jaechan Lee, Yangsibo Huang, Sadhika Malladi, Jieyu Zhao, Ari Holtzman, Daogao Liu, Luke Zettlemoyer, Noah A. Smith, Chiyuan Zhang

Language models (LMs) are trained on vast amounts of text data, which may
include private and copyrighted content. Data owners may request the removal of
their data from a trained model due to privacy or copyright concerns. However,
exactly unlearning only these datapoints (i.e., retraining with the data
removed) is intractable in modern-day models. This has led to the development
of many approximate unlearning algorithms. The evaluation of the efficacy of
these algorithms has traditionally been narrow in scope, failing to precisely
quantify the success and practicality of the algorithm from the perspectives of
both the model deployers and the data owners. We address this issue by
proposing MUSE, a comprehensive machine unlearning evaluation benchmark that
enumerates six diverse desirable properties for unlearned models: (1) no
verbatim memorization, (2) no knowledge memorization, (3) no privacy leakage,
(4) utility preservation on data not intended for removal, (5) scalability with
respect to the size of removal requests, and (6) sustainability over sequential
unlearning requests. Using these criteria, we benchmark how effectively eight
popular unlearning algorithms on 7B-parameter LMs can unlearn Harry Potter
books and news articles. Our results demonstrate that most algorithms can
prevent verbatim memorization and knowledge memorization to varying degrees,
but only one algorithm does not lead to severe privacy leakage. Furthermore,
existing algorithms fail to meet deployer's expectations because they often
degrade general model utility and also cannot sustainably accommodate
successive unlearning requests or large-scale content removal. Our findings
identify key issues with the practicality of existing unlearning algorithms on
language models, and we release our benchmark to facilitate further
evaluations: muse-bench.github.io

摘要：<paragraph>語言模型 (LM) 是在大量的文字資料上訓練出來的，其中可能包含私人和受版權保護的內容。資料擁有者可能會要求從訓練好的模型中移除他們的資料，原因是隱私或版權問題。然而，精確地取消學習僅這些資料點（即在移除資料後重新訓練）在現代模型中是不可行的。這導致了許多近似取消學習演算法的開發。傳統上，對這些演算法效能的評估範圍很窄，無法精確量化演算法從模型部署者和資料擁有者的角度來看是否成功且實用。我們透過提出 MUSE 來解決這個問題，MUSE 是個全面的機器取消學習評量基準，它列舉了取消學習模型的六個不同的理想屬性：(1) 沒有逐字記憶，(2) 沒有知識記憶，(3) 沒有隱私外洩，(4) 對未打算移除的資料保留效用，(5) 針對移除要求的規模進行調整，以及 (6) 對連續取消學習要求的永續性。使用這些標準，我們評量了八種流行的取消學習演算法在 7B 參數 LM 上取消學習哈利波特書籍和新聞文章的有效性。我們的結果表明，大多數演算法都能在不同程度上防止逐字記憶和知識記憶，但只有一種演算法不會導致嚴重的隱私外洩。此外，現有的演算法無法滿足部署者的期望，因為它們通常會降低一般模型的效用，而且也無法持續滿足連續的取消學習要求或大規模內容移除。我們的研究結果找出了現有取消學習演算法在語言模型上的實用性的關鍵問題，並且我們釋出我們的基準以利進一步評估：muse-bench.github.io</paragraph>

##### **Exploiting Heterogeneity in Timescales for Sparse Recurrent Spiking Neural Networks for Energy-Efficient Edge Computing**
2407.06452v1 by Biswadeep Chakraborty, Saibal Mukhopadhyay

Spiking Neural Networks (SNNs) represent the forefront of neuromorphic
computing, promising energy-efficient and biologically plausible models for
complex tasks. This paper weaves together three groundbreaking studies that
revolutionize SNN performance through the introduction of heterogeneity in
neuron and synapse dynamics. We explore the transformative impact of
Heterogeneous Recurrent Spiking Neural Networks (HRSNNs), supported by rigorous
analytical frameworks and novel pruning methods like Lyapunov Noise Pruning
(LNP). Our findings reveal how heterogeneity not only enhances classification
performance but also reduces spiking activity, leading to more efficient and
robust networks. By bridging theoretical insights with practical applications,
this comprehensive summary highlights the potential of SNNs to outperform
traditional neural networks while maintaining lower computational costs. Join
us on a journey through the cutting-edge advancements that pave the way for the
future of intelligent, energy-efficient neural computing.

摘要：尖峰神經網路（SNN）代表神經形態運算的最前沿，有望為複雜任務提供節能且在生物學上合理的模型。本文將三項突破性研究交織在一起，這些研究透過在神經元和突觸動力學中引入異質性來革新 SNN 效能。我們探討異質遞迴尖峰神經網路（HRSNN）的轉型影響，並得到嚴謹的分析架構和創新的修剪方法（例如李亞普諾夫雜訊修剪（LNP））的支持。我們的研究結果揭示異質性不僅增強分類效能，還能減少尖峰活動，從而形成更有效率且穩健的網路。透過將理論見解與實際應用結合，這份全面的摘要強調了 SNN 在維持較低運算成本的同時超越傳統神經網路的潛力。加入我們，踏上尖端進展的旅程，為智慧、節能神經運算的未來鋪路。

##### **Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment**
2407.06443v1 by Qizhang Feng, Siva Rajesh Kasa, Hyokun Yun, Choon Hui Teo, Sravan Babu Bodapati

Large Language Models (LLMs) have seen widespread adoption due to their
remarkable natural language capabilities. However, when deploying them in
real-world settings, it is important to align LLMs to generate texts according
to acceptable human standards. Methods such as Proximal Policy Optimization
(PPO) and Direct Preference Optimization (DPO) have made significant progress
in refining LLMs using human preference data. However, the privacy concerns
inherent in utilizing such preference data have yet to be adequately studied.
In this paper, we investigate the vulnerability of LLMs aligned using human
preference datasets to membership inference attacks (MIAs), highlighting the
shortcomings of previous MIA approaches with respect to preference data. Our
study has two main contributions: first, we introduce a novel reference-based
attack framework specifically for analyzing preference data called PREMIA
(\uline{Pre}ference data \uline{MIA}); second, we provide empirical evidence
that DPO models are more vulnerable to MIA compared to PPO models. Our findings
highlight gaps in current privacy-preserving practices for LLM alignment.

摘要：大型語言模型 (LLM) 因其卓越的自然語言能力而被廣泛採用。然而，在實際環境中部署它們時，重要的是讓 LLM 根據可接受的人類標準生成文本。近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO) 等方法在使用人類偏好數據微調 LLM 方面取得了顯著進展。然而，利用此類偏好數據所固有的隱私問題尚未得到充分研究。在本文中，我們探討了使用人類偏好數據集對齊的 LLM 對成員推論攻擊 (MIA) 的脆弱性，強調了先前 MIA 方法在偏好數據方面的缺點。我們的研究有兩個主要貢獻：首先，我們引入了一個針對偏好數據進行分析的全新基於參考的攻擊框架，稱為 PREMIA（\uline{Pre}ference data \uline{MIA}）；其次，我們提供經驗證據表明，與 PPO 模型相比，DPO 模型更容易受到 MIA 的攻擊。我們的研究結果突顯了當前 LLM 對齊隱私保護措施的不足之處。

##### **A Single Transformer for Scalable Vision-Language Modeling**
2407.06438v1 by Yangyi Chen, Xingyao Wang, Hao Peng, Heng Ji

We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.
Current large vision-language models (LVLMs) such as LLaVA mostly employ
heterogeneous architectures that connect pre-trained visual encoders with large
language models (LLMs) to facilitate visual recognition and complex reasoning.
Although achieving remarkable performance with relatively lightweight training,
we identify four primary scalability limitations: (1) The visual capacity is
constrained by pre-trained visual encoders, which are typically an order of
magnitude smaller than LLMs. (2) The heterogeneous architecture complicates the
use of established hardware and software infrastructure. (3) Study of scaling
laws on such architecture must consider three separate components - visual
encoder, connector, and LLMs, which complicates the analysis. (4) The use of
existing visual encoders typically requires following a pre-defined
specification of image inputs pre-processing, for example, by reshaping inputs
to fixed-resolution square images, which presents difficulties in processing
and training on high-resolution images or those with unusual aspect ratio. A
unified single Transformer architecture, like SOLO, effectively addresses these
scalability concerns in LVLMs; however, its limited adoption in the modern
context likely stems from the absence of reliable training recipes that balance
both modalities and ensure stable training for billion-scale models. In this
paper, we introduce the first open-source training recipe for developing SOLO,
an open-source 7B LVLM using moderate academic resources. The training recipe
involves initializing from LLMs, sequential pre-training on ImageNet and
web-scale data, and instruction fine-tuning on our curated high-quality
datasets. On extensive evaluation, SOLO demonstrates performance comparable to
LLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.

摘要：<paragraph>我們提出了 SOLO，一個用於可擴充視覺語言模型的單一Transformer。
目前的巨量視覺語言模型 (LVLMs)，例如 LLaVA，大多採用異質架構，將預先訓練好的視覺編碼器與巨量語言模型 (LLMs) 連接起來，以促進視覺識別和複雜推理。
儘管在相對輕量級的訓練中實現了顯著的效能，我們發現了四個主要的擴充性限制：(1) 視覺容量受到預先訓練好的視覺編碼器的限制，而視覺編碼器通常比 LLM 小一個數量級。(2) 異質架構使既有硬體和軟體基礎設施的使用變得複雜。(3) 此類架構上擴充定律的研究必須考量三個獨立的元件，即視覺編碼器、連接器和 LLM，這使得分析變得複雜。(4) 使用現有的視覺編碼器通常需要遵循預先定義的影像輸入前處理規格，例如，將輸入重新調整為固定解析度的正方形影像，這在處理和訓練高解析度影像或具有異常長寬比的影像時會造成困難。統一的單一Transformer架構，例如 SOLO，有效地解決了 LVLMs 中的這些擴充性問題；然而，它在現代環境中的採用有限，這可能是因為缺乏平衡兩種模式並確保十億規模模型穩定訓練的可靠訓練配方。在本文中，我們介紹了第一個用於開發 SOLO 的開源訓練配方，SOLO 是一個使用適度的學術資源的開源 7B LVLM。訓練配方涉及從 LLM 初始化、在 ImageNet 和網路規模資料上進行順序預訓練，以及在我們策劃的高品質資料集上進行指令微調。在廣泛的評估中，SOLO 表現出與 LLaVA-v1.5-7B 相當的效能，特別是在視覺數學推理方面表現出色。</paragraph>

