{"2406.05132": {"publish_time": "2024-06-07", "title": "3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs", "paper_summary": "The integration of language and 3D perception is crucial for developing\nembodied agents and robots that comprehend and interact with the physical\nworld. While large language models (LLMs) have demonstrated impressive language\nunderstanding and generation capabilities, their adaptation to 3D environments\n(3D-LLMs) remains in its early stages. A primary challenge is the absence of\nlarge-scale datasets that provide dense grounding between language and 3D\nscenes. In this paper, we introduce 3D-GRAND, a pioneering large-scale dataset\ncomprising 40,087 household scenes paired with 6.2 million densely-grounded\nscene-language instructions. Our results show that instruction tuning with\n3D-GRAND significantly enhances grounding capabilities and reduces\nhallucinations in 3D-LLMs. As part of our contributions, we propose a\ncomprehensive benchmark 3D-POPE to systematically evaluate hallucination in\n3D-LLMs, enabling fair comparisons among future models. Our experiments\nhighlight a scaling effect between dataset size and 3D-LLM performance,\nemphasizing the critical role of large-scale 3D-text datasets in advancing\nembodied AI research. Notably, our results demonstrate early signals for\neffective sim-to-real transfer, indicating that models trained on large\nsynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and\n3D-POPE, we aim to equip the embodied AI community with essential resources and\ninsights, setting the stage for more reliable and better-grounded 3D-LLMs.\nProject website: https://3d-grand.github.io", "paper_summary_zh": "\u8a9e\u8a00\u548c 3D \u611f\u77e5\u7684\u6574\u5408\u5c0d\u65bc\u958b\u767c\u7406\u89e3\u4e26\u8207\u7269\u7406\u4e16\u754c\u4e92\u52d5\u7684\u5177\u8eab\u4ee3\u7406\u548c\u6a5f\u5668\u4eba\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8a9e\u8a00\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u5c0d 3D \u74b0\u5883 (3D-LLM) \u7684\u9069\u61c9\u4ecd\u8655\u65bc\u65e9\u671f\u968e\u6bb5\u3002\u4e00\u500b\u4e3b\u8981\u7684\u6311\u6230\u662f\u7f3a\u4e4f\u63d0\u4f9b\u8a9e\u8a00\u548c 3D \u5834\u666f\u4e4b\u9593\u5bc6\u96c6\u57fa\u790e\u7684\u5927\u898f\u6a21\u8cc7\u6599\u96c6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 3D-GRAND\uff0c\u4e00\u500b\u7531 40,087 \u500b\u5bb6\u5ead\u5834\u666f\u914d\u5c0d 620 \u842c\u500b\u5bc6\u96c6\u57fa\u790e\u5834\u666f\u8a9e\u8a00\u6307\u4ee4\u7d44\u6210\u7684\u958b\u5275\u6027\u5927\u578b\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u4f7f\u7528 3D-GRAND \u9032\u884c\u6307\u4ee4\u8abf\u6574\u986f\u8457\u589e\u5f37\u4e86\u57fa\u790e\u80fd\u529b\uff0c\u4e26\u6e1b\u5c11\u4e86 3D-LLM \u4e2d\u7684\u5e7b\u89ba\u3002\u4f5c\u70ba\u6211\u5011\u8ca2\u737b\u7684\u4e00\u90e8\u5206\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5168\u9762\u7684\u57fa\u6e96 3D-POPE\uff0c\u4ee5\u7cfb\u7d71\u5730\u8a55\u4f30 3D-LLM \u4e2d\u7684\u5e7b\u89ba\uff0c\u4f7f\u672a\u4f86\u7684\u6a21\u578b\u4e4b\u9593\u80fd\u5920\u9032\u884c\u516c\u5e73\u7684\u6bd4\u8f03\u3002\u6211\u5011\u7684\u5be6\u9a57\u5f37\u8abf\u4e86\u8cc7\u6599\u96c6\u5927\u5c0f\u548c 3D-LLM \u6027\u80fd\u4e4b\u9593\u7684\u898f\u6a21\u6548\u61c9\uff0c\u5f37\u8abf\u4e86\u5927\u898f\u6a21 3D-text \u8cc7\u6599\u96c6\u5728\u63a8\u9032\u5177\u8eab AI \u7814\u7a76\u4e2d\u7684\u95dc\u9375\u4f5c\u7528\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u7d50\u679c\u5c55\u793a\u4e86\u6709\u6548\u6a21\u64ec\u5230\u771f\u5be6\u50b3\u8f38\u7684\u65e9\u671f\u4fe1\u865f\uff0c\u8868\u660e\u5728\u5927\u578b\u5408\u6210\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u771f\u5be6\u4e16\u754c\u7684 3D \u6383\u63cf\u4e2d\u8868\u73fe\u826f\u597d\u3002\u900f\u904e 3D-GRAND \u548c 3D-POPE\uff0c\u6211\u5011\u65e8\u5728\u70ba\u5177\u8eab AI \u793e\u7fa4\u63d0\u4f9b\u5fc5\u8981\u7684\u8cc7\u6e90\u548c\u898b\u89e3\uff0c\u70ba\u66f4\u53ef\u9760\u4e14\u57fa\u790e\u66f4\u597d\u7684 3D-LLM \u5960\u5b9a\u57fa\u790e\u3002\u5c08\u6848\u7db2\u7ad9\uff1ahttps://3d-grand.github.io", "author": "Jianing Yang et.al.", "authors": "Jianing Yang, Xuweiyi Chen, Nikhil Madaan, Madhavan Iyengar, Shengyi Qian, David F. Fouhey, Joyce Chai", "id": "2406.05132v1", "paper_url": "http://arxiv.org/abs/2406.05132v1", "repo": "null"}}