{"2406.02537": {"publish_time": "2024-06-04", "title": "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners", "paper_summary": "Top-view perspective denotes a typical way in which humans read and reason\nover different types of maps, and it is vital for localization and navigation\nof humans as well as of `non-human' agents, such as the ones backed by large\nVision-Language Models (VLMs). Nonetheless, spatial reasoning capabilities of\nmodern VLMs remain unattested and underexplored. In this work, we thus study\ntheir capability to understand and reason over spatial relations from the top\nview. The focus on top view also enables controlled evaluations at different\ngranularity of spatial reasoning; we clearly disentangle different abilities\n(e.g., recognizing particular objects versus understanding their relative\npositions). We introduce the TopViewRS (Top-View Reasoning in Space) dataset,\nconsisting of 11,384 multiple-choice questions with either realistic or\nsemantic top-view map as visual input. We then use it to study and evaluate\nVLMs across 4 perception and reasoning tasks with different levels of\ncomplexity. Evaluation of 10 representative open- and closed-source VLMs\nreveals the gap of more than 50% compared to average human performance, and it\nis even lower than the random baseline in some cases. Although additional\nexperiments show that Chain-of-Thought reasoning can boost model capabilities\nby 5.82% on average, the overall performance of VLMs remains limited. Our\nfindings underscore the critical need for enhanced model capability in top-view\nspatial reasoning and set a foundation for further research towards human-level\nproficiency of VLMs in real-world multimodal tasks.", "paper_summary_zh": "<paragraph>\u81ea\u4e0a\u800c\u4e0b\u7684\u8996\u89d2\u8868\u793a\u4eba\u985e\u95b1\u8b80\u548c\u7406\u89e3\u4e0d\u540c\u985e\u578b\u5730\u5716\u7684\u5178\u578b\u65b9\u5f0f\uff0c\u5c0d\u65bc\u4eba\u985e\u4ee5\u53ca\u7531\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u652f\u63f4\u7684\u300c\u975e\u4eba\u985e\u300d\u4ee3\u7406\u4eba\u7684\u5b9a\u4f4d\u548c\u5c0e\u822a\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u73fe\u4ee3 VLM \u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u4ecd\u7136\u672a\u7d93\u8b49\u5be6\u4e14\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\u7814\u7a76\u4e86\u5b83\u5011\u5f9e\u81ea\u4e0a\u800c\u4e0b\u8996\u89d2\u7406\u89e3\u548c\u63a8\u8ad6\u7a7a\u9593\u95dc\u4fc2\u7684\u80fd\u529b\u3002\u5c08\u6ce8\u65bc\u81ea\u4e0a\u800c\u4e0b\u7684\u8996\u89d2\u4e5f\u80fd\u5728\u4e0d\u540c\u7684\u7a7a\u9593\u63a8\u7406\u7c92\u5ea6\u4e0b\u9032\u884c\u53d7\u63a7\u8a55\u4f30\uff1b\u6211\u5011\u6e05\u695a\u5730\u5340\u5206\u4e86\u4e0d\u540c\u7684\u80fd\u529b\uff08\u4f8b\u5982\uff0c\u8fa8\u8b58\u7279\u5b9a\u7269\u4ef6\u8207\u7406\u89e3\u5b83\u5011\u7684\u76f8\u5c0d\u4f4d\u7f6e\uff09\u3002\u6211\u5011\u5f15\u5165\u4e86 TopViewRS\uff08\u7a7a\u9593\u4e2d\u7684\u81ea\u4e0a\u800c\u4e0b\u63a8\u7406\uff09\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 11,384 \u500b\u591a\u9078\u984c\uff0c\u4e26\u4ee5\u903c\u771f\u7684\u6216\u8a9e\u7fa9\u81ea\u4e0a\u800c\u4e0b\u5730\u5716\u4f5c\u70ba\u8996\u89ba\u8f38\u5165\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u5b83\u4f86\u7814\u7a76\u548c\u8a55\u4f30 VLM \u5728 4 \u500b\u4e0d\u540c\u8907\u96dc\u7a0b\u5ea6\u7684\u611f\u77e5\u548c\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u3002\u5c0d 10 \u500b\u5177\u6709\u4ee3\u8868\u6027\u7684\u958b\u6e90\u548c\u9589\u6e90 VLM \u7684\u8a55\u4f30\u986f\u793a\uff0c\u8207\u4eba\u985e\u7684\u5e73\u5747\u8868\u73fe\u76f8\u6bd4\uff0c\u5dee\u8ddd\u8d85\u904e 50%\uff0c\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u751a\u81f3\u4f4e\u65bc\u96a8\u6a5f\u57fa\u6e96\u3002\u5118\u7ba1\u984d\u5916\u7684\u5be6\u9a57\u8868\u660e\uff0c\u601d\u8003\u93c8\u63a8\u7406\u53ef\u4ee5\u5c07\u6a21\u578b\u80fd\u529b\u5e73\u5747\u63d0\u9ad8 5.82%\uff0c\u4f46 VLM \u7684\u6574\u9ad4\u8868\u73fe\u4ecd\u7136\u6709\u9650\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\u4e86\u589e\u5f37\u81ea\u4e0a\u800c\u4e0b\u7a7a\u9593\u63a8\u7406\u6a21\u578b\u80fd\u529b\u7684\u95dc\u9375\u9700\u6c42\uff0c\u4e26\u70ba VLM \u5728\u73fe\u5be6\u4e16\u754c\u591a\u6a21\u614b\u4efb\u52d9\u4e2d\u9054\u5230\u4eba\u985e\u6c34\u6e96\u7684\u719f\u7df4\u5ea6\u5960\u5b9a\u4e86\u9032\u4e00\u6b65\u7814\u7a76\u7684\u57fa\u790e\u3002</paragraph>", "author": "Chengzu Li et.al.", "authors": "Chengzu Li, Caiqi Zhang, Han Zhou, Nigel Collier, Anna Korhonen, Ivan Vuli\u0107", "id": "2406.02537v1", "paper_url": "http://arxiv.org/abs/2406.02537v1", "repo": "null"}}