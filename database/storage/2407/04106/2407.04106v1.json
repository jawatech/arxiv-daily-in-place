{"2407.04106": {"publish_time": "2024-07-04", "title": "MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis", "paper_summary": "Recent advancements in artificial intelligence (AI) have precipitated\nsignificant breakthroughs in healthcare, particularly in refining diagnostic\nprocedures. However, previous studies have often been constrained to limited\nfunctionalities. This study introduces MiniGPT-Med, a vision-language model\nderived from large-scale language models and tailored for medical applications.\nMiniGPT-Med demonstrates remarkable versatility across various imaging\nmodalities, including X-rays, CT scans, and MRIs, enhancing its utility. The\nmodel is capable of performing tasks such as medical report generation, visual\nquestion answering (VQA), and disease identification within medical imagery.\nIts integrated processing of both image and textual clinical data markedly\nimproves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's\nsuperior performance in disease grounding, medical report generation, and VQA\nbenchmarks, representing a significant step towards reducing the gap in\nassisting radiology practice. Furthermore, it achieves state-of-the-art\nperformance on medical report generation, higher than the previous best model\nby 19\\% accuracy. MiniGPT-Med promises to become a general interface for\nradiology diagnoses, enhancing diagnostic efficiency across a wide range of\nmedical imaging applications.", "paper_summary_zh": "\u96a8\u8457\u4eba\u5de5\u667a\u6167 (AI) \u7684\u6700\u65b0\u9032\u5c55\uff0c\u91ab\u7642\u4fdd\u5065\u9818\u57df\u51fa\u73fe\u4e86\u986f\u8457\u7684\u7a81\u7834\uff0c\u7279\u5225\u662f\u5728\u6539\u5584\u8a3a\u65b7\u7a0b\u5e8f\u65b9\u9762\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u7814\u7a76\u901a\u5e38\u50c5\u9650\u65bc\u6709\u9650\u7684\u529f\u80fd\u3002\u9019\u9805\u7814\u7a76\u5f15\u5165\u4e86 MiniGPT-Med\uff0c\u9019\u662f\u4e00\u7a2e\u6e90\u81ea\u5927\u898f\u6a21\u8a9e\u8a00\u6a21\u578b\u4e14\u5c08\u70ba\u91ab\u7642\u61c9\u7528\u800c\u8a2d\u8a08\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u3002MiniGPT-Med \u5728\u5404\u7a2e\u5f71\u50cf\u6a21\u5f0f\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u591a\u529f\u80fd\u6027\uff0c\u5305\u62ec X \u5149\u3001\u96fb\u8166\u65b7\u5c64\u6383\u63cf\u548c MRI\uff0c\u9032\u800c\u589e\u5f37\u5176\u6548\u7528\u3002\u8a72\u6a21\u578b\u80fd\u5920\u57f7\u884c\u8af8\u5982\u91ab\u7642\u5831\u544a\u751f\u6210\u3001\u8996\u89ba\u554f\u7b54 (VQA) \u548c\u91ab\u7642\u5f71\u50cf\u4e2d\u7684\u75be\u75c5\u8b58\u5225\u7b49\u4efb\u52d9\u3002\u5b83\u5c07\u5f71\u50cf\u548c\u6587\u5b57\u81e8\u5e8a\u8cc7\u6599\u6574\u5408\u8655\u7406\uff0c\u986f\u8457\u63d0\u9ad8\u4e86\u8a3a\u65b7\u6e96\u78ba\u6027\u3002\u6211\u5011\u7684\u5be6\u8b49\u8a55\u4f30\u8b49\u5be6\u4e86 MiniGPT-Med \u5728\u75be\u75c5\u57fa\u790e\u3001\u91ab\u7642\u5831\u544a\u751f\u6210\u548c VQA \u57fa\u6e96\u4e0a\u7684\u512a\u7570\u8868\u73fe\uff0c\u9019\u4ee3\u8868\u4e86\u7e2e\u5c0f\u5354\u52a9\u653e\u5c04\u8a3a\u65b7\u5be6\u52d9\u5dee\u8ddd\u7684\u91cd\u8981\u4e00\u6b65\u3002\u6b64\u5916\uff0c\u5b83\u5728\u91ab\u7642\u5831\u544a\u751f\u6210\u65b9\u9762\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u8868\u73fe\uff0c\u6bd4\u5148\u524d\u7684\u6700\u4f73\u6a21\u578b\u9ad8\u51fa 19% \u7684\u6e96\u78ba\u5ea6\u3002MiniGPT-Med \u6709\u671b\u6210\u70ba\u653e\u5c04\u8a3a\u65b7\u7684\u901a\u7528\u4ecb\u9762\uff0c\u9032\u800c\u63d0\u5347\u5404\u7a2e\u91ab\u7642\u5f71\u50cf\u61c9\u7528\u4e2d\u7684\u8a3a\u65b7\u6548\u7387\u3002", "author": "Asma Alkhaldi et.al.", "authors": "Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny", "id": "2407.04106v1", "paper_url": "http://arxiv.org/abs/2407.04106v1", "repo": "null"}}