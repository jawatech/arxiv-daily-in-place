{"2410.13604": {"publish_time": "2024-10-17", "title": "Large Language Models as Narrative-Driven Recommenders", "paper_summary": "Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.", "paper_summary_zh": "<paragraph>\u4ee5\u6558\u4e8b\u70ba\u4e3b\u7684\u63a8\u85a6\u7cfb\u7d71\u65e8\u5728\u70ba\u300c\u6211\u60f3\u770b\u4e00\u90e8\u60c5\u7bc0\u66f2\u6298\u96e2\u5947\u7684\u9a5a\u609a\u7247\uff0c\u50cf\u662f\u300a\u9694\u96e2\u5cf6\u300b\u300d\u7b49\u4ee5\u81ea\u7531\u5f62\u5f0f\u6587\u5b57\u8868\u9054\u7684\u4f7f\u7528\u8005\u8981\u6c42\u63d0\u4f9b\u500b\u4eba\u5316\u5efa\u8b70\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u88ab\u8b49\u660e\u64c5\u9577\u8655\u7406\u4e00\u822c\u81ea\u7136\u8a9e\u8a00\u67e5\u8a62\uff0c\u4f46\u5b83\u5011\u5728\u8655\u7406\u6b64\u985e\u63a8\u85a6\u8981\u6c42\u65b9\u9762\u7684\u6548\u80fd\u4ecd\u76f8\u5c0d\u672a\u7d93\u63a2\u8a0e\u3002\u70ba\u4e86\u7e2e\u5c0f\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5728\u96fb\u5f71\u63a8\u85a6\u8a2d\u5b9a\u4e2d\u6bd4\u8f03\u4e86 38 \u500b\u4e0d\u540c\u898f\u6a21\u7684\u958b\u653e\u548c\u9589\u6e90 LLM \u7684\u6548\u80fd\uff0c\u4f8b\u5982 LLama 3.2 \u548c GPT-4o\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5229\u7528 Reddit \u96fb\u5f71\u5efa\u8b70\u793e\u7fa4\u7684\u8cbc\u6587\u5f59\u7de8\u800c\u6210\u7684\u9ec3\u91d1\u6a19\u6e96\u3001\u7fa4\u773e\u5de5\u4f5c\u8005\u8a3b\u89e3\u7684\u8cc7\u6599\u96c6\uff0c\u4e26\u63a1\u7528\u5404\u7a2e\u63d0\u793a\u7b56\u7565\uff0c\u5305\u62ec\u96f6\u6b21\u5b78\u7fd2\u3001\u8eab\u5206\u548c\u5c11\u6b21\u5b78\u7fd2\u63d0\u793a\u3002\u6211\u5011\u7684\u767c\u73fe\u8b49\u660e\u4e86 LLM \u7522\u751f\u8207\u60c5\u5883\u76f8\u95dc\u7684\u96fb\u5f71\u63a8\u85a6\u7684\u80fd\u529b\uff0c\u986f\u8457\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982 doc2vec\u3002\u96d6\u7136\u6211\u5011\u767c\u73fe\u9589\u6e90\u548c\u5927\u578b\u53c3\u6578\u5316\u6a21\u578b\u901a\u5e38\u8868\u73fe\u6700\u4f73\uff0c\u4f46\u4e2d\u578b\u958b\u653e\u6e90\u78bc\u6a21\u578b\u4ecd\u7136\u5177\u6709\u7af6\u722d\u529b\uff0c\u50c5\u7565\u905c\u65bc\u5b83\u5011\u5728\u904b\u7b97\u4e0a\u8f03\u6602\u8cb4\u7684\u5c0d\u61c9\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u5927\u591a\u6578\u6a21\u578b\u5728\u63d0\u793a\u7b56\u7565\u4e0a\u6c92\u6709\u986f\u8457\u5dee\u7570\uff0c\u9019\u5f37\u8abf\u4e86\u96f6\u6b21\u5b78\u7fd2\u63d0\u793a\u7b49\u7c21\u55ae\u65b9\u6cd5\u5728\u4ee5\u6558\u4e8b\u70ba\u4e3b\u7684\u63a8\u85a6\u4e2d\u7684\u6548\u80fd\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u9019\u9805\u5de5\u4f5c\u70ba\u63a8\u85a6\u7cfb\u7d71\u7814\u7a76\u4eba\u54e1\u548c\u65e8\u5728\u5c07 LLM \u6574\u5408\u5230\u5be6\u969b\u63a8\u85a6\u5de5\u5177\u4e2d\u7684\u5be6\u52d9\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\u3002</paragraph>", "author": "Lukas Eberhard et.al.", "authors": "Lukas Eberhard, Thorsten Ruprechter, Denis Helic", "id": "2410.13604v1", "paper_url": "http://arxiv.org/abs/2410.13604v1", "repo": "null"}}