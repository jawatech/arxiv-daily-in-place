{"2409.11272": {"publish_time": "2024-09-17", "title": "LOLA -- An Open-Source Massively Multilingual Large Language Model", "paper_summary": "This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.", "paper_summary_zh": "\u672c\u8ad6\u6587\u63d0\u51fa LOLA\uff0c\u4e00\u7a2e\u5927\u898f\u6a21\u591a\u8a9e\u8a00\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u7a00\u758f\u6df7\u5408\u5c08\u5bb6Transformer\u67b6\u69cb\uff0c\u91dd\u5c0d\u8d85\u904e 160 \u7a2e\u8a9e\u8a00\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u7684\u67b6\u69cb\u548c\u5be6\u4f5c\u9078\u64c7\uff0c\u89e3\u6c7a\u4e86\u5728\u7dad\u6301\u6548\u7387\u548c\u907f\u514d\u591a\u8a9e\u8a00\u5e38\u898b\u9677\u9631\u7684\u540c\u6642\uff0c\u5229\u7528\u8a9e\u8a00\u591a\u6a23\u6027\u7684\u6311\u6230\u3002\u6211\u5011\u5c0d\u8a55\u4f30\u7d50\u679c\u7684\u5206\u6790\uff0c\u986f\u793a\u5728\u81ea\u7136\u8a9e\u8a00\u751f\u6210\u548c\u7406\u89e3\u4efb\u52d9\u4e2d\u5177\u6709\u7af6\u722d\u529b\u7684\u8868\u73fe\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5b78\u7fd2\u5230\u7684\u5c08\u5bb6\u8def\u7531\u6a5f\u5236\uff0c\u5982\u4f55\u5229\u7528\u96b1\u542b\u7684\u7cfb\u7d71\u767c\u751f\u8a9e\u8a00\u6a21\u5f0f\uff0c\u4f86\u6f5b\u5728\u6e1b\u8f15\u591a\u8a9e\u8a00\u7684\u8a5b\u5492\u3002\u6211\u5011\u6df1\u5165\u63a2\u8a0e\u8a13\u7df4\u904e\u7a0b\u3001\u5c0d\u8cc7\u6599\u96c6\u7684\u5206\u6790\uff0c\u4ee5\u53ca\u5c0d\u6a21\u578b\u512a\u7f3a\u9ede\u7684\u5e73\u8861\u63a2\u8a0e\u3002\u4f5c\u70ba\u4e00\u500b\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\uff0cLOLA \u63a8\u5ee3\u53ef\u8907\u88fd\u6027\uff0c\u4e26\u4f5c\u70ba\u672a\u4f86\u7814\u7a76\u7684\u7a69\u56fa\u57fa\u790e\u3002\u6211\u5011\u7684\u767c\u73fe\uff0c\u4f7f\u958b\u767c\u51fa\u8de8\u8a9e\u8a00\u5177\u6709\u5f37\u5927\u3001\u53ef\u64f4\u5145\u6027\u80fd\u7684\u8a08\u7b97\u9ad8\u6548\u591a\u8a9e\u8a00\u6a21\u578b\u6210\u70ba\u53ef\u80fd\u3002", "author": "Nikit Srivastava et.al.", "authors": "Nikit Srivastava, Denis Kuchelev, Tatiana Moteu, Kshitij Shetty, Michael R\u00f6der, Diego Moussallem, Hamada Zahera, Axel-Cyrille Ngonga Ngomo", "id": "2409.11272v2", "paper_url": "http://arxiv.org/abs/2409.11272v2", "repo": "https://github.com/dice-group/lola"}}