{"2411.19335": {"publish_time": "2024-11-28", "title": "PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning", "paper_summary": "Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a\npromising paradigm for privacy-preserving and efficient adaptation of\nPre-trained Language Models (PLMs) in Federated Learning (FL) settings. It\npreserves data privacy by keeping the data decentralized and training the model\non local devices, ensuring that raw data never leaves the user's device.\nMoreover, the integration of PEFT methods such as LoRA significantly reduces\nthe number of trainable parameters compared to fine-tuning the entire model,\nthereby minimizing communication costs and computational overhead. Despite its\npotential, the security implications of FedPEFT remain underexplored. This\npaper introduces a novel security threat to FedPEFT, termed PEFT-as-an-Attack\n(PaaA), which exposes how PEFT can be exploited as an attack vector to\ncircumvent PLMs' safety alignment and generate harmful content in response to\nmalicious prompts. Our evaluation of PaaA reveals that with less than 1% of the\nmodel's parameters set as trainable, and a small subset of clients acting\nmaliciously, the attack achieves an approximate 80% attack success rate using\nrepresentative PEFT methods such as LoRA. To mitigate this threat, we further\ninvestigate potential defense strategies, including Robust Aggregation Schemes\n(RASs) and Post-PEFT Safety Alignment (PPSA). However, our empirical analysis\nhighlights the limitations of these defenses, i.e., even the most advanced\nRASs, such as DnC and ClippedClustering, struggle to defend against PaaA in\nscenarios with highly heterogeneous data distributions. Similarly, while PPSA\ncan reduce attack success rates to below 10%, it severely degrades the model's\naccuracy on the target task. Our results underscore the urgent need for more\neffective defense mechanisms that simultaneously ensure security and maintain\nthe performance of the FedPEFT paradigm.", "paper_summary_zh": "\u806f\u90a6\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (FedPEFT) \u5df2\u6210\u70ba\u806f\u90a6\u5b78\u7fd2 (FL) \u8a2d\u5b9a\u4e2d\u4e00\u7a2e\u6709\u524d\u9014\u7684\u7bc4\u4f8b\uff0c\u7528\u65bc\u96b1\u79c1\u4fdd\u8b77\u548c\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b (PLM) \u7684\u9ad8\u6548\u9069\u61c9\u3002\u5b83\u900f\u904e\u7dad\u6301\u8cc7\u6599\u5206\u6563\u5316\u548c\u5728\u672c\u5730\u88dd\u7f6e\u4e0a\u8a13\u7df4\u6a21\u578b\u4f86\u7dad\u8b77\u8cc7\u6599\u96b1\u79c1\uff0c\u78ba\u4fdd\u539f\u59cb\u8cc7\u6599\u7d55\u4e0d\u6703\u96e2\u958b\u4f7f\u7528\u8005\u7684\u88dd\u7f6e\u3002\u6b64\u5916\uff0c\u6574\u5408 LoRA \u7b49 PEFT \u65b9\u6cd5\u53ef\u5927\u5e45\u6e1b\u5c11\u53ef\u8a13\u7df4\u53c3\u6578\u7684\u6578\u91cf\uff0c\u8207\u5fae\u8abf\u6574\u500b\u6a21\u578b\u76f8\u6bd4\uff0c\u5f9e\u800c\u5c07\u901a\u8a0a\u6210\u672c\u548c\u904b\u7b97\u8ca0\u64d4\u964d\u81f3\u6700\u4f4e\u3002\u5118\u7ba1\u6709\u6f5b\u529b\uff0cFedPEFT \u7684\u5b89\u5168\u6027\u5f71\u97ff\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u8a0e\u3002\u672c\u6587\u4ecb\u7d39\u4e86 FedPEFT \u7684\u4e00\u7a2e\u65b0\u578b\u5b89\u5168\u5a01\u8105\uff0c\u7a31\u70ba PEFT \u4f5c\u70ba\u653b\u64ca (PaaA)\uff0c\u5b83\u63ed\u9732\u4e86 PEFT \u5982\u4f55\u88ab\u7576\u4f5c\u653b\u64ca\u5a92\u4ecb\uff0c\u7528\u4ee5\u898f\u907f PLM \u7684\u5b89\u5168\u6bd4\u5c0d\uff0c\u4e26\u6839\u64da\u60e1\u610f\u63d0\u793a\u7522\u751f\u6709\u5bb3\u5167\u5bb9\u3002\u6211\u5011\u5c0d PaaA \u7684\u8a55\u4f30\u986f\u793a\uff0c\u4f7f\u7528 LoRA \u7b49\u5177\u4ee3\u8868\u6027\u7684 PEFT \u65b9\u6cd5\uff0c\u5373\u4f7f\u53ea\u6709\u4e0d\u5230 1% \u7684\u6a21\u578b\u53c3\u6578\u8a2d\u5b9a\u70ba\u53ef\u8a13\u7df4\u53c3\u6578\uff0c\u4e14\u53ea\u6709\u5c11\u6578\u7528\u6236\u60e1\u610f\u884c\u4e8b\uff0c\u653b\u64ca\u4ecd\u53ef\u9054\u5230\u7d04 80% \u7684\u653b\u64ca\u6210\u529f\u7387\u3002\u70ba\u4e86\u6e1b\u8f15\u6b64\u5a01\u8105\uff0c\u6211\u5011\u9032\u4e00\u6b65\u63a2\u8a0e\u6f5b\u5728\u7684\u9632\u79a6\u7b56\u7565\uff0c\u5305\u62ec\u7a69\u5065\u805a\u5408\u65b9\u6848 (RAS) \u548c PEFT \u5f8c\u5b89\u5168\u6bd4\u5c0d (PPSA)\u3002\u7136\u800c\uff0c\u6211\u5011\u7684\u5be6\u8b49\u5206\u6790\u7a81\u986f\u4e86\u9019\u4e9b\u9632\u79a6\u7684\u9650\u5236\uff0c\u4ea6\u5373\uff0c\u5373\u4f7f\u662f\u6700\u5148\u9032\u7684 RAS\uff0c\u4f8b\u5982 DnC \u548c ClippedClustering\uff0c\u5728\u8cc7\u6599\u5206\u4f48\u9ad8\u5ea6\u7570\u8cea\u5316\u7684\u60c5\u6cc1\u4e0b\uff0c\u4e5f\u5f88\u96e3\u62b5\u79a6 PaaA\u3002\u540c\u6a23\u5730\uff0c\u96d6\u7136 PPSA \u53ef\u4ee5\u5c07\u653b\u64ca\u6210\u529f\u7387\u964d\u4f4e\u5230 10% \u4ee5\u4e0b\uff0c\u4f46\u5b83\u6703\u56b4\u91cd\u964d\u4f4e\u6a21\u578b\u5728\u76ee\u6a19\u4efb\u52d9\u4e0a\u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u7d50\u679c\u5f37\u8abf\u4e86\u8feb\u5207\u9700\u8981\u66f4\u6709\u6548\u7684\u9632\u79a6\u6a5f\u5236\uff0c\u540c\u6642\u78ba\u4fdd\u5b89\u5168\u6027\u4e26\u7dad\u6301 FedPEFT \u7bc4\u4f8b\u7684\u6548\u80fd\u3002", "author": "Shenghui Li et.al.", "authors": "Shenghui Li, Edith C. -H. Ngai, Fanghua Ye, Thiemo Voigt", "id": "2411.19335v1", "paper_url": "http://arxiv.org/abs/2411.19335v1", "repo": "null"}}