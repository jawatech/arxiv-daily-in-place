{"2408.12326": {"publish_time": "2024-08-22", "title": "Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models", "paper_summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various machine learning (ML) tasks. Given the high costs of creating\nannotated datasets for supervised learning, LLMs offer a valuable alternative\nby enabling effective few-shot in-context learning. However, these models can\nproduce hallucinations, particularly in domains with incomplete knowledge.\nAdditionally, current methods for knowledge distillation using LLMs often\nstruggle to enhance the effectiveness of both teacher and student models. To\naddress these challenges, we introduce DualChecker, an innovative framework\ndesigned to mitigate hallucinations and improve the performance of both teacher\nand student models during knowledge distillation. DualChecker employs\nContextAligner to ensure that the context provided by teacher models aligns\nwith human labeling standards. It also features a dynamic checker system that\nenhances model interaction: one component re-prompts teacher models with more\ndetailed content when they show low confidence, and another identifies\nborderline cases from student models to refine the teaching templates. This\ninteractive process promotes continuous improvement and effective knowledge\ntransfer between the models. We evaluate DualChecker using a green innovation\ntextual dataset that includes binary, multiclass, and token classification\ntasks. The experimental results show that DualChecker significantly outperforms\nexisting state-of-the-art methods, achieving up to a 17% improvement in F1\nscore for teacher models and 10% for student models. Notably, student models\nfine-tuned with LLM predictions perform comparably to those fine-tuned with\nactual data, even in a challenging domain. We make all datasets, models, and\ncode from this research publicly available.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7a2e\u6a5f\u5668\u5b78\u7fd2 (ML) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u7531\u65bc\u5efa\u7acb\u6a19\u8a3b\u8cc7\u6599\u96c6\u4ee5\u9032\u884c\u76e3\u7763\u5f0f\u5b78\u7fd2\u7684\u6210\u672c\u5f88\u9ad8\uff0cLLM \u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u50f9\u503c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u65b9\u6cd5\u662f\u555f\u7528\u6709\u6548\u7684\u5c0f\u6a23\u672c\u60c5\u5883\u5b78\u7fd2\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u80fd\u6703\u7522\u751f\u5e7b\u89ba\uff0c\u7279\u5225\u662f\u5728\u77e5\u8b58\u4e0d\u5b8c\u6574\u7684\u9818\u57df\u4e2d\u3002\u6b64\u5916\uff0c\u76ee\u524d\u4f7f\u7528 LLM \u9032\u884c\u77e5\u8b58\u84b8\u993e\u7684\u65b9\u6cd5\u901a\u5e38\u96e3\u4ee5\u63d0\u5347\u6559\u5e2b\u548c\u5b78\u751f\u6a21\u578b\u7684\u6548\u80fd\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 DualChecker\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u65e8\u5728\u6e1b\u8f15\u5e7b\u89ba\u4e26\u5728\u77e5\u8b58\u84b8\u993e\u671f\u9593\u63d0\u5347\u6559\u5e2b\u548c\u5b78\u751f\u6a21\u578b\u7684\u6548\u80fd\u3002DualChecker \u4f7f\u7528 ContextAligner \u4f86\u78ba\u4fdd\u6559\u5e2b\u6a21\u578b\u63d0\u4f9b\u7684\u5167\u5bb9\u8207\u4eba\u985e\u6a19\u8a18\u6a19\u6e96\u4e00\u81f4\u3002\u5b83\u9084\u5177\u5099\u4e00\u500b\u52d5\u614b\u6aa2\u67e5\u5668\u7cfb\u7d71\uff0c\u53ef\u4ee5\u589e\u5f37\u6a21\u578b\u4e92\u52d5\uff1a\u4e00\u500b\u7d44\u4ef6\u6703\u5728\u6559\u5e2b\u6a21\u578b\u986f\u793a\u51fa\u4f4e\u4fe1\u5fc3\u6642\u91cd\u65b0\u63d0\u793a\u66f4\u8a73\u7d30\u7684\u5167\u5bb9\uff0c\u53e6\u4e00\u500b\u7d44\u4ef6\u6703\u5f9e\u5b78\u751f\u6a21\u578b\u4e2d\u627e\u51fa\u81e8\u754c\u6848\u4f8b\u4ee5\u6539\u5584\u6559\u5b78\u7bc4\u672c\u3002\u9019\u500b\u4e92\u52d5\u904e\u7a0b\u4fc3\u8fdb\u4e86\u6a21\u578b\u4e4b\u9593\u7684\u6301\u7e8c\u6539\u9032\u548c\u6709\u6548\u7684\u77e5\u8b58\u50b3\u905e\u3002\u6211\u5011\u4f7f\u7528\u5305\u542b\u4e8c\u5143\u3001\u591a\u985e\u548c\u6a19\u8a18\u5206\u985e\u4efb\u52d9\u7684\u7da0\u8272\u5275\u65b0\u6587\u672c\u8cc7\u6599\u96c6\u4f86\u8a55\u4f30 DualChecker\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cDualChecker \u7684\u8868\u73fe\u986f\u8457\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u65b9\u6cd5\uff0c\u6559\u5e2b\u6a21\u578b\u7684 F1 \u5206\u6578\u63d0\u5347\u4e86 17%\uff0c\u5b78\u751f\u6a21\u578b\u7684 F1 \u5206\u6578\u63d0\u5347\u4e86 10%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4f7f\u7528 LLM \u9810\u6e2c\u9032\u884c\u5fae\u8abf\u7684\u5b78\u751f\u6a21\u578b\u8868\u73fe\u8207\u4f7f\u7528\u5be6\u969b\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u7684\u5b78\u751f\u6a21\u578b\u76f8\u7576\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6230\u6027\u7684\u9818\u57df\u4e2d\u4e5f\u662f\u5982\u6b64\u3002\u6211\u5011\u516c\u958b\u4e86\u672c\u7814\u7a76\u4e2d\u6240\u6709\u7684\u8cc7\u6599\u96c6\u3001\u6a21\u578b\u548c\u7a0b\u5f0f\u78bc\u3002</paragraph>", "author": "Meiyun Wang et.al.", "authors": "Meiyun Wang, Masahiro Suzuki, Hiroki Sakaji, Kiyoshi Izumi", "id": "2408.12326v1", "paper_url": "http://arxiv.org/abs/2408.12326v1", "repo": "https://github.com/kirawang23/dualchecker"}}