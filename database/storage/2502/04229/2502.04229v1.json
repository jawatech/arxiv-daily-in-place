{"2502.04229": {"publish_time": "2025-02-06", "title": "Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data", "paper_summary": "Dataset distillation (DD) enhances training efficiency and reduces bandwidth\nby condensing large datasets into smaller synthetic ones. It enables models to\nachieve performance comparable to those trained on the raw full dataset and has\nbecome a widely adopted method for data sharing. However, security concerns in\nDD remain underexplored. Existing studies typically assume that malicious\nbehavior originates from dataset owners during the initial distillation\nprocess, where backdoors are injected into raw datasets. In contrast, this work\nis the first to address a more realistic and concerning threat: attackers may\nintercept the dataset distribution process, inject backdoors into the distilled\ndatasets, and redistribute them to users. While distilled datasets were\npreviously considered resistant to backdoor attacks, we demonstrate that they\nremain vulnerable to such attacks. Furthermore, we show that attackers do not\neven require access to any raw data to inject the backdoors successfully.\nSpecifically, our approach reconstructs conceptual archetypes for each class\nfrom the model trained on the distilled dataset. Backdoors are then injected\ninto these archetypes to update the distilled dataset. Moreover, we ensure the\nupdated dataset not only retains the backdoor but also preserves the original\noptimization trajectory, thus maintaining the knowledge of the raw dataset. To\nachieve this, a hybrid loss is designed to integrate backdoor information along\nthe benign optimization trajectory, ensuring that previously learned\ninformation is not forgotten. Extensive experiments demonstrate that distilled\ndatasets are highly vulnerable to backdoor attacks, with risks pervasive across\nvarious raw datasets, distillation methods, and downstream training strategies.\nMoreover, our attack method is efficient, capable of synthesizing a malicious\ndistilled dataset in under one minute in certain cases.", "paper_summary_zh": "<paragraph>\u8cc7\u6599\u96c6\u84b8\u993e (DD) \u900f\u904e\u5c07\u5927\u578b\u8cc7\u6599\u96c6\u6fc3\u7e2e\u6210\u8f03\u5c0f\u7684\u5408\u6210\u8cc7\u6599\u96c6\uff0c\u4f86\u63d0\u5347\u8a13\u7df4\u6548\u7387\u4e26\u6e1b\u5c11\u983b\u5bec\u3002\u5b83\u8b93\u6a21\u578b\u80fd\u5920\u9054\u5230\u8207\u5728\u539f\u59cb\u5b8c\u6574\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u76f8\u5ab2\u7f8e\u7684\u6548\u80fd\uff0c\u4e26\u5df2\u6210\u70ba\u8cc7\u6599\u5171\u4eab\u7684\u5ee3\u6cdb\u63a1\u7528\u65b9\u6cd5\u3002\u7136\u800c\uff0cDD \u4e2d\u7684\u5b89\u5168\u7591\u616e\u4ecd\u672a\u7372\u5f97\u5145\u5206\u63a2\u8a0e\u3002\u73fe\u6709\u7814\u7a76\u901a\u5e38\u5047\u8a2d\u60e1\u610f\u884c\u70ba\u6e90\u81ea\u65bc\u8cc7\u6599\u96c6\u64c1\u6709\u8005\u5728\u6700\u521d\u7684\u84b8\u993e\u904e\u7a0b\u4e2d\uff0c\u5c07\u5f8c\u9580\u6ce8\u5165\u539f\u59cb\u8cc7\u6599\u96c6\u3002\u76f8\u53cd\u5730\uff0c\u9019\u9805\u5de5\u4f5c\u9996\u6b21\u63a2\u8a0e\u4e00\u500b\u66f4\u5be6\u969b\u4e14\u4ee4\u4eba\u64d4\u6182\u7684\u5a01\u8105\uff1a\u653b\u64ca\u8005\u53ef\u80fd\u6514\u622a\u8cc7\u6599\u96c6\u5206\u767c\u6d41\u7a0b\uff0c\u5c07\u5f8c\u9580\u6ce8\u5165\u84b8\u993e\u8cc7\u6599\u96c6\uff0c\u4e26\u5c07\u5176\u91cd\u65b0\u5206\u767c\u7d66\u4f7f\u7528\u8005\u3002\u5118\u7ba1\u84b8\u993e\u8cc7\u6599\u96c6\u5148\u524d\u88ab\u8a8d\u70ba\u80fd\u62b5\u6297\u5f8c\u9580\u653b\u64ca\uff0c\u4f46\u6211\u5011\u8b49\u660e\u5b83\u5011\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u6b64\u985e\u653b\u64ca\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\u653b\u64ca\u8005\u751a\u81f3\u4e0d\u9700\u8981\u5b58\u53d6\u4efb\u4f55\u539f\u59cb\u8cc7\u6599\u5c31\u80fd\u6210\u529f\u6ce8\u5165\u5f8c\u9580\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u505a\u6cd5\u662f\u6839\u64da\u5728\u84b8\u993e\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\uff0c\u70ba\u6bcf\u500b\u985e\u5225\u91cd\u5efa\u6982\u5ff5\u539f\u578b\u3002\u7136\u5f8c\u5c07\u5f8c\u9580\u6ce8\u5165\u9019\u4e9b\u539f\u578b\uff0c\u4ee5\u66f4\u65b0\u84b8\u993e\u8cc7\u6599\u96c6\u3002\u6b64\u5916\uff0c\u6211\u5011\u78ba\u4fdd\u66f4\u65b0\u5f8c\u7684\u8cc7\u6599\u96c6\u4e0d\u50c5\u4fdd\u7559\u5f8c\u9580\uff0c\u9084\u4fdd\u7559\u539f\u59cb\u6700\u4f73\u5316\u8ecc\u8de1\uff0c\u5f9e\u800c\u7dad\u8b77\u539f\u59cb\u8cc7\u6599\u96c6\u7684\u77e5\u8b58\u3002\u70ba\u9054\u6210\u6b64\u76ee\u7684\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u6df7\u5408\u640d\u5931\u51fd\u6578\uff0c\u4ee5\u5c07\u5f8c\u9580\u8cc7\u8a0a\u6574\u5408\u5230\u826f\u6027\u6700\u4f73\u5316\u8ecc\u8de1\u4e2d\uff0c\u78ba\u4fdd\u5148\u524d\u5b78\u7fd2\u7684\u8cc7\u8a0a\u4e0d\u6703\u88ab\u907a\u5fd8\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u660e\u84b8\u993e\u8cc7\u6599\u96c6\u6975\u6613\u53d7\u5230\u5f8c\u9580\u653b\u64ca\uff0c\u98a8\u96aa\u666e\u904d\u5b58\u5728\u65bc\u5404\u7a2e\u539f\u59cb\u8cc7\u6599\u96c6\u3001\u84b8\u993e\u65b9\u6cd5\u548c\u4e0b\u6e38\u8a13\u7df4\u7b56\u7565\u4e2d\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u653b\u64ca\u65b9\u6cd5\u5f88\u6709\u6548\u7387\uff0c\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u80fd\u5920\u5728\u4e0d\u5230\u4e00\u5206\u9418\u7684\u6642\u9593\u5167\u5408\u6210\u60e1\u610f\u7684\u84b8\u993e\u8cc7\u6599\u96c6\u3002</paragraph>", "author": "Ziyuan Yang et.al.", "authors": "Ziyuan Yang, Ming Yan, Yi Zhang, Joey Tianyi Zhou", "id": "2502.04229v1", "paper_url": "http://arxiv.org/abs/2502.04229v1", "repo": "null"}}