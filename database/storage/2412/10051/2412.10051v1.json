{"2412.10051": {"publish_time": "2024-12-13", "title": "TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting from Sparse Views", "paper_summary": "Recent advances in Gaussian Splatting have significantly advanced the field,\nachieving both panoptic and interactive segmentation of 3D scenes. However,\nexisting methodologies often overlook the critical need for reconstructing\nspecified targets with complex structures from sparse views. To address this\nissue, we introduce TSGaussian, a novel framework that combines semantic\nconstraints with depth priors to avoid geometry degradation in challenging\nnovel view synthesis tasks. Our approach prioritizes computational resources on\ndesignated targets while minimizing background allocation. Bounding boxes from\nYOLOv9 serve as prompts for Segment Anything Model to generate 2D mask\npredictions, ensuring semantic accuracy and cost efficiency. TSGaussian\neffectively clusters 3D gaussians by introducing a compact identity encoding\nfor each Gaussian ellipsoid and incorporating 3D spatial consistency\nregularization. Leveraging these modules, we propose a pruning strategy to\neffectively reduce redundancy in 3D gaussians. Extensive experiments\ndemonstrate that TSGaussian outperforms state-of-the-art methods on three\nstandard datasets and a new challenging dataset we collected, achieving\nsuperior results in novel view synthesis of specific objects. Code is available\nat: https://github.com/leon2000-ai/TSGaussian.", "paper_summary_zh": "\u9ad8\u65af\u6563\u5c04\u7684\u6700\u65b0\u8fdb\u5c55\u663e\u8457\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5b9e\u73b0\u4e86 3D \u573a\u666f\u7684\u5168\u666f\u548c\u4ea4\u4e92\u5f0f\u5206\u5272\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u5ffd\u89c6\u4e86\u4ece\u7a00\u758f\u89c6\u56fe\u91cd\u5efa\u5177\u6709\u590d\u6742\u7ed3\u6784\u7684\u7279\u5b9a\u76ee\u6807\u7684\u5173\u952e\u9700\u6c42\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 TSGaussian\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5b83\u5c06\u8bed\u4e49\u7ea6\u675f\u4e0e\u6df1\u5ea6\u5148\u9a8c\u76f8\u7ed3\u5408\uff0c\u4ee5\u907f\u514d\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u65b0\u89c6\u56fe\u5408\u6210\u4efb\u52a1\u4e2d\u51e0\u4f55\u9000\u5316\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5c06\u8ba1\u7b97\u8d44\u6e90\u4f18\u5148\u5206\u914d\u7ed9\u6307\u5b9a\u76ee\u6807\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u80cc\u666f\u5206\u914d\u3002\u6765\u81ea YOLOv9 \u7684\u8fb9\u754c\u6846\u7528\u4f5c\u63d0\u793a\uff0c\u4ee5\u4f7f Segment Anything Model \u751f\u6210 2D \u63a9\u7801\u9884\u6d4b\uff0c\u786e\u4fdd\u8bed\u4e49\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u76ca\u3002TSGaussian \u901a\u8fc7\u4e3a\u6bcf\u4e2a\u9ad8\u65af\u692d\u7403\u4f53\u5f15\u5165\u7d27\u51d1\u7684\u8eab\u4efd\u7f16\u7801\u5e76\u7ed3\u5408 3D \u7a7a\u95f4\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u6709\u6548\u5730\u5bf9 3D \u9ad8\u65af\u8fdb\u884c\u805a\u7c7b\u3002\u5229\u7528\u8fd9\u4e9b\u6a21\u5757\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4fee\u526a\u7b56\u7565\uff0c\u4ee5\u6709\u6548\u51cf\u5c11 3D \u9ad8\u65af\u4e2d\u7684\u5197\u4f59\u3002\u5927\u91cf\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTSGaussian \u5728\u4e09\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u548c\u6211\u4eec\u6536\u96c6\u7684\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u65b0\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u7279\u5b9a\u5bf9\u8c61\u7684 novel view synthesis \u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u679c\u3002\u4ee3\u7801\u53ef\u4ece\u4ee5\u4e0b\u7f51\u5740\u83b7\u5f97\uff1ahttps://github.com/leon2000-ai/TSGaussian\u3002", "author": "Liang Zhao et.al.", "authors": "Liang Zhao, Zehan Bao, Yi Xie, Hong Chen, Yaohui Chen, Weifu Li", "id": "2412.10051v1", "paper_url": "http://arxiv.org/abs/2412.10051v1", "repo": "null"}}