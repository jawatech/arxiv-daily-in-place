{"2412.16108": {"publish_time": "2024-12-20", "title": "Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring", "paper_summary": "The integration of Large Vision-Language Models (LVLMs) such as OpenAI's\nGPT-4 Vision into various sectors has marked a significant evolution in the\nfield of artificial intelligence, particularly in the analysis and\ninterpretation of visual data. This paper explores the practical application of\nGPT-4 Vision in the construction industry, focusing on its capabilities in\nmonitoring and tracking the progress of construction projects. Utilizing\nhigh-resolution aerial imagery of construction sites, the study examines how\nGPT-4 Vision performs detailed scene analysis and tracks developmental changes\nover time. The findings demonstrate that while GPT-4 Vision is proficient in\nidentifying construction stages, materials, and machinery, it faces challenges\nwith precise object localization and segmentation. Despite these limitations,\nthe potential for future advancements in this technology is considerable. This\nresearch not only highlights the current state and opportunities of using LVLMs\nin construction but also discusses future directions for enhancing the model's\nutility through domain-specific training and integration with other computer\nvision techniques and digital twins.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5982 OpenAI \u7684 GPT-4 Vision \u6574\u5408\u5230\u5404\u500b\u9818\u57df\uff0c\u6a19\u8a8c\u8457\u4eba\u5de5\u667a\u6167\u9818\u57df\u7684\u91cd\u5927\u6f14\u9032\uff0c\u7279\u5225\u662f\u5728\u8996\u89ba\u8cc7\u6599\u7684\u5206\u6790\u548c\u8a6e\u91cb\u65b9\u9762\u3002\u672c\u6587\u63a2\u8a0e GPT-4 Vision \u5728\u5efa\u7bc9\u7522\u696d\u7684\u5be6\u969b\u61c9\u7528\uff0c\u91cd\u9ede\u5728\u65bc\u5176\u76e3\u63a7\u548c\u8ffd\u8e64\u5efa\u7bc9\u5c08\u6848\u9032\u5ea6\u7684\u80fd\u529b\u3002\u672c\u7814\u7a76\u5229\u7528\u5efa\u7bc9\u5de5\u5730\u7684\u89e3\u6790\u5ea6\u822a\u7167\u5f71\u50cf\uff0c\u63a2\u8a0e GPT-4 Vision \u5982\u4f55\u57f7\u884c\u8a73\u7d30\u5834\u666f\u5206\u6790\uff0c\u4e26\u8ffd\u8e64\u6642\u9593\u6f14\u9032\u7684\u8b8a\u5316\u3002\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u96d6\u7136 GPT-4 Vision \u80fd\u719f\u7df4\u5730\u8fa8\u8b58\u65bd\u5de5\u968e\u6bb5\u3001\u6750\u6599\u548c\u6a5f\u68b0\uff0c\u4f46\u5728\u7cbe\u78ba\u7684\u7269\u4ef6\u5b9a\u4f4d\u548c\u5206\u5272\u65b9\u9762\u4ecd\u6709\u6311\u6230\u3002\u5118\u7ba1\u6709\u9019\u4e9b\u9650\u5236\uff0c\u9019\u9805\u6280\u8853\u672a\u4f86\u9032\u5c55\u7684\u6f5b\u529b\u4ecd\u76f8\u7576\u53ef\u89c0\u3002\u672c\u7814\u7a76\u4e0d\u50c5\u91cd\u9ede\u8aaa\u660e LVLMs \u5728\u5efa\u7bc9\u696d\u7684\u73fe\u6cc1\u548c\u6a5f\u6703\uff0c\u4e5f\u8a0e\u8ad6\u4e86\u900f\u904e\u7279\u5b9a\u9818\u57df\u8a13\u7df4\u548c\u8207\u5176\u4ed6\u96fb\u8166\u8996\u89ba\u6280\u8853\u548c\u6578\u4f4d\u5206\u8eab\u6574\u5408\u4f86\u589e\u5f37\u6a21\u578b\u6548\u7528\u7684\u672a\u4f86\u65b9\u5411\u3002", "author": "Ahmet Bahaddin Ersoz et.al.", "authors": "Ahmet Bahaddin Ersoz", "id": "2412.16108v1", "paper_url": "http://arxiv.org/abs/2412.16108v1", "repo": "null"}}