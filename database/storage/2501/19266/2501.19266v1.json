{"2501.19266": {"publish_time": "2025-01-31", "title": "Jackpot! Alignment as a Maximal Lottery", "paper_summary": "Reinforcement Learning from Human Feedback (RLHF), the standard for aligning\nLarge Language Models (LLMs) with human values, is known to fail to satisfy\nproperties that are intuitively desirable, such as respecting the preferences\nof the majority \\cite{ge2024axioms}. To overcome these issues, we propose the\nuse of a probabilistic Social Choice rule called \\emph{maximal lotteries} as a\nreplacement for RLHF. We show that a family of alignment techniques, namely\nNash Learning from Human Feedback (NLHF) \\cite{munos2023nash} and variants,\napproximate maximal lottery outcomes and thus inherit its beneficial\nproperties.\n  We confirm experimentally that our proposed methodology handles situations\nthat arise when working with preferences more robustly than standard RLHF,\nincluding supporting the preferences of the majority, providing principled ways\nof handling non-transitivities in the preference data, and robustness to\nirrelevant alternatives. This results in systems that better incorporate human\nvalues and respect human intentions.", "paper_summary_zh": "\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF) \u662f\u8abf\u6574\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u50f9\u503c\u89c0\u7684\u6a19\u6e96\uff0c\u5df2\u77e5\u7121\u6cd5\u6eff\u8db3\u76f4\u89c0\u4e0a\u7406\u60f3\u7684\u5c6c\u6027\uff0c\u4f8b\u5982\u5c0a\u91cd\u5927\u591a\u6578\u4eba\u7684\u504f\u597d \\cite{ge2024axioms}\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u7a31\u70ba\u300c\u6700\u5927\u6a02\u900f\u300d\u7684\u6a5f\u7387\u6027\u793e\u6703\u9078\u64c7\u898f\u5247\uff0c\u4f5c\u70ba RLHF \u7684\u66ff\u4ee3\u65b9\u6848\u3002\u6211\u5011\u8b49\u660e\u4e86\u4e00\u7cfb\u5217\u8abf\u6574\u6280\u8853\uff0c\u5373\u4eba\u985e\u56de\u994b\u7d0d\u8a31\u5b78\u7fd2 (NLHF) \\cite{munos2023nash} \u53ca\u5176\u8b8a\u9ad4\uff0c\u8fd1\u4f3c\u65bc\u6700\u5927\u6a02\u900f\u7d50\u679c\uff0c\u56e0\u6b64\u7e7c\u627f\u4e86\u5176\u6709\u76ca\u5c6c\u6027\u3002\n\u6211\u5011\u900f\u904e\u5be6\u9a57\u78ba\u8a8d\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u6a19\u6e96 RLHF \u66f4\u7a69\u5065\u5730\u8655\u7406\u4f7f\u7528\u504f\u597d\u6642\u51fa\u73fe\u7684\u60c5\u6cc1\uff0c\u5305\u62ec\u652f\u6301\u5927\u591a\u6578\u4eba\u7684\u504f\u597d\u3001\u63d0\u4f9b\u8655\u7406\u504f\u597d\u8cc7\u6599\u4e2d\u975e\u905e\u79fb\u6027\u7684\u539f\u5247\u6027\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c0d\u7121\u95dc\u9078\u9805\u7684\u7a69\u5065\u6027\u3002\u9019\u6703\u7522\u751f\u66f4\u597d\u7684\u7d0d\u5165\u4eba\u985e\u50f9\u503c\u89c0\u4e26\u5c0a\u91cd\u4eba\u985e\u610f\u5716\u7684\u7cfb\u7d71\u3002", "author": "Roberto-Rafael Maura-Rivero et.al.", "authors": "Roberto-Rafael Maura-Rivero, Marc Lanctot, Francesco Visin, Kate Larson", "id": "2501.19266v1", "paper_url": "http://arxiv.org/abs/2501.19266v1", "repo": "null"}}