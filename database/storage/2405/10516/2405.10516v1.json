{"2405.10516": {"publish_time": "2024-05-17", "title": "Language Models can Evaluate Themselves via Probability Discrepancy", "paper_summary": "In this paper, we initiate our discussion by demonstrating how Large Language\nModels (LLMs), when tasked with responding to queries, display a more even\nprobability distribution in their answers if they are more adept, as opposed to\ntheir less skilled counterparts. Expanding on this foundational insight, we\npropose a new self-evaluation method ProbDiff for assessing the efficacy of\nvarious LLMs. This approach obviates the necessity for an additional evaluation\nmodel or the dependence on external, proprietary models like GPT-4 for\njudgment. It uniquely utilizes the LLMs being tested to compute the probability\ndiscrepancy between the initial response and its revised versions. A higher\ndiscrepancy for a given query between two LLMs indicates a relatively weaker\ncapability. Our findings reveal that ProbDiff achieves results on par with\nthose obtained from evaluations based on GPT-4, spanning a range of scenarios\nthat include natural language generation (NLG) tasks such as translation,\nsummarization, and our proposed Xiaohongshu blog writing task, and benchmarks\nfor LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of\nvarying magnitudes.", "paper_summary_zh": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5c55\u793a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u56de\u7b54\u67e5\u8a62\u6642\uff0c\u5982\u679c\u5b83\u5011\u66f4\u719f\u7df4\uff0c\u5247\u5176\u7b54\u6848\u7684\u6a5f\u7387\u5206\u4f48\u6703\u66f4\u5e73\u5747\uff0c\u8207\u6280\u80fd\u8f03\u5dee\u7684\u6a21\u578b\u76f8\u53cd\uff0c\u4f86\u958b\u555f\u6211\u5011\u7684\u8a0e\u8ad6\u3002\u5728\u9019\u500b\u57fa\u790e\u898b\u89e3\u7684\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u81ea\u6211\u8a55\u4f30\u65b9\u6cd5 ProbDiff\uff0c\u7528\u65bc\u8a55\u4f30\u5404\u7a2e LLM \u7684\u6548\u80fd\u3002\u9019\u7a2e\u65b9\u6cd5\u6d88\u9664\u4e86\u5c0d\u984d\u5916\u8a55\u4f30\u6a21\u578b\u6216\u4f9d\u8cf4\u65bc GPT-4 \u7b49\u5916\u90e8\u3001\u5c08\u6709\u6a21\u578b\u9032\u884c\u5224\u65b7\u7684\u5fc5\u8981\u6027\u3002\u5b83\u7368\u7279\u5730\u5229\u7528\u53d7\u6e2c\u7684 LLM \u4f86\u8a08\u7b97\u521d\u59cb\u56de\u61c9\u53ca\u5176\u4fee\u8a02\u7248\u672c\u4e4b\u9593\u7684\u6a5f\u7387\u5dee\u7570\u3002\u5c0d\u65bc\u7d66\u5b9a\u7684\u67e5\u8a62\uff0c\u5169\u500b LLM \u4e4b\u9593\u7684\u5dee\u7570\u8d8a\u5927\uff0c\u8868\u793a\u80fd\u529b\u76f8\u5c0d\u8f03\u5f31\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0cProbDiff \u9054\u5230\u4e86\u8207\u57fa\u65bc GPT-4 \u7684\u8a55\u4f30\u6240\u7372\u5f97\u7684\u7d50\u679c\u76f8\u7576\u7684\u7d50\u679c\uff0c\u6db5\u84cb\u4e86\u5404\u7a2e\u60c5\u5883\uff0c\u5305\u62ec\u81ea\u7136\u8a9e\u8a00\u751f\u6210 (NLG) \u4efb\u52d9\uff0c\u4f8b\u5982\u7ffb\u8b6f\u3001\u6458\u8981\u548c\u6211\u5011\u63d0\u51fa\u7684 Xiaohongshu \u90e8\u843d\u683c\u5beb\u4f5c\u4efb\u52d9\uff0c\u4ee5\u53ca\u8de8\u8d8a\u4e0d\u540c\u898f\u6a21 LLM \u7684 LLM \u8a55\u4f30\u57fa\u6e96\uff0c\u4f8b\u5982 AlignBench\u3001MT-Bench \u548c AlpacaEval\u3002", "author": "Tingyu Xia et.al.", "authors": "Tingyu Xia, Bowen Yu, Yuan Wu, Yi Chang, Chang Zhou", "id": "2405.10516v1", "paper_url": "http://arxiv.org/abs/2405.10516v1", "repo": "https://github.com/xiatingyu/probdiff"}}