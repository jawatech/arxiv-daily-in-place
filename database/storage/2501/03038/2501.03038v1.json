{"2501.03038": {"publish_time": "2025-01-06", "title": "Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders", "paper_summary": "Automatic Music Transcription (AMT), aiming to get musical notes from raw\naudio, typically uses frame-level systems with piano-roll outputs or language\nmodel (LM)-based systems with note-level predictions. However, frame-level\nsystems require manual thresholding, while the LM-based systems struggle with\nlong sequences. In this paper, we propose a hybrid method combining pre-trained\nroll-based encoders with an LM decoder to leverage the strengths of both\nmethods. Besides, our approach employs a hierarchical prediction strategy,\nfirst predicting onset and pitch, then velocity, and finally offset. The\nhierarchical prediction strategy reduces computational costs by breaking down\nlong sequences into different hierarchies. Evaluated on two benchmark\nroll-based encoders, our method outperforms traditional piano-roll outputs 0.01\nand 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a\nperformance-enhancing plug-in for arbitrary roll-based music transcription\nencoder. We release the code of this work at\nhttps://github.com/yongyizang/AMT_train.", "paper_summary_zh": "\u81ea\u52d5\u97f3\u6a02\u8f49\u9304 (AMT) \u65e8\u5728\u5f9e\u539f\u59cb\u97f3\u8a0a\u4e2d\u53d6\u5f97\u97f3\u7b26\uff0c\u901a\u5e38\u4f7f\u7528\u5e36\u6709\u92fc\u7434\u5377\u8ef8\u8f38\u51fa\u7684\u5e40\u7d1a\u7cfb\u7d71\u6216\u5e36\u6709\u97f3\u7b26\u7d1a\u9810\u6e2c\u7684\u57fa\u65bc\u8a9e\u8a00\u6a21\u578b (LM) \u7684\u7cfb\u7d71\u3002\u7136\u800c\uff0c\u5e40\u7d1a\u7cfb\u7d71\u9700\u8981\u624b\u52d5\u8a2d\u5b9a\u95be\u503c\uff0c\u800c\u57fa\u65bc LM \u7684\u7cfb\u7d71\u5247\u96e3\u4ee5\u8655\u7406\u9577\u5e8f\u5217\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u6df7\u5408\u65b9\u6cd5\uff0c\u5c07\u9810\u8a13\u7df4\u7684\u57fa\u65bc\u5377\u8ef8\u7684\u7de8\u78bc\u5668\u8207 LM \u89e3\u78bc\u5668\u7d50\u5408\u8d77\u4f86\uff0c\u4ee5\u5229\u7528\u5169\u7a2e\u65b9\u6cd5\u7684\u512a\u52e2\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u505a\u6cd5\u63a1\u7528\u4e86\u5206\u5c64\u9810\u6e2c\u7b56\u7565\uff0c\u9996\u5148\u9810\u6e2c\u8d77\u59cb\u548c\u97f3\u9ad8\uff0c\u7136\u5f8c\u9810\u6e2c\u901f\u5ea6\uff0c\u6700\u5f8c\u9810\u6e2c\u504f\u79fb\u3002\u5206\u5c64\u9810\u6e2c\u7b56\u7565\u901a\u904e\u5c07\u9577\u5e8f\u5217\u5206\u89e3\u70ba\u4e0d\u540c\u7684\u5c64\u6b21\u7d50\u69cb\u4f86\u964d\u4f4e\u904b\u7b97\u6210\u672c\u3002\u5728\u5169\u500b\u57fa\u6e96\u5377\u8ef8\u7de8\u78bc\u5668\u4e0a\u9032\u884c\u8a55\u4f30\u5f8c\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u8d77\u59cb-\u504f\u79fb-\u901f\u5ea6 F1 \u5206\u6578\u4e0a\u512a\u65bc\u50b3\u7d71\u7684\u92fc\u7434\u5377\u8ef8\u8f38\u51fa 0.01 \u548c 0.022\uff0c\u8b49\u660e\u4e86\u5176\u4f5c\u70ba\u4efb\u610f\u57fa\u65bc\u5377\u8ef8\u7684\u97f3\u6a02\u8f49\u9304\u7de8\u78bc\u5668\u7684\u6548\u80fd\u63d0\u5347\u5916\u639b\u7a0b\u5f0f\u4e4b\u6f5b\u529b\u3002\u6211\u5011\u5728 https://github.com/yongyizang/AMT_train \u4e0a\u767c\u5e03\u4e86\u9019\u9805\u5de5\u4f5c\u7684\u7a0b\u5f0f\u78bc\u3002", "author": "Dichucheng Li et.al.", "authors": "Dichucheng Li, Yongyi Zang, Qiuqiang Kong", "id": "2501.03038v1", "paper_url": "http://arxiv.org/abs/2501.03038v1", "repo": "null"}}