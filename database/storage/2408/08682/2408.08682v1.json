{"2408.08682": {"publish_time": "2024-08-16", "title": "LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression", "paper_summary": "The key to effective point cloud compression is to obtain a robust context\nmodel consistent with complex 3D data structures. Recently, the advancement of\nlarge language models (LLMs) has highlighted their capabilities not only as\npowerful generators for in-context learning and generation but also as\neffective compressors. These dual attributes of LLMs make them particularly\nwell-suited to meet the demands of data compression. Therefore, this paper\nexplores the potential of using LLM for compression tasks, focusing on lossless\npoint cloud geometry compression (PCGC) experiments. However, applying LLM\ndirectly to PCGC tasks presents some significant challenges, i.e., LLM does not\nunderstand the structure of the point cloud well, and it is a difficult task to\nfill the gap between text and point cloud through text description, especially\nfor large complicated and small shapeless point clouds. To address these\nproblems, we introduce a novel architecture, namely the Large Language\nModel-based Point Cloud Geometry Compression (LLM-PCGC) method, using LLM to\ncompress point cloud geometry information without any text description or\naligning operation. By utilizing different adaptation techniques for\ncross-modality representation alignment and semantic consistency, including\nclustering, K-tree, token mapping invariance, and Low Rank Adaptation (LoRA),\nthe proposed method can translate LLM to a compressor/generator for point\ncloud. To the best of our knowledge, this is the first structure to employ LLM\nas a compressor for point cloud data. Experiments demonstrate that the LLM-PCGC\noutperforms the other existing methods significantly, by achieving -40.213% bit\nrate reduction compared to the reference software of MPEG Geometry-based Point\nCloud Compression (G-PCC) standard, and by achieving -2.267% bit rate reduction\ncompared to the state-of-the-art learning-based method.", "paper_summary_zh": "\u8981\u6709\u6548\u58d3\u7e2e\u9ede\u96f2\uff0c\u95dc\u9375\u5728\u65bc\u53d6\u5f97\u8207\u8907\u96dc 3D \u8cc7\u6599\u7d50\u69cb\u4e00\u81f4\u7684\u7a69\u5065\u60c5\u5883\u6a21\u578b\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9032\u5c55\u7a81\u986f\u51fa\u5b83\u5011\u4e0d\u50c5\u4f5c\u70ba\u5f37\u5927\u7684\u7522\u751f\u5668\uff0c\u53ef\u7528\u65bc\u60c5\u5883\u5b78\u7fd2\u548c\u7522\u751f\uff0c\u9084\u80fd\u4f5c\u70ba\u6709\u6548\u7684\u58d3\u7e2e\u5668\u3002LLM \u7684\u9019\u4e9b\u96d9\u91cd\u5c6c\u6027\u4f7f\u5b83\u5011\u7279\u5225\u9069\u5408\u6eff\u8db3\u8cc7\u6599\u58d3\u7e2e\u7684\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u672c\u6587\u63a2\u8a0e\u4e86\u4f7f\u7528 LLM \u57f7\u884c\u58d3\u7e2e\u4efb\u52d9\u7684\u6f5b\u529b\uff0c\u91cd\u9ede\u5728\u65bc\u7121\u640d\u9ede\u96f2\u5e7e\u4f55\u58d3\u7e2e (PCGC) \u5be6\u9a57\u3002\u7136\u800c\uff0c\u5c07 LLM \u76f4\u63a5\u61c9\u7528\u65bc PCGC \u4efb\u52d9\u6703\u7522\u751f\u4e00\u4e9b\u91cd\u5927\u6311\u6230\uff0c\u4f8b\u5982 LLM \u4e0d\u4e86\u89e3\u9ede\u96f2\u7d50\u69cb\uff0c\u800c\u4e14\u900f\u904e\u6587\u5b57\u63cf\u8ff0\u4f86\u586b\u88dc\u6587\u5b57\u548c\u9ede\u96f2\u4e4b\u9593\u7684\u5dee\u8ddd\u662f\u4e00\u9805\u56f0\u96e3\u7684\u4efb\u52d9\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u5927\u578b\u8907\u96dc\u4e14\u7121\u5b9a\u5f62\u7684\u5c0f\u9ede\u96f2\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u5373\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u9ede\u96f2\u5e7e\u4f55\u58d3\u7e2e (LLM-PCGC) \u65b9\u6cd5\uff0c\u4f7f\u7528 LLM \u58d3\u7e2e\u9ede\u96f2\u5e7e\u4f55\u8cc7\u8a0a\uff0c\u800c\u7121\u9700\u4efb\u4f55\u6587\u5b57\u63cf\u8ff0\u6216\u5c0d\u9f4a\u64cd\u4f5c\u3002\u900f\u904e\u4f7f\u7528\u4e0d\u540c\u7684\u9069\u61c9\u6280\u8853\u4f86\u9032\u884c\u8de8\u6a21\u614b\u8868\u793a\u5c0d\u9f4a\u548c\u8a9e\u610f\u4e00\u81f4\u6027\uff0c\u5305\u62ec\u5206\u7fa4\u3001K \u6a39\u3001\u6a19\u8a18\u5c0d\u61c9\u4e0d\u8b8a\u6027\u548c\u4f4e\u79e9\u9069\u61c9 (LoRA)\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5c07 LLM \u8f49\u63db\u70ba\u9ede\u96f2\u7684\u58d3\u7e2e\u5668/\u7522\u751f\u5668\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5c07 LLM \u7528\u4f5c\u9ede\u96f2\u8cc7\u6599\u58d3\u7e2e\u5668\u7684\u7d50\u69cb\u3002\u5be6\u9a57\u8b49\u660e\uff0c\u8207 MPEG \u57fa\u65bc\u5e7e\u4f55\u7684\u9ede\u96f2\u58d3\u7e2e (G-PCC) \u6a19\u6e96\u7684\u53c3\u8003\u8edf\u9ad4\u76f8\u6bd4\uff0cLLM-PCGC \u7684\u4f4d\u5143\u7387\u964d\u4f4e\u4e86 -40.213%\uff0c\u8207\u6700\u5148\u9032\u7684\u57fa\u65bc\u5b78\u7fd2\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4f4d\u5143\u7387\u964d\u4f4e\u4e86 -2.267%\uff0c\u5927\u5e45\u512a\u65bc\u5176\u4ed6\u73fe\u6709\u65b9\u6cd5\u3002", "author": "Yuqi Ye et.al.", "authors": "Yuqi Ye, Wei Gao", "id": "2408.08682v1", "paper_url": "http://arxiv.org/abs/2408.08682v1", "repo": "null"}}