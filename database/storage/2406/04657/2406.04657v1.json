{"2406.04657": {"publish_time": "2024-06-07", "title": "Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise", "paper_summary": "Modern training strategies of deep neural networks (NNs) tend to induce a\nheavy-tailed (HT) spectra of layer weights. Extensive efforts to study this\nphenomenon have found that NNs with HT weight spectra tend to generalize well.\nA prevailing notion for the occurrence of such HT spectra attributes gradient\nnoise during training as a key contributing factor. Our work shows that\ngradient noise is unnecessary for generating HT weight spectra: two-layer NNs\ntrained with full-batch Gradient Descent/Adam can exhibit HT spectra in their\nweights after finite training steps. To this end, we first identify the scale\nof the learning rate at which one step of full-batch Adam can lead to feature\nlearning in the shallow NN, particularly when learning a single index teacher\nmodel. Next, we show that multiple optimizer steps with such (sufficiently)\nlarge learning rates can transition the bulk of the weight's spectra into an HT\ndistribution. To understand this behavior, we present a novel perspective based\non the singular vectors of the weight matrices and optimizer updates. We show\nthat the HT weight spectrum originates from the `spike', which is generated\nfrom feature learning and interacts with the main bulk to generate an HT\nspectrum. Finally, we analyze the correlations between the HT weight spectra\nand generalization after multiple optimizer updates with varying learning\nrates.", "paper_summary_zh": "\u73fe\u4ee3\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (NN) \u7684\u8a13\u7df4\u7b56\u7565\u50be\u5411\u65bc\u8a98\u767c\u5c64\u6b0a\u91cd\u7684\u91cd\u5c3e (HT) \u983b\u8b5c\u3002\u91dd\u5c0d\u6b64\u73fe\u8c61\u9032\u884c\u5ee3\u6cdb\u7814\u7a76\u767c\u73fe\uff0c\u5177\u6709 HT \u6b0a\u91cd\u983b\u8b5c\u7684 NN \u50be\u5411\u65bc\u6cdb\u5316\u826f\u597d\u3002\u5c0d\u65bc\u6b64\u985e HT \u983b\u8b5c\u767c\u751f\u7684\u666e\u904d\u6982\u5ff5\u5c07\u8a13\u7df4\u671f\u9593\u7684\u68af\u5ea6\u96dc\u8a0a\u6b78\u56e0\u65bc\u4e00\u500b\u95dc\u9375\u7684\u4fc3\u6210\u56e0\u7d20\u3002\u6211\u5011\u7684\u7814\u7a76\u8868\u660e\uff0c\u68af\u5ea6\u96dc\u8a0a\u5c0d\u65bc\u7522\u751f HT \u6b0a\u91cd\u983b\u8b5c\u4e26\u975e\u5fc5\u8981\uff1a\u4f7f\u7528\u5168\u6279\u6b21\u68af\u5ea6\u4e0b\u964d/Adam \u8a13\u7df4\u7684\u5169\u5c64 NN \u5728\u7d93\u904e\u6709\u9650\u7684\u8a13\u7df4\u6b65\u9a5f\u5f8c\uff0c\u5176\u6b0a\u91cd\u4e2d\u53ef\u80fd\u6703\u51fa\u73fe HT \u983b\u8b5c\u3002\u70ba\u6b64\uff0c\u6211\u5011\u9996\u5148\u627e\u51fa\u5168\u6279\u6b21 Adam \u7684\u4e00\u6b65\u53ef\u4ee5\u5c0e\u81f4\u6dfa\u5c64 NN \u4e2d\u7684\u7279\u5fb5\u5b78\u7fd2\u7684\u5b78\u7fd2\u7387\u898f\u6a21\uff0c\u7279\u5225\u662f\u5728\u5b78\u7fd2\u55ae\u4e00\u7d22\u5f15\u6559\u5e2b\u6a21\u578b\u6642\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5177\u6709\u6b64\u985e\uff08\u8db3\u5920\uff09\u5927\u5b78\u7fd2\u7387\u7684\u591a\u500b\u6700\u4f73\u5316\u6b65\u9a5f\u53ef\u4ee5\u5c07\u6b0a\u91cd\u983b\u8b5c\u7684\u5927\u90e8\u5206\u8f49\u63db\u70ba HT \u5206\u5e03\u3002\u70ba\u4e86\u7406\u89e3\u6b64\u884c\u70ba\uff0c\u6211\u5011\u6839\u64da\u6b0a\u91cd\u77e9\u9663\u548c\u6700\u4f73\u5316\u66f4\u65b0\u7684\u5947\u7570\u5411\u91cf\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u89c0\u9ede\u3002\u6211\u5011\u5c55\u793a\u4e86 HT \u6b0a\u91cd\u983b\u8b5c\u6e90\u81ea\u65bc\u300c\u5c16\u5cf0\u300d\uff0c\u8a72\u5c16\u5cf0\u662f\u7531\u7279\u5fb5\u5b78\u7fd2\u7522\u751f\u7684\uff0c\u4e26\u8207\u4e3b\u9ad4\u4ea4\u4e92\u4ee5\u7522\u751f HT \u983b\u8b5c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5206\u6790\u4e86\u5728\u5177\u6709\u4e0d\u540c\u5b78\u7fd2\u7387\u7684\u591a\u500b\u6700\u4f73\u5316\u66f4\u65b0\u5f8c\uff0cHT \u6b0a\u91cd\u983b\u8b5c\u8207\u6cdb\u5316\u4e4b\u9593\u7684\u95dc\u806f\u6027\u3002", "author": "Vignesh Kothapalli et.al.", "authors": "Vignesh Kothapalli, Tianyu Pang, Shenyang Deng, Zongmin Liu, Yaoqing Yang", "id": "2406.04657v1", "paper_url": "http://arxiv.org/abs/2406.04657v1", "repo": "null"}}