{"2409.00133": {"publish_time": "2024-08-29", "title": "A Survey for Large Language Models in Biomedicine", "paper_summary": "Recent breakthroughs in large language models (LLMs) offer unprecedented\nnatural language understanding and generation capabilities. However, existing\nsurveys on LLMs in biomedicine often focus on specific applications or model\narchitectures, lacking a comprehensive analysis that integrates the latest\nadvancements across various biomedical domains. This review, based on an\nanalysis of 484 publications sourced from databases including PubMed, Web of\nScience, and arXiv, provides an in-depth examination of the current landscape,\napplications, challenges, and prospects of LLMs in biomedicine, distinguishing\nitself by focusing on the practical implications of these models in real-world\nbiomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot\nlearning across a broad spectrum of biomedical tasks, including diagnostic\nassistance, drug discovery, and personalized medicine, among others, with\ninsights drawn from 137 key studies. Then, we discuss adaptation strategies of\nLLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to\nenhance their performance in specialized biomedical contexts where zero-shot\nfails to achieve, such as medical question answering and efficient processing\nof biomedical literature. Finally, we discuss the challenges that LLMs face in\nthe biomedicine domain including data privacy concerns, limited model\ninterpretability, issues with dataset quality, and ethics due to the sensitive\nnature of biomedical data, the need for highly reliable model outputs, and the\nethical implications of deploying AI in healthcare. To address these\nchallenges, we also identify future research directions of LLM in biomedicine\nincluding federated learning methods to preserve data privacy and integrating\nexplainable AI methodologies to enhance the transparency of LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u7a81\u7834\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002\u7136\u800c\uff0c\u73fe\u6709\u95dc\u65bc\u751f\u7269\u91ab\u5b78\u4e2d LLM \u7684\u8abf\u67e5\u901a\u5e38\u5c08\u6ce8\u65bc\u7279\u5b9a\u61c9\u7528\u6216\u6a21\u578b\u67b6\u69cb\uff0c\u7f3a\u4e4f\u6574\u5408\u5404\u7a2e\u751f\u7269\u91ab\u5b78\u9818\u57df\u6700\u65b0\u9032\u5c55\u7684\u5168\u9762\u5206\u6790\u3002\u672c\u7d9c\u8ff0\u57fa\u65bc\u5c0d\u4f86\u81ea PubMed\u3001Web of Science \u548c arXiv \u7b49\u6578\u64da\u5eab\u7684 484 \u7bc7\u51fa\u7248\u7269\u7684\u5206\u6790\uff0c\u6df1\u5165\u63a2\u8a0e\u4e86\u751f\u7269\u91ab\u5b78\u4e2d LLM \u7684\u7576\u524d\u73fe\u6cc1\u3001\u61c9\u7528\u3001\u6311\u6230\u548c\u524d\u666f\uff0c\u5176\u7279\u9ede\u662f\u95dc\u6ce8\u9019\u4e9b\u6a21\u578b\u5728\u73fe\u5be6\u4e16\u754c\u751f\u7269\u91ab\u5b78\u80cc\u666f\u4e2d\u7684\u5be6\u969b\u61c9\u7528\u3002\u9996\u5148\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u5728\u5ee3\u6cdb\u7684\u751f\u7269\u91ab\u5b78\u4efb\u52d9\u4e2d\u7684\u96f6\u6b21\u5b78\u7fd2\u80fd\u529b\uff0c\u5305\u62ec\u8a3a\u65b7\u8f14\u52a9\u3001\u85e5\u7269\u767c\u73fe\u548c\u500b\u6027\u5316\u91ab\u7642\u7b49\uff0c\u4e26\u5f9e 137 \u9805\u95dc\u9375\u7814\u7a76\u4e2d\u6c72\u53d6\u898b\u89e3\u3002\u7136\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86 LLM \u7684\u9069\u61c9\u7b56\u7565\uff0c\u5305\u62ec\u55ae\u6a21\u614b\u548c\u591a\u6a21\u614b LLM \u7684\u5fae\u8abf\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f37\u5b83\u5011\u5728\u96f6\u6b21\u5b78\u7fd2\u7121\u6cd5\u5be6\u73fe\u7684\u5c08\u696d\u751f\u7269\u91ab\u5b78\u80cc\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u4f8b\u5982\u91ab\u7642\u554f\u984c\u89e3\u7b54\u548c\u751f\u7269\u91ab\u5b78\u6587\u737b\u7684\u6709\u6548\u8655\u7406\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86 LLM \u5728\u751f\u7269\u91ab\u5b78\u9818\u57df\u9762\u81e8\u7684\u6311\u6230\uff0c\u5305\u62ec\u6578\u64da\u96b1\u79c1\u554f\u984c\u3001\u6a21\u578b\u53ef\u89e3\u91cb\u6027\u6709\u9650\u3001\u6578\u64da\u96c6\u8cea\u91cf\u554f\u984c\u4ee5\u53ca\u7531\u65bc\u751f\u7269\u91ab\u5b78\u6578\u64da\u7684\u654f\u611f\u6027\u3001\u5c0d\u9ad8\u5ea6\u53ef\u9760\u6a21\u578b\u8f38\u51fa\u7684\u9700\u6c42\u4ee5\u53ca\u5728\u91ab\u7642\u4fdd\u5065\u4e2d\u90e8\u7f72 AI \u7684\u502b\u7406\u5f71\u97ff\u800c\u7522\u751f\u7684\u502b\u7406\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u9084\u78ba\u5b9a\u4e86\u751f\u7269\u91ab\u5b78\u4e2d LLM \u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u7528\u65bc\u4fdd\u8b77\u6578\u64da\u96b1\u79c1\u7684\u806f\u5408\u5b78\u7fd2\u65b9\u6cd5\u4ee5\u53ca\u6574\u5408\u53ef\u89e3\u91cb AI \u65b9\u6cd5\u4ee5\u589e\u5f37 LLM \u7684\u900f\u660e\u5ea6\u3002", "author": "Chong Wang et.al.", "authors": "Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Li\u00f2, Tianyun Wang, Yu Guang Wang, Yiqing Shen", "id": "2409.00133v1", "paper_url": "http://arxiv.org/abs/2409.00133v1", "repo": "null"}}