{"2407.07011": {"publish_time": "2024-07-09", "title": "Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning", "paper_summary": "Large language models (LLMs) have shown a remarkable ability to learn and\nperform complex tasks through in-context learning (ICL). However, a\ncomprehensive understanding of its internal mechanisms is still lacking. This\npaper explores the role of induction heads in a few-shot ICL setting. We\nanalyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract\npattern recognition and NLP tasks. Our results show that even a minimal\nablation of induction heads leads to ICL performance decreases of up to ~32%\nfor abstract pattern recognition tasks, bringing the performance close to\nrandom. For NLP tasks, this ablation substantially decreases the model's\nability to benefit from examples, bringing few-shot ICL performance close to\nthat of zero-shot prompts. We further use attention knockout to disable\nspecific induction patterns, and present fine-grained evidence for the role\nthat the induction mechanism plays in ICL.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u900f\u904e\u60c5\u5883\u5b78\u7fd2 (ICL) \u5b78\u7fd2\u53ca\u57f7\u884c\u8907\u96dc\u4efb\u52d9\u7684\u5353\u8d8a\u80fd\u529b\u3002\u7136\u800c\uff0c\u6211\u5011\u5c0d\u5176\u5167\u90e8\u6a5f\u5236\u7684\u5168\u9762\u7406\u89e3\u4ecd\u6709\u4e0d\u8db3\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u5728\u5c11\u6b21\u6578 ICL \u8a2d\u5b9a\u4e2d\u6b78\u7d0d\u982d\u90e8\u7684\u4f5c\u7528\u3002\u6211\u5011\u5206\u6790\u4e86\u5169\u500b\u6700\u5148\u9032\u7684\u6a21\u578b\uff0c\u5373 Llama-3-8B \u548c InternLM2-20B\uff0c\u91dd\u5c0d\u62bd\u8c61\u6a21\u5f0f\u8b58\u5225\u548c NLP \u4efb\u52d9\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5373\u4f7f\u5c0d\u6b78\u7d0d\u982d\u90e8\u9032\u884c\u6700\u5c0f\u7684\u6d88\u878d\u4e5f\u6703\u5c0e\u81f4\u62bd\u8c61\u6a21\u5f0f\u8b58\u5225\u4efb\u52d9\u7684 ICL \u6548\u80fd\u964d\u4f4e\u591a\u9054 ~32%\uff0c\u4f7f\u6548\u80fd\u63a5\u8fd1\u96a8\u6a5f\u3002\u5c0d\u65bc NLP \u4efb\u52d9\uff0c\u9019\u7a2e\u6d88\u878d\u6703\u5927\u5e45\u964d\u4f4e\u6a21\u578b\u5f9e\u7bc4\u4f8b\u4e2d\u7372\u76ca\u7684\u80fd\u529b\uff0c\u4f7f\u5c11\u6b21\u6578 ICL \u6548\u80fd\u63a5\u8fd1\u96f6\u6b21\u6578\u63d0\u793a\u3002\u6211\u5011\u9032\u4e00\u6b65\u4f7f\u7528\u6ce8\u610f\u529b\u4e2d\u65b7\u4f86\u505c\u7528\u7279\u5b9a\u7684\u6b78\u7d0d\u6a21\u5f0f\uff0c\u4e26\u63d0\u51fa\u5177\u9ad4\u8b49\u64da\u4f86\u8aaa\u660e\u6b78\u7d0d\u6a5f\u5236\u5728 ICL \u4e2d\u6240\u626e\u6f14\u7684\u89d2\u8272\u3002", "author": "J. Crosbie et.al.", "authors": "J. Crosbie, E. Shutova", "id": "2407.07011v1", "paper_url": "http://arxiv.org/abs/2407.07011v1", "repo": "null"}}