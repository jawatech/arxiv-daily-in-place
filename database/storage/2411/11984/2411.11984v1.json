{"2411.11984": {"publish_time": "2024-11-18", "title": "Understanding Chain-of-Thought in LLMs through Information Theory", "paper_summary": "Large Language Models (LLMs) have shown impressive performance in complex\nreasoning tasks through Chain-of-Thought (CoT) reasoning, allowing models to\nbreak down problems into manageable sub-tasks. However, existing CoT evaluation\ntechniques either require annotated CoT data or fall short in accurately\nassessing intermediate reasoning steps, leading to high rates of false\npositives. In this paper, we formalize CoT reasoning in LLMs through an\ninformation-theoretic lens. Specifically, our framework quantifies the\n`information gain' at each reasoning step, enabling the identification of\nfailure modes in LLMs without the need for expensive annotated datasets. We\ndemonstrate the efficacy of our approach through extensive experiments on toy\nand GSM-8K data, where it significantly outperforms existing outcome-based\nmethods by providing more accurate insights into model performance on\nindividual tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u900f\u904e\u601d\u8003\u93c8 (CoT) \u63a8\u7406\u5728\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u9a5a\u4eba\u7684\u6548\u80fd\uff0c\u8b93\u6a21\u578b\u80fd\u5c07\u554f\u984c\u5206\u89e3\u6210\u53ef\u7ba1\u7406\u7684\u5b50\u4efb\u52d9\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 CoT \u8a55\u4f30\u6280\u8853\u9700\u8981\u6a19\u8a18\u7684 CoT \u8cc7\u6599\uff0c\u6216\u7121\u6cd5\u6e96\u78ba\u8a55\u4f30\u4e2d\u9593\u63a8\u7406\u6b65\u9a5f\uff0c\u5c0e\u81f4\u5927\u91cf\u7684\u5047\u967d\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u8cc7\u8a0a\u7406\u8ad6\u7684\u89c0\u9ede\u5f62\u5f0f\u5316 LLM \u4e2d\u7684 CoT \u63a8\u7406\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u67b6\u69cb\u91cf\u5316\u4e86\u6bcf\u500b\u63a8\u7406\u6b65\u9a5f\u7684\u300c\u8cc7\u8a0a\u589e\u76ca\u300d\uff0c\u8b93\u7121\u9700\u6602\u8cb4\u7684\u6a19\u8a18\u8cc7\u6599\u96c6\u4e5f\u80fd\u627e\u51fa LLM \u7684\u5931\u6557\u6a21\u5f0f\u3002\u6211\u5011\u900f\u904e\u73a9\u5177\u548c GSM-8K \u8cc7\u6599\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6548\u80fd\uff0c\u5b83\u900f\u904e\u63d0\u4f9b\u66f4\u6e96\u78ba\u7684\u898b\u89e3\uff0c\u5728\u500b\u5225\u4efb\u52d9\u4e0a\u5927\u5e45\u512a\u65bc\u73fe\u6709\u7684\u57fa\u65bc\u7d50\u679c\u7684\u65b9\u6cd5\u3002", "author": "Jean-Francois Ton et.al.", "authors": "Jean-Francois Ton, Muhammad Faaiz Taufiq, Yang Liu", "id": "2411.11984v1", "paper_url": "http://arxiv.org/abs/2411.11984v1", "repo": "null"}}