{"2412.11990": {"publish_time": "2024-12-16", "title": "ExecRepoBench: Multi-level Executable Code Completion Evaluation", "paper_summary": "Code completion has become an essential tool for daily software development.\nExisting evaluation benchmarks often employ static methods that do not fully\ncapture the dynamic nature of real-world coding environments and face\nsignificant challenges, including limited context length, reliance on\nsuperficial evaluation metrics, and potential overfitting to training datasets.\nIn this work, we introduce a novel framework for enhancing code completion in\nsoftware development through the creation of a repository-level benchmark\nExecRepoBench and the instruction corpora Repo-Instruct, aim at improving the\nfunctionality of open-source large language models (LLMs) in real-world coding\nscenarios that involve complex interdependencies across multiple files.\nExecRepoBench includes 1.2K samples from active Python repositories. Plus, we\npresent a multi-level grammar-based completion methodology conditioned on the\nabstract syntax tree to mask code fragments at various logical units (e.g.\nstatements, expressions, and functions). Then, we fine-tune the open-source LLM\nwith 7B parameters on Repo-Instruct to produce a strong code completion\nbaseline model Qwen2.5-Coder-Instruct-C based on the open-source model.\nQwen2.5-Coder-Instruct-C is rigorously evaluated against existing benchmarks,\nincluding MultiPL-E and ExecRepoBench, which consistently outperforms prior\nbaselines across all programming languages. The deployment of \\ourmethod{} can\nbe used as a high-performance, local service for programming\ndevelopment\\footnote{\\url{https://execrepobench.github.io/}}.", "paper_summary_zh": "<paragraph>\u7a0b\u5f0f\u78bc\u88dc\u5168\u5df2\u6210\u70ba\u65e5\u5e38\u8edf\u9ad4\u958b\u767c\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u5de5\u5177\u3002\n\u73fe\u6709\u7684\u8a55\u4f30\u57fa\u6e96\u901a\u5e38\u63a1\u7528\u975c\u614b\u65b9\u6cd5\uff0c\u7121\u6cd5\u5145\u5206\u6355\u6349\u771f\u5be6\u4e16\u754c\u7de8\u78bc\u74b0\u5883\u7684\u52d5\u614b\u7279\u6027\uff0c\u4e26\u4e14\u9762\u81e8\u91cd\u5927\u6311\u6230\uff0c\u5305\u62ec\u53d7\u9650\u7684\u5167\u5bb9\u9577\u5ea6\u3001\u4f9d\u8cf4\u65bc\u6d6e\u9762\u7684\u8a55\u4f30\u6307\u6a19\uff0c\u4ee5\u53ca\u6f5b\u5728\u904e\u5ea6\u64ec\u5408\u8a13\u7df4\u8cc7\u6599\u96c6\u3002\n\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u900f\u904e\u5efa\u7acb\u5132\u5b58\u5eab\u5c64\u7d1a\u57fa\u6e96 ExecRepoBench \u548c\u6307\u4ee4\u8a9e\u6599\u5eab Repo-Instruct\uff0c\u4f86\u589e\u5f37\u8edf\u9ad4\u958b\u767c\u4e2d\u7684\u7a0b\u5f0f\u78bc\u88dc\u5168\uff0c\u65e8\u5728\u6539\u5584\u958b\u6e90\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6d89\u53ca\u591a\u500b\u6a94\u6848\u4e4b\u9593\u8907\u96dc\u76f8\u4e92\u4f9d\u8cf4\u95dc\u4fc2\u7684\u771f\u5be6\u4e16\u754c\u7de8\u78bc\u5834\u666f\u4e2d\u7684\u529f\u80fd\u3002\nExecRepoBench \u5305\u542b\u4f86\u81ea\u6d3b\u8e8d Python \u5132\u5b58\u5eab\u7684 1.2K \u500b\u7bc4\u4f8b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u591a\u5c64\u7d1a\u57fa\u65bc\u8a9e\u6cd5\u7684\u88dc\u5168\u65b9\u6cd5\uff0c\u4ee5\u62bd\u8c61\u8a9e\u6cd5\u6a39\u70ba\u689d\u4ef6\uff0c\u5728\u5404\u7a2e\u908f\u8f2f\u55ae\u5143\uff08\u4f8b\u5982\u9673\u8ff0\u5f0f\u3001\u8868\u9054\u5f0f\u548c\u51fd\u5f0f\uff09\u906e\u7f69\u7a0b\u5f0f\u78bc\u7247\u6bb5\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528 Repo-Instruct \u5fae\u8abf\u5177\u6709 7B \u53c3\u6578\u7684\u958b\u6e90 LLM\uff0c\u4ee5\u5efa\u7acb\u4e00\u500b\u5f37\u5927\u7684\u7a0b\u5f0f\u78bc\u88dc\u5168\u57fa\u6e96\u6a21\u578b Qwen2.5-Coder-Instruct-C\uff0c\u8a72\u6a21\u578b\u57fa\u65bc\u958b\u6e90\u6a21\u578b\u3002\nQwen2.5-Coder-Instruct-C \u91dd\u5c0d\u73fe\u6709\u57fa\u6e96\u9032\u884c\u56b4\u683c\u8a55\u4f30\uff0c\u5305\u62ec MultiPL-E \u548c ExecRepoBench\uff0c\u5728\u6240\u6709\u7a0b\u5f0f\u8a9e\u8a00\u4e2d\u59cb\u7d42\u512a\u65bc\u5148\u524d\u7684\u57fa\u6e96\u3002\\ourmethod{} \u7684\u90e8\u7f72\u53ef\u4ee5\u7528\u4f5c\u7a0b\u5f0f\u958b\u767c\u7684\u9ad8\u6548\u80fd\u3001\u672c\u6a5f\u670d\u52d9\\footnote{\\url{https://execrepobench.github.io/}}\u3002</paragraph>", "author": "Jian Yang et.al.", "authors": "Jian Yang, Jiajun Zhang, Jiaxi Yang, Ke Jin, Lei Zhang, Qiyao Peng, Ken Deng, Yibo Miao, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin", "id": "2412.11990v1", "paper_url": "http://arxiv.org/abs/2412.11990v1", "repo": "null"}}