{"2405.14437": {"publish_time": "2024-05-23", "title": "Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models", "paper_summary": "Recently, using large pretrained Transformer models for transfer learning\ntasks has evolved to the point where they have become one of the flagship\ntrends in the Natural Language Processing (NLP) community, giving rise to\nvarious outlooks such as prompt-based, adapters or combinations with\nunsupervised approaches, among many others. This work proposes a 3 Phase\ntechnique to adjust a base model for a classification task. First, we adapt the\nmodel's signal to the data distribution by performing further training with a\nDenoising Autoencoder (DAE). Second, we adjust the representation space of the\noutput to the corresponding classes by clustering through a Contrastive\nLearning (CL) method. In addition, we introduce a new data augmentation\napproach for Supervised Contrastive Learning to correct the unbalanced\ndatasets. Third, we apply fine-tuning to delimit the predefined categories.\nThese different phases provide relevant and complementary knowledge to the\nmodel to learn the final task. We supply extensive experimental results on\nseveral datasets to demonstrate these claims. Moreover, we include an ablation\nstudy and compare the proposed method against other ways of combining these\ntechniques.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u4f7f\u7528\u5927\u578b\u9884\u8bad\u7ec3 Transformer \u6a21\u578b\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u7684\u4efb\u52a1\u5df2\u7ecf\u53d1\u5c55\u5230\u6210\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406 (NLP) \u793e\u7fa4\u4e2d\u65d7\u8230\u8d8b\u52bf\u4e4b\u4e00\u7684\u5730\u6b65\uff0c\u50ac\u751f\u4e86\u5404\u79cd\u5c55\u671b\uff0c\u4f8b\u5982\u57fa\u4e8e\u63d0\u793a\u3001\u9002\u914d\u5668\u6216\u4e0e\u65e0\u76d1\u7763\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u8fd8\u6709\u8bb8\u591a\u5176\u4ed6\u65b9\u6cd5\u3002\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd 3 \u9636\u6bb5\u6280\u672f\uff0c\u7528\u4e8e\u8c03\u6574\u57fa\u7840\u6a21\u578b\u4ee5\u8fdb\u884c\u5206\u7c7b\u4efb\u52a1\u3002\u9996\u5148\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668 (DAE) \u6267\u884c\u8fdb\u4e00\u6b65\u7684\u8bad\u7ec3\uff0c\u5c06\u6a21\u578b\u7684\u4fe1\u53f7\u8c03\u6574\u5230\u6570\u636e\u5206\u5e03\u3002\u5176\u6b21\uff0c\u6211\u4eec\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60 (CL) \u65b9\u6cd5\u8fdb\u884c\u805a\u7c7b\uff0c\u5c06\u8f93\u51fa\u7684\u8868\u793a\u7a7a\u95f4\u8c03\u6574\u5230\u76f8\u5e94\u7684\u7c7b\u522b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u6269\u5145\u65b9\u6cd5\uff0c\u7528\u4e8e\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ee5\u7ea0\u6b63\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u3002\u7b2c\u4e09\uff0c\u6211\u4eec\u5e94\u7528\u5fae\u8c03\u6765\u5212\u5b9a\u9884\u5b9a\u4e49\u7684\u7c7b\u522b\u3002\u8fd9\u4e9b\u4e0d\u540c\u7684\u9636\u6bb5\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e86\u76f8\u5173\u4e14\u4e92\u8865\u7684\u77e5\u8bc6\uff0c\u4ee5\u5b66\u4e60\u6700\u7ec8\u4efb\u52a1\u3002\u6211\u4eec\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4ee5\u8bc1\u660e\u8fd9\u4e9b\u8bf4\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5305\u62ec\u6d88\u878d\u7814\u7a76\uff0c\u5e76\u5c06\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0e\u7ed3\u5408\u8fd9\u4e9b\u6280\u672f\u7684\u5176\u4ed6\u65b9\u5f0f\u8fdb\u884c\u6bd4\u8f83\u3002", "author": "Alejo Lopez-Avila et.al.", "authors": "Alejo Lopez-Avila, V\u00edctor Su\u00e1rez-Paniagua", "id": "2405.14437v1", "paper_url": "http://arxiv.org/abs/2405.14437v1", "repo": "https://github.com/vsuarezpaniagua/3-phase_finetuning"}}