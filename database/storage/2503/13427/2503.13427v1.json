{"2503.13427": {"publish_time": "2025-03-17", "title": "xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference", "paper_summary": "Recent breakthroughs in solving reasoning, math and coding problems with\nLarge Language Models (LLMs) have been enabled by investing substantial\ncomputation budgets at inference time. Therefore, inference speed is one of the\nmost critical properties of LLM architectures, and there is a growing need for\nLLMs that are efficient and fast at inference. Recently, LLMs built on the\nxLSTM architecture have emerged as a powerful alternative to Transformers,\noffering linear compute scaling with sequence length and constant memory usage,\nboth highly desirable properties for efficient inference. However, such\nxLSTM-based LLMs have yet to be scaled to larger models and assessed and\ncompared with respect to inference speed and efficiency. In this work, we\nintroduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's\narchitectural benefits with targeted optimizations for fast and efficient\ninference. Our experiments demonstrate that xLSTM 7B achieves performance on\ndownstream tasks comparable to other similar-sized LLMs, while providing\nsignificantly faster inference speeds and greater efficiency compared to Llama-\nand Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most\nefficient 7B LLM, offering a solution for tasks that require large amounts of\ntest-time computation. Our work highlights xLSTM's potential as a foundational\narchitecture for methods building on heavy use of LLM inference. Our model\nweights, model code and training code are open-source.", "paper_summary_zh": "<paragraph>\u8fd1\u5e74\u4f86\uff0c\u85c9\u7531\u6295\u5165\u5927\u91cf\u7684\u63a8\u8ad6\u904b\u7b97\u8cc7\u6e90\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u89e3\u6c7a\u63a8\u7406\u3001\u6578\u5b78\u548c\u7de8\u78bc\u554f\u984c\u65b9\u9762\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u9032\u5c55\u3002\u56e0\u6b64\uff0c\u63a8\u8ad6\u901f\u5ea6\u662f LLM \u67b6\u69cb\u6700\u95dc\u9375\u7684\u7279\u6027\u4e4b\u4e00\uff0c\u800c\u4e14\u5c0d\u65bc\u9ad8\u6548\u5feb\u901f\u63a8\u8ad6\u7684 LLM \u7684\u9700\u6c42\u4e5f\u65e5\u76ca\u589e\u9577\u3002\u6700\u8fd1\uff0c\u57fa\u65bc xLSTM \u67b6\u69cb\u69cb\u5efa\u7684 LLM \u5df2\u6210\u70ba Transformer \u7684\u5f37\u5927\u66ff\u4ee3\u65b9\u6848\uff0c\u5b83\u5177\u6709\u7dda\u6027\u8a08\u7b97\u898f\u6a21\u5316\uff08\u8207\u5e8f\u5217\u9577\u5ea6\u76f8\u95dc\uff09\u548c\u6046\u5b9a\u5167\u5b58\u4f7f\u7528\u91cf\u7684\u7279\u6027\uff0c\u9019\u4e9b\u90fd\u662f\u9ad8\u6548\u63a8\u8ad6\u975e\u5e38\u9700\u8981\u7684\u7279\u6027\u3002\u7136\u800c\uff0c\u6b64\u985e\u57fa\u65bc xLSTM \u7684 LLM \u5c1a\u672a\u64f4\u5c55\u5230\u66f4\u5927\u7684\u6a21\u578b\uff0c\u4e5f\u5c1a\u672a\u5c31\u63a8\u8ad6\u901f\u5ea6\u548c\u6548\u7387\u9032\u884c\u8a55\u4f30\u548c\u6bd4\u8f03\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a8\u51fa\u4e86 xLSTM 7B\uff0c\u9019\u662f\u4e00\u500b 70 \u5104\u53c3\u6578\u7684 LLM\uff0c\u5b83\u7d50\u5408\u4e86 xLSTM \u7684\u67b6\u69cb\u512a\u52e2\u548c\u91dd\u5c0d\u5feb\u901f\u9ad8\u6548\u63a8\u8ad6\u7684\u76ee\u6a19\u512a\u5316\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cxLSTM 7B \u5728\u4e0b\u6e38\u4efb\u52d9\u4e0a\u7684\u6027\u80fd\u8207\u5176\u4ed6\u985e\u4f3c\u898f\u6a21\u7684 LLM \u76f8\u7576\uff0c\u540c\u6642\u8207\u57fa\u65bc Llama \u548c Mamba \u7684 LLM \u76f8\u6bd4\uff0c\u63d0\u4f9b\u4e86\u986f\u8457\u66f4\u5feb\u7684\u63a8\u8ad6\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u6548\u7387\u3002\u9019\u4e9b\u7d50\u679c\u78ba\u7acb\u4e86 xLSTM 7B \u4f5c\u70ba\u6700\u5feb\u3001\u6700\u9ad8\u6548\u7684 7B LLM \u7684\u5730\u4f4d\uff0c\u70ba\u9700\u8981\u5927\u91cf\u6e2c\u8a66\u6642\u9593\u8a08\u7b97\u7684\u4efb\u52d9\u63d0\u4f9b\u4e86\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u5de5\u4f5c\u7a81\u51fa\u4e86 xLSTM \u4f5c\u70ba\u5927\u91cf\u4f7f\u7528 LLM \u63a8\u8ad6\u4e4b\u65b9\u6cd5\u7684\u57fa\u790e\u67b6\u69cb\u7684\u6f5b\u529b\u3002\u6211\u5011\u7684\u6a21\u578b\u6b0a\u91cd\u3001\u6a21\u578b\u7a0b\u5f0f\u78bc\u548c\u8a13\u7df4\u7a0b\u5f0f\u78bc\u90fd\u662f\u958b\u6e90\u7684\u3002\n</paragraph>\n", "author": "Maximilian Beck et.al.", "authors": "Maximilian Beck, Korbinian P\u00f6ppel, Phillip Lippe, Richard Kurle, Patrick M. Blies, G\u00fcnter Klambauer, Sebastian B\u00f6ck, Sepp Hochreiter", "id": "2503.13427v1", "paper_url": "http://arxiv.org/abs/2503.13427v1", "repo": "null"}}