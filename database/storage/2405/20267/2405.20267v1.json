{"2405.20267": {"publish_time": "2024-05-30", "title": "Auto Arena of LLMs: Automating LLM Evaluations with Agent Peer-battles and Committee Discussions", "paper_summary": "As LLMs evolve on a daily basis, there is an urgent need for a trustworthy\nevaluation method that can provide robust evaluation results in a timely\nfashion. Currently, as static benchmarks are prone to contamination concerns,\nusers tend to trust human voting platforms, such as Chatbot Arena. However,\nhuman annotations require extensive manual efforts. To provide an automatic,\nrobust, and trustworthy evaluation framework, we innovatively propose the\nAuto-Arena of LLMs, which automates the entire evaluation process with LLM\nagents. Firstly, an examiner LLM devises queries. Then, a pair of candidate\nLLMs engage in a multi-round peer-battle around the query, during which the\nLLM's true performance gaps become visible. Finally, a committee of LLM judges\ncollectively discuss and determine the winner, which alleviates bias and\npromotes fairness. In our extensive experiment on the 17 newest LLMs,\nAuto-Arena shows the highest correlation with human preferences, providing a\npromising alternative to human evaluation platforms.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u6bcf\u5929\u90fd\u5728\u9032\u6b65\uff0c\u8feb\u5207\u9700\u8981\u4e00\u7a2e\u53ef\u4fe1\u8cf4\u7684\u8a55\u4f30\u65b9\u6cd5\uff0c\u80fd\u5920\u53ca\u6642\u63d0\u4f9b\u7a69\u5065\u7684\u8a55\u4f30\u7d50\u679c\u3002\u76ee\u524d\uff0c\u7531\u65bc\u975c\u614b\u57fa\u6e96\u5bb9\u6613\u53d7\u5230\u6c61\u67d3\u554f\u984c\u7684\u5f71\u97ff\uff0c\u4f7f\u7528\u8005\u50be\u5411\u65bc\u4fe1\u4efb\u4eba\u985e\u6295\u7968\u5e73\u53f0\uff0c\u4f8b\u5982 Chatbot Arena\u3002\u7136\u800c\uff0c\u4eba\u985e\u6a19\u8a3b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\u3002\u70ba\u4e86\u63d0\u4f9b\u4e00\u500b\u81ea\u52d5\u5316\u3001\u7a69\u5065\u4e14\u53ef\u4fe1\u8cf4\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u6211\u5011\u5275\u65b0\u5730\u63d0\u51fa\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684 Auto-Arena\uff0c\u5b83\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4ee3\u7406\u81ea\u52d5\u5316\u6574\u500b\u8a55\u4f30\u904e\u7a0b\u3002\u9996\u5148\uff0c\u4e00\u500b\u5be9\u67e5\u54e1\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u8a2d\u8a08\u67e5\u8a62\u3002\u7136\u5f8c\uff0c\u4e00\u5c0d\u5019\u9078\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u570d\u7e5e\u67e5\u8a62\u9032\u884c\u591a\u8f2a\u9ede\u5c0d\u9ede\u6230\u9b25\uff0c\u5728\u6b64\u904e\u7a0b\u4e2d\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u771f\u5be6\u6027\u80fd\u5dee\u8ddd\u8b8a\u5f97\u660e\u986f\u3002\u6700\u5f8c\uff0c\u4e00\u500b\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7d44\u6210\u7684\u8a55\u5be9\u59d4\u54e1\u6703\u5171\u540c\u8a0e\u8ad6\u4e26\u78ba\u5b9a\u7372\u52dd\u8005\uff0c\u9019\u6e1b\u8f15\u4e86\u504f\u898b\u4e26\u4fc3\u9032\u4e86\u516c\u5e73\u6027\u3002\u5728\u6211\u5011\u5c0d 17 \u500b\u6700\u65b0\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u4e2d\uff0cAuto-Arena \u8207\u4eba\u985e\u504f\u597d\u7684\u76f8\u95dc\u6027\u6700\u9ad8\uff0c\u70ba\u4eba\u985e\u8a55\u4f30\u5e73\u53f0\u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u524d\u9014\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "author": "Ruochen Zhao et.al.", "authors": "Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Deli Zhao, Lidong Bing", "id": "2405.20267v1", "paper_url": "http://arxiv.org/abs/2405.20267v1", "repo": "null"}}