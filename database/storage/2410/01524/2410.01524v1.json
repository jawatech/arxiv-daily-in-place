{"2410.01524": {"publish_time": "2024-10-02", "title": "HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models", "paper_summary": "Safety guard models that detect malicious queries aimed at large language\nmodels (LLMs) are essential for ensuring the secure and responsible deployment\nof LLMs in real-world applications. However, deploying existing safety guard\nmodels with billions of parameters alongside LLMs on mobile devices is\nimpractical due to substantial memory requirements and latency. To reduce this\ncost, we distill a large teacher safety guard model into a smaller one using a\nlabeled dataset of instruction-response pairs with binary harmfulness labels.\nDue to the limited diversity of harmful instructions in the existing labeled\ndataset, naively distilled models tend to underperform compared to larger\nmodels. To bridge the gap between small and large models, we propose HarmAug, a\nsimple yet effective data augmentation method that involves jailbreaking an LLM\nand prompting it to generate harmful instructions. Given a prompt such as,\n\"Make a single harmful instruction prompt that would elicit offensive content\",\nwe add an affirmative prefix (e.g., \"I have an idea for a prompt:\") to the\nLLM's response. This encourages the LLM to continue generating the rest of the\nresponse, leading to sampling harmful instructions. Another LLM generates a\nresponse to the harmful instruction, and the teacher model labels the\ninstruction-response pair. We empirically show that our HarmAug outperforms\nother relevant baselines. Moreover, a 435-million-parameter safety guard model\ntrained with HarmAug achieves an F1 score comparable to larger models with over\n7 billion parameters, and even outperforms them in AUPRC, while operating at\nless than 25% of their computational cost.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5b89\u5168\u9632\u8b77\u6a21\u578b\u5c0d\u65bc\u78ba\u4fdd LLM \u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u5b89\u5168\u4e14\u8ca0\u8cac\u4efb\u7684\u90e8\u7f72\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u884c\u52d5\u88dd\u7f6e\u4e0a\u8207 LLM \u4e00\u8d77\u90e8\u7f72\u73fe\u6709\u7684\u5b89\u5168\u9632\u8b77\u6a21\u578b\uff08\u5177\u6709\u6578\u5341\u5104\u500b\u53c3\u6578\uff09\u4e26\u4e0d\u5be6\u969b\uff0c\u56e0\u70ba\u9019\u9700\u8981\u5927\u91cf\u7684\u8a18\u61b6\u9ad4\u548c\u5ef6\u9072\u3002\u70ba\u4e86\u964d\u4f4e\u6210\u672c\uff0c\u6211\u5011\u4f7f\u7528\u5e36\u6709\u4e8c\u5143\u6709\u5bb3\u6a19\u7c64\u7684\u6307\u4ee4\u56de\u61c9\u914d\u5c0d\u6a19\u8a18\u8cc7\u6599\u96c6\uff0c\u5c07\u5927\u578b\u6559\u5e2b\u5b89\u5168\u9632\u8b77\u6a21\u578b\u63d0\u7149\u6210\u8f03\u5c0f\u7684\u6a21\u578b\u3002\u7531\u65bc\u73fe\u6709\u6a19\u8a18\u8cc7\u6599\u96c6\u4e2d\u6709\u5bb3\u6307\u4ee4\u7684\u591a\u6a23\u6027\u6709\u9650\uff0c\u56e0\u6b64\u5929\u771f\u63d0\u7149\u7684\u6a21\u578b\u5f80\u5f80\u8868\u73fe\u4e0d\u5982\u8f03\u5927\u7684\u6a21\u578b\u3002\u70ba\u4e86\u7e2e\u5c0f\u5c0f\u578b\u548c\u5927\u578b\u6a21\u578b\u4e4b\u9593\u7684\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86 HarmAug\uff0c\u9019\u662f\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5c0d LLM \u9032\u884c\u8d8a\u7344\u4e26\u63d0\u793a\u5b83\u7522\u751f\u6709\u5bb3\u6307\u4ee4\u3002\u7d66\u5b9a\u4e00\u500b\u63d0\u793a\uff0c\u4f8b\u5982\u300c\u63d0\u51fa\u4e00\u500b\u6709\u5bb3\u7684\u6307\u4ee4\u63d0\u793a\uff0c\u6703\u5f15\u767c\u4ee4\u4eba\u53cd\u611f\u7684\u5167\u5bb9\u300d\uff0c\u6211\u5011\u5728 LLM \u7684\u56de\u61c9\u4e2d\u52a0\u4e0a\u4e00\u500b\u80af\u5b9a\u7684\u524d\u7db4\uff08\u4f8b\u5982\uff0c\u300c\u6211\u6709\u4e00\u500b\u63d0\u793a\u7684\u60f3\u6cd5\uff1a\u300d\uff09\u3002\u9019\u9f13\u52f5 LLM \u7e7c\u7e8c\u7522\u751f\u5176\u9918\u7684\u56de\u61c9\uff0c\u5c0e\u81f4\u63a1\u6a23\u6709\u5bb3\u6307\u4ee4\u3002\u53e6\u4e00\u500b LLM \u5c0d\u6709\u5bb3\u6307\u4ee4\u7522\u751f\u56de\u61c9\uff0c\u800c\u6559\u5e2b\u6a21\u578b\u6a19\u8a18\u6307\u4ee4\u56de\u61c9\u914d\u5c0d\u3002\u6211\u5011\u7d93\u9a57\u6027\u5730\u8868\u660e\uff0c\u6211\u5011\u7684 HarmAug \u512a\u65bc\u5176\u4ed6\u76f8\u95dc\u57fa\u6e96\u3002\u6b64\u5916\uff0c\u4f7f\u7528 HarmAug \u8a13\u7df4\u7684 4.35 \u5104\u53c3\u6578\u5b89\u5168\u9632\u8b77\u6a21\u578b\u9054\u5230\u4e86\u8207\u8d85\u904e 70 \u5104\u53c3\u6578\u7684\u5927\u578b\u6a21\u578b\u76f8\u7576\u7684 F1 \u5206\u6578\uff0c\u751a\u81f3\u5728 AUPRC \u4e2d\u512a\u65bc\u5b83\u5011\uff0c\u540c\u6642\u904b\u7b97\u6210\u672c\u4e0d\u5230\u5b83\u5011\u7684 25%\u3002", "author": "Seanie Lee et.al.", "authors": "Seanie Lee, Haebin Seong, Dong Bok Lee, Minki Kang, Xiaoyin Chen, Dominik Wagner, Yoshua Bengio, Juho Lee, Sung Ju Hwang", "id": "2410.01524v1", "paper_url": "http://arxiv.org/abs/2410.01524v1", "repo": "https://github.com/imnotkind/HarmAug"}}