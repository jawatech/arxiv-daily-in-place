{"2410.14425": {"publish_time": "2024-10-18", "title": "Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation", "paper_summary": "Parameter-efficient fine-tuning (PEFT) can bridge the gap between large\nlanguage models (LLMs) and downstream tasks. However, PEFT has been proven\nvulnerable to malicious attacks. Research indicates that poisoned LLMs, even\nafter PEFT, retain the capability to activate internalized backdoors when input\nsamples contain predefined triggers. In this paper, we introduce a novel\nweak-to-strong unlearning algorithm to defend against backdoor attacks based on\nfeature alignment knowledge distillation, named W2SDefense. Specifically, we\nfirst train a small-scale language model through full-parameter fine-tuning to\nserve as the clean teacher model. Then, this teacher model guides the\nlarge-scale poisoned student model in unlearning the backdoor, leveraging PEFT.\nTheoretical analysis suggests that W2SDefense has the potential to enhance the\nstudent model's ability to unlearn backdoor features, preventing the activation\nof the backdoor. We conduct experiments on text classification tasks involving\nthree state-of-the-art language models and three different backdoor attack\nalgorithms. Our empirical results demonstrate the outstanding performance of\nW2SDefense in defending against backdoor attacks without compromising model\nperformance.", "paper_summary_zh": "\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (PEFT) \u53ef\u4ee5\u5f4c\u5408\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u4e0b\u6e38\u4efb\u52d9\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u7136\u800c\uff0cPEFT \u5df2\u88ab\u8b49\u660e\u5bb9\u6613\u53d7\u5230\u60e1\u610f\u653b\u64ca\u3002\u7814\u7a76\u8868\u660e\uff0c\u4e2d\u6bd2\u7684 LLM\uff0c\u5373\u4f7f\u5728 PEFT \u4e4b\u5f8c\uff0c\u4ecd\u6709\u80fd\u529b\u5728\u8f38\u5165\u7bc4\u4f8b\u5305\u542b\u9810\u5b9a\u7fa9\u89f8\u767c\u5668\u6642\u555f\u52d5\u5167\u90e8\u5f8c\u9580\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5f31\u5230\u5f37\u7684\u907a\u5fd8\u6f14\u7b97\u6cd5\uff0c\u4ee5\u57fa\u65bc\u7279\u5fb5\u5c0d\u9f4a\u77e5\u8b58\u84b8\u993e\u4f86\u9632\u79a6\u5f8c\u9580\u653b\u64ca\uff0c\u7a31\u70ba W2SDefense\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u901a\u904e\u5168\u53c3\u6578\u5fae\u8abf\u8a13\u7df4\u4e00\u500b\u5c0f\u898f\u6a21\u8a9e\u8a00\u6a21\u578b\uff0c\u4f5c\u70ba\u4e7e\u6de8\u7684\u6559\u5e2b\u6a21\u578b\u3002\u7136\u5f8c\uff0c\u9019\u500b\u6559\u5e2b\u6a21\u578b\u6307\u5c0e\u5927\u898f\u6a21\u4e2d\u6bd2\u7684\u5b78\u751f\u6a21\u578b\u5728\u5229\u7528 PEFT \u907a\u5fd8\u5f8c\u9580\u3002\u7406\u8ad6\u5206\u6790\u8868\u660e\uff0cW2SDefense \u6709\u53ef\u80fd\u589e\u5f37\u5b78\u751f\u6a21\u578b\u907a\u5fd8\u5f8c\u9580\u7279\u5fb5\u7684\u80fd\u529b\uff0c\u9632\u6b62\u5f8c\u9580\u88ab\u555f\u52d5\u3002\u6211\u5011\u5c0d\u6d89\u53ca\u4e09\u500b\u6700\u5148\u9032\u8a9e\u8a00\u6a21\u578b\u548c\u4e09\u500b\u4e0d\u540c\u5f8c\u9580\u653b\u64ca\u6f14\u7b97\u6cd5\u7684\u6587\u672c\u5206\u985e\u4efb\u52d9\u9032\u884c\u4e86\u5be6\u9a57\u3002\u6211\u5011\u7684\u5be6\u8b49\u7d50\u679c\u8b49\u660e\u4e86 W2SDefense \u5728\u9632\u79a6\u5f8c\u9580\u653b\u64ca\u65b9\u9762\u7684\u51fa\u8272\u8868\u73fe\uff0c\u800c\u4e0d\u6703\u640d\u5bb3\u6a21\u578b\u6027\u80fd\u3002", "author": "Shuai Zhao et.al.", "authors": "Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Meihuizi Jia, Yichao Feng, Luu Anh Tuan", "id": "2410.14425v1", "paper_url": "http://arxiv.org/abs/2410.14425v1", "repo": "https://github.com/shuaizhao95/Unlearning"}}