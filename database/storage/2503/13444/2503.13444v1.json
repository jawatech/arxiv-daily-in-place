{"2503.13444": {"publish_time": "2025-03-17", "title": "VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning", "paper_summary": "Videos, with their unique temporal dimension, demand precise grounded\nunderstanding, where answers are directly linked to visual, interpretable\nevidence. Despite significant breakthroughs in reasoning capabilities within\nLarge Language Models, multi-modal reasoning - especially for videos - remains\nunexplored. In this work, we introduce VideoMind, a novel video-language agent\ndesigned for temporal-grounded video understanding. VideoMind incorporates two\nkey innovations: (i) We identify essential capabilities for video temporal\nreasoning and develop a role-based agentic workflow, including a planner for\ncoordinating different roles, a grounder for temporal localization, a verifier\nto assess temporal interval accuracy, and an answerer for question-answering.\n(ii) To efficiently integrate these diverse roles, we propose a novel\nChain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA\nadaptors while avoiding the overhead of multiple models, thus balancing\nefficiency and flexibility. Extensive experiments on 14 public benchmarks\ndemonstrate that our agent achieves state-of-the-art performance on diverse\nvideo understanding tasks, including 3 on grounded video question-answering, 6\non video temporal grounding, and 5 on general video question-answering,\nunderscoring its effectiveness in advancing video agent and long-form temporal\nreasoning.", "paper_summary_zh": "<paragraph>\u5f71\u7247\u6709\u8457\u7368\u7279\u7684\u6642\u9593\u7dad\u5ea6\uff0c\u9700\u8981\u7cbe\u78ba\u7684 grounding \u7406\u89e3\uff0c\u4e5f\u5c31\u662f\u7b54\u6848\u8981\u76f4\u63a5\u9023\u7d50\u5230\u8996\u89ba\u4e0a\u53ef\u8a6e\u91cb\u7684\u8b49\u64da\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u7a81\u7834\uff0c\u4f46\u591a\u6a21\u614b\u63a8\u7406\uff0c\u5c24\u5176\u662f\u5f71\u7247\u65b9\u9762\u7684\u63a8\u7406\uff0c\u4ecd\u7136\u672a\u88ab\u63a2\u7d22\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 VideoMind\uff0c\u4e00\u500b\u70ba grounding \u6642\u9593\u7684\u5f71\u7247\u7406\u89e3\u800c\u8a2d\u8a08\u7684\u65b0\u578b\u5f71\u7247\u8a9e\u8a00\u4ee3\u7406\u3002VideoMind \u5305\u542b\u4e86\u5169\u500b\u95dc\u9375\u5275\u65b0\uff1a(i) \u6211\u5011\u78ba\u5b9a\u4e86\u5f71\u7247\u6642\u9593\u63a8\u7406\u7684\u5fc5\u8981\u80fd\u529b\uff0c\u4e26\u958b\u767c\u4e86\u4e00\u500b\u57fa\u65bc\u89d2\u8272\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u7528\u65bc\u5354\u8abf\u4e0d\u540c\u89d2\u8272\u7684\u898f\u5283\u5668\u3001\u7528\u65bc\u6642\u9593\u5b9a\u4f4d\u7684 grounding \u5668\u3001\u7528\u65bc\u8a55\u4f30\u6642\u9593\u9593\u9694\u6e96\u78ba\u6027\u7684\u9a57\u8b49\u5668\uff0c\u4ee5\u53ca\u7528\u65bc\u554f\u7b54\u7684\u56de\u7b54\u5668\u3002(ii) \u70ba\u4e86\u6709\u6548\u5730\u6574\u5408\u9019\u4e9b\u4e0d\u540c\u7684\u89d2\u8272\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684 LoRA \u93c8\u7b56\u7565\uff0c\u900f\u904e\u8f15\u91cf\u7d1a\u7684 LoRA \u8f49\u63a5\u5668\u5be6\u73fe\u7121\u7e2b\u7684\u89d2\u8272\u5207\u63db\uff0c\u540c\u6642\u907f\u514d\u4e86\u591a\u500b\u6a21\u578b\u7684\u958b\u92b7\uff0c\u5f9e\u800c\u5e73\u8861\u6548\u7387\u548c\u9748\u6d3b\u6027\u3002\u5728 14 \u500b\u516c\u958b\u57fa\u6e96\u6e2c\u8a66\u4e0a\u7684\u5927\u91cf\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u4ee3\u7406\u5728\u5404\u7a2e\u5f71\u7247\u7406\u89e3\u4efb\u52d9\u4e0a\u90fd\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\uff0c\u5305\u62ec 3 \u500b grounding \u5f71\u7247\u554f\u7b54\u30016 \u500b\u5f71\u7247\u6642\u9593 grounding \u548c 5 \u500b\u4e00\u822c\u5f71\u7247\u554f\u7b54\uff0c\u7a81\u986f\u4e86\u5176\u5728\u63a8\u9032\u5f71\u7247\u4ee3\u7406\u548c\u9577\u683c\u5f0f\u6642\u9593\u63a8\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\u3002</paragraph>\n", "author": "Ye Liu et.al.", "authors": "Ye Liu, Kevin Qinghong Lin, Chang Wen Chen, Mike Zheng Shou", "id": "2503.13444v1", "paper_url": "http://arxiv.org/abs/2503.13444v1", "repo": "null"}}