
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-07**|**SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**|Vinícius Di Oliveira et.al.|[2408.03936v1](http://arxiv.org/abs/2408.03936v1)|null|
|**2024-08-07**|**From Words to Worth: Newborn Article Impact Prediction with LLM**|Penghai Zhao et.al.|[2408.03934v1](http://arxiv.org/abs/2408.03934v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v1](http://arxiv.org/abs/2408.03910v1)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**|Shachi H Kumar et.al.|[2408.03907v1](http://arxiv.org/abs/2408.03907v1)|null|
|**2024-08-07**|**Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**|Beomseok Lee et.al.|[2408.03900v1](http://arxiv.org/abs/2408.03900v1)|[link](https://github.com/hlt-mt/speech-massive)|
|**2024-08-07**|**Simplifying Scholarly Abstracts for Accessible Digital Libraries**|Haining Wang et.al.|[2408.03899v1](http://arxiv.org/abs/2408.03899v1)|null|
|**2024-08-07**|**MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**|Renzhi Wang et.al.|[2408.03892v1](http://arxiv.org/abs/2408.03892v1)|null|
|**2024-08-07**|**Personalized Clinical Note Generation from Doctor-Patient Conversations**|Nathan Brake et.al.|[2408.03874v1](http://arxiv.org/abs/2408.03874v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**|Zihao Li et.al.|[2408.03871v1](http://arxiv.org/abs/2408.03871v1)|[link](https://github.com/hecta-uom/plaba-mu)|
|**2024-08-07**|**Why transformers are obviously good models of language**|Felix Hill et.al.|[2408.03855v1](http://arxiv.org/abs/2408.03855v1)|null|
|**2024-08-07**|**Hate Speech Detection and Classification in Amharic Text with Deep Learning**|Samuel Minale Gashe et.al.|[2408.03849v1](http://arxiv.org/abs/2408.03849v1)|null|
|**2024-08-07**|**MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**|Yuchen Dong et.al.|[2408.03841v1](http://arxiv.org/abs/2408.03841v1)|null|
|**2024-08-07**|**WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**|Prannaya Gupta et.al.|[2408.03837v1](http://arxiv.org/abs/2408.03837v1)|null|
|**2024-08-07**|**Target Prompting for Information Extraction with Vision Language Model**|Dipankar Medhi et.al.|[2408.03834v1](http://arxiv.org/abs/2408.03834v1)|null|
|**2024-08-07**|**Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**|Forough Mehralian et.al.|[2408.03827v1](http://arxiv.org/abs/2408.03827v1)|null|
|**2024-08-07**|**Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning**|Simret Araya Gebreegziabher et.al.|[2408.03819v1](http://arxiv.org/abs/2408.03819v1)|null|
|**2024-08-07**|**Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring**|Zifan Wang et.al.|[2408.03811v1](http://arxiv.org/abs/2408.03811v1)|null|
|**2024-08-07**|**Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning**|Martin Moder et.al.|[2408.03807v1](http://arxiv.org/abs/2408.03807v1)|null|
|**2024-08-07**|**Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations**|Erica Coppolillo et.al.|[2408.03772v1](http://arxiv.org/abs/2408.03772v1)|[link](https://github.com/ericacoppolillo/explore)|
|**2024-08-07**|**'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization**|Meisin Lee et.al.|[2408.03762v1](http://arxiv.org/abs/2408.03762v1)|null|
|**2024-08-07**|**Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions**|Lucas Correia et.al.|[2408.03747v1](http://arxiv.org/abs/2408.03747v1)|null|
|**2024-08-07**|**Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling**|Jian Xu et.al.|[2408.03746v1](http://arxiv.org/abs/2408.03746v1)|null|
|**2024-08-07**|**Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification**|Georgia Sovatzidi et.al.|[2408.03745v1](http://arxiv.org/abs/2408.03745v1)|null|
|**2024-08-07**|**Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation**|Jingjing Xie et.al.|[2408.03735v1](http://arxiv.org/abs/2408.03735v1)|[link](https://github.com/xjjxmu/qslaw)|
|**2024-08-07**|**Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks**|Zizhang Chen et.al.|[2408.03732v1](http://arxiv.org/abs/2408.03732v1)|null|
|**2024-08-07**|**Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction**|Benjamin Matthias Ruppik et.al.|[2408.03706v1](http://arxiv.org/abs/2408.03706v1)|null|
|**2024-08-07**|**A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework**|Emna Baccour et.al.|[2408.03694v1](http://arxiv.org/abs/2408.03694v1)|null|
|**2024-08-07**|**NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time**|Yilong Chen et.al.|[2408.03675v2](http://arxiv.org/abs/2408.03675v2)|[link](https://github.com/PaddlePaddle/Research)|
|**2024-08-07**|**mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search**|Ahmed Abdou et.al.|[2408.03652v1](http://arxiv.org/abs/2408.03652v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|null|
|**2024-08-07**|**CARE: A Clue-guided Assistant for CSRs to Read User Manuals**|Weihong Du et.al.|[2408.03633v2](http://arxiv.org/abs/2408.03633v2)|null|
|**2024-08-07**|**Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis**|Zebin Yao et.al.|[2408.03632v1](http://arxiv.org/abs/2408.03632v1)|null|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631v1](http://arxiv.org/abs/2408.03631v1)|null|
|**2024-08-07**|**PAGED: A Benchmark for Procedural Graphs Extraction from Documents**|Weihong Du et.al.|[2408.03630v2](http://arxiv.org/abs/2408.03630v2)|null|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-07**|**A Logical Fallacy-Informed Framework for Argument Generation**|Luca Mouchel et.al.|[2408.03618v1](http://arxiv.org/abs/2408.03618v1)|null|
|**2024-08-07**|**Is Child-Directed Speech Effective Training Data for Language Models?**|Steven Y. Feng et.al.|[2408.03617v1](http://arxiv.org/abs/2408.03617v1)|null|
|**2024-08-07**|**Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**|Zaijing Li et.al.|[2408.03615v1](http://arxiv.org/abs/2408.03615v1)|null|
|**2024-08-07**|**EnJa: Ensemble Jailbreak on Large Language Models**|Jiahao Zhang et.al.|[2408.03603v1](http://arxiv.org/abs/2408.03603v1)|null|
|**2024-08-07**|**Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation**|Karn N. Watcharasupat et.al.|[2408.03588v1](http://arxiv.org/abs/2408.03588v1)|null|
|**2024-08-07**|**Hierarchical Neural Constructive Solver for Real-world TSP Scenarios**|Yong Liang Goh et.al.|[2408.03585v1](http://arxiv.org/abs/2408.03585v1)|null|
|**2024-08-07**|**Teach CLIP to Develop a Number Sense for Ordinal Regression**|Yao Du et.al.|[2408.03574v1](http://arxiv.org/abs/2408.03574v1)|null|
|**2024-08-07**|**Active Testing of Large Language Model via Multi-Stage Sampling**|Yuheng Huang et.al.|[2408.03573v1](http://arxiv.org/abs/2408.03573v1)|null|
|**2024-08-07**|**2D-OOB: Attributing Data Contribution through Joint Valuation Framework**|Yifan Sun et.al.|[2408.03572v1](http://arxiv.org/abs/2408.03572v1)|null|
|**2024-08-07**|**Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning**|Zi-Yi Dou et.al.|[2408.03567v1](http://arxiv.org/abs/2408.03567v1)|null|
|**2024-08-07**|**A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case**|Sonia Meyer et.al.|[2408.03562v1](http://arxiv.org/abs/2408.03562v1)|null|
|**2024-08-07**|**MPC-Minimized Secure LLM Inference**|Deevashwer Rathee et.al.|[2408.03561v1](http://arxiv.org/abs/2408.03561v1)|null|
|**2024-08-07**|**Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection**|Subaru Kimura et.al.|[2408.03554v1](http://arxiv.org/abs/2408.03554v1)|null|
|**2024-08-07**|**Unlocking the Non-Native Language Context Limitation: Native Language Prompting Facilitates Knowledge Elicitation**|Baixuan Li et.al.|[2408.03544v1](http://arxiv.org/abs/2408.03544v1)|[link](https://github.com/anonynlp/natlan)|
|**2024-08-07**|**EXAONE 3.0 7.8B Instruction Tuned Language Model**|LG AI Research et.al.|[2408.03541v2](http://arxiv.org/abs/2408.03541v2)|null|
|**2024-08-07**|**Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation**|Jiachen Zhu et.al.|[2408.03533v1](http://arxiv.org/abs/2408.03533v1)|null|
|**2024-08-07**|**Exploring the extent of similarities in software failures across industries using LLMs**|Martin Detloff et.al.|[2408.03528v2](http://arxiv.org/abs/2408.03528v2)|null|
|**2024-08-07**|**EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora**|Faisal Qarah et.al.|[2408.03524v1](http://arxiv.org/abs/2408.03524v1)|null|
|**2024-08-07**|**RepoMasterEval: Evaluating Code Completion via Real-World Repositories**|Qinyun Wu et.al.|[2408.03519v1](http://arxiv.org/abs/2408.03519v1)|null|
|**2024-08-07**|**A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems**|Wenxiao Zhang et.al.|[2408.03515v1](http://arxiv.org/abs/2408.03515v1)|null|
|**2024-08-07**|**MoExtend: Tuning New Experts for Modality and Task Extension**|Shanshan Zhong et.al.|[2408.03511v1](http://arxiv.org/abs/2408.03511v1)|null|
|**2024-08-07**|**1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data**|Calvin Tan et.al.|[2408.03506v1](http://arxiv.org/abs/2408.03506v1)|[link](https://github.com/Pints-AI/1.5-Pints)|
|**2024-08-07**|**Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation**|Weiqi Feng et.al.|[2408.03505v1](http://arxiv.org/abs/2408.03505v1)|null|
|**2024-08-07**|**Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN**|Chang Yu et.al.|[2408.03497v1](http://arxiv.org/abs/2408.03497v1)|null|
|**2024-08-07**|**Automated Theorem Provers Help Improve Large Language Model Reasoning**|Lachlan McGinness et.al.|[2408.03492v1](http://arxiv.org/abs/2408.03492v1)|null|
|**2024-08-07**|**Harnessing the Power of LLMs in Source Code Vulnerability Detection**|Andrew A Mahyari et.al.|[2408.03489v1](http://arxiv.org/abs/2408.03489v1)|null|
|**2024-08-06**|**Can LLMs Serve As Time Series Anomaly Detectors?**|Manqing Dong et.al.|[2408.03475v1](http://arxiv.org/abs/2408.03475v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|null|
|**2024-08-06**|**EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures**|Teng Liang et.al.|[2408.03449v1](http://arxiv.org/abs/2408.03449v1)|null|
|**2024-08-06**|**Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers**|Marcus Buckmann et.al.|[2408.03414v1](http://arxiv.org/abs/2408.03414v1)|null|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning**|Hieu Man et.al.|[2408.03402v1](http://arxiv.org/abs/2408.03402v1)|[link](https://github.com/nlp-uoregon/ullme)|
|**2024-08-06**|**Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey**|Vu Tuan Truong et.al.|[2408.03400v1](http://arxiv.org/abs/2408.03400v1)|null|
|**2024-08-06**|**RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms**|Luis Roque et.al.|[2408.03399v1](http://arxiv.org/abs/2408.03399v1)|null|
|**2024-08-06**|**A Non-negative VAE:the Generalized Gamma Belief Network**|Zhibin Duan et.al.|[2408.03388v1](http://arxiv.org/abs/2408.03388v1)|null|
|**2024-08-06**|**LLaVA-OneVision: Easy Visual Task Transfer**|Bo Li et.al.|[2408.03326v1](http://arxiv.org/abs/2408.03326v1)|null|
|**2024-08-06**|**CoverBench: A Challenging Benchmark for Complex Claim Verification**|Alon Jacovi et.al.|[2408.03325v1](http://arxiv.org/abs/2408.03325v1)|null|
|**2024-08-06**|**Training LLMs to Recognize Hedges in Spontaneous Narratives**|Amie J. Paige et.al.|[2408.03319v1](http://arxiv.org/abs/2408.03319v1)|null|
|**2024-08-06**|**Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**|Charlie Snell et.al.|[2408.03314v1](http://arxiv.org/abs/2408.03314v1)|null|
|**2024-08-06**|**Prioritize Alignment in Dataset Distillation**|Zekai Li et.al.|[2408.03360v1](http://arxiv.org/abs/2408.03360v1)|null|
|**2024-08-06**|**KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**|Ruizhe Zhang et.al.|[2408.03297v1](http://arxiv.org/abs/2408.03297v1)|null|
|**2024-08-06**|**Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**|Lizi Zhang et.al.|[2408.03292v1](http://arxiv.org/abs/2408.03292v1)|null|
|**2024-08-06**|**SARA: Singular-Value Based Adaptive Low-Rank Adaption**|Jihao Gu et.al.|[2408.03290v1](http://arxiv.org/abs/2408.03290v1)|null|
|**2024-08-06**|**StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**|Boxi Cao et.al.|[2408.03281v2](http://arxiv.org/abs/2408.03281v2)|[link](https://github.com/c-box/structeval)|
|**2024-08-06**|**Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**|Angie Boggust et.al.|[2408.03274v1](http://arxiv.org/abs/2408.03274v1)|null|
|**2024-08-06**|**LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification**|Zhen Qin et.al.|[2408.03359v1](http://arxiv.org/abs/2408.03359v1)|null|
|**2024-08-06**|**Synthesizing Text-to-SQL Data from Weak and Strong LLMs**|Jiaxi Yang et.al.|[2408.03256v1](http://arxiv.org/abs/2408.03256v1)|null|
|**2024-08-06**|**Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**|Yifei Wang et.al.|[2408.03247v1](http://arxiv.org/abs/2408.03247v1)|null|
|**2024-08-06**|**Making Long-Context Language Models Better Multi-Hop Reasoners**|Yanyang Li et.al.|[2408.03246v1](http://arxiv.org/abs/2408.03246v1)|[link](https://github.com/lavi-lab/longcontextreasoner)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**|Zifeng Cheng et.al.|[2408.03202v1](http://arxiv.org/abs/2408.03202v1)|null|
|**2024-08-06**|**Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**|Kunkun Hao et.al.|[2408.03200v2](http://arxiv.org/abs/2408.03200v2)|null|
|**2024-08-06**|**Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**|Pranita Deshmukh et.al.|[2408.03172v1](http://arxiv.org/abs/2408.03172v1)|null|
|**2024-08-06**|**Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**|Elia Cereda et.al.|[2408.03168v1](http://arxiv.org/abs/2408.03168v1)|null|
|**2024-08-06**|**Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**|Rabih Chamas et.al.|[2408.03164v1](http://arxiv.org/abs/2408.03164v1)|[link](https://github.com/rabihchamas/dcls-gradcam-eval)|
|**2024-08-06**|**Conditioning LLMs with Emotion in Neural Machine Translation**|Charles Brazier et.al.|[2408.03150v1](http://arxiv.org/abs/2408.03150v1)|null|
|**2024-08-06**|**Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**|Yanghai Zhang et.al.|[2408.03149v1](http://arxiv.org/abs/2408.03149v1)|null|
|**2024-08-06**|**Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**|Leo Donisch et.al.|[2408.03130v1](http://arxiv.org/abs/2408.03130v1)|null|
|**2024-08-06**|**Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**|Artur Guimarães et.al.|[2408.03127v1](http://arxiv.org/abs/2408.03127v1)|null|
|**2024-08-06**|**COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**|Rajvee Sheth et.al.|[2408.03125v1](http://arxiv.org/abs/2408.03125v1)|[link](https://github.com/lingo-iitgn/commentator)|
|**2024-08-06**|**Evaluating the Translation Performance of Large Language Models Based on Euas-20**|Yan Huang et.al.|[2408.03119v1](http://arxiv.org/abs/2408.03119v1)|null|
|**2024-08-06**|**Topic Modeling with Fine-tuning LLMs and Bag of Sentences**|Johannes Schneider et.al.|[2408.03099v1](http://arxiv.org/abs/2408.03099v1)|[link](https://github.com/johntailor/ft-topic)|
|**2024-08-06**|**500xCompressor: Generalized Prompt Compression for Large Language Models**|Zongqian Li et.al.|[2408.03094v1](http://arxiv.org/abs/2408.03094v1)|null|

#### Abstracts
##### **SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**
2408.03936v1 by Vinícius Di Oliveira, Yuri Façanha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino

Natural language processing (NLP) has seen significant advancements with the
advent of large language models (LLMs). However, substantial improvements are
still needed for languages other than English, especially for specific domains
like the applications of Mercosur Common Nomenclature (NCM), a Brazilian
Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a
foundational Portuguese LLM, as an LLM source to implement the NCM application
processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)
technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.
This approach retains the chain-of-thought (CoT) methodology for prompt
development in a more concise and streamlined manner, utilizing brief and
focused documents for training. The proposed model demonstrates an efficient
and cost-effective alternative for fine-tuning smaller LLMs, significantly
outperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the
research focuses on NCM applications, the methodology can be easily adapted for
HS applications worldwide.

摘要：自然語言處理 (NLP) 隨著大型語言模型 (LLM) 的出現而獲得顯著進展。然而，對於英語以外的語言，特別是像巴西統一制度 (HS) 的南方共同市場共同法規 (NCM) 應用等特定領域，仍需要大幅改進。為了解決這個差距，本研究使用 TeenyTineLLaMA（一種基礎的葡萄牙語 LLM）作為 LLM 來源，來實作 NCM 應用處理。此外，提出了一種簡化的檢索增強微調 (RAFT) 技術，稱為 SLIM-RAFT，用於 LLM 的任務特定微調。這種方法保留了思考鏈 (CoT) 方法，用於以更簡潔和流暢的方式開發提示，並利用簡短且重點明確的文件進行訓練。所提出的模型展示了一個有效且經濟的替代方案，用於微調較小的 LLM，在相同的任務中顯著優於 TeenyTineLLaMA 和 ChatGPT-4。儘管研究重點在於 NCM 應用，但該方法可以很容易地適用於全球的 HS 應用。

##### **From Words to Worth: Newborn Article Impact Prediction with LLM**
2408.03934v1 by Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li

As the academic landscape expands, the challenge of efficiently identifying
potentially high-impact articles among the vast number of newly published works
becomes critical. This paper introduces a promising approach, leveraging the
capabilities of fine-tuned LLMs to predict the future impact of newborn
articles solely based on titles and abstracts. Moving beyond traditional
methods heavily reliant on external information, the proposed method discerns
the shared semantic features of highly impactful papers from a large collection
of title-abstract and potential impact pairs. These semantic features are
further utilized to regress an improved metric, TNCSI_SP, which has been
endowed with value, field, and time normalization properties. Additionally, a
comprehensive dataset has been constructed and released for fine-tuning the
LLM, containing over 12,000 entries with corresponding titles, abstracts, and
TNCSI_SP. The quantitative results, with an NDCG@20 of 0.901, demonstrate that
the proposed approach achieves state-of-the-art performance in predicting the
impact of newborn articles when compared to competitive counterparts. Finally,
we demonstrate a real-world application for predicting the impact of newborn
journal articles to demonstrate its noteworthy practical value. Overall, our
findings challenge existing paradigms and propose a shift towards a more
content-focused prediction of academic impact, offering new insights for
assessing newborn article impact.

摘要：隨著學術領域的擴展，在大量新出版的作品中有效找出潛在高影響力文章的挑戰變得至關重要。本文介紹了一種有前途的方法，利用微調 LLM 的能力來預測新生文章的未來影響，僅根據標題和摘要。超越了傳統方法，該方法依賴於外部資訊，提出的方法從大量的標題摘要和潛在影響對中辨別出高影響力論文的共用語義特徵。這些語義特徵進一步用於回歸一個改進的指標 TNCSI_SP，該指標已賦予值、欄位和時間正規化屬性。此外，還構建並發布了一個綜合資料集，用於微調 LLM，其中包含超過 12,000 個條目，以及對應的標題、摘要和 TNCSI_SP。定量結果，NDCG@20 為 0.901，證明了與競爭對手相比，所提出的方法在預測新生文章的影響方面達到了最先進的效能。最後，我們展示了一個現實世界的應用，用於預測新生期刊文章的影響，以證明其顯著的實用價值。總的來說，我們的發現挑戰了現有的範例，並建議轉向更注重內容的學術影響預測，為評估新生文章影響提供了新的見解。

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v1 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce \framework, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, \framework enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess \framework using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, \framework demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

摘要：大型語言模型 (LLM) 在獨立程式碼任務中表現出色，例如 HumanEval 和 MBPP，但處理整個程式碼儲存庫時卻遇到困難。這個挑戰促使研究人員加強 LLM 與程式碼庫的互動，並以儲存庫為規模。目前的解決方案依賴於基於相似性的擷取或手動工具和 API，每種方法都有顯著的缺點。基於相似性的擷取在複雜任務中通常召回率低，而手動工具和 API 通常是特定於任務的，需要專家知識，這會降低它們在不同程式碼任務和實際應用中的概括性。為了減輕這些限制，我們引入了 \framework，一個將 LLM 代理與從程式碼儲存庫中提取的圖形資料庫介面整合的系統。透過利用圖形資料庫的結構特性和圖形查詢語言的靈活性，\framework 使 LLM 代理能夠建構和執行查詢，允許精確、有程式碼結構意識的內容擷取和程式碼導覽。我們使用三個基準來評估 \framework：CrossCodeEval、SWE-bench 和 EvoCodeBench。此外，我們開發了五個實際的程式碼應用程式。有了統一的圖形資料庫架構，\framework 在學術和實際環境中都展現出競爭力的效能和潛力，展示了它在軟體工程中的多功能性和有效性。我們的應用程式示範：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。

##### **Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**
2408.03907v1 by Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman

Large Language Models (LLMs) have excelled at language understanding and
generating human-level text. However, even with supervised training and human
alignment, these LLMs are susceptible to adversarial attacks where malicious
users can prompt the model to generate undesirable text. LLMs also inherently
encode potential biases that can cause various harmful effects during
interactions. Bias evaluation metrics lack standards as well as consensus and
existing methods often rely on human-generated templates and annotations which
are expensive and labor intensive. In this work, we train models to
automatically create adversarial prompts to elicit biased responses from target
LLMs. We present LLM- based bias evaluation metrics and also analyze several
existing automatic evaluation methods and metrics. We analyze the various
nuances of model responses, identify the strengths and weaknesses of model
families, and assess where evaluation methods fall short. We compare these
metrics to human evaluation and validate that the LLM-as-a-Judge metric aligns
with human judgement on bias in response generation.

摘要：大型語言模型 (LLM) 在語言理解和產生人類層級文字方面表現出色。然而，即使經過監督式訓練和人類校準，這些 LLM 仍容易受到對抗性攻擊，惡意使用者可以提示模型產生不良文字。LLM 本身也編碼了潛在偏見，可能在互動過程中造成各種有害影響。偏見評估指標缺乏標準和共識，現有方法通常依賴於人工產生的範本和註解，這些範本和註解昂貴且耗費人力。在這項工作中，我們訓練模型自動建立對抗性提示，從目標 LLM 引出有偏見的回應。我們提出基於 LLM 的偏見評估指標，並分析了幾種現有的自動評估方法和指標。我們分析模型回應的各種細微差別，找出模型系列的優缺點，並評估評估方法的不足之處。我們將這些指標與人類評估進行比較，並驗證 LLM 作為評判指標與人類對回應中偏見的判斷一致。

##### **Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**
2408.03900v1 by Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier

We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)
dataset comprising the speech counterpart for a portion of the MASSIVE textual
corpus. Speech-MASSIVE covers 12 languages from different families and inherits
from MASSIVE the annotations for the intent prediction and slot-filling tasks.
Our extension is prompted by the scarcity of massively multilingual SLU
datasets and the growing need for versatile speech datasets to assess
foundation models (LLMs, speech encoders) across languages and tasks. We
provide a multimodal, multitask, multilingual dataset and report SLU baselines
using both cascaded and end-to-end architectures in various training scenarios
(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the
suitability of Speech-MASSIVE for benchmarking other tasks such as speech
transcription, language identification, and speech translation. The dataset,
models, and code are publicly available at:
https://github.com/hlt-mt/Speech-MASSIVE

摘要：我們提出 Speech-MASSIVE，一個多語言的口語理解 (SLU)
資料集，包含 MASSIVE 文本語料庫一部分的口語對應部分。Speech-MASSIVE 涵蓋了來自不同語系的 12 種語言，並繼承了 MASSIVE 中用於意圖預測和槽位填補任務的註解。
我們的擴展是由大量的多語言 SLU 資料集的稀缺性以及評估跨語言和任務的基礎模型 (LLM、語音編碼器) 對通用語音資料集日益增長的需求所推動的。我們提供了一個多模態、多任務、多語言的資料集，並在各種訓練場景（零次學習、少次學習和完全微調）中報告了使用串聯和端到端架構的 SLU 基線。此外，我們展示了 Speech-MASSIVE 適用於對其他任務（例如語音轉錄、語言識別和語音翻譯）進行基準測試。資料集、模型和程式碼可在以下位置公開獲得：
https://github.com/hlt-mt/Speech-MASSIVE

##### **Simplifying Scholarly Abstracts for Accessible Digital Libraries**
2408.03899v1 by Haining Wang, Jason Clark

Standing at the forefront of knowledge dissemination, digital libraries
curate vast collections of scientific literature. However, these scholarly
writings are often laden with jargon and tailored for domain experts rather
than the general public. As librarians, we strive to offer services to a
diverse audience, including those with lower reading levels. To extend our
services beyond mere access, we propose fine-tuning a language model to rewrite
scholarly abstracts into more comprehensible versions, thereby making scholarly
literature more accessible when requested. We began by introducing a corpus
specifically designed for training models to simplify scholarly abstracts. This
corpus consists of over three thousand pairs of abstracts and significance
statements from diverse disciplines. We then fine-tuned four language models
using this corpus. The outputs from the models were subsequently examined both
quantitatively for accessibility and semantic coherence, and qualitatively for
language quality, faithfulness, and completeness. Our findings show that the
resulting models can improve readability by over three grade levels, while
maintaining fidelity to the original content. Although commercial
state-of-the-art models still hold an edge, our models are much more compact,
can be deployed locally in an affordable manner, and alleviate the privacy
concerns associated with using commercial models. We envision this work as a
step toward more inclusive and accessible libraries, improving our services for
young readers and those without a college degree.

摘要：作為知識傳播的最前線，數位圖書館管理著龐大科學文獻的集合。然而，這些學術寫作通常充滿術語，並針對領域專家量身打造，而非一般大眾。身為圖書館員，我們致力於為多元受眾提供服務，包括閱讀能力較低者。為了將我們的服務擴展到單純存取之外，我們建議微調語言模型，將學術摘要改寫為更易於理解的版本，從而讓學術文獻在需要時更易於存取。我們首先引入一個專門設計用於訓練模型以簡化學術摘要的語料庫。此語料庫包含來自不同領域的三千多對摘要和重要性聲明。然後，我們使用此語料庫微調了四個語言模型。接著，從模型輸出的結果中，我們定量檢查了可存取性和語義相干性，並定性檢查了語言品質、忠實度和完整性。我們的研究結果顯示，這些模型可以將可讀性提升超過三個年級程度，同時維持對原始內容的忠實度。儘管商業最先進的模型仍佔有一席之地，但我們的模型更為精簡，可以經濟實惠的方式在本地部署，並減輕與使用商業模型相關的隱私問題。我們將這項工作視為邁向更具包容性和可存取性的圖書館的一步，改善我們對年輕讀者和沒有大學學位的讀者的服務。

##### **MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**
2408.03892v1 by Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma

Cyber-Physical Systems (CPSs) are increasingly prevalent across various
industrial and daily-life domains, with applications ranging from robotic
operations to autonomous driving. With recent advancements in artificial
intelligence (AI), learning-based components, especially AI controllers, have
become essential in enhancing the functionality and efficiency of CPSs.
However, the lack of interpretability in these AI controllers presents
challenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).
Existing methods for improving the safety of AI controllers often involve
neural network repair, which requires retraining with additional adversarial
examples or access to detailed internal information of the neural network.
Hence, these approaches have limited applicability for black-box policies,
where only the inputs and outputs are accessible during operation. To overcome
this, we propose MORTAR, a runtime action repair framework designed for AI-CPSs
in this work. MORTAR begins by constructing a prediction model that forecasts
the quality of actions proposed by the AI controller. If an unsafe action is
detected, MORTAR then initiates a repair process to correct it. The generation
of repaired actions is achieved through an optimization process guided by the
safety estimates from the prediction model. We evaluate the effectiveness of
MORTAR across various CPS tasks and AI controllers. The results demonstrate
that MORTAR can efficiently improve task completion rates of AI controllers
under specified safety specifications. Meanwhile, it also maintains minimal
computational overhead, ensuring real-time operation of the AI-CPSs.

摘要：網路物理系統 (CPS) 在各種產業和日常生活領域中越來越普遍，應用範圍從機器人作業到自動駕駛。隨著人工智慧 (AI) 的最新進展，基於學習的元件，尤其是 AI 控制器，已成為增強 CPS 功能和效率的必要條件。
然而，這些 AI 控制器缺乏可解釋性，對 AI 驅動的 CPS (AI-CPS) 的安全性與品質保證提出了挑戰。現有的改善 AI 控制器安全性的方法通常涉及神經網路修復，這需要使用額外的對抗性範例重新訓練或取得神經網路的詳細內部資訊。
因此，這些方法對於黑盒政策的適用性有限，因為在操作期間只能存取輸入和輸出。為了克服這個問題，我們在這項工作中提出了 MORTAR，一個專為 AI-CPS 設計的執行時間動作修復架構。MORTAR 首先建立一個預測模型，用於預測 AI 控制器建議的動作品質。如果偵測到不安全的動作，MORTAR 接著會啟動一個修復程序來修正它。修復動作的產生是透過一個最佳化程序達成，這個程序由預測模型的安全估計值引導。我們評估了 MORTAR 在各種 CPS 任務和 AI 控制器中的有效性。結果證明 MORTAR 能在指定的安全性規範下有效率地改善 AI 控制器的任務完成率。同時，它也維持最小的運算負擔，確保 AI-CPS 的即時操作。

##### **Personalized Clinical Note Generation from Doctor-Patient Conversations**
2408.03874v1 by Nathan Brake, Thomas Schaaf

In this work, we present a novel technique to improve the quality of draft
clinical notes for physicians. This technique is concentrated on the ability to
model implicit physician conversation styles and note preferences. We also
introduce a novel technique for the enrollment of new physicians when a limited
number of clinical notes paired with conversations are available for that
physician, without the need to re-train a model to support them. We show that
our technique outperforms the baseline model by improving the ROUGE-2 score of
the History of Present Illness section by 13.8%, the Physical Examination
section by 88.6%, and the Assessment & Plan section by 50.8%.

摘要：在這項工作中，我們提出了一種新的技術來改善醫師的臨床草稿筆記品質。此技術集中在模擬隱含的醫師對話風格和筆記偏好的能力。我們還引入了一種新的技術，用於在只有少數配對對話的臨床筆記可用於該醫師時註冊新醫師，而無需重新訓練模型來支援他們。我們展示了我們的技術通過將現病史部分的 ROUGE-2 分數提高 13.8%、身體檢查部分提高 88.6%、評估和計畫部分提高 50.8%，表現優於基準模型。

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

摘要：時間序列預測在許多領域中都是一項重要的任務，從供應鏈管理到天氣預測都有涉及。最近，Transformer 神經網路架構在常見時間序列基準資料集的預測中展現了令人滿意的成果。然而，應用於供應鏈需求預測的範疇受到限制，因為供應鏈需求預測可能具有稀疏性和跨系列效應等具挑戰性的特徵。
  在這項工作中，我們探討了將基於 Transformer 的模型應用於供應鏈需求預測。特別是，我們開發了一種新的基於 Transformer 的預測方法，使用一個共用的、每個時間序列的多任務網路，並在初始元件中套用跨時間序列的注意力，以擷取互動並協助解決稀疏性問題。我們提供了一個案例研究，應用我們的做法成功改善了一家醫療器材製造公司的需求預測。為了進一步驗證我們的做法，我們也將其應用於公開的需求預測資料集，並證明與各種基線和最先進的預測方法相比，在私有和公開資料集中的表現具有競爭力或優於這些方法。

##### **BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**
2408.03871v1 by Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic

In this system report, we describe the models and methods we used for our
participation in the PLABA2023 task on biomedical abstract simplification, part
of the TAC 2023 tracks. The system outputs we submitted come from the following
three categories: 1) domain fine-tuned T5-like models including Biomedical-T5
and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes
(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we
carried out for this task on BioGPT finetuning. In the official automatic
evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model
LaySciFive ranks 3rd among all 13 evaluated systems. In the official human
evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score
92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It
also produced a high score 91.57 on Fluency in comparison to the highest score
93.53. In the second round of submissions, our team using ChatGPT-prompting
ranks the 2nd in several categories including simplified term accuracy score
92.26 and completeness score 96.58, and a very similar score on faithfulness
score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our
codes, fine-tuned models, prompts, and data splits from the system development
stage will be available at https://github.com/ HECTA-UoM/PLABA-MU

摘要：<paragraph>在這個系統報告中，我們描述了我們在 TAC 2023 軌道的一部分，PLABA2023 生物醫學摘要簡化任務中所使用的模型和方法。我們提交的系統輸出來自以下三種類別：1) 領域微調的 T5 類似模型，包括 Biomedical-T5 和 Lay-SciFive；2) 微調 BARTLarge 模型，具有可控屬性（通過代幣）BART-w-CTs；3) ChatGPT 提示。我們還展示了我們在 BioGPT 微調中為這項任務所做的工作。在使用 SARI 分數的官方自動評估中，BeeManc 在所有團隊中排名第 2，我們的模型 LaySciFive 在所有 13 個評估系統中排名第 3。在官方人工評估中，我們的模型 BART-w-CTs 在句子簡潔性（分數 92.84）中排名第 2，在術語簡潔性（分數 82.33）中排名第 3，在所有 7 個評估系統中排名第 3；它還產生了 91.57 的高流暢度分數，而最高分為 93.53。在第二輪提交中，我們使用 ChatGPT 提示的團隊在幾個類別中排名第 2，包括簡化術語準確度分數 92.26 和完整性分數 96.58，以及對 PLABA-base-1（95.73）重新評估的忠實度分數 95.3 非常相似通過人工評估。我們的代碼、微調模型、提示和系統開發階段的數據分割將在 https://github.com/ HECTA-UoM/PLABA-MU 中提供</paragraph>

##### **Why transformers are obviously good models of language**
2408.03855v1 by Felix Hill

Nobody knows how language works, but many theories abound. Transformers are a
class of neural networks that process language automatically with more success
than alternatives, both those based on neural computations and those that rely
on other (e.g. more symbolic) mechanisms. Here, I highlight direct connections
between the transformer architecture and certain theoretical perspectives on
language. The empirical success of transformers relative to alternative models
provides circumstantial evidence that the linguistic approaches that
transformers embody should be, at least, evaluated with greater scrutiny by the
linguistics community and, at best, considered to be the currently best
available theories.

摘要：沒有人知道語言是如何運作的，但有許多理論流傳。Transformer是一種神經網路，可以自動處理語言，比其他基於神經運算和依賴其他（例如更具象徵性的）機制的替代方案更成功。在此，我重點說明Transformer架構與語言的某些理論觀點之間的直接關聯。Transformer相對於替代模型的經驗成功提供了環境證據，證明Transformer所體現的語言方法應至少受到語言學界的更嚴格評估，並在最好的情況下被認為是當前可用的最佳理論。

##### **Hate Speech Detection and Classification in Amharic Text with Deep Learning**
2408.03849v1 by Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie

Hate speech is a growing problem on social media. It can seriously impact
society, especially in countries like Ethiopia, where it can trigger conflicts
among diverse ethnic and religious groups. While hate speech detection in
resource rich languages are progressing, for low resource languages such as
Amharic are lacking. To address this gap, we develop Amharic hate speech data
and SBi-LSTM deep learning model that can detect and classify text into four
categories of hate speech: racial, religious, gender, and non-hate speech. We
have annotated 5k Amharic social media post and comment data into four
categories. The data is annotated using a custom annotation tool by a total of
100 native Amharic speakers. The model achieves a 94.8 F1-score performance.
Future improvements will include expanding the dataset and develop state-of-the
art models.
  Keywords: Amharic hate speech detection, classification, Amharic dataset,
Deep Learning, SBi-LSTM

摘要：仇恨言論是社群媒體上日益嚴重的問題。它會嚴重影響社會，特別是在像衣索比亞這樣的國家，它會引發不同種族和宗教團體之間的衝突。雖然資源豐富的語言仇恨言論偵測正在進展中，但像阿姆哈拉語這樣的低資源語言卻缺乏。為了解決這個差距，我們開發了阿姆哈拉語仇恨言論資料和 SBi-LSTM 深度學習模型，可以偵測並將文字分類為四種類別的仇恨言論：種族、宗教、性別和非仇恨言論。我們已將 5 千個阿姆哈拉語社群媒體貼文和留言資料註解為四種類別。資料是由總共 100 位母語為阿姆哈拉語的講者使用自訂註解工具進行註解。該模型達到了 94.8 的 F1 分數表現。未來的改進將包括擴充資料集和開發最先進的模型。
關鍵字：阿姆哈拉語仇恨言論偵測、分類、阿姆哈拉語資料集、深度學習、SBi-LSTM

##### **MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**
2408.03841v1 by Yuchen Dong, XiaoXiang Fang, Yuchen Hu, Renshuang Jiang, Zhe Jiang

The application of large language models to facilitate automated software
operations and tool generation (SOTG), thus augmenting software productivity,
mirrors the early stages of human evolution when the ability to create and use
tools accelerated the progress of civilization. These complex tasks require AI
to continuously summarize and improve. Current research often overlooks the
importance of converting real-time task experiences into system memory and
differentiating the value of existing knowledge for future reference. This
paper addresses these issues by evolving external memory models into
Memory-Loop Networks for timely memorization and experience referencing. We
also enhance a RAG mechanism with knowledge precision segmentation to utilize
memory based on value differentiation, and design the MaxMind model for SOTG
accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an
electronic spreadsheet processing system aligned with the MaxMind philosophy.
Comparative experiments with SheetCopilot have demonstrated that the
accumulation and recycling of task memories lead to a steady enhancement in
task success rate, with an improvement rate of approximately 3%-6% per round in
this implementation example. Note that as the memories continue to grow, this
cumulative improvement may be substantial. The inclusion of memory recycling
can also boost the system's task execution efficiency by up to 25%, and it can
address the retraining issue faced by LLMs when handling specialized tasks
through memories transfer.These suggest that MaxMind has significant potential
to enhance the capabilities and productivity of LLM systems in SOTG.

摘要：大型語言模型的應用有助於促進自動化軟體操作和工具生成 (SOTG)，進而提升軟體生產力，這反映了人類演化的早期階段，當時創造和使用工具的能力加速了文明的進步。這些複雜的任務需要 AI 持續總結和改進。目前的許多研究常常忽略將即時任務經驗轉換為系統記憶，以及區分現有知識對未來參考價值的重要性。本文透過將外部記憶模型演變成記憶迴圈網路，以實現及時記憶和經驗參考，來解決這些問題。我們也透過知識精準分段來強化 RAG 機制，以根據價值區分來利用記憶，並據此設計用於 SOTG 的 MaxMind 模型。為了展示我們的做法，我們開發了 MaxMind4Sheet，這是一個與 MaxMind 理念一致的電子試算表處理系統。與 SheetCopilot 進行的比較實驗已證明，任務記憶的累積和再利用會持續提升任務成功率，在此實作範例中，每回合的提升率約為 3%-6%。請注意，隨著記憶的持續增加，這種累積提升可能會很可觀。納入記憶再利用也能提升系統的任務執行效率，最高可達 25%，而且它能透過記憶轉移來解決 LLM 在處理專業任務時所面臨的重新訓練問題。這些都顯示出 MaxMind 在提升 LLM 系統在 SOTG 中的能力和生產力方面具有顯著的潛力。

##### **WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**
2408.03837v1 by Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria

WalledEval is a comprehensive AI safety testing toolkit designed to evaluate
large language models (LLMs). It accommodates a diverse range of models,
including both open-weight and API-based ones, and features over 35 safety
benchmarks covering areas such as multilingual safety, exaggerated safety, and
prompt injections. The framework supports both LLM and judge benchmarking, and
incorporates custom mutators to test safety against various text-style
mutations such as future tense and paraphrasing. Additionally, WalledEval
introduces WalledGuard, a new, small and performant content moderation tool,
and SGXSTest, a benchmark for assessing exaggerated safety in cultural
contexts. We make WalledEval publicly available at
https://github.com/walledai/walledevalA.

摘要：WalledEval 是一個全面的 AI 安全測試工具包，旨在評估大型語言模型 (LLM)。它容納了各種模型，包括開放權重和基於 API 的模型，並具有超過 35 個安全基準，涵蓋多語言安全、誇張安全和提示注入等領域。該框架支援 LLM 和評審基準測試，並整合自訂變異器，以針對各種文字樣式變異（例如未來式和同義改寫）測試安全性。此外，WalledEval 引入了 WalledGuard，這是一個新的、小巧且高效的內容審核工具，以及 SGXSTest，一個用於評估文化背景中誇大安全性的基準。我們在 https://github.com/walledai/walledevalA 上公開 WalledEval。

##### **Target Prompting for Information Extraction with Vision Language Model**
2408.03834v1 by Dipankar Medhi

The recent trend in the Large Vision and Language model has brought a new
change in how information extraction systems are built. VLMs have set a new
benchmark with their State-of-the-art techniques in understanding documents and
building question-answering systems across various industries. They are
significantly better at generating text from document images and providing
accurate answers to questions. However, there are still some challenges in
effectively utilizing these models to build a precise conversational system.
General prompting techniques used with large language models are often not
suitable for these specially designed vision language models. The output
generated by such generic input prompts is ordinary and may contain information
gaps when compared with the actual content of the document. To obtain more
accurate and specific answers, a well-targeted prompt is required by the vision
language model, along with the document image. In this paper, a technique is
discussed called Target prompting, which focuses on explicitly targeting parts
of document images and generating related answers from those specific regions
only. The paper also covers the evaluation of response for each prompting
technique using different user queries and input prompts.

摘要：近期大型視覺與語言模型的趨勢為資訊萃取系統的建置方式帶來了新的變化。VLMs 以其在理解文件和建立跨產業問答系統的最新技術樹立了新的基準。它們在從文件影像產生文字和提供準確的答案方面顯著地更出色。然而，在有效利用這些模型來建立精確的對話系統方面仍有一些挑戰。與大型語言模型一起使用的一般提示技術通常不適合這些特別設計的視覺語言模型。此類一般輸入提示產生的輸出很普通，與文件的實際內容相比時可能會包含資訊差距。為了獲得更準確且具體的答案，視覺語言模型需要一個明確的目標提示，以及文件影像。在本文中，討論了一種稱為目標提示的技術，其專注於明確鎖定文件影像的部分，並僅從那些特定區域產生相關答案。本文還涵蓋了使用不同的使用者查詢和輸入提示對每種提示技術的回應評估。

##### **Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**
2408.03827v1 by Forough Mehralian, Titus Barik, Jeff Nichols, Amanda Swearngin

Accessibility is crucial for inclusive app usability, yet developers often
struggle to identify and fix app accessibility issues due to a lack of
awareness, expertise, and inadequate tools. Current accessibility testing tools
can identify accessibility issues but may not always provide guidance on how to
address them. We introduce FixAlly, an automated tool designed to suggest
source code fixes for accessibility issues detected by automated accessibility
scanners. FixAlly employs a multi-agent LLM architecture to generate fix
strategies, localize issues within the source code, and propose code
modification suggestions to fix the accessibility issue. Our empirical study
demonstrates FixAlly's capability in suggesting fixes that resolve issues found
by accessibility scanners -- with an effectiveness of 77% in generating
plausible fix suggestions -- and our survey of 12 iOS developers finds they
would be willing to accept 69.4% of evaluated fix suggestions.

摘要：無障礙功能對於包容性應用程式可用性至關重要，但開發人員經常因缺乏意識、專業知識和工具不足而難以識別和修復應用程式無障礙性問題。目前的無障礙性測試工具可以識別無障礙性問題，但可能無法始終提供如何解決這些問題的指導。我們介紹 FixAlly，這是一個自動化工具，旨在為自動化無障礙性掃描器檢測到的無障礙性問題建議原始碼修復程式。FixAlly 採用多代理 LLM 架構來產生修復策略，在原始碼中找出問題，並提出修復無障礙性問題的程式碼修改建議。我們的實證研究證明了 FixAlly 在建議修復程式以解決無障礙性掃描器發現的問題方面的能力——在產生看似合理的修復建議方面有效率為 77%——而且我們對 12 位 iOS 開發人員的調查發現，他們願意接受 69.4% 的評估修復建議。

##### **Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning**
2408.03819v1 by Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby Jia-Jun Li

Active Learning (AL) allows models to learn interactively from user feedback.
This paper introduces a counterfactual data augmentation approach to AL,
particularly addressing the selection of datapoints for user querying, a
pivotal concern in enhancing data efficiency. Our approach is inspired by
Variation Theory, a theory of human concept learning that emphasizes the
essential features of a concept by focusing on what stays the same and what
changes. Instead of just querying with existing datapoints, our approach
synthesizes artificial datapoints that highlight potential key similarities and
differences among labels using a neuro-symbolic pipeline combining large
language models (LLMs) and rule-based models. Through an experiment in the
example domain of text classification, we show that our approach achieves
significantly higher performance when there are fewer annotated data. As the
annotated training data gets larger the impact of the generated data starts to
diminish showing its capability to address the cold start problem in AL. This
research sheds light on integrating theories of human learning into the
optimization of AL.

摘要：主動學習 (AL) 允許模型從使用者回饋中互動式地學習。
本文介紹一種反事實資料擴充方法到 AL，
特別處理使用者查詢資料點的選擇，這是提升資料效率的關鍵問題。我們的做法受到變異理論的啟發，一種強調概念的本質特徵，著重於什麼保持不變和什麼改變的人類概念學習理論。我們的做法並非僅使用現有資料點查詢，而是使用結合大型語言模型 (LLM) 和基於規則模型的神經符號管線，合成人工資料點，以突顯標籤之間的潛在關鍵相似性和差異。透過在文字分類範例領域中的實驗，我們顯示我們的做法在註解資料較少時，可達到顯著更高的效能。隨著註解訓練資料變大，生成資料的影響開始減弱，顯示其解決 AL 中冷啟動問題的能力。這項研究說明了將人類學習理論整合到 AL 最佳化中的方法。

##### **Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring**
2408.03811v1 by Zifan Wang, Christopher Ormerod

Automated Short Answer Scoring (ASAS) is a critical component in educational
assessment. While traditional ASAS systems relied on rule-based algorithms or
complex deep learning methods, recent advancements in Generative Language
Models (GLMs) offer new opportunities for improvement. This study explores the
application of GLMs to ASAS, leveraging their off-the-shelf capabilities and
performance in various domains. We propose a novel pipeline that combines
vector databases, transformer-based encoders, and GLMs to enhance short answer
scoring accuracy. Our approach stores training responses in a vector database,
retrieves semantically similar responses during inference, and employs a GLM to
analyze these responses and determine appropriate scores. We further optimize
the system through fine-tuned retrieval processes and prompt engineering.
Evaluation on the SemEval 2013 dataset demonstrates a significant improvement
on the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,
highlighting the potential of GLMs in advancing ASAS technology.

摘要：自動化簡答評分 (ASAS) 是教育評量中的關鍵組成部分。雖然傳統的 ASAS 系統依賴於基於規則的演算法或複雜的深度學習方法，但生成式語言模型 (GLM) 的近期進展為改進提供了新的機會。本研究探討了 GLM 在 ASAS 中的應用，利用它們的現成功能和在各種領域的效能。我們提出了一個新穎的管道，結合了向量資料庫、基於轉換器的編碼器和 GLM，以提高簡答評分準確度。我們的做法是將訓練回應儲存在向量資料庫中，在推論過程中擷取語義上相似的回應，並採用 GLM 來分析這些回應並確定適當的分數。我們進一步透過微調擷取流程和提示工程來優化系統。在 SemEval 2013 資料集上的評估顯示，與現有方法相比，在 SCIENTSBANK 三向和二向任務上有了顯著的改進，突顯了 GLM 在推進 ASAS 技術方面的潛力。

##### **Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning**
2408.03807v1 by Martin Moder, Stephen Adhisaputra, Josef Pauli

This paper addresses navigation in crowded environments by integrating
goal-conditioned generative models with Sampling-based Model Predictive Control
(SMPC). We introduce goal-conditioned autoregressive models to generate crowd
behaviors, capturing intricate interactions among individuals. The model
processes potential robot trajectory samples and predicts the reactions of
surrounding individuals, enabling proactive robotic navigation in complex
scenarios. Extensive experiments show that this algorithm enables real-time
navigation, significantly reducing collision rates and path lengths, and
outperforming selected baseline methods. The practical effectiveness of this
algorithm is validated on an actual robotic platform, demonstrating its
capability in dynamic settings.

摘要：本文透過整合目標條件生成模型與基於取樣的模型預測控制 (SMPC) 來探討擁擠環境中的導航。我們引進目標條件自迴歸模型來產生群眾行為，捕捉個人之間的複雜互動。此模型處理潛在機器人軌跡範例，並預測周圍個體的反應，讓機器人在複雜場景中能進行主動導航。廣泛的實驗顯示，此演算法能進行即時導航，大幅降低碰撞率和路徑長度，並且優於選定的基線方法。此演算法的實用有效性已在實際機器人平台上驗證，證明其在動態設定中的能力。

##### **Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations**
2408.03772v1 by Erica Coppolillo, Giuseppe Manco, Aristides Gionis

Providing recommendations that are both relevant and diverse is a key
consideration of modern recommender systems. Optimizing both of these measures
presents a fundamental trade-off, as higher diversity typically comes at the
cost of relevance, resulting in lower user engagement. Existing recommendation
algorithms try to resolve this trade-off by combining the two measures,
relevance and diversity, into one aim and then seeking recommendations that
optimize the combined objective, for a given number of items to recommend.
Traditional approaches, however, do not consider the user interaction with the
recommended items.
  In this paper, we put the user at the central stage, and build on the
interplay between relevance, diversity, and user behavior. In contrast to
applications where the goal is solely to maximize engagement, we focus on
scenarios aiming at maximizing the total amount of knowledge encountered by the
user. We use diversity as a surrogate of the amount of knowledge obtained by
the user while interacting with the system, and we seek to maximize diversity.
We propose a probabilistic user-behavior model in which users keep interacting
with the recommender system as long as they receive relevant recommendations,
but they may stop if the relevance of the recommended items drops. Thus, for a
recommender system to achieve a high-diversity measure, it will need to produce
recommendations that are both relevant and diverse.
  Finally, we propose a novel recommendation strategy that combines relevance
and diversity by a copula function. We conduct an extensive evaluation of the
proposed methodology over multiple datasets, and we show that our strategy
outperforms several state-of-the-art competitors. Our implementation is
publicly available at https://github.com/EricaCoppolillo/EXPLORE.

摘要：提供既相關又多樣化的建議是現代推薦系統的一項重要考量。最佳化這兩個指標會產生根本性的取捨，因為更高的多樣性通常會以相關性為代價，導致使用者的參與度降低。現有的推薦演算法會嘗試透過將這兩個指標（相關性和多樣性）結合為一個目標，然後尋找最佳化結合目標的建議，以推薦給定的項目數量來解決此取捨。然而，傳統方法並未考量使用者與推薦項目的互動。
  
在本文中，我們將使用者置於核心階段，並建立在相關性、多樣性和使用者行為之間的交互作用上。與目標僅為最大化參與度的應用程式相反，我們專注於旨在最大化使用者所遭遇的總知識量的場景。我們將多樣性用作使用者與系統互動時所獲得知識量的替代指標，並且我們尋求最大化多樣性。我們提出一個機率性的使用者行為模型，在其中使用者會持續與推薦系統互動，只要他們收到相關的建議，但如果推薦項目的相關性下降，他們可能會停止互動。因此，對於推薦系統來說，若要達成高多樣性指標，它需要產生既相關又多樣化的建議。
  
最後，我們提出一個新穎的推薦策略，透過一個連接函數將相關性和多樣性結合起來。我們對所提出的方法在多個資料集上進行廣泛的評估，並且我們顯示我們的策略優於數個最先進的競爭者。我們的實作公開於 https://github.com/EricaCoppolillo/EXPLORE。

##### **'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization**
2408.03762v1 by Meisin Lee, Soon Lay-Ki

This paper presents our participation under the team name `Finance Wizard' in
the FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It
documents our pipeline approach of fine-tuning a foundation model into a
task-specific model for Financial Text Summarization. It involves (1) adapting
Llama3 8B, a foundation model, to the Finance domain via continued
pre-training, (2) multi-task instruction-tuning to further equip the model with
more finance-related capabilities, (3) finally fine-tuning the model into a
task-specific `expert'. Our model, FinLlama3\_sum, yielded commendable results,
securing the third position in its category with a ROUGE-1 score of 0.521.

摘要：本文介紹我們在 FinNLP-AgentScen 2024 共享任務 #2：財務文本摘要中以「Finance Wizard」為隊名參與的過程。它記錄了我們將基礎模型微調為財務文本摘要任務特定模型的管道方法。它包括 (1) 透過持續預訓練將基礎模型 Llama3 8B 調整為財務領域，(2) 多任務指令微調，進一步為模型裝備更多與財務相關的能力，(3) 最後微調模型成為任務特定的「專家」。我們的模型 FinLlama3_sum 獲得了令人稱道的結果，在 ROUGE-1 分數為 0.521 的類別中獲得了第三名。

##### **Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions**
2408.03747v1 by Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna V. Kononova

Time-series anomaly detection plays an important role in engineering
processes, like development, manufacturing and other operations involving
dynamic systems. These processes can greatly benefit from advances in the
field, as state-of-the-art approaches may aid in cases involving, for example,
highly dimensional data. To provide the reader with understanding of the
terminology, this survey introduces a novel taxonomy where a distinction
between online and offline, and training and inference is made. Additionally,
it presents the most popular data sets and evaluation metrics used in the
literature, as well as a detailed analysis. Furthermore, this survey provides
an extensive overview of the state-of-the-art model-based online semi- and
unsupervised anomaly detection approaches for multivariate time-series data,
categorising them into different model families and other properties. The
biggest research challenge revolves around benchmarking, as currently there is
no reliable way to compare different approaches against one another. This
problem is two-fold: on the one hand, public data sets suffers from at least
one fundamental flaw, while on the other hand, there is a lack of intuitive and
representative evaluation metrics in the field. Moreover, the way most
publications choose a detection threshold disregards real-world conditions,
which hinders the application in the real world. To allow for tangible advances
in the field, these issues must be addressed in future work.

摘要：時間序列異常偵測在工程製程中扮演著重要的角色，例如開發、製造和涉及動態系統的其他作業。這些製程可以從該領域的進展中獲益良多，因為最先進的方法可以協助處理例如高維度資料的案例。為了讓讀者了解術語，本調查引入了一個新的分類法，其中區分了線上和離線，以及訓練和推論。此外，它還介紹了文獻中使用最廣泛的資料集和評估指標，以及詳細的分析。此外，本調查提供了基於模型的線上半監督和非監督異常偵測方法的最新技術的廣泛概述，並將其分類為不同的模型家族和其他屬性。最大的研究挑戰圍繞著基準測試，因為目前沒有可靠的方法可以將不同的方法相互比較。這個問題有兩個方面：一方面，公開資料集至少存在一個基本缺陷，另一方面，該領域缺乏直觀且具代表性的評估指標。此外，大多數出版物選擇偵測閾值的方式不考慮現實世界的條件，這阻礙了在現實世界中的應用。為了讓該領域有具體的進展，這些問題必須在未來的研究中加以解決。

##### **Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling**
2408.03746v1 by Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley

Bayesian Last Layer (BLL) models focus solely on uncertainty in the output
layer of neural networks, demonstrating comparable performance to more complex
Bayesian models. However, the use of Gaussian priors for last layer weights in
Bayesian Last Layer (BLL) models limits their expressive capacity when faced
with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this
shortfall, we introduce a novel approach that combines diffusion techniques and
implicit priors for variational learning of Bayesian last layer weights. This
method leverages implicit distributions for modeling weight priors in BLL,
coupled with diffusion samplers for approximating true posterior predictions,
thereby establishing a comprehensive Bayesian prior and posterior estimation
strategy. By delivering an explicit and computationally efficient variational
lower bound, our method aims to augment the expressive abilities of BLL models,
enhancing model accuracy, calibration, and out-of-distribution detection
proficiency. Through detailed exploration and experimental validation, We
showcase the method's potential for improving predictive accuracy and
uncertainty quantification while ensuring computational efficiency.

摘要：貝氏最後一層 (BLL) 模型專注於神經網路輸出層的不確定性，展現出與更複雜的貝氏模型相近的效能。然而，在貝氏最後一層 (BLL) 模型中，使用高斯先驗來作為最後一層權重，會在面對非高斯、異常值豐富或高維度資料集時，限制其表達能力。為了解決這個缺點，我們提出一個新穎的方法，結合擴散技術和隱式先驗，用於貝氏最後一層權重的變異學習。此方法利用隱式分佈來對 BLL 中的權重先驗進行建模，並結合擴散採樣器來逼近真實後驗預測，從而建立一個全面的貝氏先驗和後驗估計策略。透過提供一個明確且計算效率高的變異下界，我們的方法旨在擴充 BLL 模型的表達能力，提升模型準確度、校準和異常偵測能力。透過詳細的探討和實驗驗證，我們展示了此方法在提升預測準確度和不確定性量化的潛力，同時確保計算效率。

##### **Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification**
2408.03745v1 by Georgia Sovatzidi, Michael D. Vasilakakis, Dimitris K. Iakovidis

The interpretability of machine learning models is critical, as users may be
reluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been
proposed as an extension of FCMs offering a natural mechanism to assess the
quality of their output through the estimation of hesitancy, a concept
resembling to human hesitation in decision making. To address the challenge of
interpretable image classification, this paper introduces a novel framework,
named Interpretable Intuitionistic FCM (I2FCM) which is domain-independent,
simple to implement, and can be applied on Convolutional Neural Network (CNN)
models, rendering them interpretable. To the best of our knowledge this is the
first time iFCMs are applied for image classification. Further novel
contributions include: a feature extraction process focusing on the most
informative image regions; a learning algorithm for data-driven determination
of the intuitionistic fuzzy interconnections of the iFCM; an inherently
interpretable classification approach based on image contents. In the context
of image classification, hesitancy is considered as a degree of inconfidence
with which an image is categorized to a class. The constructed iFCM model
distinguishes the most representative image semantics and analyses them
utilizing cause-and-effect relations. The effectiveness of the introduced
framework is evaluated on publicly available datasets, and the experimental
results confirm that it can provide enhanced classification performance, while
providing interpretable inferences.

摘要：機器學習模型的可解釋性至關重要，因為使用者可能不願意依賴其推論。直覺主義模糊聚類（iFCM）已被提出作為 FCM 的延伸，提供一種自然機制，通過估計猶豫程度來評估其輸出的品質，猶豫程度是一個類似於人類在決策中猶豫的概念。為了應對可解釋影像分類的挑戰，本文介紹了一個新穎的框架，稱為可解釋直覺主義模糊聚類（I2FCM），它與領域無關，易於實作，並且可以應用於卷積神經網路（CNN）模型，使其可解釋。據我們所知，這是 iFCM 首次應用於影像分類。進一步的新穎貢獻包括：專注於最有意義影像區域的特徵萃取過程；用於資料驅動的 iFCM 直覺模糊互連確定的學習演算法；一種基於影像內容的內在可解釋分類方法。在影像分類的背景下，猶豫程度被視為將影像分類到類別的不確定程度。建構的 iFCM 模型區分最具代表性的影像語義，並利用因果關係對其進行分析。所提出的框架的有效性在公開可用的資料集上得到評估，實驗結果證實它可以提供增強的分類效能，同時提供可解釋的推論。

##### **Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation**
2408.03735v1 by Jingjing Xie, Yuxin Zhang, Mingbao Lin, Liujuan Cao, Rongrong Ji

This paper presents the first study to explore the potential of parameter
quantization for multimodal large language models to alleviate the significant
resource constraint encountered during vision-language instruction tuning. We
introduce a Quantization-aware Scale LeArning method based on multimodal
Warmup, termed QSLAW. This method is grounded in two key innovations: (1) The
learning of group-wise scale factors for quantized LLM weights to mitigate the
quantization error arising from activation outliers and achieve more effective
vision-language instruction tuning; (2) The implementation of a multimodal
warmup that progressively integrates linguistic and multimodal training
samples, thereby preventing overfitting of the quantized model to multimodal
data while ensuring stable adaptation of multimodal large language models to
downstream vision-language tasks. Extensive experiments demonstrate that models
quantized by QSLAW perform on par with, or even surpass, their full-precision
counterparts, while facilitating up to 1.4 times reduction in VL tuning time
and GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.

摘要：本文提出了第一项研究，探讨参数量化在多模态大型语言模型中的潜力，以缓解在视觉语言指令调整期间遇到的重大资源限制。我们引入了一种基于多模态预热量化感知量化学习方法，称为 QSLAW。此方法基于两项关键创新：(1) 学习量化 LLM 权重的组级比例因子，以减轻由激活值异常值引起的量化误差，并实现更有效的视觉语言指令调整；(2) 实施多模态预热，逐渐集成语言和多模态训练样本，从而防止量化模型过度拟合多模态数据，同时确保多模态大型语言模型稳定适应下游视觉语言任务。大量实验表明，由 QSLAW 量化的模型性能与它们的完全精度对应模型相当，甚至超过它们，同时将 VL 调整时间和 GPU 消耗减少了 1.4 倍。我们的代码已发布在 https://github.com/xjjxmu/QSLAW。

##### **Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks**
2408.03732v1 by Zizhang Chen, Pengyu Hong, Sandeep Madireddy

Uncertainty quantification enables users to assess the reliability of
responses generated by large language models (LLMs). We present a novel
Question Rephrasing technique to evaluate the input uncertainty of LLMs, which
refers to the uncertainty arising from equivalent variations of the inputs
provided to LLMs. This technique is integrated with sampling methods that
measure the output uncertainty of LLMs, thereby offering a more comprehensive
uncertainty assessment. We validated our approach on property prediction and
reaction prediction for molecular chemistry tasks.

摘要：不確定量化使用戶能夠評估大型語言模型 (LLM) 所產生的回應可靠性。我們提出了一種新穎的問題重述技術，用於評估 LLM 的輸入不確定性，這指的是提供給 LLM 的輸入等效變化所產生的不確定性。此技術與用於測量 LLM 輸出不確定性的抽樣方法整合在一起，從而提供更全面的不確定性評估。我們驗證了我們在分子化學任務中對性質預測和反應預測的方法。

##### **Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction**
2408.03706v1 by Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, Milica Gašić

A common approach for sequence tagging tasks based on contextual word
representations is to train a machine learning classifier directly on these
embedding vectors. This approach has two shortcomings. First, such methods
consider single input sequences in isolation and are unable to put an
individual embedding vector in relation to vectors outside the current local
context of use. Second, the high performance of these models relies on
fine-tuning the embedding model in conjunction with the classifier, which may
not always be feasible due to the size or inaccessibility of the underlying
feature-generation model. It is thus desirable, given a collection of embedding
vectors of a corpus, i.e., a datastore, to find features of each vector that
describe its relation to other, similar vectors in the datastore. With this in
mind, we introduce complexity measures of the local topology of the latent
space of a contextual language model with respect to a given datastore. The
effectiveness of our features is demonstrated through their application to
dialogue term extraction. Our work continues a line of research that explores
the manifold hypothesis for word embeddings, demonstrating that local structure
in the space carved out by word embeddings can be exploited to infer semantic
properties.

摘要：基於上下文詞彙表徵的序列標註任務，常見方法是直接在這些嵌入向量上訓練機器學習分類器。這種方法有兩個缺點。首先，此類方法孤立地考慮單一輸入序列，無法將個別嵌入向量與當前局部使用情境外的向量建立關係。其次，這些模型的高效能仰賴於將嵌入模型與分類器結合進行微調，但由於底層特徵生成模型的規模或難以取得，這並不總是可行。因此，假設給定語料庫的嵌入向量集合，即資料儲存庫，理想的做法是找出每個向量的特徵，描述其與資料儲存庫中其他類似向量的關係。基於這個想法，我們針對上下文語言模型的潛在空間局部拓撲結構，相對於給定資料儲存庫，引入了複雜性測量。我們特徵的有效性透過應用於對話術語萃取來證明。我們的研究延續了一系列探討詞彙嵌入流形假說的探究，證明詞彙嵌入所構成的空間中的局部結構可用於推論語義屬性。

##### **A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework**
2408.03694v1 by Emna Baccour, Aiman Erbad, Amr Mohamed, Mounir Hamdi, Mohsen Guizani

The metaverse, envisioned as the next digital frontier for avatar-based
virtual interaction, involves high-performance models. In this dynamic
environment, users' tasks frequently shift, requiring fast model
personalization despite limited data. This evolution consumes extensive
resources and requires vast data volumes. To address this, meta-learning
emerges as an invaluable tool for metaverse users, with federated meta-learning
(FML), offering even more tailored solutions owing to its adaptive
capabilities. However, the metaverse is characterized by users heterogeneity
with diverse data structures, varied tasks, and uneven sample sizes,
potentially undermining global training outcomes due to statistical difference.
Given this, an urgent need arises for smart coalition formation that accounts
for these disparities. This paper introduces a dual game-theoretic framework
for metaverse services involving meta-learners as workers to manage FML. A
blockchain-based cooperative coalition formation game is crafted, grounded on a
reputation metric, user similarity, and incentives. We also introduce a novel
reputation system based on users' historical contributions and potential
contributions to present tasks, leveraging correlations between past and new
tasks. Finally, a Stackelberg game-based incentive mechanism is presented to
attract reliable workers to participate in meta-learning, minimizing users'
energy costs, increasing payoffs, boosting FML efficacy, and improving
metaverse utility. Results show that our dual game framework outperforms
best-effort, random, and non-uniform clustering schemes - improving training
performance by up to 10%, cutting completion times by as much as 30%, enhancing
metaverse utility by more than 25%, and offering up to 5% boost in training
efficiency over non-blockchain systems, effectively countering misbehaving
users.

摘要：元宇宙被设想为基于化身的虚拟交互的下一个数字前沿，涉及高性能模型。在这个动态环境中，用户的任务经常发生变化，需要快速模型个性化，尽管数据有限。这种演变消耗了大量资源，需要大量数据。为了解决这个问题，元学习作为元宇宙用户的宝贵工具出现，其中联邦元学习 (FML) 由于其自适应能力而提供了更多定制的解决方案。然而，元宇宙的特点是用户异构性，数据结构多样，任务各异，样本量不均，这可能会因统计差异而破坏全局训练结果。鉴于此，迫切需要建立考虑这些差异的智能联盟。本文介绍了一个双重博弈论框架，用于元宇宙服务，其中涉及元学习者作为工人来管理 FML。基于声誉指标、用户相似性和激励措施，构建了一个基于区块链的合作联盟形成博弈。我们还引入了一个基于用户历史贡献和对当前任务的潜在贡献的新声誉系统，利用过去和新任务之间的相关性。最后，提出了一个基于 Stackelberg 博弈的激励机制，以吸引可靠的工人参与元学习，最大限度地降低用户的能源成本，增加收益，提高 FML 效能，并提高元宇宙效用。结果表明，我们的双重博弈框架优于尽力而为、随机和非均匀聚类方案——将训练性能提高了 10%，将完成时间缩短了 30%，将元宇宙效用提高了 25%，并且比非区块链系统提高了 5% 的训练效率，有效地对抗了行为不端的用户。

##### **NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time**
2408.03675v2 by Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu

Large Language Models (LLMs) have ignited an innovative surge of AI
applications, marking a new era of exciting possibilities equipped with
extended context windows. However, hosting these models is cost-prohibitive
mainly due to the extensive memory consumption of KV Cache involving
long-context modeling. Despite several works proposing to evict unnecessary
tokens from the KV Cache, most of them rely on the biased local statistics of
accumulated attention scores and report performance using unconvincing metric
like perplexity on inadequate short-text evaluation. In this paper, we propose
NACL, a general framework for long-context KV cache eviction that achieves more
optimal and efficient eviction in a single operation during the encoding phase.
Due to NACL's efficiency, we combine more accurate attention score statistics
in PROXY TOKENS EVICTION with the diversified random eviction strategy of
RANDOM EVICTION, aiming to alleviate the issue of attention bias and enhance
the robustness in maintaining pivotal tokens for long-context modeling tasks.
Notably, our method significantly improves the performance on short- and
long-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%
with over 95% performance maintenance. The code is available at
https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.

摘要：大型語言模型 (LLM) 已經點燃了 AI 應用創新的浪潮，標誌著一個新的時代，這個時代充滿了令人興奮的可能性，並配備了擴展的上下文窗口。然而，託管這些模型的成本過高，這主要是因為 KV 快取涉及長上下文建模，會消耗大量記憶體。儘管有幾項工作建議從 KV 快取中驅逐不必要的權杖，但它們大多依賴於累積注意力分數的偏頗局部統計資料，並使用令人信服的指標（例如在不充分的短文本評估中使用困惑度）來報告效能。在本文中，我們提出 NACL，這是一個用於長上下文 KV 快取驅逐的通用框架，可以在編碼階段的單一操作中實現更佳且更有效的驅逐。由於 NACL 的效率，我們將更準確的注意力分數統計資料與 RANDOM EVICTION 的多樣化隨機驅逐策略結合在 PROXY TOKENS EVICTION 中，旨在減輕注意力偏差的問題，並增強在維護長上下文建模任務的關鍵權杖時的穩健性。值得注意的是，我們的模型分別將短文本和長文本任務的效能顯著提升了 80% 和 76%，將 KV 快取減少了 50%，同時效能維持在 95% 以上。程式碼可以在 https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL 中取得。

##### **mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search**
2408.03652v1 by Ahmed Abdou, Tasneem Mohsen

Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)
that aims to identify and classify entities in text into predefined categories.
However, when applied to Arabic data, NER encounters unique challenges stemming
from the language's rich morphological inflections, absence of capitalization
cues, and spelling variants, where a single word can comprise multiple
morphemes. In this paper, we introduce Arabic KNN-NER, our submission to the
Wojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the
shared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained
flat-entity recognition for Arabic text, where we identify a single main entity
and possibly zero or multiple sub-entities for each word. Arabic KNN-NER
augments the probability distribution of a fine-tuned model with another label
probability distribution derived from performing a KNN search over the cached
training data. Our submission achieved 91% on the test set on the WojoodFine
dataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.

摘要：命名實體辨識 (NER) 是自然語言處理 (NLP) 中的一項任務，旨在識別和將文字中的實體分類到預先定義的類別中。然而，當應用於阿拉伯語資料時，NER 會遇到獨特的挑戰，這些挑戰源於該語言豐富的形態變化、缺乏大寫線索以及拼寫變體，其中一個單字可能包含多個語素。在本文中，我們介紹了阿拉伯語 KNN-NER，這是我們提交給 Wojood NER 共享任務 2024（ArabicNLP 2024）的內容。我們參與了共享子任務 1 平面 NER。在這個共享子任務中，我們處理阿拉伯語文字的細粒度平面實體辨識，其中我們識別每個單字的單一主要實體以及可能為零或多個子實體。阿拉伯語 KNN-NER 使用從快取訓練資料中執行 KNN 搜尋衍生的另一個標籤機率分佈，來擴充微調模型的機率分佈。我們在 WojoodFine 資料集的測試集中獲得 91%，讓阿拉伯語 KNN-NER 名列共享任務排行榜首位。

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

摘要：自動憂鬱症偵測的利用顯著提升了憂鬱症患者的早期介入。儘管有許多使用錄製臨床訪談影片的自動憂鬱症偵測提案，但對於考量訪談問題的階層結構這方面卻鮮少關注。在用於診斷憂鬱症的臨床訪談中，臨床醫師會使用包含例行基準問題和追蹤問題的結構化問卷來評估受訪者的狀況。本文介紹了 HiQuE（階層式問題嵌入網路），這是一種新穎的憂鬱症偵測架構，它利用了臨床訪談中主要問題和追蹤問題之間的階層關係。HiQuE 能夠透過學習多種方式之間的互惠資訊，有效地擷取每個問題在憂鬱症診斷中的重要性。我們在廣泛使用的臨床訪談資料 DAIC-WOZ 上進行了廣泛的實驗，我們的模型優於其他最先進的多模態憂鬱症偵測模型和情緒辨識模型，展示了其在憂鬱症偵測中的臨床效用。

##### **CARE: A Clue-guided Assistant for CSRs to Read User Manuals**
2408.03633v2 by Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei

It is time-saving to build a reading assistant for customer service
representations (CSRs) when reading user manuals, especially information-rich
ones. Current solutions don't fit the online custom service scenarios well due
to the lack of attention to user questions and possible responses. Hence, we
propose to develop a time-saving and careful reading assistant for CSRs, named
CARE. It can help the CSRs quickly find proper responses from the user manuals
via explicit clue chains. Specifically, each of the clue chains is formed by
inferring over the user manuals, starting from the question clue aligned with
the user question and ending at a possible response. To overcome the shortage
of supervised data, we adopt the self-supervised strategy for model learning.
The offline experiment shows that CARE is efficient in automatically inferring
accurate responses from the user manual. The online experiment further
demonstrates the superiority of CARE to reduce CSRs' reading burden and keep
high service quality, in particular with >35% decrease in time spent and
keeping a >0.75 ICC score.

摘要：建構一個閱讀助理，協助客服代表 (CSR) 閱讀使用者手冊，特別是資訊豐富的手冊，可以節省時間。目前的解決方案由於缺乏對使用者問題和可能回應的關注，因此不太適合線上客服場景。因此，我們提議開發一個節省時間且仔細的閱讀助理，名為 CARE，它可以透過明確的線索鏈幫助客服代表快速從使用者手冊中找到適當的回應。具體來說，每個線索鏈都是透過推論使用者手冊形成的，從與使用者問題一致的問題線索開始，並在可能的回應中結束。為了克服監督式資料的不足，我們採用自監督策略進行模型學習。離線實驗表明，CARE 可以從使用者手冊中自動推論出準確的回應。線上實驗進一步證明了 CARE 在減輕客服代表的閱讀負擔和保持高服務品質方面的優越性，特別是將花費時間減少 >35%，並保持 >0.75 ICC 分數。

##### **Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis**
2408.03632v1 by Zebin Yao, Fangxiang Feng, Ruifan Li, Xiaojie Wang

The customization of text-to-image models has seen significant advancements,
yet generating multiple personalized concepts remains a challenging task.
Current methods struggle with attribute leakage and layout confusion when
handling multiple concepts, leading to reduced concept fidelity and semantic
consistency. In this work, we introduce a novel training-free framework,
Concept Conductor, designed to ensure visual fidelity and correct layout in
multi-concept customization. Concept Conductor isolates the sampling processes
of multiple custom models to prevent attribute leakage between different
concepts and corrects erroneous layouts through self-attention-based spatial
guidance. Additionally, we present a concept injection technique that employs
shape-aware masks to specify the generation area for each concept. This
technique injects the structure and appearance of personalized concepts through
feature fusion in the attention layers, ensuring harmony in the final image.
Extensive qualitative and quantitative experiments demonstrate that Concept
Conductor can consistently generate composite images with accurate layouts
while preserving the visual details of each concept. Compared to existing
baselines, Concept Conductor shows significant performance improvements. Our
method supports the combination of any number of concepts and maintains high
fidelity even when dealing with visually similar concepts. The code and models
are available at https://github.com/Nihukat/Concept-Conductor.

摘要：文字轉圖像模型的客製化已取得顯著進展，
但產生多個個人化概念仍然是一項具有挑戰性的任務。
現有方法在處理多個概念時會出現屬性外洩和版面混淆的問題，導致概念保真度降低和語義一致性。在這項工作中，我們引入了一個新穎的無訓練框架，概念指揮器，旨在確保多概念客製化中的視覺保真度和正確版面。概念指揮器隔離多個自訂模型的取樣過程，以防止不同概念之間的屬性外洩，並透過基於自我注意力的空間引導來修正錯誤的版面。此外，我們提出了一種概念注入技術，採用形狀感知遮罩來指定每個概念的生成區域。此技術透過注意層中的特徵融合來注入個人化概念的結構和外觀，確保最終影像的和諧。廣泛的定性和定量實驗證明，概念指揮器可以持續產生具有準確版面且保留每個概念視覺細節的複合影像。與現有的基線相比，概念指揮器顯示出顯著的效能提升。我們的模型支援任意數量的概念組合，即使在處理視覺上相似的概念時也能維持高保真度。程式碼和模型可在 https://github.com/Nihukat/Concept-Conductor 取得。

##### **Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**
2408.03631v1 by Yanhu Wang, Muhammad Muzammil Afzal, Zhengyang Li, Jie Zhou, Chenyuan Feng, Shuaishuai Guo, Tony Q. S. Quek

Traditional base station siting (BSS) methods rely heavily on drive testing
and user feedback, which are laborious and require extensive expertise in
communication, networking, and optimization. As large language models (LLMs)
and their associated technologies advance, particularly in the realms of prompt
engineering and agent engineering, network optimization will witness a
revolutionary approach. This approach entails the strategic use of well-crafted
prompts to infuse human experience and knowledge into these sophisticated LLMs,
and the deployment of autonomous agents as a communication bridge to seamlessly
connect the machine language based LLMs with human users using natural
language. This integration represents the future paradigm of artificial
intelligence (AI) as a service and AI for more ease. As a preliminary
exploration, this research first develops a novel LLM-empowered BSS
optimization framework, and heuristically proposes four different potential
implementations: the strategies based on Prompt-optimized LLM (PoL),
human-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and
Cooperative multiple LLM-based autonomous BSS agents (CLaBa). Through
evaluation on real-world data, the experiments demonstrate that prompt-assisted
LLMs and LLM-based agents can generate more efficient, cost-effective, and
reliable network deployments, noticeably enhancing the efficiency of BSS
optimization and reducing trivial manual participation.

摘要：傳統基地台選址（BSS）方法過度依賴路測和使用者回饋，這很費力，且需要在通訊、網路和最佳化方面具備豐富的專業知識。隨著大型語言模型（LLM）及其相關技術的進展，特別是在提示工程和代理工程領域，網路最佳化將見證一場革命性的方法。此方法需要策略性地使用精心製作的提示，將人類經驗和知識注入這些複雜的 LLM，並部署自主代理作為通訊橋梁，使用自然語言將基於機器語言的 LLM 與人類使用者無縫連接。這種整合代表了人工智慧（AI）作為服務和 AI 的未來典範，讓 AI 更輕鬆。作為初步探索，本研究首先開發了一個新穎的 LLM 強化 BSS 最佳化架構，並啟發式地提出了四種不同的潛在實作：基於提示最佳化 LLM（PoL）的策略、人機協作 LLM（HiLL）、LLM 強化自主 BSS 代理（LaBa）和協作式多個 LLM 基礎自主 BSS 代理（CLaBa）。透過對真實世界資料的評估，實驗證明提示輔助 LLM 和基於 LLM 的代理可以產生更高效率、更具成本效益且更可靠的網路部署，顯著提升 BSS 最佳化的效率，並減少瑣碎的人工參與。

##### **PAGED: A Benchmark for Procedural Graphs Extraction from Documents**
2408.03630v2 by Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei

Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.

摘要：自動從文件中萃取程序圖表是一種低成本的方式，讓使用者能透過瀏覽視覺化圖表，輕鬆理解複雜的程序。儘管近期研究已有所進展，但仍有待解答的問題：現有的研究是否已妥善解決此任務（Q1），以及新興的大語言模型（LLM）是否能為此任務帶來新的契機（Q2）。為此，我們提出一個新的基準 PAGED，配備大型高品質資料集和標準評量。它探討了五個最先進的基線，揭示了它們無法良好地萃取最佳程序圖表，原因在於它們過度依賴手寫規則和有限的可用資料。我們進一步在 PAGED 中納入三個先進的 LLM，並透過新穎的自精進策略加以強化。結果指出 LLM 在識別文本元素方面的優勢，以及它們在建立邏輯結構方面的差距。我們希望 PAGED 能成為自動程序圖表萃取的主要里程碑，而 PAGED 中的探討能為非順序元素間的邏輯推理研究提供見解。

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

摘要：背景：電子病歷 (EHR) 中拼寫的準確性是有效臨床照護、研究和確保患者安全性的關鍵因素。波斯語擁有豐富的詞彙和複雜的特徵，對真實世界的錯誤更正提出了獨特的挑戰。本研究旨在開發一種創新的方法來偵測和更正波斯語臨床文本中的拼寫錯誤。
方法：我們的策略採用了最先進的預訓練模型，該模型經過精心微調，專門用於波斯語臨床領域中的拼寫更正任務。此模型由創新的正字法相似性匹配演算法 PERTO 補充，該演算法使用字元的視覺相似性來對更正候選項進行排名。
結果：對我們方法的評估證明了其在偵測和糾正波斯語臨床文本中的文字錯誤方面的穩健性和準確性。在非文字錯誤更正方面，當使用 PERTO 演算法時，我們的模型實現了 90.0% 的 F1 分數。對於真實世界的錯誤偵測，我們的模型展示了其最高的效能，實現了 90.6% 的 F1 分數。此外，當使用 PERTO 演算法時，該模型達到了其最高的 F1 分數 91.5%，用於真實世界的錯誤更正。
結論：儘管存在某些限制，但我們的模型代表了波斯語臨床文本拼寫錯誤偵測和更正領域的重大進展。透過有效解決波斯語所帶來的獨特挑戰，我們的做法為更準確和有效的臨床文件鋪路，有助於改善患者照護和安全性。未來的研究可以探討其在波斯語醫學領域其他領域的應用，以增強其影響力和實用性。

##### **A Logical Fallacy-Informed Framework for Argument Generation**
2408.03618v1 by Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

Despite the remarkable performance of Large Language Models (LLMs), they
still struggle with generating logically sound arguments, resulting in
potential risks such as spreading misinformation. An important factor
contributing to LLMs' suboptimal performance in generating coherent arguments
is their oversight of logical fallacies. To address this issue, we introduce
FIPO, a fallacy-informed framework that leverages preference optimization
methods to steer LLMs toward logically sound arguments. FIPO includes a
classification loss, to capture the fine-grained information on fallacy
categories. Our results on argumentation datasets show that our method reduces
the fallacy errors by up to 17.5%. Furthermore, our human evaluation results
indicate that the quality of the generated arguments by our method
significantly outperforms the fine-tuned baselines, as well as prior preference
optimization methods, such as DPO. These findings highlight the importance of
ensuring models are aware of logical fallacies for effective argument
generation.

摘要：儘管大型語言模型 (LLM) 擁有傑出的表現，它們在產生合乎邏輯的論述上仍有困難，導致潛在風險，例如散布錯誤訊息。造成 LLM 在產生連貫論述時表現不佳的一個重要因素，是它們忽略了邏輯謬誤。為了解決這個問題，我們引入了 FIPO，一個以謬誤為基礎的架構，它利用偏好最佳化方法將 LLM 引導至合乎邏輯的論述。FIPO 包含一個分類損失，以擷取關於謬誤類別的細微資訊。我們在論證資料集上的結果顯示，我們的模型將謬誤錯誤減少了 17.5%。此外，我們的人工評估結果指出，我們的模型產生的論述品質顯著優於微調基線，以及先前的偏好最佳化方法，例如 DPO。這些發現強調了確保模型了解邏輯謬誤對於有效產生論述的重要性。

##### **Is Child-Directed Speech Effective Training Data for Language Models?**
2408.03617v1 by Steven Y. Feng, Noah D. Goodman, Michael C. Frank

While high-performing language models are typically trained on hundreds of
billions of words, human children become fluent language users with a much
smaller amount of data. What are the features of the data they receive, and how
do these features support language modeling objectives? To investigate this
question, we train GPT-2 models on 29M words of English-language child-directed
speech and a new matched, synthetic dataset (TinyDialogues), comparing to a
heterogeneous blend of datasets from the BabyLM challenge. We evaluate both the
syntactic and semantic knowledge of these models using developmentally-inspired
evaluations. Through pretraining experiments, we test whether the global
developmental ordering or the local discourse ordering of children's training
data support high performance relative to other datasets. The local properties
of the data affect model results, but somewhat surprisingly, global properties
do not. Further, child language input is not uniquely valuable for training
language models. These findings support the hypothesis that, rather than
proceeding from better data, children's learning is instead substantially more
efficient than current language modeling techniques.

摘要：儘管高性能語言模型通常會在數百億個單字上進行訓練，但人類孩童只需使用更少量的資料，就能成為流利的語言使用者。他們接收的資料有哪些特徵，這些特徵如何支援語言建模目標？為了探討這個問題，我們在 2900 萬個單字的英語兒童導向語言和一個新的匹配式合成資料集 (TinyDialogues) 上訓練 GPT-2 模型，並與 BabyLM 挑戰中各種異質資料集進行比較。我們使用發展靈感評估來評估這些模型的句法和語義知識。透過預訓練實驗，我們測試兒童訓練資料的整體發展順序或局部語篇順序是否相對於其他資料集支援高性能。資料的局部屬性會影響模型結果，但令人驚訝的是，整體屬性並不會。此外，兒童語言輸入並非訓練語言模型的唯一有價值資料。這些發現支持以下假設：兒童的學習並非來自更好的資料，而是比目前的語言建模技術有效率許多。

##### **Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**
2408.03615v1 by Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie

Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.

摘要：打造一個通用代理是人工智慧領域長久以來的願景。現有的代理在許多領域都有顯著的進步，但它們仍難以在開放世界中完成長時程任務。我們將此歸因於缺乏必要的知識和多模態經驗，這些知識和經驗可以引導代理完成各種長時程任務。在本文中，我們提出一個混合多模態記憶體模組來解決上述挑戰。它 1) 將知識轉換為階層式導向知識圖，讓代理能夠明確地表示和學習世界知識，以及 2) 將歷史資訊摘要成抽象的多模態經驗池，為代理提供豐富的參考，以便進行情境學習。在混合多模態記憶體模組之上，建構了一個多模態代理，Optimus-1，它具備專用的知識導向規劃器和經驗驅動的反射器，有助於在 Minecraft 中面對長時程任務時進行更好的規劃和反思。廣泛的實驗結果顯示，Optimus-1 在具有挑戰性的長時程任務基準上顯著優於所有現有代理，並且在許多任務上展現出接近人類的效能。此外，我們引入各種多模態大型語言模型 (MLLM) 作為 Optimus-1 的骨幹。實驗結果顯示，Optimus-1 在混合多模態記憶體模組的幫助下展現出強大的泛化能力，在許多任務上優於 GPT-4V 基準。

##### **EnJa: Ensemble Jailbreak on Large Language Models**
2408.03603v1 by Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang

As Large Language Models (LLMs) are increasingly being deployed in
safety-critical applications, their vulnerability to potential jailbreaks --
malicious prompts that can disable the safety mechanism of LLMs -- has
attracted growing research attention. While alignment methods have been
proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can
still be jailbroken by carefully crafted malicious prompts, producing content
that violates policy regulations. Existing jailbreak attacks on LLMs can be
categorized into prompt-level methods which make up stories/logic to circumvent
safety alignment and token-level attack methods which leverage gradient methods
to find adversarial tokens. In this work, we introduce the concept of Ensemble
Jailbreak and explore methods that can integrate prompt-level and token-level
jailbreak into a more powerful hybrid jailbreak attack. Specifically, we
propose a novel EnJa attack to hide harmful instructions using prompt-level
jailbreak, boost the attack success rate using a gradient-based attack, and
connect the two types of jailbreak attacks via a template-based connector. We
evaluate the effectiveness of EnJa on several aligned models and show that it
achieves a state-of-the-art attack success rate with fewer queries and is much
stronger than any individual jailbreak.

摘要：隨著大型語言模型（LLM）日益廣泛地部署在安全關鍵型應用程式中，它們容易受到潛在越獄的攻擊，惡意提示可以停用 LLM 的安全機制，這引起了越來越多的研究關注。儘管已提出比對方法來保護 LLM 不受越獄攻擊，但許多人發現，精心設計的惡意提示仍然可以越獄比對後的 LLM，產生違反政策法規的內容。現有的針對 LLM 的越獄攻擊可分為提示層級方法，該方法編造故事/邏輯來規避安全比對，以及利用梯度方法來尋找對抗性權杖的權杖層級攻擊方法。在這項工作中，我們引入了整體越獄的概念，並探討了可以將提示層級和權杖層級越獄整合到更強大的混合越獄攻擊中的方法。具體來說，我們提出了一種新穎的 EnJa 攻擊，使用提示層級越獄來隱藏有害指令，使用基於梯度的攻擊來提高攻擊成功率，並通過基於範本的連接器連接兩種類型的越獄攻擊。我們評估了 EnJa 在多個比對模型上的有效性，並表明它以較少的查詢達到了最先進的攻擊成功率，並且比任何單獨的越獄攻擊都強得多。

##### **Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation**
2408.03588v1 by Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife

Cinematic audio source separation (CASS) is a fairly new subtask of audio
source separation. A typical setup of CASS is a three-stem problem, with the
aim of separating the mixture into the dialogue stem (DX), music stem (MX), and
effects stem (FX). In practice, however, several edge cases exist as some sound
sources do not fit neatly in either of these three stems, necessitating the use
of additional auxiliary stems in production. One very common edge case is the
singing voice in film audio, which may belong in either the DX or MX, depending
heavily on the cinematic context. In this work, we demonstrate a very
straightforward extension of the dedicated-decoder Bandit and query-based
single-decoder Banquet models to a four-stem problem, treating non-musical
dialogue, instrumental music, singing voice, and effects as separate stems.
Interestingly, the query-based Banquet model outperformed the dedicated-decoder
Bandit model. We hypothesized that this is due to a better feature alignment at
the bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model
implementation will be made available at
https://github.com/kwatcharasupat/source-separation-landing.

摘要：電影音訊來源分離 (CASS) 是音訊來源分離中相當新的子任務。CASS 的典型設定是三幹問題，目標是將混合物分離為對話幹 (DX)、音樂幹 (MX) 和效果幹 (FX)。然而，在實際應用中，存在許多邊緣情況，因為有些音訊來源無法完全符合這三個幹中的任何一個，因此在製作過程中需要使用額外的輔助幹。一個非常常見的邊緣情況是電影音訊中的歌唱聲，它可能屬於 DX 或 MX，很大程度上取決於電影背景。在這項工作中，我們展示了一個非常直接的延伸，將專用解碼器 Bandit 和基於查詢的單一解碼器 Banquet 模型擴展到四幹問題，將非音樂對話、器樂、歌唱和效果視為獨立的幹。有趣的是，基於查詢的 Banquet 模型優於專用解碼器 Bandit 模型。我們假設這是因為頻帶不可知的 FiLM 層強制執行的瓶頸處有更好的特徵對齊。資料集和模型實作將在 https://github.com/kwatcharasupat/source-separation-landing 提供。

##### **Hierarchical Neural Constructive Solver for Real-world TSP Scenarios**
2408.03585v1 by Yong Liang Goh, Zhiguang Cao, Yining Ma, Yanfei Dong, Mohammed Haroon Dupty, Wee Sun Lee

Existing neural constructive solvers for routing problems have predominantly
employed transformer architectures, conceptualizing the route construction as a
set-to-sequence learning task. However, their efficacy has primarily been
demonstrated on entirely random problem instances that inadequately capture
real-world scenarios. In this paper, we introduce realistic Traveling Salesman
Problem (TSP) scenarios relevant to industrial settings and derive the
following insights: (1) The optimal next node (or city) to visit often lies
within proximity to the current node, suggesting the potential benefits of
biasing choices based on current locations. (2) Effectively solving the TSP
requires robust tracking of unvisited nodes and warrants succinct grouping
strategies. Building upon these insights, we propose integrating a learnable
choice layer inspired by Hypernetworks to prioritize choices based on the
current location, and a learnable approximate clustering algorithm inspired by
the Expectation-Maximization algorithm to facilitate grouping the unvisited
cities. Together, these two contributions form a hierarchical approach towards
solving the realistic TSP by considering both immediate local neighbourhoods
and learning an intermediate set of node representations. Our hierarchical
approach yields superior performance compared to both classical and recent
transformer models, showcasing the efficacy of the key designs.

摘要：現有的神經建構求解器主要使用Transformer架構，將路線建構概念化為集合到序列的學習任務。然而，它們的效能主要展現在完全隨機的問題實例上，無法充分捕捉現實世界的場景。在本文中，我們引入了與工業環境相關的現實旅行商問題 (TSP) 場景，並得出以下見解：(1) 下一個要拜訪的最佳節點（或城市）通常位於當前節點的附近，這表明根據當前位置調整選擇的潛在好處。(2) 有效地解決 TSP 需要穩健地追蹤未拜訪的節點，並保證簡潔的分組策略。根據這些見解，我們建議整合受 Hypernetworks 啟發的可學習選擇層，以根據當前位置優先選擇，以及受期望最大化演算法啟發的可學習近似分群演算法，以利於對未拜訪的城市進行分組。這兩個貢獻共同形成了一個階層式方法，透過考慮鄰近的局部鄰域和學習一組中間節點表示，來解決現實的 TSP。與傳統和最近的Transformer模型相比，我們的階層式方法產生了更好的效能，展示了關鍵設計的效能。

##### **Teach CLIP to Develop a Number Sense for Ordinal Regression**
2408.03574v1 by Yao Du, Qiang Zhai, Weihang Dai, Xiaomeng Li

Ordinal regression is a fundamental problem within the field of computer
vision, with customised well-trained models on specific tasks. While
pre-trained vision-language models (VLMs) have exhibited impressive performance
on various vision tasks, their potential for ordinal regression has received
less exploration. In this study, we first investigate CLIP's potential for
ordinal regression, from which we expect the model could generalise to
different ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP
fails on this task, since current VLMs have a well-documented limitation of
encapsulating compositional concepts such as number sense. We propose a simple
yet effective method called NumCLIP to improve the quantitative understanding
of VLMs. We disassemble the exact image to number-specific text matching
problem into coarse classification and fine prediction stages. We discretize
and phrase each numerical bin with common language concept to better leverage
the available pre-trained alignment in CLIP. To consider the inherent
continuous property of ordinal regression, we propose a novel fine-grained
cross-modal ranking-based regularisation loss specifically designed to keep
both semantic and ordinal alignment in CLIP's feature space. Experimental
results on three general ordinal regression tasks demonstrate the effectiveness
of NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating
and image aesthetics assessment task, respectively. Code is publicly available
at https://github.com/xmed-lab/NumCLIP.

摘要：序數迴歸是電腦視覺領域中的基本問題，其中包含特定任務上的客製化訓練模型。雖然預先訓練的視覺語言模型 (VLM) 已在各種視覺任務中展現出令人印象深刻的效能，但對於序數迴歸的潛力則較少探索。在本研究中，我們首先探討 CLIP 對序數迴歸的潛力，我們預期模型可以概括到不同的序數迴歸任務和場景。不幸的是，香草 CLIP 在此任務上失敗，因為目前的 VLM 已有文件記載的限制，無法封裝諸如數字感等組合概念。我們提出一個簡單但有效的方法，稱為 NumCLIP，以改善 VLM 的量化理解。我們將精確影像分解為數字特定文字比對問題，再細分為粗略分類和精細預測階段。我們將每個數字箱離散化並以常見語言概念表達，以更好地利用 CLIP 中可用的預先訓練對齊。為了考量序數迴歸的內在連續特性，我們提出一個新穎的細粒度跨模態排序基礎正則化損失，特別設計用於在 CLIP 的特徵空間中保持語意和序數對齊。在三個一般序數迴歸任務上的實驗結果證明了 NumCLIP 的有效性，在歷史影像約會和影像美學評估任務上分別提高了 10% 和 3.83% 的準確度。程式碼已公開於 https://github.com/xmed-lab/NumCLIP。

##### **Active Testing of Large Language Model via Multi-Stage Sampling**
2408.03573v1 by Yuheng Huang, Jiayang Song, Qiang Hu, Felix Juefei-Xu, Lei Ma

Performance evaluation plays a crucial role in the development life cycle of
large language models (LLMs). It estimates the model's capability, elucidates
behavior characteristics, and facilitates the identification of potential
issues and limitations, thereby guiding further improvement. Given that LLMs'
diverse task-handling abilities stem from large volumes of training data, a
comprehensive evaluation also necessitates abundant, well-annotated, and
representative test data to assess LLM performance across various downstream
tasks. However, the demand for high-quality test data often entails substantial
time, computational resources, and manual efforts, sometimes causing the
evaluation to be inefficient or impractical. To address these challenges,
researchers propose active testing, which estimates the overall performance by
selecting a subset of test data. Nevertheless, the existing active testing
methods tend to be inefficient, even inapplicable, given the unique new
challenges of LLMs (e.g., diverse task types, increased model complexity, and
unavailability of training data). To mitigate such limitations and expedite the
development cycle of LLMs, in this work, we introduce AcTracer, an active
testing framework tailored for LLMs that strategically selects a small subset
of test data to achieve a nearly optimal performance estimation for LLMs.
AcTracer utilizes both internal and external information from LLMs to guide the
test sampling process, reducing variance through a multi-stage pool-based
active selection. Our experiment results demonstrate that AcTracer achieves
state-of-the-art performance compared to existing methods across various tasks,
with up to 38.83% improvement over previous SOTA.

摘要：效能評估在大型語言模型 (LLM) 的開發生命週期中扮演著至關重要的角色。它評估模型的能力、闡明行為特徵，並協助找出潛在的問題和限制，進而引導後續的改善。由於 LLM 處理各種任務的能力源自於大量的訓練資料，因此全面的評估也需要豐富、標註完善且具代表性的測試資料，才能評估 LLM 在各種下游任務中的效能。然而，高品質測試資料的需求通常需要大量的時間、運算資源和人工，有時會導致評估效率低落或不切實際。為了應對這些挑戰，研究人員提出主動測試，透過選取測試資料的子集來評估整體效能。儘管如此，現有的主動測試方法往往效率不彰，甚至無法適用，因為 LLM 具有獨特的新挑戰（例如，多樣化的任務類型、增加的模型複雜度和訓練資料的不可用性）。為了減輕這些限制並加速 LLM 的開發週期，我們在這項工作中引入了 AcTracer，一個專為 LLM 量身打造的主動測試框架，它策略性地選取測試資料的小子集，以達成 LLM 近乎最佳的效能評估。AcTracer 利用來自 LLM 的內部和外部資訊來引導測試抽樣程序，透過多階段基於池的主動選擇來降低變異。我們的實驗結果證明，AcTracer 在各種任務中都達到與現有方法相比的最新效能，相較於先前的 SOTA，進步幅度高達 38.83%。

##### **2D-OOB: Attributing Data Contribution through Joint Valuation Framework**
2408.03572v1 by Yifan Sun, Jingyan Shen, Yongchan Kwon

Data valuation has emerged as a powerful framework to quantify the
contribution of each datum to the training of a particular machine learning
model. However, it is crucial to recognize that the quality of various cells
within a single data point can vary greatly in practice. For example, even in
the case of an abnormal data point, not all cells are necessarily noisy. The
single scalar valuation assigned by existing methods blurs the distinction
between noisy and clean cells of a data point, thereby compromising the
interpretability of the valuation. In this paper, we propose 2D-OOB, an
out-of-bag estimation framework for jointly determining helpful (or
detrimental) samples, as well as the particular cells that drive them. Our
comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art
performance across multiple use cases, while being exponentially faster. 2D-OOB
excels in detecting and rectifying fine-grained outliers at the cell level, as
well as localizing backdoor triggers in data poisoning attacks.

摘要：資料評估已成為量化每個資料對特定機器學習模型訓練貢獻的強大框架。然而，至關重要的是要認識到單一資料點中各個單元的品質在實務上可能差異很大。舉例來說，即使在異常資料點的情況下，也並非所有單元都必然有雜訊。現有方法所分配的單一標量評估模糊了資料點中雜訊單元與乾淨單元之間的區別，因而損害了評估的可解釋性。在本文中，我們提出 2D-OOB，一個袋外估計框架，用於共同確定有幫助（或有害）的樣本，以及驅動它們的特定單元。我們的全面實驗證明，2D-OOB 在多個使用案例中都達到了最先進的效能，同時速度呈指數級提升。2D-OOB 在偵測和修正單元層級的細粒度異常值方面表現出色，同時也能在資料中毒攻擊中定位後門觸發器。

##### **Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning**
2408.03567v1 by Zi-Yi Dou, Xitong Yang, Tushar Nagarajan, Huiyu Wang, Jing Huang, Nanyun Peng, Kris Kitani, Fu-Jen Chu

We present EMBED (Egocentric Models Built with Exocentric Data), a method
designed to transform exocentric video-language data for egocentric video
representation learning. Large-scale exocentric data covers diverse activities
with significant potential for egocentric learning, but inherent disparities
between egocentric and exocentric data pose challenges in utilizing one view
for the other seamlessly. Egocentric videos predominantly feature close-up
hand-object interactions, whereas exocentric videos offer a broader perspective
on human activities. Additionally, narratives in egocentric datasets are
typically more action-centric and closely linked with the visual content, in
contrast to the narrative styles found in exocentric datasets. To address these
challenges, we employ a data transformation framework to adapt exocentric data
for egocentric training, focusing on identifying specific video clips that
emphasize hand-object interactions and transforming narration styles to align
with egocentric perspectives. By applying both vision and language style
transfer, our framework creates a new egocentric dataset derived from
exocentric video-language data. Through extensive evaluations, we demonstrate
the effectiveness of EMBED, achieving state-of-the-art results across various
egocentric downstream tasks, including an absolute improvement of 4.7% on the
Epic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification
benchmarks in zero-shot settings. Furthermore, EMBED enables egocentric
video-language models to perform competitively in exocentric tasks. Finally, we
showcase EMBED's application across various exocentric datasets, exhibiting
strong generalization capabilities when applied to different exocentric
datasets.

摘要：<paragraph>我們提出 EMBED（以異心資料建構的自心模型），一種方法
旨在將異心影片語言資料轉換為自心影片
表徵學習。大規模異心資料涵蓋各種活動
具有自心學習的潛力，但異心與自心資料之間的固有差異
在無縫使用一個視角時造成挑戰。自心影片主要特寫
手部物體互動，而異心影片則提供更廣泛的人類活動觀點。此外，自心資料集中的敘述
通常更以動作為中心，並且與視覺內容緊密連結，這與異心資料集中發現的敘事風格形成對比。為了應對這些
挑戰，我們採用資料轉換框架來調整異心資料
用於自心訓練，專注於識別強調手部物體互動並轉換敘事風格以與自心觀點一致的特定影片片段。透過應用視覺和語言風格
轉移，我們的框架建立一個新的自心資料集，源自
異心影片語言資料。透過廣泛的評估，我們證明 EMBED 的有效性，在各種
自心下游任務中達成最先進的結果，包括在 Epic-Kitchens-100 多實例檢索中絕對改善 4.7%，以及在 EGTEA 分類中改善 6.2%
零次設定中的基準。此外，EMBED 使自心
影片語言模型能夠在異心任務中具有競爭力。最後，我們
展示 EMBED 在各種異心資料集中的應用，在應用於不同異心時展現強大的概化能力
資料集。</paragraph>

##### **A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case**
2408.03562v1 by Sonia Meyer, Shreya Singh, Bertha Tam, Christopher Ton, Angel Ren

This research compares large language model (LLM) fine-tuning methods,
including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning
(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally
compared LLM evaluation methods including End to End (E2E) benchmark method of
"Golden Answers", traditional natural language processing (NLP) metrics, RAG
Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,
using the travel chatbot use case. The travel dataset was sourced from the the
Reddit API by requesting posts from travel-related subreddits to get
travel-related conversation prompts and personalized travel experiences, and
augmented for each fine-tuning method. We used two pretrained LLMs utilized for
fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to
the two pretrained models. The inferences from these models are extensively
evaluated against the aforementioned metrics. The best model according to human
evaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a
Reinforcement Learning from Human Feedback (RLHF) training pipeline, and
ultimately was evaluated as the best model. Our main findings are that: 1)
quantitative and Ragas metrics do not align with human evaluation, 2) Open AI
GPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep
humans in the loop for evaluation because, 4) traditional NLP metrics
insufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms
QLoRA, but still needs postprocessing, 7) RLHF improves model performance
significantly. Next steps include improving data quality, increasing data
quantity, exploring RAG methods, and focusing data collection on a specific
city, which would improve data quality by narrowing the focus, while creating a
useful product.

摘要：本研究比較了大型語言模型 (LLM) 微調方法，包括量化低秩適配器 (QLoRA)、檢索擴增微調 (RAFT) 和人類回饋強化學習 (RLHF)，並額外比較了 LLM 評估方法，包括「黃金答案」的端對端 (E2E) 基準方法、傳統自然語言處理 (NLP) 指標、RAG 評估 (Ragas)、OpenAI GPT-4 評估指標和人類評估，並使用旅遊聊天機器人用例。旅遊資料集來自 Reddit API，透過要求旅遊相關子版塊的貼文來取得旅遊相關對話提示和個人化旅遊體驗，並針對每種微調方法進行擴充。我們使用了兩個預訓練 LLM，用於微調研究：LLaMa 2 7B 和 Mistral 7B。QLoRA 和 RAFT 應用於這兩個預訓練模型。廣泛評估這些模型的推論結果，並使用上述指標。根據人類評估和一些 GPT-4 指標，最好的模型是 Mistral RAFT，因此它接受了人類回饋強化學習 (RLHF) 訓練流程，並最終被評為最佳模型。我們的發現主要有：1) 定量和 Ragas 指標與人類評估不一致，2) Open AI GPT-4 評估最符合人類評估，3) 必須讓人類參與評估，因為 4) 傳統 NLP 指標不足，5) Mistral 通常優於 LLaMa，6) RAFT 優於 QLoRA，但仍需要後處理，7) RLHF 大幅提升了模型效能。後續步驟包括提升資料品質、增加資料數量、探索 RAG 方法，以及專注於特定城市的資料收集，這將透過縮小焦點來提升資料品質，同時創造有用的產品。

##### **MPC-Minimized Secure LLM Inference**
2408.03561v1 by Deevashwer Rathee, Dacheng Li, Ion Stoica, Hao Zhang, Raluca Popa

Many inference services based on large language models (LLMs) pose a privacy
concern, either revealing user prompts to the service or the proprietary
weights to the user. Secure inference offers a solution to this problem through
secure multi-party computation (MPC), however, it is still impractical for
modern LLM workload due to the large overhead imposed by MPC. To address this
overhead, we propose Marill, a framework that adapts LLM fine-tuning to
minimize MPC usage during secure inference. Marill introduces high-level
architectural changes during fine-tuning that significantly reduce the number
of expensive operations needed within MPC during inference, by removing some
and relocating others outside MPC without compromising security. As a result,
Marill-generated models are more efficient across all secure inference
protocols and our approach complements MPC-friendly approximations for such
operations. Compared to standard fine-tuning, Marill results in 3.6-11.3x
better runtime and 2.4-6.9x better communication during secure inference across
various MPC settings, while typically preserving over 90% performance across
downstream tasks.

摘要：許多基於大型語言模型 (LLM) 的推論服務會造成隱私問題，因為它們會向服務揭露使用者的提示，或向使用者揭露專有權重。安全推論透過安全多方運算 (MPC) 提供了解決此問題的方法，然而，由於 MPC 帶來的龐大開銷，對於現代 LLM 工作負載而言，它仍然不切實際。為了解決這個開銷問題，我們提出了 Marill，一個框架，它採用 LLM 微調來將安全推論期間的 MPC 使用量降至最低。Marill 在微調期間引入了高階架構變更，藉由移除一些昂貴運算，並將其他運算移至 MPC 外部，大幅減少在推論期間 MPC 內部所需的昂貴運算數量，同時不損害安全性。因此，Marill 生成的模型在所有安全推論協定中都更有效率，而且我們的方法補充了這些運算的 MPC 友善近似值。與標準微調相比，Marill 在各種 MPC 設定下的安全推論中，執行時間改善了 3.6-11.3 倍，通訊改善了 2.4-6.9 倍，同時在下游任務中通常保留了超過 90% 的效能。

##### **Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection**
2408.03554v1 by Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, Jun Suzuki, Keisuke Sakaguchi

We explore visual prompt injection (VPI) that maliciously exploits the
ability of large vision-language models (LVLMs) to follow instructions drawn
onto the input image. We propose a new VPI method, "goal hijacking via visual
prompt injection" (GHVPI), that swaps the execution task of LVLMs from an
original task to an alternative task designated by an attacker. The
quantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and
demonstrates a notable attack success rate of 15.8%, which is an unignorable
security risk. Our analysis also shows that successful GHVPI requires high
character recognition capability and instruction-following ability in LVLMs.

摘要：我們探討惡意利用大型視覺語言模型 (LVLMs) 遵循繪製在輸入影像上的指令的能力的視覺提示注入 (VPI)。我們提出一個新的 VPI 方法，即「透過視覺提示注入進行目標劫持」(GHVPI)，它將 LVLMs 的執行任務從原始任務替換為攻擊者指定的替代任務。定量分析表明 GPT-4V 容易受到 GHVPI 攻擊，並展示出顯著的 15.8% 攻擊成功率，這是一個不容忽視的安全風險。我們的分析還表明，成功的 GHVPI 需要 LVLMs 具備高字符辨識能力和遵循指令的能力。

##### **Unlocking the Non-Native Language Context Limitation: Native Language Prompting Facilitates Knowledge Elicitation**
2408.03544v1 by Baixuan Li, Yunlong Fan, Zhiqiang Gao

Multilingual large language models (MLLMs) struggle to answer questions posed
in non-dominant languages, even though they have already acquired the relevant
knowledge from their dominant language corpus. In contrast, human multilinguals
can overcome this issue by invoking the relatively rich knowledge acquired from
native language texts through Positive Native Language Transfer (PNLT).
Inspired by this, we analogize the dominant language of MLLMs to the native
language of human multilinguals, and propose Native Language Prompting (NatLan)
to simulate the PNLT observed in human multilinguals. It explicitly creates
native language contexts for MLLMs to facilitate the elicitation of the rich
native language knowledge during question-answering, unlocking the limitations
imposed by non-native language contexts on the effective application of
knowledge. By employing multi-MLLM collaboration, NatLan reduces the workload
on each MLLM in simulating PNLT and refines semantic transfer. On the C-Eval
benchmark, NatLan provides up to a 10.1% average accuracy improvement and up to
a 5.0% increase in the hard-level subset across five MLLMs, surpassing all
top-notch related methods. Our code is available at
https://github.com/AnonyNLP/NatLan.

摘要：多語言大型語言模型 (MLLM) 難以回答以非主要語言提出的問題，即使它們已經從其主要語言語料庫中獲得相關知識。相比之下，人類多語言使用者可以透過調用從母語文本中獲得的相對豐富知識來克服這個問題，透過正向母語轉移 (PNLT) 實現。受到此啟發，我們將 MLLM 的主要語言類比為人類多語言使用者的母語，並提出母語提示 (NatLan) 來模擬人類多語言使用者中觀察到的 PNLT。它明確為 MLLM 建立母語脈絡，以利於在問答過程中引出豐富的母語知識，打破非母語脈絡對知識有效應用造成的限制。透過採用多 MLLM 協作，NatLan 減少了每個 MLLM 在模擬 PNLT 時的工作量，並改善了語義轉移。在 C-Eval 基準測試中，NatLan 在五個 MLLM 中提供了高達 10.1% 的平均準確度提升，以及難度子集高達 5.0% 的提升，超越所有頂尖相關方法。我們的程式碼可於 https://github.com/AnonyNLP/NatLan 取得。

##### **EXAONE 3.0 7.8B Instruction Tuned Language Model**
2408.03541v2 by LG AI Research, :, Soyoung An, Kyunghoon Bae, Eunbi Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Yeonjung Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Euisoon Kim, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Moontae Lee, Seungjun Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Boseong Seo, Sihoon Yang, Heuiyeen Yeen, Kyungjae Yoo, Hyeongu Yun

We introduce EXAONE 3.0 instruction-tuned language model, the first open
model in the family of Large Language Models (LLMs) developed by LG AI
Research. Among different model sizes, we publicly release the 7.8B
instruction-tuned model to promote open research and innovations. Through
extensive evaluations across a wide range of public and in-house benchmarks,
EXAONE 3.0 demonstrates highly competitive real-world performance with
instruction-following capability against other state-of-the-art open models of
similar size. Our comparative analysis shows that EXAONE 3.0 excels
particularly in Korean, while achieving compelling performance across general
tasks and complex reasoning. With its strong real-world effectiveness and
bilingual proficiency, we hope that EXAONE keeps contributing to advancements
in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at
https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct

摘要：我們推出 EXAONE 3.0 指令調整語言模型，是 LG AI 研究開發的大型語言模型 (LLM) 家族中的第一個開放模型。在不同的模型規模中，我們公開發布 7.8B 指令調整模型，以促進開放研究和創新。透過對廣泛的公開和內部基準進行廣泛的評估，EXAONE 3.0 展現了高度競爭的真實世界效能，並具備與其他類似規模的最新開放模型相抗衡的指令遵循能力。我們的比較分析顯示，EXAONE 3.0 特別擅長韓語，同時在一般任務和複雜推理中都能達到令人信服的效能。憑藉其強大的真實世界效能和雙語能力，我們希望 EXAONE 能持續為專家 AI 的進步做出貢獻。我們的 EXAONE 3.0 指令調整模型可在 https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct 取得

##### **Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation**
2408.03533v1 by Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

We primarily focus on the field of large language models (LLMs) for
recommendation, which has been actively explored recently and poses a
significant challenge in effectively enhancing recommender systems with logical
reasoning abilities and open-world knowledge. Current mainstream efforts mainly
center around injecting personalized information from recommendation models
into LLMs by customizing input templates or aligning representations between
semantic and recommendation spaces at the prediction layer. However, they face
three significant limitations: (1) LoRA is mostly used as a core component in
existing works, but personalization is not well established in LoRA parameters
as the LoRA matrix shared by every user may not cater to different users'
characteristics, leading to suboptimal performance. (2) Although lifelong
personalized behavior sequences are ideal for personalization, their use raises
effectiveness and efficiency issues since LLMs require escalating training and
inference time to extend text lengths. (3) Existing approaches aren't scalable
for large datasets due to training efficiency constraints. Thus, LLMs only see
a small fraction of the datasets (e.g., less than 10%) instead of the whole
datasets, limiting their exposure to the full training space. To address these
problems, we propose RecLoRA. This model incorporates a Personalized LoRA
module that maintains independent LoRAs for different users and a Long-Short
Modality Retriever that retrieves different history lengths for different
modalities, significantly improving performance while adding minimal time cost.
Furthermore, we design a Few2Many Learning Strategy, using a conventional
recommendation model as a lens to magnify small training spaces to full spaces.
Extensive experiments on public datasets demonstrate the efficacy of our
RecLoRA compared to existing baseline models.

摘要：我們主要關注大型語言模型 (LLM) 在推薦領域的應用，這是一個近期積極探索的領域，並對有效提升推薦系統的邏輯推理能力和開放世界知識構成重大挑戰。目前的普遍做法主要圍繞著透過自訂輸入範本或在預測層對齊語意和推薦空間的表徵，將推薦模型中的個人化資訊注入 LLM。然而，它們面臨三項重大的限制：(1) LoRA 主要用作現有作品中的核心元件，但個人化並未在 LoRA 參數中建立完善，因為每個使用者共用的 LoRA 矩陣可能無法滿足不同使用者的特性，導致效能不佳。(2) 儘管終身個人化行為序列是個人化的理想選擇，但它們的使用會引發效能和效率問題，因為 LLM 需要增加訓練和推論時間以延伸文字長度。(3) 現有方法由於訓練效率限制，無法擴充到大型資料集。因此，LLM 僅看到資料集的一小部分（例如，不到 10%），而不是整個資料集，這限制了它們接觸完整訓練空間的機會。為了解決這些問題，我們提出 RecLoRA。此模型包含一個個人化 LoRA 模組，為不同的使用者維護獨立的 LoRA，以及一個長短期型態擷取器，為不同的型態擷取不同的歷史長度，在增加極少時間成本的同時大幅提升效能。此外，我們設計了一個少對多學習策略，使用傳統的推薦模型作為透鏡，將小型訓練空間放大到完整空間。在公開資料集上的廣泛實驗證明了我們的 RecLoRA 與現有的基準模型相比的效能。

##### **Exploring the extent of similarities in software failures across industries using LLMs**
2408.03528v2 by Martin Detloff

The rapid evolution of software development necessitates enhanced safety
measures. Extracting information about software failures from companies is
becoming increasingly more available through news articles.
  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)
model to extract industry-specific information. Although the FAIL model's
database is rich in information, it could benefit from further categorization
and industry-specific insights to further assist software engineers.
  In previous work news articles were collected from reputable sources and
categorized by incidents inside a database. Prompt engineering and Large
Language Models (LLMs) were then applied to extract relevant information
regarding the software failure. This research extends these methods by
categorizing articles into specific domains and types of software failures. The
results are visually represented through graphs.
  The analysis shows that throughout the database some software failures occur
significantly more often in specific industries. This categorization provides a
valuable resource for software engineers and companies to identify and address
common failures.
  This research highlights the synergy between software engineering and Large
Language Models (LLMs) to automate and enhance the analysis of software
failures. By transforming data from the database into an industry specific
model, we provide a valuable resource that can be used to identify common
vulnerabilities, predict potential risks, and implement proactive measures for
preventing software failures. Leveraging the power of the current FAIL database
and data visualization, we aim to provide an avenue for safer and more secure
software in the future.

摘要：<paragraph>軟體開發快速演進，迫切需要增強安全措施。從公司新聞文章中萃取軟體故障資訊正變得越來越容易。
此研究利用大型語言模型（LLM）故障分析調查（FAIL）模型萃取產業特定資訊。儘管 FAIL 模型的資料庫資訊豐富，但若能進一步分類並提供產業特定見解，將有助於軟體工程師。
在先前的研究中，我們從信譽良好的來源收集新聞文章，並將其分類為資料庫中的事件。接著應用提示工程和大型語言模型（LLM）萃取與軟體故障相關的資訊。此研究透過將文章分類到特定領域和軟體故障類型，延伸了這些方法。結果透過圖表視覺化呈現。
分析顯示，在整個資料庫中，某些軟體故障在特定產業中發生的頻率顯著較高。此分類為軟體工程師和公司提供了寶貴的資源，可識別並解決常見故障。
此研究強調了軟體工程與大型語言模型（LLM）之間的綜效作用，可自動化並增強軟體故障分析。透過將資料庫中的資料轉換為產業特定模型，我們提供了一項寶貴的資源，可用於識別常見漏洞、預測潛在風險，並實施主動措施來預防軟體故障。我們利用現有 FAIL 資料庫和資料視覺化的優勢，旨在為未來提供更安全且穩定的軟體。</paragraph>

##### **EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora**
2408.03524v1 by Faisal Qarah

This study presents EgyBERT, an Arabic language model pretrained on 10.4 GB
of Egyptian dialectal texts. We evaluated EgyBERT's performance by comparing it
with five other multidialect Arabic language models across 10 evaluation
datasets. EgyBERT achieved the highest average F1-score of 84.25% and an
accuracy of 87.33%, significantly outperforming all other comparative models,
with MARBERTv2 as the second best model achieving an F1-score 83.68% and an
accuracy 87.19%. Additionally, we introduce two novel Egyptian dialectal
corpora: the Egyptian Tweets Corpus (ETC), containing over 34.33 million tweets
(24.89 million sentences) amounting to 2.5 GB of text, and the Egyptian Forums
Corpus (EFC), comprising over 44.42 million sentences (7.9 GB of text)
collected from various Egyptian online forums. Both corpora are used in
pretraining the new model, and they are the largest Egyptian dialectal corpora
to date reported in the literature. Furthermore, this is the first study to
evaluate the performance of various language models on Egyptian dialect
datasets, revealing significant differences in performance that highlight the
need for more dialect-specific models. The results confirm the effectiveness of
EgyBERT model in processing and analyzing Arabic text expressed in Egyptian
dialect, surpassing other language models included in the study. EgyBERT model
is publicly available on \url{https://huggingface.co/faisalq/EgyBERT}.

摘要：本研究展示了 EgyBERT，這是一個在 10.4 GB 的埃及方言文本上預先訓練的阿拉伯語語言模型。我們透過與五個其他多方言阿拉伯語語言模型在 10 個評估資料集上進行比較，來評估 EgyBERT 的效能。EgyBERT 達到了最高的平均 F1 分數為 84.25% 和準確率為 87.33%，顯著優於所有其他比較模型，其中 MARBERTv2 作為第二好的模型，達到了 F1 分數 83.68% 和準確率 87.19%。此外，我們引入了兩個新穎的埃及方言語料庫：埃及推文語料庫 (ETC)，包含超過 3433 萬條推文（2489 萬個句子），相當於 2.5 GB 的文字，以及埃及論壇語料庫 (EFC)，包含超過 4442 萬個句子（7.9 GB 的文字），從各種埃及線上論壇收集而來。這兩個語料庫都用於預先訓練新模型，而且它們是迄今為止在文獻中報導的最大的埃及方言語料庫。此外，這是第一個評估各種語言模型在埃及方言資料集上的效能的研究，揭示了效能上的顯著差異，這突顯了對更多特定方言模型的需求。結果證實了 EgyBERT 模型在處理和分析以埃及方言表達的阿拉伯語文本方面的有效性，優於研究中包含的其他語言模型。EgyBERT 模型已公開發布在 \url{https://huggingface.co/faisalq/EgyBERT}。

##### **RepoMasterEval: Evaluating Code Completion via Real-World Repositories**
2408.03519v1 by Qinyun Wu, Chao Peng, Pengfei Gao, Ruida Hu, Haoyu Gan, Bo Jiang, Jinhe Tang, Zhiwen Deng, Zhanming Guan, Cuiyun Gao, Xia Liu, Ping Yang

With the growing reliance on automated code completion tools in software
development, the need for robust evaluation benchmarks has become critical.
However, existing benchmarks focus more on code generation tasks in function
and class level and provide rich text description to prompt the model. By
contrast, such descriptive prompt is commonly unavailable in real development
and code completion can occur in wider range of situations such as in the
middle of a function or a code block. These limitations makes the evaluation
poorly align with the practical scenarios of code completion tools. In this
paper, we propose RepoMasterEval, a novel benchmark for evaluating code
completion models constructed from real-world Python and TypeScript
repositories. Each benchmark datum is generated by masking a code snippet
(ground truth) from one source code file with existing test suites. To improve
test accuracy of model generated code, we employ mutation testing to measure
the effectiveness of the test cases and we manually crafted new test cases for
those test suites with low mutation score. Our empirical evaluation on 6
state-of-the-art models shows that test argumentation is critical in improving
the accuracy of the benchmark and RepoMasterEval is able to report difference
in model performance in real-world scenarios. The deployment of RepoMasterEval
in a collaborated company for one month also revealed that the benchmark is
useful to give accurate feedback during model training and the score is in high
correlation with the model's performance in practice. Based on our findings, we
call for the software engineering community to build more LLM benchmarks
tailored for code generation tools taking the practical and complex development
environment into consideration.

摘要：<paragraph>隨著軟體開發中越來越依賴自動化程式碼完成工具，對健全的評估基準的需求變得至關重要。
然而，現有的基準更注重函式和類別層級的程式碼產生任務，並提供豐富的文字描述來提示模型。
相反地，這種描述性提示通常在實際開發中不可用，而且程式碼完成可以在更廣泛的情況下發生，例如在函式或程式碼區塊的中間。
這些限制使得評估與程式碼完成工具的實際場景對齊不佳。
在本文中，我們提出 RepoMasterEval，這是一個用於評估從真實世界 Python 和 TypeScript 儲存庫建構的程式碼完成模型的新基準。
每個基準資料都是透過遮蔽來自一個原始碼檔案的程式碼片段（基本事實）和現有的測試套件來產生的。
為了提高模型產生程式碼的測試準確度，我們採用突變測試來衡量測試案例的有效性，並為突變分數低的那些測試套件手動建立新的測試案例。
我們對 6 個最先進的模型進行的實證評估顯示，測試論證對於提高基準的準確度至關重要，而 RepoMasterEval 能夠報告真實世界場景中模型效能的差異。
在一家合作公司中部署 RepoMasterEval 一個月後，也發現該基準有助於在模型訓練期間提供準確的回饋，而且分數與模型在實際中的效能高度相關。
根據我們的發現，我們呼籲軟體工程社群建立更多針對程式碼產生工具量身打造的 LLM 基準，並將實際且複雜的開發環境納入考量。</paragraph>

##### **A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems**
2408.03515v1 by Wenxiao Zhang, Xiangrui Kong, Conan Dewitt, Thomas Braunl, Jin B. Hong

The integration of Large Language Models (LLMs) like GPT-4o into robotic
systems represents a significant advancement in embodied artificial
intelligence. These models can process multi-modal prompts, enabling them to
generate more context-aware responses. However, this integration is not without
challenges. One of the primary concerns is the potential security risks
associated with using LLMs in robotic navigation tasks. These tasks require
precise and reliable responses to ensure safe and effective operation.
Multi-modal prompts, while enhancing the robot's understanding, also introduce
complexities that can be exploited maliciously. For instance, adversarial
inputs designed to mislead the model can lead to incorrect or dangerous
navigational decisions. This study investigates the impact of prompt injections
on mobile robot performance in LLM-integrated systems and explores secure
prompt strategies to mitigate these risks. Our findings demonstrate a
substantial overall improvement of approximately 30.8% in both attack detection
and system performance with the implementation of robust defence mechanisms,
highlighting their critical role in enhancing security and reliability in
mission-oriented tasks.

摘要：大型語言模型 (LLM) 如 GPT-4o 整合到機器人系統中，代表了具身人工智慧的重大進步。這些模型可以處理多模態提示，使它們能夠產生更多基於內容的回應。然而，這種整合並非沒有挑戰。主要問題之一是與在機器人導航任務中使用 LLM 相關的潛在安全風險。這些任務需要準確且可靠的回應，以確保安全且有效的操作。多模態提示在增強機器人理解力的同時，也引入了可能會被惡意利用的複雜性。例如，旨在誤導模型的對抗性輸入可能會導致不正確或危險的導航決策。本研究探討了提示注入對 LLM 整合系統中移動機器人效能的影響，並探討了安全的提示策略以降低這些風險。我們的研究結果證明，透過實施強大的防禦機制，攻擊偵測和系統效能整體大幅提升了約 30.8%，突顯了它們在提升任務導向任務中的安全性與可靠性的關鍵作用。

##### **MoExtend: Tuning New Experts for Modality and Task Extension**
2408.03511v1 by Shanshan Zhong, Shanghua Gao, Zhongzhan Huang, Wushao Wen, Marinka Zitnik, Pan Zhou

Large language models (LLMs) excel in various tasks but are primarily trained
on text data, limiting their application scope. Expanding LLM capabilities to
include vision-language understanding is vital, yet training them on multimodal
data from scratch is challenging and costly. Existing instruction tuning
methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs
via fully fine-tuning LLMs to bridge the modality gap. However, full
fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous
knowledge, and high training costs particularly in the era of increasing tasks
and modalities. To solve this issue, we introduce MoExtend, an effective
framework designed to streamline the modality adaptation and extension of
Mixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts
into pre-trained MoE models, endowing them with novel knowledge without the
need to tune pretrained models such as MoE and vision encoders. This approach
enables rapid adaptation and extension to new modal data or tasks, effectively
addressing the challenge of accommodating new modalities within LLMs.
Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk
of catastrophic forgetting. Experimental results demonstrate the efficacy and
efficiency of MoExtend in enhancing the multimodal capabilities of LLMs,
contributing to advancements in multimodal AI research. Code:
https://github.com/zhongshsh/MoExtend.

摘要：大型語言模型 (LLM) 在各種任務中表現出色，但主要訓練
文本資料，限制了其應用範圍。擴展 LLM 能力以
包含視覺語言理解至關重要，但從頭開始訓練它們多模態
資料具有挑戰性且成本高昂。現有的指令調整
方法，例如 LLAVA，通常通過完全微調 LLM 來連接預訓練的 CLIP 視覺編碼器和 LLM
彌合模態差距。然而，完全微調會受到災難性遺忘的困擾，即忘記之前的
知識，特別是在任務和模態增加的時代，訓練成本很高
為了解決這個問題，我們引入了 MoExtend，一個有效的
架構設計用於簡化模態適應和擴展
混合專家 (MoE) 模型。MoExtend 將新的專家無縫集成到預訓練的 MoE 模型中，賦予它們新的知識，而無需調整預訓練的模型，例如 MoE 和視覺編碼器。這種方法
能夠快速適應和擴展到新的模態資料或任務，有效地
解決了在 LLM 中容納新模態的挑戰。
此外，MoExtend 避免調整預訓練的模型，從而降低了風險
災難性遺忘。實驗結果證明了 MoExtend 在增強 LLM 的多模態能力方面的有效性和效率，
促進多模態 AI 研究的進步。程式碼：
https://github.com/zhongshsh/MoExtend。

##### **1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data**
2408.03506v1 by Calvin Tan, Jerome Wang

This paper presents a compute-efficient approach to pre-training a Language
Model-the "1.5-Pints"-in only 9 days, while outperforming state-of-the-art
models as an instruction-following assistant.Based on MT-Bench (a benchmark
that emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and
Microsoft's Phi.This is achieved by a carefully curated pre-training dataset of
57 billion tokens, using a mix of automated workflows and manual human review.
The selection of the dataset prioritizes content that is considered expository
and "textbook-like" to aid the model in reasoning and logical deduction,
culminating in its overall ability as a strong and versatile AI model. In terms
of the model architecture, we employed a modified Mistral tokenizer, alongside
a Llama-2 architecture for wider compatibility. For training, we adopted the
methodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints
demonstrates that by focusing on data quality over quantity in LLM training, we
can significantly reduce training time and resources required. We believe this
approach will not only make pre-training more accessible but also reduce our
carbon footprint. Our findings and resources from this research are
open-sourced, aiming to facilitate further advancements in the field. The
1.5-Pints model is available in two versions: 2K and 16K context windows.

摘要：<paragraph>本文提出了一個計算效率高的訓練方法，可以在短短 9 天內預訓練一個語言模型「1.5-Pints」，同時在作為指令追蹤助理的表現上優於最先進的模型。根據 MT-Bench（一個模擬人類判斷的基準測試），1.5-Pints 優於 Apple 的 OpenELM 和 Microsoft 的 Phi。這是透過一個經過仔細策劃的 570 億個符號的預訓練資料集實現的，結合了自動化工作流程和人工審查。資料集的選擇優先考慮被視為說明性和「教科書式」的內容，以幫助模型進行推理和邏輯演繹，最終形成其作為一個強大且用途廣泛的 AI 模型的整體能力。在模型架構方面，我們採用了一個修改過的 Mistral 分詞器，以及一個 Llama-2 架構以實現更廣泛的相容性。在訓練方面，我們採用了 StableLM、TinyLlama 和 Huggingface Zephyr 所使用的訓練方法。1.5-Pints 證明了透過在 LLM 訓練中重視資料品質而非數量，我們可以大幅減少訓練時間和所需的資源。我們相信這種方法不僅會讓預訓練更容易取得，還能減少我們的碳足跡。我們從這項研究中獲得的發現和資源都是開源的，目的是促進該領域的進一步發展。1.5-Pints 模型提供兩個版本：2K 和 16K 的上下文視窗。</paragraph>

##### **Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation**
2408.03505v1 by Weiqi Feng, Yangrui Chen, Shaoyu Wang, Yanghua Peng, Haibin Lin, Minlan Yu

Multimodal large language models (MLLMs) have extended the success of large
language models (LLMs) to multiple data types, such as image, text and audio,
achieving significant performance in various domains, including multimodal
translation, visual question answering and content generation. Nonetheless,
existing systems are inefficient to train MLLMs due to substantial GPU bubbles
caused by the heterogeneous modality models and complex data dependencies in 3D
parallelism. This paper proposes Optimus, a distributed MLLM training system
that reduces end-to-end MLLM training time. Optimus is based on our principled
analysis that scheduling the encoder computation within the LLM bubbles can
reduce bubbles in MLLM training. To make scheduling encoder computation
possible for all GPUs, Optimus searches the separate parallel plans for encoder
and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM
bubbles without breaking the original data dependencies in the MLLM model
architecture. We further decompose encoder layer computation into a series of
kernels, and analyze the common bubble pattern of 3D parallelism to carefully
optimize the sub-millisecond bubble scheduling, minimizing the overall training
time. Our experiments in a production cluster show that Optimus accelerates
MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs
compared to baselines.

摘要：多模態大型語言模型 (MLLM) 已將大型語言模型 (LLM) 的成功擴展到多種資料類型，例如影像、文字和音訊，在多模態翻譯、視覺問答和內容產生等各種領域中均取得顯著的表現。儘管如此，現有的系統由於異質模態模型和 3D 並行處理中複雜的資料依賴性而導致大量的 GPU 暫停，因此訓練 MLLM 的效率很低。本文提出 Optimus，這是一個分散式的 MLLM 訓練系統，可減少端對端的 MLLM 訓練時間。Optimus 是基於我們有原則的分析，即在 LLM 暫停中排程編碼器運算可以減少 MLLM 訓練中的暫停。為使所有 GPU 都能排程編碼器運算，Optimus 會搜尋編碼器和 LLM 的獨立並行計畫，並採用暫停排程演算法，以利用 LLM 暫停，而不會中斷 MLLM 模型架構中的原始資料依賴性。我們進一步將編碼器層運算分解成一系列的核，並分析 3D 並行處理的常見暫停模式，以仔細最佳化次毫秒的暫停排程，將整體訓練時間降至最低。我們在生產叢集中的實驗顯示，與基準相比，Optimus 在 3072 個 GPU 上使用 ViT-22B 和 GPT-175B 模型，將 MLLM 訓練速度加快了 20.5%-21.3%。

##### **Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN**
2408.03497v1 by Chang Yu, Yixin Jin, Qianwen Xing, Ye Zhang, Shaobo Guo, Shuchen Meng

Bank credit risk is a significant challenge in modern financial transactions,
and the ability to identify qualified credit card holders among a large number
of applicants is crucial for the profitability of a bank'sbank's credit card
business. In the past, screening applicants'applicants' conditions often
required a significant amount of manual labor, which was time-consuming and
labor-intensive. Although the accuracy and reliability of previously used ML
models have been continuously improving, the pursuit of more reliable and
powerful AI intelligent models is undoubtedly the unremitting pursuit by major
banks in the financial industry. In this study, we used a dataset of over
40,000 records provided by a commercial bank as the research object. We
compared various dimensionality reduction techniques such as PCA and T-SNE for
preprocessing high-dimensional datasets and performed in-depth adaptation and
tuning of distributed models such as LightGBM and XGBoost, as well as deep
models like Tabnet. After a series of research and processing, we obtained
excellent research results by combining SMOTEENN with these techniques. The
experiments demonstrated that LightGBM combined with PCA and SMOTEENN
techniques can assist banks in accurately predicting potential high-quality
customers, showing relatively outstanding performance compared to other models.

摘要：銀行信貸風險是現代金融交易中的重大挑戰，在眾多申請人中識別出合格的信用卡持有人對於銀行的信用卡業務獲利至關重要。過去，篩選申請人的條件通常需要大量的人工勞動，這既耗時又費力。儘管先前使用的 ML 模型的準確性和可靠性持續提升，但追求更可靠且強大的 AI 智能模型無疑是金融產業中各大銀行的不懈追求。在本研究中，我們使用一家商業銀行提供的超過 40,000 筆記錄的資料集作為研究對象。我們比較了 PCA 和 T-SNE 等各種降維技術以預處理高維度資料集，並對 LightGBM 和 XGBoost 等分散式模型以及 Tabnet 等深度模型進行深度調整和微調。經過一系列的研究和處理，我們結合 SMOTEENN 與這些技術獲得了優異的研究成果。實驗證明，LightGBM 結合 PCA 和 SMOTEENN 技術可以協助銀行準確預測潛在的高品質客戶，與其他模型相比表現相對出色。

##### **Automated Theorem Provers Help Improve Large Language Model Reasoning**
2408.03492v1 by Lachlan McGinness, Peter Baumgartner

In this paper we demonstrate how logic programming systems and Automated
first-order logic Theorem Provers (ATPs) can improve the accuracy of Large
Language Models (LLMs) for logical reasoning tasks where the baseline
performance is given by direct LLM solutions. We first evaluate LLM reasoning
on steamroller problems using the PRONTOQA benchmark. We show how accuracy can
be improved with a neuro-symbolic architecture where the LLM acts solely as a
front-end for translating a given problem into a formal logic language and an
automated reasoning engine is called for solving it. However, this approach
critically hinges on the correctness of the LLM translation. To assess this
translation correctness, we secondly define a framework of syntactic and
semantic error categories. We implemented the framework and used it to identify
errors that LLMs make in the benchmark domain. Based on these findings, we
thirdly extended our method with capabilities for automatically correcting
syntactic and semantic errors. For semantic error correction we integrate
first-order logic ATPs, which is our main and novel contribution. We
demonstrate that this approach reduces semantic errors significantly and
further increases the accurracy of LLM logical reasoning.

摘要：<paragraph>在本文中，我們展示了邏輯程式系統和自動化一階邏輯定理證明器 (ATP) 如何提升大型語言模型 (LLM) 在邏輯推理任務中的準確性，其中基準效能由直接的 LLM 解決方案提供。我們首先使用 PRONTOQA 基準評估 LLM 推理在壓路機問題上的表現。我們展示了如何透過神經符號架構提升準確性，其中 LLM 僅作為前端，將給定的問題轉換為形式邏輯語言，並呼叫自動推理引擎來解決它。然而，此方法至關重要地取決於 LLM 轉換的正確性。為了評估此轉換的正確性，我們其次定義了語法和語義錯誤類別的框架。我們實作了這個框架，並使用它來識別 LLM 在基準領域中產生的錯誤。基於這些發現，我們第三點擴充了我們的程式，使其具備自動修正語法和語義錯誤的能力。對於語義錯誤修正，我們整合了一階邏輯 ATP，這是我們的主要且新穎的貢獻。我們展示了此方法大幅減少了語義錯誤，並進一步提升了 LLM 邏輯推理的準確性。</paragraph>

##### **Harnessing the Power of LLMs in Source Code Vulnerability Detection**
2408.03489v1 by Andrew A Mahyari

Software vulnerabilities, caused by unintentional flaws in source code, are a
primary root cause of cyberattacks. Static analysis of source code has been
widely used to detect these unintentional defects introduced by software
developers. Large Language Models (LLMs) have demonstrated human-like
conversational abilities due to their capacity to capture complex patterns in
sequential data, such as natural languages. In this paper, we harness LLMs'
capabilities to analyze source code and detect known vulnerabilities. To ensure
the proposed vulnerability detection method is universal across multiple
programming languages, we convert source code to LLVM IR and train LLMs on
these intermediate representations. We conduct extensive experiments on various
LLM architectures and compare their accuracy. Our comprehensive experiments on
real-world and synthetic codes from NVD and SARD demonstrate high accuracy in
identifying source code vulnerabilities.

摘要：軟體漏洞是由原始碼中的無心瑕疵所造成，是網路攻擊的主要根源。原始碼的靜態分析已廣泛用於偵測軟體開發人員所引入的這些無心缺陷。大型語言模型 (LLM) 已展現出類似人類的對話能力，因為它們有能力擷取序列資料中的複雜模式，例如自然語言。在本文中，我們利用 LLM 的能力來分析原始碼並偵測已知的漏洞。為了確保所提出的漏洞偵測方法在多種程式語言中通用，我們將原始碼轉換為 LLVM IR，並在這些中間表示上訓練 LLM。我們對各種 LLM 架構進行廣泛的實驗，並比較其準確性。我們對來自 NVD 和 SARD 的真實世界和合成程式碼進行的全面實驗，證明了在識別原始碼漏洞方面具有很高的準確性。

##### **Can LLMs Serve As Time Series Anomaly Detectors?**
2408.03475v1 by Manqing Dong, Hao Huang, Longbing Cao

An emerging topic in large language models (LLMs) is their application to
time series forecasting, characterizing mainstream and patternable
characteristics of time series. A relevant but rarely explored and more
challenging question is whether LLMs can detect and explain time series
anomalies, a critical task across various real-world applications. In this
paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,
in detecting and explaining anomalies in time series. Our studies reveal that:
1) LLMs cannot be directly used for time series anomaly detection. 2) By
designing prompt strategies such as in-context learning and chain-of-thought
prompting, GPT-4 can detect time series anomalies with results competitive to
baseline methods. 3) We propose a synthesized dataset to automatically generate
time series anomalies with corresponding explanations. By applying instruction
fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time
series anomaly detection tasks. In summary, our exploration shows the promising
potential of LLMs as time series anomaly detectors.

摘要：大型語言模型 (LLM) 中一個新興的主題是其在時間序列預測中的應用，描述時間序列的主流和可模式化特徵。一個相關但鮮少探討且更具挑戰性的問題是 LLM 是否能偵測並解釋時間序列異常值，這是一個各種實際應用中至關重要的任務。在本文中，我們探討 LLM 的能力，特別是 GPT-4 和 LLaMA3，在時間序列中偵測並解釋異常值。我們的研究顯示：
1) LLM 無法直接用於時間序列異常值偵測。2) 透過設計提示策略，例如情境學習和思想鏈提示，GPT-4 可以偵測時間序列異常值，其結果與基準方法具有競爭力。3) 我們提出一個綜合資料集，以自動產生帶有對應解釋的時間序列異常值。透過在此資料集上應用指令微調，LLaMA3 在時間序列異常值偵測任務中展現出進步的效能。總而言之，我們的探討顯示出 LLM 作為時間序列異常值偵測器的潛力。

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

摘要：識別具有不同治療反應的患者子群是為醫療建議、指南和未來臨床試驗的設計提供資訊的一項重要任務。現有的子群分析方法主要集中於隨機對照試驗 (RCT)，其中治療分配是隨機的。此外，RCT 的患者群體通常受到成本的限制，且無法代表在現實世界臨床實務中可能接受治療的患者異質性。因此，當應用於觀察性研究時，此類方法會因治療的非隨機化而產生顯著的統計偏差。我們的研究引入了一種新的、結果導向的方法，用於識別觀察性研究中的治療反應子群。我們的做法是將每個患者分配到一個子群，該子群與兩個事件發生時間分配相關：一個在治療下，另一個在對照機制下。因此，它介於個別化和平均治療效果估計之間。我們模型的假設導致通過逆向傾向加權對來自治療非隨機化的統計偏差進行簡單校正。在實驗中，我們的做法在隨機和觀察性治療機制中都顯著優於當前最先進的結果導向子群分析方法。

##### **EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures**
2408.03449v1 by Teng Liang, Andrews Damoah

Electroencephalography (EEG) analysis is an important domain in the realm of
Brain-Computer Interface (BCI) research. To ensure BCI devices are capable of
providing practical applications in the real world, brain signal processing
techniques must be fast, accurate, and resource-conscious to deliver
low-latency neural analytics. This study presents a model that leverages a
pre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression
tasks. Our results showcase that this model is capable of performing at a level
comparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the
EEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our
research presents a cost-effective model applicable to resource-constrained
devices and contributes to expanding future research on lightweight,
mobile-friendly models for EEG regression.

摘要：腦電圖 (EEG) 分析是腦機介面 (BCI) 研究中的一個重要領域。為了確保 BCI 裝置能夠在現實世界中提供實際應用，腦信號處理技術必須快速、準確且注重資源，才能提供低延遲神經分析。本研究提出一個模型，該模型利用預先訓練的 MobileViT 與知識蒸餾 (KD) 來進行 EEG 回歸任務。我們的結果顯示，這個模型能夠以與先前最先進技術 (SOTA) 相當的層級執行（僅低 3%），同時執行速度快 33%，大小小 60%。我們的研究提出一個適用於受限資源裝置的具成本效益模型，並有助於擴展未來針對 EEG 回歸的輕量化、適用於行動裝置的模型研究。

##### **Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers**
2408.03414v1 by Marcus Buckmann, Edward Hill

For simple classification tasks, we show that users can benefit from the
advantages of using small, local, generative language models instead of large
commercial models without a trade-off in performance or introducing extra
labelling costs. These advantages, including those around privacy,
availability, cost, and explainability, are important both in commercial
applications and in the broader democratisation of AI. Through experiments on
17 sentence classification tasks (2-4 classes), we show that penalised logistic
regression on the embeddings from a small LLM equals (and usually betters) the
performance of a large LLM in the "tens-of-shot" regime. This requires no more
labelled instances than are needed to validate the performance of the large
LLM. Finally, we extract stable and sensible explanations for classification
decisions.

摘要：對於簡單的分類任務，我們展示了使用者可以受益於使用小型、本地的生成語言模型，而不是大型商業模型，而不會在效能上有所取捨或產生額外的標記成本。這些優點，包括隱私、可用性、成本和可解釋性，在商業應用和更廣泛的 AI 民主化中都很重要。透過對 17 個句子分類任務（2-4 個類別）進行實驗，我們展示了對來自小型 LLM 的嵌入進行懲罰式邏輯迴歸等於（通常優於）大型 LLM 在「數十次拍攝」模式下的效能。這不需要比驗證大型 LLM 的效能所需的標記實例更多。最後，我們針對分類決策提取出穩定且明智的解釋。

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

摘要：隨機多智能體多臂賭徒通常假設每個手臂的回報遵循固定分佈，無論哪個智能體拉動手臂。然而，在許多真實世界設定中，回報可能取決於每個智能體對其環境的敏感度。在醫學篩檢中，疾病檢測率會因測試類型而異；在偏好匹配中，回報可能取決於使用者偏好；在環境感測中，觀察品質可能因感測器而異。由於過去的工作未說明如何配置這些類型異質但已知敏感度的智能體在隨機賭徒設定中，我們引入一種 UCB 風格演算法，Min-Width，它會彙總來自不同智能體的資訊。在這樣做的過程中，我們解決了 (i) 彙總回報的共同挑戰，這些回報遵循每個智能體手臂配對的不同分佈，以及 (ii) 協調將智能體指定給手臂。Min-Width 促進異質智能體之間的有效協作，利用智能體回報函數中的已知結構來適當地加權其回報。我們分析 Min-Width 的遺憾，並進行偽合成和完全合成實驗來研究不同層級資訊共享的效能。我們的結果證實，當敏感度在不同智能體間差異較大時，對智能體異質性建模的收益往往較高，而結合更多資訊並不總是會改善效能。

##### **ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning**
2408.03402v1 by Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Thien Huu Nguyen

Large Language Models (LLMs) excel in various natural language processing
tasks, but leveraging them for dense passage embedding remains challenging.
This is due to their causal attention mechanism and the misalignment between
their pre-training objectives and the text ranking tasks. Despite some recent
efforts to address these issues, existing frameworks for LLM-based text
embeddings have been limited by their support for only a limited range of LLM
architectures and fine-tuning strategies, limiting their practical application
and versatility. In this work, we introduce the Unified framework for Large
Language Model Embedding (ULLME), a flexible, plug-and-play implementation that
enables bidirectional attention across various LLMs and supports a range of
fine-tuning strategies. We also propose Generation-augmented Representation
Learning (GRL), a novel fine-tuning method to boost LLMs for text embedding
tasks. GRL enforces consistency between representation-based and
generation-based relevance scores, leveraging LLMs' powerful generative
abilities for learning passage embeddings. To showcase our framework's
flexibility and effectiveness, we release three pre-trained models from ULLME
with different backbone architectures, ranging from 1.5B to 8B parameters, all
of which demonstrate strong performance on the Massive Text Embedding
Benchmark. Our framework is publicly available at:
https://github.com/nlp-uoregon/ullme. A demo video for ULLME can also be found
at https://rb.gy/ws1ile.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中表現出色，但利用它們進行密集段落嵌入仍然具有挑戰性。這是因為它們的因果注意機制以及它們的預訓練目標與文本排序任務之間的錯位。儘管最近為了解決這些問題做出了些許努力，但現有的基於 LLM 的文本嵌入架構受到其僅支援有限範圍的 LLM 架構和微調策略的限制，從而限制了它們的實際應用和多功能性。在這項工作中，我們介紹了大型語言模型嵌入的統一框架 (ULLME)，這是一個靈活的即插即用實作，可以在各種 LLM 中啟用雙向注意，並支援一系列微調策略。我們還提出了生成增強表示學習 (GRL)，這是一種新的微調方法，可以提升 LLM 以進行文本嵌入任務。GRL 確保基於表示和基於生成的相關性分數之間的一致性，利用 LLM 強大的生成能力來學習段落嵌入。為了展示我們框架的靈活性與有效性，我們從 ULLME 發布了三個預訓練模型，它們具有不同的主幹架構，範圍從 1.5B 到 8B 參數，所有這些模型在 Massive Text Embedding Benchmark 上都表現出強勁的效能。我們的框架公開於：https://github.com/nlp-uoregon/ullme。ULLME 的示範影片也可以在 https://rb.gy/ws1ile 找到。

##### **Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey**
2408.03400v1 by Vu Tuan Truong, Luan Ba Dang, Long Bao Le

Diffusion models (DMs) have achieved state-of-the-art performance on various
generative tasks such as image synthesis, text-to-image, and text-guided
image-to-image generation. However, the more powerful the DMs, the more harmful
they potentially are. Recent studies have shown that DMs are prone to a wide
range of attacks, including adversarial attacks, membership inference, backdoor
injection, and various multi-modal threats. Since numerous pre-trained DMs are
published widely on the Internet, potential threats from these attacks are
especially detrimental to the society, making DM-related security a worth
investigating topic. Therefore, in this paper, we conduct a comprehensive
survey on the security aspect of DMs, focusing on various attack and defense
methods for DMs. First, we present crucial knowledge of DMs with five main
types of DMs, including denoising diffusion probabilistic models, denoising
diffusion implicit models, noise conditioned score networks, stochastic
differential equations, and multi-modal conditional DMs. We further survey a
variety of recent studies investigating different types of attacks that exploit
the vulnerabilities of DMs. Then, we thoroughly review potential
countermeasures to mitigate each of the presented threats. Finally, we discuss
open challenges of DM-related security and envision certain research directions
for this topic.

摘要：擴散模型 (DM) 在各種生成任務上達到了最先進的性能，例如影像合成、文字轉影像和文字引導影像轉影像生成。然而，DM 越強大，潛在的危害就越大。最近的研究表明，DM 容易受到廣泛的攻擊，包括對抗性攻擊、成員推論、後門注入和各種多模式威脅。由於許多預先訓練的 DM 廣泛發布在網路上，這些攻擊的潛在威脅特別有害於社會，使得與 DM 相關的安全性成為一個值得探討的主題。因此，在本文中，我們對 DM 的安全性方面進行了全面的調查，重點關注 DM 的各種攻擊和防禦方法。首先，我們介紹了 DM 的關鍵知識，包括五種類型的 DM，包括去噪擴散機率模型、去噪擴散隱式模型、雜訊條件分數網路、隨機微分方程式和多模式條件 DM。我們進一步調查了各種最近的研究，探討了利用 DM 漏洞的不同類型的攻擊。然後，我們徹底檢視了減輕每種呈現威脅的潛在對策。最後，我們討論了與 DM 相關的安全性的公開挑戰，並預想這個主題的某些研究方向。

##### **RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms**
2408.03399v1 by Luis Roque, Carlos Soares, Luís Torgo

We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)
framework, designed to assess the robustness of hierarchical time series
forecasting models and algorithms on real-world datasets. Hierarchical time
series, where lower-level forecasts must sum to upper-level ones, are prevalent
in various contexts, such as retail sales across countries. Current empirical
evaluations of forecasting methods are often limited to a small set of
benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS
addresses this gap by systematically altering existing datasets and modifying
the characteristics of individual series and their interrelations. It uses a
set of parameterizable transformations to simulate those changes in the data
distribution. Additionally, RHiOTS incorporates an innovative visualization
component, turning complex, multidimensional robustness evaluation results into
intuitive, easily interpretable visuals. This approach allows an in-depth
analysis of algorithm and model behavior under diverse conditions. We
illustrate the use of RHiOTS by analyzing the predictive performance of several
algorithms. Our findings show that traditional statistical methods are more
robust than state-of-the-art deep learning algorithms, except when the
transformation effect is highly disruptive. Furthermore, we found no
significant differences in the robustness of the algorithms when applying
specific reconciliation methods, such as MinT. RHiOTS provides researchers with
a comprehensive tool for understanding the nuanced behavior of forecasting
algorithms, offering a more reliable basis for selecting the most appropriate
method for a given problem.

摘要：<paragraph>我們介紹階層化時間序列的穩健性 (RHiOTS) 框架，旨在評估階層化時間序列預測模型和演算法在實際資料集上的穩健性。階層化時間序列（其中較低層級的預測必須加總為較高層級的預測）在各種情境中很常見，例如各國的零售銷售。預測方法的現有經驗評估通常僅限於少數基準資料集，無法全面了解演算法行為。RHiOTS 透過系統性地改變現有資料集並修改個別序列及其相互關係的特徵，來解決這個問題。它使用一組可參數化的轉換來模擬資料分佈中的這些變化。此外，RHiOTS 結合了一個創新的視覺化元件，將複雜的多維穩健性評估結果轉換為直觀且易於解讀的視覺效果。這種方法允許深入分析演算法和模型在不同條件下的行為。我們透過分析多種演算法的預測效能來說明 RHiOTS 的使用方式。我們的研究結果顯示，傳統的統計方法比最先進的深度學習演算法更穩健，除非轉換效應具有高度破壞性。此外，我們發現當應用特定的調和方法（例如 MinT）時，演算法的穩健性沒有顯著差異。RHiOTS 為研究人員提供了一個全面的工具，用於了解預測演算法的細微行為，並為選擇最適合特定問題的方法提供更可靠的依據。</paragraph>

##### **A Non-negative VAE:the Generalized Gamma Belief Network**
2408.03388v1 by Zhibin Duan, Tiansheng Wen, Muyao Wang, Bo Chen, Mingyuan Zhou

The gamma belief network (GBN), often regarded as a deep topic model, has
demonstrated its potential for uncovering multi-layer interpretable latent
representations in text data. Its notable capability to acquire interpretable
latent factors is partially attributed to sparse and non-negative
gamma-distributed latent variables. However, the existing GBN and its
variations are constrained by the linear generative model, thereby limiting
their expressiveness and applicability. To address this limitation, we
introduce the generalized gamma belief network (Generalized GBN) in this paper,
which extends the original linear generative model to a more expressive
non-linear generative model. Since the parameters of the Generalized GBN no
longer possess an analytic conditional posterior, we further propose an
upward-downward Weibull inference network to approximate the posterior
distribution of the latent variables. The parameters of both the generative
model and the inference network are jointly trained within the variational
inference framework. Finally, we conduct comprehensive experiments on both
expressivity and disentangled representation learning tasks to evaluate the
performance of the Generalized GBN against state-of-the-art Gaussian
variational autoencoders serving as baselines.

摘要：伽马信念網路 (GBN) 通常被視為深度主題模型，已展現出其在解構文本資料中多層可解釋潛在表徵的潛力。其獲取可解釋潛在因子的顯著能力部分歸因於稀疏且非負的伽馬分布潛在變數。然而，現有的 GBN 及其變異受到線性生成模型的約束，從而限制了其表現力和適用性。為了解決這個限制，我們在這篇論文中引入了廣義伽馬信念網路 (廣義 GBN)，它將原始線性生成模型擴展到更具表現力的非線性生成模型。由於廣義 GBN 的參數不再具有解析條件後驗，我們進一步提出了向上向下威布爾推論網路來近似潛在變數的後驗分佈。生成模型和推論網路的參數在變分推論架構內聯合訓練。最後，我們對表現力和解糾纏表徵學習任務進行了全面的實驗，以評估廣義 GBN 相對於作為基準的高斯變分自動編碼器的效能。

##### **LLaVA-OneVision: Easy Visual Task Transfer**
2408.03326v1 by Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li

We present LLaVA-OneVision, a family of open large multimodal models (LMMs)
developed by consolidating our insights into data, models, and visual
representations in the LLaVA-NeXT blog series. Our experimental results
demonstrate that LLaVA-OneVision is the first single model that can
simultaneously push the performance boundaries of open LMMs in three important
computer vision scenarios: single-image, multi-image, and video scenarios.
Importantly, the design of LLaVA-OneVision allows strong transfer learning
across different modalities/scenarios, yielding new emerging capabilities. In
particular, strong video understanding and cross-scenario capabilities are
demonstrated through task transfer from images to videos.

摘要：我們展示 LLaVA-OneVision，一個開放式大型多模態模型 (LMM) 家族，
透過整合我們對 LLaVA-NeXT 部落格系列中資料、模型和視覺
表現的見解而開發。我們的實驗結果證明 LLaVA-OneVision 是第一個單一模型，可以
同時在三個重要的電腦視覺場景中擴展開放式 LMM 的效能界限：單一影像、多重影像和影片場景。
重要的是，LLaVA-OneVision 的設計允許在不同的模態/場景中進行強大的轉移學習，產生新的新興能力。特別是，
透過從影像到影片的任務轉移，展示了強大的影片理解和跨場景能力。

##### **CoverBench: A Challenging Benchmark for Complex Claim Verification**
2408.03325v1 by Alon Jacovi, Moran Ambar, Eyal Ben-David, Uri Shaham, Amir Feder, Mor Geva, Dror Marcus, Avi Caciularu

There is a growing line of research on verifying the correctness of language
models' outputs. At the same time, LMs are being used to tackle complex queries
that require reasoning. We introduce CoverBench, a challenging benchmark
focused on verifying LM outputs in complex reasoning settings. Datasets that
can be used for this purpose are often designed for other complex reasoning
tasks (e.g., QA) targeting specific use-cases (e.g., financial tables),
requiring transformations, negative sampling and selection of hard examples to
collect such a benchmark. CoverBench provides a diversified evaluation for
complex claim verification in a variety of domains, types of reasoning,
relatively long inputs, and a variety of standardizations, such as multiple
representations for tables where available, and a consistent schema. We
manually vet the data for quality to ensure low levels of label noise. Finally,
we report a variety of competitive baseline results to show CoverBench is
challenging and has very significant headroom. The data is available at
https://huggingface.co/datasets/google/coverbench .

摘要：對於驗證語言模型輸出的正確性，有越來越多的研究。同時，LM 被用於解決需要推理的複雜查詢。我們介紹 CoverBench，這是一個具有挑戰性的基準，專注於驗證複雜推理設定中的 LM 輸出。可用於此目的的資料集通常是為其他複雜推理任務（例如，QA）而設計的，這些任務針對特定用例（例如，財務表格），需要轉換、負面抽樣和選擇困難範例來收集此類基準。CoverBench 提供了對各種領域、推理類型、相對較長的輸入以及各種標準化的多元評估，例如表格的各種表示（如果可用）和一致的架構。我們手動審查資料的品質，以確保低程度的標籤雜訊。最後，我們報告了各種競爭性的基準結果，以顯示 CoverBench 具有挑戰性且有非常顯著的進步空間。資料可在 https://huggingface.co/datasets/google/coverbench 取得。

##### **Training LLMs to Recognize Hedges in Spontaneous Narratives**
2408.03319v1 by Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan

Hedges allow speakers to mark utterances as provisional, whether to signal
non-prototypicality or "fuzziness", to indicate a lack of commitment to an
utterance, to attribute responsibility for a statement to someone else, to
invite input from a partner, or to soften critical feedback in the service of
face-management needs. Here we focus on hedges in an experimentally
parameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced
from memory by 21 speakers for co-present addressees, transcribed to text
(Galati and Brennan, 2010). We created a gold standard of hedges annotated by
human coders (the Roadrunner-Hedge corpus) and compared three LLM-based
approaches for hedge detection: fine-tuning BERT, and zero and few-shot
prompting with GPT-4o and LLaMA-3. The best-performing approach was a
fine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on
the top performing approaches, we used an LLM-in-the-Loop approach to improve
the gold standard coding, as well as to highlight cases in which hedges are
ambiguous in linguistically interesting ways that will guide future research.
This is the first step in our research program to train LLMs to interpret and
generate collateral signals appropriately and meaningfully in conversation.

摘要：<paragraph>對沖允許說話者將言論標記為暫定的，無論是要標示非原型或「模糊性」，表示對言論缺乏承諾，將聲明的責任歸咎於他人，邀請夥伴提供意見，或在面子管理需求的服務中軟化批評性的回饋。在這裡，我們專注於 21 位說話者為共同出席的受話者自發性地從記憶中產生 63 個 Roadrunner 卡通敘事的實驗性參數化語料庫中的對沖，並轉錄成文字（Galati 和 Brennan，2010 年）。我們建立了由人類編碼器註釋的對沖黃金標準（Roadrunner-Hedge 語料庫），並比較了三種基於 LLM 的對沖偵測方法：微調 BERT，以及使用 GPT-4o 和 LLaMA-3 進行零次和少次提示。表現最佳的方法是微調後的 BERT 模型，其次是少次提示的 GPT-4o。在對表現最佳的方法進行錯誤分析後，我們使用 LLM-in-the-Loop 方法來改進黃金標準編碼，並強調對沖在語言學上有趣的方面中模稜兩可的情況，這將指導未來的研究。這是我們研究計畫的第一步，目的是訓練 LLM 在對話中適當地且有意義地解釋和產生附帶信號。</paragraph>

##### **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**
2408.03314v1 by Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar

Enabling LLMs to improve their outputs by using more test-time computation is
a critical step towards building generally self-improving agents that can
operate on open-ended natural language. In this paper, we study the scaling of
inference-time computation in LLMs, with a focus on answering the question: if
an LLM is allowed to use a fixed but non-trivial amount of inference-time
compute, how much can it improve its performance on a challenging prompt?
Answering this question has implications not only on the achievable performance
of LLMs, but also on the future of LLM pretraining and how one should tradeoff
inference-time and pre-training compute. Despite its importance, little
research attempted to understand the scaling behaviors of various test-time
inference methods. Moreover, current work largely provides negative results for
a number of these strategies. In this work, we analyze two primary mechanisms
to scale test-time computation: (1) searching against dense, process-based
verifier reward models; and (2) updating the model's distribution over a
response adaptively, given the prompt at test time. We find that in both cases,
the effectiveness of different approaches to scaling test-time compute
critically varies depending on the difficulty of the prompt. This observation
motivates applying a "compute-optimal" scaling strategy, which acts to most
effectively allocate test-time compute adaptively per prompt. Using this
compute-optimal strategy, we can improve the efficiency of test-time compute
scaling by more than 4x compared to a best-of-N baseline. Additionally, in a
FLOPs-matched evaluation, we find that on problems where a smaller base model
attains somewhat non-trivial success rates, test-time compute can be used to
outperform a 14x larger model.

摘要：讓 LLM 能夠透過使用更多測試時間運算來改善其產出，是建立一般自改善代理程式的重要步驟，該代理程式可以在開放式自然語言中運作。在本文中，我們研究了 LLM 中推論時間運算的擴充，重點在回答下列問題：如果允許 LLM 使用固定但非瑣碎的推論時間運算量，它可以在具挑戰性的提示中改善多少效能？回答這個問題不僅對 LLM 可達到的效能有影響，也對 LLM 預訓練的未來以及如何權衡推論時間與預訓練運算產生影響。儘管其重要性，但很少有研究嘗試了解各種測試時間推論方法的擴充行為。此外，目前的工作在很大程度上為許多這些策略提供了負面結果。在這項工作中，我們分析了兩種擴充測試時間運算的主要機制：(1) 針對密集的、基於程序的驗證器獎勵模型進行搜尋；以及 (2) 根據測試時間的提示，自適應地更新模型在回應上的分佈。我們發現，在這兩種情況下，擴充測試時間運算的不同方法的有效性，會根據提示的難度而有顯著差異。這個觀察結果促使我們採用「運算最佳化」擴充策略，該策略的作用是針對每個提示自適應地最有效地配置測試時間運算。使用這個運算最佳化策略，與最佳 N 基準線相比，我們可以將測試時間運算擴充的效率提高 4 倍以上。此外，在 FLOPs 匹配的評估中，我們發現對於較小的基礎模型達到相當不平凡的成功率的問題，測試時間運算可用於優於大 14 倍的模型。

##### **Prioritize Alignment in Dataset Distillation**
2408.03360v1 by Zekai Li, Ziyao Guo, Wangbo Zhao, Tianle Zhang, Zhi-Qi Cheng, Samir Khaki, Kaipeng Zhang, Ahmad Sajed, Konstantinos N Plataniotis, Kai Wang, Yang You

Dataset Distillation aims to compress a large dataset into a significantly
more compact, synthetic one without compromising the performance of the trained
models. To achieve this, existing methods use the agent model to extract
information from the target dataset and embed it into the distilled dataset.
Consequently, the quality of extracted and embedded information determines the
quality of the distilled dataset. In this work, we find that existing methods
introduce misaligned information in both information extraction and embedding
stages. To alleviate this, we propose Prioritize Alignment in Dataset
Distillation (PAD), which aligns information from the following two
perspectives. 1) We prune the target dataset according to the compressing ratio
to filter the information that can be extracted by the agent model. 2) We use
only deep layers of the agent model to perform the distillation to avoid
excessively introducing low-level information. This simple strategy effectively
filters out misaligned information and brings non-trivial improvement for
mainstream matching-based distillation algorithms. Furthermore, built on
trajectory matching, \textbf{PAD} achieves remarkable improvements on various
benchmarks, achieving state-of-the-art performance.

摘要：数据集蒸馏旨在将大型数据集压缩成一个显著更紧凑、合成的数据集，而不会损害训练模型的性能。为了实现这一目标，现有方法使用代理模型从目标数据集中提取信息，并将其嵌入到蒸馏数据集中。因此，提取和嵌入的信息的质量决定了蒸馏数据集的质量。在这项工作中，我们发现现有方法在信息提取和嵌入阶段都引入了不一致的信息。为了缓解这种情况，我们提出了数据集蒸馏中的优先对齐（PAD），它从以下两个角度对齐信息。1) 我们根据压缩率对目标数据集进行剪枝，以过滤掉代理模型可以提取的信息。2) 我们仅使用代理模型的深度层来执行蒸馏，以避免过度引入低级信息。这种简单的策略有效地过滤掉了不一致的信息，并为基于匹配的主流蒸馏算法带来了非平凡的改进。此外，基于轨迹匹配，\textbf{PAD} 在各种基准上取得了显着的改进，实现了最先进的性能。

##### **KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**
2408.03297v1 by Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, Yasha Wang

By integrating external knowledge, Retrieval-Augmented Generation (RAG) has
become an effective strategy for mitigating the hallucination problems that
large language models (LLMs) encounter when dealing with knowledge-intensive
tasks. However, in the process of integrating external non-parametric
supporting evidence with internal parametric knowledge, inevitable knowledge
conflicts may arise, leading to confusion in the model's responses. To enhance
the knowledge selection of LLMs in various contexts, some research has focused
on refining their behavior patterns through instruction-tuning. Nonetheless,
due to the absence of explicit negative signals and comparative objectives,
models fine-tuned in this manner may still exhibit undesirable behaviors in the
intricate and realistic retrieval scenarios. To this end, we propose a
Knowledge-aware Preference Optimization, dubbed KaPO, aimed at achieving
controllable knowledge selection in real retrieval scenarios. Concretely, we
explore and simulate error types across diverse context combinations and learn
how to avoid these negative signals through preference optimization methods.
Simultaneously, by adjusting the balance between response length and the
proportion of preference data representing different behavior patterns, we
enhance the adherence capabilities and noise robustness of LLMs in a balanced
manner. Experimental results show that KaPO outperforms previous methods for
handling knowledge conflicts by over 37%, while also exhibiting robust
generalization across various out-of-distribution datasets.

摘要：透過整合外部知識，檢索增強生成（RAG）已成為減輕大型語言模型（LLM）在處理知識密集型任務時所遇到的幻覺問題的有效策略。然而，在將外部非參數支持證據與內部參數知識整合的過程中，可能會產生不可避免的知識衝突，導致模型回應混淆。為了增強 LLM 在各種情境中的知識選擇，一些研究已專注於透過指令微調來改善其行為模式。儘管如此，由於缺乏明確的負面訊號和比較目標，以這種方式微調的模型在複雜且真實的檢索情境中仍可能表現出不良行為。為此，我們提出一個稱為 KaPO 的知識感知偏好最佳化，旨在實現實際檢索情境中的可控知識選擇。具體來說，我們探索並模擬各種情境組合中的錯誤類型，並學習如何透過偏好最佳化方法來避免這些負面訊號。同時，透過調整回應長度和代表不同行為模式的偏好資料比例之間的平衡，我們以平衡的方式增強了 LLM 的遵守能力和抗噪性。實驗結果顯示，KaPO 在處理知識衝突方面優於先前的各種方法，優勢超過 37%，同時在各種非分佈資料集上也表現出強大的泛化能力。

##### **Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**
2408.03292v1 by Lizi Zhang, Azadeh Davoodi

There has been significant recent progress to reduce the computational effort
of static IR drop analysis using neural networks, and modeling as an
image-to-image translation task. A crucial issue is the lack of sufficient data
from real industry designs to train these networks. Additionally, there is no
methodology to explain a high-drop pixel in a predicted IR drop image to its
specific root-causes. In this work, we first propose a U-Net neural network
model with attention gates which is specifically tailored to achieve fast and
accurate image-based static IR drop prediction. Attention gates allow selective
emphasis on relevant parts of the input data without supervision which is
desired because of the often sparse nature of the IR drop map. We propose a
two-phase training process which utilizes a mix of artificially-generated data
and a limited number of points from real designs. The results are, on-average,
18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of
the ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we
propose a fast method using saliency maps which can explain a predicted IR drop
in terms of specific input pixels contributing the most to a drop. In our
experiments, we show the number of high IR drop pixels can be reduced
on-average by 18% by mimicking upsize of a tiny portion of PDN's resistive
edges.

摘要：<paragraph>利用神經網路和將其建模為影像轉換任務，最近在降低靜態 IR 降壓分析的計算工作上取得顯著進展。一個關鍵問題是缺乏來自真實產業設計的足夠資料來訓練這些網路。此外，沒有方法可以解釋預測 IR 降壓影像中的高降壓像素及其具體根本原因。在這項工作中，我們首先提出一個具有注意力閘的 U-Net 神經網路模型，它專門設計用於實現快速且準確的基於影像的靜態 IR 降壓預測。注意力閘允許選擇性地強調輸入資料中相關部分，而無需監督，這是因為 IR 降壓圖通常具有稀疏特性的緣故。我們提出了一個兩階段訓練過程，它利用人工生成資料和來自真實設計的有限數量的點。與 ICCAD 2023 競賽的獲勝者（僅 U-Net）相比，在真實設計上測試時，結果在 MAE 上平均提高 18%（53%），在 F1 分數上提高 14%（113%）。其次，我們提出了一種使用顯著性圖的快速方法，它可以用貢獻降壓最多的特定輸入像素來解釋預測的 IR 降壓。在我們的實驗中，我們表明，通過模擬縮小 PDN 電阻邊緣的一小部分，可以將高 IR 降壓像素的數量平均減少 18%。</paragraph>

##### **SARA: Singular-Value Based Adaptive Low-Rank Adaption**
2408.03290v1 by Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong

With the increasing number of parameters in large pre-trained models, LoRA as
a parameter-efficient fine-tuning(PEFT) method is widely used for not adding
inference overhead. The LoRA method assumes that weight changes during
fine-tuning can be approximated by low-rank matrices. However, the rank values
need to be manually verified to match different downstream tasks, and they
cannot accommodate the varying importance of different layers in the model. In
this work, we first analyze the relationship between the performance of
different layers and their ranks using SVD. Based on this, we design the
Singular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds
the rank during initialization by performing SVD on the pre-trained weights.
Additionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly
reduces the number of parameters by fine-tuning only multiple parallel sets of
singular values controlled by a router. Extensive experiments on various
complex tasks demonstrate the simplicity and parameter efficiency of our
methods. They can effectively and adaptively find the most suitable rank for
each layer of each model.

摘要：隨著大型預訓練模型中參數數量的增加，LoRA 作為一種參數高效的微調 (PEFT) 方法被廣泛用於不增加推理開銷。LoRA 方法假設微調期間的權重變化可以用低秩矩陣近似。然而，秩值需要手動驗證以匹配不同的下游任務，並且它們無法適應模型中不同層的不同重要性。在這項工作中，我們首先使用 SVD 分析不同層的性能與其秩之間的關係。基於此，我們設計了基於奇異值的自適應低秩適應 (SARA)，它通過對預訓練權重執行 SVD 來自適應地找到初始化期間的秩。此外，我們探索了混合 SARA (Mo-SARA)，它通過僅微調由路由器控制的奇異值的多個並行集來顯著減少參數數量。在各種複雜任務上的大量實驗證明了我們方法的簡潔性和參數效率。它們可以有效且自適應地找到每個模型每一層最合適的秩。

##### **StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**
2408.03281v2 by Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun

Evaluation is the baton for the development of large language models. Current
evaluations typically employ a single-item assessment paradigm for each atomic
test objective, which struggles to discern whether a model genuinely possesses
the required capabilities or merely memorizes/guesses the answers to specific
questions. To this end, we propose a novel evaluation framework referred to as
StructEval. Starting from an atomic test objective, StructEval deepens and
broadens the evaluation by conducting a structured assessment across multiple
cognitive levels and critical concepts, and therefore offers a comprehensive,
robust and consistent evaluation for LLMs. Experiments on three widely-used
benchmarks demonstrate that StructEval serves as a reliable tool for resisting
the risk of data contamination and reducing the interference of potential
biases, thereby providing more reliable and consistent conclusions regarding
model capabilities. Our framework also sheds light on the design of future
principled and trustworthy LLM evaluation protocols.

摘要：評估是大語言模型發展的指標。目前的評估通常對每個原子測試目標採用單一項目評估範例，這很難辨別模型是否真正具備所需的技能，或僅僅是記憶/猜測特定問題的答案。為此，我們提出一個稱為 StructEval 的新評估架構。從一個原子測試目標開始，StructEval 透過在多個認知層面和關鍵概念中進行結構化評估來加深和擴展評估，因此為 LLM 提供全面、穩健且一致的評估。在三個廣泛使用的基準測試上的實驗表明，StructEval 可作為抵抗資料污染風險和減少潛在偏差干擾的可靠工具，從而對模型能力提供更可靠且一致的結論。我們的架構也為未來基於原則且值得信賴的 LLM 評估協定的設計提供了啟示。

##### **Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**
2408.03274v1 by Angie Boggust, Venkatesh Sivaraman, Yannick Assogba, Donghao Ren, Dominik Moritz, Fred Hohman

To deploy machine learning models on-device, practitioners use compression
algorithms to shrink and speed up models while maintaining their high-quality
output. A critical aspect of compression in practice is model comparison,
including tracking many compression experiments, identifying subtle changes in
model behavior, and negotiating complex accuracy-efficiency trade-offs.
However, existing compression tools poorly support comparison, leading to
tedious and, sometimes, incomplete analyses spread across disjoint tools. To
support real-world comparative workflows, we develop an interactive visual
system called Compress and Compare. Within a single interface, Compress and
Compare surfaces promising compression strategies by visualizing provenance
relationships between compressed models and reveals compression-induced
behavior changes by comparing models' predictions, weights, and activations. We
demonstrate how Compress and Compare supports common compression analysis tasks
through two case studies, debugging failed compression on generative language
models and identifying compression artifacts in image classification models. We
further evaluate Compress and Compare in a user study with eight compression
experts, illustrating its potential to provide structure to compression
workflows, help practitioners build intuition about compression, and encourage
thorough analysis of compression's effect on model behavior. Through these
evaluations, we identify compression-specific challenges that future visual
analytics tools should consider and Compress and Compare visualizations that
may generalize to broader model comparison tasks.

摘要：為了在裝置上部署機器學習模型，實務工作者會使用壓縮演算法來縮小模型的規模並加快模型的速度，同時維持其高品質的輸出。在實際應用中，壓縮的一個重要面向是模型比較，包括追蹤許多壓縮實驗、找出模型行為中的細微變化，以及協商複雜的準確度與效率折衷。然而，現有的壓縮工具對於比較的支持很差，導致繁瑣且有時不完整的分析散布在不同的工具中。為了支援真實世界的比較工作流程，我們開發了一個互動式視覺系統，稱為「壓縮與比較」。在單一介面中，「壓縮與比較」會透過視覺化壓縮模型之間的來源關係，找出有前景的壓縮策略，並透過比較模型的預測、權重和激勵，揭露壓縮引發的行為變化。我們透過兩個案例研究展示「壓縮與比較」如何支援常見的壓縮分析任務，包括偵錯生成語言模型中失敗的壓縮，以及找出影像分類模型中的壓縮人工製品。我們進一步在一個使用者研究中評估「壓縮與比較」，該研究有八位壓縮專家參與，說明其提供結構給壓縮工作流程、協助實務工作者建立關於壓縮的直覺，以及鼓勵徹底分析壓縮對模型行為的影響的潛力。透過這些評估，我們找出未來的視覺分析工具應考量的特定於壓縮的挑戰，以及可能會推廣到更廣泛的模型比較任務的「壓縮與比較」視覺化。

##### **LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification**
2408.03359v1 by Zhen Qin, Junru Wu, Jiaming Shen, Tianqi Liu, Xuanhui Wang

We introduce LAMPO, a novel paradigm that leverages Large Language Models
(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike
conventional methods, which concatenate all demonstration examples with the
test instance and prompt LLMs to produce the pointwise prediction, our
framework uses the LLM as a preference machine that makes a relative
comparative decision between the test instance and each demonstration. A
self-supervised method is then introduced to aggregate these binary comparisons
into the final ordinal decision. LAMPO addresses several limitations inherent
in previous methods, including context length constraints, ordering biases, and
challenges associated with absolute point-wise estimation. Extensive
experiments on seven public datasets demonstrate LAMPO's remarkably competitive
performance across a diverse spectrum of applications (e.g., movie review
analysis and hate speech detection). Notably, in certain applications, the
improvement can be substantial, exceeding 20% in an absolute term. Moreover, we
believe LAMPO represents an interesting addition to the non-parametric
application layered on top of LLMs, as it supports black-box LLMs without
necessitating the outputting of LLM's internal states (e.g., embeddings), as
seen in previous approaches.

摘要：我們介紹 LAMPO，這是一種新穎的範例，它利用大型語言模型 (LLM) 來解決少次數多類別序數分類任務。與傳統方法不同，傳統方法會將所有示範範例與測試實例串聯，並提示 LLM 產生逐點預測，我們的架構使用 LLM 作為偏好機器，在測試實例和每個示範之間做出相對比較決策。然後引入一種自我監督方法，將這些二元比較彙總成最終的序數決策。LAMPO 解決了先前方法中固有的幾個限制，包括上下文長度限制、排序偏差以及與絕對逐點估計相關的挑戰。在七個公共資料集上的大量實驗證明了 LAMPO 在各種應用（例如，電影評論分析和仇恨言論偵測）中具有顯著的競爭力。值得注意的是，在某些應用中，進步可能是實質性的，以絕對值超過 20%。此外，我們相信 LAMPO 是建立在 LLM 之上的非參數應用的一個有趣的補充，因為它支援黑盒 LLM，而不需要輸出 LLM 的內部狀態（例如，嵌入），如先前方法中所見。

##### **Synthesizing Text-to-SQL Data from Weak and Strong LLMs**
2408.03256v1 by Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou

The capability gap between open-source and closed-source large language
models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we
introduce a synthetic data approach that combines data produced by larger, more
powerful models (strong models) with error information data generated by
smaller, not well-aligned models (weak models). The method not only enhances
the domain generalization of text-to-SQL models but also explores the potential
of error data supervision through preference learning. Furthermore, we employ
the synthetic data approach for instruction tuning on open-source LLMs,
resulting SENSE, a specialized text-to-SQL model. The effectiveness of SENSE is
demonstrated through state-of-the-art results on the SPIDER and BIRD
benchmarks, bridging the performance gap between open-source models and methods
prompted by closed-source models.

摘要：開放原始碼與閉源大型語言模型 (LLM) 之間的能力差距，仍然是文字轉 SQL 任務中的一項挑戰。在本文中，我們介紹了一種合成資料方法，它結合了由更大、更強大的模型 (強模型) 所產生的資料，以及由較小、對齊不佳的模型 (弱模型) 所產生的錯誤資訊資料。此方法不僅增強了文字轉 SQL 模型的領域概括性，還透過偏好學習探索了錯誤資料監督的潛力。此外，我們將合成資料方法用於開放原始碼 LLM 上的指令調整，產生了 SENSE，一種專門的文字轉 SQL 模型。SENSE 的有效性透過 SPIDER 和 BIRD 基準測試的最新結果得到證明，縮小了開放原始碼模型與閉源模型提示方法之間的效能差距。

##### **Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**
2408.03247v1 by Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng

In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.

摘要：<paragraph>在本文中，我們探討大型語言模型 (LLM) 在面對推理任務時，是否會主動回憶或檢索其內部事實知識庫。透過知識神經元分析 LLM 在每個推理步驟中的內部事實回憶，我們發現 LLM 在某些情況下無法利用關鍵的事實關聯。相反地，他們傾向於選擇替代的捷徑途徑來回答推理問題。透過手動操作 LLM 中參數化知識的回憶過程，我們證明了增強此回憶過程會直接改善推理表現，而抑制它則會導致顯著的退化。此外，我們評估了思想鏈 (CoT) 提示的影響，這是一種解決複雜推理任務的強大技術。我們的研究結果表明，CoT 可以透過鼓勵 LLM 從事有序且可靠的推理來加強對事實知識的回憶。此外，我們探討了背景衝突如何影響推理過程中事實的檢索，以全面了解 LLM 的事實回憶行為。代碼和數據將很快提供。</paragraph>

##### **Making Long-Context Language Models Better Multi-Hop Reasoners**
2408.03246v1 by Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang

Recent advancements in long-context modeling have enhanced language models
(LMs) for complex tasks across multiple NLP applications. Despite this
progress, we find that these models struggle with multi-hop reasoning and
exhibit decreased performance in the presence of noisy contexts. In this paper,
we introduce Reasoning with Attributions, a novel approach that prompts LMs to
supply attributions for each assertion during their reasoning. We validate our
approach through experiments on three multi-hop datasets, employing both
proprietary and open-source models, and demonstrate its efficacy and
resilience. Furthermore, we explore methods to augment reasoning capabilities
via fine-tuning and offer an attribution-annotated dataset and a specialized
training strategy. Our fine-tuned model achieves competitive performance on
multi-hop reasoning benchmarks, closely paralleling proprietary LMs such as
ChatGPT and Claude-instant.

摘要：最近在長文本建模方面的進展增強了語言模型 (LM) 在多個 NLP 應用中處理複雜任務的能力。儘管有這些進展，我們發現這些模型在多跳推理方面遇到困難，並且在存在嘈雜環境時表現下降。在本文中，我們介紹了歸因推理，這是一種新穎的方法，它提示 LM 在推理過程中為每個斷言提供歸因。我們通過在三個多跳數據集上進行實驗驗證了我們的做法，同時採用專有模型和開源模型，並展示了其有效性和彈性。此外，我們探索了通過微調來擴充推理能力的方法，並提供了一個歸因註釋數據集和一個專門的訓練策略。我們微調後的模型在多跳推理基準上取得了有競爭力的表現，與專有 LM（例如 ChatGPT 和 Claude-instant）密切相關。

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

摘要：阿茲海默症 (AD) 是一種目前無法治癒的神經退化性疾病。
準確地偵測 AD，特別是在早期階段，代表一項高度的研究優先事項。AD 的特徵是會逐漸認知功能受損，這與腦部功能連接性 (FC) 的改變有關。基於這種關聯，在過去的數十年中，許多研究已使用 FC 和機器學習來區分 AD 和健康老化。這種偵測方法的最新發展，突顯了使用圖神經網路 (GNN) 作為腦部功能分析。在本文中，我們提出了一個堆疊的時空特徵萃取和圖形生成，基於 AD 分類模型，使用靜止狀態 fMRI。所提出的多層級生成連接組 (MLC) 基於圖形卷積網路 (GCN) (MLC-GCN) 包含一個多圖形生成區塊和一個 GCN 預測區塊。多圖形生成區塊包含一個時空特徵萃取層的階層，用於萃取不同深度下的時空 rsfMRI 特徵，並建立對應的連接組。GCN 預測區塊採用已學習的多層級連接組，在每個層級建立並最佳化 GCN，並將已學習的圖形特徵串聯成用於 AD 分類的最終預測特徵。透過獨立的群組驗證，MLC-GCN 在區分 MCI、AD 和正常老化方面，表現優於最先進的 GCN 和基於 rsfMRI 的 AD 分類器。所提出的 MLC-GCN 也在從兩個獨立的資料集中學習臨床上合理的連接組節點和連接特徵方面，表現出高度的可解釋性。雖然我們只在 AD 上測試 MLC-GCN，但基本的基於 rsfMRI 的多層級學習 GCN 基於結果預測策略，對其他疾病或臨床結果有效。

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

摘要：<paragraph>針對手術器械分割（SIS）的個人化聯邦學習（PFL）是一種有前景的方法。它讓多個臨床地點能夠在隱私的條件下共同訓練一系列模型，每個模型都根據每個地點的個別分佈進行調整。現有的 PFL 方法很少考慮多頭自我注意力的個人化，而且沒有考慮外觀的多樣性和器械形狀的相似性，這兩者都存在於手術場景中。因此，我們提出了 PFedSIS，這是一種具有視覺特徵先驗的 SIS 的新型 PFL 方法，它結合了全局個性化解糾纏（GPD）、外觀調節個性化增強（APE）和形狀相似性全局增強（SGE），以提升每個地點的 SIS 效能。GPD 代表了針對多頭自我注意力個性化進行頭部分配的首次嘗試。為了保留每個地點的獨特外觀表示並逐漸利用地點間的差異，APE 引入了外觀調節，並透過超網路為每個地點的個性化參數提供自訂的逐層聚合解決方案。器械的相互形狀資訊透過 SGE 進行維護和共享，這增強了影像層級上的跨風格形狀一致性，並計算每個地點在預測層級上的形狀相似性貢獻，以更新全局參數。PFedSIS 在骰子系數上優於現有最先進的方法，分別提升了 +1.51%、IoU 提升了 +2.11%、ASSD 降低了 -2.79、HD95 效能提升了 -15.55。對應的程式碼和模型將在 https://github.com/wzjialang/PFedSIS 上發布。</paragraph>

##### **A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**
2408.03202v1 by Zifeng Cheng, Zhiwei Jiang, Yafeng Yin, Zhaoling Chen, Cong Wang, Shiping Ge, Qiguo Huang, Qing Gu

Multi-Label Text Classification (MLTC) is a practical yet challenging task
that involves assigning multiple non-exclusive labels to each document.
Previous studies primarily focus on capturing label correlations to assist
label prediction by introducing special labeling schemes, designing specific
model structures, or adding auxiliary tasks. Recently, the $k$ Nearest Neighbor
($k$NN) framework has shown promise by retrieving labeled samples as references
to mine label co-occurrence information in the embedding space. However, two
critical biases, namely embedding alignment bias and confidence estimation
bias, are often overlooked, adversely affecting prediction performance. In this
paper, we introduce a DEbiased Nearest Neighbors (DENN) framework for MLTC,
specifically designed to mitigate these biases. To address embedding alignment
bias, we propose a debiased contrastive learning strategy, enhancing neighbor
consistency on label co-occurrence. For confidence estimation bias, we present
a debiased confidence estimation strategy, improving the adaptive combination
of predictions from $k$NN and inductive binary classifications. Extensive
experiments conducted on four public benchmark datasets (i.e., AAPD, RCV1-V2,
Amazon-531, and EUR-LEX57K) showcase the effectiveness of our proposed method.
Besides, our method does not introduce any extra parameters.

摘要：多標籤文字分類 (MLTC) 是一項實用卻具有挑戰性的任務，涉及將多個非獨佔標籤指派給每個文件。先前的研究主要專注於擷取標籤關聯性，藉由引入特殊標籤架構、設計特定模型結構或新增輔助任務來協助標籤預測。最近，k 最近鄰 ($k$NN) 架構透過擷取標籤樣本作為參考，在嵌入空間中挖掘標籤共現資訊，展現了前景。然而，兩個關鍵偏差，即嵌入對齊偏差和信心估計偏差，經常被忽略，對預測效能產生負面影響。在本文中，我們介紹了用於 MLTC 的去偏差最近鄰 (DENN) 架構，特別設計用於減輕這些偏差。為了處理嵌入對齊偏差，我們提出了一種去偏差對比學習策略，增強鄰居在標籤共現上的一致性。對於信心估計偏差，我們提出了一種去偏差信心估計策略，改善了來自 $k$NN 和歸納二元分類的預測的適應性組合。在四個公開基準資料集（即 AAPD、RCV1-V2、Amazon-531 和 EUR-LEX57K）上進行的廣泛實驗展示了我們提出的方法的有效性。此外，我們的方法沒有引入任何額外參數。

##### **Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**
2408.03200v2 by Kunkun Hao, Yonggang Luo, Wen Cui, Yuqiao Bai, Jucheng Yang, Songyang Yan, Yuxi Pan, Zijiang Yang

Evaluating the decision-making system is indispensable in developing
autonomous vehicles, while realistic and challenging safety-critical test
scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks
to the long-tailed distribution, sparsity, and rarity in real-world data sets.
To tackle this problem, in this paper, we introduce a natural adversarial
scenario generation solution using naturalistic human driving priors and
reinforcement learning techniques. By doing this, we can obtain large-scale
test scenarios that are both diverse and realistic. Specifically, we build a
simulation environment that mimics natural traffic interaction scenarios.
Informed by this environment, we implement a two-stage procedure. The first
stage incorporates conventional rule-based models, e.g., IDM~(Intelligent
Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes)
model, to coarsely and discretely capture and calibrate key control parameters
from the real-world dataset. Next, we leverage GAIL~(Generative Adversarial
Imitation Learning) to represent driver behaviors continuously. The derived
GAIL can be further used to design a PPO~(Proximal Policy Optimization)-based
actor-critic network framework to fine-tune the reward function, and then
optimizes our natural adversarial scenario generation solution. Extensive
experiments have been conducted in the NGSIM dataset including the trajectory
of 3,000 vehicles. Essential traffic parameters were measured in comparison
with the baseline model, e.g., the collision rate, accelerations, steering, and
the number of lane changes. Our findings demonstrate that the proposed model
can generate realistic safety-critical test scenarios covering both naturalness
and adversariality, which can be a cornerstone for the development of
autonomous vehicles.

摘要：在開發自動駕駛車輛時，評估決策系統是不可或缺的，而逼真且具有挑戰性的安全關鍵測試情境扮演著至關重要的角色。要取得這些情境並非易事，這是因為在現實世界的資料集中存在長尾分布、稀疏性和稀有性。為了解決這個問題，我們在本文中介紹了一種使用自然對抗情境生成解決方案，該解決方案採用自然的人類駕駛先驗和強化學習技術。透過這樣做，我們可以取得既多樣化又逼真的大規模測試情境。具體來說，我們建立了一個模擬環境，模擬了自然的交通互動情境。在這個環境的指導下，我們實施了一個兩階段程序。第一階段納入了傳統的基於規則的模型，例如 IDM（智慧駕駛模型）和 MOBIL（最小化換車道造成的整體煞車）模型，以粗略且離散的方式擷取和校準來自現實世界資料集的主要控制參數。接下來，我們利用 GAIL（生成對抗模仿學習）來持續表示駕駛行為。衍生的 GAIL 可進一步用於設計一個基於 PPO（近端策略最佳化）的動作-評論網路架構，以微調獎勵函數，然後最佳化我們的自然對抗情境生成解決方案。我們在 NGSIM 資料集中進行了廣泛的實驗，其中包括 3,000 輛車輛的軌跡。與基準模型相比，我們測量了重要的交通參數，例如碰撞率、加速度、轉向和換車道次數。我們的研究結果表明，所提出的模型可以生成涵蓋自然性和對抗性的逼真安全關鍵測試情境，這可能是開發自動駕駛車輛的基石。

##### **Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**
2408.03172v1 by Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi

With the surge in digital content in low-resource languages, there is an
escalating demand for advanced Natural Language Processing (NLP) techniques
tailored to these languages. BERT (Bidirectional Encoder Representations from
Transformers), serving as the foundational framework for numerous NLP
architectures and language models, is increasingly employed for the development
of low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method
for fine-tuning Large Language Models (LLMs) and reducing the training
parameters to some extent to decrease the computational costs needed for
training the model and achieve results comparable to a fully fine-tuned model.
In this work, we present a study of PEFT methods for the Indic low-resource
language Marathi. We conduct a comprehensive analysis of PEFT methods applied
to various monolingual and multilingual Marathi BERT models. These approaches
are evaluated on prominent text classification datasets like MahaSent,
MahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to
significantly expedite the training speed of the models, addressing a critical
aspect of model development and deployment. In this study, we explore Low-Rank
Adaptation of Large Language Models (LoRA) and adapter methods for low-resource
text classification. We show that these methods are competitive with full
fine-tuning and can be used without loss in accuracy. This study contributes
valuable insights into the effectiveness of Marathi BERT models, offering a
foundation for the continued advancement of NLP capabilities in Marathi and
similar Indic languages.

摘要：<paragraph>隨著低資源語言的數位內容激增，對於針對這些語言量身打造的先進自然語言處理 (NLP) 技術的需求也與日俱增。BERT（來自 Transformer 的雙向編碼器表示法）作為許多 NLP 架構和語言模型的基本架構，正日益用於開發低資源 NLP 模型。參數高效微調 (PEFT) 是一種微調大型語言模型 (LLM) 並在一定程度上減少訓練參數的方法，以降低訓練模型所需的運算成本，並獲得與完全微調模型相當的結果。在這項工作中，我們提出對印度低資源語言馬拉提語的 PEFT 方法進行研究。我們對應用於各種單語和多語馬拉提語 BERT 模型的 PEFT 方法進行了全面分析。這些方法在著名的文本分類資料集（例如 MahaSent、MahaHate 和 MahaNews）上進行評估。PEFT 技術的整合被證明可以顯著加快模型的訓練速度，解決了模型開發和部署的一個關鍵方面。在這項研究中，我們探討了大型語言模型 (LoRA) 的低秩適應和低資源文本分類的適配器方法。我們表明，這些方法與完全微調具有競爭力，並且可以在不損失準確性的情況下使用。這項研究對馬拉提語 BERT 模型的有效性提供了有價值的見解，為馬拉提語和類似印度語言的 NLP 能力持續進步奠定了基礎。</paragraph>

##### **Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**
2408.03168v1 by Elia Cereda, Alessandro Giusti, Daniele Palossi

Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning
(TinyML), such as nano-drones, are becoming an increasingly attractive
technology. Their small form factor (i.e., ~10cm diameter) ensures vast
applicability, ranging from the exploration of narrow disaster scenarios to
safe human-robot interaction. Simple electronics make these CPSes inexpensive,
but strongly limit the computational, memory, and sensing resources available
on board. In real-world applications, these limitations are further exacerbated
by domain shift. This fundamental machine learning problem implies that model
perception performance drops when moving from the training domain to a
different deployment one. To cope with and mitigate this general problem, we
present a novel on-device fine-tuning approach that relies only on the limited
ultra-low power resources available aboard nano-drones. Then, to overcome the
lack of ground-truth training labels aboard our CPS, we also employ a
self-supervised method based on ego-motion consistency. Albeit our work builds
on top of a specific real-world vision-based human pose estimation task, it is
widely applicable for many embedded TinyML use cases. Our 512-image on-device
training procedure is fully deployed aboard an ultra-low power GWT GAP9
System-on-Chip and requires only 1MB of memory while consuming as low as 19mW
or running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our
on-device learning approach by field-testing our closed-loop CPS, showing a
reduction in horizontal position error of up to 26% vs. a non-fine-tuned
state-of-the-art baseline. In the most challenging never-seen-before
environment, our on-device learning procedure makes the difference between
succeeding or failing the mission.

摘要：<paragraph>由微型機器學習（TinyML）驅動的微型化網際網路實體系統（CPS），例如奈米無人機，正成為越來越有吸引力的技術。它們的小外形（即直徑約 10 公分）確保了廣泛的適用性，從探索狹窄的災難場景到安全的人機互動。簡單的電子產品讓這些 CPS 價格低廉，但極大地限制了機載的運算、記憶體和感測資源。在實際應用中，這些限制因領域轉移而進一步惡化。這個基本的機器學習問題意味著，當從訓練領域轉移到不同的部署領域時，模型感知效能會下降。為了應對和減輕這個普遍問題，我們提出了一種新穎的裝置上微調方法，僅依賴於奈米無人機上可用的有限超低功率資源。然後，為了克服我們的 CPS 上缺乏地面真實訓練標籤，我們還採用了一種基於自我運動一致性的自監督方法。儘管我們的研究建立在具體的真實世界基於視覺的人體姿勢估計任務之上，但它廣泛適用於許多嵌入式 TinyML 使用案例。我們的 512 影像裝置上訓練程序完全部署在超低功率 GWT GAP9 晶片組上，只需要 1MB 的記憶體，同時消耗低至 19mW，或僅在 510ms（38mW）下執行。最後，我們透過實地測試我們的閉環 CPS 來展示我們的裝置上學習方法的優點，與非微調的最新基準相比，顯示水平位置誤差減少了 26%。在最具挑戰性的前所未見環境中，我們的裝置上學習程序在任務的成功或失敗之間產生了差異。</paragraph>

##### **Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**
2408.03164v1 by Rabih Chamas, Ismail Khalfaoui-Hassani, Timothee Masquelier

Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced
convolution method that allows enlarging the receptive fields (RF) without
increasing the number of parameters, like the dilated convolution, yet without
imposing a regular grid. DCLS has been shown to outperform the standard and
dilated convolutions on several computer vision benchmarks. Here, we show that,
in addition, DCLS increases the models' interpretability, defined as the
alignment with human visual strategies. To quantify it, we use the Spearman
correlation between the models' GradCAM heatmaps and the ClickMe dataset
heatmaps, which reflect human visual attention. We took eight reference models
- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and
36) - and drop-in replaced the standard convolution layers with DCLS ones. This
improved the interpretability score in seven of them. Moreover, we observed
that Grad-CAM generated random heatmaps for two models in our study: CAFormer
and ConvFormer models, leading to low interpretability scores. We addressed
this issue by introducing Threshold-Grad-CAM, a modification built on top of
Grad-CAM that enhanced interpretability across nearly all models. The code and
checkpoints to reproduce this study are available at:
https://github.com/rabihchamas/DCLS-GradCAM-Eval.

摘要：可學習間距擴展卷積 (DCLS) 是一種近期進階的卷積方法，允許擴展感受野 (RF)，而無須增加參數數量，就像擴展卷積一樣，但無須強制使用規則網格。已證實 DCLS 在多個電腦視覺基準上優於標準卷積和擴展卷積。在此，我們展示 DCLS 除了能提升模型的可詮釋性，定義為與人類視覺策略的一致性。為量化它，我們使用模型的 GradCAM 熱圖與 ClickMe 資料集熱圖之間的 Spearman 相關性，它反映了人類的視覺注意力。我們採用了八個參考模型 - ResNet50、ConvNeXt (T、S 和 B)、CAFormer、ConvFormer 和 FastViT (sa 24 和 36) - 並以 DCLS 取代標準卷積層。這提升了其中七個模型的可詮釋性分數。此外，我們觀察到 Grad-CAM 為我們研究中的兩個模型產生了隨機熱圖：CAFormer 和 ConvFormer 模型，導致可詮釋性分數低。我們透過引入 Threshold-Grad-CAM 來解決這個問題，這是一種建立在 Grad-CAM 之上的修改，可增強幾乎所有模型的可詮釋性。可於以下網址取得重現此研究的程式碼和檢查點：https://github.com/rabihchamas/DCLS-GradCAM-Eval。

##### **Conditioning LLMs with Emotion in Neural Machine Translation**
2408.03150v1 by Charles Brazier, Jean-Luc Rouas

Large Language Models (LLMs) have shown remarkable performance in Natural
Language Processing tasks, including Machine Translation (MT). In this work, we
propose a novel MT pipeline that integrates emotion information extracted from
a Speech Emotion Recognition (SER) model into LLMs to enhance translation
quality. We first fine-tune five existing LLMs on the Libri-trans dataset and
select the most performant model. Subsequently, we augment LLM prompts with
different dimensional emotions and train the selected LLM under these different
configurations. Our experiments reveal that integrating emotion information,
especially arousal, into LLM prompts leads to notable improvements in
translation quality.

摘要：大型語言模型 (LLM) 在自然語言處理任務，包括機器翻譯 (MT)，中展現出卓越的表現。在這項工作中，我們提出一個創新的 MT 管道，將從語音情緒辨識 (SER) 模型中提取的情緒資訊整合到 LLM 中，以提升翻譯品質。我們首先在 Libri-trans 資料集上微調五個現有的 LLM，並選出表現最佳的模型。接著，我們使用不同維度的情緒擴充 LLM 提示，並在這些不同的設定下訓練選定的 LLM。我們的實驗顯示，將情緒資訊，尤其是喚醒，整合到 LLM 提示中，會顯著提升翻譯品質。

##### **Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**
2408.03149v1 by Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen

The rapid increase in multimedia data has spurred advancements in Multimodal
Summarization with Multimodal Output (MSMO), which aims to produce a multimodal
summary that integrates both text and relevant images. The inherent
heterogeneity of content within multimodal inputs and outputs presents a
significant challenge to the execution of MSMO. Traditional approaches
typically adopt a holistic perspective on coarse image-text data or individual
visual objects, overlooking the essential connections between objects and the
entities they represent. To integrate the fine-grained entity knowledge, we
propose an Entity-Guided Multimodal Summarization model (EGMS). Our model,
building on BART, utilizes dual multimodal encoders with shared weights to
process text-image and entity-image information concurrently. A gating
mechanism then combines visual data for enhanced textual summary generation,
while image selection is refined through knowledge distillation from a
pre-trained vision-language model. Extensive experiments on public MSMO dataset
validate the superiority of the EGMS method, which also prove the necessity to
incorporate entity information into MSMO problem.

摘要：隨著多媒體資料的快速增加，刺激了多模態輸出多模態摘要 (MSMO) 的進展，其目標是產生一個整合文字和相關影像的多模態摘要。多模態輸入和輸出內在的異質性，對 MSMO 的執行構成重大挑戰。傳統方法通常採用整體觀點，針對粗略的影像文字資料或個別視覺物件，忽略了物件與其所代表實體之間的本質關聯性。為了整合細粒度的實體知識，我們提出一個實體引導式多模態摘要模型 (EGMS)。我們的模型建構在 BART 上，利用具有共享權重的雙重多模態編碼器，同時處理文字影像和實體影像資訊。一個閘控機制接著結合視覺資料，以增強文字摘要的生成，同時透過預先訓練的視覺語言模型的知識萃取，精煉影像選擇。在公開 MSMO 資料集上的廣泛實驗驗證了 EGMS 方法的優越性，也證明了將實體資訊納入 MSMO 問題的必要性。

##### **Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**
2408.03130v1 by Leo Donisch, Sigurd Schacht, Carsten Lanquillon

Large language models are ubiquitous in natural language processing because
they can adapt to new tasks without retraining. However, their sheer scale and
complexity present unique challenges and opportunities, prompting researchers
and practitioners to explore novel model training, optimization, and deployment
methods. This literature review focuses on various techniques for reducing
resource requirements and compressing large language models, including
quantization, pruning, knowledge distillation, and architectural optimizations.
The primary objective is to explore each method in-depth and highlight its
unique challenges and practical applications. The discussed methods are
categorized into a taxonomy that presents an overview of the optimization
landscape and helps navigate it to understand the research trajectory better.

摘要：大型語言模型在自然語言處理中無處不在，因為它們無需重新訓練即可適應新任務。然而，它們的規模和複雜性帶來了獨特的挑戰和機遇，促使研究人員和從業者探索新的模型訓練、最佳化和部署方法。這篇文獻回顧重點探討各種技術，以減少資源需求並壓縮大型語言模型，包括量化、剪枝、知識蒸餾和架構最佳化。主要目標是深入探討每種方法，並強調其獨特的挑戰和實際應用。所討論的方法被分類到一個分類法中，該分類法概述了最佳化領域，並有助於瀏覽它以更好地理解研究軌跡。

##### **Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**
2408.03127v1 by Artur Guimarães, Bruno Martins, João Magalhães

This paper describes our approach to the SemEval-2024 safe biomedical Natural
Language Inference for Clinical Trials (NLI4CT) task, which concerns
classifying statements about Clinical Trial Reports (CTRs). We explored the
capabilities of Mistral-7B, a generalist open-source Large Language Model
(LLM). We developed a prompt for the NLI4CT task, and fine-tuned a quantized
version of the model using an augmented version of the training dataset. The
experimental results show that this approach can produce notable results in
terms of the macro F1-score, while having limitations in terms of faithfulness
and consistency. All the developed code is publicly available on a GitHub
repository

摘要：本文描述了我們對 SemEval-2024 安全生物醫學自然語言推論臨床試驗 (NLI4CT) 任務的方法，該任務涉及對臨床試驗報告 (CTR) 中的陳述進行分類。我們探討了 Mistral-7B 的能力，這是一個通才的開源大型語言模型 (LLM)。我們為 NLI4CT 任務開發了一個提示，並使用訓練數據集的擴充版本對模型的量化版本進行了微調。實驗結果表明，這種方法在宏觀 F1 分數方面可以產生顯著的結果，同時在保真度和一致性方面存在局限性。所有已開發的代碼都公開發布在 GitHub 倉庫中

##### **COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**
2408.03125v1 by Rajvee Sheth, Shubh Nisar, Heenaben Prajapati, Himanshu Beniwal, Mayank Singh

As the NLP community increasingly addresses challenges associated with
multilingualism, robust annotation tools are essential to handle multilingual
datasets efficiently. In this paper, we introduce a code-mixed multilingual
text annotation framework, COMMENTATOR, specifically designed for annotating
code-mixed text. The tool demonstrates its effectiveness in token-level and
sentence-level language annotation tasks for Hinglish text. We perform robust
qualitative human-based evaluations to showcase COMMENTATOR led to 5x faster
annotations than the best baseline. Our code is publicly available at
\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is
available at \url{https://bit.ly/commentator_video}.

摘要：隨著 NLP 社群日益著重於因多語言性而面臨的挑戰，穩健的註解工具對於有效處理多語言資料集至關重要。在本文中，我們介紹了一個程式碼混合多語言文字註解架構 COMMENTATOR，專門設計用於註解程式碼混合文字。此工具展現其在 Hinglish 文字的詞元層級和句子層級語言註解任務中的效能。我們執行穩健的定性人工評估，以展示 COMMENTATOR 的註解速度比最佳基線快 5 倍。我們的程式碼已公開於 \url{https://github.com/lingo-iitgn/commentator}。示範影片可於 \url{https://bit.ly/commentator_video} 取得。

##### **Evaluating the Translation Performance of Large Language Models Based on Euas-20**
2408.03119v1 by Yan Huang, Wei Liu

In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.

摘要：近年來，隨著深度學習技術的快速發展，
BERT 和 GPT 等大型語言模型（LLM）在自然語言處理任務中取得了突破性的
成果。機器翻譯（MT）作為自然語言處理的核心任務之一，也受益於
大型語言模型的發展而取得了質的飛躍。儘管大型語言模型在翻譯性能上取得了顯著進展，
機器翻譯仍然面臨著諸多挑戰。因此，本文構建了 Euas-20 數據集，用於評估大型
語言模型在翻譯任務上的表現、不同語言的翻譯能力，以及預訓練數據對 LLM 翻譯能力的影響，供研究人員和開發人員使用。

##### **Topic Modeling with Fine-tuning LLMs and Bag of Sentences**
2408.03099v1 by Johannes Schneider

Large language models (LLM)'s are increasingly used for topic modeling
outperforming classical topic models such as LDA. Commonly, pre-trained LLM
encoders such as BERT are used out-of-the-box despite the fact that fine-tuning
is known to improve LLMs considerably. The challenge lies in obtaining a
suitable (labeled) dataset for fine-tuning. In this paper, we use the recent
idea to use bag of sentences as the elementary unit in computing topics. In
turn, we derive an approach FT-Topic to perform unsupervised fine-tuning
relying primarily on two steps for constructing a training dataset in an
automatic fashion. First, a heuristic method to identifies pairs of sentence
groups that are either assumed to be of the same or different topics. Second,
we remove sentence pairs that are likely labeled incorrectly. The dataset is
then used to fine-tune an encoder LLM, which can be leveraged by any topic
modeling approach using embeddings. However, in this work, we demonstrate its
effectiveness by deriving a novel state-of-the-art topic modeling method called
SenClu, which achieves fast inference through an expectation-maximization
algorithm and hard assignments of sentence groups to a single topic, while
giving users the possibility to encode prior knowledge on the topic-document
distribution. Code is at \url{https://github.com/JohnTailor/FT-Topic}

摘要：大型語言模型 (LLM) 愈來愈常被用於主題模型，其效能優於 LDA 等傳統主題模型。儘管微調已知能大幅改善 LLM，但通常會直接使用預先訓練好的 LLM 編碼器，例如 BERT。挑戰在於取得適合的（標籤）資料集以進行微調。在本文中，我們採用最近的想法，將句子組當作運算主題的基本單位。反過來，我們衍生出 FT-Topic 方法，以執行非監督式微調，主要依賴兩個步驟自動建構訓練資料集。首先，採用啟發式方法來識別假設為同主題或不同主題的句子組對。其次，我們移除標籤可能不正確的句子對。然後使用資料集微調編碼器 LLM，任何使用嵌入式的主題模型方法都能運用該編碼器。然而，我們在此工作中透過衍生出稱為 SenClu 的新式最先進主題模型方法，來證明其有效性。該方法透過期望值最大化演算法和句子組對單一主題的硬式指派，快速進行推論，同時讓使用者能夠對主題文件分布編碼先驗知識。程式碼位於 \url{https://github.com/JohnTailor/FT-Topic}

##### **500xCompressor: Generalized Prompt Compression for Large Language Models**
2408.03094v1 by Zongqian Li, Yixuan Su, Nigel Collier

Prompt compression is crucial for enhancing inference speed, reducing costs,
and improving user experience. However, current methods face challenges such as
low compression ratios and potential data leakage during evaluation. To address
these issues, we propose 500xCompressor, a method that compresses extensive
natural language contexts into a minimum of one single special token. The
500xCompressor introduces approximately 0.3% additional parameters and achieves
compression ratios ranging from 6x to 480x. It is designed to compress any
text, answer various types of questions, and could be utilized by the original
large language model (LLM) without requiring fine-tuning. Initially,
500xCompressor was pretrained on the Arxiv Corpus, followed by fine-tuning on
the ArxivQA dataset, and subsequently evaluated on strictly unseen and
classical question answering (QA) datasets. The results demonstrate that the
LLM retained 62.26-72.89% of its capabilities compared to using non-compressed
prompts. This study also shows that not all the compressed tokens are equally
utilized and that K V values have significant advantages over embeddings in
preserving information at high compression ratios. The highly compressive
nature of natural language prompts, even for fine-grained complex information,
suggests promising potential for future applications and further research into
developing a new LLM language.

摘要：提示壓縮對於提升推論速度、降低成本和改善使用者體驗至關重要。然而，目前的方法面臨低壓縮率和評估期間潛在資料外洩等挑戰。為了解決這些問題，我們提出 500xCompressor，這是一種將廣泛的自然語言脈絡壓縮成最少一個特殊符號的方法。500xCompressor 引入了約 0.3% 的額外參數，並達到了 6 倍到 480 倍的壓縮率。它被設計用於壓縮任何文字、回答各種類型的問題，並且可以在不需微調的情況下由原始的大語言模型 (LLM) 使用。最初，500xCompressor 在 Arxiv Corpus 上進行預訓練，然後在 ArxivQA 資料集上進行微調，最後在完全未見過和經典的問題解答 (QA) 資料集上進行評估。結果表明，與使用未壓縮提示相比，LLM 保留了 62.26-72.89% 的能力。這項研究還表明，並非所有壓縮的符號都得到平等利用，並且 K V 值在高壓縮率下比嵌入式更具備保留資訊的優勢。即使對於細緻複雜的資訊，自然語言提示的高度壓縮特性也顯示出未來應用和進一步研究開發新的 LLM 語言的潛力。

