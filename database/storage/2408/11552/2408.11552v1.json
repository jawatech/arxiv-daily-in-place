{"2408.11552": {"publish_time": "2024-08-21", "title": "Explainable Deep Learning Framework for Human Activity Recognition", "paper_summary": "In the realm of human activity recognition (HAR), the integration of\nexplainable Artificial Intelligence (XAI) emerges as a critical necessity to\nelucidate the decision-making processes of complex models, fostering\ntransparency and trust. Traditional explanatory methods like Class Activation\nMapping (CAM) and attention mechanisms, although effective in highlighting\nregions vital for decisions in various contexts, prove inadequate for HAR. This\ninadequacy stems from the inherently abstract nature of HAR data, rendering\nthese explanations obscure. In contrast, state-of-th-art post-hoc\ninterpretation techniques for time series can explain the model from other\nperspectives. However, this requires extra effort. It usually takes 10 to 20\nseconds to generate an explanation. To overcome these challenges, we proposes a\nnovel, model-agnostic framework that enhances both the interpretability and\nefficacy of HAR models through the strategic use of competitive data\naugmentation. This innovative approach does not rely on any particular model\narchitecture, thereby broadening its applicability across various HAR models.\nBy implementing competitive data augmentation, our framework provides intuitive\nand accessible explanations of model decisions, thereby significantly advancing\nthe interpretability of HAR systems without compromising on performance.", "paper_summary_zh": "\u5728\u4eba\u985e\u6d3b\u52d5\u8fa8\u8b58\uff08HAR\uff09\u9818\u57df\u4e2d\uff0c\u53ef\u89e3\u91cb\u4eba\u5de5\u667a\u6167\uff08XAI\uff09\u7684\u6574\u5408\u6210\u70ba\u95dc\u9375\u5fc5\u8981\u6027\uff0c\u7528\u65bc\u95e1\u660e\u8907\u96dc\u6a21\u578b\u7684\u6c7a\u7b56\u904e\u7a0b\uff0c\u4fc3\u9032\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002\u50b3\u7d71\u7684\u8aaa\u660e\u65b9\u6cd5\uff0c\u4f8b\u5982\u985e\u5225\u6fc0\u6d3b\u5c0d\u61c9\uff08CAM\uff09\u548c\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u96d6\u7136\u6709\u6548\u5730\u7a81\u986f\u5728\u5404\u7a2e\u60c5\u5883\u4e2d\u5c0d\u6c7a\u7b56\u81f3\u95dc\u91cd\u8981\u7684\u5340\u57df\uff0c\u4f46\u8b49\u660e\u4e0d\u9069\u7528\u65bc HAR\u3002\u9019\u7a2e\u4e0d\u9069\u7528\u6027\u6e90\u81ea\u65bc HAR \u8cc7\u6599\u672c\u8cea\u4e0a\u62bd\u8c61\uff0c\u5c0e\u81f4\u9019\u4e9b\u8aaa\u660e\u6a21\u7a1c\u5169\u53ef\u3002\u76f8\u53cd\u5730\uff0c\u6642\u9593\u5e8f\u5217\u7684\u6700\u65b0\u4e8b\u5f8c\u8a6e\u91cb\u6280\u8853\u53ef\u4ee5\u5f9e\u5176\u4ed6\u89c0\u9ede\u8aaa\u660e\u6a21\u578b\u3002\u7136\u800c\uff0c\u9019\u9700\u8981\u984d\u5916\u7684\u52aa\u529b\u3002\u901a\u5e38\u9700\u8981 10 \u5230 20 \u79d2\u624d\u80fd\u7522\u751f\u8aaa\u660e\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5275\u65b0\u7684\u3001\u8207\u6a21\u578b\u7121\u95dc\u7684\u67b6\u69cb\uff0c\u900f\u904e\u7b56\u7565\u6027\u5730\u4f7f\u7528\u7af6\u722d\u6027\u8cc7\u6599\u64f4\u5145\u4f86\u589e\u5f37 HAR \u6a21\u578b\u7684\u53ef\u8a6e\u91cb\u6027\u548c\u6548\u80fd\u3002\u9019\u7a2e\u5275\u65b0\u65b9\u6cd5\u4e0d\u4f9d\u8cf4\u4efb\u4f55\u7279\u5b9a\u7684\u6a21\u578b\u67b6\u69cb\uff0c\u5f9e\u800c\u64f4\u5c55\u5176\u5728\u5404\u7a2e HAR \u6a21\u578b\u4e2d\u7684\u9069\u7528\u6027\u3002\u900f\u904e\u5be6\u4f5c\u7af6\u722d\u6027\u8cc7\u6599\u64f4\u5145\uff0c\u6211\u5011\u7684\u67b6\u69cb\u63d0\u4f9b\u76f4\u89ba\u4e14\u5bb9\u6613\u7406\u89e3\u7684\u6a21\u578b\u6c7a\u7b56\u8aaa\u660e\uff0c\u5f9e\u800c\u5927\u5e45\u63d0\u5347 HAR \u7cfb\u7d71\u7684\u53ef\u8a6e\u91cb\u6027\uff0c\u540c\u6642\u4e0d\u640d\u53ca\u6548\u80fd\u3002", "author": "Yiran Huang et.al.", "authors": "Yiran Huang, Yexu Zhou, Haibin Zhao, Till Riedel, Michael Beigl", "id": "2408.11552v1", "paper_url": "http://arxiv.org/abs/2408.11552v1", "repo": "null"}}