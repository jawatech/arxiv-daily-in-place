{"2405.09673": {"publish_time": "2024-05-15", "title": "LoRA Learns Less and Forgets Less", "paper_summary": "Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning\nmethod for large language models. LoRA saves memory by training only low rank\nperturbations to selected weight matrices. In this work, we compare the\nperformance of LoRA and full finetuning on two target domains, programming and\nmathematics. We consider both the instruction finetuning ($\\approx$100K\nprompt-response pairs) and continued pretraining ($\\approx$10B unstructured\ntokens) data regimes. Our results show that, in most settings, LoRA\nsubstantially underperforms full finetuning. Nevertheless, LoRA exhibits a\ndesirable form of regularization: it better maintains the base model's\nperformance on tasks outside the target domain. We show that LoRA provides\nstronger regularization compared to common techniques such as weight decay and\ndropout; it also helps maintain more diverse generations. We show that full\nfinetuning learns perturbations with a rank that is 10-100X greater than\ntypical LoRA configurations, possibly explaining some of the reported gaps. We\nconclude by proposing best practices for finetuning with LoRA.", "paper_summary_zh": "\u4f4e\u79e9\u9069\u61c9 (LoRA) \u662f\u4e00\u7a2e\u5ee3\u6cdb\u4f7f\u7528\u7684\u53c3\u6578\u6709\u6548\u5fae\u8abf\u65b9\u6cd5\uff0c\u9069\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002LoRA \u50c5\u901a\u904e\u8a13\u7df4\u9078\u5b9a\u6b0a\u91cd\u77e9\u9663\u7684\u4f4e\u79e9\u64fe\u52d5\u4f86\u7bc0\u7701\u8a18\u61b6\u9ad4\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u6bd4\u8f03\u4e86 LoRA \u548c\u5b8c\u5168\u5fae\u8abf\u5728\u5169\u500b\u76ee\u6a19\u9818\u57df\uff08\u7a0b\u5f0f\u8a2d\u8a08\u548c\u6578\u5b78\uff09\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u540c\u6642\u8003\u616e\u4e86\u6307\u4ee4\u5fae\u8abf\uff08$\\approx$100K \u63d0\u793a\u56de\u61c9\u5c0d\uff09\u548c\u6301\u7e8c\u9810\u8a13\u7df4\uff08$\\approx$10B \u975e\u7d50\u69cb\u5316\u4ee3\u5e63\uff09\u8cc7\u6599\u6a21\u5f0f\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5728\u5927\u591a\u6578\u8a2d\u5b9a\u4e2d\uff0cLoRA \u7684\u6548\u80fd\u9060\u4f4e\u65bc\u5b8c\u5168\u5fae\u8abf\u3002\u5118\u7ba1\u5982\u6b64\uff0cLoRA \u5c55\u73fe\u4e86\u4e00\u7a2e\u7406\u60f3\u7684\u6b63\u5247\u5316\u5f62\u5f0f\uff1a\u5b83\u80fd\u66f4\u597d\u5730\u7dad\u6301\u57fa\u790e\u6a21\u578b\u5728\u76ee\u6a19\u9818\u57df\u4ee5\u5916\u4efb\u52d9\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u8b49\u660e\u8207\u6b0a\u91cd\u8870\u6e1b\u548c\u4e2d\u65b7\u7b49\u5e38\u898b\u6280\u8853\u76f8\u6bd4\uff0cLoRA \u63d0\u4f9b\u4e86\u66f4\u5f37\u5927\u7684\u6b63\u5247\u5316\uff1b\u5b83\u4e5f\u6709\u52a9\u65bc\u7dad\u6301\u66f4\u591a\u6a23\u5316\u7684\u751f\u6210\u3002\u6211\u5011\u8b49\u660e\u5b8c\u5168\u5fae\u8abf\u5b78\u7fd2\u5230\u7684\u64fe\u52d5\u79e9\u6bd4\u5178\u578b\u7684 LoRA \u7d44\u614b\u5927 10-100 \u500d\uff0c\u9019\u53ef\u80fd\u89e3\u91cb\u4e86\u4e00\u4e9b\u5831\u544a\u7684\u5dee\u8ddd\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4f7f\u7528 LoRA \u9032\u884c\u5fae\u8abf\u7684\u6700\u4f73\u5be6\u52d9\u3002", "author": "Dan Biderman et.al.", "authors": "Dan Biderman, Jose Gonzalez Ortiz, Jacob Portes, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, John P. Cunningham", "id": "2405.09673v1", "paper_url": "http://arxiv.org/abs/2405.09673v1", "repo": "null"}}