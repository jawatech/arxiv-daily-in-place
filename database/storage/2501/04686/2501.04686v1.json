{"2501.04686": {"publish_time": "2025-01-08", "title": "URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics", "paper_summary": "Chain-of-thought (CoT) reasoning has been widely applied in the mathematical\nreasoning of Large Language Models (LLMs). Recently, the introduction of\nderivative process supervision on CoT trajectories has sparked discussions on\nenhancing scaling capabilities during test time, thereby boosting the potential\nof these models. However, in multimodal mathematical reasoning, the scarcity of\nhigh-quality CoT training data has hindered existing models from achieving\nhigh-precision CoT reasoning and has limited the realization of reasoning\npotential during test time. In this work, we propose a three-module synthesis\nstrategy that integrates CoT distillation, trajectory-format rewriting, and\nformat unification. It results in a high-quality CoT reasoning instruction\nfine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively\nvalidate the state-of-the-art (SOTA) performance of the trained URSA-7B model\non multiple multimodal mathematical benchmarks. For test-time scaling, we\nintroduce a data synthesis strategy that automatically generates process\nannotation datasets, known as DualMath-1.1M, focusing on both interpretation\nand logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT\nreasoning capabilities to robust supervision abilities. The trained URSA-RM-7B\nacts as a verifier, effectively enhancing the performance of URSA-7B at test\ntime. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD)\nverifying capabilities, showcasing its generalization. Model weights, training\ndata and code will be open-sourced.", "paper_summary_zh": "<paragraph>\u93c8\u689d\u601d\u8003\uff08CoT\uff09\u63a8\u7406\u5df2\u5ee3\u6cdb\u61c9\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6578\u5b78\u63a8\u7406\u4e2d\u3002\u6700\u8fd1\uff0c\u5728 CoT \u8ecc\u8de1\u4e2d\u5f15\u5165\u5c0e\u6578\u904e\u7a0b\u76e3\u7763\uff0c\u5f15\u767c\u4e86\u95dc\u65bc\u5728\u6e2c\u8a66\u671f\u9593\u589e\u5f37\u898f\u6a21\u5316\u80fd\u529b\u7684\u8a0e\u8ad6\uff0c\u5f9e\u800c\u63d0\u5347\u4e86\u9019\u4e9b\u6a21\u578b\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u5728\u591a\u6a21\u614b\u6578\u5b78\u63a8\u7406\u4e2d\uff0c\u9ad8\u54c1\u8cea CoT \u8a13\u7df4\u8cc7\u6599\u7684\u7a00\u7f3a\u6027\u963b\u7919\u4e86\u73fe\u6709\u6a21\u578b\u5be6\u73fe\u9ad8\u7cbe\u5ea6\u7684 CoT \u63a8\u7406\uff0c\u4e26\u9650\u5236\u4e86\u5728\u6e2c\u8a66\u671f\u9593\u5be6\u73fe\u63a8\u7406\u6f5b\u529b\u7684\u53ef\u80fd\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u4e09\u6a21\u7d44\u5408\u6210\u7b56\u7565\uff0c\u5b83\u6574\u5408\u4e86 CoT \u84b8\u993e\u3001\u8ecc\u8de1\u683c\u5f0f\u91cd\u5beb\u548c\u683c\u5f0f\u7d71\u4e00\u3002\u5b83\u7522\u751f\u4e86\u4e00\u500b\u9ad8\u54c1\u8cea\u7684 CoT \u63a8\u7406\u6307\u4ee4\u5fae\u8abf\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u591a\u6a21\u614b\u6578\u5b78\uff0cMMathCoT-1M\u3002\u6211\u5011\u5168\u9762\u9a57\u8b49\u4e86\u8a13\u7df4\u5f8c\u7684 URSA-7B \u6a21\u578b\u5728\u591a\u500b\u591a\u6a21\u614b\u6578\u5b78\u57fa\u6e96\u4e0a\u7684\u6700\u65b0\u6280\u8853\uff08SOTA\uff09\u6548\u80fd\u3002\u5c0d\u65bc\u6e2c\u8a66\u6642\u9593\u7e2e\u653e\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u8cc7\u6599\u5408\u6210\u7b56\u7565\uff0c\u5b83\u81ea\u52d5\u7522\u751f\u904e\u7a0b\u8a3b\u89e3\u8cc7\u6599\u96c6\uff0c\u7a31\u70ba DualMath-1.1M\uff0c\u91cd\u9ede\u95dc\u6ce8\u89e3\u91cb\u548c\u908f\u8f2f\u3002\u901a\u904e\u9032\u4e00\u6b65\u8a13\u7df4 URSA-7B \u5728 DualMath-1.1M \u4e0a\uff0c\u6211\u5011\u5f9e CoT \u63a8\u7406\u80fd\u529b\u904e\u6e21\u5230\u5f37\u5927\u7684\u76e3\u7763\u80fd\u529b\u3002\u8a13\u7df4\u5f8c\u7684 URSA-RM-7B \u4f5c\u70ba\u9a57\u8b49\u5668\uff0c\u6709\u6548\u5730\u589e\u5f37\u4e86 URSA-7B \u5728\u6e2c\u8a66\u6642\u9593\u7684\u6548\u80fd\u3002URSA-RM-7B \u9084\u5c55\u793a\u4e86\u51fa\u8272\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u9a57\u8b49\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5b83\u7684\u6cdb\u5316\u6027\u3002\u6a21\u578b\u6b0a\u91cd\u3001\u8a13\u7df4\u8cc7\u6599\u548c\u7a0b\u5f0f\u78bc\u5c07\u6703\u958b\u6e90\u3002</paragraph>", "author": "Ruilin Luo et.al.", "authors": "Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang", "id": "2501.04686v1", "paper_url": "http://arxiv.org/abs/2501.04686v1", "repo": "null"}}