{"2407.14467": {"publish_time": "2024-07-19", "title": "Check-Eval: A Checklist-based Approach for Evaluating Text Quality", "paper_summary": "Evaluating the quality of text generated by large language models (LLMs)\nremains a significant challenge. Traditional metrics often fail to align well\nwith human judgments, particularly in tasks requiring creativity and nuance. In\nthis paper, we propose Check-Eval, a novel evaluation framework leveraging LLMs\nto assess the quality of generated text through a checklist-based approach.\nCheck-Eval can be employed as both a reference-free and reference-dependent\nevaluation method, providing a structured and interpretable assessment of text\nquality. The framework consists of two main stages: checklist generation and\nchecklist evaluation. We validate Check-Eval on two benchmark datasets:\nPortuguese Legal Semantic Textual Similarity and SummEval. Our results\ndemonstrate that Check-Eval achieves higher correlations with human judgments\ncompared to existing metrics, such as G-Eval and GPTScore, underscoring its\npotential as a more reliable and effective evaluation framework for natural\nlanguage generation tasks. The code for our experiments is available at\nhttps://anonymous.4open.science/r/check-eval-0DB4.", "paper_summary_zh": "\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u6240\u7522\u751f\u7684\u6587\u5b57\u54c1\u8cea\uff0c\u4f9d\u7136\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\u3002\u50b3\u7d71\u7684\u6307\u6a19\u5f80\u5f80\u7121\u6cd5\u8207\u4eba\u985e\u7684\u5224\u65b7\u6e96\u5247\u5c0d\u9f4a\uff0c\u7279\u5225\u662f\u5728\u9700\u8981\u5275\u610f\u548c\u7d30\u5fae\u5dee\u5225\u7684\u4efb\u52d9\u4e2d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Check-Eval\uff0c\u4e00\u500b\u5275\u65b0\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u5229\u7528 LLM \u900f\u904e\u57fa\u65bc\u6aa2\u67e5\u6e05\u55ae\u7684\u65b9\u6cd5\u4f86\u8a55\u4f30\u6240\u7522\u751f\u6587\u5b57\u7684\u54c1\u8cea\u3002Check-Eval \u53ef\u540c\u6642\u4f5c\u70ba\u7121\u53c3\u8003\u548c\u4f9d\u64da\u53c3\u8003\u7684\u8a55\u4f30\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5c0d\u6587\u5b57\u54c1\u8cea\u6709\u689d\u7406\u4e14\u53ef\u89e3\u91cb\u7684\u8a55\u4f30\u3002\u8a72\u67b6\u69cb\u5305\u542b\u5169\u500b\u4e3b\u8981\u968e\u6bb5\uff1a\u6aa2\u67e5\u6e05\u55ae\u7522\u751f\u548c\u6aa2\u67e5\u6e05\u55ae\u8a55\u4f30\u3002\u6211\u5011\u5728\u5169\u500b\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u9a57\u8b49 Check-Eval\uff1a\u8461\u8404\u7259\u8a9e\u6cd5\u5f8b\u8a9e\u7fa9\u6587\u5b57\u76f8\u4f3c\u5ea6\u548c SummEval\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u8207\u73fe\u6709\u7684\u6307\u6a19\uff08\u4f8b\u5982 G-Eval \u548c GPTScore\uff09\u76f8\u6bd4\uff0cCheck-Eval \u8207\u4eba\u985e\u5224\u65b7\u7684\u76f8\u95dc\u6027\u66f4\u9ad8\uff0c\u9019\u5f37\u8abf\u4e86\u5b83\u4f5c\u70ba\u81ea\u7136\u8a9e\u8a00\u7522\u751f\u4efb\u52d9\u66f4\u53ef\u9760\u4e14\u6709\u6548\u7684\u8a55\u4f30\u67b6\u69cb\u7684\u6f5b\u529b\u3002\u6211\u5011\u5be6\u9a57\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://anonymous.4open.science/r/check-eval-0DB4 \u53d6\u5f97\u3002", "author": "Jayr Pereira et.al.", "authors": "Jayr Pereira, Roberto Lotufo", "id": "2407.14467v1", "paper_url": "http://arxiv.org/abs/2407.14467v1", "repo": "null"}}