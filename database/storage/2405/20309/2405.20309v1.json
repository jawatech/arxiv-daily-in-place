{"2405.20309": {"publish_time": "2024-05-30", "title": "Large Language Models Can Self-Improve At Web Agent Tasks", "paper_summary": "Training models to act as agents that can effectively navigate and perform\nactions in a complex environment, such as a web browser, has typically been\nchallenging due to lack of training data. Large language models (LLMs) have\nrecently demonstrated some capability to navigate novel environments as agents\nin a zero-shot or few-shot fashion, purely guided by natural language\ninstructions as prompts. Recent research has also demonstrated LLMs have the\ncapability to exceed their base performance through self-improvement, i.e.\nfine-tuning on data generated by the model itself. In this work, we explore the\nextent to which LLMs can self-improve their performance as agents in\nlong-horizon tasks in a complex environment using the WebArena benchmark. In\nWebArena, an agent must autonomously navigate and perform actions on web pages\nto achieve a specified objective. We explore fine-tuning on three distinct\nsynthetic training data mixtures and achieve a 31\\% improvement in task\ncompletion rate over the base model on the WebArena benchmark through a\nself-improvement procedure. We additionally contribute novel evaluation metrics\nfor assessing the performance, robustness, capabilities, and quality of\ntrajectories of our fine-tuned agent models to a greater degree than simple,\naggregate-level benchmark scores currently used to measure self-improvement.", "paper_summary_zh": "<paragraph>\u8a13\u7df4\u6a21\u578b\u6210\u70ba\u4ee3\u7406\u4eba\uff0c\u5728\u8907\u96dc\u7684\u74b0\u5883\u4e2d\u6709\u6548\u5c0e\u822a\u4e26\u57f7\u884c\u52d5\u4f5c\uff0c\u4f8b\u5982\u7db2\u9801\u700f\u89bd\u5668\uff0c\u7531\u65bc\u7f3a\u4e4f\u8a13\u7df4\u8cc7\u6599\uff0c\u901a\u5e38\u5177\u6709\u6311\u6230\u6027\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6700\u8fd1\u5df2\u5c55\u793a\u51fa\u4e00\u4e9b\u80fd\u529b\uff0c\u53ef\u4f5c\u70ba\u4ee3\u7406\u4eba\u5728\u65b0\u7684\u74b0\u5883\u4e2d\u5c0e\u822a\uff0c\u4ee5\u96f6\u6b21\u5b78\u7fd2\u6216\u5c11\u6b21\u5b78\u7fd2\u7684\u65b9\u5f0f\uff0c\u7d14\u7cb9\u7531\u81ea\u7136\u8a9e\u8a00\u6307\u793a\u4f5c\u70ba\u63d0\u793a\u3002\u6700\u8fd1\u7684\u7814\u7a76\u4e5f\u8868\u660e\uff0cLLM \u6709\u80fd\u529b\u900f\u904e\u81ea\u6211\u63d0\u5347\u4f86\u8d85\u8d8a\u5176\u57fa\u672c\u6548\u80fd\uff0c\u5373\u5c0d\u6a21\u578b\u672c\u8eab\u7522\u751f\u7684\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u5728\u8907\u96dc\u74b0\u5883\u4e2d\u4f7f\u7528 WebArena \u57fa\u6e96\u4f5c\u70ba\u4ee3\u7406\u4eba\u5728\u9577\u671f\u4efb\u52d9\u4e2d\u81ea\u6211\u63d0\u5347\u5176\u6548\u80fd\u7684\u7a0b\u5ea6\u3002\u5728 WebArena \u4e2d\uff0c\u4ee3\u7406\u4eba\u5fc5\u9808\u81ea\u4e3b\u5c0e\u822a\u4e26\u5c0d\u7db2\u9801\u57f7\u884c\u52d5\u4f5c\uff0c\u4ee5\u9054\u6210\u6307\u5b9a\u76ee\u6a19\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u5c0d\u4e09\u7a2e\u4e0d\u540c\u7684\u5408\u6210\u8a13\u7df4\u8cc7\u6599\u6df7\u5408\u9032\u884c\u5fae\u8abf\uff0c\u4e26\u900f\u904e\u81ea\u6211\u63d0\u5347\u7a0b\u5e8f\u5728 WebArena \u57fa\u6e96\u4e0a\u5be6\u73fe\u4e86\u4efb\u52d9\u5b8c\u6210\u7387\u6bd4\u57fa\u790e\u6a21\u578b\u63d0\u5347 31%\u3002\u6b64\u5916\uff0c\u6211\u5011\u70ba\u8a55\u4f30\u5fae\u8abf\u4ee3\u7406\u4eba\u6a21\u578b\u7684\u6548\u80fd\u3001\u7a69\u5065\u6027\u3001\u80fd\u529b\u548c\u8ecc\u8de1\u54c1\u8cea\uff0c\u8ca2\u737b\u4e86\u65b0\u7a4e\u7684\u8a55\u4f30\u6307\u6a19\uff0c\u5176\u7a0b\u5ea6\u9060\u9ad8\u65bc\u76ee\u524d\u7528\u65bc\u8861\u91cf\u81ea\u6211\u63d0\u5347\u7684\u7c21\u55ae\u805a\u5408\u5c64\u7d1a\u57fa\u6e96\u5206\u6578\u3002</paragraph>", "author": "Ajay Patel et.al.", "authors": "Ajay Patel, Markus Hofmarcher, Claudiu Leoveanu-Condrei, Marius-Constantin Dinu, Chris Callison-Burch, Sepp Hochreiter", "id": "2405.20309v1", "paper_url": "http://arxiv.org/abs/2405.20309v1", "repo": "null"}}