{"2408.01415": {"publish_time": "2024-08-02", "title": "Conditional LoRA Parameter Generation", "paper_summary": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.", "paper_summary_zh": "\u751f\u6210\u5f0f\u6a21\u578b\u5728\u5f71\u50cf\u3001\u5f71\u7247\u548c\u6587\u5b57\u9818\u57df\u5df2\u53d6\u5f97\u986f\u8457\u7684\u6210\u529f\u3002\u53d7\u6b64\u555f\u767c\uff0c\u7814\u7a76\u4eba\u54e1\u5df2\u63a2\u8a0e\u5229\u7528\u751f\u6210\u5f0f\u6a21\u578b\u4f86\u7522\u751f\u795e\u7d93\u7db2\u8def\u53c3\u6578\u3002\u7136\u800c\uff0c\u9019\u4e9b\u52aa\u529b\u53d7\u5230\u53c3\u6578\u5927\u5c0f\u548c\u7522\u751f\u9ad8\u6027\u80fd\u53c3\u6578\u7684\u5be6\u7528\u6027\u7684\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa COND P-DIFF\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u53ef\u63a7\u9ad8\u6027\u80fd\u53c3\u6578\u7522\u751f\u7684\u53ef\u884c\u6027\uff0c\u7279\u5225\u662f\u5728\u5fae\u8abf\u904e\u7a0b\u4e2d\u91dd\u5c0d LoRA\uff08\u4f4e\u79e9\u9069\u61c9\uff09\u6b0a\u91cd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63a1\u7528\u81ea\u52d5\u7de8\u78bc\u5668\u4f86\u63d0\u53d6\u53c3\u6578\u7684\u6709\u6548\u6f5b\u5728\u8868\u793a\u3002\u7136\u5f8c\uff0c\u6211\u5011\u8a13\u7df4\u4e00\u500b\u689d\u4ef6\u6f5b\u5728\u64f4\u6563\u6a21\u578b\uff0c\u6839\u64da\u7279\u5b9a\u4efb\u52d9\u689d\u4ef6\u5f9e\u96a8\u6a5f\u96dc\u8a0a\u4e2d\u5408\u6210\u9ad8\u6027\u80fd\u6a21\u578b\u53c3\u6578\u3002\u96fb\u8166\u8996\u89ba\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\u7684\u5be6\u9a57\u7d50\u679c\u4e00\u81f4\u5730\u8b49\u660e\uff0cCOND P-DIFF \u53ef\u4ee5\u7522\u751f\u91dd\u5c0d\u7d66\u5b9a\u4efb\u52d9\u9032\u884c\u689d\u4ef6\u5316\u7684\u6548\u80fd\u53c3\u6578\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u8207\u900f\u904e\u4e00\u822c\u6700\u4f73\u5316\u65b9\u6cd5\u7372\u5f97\u7684\u5206\u5e03\u76f8\u6bd4\uff0cCOND P-DIFF \u751f\u6210\u7684\u53c3\u6578\u5206\u5e03\u5448\u73fe\u51fa\u5dee\u7570\uff0c\u8868\u793a\u5177\u6709\u4e00\u5b9a\u7a0b\u5ea6\u7684\u6982\u5316\u80fd\u529b\u3002\u6211\u5011\u7684\u7814\u7a76\u70ba\u689d\u4ef6\u9a45\u52d5\u53c3\u6578\u751f\u6210\u7684\u9032\u4e00\u6b65\u63a2\u7d22\u92ea\u5e73\u4e86\u9053\u8def\uff0c\u70ba\u795e\u7d93\u7db2\u8def\u7684\u4efb\u52d9\u7279\u5b9a\u9069\u61c9\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "author": "Xiaolong Jin et.al.", "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You", "id": "2408.01415v1", "paper_url": "http://arxiv.org/abs/2408.01415v1", "repo": "null"}}