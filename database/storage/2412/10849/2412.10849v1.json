{"2412.10849": {"publish_time": "2024-12-14", "title": "Superhuman performance of a large language model on the reasoning tasks of a physician", "paper_summary": "Performance of large language models (LLMs) on medical tasks has\ntraditionally been evaluated using multiple choice question benchmarks.\nHowever, such benchmarks are highly constrained, saturated with repeated\nimpressive performance by LLMs, and have an unclear relationship to performance\nin real clinical scenarios. Clinical reasoning, the process by which physicians\nemploy critical thinking to gather and synthesize clinical data to diagnose and\nmanage medical problems, remains an attractive benchmark for model performance.\nPrior LLMs have shown promise in outperforming clinicians in routine and\ncomplex diagnostic scenarios. We sought to evaluate OpenAI's o1-preview model,\na model developed to increase run-time via chain of thought processes prior to\ngenerating a response. We characterize the performance of o1-preview with five\nexperiments including differential diagnosis generation, display of diagnostic\nreasoning, triage differential diagnosis, probabilistic reasoning, and\nmanagement reasoning, adjudicated by physician experts with validated\npsychometrics. Our primary outcome was comparison of the o1-preview output to\nidentical prior experiments that have historical human controls and benchmarks\nof previous LLMs. Significant improvements were observed with differential\ndiagnosis generation and quality of diagnostic and management reasoning. No\nimprovements were observed with probabilistic reasoning or triage differential\ndiagnosis. This study highlights o1-preview's ability to perform strongly on\ntasks that require complex critical thinking such as diagnosis and management\nwhile its performance on probabilistic reasoning tasks was similar to past\nmodels. New robust benchmarks and scalable evaluation of LLM capabilities\ncompared to human physicians are needed along with trials evaluating AI in real\nclinical settings.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u91ab\u7642\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u901a\u5e38\u4f7f\u7528\u591a\u9078\u984c\u57fa\u6e96\u9032\u884c\u8a55\u4f30\u3002\u7136\u800c\uff0c\u6b64\u985e\u57fa\u6e96\u53d7\u5230\u9ad8\u5ea6\u9650\u5236\uff0c\u5145\u65a5\u8457 LLM \u91cd\u8907\u4e14\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8868\u73fe\uff0c\u4e14\u8207\u5be6\u969b\u81e8\u5e8a\u5834\u666f\u4e2d\u7684\u8868\u73fe\u95dc\u4fc2\u4e0d\u660e\u78ba\u3002\u81e8\u5e8a\u63a8\u7406\uff0c\u5373\u91ab\u5e2b\u904b\u7528\u6279\u5224\u6027\u601d\u8003\u6536\u96c6\u548c\u7d9c\u5408\u81e8\u5e8a\u8cc7\u6599\u4ee5\u8a3a\u65b7\u548c\u7ba1\u7406\u91ab\u7642\u554f\u984c\u7684\u904e\u7a0b\uff0c\u4ecd\u7136\u662f\u6a21\u578b\u8868\u73fe\u7684\u8a98\u4eba\u57fa\u6e96\u3002\u5148\u524d\u7684 LLM \u5df2\u5c55\u73fe\u51fa\u5728\u5e38\u898f\u548c\u8907\u96dc\u8a3a\u65b7\u5834\u666f\u4e2d\u512a\u65bc\u81e8\u5e8a\u91ab\u5e2b\u7684\u6f5b\u529b\u3002\u6211\u5011\u8a66\u5716\u8a55\u4f30 OpenAI \u7684 o1-preview \u6a21\u578b\uff0c\u9019\u662f\u4e00\u500b\u5728\u7522\u751f\u56de\u61c9\u4e4b\u524d\u900f\u904e\u601d\u8003\u904e\u7a0b\u93c8\u4f86\u589e\u52a0\u57f7\u884c\u6642\u9593\u7684\u6a21\u578b\u3002\u6211\u5011\u900f\u904e\u4e94\u9805\u5be6\u9a57\u4f86\u63cf\u8ff0 o1-preview \u7684\u8868\u73fe\uff0c\u5305\u62ec\u9451\u5225\u8a3a\u65b7\u7522\u751f\u3001\u8a3a\u65b7\u63a8\u7406\u986f\u793a\u3001\u5206\u6d41\u9451\u5225\u8a3a\u65b7\u3001\u6a5f\u7387\u63a8\u7406\u548c\u7ba1\u7406\u63a8\u7406\uff0c\u4e26\u7531\u7d93\u904e\u9a57\u8b49\u7684\u5fc3\u7406\u6e2c\u91cf\u5b78\u7684\u91ab\u5e2b\u5c08\u5bb6\u9032\u884c\u5224\u5b9a\u3002\u6211\u5011\u7684\u4e3b\u8981\u7d50\u679c\u662f\u5c07 o1-preview \u8f38\u51fa\u8207\u5177\u6709\u6b77\u53f2\u4eba\u985e\u63a7\u5236\u548c\u5148\u524d LLM \u57fa\u6e96\u7684\u76f8\u540c\u5148\u524d\u5be6\u9a57\u9032\u884c\u6bd4\u8f03\u3002\u5728\u9451\u5225\u8a3a\u65b7\u7522\u751f\u548c\u8a3a\u65b7\u548c\u7ba1\u7406\u63a8\u7406\u54c1\u8cea\u65b9\u9762\u89c0\u5bdf\u5230\u986f\u8457\u7684\u9032\u6b65\u3002\u5728\u6a5f\u7387\u63a8\u7406\u6216\u5206\u6d41\u9451\u5225\u8a3a\u65b7\u65b9\u9762\u6c92\u6709\u89c0\u5bdf\u5230\u9032\u6b65\u3002\u9019\u9805\u7814\u7a76\u7a81\u986f\u4e86 o1-preview \u5728\u57f7\u884c\u9700\u8981\u8907\u96dc\u6279\u5224\u6027\u601d\u8003\u7684\u4efb\u52d9\uff08\u4f8b\u5982\u8a3a\u65b7\u548c\u7ba1\u7406\uff09\u65b9\u9762\u7684\u5f37\u5927\u80fd\u529b\uff0c\u800c\u5b83\u5728\u6a5f\u7387\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u5247\u8207\u904e\u53bb\u7684\u6a21\u578b\u985e\u4f3c\u3002\u9700\u8981\u65b0\u7684\u7a69\u5065\u57fa\u6e96\u548c LLM \u80fd\u529b\u7684\u53ef\u64f4\u5145\u8a55\u4f30\uff0c\u8207\u4eba\u985e\u91ab\u5e2b\u9032\u884c\u6bd4\u8f03\uff0c\u4ee5\u53ca\u8a55\u4f30 AI \u5728\u5be6\u969b\u81e8\u5e8a\u74b0\u5883\u4e2d\u7684\u8a66\u9a57\u3002", "author": "Peter G. Brodeur et.al.", "authors": "Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman", "id": "2412.10849v1", "paper_url": "http://arxiv.org/abs/2412.10849v1", "repo": "null"}}