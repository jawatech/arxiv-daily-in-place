{"2405.01705": {"publish_time": "2024-05-02", "title": "Long Tail Image Generation Through Feature Space Augmentation and Iterated Learning", "paper_summary": "Image and multimodal machine learning tasks are very challenging to solve in\nthe case of poorly distributed data. In particular, data availability and\nprivacy restrictions exacerbate these hurdles in the medical domain. The state\nof the art in image generation quality is held by Latent Diffusion models,\nmaking them prime candidates for tackling this problem. However, a few key\nissues still need to be solved, such as the difficulty in generating data from\nunder-represented classes and a slow inference process. To mitigate these\nissues, we propose a new method for image augmentation in long-tailed data\nbased on leveraging the rich latent space of pre-trained Stable Diffusion\nModels. We create a modified separable latent space to mix head and tail class\nexamples. We build this space via Iterated Learning of underlying sparsified\nembeddings, which we apply to task-specific saliency maps via a K-NN approach.\nCode is available at\nhttps://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning", "paper_summary_zh": "", "author": "Rafael Elberg et.al.", "authors": "Rafael Elberg,Denis Parra,Mircea Petrache", "id": "2405.01705v1", "paper_url": "http://arxiv.org/abs/2405.01705v1", "repo": "https://github.com/sugarfreemanatee/feature-space-augmentation-and-iterated-learning"}}