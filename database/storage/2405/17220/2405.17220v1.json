{"2405.17220": {"publish_time": "2024-05-27", "title": "RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness", "paper_summary": "Learning from feedback reduces the hallucination of multimodal large language\nmodels (MLLMs) by aligning them with human preferences. While traditional\nmethods rely on labor-intensive and time-consuming manual labeling, recent\napproaches employing models as automatic labelers have shown promising results\nwithout human intervention. However, these methods heavily rely on costly\nproprietary models like GPT-4V, resulting in scalability issues. Moreover, this\nparadigm essentially distills the proprietary models to provide a temporary\nsolution to quickly bridge the performance gap. As this gap continues to\nshrink, the community is soon facing the essential challenge of aligning MLLMs\nusing labeler models of comparable capability. In this work, we introduce\nRLAIF-V, a novel framework that aligns MLLMs in a fully open-source paradigm\nfor super GPT-4V trustworthiness. RLAIF-V maximally exploits the open-source\nfeedback from two perspectives, including high-quality feedback data and online\nfeedback learning algorithm. Extensive experiments on seven benchmarks in both\nautomatic and human evaluation show that RLAIF-V substantially enhances the\ntrustworthiness of models without sacrificing performance on other tasks. Using\na 34B model as labeler, RLAIF-V 7B model reduces object hallucination by 82.9\\%\nand overall hallucination by 42.1\\%, outperforming the labeler model.\nRemarkably, RLAIF-V also reveals the self-alignment potential of open-source\nMLLMs, where a 12B model can learn from the feedback of itself to achieve less\nthan 29.5\\% overall hallucination rate, surpassing GPT-4V (45.9\\%) by a large\nmargin. The results shed light on a promising route to enhance the efficacy of\nleading-edge MLLMs.", "paper_summary_zh": "<paragraph>\u5f9e\u56de\u994b\u4e2d\u5b78\u7fd2\u53ef\u6e1b\u5c11\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u5e7b\u89ba\uff0c\u65b9\u6cd5\u662f\u8b93\u5b83\u5011\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u96d6\u7136\u50b3\u7d71\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u52de\u529b\u5bc6\u96c6\u4e14\u8017\u6642\u7684\u6a19\u7c64\u624b\u52d5\u6a19\u8a18\uff0c\u4f46\u6700\u8fd1\u63a1\u7528\u6a21\u578b\u4f5c\u70ba\u81ea\u52d5\u6a19\u7c64\u5668\u7684\u505a\u6cd5\u5df2\u986f\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7d50\u679c\uff0c\u800c\u7121\u9700\u4eba\u5de5\u5e72\u9810\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u56b4\u91cd\u4f9d\u8cf4\u65bc\u50cf GPT-4V \u9019\u6a23\u7684\u6602\u8cb4\u5c08\u6709\u6a21\u578b\uff0c\u5c0e\u81f4\u53ef\u64f4\u5145\u6027\u554f\u984c\u3002\u6b64\u5916\uff0c\u9019\u7a2e\u7bc4\u4f8b\u57fa\u672c\u4e0a\u6703\u7cbe\u7c21\u5c08\u6709\u6a21\u578b\uff0c\u4ee5\u63d0\u4f9b\u66ab\u6642\u89e3\u6c7a\u65b9\u6848\u4f86\u5feb\u901f\u7e2e\u5c0f\u6548\u80fd\u5dee\u8ddd\u3002\u96a8\u8457\u9019\u500b\u5dee\u8ddd\u6301\u7e8c\u7e2e\u5c0f\uff0c\u793e\u7fa4\u5f88\u5feb\u5c31\u6703\u9762\u81e8\u4f7f\u7528\u5177\u6709\u53ef\u6bd4\u80fd\u529b\u7684\u6a19\u7c64\u5668\u6a21\u578b\u4f86\u8abf\u6574 MLLM \u7684\u57fa\u672c\u6311\u6230\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 RLAIF-V\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u6846\u67b6\uff0c\u5b83\u5728\u4e00\u500b\u5b8c\u5168\u958b\u6e90\u7684\u7bc4\u4f8b\u4e2d\u8abf\u6574 MLLM\uff0c\u4ee5\u7372\u5f97\u8d85 GPT-4V \u7684\u53ef\u4fe1\u5ea6\u3002RLAIF-V \u5f9e\u5169\u500b\u89d2\u5ea6\u6700\u5927\u7a0b\u5ea6\u5730\u5229\u7528\u958b\u6e90\u56de\u994b\uff0c\u5305\u62ec\u9ad8\u54c1\u8cea\u56de\u994b\u8cc7\u6599\u548c\u7dda\u4e0a\u56de\u994b\u5b78\u7fd2\u6f14\u7b97\u6cd5\u3002\u5728\u81ea\u52d5\u548c\u4eba\u5de5\u8a55\u4f30\u4e2d\u5c0d\u4e03\u500b\u57fa\u6e96\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0cRLAIF-V \u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\uff0c\u800c\u4e0d\u6703\u72a7\u7272\u5176\u4ed6\u4efb\u52d9\u7684\u6548\u80fd\u3002\u4f7f\u7528 34B \u6a21\u578b\u4f5c\u70ba\u6a19\u7c64\u5668\uff0cRLAIF-V 7B \u6a21\u578b\u5c07\u7269\u4ef6\u5e7b\u89ba\u6e1b\u5c11\u4e86 82.9%\uff0c\u6574\u9ad4\u5e7b\u89ba\u6e1b\u5c11\u4e86 42.1%\uff0c\u8868\u73fe\u512a\u65bc\u6a19\u7c64\u5668\u6a21\u578b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cRLAIF-V \u4e5f\u63ed\u793a\u4e86\u958b\u6e90 MLLM \u7684\u81ea\u6211\u8abf\u6574\u6f5b\u529b\uff0c\u5176\u4e2d\u4e00\u500b 12B \u6a21\u578b\u53ef\u4ee5\u5f9e\u81ea\u8eab\u7684\u56de\u994b\u4e2d\u5b78\u7fd2\uff0c\u4ee5\u9054\u5230\u4f4e\u65bc 29.5% \u7684\u6574\u9ad4\u5e7b\u89ba\u7387\uff0c\u5927\u5e45\u8d85\u8d8a GPT-4V (45.9%)\u3002\u9019\u4e9b\u7d50\u679c\u70ba\u63d0\u5347\u9818\u5148 MLLM \u7684\u529f\u6548\u7167\u4eae\u4e86\u4e00\u689d\u6709\u5e0c\u671b\u7684\u9014\u5f91\u3002</paragraph>", "author": "Tianyu Yu et.al.", "authors": "Tianyu Yu, Haoye Zhang, Yuan Yao, Yunkai Dang, Da Chen, Xiaoman Lu, Ganqu Cui, Taiwen He, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun", "id": "2405.17220v1", "paper_url": "http://arxiv.org/abs/2405.17220v1", "repo": "https://github.com/rlhf-v/rlaif-v"}}