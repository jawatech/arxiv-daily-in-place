{"2410.06682": {"publish_time": "2024-10-09", "title": "Enhancing Multimodal LLM for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization", "paper_summary": "Videos contain a wealth of information, and generating detailed and accurate\ndescriptions in natural language is a key aspect of video understanding. In\nthis paper, we present video-SALMONN 2, an advanced audio-visual large language\nmodel (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with\npaired audio) captioning through directed preference optimization (DPO). We\npropose new metrics to evaluate the completeness and accuracy of video\ndescriptions, which are optimized using DPO. To further improve training, we\nintroduce a novel multi-round DPO (mrDPO) approach, which involves periodically\nupdating the DPO reference model, merging and re-initializing the LoRA module\nas a proxy for parameter updates after each training round (1,000 steps), and\nincorporating guidance from ground-truth video captions to stabilize the\nprocess. To address potential catastrophic forgetting of non-captioning\nabilities due to mrDPO, we propose rebirth tuning, which finetunes the pre-DPO\nLLM by using the captions generated by the mrDPO-trained model as supervised\nlabels. Experiments show that mrDPO significantly enhances video-SALMONN 2's\ncaptioning accuracy, reducing global and local error rates by 40\\% and 20\\%,\nrespectively, while decreasing the repetition rate by 35\\%. The final\nvideo-SALMONN 2 model, with just 7 billion parameters, surpasses leading models\nsuch as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining\ncompetitive performance to the state-of-the-art on widely used video\nquestion-answering benchmark among models of similar size. Upon acceptance, we\nwill release the code, model checkpoints, and training and test data. Demos are\navailable at\n\\href{https://video-salmonn-2.github.io}{https://video-salmonn-2.github.io}.", "paper_summary_zh": "\u5f71\u7247\u5305\u542b\u8c50\u5bcc\u7684\u8cc7\u8a0a\uff0c\u800c\u4ee5\u81ea\u7136\u8a9e\u8a00\u7522\u751f\u8a73\u7d30\u4e14\u6e96\u78ba\u7684\u63cf\u8ff0\u662f\u5f71\u7247\u7406\u89e3\u7684\u91cd\u8981\u9762\u5411\u3002\u5728\u9019\u7bc7\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa video-SALMONN 2\uff0c\u9019\u662f\u4e00\u500b\u9032\u968e\u7684\u97f3\u8a0a\u8996\u89ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u5177\u5099\u4f4e\u968e\u5c64\u6b21\u9069\u61c9 (LoRA)\uff0c\u5c08\u70ba\u900f\u904e\u5c0e\u5411\u504f\u597d\u6700\u4f73\u5316 (DPO) \u9032\u884c\u589e\u5f37\u5f71\u7247\uff08\u642d\u914d\u97f3\u8a0a\uff09\u5b57\u5e55\u7de8\u5beb\u800c\u8a2d\u8a08\u3002\u6211\u5011\u63d0\u51fa\u65b0\u7684\u6307\u6a19\u4f86\u8a55\u4f30\u5f71\u7247\u63cf\u8ff0\u7684\u5b8c\u6574\u6027\u548c\u6e96\u78ba\u6027\uff0c\u4e26\u4f7f\u7528 DPO \u9032\u884c\u6700\u4f73\u5316\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u6539\u5584\u8a13\u7df4\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u8f2a DPO (mrDPO) \u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u62ec\u5b9a\u671f\u66f4\u65b0 DPO \u53c3\u8003\u6a21\u578b\uff0c\u5728\u6bcf\u6b21\u8a13\u7df4\u8f2a\u6b21\uff081,000 \u6b65\u9a5f\uff09\u5f8c\u5408\u4f75\u4e26\u91cd\u65b0\u521d\u59cb\u5316 LoRA \u6a21\u7d44\u4f5c\u70ba\u53c3\u6578\u66f4\u65b0\u7684\u4ee3\u7406\uff0c\u4e26\u7d0d\u5165\u771f\u5be6\u5f71\u7247\u5b57\u5e55\u7684\u6307\u5c0e\uff0c\u4ee5\u7a69\u5b9a\u6b64\u7a0b\u5e8f\u3002\u70ba\u4e86\u89e3\u6c7a\u7531\u65bc mrDPO \u5c0e\u81f4\u975e\u5b57\u5e55\u7de8\u5beb\u80fd\u529b\u6f5b\u5728\u7684\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u6211\u5011\u63d0\u51fa\u91cd\u751f\u5fae\u8abf\uff0c\u5b83\u6703\u4f7f\u7528 mrDPO \u8a13\u7df4\u6a21\u578b\u7522\u751f\u7684\u5b57\u5e55\u4f5c\u70ba\u76e3\u7763\u6a19\u7c64\uff0c\u5c0d DPO \u524d\u7684 LLM \u9032\u884c\u5fae\u8abf\u3002\u5be6\u9a57\u986f\u793a\uff0cmrDPO \u5927\u5e45\u63d0\u5347 video-SALMONN 2 \u7684\u5b57\u5e55\u7de8\u5beb\u6e96\u78ba\u5ea6\uff0c\u5206\u5225\u964d\u4f4e\u4e86 40% \u548c 20% \u7684\u6574\u9ad4\u548c\u5c40\u90e8\u932f\u8aa4\u7387\uff0c\u540c\u6642\u5c07\u91cd\u8907\u7387\u964d\u4f4e\u4e86 35%\u3002\u6700\u7d42\u7684 video-SALMONN 2 \u6a21\u578b\u50c5\u6709 70 \u5104\u500b\u53c3\u6578\uff0c\u5728\u5f71\u7247\u5b57\u5e55\u7de8\u5beb\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4e86 GPT-4o \u548c Gemini-1.5-Pro \u7b49\u9818\u5148\u6a21\u578b\uff0c\u540c\u6642\u5728\u5ee3\u6cdb\u4f7f\u7528\u7684\u5f71\u7247\u554f\u7b54\u57fa\u6e96\u4e2d\uff0c\u7dad\u6301\u8207\u540c\u7b49\u898f\u6a21\u6a21\u578b\u7684\u6700\u65b0\u6280\u8853\u7af6\u722d\u529b\u3002\u5728\u7372\u63a5\u53d7\u5f8c\uff0c\u6211\u5011\u5c07\u91cb\u51fa\u7a0b\u5f0f\u78bc\u3001\u6a21\u578b\u6aa2\u67e5\u9ede\uff0c\u4ee5\u53ca\u8a13\u7df4\u548c\u6e2c\u8a66\u8cc7\u6599\u3002\u5c55\u793a\u53ef\u898b\u65bc\n\\href{https://video-salmonn-2.github.io}{https://video-salmonn-2.github.io}\u3002", "author": "Changli Tang et.al.", "authors": "Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zujun Ma, Chao Zhang", "id": "2410.06682v1", "paper_url": "http://arxiv.org/abs/2410.06682v1", "repo": "null"}}