{"2406.02057": {"publish_time": "2024-06-04", "title": "Tabular and Deep Learning for the Whittle Index", "paper_summary": "The Whittle index policy is a heuristic that has shown remarkably good\nperformance (with guaranteed asymptotic optimality) when applied to the class\nof problems known as Restless Multi-Armed Bandit Problems (RMABPs). In this\npaper we present QWI and QWINN, two reinforcement learning algorithms,\nrespectively tabular and deep, to learn the Whittle index for the total\ndiscounted criterion. The key feature is the use of two time-scales, a faster\none to update the state-action Q -values, and a relatively slower one to update\nthe Whittle indices. In our main theoretical result we show that QWI, which is\na tabular implementation, converges to the real Whittle indices. We then\npresent QWINN, an adaptation of QWI algorithm using neural networks to compute\nthe Q -values on the faster time-scale, which is able to extrapolate\ninformation from one state to another and scales naturally to large state-space\nenvironments. For QWINN, we show that all local minima of the Bellman error are\nlocally stable equilibria, which is the first result of its kind for DQN-based\nschemes. Numerical computations show that QWI and QWINN converge faster than\nthe standard Q -learning algorithm, neural-network based approximate Q-learning\nand other state of the art algorithms.", "paper_summary_zh": "\u60e0\u7279\u723e\u6307\u6578\u653f\u7b56\u662f\u4e00\u7a2e\u555f\u767c\u6cd5\uff0c\u5728\u61c9\u7528\u65bc\u7a31\u70ba\u4e0d\u5b89\u591a\u81c2\u8ced\u5f92\u554f\u984c (RMABP) \u7684\u554f\u984c\u985e\u578b\u6642\uff0c\u5df2\u5c55\u73fe\u51fa\u6975\u4f73\u7684\u8868\u73fe\uff08\u6709\u4fdd\u8b49\u7684\u6f38\u8fd1\u6700\u512a\u6027\uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa QWI \u548c QWINN\uff0c\u9019\u5169\u7a2e\u5206\u5225\u70ba\u8868\u683c\u548c\u6df1\u5ea6\u589e\u5f37\u5b78\u7fd2\u6f14\u7b97\u6cd5\uff0c\u7528\u65bc\u5b78\u7fd2\u7e3d\u6298\u73fe\u6e96\u5247\u7684\u60e0\u7279\u723e\u6307\u6578\u3002\u5176\u95dc\u9375\u7279\u5fb5\u662f\u4f7f\u7528\u5169\u500b\u6642\u9593\u5c3a\u5ea6\uff0c\u4e00\u500b\u8f03\u5feb\u7684\u6642\u9593\u5c3a\u5ea6\u7528\u65bc\u66f4\u65b0\u72c0\u614b\u52d5\u4f5c Q \u503c\uff0c\u53e6\u4e00\u500b\u8f03\u6162\u7684\u6642\u9593\u5c3a\u5ea6\u7528\u65bc\u66f4\u65b0\u60e0\u7279\u723e\u6307\u6578\u3002\u5728\u6211\u5011\u7684\u4e3b\u8981\u7406\u8ad6\u7d50\u679c\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u8868\u683c\u5be6\u4f5c\u7684 QWI \u6703\u6536\u6582\u5230\u771f\u6b63\u7684\u60e0\u7279\u723e\u6307\u6578\u3002\u63a5\u8457\uff0c\u6211\u5011\u63d0\u51fa QWINN\uff0c\u4e00\u7a2e\u4f7f\u7528\u795e\u7d93\u7db2\u8def\u8a08\u7b97\u8f03\u5feb\u6642\u9593\u5c3a\u5ea6\u4e0a Q \u503c\u7684 QWI \u6f14\u7b97\u6cd5\u6539\u7de8\uff0c\u5b83\u80fd\u5920\u5f9e\u4e00\u500b\u72c0\u614b\u63a8\u65b7\u5230\u53e6\u4e00\u500b\u72c0\u614b\uff0c\u4e26\u81ea\u7136\u5730\u64f4\u5c55\u5230\u5927\u578b\u72c0\u614b\u7a7a\u9593\u74b0\u5883\u3002\u5c0d\u65bc QWINN\uff0c\u6211\u5011\u5c55\u793a\u4e86\u8c9d\u723e\u66fc\u8aa4\u5dee\u7684\u6240\u6709\u5c40\u90e8\u6700\u5c0f\u503c\u90fd\u662f\u5c40\u90e8\u7a69\u5b9a\u5747\u8861\uff0c\u9019\u662f\u57fa\u65bc DQN \u7684\u67b6\u69cb\u9996\u6b21\u51fa\u73fe\u7684\u6b64\u985e\u7d50\u679c\u3002\u6578\u503c\u904b\u7b97\u986f\u793a\uff0cQWI \u548c QWINN \u7684\u6536\u6582\u901f\u5ea6\u6bd4\u6a19\u6e96 Q \u5b78\u7fd2\u6f14\u7b97\u6cd5\u3001\u57fa\u65bc\u795e\u7d93\u7db2\u8def\u7684\u8fd1\u4f3c Q \u5b78\u7fd2\u548c\u5176\u4ed6\u6700\u5148\u9032\u7684\u6f14\u7b97\u6cd5\u5feb\u3002", "author": "Francisco Robledo Rela\u00f1o et.al.", "authors": "Francisco Robledo Rela\u00f1o, Vivek Borkar, Urtzi Ayesta, Konstantin Avrachenkov", "id": "2406.02057v1", "paper_url": "http://arxiv.org/abs/2406.02057v1", "repo": "null"}}