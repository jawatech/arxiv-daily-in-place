{"2410.11502": {"publish_time": "2024-10-15", "title": "Offline Model-Based Optimization by Learning to Rank", "paper_summary": "Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.", "paper_summary_zh": "<paragraph>\u96e2\u7dda\u6a21\u578b\u57fa\u790e\u6700\u4f73\u5316 (MBO) \u7684\u76ee\u6a19\u662f\u627e\u51fa\u4e00\u500b\u8a2d\u8a08\uff0c\u4f7f\u7528\u50c5\u6709\u56fa\u5b9a\u9810\u5148\u6536\u96c6\u7684\u8a2d\u8a08\u8cc7\u6599\u96c6\u53ca\u5176\u5c0d\u61c9\u5206\u6578\uff0c\u6700\u5927\u5316\u9ed1\u76d2\u51fd\u6578\u3002\u96e2\u7dda MBO \u7684\u5e38\u898b\u65b9\u6cd5\u662f\u900f\u904e\u6700\u5c0f\u5316\u5747\u65b9\u8aa4\u5dee (MSE) \u4f86\u8a13\u7df4\u56de\u6b78\u57fa\u790e\u4ee3\u7406\u6a21\u578b\uff0c\u7136\u5f8c\u5728\u9019\u500b\u4ee3\u7406\u6a21\u578b\u4e2d\u900f\u904e\u4e0d\u540c\u7684\u6700\u4f73\u5316\u5668 (\u4f8b\u5982\uff0c\u68af\u5ea6\u4e0a\u5347) \u627e\u51fa\u6700\u4f73\u8a2d\u8a08\u3002\u7136\u800c\uff0c\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\u662f\u5206\u4f48\u5916\u8aa4\u5dee\u7684\u98a8\u96aa\uff0c\u4e5f\u5c31\u662f\u8aaa\uff0c\u4ee3\u7406\u6a21\u578b\u901a\u5e38\u6703\u9ad8\u4f30\u5206\u6578\uff0c\u4e26\u8aa4\u5c0e\u6700\u4f73\u5316\u5668\u9032\u5165\u6b21\u4f73\u5340\u57df\u3002\u5148\u524d\u7684\u7814\u7a76\u5617\u8a66\u4f7f\u7528\u5404\u7a2e\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u4f8b\u5982\u4f7f\u7528\u6b63\u5247\u5316\u6280\u8853\u548c\u6574\u9ad4\u5b78\u7fd2\u4f86\u589e\u5f37\u6a21\u578b\u7684\u7a69\u5065\u6027\uff0c\u4f46\u554f\u984c\u4ecd\u7136\u5b58\u5728\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4e3b\u5f35\u4f7f\u7528 MSE \u8a13\u7df4\u7684\u56de\u6b78\u6a21\u578b\u8207\u96e2\u7dda MBO \u7684\u4e3b\u8981\u76ee\u6a19\u4e0d\u4e00\u81f4\uff0c\u96e2\u7dda MBO \u7684\u76ee\u6a19\u662f\u9078\u64c7\u6709\u524d\u666f\u7684\u8a2d\u8a08\uff0c\u800c\u4e0d\u662f\u7cbe\u78ba\u9810\u6e2c\u5176\u5206\u6578\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5982\u679c\u4ee3\u7406\u6a21\u578b\u53ef\u4ee5\u6839\u64da\u5019\u9078\u8a2d\u8a08\u7684\u76f8\u5c0d\u5206\u6578\u95dc\u4fc2\u4f86\u7dad\u6301\u9806\u5e8f\uff0c\u5b83\u751a\u81f3\u53ef\u4ee5\u5728\u6c92\u6709\u7cbe\u78ba\u9810\u6e2c\u7684\u60c5\u6cc1\u4e0b\u7522\u751f\u6700\u4f73\u8a2d\u8a08\u3002\u70ba\u4e86\u9a57\u8b49\u9019\u4e00\u9ede\uff0c\u6211\u5011\u9032\u884c\u5be6\u9a57\u4f86\u6bd4\u8f03\u6700\u7d42\u8a2d\u8a08\u7684\u54c1\u8cea\u548c MSE \u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u767c\u73fe\u76f8\u95dc\u6027\u975e\u5e38\u4f4e\u3002\u76f8\u53cd\u5730\uff0c\u4e00\u500b\u8861\u91cf\u9806\u5e8f\u7dad\u6301\u54c1\u8cea\u7684\u6307\u6a19\u986f\u793a\u51fa\u986f\u8457\u66f4\u5f37\u7684\u76f8\u95dc\u6027\u3002\u6839\u64da\u9019\u500b\u89c0\u5bdf\uff0c\u6211\u5011\u5efa\u8b70\u5b78\u7fd2\u4e00\u500b\u6392\u540d\u57fa\u790e\u6a21\u578b\uff0c\u5229\u7528\u5b78\u7fd2\u6392\u540d\u6280\u8853\u6839\u64da\u76f8\u5c0d\u5206\u6578\u4f86\u512a\u5148\u8003\u616e\u6709\u524d\u666f\u7684\u8a2d\u8a08\u3002\u6211\u5011\u5c55\u793a\u4e86\u6392\u540d\u640d\u5931\u7684\u6cdb\u5316\u8aa4\u5dee\u53ef\u4ee5\u5f97\u5230\u5f88\u597d\u7684\u7d04\u675f\u3002\u5728\u4e0d\u540c\u4efb\u52d9\u4e2d\u7684\u7d93\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u63d0\u51fa\u7684\u6392\u540d\u57fa\u790e\u6a21\u578b\u6bd4\u73fe\u6709\u7684\u4e8c\u5341\u7a2e\u65b9\u6cd5\u5177\u6709\u66f4\u512a\u7570\u7684\u6548\u80fd\u3002</paragraph>", "author": "Rong-Xi Tan et.al.", "authors": "Rong-Xi Tan, Ke Xue, Shen-Huan Lyu, Haopu Shang, Yao Wang, Yaoyuan Wang, Sheng Fu, Chao Qian", "id": "2410.11502v1", "paper_url": "http://arxiv.org/abs/2410.11502v1", "repo": "null"}}