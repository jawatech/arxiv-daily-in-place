{"2406.10149": {"publish_time": "2024-06-14", "title": "BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack", "paper_summary": "In recent years, the input context sizes of large language models (LLMs) have\nincreased dramatically. However, existing evaluation methods have not kept\npace, failing to comprehensively assess the efficiency of models in handling\nlong contexts. To bridge this gap, we introduce the BABILong benchmark,\ndesigned to test language models' ability to reason across facts distributed in\nextremely long documents. BABILong includes a diverse set of 20 reasoning\ntasks, including fact chaining, simple induction, deduction, counting, and\nhandling lists/sets. These tasks are challenging on their own, and even more\ndemanding when the required facts are scattered across long natural text. Our\nevaluations show that popular LLMs effectively utilize only 10-20\\% of the\ncontext and their performance declines sharply with increased reasoning\ncomplexity. Among alternatives to in-context reasoning, Retrieval-Augmented\nGeneration methods achieve a modest 60\\% accuracy on single-fact question\nanswering, independent of context length. Among context extension methods, the\nhighest performance is demonstrated by recurrent memory transformers, enabling\nthe processing of lengths up to 11 million tokens. The BABILong benchmark is\nextendable to any length to support the evaluation of new upcoming models with\nincreased capabilities, and we provide splits up to 1 million token lengths.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8f93\u5165\u4e0a\u4e0b\u6587\u5927\u5c0f\u5df2\u5927\u5e45\u589e\u52a0\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u5e76\u672a\u8ddf\u4e0a\u6b65\u4f10\uff0c\u672a\u80fd\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u6548\u7387\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86 BABILong \u57fa\u51c6\uff0c\u65e8\u5728\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u5728\u6781\u957f\u6587\u6863\u4e2d\u5206\u5e03\u7684\u4e8b\u5b9e\u4e2d\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002BABILong \u5305\u542b 20 \u9879\u4e0d\u540c\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u5305\u62ec\u4e8b\u5b9e\u94fe\u63a5\u3001\u7b80\u5355\u5f52\u7eb3\u3001\u6f14\u7ece\u3001\u8ba1\u6570\u4ee5\u53ca\u5904\u7406\u5217\u8868/\u96c6\u5408\u3002\u8fd9\u4e9b\u4efb\u52a1\u672c\u8eab\u5177\u6709\u6311\u6218\u6027\uff0c\u5f53\u6240\u9700\u7684\u4e8b\u5b9e\u5206\u6563\u5728\u5f88\u957f\u7684\u81ea\u7136\u6587\u672c\u4e2d\u65f6\uff0c\u96be\u5ea6\u66f4\u5927\u3002\u6211\u4eec\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6d41\u884c\u7684 LLM \u5b9e\u9645\u4e0a\u53ea\u5229\u7528\u4e86 10-20% \u7684\u4e0a\u4e0b\u6587\uff0c\u5e76\u4e14\u5b83\u4eec\u7684\u6027\u80fd\u968f\u7740\u63a8\u7406\u590d\u6742\u6027\u7684\u589e\u52a0\u800c\u6025\u5267\u4e0b\u964d\u3002\u5728\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u66ff\u4ee3\u65b9\u6848\u4e2d\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u5355\u4e8b\u5b9e\u95ee\u9898\u89e3\u7b54\u4e2d\u5b9e\u73b0\u4e86 60% \u7684\u9002\u5ea6\u51c6\u786e\u7387\uff0c\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u65e0\u5173\u3002\u5728\u4e0a\u4e0b\u6587\u6269\u5c55\u65b9\u6cd5\u4e2d\uff0c\u5faa\u73af\u8bb0\u5fc6\u8f6c\u6362\u5668\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u6027\u80fd\uff0c\u80fd\u591f\u5904\u7406\u957f\u8fbe 1100 \u4e07\u4e2a\u6807\u8bb0\u7684\u957f\u5ea6\u3002BABILong \u57fa\u51c6\u53ef\u4ee5\u6269\u5c55\u5230\u4efb\u4f55\u957f\u5ea6\uff0c\u4ee5\u652f\u6301\u8bc4\u4f30\u5177\u6709\u66f4\u591a\u529f\u80fd\u7684\u65b0\u5174\u6a21\u578b\uff0c\u5e76\u4e14\u6211\u4eec\u63d0\u4f9b\u4e86\u957f\u8fbe 100 \u4e07\u4e2a\u6807\u8bb0\u957f\u5ea6\u7684\u62c6\u5206\u3002", "author": "Yuri Kuratov et.al.", "authors": "Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Ivan Rodkin, Dmitry Sorokin, Artyom Sorokin, Mikhail Burtsev", "id": "2406.10149v1", "paper_url": "http://arxiv.org/abs/2406.10149v1", "repo": "null"}}