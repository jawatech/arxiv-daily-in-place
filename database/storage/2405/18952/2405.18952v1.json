{"2405.18952": {"publish_time": "2024-05-29", "title": "Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets", "paper_summary": "Training Large Language Models (LLMs) with Reinforcement Learning from AI\nFeedback (RLAIF) aligns model outputs more closely with human preferences. This\ninvolves an evaluator model ranking multiple candidate responses to user\nprompts. However, the rankings from popular evaluator models such as GPT-4 can\nbe inconsistent. We propose the Repeat Ranking method - where we evaluate the\nsame responses multiple times and train only on those responses which are\nconsistently ranked. Using 2,714 prompts in 62 languages, we generated\nresponses from 7 top multilingual LLMs and had GPT-4 rank them five times each.\nEvaluating on MT-Bench chat benchmarks in six languages, our method\noutperformed the standard practice of training on all available prompts. Our\nwork highlights the quality versus quantity trade-off in RLAIF dataset\ngeneration and offers a stackable strategy for enhancing dataset and thus model\nquality.", "paper_summary_zh": "\u4f7f\u7528\u4f86\u81ea AI \u7684\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff08RLAIF\uff09\u53ef\u8b93\u6a21\u578b\u8f38\u51fa\u8207\u4eba\u985e\u504f\u597d\u66f4\u70ba\u4e00\u81f4\u3002\u9019\u6d89\u53ca\u8a55\u4f30\u6a21\u578b\u5c0d\u4f7f\u7528\u8005\u63d0\u793a\u7684\u6392\u540d\uff0c\u5176\u4e2d\u6709\u591a\u500b\u5019\u9078\u56de\u61c9\u3002\u7136\u800c\uff0c\u4f86\u81ea\u71b1\u9580\u8a55\u4f30\u6a21\u578b\uff08\u4f8b\u5982 GPT-4\uff09\u7684\u6392\u540d\u53ef\u80fd\u4e0d\u4e00\u81f4\u3002\u6211\u5011\u63d0\u51fa\u91cd\u8907\u6392\u540d\u65b9\u6cd5\uff0c\u5176\u4e2d\u6211\u5011\u5c0d\u76f8\u540c\u7684\u56de\u61c9\u9032\u884c\u591a\u6b21\u8a55\u4f30\uff0c\u4e26\u53ea\u91dd\u5c0d\u6301\u7e8c\u6392\u540d\u7684\u56de\u61c9\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u5728 62 \u7a2e\u8a9e\u8a00\u4e2d\u4f7f\u7528 2,714 \u500b\u63d0\u793a\uff0c\u5f9e 7 \u500b\u9802\u5c16\u591a\u8a9e\u8a00 LLM \u4e2d\u7522\u751f\u56de\u61c9\uff0c\u4e26\u8b93 GPT-4 \u5c0d\u6bcf\u500b\u56de\u61c9\u9032\u884c\u4e94\u6b21\u6392\u540d\u3002\u5728\u516d\u7a2e\u8a9e\u8a00\u7684 MT-Bench \u804a\u5929\u57fa\u6e96\u4e2d\u9032\u884c\u8a55\u4f30\uff0c\u6211\u5011\u7684\u505a\u6cd5\u512a\u65bc\u5728\u6240\u6709\u53ef\u7528\u63d0\u793a\u4e0a\u9032\u884c\u8a13\u7df4\u7684\u6a19\u6e96\u505a\u6cd5\u3002\u6211\u5011\u7684\u7814\u7a76\u91cd\u9ede\u5728\u65bc RLAIF \u8cc7\u6599\u96c6\u751f\u6210\u4e2d\u54c1\u8cea\u8207\u6578\u91cf\u7684\u6b0a\u8861\uff0c\u4e26\u63d0\u4f9b\u53ef\u5806\u758a\u7684\u7b56\u7565\u4f86\u589e\u5f37\u8cc7\u6599\u96c6\uff0c\u9032\u800c\u63d0\u5347\u6a21\u578b\u54c1\u8cea\u3002", "author": "Peter Devine et.al.", "authors": "Peter Devine", "id": "2405.18952v1", "paper_url": "http://arxiv.org/abs/2405.18952v1", "repo": "null"}}