{"2501.07824": {"publish_time": "2025-01-14", "title": "Real-time Verification and Refinement of Language Model Text Generation", "paper_summary": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of natural language tasks. However, a critical challenge remains in that\nthey sometimes generate factually incorrect answers. To address this, while\nmany previous work has focused on identifying errors in their generation and\nfurther refining them, they are slow in deployment since they are designed to\nverify the response from LLMs only after their entire generation (from the\nfirst to last tokens) is done. Further, we observe that once LLMs generate\nincorrect tokens early on, there is a higher likelihood that subsequent tokens\nwill also be factually incorrect. To this end, in this work, we propose\nStreaming-VR (Streaming Verification and Refinement), a novel approach designed\nto enhance the efficiency of verification and refinement of LLM outputs.\nSpecifically, the proposed Streaming-VR enables on-the-fly verification and\ncorrection of tokens as they are being generated, similar to a streaming\nprocess, ensuring that each subset of tokens is checked and refined in\nreal-time by another LLM as the LLM constructs its response. Through\ncomprehensive evaluations on multiple datasets, we demonstrate that our\napproach not only enhances the factual accuracy of LLMs, but also offers a more\nefficient solution compared to prior refinement methods.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5ee3\u6cdb\u7684\u81ea\u7136\u8a9e\u8a00\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u4e00\u500b\u95dc\u9375\u7684\u6311\u6230\u5728\u65bc\u5b83\u5011\u6709\u6642\u6703\u7522\u751f\u4e8b\u5be6\u4e0a\u4e0d\u6b63\u78ba\u7684\u7b54\u6848\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u96d6\u7136\u8a31\u591a\u5148\u524d\u7684\u5de5\u4f5c\u5c08\u6ce8\u65bc\u8b58\u5225\u5b83\u5011\u7522\u751f\u7684\u932f\u8aa4\u4e26\u9032\u4e00\u6b65\u4fee\u6b63\uff0c\u4f46\u7531\u65bc\u5b83\u5011\u88ab\u8a2d\u8a08\u70ba\u50c5\u5728\u5b83\u5011\u7684\u6574\u500b\u7522\u751f\uff08\u5f9e\u7b2c\u4e00\u500b\u5230\u6700\u5f8c\u4e00\u500b\u7b26\u865f\uff09\u5b8c\u6210\u5f8c\u624d\u9a57\u8b49 LLM \u7684\u56de\u61c9\uff0c\u56e0\u6b64\u5b83\u5011\u7684\u90e8\u7f72\u901f\u5ea6\u5f88\u6162\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u4e00\u65e6 LLM \u5728\u65e9\u671f\u7522\u751f\u4e0d\u6b63\u78ba\u7684\u7b26\u865f\uff0c\u5f8c\u7e8c\u7b26\u865f\u4e5f\u66f4\u6709\u53ef\u80fd\u5728\u4e8b\u5be6\u4e0a\u4e0d\u6b63\u78ba\u3002\u70ba\u6b64\uff0c\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e32\u6d41 VR\uff08\u4e32\u6d41\u9a57\u8b49\u548c\u4fee\u6b63\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8 LLM \u8f38\u51fa\u7684\u9a57\u8b49\u548c\u4fee\u6b63\u6548\u7387\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6240\u63d0\u51fa\u7684\u4e32\u6d41 VR \u80fd\u5920\u5728\u7b26\u865f\u88ab\u7522\u751f\u7684\u540c\u6642\u5c0d\u5176\u9032\u884c\u5373\u6642\u9a57\u8b49\u548c\u4fee\u6b63\uff0c\u985e\u4f3c\u65bc\u4e32\u6d41\u8655\u7406\uff0c\u78ba\u4fdd\u7b26\u865f\u7684\u6bcf\u500b\u5b50\u96c6\u5728 LLM \u5efa\u69cb\u5176\u56de\u61c9\u6642\u7531\u53e6\u4e00\u500b LLM \u5373\u6642\u6aa2\u67e5\u548c\u4fee\u6b63\u3002\u900f\u904e\u5c0d\u591a\u500b\u8cc7\u6599\u96c6\u9032\u884c\u5168\u9762\u7684\u8a55\u4f30\uff0c\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u4e0d\u50c5\u589e\u5f37\u4e86 LLM \u7684\u4e8b\u5be6\u6e96\u78ba\u6027\uff0c\u800c\u4e14\u8207\u5148\u524d\u7684\u4fee\u6b63\u65b9\u6cd5\u76f8\u6bd4\uff0c\u9084\u63d0\u4f9b\u4e86\u4e00\u500b\u66f4\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\u3002", "author": "Joonho Ko et.al.", "authors": "Joonho Ko, Jinheon Baek, Sung Ju Hwang", "id": "2501.07824v1", "paper_url": "http://arxiv.org/abs/2501.07824v1", "repo": "null"}}