{"2410.23875": {"publish_time": "2024-10-31", "title": "Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs", "paper_summary": "Large Language Models (LLMs) have shown remarkable reasoning capabilities on\ncomplex tasks, but they still suffer from out-of-date knowledge,\nhallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)\ncan provide explicit and editable knowledge for LLMs to alleviate these issues.\nExisting paradigm of KG-augmented LLM manually predefines the breadth of\nexploration space and requires flawless navigation in KGs. However, this\nparadigm cannot adaptively explore reasoning paths in KGs based on the question\nsemantics and self-correct erroneous reasoning paths, resulting in a bottleneck\nin efficiency and effect. To address these limitations, we propose a novel\nself-correcting adaptive planning paradigm for KG-augmented LLM named\nPlan-on-Graph (PoG), which first decomposes the question into several\nsub-objectives and then repeats the process of adaptively exploring reasoning\npaths, updating memory, and reflecting on the need to self-correct erroneous\nreasoning paths until arriving at the answer. Specifically, three important\nmechanisms of Guidance, Memory, and Reflection are designed to work together,\nto guarantee the adaptive breadth of self-correcting planning for graph\nreasoning. Finally, extensive experiments on three real-world datasets\ndemonstrate the effectiveness and efficiency of PoG.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8907\u96dc\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u77e5\u8b58\u904e\u6642\u3001\u5e7b\u89ba\u548c\u6c7a\u7b56\u4e0d\u900f\u660e\u7684\u554f\u984c\u3002\u76f8\u53cd\u5730\uff0c\u77e5\u8b58\u5716\u8b5c (KG) \u53ef\u4ee5\u63d0\u4f9b\u660e\u78ba\u4e14\u53ef\u7de8\u8f2f\u7684\u77e5\u8b58\uff0c\u4f9b LLM \u7de9\u89e3\u9019\u4e9b\u554f\u984c\u3002\u73fe\u6709\u7684 KG \u589e\u5f37 LLM \u5178\u7bc4\u624b\u52d5\u9810\u5148\u5b9a\u7fa9\u63a2\u7d22\u7a7a\u9593\u7684\u5ee3\u5ea6\uff0c\u4e26\u9700\u8981\u5728 KG \u4e2d\u5b8c\u7f8e\u5c0e\u822a\u3002\u7136\u800c\uff0c\u6b64\u5178\u7bc4\u7121\u6cd5\u6839\u64da\u554f\u984c\u8a9e\u610f\u81ea\u9069\u61c9\u5730\u63a2\u7d22 KG \u4e2d\u7684\u63a8\u7406\u8def\u5f91\uff0c\u4e26\u81ea\u884c\u7cfe\u6b63\u932f\u8aa4\u7684\u63a8\u7406\u8def\u5f91\uff0c\u5c0e\u81f4\u6548\u7387\u548c\u6548\u679c\u7684\u74f6\u9838\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba\u5716\u5f62\u8a08\u756b (PoG) \u7684 KG \u589e\u5f37 LLM \u7684\u65b0\u7a4e\u81ea\u4fee\u6b63\u81ea\u9069\u61c9\u898f\u5283\u5178\u7bc4\uff0c\u5b83\u9996\u5148\u5c07\u554f\u984c\u5206\u89e3\u6210\u5e7e\u500b\u5b50\u76ee\u6a19\uff0c\u7136\u5f8c\u91cd\u8907\u81ea\u9069\u61c9\u63a2\u7d22\u63a8\u7406\u8def\u5f91\u3001\u66f4\u65b0\u8a18\u61b6\u9ad4\u548c\u53cd\u601d\u9700\u8981\u81ea\u884c\u7cfe\u6b63\u932f\u8aa4\u63a8\u7406\u8def\u5f91\u7684\u904e\u7a0b\uff0c\u76f4\u5230\u5f97\u51fa\u7b54\u6848\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6307\u5c0e\u3001\u8a18\u61b6\u548c\u53cd\u601d\u9019\u4e09\u500b\u91cd\u8981\u6a5f\u5236\u88ab\u8a2d\u8a08\u70ba\u5354\u540c\u904b\u4f5c\uff0c\u4ee5\u4fdd\u8b49\u81ea\u4fee\u6b63\u898f\u5283\u5728\u5716\u5f62\u63a8\u7406\u4e2d\u7684\u81ea\u9069\u61c9\u5ee3\u5ea6\u3002\u6700\u5f8c\uff0c\u5728\u4e09\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86 PoG \u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "author": "Liyi Chen et.al.", "authors": "Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong", "id": "2410.23875v1", "paper_url": "http://arxiv.org/abs/2410.23875v1", "repo": "https://github.com/liyichen-cly/pog"}}