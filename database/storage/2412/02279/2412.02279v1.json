{"2412.02279": {"publish_time": "2024-12-03", "title": "A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis", "paper_summary": "Recently, Large Language Models (LLMs) have garnered increasing attention in\nthe field of natural language processing, revolutionizing numerous downstream\ntasks with powerful reasoning and generation abilities. For example, In-Context\nLearning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box\nLLMs to execute downstream tasks by analogy learning without any fine-tuning.\nBesides, in a fine-tuning-dependent paradigm where substantial training data\nexists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,\nenable LLMs to achieve excellent performance comparable to full fine-tuning.\n  However, these fascinating techniques employed by LLMs have not been fully\nexploited in the ABSA field. Previous works probe LLMs in ABSA by merely using\nrandomly selected input-output pairs as demonstrations in ICL, resulting in an\nincomplete and superficial evaluation. In this paper, we shed light on a\ncomprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8\nABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation\nto unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''\nFor the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using\ninstruction-based multi-task learning. For the fine-tuning-free paradigm, we\npropose 3 demonstration selection strategies to stimulate the few-shot\nabilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a\nnew state-of-the-art performance compared to fine-tuned Small Language Models\n(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the\nfine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still\nshowcase impressive potential and even compete with fine-tuned SLMs on some\nABSA subtasks.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5907\u53d7\u5173\u6ce8\uff0c\u5176\u5f3a\u5927\u7684\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\u5f7b\u5e95\u6539\u53d8\u4e86\u4f17\u591a\u4e0b\u6e38\u4efb\u52a1\u3002\u4f8b\u5982\uff0c\u8bed\u5883\u5b66\u4e60 (ICL) \u5f15\u5165\u4e86\u4e00\u79cd\u65e0\u5fae\u8c03\u8303\u4f8b\uff0c\u5141\u8bb8\u5f00\u7bb1\u5373\u7528\u7684 LLM \u901a\u8fc7\u7c7b\u6bd4\u5b66\u4e60\u6267\u884c\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u65e0\u9700\u4efb\u4f55\u5fae\u8c03\u3002\u6b64\u5916\uff0c\u5728\u5b58\u5728\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u5fae\u8c03\u76f8\u5173\u8303\u4f8b\u4e2d\uff0c\u4f5c\u4e3a\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03 (PEFT) \u4f7f LLM \u80fd\u591f\u5b9e\u73b0\u4e0e\u5b8c\u5168\u5fae\u8c03\u76f8\u5f53\u7684\u51fa\u8272\u6027\u80fd\u3002\n\u7136\u800c\uff0cLLM \u6240\u91c7\u7528\u7684\u8fd9\u4e9b\u5f15\u4eba\u5165\u80dc\u7684\u6280\u672f\u5c1a\u672a\u5728 ABSA \u9886\u57df\u5f97\u5230\u5145\u5206\u5229\u7528\u3002\u5148\u524d\u7684\u7814\u7a76\u901a\u8fc7\u5728 ICL \u4e2d\u4ec5\u4f7f\u7528\u968f\u673a\u9009\u62e9\u7684\u8f93\u5165\u8f93\u51fa\u5bf9\u4f5c\u4e3a\u6f14\u793a\u6765\u63a2\u7a76 ABSA \u4e2d\u7684 LLM\uff0c\u4ece\u800c\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u5b8c\u6574\u4e14\u80a4\u6d45\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u91cd\u70b9\u5bf9 ABSA \u9886\u57df\u4e2d\u7684 LLM \u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u6d89\u53ca 13 \u4e2a\u6570\u636e\u96c6\u30018 \u4e2a ABSA \u5b50\u4efb\u52a1\u548c 6 \u4e2a LLM\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4efb\u52a1\u516c\u5f0f\uff0c\u4ee5\u7edf\u4e00\u201c\u591a\u4e2a\u8303\u4f8b\u4e2d\u7684\u591a\u4e2a ABSA \u5b50\u4efb\u52a1\u7684\u591a\u4e2a LLM\u201d\u3002\u5bf9\u4e8e\u5fae\u8c03\u76f8\u5173\u8303\u4f8b\uff0c\u6211\u4eec\u4f7f\u7528\u57fa\u4e8e\u6307\u4ee4\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6709\u6548\u5730\u5fae\u8c03 LLM\u3002\u5bf9\u4e8e\u65e0\u5fae\u8c03\u8303\u4f8b\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 3 \u79cd\u6f14\u793a\u9009\u62e9\u7b56\u7565\u6765\u6fc0\u53d1 LLM \u7684\u5c0f\u6837\u672c\u80fd\u529b\u3002\u6211\u4eec\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5fae\u8c03\u76f8\u5173\u8303\u4f8b\u4e2d\u7684\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b (SLM) \u76f8\u6bd4\uff0cLLM \u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5728 SLM \u65e0\u6548\u7684\u65e0\u5fae\u8c03\u8303\u4f8b\u4e2d\uff0c\u5e26\u6709 ICL \u7684 LLM \u4ecd\u7136\u5c55\u793a\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6f5c\u529b\uff0c\u751a\u81f3\u5728\u67d0\u4e9b ABSA \u5b50\u4efb\u52a1\u4e0a\u4e0e\u5fae\u8c03\u7684 SLM \u7ade\u4e89\u3002</paragraph>", "author": "Changzhi Zhou et.al.", "authors": "Changzhi Zhou, Dandan Song, Yuhang Tian, Zhijing Wu, Hao Wang, Xinyu Zhang, Jun Yang, Ziyi Yang, Shuhao Zhang", "id": "2412.02279v1", "paper_url": "http://arxiv.org/abs/2412.02279v1", "repo": "null"}}