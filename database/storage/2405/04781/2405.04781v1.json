{"2405.04781": {"publish_time": "2024-05-08", "title": "CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization", "paper_summary": "Large language models (LLMs) have demonstrated astonishing capabilities in\nnatural language processing (NLP) tasks, sparking interest in their application\nto professional domains with higher specialized requirements. However,\nrestricted access to closed-source LLMs via APIs and the difficulty in\ncollecting massive high-quality datasets pose obstacles to the development of\nlarge language models in education fields of various courses. Given these\nchallenges, we propose CourseGPT-zh, a course-oriented education LLM that\nsupports customization and low-cost deployment. To address the\ncomprehensiveness and diversity requirements of course-specific corpora, we\ndesign a high-quality question-answering corpus distillation framework\nincorporating prompt optimization, which effectively mines textbook knowledge\nand enhances its diversity. Moreover, considering the alignment of LLM\nresponses with user needs, a novel method for discrete prompt optimization\nbased on LLM-as-Judge is introduced. During optimization, this framework\nleverages the LLM's ability to reflect on and exploit error feedback and\npatterns, allowing for prompts that meet user needs and preferences while\nsaving response length. Lastly, we obtain CourseGPT-zh based on the open-source\nLLM using parameter-efficient fine-tuning. Experimental results show that our\ndiscrete prompt optimization framework effectively improves the response\nquality of ChatGPT, and CourseGPT-zh exhibits strong professional capabilities\nin specialized knowledge question-answering, significantly outperforming\ncomparable open-source models.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u9a5a\u4eba\u7684\u80fd\u529b\uff0c\u6fc0\u767c\u4e86\u5c07\u5176\u61c9\u7528\u65bc\u5c08\u696d\u9818\u57df\uff0c\u4ee5\u6eff\u8db3\u66f4\u9ad8\u5c08\u696d\u5316\u9700\u6c42\u7684\u8208\u8da3\u3002\u7136\u800c\uff0c\u900f\u904e API \u9650\u5236\u5b58\u53d6\u5c01\u9589\u539f\u59cb\u78bc\u7684 LLM\uff0c\u4ee5\u53ca\u96e3\u4ee5\u6536\u96c6\u5927\u91cf\u9ad8\u54c1\u8cea\u8cc7\u6599\u96c6\uff0c\u5c0d\u5404\u7a2e\u8ab2\u7a0b\u7684\u6559\u80b2\u9818\u57df\u4e2d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u958b\u767c\u69cb\u6210\u969c\u7919\u3002\u9451\u65bc\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa CourseGPT-zh\uff0c\u4e00\u500b\u4ee5\u8ab2\u7a0b\u70ba\u5c0e\u5411\u7684\u6559\u80b2 LLM\uff0c\u652f\u63f4\u5ba2\u88fd\u5316\u548c\u4f4e\u6210\u672c\u90e8\u7f72\u3002\u70ba\u4e86\u6eff\u8db3\u8ab2\u7a0b\u7279\u5b9a\u8a9e\u6599\u5eab\u7684\u5168\u9762\u6027\u548c\u591a\u6a23\u6027\u9700\u6c42\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u9ad8\u54c1\u8cea\u554f\u7b54\u8a9e\u6599\u5eab\u8403\u53d6\u67b6\u69cb\uff0c\u7d50\u5408\u63d0\u793a\u6700\u4f73\u5316\uff0c\u6709\u6548\u6316\u6398\u6559\u79d1\u66f8\u77e5\u8b58\u4e26\u63d0\u5347\u5176\u591a\u6a23\u6027\u3002\u6b64\u5916\uff0c\u8003\u91cf\u5230 LLM \u56de\u61c9\u8207\u4f7f\u7528\u8005\u9700\u6c42\u7684\u4e00\u81f4\u6027\uff0c\u5f15\u5165\u4e86\u57fa\u65bc LLM-as-Judge \u7684\u96e2\u6563\u63d0\u793a\u6700\u4f73\u5316\u65b0\u65b9\u6cd5\u3002\u5728\u6700\u4f73\u5316\u904e\u7a0b\u4e2d\uff0c\u6b64\u67b6\u69cb\u5229\u7528 LLM \u53cd\u601d\u548c\u5229\u7528\u932f\u8aa4\u56de\u994b\u548c\u6a21\u5f0f\u7684\u80fd\u529b\uff0c\u5141\u8a31\u63d0\u793a\u6eff\u8db3\u4f7f\u7528\u8005\u9700\u6c42\u548c\u504f\u597d\uff0c\u540c\u6642\u7bc0\u7701\u56de\u61c9\u9577\u5ea6\u3002\u6700\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u53c3\u6578\u6709\u6548\u5fae\u8abf\uff0c\u6839\u64da\u958b\u6e90 LLM \u7372\u5f97 CourseGPT-zh\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u96e2\u6563\u63d0\u793a\u6700\u4f73\u5316\u67b6\u69cb\u6709\u6548\u63d0\u5347 ChatGPT \u7684\u56de\u61c9\u54c1\u8cea\uff0c\u800c CourseGPT-zh \u5728\u5c08\u696d\u77e5\u8b58\u554f\u7b54\u4e2d\u5c55\u73fe\u5f37\u5927\u7684\u5c08\u696d\u80fd\u529b\uff0c\u986f\u8457\u512a\u65bc\u540c\u985e\u958b\u6e90\u6a21\u578b\u3002", "author": "Zheyan Qu et.al.", "authors": "Zheyan Qu, Lu Yin, Zitong Yu, Wenbo Wang, Xing zhang", "id": "2405.04781v1", "paper_url": "http://arxiv.org/abs/2405.04781v1", "repo": "null"}}