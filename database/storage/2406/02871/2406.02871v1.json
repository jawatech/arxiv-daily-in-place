{"2406.02871": {"publish_time": "2024-06-05", "title": "Sound Heuristic Search Value Iteration for Undiscounted POMDPs with Reachability Objectives", "paper_summary": "Partially Observable Markov Decision Processes (POMDPs) are powerful models\nfor sequential decision making under transition and observation uncertainties.\nThis paper studies the challenging yet important problem in POMDPs known as the\n(indefinite-horizon) Maximal Reachability Probability Problem (MRPP), where the\ngoal is to maximize the probability of reaching some target states. This is\nalso a core problem in model checking with logical specifications and is\nnaturally undiscounted (discount factor is one). Inspired by the success of\npoint-based methods developed for discounted problems, we study their\nextensions to MRPP. Specifically, we focus on trial-based heuristic search\nvalue iteration techniques and present a novel algorithm that leverages the\nstrengths of these techniques for efficient exploration of the belief space\n(informed search via value bounds) while addressing their drawbacks in handling\nloops for indefinite-horizon problems. The algorithm produces policies with\ntwo-sided bounds on optimal reachability probabilities. We prove convergence to\nan optimal policy from below under certain conditions. Experimental evaluations\non a suite of benchmarks show that our algorithm outperforms existing methods\nin almost all cases in both probability guarantees and computation time.", "paper_summary_zh": "\u90e8\u5206\u53ef\u89c0\u5bdf\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (POMDP) \u662f\u5728\u8f49\u79fb\u548c\u89c0\u5bdf\u4e0d\u78ba\u5b9a\u6027\u4e0b\u9032\u884c\u9806\u5e8f\u6c7a\u7b56\u7684\u6709\u529b\u6a21\u578b\u3002\u672c\u6587\u7814\u7a76\u4e86 POMDP \u4e2d\u5177\u6709\u6311\u6230\u6027\u4f46\u91cd\u8981\u7684\u554f\u984c\uff0c\u7a31\u70ba\uff08\u7121\u9650\u6642\u9593\u8ef8\uff09\u6700\u5927\u53ef\u9054\u6a5f\u7387\u554f\u984c (MRPP)\uff0c\u5176\u76ee\u6a19\u662f\u6700\u5927\u5316\u9054\u5230\u67d0\u4e9b\u76ee\u6a19\u72c0\u614b\u7684\u6a5f\u7387\u3002\u9019\u4e5f\u662f\u5177\u6709\u908f\u8f2f\u898f\u7bc4\u7684\u6a21\u578b\u6aa2\u67e5\u4e2d\u7684\u6838\u5fc3\u554f\u984c\uff0c\u4e26\u4e14\u672c\u8cea\u4e0a\u6c92\u6709\u6298\u6263\uff08\u6298\u6263\u56e0\u5b50\u70ba\u4e00\uff09\u3002\u53d7\u5230\u70ba\u6298\u6263\u554f\u984c\u958b\u767c\u7684\u57fa\u65bc\u9ede\u7684\u65b9\u6cd5\u7684\u6210\u529f\u555f\u767c\uff0c\u6211\u5011\u7814\u7a76\u4e86\u5b83\u5011\u5c0d MRPP \u7684\u64f4\u5145\u3002\u5177\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u57fa\u65bc\u8a66\u9a57\u7684\u555f\u767c\u5f0f\u641c\u5c0b\u503c\u8fed\u4ee3\u6280\u8853\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u6f14\u7b97\u6cd5\uff0c\u5b83\u5229\u7528\u4e86\u9019\u4e9b\u6280\u8853\u7684\u512a\u52e2\u4f86\u6709\u6548\u63a2\u7d22\u4fe1\u5ff5\u7a7a\u9593\uff08\u900f\u904e\u503c\u908a\u754c\u9032\u884c\u660e\u667a\u641c\u5c0b\uff09\uff0c\u540c\u6642\u89e3\u6c7a\u4e86\u5b83\u5011\u5728\u8655\u7406\u7121\u9650\u6642\u9593\u8ef8\u554f\u984c\u7684\u8ff4\u5708\u6642\u7684\u7f3a\u9ede\u3002\u8a72\u6f14\u7b97\u6cd5\u7522\u751f\u5c0d\u6700\u4f73\u53ef\u9054\u6a5f\u7387\u5177\u6709\u96d9\u908a\u908a\u754c\u7684\u7b56\u7565\u3002\u6211\u5011\u8b49\u660e\u4e86\u5728\u7279\u5b9a\u689d\u4ef6\u4e0b\u5f9e\u4e0b\u65b9\u6536\u6582\u5230\u6700\u4f73\u7b56\u7565\u3002\u5c0d\u4e00\u7cfb\u5217\u57fa\u6e96\u7684\u5be6\u9a57\u8a55\u4f30\u8868\u660e\uff0c\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u5728\u5e7e\u4e4e\u6240\u6709\u60c5\u6cc1\u4e0b\uff0c\u5728\u6a5f\u7387\u4fdd\u8b49\u548c\u904b\u7b97\u6642\u9593\u65b9\u9762\u90fd\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002", "author": "Qi Heng Ho et.al.", "authors": "Qi Heng Ho, Martin S. Feather, Federico Rossi, Zachary N. Sunberg, Morteza Lahijanian", "id": "2406.02871v1", "paper_url": "http://arxiv.org/abs/2406.02871v1", "repo": "null"}}