{"2412.07626": {"publish_time": "2024-12-10", "title": "OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations", "paper_summary": "Document content extraction is crucial in computer vision, especially for\nmeeting the high-quality data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) technologies. However, current document\nparsing methods suffer from significant limitations in terms of diversity and\ncomprehensive evaluation. To address these challenges, we introduce\nOmniDocBench, a novel multi-source benchmark designed to advance automated\ndocument content extraction. OmniDocBench includes a meticulously curated and\nannotated high-quality evaluation dataset comprising nine diverse document\ntypes, such as academic papers, textbooks, slides, among others. Our benchmark\nprovides a flexible and comprehensive evaluation framework with 19 layout\ncategory labels and 14 attribute labels, enabling multi-level assessments\nacross entire datasets, individual modules, or specific data types. Using\nOmniDocBench, we perform an exhaustive comparative analysis of existing modular\npipelines and multimodal end-to-end methods, highlighting their limitations in\nhandling document diversity and ensuring fair evaluation. OmniDocBench\nestablishes a robust, diverse, and fair evaluation standard for the document\ncontent extraction field, offering crucial insights for future advancements and\nfostering the development of document parsing technologies. The codes and\ndataset is available in https://github.com/opendatalab/OmniDocBench.", "paper_summary_zh": "\u6587\u4ef6\u5167\u5bb9\u8403\u53d6\u5728\u96fb\u8166\u8996\u89ba\u4e2d\u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u70ba\u4e86\u6eff\u8db3\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u6280\u8853\u7684\u9ad8\u54c1\u8cea\u8cc7\u6599\u9700\u6c42\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u7684\u6587\u4ef6\u89e3\u6790\u65b9\u6cd5\u5728\u591a\u6a23\u6027\u548c\u5168\u9762\u8a55\u4f30\u65b9\u9762\u5b58\u5728\u91cd\u5927\u9650\u5236\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 OmniDocBench\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u591a\u4f86\u6e90\u57fa\u6e96\u6e2c\u8a66\uff0c\u65e8\u5728\u63a8\u9032\u81ea\u52d5\u5316\u6587\u4ef6\u5167\u5bb9\u8403\u53d6\u3002OmniDocBench \u5305\u542b\u4e00\u500b\u7cbe\u5fc3\u7b56\u5283\u548c\u8a3b\u89e3\u7684\u9ad8\u54c1\u8cea\u8a55\u4f30\u8cc7\u6599\u96c6\uff0c\u5305\u542b\u4e5d\u7a2e\u591a\u6a23\u7684\u6587\u4ef6\u985e\u578b\uff0c\u4f8b\u5982\u5b78\u8853\u8ad6\u6587\u3001\u6559\u79d1\u66f8\u3001\u6295\u5f71\u7247\u7b49\u3002\u6211\u5011\u7684\u57fa\u6e96\u6e2c\u8a66\u63d0\u4f9b\u4e86\u4e00\u500b\u9748\u6d3b\u4e14\u5168\u9762\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u5305\u542b 19 \u500b\u7248\u9762\u985e\u5225\u6a19\u7c64\u548c 14 \u500b\u5c6c\u6027\u6a19\u7c64\uff0c\u53ef\u4ee5\u5728\u6574\u500b\u8cc7\u6599\u96c6\u3001\u500b\u5225\u6a21\u7d44\u6216\u7279\u5b9a\u8cc7\u6599\u985e\u578b\u4e2d\u9032\u884c\u591a\u5c64\u7d1a\u8a55\u4f30\u3002\u4f7f\u7528 OmniDocBench\uff0c\u6211\u5011\u5c0d\u73fe\u6709\u7684\u6a21\u7d44\u5316\u7ba1\u7dda\u548c\u591a\u6a21\u614b\u7aef\u5230\u7aef\u65b9\u6cd5\u9032\u884c\u4e86\u8a73\u76e1\u7684\u6bd4\u8f03\u5206\u6790\uff0c\u7a81\u986f\u4e86\u5b83\u5011\u5728\u8655\u7406\u6587\u4ef6\u591a\u6a23\u6027\u548c\u78ba\u4fdd\u516c\u5e73\u8a55\u4f30\u65b9\u9762\u7684\u9650\u5236\u3002OmniDocBench \u70ba\u6587\u4ef6\u5167\u5bb9\u8403\u53d6\u9818\u57df\u5efa\u7acb\u4e86\u4e00\u500b\u5f37\u5927\u3001\u591a\u6a23\u4e14\u516c\u5e73\u7684\u8a55\u4f30\u6a19\u6e96\uff0c\u70ba\u672a\u4f86\u7684\u9032\u6b65\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u898b\u89e3\uff0c\u4e26\u4fc3\u9032\u4e86\u6587\u4ef6\u89e3\u6790\u6280\u8853\u7684\u767c\u5c55\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/opendatalab/OmniDocBench \u4e2d\u53d6\u5f97\u3002", "author": "Linke Ouyang et.al.", "authors": "Linke Ouyang, Yuan Qu, Hongbin Zhou, Jiawei Zhu, Rui Zhang, Qunshu Lin, Bin Wang, Zhiyuan Zhao, Man Jiang, Xiaomeng Zhao, Jin Shi, Fan Wu, Pei Chu, Minghao Liu, Zhenxiang Li, Chao Xu, Bo Zhang, Botian Shi, Zhongying Tu, Conghui He", "id": "2412.07626v1", "paper_url": "http://arxiv.org/abs/2412.07626v1", "repo": "https://github.com/opendatalab/OmniDocBench"}}