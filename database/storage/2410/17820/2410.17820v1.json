{"2410.17820": {"publish_time": "2024-10-23", "title": "Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination", "paper_summary": "Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models\n(LLMs) that employs a generator to suggest reasoning steps and a discriminator\nto decide which steps to implement. ToT demonstrates strong performance on\nreasoning tasks, often surpassing simple methods such as Input-Output (IO)\nprompting and Chain-of-Thought (CoT) reasoning. However, ToT does not\nconsistently outperform such simpler methods across all models, leaving large\nknowledge gaps on the conditions under which ToT is most beneficial. In this\npaper, we analyze the roles of the generator and discriminator separately to\nbetter understand the conditions when ToT is beneficial. We find that the\ngenerator plays a more critical role than the discriminator in driving the\nsuccess of ToT. While using even a smaller model as the discriminator, scaling\nthe generator leads to notable improvements in ToT performance, whereas scaling\nthe discriminator with a fixed generator yields only marginal gains. Our\nresults show that models across different scales exhibit comparable\ndiscrimination capabilities, yet differ significantly in their generative\nperformance for ToT.", "paper_summary_zh": "\u601d\u8003\u4e4b\u6a39\uff08ToT\uff09\u662f\u4e00\u7a2e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5b83\u4f7f\u7528\u751f\u6210\u5668\u4f86\u5efa\u8b70\u63a8\u7406\u6b65\u9a5f\uff0c\u4e26\u4f7f\u7528\u5224\u5225\u5668\u4f86\u6c7a\u5b9a\u8981\u5be6\u65bd\u54ea\u4e9b\u6b65\u9a5f\u3002ToT \u5728\u63a8\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u901a\u5e38\u8d85\u8d8a\u4e86\u8f38\u5165\u8f38\u51fa\uff08IO\uff09\u63d0\u793a\u548c\u601d\u8003\u93c8\uff08CoT\uff09\u63a8\u7406\u7b49\u7c21\u55ae\u65b9\u6cd5\u3002\u7136\u800c\uff0cToT \u4e26\u672a\u5728\u6240\u6709\u6a21\u578b\u4e2d\u59cb\u7d42\u512a\u65bc\u9019\u4e9b\u66f4\u7c21\u55ae\u7684\u65b9\u6cd5\uff0c\u9019\u4f7f\u5f97\u5728 ToT \u6700\u6709\u76ca\u7684\u689d\u4ef6\u4e0b\u7559\u4e0b\u4e86\u5de8\u5927\u7684\u77e5\u8b58\u7a7a\u767d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5206\u5225\u5206\u6790\u4e86\u751f\u6210\u5668\u548c\u5224\u5225\u5668\u7684\u89d2\u8272\uff0c\u4ee5\u66f4\u597d\u5730\u4e86\u89e3 ToT \u6709\u76ca\u7684\u689d\u4ef6\u3002\u6211\u5011\u767c\u73fe\u751f\u6210\u5668\u5728\u63a8\u52d5 ToT \u7684\u6210\u529f\u65b9\u9762\u767c\u63ee\u4e86\u6bd4\u5224\u5225\u5668\u66f4\u95dc\u9375\u7684\u4f5c\u7528\u3002\u96d6\u7136\u5373\u4f7f\u4f7f\u7528\u8f03\u5c0f\u7684\u6a21\u578b\u4f5c\u70ba\u5224\u5225\u5668\uff0c\u4f46\u64f4\u5c55\u751f\u6210\u5668\u4e5f\u6703\u5c0e\u81f4 ToT \u6027\u80fd\u986f\u8457\u63d0\u5347\uff0c\u800c\u4f7f\u7528\u56fa\u5b9a\u751f\u6210\u5668\u64f4\u5c55\u5224\u5225\u5668\u53ea\u6703\u7522\u751f\u908a\u969b\u6536\u76ca\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u4e0d\u540c\u898f\u6a21\u7684\u6a21\u578b\u8868\u73fe\u51fa\u53ef\u6bd4\u8f03\u7684\u5224\u5225\u80fd\u529b\uff0c\u4f46\u5728 ToT \u7684\u751f\u6210\u6027\u80fd\u65b9\u9762\u537b\u6709\u986f\u8457\u5dee\u7570\u3002", "author": "Qiqi Chen et.al.", "authors": "Qiqi Chen, Xinpeng Wang, Philipp Mondorf, Michael A. Hedderich, Barbara Plank", "id": "2410.17820v1", "paper_url": "http://arxiv.org/abs/2410.17820v1", "repo": "https://github.com/mainlp/tot-eval"}}