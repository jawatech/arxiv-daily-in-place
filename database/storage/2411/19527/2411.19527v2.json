{"2411.19527": {"publish_time": "2024-11-29", "title": "DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding", "paper_summary": "Human motion, inherently continuous and dynamic, presents significant\nchallenges for generative models. Despite their dominance, discrete\nquantization methods, such as VQ-VAEs, suffer from inherent limitations,\nincluding restricted expressiveness and frame-wise noise artifacts. Continuous\napproaches, while producing smoother and more natural motions, often falter due\nto high-dimensional complexity and limited training data. To resolve this\n\"discord\" between discrete and continuous representations, we introduce\nDisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding, a\nnovel method that decodes discrete motion tokens into continuous motion through\nrectified flow. By employing an iterative refinement process in the continuous\nspace, DisCoRD captures fine-grained dynamics and ensures smoother and more\nnatural motions. Compatible with any discrete-based framework, our method\nenhances naturalness without compromising faithfulness to the conditioning\nsignals. Extensive evaluations demonstrate that DisCoRD achieves\nstate-of-the-art performance, with FID of 0.032 on HumanML3D and 0.169 on\nKIT-ML. These results solidify DisCoRD as a robust solution for bridging the\ndivide between discrete efficiency and continuous realism. Our project page is\navailable at: https://whwjdqls.github.io/discord.github.io/.", "paper_summary_zh": "\u4eba\u985e\u52d5\u4f5c\u672c\u8cea\u4e0a\u662f\u9023\u7e8c\u4e14\u52d5\u614b\u7684\uff0c\u5c0d\u751f\u6210\u6a21\u578b\u4f86\u8aaa\u662f\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\u3002\u5118\u7ba1\u96e2\u6563\u91cf\u5316\u65b9\u6cd5\uff08\u4f8b\u5982 VQ-VAE\uff09\u4f54\u64da\u4e3b\u5c0e\u5730\u4f4d\uff0c\u4f46\u5b83\u5011\u5b58\u5728\u56fa\u6709\u7684\u9650\u5236\uff0c\u5305\u62ec\u8868\u73fe\u529b\u53d7\u9650\u548c\u9010\u5e40\u566a\u8072\u507d\u5f71\u3002\u9023\u7e8c\u65b9\u6cd5\u96d6\u7136\u80fd\u7522\u751f\u66f4\u5e73\u6ed1\u3001\u66f4\u81ea\u7136\u7684\u52d5\u4f5c\uff0c\u4f46\u7531\u65bc\u9ad8\u7dad\u8907\u96dc\u6027\u548c\u8a13\u7df4\u6578\u64da\u6709\u9650\uff0c\u5f80\u5f80\u6703\u5931\u6557\u3002\u70ba\u4e86\u89e3\u6c7a\u96e2\u6563\u548c\u9023\u7e8c\u8868\u793a\u4e4b\u9593\u7684\u300c\u4e0d\u5354\u8abf\u300d\uff0c\u6211\u5011\u5f15\u5165\u4e86 DisCoRD\uff1a\u901a\u904e\u4fee\u6b63\u6d41\u89e3\u78bc\u5c07\u96e2\u6563\u52d5\u4f5c\u7b26\u865f\u89e3\u78bc\u70ba\u9023\u7e8c\u52d5\u4f5c\uff0c\u9019\u662f\u4e00\u7a2e\u900f\u904e\u4fee\u6b63\u6d41\u5c07\u96e2\u6563\u52d5\u4f5c\u7b26\u865f\u89e3\u78bc\u70ba\u9023\u7e8c\u52d5\u4f5c\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u904e\u5728\u9023\u7e8c\u7a7a\u9593\u4e2d\u63a1\u7528\u8fed\u4ee3\u7d30\u5316\u904e\u7a0b\uff0cDisCoRD \u80fd\u6355\u6349\u7d30\u5fae\u7684\u52d5\u614b\uff0c\u4e26\u78ba\u4fdd\u52d5\u4f5c\u66f4\u5e73\u6ed1\u3001\u66f4\u81ea\u7136\u3002\u6211\u5011\u7684\u9019\u7a2e\u65b9\u6cd5\u8207\u4efb\u4f55\u57fa\u65bc\u96e2\u6563\u7684\u65b9\u6cd5\u76f8\u5bb9\uff0c\u80fd\u5728\u4e0d\u640d\u5bb3\u5c0d\u689d\u4ef6\u4fe1\u865f\u7684\u5fe0\u5be6\u5ea6\u7684\u540c\u6642\u589e\u5f37\u81ea\u7136\u6027\u3002\u5ee3\u6cdb\u7684\u8a55\u4f30\u8868\u660e\uff0cDisCoRD \u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\uff0c\u5728 HumanML3D \u4e0a\u7684 FID \u70ba 0.032\uff0c\u5728 KIT-ML \u4e0a\u7684 FID \u70ba 0.169\u3002\u9019\u4e9b\u7d50\u679c\u978f\u56fa\u4e86 DisCoRD \u4f5c\u70ba\u9023\u63a5\u96e2\u6563\u6548\u7387\u548c\u9023\u7e8c\u771f\u5be6\u6027\u4e4b\u9593\u9d3b\u6e9d\u7684\u5f37\u5927\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u5c08\u6848\u9801\u9762\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://whwjdqls.github.io/discord.github.io/\u3002", "author": "Jungbin Cho et.al.", "authors": "Jungbin Cho, Junwan Kim, Jisoo Kim, Minseo Kim, Mingu Kang, Sungeun Hong, Tae-Hyun Oh, Youngjae Yu", "id": "2411.19527v2", "paper_url": "http://arxiv.org/abs/2411.19527v2", "repo": "null"}}