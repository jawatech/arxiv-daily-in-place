{"2501.05559": {"publish_time": "2025-01-09", "title": "Soup to go: mitigating forgetting during continual learning with model averaging", "paper_summary": "In continual learning, where task data arrives in a sequence, fine-tuning on\nlater tasks will often lead to performance degradation on earlier tasks. This\nis especially pronounced when these tasks come from diverse domains. In this\nsetting, how can we mitigate catastrophic forgetting of earlier tasks and\nretain what the model has learned with minimal computational expenses? Inspired\nby other merging methods, and L2-regression, we propose Sequential Fine-tuning\nwith Averaging (SFA), a method that merges currently training models with\nearlier checkpoints during the course of training. SOTA approaches typically\nmaintain a data buffer of past tasks or impose a penalty at each gradient step.\nIn contrast, our method achieves comparable results without the need to store\npast data, or multiple copies of parameters for each gradient step.\nFurthermore, our method outperforms common merging techniques such as Task\nArithmetic, TIES Merging, and WiSE-FT, as well as other penalty methods like L2\nand Elastic Weight Consolidation. In turn, our method offers insight into the\nbenefits of merging partially-trained models during training across both image\nand language domains.", "paper_summary_zh": "\u5728\u6301\u7e8c\u5b78\u7fd2\u4e2d\uff0c\u4efb\u52d9\u8cc7\u6599\u4ee5\u5e8f\u5217\u5f62\u5f0f\u51fa\u73fe\uff0c\u5f8c\u7e8c\u4efb\u52d9\u7684\u5fae\u8abf\u901a\u5e38\u6703\u5c0e\u81f4\u5148\u524d\u4efb\u52d9\u7684\u6548\u80fd\u4e0b\u964d\u3002\u7576\u9019\u4e9b\u4efb\u52d9\u4f86\u81ea\u4e0d\u540c\u7684\u9818\u57df\u6642\uff0c\u9019\u7a2e\u60c5\u6cc1\u5c24\u5176\u660e\u986f\u3002\u5728\u6b64\u8a2d\u5b9a\u4e2d\uff0c\u6211\u5011\u5982\u4f55\u6e1b\u8f15\u5148\u524d\u4efb\u52d9\u7684\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u4e26\u4ee5\u6700\u5c0f\u7684\u904b\u7b97\u6210\u672c\u4fdd\u7559\u6a21\u578b\u6240\u5b78\u5230\u7684\u77e5\u8b58\uff1f\u53d7\u5230\u5176\u4ed6\u5408\u4f75\u65b9\u6cd5\u548c L2 \u56de\u6b78\u7684\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u5e8f\u8cab\u5fae\u8abf\u8207\u5e73\u5747 (SFA)\uff0c\u9019\u662f\u4e00\u7a2e\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u5c07\u76ee\u524d\u8a13\u7df4\u7684\u6a21\u578b\u8207\u8f03\u65e9\u7684\u6aa2\u67e5\u9ede\u5408\u4f75\u7684\u65b9\u6cd5\u3002\u73fe\u6709\u6280\u8853\u901a\u5e38\u6703\u7dad\u8b77\u904e\u53bb\u4efb\u52d9\u7684\u8cc7\u6599\u7de9\u885d\u5340\uff0c\u6216\u5728\u6bcf\u500b\u68af\u5ea6\u6b65\u9a5f\u4e2d\u65bd\u52a0\u61f2\u7f70\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u5728\u4e0d\u9700\u8981\u5132\u5b58\u904e\u53bb\u8cc7\u6599\u6216\u6bcf\u500b\u68af\u5ea6\u6b65\u9a5f\u7684\u53c3\u6578\u591a\u500b\u526f\u672c\u7684\u60c5\u6cc1\u4e0b\uff0c\u5c31\u80fd\u9054\u6210\u76f8\u7576\u7684\u7d50\u679c\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u512a\u65bc\u5e38\u898b\u7684\u5408\u4f75\u6280\u8853\uff0c\u4f8b\u5982\u4efb\u52d9\u7b97\u8853\u3001TIES \u5408\u4f75\u548c WiSE-FT\uff0c\u4ee5\u53ca\u5176\u4ed6\u61f2\u7f70\u65b9\u6cd5\uff0c\u4f8b\u5982 L2 \u548c\u5f48\u6027\u6b0a\u91cd\u5408\u4f75\u3002\u53cd\u904e\u4f86\uff0c\u6211\u5011\u7684\u512a\u52e2\u5728\u65bc\u5728\u5f71\u50cf\u548c\u8a9e\u8a00\u9818\u57df\u7684\u8a13\u7df4\u904e\u7a0b\u4e2d\uff0c\u5408\u4f75\u90e8\u5206\u8a13\u7df4\u6a21\u578b\u7684\u597d\u8655\u3002", "author": "Anat Kleiman et.al.", "authors": "Anat Kleiman, Gintare Karolina Dziugaite, Jonathan Frankle, Sham Kakade, Mansheej Paul", "id": "2501.05559v1", "paper_url": "http://arxiv.org/abs/2501.05559v1", "repo": "null"}}