{"2410.08048": {"publish_time": "2024-10-10", "title": "VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers", "paper_summary": "Recent advancements in test time compute, particularly through the use of\nverifier models, have significantly enhanced the reasoning capabilities of\nLarge Language Models (LLMs). This generator-verifier approach closely\nresembles the actor-critic framework in reinforcement learning (RL). However,\ncurrent verifier models in LLMs often rely on supervised fine-tuning without\ntemporal difference learning such as Q-learning. This paper introduces\nVerifierQ, a novel approach that integrates Offline Q-learning into LLM\nverifier models. We address three key challenges in applying Q-learning to\nLLMs: (1) handling utterance-level Markov Decision Processes (MDPs), (2)\nmanaging large action spaces, and (3) mitigating overestimation bias. VerifierQ\nintroduces a modified Bellman update for bounded Q-values, incorporates\nImplicit Q-learning (IQL) for efficient action space management, and integrates\na novel Conservative Q-learning (CQL) formulation for balanced Q-value\nestimation. Our method enables parallel Q-value computation and improving\ntraining efficiency. While recent work has explored RL techniques like MCTS for\ngenerators, VerifierQ is among the first to investigate the verifier (critic)\naspect in LLMs through Q-learning. This integration of RL principles into\nverifier models complements existing advancements in generator techniques,\npotentially enabling more robust and adaptive reasoning in LLMs. Experimental\nresults on mathematical reasoning tasks demonstrate VerifierQ's superior\nperformance compared to traditional supervised fine-tuning approaches, with\nimprovements in efficiency, accuracy and robustness. By enhancing the synergy\nbetween generation and evaluation capabilities, VerifierQ contributes to the\nongoing evolution of AI systems in addressing complex cognitive tasks across\nvarious domains.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u5728\u6e2c\u8a66\u6642\u9593\u8a08\u7b97\u65b9\u9762\u7684\u9032\u5c55\uff0c\u7279\u5225\u662f\u900f\u904e\u9a57\u8b49\u6a21\u578b\u7684\u4f7f\u7528\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\u3002\u9019\u7a2e\u751f\u6210\u5668\u9a57\u8b49\u65b9\u6cd5\u8207\u5f37\u5316\u5b78\u7fd2 (RL) \u4e2d\u7684\u884c\u52d5\u8005-\u8a55\u8ad6\u8005\u67b6\u69cb\u975e\u5e38\u76f8\u4f3c\u3002\u7136\u800c\uff0cLLM \u4e2d\u76ee\u524d\u7684\u9a57\u8b49\u6a21\u578b\u901a\u5e38\u4f9d\u8cf4\u65bc\u76e3\u7763\u5fae\u8abf\uff0c\u800c\u6c92\u6709\u6642\u9593\u5dee\u5b78\u7fd2\uff0c\u4f8b\u5982 Q \u5b78\u7fd2\u3002\u672c\u6587\u4ecb\u7d39\u4e86 VerifierQ\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5c07\u96e2\u7dda Q \u5b78\u7fd2\u6574\u5408\u5230 LLM \u9a57\u8b49\u6a21\u578b\u4e2d\u3002\u6211\u5011\u89e3\u6c7a\u4e86\u5c07 Q \u5b78\u7fd2\u61c9\u7528\u65bc LLM \u7684\u4e09\u500b\u4e3b\u8981\u6311\u6230\uff1a(1) \u8655\u7406\u8a71\u8a9e\u7d1a\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (MDP)\uff0c(2) \u7ba1\u7406\u5927\u578b\u52d5\u4f5c\u7a7a\u9593\uff0c\u4ee5\u53ca (3) \u6e1b\u8f15\u9ad8\u4f30\u504f\u5dee\u3002VerifierQ \u91dd\u5c0d\u6709\u754c Q \u503c\u5f15\u5165\u4e86\u4fee\u6539\u5f8c\u7684 Bellman \u66f4\u65b0\uff0c\u7d50\u5408\u4e86\u96b1\u5f0f Q \u5b78\u7fd2 (IQL) \u4ee5\u9032\u884c\u6709\u6548\u7684\u52d5\u4f5c\u7a7a\u9593\u7ba1\u7406\uff0c\u4e26\u6574\u5408\u4e86\u4e00\u7a2e\u65b0\u7684\u4fdd\u5b88 Q \u5b78\u7fd2 (CQL) \u516c\u5f0f\uff0c\u4ee5\u9032\u884c\u5e73\u8861\u7684 Q \u503c\u4f30\u8a08\u3002\u6211\u5011\u7684\u6a21\u578b\u652f\u63f4\u4e26\u884c Q \u503c\u8a08\u7b97\uff0c\u4e26\u63d0\u9ad8\u8a13\u7df4\u6548\u7387\u3002\u96d6\u7136\u6700\u8fd1\u7684\u7814\u7a76\u63a2\u7d22\u4e86 MCTS \u7b49 RL \u6280\u8853\u4ee5\u7528\u65bc\u751f\u6210\u5668\uff0c\u4f46 VerifierQ \u662f\u7b2c\u4e00\u500b\u900f\u904e Q \u5b78\u7fd2\u63a2\u8a0e LLM \u4e2d\u9a57\u8b49\u8005\uff08\u8a55\u8ad6\u8005\uff09\u65b9\u9762\u7684\u7814\u7a76\u3002\u9019\u7a2e\u5c07 RL \u539f\u5247\u6574\u5408\u5230\u9a57\u8b49\u6a21\u578b\u4e2d\u7684\u505a\u6cd5\uff0c\u88dc\u5145\u4e86\u751f\u6210\u5668\u6280\u8853\u4e2d\u73fe\u6709\u7684\u9032\u5c55\uff0c\u6f5b\u5728\u5730\u8b93 LLM \u80fd\u5920\u9032\u884c\u66f4\u5f37\u5065\u4e14\u9069\u61c9\u6027\u66f4\u5f37\u7684\u63a8\u7406\u3002\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86 VerifierQ \u512a\u65bc\u50b3\u7d71\u76e3\u7763\u5fae\u8abf\u65b9\u6cd5\uff0c\u5728\u6548\u7387\u3001\u6e96\u78ba\u6027\u548c\u5f37\u5065\u6027\u65b9\u9762\u90fd\u6709\u6240\u63d0\u5347\u3002\u900f\u904e\u52a0\u5f37\u751f\u6210\u8207\u8a55\u4f30\u80fd\u529b\u4e4b\u9593\u7684\u5354\u540c\u4f5c\u7528\uff0cVerifierQ \u6709\u52a9\u65bc AI \u7cfb\u7d71\u6301\u7e8c\u6f14\u9032\uff0c\u4ee5\u89e3\u6c7a\u5404\u7a2e\u9818\u57df\u4e2d\u7684\u8907\u96dc\u8a8d\u77e5\u4efb\u52d9\u3002</paragraph>", "author": "Jianing Qi et.al.", "authors": "Jianing Qi, Hao Tang, Zhigang Zhu", "id": "2410.08048v1", "paper_url": "http://arxiv.org/abs/2410.08048v1", "repo": "null"}}