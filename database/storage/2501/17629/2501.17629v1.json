{"2501.17629": {"publish_time": "2025-01-29", "title": "The Imitation Game According To Turing", "paper_summary": "The current cycle of hype and anxiety concerning the benefits and risks to\nhuman society of Artificial Intelligence is fuelled, not only by the increasing\nuse of generative AI and other AI tools by the general public, but also by\nclaims made on behalf of such technology by popularizers and scientists. In\nparticular, recent studies have claimed that Large Language Models (LLMs) can\npass the Turing Test-a goal for AI since the 1950s-and therefore can \"think\".\nLarge-scale impacts on society have been predicted as a result. Upon detailed\nexamination, however, none of these studies has faithfully applied Turing's\noriginal instructions. Consequently, we conducted a rigorous Turing Test with\nGPT-4-Turbo that adhered closely to Turing's instructions for a three-player\nimitation game. We followed established scientific standards where Turing's\ninstructions were ambiguous or missing. For example, we performed a\nComputer-Imitates-Human Game (CIHG) without constraining the time duration and\nconducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one\nparticipant correctly identified the LLM, showing that one of today's most\nadvanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent\nextravagant claims for such models are unsupported, and do not warrant either\noptimism or concern about the social impact of thinking machines.", "paper_summary_zh": "\u7576\u524d\u95dc\u65bc\u4eba\u5de5\u667a\u6167\u5c0d\u4eba\u985e\u793e\u6703\u7684\u5229\u5f0a\u7684\u7092\u4f5c\u548c\u7126\u616e\u5faa\u74b0\uff0c\u4e0d\u50c5\u662f\u7531\u65bc\u516c\u773e\u5c0d\u751f\u6210\u5f0f AI \u548c\u5176\u4ed6 AI \u5de5\u5177\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u52a0\uff0c\u9084\u7531\u65bc\u63a8\u5ee3\u8005\u548c\u79d1\u5b78\u5bb6\u5c0d\u6b64\u985e\u6280\u8853\u63d0\u51fa\u7684\u4e3b\u5f35\u3002\u7279\u5225\u662f\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u8072\u7a31\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u53ef\u4ee5\u901a\u904e\u5716\u9748\u6e2c\u8a66\u2014\u2014\u81ea 1950 \u5e74\u4ee3\u4ee5\u4f86 AI \u7684\u76ee\u6a19\u2014\u2014\u56e0\u6b64\u53ef\u4ee5\u300c\u601d\u8003\u300d\u3002\u9810\u6e2c\u9019\u5c07\u5c0d\u793e\u6703\u7522\u751f\u5927\u898f\u6a21\u5f71\u97ff\u3002\u7136\u800c\uff0c\u7d93\u904e\u4ed4\u7d30\u6aa2\u67e5\uff0c\u9019\u4e9b\u7814\u7a76\u90fd\u6c92\u6709\u5fe0\u5be6\u5730\u61c9\u7528\u5716\u9748\u7684\u539f\u59cb\u8aaa\u660e\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5c0d GPT-4-Turbo \u9032\u884c\u4e86\u4e00\u9805\u56b4\u683c\u7684\u5716\u9748\u6e2c\u8a66\uff0c\u56b4\u683c\u9075\u5b88\u5716\u9748\u5c0d\u4e09\u4eba\u6a21\u4eff\u904a\u6232\u7684\u8aaa\u660e\u3002\u5728\u5716\u9748\u7684\u8aaa\u660e\u6a21\u68f1\u5169\u53ef\u6216\u7f3a\u5931\u7684\u60c5\u6cc1\u4e0b\uff0c\u6211\u5011\u9075\u5faa\u65e2\u5b9a\u7684\u79d1\u5b78\u6a19\u6e96\u3002\u4f8b\u5982\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u5834\u8a08\u7b97\u6a5f\u6a21\u4eff\u4eba\u985e\u904a\u6232 (CIHG)\uff0c\u6c92\u6709\u9650\u5236\u6642\u9593\uff0c\u4e26\u9032\u884c\u4e86\u4e00\u5834\u7537\u4eba\u6a21\u4eff\u5973\u4eba\u904a\u6232 (MIWG) \u4f5c\u70ba\u57fa\u6e96\u3002\u9664\u4e86\u53c3\u8207\u8005\u6b63\u78ba\u5730\u8b58\u5225\u4e86 LLM \u4e4b\u5916\uff0c\u6240\u6709\u53c3\u8207\u8005\u90fd\u6b63\u78ba\u5730\u8b58\u5225\u4e86 LLM\uff0c\u9019\u8868\u660e\u7576\u4eca\u6700\u5148\u9032\u7684 LLM \u4e4b\u4e00\u7121\u6cd5\u901a\u904e\u56b4\u683c\u7684\u5716\u9748\u6e2c\u8a66\u3002\u6211\u5011\u5f97\u51fa\u7d50\u8ad6\uff0c\u6700\u8fd1\u5c0d\u6b64\u985e\u6a21\u578b\u7684\u8a87\u5f35\u8aaa\u6cd5\u5f97\u4e0d\u5230\u652f\u6301\uff0c\u4e5f\u4e0d\u4fdd\u8b49\u5c0d\u601d\u8003\u6a5f\u5668\u5c0d\u793e\u6703\u5f71\u97ff\u7684\u6a02\u89c0\u6216\u64d4\u6182\u3002", "author": "Sharon Temtsin et.al.", "authors": "Sharon Temtsin, Diane Proudfoot, David Kaber, Christoph Bartneck", "id": "2501.17629v1", "paper_url": "http://arxiv.org/abs/2501.17629v1", "repo": "null"}}