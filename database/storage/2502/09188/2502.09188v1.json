{"2502.09188": {"publish_time": "2025-02-13", "title": "Matina: A Large-Scale 73B Token Persian Text Corpus", "paper_summary": "Text corpora are essential for training models used in tasks like\nsummarization, translation, and large language models (LLMs). While various\nefforts have been made to collect monolingual and multilingual datasets in many\nlanguages, Persian has often been underrepresented due to limited resources for\ndata collection and preprocessing. Existing Persian datasets are typically\nsmall and lack content diversity, consisting mainly of weblogs and news\narticles. This shortage of high-quality, varied data has slowed the development\nof NLP models and open-source LLMs for Persian. Since model performance depends\nheavily on the quality of training data, we address this gap by introducing the\nMatina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed\nand deduplicated to ensure high data quality. We further assess its\neffectiveness by training and evaluating transformer-based models on key NLP\ntasks. Both the dataset and preprocessing codes are publicly available,\nenabling researchers to build on and improve this resource for future Persian\nNLP advancements.", "paper_summary_zh": "\u6587\u5b57\u8a9e\u6599\u5eab\u5c0d\u65bc\u8a13\u7df4\u7528\u65bc\u6458\u8981\u3001\u7ffb\u8b6f\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7b49\u4efb\u52d9\u7684\u6a21\u578b\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u5df2\u505a\u51fa\u5404\u7a2e\u52aa\u529b\u4f86\u6536\u96c6\u8a31\u591a\u8a9e\u8a00\u4e2d\u7684\u55ae\u8a9e\u548c\u591a\u8a9e\u8a00\u8cc7\u6599\u96c6\uff0c\u4f46\u7531\u65bc\u8cc7\u6599\u6536\u96c6\u548c\u9810\u8655\u7406\u8cc7\u6e90\u6709\u9650\uff0c\u6ce2\u65af\u8a9e\u5e38\u5e38\u4ee3\u8868\u6027\u4e0d\u8db3\u3002\u73fe\u6709\u7684\u6ce2\u65af\u8a9e\u8cc7\u6599\u96c6\u901a\u5e38\u5f88\u5c0f\uff0c\u800c\u4e14\u7f3a\u4e4f\u5167\u5bb9\u591a\u6a23\u6027\uff0c\u4e3b\u8981\u7531\u7db2\u8a8c\u548c\u65b0\u805e\u6587\u7ae0\u7d44\u6210\u3002\u9019\u7a2e\u512a\u8cea\u3001\u591a\u6a23\u5316\u8cc7\u6599\u7684\u77ed\u7f3a\u6e1b\u7de9\u4e86\u6ce2\u65af\u8a9e\u7684 NLP \u6a21\u578b\u548c\u958b\u6e90 LLM \u7684\u958b\u767c\u3002\u7531\u65bc\u6a21\u578b\u6548\u80fd\u9ad8\u5ea6\u4f9d\u8cf4\u8a13\u7df4\u8cc7\u6599\u7684\u54c1\u8cea\uff0c\u6211\u5011\u900f\u904e\u63a8\u51fa Matina \u8a9e\u6599\u5eab\u4f86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0cMatina \u8a9e\u6599\u5eab\u662f\u4e00\u500b\u65b0\u7684\u6ce2\u65af\u8a9e\u8cc7\u6599\u96c6\uff0c\u5305\u542b 72.9B \u500b\u5b57\u5143\uff0c\u7d93\u904e\u4ed4\u7d30\u9810\u8655\u7406\u548c\u53bb\u91cd\uff0c\u4ee5\u78ba\u4fdd\u8cc7\u6599\u54c1\u8cea\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e\u5728\u95dc\u9375 NLP \u4efb\u52d9\u4e0a\u8a13\u7df4\u548c\u8a55\u4f30\u57fa\u65bc\u8f49\u63db\u5668\u7684\u6a21\u578b\u4f86\u8a55\u4f30\u5176\u6709\u6548\u6027\u3002\u8cc7\u6599\u96c6\u548c\u9810\u8655\u7406\u7a0b\u5f0f\u78bc\u90fd\u662f\u516c\u958b\u7684\uff0c\u4f7f\u7814\u7a76\u4eba\u54e1\u80fd\u5920\u5efa\u7acb\u548c\u6539\u5584\u9019\u500b\u8cc7\u6e90\uff0c\u4ee5\u4fc3\u9032\u672a\u4f86\u7684\u6ce2\u65af\u8a9e NLP \u9032\u5c55\u3002", "author": "Sara Bourbour Hosseinbeigi et.al.", "authors": "Sara Bourbour Hosseinbeigi, Fatemeh Taherinezhad, Heshaam Faili, Hamed Baghbani, Fatemeh Nadi, Mostafa Amiri", "id": "2502.09188v1", "paper_url": "http://arxiv.org/abs/2502.09188v1", "repo": "null"}}