{"2407.01992": {"publish_time": "2024-07-02", "title": "Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?", "paper_summary": "Recent work shows that large language models (LLMs) can answer\nmultiple-choice questions using only the choices, but does this mean that MCQA\nleaderboard rankings of LLMs are largely influenced by abilities in\nchoices-only settings? To answer this, we use a contrast set that probes if\nLLMs over-rely on choices-only shortcuts in MCQA. While previous works build\ncontrast sets via expensive human annotations or model-generated data which can\nbe biased, we employ graph mining to extract contrast sets from existing MCQA\ndatasets. We use our method on UnifiedQA, a group of six commonsense reasoning\ndatasets with high choices-only accuracy, to build an 820-question contrast\nset. After validating our contrast set, we test 12 LLMs, finding that these\nmodels do not exhibit reliance on choice-only shortcuts when given both the\nquestion and choices. Thus, despite the susceptibility~of MCQA to high\nchoices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA\nleaderboards just due to their ability to exploit choices-only shortcuts.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4ec5\u4f7f\u7528\u9009\u9879\u5c31\u80fd\u56de\u7b54\u591a\u9879\u9009\u62e9\u9898\uff0c\u4f46\u8fd9\u662f\u5426\u8868\u793a\u591a\u9879\u9009\u62e9\u95ee\u7b54 (MCQA) \u6392\u884c\u699c\u4e0a\u7684 LLM \u4e3b\u8981\u53d7\u9650\u4e8e\u4ec5\u9009\u9879\u8bbe\u7f6e\u4e2d\u7684\u80fd\u529b\uff1f\u4e3a\u4e86\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u4f7f\u7528\u5bf9\u6bd4\u96c6\u6765\u63a2\u67e5 LLM \u5728 MCQA \u4e2d\u662f\u5426\u8fc7\u5ea6\u4f9d\u8d56\u4ec5\u9009\u9879\u6377\u5f84\u3002\u867d\u7136\u5148\u524d\u7684\u7814\u7a76\u901a\u8fc7\u6602\u8d35\u7684\u4eba\u5de5\u6ce8\u91ca\u6216\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u6a21\u578b\u751f\u6210\u6570\u636e\u6765\u6784\u5efa\u5bf9\u6bd4\u96c6\uff0c\u4f46\u6211\u4eec\u91c7\u7528\u56fe\u6316\u6398\u4ece\u73b0\u6709 MCQA \u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u5bf9\u6bd4\u96c6\u3002\u6211\u4eec\u4f7f\u7528\u6211\u4eec\u7684\u65b9\u6cd5\u5728 UnifiedQA \u4e0a\uff0c\u8fd9\u662f\u4e00\u4e2a\u7531\u516d\u4e2a\u5177\u6709\u9ad8\u4ec5\u9009\u9879\u51c6\u786e\u7387\u7684\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\u7ec4\u6210\u7684\u7ec4\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a 820 \u9898\u7684\u5bf9\u6bd4\u96c6\u3002\u5728\u9a8c\u8bc1\u6211\u4eec\u7684\u5bf9\u6bd4\u96c6\u540e\uff0c\u6211\u4eec\u6d4b\u8bd5\u4e86 12 \u4e2a LLM\uff0c\u53d1\u73b0\u5f53\u540c\u65f6\u7ed9\u51fa\u95ee\u9898\u548c\u9009\u9879\u65f6\uff0c\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4f1a\u8868\u73b0\u51fa\u5bf9\u4ec5\u9009\u9879\u6377\u5f84\u7684\u4f9d\u8d56\u3002\u56e0\u6b64\uff0c\u5c3d\u7ba1 MCQA \u5bb9\u6613\u53d7\u5230\u9ad8\u4ec5\u9009\u9879\u51c6\u786e\u7387\u7684\u5f71\u54cd\uff0c\u4f46\u6211\u4eec\u8ba4\u4e3a LLM \u5728 MCQA \u6392\u884c\u699c\u4e0a\u83b7\u5f97\u9ad8\u6392\u540d\u5e76\u975e\u4ec5\u4ec5\u56e0\u4e3a\u5b83\u4eec\u5229\u7528\u4ec5\u9009\u9879\u6377\u5f84\u7684\u80fd\u529b\u3002", "author": "Nishant Balepur et.al.", "authors": "Nishant Balepur, Rachel Rudinger", "id": "2407.01992v1", "paper_url": "http://arxiv.org/abs/2407.01992v1", "repo": "null"}}