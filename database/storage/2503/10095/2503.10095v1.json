{"2503.10095": {"publish_time": "2025-03-13", "title": "Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for Mental Health Prediction via Online Text", "paper_summary": "Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u5f9e\u7dda\u4e0a\u6587\u672c\u9810\u6e2c\u5fc3\u7406\u5065\u5eb7\u7d50\u679c\u7684\u6f5b\u529b\uff0c\u4f46\u50b3\u7d71\u7684\u5206\u985e\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\u548c\u7a69\u5065\u6027\u3002\u672c\u7814\u7a76\u8a55\u4f30\u4e86\u7d50\u69cb\u5316\u63a8\u7406\u6280\u8853\u2014\u2014\u601d\u7dad\u93c8 (CoT)\u3001\u81ea\u6d3d\u6027 (SC-CoT) \u548c\u601d\u7dad\u6a39 (ToT)\u2014\u2014\u4ee5\u63d0\u9ad8\u5f9e Reddit \u7372\u53d6\u7684\u591a\u500b\u5fc3\u7406\u5065\u5eb7\u6578\u64da\u96c6\u7684\u5206\u985e\u6e96\u78ba\u6027\u3002\u6211\u5011\u4f7f\u7528\u95dc\u9375\u6027\u80fd\u6307\u6a19\uff0c\u4f8b\u5982\u5e73\u8861\u6e96\u78ba\u5ea6\u3001F1 \u5206\u6578\u548c\u654f\u611f\u6027/\u7279\u7570\u6027\uff0c\u5206\u6790\u4e86\u63a8\u7406\u9a45\u52d5\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5305\u62ec\u96f6\u6a23\u672c CoT \u548c\u5c11\u6a23\u672c CoT\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u63a8\u7406\u589e\u5f37\u6280\u8853\u6bd4\u76f4\u63a5\u9810\u6e2c\u63d0\u9ad8\u4e86\u5206\u985e\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u8907\u96dc\u60c5\u6cc1\u4e0b\u3002\u8207\u57fa\u6e96\u6e2c\u8a66\uff08\u4f8b\u5982\u96f6\u6a23\u672c\u975e CoT \u63d0\u793a\uff09\u4ee5\u53ca\u5fae\u8abf\u7684\u9810\u8a13\u7df4\u8f49\u63db\u5668\uff08\u4f8b\u5982 BERT \u548c Mental-RoBerta\uff09\u4ee5\u53ca\u5fae\u8abf\u7684\u958b\u6e90 LLM\uff08\u4f8b\u5982 Mental Alpaca \u548c Mental-Flan-T5\uff09\u76f8\u6bd4\uff0c\u63a8\u7406\u9a45\u52d5\u7684 LLM \u5728 Dreaddit\uff08\u6bd4 M-LLM \u9ad8 0.52%\uff0c\u6bd4 BERT \u9ad8 0.82%\uff09\u548c SDCNL\uff08\u6bd4 M-LLM \u9ad8 4.67%\uff0c\u6bd4 BERT \u9ad8 2.17%\uff09\u7b49\u6578\u64da\u96c6\u4e0a\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\u3002\u7136\u800c\uff0c\u5728\u6291\u9b31\u56b4\u91cd\u7a0b\u5ea6\u65b9\u9762\u7684\u8868\u73fe\u6709\u6240\u4e0b\u964d\uff0c\u800c CSSRS \u9810\u6e2c\u8868\u660e\u5b58\u5728\u6578\u64da\u96c6\u7279\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u9019\u53ef\u80fd\u662f\u56e0\u70ba\u6211\u5011\u4f7f\u7528\u4e86\u66f4\u5ee3\u6cdb\u7684\u6e2c\u8a66\u96c6\u3002\u5728\u63d0\u793a\u7b56\u7565\u4e2d\uff0c\u5c11\u6a23\u672c CoT \u7684\u8868\u73fe\u4e00\u76f4\u512a\u65bc\u5176\u4ed6\u7b56\u7565\uff0c\u9019\u5f37\u5316\u4e86\u63a8\u7406\u9a45\u52d5\u7684 LLM \u7684\u6709\u6548\u6027\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u6578\u64da\u96c6\u7684\u53ef\u8b8a\u6027\u7a81\u986f\u4e86\u6a21\u578b\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91cb\u6027\u65b9\u9762\u7684\u6311\u6230\u3002\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u65bc\u63a8\u7406\u7684 LLM \u6280\u8853\u5728\u5fc3\u7406\u5065\u5eb7\u6587\u672c\u5206\u985e\u65b9\u9762\u7684\u7d9c\u5408\u57fa\u6e96\u3002\u5b83\u63d0\u4f9b\u4e86\u5c0d\u5176\u5728\u53ef\u64f4\u5c55\u81e8\u5e8a\u61c9\u7528\u4e2d\u7684\u6f5b\u529b\u7684\u898b\u89e3\uff0c\u540c\u6642\u4e5f\u6307\u51fa\u4e86\u672a\u4f86\u6539\u9032\u7684\u95dc\u9375\u6311\u6230\u3002</paragraph>\n", "author": "Avinash Patil et.al.", "authors": "Avinash Patil, Amardeep Kour Gedhu", "id": "2503.10095v1", "paper_url": "http://arxiv.org/abs/2503.10095v1", "repo": "null"}}