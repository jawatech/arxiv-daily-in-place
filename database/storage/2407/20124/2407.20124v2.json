{"2407.20124": {"publish_time": "2024-07-29", "title": "AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics", "paper_summary": "The rapid evolution of multimedia and computer vision technologies requires\nadaptive visual model deployment strategies to effectively handle diverse tasks\nand varying environments. This work introduces AxiomVision, a novel framework\nthat can guarantee accuracy by leveraging edge computing to dynamically select\nthe most efficient visual models for video analytics under diverse scenarios.\nUtilizing a tiered edge-cloud architecture, AxiomVision enables the deployment\nof a broad spectrum of visual models, from lightweight to complex DNNs, that\ncan be tailored to specific scenarios while considering camera source impacts.\nIn addition, AxiomVision provides three core innovations: (1) a dynamic visual\nmodel selection mechanism utilizing continual online learning, (2) an efficient\nonline method that efficiently takes into account the influence of the camera's\nperspective, and (3) a topology-driven grouping approach that accelerates the\nmodel selection process. With rigorous theoretical guarantees, these\nadvancements provide a scalable and effective solution for visual tasks\ninherent to multimedia systems, such as object detection, classification, and\ncounting. Empirically, AxiomVision achieves a 25.7\\% improvement in accuracy.", "paper_summary_zh": "\u591a\u5a92\u9ad4\u548c\u96fb\u8166\u8996\u89ba\u6280\u8853\u7684\u5feb\u901f\u6f14\u9032\u9700\u8981\u81ea\u9069\u61c9\u8996\u89ba\u6a21\u578b\u90e8\u7f72\u7b56\u7565\uff0c\u624d\u80fd\u6709\u6548\u8655\u7406\u5404\u7a2e\u4efb\u52d9\u548c\u8b8a\u52d5\u7684\u74b0\u5883\u3002\u9019\u9805\u5de5\u4f5c\u4ecb\u7d39\u4e86 AxiomVision\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u5b83\u80fd\u900f\u904e\u5229\u7528\u908a\u7de3\u904b\u7b97\u4f86\u52d5\u614b\u9078\u64c7\u5728\u5404\u7a2e\u5834\u666f\u4e0b\u6700\u6709\u6548\u7684\u8996\u89ba\u6a21\u578b\uff0c\u5f9e\u800c\u4fdd\u8b49\u6e96\u78ba\u6027\u3002\u5229\u7528\u5206\u5c64\u908a\u7de3\u96f2\u67b6\u69cb\uff0cAxiomVision \u80fd\u90e8\u7f72\u5ee3\u6cdb\u7684\u8996\u89ba\u6a21\u578b\uff0c\u5f9e\u8f15\u91cf\u7d1a\u5230\u8907\u96dc\u7684 DNN\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u6839\u64da\u7279\u5b9a\u5834\u666f\u9032\u884c\u8abf\u6574\uff0c\u540c\u6642\u8003\u616e\u76f8\u6a5f\u4f86\u6e90\u7684\u5f71\u97ff\u3002\u6b64\u5916\uff0cAxiomVision \u63d0\u4f9b\u4e86\u4e09\u9805\u6838\u5fc3\u5275\u65b0\uff1a(1) \u5229\u7528\u6301\u7e8c\u5728\u7dda\u5b78\u7fd2\u7684\u52d5\u614b\u8996\u89ba\u6a21\u578b\u9078\u64c7\u6a5f\u5236\uff0c(2) \u6709\u6548\u8003\u616e\u76f8\u6a5f\u8996\u89d2\u5f71\u97ff\u7684\u6709\u6548\u5728\u7dda\u65b9\u6cd5\uff0c\u4ee5\u53ca (3) \u52a0\u901f\u6a21\u578b\u9078\u64c7\u904e\u7a0b\u7684\u62d3\u64b2\u9a45\u52d5\u5206\u7d44\u65b9\u6cd5\u3002\u900f\u904e\u56b4\u8b39\u7684\u7406\u8ad6\u4fdd\u8b49\uff0c\u9019\u4e9b\u9032\u5c55\u70ba\u591a\u5a92\u9ad4\u7cfb\u7d71\u56fa\u6709\u7684\u8996\u89ba\u4efb\u52d9\uff08\u4f8b\u5982\u7269\u9ad4\u5075\u6e2c\u3001\u5206\u985e\u548c\u8a08\u6578\uff09\u63d0\u4f9b\u4e86\u53ef\u64f4\u5145\u4e14\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6839\u64da\u7d93\u9a57\uff0cAxiomVision \u5728\u6e96\u78ba\u5ea6\u4e0a\u7372\u5f97\u4e86 25.7% \u7684\u63d0\u5347\u3002", "author": "Xiangxiang Dai et.al.", "authors": "Xiangxiang Dai, Zeyu Zhang, Peng Yang, Yuedong Xu, Xutong Liu, John C. S. Lui", "id": "2407.20124v2", "paper_url": "http://arxiv.org/abs/2407.20124v2", "repo": "https://github.com/zeyuzhangzyz/axiomvision"}}