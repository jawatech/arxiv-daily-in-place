
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-10**|**LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models**|Feng Li et.al.|[2407.07895v1](http://arxiv.org/abs/2407.07895v1)|[link](https://github.com/LLaVA-VL/LLaVA-NeXT)|
|**2024-07-10**|**Training on the Test Task Confounds Evaluation and Emergence**|Ricardo Dominguez-Olmedo et.al.|[2407.07890v1](http://arxiv.org/abs/2407.07890v1)|[link](https://github.com/socialfoundations/training-on-the-test-task)|
|**2024-07-10**|**Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization**|Junkang Wu et.al.|[2407.07880v1](http://arxiv.org/abs/2407.07880v1)|[link](https://github.com/junkangwu/dr_dpo)|
|**2024-07-10**|**Generative Image as Action Models**|Mohit Shridhar et.al.|[2407.07875v1](http://arxiv.org/abs/2407.07875v1)|null|
|**2024-07-10**|**Toto: Time Series Optimized Transformer for Observability**|Ben Cohen et.al.|[2407.07874v2](http://arxiv.org/abs/2407.07874v2)|null|
|**2024-07-10**|**FACTS About Building Retrieval Augmented Generation-based Chatbots**|Rama Akkiraju et.al.|[2407.07858v1](http://arxiv.org/abs/2407.07858v1)|null|
|**2024-07-10**|**Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers**|Cody Wild et.al.|[2407.07848v1](http://arxiv.org/abs/2407.07848v1)|null|
|**2024-07-10**|**Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison**|Qian Yang et.al.|[2407.07840v1](http://arxiv.org/abs/2407.07840v1)|null|
|**2024-07-10**|**RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation**|Tao Li et.al.|[2407.07835v1](http://arxiv.org/abs/2407.07835v1)|[link](https://github.com/tourlics/robus_dataset)|
|**2024-07-10**|**Transformer Alignment in Large Language Models**|Murdock Aubry et.al.|[2407.07810v1](http://arxiv.org/abs/2407.07810v1)|null|
|**2024-07-10**|**ROSA: Random Subspace Adaptation for Efficient Fine-Tuning**|Marawan Gamal Abdel Hameed et.al.|[2407.07802v1](http://arxiv.org/abs/2407.07802v1)|[link](https://github.com/rosa-paper/rosa)|
|**2024-07-10**|**AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning**|Jongsuk Kim et.al.|[2407.07801v2](http://arxiv.org/abs/2407.07801v2)|null|
|**2024-07-10**|**Attribute or Abstain: Large Language Models as Long Document Assistants**|Jan Buchmann et.al.|[2407.07799v1](http://arxiv.org/abs/2407.07799v1)|[link](https://github.com/ukplab/arxiv2024-attribute-or-abstain)|
|**2024-07-10**|**Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard**|Oguzhan Topsakal et.al.|[2407.07796v2](http://arxiv.org/abs/2407.07796v2)|[link](https://github.com/research-outcome/llm-game-benchmark)|
|**2024-07-10**|**Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities**|Tianjie Ju et.al.|[2407.07791v1](http://arxiv.org/abs/2407.07791v1)|[link](https://github.com/Jometeorie/KnowledgeSpread)|
|**2024-07-10**|**WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment**|Jiefu Ou et.al.|[2407.07778v1](http://arxiv.org/abs/2407.07778v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v1](http://arxiv.org/abs/2407.07775v1)|null|
|**2024-07-10**|**Learning Spatial-Semantic Features for Robust Video Object Segmentation**|Xin Li et.al.|[2407.07760v1](http://arxiv.org/abs/2407.07760v1)|null|
|**2024-07-10**|**Fine-Tuning Large Language Models with User-Level Differential Privacy**|Zachary Charles et.al.|[2407.07737v1](http://arxiv.org/abs/2407.07737v1)|null|
|**2024-07-10**|**SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis**|Zihao Wang et.al.|[2407.07728v2](http://arxiv.org/abs/2407.07728v2)|null|
|**2024-07-10**|**PaliGemma: A versatile 3B VLM for transfer**|Lucas Beyer et.al.|[2407.07726v1](http://arxiv.org/abs/2407.07726v1)|null|
|**2024-07-10**|**Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control**|Elahe Delavari et.al.|[2407.07684v1](http://arxiv.org/abs/2407.07684v1)|null|
|**2024-07-10**|**The Language of Weather: Social Media Reactions to Weather Accounting for Climatic and Linguistic Baselines**|James C. Young et.al.|[2407.07683v1](http://arxiv.org/abs/2407.07683v1)|null|
|**2024-07-10**|**Why should we ever automate moral decision making?**|Vincent Conitzer et.al.|[2407.07671v1](http://arxiv.org/abs/2407.07671v1)|null|
|**2024-07-10**|**How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning**|Giuseppe Serra et.al.|[2407.07668v1](http://arxiv.org/abs/2407.07668v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry**|Martin Lindström et.al.|[2407.07664v1](http://arxiv.org/abs/2407.07664v1)|[link](https://github.com/martinlindstrom/coding_theoretic_hpl)|
|**2024-07-10**|**Tuning Vision-Language Models with Candidate Labels by Prompt Alignment**|Zhifang Zhang et.al.|[2407.07638v2](http://arxiv.org/abs/2407.07638v2)|null|
|**2024-07-10**|**A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training**|Michał Perełkiewicz et.al.|[2407.07630v1](http://arxiv.org/abs/2407.07630v1)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**The Computational Learning of Construction Grammars: State of the Art and Prospective Roadmap**|Jonas Doumen et.al.|[2407.07606v1](http://arxiv.org/abs/2407.07606v1)|null|
|**2024-07-10**|**Early Explorations of Lightweight Models for Wound Segmentation on Mobile Devices**|Vanessa Borst et.al.|[2407.07605v2](http://arxiv.org/abs/2407.07605v2)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model**|Yatai Ji et.al.|[2407.07577v1](http://arxiv.org/abs/2407.07577v1)|[link](https://github.com/jiyt17/ida-vlm)|
|**2024-07-10**|**HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing**|Arnon Turetzky et.al.|[2407.07566v1](http://arxiv.org/abs/2407.07566v1)|null|
|**2024-07-10**|**On Leakage of Code Generation Evaluation Datasets**|Alexandre Matton et.al.|[2407.07565v2](http://arxiv.org/abs/2407.07565v2)|null|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|null|
|**2024-07-10**|**Disentangling Masked Autoencoders for Unsupervised Domain Generalization**|An Zhang et.al.|[2407.07544v1](http://arxiv.org/abs/2407.07544v1)|[link](https://github.com/rookiehb/dismae)|
|**2024-07-10**|**Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search**|Kirill Paramonov et.al.|[2407.07541v1](http://arxiv.org/abs/2407.07541v1)|null|
|**2024-07-10**|**Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models**|Jin Liu et.al.|[2407.07531v1](http://arxiv.org/abs/2407.07531v1)|null|
|**2024-07-10**|**How Aligned are Different Alignment Metrics?**|Jannis Ahlert et.al.|[2407.07530v1](http://arxiv.org/abs/2407.07530v1)|null|
|**2024-07-10**|**CHILLI: A data context-aware perturbation method for XAI**|Saif Anwar et.al.|[2407.07521v1](http://arxiv.org/abs/2407.07521v1)|null|
|**2024-07-10**|**Generative AI for RF Sensing in IoT systems**|Li Wang et.al.|[2407.07506v1](http://arxiv.org/abs/2407.07506v1)|null|
|**2024-07-10**|**Bucket Pre-training is All You Need**|Hongtao Liu et.al.|[2407.07495v1](http://arxiv.org/abs/2407.07495v1)|null|
|**2024-07-10**|**FUNAvg: Federated Uncertainty Weighted Averaging for Datasets with Diverse Labels**|Malte Tölle et.al.|[2407.07488v1](http://arxiv.org/abs/2407.07488v1)|[link](https://github.com/cardio-ai/funavg)|
|**2024-07-10**|**Review-LLM: Harnessing Large Language Models for Personalized Review Generation**|Qiyao Peng et.al.|[2407.07487v1](http://arxiv.org/abs/2407.07487v1)|null|
|**2024-07-10**|**Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations**|Luca Marzari et.al.|[2407.07482v1](http://arxiv.org/abs/2407.07482v1)|[link](https://github.com/lmarza/apas)|
|**2024-07-10**|**Rectifier: Code Translation with Corrector via LLMs**|Xin Yin et.al.|[2407.07472v1](http://arxiv.org/abs/2407.07472v1)|[link](https://github.com/vinci-grape/rectifier)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-10**|**Secondary Structure-Guided Novel Protein Sequence Generation with Latent Graph Diffusion**|Yutong Hu et.al.|[2407.07443v1](http://arxiv.org/abs/2407.07443v1)|[link](https://github.com/riacd/cpdiffusion-ss)|
|**2024-07-10**|**Controllable Navigation Instruction Generation with Chain of Thought Prompting**|Xianghao Kong et.al.|[2407.07433v1](http://arxiv.org/abs/2407.07433v1)|[link](https://github.com/refkxh/c-instructor)|
|**2024-07-10**|**Out-of-distribution generalisation in spoken language understanding**|Dejan Porjazovski et.al.|[2407.07425v1](http://arxiv.org/abs/2407.07425v1)|[link](https://github.com/aalto-speech/slurpfood)|
|**2024-07-10**|**KpopMT: Translation Dataset with Terminology for Kpop Fandom**|JiWoo Kim et.al.|[2407.07413v1](http://arxiv.org/abs/2407.07413v1)|[link](https://github.com/skswldndi/KpopMT)|
|**2024-07-10**|**Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**|Seonghoon Yu et.al.|[2407.07412v1](http://arxiv.org/abs/2407.07412v1)|[link](https://github.com/seonghoon-yu/pseudo-ris)|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems**|Chashi Mahiul Islam et.al.|[2407.07392v1](http://arxiv.org/abs/2407.07392v1)|null|
|**2024-07-10**|**Automatic Extraction of Disease Risk Factors from Medical Publications**|Maxim Rubchinsky et.al.|[2407.07373v1](http://arxiv.org/abs/2407.07373v1)|[link](https://github.com/maximrub/diseases-risk-factors)|
|**2024-07-10**|**LokiLM: Technical Report**|Justin Kiefel et.al.|[2407.07370v1](http://arxiv.org/abs/2407.07370v1)|null|
|**2024-07-10**|**Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?**|Zemian Ke et.al.|[2407.07364v1](http://arxiv.org/abs/2407.07364v1)|null|
|**2024-07-10**|**Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture**|Jiayang Song et.al.|[2407.07342v1](http://arxiv.org/abs/2407.07342v1)|null|
|**2024-07-10**|**MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization**|Gaurav Sahu et.al.|[2407.07341v1](http://arxiv.org/abs/2407.07341v1)|null|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models**|Messi H. J. Lee et.al.|[2407.07329v1](http://arxiv.org/abs/2407.07329v1)|null|
|**2024-07-10**|**Fuse, Reason and Verify: Geometry Problem Solving with Parsed Clauses from Diagram**|Ming-Liang Zhang et.al.|[2407.07327v1](http://arxiv.org/abs/2407.07327v1)|null|
|**2024-07-10**|**HiLight: Technical Report on the Motern AI Video Language Model**|Zhiting Wang et.al.|[2407.07325v2](http://arxiv.org/abs/2407.07325v2)|null|
|**2024-07-10**|**RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension**|Hung Phan et.al.|[2407.07321v1](http://arxiv.org/abs/2407.07321v1)|null|
|**2024-07-10**|**ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models**|Benjamin Ascoli et.al.|[2407.07313v1](http://arxiv.org/abs/2407.07313v1)|null|
|**2024-07-10**|**ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting**|Luoxiao Yang et.al.|[2407.07311v1](http://arxiv.org/abs/2407.07311v1)|[link](https://github.com/ikeyang/vitime)|
|**2024-07-10**|**Inference Performance Optimization for Large Language Models on CPUs**|Pujiang He et.al.|[2407.07304v1](http://arxiv.org/abs/2407.07304v1)|[link](https://github.com/intel/xfastertransformer)|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-10**|**Structural Design Through Reinforcement Learning**|Thomas Rochefort-Beaudoin et.al.|[2407.07288v1](http://arxiv.org/abs/2407.07288v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**Exploring Camera Encoder Designs for Autonomous Driving Perception**|Barath Lakshmanan et.al.|[2407.07276v1](http://arxiv.org/abs/2407.07276v1)|null|
|**2024-07-09**|**Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support**|Karn N. Watcharasupat et.al.|[2407.07275v1](http://arxiv.org/abs/2407.07275v1)|null|
|**2024-07-09**|**Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models**|Jupinder Parmar et.al.|[2407.07263v1](http://arxiv.org/abs/2407.07263v1)|null|
|**2024-07-09**|**Identification of emotions on Twitter during the 2022 electoral process in Colombia**|Juan Jose Iguaran Fernandez et.al.|[2407.07258v1](http://arxiv.org/abs/2407.07258v1)|null|
|**2024-07-09**|**Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models**|Yun Qi Li et.al.|[2407.07229v1](http://arxiv.org/abs/2407.07229v1)|[link](https://github.com/astrodatalab/li2024_public)|
|**2024-07-09**|**ConvNLP: Image-based AI Text Detection**|Suriya Prakash Jambunathan et.al.|[2407.07225v1](http://arxiv.org/abs/2407.07225v1)|null|
|**2024-07-09**|**AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**|Jiaxi Cui et.al.|[2407.07094v1](http://arxiv.org/abs/2407.07094v1)|[link](https://github.com/pandavt/datatager)|
|**2024-07-09**|**FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**|Liqun Ma et.al.|[2407.07093v1](http://arxiv.org/abs/2407.07093v1)|[link](https://github.com/liqunma/fbi-llm)|
|**2024-07-09**|**Safe and Reliable Training of Learning-Based Aerospace Controllers**|Udayan Mandal et.al.|[2407.07088v1](http://arxiv.org/abs/2407.07088v1)|[link](https://github.com/neuralnetworkverification/artifact-dasc-docking)|
|**2024-07-09**|**CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**|Tong Chen et.al.|[2407.07087v1](http://arxiv.org/abs/2407.07087v1)|[link](https://github.com/chentong0/copy-bench)|
|**2024-07-09**|**Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**|Logan Cross et.al.|[2407.07086v1](http://arxiv.org/abs/2407.07086v1)|[link](https://github.com/locross93/hypothetical-minds)|
|**2024-07-09**|**Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**|Shaltiel Shmidman et.al.|[2407.07080v1](http://arxiv.org/abs/2407.07080v1)|null|
|**2024-07-09**|**ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**|Shaozhe Hao et.al.|[2407.07077v1](http://arxiv.org/abs/2407.07077v1)|[link](https://github.com/haoosz/conceptexpress)|
|**2024-07-09**|**Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**|Yung-Sung Chuang et.al.|[2407.07071v1](http://arxiv.org/abs/2407.07071v1)|[link](https://github.com/voidism/lookback-lens)|
|**2024-07-09**|**Prompting Techniques for Secure Code Generation: A Systematic Investigation**|Catherine Tony et.al.|[2407.07064v1](http://arxiv.org/abs/2407.07064v1)|null|
|**2024-07-09**|**Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**|Weize Chen et.al.|[2407.07061v2](http://arxiv.org/abs/2407.07061v2)|[link](https://github.com/openbmb/ioa)|
|**2024-07-09**|**CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**|Yangmin Li et.al.|[2407.07046v1](http://arxiv.org/abs/2407.07046v1)|null|
|**2024-07-09**|**Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**|Christian Riefolo et.al.|[2407.07045v1](http://arxiv.org/abs/2407.07045v1)|[link](https://github.com/thescreamingmonkey/mbm-em)|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**|Yue Zhang et.al.|[2407.07035v1](http://arxiv.org/abs/2407.07035v1)|null|
|**2024-07-09**|**Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**|Daiqing Wu et.al.|[2407.07026v1](http://arxiv.org/abs/2407.07026v1)|null|
|**2024-07-09**|**Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**|Jeongseok Hyun et.al.|[2407.07024v1](http://arxiv.org/abs/2407.07024v1)|[link](https://github.com/hyunjs/stov-tal)|
|**2024-07-09**|**Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**|Haicheng Liao et.al.|[2407.07020v1](http://arxiv.org/abs/2407.07020v1)|null|
|**2024-07-09**|**Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**|Inwon Kang et.al.|[2407.07019v1](http://arxiv.org/abs/2407.07019v1)|null|

#### Abstracts
##### **LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models**
2407.07895v1 by Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, Chunyuan Li

Visual instruction tuning has made considerable strides in enhancing the
capabilities of Large Multimodal Models (LMMs). However, existing open LMMs
largely focus on single-image tasks, their applications to multi-image
scenarios remains less explored. Additionally, prior LMM research separately
tackles different scenarios, leaving it impossible to generalize cross
scenarios with new emerging capabilities. To this end, we introduce
LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame
(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To
enable these capabilities, we regard the interleaved data format as a general
template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4
primary domains with 14 tasks and 41 datasets. We also curate the
LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance
of LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading
results in multi-image, video, and 3D benchmarks, while maintaining the
performance of single-image tasks. Besides, our model also exhibits several
emerging capabilities, e.g., transferring tasks across different settings and
modalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT

摘要：視覺指令調整已在提升大型多模態模型 (LMM) 能力方面取得顯著進展。然而，現有的開放式 LMM 主要專注於單一影像任務，其在多影像場景中的應用仍較少探索。此外，先前的 LMM 研究分別處理不同的場景，導致無法透過新興能力對跨場景進行概括。為此，我們引入了 LLaVA-NeXT-Interleave，它同時處理 LMM 中的多影像、多幀（影片）、多視角（3D）和多區塊（單一影像）場景。為了啟用這些能力，我們將交錯資料格式視為一般範本，並編譯包含 1,177.6k 個樣本的 M4-Instruct 資料集，涵蓋 4 個主要領域，包含 14 個任務和 41 個資料集。我們也策劃了 LLaVA-Interleave Bench，以全面評估 LMM 的多影像效能。透過廣泛的實驗，LLaVA-NeXT-Interleave 在多影像、影片和 3D 基準測試中取得領先的結果，同時維持單一影像任務的效能。此外，我們的模型也展現了多項新興能力，例如在不同設定和模態之間轉移任務。程式碼可在 https://github.com/LLaVA-VL/LLaVA-NeXT 取得

##### **Training on the Test Task Confounds Evaluation and Emergence**
2407.07890v1 by Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt

We study a fundamental problem in the evaluation of large language models
that we call training on the test task. Unlike wrongful practices like training
on the test data, leakage, or data contamination, training on the test task is
not a malpractice. Rather, the term describes a growing set of techniques to
include task-relevant data in the pretraining stage of a language model. We
demonstrate that training on the test task confounds both relative model
evaluations and claims about emergent capabilities. We argue that the seeming
superiority of one model family over another may be explained by a different
degree of training on the test task. To this end, we propose an effective
method to adjust for training on the test task by fine-tuning each model under
comparison on the same task-relevant data before evaluation. We then show that
instances of emergent behavior largely vanish once we adjust for training on
the test task. This also applies to reported instances of emergent behavior
that cannot be explained by the choice of evaluation metric. Our work promotes
a new perspective on the evaluation of large language models with broad
implications for benchmarking and the study of emergent capabilities.

摘要：我們研究大型語言模型評估中一個基本的難題，我們稱之為測試任務訓練。與訓練測試資料、洩漏或資料污染等不當做法不同，訓練測試任務並非一種不正當行為。反之，此術語描述了一組日益增長的技術，用於在語言模型的預訓練階段納入與任務相關的資料。我們證明，訓練測試任務會混淆相對模型評估和關於新興能力的主張。我們認為，一個模型家族看似優於另一個模型家族，可能是由於訓練測試任務的程度不同。為此，我們提出了一種有效的方法來調整訓練測試任務，方法是在評估之前使用相同的任務相關資料對每個模型進行微調。然後，我們表明，一旦我們調整訓練測試任務，新興行為的實例就會在很大程度上消失。這也適用於無法用評估指標的選擇來解釋的新興行為的報告實例。我們的研究促進了對大型語言模型評估的新觀點，對基準測試和新興能力的研究具有廣泛的影響。

##### **Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization**
2407.07880v1 by Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He

This study addresses the challenge of noise in training datasets for Direct
Preference Optimization (DPO), a method for aligning Large Language Models
(LLMs) with human preferences. We categorize noise into pointwise noise, which
includes low-quality data points, and pairwise noise, which encompasses
erroneous data pair associations that affect preference rankings. Utilizing
Distributionally Robust Optimization (DRO), we enhance DPO's resilience to
these types of noise. Our theoretical insights reveal that DPO inherently
embeds DRO principles, conferring robustness to pointwise noise, with the
regularization coefficient $\beta$ playing a critical role in its noise
resistance. Extending this framework, we introduce Distributionally
Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing
against worst-case pairwise scenarios. The novel hyperparameter $\beta'$ in Dr.
DPO allows for fine-tuned control over data pair reliability, providing a
strategic balance between exploration and exploitation in noisy training
environments. Empirical evaluations demonstrate that Dr. DPO substantially
improves the quality of generated text and response accuracy in preference
datasets, showcasing enhanced performance in both noisy and noise-free
settings. The code is available at https://github.com/junkangwu/Dr_DPO.

摘要：本研究探讨了直接偏好优化 (DPO) 训练数据集中的噪声挑战，DPO 是一种将大型语言模型 (LLM) 与人类偏好相匹配的方法。我们将噪声分为逐点噪声，其中包括低质量数据点，以及成对噪声，其中包括影响偏好排名的错误数据对关联。利用分布鲁棒优化 (DRO)，我们增强了 DPO 对这些类型噪声的弹性。我们的理论见解表明，DPO 本质上嵌入了 DRO 原则，赋予了对逐点噪声的鲁棒性，其中正则化系数 $\beta$ 在其抗噪声中起着至关重要的作用。扩展此框架，我们引入了分布鲁棒化 DPO (Dr. DPO)，它通过针对最坏情况成对场景进行优化来集成成对鲁棒性。Dr. DPO 中的新型超参数 $\beta'$ 允许对数据对可靠性进行微调控制，在嘈杂的训练环境中提供探索和利用之间的战略平衡。经验评估表明，Dr. DPO 在首选数据集中的生成文本质量和响应准确性方面有了实质性的提高，在有噪声和无噪声设置中都展示了增强的性能。代码可在 https://github.com/junkangwu/Dr_DPO 获得。

##### **Generative Image as Action Models**
2407.07875v1 by Mohit Shridhar, Yat Long Lo, Stephen James

Image-generation diffusion models have been fine-tuned to unlock new
capabilities such as image-editing and novel view synthesis. Can we similarly
unlock image-generation models for visuomotor control? We present GENIMA, a
behavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'
as targets on RGB images. These images are fed into a controller that maps the
visual targets into a sequence of joint-positions. We study GENIMA on 25
RLBench and 9 real-world manipulation tasks. We find that, by lifting actions
into image-space, internet pre-trained diffusion models can generate policies
that outperform state-of-the-art visuomotor approaches, especially in
robustness to scene perturbations and generalizing to novel objects. Our method
is also competitive with 3D agents, despite lacking priors such as depth,
keypoints, or motion-planners.

摘要：影像產生擴散模型已經經過微調以解鎖新的能力，例如影像編輯和新視圖合成。我們能用類似的方式解鎖影像產生模型用於視動控制嗎？我們提出 GENIMA，一種行為複製代理，它微調 Stable Diffusion 以在 RGB 影像上「繪製關節動作」作為目標。這些影像會輸入到控制器中，控制器會將視覺目標對應到一系列關節位置。我們在 25 個 RLBench 和 9 個真實世界的操作任務中研究 GENIMA。我們發現，透過將動作提升到影像空間，網際網路預訓練擴散模型可以產生策略，其表現優於最先進的視動控制方法，尤其是在場景擾動的穩健性以及對新物體的泛化方面。我們的模型即使缺乏深度、關鍵點或動作規劃器等先驗知識，也能與 3D 代理競爭。

##### **Toto: Time Series Optimized Transformer for Observability**
2407.07874v2 by Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal

This technical report describes the Time Series Optimized Transformer for
Observability (Toto), a new state of the art foundation model for time series
forecasting developed by Datadog. In addition to advancing the state of the art
on generalized time series benchmarks in domains such as electricity and
weather, this model is the first general-purpose time series forecasting
foundation model to be specifically tuned for observability metrics.
  Toto was trained on a dataset of one trillion time series data points, the
largest among all currently published time series foundation models. Alongside
publicly available time series datasets, 75% of the data used to train Toto
consists of fully anonymous numerical metric data points from the Datadog
platform.
  In our experiments, Toto outperforms existing time series foundation models
on observability data. It does this while also excelling at general-purpose
forecasting tasks, achieving state-of-the-art zero-shot performance on multiple
open benchmark datasets.

摘要：這份技術報告描述了觀測時間序列最佳化Transformer (Toto)，這是一個由 Datadog 開發的新型時間序列預測基礎模型。除了提升電力和天氣等領域的廣泛時間序列基準的技術水準外，這個模型也是第一個專門針對可觀察性指標調整的通用時間序列預測基礎模型。

Toto 是以一個擁有 1 兆筆時間序列資料點的資料集訓練而成的，在目前已發布的所有時間序列基礎模型中規模最大。除了公開的時間序列資料集，用於訓練 Toto 的資料有 75% 來自 Datadog 平台的完全匿名數值指標資料點。

在我們的實驗中，Toto 在可觀察性資料上勝過現有的時間序列基礎模型。它在執行此操作的同時，也在通用預測任務中表現出色，在多個開放基準資料集上達成最先進的零次學習效能。

##### **FACTS About Building Retrieval Augmented Generation-based Chatbots**
2407.07858v1 by Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano

Enterprise chatbots, powered by generative AI, are emerging as key
applications to enhance employee productivity. Retrieval Augmented Generation
(RAG), Large Language Models (LLMs), and orchestration frameworks like
Langchain and Llamaindex are crucial for building these chatbots. However,
creating effective enterprise chatbots is challenging and requires meticulous
RAG pipeline engineering. This includes fine-tuning embeddings and LLMs,
extracting documents from vector databases, rephrasing queries, reranking
results, designing prompts, honoring document access controls, providing
concise responses, including references, safeguarding personal information, and
building orchestration agents. We present a framework for building RAG-based
chatbots based on our experience with three NVIDIA chatbots: for IT/HR
benefits, financial earnings, and general content. Our contributions are
three-fold: introducing the FACTS framework (Freshness, Architectures, Cost,
Testing, Security), presenting fifteen RAG pipeline control points, and
providing empirical results on accuracy-latency tradeoffs between large and
small LLMs. To the best of our knowledge, this is the first paper of its kind
that provides a holistic view of the factors as well as solutions for building
secure enterprise-grade chatbots."

摘要：由生成式 AI 驅動的企業聊天機器人，正作為提升員工生產力的關鍵應用程式浮現。檢索擴充生成 (RAG)、大型語言模型 (LLM) 和 Langchain 與 Llamaindex 等編排架構對於建構這些聊天機器人至關重要。然而，建立有效的企業聊天機器人具有挑戰性，需要細緻的 RAG 管道工程。這包括微調嵌入和 LLM、從向量資料庫中萃取文件、改寫查詢、重新排列結果、設計提示、遵守文件存取控制、提供簡潔的回應、包括參考資料、保障個人資訊，以及建構編排代理。我們根據在 NVIDIA 的三個聊天機器人（針對 IT/HR 福利、財務收益和一般內容）的經驗，提出了一個建構基於 RAG 的聊天機器人的架構。我們的貢獻有三方面：引入 FACTS 架構（新鮮度、架構、成本、測試、安全性）、提出十五個 RAG 管道控制點，以及提供大型和小型 LLM 之間準確度-延遲權衡的經驗結果。據我們所知，這是第一篇提供全面觀點的論文，探討建構安全企業級聊天機器人的因素和解決方案。

##### **Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers**
2407.07848v1 by Cody Wild, Jesper Anderson

Previous work has demonstrated that MLPs within ReLU Transformers exhibit
high levels of sparsity, with many of their activations equal to zero for any
given token. We build on that work to more deeply explore how token-level
sparsity evolves over the course of training, and how it connects to broader
sparsity patterns over the course of a sequence or batch, demonstrating that
the different layers within small transformers exhibit distinctly
layer-specific patterns on both of these fronts. In particular, we demonstrate
that the first and last layer of the network have distinctive and in many ways
inverted relationships to sparsity, and explore implications for the structure
of feature representations being learned at different depths of the model. We
additionally explore the phenomenon of ReLU dimensions "turning off", and show
evidence suggesting that "neuron death" is being primarily driven by the
dynamics of training, rather than simply occurring randomly or accidentally as
a result of outliers.

摘要：先前的研究表明，ReLU Transformer 中的 MLP 具有高度的稀疏性，其中许多激活对于任何给定的标记都等于零。我们基于这项研究更深入地探讨标记级稀疏性如何在训练过程中演变，以及它如何连接到序列或批次过程中的更广泛稀疏性模式，证明小 Transformer 中的不同层在这些方面都表现出明显不同的特定于层的模式。特别是，我们证明网络的第一层和最后一层具有独特且在许多方面与稀疏性成反比的关系，并探讨对在模型的不同深度处学习的特征表示的结构的影响。我们还探讨了 ReLU 维度“关闭”的现象，并展示了证据表明“神经元死亡”主要是由训练动态驱动的，而不是仅仅由于异常值而随机或偶然发生的。

##### **Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison**
2407.07840v1 by Qian Yang, Weixiang Yan, Aishwarya Agrawal

Despite tremendous advancements, current state-of-the-art Vision-Language
Models (VLMs) are still far from perfect. They tend to hallucinate and may
generate biased responses. In such circumstances, having a way to assess the
reliability of a given response generated by a VLM is quite useful. Existing
methods, such as estimating uncertainty using answer likelihoods or
prompt-based confidence generation, often suffer from overconfidence. Other
methods use self-consistency comparison but are affected by confirmation
biases. To alleviate these, we propose \textbf{De}compose and \textbf{C}ompare
\textbf{C}onsistency (\texttt{DeCC}) for reliability measurement. By comparing
the consistency between the direct answer generated using the VLM's internal
reasoning process, and the indirect answers obtained by decomposing the
question into sub-questions and reasoning over the sub-answers produced by the
VLM, \texttt{DeCC} measures the reliability of VLM's direct answer. Experiments
across six vision-language tasks with three VLMs show \texttt{DeCC}'s
reliability estimation achieves better correlation with task accuracy compared
to the existing methods.

摘要：儘管有長足的進展，目前的最新視覺語言模型（VLM）仍遠未完美。它們傾向於產生幻覺，並且可能會產生有偏見的回應。在這種情況下，有一種方法可以評估 VLM 生成的特定回應的可靠性非常有用。現有的方法，例如使用答案可能性估計不確定性或基於提示的信心生成，通常會過於自信。其他方法使用自我一致性比較，但會受到確認偏誤的影響。為了緩解這些問題，我們提出\textbf{分}解和\textbf{比}較\textbf{一}致性（\texttt{DeCC}）以進行可靠性測量。透過比較使用 VLM 內部推理過程產生的直接答案與透過將問題分解成子問題並對 VLM 產生的子答案進行推理而獲得的間接答案之間的一致性，\texttt{DeCC} 測量 VLM 直接答案的可靠性。使用三個 VLM 進行的六項視覺語言任務的實驗表明，與現有方法相比，\texttt{DeCC} 的可靠性估計與任務準確性具有更好的相關性。

##### **RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation**
2407.07835v1 by Tao Li, Ruihang Li, Huangnan Zheng, Shanding Ye, Shijian Li, Zhijie Pan

Automated 3D city generation, focusing on road networks and building layouts,
is in high demand for applications in urban design, multimedia games and
autonomous driving simulations. The surge of generative AI facilitates
designing city layouts based on deep learning models. However, the lack of
high-quality datasets and benchmarks hinders the progress of these data-driven
methods in generating road networks and building layouts. Furthermore, few
studies consider urban characteristics, which generally take graphics as
analysis objects and are crucial for practical applications, to control the
generative process. To alleviate these problems, we introduce a multimodal
dataset with accompanying evaluation metrics for controllable generation of
Road networks and Building layouts (RoBus), which is the first and largest
open-source dataset in city generation so far. RoBus dataset is formatted as
images, graphics and texts, with $72,400$ paired samples that cover around
$80,000km^2$ globally. We analyze the RoBus dataset statistically and validate
the effectiveness against existing road networks and building layouts
generation methods. Additionally, we design new baselines that incorporate
urban characteristics, such as road orientation and building density, in the
process of generating road networks and building layouts using the RoBus
dataset, enhancing the practicality of automated urban design. The RoBus
dataset and related codes are published at
https://github.com/tourlics/RoBus_Dataset.

摘要：自動化 3D 城市生成，專注於道路網路和建築物配置，
在城市設計、多媒體遊戲和自動駕駛模擬中廣受歡迎。生成式 AI 的激增促進
基於深度學習模型設計城市配置。然而，缺乏
高品質的資料集和基準阻礙了這些資料驅動
方法在生成道路網路和建築物配置方面的進展。此外，很少
研究考慮城市特徵，這些特徵通常將圖形作為
分析物件，並且對於實際應用至關重要，以控制
生成過程。為了緩解這些問題，我們引入了多模式
資料集，並附有評估指標，用於可控生成
道路網路和建築物配置 (RoBus)，這是目前第一個也是最大的
開放原始碼城市生成資料集。RoBus 資料集格式化為
影像、圖形和文字，配對樣本數為 $72,400$，涵蓋全球約
$80,000km^2$。我們對 RoBus 資料集進行統計分析，並驗證
其對現有道路網路和建築物配置的有效性
生成方法。此外，我們設計了新的基準，將
城市特徵，例如道路方向和建築物密度，納入
使用 RoBus 生成道路網路和建築物配置的過程中
資料集，增強自動化城市設計的實用性。 RoBus
資料集和相關程式碼已發布於
https://github.com/tourlics/RoBus_Dataset。

##### **Transformer Alignment in Large Language Models**
2407.07810v1 by Murdock Aubry, Haoming Meng, Anton Sugolov, Vardan Papyan

Large Language Models (LLMs) have made significant strides in natural
language processing, and a precise understanding of the internal mechanisms
driving their success is essential. We regard LLMs as transforming embeddings
via a discrete, coupled, nonlinear, dynamical system in high dimensions. This
perspective motivates tracing the trajectories of individual tokens as they
pass through transformer blocks, and linearizing the system along these
trajectories through their Jacobian matrices. In our analysis of 38 openly
available LLMs, we uncover the alignment of top left and right singular vectors
of Residual Jacobians, as well as the emergence of linearity and layer-wise
exponential growth. Notably, we discover that increased alignment
$\textit{positively correlates}$ with model performance. Metrics evaluated
post-training show significant improvement in comparison to measurements made
with randomly initialized weights, highlighting the significant effects of
training in transformers. These findings reveal a remarkable level of
regularity that has previously been overlooked, reinforcing the dynamical
interpretation and paving the way for deeper understanding and optimization of
LLM architectures.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了重大進展，而準確理解推動其成功的內部機制至關重要。我們將 LLM 視為通過高維度的離散、耦合、非線性動態系統轉換嵌入。這種觀點激勵我們追蹤個別符號在通過變換器區塊時的軌跡，並通過其雅可比矩陣沿這些軌跡對系統進行線性化。在我們對 38 個公開可用的 LLM 的分析中，我們發現了殘差雅可比矩陣的左奇異向量和右奇異向量的對齊，以及線性和逐層指數增長的出現。值得注意的是，我們發現增加對齊度會與模型性能呈正相關。與使用隨機初始化權重進行的測量相比，訓練後評估的指標顯示出顯著改進，突出了Transformer訓練的顯著影響。這些發現揭示了一個以前被忽視的顯著規律性，加強了動態解釋，並為 LLM 架構的更深入理解和優化鋪平了道路。

##### **ROSA: Random Subspace Adaptation for Efficient Fine-Tuning**
2407.07802v1 by Marawan Gamal Abdel Hameed, Aristides Milios, Siva Reddy, Guillaume Rabusseau

Model training requires significantly more memory, compared with inference.
Parameter efficient fine-tuning (PEFT) methods provide a means of adapting
large models to downstream tasks using less memory. However, existing methods
such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce
latency overhead at inference time or achieve subpar downstream performance
compared with full fine-tuning. In this work we propose Random Subspace
Adaptation (ROSA), a method that outperforms previous PEFT methods by a
significant margin, while maintaining a zero latency overhead during inference
time. In contrast to previous methods, ROSA is able to adapt subspaces of
arbitrarily large dimension, better approximating full-finetuning. We
demonstrate both theoretically and experimentally that this makes ROSA strictly
more expressive than LoRA, without consuming additional memory during runtime.
As PEFT methods are especially useful in the natural language processing
domain, where models operate on scales that make full fine-tuning very
expensive, we evaluate ROSA in two common NLP scenarios: natural language
generation (NLG) and natural language understanding (NLU) with GPT-2 and
RoBERTa, respectively. We show that on almost every GLUE task ROSA outperforms
LoRA by a significant margin, while also outperforming LoRA on NLG tasks. Our
code is available at https://github.com/rosa-paper/rosa

摘要：模型訓練需要顯著更多的記憶體，與推理相比。
參數高效微調 (PEFT) 方法提供了一種使用較少記憶體將大型模型適應於下游任務的方法。然而，現有的方法，例如適配器、提示調整或低秩適應 (LoRA)，會在推理時引入延遲開銷，或與完全微調相比，達到次佳的下游效能。在這項工作中，我們提出隨機子空間適應 (ROSA)，一種方法，它在顯著的幅度上優於先前的 PEFT 方法，同時在推理時維持零延遲開銷。與先前的 PEFT 方法不同，ROSA 能夠適應任意大維度的子空間，更好地近似完全微調。我們在理論上和實驗上證明，這使得 ROSA 在不消耗額外執行時間記憶體的情況下，比 LoRA 更具表現力。由於 PEFT 方法在自然語言處理領域特別有用，在該領域模型在規模上運作，使得完全微調非常昂貴，我們在兩種常見的 NLP 場景中評估 ROSA：自然語言生成 (NLG) 和自然語言理解 (NLU)，分別使用 GPT-2 和 RoBERTa。我們表明，在幾乎每個 GLUE 任務中，ROSA 都以顯著的幅度優於 LoRA，同時也在 NLG 任務中優於 LoRA。我們的程式碼可在 https://github.com/rosa-paper/rosa 取得

##### **AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning**
2407.07801v2 by Jongsuk Kim, Jiwon Shin, Junmo Kim

In recent years, advancements in representation learning and language models
have propelled Automated Captioning (AC) to new heights, enabling the
generation of human-level descriptions. Leveraging these advancements, we
propose AVCap, an Audio-Visual Captioning framework, a simple yet powerful
baseline approach applicable to audio-visual captioning. AVCap utilizes
audio-visual features as text tokens, which has many advantages not only in
performance but also in the extensibility and scalability of the model. AVCap
is designed around three pivotal dimensions: the exploration of optimal
audio-visual encoder architectures, the adaptation of pre-trained models
according to the characteristics of generated text, and the investigation into
the efficacy of modality fusion in captioning. Our method outperforms existing
audio-visual captioning methods across all metrics and the code is available on
https://github.com/JongSuk1/AVCap

摘要：近年來，表示學習和語言模型的進展已將自動字幕 (AC) 推升至新的高度，實現了人類等級描述的產生。利用這些進展，我們提出 AVCap，一個音訊視覺字幕框架，一個適用於音訊視覺字幕的簡單但強大的基線方法。AVCap 利用音訊視覺特徵作為文字符號，這不僅在效能方面，而且在模型的可擴充性和可擴充性方面都有許多優點。AVCap 的設計圍繞三個關鍵面向：最佳音訊視覺編碼器架構的探索、根據產生文字的特徵調整預先訓練的模型，以及調查字幕中模態融合的效能。我們的模型在所有指標上都優於現有的音訊視覺字幕方法，且程式碼可於 https://github.com/JongSuk1/AVCap 取得

##### **Attribute or Abstain: Large Language Models as Long Document Assistants**
2407.07799v1 by Jan Buchmann, Xiao Liu, Iryna Gurevych

LLMs can help humans working with long documents, but are known to
hallucinate. Attribution can increase trust in LLM responses: The LLM provides
evidence that supports its response, which enhances verifiability. Existing
approaches to attribution have only been evaluated in RAG settings, where the
initial retrieval confounds LLM performance. This is crucially different from
the long document setting, where retrieval is not needed, but could help. Thus,
a long document specific evaluation of attribution is missing. To fill this
gap, we present LAB, a benchmark of 6 diverse long document tasks with
attribution, and experiment with different approaches to attribution on 4 LLMs
of different sizes, both prompted and fine-tuned. We find that citation, i.e.
response generation and evidence extraction in one step, mostly performs best.
We investigate whether the ``Lost in the Middle'' phenomenon exists for
attribution, but do not find this. We also find that evidence quality can
predict response quality on datasets with simple responses, but not so for
complex responses, as models struggle with providing evidence for complex
claims. We release code and data for further investigation.

摘要：大型語言模型可以幫助人類處理長篇文件，但它們會出現幻覺。標示出處可以增加對大型語言模型回應的信任：大型語言模型提供了支持其回應的證據，這增強了可驗證性。現有的歸因方法僅在 RAG 設定中進行評估，其中初始檢索會混淆大型語言模型的效能。這與不需要檢索但可能有所幫助的長篇文件設定有根本上的不同。因此，缺少針對長篇文件的特定歸因評估。為了填補這個空白，我們提出了 LAB，這是一個包含 6 項不同長篇文件任務的基準，並在 4 個不同規模的大型語言模型上嘗試不同的歸因方法，包括提示式和微調。我們發現引文，即一步完成回應產生和證據提取，通常表現最佳。我們探討了「迷失在中間」現象是否存在於歸因中，但沒有發現。我們還發現，在回應簡單的資料集上，證據品質可以預測回應品質，但對於複雜的回應則不然，因為模型難以提供複雜說法的證據。我們釋出程式碼和資料以供進一步探討。

##### **Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard**
2407.07796v2 by Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper

We introduce a novel and extensible benchmark for large language models
(LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.
The open-source game simulation code, available on GitHub, allows LLMs to
compete and generates detailed data files in JSON, CSV, TXT, and PNG formats
for leaderboard rankings and further analysis. We present the results of games
among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by
Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and
GPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of
results from other LLMs. In total, we simulated 2,310 matches (5 sessions for
each pair among 7 LLMs and a random player) across three types of games, using
three distinct prompt types: list, illustration, and image. The results
revealed significant variations in LLM performance across different games and
prompt types, with analysis covering win and disqualification rates, missed
opportunity analysis, and invalid move analysis. The details of the leaderboard
and result matrix data are available as open-access data on GitHub. This study
enhances our understanding of LLMs' capabilities in playing games they were not
specifically trained for, helping to assess their rule comprehension and
strategic thinking. On the path to Artificial General Intelligence (AGI), this
study lays the groundwork for future exploration into their utility in complex
decision-making scenarios, illuminating their strategic thinking abilities and
offering directions for further inquiry into the limits of LLMs within
game-based frameworks.

摘要：<paragraph>我們透過格線遊戲，例如井字遊戲、四連線和五子棋，為大型語言模型 (LLM) 引入一個新穎且可擴充的基準。
開放原始碼的遊戲模擬程式碼，可在 GitHub 上取得，允許 LLM 競爭並產生 JSON、CSV、TXT 和 PNG 格式的詳細資料檔案，以供排行榜排名和進一步分析。我們展示了領先 LLM 之間的遊戲結果，包括 Anthropic 的 Claude 3.5 Sonnet 和 Claude 3 Sonnet、Google 的 Gemini 1.5 Pro 和 Gemini 1.5 Flash、OpenAI 的 GPT-4 Turbo 和 GPT-4o，以及 Meta 的 Llama3-70B。我們也鼓勵提交其他 LLM 的結果。總計，我們模擬了 2,310 場比賽（7 個 LLM 和一位隨機玩家之間的 5 場比賽），使用三種不同類型的遊戲和三種不同的提示類型：清單、插圖和影像。結果顯示，不同遊戲和提示類型之間的 LLM 效能存在顯著差異，分析涵蓋獲勝率和取消資格率、錯失機會分析和無效移動分析。排行榜和結果矩陣資料的詳細資訊以開放取用的資料形式在 GitHub 上提供。這項研究增進了我們對 LLM 在未針對其進行特定訓練的遊戲中進行遊戲的能力的了解，有助於評估其規則理解和策略思考。在通往人工通用智慧 (AGI) 的道路上，這項研究為未來探索其在複雜決策情境中的效用奠定了基礎，闡明了其策略思考能力，並為進一步探究 LLM 在基於遊戲的架構中的限制提供了方向。</paragraph>

##### **Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities**
2407.07791v1 by Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu

The rapid adoption of large language models (LLMs) in multi-agent systems has
highlighted their impressive capabilities in various applications, such as
collaborative problem-solving and autonomous negotiation. However, the security
implications of these LLM-based multi-agent systems have not been thoroughly
investigated, particularly concerning the spread of manipulated knowledge. In
this paper, we investigate this critical issue by constructing a detailed
threat model and a comprehensive simulation environment that mirrors real-world
multi-agent deployments in a trusted platform. Subsequently, we propose a novel
two-stage attack method involving Persuasiveness Injection and Manipulated
Knowledge Injection to systematically explore the potential for manipulated
knowledge (i.e., counterfactual and toxic knowledge) spread without explicit
prompt manipulation.
  Our method leverages the inherent vulnerabilities of LLMs in handling world
knowledge, which can be exploited by attackers to unconsciously spread
fabricated information. Through extensive experiments, we demonstrate that our
attack method can successfully induce LLM-based agents to spread both
counterfactual and toxic knowledge without degrading their foundational
capabilities during agent communication. Furthermore, we show that these
manipulations can persist through popular retrieval-augmented generation
frameworks, where several benign agents store and retrieve manipulated chat
histories for future interactions. This persistence indicates that even after
the interaction has ended, the benign agents may continue to be influenced by
manipulated knowledge. Our findings reveal significant security risks in
LLM-based multi-agent systems, emphasizing the imperative need for robust
defenses against manipulated knowledge spread, such as introducing ``guardian''
agents and advanced fact-checking tools.

摘要：大型語言模型 (LLM) 在多主體系統中的快速採用突顯了它們在各種應用中的驚人功能，例如協作問題解決和自主協商。然而，這些基於 LLM 的多主體系統的安全性影響尚未得到徹底調查，特別是關於操縱知識的傳播。在本文中，我們通過構建一個詳細的威脅模型和一個全面的模擬環境來調查這個關鍵問題，該環境反映了在受信任平台中真實世界的多主體部署。隨後，我們提出了一種新穎的兩階段攻擊方法，涉及說服力注入和操縱知識注入，以系統地探索操縱知識（即反事實和有毒知識）在沒有明確提示操縱的情況下傳播的可能性。
我們的辦法利用了 LLM 在處理世界知識時固有的漏洞，攻擊者可以利用這些漏洞無意識地傳播虛假信息。通過廣泛的實驗，我們證明了我們的攻擊方法可以成功地誘導基於 LLM 的代理傳播反事實和有毒知識，而不會在代理通信過程中降低其基礎能力。此外，我們表明，這些操縱可以通過流行的檢索增強生成框架持續存在，在該框架中，幾個良性代理存儲和檢索操縱的聊天記錄以供將來交互。這種持續性表明，即使在交互結束後，良性代理仍可能繼續受到操縱知識的影響。我們的發現揭示了基於 LLM 的多主體系統中存在的重大安全風險，強調了對抗操縱知識傳播的強大防禦措施的迫切需要，例如引入``守護者''代理和先進的事實核查工具。

##### **WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment**
2407.07778v1 by Jiefu Ou, Arda Uzunoglu, Benjamin Van Durme, Daniel Khashabi

AI systems make decisions in physical environments through primitive actions
or affordances that are accessed via API calls. While deploying AI agents in
the real world involves numerous high-level actions, existing embodied
simulators offer a limited set of domain-salient APIs. This naturally brings up
the questions: how many primitive actions (APIs) are needed for a versatile
embodied agent, and what should they look like? We explore this via a thought
experiment: assuming that wikiHow tutorials cover a wide variety of
human-written tasks, what is the space of APIs needed to cover these
instructions? We propose a framework to iteratively induce new APIs by
grounding wikiHow instruction to situated agent policies. Inspired by recent
successes in large language models (LLMs) for embodied planning, we propose a
few-shot prompting to steer GPT-4 to generate Pythonic programs as agent
policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and
then 2) fabricate new API calls when necessary. The focus of this thought
experiment is on defining these APIs rather than their executability. We apply
the proposed pipeline on instructions from wikiHow tutorials. On a small
fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary
for capturing the rich variety of tasks in the physical world. A detailed
automatic and human analysis of the induction output reveals that the proposed
pipeline enables effective reuse and creation of APIs. Moreover, a manual
review revealed that existing simulators support only a small subset of the
induced APIs (9 of the top 50 frequent APIs), motivating the development of
action-rich embodied environments.

摘要：人工智能系統透過基本動作或可透過 API 呼叫存取的便利功能在實際環境中做出決策。雖然在現實世界中部署 AI 代理會涉及許多高階動作，但現有的具體模擬器僅提供有限的領域顯著 API。這自然會引發疑問：一個多功能的具體代理需要多少基本動作 (API)，它們應該是什麼樣子？我們透過一個思想實驗來探討這一點：假設 wikiHow 教學涵蓋了各種各樣的人類書寫任務，那麼涵蓋這些說明所需的 API 空間是什麼？我們提出一個架構，透過將 wikiHow 說明與具體代理政策相結合，反覆誘導出新的 API。受到大型語言模型 (LLM) 在具體規劃中近期成功的啟發，我們提出一個少次提示，引導 GPT-4 生成 Pythonic 程式作為代理政策，並透過 1) 重複使用一組種子 API，然後 2) 在必要時捏造新的 API 呼叫來引導大量的 API。這個思想實驗的重點在於定義這些 API，而不是它們的可執行性。我們將提議的管道應用於 wikiHow 教學的說明。在教學的一小部分 (0.5%) 中，我們誘導出一個包含 300 多個 API 的動作空間，這些 API 對於捕捉現實世界中豐富多樣的任務是必要的。對誘導輸出的詳細自動和人工分析顯示，提議的管道可以有效地重複使用和建立 API。此外，手動檢閱顯示現有的模擬器僅支援誘導 API 的一小部分 (前 50 個頻繁 API 中的 9 個)，這促使開發動作豐富的具體環境。

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v1 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin.

摘要：<paragraph>導航研究中一個難以捉摸的目標是建立一個智慧代理，它
可以理解包含自然語言和影像的多模態指令，並執行有用的導航。為了達成這個目標，我們研究了一個廣泛有用的導航任務類別，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的最新進展在實現這個目標方面展現了一條有希望的道路，因為它展示了感知和推理多模態輸入的能力。
然而，VLM 通常被訓練來預測文字輸出，而如何最佳地將它們用於導航是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它將示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標畫面。接下來，低階政策使用目標畫面和離線建構的拓撲圖在每個時間步產生機器人動作。我們在一個 836 平方公尺的真實世界環境中評估了 Mobility VLA，並顯示 Mobility VLA 在以前無法解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」並拿著一個塑膠箱）上具有很高的端到端成功率。</paragraph>

##### **Learning Spatial-Semantic Features for Robust Video Object Segmentation**
2407.07760v1 by Xin Li, Deshui Miao, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang

Tracking and segmenting multiple similar objects with complex or separate
parts in long-term videos is inherently challenging due to the ambiguity of
target parts and identity confusion caused by occlusion, background clutter,
and long-term variations. In this paper, we propose a robust video object
segmentation framework equipped with spatial-semantic features and
discriminative object queries to address the above issues. Specifically, we
construct a spatial-semantic network comprising a semantic embedding block and
spatial dependencies modeling block to associate the pretrained ViT features
with global semantic features and local spatial features, providing a
comprehensive target representation. In addition, we develop a masked
cross-attention module to generate object queries that focus on the most
discriminative parts of target objects during query propagation, alleviating
noise accumulation and ensuring effective long-term query propagation. The
experimental results show that the proposed method set a new state-of-the-art
performance on multiple datasets, including the DAVIS2017 test (89.1%),
YoutubeVOS 2019 (88.5%), MOSE (75.1%), LVOS test (73.0%), and LVOS val (75.1%),
which demonstrate the effectiveness and generalization capacity of the proposed
method. We will make all source code and trained models publicly available.

摘要：由於目標部分的模糊性以及遮擋、背景雜訊和長期變化造成的身份混淆，在長期影片中追蹤和區分多個相似物體（具有複雜或分開的部分）本質上具有挑戰性。在本文中，我們提出了一個穩健的影片物件分割架構，配備了空間語義特徵和辨別式物件查詢，以解決上述問題。具體來說，我們建構了一個空間語義網路，包括語義嵌入區塊和空間依賴性建模區塊，以將預訓練的 ViT 特徵與全域語義特徵和局部空間特徵關聯起來，提供全面的目標表示。此外，我們開發了一個遮罩交叉注意力模組，以產生在查詢傳播期間專注於目標物件最具辨別力的部分的物件查詢，減輕雜訊累積並確保有效的長期查詢傳播。實驗結果顯示，所提出的方法在多個資料集上設定了新的最先進效能，包括 DAVIS2017 測試 (89.1%)、YoutubeVOS 2019 (88.5%)、MOSE (75.1%)、LVOS 測試 (73.0%) 和 LVOS val (75.1%)，證明了所提出方法的有效性和泛化能力。我們將公開所有原始碼和訓練過的模型。

##### **Fine-Tuning Large Language Models with User-Level Differential Privacy**
2407.07737v1 by Zachary Charles, Arun Ganesh, Ryan McKenna, H. Brendan McMahan, Nicole Mitchell, Krishna Pillutla, Keith Rush

We investigate practical and scalable algorithms for training large language
models (LLMs) with user-level differential privacy (DP) in order to provably
safeguard all the examples contributed by each user. We study two variants of
DP-SGD with: (1) example-level sampling (ELS) and per-example gradient
clipping, and (2) user-level sampling (ULS) and per-user gradient clipping. We
derive a novel user-level DP accountant that allows us to compute provably
tight privacy guarantees for ELS. Using this, we show that while ELS can
outperform ULS in specific settings, ULS generally yields better results when
each user has a diverse collection of examples. We validate our findings
through experiments in synthetic mean estimation and LLM fine-tuning tasks
under fixed compute budgets. We find that ULS is significantly better in
settings where either (1) strong privacy guarantees are required, or (2) the
compute budget is large. Notably, our focus on LLM-compatible training
algorithms allows us to scale to models with hundreds of millions of parameters
and datasets with hundreds of thousands of users.

摘要：我們探討了用使用者層級差分隱私 (DP) 訓練大型語言模型 (LLM) 的實用且可擴充的演算法，以證明保護每個使用者貢獻的所有範例。我們研究了 DP-SGD 的兩個變體：(1) 範例層級抽樣 (ELS) 和每個範例梯度裁剪，以及 (2) 使用者層級抽樣 (ULS) 和每個使用者梯度裁剪。我們推導了一個新穎的使用者層級 DP 會計員，允許我們計算出 ELS 的可證明嚴格隱私保證。使用這個方法，我們顯示 ELS 可以在特定設定中優於 ULS，而當每個使用者都有多樣化的範例集合時，ULS 通常會產生更好的結果。我們透過在固定運算預算下的合成平均估計和 LLM 微調任務中進行實驗來驗證我們的發現。我們發現 ULS 在 (1) 需要強隱私保證或 (2) 運算預算很大的設定中顯著較好。值得注意的是，我們專注於 LLM 相容的訓練演算法，使我們能夠擴充到具有數億個參數和數十萬使用者的資料集的模型。

##### **SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis**
2407.07728v2 by Zihao Wang, Le Ma, Yan Liu, Kejun Zhang

Singing voice conversion (SVC) aims to convert a singer's voice in a given
music piece to another singer while keeping the original content. We propose an
end-to-end feature disentanglement-based model, which we named SaMoye, to
enable zero-shot many-to-many singing voice conversion. SaMoye disentangles the
features of the singing voice into content features, timbre features, and pitch
features respectively. The content features are enhanced using a GPT-based
model to perform cross-prediction with the phoneme of the lyrics. SaMoye can
generate the music with converted voice by replacing the timbre features with
the target singer. We also establish an unparalleled large-scale dataset to
guarantee zero-shot performance. The dataset consists of 1500k pure singing
vocal clips containing at least 10,000 singers.

摘要：歌唱聲音轉換 (SVC) 旨在將給定音樂片段中的歌手聲音轉換為另一位歌手，同時保留原始內容。我們提出了一個端到端的特徵解糾纏模型，我們將其命名為 SaMoye，以實現零次學習多對多歌唱聲音轉換。SaMoye 將歌唱聲音的特徵解糾纏為內容特徵、音色特徵和音高特徵。內容特徵使用基於 GPT 的模型進行增強，以對歌詞音素執行交叉預測。SaMoye 可以通過用目標歌手的音色特徵替換音色特徵來生成轉換聲音的音樂。我們還建立了一個無與倫比的大規模數據集，以保證零次學習性能。該數據集包含 1500k 個純歌唱聲樂片段，包含至少 10,000 名歌手。

##### **PaliGemma: A versatile 3B VLM for transfer**
2407.07726v1 by Lucas Beyer, Andreas Steiner, André Susano Pinto, Alexander Kolesnikov, Xiao Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael Tschannen, Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula, Fangyu Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby, Manoj Kumar, Keran Rong, Julian Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bošnjak, Xi Chen, Matthias Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic, Joan Puigcerver, Pinelopi Papalampidi, Olivier Henaff, Xi Xiong, Radu Soricut, Jeremiah Harmsen, Xiaohua Zhai

PaliGemma is an open Vision-Language Model (VLM) that is based on the
SigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to
be a versatile and broadly knowledgeable base model that is effective to
transfer. It achieves strong performance on a wide variety of open-world tasks.
We evaluate PaliGemma on almost 40 diverse tasks including standard VLM
benchmarks, but also more specialized tasks such as remote-sensing and
segmentation.

摘要：PaliGemma 是一種開放的視覺語言模型 (VLM)，它基於 SigLIP-So400m 視覺編碼器和 Gemma-2B 語言模型。它的訓練目標是成為一個通用且知識淵博的基本模型，能夠有效轉移。它在廣泛的開放世界任務中都取得了強勁的表現。我們在近 40 項不同的任務中評估 PaliGemma，包括標準 VLM 基準，以及更專業的任務，例如遙感和分割。

##### **Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control**
2407.07684v1 by Elahe Delavari, John Moore, Junho Hong, Jaerock Kwon

This paper presents a novel approach to Autonomous Vehicle (AV) control
through the application of active inference, a theory derived from neuroscience
that conceptualizes the brain as a predictive machine. Traditional autonomous
driving systems rely heavily on Modular Pipelines, Imitation Learning, or
Reinforcement Learning, each with inherent limitations in adaptability,
generalization, and computational efficiency. Active inference addresses these
challenges by minimizing prediction error (termed "surprise") through a dynamic
model that balances perception and action. Our method integrates active
inference with deep learning to manage lateral control in AVs, enabling them to
perform lane following maneuvers within a simulated urban environment. We
demonstrate that our model, despite its simplicity, effectively learns and
generalizes from limited data without extensive retraining, significantly
reducing computational demands. The proposed approach not only enhances the
adaptability and performance of AVs in dynamic scenarios but also aligns
closely with human-like driving behavior, leveraging a generative model to
predict and adapt to environmental changes. Results from extensive experiments
in the CARLA simulator show promising outcomes, outperforming traditional
methods in terms of adaptability and efficiency, thereby advancing the
potential of active inference in real-world autonomous driving applications.

摘要：本論文提出了一種自駕車 (AV) 控制的新方法，透過主動推論的應用，主動推論是一種源自神經科學的理論，將大腦概念化為一個預測機器。傳統的自動駕駛系統嚴重依賴模組化管線、模仿學習或強化學習，每種方法在適應性、概括性和計算效率方面都有其固有的限制。主動推論透過一個平衡感知和動作的動態模型，將預測誤差（稱為「驚喜」）最小化，來解決這些挑戰。我們的模型將主動推論與深度學習整合，以管理自駕車的橫向控制，讓它們能夠在模擬的城市環境中執行車道追蹤操作。我們證明了我們的模型儘管很簡單，但能有效學習和概括有限的資料，而無需廣泛的重新訓練，大幅減少了計算需求。所提出的方法不僅增強了自駕車在動態場景中的適應性和效能，而且與類人駕駛行為緊密結合，利用生成模型來預測和適應環境變化。在 CARLA 模擬器中進行的廣泛實驗結果顯示了有希望的結果，在適應性和效率方面優於傳統方法，從而提升了主動推論在實際自駕車應用中的潛力。

##### **The Language of Weather: Social Media Reactions to Weather Accounting for Climatic and Linguistic Baselines**
2407.07683v1 by James C. Young, Rudy Arthur, Hywel T. P. Williams

This study explores how different weather conditions influence public
sentiment on social media, focusing on Twitter data from the UK. By considering
climate and linguistic baselines, we improve the accuracy of weather-related
sentiment analysis. Our findings show that emotional responses to weather are
complex, influenced by combinations of weather variables and regional language
differences. The results highlight the importance of context-sensitive methods
for better understanding public mood in response to weather, which can enhance
impact-based forecasting and risk communication in the context of climate
change.

摘要：本研究探討不同天氣狀況如何影響公眾在社群媒體上的情緒，重點放在英國的 Twitter 資料。透過考慮氣候和語言基準，我們改善了與天氣相關的情緒分析的準確性。我們的研究結果顯示，對天氣的情緒反應很複雜，受到天氣變數組合和區域語言差異的影響。這些結果強調了情境敏感方法在更了解公眾對天氣反應的情緒的重要性，這可以加強基於影響的預測和氣候變遷背景下的風險溝通。

##### **Why should we ever automate moral decision making?**
2407.07671v1 by Vincent Conitzer

While people generally trust AI to make decisions in various aspects of their
lives, concerns arise when AI is involved in decisions with significant moral
implications. The absence of a precise mathematical framework for moral
reasoning intensifies these concerns, as ethics often defies simplistic
mathematical models. Unlike fields such as logical reasoning, reasoning under
uncertainty, and strategic decision-making, which have well-defined
mathematical frameworks, moral reasoning lacks a broadly accepted framework.
This absence raises questions about the confidence we can place in AI's moral
decision-making capabilities.
  The environments in which AI systems are typically trained today seem
insufficiently rich for such a system to learn ethics from scratch, and even if
we had an appropriate environment, it is unclear how we might bring about such
learning. An alternative approach involves AI learning from human moral
decisions. This learning process can involve aggregating curated human
judgments or demonstrations in specific domains, or leveraging a foundation
model fed with a wide range of data. Still, concerns persist, given the
imperfections in human moral decision making.
  Given this, why should we ever automate moral decision making -- is it not
better to leave all moral decision making to humans? This paper lays out a
number of reasons why we should expect AI systems to engage in decisions with a
moral component, with brief discussions of the associated risks.

摘要：儘管人們普遍相信 AI 能在生活各方面做出決策，但當 AI 參與涉及重大道德意義的決策時，就會產生疑慮。由於缺乏精確的數學框架來進行道德推理，因此加劇了這些疑慮，因為道德通常不符合簡化的數學模型。與邏輯推理、不確定性推理和策略決策制定等領域不同，這些領域有明確的數學框架，而道德推理卻缺乏廣泛接受的框架。這種缺失引發了我們對 AI 道德決策能力的信心提出質疑。
  AI 系統在當今接受訓練的環境似乎不足以讓此類系統從頭學習道德，即使我們有適當的環境，也不清楚我們如何能實現這種學習。另一種方法涉及 AI 從人類道德決策中學習。此學習過程可能涉及彙整特定領域中經過策劃的人類判斷或示範，或利用提供大量資料的基礎模型。儘管如此，由於人類道德決策制定中的缺陷，疑慮仍然存在。
  有鑑於此，我們為什麼要自動化道德決策制定——難道將所有道德決策制定留給人類不是更好的選擇嗎？本文列出了我們應期待 AI 系統參與具有道德成分的決策的若干原因，並簡要討論相關風險。

##### **How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning**
2407.07668v1 by Giuseppe Serra, Ben Werner, Florian Buettner

Many real-world applications require machine-learning models to be able to
deal with non-stationary data distributions and thus learn autonomously over an
extended period of time, often in an online setting. One of the main challenges
in this scenario is the so-called catastrophic forgetting (CF) for which the
learning model tends to focus on the most recent tasks while experiencing
predictive degradation on older ones. In the online setting, the most effective
solutions employ a fixed-size memory buffer to store old samples used for
replay when training on new tasks. Many approaches have been presented to
tackle this problem. However, it is not clear how predictive uncertainty
information for memory management can be leveraged in the most effective manner
and conflicting strategies are proposed to populate the memory. Are the
easiest-to-forget or the easiest-to-remember samples more effective in
combating CF? Starting from the intuition that predictive uncertainty provides
an idea of the samples' location in the decision space, this work presents an
in-depth analysis of different uncertainty estimates and strategies for
populating the memory. The investigation provides a better understanding of the
characteristics data points should have for alleviating CF. Then, we propose an
alternative method for estimating predictive uncertainty via the generalised
variance induced by the negative log-likelihood. Finally, we demonstrate that
the use of predictive uncertainty measures helps in reducing CF in different
settings.

摘要：許多實際應用都需要機器學習模型能夠處理非平穩資料分佈，並在一段長時間內自主學習，通常是在線上設定中。在這種情況下，主要的挑戰之一是所謂的災難性遺忘 (CF)，學習模型傾向於專注於最新的任務，同時在舊任務上遇到預測性退化。在線上設定中，最有效的解決方案採用固定大小的記憶體緩衝區來儲存用於在訓練新任務時重播的舊範例。已經提出了許多方法來解決這個問題。然而，目前尚不清楚如何以最有效的方式利用預測不確定性資訊進行記憶體管理，並且提出了相互衝突的策略來填充記憶體。最容易遺忘或最容易記住的範例在對抗 CF 中哪個更有效？從預測不確定性提供決策空間中範例位置的想法這個直覺出發，這項工作提出了一個對不同不確定性估計和策略的深入分析，以填充記憶體。這項調查提供了對資料點應具有的特徵以減輕 CF 的更深入了解。然後，我們提出了一種透過負對數似然引發的廣義變異來估計預測不確定性的替代方法。最後，我們證明了使用預測不確定性測量有助於在不同的設定中減少 CF。

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

摘要：一個全面的定性評估架構，適用於醫療保健領域的大型語言模型 (LLM)，其範圍超越傳統的準確度和定量指標。我們提出用於評估 LLM 的 5 個關鍵面向：安全性、共識、客觀性、可複製性和可解釋性 (S.C.O.R.E.)。我們建議 S.C.O.R.E. 可以作為評估架構的基礎，適用於未來的基於 LLM 的模型，這些模型對於醫療保健和臨床應用來說是安全、可靠、值得信賴且合乎道德的。

##### **A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry**
2407.07664v1 by Martin Lindström, Borja Rodríguez-Gálvez, Ragnar Thobaben, Mikael Skoglund

Hyperspherical Prototypical Learning (HPL) is a supervised approach to
representation learning that designs class prototypes on the unit hypersphere.
The prototypes bias the representations to class separation in a scale
invariant and known geometry. Previous approaches to HPL have either of the
following shortcomings: (i) they follow an unprincipled optimisation procedure;
or (ii) they are theoretically sound, but are constrained to only one possible
latent dimension. In this paper, we address both shortcomings. To address (i),
we present a principled optimisation procedure whose solution we show is
optimal. To address (ii), we construct well-separated prototypes in a wide
range of dimensions using linear block codes. Additionally, we give a full
characterisation of the optimal prototype placement in terms of achievable and
converse bounds, showing that our proposed methods are near-optimal.

摘要：超球原型學習 (HPL) 是表示學習的一種監督式方法，它在單位超球面上設計類原型。
原型將表示偏向於類分離，在一個尺度不變且已知的幾何結構中。
先前的 HPL 方法有以下缺點：(i) 它們遵循一個沒有原則的最佳化程序；
或 (ii) 它們在理論上是合理的，但僅限於一個可能的潛在維度。
在本文中，我們將解決這兩個缺點。為了解決 (i)，
我們提出一個有原則的最佳化程序，我們展示其解是最優的。
為了解決 (ii)，我們使用線性區塊碼在廣泛的維度中構建出分離良好的原型。
此外，我們對可實現和相反界限方面的最佳原型放置給出了一個完整的表徵，
表明我們提出的方法接近最佳。

##### **Tuning Vision-Language Models with Candidate Labels by Prompt Alignment**
2407.07638v2 by Zhifang Zhang, Beibei Li

Vision-language models (VLMs) can learn high-quality representations from a
large-scale training dataset of image-text pairs. Prompt learning is a popular
approach to fine-tuning VLM to adapt them to downstream tasks. Despite the
satisfying performance, a major limitation of prompt learning is the demand for
labelled data. In real-world scenarios, we may only obtain candidate labels
(where the true label is included) instead of the true labels due to data
privacy or sensitivity issues. In this paper, we provide the first study on
prompt learning with candidate labels for VLMs. We empirically demonstrate that
prompt learning is more advantageous than other fine-tuning methods, for
handling candidate labels. Nonetheless, its performance drops when the label
ambiguity increases. In order to improve its robustness, we propose a simple
yet effective framework that better leverages the prior knowledge of VLMs to
guide the learning process with candidate labels. Specifically, our framework
disambiguates candidate labels by aligning the model output with the mixed
class posterior jointly predicted by both the learnable and the handcrafted
prompt. Besides, our framework can be equipped with various off-the-shelf
training objectives for learning with candidate labels to further improve their
performance. Extensive experiments demonstrate the effectiveness of our
proposed framework.

摘要：視覺語言模型 (VLM) 能從大型影像文字配對訓練資料集中學習到高品質的表徵。提示學習是一種流行的方法，用於微調 VLM 以適應下游任務。儘管有令人滿意的表現，但提示學習的一大限制是對標記資料的需求。在實際場景中，我們可能只能取得候選標籤（其中包含真實標籤），而不是由於資料隱私或敏感性問題而取得真實標籤。在本文中，我們提供了第一個關於使用候選標籤進行 VLM 提示學習的研究。我們憑經驗證明，對於處理候選標籤而言，提示學習比其他微調方法更有優勢。儘管如此，當標籤模糊性增加時，其效能會下降。為了提高其穩健性，我們提出了一個簡單但有效的架構，它能更好地利用 VLM 的先驗知識來指導使用候選標籤的學習過程。具體來說，我們的架構透過將模型輸出與可學習提示和手工提示共同預測的混合類別後驗機率對齊，來消除候選標籤的歧義。此外，我們的架構可以配備各種現成的訓練目標，以使用候選標籤進行學習，以進一步提高其效能。廣泛的實驗證明了我們提出的架構的有效性。

##### **A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training**
2407.07630v1 by Michał Perełkiewicz, Rafał Poświata

This article presents a comprehensive review of the challenges associated
with using massive web-mined corpora for the pre-training of large language
models (LLMs). This review identifies key challenges in this domain, including
challenges such as noise (irrelevant or misleading information), duplication of
content, the presence of low-quality or incorrect information, biases, and the
inclusion of sensitive or personal information in web-mined corpora. Addressing
these issues is crucial for the development of accurate, reliable, and
ethically responsible language models. Through an examination of current
methodologies for data cleaning, pre-processing, bias detection and mitigation,
we highlight the gaps in existing approaches and suggest directions for future
research. Our discussion aims to catalyze advancements in developing more
sophisticated and ethically responsible LLMs.

摘要：這篇文章全面回顧了使用大量網頁挖掘語料庫預訓練大型語言模型 (LLM) 所面臨的挑戰。此回顧辨識出此領域中的主要挑戰，包括雜訊（不相關或誤導資訊）、內容重複、存在低品質或不正確的資訊、偏見，以及網頁挖掘語料庫中包含敏感或個人資訊。解決這些問題對於開發精確、可靠且符合道德規範的語言模型至關重要。透過檢視現行資料清理、前處理、偏見偵測和緩解的方法，我們強調現有方法的差距，並建議未來研究的方向。我們的討論旨在催化開發更精緻且符合道德規範的 LLM。

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **The Computational Learning of Construction Grammars: State of the Art and Prospective Roadmap**
2407.07606v1 by Jonas Doumen, Veronica Juliana Schmalz, Katrien Beuls, Paul Van Eecke

This paper documents and reviews the state of the art concerning
computational models of construction grammar learning. It brings together prior
work on the computational learning of form-meaning pairings, which has so far
been studied in several distinct areas of research. The goal of this paper is
threefold. First of all, it aims to synthesise the variety of methodologies
that have been proposed to date and the results that have been obtained.
Second, it aims to identify those parts of the challenge that have been
successfully tackled and reveal those that require further research. Finally,
it aims to provide a roadmap which can help to boost and streamline future
research efforts on the computational learning of large-scale, usage-based
construction grammars.

摘要：本文档记录并检视了有关建构语法学习的计算模型的最新技术。它汇集了先前关于形式-意义配对的计算学习工作，该工作迄今已在几个不同的研究领域中得到研究。本文的目标有三方面。首先，它旨在综合迄今为止提出的各种方法以及获得的结果。其次，它旨在找出已成功解决的挑战部分，并揭示需要进一步研究的部分。最后，它旨在提供一个路线图，该路线图可以帮助促进和简化未来在基于使用的大规模建构语法的计算学习上的研究工作。

##### **Early Explorations of Lightweight Models for Wound Segmentation on Mobile Devices**
2407.07605v2 by Vanessa Borst, Timo Dittus, Konstantin Müller, Samuel Kounev

The aging population poses numerous challenges to healthcare, including the
increase in chronic wounds in the elderly. The current approach to wound
assessment by therapists based on photographic documentation is subjective,
highlighting the need for computer-aided wound recognition from smartphone
photos. This offers objective and convenient therapy monitoring, while being
accessible to patients from their home at any time. However, despite research
in mobile image segmentation, there is a lack of focus on mobile wound
segmentation. To address this gap, we conduct initial research on three
lightweight architectures to investigate their suitability for smartphone-based
wound segmentation. Using public datasets and UNet as a baseline, our results
are promising, with both ENet and TopFormer, as well as the larger UNeXt
variant, showing comparable performance to UNet. Furthermore, we deploy the
models into a smartphone app for visual assessment of live segmentation, where
results demonstrate the effectiveness of TopFormer in distinguishing wounds
from wound-coloured objects. While our study highlights the potential of
transformer models for mobile wound segmentation, future work should aim to
further improve the mask contours.

摘要：人口老齡化對醫療保健構成許多挑戰，包括老年人慢性傷口增加。治療師根據照片文件進行傷口評估的現有方法是主觀的，這凸顯了從智慧型手機照片進行電腦輔助傷口識別的需求。這提供了客觀且便利的治療監控，同時患者隨時都可以在家使用。然而，儘管有行動影像分割的研究，但缺乏對行動傷口分割的關注。為了解決這個差距，我們對三種輕量級架構進行初步研究，以調查它們是否適合用於基於智慧型手機的傷口分割。使用公開資料集和 UNet 作為基準，我們的結果很有希望，ENet 和 TopFormer 以及較大的 UNeXt 變體都顯示出與 UNet 相當的效能。此外，我們將模型部署到智慧型手機應用程式中，以進行即時分割的視覺評估，結果證明了 TopFormer 在區分傷口和傷口顏色物體方面的有效性。雖然我們的研究突顯了Transformer模型在行動傷口分割方面的潛力，但未來的研究應旨在進一步改善遮罩輪廓。

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

摘要：咬合接觸是上顎和下顎後牙咬合面相遇的位置。咬合接觸偵測是恢復咀嚼功能喪失的必要工具，也是牙科領域中的一項強制性評估，特別是在贋復牙科和修復牙科中具有重要意義。最常見的咬合接觸偵測方法是使用咬合紙。然而，此方法可能會顯示出顯著的醫學假陽性和醫學假陰性接觸區域，讓臨床醫師難以找出真正的咬合跡象。為了解決這個問題，我們提出一個多類別的 Vision Transformer 和全卷積網路集合語意分割模型，並結合分層損失函數，我們將其命名為分層全卷積分支轉換器 (H-FCBFormer)。我們還提出了一種生成醫學真陽性語意分割遮罩的方法，該方法源自專家註解的咬合紙遮罩和金標準遮罩。所提出的模型在偵測醫學真陽性接觸方面優於其他機器學習方法，並且在準確識別物件式咬合接觸區域方面優於牙醫師，同時識別所需時間卻顯著減少。程式碼可在 https://github.com/Banksylel/H-FCBFormer 取得。

##### **IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model**
2407.07577v1 by Yatai Ji, Shilong Zhang, Jie Wu, Peize Sun, Weifeng Chen, Xuefeng Xiao, Sidi Yang, Yujiu Yang, Ping Luo

The rapid advancement of Large Vision-Language models (LVLMs) has
demonstrated a spectrum of emergent capabilities. Nevertheless, current models
only focus on the visual content of a single scenario, while their ability to
associate instances across different scenes has not yet been explored, which is
essential for understanding complex visual content, such as movies with
multiple characters and intricate plots. Towards movie understanding, a
critical initial step for LVLMs is to unleash the potential of character
identities memory and recognition across multiple visual scenarios. To achieve
the goal, we propose visual instruction tuning with ID reference and develop an
ID-Aware Large Vision-Language Model, IDA-VLM. Furthermore, our research
introduces a novel benchmark MM-ID, to examine LVLMs on instance IDs memory and
recognition across four dimensions: matching, location, question-answering, and
captioning. Our findings highlight the limitations of existing LVLMs in
recognizing and associating instance identities with ID reference. This paper
paves the way for future artificial intelligence systems to possess
multi-identity visual inputs, thereby facilitating the comprehension of complex
visual narratives like movies.

摘要：大型視覺語言模型 (LVLMs) 的快速進展已展現一系列新興能力。然而，目前的模型僅專注於單一場景的視覺內容，而它們跨不同場景關聯實例的能力尚未被探索，這對於理解複雜的視覺內容（例如具有多個角色和複雜情節的電影）至關重要。為了理解電影，LVLMs 的關鍵第一步是發揮角色身分記憶和跨多個視覺場景識別的潛力。為達成目標，我們提出使用 ID 參考進行視覺指令調整，並開發出 ID 感知大型視覺語言模型 IDA-VLM。此外，我們的研究引入了一個新基準 MM-ID，以在四個面向（匹配、位置、問答和字幕）上檢驗 LVLMs 在實例 ID 記憶和識別方面的表現。我們的研究結果突顯了現有 LVLMs 在識別和關聯實例身分與 ID 參考方面的限制。本文為未來的 AI 系統鋪平了道路，讓它們擁有多重身分視覺輸入，從而促進對電影等複雜視覺敘事的理解。

##### **HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing**
2407.07566v1 by Arnon Turetzky, Or Tal, Yael Segal-Feldman, Yehoshua Dissen, Ella Zeldes, Amit Roth, Eyal Cohen, Yosi Shrem, Bronya R. Chernyak, Olga Seleznova, Joseph Keshet, Yossi Adi

We present HebDB, a weakly supervised dataset for spoken language processing
in the Hebrew language. HebDB offers roughly 2500 hours of natural and
spontaneous speech recordings in the Hebrew language, consisting of a large
variety of speakers and topics. We provide raw recordings together with a
pre-processed, weakly supervised, and filtered version. The goal of HebDB is to
further enhance research and development of spoken language processing tools
for the Hebrew language. Hence, we additionally provide two baseline systems
for Automatic Speech Recognition (ASR): (i) a self-supervised model; and (ii) a
fully supervised model. We present the performance of these two methods
optimized on HebDB and compare them to current multi-lingual ASR alternatives.
Results suggest the proposed method reaches better results than the evaluated
baselines considering similar model sizes. Dataset, code, and models are
publicly available under https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/.

摘要：我們提出 HebDB，一個希伯來語口語處理的弱監督資料集。HebDB 提供大約 2500 小時的希伯來語自然且自發的語音錄音，包含各種講者和主題。我們提供原始錄音以及經過預處理、弱監督和過濾的版本。HebDB 的目標是進一步增強希伯來語口語處理工具的研究和開發。因此，我們另外提供了兩個自動語音辨識 (ASR) 的基準系統：(i) 自我監督模型；(ii) 完全監督模型。我們展示了這兩種方法在 HebDB 上最佳化的效能，並將它們與目前的多分語言 ASR 替代方案進行比較。結果表明，所提出的方法在考慮類似模型大小的情況下，比評估的基準線獲得更好的結果。資料集、程式碼和模型可在 https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/ 下公開取得。

##### **On Leakage of Code Generation Evaluation Datasets**
2407.07565v2 by Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen Gilsenan-McMahon, Matthias Gallé

In this paper we consider contamination by code generation test sets, in
particular in their use in modern large language models. We discuss three
possible sources of such contamination and show findings supporting each of
them: (i) direct data leakage, (ii) indirect data leakage through the use of
synthetic data and (iii) overfitting to evaluation sets during model selection.
Key to our findings is a new dataset of 161 prompts with their associated
python solutions, dataset which is released at
https://huggingface.co/datasets/CohereForAI/lbpp .

摘要：在本文中，我們考慮了由程式碼生成測試集造成的污染，特別是在它們在現代大型語言模型中的使用。我們討論了這種污染的三個可能來源，並展示了支持每個來源的發現：(i) 直接資料外洩，(ii) 通過使用合成資料進行間接資料外洩，以及 (iii) 在模型選擇期間過度擬合評估集。我們的發現的關鍵是一個新的資料集，其中包含 161 個提示及其關聯的 Python 程式碼，該資料集已在 https://huggingface.co/datasets/CohereForAI/lbpp 發布。

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

摘要：機器人輔助進食有潛力改善行動不便、無法自行進食的個人生活品質。然而，現有的進食系統所能處理的均質、精選餐盤與實際的餐點之間存在著很大的差距。進食實際的餐點極具挑戰性，因為機器人可能遇到的食物種類繁多，每種食物都需要特定的操作策略，而這些策略必須在一個長期的範圍內進行排序，才能進食一整餐。一個輔助進食系統不僅應該能夠有效地對不同的策略進行排序，以便進食一整餐，還應該在任務的個性化性質下，考量使用者的偏好。我們透過 FLAIR 來解決這個問題，FLAIR 是針對長時程進食的系統，它利用基礎模型的常識和少量推理能力，以及一個參數化技能庫，來規劃和執行使用者偏好且有效的進食順序。在 6 個實際餐盤的真實世界評估中，我們發現 FLAIR 可以有效地利用各種技能庫進行有效的食物取用，同時遵守 42 位行動不便參與者的不同偏好，這是在使用者研究中評估的。我們展示了 FLAIR 與現有進食轉移方法 [19, 28] 的無縫整合，並在 2 個機構和 3 個機器人中部署它，說明了它的適應性。最後，我們透過成功餵食一位行動不便的受照護者來說明我們系統在真實世界中的功效。補充材料和影片可以在這裡找到：https://emprise.cs.cornell.edu/flair。

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

摘要：大型語言模型（LLM）最近已成為各種語言生成任務的強大工具。儘管如此，這項進展在阿拉伯語中較為緩慢。在這項工作中，我們專注於從 LLM 生成故事的任務。對於我們的訓練，我們使用通過機器翻譯（MT）以及 GPT-4 獲得的故事。對於 MT 資料，我們開發了一個仔細的管道，以確保我們獲得高品質的故事。對於我們的 GPT-41 資料，我們引入了精心製作的提示，使我們能夠生成非常適合阿拉伯語環境的資料，包括現代標準阿拉伯語（MSA）和兩種阿拉伯語方言（埃及語和摩洛哥語）。例如，我們生成針對各種阿拉伯國家的故事，主題廣泛。我們的評估顯示，我們針對這些訓練資料集進行微調的模型可以生成符合我們指示的連貫故事。我們還進行了廣泛的自動和人工評估，將我們的模型與最先進的專有和開放原始碼模型進行比較。我們的資料集和模型將在 https: //github.com/UBC-NLP/arastories 公開。

##### **Disentangling Masked Autoencoders for Unsupervised Domain Generalization**
2407.07544v1 by An Zhang, Han Wang, Xiang Wang, Tat-Seng Chua

Domain Generalization (DG), designed to enhance out-of-distribution (OOD)
generalization, is all about learning invariance against domain shifts
utilizing sufficient supervision signals. Yet, the scarcity of such labeled
data has led to the rise of unsupervised domain generalization (UDG) - a more
important yet challenging task in that models are trained across diverse
domains in an unsupervised manner and eventually tested on unseen domains. UDG
is fast gaining attention but is still far from well-studied. To close the
research gap, we propose a novel learning framework designed for UDG, termed
the Disentangled Masked Auto Encoder (DisMAE), aiming to discover the
disentangled representations that faithfully reveal the intrinsic features and
superficial variations without access to the class label. At its core is the
distillation of domain-invariant semantic features, which cannot be
distinguished by domain classifier, while filtering out the domain-specific
variations (for example, color schemes and texture patterns) that are unstable
and redundant. Notably, DisMAE co-trains the asymmetric dual-branch
architecture with semantic and lightweight variation encoders, offering dynamic
data manipulation and representation level augmentation capabilities. Extensive
experiments on four benchmark datasets (i.e., DomainNet, PACS, VLCS, Colored
MNIST) with both DG and UDG tasks demonstrate that DisMAE can achieve
competitive OOD performance compared with the state-of-the-art DG and UDG
baselines, which shed light on potential research line in improving the
generalization ability with large-scale unlabeled data.

摘要：領域泛化 (DG) 旨在增強非分佈 (OOD) 泛化，其關鍵在於利用足夠的監督訊號來學習對抗領域轉移的不變性。然而，此類標記資料的稀缺性導致無監督領域泛化 (UDG) 的興起，這是一項更重要但更具挑戰性的任務，因為模型是以無監督的方式在不同的領域中訓練，並最終在未見過的領域中進行測試。UDG 迅速受到關注，但仍遠未得到充分的研究。為了縮小研究差距，我們提出了一個專為 UDG 設計的新穎學習架構，稱為分離遮罩自動編碼器 (DisMAE)，旨在發現分離的表徵，這些表徵忠實地揭示了內在特徵和表面變化，而無需存取類別標籤。其核心是對領域不變語義特徵的萃取，這些特徵無法被領域分類器區分，同時過濾掉不穩定且冗餘的領域特定變化（例如，配色方案和紋理模式）。值得注意的是，DisMAE 使用語義和輕量級變異編碼器共同訓練不對稱的雙分支架構，提供動態資料處理和表徵層級擴充功能。在四個基準資料集（即 DomainNet、PACS、VLCS、Colored MNIST）上進行的廣泛實驗，包括 DG 和 UDG 任務，證明 DisMAE 能夠與最先進的 DG 和 UDG 基準相比，取得具有競爭力的 OOD 效能，這為利用大規模未標記資料改善泛化能力的潛在研究方向提供了啟示。

##### **Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search**
2407.07541v1 by Kirill Paramonov, Jia-Xing Zhong, Umberto Michieli, Jijoong Moon, Mete Ozay

In this paper, we address a recent trend in robotic home appliances to
include vision systems on personal devices, capable of personalizing the
appliances on the fly. In particular, we formulate and address an important
technical task of personal object search, which involves localization and
identification of personal items of interest on images captured by robotic
appliances, with each item referenced only by a few annotated images. The task
is crucial for robotic home appliances and mobile systems, which need to
process personal visual scenes or to operate with particular personal objects
(e.g., for grasping or navigation). In practice, personal object search
presents two main technical challenges. First, a robot vision system needs to
be able to distinguish between many fine-grained classes, in the presence of
occlusions and clutter. Second, the strict resource requirements for the
on-device system restrict the usage of most state-of-the-art methods for
few-shot learning and often prevent on-device adaptation. In this work, we
propose Swiss DINO: a simple yet effective framework for one-shot personal
object search based on the recent DINOv2 transformer model, which was shown to
have strong zero-shot generalization properties. Swiss DINO handles challenging
on-device personalized scene understanding requirements and does not require
any adaptation training. We show significant improvement (up to 55%) in
segmentation and recognition accuracy compared to the common lightweight
solutions, and significant footprint reduction of backbone inference time (up
to 100x) and GPU consumption (up to 10x) compared to the heavy
transformer-based solutions.

摘要：<paragraph>在本文中，我們探討機器人家庭電器的一項最新趨勢，在個人裝置上包含視覺系統，能夠即時個人化電器。特別是，我們制定並解決了一個重要的技術任務，即個人物品搜尋，其中涉及在機器人電器拍攝的影像中，定位和辨識個人感興趣的物品，每個物品僅由少數標註影像作為參考。此任務對於機器人家庭電器和行動系統至關重要，這些系統需要處理個人視覺場景或使用特定個人物品（例如，用於抓取或導航）。在實務上，個人物品搜尋呈現兩個主要的技術挑戰。首先，機器人視覺系統需要能夠區分許多細緻的類別，即使在有遮擋和雜亂的情況下。其次，對裝置系統的嚴格資源需求限制了使用大多數最先進的少樣本學習方法，並且經常會妨礙裝置上的適應。在這項工作中，我們提出 Swiss DINO：一個簡單但有效的框架，用於基於最近的 DINOv2 轉換器模型進行一次性個人物品搜尋，該模型被證明具有強大的零樣本泛化特性。Swiss DINO 處理具有挑戰性的裝置上個人化場景理解需求，並且不需要任何適應訓練。與常見的輕量化解決方案相比，我們在分割和辨識準確度方面展示了顯著的提升（高達 55%），並且與基於轉換器的重型解決方案相比，顯著減少了主幹推論時間（高達 100 倍）和 GPU 消耗（高達 10 倍）。</paragraph>

##### **Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models**
2407.07531v1 by Jin Liu, Qingquan Li, Wenlong Du

In current benchmarks for evaluating large language models (LLMs), there are
issues such as evaluation content restriction, untimely updates, and lack of
optimization guidance. In this paper, we propose a new paradigm for the
measurement of LLMs: Benchmarking-Evaluation-Assessment. Our paradigm shifts
the "location" of LLM evaluation from the "examination room" to the "hospital".
Through conducting a "physical examination" on LLMs, it utilizes specific
task-solving as the evaluation content, performs deep attribution of existing
problems within LLMs, and provides recommendation for optimization.

摘要：在當前用於評估大型語言模型 (LLM) 的基準中，存在評估內容限制、更新不即時以及缺乏最佳化指導等問題。在本文中，我們提出一個新的範例來測量 LLM：基準評估。我們的範例將 LLM 評估的「位置」從「考場」轉移到「醫院」。透過對 LLM 進行「身體檢查」，它利用具體的任務解決作為評估內容，對 LLM 內部現有問題進行深入歸因，並提供最佳化建議。

##### **How Aligned are Different Alignment Metrics?**
2407.07530v1 by Jannis Ahlert, Thomas Klein, Felix Wichmann, Robert Geirhos

In recent years, various methods and benchmarks have been proposed to
empirically evaluate the alignment of artificial neural networks to human
neural and behavioral data. But how aligned are different alignment metrics? To
answer this question, we analyze visual data from Brain-Score (Schrimpf et al.,
2018), including metrics from the model-vs-human toolbox (Geirhos et al.,
2021), together with human feature alignment (Linsley et al., 2018; Fel et al.,
2022) and human similarity judgements (Muttenthaler et al., 2022). We find that
pairwise correlations between neural scores and behavioral scores are quite low
and sometimes even negative. For instance, the average correlation between
those 80 models on Brain-Score that were fully evaluated on all 69 alignment
metrics we considered is only 0.198. Assuming that all of the employed metrics
are sound, this implies that alignment with human perception may best be
thought of as a multidimensional concept, with different methods measuring
fundamentally different aspects. Our results underline the importance of
integrative benchmarking, but also raise questions about how to correctly
combine and aggregate individual metrics. Aggregating by taking the arithmetic
average, as done in Brain-Score, leads to the overall performance currently
being dominated by behavior (95.25% explained variance) while the neural
predictivity plays a less important role (only 33.33% explained variance). As a
first step towards making sure that different alignment metrics all contribute
fairly towards an integrative benchmark score, we therefore conclude by
comparing three different aggregation options.

摘要：近年来，已提出各种方法和基准来凭经验评估人工神经网络与人类神经和行为数据的一致性。但不同的对齐度量标准有多一致？为了回答这个问题，我们分析了 Brain-Score（Schrimpf 等人，2018 年）中的视觉数据，包括来自模型与人类工具箱（Geirhos 等人，2021 年）的度量标准，以及人类特征对齐（Linsley 等人，2018 年；Fel 等人，2022 年）和人类相似性判断（Muttenthaler 等人，2022 年）。我们发现神经分数和行为分数之间的成对相关性相当低，有时甚至为负。例如，在 Brain-Score 上经过所有 69 个对齐度量标准全面评估的 80 个模型之间的平均相关性仅为 0.198。假设所有采用的度量标准都是合理的，这意味着与人类感知的对齐可能最好被认为是一个多维概念，不同的方法测量着根本不同的方面。我们的结果强调了综合基准测试的重要性，但也提出了有关如何正确组合和汇总各个度量标准的问题。通过取算术平均值进行汇总，如 Brain-Score 中所做的那样，导致整体性能目前主要受行为支配（解释方差 95.25%），而神经预测性所起的作用较小（仅解释方差 33.33%）。作为确保不同的对齐度量标准都能公平地为综合基准分数做出贡献的第一步，我们因此通过比较三个不同的汇总选项来结束。

##### **CHILLI: A data context-aware perturbation method for XAI**
2407.07521v1 by Saif Anwar, Nathan Griffiths, Abhir Bhalerao, Thomas Popham

The trustworthiness of Machine Learning (ML) models can be difficult to
assess, but is critical in high-risk or ethically sensitive applications. Many
models are treated as a `black-box' where the reasoning or criteria for a final
decision is opaque to the user. To address this, some existing Explainable AI
(XAI) approaches approximate model behaviour using perturbed data. However,
such methods have been criticised for ignoring feature dependencies, with
explanations being based on potentially unrealistic data. We propose a novel
framework, CHILLI, for incorporating data context into XAI by generating
contextually aware perturbations, which are faithful to the training data of
the base model being explained. This is shown to improve both the soundness and
accuracy of the explanations.

摘要：機器學習 (ML) 模型的信賴度難以評估，但在高風險或道德敏感的應用中至關重要。許多模型被視為「黑盒子」，使用者無法了解最終決策的推理或標準。為了解決這個問題，一些現有的可解釋人工智慧 (XAI) 方法使用擾動資料來近似模型行為。然而，這些方法因忽略特徵依賴性而受到批評，因為解釋是基於潛在不切實際的資料。我們提出一個創新的架構 CHILLI，透過產生符合被解釋基礎模型訓練資料的脈絡感知擾動，將資料脈絡納入 XAI。這已被證明可以改善解釋的健全性和準確性。

##### **Generative AI for RF Sensing in IoT systems**
2407.07506v1 by Li Wang, Chao Zhang, Qiyang Zhao, Hang Zou, Samson Lasaulce, Giuseppe Valenzise, Zhuo He, Merouane Debbah

The development of wireless sensing technologies, using signals such as
Wi-Fi, infrared, and RF to gather environmental data, has significantly
advanced within Internet of Things (IoT) systems. Among these, Radio Frequency
(RF) sensing stands out for its cost-effective and non-intrusive monitoring of
human activities and environmental changes. However, traditional RF sensing
methods face significant challenges, including noise, interference, incomplete
data, and high deployment costs, which limit their effectiveness and
scalability. This paper investigates the potential of Generative AI (GenAI) to
overcome these limitations within the IoT ecosystem. We provide a comprehensive
review of state-of-the-art GenAI techniques, focusing on their application to
RF sensing problems. By generating high-quality synthetic data, enhancing
signal quality, and integrating multi-modal data, GenAI offers robust solutions
for RF environment reconstruction, localization, and imaging. Additionally,
GenAI's ability to generalize enables IoT devices to adapt to new environments
and unseen tasks, improving their efficiency and performance. The main
contributions of this article include a detailed analysis of the challenges in
RF sensing, the presentation of innovative GenAI-based solutions, and the
proposal of a unified framework for diverse RF sensing tasks. Through case
studies, we demonstrate the effectiveness of integrating GenAI models, leading
to advanced, scalable, and intelligent IoT systems.

摘要：無線感測技術的發展，使用 Wi-Fi、紅外線和射頻等訊號來收集環境資料，在物聯網 (IoT) 系統中已顯著進步。其中，射頻 (RF) 感測以其具成本效益且非侵入性的方式監控人類活動和環境變化而脫穎而出。然而，傳統的射頻感測方法面臨著重大的挑戰，包括噪音、干擾、資料不完整和部署成本高，這些限制了其有效性和可擴充性。本文探討了生成式 AI (GenAI) 在 IoT 生態系統中克服這些限制的潛力。我們提供了對最新 GenAI 技術的全面回顧，重點關注其在射頻感測問題中的應用。透過生成高品質的合成資料、增強訊號品質和整合多模式資料，GenAI 為射頻環境重建、定位和影像提供強大的解決方案。此外，GenAI 的泛化能力使 IoT 裝置能夠適應新的環境和未知的任務，從而提高其效率和效能。本文的主要貢獻包括對射頻感測挑戰的詳細分析、創新的基於 GenAI 的解決方案的展示，以及統一架構的提議，以應對多樣化的射頻感測任務。透過案例研究，我們展示了整合 GenAI 模型的有效性，從而實現先進、可擴充和智慧的 IoT 系統。

##### **Bucket Pre-training is All You Need**
2407.07495v1 by Hongtao Liu, Qiyao Peng, Qing Yang, Kai Liu, Hongyan Xu

Large language models (LLMs) have demonstrated exceptional performance across
various natural language processing tasks. However, the conventional
fixed-length data composition strategy for pretraining, which involves
concatenating and splitting documents, can introduce noise and limit the
model's ability to capture long-range dependencies. To address this, we first
introduce three metrics for evaluating data composition quality: padding ratio,
truncation ratio, and concatenation ratio. We further propose a multi-bucket
data composition method that moves beyond the fixed-length paradigm, offering a
more flexible and efficient approach to pretraining. Extensive experiments
demonstrate that our proposed method could significantly improving both the
efficiency and efficacy of LLMs pretraining. Our approach not only reduces
noise and preserves context but also accelerates training, making it a
promising solution for LLMs pretraining.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展現出卓越的效能。然而，預訓練的傳統固定長度資料組合策略（涉及串接和分割文件）可能會引入雜訊並限制模型擷取長程依賴關係的能力。為了解決這個問題，我們首先提出三個用於評估資料組合品質的指標：填充率、截斷率和串接率。我們進一步提出一個超越固定長度範例的多儲存區資料組合方法，提供一種更靈活且更有效率的預訓練方法。廣泛的實驗證明，我們提出的方法可以顯著提高 LLM 預訓練的效率和效能。我們的做法不僅減少雜訊並保留上下文，還能加速訓練，使其成為 LLM 預訓練的有前途的解決方案。

##### **FUNAvg: Federated Uncertainty Weighted Averaging for Datasets with Diverse Labels**
2407.07488v1 by Malte Tölle, Fernando Navarro, Sebastian Eble, Ivo Wolf, Bjoern Menze, Sandy Engelhardt

Federated learning is one popular paradigm to train a joint model in a
distributed, privacy-preserving environment. But partial annotations pose an
obstacle meaning that categories of labels are heterogeneous over clients. We
propose to learn a joint backbone in a federated manner, while each site
receives its own multi-label segmentation head. By using Bayesian techniques we
observe that the different segmentation heads although only trained on the
individual client's labels also learn information about the other labels not
present at the respective site. This information is encoded in their predictive
uncertainty. To obtain a final prediction we leverage this uncertainty and
perform a weighted averaging of the ensemble of distributed segmentation heads,
which allows us to segment "locally unknown" structures. With our method, which
we refer to as FUNAvg, we are even on-par with the models trained and tested on
the same dataset on average. The code is publicly available at
https://github.com/Cardio-AI/FUNAvg.

摘要：联邦学习是一种流行的范例，用于在分布式、保护隐私的环境中训练联合模型。但是，部分注释构成了一个障碍，这意味着标签类别在客户端之间是异构的。我们建议以联邦方式学习联合主干，同时每个站点接收自己的多标签分割头。通过使用贝叶斯技术，我们观察到不同的分割头虽然只针对各个客户端的标签进行训练，但也会学习有关其他标签的信息，而这些标签并不存在于各个站点中。此信息编码在它们的预测不确定性中。为了获得最终预测，我们利用这种不确定性，并对分布式分割头的集合执行加权平均，这使我们能够分割“局部未知”结构。通过我们的方法（我们称之为 FUNAvg），我们甚至可以与在同一数据集上平均训练和测试的模型相提并论。代码已公开发布在 https://github.com/Cardio-AI/FUNAvg。

##### **Review-LLM: Harnessing Large Language Models for Personalized Review Generation**
2407.07487v1 by Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang

Product review generation is an important task in recommender systems, which
could provide explanation and persuasiveness for the recommendation. Recently,
Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling
and generating ability, which could be applied in review generation. However,
directly applying the LLMs for generating reviews might be troubled by the
``polite'' phenomenon of the LLMs and could not generate personalized reviews
(e.g., negative reviews). In this paper, we propose Review-LLM that customizes
LLMs for personalized review generation. Firstly, we construct the prompt input
by aggregating user historical behaviors, which include corresponding item
titles and reviews. This enables the LLMs to capture user interest features and
review writing style. Secondly, we incorporate ratings as indicators of
satisfaction into the prompt, which could further improve the model's
understanding of user preferences and the sentiment tendency control of
generated reviews. Finally, we feed the prompt text into LLMs, and use
Supervised Fine-Tuning (SFT) to make the model generate personalized reviews
for the given user and target item. Experimental results on the real-world
dataset show that our fine-tuned model could achieve better review generation
performance than existing close-source LLMs.

摘要：產品評論生成在推薦系統中是一項重要的任務，它可以為推薦提供解釋和說服力。最近，大型語言模型（LLM，例如 ChatGPT）展示了出色的文本建模和生成能力，可以應用於評論生成。然而，直接應用 LLM 來生成評論可能會受到 LLM 的「禮貌」現象的困擾，並且無法生成個性化評論（例如負面評論）。在本文中，我們提出了 Review-LLM，它自訂了 LLM 以進行個性化評論生成。首先，我們通過彙總用戶歷史行為（包括對應的商品標題和評論）來構建提示輸入。這使 LLM 能夠捕捉用戶興趣特徵和評論寫作風格。其次，我們將評分作為滿意度的指標納入提示中，這可以進一步提高模型對用戶偏好和生成評論的情緒傾向控制的理解。最後，我們將提示文本輸入 LLM，並使用監督微調 (SFT) 使模型為給定的用戶和目標商品生成個性化評論。在真實世界數據集上的實驗結果表明，我們微調的模型可以比現有的閉源 LLM 獲得更好的評論生成性能。

##### **Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations**
2407.07482v1 by Luca Marzari, Francesco Leofante, Ferdinando Cicalese, Alessandro Farinelli

We study the problem of assessing the robustness of counterfactual
explanations for deep learning models. We focus on $\textit{plausible model
shifts}$ altering model parameters and propose a novel framework to reason
about the robustness property in this setting. To motivate our solution, we
begin by showing for the first time that computing the robustness of
counterfactuals with respect to plausible model shifts is NP-complete. As this
(practically) rules out the existence of scalable algorithms for exactly
computing robustness, we propose a novel probabilistic approach which is able
to provide tight estimates of robustness with strong guarantees while
preserving scalability. Remarkably, and differently from existing solutions
targeting plausible model shifts, our approach does not impose requirements on
the network to be analyzed, thus enabling robustness analysis on a wider range
of architectures. Experiments on four binary classification datasets indicate
that our method improves the state of the art in generating robust
explanations, outperforming existing methods on a range of metrics.

摘要：我們研究評估深度學習模型的反事實解釋的穩健性的問題。我們專注於改變模型參數的「合理的模型轉移」，並提出一個新的框架，來推論這種設定中的穩健性屬性。為了激勵我們的解決方案，我們首先展示了計算反事實的穩健性，對於合理的模型轉移來說是 NP 完全的。由於這（實際上）排除了精確計算穩健性的可擴充演算法的存在，我們提出了一種新的機率方法，它能夠在保留可擴充性的同時，提供具有強大保證的穩健性緊密估計。值得注意的是，與針對合理的模型轉移的現有解決方案不同，我們的解決方案不會對要分析的網路施加要求，因此可以在更廣泛的架構上進行穩健性分析。在四個二元分類資料集上的實驗表明，我們的模型改進了產生穩健解釋的最新技術，在各種指標上優於現有模型。

##### **Rectifier: Code Translation with Corrector via LLMs**
2407.07472v1 by Xin Yin, Chao Ni, Tien N. Nguyen, Shaohua Wang, Xiaohu Yang

Software migration is garnering increasing attention with the evolution of
software and society. Early studies mainly relied on handcrafted translation
rules to translate between two languages, the translation process is
error-prone and time-consuming. In recent years, researchers have begun to
explore the use of pre-trained large language models (LLMs) in code
translation. However, code translation is a complex task that LLMs would
generate mistakes during code translation, they all produce certain types of
errors when performing code translation tasks, which include (1) compilation
error, (2) runtime error, (3) functional error, and (4) non-terminating
execution. We found that the root causes of these errors are very similar (e.g.
failure to import packages, errors in loop boundaries, operator errors, and
more). In this paper, we propose a general corrector, namely Rectifier, which
is a micro and universal model for repairing translation errors. It learns from
errors generated by existing LLMs and can be widely applied to correct errors
generated by any LLM. The experimental results on translation tasks between
C++, Java, and Python show that our model has effective repair ability, and
cross experiments also demonstrate the robustness of our method.

摘要：隨著軟體和社會的演進，軟體遷移正獲得越來越多的關注。早期研究主要依賴於人工翻譯規則在兩種語言之間進行翻譯，翻譯過程容易出錯且耗時。近年來，研究人員已開始探索在程式碼翻譯中使用預先訓練的大語言模型 (LLM)。然而，程式碼翻譯是一項複雜的任務，LLM 在程式碼翻譯過程中會產生錯誤，它們在執行程式碼翻譯任務時都會產生特定類型的錯誤，包括 (1) 編譯錯誤、(2) 執行時期錯誤、(3) 功能錯誤和 (4) 非終止執行。我們發現這些錯誤的根本原因非常相似 (例如，無法匯入套件、迴圈邊界錯誤、運算子錯誤等等)。在本文中，我們提出了一種通用校正器，即 Rectifier，它是一個用於修復翻譯錯誤的微型且通用的模型。它從現有 LLM 產生的錯誤中學習，並且可以廣泛應用於修正任何 LLM 產生的錯誤。在 C++、Java 和 Python 之間的翻譯任務上的實驗結果表明，我們的模型具有有效的修復能力，並且交叉實驗也證明了我們方法的穩健性。

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Secondary Structure-Guided Novel Protein Sequence Generation with Latent Graph Diffusion**
2407.07443v1 by Yutong Hu, Yang Tan, Andi Han, Lirong Zheng, Liang Hong, Bingxin Zhou

The advent of deep learning has introduced efficient approaches for de novo
protein sequence design, significantly improving success rates and reducing
development costs compared to computational or experimental methods. However,
existing methods face challenges in generating proteins with diverse lengths
and shapes while maintaining key structural features. To address these
challenges, we introduce CPDiffusion-SS, a latent graph diffusion model that
generates protein sequences based on coarse-grained secondary structural
information. CPDiffusion-SS offers greater flexibility in producing a variety
of novel amino acid sequences while preserving overall structural constraints,
thus enhancing the reliability and diversity of generated proteins.
Experimental analyses demonstrate the significant superiority of the proposed
method in producing diverse and novel sequences, with CPDiffusion-SS surpassing
popular baseline methods on open benchmarks across various quantitative
measurements. Furthermore, we provide a series of case studies to highlight the
biological significance of the generation performance by the proposed method.
The source code is publicly available at
https://github.com/riacd/CPDiffusion-SS

摘要：深度学习的出现为从头蛋白质序列设计引入了高效方法，与计算或实验方法相比，显著提高了成功率并降低了开发成本。然而，现有方法在生成具有不同长度和形状且同时保持关键结构特征的蛋白质时面临挑战。为了应对这些挑战，我们引入了 CPDiffusion-SS，这是一种基于粗粒度二级结构信息的潜图扩散模型，用于生成蛋白质序列。CPDiffusion-SS 在生成各种新型氨基酸序列时提供了更大的灵活性，同时保留了整体结构约束，从而增强了生成蛋白质的可靠性和多样性。实验分析表明，所提出的方法在生成多样且新颖的序列方面具有显着的优势，在各种定量测量中，CPDiffusion-SS 超越了开放基准测试中的流行基线方法。此外，我们提供了一系列案例研究，以突出所提出的方法的生成性能的生物学意义。源代码可在 https://github.com/riacd/CPDiffusion-SS 公开获得

##### **Controllable Navigation Instruction Generation with Chain of Thought Prompting**
2407.07433v1 by Xianghao Kong, Jinyu Chen, Wenguan Wang, Hang Su, Xiaolin Hu, Yi Yang, Si Liu

Instruction generation is a vital and multidisciplinary research area with
broad applications. Existing instruction generation models are limited to
generating instructions in a single style from a particular dataset, and the
style and content of generated instructions cannot be controlled. Moreover,
most existing instruction generation methods also disregard the spatial
modeling of the navigation environment. Leveraging the capabilities of Large
Language Models (LLMs), we propose C-Instructor, which utilizes the
chain-of-thought-style prompt for style-controllable and content-controllable
instruction generation. Firstly, we propose a Chain of Thought with Landmarks
(CoTL) mechanism, which guides the LLM to identify key landmarks and then
generate complete instructions. CoTL renders generated instructions more
accessible to follow and offers greater controllability over the manipulation
of landmark objects. Furthermore, we present a Spatial Topology Modeling Task
to facilitate the understanding of the spatial structure of the environment.
Finally, we introduce a Style-Mixed Training policy, harnessing the prior
knowledge of LLMs to enable style control for instruction generation based on
different prompts within a single model instance. Extensive experiments
demonstrate that instructions generated by C-Instructor outperform those
generated by previous methods in text metrics, navigation guidance evaluation,
and user studies.

摘要：指令生成是一个至关重要的多学科研究领域，具有广泛的应用。现有的指令生成模型仅限于从特定数据集生成单一风格的指令，并且无法控制生成指令的风格和内容。此外，大多数现有的指令生成方法也忽略了导航环境的空间建模。利用大型语言模型 (LLM) 的功能，我们提出了 C-Instructor，它利用思想链风格的提示进行风格可控和内容可控的指令生成。首先，我们提出了带有地标的思想链 (CoTL) 机制，它指导 LLM 识别关键地标，然后生成完整的指令。CoTL 使生成的指令更容易遵循，并提供了对地标对象操作的更大可控性。此外，我们提出了空间拓扑建模任务，以促进对环境空间结构的理解。最后，我们引入了一种风格混合训练策略，利用 LLM 的先验知识，以便在单个模型实例中基于不同的提示启用指令生成的风格控制。大量的实验表明，C-Instructor 生成的指令在文本指标、导航指导评估和用户研究中优于以前方法生成的指令。

##### **Out-of-distribution generalisation in spoken language understanding**
2407.07425v1 by Dejan Porjazovski, Anssi Moisio, Mikko Kurimo

Test data is said to be out-of-distribution (OOD) when it unexpectedly
differs from the training data, a common challenge in real-world use cases of
machine learning. Although OOD generalisation has gained interest in recent
years, few works have focused on OOD generalisation in spoken language
understanding (SLU) tasks. To facilitate research on this topic, we introduce a
modified version of the popular SLU dataset SLURP, featuring data splits for
testing OOD generalisation in the SLU task. We call our modified dataset SLURP
For OOD generalisation, or SLURPFOOD. Utilising our OOD data splits, we find
end-to-end SLU models to have limited capacity for generalisation. Furthermore,
by employing model interpretability techniques, we shed light on the factors
contributing to the generalisation difficulties of the models. To improve the
generalisation, we experiment with two techniques, which improve the results on
some, but not all the splits, emphasising the need for new techniques.

摘要：測試資料被認為是 out-of-distribution (OOD)，當它不同於訓練資料時，這是機器學習在實際使用案例中常見的挑戰。儘管 OOD generalization 在近年來引起興趣，但很少有研究專注於口語理解 (SLU) 任務中的 OOD generalization。為了促進對此主題的研究，我們引入了廣受歡迎的 SLU 資料集 SLURP 的修改版本，其中包含用於測試 SLU 任務中 OOD generalization 的資料分割。我們將修改後的資料集稱為 SLURP for OOD generalization，或 SLURPFOOD。利用我們的 OOD 資料分割，我們發現端到端 SLU 模型的 generalization 能力有限。此外，透過採用模型可解釋性技術，我們闡明了導致模型 generalization 困難的因素。為了改善 generalization，我們嘗試了兩種技術，它們改善了一些分割的結果，但並非所有分割，強調了對新技術的需求。

##### **KpopMT: Translation Dataset with Terminology for Kpop Fandom**
2407.07413v1 by JiWoo Kim, Yunsu Kim, JinYeong Bak

While machines learn from existing corpora, humans have the unique capability
to establish and accept new language systems. This makes human form unique
language systems within social groups. Aligning with this, we focus on a gap
remaining in addressing translation challenges within social groups, where
in-group members utilize unique terminologies. We propose KpopMT dataset, which
aims to fill this gap by enabling precise terminology translation, choosing
Kpop fandom as an initiative for social groups given its global popularity.
Expert translators provide 1k English translations for Korean posts and
comments, each annotated with specific terminology within social groups'
language systems. We evaluate existing translation systems including GPT models
on KpopMT to identify their failure cases. Results show overall low scores,
underscoring the challenges of reflecting group-specific terminologies and
styles in translation. We make KpopMT publicly available.

摘要：機器從現有語料庫中學習，而人類擁有建立和接受新語言系統的獨特能力。這使得人類在社會群體中形成獨特的語言系統。與此一致，我們專注於解決社會群體內翻譯挑戰的差距，在群組成員使用獨特術語的情況下。我們提出 KpopMT 資料集，旨在通過啟用精確術語翻譯來填補這一空白，選擇 Kpop 粉絲群作為社會群體的倡議，因為它在全球範圍內很受歡迎。專家翻譯人員為韓語帖子和評論提供了 1k 個英文翻譯，每個翻譯都註釋了社會群體語言系統中的特定術語。我們評估了包括 GPT 模型在內的現有翻譯系統在 KpopMT 上，以找出它們的失敗案例。結果顯示總體得分較低，強調了在翻譯中反映特定群體術語和風格的挑戰。我們公開了 KpopMT。

##### **Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**
2407.07412v1 by Seonghoon Yu, Paul Hongsuck Seo, Jeany Son

We propose a new framework that automatically generates high-quality
segmentation masks with their referring expressions as pseudo supervisions for
referring image segmentation (RIS). These pseudo supervisions allow the
training of any supervised RIS methods without the cost of manual labeling. To
achieve this, we incorporate existing segmentation and image captioning
foundation models, leveraging their broad generalization capabilities. However,
the naive incorporation of these models may generate non-distinctive
expressions that do not distinctively refer to the target masks. To address
this challenge, we propose two-fold strategies that generate distinctive
captions: 1) 'distinctive caption sampling', a new decoding method for the
captioning model, to generate multiple expression candidates with detailed
words focusing on the target. 2) 'distinctiveness-based text filtering' to
further validate the candidates and filter out those with a low level of
distinctiveness. These two strategies ensure that the generated text
supervisions can distinguish the target from other objects, making them
appropriate for the RIS annotations. Our method significantly outperforms both
weakly and zero-shot SoTA methods on the RIS benchmark datasets. It also
surpasses fully supervised methods in unseen domains, proving its capability to
tackle the open-world challenge within RIS. Furthermore, integrating our method
with human annotations yields further improvements, highlighting its potential
in semi-supervised learning applications.

摘要：我們提出一個新的架構，它會自動生成高品質的分割遮罩，並將其參照表達式作為偽監督，以進行參照影像分割 (RIS)。這些偽監督允許訓練任何受監督的 RIS 方法，而無需手動標記的成本。為達成此目的，我們整合現有的分割和影像字幕基礎模型，利用其廣泛的概括能力。然而，天真地整合這些模型可能會產生不具區別性的表達式，而無法明確地參照目標遮罩。為了解決這個挑戰，我們提出兩方面的策略來產生有區別性的字幕：1)「有區別性的字幕取樣」，一種新的字幕模型解碼方法，用於產生多個表達式候選，並使用詳細的字詞專注於目標。2)「基於區別性的文字過濾」，用於進一步驗證候選並過濾掉區別性較低的候選。這兩種策略可確保產生的文字監督可以將目標與其他物件區分開來，使其適用於 RIS 標註。我們的模型在 RIS 基準資料集上明顯優於弱標註和零次學習的 SoTA 模型。它也超越了在未見領域中的完全監督模型，證明了它在 RIS 中應對開放世界挑戰的能力。此外，將我們的模型與人工標註整合，會產生進一步的改進，突顯了它在半監督學習應用中的潛力。

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

摘要：人类观察模式的眼球注视已越来越多地融入视觉任务的解决方案中。尽管最近探索了利用注视来辅助深度网络，但很少有研究利用注视作为医学图像分割的有效注释方法，这通常需要大量的注释成本。在本文中，我们提出收集密集的弱监督，用于具有凝视注释方案的医学图像分割。为了用注视进行训练，我们提出了一个多级框架，该框架从区分性人类注意力训练多个网络，并通过在凝视热图上应用分层阈值来模拟一组伪掩码。此外，为了减轻注视噪声，利用跨级一致性来正则化过度拟合的噪声标签，将模型引导至由对等网络学习的干净模式。所提出的方法已在两个公共医学数据集的多息肉和前列腺分割任务上得到验证。我们贡献了一个名为 GazeMedSeg 的高质量凝视数据集，作为流行医学分割数据集的扩展。据我们所知，这是医学图像分割的第一个凝视数据集。我们的实验表明，在性能和注释时间方面，凝视注释优于以前的标签高效注释方案。我们收集的凝视数据和代码可在以下位置获得：https://github.com/med-air/GazeMedSeg。

##### **Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems**
2407.07392v1 by Chashi Mahiul Islam, Shaeke Salman, Montasir Shams, Xiuwen Liu, Piyush Kumar

Building on the unprecedented capabilities of large language models for
command understanding and zero-shot recognition of multi-modal vision-language
transformers, visual language navigation (VLN) has emerged as an effective way
to address multiple fundamental challenges toward a natural language interface
to robot navigation. However, such vision-language models are inherently
vulnerable due to the lack of semantic meaning of the underlying embedding
space. Using a recently developed gradient based optimization procedure, we
demonstrate that images can be modified imperceptibly to match the
representation of totally different images and unrelated texts for a
vision-language model. Building on this, we develop algorithms that can
adversarially modify a minimal number of images so that the robot will follow a
route of choice for commands that require a number of landmarks. We demonstrate
that experimentally using a recently proposed VLN system; for a given
navigation command, a robot can be made to follow drastically different routes.
We also develop an efficient algorithm to detect such malicious modifications
reliably based on the fact that the adversarially modified images have much
higher sensitivity to added Gaussian noise than the original images.

摘要：建立在大语言模型对命令理解和多模态视觉语言转换器的零样本识别能力的基础上，视觉语言导航 (VLN) 已成为解决面向机器人导航的自然语言界面的多个基本挑战的有效方法。然而，由于底层嵌入空间缺乏语义意义，此类视觉语言模型本质上是脆弱的。使用最近开发的基于梯度的优化程序，我们证明可以对图像进行不可察觉的修改，以匹配视觉语言模型中完全不同图像和无关文本的表示。在此基础上，我们开发了对抗性修改最小数量图像的算法，以便机器人按照需要多个地标的命令选择一条路线。我们使用最近提出的 VLN 系统进行了实验性演示；对于给定的导航命令，可以使机器人按照截然不同的路线前进。我们还开发了一种有效的算法来可靠地检测此类恶意修改，事实是，对抗性修改的图像对添加的高斯噪声的敏感性远高于原始图像。

##### **Automatic Extraction of Disease Risk Factors from Medical Publications**
2407.07373v1 by Maxim Rubchinsky, Ella Rabinovich, Adi Shraibman, Netanel Golan, Tali Sahar, Dorit Shweiki

We present a novel approach to automating the identification of risk factors
for diseases from medical literature, leveraging pre-trained models in the
bio-medical domain, while tuning them for the specific task. Faced with the
challenges of the diverse and unstructured nature of medical articles, our
study introduces a multi-step system to first identify relevant articles, then
classify them based on the presence of risk factor discussions and, finally,
extract specific risk factor information for a disease through a
question-answering model.
  Our contributions include the development of a comprehensive pipeline for the
automated extraction of risk factors and the compilation of several datasets,
which can serve as valuable resources for further research in this area. These
datasets encompass a wide range of diseases, as well as their associated risk
factors, meticulously identified and validated through a fine-grained
evaluation scheme. We conducted both automatic and thorough manual evaluation,
demonstrating encouraging results. We also highlight the importance of
improving models and expanding dataset comprehensiveness to keep pace with the
rapidly evolving field of medical research.

摘要：我們提出了一種新穎的方法，用於自動化從醫學文獻中識別疾病風險因素，利用生物醫學領域中預先訓練的模型，同時針對特定任務對其進行調整。面對醫學文章多樣化和非結構化的挑戰，我們的研究引入了一個多步驟系統，首先識別相關文章，然後根據風險因素討論的存在對其進行分類，最後，通過問答模型提取特定疾病的風險因素信息。
我們的貢獻包括開發了一個用於自動提取風險因素的綜合管道，以及編制了幾個數據集，這些數據集可以用作進一步研究該領域的寶貴資源。這些數據集涵蓋了廣泛的疾病及其相關的風險因素，並通過細粒度的評估方案進行了細緻的識別和驗證。我們進行了自動和徹底的手動評估，展示了令人鼓舞的結果。我們還強調了改進模型和擴展數據集全面性的重要性，以跟上快速發展的醫學研究領域。

##### **LokiLM: Technical Report**
2407.07370v1 by Justin Kiefel, Shrey Shah

In this work, we introduce LokiLM, a 1.4B parameter large language model
trained on 500B tokens. Our model performs strongly in natural language
reasoning tasks and achieves state-of-the-art performance among models with
1.5B parameters or less. LokiLM is trained using multi-teacher knowledge
distillation and high-quality training data to achieve benchmark results
competitive with larger models trained on significantly more tokens. We support
these findings by introducing steps to avoid benchmark contamination and
overfitting throughout our development process. Despite its promising
performance, LokiLM exhibits a concerning amount of hallucinations and scores
poorly on the TruthfulQA benchmark, so we do not release the model publicly.

摘要：在這項工作中，我們介紹了 LokiLM，一個擁有 1.4B 參數的大型語言模型，並以 500B 個符號進行訓練。我們的模型在自然語言推理任務中表現出色，並且在參數少於或等於 1.5B 的模型中取得了最先進的效能。LokiLM 使用多教師知識蒸餾和高品質訓練資料進行訓練，以取得與在更多符號上訓練的大型模型相競爭的基準結果。我們透過在整個開發過程中引入步驟來避免基準污染和過度擬合，來支持這些發現。儘管 LokiLM 具有令人滿意的效能，但它展現出令人擔憂的幻覺數量，且在 TruthfulQA 基準測試中得分不佳，因此我們不會公開發布該模型。

##### **Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?**
2407.07364v1 by Zemian Ke, Qiling Zou, Jiachao Liu, Sean Qian

System optimal traffic routing can mitigate congestion by assigning routes
for a portion of vehicles so that the total travel time of all vehicles in the
transportation system can be reduced. However, achieving real-time optimal
routing poses challenges due to uncertain demands and unknown system dynamics,
particularly in expansive transportation networks. While physics model-based
methods are sensitive to uncertainties and model mismatches, model-free
reinforcement learning struggles with learning inefficiencies and
interpretability issues. Our paper presents TransRL, a novel algorithm that
integrates reinforcement learning with physics models for enhanced performance,
reliability, and interpretability. TransRL begins by establishing a
deterministic policy grounded in physics models, from which it learns from and
is guided by a differentiable and stochastic teacher policy. During training,
TransRL aims to maximize cumulative rewards while minimizing the Kullback
Leibler (KL) divergence between the current policy and the teacher policy. This
approach enables TransRL to simultaneously leverage interactions with the
environment and insights from physics models. We conduct experiments on three
transportation networks with up to hundreds of links. The results demonstrate
TransRL's superiority over traffic model-based methods for being adaptive and
learning from the actual network data. By leveraging the information from
physics models, TransRL consistently outperforms state-of-the-art reinforcement
learning algorithms such as proximal policy optimization (PPO) and soft actor
critic (SAC). Moreover, TransRL's actions exhibit higher reliability and
interpretability compared to baseline reinforcement learning approaches like
PPO and SAC.

摘要：<paragraph>系統最佳交通路線規劃可以透過分配車輛路線，減少交通壅塞，進而減少運輸系統中所有車輛的總體行駛時間。然而，由於不確定的需求和未知的系統動態，特別是在廣大的運輸網路中，要達成即時的最佳路線規劃會遇到挑戰。雖然基於物理模型的方法對不確定性和模型不匹配很敏感，但無模型的強化學習則在學習效率低落和可解釋性問題上掙扎。我們的論文提出了 TransRL，一種創新的演算法，它將強化學習與物理模型整合，以提升效能、可靠性和可解釋性。TransRL 首先建立一個基於物理模型的確定性政策，從中學習並由一個可微分且隨機的老師政策指導。在訓練期間，TransRL 旨在最大化累積獎勵，同時最小化當前政策與老師政策之間的 Kullback Leibler (KL) 距離。這種方法使 TransRL 能同時利用與環境的互動和物理模型的見解。我們在三個具有數百個連結的運輸網路中進行實驗。結果證明 TransRL 優於基於交通模型的方法，因為它具有適應性，並能從實際網路資料中學習。透過利用物理模型中的資訊，TransRL 持續優於最先進的強化學習演算法，例如近端政策最佳化 (PPO) 和軟性動作評論家 (SAC)。此外，與 PPO 和 SAC 等基線強化學習方法相比，TransRL 的動作展現出更高的可靠性和可解釋性。</paragraph>

##### **Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture**
2407.07342v1 by Jiayang Song, Yuheng Huang, Zhehua Zhou, Lei Ma

As safety remains a crucial concern throughout the development lifecycle of
Large Language Models (LLMs), researchers and industrial practitioners have
increasingly focused on safeguarding and aligning LLM behaviors with human
preferences and ethical standards. LLMs, trained on extensive multilingual
corpora, exhibit powerful generalization abilities across diverse languages and
domains. However, current safety alignment practices predominantly focus on
single-language scenarios, which leaves their effectiveness in complex
multilingual contexts, especially for those complex mixed-language formats,
largely unexplored. In this study, we introduce Multilingual Blending, a
mixed-language query-response scheme designed to evaluate the safety alignment
of various state-of-the-art LLMs (e.g., GPT-4o, GPT-3.5, Llama3) under
sophisticated, multilingual conditions. We further investigate language
patterns such as language availability, morphology, and language family that
could impact the effectiveness of Multilingual Blending in compromising the
safeguards of LLMs. Our experimental results show that, without meticulously
crafted prompt templates, Multilingual Blending significantly amplifies the
detriment of malicious queries, leading to dramatically increased bypass rates
in LLM safety alignment (67.23% on GPT-3.5 and 40.34% on GPT-4o), far exceeding
those of single-language baselines. Moreover, the performance of Multilingual
Blending varies notably based on intrinsic linguistic properties, with
languages of different morphology and from diverse families being more prone to
evading safety alignments. These findings underscore the necessity of
evaluating LLMs and developing corresponding safety alignment strategies in a
complex, multilingual context to align with their superior cross-language
generalization capabilities.

摘要：由於安全性在大型語言模型 (LLM) 的整個開發週期中仍然是一個至關重要的問題，因此研究人員和產業從業者越來越專注於保障和調整 LLM 行為，以符合人類偏好和道德標準。LLM 在廣泛的多語言語料庫上訓練，展現出跨越不同語言和領域的強大泛化能力。然而，目前的安全性調整實務主要專注於單一語言場景，這使得它們在複雜的多語言環境中，特別是那些複雜的混合語言格式中的有效性，在很大程度上仍未得到探討。在這項研究中，我們引入了多語言混合，這是一種混合語言查詢回應機制，旨在評估各種最先進的 LLM（例如 GPT-4o、GPT-3.5、Llama3）在複雜的多語言條件下的安全性調整。我們進一步研究了語言模式，例如語言可用性、形態和語言系，這些模式可能會影響多語言混合在破壞 LLM 保障措施方面的有效性。我們的實驗結果表明，在沒有精心製作的提示範本的情況下，多語言混合會顯著放大惡意查詢的損害，導致 LLM 安全性調整的繞過率大幅增加（GPT-3.5 上為 67.23%，GPT-4o 上為 40.34%），遠遠超過單一語言基線。此外，多語言混合的效能會根據內在語言特性而有顯著差異，不同形態和來自不同語言系的語言更容易規避安全性調整。這些發現強調了在複雜的多語言環境中評估 LLM 並制定相應的安全性調整策略的必要性，以符合它們卓越的跨語言泛化能力。

##### **MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization**
2407.07341v1 by Gaurav Sahu, Issam H. Laradji

Low-resource extractive text summarization is a vital but heavily
underexplored area of research. Prior literature either focuses on abstractive
text summarization or prompts a large language model (LLM) like GPT-3 directly
to generate summaries. In this work, we propose MixSumm for low-resource
extractive text summarization. Specifically, MixSumm prompts an open-source
LLM, LLaMA-3-70b, to generate documents that mix information from multiple
topics as opposed to generating documents without mixup, and then trains a
summarization model on the generated dataset. We use ROUGE scores and L-Eval, a
reference-free LLaMA-3-based evaluation method to measure the quality of
generated summaries. We conduct extensive experiments on a challenging text
summarization benchmark comprising the TweetSumm, WikiHow, and ArXiv/PubMed
datasets and show that our LLM-based data augmentation framework outperforms
recent prompt-based approaches for low-resource extractive summarization.
Additionally, our results also demonstrate effective knowledge distillation
from LLaMA-3-70b to a small BERT-based extractive summarizer.

摘要：低資源萃取式文字摘要是一個重要但嚴重未被探索的研究領域。先前的文獻要么專注於摘要式文字摘要，要么直接提示大型語言模型 (LLM) 如 GPT-3 來產生摘要。在這項工作中，我們提出 MixSumm 用於低資源萃取式文字摘要。具體來說，MixSumm 提示開源 LLM、LLaMA-3-70b，產生混合來自多個主題的資訊的文件，而不是產生沒有混淆的文件，然後在產生的資料集上訓練摘要模型。我們使用 ROUGE 分數和 L-Eval，一種基於 LLaMA-3 的無參考評估方法來衡量產生摘要的品質。我們在一個具有挑戰性的文字摘要基準上進行廣泛的實驗，包括 TweetSumm、WikiHow 和 ArXiv/PubMed 資料集，並展示我們的基於 LLM 的資料擴充架構優於最近的基於提示的方法，用於低資源萃取式摘要。此外，我們的結果還展示了從 LLaMA-3-70b 到小型基於 BERT 的萃取式摘要器的有效知識提煉。

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

摘要：方法學的進展自動化生成差異診斷 (DDx)，以預測給定患者症狀描述的潛在疾病清單，對於臨床推理和決策支援等應用至關重要。然而，提供這些差異診斷的推理或解釋更有意義。幸運的是，大型語言模型 (LLM) 擁有強大的語言處理能力，並已被證明在各種相關任務中有效。受此潛力的激勵，我們研究了 LLM 在可解釋的 DDx 中的應用。首先，我們開發了一個新的 DDx 數據集，其中包含專家對 570 個公共臨床筆記的解釋。其次，我們提出了一個名為 Dual-Inf 的新框架，它使 LLM 能夠進行雙向推理以進行解釋。人類和自動化評估都證明了 Dual-Inf 在預測差異和診斷解釋方面的有效性。具體來說，Dual-Inf 在 DDx 解釋中超過基線方法的性能改進超過 32% w.r.t. BERTScore。此外，實驗驗證了 Dual-Inf (1) 在解釋中產生較少的錯誤，(2) 具有很好的概括性，(3) 對罕見疾病的診斷和解釋很有前景。

##### **Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models**
2407.07329v1 by Messi H. J. Lee, Calvin K. Lai

Homogeneity bias in Large Language Models (LLMs) refers to their tendency to
homogenize the representations of some groups compared to others. Previous
studies documenting this bias have predominantly used encoder models, which may
have inadvertently introduced biases. To address this limitation, we prompted
GPT-4 to generate single word/expression completions associated with 18
situation cues - specific, measurable elements of environments that influence
how individuals perceive situations and compared the variability of these
completions using probability of differentiation. This approach directly
assessed homogeneity bias from the model's outputs, bypassing encoder models.
Across five studies, we find that homogeneity bias is highly volatile across
situation cues and writing prompts, suggesting that the bias observed in past
work may reflect those within encoder models rather than LLMs. Furthermore,
these results suggest that homogeneity bias in LLMs is brittle, as even minor
and arbitrary changes in prompts can significantly alter the expression of
biases. Future work should further explore how variations in syntactic features
and topic choices in longer text generations influence homogeneity bias in
LLMs.

摘要：大型語言模型 (LLM) 中的同質性偏差是指它們傾向於將某些群體的表徵同質化，而與其他群體相比。先前記錄這種偏差的研究主要使用編碼器模型，這可能會無意中引入偏差。為了解決這個限制，我們提示 GPT-4 生成與 18 個情境線索相關的單字/表達式完成——環境中具體可衡量的元素，會影響個人如何感知情境，並使用差異機率比較這些完成的變異性。此方法直接評估模型輸出的同質性偏差，繞過編碼器模型。在五項研究中，我們發現同質性偏差在情境線索和寫作提示中高度不穩定，這表明過去工作中觀察到的偏差可能反映編碼器模型中的偏差，而不是 LLM。此外，這些結果表明 LLM 中的同質性偏差很脆弱，因為提示中的微小且隨意的更改會顯著改變偏差的表達。未來的研究應進一步探討語法特徵的變化以及較長文本生成中的主題選擇如何影響 LLM 中的同質性偏差。

##### **Fuse, Reason and Verify: Geometry Problem Solving with Parsed Clauses from Diagram**
2407.07327v1 by Ming-Liang Zhang, Zhong-Zhi Li, Fei Yin, Liang Lin, Cheng-Lin Liu

Geometry problem solving (GPS) requires capacities of multi-modal
understanding, multi-hop reasoning and theorem knowledge application. In this
paper, we propose a neural-symbolic model for plane geometry problem solving
(PGPS), named PGPSNet-v2, with three key steps: modal fusion, reasoning process
and knowledge verification. In modal fusion, we leverage textual clauses to
express fine-grained structural and semantic content of geometry diagram, and
fuse diagram with textual problem efficiently through structural-semantic
pre-training. For reasoning, we design an explicable solution program to
describe the geometric reasoning process, and employ a self-limited decoder to
generate solution program autoregressively. To reduce solution errors, a
multi-level theorem verifier is proposed to eliminate solutions that do not
match geometric principles, alleviating the hallucination of the neural model.
We also construct a large-scale geometry problem dataset called PGPS9K,
containing fine-grained annotations of textual clauses, solution program and
involved knowledge tuples. Extensive experiments on datasets Geometry3K and
PGPS9K show that our PGPSNet solver outperforms existing symbolic and neural
solvers in GPS performance, while maintaining good explainability and
reliability, and the solver components (fusion, reasoning, verification) are
all justified effective.

摘要：<paragraph>几何問題求解 (GPS) 需要具備多模態理解、多跳推理和定理知識應用能力。在本文中，我們提出了平面幾何問題求解 (PGPS) 的神經符號模型，名為 PGPSNet-v2，它包含三個關鍵步驟：模態融合、推理過程和知識驗證。在模態融合中，我們利用文本子句表達幾何圖形的細粒度結構和語義內容，並通過結構語義預訓練有效地將圖形與文本問題融合。對於推理，我們設計了一個可解釋的求解程式來描述幾何推理過程，並採用自限解碼器自迴歸生成求解程式。為了減少求解錯誤，提出了一個多級定理驗證器來消除不符合幾何原理的求解方案，從而減輕神經模型的幻覺。我們還構建了一個名為 PGPS9K 的大型幾何問題數據集，其中包含文本子句、求解程式和涉及的知識元組的細粒度註解。在數據集 Geometry3K 和 PGPS9K 上進行的廣泛實驗表明，我們的 PGPSNet 求解器在 GPS 性能方面優於現有的符號和神經求解器，同時保持良好的可解釋性和可靠性，並且求解器組件（融合、推理、驗證）都被證明是有效的。</paragraph>

##### **HiLight: Technical Report on the Motern AI Video Language Model**
2407.07325v2 by Zhiting Wang, Qiangong Zhou, Kangjie Yang, Zongyang Liu, Xin Mao

This technical report presents the implementation of a state-of-the-art video
encoder for video-text modal alignment and a video conversation framework
called HiLight, which features dual visual towers. The work is divided into two
main parts: 1.alignment of video and text modalities; 2.convenient and
efficient way to interact with users. Our goal is to address the task of video
comprehension in the context of billiards. The report includes a discussion of
the concepts and the final solution developed during the task's implementation.

摘要：本技術報告介紹了一個最先進的影片編碼器的實作，用於影片文字模態對齊，以及一個名為 HiLight 的影片對話架構，其特色是具有雙重視覺塔。這項工作分為兩個主要部分：1.影片與文字模態對齊；2.與使用者互動的便利且有效率的方式。我們的目標是解決在撞球背景下影片理解的任務。報告包含在任務實作期間發展的概念和最終解決方案的討論。

##### **RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension**
2407.07321v1 by Hung Phan, Anurag Acharya, Sarthak Chaturvedi, Shivam Sharma, Mike Parker, Dan Nally, Ali Jannesari, Karl Pazdernik, Mahantesh Halappanavar, Sai Munikoti, Sameera Horawalavithana

Large Language Models (LLMs) have been applied to many research problems
across various domains. One of the applications of LLMs is providing
question-answering systems that cater to users from different fields. The
effectiveness of LLM-based question-answering systems has already been
established at an acceptable level for users posing questions in popular and
public domains such as trivia and literature. However, it has not often been
established in niche domains that traditionally require specialized expertise.
To this end, we construct the NEPAQuAD1.0 benchmark to evaluate the performance
of three frontier LLMs -- Claude Sonnet, Gemini, and GPT-4 -- when answering
questions originating from Environmental Impact Statements prepared by U.S.
federal government agencies in accordance with the National Environmental
Environmental Act (NEPA). We specifically measure the ability of LLMs to
understand the nuances of legal, technical, and compliance-related information
present in NEPA documents in different contextual scenarios. For example, we
test the LLMs' internal prior NEPA knowledge by providing questions without any
context, as well as assess how LLMs synthesize the contextual information
present in long NEPA documents to facilitate the question/answering task. We
compare the performance of the long context LLMs and RAG powered models in
handling different types of questions (e.g., problem-solving, divergent). Our
results suggest that RAG powered models significantly outperform the long
context models in the answer accuracy regardless of the choice of the frontier
LLM. Our further analysis reveals that many models perform better answering
closed questions than divergent and problem-solving questions.

摘要：大型語言模型 (LLM) 已應用於各種領域的許多研究問題。LLM 的應用之一是提供針對不同領域使用者的問答系統。基於 LLM 的問答系統的有效性已在熱門和公共領域（例如瑣事和文學）中提出問題的使用者中達到可接受的水平。然而，它並未經常在傳統上需要專業知識的利基領域中建立。為此，我們構建了 NEPAQuAD1.0 基準來評估三個前沿 LLM 的性能——Claude Sonnet、Gemini 和 GPT-4——在回答由美國聯邦政府機構根據國家環境環境法 (NEPA) 編製的環境影響報告書中產生的問題時。我們特別衡量了 LLM 在不同語境場景中理解 NEPA 文件中存在的法律、技術和合規相關資訊細微差別的能力。例如，我們通過提供沒有任何背景的問題來測試 LLM 的內部先驗 NEPA 知識，並評估 LLM 如何綜合 NEPA 長文件中存在的語境資訊以促進問答任務。我們比較了長語境 LLM 和 RAG 驅動模型在處理不同類型問題（例如，問題解決、發散）方面的性能。我們的結果表明，無論選擇哪個前沿 LLM，RAG 驅動模型在回答準確性方面都顯著優於長語境模型。我們的進一步分析表明，許多模型在回答封閉式問題方面的表現優於發散式和問題解決問題。

##### **ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models**
2407.07313v1 by Benjamin Ascoli, Ram Kandikonda, Jinho D. Choi

The task of Text-to-SQL enables anyone to retrieve information from SQL
databases using natural language. Despite several challenges, recent models
have made remarkable advancements in this task using large language models
(LLMs). Interestingly, we find that LLM-based models without fine-tuning
exhibit distinct natures compared to their fine-tuned counterparts, leading to
inadequacies in current evaluation metrics to accurately convey their
performance. Thus, we analyze the two primary metrics, Test Suite Execution
Accuracy (EXE) and Exact Set Matching Accuracy (ESM), to examine their
robustness for this task and address shortcomings. We compare the performance
of 9 LLM-based models using EXE, the original ESM, and our improved ESM (called
ESM+). Our results show that EXE and ESM have high false positive and negative
rates of 11.3% and 13.9%, while ESM+ gives those of 0.1% and 2.6% respectively,
providing a significantly more stable evaluation. We release the ESM+ script as
open-source for the community to contribute, while enjoying a more reliable
assessment of Text-to-SQL.

摘要：文字轉 SQL 的任務讓任何人能夠使用自然語言從 SQL 資料庫中擷取資訊。儘管有許多挑戰，最近的模型使用大型語言模型 (LLM) 在這項任務中取得了顯著的進展。有趣的是，我們發現沒有微調的基於 LLM 的模型與經過微調的模型相比展現出截然不同的特性，導致目前的評估指標無法準確傳達其效能。因此，我們分析了兩個主要的指標，測試套件執行準確度 (EXE) 和完全集合匹配準確度 (ESM)，以檢查它們對這項任務的穩健性並解決缺點。我們使用 EXE、原始 ESM 和我們改進的 ESM（稱為 ESM+）比較了 9 個基於 LLM 的模型的效能。我們的結果顯示，EXE 和 ESM 的假陽性和假陰性比率分別高達 11.3% 和 13.9%，而 ESM+ 的比率分別為 0.1% 和 2.6%，提供了顯著更穩定的評估。我們將 ESM+ 腳本釋出為開源，供社群貢獻，同時享有對文字轉 SQL 的更可靠評估。

##### **ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting**
2407.07311v1 by Luoxiao Yang, Yun Wang, Xinqi Fan, Israel Cohen, Yue Zhao, Zijun Zhang

The success of large pretrained models in natural language processing (NLP)
and computer vision (CV) has opened new avenues for constructing foundation
models for time series forecasting (TSF). Traditional TSF foundation models
rely heavily on numerical data fitting. In contrast, the human brain is
inherently skilled at processing visual information, prefer predicting future
trends by observing visualized sequences. From a biomimetic perspective,
utilizing models to directly process numerical sequences might not be the most
effective route to achieving Artificial General Intelligence (AGI). This paper
proposes ViTime, a novel Visual Intelligence-based foundation model for TSF.
ViTime overcomes the limitations of numerical time series data fitting by
utilizing visual data processing paradigms and employs a innovative data
synthesis method during training, called Real Time Series (RealTS). Experiments
on a diverse set of previously unseen forecasting datasets demonstrate that
ViTime achieves state-of-the-art zero-shot performance, even surpassing the
best individually trained supervised models in some situations. These findings
suggest that visual intelligence can significantly enhance time series analysis
and forecasting, paving the way for more advanced and versatile models in the
field. The code for our framework is accessible at
https://github.com/IkeYang/ViTime.

摘要：大型預訓練模型在自然語言處理 (NLP) 和電腦視覺 (CV) 中的成功，為建構時間序列預測 (TSF) 的基礎模型開啟了新途徑。傳統的 TSF 基礎模型嚴重依賴數字資料擬合。相反地，人腦天生擅長處理視覺資訊，偏好透過觀察視覺化序列來預測未來趨勢。從仿生學的角度來看，使用模型直接處理數字序列可能不是實現人工通用智慧 (AGI) 的最有效途徑。本文提出 ViTime，一種基於視覺智慧的新型 TSF 基礎模型。ViTime 透過利用視覺資料處理範例，克服了數字時間序列資料擬合的限制，並在訓練期間採用創新的資料合成方法，稱為 Real Time Series (RealTS)。在各種先前未見過的預測資料集上進行的實驗證明，ViTime 達到了最先進的零次學習效能，甚至在某些情況下超越了個別訓練的最佳監督模型。這些發現表明，視覺智慧可以顯著增強時間序列分析和預測，為該領域更先進且多功能的模型鋪平道路。我們架構的程式碼可於 https://github.com/IkeYang/ViTime 取得。

##### **Inference Performance Optimization for Large Language Models on CPUs**
2407.07304v1 by Pujiang He, Shan Zhou, Wenhuan Huang, Changqing Li, Duyi Wang, Bin Guo, Chen Meng, Sheng Gui, Weifei Yu, Yi Xie

Large language models (LLMs) have shown exceptional performance and vast
potential across diverse tasks. However, the deployment of LLMs with high
performance in low-resource environments has garnered significant attention in
the industry. When GPU hardware resources are limited, we can explore
alternative options on CPUs. To mitigate the financial burden and alleviate
constraints imposed by hardware resources, optimizing inference performance is
necessary. In this paper, we introduce an easily deployable inference
performance optimization solution aimed at accelerating LLMs on CPUs. In this
solution, we implement an effective way to reduce the KV cache size while
ensuring precision. We propose a distributed inference optimization approach
and implement it based on oneAPI Collective Communications Library.
Furthermore, we propose optimization approaches for LLMs on CPU, and conduct
tailored optimizations for the most commonly used models. The code is
open-sourced at https://github.com/intel/xFasterTransformer.

摘要：大型語言模型 (LLM) 在各種任務中展現出非凡的效能和廣泛的潛力。然而，在低資源環境中部署高效能的 LLM 已引起業界的極大關注。當 GPU 硬體資源有限時，我們可以在 CPU 上探索其他選項。為了減輕財務負擔並緩解硬體資源帶來的限制，最佳化推理效能是必要的。在本文中，我們介紹了一個易於部署的推理效能最佳化解決方案，旨在加速 CPU 上的 LLM。在此解決方案中，我們實作了一種有效的方法來減少 KV 快取大小，同時確保精確度。我們提出了一種分散式推理最佳化方法，並根據 oneAPI Collective Communications Library 來實作它。此外，我們提出了針對 CPU 上 LLM 的最佳化方法，並針對最常用的模型進行客製化最佳化。程式碼已在 https://github.com/intel/xFasterTransformer 開源。

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

摘要：放射治療 (RT) 是最有效的癌症治療方法之一，其成功有賴於目標的準確描繪。然而，目標描繪是一項全面的醫療決策，目前完全依賴人類專家的手動程序。手動描繪耗時、費力，且受觀察者間差異影響。儘管人工智慧 (AI) 技術的進步已顯著增強正常組織的自動輪廓描繪，但 RT 目標體積的準確描繪仍是一項挑戰。在本研究中，我們提出一個基於視覺語言模型的 RT 目標體積自動描繪網路，稱為 Radformer。Radformer 利用階層式視覺Transformer作為主幹，並整合大型語言模型從臨床資料中提取豐富文字特徵。我們引入一個視覺語言注意力模組 (VLAM)，用於整合視覺和語言特徵，以進行語言感知視覺編碼 (LAVE)。Radformer 已在一個包含 2985 名接受 RT 治療的頭頸癌患者的資料集上進行評估。指標，包括 Dice 相似係數 (DSC)、聯集比 (IOU) 和第 95 個百分位數 Hausdorff 距離 (HD95)，用於定量評估模型的效能。我們的結果表明，與其他最先進的模型相比，Radformer 具有優異的分割效能，驗證了其在 RT 實務中應用的潛力。

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

摘要：在不作平穩假設的情況下從觀測時間序列中發現因果關係是一項重大挑戰。在實務中，這個挑戰在許多領域中很常見，例如零售銷售、運輸系統和醫學科學。在此，我們考慮非平穩時間序列類別的這個問題。這種類型的時間序列的結構因果模型 (SCM)，稱為半平穩時間序列，展示了有限數量的不同因果機制會隨著時間順序且週期性地發生。這個模型具有相當大的實用性，因為它可以表示週期性，包括季節性和晝夜變化等常見現象。我們提出了一個基於約束的非參數演算法，用於發現這個設定中的因果關係。產生的演算法 PCMCI$_{\Omega}$ 可以捕捉因果機制中的交替和重複變化，然後藉由條件獨立 (CI) 檢定來識別基礎因果圖。我們證明這個演算法在識別離散時間序列上的因果關係時是合理的。我們使用連續和離散模擬資料進行廣泛的實驗，以驗證演算法。我們也將我們的演算法應用於真實世界的氣候資料集。

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

摘要：時間序列的變異點偵測旨在找出時間序列的機率分佈改變的時間。它廣泛應用於許多領域，例如人類活動感測與醫學科學。在多變量時間序列的背景中，這通常涉及檢視高維度資料的聯合分佈：如果任何一個變數改變，則假設整個時間序列已經改變。然而，在實際應用中，我們可能只對時間序列的特定組成部分感興趣，探索它們的分佈在其他時間序列存在的情況下突然改變。在這裡，假設一個基礎的結構因果模型支配著時間序列資料的生成，我們透過提出一個兩階段非參數演算法來解決這個問題，該演算法首先透過基於約束的發現方法來學習因果結構的部分。然後，該演算法使用條件相對 Pearson 差異估計來找出變異點。條件相對 Pearson 差異量化時間序列中連續區段之間的分佈差異，而因果發現方法可以專注於因果機制，促進取得獨立且同分布 (IID) 的樣本。理論上，樣本為 IID 的典型假設在傳統變異點偵測方法中可以根據因果馬可夫條件放寬。透過在合成和真實世界資料集上進行實驗，我們驗證了我們方法的正確性和實用性。

##### **Structural Design Through Reinforcement Learning**
2407.07288v1 by Thomas Rochefort-Beaudoin, Aurelian Vadean, Niels Aage, Sofiane Achiche

This paper introduces the Structural Optimization gym (SOgym), a novel
open-source reinforcement learning environment designed to advance the
application of machine learning in topology optimization. SOgym aims for RL
agents to learn to generate physically viable and structurally robust designs
by integrating the physics of TO directly into the reward function. To enhance
scalability, SOgym leverages feature mapping methods as a mesh-independent
interface between the environment and the agent, allowing for efficient
interaction with the design variables regardless of the mesh resolution.
Baseline results are presented using a model-free proximal policy optimization
agent and a model-based DreamerV3 agent. Three observation space configurations
were tested. The TopOpt game inspired configuration, an interactive educational
tool that improves students' intuition in designing structures to minimize
compliance under volume constraints, performed best in terms of performance and
sample efficiency. The 100M parameter version of DreamerV3 produced structures
within 54% of the baseline compliance achieved by traditional optimization
methods as well as a 0% disconnection rate, an improvement over supervised
learning approaches that often struggle with disconnected load paths. When
comparing the learning rates of the agents to those of engineering students
from the TopOpt game experiment, the DreamerV3-100M model shows a learning rate
approximately four orders of magnitude lower, an impressive feat for a policy
trained from scratch through trial and error. These results suggest RL's
potential to solve continuous TO problems and its capacity to explore and learn
from diverse design solutions. SOgym provides a platform for developing RL
agents for complex structural design challenges and is publicly available to
support further research in the field.

摘要：<paragraph>本文介绍了结构优化健身房 (SOgym)，这是一个新颖的开源强化学习环境，旨在推进机器学习在拓扑优化中的应用。SOgym 的目标是让 RL 代理学习生成物理可行且结构稳健的设计，方法是将 TO 的物理特性直接整合到奖励函数中。为了提高可扩展性，SOgym 利用特征映射方法作为环境和代理之间的网格无关接口，从而可以与设计变量进行高效交互，而不管网格分辨率如何。使用无模型近端策略优化代理和基于模型的 DreamerV3 代理展示了基准结果。测试了三种观察空间配置。受 TopOpt 游戏启发的配置是一种交互式教育工具，可以提高学生在设计结构以最大限度地减少体积约束下的柔顺性方面的直觉，在性能和样本效率方面表现最佳。DreamerV3 的 100M 参数版本产生的结构在传统优化方法实现的基准柔顺性范围内为 54%，并且断开率为 0%，这比通常难以处理断开负载路径的监督学习方法有所改进。当将代理的学习率与来自 TopOpt 游戏实验的工程学生的学习率进行比较时，DreamerV3-100M 模型显示的学习率大约低四个数量级，对于通过反复试验从头开始训练的策略来说，这是一个令人印象深刻的壮举。这些结果表明 RL 有可能解决连续 TO 问题，并有能力探索和学习各种设计解决方案。SOgym 为开发用于复杂结构设计挑战的 RL 代理提供了一个平台，并且公开可用以支持该领域的进一步研究。</paragraph>

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

摘要：血液生物標記是醫療保健提供者用於診斷、監測和治療各種疾病的重要工具。目前的參考值和建議範圍通常依賴於人群統計數據，而這些數據可能無法充分說明由生活方式和基因等因素驅動的個體間變異的影響。在這項工作中，我們引入了一個新的框架來預測未來的血液生物標記值，並通過從生活方式數據（身體活動和睡眠）和血液生物標記中學習到的表徵來定義個性化參考。我們提出的方法學習了一個基於相似性的嵌入空間，該空間捕捉了生物標記和生活方式因素之間的複雜關係。使用英國生物銀行（257K 參與者），我們的結果表明，我們深度學習的嵌入優於傳統和當前最先進的表徵學習技術，可以預測臨床診斷。使用擁有後續訪視的 6440 名參與者的英國生物銀行子集，我們驗證了在血液生物標記模型中直接包含這些嵌入和生活方式因素可以改善從單次實驗室訪問中預測未來實驗室值。這種個性化建模方法為開發更準確的風險分層工具和定制預防保健策略提供了基礎。在臨床環境中，這轉化為早期疾病檢測、更及時的干預，最終轉向個性化醫療保健的潛力。

##### **Exploring Camera Encoder Designs for Autonomous Driving Perception**
2407.07276v1 by Barath Lakshmanan, Joshua Chen, Shiyi Lan, Maying Shen, Zhiding Yu, Jose M. Alvarez

The cornerstone of autonomous vehicles (AV) is a solid perception system,
where camera encoders play a crucial role. Existing works usually leverage
pre-trained Convolutional Neural Networks (CNN) or Vision Transformers (ViTs)
designed for general vision tasks, such as image classification, segmentation,
and 2D detection. Although those well-known architectures have achieved
state-of-the-art accuracy in AV-related tasks, e.g., 3D Object Detection, there
remains significant potential for improvement in network design due to the
nuanced complexities of industrial-level AV dataset. Moreover, existing public
AV benchmarks usually contain insufficient data, which might lead to inaccurate
evaluation of those architectures.To reveal the AV-specific model insights, we
start from a standard general-purpose encoder, ConvNeXt and progressively
transform the design. We adjust different design parameters including width and
depth of the model, stage compute ratio, attention mechanisms, and input
resolution, supported by systematic analysis to each modifications. This
customization yields an architecture optimized for AV camera encoder achieving
8.79% mAP improvement over the baseline. We believe our effort could become a
sweet cookbook of image encoders for AV and pave the way to the next-level
drive system.

摘要：自動駕駛車輛 (AV) 的基石是一個穩固的感知系統，其中相機編碼器扮演著至關重要的角色。現有的作品通常利用為一般視覺任務（例如影像分類、分割和 2D 偵測）設計的預先訓練的卷積神經網路 (CNN) 或視覺Transformer (ViT)。雖然這些著名的架構在 AV 相關任務（例如 3D 物件偵測）中已達到最先進的準確度，但由於產業級 AV 資料集的細微複雜性，網路設計仍有顯著的改進潛力。此外，現有的公開 AV 基準通常包含不足的資料，這可能會導致這些架構的評估不準確。為了揭示 AV 特定的模型見解，我們從一個標準的通用編碼器 ConvNeXt 開始，並逐步轉換設計。我們調整不同的設計參數，包括模型的寬度和深度、階段運算比、注意力機制和輸入解析度，並透過系統分析支援每個修改。此自訂化產生了一個針對 AV 相機編碼器最佳化的架構，與基準相比，mAP 提升了 8.79%。我們相信我們的努力可以成為 AV 影像編碼器的甜蜜食譜，並為下一級的驅動系統鋪路。

##### **Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support**
2407.07275v1 by Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife

Cinematic audio source separation (CASS) is a relatively new subtask of audio
source separation, concerned with the separation of a mixture into the
dialogue, music, and effects stems. To date, only one publicly available
dataset exists for CASS, that is, the Divide and Remaster (DnR) dataset, which
is currently at version 2. While DnR v2 has been an incredibly useful resource
for CASS, several areas of improvement have been identified, particularly
through its use in the 2023 Sound Demixing Challenge. In this work, we develop
version 3 of the DnR dataset, addressing issues relating to vocal content in
non-dialogue stems, loudness distributions, mastering process, and linguistic
diversity. In particular, the dialogue stem of DnR v3 includes speech content
from more than 30 languages from multiple families including but not limited to
the Germanic, Romance, Indo-Aryan, Dravidian, Malayo-Polynesian, and Bantu
families. Benchmark results using the Bandit model indicated that training on
multilingual data yields significant generalizability to the model even in
languages with low data availability. Even in languages with high data
availability, the multilingual model often performs on par or better than
dedicated models trained on monolingual CASS datasets.

摘要：電影音訊來源分離 (CASS) 是音訊來源分離的相對較新的子任務，關注於將混合音訊分離為對話、音樂和效果音源。迄今為止，CASS 僅有一個公開可用的資料集，即 Divide and Remaster (DnR) 資料集，目前為版本 2。雖然 DnR v2 一直是 CASS 的一個非常有用的資源，但已經找出幾個改善領域，特別是透過在 2023 年 Sound Demixing Challenge 中使用它。在此工作中，我們開發了 DnR 資料集的版本 3，解決了與非對話音源中的語音內容、響度分佈、母帶處理和語言多樣性相關的問題。特別是，DnR v3 的對話音源包含來自 30 多種語言的語音內容，這些語言來自多個語系，包括但不限於日耳曼語系、羅曼語系、印度-雅利安語系、達羅毗荼語系、馬來-波利尼西亞語系和班圖語系。使用 Bandit 模型的基準結果表明，即使在資料可用性低的語言中，在多語言資料上進行訓練也會對模型產生顯著的泛化性。即使在資料可用性高的語言中，多語言模型的表現通常與在單語言 CASS 資料集上訓練的專用模型相當或更好。

##### **Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models**
2407.07263v1 by Jupinder Parmar, Sanjev Satheesh, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

As language models have scaled both their number of parameters and
pretraining dataset sizes, the computational cost for pretraining has become
intractable except for the most well-resourced teams. This increasing cost
makes it ever more important to be able to reuse a model after it has completed
pretraining; allowing for a model's abilities to further improve without
needing to train from scratch. In this work, we detail a set of guidelines that
cover how to design efficacious data distributions and learning rate schedules
for continued pretraining of language models. When applying these findings
within a continued pretraining run on top of a well-trained 15B parameter
model, we show an improvement of 9\% in average model accuracy compared to the
baseline of continued training on the pretraining set. The resulting recipe
provides a practical starting point with which to begin developing language
models through reuse rather than retraining.

摘要：隨著語言模型擴展其參數數量和預訓練資料集大小，預訓練的運算成本已變得難以處理，除了資源最豐富的團隊外。這種成本的增加使得在預訓練完成後能夠重複使用模型變得更加重要；允許模型的能力進一步提升，而無需從頭開始訓練。在這項工作中，我們詳細說明了一組準則，涵蓋如何設計有效的資料分佈和學習率時間表，以持續預訓練語言模型。在訓練有素的 15B 參數模型上應用這些發現時，我們展示了與在預訓練集上持續訓練的基準相比，平均模型準確度提高了 9%。由此產生的方法提供了一個實用的起點，可以開始通過重複使用而不是重新訓練來開發語言模型。

##### **Identification of emotions on Twitter during the 2022 electoral process in Colombia**
2407.07258v1 by Juan Jose Iguaran Fernandez, Juan Manuel Perez, German Rosati

The study of Twitter as a means for analyzing social phenomena has gained
interest in recent years due to the availability of large amounts of data in a
relatively spontaneous environment. Within opinion-mining tasks, emotion
detection is specially relevant, as it allows for the identification of
people's subjective responses to different social events in a more granular way
than traditional sentiment analysis based on polarity. In the particular case
of political events, the analysis of emotions in social networks can provide
valuable information on the perception of candidates, proposals, and other
important aspects of the public debate. In spite of this importance, there are
few studies on emotion detection in Spanish and, to the best of our knowledge,
few resources are public for opinion mining in Colombian Spanish, highlighting
the need for generating resources addressing the specific cultural
characteristics of this variety. In this work, we present a small corpus of
tweets in Spanish related to the 2022 Colombian presidential elections,
manually labeled with emotions using a fine-grained taxonomy. We perform
classification experiments using supervised state-of-the-art models (BERT
models) and compare them with GPT-3.5 in few-shot learning settings. We make
our dataset and code publicly available for research purposes.

摘要：近年來，由於在相對自發的環境中獲得大量資料，將 Twitter 視為分析社會現象的一種手段的研究引起了興趣。在輿論挖掘任務中，情緒偵測特別相關，因為它允許以比傳統基於極性的情緒分析更細緻的方式，來識別人們對不同社會事件的主觀反應。特別是在政治事件中，社交網路中情緒的分析可以提供有關候選人、提案和其他重要公共辯論面向的觀感的有價值資訊。儘管如此重要，但對於西班牙語的情緒偵測研究卻很少，並且就我們所知，針對哥倫比亞西班牙語的輿論挖掘，公開的資源也很少，這突顯了產生針對此變體的特定文化特徵的資源的需求。在這項工作中，我們提出了一個與 2022 年哥倫比亞總統選舉相關的西班牙語推文語料庫，使用細緻的分類法手動標記情緒。我們使用監督最先進的模型（BERT 模型）執行分類實驗，並在少次學習設定中將它們與 GPT-3.5 進行比較。我們將我們的資料集和程式碼公開供研究用途。

##### **Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models**
2407.07229v1 by Yun Qi Li, Tuan Do, Evan Jones, Bernie Boscoe, Kevin Alfaro, Zooey Nguyen

Generative models producing images have enormous potential to advance
discoveries across scientific fields and require metrics capable of quantifying
the high dimensional output. We propose that astrophysics data, such as galaxy
images, can test generative models with additional physics-motivated ground
truths in addition to human judgment. For example, galaxies in the Universe
form and change over billions of years, following physical laws and
relationships that are both easy to characterize and difficult to encode in
generative models. We build a conditional denoising diffusion probabilistic
model (DDPM) and a conditional variational autoencoder (CVAE) and test their
ability to generate realistic galaxies conditioned on their redshifts (galaxy
ages). This is one of the first studies to probe these generative models using
physically motivated metrics. We find that both models produce comparable
realistic galaxies based on human evaluation, but our physics-based metrics are
better able to discern the strengths and weaknesses of the generative models.
Overall, the DDPM model performs better than the CVAE on the majority of the
physics-based metrics. Ultimately, if we can show that generative models can
learn the physics of galaxy evolution, they have the potential to unlock new
astrophysical discoveries.

摘要：生成影像的生成模型具有促進科學領域發現的巨大潛力，並且需要能夠量化高維度輸出的指標。我們提出，天文物理數據（例如星系影像）可以使用額外的物理激勵基準真值以及人為判斷來測試生成模型。舉例來說，宇宙中的星系在數十億年來形成並改變，遵循物理定律和關係，這些定律和關係既容易描述，又難以編碼在生成模型中。我們建構條件式去噪擴散機率模型 (DDPM) 和條件式變異自動編碼器 (CVAE)，並測試它們在以紅移（星系年齡）為條件下產生逼真星系的能力。這是第一批使用物理激勵指標探測這些生成模型的研究之一。我們發現，根據人為評估，這兩個模型都能產生可比較的逼真星系，但我們的基於物理的指標更能辨別生成模型的優缺點。總體而言，DDPM 模型在大部分基於物理的指標上表現優於 CVAE。最終，如果我們能證明生成模型可以學習星系演化的物理，它們就有可能解鎖新的天體物理發現。

##### **ConvNLP: Image-based AI Text Detection**
2407.07225v1 by Suriya Prakash Jambunathan, Ashwath Shankarnarayan, Parijat Dube

The potentials of Generative-AI technologies like Large Language models
(LLMs) to revolutionize education are undermined by ethical considerations
around their misuse which worsens the problem of academic dishonesty. LLMs like
GPT-4 and Llama 2 are becoming increasingly powerful in generating
sophisticated content and answering questions, from writing academic essays to
solving complex math problems. Students are relying on these LLMs to complete
their assignments and thus compromising academic integrity. Solutions to detect
LLM-generated text are compute-intensive and often lack generalization. This
paper presents a novel approach for detecting LLM-generated AI-text using a
visual representation of word embedding. We have formulated a novel
Convolutional Neural Network called ZigZag ResNet, as well as a scheduler for
improving generalization, named ZigZag Scheduler. Through extensive evaluation
using datasets of text generated by six different state-of-the-art LLMs, our
model demonstrates strong intra-domain and inter-domain generalization
capabilities. Our best model detects AI-generated text with an impressive
average detection rate (over inter- and intra-domain test data) of 88.35%.
Through an exhaustive ablation study, our ZigZag ResNet and ZigZag Scheduler
provide a performance improvement of nearly 4% over the vanilla ResNet. The
end-to-end inference latency of our model is below 2.5ms per sentence. Our
solution offers a lightweight, computationally efficient, and faster
alternative to existing tools for AI-generated text detection, with better
generalization performance. It can help academic institutions in their fight
against the misuse of LLMs in academic settings. Through this work, we aim to
contribute to safeguarding the principles of academic integrity and ensuring
the trustworthiness of student work in the era of advanced LLMs.

摘要：<paragraph>大型語言模型 (LLM) 等生成式 AI 技術的潛力，可能會因為其誤用所帶來的道德考量而受到削弱，這會惡化學術不誠實的問題。GPT-4 和 Llama 2 等 LLM 在產生精緻內容和回答問題方面變得越來越強大，從撰寫學術論文到解決複雜的數學問題。學生依賴這些 LLM 來完成作業，因此損害了學術誠信。偵測 LLM 生成的文字的解決方案需要大量的運算，而且通常缺乏概括性。本文提出了一個新穎的方法，使用詞嵌入的視覺表示來偵測 LLM 生成的 AI 文字。我們制定了一個名為 ZigZag ResNet 的新卷積神經網路，以及一個名為 ZigZag Scheduler 的排程器，以改善概括性。透過使用六個不同的最先進 LLM 生成的文字資料集進行廣泛的評估，我們的模型展示了強大的領域內和領域間概括能力。我們最好的模型以令人印象深刻的平均檢測率 (超過領域間和領域內測試資料) 88.35% 檢測到 AI 生成的文字。透過詳盡的消融研究，我們的 ZigZag ResNet 和 ZigZag Scheduler 提供了比香草 ResNet 幾乎提升 4% 的效能。我們模型的端到端推論延遲低於每句 2.5 毫秒。我們的解決方案提供了一個輕量級、計算效率高且比現有 AI 生成的文字偵測工具更快的替代方案，並具有更好的概括效能。它可以幫助學術機構對抗在學術環境中濫用 LLM 的行為。透過這項工作，我們旨在為維護學術誠信的原則做出貢獻，並確保在先進 LLM 的時代中學生作業的可信度。</paragraph>

##### **AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**
2407.07094v1 by Jiaxi Cui, Wentao Zhang, Jing Tang, Xudong Tong, Zhenwei Zhang, Amie, Jing Wen, Rongsheng Wang, Pengfei Wu

The pervasive deployment of Large Language Models-LLMs in various sectors
often neglects the nuanced requirements of individuals and small organizations,
who benefit more from models precisely tailored to their specific business
contexts rather than those with broadly superior general capabilities. This
work introduces \textbf{AnyTaskTune}, a novel fine-tuning methodology coined as
\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on
a diverse array of domain-specific tasks. This method involves a meticulous
process to identify and define targeted sub-tasks within a domain, followed by
the creation of specialized enhancement datasets for fine-tuning, thereby
optimizing task-specific model performance. We conducted comprehensive
fine-tuning experiments not only in the legal domain for tasks such as keyword
extraction and sentence prediction but across over twenty different sub-tasks
derived from the domains of finance, healthcare, law, psychology, consumer
services, and human resources. To substantiate our approach and facilitate
community engagement, we will open-source these bilingual task datasets. Our
findings demonstrate that models fine-tuned using the \textbf{Task-Fine-Tune}
methodology not only achieve superior performance on these specific tasks but
also significantly outperform models with higher general capabilities in their
respective domains. Our work is publicly available at
\url{https://github.com/PandaVT/DataTager}.

摘要：各種產業中普遍部署大型語言模型 (LLM) 時，常常忽略個人和小型組織的細微需求，而這些對象較能從精準調整到其特定商業脈絡的模型中獲益，而非具備廣泛卓越一般能力的模型。本研究介紹一種新穎的微調方法，稱為「任務微調」(Task-Fine-Tune)，專門開發用於提升模型在各種特定領域任務上的效能。此方法包含一個細緻的程序，用於識別和定義領域內的目標子任務，然後建立專門的強化資料集進行微調，進而最佳化特定任務的模型效能。我們不僅在法律領域進行全面的微調實驗，針對關鍵字萃取和句子預測等任務，還涵蓋從金融、醫療保健、法律、心理學、消費者服務和人力資源等領域衍生的二十多個不同子任務。為了證實我們的做法並促進社群參與，我們將開放這些雙語任務資料集的原始碼。我們的研究結果顯示，使用「任務微調」方法微調的模型不僅在這些特定任務上達到卓越效能，而且在各自領域中也明顯優於具備較高一般能力的模型。我們的研究成果已於 https://github.com/PandaVT/DataTager 公開。

##### **FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**
2407.07093v1 by Liqun Ma, Mingjie Sun, Zhiqiang Shen

This work presents a Fully BInarized Large Language Model (FBI-LLM),
demonstrating for the first time how to train a large-scale binary language
model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to
match the performance of its full-precision counterparts (e.g., FP16 or BF16)
in transformer-based LLMs. It achieves this by employing an autoregressive
distillation (AD) loss with maintaining equivalent model dimensions (130M,
1.3B, 7B) and training data volume as regular LLM pretraining, while delivering
competitive results in terms of perplexity and task-specific effectiveness.
Intriguingly, by analyzing the training trajectory, we find that the pretrained
weight is not necessary for training binarized LLMs from scratch. This research
encourages a new computational framework and may facilitate the future design
of specialized hardware tailored for fully 1-bit LLMs. We make all models,
code, and training dataset fully accessible and transparent to support further
research (Code: https://github.com/LiqunMa/FBI-LLM. Model:
https://huggingface.co/LiqunMa/).

摘要：本研究提出了一個全二值化大型語言模型 (FBI-LLM)，首次展示如何從頭訓練一個大型二值語言模型（不是像 BitNet b1.58 那樣的局部二值或三值 LLM），以匹配其全精度對應項（例如，FP16 或 BF16）在基於Transformer的 LLM 中的性能。它通過採用自迴歸蒸餾 (AD) 損失來實現這一點，同時保持等效的模型維度（130M、1.3B、7B）和訓練數據量作為常規 LLM 預訓練，同時在困惑度和特定任務的有效性方面提供有競爭力的結果。有趣的是，通過分析訓練軌跡，我們發現預訓練權重對於從頭訓練二值化 LLM 並非必要。這項研究鼓勵新的計算框架，並可能促進專門針對全 1 位元 LLM 量身打造的硬體的未來設計。我們讓所有模型、程式碼和訓練資料集完全公開且透明，以支持進一步的研究（程式碼：https://github.com/LiqunMa/FBI-LLM。模型：https://huggingface.co/LiqunMa/）。

##### **Safe and Reliable Training of Learning-Based Aerospace Controllers**
2407.07088v1 by Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee Newell, Umberto Ravaioli, Baoluo Meng, Michael Durling, Kerianne Hobbs, Milan Ganai, Tobey Shim, Guy Katz, Clark Barrett

In recent years, deep reinforcement learning (DRL) approaches have generated
highly successful controllers for a myriad of complex domains. However, the
opaque nature of these models limits their applicability in aerospace systems
and safety-critical domains, in which a single mistake can have dire
consequences. In this paper, we present novel advancements in both the training
and verification of DRL controllers, which can help ensure their safe behavior.
We showcase a design-for-verification approach utilizing k-induction and
demonstrate its use in verifying liveness properties. In addition, we also give
a brief overview of neural Lyapunov Barrier certificates and summarize their
capabilities on a case study. Finally, we describe several other novel
reachability-based approaches which, despite failing to provide guarantees of
interest, could be effective for verification of other DRL systems, and could
be of further interest to the community.

摘要：近年來，深度強化學習 (DRL) 方法已產生了許多複雜領域的極為成功的控制器。然而，這些模型的不透明性質限制了它們在航空太空系統和安全關鍵領域中的應用性，在這些領域中，一個錯誤可能會導致可怕的後果。在本文中，我們展示了 DRL 控制器的訓練和驗證方面的最新進展，這有助於確保其安全行為。我們展示了一個利用 k 感應的設計驗證方法，並展示了它在驗證活性屬性中的用途。此外，我們還簡要概述了神經李亞普諾夫障礙證書，並總結了它們在案例研究中的能力。最後，我們描述了幾種其他新穎的可達性方法，儘管這些方法未能提供感興趣的保證，但它們對於驗證其他 DRL 系統可能是有效的，並且可能對社區進一步感興趣。

##### **CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**
2407.07087v1 by Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh

Evaluating the degree of reproduction of copyright-protected content by
language models (LMs) is of significant interest to the AI and legal
communities. Although both literal and non-literal similarities are considered
by courts when assessing the degree of reproduction, prior research has focused
only on literal similarities. To bridge this gap, we introduce CopyBench, a
benchmark designed to measure both literal and non-literal copying in LM
generations. Using copyrighted fiction books as text sources, we provide
automatic evaluation protocols to assess literal and non-literal copying,
balanced against the model utility in terms of the ability to recall facts from
the copyrighted works and generate fluent completions. We find that, although
literal copying is relatively rare, two types of non-literal copying -- event
copying and character copying -- occur even in models as small as 7B
parameters. Larger models demonstrate significantly more copying, with literal
copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3%
to 6.9% when comparing Llama3-8B and 70B models, respectively. We further
evaluate the effectiveness of current strategies for mitigating copying and
show that (1) training-time alignment can reduce literal copying but may
increase non-literal copying, and (2) current inference-time mitigation methods
primarily reduce literal but not non-literal copying.

摘要：評估語言模型 (LM) 複製受版權保護內容的程度，對 AI 和法律社群而言意義重大。儘管法院在評估複製程度時會考慮文字和非文字的相似性，但先前的研究僅關注文字相似性。為了彌補這個差距，我們引入了 CopyBench，一個基準測試，旨在衡量 LM 生成中的文字和非文字複製。使用受版權保護的小說書籍作為文本來源，我們提供了自動評估協定，以評估文字和非文字複製，並根據從受版權保護的作品中提取事實和產生流暢完成的能力，來衡量模型實用性。我們發現，儘管文字複製相對罕見，但即使在參數小至 7B 的模型中，也會發生兩種非文字複製——事件複製和角色複製。較大的模型顯示出顯著更多的複製，當比較 Llama3-8B 和 70B 模型時，文字複製率從 0.2% 增加到 10.5%，非文字複製從 2.3% 增加到 6.9%。我們進一步評估了當前減輕複製策略的有效性，並表明 (1) 訓練時間校準可以減少文字複製，但可能會增加非文字複製，以及 (2) 當前的推論時間減輕方法主要減少文字複製，但不會減少非文字複製。

##### **Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**
2407.07086v1 by Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber

Multi-agent reinforcement learning (MARL) methods struggle with the
non-stationarity of multi-agent systems and fail to adaptively learn online
when tested with novel agents. Here, we leverage large language models (LLMs)
to create an autonomous agent that can handle these challenges. Our agent,
Hypothetical Minds, consists of a cognitively-inspired architecture, featuring
modular components for perception, memory, and hierarchical planning over two
levels of abstraction. We introduce the Theory of Mind module that scaffolds
the high-level planning process by generating hypotheses about other agents'
strategies in natural language. It then evaluates and iteratively refines these
hypotheses by reinforcing hypotheses that make correct predictions about the
other agents' behavior. Hypothetical Minds significantly improves performance
over previous LLM-agent and RL baselines on a range of competitive, mixed
motive, and collaborative domains in the Melting Pot benchmark, including both
dyadic and population-based environments. Additionally, comparisons against
LLM-agent baselines and ablations reveal the importance of hypothesis
evaluation and refinement for succeeding on complex scenarios.

摘要：多智能體強化學習 (MARL) 方法難以應對多智能體系統的不穩定性，並且在使用新智能體進行測試時無法適應性地線上學習。在這裡，我們利用大型語言模型 (LLM) 來創建一個可以應對這些挑戰的自主智能體。我們的智能體 Hypothetical Minds 由認知啟發的架構組成，具有用於感知、記憶和分層規劃的模組化組件，涵蓋兩個抽象層級。我們引入了心智理論模組，該模組透過以自然語言生成關於其他智能體策略的假設，來支撐高階規劃流程。然後，它會評估並反覆優化這些假設，方法是強化對其他智能體行為做出正確預測的假設。在 Melting Pot 基準中的一系列競爭、混合動機和協作領域（包括二元和基於群體的環境），Hypothetical Minds 的效能顯著優於先前的 LLM 智能體和 RL 基準。此外，與 LLM 智能體基線和消融的比較顯示了假設評估和優化對於在複雜場景中取得成功的重要性。

##### **Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**
2407.07080v1 by Shaltiel Shmidman, Avi Shmidman, Amir DN Cohen, Moshe Koppel

Training large language models (LLMs) in low-resource languages such as
Hebrew poses unique challenges. In this paper, we introduce DictaLM2.0 and
DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a
substantial corpus of approximately 200 billion tokens in both Hebrew and
English. Adapting a pre-trained model to a new language involves specialized
techniques that differ significantly from training a model from scratch or
further training existing models on well-resourced languages such as English.
We outline these novel training methodologies, which facilitate effective
learning and adaptation to the linguistic properties of Hebrew. Additionally,
we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to
enhance its performance on task-specific instructions. To rigorously evaluate
our models, we introduce a new benchmark suite for Hebrew LLM evaluation,
covering a diverse set of tasks including Question Answering, Sentiment
Analysis, Winograd Schema Challenge, Translation, and Summarization. Our work
not only addresses the intricacies of training LLMs in low-resource languages
but also proposes a framework that can be leveraged for adapting other LLMs to
various non-English languages, contributing to the broader field of
multilingual NLP.

摘要：在希伯來語等低資源語言中訓練大型語言模型 (LLM) 會帶來獨特的挑戰。在本文中，我們介紹了 DictaLM2.0 和 DictaLM2.0-Instruct，這兩個 LLM 是從 Mistral 模型衍生的，並在包含約 2,000 億個希伯來語和英語詞彙的龐大語料庫中訓練。將預訓練模型適應到新語言涉及專業技術，這與從頭開始訓練模型或進一步訓練現有模型（例如英語等資源豐富的語言）有顯著不同。我們概述了這些新穎的訓練方法，有助於有效學習和適應希伯來語的語言特性。此外，我們針對全面的指導資料集微調 DictaLM2.0-Instruct，以提升其在特定任務指示上的效能。為了嚴格評估我們的模型，我們為希伯來語 LLM 評估引入了新的基準組，涵蓋了多樣化的任務集，包括問答、情緒分析、Winograd 模式挑戰、翻譯和摘要。我們的研究不僅解決了在低資源語言中訓練 LLM 的複雜性，還提出了可用於將其他 LLM 適應到各種非英語語言的架構，為多語言 NLP 的廣泛領域做出貢獻。

##### **ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**
2407.07077v1 by Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, Kwan-Yee K. Wong

While personalized text-to-image generation has enabled the learning of a
single concept from multiple images, a more practical yet challenging scenario
involves learning multiple concepts within a single image. However, existing
works tackling this scenario heavily rely on extensive human annotations. In
this paper, we introduce a novel task named Unsupervised Concept Extraction
(UCE) that considers an unsupervised setting without any human knowledge of the
concepts. Given an image that contains multiple concepts, the task aims to
extract and recreate individual concepts solely relying on the existing
knowledge from pretrained diffusion models. To achieve this, we present
ConceptExpress that tackles UCE by unleashing the inherent capabilities of
pretrained diffusion models in two aspects. Specifically, a concept
localization approach automatically locates and disentangles salient concepts
by leveraging spatial correspondence from diffusion self-attention; and based
on the lookup association between a concept and a conceptual token, a
concept-wise optimization process learns discriminative tokens that represent
each individual concept. Finally, we establish an evaluation protocol tailored
for the UCE task. Extensive experiments demonstrate that ConceptExpress is a
promising solution to the UCE task. Our code and data are available at:
https://github.com/haoosz/ConceptExpress

摘要：<paragraph>雖然個人化的文字轉圖像生成已能從多張圖像中學習單一概念，但更實際且具挑戰性的場景是學習單一圖像中的多個概念。然而，現有的處理此場景的作品極度依賴於大量的標註。在本文中，我們引入了一個名為無監督概念萃取 (UCE) 的新任務，它考慮了在沒有人類概念知識的情況下的無監督設定。給定包含多個概念的圖像，此任務旨在僅依賴於預訓練擴散模型的現有知識來萃取和重建個別概念。為達成此目的，我們提出了 ConceptExpress，它透過釋放預訓練擴散模型在兩個方面的固有能力來處理 UCE。具體來說，概念定位方法透過利用擴散自注意力中的空間對應自動定位和解開顯著概念；而基於概念和概念 token 之間的查詢關聯，概念優化程序會學習表示每個個別概念的區分 token。最後，我們建立了一個專門針對 UCE 任務的評估協定。廣泛的實驗證明 ConceptExpress 是 UCE 任務的有前途的解決方案。我們的程式碼和資料可在以下取得：https://github.com/haoosz/ConceptExpress</paragraph>

##### **Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**
2407.07071v1 by Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James Glass

When asked to summarize articles or answer questions given a passage, large
language models (LLMs) can hallucinate details and respond with unsubstantiated
answers that are inaccurate with respect to the input context. This paper
describes a simple approach for detecting such contextual hallucinations. We
hypothesize that contextual hallucinations are related to the extent to which
an LLM attends to information in the provided context versus its own
generations. Based on this intuition, we propose a simple hallucination
detection model whose input features are given by the ratio of attention
weights on the context versus newly generated tokens (for each attention head).
We find that a linear classifier based on these lookback ratio features is as
effective as a richer detector that utilizes the entire hidden states of an LLM
or a text-based entailment model. The lookback ratio-based detector -- Lookback
Lens -- is found to transfer across tasks and even models, allowing a detector
that is trained on a 7B model to be applied (without retraining) to a larger
13B model. We further apply this detector to mitigate contextual
hallucinations, and find that a simple classifier-guided decoding approach is
able to reduce the amount of hallucination, for example by 9.6% in the XSum
summarization task.

摘要：當要求大型語言模型 (LLM) 總結文章或回答給定段落的題目時，它們可能會產生幻覺細節，並以與輸入內容無關的不實答案回應。本論文描述了一種檢測此類語境幻覺的簡單方法。我們假設語境幻覺與 LLM 關注所提供語境中的資訊與其自身產生的資訊的程度有關。基於此直覺，我們提出了一個簡單的幻覺檢測模型，其輸入特徵由語境與新產生的權標 (對於每個注意力頭) 上的注意力權重比率給出。我們發現基於這些回顧比率特徵的線性分類器與利用 LLM 的整個隱藏狀態或基於文字的蘊涵模型的更豐富的檢測器一樣有效。發現基於回顧比率的檢測器——回顧鏡頭——可以跨任務甚至跨模型傳輸，允許在 7B 模型上訓練的檢測器應用於更大的 13B 模型 (無需重新訓練)。我們進一步應用此檢測器來減輕語境幻覺，並發現一個簡單的分類器引導的解碼方法能夠減少幻覺量，例如在 XSum 摘要任務中減少 9.6%。

##### **Prompting Techniques for Secure Code Generation: A Systematic Investigation**
2407.07064v1 by Catherine Tony, Nicolás E. Díaz Ferreyra, Markus Mutas, Salem Dhiff, Riccardo Scandariato

Large Language Models (LLMs) are gaining momentum in software development
with prompt-driven programming enabling developers to create code from natural
language (NL) instructions. However, studies have questioned their ability to
produce secure code and, thereby, the quality of prompt-generated software.
Alongside, various prompting techniques that carefully tailor prompts have
emerged to elicit optimal responses from LLMs. Still, the interplay between
such prompting strategies and secure code generation remains under-explored and
calls for further investigations. OBJECTIVE: In this study, we investigate the
impact of different prompting techniques on the security of code generated from
NL instructions by LLMs. METHOD: First we perform a systematic literature
review to identify the existing prompting techniques that can be used for code
generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,
and GPT-4 models for secure code generation. For this, we used an existing
dataset consisting of 150 NL security-relevant code-generation prompts.
RESULTS: Our work (i) classifies potential prompting techniques for code
generation (ii) adapts and evaluates a subset of the identified techniques for
secure code generation tasks and (iii) observes a reduction in security
weaknesses across the tested LLMs, especially after using an existing technique
called Recursive Criticism and Improvement (RCI), contributing valuable
insights to the ongoing discourse on LLM-generated code security.

摘要：大型語言模型 (LLM) 在軟體開發中獲得了動能，提示驅動程式讓開發人員能夠從自然語言 (NL) 指令建立程式碼。然而，研究質疑它們產生安全程式碼的能力，從而質疑提示產生的軟體品質。此外，出現了各種仔細調整提示的提示技術，從 LLM 引發最佳回應。儘管如此，這種提示策略與安全程式碼產生之間的交互作用仍然未被充分探討，並需要進一步調查。目標：在本研究中，我們調查了不同提示技術對 LLM 從 NL 指令產生的程式碼安全性的影響。方法：首先，我們執行系統性的文獻回顧，以找出可用於程式碼產生任務的現有提示技術。在 GPT-3、GPT-3.5 和 GPT-4 模型上評估這些技術的子集，以產生安全程式碼。為此，我們使用了一個現有的資料集，其中包含 150 個與 NL 安全相關的程式碼產生提示。結果：我們的研究 (i) 分類了程式碼產生的潛在提示技術 (ii) 調整並評估了一部分已識別的技術，以進行安全的程式碼產生任務，以及 (iii) 觀察到在測試的 LLM 中，特別是在使用現有的技術，稱為遞迴批評和改進 (RCI) 之後，安全性弱點減少，為 LLM 產生的程式碼安全性持續討論提供了有價值的見解。

##### **Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**
2407.07061v2 by Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun

The rapid advancement of large language models (LLMs) has paved the way for
the development of highly capable autonomous agents. However, existing
multi-agent frameworks often struggle with integrating diverse capable
third-party agents due to reliance on agents defined within their own
ecosystems. They also face challenges in simulating distributed environments,
as most frameworks are limited to single-device setups. Furthermore, these
frameworks often rely on hard-coded communication pipelines, limiting their
adaptability to dynamic task requirements. Inspired by the concept of the
Internet, we propose the Internet of Agents (IoA), a novel framework that
addresses these limitations by providing a flexible and scalable platform for
LLM-based multi-agent collaboration. IoA introduces an agent integration
protocol, an instant-messaging-like architecture design, and dynamic mechanisms
for agent teaming and conversation flow control. Through extensive experiments
on general assistant tasks, embodied AI tasks, and retrieval-augmented
generation benchmarks, we demonstrate that IoA consistently outperforms
state-of-the-art baselines, showcasing its ability to facilitate effective
collaboration among heterogeneous agents. IoA represents a step towards linking
diverse agents in an Internet-like environment, where agents can seamlessly
collaborate to achieve greater intelligence and capabilities. Our codebase has
been released at \url{https://github.com/OpenBMB/IoA}.

摘要：大型語言模型 (LLM) 的快速進展為高度自主代理的發展鋪平了道路。然而，現有的多代理架構通常難以整合多樣化的第三方代理，因為它們依賴於在自身生態系統中定義的代理。它們在模擬分散式環境時也面臨挑戰，因為大多數架構僅限於單設備設置。此外，這些架構通常依賴於硬編碼的通信管道，限制了它們適應動態任務需求的能力。受互聯網概念的啟發，我們提出了代理互聯網 (IoA)，這是一個新穎的框架，通過提供一個靈活且可擴展的 LLM 多代理協作平台來解決這些限制。IoA 引入了代理整合協議、即時訊息類架構設計以及代理組隊和對話流程控制的動態機制。通過對一般助理任務、具體化 AI 任務和檢索增強生成基準的廣泛實驗，我們證明 IoA 始終優於最先進的基準，展示了其促進異質代理之間有效協作的能力。IoA 代表了在類互聯網環境中連結不同代理的一步，在該環境中，代理可以無縫協作以實現更高的智慧和能力。我們的代碼庫已發布於 \url{https://github.com/OpenBMB/IoA}。

##### **CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**
2407.07046v1 by Yangmin Li, Ruiqi Zhu, Wengen Li

Multimodal sentiment analysis is an active research area that combines
multiple data modalities, e.g., text, image and audio, to analyze human
emotions and benefits a variety of applications. Existing multimodal sentiment
analysis methods can be classified as modality interaction-based methods,
modality transformation-based methods and modality similarity-based methods.
However, most of these methods highly rely on the strong correlations between
modalities, and cannot fully uncover and utilize the correlations between
modalities to enhance sentiment analysis. Therefore, these methods usually
achieve bad performance for identifying the sentiment of multimodal data with
weak correlations. To address this issue, we proposed a two-stage
semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)
which consists pre-training stage and prediction stage. At the pre-training
stage, a modality correlation contrastive learning module is designed to
efficiently learn modality correlation coefficients between different
modalities. At the prediction stage, the learned correlation coefficients are
fused with modality representations to make the sentiment prediction. According
to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT
obviously surpasses state-of-the-art multimodal sentiment analysis methods.

摘要：多模态情感分析是一个活跃的研究领域，它结合了多种数据模式，例如文本、图像和音频，来分析人类情绪，并使各种应用程序受益。现有的多模态情感分析方法可以分为基于模态交互的方法、基于模态转换的方法和基于模态相似性的方法。然而，这些方法大多高度依赖于模态之间的强相关性，并且无法充分发现和利用模态之间的相关性来增强情感分析。因此，这些方法通常在识别弱相关性多模态数据的语义时表现不佳。为了解决这个问题，我们提出了一个两阶段的半监督模型，称为相关感知多模态转换器 (CorMulT)，它由预训练阶段和预测阶段组成。在预训练阶段，设计了一个模态相关对比学习模块，以有效地学习不同模态之间的模态相关系数。在预测阶段，学习到的相关系数与模态表示融合，以进行情感预测。根据流行的多模态数据集 CMU-MOSEI 上的实验，CorMulT 明显超越了最先进的多模态情感分析方法。

##### **Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**
2407.07045v1 by Christian Riefolo, Nicola Fanizzi, Claudia d'Amato

Tackling the problem of learning probabilistic classifiers from incomplete
data in the context of Knowledge Graphs expressed in Description Logics, we
describe an inductive approach based on learning simple belief networks.
Specifically, we consider a basic probabilistic model, a Naive Bayes
classifier, based on multivariate Bernoullis and its extension to a two-tier
network in which this classification model is connected to a lower layer
consisting of a mixture of Bernoullis. We show how such models can be converted
into (probabilistic) axioms (or rules) thus ensuring more interpretability.
Moreover they may be also initialized exploiting expert knowledge. We present
and discuss the outcomes of an empirical evaluation which aimed at testing the
effectiveness of the models on a number of random classification problems with
different ontologies.

摘要：針對在描述邏輯中表示的知識圖表中從不完整資料學習機率分類器的問題，我們描述一種基於學習簡單信念網路的歸納方法。具體來說，我們考慮一個基本的機率模型，一個樸素貝氏分類器，它基於多變量伯努利分布及其擴展到一個兩層網路，其中這個分類模型連接到由伯努利混合組成的下層。我們展示如何將這些模型轉換為（機率）公理（或規則），從而確保更高的可解釋性。此外，它們還可以利用專家知識進行初始化。我們提出並討論了實證評估的結果，其目的是測試這些模型在具有不同本體的多個隨機分類問題上的有效性。

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**
2407.07035v1 by Yue Zhang, Ziqiao Ma, Jialu Li, Yanyuan Qiao, Zun Wang, Joyce Chai, Qi Wu, Mohit Bansal, Parisa Kordjamshidi

Vision-and-Language Navigation (VLN) has gained increasing attention over
recent years and many approaches have emerged to advance their development. The
remarkable achievements of foundation models have shaped the challenges and
proposed methods for VLN research. In this survey, we provide a top-down review
that adopts a principled framework for embodied planning and reasoning, and
emphasizes the current methods and future opportunities leveraging foundation
models to address VLN challenges. We hope our in-depth discussions could
provide valuable resources and insights: on one hand, to milestone the progress
and explore opportunities and potential roles for foundation models in this
field, and on the other, to organize different challenges and solutions in VLN
to foundation model researchers.

摘要：視覺語言導航 (VLN) 近年來備受關注，許多方法也應運而生，以推進其發展。基礎模型的顯著成就塑造了 VLN 研究的挑戰和提出的方法。在這項調查中，我們提供了一項自上而下的回顧，採用了具體的框架進行具體規劃和推理，並強調了當前的方法和未來的機會，利用基礎模型來應對 VLN 挑戰。我們希望我們的深入討論能提供有價值的資源和見解：一方面，記錄進度並探索基礎模型在這一領域的機會和潛在作用，另一方面，組織 VLN 中不同的挑戰和解決方案，以供基礎模型研究人員參考。

##### **Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**
2407.07026v1 by Daiqing Wu, Dongbao Yang, Huawen Shen, Can Ma, Yu Zhou

With the proliferation of social media posts in recent years, the need to
detect sentiments in multimodal (image-text) content has grown rapidly. Since
posts are user-generated, the image and text from the same post can express
different or even contradictory sentiments, leading to potential
\textbf{sentiment discrepancy}. However, existing works mainly adopt a
single-branch fusion structure that primarily captures the consistent sentiment
between image and text. The ignorance or implicit modeling of discrepant
sentiment results in compromised unimodal encoding and limited performances. In
this paper, we propose a semantics Completion and Decomposition (CoDe) network
to resolve the above issue. In the semantics completion module, we complement
image and text representations with the semantics of the OCR text embedded in
the image, helping bridge the sentiment gap. In the semantics decomposition
module, we decompose image and text representations with exclusive projection
and contrastive learning, thereby explicitly capturing the discrepant sentiment
between modalities. Finally, we fuse image and text representations by
cross-attention and combine them with the learned discrepant sentiment for
final classification. Extensive experiments conducted on four multimodal
sentiment datasets demonstrate the superiority of CoDe against SOTA methods.

摘要：隨著近年來社群媒體貼文的激增，偵測多模態（圖像文字）內容的情緒的需求也迅速增長。由於貼文是由使用者產生的，來自同一個貼文的圖像和文字可能表達出不同甚至矛盾的情緒，導致潛在的**情緒差異**。然而，現有的作品主要採用單分支融合結構，主要擷取圖像和文字之間一致的情緒。對矛盾情緒的忽略或隱式建模導致受損的單模態編碼和有限的效能。在本文中，我們提出語義完成和分解 (CoDe) 網路來解決上述問題。在語義完成模組中，我們以嵌入在圖像中的 OCR 文字的語義來補充圖像和文字表示，有助於縮小情緒差距。在語義分解模組中，我們使用獨家投影和對比學習來分解圖像和文字表示，從而明確擷取模態之間的矛盾情緒。最後，我們透過交叉注意力融合圖像和文字表示，並將它們與學習到的矛盾情緒結合起來進行最終分類。在四個多模態情緒資料集上進行的廣泛實驗證明了 CoDe 優於 SOTA 方法。

##### **Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**
2407.07024v1 by Jeongseok Hyun, Su Ho Han, Hyolim Kang, Joon-Young Lee, Seon Joo Kim

The vocabulary size in temporal action localization (TAL) is constrained by
the scarcity of large-scale annotated datasets. To address this, recent works
incorporate powerful pre-trained vision-language models (VLMs), such as CLIP,
to perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on
extensive image/video-text pairs, existing OV-TAL methods still rely on small,
fully labeled TAL datasets for training an action localizer. In this paper, we
explore the scalability of self-training with unlabeled YouTube videos for
OV-TAL. Our self-training approach consists of two stages. First, a
class-agnostic action localizer is trained on a human-labeled TAL dataset and
used to generate pseudo-labels for unlabeled videos. Second, the large-scale
pseudo-labeled dataset is combined with the human-labeled dataset to train the
localizer. Extensive experiments demonstrate that leveraging web-scale videos
in self-training significantly enhances the generalizability of an action
localizer. Additionally, we highlighted issues with existing OV-TAL evaluation
schemes and proposed a new evaluation protocol. Code is released at
https://github.com/HYUNJS/STOV-TAL

摘要：時序動作定位 (TAL) 中的詞彙量受到大規模標註資料集稀少的限制。為了解決這個問題，最近的研究結合了強大的預訓練視覺語言模型 (VLM)，例如 CLIP，來執行開放詞彙 TAL (OV-TAL)。然而，與在大量的影像/影片-文字配對上訓練的 VLM 不同，現有的 OV-TAL 方法仍然依賴於小型、完全標註的 TAL 資料集來訓練動作定位器。在本文中，我們探討了使用未標註的 YouTube 影片進行自訓練在 OV-TAL 中的可擴充性。我們的自訓練方法包含兩個階段。首先，在人工標註的 TAL 資料集上訓練一個與類別無關的動作定位器，並用於為未標註的影片產生偽標籤。其次，將大規模的偽標籤資料集與人工標註的資料集結合起來訓練定位器。大量的實驗證明，在自訓練中利用網路規模的影片可以顯著增強動作定位器的泛化能力。此外，我們強調了現有 OV-TAL 評估方案的問題，並提出了一個新的評估協定。程式碼已發布於 https://github.com/HYUNJS/STOV-TAL

##### **Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**
2407.07020v1 by Haicheng Liao, Yongkang Li, Zhenning Li, Chengyue Wang, Chunlin Tian, Yuming Huang, Zilin Bian, Kaiqun Zhu, Guofa Li, Ziyuan Pu, Jia Hu, Zhiyong Cui, Chengzhong Xu

Accurately and safely predicting the trajectories of surrounding vehicles is
essential for fully realizing autonomous driving (AD). This paper presents the
Human-Like Trajectory Prediction model (HLTP++), which emulates human cognitive
processes to improve trajectory prediction in AD. HLTP++ incorporates a novel
teacher-student knowledge distillation framework. The "teacher" model equipped
with an adaptive visual sector, mimics the dynamic allocation of attention
human drivers exhibit based on factors like spatial orientation, proximity, and
driving speed. On the other hand, the "student" model focuses on real-time
interaction and human decision-making, drawing parallels to the human memory
storage mechanism. Furthermore, we improve the model's efficiency by
introducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for
faster and more precise predictions with fewer parameters. Evaluated using the
NGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance
compared to existing models, which reduces the predicted trajectory error with
over 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++
demonstrates strong adaptability in challenging environments with incomplete
input data. This marks a significant stride in the journey towards fully AD
systems.

摘要：準確且安全地預測周圍車輛的軌跡對於完全實現自動駕駛 (AD) 至關重要。本文提出類人軌跡預測模型 (HLTP++)，模擬人類認知過程以改善 AD 中的軌跡預測。HLTP++ 採用新穎的師生知識蒸餾框架。配備自適應視覺扇區的「教師」模型，模擬人類駕駛員根據空間方向、接近度和行駛速度等因素動態分配注意力。另一方面，「學生」模型專注於即時互動和人類決策，與人類記憶儲存機制形成對應。此外，我們通過引入新的傅立葉自適應尖峰神經網路 (FA-SNN) 來提高模型的效率，從而使用更少的參數進行更快速、更準確的預測。使用 NGSIM、HighD 和 MoCAD 基準進行評估，HLTP++ 表現出優於現有模型的卓越性能，在 NGSIM 資料集上將預測軌跡誤差降低了 11% 以上，在 HighD 資料集上降低了 25%。此外，HLTP++ 在輸入資料不完整的情況下表現出強大的適應性。這標誌著朝著完全 AD 系統邁出了重要的一步。

##### **Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**
2407.07019v1 by Inwon Kang, William Van Woensel, Oshani Seneviratne

We explore using Large Language Models (LLMs) to generate application code
that automates health insurance processes from text-based policies. We target
blockchain-based smart contracts as they offer immutability, verifiability,
scalability, and a trustless setting: any number of parties can use the smart
contracts, and they need not have previously established trust relationships
with each other. Our methodology generates outputs at increasing levels of
technical detail: (1) textual summaries, (2) declarative decision logic, and
(3) smart contract code with unit tests. We ascertain LLMs are good at the task
(1), and the structured output is useful to validate tasks (2) and (3).
Declarative languages (task 2) are often used to formalize healthcare policies,
but their execution on blockchain is non-trivial. Hence, task (3) attempts to
directly automate the process using smart contracts. To assess the LLM output,
we propose completeness, soundness, clarity, syntax, and functioning code as
metrics. Our evaluation employs three health insurance policies (scenarios)
with increasing difficulty from Medicare's official booklet. Our evaluation
uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our
findings confirm that LLMs perform quite well in generating textual summaries.
Although outputs from tasks (2)-(3) are useful starting points, they require
human oversight: in multiple cases, even "runnable" code will not yield sound
results; the popularity of the target language affects the output quality; and
more complex scenarios still seem a bridge too far. Nevertheless, our
experiments demonstrate the promise of LLMs for translating textual process
descriptions into smart contracts.

摘要：<paragraph>我們探討使用大型語言模型 (LLM) 來產生應用程式程式碼，以自動化基於文字政策的健康保險流程。我們以區塊鏈智慧合約為目標，因為它們提供不可變性、可驗證性、可擴充性，以及無需信任的設定：任何數量的參與方都可以使用智慧合約，而且他們不必事先建立彼此的信任關係。我們的做法會產生技術細節程度越來越高的輸出：(1) 文字摘要，(2) 宣告式決策邏輯，以及 (3) 具備單元測試的智慧合約程式碼。我們確定 LLM 擅長任務 (1)，而結構化輸出有助於驗證任務 (2) 和 (3)。宣告式語言 (任務 2) 通常用於將醫療保健政策形式化，但它們在區塊鏈上的執行並非易事。因此，任務 (3) 嘗試直接使用智慧合約自動化流程。為了評估 LLM 輸出，我們提出完整性、健全性、清晰性、語法和運作程式碼作為指標。我們的評估採用了三項醫療保險政策（場景），其難度從 Medicare 的官方手冊中逐漸增加。我們的評估使用 GPT-3.5 Turbo、GPT-3.5 Turbo 16K、GPT-4、GPT-4 Turbo 和 CodeLLaMA。我們的發現證實，LLM 在產生文字摘要方面表現得非常好。儘管任務 (2)-(3) 的輸出是有用的起點，但它們需要人工監督：在多種情況下，即使是「可執行」的程式碼也不會產生健全的結果；目標語言的普及程度會影響輸出品質；而且更複雜的場景似乎仍遙不可及。儘管如此，我們的實驗證明了 LLM 在將文字流程描述轉換為智慧合約方面的潛力。</paragraph>

