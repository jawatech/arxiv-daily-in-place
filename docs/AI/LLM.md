
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Canonical Variates in Wasserstein Metric Space**|Jia Li et.al.|[2405.15768v1](http://arxiv.org/abs/2405.15768v1)|null|
|**2024-05-24**|**Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**|Pranab Sahoo et.al.|[2405.15766v1](http://arxiv.org/abs/2405.15766v1)|[link](https://github.com/singhayush27/mmade)|
|**2024-05-24**|**Scaling Laws for Discriminative Classification in Large Language Models**|Dean Wyatte et.al.|[2405.15765v1](http://arxiv.org/abs/2405.15765v1)|null|
|**2024-05-24**|**GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction**|Virginia K. Felkner et.al.|[2405.15760v1](http://arxiv.org/abs/2405.15760v1)|null|
|**2024-05-24**|**InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation**|Yuchi Wang et.al.|[2405.15758v1](http://arxiv.org/abs/2405.15758v1)|[link](https://github.com/wangyuchi369/InstructAvatar)|
|**2024-05-24**|**Sparse Expansion and Neuronal Disentanglement**|Shashata Sawmya et.al.|[2405.15756v1](http://arxiv.org/abs/2405.15756v1)|null|
|**2024-05-24**|**Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence**|Abhinav Patil et.al.|[2405.15750v1](http://arxiv.org/abs/2405.15750v1)|null|
|**2024-05-24**|**Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**|Andres Algaba et.al.|[2405.15739v1](http://arxiv.org/abs/2405.15739v1)|null|
|**2024-05-24**|**Understanding the differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks**|Jerome Sieber et.al.|[2405.15731v1](http://arxiv.org/abs/2405.15731v1)|[link](https://github.com/intelligentcontrolsystems/dsf-mqar)|
|**2024-05-24**|**Optimizing Large Language Models for OpenAPI Code Completion**|Bohdan Petryshyn et.al.|[2405.15729v1](http://arxiv.org/abs/2405.15729v1)|null|
|**2024-05-24**|**EmpathicStories++: A Multimodal Dataset for Empathy towards Personal Experiences**|Jocelyn Shen et.al.|[2405.15708v1](http://arxiv.org/abs/2405.15708v1)|null|
|**2024-05-24**|**Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models**|Yue Zhang et.al.|[2405.15684v1](http://arxiv.org/abs/2405.15684v1)|null|
|**2024-05-24**|**VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging the Visual Perception Gap**|Sreyan Ghosh et.al.|[2405.15683v1](http://arxiv.org/abs/2405.15683v1)|null|
|**2024-05-24**|**Consistency of Neural Causal Partial Identification**|Jiyuan Tan et.al.|[2405.15673v1](http://arxiv.org/abs/2405.15673v1)|null|
|**2024-05-24**|**Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF) Tables**|James Hinns et.al.|[2405.15661v1](http://arxiv.org/abs/2405.15661v1)|null|
|**2024-05-24**|**HDC: Hierarchical Semantic Decoding with Counting Assistance for Generalized Referring Expression Segmentation**|Zhuoyan Luo et.al.|[2405.15658v1](http://arxiv.org/abs/2405.15658v1)|null|
|**2024-05-24**|**GECKO: Generative Language Model for English, Code and Korean**|Sungwoo Oh et.al.|[2405.15640v1](http://arxiv.org/abs/2405.15640v1)|null|
|**2024-05-24**|**M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models**|Hongyu Wang et.al.|[2405.15638v1](http://arxiv.org/abs/2405.15638v1)|[link](https://github.com/m4u-benchmark/m4u)|
|**2024-05-24**|**Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment**|Hao Sun et.al.|[2405.15624v1](http://arxiv.org/abs/2405.15624v1)|null|
|**2024-05-24**|**Neuromorphic dreaming: A pathway to efficient learning in artificial agents**|Ingo Blakowski et.al.|[2405.15616v1](http://arxiv.org/abs/2405.15616v1)|null|
|**2024-05-24**|**Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study**|Karl Tamberg et.al.|[2405.15614v1](http://arxiv.org/abs/2405.15614v1)|null|
|**2024-05-24**|**Text Generation: A Systematic Literature Review of Tasks, Evaluation, and Challenges**|Jonas Becker et.al.|[2405.15604v1](http://arxiv.org/abs/2405.15604v1)|null|
|**2024-05-24**|**MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel Data Fusion Network Model Integrating CNN, LSTM, and GRU**|Md Abrar Jahin et.al.|[2405.15598v1](http://arxiv.org/abs/2405.15598v1)|null|
|**2024-05-24**|**Profiling checkpointing schedules in adjoint ST-AD**|Laurent Hascoët et.al.|[2405.15590v1](http://arxiv.org/abs/2405.15590v1)|null|
|**2024-05-24**|**Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems**|Vishal Vivek Saley et.al.|[2405.15585v1](http://arxiv.org/abs/2405.15585v1)|null|
|**2024-05-24**|**Generating density nowcasts for U.S. GDP growth with deep learning: Bayes by Backprop and Monte Carlo dropout**|Kristóf Németh et.al.|[2405.15579v1](http://arxiv.org/abs/2405.15579v1)|null|
|**2024-05-24**|**OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code**|Maxence Faldor et.al.|[2405.15568v1](http://arxiv.org/abs/2405.15568v1)|null|
|**2024-05-24**|**Rethinking Independent Cross-Entropy Loss For Graph-Structured Data**|Rui Miao et.al.|[2405.15564v1](http://arxiv.org/abs/2405.15564v1)|null|
|**2024-05-24**|**Certifiably Robust RAG against Retrieval Corruption**|Chong Xiang et.al.|[2405.15556v1](http://arxiv.org/abs/2405.15556v1)|null|
|**2024-05-24**|**Sparse Matrix in Large Language Model Fine-tuning**|Haoze He et.al.|[2405.15525v1](http://arxiv.org/abs/2405.15525v1)|null|
|**2024-05-24**|**Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language Models**|Igor Shilov et.al.|[2405.15523v1](http://arxiv.org/abs/2405.15523v1)|null|
|**2024-05-24**|**A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search**|Huimu Wang et.al.|[2405.15521v1](http://arxiv.org/abs/2405.15521v1)|null|
|**2024-05-24**|**On the Convexity and Reliability of the Bethe Free Energy Approximation**|Harald Leisenberger et.al.|[2405.15514v1](http://arxiv.org/abs/2405.15514v1)|null|
|**2024-05-24**|**ChatGPT Code Detection: Techniques for Uncovering the Source of Code**|Marc Oedingen et.al.|[2405.15512v1](http://arxiv.org/abs/2405.15512v1)|null|
|**2024-05-24**|**Revisiting Counterfactual Regression through the Lens of Gromov-Wasserstein Information Bottleneck**|Hao Yang et.al.|[2405.15505v1](http://arxiv.org/abs/2405.15505v1)|[link](https://github.com/peteryang1031/causal-gwib)|
|**2024-05-24**|**Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs**|Siyuan Guo et.al.|[2405.15485v1](http://arxiv.org/abs/2405.15485v1)|null|
|**2024-05-24**|**Editable Concept Bottleneck Models**|Lijie Hu et.al.|[2405.15476v1](http://arxiv.org/abs/2405.15476v1)|null|
|**2024-05-24**|**Emergence of a High-Dimensional Abstraction Phase in Language Transformers**|Emily Cheng et.al.|[2405.15471v1](http://arxiv.org/abs/2405.15471v1)|null|
|**2024-05-24**|**Linearly Controlled Language Generation with Performative Guarantees**|Emily Cheng et.al.|[2405.15454v1](http://arxiv.org/abs/2405.15454v1)|null|
|**2024-05-24**|**Benchmarking Pre-trained Large Language Models' Potential Across Urdu NLP tasks**|Munief Hassan Tahir et.al.|[2405.15453v1](http://arxiv.org/abs/2405.15453v1)|null|
|**2024-05-24**|**Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top**|Keyuan Cheng et.al.|[2405.15452v1](http://arxiv.org/abs/2405.15452v1)|null|
|**2024-05-24**|**HyperInterval: Hypernetwork approach to training weight interval regions in continual learning**|Patryk Krukowski et.al.|[2405.15444v1](http://arxiv.org/abs/2405.15444v1)|[link](https://github.com/gmum/hyperinterval)|
|**2024-05-24**|**Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented Knowledge Graphs and Vector Database for Accreditation Reporting Assistance**|Candace Edwards et.al.|[2405.15436v1](http://arxiv.org/abs/2405.15436v1)|[link](https://github.com/cs-edwards/advrag)|
|**2024-05-24**|**Luban: Building Open-Ended Creative Agents via Autonomous Embodied Verification**|Yuxuan Guo et.al.|[2405.15414v1](http://arxiv.org/abs/2405.15414v1)|null|
|**2024-05-24**|**ORCA: A Global Ocean Emulator for Multi-year to Decadal Predictions**|Zijie Guo et.al.|[2405.15412v1](http://arxiv.org/abs/2405.15412v1)|null|
|**2024-05-24**|**PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**|Yuandou Wang et.al.|[2405.15398v1](http://arxiv.org/abs/2405.15398v1)|[link](https://github.com/yuandou168/price)|
|**2024-05-24**|**Language-Driven Interactive Traffic Trajectory Generation**|Junkai Xia et.al.|[2405.15388v1](http://arxiv.org/abs/2405.15388v1)|null|
|**2024-05-24**|**Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search**|Nicola Dainese et.al.|[2405.15383v1](http://arxiv.org/abs/2405.15383v1)|null|
|**2024-05-24**|**A Planet Scale Spatial-Temporal Knowledge Graph Based On OpenStreetMap And H3 Grid**|Martin Böckling et.al.|[2405.15375v1](http://arxiv.org/abs/2405.15375v1)|null|
|**2024-05-24**|**Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph**|Runsong Jia et.al.|[2405.15374v1](http://arxiv.org/abs/2405.15374v1)|null|
|**2024-05-24**|**Autonomous Quilt Spreading for Caregiving Robots**|Yuchun Guo et.al.|[2405.15373v1](http://arxiv.org/abs/2405.15373v1)|null|
|**2024-05-24**|**Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection**|Jun Liu et.al.|[2405.15370v1](http://arxiv.org/abs/2405.15370v1)|null|
|**2024-05-24**|**Pipeline Parallelism with Controllable Memory**|Penghui Qi et.al.|[2405.15362v1](http://arxiv.org/abs/2405.15362v1)|null|
|**2024-05-24**|**UnKE: Unstructured Knowledge Editing in Large Language Models**|Jingcheng Deng et.al.|[2405.15349v1](http://arxiv.org/abs/2405.15349v1)|null|
|**2024-05-24**|**BiSup: Bidirectional Quantization Error Suppression for Large Language Models**|Minghui Zou et.al.|[2405.15346v1](http://arxiv.org/abs/2405.15346v1)|null|
|**2024-05-24**|**V-Zen: Efficient GUI Understanding and Precise Grounding With A Novel Multimodal LLM**|Abdur Rahman et.al.|[2405.15341v1](http://arxiv.org/abs/2405.15341v1)|null|
|**2024-05-24**|**Detection and Positive Reconstruction of Cognitive Distortion sentences: Mandarin Dataset and Evaluation**|Shuya Lin et.al.|[2405.15334v1](http://arxiv.org/abs/2405.15334v1)|null|
|**2024-05-24**|**Decompose and Aggregate: A Step-by-Step Interpretable Evaluation Framework**|Minzhi Li et.al.|[2405.15329v1](http://arxiv.org/abs/2405.15329v1)|null|
|**2024-05-24**|**Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs**|Asım Ersoy et.al.|[2405.15320v1](http://arxiv.org/abs/2405.15320v1)|[link](https://github.com/asimokby/turkish-gec)|
|**2024-05-24**|**Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training**|Wenyu Du et.al.|[2405.15319v1](http://arxiv.org/abs/2405.15319v1)|null|
|**2024-05-24**|**Are Long-LLMs A Necessity For Long-Context Tasks?**|Hongjin Qian et.al.|[2405.15318v1](http://arxiv.org/abs/2405.15318v1)|null|
|**2024-05-24**|**NuwaTS: Mending Every Incomplete Time Series**|Jinguo Cheng et.al.|[2405.15317v1](http://arxiv.org/abs/2405.15317v1)|[link](https://github.com/chengyui/nuwats)|
|**2024-05-24**|**\textsc{Retro}]{\textsc{Retro}: \underline{Re}using \underline{t}eacher p\underline{ro}jection head for efficient embedding distillation on Lightweight Models via Self-supervised Learning**|Khanh-Binh Nguyen et.al.|[2405.15311v1](http://arxiv.org/abs/2405.15311v1)|null|
|**2024-05-24**|**Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation**|Ge Qu et.al.|[2405.15307v1](http://arxiv.org/abs/2405.15307v1)|null|
|**2024-05-24**|**DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ**|Jonas Belouadi et.al.|[2405.15306v1](http://arxiv.org/abs/2405.15306v1)|[link](https://github.com/potamides/detikzify)|
|**2024-05-24**|**Towards Understanding How Transformer Perform Multi-step Reasoning with Matching Operation**|Zhiwei Wang et.al.|[2405.15302v1](http://arxiv.org/abs/2405.15302v1)|null|
|**2024-05-24**|**Semi-Supervised Learning guided by the Generalized Bayes Rule under Soft Revision**|Stefan Dietrich et.al.|[2405.15294v1](http://arxiv.org/abs/2405.15294v1)|null|
|**2024-05-24**|**Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**|Jokin Alcibar et.al.|[2405.15292v1](http://arxiv.org/abs/2405.15292v1)|null|
|**2024-05-24**|**Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation**|Abhinav Jain et.al.|[2405.15282v1](http://arxiv.org/abs/2405.15282v1)|null|
|**2024-05-24**|**DFGNN: Dual-frequency Graph Neural Network for Sign-aware Feedback**|Yiqing Wu et.al.|[2405.15280v1](http://arxiv.org/abs/2405.15280v1)|null|
|**2024-05-24**|**Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images**|Saul Fuster et.al.|[2405.15264v1](http://arxiv.org/abs/2405.15264v1)|[link](https://github.com/biomedical-data-analysis-laboratory/histoprognostics)|
|**2024-05-24**|**Novel Kernel Models and Exact Representor Theory for Neural Networks Beyond the Over-Parameterized Regime**|Alistair Shilton et.al.|[2405.15254v1](http://arxiv.org/abs/2405.15254v1)|null|
|**2024-05-24**|**Coaching Copilot: Blended Form of an LLM-Powered Chatbot and a Human Coach to Effectively Support Self-Reflection for Leadership Growth**|Riku Arakawa et.al.|[2405.15250v1](http://arxiv.org/abs/2405.15250v1)|null|
|**2024-05-24**|**DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception**|Run Luo et.al.|[2405.15232v1](http://arxiv.org/abs/2405.15232v1)|null|
|**2024-05-24**|**$i$REPO: $i$mplicit Reward Pairwise Difference based Empirical Preference Optimization**|Long Tan Le et.al.|[2405.15230v1](http://arxiv.org/abs/2405.15230v1)|null|
|**2024-05-24**|**Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition**|Zijin Gu et.al.|[2405.15216v1](http://arxiv.org/abs/2405.15216v1)|null|
|**2024-05-24**|**Decoding at the Speed of Thought: Harnessing Parallel Decoding of Lexical Units for LLMs**|Chenxi Sun et.al.|[2405.15208v1](http://arxiv.org/abs/2405.15208v1)|null|
|**2024-05-24**|**Cross-Task Defense: Instruction-Tuning LLMs for Content Safety**|Yu Fu et.al.|[2405.15202v1](http://arxiv.org/abs/2405.15202v1)|null|
|**2024-05-24**|**RAEE: A Training-Free Retrieval-Augmented Early Exiting Framework for Efficient Inference**|Lianming Huang et.al.|[2405.15198v1](http://arxiv.org/abs/2405.15198v1)|null|
|**2024-05-24**|**Efficient Reinforcement Learning via Large Language Model-based Search**|Siddhant Bhambri et.al.|[2405.15194v1](http://arxiv.org/abs/2405.15194v1)|null|
|**2024-05-24**|**SOAP: Enhancing Efficiency of Generated Code via Self-Optimization**|Dong Huang et.al.|[2405.15189v1](http://arxiv.org/abs/2405.15189v1)|[link](https://github.com/huangd1999/soap)|
|**2024-05-24**|**An Evaluation of Estimative Uncertainty in Large Language Models**|Zhisheng Tang et.al.|[2405.15185v1](http://arxiv.org/abs/2405.15185v1)|null|
|**2024-05-24**|**RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation**|Peihua Mai et.al.|[2405.15182v1](http://arxiv.org/abs/2405.15182v1)|null|
|**2024-05-24**|**VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks**|Yang Li et.al.|[2405.15179v1](http://arxiv.org/abs/2405.15179v1)|null|
|**2024-05-24**|**Diffusion Actor-Critic with Entropy Regulator**|Yinuo Wang et.al.|[2405.15177v1](http://arxiv.org/abs/2405.15177v1)|null|
|**2024-05-24**|**A Solution-based LLM API-using Methodology for Academic Information Seeking**|Yuanchun Wang et.al.|[2405.15165v1](http://arxiv.org/abs/2405.15165v1)|[link](https://github.com/ruckbreasoning/soay)|
|**2024-05-24**|**From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks**|Jacob Russin et.al.|[2405.15164v1](http://arxiv.org/abs/2405.15164v1)|null|
|**2024-05-24**|**Online Prompt Pricing based on Combinatorial Multi-Armed Bandit and Hierarchical Stackelberg Game**|Meiling Li et.al.|[2405.15154v1](http://arxiv.org/abs/2405.15154v1)|null|
|**2024-05-24**|**Machine Unlearning in Large Language Models**|Saaketh Koundinya Gundavarapu et.al.|[2405.15152v1](http://arxiv.org/abs/2405.15152v1)|[link](https://github.com/shreya1313/llm-unlearning)|
|**2024-05-24**|**CulturePark: Boosting Cross-cultural Understanding in Large Language Models**|Cheng Li et.al.|[2405.15145v1](http://arxiv.org/abs/2405.15145v1)|null|
|**2024-05-24**|**Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models**|Cong Lu et.al.|[2405.15143v1](http://arxiv.org/abs/2405.15143v1)|[link](https://github.com/conglu1997/intelligent-go-explore)|
|**2024-05-24**|**Efficient Biomedical Entity Linking: Clinical Text Standardization with Low-Resource Techniques**|Akshit Achara et.al.|[2405.15134v1](http://arxiv.org/abs/2405.15134v1)|null|
|**2024-05-24**|**OptLLM: Optimal Assignment of Queries to Large Language Models**|Yueyue Liu et.al.|[2405.15130v1](http://arxiv.org/abs/2405.15130v1)|null|
|**2024-05-24**|**Benchmarking Hierarchical Image Pyramid Transformer for the classification of colon biopsies and polyps in histopathology images**|Nohemi Sofia Leon Contreras et.al.|[2405.15127v1](http://arxiv.org/abs/2405.15127v1)|null|
|**2024-05-24**|**Scaling Law for Time Series Forecasting**|Jingzhe Shi et.al.|[2405.15124v1](http://arxiv.org/abs/2405.15124v1)|[link](https://github.com/jingzheshi/scalinglawfortimeseriesforecasting)|
|**2024-05-24**|**Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models**|Nicholas J Dobbins et.al.|[2405.15122v1](http://arxiv.org/abs/2405.15122v1)|null|
|**2024-05-24**|**Quantifying the Gain in Weak-to-Strong Generalization**|Moses Charikar et.al.|[2405.15116v1](http://arxiv.org/abs/2405.15116v1)|null|
|**2024-05-24**|**CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems**|Abbas Ghaddar et.al.|[2405.15110v1](http://arxiv.org/abs/2405.15110v1)|null|
|**2024-05-23**|**Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding**|Suyoung Kim et.al.|[2405.15097v1](http://arxiv.org/abs/2405.15097v1)|null|
|**2024-05-23**|**Dissociation of Faithful and Unfaithful Reasoning in LLMs**|Evelyn Yee et.al.|[2405.15092v1](http://arxiv.org/abs/2405.15092v1)|[link](https://github.com/coterrorrecovery/coterrorrecovery)|

#### Abstracts
##### **Canonical Variates in Wasserstein Metric Space**
2405.15768v1 by Jia Li, Lin Lin

In this paper, we address the classification of instances each characterized
not by a singular point, but by a distribution on a vector space. We employ the
Wasserstein metric to measure distances between distributions, which are then
used by distance-based classification algorithms such as k-nearest neighbors,
k-means, and pseudo-mixture modeling. Central to our investigation is dimension
reduction within the Wasserstein metric space to enhance classification
accuracy. We introduce a novel approach grounded in the principle of maximizing
Fisher's ratio, defined as the quotient of between-class variation to
within-class variation. The directions in which this ratio is maximized are
termed discriminant coordinates or canonical variates axes. In practice, we
define both between-class and within-class variations as the average squared
distances between pairs of instances, with the pairs either belonging to the
same class or to different classes. This ratio optimization is achieved through
an iterative algorithm, which alternates between optimal transport and
maximization steps within the vector space. We conduct empirical studies to
assess the algorithm's convergence and, through experimental validation,
demonstrate that our dimension reduction technique substantially enhances
classification performance. Moreover, our method outperforms well-established
algorithms that operate on vector representations derived from distributional
data. It also exhibits robustness against variations in the distributional
representations of data clouds.

摘要：<paragraph>在本文中，我们讨论了每個實例的分類，每個實例的特徵並非單一點，而是在向量空間中的分佈。我們採用 Wasserstein 度量來測量分佈之間的距離，然後由基於距離的分類演算法（例如 k-最近鄰居、k-means 和偽混合模型）使用這些距離。我們調查的重點是 Wasserstein 度量空間中的降維，以提高分類準確度。我們引入了一種新的方法，其基礎是最大化 Fisher 比率的原理，定義為類間變異與類內變異的商。此比率最大化的方向稱為判別坐標或典型變異軸。在實際中，我們將類間變異和類內變異定義為實例對之間的平均平方距離，其中這些對屬於同一個類別或不同的類別。此比率最佳化是透過一個反覆演算法來實現的，此演算法在向量空間中交替進行最佳傳輸和最大化步驟。我們進行實證研究來評估演算法的收斂性，並透過實驗驗證，證明我們的降維技術大幅提升了分類效能。此外，我們的演算法優於運作在從分佈式資料衍生的向量表示上的既有演算法。它也對資料雲的分佈式表示中的變異表現出穩健性。</paragraph>

##### **Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**
2405.15766v1 by Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal

The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,
enhancing patient safety by identifying potential risks associated with
medications, facilitating early detection of adverse events, and guiding
regulatory decision-making. Traditional ADE detection methods are reliable but
slow, not easily adaptable to large-scale operations, and offer limited
information. With the exponential increase in data sources like social media
content, biomedical literature, and Electronic Medical Records (EMR),
extracting relevant ADE-related information from these unstructured texts is
imperative. Previous ADE mining studies have focused on text-based
methodologies, overlooking visual cues, limiting contextual comprehension, and
hindering accurate interpretation. To address this gap, we present a MultiModal
Adverse Drug Event (MMADE) detection dataset, merging ADE-related textual
information with visual aids. Additionally, we introduce a framework that
leverages the capabilities of LLMs and VLMs for ADE detection by generating
detailed descriptions of medical images depicting ADEs, aiding healthcare
professionals in visually identifying adverse events. Using our MMADE dataset,
we showcase the significance of integrating visual cues from images to enhance
overall performance. This approach holds promise for patient safety, ADE
awareness, and healthcare accessibility, paving the way for further exploration
in personalized healthcare.

摘要：藥物警戒中，不適當藥物事件 (ADE) 的挖掘至關重要，
透過識別與藥物相關的潛在風險、促進早期發現不良事件，並指導法規決策，來提升病患安全。傳統的 ADE 偵測方法可靠但緩慢，不易適應大規模作業，且提供有限的資訊。隨著社群媒體內容、生物醫學文獻和電子病歷 (EMR) 等資料來源呈指數級增加，從這些非結構化文字中萃取相關的 ADE 相關資訊勢在必行。先前的 ADE 挖掘研究著重於基於文字的方法，忽略了視覺線索，限制了脈絡理解，並阻礙了準確的詮釋。為了解決這個差距，我們提出了多模態不適當藥物事件 (MMADE) 偵測資料集，將 ADE 相關文字資訊與視覺輔助工具合併。此外，我們還導入了一個框架，該框架利用 LLM 和 VLM 的功能進行 ADE 偵測，透過產生描繪 ADE 的醫學影像的詳細說明，協助醫療專業人員視覺化識別不良事件。使用我們的 MMADE 資料集，我們展示了從影像中整合視覺線索以提升整體效能的重要性。這種方法有望提升病患安全、ADE 意識和醫療保健的可近性，為個人化醫療保健的進一步探索鋪路。

##### **Scaling Laws for Discriminative Classification in Large Language Models**
2405.15765v1 by Dean Wyatte, Fatemeh Tahmasbi, Ming Li, Thomas Markovich

Modern large language models (LLMs) represent a paradigm shift in what can
plausibly be expected of machine learning models. The fact that LLMs can
effectively generate sensible answers to a diverse range of queries suggests
that they would be useful in customer support applications. While powerful,
LLMs have been observed to be prone to hallucination which unfortunately makes
their near term use in customer support applications challenging. To address
this issue we present a system that allows us to use an LLM to augment our
customer support advocates by re-framing the language modeling task as a
discriminative classification task. In this framing, we seek to present the
top-K best template responses for a customer support advocate to use when
responding to a customer. We present the result of both offline and online
experiments where we observed offline gains and statistically significant
online lifts for our experimental system. Along the way, we present observed
scaling curves for validation loss and top-K accuracy, resulted from model
parameter ablation studies. We close by discussing the space of trade-offs with
respect to model size, latency, and accuracy as well as and suggesting future
applications to explore.

摘要：現代大型語言模型 (LLM) 代表了機器學習模型合理預期中的一個典範轉移。LLM 能夠有效地對各種查詢產生合理的答案，這表明它們在客戶支援應用程式中會很有用。雖然功能強大，但已觀察到 LLM 容易產生幻覺，這很不幸地讓它們在客戶支援應用程式中的近期使用面臨挑戰。為了解決這個問題，我們提出一個系統，允許我們使用 LLM 來擴充我們的客戶支援倡導者，方法是將語言建模任務重新定義為一個判別分類任務。在此框架中，我們尋求呈現給客戶支援倡導者前 K 個最佳範本回應，以便在回應客戶時使用。我們呈現離線和線上實驗的結果，在這些實驗中，我們觀察到離線收益和我們實驗系統的統計顯著線上提升。在此過程中，我們呈現了驗證損失和前 K 個準確度的觀察縮放曲線，這些曲線來自模型參數消融研究。最後，我們討論了模型大小、延遲和準確度方面的取捨空間，並建議探索未來的應用程式。

##### **GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction**
2405.15760v1 by Virginia K. Felkner, Jennifer A. Thompson, Jonathan May

Social biases in LLMs are usually measured via bias benchmark datasets.
Current benchmarks have limitations in scope, grounding, quality, and human
effort required. Previous work has shown success with a community-sourced,
rather than crowd-sourced, approach to benchmark development. However, this
work still required considerable effort from annotators with relevant lived
experience. This paper explores whether an LLM (specifically, GPT-3.5-Turbo)
can assist with the task of developing a bias benchmark dataset from responses
to an open-ended community survey. We also extend the previous work to a new
community and set of biases: the Jewish community and antisemitism. Our
analysis shows that GPT-3.5-Turbo has poor performance on this annotation task
and produces unacceptable quality issues in its output. Thus, we conclude that
GPT-3.5-Turbo is not an appropriate substitute for human annotation in
sensitive tasks related to social biases, and that its use actually negates
many of the benefits of community-sourcing bias benchmarks.

摘要：語言模型中的社會偏見通常是透過偏見基準資料集來衡量的。
目前的基準在範圍、基礎、品質和所需的人力上都有限制。先前的研究顯示，以社群為來源，而非群眾外包的方式來進行基準開發是成功的。然而，這項工作仍需要具有相關生活經驗的註解者付出相當大的努力。本文探討 LLM（特別是 GPT-3.5-Turbo）是否能協助執行從開放式社群調查回應中開發偏見基準資料集的任務。我們也將先前的研究延伸至新的社群和偏見：猶太社群和反猶太主義。我們的分析顯示，GPT-3.5-Turbo 在這項註解任務上的表現不佳，且其產出的品質問題無法接受。因此，我們得出結論：GPT-3.5-Turbo 無法適當地取代人類在與社會偏見相關的敏感任務中進行註解，且其使用實際上抵消了社群外包偏見基準的許多好處。

##### **InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation**
2405.15758v1 by Yuchi Wang, Junliang Guo, Jianhong Bai, Runyi Yu, Tianyu He, Xu Tan, Xu Sun, Jiang Bian

Recent talking avatar generation models have made strides in achieving
realistic and accurate lip synchronization with the audio, but often fall short
in controlling and conveying detailed expressions and emotions of the avatar,
making the generated video less vivid and controllable. In this paper, we
propose a novel text-guided approach for generating emotionally expressive 2D
avatars, offering fine-grained control, improved interactivity, and
generalizability to the resulting video. Our framework, named InstructAvatar,
leverages a natural language interface to control the emotion as well as the
facial motion of avatars. Technically, we design an automatic annotation
pipeline to construct an instruction-video paired training dataset, equipped
with a novel two-branch diffusion-based generator to predict avatars with audio
and text instructions at the same time. Experimental results demonstrate that
InstructAvatar produces results that align well with both conditions, and
outperforms existing methods in fine-grained emotion control, lip-sync quality,
and naturalness. Our project page is
https://wangyuchi369.github.io/InstructAvatar/.

摘要：最近的對話頭像生成模型在實現音訊的逼真且準確的唇部同步方面取得了進展，但通常在控制和傳達頭像的詳細表情和情緒方面做得不夠，這使得生成的影片較不生動且可控。在本文中，我們提出了一種新穎的文字引導方法來生成情緒表達的 2D 頭像，提供細緻的控制、改善的互動性，以及對結果影片的概括性。我們的架構名為 InstructAvatar，利用自然語言介面來控制情緒以及頭像的面部動作。在技術上，我們設計了一個自動註解管道來建構一個指令影片配對的訓練資料集，並配備一個新穎的雙分支擴散式生成器，以同時使用音訊和文字指令來預測頭像。實驗結果證明 InstructAvatar 產生的結果與這兩個條件都非常吻合，並且在細緻的情緒控制、唇部同步品質和自然度方面優於現有方法。我們的專案頁面是 https://wangyuchi369.github.io/InstructAvatar/。

##### **Sparse Expansion and Neuronal Disentanglement**
2405.15756v1 by Shashata Sawmya, Linghao Kong, Ilia Markov, Dan Alistarh, Nir Shavit

We show how to improve the inference efficiency of an LLM by expanding it
into a mixture of sparse experts, where each expert is a copy of the original
weights, one-shot pruned for a specific cluster of input values. We call this
approach $\textit{Sparse Expansion}$. We show that, for models such as Llama 2
70B, as we increase the number of sparse experts, Sparse Expansion outperforms
all other one-shot sparsification approaches for the same inference FLOP budget
per token, and that this gap grows as sparsity increases, leading to inference
speedups.
  But why? To answer this, we provide strong evidence that the mixture of
sparse experts is effectively $\textit{disentangling}$ the input-output
relationship of every individual neuron across clusters of inputs.
Specifically, sparse experts approximate the dense neuron output distribution
with fewer weights by decomposing the distribution into a collection of simpler
ones, each with a separate sparse dot product covering it. Interestingly, we
show that the Wasserstein distance between a neuron's output distribution and a
Gaussian distribution is an indicator of its entanglement level and
contribution to the accuracy of the model. Every layer of an LLM has a fraction
of highly entangled Wasserstein neurons, and model performance suffers more
when these are sparsified as opposed to others.

摘要：我們展示如何透過將 LLM 擴充為稀疏專家組合來提升推論效率，其中每個專家都是原始權重的副本，針對特定輸入值群集進行一次性剪枝。我們稱這種方法為「稀疏擴充」。我們展示，對於 Llama 2 70B 等模型，隨著我們增加稀疏專家的數量，稀疏擴充在相同的每令牌推論 FLOP 預算上優於所有其他一次性稀疏化方法，並且隨著稀疏性的增加，此差距會擴大，導致推論加速。
但為什麼？為了回答這個問題，我們提供了強有力的證據，證明稀疏專家組合有效地「解開」了每個個別神經元在輸入群集中的輸入輸出關係。具體來說，稀疏專家透過將分佈分解為一系列較簡單的分佈（每個分佈都有單獨的稀疏點積覆蓋它）來近似密集神經元輸出分佈，並使用較少的權重。有趣的是，我們展示了一個神經元輸出分佈與高斯分佈之間的 Wasserstein 距離是其糾纏程度和對模型準確性貢獻的指標。LLM 的每一層都有一部分高度糾纏的 Wasserstein 神經元，並且當這些神經元被稀疏化（相對於其他神經元）時，模型效能會受到更大的影響。

##### **Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence**
2405.15750v1 by Abhinav Patil, Jaap Jumelet, Yu Ying Chiu, Andy Lapastora, Peter Shen, Lexie Wang, Clevis Willrich, Shane Steinert-Threlkeld

This paper introduces Filtered Corpus Training, a method that trains language
models (LMs) on corpora with certain linguistic constructions filtered out from
the training data, and uses it to measure the ability of LMs to perform
linguistic generalization on the basis of indirect evidence. We apply the
method to both LSTM and Transformer LMs (of roughly comparable size),
developing filtered corpora that target a wide range of linguistic phenomena.
Our results show that while transformers are better qua LMs (as measured by
perplexity), both models perform equally and surprisingly well on linguistic
generalization measures, suggesting that they are capable of generalizing from
indirect evidence.

摘要：本文介紹了過濾語料訓練，這是一種在語料庫中過濾掉特定語言結構的訓練語言模型 (LM) 的方法，並用於衡量 LM 在間接證據基礎上執行語言概括的能力。我們將該方法應用於 LSTM 和 Transformer LM（大小大致相當），開發了針對各種語言現象的過濾語料庫。我們的結果表明，雖然 Transformer 在 LM 方面表現得更好（根據困惑度衡量），但這兩種模型在語言概括測量上表現得同樣好且令人驚訝，這表明它們能夠從間接證據中進行概括。

##### **Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias**
2405.15739v1 by Andres Algaba, Carmen Mazijn, Vincent Holst, Floriano Tori, Sylvia Wenmackers, Vincent Ginis

Citation practices are crucial in shaping the structure of scientific
knowledge, yet they are often influenced by contemporary norms and biases. The
emergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic
to these practices. Interestingly, the characteristics and potential biases of
references recommended by LLMs that entirely rely on their parametric
knowledge, and not on search or retrieval-augmented generation, remain
unexplored. Here, we analyze these characteristics in an experiment using a
dataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after
GPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our
experiment, GPT-4 was tasked with suggesting scholarly references for the
anonymized in-text citations within these papers. Our findings reveal a
remarkable similarity between human and LLM citation patterns, but with a more
pronounced high citation bias in GPT-4, which persists even after controlling
for publication year, title length, number of authors, and venue. Additionally,
we observe a large consistency between the characteristics of GPT-4's existing
and non-existent generated references, indicating the model's internalization
of citation patterns. By analyzing citation graphs, we show that the references
recommended by GPT-4 are embedded in the relevant citation context, suggesting
an even deeper conceptual internalization of the citation networks. While LLMs
can aid in citation generation, they may also amplify existing biases and
introduce new ones, potentially skewing scientific knowledge dissemination. Our
results underscore the need for identifying the model's biases and for
developing balanced methods to interact with LLMs in general.

摘要：<paragraph>引文實務對於形塑科學知識的結構至關重要，但常常受到當代規範和偏見的影響。大型語言模型 (LLM) 如 GPT-4 的出現為這些實務帶來了新的動態。有趣的是，完全依賴參數化知識而非搜尋或檢索增強生成，由 LLM 推薦的參考文獻的特性和潛在偏見仍然未經探究。在此，我們使用一個包含來自 AAAI、NeurIPS、ICML 和 ICLR 的 166 篇論文的資料集，在 GPT-4 的知識截止日期後發布，總計包含 3,066 篇參考文獻，對這些特性進行分析。在我們的實驗中，GPT-4 的任務是為這些論文中的匿名內文引文建議學術參考文獻。我們的研究結果顯示，人類和 LLM 的引文模式有顯著的相似性，但 GPT-4 的高引文偏見更為顯著，即使在控制了出版年份、標題長度、作者數量和場地後，這種情況仍然存在。此外，我們觀察到 GPT-4 現有和不存在的生成參考文獻的特性之間有很大的相容性，這表明模型內化了引文模式。透過分析引文圖，我們顯示 GPT-4 推薦的參考文獻嵌入在相關的引文脈絡中，這表明對引文網路有更深入的概念內化。雖然 LLM 可以協助生成引文，但它們也可能放大現有的偏見並引入新的偏見，潛在地扭曲科學知識的傳播。我們的結果強調了識別模型偏見和發展平衡的方法以與 LLM 進行互動的需求。</paragraph>

##### **Understanding the differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks**
2405.15731v1 by Jerome Sieber, Carmen Amo Alonso, Alexandre Didier, Melanie N. Zeilinger, Antonio Orvieto

Softmax attention is the principle backbone of foundation models for various
artificial intelligence applications, yet its quadratic complexity in sequence
length can limit its inference throughput in long-context settings. To address
this challenge, alternative architectures such as linear attention, State Space
Models (SSMs), and Recurrent Neural Networks (RNNs) have been considered as
more efficient alternatives. While connections between these approaches exist,
such models are commonly developed in isolation and there is a lack of
theoretical understanding of the shared principles underpinning these
architectures and their subtle differences, greatly influencing performance and
scalability. In this paper, we introduce the Dynamical Systems Framework (DSF),
which allows a principled investigation of all these architectures in a common
representation. Our framework facilitates rigorous comparisons, providing new
insights on the distinctive characteristics of each model class. For instance,
we compare linear attention and selective SSMs, detailing their differences and
conditions under which both are equivalent. We also provide principled
comparisons between softmax attention and other model classes, discussing the
theoretical conditions under which softmax attention can be approximated.
Additionally, we substantiate these new insights with empirical validations and
mathematical arguments. This shows the DSF's potential to guide the systematic
development of future more efficient and scalable foundation models.

摘要：Softmax 注意力是各種人工智能應用中基礎模型的主要骨幹，但其在序列長度中的二次複雜度可能會限制其在長情境設定中的推論吞吐量。為了應對這一挑戰，線性注意力、狀態空間模型 (SSM) 和遞迴神經網路 (RNN) 等替代架構被視為更有效的替代方案。儘管這些方法之間存在聯繫，但這些模型通常是孤立開發的，並且缺乏對支撐這些架構及其細微差異的共同原理的理論理解，這極大地影響了效能和可擴充性。在本文中，我們引入了動態系統框架 (DSF)，它允許在一個共同表示中對所有這些架構進行原則性研究。我們的框架促進了嚴謹的比較，提供了對每個模型類別的獨特特徵的新見解。例如，我們比較了線性注意力和選擇性 SSM，詳細說明了它們的差異以及在哪些條件下兩者是等效的。我們還對 softmax 注意力和其他模型類別進行了原則性比較，討論了可以在哪些理論條件下近似 softmax 注意力。此外，我們用經驗驗證和數學論證來證實這些新見解。這顯示了 DSF 指導未來更有效率且可擴充的基礎模型的系統化開發的潛力。

##### **Optimizing Large Language Models for OpenAPI Code Completion**
2405.15729v1 by Bohdan Petryshyn, Mantas Lukoševičius

Recent advancements in Large Language Models (LLMs) and their utilization in
code generation tasks have significantly reshaped the field of software
development. Despite the remarkable efficacy of code completion solutions in
mainstream programming languages, their performance lags when applied to less
ubiquitous formats such as OpenAPI definitions. This study evaluates the
OpenAPI completion performance of GitHub Copilot, a prevalent commercial code
completion tool, and proposes a set of task-specific optimizations leveraging
Meta's open-source model Code Llama. A semantics-aware OpenAPI completion
benchmark proposed in this research is used to perform a series of experiments
through which the impact of various prompt-engineering and fine-tuning
techniques on the Code Llama model's performance is analyzed. The fine-tuned
Code Llama model reaches a peak correctness improvement of 55.2% over GitHub
Copilot despite utilizing 25 times fewer parameters than the commercial
solution's underlying Codex model. Additionally, this research proposes an
enhancement to a widely used code infilling training technique, addressing the
issue of underperformance when the model is prompted with context sizes smaller
than those used during training.

摘要：大型語言模型 (LLM) 的最新進展及其在程式碼產生任務中的應用已大幅改變軟體開發領域。儘管主流程式語言中的程式碼完成解決方案具有顯著的效能，但當應用於較不普遍的格式，例如 OpenAPI 定義時，其效能就會落後。本研究評估了 GitHub Copilot（一種流行的商用程式碼完成工具）的 OpenAPI 完成效能，並提出了一組利用 Meta 開源模型 Code Llama 的特定任務最佳化。本研究中提出的語義感知 OpenAPI 完成基準用於執行一系列實驗，透過這些實驗分析各種提示工程和微調技術對 Code Llama 模型效能的影響。微調後的 Code Llama 模型的正確性提升幅度達到 55.2%，優於 GitHub Copilot，儘管其使用的參數比商用解決方案的基礎 Codex 模型少了 25 倍。此外，本研究提出了一種對廣泛使用的程式碼填補訓練技術的強化，解決了當模型提示的內容大小小於訓練期間使用的內容大小時效能不佳的問題。

##### **EmpathicStories++: A Multimodal Dataset for Empathy towards Personal Experiences**
2405.15708v1 by Jocelyn Shen, Yubin Kim, Mohit Hulse, Wazeer Zulfikar, Sharifa Alghowinem, Cynthia Breazeal, Hae Won Park

Modeling empathy is a complex endeavor that is rooted in interpersonal and
experiential dimensions of human interaction, and remains an open problem
within AI. Existing empathy datasets fall short in capturing the richness of
empathy responses, often being confined to in-lab or acted scenarios, lacking
longitudinal data, and missing self-reported labels. We introduce a new
multimodal dataset for empathy during personal experience sharing: the
EmpathicStories++ dataset
(https://mitmedialab.github.io/empathic-stories-multimodal/) containing 53
hours of video, audio, and text data of 41 participants sharing vulnerable
experiences and reading empathically resonant stories with an AI agent.
EmpathicStories++ is the first longitudinal dataset on empathy, collected over
a month-long deployment of social robots in participants' homes, as
participants engage in natural, empathic storytelling interactions with AI
agents. We then introduce a novel task of predicting individuals' empathy
toward others' stories based on their personal experiences, evaluated in two
contexts: participants' own personal shared story context and their reflections
on stories they read. We benchmark this task using state-of-the-art models to
pave the way for future improvements in contextualized and longitudinal empathy
modeling. Our work provides a valuable resource for further research in
developing empathetic AI systems and understanding the intricacies of human
empathy within genuine, real-world settings.

摘要：同理心建模是一項複雜的工作，植根於人際互動和人類互動的體驗面向，並且仍然是 AI 中的開放性問題。現有的同理心數據集無法捕捉到同理心反應的豐富性，通常僅限於實驗室或表演場景，缺乏縱向數據，並且缺少自我報告的標籤。我們引入了一個新的多模態數據集，用於在個人經驗分享期間培養同理心：EmpathicStories++ 數據集（https://mitmedialab.github.io/empathic-stories-multimodal/），其中包含 41 位參與者分享脆弱經歷和與 AI 代理閱讀共鳴故事的 53 小時的視頻、音頻和文本數據。EmpathicStories++ 是第一個關於同理心的縱向數據集，在參與者的家中部署社交機器人一個月後收集，因為參與者與 AI 代理進行自然的、富有同理心的講故事互動。然後，我們引入了一項新任務，即根據個人的經歷預測個人對他人故事的同理心，在兩個背景下進行評估：參與者自己的個人分享故事背景和他們對所閱讀故事的反思。我們使用最先進的模型對此任務進行基準測試，為未來的語境化和縱向同理心建模的改進鋪平道路。我們的研究為進一步研究開發同理心 AI 系統和了解真實現實環境中人類同理心的複雜性提供了寶貴的資源。

##### **Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models**
2405.15684v1 by Yue Zhang, Hehe Fan, Yi Yang

To bridge the gap between vision and language modalities, Multimodal Large
Language Models (MLLMs) usually learn an adapter that converts visual inputs to
understandable tokens for Large Language Models (LLMs). However, most adapters
generate consistent visual tokens, regardless of the specific objects of
interest mentioned in the prompt. Since these adapters distribute equal
attention to every detail in the image and focus on the entire scene, they may
increase the cognitive load for LLMs, particularly when processing complex
scenes. To alleviate this problem, we propose prompt-aware adapters. These
adapters are designed with the capability to dynamically embed visual inputs
based on the specific focus of the prompt. Specifically, prompt-aware adapters
utilize both global and local textual features to capture the most relevant
visual clues from the prompt at both coarse and fine granularity levels. This
approach significantly enhances the ability of LLMs to understand and interpret
visual content. Experiments on various visual question answering tasks, such as
counting and position reasoning, demonstrate the effectiveness of prompt-aware
adapters.

摘要：為了彌合視覺與語言模態之間的差距，多模態大型語言模型 (MLLM) 通常會學習一個轉接器，將視覺輸入轉換為大型語言模型 (LLM) 可以理解的代碼。然而，大多數轉接器會產生一致的視覺代碼，而不管提示中提到的特定感興趣對象為何。由於這些轉接器將相同的注意力分配給影像中的每個細節，並專注於整個場景，因此可能會增加 LLM 的認知負載，特別是在處理複雜場景時。為了減輕這個問題，我們提出了提示感知轉接器。這些轉接器被設計為具備根據提示的特定焦點動態嵌入視覺輸入的能力。具體來說，提示感知轉接器同時利用全局和局部文字特徵，以在粗略和精細粒度層級從提示中擷取最相關的視覺線索。這種方法顯著增強了 LLM 理解和詮釋視覺內容的能力。在各種視覺問題回答任務（例如計數和位置推理）上的實驗證明了提示感知轉接器的有效性。

##### **VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging the Visual Perception Gap**
2405.15683v1 by Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha

Recent interest in Large Vision-Language Models (LVLMs) for practical
applications is moderated by the significant challenge of hallucination or the
inconsistency between the factual information and the generated text. In this
paper, we first perform an in-depth analysis of hallucinations and discover
several novel insights about how and when LVLMs hallucinate. From our analysis,
we show that: (1) The community's efforts have been primarily targeted towards
reducing hallucinations related to visual recognition (VR) prompts (e.g.,
prompts that only require describing the image), thereby ignoring
hallucinations for cognitive prompts (e.g., prompts that require additional
skills like reasoning on contents of the image). (2) LVLMs lack visual
perception, i.e., they can see but not necessarily understand or perceive the
input image. We analyze responses to cognitive prompts and show that LVLMs
hallucinate due to a perception gap: although LVLMs accurately recognize visual
elements in the input image and possess sufficient cognitive skills, they
struggle to respond accurately and hallucinate. To overcome this shortcoming,
we propose Visual Description Grounded Decoding (VDGD), a simple, robust, and
training-free method for alleviating hallucinations. Specifically, we first
describe the image and add it as a prefix to the instruction. Next, during
auto-regressive decoding, we sample from the plausible candidates according to
their KL-Divergence (KLD) to the description, where lower KLD is given higher
preference. Experimental results on several benchmarks and LVLMs show that VDGD
improves significantly over other baselines in reducing hallucinations. We also
propose VaLLu, a benchmark for the comprehensive evaluation of the cognitive
capabilities of LVLMs.

摘要：<paragraph>最近對大型視覺語言模型 (LVLMs) 在實際應用中的興趣受到幻覺或事實資訊與生成文字之間不一致的重大挑戰所影響。在本文中，我們首先對幻覺進行深入分析，並發現有關 LVLMs 如何以及何時產生幻覺的幾個新見解。從我們的分析中，我們表明：(1) 社群的努力主要針對減少與視覺辨識 (VR) 提示相關的幻覺 (例如，僅需要描述影像的提示)，從而忽略認知提示的幻覺 (例如，需要額外技能的提示，例如對影像內容進行推理)。(2) LVLMs 缺乏視覺感知，也就是說，它們可以看到，但不一定能理解或感知輸入影像。我們分析對認知提示的回應，並表明 LVLMs 由於感知差距而產生幻覺：儘管 LVLMs 能準確辨識輸入影像中的視覺元素，並具備足夠的認知技能，但它們難以準確回應並產生幻覺。為了克服這個缺點，我們提出視覺描述接地解碼 (VDGD)，這是一種簡單、強健且無需訓練的方法，可以減輕幻覺。具體來說，我們首先描述影像，並將其作為指令的前綴新增。接下來，在自迴歸解碼過程中，我們根據它們與描述的 KL-散度 (KLD) 從合理的候選項中進行抽樣，其中較低的 KLD 會獲得較高的優先權。在幾個基準和 LVLMs 上的實驗結果表明，VDGD 在減少幻覺方面顯著優於其他基準。我們還提出了 VaLLu，這是一個用於全面評估 LVLMs 認知能力的基準。</paragraph>

##### **Consistency of Neural Causal Partial Identification**
2405.15673v1 by Jiyuan Tan, Jose Blanchet, Vasilis Syrgkanis

Recent progress in Neural Causal Models (NCMs) showcased how identification
and partial identification of causal effects can be automatically carried out
via training of neural generative models that respect the constraints encoded
in a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,
formal consistency of these methods has only been proven for the case of
discrete variables or only for linear causal models. In this work, we prove
consistency of partial identification via NCMs in a general setting with both
continuous and categorical variables. Further, our results highlight the impact
of the design of the underlying neural network architecture in terms of depth
and connectivity as well as the importance of applying Lipschitz regularization
in the training phase. In particular, we provide a counterexample showing that
without Lipschitz regularization the NCM may not be asymptotically consistent.
Our results are enabled by new results on the approximability of structural
causal models via neural generative models, together with an analysis of the
sample complexity of the resulting architectures and how that translates into
an error in the constrained optimization problem that defines the partial
identification bounds.

摘要：神經因果模型 (NCM) 的最新進展展示了如何透過訓練符合給定因果圖中編碼約束的神經生成模型，自動執行因果效應的識別和部分識別 [Xia 等人 2022 年，Balazadeh 等人 2022 年]。然而，這些方法的形式一致性僅證明了離散變數或僅線性因果模型的情況。在這項工作中，我們證明了在具有連續和分類變數的通用設定中，透過 NCM 進行部分識別的一致性。此外，我們的結果突出了基礎神經網路架構的設計在深度和連接性方面的影響，以及在訓練階段應用 Lipschitz 正則化的重要性。特別是，我們提供了一個反例，表明在沒有 Lipschitz 正則化的情況下，NCM 可能不會漸近一致。我們的成果得益於透過神經生成模型對結構因果模型近似性的新成果，以及對所得架構的樣本複雜性的分析，以及這如何轉化為定義部分識別邊界的約束最佳化問題中的誤差。

##### **Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF) Tables**
2405.15661v1 by James Hinns, David Martens

The rise of deep learning in image classification has brought unprecedented
accuracy but also highlighted a key issue: the use of 'shortcuts' by models.
Such shortcuts are easy-to-learn patterns from the training data that fail to
generalise to new data. Examples include the use of a copyright watermark to
recognise horses, snowy background to recognise huskies, or ink markings to
detect malignant skin lesions. The explainable AI (XAI) community has suggested
using instance-level explanations to detect shortcuts without external data,
but this requires the examination of many explanations to confirm the presence
of such shortcuts, making it a labour-intensive process. To address these
challenges, we introduce Counterfactual Frequency (CoF) tables, a novel
approach that aggregates instance-based explanations into global insights, and
exposes shortcuts. The aggregation implies the need for some semantic concepts
to be used in the explanations, which we solve by labelling the segments of an
image. We demonstrate the utility of CoF tables across several datasets,
revealing the shortcuts learned from them.

摘要：深度學習在影像分類中的崛起帶來了前所未有的準確性，但也突顯了一個關鍵問題：模型使用「捷徑」。此類捷徑是從訓練資料中學習到的易於學習的模式，無法概括到新資料。範例包括使用版權浮水印來辨識馬匹、使用雪地背景來辨識哈士奇，或使用墨水標記來偵測惡性皮膚病灶。可解釋人工智慧 (XAI) 社群建議使用個體級別的解釋來偵測捷徑，而無需外部資料，但這需要檢查許多解釋才能確認此類捷徑的存在，使其成為一個勞力密集的程序。為了應對這些挑戰，我們引入了反事實頻率 (CoF) 表格，一種將基於個體的解釋彙總成整體見解並揭露捷徑的新方法。彙總意味著需要在解釋中使用一些語義概念，我們透過標記影像的區段來解決此問題。我們展示了 CoF 表格在多個資料集中的實用性，揭露了從中學習到的捷徑。

##### **HDC: Hierarchical Semantic Decoding with Counting Assistance for Generalized Referring Expression Segmentation**
2405.15658v1 by Zhuoyan Luo, Yinghao Wu, Yong Liu, Yicheng Xiao, Xiao-Ping Zhang, Yujiu Yang

The newly proposed Generalized Referring Expression Segmentation (GRES)
amplifies the formulation of classic RES by involving multiple/non-target
scenarios. Recent approaches focus on optimizing the last modality-fused
feature which is directly utilized for segmentation and object-existence
identification. However, the attempt to integrate all-grained information into
a single joint representation is impractical in GRES due to the increased
complexity of the spatial relationships among instances and deceptive text
descriptions. Furthermore, the subsequent binary target justification across
all referent scenarios fails to specify their inherent differences, leading to
ambiguity in object understanding. To address the weakness, we propose a
$\textbf{H}$ierarchical Semantic $\textbf{D}$ecoding with $\textbf{C}$ounting
Assistance framework (HDC). It hierarchically transfers complementary modality
information across granularities, and then aggregates each well-aligned
semantic correspondence for multi-level decoding. Moreover, with complete
semantic context modeling, we endow HDC with explicit counting capability to
facilitate comprehensive object perception in multiple/single/non-target
settings. Experimental results on gRefCOCO, Ref-ZOM, R-RefCOCO, and RefCOCO
benchmarks demonstrate the effectiveness and rationality of HDC which
outperforms the state-of-the-art GRES methods by a remarkable margin. Code will
be available $\href{https://github.com/RobertLuo1/HDC}{here}$.

摘要：新提出的廣泛指稱表達式分段 (GRES)
透過涉及多重/非目標情境擴展經典 RES 的公式化。最近的方法著重於最佳化最後的模態融合
特徵，該特徵直接用於分段和物件存在識別。然而，由於實例之間空間關係的複雜性增加和具誤導性的文字描述，在 GRES 中將所有粒度資訊整合到單一聯合表示中的嘗試是不切實際的。此外，後續所有指涉情境中的二元目標證成無法指定其內在差異，導致物件理解產生歧義。為了解決這個弱點，我們提出一個
$\textbf{H}$ierarchical Semantic $\textbf{D}$ecoding with $\textbf{C}$ounting
Assistance 框架 (HDC)。它分層地傳輸不同粒度之間的互補模態資訊，然後彙總每個對齊良好的
語意對應以進行多層次解碼。此外，透過完整的語意脈絡建模，我們賦予 HDC 明確的計數能力，以促進在多重/單一/非目標設定中的全面物件感知。在 gRefCOCO、Ref-ZOM、R-RefCOCO 和 RefCOCO 基準上的實驗結果證明了 HDC 的有效性和合理性，它以顯著幅度優於最先進的 GRES 方法。程式碼將在 $\href{https://github.com/RobertLuo1/HDC}{這裡}$ 提供。

##### **GECKO: Generative Language Model for English, Code and Korean**
2405.15640v1 by Sungwoo Oh, Donggyu Kim

We introduce GECKO, a bilingual large language model (LLM) optimized for
Korean and English, along with programming languages. GECKO is pretrained on
the balanced, high-quality corpus of Korean and English employing LLaMA
architecture. In this report, we share the experiences of several efforts to
build a better data pipeline for the corpus and to train our model. GECKO shows
great efficiency in token generations for both Korean and English, despite its
small size of vocabulary. We measure the performance on the representative
benchmarks in terms of Korean, English and Code, and it exhibits great
performance on KMMLU (Korean MMLU) and modest performance in English and Code,
even with its smaller number of trained tokens compared to English-focused
LLMs. GECKO is available to the open-source community under a permissive
license. We hope our work offers a research baseline and practical insights for
Korean LLM research. The model can be found at:
https://huggingface.co/kifai/GECKO-7B

摘要：我們介紹 GECKO，一種雙語大型語言模型 (LLM)，針對韓語、英語以及程式語言進行最佳化。GECKO 使用 LLaMA 架構，在韓語和英語的平衡、高品質語料庫中進行預訓練。在此報告中，我們分享了多項努力的經驗，以建立更好的語料庫資料管道並訓練我們的模型。儘管 GECKO 的詞彙量很小，但在韓語和英語的代幣產生方面展現了極高的效率。我們根據韓語、英語和程式碼的代表性基準來衡量效能，即使與專注於英語的 LLM 相比，訓練代幣數量較少，它在 KMMLU（韓語 MMLU）上展現了極佳的效能，在英語和程式碼方面則表現平平。GECKO 在寬鬆的許可證下提供給開源社群。我們希望我們的成果能為韓語 LLM 研究提供研究基準和實務見解。模型可在以下位置找到：
https://huggingface.co/kifai/GECKO-7B

##### **M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models**
2405.15638v1 by Hongyu Wang, Jiayu Xu, Senwei Xie, Ruiping Wang, Jialin Li, Zhaojie Xie, Bin Zhang, Chuyan Xiong, Xilin Chen

Multilingual multimodal reasoning is a core component in achieving
human-level intelligence. However, most existing benchmarks for multilingual
multimodal reasoning struggle to differentiate between models of varying
performance; even language models without visual capabilities can easily
achieve high scores. This leaves a comprehensive evaluation of leading
multilingual multimodal models largely unexplored. In this work, we introduce
M4U, a novel and challenging benchmark for assessing the capability of
multi-discipline multilingual multimodal understanding and reasoning. M4U
contains 8,931 samples covering 64 disciplines across 16 subfields in Science,
Engineering, and Healthcare in Chinese, English, and German. Using M4U, we
conduct extensive evaluations of 21 leading Large Multimodal Models (LMMs) and
Large Language Models (LLMs) with external tools. The evaluation results show
that the state-of-the-art model, GPT-4o, achieves only 47.6% average accuracy
on M4U. Additionally, we observe that the leading LMMs exhibit significant
language preferences. Our in-depth analysis indicates that leading LMMs,
including GPT-4o, suffer performance degradation when prompted with
cross-lingual multimodal questions, such as images with key textual information
in Chinese while the question is in German. We believe that M4U can serve as a
crucial tool for systematically evaluating LMMs based on their multilingual
multimodal reasoning capabilities and monitoring their development. The
homepage, codes and data are public available.

摘要：<paragraph>多模態的多語言推理是實現人類智慧的核心組成部分。然而，現有的多模態多語言推理基準在區分不同效能的模型上遇到困難；即使沒有視覺能力的語言模型也能輕易獲得高分。這使得對領先的多模態多語言模型的全面評估在很大程度上仍未探索。在這項工作中，我們介紹了 M4U，這是一個用於評估多學科多語言多模態理解和推理能力的新穎且具有挑戰性的基準。M4U 包含 8,931 個範例，涵蓋科學、工程和醫療保健領域的 16 個子領域的 64 個學科，語言包括中文、英文和德文。使用 M4U，我們對 21 個領先的大型多模態模型 (LMM) 和大型語言模型 (LLM) 進行了廣泛評估，並使用了外部工具。評估結果顯示，最先進的模型 GPT-4o 在 M4U 上僅獲得 47.6% 的平均準確度。此外，我們觀察到領先的 LMM 表現出顯著的語言偏好。我們的深入分析表明，包括 GPT-4o 在內的領先 LMM 在提示使用跨語言多模態問題時會出現效能下降，例如圖像中包含中文關鍵文字資訊，而問題是用德文提出的。我們相信 M4U 可以作為一個重要的工具，用於根據 LMM 的多語言多模態推理能力對其進行系統評估，並監控其發展。首頁、程式碼和資料公開可用。</paragraph>

##### **Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment**
2405.15624v1 by Hao Sun, Mihaela van der Schaar

Aligning Large Language Models (LLMs) is crucial for enhancing their safety
and utility. However, existing methods, primarily based on preference datasets,
face challenges such as noisy labels, high annotation costs, and privacy
concerns. In this work, we introduce Alignment from Demonstrations (AfD), a
novel approach leveraging high-quality demonstration data to overcome these
challenges. We formalize AfD within a sequential decision-making framework,
highlighting its unique challenge of missing reward signals. Drawing insights
from forward and inverse reinforcement learning, we introduce divergence
minimization objectives for AfD. Analytically, we elucidate the mass-covering
and mode-seeking behaviors of various approaches, explaining when and why
certain methods are superior. Practically, we propose a computationally
efficient algorithm that extrapolates over a tailored reward model for AfD. We
validate our key insights through experiments on the Harmless and Helpful
tasks, demonstrating their strong empirical performance while maintaining
simplicity.

摘要：對齊大型語言模型 (LLM) 對於增強其安全性
和實用性至關重要。然而，現有方法（主要基於偏好資料集）
面臨諸如標籤雜訊、標註成本高和隱私等挑戰
疑慮。在這項工作中，我們引入了示範對齊 (AfD)，一種
利用高品質示範資料來克服這些挑戰的新方法。我們在序貫決策制定架構中形式化 AfD，
強調其錯失獎勵訊號的獨特挑戰。從正向和反向強化學習中汲取見解，我們引入了 AfD 的差異最小化目標。在分析上，我們闡明了各種方法的質量覆蓋
和模式尋求行為，解釋了某些方法何時以及為何優越。在實務上，我們提出了一種計算
一種對於 AfD 的量身打造獎勵模型進行外推的有效率演算法。我們
通過在無害和有益任務上的實驗驗證我們的關鍵見解，證明其強大的經驗效能，同時維持
簡潔性。

##### **Neuromorphic dreaming: A pathway to efficient learning in artificial agents**
2405.15616v1 by Ingo Blakowski, Dmitrii Zendrikov, Cristiano Capone, Giacomo Indiveri

Achieving energy efficiency in learning is a key challenge for artificial
intelligence (AI) computing platforms. Biological systems demonstrate
remarkable abilities to learn complex skills quickly and efficiently. Inspired
by this, we present a hardware implementation of model-based reinforcement
learning (MBRL) using spiking neural networks (SNNs) on mixed-signal
analog/digital neuromorphic hardware. This approach leverages the energy
efficiency of mixed-signal neuromorphic chips while achieving high sample
efficiency through an alternation of online learning, referred to as the
"awake" phase, and offline learning, known as the "dreaming" phase. The model
proposed includes two symbiotic networks: an agent network that learns by
combining real and simulated experiences, and a learned world model network
that generates the simulated experiences. We validate the model by training the
hardware implementation to play the Atari game Pong. We start from a baseline
consisting of an agent network learning without a world model and dreaming,
which successfully learns to play the game. By incorporating dreaming, the
number of required real game experiences are reduced significantly compared to
the baseline. The networks are implemented using a mixed-signal neuromorphic
processor, with the readout layers trained using a computer in-the-loop, while
the other layers remain fixed. These results pave the way toward
energy-efficient neuromorphic learning systems capable of rapid learning in
real world applications and use-cases.

摘要：在學習中實現能源效率是人工智慧 (AI) 計算平台的一項關鍵挑戰。生物系統展現了快速且有效率學習複雜技能的驚人能力。受到此啟發，我們在混合訊號類比/數位神經型態硬體上，使用脈衝神經網路 (SNN) 提出一個基於模型的強化學習 (MBRL) 硬體實作。此方法利用混合訊號神經型態晶片的能源效率，同時透過稱為「清醒」階段的線上學習與稱為「作夢」階段的離線學習交替進行，來達成高取樣效率。所提出的模型包含兩個共生網路：透過結合真實和模擬經驗來學習的代理網路，以及產生模擬經驗的已學習世界模型網路。我們透過訓練硬體實作來玩 Atari 遊戲 Pong，來驗證模型。我們從一個基線開始，該基線包含一個沒有世界模型和作夢的代理網路學習，它成功學會玩遊戲。透過結合作夢，與基線相比，所需真實遊戲經驗的數量大幅減少。這些網路使用混合訊號神經型態處理器實作，讀取層使用電腦在迴路中訓練，而其他層保持固定。這些結果為能夠在真實世界應用和使用案例中快速學習的節能神經型態學習系統鋪路。

##### **Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study**
2405.15614v1 by Karl Tamberg, Hayretdin Bahsi

Despite various approaches being employed to detect vulnerabilities, the
number of reported vulnerabilities shows an upward trend over the years. This
suggests the problems are not caught before the code is released, which could
be caused by many factors, like lack of awareness, limited efficacy of the
existing vulnerability detection tools or the tools not being user-friendly. To
help combat some issues with traditional vulnerability detection tools, we
propose using large language models (LLMs) to assist in finding vulnerabilities
in source code. LLMs have shown a remarkable ability to understand and generate
code, underlining their potential in code-related tasks. The aim is to test
multiple state-of-the-art LLMs and identify the best prompting strategies,
allowing extraction of the best value from the LLMs. We provide an overview of
the strengths and weaknesses of the LLM-based approach and compare the results
to those of traditional static analysis tools. We find that LLMs can pinpoint
many more issues than traditional static analysis tools, outperforming
traditional tools in terms of recall and F1 scores. The results should benefit
software developers and security analysts responsible for ensuring that the
code is free of vulnerabilities.

摘要：儘管採用各種方法來偵測漏洞，但多年來報告的漏洞數量呈現上升趨勢。這表示在程式碼發佈前並未發現問題，這可能是由許多因素所造成，例如缺乏意識、現有漏洞偵測工具的效能有限或工具對使用者不友善。為協助解決傳統漏洞偵測工具的一些問題，我們建議使用大型語言模型 (LLM) 來協助尋找原始碼中的漏洞。LLM 已展現出理解和產生程式碼的驚人能力，凸顯其在程式碼相關任務中的潛力。目標是測試多種最先進的 LLM，並找出最佳提示策略，從 LLM 中萃取最佳價值。我們提供了 LLM 為基礎方法的優缺點概述，並將結果與傳統靜態分析工具的結果進行比較。我們發現 LLM 可以精確指出比傳統靜態分析工具更多的問題，在召回率和 F1 分數方面優於傳統工具。這些結果應有助於負責確保程式碼沒有漏洞的軟體開發人員和安全分析師。

##### **Text Generation: A Systematic Literature Review of Tasks, Evaluation, and Challenges**
2405.15604v1 by Jonas Becker, Jan Philip Wahle, Bela Gipp, Terry Ruas

Text generation has become more accessible than ever, and the increasing
interest in these systems, especially those using large language models, has
spurred an increasing number of related publications. We provide a systematic
literature review comprising 244 selected papers between 2017 and 2024. This
review categorizes works in text generation into five main tasks: open-ended
text generation, summarization, translation, paraphrasing, and question
answering. For each task, we review their relevant characteristics, sub-tasks,
and specific challenges (e.g., missing datasets for multi-document
summarization, coherence in story generation, and complex reasoning for
question answering). Additionally, we assess current approaches for evaluating
text generation systems and ascertain problems with current metrics. Our
investigation shows nine prominent challenges common to all tasks and sub-tasks
in recent text generation publications: bias, reasoning, hallucinations,
misuse, privacy, interpretability, transparency, datasets, and computing. We
provide a detailed analysis of these challenges, their potential solutions, and
which gaps still require further engagement from the community. This systematic
literature review targets two main audiences: early career researchers in
natural language processing looking for an overview of the field and promising
research directions, as well as experienced researchers seeking a detailed view
of tasks, evaluation methodologies, open challenges, and recent mitigation
strategies.

摘要：文本生成比以往任何時候都更容易，對這些系統的興趣日益增加，特別是那些使用大型語言模型的系統，激發了越來越多的相關出版物。我們提供了 2017 年至 2024 年間 244 篇精選論文的系統性文獻回顧。此回顧將文本生成中的作品分類為五項主要任務：開放式文本生成、摘要、翻譯、改寫和問題解答。對於每一項任務，我們回顧其相關特徵、子任務和具體挑戰（例如，多文件摘要的資料集缺失、故事生成中的連貫性和問題解答中的複雜推理）。此外，我們評估了評估文本生成系統的當前方法，並確定了當前指標的問題。我們的調查顯示，在最近的文本生成出版物中，所有任務和子任務都存在九項突出的共同挑戰：偏見、推理、幻覺、誤用、隱私、可解釋性、透明度、資料集和計算。我們對這些挑戰、其潛在解決方案以及哪些差距仍需要社群進一步參與進行了詳細分析。這項系統性文獻回顧鎖定兩個主要受眾：正在尋找該領域概況和有前途的研究方向的自然語言處理領域的早期職業研究人員，以及尋求任務、評估方法、公開挑戰和近期緩解策略的詳細觀點的經驗豐富的研究人員。

##### **MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel Data Fusion Network Model Integrating CNN, LSTM, and GRU**
2405.15598v1 by Md Abrar Jahin, Asef Shahriar, Md Al Amin

Accurate demand forecasting is crucial for optimizing supply chain
management. Traditional methods often fail to capture complex patterns from
seasonal variability and special events. Despite advancements in deep learning,
interpretable forecasting models remain a challenge. To address this, we
introduce the Multi-Channel Data Fusion Network (MCDFN), a hybrid architecture
that integrates Convolutional Neural Networks (CNN), Long Short-Term Memory
networks (LSTM), and Gated Recurrent Units (GRU) to enhance predictive
performance by extracting spatial and temporal features from time series data.
Our rigorous benchmarking demonstrates that MCDFN outperforms seven other
deep-learning models, achieving superior metrics: MSE (23.5738%), RMSE
(4.8553%), MAE (3.9991%), and MAPE (20.1575%). Additionally, MCDFN's
predictions were statistically indistinguishable from actual values, confirmed
by a paired t-test with a 5% p-value and a 10-fold cross-validated statistical
paired t-test. We apply explainable AI techniques like ShapTime and Permutation
Feature Importance to enhance interpretability. This research advances demand
forecasting methodologies and offers practical guidelines for integrating MCDFN
into supply chain systems, highlighting future research directions for
scalability and user-friendly deployment.

摘要：準確的需求預測對於優化供應鏈管理至關重要。傳統方法往往無法掌握季節性變化和特殊事件的複雜模式。儘管深度學習有進步，但可解釋的預測模型仍然是一個挑戰。為了解決這個問題，我們引入了多通道數據融合網路 (MCDFN)，這是一種混合架構，整合了卷積神經網路 (CNN)、長短期記憶網路 (LSTM) 和門控循環單元 (GRU) 來增強預測性能，方法是從時間序列數據中提取空間和時間特徵。我們的嚴格基準測試表明，MCDFN 優於其他七種深度學習模型，達到了優異的指標：MSE (23.5738%)、RMSE (4.8553%)、MAE (3.9991%) 和 MAPE (20.1575%)。此外，MCDFN 的預測與實際值在統計上沒有區別，這通過配對 t 檢定（p 值為 5%）和 10 倍交叉驗證的統計配對 t 檢定得到證實。我們應用可解釋的 AI 技術，如 ShapTime 和置換特徵重要性，以增強可解釋性。本研究推動了需求預測方法，並為將 MCDFN 整合到供應鏈系統中提供了實用指南，重點說明了可擴充性和用戶友善部署的未來研究方向。

##### **Profiling checkpointing schedules in adjoint ST-AD**
2405.15590v1 by Laurent Hascoët, Jean-Luc Bouchot, Shreyas Sunil Gaikwad, Sri Hari Krishna Narayanan, Jan Hückelheim

Checkpointing is a cornerstone of data-flow reversal in adjoint algorithmic
differentiation. Checkpointing is a storage/recomputation trade-off that can be
applied at different levels, one of which being the call tree. We are looking
for good placements of checkpoints onto the call tree of a given application,
to reduce run time and memory footprint of its adjoint. There is no known
optimal solution to this problem other than a combinatorial search on all
placements. We propose a heuristics based on run-time profiling of the adjoint
code. We describe implementation of this profiling tool in an existing
source-transformation AD tool. We demonstrate the interest of this approach on
test cases taken from the MITgcm ocean and atmospheric global circulation
model. We discuss the limitations of our approach and propose directions to
lift them.

摘要：檢查點是伴隨演算法微分中資料流反轉的基石。檢查點是一種儲存/重新計算的折衷方案，可以在不同層級套用，其中一項是呼叫樹。我們正在尋找將檢查點放置在給定應用程式的呼叫樹上的良好位置，以減少其伴隨的執行時間和記憶體使用量。除了對所有配置進行組合搜尋之外，沒有已知最佳解決方案可以解決此問題。我們提出一個基於伴隨程式碼執行時間設定檔的啟發法。我們在現有的原始碼轉換 AD 工具中描述這個設定檔工具的實作。我們在從 MITgcm 海洋和全球大氣環流模型取得的測試案例中展示此方法的興趣。我們討論此方法的限制，並提出解除限制的方向。

##### **Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems**
2405.15585v1 by Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu, Mausam

Large language models (LLM) based end-to-end task-oriented dialog (TOD)
systems built using few-shot (in-context) learning perform better than
supervised models only when the train data is limited. This is due to the
inherent ability of LLMs to learn any task with just a few demonstrations. As
the number of train dialogs increases, supervised SoTA models surpass
in-context learning LLMs as they learn to better align with the style of the
system responses in the training data, which LLMs struggle to mimic. In
response, we propose SyncTOD, which synergizes LLMs with useful hints about the
task for improved alignment. At a high level, SyncTOD trains auxiliary models
to provide these hints and select exemplars for the in-context prompts. With
ChatGPT, SyncTOD achieves superior performance compared to LLM-based baselines
and SoTA models in low-data settings, while retaining competitive performance
in full-data settings

摘要：大型語言模型 (LLM) 基於端到端任務導向對話 (TOD) 系統建構，使用少量範例 (情境中) 學習的表現優於監督式模型，僅當訓練資料有限時。這是因為 LLM 固有具備僅使用少數示範就能學習任何任務的能力。隨著訓練對話數量的增加，監督式 SoTA 模型超越情境中學習的 LLM，因為它們學會更符合訓練資料中系統回應的風格，而 LLM 難以模仿。為了解決這個問題，我們提出 SyncTOD，它結合了 LLM 和關於任務的有用提示，以改善對齊。在高層級中，SyncTOD 訓練輔助模型來提供這些提示，並為情境中提示選擇範例。有了 ChatGPT，SyncTOD 在低資料設定中實現了優於基於 LLM 的基準和 SoTA 模型的卓越效能，同時在全資料設定中保持競爭力

##### **Generating density nowcasts for U.S. GDP growth with deep learning: Bayes by Backprop and Monte Carlo dropout**
2405.15579v1 by Kristóf Németh, Dániel Hadházi

Recent results in the literature indicate that artificial neural networks
(ANNs) can outperform the dynamic factor model (DFM) in terms of the accuracy
of GDP nowcasts. Compared to the DFM, the performance advantage of these highly
flexible, nonlinear estimators is particularly evident in periods of recessions
and structural breaks. From the perspective of policy-makers, however, nowcasts
are the most useful when they are conveyed with uncertainty attached to them.
While the DFM and other classical time series approaches analytically derive
the predictive (conditional) distribution for GDP growth, ANNs can only produce
point nowcasts based on their default training procedure (backpropagation). To
fill this gap, first in the literature, we adapt two different deep learning
algorithms that enable ANNs to generate density nowcasts for U.S. GDP growth:
Bayes by Backprop and Monte Carlo dropout. The accuracy of point nowcasts,
defined as the mean of the empirical predictive distribution, is evaluated
relative to a naive constant growth model for GDP and a benchmark DFM
specification. Using a 1D CNN as the underlying ANN architecture, both
algorithms outperform those benchmarks during the evaluation period (2012:Q1 --
2022:Q4). Furthermore, both algorithms are able to dynamically adjust the
location (mean), scale (variance), and shape (skew) of the empirical predictive
distribution. The results indicate that both Bayes by Backprop and Monte Carlo
dropout can effectively augment the scope and functionality of ANNs, rendering
them a fully compatible and competitive alternative for classical time series
approaches.

摘要：<paragraph>文獻中最近的研究結果表明，人工神經網路 (ANN) 在 GDP 即時預測準確度方面可以優於動態因子模型 (DFM)。與 DFM 相比，這些高度靈活的非線性估計量的效能優勢在衰退和結構性斷裂時期特別明顯。然而，從政策制定者的角度來看，即時預測在傳達時附帶不確定性時最有幫助。雖然 DFM 和其他經典時間序列方法分析性地推導出 GDP 增長的預測 (條件) 分佈，但 ANN 只能根據其預設的訓練程序 (反向傳播) 產生點預測。為了填補這個空白，我們首先在文獻中調整兩種不同的深度學習演算法，使 ANN 能夠為美國 GDP 增長產生密度預測：反向傳播貝氏法和蒙地卡羅輟學法。定義為經驗預測分佈平均值的點預測準確度，相對於 GDP 的樸素常量成長模型和基準 DFM 規格進行評估。使用 1D CNN 作為基礎 ANN 架構，這兩種演算法在評估期間 (2012:Q1 -- 2022:Q4) 都優於這些基準。此外，這兩種演算法都能動態調整經驗預測分佈的位置 (平均值)、規模 (變異數) 和形狀 (偏度)。結果表明，反向傳播貝氏法和蒙地卡羅輟學法都能有效擴充 ANN 的範圍和功能，使其成為經典時間序列方法的完全相容且具有競爭力的替代方案。</paragraph>

##### **OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code**
2405.15568v1 by Maxence Faldor, Jenny Zhang, Antoine Cully, Jeff Clune

Open-ended and AI-generating algorithms aim to continuously generate and
solve increasingly complex tasks indefinitely, offering a promising path toward
more general intelligence. To accomplish this grand vision, learning must occur
within a vast array of potential tasks. Existing approaches to automatically
generating environments are constrained within manually predefined, often
narrow distributions of environment, limiting their ability to create any
learning environment. To address this limitation, we introduce a novel
framework, OMNI-EPIC, that augments previous work in Open-endedness via Models
of human Notions of Interestingness (OMNI) with Environments Programmed in Code
(EPIC). OMNI-EPIC leverages foundation models to autonomously generate code
specifying the next learnable (i.e., not too easy or difficult for the agent's
current skill set) and interesting (e.g., worthwhile and novel) tasks.
OMNI-EPIC generates both environments (e.g., an obstacle course) and reward
functions (e.g., progress through the obstacle course quickly without touching
red objects), enabling it, in principle, to create any simulatable learning
task. We showcase the explosive creativity of OMNI-EPIC, which continuously
innovates to suggest new, interesting learning challenges. We also highlight
how OMNI-EPIC can adapt to reinforcement learning agents' learning progress,
generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can
endlessly create learnable and interesting environments, further propelling the
development of self-improving AI systems and AI-Generating Algorithms. Project
website with videos: https://dub.sh/omniepic

摘要：開放式和 AI 生成演算法旨在持續生成和解決越來越複雜的任務，提供一條通往更通用智慧的道路。為了實現這個宏偉的願景，學習必須發生在大量的潛在任務中。自動產生環境的現有方法受限於手動預定義的、通常狹窄的環境分佈，限制了它們建立任何學習環境的能力。為了解決這個限制，我們引入了一個新的框架 OMNI-EPIC，它透過人類有趣概念模型 (OMNI) 的開放性，以及用程式碼編寫的環境 (EPIC) 來擴充先前的研究。OMNI-EPIC 利用基礎模型來自主產生程式碼，指定下一個可學習的（例如，對於代理目前的技能組來說不太容易或太困難）且有趣的（例如，有價值且新穎）任務。OMNI-EPIC 產生環境（例如，障礙賽）和獎勵函數（例如，快速通過障礙賽而不接觸紅色物體），在原則上，它能夠建立任何可模擬的學習任務。我們展示了 OMNI-EPIC 的爆炸性創造力，它不斷創新，提出新的、有趣的學習挑戰。我們也強調 OMNI-EPIC 如何適應強化學習代理的學習進度，產生難度適中的任務。總而言之，OMNI-EPIC 可以無止盡地建立可學習且有趣的環境，進一步推動自我提升 AI 系統和 AI 生成演算法的發展。專案網站和影片：https://dub.sh/omniepic

##### **Rethinking Independent Cross-Entropy Loss For Graph-Structured Data**
2405.15564v1 by Rui Miao, Kaixiong Zhou, Yili Wang, Ninghao Liu, Ying Wang, Xin Wang

Graph neural networks (GNNs) have exhibited prominent performance in learning
graph-structured data. Considering node classification task, based on the i.i.d
assumption among node labels, the traditional supervised learning simply sums
up cross-entropy losses of the independent training nodes and applies the
average loss to optimize GNNs' weights. But different from other data formats,
the nodes are naturally connected. It is found that the independent
distribution modeling of node labels restricts GNNs' capability to generalize
over the entire graph and defend adversarial attacks. In this work, we propose
a new framework, termed joint-cluster supervised learning, to model the joint
distribution of each node with its corresponding cluster. We learn the joint
distribution of node and cluster labels conditioned on their representations,
and train GNNs with the obtained joint loss. In this way, the data-label
reference signals extracted from the local cluster explicitly strengthen the
discrimination ability on the target node. The extensive experiments
demonstrate that our joint-cluster supervised learning can effectively bolster
GNNs' node classification accuracy. Furthermore, being benefited from the
reference signals which may be free from spiteful interference, our learning
paradigm significantly protects the node classification from being affected by
the adversarial attack.

摘要：圖神經網路 (GNN) 在學習圖形結構資料方面表現出色。考量節點分類任務，基於節點標籤中的 i.i.d 假設，傳統的監督式學習僅將獨立訓練節點的交叉熵損失相加，並套用平均損失來最佳化 GNN 的權重。但與其他資料格式不同的是，節點是自然連接的。發現節點標籤的獨立分佈模型限制了 GNN 在整個圖形中概括化和防禦對抗攻擊的能力。在這項工作中，我們提出了一個新的架構，稱為聯合叢集監督式學習，以對每個節點及其對應叢集建模聯合分佈。我們在節點和叢集標籤的表示條件下學習聯合分佈，並使用獲得的聯合損失訓練 GNN。藉此方式，從局部叢集中提取的資料標籤參考訊號明確地增強了目標節點的辨別能力。廣泛的實驗證明，我們的聯合叢集監督式學習可以有效地提升 GNN 的節點分類準確度。此外，由於受益於可能不受惡意干擾的參考訊號，我們的學習範例顯著地保護節點分類不受對抗攻擊的影響。

##### **Certifiably Robust RAG against Retrieval Corruption**
2405.15556v1 by Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal

Retrieval-augmented generation (RAG) has been shown vulnerable to retrieval
corruption attacks: an attacker can inject malicious passages into retrieval
results to induce inaccurate responses. In this paper, we propose RobustRAG as
the first defense framework against retrieval corruption attacks. The key
insight of RobustRAG is an isolate-then-aggregate strategy: we get LLM
responses from each passage in isolation and then securely aggregate these
isolated responses. To instantiate RobustRAG, we design keyword-based and
decoding-based algorithms for securely aggregating unstructured text responses.
Notably, RobustRAG can achieve certifiable robustness: we can formally prove
and certify that, for certain queries, RobustRAG can always return accurate
responses, even when the attacker has full knowledge of our defense and can
arbitrarily inject a small number of malicious passages. We evaluate RobustRAG
on open-domain QA and long-form text generation datasets and demonstrate its
effectiveness and generalizability across various tasks and datasets.

摘要：檢索增強生成 (RAG) 已被證明容易受到檢索破壞攻擊：攻擊者可以將惡意段落注入檢索結果中，以誘發不準確的回應。在本文中，我們提出 RobustRAG 作為對抗檢索破壞攻擊的第一個防禦架構。RobustRAG 的關鍵見解是孤立後聚合策略：我們從每個段落中孤立地獲得 LLM 回應，然後安全地聚合這些孤立的回應。為了實例化 RobustRAG，我們設計了基於關鍵字和基於解碼的演算法，用於安全地聚合非結構化文本回應。值得注意的是，RobustRAG 可以實現可驗證的穩健性：我們可以正式證明並證明，對於某些查詢，即使攻擊者完全了解我們的防禦措施，並且可以任意注入少量惡意段落，RobustRAG 也可以始終回傳準確的回應。我們在開放領域問答和長篇文字生成資料集上評估 RobustRAG，並展示其在各種任務和資料集中的有效性和泛化能力。

##### **Sparse Matrix in Large Language Model Fine-tuning**
2405.15525v1 by Haoze He, Juncheng Billy Li, Xuan Jiang, Heather Miller

LoRA and its variants have become popular parameter-efficient fine-tuning
(PEFT) methods due to their ability to avoid excessive computational costs.
However, an accuracy gap often exists between PEFT methods and full fine-tuning
(FT), and this gap has yet to be systematically studied. In this work, we
introduce a method for selecting sparse sub-matrices that aim to minimize the
performance gap between PEFT vs. full fine-tuning (FT) while also reducing both
fine-tuning computational cost and memory cost. Our Sparse Matrix Tuning (SMT)
method begins by identifying the most significant sub-matrices in the gradient
update, updating only these blocks during the fine-tuning process. In our
experiments, we demonstrate that SMT consistently surpasses other PEFT baseline
(e.g. LoRA and DoRA) in fine-tuning popular large language models such as LLaMA
across a broad spectrum of tasks, while reducing the GPU memory footprint by
67% compared to FT. We also examine how the performance of LoRA and DoRA tends
to plateau and decline as the number of trainable parameters increases, in
contrast, our SMT method does not suffer from such issue.

摘要：LoRA 及其變體已成為熱門的參數高效微調 (PEFT) 方法，因為它們能夠避免過高的計算成本。
然而，PEFT 方法和完全微調 (FT) 之間通常存在準確性差距，而這個差距尚未經過系統性研究。在這項工作中，我們
提出了一種選擇稀疏子矩陣的方法，旨在最小化 PEFT 與完全微調 (FT) 之間的效能差距，同時也能降低微調的計算成本和記憶體成本。我們的稀疏矩陣微調 (SMT) 方法首先識別梯度更新中最重要的子矩陣，並在微調過程中僅更新這些區塊。在我們的
實驗中，我們證明 SMT 在微調 LLaMA 等熱門大型語言模型方面始終優於其他 PEFT 基準 (例如 LoRA 和 DoRA)，同時在各種任務中將 GPU 記憶體使用量減少了
67%，與 FT 相比。我們還研究了 LoRA 和 DoRA 的效能如何隨著可訓練參數的增加而趨於平穩並下降，
相反，我們的 SMT 方法並不存在這樣的問題。

##### **Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language Models**
2405.15523v1 by Igor Shilov, Matthieu Meeus, Yves-Alexandre de Montjoye

The immense datasets used to develop Large Language Models (LLMs) often
include copyright-protected content, typically without the content creator's
consent. Copyright traps have been proposed to be injected into the original
content, improving content detectability in newly released LLMs. Traps,
however, rely on the exact duplication of a unique text sequence, leaving them
vulnerable to commonly deployed data deduplication techniques. We here propose
the generation of fuzzy copyright traps, featuring slight modifications across
duplication. When injected in the fine-tuning data of a 1.3B LLM, we show fuzzy
trap sequences to be memorized nearly as well as exact duplicates.
Specifically, the Membership Inference Attack (MIA) ROC AUC only drops from
0.90 to 0.87 when 4 tokens are replaced across the fuzzy duplicates. We also
find that selecting replacement positions to minimize the exact overlap between
fuzzy duplicates leads to similar memorization, while making fuzzy duplicates
highly unlikely to be removed by any deduplication process. Lastly, we argue
that the fact that LLMs memorize across fuzzy duplicates challenges the study
of LLM memorization relying on naturally occurring duplicates. Indeed, we find
that the commonly used training dataset, The Pile, contains significant amounts
of fuzzy duplicates. This introduces a previously unexplored confounding factor
in post-hoc studies of LLM memorization, and questions the effectiveness of
(exact) data deduplication as a privacy protection technique.

摘要：大型語言模型 (LLM) 的開發仰賴於大量的資料集，而這些資料集通常包含受著作權保護的內容，且通常未經內容創作者的同意。有人提出在原始內容中注入著作權陷阱，藉此提升新發布的 LLM 中內容的可偵測性。然而，陷阱依賴於獨特文字序列的精確複製，這使得它們容易受到常見的資料重複刪除技術影響。我們在此提出模糊著作權陷阱的產生，其特點是在重複刪除中進行些微修改。當注入 1.3B LLM 的微調資料中時，我們發現模糊陷阱序列的記憶化效果幾乎與精確重複相同。具體來說，當在模糊重複中替換 4 個符號時，成員推論攻擊 (MIA) ROC AUC 僅從 0.90 降至 0.87。我們還發現，選擇替換位置以最小化模糊重複之間的精確重疊，會導致類似的記憶化，同時讓模糊重複不太可能被任何重複刪除程序移除。最後，我們認為 LLM 在模糊重複中進行記憶化的現象，挑戰了依賴自然發生的重複進行 LLM 記憶化的研究。事實上，我們發現常用的訓練資料集 The Pile 中包含大量的模糊重複。這在事後對 LLM 記憶化的研究中引入了先前未探索的混淆因素，並質疑（精確）資料重複刪除作為隱私保護技術的有效性。

##### **A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search**
2405.15521v1 by Huimu Wang, Mingming Li, Dadong Miao, Songlin Wang, Guoyu Tang, Lin Liu, Sulong Xu, Jinghe Hu

Re-ranking is a process of rearranging ranking list to more effectively meet
user demands by accounting for the interrelationships between items. Existing
methods predominantly enhance the precision of search results, often at the
expense of diversity, leading to outcomes that may not fulfill the varied needs
of users. Conversely, methods designed to promote diversity might compromise
the precision of the results, failing to satisfy the users' requirements for
accuracy. To alleviate the above problems, this paper proposes a
Preference-oriented Diversity Model Based on Mutual-information (PODM-MI),
which consider both accuracy and diversity in the re-ranking process.
Specifically, PODM-MI adopts Multidimensional Gaussian distributions based on
variational inference to capture users' diversity preferences with uncertainty.
Then we maximize the mutual information between the diversity preferences of
the users and the candidate items using the maximum variational inference lower
bound to enhance their correlations. Subsequently, we derive a utility matrix
based on the correlations, enabling the adaptive ranking of items in line with
user preferences and establishing a balance between the aforementioned
objectives. Experimental results on real-world online e-commerce systems
demonstrate the significant improvements of PODM-MI, and we have successfully
deployed PODM-MI on an e-commerce search platform.

摘要：重新排序是透過考慮項目之間的相互關係，重新排列排名清單的過程，以更有效地滿足使用者需求。現有方法主要提升搜尋結果的精確度，通常是以多樣性為代價，導致無法滿足使用者多元需求的結果。相反地，旨在提升多樣性的方法可能會影響結果的精確度，無法滿足使用者對精確度的要求。為了緩解上述問題，本文提出一個基於互信息的偏好導向多樣性模型 (PODM-MI)，在重新排序過程中同時考慮精確度和多樣性。具體來說，PODM-MI 採用基於變異推論的多維高斯分布，以不確定性捕捉使用者的多樣性偏好。然後，我們使用最大變異推論下界最大化使用者多樣性偏好和候選項目之間的互信息，以提升它們之間的關聯性。隨後，我們根據關聯性推導一個效用矩陣，讓項目能夠根據使用者偏好進行自適應排名，並在上述目標之間取得平衡。在真實世界的線上電子商務系統上的實驗結果證明了 PODM-MI 的顯著改進，我們已成功將 PODM-MI 部署在電子商務搜尋平台上。

##### **On the Convexity and Reliability of the Bethe Free Energy Approximation**
2405.15514v1 by Harald Leisenberger, Christian Knoll, Franz Pernkopf

The Bethe free energy approximation provides an effective way for relaxing
NP-hard problems of probabilistic inference. However, its accuracy depends on
the model parameters and particularly degrades if a phase transition in the
model occurs. In this work, we analyze when the Bethe approximation is reliable
and how this can be verified. We argue and show by experiment that it is mostly
accurate if it is convex on a submanifold of its domain, the 'Bethe box'. For
verifying its convexity, we derive two sufficient conditions that are based on
the definiteness properties of the Bethe Hessian matrix: the first uses the
concept of diagonal dominance, and the second decomposes the Bethe Hessian
matrix into a sum of sparse matrices and characterizes the definiteness
properties of the individual matrices in that sum. These theoretical results
provide a simple way to estimate the critical phase transition temperature of a
model. As a practical contribution we propose $\texttt{BETHE-MIN}$, a projected
quasi-Newton method to efficiently find a minimum of the Bethe free energy.

摘要：貝氏自由能近似提供了一種有效的方法來放鬆概率推理的 NP 難題。然而，其準確性取決於模型參數，特別是在模型中發生相變時會特別下降。在這項工作中，我們分析了貝氏近似何時可靠，以及如何驗證這一點。我們通過實驗論證並表明，如果它在其域的子流形「貝氏方塊」上是凸的，那麼它大多是準確的。為了驗證其凸性，我們導出了兩個充分條件，它們基於貝氏海森矩陣的確定性屬性：第一個使用對角優勢的概念，第二個將貝氏海森矩陣分解為稀疏矩陣的總和，並描述了該總和中個別矩陣的確定性屬性。這些理論結果提供了一種簡單的方法來估計模型的臨界相變溫度。作為一個實際貢獻，我們提出了 $\texttt{BETHE-MIN}$，這是一種投影的準牛頓方法，可以有效地找到貝氏自由能的最小值。

##### **ChatGPT Code Detection: Techniques for Uncovering the Source of Code**
2405.15512v1 by Marc Oedingen, Raphael C. Engelhardt, Robin Denz, Maximilian Hammer, Wolfgang Konen

In recent times, large language models (LLMs) have made significant strides
in generating computer code, blurring the lines between code created by humans
and code produced by artificial intelligence (AI). As these technologies evolve
rapidly, it is crucial to explore how they influence code generation,
especially given the risk of misuse in areas like higher education. This paper
explores this issue by using advanced classification techniques to
differentiate between code written by humans and that generated by ChatGPT, a
type of LLM. We employ a new approach that combines powerful embedding features
(black-box) with supervised learning algorithms - including Deep Neural
Networks, Random Forests, and Extreme Gradient Boosting - to achieve this
differentiation with an impressive accuracy of 98%. For the successful
combinations, we also examine their model calibration, showing that some of the
models are extremely well calibrated. Additionally, we present white-box
features and an interpretable Bayes classifier to elucidate critical
differences between the code sources, enhancing the explainability and
transparency of our approach. Both approaches work well but provide at most
85-88% accuracy. We also show that untrained humans solve the same task not
better than random guessing. This study is crucial in understanding and
mitigating the potential risks associated with using AI in code generation,
particularly in the context of higher education, software development, and
competitive programming.

摘要：<paragraph>最近，大型语言模型 (LLM) 在生成计算机代码方面取得了重大进展，模糊了人类创建的代码和人工智能 (AI) 生成的代码之间的界限。随着这些技术迅速发展，探索它们如何影响代码生成至关重要，尤其考虑到在高等教育等领域滥用的风险。本文通过使用先进的分类技术来探索这个问题，以区分人类编写的代码和 ChatGPT（一种 LLM）生成的代码。我们采用了一种新方法，将强大的嵌入式特征（黑匣子）与监督学习算法相结合，包括深度神经网络、随机森林和极端梯度提升，以实现这种差异化，准确度高达 98%。对于成功的组合，我们还检查了它们的模型校准，表明一些模型校准得非常好。此外，我们提出了白盒特征和可解释的贝叶斯分类器，以阐明代码源之间的关键差异，增强了我们方法的可解释性和透明性。两种方法都很好，但准确率最多为 85-88%。我们还表明，未经训练的人类解决相同任务的准确率不高于随机猜测。这项研究对于理解和减轻在代码生成中使用 AI 相关的潜在风险至关重要，特别是在高等教育、软件开发和竞技编程的背景下。</paragraph>

##### **Revisiting Counterfactual Regression through the Lens of Gromov-Wasserstein Information Bottleneck**
2405.15505v1 by Hao Yang, Zexu Sun, Hongteng Xu, Xu Chen

As a promising individualized treatment effect (ITE) estimation method,
counterfactual regression (CFR) maps individuals' covariates to a latent space
and predicts their counterfactual outcomes. However, the selection bias between
control and treatment groups often imbalances the two groups' latent
distributions and negatively impacts this method's performance. In this study,
we revisit counterfactual regression through the lens of information bottleneck
and propose a novel learning paradigm called Gromov-Wasserstein information
bottleneck (GWIB). In this paradigm, we learn CFR by maximizing the mutual
information between covariates' latent representations and outcomes while
penalizing the kernelized mutual information between the latent representations
and the covariates. We demonstrate that the upper bound of the penalty term can
be implemented as a new regularizer consisting of $i)$ the fused
Gromov-Wasserstein distance between the latent representations of different
groups and $ii)$ the gap between the transport cost generated by the model and
the cross-group Gromov-Wasserstein distance between the latent representations
and the covariates. GWIB effectively learns the CFR model through alternating
optimization, suppressing selection bias while avoiding trivial latent
distributions. Experiments on ITE estimation tasks show that GWIB consistently
outperforms state-of-the-art CFR methods. To promote the research community, we
release our project at https://github.com/peteryang1031/Causal-GWIB.

摘要：作為一個有前途的個人化處理效果（ITE）估計方法，反事實迴歸（CFR）將個人的協變數對應到一個潛在空間，並預測其反事實結果。然而，對照組和處理組之間的選擇偏差通常會使這兩個組的潛在分佈失去平衡，並對此方法的效能產生負面影響。在本研究中，我們透過資訊瓶頸的觀點重新檢視反事實迴歸，並提出一個稱為 Gromov-Wasserstein 資訊瓶頸（GWIB）的新穎學習範例。在此範例中，我們透過最大化協變數潛在表徵與結果之間的互資訊來學習 CFR，同時懲罰潛在表徵與協變數之間的核化互資訊。我們證明懲罰項的上限可以實作為一個新的正則化項，其中包含 $i)$ 不同組之間潛在表徵的融合 Gromov-Wasserstein 距離，以及 $ii)$ 模型產生的運送成本與潛在表徵和協變數之間的跨組 Gromov-Wasserstein 距離的差距。GWIB 有效地透過交替最佳化來學習 CFR 模型，在避免平凡潛在分佈的同時抑制選擇偏差。ITE 估計任務的實驗顯示，GWIB 持續優於最先進的 CFR 方法。為了促進研究社群，我們在 https://github.com/peteryang1031/Causal-GWIB 釋出我們的專案。

##### **Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs**
2405.15485v1 by Siyuan Guo, Aniket Didolkar, Nan Rosemary Ke, Anirudh Goyal, Ferenc Huszár, Bernhard Schölkopf

We are beginning to see progress in language model assisted scientific
discovery. Motivated by the use of LLMs as a general scientific assistant, this
paper assesses the domain knowledge of LLMs through its understanding of
different mathematical skills required to solve problems. In particular, we
look at not just what the pre-trained model already knows, but how it learned
to learn from information during in-context learning or instruction-tuning
through exploiting the complex knowledge structure within mathematics.
Motivated by the Neural Tangent Kernel (NTK), we propose \textit{NTKEval} to
assess changes in LLM's probability distribution via training on different
kinds of math data. Our systematic analysis finds evidence of domain
understanding during in-context learning. By contrast, certain
instruction-tuning leads to similar performance changes irrespective of
training on different data, suggesting a lack of domain understanding across
different skills.

摘要：我們開始看到語言模型輔助的科學發現進展。本文以 LLM 作為一般科學助理的使用為動機，透過 LLM 對解決問題所需的各種數學技能的理解來評估 LLM 的領域知識。特別是，我們不僅關注預先訓練的模型已經知道什麼，還關注它如何透過在情境學習或指令調整期間從資訊中學習，並透過利用數學中複雜的知識結構來學習。受神經切線核 (NTK) 的啟發，我們提出 \textit{NTKEval} 來評估 LLM 在不同類型的數學資料上訓練後其機率分佈的變化。我們的系統分析發現了在情境學習期間領域理解的證據。相比之下，某些指令調整會導致類似的效能變化，而與在不同資料上訓練無關，這表示缺乏跨不同技能的領域理解。

##### **Editable Concept Bottleneck Models**
2405.15476v1 by Lijie Hu, Chenyang Ren, Zhengyu Hu, Cheng-Long Wang, Di Wang

Concept Bottleneck Models (CBMs) have garnered much attention for their
ability to elucidate the prediction process through a human-understandable
concept layer. However, most previous studies focused on cases where the data,
including concepts, are clean. In many scenarios, we always need to
remove/insert some training data or new concepts from trained CBMs due to
different reasons, such as privacy concerns, data mislabelling, spurious
concepts, and concept annotation errors. Thus, the challenge of deriving
efficient editable CBMs without retraining from scratch persists, particularly
in large-scale applications. To address these challenges, we propose Editable
Concept Bottleneck Models (ECBMs). Specifically, ECBMs support three different
levels of data removal: concept-label-level, concept-level, and data-level.
ECBMs enjoy mathematically rigorous closed-form approximations derived from
influence functions that obviate the need for re-training. Experimental results
demonstrate the efficiency and effectiveness of our ECBMs, affirming their
adaptability within the realm of CBMs.

摘要：概念瓶颈模型 (CBM) 因其透過人類可理解的概念層闡明預測過程的能力而備受關注。然而，大多數先前的研究都集中在資料（包括概念）乾淨的情況。在許多情況下，我們總是需要基於不同的原因（例如隱私考量、資料標籤錯誤、虛假概念和概念註解錯誤）從受過訓練的 CBM 中移除/插入一些訓練資料或新概念。因此，在不從頭開始重新訓練的情況下，衍生出可編輯的有效 CBM 的挑戰仍然存在，特別是在大型應用程式中。為了應對這些挑戰，我們提出可編輯概念瓶頸模型 (ECBM)。具體來說，ECBM 支援三個不同的資料移除層級：概念標籤層級、概念層級和資料層級。ECBM 享有從影響函數中衍生的數學上嚴謹的閉合形式近似值，消除了重新訓練的需要。實驗結果證明了我們 ECBM 的效率和有效性，肯定了它們在 CBM 領域內的適應性。

##### **Emergence of a High-Dimensional Abstraction Phase in Language Transformers**
2405.15471v1 by Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni

A language model (LM) is a mapping from a linguistic context to an output
token. However, much remains to be known about this mapping, including how its
geometric properties relate to its function. We take a high-level geometric
approach to its analysis, observing, across five pre-trained transformer-based
LMs and three input datasets, a distinct phase characterized by high intrinsic
dimensionality. During this phase, representations (1) correspond to the first
full linguistic abstraction of the input; (2) are the first to viably transfer
to downstream tasks; (3) predict each other across different LMs. Moreover, we
find that an earlier onset of the phase strongly predicts better language
modelling performance. In short, our results suggest that a central
high-dimensionality phase underlies core linguistic processing in many common
LM architectures.

摘要：語言模型 (LM) 是一種從語言環境映射到輸出
符號的映射。然而，關於此映射還有許多未知之處，包括它的
幾何屬性如何與其功能相關。我們採用高層級的幾何
方法來分析它，觀察跨越五個預先訓練的基於Transformer的
LM 和三個輸入資料集，一個以高內在維度為特徵的獨特階段。在此階段，表示 (1) 對應於輸入的第一個完整語言抽象；(2) 是第一個可行地轉移
到下游任務的；(3) 在不同的 LM 之間相互預測。此外，我們
發現該階段的較早開始強烈預測更好的語言
建模性能。簡而言之，我們的結果表明，一個中心
高維度階段是許多常見
LM 架構中核心語言處理的基礎。

##### **Linearly Controlled Language Generation with Performative Guarantees**
2405.15454v1 by Emily Cheng, Marco Baroni, Carmen Amo Alonso

The increasing prevalence of Large Language Models (LMs) in critical
applications highlights the need for controlled language generation strategies
that are not only computationally efficient but that also enjoy performance
guarantees. To achieve this, we use a common model of concept semantics as
linearly represented in an LM's latent space. In particular, we take the view
that natural language generation traces a trajectory in this continuous
semantic space, realized by the language model's hidden activations. This view
permits a control-theoretic treatment of text generation in latent space, in
which we propose a lightweight, gradient-free intervention that dynamically
steers trajectories away from regions corresponding to undesired meanings.
Crucially, we show that this intervention, which we compute in closed form, is
guaranteed (in probability) to steer the output into the allowed region.
Finally, we demonstrate on a toxicity avoidance objective that the intervention
steers language away from undesired content while maintaining text quality.

摘要：大型語言模型 (LM) 在關鍵應用程式中日益普遍，這突顯出對受控語言產生策略的需求，這些策略不僅在運算上有效率，而且還能享有效能保證。為達成此目的，我們使用概念語義的共同模型，在 LM 的潛在空間中以線性方式表示。特別是，我們認為自然語言產生會在這個連續語義空間中追蹤一個軌跡，並由語言模型的隱藏啟動實現。這種觀點允許對潛在空間中的文字產生進行控制理論處理，其中我們提出一個輕量級、無梯度的介入措施，動態地將軌跡導離對應於不需要意義的區域。至關重要的是，我們證明了這個我們以封閉形式計算的介入措施，保證 (在機率上) 將輸出導向允許的區域。最後，我們在毒性避免目標上證明，介入措施將語言導離不需要的內容，同時維持文字品質。

##### **Benchmarking Pre-trained Large Language Models' Potential Across Urdu NLP tasks**
2405.15453v1 by Munief Hassan Tahir, Sana Shams, Layba Fiaz, Farah Adeeba, Sarmad Hussain

Large Language Models (LLMs) pre-trained on multilingual data have
revolutionized natural language processing research, by transitioning from
languages and task specific model pipelines to a single model adapted on a
variety of tasks. However majority of existing multilingual NLP benchmarks for
LLMs provide evaluation data in only few languages with little linguistic
diversity. In addition these benchmarks lack quality assessment against the
respective state-of the art models. This study presents an in-depth examination
of prominent LLMs; GPT-3.5-turbo, Llama2-7B-Chat, Bloomz 7B1 and Bloomz 3B,
across 14 tasks using 15 Urdu datasets, in a zero-shot setting, and their
performance against state-of-the-art (SOTA) models, has been compared and
analysed. Our experiments show that SOTA models surpass all the encoder-decoder
pre-trained language models in all Urdu NLP tasks with zero-shot learning. Our
results further show that LLMs with fewer parameters, but more language
specific data in the base model perform better than larger computational
models, but low language data.

摘要：大型語言模型 (LLM) 預先在多語言資料上進行訓練，透過從特定語言和任務模型管線轉換為適應各種任務的單一模型，徹底改變了自然語言處理研究。然而，現有的大多數多語言 NLP 基準測試僅提供少數語言的評估資料，語言多樣性較低。此外，這些基準測試缺乏針對各自最先進模型的品質評估。本研究深入探討了主要的 LLM；GPT-3.5-turbo、Llama2-7B-Chat、Bloomz 7B1 和 Bloomz 3B，使用 15 個烏爾都語資料集，在零次學習設定中執行 14 項任務，並比較和分析它們相對於最先進 (SOTA) 模型的效能。我們的實驗顯示，SOTA 模型在所有烏爾都語 NLP 任務中都超越了所有編碼器解碼器預先訓練的語言模型，且採用零次學習。我們的結果進一步顯示，參數較少但基本模型中語言特定資料較多的 LLM，其效能優於計算模型較大但語言資料較少的 LLM。

##### **Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top**
2405.15452v1 by Keyuan Cheng, Muhammad Asif Ali, Shu Yang, Gang Ling, Yuxuan Zhai, Haoyang Fei, Ke Xu, Lu Yu, Lijie Hu, Di Wang

Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key
challenge in Large Language Models (LLMs). While best-performing solutions in
this domain use a plan and solve paradigm to split a question into
sub-questions followed by response generation, we claim that this approach is
sub-optimal as it fails for hard to decompose questions, and it does not
explicitly cater to correlated knowledge updates resulting as a consequence of
knowledge edits. This has a detrimental impact on the overall consistency of
the updated knowledge. To address these issues, in this paper, we propose a
novel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a
cherry on the top for augmenting the performance of all existing MQA methods
under KE. Specifically, RULE-KE leverages rule discovery to discover a set of
logical rules. Then, it uses these discovered rules to update knowledge about
facts highly correlated with the edit. Experimental evaluation using existing
and newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment
both performances of parameter-based and memory-based solutions up to 92% and
112.9%, respectively.

摘要：<paragraph>在知識編輯 (KE) 下的多跳問答 (MQA) 是大型語言模型 (LLM) 的關鍵挑戰。雖然在這個領域中表現最佳的解決方案使用計畫和解決範例將問題拆分為子問題，然後再產生回應，但我們聲稱這種方法次佳，因為它無法分解困難的問題，而且它沒有明確滿足因知識編輯而產生的相關知識更新。這對更新知識的整體一致性有不利影響。為了解決這些問題，在本文中，我們提出了一個名為 RULE-KE 的新框架，即基於 RULE 的知識編輯，它是用於增強所有現有 MQA 方法在 KE 下的效能的錦上添花。具體來說，RULE-KE 利用規則發現來發現一組邏輯規則。然後，它使用這些發現的規則來更新與編輯高度相關的事實的知識。使用現有和新整理的資料集（即 RKE-EVAL）進行的實驗評估表明，RULE-KE 有助於分別將基於參數和基於記憶體的解決方案的效能提高到 92% 和 112.9%。</paragraph>

##### **HyperInterval: Hypernetwork approach to training weight interval regions in continual learning**
2405.15444v1 by Patryk Krukowski, Anna Bielawska, Kamil Książek, Paweł Wawrzyński, Paweł Batorski, Przemysław Spurek

Recently, a new Continual Learning (CL) paradigm was presented to control
catastrophic forgetting, called Interval Continual Learning (InterContiNet),
which relies on enforcing interval constraints on the neural network parameter
space. Unfortunately, InterContiNet training is challenging due to the high
dimensionality of the weight space, making intervals difficult to manage. To
address this issue, we introduce HyperInterval, a technique that employs
interval arithmetic within the embedding space and utilizes a hypernetwork to
map these intervals to the target network parameter space. We train interval
embeddings for consecutive tasks and train a hypernetwork to transform these
embeddings into weights of the target network. An embedding for a given task is
trained along with the hypernetwork, preserving the response of the target
network for the previous task embeddings. Interval arithmetic works with a more
manageable, lower-dimensional embedding space rather than directly preparing
intervals in a high-dimensional weight space. Our model allows faster and more
efficient training. Furthermore, HyperInterval maintains the guarantee of not
forgetting. At the end of training, we can choose one universal embedding to
produce a single network dedicated to all tasks. In such a framework,
hypernetwork is used only for training and can be seen as a meta-trainer.
HyperInterval obtains significantly better results than InterContiNet and gives
SOTA results on several benchmarks.

摘要：最近，提出了一种新的连续学习 (CL) 范例来控制灾难性遗忘，称为区间连续学习 (InterContiNet)，它依赖于在神经网络参数空间中实施区间约束。不幸的是，由于权重空间的高维性，InterContiNet 训练具有挑战性，这使得区间难以管理。为了解决这个问题，我们引入了 HyperInterval，这是一种在嵌入空间中使用区间算法并利用超网络将这些区间映射到目标网络参数空间的技术。我们对连续任务训练区间嵌入，并训练超网络将这些嵌入转换为目标网络的权重。给定任务的嵌入与超网络一起训练，保留目标网络对先前任务嵌入的响应。区间算法使用更易于管理的低维嵌入空间，而不是直接在高维权重空间中准备区间。我们的模型允许更快、更有效的训练。此外，HyperInterval 保证不遗忘。在训练结束时，我们可以选择一个通用嵌入来生成一个专门用于所有任务的单一网络。在这样的框架中，超网络仅用于训练，可以看作元训练器。HyperInterval 获得明显优于 InterContiNet 的结果，并在多个基准上给出了 SOTA 结果。

##### **Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented Knowledge Graphs and Vector Database for Accreditation Reporting Assistance**
2405.15436v1 by Candace Edwards

In higher education, accreditation is a quality assurance process, where an
institution demonstrates a commitment to delivering high quality programs and
services to their students. For business schools nationally and internationally
the Association to Advance Collegiate Schools of Business (AACSB) accreditation
is the gold standard. For a business school to receive and subsequently
maintain accreditation, the school must undertake a rigorous, time consuming
reporting and peer review process, to demonstrate alignment with the AACSB
Standards. For this project we create a hybrid context retrieval augmented
generation pipeline that can assist in the documentation alignment and
reporting process necessary for accreditation. We implement both a vector
database and knowledge graph, as knowledge stores containing both institutional
data and AACSB Standard data. The output of the pipeline can be used by
institution stakeholders to build their accreditation report, dually grounded
by the context from the knowledge stores. To develop our knowledge graphs we
utilized both a manual construction process as well as an LLM Augmented
Knowledge Graph approach. We evaluated the pipeline using the RAGAs framework
and observed optimal performance on answer relevancy and answer correctness
metrics.

摘要：在高等教育中，認證是一種品質保證程序，機構在此程序中展現對提供高品質計畫和服務給學生的承諾。對於國內和國際商學院而言，國際商管學院促進協會 (AACSB) 認證是黃金標準。商學院若要取得並維持認證，學校必須進行嚴格且耗時的報告和同儕審查程序，以證明符合 AACSB 標準。在這個專案中，我們建立了一個混合式脈絡擷取增強式產生管線，可以協助認證所需的說明文件對齊和報告程序。我們實作了向量資料庫和知識圖譜，作為包含機構資料和 AACSB 標準資料的知識儲存。管線的輸出可供機構利害關係人用於建構其認證報告，並由知識儲存中的脈絡雙重依據。為了開發我們的知識圖譜，我們利用了手動建構程序和 LLM 增強知識圖譜方法。我們使用 RAGAs 架構評估管線，並觀察到在答案相關性和答案正確性指標上獲得最佳效能。

##### **Luban: Building Open-Ended Creative Agents via Autonomous Embodied Verification**
2405.15414v1 by Yuxuan Guo, Shaohui Peng, Jiaming Guo, Di Huang, Xishan Zhang, Rui Zhang, Yifan Hao, Ling Li, Zikang Tian, Mingju Gao, Yutai Li, Yiming Gan, Shuai Liang, Zihao Zhang, Zidong Du, Qi Guo, Xing Hu, Yunji Chen

Building open agents has always been the ultimate goal in AI research, and
creative agents are the more enticing. Existing LLM agents excel at
long-horizon tasks with well-defined goals (e.g., `mine diamonds' in
Minecraft). However, they encounter difficulties on creative tasks with open
goals and abstract criteria due to the inability to bridge the gap between
them, thus lacking feedback for self-improvement in solving the task. In this
work, we introduce autonomous embodied verification techniques for agents to
fill the gap, laying the groundwork for creative tasks. Specifically, we
propose the Luban agent target creative building tasks in Minecraft, which
equips with two-level autonomous embodied verification inspired by human design
practices: (1) visual verification of 3D structural speculates, which comes
from agent synthesized CAD modeling programs; (2) pragmatic verification of the
creation by generating and verifying environment-relevant functionality
programs based on the abstract criteria. Extensive multi-dimensional human
studies and Elo ratings show that the Luban completes diverse creative building
tasks in our proposed benchmark and outperforms other baselines ($33\%$ to
$100\%$) in both visualization and pragmatism. Additional demos on the
real-world robotic arm show the creation potential of the Luban in the physical
world.

摘要：建立開放代理一直是人工智慧研究的終極目標，而富有創意的代理更是誘人。現有的 LLM 代理擅長於目標明確的長時程任務（例如 Minecraft 中的「開採鑽石」）。然而，由於無法彌合目標開放且標準抽象的創意任務之間的差距，他們在這些任務上會遇到困難，因此缺乏自我改善以解決任務的回饋。在這項工作中，我們引入了代理的自主具身驗證技術來填補差距，為創意任務奠定基礎。具體來說，我們提出了 Luban 代理目標 Minecraft 中的創意建築任務，它配備了受人類設計實務啟發的兩級自主具身驗證：(1) 3D 結構假設的視覺驗證，來自代理合成 CAD 建模程式；(2) 根據抽象標準產生並驗證與環境相關的功能程式的創作實用驗證。廣泛的多維度人類研究和 Elo 評分顯示，Luban 在我們提出的基準中完成了各種創意建築任務，並且在視覺化和實用性方面都優於其他基準（33% 到 100%）。在真實機器手臂上的其他示範顯示了 Luban 在物理世界中的創作潛力。

##### **ORCA: A Global Ocean Emulator for Multi-year to Decadal Predictions**
2405.15412v1 by Zijie Guo, Pumeng Lyu, Fenghua Ling, Jing-Jia Luo, Niklas Boers, Wanli Ouyang, Lei Bai

Ocean dynamics plays a crucial role in driving global weather and climate
patterns. Accurate and efficient modeling of ocean dynamics is essential for
improved understanding of complex ocean circulation and processes, for
predicting climate variations and their associated teleconnections, and for
addressing the challenges of climate change. While great efforts have been made
to improve numerical Ocean General Circulation Models (OGCMs), accurate
forecasting of global oceanic variations for multi-year remains to be a
long-standing challenge. Here, we introduce ORCA (Oceanic Reliable foreCAst),
the first data-driven model predicting global ocean circulation from multi-year
to decadal time scales. ORCA accurately simulates the three-dimensional
circulations and dynamics of the global ocean with high physical consistency.
Hindcasts of key oceanic variables demonstrate ORCA's remarkable prediction
skills in predicting ocean variations compared with state-of-the-art numerical
OGCMs and abilities in capturing occurrences of extreme events at the
subsurface ocean and ENSO vertical patterns. These results demonstrate the
potential of data-driven ocean models for providing cheap, efficient, and
accurate global ocean modeling and prediction. Moreover, ORCA stably and
faithfully emulates ocean dynamics at decadal timescales, demonstrating its
potential even for climate projections. The model will be available at
https://github.com/OpenEarthLab/ORCA.

摘要：海洋動力在推動全球天氣和氣候模式中扮演著至關重要的角色。準確且有效率的海洋動力建模對於增進了解複雜的海洋環流和程序、預測氣候變化及其相關的遙相關、並解決氣候變遷的挑戰至關重要。儘管已投入大量心力改善數值海洋環流模式 (OGCM)，但對於多年期全球海洋變化的準確預測仍是一個長期的挑戰。在此，我們介紹 ORCA（海洋可靠預測），這是第一個從多年期到十年期時間尺度預測全球海洋環流的資料驅動模型。ORCA 以高度物理一致性準確模擬全球海洋的三維環流和動力。關鍵海洋變數的後向預測證明了 ORCA 在預測海洋變化方面的顯著預測技巧，與最先進的數值 OGCM 相比，以及在捕捉海底海洋和 ENSO 垂直模式的極端事件發生方面的能力。這些結果證明了資料驅動海洋模型在提供便宜、有效率且準確的全球海洋建模和預測方面的潛力。此外，ORCA 在十年期時間尺度上穩定且忠實地模擬海洋動力，證明了其甚至在氣候預測方面的潛力。此模型將在 https://github.com/OpenEarthLab/ORCA 上提供。

##### **PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**
2405.15398v1 by Yuandou Wang, Neel Kanwal, Kjersti Engan, Chunming Rong, Paola Grosso, Zhiming Zhao

Running deep neural networks for large medical images is a resource-hungry
and time-consuming task with centralized computing. Outsourcing such medical
image processing tasks to hybrid clouds has benefits, such as a significant
reduction of execution time and monetary cost. However, due to privacy
concerns, it is still challenging to process sensitive medical images over
clouds, which would hinder their deployment in many real-world applications. To
overcome this, we first formulate the overall optimization objectives of the
privacy-preserving distributed system model, i.e., minimizing the amount of
information about the private data learned by the adversaries throughout the
process, reducing the maximum execution time and cost under the user budget
constraint. We propose a novel privacy-preserving and cost-effective method
called PriCE to solve this multi-objective optimization problem. We performed
extensive simulation experiments for artifact detection tasks on medical images
using an ensemble of five deep convolutional neural network inferences as the
workflow task. Experimental results show that PriCE successfully splits a wide
range of input gigapixel medical images with graph-coloring-based strategies,
yielding desired output utility and lowering the privacy risk, makespan, and
monetary cost under user's budget.

摘要：執行大型醫療影像的深度神經網路是項資源消耗且耗時的任務，需要集中式運算。將此類醫療影像處理任務外包給混合雲端具有好處，例如大幅縮短執行時間和金錢成本。然而，由於隱私問題，在雲端處理敏感的醫療影像仍是一項挑戰，這會阻礙它們在許多實際應用中的部署。為了解決這個問題，我們首先制定了隱私保護分散式系統模型的整體最佳化目標，即最小化對手在整個過程中所得知的私人資料資訊量，在使用者預算限制下減少最大的執行時間和成本。我們提出了一種稱為 PriCE 的新型隱私保護且成本效益高的方式來解決這個多目標最佳化問題。我們對醫療影像上的人工製品偵測任務執行廣泛的模擬實驗，使用五個深度卷積神經網路推論的整體作為工作流程任務。實驗結果顯示，PriCE 成功地使用基於圖形著色的策略來分割各種輸入的千兆畫素醫療影像，產生所需的輸出效用並降低隱私風險、執行時間和在使用者預算下的金錢成本。

##### **Language-Driven Interactive Traffic Trajectory Generation**
2405.15388v1 by Junkai Xia, Chenxin Xu, Qingyao Xu, Chen Xie, Yanfeng Wang, Siheng Chen

Realistic trajectory generation with natural language control is pivotal for
advancing autonomous vehicle technology. However, previous methods focus on
individual traffic participant trajectory generation, thus failing to account
for the complexity of interactive traffic dynamics. In this work, we propose
InteractTraj, the first language-driven traffic trajectory generator that can
generate interactive traffic trajectories. InteractTraj interprets abstract
trajectory descriptions into concrete formatted interaction-aware numerical
codes and learns a mapping between these formatted codes and the final
interactive trajectories. To interpret language descriptions, we propose a
language-to-code encoder with a novel interaction-aware encoding strategy. To
produce interactive traffic trajectories, we propose a code-to-trajectory
decoder with interaction-aware feature aggregation that synergizes vehicle
interactions with the environmental map and the vehicle moves. Extensive
experiments show our method demonstrates superior performance over previous
SoTA methods, offering a more realistic generation of interactive traffic
trajectories with high controllability via diverse natural language commands.
Our code is available at https://github.com/X1a-jk/InteractTraj.git

摘要：以自然語言控制的真實軌跡生成對於推進自動駕駛技術至關重要。然而，先前的研究方法專注於個別交通參與者的軌跡生成，因此無法考量互動式交通動態的複雜性。在本文中，我們提出 InteractTraj，這是第一個以語言驅動的交通軌跡生成器，可以生成互動式的交通軌跡。InteractTraj 將抽象的軌跡描述轉換為具體格式化的互動感知數值代碼，並學習這些格式化代碼與最終互動軌跡之間的對應關係。為了詮釋語言描述，我們提出一個語言到代碼編碼器，並採用一種新穎的互動感知編碼策略。為了產生互動式的交通軌跡，我們提出一個代碼到軌跡解碼器，並採用互動感知特徵聚合，將車輛互動與環境地圖和車輛移動協同起來。廣泛的實驗顯示，我們的研究方法表現優於先前的 SoTA 方法，透過多樣化的自然語言指令，提供更真實的互動式交通軌跡生成，並具備高度可控性。我們的程式碼可在 https://github.com/X1a-jk/InteractTraj.git 取得

##### **Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search**
2405.15383v1 by Nicola Dainese, Matteo Merler, Minttu Alakuijala, Pekka Marttinen

In this work we consider Code World Models, world models generated by a Large
Language Model (LLM) in the form of Python code for model-based Reinforcement
Learning (RL). Calling code instead of LLMs for planning has the advantages of
being precise, reliable, interpretable, and extremely efficient. However,
writing appropriate Code World Models requires the ability to understand
complex instructions, to generate exact code with non-trivial logic and to
self-debug a long program with feedback from unit tests and environment
trajectories. To address these challenges, we propose Generate, Improve and Fix
with Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy for
LLMs. To test our approach, we introduce the Code World Models Benchmark
(CWMB), a suite of program synthesis and planning tasks comprised of 18 diverse
RL environments paired with corresponding textual descriptions and curated
trajectories. GIF-MCTS surpasses all baselines on the CWMB and two other
benchmarks, and we show that the Code World Models synthesized with it can be
successfully used for planning, resulting in model-based RL agents with greatly
improved sample efficiency and inference speed.

摘要：在這項工作中，我們考慮了程式碼世界模型，由大型語言模型 (LLM) 以 Python 程式碼的形式產生，用於基於模型的強化學習 (RL)。呼叫程式碼而非 LLM 來規劃具有精確、可靠、可詮釋和極高效能的優點。然而，撰寫適當的程式碼世界模型需要理解複雜指令、產生具有非平凡邏輯的確切程式碼，以及使用單元測試和環境軌跡的回饋來自我偵錯長程式碼的能力。為了應對這些挑戰，我們提出了生成、改善和修復與蒙地卡羅樹狀搜尋 (GIF-MCTS) 的新程式碼生成策略，用於 LLM。為了測試我們的做法，我們引入了程式碼世界模型基準 (CWMB)，這是一套程式碼合成和規劃任務，包含 18 種不同的 RL 環境，搭配對應的文字描述和策劃的軌跡。GIF-MCTS 在 CWMB 和其他兩個基準上超越所有基準，我們表明使用它合成的程式碼世界模型可成功用於規劃，從而產生具有大幅改善的樣本效率和推論速度的基於模型的 RL 代理。

##### **A Planet Scale Spatial-Temporal Knowledge Graph Based On OpenStreetMap And H3 Grid**
2405.15375v1 by Martin Böckling, Heiko Paulheim, Sarah Detzler

Geospatial data plays a central role in modeling our world, for which
OpenStreetMap (OSM) provides a rich source of such data. While often spatial
data is represented in a tabular format, a graph based representation provides
the possibility to interconnect entities which would have been separated in a
tabular representation. We propose in our paper a framework which supports a
planet scale transformation of OpenStreetMap data into a Spatial Temporal
Knowledge Graph. In addition to OpenStreetMap data, we align the different
OpenStreetMap geometries on individual h3 grid cells. We compare our
constructed spatial knowledge graph to other spatial knowledge graphs and
outline our contribution in this paper. As a basis for our computation, we use
Apache Sedona as a computational framework for our Spatial Temporal Knowledge
Graph construction

摘要：地理空間資料在建構我們的世界的模型中扮演著核心角色，而 OpenStreetMap（OSM）提供了豐富的此類資料來源。雖然空間資料經常以表格格式呈現，但基於圖形的表示方式提供了將實體互連的可能性，這些實體在表格表示方式中會被分開。我們在論文中提出一個架構，支援將 OpenStreetMap 資料大規模轉換為時空知識圖譜。除了 OpenStreetMap 資料之外，我們將不同的 OpenStreetMap 幾何形狀對齊在個別 h3 格網儲存格上。我們將建構的時空知識圖譜與其他時空知識圖譜進行比較，並在本文中概述我們的貢獻。作為運算的基礎，我們使用 Apache Sedona 作為時空知識圖譜建構的運算架構

##### **Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph**
2405.15374v1 by Runsong Jia, Bowen Zhang, Sergio J. Rodríguez Méndez, Pouya G. Omran

The proposed research aims to develop an innovative semantic query processing
system that enables users to obtain comprehensive information about research
works produced by Computer Science (CS) researchers at the Australian National
University (ANU). The system integrates Large Language Models (LLMs) with the
ANU Scholarly Knowledge Graph (ASKG), a structured repository of all
research-related artifacts produced at ANU in the CS field. Each artifact and
its parts are represented as textual nodes stored in a Knowledge Graph (KG).
  To address the limitations of traditional scholarly KG construction and
utilization methods, which often fail to capture fine-grained details, we
propose a novel framework that integrates the Deep Document Model (DDM) for
comprehensive document representation and the KG-enhanced Query Processing
(KGQP) for optimized complex query handling. DDM enables a fine-grained
representation of the hierarchical structure and semantic relationships within
academic papers, while KGQP leverages the KG structure to improve query
accuracy and efficiency with LLMs.
  By combining the ASKG with LLMs, our approach enhances knowledge utilization
and natural language understanding capabilities. The proposed system employs an
automatic LLM-SPARQL fusion to retrieve relevant facts and textual nodes from
the ASKG. Initial experiments demonstrate that our framework is superior to
baseline methods in terms of accuracy retrieval and query efficiency.
  We showcase the practical application of our framework in academic research
scenarios, highlighting its potential to revolutionize scholarly knowledge
management and discovery. This work empowers researchers to acquire and utilize
knowledge from documents more effectively and provides a foundation for
developing precise and reliable interactions with LLMs.

摘要：<paragraph>擬議的研究旨在開發創新的語義查詢處理系統，使用戶能夠獲得由澳洲國立大學（ANU）電腦科學（CS）研究人員產出的研究著作的全面資訊。此系統整合大型語言模型（LLM）與澳洲國立大學學術知識圖譜（ASKG），後者為在澳洲國立大學 CS 領域產出的所有研究相關人工製品的結構化儲存庫。每個人工製品及其部分以儲存在知識圖譜（KG）中的文字節點表示。
為了解決傳統學術 KG 建構和使用方式的限制，這些方式通常無法擷取細微的細節，我們提出一個新的架構，它整合深度文件模型（DDM）以進行全面的文件表示，以及 KG 增強查詢處理（KGQP）以進行最佳化的複雜查詢處理。DDM 能夠細微地表示學術論文中的階層結構和語義關係，而 KGQP 則利用 KG 結構透過 LLM 來改善查詢的準確性和效率。
透過將 ASKG 與 LLM 結合，我們的做法增強了知識利用和自然語言理解能力。擬議的系統採用自動 LLM-SPARQL 融合來從 ASKG 擷取相關事實和文字節點。初步實驗顯示，我們的架構在準確性擷取和查詢效率方面優於基準方法。
我們展示了我們的架構在學術研究情境中的實際應用，強調其革新學術知識管理和發現的潛力。這項工作賦能研究人員更有效地取得和利用文件中的知識，並為與 LLM 進行精確且可靠的互動奠定基礎。</paragraph>

##### **Autonomous Quilt Spreading for Caregiving Robots**
2405.15373v1 by Yuchun Guo, Zhiqing Lu, Yanling Zhou, Xin Jiang

In this work, we propose a novel strategy to ensure infants, who
inadvertently displace their quilts during sleep, are promptly and accurately
re-covered. Our approach is formulated into two subsequent steps: interference
resolution and quilt spreading. By leveraging the DWPose human skeletal
detection and the Segment Anything instance segmentation models, the proposed
method can accurately recognize the states of the infant and the quilt over
her, which involves addressing the interferences resulted from an infant's
limbs laid on part of the quilt. Building upon prior research, the EM*D deep
learning model is employed to forecast quilt state transitions before and after
quilt spreading actions. To improve the sensitivity of the network in
distinguishing state variation of the handled quilt, we introduce an enhanced
loss function that translates the voxelized quilt state into a more
representative one. Both simulation and real-world experiments validate the
efficacy of our method, in spreading and recover a quilt over an infant.

摘要：在這項工作中，我們提出了一種新穎的策略，以確保在睡眠期間不小心踢掉被子的嬰兒能夠迅速且準確地重新蓋好被子。我們的做法被制定成兩個後續步驟：干擾解決和被子鋪展。通過利用 DWPose 人體骨骼檢測和 Segment Anything 實例分割模型，所提出的方法可以準確識別嬰兒和其身上被子的狀態，其中包括解決嬰兒的四肢放在被子一部分上所造成的干擾。基於先前的研究，EM*D 深度學習模型被用於預測在被子鋪展動作前後的被子狀態轉換。為了提高網路在區分處理過的被子的狀態變化時的敏感度，我們引入了一個增強的損失函數，它將體素化的被子狀態轉換為更具代表性的狀態。模擬和真實世界的實驗都驗證了我們的方法在為嬰兒鋪展和蓋好被子方面的有效性。

##### **Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection**
2405.15370v1 by Jun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

Time series anomaly detection (TSAD) plays a crucial role in various
industries by identifying atypical patterns that deviate from standard trends,
thereby maintaining system integrity and enabling prompt response measures.
Traditional TSAD models, which often rely on deep learning, require extensive
training data and operate as black boxes, lacking interpretability for detected
anomalies. To address these challenges, we propose LLMAD, a novel TSAD method
that employs Large Language Models (LLMs) to deliver accurate and interpretable
TSAD results. LLMAD innovatively applies LLMs for in-context anomaly detection
by retrieving both positive and negative similar time series segments,
significantly enhancing LLMs' effectiveness. Furthermore, LLMAD employs the
Anomaly Detection Chain-of-Thought (AnoCoT) approach to mimic expert logic for
its decision-making process. This method further enhances its performance and
enables LLMAD to provide explanations for their detections through versatile
perspectives, which are particularly important for user decision-making.
Experiments on three datasets indicate that our LLMAD achieves detection
performance comparable to state-of-the-art deep learning methods while offering
remarkable interpretability for detections. To the best of our knowledge, this
is the first work that directly employs LLMs for TSAD.

摘要：時間序列異常偵測 (TSAD) 在各種產業中扮演著至關重要的角色，透過找出偏離標準趨勢的異常模式，進而維護系統的完整性並促成及時的回應措施。傳統的 TSAD 模型通常仰賴深度學習，需要大量的訓練資料，且運作方式就像黑盒子，缺乏對偵測到的異常現象的詮釋能力。為了應對這些挑戰，我們提出 LLMAD，這是一種創新的 TSAD 方法，採用大型語言模型 (LLM) 來提供準確且可解釋的 TSAD 結果。LLMAD 創新地應用 LLM 進行情境異常偵測，透過擷取正負相似的時間序列片段，大幅提升 LLM 的效能。此外，LLMAD 採用異常偵測思考鏈 (AnoCoT) 方法來模擬專家的邏輯，作為其決策流程。此方法進一步提升其效能，並讓 LLMAD 能夠透過多面向的觀點對其偵測結果提供說明，這對於使用者的決策制定而言特別重要。在三個資料集上的實驗顯示，我們的 LLMAD 達到了與現有深度學習方法相當的偵測效能，同時也為偵測結果提供了卓越的可解釋性。據我們所知，這是第一個直接採用 LLM 進行 TSAD 的研究。

##### **Pipeline Parallelism with Controllable Memory**
2405.15362v1 by Penghui Qi, Xinyi Wan, Nyamdavaa Amar, Min Lin

Pipeline parallelism has been widely explored, but most existing schedules
lack a systematic methodology. In this paper, we propose a framework to
decompose pipeline schedules as repeating a building block and we show that the
lifespan of the building block decides the peak activation memory of the
pipeline schedule. Guided by the observations, we find that almost all existing
pipeline schedules, to the best of our knowledge, are memory inefficient. To
address this, we introduce a family of memory efficient building blocks with
controllable activation memory, which can reduce the peak activation memory to
1/2 of 1F1B without sacrificing efficiency, and even to 1/3 with comparable
throughput. We can also achieve almost zero pipeline bubbles while maintaining
the same activation memory as 1F1B. Our evaluations demonstrate that in pure
pipeline parallelism settings, our methods outperform 1F1B by from 7% to 55% in
terms of throughput. When employing a grid search over hybrid parallelism
hyperparameters in practical scenarios, our proposed methods demonstrate a 16%
throughput improvement over the 1F1B baseline for large language models.

摘要：管道并行已得到广泛探索，但大多数现有计划缺乏系统的方法。在本文中，我们提出了一个框架，将管道计划分解为重复构建块，并且我们表明构建块的生命周期决定了管道计划的峰值激活内存。在观察的指导下，我们发现几乎所有现有的管道计划，据我们所知，都是内存效率低下的。为了解决这个问题，我们引入了一系列具有可控激活内存的内存高效构建块，它可以在不牺牲效率的情况下将峰值激活内存减少到 1F1B 的 1/2，甚至在具有可比吞吐量的情况下减少到 1/3。我们还可以在与 1F1B 相同的激活内存的情况下实现几乎为零的管道气泡。我们的评估表明，在纯管道并行设置中，我们的方法在吞吐量方面比 1F1B 高出 7% 至 55%。在实际场景中对混合并行超参数采用网格搜索时，我们提出的方法展示了比 1F1B 基线高出 16% 的吞吐量改进，适用于大型语言模型。

##### **UnKE: Unstructured Knowledge Editing in Large Language Models**
2405.15349v1 by Jingcheng Deng, Zihao Wei, Liang Pang, Hanxing Ding, Huawei Shen, Xueqi Cheng

Recent knowledge editing methods have primarily focused on modifying
structured knowledge in large language models, heavily relying on the
assumption that structured knowledge is stored as key-value pairs locally in
MLP layers or specific neurons. However, this task setting overlooks the fact
that a significant portion of real-world knowledge is stored in an unstructured
format, characterized by long-form content, noise, and a complex yet
comprehensive nature. The "knowledge locating" and "term-driven optimization"
techniques conducted from the assumption used in previous methods (e.g., MEMIT)
are ill-suited for unstructured knowledge. To address these challenges, we
propose a novel unstructured knowledge editing method, namely UnKE, which
extends previous assumptions in the layer dimension and token dimension.
Firstly, in the layer dimension, we discard the "knowledge locating" step and
treat first few layers as the key, which expand knowledge storage through
layers to break the "knowledge stored locally" assumption. Next, we replace
"term-driven optimization" with "cause-driven optimization" across all inputted
tokens in the token dimension, directly optimizing the last layer of the key
generator to perform editing to generate the required key vectors. By utilizing
key-value pairs at the layer level, UnKE effectively represents and edits
complex and comprehensive unstructured knowledge, leveraging the potential of
both the MLP and attention layers. Results on newly proposed unstructure
knowledge editing dataset (UnKEBench) and traditional structured datasets
demonstrate that UnKE achieves remarkable performance, surpassing strong
baselines.

摘要：<paragraph>最近的知識編輯方法主要集中於修改大型語言模型中的結構化知識，嚴重依賴於結構化知識以鍵值對形式局部儲存在 MLP 層或特定神經元中的假設。然而，此任務設定忽略了現實世界知識的很大一部分是以非結構化格式儲存，其特徵為長篇內容、雜訊和複雜但全面的性質。「知識定位」和「術語驅動最佳化」技術是根據先前方法（例如 MEMIT）中使用的假設進行的，不適合非結構化知識。為了應對這些挑戰，我們提出了一種新穎的非結構化知識編輯方法，即 UnKE，它在層次維度和標記維度上延伸了先前的假設。首先，在層次維度中，我們捨棄「知識定位」步驟，並將前幾層視為鍵，通過層次來擴展知識儲存，以打破「知識局部儲存」假設。接下來，我們用「因果驅動最佳化」取代標記維度中所有輸入標記的「術語驅動最佳化」，直接最佳化鍵生成器的最後一層，以進行編輯以生成所需的鍵向量。通過利用層級的鍵值對，UnKE 有效地表示和編輯複雜且全面的非結構化知識，同時利用了 MLP 和注意力層的潛力。在最新提出的非結構化知識編輯資料集 (UnKEBench) 和傳統結構化資料集上的結果證明，UnKE 達到了顯著的效能，超越了強大的基線。</paragraph>

##### **BiSup: Bidirectional Quantization Error Suppression for Large Language Models**
2405.15346v1 by Minghui Zou, Ronghui Guo, Sai Zhang, Xiaowang Zhang, Zhiyong Feng

As the size and context length of Large Language Models (LLMs) grow,
weight-activation quantization has emerged as a crucial technique for efficient
deployment of LLMs. Compared to weight-only quantization, weight-activation
quantization presents greater challenges due to the presence of outliers in
activations. Existing methods have made significant progress by exploring
mixed-precision quantization and outlier suppression. However, these methods
primarily focus on optimizing the results of single matrix multiplication,
neglecting the bidirectional propagation of quantization errors in LLMs.
Specifically, errors accumulate vertically within the same token through
layers, and diffuse horizontally across different tokens due to self-attention
mechanisms. To address this issue, we introduce BiSup, a Bidirectional
quantization error Suppression method. By constructing appropriate optimizable
parameter spaces, BiSup utilizes a small amount of data for quantization-aware
parameter-efficient fine-tuning to suppress the error vertical accumulation.
Besides, BiSup employs prompt mixed-precision quantization strategy, which
preserves high precision for the key-value cache of system prompts, to mitigate
the error horizontal diffusion. Extensive experiments on Llama and Qwen
families demonstrate that BiSup can improve performance over two
state-of-the-art methods (the average WikiText2 perplexity decreases from 13.26
to 9.41 for Atom and from 14.33 to 7.85 for QuaRot under the W3A3-g128
configuration), further facilitating the practical applications of low-bit
weight-activation quantization.

摘要：隨著大型語言模型 (LLM) 的規模和內容長度不斷增長，
權重激活量化已成為 LLM 有效部署的一項關鍵技術。與僅權重量化相比，權重激活量化由於激活值中存在異常值而帶來了更大的挑戰。現有方法通過探索混合精度量化和異常值抑制取得了顯著進展。然而，這些方法主要著重於優化單一矩陣乘法的結果，而忽視了 LLM 中量化誤差的雙向傳播。具體來說，誤差在同一令牌內通過層垂直累積，並由於自注意力機制而橫向擴散到不同令牌。為了解決這個問題，我們引入了 BiSup，一種雙向量化誤差抑制方法。通過構建適當的可優化參數空間，BiSup 利用少量數據進行量化感知的參數高效微調，以抑制誤差垂直累積。此外，BiSup 採用提示混合精度量化策略，該策略保留了系統提示的鍵值快取的高精度，以減輕誤差水平擴散。在 Llama 和 Qwen 家族上的大量實驗表明，BiSup 可以優於兩種最先進的方法（在 W3A3-g128 配置下，Atom 的平均 WikiText2 困惑度從 13.26 減少到 9.41，QuaRot 的困惑度從 14.33 減少到 7.85），進一步促進了低位元權重激活量化的實際應用。

##### **V-Zen: Efficient GUI Understanding and Precise Grounding With A Novel Multimodal LLM**
2405.15341v1 by Abdur Rahman, Rajat Chawla, Muskaan Kumar, Arkajit Datta, Adarsh Jha, Mukunda NS, Ishaan Bhola

In the rapidly evolving landscape of AI research and application, Multimodal
Large Language Models (MLLMs) have emerged as a transformative force, adept at
interpreting and integrating information from diverse modalities such as text,
images, and Graphical User Interfaces (GUIs). Despite these advancements, the
nuanced interaction and understanding of GUIs pose a significant challenge,
limiting the potential of existing models to enhance automation levels. To
bridge this gap, this paper presents V-Zen, an innovative Multimodal Large
Language Model (MLLM) meticulously crafted to revolutionise the domain of GUI
understanding and grounding. Equipped with dual-resolution image encoders,
V-Zen establishes new benchmarks in efficient grounding and next-action
prediction, thereby laying the groundwork for self-operating computer systems.
Complementing V-Zen is the GUIDE dataset, an extensive collection of real-world
GUI elements and task-based sequences, serving as a catalyst for specialised
fine-tuning. The successful integration of V-Zen and GUIDE marks the dawn of a
new era in multimodal AI research, opening the door to intelligent, autonomous
computing experiences. This paper extends an invitation to the research
community to join this exciting journey, shaping the future of GUI automation.
In the spirit of open science, our code, data, and model will be made publicly
available, paving the way for multimodal dialogue scenarios with intricate and
precise interactions.

摘要：在快速演變的人工智慧研究和應用領域中，多模態大型語言模型 (MLLM) 已成為一股變革力量，擅長解讀和整合來自不同模態的資訊，例如文字、影像和圖形使用者介面 (GUI)。儘管有這些進展，GUI 的細微互動和理解仍構成重大挑戰，限制了現有模型提升自動化程度的潛力。為了彌合這個差距，本文提出了 V-Zen，這是一個創新的多模態大型語言模型 (MLLM)，經過精心打造，旨在革新 GUI 理解和基礎領域。V-Zen 配備了雙解析度影像編碼器，在高效基礎和下一個動作預測方面建立了新的基準，從而為自運作電腦系統奠定了基礎。與 V-Zen 相輔相成的是 GUIDE 資料集，這是一個廣泛的真實世界 GUI 元素和基於任務的序列集合，可用作專門微調的催化劑。V-Zen 和 GUIDE 的成功整合標誌著多模態人工智慧研究新紀元的到來，為智慧型、自主的運算體驗開啟了大門。本文邀請研究社群加入這趟令人興奮的旅程，共同形塑 GUI 自動化的未來。本著開放科學的精神，我們的程式碼、資料和模型將公開提供，為具有複雜且精確互動的多模態對話場景鋪路。

##### **Detection and Positive Reconstruction of Cognitive Distortion sentences: Mandarin Dataset and Evaluation**
2405.15334v1 by Shuya Lin, Yuxiong Wang, Jonathan Dong, Shiguang Ni

This research introduces a Positive Reconstruction Framework based on
positive psychology theory. Overcoming negative thoughts can be challenging,
our objective is to address and reframe them through a positive
reinterpretation. To tackle this challenge, a two-fold approach is necessary:
identifying cognitive distortions and suggesting a positively reframed
alternative while preserving the original thought's meaning. Recent studies
have investigated the application of Natural Language Processing (NLP) models
in English for each stage of this process. In this study, we emphasize the
theoretical foundation for the Positive Reconstruction Framework, grounded in
broaden-and-build theory. We provide a shared corpus containing 4001 instances
for detecting cognitive distortions and 1900 instances for positive
reconstruction in Mandarin. Leveraging recent NLP techniques, including
transfer learning, fine-tuning pretrained networks, and prompt engineering, we
demonstrate the effectiveness of automated tools for both tasks. In summary,
our study contributes to multilingual positive reconstruction, highlighting the
effectiveness of NLP in cognitive distortion detection and positive
reconstruction.

摘要：本研究基於正向心理學理論，提出一個正向重建架構。克服負面思考可能具有挑戰性，我們的目標是透過正向重新詮釋來處理並重新建構它們。為了應對這項挑戰，必須採取雙管齊下的方法：識別認知扭曲，並在保留原始思想意義的同時，提出一個正向重新建構的替代方案。最近的研究探討了自然語言處理 (NLP) 模型在這個過程中每個階段的應用。在本研究中，我們強調正向重建架構的理論基礎，奠基於擴展與建構理論。我們提供了一個共享語料庫，其中包含 4001 個用於偵測認知扭曲的實例，以及 1900 個用於正向重建的中文實例。透過利用最近的 NLP 技術，包括遷移學習、微調預訓練網路和提示工程，我們證明了自動化工具在兩個任務中的有效性。總而言之，我們的研究有助於多語言正向重建，強調 NLP 在認知扭曲偵測和正向重建中的有效性。

##### **Decompose and Aggregate: A Step-by-Step Interpretable Evaluation Framework**
2405.15329v1 by Minzhi Li, Zhengyuan Liu, Shumin Deng, Shafiq Joty, Nancy F. Chen, Min-Yen Kan

The acceleration of Large Language Models (LLMs) research has opened up new
possibilities for evaluating generated texts. They serve as scalable and
economical evaluators, but the question of how reliable these evaluators are
has emerged as a crucial research question. Prior research efforts in the
meta-evaluation of LLMs as judges limit the prompting of an LLM to a single use
to obtain a final evaluation decision. They then compute the agreement between
LLMs' outputs and human labels. This lacks interpretability in understanding
the evaluation capability of LLMs. In light of this challenge, we propose
Decompose and Aggregate, which breaks down the evaluation process into
different stages based on pedagogical practices. Our experiments illustrate
that it not only provides a more interpretable window for how well LLMs
evaluate, but also leads to improvements up to 39.6% for different LLMs on a
variety of meta-evaluation benchmarks.

摘要：大型語言模型 (LLM) 研究的加速為評估生成的文字開啟了新的可能性。它們作為可擴充且經濟的評估器，但這些評估器有多可靠的問題已成為一項重要的研究課題。先前針對 LLM 作為評審進行元評估的研究工作，將 LLM 的提示限制為單一用途，以取得最終的評估決定。接著，他們計算 LLM 的輸出與人類標籤之間的一致性。這在理解 LLM 的評估能力方面缺乏可解釋性。有鑑於此挑戰，我們提出分解與彙總，它根據教學實務將評估流程分解為不同的階段。我們的實驗說明，它不僅為 LLM 的評估表現提供了更具可解釋性的視窗，還讓不同 LLM 在各種元評估基準上獲得高達 39.6% 的進步。

##### **Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs**
2405.15320v1 by Asım Ersoy, Olcay Taner Yıldız

Grammatical Error Correction has seen significant progress with the recent
advancements in deep learning. As those methods require huge amounts of data,
synthetic datasets are being built to fill this gap. Unfortunately, synthetic
datasets are not organic enough in some cases and even require clean data to
start with. Furthermore, most of the work that has been done is focused mostly
on English. In this work, we introduce a new organic data-driven approach,
clean insertions, to build parallel Turkish Grammatical Error Correction
datasets from any organic data, and to clean the data used for training Large
Language Models. We achieve state-of-the-art results on two Turkish Grammatical
Error Correction test sets out of the three publicly available ones. We also
show the effectiveness of our method on the training losses of training
language models.

摘要：語法錯誤更正已隨著深度學習的最新進展而顯著進步。由於這些方法需要大量資料，因此正在建立合成資料集以填補此差距。不幸的是，在某些情況下，合成資料集不夠自然，甚至需要從乾淨的資料開始。此外，大多數已完成的工作主要集中在英語上。在這項工作中，我們介紹了一種新的有機資料驅動方法，即乾淨插入，以從任何有機資料建立平行的土耳其語法錯誤更正資料集，並清理用於訓練大型語言模型的資料。我們在三組公開可用的資料集中，於兩組土耳其語法錯誤更正測試集中達到了最先進的結果。我們還展示了我們的方法在訓練語言模型的訓練損失上的有效性。

##### **Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training**
2405.15319v1 by Wenyu Du, Tongxu Luo, Zihan Qiu, Zeyu Huang, Yikang Shen, Reynold Cheng, Yike Guo, Jie Fu

LLMs are computationally expensive to pre-train due to their large scale.
Model growth emerges as a promising approach by leveraging smaller models to
accelerate the training of larger ones. However, the viability of these model
growth methods in efficient LLM pre-training remains underexplored. This work
identifies three critical $\underline{\textit{O}}$bstacles: ($\textit{O}$1)
lack of comprehensive evaluation, ($\textit{O}$2) untested viability for
scaling, and ($\textit{O}$3) lack of empirical guidelines. To tackle
$\textit{O}$1, we summarize existing approaches into four atomic growth
operators and systematically evaluate them in a standardized LLM pre-training
setting. Our findings reveal that a depthwise stacking operator, called
$G_{\text{stack}}$, exhibits remarkable acceleration in training, leading to
decreased loss and improved overall performance on eight standard NLP
benchmarks compared to strong baselines. Motivated by these promising results,
we conduct extensive experiments to delve deeper into $G_{\text{stack}}$ to
address $\textit{O}$2 and $\textit{O}$3. For $\textit{O}$2 (untested
scalability), our study shows that $G_{\text{stack}}$ is scalable and
consistently performs well, with experiments up to 7B LLMs after growth and
pre-training LLMs with 750B tokens. For example, compared to a conventionally
trained 7B model using 300B tokens, our $G_{\text{stack}}$ model converges to
the same loss with 194B tokens, resulting in a 54.6\% speedup. We further
address $\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines
to determine growth timing and growth factor for $G_{\text{stack}}$, making it
practical in general LLM pre-training. We also provide in-depth discussions and
comprehensive ablation studies of $G_{\text{stack}}$. Our code and pre-trained
model are available at
$\href{https://llm-stacking.github.io/}{https://llm-stacking.github.io/}$.

摘要：<paragraph>由於規模龐大，LLM 在預訓練時需要大量的計算成本。
模型增長成為了一種有前途的方法，它利用較小的模型來加速較大模型的訓練。
然而，這些模型增長方法在高效 LLM 預訓練中的可行性仍未得到充分探索。
這項工作確定了三個關鍵的障礙：($\textit{O}$1) 缺乏全面的評估，($\textit{O}$2) 未測試的擴展可行性，以及 ($ \textit{O}$3) 缺乏經驗準則。
為了解決 $\textit{O}$1，我們將現有的方法總結為四個原子增長運算子，並在標準化的 LLM 預訓練設置中系統地評估它們。
我們的研究結果表明，一種稱為 $G_{\text{stack}}$ 的深度堆疊運算子在訓練中表現出顯著的加速，與強大的基準相比，在八個標準 NLP 基準上導致損失降低和整體性能提升。
受這些有希望的結果的啟發，我們進行了大量的實驗，深入探討 $G_{\text{stack}}$ 以解決 $\textit{O}$2 和 $\textit{O}$3。
對於 $\textit{O}$2（未測試的可擴展性），我們的研究表明 $G_{\text{stack}}$ 是可擴展的，並且始終表現良好，在增長和預訓練具有 750B 個令牌的 LLM 之後，實驗高達 7B LLM。
例如，與使用 300B 個令牌的傳統訓練的 7B 模型相比，我們的 $G_{\text{stack}}$ 模型使用 194B 個令牌收斂到相同的損失，從而將速度提高了 54.6%。
我們進一步通過形式化準則來確定 $G_{\text{stack}}$ 的增長時機和增長因子，從而解決 $\textit{O}$3（缺乏經驗準則），使其在一般的 LLM 預訓練中具有實用性。
我們還提供了 $G_{\text{stack}}$ 的深入討論和全面的消融研究。
我們的代碼和預訓練模型可在
$\href{https://llm-stacking.github.io/}{https://llm-stacking.github.io/}$ 獲得。</paragraph>

##### **Are Long-LLMs A Necessity For Long-Context Tasks?**
2405.15318v1 by Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Yujia Zhou, Xu Chen, Zhicheng Dou

The learning and deployment of long-LLMs remains a challenging problem
despite recent progresses. In this work, we argue that the long-LLMs are not a
necessity to solve long-context tasks, as common long-context tasks are
short-context solvable, i.e. they can be solved by purely working with oracle
short-contexts within the long-context tasks' inputs. On top of this argument,
we propose a framework called LC-Boost (Long-Context Bootstrapper), which
enables a short-LLM to address the long-context tasks in a bootstrapping
manner. In our framework, the short-LLM prompts itself to reason for two
critical decisions: 1) how to access to the appropriate part of context within
the input, 2) how to make effective use of the accessed context. By adaptively
accessing and utilizing the context based on the presented tasks, LC-Boost can
serve as a general framework to handle diversified long-context processing
problems. We comprehensively evaluate different types of tasks from popular
long-context benchmarks, where LC-Boost is able to achieve a substantially
improved performance with a much smaller consumption of resource.

摘要：儘管近期有進展，長期 LLM 的學習和部署仍然是一個具有挑戰性的問題。在這項工作中，我們論證長期 LLM 並非解決長期語境任務的必要條件，因為常見的長期語境任務是短期語境可解的，即它們可以透過純粹使用長期語境任務輸入中的神諭短期語境來解決。在此論點之上，我們提出一個稱為 LC-Boost（長期語境引導程式）的框架，它能讓短期 LLM 以引導方式來處理長期語境任務。在我們的框架中，短期 LLM 提示自己推論兩個關鍵決策：1) 如何存取輸入中語境的適當部分，2) 如何有效利用已存取的語境。透過根據所提供的任務自適應地存取和利用語境，LC-Boost 可作為一個通用框架來處理多樣化的長期語境處理問題。我們全面評估來自熱門長期語境基準的各種任務類型，其中 LC-Boost 能以更少的資源消耗大幅提升效能。

##### **NuwaTS: Mending Every Incomplete Time Series**
2405.15317v1 by Jinguo Cheng, Chunwei Yang, Wanlin Cai, Yuxuan Liang, Yuankai Wu

Time series imputation plays a crucial role in various real-world systems and
has been extensively explored. Models for time series imputation often require
specialization, necessitating distinct designs for different domains and
missing patterns. In this study, we introduce NuwaTS, a framework to repurpose
Pre-trained Language Model (PLM) for general time series imputation. Once
trained, this model can be applied to imputation tasks on incomplete time
series from any domain with any missing patterns. We begin by devising specific
embeddings for each sub-series patch of the incomplete time series. These
embeddings encapsulate information about the patch itself, the missing data
patterns within the patch, and the patch's statistical characteristics. To
enhance the model's adaptability to different missing patterns, we propose a
contrastive learning approach to make representations of the same patch more
similar across different missing patterns. By combining this contrastive loss
with the missing data imputation task, we train PLMs to obtain a one-for-all
imputation model. Furthermore, we utilize a plug-and-play layer-wise
fine-tuning approach to train domain-specific models. Experimental results
demonstrate that leveraging a dataset of over seventeen million time series
from diverse domains, we obtain a one-for-all imputation model which
outperforms existing domain-specific models across various datasets and missing
patterns. Additionally, we find that NuwaTS can be generalized to other time
series tasks such as forecasting. Our codes are available at
https://github.com/Chengyui/NuwaTS.

摘要：時間序列填補在各種真實世界系統中扮演著至關重要的角色，並且已被廣泛探討。時間序列填補模型通常需要專業化，這使得不同領域和遺失模式需要不同的設計。在這項研究中，我們引入了 NuwaTS，一個用於重新利用預訓練語言模型 (PLM) 以進行一般時間序列填補的架構。一旦訓練完成，此模型就可以應用於來自任何領域且具有任何遺失模式的不完整時間序列的填補任務。我們首先為不完整時間序列的每個子序列區塊設計特定的嵌入。這些嵌入封裝了有關區塊本身、區塊內的遺失數據模式以及區塊統計特徵的資訊。為了增強模型對不同遺失模式的適應性，我們提出了一種對比學習方法，以使同一個區塊的表示在不同的遺失模式之間更相似。透過將此對比損失與遺失數據填補任務結合，我們訓練 PLM 以獲得一個通用的填補模型。此外，我們利用即插即用的逐層微調方法來訓練特定於領域的模型。實驗結果表明，透過利用來自不同領域的超過一千七百萬個時間序列的資料集，我們獲得了一個通用的填補模型，它在各種資料集和遺失模式中都優於現有的特定於領域的模型。此外，我們發現 NuwaTS 可以推廣到其他時間序列任務，例如預測。我們的程式碼可在 https://github.com/Chengyui/NuwaTS 獲得。

##### **\textsc{Retro}]{\textsc{Retro}: \underline{Re}using \underline{t}eacher p\underline{ro}jection head for efficient embedding distillation on Lightweight Models via Self-supervised Learning**
2405.15311v1 by Khanh-Binh Nguyen, Chae Jung Park

Self-supervised learning (SSL) is gaining attention for its ability to learn
effective representations with large amounts of unlabeled data.
  Lightweight models can be distilled from larger self-supervised pre-trained
models using contrastive and consistency constraints.
  Still, the different sizes of the projection heads make it challenging for
students to mimic the teacher's embedding accurately.
  We propose \textsc{Retro}, which reuses the teacher's projection head for
students, and our experimental results demonstrate significant improvements
over the state-of-the-art on all lightweight models.
  For instance, when training EfficientNet-B0 using ResNet-50/101/152 as
teachers, our approach improves the linear result on ImageNet to $66.9\%$,
$69.3\%$, and $69.8\%$, respectively, with significantly fewer parameters.

摘要：自监督学习 (SSL) 因其利用大量未标记数据学习有效表征的能力而备受关注。
利用对比和一致性约束，可以从较大的自监督预训练模型中提炼轻量级模型。
然而，投影头的不同大小使得学生难以准确地模仿教师的嵌入。
我们提出了 \textsc{Retro}，它为学生重复利用教师的投影头，而我们的实验结果表明，在所有轻量级模型上都取得了比最先进技术显著的改进。
例如，当使用 ResNet-50/101/152 作为教师训练 EfficientNet-B0 时，我们的方法将 ImageNet 上的线性结果分别提高到 66.9%、69.3% 和 69.8%，而参数却明显减少。

##### **Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation**
2405.15307v1 by Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo, Chenhao Ma, Reynold Cheng

Large Language Models (LLMs) driven by In-Context Learning (ICL) have
significantly improved the performance of text-to-SQL. Previous methods
generally employ a two-stage reasoning framework, namely 1) schema linking and
2) logical synthesis, making the framework not only effective but also
interpretable. Despite these advancements, the inherent bad nature of the
generalization of LLMs often results in hallucinations, which limits the full
potential of LLMs. In this work, we first identify and categorize the common
types of hallucinations at each stage in text-to-SQL. We then introduce a novel
strategy, Task Alignment (TA), designed to mitigate hallucinations at each
stage. TA encourages LLMs to take advantage of experiences from similar tasks
rather than starting the tasks from scratch. This can help LLMs reduce the
burden of generalization, thereby mitigating hallucinations effectively. We
further propose TA-SQL, a text-to-SQL framework based on this strategy. The
experimental results and comprehensive analysis demonstrate the effectiveness
and robustness of our framework. Specifically, it enhances the performance of
the GPT-4 baseline by 21.23% relatively on BIRD dev and it yields significant
improvements across six models and four mainstream, complex text-to-SQL
benchmarks.

摘要：<paragraph>由情境學習 (ICL) 驅動的大型語言模型 (LLM) 已顯著改善文字轉 SQL 的效能。先前的做法通常採用兩階段推理架構，即 1) 架構連結和 2) 邏輯綜合，使架構不僅有效，而且可詮釋。儘管有這些進展，LLM 廣泛化固有的不良性質通常會導致幻覺，這限制了 LLM 的全部潛力。在這項工作中，我們首先識別並分類文字轉 SQL 各個階段常見的幻覺類型。然後，我們引入一種新策略，任務對齊 (TA)，旨在減輕每個階段的幻覺。TA 鼓勵 LLM 利用類似任務的經驗，而不是從頭開始執行任務。這有助於 LLM 減輕廣泛化的負擔，從而有效減輕幻覺。我們進一步提出基於此策略的文字轉 SQL 框架 TA-SQL。實驗結果和綜合分析證明了我們框架的有效性和穩健性。具體來說，它將 GPT-4 基準在 BIRD dev 上的效能提高了 21.23%，並且在六個模型和四個主流、複雜的文字轉 SQL 基準上產生了顯著的改善。</paragraph>

##### **DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ**
2405.15306v1 by Jonas Belouadi, Steffen Eger, Simone Paolo Ponzetto

Creating high-quality scientific figures can be time-consuming and
challenging, even though sketching ideas on paper is relatively easy.
Furthermore, recreating existing figures that are not stored in formats
preserving semantic information is equally complex. To tackle this problem, we
introduce DeTikZify, a novel multimodal language model that automatically
synthesizes scientific figures as semantics-preserving TikZ graphics programs
based on sketches and existing figures. To achieve this, we create three new
datasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k
human-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn
sketches with their corresponding scientific figures; and SciCap++, a
collection of diverse scientific figures and associated metadata. We train
DeTikZify on SciCap++ and DaTikZv2, along with synthetically generated sketches
learned from SketchFig. We also introduce an MCTS-based inference algorithm
that enables DeTikZify to iteratively refine its outputs without the need for
additional training. Through both automatic and human evaluation, we
demonstrate that DeTikZify outperforms commercial Claude 3 and GPT-4V in
synthesizing TikZ programs, with the MCTS algorithm effectively boosting its
performance. We make our code, models, and datasets publicly available.

摘要：建立高品質的科學圖形可能很費時且具挑戰性，即使在紙上勾勒想法相對容易。此外，重新建立未儲存在保留語義資訊格式中的現有圖形同樣複雜。為了解決這個問題，我們引入了 DeTikZify，這是一個新穎的多模態語言模型，它根據草圖和現有圖形自動綜合科學圖形作為語義保留 TikZ 圖形程式。為了達成這個目標，我們建立了三個新資料集：DaTikZv2，目前最大的 TikZ 資料集，包含超過 360k 人類建立的 TikZ 圖形；SketchFig，一個將手繪草圖與其對應科學圖形配對的資料集；以及 SciCap++，一個包含各種科學圖形和相關元資料的集合。我們在 SciCap++ 和 DaTikZv2 上訓練 DeTikZify，以及從 SketchFig 學習的合成產生草圖。我們還引入了一個基於 MCTS 的推論演算法，讓 DeTikZify 能夠反覆改善其輸出，而無需額外訓練。透過自動和人工評估，我們證明 DeTikZify 在綜合 TikZ 程式方面優於商業 Claude 3 和 GPT-4V，而 MCTS 演算法有效地提升了其效能。我們公開我們的程式碼、模型和資料集。

##### **Towards Understanding How Transformer Perform Multi-step Reasoning with Matching Operation**
2405.15302v1 by Zhiwei Wang, Yunji Wang, Zhongwang Zhang, Zhangchen Zhou, Hui Jin, Tianyang Hu, Jiacheng Sun, Zhenguo Li, Yaoyu Zhang, Zhi-Qin John Xu

Large language models have consistently struggled with complex reasoning
tasks, such as mathematical problem-solving. Investigating the internal
reasoning mechanisms of these models can help us design better model
architectures and training strategies, ultimately enhancing their reasoning
capabilities. In this study, we examine the matching mechanism employed by
Transformer for multi-step reasoning on a constructed dataset. We investigate
factors that influence the model's matching mechanism and discover that small
initialization and post-LayerNorm can facilitate the formation of the matching
mechanism, thereby enhancing the model's reasoning ability. Moreover, we
propose a method to improve the model's reasoning capability by adding
orthogonal noise. Finally, we investigate the parallel reasoning mechanism of
Transformers and propose a conjecture on the upper bound of the model's
reasoning ability based on this phenomenon. These insights contribute to a
deeper understanding of the reasoning processes in large language models and
guide designing more effective reasoning architectures and training strategies.

摘要：大型語言模型在複雜推理任務（例如數學問題求解）方面一直面臨挑戰。探討這些模型的內部推理機制有助於我們設計更好的模型架構和訓練策略，最終提升其推理能力。在本研究中，我們檢視 Transformer 在建構資料集上進行多步驟推理時所採用的配對機制。我們探討影響模型配對機制的因素，並發現小的初始化和 LayerNorm 後處理有助於配對機制的形成，進而提升模型的推理能力。此外，我們提出了一種方法，透過加入正交雜訊來提升模型的推理能力。最後，我們探討 Transformer 的平行推理機制，並根據此現象提出模型推理能力的上限猜想。這些見解有助於更深入地了解大型語言模型中的推理過程，並指導設計更有效的推理架構和訓練策略。

##### **Semi-Supervised Learning guided by the Generalized Bayes Rule under Soft Revision**
2405.15294v1 by Stefan Dietrich, Julian Rodemann, Christoph Jansen

We provide a theoretical and computational investigation of the Gamma-Maximin
method with soft revision, which was recently proposed as a robust criterion
for pseudo-label selection (PLS) in semi-supervised learning. Opposed to
traditional methods for PLS we use credal sets of priors ("generalized Bayes")
to represent the epistemic modeling uncertainty. These latter are then updated
by the Gamma-Maximin method with soft revision. We eventually select
pseudo-labeled data that are most likely in light of the least favorable
distribution from the so updated credal set. We formalize the task of finding
optimal pseudo-labeled data w.r.t. the Gamma-Maximin method with soft revision
as an optimization problem. A concrete implementation for the class of logistic
models then allows us to compare the predictive power of the method with
competing approaches. It is observed that the Gamma-Maximin method with soft
revision can achieve very promising results, especially when the proportion of
labeled data is low.

摘要：我們提供 Gamma-Maximin 方法的理論和計算調查，它採用軟修正，最近被提議作為半監督學習中偽標籤選擇 (PLS) 的穩健準則。與 PLS 的傳統方法相反，我們使用先驗的可信集（「廣義貝氏」）來表示認識建模的不確定性。然後，這些後者由 Gamma-Maximin 方法透過軟修正更新。我們最終選擇最可能根據已更新可信集中最不利的分配的偽標籤資料。我們將尋找相對於 Gamma-Maximin 方法的最佳偽標籤資料 w.r.t. 的任務形式化為一個最佳化問題。然後，針對邏輯模型類別的具體實作允許我們將該方法的預測能力與競爭方法進行比較。可以觀察到，採用軟修正的 Gamma-Maximin 方法可以達成非常有希望的結果，特別是在標籤資料的比例較低時。

##### **Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**
2405.15292v1 by Jokin Alcibar, Jose I. Aizpurua, Ekhi Zugasti

Batteries are a key enabling technology for the decarbonization of transport
and energy sectors. The safe and reliable operation of batteries is crucial for
battery-powered systems. In this direction, the development of accurate and
robust battery state-of-health prognostics models can unlock the potential of
autonomous systems for complex, remote and reliable operations. The combination
of Neural Networks, Bayesian modelling concepts and ensemble learning
strategies, form a valuable prognostics framework to combine uncertainty in a
robust and accurate manner. Accordingly, this paper introduces a Bayesian
ensemble learning approach to predict the capacity depletion of lithium-ion
batteries. The approach accurately predicts the capacity fade and quantifies
the uncertainty associated with battery design and degradation processes. The
proposed Bayesian ensemble methodology employs a stacking technique,
integrating multiple Bayesian neural networks (BNNs) as base learners, which
have been trained on data diversity. The proposed method has been validated
using a battery aging dataset collected by the NASA Ames Prognostics Center of
Excellence. Obtained results demonstrate the improved accuracy and robustness
of the proposed probabilistic fusion approach with respect to (i) a single BNN
model and (ii) a classical stacking strategy based on different BNNs.

摘要：電池是運輸和能源部門脫碳的重要使能技術。電池的安全性、可靠性對於電池供電系統至關重要。在這個方向上，準確、穩健的電池健康狀態預測模型的開發，可以釋放自主系統在複雜、遠程和可靠操作方面的潛力。神經網路、貝氏建模概念和集成學習策略的結合，形成了一個有價值的預測框架，以穩健、準確的方式結合不確定性。因此，本文介紹了一種貝氏集成學習方法來預測鋰離子電池的容量衰減。該方法準確預測了容量衰減，並量化了與電池設計和退化過程相關的不確定性。所提出的貝氏集成方法採用堆疊技術，將多個貝氏神經網路 (BNN) 作為基礎學習器進行整合，這些基礎學習器已經過資料多樣性的訓練。所提出的方法已經過 NASA Ames 預測卓越中心的電池老化資料集驗證。獲得的結果證明了所提出的概率融合方法相對於 (i) 單個 BNN 模型和 (ii) 基於不同 BNN 的經典堆疊策略，改進了準確性和穩健性。

##### **Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation**
2405.15282v1 by Abhinav Jain, Swarat Chaudhuri, Thomas Reps, Chris Jermaine

Parameter-Efficient Fine-Tuning (PEFT) has become the standard for
customising Foundation Models (FMs) to user-specific downstream tasks. However,
typical PEFT methods require storing multiple task-specific adapters, creating
scalability issues as these adapters must be housed and run at the FM server.
Traditional prompt tuning offers a potential solution by customising them
through task-specific input prefixes, but it under-performs compared to other
PEFT methods like LoRA. To address this gap, we propose Low-Rank Prompt
Adaptation (LOPA), a prompt-tuning-based approach that performs on par with
state-of-the-art PEFT methods and full fine-tuning while being more
parameter-efficient and not requiring a server-based adapter. LOPA generates
soft prompts by balancing between sharing task-specific information across
instances and customization for each instance. It uses a low-rank decomposition
of the soft-prompt component encoded for each instance to achieve parameter
efficiency. We provide a comprehensive evaluation on multiple natural language
understanding and code generation and understanding tasks across a wide range
of foundation models with varying sizes.

摘要：參數高效微調 (PEFT) 已成為將基礎模型 (FM) 客製化至使用者特定下游任務的標準。然而，典型的 PEFT 方法需要儲存多個任務特定適配器，由於這些適配器必須安置在 FM 伺服器並執行於伺服器上，因此會產生可擴充性問題。傳統提示微調透過任務特定輸入前綴來自訂提示，提供了一個潛在的解決方案，但它的表現不如 LoRA 等其他 PEFT 方法。為了解決這個差距，我們提出低秩提示適應 (LOPA)，這是一種基於提示微調的方法，其效能與最先進的 PEFT 方法和完整微調相當，同時更具參數效率，且不需要基於伺服器的適配器。LOPA 透過平衡在不同執行個體間分享任務特定資訊以及針對每個執行個體進行客製化，來產生軟提示。它使用針對每個執行個體編碼的軟提示組件的低秩分解，以達成參數效率。我們針對各種大小的基礎模型，提供多項自然語言理解、程式碼產生與理解任務的全面評估。

##### **DFGNN: Dual-frequency Graph Neural Network for Sign-aware Feedback**
2405.15280v1 by Yiqing Wu, Ruobing Xie, Zhao Zhang, Xu Zhang, Fuzhen Zhuang, Leyu Lin, Zhanhui Kang, Yongjun Xu

The graph-based recommendation has achieved great success in recent years.
However, most existing graph-based recommendations focus on capturing user
preference based on positive edges/feedback, while ignoring negative
edges/feedback (e.g., dislike, low rating) that widely exist in real-world
recommender systems. How to utilize negative feedback in graph-based
recommendations still remains underexplored. In this study, we first conducted
a comprehensive experimental analysis and found that (1) existing graph neural
networks are not well-suited for modeling negative feedback, which acts as a
high-frequency signal in a user-item graph. (2) The graph-based recommendation
suffers from the representation degeneration problem. Based on the two
observations, we propose a novel model that models positive and negative
feedback from a frequency filter perspective called Dual-frequency Graph Neural
Network for Sign-aware Recommendation (DFGNN). Specifically, in DFGNN, the
designed dual-frequency graph filter (DGF) captures both low-frequency and
high-frequency signals that contain positive and negative feedback.
Furthermore, the proposed signed graph regularization is applied to maintain
the user/item embedding uniform in the embedding space to alleviate the
representation degeneration problem. Additionally, we conduct extensive
experiments on real-world datasets and demonstrate the effectiveness of the
proposed model. Codes of our model will be released upon acceptance.

摘要：近年來，基於圖形的推薦已取得巨大的成功。
然而，現有的基於圖形的推薦大多集中於根據正邊緣/回饋來捕捉使用者偏好，而忽略了在現實世界的推薦系統中廣泛存在的負邊緣/回饋（例如不喜歡、低評分）。如何利用負回饋在基於圖形的推薦中仍然是一個尚未充分探索的領域。在本研究中，我們首先進行了全面的實驗分析，發現（1）現有的圖神經網路不適合於對負回饋進行建模，而負回饋在使用者-項目圖形中作為一個高頻率訊號。（2）基於圖形的推薦會遭受表示退化的問題。基於這兩個觀察結果，我們提出了一個新的模型，從頻率濾波器的角度對正回饋和負回饋進行建模，稱為雙頻率圖神經網路，用於具備感知符號的推薦（DFGNN）。具體來說，在 DFGNN 中，設計的雙頻率圖形濾波器 (DGF) 捕捉包含正回饋和負回饋的低頻率和高頻率訊號。此外，應用建議的帶符號圖形正則化來維護嵌入空間中的使用者/項目嵌入的一致性，以緩解表示退化的問題。此外，我們對真實世界的資料集進行了廣泛的實驗，並展示了所提出模型的有效性。我們的模型程式碼將在被接受後釋出。

##### **Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images**
2405.15264v1 by Saul Fuster, Farbod Khoraminia, Julio Silva-Rodríguez, Umay Kiraz, Geert J. L. H. van Leenders, Trygve Eftestøl, Valery Naranjo, Emiel A. M. Janssen, Tahlita C. M. Zuiverloon, Kjersti Engan

We present a pioneering investigation into the application of deep learning
techniques to analyze histopathological images for addressing the substantial
challenge of automated prognostic prediction. Prognostic prediction poses a
unique challenge as the ground truth labels are inherently weak, and the model
must anticipate future events that are not directly observable in the image. To
address this challenge, we propose a novel three-part framework comprising of a
convolutional network based tissue segmentation algorithm for region of
interest delineation, a contrastive learning module for feature extraction, and
a nested multiple instance learning classification module. Our study explores
the significance of various regions of interest within the histopathological
slides and exploits diverse learning scenarios. The pipeline is initially
validated on artificially generated data and a simpler diagnostic task.
Transitioning to prognostic prediction, tasks become more challenging.
Employing bladder cancer as use case, our best models yield an AUC of 0.721 and
0.678 for recurrence and treatment outcome prediction respectively.

摘要：我們提出了一項開創性的研究，探討將深度學習技術應用於分析組織病理學影像，以解決自動化預後預測的重大挑戰。預後預測是一個獨特的挑戰，因為真實標籤本質上很薄弱，而且模型必須預測影像中無法直接觀察到的未來事件。為了應對這個挑戰，我們提出了一個新穎的三部分架構，包括基於卷積網路的組織分割演算法，用於感興趣區域的描繪、對比學習模組用於特徵提取，以及巢狀多實例學習分類模組。我們的研究探討了組織病理學切片中各種感興趣區域的重要性，並利用了不同的學習場景。管道最初在人工生成資料和更簡單的診斷任務上得到驗證。在轉向預後預測時，任務變得更具挑戰性。以膀胱癌為使用案例，我們最好的模型分別產生了 0.721 和 0.678 的 AUC，用於復發和治療結果預測。

##### **Novel Kernel Models and Exact Representor Theory for Neural Networks Beyond the Over-Parameterized Regime**
2405.15254v1 by Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh

This paper presents two models of neural-networks and their training
applicable to neural networks of arbitrary width, depth and topology, assuming
only finite-energy neural activations; and a novel representor theory for
neural networks in terms of a matrix-valued kernel. The first model is exact
(un-approximated) and global, casting the neural network as an elements in a
reproducing kernel Banach space (RKBS); we use this model to provide tight
bounds on Rademacher complexity. The second model is exact and local, casting
the change in neural network function resulting from a bounded change in
weights and biases (ie. a training step) in reproducing kernel Hilbert space
(RKHS) in terms of a local-intrinsic neural kernel (LiNK). This local model
provides insight into model adaptation through tight bounds on Rademacher
complexity of network adaptation. We also prove that the neural tangent kernel
(NTK) is a first-order approximation of the LiNK kernel. Finally, and noting
that the LiNK does not provide a representor theory for technical reasons, we
present an exact novel representor theory for layer-wise neural network
training with unregularized gradient descent in terms of a local-extrinsic
neural kernel (LeNK). This representor theory gives insight into the role of
higher-order statistics in neural network training and the effect of kernel
evolution in neural-network kernel models. Throughout the paper (a) feedforward
ReLU networks and (b) residual networks (ResNet) are used as illustrative
examples.

摘要：<paragraph>本文提出了两种神经网络模型及其训练，适用于任意宽度、深度和拓扑的神经网络，仅假设有限能量神经激活；以及一个新颖的矩阵值核表示理论神经网络。第一个模型是精确的（未近似）和全局的，将神经网络作为再生核 Banach 空间（RKBS）中的元素；我们使用此模型为 Rademacher 复杂性提供严格的界限。第二个模型是精确且局部的，将由于权重和偏差的有限变化（即训练步骤）而导致的神经网络函数的变化，转化为再现核希尔伯特空间（RKHS）中的局部内在神经核（LiNK）。这个局部模型通过对网络适应的 Rademacher 复杂性的严格界限，提供了对模型适应的见解。我们还证明了神经切线核（NTK）是 LiNK 核的一阶近似。最后，注意到 LiNK 出于技术原因没有提供表示理论，我们提出了一个精确的新颖表示理论，用于在局部外在神经核（LeNK）方面进行层级神经网络训练，其中没有正则化梯度下降。这个表示理论深入了解了高阶统计在神经网络训练中的作用，以及核演化在神经网络核模型中的影响。在整篇论文中，（a）前馈 ReLU 网络和（b）残差网络（ResNet）被用作说明性示例。</paragraph>

##### **Coaching Copilot: Blended Form of an LLM-Powered Chatbot and a Human Coach to Effectively Support Self-Reflection for Leadership Growth**
2405.15250v1 by Riku Arakawa, Hiromu Yakura

Chatbots' role in fostering self-reflection is now widely recognized,
especially in inducing users' behavior change. While the benefits of 24/7
availability, scalability, and consistent responses have been demonstrated in
contexts such as healthcare and tutoring to help one form a new habit, their
utilization in coaching necessitating deeper introspective dialogue to induce
leadership growth remains unexplored. This paper explores the potential of such
a chatbot powered by recent Large Language Models (LLMs) in collaboration with
professional coaches in the field of executive coaching. Through a design
workshop with them and two weeks of user study involving ten coach-client
pairs, we explored the feasibility and nuances of integrating chatbots to
complement human coaches. Our findings highlight the benefits of chatbots'
ubiquity and reasoning capabilities enabled by LLMs while identifying their
limitations and design necessities for effective collaboration between human
coaches and chatbots. By doing so, this work contributes to the foundation for
augmenting one's self-reflective process with prevalent conversational agents
through the human-in-the-loop approach.

摘要：聊天機器人在促進自我反省中的作用現在廣受認可，
特別是在誘導使用者行為改變方面。雖然 24/7 可用性、可擴充性和一致回應的好處已在醫療保健和輔導等背景中得到證明，有助於形成一個新習慣，但它們在教練中利用需要更深入的內省對話以誘導領導力成長仍未被探索。本文探討了由最近的大語言模型 (LLM) 提供支援的此類聊天機器人在與高階教練領域的專業教練合作中的潛力。透過與他們進行設計工作坊和兩週的使用者研究，其中涉及十對教練和客戶，我們探討了整合聊天機器人以補充人類教練的可行性和細微差別。我們的研究結果突出了聊天機器人普遍性和推理能力的好處，這些能力是由 LLM 啟用的，同時也確定了它們的限制和設計必要性，以實現人類教練和聊天機器人之間的有效協作。透過這樣做，這項工作有助於建立基礎，以透過人類參與循環的方法，利用普遍的對話代理來擴充一個人的自我反省過程。

##### **DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception**
2405.15232v1 by Run Luo, Yunshui Li, Longze Chen, Wanwei He, Ting-En Lin, Ziqiang Liu, Lei Zhang, Zikai Song, Xiaobo Xia, Tongliang Liu, Min Yang, Binyuan Hui

The development of large language models (LLMs) has significantly advanced
the emergence of large multimodal models (LMMs). While LMMs have achieved
tremendous success by promoting the synergy between multimodal comprehension
and creation, they often face challenges when confronted with
out-of-distribution data. This is primarily due to their reliance on image
encoders trained to encode images into task-relevant features, which may lead
them to disregard irrelevant details. Delving into the modeling capabilities of
diffusion models for images naturally prompts the question: Can diffusion
models serve as the eyes of large language models for image perception? In this
paper, we propose DEEM, a simple and effective approach that utilizes the
generative feedback of diffusion models to align the semantic distributions of
the image encoder. This addresses the drawbacks of previous methods that solely
relied on image encoders like ViT, thereby enhancing the model's resilience
against out-of-distribution samples and reducing visual hallucinations.
Importantly, this is achieved without requiring additional training modules and
with fewer training parameters. We extensively evaluated DEEM on both our newly
constructed RobustVQA benchmark and another well-known benchmark, POPE, for
object hallucination. Compared to the state-of-the-art interleaved content
generation models, DEEM exhibits enhanced robustness and a superior capacity to
alleviate model hallucinations while utilizing fewer trainable parameters, less
pre-training data (10%), and a smaller base model size.

摘要：大型語言模型（LLM）的發展顯著促進了大型多模態模型（LMM）的出現。儘管 LMM 透過促進多模態理解和創作之間的協同效應而取得了巨大的成功，但它們在面對分布外數據時常常會遇到挑戰。這主要是因為它們依賴於圖像編碼器，而圖像編碼器經過訓練，可以將圖像編碼成與任務相關的特徵，這可能會導致它們忽略無關的細節。深入探討用於圖像的擴散模型的建模能力自然會引發一個問題：擴散模型可以作為大型語言模型的「眼睛」用於圖像感知嗎？在本文中，我們提出了 DEEM，這是一種簡單且有效的方法，它利用擴散模型的生成反饋來校準圖像編碼器的語義分布。這解決了以前僅依賴於 ViT 等圖像編碼器的缺點，從而增強了模型對分布外樣本的適應力並減少了視覺幻覺。重要的是，這是在不需要額外訓練模組和使用較少訓練參數的情況下實現的。我們在我們新構建的 RobustVQA 評量標準和另一個著名的評量標準 POPE 上對 DEEM 進行了廣泛的評估，以進行物件幻覺。與最先進的交錯內容生成模型相比，DEEM 表現出增強的適應力和優越的能力，可以在使用較少的可訓練參數、較少的預訓練數據（10%）和較小的基礎模型大小的情況下減輕模型幻覺。

##### **$i$REPO: $i$mplicit Reward Pairwise Difference based Empirical Preference Optimization**
2405.15230v1 by Long Tan Le, Han Shu, Tung-Anh Nguyen, Choong Seon Hong, Nguyen H. Tran

While astonishingly capable, large Language Models (LLM) can sometimes
produce outputs that deviate from human expectations. Such deviations
necessitate an alignment phase to prevent disseminating untruthful, toxic, or
biased information. Traditional alignment methods based on reinforcement
learning often struggle with the identified instability, whereas preference
optimization methods are limited by their overfitting to pre-collected
hard-label datasets. In this paper, we propose a novel LLM alignment framework
named $i$REPO, which utilizes implicit Reward pairwise difference regression
for Empirical Preference Optimization. Particularly, $i$REPO employs
self-generated datasets labelled by empirical human (or AI annotator)
preference to iteratively refine the aligned policy through a novel
regression-based loss function. Furthermore, we introduce an innovative
algorithm backed by theoretical guarantees for achieving optimal results under
ideal assumptions and providing a practical performance-gap result without such
assumptions. Experimental results with Phi-2 and Mistral-7B demonstrate that
$i$REPO effectively achieves self-alignment using soft-label, self-generated
responses and the logit of empirical AI annotators. Furthermore, our approach
surpasses preference optimization baselines in evaluations using the Language
Model Evaluation Harness and Multi-turn benchmarks.

摘要：儘管大型語言模型 (LLM) 具有驚人的能力，但有時仍會產生偏離人類預期的輸出。此類偏差需要校準階段才能防止散布不實、有害或有偏見的資訊。傳統的校準方法基於強化學習，通常難以處理已識別的不穩定性，而偏好最佳化方法則受限於過度擬合預先收集的硬標籤資料集。在本文中，我們提出一個名為 $i$REPO 的新型 LLM 校準架構，它利用隱式獎勵成對差異回歸進行經驗偏好最佳化。特別是，$i$REPO 使用由經驗人類（或 AI 標註員）偏好標籤的自生資料集，透過新型的基於回歸的損失函數反覆優化校準政策。此外，我們引入一種創新的演算法，並提供理論保證，可在理想假設下達成最佳結果，並在沒有此類假設的情況下提供實際的效能差距結果。使用 Phi-2 和 Mistral-7B 的實驗結果證明，$i$REPO 有效地使用軟標籤、自生回應和經驗 AI 標註員的 logit 達到自我校準。此外，我們的做法在使用語言模型評估工具和多輪基準進行評估時，超越了偏好最佳化基準。

##### **Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition**
2405.15216v1 by Zijin Gu, Tatiana Likhomanenko, He Bai, Erik McDermott, Ronan Collobert, Navdeep Jaitly

Language models (LMs) have long been used to improve results of automatic
speech recognition (ASR) systems, but they are unaware of the errors that ASR
systems make. Error correction models are designed to fix ASR errors, however,
they showed little improvement over traditional LMs mainly due to the lack of
supervised training data. In this paper, we present Denoising LM (DLM), which
is a $\textit{scaled}$ error correction model trained with vast amounts of
synthetic data, significantly exceeding prior attempts meanwhile achieving new
state-of-the-art ASR performance. We use text-to-speech (TTS) systems to
synthesize audio, which is fed into an ASR system to produce noisy hypotheses,
which are then paired with the original texts to train the DLM. DLM has several
$\textit{key ingredients}$: (i) up-scaled model and data; (ii) usage of
multi-speaker TTS systems; (iii) combination of multiple noise augmentation
strategies; and (iv) new decoding techniques. With a Transformer-CTC ASR, DLM
achieves 1.5% word error rate (WER) on $\textit{test-clean}$ and 3.3% WER on
$\textit{test-other}$ on Librispeech, which to our knowledge are the best
reported numbers in the setting where no external audio data are used and even
match self-supervised methods which use external audio data. Furthermore, a
single DLM is applicable to different ASRs, and greatly surpassing the
performance of conventional LM based beam-search rescoring. These results
indicate that properly investigated error correction models have the potential
to replace conventional LMs, holding the key to a new level of accuracy in ASR
systems.

摘要：<paragraph>語言模型 (LM) 長期以來一直用於改善自動語音辨識 (ASR) 系統的結果，但它們不知道 ASR 系統會產生哪些錯誤。錯誤修正模型旨在修正 ASR 錯誤，然而，它們僅比傳統 LM 稍有改善，主要是因為缺乏監督式訓練資料。在本文中，我們提出降噪 LM (DLM)，這是一個經過大量合成資料訓練的「縮放」錯誤修正模型，大幅超越先前的嘗試，同時達成新的 ASR 最佳表現。我們使用文字轉語音 (TTS) 系統合成音訊，將其輸入 ASR 系統產生有雜訊的假設，然後將其與原始文字配對來訓練 DLM。DLM 有幾個「關鍵要素」：(i) 擴充模型與資料；(ii) 使用多重發音者 TTS 系統；(iii) 結合多種雜訊擴充策略；以及 (iv) 新的解碼技術。透過 Transformer-CTC ASR，DLM 在 Librispeech 的「test-clean」上達成 1.5% 的字元錯誤率 (WER)，在「test-other」上達成 3.3% 的 WER，據我們所知，這些是在未使用外部音訊資料的設定中所報告的最佳數字，甚至與使用外部音訊資料的自監督方法相符。此外，單一 DLM 可用於不同的 ASR，並大幅超越基於傳統 LM 的 beam-search rescoring 的表現。這些結果顯示，經過適當研究的錯誤修正模型有潛力取代傳統 LM，掌握讓 ASR 系統達到新準確度等級的關鍵。</paragraph>

##### **Decoding at the Speed of Thought: Harnessing Parallel Decoding of Lexical Units for LLMs**
2405.15208v1 by Chenxi Sun, Hongzhi Zhang, Zijia Lin, Jingyuan Zhang, Fuzheng Zhang, Zhongyuan Wang, Bin Chen, Chengru Song, Di Zhang, Kun Gai, Deyi Xiong

Large language models have demonstrated exceptional capability in natural
language understanding and generation. However, their generation speed is
limited by the inherently sequential nature of their decoding process, posing
challenges for real-time applications. This paper introduces Lexical Unit
Decoding (LUD), a novel decoding methodology implemented in a data-driven
manner, accelerating the decoding process without sacrificing output quality.
The core of our approach is the observation that a pre-trained language model
can confidently predict multiple contiguous tokens, forming the basis for a
\textit{lexical unit}, in which these contiguous tokens could be decoded in
parallel. Extensive experiments validate that our method substantially reduces
decoding time while maintaining generation quality, i.e., 33\% speed up on
natural language generation with no quality loss, and 30\% speed up on code
generation with a negligible quality loss of 3\%. Distinctively, LUD requires
no auxiliary models and does not require changes to existing architectures. It
can also be integrated with other decoding acceleration methods, thus achieving
an even more pronounced inference efficiency boost. We posit that the
foundational principles of LUD could define a new decoding paradigm for future
language models, enhancing their applicability for a broader spectrum of
applications. All codes are be publicly available at
https://github.com/tjunlp-lab/Lexical-Unit-Decoding-LUD-. Keywords: Parallel
Decoding, Lexical Unit Decoding, Large Language Model

摘要：大型語言模型已在自然語言理解和生成方面展現出非凡的能力。然而，它們的生成速度受到其解碼過程中固有的順序性的限制，對實時應用程式構成挑戰。本文介紹了詞彙單元解碼 (LUD)，這是一種以資料驅動方式實作的新穎解碼方法，可加速解碼過程，同時不犧牲輸出品質。我們方法的核心是觀察到預先訓練的語言模型可以自信地預測多個連續的詞元，形成「詞彙單元」的基礎，其中這些連續的詞元可以並行解碼。廣泛的實驗驗證了我們的模型大幅減少了解碼時間，同時維持了生成品質，即自然語言生成速度提升了 33%，品質沒有損失，而程式碼生成速度提升了 30%，品質損失可以忽略不計，只有 3%。特別的是，LUD 不需要輔助模型，也不需要變更現有的架構。它也可以與其他解碼加速方法整合，進而大幅提升推論效率。我們認為，LUD 的基本原理可以為未來的語言模型定義一種新的解碼典範，擴大其在更廣泛應用程式中的適用性。所有程式碼都可以在 https://github.com/tjunlp-lab/Lexical-Unit-Decoding-LUD- 公開取得。關鍵字：並行解碼、詞彙單元解碼、大型語言模型

##### **Cross-Task Defense: Instruction-Tuning LLMs for Content Safety**
2405.15202v1 by Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, Yue Dong

Recent studies reveal that Large Language Models (LLMs) face challenges in
balancing safety with utility, particularly when processing long texts for NLP
tasks like summarization and translation. Despite defenses against malicious
short questions, the ability of LLMs to safely handle dangerous long content,
such as manuals teaching illicit activities, remains unclear. Our work aims to
develop robust defenses for LLMs in processing malicious documents alongside
benign NLP task queries. We introduce a defense dataset comprised of
safety-related examples and propose single-task and mixed-task losses for
instruction tuning. Our empirical results demonstrate that LLMs can
significantly enhance their capacity to safely manage dangerous content with
appropriate instruction tuning. Additionally, strengthening the defenses of
tasks most susceptible to misuse is effective in protecting LLMs against
processing harmful information. We also observe that trade-offs between utility
and safety exist in defense strategies, where Llama2, utilizing our proposed
approach, displays a significantly better balance compared to Llama1.

摘要：最近的研究表明，大型語言模型 (LLM) 在平衡安全性與實用性方面面臨挑戰，特別是在處理長篇文字以進行自然語言處理 (NLP) 任務（例如摘要和翻譯）時。儘管採取了防範惡意簡短問題的措施，但 LLM 安全處理危險長篇內容（例如教授非法活動的手冊）的能力仍不明確。我們的研究旨在為 LLM 處理惡意文件和良性 NLP 任務查詢時開發強大的防禦措施。我們引入了一個包含與安全性相關範例的防禦數據集，並提出單任務和混合任務損失用於指令調整。我們的實證結果表明，LLM 可以透過適當的指令調整，大幅提升其安全管理危險內容的能力。此外，加強最容易被誤用的任務的防禦措施，有助於保護 LLM 不處理有害資訊。我們還觀察到，在防禦策略中，實用性和安全性之間存在權衡，其中採用我們提議方法的 Llama2，與 Llama1 相比，展現出明顯更好的平衡。

##### **RAEE: A Training-Free Retrieval-Augmented Early Exiting Framework for Efficient Inference**
2405.15198v1 by Lianming Huang, Shangyu Wu, Yufei Cui, Ying Xiong, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue

Deploying large language model inference remains challenging due to their
high computational overhead. Early exiting accelerates model inference by
adaptively reducing the number of inference layers. Existing methods require
training internal classifiers to determine whether to exit at each intermediate
layer. However, such classifier-based early exiting frameworks require
significant effort to design and train the classifiers. To address these
limitations, this paper proposes RAEE, a training-free Retrieval-Augmented
Early Exiting framework for efficient inference. First, this paper demonstrates
that the early exiting problem can be modeled as a distribution prediction
problem, where the distribution is approximated using similar data's existing
information. Next, the paper details the process of collecting existing
information to build the retrieval database. Finally, based on the pre-built
retrieval database, RAEE leverages the retrieved similar data's exiting
information to guide the backbone model to exit at the layer, which is
predicted by the approximated distribution. Experimental results demonstrate
that the proposed RAEE can significantly accelerate inference. RAEE also
achieves state-of-the-art zero-shot performance on 8 classification tasks.

摘要：由於大型語言模型推論的運算負擔過高，部署大型語言模型推論仍然具有挑戰性。早期退出透過自適應減少推論層數，加速模型推論。現有方法需要訓練內部分類器來決定是否在每個中間層退出。然而，這種基於分類器的早期退出架構需要大量的精力來設計和訓練分類器。為了解決這些限制，本文提出 RAEE，一種免訓練的檢索增強早期退出架構，用於高效推論。首先，本文證明早期退出問題可以建模為一個分佈預測問題，其中使用類似資料的現有資訊來近似分佈。接著，本文詳細說明收集現有資訊以建立檢索資料庫的過程。最後，RAEE 在預先建立的檢索資料庫的基礎上，利用檢索到的類似資料的退出資訊來引導主幹模型退出在層中，該層由近似分佈預測。實驗結果證明，所提出的 RAEE 可以顯著加速推論。RAEE 也在 8 個分類任務中達成最先進的零次學習效能。

##### **Efficient Reinforcement Learning via Large Language Model-based Search**
2405.15194v1 by Siddhant Bhambri, Amrita Bhattacharjee, Huan Liu, Subbarao Kambhampati

Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward
domains, and the problem is pronounced if there are stochastic transitions. To
improve the sample efficiency, reward shaping is a well-studied approach to
introduce intrinsic rewards that can help the RL agent converge to an optimal
policy faster. However, designing a useful reward shaping function specific to
each problem is challenging, even for domain experts. They would either have to
rely on task-specific domain knowledge or provide an expert demonstration
independently for each task. Given, that Large Language Models (LLMs) have
rapidly gained prominence across a magnitude of natural language tasks, we aim
to answer the following question: Can we leverage LLMs to construct a reward
shaping function that can boost the sample efficiency of an RL agent? In this
work, we aim to leverage off-the-shelf LLMs to generate a guide policy by
solving a simpler deterministic abstraction of the original problem that can
then be used to construct the reward shaping function for the downstream RL
agent. Given the ineffectiveness of directly prompting LLMs, we propose MEDIC:
a framework that augments LLMs with a Model-based feEDback critIC, which
verifies LLM-generated outputs, to generate a possibly sub-optimal but valid
plan for the abstract problem. Our experiments across domains from the BabyAI
environment suite show 1) the effectiveness of augmenting LLMs with MEDIC, 2) a
significant improvement in the sample complexity of PPO and A2C-based RL agents
when guided by our LLM-generated plan, and finally, 3) pave the direction for
further explorations of how these models can be used to augment existing RL
pipelines.

摘要：<paragraph>強化學習 (RL) 在稀疏獎勵領域中會遇到樣本效率低下的問題，而如果存在隨機轉換，則問題會更加嚴重。為了提高樣本效率，獎勵成形是一種經過充分研究的方法，用於引入內在獎勵，可以幫助 RL 代理更快地收斂到最佳策略。然而，針對每個問題設計一個有用的獎勵成形函數是一項挑戰，即使對於領域專家而言也是如此。他們必須依賴特定於任務的領域知識，或者為每個任務獨立提供專家示範。鑑於大型語言模型 (LLM) 已迅速在大量自然語言任務中獲得突出地位，我們旨在回答以下問題：我們能利用 LLM 來建構一個獎勵成形函數，從而提升 RL 代理的樣本效率嗎？在這項工作中，我們旨在利用現成的 LLM，透過解決原始問題的一個更簡單的確定性抽象來產生一個引導策略，然後可以用它來為下游 RL 代理建構獎勵成形函數。鑑於直接提示 LLM 的無效性，我們提出了 MEDIC：一個使用基於模型的回饋批評器來擴充 LLM 的框架，它會驗證 LLM 產生的輸出，以產生一個可能次於最佳但有效的抽象問題計畫。我們在 BabyAI 環境套件中跨領域進行的實驗顯示 1) 使用 MEDIC 擴充 LLM 的有效性，2) 在由我們的 LLM 產生的計畫引導下，基於 PPO 和 A2C 的 RL 代理的樣本複雜度有顯著改善，最後，3) 為進一步探索如何使用這些模型來擴充現有的 RL 管線鋪平了道路。</paragraph>

##### **SOAP: Enhancing Efficiency of Generated Code via Self-Optimization**
2405.15189v1 by Dong Huang, Jianbo Dai, Han Weng, Puzhen Wu, Yuhao Qing, Jie M. Zhang, Heming Cui, Zhijiang Guo

Large language models (LLMs) have shown remarkable progress in code
generation, but their generated code often suffers from inefficiency, resulting
in longer execution times and higher memory consumption. To address this issue,
we propose Self Optimization based on OverheAd Profile (SOAP), a
self-optimization framework that utilizes execution overhead profiles to
improve the efficiency of LLM-generated code. SOAP first generates code using
an LLM, then executes it locally to capture execution time and memory usage
profiles. These profiles are fed back to the LLM, which then revises the code
to reduce overhead. To evaluate the effectiveness of SOAP, we conduct extensive
experiments on the EffiBench, HumanEval, and MBPP with 16 open-source and 6
closed-source models. Our evaluation results demonstrate that through iterative
self-optimization, SOAP significantly enhances the efficiency of LLM-generated
code. For example, the execution time (ET) of StarCoder2-15B for the EffiBench
decreases from 0.93 (s) to 0.12 (s) which reduces 87.1% execution time
requirement compared with the initial code. The total memory usage (TMU) of
StarCoder2-15B also decreases from 22.02 (Mb*s) to 2.03 (Mb*s), which decreases
90.8% total memory consumption during the execution process. The source code of
SOAP was released in https://github.com/huangd1999/SOAP.

摘要：大型語言模型 (LLM) 在程式碼生成方面展現了顯著的進展，但其生成的程式碼常常效率不彰，導致執行時間較長且記憶體消耗較高。為了解決這個問題，我們提出了基於開銷剖析的自最佳化 (SOAP)，這是一個自最佳化架構，利用執行開銷剖析來改善 LLM 生成的程式碼效率。SOAP 首先使用 LLM 產生程式碼，然後在本地執行它以擷取執行時間和記憶體使用量剖析。這些剖析會回饋給 LLM，然後 LLM 會修改程式碼以減少開銷。為了評估 SOAP 的有效性，我們在 EffiBench、HumanEval 和 MBPP 上針對 16 個開源模型和 6 個閉源模型進行了廣泛的實驗。我們的評估結果表明，透過反覆的自最佳化，SOAP 大幅提升了 LLM 生成的程式碼效率。例如，EffiBench 中 StarCoder2-15B 的執行時間 (ET) 從 0.93 (秒) 減少到 0.12 (秒)，與初始程式碼相比，減少了 87.1% 的執行時間需求。StarCoder2-15B 的總記憶體使用量 (TMU) 也從 22.02 (Mb*s) 減少到 2.03 (Mb*s)，在執行過程中減少了 90.8% 的總記憶體消耗。SOAP 的原始程式碼已發布在 https://github.com/huangd1999/SOAP。

##### **An Evaluation of Estimative Uncertainty in Large Language Models**
2405.15185v1 by Zhisheng Tang, Ke Shen, Mayank Kejriwal

Words of estimative probability (WEPs), such as ''maybe'' or ''probably not''
are ubiquitous in natural language for communicating estimative uncertainty,
compared with direct statements involving numerical probability. Human
estimative uncertainty, and its calibration with numerical estimates, has long
been an area of study -- including by intelligence agencies like the CIA. This
study compares estimative uncertainty in commonly used large language models
(LLMs) like GPT-4 and ERNIE-4 to that of humans, and to each other. Here we
show that LLMs like GPT-3.5 and GPT-4 align with human estimates for some, but
not all, WEPs presented in English. Divergence is also observed when the LLM is
presented with gendered roles and Chinese contexts. Further study shows that an
advanced LLM like GPT-4 can consistently map between statistical and estimative
uncertainty, but a significant performance gap remains. The results contribute
to a growing body of research on human-LLM alignment.

摘要：估計機率詞 (WEP)，例如「可能」或「可能不會」，在自然語言中用於傳達估計的不確定性，與涉及數值機率的直接陳述相比。人類的估計不確定性及其與數值估計的校準，長期以來一直是研究領域，包括中央情報局等情報機構。本研究將 GPT-4 和 ERNIE-4 等常用大型語言模型 (LLM) 中的估計不確定性與人類的不確定性以及彼此之間的不確定性進行比較。在這裡，我們展示了像 GPT-3.5 和 GPT-4 這樣的 LLM 在某些方面與人類估計一致，但並非所有以英語呈現的 WEP 都一致。當 LLM 呈現性別角色和中文語境時，也會觀察到差異。進一步的研究表明，像 GPT-4 這樣的先進 LLM 可以持續對應統計和估計不確定性，但仍存在顯著的效能差距。這些結果有助於人類 LLM 對齊研究的發展。

##### **RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation**
2405.15182v1 by Peihua Mai, Ran Yan, Yan Pang

Federated learning (FL) allows multiple devices to train a model
collaboratively without sharing their data. Despite its benefits, FL is
vulnerable to privacy leakage and poisoning attacks. To address the privacy
concern, secure aggregation (SecAgg) is often used to obtain the aggregation of
gradients on sever without inspecting individual user updates. Unfortunately,
existing defense strategies against poisoning attacks rely on the analysis of
local updates in plaintext, making them incompatible with SecAgg. To reconcile
the conflicts, we propose a robust federated learning framework against
poisoning attacks (RFLPA) based on SecAgg protocol. Our framework computes the
cosine similarity between local updates and server updates to conduct robust
aggregation. Furthermore, we leverage verifiable packed Shamir secret sharing
to achieve reduced communication cost of $O(M+N)$ per user, and design a novel
dot-product aggregation algorithm to resolve the issue of increased information
leakage. Our experimental results show that RFLPA significantly reduces
communication and computation overhead by over $75\%$ compared to the
state-of-the-art method, BREA, while maintaining competitive accuracy.

摘要：聯邦學習 (FL) 允許多個裝置共同訓練模型，而無需分享其資料。儘管有其優點，但 FL 容易受到隱私外洩和中毒攻擊。為了解決隱私問題，安全聚合 (SecAgg) 通常用於在伺服器上取得梯度的聚合，而無需檢查個別使用者的更新。不幸的是，現有的防禦中毒攻擊策略依賴於明文分析本地更新，這使得它們與 SecAgg 不相容。為了調和衝突，我們提出了一個基於 SecAgg 協定的防禦中毒攻擊的強健聯邦學習架構 (RFLPA)。我們的架構計算本地更新和伺服器更新之間的餘弦相似度，以執行強健聚合。此外，我們利用可驗證的打包 Shamir 秘密共享，以實現每個使用者的 $O(M+N)$ 降低通訊成本，並設計一種新穎的點積聚合演算法，以解決資訊外洩增加的問題。我們的實驗結果顯示，與最先進的方法 BREA 相比，RFLPA 將通訊和運算開銷大幅降低超過 $75\%$，同時維持競爭力的準確度。

##### **VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks**
2405.15179v1 by Yang Li, Shaobo Han, Shihao Ji

As the adoption of large language models increases and the need for per-user
or per-task model customization grows, the parameter-efficient fine-tuning
(PEFT) methods, such as low-rank adaptation (LoRA) and its variants, incur
substantial storage and transmission costs. To further reduce stored
parameters, we introduce a "divide-and-share" paradigm that breaks the barriers
of low-rank decomposition across matrix dimensions, modules and layers by
sharing parameters globally via a \textit{vector bank}. As an instantiation of
the paradigm to LoRA, our proposed VB-LoRA composites \textit{all} the low-rank
matrices of LoRA from a shared \textit{vector bank} with a differentiable
top-$k$ admixture module. VB-LoRA achieves extreme parameter efficiency while
maintaining comparable or better performance compared to state-of-the-art PEFT
methods. Extensive experiments demonstrate the effectiveness of VB-LoRA on
natural language understanding, natural language generation, and instruction
tuning tasks. When fine-tuning the Llama2-13B model, VB-LoRA only uses 0.4\% of
LoRA's stored parameters yet attaining superior results. Our source code is
available at \url{https://github.com/leo-yangli/VB-LoRA}.

摘要：隨著大型語言模型的採用增加，以及對每個使用者或每個任務模型自訂化的需求增加，參數有效微調 (PEFT) 方法（例如低秩適應 (LoRA) 及其變體）會產生大量的儲存和傳輸成本。為了進一步減少儲存的參數，我們引入了「分割和共享」範例，它透過共享參數打破了跨矩陣維度、模組和層的低秩分解障礙，並透過\textit{向量庫}在全球範圍內共享參數。作為 LoRA 範例的實例，我們提出的 VB-LoRA 複合了 LoRA 的\textit{所有}低秩矩陣，這些矩陣來自於一個共享的\textit{向量庫}，並有一個可微分的頂層-$k$混合模組。VB-LoRA 達到了極端的參數效率，同時與最先進的 PEFT 方法相比，維持了相當或更好的效能。廣泛的實驗證明了 VB-LoRA 在自然語言理解、自然語言生成和指令調整任務上的有效性。在微調 Llama2-13B 模型時，VB-LoRA 只使用了 LoRA 儲存參數的 0.4%，卻達到了更好的結果。我們的原始碼可以在 \url{https://github.com/leo-yangli/VB-LoRA} 取得。

##### **Diffusion Actor-Critic with Entropy Regulator**
2405.15177v1 by Yinuo Wang, Likun Wang, Yuxuan Jiang, Wenjun Zou, Tong Liu, Xujie Song, Wenxuan Wang, Liming Xiao, Jiang Wu, Jingliang Duan, Shengbo Eben Li

Reinforcement learning (RL) has proven highly effective in addressing complex
decision-making and control tasks. However, in most traditional RL algorithms,
the policy is typically parameterized as a diagonal Gaussian distribution with
learned mean and variance, which constrains their capability to acquire complex
policies. In response to this problem, we propose an online RL algorithm termed
diffusion actor-critic with entropy regulator (DACER). This algorithm
conceptualizes the reverse process of the diffusion model as a novel policy
function and leverages the capability of the diffusion model to fit multimodal
distributions, thereby enhancing the representational capacity of the policy.
Since the distribution of the diffusion policy lacks an analytical expression,
its entropy cannot be determined analytically. To mitigate this, we propose a
method to estimate the entropy of the diffusion policy utilizing Gaussian
mixture model. Building on the estimated entropy, we can learn a parameter
$\alpha$ that modulates the degree of exploration and exploitation. Parameter
$\alpha$ will be employed to adaptively regulate the variance of the added
noise, which is applied to the action output by the diffusion model.
Experimental trials on MuJoCo benchmarks and a multimodal task demonstrate that
the DACER algorithm achieves state-of-the-art (SOTA) performance in most MuJoCo
control tasks while exhibiting a stronger representational capacity of the
diffusion policy.

摘要：強化學習 (RL) 已被證明在解決複雜決策制定和控制任務方面非常有效。然而，在大多數傳統的 RL 演算法中，策略通常被參數化為對角高斯分佈，具有學習到的平均值和變異數，這限制了它們獲取複雜策略的能力。為了應對這個問題，我們提出了一種名為擴散動作-評論家與熵調節器 (DACER) 的線上 RL 演算法。此演算法將擴散模型的反向過程概念化為一種新穎的策略函數，並利用擴散模型擬合多模態分佈的能力，從而增強策略的表示能力。由於擴散策略的分佈缺乏解析表達式，因此無法解析地確定其熵。為了減輕這個問題，我們提出了一種使用高斯混合模型估計擴散策略熵的方法。建立在估計的熵之上，我們可以學習一個參數 $\alpha$，它調節探索和利用的程度。參數 $\alpha$ 將被用於自適應地調節擴散模型對動作輸出的加性雜訊的變異數。在 MuJoCo 基準和多模態任務上的實驗試驗表明，DACER 演算法在大多數 MuJoCo 控制任務中實現了最先進 (SOTA) 的效能，同時展現出擴散策略更強的表示能力。

##### **A Solution-based LLM API-using Methodology for Academic Information Seeking**
2405.15165v1 by Yuanchun Wang, Jifan Yu, Zijun Yao, Jing Zhang, Yuyang Xie, Shangqing Tu, Yiyang Fu, Youhe Feng, Jinkai Zhang, Jingyao Zhang, Bowen Huang, Yuanyao Li, Huihui Yuan, Lei Hou, Juanzi Li, Jie Tang

Applying large language models (LLMs) for academic API usage shows promise in
reducing researchers' academic information seeking efforts. However, current
LLM API-using methods struggle with complex API coupling commonly encountered
in academic queries. To address this, we introduce SoAy, a solution-based LLM
API-using methodology for academic information seeking. It uses code with a
solution as the reasoning method, where a solution is a pre-constructed API
calling sequence. The addition of the solution reduces the difficulty for the
model to understand the complex relationships between APIs. Code improves the
efficiency of reasoning.
  To evaluate SoAy, we introduce SoAyBench, an evaluation benchmark accompanied
by SoAyEval, built upon a cloned environment of APIs from AMiner. Experimental
results demonstrate a 34.58-75.99\% performance improvement compared to
state-of-the-art LLM API-based baselines. All datasets, codes, tuned models,
and deployed online services are publicly accessible at
https://github.com/RUCKBReasoning/SoAy.

摘要：將大型語言模型 (LLM) 應用於學術 API 使用，顯示出有助於降低研究人員在學術資訊尋找上的努力。然而，目前使用 LLM API 的方法，在學術查詢中常見的複雜 API 耦合上仍有困難。為了解決這個問題，我們引入了 SoAy，一種基於解決方案的 LLM API 使用方法，用於學術資訊尋找。它使用具有解決方案的程式碼作為推理方法，其中解決方案是一個預先建構的 API 呼叫順序。加入解決方案後，模型理解 API 之間複雜關係的難度降低了。程式碼改善了推理效率。
為了評估 SoAy，我們引入了 SoAyBench，一個評估基準，並附帶了 SoAyEval，建立在 AMiner 的 API 克隆環境之上。實驗結果顯示，與最先進的基於 LLM API 的基線相比，效能提升了 34.58-75.99%。所有資料集、程式碼、調整過的模型和部署的線上服務都可以在 https://github.com/RUCKBReasoning/SoAy 公開取得。

##### **From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks**
2405.15164v1 by Jacob Russin, Sam Whitman McGrath, Danielle J. Williams, Lotem Elber-Dorozko

Compositionality has long been considered a key explanatory property
underlying human intelligence: arbitrary concepts can be composed into novel
complex combinations, permitting the acquisition of an open ended, potentially
infinite expressive capacity from finite learning experiences. Influential
arguments have held that neural networks fail to explain this aspect of
behavior, leading many to dismiss them as viable models of human cognition.
Over the last decade, however, modern deep neural networks (DNNs), which share
the same fundamental design principles as their predecessors, have come to
dominate artificial intelligence, exhibiting the most advanced cognitive
behaviors ever demonstrated in machines. In particular, large language models
(LLMs), DNNs trained to predict the next word on a large corpus of text, have
proven capable of sophisticated behaviors such as writing syntactically complex
sentences without grammatical errors, producing cogent chains of reasoning, and
even writing original computer programs -- all behaviors thought to require
compositional processing. In this chapter, we survey recent empirical work from
machine learning for a broad audience in philosophy, cognitive science, and
neuroscience, situating recent breakthroughs within the broader context of
philosophical arguments about compositionality. In particular, our review
emphasizes two approaches to endowing neural networks with compositional
generalization capabilities: (1) architectural inductive biases, and (2)
metalearning, or learning to learn. We also present findings suggesting that
LLM pretraining can be understood as a kind of metalearning, and can thereby
equip DNNs with compositional generalization abilities in a similar way. We
conclude by discussing the implications that these findings may have for the
study of compositionality in human cognition and by suggesting avenues for
future research.

摘要：組合性長期以來被認為是人類智能背後的一項關鍵解釋性特質：任意的概念可以組合成新穎的複雜組合，允許從有限的學習經驗中獲得開放式、潛在無限的表達能力。有影響力的論點認為，神經網路無法解釋行為的這個面向，導致許多人將它們視為人類認知的可行模型。然而，在過去十年中，現代深度神經網路 (DNN) 與其前身共享相同的基礎設計原理，已開始主導人工智慧，展現出機器有史以來最先進的認知行為。特別是，大型語言模型 (LLM) 是在大量文本語料庫中訓練來預測下一個單字的 DNN，已被證明具備複雜的行為，例如撰寫語法上沒有錯誤的句法複雜句子、產生有力的推理鏈，甚至撰寫原始電腦程式，這些行為都被認為需要組合處理。在本章中，我們針對哲學、認知科學和神經科學的廣泛受眾調查了機器學習的最新實證研究，將最近的突破置於關於組合性的哲學論點的更廣泛背景中。特別是，我們的評論強調了兩種賦予神經網路組合泛化能力的方法：(1) 架構歸納偏差，以及 (2) 元學習，或學習學習。我們也提出研究結果，表明 LLM 預訓練可以理解為一種元學習，從而可以用類似的方式為 DNN 提供組合泛化能力。我們最後討論這些發現可能對人類認知中組合性的研究有何影響，並建議未來的研究途徑。

##### **Online Prompt Pricing based on Combinatorial Multi-Armed Bandit and Hierarchical Stackelberg Game**
2405.15154v1 by Meiling Li, Hongrun Ren, Haixu Xiong, Zhenxing Qian, Xinpeng Zhang

Generation models have shown promising performance in various tasks, making
trading around machine learning models possible. In this paper, we aim at a
novel prompt trading scenario, prompt bundle trading (PBT) system, and propose
an online pricing mechanism. Based on the combinatorial multi-armed bandit
(CMAB) and three-stage hierarchical Stackelburg (HS) game, our pricing
mechanism considers the profits of the consumer, platform, and seller,
simultaneously achieving the profit satisfaction of these three participants.
We break down the pricing issue into two steps, namely unknown category
selection and incentive strategy optimization. The former step is to select a
set of categories with the highest qualities, and the latter is to derive the
optimal strategy for each participant based on the chosen categories. Unlike
the existing fixed pricing mode, the PBT pricing mechanism we propose is more
flexible and diverse, which is more in accord with the transaction needs of
real-world scenarios. We test our method on a simulated text-to-image dataset.
The experimental results demonstrate the effectiveness of our algorithm, which
provides a feasible price-setting standard for the prompt marketplaces.

摘要：生成模型在各種任務中展現出有前景的效能，讓機器學習模型之間的交易成為可能。在本文中，我們針對一種新穎的提示交易場景、提示組合交易 (PBT) 系統，並提出一個線上定價機制。我們的定價機制基於組合多重拉霸機 (CMAB) 和三階段階層式 Stackelburg (HS) 博弈，同時考量消費者、平台和賣方的利潤，同時達成這三方參與者的利潤滿意度。我們將定價問題分解為兩個步驟，即未知類別選擇和誘因策略最佳化。前一步驟是選擇一組品質最高的類別，後一步驟是根據所選類別為每個參與者推導最佳策略。與現有的固定定價模式不同，我們提出的 PBT 定價機制更靈活、更多樣化，更符合現實世界場景的交易需求。我們在模擬的文字轉圖像資料集上測試我們的模型。實驗結果證明了我們演算法的有效性，為提示市場提供了一個可行的價格設定標準。

##### **Machine Unlearning in Large Language Models**
2405.15152v1 by Saaketh Koundinya Gundavarapu, Shreya Agarwal, Arushi Arora, Chandana Thimmalapura Jagadeeshaiah

Machine unlearning, a novel area within artificial intelligence, focuses on
addressing the challenge of selectively forgetting or reducing undesirable
knowledge or behaviors in machine learning models, particularly in the context
of large language models (LLMs). This paper introduces a methodology to align
LLMs, such as Open Pre-trained Transformer Language Models, with ethical,
privacy, and safety standards by leveraging the gradient ascent algorithm for
knowledge unlearning. Our approach aims to selectively erase or modify learned
information in LLMs, targeting harmful responses and copyrighted content. This
paper presents a dual-pronged approach to enhance the ethical and safe behavior
of large language models (LLMs) by addressing the issues of harmful responses
and copyrighted content. To mitigate harmful responses, we applied gradient
ascent on the PKU dataset, achieving a 75\% reduction in harmful responses for
Open Pre-trained Transformer Language Models (OPT1.3b and OPT2.7b)
\citet{zhang2022opt} while retaining previous knowledge using the TruthfulQA
dataset \citet{DBLP:journals/corr/abs-2109-07958}. For handling copyrighted
content, we constructed a custom dataset based on the Lord of the Rings corpus
and aligned LLMs (OPT1.3b and OPT2.7b) \citet{zhang2022opt} through LoRA:
Low-Rank Adaptation of Large Language Models
\citet{DBLP:journals/corr/abs-2106-09685} finetuning. Subsequently, we employed
gradient ascent to unlearn the Lord of the Rings content, resulting in a
remarkable reduction in the presence of copyrighted material. To maintain a
diverse knowledge base, we utilized the Book Corpus dataset. Additionally, we
propose a new evaluation technique for assessing the effectiveness of harmful
unlearning.

摘要：機器去學習，人工智慧的一個新領域，專注於處理選擇性遺忘或減少機器學習模型中不良的知識或行為的挑戰，尤其是在大型語言模型 (LLM) 的情況下。本文介紹了一種方法，可以通過利用梯度上升演算法進行知識去學習，將 LLM（例如 Open Pre-trained Transformer Language Models）與道德、隱私和安全標準保持一致。我們的方法旨在選擇性地刪除或修改 LLM 中學習到的資訊，鎖定有害的回應和受版權保護的內容。本文提出了一種雙管齊下的方法，通過解決有害回應和受版權保護的內容問題，來增強大型語言模型 (LLM) 的道德和安全行為。為了減輕有害的回應，我們在 PKU 資料集上應用梯度上升，使 Open Pre-trained Transformer Language Models (OPT1.3b 和 OPT2.7b) 的有害回應減少了 75%，同時使用 TruthfulQA 資料集保留了先前的知識\citet{zhang2022opt}。對於處理受版權保護的內容，我們根據魔戒語料庫構建了一個自訂資料集，並透過 LoRA：大型語言模型的低秩適應調整 LLM（OPT1.3b 和 OPT2.7b）\citet{DBLP:journals/corr/abs-2106-09685}。隨後，我們採用梯度上升來取消學習魔戒的內容，從而顯著減少了受版權保護的材料的存在。為了維護多元化的知識庫，我們利用了 Book Corpus 資料集。此外，我們提出了一種新的評估技術，用於評估有害去學習的有效性。

##### **CulturePark: Boosting Cross-cultural Understanding in Large Language Models**
2405.15145v1 by Cheng Li, Damien Teney, Linyi Yang, Qingsong Wen, Xing Xie, Jindong Wang

Cultural bias is pervasive in many large language models (LLMs), largely due
to the deficiency of data representative of different cultures. Typically,
cultural datasets and benchmarks are constructed either by extracting subsets
of existing datasets or by aggregating from platforms such as Wikipedia and
social media. However, these approaches are highly dependent on real-world data
and human annotations, making them costly and difficult to scale. Inspired by
cognitive theories on social communication, this paper introduces CulturePark,
an LLM-powered multi-agent communication framework for cultural data
collection. CulturePark simulates cross-cultural human communication with
LLM-based agents playing roles in different cultures. It generates high-quality
cross-cultural dialogues encapsulating human beliefs, norms, and customs. Using
CulturePark, we generated 41,000 cultural samples to fine-tune eight
culture-specific LLMs. We evaluated these models across three downstream tasks:
content moderation, cultural alignment, and cultural education. Results show
that for content moderation, our GPT-3.5-based models either match or
outperform GPT-4 on datasets. Regarding cultural alignment, our models surpass
GPT-4 on Hofstede's VSM 13 framework. Furthermore, for cultural education of
human participants, our models demonstrate superior outcomes in both learning
efficacy and user experience compared to GPT-4. CulturePark proves an important
step in addressing cultural bias and advancing the democratization of AI,
highlighting the critical role of culturally inclusive data in model training.

摘要：<paragraph>文化偏見在許多大型語言模型 (LLM) 中普遍存在，這主要是由於代表不同文化的資料不足所致。一般而言，文化資料集和基準是透過萃取現有資料集的子集或從維基百科和社群媒體等平台彙整而來。然而，這些方法高度依賴真實世界的資料和人工標註，這使得它們昂貴且難以擴充。本論文受到社會溝通認知理論的啟發，介紹了 CulturePark，一個由 LLM 驅動的多代理溝通架構，用於文化資料收集。CulturePark 模擬了跨文化的溝通，其中基於 LLM 的代理扮演不同文化的角色。它產生了高品質的跨文化對話，涵蓋了人類的信念、規範和習俗。我們使用 CulturePark 生成了 41,000 個文化範例，以微調八個特定文化的 LLM。我們針對這三個下游任務評估了這些模型：內容審核、文化對齊和文化教育。結果顯示，對於內容審核，我們基於 GPT-3.5 的模型在資料集上與 GPT-4 相匹配或表現優於 GPT-4。關於文化對齊，我們的模型在霍夫斯泰德的 VSM 13 架構上超越了 GPT-4。此外，對於人類參與者的文化教育，我們的模型在學習成效和使用者體驗方面都展現出比 GPT-4 更優異的成果。CulturePark 證明了在解決文化偏見和促進 AI 民主化方面邁出了重要一步，突顯了文化包容性資料在模型訓練中扮演的關鍵角色。</paragraph>

##### **Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models**
2405.15143v1 by Cong Lu, Shengran Hu, Jeff Clune

Go-Explore is a powerful family of algorithms designed to solve
hard-exploration problems, built on the principle of archiving discovered
states, and iteratively returning to and exploring from the most promising
states. This approach has led to superhuman performance across a wide variety
of challenging problems including Atari games and robotic control, but requires
manually designing heuristics to guide exploration, which is time-consuming and
infeasible in general. To resolve this, we propose Intelligent Go-Explore (IGE)
which greatly extends the scope of the original Go-Explore by replacing these
heuristics with the intelligence and internalized human notions of
interestingness captured by giant foundation models (FMs). This provides IGE
with a human-like ability to instinctively identify how interesting or
promising any new state is (e.g. discovering new objects, locations, or
behaviors), even in complex environments where heuristics are hard to define.
Moreover, IGE offers the exciting and previously impossible opportunity to
recognize and capitalize on serendipitous discoveries that cannot be predicted
ahead of time. We evaluate IGE on a range of language-based tasks that require
search and exploration. In Game of 24, a multistep mathematical reasoning
problem, IGE reaches 100% success rate 70.8% faster than the best classic graph
search baseline. Next, in BabyAI-Text, a challenging partially observable
gridworld, IGE exceeds the previous SOTA with orders of magnitude fewer online
samples. Finally, in TextWorld, we show the unique ability of IGE to succeed in
settings requiring long-horizon exploration where prior SOTA FM agents like
Reflexion completely fail. Overall, IGE combines the tremendous strengths of
FMs and the powerful Go-Explore algorithm, opening up a new frontier of
research into creating more generally capable agents with impressive
exploration capabilities.

摘要：Go-Explore 是一系列強大的演算法，旨在解決困難的探索問題，其建立在封存已發現狀態的原則上，並反覆返回並從最有希望的狀態進行探索。這種方法已在各種具有挑戰性的問題中帶來了超人的表現，包括 Atari 遊戲和機器人控制，但需要人工設計啟發法來指導探索，這既耗時又通常不可行。為了解決這個問題，我們提出了 Intelligent Go-Explore (IGE)，它透過用巨型基礎模型 (FM) 捕捉到的智慧和內化的人類有趣性概念取代這些啟發法，進而大幅擴展了原始 Go-Explore 的範圍。這賦予 IGE 類似人類的能力，可以本能地識別任何新狀態有多有趣或有希望（例如發現新物件、位置或行為），即使在難以定義啟發法的複雜環境中也是如此。此外，IGE 提供了一個令人興奮且前所未有的機會，可以認識並利用無法預先預測的意外發現。我們在需要搜尋和探索的一系列基於語言的任務上評估 IGE。在 24 點遊戲中，IGE 是一個多步驟的數學推理問題，其達到 100% 的成功率，比最佳經典圖形搜尋基線快 70.8%。接下來，在 BabyAI-Text 中，一個具有挑戰性的部分可觀察網格世界，IGE 超越了先前的 SOTA，線上範例數量減少了幾個數量級。最後，在 TextWorld 中，我們展示了 IGE 在需要長期探索的設定中取得成功的獨特能力，在該設定中，先前的 SOTA FM 代理（例如 Reflexion）完全失敗。總的來說，IGE 結合了 FM 和強大的 Go-Explore 演算法的巨大優勢，開啟了探索創造更具一般能力且具有令人印象深刻的探索能力的代理的新研究領域。

##### **Efficient Biomedical Entity Linking: Clinical Text Standardization with Low-Resource Techniques**
2405.15134v1 by Akshit Achara, Sanand Sasidharan, Gagan N

Clinical text is rich in information, with mentions of treatment, medication
and anatomy among many other clinical terms. Multiple terms can refer to the
same core concepts which can be referred as a clinical entity. Ontologies like
the Unified Medical Language System (UMLS) are developed and maintained to
store millions of clinical entities including the definitions, relations and
other corresponding information. These ontologies are used for standardization
of clinical text by normalizing varying surface forms of a clinical term
through Biomedical entity linking. With the introduction of transformer-based
language models, there has been significant progress in Biomedical entity
linking. In this work, we focus on learning through synonym pairs associated
with the entities. As compared to the existing approaches, our approach
significantly reduces the training data and resource consumption. Moreover, we
propose a suite of context-based and context-less reranking techniques for
performing the entity disambiguation. Overall, we achieve similar performance
to the state-of-the-art zero-shot and distant supervised entity linking
techniques on the Medmentions dataset, the largest annotated dataset on UMLS,
without any domain-based training. Finally, we show that retrieval performance
alone might not be sufficient as an evaluation metric and introduce an article
level quantitative and qualitative analysis to reveal further insights on the
performance of entity linking methods.

摘要：臨床文本資訊豐富，其中包含治療、藥物和解剖學等許多其他臨床術語。多個術語可以指涉同一個核心概念，可以稱之為臨床實體。像統一醫學語言系統 (UMLS) 等本体論的開發和維護，是用於儲存數百萬個臨床實體，包括定義、關係和其他對應資訊。這些本体論用於通過生物醫學實體連結，對臨床文本進行標準化，以標準化臨床術語的不同表面形式。隨著基於轉換器的語言模型的引入，生物醫學實體連結方面取得了重大進展。在這項工作中，我們專注於通過與實體關聯的同義詞對進行學習。與現有方法相比，我們的做法顯著減少了訓練資料和資源消耗。此外，我們提出了一套基於上下文和無上下文的重新排序技術，用於執行實體消歧。總的來說，我們在 Medmentions 資料集（UMLS 上最大的註釋資料集）上實現了與最先進的零次學習和遠程監督實體連結技術相似的效能，而無需任何基於領域的訓練。最後，我們表明，檢索效能本身可能不足以作為評估指標，並引入文章層級的量化和定性分析，以揭示實體連結方法效能的進一步見解。

##### **OptLLM: Optimal Assignment of Queries to Large Language Models**
2405.15130v1 by Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li

Large Language Models (LLMs) have garnered considerable attention owing to
their remarkable capabilities, leading to an increasing number of companies
offering LLMs as services. Different LLMs achieve different performance at
different costs. A challenge for users lies in choosing the LLMs that best fit
their needs, balancing cost and performance. In this paper, we propose a
framework for addressing the cost-effective query allocation problem for LLMs.
Given a set of input queries and candidate LLMs, our framework, named OptLLM,
provides users with a range of optimal solutions to choose from, aligning with
their budget constraints and performance preferences, including options for
maximizing accuracy and minimizing cost. OptLLM predicts the performance of
candidate LLMs on each query using a multi-label classification model with
uncertainty estimation and then iteratively generates a set of non-dominated
solutions by destructing and reconstructing the current solution. To evaluate
the effectiveness of OptLLM, we conduct extensive experiments on various types
of tasks, including text classification, question answering, sentiment
analysis, reasoning, and log parsing. Our experimental results demonstrate that
OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same
accuracy as the best LLM. Compared to other multi-objective optimization
algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or
saves costs by 8.79% and 95.87% while maintaining the highest attainable
accuracy.

摘要：大型語言模型 (LLM) 因其卓越的能力而備受關注，導致越來越多的公司將 LLM 作為服務提供。不同的 LLM 以不同的成本實現不同的效能。使用者面臨的挑戰在於選擇最符合其需求的 LLM，並在成本和效能之間取得平衡。在本文中，我們提出一個解決 LLM 的經濟有效查詢分配問題的架構。給定一組輸入查詢和候選 LLM，我們名為 OptLLM 的架構為使用者提供一系列最佳解供其選擇，符合其預算限制和效能偏好，包括最大化準確度和最小化成本的選項。OptLLM 使用具有不確定性估計的多標籤分類模型預測候選 LLM 在每個查詢上的效能，然後透過破壞和重建目前的解，反覆產生一組非支配解。為了評估 OptLLM 的有效性，我們對各種類型的任務進行廣泛的實驗，包括文字分類、問答、情緒分析、推理和日誌剖析。我們的實驗結果證明，OptLLM 在達到與最佳 LLM 相同準確度的同時，大幅降低了 2.40% 到 49.18% 的成本。與其他多目標最佳化演算法相比，OptLLM 在相同成本下將準確度提升了 2.94% 到 69.05%，或在維持最高可達到的準確度的同時，節省了 8.79% 和 95.87% 的成本。

##### **Benchmarking Hierarchical Image Pyramid Transformer for the classification of colon biopsies and polyps in histopathology images**
2405.15127v1 by Nohemi Sofia Leon Contreras, Marina D'Amato, Francesco Ciompi, Clement Grisi, Witali Aswolinskiy, Simona Vatrano, Filippo Fraggetta, Iris Nagtegaal

Training neural networks with high-quality pixel-level annotation in
histopathology whole-slide images (WSI) is an expensive process due to
gigapixel resolution of WSIs. However, recent advances in self-supervised
learning have shown that highly descriptive image representations can be
learned without the need for annotations. We investigate the application of the
recent Hierarchical Image Pyramid Transformer (HIPT) model for the specific
task of classification of colorectal biopsies and polyps. After evaluating the
effectiveness of TCGA-learned features in the original HIPT model, we
incorporate colon biopsy image information into HIPT's pretraining using two
distinct strategies: (1) fine-tuning HIPT from the existing TCGA weights and
(2) pretraining HIPT from random weight initialization. We compare the
performance of these pretraining regimes on two colorectal biopsy
classification tasks: binary and multiclass classification.

摘要：訓練神經網路以高品質像素級註解在病理學全玻片影像 (WSI) 中是一個昂貴的過程，因為 WSI 的解析度為十億畫素。然而，自監督學習的最新進展顯示，高度描述性的影像表徵可以在不需要註解的情況下學習。我們研究階層式影像金字塔Transformer (HIPT) 模型在結直腸活檢和息肉分類特定任務中的應用。在評估原始 HIPT 模型中 TCGA 學習特徵的有效性後，我們使用兩種不同的策略將結腸活檢影像資訊納入 HIPT 的預訓練：(1) 從現有的 TCGA 權重微調 HIPT，以及 (2) 從隨機權重初始化預訓練 HIPT。我們在兩個結直腸活檢分類任務中比較這些預訓練機制的效能：二元分類和多類分類。

##### **Scaling Law for Time Series Forecasting**
2405.15124v1 by Jingzhe Shi, Qinwei Ma, Huan Ma, Lei Li

Scaling law that rewards large datasets, complex models and enhanced data
granularity has been observed in various fields of deep learning. Yet, studies
on time series forecasting have cast doubt on scaling behaviors of deep
learning methods for time series forecasting: while more training data improves
performance, more capable models do not always outperform less capable models,
and longer input horizons may hurt performance for some models. We propose a
theory for scaling law for time series forecasting that can explain these
seemingly abnormal behaviors. We take into account the impact of dataset size
and model complexity, as well as time series data granularity, particularly
focusing on the look-back horizon, an aspect that has been unexplored in
previous theories. Furthermore, we empirically evaluate various models using a
diverse set of time series forecasting datasets, which (1) verifies the
validity of scaling law on dataset size and model complexity within the realm
of time series forecasting, and (2) validates our theoretical framework,
particularly regarding the influence of look back horizon. We hope our findings
may inspire new models targeting time series forecasting datasets of limited
size, as well as large foundational datasets and models for time series
forecasting in future works.\footnote{Codes for our experiments will be made
public at:
\url{https://github.com/JingzheShi/ScalingLawForTimeSeriesForecasting}.

摘要：<paragraph>在深度學習的各種領域中，已經觀察到擴充法則獎勵大型資料集、複雜模型和增強資料粒度。然而，時間序列預測的研究對時間序列預測的深度學習方法的擴充行為提出質疑：雖然更多訓練資料可以改善效能，但更強大的模型並非總是優於較弱的模型，而且較長的輸入時間範圍可能會損害某些模型的效能。我們提出一個時間序列預測的擴充法則理論，可以解釋這些看似異常的行為。我們考慮資料集大小和模型複雜度的影響，以及時間序列資料粒度，特別關注回顧時間範圍，這是以前理論中未探討的一個面向。此外，我們使用多樣化的時間序列預測資料集對各種模型進行經驗評估，這（1）驗證了時間序列預測領域中資料集大小和模型複雜度的擴充法則的有效性，以及（2）驗證了我們的理論架構，特別是關於回顧時間範圍的影響。我們希望我們的發現可以激勵新的模型，針對有限大小的時間序列預測資料集，以及未來時間序列預測的大型基礎資料集和模型。\footnote{我們實驗的程式碼將公佈於：\url{https://github.com/JingzheShi/ScalingLawForTimeSeriesForecasting}。}</paragraph>

##### **Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models**
2405.15122v1 by Nicholas J Dobbins

Background: Biomedical entity normalization is critical to biomedical
research because the richness of free-text clinical data, such as progress
notes, can often be fully leveraged only after translating words and phrases
into structured and coded representations suitable for analysis. Large Language
Models (LLMs), in turn, have shown great potential and high performance in a
variety of natural language processing (NLP) tasks, but their application for
normalization remains understudied.
  Methods: We applied both proprietary and open-source LLMs in combination with
several rule-based normalization systems commonly used in biomedical research.
We used a two-step LLM integration approach, (1) using an LLM to generate
alternative phrasings of a source utterance, and (2) to prune candidate UMLS
concepts, using a variety of prompting methods. We measure results by
$F_{\beta}$, where we favor recall over precision, and F1.
  Results: We evaluated a total of 5,523 concept terms and text contexts from a
publicly available dataset of human-annotated biomedical abstracts.
Incorporating GPT-3.5-turbo increased overall $F_{\beta}$ and F1 in
normalization systems +9.5 and +7.3 (MetaMapLite), +13.9 and +10.9 (QuickUMLS),
and +10.5 and +10.3 (BM25), while the open-source Vicuna model achieved +10.8
and +12.2 (MetaMapLite), +14.7 and +15 (QuickUMLS), and +15.6 and +18.7 (BM25).
  Conclusions: Existing general-purpose LLMs, both propriety and open-source,
can be leveraged at scale to greatly improve normalization performance using
existing tools, with no fine-tuning.

摘要：<paragraph>背景：生物医学实体标准化对于生物医学研究至关重要，因为自由文本临床数据（例如进展记录）的丰富性通常只有在将单词和短语转换为适合分析的结构化和编码表示后才能得到充分利用。反过来，大语言模型 (LLM) 在各种自然语言处理 (NLP) 任务中显示出巨大的潜力和高性能，但它们在标准化方面的应用仍然未得到充分研究。
方法：我们将专有和开源 LLM 与生物医学研究中常用的几个基于规则的标准化系统相结合。我们使用了两步 LLM 集成方法，（1）使用 LLM 生成源话语的替代措辞，以及（2）使用各种提示方法来修剪候选 UMLS 概念。我们通过 $F_{\beta}$ 衡量结果，其中我们更倾向于召回率而不是准确率，以及 F1。
结果：我们从人类注释的生物医学摘要的公开数据集评估了总共 5,523 个概念术语和文本上下文。结合 GPT-3.5-turbo 使标准化系统中的整体 $F_{\beta}$ 和 F1 分别提高了 +9.5 和 +7.3（MetaMapLite），+13.9 和 +10.9（QuickUMLS），以及 +10.5 和 +10.3（BM25），而开源 Vicuna 模型分别提高了 +10.8 和 +12.2（MetaMapLite），+14.7 和 +15（QuickUMLS），以及 +15.6 和 +18.7（BM25）。
结论：现有的通用 LLM，无论是专有的还是开源的，都可以大规模利用，以使用现有工具极大地提高标准化性能，而无需进行微调。</paragraph>

##### **Quantifying the Gain in Weak-to-Strong Generalization**
2405.15116v1 by Moses Charikar, Chirag Pabbaraju, Kirankumar Shiragur

Recent advances in large language models have shown capabilities that are
extraordinary and near-superhuman. These models operate with such complexity
that reliably evaluating and aligning them proves challenging for humans. This
leads to the natural question: can guidance from weak models (like humans)
adequately direct the capabilities of strong models? In a recent and somewhat
surprising work, Burns et al. (2023) empirically demonstrated that when strong
models (like GPT-4) are finetuned using labels generated by weak supervisors
(like GPT-2), the strong models outperform their weaker counterparts -- a
phenomenon they term weak-to-strong generalization.
  In this work, we present a theoretical framework for understanding
weak-to-strong generalization. Specifically, we show that the improvement in
performance achieved by strong models over their weaker counterparts is
quantified by the misfit error incurred by the strong model on labels generated
by the weaker model. Our theory reveals several curious algorithmic insights.
For instance, we can predict the amount by which the strong model will improve
over the weak model, and also choose among different weak models to train the
strong model, based on its misfit error. We validate our theoretical findings
through various empirical assessments.

摘要：<paragraph>大型語言模型的最新進展展現出非凡且近乎超人的能力。這些模型以極高的複雜度運作，可靠地評估和調整它們對人類來說具有挑戰性。這導致了一個自然的問題：來自弱模型（如人類）的指導能否充分指導強模型的能力？在最近一項有點令人驚訝的研究中，Burns 等人（2023 年）通過實證證明，當強模型（如 GPT-4）使用由弱監督器（如 GPT-2）產生的標籤進行微調時，強模型的表現優於它們較弱的對應模型——他們將這種現象稱為弱到強的泛化。
在這項研究中，我們提出了一個理論框架來理解弱到強的泛化。具體來說，我們表明，強模型相對於它們較弱的對應模型所取得的效能提升，是由強模型在較弱模型產生的標籤上產生的失配誤差量化的。我們的理論揭示了幾個有趣的演算法見解。例如，我們可以預測強模型將比弱模型改善的程度，並且還可以根據其失配誤差，在不同的弱模型中選擇用於訓練強模型的模型。我們通過各種實證評估驗證了我們的理論發現。</paragraph>

##### **CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems**
2405.15110v1 by Abbas Ghaddar, David Alfonso-Hermelo, Philippe Langlais, Mehdi Rezagholizadeh, Boxing Chen, Prasanna Parthasarathi

In this work, we dive deep into one of the popular knowledge-grounded
dialogue benchmarks that focus on faithfulness, FaithDial. We show that a
significant portion of the FaithDial data contains annotation artifacts, which
may bias models towards completely ignoring the conversation history. We
therefore introduce CHARP, a diagnostic test set, designed for an improved
evaluation of hallucinations in conversational model. CHARP not only measures
hallucination but also the compliance of the models to the conversation task.
Our extensive analysis reveals that models primarily exhibit poor performance
on CHARP due to their inability to effectively attend to and reason over the
conversation history. Furthermore, the evaluation methods of FaithDial fail to
capture these shortcomings, neglecting the conversational history. Our findings
indicate that there is substantial room for contribution in both dataset
creation and hallucination evaluation for knowledge-grounded dialogue, and that
CHARP can serve as a tool for monitoring the progress in this particular
research area. CHARP is publicly available at
https://huggingface.co/datasets/huawei-noah/CHARP

摘要：在這項工作中，我們深入探討了專注於忠實度的熱門知識基礎對話基準之一 FaithDial。我們展示了 FaithDial 資料的很大一部分包含註釋人工製品，這可能會使模型完全忽略對話記錄。因此，我們引入了 CHARP，一個診斷測試集，旨在改進對話模型中幻覺的評估。CHARP 不僅衡量幻覺，還衡量模型對對話任務的遵守程度。我們的廣泛分析表明，模型主要在 CHARP 上表現不佳，原因是它們無法有效地關注和推理對話記錄。此外，FaithDial 的評估方法未能捕捉到這些缺點，忽視了對話記錄。我們的研究結果表明，在知識基礎對話的資料集建立和幻覺評估方面都有很大的貢獻空間，而且 CHARP 可以作為監控這個特定研究領域進展的工具。CHARP 在 https://huggingface.co/datasets/huawei-noah/CHARP 公開提供

##### **Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding**
2405.15097v1 by Suyoung Kim, Jiyeon Hwang, Ho-Young Jung

Recently, deep end-to-end learning has been studied for intent classification
in Spoken Language Understanding (SLU). However, end-to-end models require a
large amount of speech data with intent labels, and highly optimized models are
generally sensitive to the inconsistency between the training and evaluation
conditions. Therefore, a natural language understanding approach based on
Automatic Speech Recognition (ASR) remains attractive because it can utilize a
pre-trained general language model and adapt to the mismatch of the speech
input environment. Using this module-based approach, we improve a noisy-channel
model to handle transcription inconsistencies caused by ASR errors. We propose
a two-stage method, Contrastive and Consistency Learning (CCL), that correlates
error patterns between clean and noisy ASR transcripts and emphasizes the
consistency of the latent features of the two transcripts. Experiments on four
benchmark datasets show that CCL outperforms existing methods and improves the
ASR robustness in various noisy environments. Code is available at
https://github.com/syoung7388/CCL.

摘要：最近，深度端到端學習已被研究用於口語理解 (SLU) 中的意圖分類。然而，端到端模型需要大量帶有意圖標籤的語音資料，而高度最佳化的模型通常對訓練和評估條件之間的不一致很敏感。因此，基於自動語音辨識 (ASR) 的自然語言理解方法仍然具有吸引力，因為它可以利用預先訓練的通用語言模型並適應語音輸入環境的不匹配。使用這種基於模組的方法，我們改進了一個雜訊通道模型，以處理由 ASR 錯誤引起的轉錄不一致。我們提出了一種兩階段方法，對比和一致性學習 (CCL)，它將乾淨和雜訊 ASR 轉錄之間的錯誤模式關聯起來，並強調兩個轉錄的潛在特徵的一致性。在四個基準資料集上的實驗表明，CCL 優於現有方法，並在各種雜訊環境中改善了 ASR 的穩健性。程式碼可在 https://github.com/syoung7388/CCL 取得。

##### **Dissociation of Faithful and Unfaithful Reasoning in LLMs**
2405.15092v1 by Evelyn Yee, Alice Li, Chenyu Tang, Yeon Ho Jung, Ramamohan Paturi, Leon Bergen

Large language models (LLMs) improve their performance in downstream tasks
when they generate Chain of Thought reasoning text before producing an answer.
Our research investigates how LLMs recover from errors in Chain of Thought,
reaching the correct final answer despite mistakes in the reasoning text.
Through analysis of these error recovery behaviors, we find evidence for
unfaithfulness in Chain of Thought, but we also identify many clear examples of
faithful error recovery behaviors. We identify factors that shift LLM recovery
behavior: LLMs recover more frequently from obvious errors and in contexts that
provide more evidence for the correct answer. However, unfaithful recoveries
show the opposite behavior, occurring more frequently for more difficult error
positions. Our results indicate that there are distinct mechanisms driving
faithful and unfaithful error recoveries. Our results challenge the view that
LLM reasoning is a uniform, coherent process.

摘要：大型語言模型 (LLM) 在產生答案之前生成思維鏈推理文字時，會提升其在下游任務中的表現。
我們的研究探討 LLM 如何從思維鏈中的錯誤中復原，儘管推理文字有錯誤，但仍能得到正確的最終答案。
透過分析這些錯誤復原行為，我們找到了思維鏈中不忠實的證據，但我們也找到了許多清晰的忠實錯誤復原行為範例。我們找出影響 LLM 復原行為的因素：LLM 從明顯的錯誤中復原的頻率較高，且在提供更多正確答案證據的脈絡中復原。然而，不忠實的復原行為表現相反，在較困難的錯誤位置中復原的頻率較高。我們的結果表明，有不同的機制驅動忠實和不忠實的錯誤復原。我們的結果挑戰了 LLM 推理是一個統一、連貫過程的觀點。

