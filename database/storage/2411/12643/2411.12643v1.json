{"2411.12643": {"publish_time": "2024-11-19", "title": "DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models", "paper_summary": "The rapid advancement of artificial intelligence has led to increasingly\nsophisticated deep learning models, which frequently operate as opaque 'black\nboxes' with limited transparency in their decision-making processes. This lack\nof interpretability presents considerable challenges, especially in high-stakes\napplications where understanding the rationale behind a model's outputs is as\nessential as the outputs themselves. This study addresses the pressing need for\ninterpretability in AI systems, emphasizing its role in fostering trust,\nensuring accountability, and promoting responsible deployment in\nmission-critical fields. To address the interpretability challenge in deep\nlearning, we introduce DLBacktrace, an innovative technique developed by the\nAryaXAI team to illuminate model decisions across a wide array of domains,\nincluding simple Multi Layer Perceptron (MLPs), Convolutional Neural Networks\n(CNNs), Large Language Models (LLMs), Computer Vision Models, and more.\n  We provide a comprehensive overview of the DLBacktrace algorithm and present\nbenchmarking results, comparing its performance against established\ninterpretability methods, such as SHAP, LIME, GradCAM, Integrated Gradients,\nSmoothGrad, and Attention Rollout, using diverse task-based metrics. The\nproposed DLBacktrace technique is compatible with various model architectures\nbuilt in PyTorch and TensorFlow, supporting models like Llama 3.2, other NLP\narchitectures such as BERT and LSTMs, computer vision models like ResNet and\nU-Net, as well as custom deep neural network (DNN) models for tabular data.\nThis flexibility underscores DLBacktrace's adaptability and effectiveness in\nenhancing model transparency across a broad spectrum of applications. The\nlibrary is open-sourced and available at https://github.com/AryaXAI/DLBacktrace .", "paper_summary_zh": "\u96a8\u8457\u4eba\u5de5\u667a\u6167\u7684\u5feb\u901f\u9032\u5c55\uff0c\u7522\u751f\u4e86\u8d8a\u4f86\u8d8a\u8907\u96dc\u7684\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\uff0c\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u4f5c\u70ba\u4e0d\u900f\u660e\u7684\u300c\u9ed1\u76d2\u5b50\u300d\u904b\u4f5c\uff0c\u5728\u6c7a\u7b56\u904e\u7a0b\u4e2d\u900f\u660e\u5ea6\u6709\u9650\u3002\u9019\u7a2e\u53ef\u89e3\u91cb\u6027\u7684\u7f3a\u4e4f\u5e36\u4f86\u4e86\u76f8\u7576\u5927\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u9ad8\u98a8\u96aa\u61c9\u7528\u4e2d\uff0c\u4e86\u89e3\u6a21\u578b\u8f38\u51fa\u7684\u80cc\u5f8c\u539f\u56e0\u8207\u8f38\u51fa\u672c\u8eab\u4e00\u6a23\u91cd\u8981\u3002\u672c\u7814\u7a76\u89e3\u6c7a\u4e86 AI \u7cfb\u7d71\u4e2d\u5c0d\u65bc\u53ef\u89e3\u91cb\u6027\u7684\u8feb\u5207\u9700\u6c42\uff0c\u5f37\u8abf\u5176\u5728\u5efa\u7acb\u4fe1\u4efb\u3001\u78ba\u4fdd\u554f\u8cac\u5236\u4ee5\u53ca\u5728\u4efb\u52d9\u95dc\u9375\u9818\u57df\u4fc3\u9032\u8ca0\u8cac\u4efb\u90e8\u7f72\u4e2d\u7684\u4f5c\u7528\u3002\u70ba\u4e86\u61c9\u5c0d\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u7684\u53ef\u89e3\u91cb\u6027\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 DLBacktrace\uff0c\u9019\u662f\u4e00\u7a2e\u7531 AryaXAI \u5718\u968a\u958b\u767c\u7684\u5275\u65b0\u6280\u8853\uff0c\u7528\u65bc\u95e1\u660e\u5404\u7a2e\u9818\u57df\u7684\u6a21\u578b\u6c7a\u7b56\uff0c\u5305\u62ec\u7c21\u55ae\u7684\u591a\u5c64\u611f\u77e5\u5668 (MLP)\u3001\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN)\u3001\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3001\u96fb\u8166\u8996\u89ba\u6a21\u578b\u7b49\u7b49\u3002\u6211\u5011\u63d0\u4f9b\u4e86 DLBacktrace \u6f14\u7b97\u6cd5\u7684\u5168\u9762\u6982\u8ff0\uff0c\u4e26\u63d0\u51fa\u4e86\u57fa\u6e96\u6e2c\u8a66\u7d50\u679c\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u57fa\u65bc\u4efb\u52d9\u7684\u6307\u6a19\uff0c\u5c07\u5176\u6548\u80fd\u8207\u5df2\u5efa\u7acb\u7684\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\uff08\u4f8b\u5982 SHAP\u3001LIME\u3001GradCAM\u3001\u6574\u5408\u68af\u5ea6\u3001SmoothGrad \u548c\u6ce8\u610f\u529b\u5c55\u958b\uff09\u9032\u884c\u6bd4\u8f03\u3002\u5efa\u8b70\u7684 DLBacktrace \u6280\u8853\u8207\u5728 PyTorch \u548c TensorFlow \u4e2d\u5efa\u7acb\u7684\u5404\u7a2e\u6a21\u578b\u67b6\u69cb\u76f8\u5bb9\uff0c\u652f\u63f4 Llama 3.2 \u7b49\u6a21\u578b\u3001\u5176\u4ed6 NLP \u67b6\u69cb\uff08\u4f8b\u5982 BERT \u548c LSTM\uff09\u3001\u96fb\u8166\u8996\u89ba\u6a21\u578b\uff08\u4f8b\u5982 ResNet \u548c U-Net\uff09\uff0c\u4ee5\u53ca\u7528\u65bc\u8868\u683c\u8cc7\u6599\u7684\u5ba2\u88fd\u5316\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (DNN) \u6a21\u578b\u3002\u9019\u7a2e\u9748\u6d3b\u6027\u7a81\u986f\u4e86 DLBacktrace \u5728\u5ee3\u6cdb\u61c9\u7528\u4e2d\u589e\u5f37\u6a21\u578b\u900f\u660e\u5ea6\u7684\u9069\u61c9\u6027\u548c\u6709\u6548\u6027\u3002\u6b64\u7a0b\u5f0f\u5eab\u662f\u958b\u6e90\u7684\uff0c\u53ef\u5728 https://github.com/AryaXAI/DLBacktrace \u53d6\u5f97\u3002", "author": "Vinay Kumar Sankarapu et.al.", "authors": "Vinay Kumar Sankarapu, Chintan Chitroda, Yashwardhan Rathore, Neeraj Kumar Singh, Pratinav Seth", "id": "2411.12643v1", "paper_url": "http://arxiv.org/abs/2411.12643v1", "repo": "https://github.com/aryaxai/dlbacktrace"}}