{"2410.14225": {"publish_time": "2024-10-18", "title": "Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model", "paper_summary": "Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task\nthat aims to extract entities and their relations from text-image pairs in\nsocial media posts. Existing methods for JMERE require large amounts of labeled\ndata. However, gathering and annotating fine-grained multimodal data for JMERE\nposes significant challenges. Initially, we construct diverse and comprehensive\nmultimodal few-shot datasets fitted to the original data distribution. To\naddress the insufficient information in the few-shot setting, we introduce the\n\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt\n\\textbf{M}odel (KECPM) for JMERE. This method can effectively address the\nproblem of insufficient information in the few-shot setting by guiding a large\nlanguage model to generate supplementary background knowledge. Our proposed\nmethod comprises two stages: (1) a knowledge ingestion stage that dynamically\nformulates prompts based on semantic similarity guide ChatGPT generating\nrelevant knowledge and employs self-reflection to refine the knowledge; (2) a\nknowledge-enhanced language model stage that merges the auxiliary knowledge\nwith the original input and utilizes a transformer-based model to align with\nJMERE's required output format. We extensively evaluate our approach on a\nfew-shot dataset derived from the JMERE dataset, demonstrating its superiority\nover strong baselines in terms of both micro and macro F$_1$ scores.\nAdditionally, we present qualitative analyses and case studies to elucidate the\neffectiveness of our model.", "paper_summary_zh": "<paragraph>\u806f\u5408\u591a\u6a21\u614b\u5be6\u9ad4\u95dc\u4fc2\u62bd\u53d6 (JMERE) \u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u65e8\u5728\u5f9e\u793e\u7fa4\u5a92\u9ad4\u6587\u7ae0\u4e2d\u7684\u6587\u5b57\u5f71\u50cf\u5c0d\u4e2d\u62bd\u53d6\u5be6\u9ad4\u53ca\u5176\u95dc\u4fc2\u3002\u73fe\u6709\u7684 JMERE \u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6a19\u7c64\u8cc7\u6599\u3002\u7136\u800c\uff0c\u6536\u96c6\u548c\u6a19\u8a3b JMERE \u7684\u7d30\u7c92\u5ea6\u591a\u6a21\u614b\u8cc7\u6599\u6703\u5e36\u4f86\u91cd\u5927\u7684\u6311\u6230\u3002\u6700\u521d\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u591a\u6a23\u5316\u4e14\u5168\u9762\u7684\u591a\u6a21\u614b\u5c11\u91cf\u8cc7\u6599\u96c6\uff0c\u4ee5\u7b26\u5408\u539f\u59cb\u8cc7\u6599\u5206\u4f48\u3002\u70ba\u4e86\u89e3\u6c7a\u5c11\u91cf\u8cc7\u6599\u8a2d\u5b9a\u4e2d\u7684\u8cc7\u8a0a\u4e0d\u8db3\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\\textbf{K}nowledge-\\textbf{E}nhanced \\textbf{C}ross-modal \\textbf{P}rompt \\textbf{M}odel (KECPM) for JMERE\u3002\u6b64\u65b9\u6cd5\u53ef\u4ee5\u900f\u904e\u5f15\u5c0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7522\u751f\u88dc\u5145\u80cc\u666f\u77e5\u8b58\u4f86\u6709\u6548\u89e3\u6c7a\u5c11\u91cf\u8cc7\u6599\u8a2d\u5b9a\u4e2d\u7684\u8cc7\u8a0a\u4e0d\u8db3\u554f\u984c\u3002\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u5305\u542b\u5169\u500b\u968e\u6bb5\uff1a(1) \u77e5\u8b58\u5438\u6536\u968e\u6bb5\uff0c\u6839\u64da\u8a9e\u7fa9\u76f8\u4f3c\u6027\u6307\u5357\u52d5\u614b\u5236\u5b9a\u63d0\u793a\uff0c\u5f15\u5c0e ChatGPT \u7522\u751f\u76f8\u95dc\u77e5\u8b58\uff0c\u4e26\u5229\u7528\u81ea\u6211\u53cd\u7701\u4f86\u7cbe\u9032\u77e5\u8b58\uff1b(2) \u77e5\u8b58\u589e\u5f37\u8a9e\u8a00\u6a21\u578b\u968e\u6bb5\uff0c\u5c07\u8f14\u52a9\u77e5\u8b58\u8207\u539f\u59cb\u8f38\u5165\u5408\u4f75\uff0c\u4e26\u5229\u7528\u57fa\u65bc\u8f49\u63db\u5668\u7684\u6a21\u578b\u8207 JMERE \u6240\u9700\u7684\u8f38\u51fa\u683c\u5f0f\u5c0d\u9f4a\u3002\u6211\u5011\u5ee3\u6cdb\u8a55\u4f30\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u5f9e JMERE \u8cc7\u6599\u96c6\u884d\u751f\u7684\u5c11\u91cf\u8cc7\u6599\u96c6\u4e0a\u7684\u8868\u73fe\uff0c\u8b49\u660e\u5176\u5728\u5fae\u89c0\u548c\u5de8\u89c0 F$_1$ \u5206\u6578\u65b9\u9762\u90fd\u512a\u65bc\u5f37\u5927\u7684\u57fa\u6e96\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u5b9a\u6027\u5206\u6790\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u4ee5\u95e1\u660e\u6211\u5011\u6a21\u578b\u7684\u6709\u6548\u6027\u3002</paragraph>", "author": "Li Yuan et.al.", "authors": "Li Yuan, Yi Cai, Junsheng Huang", "id": "2410.14225v1", "paper_url": "http://arxiv.org/abs/2410.14225v1", "repo": "null"}}