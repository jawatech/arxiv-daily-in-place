{"2405.18144": {"publish_time": "2024-05-28", "title": "4-bit Shampoo for Memory-Efficient Network Training", "paper_summary": "Second-order optimizers, maintaining a matrix termed a preconditioner, are\nsuperior to first-order optimizers in both theory and practice. The states\nforming the preconditioner and its inverse root restrict the maximum size of\nmodels trained by second-order optimizers. To address this, compressing 32-bit\noptimizer states to lower bitwidths has shown promise in reducing memory usage.\nHowever, current approaches only pertain to first-order optimizers. In this\npaper, we propose the first 4-bit second-order optimizers, exemplified by 4-bit\nShampoo, maintaining performance similar to that of 32-bit ones. We show that\nquantizing the eigenvector matrix of the preconditioner in 4-bit Shampoo is\nremarkably better than quantizing the preconditioner itself both theoretically\nand experimentally. By rectifying the orthogonality of the quantized\neigenvector matrix, we enhance the approximation of the preconditioner's\neigenvector matrix, which also benefits the computation of its inverse 4-th\nroot. Besides, we find that linear square quantization slightly outperforms\ndynamic tree quantization when quantizing second-order optimizer states.\nEvaluation on various networks for image classification demonstrates that our\n4-bit Shampoo achieves comparable test accuracy to its 32-bit counterpart while\nbeing more memory-efficient. The source code will be made available.", "paper_summary_zh": "\u4e8c\u968e\u6700\u4f73\u5316\u5668\uff0c\u7dad\u8b77\u4e00\u500b\u7a31\u70ba\u9810\u8655\u7406\u5668\u7684\u77e9\u9663\uff0c\u5728\u7406\u8ad6\u548c\u5be6\u52d9\u4e0a\u90fd\u512a\u65bc\u4e00\u968e\u6700\u4f73\u5316\u5668\u3002\u5f62\u6210\u9810\u8655\u7406\u5668\u53ca\u5176\u9006\u6839\u7684\u72c0\u614b\u6703\u9650\u5236\u4e8c\u968e\u6700\u4f73\u5316\u5668\u8a13\u7df4\u6a21\u578b\u7684\u6700\u5927\u898f\u6a21\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u5c07 32 \u4f4d\u5143\u6700\u4f73\u5316\u5668\u72c0\u614b\u58d3\u7e2e\u6210\u8f03\u4f4e\u7684\u4f4d\u5143\u5bec\u5ea6\uff0c\u5df2\u5c55\u73fe\u51fa\u5728\u6e1b\u5c11\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u65b9\u9762\u5f88\u6709\u524d\u666f\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u65b9\u6cd5\u50c5\u9069\u7528\u65bc\u4e00\u968e\u6700\u4f73\u5316\u5668\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u7b2c\u4e00\u500b 4 \u4f4d\u5143\u4e8c\u968e\u6700\u4f73\u5316\u5668\uff0c\u4ee5 4 \u4f4d\u5143 Shampoo \u70ba\u4f8b\uff0c\u7dad\u6301\u8207 32 \u4f4d\u5143\u6700\u4f73\u5316\u5668\u76f8\u4f3c\u7684\u6548\u80fd\u3002\u6211\u5011\u5c55\u793a\u51fa\uff0c\u5c07\u9810\u8655\u7406\u5668\u7684\u7279\u5fb5\u5411\u91cf\u77e9\u9663\u91cf\u5316\u70ba 4 \u4f4d\u5143 Shampoo \u5728\u7406\u8ad6\u548c\u5be6\u9a57\u4e0a\u90fd\u986f\u8457\u512a\u65bc\u91cf\u5316\u9810\u8655\u7406\u5668\u672c\u8eab\u3002\u900f\u904e\u4fee\u6b63\u91cf\u5316\u7279\u5fb5\u5411\u91cf\u77e9\u9663\u7684\u6b63\u4ea4\u6027\uff0c\u6211\u5011\u589e\u5f37\u4e86\u5c0d\u9810\u8655\u7406\u5668\u7279\u5fb5\u5411\u91cf\u77e9\u9663\u7684\u8fd1\u4f3c\uff0c\u9019\u4e5f\u6709\u52a9\u65bc\u8a08\u7b97\u5176\u9006 4 \u6b21\u6839\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\u7dda\u6027\u5e73\u65b9\u91cf\u5316\u5728\u91cf\u5316\u4e8c\u968e\u6700\u4f73\u5316\u5668\u72c0\u614b\u6642\uff0c\u7565\u512a\u65bc\u52d5\u614b\u6a39\u91cf\u5316\u3002\u5728\u5404\u7a2e\u7db2\u8def\u4e0a\u7684\u5f71\u50cf\u5206\u985e\u8a55\u4f30\u8b49\u660e\uff0c\u6211\u5011\u7684 4 \u4f4d\u5143 Shampoo \u9054\u5230\u8207\u5176 32 \u4f4d\u5143\u5c0d\u61c9\u7248\u672c\u76f8\u7576\u7684\u6e2c\u8a66\u6e96\u78ba\u5ea6\uff0c\u540c\u6642\u66f4\u5177\u8a18\u61b6\u9ad4\u6548\u7387\u3002\u539f\u59cb\u78bc\u5c07\u6703\u516c\u958b\u3002", "author": "Sike Wang et.al.", "authors": "Sike Wang, Jia Li, Pan Zhou, Hua Huang", "id": "2405.18144v1", "paper_url": "http://arxiv.org/abs/2405.18144v1", "repo": "null"}}