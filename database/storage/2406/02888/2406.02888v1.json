{"2406.02888": {"publish_time": "2024-06-05", "title": "HYDRA: Model Factorization Framework for Black-Box LLM Personalization", "paper_summary": "Personalization has emerged as a critical research area in modern intelligent\nsystems, focusing on mining users' behavioral history and adapting to their\npreferences for delivering tailored experiences. Despite the remarkable\nfew-shot capabilities exhibited by black-box large language models (LLMs), the\ninherent opacity of their model parameters presents significant challenges in\naligning the generated output with individual expectations. Existing solutions\nhave primarily focused on prompt design to incorporate user-specific profiles\nand behaviors; however, such approaches often struggle to generalize\neffectively due to their inability to capture shared knowledge among all users.\nTo address these challenges, we propose HYDRA, a model factorization framework\nthat captures both user-specific behavior patterns from historical data and\nshared general knowledge among all users to deliver personalized generation. In\norder to capture user-specific behavior patterns, we first train a reranker to\nprioritize the most useful information from top-retrieved relevant historical\nrecords. By combining the prioritized history with the corresponding query, we\ntrain an adapter to align the output with individual user-specific preferences,\neliminating the reliance on access to inherent model parameters of black-box\nLLMs. Both the reranker and the adapter can be decomposed into a base model\nwith multiple user-specific heads, resembling a hydra. The base model maintains\nshared knowledge across users, while the multiple personal heads capture\nuser-specific preferences. Experimental results demonstrate that HYDRA\noutperforms existing state-of-the-art prompt-based methods by an average\nrelative improvement of 9.01% across five diverse personalization tasks in the\nLaMP benchmark. Our implementation is available at\nhttps://github.com/night-chen/HYDRA.", "paper_summary_zh": "<paragraph>\u500b\u4eba\u5316\u5df2\u6210\u70ba\u73fe\u4ee3\u667a\u6167\u7cfb\u7d71\u4e2d\u4e00\u9805\u91cd\u8981\u7684\u7814\u7a76\u9818\u57df\uff0c\u5c08\u6ce8\u65bc\u6316\u6398\u4f7f\u7528\u8005\u7684\u884c\u70ba\u6b77\u53f2\uff0c\u4e26\u6839\u64da\u5176\u504f\u597d\u63d0\u4f9b\u5ba2\u88fd\u5316\u9ad4\u9a57\u3002\u5118\u7ba1\u9ed1\u76d2\u5b50\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u73fe\u51fa\u975e\u51e1\u7684\u5c11\u91cf\u6b21\u6578\u80fd\u529b\uff0c\u4f46\u5176\u6a21\u578b\u53c3\u6578\u56fa\u6709\u7684\u4e0d\u900f\u660e\u6027\u5728\u5c07\u7522\u751f\u7684\u8f38\u51fa\u8207\u500b\u5225\u671f\u671b\u76f8\u7b26\u6642\uff0c\u5e36\u4f86\u91cd\u5927\u6311\u6230\u3002\u73fe\u6709\u7684\u89e3\u6c7a\u65b9\u6848\u4e3b\u8981\u5c08\u6ce8\u65bc\u63d0\u793a\u8a2d\u8a08\uff0c\u4ee5\u7d0d\u5165\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u500b\u4eba\u8cc7\u6599\u548c\u884c\u70ba\uff1b\u7136\u800c\uff0c\u6b64\u985e\u65b9\u6cd5\u7531\u65bc\u7121\u6cd5\u64f7\u53d6\u6240\u6709\u4f7f\u7528\u8005\u4e4b\u9593\u7684\u5171\u7528\u77e5\u8b58\uff0c\u56e0\u6b64\u901a\u5e38\u96e3\u4ee5\u6709\u6548\u6982\u5316\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa HYDRA\uff0c\u9019\u662f\u4e00\u500b\u6a21\u578b\u5206\u89e3\u67b6\u69cb\uff0c\u53ef\u5f9e\u6b77\u53f2\u8cc7\u6599\u4e2d\u64f7\u53d6\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u884c\u70ba\u6a21\u5f0f\uff0c\u4e26\u5728\u6240\u6709\u4f7f\u7528\u8005\u4e4b\u9593\u5171\u7528\u4e00\u822c\u77e5\u8b58\uff0c\u4ee5\u63d0\u4f9b\u500b\u4eba\u5316\u751f\u6210\u3002\u70ba\u4e86\u64f7\u53d6\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u884c\u70ba\u6a21\u5f0f\uff0c\u6211\u5011\u9996\u5148\u8a13\u7df4\u4e00\u500b\u91cd\u65b0\u6392\u540d\u5668\uff0c\u4ee5\u512a\u5148\u8655\u7406\u5f9e\u9802\u7aef\u64f7\u53d6\u5230\u7684\u76f8\u95dc\u6b77\u53f2\u8a18\u9304\u4e2d\u6700\u6709\u7528\u7684\u8cc7\u8a0a\u3002\u900f\u904e\u5c07\u512a\u5148\u6392\u5e8f\u7684\u6b77\u53f2\u8a18\u9304\u8207\u5c0d\u61c9\u7684\u67e5\u8a62\u76f8\u7d50\u5408\uff0c\u6211\u5011\u8a13\u7df4\u4e00\u500b\u9069\u914d\u5668\uff0c\u4ee5\u5c07\u8f38\u51fa\u8207\u500b\u5225\u4f7f\u7528\u8005\u7684\u7279\u5b9a\u504f\u597d\u76f8\u7b26\uff0c\u7121\u9700\u4f9d\u8cf4\u5b58\u53d6\u9ed1\u76d2\u5b50 LLM \u7684\u56fa\u6709\u6a21\u578b\u53c3\u6578\u3002\u91cd\u65b0\u6392\u540d\u5668\u548c\u9069\u914d\u5668\u90fd\u53ef\u4ee5\u5206\u89e3\u6210\u4e00\u500b\u5177\u6709\u591a\u500b\u4f7f\u7528\u8005\u7279\u5b9a\u4e3b\u9ad4\u7684\u57fa\u790e\u6a21\u578b\uff0c\u985e\u4f3c\u65bc\u4e5d\u982d\u86c7\u3002\u57fa\u790e\u6a21\u578b\u7dad\u8b77\u4f7f\u7528\u8005\u4e4b\u9593\u7684\u5171\u7528\u77e5\u8b58\uff0c\u800c\u591a\u500b\u500b\u4eba\u4e3b\u9ad4\u5247\u64f7\u53d6\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u504f\u597d\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u5728 LaMP \u57fa\u6e96\u4e2d\u7684\u4e94\u9805\u4e0d\u540c\u7684\u500b\u4eba\u5316\u4efb\u52d9\u4e2d\uff0cHYDRA \u7684\u8868\u73fe\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u63d0\u793a\u5f0f\u65b9\u6cd5\uff0c\u5e73\u5747\u76f8\u5c0d\u6539\u5584\u5e45\u5ea6\u70ba 9.01%\u3002\u6211\u5011\u7684\u5be6\u4f5c\u53ef\u5728 https://github.com/night-chen/HYDRA \u53d6\u5f97\u3002</paragraph>", "author": "Yuchen Zhuang et.al.", "authors": "Yuchen Zhuang, Haotian Sun, Yue Yu, Qifan Wang, Chao Zhang, Bo Dai", "id": "2406.02888v1", "paper_url": "http://arxiv.org/abs/2406.02888v1", "repo": "null"}}