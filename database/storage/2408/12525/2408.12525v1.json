{"2408.12525": {"publish_time": "2024-08-22", "title": "PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators", "paper_summary": "Procedural Content Generation via Reinforcement Learning (PCGRL) has been\nintroduced as a means by which controllable designer agents can be trained\nbased only on a set of computable metrics acting as a proxy for the level's\nquality and key characteristics. While PCGRL offers a unique set of affordances\nfor game designers, it is constrained by the compute-intensive process of\ntraining RL agents, and has so far been limited to generating relatively small\nlevels. To address this issue of scale, we implement several PCGRL environments\nin Jax so that all aspects of learning and simulation happen in parallel on the\nGPU, resulting in faster environment simulation; removing the CPU-GPU transfer\nof information bottleneck during RL training; and ultimately resulting in\nsignificantly improved training speed. We replicate several key results from\nprior works in this new framework, letting models train for much longer than\npreviously studied, and evaluating their behavior after 1 billion timesteps.\nAiming for greater control for human designers, we introduce randomized level\nsizes and frozen \"pinpoints\" of pivotal game tiles as further ways of\ncountering overfitting. To test the generalization ability of learned\ngenerators, we evaluate models on large, out-of-distribution map sizes, and\nfind that partial observation sizes learn more robust design strategies.", "paper_summary_zh": "\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08PCGRL\uff09\u5df2\u88ab\u5f15\u5165\uff0c\u4f5c\u4e3a\u4e00\u79cd\u624b\u6bb5\uff0c\u53ef\u6839\u636e\u4e00\u7ec4\u53ef\u8ba1\u7b97\u7684\u6307\u6807\uff08\u4f5c\u4e3a\u5173\u5361\u8d28\u91cf\u548c\u5173\u952e\u7279\u5f81\u7684\u4ee3\u7406\uff09\u6765\u8bad\u7ec3\u53ef\u63a7\u7684\u8bbe\u8ba1\u5e08\u4ee3\u7406\u3002\u867d\u7136 PCGRL \u4e3a\u6e38\u620f\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u4e86\u4e00\u7ec4\u72ec\u7279\u7684\u4fbf\u5229\u6027\uff0c\u4f46\u5b83\u53d7\u5230\u8bad\u7ec3 RL \u4ee3\u7406\u7684\u8ba1\u7b97\u5bc6\u96c6\u578b\u8fc7\u7a0b\u7684\u9650\u5236\uff0c\u5e76\u4e14\u5230\u76ee\u524d\u4e3a\u6b62\u4ec5\u9650\u4e8e\u751f\u6210\u76f8\u5bf9\u8f83\u5c0f\u7684\u5173\u5361\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5728 Jax \u4e2d\u5b9e\u73b0\u4e86\u51e0\u4e2a PCGRL \u73af\u5883\uff0c\u4ee5\u4fbf\u5b66\u4e60\u548c\u6a21\u62df\u7684\u6240\u6709\u65b9\u9762\u90fd\u5728 GPU \u4e0a\u5e76\u884c\u53d1\u751f\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5feb\u7684\u73af\u5883\u6a21\u62df\uff1b\u5728 RL \u8bad\u7ec3\u671f\u95f4\u6d88\u9664 CPU-GPU \u4fe1\u606f\u74f6\u9888\u4f20\u8f93\uff1b\u5e76\u6700\u7ec8\u663e\u7740\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u3002\u6211\u4eec\u5728\u8fd9\u4e00\u65b0\u6846\u67b6\u4e2d\u590d\u5236\u4e86\u5148\u524d\u5de5\u4f5c\u7684\u4e00\u4e9b\u5173\u952e\u7ed3\u679c\uff0c\u8ba9\u6a21\u578b\u8bad\u7ec3\u7684\u65f6\u95f4\u6bd4\u4ee5\u524d\u7684\u7814\u7a76\u957f\u5f97\u591a\uff0c\u5e76\u5728 10 \u4ebf\u4e2a\u65f6\u95f4\u6b65\u4e4b\u540e\u8bc4\u4f30\u4e86\u5b83\u4eec\u7684\u884c\u4e3a\u3002\u4e3a\u4e86\u8ba9\u4eba\u7c7b\u8bbe\u8ba1\u5e08\u83b7\u5f97\u66f4\u5927\u7684\u63a7\u5236\u6743\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u968f\u673a\u5173\u5361\u5927\u5c0f\u548c\u5173\u952e\u6e38\u620f\u56fe\u5757\u7684\u51bb\u7ed3\u201c\u5173\u952e\u70b9\u201d\uff0c\u4f5c\u4e3a\u5bf9\u6297\u8fc7\u62df\u5408\u7684\u8fdb\u4e00\u6b65\u65b9\u6cd5\u3002\u4e3a\u4e86\u6d4b\u8bd5\u5b66\u4e60\u751f\u6210\u5668\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6211\u4eec\u5728\u5927\u578b\u3001\u5206\u5e03\u5916\u7684\u5730\u56fe\u5927\u5c0f\u4e0a\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u53d1\u73b0\u90e8\u5206\u89c2\u5bdf\u5927\u5c0f\u5b66\u4e60\u4e86\u66f4\u7a33\u5065\u7684\u8bbe\u8ba1\u7b56\u7565\u3002", "author": "Sam Earle et.al.", "authors": "Sam Earle, Zehua Jiang, Julian Togelius", "id": "2408.12525v1", "paper_url": "http://arxiv.org/abs/2408.12525v1", "repo": "null"}}