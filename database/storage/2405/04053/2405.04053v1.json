{"2405.04053": {"publish_time": "2024-05-07", "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT", "paper_summary": "This research examines the effectiveness of OpenAI's GPT models as\nindependent evaluators of text summaries generated by six transformer-based\nmodels from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.\nWe evaluated these summaries based on essential properties of high-quality\nsummary - conciseness, relevance, coherence, and readability - using\ntraditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,\nwe also employed GPT not as a summarizer but as an evaluator, allowing it to\nindependently assess summary quality without predefined metrics. Our analysis\nrevealed significant correlations between GPT evaluations and traditional\nmetrics, particularly in assessing relevance and coherence. The results\ndemonstrate GPT's potential as a robust tool for evaluating text summaries,\noffering insights that complement established metrics and providing a basis for\ncomparative analysis of transformer-based models in natural language processing\ntasks.", "paper_summary_zh": "\u672c\u7814\u7a76\u6aa2\u8996\u4e86 OpenAI \u7684 GPT \u6a21\u578b\u4f5c\u70ba Hugging Face \u4e2d\u516d\u500bTransformer\u6a21\u578b\uff08DistilBART\u3001BERT\u3001ProphetNet\u3001T5\u3001BART \u548c PEGASUS\uff09\u6240\u7522\u751f\u6587\u5b57\u6458\u8981\u7684\u7368\u7acb\u8a55\u4f30\u54e1\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u6839\u64da\u9ad8\u54c1\u8cea\u6458\u8981\u7684\u57fa\u672c\u5c6c\u6027\uff08\u7c21\u6f54\u6027\u3001\u76f8\u95dc\u6027\u3001\u4e00\u81f4\u6027\u548c\u53ef\u8b80\u6027\uff09\u4f86\u8a55\u4f30\u9019\u4e9b\u6458\u8981\uff0c\u4e26\u4f7f\u7528\u50b3\u7d71\u6307\u6a19\uff0c\u4f8b\u5982 ROUGE \u548c\u6f5b\u5728\u8a9e\u7fa9\u5206\u6790 (LSA)\u3002\u7368\u7279\u7684\u662f\uff0c\u6211\u5011\u4e0d\u50c5\u5c07 GPT \u7528\u4f5c\u6458\u8981\u5de5\u5177\uff0c\u9084\u7528\u4f5c\u8a55\u4f30\u5de5\u5177\uff0c\u8b93\u5b83\u80fd\u5920\u5728\u6c92\u6709\u9810\u5b9a\u7fa9\u6307\u6a19\u7684\u60c5\u6cc1\u4e0b\u7368\u7acb\u8a55\u4f30\u6458\u8981\u54c1\u8cea\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a GPT \u8a55\u4f30\u8207\u50b3\u7d71\u6307\u6a19\u4e4b\u9593\u5b58\u5728\u986f\u8457\u76f8\u95dc\u6027\uff0c\u7279\u5225\u662f\u5728\u8a55\u4f30\u76f8\u95dc\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u3002\u7d50\u679c\u8b49\u660e\u4e86 GPT \u4f5c\u70ba\u8a55\u4f30\u6587\u5b57\u6458\u8981\u7684\u5f37\u5927\u5de5\u5177\u7684\u6f5b\u529b\uff0c\u5b83\u63d0\u4f9b\u7684\u898b\u89e3\u88dc\u5145\u4e86\u65e2\u5b9a\u7684\u6307\u6a19\uff0c\u4e26\u70ba\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2dTransformer\u6a21\u578b\u7684\u6bd4\u8f03\u5206\u6790\u63d0\u4f9b\u4e86\u57fa\u790e\u3002", "author": "Hassan Shakil et.al.", "authors": "Hassan Shakil, Atqiya Munawara Mahi, Phuoc Nguyen, Zeydy Ortiz, Mamoun T. Mardini", "id": "2405.04053v1", "paper_url": "http://arxiv.org/abs/2405.04053v1", "repo": "null"}}