{"2407.21315": {"publish_time": "2024-07-31", "title": "Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances", "paper_summary": "This paper introduces a novel approach to emotion detection in speech using\nLarge Language Models (LLMs). We address the limitation of LLMs in processing\naudio inputs by translating speech characteristics into natural language\ndescriptions. Our method integrates these descriptions into text prompts,\nenabling LLMs to perform multimodal emotion analysis without architectural\nmodifications. We evaluate our approach on two datasets: IEMOCAP and MELD,\ndemonstrating significant improvements in emotion recognition accuracy,\nparticularly for high-quality audio data. Our experiments show that\nincorporating speech descriptions yields a 2 percentage point increase in\nweighted F1 score on IEMOCAP (from 70.111\\% to 72.596\\%). We also compare\nvarious LLM architectures and explore the effectiveness of different feature\nrepresentations. Our findings highlight the potential of this approach in\nenhancing emotion detection capabilities of LLMs and underscore the importance\nof audio quality in speech-based emotion recognition tasks. We'll release the\nsource code on Github.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u8a9e\u97f3\u7684\u60c5\u7dd2\u5075\u6e2c\u3002\u6211\u5011\u900f\u904e\u5c07\u8a9e\u97f3\u7279\u5fb5\u8f49\u63db\u70ba\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\uff0c\u4f86\u89e3\u6c7a LLM \u5728\u8655\u7406\u97f3\u8a0a\u8f38\u5165\u6642\u7684\u9650\u5236\u3002\u6211\u5011\u7684\u6280\u8853\u5c07\u9019\u4e9b\u63cf\u8ff0\u6574\u5408\u5230\u6587\u5b57\u63d0\u793a\u4e2d\uff0c\u8b93 LLM \u80fd\u5920\u5728\u4e0d\u4fee\u6539\u67b6\u69cb\u7684\u60c5\u6cc1\u4e0b\u57f7\u884c\u591a\u6a21\u614b\u7684\u60c5\u7dd2\u5206\u6790\u3002\u6211\u5011\u5728\u5169\u500b\u8cc7\u6599\u96c6\uff1aIEMOCAP \u548c MELD \u4e0a\u8a55\u4f30\u6211\u5011\u7684\u6280\u8853\uff0c\u986f\u793a\u51fa\u5728\u60c5\u7dd2\u8fa8\u8b58\u6e96\u78ba\u5ea6\u4e0a\u5927\u5e45\u63d0\u5347\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u9ad8\u54c1\u8cea\u7684\u97f3\u8a0a\u8cc7\u6599\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u52a0\u5165\u8a9e\u97f3\u63cf\u8ff0\u8b93 IEMOCAP \u4e0a\u7684\u52a0\u6b0a F1 \u5206\u6578\u63d0\u5347\u4e86 2 \u500b\u767e\u5206\u9ede\uff08\u5f9e 70.111% \u5230 72.596%\uff09\u3002\u6211\u5011\u4e5f\u6bd4\u8f03\u4e86\u5404\u7a2e LLM \u67b6\u69cb\uff0c\u4e26\u63a2\u7d22\u4e86\u4e0d\u540c\u7279\u5fb5\u8868\u5fb5\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u7684\u767c\u73fe\u7a81\u986f\u4e86\u9019\u7a2e\u6280\u8853\u5728\u63d0\u5347 LLM \u60c5\u7dd2\u5075\u6e2c\u80fd\u529b\u7684\u6f5b\u529b\uff0c\u4e26\u5f37\u8abf\u4e86\u97f3\u8a0a\u54c1\u8cea\u5728\u57fa\u65bc\u8a9e\u97f3\u7684\u60c5\u7dd2\u8fa8\u8b58\u4efb\u52d9\u4e2d\u7684\u91cd\u8981\u6027\u3002\u6211\u5011\u5c07\u5728 Github \u4e0a\u91cb\u51fa\u539f\u59cb\u78bc\u3002", "author": "Zehui Wu et.al.", "authors": "Zehui Wu, Ziwei Gong, Lin Ai, Pengyuan Shi, Kaan Donbekci, Julia Hirschberg", "id": "2407.21315v2", "paper_url": "http://arxiv.org/abs/2407.21315v2", "repo": "null"}}