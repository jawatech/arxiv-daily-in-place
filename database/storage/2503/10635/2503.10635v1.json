{"2503.10635": {"publish_time": "2025-03-13", "title": "A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1", "paper_summary": "Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.", "paper_summary_zh": "<paragraph>\u5118\u7ba1\u5728\u958b\u6e90\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u57fa\u65bc\u9077\u79fb\u7684\u76ee\u6a19\u653b\u64ca\u901a\u5e38\u5c0d\u9ed1\u7bb1\u5546\u696d LVLMs \u7121\u6548\u3002\u5206\u6790\u5931\u6557\u7684\u5c0d\u6297\u6027\u64fe\u52d5\u767c\u73fe\uff0c\u5b78\u7fd2\u5230\u7684\u64fe\u52d5\u901a\u5e38\u4f86\u81ea\u5747\u52fb\u5206\u4f48\uff0c\u7f3a\u4e4f\u6e05\u6670\u7684\u8a9e\u7fa9\u7d30\u7bc0\uff0c\u5c0e\u81f4\u610f\u5916\u7684\u97ff\u61c9\u3002\u9019\u7a2e\u8a9e\u7fa9\u4fe1\u606f\u7684\u56b4\u91cd\u7f3a\u5931\u5c0e\u81f4\u5546\u696d LVLMs \u8981\u9ebc\u5b8c\u5168\u5ffd\u7565\u64fe\u52d5\uff0c\u8981\u9ebc\u8aa4\u89e3\u5176\u5d4c\u5165\u7684\u8a9e\u7fa9\uff0c\u5f9e\u800c\u5c0e\u81f4\u653b\u64ca\u5931\u6557\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u6ce8\u610f\u5230\u8b58\u5225\u6838\u5fc3\u8a9e\u7fa9\u5c0d\u8c61\u662f\u4f7f\u7528\u5404\u7a2e\u6578\u64da\u96c6\u548c\u65b9\u6cd5\u8a13\u7df4\u6a21\u578b\u7684\u95dc\u9375\u76ee\u6a19\u3002\u9019\u7a2e\u898b\u89e3\u4fc3\u4f7f\u6211\u5011\u63a1\u7528\u4e00\u7a2e\u65b9\u6cd5\uff0c\u901a\u904e\u5728\u5c40\u90e8\u5340\u57df\u5167\u7de8\u78bc\u660e\u78ba\u7684\u8a9e\u7fa9\u7d30\u7bc0\u4f86\u63d0\u9ad8\u8a9e\u7fa9\u6e05\u6670\u5ea6\uff0c\u5f9e\u800c\u78ba\u4fdd\u4e92\u64cd\u4f5c\u6027\u548c\u6355\u7372\u66f4\u7d30\u7c92\u5ea6\u7684\u7279\u5fb5\uff0c\u4e26\u5c07\u4fee\u6539\u96c6\u4e2d\u5728\u8a9e\u7fa9\u8c50\u5bcc\u7684\u5340\u57df\uff0c\u800c\u4e0d\u662f\u5747\u52fb\u61c9\u7528\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u9ad8\u6548\u7684\u89e3\u6c7a\u65b9\u6848\uff1a\u5728\u6bcf\u500b\u512a\u5316\u6b65\u9a5f\u4e2d\uff0c\u5c0d\u6297\u6027\u5716\u50cf\u6703\u4ee5\u53d7\u63a7\u7684\u7e31\u6a6b\u6bd4\u548c\u6bd4\u4f8b\u96a8\u6a5f\u88c1\u526a\uff0c\u8abf\u6574\u5927\u5c0f\uff0c\u7136\u5f8c\u5728\u5d4c\u5165\u7a7a\u9593\u4e2d\u8207\u76ee\u6a19\u5716\u50cf\u5c0d\u9f4a\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u5be6\u4e86\u6211\u5011\u7684\u5047\u8a2d\u3002\u6211\u5011\u7528\u5c40\u90e8\u805a\u5408\u64fe\u52d5\u7cbe\u5fc3\u88fd\u4f5c\u7684\u5c0d\u6297\u6027\u793a\u4f8b\uff0c\u96c6\u4e2d\u5728\u95dc\u9375\u5340\u57df\uff0c\u5c0d\u5546\u696d LVLMs \u8868\u73fe\u51fa\u9a5a\u4eba\u7684\u826f\u597d\u9077\u79fb\u6027\uff0c\u5305\u62ec GPT-4.5\u3001GPT-4o\u3001Gemini-2.0-flash\u3001Claude-3.5-sonnet\u3001Claude-3.7-sonnet\uff0c\u751a\u81f3\u63a8\u7406\u6a21\u578b\uff0c\u5982 o1\u3001Claude-3.7-thinking \u548c Gemini-2.0-flash-thinking\u3002\u6211\u5011\u7684\u65b9\u6cd5\u5728 GPT-4.5\u30014o \u548c o1 \u4e0a\u7684\u6210\u529f\u7387\u8d85\u904e 90%\uff0c\u986f\u8457\u512a\u65bc\u6240\u6709\u5148\u524d\u6700\u5148\u9032\u7684\u653b\u64ca\u65b9\u6cd5\u3002\u6211\u5011\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u512a\u5316\u7684\u5c0d\u6297\u6027\u793a\u4f8b\u548c\u8a13\u7df4\u4ee3\u78bc\u53ef\u5728 https://github.com/VILA-Lab/M-Attack \u7372\u53d6\u3002</paragraph>\n", "author": "Zhaoyi Li et.al.", "authors": "Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen", "id": "2503.10635v1", "paper_url": "http://arxiv.org/abs/2503.10635v1", "repo": "null"}}