{"2501.17132": {"publish_time": "2025-01-28", "title": "ASTRAL: Automated Safety Testing of Large Language Models", "paper_summary": "Large Language Models (LLMs) have recently gained attention due to their\nability to understand and generate sophisticated human-like content. However,\nensuring their safety is paramount as they might provide harmful and unsafe\nresponses. Existing LLM testing frameworks address various safety-related\nconcerns (e.g., drugs, terrorism, animal abuse) but often face challenges due\nto unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool\nthat automates the generation and execution of test cases (i.e., prompts) for\ntesting the safety of LLMs. First, we introduce a novel black-box coverage\ncriterion to generate balanced and diverse unsafe test inputs across a diverse\nset of safety categories as well as linguistic writing characteristics (i.e.,\ndifferent style and persuasive writing techniques). Second, we propose an\nLLM-based approach that leverages Retrieval Augmented Generation (RAG),\nfew-shot prompting strategies and web browsing to generate up-to-date test\ninputs. Lastly, similar to current LLM test automation techniques, we leverage\nLLMs as test oracles to distinguish between safe and unsafe test outputs,\nallowing a fully automated testing approach. We conduct an extensive evaluation\non well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms\nother LLMs when acting as the test oracle, accurately detecting unsafe\nresponses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs\nthat are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard);\nii) the results confirm that our approach can uncover nearly twice as many\nunsafe LLM behaviors with the same number of test inputs compared to currently\nused static datasets; and iii) our black-box coverage criterion combined with\nweb browsing can effectively guide the LLM on generating up-to-date unsafe test\ninputs, significantly increasing the number of unsafe LLM behaviors.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u6700\u8fd1\u56e0\u5176\u7406\u89e3\u548c\u751f\u6210\u8907\u96dc\u7684\u4eba\u985e\u5167\u5bb9\u7684\u80fd\u529b\u800c\u5099\u53d7\u95dc\u6ce8\u3002\u7136\u800c\uff0c\u78ba\u4fdd\u5b83\u5011\u7684\u5b89\u5168\u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba\u5b83\u5011\u53ef\u80fd\u6703\u63d0\u4f9b\u6709\u5bb3\u548c\u4e0d\u5b89\u5168\u7684\u56de\u61c9\u3002\u73fe\u6709\u7684 LLM \u6e2c\u8a66\u6846\u67b6\u89e3\u6c7a\u4e86\u5404\u7a2e\u8207\u5b89\u5168\u76f8\u95dc\u7684\u554f\u984c\uff08\u4f8b\u5982\uff0c\u85e5\u7269\u3001\u6050\u6016\u4e3b\u7fa9\u3001\u8650\u5f85\u52d5\u7269\uff09\uff0c\u4f46\u7531\u65bc\u6578\u64da\u96c6\u4e0d\u5e73\u8861\u548c\u904e\u6642\uff0c\u5b83\u5011\u5e38\u5e38\u9762\u81e8\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 ASTRAL\uff0c\u9019\u662f\u4e00\u500b\u5de5\u5177\uff0c\u53ef\u4ee5\u81ea\u52d5\u751f\u6210\u548c\u57f7\u884c\u6e2c\u8a66\u7528\u4f8b\uff08\u5373\u63d0\u793a\uff09\uff0c\u4ee5\u6e2c\u8a66 LLM \u7684\u5b89\u5168\u6027\u3002\u9996\u5148\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u9ed1\u76d2\u8986\u84cb\u6a19\u6e96\uff0c\u4ee5\u751f\u6210\u8de8\u8d8a\u4e0d\u540c\u5b89\u5168\u985e\u5225\u4ee5\u53ca\u8a9e\u8a00\u5beb\u4f5c\u7279\u5fb5\uff08\u5373\u4e0d\u540c\u98a8\u683c\u548c\u8aaa\u670d\u6027\u5beb\u4f5c\u6280\u5de7\uff09\u7684\u5e73\u8861\u4e14\u591a\u6a23\u5316\u7684\u4e0d\u5b89\u5168\u6e2c\u8a66\u8f38\u5165\u3002\u5176\u6b21\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc LLM \u7684\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u5229\u7528\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u3001\u5c11\u6b21\u63d0\u793a\u7b56\u7565\u548c\u7db2\u7d61\u700f\u89bd\u4f86\u751f\u6210\u6700\u65b0\u7684\u6e2c\u8a66\u8f38\u5165\u3002\u6700\u5f8c\uff0c\u8207\u7576\u524d\u7684 LLM \u6e2c\u8a66\u81ea\u52d5\u5316\u6280\u8853\u985e\u4f3c\uff0c\u6211\u5011\u5229\u7528 LLM \u4f5c\u70ba\u6e2c\u8a66\u9810\u8a00\u4f86\u5340\u5206\u5b89\u5168\u548c\u4e0d\u5b89\u5168\u7684\u6e2c\u8a66\u8f38\u51fa\uff0c\u5f9e\u800c\u5141\u8a31\u5b8c\u5168\u81ea\u52d5\u5316\u7684\u6e2c\u8a66\u65b9\u6cd5\u3002\u6211\u5011\u5c0d\u773e\u6240\u5468\u77e5\u7684 LLM \u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u8a55\u4f30\uff0c\u63ed\u793a\u4e86\u4ee5\u4e0b\u95dc\u9375\u767c\u73fe\uff1ai) GPT3.5 \u5728\u5145\u7576\u6e2c\u8a66\u9810\u8a00\u6642\u512a\u65bc\u5176\u4ed6 LLM\uff0c\u6e96\u78ba\u6aa2\u6e2c\u4e0d\u5b89\u5168\u7684\u97ff\u61c9\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u66f4\u65b0\u7684 LLM\uff08\u4f8b\u5982\uff0cGPT-4\uff09\uff0c\u4ee5\u53ca\u5c08\u9580\u5b9a\u5236\u70ba\u6aa2\u6e2c\u4e0d\u5b89\u5168\u7684 LLM \u8f38\u51fa\u7684 LLM\uff08\u4f8b\u5982\uff0cLlamaGuard\uff09\uff1bii) \u7d50\u679c\u8b49\u5be6\uff0c\u8207\u7576\u524d\u4f7f\u7528\u7684\u975c\u614b\u6578\u64da\u96c6\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u65b9\u6848\u53ef\u4ee5\u7528\u76f8\u540c\u6578\u91cf\u7684\u6e2c\u8a66\u8f38\u5165\u767c\u73fe\u5e7e\u4e4e\u591a\u4e00\u500d\u7684\u4e0d\u5b89\u5168 LLM \u884c\u70ba\uff1biii) \u6211\u5011\u7684\u9ed1\u76d2\u8986\u84cb\u6a19\u6e96\u8207\u7db2\u7d61\u700f\u89bd\u76f8\u7d50\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u6307\u5c0e LLM \u751f\u6210\u6700\u65b0\u7684\u4e0d\u5b89\u5168\u6e2c\u8a66\u8f38\u5165\uff0c\u5f9e\u800c\u986f\u8457\u589e\u52a0\u4e0d\u5b89\u5168 LLM \u884c\u70ba\u7684\u6578\u91cf\u3002</paragraph>", "author": "Miriam Ugarte et.al.", "authors": "Miriam Ugarte, Pablo Valle, Jos\u00e9 Antonio Parejo, Sergio Segura, Aitor Arrieta", "id": "2501.17132v1", "paper_url": "http://arxiv.org/abs/2501.17132v1", "repo": "null"}}