{"2405.03153": {"publish_time": "2024-05-06", "title": "Exploring the Potential of the Large Language Models (LLMs) in Identifying Misleading News Headlines", "paper_summary": "In the digital age, the prevalence of misleading news headlines poses a\nsignificant challenge to information integrity, necessitating robust detection\nmechanisms. This study explores the efficacy of Large Language Models (LLMs) in\nidentifying misleading versus non-misleading news headlines. Utilizing a\ndataset of 60 articles, sourced from both reputable and questionable outlets\nacross health, science & tech, and business domains, we employ three LLMs-\nChatGPT-3.5, ChatGPT-4, and Gemini-for classification. Our analysis reveals\nsignificant variance in model performance, with ChatGPT-4 demonstrating\nsuperior accuracy, especially in cases with unanimous annotator agreement on\nmisleading headlines. The study emphasizes the importance of human-centered\nevaluation in developing LLMs that can navigate the complexities of\nmisinformation detection, aligning technical proficiency with nuanced human\njudgment. Our findings contribute to the discourse on AI ethics, emphasizing\nthe need for models that are not only technically advanced but also ethically\naligned and sensitive to the subtleties of human interpretation.", "paper_summary_zh": "", "author": "Md Main Uddin Rony et.al.", "authors": "Md Main Uddin Rony,Md Mahfuzul Haque,Mohammad Ali,Ahmed Shatil Alam,Naeemul Hassan", "id": "2405.03153v1", "paper_url": "http://arxiv.org/abs/2405.03153v1", "repo": "null"}}