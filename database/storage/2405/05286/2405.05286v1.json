{"2405.05286": {"publish_time": "2024-05-07", "title": "Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights", "paper_summary": "The applications of artificial intelligence (AI) are rapidly evolving, and\nthey are also commonly used in safety-critical domains, such as autonomous\ndriving and medical diagnosis, where functional safety is paramount. In\nAI-driven systems, uncertainty estimation allows the user to avoid\noverconfidence predictions and achieve functional safety. Therefore, the\nrobustness and reliability of model predictions can be improved. However,\nconventional uncertainty estimation methods, such as the deep ensemble method,\nimpose high computation and, accordingly, hardware (latency and energy)\noverhead because they require the storage and processing of multiple models.\nAlternatively, Monte Carlo dropout (MC-dropout) methods, although having low\nmemory overhead, necessitate numerous ($\\sim 100$) forward passes, leading to\nhigh computational overhead and latency. Thus, these approaches are not\nsuitable for battery-powered edge devices with limited computing and memory\nresources. In this paper, we propose the Tiny-Deep Ensemble approach, a\nlow-cost approach for uncertainty estimation on edge devices. In our approach,\nonly normalization layers are ensembled $M$ times, with all ensemble members\nsharing common weights and biases, leading to a significant decrease in storage\nrequirements and latency. Moreover, our approach requires only one forward pass\nin a hardware architecture that allows batch processing for inference and\nuncertainty estimation. Furthermore, it has approximately the same memory\noverhead compared to a single model. Therefore, latency and memory overhead are\nreduced by a factor of up to $\\sim M\\times$. Nevertheless, our method does not\ncompromise accuracy, with an increase in inference accuracy of up to $\\sim 1\\%$\nand a reduction in RMSE of $17.17\\%$ in various benchmark datasets, tasks, and\nstate-of-the-art architectures.", "paper_summary_zh": "<paragraph>\u4eba\u5de5\u667a\u6167 (AI) \u7684\u61c9\u7528\u6b63\u5728\u5feb\u901f\u6f14\u9032\uff0c\u800c\u4e14\u5b83\u5011\u4e5f\u5e38\u88ab\u7528\u65bc\u5b89\u5168\u95dc\u9375\u9818\u57df\uff0c\u4f8b\u5982\u81ea\u52d5\u99d5\u99db\u548c\u91ab\u7642\u8a3a\u65b7\uff0c\u529f\u80fd\u5b89\u5168\u81f3\u95dc\u91cd\u8981\u3002\u5728 AI \u9a45\u52d5\u7684\u7cfb\u7d71\u4e2d\uff0c\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u5141\u8a31\u4f7f\u7528\u8005\u907f\u514d\u904e\u5ea6\u81ea\u4fe1\u7684\u9810\u6e2c\u4e26\u5be6\u73fe\u529f\u80fd\u5b89\u5168\u3002\u56e0\u6b64\uff0c\u6a21\u578b\u9810\u6e2c\u7684\u7a69\u5065\u6027\u548c\u53ef\u9760\u6027\u53ef\u4ee5\u7372\u5f97\u63d0\u5347\u3002\u7136\u800c\uff0c\u50b3\u7d71\u7684\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u65b9\u6cd5\uff0c\u4f8b\u5982\u6df1\u5ea6\u96c6\u6210\u65b9\u6cd5\uff0c\u6703\u9020\u6210\u9ad8\u904b\u7b97\uff0c\u56e0\u6b64\u6709\u786c\u9ad4 (\u5ef6\u9072\u548c\u80fd\u6e90) \u7684\u958b\u92b7\uff0c\u56e0\u70ba\u5b83\u5011\u9700\u8981\u5132\u5b58\u548c\u8655\u7406\u591a\u500b\u6a21\u578b\u3002\u53ef\u9078\u64c7\u7684\u8499\u5730\u5361\u7f85\u4e2d\u65b7 (MC-dropout) \u65b9\u6cd5\uff0c\u5118\u7ba1\u8a18\u61b6\u9ad4\u958b\u92b7\u4f4e\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684 ($\\sim 100$) \u524d\u5411\u50b3\u905e\uff0c\u5c0e\u81f4\u9ad8\u904b\u7b97\u958b\u92b7\u548c\u5ef6\u9072\u3002\u56e0\u6b64\uff0c\u9019\u4e9b\u65b9\u6cd5\u4e0d\u9069\u5408\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u8cc7\u6e90\u6709\u9650\u7684\u96fb\u6c60\u4f9b\u96fb\u908a\u7de3\u88dd\u7f6e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Tiny-Deep Ensemble \u65b9\u6cd5\uff0c\u4e00\u7a2e\u5728\u908a\u7de3\u88dd\u7f6e\u4e0a\u9032\u884c\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u7684\u4f4e\u6210\u672c\u65b9\u6cd5\u3002\u5728\u6211\u5011\u7684\u65b9\u6cd5\u4e2d\uff0c\u53ea\u6709\u6b63\u898f\u5316\u5c64\u88ab\u96c6\u6210 $M$ \u6b21\uff0c\u6240\u6709\u96c6\u6210\u6210\u54e1\u5171\u4eab\u5171\u540c\u7684\u6b0a\u91cd\u548c\u504f\u5dee\uff0c\u5c0e\u81f4\u5132\u5b58\u9700\u6c42\u548c\u5ef6\u9072\u986f\u8457\u964d\u4f4e\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u53ea\u5728\u786c\u9ad4\u67b6\u69cb\u4e2d\u9700\u8981\u4e00\u6b21\u524d\u5411\u50b3\u905e\uff0c\u8a72\u67b6\u69cb\u5141\u8a31\u6279\u6b21\u8655\u7406\u4ee5\u9032\u884c\u63a8\u8ad6\u548c\u4e0d\u78ba\u5b9a\u6027\u4f30\u8a08\u3002\u6b64\u5916\uff0c\u8207\u55ae\u4e00\u6a21\u578b\u76f8\u6bd4\uff0c\u5b83\u5927\u7d04\u6709\u76f8\u540c\u7684\u8a18\u61b6\u9ad4\u958b\u92b7\u3002\u56e0\u6b64\uff0c\u5ef6\u9072\u548c\u8a18\u61b6\u9ad4\u958b\u92b7\u6700\u591a\u53ef\u6e1b\u5c11 $\\sim M\\times$ \u500d\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e26\u672a\u640d\u5bb3\u6e96\u78ba\u6027\uff0c\u5728\u5404\u7a2e\u57fa\u6e96\u8cc7\u6599\u96c6\u3001\u4efb\u52d9\u548c\u6700\u5148\u9032\u7684\u67b6\u69cb\u4e2d\uff0c\u63a8\u7406\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 $\\sim 1\\%$\uff0cRMSE \u964d\u4f4e\u4e86 $17.17\\%$\u3002</paragraph>", "author": "Soyed Tuhin Ahmed et.al.", "authors": "Soyed Tuhin Ahmed, Michael Hefenbrock, Mehdi B. Tahoori", "id": "2405.05286v1", "paper_url": "http://arxiv.org/abs/2405.05286v1", "repo": "null"}}