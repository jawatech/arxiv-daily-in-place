{"2408.14153": {"publish_time": "2024-08-26", "title": "Explaining Vision-Language Similarities in Dual Encoders with Feature-Pair Attributions", "paper_summary": "Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and learn similarities between them. However, it is not\nunderstood how such models compare two inputs. Here, we address this research\ngap with two contributions. First, we derive a method to attribute predictions\nof any differentiable dual encoder onto feature-pair interactions between its\ninputs. Second, we apply our method to CLIP-type models and show that they\nlearn fine-grained correspondences between parts of captions and regions in\nimages. They match objects across input modes and also account for mismatches.\nHowever, this visual-linguistic grounding ability heavily varies between object\nclasses, depends on the training data distribution, and largely improves after\nin-domain training. Using our method we can identify knowledge gaps about\nspecific object classes in individual models and can monitor their improvement\nupon fine-tuning.", "paper_summary_zh": "\u96d9\u7de8\u78bc\u5668\u67b6\u69cb\uff0c\u5982 CLIP \u6a21\u578b\uff0c\u5c07\u5169\u7a2e\u8f38\u5165\u985e\u578b\u6620\u5c04\u5230\u5171\u4eab\u5d4c\u5165\u7a7a\u9593\uff0c\u4e26\u5b78\u7fd2\u5b83\u5011\u4e4b\u9593\u7684\u76f8\u4f3c\u6027\u3002\u7136\u800c\uff0c\u5c1a\u4e0d\u6e05\u695a\u6b64\u985e\u6a21\u578b\u5982\u4f55\u6bd4\u8f03\u5169\u500b\u8f38\u5165\u3002\u5728\u6b64\uff0c\u6211\u5011\u4ee5\u5169\u500b\u8ca2\u737b\u4f86\u89e3\u6c7a\u9019\u500b\u7814\u7a76\u5dee\u8ddd\u3002\u9996\u5148\uff0c\u6211\u5011\u63a8\u5c0e\u51fa\u4e00\u7a2e\u65b9\u6cd5\uff0c\u5c07\u4efb\u4f55\u53ef\u5fae\u5206\u96d9\u7de8\u78bc\u5668\u7684\u9810\u6e2c\u6b78\u56e0\u65bc\u5176\u8f38\u5165\u4e4b\u9593\u7684\u7279\u5fb5\u5c0d\u4ea4\u4e92\u3002\u5176\u6b21\uff0c\u6211\u5011\u5c07\u6211\u5011\u7684\u6a21\u578b\u61c9\u7528\u5230 CLIP \u985e\u578b\u6a21\u578b\uff0c\u4e26\u5c55\u793a\u5b83\u5011\u5b78\u7fd2\u4e86\u6a19\u984c\u90e8\u5206\u548c\u5716\u50cf\u5340\u57df\u4e4b\u9593\u7684\u7d30\u7c92\u5ea6\u5c0d\u61c9\u95dc\u4fc2\u3002\u5b83\u5011\u8de8\u8f38\u5165\u6a21\u5f0f\u5339\u914d\u5c0d\u8c61\uff0c\u4e26\u8003\u616e\u4e0d\u5339\u914d\u3002\u7136\u800c\uff0c\u9019\u7a2e\u8996\u89ba\u8a9e\u8a00\u57fa\u790e\u80fd\u529b\u5728\u5c0d\u8c61\u985e\u5225\u4e4b\u9593\u5dee\u7570\u5f88\u5927\uff0c\u53d6\u6c7a\u65bc\u8a13\u7df4\u6578\u64da\u5206\u4f48\uff0c\u4e26\u4e14\u5728\u57df\u5167\u8a13\u7df4\u5f8c\u5927\u5e45\u6539\u5584\u3002\u4f7f\u7528\u6211\u5011\u7684\u6a21\u578b\uff0c\u6211\u5011\u53ef\u4ee5\u8b58\u5225\u500b\u5225\u6a21\u578b\u4e2d\u7279\u5b9a\u5c0d\u8c61\u985e\u5225\u7684\u77e5\u8b58\u5dee\u8ddd\uff0c\u4e26\u76e3\u63a7\u5b83\u5011\u5728\u5fae\u8abf\u5f8c\u7684\u6539\u9032\u3002", "author": "Lucas M\u00f6ller et.al.", "authors": "Lucas M\u00f6ller, Pascal Tilli, Ngoc Thang Vu, Sebastian Pad\u00f3", "id": "2408.14153v1", "paper_url": "http://arxiv.org/abs/2408.14153v1", "repo": "null"}}