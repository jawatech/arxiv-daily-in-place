{"2411.07446": {"publish_time": "2024-11-12", "title": "Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection", "paper_summary": "Automatic prompt engineering aims to enhance the generation quality of large\nlanguage models (LLMs). Recent works utilize feedbacks generated from erroneous\ncases to guide the prompt optimization. During inference, they may further\nretrieve several semantically-related exemplars and concatenate them to the\noptimized prompts to improve the performance. However, those works only utilize\nthe feedback at the current step, ignoring historical and unseleccted feedbacks\nwhich are potentially beneficial. Moreover, the selection of exemplars only\nconsiders the general semantic relationship and may not be optimal in terms of\ntask performance and matching with the optimized prompt. In this work, we\npropose an Exemplar-Guided Reflection with Memory mechanism (ERM) to realize\nmore efficient and accurate prompt optimization. Specifically, we design an\nexemplar-guided reflection mechanism where the feedback generation is\nadditionally guided by the generated exemplars. We further build two kinds of\nmemory to fully utilize the historical feedback information and support more\neffective exemplar retrieval. Empirical evaluations show our method surpasses\nprevious state-of-the-arts with less optimization steps, i.e., improving F1\nscore by 10.1 on LIAR dataset, and reducing half of the optimization steps on\nProTeGi.", "paper_summary_zh": "\u81ea\u52d5\u63d0\u793a\u5de5\u7a0b\u65e8\u5728\u63d0\u5347\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u751f\u6210\u54c1\u8cea\u3002\u8fd1\u671f\u7814\u7a76\u5229\u7528\u932f\u8aa4\u6848\u4f8b\u7522\u751f\u7684\u56de\u994b\u4f86\u5f15\u5c0e\u63d0\u793a\u6700\u4f73\u5316\u3002\u5728\u63a8\u8ad6\u904e\u7a0b\u4e2d\uff0c\u5b83\u5011\u53ef\u80fd\u6703\u9032\u4e00\u6b65\u64f7\u53d6\u5e7e\u500b\u8a9e\u7fa9\u76f8\u95dc\u7684\u7bc4\u4f8b\uff0c\u4e26\u5c07\u5b83\u5011\u4e32\u63a5\u81f3\u6700\u4f73\u5316\u7684\u63d0\u793a\u4ee5\u63d0\u5347\u6548\u80fd\u3002\u7136\u800c\uff0c\u9019\u4e9b\u7814\u7a76\u50c5\u5229\u7528\u7576\u524d\u6b65\u9a5f\u7684\u56de\u994b\uff0c\u5ffd\u7565\u4e86\u6f5b\u5728\u6709\u76ca\u7684\u6b77\u53f2\u56de\u994b\u548c\u672a\u9078\u64c7\u7684\u56de\u994b\u3002\u6b64\u5916\uff0c\u7bc4\u4f8b\u7684\u9078\u64c7\u50c5\u8003\u616e\u4e00\u822c\u8a9e\u7fa9\u95dc\u4fc2\uff0c\u5c31\u4efb\u52d9\u6548\u80fd\u548c\u8207\u6700\u4f73\u5316\u63d0\u793a\u7684\u5339\u914d\u800c\u8a00\u53ef\u80fd\u4e0d\u662f\u6700\u4f73\u7684\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5177\u6709\u8a18\u61b6\u6a5f\u5236\u7684\u7bc4\u4f8b\u5f15\u5c0e\u53cd\u601d (ERM)\uff0c\u4ee5\u5be6\u73fe\u66f4\u6709\u6548\u7387\u4e14\u6e96\u78ba\u7684\u63d0\u793a\u6700\u4f73\u5316\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8a2d\u8a08\u4e00\u500b\u7bc4\u4f8b\u5f15\u5c0e\u53cd\u601d\u6a5f\u5236\uff0c\u5176\u4e2d\u56de\u994b\u7522\u751f\u9032\u4e00\u6b65\u7531\u7522\u751f\u7684\u7bc4\u4f8b\u5f15\u5c0e\u3002\u6211\u5011\u9032\u4e00\u6b65\u5efa\u69cb\u5169\u7a2e\u8a18\u61b6\u9ad4\uff0c\u4ee5\u5145\u5206\u5229\u7528\u6b77\u53f2\u56de\u994b\u8cc7\u8a0a\uff0c\u4e26\u652f\u63f4\u66f4\u6709\u6548\u7684\u7bc4\u4f8b\u64f7\u53d6\u3002\u7d93\u9a57\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u4ee5\u66f4\u5c11\u7684\u6700\u4f73\u5316\u6b65\u9a5f\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u6280\u8853\u6c34\u6e96\uff0c\u4ea6\u5373\u5728 LIAR \u8cc7\u6599\u96c6\u4e0a\u5c07 F1 \u5206\u6578\u63d0\u5347\u4e86 10.1\uff0c\u4e26\u5728 ProTeGi \u4e0a\u6e1b\u5c11\u4e86\u4e00\u534a\u7684\u6700\u4f73\u5316\u6b65\u9a5f\u3002", "author": "Cilin Yan et.al.", "authors": "Cilin Yan, Jingyun Wang, Lin Zhang, Ruihui Zhao, Xiaopu Wu, Kai Xiong, Qingsong Liu, Guoliang Kang, Yangyang Kang", "id": "2411.07446v1", "paper_url": "http://arxiv.org/abs/2411.07446v1", "repo": "null"}}