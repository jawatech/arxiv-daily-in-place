{"2501.11721": {"publish_time": "2025-01-20", "title": "Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy", "paper_summary": "Large language models (LLMs) have demonstrated remarkable proficiency in\ngenerating detailed and coherent explanations of complex concepts. However, the\nextent to which these models truly comprehend the concepts they articulate\nremains unclear. To assess the level of comprehension of a model relative to\nthe content it generates, we implemented a self-evaluation pipeline where\nmodels: (i) given a topic generate an excerpt with information about the topic,\n(ii) given an excerpt generate question-answer pairs, and finally (iii) given a\nquestion generate an answer. We refer to this self-evaluation approach as\nExplain-Query-Test (EQT). Interestingly, the accuracy on generated questions\nresulting from running the EQT pipeline correlates strongly with the model\nperformance as verified by typical benchmarks such as MMLU-Pro. In other words,\nEQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank\nmodels without the need for any external source of evaluation data other than\nlists of topics of interest. Moreover, our results reveal a disparity between\nthe models' ability to produce detailed explanations and their performance on\nquestions related to those explanations. This gap highlights fundamental\nlimitations in the internal knowledge representation and reasoning abilities of\ncurrent LLMs. We release the code at https://github.com/asgsaeid/EQT.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u719f\u7df4\u5ea6\uff0c\u80fd\u7522\u751f\u8907\u96dc\u6982\u5ff5\u7684\u8a73\u7d30\u4e14\u9023\u8cab\u7684\u89e3\u91cb\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u5b83\u5011\u6240\u8868\u9054\u7684\u6982\u5ff5\uff0c\u9019\u4e00\u9ede\u4ecd\u4e0d\u6e05\u695a\u3002\u70ba\u4e86\u8a55\u4f30\u6a21\u578b\u76f8\u5c0d\u65bc\u5b83\u6240\u7522\u751f\u5167\u5bb9\u7684\u7406\u89e3\u7a0b\u5ea6\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u500b\u81ea\u6211\u8a55\u4f30\u7ba1\u9053\uff0c\u5176\u4e2d\u6a21\u578b\uff1a(i) \u7d66\u5b9a\u4e00\u500b\u4e3b\u984c\uff0c\u7522\u751f\u4e00\u6bb5\u5305\u542b\u95dc\u65bc\u8a72\u4e3b\u984c\u7684\u8cc7\u8a0a\u7684\u6458\u9304\uff0c(ii) \u7d66\u5b9a\u4e00\u500b\u6458\u9304\uff0c\u7522\u751f\u554f\u984c-\u7b54\u6848\u5c0d\uff0c\u6700\u5f8c (iii) \u7d66\u5b9a\u4e00\u500b\u554f\u984c\uff0c\u7522\u751f\u4e00\u500b\u7b54\u6848\u3002\u6211\u5011\u5c07\u9019\u7a2e\u81ea\u6211\u8a55\u4f30\u65b9\u6cd5\u7a31\u70ba\u300c\u89e3\u91cb-\u67e5\u8a62-\u6e2c\u8a66\u300d(EQT)\u3002\u6709\u8da3\u7684\u662f\uff0c\u57f7\u884c EQT \u7ba1\u9053\u6240\u7522\u751f\u7684\u554f\u984c\u7684\u6e96\u78ba\u6027\u8207\u6a21\u578b\u6548\u80fd\u5bc6\u5207\u76f8\u95dc\uff0c\u9019\u5df2\u7531\u5178\u578b\u7684\u57fa\u6e96\uff08\u4f8b\u5982 MMLU-Pro\uff09\u9a57\u8b49\u3002\u63db\u53e5\u8a71\u8aaa\uff0cEQT \u7684\u6548\u80fd\u53ef\u4ee5\u9810\u6e2c MMLU-Pro \u7684\u6548\u80fd\uff0c\u4e14 EQT \u53ef\u7528\u65bc\u5c0d\u6a21\u578b\u9032\u884c\u6392\u540d\uff0c\u800c\u7121\u9700\u4efb\u4f55\u5916\u90e8\u8a55\u4f30\u8cc7\u6599\u4f86\u6e90\uff0c\u53ea\u8981\u6709\u611f\u8208\u8da3\u7684\u4e3b\u984c\u6e05\u55ae\u5373\u53ef\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u7d50\u679c\u63ed\u793a\u4e86\u6a21\u578b\u7522\u751f\u8a73\u7d30\u89e3\u91cb\u7684\u80fd\u529b\u8207\u5b83\u5011\u5c0d\u8207\u9019\u4e9b\u89e3\u91cb\u76f8\u95dc\u7684\u554f\u984c\u7684\u6548\u80fd\u4e4b\u9593\u7684\u5dee\u7570\u3002\u9019\u500b\u5dee\u8ddd\u7a81\u986f\u4e86\u7576\u524d LLM \u5728\u5167\u90e8\u77e5\u8b58\u8868\u793a\u548c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6839\u672c\u9650\u5236\u3002\u6211\u5011\u5728 https://github.com/asgsaeid/EQT \u91cb\u51fa\u7a0b\u5f0f\u78bc\u3002", "author": "Saeid Asgari Taghanaki et.al.", "authors": "Saeid Asgari Taghanaki, Joao Monteiro", "id": "2501.11721v1", "paper_url": "http://arxiv.org/abs/2501.11721v1", "repo": "https://github.com/asgsaeid/eqt"}}