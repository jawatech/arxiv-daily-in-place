{"2405.03401": {"publish_time": "2024-05-06", "title": "E2GNN: Efficient Graph Neural Network Ensembles for Semi-Supervised Classification", "paper_summary": "This work studies ensemble learning for graph neural networks (GNNs) under\nthe popular semi-supervised setting. Ensemble learning has shown superiority in\nimproving the accuracy and robustness of traditional machine learning by\ncombining the outputs of multiple weak learners. However, adopting a similar\nidea to integrate different GNN models is challenging because of two reasons.\nFirst, GNN is notorious for its poor inference ability, so naively assembling\nmultiple GNN models would deteriorate the inference efficiency. Second, when\nGNN models are trained with few labeled nodes, their performance are limited.\nIn this case, the vanilla ensemble approach, e.g., majority vote, may be\nsub-optimal since most base models, i.e., GNNs, may make the wrong predictions.\nTo this end, in this paper, we propose an efficient ensemble learner--E2GNN to\nassemble multiple GNNs in a learnable way by leveraging both labeled and\nunlabeled nodes. Specifically, we first pre-train different GNN models on a\ngiven data scenario according to the labeled nodes. Next, instead of directly\ncombing their outputs for label inference, we train a simple multi-layer\nperceptron--MLP model to mimic their predictions on both labeled and unlabeled\nnodes. Then the unified MLP model is deployed to infer labels for unlabeled or\nnew nodes. Since the predictions of unlabeled nodes from different GNN models\nmay be incorrect, we develop a reinforced discriminator to effectively filter\nout those wrongly predicted nodes to boost the performance of MLP. By doing\nthis, we suggest a principled approach to tackle the inference issues of GNN\nensembles and maintain the merit of ensemble learning: improved performance.\nComprehensive experiments over both transductive and inductive settings, across\ndifferent GNN backbones and 8 benchmark datasets, demonstrate the superiority\nof E2GNN.", "paper_summary_zh": "", "author": "Xin Zhang et.al.", "authors": "Xin Zhang,Daochen Zha,Qiaoyu Tan", "id": "2405.03401v1", "paper_url": "http://arxiv.org/abs/2405.03401v1", "repo": "null"}}