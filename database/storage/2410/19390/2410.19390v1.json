{"2410.19390": {"publish_time": "2024-10-25", "title": "CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation", "paper_summary": "Obtaining well-calibrated photometric redshift probability densities for\ngalaxies without a spectroscopic measurement remains a challenge. Deep learning\ndiscriminative models, typically fed with multi-band galaxy images, can produce\noutputs that mimic probability densities and achieve state-of-the-art accuracy.\nHowever, such models may be affected by miscalibration that would result in\ndiscrepancies between the model outputs and the actual distributions of true\nredshifts. Our work develops a novel method called the Contrastive Learning and\nAdaptive KNN for Photometric Redshift (CLAP) that resolves this issue. It\nleverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)\nto construct and calibrate raw probability density estimates, and implements a\nrefitting procedure to resume end-to-end discriminative models ready to produce\nfinal estimates for large-scale imaging data. The harmonic mean is adopted to\ncombine an ensemble of estimates from multiple realisations for improving\naccuracy. Our experiments demonstrate that CLAP takes advantage of both deep\nlearning and KNN, outperforming benchmark methods on the calibration of\nprobability density estimates and retaining high accuracy and computational\nefficiency. With reference to CLAP, we point out that miscalibration is\nparticularly sensitive to the method-induced excessive correlations among data\ninstances in addition to the unaccounted-for epistemic uncertainties. Reducing\nthe uncertainties may not guarantee the removal of miscalibration due to the\npresence of such excessive correlations, yet this is a problem for conventional\ndeep learning methods rather than CLAP. These discussions underscore the\nrobustness of CLAP for obtaining photometric redshift probability densities\nrequired by astrophysical and cosmological applications. This is the first\npaper in our series on CLAP.", "paper_summary_zh": "\u53d6\u5f97\u6ca1\u6709\u5149\u8c31\u6d4b\u91cf\u7684\u661f\u7cfb\u7684\u6821\u51c6\u826f\u597d\u7684\u5149\u5ea6\u7ea2\u79fb\u6982\u7387\u5bc6\u5ea6\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u6df1\u5ea6\u5b66\u4e60\u5224\u522b\u6a21\u578b\u901a\u5e38\u4ee5\u591a\u6ce2\u6bb5\u661f\u7cfb\u56fe\u50cf\u4e3a\u98df\uff0c\u53ef\u4ee5\u4ea7\u751f\u6a21\u4eff\u6982\u7387\u5bc6\u5ea6\u5e76\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u7684\u8f93\u51fa\u3002\u7136\u800c\uff0c\u6b64\u7c7b\u6a21\u578b\u53ef\u80fd\u4f1a\u53d7\u5230\u9519\u8bef\u6821\u51c6\u7684\u5f71\u54cd\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u4e0e\u771f\u5b9e\u7ea2\u79fb\u7684\u5b9e\u9645\u5206\u5e03\u4e4b\u95f4\u51fa\u73b0\u5dee\u5f02\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u5f00\u53d1\u4e86\u4e00\u79cd\u79f0\u4e3a\u5bf9\u6bd4\u5b66\u4e60\u548c\u81ea\u9002\u5e94 KNN \u5149\u5ea6\u7ea2\u79fb (CLAP) \u7684\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5b83\u5229\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60 (SCL) \u548c k \u6700\u8fd1\u90bb (KNN) \u6765\u6784\u5efa\u548c\u6821\u51c6\u539f\u59cb\u6982\u7387\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u5e76\u5b9e\u65bd\u91cd\u65b0\u62df\u5408\u7a0b\u5e8f\u4ee5\u6062\u590d\u7aef\u5230\u7aef\u5224\u522b\u6a21\u578b\uff0c\u4ee5\u4fbf\u4e3a\u5927\u89c4\u6a21\u6210\u50cf\u6570\u636e\u751f\u6210\u6700\u7ec8\u4f30\u8ba1\u3002\u91c7\u7528\u8c03\u548c\u5e73\u5747\u503c\u6765\u7ec4\u5408\u6765\u81ea\u591a\u4e2a\u5b9e\u73b0\u7684\u4f30\u8ba1\u96c6\u5408\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCLAP \u540c\u65f6\u5229\u7528\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c KNN\uff0c\u5728\u6982\u7387\u5bc6\u5ea6\u4f30\u8ba1\u7684\u6821\u51c6\u4e0a\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002\u53c2\u8003 CLAP\uff0c\u6211\u4eec\u6307\u51fa\u6821\u51c6\u4e0d\u826f\u5bf9\u65b9\u6cd5\u5f15\u8d77\u7684\u9664\u4e86\u672a\u8003\u8651\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e4b\u5916\u7684\u6570\u636e\u5b9e\u4f8b\u4e4b\u95f4\u7684\u8fc7\u5ea6\u76f8\u5173\u6027\u7279\u522b\u654f\u611f\u3002\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u6d88\u9664\u9519\u8bef\u6821\u51c6\uff0c\u56e0\u4e3a\u5b58\u5728\u8fd9\u79cd\u8fc7\u5ea6\u76f8\u5173\u6027\uff0c\u4f46\u5bf9\u4e8e\u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6765\u8bf4\u8fd9\u662f\u4e00\u4e2a\u95ee\u9898\uff0c\u800c\u4e0d\u662f CLAP\u3002\u8fd9\u4e9b\u8ba8\u8bba\u5f3a\u8c03\u4e86 CLAP \u5728\u83b7\u53d6\u5929\u4f53\u7269\u7406\u548c\u5b87\u5b99\u5b66\u5e94\u7528\u6240\u9700\u7684\u7ea2\u79fb\u6982\u7387\u5bc6\u5ea6\u65b9\u9762\u7684\u9c81\u68d2\u6027\u3002\u8fd9\u662f\u6211\u4eec\u5173\u4e8e CLAP \u7684\u7cfb\u5217\u6587\u7ae0\u4e2d\u7684\u7b2c\u4e00\u7bc7\u3002", "author": "Qiufan Lin et.al.", "authors": "Qiufan Lin, Hengxin Ruan, Dominique Fouchez, Shupei Chen, Rui Li, Paulo Montero-Camacho, Nicola R. Napolitano, Yuan-Sen Ting, Wei Zhang", "id": "2410.19390v1", "paper_url": "http://arxiv.org/abs/2410.19390v1", "repo": "https://github.com/QiufanLin/CLAP-I"}}