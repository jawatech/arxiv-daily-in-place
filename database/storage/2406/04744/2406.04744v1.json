{"2406.04744": {"publish_time": "2024-06-07", "title": "CRAG -- Comprehensive RAG Benchmark", "paper_summary": "Retrieval-Augmented Generation (RAG) has recently emerged as a promising\nsolution to alleviate Large Language Model (LLM)'s deficiency in lack of\nknowledge. Existing RAG datasets, however, do not adequately represent the\ndiverse and dynamic nature of real-world Question Answering (QA) tasks. To\nbridge this gap, we introduce the Comprehensive RAG Benchmark (CRAG), a factual\nquestion answering benchmark of 4,409 question-answer pairs and mock APIs to\nsimulate web and Knowledge Graph (KG) search. CRAG is designed to encapsulate a\ndiverse array of questions across five domains and eight question categories,\nreflecting varied entity popularity from popular to long-tail, and temporal\ndynamisms ranging from years to seconds. Our evaluation on this benchmark\nhighlights the gap to fully trustworthy QA. Whereas most advanced LLMs achieve\n<=34% accuracy on CRAG, adding RAG in a straightforward manner improves the\naccuracy only to 44%. State-of-the-art industry RAG solutions only answer 63%\nquestions without any hallucination. CRAG also reveals much lower accuracy in\nanswering questions regarding facts with higher dynamism, lower popularity, or\nhigher complexity, suggesting future research directions. The CRAG benchmark\nlaid the groundwork for a KDD Cup 2024 challenge, attracting thousands of\nparticipants and submissions within the first 50 days of the competition. We\ncommit to maintaining CRAG to serve research communities in advancing RAG\nsolutions and general QA solutions.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u6700\u8fd1\u4f5c\u70ba\u4e00\u7a2e\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\u51fa\u73fe\uff0c\u4ee5\u7de9\u89e3\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u77e5\u8b58\u7f3a\u4e4f\u65b9\u9762\u7684\u7f3a\u9677\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 RAG \u8cc7\u6599\u96c6\u4e26\u4e0d\u80fd\u5145\u5206\u4ee3\u8868\u73fe\u5be6\u4e16\u754c\u554f\u7b54 (QA) \u4efb\u52d9\u7684\u591a\u6a23\u6027\u548c\u52d5\u614b\u6027\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u4e00\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86\u7d9c\u5408 RAG \u57fa\u6e96 (CRAG)\uff0c\u9019\u662f\u4e00\u500b\u7531 4,409 \u500b\u554f\u7b54\u5c0d\u548c\u6a21\u64ec\u7db2\u8def\u548c\u77e5\u8b58\u5716\u8b5c (KG) \u641c\u5c0b\u7684\u6a21\u64ec API \u7d44\u6210\u7684\u57fa\u65bc\u4e8b\u5be6\u7684\u554f\u7b54\u57fa\u6e96\u3002CRAG \u88ab\u8a2d\u8a08\u6210\u56ca\u62ec\u8de8\u8d8a\u4e94\u500b\u9818\u57df\u548c\u516b\u500b\u554f\u984c\u985e\u5225\u7684\u5404\u7a2e\u554f\u984c\uff0c\u53cd\u6620\u4e86\u5f9e\u6d41\u884c\u5230\u9577\u5c3e\u7684\u5404\u7a2e\u5be6\u9ad4\u6d41\u884c\u5ea6\uff0c\u4ee5\u53ca\u5f9e\u5e74\u5230\u79d2\u7684\u6642\u9593\u52d5\u614b\u3002\u6211\u5011\u5c0d\u6b64\u57fa\u6e96\u7684\u8a55\u4f30\u7a81\u51fa\u4e86\u5b8c\u5168\u503c\u5f97\u4fe1\u8cf4\u7684 QA \u7684\u5dee\u8ddd\u3002\u5118\u7ba1\u5927\u591a\u6578\u5148\u9032\u7684 LLM \u5728 CRAG \u4e0a\u7684\u6e96\u78ba\u7387\u4f4e\u65bc\u7b49\u65bc 34%\uff0c\u4f46\u4ee5\u4e00\u7a2e\u76f4\u63a5\u7684\u65b9\u5f0f\u6dfb\u52a0 RAG \u50c5\u5c07\u6e96\u78ba\u7387\u63d0\u9ad8\u5230 44%\u3002\u6700\u5148\u9032\u7684\u7522\u696d RAG \u89e3\u6c7a\u65b9\u6848\u50c5\u56de\u7b54 63% \u7684\u554f\u984c\uff0c\u4e14\u6c92\u6709\u4efb\u4f55\u5e7b\u89ba\u3002CRAG \u9084\u986f\u793a\u5728\u56de\u7b54\u5177\u6709\u66f4\u9ad8\u52d5\u614b\u6027\u3001\u8f03\u4f4e\u6d41\u884c\u5ea6\u6216\u66f4\u9ad8\u8907\u96dc\u6027\u7684\u4e8b\u5be6\u76f8\u95dc\u554f\u984c\u6642\u6e96\u78ba\u7387\u8981\u4f4e\u5f97\u591a\uff0c\u9019\u8868\u660e\u4e86\u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\u3002CRAG \u57fa\u6e96\u70ba 2024 \u5e74 KDD \u676f\u6311\u6230\u8cfd\u5960\u5b9a\u4e86\u57fa\u790e\uff0c\u5728\u6bd4\u8cfd\u958b\u59cb\u5f8c\u7684\u524d 50 \u5929\u5167\u5438\u5f15\u4e86\u6578\u5343\u540d\u53c3\u8207\u8005\u548c\u63d0\u4ea4\u3002\u6211\u5011\u627f\u8afe\u7dad\u8b77 CRAG\uff0c\u4ee5\u670d\u52d9\u65bc\u7814\u7a76\u793e\u7fa4\uff0c\u63a8\u9032 RAG \u89e3\u6c7a\u65b9\u6848\u548c\u4e00\u822c QA \u89e3\u6c7a\u65b9\u6848\u3002", "author": "Xiao Yang et.al.", "authors": "Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong", "id": "2406.04744v1", "paper_url": "http://arxiv.org/abs/2406.04744v1", "repo": "null"}}