{"2405.05508": {"publish_time": "2024-05-09", "title": "Redefining Information Retrieval of Structured Database via Large Language Models", "paper_summary": "Retrieval augmentation is critical when Language Models (LMs) exploit\nnon-parametric knowledge related to the query through external knowledge bases\nbefore reasoning. The retrieved information is incorporated into LMs as context\nalongside the query, enhancing the reliability of responses towards factual\nquestions. Prior researches in retrieval augmentation typically follow a\nretriever-generator paradigm. In this context, traditional retrievers encounter\nchallenges in precisely and seamlessly extracting query-relevant information\nfrom knowledge bases. To address this issue, this paper introduces a novel\nretrieval augmentation framework called ChatLR that primarily employs the\npowerful semantic understanding ability of Large Language Models (LLMs) as\nretrievers to achieve precise and concise information retrieval. Additionally,\nwe construct an LLM-based search and question answering system tailored for the\nfinancial domain by fine-tuning LLM on two tasks including Text2API and API-ID\nrecognition. Experimental results demonstrate the effectiveness of ChatLR in\naddressing user queries, achieving an overall information retrieval accuracy\nexceeding 98.8\\%.", "paper_summary_zh": "\u68c0\u7d22\u589e\u5f3a\u5bf9\u4e8e\u8bed\u8a00\u6a21\u578b (LM) \u5728\u63a8\u7406\u4e4b\u524d\u901a\u8fc7\u5916\u90e8\u77e5\u8bc6\u5e93\u5229\u7528\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u975e\u53c2\u6570\u77e5\u8bc6\u81f3\u5173\u91cd\u8981\u3002\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u4e0e\u67e5\u8be2\u4e00\u8d77\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u5408\u5e76\u5230 LM \u4e2d\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u5bf9\u4e8b\u5b9e\u95ee\u9898\u7684\u54cd\u5e94\u7684\u53ef\u9760\u6027\u3002\u68c0\u7d22\u589e\u5f3a\u4e2d\u7684\u5148\u524d\u7814\u7a76\u901a\u5e38\u9075\u5faa\u68c0\u7d22\u5668\u751f\u6210\u5668\u8303\u4f8b\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u68c0\u7d22\u5668\u5728\u4ece\u77e5\u8bc6\u5e93\u4e2d\u7cbe\u786e\u65e0\u7f1d\u5730\u63d0\u53d6\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u4fe1\u606f\u65f6\u9047\u5230\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u79f0\u4e3a ChatLR \u7684\u65b0\u578b\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4f5c\u4e3a\u68c0\u7d22\u5668\u5f3a\u5927\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u6765\u5b9e\u73b0\u7cbe\u786e\u7b80\u6d01\u7684\u4fe1\u606f\u68c0\u7d22\u3002\u6b64\u5916\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e LLM \u7684\u641c\u7d22\u548c\u95ee\u7b54\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u5728 Text2API \u548c API-ID \u8bc6\u522b\u4e24\u4e2a\u4efb\u52a1\u4e0a\u5fae\u8c03 LLM\uff0c\u4e13\u95e8\u7528\u4e8e\u91d1\u878d\u9886\u57df\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86 ChatLR \u5728\u89e3\u51b3\u7528\u6237\u67e5\u8be2\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7 98.8% \u7684\u6574\u4f53\u4fe1\u606f\u68c0\u7d22\u51c6\u786e\u7387\u3002", "author": "Mingzhu Wang et.al.", "authors": "Mingzhu Wang, Yuzhe Zhang, Qihang Zhao, Juanyi Yang, Hong Zhang", "id": "2405.05508v1", "paper_url": "http://arxiv.org/abs/2405.05508v1", "repo": "null"}}