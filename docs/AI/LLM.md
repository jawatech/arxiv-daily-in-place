
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-06**|**LLaVA-OneVision: Easy Visual Task Transfer**|Bo Li et.al.|[2408.03326v1](http://arxiv.org/abs/2408.03326v1)|null|
|**2024-08-06**|**CoverBench: A Challenging Benchmark for Complex Claim Verification**|Alon Jacovi et.al.|[2408.03325v1](http://arxiv.org/abs/2408.03325v1)|null|
|**2024-08-06**|**Training LLMs to Recognize Hedges in Spontaneous Narratives**|Amie J. Paige et.al.|[2408.03319v1](http://arxiv.org/abs/2408.03319v1)|null|
|**2024-08-06**|**Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**|Charlie Snell et.al.|[2408.03314v1](http://arxiv.org/abs/2408.03314v1)|null|
|**2024-08-06**|**KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**|Ruizhe Zhang et.al.|[2408.03297v1](http://arxiv.org/abs/2408.03297v1)|null|
|**2024-08-06**|**Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**|Lizi Zhang et.al.|[2408.03292v1](http://arxiv.org/abs/2408.03292v1)|null|
|**2024-08-06**|**SARA: Singular-Value Based Adaptive Low-Rank Adaption**|Jihao Gu et.al.|[2408.03290v1](http://arxiv.org/abs/2408.03290v1)|null|
|**2024-08-06**|**StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**|Boxi Cao et.al.|[2408.03281v2](http://arxiv.org/abs/2408.03281v2)|[link](https://github.com/c-box/structeval)|
|**2024-08-06**|**Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**|Angie Boggust et.al.|[2408.03274v1](http://arxiv.org/abs/2408.03274v1)|null|
|**2024-08-06**|**Synthesizing Text-to-SQL Data from Weak and Strong LLMs**|Jiaxi Yang et.al.|[2408.03256v1](http://arxiv.org/abs/2408.03256v1)|null|
|**2024-08-06**|**Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**|Yifei Wang et.al.|[2408.03247v1](http://arxiv.org/abs/2408.03247v1)|null|
|**2024-08-06**|**Making Long-Context Language Models Better Multi-Hop Reasoners**|Yanyang Li et.al.|[2408.03246v1](http://arxiv.org/abs/2408.03246v1)|[link](https://github.com/lavi-lab/longcontextreasoner)|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**|Zifeng Cheng et.al.|[2408.03202v1](http://arxiv.org/abs/2408.03202v1)|null|
|**2024-08-06**|**Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**|Kunkun Hao et.al.|[2408.03200v2](http://arxiv.org/abs/2408.03200v2)|null|
|**2024-08-06**|**Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**|Pranita Deshmukh et.al.|[2408.03172v1](http://arxiv.org/abs/2408.03172v1)|null|
|**2024-08-06**|**Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**|Elia Cereda et.al.|[2408.03168v1](http://arxiv.org/abs/2408.03168v1)|null|
|**2024-08-06**|**Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**|Rabih Chamas et.al.|[2408.03164v1](http://arxiv.org/abs/2408.03164v1)|[link](https://github.com/rabihchamas/dcls-gradcam-eval)|
|**2024-08-06**|**Conditioning LLMs with Emotion in Neural Machine Translation**|Charles Brazier et.al.|[2408.03150v1](http://arxiv.org/abs/2408.03150v1)|null|
|**2024-08-06**|**Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**|Yanghai Zhang et.al.|[2408.03149v1](http://arxiv.org/abs/2408.03149v1)|null|
|**2024-08-06**|**Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**|Leo Donisch et.al.|[2408.03130v1](http://arxiv.org/abs/2408.03130v1)|null|
|**2024-08-06**|**Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**|Artur Guimarães et.al.|[2408.03127v1](http://arxiv.org/abs/2408.03127v1)|null|
|**2024-08-06**|**COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**|Rajvee Sheth et.al.|[2408.03125v1](http://arxiv.org/abs/2408.03125v1)|[link](https://github.com/lingo-iitgn/commentator)|
|**2024-08-06**|**Evaluating the Translation Performance of Large Language Models Based on Euas-20**|Yan Huang et.al.|[2408.03119v1](http://arxiv.org/abs/2408.03119v1)|null|
|**2024-08-06**|**Topic Modeling with Fine-tuning LLMs and Bag of Sentences**|Johannes Schneider et.al.|[2408.03099v1](http://arxiv.org/abs/2408.03099v1)|[link](https://github.com/johntailor/ft-topic)|
|**2024-08-06**|**500xCompressor: Generalized Prompt Compression for Large Language Models**|Zongqian Li et.al.|[2408.03094v1](http://arxiv.org/abs/2408.03094v1)|null|
|**2024-08-06**|**Learning Provably Robust Policies in Uncertain Parametric Environments**|Yannik Schnitzer et.al.|[2408.03093v1](http://arxiv.org/abs/2408.03093v1)|null|
|**2024-08-06**|**Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement**|Le Yu et.al.|[2408.03092v1](http://arxiv.org/abs/2408.03092v1)|null|
|**2024-08-06**|**Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**|Jinglong Gao et.al.|[2408.03079v1](http://arxiv.org/abs/2408.03079v1)|null|
|**2024-08-06**|**BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications**|G. Manni et.al.|[2408.03078v1](http://arxiv.org/abs/2408.03078v1)|null|
|**2024-08-06**|**Towards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models**|Amelie Robrecht et.al.|[2408.03074v1](http://arxiv.org/abs/2408.03074v1)|null|
|**2024-08-06**|**Probing structural constraints of negation in Pretrained Language Models**|David Kletz et.al.|[2408.03070v1](http://arxiv.org/abs/2408.03070v1)|null|
|**2024-08-06**|**Analysis of Argument Structure Constructions in a Deep Recurrent Language Model**|Pegah Ramezani et.al.|[2408.03062v1](http://arxiv.org/abs/2408.03062v1)|null|
|**2024-08-06**|**OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents**|Qiang Sun et.al.|[2408.03047v1](http://arxiv.org/abs/2408.03047v1)|null|
|**2024-08-06**|**L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization**|Elvys Linhares Pontes et.al.|[2408.03033v1](http://arxiv.org/abs/2408.03033v1)|null|
|**2024-08-06**|**Integrating Controllable Motion Skills from Demonstrations**|Honghao Liao et.al.|[2408.03018v1](http://arxiv.org/abs/2408.03018v1)|null|
|**2024-08-06**|**Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**|Daniel Steinigen et.al.|[2408.03010v1](http://arxiv.org/abs/2408.03010v1)|null|
|**2024-08-06**|**LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning**|Lekai Chen et.al.|[2408.02999v1](http://arxiv.org/abs/2408.02999v1)|null|
|**2024-08-06**|**ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval**|Ruixiang Zhao et.al.|[2408.02978v1](http://arxiv.org/abs/2408.02978v1)|null|
|**2024-08-06**|**Empathy Level Alignment via Reinforcement Learning for Empathetic Response Generation**|Hui Ma et.al.|[2408.02976v1](http://arxiv.org/abs/2408.02976v1)|null|
|**2024-08-06**|**EC-Guide: A Comprehensive E-Commerce Guide for Instruction Tuning and Quantization**|Zhaopeng Feng et.al.|[2408.02970v1](http://arxiv.org/abs/2408.02970v1)|[link](https://github.com/fzp0424/ec-guide-kddup-2024)|
|**2024-08-06**|**Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval**|Iman Azimi et.al.|[2408.02964v1](http://arxiv.org/abs/2408.02964v1)|null|
|**2024-08-06**|**Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps**|Yifan Zhu et.al.|[2408.02949v1](http://arxiv.org/abs/2408.02949v1)|null|
|**2024-08-06**|**Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality**|Da Ju et.al.|[2408.02948v1](http://arxiv.org/abs/2408.02948v1)|null|
|**2024-08-06**|**Scaling Laws for Data Poisoning in LLMs**|Dillon Bowen et.al.|[2408.02946v1](http://arxiv.org/abs/2408.02946v1)|null|
|**2024-08-06**|**Self-Supervised Learning for Multi-Channel Neural Transducer**|Atsushi Kojima et.al.|[2408.02945v1](http://arxiv.org/abs/2408.02945v1)|null|
|**2024-08-06**|**LLM-Empowered Resource Allocation in Wireless Communications Systems**|Woongsup Lee et.al.|[2408.02944v1](http://arxiv.org/abs/2408.02944v1)|null|
|**2024-08-06**|**HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection**|Yuxin Wang et.al.|[2408.02927v1](http://arxiv.org/abs/2408.02927v1)|null|
|**2024-08-06**|**Intermediate direct preference optimization**|Atsushi Kojima et.al.|[2408.02923v1](http://arxiv.org/abs/2408.02923v1)|null|
|**2024-08-06**|**A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model**|Jingwen Zhou et.al.|[2408.02920v1](http://arxiv.org/abs/2408.02920v1)|null|
|**2024-08-06**|**Data Checklist: On Unit-Testing Datasets with Usable Information**|Heidi C. Zhang et.al.|[2408.02919v1](http://arxiv.org/abs/2408.02919v1)|null|
|**2024-08-06**|**KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance**|Jingxian Lu et.al.|[2408.02912v1](http://arxiv.org/abs/2408.02912v1)|null|
|**2024-08-06**|**Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**|Tiezheng Guo et.al.|[2408.02907v1](http://arxiv.org/abs/2408.02907v1)|null|
|**2024-08-06**|**Enabling Intelligent Traffic Systems: A Deep Learning Method for Accurate Arabic License Plate Recognition**|M. A. Sayedelahl et.al.|[2408.02904v1](http://arxiv.org/abs/2408.02904v1)|null|
|**2024-08-06**|**Lighthouse: A User-Friendly Library for Reproducible Video Moment Retrieval and Highlight Detection**|Taichi Nishimura et.al.|[2408.02901v1](http://arxiv.org/abs/2408.02901v1)|[link](https://github.com/line/lighthouse)|
|**2024-08-06**|**SETN: Stock Embedding Enhanced with Textual and Network Information**|Takehiro Takayanagi et.al.|[2408.02899v1](http://arxiv.org/abs/2408.02899v1)|null|
|**2024-08-06**|**A Metric Driven Approach to Mixed Precision Training**|Mitchelle Rasquinha et.al.|[2408.02897v1](http://arxiv.org/abs/2408.02897v1)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-06**|**Compromising Embodied Agents with Contextual Backdoor Attacks**|Aishan Liu et.al.|[2408.02882v1](http://arxiv.org/abs/2408.02882v1)|null|
|**2024-08-06**|**Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning**|Dmitri Iourovitski et.al.|[2408.02871v1](http://arxiv.org/abs/2408.02871v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|null|
|**2024-08-05**|**A Framework for Fine-Tuning LLMs using Heterogeneous Feedback**|Ryan Aponte et.al.|[2408.02861v1](http://arxiv.org/abs/2408.02861v1)|null|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|null|
|**2024-08-05**|**Development of REGAI: Rubric Enabled Generative Artificial Intelligence**|Zach Johnson et.al.|[2408.02811v1](http://arxiv.org/abs/2408.02811v1)|null|
|**2024-08-05**|**Examining Gender and Power on Wikipedia Through Face and Politeness**|Adil Soubki et.al.|[2408.02798v1](http://arxiv.org/abs/2408.02798v1)|null|
|**2024-08-05**|**LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory**|Jillian Ross et.al.|[2408.02784v1](http://arxiv.org/abs/2408.02784v1)|null|
|**2024-08-05**|**Self-Taught Evaluators**|Tianlu Wang et.al.|[2408.02666v1](http://arxiv.org/abs/2408.02666v1)|null|
|**2024-08-05**|**Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?**|Mohammad Bahrami Karkevandi et.al.|[2408.02651v1](http://arxiv.org/abs/2408.02651v1)|null|
|**2024-08-05**|**SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models**|Muxi Diao et.al.|[2408.02632v1](http://arxiv.org/abs/2408.02632v1)|null|
|**2024-08-05**|**Language Model Can Listen While Speaking**|Ziyang Ma et.al.|[2408.02622v1](http://arxiv.org/abs/2408.02622v1)|null|
|**2024-08-05**|**BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba**|Ling Yue et.al.|[2408.02600v1](http://arxiv.org/abs/2408.02600v1)|null|
|**2024-08-05**|**Progressively Selective Label Enhancement for Language Model Alignment**|Biao Liu et.al.|[2408.02599v1](http://arxiv.org/abs/2408.02599v1)|null|
|**2024-08-05**|**Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection**|Sajal Aggarwal et.al.|[2408.02595v1](http://arxiv.org/abs/2408.02595v1)|null|
|**2024-08-05**|**Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization**|Ankan Mullick et.al.|[2408.02584v1](http://arxiv.org/abs/2408.02584v1)|null|
|**2024-08-05**|**Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition**|Jaeyoung Kim et.al.|[2408.02582v1](http://arxiv.org/abs/2408.02582v1)|null|
|**2024-08-05**|**Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs**|Ananya Pandey et.al.|[2408.02571v1](http://arxiv.org/abs/2408.02571v1)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559v1](http://arxiv.org/abs/2408.02559v1)|null|
|**2024-08-05**|**MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization**|Yiwen Chen et.al.|[2408.02555v1](http://arxiv.org/abs/2408.02555v1)|null|
|**2024-08-05**|**The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces**|Costanza Armanini et.al.|[2408.02547v1](http://arxiv.org/abs/2408.02547v1)|null|
|**2024-08-05**|**RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation**|Daniel Fleischer et.al.|[2408.02545v1](http://arxiv.org/abs/2408.02545v1)|null|
|**2024-08-05**|**Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions**|Xinbei Ma et.al.|[2408.02544v1](http://arxiv.org/abs/2408.02544v1)|null|
|**2024-08-05**|**OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar**|Christoph Rauchegger et.al.|[2408.02520v1](http://arxiv.org/abs/2408.02520v1)|null|
|**2024-08-05**|**UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model**|Zhaowei Li et.al.|[2408.02503v1](http://arxiv.org/abs/2408.02503v1)|[link](https://github.com/lzw-lzw/unifiedmllm)|
|**2024-08-05**|**MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis**|Dongwei Xu et.al.|[2408.02714v1](http://arxiv.org/abs/2408.02714v1)|null|
|**2024-08-05**|**A First Look at License Compliance Capability of LLMs in Code Generation**|Weiwei Xu et.al.|[2408.02487v1](http://arxiv.org/abs/2408.02487v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479v1](http://arxiv.org/abs/2408.02479v1)|null|
|**2024-08-05**|**Automatic Voice Identification after Speech Resynthesis using PPG**|Thibault Gaudier et.al.|[2408.02712v1](http://arxiv.org/abs/2408.02712v1)|null|
|**2024-08-05**|**An investigation into the causes of race bias in AI-based cine CMR segmentation**|Tiarna Lee et.al.|[2408.02462v1](http://arxiv.org/abs/2408.02462v1)|null|
|**2024-08-05**|**Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach**|Wanxu Wei et.al.|[2408.02456v1](http://arxiv.org/abs/2408.02456v1)|null|
|**2024-08-05**|**Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion Models**|Pushkar Jajoria et.al.|[2408.02711v1](http://arxiv.org/abs/2408.02711v1)|null|
|**2024-08-05**|**Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models**|Zhi Rui Tam et.al.|[2408.02442v1](http://arxiv.org/abs/2408.02442v1)|null|
|**2024-08-05**|**Long Input Benchmark for Russian Analysis**|Igor Churin et.al.|[2408.02439v1](http://arxiv.org/abs/2408.02439v1)|null|
|**2024-08-05**|**Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation**|Shutong Feng et.al.|[2408.02417v1](http://arxiv.org/abs/2408.02417v1)|null|
|**2024-08-05**|**Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models**|Zi Liang et.al.|[2408.02416v1](http://arxiv.org/abs/2408.02416v1)|null|
|**2024-08-05**|**Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models**|Tongtong Feng et.al.|[2408.02408v1](http://arxiv.org/abs/2408.02408v1)|null|
|**2024-08-05**|**SnapE -- Training Snapshot Ensembles of Link Prediction Models**|Ali Shaban et.al.|[2408.02707v1](http://arxiv.org/abs/2408.02707v1)|null|
|**2024-08-05**|**Enhancing AI-based Generation of Software Exploits with Contextual Information**|Pietro Liguori et.al.|[2408.02402v2](http://arxiv.org/abs/2408.02402v2)|null|
|**2024-08-05**|**A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**|Vanni Zavarella et.al.|[2408.02377v1](http://arxiv.org/abs/2408.02377v1)|null|
|**2024-08-05**|**Operationalizing Contextual Integrity in Privacy-Conscious Assistants**|Sahra Ghalebikesabi et.al.|[2408.02373v1](http://arxiv.org/abs/2408.02373v1)|null|

#### Abstracts
##### **LLaVA-OneVision: Easy Visual Task Transfer**
2408.03326v1 by Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li

We present LLaVA-OneVision, a family of open large multimodal models (LMMs)
developed by consolidating our insights into data, models, and visual
representations in the LLaVA-NeXT blog series. Our experimental results
demonstrate that LLaVA-OneVision is the first single model that can
simultaneously push the performance boundaries of open LMMs in three important
computer vision scenarios: single-image, multi-image, and video scenarios.
Importantly, the design of LLaVA-OneVision allows strong transfer learning
across different modalities/scenarios, yielding new emerging capabilities. In
particular, strong video understanding and cross-scenario capabilities are
demonstrated through task transfer from images to videos.

摘要：我們展示 LLaVA-OneVision，一個開放式大型多模態模型 (LMM) 家族，
透過整合我們對 LLaVA-NeXT 部落格系列中資料、模型和視覺
表現的見解而開發。我們的實驗結果證明 LLaVA-OneVision 是第一個單一模型，可以
同時在三個重要的電腦視覺場景中擴展開放式 LMM 的效能界限：單一影像、多重影像和影片場景。
重要的是，LLaVA-OneVision 的設計允許在不同的模態/場景中進行強大的轉移學習，產生新的新興能力。特別是，
透過從影像到影片的任務轉移，展示了強大的影片理解和跨場景能力。

##### **CoverBench: A Challenging Benchmark for Complex Claim Verification**
2408.03325v1 by Alon Jacovi, Moran Ambar, Eyal Ben-David, Uri Shaham, Amir Feder, Mor Geva, Dror Marcus, Avi Caciularu

There is a growing line of research on verifying the correctness of language
models' outputs. At the same time, LMs are being used to tackle complex queries
that require reasoning. We introduce CoverBench, a challenging benchmark
focused on verifying LM outputs in complex reasoning settings. Datasets that
can be used for this purpose are often designed for other complex reasoning
tasks (e.g., QA) targeting specific use-cases (e.g., financial tables),
requiring transformations, negative sampling and selection of hard examples to
collect such a benchmark. CoverBench provides a diversified evaluation for
complex claim verification in a variety of domains, types of reasoning,
relatively long inputs, and a variety of standardizations, such as multiple
representations for tables where available, and a consistent schema. We
manually vet the data for quality to ensure low levels of label noise. Finally,
we report a variety of competitive baseline results to show CoverBench is
challenging and has very significant headroom. The data is available at
https://huggingface.co/datasets/google/coverbench .

摘要：對於驗證語言模型輸出的正確性，有越來越多的研究。同時，LM 被用於解決需要推理的複雜查詢。我們介紹 CoverBench，這是一個具有挑戰性的基準，專注於驗證複雜推理設定中的 LM 輸出。可用於此目的的資料集通常是為其他複雜推理任務（例如，QA）而設計的，這些任務針對特定用例（例如，財務表格），需要轉換、負面抽樣和選擇困難範例來收集此類基準。CoverBench 提供了對各種領域、推理類型、相對較長的輸入以及各種標準化的多元評估，例如表格的各種表示（如果可用）和一致的架構。我們手動審查資料的品質，以確保低程度的標籤雜訊。最後，我們報告了各種競爭性的基準結果，以顯示 CoverBench 具有挑戰性且有非常顯著的進步空間。資料可在 https://huggingface.co/datasets/google/coverbench 取得。

##### **Training LLMs to Recognize Hedges in Spontaneous Narratives**
2408.03319v1 by Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan

Hedges allow speakers to mark utterances as provisional, whether to signal
non-prototypicality or "fuzziness", to indicate a lack of commitment to an
utterance, to attribute responsibility for a statement to someone else, to
invite input from a partner, or to soften critical feedback in the service of
face-management needs. Here we focus on hedges in an experimentally
parameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced
from memory by 21 speakers for co-present addressees, transcribed to text
(Galati and Brennan, 2010). We created a gold standard of hedges annotated by
human coders (the Roadrunner-Hedge corpus) and compared three LLM-based
approaches for hedge detection: fine-tuning BERT, and zero and few-shot
prompting with GPT-4o and LLaMA-3. The best-performing approach was a
fine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on
the top performing approaches, we used an LLM-in-the-Loop approach to improve
the gold standard coding, as well as to highlight cases in which hedges are
ambiguous in linguistically interesting ways that will guide future research.
This is the first step in our research program to train LLMs to interpret and
generate collateral signals appropriately and meaningfully in conversation.

摘要：<paragraph>對沖允許說話者將言論標記為暫定的，無論是要標示非原型或「模糊性」，表示對言論缺乏承諾，將聲明的責任歸咎於他人，邀請夥伴提供意見，或在面子管理需求的服務中軟化批評性的回饋。在這裡，我們專注於 21 位說話者為共同出席的受話者自發性地從記憶中產生 63 個 Roadrunner 卡通敘事的實驗性參數化語料庫中的對沖，並轉錄成文字（Galati 和 Brennan，2010 年）。我們建立了由人類編碼器註釋的對沖黃金標準（Roadrunner-Hedge 語料庫），並比較了三種基於 LLM 的對沖偵測方法：微調 BERT，以及使用 GPT-4o 和 LLaMA-3 進行零次和少次提示。表現最佳的方法是微調後的 BERT 模型，其次是少次提示的 GPT-4o。在對表現最佳的方法進行錯誤分析後，我們使用 LLM-in-the-Loop 方法來改進黃金標準編碼，並強調對沖在語言學上有趣的方面中模稜兩可的情況，這將指導未來的研究。這是我們研究計畫的第一步，目的是訓練 LLM 在對話中適當地且有意義地解釋和產生附帶信號。</paragraph>

##### **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**
2408.03314v1 by Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar

Enabling LLMs to improve their outputs by using more test-time computation is
a critical step towards building generally self-improving agents that can
operate on open-ended natural language. In this paper, we study the scaling of
inference-time computation in LLMs, with a focus on answering the question: if
an LLM is allowed to use a fixed but non-trivial amount of inference-time
compute, how much can it improve its performance on a challenging prompt?
Answering this question has implications not only on the achievable performance
of LLMs, but also on the future of LLM pretraining and how one should tradeoff
inference-time and pre-training compute. Despite its importance, little
research attempted to understand the scaling behaviors of various test-time
inference methods. Moreover, current work largely provides negative results for
a number of these strategies. In this work, we analyze two primary mechanisms
to scale test-time computation: (1) searching against dense, process-based
verifier reward models; and (2) updating the model's distribution over a
response adaptively, given the prompt at test time. We find that in both cases,
the effectiveness of different approaches to scaling test-time compute
critically varies depending on the difficulty of the prompt. This observation
motivates applying a "compute-optimal" scaling strategy, which acts to most
effectively allocate test-time compute adaptively per prompt. Using this
compute-optimal strategy, we can improve the efficiency of test-time compute
scaling by more than 4x compared to a best-of-N baseline. Additionally, in a
FLOPs-matched evaluation, we find that on problems where a smaller base model
attains somewhat non-trivial success rates, test-time compute can be used to
outperform a 14x larger model.

摘要：讓 LLM 能夠透過使用更多測試時間運算來改善其產出，是建立一般自改善代理程式的重要步驟，該代理程式可以在開放式自然語言中運作。在本文中，我們研究了 LLM 中推論時間運算的擴充，重點在回答下列問題：如果允許 LLM 使用固定但非瑣碎的推論時間運算量，它可以在具挑戰性的提示中改善多少效能？回答這個問題不僅對 LLM 可達到的效能有影響，也對 LLM 預訓練的未來以及如何權衡推論時間與預訓練運算產生影響。儘管其重要性，但很少有研究嘗試了解各種測試時間推論方法的擴充行為。此外，目前的工作在很大程度上為許多這些策略提供了負面結果。在這項工作中，我們分析了兩種擴充測試時間運算的主要機制：(1) 針對密集的、基於程序的驗證器獎勵模型進行搜尋；以及 (2) 根據測試時間的提示，自適應地更新模型在回應上的分佈。我們發現，在這兩種情況下，擴充測試時間運算的不同方法的有效性，會根據提示的難度而有顯著差異。這個觀察結果促使我們採用「運算最佳化」擴充策略，該策略的作用是針對每個提示自適應地最有效地配置測試時間運算。使用這個運算最佳化策略，與最佳 N 基準線相比，我們可以將測試時間運算擴充的效率提高 4 倍以上。此外，在 FLOPs 匹配的評估中，我們發現對於較小的基礎模型達到相當不平凡的成功率的問題，測試時間運算可用於優於大 14 倍的模型。

##### **KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**
2408.03297v1 by Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, Yasha Wang

By integrating external knowledge, Retrieval-Augmented Generation (RAG) has
become an effective strategy for mitigating the hallucination problems that
large language models (LLMs) encounter when dealing with knowledge-intensive
tasks. However, in the process of integrating external non-parametric
supporting evidence with internal parametric knowledge, inevitable knowledge
conflicts may arise, leading to confusion in the model's responses. To enhance
the knowledge selection of LLMs in various contexts, some research has focused
on refining their behavior patterns through instruction-tuning. Nonetheless,
due to the absence of explicit negative signals and comparative objectives,
models fine-tuned in this manner may still exhibit undesirable behaviors in the
intricate and realistic retrieval scenarios. To this end, we propose a
Knowledge-aware Preference Optimization, dubbed KaPO, aimed at achieving
controllable knowledge selection in real retrieval scenarios. Concretely, we
explore and simulate error types across diverse context combinations and learn
how to avoid these negative signals through preference optimization methods.
Simultaneously, by adjusting the balance between response length and the
proportion of preference data representing different behavior patterns, we
enhance the adherence capabilities and noise robustness of LLMs in a balanced
manner. Experimental results show that KaPO outperforms previous methods for
handling knowledge conflicts by over 37%, while also exhibiting robust
generalization across various out-of-distribution datasets.

摘要：透過整合外部知識，檢索增強生成（RAG）已成為減輕大型語言模型（LLM）在處理知識密集型任務時所遇到的幻覺問題的有效策略。然而，在將外部非參數支持證據與內部參數知識整合的過程中，可能會產生不可避免的知識衝突，導致模型回應混淆。為了增強 LLM 在各種情境中的知識選擇，一些研究已專注於透過指令微調來改善其行為模式。儘管如此，由於缺乏明確的負面訊號和比較目標，以這種方式微調的模型在複雜且真實的檢索情境中仍可能表現出不良行為。為此，我們提出一個稱為 KaPO 的知識感知偏好最佳化，旨在實現實際檢索情境中的可控知識選擇。具體來說，我們探索並模擬各種情境組合中的錯誤類型，並學習如何透過偏好最佳化方法來避免這些負面訊號。同時，透過調整回應長度和代表不同行為模式的偏好資料比例之間的平衡，我們以平衡的方式增強了 LLM 的遵守能力和抗噪性。實驗結果顯示，KaPO 在處理知識衝突方面優於先前的各種方法，優勢超過 37%，同時在各種非分佈資料集上也表現出強大的泛化能力。

##### **Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**
2408.03292v1 by Lizi Zhang, Azadeh Davoodi

There has been significant recent progress to reduce the computational effort
of static IR drop analysis using neural networks, and modeling as an
image-to-image translation task. A crucial issue is the lack of sufficient data
from real industry designs to train these networks. Additionally, there is no
methodology to explain a high-drop pixel in a predicted IR drop image to its
specific root-causes. In this work, we first propose a U-Net neural network
model with attention gates which is specifically tailored to achieve fast and
accurate image-based static IR drop prediction. Attention gates allow selective
emphasis on relevant parts of the input data without supervision which is
desired because of the often sparse nature of the IR drop map. We propose a
two-phase training process which utilizes a mix of artificially-generated data
and a limited number of points from real designs. The results are, on-average,
18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of
the ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we
propose a fast method using saliency maps which can explain a predicted IR drop
in terms of specific input pixels contributing the most to a drop. In our
experiments, we show the number of high IR drop pixels can be reduced
on-average by 18% by mimicking upsize of a tiny portion of PDN's resistive
edges.

摘要：<paragraph>利用神經網路和將其建模為影像轉換任務，最近在降低靜態 IR 降壓分析的計算工作上取得顯著進展。一個關鍵問題是缺乏來自真實產業設計的足夠資料來訓練這些網路。此外，沒有方法可以解釋預測 IR 降壓影像中的高降壓像素及其具體根本原因。在這項工作中，我們首先提出一個具有注意力閘的 U-Net 神經網路模型，它專門設計用於實現快速且準確的基於影像的靜態 IR 降壓預測。注意力閘允許選擇性地強調輸入資料中相關部分，而無需監督，這是因為 IR 降壓圖通常具有稀疏特性的緣故。我們提出了一個兩階段訓練過程，它利用人工生成資料和來自真實設計的有限數量的點。與 ICCAD 2023 競賽的獲勝者（僅 U-Net）相比，在真實設計上測試時，結果在 MAE 上平均提高 18%（53%），在 F1 分數上提高 14%（113%）。其次，我們提出了一種使用顯著性圖的快速方法，它可以用貢獻降壓最多的特定輸入像素來解釋預測的 IR 降壓。在我們的實驗中，我們表明，通過模擬縮小 PDN 電阻邊緣的一小部分，可以將高 IR 降壓像素的數量平均減少 18%。</paragraph>

##### **SARA: Singular-Value Based Adaptive Low-Rank Adaption**
2408.03290v1 by Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong

With the increasing number of parameters in large pre-trained models, LoRA as
a parameter-efficient fine-tuning(PEFT) method is widely used for not adding
inference overhead. The LoRA method assumes that weight changes during
fine-tuning can be approximated by low-rank matrices. However, the rank values
need to be manually verified to match different downstream tasks, and they
cannot accommodate the varying importance of different layers in the model. In
this work, we first analyze the relationship between the performance of
different layers and their ranks using SVD. Based on this, we design the
Singular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds
the rank during initialization by performing SVD on the pre-trained weights.
Additionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly
reduces the number of parameters by fine-tuning only multiple parallel sets of
singular values controlled by a router. Extensive experiments on various
complex tasks demonstrate the simplicity and parameter efficiency of our
methods. They can effectively and adaptively find the most suitable rank for
each layer of each model.

摘要：隨著大型預訓練模型中參數數量的增加，LoRA 作為一種參數高效的微調 (PEFT) 方法被廣泛用於不增加推理開銷。LoRA 方法假設微調期間的權重變化可以用低秩矩陣近似。然而，秩值需要手動驗證以匹配不同的下游任務，並且它們無法適應模型中不同層的不同重要性。在這項工作中，我們首先使用 SVD 分析不同層的性能與其秩之間的關係。基於此，我們設計了基於奇異值的自適應低秩適應 (SARA)，它通過對預訓練權重執行 SVD 來自適應地找到初始化期間的秩。此外，我們探索了混合 SARA (Mo-SARA)，它通過僅微調由路由器控制的奇異值的多個並行集來顯著減少參數數量。在各種複雜任務上的大量實驗證明了我們方法的簡潔性和參數效率。它們可以有效且自適應地找到每個模型每一層最合適的秩。

##### **StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**
2408.03281v2 by Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun

Evaluation is the baton for the development of large language models. Current
evaluations typically employ a single-item assessment paradigm for each atomic
test objective, which struggles to discern whether a model genuinely possesses
the required capabilities or merely memorizes/guesses the answers to specific
questions. To this end, we propose a novel evaluation framework referred to as
StructEval. Starting from an atomic test objective, StructEval deepens and
broadens the evaluation by conducting a structured assessment across multiple
cognitive levels and critical concepts, and therefore offers a comprehensive,
robust and consistent evaluation for LLMs. Experiments on three widely-used
benchmarks demonstrate that StructEval serves as a reliable tool for resisting
the risk of data contamination and reducing the interference of potential
biases, thereby providing more reliable and consistent conclusions regarding
model capabilities. Our framework also sheds light on the design of future
principled and trustworthy LLM evaluation protocols.

摘要：評估是大語言模型發展的指標。目前的評估通常對每個原子測試目標採用單一項目評估範例，這很難辨別模型是否真正具備所需的技能，或僅僅是記憶/猜測特定問題的答案。為此，我們提出一個稱為 StructEval 的新評估架構。從一個原子測試目標開始，StructEval 透過在多個認知層面和關鍵概念中進行結構化評估來加深和擴展評估，因此為 LLM 提供全面、穩健且一致的評估。在三個廣泛使用的基準測試上的實驗表明，StructEval 可作為抵抗資料污染風險和減少潛在偏差干擾的可靠工具，從而對模型能力提供更可靠且一致的結論。我們的架構也為未來基於原則且值得信賴的 LLM 評估協定的設計提供了啟示。

##### **Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**
2408.03274v1 by Angie Boggust, Venkatesh Sivaraman, Yannick Assogba, Donghao Ren, Dominik Moritz, Fred Hohman

To deploy machine learning models on-device, practitioners use compression
algorithms to shrink and speed up models while maintaining their high-quality
output. A critical aspect of compression in practice is model comparison,
including tracking many compression experiments, identifying subtle changes in
model behavior, and negotiating complex accuracy-efficiency trade-offs.
However, existing compression tools poorly support comparison, leading to
tedious and, sometimes, incomplete analyses spread across disjoint tools. To
support real-world comparative workflows, we develop an interactive visual
system called Compress and Compare. Within a single interface, Compress and
Compare surfaces promising compression strategies by visualizing provenance
relationships between compressed models and reveals compression-induced
behavior changes by comparing models' predictions, weights, and activations. We
demonstrate how Compress and Compare supports common compression analysis tasks
through two case studies, debugging failed compression on generative language
models and identifying compression artifacts in image classification models. We
further evaluate Compress and Compare in a user study with eight compression
experts, illustrating its potential to provide structure to compression
workflows, help practitioners build intuition about compression, and encourage
thorough analysis of compression's effect on model behavior. Through these
evaluations, we identify compression-specific challenges that future visual
analytics tools should consider and Compress and Compare visualizations that
may generalize to broader model comparison tasks.

摘要：為了在裝置上部署機器學習模型，實務工作者會使用壓縮演算法來縮小模型的規模並加快模型的速度，同時維持其高品質的輸出。在實際應用中，壓縮的一個重要面向是模型比較，包括追蹤許多壓縮實驗、找出模型行為中的細微變化，以及協商複雜的準確度與效率折衷。然而，現有的壓縮工具對於比較的支持很差，導致繁瑣且有時不完整的分析散布在不同的工具中。為了支援真實世界的比較工作流程，我們開發了一個互動式視覺系統，稱為「壓縮與比較」。在單一介面中，「壓縮與比較」會透過視覺化壓縮模型之間的來源關係，找出有前景的壓縮策略，並透過比較模型的預測、權重和激勵，揭露壓縮引發的行為變化。我們透過兩個案例研究展示「壓縮與比較」如何支援常見的壓縮分析任務，包括偵錯生成語言模型中失敗的壓縮，以及找出影像分類模型中的壓縮人工製品。我們進一步在一個使用者研究中評估「壓縮與比較」，該研究有八位壓縮專家參與，說明其提供結構給壓縮工作流程、協助實務工作者建立關於壓縮的直覺，以及鼓勵徹底分析壓縮對模型行為的影響的潛力。透過這些評估，我們找出未來的視覺分析工具應考量的特定於壓縮的挑戰，以及可能會推廣到更廣泛的模型比較任務的「壓縮與比較」視覺化。

##### **Synthesizing Text-to-SQL Data from Weak and Strong LLMs**
2408.03256v1 by Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou

The capability gap between open-source and closed-source large language
models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we
introduce a synthetic data approach that combines data produced by larger, more
powerful models (strong models) with error information data generated by
smaller, not well-aligned models (weak models). The method not only enhances
the domain generalization of text-to-SQL models but also explores the potential
of error data supervision through preference learning. Furthermore, we employ
the synthetic data approach for instruction tuning on open-source LLMs,
resulting SENSE, a specialized text-to-SQL model. The effectiveness of SENSE is
demonstrated through state-of-the-art results on the SPIDER and BIRD
benchmarks, bridging the performance gap between open-source models and methods
prompted by closed-source models.

摘要：開放原始碼與閉源大型語言模型 (LLM) 之間的能力差距，仍然是文字轉 SQL 任務中的一項挑戰。在本文中，我們介紹了一種合成資料方法，它結合了由更大、更強大的模型 (強模型) 所產生的資料，以及由較小、對齊不佳的模型 (弱模型) 所產生的錯誤資訊資料。此方法不僅增強了文字轉 SQL 模型的領域概括性，還透過偏好學習探索了錯誤資料監督的潛力。此外，我們將合成資料方法用於開放原始碼 LLM 上的指令調整，產生了 SENSE，一種專門的文字轉 SQL 模型。SENSE 的有效性透過 SPIDER 和 BIRD 基準測試的最新結果得到證明，縮小了開放原始碼模型與閉源模型提示方法之間的效能差距。

##### **Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**
2408.03247v1 by Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng

In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.

摘要：<paragraph>在本文中，我們探討大型語言模型 (LLM) 在面對推理任務時，是否會主動回憶或檢索其內部事實知識庫。透過知識神經元分析 LLM 在每個推理步驟中的內部事實回憶，我們發現 LLM 在某些情況下無法利用關鍵的事實關聯。相反地，他們傾向於選擇替代的捷徑途徑來回答推理問題。透過手動操作 LLM 中參數化知識的回憶過程，我們證明了增強此回憶過程會直接改善推理表現，而抑制它則會導致顯著的退化。此外，我們評估了思想鏈 (CoT) 提示的影響，這是一種解決複雜推理任務的強大技術。我們的研究結果表明，CoT 可以透過鼓勵 LLM 從事有序且可靠的推理來加強對事實知識的回憶。此外，我們探討了背景衝突如何影響推理過程中事實的檢索，以全面了解 LLM 的事實回憶行為。代碼和數據將很快提供。</paragraph>

##### **Making Long-Context Language Models Better Multi-Hop Reasoners**
2408.03246v1 by Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang

Recent advancements in long-context modeling have enhanced language models
(LMs) for complex tasks across multiple NLP applications. Despite this
progress, we find that these models struggle with multi-hop reasoning and
exhibit decreased performance in the presence of noisy contexts. In this paper,
we introduce Reasoning with Attributions, a novel approach that prompts LMs to
supply attributions for each assertion during their reasoning. We validate our
approach through experiments on three multi-hop datasets, employing both
proprietary and open-source models, and demonstrate its efficacy and
resilience. Furthermore, we explore methods to augment reasoning capabilities
via fine-tuning and offer an attribution-annotated dataset and a specialized
training strategy. Our fine-tuned model achieves competitive performance on
multi-hop reasoning benchmarks, closely paralleling proprietary LMs such as
ChatGPT and Claude-instant.

摘要：最近在長文本建模方面的進展增強了語言模型 (LM) 在多個 NLP 應用中處理複雜任務的能力。儘管有這些進展，我們發現這些模型在多跳推理方面遇到困難，並且在存在嘈雜環境時表現下降。在本文中，我們介紹了歸因推理，這是一種新穎的方法，它提示 LM 在推理過程中為每個斷言提供歸因。我們通過在三個多跳數據集上進行實驗驗證了我們的做法，同時採用專有模型和開源模型，並展示了其有效性和彈性。此外，我們探索了通過微調來擴充推理能力的方法，並提供了一個歸因註釋數據集和一個專門的訓練策略。我們微調後的模型在多跳推理基準上取得了有競爭力的表現，與專有 LM（例如 ChatGPT 和 Claude-instant）密切相關。

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

摘要：<paragraph>針對手術器械分割（SIS）的個人化聯邦學習（PFL）是一種有前景的方法。它讓多個臨床地點能夠在隱私的條件下共同訓練一系列模型，每個模型都根據每個地點的個別分佈進行調整。現有的 PFL 方法很少考慮多頭自我注意力的個人化，而且沒有考慮外觀的多樣性和器械形狀的相似性，這兩者都存在於手術場景中。因此，我們提出了 PFedSIS，這是一種具有視覺特徵先驗的 SIS 的新型 PFL 方法，它結合了全局個性化解糾纏（GPD）、外觀調節個性化增強（APE）和形狀相似性全局增強（SGE），以提升每個地點的 SIS 效能。GPD 代表了針對多頭自我注意力個性化進行頭部分配的首次嘗試。為了保留每個地點的獨特外觀表示並逐漸利用地點間的差異，APE 引入了外觀調節，並透過超網路為每個地點的個性化參數提供自訂的逐層聚合解決方案。器械的相互形狀資訊透過 SGE 進行維護和共享，這增強了影像層級上的跨風格形狀一致性，並計算每個地點在預測層級上的形狀相似性貢獻，以更新全局參數。PFedSIS 在骰子系數上優於現有最先進的方法，分別提升了 +1.51%、IoU 提升了 +2.11%、ASSD 降低了 -2.79、HD95 效能提升了 -15.55。對應的程式碼和模型將在 https://github.com/wzjialang/PFedSIS 上發布。</paragraph>

##### **A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**
2408.03202v1 by Zifeng Cheng, Zhiwei Jiang, Yafeng Yin, Zhaoling Chen, Cong Wang, Shiping Ge, Qiguo Huang, Qing Gu

Multi-Label Text Classification (MLTC) is a practical yet challenging task
that involves assigning multiple non-exclusive labels to each document.
Previous studies primarily focus on capturing label correlations to assist
label prediction by introducing special labeling schemes, designing specific
model structures, or adding auxiliary tasks. Recently, the $k$ Nearest Neighbor
($k$NN) framework has shown promise by retrieving labeled samples as references
to mine label co-occurrence information in the embedding space. However, two
critical biases, namely embedding alignment bias and confidence estimation
bias, are often overlooked, adversely affecting prediction performance. In this
paper, we introduce a DEbiased Nearest Neighbors (DENN) framework for MLTC,
specifically designed to mitigate these biases. To address embedding alignment
bias, we propose a debiased contrastive learning strategy, enhancing neighbor
consistency on label co-occurrence. For confidence estimation bias, we present
a debiased confidence estimation strategy, improving the adaptive combination
of predictions from $k$NN and inductive binary classifications. Extensive
experiments conducted on four public benchmark datasets (i.e., AAPD, RCV1-V2,
Amazon-531, and EUR-LEX57K) showcase the effectiveness of our proposed method.
Besides, our method does not introduce any extra parameters.

摘要：多標籤文字分類 (MLTC) 是一項實用卻具有挑戰性的任務，涉及將多個非獨佔標籤指派給每個文件。先前的研究主要專注於擷取標籤關聯性，藉由引入特殊標籤架構、設計特定模型結構或新增輔助任務來協助標籤預測。最近，k 最近鄰 ($k$NN) 架構透過擷取標籤樣本作為參考，在嵌入空間中挖掘標籤共現資訊，展現了前景。然而，兩個關鍵偏差，即嵌入對齊偏差和信心估計偏差，經常被忽略，對預測效能產生負面影響。在本文中，我們介紹了用於 MLTC 的去偏差最近鄰 (DENN) 架構，特別設計用於減輕這些偏差。為了處理嵌入對齊偏差，我們提出了一種去偏差對比學習策略，增強鄰居在標籤共現上的一致性。對於信心估計偏差，我們提出了一種去偏差信心估計策略，改善了來自 $k$NN 和歸納二元分類的預測的適應性組合。在四個公開基準資料集（即 AAPD、RCV1-V2、Amazon-531 和 EUR-LEX57K）上進行的廣泛實驗展示了我們提出的方法的有效性。此外，我們的方法沒有引入任何額外參數。

##### **Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**
2408.03200v2 by Kunkun Hao, Yonggang Luo, Wen Cui, Yuqiao Bai, Jucheng Yang, Songyang Yan, Yuxi Pan, Zijiang Yang

Evaluating the decision-making system is indispensable in developing
autonomous vehicles, while realistic and challenging safety-critical test
scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks
to the long-tailed distribution, sparsity, and rarity in real-world data sets.
To tackle this problem, in this paper, we introduce a natural adversarial
scenario generation solution using naturalistic human driving priors and
reinforcement learning techniques. By doing this, we can obtain large-scale
test scenarios that are both diverse and realistic. Specifically, we build a
simulation environment that mimics natural traffic interaction scenarios.
Informed by this environment, we implement a two-stage procedure. The first
stage incorporates conventional rule-based models, e.g., IDM~(Intelligent
Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes)
model, to coarsely and discretely capture and calibrate key control parameters
from the real-world dataset. Next, we leverage GAIL~(Generative Adversarial
Imitation Learning) to represent driver behaviors continuously. The derived
GAIL can be further used to design a PPO~(Proximal Policy Optimization)-based
actor-critic network framework to fine-tune the reward function, and then
optimizes our natural adversarial scenario generation solution. Extensive
experiments have been conducted in the NGSIM dataset including the trajectory
of 3,000 vehicles. Essential traffic parameters were measured in comparison
with the baseline model, e.g., the collision rate, accelerations, steering, and
the number of lane changes. Our findings demonstrate that the proposed model
can generate realistic safety-critical test scenarios covering both naturalness
and adversariality, which can be a cornerstone for the development of
autonomous vehicles.

摘要：在開發自動駕駛車輛時，評估決策系統是不可或缺的，而逼真且具有挑戰性的安全關鍵測試情境扮演著至關重要的角色。要取得這些情境並非易事，這是因為在現實世界的資料集中存在長尾分布、稀疏性和稀有性。為了解決這個問題，我們在本文中介紹了一種使用自然對抗情境生成解決方案，該解決方案採用自然的人類駕駛先驗和強化學習技術。透過這樣做，我們可以取得既多樣化又逼真的大規模測試情境。具體來說，我們建立了一個模擬環境，模擬了自然的交通互動情境。在這個環境的指導下，我們實施了一個兩階段程序。第一階段納入了傳統的基於規則的模型，例如 IDM（智慧駕駛模型）和 MOBIL（最小化換車道造成的整體煞車）模型，以粗略且離散的方式擷取和校準來自現實世界資料集的主要控制參數。接下來，我們利用 GAIL（生成對抗模仿學習）來持續表示駕駛行為。衍生的 GAIL 可進一步用於設計一個基於 PPO（近端策略最佳化）的動作-評論網路架構，以微調獎勵函數，然後最佳化我們的自然對抗情境生成解決方案。我們在 NGSIM 資料集中進行了廣泛的實驗，其中包括 3,000 輛車輛的軌跡。與基準模型相比，我們測量了重要的交通參數，例如碰撞率、加速度、轉向和換車道次數。我們的研究結果表明，所提出的模型可以生成涵蓋自然性和對抗性的逼真安全關鍵測試情境，這可能是開發自動駕駛車輛的基石。

##### **Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**
2408.03172v1 by Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi

With the surge in digital content in low-resource languages, there is an
escalating demand for advanced Natural Language Processing (NLP) techniques
tailored to these languages. BERT (Bidirectional Encoder Representations from
Transformers), serving as the foundational framework for numerous NLP
architectures and language models, is increasingly employed for the development
of low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method
for fine-tuning Large Language Models (LLMs) and reducing the training
parameters to some extent to decrease the computational costs needed for
training the model and achieve results comparable to a fully fine-tuned model.
In this work, we present a study of PEFT methods for the Indic low-resource
language Marathi. We conduct a comprehensive analysis of PEFT methods applied
to various monolingual and multilingual Marathi BERT models. These approaches
are evaluated on prominent text classification datasets like MahaSent,
MahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to
significantly expedite the training speed of the models, addressing a critical
aspect of model development and deployment. In this study, we explore Low-Rank
Adaptation of Large Language Models (LoRA) and adapter methods for low-resource
text classification. We show that these methods are competitive with full
fine-tuning and can be used without loss in accuracy. This study contributes
valuable insights into the effectiveness of Marathi BERT models, offering a
foundation for the continued advancement of NLP capabilities in Marathi and
similar Indic languages.

摘要：<paragraph>隨著低資源語言的數位內容激增，對於針對這些語言量身打造的先進自然語言處理 (NLP) 技術的需求也與日俱增。BERT（來自 Transformer 的雙向編碼器表示法）作為許多 NLP 架構和語言模型的基本架構，正日益用於開發低資源 NLP 模型。參數高效微調 (PEFT) 是一種微調大型語言模型 (LLM) 並在一定程度上減少訓練參數的方法，以降低訓練模型所需的運算成本，並獲得與完全微調模型相當的結果。在這項工作中，我們提出對印度低資源語言馬拉提語的 PEFT 方法進行研究。我們對應用於各種單語和多語馬拉提語 BERT 模型的 PEFT 方法進行了全面分析。這些方法在著名的文本分類資料集（例如 MahaSent、MahaHate 和 MahaNews）上進行評估。PEFT 技術的整合被證明可以顯著加快模型的訓練速度，解決了模型開發和部署的一個關鍵方面。在這項研究中，我們探討了大型語言模型 (LoRA) 的低秩適應和低資源文本分類的適配器方法。我們表明，這些方法與完全微調具有競爭力，並且可以在不損失準確性的情況下使用。這項研究對馬拉提語 BERT 模型的有效性提供了有價值的見解，為馬拉提語和類似印度語言的 NLP 能力持續進步奠定了基礎。</paragraph>

##### **Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**
2408.03168v1 by Elia Cereda, Alessandro Giusti, Daniele Palossi

Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning
(TinyML), such as nano-drones, are becoming an increasingly attractive
technology. Their small form factor (i.e., ~10cm diameter) ensures vast
applicability, ranging from the exploration of narrow disaster scenarios to
safe human-robot interaction. Simple electronics make these CPSes inexpensive,
but strongly limit the computational, memory, and sensing resources available
on board. In real-world applications, these limitations are further exacerbated
by domain shift. This fundamental machine learning problem implies that model
perception performance drops when moving from the training domain to a
different deployment one. To cope with and mitigate this general problem, we
present a novel on-device fine-tuning approach that relies only on the limited
ultra-low power resources available aboard nano-drones. Then, to overcome the
lack of ground-truth training labels aboard our CPS, we also employ a
self-supervised method based on ego-motion consistency. Albeit our work builds
on top of a specific real-world vision-based human pose estimation task, it is
widely applicable for many embedded TinyML use cases. Our 512-image on-device
training procedure is fully deployed aboard an ultra-low power GWT GAP9
System-on-Chip and requires only 1MB of memory while consuming as low as 19mW
or running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our
on-device learning approach by field-testing our closed-loop CPS, showing a
reduction in horizontal position error of up to 26% vs. a non-fine-tuned
state-of-the-art baseline. In the most challenging never-seen-before
environment, our on-device learning procedure makes the difference between
succeeding or failing the mission.

摘要：<paragraph>由微型機器學習（TinyML）驅動的微型化網際網路實體系統（CPS），例如奈米無人機，正成為越來越有吸引力的技術。它們的小外形（即直徑約 10 公分）確保了廣泛的適用性，從探索狹窄的災難場景到安全的人機互動。簡單的電子產品讓這些 CPS 價格低廉，但極大地限制了機載的運算、記憶體和感測資源。在實際應用中，這些限制因領域轉移而進一步惡化。這個基本的機器學習問題意味著，當從訓練領域轉移到不同的部署領域時，模型感知效能會下降。為了應對和減輕這個普遍問題，我們提出了一種新穎的裝置上微調方法，僅依賴於奈米無人機上可用的有限超低功率資源。然後，為了克服我們的 CPS 上缺乏地面真實訓練標籤，我們還採用了一種基於自我運動一致性的自監督方法。儘管我們的研究建立在具體的真實世界基於視覺的人體姿勢估計任務之上，但它廣泛適用於許多嵌入式 TinyML 使用案例。我們的 512 影像裝置上訓練程序完全部署在超低功率 GWT GAP9 晶片組上，只需要 1MB 的記憶體，同時消耗低至 19mW，或僅在 510ms（38mW）下執行。最後，我們透過實地測試我們的閉環 CPS 來展示我們的裝置上學習方法的優點，與非微調的最新基準相比，顯示水平位置誤差減少了 26%。在最具挑戰性的前所未見環境中，我們的裝置上學習程序在任務的成功或失敗之間產生了差異。</paragraph>

##### **Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**
2408.03164v1 by Rabih Chamas, Ismail Khalfaoui-Hassani, Timothee Masquelier

Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced
convolution method that allows enlarging the receptive fields (RF) without
increasing the number of parameters, like the dilated convolution, yet without
imposing a regular grid. DCLS has been shown to outperform the standard and
dilated convolutions on several computer vision benchmarks. Here, we show that,
in addition, DCLS increases the models' interpretability, defined as the
alignment with human visual strategies. To quantify it, we use the Spearman
correlation between the models' GradCAM heatmaps and the ClickMe dataset
heatmaps, which reflect human visual attention. We took eight reference models
- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and
36) - and drop-in replaced the standard convolution layers with DCLS ones. This
improved the interpretability score in seven of them. Moreover, we observed
that Grad-CAM generated random heatmaps for two models in our study: CAFormer
and ConvFormer models, leading to low interpretability scores. We addressed
this issue by introducing Threshold-Grad-CAM, a modification built on top of
Grad-CAM that enhanced interpretability across nearly all models. The code and
checkpoints to reproduce this study are available at:
https://github.com/rabihchamas/DCLS-GradCAM-Eval.

摘要：可學習間距擴展卷積 (DCLS) 是一種近期進階的卷積方法，允許擴展感受野 (RF)，而無須增加參數數量，就像擴展卷積一樣，但無須強制使用規則網格。已證實 DCLS 在多個電腦視覺基準上優於標準卷積和擴展卷積。在此，我們展示 DCLS 除了能提升模型的可詮釋性，定義為與人類視覺策略的一致性。為量化它，我們使用模型的 GradCAM 熱圖與 ClickMe 資料集熱圖之間的 Spearman 相關性，它反映了人類的視覺注意力。我們採用了八個參考模型 - ResNet50、ConvNeXt (T、S 和 B)、CAFormer、ConvFormer 和 FastViT (sa 24 和 36) - 並以 DCLS 取代標準卷積層。這提升了其中七個模型的可詮釋性分數。此外，我們觀察到 Grad-CAM 為我們研究中的兩個模型產生了隨機熱圖：CAFormer 和 ConvFormer 模型，導致可詮釋性分數低。我們透過引入 Threshold-Grad-CAM 來解決這個問題，這是一種建立在 Grad-CAM 之上的修改，可增強幾乎所有模型的可詮釋性。可於以下網址取得重現此研究的程式碼和檢查點：https://github.com/rabihchamas/DCLS-GradCAM-Eval。

##### **Conditioning LLMs with Emotion in Neural Machine Translation**
2408.03150v1 by Charles Brazier, Jean-Luc Rouas

Large Language Models (LLMs) have shown remarkable performance in Natural
Language Processing tasks, including Machine Translation (MT). In this work, we
propose a novel MT pipeline that integrates emotion information extracted from
a Speech Emotion Recognition (SER) model into LLMs to enhance translation
quality. We first fine-tune five existing LLMs on the Libri-trans dataset and
select the most performant model. Subsequently, we augment LLM prompts with
different dimensional emotions and train the selected LLM under these different
configurations. Our experiments reveal that integrating emotion information,
especially arousal, into LLM prompts leads to notable improvements in
translation quality.

摘要：大型語言模型 (LLM) 在自然語言處理任務，包括機器翻譯 (MT)，中展現出卓越的表現。在這項工作中，我們提出一個創新的 MT 管道，將從語音情緒辨識 (SER) 模型中提取的情緒資訊整合到 LLM 中，以提升翻譯品質。我們首先在 Libri-trans 資料集上微調五個現有的 LLM，並選出表現最佳的模型。接著，我們使用不同維度的情緒擴充 LLM 提示，並在這些不同的設定下訓練選定的 LLM。我們的實驗顯示，將情緒資訊，尤其是喚醒，整合到 LLM 提示中，會顯著提升翻譯品質。

##### **Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**
2408.03149v1 by Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen

The rapid increase in multimedia data has spurred advancements in Multimodal
Summarization with Multimodal Output (MSMO), which aims to produce a multimodal
summary that integrates both text and relevant images. The inherent
heterogeneity of content within multimodal inputs and outputs presents a
significant challenge to the execution of MSMO. Traditional approaches
typically adopt a holistic perspective on coarse image-text data or individual
visual objects, overlooking the essential connections between objects and the
entities they represent. To integrate the fine-grained entity knowledge, we
propose an Entity-Guided Multimodal Summarization model (EGMS). Our model,
building on BART, utilizes dual multimodal encoders with shared weights to
process text-image and entity-image information concurrently. A gating
mechanism then combines visual data for enhanced textual summary generation,
while image selection is refined through knowledge distillation from a
pre-trained vision-language model. Extensive experiments on public MSMO dataset
validate the superiority of the EGMS method, which also prove the necessity to
incorporate entity information into MSMO problem.

摘要：隨著多媒體資料的快速增加，刺激了多模態輸出多模態摘要 (MSMO) 的進展，其目標是產生一個整合文字和相關影像的多模態摘要。多模態輸入和輸出內在的異質性，對 MSMO 的執行構成重大挑戰。傳統方法通常採用整體觀點，針對粗略的影像文字資料或個別視覺物件，忽略了物件與其所代表實體之間的本質關聯性。為了整合細粒度的實體知識，我們提出一個實體引導式多模態摘要模型 (EGMS)。我們的模型建構在 BART 上，利用具有共享權重的雙重多模態編碼器，同時處理文字影像和實體影像資訊。一個閘控機制接著結合視覺資料，以增強文字摘要的生成，同時透過預先訓練的視覺語言模型的知識萃取，精煉影像選擇。在公開 MSMO 資料集上的廣泛實驗驗證了 EGMS 方法的優越性，也證明了將實體資訊納入 MSMO 問題的必要性。

##### **Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**
2408.03130v1 by Leo Donisch, Sigurd Schacht, Carsten Lanquillon

Large language models are ubiquitous in natural language processing because
they can adapt to new tasks without retraining. However, their sheer scale and
complexity present unique challenges and opportunities, prompting researchers
and practitioners to explore novel model training, optimization, and deployment
methods. This literature review focuses on various techniques for reducing
resource requirements and compressing large language models, including
quantization, pruning, knowledge distillation, and architectural optimizations.
The primary objective is to explore each method in-depth and highlight its
unique challenges and practical applications. The discussed methods are
categorized into a taxonomy that presents an overview of the optimization
landscape and helps navigate it to understand the research trajectory better.

摘要：大型語言模型在自然語言處理中無處不在，因為它們無需重新訓練即可適應新任務。然而，它們的規模和複雜性帶來了獨特的挑戰和機遇，促使研究人員和從業者探索新的模型訓練、最佳化和部署方法。這篇文獻回顧重點探討各種技術，以減少資源需求並壓縮大型語言模型，包括量化、剪枝、知識蒸餾和架構最佳化。主要目標是深入探討每種方法，並強調其獨特的挑戰和實際應用。所討論的方法被分類到一個分類法中，該分類法概述了最佳化領域，並有助於瀏覽它以更好地理解研究軌跡。

##### **Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**
2408.03127v1 by Artur Guimarães, Bruno Martins, João Magalhães

This paper describes our approach to the SemEval-2024 safe biomedical Natural
Language Inference for Clinical Trials (NLI4CT) task, which concerns
classifying statements about Clinical Trial Reports (CTRs). We explored the
capabilities of Mistral-7B, a generalist open-source Large Language Model
(LLM). We developed a prompt for the NLI4CT task, and fine-tuned a quantized
version of the model using an augmented version of the training dataset. The
experimental results show that this approach can produce notable results in
terms of the macro F1-score, while having limitations in terms of faithfulness
and consistency. All the developed code is publicly available on a GitHub
repository

摘要：本文描述了我們對 SemEval-2024 安全生物醫學自然語言推論臨床試驗 (NLI4CT) 任務的方法，該任務涉及對臨床試驗報告 (CTR) 中的陳述進行分類。我們探討了 Mistral-7B 的能力，這是一個通才的開源大型語言模型 (LLM)。我們為 NLI4CT 任務開發了一個提示，並使用訓練數據集的擴充版本對模型的量化版本進行了微調。實驗結果表明，這種方法在宏觀 F1 分數方面可以產生顯著的結果，同時在保真度和一致性方面存在局限性。所有已開發的代碼都公開發布在 GitHub 倉庫中

##### **COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**
2408.03125v1 by Rajvee Sheth, Shubh Nisar, Heenaben Prajapati, Himanshu Beniwal, Mayank Singh

As the NLP community increasingly addresses challenges associated with
multilingualism, robust annotation tools are essential to handle multilingual
datasets efficiently. In this paper, we introduce a code-mixed multilingual
text annotation framework, COMMENTATOR, specifically designed for annotating
code-mixed text. The tool demonstrates its effectiveness in token-level and
sentence-level language annotation tasks for Hinglish text. We perform robust
qualitative human-based evaluations to showcase COMMENTATOR led to 5x faster
annotations than the best baseline. Our code is publicly available at
\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is
available at \url{https://bit.ly/commentator_video}.

摘要：隨著 NLP 社群日益著重於因多語言性而面臨的挑戰，穩健的註解工具對於有效處理多語言資料集至關重要。在本文中，我們介紹了一個程式碼混合多語言文字註解架構 COMMENTATOR，專門設計用於註解程式碼混合文字。此工具展現其在 Hinglish 文字的詞元層級和句子層級語言註解任務中的效能。我們執行穩健的定性人工評估，以展示 COMMENTATOR 的註解速度比最佳基線快 5 倍。我們的程式碼已公開於 \url{https://github.com/lingo-iitgn/commentator}。示範影片可於 \url{https://bit.ly/commentator_video} 取得。

##### **Evaluating the Translation Performance of Large Language Models Based on Euas-20**
2408.03119v1 by Yan Huang, Wei Liu

In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.

摘要：近年來，隨著深度學習技術的快速發展，
BERT 和 GPT 等大型語言模型（LLM）在自然語言處理任務中取得了突破性的
成果。機器翻譯（MT）作為自然語言處理的核心任務之一，也受益於
大型語言模型的發展而取得了質的飛躍。儘管大型語言模型在翻譯性能上取得了顯著進展，
機器翻譯仍然面臨著諸多挑戰。因此，本文構建了 Euas-20 數據集，用於評估大型
語言模型在翻譯任務上的表現、不同語言的翻譯能力，以及預訓練數據對 LLM 翻譯能力的影響，供研究人員和開發人員使用。

##### **Topic Modeling with Fine-tuning LLMs and Bag of Sentences**
2408.03099v1 by Johannes Schneider

Large language models (LLM)'s are increasingly used for topic modeling
outperforming classical topic models such as LDA. Commonly, pre-trained LLM
encoders such as BERT are used out-of-the-box despite the fact that fine-tuning
is known to improve LLMs considerably. The challenge lies in obtaining a
suitable (labeled) dataset for fine-tuning. In this paper, we use the recent
idea to use bag of sentences as the elementary unit in computing topics. In
turn, we derive an approach FT-Topic to perform unsupervised fine-tuning
relying primarily on two steps for constructing a training dataset in an
automatic fashion. First, a heuristic method to identifies pairs of sentence
groups that are either assumed to be of the same or different topics. Second,
we remove sentence pairs that are likely labeled incorrectly. The dataset is
then used to fine-tune an encoder LLM, which can be leveraged by any topic
modeling approach using embeddings. However, in this work, we demonstrate its
effectiveness by deriving a novel state-of-the-art topic modeling method called
SenClu, which achieves fast inference through an expectation-maximization
algorithm and hard assignments of sentence groups to a single topic, while
giving users the possibility to encode prior knowledge on the topic-document
distribution. Code is at \url{https://github.com/JohnTailor/FT-Topic}

摘要：大型語言模型 (LLM) 愈來愈常被用於主題模型，其效能優於 LDA 等傳統主題模型。儘管微調已知能大幅改善 LLM，但通常會直接使用預先訓練好的 LLM 編碼器，例如 BERT。挑戰在於取得適合的（標籤）資料集以進行微調。在本文中，我們採用最近的想法，將句子組當作運算主題的基本單位。反過來，我們衍生出 FT-Topic 方法，以執行非監督式微調，主要依賴兩個步驟自動建構訓練資料集。首先，採用啟發式方法來識別假設為同主題或不同主題的句子組對。其次，我們移除標籤可能不正確的句子對。然後使用資料集微調編碼器 LLM，任何使用嵌入式的主題模型方法都能運用該編碼器。然而，我們在此工作中透過衍生出稱為 SenClu 的新式最先進主題模型方法，來證明其有效性。該方法透過期望值最大化演算法和句子組對單一主題的硬式指派，快速進行推論，同時讓使用者能夠對主題文件分布編碼先驗知識。程式碼位於 \url{https://github.com/JohnTailor/FT-Topic}

##### **500xCompressor: Generalized Prompt Compression for Large Language Models**
2408.03094v1 by Zongqian Li, Yixuan Su, Nigel Collier

Prompt compression is crucial for enhancing inference speed, reducing costs,
and improving user experience. However, current methods face challenges such as
low compression ratios and potential data leakage during evaluation. To address
these issues, we propose 500xCompressor, a method that compresses extensive
natural language contexts into a minimum of one single special token. The
500xCompressor introduces approximately 0.3% additional parameters and achieves
compression ratios ranging from 6x to 480x. It is designed to compress any
text, answer various types of questions, and could be utilized by the original
large language model (LLM) without requiring fine-tuning. Initially,
500xCompressor was pretrained on the Arxiv Corpus, followed by fine-tuning on
the ArxivQA dataset, and subsequently evaluated on strictly unseen and
classical question answering (QA) datasets. The results demonstrate that the
LLM retained 62.26-72.89% of its capabilities compared to using non-compressed
prompts. This study also shows that not all the compressed tokens are equally
utilized and that K V values have significant advantages over embeddings in
preserving information at high compression ratios. The highly compressive
nature of natural language prompts, even for fine-grained complex information,
suggests promising potential for future applications and further research into
developing a new LLM language.

摘要：提示壓縮對於提升推論速度、降低成本和改善使用者體驗至關重要。然而，目前的方法面臨低壓縮率和評估期間潛在資料外洩等挑戰。為了解決這些問題，我們提出 500xCompressor，這是一種將廣泛的自然語言脈絡壓縮成最少一個特殊符號的方法。500xCompressor 引入了約 0.3% 的額外參數，並達到了 6 倍到 480 倍的壓縮率。它被設計用於壓縮任何文字、回答各種類型的問題，並且可以在不需微調的情況下由原始的大語言模型 (LLM) 使用。最初，500xCompressor 在 Arxiv Corpus 上進行預訓練，然後在 ArxivQA 資料集上進行微調，最後在完全未見過和經典的問題解答 (QA) 資料集上進行評估。結果表明，與使用未壓縮提示相比，LLM 保留了 62.26-72.89% 的能力。這項研究還表明，並非所有壓縮的符號都得到平等利用，並且 K V 值在高壓縮率下比嵌入式更具備保留資訊的優勢。即使對於細緻複雜的資訊，自然語言提示的高度壓縮特性也顯示出未來應用和進一步研究開發新的 LLM 語言的潛力。

##### **Learning Provably Robust Policies in Uncertain Parametric Environments**
2408.03093v1 by Yannik Schnitzer, Alessandro Abate, David Parker

We present a data-driven approach for learning MDP policies that are robust
across stochastic environments whose transition probabilities are defined by
parameters with an unknown distribution. We produce probably approximately
correct (PAC) guarantees for the performance of these learned policies in a
new, unseen environment over the unknown distribution. Our approach is based on
finite samples of the MDP environments, for each of which we build an
approximation of the model as an interval MDP, by exploring a set of generated
trajectories. We use the built approximations to synthesise a single policy
that performs well (meets given requirements) across the sampled environments,
and furthermore bound its risk (of not meeting the given requirements) when
deployed in an unseen environment. Our procedure offers a trade-off between the
guaranteed performance of the learned policy and the risk of not meeting the
guarantee in an unseen environment. Our approach exploits knowledge of the
environment's state space and graph structure, and we show how additional
knowledge of its parametric structure can be leveraged to optimize learning and
to obtain tighter guarantees from less samples. We evaluate our approach on a
diverse range of established benchmarks, demonstrating that we can generate
highly performing and robust policies, along with guarantees that tightly
quantify their performance and the associated risk.

摘要：<paragraph>我們提出一個資料驅動的方法，用於學習在隨機環境中穩健的 MDP 政策，其轉換機率由具有未知分佈的參數定義。我們為這些學習政策在未知分佈的新環境中產生的效能，提供近似正確 (PAC) 的保證。我們的做法是基於 MDP 環境的有限樣本，對於每個樣本，我們透過探索一組已產生的軌跡，建立一個區間 MDP 模型近似值。我們使用建立的近似值來綜合一個在採樣環境中表現良好的單一政策（符合給定的需求），並且進一步限制其風險（不符合給定需求）時，在未見環境中部署。我們的程序在學習政策的保證效能與在未見環境中不符合保證的風險之間，提供一個折衷方案。我們的做法利用環境狀態空間和圖形結構的知識，並且我們展示如何利用其參數結構的額外知識，來最佳化學習並從更少的樣本中獲得更嚴格的保證。我們在各種已建立的基準上評估我們的做法，證明我們可以產生高執行效能和穩健的政策，以及嚴格量化其效能和相關風險的保證。</paragraph>

##### **Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement**
2408.03092v1 by Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li

Merging Large Language Models (LLMs) aims to amalgamate multiple homologous
LLMs into one with all the capabilities. Ideally, any LLMs sharing the same
backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT)
with minor parameter changes or Pre-Trained (PT) with substantial parameter
shifts. However, existing methods often manually assign the model importance,
rendering them feasible only for LLMs with similar parameter alterations, such
as multiple FT LLMs. The diverse parameter changed ranges between FT and PT
LLMs pose challenges for current solutions in empirically determining the
optimal combination. In this paper, we make a pioneering effort to broaden the
applicability of merging techniques from FT to PT LLMs. We initially examine
the efficacy of current methods in merging FT and PT LLMs, discovering that
they struggle to deal with PT LLMs. Subsequently, we introduce an approach
based on WeIght DisENtanglement (WIDEN) to effectively extend the merging
scope, which first disentangles model weights into magnitude and direction
components, and then performs adaptive fusion by considering their respective
contributions. In the experiments, we merge Qwen1.5-Chat (an FT LLM with
instruction-following skills) with Sailor (a PT LLM with multilingual
abilities) across 7B and 14B model scales. Results reveal that: (1) existing
solutions usually fail when merging Sailor, either losing both abilities or
only retaining instruction-following skills; (2) WIDEN successfully injects the
multilingual abilities of Sailor into Qwen1.5-Chat and make it proficient in
Southeast Asian languages, achieving enhancements in the fundamental
capabilities. In light of previous research, we also merge multiple 13B FT LLMs
and observe that WIDEN achieves a balanced amalgamation of instruction
following, mathematical reasoning, and code generation skills.

摘要：合併大型語言模型 (LLM) 旨在將多個同源 LLM 整合為一個具備所有功能的 LLM。理想情況下，任何共享相同主幹的 LLM 都應該是可合併的，無論它們是否經過微調 (FT) 以進行較小的參數變更，或經過預訓練 (PT) 以進行大幅度的參數轉移。然而，現有的方法通常會手動指定模型重要性，使其僅適用於參數變更相似的 LLM，例如多個 FT LLM。FT 和 PT LLM 之間不同的參數變更範圍對當前解決方案在經驗上確定最佳組合構成挑戰。在本文中，我們做出了開創性的努力，將合併技術的適用性從 FT 擴展到 PT LLM。我們最初檢查了當前方法在合併 FT 和 PT LLM 中的功效，發現它們難以處理 PT LLM。隨後，我們引入了一種基於權重解開 (WIDEN) 的方法來有效擴展合併範圍，該方法首先將模型權重解開為大小和方向分量，然後通過考慮它們各自的貢獻來執行自適應融合。在實驗中，我們將 Qwen1.5-Chat（具有指令遵循技能的 FT LLM）與 Sailor（具有多語言能力的 PT LLM）合併在 7B 和 14B 模型規模中。結果表明：(1) 現有的解決方案在合併 Sailor 時通常會失敗，要麼失去兩種能力，要麼僅保留指令遵循技能；(2) WIDEN 成功地將 Sailor 的多語言能力注入 Qwen1.5-Chat，使其精通東南亞語言，並增強了基本能力。根據先前的研究，我們還合併了多個 13B FT LLM，並觀察到 WIDEN 達到了指令遵循、數學推理和程式碼生成技能的平衡融合。

##### **Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**
2408.03079v1 by Jinglong Gao, Chen Lu, Xiao Ding, Zhongyang Li, Ting Liu, Bing Qin

Event Causality Extraction (ECE) aims at extracting causal event pairs from
texts. Despite ChatGPT's recent success, fine-tuning small models remains the
best approach for the ECE task. However, existing fine-tuning based ECE methods
cannot address all three key challenges in ECE simultaneously: 1) Complex
Causality Extraction, where multiple causal-effect pairs occur within a single
sentence; 2) Subtask~ Interaction, which involves modeling the mutual
dependence between the two subtasks of ECE, i.e., extracting events and
identifying the causal relationship between extracted events; and 3) Knowledge
Fusion, which requires effectively fusing the knowledge in two modalities,
i.e., the expressive pretrained language models and the structured knowledge
graphs. In this paper, we propose a unified ECE framework (UniCE to address all
three issues in ECE simultaneously. Specifically, we design a subtask
interaction mechanism to enable mutual interaction between the two ECE
subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in
the two modalities. Furthermore, we employ separate decoders for each subtask
to facilitate complex causality extraction. Experiments on three benchmark
datasets demonstrate that our method achieves state-of-the-art performance and
outperforms ChatGPT with a margin of at least 30% F1-score. More importantly,
our model can also be used to effectively improve the ECE performance of
ChatGPT via in-context learning.

摘要：事件因果關係萃取 (ECE) 的目標是從文本中萃取出因果事件對。儘管 ChatGPT 最近獲得成功，微調小型模型仍是 ECE 任務的最佳方法。然而，現有的基於微調的 ECE 方法無法同時解決 ECE 中的三個主要挑戰：1) 複雜因果關係萃取，其中多個因果關係對出現在單一句子中；2) 子任務互動，這涉及對 ECE 的兩個子任務（即萃取事件和識別萃取事件之間的因果關係）之間的相互依賴性進行建模；3) 知識融合，這需要有效地融合兩種模式中的知識，即表達式的預訓練語言模型和結構化的知識圖譜。在本文中，我們提出一個統一的 ECE 框架 (UniCE)，以同時解決 ECE 中的所有三個問題。具體來說，我們設計了一個子任務互動機制，以實現兩個 ECE 子任務之間的相互互動。此外，我們設計了一個知識融合機制來融合兩種模式中的知識。此外，我們針對每個子任務採用單獨的解碼器，以促進複雜因果關係的萃取。在三個基準資料集上的實驗表明，我們的方法達到了最先進的效能，並且以至少 30% 的 F1 分數優於 ChatGPT。更重要的是，我們的模型也可以透過情境學習有效地提升 ChatGPT 的 ECE 效能。

##### **BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications**
2408.03078v1 by G. Manni, C. Lauretti, F. Prata, R. Papalia, L. Zollo, P. Soda

Endoscopic surgery relies on two-dimensional views, posing challenges for
surgeons in depth perception and instrument manipulation. While Simultaneous
Localization and Mapping (SLAM) has emerged as a promising solution to address
these limitations, its implementation in endoscopic procedures presents
significant challenges due to hardware limitations, such as the use of a
monocular camera and the absence of odometry sensors. This study presents a
robust deep learning-based SLAM approach that combines state-of-the-art and
newly developed models. It consists of three main parts: the Monocular Pose
Estimation Module that introduces a novel unsupervised method based on the
CycleGAN architecture, the Monocular Depth Estimation Module that leverages the
novel Zoe architecture, and the 3D Reconstruction Module which uses information
from the previous models to create a coherent surgical map. The performance of
the procedure was rigorously evaluated using three publicly available datasets
(Hamlyn, EndoSLAM, and SCARED) and benchmarked against two state-of-the-art
methods, EndoSFMLearner and EndoDepth. The integration of Zoe in the MDEM
demonstrated superior performance compared to state-of-the-art depth estimation
algorithms in endoscopy, whereas the novel approach in the MPEM exhibited
competitive performance and the lowest inference time. The results showcase the
robustness of our approach in laparoscopy, gastroscopy, and colonoscopy, three
different scenarios in endoscopic surgery. The proposed SLAM approach has the
potential to improve the accuracy and efficiency of endoscopic procedures by
providing surgeons with enhanced depth perception and 3D reconstruction
capabilities.

摘要：內視鏡手術依賴於二維視圖，對外科醫生在深度感知和器械操作方面構成挑戰。雖然同時定位與建圖 (SLAM) 已成為解決這些限制的有希望的方案，但由於硬體限制，例如使用單眼相機和缺乏里程計感測器，其在內視鏡手術中的實施面臨重大挑戰。本研究提出了一種強大的深度學習式 SLAM 方法，結合了最先進和新開發的模型。它包含三個主要部分：單眼姿勢估計模組，引入了基於 CycleGAN 架構的新型非監督式方法；單眼深度估計模組，利用了新型 Zoe 架構；以及 3D 重建模組，它使用前一模型中的資訊來建立一個連貫的手術地圖。使用三個公開可用的資料集（Hamlyn、EndoSLAM 和 SCARED）嚴格評估了該手術的效能，並根據兩個最先進的方法 EndoSFMLearner 和 EndoDepth 進行基準測試。與內視鏡中最先進的深度估計演算法相比，Zoe 在 MDEM 中的整合表現出優異的效能，而 MPEM 中的新方法表現出競爭力且推論時間最短。結果展示了我們的方法在腹腔鏡檢查、胃鏡檢查和結腸鏡檢查中的穩健性，這是內視鏡手術中的三種不同場景。所提出的 SLAM 方法有可能透過為外科醫生提供增強的深度感知和 3D 重建能力，來提高內視鏡手術的準確性和效率。

##### **Towards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models**
2408.03074v1 by Amelie Robrecht, Judith Sieker, Clara Lachenmaier, Sina Zarieß, Stefan Kopp

In this work, we want to give an overview on which pragmatic abilities have
been tested in LLMs so far and how these tests have been carried out. To do
this, we first discuss the scope of the field of pragmatics and suggest a
subdivision into discourse pragmatics and interactional pragmatics. We give a
non-exhaustive overview of the phenomena of those two subdomains and the
methods traditionally used to analyze them. We subsequently consider the
resulting heterogeneous set of phenomena and methods as a starting point for
our survey of work on discourse pragmatics and interactional pragmatics in the
context of LLMs.

摘要：在這項研究中，我們希望概述到目前為止在 LLM 中測試過哪些語用能力，以及這些測試是如何進行的。為此，我們首先討論語用學領域的範圍，並建議將其細分為語篇語用學和互動語用學。我們對這兩個子領域的現象以及傳統上用於分析它們的方法進行了非詳盡的概述。隨後，我們將由此產生的異質現象和方法集合作為我們在 LLM 背景下對語篇語用學和互動語用學工作的調查的起點。

##### **Probing structural constraints of negation in Pretrained Language Models**
2408.03070v1 by David Kletz, Marie Candito, Pascal Amsili

Contradictory results about the encoding of the semantic impact of negation
in pretrained language models (PLMs). have been drawn recently (e.g. Kassner
and Sch{\"u}tze (2020); Gubelmann and Handschuh (2022)). In this paper we focus
rather on the way PLMs encode negation and its formal impact, through the
phenomenon of the Negative Polarity Item (NPI) licensing in English. More
precisely, we use probes to identify which contextual representations best
encode 1) the presence of negation in a sentence, and 2) the polarity of a
neighboring masked polarity item. We find that contextual representations of
tokens inside the negation scope do allow for (i) a better prediction of the
presence of not compared to those outside the scope and (ii) a better
prediction of the right polarity of a masked polarity item licensed by not,
although the magnitude of the difference varies from PLM to PLM. Importantly,
in both cases the trend holds even when controlling for distance to not. This
tends to indicate that the embeddings of these models do reflect the notion of
negation scope, and do encode the impact of negation on NPI licensing. Yet,
further control experiments reveal that the presence of other lexical items is
also better captured when using the contextual representation of a token within
the same syntactic clause than outside from it, suggesting that PLMs simply
capture the more general notion of syntactic clause.

摘要：最近关于否定语义影响编码的矛盾结果在预训练语言模型 (PLM) 中被提出（例如 Kassner 和 Schutze (2020)；Gubelmann 和 Handschuh (2022)）。在本文中，我们更专注于 PLM 编码否定及其形式影响的方式，通过英语中否定极性项目 (NPI) 许可的现象。更准确地说，我们使用探测来识别哪些上下文表示最能编码 1) 句子中否定的存在，以及 2) 相邻掩码极性项目的极性。我们发现否定范围内的标记的上下文表示确实允许 (i) 与范围外的标记相比，更好地预测 not 的存在，以及 (ii) 更好地预测由 not 许可的掩码极性项目的正确极性，尽管差异的幅度因 PLM 而异。重要的是，在这两种情况下，即使在控制与 not 的距离时，趋势仍然成立。这倾向于表明这些模型的嵌入确实反映了否定范围的概念，并确实对否定对 NPI 许可的影响进行编码。然而，进一步的控制实验表明，在同一语法子句中使用标记的上下文表示比在子句外使用标记的上下文表示时，其他词法项目的出现也能得到更好的捕捉，这表明 PLM 仅仅捕捉到语法子句的更一般概念。

##### **Analysis of Argument Structure Constructions in a Deep Recurrent Language Model**
2408.03062v1 by Pegah Ramezani, Achim Schilling, Patrick Krauss

Understanding how language and linguistic constructions are processed in the
brain is a fundamental question in cognitive computational neuroscience. In
this study, we explore the representation and processing of Argument Structure
Constructions (ASCs) in a recurrent neural language model. We trained a Long
Short-Term Memory (LSTM) network on a custom-made dataset consisting of 2000
sentences, generated using GPT-4, representing four distinct ASCs: transitive,
ditransitive, caused-motion, and resultative constructions.
  We analyzed the internal activations of the LSTM model's hidden layers using
Multidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding
(t-SNE) to visualize the sentence representations. The Generalized
Discrimination Value (GDV) was calculated to quantify the degree of clustering
within these representations. Our results show that sentence representations
form distinct clusters corresponding to the four ASCs across all hidden layers,
with the most pronounced clustering observed in the last hidden layer before
the output layer. This indicates that even a relatively simple,
brain-constrained recurrent neural network can effectively differentiate
between various construction types.
  These findings are consistent with previous studies demonstrating the
emergence of word class and syntax rule representations in recurrent language
models trained on next word prediction tasks. In future work, we aim to
validate these results using larger language models and compare them with
neuroimaging data obtained during continuous speech perception. This study
highlights the potential of recurrent neural language models to mirror
linguistic processing in the human brain, providing valuable insights into the
computational and neural mechanisms underlying language understanding.

摘要：<paragraph>了解語言和語言建構如何在腦中被處理，是認知計算神經科學中的基本問題。在這項研究中，我們探索了遞迴神經語言模型中論元結構建構（ASC）的表示和處理。我們訓練了一個長短期記憶（LSTM）網路，使用一個由 GPT-4 生成的，包含 2000 個句子的自訂資料集，代表四個不同的 ASC：及物、雙及物、致動和結果建構。
  我們使用多維度縮放（MDS）和 t 分布隨機鄰域嵌入（t-SNE）分析了 LSTM 模型隱藏層的內部激活，以視覺化句子表示。計算廣義判別值（GDV）以量化這些表示中的聚類程度。我們的結果表明，句子表示在所有隱藏層中形成對應於四個 ASC 的不同群集，在輸出層之前的最後一個隱藏層中觀察到最明顯的聚類。這表明即使是一個相對簡單、受大腦約束的遞迴神經網路也能有效區分各種建構類型。
  這些發現與先前的研究一致，這些研究證明了在訓練於下一個字預測任務的遞迴語言模型中，詞類和句法規則表示的出現。在未來的研究中，我們旨在使用更大的語言模型驗證這些結果，並將它們與在連續語音感知過程中獲得的神經影像數據進行比較。這項研究強調了遞迴神經語言模型反映人腦中語言處理的潛力，為語言理解的計算和神經機制提供了寶貴的見解。</paragraph>

##### **OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents**
2408.03047v1 by Qiang Sun, Yuanyi Luo, Sirui Li, Wenxiao Zhang, Wei Liu

Multimodal conversational agents are highly desirable because they offer
natural and human-like interaction. However, there is a lack of comprehensive
end-to-end solutions to support collaborative development and benchmarking.
While proprietary systems like GPT-4o and Gemini demonstrating impressive
integration of audio, video, and text with response times of 200-250ms,
challenges remain in balancing latency, accuracy, cost, and data privacy. To
better understand and quantify these issues, we developed OpenOmni, an
open-source, end-to-end pipeline benchmarking tool that integrates advanced
technologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented
Generation, Large Language Models, along with the ability to integrate
customized models. OpenOmni supports local and cloud deployment, ensuring data
privacy and supporting latency and accuracy benchmarking. This flexible
framework allows researchers to customize the pipeline, focusing on real
bottlenecks and facilitating rapid proof-of-concept development. OpenOmni can
significantly enhance applications like indoor assistance for visually impaired
individuals, advancing human-computer interaction. Our demonstration video is
available https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available via
https://openomni.ai4wa.com, code is available via
https://github.com/AI4WA/OpenOmniFramework.

摘要：多模态对话代理极具吸引力，因为它们提供自然且类似人类的互动。然而，缺乏全面的端到端解决方案来支持协作开发和基准测试。虽然像 GPT-4o 和 Gemini 这样的专有系统展示了令人印象深刻的音频、视频和文本集成，响应时间为 200-250 毫秒，但在平衡延迟、准确性、成本和数据隐私方面仍然存在挑战。为了更好地理解和量化这些问题，我们开发了 OpenOmni，这是一个开源的端到端管道基准测试工具，它集成了先进的技术，如语音转文本、情感检测、检索增强生成、大语言模型，以及集成自定义模型的能力。OpenOmni 支持本地和云部署，确保数据隐私并支持延迟和准确性基准测试。这个灵活的框架允许研究人员自定义管道，专注于真正的瓶颈并促进快速的概念验证开发。OpenOmni 可以显著增强应用程序，如为视障人士提供室内帮助，推进人机交互。我们的演示视频可在 https://www.youtube.com/watch?v=zaSiT3clWqY 获得，演示可在 https://openomni.ai4wa.com 获得，代码可在 https://github.com/AI4WA/OpenOmniFramework 获得。

##### **L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization**
2408.03033v1 by Elvys Linhares Pontes, Carlos-Emiliano González-Gallardo, Mohamed Benjannet, Caryn Qu, Antoine Doucet

This article details our participation (L3iTC) in the FinLLM Challenge Task
2024, focusing on two key areas: Task 1, financial text classification, and
Task 2, financial text summarization. To address these challenges, we
fine-tuned several large language models (LLMs) to optimize performance for
each task. Specifically, we used 4-bit quantization and LoRA to determine which
layers of the LLMs should be trained at a lower precision. This approach not
only accelerated the fine-tuning process on the training data provided by the
organizers but also enabled us to run the models on low GPU memory. Our
fine-tuned models achieved third place for the financial classification task
with an F1-score of 0.7543 and secured sixth place in the financial
summarization task on the official test datasets.

摘要：本文詳細說明我們（L3iTC）參與 2024 年 FinLLM 挑戰任務，重點關注兩個關鍵領域：任務 1，財務文字分類，以及任務 2，財務文字摘要。為了應對這些挑戰，我們微調了多個大型語言模型 (LLM)，以優化每個任務的效能。具體來說，我們使用 4 位元量化和 LoRA 來確定 LLM 的哪些層次應以較低的精度進行訓練。此方法不僅加速了組織者提供的訓練資料的微調過程，還使我們能夠在低 GPU 記憶體上執行模型。我們微調的模型在財務分類任務中以 0.7543 的 F1 分數獲得第三名，並在官方測試資料集中的財務摘要任務中獲得第六名。

##### **Integrating Controllable Motion Skills from Demonstrations**
2408.03018v1 by Honghao Liao, Zhiheng Li, Ziyu Meng, Ran Song, Yibin Li, Wei Zhang

The expanding applications of legged robots require their mastery of
versatile motion skills. Correspondingly, researchers must address the
challenge of integrating multiple diverse motion skills into controllers. While
existing reinforcement learning (RL)-based approaches have achieved notable
success in multi-skill integration for legged robots, these methods often
require intricate reward engineering or are restricted to integrating a
predefined set of motion skills constrained by specific task objectives,
resulting in limited flexibility. In this work, we introduce a flexible
multi-skill integration framework named Controllable Skills Integration (CSI).
CSI enables the integration of a diverse set of motion skills with varying
styles into a single policy without the need for complex reward tuning.
Furthermore, in a hierarchical control manner, the trained low-level policy can
be coupled with a high-level Natural Language Inference (NLI) module to enable
preliminary language-directed skill control. Our experiments demonstrate that
CSI can flexibly integrate a diverse array of motion skills more
comprehensively and facilitate the transitions between different skills.
Additionally, CSI exhibits good scalability as the number of motion skills to
be integrated increases significantly.

摘要：四足機器人的應用範圍不斷擴展，因此需要它們精通各種運動技能。相應地，研究人員必須解決將多種不同的運動技能整合到控制器中的挑戰。雖然現有的基於強化學習 (RL) 的方法在四足機器人的多技能整合中取得了顯著的成功，但這些方法通常需要複雜的獎勵工程，或者僅限於整合受特定任務目標約束的預定義運動技能集，導致靈活性受限。在這項工作中，我們引入了一個名為可控技能整合 (CSI) 的靈活多技能整合框架。CSI 能夠將具有不同風格的多種運動技能整合到單一策略中，而無需進行複雜的獎勵調整。此外，在分層控制方式中，訓練有素的低階策略可以與高階自然語言推理 (NLI) 模組結合，以實現初步的語言指導技能控制。我們的實驗表明，CSI 能夠靈活地整合更多樣化的運動技能，並促進不同技能之間的轉換。此外，隨著需要整合的運動技能數量大幅增加，CSI 展現出良好的可擴充性。

##### **Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**
2408.03010v1 by Daniel Steinigen, Roman Teucher, Timm Heine Ruland, Max Rudat, Nicolas Flores-Herr, Peter Fischer, Nikola Milosevic, Christopher Schymura, Angelo Ziletti

Recent advancements in Large Language Models (LLMs) have showcased their
proficiency in answering natural language queries. However, their effectiveness
is hindered by limited domain-specific knowledge, raising concerns about the
reliability of their responses. We introduce a hybrid system that augments LLMs
with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual
correctness using a KG-based retrieval approach. We focus on a medical KG to
demonstrate our methodology, which includes (1) pre-processing, (2) Cypher
query generation, (3) Cypher query processing, (4) KG retrieval, and (5)
LLM-enhanced response generation. We evaluate our system on a curated dataset
of 69 samples, achieving a precision of 78\% in retrieving correct KG nodes.
Our findings indicate that the hybrid system surpasses a standalone LLM in
accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method.
This positions the system as a promising tool for applications that demand
factual correctness and completeness, such as target identification -- a
critical process in pinpointing biological entities for disease treatment or
crop enhancement. Moreover, its intuitive search interface and ability to
provide accurate responses within seconds make it well-suited for
time-sensitive, precision-focused research contexts. We publish the source code
together with the dataset and the prompt templates used.

摘要：大型語言模型 (LLM) 的最新進展展示了它們在回答自然語言查詢方面的能力。然而，它們的有效性受到特定領域知識有限的阻礙，這引起了對其回應可靠性的擔憂。我們引入了一個混合系統，該系統使用特定領域的知識圖譜 (KG) 來擴充 LLM，從而旨在使用基於 KG 的檢索方法來增強事實正確性。我們專注於一個醫學 KG 來演示我們的 methodology，其中包括 (1) 預處理，(2) Cypher 查詢生成，(3) Cypher 查詢處理，(4) KG 檢索，以及 (5) LLM 增強的回應生成。我們在一個由 69 個樣本組成的精選數據集上評估我們的系統，在檢索正確的 KG 節點時達到了 78% 的精度。我們的研究結果表明，混合系統在準確性和完整性方面都超過了單獨的 LLM，這通過 LLM 作為評審評估方法得到驗證。這將系統定位為對應用程式來說一個有前途的工具，這些應用程式需要事實正確性和完整性，例如目標識別——在疾病治療或作物改良中精確定位生物實體的關鍵過程。此外，其直觀的搜尋介面和在數秒內提供準確回應的能力使其非常適合時間敏感、注重精確度的研究情境。我們將原始碼與數據集和使用的提示範本一起發布。

##### **LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning**
2408.02999v1 by Lekai Chen, Ashutosh Trivedi, Alvaro Velasquez

The emergence of intelligence in large language models (LLMs) has inspired
investigations into their integration into automata learning. This paper
introduces the probabilistic Minimally Adequate Teacher (pMAT) formulation,
which leverages a probabilistic oracle that could give persistent errors
randomly during answering the membership queries for deterministic finite
automata (DFA) learning. Given the tendency of LLMs to produce hallucinatory
content, we have developed techniques to improve answer accuracy and ensure the
correctness of the learned automata. We propose the $\mathtt{Discrimination}$
prompt as well as the $\mathtt{Verification}$ prompt and explore their
advantages over common prompts. Additionally, we compare DFA learning
performance between the TTT algorithm and common active learning algorithms. To
address the exponential number of persistent errors, we implement a dynamic
query cache refinement algorithm that identifies and corrects conflicting
queries by combining the active and passive learning algorithms. The empirical
results demonstrate the robustness and efficiency of our approach, providing a
theoretical foundation for automata learning with LLMs in the loop.

摘要：大型語言模型 (LLM) 中智慧的出現，激勵了針對它們整合到自動機學習的研究。本文介紹了機率性的最低限度適當教師 (pMAT) 公式，它利用了一個機率性的神諭，它在回答確定有限自動機 (DFA) 學習的成員查詢時，可能會隨機給出持續性的錯誤。鑑於 LLM 產生幻覺內容的傾向，我們已經開發了技術來改善答案的準確性，並確保學習到的自動機的正確性。我們提出了 $\mathtt{Discrimination}$ 提示以及 $\mathtt{Verification}$ 提示，並探討它們相對於常見提示的優點。此外，我們比較了 TTT 演算法和常見主動學習演算法之間的 DFA 學習效能。為了解決持續性錯誤的指數數量，我們實作了一個動態查詢快取精緻化演算法，它透過結合主動和被動學習演算法來識別並修正衝突的查詢。實證結果證明了我們方法的穩健性和效率，為迴圈中的 LLM 自動機學習提供了理論基礎。

##### **ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval**
2408.02978v1 by Ruixiang Zhao, Jian Jia, Yan Li, Xuehan Bai, Quan Chen, Han Li, Peng Jiang, Xirong Li

E-commerce is increasingly multimedia-enriched, with products exhibited in a
broad-domain manner as images, short videos, or live stream promotions. A
unified and vectorized cross-domain production representation is essential. Due
to large intra-product variance and high inter-product similarity in the
broad-domain scenario, a visual-only representation is inadequate. While
Automatic Speech Recognition (ASR) text derived from the short or live-stream
videos is readily accessible, how to de-noise the excessively noisy text for
multimodal representation learning is mostly untouched. We propose ASR-enhanced
Multimodal Product Representation Learning (AMPere). In order to extract
product-specific information from the raw ASR text, AMPere uses an
easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text,
together with visual data, is then fed into a multi-branch network to generate
compact multimodal embeddings. Extensive experiments on a large-scale
tri-domain dataset verify the effectiveness of AMPere in obtaining a unified
multimodal product representation that clearly improves cross-domain product
retrieval.

摘要：電子商務日益豐富多媒體，產品以影像、短片或直播促銷等廣域方式展示。統一且向量化的跨域製作表示至關重要。由於廣域場景中產品內部差異大，產品間相似性高，僅視覺表示是不夠的。雖然可以輕易取得短片或直播影片的自動語音辨識 (ASR) 文字，但如何為多模態表示學習去雜訊化過度雜訊的文字，大多數仍未觸及。我們提出 ASR 增強的多模態產品表示學習 (AMPere)。為了從原始 ASR 文字中萃取產品特定資訊，AMPere 使用容易實作的 LLM-based ASR 文字摘要器。LLM 摘要的文字與視覺資料一起，接著輸入多分支網路，產生緊湊的多模態嵌入。在大型三域資料集上進行廣泛的實驗，驗證了 AMPere 在取得統一的多模態產品表示上的效能，明顯改善了跨域產品檢索。

##### **Empathy Level Alignment via Reinforcement Learning for Empathetic Response Generation**
2408.02976v1 by Hui Ma, Bo Zhang, Bo Xu, Jian Wang, Hongfei Lin, Xiao Sun

Empathetic response generation, aiming at understanding the user's situation
and feelings and respond empathically, is crucial in building human-like
dialogue systems. Previous methods mainly focus on using maximum likelihood
estimation as the optimization objective for training response generation
models, without taking into account the empathy level alignment between
generated responses and target responses. To this end, we propose an empathetic
response generation using reinforcement learning (EmpRL) framework. The
framework designs an effective empathy reward function and generates empathetic
responses by maximizing the expected reward through reinforcement learning.
Given the powerful text generation capability of pre-trained language models,
EmpRL utilizes the pre-trained T5 model as the generator and conducts further
training to initialize the policy. To align the empathy level between generated
responses and target responses in the context, an empathy reward function
containing three empathy communication mechanisms, i.e., emotional reaction,
interpretation, and exploration, is constructed using pre-designed and
pre-trained empathy identifiers. Finally, the proximal policy optimization
algorithm is used to further train the policy to produce empathetic responses.
Both automatic and manual evaluations demonstrate that the proposed EmpRL
framework can improve the quality of generated responses, enhance the empathy
level similarity between generated and target responses, and produce empathetic
responses covering both affective and cognitive aspects.

摘要：同理心回應生成，旨在理解使用者的處境和感受，並以同理心回應，對於建立類人對話系統至關重要。先前的研究方法主要著重於使用最大似然估計作為訓練回應生成模型的最佳化目標，而未考量生成回應與目標回應之間的同理心層級對齊。為此，我們提出了一個使用強化學習（EmpRL）架構的同理心回應生成方法。該架構設計了一個有效的同理心回饋函數，並透過強化學習最大化預期回饋來產生同理心回應。鑑於預先訓練的語言模型強大的文字生成能力，EmpRL 使用預先訓練的 T5 模型作為生成器，並進行進一步的訓練來初始化政策。為了在脈絡中對齊生成回應與目標回應的同理心層級，我們使用預先設計和預先訓練的同理心識別符號，建構了一個包含三種同理心溝通機制的同理心回饋函數，即情緒反應、詮釋和探索。最後，我們使用近端政策最佳化演算法進一步訓練政策，以產生同理心回應。自動和手動評估均顯示，所提出的 EmpRL 架構可以提升生成回應的品質，增強生成回應與目標回應之間的同理心層級相似性，並產生涵蓋情感和認知層面的同理心回應。

##### **EC-Guide: A Comprehensive E-Commerce Guide for Instruction Tuning and Quantization**
2408.02970v1 by Zhaopeng Feng, Zijie Meng, Zuozhu Liu

Large language models (LLMs) have attracted considerable attention in various
fields for their cost-effective solutions to diverse challenges, especially
with advancements in instruction tuning and quantization. E-commerce, with its
complex tasks and extensive product-user interactions, presents a promising
application area for LLMs. However, the domain-specific concepts and knowledge
inherent in e-commerce pose significant challenges for adapting general LLMs.
To address this issue, we developed EC-Guide
\href{https://github.com/fzp0424/EC-Guide-KDDUP-2024}, a comprehensive
e-commerce guide for instruction tuning and quantization of LLMs. We also
heuristically integrated Chain-of-Thought (CoT) during inference to enhance
arithmetic performance. Our approach achieved the 2nd place in Track 2 and 5th
place in Track 5 at the Amazon KDD Cup'24
\href{https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms}.
Additionally, our solution is model-agnostic, enabling effective scalability
across larger systems.

摘要：大型語言模型 (LLM) 因其在各種領域中以具成本效益的方式解決各種挑戰而備受關注，特別是在指令調整和量化方面取得進展。電子商務及其複雜的任務和廣泛的產品使用者互動，為 LLM 呈現了一個大有可為的應用領域。然而，電子商務中固有的特定領域概念和知識，對一般 LLM 的適應提出了重大挑戰。為了解決這個問題，我們開發了 EC-Guide \href{https://github.com/fzp0424/EC-Guide-KDDUP-2024}，這是一個針對 LLM 指令調整和量化的全面電子商務指南。我們還在推理期間啟發式地整合了思考鏈 (CoT)，以增強算術效能。我們的做法在 Amazon KDD Cup'24 的軌道 2 中獲得第 2 名，在軌道 5 中獲得第 5 名 \href{https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms}。此外，我們的解決方案與模型無關，可以在更大的系統中有效擴展。

##### **Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval**
2408.02964v1 by Iman Azimi, Mohan Qi, Li Wang, Amir M. Rahmani, Youlin Li

Large language models (LLMs) are fundamentally transforming human-facing
applications in the health and well-being domains: boosting patient engagement,
accelerating clinical decision-making, and facilitating medical education.
Although state-of-the-art LLMs have shown superior performance in several
conversational applications, evaluations within nutrition and diet applications
are still insufficient. In this paper, we propose to employ the Registered
Dietitian (RD) exam to conduct a standard and comprehensive evaluation of
state-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, assessing
both accuracy and consistency in nutrition queries. Our evaluation includes
1050 RD exam questions encompassing several nutrition topics and proficiency
levels. In addition, for the first time, we examine the impact of Zero-Shot
(ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency (CoT-SC),
and Retrieval Augmented Prompting (RAP) on both accuracy and consistency of the
responses. Our findings revealed that while these LLMs obtained acceptable
overall performance, their results varied considerably with different prompts
and question domains. GPT-4o with CoT-SC prompting outperformed the other
approaches, whereas Gemini 1.5 Pro with ZS recorded the highest consistency.
For GPT-4o and Claude 3.5, CoT improved the accuracy, and CoT-SC improved both
accuracy and consistency. RAP was particularly effective for GPT-4o to answer
Expert level questions. Consequently, choosing the appropriate LLM and
prompting technique, tailored to the proficiency level and specific domain, can
mitigate errors and potential risks in diet and nutrition chatbots.

摘要：大型語言模型 (LLM) 正在從根本上轉變健康和福祉領域中面向人類的應用：提升患者參與度、加速臨床決策制定，並促進醫學教育。儘管最先進的 LLM 已在多項對話式應用中展現出優異的效能，但在營養和飲食應用中的評估仍不足。在本文中，我們提議採用註冊營養師 (RD) 考試來對最先進的 LLM、GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5 Pro 進行標準且全面的評估，評估營養查詢的準確性和一致性。我們的評估包含 1050 個 RD 考試題目，涵蓋多個營養主題和熟練程度。此外，我們首次探討零次學習 (ZS)、思考鏈 (CoT)、具有自我一致性的思考鏈 (CoT-SC) 和檢索增強提示 (RAP) 對回應準確性和一致性的影響。我們的研究結果顯示，儘管這些 LLM 獲得可接受的整體效能，但其結果因不同的提示和問題領域而有很大差異。使用 CoT-SC 提示的 GPT-4o 優於其他方法，而使用 ZS 的 Gemini 1.5 Pro 則記錄到最高的一致性。對於 GPT-4o 和 Claude 3.5，CoT 提高了準確性，而 CoT-SC 則同時提高了準確性和一致性。RAP 對於 GPT-4o 回答專家級別的問題特別有效。因此，選擇適當的 LLM 和提示技巧，並根據熟練程度和特定領域進行調整，可以減輕飲食和營養聊天機器人的錯誤和潛在風險。

##### **Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps**
2408.02949v1 by Yifan Zhu, Pranay Thangeda, Erica L Tevere, Ashish Goel, Erik Kramer, Hari D Nayar, Melkior Ornik, Kris Hauser

Autonomous lander missions on extraterrestrial bodies need to sample granular
materials while coping with domain shifts, even when sampling strategies are
extensively tuned on Earth. To tackle this challenge, this paper studies the
few-shot scooping problem and proposes a vision-based adaptive scooping
strategy that uses the deep kernel Gaussian process method trained with a novel
meta-training strategy to learn online from very limited experience on
out-of-distribution target terrains. Our Deep Kernel Calibration with Maximal
Deployment Gaps (kCMD) strategy explicitly trains a deep kernel model to adapt
to large domain shifts by creating simulated maximal deployment gaps from an
offline training dataset and training models to overcome these deployment gaps
during training. Employed in a Bayesian Optimization sequential decision-making
framework, the proposed method allows the robot to perform high-quality
scooping actions on out-of-distribution terrains after a few attempts,
significantly outperforming non-adaptive methods proposed in the excavation
literature as well as other state-of-the-art meta-learning methods. The
proposed method also demonstrates zero-shot transfer capability, successfully
adapting to the NASA OWLAT platform, which serves as a state-of-the-art
simulator for potential future planetary missions. These results demonstrate
the potential of training deep models with simulated deployment gaps for more
generalizable meta-learning in high-capacity models. Furthermore, they
highlight the promise of our method in autonomous lander sampling missions by
enabling landers to overcome the deployment gap between Earth and
extraterrestrial bodies.

摘要：<paragraph>外星天體上的自主登陸任務需要採集顆粒材料，同時應對領域轉變，即使在廣泛調整地球上的採集策略時也是如此。為了應對這一挑戰，本文研究了少次嘗試的挖取問題，並提出了一種基於視覺的自適應挖取策略，該策略使用深度核高斯過程方法進行訓練，採用新穎的元訓練策略，從分布目標地形上的非常有限的經驗中在線學習。我們採用最大部署差距的深度核校準 (kCMD) 策略，明確訓練深度核模型以適應大的領域轉變，方法是從離線訓練數據集創建模擬的最大部署差距，並訓練模型在訓練過程中克服這些部署差距。所提出的方法採用貝葉斯優化序貫決策制定框架，使機器人在經過幾次嘗試後能夠在外部分布地形上執行高品質的挖取動作，顯著優於挖掘文獻中提出的非自適應方法以及其他最先進的元學習方法。所提出的方法還展示了零次嘗試轉移能力，成功適應了 NASA OWLAT 平台，該平台是潛在未來行星任務的最新模擬器。這些結果展示了使用模擬部署差距訓練深度模型以在高容量模型中進行更具泛化性的元學習的潛力。此外，它們通過使登陸器能夠克服地球和外星天體之間的部署差距，突出了我們的方法在自主登陸器採樣任務中的前景。</paragraph>

##### **Are Female Carpenters like Blue Bananas? A Corpus Investigation of Occupation Gender Typicality**
2408.02948v1 by Da Ju, Karen Ulrich, Adina Williams

People tend to use language to mention surprising properties of events: for
example, when a banana is blue, we are more likely to mention color than when
it is yellow. This fact is taken to suggest that yellowness is somehow a
typical feature of bananas, and blueness is exceptional. Similar to how a
yellow color is typical of bananas, there may also be genders that are typical
of occupations. In this work, we explore this question using information
theoretic techniques coupled with corpus statistic analysis. In two distinct
large corpora, we do not find strong evidence that occupations and gender
display the same patterns of mentioning as do bananas and color. Instead, we
find that gender mentioning is correlated with femaleness of occupation in
particular, suggesting perhaps that woman-dominated occupations are seen as
somehow ``more gendered'' than male-dominated ones, and thereby they encourage
more gender mentioning overall.

摘要：人們傾向於用語言提及事件的驚人屬性：例如，當香蕉是藍色的時候，我們更有可能提到顏色，而不是當它變黃的時候。這個事實表明，黃色在某種程度上是香蕉的典型特徵，而藍色則是非典型的。類似於黃色是香蕉的典型顏色，某些性別也可能是職業的典型特徵。在這項工作中，我們使用資訊理論技術結合語料庫統計分析來探討這個問題。在兩個不同的大型語料庫中，我們沒有發現強有力的證據表明職業和性別與香蕉和顏色顯示相同的提及模式。相反，我們發現性別提及與職業的女性化特別相關，這可能表明女性主導的職業在某種程度上被視為「更具性別」，從而整體上鼓勵更多地提及性別。

##### **Scaling Laws for Data Poisoning in LLMs**
2408.02946v1 by Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine

Recent work shows that LLMs are vulnerable to data poisoning, in which they
are trained on partially corrupted or harmful data. Poisoned data is hard to
detect, breaks guardrails, and leads to undesirable and harmful behavior. Given
the intense efforts by leading labs to train and deploy increasingly larger and
more capable LLMs, it is critical to ask if the risk of data poisoning will be
naturally mitigated by scale, or if it is an increasing threat. We consider
three threat models by which data poisoning can occur: malicious fine-tuning,
imperfect data curation, and intentional data contamination. Our experiments
evaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72
billion parameters on three datasets which speak to each of our threat models.
We find that larger LLMs are increasingly vulnerable, learning harmful behavior
-- including sleeper agent behavior -- significantly more quickly than smaller
LLMs with even minimal data poisoning. These results underscore the need for
robust safeguards against data poisoning in larger LLMs.

摘要：最近的研究显示，大型语言模型 (LLM) 容易受到数据中毒的影响，即在部分损坏或有害的数据上进行训练。中毒数据难以检测，会破坏防护措施，并导致不良和有害的行为。鉴于领先实验室在训练和部署越来越大、功能更强大的 LLM 方面付出了巨大努力，因此至关重要的是要问数据中毒的风险是否会随着规模的扩大而自然减轻，或者是否会成为越来越大的威胁。我们考虑了三种数据中毒可能发生的威胁模型：恶意微调、不完美的数据整理和故意的数据污染。我们的实验评估了数据中毒对 23 个前沿 LLM 的影响，这些 LLM 的参数范围从 15 亿到 720 亿，针对三个数据集，每个数据集都针对我们的威胁模型之一。我们发现，较大的 LLM 越来越容易受到攻击，学习有害行为（包括休眠代理行为）的速度明显快于即使是最小的数据中毒的较小 LLM。这些结果强调了需要针对大型 LLM 中的数据中毒采取强有力的保障措施。

##### **Self-Supervised Learning for Multi-Channel Neural Transducer**
2408.02945v1 by Atsushi Kojima

Self-supervised learning, such as with the wav2vec 2.0 framework
significantly improves the accuracy of end-to-end automatic speech recognition
(ASR). Wav2vec 2.0 has been applied to single-channel end-to-end ASR models. In
this work, we explored a self-supervised learning method for a multi-channel
end-to-end ASR model based on the wav2vec 2.0 framework. As the multi-channel
end-to-end ASR model, we focused on a multi-channel neural transducer. In
pre-training, we compared three different methods for feature quantization to
train a multi-channel conformer audio encoder: joint quantization, feature-wise
quantization and channel-wise quantization. In fine-tuning, we trained the
multi-channel conformer-transducer. All experiments were conducted using the
far-field in-house and CHiME-4 datasets. The results of the experiments showed
that feature-wise quantization was the most effective among the methods. We
observed a 66% relative reduction in character error rate compared with the
model without any pre-training for the far-field in-house dataset.

摘要：自監督學習，例如使用 wav2vec 2.0 架構，大幅提升端對端自動語音辨識 (ASR) 的準確度。Wav2vec 2.0 已應用於單聲道端對端 ASR 模型。在這項工作中，我們探討了基於 wav2vec 2.0 架構的多聲道端對端 ASR 模型的自我監督學習方法。作為多聲道端對端 ASR 模型，我們專注於多聲道神經轉換器。在預訓練中，我們比較了三種不同的特徵量化方法，以訓練多聲道構形音訊編碼器：聯合量化、特徵量化和通道量化。在微調中，我們訓練了多聲道構形轉換器。所有實驗均使用遠場內部和 CHiME-4 資料集進行。實驗結果顯示，在這些方法中，特徵量化是最有效的。我們觀察到，與沒有任何預訓練的遠場內部資料集模型相比，字元錯誤率相對減少了 66%。

##### **LLM-Empowered Resource Allocation in Wireless Communications Systems**
2408.02944v1 by Woongsup Lee, Jeonghun Park

The recent success of large language models (LLMs) has spurred their
application in various fields. In particular, there have been efforts to
integrate LLMs into various aspects of wireless communication systems. The use
of LLMs in wireless communication systems has the potential to realize
artificial general intelligence (AGI)-enabled wireless networks. In this paper,
we investigate an LLM-based resource allocation scheme for wireless
communication systems. Specifically, we formulate a simple resource allocation
problem involving two transmit pairs and develop an LLM-based resource
allocation approach that aims to maximize either energy efficiency or spectral
efficiency. Additionally, we consider the joint use of low-complexity resource
allocation techniques to compensate for the reliability shortcomings of the
LLM-based scheme. After confirming the applicability and feasibility of
LLM-based resource allocation, we address several key technical challenges that
remain in applying LLMs in practice.

摘要：大型語言模型 (LLM) 最近的成功，促使它們在各個領域的應用。特別是，一直有努力將 LLM 整合到無線通信系統的各個方面。在無線通信系統中使用 LLM 有可能實現人工通用智慧 (AGI) 啟用的無線網路。在本文中，我們研究了一種基於 LLM 的無線通信系統資源分配方案。具體來說，我們制定了一個涉及兩個傳輸對的簡單資源分配問題，並開發了一種基於 LLM 的資源分配方法，旨在最大化能量效率或頻譜效率。此外，我們考慮了低複雜度資源分配技術的聯合使用，以彌補基於 LLM 的方案的可靠性不足。在確認了基於 LLM 的資源分配的適用性和可行性後，我們解決了在實務中應用 LLM 時仍存在的幾個關鍵技術挑戰。

##### **HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection**
2408.02927v1 by Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang

Data serves as the fundamental foundation for advancing deep learning,
particularly tabular data presented in a structured format, which is highly
conducive to modeling. However, even in the era of LLM, obtaining tabular data
from sensitive domains remains a challenge due to privacy or copyright
concerns. Hence, exploring how to effectively use models like LLMs to generate
realistic and privacy-preserving synthetic tabular data is urgent. In this
paper, we take a step forward to explore LLMs for tabular data synthesis and
privacy protection, by introducing a new framework HARMONIC for tabular data
generation and evaluation. In the tabular data generation of our framework,
unlike previous small-scale LLM-based methods that rely on continued
pre-training, we explore the larger-scale LLMs with fine-tuning to generate
tabular data and enhance privacy. Based on idea of the k-nearest neighbors
algorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to
discover inter-row relationships. Then, with fine-tuning, LLMs are trained to
remember the format and connections of the data rather than the data itself,
which reduces the risk of privacy leakage. In the evaluation part of our
framework, we develop specific privacy risk metrics DLT for LLM synthetic data
generation, as well as performance evaluation metrics LLE for downstream LLM
tasks. Our experiments find that this tabular data generation framework
achieves equivalent performance to existing methods with better privacy, which
also demonstrates our evaluation framework for the effectiveness of synthetic
data and privacy risks in LLM scenarios.

摘要：<paragraph>資料作為推動深度學習的基礎，
特別是結構化呈現的表格資料，非常適合建模。然而，即使在 LLM 時代，由於隱私或版權問題，從敏感領域取得表格資料仍然是一項挑戰。因此，探討如何有效使用 LLM 等模型來產生逼真且保護隱私的合成表格資料非常迫切。在本文中，我們進一步探討 LLM 在表格資料合成和隱私保護方面的應用，並介紹一個新的表格資料產生和評估框架 HARMONIC。在我們框架的表格資料產生中，與依賴持續預訓練的先前小規模基於 LLM 的方法不同，我們探討使用微調的大規模 LLM 來產生表格資料並增強隱私。基於 k 最近鄰演算法的想法，構建了一個指令微調資料集，以激勵 LLM 發現列間關係。然後，透過微調，訓練 LLM 記住資料的格式和關聯性，而不是資料本身，這降低了隱私洩露的風險。在我們框架的評估部分，我們開發了針對 LLM 合成資料產生的特定隱私風險指標 DLT，以及下游 LLM 任務的效能評估指標 LLE。我們的實驗發現，此表格資料產生框架在具有更好隱私性的情況下，達到了與現有方法相當的效能，這也證明了我們評估框架在 LLM 場景中合成資料和隱私風險的有效性。</paragraph>

##### **Intermediate direct preference optimization**
2408.02923v1 by Atsushi Kojima

We propose the intermediate direct preference optimization (DPO) method to
calculate the DPO loss at selected intermediate layers as an auxiliary loss for
finetuning large language models (LLMs). The conventional DPO method fine-tunes
a supervised fine-tuning (SFT) model by calculating the DPO loss using logits
from the final layer. In our intermediate DPO approach, DPO losses are
calculated using the logits from K-selected intermediate layers and averaged to
obtain the intermediate DPO loss. For training the intermediate DPO model, the
final loss is obtained by calculating the weighted sum of the DPO and
intermediate DPO losses. During inference, the intermediate DPO model decodes
using the final layer logits similarly to the conventional DPO model. In
experiments using the ultrafeedback dataset, the performance of the
intermediate DPO model was evaluated using GPT-4. As a result, the intermediate
DPO model trained using the intermediate DPO loss calculated at the 22nd layer
of a 32-layer SFT model achieved win rates of 52.5% and 67.5% against the
conventional DPO and SFT models, respectively, demonstrating the effectiveness
of the proposed method. Furthermore, we report the relationships among the
position of the selected intermediate layers, the number of layers, and
performance.

摘要：我們提出中間直接偏好最佳化 (DPO) 方法，以在選定的中間層計算 DPO 損失，作為微調大型語言模型 (LLM) 的輔助損失。傳統的 DPO 方法通過使用來自最終層的 logit 計算 DPO 損失，對監督微調 (SFT) 模型進行微調。在我們的中間 DPO 方法中，DPO 損失使用來自 K 個選定中間層的 logit 計算，並取平均值以獲得中間 DPO 損失。為了訓練中間 DPO 模型，最終損失是通過計算 DPO 和中間 DPO 損失的加權和來獲得的。在推理過程中，中間 DPO 模型使用最終層 logit 解碼，類似於傳統的 DPO 模型。在使用 ultrafeedback 資料集的實驗中，使用 GPT-4 評估了中間 DPO 模型的效能。結果，使用在 32 層 SFT 模型的第 22 層計算的中間 DPO 損失訓練的中間 DPO 模型，分別對傳統 DPO 和 SFT 模型達到了 52.5% 和 67.5% 的獲勝率，證明了所提出方法的有效性。此外，我們報告了選定的中間層的位置、層數和效能之間的關係。

##### **A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model**
2408.02920v1 by Jingwen Zhou, Qinghua Lu, Jieshan Chen, Liming Zhu, Xiwei Xu, Zhenchang Xing, Stefan Harrer

The rapid advancement of AI technology has led to widespread applications of
agent systems across various domains. However, the need for detailed
architecture design poses significant challenges in designing and operating
these systems. This paper introduces a taxonomy focused on the architectures of
foundation-model-based agents, addressing critical aspects such as functional
capabilities and non-functional qualities. We also discuss the operations
involved in both design-time and run-time phases, providing a comprehensive
view of architectural design and operational characteristics. By unifying and
detailing these classifications, our taxonomy aims to improve the design of
foundation-model-based agents. Additionally, the paper establishes a decision
model that guides critical design and runtime decisions, offering a structured
approach to enhance the development of foundation-model-based agents. Our
contributions include providing a structured architecture design option and
guiding the development process of foundation-model-based agents, thereby
addressing current fragmentation in the field.

摘要：隨著人工智慧技術的快速進步，已導致代理系統在各個領域廣泛應用。然而，對詳細架構設計的需求在設計和操作這些系統時提出了重大挑戰。本文介紹了一個分類，重點關注基於基礎模型的代理架構，探討功能能力和非功能品質等關鍵方面。我們還討論了設計時和運行時階段涉及的操作，提供了架構設計和運作特性的全面觀點。通過統一和詳細說明這些分類，我們的分類法旨在改進基於基礎模型的代理的設計。此外，本文建立了一個決策模型，用於指導關鍵設計和運行時決策，提供了一種結構化方法來增強基於基礎模型的代理的開發。我們的貢獻包括提供一個結構化的架構設計選項和指導基於基礎模型的代理的開發過程，從而解決該領域當前的碎片化問題。

##### **Data Checklist: On Unit-Testing Datasets with Usable Information**
2408.02919v1 by Heidi C. Zhang, Shabnam Behzad, Kawin Ethayarajh, Dan Jurafsky

Model checklists (Ribeiro et al., 2020) have emerged as a useful tool for
understanding the behavior of LLMs, analogous to unit-testing in software
engineering. However, despite datasets being a key determinant of model
behavior, evaluating datasets, e.g., for the existence of annotation artifacts,
is largely done ad hoc, once a problem in model behavior has already been found
downstream. In this work, we take a more principled approach to unit-testing
datasets by proposing a taxonomy based on the V-information literature. We call
a collection of such unit tests a data checklist. Using a checklist, not only
are we able to recover known artifacts in well-known datasets such as SNLI, but
we also discover previously unknown artifacts in preference datasets for LLM
alignment. Data checklists further enable a new kind of data filtering, which
we use to improve the efficacy and data efficiency of preference alignment.

摘要：模型核對清單（Ribeiro 等人，2020 年）已成為了解 LLM 行為的有用工具，類似於軟體工程中的單元測試。然而，儘管資料集是模型行為的主要決定因素，但評估資料集（例如，是否存在標註人工製品）通常是臨時進行的，一旦發現模型行為中的問題，就會在後續流程中發現。在這項工作中，我們採用基於 V 型資訊文獻的分類法，對單元測試資料集採取更具原則性的方法。我們稱此類單元測試的集合為資料核對清單。透過使用核對清單，我們不僅能夠在 SNLI 等知名資料集中恢復已知的的人工製品，還能發現 LLM 對齊偏好資料集中先前未知的人工製品。資料核對清單進一步啟用了一種新的資料過濾，我們使用它來改善偏好對齊的效能和資料效率。

##### **KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance**
2408.02912v1 by Jingxian Lu, Wenke Xia, Dong Wang, Zhigang Wang, Bin Zhao, Di Hu, Xuelong Li

Online Imitation Learning methods struggle with the gap between extensive
online exploration space and limited expert trajectories, which hinder
efficient exploration due to inaccurate task-aware reward estimation. Inspired
by the findings from cognitive neuroscience that task decomposition could
facilitate cognitive processing for efficient learning, we hypothesize that an
agent could estimate precise task-aware imitation rewards for efficient online
exploration by decomposing the target task into the objectives of "what to do"
and the mechanisms of "how to do". In this work, we introduce the hybrid
Key-state guided Online Imitation (KOI) learning approach, which leverages the
integration of semantic and motion key states as guidance for task-aware reward
estimation. Initially, we utilize the visual-language models to segment the
expert trajectory into semantic key states, indicating the objectives of "what
to do". Within the intervals between semantic key states, optical flow is
employed to capture motion key states to understand the process of "how to do".
By integrating a thorough grasp of both semantic and motion key states, we
refine the trajectory-matching reward computation, encouraging task-aware
exploration for efficient online imitation learning. Our experiment results
prove that our method is more sample efficient in the Meta-World and LIBERO
environments. We also conduct real-world robotic manipulation experiments to
validate the efficacy of our method, demonstrating the practical applicability
of our KOI method.

摘要：線上模仿學習方法在於廣泛的線上探索空間和有限的專家軌跡之間的差距，這會阻礙有效的探索，因為任務感知獎勵估計不準確。受認知神經科學的發現啟發，即任務分解可以促進認知處理以進行有效的學習，我們假設一個代理可以通過將目標任務分解為「要做什么」的目標和「如何做」的機制，估計精確的任務感知模仿獎勵以進行有效的線上探索。在這項工作中，我們引入了混合關鍵狀態引導的線上模仿 (KOI) 學習方法，它利用語義和動作關鍵狀態的整合作為任務感知獎勵估計的指導。最初，我們利用視覺語言模型將專家軌跡分割成語義關鍵狀態，表示「要做什么」的目標。在語義關鍵狀態之間的間隔內，使用光流來捕捉動作關鍵狀態以了解「如何做」的過程。通過整合對語義和動作關鍵狀態的透徹掌握，我們改進了軌跡匹配獎勵計算，鼓勵任務感知探索以進行有效的線上模仿學習。我們的實驗結果證明，我們的模型在 Meta-World 和 LIBERO 環境中具有更高的樣本效率。我們還進行了真實世界的機器人操作實驗，以驗證我們方法的有效性，證明了我們 KOI 方法的實際適用性。

##### **Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**
2408.02907v1 by Tiezheng Guo, Chen Wang, Yanyi Liu, Jiawei Tang, Pan Li, Sai Xu, Qingwen Yang, Xianlin Gao, Zhi Li, Yingyou Wen

Retrieving external knowledge and prompting large language models with
relevant information is an effective paradigm to enhance the performance of
question-answering tasks. Previous research typically handles paragraphs from
external documents in isolation, resulting in a lack of context and ambiguous
references, particularly in multi-document and complex tasks. To overcome these
challenges, we propose a new retrieval framework IIER, that leverages
Inter-chunk Interactions to Enhance Retrieval. This framework captures the
internal connections between document chunks by considering three types of
interactions: structural, keyword, and semantic. We then construct a unified
Chunk-Interaction Graph to represent all external documents comprehensively.
Additionally, we design a graph-based evidence chain retriever that utilizes
previous paths and chunk interactions to guide the retrieval process. It
identifies multiple seed nodes based on the target question and iteratively
searches for relevant chunks to gather supporting evidence. This retrieval
process refines the context and reasoning chain, aiding the large language
model in reasoning and answer generation. Extensive experiments demonstrate
that IIER outperforms strong baselines across four datasets, highlighting its
effectiveness in improving retrieval and reasoning capabilities.

摘要：取得外部知識並提示大型語言模型提供相關資訊，是提升問答任務效能的有效典範。先前的研究通常孤立地處理外部文件中的段落，導致缺乏脈絡和模稜兩可的參考，特別是在多文件和複雜的任務中。為了克服這些挑戰，我們提出一個新的檢索架構 IIER，利用區塊間互動來增強檢索。這個架構透過考量三種類型的互動來擷取文件區塊之間的內部連結：結構、關鍵字和語意。然後，我們建構一個統一的區塊互動圖，以全面表示所有外部文件。此外，我們設計一個基於圖形的證據鏈檢索器，利用先前的路徑和區塊互動來引導檢索程序。它根據目標問題識別多個種子節點，並反覆搜尋相關區塊以收集佐證證據。這個檢索程序精煉了脈絡和推理鏈，協助大型語言模型進行推理和答案產生。廣泛的實驗證明，IIER 在四個資料集上優於強大的基準，突顯其在改善檢索和推理能力方面的效能。

##### **Enabling Intelligent Traffic Systems: A Deep Learning Method for Accurate Arabic License Plate Recognition**
2408.02904v1 by M. A. Sayedelahl

This paper introduces a novel two-stage framework for accurate Egyptian
Vehicle License Plate Recognition (EVLPR). The first stage employs image
processing techniques to reliably localize license plates, while the second
stage utilizes a custom-designed deep learning model for robust Arabic
character recognition. The proposed system achieves a remarkable 99.3% accuracy
on a diverse dataset, surpassing existing approaches. Its potential
applications extend to intelligent traffic management, including traffic
violation detection and parking optimization. Future research will focus on
enhancing the system's capabilities through architectural refinements, expanded
datasets, and addressing system dependencies.

摘要：本文介紹了一個新穎的兩階段架構，用於精確的埃及車牌識別 (EVLPR)。第一階段採用影像處理技術來可靠地定位車牌，而第二階段則利用客製化設計的深度學習模型，用於強大的阿拉伯文字辨識。所提出的系統在一個多樣化的資料集上達到了 99.3% 的驚人準確度，超越了現有的方法。其潛在應用延伸到智慧交通管理，包括交通違規偵測和停車優化。未來的研究將專注於透過架構改良、擴充資料集和解決系統依賴性來增強系統的功能。

##### **Lighthouse: A User-Friendly Library for Reproducible Video Moment Retrieval and Highlight Detection**
2408.02901v1 by Taichi Nishimura, Shota Nakada, Hokuto Munakata, Tatsuya Komatsu

We propose Lighthouse, a user-friendly library for reproducible video moment
retrieval and highlight detection (MR-HD). Although researchers proposed
various MR-HD approaches, the research community holds two main issues. The
first is a lack of comprehensive and reproducible experiments across various
methods, datasets, and video-text features. This is because no unified training
and evaluation codebase covers multiple settings. The second is user-unfriendly
design. Because previous works use different libraries, researchers set up
individual environments. In addition, most works release only the training
codes, requiring users to implement the whole inference process of MR-HD.
Lighthouse addresses these issues by implementing a unified reproducible
codebase that includes six models, three features, and five datasets. In
addition, it provides an inference API and web demo to make these methods
easily accessible for researchers and developers. Our experiments demonstrate
that Lighthouse generally reproduces the reported scores in the reference
papers. The code is available at https://github.com/line/lighthouse.

摘要：我們提出 Lighthouse，一個用於可重製影片時刻檢索和重點偵測 (MR-HD) 的使用者友善程式庫。儘管研究人員提出了各種 MR-HD 方法，但研究社群仍有兩個主要問題。第一個問題是缺乏跨各種方法、資料集和影片文字特徵的全面且可重製的實驗。這是因為沒有統一的訓練和評估程式碼庫涵蓋多種設定。第二個問題是使用者不友善的設計。由於先前的著作使用不同的程式庫，因此研究人員會設定個別的環境。此外，大多數著作僅發布訓練程式碼，要求使用者實作 MR-HD 的整個推論流程。Lighthouse 透過實作一個統一的可重製程式碼庫來解決這些問題，其中包含六個模型、三個特徵和五個資料集。此外，它提供一個推論 API 和網路展示，讓研究人員和開發人員可以輕鬆存取這些方法。我們的實驗證明 Lighthouse 通常會重製參考論文中報告的分數。程式碼可在 https://github.com/line/lighthouse 取得。

##### **SETN: Stock Embedding Enhanced with Textual and Network Information**
2408.02899v1 by Takehiro Takayanagi, Hiroki Sakaji, Kiyoshi Izumi

Stock embedding is a method for vector representation of stocks. There is a
growing demand for vector representations of stock, i.e., stock embedding, in
wealth management sectors, and the method has been applied to various tasks
such as stock price prediction, portfolio optimization, and similar fund
identifications. Stock embeddings have the advantage of enabling the
quantification of relative relationships between stocks, and they can extract
useful information from unstructured data such as text and network data. In
this study, we propose stock embedding enhanced with textual and network
information (SETN) using a domain-adaptive pre-trained transformer-based model
to embed textual information and a graph neural network model to grasp network
information. We evaluate the performance of our proposed model on related
company information extraction tasks. We also demonstrate that stock embeddings
obtained from the proposed model perform better in creating thematic funds than
those obtained from baseline methods, providing a promising pathway for various
applications in the wealth management industry.

摘要：股票嵌入是一種股票向量表示方法。在財富管理部門中，對股票向量表示（即股票嵌入）的需求日益增長，並且該方法已應用於各種任務，例如股票價格預測、投資組合最佳化和類似基金識別。股票嵌入的優點在於能夠量化股票之間的相對關係，並且它們可以從非結構化數據（例如文本和網路數據）中提取有用的資訊。在本研究中，我們提出使用領域自適應預訓練轉換器模型來嵌入文本資訊，並使用圖神經網路模型來掌握網路資訊，以增強文本和網路資訊的股票嵌入 (SETN)。我們在相關公司資訊萃取任務上評估我們所提出的模型的效能。我們也證明，從所提出的模型中取得的股票嵌入在建立主題基金時，表現優於從基線方法中取得的股票嵌入，為財富管理產業中的各種應用提供了有希望的途徑。

##### **A Metric Driven Approach to Mixed Precision Training**
2408.02897v1 by Mitchelle Rasquinha, Gil Tabak

As deep learning methodologies have developed, it has been generally agreed
that increasing neural network size improves model quality. However, this is at
the expense of memory and compute requirements, which also need to be
increased. Various efficiency techniques have been proposed to rein in hardware
costs, one being the use of low precision numerics. Recent accelerators have
introduced several different 8-bit data types to help accommodate DNNs in terms
of numerics. In this paper, we identify a metric driven methodology to aid in
the choice of numerics. We demonstrate how such a methodology can help scale
training of a language representation model. The technique can be generalized
to other model architectures.

摘要：隨著深度學習方法的發展，人們普遍認為增加神經網路規模可以提升模型品質。然而，這會以記憶體和運算需求為代價，而這些需求也需要增加。為了控制硬體成本，已經提出了各種效率技術，其中一種就是使用低精度數值。最近的加速器引入了數種不同的 8 位元資料類型，以幫助在數值方面容納 DNN。在本文中，我們找出一個由指標驅動的方法，以協助選擇數值。我們展示了這種方法如何有助於擴充語言表示模型的訓練。此技術可以廣泛應用於其他模型架構。

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

摘要：心電圖 (ECG) 可擷取心臟的電氣訊號，用於評估各種心臟疾病。實際上，心電圖資料儲存在數位化訊號或列印影像中。儘管已出現許多針對數位化訊號的深度學習模型，但許多醫院基於成本考量，仍偏好影像儲存。鑑於許多臨床環境中缺乏原始心電圖訊號，我們提出 VizECGNet，它僅使用列印的心電圖圖形來判斷多種心血管疾病的預後。在訓練期間，跨模態注意力模組 (CMAM) 用於整合來自兩種模態（影像和訊號）的資訊，而自我模態注意力模組 (SMAM) 則擷取每個模態中心電圖資料中固有的長程依賴性。此外，我們利用知識萃取來改善每個模態串流中兩個不同預測之間的相似性。這種創新的多模態深度學習架構，可以在推論期間僅使用心電圖影像。與基於訊號的心電圖分類模型相比，輸入影像的 VizECGNet 在精準度、召回率和 F1 分數方面獲得更高的效能，分別提升了 3.50%、8.21% 和 7.38%。

##### **Compromising Embodied Agents with Contextual Backdoor Attacks**
2408.02882v1 by Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao

Large language models (LLMs) have transformed the development of embodied
intelligence. By providing a few contextual demonstrations, developers can
utilize the extensive internal knowledge of LLMs to effortlessly translate
complex tasks described in abstract language into sequences of code snippets,
which will serve as the execution logic for embodied agents. However, this
paper uncovers a significant backdoor security threat within this process and
introduces a novel method called \method{}. By poisoning just a few contextual
demonstrations, attackers can covertly compromise the contextual environment of
a black-box LLM, prompting it to generate programs with context-dependent
defects. These programs appear logically sound but contain defects that can
activate and induce unintended behaviors when the operational agent encounters
specific triggers in its interactive environment. To compromise the LLM's
contextual environment, we employ adversarial in-context generation to optimize
poisoned demonstrations, where an LLM judge evaluates these poisoned prompts,
reporting to an additional LLM that iteratively optimizes the demonstration in
a two-player adversarial game using chain-of-thought reasoning. To enable
context-dependent behaviors in downstream agents, we implement a dual-modality
activation strategy that controls both the generation and execution of program
defects through textual and visual triggers. We expand the scope of our attack
by developing five program defect modes that compromise key aspects of
confidentiality, integrity, and availability in embodied agents. To validate
the effectiveness of our approach, we conducted extensive experiments across
various tasks, including robot planning, robot manipulation, and compositional
visual reasoning. Additionally, we demonstrate the potential impact of our
approach by successfully attacking real-world autonomous driving systems.

摘要：大型語言模型 (LLM) 已轉變具身智能的發展。透過提供一些語境示範，開發人員可以利用 LLM 廣泛的內部知識，毫不費力地將以抽象語言描述的複雜任務轉換為程式碼片段序列，這些序列將作為具身代理的執行邏輯。然而，本文揭露了這個過程中一個重大的後門安全威脅，並介紹了一種稱為 \method{} 的新方法。透過毒害僅少數幾個語境示範，攻擊者可以秘密地危害黑盒 LLM 的語境環境，促使它產生具有語境依賴性缺陷的程式。這些程式看起來合乎邏輯，但包含缺陷，當運作代理在互動環境中遇到特定觸發器時，這些缺陷會被啟動並引發意外的行為。為了危害 LLM 的語境環境，我們採用對抗性的語境中產生來最佳化中毒的示範，其中一個 LLM 評判員會評估這些中毒的提示，向另一個 LLM 報告，後者會在一個雙人對抗遊戲中使用思維鏈推理反覆最佳化示範。為了在下游代理中啟用語境依賴性行為，我們實作了一個雙模態啟動策略，透過文字和視覺觸發器控制程式缺陷的產生和執行。透過開發五種危害具身代理中機密性、完整性及可用性的關鍵面向的程式缺陷模式，我們擴大了攻擊範圍。為了驗證我們方法的有效性，我們在各種任務中進行了廣泛的實驗，包括機器人規劃、機器人操作和組合視覺推理。此外，我們透過成功攻擊真實世界的自動駕駛系統，展示了我們方法的潛在影響。

##### **Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning**
2408.02871v1 by Dmitri Iourovitski, Sanat Sharma, Rakshak Talwar

As content generated by Large Language Model (LLM) has grown exponentially,
the ability to accurately identify and fingerprint such text has become
increasingly crucial. In this work, we introduce a novel black-box approach for
fingerprinting LLMs, achieving an impressive 72% accuracy in identifying the
correct family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of
LLMs. We present an evolutionary strategy that leverages the capabilities of
one LLM to discover the most salient features for identifying other LLMs. Our
method employs a unique "Hide and Seek" algorithm, where an Auditor LLM
generates discriminative prompts, and a Detective LLM analyzes the responses to
fingerprint the target models. This approach not only demonstrates the
feasibility of LLM-driven model identification but also reveals insights into
the semantic manifolds of different LLM families. By iteratively refining
prompts through in-context learning, our system uncovers subtle distinctions
between model outputs, providing a powerful tool for LLM analysis and
verification. This research opens new avenues for understanding LLM behavior
and has significant implications for model attribution, security, and the
broader field of AI transparency.

摘要：隨著大型語言模型 (LLM) 生成的內容呈指數級增長，準確識別和辨識此類文本的能力變得越來越關鍵。在這項工作中，我們引入了一種新穎的黑盒方法來辨識 LLM，在辨識一組 LLM 中正確的模型家族（例如 Llama、Mistral、Gemma 等）方面達到了令人印象深刻的 72% 準確度。我們提出了一種演化策略，該策略利用一個 LLM 的能力來發現辨識其他 LLM 最顯著的特徵。我們的模型採用獨特的「捉迷藏」演算法，其中審核 LLM 會產生區分提示，而偵探 LLM 會分析回應以辨識目標模型。這種方法不僅展示了 LLM 驅動模型識別的可行性，還揭示了不同 LLM 家族的語義流形。通過透過情境學習反覆調整提示，我們的系統揭示了模型輸出之間的細微區別，為 LLM 分析和驗證提供了一個強大的工具。這項研究為理解 LLM 行為開闢了新途徑，並對模型歸因、安全性以及更廣泛的人工智慧透明度領域產生重大影響。

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

摘要：眼科診斷方法改良的必要性十分迫切，特別是在較不發達地區，那裡專科醫師和先進設備取得不易。因此，我們引進 VisionUnite，一種新穎的視覺語言基礎模型，並以臨床知識強化眼科。VisionUnite 已在包含 124 萬張影像文字對的大型資料集上進行預訓練，並透過我們建議的 MMFundus 資料集進一步優化，其中包含 296,379 張高品質眼底影像文字對和 889,137 個模擬的醫師病患對話實例。我們的實驗指出 VisionUnite 優於現有的生成式基礎模型，例如 GPT-4V 和 Gemini Pro。它也展現出與初階眼科醫師相當的診斷能力。VisionUnite 在各種臨床情境中表現良好，包括開放式多疾病診斷、臨床說明和病患互動，使其成為初步眼科疾病篩檢的高度多功能工具。VisionUnite 也可用作初階眼科醫師的教育輔助工具，加速他們對於常見和罕見眼科疾病知識的習得。VisionUnite 代表了眼科的重大進展，對診斷、醫學教育和疾病機轉的理解具有廣泛的影響。

##### **A Framework for Fine-Tuning LLMs using Heterogeneous Feedback**
2408.02861v1 by Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka

Large language models (LLMs) have been applied to a wide range of tasks,
including text summarization, web navigation, and chatbots. They have
benefitted from supervised fine-tuning (SFT) and reinforcement learning from
human feedback (RLHF) following an unsupervised pretraining. These datasets can
be difficult to collect, limited in scope, and vary in sample quality.
Additionally, datasets can vary extensively in supervision format, from
numerical to binary as well as multi-dimensional with many different values. We
present a framework for fine-tuning LLMs using heterogeneous feedback, which
has two main components. First, we combine the heterogeneous feedback data into
a single supervision format, compatible with methods like SFT and RLHF. Next,
given this unified feedback dataset, we extract a high-quality and diverse
subset to obtain performance increases potentially exceeding the full dataset.
We conduct extensive experiments to understand the effectiveness of these
techniques for incorporating heterogeneous feedback, and demonstrate
improvements from using a high-quality and diverse subset of the data. We find
that our framework is able to improve models in multiple areas simultaneously,
such as in instruction following and bias reduction.

摘要：大型語言模型 (LLM) 已應用於各種任務，
包括文字摘要、網頁瀏覽和聊天機器人。它們
受益於無監督預訓練後的監督微調 (SFT) 和人類回饋的強化學習 (RLHF)。這些資料集可能
難以收集、範圍受限且樣本品質不一。
此外，資料集在監督格式上可能差異很大，從
數字到二元，以及具有許多不同值的多分量。我們
提出了一個使用異質回饋微調 LLM 的框架，它
有兩個主要組成部分。首先，我們將異質回饋資料合併為
單一監督格式，與 SFT 和 RLHF 等方法相容。接下來，
給定這個統一的回饋資料集，我們提取一個高品質且多樣化的
子集，以獲得潛在超過完整資料集的效能提升。
我們進行了廣泛的實驗，以了解這些
技術在整合異質回饋方面的有效性，並展示
使用高品質且多樣化的資料子集所帶來的改進。我們發現
我們的框架能夠同時改善模型的各個領域，
例如指令遵循和偏差減少。

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

摘要：開發自監督學習 (SSL) 模型，可以學習 H&E 吉像素全切片影像 (WSI) 的通用且可轉移表示，在計算病理學中正變得越來越有價值。這些模型有潛力推進關鍵任務，例如少次分類、切片檢索和患者分層。現有的切片表示學習方法將 SSL 的原理從小影像（例如 224 x 224 補丁）延伸到整個切片，通常透過對齊切片的兩個不同擴增（或視圖）。然而，生成的表示仍受到視圖有限的臨床和生物多樣性的限制。相反，我們假設使用多種標記染色的切片，例如免疫組織化學染色，可以用作不同的視圖來形成豐富的與任務無關的訓練訊號。為此，我們介紹 Madeleine，一種用於切片表示學習的多模式預訓練策略。Madeleine 使用雙重全局-局部跨染色對齊目標在大量乳癌樣本（N=4,211 個橫跨五種染色的 WSI）和腎臟移植樣本（N=12,070 個橫跨四種染色的 WSI）上進行訓練。我們在各種下游評估中展示了 Madeleine 學習的切片表示的品質，從形態和分子分類到預後預測，包括使用來自多個醫療中心的 7,299 個 WSI 的 21 項任務。程式碼可在 https://github.com/mahmoodlab/MADELEINE 取得。

##### **Development of REGAI: Rubric Enabled Generative Artificial Intelligence**
2408.02811v1 by Zach Johnson, Jeremy Straub

This paper presents and evaluates a new retrieval augmented generation (RAG)
and large language model (LLM)-based artificial intelligence (AI) technique:
rubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,
which can be created manually or automatically by the system, to enhance the
performance of LLMs for evaluation purposes. REGAI improves on the performance
of both classical LLMs and RAG-based LLM techniques. This paper describes
REGAI, presents data regarding its performance and discusses several possible
application areas for the technology.

摘要：本文介紹並評估一種新的檢索擴增生成 (RAG) 和大型語言模型 (LLM) 為基礎的人工智慧 (AI) 技術：標準啟用生成式人工智慧 (REGAI)。REGAI 使用標準，這些標準可以由系統手動或自動建立，以增強 LLM 的效能，以用於評量目的。REGAI 改善了傳統 LLM 和基於 RAG 的 LLM 技術的效能。本文說明 REGAI，提供有關其效能的資料，並討論該技術的幾個可能的應用領域。

##### **Examining Gender and Power on Wikipedia Through Face and Politeness**
2408.02798v1 by Adil Soubki, Shyne Choi, Owen Rambow

We propose a framework for analyzing discourse by combining two
interdependent concepts from sociolinguistic theory: face acts and politeness.
While politeness has robust existing tools and data, face acts are less
resourced. We introduce a new corpus created by annotating Wikipedia talk pages
with face acts and we use this to train a face act tagger. We then employ our
framework to study how face and politeness interact with gender and power in
discussions between Wikipedia editors. Among other findings, we observe that
female Wikipedians are not only more polite, which is consistent with prior
studies, but that this difference corresponds with significantly more language
directed at humbling aspects of their own face. Interestingly, the distinction
nearly vanishes once limiting to editors with administrative power.

摘要：我們提出一個分析話語的架構，結合社會語言學理論中的兩個相互依賴的概念：面子行為和禮貌。
雖然禮貌有強大的現有工具和資料，但面子行為的資源較少。我們引入一個新的語料庫，它是通過用面子行為註釋維基百科討論頁面創建的，我們使用它來訓練一個面子行為標記器。然後，我們使用我們的框架來研究面子和禮貌如何在維基百科編輯之間的討論中與性別和權力互動。在其他發現中，我們觀察到女性維基百科編輯者不僅更禮貌，這與先前的研究一致，而且這種差異與更多針對自己面子謙卑方面的語言相一致。有趣的是，一旦限制在具有管理權力的編輯者，這種區別幾乎消失。

##### **LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory**
2408.02784v1 by Jillian Ross, Yoon Kim, Andrew W. Lo

Humans are not homo economicus (i.e., rational economic beings). As humans,
we exhibit systematic behavioral biases such as loss aversion, anchoring,
framing, etc., which lead us to make suboptimal economic decisions. Insofar as
such biases may be embedded in text data on which large language models (LLMs)
are trained, to what extent are LLMs prone to the same behavioral biases?
Understanding these biases in LLMs is crucial for deploying LLMs to support
human decision-making. We propose utility theory-a paradigm at the core of
modern economic theory-as an approach to evaluate the economic biases of LLMs.
Utility theory enables the quantification and comparison of economic behavior
against benchmarks such as perfect rationality or human behavior. To
demonstrate our approach, we quantify and compare the economic behavior of a
variety of open- and closed-source LLMs. We find that the economic behavior of
current LLMs is neither entirely human-like nor entirely economicus-like. We
also find that most current LLMs struggle to maintain consistent economic
behavior across settings. Finally, we illustrate how our approach can measure
the effect of interventions such as prompting on economic biases.

摘要：人類並非經濟人（即理性的經濟個體）。作為人類，
我們表現出系統性的行為偏差，例如厭惡損失、錨定、
框架等，這些偏差導致我們做出次優的經濟決策。在
此類偏差可能嵌入大型語言模型 (LLM) 接受訓練的文本數據中，LLM 在多大程度上容易出現相同的行為偏差？
了解 LLM 中的這些偏差對於部署 LLM 以支持
人類決策至關重要。我們提出效用理論——現代經濟理論的核心範式——作為一種評估 LLM 經濟偏差的方法。
效用理論能夠量化和比較經濟行為
與完美理性或人類行為等基準。為了
展示我們的做法，我們量化和比較了
各種開源和閉源 LLM 的經濟行為。我們發現，當前 LLM 的經濟行為既不像人類也不完全像經濟人。我們
還發現，大多數當前 LLM 難以在不同設置中保持一致的經濟行為。最後，我們說明了我們的做法如何衡量
提示等干預措施對經濟偏差的影響。

##### **Self-Taught Evaluators**
2408.02666v1 by Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane Dwivedi-Yu, Richard Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, Xian Li

Model-based evaluation is at the heart of successful model development -- as
a reward model for training, and as a replacement for human evaluation. To
train such evaluators, the standard approach is to collect a large amount of
human preference judgments over model responses, which is costly and the data
becomes stale as models improve. In this work, we present an approach that aims
to im-prove evaluators without human annotations, using synthetic training data
only. Starting from unlabeled instructions, our iterative self-improvement
scheme generates contrasting model outputs and trains an LLM-as-a-Judge to
produce reasoning traces and final judgments, repeating this training at each
new iteration using the improved predictions. Without any labeled preference
data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)
from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms
commonly used LLM judges such as GPT-4 and matches the performance of the
top-performing reward models trained with labeled examples.

摘要：基於模型的評估是成功模型開發的核心，作為訓練的獎勵模型，以及作為人工評估的替代方案。為了訓練此類評估器，標準方法是收集大量人類偏好判斷，以對模型反應進行評估，這既昂貴，而且隨著模型的改進，數據也會變得陳舊。在這項工作中，我們提出了一種旨在在沒有人工註解的情況下改進評估器的方法，僅使用合成訓練數據。從未標記的說明開始，我們的迭代式自我改進方案會產生對比的模型輸出，並訓練 LLM-as-a-Judge 以產生推理追蹤和最終判斷，在每次新的迭代中使用改進的預測重複此訓練。在沒有任何標記的偏好數據的情況下，我們的自學評估器可以將強大的 LLM（Llama3-70B-Instruct）從 RewardBench 上的 75.4 提升到 88.3（多數投票為 88.7）。這優於常用的 LLM 評審，例如 GPT-4，並且與使用標記範例訓練的效能最佳的獎勵模型的效能相匹配。

##### **Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?**
2408.02651v1 by Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad

Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language tasks, but their safety and morality remain contentious due to
their training on internet text corpora. To address these concerns, alignment
techniques have been developed to improve the public usability and safety of
LLMs. Yet, the potential for generating harmful content through these models
seems to persist. This paper explores the concept of jailbreaking
LLMs-reversing their alignment through adversarial triggers. Previous methods,
such as soft embedding prompts, manually crafted prompts, and gradient-based
automatic prompts, have had limited success on black-box models due to their
requirements for model access and for producing a low variety of manually
crafted prompts, making them susceptible to being blocked. This paper
introduces a novel approach using reinforcement learning to optimize
adversarial triggers, requiring only inference API access to the target model
and a small surrogate model. Our method, which leverages a BERTScore-based
reward function, enhances the transferability and effectiveness of adversarial
triggers on new black-box models. We demonstrate that this approach improves
the performance of adversarial triggers on a previously untested language
model.

摘要：大型語言模型 (LLM) 在自然語言任務中展現出令人印象深刻的能力，但由於它們在網際網路文字語料庫上訓練，安全性與道德性仍有爭議。為了解決這些問題，已開發出校準技術來改善 LLM 的公開可用性和安全性。然而，透過這些模型產生有害內容的可能性似乎仍然存在。本文探討了越獄 LLM 的概念，透過對抗性觸發器來逆轉它們的校準。先前的技術，例如軟嵌入提示、手動製作提示和基於梯度的自動提示，由於需要存取模型和產生少量手動製作提示，導致在黑箱模型上成功有限，使其容易受到封鎖。本文介紹了一種使用強化學習來最佳化對抗性觸發器的新方法，只需要推論 API 存取目標模型和一個小型代理模型。我們的技術利用基於 BERTScore 的獎勵函數，增強了對抗性觸發器在新黑箱模型上的可傳遞性和有效性。我們證明了這種方法改善了對抗性觸發器在先前未測試過的語言模型上的效能。

##### **SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models**
2408.02632v1 by Muxi Diao, Rumei Li, Shiyang Liu, Guogang Liao, Jingang Wang, Xunliang Cai, Weiran Xu

As large language models (LLMs) continue to advance in capability and
influence, ensuring their security and preventing harmful outputs has become
crucial. A promising approach to address these concerns involves training
models to automatically generate adversarial prompts for red teaming. However,
the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness
of current adversarial methods, which struggle to specifically target and
explore the weaknesses of these models. To tackle these challenges, we
introduce the $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$
optimization framework, which enhances security by leveraging data generated by
the model itself. SEAS operates through three iterative stages: Initialization,
Attack, and Adversarial Optimization, refining both the Red Team and Target
models to improve robustness and safety. This framework reduces reliance on
manual testing and significantly enhances the security capabilities of LLMs.
Our contributions include a novel adversarial framework, a comprehensive safety
dataset, and after three iterations, the Target model achieves a security level
comparable to GPT-4, while the Red Team model shows a marked increase in attack
success rate (ASR) against advanced models.

摘要：隨著大型語言模型 (LLM) 在能力和影響力方面持續進步，確保其安全性並防止有害輸出已變得至關重要。解決這些問題的一個有前途的方法涉及訓練模型以自動生成對抗性提示以進行紅隊演練。然而，LLM 中漏洞的微妙性不斷演變，挑戰了當前對抗方法的有效性，這些方法難以針對這些模型的弱點並加以探索。為了應對這些挑戰，我們引入了 $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$ 最佳化架構，它通過利用模型本身產生的數據來增強安全性。SEAS 通過三個反覆運算階段運作：初始化、攻擊和對抗性最佳化，優化紅隊和目標模型以提高穩健性和安全性。此架構減少了對手動測試的依賴，並顯著增強了 LLM 的安全功能。我們的貢獻包括一個新穎的對抗性架構、一個全面的安全性資料集，並且經過三次反覆運算後，目標模型達到了與 GPT-4 相當的安全性等級，而紅隊模型顯示出對抗高級模型的攻擊成功率 (ASR) 明顯增加。

##### **Language Model Can Listen While Speaking**
2408.02622v1 by Ziyang Ma, Yakun Song, Chenpeng Du, Jian Cong, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen

Dialogue serves as the most natural manner of human-computer interaction
(HCI). Recent advancements in speech language models (SLM) have significantly
enhanced speech-based conversational AI. However, these models are limited to
turn-based conversation, lacking the ability to interact with humans in
real-time spoken scenarios, for example, being interrupted when the generated
content is not satisfactory. To address these limitations, we explore full
duplex modeling (FDM) in interactive speech language models (iSLM), focusing on
enhancing real-time interaction and, more explicitly, exploring the
quintessential ability of interruption. We introduce a novel model design,
namely listening-while-speaking language model (LSLM), an end-to-end system
equipped with both listening and speaking channels. Our LSLM employs a
token-based decoder-only TTS for speech generation and a streaming
self-supervised learning (SSL) encoder for real-time audio input. LSLM fuses
both channels for autoregressive generation and detects turn-taking in real
time. Three fusion strategies -- early fusion, middle fusion, and late fusion
-- are explored, with middle fusion achieving an optimal balance between speech
generation and real-time interaction. Two experimental settings, command-based
FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity
to diverse instructions. Our results highlight LSLM's capability to achieve
duplex communication with minimal impact on existing systems. This study aims
to advance the development of interactive speech dialogue systems, enhancing
their applicability in real-world contexts.

摘要：對話是人機互動 (HCI) 最自然的方式。語音語言模型 (SLM) 的最新進展已大幅提升基於語音的對話式 AI。然而，這些模型僅限於回合制對話，無法與人類進行即時口語互動，例如在產生的內容不令人滿意時被打斷。為了解決這些限制，我們在互動式語音語言模型 (iSLM) 中探索全雙工建模 (FDM)，重點在於增強即時互動，更明確地說，探索中斷的精髓能力。我們引入了一種新穎的模型設計，即聆聽時說話語言模型 (LSLM)，這是一個具備聆聽和說話通道的端對端系統。我們的 LSLM 使用基於代碼的僅解碼器 TTS 進行語音產生，並使用串流自監督學習 (SSL) 編碼器進行即時音訊輸入。LSLM 融合了兩個通道進行自迴歸產生，並即時偵測輪流發言。探索了三個融合策略——早期融合、中期融合和後期融合——其中中期融合在語音產生和即時互動之間取得了最佳平衡。兩種實驗設定，基於指令的 FDM 和基於語音的 FDM，展示了 LSLM 對雜訊的穩健性和對不同指令的敏感性。我們的結果突顯了 LSLM 在對現有系統影響最小的情況下實現雙工通訊的能力。本研究旨在推動互動式語音對話系統的發展，增強其在現實世界中的應用性。

##### **BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba**
2408.02600v1 by Ling Yue, Sixue Xing, Yingzhou Lu, Tianfan Fu

The advancement of natural language processing (NLP) in biology hinges on
models' ability to interpret intricate biomedical literature. Traditional
models often struggle with the complex and domain-specific language in this
field. In this paper, we present BioMamba, a pre-trained model specifically
designed for biomedical text mining. BioMamba builds upon the Mamba
architecture and is pre-trained on an extensive corpus of biomedical
literature. Our empirical studies demonstrate that BioMamba significantly
outperforms models like BioBERT and general-domain Mamba across various
biomedical tasks. For instance, BioMamba achieves a 100 times reduction in
perplexity and a 4 times reduction in cross-entropy loss on the BioASQ test
set. We provide an overview of the model architecture, pre-training process,
and fine-tuning techniques. Additionally, we release the code and trained model
to facilitate further research.

摘要：自然語言處理 (NLP) 在生物學中的進展取決於
模型詮釋複雜生物醫學文獻的能力。傳統
模型經常難以應付這個領域中複雜且領域特定的語言。在本文中，我們提出 BioMamba，一種專門
設計用於生物醫學文本探勘的預訓練模型。BioMamba 建立在 Mamba
架構之上，並在大量的生物醫學預訓練
文獻上進行預訓練。我們的實證研究證明，BioMamba 在各種
生物醫學任務上都明顯優於 BioBERT 和一般領域的 Mamba。例如，BioMamba 在 BioASQ 測試
集中將困惑度降低了 100 倍，並將交叉熵損失降低了 4 倍。我們提供了模型架構、預訓練流程的概述，
以及微調技術。此外，我們釋出程式碼和訓練好的模型
以促進進一步的研究。

##### **Progressively Selective Label Enhancement for Language Model Alignment**
2408.02599v1 by Biao Liu, Ning Xu, Xin Geng

Large Language Models have demonstrated impressive capabilities in various
language tasks but may produce content that misaligns with human expectations,
raising ethical and legal concerns. Therefore, it is important to explore the
limitations and implement restrictions on the models to ensure safety and
compliance, with Reinforcement Learning from Human Feedback (RLHF) being the
primary method. Due to challenges in stability and scalability with the RLHF
stages, researchers are exploring alternative methods to achieve effects
comparable to those of RLHF. However, these methods often depend on large
high-quality datasets and inefficiently utilize generated data. To deal with
this problem, we propose PSLE, i.e., Progressively Selective Label Enhancement
for Language Model Alignment, a framework that fully utilizes all generated
data by guiding the model with principles to align outputs with human
expectations. Using a dynamically updated threshold, our approach ensures
efficient data utilization by incorporating all generated responses and
weighting them based on their corresponding reward scores. Experimental results
on multiple datasets demonstrate the effectiveness of PSLE compared to existing
language model alignment methods.

摘要：大型語言模型已在各種語言任務中展現出令人印象深刻的能力，但可能會產生與人類期望不符的內容，引發道德和法律方面的疑慮。因此，探索模型的限制並實施限制以確保安全性和合規性非常重要，而透過人類回饋的強化學習 (RLHF) 是主要方法。由於 RLHF 階段在穩定性和可擴充性方面存在挑戰，研究人員正在探索替代方法以實現與 RLHF 相當的效果。然而，這些方法通常依賴於大型高品質的資料集，且無法有效利用產生的資料。為了解決這個問題，我們提出 PSLE，即語言模型比對的漸進式選擇標籤增強，這是一個透過指導模型使用原則來比對輸出與人類期望，進而充分利用所有產生資料的框架。我們的做法使用動態更新的閾值，透過納入所有產生的回應並根據其對應的獎勵分數加權，確保有效利用資料。在多個資料集上的實驗結果證明了 PSLE 與現有的語言模型比對方法相比的有效性。

##### **Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection**
2408.02595v1 by Sajal Aggarwal, Ananya Pandey, Dinesh Kumar Vishwakarma

Sarcasm is a type of irony, characterized by an inherent mismatch between the
literal interpretation and the intended connotation. Though sarcasm detection
in text has been extensively studied, there are situations in which textual
input alone might be insufficient to perceive sarcasm. The inclusion of
additional contextual cues, such as images, is essential to recognize sarcasm
in social media data effectively. This study presents a novel framework for
multimodal sarcasm detection that can process input triplets. Two components of
these triplets comprise the input text and its associated image, as provided in
the datasets. Additionally, a supplementary modality is introduced in the form
of descriptive image captions. The motivation behind incorporating this visual
semantic representation is to more accurately capture the discrepancies between
the textual and visual content, which are fundamental to the sarcasm detection
task. The primary contributions of this study are: (1) a robust textual feature
extraction branch that utilizes a cross-lingual language model; (2) a visual
feature extraction branch that incorporates a self-regulated residual ConvNet
integrated with a lightweight spatially aware attention module; (3) an
additional modality in the form of image captions generated using an
encoder-decoder architecture capable of reading text embedded in images; (4)
distinct attention modules to effectively identify the incongruities between
the text and two levels of image representations; (5) multi-level cross-domain
semantic incongruity representation achieved through feature fusion. Compared
with cutting-edge baselines, the proposed model achieves the best accuracy of
92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and
MultiBully datasets.

摘要：<paragraph>諷刺是一種反諷，其特點是字面意思與預期的含義之間存在固有的不匹配。雖然文本中的諷刺偵測已被廣泛研究，但在某些情況下，單獨的文本輸入可能不足以感知諷刺。加入額外的上下文線索，例如圖片，對於有效識別社群媒體資料中的諷刺至關重要。本研究提出了一個多模態諷刺偵測的新框架，可以處理輸入三元組。這些三元組的兩個組成部分包括輸入文本及其關聯圖片，如資料集中所提供的。此外，以描述性圖片標題的形式引入了一個補充模態。加入這種視覺語義表示的動機是更準確地捕捉文本和視覺內容之間的差異，這對於諷刺偵測任務至關重要。本研究的主要貢獻包括：(1) 一個強健的文本特徵提取分支，它利用了一個跨語言語言模型；(2) 一個視覺特徵提取分支，它結合了一個自調節殘差 ConvNet，並集成了輕量級空間感知注意力模組；(3) 一個額外的模態，以圖片標題的形式，使用一個能夠讀取圖片中嵌入文本的編碼器-解碼器架構產生；(4) 不同的注意力模組，以有效識別文本和兩個層級的圖片表示之間的不一致；(5) 通過特徵融合實現的多層級跨領域語義不一致表示。與尖端的基準相比，所提出的模型分別在 Twitter 多模態諷刺和 MultiBully 資料集上達到了 92.89% 和 64.48% 的最佳準確度。</paragraph>

##### **Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization**
2408.02584v1 by Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Aditya Vempaty, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku

The ever-increasing volume of digital information necessitates efficient
methods for users to extract key insights from lengthy documents. Aspect-based
summarization offers a targeted approach, generating summaries focused on
specific aspects within a document. Despite advancements in aspect-based
summarization research, there is a continuous quest for improved model
performance. Given that large language models (LLMs) have demonstrated the
potential to revolutionize diverse tasks within natural language processing,
particularly in the problem of summarization, this paper explores the potential
of fine-tuning LLMs for the aspect-based summarization task. We evaluate the
impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,
Gemma and Aya, on a publicly available domain-specific aspect based summary
dataset. We hypothesize that this approach will enable these models to
effectively identify and extract aspect-related information, leading to
superior quality aspect-based summaries compared to the state-of-the-art. We
establish a comprehensive evaluation framework to compare the performance of
fine-tuned LLMs against competing aspect-based summarization methods and
vanilla counterparts of the fine-tuned LLMs. Our work contributes to the field
of aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs
for generating high-quality aspect-based summaries. Furthermore, it opens doors
for further exploration of using LLMs for targeted information extraction tasks
across various NLP domains.

摘要：隨著數位資訊量不斷增加，使用者需要有效率的方法從冗長的文件中萃取出重點洞察。基於面向面向的摘要提供了一個目標導向的方法，產生摘要，專注於文件中的特定面向。儘管在基於面向的摘要研究中有進展，但仍持續追求改善模型效能。考量到大型語言模型 (LLM) 已展現出革新自然語言處理中各種任務的潛力，特別是在摘要問題中，本文探討了微調 LLM 以用於基於面向的摘要任務的潛力。我們評估微調開放原始碼基礎 LLM（包括 Llama2、Mistral、Gemma 和 Aya）對公開可用的特定領域面向摘要資料集的影響。我們假設這種方法將使這些模型能夠有效地識別和萃取出與面向相關的資訊，產生與現有技術相比品質更優異的基於面向的摘要。我們建立了一個全面的評估架構，以比較微調 LLM 與競爭的基於面向的摘要方法以及微調 LLM 的原始版本之間的效能。我們的研究透過展示微調 LLM 以產生高品質的基於面向的摘要的效能，為基於面向的摘要領域做出貢獻。此外，它也開啟了進一步探索使用 LLM 進行跨各種 NLP 領域的目標資訊萃取任務的大門。

##### **Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition**
2408.02582v1 by Jaeyoung Kim, Han Lu, Soheil Khorram, Anshuman Tripathi, Qian Zhang, Hasim Sak

Modern automatic speech recognition (ASR) systems are typically trained on
more than tens of thousands hours of speech data, which is one of the main
factors for their great success. However, the distribution of such data is
typically biased towards common accents or typical speech patterns. As a
result, those systems often poorly perform on atypical accented speech. In this
paper, we present accent clustering and mining schemes for fair speech
recognition systems which can perform equally well on under-represented
accented speech. For accent recognition, we applied three schemes to overcome
limited size of supervised accent data: supervised or unsupervised
pre-training, distributionally robust optimization (DRO) and unsupervised
clustering. Three schemes can significantly improve the accent recognition
model especially for unbalanced and small accented speech. Fine-tuning ASR on
the mined Indian accent speech using the proposed supervised or unsupervised
clustering schemes showed 10.0% and 5.3% relative improvements compared to
fine-tuning on the randomly sampled speech, respectively.

摘要：現代自動語音辨識 (ASR) 系統通常會在超過數萬小時的語音資料上進行訓練，這是它們成功的主要因素之一。然而，此類資料的分配通常會偏向於常見的口音或典型的語音模式。因此，這些系統在非典型口音的語音上往往表現不佳。在本文中，我們提出公平語音辨識系統的口音分群和挖掘方案，這些方案可以在代表性不足的口音語音上表現得一樣好。對於口音辨識，我們應用三種方案來克服監督式口音資料的規模限制：監督式或非監督式預訓練、分佈穩健最佳化 (DRO) 和非監督式分群。三種方案可以顯著改善口音辨識模型，特別是對於不平衡且規模小的口音語音。使用建議的監督式或非監督式分群方案對挖掘的印度口音語音進行 ASR 微調，與對隨機取樣的語音進行微調相比，分別顯示出 10.0% 和 5.3% 的相對改善。

##### **Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs**
2408.02571v1 by Ananya Pandey, Dinesh Kumar Vishwakarma

The emoticons are symbolic representations that generally accompany the
textual content to visually enhance or summarize the true intention of a
written message. Although widely utilized in the realm of social media, the
core semantics of these emoticons have not been extensively explored based on
multiple modalities. Incorporating textual and visual information within a
single message develops an advanced way of conveying information. Hence, this
research aims to analyze the relationship among sentences, visuals, and
emoticons. For an orderly exposition, this paper initially provides a detailed
examination of the various techniques for extracting multimodal features,
emphasizing the pros and cons of each method. Through conducting a
comprehensive examination of several multimodal algorithms, with specific
emphasis on the fusion approaches, we have proposed a novel contrastive
learning based multimodal architecture. The proposed model employs the joint
training of dual-branch encoder along with the contrastive learning to
accurately map text and images into a common latent space. Our key finding is
that by integrating the principle of contrastive learning with that of the
other two branches yields superior results. The experimental results
demonstrate that our suggested methodology surpasses existing multimodal
approaches in terms of accuracy and robustness. The proposed model attained an
accuracy of 91% and an MCC-score of 90% while assessing emoticons using the
Multimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence
that deep features acquired by contrastive learning are more efficient,
suggesting that the proposed fusion technique also possesses strong
generalisation capabilities for recognising emoticons across several modes.

摘要：表情符號是象徵性的表示，通常伴隨著文字內容，以視覺方式增強或總結書面訊息的真實意圖。雖然在社群媒體領域廣泛使用，但這些表情符號的核心語義尚未根據多種模式廣泛探討。在單一訊息中納入文字和視覺資訊，發展出傳達資訊的先進方式。因此，本研究旨在分析句子、視覺和表情符號之間的關係。為了有條理地說明，本文最初詳細探討了各種萃取多模態特徵的技術，並強調了每種方法的優缺點。透過對多種多模態演算法進行全面探討，特別強調融合方法，我們提出了一種基於對比學習的新穎多模態架構。所提出的模型採用雙分支編碼器的聯合訓練，以及對比學習，以準確地將文字和影像對應到一個共同的潛在空間。我們的關鍵發現是，將對比學習的原則與其他兩個分支的原則整合起來，會產生更好的結果。實驗結果表明，我們建議的方法在準確性和穩健性方面優於現有的多模態方法。所提出的模型在使用從 Twitter 取得的多模態 Twitter 表情符號資料集評估表情符號時，達到了 91% 的準確度和 90% 的 MCC 分數。我們提供了證據，證明透過對比學習獲得的深度特徵更有效率，這表示所提出的融合技術也具備跨多種模式辨識表情符號的強大泛化能力。

##### **Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**
2408.02559v1 by Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, Yangqiu Song

Large language models (LLMs) have shown success in handling simple games with
imperfect information and enabling multi-agent coordination, but their ability
to facilitate practical collaboration against other agents in complex,
imperfect information environments, especially in a non-English environment,
still needs to be explored. This study investigates the applicability of
knowledge acquired by open-source and API-based LLMs to sophisticated
text-based games requiring agent collaboration under imperfect information,
comparing their performance to established baselines using other types of
agents. We propose a Theory of Mind (ToM) planning technique that allows LLM
agents to adapt their strategy against various adversaries using only game
rules, current state, and historical context as input. An external tool was
incorporated to mitigate the challenge of dynamic and extensive action spaces
in this card game. Our results show that although a performance gap exists
between current LLMs and state-of-the-art reinforcement learning (RL) models,
LLMs demonstrate ToM capabilities in this game setting. It consistently
improves their performance against opposing agents, suggesting their ability to
understand the actions of allies and adversaries and establish collaboration
with allies. To encourage further research and understanding, we have made our
codebase openly accessible.

摘要：大型語言模型 (LLM) 已展現出在處理具有不完美資訊的簡單遊戲以及啟用多重代理協調方面的成功，但其促進在複雜、不完美資訊環境中與其他代理進行實際協作的能力，特別是在非英語環境中，仍有待探討。本研究探討了開放原始碼和基於 API 的 LLM 所獲得的知識，在需要代理在不完美資訊下協作的精緻文字遊戲中的適用性，並將其效能與使用其他類型代理的已建立基準進行比較。我們提出了一種心智理論 (ToM) 規劃技術，允許 LLM 代理僅使用遊戲規則、目前狀態和歷史背景作為輸入，來調整其對抗各種對手的策略。在這個紙牌遊戲中，整合了一個外部工具來減輕動態且廣泛動作空間的挑戰。我們的結果顯示，儘管目前的 LLM 和最先進的強化學習 (RL) 模型之間存在效能差距，但 LLM 在此遊戲設定中展現了 ToM 能力。它持續提升其對抗敵對代理的效能，表明其了解盟友和敵人的行動，並與盟友建立合作的能力。為了鼓勵進一步的研究和理解，我們已公開我們的程式碼庫。

##### **MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization**
2408.02555v1 by Yiwen Chen, Yikai Wang, Yihao Luo, Zhengyi Wang, Zilong Chen, Jun Zhu, Chi Zhang, Guosheng Lin

We introduce MeshAnything V2, an autoregressive transformer that generates
Artist-Created Meshes (AM) aligned to given shapes. It can be integrated with
various 3D asset production pipelines to achieve high-quality, highly
controllable AM generation. MeshAnything V2 surpasses previous methods in both
efficiency and performance using models of the same size. These improvements
are due to our newly proposed mesh tokenization method: Adjacent Mesh
Tokenization (AMT). Different from previous methods that represent each face
with three vertices, AMT uses a single vertex whenever possible. Compared to
previous methods, AMT requires about half the token sequence length to
represent the same mesh in average. Furthermore, the token sequences from AMT
are more compact and well-structured, fundamentally benefiting AM generation.
Our extensive experiments show that AMT significantly improves the efficiency
and performance of AM generation. Project Page:
https://buaacyw.github.io/meshanything-v2/

摘要：我們介紹了 MeshAnything V2，這是一種自迴歸轉換器，可生成與給定形狀對齊的藝術家創建網格 (AM)。它可以與各種 3D 資產製作管道整合，以實現高品質、高度可控的 AM 生成。MeshAnything V2 在效率和效能方面都超越了之前的模型，使用相同大小的模型。這些改進歸功於我們新提出的網格標記化方法：相鄰網格標記化 (AMT)。與之前用三個頂點表示每個面的方法不同，AMT 盡可能使用單個頂點。與之前的模型相比，AMT 平均需要大約一半的標記序列長度來表示相同的網格。此外，來自 AMT 的標記序列更緊湊且結構良好，從根本上有利於 AM 生成。我們廣泛的實驗表明，AMT 大幅提高了 AM 生成效率和效能。專案頁面：
https://buaacyw.github.io/meshanything-v2/

##### **The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces**
2408.02547v1 by Costanza Armanini, Tuka Alhanai, Farah E. Shamout, S. Farokh Atashzar

Developing accurate hand gesture perception models is critical for various
robotic applications, enabling effective communication between humans and
machines and directly impacting neurorobotics and interactive robots. Recently,
surface electromyography (sEMG) has been explored for its rich informational
context and accessibility when combined with advanced machine learning
approaches and wearable systems. The literature presents numerous approaches to
boost performance while ensuring robustness for neurorobots using sEMG, often
resulting in models requiring high processing power, large datasets, and less
scalable solutions. This paper addresses this challenge by proposing the
decoding of muscle synchronization rather than individual muscle activation. We
study coherence-based functional muscle networks as the core of our perception
model, proposing that functional synchronization between muscles and the
graph-based network of muscle connectivity encode contextual information about
intended hand gestures. This can be decoded using shallow machine learning
approaches without the need for deep temporal networks. Our technique could
impact myoelectric control of neurorobots by reducing computational burdens and
enhancing efficiency. The approach is benchmarked on the Ninapro database,
which contains 12 EMG signals from 40 subjects performing 17 hand gestures. It
achieves an accuracy of 85.1%, demonstrating improved performance compared to
existing methods while requiring much less computational power. The results
support the hypothesis that a coherence-based functional muscle network encodes
critical information related to gesture execution, significantly enhancing hand
gesture perception with potential applications for neurorobotic systems and
interactive machines.

摘要：開發準確的手部手勢感知模型對於各種機器人應用至關重要，能讓人類與機器之間有效溝通，並直接影響神經機器人和互動式機器人。最近，表面肌電圖 (sEMG) 已被探索其豐富的資訊脈絡和可及性，並與先進的機器學習方法和可穿戴系統結合使用。文獻提出了許多方法來提升效能，同時確保使用 sEMG 的神經機器人的穩健性，通常會產生需要高處理能力、大型資料集和較不具擴充性的解決方案。本文透過提出解碼肌肉同步化，而非個別肌肉活化，來解決此挑戰。我們研究基於相干性的功能性肌肉網路，作為我們感知模型的核心，提出肌肉之間的功能性同步化和基於圖形的肌肉連接網路編碼有關預期手部手勢的背景資訊。這可以使用淺層機器學習方法解碼，而不需要深度時間網路。我們的技術可以透過減少運算負擔和提高效率，影響神經機器人的肌電控制。此方法以 Ninapro 資料庫為基準，其中包含來自 40 位受試者執行 17 種手部手勢的 12 個 EMG 訊號。它達到了 85.1% 的準確度，與現有方法相比，表現有所提升，同時需要的運算能力也少了很多。結果支持了基於相干性的功能性肌肉網路編碼與手勢執行相關的重要資訊的假設，顯著增強了手部手勢感知，並具有神經機器人系統和互動式機器人的潛在應用。

##### **RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation**
2408.02545v1 by Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak

Implementing Retrieval-Augmented Generation (RAG) systems is inherently
complex, requiring deep understanding of data, use cases, and intricate design
decisions. Additionally, evaluating these systems presents significant
challenges, necessitating assessment of both retrieval accuracy and generative
quality through a multi-faceted approach. We introduce RAG Foundry, an
open-source framework for augmenting large language models for RAG use cases.
RAG Foundry integrates data creation, training, inference and evaluation into a
single workflow, facilitating the creation of data-augmented datasets for
training and evaluating large language models in RAG settings. This integration
enables rapid prototyping and experimentation with various RAG techniques,
allowing users to easily generate datasets and train RAG models using internal
or specialized knowledge sources. We demonstrate the framework effectiveness by
augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG
configurations, showcasing consistent improvements across three
knowledge-intensive datasets. Code is released as open-source in
https://github.com/IntelLabs/RAGFoundry.

摘要：實作檢索增強生成（RAG）系統本質上很複雜，需要深入了解資料、使用案例和複雜的設計決策。此外，評估這些系統會帶來顯著的挑戰，需要透過多面向的方法評估檢索準確度和生成品質。我們介紹 RAG Foundry，一個用於擴充大型語言模型以進行 RAG 使用案例的開源架構。RAG Foundry 將資料建立、訓練、推論和評估整合到單一工作流程中，簡化了資料增強資料集的建立，以便在 RAG 設定中訓練和評估大型語言模型。這種整合能快速製作原型和使用各種 RAG 技術進行實驗，讓使用者能輕鬆使用內部或專業知識來源來產生資料集並訓練 RAG 模型。我們透過使用多樣化的 RAG 組態來擴充和微調 Llama-3 和 Phi-3 模型來展示架構的有效性，展示了在三個知識密集型資料集中的持續改進。程式碼已在 https://github.com/IntelLabs/RAGFoundry 中以開源方式釋出。

##### **Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions**
2408.02544v1 by Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, Hai Zhao

This paper investigates the faithfulness of multimodal large language model
(MLLM) agents in the graphical user interface (GUI) environment, aiming to
address the research question of whether multimodal GUI agents can be
distracted by environmental context. A general setting is proposed where both
the user and the agent are benign, and the environment, while not malicious,
contains unrelated content. A wide range of MLLMs are evaluated as GUI agents
using our simulated dataset, following three working patterns with different
levels of perception. Experimental results reveal that even the most powerful
models, whether generalist agents or specialist GUI agents, are susceptible to
distractions. While recent studies predominantly focus on the helpfulness
(i.e., action accuracy) of multimodal agents, our findings indicate that these
agents are prone to environmental distractions, resulting in unfaithful
behaviors. Furthermore, we switch to the adversarial perspective and implement
environment injection, demonstrating that such unfaithfulness can be exploited,
leading to unexpected risks.

摘要：本文探討了圖形使用者介面 (GUI) 環境中多模態大型語言模型 (MLLM) 代理的忠實度，旨在解決多模態 GUI 代理是否會受到環境背景影響的研究問題。本文提出了一般設定，其中使用者和代理都是良性的，而環境雖然沒有惡意，但包含不相關的內容。我們使用模擬資料集評估了廣泛的 MLLM 作為 GUI 代理，遵循具有不同感知層級的三種工作模式。實驗結果顯示，即使是最強大的模型（無論是通才代理還是專家 GUI 代理）都容易受到干擾。儘管最近的研究主要關注多模態代理的有用性（即動作準確性），但我們的研究結果表明，這些代理容易受到環境干擾，導致不忠實的行為。此外，我們轉向對抗觀點並實作環境注入，證明這種不忠實可以被利用，導致意外的風險。

##### **OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar**
2408.02520v1 by Christoph Rauchegger, Sonja Mei Wang, Pieter Delobelle

The FIFA World Cup in Qatar was discussed extensively in the news and on
social media. Due to news reports with allegations of human rights violations,
there were calls to boycott it. Wearing a OneLove armband was part of a planned
protest activity. Controversy around the armband arose when FIFA threatened to
sanction captains who wear it. To understand what topics Twitter users Tweeted
about and what the opinion of German Twitter users was towards the OneLove
armband, we performed an analysis of German Tweets published during the World
Cup using in-context learning with LLMs. We validated the labels on human
annotations. We found that Twitter users initially discussed the armband's
impact, LGBT rights, and politics; after the ban, the conversation shifted
towards politics in sports in general, accompanied by a subtle shift in
sentiment towards neutrality. Our evaluation serves as a framework for future
research to explore the impact of sports activism and evolving public
sentiment. This is especially useful in settings where labeling datasets for
specific opinions is unfeasible, such as when events are unfolding.

摘要：卡達的 FIFA 世界盃在新聞和社群媒體上被廣泛討論。由於新聞報導中有人指控有侵犯人權的行為，因此有人呼籲抵制。佩戴 OneLove 臂章是計畫抗議活動的一部分。當 FIFA 威脅要制裁佩戴臂章的隊長時，圍繞臂章的爭議隨之而起。為了了解 Twitter 用戶推文的主題以及德國 Twitter 用戶對 OneLove 臂章的看法，我們使用 LLM 的語境學習對世界盃期間發布的德文推文進行了分析。我們驗證了人工標註的標籤。我們發現，Twitter 用戶最初討論的是臂章的影響、LGBT 權利和政治；在禁令之後，對話轉向體育中的政治，同時情緒微妙地轉向中立。我們的評估作為未來研究探索運動激進主義和公眾情緒演變的影響的框架。這在為特定意見標記資料集不可行的情況下特別有用，例如在事件正在展開時。

##### **UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model**
2408.02503v1 by Zhaowei Li, Wei Wang, YiQing Cai, Xu Qi, Pengyu Wang, Dong Zhang, Hang Song, Botian Jiang, Zhida Huang, Tao Wang

Significant advancements has recently been achieved in the field of
multi-modal large language models (MLLMs), demonstrating their remarkable
capabilities in understanding and reasoning across diverse tasks. However,
these models are often trained for specific tasks and rely on task-specific
input-output formats, limiting their applicability to a broader range of tasks.
This raises a fundamental question: Can we develop a unified approach to
represent and handle different multi-modal tasks to maximize the
generalizability of MLLMs? In this paper, we propose UnifiedMLLM, a
comprehensive model designed to represent various tasks using a unified
representation. Our model exhibits strong capabilities in comprehending the
implicit intent of user instructions and preforming reasoning. In addition to
generating textual responses, our model also outputs task tokens and grounding
tokens, serving as indicators of task types and task granularity. These outputs
are subsequently routed through the task router and directed to specific expert
models for task completion. To train our model, we construct a task-specific
dataset and an 100k multi-task dataset encompassing complex scenarios.
Employing a three-stage training strategy, we equip our model with robust
reasoning and task processing capabilities while preserving its generalization
capacity and knowledge reservoir. Extensive experiments showcase the impressive
performance of our unified representation approach across various tasks,
surpassing existing methodologies. Furthermore, our approach exhibits
exceptional scalability and generality. Our code, model, and dataset will be
available at \url{https://github.com/lzw-lzw/UnifiedMLLM}.

摘要：<paragraph>最近，多模态大型语言模型 (MLLM) 领域取得了重大进展，展示了它们在理解和推理各种任务方面的卓越能力。然而，这些模型通常针对特定任务进行训练，并依赖于特定任务的输入输出格式，这限制了它们在更广泛的任务范围内的适用性。这引发了一个基本问题：我们能否开发一种统一的方法来表示和处理不同的多模态任务，以最大化 MLLM 的泛化能力？在本文中，我们提出了 UnifiedMLLM，这是一个综合模型，旨在使用统一表示来表示各种任务。我们的模型在理解用户指令的隐含意图和进行推理方面表现出强大的能力。除了生成文本响应之外，我们的模型还输出任务标记和基础标记，作为任务类型和任务粒度的指标。这些输出随后通过任务路由器路由，并定向到特定专家模型以完成任务。为了训练我们的模型，我们构建了一个特定于任务的数据集和一个包含复杂场景的 100k 多任务数据集。采用三阶段训练策略，我们为我们的模型配备了强大的推理和任务处理能力，同时保留了它的泛化能力和知识储备。广泛的实验展示了我们的统一表示方法在各种任务中的出色表现，超越了现有方法。此外，我们的方法表现出卓越的可扩展性和通用性。我们的代码、模型和数据集将在 \url{https://github.com/lzw-lzw/UnifiedMLLM} 上提供。</paragraph>

##### **MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis**
2408.02714v1 by Dongwei Xu, Jiajun Chen, Yao Lu, Tianhao Xia, Qi Xuan, Wei Wang, Yun Lin, Xiaoniu Yang

Recently, deep learning technology has been successfully introduced into
Automatic Modulation Recognition (AMR) tasks. However, the success of deep
learning is all attributed to the training on large-scale datasets. Such a
large amount of data brings huge pressure on storage, transmission and model
training. In order to solve the problem of large amount of data, some
researchers put forward the method of data distillation, which aims to compress
large training data into smaller synthetic datasets to maintain its
performance. While numerous data distillation techniques have been developed
within the realm of image processing, the unique characteristics of signals set
them apart. Signals exhibit distinct features across various domains,
necessitating specialized approaches for their analysis and processing. To this
end, a novel dataset distillation method--Multi-domain Distribution Matching
(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to
translate timedomain signals into the frequency domain, and then uses a model
to compute distribution matching losses between the synthetic and real
datasets, considering both the time and frequency domains. Ultimately, these
two losses are integrated to update the synthetic dataset. We conduct extensive
experiments on three AMR datasets. Experimental results show that, compared
with baseline methods, our method achieves better performance under the same
compression ratio. Furthermore, we conduct crossarchitecture generalization
experiments on several models, and the experimental results show that our
synthetic datasets can generalize well on other unseen models.

摘要：<paragraph>近期，深度学习技术已成功引入到自动调制识别（AMR）任务中。然而，深度学习的成功都归功于在大规模数据集上的训练。如此大量的数据给存储、传输和模型训练带来了巨大的压力。为了解决数据量大的问题，一些研究者提出了数据蒸馏的方法，其目的是将大型训练数据压缩成更小的合成数据集，以保持其性能。虽然在图像处理领域已经开发出了许多数据蒸馏技术，但信号的独特特性使它们与众不同。信号在各个域中表现出不同的特征，需要专门的方法来对其进行分析和处理。为此，提出了一种新颖的数据集蒸馏方法——多域分布匹配（MDM）。MDM 采用离散傅里叶变换（DFT）将时域信号转换为频域，然后使用模型来计算合成数据集和真实数据集之间的分布匹配损失，同时考虑时域和频域。最终，这两个损失被集成起来更新合成数据集。我们在三个 AMR 数据集上进行了广泛的实验。实验结果表明，与基线方法相比，我们的方法在相同的压缩比下获得了更好的性能。此外，我们对几个模型进行了跨架构泛化实验，实验结果表明，我们的合成数据集可以在其他未见模型上很好地泛化。</paragraph>

##### **A First Look at License Compliance Capability of LLMs in Code Generation**
2408.02487v1 by Weiwei Xu, Kai Gao, Hao He, Minghui Zhou

Recent advances in Large Language Models (LLMs) have revolutionized code
generation, leading to widespread adoption of AI coding tools by developers.
However, LLMs can generate license-protected code without providing the
necessary license information, leading to potential intellectual property
violations during software production. This paper addresses the critical, yet
underexplored, issue of license compliance in LLM-generated code by
establishing a benchmark to evaluate the ability of LLMs to provide accurate
license information for their generated code. To establish this benchmark, we
conduct an empirical study to identify a reasonable standard for "striking
similarity" that excludes the possibility of independent creation, indicating a
copy relationship between the LLM output and certain open-source code. Based on
this standard, we propose an evaluation benchmark LiCoEval, to evaluate the
license compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular
LLMs, finding that even top-performing LLMs produce a non-negligible proportion
(0.88% to 2.01%) of code strikingly similar to existing open-source
implementations. Notably, most LLMs fail to provide accurate license
information, particularly for code under copyleft licenses. These findings
underscore the urgent need to enhance LLM compliance capabilities in code
generation tasks. Our study provides a foundation for future research and
development to improve license compliance in AI-assisted software development,
contributing to both the protection of open-source software copyrights and the
mitigation of legal risks for LLM users.

摘要：<paragraph>大型語言模型 (LLM) 的近期進展徹底改變了程式碼生成，導致開發人員廣泛採用 AI 編碼工具。然而，LLM 可以生成受許可證保護的程式碼，而沒有提供必要的許可證資訊，這會在軟體製作過程中導致潛在的智慧財產權侵權。本文探討 LLM 生成的程式碼中許可證合規性的關鍵議題（但尚未充分探討），方法是建立基準來評估 LLM 為其生成的程式碼提供準確許可證資訊的能力。為了建立這個基準，我們進行實證研究，以找出「極度相似」的合理標準，排除獨立創作的可能性，表示 LLM 輸出與特定開源程式碼之間的複製關係。基於這個標準，我們提出評估基準 LiCoEval，以評估 LLM 的許可證合規能力。使用 LiCoEval，我們評估了 14 個流行的 LLM，發現即使效能最好的 LLM 仍會產生與現有開源實作極度相似的程式碼，比例不可忽略（0.88% 至 2.01%）。值得注意的是，大多數 LLM 無法提供準確的許可證資訊，特別是受 copyleft 許可證保護的程式碼。這些發現強調了在程式碼生成任務中增強 LLM 合規能力的迫切需求。我們的研究為未來的研究和開發奠定了基礎，以改善 AI 輔助軟體開發中的許可證合規性，有助於保護開源軟體的著作權，並減輕 LLM 使用者的法律風險。</paragraph>

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

摘要：擴增實境 (AR) 具有透過讓外科醫生可視化患者體內關鍵結構來革新外科手術程序的潛力。這是透過將術前器官模型疊加到實際解剖結構上來實現的。手術過程中器官的動態變形帶來了挑戰，這使得術前模型不足以忠實地呈現術中解剖結構。為了在擴增手術中實現可靠的導航，對術中變形進行建模以獲得術前器官模型與術中解剖結構的準確對齊是不可或缺的。儘管存在各種用於建模術中器官變形的方法，但系統地對這些方法進行分類和總結的文獻回顧仍然很少。本綜述旨在通過提供對擴增實境手術中術中器官變形的建模方法的全面且技術導向的概述來填補這一空白。通過系統的搜尋和篩選過程，本綜述納入了 112 篇密切相關的論文。通過呈現器官變形建模方法的現狀及其臨床應用，本綜述旨在加深對 AR 引導手術中器官變形建模的理解，並探討未來進展的潛在主題。

##### **From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**
2408.02479v1 by Haolin Jin, Linghan Huang, Haipeng Cai, Jun Yan, Bo Li, Huaming Chen

With the rise of large language models (LLMs), researchers are increasingly
exploring their applications in var ious vertical domains, such as software
engineering. LLMs have achieved remarkable success in areas including code
generation and vulnerability detection. However, they also exhibit numerous
limitations and shortcomings. LLM-based agents, a novel tech nology with the
potential for Artificial General Intelligence (AGI), combine LLMs as the core
for decision-making and action-taking, addressing some of the inherent
limitations of LLMs such as lack of autonomy and self-improvement. Despite
numerous studies and surveys exploring the possibility of using LLMs in
software engineering, it lacks a clear distinction between LLMs and LLM based
agents. It is still in its early stage for a unified standard and benchmarking
to qualify an LLM solution as an LLM-based agent in its domain. In this survey,
we broadly investigate the current practice and solutions for LLMs and
LLM-based agents for software engineering. In particular we summarise six key
topics: requirement engineering, code generation, autonomous decision-making,
software design, test generation, and software maintenance. We review and
differentiate the work of LLMs and LLM-based agents from these six topics,
examining their differences and similarities in tasks, benchmarks, and
evaluation metrics. Finally, we discuss the models and benchmarks used,
providing a comprehensive analysis of their applications and effectiveness in
software engineering. We anticipate this work will shed some lights on pushing
the boundaries of LLM-based agents in software engineering for future research.

摘要：<paragraph>隨著大型語言模型 (LLM) 的興起，研究人員正越來越探索它們在各種垂直領域的應用，例如軟體工程。LLM 在包括程式碼生成和漏洞偵測等領域取得了顯著的成功。然而，它們也表現出許多限制和缺點。基於 LLM 的代理是一種新穎的技術，具有具備人工通用智慧 (AGI) 的潛力，結合 LLM 作為決策制定和採取行動的核心，解決了 LLM 的一些固有限制，例如缺乏自主性和自我完善。儘管有許多研究和調查探索在軟體工程中使用 LLM 的可能性，但它缺乏 LLM 和基於 LLM 的代理之間的明確區別。對於統一標準和基準以使其域中的 LLM 解决方案有資格成為基於 LLM 的代理，它仍處於早期階段。在本次調查中，我們廣泛調查了 LLM 和基於 LLM 的軟體工程代理的當前實務和解決方案。特別是，我們總結了六個關鍵主題：需求工程、程式碼生成、自主決策制定、軟體設計、測試生成和軟體維護。我們回顧並區分了 LLM 和基於 LLM 的代理在這六個主題中的工作，檢視它們在任務、基準和評估指標上的差異和相似性。最後，我們討論了所使用的模型和基準，全面分析了它們在軟體工程中的應用和有效性。我們預期這項工作將為推動基於 LLM 的代理在軟體工程中的界限提供一些啟示，以利未來的研究。</paragraph>

##### **Automatic Voice Identification after Speech Resynthesis using PPG**
2408.02712v1 by Thibault Gaudier, Marie Tahon, Anthony Larcher, Yannick Estève

Speech resynthesis is a generic task for which we want to synthesize audio
with another audio as input, which finds applications for media monitors and
journalists.Among different tasks addressed by speech resynthesis, voice
conversion preserves the linguistic information while modifying the identity of
the speaker, and speech edition preserves the identity of the speaker but some
words are modified.In both cases, we need to disentangle speaker and phonetic
contents in intermediate representations.Phonetic PosteriorGrams (PPG) are a
frame-level probabilistic representation of phonemes, and are usually
considered speaker-independent.This paper presents a PPG-based speech
resynthesis system.A perceptive evaluation assesses that it produces correct
audio quality.Then, we demonstrate that an automatic speaker verification model
is not able to recover the source speaker after re-synthesis with PPG, even
when the model is trained on synthetic data.

摘要：語音重合成是一項通用任務，我們希望使用其他音訊作為輸入來合成音訊，這在媒體監控和新聞記者中會有所應用。在語音重合成解決的不同任務中，語音轉換會保留語言資訊，同時修改說話者的身分，而語音編輯會保留說話者的身分，但會修改一些單字。這兩種情況下，我們都需要在中間表徵中解開說話者和語音內容。語音後部語法（PPG）是音素的框架層級機率表徵，通常被認為與說話者無關。本文提出了一個基於 PPG 的語音重合成系統。一個知覺評估評估它產生正確的音訊品質。然後，我們證明了一個自動說話者驗證模型無法在使用 PPG 重新合成後恢復來源說話者，即使該模型是在合成資料上訓練的。

##### **An investigation into the causes of race bias in AI-based cine CMR segmentation**
2408.02462v1 by Tiarna Lee, Esther Puyol-Anton, Bram Ruijsink, Sebastien Roujol, Theodore Barfoot, Shaheim Ogbomo-Harmitt, Miaojing Shi, Andrew P. King

Artificial intelligence (AI) methods are being used increasingly for the
automated segmentation of cine cardiac magnetic resonance (CMR) imaging.
However, these methods have been shown to be subject to race bias, i.e. they
exhibit different levels of performance for different races depending on the
(im)balance of the data used to train the AI model. In this paper we
investigate the source of this bias, seeking to understand its root cause(s) so
that it can be effectively mitigated. We perform a series of classification and
segmentation experiments on short-axis cine CMR images acquired from Black and
White subjects from the UK Biobank and apply AI interpretability methods to
understand the results. In the classification experiments, we found that race
can be predicted with high accuracy from the images alone, but less accurately
from ground truth segmentations, suggesting that the distributional shift
between races, which is often the cause of AI bias, is mostly image-based
rather than segmentation-based. The interpretability methods showed that most
attention in the classification models was focused on non-heart regions, such
as subcutaneous fat. Cropping the images tightly around the heart reduced
classification accuracy to around chance level. Similarly, race can be
predicted from the latent representations of a biased segmentation model,
suggesting that race information is encoded in the model. Cropping images
tightly around the heart reduced but did not eliminate segmentation bias. We
also investigate the influence of possible confounders on the bias observed.

摘要：人工智慧 (AI) 方法正日益用於自動分割心臟電影式磁振造影 (CMR) 影像。
然而，這些方法已被證明會受到種族偏見的影響，即根據用於訓練 AI 模型的資料的 (不) 平衡，它們對不同種族展現出不同層級的效能。在本文中，我們調查此偏見的來源，試圖了解其根本原因，以便能有效減輕它。我們對來自英國生物銀行的黑人和白人受試者所取得的短軸心臟電影式 CMR 影像執行一系列分類和分割實驗，並套用 AI 可解釋性方法來了解結果。在分類實驗中，我們發現僅從影像就能以高準確度預測種族，但從真實分割的準確度較低，這表示種族之間的分配轉移（通常是 AI 偏見的原因）主要是基於影像，而非基於分割。可解釋性方法顯示，分類模型中的大部分注意力都集中在非心臟區域，例如皮下脂肪。緊密裁剪影像以圍繞心臟會將分類準確度降低至接近隨機層級。同樣地，種族可以從有偏見的分割模型的潛在表示中預測，這表示種族資訊已編碼在模型中。緊密裁剪影像以圍繞心臟會降低分割偏見，但無法消除它。我們也調查可能混淆因子對所觀察到的偏見的影響。

##### **Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach**
2408.02456v1 by Wanxu Wei, Yitong Song, Bin Yao

Knowledge graphs (KGs) play a vital role in enhancing search results and
recommendation systems. With the rapid increase in the size of the KGs, they
are becoming inaccuracy and incomplete. This problem can be solved by the
knowledge graph completion methods, of which graph attention network
(GAT)-based methods stand out since their superior performance. However,
existing GAT-based knowledge graph completion methods often suffer from
overfitting issues when dealing with heterogeneous knowledge graphs, primarily
due to the unbalanced number of samples. Additionally, these methods
demonstrate poor performance in predicting the tail (head) entity that shares
the same relation and head (tail) entity with others. To solve these problems,
we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH
incorporates two separate attention network modules that work synergistically
to predict the missing entities. We also introduce novel encoding and feature
transformation approaches, enabling the robust performance of GATH in scenarios
with imbalanced samples. Comprehensive experiments are conducted to evaluate
the GATH's performance. Compared with the existing SOTA GAT-based model on
Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the
FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.

摘要：知識圖譜 (KG) 在提升搜尋結果和推薦系統中扮演著至關重要的角色。隨著 KG 規模的快速增長，它們正變得不準確且不完整。這個問題可以透過知識圖譜完成方法來解決，其中基於圖注意力網路 (GAT) 的方法因其卓越的效能而脫穎而出。然而，現有的基於 GAT 的知識圖譜完成方法在處理異質知識圖譜時，通常會遇到過度擬合的問題，這主要是由於樣本數不平衡所致。此外，這些方法在預測與他人共享相同關係和頭部 (尾部) 實體的尾部 (頭部) 實體時，表現不佳。為了解決這些問題，我們提出了 GATH，這是一種專為異質 KG 設計的創新 GAT 基礎方法。GATH 結合了兩個獨立的注意力網路模組，它們協同工作以預測缺失的實體。我們還引入了創新的編碼和特徵轉換方法，讓 GATH 在樣本不平衡的場景中能有穩健的表現。我們進行了全面的實驗來評估 GATH 的效能。與現有的 SOTA GAT 基礎模型在 Hits@10 和 MRR 指標上相比，我們的模型在 FB15K-237 資料集上分別提升了 5.2% 和 5.2% 的效能，在 WN18RR 資料集上分別提升了 4.5% 和 14.6%。

##### **Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion Models**
2408.02711v1 by Pushkar Jajoria, James McDermott

This study introduces a text-conditioned approach to generating drumbeats
with Latent Diffusion Models (LDMs). It uses informative conditioning text
extracted from training data filenames. By pretraining a text and drumbeat
encoder through contrastive learning within a multimodal network, aligned
following CLIP, we align the modalities of text and music closely.
Additionally, we examine an alternative text encoder based on multihot text
encodings. Inspired by musics multi-resolution nature, we propose a novel LSTM
variant, MultiResolutionLSTM, designed to operate at various resolutions
independently. In common with recent LDMs in the image space, it speeds up the
generation process by running diffusion in a latent space provided by a
pretrained unconditional autoencoder. We demonstrate the originality and
variety of the generated drumbeats by measuring distance (both over binary
pianorolls and in the latent space) versus the training dataset and among the
generated drumbeats. We also assess the generated drumbeats through a listening
test focused on questions of quality, aptness for the prompt text, and novelty.
We show that the generated drumbeats are novel and apt to the prompt text, and
comparable in quality to those created by human musicians.

摘要：本研究引入一種以文字為條件的方法，用潛在擴散模型 (LDM) 產生鼓點。它使用從訓練資料檔名中提取的資訊性條件文字。透過在多模態網路中使用對比學習預訓練文字和鼓點編碼器，並按照 CLIP 對齊，我們緊密對齊文字和音樂的模態。此外，我們探討一種基於多熱文字編碼的替代文字編碼器。受音樂的多解析度特性的啟發，我們提出一個新穎的 LSTM 變體 MultiResolutionLSTM，旨在獨立運作於各種解析度。與影像空間中最近的 LDM 相同，它透過在預訓練無條件自動編碼器提供的潛在空間中執行擴散來加速生成過程。我們透過測量距離（在二進制鋼琴捲軸和潛在空間中）相對於訓練資料集和生成的鼓點，來證明生成鼓點的獨創性和多樣性。我們還透過專注於品質、對提示文字的適當性和新穎性的聆聽測試評估生成的鼓點。我們展示生成的鼓點新穎且適於提示文字，並且品質與人類音樂家創作的鼓點相當。

##### **Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models**
2408.02442v1 by Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen

Structured generation, the process of producing content in standardized
formats like JSON and XML, is widely utilized in real-world applications to
extract key output information from large language models (LLMs). This study
investigates whether such constraints on generation space impact LLMs'
abilities, including reasoning and domain knowledge comprehension.
Specifically, we evaluate LLMs' performance when restricted to adhere to
structured formats versus generating free-form responses across various common
tasks. Surprisingly, we observe a significant decline in LLMs' reasoning
abilities under format restrictions. Furthermore, we find that stricter format
constraints generally lead to greater performance degradation in reasoning
tasks.

摘要：結構化生成，即以 JSON 和 XML 等標準化格式製作內容的過程，廣泛用於實際應用中，從大型語言模型 (LLM) 中提取關鍵輸出資訊。本研究探討此類生成空間限制是否會影響 LLM 的能力，包括推理和領域知識理解。具體來說，我們評估 LLM 在受限於遵循結構化格式與在各種常見任務中產生自由形式回應時的表現。令人驚訝的是，我們觀察到 LLM 在格式限制下的推理能力顯著下降。此外，我們發現更嚴格的格式限制通常會導致推理任務的效能更差。

##### **Long Input Benchmark for Russian Analysis**
2408.02439v1 by Igor Churin, Murat Apishev, Maria Tikhonova, Denis Shevelev, Aydar Bulatov, Yuri Kuratov, Sergej Averkiev, Alena Fenogenova

Recent advancements in Natural Language Processing (NLP) have fostered the
development of Large Language Models (LLMs) that can solve an immense variety
of tasks. One of the key aspects of their application is their ability to work
with long text documents and to process long sequences of tokens. This has
created a demand for proper evaluation of long-context understanding. To
address this need for the Russian language, we propose LIBRA (Long Input
Benchmark for Russian Analysis), which comprises 21 adapted datasets to study
the LLM's abilities to understand long texts thoroughly. The tests are divided
into four complexity groups and allow the evaluation of models across various
context lengths ranging from 4k up to 128k tokens. We provide the open-source
datasets, codebase, and public leaderboard for LIBRA to guide forthcoming
research.

摘要：自然語言處理 (NLP) 的最新進展促進了大型語言模型 (LLM) 的發展，它能解決各種各樣的任務。其應用的一個關鍵方面是它們處理長文本文件和處理長序列代幣的能力。這對長語境理解的適當評估產生了需求。為了滿足俄語的需求，我們提出了 LIBRA（俄語分析長輸入基準），它包含 21 個適用的數據集，用於研究 LLM 全面理解長文本的能力。測試分為四個複雜度組，並允許評估模型在從 4k 到 128k 代幣的各種語境長度。我們提供 LIBRA 的開源數據集、代碼庫和公開排行榜，以指導後續研究。

##### **Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation**
2408.02417v1 by Shutong Feng, Hsien-chin Lin, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Renato Vukovic, Milica Gašić

Emotions are indispensable in human communication, but are often overlooked
in task-oriented dialogue (ToD) modelling, where the task success is the
primary focus. While existing works have explored user emotions or similar
concepts in some ToD tasks, none has so far included emotion modelling into a
fully-fledged ToD system nor conducted interaction with human or simulated
users. In this work, we incorporate emotion into the complete ToD processing
loop, involving understanding, management, and generation. To this end, we
extend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour
labels. Through interactive experimentation involving both simulated and human
users, we demonstrate that our proposed framework significantly enhances the
user's emotional experience as well as the task success.

摘要：情緒在人類溝通中不可或缺，但在以任務為導向的對話 (ToD) 建模中卻經常被忽略，而任務成功是主要焦點。雖然現有研究已探討使用者情緒或類似概念在某些 ToD 任務中，但目前尚未將情緒建模納入一個成熟的 ToD 系統，也未與人類或模擬使用者進行互動。在這項研究中，我們將情緒納入完整的 ToD 處理迴圈，包括理解、管理和產生。為此，我們透過系統情感行為標籤延伸 EmoWOZ 資料集 (Feng 等人，2022)。透過涉及模擬和人類使用者的互動式實驗，我們證明我們提出的架構大幅提升使用者的情緒體驗以及任務成功。

##### **Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models**
2408.02416v1 by Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li

The drastic increase of large language models' (LLMs) parameters has led to a
new research direction of fine-tuning-free downstream customization by prompts,
i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)
play an important role in many businesses, there has emerged growing concerns
about the prompt leakage, which undermines the intellectual properties of these
services and causes downstream attacks. In this paper, we analyze the
underlying mechanism of prompt leakage, which we refer to as prompt
memorization, and develop corresponding defending strategies. By exploring the
scaling laws in prompt extraction, we analyze key attributes that influence
prompt extraction, including model sizes, prompt lengths, as well as the types
of prompts. Then we propose two hypotheses that explain how LLMs expose their
prompts. The first is attributed to the perplexity, i.e. the familiarity of
LLMs to texts, whereas the second is based on the straightforward token
translation path in attention matrices. To defend against such threats, we
investigate whether alignments can undermine the extraction of prompts. We find
that current LLMs, even those with safety alignments like GPT-4, are highly
vulnerable to prompt extraction attacks, even under the most straightforward
user attacks. Therefore, we put forward several defense strategies with the
inspiration of our findings, which achieve 83.8\% and 71.0\% drop in the prompt
extraction rate for Llama2-7B and GPT-3.5, respectively. Source code is
avaliable at \url{https://github.com/liangzid/PromptExtractionEval}.

摘要：<paragraph>大型語言模型 (LLM) 參數的急劇增加，導致了提示符進行微調自由下游自訂的新研究方向，即任務描述。雖然這些基於提示符的服務（例如 OpenAI 的 GPT）在許多企業中扮演著重要的角色，但對於提示符洩漏的擔憂與日俱增，這會破壞這些服務的智慧財產權並導致下游攻擊。在本文中，我們分析了提示符洩漏的底層機制，我們稱之為提示符記憶，並制定了相應的防禦策略。通過探索提示符提取中的規模定律，我們分析了影響提示符提取的關鍵屬性，包括模型大小、提示符長度以及提示符類型。然後，我們提出了兩個假設來解釋 LLM 如何公開其提示符。第一個歸因於困惑，即 LLM 對文本的熟悉度，而第二個則基於注意力矩陣中的直接代幣轉換路徑。為了防禦此類威脅，我們研究了對齊是否會破壞提示符的提取。我們發現當前的 LLM，即使是那些具有安全對齊功能（例如 GPT-4）的 LLM，也極易受到提示符提取攻擊，即使是在最直接的使用者攻擊下也是如此。因此，我們根據我們的發現提出了幾種防禦策略，這些策略分別為 Llama2-7B 和 GPT-3.5 的提示符提取率降低了 83.8% 和 71.0%。原始碼可於\url{https://github.com/liangzid/PromptExtractionEval}取得。</paragraph>

##### **Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models**
2408.02408v1 by Tongtong Feng, Qing Li, Xin Wang, Mingzi Wang, Guangyao Li, Wenwu Zhu

Cross-view geo-localization in GNSS-denied environments aims to determine an
unknown location by matching drone-view images with the correct geo-tagged
satellite-view images from a large gallery. Recent research shows that learning
discriminative image representations under specific weather conditions can
significantly enhance performance. However, the frequent occurrence of unseen
extreme weather conditions hinders progress. This paper introduces MCGF, a
Multi-weather Cross-view Geo-localization Framework designed to dynamically
adapt to unseen weather conditions. MCGF establishes a joint optimization
between image restoration and geo-localization using denoising diffusion
models. For image restoration, MCGF incorporates a shared encoder and a
lightweight restoration module to help the backbone eliminate weather-specific
information. For geo-localization, MCGF uses EVA-02 as a backbone for feature
extraction, with cross-entropy loss for training and cosine distance for
testing. Extensive experiments on University160k-WX demonstrate that MCGF
achieves competitive results for geo-localization in varying weather
conditions.

摘要：在 GNSS 拒絕的環境中進行跨視圖地理定位旨在通過將無人機視圖影像與來自大型圖庫的正確地理標記衛星視圖影像進行匹配來確定未知位置。最近的研究表明，在特定天氣條件下學習判別影像表徵可以顯著提高性能。然而，極端天氣條件的頻繁出現阻礙了進展。本文介紹了 MCGF，一個多天氣跨視圖地理定位框架，旨在動態適應未知天氣條件。MCGF 在影像修復和地理定位之間建立了聯合優化，使用去噪擴散模型。對於影像修復，MCGF 結合了一個共享編碼器和一個輕量級修復模組，以幫助主幹消除特定天氣資訊。對於地理定位，MCGF 使用 EVA-02 作為特徵提取的主幹，使用交叉熵損失進行訓練，使用餘弦距離進行測試。在 University160k-WX 上進行的大量實驗表明，MCGF 在不同的天氣條件下實現了地理定位的競爭結果。

##### **SnapE -- Training Snapshot Ensembles of Link Prediction Models**
2408.02707v1 by Ali Shaban, Heiko Paulheim

Snapshot ensembles have been widely used in various fields of prediction.
They allow for training an ensemble of prediction models at the cost of
training a single one. They are known to yield more robust predictions by
creating a set of diverse base models. In this paper, we introduce an approach
to transfer the idea of snapshot ensembles to link prediction models in
knowledge graphs. Moreover, since link prediction in knowledge graphs is a
setup without explicit negative examples, we propose a novel training loop that
iteratively creates negative examples using previous snapshot models. An
evaluation with four base models across four datasets shows that this approach
constantly outperforms the single model approach, while keeping the training
time constant.

摘要：快照合奏已广泛用于各种预测领域。
它们允许以训练单个模型的成本训练预测模型合奏。
众所周知，它们通过创建一组不同的基础模型来产生更稳健的预测。
在本文中，我们介绍了一种将快照合奏思想转移到知识图谱中链接预测模型的方法。
此外，由于知识图谱中的链接预测是一个没有明确负面示例的设置，我们提出了一个新颖的训练循环，
它使用以前的快照模型迭代创建负面示例。
对四个数据集上的四个基础模型的评估表明，这种方法始终优于单一模型方法，同时保持训练时间不变。

##### **Enhancing AI-based Generation of Software Exploits with Contextual Information**
2408.02402v2 by Pietro Liguori, Cristina Improta, Roberto Natella, Bojan Cukic, Domenico Cotroneo

This practical experience report explores Neural Machine Translation (NMT)
models' capability to generate offensive security code from natural language
(NL) descriptions, highlighting the significance of contextual understanding
and its impact on model performance. Our study employs a dataset comprising
real shellcodes to evaluate the models across various scenarios, including
missing information, necessary context, and unnecessary context. The
experiments are designed to assess the models' resilience against incomplete
descriptions, their proficiency in leveraging context for enhanced accuracy,
and their ability to discern irrelevant information. The findings reveal that
the introduction of contextual data significantly improves performance.
However, the benefits of additional context diminish beyond a certain point,
indicating an optimal level of contextual information for model training.
Moreover, the models demonstrate an ability to filter out unnecessary context,
maintaining high levels of accuracy in the generation of offensive security
code. This study paves the way for future research on optimizing context use in
AI-driven code generation, particularly for applications requiring a high
degree of technical precision such as the generation of offensive code.

摘要：這份實務經驗報告探討了神經機器翻譯 (NMT)
模型從自然語言 (NL) 描述產生攻擊性安全程式碼的能力，強調了脈絡理解的重要性
及其對模型效能的影響。我們的研究採用包含
真實 shellcode 的資料集，以評估模型在各種場景中的表現，包括
遺漏資訊、必要的脈絡和不必要的脈絡。這些
實驗旨在評估模型對不完整描述的韌性、它們在利用脈絡以提高準確度方面的熟練程度，
以及它們辨別不相關資訊的能力。研究結果顯示
脈絡資料的引入顯著提升了效能。然而，額外脈絡的好處在某個點之後會遞減，
指出模型訓練有最佳脈絡資訊量。此外，這些模型展現了過濾不必要脈絡的能力，
在產生攻擊性安全程式碼時維持高準確度。這項研究為未來在 AI 驅動程式碼產生中最佳化脈絡使用鋪路，特別是對於需要高
技術精準度的應用，例如產生攻擊性程式碼。

##### **A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**
2408.02377v1 by Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli

Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.

摘要：知識圖譜 (KG) 已成功應用於分析複雜的科學技術領域，自動 KG 生成方法通常建構於關係萃取模型上，捕捉文本中領域實體之間的細粒度關係。雖然這些關係完全適用於各科學領域，但現有模型是用 SciERC 等少數特定領域的資料集訓練，而且在新目標領域的表現不佳。在本論文中，我們嘗試利用大型語言模型的脈絡學習能力，執行受架構約束的資料標註，收集領域內訓練實例，用於部署在建築、營造、工程和營運 (AECO) 領域研究論文標題和摘要的基於 Transformer 的關係萃取模型。透過評估相對於在領域外資料上訓練的基準深度學習架構的效能提升，我們展示透過使用帶有結構化提示的少量學習策略，以及僅最少的專家標註，所提出的方法有可能支援科學 KG 生成模型的領域適應。

##### **Operationalizing Contextual Integrity in Privacy-Conscious Assistants**
2408.02373v1 by Sahra Ghalebikesabi, Eugene Bagdasaryan, Ren Yi, Itay Yona, Ilia Shumailov, Aneesh Pappu, Chongyang Shi, Laura Weidinger, Robert Stanforth, Leonard Berrada, Pushmeet Kohli, Po-Sen Huang, Borja Balle

Advanced AI assistants combine frontier LLMs and tool access to autonomously
perform complex tasks on behalf of users. While the helpfulness of such
assistants can increase dramatically with access to user information including
emails and documents, this raises privacy concerns about assistants sharing
inappropriate information with third parties without user supervision. To steer
information-sharing assistants to behave in accordance with privacy
expectations, we propose to operationalize $\textit{contextual integrity}$
(CI), a framework that equates privacy with the appropriate flow of information
in a given context. In particular, we design and evaluate a number of
strategies to steer assistants' information-sharing actions to be CI compliant.
Our evaluation is based on a novel form filling benchmark composed of synthetic
data and human annotations, and it reveals that prompting frontier LLMs to
perform CI-based reasoning yields strong results.

摘要：進階人工智慧助理結合前沿 LLM 與工具存取，以自動化執行複雜任務，代表使用者執行。雖然此類助理的便利性會隨著存取使用者資訊（包括電子郵件和文件）而大幅提升，但這也引發了隱私疑慮，擔心助理會在未經使用者監督的情況下，與第三方分享不適當的資訊。為了引導資訊共享助理，使其行為符合隱私期望，我們提議將「脈絡完整性」（CI）操作化，此架構將隱私與特定脈絡中適當的資訊流畫上等號。特別是，我們設計並評估多種策略，以引導助理的資訊共享行為，符合 CI 規範。我們的評估是基於由合成資料和人為註解組成的新穎表單填寫基準，結果顯示提示前沿 LLM 執行基於 CI 的推理，可產生強而有力的成果。

