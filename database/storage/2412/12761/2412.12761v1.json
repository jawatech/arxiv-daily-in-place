{"2412.12761": {"publish_time": "2024-12-17", "title": "Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection", "paper_summary": "In this paper, we reported our experiments with various strategies to improve\ncode-mixed humour and sarcasm detection. We did all of our experiments for\nHindi-English code-mixed scenario, as we have the linguistic expertise for the\nsame. We experimented with three approaches, namely (i) native sample mixing,\n(ii) multi-task learning (MTL), and (iii) prompting very large multilingual\nlanguage models (VMLMs). In native sample mixing, we added monolingual task\nsamples in code-mixed training sets. In MTL learning, we relied on native and\ncode-mixed samples of a semantically related task (hate detection in our case).\nFinally, in our third approach, we evaluated the efficacy of VMLMs via few-shot\ncontext prompting. Some interesting findings we got are (i) adding native\nsamples improved humor (raising the F1-score up to 6.76%) and sarcasm (raising\nthe F1-score up to 8.64%) detection, (ii) training MLMs in an MTL framework\nboosted performance for both humour (raising the F1-score up to 10.67%) and\nsarcasm (increment up to 12.35% in F1-score) detection, and (iii) prompting\nVMLMs couldn't outperform the other approaches. Finally, our ablation studies\nand error analysis discovered the cases where our model is yet to improve. We\nprovided our code for reproducibility.", "paper_summary_zh": "<paragraph>\u5728\u9019\u7bc7\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u5831\u544a\u4e86\u6211\u5011\u4f7f\u7528\u5404\u7a2e\u7b56\u7565\u4f86\u6539\u5584\u4ee3\u78bc\u6df7\u5408\u5e7d\u9ed8\u548c\u8af7\u523a\u5075\u6e2c\u7684\u5be6\u9a57\u3002\u6211\u5011\u5c0d\u5370\u5730\u8a9e-\u82f1\u8a9e\u4ee3\u78bc\u6df7\u5408\u5834\u666f\u9032\u884c\u4e86\u6240\u6709\u5be6\u9a57\uff0c\u56e0\u70ba\u6211\u5011\u64c1\u6709\u9019\u65b9\u9762\u7684\u8a9e\u8a00\u5c08\u696d\u77e5\u8b58\u3002\u6211\u5011\u5617\u8a66\u4e86\u4e09\u7a2e\u65b9\u6cd5\uff0c\u5206\u5225\u662f (i) \u539f\u751f\u6a23\u672c\u6df7\u5408\u3001(ii) \u591a\u4efb\u52d9\u5b78\u7fd2 (MTL) \u548c (iii) \u63d0\u793a\u975e\u5e38\u5927\u7684\u591a\u8a9e\u8a00\u8a9e\u8a00\u6a21\u578b (VMLM)\u3002\u5728\u539f\u751f\u6a23\u672c\u6df7\u5408\u4e2d\uff0c\u6211\u5011\u5728\u4ee3\u78bc\u6df7\u5408\u8a13\u7df4\u96c6\u4e2d\u6dfb\u52a0\u4e86\u55ae\u8a9e\u4efb\u52d9\u6a23\u672c\u3002\u5728 MTL \u5b78\u7fd2\u4e2d\uff0c\u6211\u5011\u4f9d\u8cf4\u65bc\u8a9e\u7fa9\u76f8\u95dc\u4efb\u52d9\uff08\u5728\u6211\u5011\u7684\u6848\u4f8b\u4e2d\u662f\u4ec7\u6068\u5075\u6e2c\uff09\u7684\u539f\u751f\u548c\u4ee3\u78bc\u6df7\u5408\u6a23\u672c\u3002\u6700\u5f8c\uff0c\u5728\u6211\u5011\u7684\u7b2c\u4e09\u7a2e\u65b9\u6cd5\u4e2d\uff0c\u6211\u5011\u901a\u904e\u5c11\u6b21\u63d0\u793a\u8a9e\u5883\u63d0\u793a\u8a55\u4f30\u4e86 VMLM \u7684\u529f\u6548\u3002\u6211\u5011\u7372\u5f97\u7684\u4e00\u4e9b\u6709\u8da3\u7684\u767c\u73fe\u662f (i) \u6dfb\u52a0\u539f\u751f\u6a23\u672c\u6539\u9032\u4e86\u5e7d\u9ed8\uff08\u5c07 F1 \u5206\u6578\u63d0\u9ad8\u5230 6.76%\uff09\u548c\u8af7\u523a\uff08\u5c07 F1 \u5206\u6578\u63d0\u9ad8\u5230 8.64%\uff09\u5075\u6e2c\uff0c(ii) \u5728 MTL \u6846\u67b6\u4e2d\u8a13\u7df4 MLM \u63d0\u5347\u4e86\u5e7d\u9ed8\uff08\u5c07 F1 \u5206\u6578\u63d0\u9ad8\u5230 10.67%\uff09\u548c\u8af7\u523a\uff08\u5c07 F1 \u5206\u6578\u63d0\u9ad8\u5230 12.35%\uff09\u5075\u6e2c\u7684\u6548\u80fd\uff0c\u4ee5\u53ca (iii) \u63d0\u793a VMLM \u7121\u6cd5\u512a\u65bc\u5176\u4ed6\u65b9\u6cd5\u3002\u6700\u5f8c\uff0c\u6211\u5011\u7684\u6d88\u878d\u7814\u7a76\u548c\u932f\u8aa4\u5206\u6790\u767c\u73fe\u4e86\u6211\u5011\u7684\u6a21\u578b\u5c1a\u672a\u6539\u9032\u7684\u6848\u4f8b\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u6211\u5011\u7684\u4ee3\u78bc\u4ee5\u4f9b\u91cd\u73fe\u3002</paragraph>", "author": "Debajyoti Mazumder et.al.", "authors": "Debajyoti Mazumder, Aakash Kumar, Jasabanta Patro", "id": "2412.12761v1", "paper_url": "http://arxiv.org/abs/2412.12761v1", "repo": "null"}}