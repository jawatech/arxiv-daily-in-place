{"2408.11227": {"publish_time": "2024-08-20", "title": "OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis", "paper_summary": "Optical coherence tomography (OCT) has become critical for diagnosing retinal\ndiseases as it enables 3D images of the retina and optic nerve. OCT acquisition\nis fast, non-invasive, affordable, and scalable. Due to its broad\napplicability, massive numbers of OCT images have been accumulated in routine\nexams, making it possible to train large-scale foundation models that can\ngeneralize to various diagnostic tasks using OCT images. Nevertheless, existing\nfoundation models for OCT only consider 2D image slices, overlooking the rich\n3D structure. Here, we present OCTCube, a 3D foundation model pre-trained on\n26,605 3D OCT volumes encompassing 1.62 million 2D OCT images. OCTCube is\ndeveloped based on 3D masked autoencoders and exploits FlashAttention to reduce\nthe larger GPU memory usage caused by modeling 3D volumes. OCTCube outperforms\n2D models when predicting 8 retinal diseases in both inductive and\ncross-dataset settings, indicating that utilizing the 3D structure in the model\ninstead of 2D data results in significant improvement. OCTCube further shows\nsuperior performance on cross-device prediction and when predicting systemic\ndiseases, such as diabetes and hypertension, further demonstrating its strong\ngeneralizability. Finally, we propose a\ncontrastive-self-supervised-learning-based OCT-IR pre-training framework (COIP)\nfor cross-modality analysis on OCT and infrared retinal (IR) images, where the\nOCT volumes are embedded using OCTCube. We demonstrate that COIP enables\naccurate alignment between OCT and IR en face images. Collectively, OCTCube, a\n3D OCT foundation model, demonstrates significantly better performance against\n2D models on 27 out of 29 tasks and comparable performance on the other two\ntasks, paving the way for AI-based retinal disease diagnosis.", "paper_summary_zh": "\u5149\u5b78\u76f8\u5e72\u65b7\u5c64\u6383\u63cf (OCT) \u5df2\u6210\u70ba\u8a3a\u65b7\u8996\u7db2\u819c\u75be\u75c5\u7684\u91cd\u8981\u5de5\u5177\uff0c\u56e0\u70ba\u5b83\u53ef\u4ee5\u63d0\u4f9b\u8996\u7db2\u819c\u548c\u8996\u795e\u7d93\u7684 3D \u5f71\u50cf\u3002OCT \u7372\u53d6\u5feb\u901f\u3001\u975e\u4fb5\u5165\u6027\u3001\u8ca0\u64d4\u5f97\u8d77\u4e14\u53ef\u64f4\u5145\u3002\u7531\u65bc\u5176\u5ee3\u6cdb\u7684\u9069\u7528\u6027\uff0c\u5927\u91cf OCT \u5f71\u50cf\u5df2\u5728\u4f8b\u884c\u6aa2\u67e5\u4e2d\u7d2f\u7a4d\uff0c\u4f7f\u5f97\u8a13\u7df4\u5927\u578b\u57fa\u790e\u6a21\u578b\u6210\u70ba\u53ef\u80fd\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528 OCT \u5f71\u50cf\u63a8\u5ee3\u5230\u5404\u7a2e\u8a3a\u65b7\u4efb\u52d9\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u73fe\u6709\u7684 OCT \u57fa\u790e\u6a21\u578b\u53ea\u8003\u616e 2D \u5f71\u50cf\u5207\u7247\uff0c\u5ffd\u7565\u4e86\u8c50\u5bcc\u7684 3D \u7d50\u69cb\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa OCTCube\uff0c\u9019\u662f\u4e00\u500b 3D \u57fa\u790e\u6a21\u578b\uff0c\u9810\u5148\u8a13\u7df4\u65bc 26,605 \u500b 3D OCT \u9ad4\u7a4d\uff0c\u5305\u542b 162 \u842c\u500b 2D OCT \u5f71\u50cf\u3002OCTCube \u662f\u57fa\u65bc 3D \u8499\u7248\u81ea\u52d5\u7de8\u78bc\u5668\u958b\u767c\u7684\uff0c\u4e26\u5229\u7528 FlashAttention \u4f86\u6e1b\u5c11\u5efa\u6a21 3D \u9ad4\u7a4d\u6240\u9020\u6210\u7684\u8f03\u5927 GPU \u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u3002OCTCube \u5728\u9810\u6e2c 8 \u7a2e\u8996\u7db2\u819c\u75be\u75c5\u6642\u512a\u65bc 2D \u6a21\u578b\uff0c\u7121\u8ad6\u662f\u5728\u6b78\u7d0d\u5f0f\u9084\u662f\u8de8\u8cc7\u6599\u96c6\u8a2d\u5b9a\u4e2d\uff0c\u9019\u8868\u793a\u5728\u6a21\u578b\u4e2d\u4f7f\u7528 3D \u7d50\u69cb\uff0c\u800c\u4e0d\u662f 2D \u8cc7\u6599\uff0c\u6703\u5e36\u4f86\u986f\u8457\u7684\u6539\u9032\u3002OCTCube \u5728\u8de8\u88dd\u7f6e\u9810\u6e2c\u548c\u9810\u6e2c\u5168\u8eab\u6027\u75be\u75c5\uff08\u4f8b\u5982\u7cd6\u5c3f\u75c5\u548c\u9ad8\u8840\u58d3\uff09\u6642\u9032\u4e00\u6b65\u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u5176\u5f37\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5c0d\u6bd4\u81ea\u76e3\u7763\u5b78\u7fd2\u7684 OCT-IR \u9810\u8a13\u7df4\u67b6\u69cb (COIP)\uff0c\u7528\u65bc OCT \u548c\u7d05\u5916\u7dda\u8996\u7db2\u819c (IR) \u5f71\u50cf\u7684\u8de8\u6a21\u614b\u5206\u6790\uff0c\u5176\u4e2d OCT \u9ad4\u7a4d\u4f7f\u7528 OCTCube \u5d4c\u5165\u3002\u6211\u5011\u8b49\u660e COIP \u80fd\u5920\u5728 OCT \u548c IR \u6b63\u9762\u5f71\u50cf\u4e4b\u9593\u9032\u884c\u6e96\u78ba\u7684\u5c0d\u9f4a\u3002\u7e3d\u7684\u4f86\u8aaa\uff0cOCTCube \u662f\u4e00\u500b 3D OCT \u57fa\u790e\u6a21\u578b\uff0c\u5728 29 \u9805\u4efb\u52d9\u4e2d\u7684 27 \u9805\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u660e\u986f\u512a\u65bc 2D \u6a21\u578b\u7684\u6548\u80fd\uff0c\u800c\u5728\u5176\u4ed6\u5169\u9805\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u76f8\u7576\u7684\u6548\u80fd\uff0c\u70ba\u57fa\u65bc AI \u7684\u8996\u7db2\u819c\u75be\u75c5\u8a3a\u65b7\u92ea\u8def\u3002", "author": "Zixuan Liu et.al.", "authors": "Zixuan Liu, Hanwen Xu, Addie Woicik, Linda G. Shapiro, Marian Blazes, Yue Wu, Cecilia S. Lee, Aaron Y. Lee, Sheng Wang", "id": "2408.11227v1", "paper_url": "http://arxiv.org/abs/2408.11227v1", "repo": "null"}}