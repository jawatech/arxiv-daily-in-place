{"2405.19266": {"publish_time": "2024-05-29", "title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications", "paper_summary": "Developing intelligent pediatric consultation systems offers promising\nprospects for improving diagnostic efficiency, especially in China, where\nhealthcare resources are scarce. Despite recent advances in Large Language\nModels (LLMs) for Chinese medicine, their performance is sub-optimal in\npediatric applications due to inadequate instruction data and vulnerable\ntraining procedures. To address the above issues, this paper builds PedCorpus,\na high-quality dataset of over 300,000 multi-task instructions from pediatric\ntextbooks, guidelines, and knowledge graph resources to fulfil diverse\ndiagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the\nfirst Chinese pediatric LLM assistant built on a systematic and robust training\npipeline. In the continuous pre-training phase, we introduce a hybrid\ninstruction pre-training mechanism to mitigate the internal-injected knowledge\ninconsistency of LLMs for medical domain adaptation. Immediately, the\nfull-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the\ngeneral medical knowledge schema into the models. After that, we devise a\ndirect following preference optimization to enhance the generation of\npediatrician-like humanistic responses. In the parameter-efficient secondary\nSFT phase, a mixture of universal-specific experts strategy is presented to\nresolve the competency conflict between medical generalist and pediatric\nexpertise mastery. Extensive results based on the metrics, GPT-4, and doctor\nevaluations on distinct doctor downstream tasks show that PediatricsGPT\nconsistently outperforms previous Chinese medical LLMs. Our model and dataset\nwill be open-source for community development.", "paper_summary_zh": "<paragraph>\u958b\u767c\u667a\u80fd\u5152\u7ae5\u8aee\u8a62\u7cfb\u7d71\uff0c\u70ba\u63d0\u9ad8\u8a3a\u65b7\u6548\u7387\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u524d\u666f\uff0c\u7279\u5225\u662f\u5728\u91ab\u7642\u8cc7\u6e90\u7a00\u7f3a\u7684\u4e2d\u570b\u3002\u5118\u7ba1\u4e2d\u6587\u91ab\u5b78\u7684\u5927\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u6700\u8fd1\u53d6\u5f97\u9032\u5c55\uff0c\u4f46\u7531\u65bc\u6559\u5b78\u8cc7\u6599\u4e0d\u8db3\u548c\u57f9\u8a13\u7a0b\u5e8f\u8106\u5f31\uff0c\u5b83\u5011\u5728\u5152\u79d1\u61c9\u7528\u4e2d\u7684\u8868\u73fe\u4e26\u975e\u6700\u4f73\u3002\u70ba\u4e86\u89e3\u6c7a\u4e0a\u8ff0\u554f\u984c\uff0c\u672c\u6587\u69cb\u5efa\u4e86 PedCorpus\uff0c\u4e00\u500b\u7531\u8d85\u904e 30 \u842c\u689d\u4f86\u81ea\u5152\u79d1\u6559\u79d1\u66f8\u3001\u6307\u5357\u548c\u77e5\u8b58\u5716\u8b5c\u8cc7\u6e90\u7684\u591a\u4efb\u52d9\u6307\u4ee4\u7d44\u6210\u7684\u512a\u8cea\u6578\u64da\u96c6\uff0c\u4ee5\u6eff\u8db3\u4e0d\u540c\u7684\u8a3a\u65b7\u9700\u6c42\u3002\u5728\u8a2d\u8a08\u826f\u597d\u7684 PedCorpus \u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e86 PediatricsGPT\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5efa\u7acb\u5728\u7cfb\u7d71\u4e14\u5f37\u5927\u7684\u8a13\u7df4\u7ba1\u9053\u4e0a\u7684\u4e2d\u6587\u5152\u79d1 LLM \u52a9\u624b\u3002\u5728\u6301\u7e8c\u7684\u9810\u8a13\u7df4\u968e\u6bb5\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u6df7\u5408\u6307\u4ee4\u9810\u8a13\u7df4\u6a5f\u5236\uff0c\u4ee5\u6e1b\u8f15 LLM \u5728\u91ab\u5b78\u9818\u57df\u9069\u61c9\u4e2d\u7684\u5167\u90e8\u6ce8\u5165\u77e5\u8b58\u4e0d\u4e00\u81f4\u3002\u7dca\u63a5\u8457\uff0c\u5229\u7528\u5168\u53c3\u6578\u76e3\u7763\u5fae\u8abf\uff08SFT\uff09\u5c07\u4e00\u822c\u91ab\u5b78\u77e5\u8b58\u67b6\u69cb\u7d0d\u5165\u6a21\u578b\u4e2d\u3002\u5728\u90a3\u4e4b\u5f8c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u76f4\u63a5\u9075\u5faa\u504f\u597d\u6700\u4f73\u5316\uff0c\u4ee5\u589e\u5f37\u985e\u5152\u79d1\u91ab\u751f\u7684\u4eba\u6587\u53cd\u61c9\u751f\u6210\u3002\u5728\u53c3\u6578\u6548\u7387\u7684\u6b21\u8981 SFT \u968e\u6bb5\uff0c\u63d0\u51fa\u4e86\u4e00\u500b\u901a\u7528\u7279\u5b9a\u5c08\u5bb6\u7b56\u7565\u7684\u6df7\u5408\uff0c\u4ee5\u89e3\u6c7a\u5167\u79d1\u91ab\u751f\u548c\u5152\u79d1\u5c08\u696d\u638c\u63e1\u4e4b\u9593\u7684\u80fd\u529b\u885d\u7a81\u3002\u57fa\u65bc\u6307\u6a19\u3001GPT-4 \u548c\u91ab\u751f\u5c0d\u4e0d\u540c\u91ab\u751f\u4e0b\u6e38\u4efb\u52d9\u7684\u8a55\u4f30\u7684\u5ee3\u6cdb\u7d50\u679c\u8868\u660e\uff0cPediatricsGPT \u6301\u7e8c\u512a\u65bc\u5148\u524d\u7684\u4e2d\u6587\u91ab\u5b78 LLM\u3002\u6211\u5011\u7684\u6a21\u578b\u548c\u6578\u64da\u96c6\u5c07\u5c0d\u793e\u7fa4\u958b\u767c\u958b\u653e\u539f\u59cb\u78bc\u3002</paragraph>", "author": "Dingkang Yang et.al.", "authors": "Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang", "id": "2405.19266v1", "paper_url": "http://arxiv.org/abs/2405.19266v1", "repo": "null"}}