{"2412.09991": {"publish_time": "2024-12-13", "title": "Visual Object Tracking across Diverse Data Modalities: A Review", "paper_summary": "Visual Object Tracking (VOT) is an attractive and significant research area\nin computer vision, which aims to recognize and track specific targets in video\nsequences where the target objects are arbitrary and class-agnostic. The VOT\ntechnology could be applied in various scenarios, processing data of diverse\nmodalities such as RGB, thermal infrared and point cloud. Besides, since no one\nsensor could handle all the dynamic and varying environments, multi-modal VOT\nis also investigated. This paper presents a comprehensive survey of the recent\nprogress of both single-modal and multi-modal VOT, especially the deep learning\nmethods. Specifically, we first review three types of mainstream single-modal\nVOT, including RGB, thermal infrared and point cloud tracking. In particular,\nwe conclude four widely-used single-modal frameworks, abstracting their schemas\nand categorizing the existing inheritors. Then we summarize four kinds of\nmulti-modal VOT, including RGB-Depth, RGB-Thermal, RGB-LiDAR and RGB-Language.\nMoreover, the comparison results in plenty of VOT benchmarks of the discussed\nmodalities are presented. Finally, we provide recommendations and insightful\nobservations, inspiring the future development of this fast-growing literature.", "paper_summary_zh": "\u8996\u89ba\u7269\u4ef6\u8ffd\u8e64 (VOT) \u662f\u96fb\u8166\u8996\u89ba\u4e2d\u4e00\u500b\u6709\u5438\u5f15\u529b\u4e14\u91cd\u8981\u7684\u7814\u7a76\u9818\u57df\uff0c\u5176\u76ee\u6a19\u662f\u8b58\u5225\u4e26\u8ffd\u8e64\u5f71\u7247\u5e8f\u5217\u4e2d\u7279\u5b9a\u7684\u76ee\u6a19\uff0c\u5176\u4e2d\u76ee\u6a19\u7269\u4ef6\u662f\u4efb\u610f\u7684\u4e14\u8207\u985e\u5225\u7121\u95dc\u3002VOT \u6280\u8853\u53ef\u61c9\u7528\u65bc\u5404\u7a2e\u5834\u666f\uff0c\u8655\u7406\u5404\u7a2e\u6a21\u5f0f\u7684\u8cc7\u6599\uff0c\u4f8b\u5982 RGB\u3001\u71b1\u7d05\u5916\u7dda\u548c\u9ede\u96f2\u3002\u6b64\u5916\uff0c\u7531\u65bc\u6c92\u6709\u4efb\u4f55\u4e00\u7a2e\u611f\u6e2c\u5668\u53ef\u4ee5\u8655\u7406\u6240\u6709\u52d5\u614b\u4e14\u591a\u8b8a\u7684\u74b0\u5883\uff0c\u56e0\u6b64\u591a\u6a21\u5f0f VOT \u4e5f\u5728\u7814\u7a76\u4e2d\u3002\u672c\u6587\u63d0\u4f9b\u4e86\u55ae\u6a21\u5f0f\u548c\u591a\u6a21\u5f0f VOT \u6700\u8fd1\u9032\u5c55\u7684\u5168\u9762\u8abf\u67e5\uff0c\u7279\u5225\u662f\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u56de\u9867\u4e86\u4e09\u7a2e\u985e\u578b\u7684\u4e3b\u6d41\u55ae\u6a21\u5f0f VOT\uff0c\u5305\u62ec RGB\u3001\u71b1\u7d05\u5916\u7dda\u548c\u9ede\u96f2\u8ffd\u8e64\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u7e3d\u7d50\u4e86\u56db\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u55ae\u6a21\u5f0f\u67b6\u69cb\uff0c\u62bd\u8c61\u5176\u67b6\u69cb\u4e26\u5206\u985e\u73fe\u6709\u7684\u7e7c\u627f\u8005\u3002\u7136\u5f8c\uff0c\u6211\u5011\u7e3d\u7d50\u4e86\u56db\u7a2e\u985e\u578b\u7684\u591a\u6a21\u5f0f VOT\uff0c\u5305\u62ec RGB-\u6df1\u5ea6\u3001RGB-\u71b1\u3001RGB-LiDAR \u548c RGB-\u8a9e\u8a00\u3002\u6b64\u5916\uff0c\u9084\u63d0\u4f9b\u4e86\u5728\u5927\u91cf VOT \u57fa\u6e96\u4e2d\u8a0e\u8ad6\u6a21\u5f0f\u7684\u6bd4\u8f03\u7d50\u679c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u5efa\u8b70\u548c\u6709\u898b\u5730\u7684\u89c0\u5bdf\uff0c\u6fc0\u52f5\u4e86\u9019\u500b\u5feb\u901f\u6210\u9577\u7684\u9818\u57df\u7684\u672a\u4f86\u767c\u5c55\u3002", "author": "Mengmeng Wang et.al.", "authors": "Mengmeng Wang, Teli Ma, Shuo Xin, Xiaojun Hou, Jiazheng Xing, Guang Dai, Jingdong Wang, Yong Liu", "id": "2412.09991v1", "paper_url": "http://arxiv.org/abs/2412.09991v1", "repo": "null"}}