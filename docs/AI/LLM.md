
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-13**|**Theoretical Benefit and Limitation of Diffusion Language Model**|Guhao Feng et.al.|[2502.09622v1](http://arxiv.org/abs/2502.09622v1)|null|
|**2025-02-13**|**MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency**|Dongzhi Jiang et.al.|[2502.09621v1](http://arxiv.org/abs/2502.09621v1)|null|
|**2025-02-13**|**Exploring the Potential of Encoder-free Architectures in 3D LMMs**|Yiwen Tang et.al.|[2502.09620v1](http://arxiv.org/abs/2502.09620v1)|null|
|**2025-02-13**|**DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References**|Xueyi Liu et.al.|[2502.09614v1](http://arxiv.org/abs/2502.09614v1)|null|
|**2025-02-13**|**Score-of-Mixture Training: Training One-Step Generative Models Made Simple**|Tejas Jayashankar et.al.|[2502.09609v1](http://arxiv.org/abs/2502.09609v1)|null|
|**2025-02-13**|**Human-LLM Coevolution: Evidence from Academic Writing**|Mingmeng Geng et.al.|[2502.09606v1](http://arxiv.org/abs/2502.09606v1)|null|
|**2025-02-13**|**SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models**|Yung-Sung Chuang et.al.|[2502.09604v1](http://arxiv.org/abs/2502.09604v1)|null|
|**2025-02-13**|**CoT-Valve: Length-Compressible Chain-of-Thought Tuning**|Xinyin Ma et.al.|[2502.09601v1](http://arxiv.org/abs/2502.09601v1)|null|
|**2025-02-13**|**Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs**|Siyan Zhao et.al.|[2502.09597v1](http://arxiv.org/abs/2502.09597v1)|null|
|**2025-02-13**|**KIMAs: A Configurable Knowledge Integrated Multi-Agent System**|Zitao Li et.al.|[2502.09596v1](http://arxiv.org/abs/2502.09596v1)|null|
|**2025-02-13**|**Logical forms complement probability in understanding language model (and human) performance**|Yixuan Wang et.al.|[2502.09589v1](http://arxiv.org/abs/2502.09589v1)|null|
|**2025-02-13**|**Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering**|Mark Beliaev et.al.|[2502.09573v1](http://arxiv.org/abs/2502.09573v1)|null|
|**2025-02-13**|**MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing**|Vlad Andrei Negru et.al.|[2502.09567v1](http://arxiv.org/abs/2502.09567v1)|null|
|**2025-02-13**|**Zero-shot generation of synthetic neurosurgical data with large language models**|Austin A. Barr et.al.|[2502.09566v1](http://arxiv.org/abs/2502.09566v1)|null|
|**2025-02-13**|**MDCrow: Automating Molecular Dynamics Workflows with Large Language Models**|Quintina Campbell et.al.|[2502.09565v1](http://arxiv.org/abs/2502.09565v1)|null|
|**2025-02-13**|**EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents**|Rui Yang et.al.|[2502.09560v1](http://arxiv.org/abs/2502.09560v1)|null|
|**2025-02-13**|**Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages**|Shreyan Biswas et.al.|[2502.09532v1](http://arxiv.org/abs/2502.09532v1)|null|
|**2025-02-13**|**Diffusion Models for Molecules: A Survey of Methods and Tasks**|Liang Wang et.al.|[2502.09511v1](http://arxiv.org/abs/2502.09511v1)|null|
|**2025-02-13**|**AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization**|Caleb Cranney et.al.|[2502.09503v1](http://arxiv.org/abs/2502.09503v1)|null|
|**2025-02-13**|**Improve LLM-based Automatic Essay Scoring with Linguistic Features**|Zhaoyi Joey Hou et.al.|[2502.09497v1](http://arxiv.org/abs/2502.09497v1)|null|
|**2025-02-13**|**Cracking the Code: Enhancing Development finance understanding with artificial intelligence**|Pierre Beaucoral et.al.|[2502.09495v1](http://arxiv.org/abs/2502.09495v1)|null|
|**2025-02-13**|**Objective quantification of mood states using large language models**|Jakub Onysk et.al.|[2502.09487v1](http://arxiv.org/abs/2502.09487v1)|null|
|**2025-02-13**|**The Multilingual Mind : A Survey of Multilingual Reasoning in Language Models**|Akash Ghosh et.al.|[2502.09457v1](http://arxiv.org/abs/2502.09457v1)|null|
|**2025-02-13**|**Pixel-Level Reasoning Segmentation via Multi-turn Conversations**|Dexian Cai et.al.|[2502.09447v1](http://arxiv.org/abs/2502.09447v1)|null|
|**2025-02-13**|**Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes**|Navdeep Kumar et.al.|[2502.09432v1](http://arxiv.org/abs/2502.09432v1)|null|
|**2025-02-13**|**Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction**|Ziyi Chen et.al.|[2502.09423v1](http://arxiv.org/abs/2502.09423v1)|null|
|**2025-02-13**|**On multi-token prediction for efficient LLM inference**|Somesh Mehra et.al.|[2502.09419v1](http://arxiv.org/abs/2502.09419v1)|null|
|**2025-02-13**|**SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models**|Daniel Fleischer et.al.|[2502.09390v1](http://arxiv.org/abs/2502.09390v1)|null|
|**2025-02-13**|**Truth Knows No Language: Evaluating Truthfulness Beyond English**|Blanca Calvo Figueras et.al.|[2502.09387v1](http://arxiv.org/abs/2502.09387v1)|null|
|**2025-02-13**|**A Deep Inverse-Mapping Model for a Flapping Robotic Wing**|Hadar Sharvit et.al.|[2502.09378v1](http://arxiv.org/abs/2502.09378v1)|null|
|**2025-02-13**|**Language Agents as Digital Representatives in Collective Decision-Making**|Daniel Jarrett et.al.|[2502.09369v1](http://arxiv.org/abs/2502.09369v1)|null|
|**2025-02-13**|**Neural Spatiotemporal Point Processes: Trends and Challenges**|Sumantrak Mukherjee et.al.|[2502.09341v1](http://arxiv.org/abs/2502.09341v1)|null|
|**2025-02-13**|**Graph Diffusion Network for Drug-Gene Prediction**|Jiayang Wu et.al.|[2502.09335v1](http://arxiv.org/abs/2502.09335v1)|null|
|**2025-02-13**|**Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs**|Itai Mondshine et.al.|[2502.09331v1](http://arxiv.org/abs/2502.09331v1)|null|
|**2025-02-13**|**A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis**|Kentaro Imajo et.al.|[2502.09316v1](http://arxiv.org/abs/2502.09316v1)|null|
|**2025-02-13**|**When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models**|Samuel Joseph Amouyal et.al.|[2502.09307v1](http://arxiv.org/abs/2502.09307v1)|null|
|**2025-02-13**|**Indeterminacy in Affective Computing: Considering Meaning and Context in Data Collection Practices**|Bernd Dudzik et.al.|[2502.09294v1](http://arxiv.org/abs/2502.09294v1)|null|
|**2025-02-13**|**SparQLe: Speech Queries to Text Translation Through LLMs**|Amirbek Djanibekov et.al.|[2502.09284v1](http://arxiv.org/abs/2502.09284v1)|null|
|**2025-02-13**|**LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection**|Wenlun Zhang et.al.|[2502.09271v1](http://arxiv.org/abs/2502.09271v1)|null|
|**2025-02-13**|**AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection**|Hezhe Qiao et.al.|[2502.09254v1](http://arxiv.org/abs/2502.09254v1)|null|
|**2025-02-13**|**The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**|Danni Feng et.al.|[2502.09247v1](http://arxiv.org/abs/2502.09247v1)|null|
|**2025-02-13**|**You Do Not Fully Utilize Transformer's Representation Capacity**|Gleb Gerasimov et.al.|[2502.09245v1](http://arxiv.org/abs/2502.09245v1)|null|
|**2025-02-13**|**From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**|Lukas Buess et.al.|[2502.09242v1](http://arxiv.org/abs/2502.09242v1)|null|
|**2025-02-13**|**Reliable Conversational Agents under ASP Control that Understand Natural Language**|Yankai Zeng et.al.|[2502.09237v1](http://arxiv.org/abs/2502.09237v1)|null|
|**2025-02-13**|**Commonsense Reasoning-Aided Autonomous Vehicle Systems**|Keegan Kimbrell et.al.|[2502.09233v1](http://arxiv.org/abs/2502.09233v1)|null|
|**2025-02-13**|**Logical foundations of Smart Contracts**|Kalonji Kalala et.al.|[2502.09232v1](http://arxiv.org/abs/2502.09232v1)|null|
|**2025-02-13**|**Relating Answer Set Programming and Many-sorted Logics for Formal Verification**|Zachary Hansen et.al.|[2502.09230v1](http://arxiv.org/abs/2502.09230v1)|null|
|**2025-02-13**|**Computational methods for Dynamic Answer Set Programming**|Susana Hahn et.al.|[2502.09228v1](http://arxiv.org/abs/2502.09228v1)|null|
|**2025-02-13**|**Generating Causally Compliant Counterfactual Explanations using ASP**|Sopam Dasgupta et.al.|[2502.09226v1](http://arxiv.org/abs/2502.09226v1)|null|
|**2025-02-13**|**Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts**|Đorđe Marković et.al.|[2502.09224v1](http://arxiv.org/abs/2502.09224v1)|null|
|**2025-02-13**|**ASP-driven User-interaction with Clinguin**|Alexander Beiser et.al.|[2502.09222v1](http://arxiv.org/abs/2502.09222v1)|null|
|**2025-02-13**|**Pearce's Characterisation in an Epistemic Domain**|Ezgi Iraz Su et.al.|[2502.09221v1](http://arxiv.org/abs/2502.09221v1)|null|
|**2025-02-13**|**Graphical Conditions for the Existence, Unicity and Number of Regular Models**|Van-Giang Trinh et.al.|[2502.09220v1](http://arxiv.org/abs/2502.09220v1)|null|
|**2025-02-13**|**Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**|Flavio Bertini et.al.|[2502.09218v1](http://arxiv.org/abs/2502.09218v1)|null|
|**2025-02-13**|**Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for Autonomous Vehicles**|Galileo Sartor et.al.|[2502.09216v1](http://arxiv.org/abs/2502.09216v1)|null|
|**2025-02-13**|**Architecture for Simulating Behavior Mode Changes in Norm-Aware Autonomous Agents**|Sean Glaze et.al.|[2502.09215v1](http://arxiv.org/abs/2502.09215v1)|null|
|**2025-02-13**|**Neuro-Symbolic Contrastive Learning for Cross-domain Inference**|Mingyue Liu et.al.|[2502.09213v1](http://arxiv.org/abs/2502.09213v1)|null|
|**2025-02-13**|**LP-LM: No Hallucinations in Question Answering with Logic Programming**|Katherine Wu et.al.|[2502.09212v1](http://arxiv.org/abs/2502.09212v1)|null|
|**2025-02-13**|**Visual Graph Question Answering with ASP and LLMs for Language Parsing**|Jakob Johannes Bauer et.al.|[2502.09211v1](http://arxiv.org/abs/2502.09211v1)|null|
|**2025-02-13**|**On LLM-generated Logic Programs and their Inference Execution Methods**|Paul Tarau et.al.|[2502.09209v1](http://arxiv.org/abs/2502.09209v1)|null|
|**2025-02-13**|**Efficient OWL2QL Meta-reasoning Using ASP-based Hybrid Knowledge Bases**|Haya Majid Qureshi et.al.|[2502.09206v1](http://arxiv.org/abs/2502.09206v1)|null|
|**2025-02-13**|**Counterfactual Explanations as Plans**|Vaishak Belle et.al.|[2502.09205v1](http://arxiv.org/abs/2502.09205v1)|null|
|**2025-02-13**|**Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**|Sanskar Sehgal et.al.|[2502.09204v1](http://arxiv.org/abs/2502.09204v1)|null|
|**2025-02-13**|**Thinking beyond the anthropomorphic paradigm benefits LLM research**|Lujain Ibrahim et.al.|[2502.09192v1](http://arxiv.org/abs/2502.09192v1)|null|
|**2025-02-13**|**Matina: A Large-Scale 73B Token Persian Text Corpus**|Sara Bourbour Hosseinbeigi et.al.|[2502.09188v1](http://arxiv.org/abs/2502.09188v1)|null|
|**2025-02-13**|**RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation**|Changzhi Zhou et.al.|[2502.09183v1](http://arxiv.org/abs/2502.09183v1)|null|
|**2025-02-13**|**FLAME: Flexible LLM-Assisted Moderation Engine**|Ivan Bakulin et.al.|[2502.09175v1](http://arxiv.org/abs/2502.09175v1)|null|
|**2025-02-13**|**Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**|Jin Cui et.al.|[2502.09173v1](http://arxiv.org/abs/2502.09173v1)|null|
|**2025-02-13**|**Musical Heritage Historical Entity Linking**|Arianna Graciotti et.al.|[2502.09168v1](http://arxiv.org/abs/2502.09168v1)|null|
|**2025-02-13**|**Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs**|Chang Liu et.al.|[2502.09156v1](http://arxiv.org/abs/2502.09156v1)|null|
|**2025-02-13**|**A Novel Dialect-Aware Framework for the Classification of Arabic Dialects and Emotions**|Nasser A Alsadhan et.al.|[2502.09128v1](http://arxiv.org/abs/2502.09128v1)|null|
|**2025-02-13**|**Automatic Pruning via Structured Lasso with Class-wise Information**|Xiang Liu et.al.|[2502.09125v1](http://arxiv.org/abs/2502.09125v1)|null|
|**2025-02-13**|**The influence of visual and linguistic cues on ignorance inference in Vision-Language Models (VLMs)**|Ye-eun Cho et.al.|[2502.09120v1](http://arxiv.org/abs/2502.09120v1)|null|
|**2025-02-13**|**One-shot Federated Learning Methods: A Practical Guide**|Xiang Liu et.al.|[2502.09104v1](http://arxiv.org/abs/2502.09104v1)|null|
|**2025-02-13**|**Logical Reasoning in Large Language Models: A Survey**|Hanmeng Liu et.al.|[2502.09100v1](http://arxiv.org/abs/2502.09100v1)|null|
|**2025-02-13**|**A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit**|Tianyi Huang et.al.|[2502.09097v1](http://arxiv.org/abs/2502.09097v1)|null|
|**2025-02-13**|**A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning**|Jia Gao et.al.|[2502.09086v1](http://arxiv.org/abs/2502.09086v1)|null|
|**2025-02-13**|**Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking**|Greta Warren et.al.|[2502.09083v1](http://arxiv.org/abs/2502.09083v1)|null|
|**2025-02-13**|**CoSER: Coordinating LLM-Based Persona Simulation of Established Roles**|Xintao Wang et.al.|[2502.09082v1](http://arxiv.org/abs/2502.09082v1)|null|
|**2025-02-13**|**Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables**|Xuzhao Geng et.al.|[2502.09073v1](http://arxiv.org/abs/2502.09073v1)|null|
|**2025-02-13**|**An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging**|Kunat Pipatanakul et.al.|[2502.09056v1](http://arxiv.org/abs/2502.09056v1)|null|
|**2025-02-13**|**Cost-Saving LLM Cascades with Early Abstention**|Michael J. Zellinger et.al.|[2502.09054v1](http://arxiv.org/abs/2502.09054v1)|null|
|**2025-02-13**|**Game Theory Meets Large Language Models: A Systematic Survey**|Haoran Sun et.al.|[2502.09053v1](http://arxiv.org/abs/2502.09053v1)|null|
|**2025-02-13**|**AIDE: Agentically Improve Visual Language Model with Domain Experts**|Ming-Chang Chiu et.al.|[2502.09051v1](http://arxiv.org/abs/2502.09051v1)|null|
|**2025-02-13**|**Leveraging Member-Group Relations via Multi-View Graph Filtering for Effective Group Recommendation**|Chae-Hyun Kim et.al.|[2502.09050v1](http://arxiv.org/abs/2502.09050v1)|null|
|**2025-02-13**|**Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation**|Jin-Duk Park et.al.|[2502.09046v1](http://arxiv.org/abs/2502.09046v1)|null|
|**2025-02-13**|**Typhoon T1: An Open Thai Reasoning Model**|Pittawat Taveekitworachai et.al.|[2502.09042v1](http://arxiv.org/abs/2502.09042v1)|null|
|**2025-02-13**|**Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning**|Lin Zhang et.al.|[2502.09022v1](http://arxiv.org/abs/2502.09022v1)|null|
|**2025-02-13**|**EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition**|Xiao Wang et.al.|[2502.09020v1](http://arxiv.org/abs/2502.09020v1)|null|
|**2025-02-13**|**Zero-shot Concept Bottleneck Models**|Shin'ya Yamaguchi et.al.|[2502.09018v1](http://arxiv.org/abs/2502.09018v1)|null|
|**2025-02-13**|**Diversity Enhances an LLM's Performance in RAG and Long-context Task**|Zhchao Wang et.al.|[2502.09017v1](http://arxiv.org/abs/2502.09017v1)|null|
|**2025-02-13**|**Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech**|Jonathan Pofcher et.al.|[2502.09004v1](http://arxiv.org/abs/2502.09004v1)|null|
|**2025-02-13**|**RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models**|Quan Wei et.al.|[2502.09003v1](http://arxiv.org/abs/2502.09003v1)|null|
|**2025-02-13**|**PixLift: Accelerating Web Browsing via AI Upscaling**|Yonas Atinafu et.al.|[2502.08995v1](http://arxiv.org/abs/2502.08995v1)|null|
|**2025-02-13**|**RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning**|Nazatul H. Sultan et.al.|[2502.08989v1](http://arxiv.org/abs/2502.08989v1)|null|
|**2025-02-13**|**Neural Force Field: Learning Generalized Physical Representation from a Few Examples**|Shiqian Li et.al.|[2502.08987v1](http://arxiv.org/abs/2502.08987v1)|null|
|**2025-02-13**|**Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning**|Hyundong Cho et.al.|[2502.08972v1](http://arxiv.org/abs/2502.08972v1)|null|
|**2025-02-13**|**RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage**|Peter Yong Zhong et.al.|[2502.08966v1](http://arxiv.org/abs/2502.08966v1)|null|
|**2025-02-13**|**Biologically Plausible Brain Graph Transformer**|Ciyuan Peng et.al.|[2502.08958v1](http://arxiv.org/abs/2502.08958v1)|null|
|**2025-02-13**|**Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning**|Leon Nissen et.al.|[2502.08954v1](http://arxiv.org/abs/2502.08954v1)|null|

#### Abstracts
##### **Theoretical Benefit and Limitation of Diffusion Language Model**
2502.09622v1 by Guhao Feng, Yihan Geng, Jian Guan, Wei Wu, Liwei Wang, Di He

Diffusion language models have emerged as a promising approach for text
generation. One would naturally expect this method to be an efficient
replacement for autoregressive models since multiple tokens can be sampled in
parallel during each diffusion step. However, its efficiency-accuracy trade-off
is not yet well understood. In this paper, we present a rigorous theoretical
analysis of a widely used type of diffusion language model, the Masked
Diffusion Model (MDM), and find that its effectiveness heavily depends on the
target evaluation metric. Under mild conditions, we prove that when using
perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling
steps regardless of sequence length, demonstrating that efficiency can be
achieved without sacrificing performance. However, when using the sequence
error rate--which is important for understanding the "correctness" of a
sequence, such as a reasoning chain--we show that the required sampling steps
must scale linearly with sequence length to obtain "correct" sequences, thereby
eliminating MDM's efficiency advantage over autoregressive models. Our analysis
establishes the first theoretical foundation for understanding the benefits and
limitations of MDMs. All theoretical findings are supported by empirical
studies.

摘要：擴散語言模型已成為文字生成的一種有前途的方法。由於在每個擴散步驟期間可以並行採樣多個符號，因此人們自然會期望這種方法成為自迴歸模型的有效替代方案。然而，它的效率準確性權衡尚未得到很好的理解。在本文中，我們對廣泛使用的擴散語言模型類型，即遮罩擴散模型 (MDM) 進行了嚴格的理論分析，並發現其有效性在很大程度上取決於目標評估指標。在溫和條件下，我們證明了當使用困惑度作為指標時，MDM 可以無論序列長度如何，在採樣步驟中實現近乎最佳的困惑度，這表明可以在不犧牲性能的情況下實現效率。然而，當使用序列錯誤率（對於理解序列的「正確性」很重要，例如推理鏈）時，我們表明所需的採樣步驟必須隨著序列長度線性縮放才能獲得「正確」的序列，從而消除了 MDM 相對於自迴歸模型的效率優勢。我們的分析為理解 MDM 的優點和局限性建立了第一個理論基礎。所有理論發現都得到了實證研究的支持。

##### **MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency**
2502.09621v1 by Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li

Answering questions with Chain-of-Thought (CoT) has significantly enhanced
the reasoning capabilities of Large Language Models (LLMs), yet its impact on
Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth
investigation. In this paper, we introduce MME-CoT, a specialized benchmark
evaluating the CoT reasoning performance of LMMs, spanning six domains: math,
science, OCR, logic, space-time, and general scenes. As the first comprehensive
study in this area, we propose a thorough evaluation suite incorporating three
novel metrics that assess the reasoning quality, robustness, and efficiency at
a fine-grained level. Leveraging curated high-quality data and a unique
evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs,
uncovering several key insights: 1) Models with reflection mechanism
demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and
demonstrating the highest quality results; 2) CoT prompting often degrades LMM
performance on perception-heavy tasks, suggesting a potentially harmful
overthinking behavior; and 3) Although the CoT quality is high, LMMs with
reflection exhibit significant inefficiency in both normal response and
self-correction phases. We hope MME-CoT serves as a foundation for advancing
multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/

摘要：<paragraph>透過思維鏈（CoT）回答問題，大幅提升了大型語言模型（LLM）的推理能力，但其對大型多模態模型（LMM）的影響仍缺乏系統性的評估和深入探討。在本文中，我們引入了 MME-CoT，一個專門的基準測試，用於評估 LMM 的 CoT 推理效能，涵蓋六個領域：數學、科學、OCR、邏輯、時空和一般場景。作為該領域的第一個全面性研究，我們提出了一個全面的評估套件，包含三個創新的指標，用於評估推理品質、穩健性和效率，並達到細微的層級。透過利用策展的高品質資料和獨特的評估策略，我們對最先進的 LMM 進行深入分析，發現了幾個關鍵見解：1）具有反思機制的模型展現出優異的 CoT 品質，其中 Kimi k1.5 優於 GPT-4o，並展現出最高品質的結果；2）CoT 提示通常會降低 LMM 在感知密集任務上的效能，這表示潛在有害的過度思考行為；3）儘管 CoT 品質很高，但具有反思能力的 LMM 在一般回應和自我修正階段都展現出顯著的低效率。我們希望 MME-CoT 能作為促進 LMM 中多模態推理的基礎。專案頁面：https://mmecot.github.io/</paragraph>

##### **Exploring the Potential of Encoder-free Architectures in 3D LMMs**
2502.09620v1 by Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao

Encoder-free architectures have been preliminarily explored in the 2D visual
domain, yet it remains an open question whether they can be effectively applied
to 3D understanding scenarios. In this paper, we present the first
comprehensive investigation into the potential of encoder-free architectures to
overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs).
These challenges include the failure to adapt to varying point cloud
resolutions and the point features from the encoder not meeting the semantic
needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to
remove the encoder and enable the LLM to assume the role of the 3D encoder: 1)
We propose the LLM-embedded Semantic Encoding strategy in the pre-training
stage, exploring the effects of various point cloud self-supervised losses. And
we present the Hybrid Semantic Loss to extract high-level semantics. 2) We
introduce the Hierarchical Geometry Aggregation strategy in the instruction
tuning stage. This incorporates inductive bias into the LLM early layers to
focus on the local details of the point clouds. To the end, we present the
first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current
state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the
classification, captioning, and VQA tasks, respectively. Our results
demonstrate that the encoder-free architecture is highly promising for
replacing encoder-based architectures in the field of 3D understanding. The
code is released at https://github.com/Ivan-Tang-3D/ENEL

摘要：<paragraph>編碼器免費架構已在 2D 視覺領域中初步探索，但它們是否能有效應用於 3D 理解場景仍是一個開放的問題。在本文中，我們提出了對編碼器免費架構潛力的首次全面調查，以克服基於編碼器的 3D 大型多模態模型 (LMM) 的挑戰。這些挑戰包括無法適應不同的點雲解析度，且來自編碼器的點特徵無法滿足大型語言模型 (LLM) 的語義需求。我們識別出 3D LMM 的關鍵方面，以移除編碼器並讓 LLM 承擔 3D 編碼器的角色：1) 我們在預訓練階段提出 LLM 嵌入式語義編碼策略，探索各種點雲自我監督損失的影響。我們提出混合語義損失來提取高階語義。2) 我們在指令調整階段引入分層幾何聚合策略。這將歸納偏差納入 LLM 早期層，以專注於點雲的局部細節。最後，我們提出第一個無編碼器 3D LMM，ENEL。我們的 7B 模型與當前最先進的模型 ShapeLLM-13B 相媲美，分別在分類、字幕和 VQA 任務中達到 55.0%、50.92% 和 42.7%。我們的結果表明，無編碼器架構極有望取代基於編碼器的架構在 3D 理解領域的應用。程式碼發布於 https://github.com/Ivan-Tang-3D/ENEL</paragraph>

##### **DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References**
2502.09614v1 by Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi

We address the challenge of developing a generalizable neural tracking
controller for dexterous manipulation from human references. This controller
aims to manage a dexterous robot hand to manipulate diverse objects for various
purposes defined by kinematic human-object interactions. Developing such a
controller is complicated by the intricate contact dynamics of dexterous
manipulation and the need for adaptivity, generalizability, and robustness.
Current reinforcement learning and trajectory optimization methods often fall
short due to their dependence on task-specific rewards or precise system
models. We introduce an approach that curates large-scale successful robot
tracking demonstrations, comprising pairs of human references and robot
actions, to train a neural controller. Utilizing a data flywheel, we
iteratively enhance the controller's performance, as well as the number and
quality of successful tracking demonstrations. We exploit available tracking
demonstrations and carefully integrate reinforcement learning and imitation
learning to boost the controller's performance in dynamic environments. At the
same time, to obtain high-quality tracking demonstrations, we individually
optimize per-trajectory tracking by leveraging the learned tracking controller
in a homotopy optimization method. The homotopy optimization, mimicking
chain-of-thought, aids in solving challenging trajectory tracking problems to
increase demonstration diversity. We showcase our success by training a
generalizable neural controller and evaluating it in both simulation and real
world. Our method achieves over a 10% improvement in success rates compared to
leading baselines. The project website with animated results is available at
https://meowuu7.github.io/DexTrack/.

摘要：<paragraph>我們解決了從人類參照中開發靈巧操作通用神經追蹤控制器的挑戰。此控制器旨在管理靈巧機器人手，以操作各種物體，以實現由運動學人機互動定義的各種目的。由於靈巧操作的複雜接觸動力學以及對適應性、通用性和魯棒性的需求，開發此類控制器很複雜。目前的強化學習和軌跡優化方法通常由於依賴於特定任務的獎勵或精確的系統模型而表現不佳。我們引入了一種方法，它策劃了大規模成功的機器人追蹤示範，包括人體參照和機器人動作對，以訓練神經控制器。利用數據飛輪，我們反覆增強控制器的性能，以及成功追蹤示範的數量和品質。我們利用可用的追蹤示範，並仔細整合強化學習和模仿學習，以提升控制器在動態環境中的性能。同時，為了獲得高品質的追蹤示範，我們透過在同倫優化方法中利用已學習的追蹤控制器，個別優化每個軌跡的追蹤。同倫優化模擬思考鏈，有助於解決具有挑戰性的軌跡追蹤問題，以增加示範的多樣性。我們展示了我們在訓練通用神經控制器並在模擬和真實世界中評估它的成功。與領先的基準相比，我們的模型在成功率方面提高了 10% 以上。包含動畫結果的專案網站可在 https://meowuu7.github.io/DexTrack/ 取得。</paragraph>

##### **Score-of-Mixture Training: Training One-Step Generative Models Made Simple**
2502.09609v1 by Tejas Jayashankar, J. Jon Ryu, Gregory Wornell

We propose Score-of-Mixture Training (SMT), a novel framework for training
one-step generative models by minimizing a class of divergences called the
$\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score
of mixture distributions between real and fake samples across multiple noise
levels. Similar to consistency models, our approach supports both training from
scratch (SMT) and distillation using a pretrained diffusion model, which we
call Score-of-Mixture Distillation (SMD). It is simple to implement, requires
minimal hyperparameter tuning, and ensures stable training. Experiments on
CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even
outperform existing methods.

摘要：我們提出混合評分訓練 (SMT)，一種透過最小化稱為 $\alpha$-偏斜 Jensen-Shannon 距離的距離類別來訓練單步生成模型的新穎架構。在核心部分，SMT 估計真實和虛假樣本之間在多個雜訊層級的混合分配評分。與一致性模型類似，我們的做法支援從頭開始訓練 (SMT) 和使用預先訓練的擴散模型進行蒸餾，我們稱之為混合評分蒸餾 (SMD)。它易於實作，只需要最小的超參數調整，並確保穩定的訓練。在 CIFAR-10 和 ImageNet 64x64 上的實驗顯示，SMT/SMD 具有競爭力，甚至可以優於現有方法。

##### **Human-LLM Coevolution: Evidence from Academic Writing**
2502.09606v1 by Mingmeng Geng, Roberto Trotta

With a statistical analysis of arXiv paper abstracts, we report a marked drop
in the frequency of several words previously identified as overused by ChatGPT,
such as "delve", starting soon after they were pointed out in early 2024. The
frequency of certain other words favored by ChatGPT, such as "significant", has
instead kept increasing. These phenomena suggest that some authors of academic
papers have adapted their use of large language models (LLMs), for example, by
selecting outputs or applying modifications to the LLM-generated content. Such
coevolution and cooperation of humans and LLMs thus introduce additional
challenges to the detection of machine-generated text in real-world scenarios.
Estimating the impact of LLMs on academic writing by examining word frequency
remains feasible, and more attention should be paid to words that were already
frequently employed, including those that have decreased in frequency.

摘要：透過對 arXiv 論文摘要進行統計分析，我們報告了幾個先前被認為 ChatGPT 過度使用的詞彙的頻率大幅下降，例如「深入探討」，從 2024 年初被指出後不久就開始下降。相反地，ChatGPT 偏好的某些其他詞彙，例如「顯著」，頻率持續增加。這些現象表明，一些學術論文作者已經調整了他們使用大型語言模型 (LLM) 的方式，例如，透過選擇輸出或對 LLM 生成的內容進行修改。因此，人類和 LLM 的這種共同演化和合作為在現實世界場景中偵測機器產生的文字帶來了額外的挑戰。透過檢視詞彙頻率來評估 LLM 對學術寫作的影響仍然可行，並且應該對已經頻繁使用的詞彙給予更多關注，包括那些頻率下降的詞彙。

##### **SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models**
2502.09604v1 by Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih

We introduce SelfCite, a novel self-supervised approach that aligns LLMs to
generate high-quality, fine-grained, sentence-level citations for the
statements in their generated responses. Instead of only relying on costly and
labor-intensive annotations, SelfCite leverages a reward signal provided by the
LLM itself through context ablation: If a citation is necessary, removing the
cited text from the context should prevent the same response; if sufficient,
retaining the cited text alone should preserve the same response. This reward
can guide the inference-time best-of-N sampling strategy to improve citation
quality significantly, as well as be used in preference optimization to
directly fine-tune the models for generating better citations. The
effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3
points on the LongBench-Cite benchmark across five long-form question answering
tasks.

摘要：我們介紹 SelfCite，一種新穎的自監督方法，它將 LLM 對齊以針對其生成回應中的陳述生成高品質、細粒度、句子級別的引用。SelfCite 不僅依賴於昂貴且勞動密集的註解，還利用 LLM 本身通過上下文消融提供的獎勵信號：如果需要引用，從上下文中移除被引用的文字應當會阻止相同的回應；如果足夠，僅保留被引用的文字應當會保留相同的回應。此獎勵可以引導推理時間最佳 N 個取樣策略以顯著改善引文品質，並用於偏好最佳化以直接微調模型以生成更好的引文。SelfCite 的有效性通過在五個長篇問答任務中將 LongBench-Cite 基準上的引文 F1 提高多達 5.3 點來證明。

##### **CoT-Valve: Length-Compressible Chain-of-Thought Tuning**
2502.09601v1 by Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang

Chain-of-Thought significantly enhances a model's reasoning capability, but
it also comes with a considerable increase in inference costs due to long
chains. With the observation that the reasoning path can be easily compressed
under easy tasks but struggle on hard tasks, we explore the feasibility of
elastically controlling the length of reasoning paths with only one model,
thereby reducing the inference overhead of reasoning models dynamically based
on task difficulty. We introduce a new tuning and inference strategy named
CoT-Valve, designed to allow models to generate reasoning chains of varying
lengths. To achieve this, we propose to identify a direction in the parameter
space that, when manipulated, can effectively control the length of generated
CoT. Moreover, we show that this property is valuable for compressing the
reasoning chain. We construct datasets with chains from long to short for the
same questions and explore two enhanced strategies for CoT-Valve: (1) a precise
length-compressible CoT tuning method, and (2) a progressive chain length
compression approach. Our experiments show that CoT-Valve successfully enables
controllability and compressibility of the chain and shows better performance
than the prompt-based control. We applied this method to QwQ-32B-Preview,
reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor
performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with
only one additional incorrect answer.

摘要：<paragraph>連續思考大幅提升了模型的推理能力，但由於鏈條過長，也大幅增加了推理成本。由於觀察到推理路徑在簡單的任務中可以輕易壓縮，但在困難的任務中卻很吃力，我們探索了僅使用一個模型彈性控制推理路徑長度的可行性，從而根據任務難度動態減少推理模型的推理開銷。我們引入了一種名為 CoT-Valve 的新調校和推理策略，旨在讓模型產生長度不一的推理鏈。為此，我們提議在參數空間中識別一個方向，在操作時可以有效控制生成的 CoT 的長度。此外，我們展示了此屬性對於壓縮推理鏈是有價值的。我們構造了從長到短的鏈條的資料集，用於相同的問題，並探索了 CoT-Valve 的兩種增強策略：(1) 精確的長度可壓縮 CoT 調校方法，以及 (2) 漸進式鏈長壓縮方法。我們的實驗表明，CoT-Valve 成功地實現了鏈條的可控性和可壓縮性，並顯示出比基於提示的控制更好的效能。我們將此方法應用於 QwQ-32B-Preview，將 GSM8K 上的推理鏈條從 741 個代幣減少到 225 個代幣，效能僅略微下降 (95.07% 至 94.92%)，而在 AIME 上從 6827 個代幣減少到 4629 個代幣，只多了一個錯誤答案。</paragraph>

##### **Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs**
2502.09597v1 by Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin

Large Language Models (LLMs) are increasingly used as chatbots, yet their
ability to personalize responses to user preferences remains limited. We
introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize
and adhere to user preferences in a long-context conversational setting.
PrefEval comprises 3,000 manually curated user preference and query pairs
spanning 20 topics. PrefEval contains user personalization or preference
information in both explicit and implicit forms, and evaluates LLM performance
using a generation and a classification task. With PrefEval, we evaluated the
aforementioned preference following capabilities of 10 open-source and
proprietary LLMs in multi-session conversations with varying context lengths up
to 100k tokens. We benchmark with various prompting, iterative feedback, and
retrieval-augmented generation methods. Our benchmarking effort reveals that
state-of-the-art LLMs face significant challenges in proactively following
users' preferences during conversations. In particular, in zero-shot settings,
preference following accuracy falls below 10% at merely 10 turns (~3k tokens)
across most evaluated models. Even with advanced prompting and retrieval
methods, preference following still deteriorates in long-context conversations.
Furthermore, we show that fine-tuning on PrefEval significantly improves
performance. We believe PrefEval serves as a valuable resource for measuring,
understanding, and enhancing LLMs' preference following abilities, paving the
way for personalized conversational agents. Our code and dataset are available
at https://prefeval.github.io/.

摘要：大型語言模型（LLM）正日益被用作聊天機器人，但它們根據使用者偏好個人化回應的能力仍然有限。我們引入了 PrefEval，一個用於評估 LLM 在長時間對話環境中推論、記憶和遵守使用者偏好的能力的基準。PrefEval 包含 3,000 個手動策劃的使用者偏好和查詢對，涵蓋 20 個主題。PrefEval 包含以明確和隱含形式表達的使用者個人化或偏好資訊，並使用生成和分類任務評估 LLM 效能。透過 PrefEval，我們評估了 10 個開源和專有 LLM 在多重對話中上述的偏好追蹤能力，對話內容長度最高達 100k 個符號。我們使用各種提示、迭代回饋和檢索增強生成方法進行基準測試。我們的基準測試工作顯示，最先進的 LLM 在對話中主動追蹤使用者偏好時面臨重大挑戰。特別是在零次學習設定中，在多數評估模型中，在僅 10 個回合（約 3k 個符號）時，偏好追蹤準確度低於 10%。即使使用進階提示和檢索方法，在長時間對話中偏好追蹤仍然會惡化。此外，我們展示了在 PrefEval 上進行微調會大幅改善效能。我們相信 PrefEval 可作為衡量、理解和提升 LLM 偏好追蹤能力的寶貴資源，為個人化對話代理鋪路。我們的程式碼和資料集可在 https://prefeval.github.io/ 取得。

##### **KIMAs: A Configurable Knowledge Integrated Multi-Agent System**
2502.09596v1 by Zitao Li, Fei Wei, Yuexiang Xie, Dawei Gao, Weirui Kuang, Zhijian Ma, Bingchen Qian, Yaliang Li, Bolin Ding

Knowledge-intensive conversations supported by large language models (LLMs)
have become one of the most popular and helpful applications that can assist
people in different aspects. Many current knowledge-intensive applications are
centered on retrieval-augmented generation (RAG) techniques. While many
open-source RAG frameworks facilitate the development of RAG-based
applications, they often fall short in handling practical scenarios complicated
by heterogeneous data in topics and formats, conversational context management,
and the requirement of low-latency response times. This technical report
presents a configurable knowledge integrated multi-agent system, KIMAs, to
address these challenges. KIMAs features a flexible and configurable system for
integrating diverse knowledge sources with 1) context management and query
rewrite mechanisms to improve retrieval accuracy and multi-turn conversational
coherency, 2) efficient knowledge routing and retrieval, 3) simple but
effective filter and reference generation mechanisms, and 4) optimized
parallelizable multi-agent pipeline execution. Our work provides a scalable
framework for advancing the deployment of LLMs in real-world settings. To show
how KIMAs can help developers build knowledge-intensive applications with
different scales and emphases, we demonstrate how we configure the system to
three applications already running in practice with reliable performance.

摘要：由大型語言模型 (LLM) 支持的知識密集型對話
已成為最受歡迎且有用的應用程式之一，可協助
人們在不同面向獲得協助。許多當前的知識密集型應用程式
都以檢索增強生成 (RAG) 技術為中心。雖然許多
開放原始碼 RAG 架構促進了基於 RAG 的應用程式開發，但它們在處理
主題和格式中異質資料、對話內容管理，以及低延遲回應時間的要求所造成的實際情況時，通常力有未逮。這份技術報告
提出了可設定的知識整合多重代理系統，KIMAs，以
解決這些挑戰。KIMAs 具備靈活且可設定的系統，可整合多樣化的知識來源，並具備 1) 內容管理和查詢
改寫機制，以提升檢索準確度和多輪對話的連貫性，2) 有效的知識路由和檢索，3) 簡單但
有效的篩選和參考產生機制，以及 4) 最佳化的可平行化多重代理管線執行。我們的作品提供了可擴充的
架構，以推動在實際環境中部署 LLM。為了展示 KIMAs 如何協助開發人員建置不同規模和重點的知識密集型應用程式，我們示範如何設定系統至
三個已實際執行且效能良好的應用程式。

##### **Logical forms complement probability in understanding language model (and human) performance**
2502.09589v1 by Yixuan Wang, Freda Shi

With the increasing interest in using large language models (LLMs) for
planning in natural language, understanding their behaviors becomes an
important research question. This work conducts a systematic investigation of
LLMs' ability to perform logical reasoning in natural language. We introduce a
controlled dataset of hypothetical and disjunctive syllogisms in propositional
and modal logic and use it as the testbed for understanding LLM performance.
Our results lead to novel insights in predicting LLM behaviors: in addition to
the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical
forms should be considered as orthogonal factors. In addition, we show
similarities and differences between the logical reasoning performances of
humans and LLMs by comparing LLM and human behavioral results.

摘要：隨著在自然語言規劃中使用大型語言模型（LLM）的興趣日益濃厚，理解其行為已成為一項重要的研究課題。本研究對 LLM 在自然語言中執行邏輯推理的能力進行了系統性調查。我們引入了一個由假設和析取三段論組成的受控資料集，並使用它作為理解 LLM 效能的測試平台。我們的結果產生了預測 LLM 行為的新見解：除了輸入的機率（Gonen 等人，2023 年；McCoy 等人，2024 年）之外，邏輯形式應被視為正交因子。此外，我們透過比較 LLM 和人類行為結果，展示了人類和 LLM 在邏輯推理表現上的相似性和差異性。

##### **Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering**
2502.09573v1 by Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu

In this study, we tackle industry challenges in video content classification
by exploring and optimizing GPT-based models for zero-shot classification
across seven critical categories of video quality. We contribute a novel
approach to improving GPT's performance through prompt optimization and policy
refinement, demonstrating that simplifying complex policies significantly
reduces false negatives. Additionally, we introduce a new
decomposition-aggregation-based prompt engineering technique, which outperforms
traditional single-prompt methods. These experiments, conducted on real
industry problems, show that thoughtful prompt design can substantially enhance
GPT's performance without additional finetuning, offering an effective and
scalable solution for improving video classification systems across various
domains in industry.

摘要：在這項研究中，我們透過探索和最佳化基於 GPT 的模型，來處理影片內容分類中的產業挑戰，並針對影片品質的七個關鍵類別進行零次學習分類。我們貢獻了一種透過提示最佳化和政策改善來提升 GPT 效能的新方法，證明簡化複雜政策能大幅減少假陰性。此外，我們還引入了一種新的基於分解聚合的提示工程技術，其效能優於傳統的單一提示方法。這些在真實產業問題上執行的實驗顯示，經過深思熟慮的提示設計可以在不進行額外微調的情況下大幅提升 GPT 的效能，為提升產業中各種領域的影片分類系統提供了一個有效且可擴充的解決方案。

##### **MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing**
2502.09567v1 by Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea

We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.

摘要：我們引入 MorphNLI，一種模組化逐步方法，用於自然語言推論 (NLI)。當對前提假設對進行分類時，我們使用語言模型來產生必要的編輯，以逐步轉換（即，變形）前提成為假設。然後，使用現成的 NLI 模型，我們追蹤推論如何隨著這些原子變化而進展，將這些中間標籤彙總成最終輸出。我們展示了我們提出的方法的優點，特別是在現實的跨網域設置中，我們的模型始終優於強大的基線，改進幅度高達 12.6%（相對）。此外，我們提出的方法是可以解釋的，因為原子編輯可以用來理解整體 NLI 標籤。

##### **Zero-shot generation of synthetic neurosurgical data with large language models**
2502.09566v1 by Austin A. Barr, Eddie Guo, Emre Sezgin

Clinical data is fundamental to advance neurosurgical research, but access is
often constrained by data availability, small sample sizes, privacy
regulations, and resource-intensive preprocessing and de-identification
procedures. Synthetic data offers a potential solution to challenges associated
with accessing and using real-world data (RWD). This study aims to evaluate the
capability of zero-shot generation of synthetic neurosurgical data with a large
language model (LLM), GPT-4o, by benchmarking with the conditional tabular
generative adversarial network (CTGAN). Synthetic datasets were compared to
real-world neurosurgical data to assess fidelity (means, proportions,
distributions, and bivariate correlations), utility (ML classifier performance
on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated
datasets matched or exceeded CTGAN performance, despite no fine-tuning or
access to RWD for pre-training. Datasets demonstrated high univariate and
bivariate fidelity to RWD without directly exposing any real patient records,
even at amplified sample size. Training an ML classifier on GPT-4o-generated
data and testing on RWD for a binary prediction task showed an F1 score (0.706)
with comparable performance to training on the CTGAN data (0.705) for
predicting postoperative functional status deterioration. GPT-4o demonstrated a
promising ability to generate high-fidelity synthetic neurosurgical data. These
findings also indicate that data synthesized with GPT-4o can effectively
augment clinical data with small sample sizes, and train ML models for
prediction of neurosurgical outcomes. Further investigation is necessary to
improve the preservation of distributional characteristics and boost classifier
performance.

摘要：<paragraph>臨床數據是推進神經外科研究的基礎，但訪問通常受到數據可用性、樣本量小、隱私法規以及資源密集型預處理和去識別程序的限制。合成數據為與存取和使用真實世界數據 (RWD) 相關的挑戰提供了潛在解決方案。本研究旨在評估使用大型語言模型 (LLM) GPT-4o 零次生成合成神經外科數據的能力，並通過條件表格生成對抗網路 (CTGAN) 進行基準測試。將合成數據集與真實世界的神經外科數據進行比較，以評估保真度（平均值、比例、分布和二元相關性）、實用性（RWD 上的 ML 分類器性能）和隱私（RWD 中記錄的重複）。儘管沒有微調或訪問 RWD 進行預訓練，但 GPT-4o 生成的數據集與 CTGAN 性能相匹配或超過 CTGAN 性能。數據集證明了對 RWD 的高單變量和二變量保真度，即使在擴充的樣本量下也不會直接公開任何真實患者記錄。在 GPT-4o 生成的數據上訓練 ML 分類器，並在 RWD 上測試二元預測任務，顯示 F1 分數 (0.706) 與在 CTGAN 數據上訓練以預測術後功能狀態惡化時的性能相當 (0.705)。GPT-4o 展示了生成高保真合成神經外科數據的潛力。這些發現還表明，使用 GPT-4o 合成的數據可以有效地增加樣本量小的臨床數據，並訓練 ML 模型以預測神經外科結果。需要進一步研究以改善分佈特徵的保留並提升分類器性能。</paragraph>

##### **MDCrow: Automating Molecular Dynamics Workflows with Large Language Models**
2502.09565v1 by Quintina Campbell, Sam Cox, Jorge Medina, Brittany Watterson, Andrew D. White

Molecular dynamics (MD) simulations are essential for understanding
biomolecular systems but remain challenging to automate. Recent advances in
large language models (LLM) have demonstrated success in automating complex
scientific tasks using LLM-based agents. In this paper, we introduce MDCrow, an
agentic LLM assistant capable of automating MD workflows. MDCrow uses
chain-of-thought over 40 expert-designed tools for handling and processing
files, setting up simulations, analyzing the simulation outputs, and retrieving
relevant information from literature and databases. We assess MDCrow's
performance across 25 tasks of varying required subtasks and difficulty, and we
evaluate the agent's robustness to both difficulty and prompt style.
\texttt{gpt-4o} is able to complete complex tasks with low variance, followed
closely by \texttt{llama3-405b}, a compelling open-source model. While prompt
style does not influence the best models' performance, it has significant
effects on smaller models.

摘要：分子動力學 (MD) 模擬對於理解生物分子系統至關重要，但自動化仍然具有挑戰性。大型語言模型 (LLM) 的最新進展已證明使用基於 LLM 的代理自動化複雜的科學任務是成功的。在本文中，我們介紹了 MDCrow，這是一個代理 LLM 助理，能夠自動化 MD 工作流程。MDCrow 使用 40 多種專家設計的工具的思考鏈來處理和處理檔案、設定模擬、分析模擬輸出，以及從文獻和資料庫中檢索相關資訊。我們評估了 MDCrow 在 25 項任務中的表現，這些任務所需的子任務和難度各不相同，並且我們評估了代理對難度和提示樣式的穩健性。\texttt{gpt-4o} 能夠以低變異完成複雜的任務，緊隨其後的是一個引人注目的開源模型 \texttt{llama3-405b}。雖然提示樣式不會影響最佳模型的效能，但它對較小的模型有顯著的影響。

##### **EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents**
2502.09560v1 by Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang

Leveraging Multi-modal Large Language Models (MLLMs) to create embodied
agents offers a promising avenue for tackling real-world tasks. While
language-centric embodied agents have garnered substantial attention,
MLLM-based embodied agents remain underexplored due to the lack of
comprehensive evaluation frameworks. To bridge this gap, we introduce
EmbodiedBench, an extensive benchmark designed to evaluate vision-driven
embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing
tasks across four environments, ranging from high-level semantic tasks (e.g.,
household) to low-level tasks involving atomic actions (e.g., navigation and
manipulation); and (2) six meticulously curated subsets evaluating essential
agent capabilities like commonsense reasoning, complex instruction
understanding, spatial awareness, visual perception, and long-term planning.
Through extensive experiments, we evaluated 13 leading proprietary and
open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel
at high-level tasks but struggle with low-level manipulation, with the best
model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a
multifaceted standardized evaluation platform that not only highlights existing
challenges but also offers valuable insights to advance MLLM-based embodied
agents. Our code is available at https://embodiedbench.github.io.

摘要：<paragraph>利用多模態大型語言模型 (MLLM) 來建立具身代理，提供了解決現實世界任務的有前景途徑。儘管以語言為中心的具身代理已獲得大量關注，但由於缺乏全面的評估框架，基於 MLLM 的具身代理仍未得到充分探索。為了彌補這一差距，我們引入了 EmbodiedBench，這是一個廣泛的基準測試，旨在評估以視覺為導向的具身代理。EmbodiedBench 的特點：(1) 跨越四個環境的 1,128 項多樣化測試任務，範圍從高層級語義任務（例如，家庭）到涉及原子動作的低層級任務（例如，導航和操作）；以及 (2) 六個精心策劃的子集，用於評估基本的代理能力，例如常識推理、複雜指令理解、空間感知、視覺感知和長期規劃。通過廣泛的實驗，我們在 EmbodiedBench 中評估了 13 個領先的專有和開源 MLLM。我們的研究結果表明：MLLM 在高層級任務中表現出色，但在低層級操作中遇到困難，表現最好的模型 GPT-4o 平均得分僅為 28.9%。EmbodiedBench 提供了一個多方面的標準化評估平台，不僅突出了現有挑戰，還提供了有價值的見解來推進基於 MLLM 的具身代理。我們的程式碼可在 https://embodiedbench.github.io/ 取得。</paragraph>

##### **Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages**
2502.09532v1 by Shreyan Biswas, Alexander Erlei, Ujwal Gadiraju

Recent advances in generative AI have precipitated a proliferation of novel
writing assistants. These systems typically rely on multilingual large language
models (LLMs), providing globalized workers the ability to revise or create
diverse forms of content in different languages. However, there is substantial
evidence indicating that the performance of multilingual LLMs varies between
languages. Users who employ writing assistance for multiple languages are
therefore susceptible to disparate output quality. Importantly, recent research
has shown that people tend to generalize algorithmic errors across independent
tasks, violating the behavioral axiom of choice independence. In this paper, we
analyze whether user utilization of novel writing assistants in a charity
advertisement writing task is affected by the AI's performance in a second
language. Furthermore, we quantify the extent to which these patterns translate
into the persuasiveness of generated charity advertisements, as well as the
role of peoples' beliefs about LLM utilization in their donation choices. Our
results provide evidence that writers who engage with an LLM-based writing
assistant violate choice independence, as prior exposure to a Spanish LLM
reduces subsequent utilization of an English LLM. While these patterns do not
affect the aggregate persuasiveness of the generated advertisements, people's
beliefs about the source of an advertisement (human versus AI) do. In
particular, Spanish-speaking female participants who believed that they read an
AI-generated advertisement strongly adjusted their donation behavior downwards.
Furthermore, people are generally not able to adequately differentiate between
human-generated and LLM-generated ads. Our work has important implications for
the design, development, integration, and adoption of multilingual LLMs as
assistive agents -- particularly in writing tasks.

摘要：<paragraph>生成式 AI 的最新進展加速了新穎寫作助理的激增。這些系統通常依賴多語言大型語言模型 (LLM)，讓全球化的工作者能夠以不同的語言修改或建立各種形式的內容。然而，有大量證據顯示多語言 LLM 的表現因語言而異。因此，使用多語言寫作協助的使用者容易受到不同的輸出品質影響。重要的是，最近的研究顯示人們傾向於在獨立的任務中概化演算法錯誤，違反了選擇獨立性的行為公理。在本文中，我們分析使用者在慈善廣告寫作任務中使用新穎寫作助理是否會受到 AI 在第二語言中的表現影響。此外，我們量化這些模式轉化為所產生慈善廣告說服力的程度，以及人們對 LLM 使用在捐款選擇中的信念所扮演的角色。我們的結果提供證據，表明與基於 LLM 的寫作助理互動的寫作者會違反選擇獨立性，因為先前接觸過西班牙語 LLM 會減少後續使用英語 LLM 的情況。雖然這些模式不會影響所產生廣告的整體說服力，但人們對廣告來源（人類與 AI）的信念會影響。特別是，相信自己閱讀 AI 生成的廣告的西班牙語系女性參與者大幅調整了他們的捐款行為。此外，人們通常無法充分區分人類產生的廣告和 LLM 產生的廣告。我們的研究對多語言 LLM 作為輔助代理的設計、開發、整合和採用具有重要的意義，特別是在寫作任務中。</paragraph>

##### **Diffusion Models for Molecules: A Survey of Methods and Tasks**
2502.09511v1 by Liang Wang, Chao Song, Zhiyuan Liu, Yu Rong, Qiang Liu, Shu Wu, Liang Wang

Generative tasks about molecules, including but not limited to molecule
generation, are crucial for drug discovery and material design, and have
consistently attracted significant attention. In recent years, diffusion models
have emerged as an impressive class of deep generative models, sparking
extensive research and leading to numerous studies on their application to
molecular generative tasks. Despite the proliferation of related work, there
remains a notable lack of up-to-date and systematic surveys in this area.
Particularly, due to the diversity of diffusion model formulations, molecular
data modalities, and generative task types, the research landscape is
challenging to navigate, hindering understanding and limiting the area's
growth. To address this, this paper conducts a comprehensive survey of
diffusion model-based molecular generative methods. We systematically review
the research from the perspectives of methodological formulations, data
modalities, and task types, offering a novel taxonomy. This survey aims to
facilitate understanding and further flourishing development in this area. The
relevant papers are summarized at:
https://github.com/AzureLeon1/awesome-molecular-diffusion-models.

摘要：<paragraph>包括但不限於分子生成在內的分子生成任務，對於藥物發現和材料設計至關重要，並持續吸引大量關注。近年來，擴散模型已成為深度生成模型中令人印象深刻的一類，激發了廣泛的研究，並導致對其應用於分子生成任務的眾多研究。儘管相關工作不斷增加，但這個領域仍然缺乏最新的系統性綜述。特別是，由於擴散模型公式、分子數據方式和生成任務類型的多樣性，研究領域難以瀏覽，阻礙了理解並限制了該領域的發展。為了解決這個問題，本文對基於擴散模型的分子生成方法進行了全面的調查。我們從方法論公式、數據方式和任務類型的角度系統性地回顧了研究，提供了一種新穎的分類法。本調查旨在促進理解並進一步促進該領域的蓬勃發展。相關論文總結如下：
https://github.com/AzureLeon1/awesome-molecular-diffusion-models。</paragraph>

##### **AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization**
2502.09503v1 by Caleb Cranney, Jesse G. Meyer

Transformer architectures have transformed AI applications but remain complex
to customize for domain experts lacking low-level implementation expertise. We
introduce AttentionSmithy, a modular software package that simplifies
transformer innovation by breaking down key components into reusable building
blocks: attention modules, feed-forward networks, normalization layers, and
positional encodings. Users can rapidly prototype and evaluate transformer
variants without extensive coding. Our framework supports four positional
encoding strategies and integrates with neural architecture search for
automated design. We validate AttentionSmithy by replicating the original
transformer under resource constraints and optimizing translation performance
by combining positional encodings. Additionally, we demonstrate its
adaptability in gene-specific modeling, achieving over 95% accuracy in cell
type classification. These case studies highlight AttentionSmithy's potential
to accelerate research across diverse fields by removing framework
implementation barriers.

摘要：Transformer 架構已轉變 AI 應用，但對於缺乏低階實作專業知識的領域專家而言，自訂仍很複雜。我們推出 AttentionSmithy，這是一個模組化軟體套件，透過將關鍵元件分解成可重複使用的建構區塊（注意力模組、前饋網路、正規化層和位置編碼）來簡化 Transformer 創新。使用者可以快速建置原型和評估 Transformer 變體，而無需大量編碼。我們的架構支援四種位置編碼策略，並整合神經架構搜尋以進行自動化設計。我們透過在資源限制下複製原始 Transformer 和結合位置編碼來最佳化翻譯效能，驗證 AttentionSmithy。此外，我們展示其在基因特定建模中的適應性，在細胞類型分類中達到超過 95% 的準確度。這些案例研究突顯 AttentionSmithy 在移除架構實作障礙後，加速各個領域研究的潛力。

##### **Improve LLM-based Automatic Essay Scoring with Linguistic Features**
2502.09497v1 by Zhaoyi Joey Hou, Alejandro Ciuba, Xiang Lorraine Li

Automatic Essay Scoring (AES) assigns scores to student essays, reducing the
grading workload for instructors. Developing a scoring system capable of
handling essays across diverse prompts is challenging due to the flexibility
and diverse nature of the writing task. Existing methods typically fall into
two categories: supervised feature-based approaches and large language model
(LLM)-based methods. Supervised feature-based approaches often achieve higher
performance but require resource-intensive training. In contrast, LLM-based
methods are computationally efficient during inference but tend to suffer from
lower performance. This paper combines these approaches by incorporating
linguistic features into LLM-based scoring. Experimental results show that this
hybrid method outperforms baseline models for both in-domain and out-of-domain
writing prompts.

摘要：自動化論文評分 (AES) 會為學生的論文評分，以減輕教師的評分工作負擔。由於寫作任務的靈活性與多樣性，開發一種評分系統來處理各種提示的論文是一項挑戰。現有方法通常分為兩類：監督式特徵方法和大型語言模型 (LLM) 方法。監督式特徵方法通常能達到較高的效能，但需要大量資源進行訓練。相比之下，LLM 方法在推論期間的計算效率很高，但效能往往較低。本文結合了這些方法，將語言特徵納入 LLM 評分中。實驗結果顯示，這種混合方法在領域內和領域外寫作提示方面都優於基準模型。

##### **Cracking the Code: Enhancing Development finance understanding with artificial intelligence**
2502.09495v1 by Pierre Beaucoral

Analyzing development projects is crucial for understanding donors aid
strategies, recipients priorities, and to assess development finance capacity
to adress development issues by on-the-ground actions. In this area, the
Organisation for Economic Co-operation and Developments (OECD) Creditor
Reporting System (CRS) dataset is a reference data source. This dataset
provides a vast collection of project narratives from various sectors
(approximately 5 million projects). While the OECD CRS provides a rich source
of information on development strategies, it falls short in informing project
purposes due to its reporting process based on donors self-declared main
objectives and pre-defined industrial sectors. This research employs a novel
approach that combines Machine Learning (ML) techniques, specifically Natural
Language Processing (NLP), an innovative Python topic modeling technique called
BERTopic, to categorise (cluster) and label development projects based on their
narrative descriptions. By revealing existing yet hidden topics of development
finance, this application of artificial intelligence enables a better
understanding of donor priorities and overall development funding and provides
methods to analyse public and private projects narratives.

摘要：分析發展專案對於了解捐助者援助策略、受贈者優先事項，以及評估發展資金能力以透過實際行動解決發展問題至關重要。在這個領域中，經濟合作暨發展組織 (OECD) 債權人報告系統 (CRS) 資料集是一個參考資料來源。此資料集提供來自各個部門的大量專案敘述（約 500 萬個專案）。雖然 OECD CRS 提供了豐富的發展策略資訊來源，但由於其報告程序基於捐助者自行申報的主要目標和預先定義的產業部門，因此在告知專案目的方面有所不足。本研究採用一種新穎的方法，結合機器學習 (ML) 技術，特別是自然語言處理 (NLP)，一種稱為 BERTopic 的創新 Python 主題建模技術，根據其敘述描述對發展專案進行分類（叢集）和標籤。透過揭露發展資金現有但隱藏的主題，這種人工智慧應用程式可以更好地了解捐助者的優先事項和整體發展資金，並提供分析公共和私人專案敘述的方法。

##### **Objective quantification of mood states using large language models**
2502.09487v1 by Jakub Onysk, Quentin Huys

Emotional states influence human behaviour and cognition, leading to diverse
thought trajectories. Similarly, Large Language Models (LLMs) showcase an
excellent level of response consistency across wide-ranging contexts (prompts).
We leverage these parallels to establish a framework for quantifying mental
states. Our approach utilises self-report questionnaires that reliably assess
these states due to their inherent sensitivity to patterns of co-occurring
responses. Specifically, we recruited a large sample of participants (N=422) to
investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set
of depressive mood states measured with participants' open-ended responses to a
depression questionnaire. We show LLM responses to held-out multiple-choice
questions, given participants' open-ended answers, correlate strongly (r:
0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation
from mood representations. We explore a link between these representations and
factor analysis. Using ridge regression, we find depression-related subspaces
within LLM hidden states. We show these subspaces to be predictive of
participants' "Depression" and "Somatic & Emotional Distress" factor scores, as
well as suicidality severity. Overall, LLMs can provide quantitative measures
of mental states. The reliability of these hinges upon how informative the
questions we ask participants are. Used correctly, this approach could
supplement mental state assessment in a variety of settings.

摘要：情緒狀態會影響人類行為和認知，導致不同的思維軌跡。同樣地，大型語言模型 (LLM) 在廣泛的脈絡（提示）中展示出極佳的反應一致性。我們利用這些相似之處來建立一個量化心理狀態的框架。我們的做法利用自我報告問卷，由於這些問卷對共生反應模式具有內在敏感性，因此可以可靠地評估這些狀態。具體來說，我們招募了大量的參與者樣本 (N=422) 來調查 LLM (Mistral-7B-OpenOrca) 如何量化一組異質的抑鬱情緒狀態，這些狀態是根據參與者對抑鬱症問卷的開放式回答來衡量的。我們展示了 LLM 對保留的多選題的回答，給定參與者的開放式回答，與真正的問卷分數密切相關 (r：0.52-0.84)，這證明了 LLM 從情緒表徵中進行概括。我們探索這些表徵與因子分析之間的聯繫。使用嶺回歸，我們在 LLM 隱藏狀態內發現了與抑鬱相關的子空間。我們展示這些子空間可以預測參與者的「抑鬱」和「軀體和情緒困擾」因子分數，以及自殺嚴重性。總體而言，LLM 可以提供心理狀態的量化測量。這些測量的可靠性取決於我們詢問參與者的問題的資訊性。如果使用得當，這種方法可以補充各種環境中的心理狀態評估。

##### **The Multilingual Mind : A Survey of Multilingual Reasoning in Language Models**
2502.09457v1 by Akash Ghosh, Debayan Datta, Sriparna Saha, Chirag Agarwal

While reasoning and multilingual capabilities in Language Models (LMs) have
achieved remarkable progress in recent years, their integration into a unified
paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning
requires language models to handle logical reasoning across languages while
addressing misalignment, biases, and challenges in low-resource settings. This
survey provides the first in-depth review of multilingual reasoning in LMs. In
this survey, we provide a systematic overview of existing methods that leverage
LMs for multilingual reasoning, specifically outlining the challenges,
motivations, and foundational aspects of applying language models to reason
across diverse languages. We provide an overview of the standard data resources
used for training multilingual reasoning in LMs and the evaluation benchmarks
employed to assess their multilingual capabilities. Next, we analyze various
state-of-the-art methods and their performance on these benchmarks. Finally, we
explore future research opportunities to improve multilingual reasoning in LMs,
focusing on enhancing their ability to handle diverse languages and complex
reasoning tasks.

摘要：儘管語言模型 (LM) 的推理和多語言能力在近年來取得顯著進展，但它們整合至統一典範（多語言推理）仍處於萌芽階段。多語言推理要求語言模型跨語言處理邏輯推理，同時解決低資源環境中的錯位、偏見和挑戰。本調查提供了 LM 中多語言推理的首次深入探討。在本調查中，我們系統性地概述了現有利用 LM 進行多語言推理的方法，特別概述了將語言模型應用於跨不同語言推理的挑戰、動機和基礎方面。我們概述了用於訓練 LM 中多語言推理的標準數據資源，以及用於評估其多語言能力的評估基準。接下來，我們分析了各種最先進的方法及其在這些基準上的表現。最後，我們探討了改進 LM 中多語言推理的未來研究機會，重點關注增強其處理不同語言和複雜推理任務的能力。

##### **Pixel-Level Reasoning Segmentation via Multi-turn Conversations**
2502.09447v1 by Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria

Existing visual perception systems focus on region-level segmentation in
single-turn dialogues, relying on complex and explicit query instructions. Such
systems cannot reason at the pixel level and comprehend dynamic user intent
that changes over interaction. Our work tackles this issue by introducing a
novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on
multi-turn conversations, tracking evolving user intent via multi-turn
interactions for fine-grained segmentation. To establish a benchmark for this
novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on
Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k
multi-turn conversational scenarios with segmentation targets. Building on
PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning
Segmentation framework, integrates pixel-level segmentation with robust
multi-turn conversation understanding, generating pixel-grounded explanations
aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in
pixel-level reasoning segmentation. Experimental results on the PRIST dataset
demonstrate that our method outperforms current segmentation-specific baselines
in terms of segmentation and LLM-based reasoning metrics. The code and data are
available at: https://github.com/ccccai239/PixelRIST.

摘要：現有的視覺感知系統專注於單輪對話中的區域級分割，依賴於複雜且明確的查詢指令。此類系統無法在像素級別推理和理解在互動中不斷變化的動態使用者意圖。我們的研究通過引入一項基於多輪對話的像素級推理分割（像素級 RS）新任務來解決此問題，通過多輪互動追蹤不斷演變的使用者意圖，以進行精細分割。為了建立此新任務的基準，我們建立了一個基於多輪對話的像素級推理分割資料集（PRIST），其中包含來自 8.3k 多輪對話場景的 24k 個語句，以及分割目標。在 PRIST 的基礎上，我們進一步提出了 MIRAS，這是一個多輪互動推理分割框架，它將像素級分割與強大的多輪對話理解整合在一起，生成符合使用者意圖的像素級解釋。PRIST 資料集和 MIRSA 框架填補了像素級推理分割的空白。在 PRIST 資料集上的實驗結果表明，我們的模型在分割和基於 LLM 的推理指標方面優於目前的特定於分割的基準。程式碼和資料可在 https://github.com/ccccai239/PixelRIST 獲得。

##### **Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes**
2502.09432v1 by Navdeep Kumar, Adarsh Gupta, Maxence Mohamed Elfatihi, Giorgia Ramponi, Kfir Yehuda Levy, Shie Mannor

We study robust Markov decision processes (RMDPs) with non-rectangular
uncertainty sets, which capture interdependencies across states unlike
traditional rectangular models. While non-rectangular robust policy evaluation
is generally NP-hard, even in approximation, we identify a powerful class of
$L_p$-bounded uncertainty sets that avoid these complexity barriers due to
their structural simplicity. We further show that this class can be decomposed
into infinitely many \texttt{sa}-rectangular $L_p$-bounded sets and leverage
its structural properties to derive a novel dual formulation for $L_p$ RMDPs.
This formulation provides key insights into the adversary's strategy and
enables the development of the first robust policy evaluation algorithms for
non-rectangular RMDPs. Empirical results demonstrate that our approach
significantly outperforms brute-force methods, establishing a promising
foundation for future investigation into non-rectangular robust MDPs.

摘要：我們研究具有非矩形不確定性集合的強健馬可夫決策過程 (RMDP)，它能捕捉到不同於傳統矩形模型的跨狀態相互依賴性。雖然非矩形強健策略評估通常是 NP-hard，即使在近似中也是如此，我們識別了一類強大的 $L_p$ 有界不確定性集合，由於其結構的簡潔性，可以避免這些複雜性障礙。我們進一步表明，此類可以分解為無限多的 \texttt{sa} 矩形 $L_p$ 有界集合，並利用其結構屬性為 $L_p$ RMDP 導出一個新的對偶公式。此公式提供了對抗者策略的重要見解，並能夠開發出第一個非矩形 RMDP 的強健策略評估演算法。實證結果表明，我們的做法顯著優於蠻力方法，為未來對非矩形強健 MDP 的研究奠定了有希望的基礎。

##### **Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction**
2502.09423v1 by Ziyi Chen, Yang Yuan, Siming Zheng, Jialong Guo, Sihan Liang, Yangang Wang, Zongguo Wang

Crystal structure forms the foundation for understanding the physical and
chemical properties of materials. Generative models have emerged as a new
paradigm in crystal structure prediction(CSP), however, accurately capturing
key characteristics of crystal structures, such as periodicity and symmetry,
remains a significant challenge. In this paper, we propose a
Transformer-Enhanced Variational Autoencoder for Crystal Structure Prediction
(TransVAE-CSP), who learns the characteristic distribution space of stable
materials, enabling both the reconstruction and generation of crystal
structures. TransVAE-CSP integrates adaptive distance expansion with
irreducible representation to effectively capture the periodicity and symmetry
of crystal structures, and the encoder is a transformer network based on an
equivariant dot product attention mechanism. Experimental results on the
carbon_24, perov_5, and mp_20 datasets demonstrate that TransVAE-CSP
outperforms existing methods in structure reconstruction and generation tasks
under various modeling metrics, offering a powerful tool for crystal structure
design and optimization.

摘要：晶體結構形成了解材料物理和化學性質的基礎。生成模型已成為晶體結構預測 (CSP) 的新典範，然而，準確捕捉晶體結構的關鍵特徵（例如週期性和對稱性）仍然是一項重大挑戰。在本文中，我們提出了一種用於晶體結構預測的 Transformer 增強變異自動編碼器 (TransVAE-CSP)，它學習穩定材料的特徵分佈空間，使晶體結構的重建和生成成為可能。TransVAE-CSP 將自適應距離擴展與不可約表示相結合，以有效地捕捉晶體結構的週期性和對稱性，並且編碼器是一個基於等變點積注意力機制的 Transformer 網路。在 carbon_24、perov_5 和 mp_20 資料集上的實驗結果表明，TransVAE-CSP 在各種建模指標下，在結構重建和生成任務中優於現有方法，為晶體結構設計和最佳化提供了一個強大的工具。

##### **On multi-token prediction for efficient LLM inference**
2502.09419v1 by Somesh Mehra, Javier Alonso Garcia, Lukas Mauch

We systematically investigate multi-token prediction (MTP) capabilities
within LLMs pre-trained for next-token prediction (NTP). We first show that
such models inherently possess MTP capabilities via numerical marginalization
over intermediate token probabilities, though performance is data-dependent and
improves with model scale. Furthermore, we explore the challenges of
integrating MTP heads into frozen LLMs and find that their hidden layers are
strongly specialized for NTP, making adaptation non-trivial. Finally, we show
that while joint training of MTP heads with the backbone improves performance,
it cannot fully overcome this barrier, prompting further research in this
direction. Our findings provide a deeper understanding of MTP applied to
pretrained LLMs, informing strategies for accelerating inference through
parallel token prediction.

摘要：我們系統性地研究了在預先訓練下用於下一個代幣預測 (NTP) 的 LLM 中的多代幣預測 (MTP) 功能。我們首先表明，此類模型透過中間代幣機率的數值邊際化本質上具備 MTP 功能，儘管效能依賴於資料，且會隨著模型規模而提升。此外，我們探討了將 MTP 頭整合到凍結 LLM 中的挑戰，發現其隱藏層高度專門用於 NTP，使得適應變得不簡單。最後，我們顯示，儘管 MTP 頭與主幹的聯合訓練會提升效能，但無法完全克服此障礙，促使我們進一步研究這個方向。我們的發現提供了對應用於預先訓練 LLM 的 MTP 更深入的理解，並為透過平行代幣預測加速推論提供策略。

##### **SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models**
2502.09390v1 by Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat

In the rapidly evolving field of Natural Language Processing, Large Language
Models (LLMs) are tasked with increasingly complex reasoning challenges.
Traditional methods like chain-of-thought prompting have shown promise but
often fall short in fully leveraging a model's reasoning capabilities. This
paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a
novel prompting technique designed to improve reasoning through a
self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts
models to generate and resolve multiple auxiliary questions before tackling the
main query, promoting a more thorough exploration of various aspects of a
topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models
across multiple question-answering datasets, demonstrate that SQuARE
significantly surpasses traditional CoT prompts and existing
rephrase-and-respond methods. By systematically decomposing queries, SQuARE
advances LLM capabilities in reasoning tasks. The code is publicly available at
https://github.com/IntelLabs/RAG-FiT/tree/square.

摘要：在快速發展的自然語言處理領域中，大型語言模型 (LLM) 負責越來越複雜的推理挑戰。
傳統方法（如思考鏈提示）已展現潛力，但通常無法充分利用模型的推理能力。本文介紹 SQuARE（順序式問答推理引擎），這是一種新穎的提示技術，旨在透過自我提問模式來改善推理。建立在 CoT 架構之上，SQuARE 提示模型在處理主要查詢之前產生並解決多個輔助問題，促進對某個主題的各個面向進行更徹底的探討。我們使用 Llama 3 和 GPT-4o 模型對多個問答資料集進行廣泛評估，結果顯示 SQuARE 明顯優於傳統 CoT 提示和現有的改寫並回應方法。透過系統性地分解查詢，SQuARE 提升了 LLM 在推理任務中的能力。程式碼已公開於 https://github.com/IntelLabs/RAG-FiT/tree/square。

##### **Truth Knows No Language: Evaluating Truthfulness Beyond English**
2502.09387v1 by Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, Rodrigo Agerri

We introduce a professionally translated extension of the TruthfulQA
benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and
Spanish. Truthfulness evaluations of large language models (LLMs) have
primarily been conducted in English. However, the ability of LLMs to maintain
truthfulness across languages remains under-explored. Our study evaluates 12
state-of-the-art open LLMs, comparing base and instruction-tuned models using
human evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our
findings reveal that, while LLMs perform best in English and worst in Basque
(the lowest-resourced language), overall truthfulness discrepancies across
languages are smaller than anticipated. Furthermore, we show that
LLM-as-a-Judge correlates more closely with human judgments than
multiple-choice metrics, and that informativeness plays a critical role in
truthfulness assessment. Our results also indicate that machine translation
provides a viable approach for extending truthfulness benchmarks to additional
languages, offering a scalable alternative to professional translation.
Finally, we observe that universal knowledge questions are better handled
across languages than context- and time-dependent ones, highlighting the need
for truthfulness evaluations that account for cultural and temporal
variability. Dataset and code are publicly available under open licenses.

摘要：我們針對 TruthfulQA 推出專業翻譯的延伸版本，旨在評估巴斯克語、加泰隆尼亞語、加利西亞語和西班牙語中的真實性。大型語言模型 (LLM) 的真實性評估主要以英語進行。然而，LLM 在不同語言中維持真實性的能力仍未得到充分探索。我們的研究評估了 12 個最先進的開放 LLM，使用人類評估、多選項指標和 LLM 作為評分標準比較基礎和指令調整模型。我們的研究結果表明，雖然 LLM 在英語中的表現最好，而在巴斯克語（資源最少的語言）中的表現最差，但整體上不同語言之間的真實性差異小於預期。此外，我們表明，與多選項指標相比，LLM 作為評分標準與人類判斷更密切相關，而且信息豐富性在真實性評估中發揮著至關重要的作用。我們的結果還表明，機器翻譯提供了一種可行的途徑，可以將真實性基準擴展到其他語言，從而提供了一種可擴展的專業翻譯替代方案。最後，我們觀察到，與上下文和時間依賴的問題相比，通用知識問題在不同語言之間的處理效果更好，這突顯了考慮文化和時間可變性的真實性評估的必要性。數據集和代碼在開放許可下公開可用。

##### **A Deep Inverse-Mapping Model for a Flapping Robotic Wing**
2502.09378v1 by Hadar Sharvit, Raz Karl, Tsevi Beatus

In systems control, the dynamics of a system are governed by modulating its
inputs to achieve a desired outcome. For example, to control the thrust of a
quad-copter propeller the controller modulates its rotation rate, relying on a
straightforward mapping between the input rotation rate and the resulting
thrust. This mapping can be inverted to determine the rotation rate needed to
generate a desired thrust. However, in complex systems, such as flapping-wing
robots where intricate fluid motions are involved, mapping inputs (wing
kinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this
mapping for real-time control is computationally impractical. Here, we report a
machine-learning solution for the inverse mapping of a flapping-wing system
based on data from an experimental system we have developed. Our model learns
the input wing motion required to generate a desired aerodynamic force outcome.
We used a sequence-to-sequence model tailored for time-series data and
augmented it with a novel adaptive-spectrum layer that implements
representation learning in the frequency domain. To train our model, we
developed a flapping wing system that simultaneously measures the wing's
aerodynamic force and its 3D motion using high-speed cameras. We demonstrate
the performance of our system on an additional open-source dataset of a
flapping wing in a different flow regime. Results show superior performance
compared with more complex state-of-the-art transformer-based models, with 11%
improvement on the test datasets median loss. Moreover, our model shows
superior inference time, making it practical for onboard robotic control. Our
open-source data and framework may improve modeling and real-time control of
systems governed by complex dynamics, from biomimetic robots to biomedical
devices.

摘要：<paragraph>在系統控制中，系統的動態受調節其輸入以實現所需結果的影響。例如，為了控制四軸旋翼推進器的推力，控制器會調節其旋轉速率，依賴於輸入旋轉速率和所產生的推力之間的直接映射。此映射可以反轉以確定產生所需推力所需的旋轉速率。然而，在複雜的系統中，例如涉及複雜流體運動的拍打式機翼機器人，將輸入（機翼運動學）映射到輸出（空氣動力）並非易事，並且反轉此映射以進行實時控制在計算上不切實際。在此，我們報告了一個基於我們開發的實驗系統數據的拍打式機翼系統反向映射的機器學習解決方案。我們的模型學習產生所需空氣動力結果所需的輸入機翼運動。我們使用了一個專門針對時間序列數據的序列到序列模型，並用一個在頻域中實現表示學習的新型自適應譜層對其進行了擴充。為了訓練我們的模型，我們開發了一個拍打式機翼系統，該系統同時使用高速相機測量機翼的空氣動力和其 3D 運動。我們在一個不同的流動狀態下拍打機翼的另一個開源數據集上展示了我們系統的性能。結果表明，與更複雜的基於Transformer的最先進模型相比，性能優異，在測試數據集中損失中值改進了 11%。此外，我們的模型顯示出優異的推理時間，使其適用於機載機器人控制。我們的開源數據和框架可以改進受複雜動態支配的系統的建模和實時控制，從仿生機器人到生物醫學設備。</paragraph>

##### **Language Agents as Digital Representatives in Collective Decision-Making**
2502.09369v1 by Daniel Jarrett, Miruna Pîslar, Michiel A. Bakker, Michael Henry Tessler, Raphael Köster, Jan Balaguer, Romuald Elie, Christopher Summerfield, Andrea Tacchetti

Consider the process of collective decision-making, in which a group of
individuals interactively select a preferred outcome from among a universe of
alternatives. In this context, "representation" is the activity of making an
individual's preferences present in the process via participation by a proxy
agent -- i.e. their "representative". To this end, learned models of human
behavior have the potential to fill this role, with practical implications for
multi-agent scenario studies and mechanism design. In this work, we investigate
the possibility of training \textit{language agents} to behave in the capacity
of representatives of human agents, appropriately expressing the preferences of
those individuals whom they stand for. First, we formalize the setting of
\textit{collective decision-making} -- as the episodic process of interaction
between a group of agents and a decision mechanism. On this basis, we then
formalize the problem of \textit{digital representation} -- as the simulation
of an agent's behavior to yield equivalent outcomes from the mechanism.
Finally, we conduct an empirical case study in the setting of
\textit{consensus-finding} among diverse humans, and demonstrate the
feasibility of fine-tuning large language models to act as digital
representatives.

摘要：考慮集體決策的過程，其中一群個人互動式地從一系列備選方案中選擇一個偏好的結果。在此脈絡中，「代表」是透過代理人（即他們的「代表」）參與，讓個人的偏好出現在這個過程中的活動。為此，人類行為的學習模型有可能填補這個角色，對多重代理人情境研究和機制設計具有實際意義。在這項工作中，我們探討訓練「語言代理人」的可能性，以代表人類代理人的身分行事，適當地表達他們所代表的那些個人的偏好。首先，我們將「集體決策」的設定形式化，作為一群代理人與決策機制之間互動的間歇性過程。在此基礎上，我們接著將「數位代表」的問題形式化，作為模擬代理人的行為，從機制中產生等效結果。最後，我們在多元人類的「共識尋求」設定中進行一個實證個案研究，並展示微調大型語言模型以作為數位代表的可行性。

##### **Neural Spatiotemporal Point Processes: Trends and Challenges**
2502.09341v1 by Sumantrak Mukherjee, Mouad Elhamdi, George Mohler, David A. Selby, Yao Xie, Sebastian Vollmer, Gerrit Grossmann

Spatiotemporal point processes (STPPs) are probabilistic models for events
occurring in continuous space and time. Real-world event data often exhibit
intricate dependencies and heterogeneous dynamics. By incorporating modern deep
learning techniques, STPPs can model these complexities more effectively than
traditional approaches. Consequently, the fusion of neural methods with STPPs
has become an active and rapidly evolving research area. In this review, we
categorize existing approaches, unify key design choices, and explain the
challenges of working with this data modality. We further highlight emerging
trends and diverse application domains. Finally, we identify open challenges
and gaps in the literature.

摘要：時空點過程 (STPP) 是事件在連續時空發生的機率模型。真實世界的事件資料通常會展現錯綜複雜的依賴關係和異質動態。透過結合現代深度學習技術，STPP 可以比傳統方法更有效地模擬這些複雜性。因此，神經方法與 STPP 的融合已成為一個活躍且快速發展的研究領域。在本篇評論中，我們對現有方法進行分類、統一關鍵設計選擇，並說明處理這種資料模式的挑戰。我們進一步強調新興趨勢和多樣化的應用領域。最後，我們找出文獻中的開放性挑戰和空白。

##### **Graph Diffusion Network for Drug-Gene Prediction**
2502.09335v1 by Jiayang Wu, Wensheng Gan, Philip S. Yu

Predicting drug-gene associations is crucial for drug development and disease
treatment. While graph neural networks (GNN) have shown effectiveness in this
task, they face challenges with data sparsity and efficient contrastive
learning implementation. We introduce a graph diffusion network for drug-gene
prediction (GDNDGP), a framework that addresses these limitations through two
key innovations. First, it employs meta-path-based homogeneous graph learning
to capture drug-drug and gene-gene relationships, ensuring similar entities
share embedding spaces. Second, it incorporates a parallel diffusion network
that generates hard negative samples during training, eliminating the need for
exhaustive negative sample retrieval. Our model achieves superior performance
on the DGIdb 4.0 dataset and demonstrates strong generalization capability on
tripartite drug-gene-disease networks. Results show significant improvements
over existing methods in drug-gene prediction tasks, particularly in handling
complex heterogeneous relationships. The source code is publicly available at
https://github.com/csjywu1/GDNDGP.

摘要：預測藥物基因關聯對藥物開發和疾病治療至關重要。雖然圖神經網路 (GNN) 已顯示在這個任務中的有效性，但它們在資料稀疏性和高效對比學習實作方面面臨挑戰。我們引入了一個用於藥物基因預測的圖擴散網路 (GDNDGP)，這是一個透過兩項關鍵創新來解決這些限制的框架。首先，它採用基於元路徑的同質圖學習來捕捉藥物-藥物和基因-基因關係，確保類似實體共享嵌入空間。其次，它整合了一個並行擴散網路，在訓練期間產生困難的負面樣本，消除了對詳盡負面樣本擷取的需求。我們的模型在 DGIdb 4.0 資料集上取得了卓越的效能，並在三方藥物-基因-疾病網路中展現強大的概化能力。結果顯示在藥物基因預測任務中，相較於現有方法有顯著的進步，特別是在處理複雜的異質關係方面。原始碼已公開於 https://github.com/csjywu1/GDNDGP。

##### **Beyond English: The Impact of Prompt Translation Strategies across Languages and Tasks in Multilingual LLMs**
2502.09331v1 by Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty

Despite advances in the multilingual capabilities of Large Language Models
(LLMs) across diverse tasks, English remains the dominant language for LLM
research and development. So, when working with a different language, this has
led to the widespread practice of pre-translation, i.e., translating the task
prompt into English before inference. Selective pre-translation, a more
surgical approach, focuses on translating specific prompt components. However,
its current use is sporagic and lacks a systematic research foundation.
Consequently, the optimal pre-translation strategy for various multilingual
settings and tasks remains unclear. In this work, we aim to uncover the optimal
setup for pre-translation by systematically assessing its use. Specifically, we
view the prompt as a modular entity, composed of four functional parts:
instruction, context, examples, and output, either of which could be translated
or not. We evaluate pre-translation strategies across 35 languages covering
both low and high-resource languages, on various tasks including Question
Answering (QA), Natural Language Inference (NLI), Named Entity Recognition
(NER), and Abstractive Summarization. Our experiments show the impact of
factors as similarity to English, translation quality and the size of
pre-trained data, on the model performance with pre-translation. We suggest
practical guidelines for choosing optimal strategies in various multilingual
settings.

摘要：儘管大型語言模型 (LLM) 在各種任務中的多語言能力有進步，英語仍然是 LLM 研究和開發的主導語言。因此，在使用不同語言時，這導致了預翻譯的廣泛實務，即在推理之前將任務提示翻譯成英語。選擇性預翻譯是一種更精準的方法，專注於翻譯特定提示組成部分。然而，目前的使用是零星的，缺乏系統性的研究基礎。因此，各種多語言設定和任務的最佳預翻譯策略仍不清楚。在這項工作中，我們旨在透過系統性評估預翻譯的使用，找出其最佳設定。具體來說，我們將提示視為一個模組化實體，由四個功能部分組成：說明、背景、範例和輸出，其中任何一個都可以翻譯或不翻譯。我們在 35 種語言中評估預翻譯策略，涵蓋低資源語言和高資源語言，以及各種任務，包括問答 (QA)、自然語言推理 (NLI)、命名實體識別 (NER) 和抽象摘要。我們的實驗顯示了與英語的相似性、翻譯品質和預訓練資料大小等因素對預翻譯模型效能的影響。我們建議在各種多語言設定中選擇最佳策略的實用指南。

##### **A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis**
2502.09316v1 by Kentaro Imajo, Masanori Hirano, Shuji Suzuki, Hiroaki Mikami

Evaluating the open-ended text generation of large language models (LLMs) is
challenging because of the lack of a clear ground truth and the high cost of
human or LLM-based assessments. We propose a novel benchmark that evaluates
LLMs using n-gram statistics and rules, without relying on human judgement or
LLM-as-a-judge approaches. Using 50 question and reference answer sets, we
introduce three new metrics based on n-grams and rules: Fluency, Truthfulness,
and Helpfulness. Our benchmark strongly correlates with GPT-4o-based
evaluations while requiring significantly fewer computational resources,
demonstrating its effectiveness as a scalable alternative for assessing LLMs'
open-ended generation capabilities.

摘要：評估大型語言模型 (LLM) 的開放式文字生成具有挑戰性，因為缺乏明確的基礎真實性，以及人工或基於 LLM 的評估成本高昂。我們提出一個新基準，使用 n-gram 統計和規則來評估 LLM，而不依賴於人工判斷或 LLM 作為評審的方法。使用 50 個問題和參考答案集，我們基於 n-gram 和規則引入了三項新指標：流暢度、真實性和有幫助性。我們的基準與基於 GPT-4o 的評估密切相關，同時需要明顯更少的計算資源，證明了其作為評估 LLM 的開放式生成能力的可擴充替代方案的有效性。

##### **When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models**
2502.09307v1 by Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant

Modern Large Language Models (LLMs) have shown human-like abilities in many
language tasks, sparking interest in comparing LLMs' and humans' language
processing. In this paper, we conduct a detailed comparison of the two on a
sentence comprehension task using garden-path constructions, which are
notoriously challenging for humans. Based on psycholinguistic research, we
formulate hypotheses on why garden-path sentences are hard, and test these
hypotheses on human participants and a large suite of LLMs using comprehension
questions. Our findings reveal that both LLMs and humans struggle with specific
syntactic complexities, with some models showing high correlation with human
comprehension. To complement our findings, we test LLM comprehension of
garden-path constructions with paraphrasing and text-to-image generation tasks,
and find that the results mirror the sentence comprehension question results,
further validating our findings on LLM understanding of these constructions.

摘要：現代大型語言模型（LLM）在許多語言任務中展現出類似人類的能力，引發了比較 LLM 與人類語言處理的興趣。在本文中，我們使用對人類來說極具挑戰的花園路徑結構，對這兩者進行了詳細比較，以進行句子理解任務。根據心理語言學研究，我們制定了關於為什麼花園路徑句子困難的假設，並使用理解問題對人類參與者和大量 LLM 測試這些假設。我們的研究結果表明，LLM 和人類都難以應付特定的句法複雜性，其中一些模型與人類理解力高度相關。為了補充我們的研究結果，我們測試了 LLM 對花園路徑結構的理解，並進行了改寫和文字轉換為圖像的生成任務，並發現結果反映了句子理解問題的結果，進一步驗證了我們對 LLM 理解這些結構的研究結果。

##### **Indeterminacy in Affective Computing: Considering Meaning and Context in Data Collection Practices**
2502.09294v1 by Bernd Dudzik, Tiffany Matej Hrkalovic, Chenxu Hao, Chirag Raman, Masha Tsfasman

Automatic Affect Prediction (AAP) uses computational analysis of input data
such as text, speech, images, and physiological signals to predict various
affective phenomena (e.g., emotions or moods). These models are typically
constructed using supervised machine-learning algorithms, which rely heavily on
labeled training datasets. In this position paper, we posit that all AAP
training data are derived from human Affective Interpretation Processes,
resulting in a form of Affective Meaning. Research on human affect indicates a
form of complexity that is fundamental to such meaning: it can possess what we
refer to here broadly as Qualities of Indeterminacy (QIs) - encompassing
Subjectivity (meaning depends on who is interpreting), Uncertainty (lack of
confidence regarding meanings' correctness), Ambiguity (meaning contains
mutually exclusive concepts) and Vagueness (meaning is situated at different
levels in a nested hierarchy). Failing to appropriately consider QIs leads to
results incapable of meaningful and reliable predictions. Based on this
premise, we argue that a crucial step in adequately addressing indeterminacy in
AAP is the development of data collection practices for modeling corpora that
involve the systematic consideration of 1) a relevant set of QIs and 2) context
for the associated interpretation processes. To this end, we are 1) outlining a
conceptual model of AIPs and the QIs associated with the meaning these produce
and a conceptual structure of relevant context, supporting understanding of its
role. Finally, we use our framework for 2) discussing examples of
context-sensitivity-related challenges for addressing QIs in data collection
setups. We believe our efforts can stimulate a structured discussion of both
the role of aspects of indeterminacy and context in research on AAP, informing
the development of better practices for data collection and analysis.

摘要：自動影響預測 (AAP) 使用輸入資料的運算分析，例如文字、語音、影像和生理訊號，來預測各種情感現象（例如情緒或心情）。這些模型通常使用監督式機器學習演算法建構，而這些演算法高度依賴標籤訓練資料集。在此立場文件中，我們主張所有 AAP 訓練資料都是從人類的情感詮釋過程中衍生而來的，進而形成一種情感意義。對人類情感的研究指出，這種複雜性是此種意義的基本要素：它可能具備我們在此廣泛稱之為不確定性品質 (QI)，包括主觀性（意義取決於詮釋者）、不確定性（對於意義正確性的信心不足）、歧義性（意義包含相互排斥的概念）和模糊性（意義位於嵌套層級的不同層級）。未能適當地考量 QI 會導致無法進行有意義且可靠預測的結果。基於此前提，我們主張，在 AAP 中適當地處理不確定性的關鍵步驟，是針對建模語料庫制定資料收集實務，其中涉及系統性地考量 1) 一組相關的 QI，以及 2) 相關詮釋過程的脈絡。為此，我們 1) 概述了 AIP 的概念模型，以及與這些 AIP 所產生的意義相關的 QI，以及相關脈絡的概念結構，支持對其角色的理解。最後，我們使用我們的架構 2) 討論了在資料收集設定中處理 QI 時，與脈絡敏感性相關的挑戰範例。我們相信我們的努力可以激勵對不確定性和脈絡面向在 AAP 研究中扮演的角色進行結構化的討論，為資料收集和分析的最佳實務發展提供資訊。

##### **SparQLe: Speech Queries to Text Translation Through LLMs**
2502.09284v1 by Amirbek Djanibekov, Hanan Aldarmaki

With the growing influence of Large Language Models (LLMs), there is
increasing interest in integrating speech representations with them to enable
more seamless multi-modal processing and speech understanding. This study
introduces a novel approach that leverages self-supervised speech
representations in combination with instruction-tuned LLMs for speech-to-text
translation. The proposed approach leverages a modality adapter to align
extracted speech features with instruction-tuned LLMs using English-language
data. Our experiments demonstrate that this method effectively preserves the
semantic content of the input speech and serves as an effective bridge between
self-supervised speech models and instruction-tuned LLMs, offering a promising
solution for various speech understanding applications.

摘要：隨著大型語言模型（LLM）影響力逐漸擴大，將語音表徵與其整合，以實現更順暢的多模態處理和語音理解，已引起越來越多的興趣。本研究提出了一種新穎的方法，該方法利用自監督語音表徵，結合指令調整的 LLM，進行語音轉文字翻譯。所提出的方法利用模態適配器，使用英語語言資料，將提取的語音特徵與指令調整的 LLM 對齊。我們的實驗證明，此方法有效地保留了輸入語音的語義內容，並作為自監督語音模型和指令調整的 LLM 之間的有效橋樑，為各種語音理解應用程式提供了一個有前景的解決方案。

##### **LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection**
2502.09271v1 by Wenlun Zhang, Enyan Dai, Kentaro Yoshioka

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
modeling data with graph structures, yet recent research reveals their
susceptibility to adversarial attacks. Traditional attack methodologies, which
rely on manipulating the original graph or adding links to artificially created
nodes, often prove impractical in real-world settings. This paper introduces a
novel adversarial scenario involving the injection of an isolated subgraph to
deceive both the link recommender and the node classifier within a GNN system.
Specifically, the link recommender is mislead to propose links between targeted
victim nodes and the subgraph, encouraging users to unintentionally establish
connections and that would degrade the node classification accuracy, thereby
facilitating a successful attack. To address this, we present the LiSA
framework, which employs a dual surrogate model and bi-level optimization to
simultaneously meet two adversarial objectives. Extensive experiments on
real-world datasets demonstrate the effectiveness of our method.

摘要：圖形神經網路 (GNN) 已展現出在對具有圖形結構的資料進行建模方面的卓越能力，但最近的研究揭露了它們容易受到對抗性攻擊的影響。傳統的攻擊方法依賴於操縱原始圖形或將連結新增至人工建立的節點，在真實世界設定中通常被證明不切實際。本文介紹了一種新穎的對抗性場景，涉及注入一個孤立的子圖形，以欺騙 GNN 系統中的連結推薦器和節點分類器。具體來說，連結推薦器被誤導為在目標受害節點和子圖形之間提出連結，鼓勵使用者無意間建立連結，這將降低節點分類準確度，從而促成攻擊成功。為了解決這個問題，我們提出了 LiSA 框架，它採用雙重代理模型和雙層最佳化，以同時滿足兩個對抗性目標。對真實世界資料集進行的廣泛實驗證明了我們方法的有效性。

##### **AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection**
2502.09254v1 by Hezhe Qiao, Chaoxi Niu, Ling Chen, Guansong Pang

Graph anomaly detection (GAD) aims to identify abnormal nodes that differ
from the majority of the nodes in a graph, which has been attracting
significant attention in recent years. Existing generalist graph models have
achieved remarkable success in different graph tasks but struggle to generalize
to the GAD task. This limitation arises from their difficulty in learning
generalized knowledge for capturing the inherently infrequent, irregular and
heterogeneous abnormality patterns in graphs from different domains. To address
this challenge, we propose AnomalyGFM, a GAD-oriented graph foundation model
that supports zero-shot inference and few-shot prompt tuning for GAD in diverse
graph datasets. One key insight is that graph-agnostic representations for
normal and abnormal classes are required to support effective zero/few-shot GAD
across different graphs. Motivated by this, AnomalyGFM is pre-trained to align
data-independent, learnable normal and abnormal class prototypes with node
representation residuals (i.e., representation deviation of a node from its
neighbors). The residual features essentially project the node information into
a unified feature space where we can effectively measure the abnormality of
nodes from different graphs in a consistent way. This provides a driving force
for the learning of graph-agnostic, discriminative prototypes for the normal
and abnormal classes, which can be used to enable zero-shot GAD on new graphs,
including very large-scale graphs. If there are few-shot labeled normal nodes
available in the new graphs, AnomalyGFM can further support prompt tuning to
leverage these nodes for better adaptation. Comprehensive experiments on 11
widely-used GAD datasets with real anomalies, demonstrate that AnomalyGFM
significantly outperforms state-of-the-art competing methods under both zero-
and few-shot GAD settings.

摘要：圖形異常偵測 (GAD) 的目標是找出與圖形中大多數節點不同的異常節點，這在近年來引起了廣泛的關注。現有的通才圖形模型在不同的圖形任務中都取得了顯著的成功，但卻難以推廣到 GAD 任務。這種限制來自於它們難以學習廣泛的知識，用於擷取來自不同領域圖形中固有的罕見、不規則和異質異常模式。為了應對這個挑戰，我們提出了 AnomalyGFM，一個面向 GAD 的圖形基礎模型，它支援零次學習推論和少次提示調整，用於在不同的圖形資料集中進行 GAD。一個關鍵見解是，需要圖形不可知的正常和異常類別表示，以支援跨不同圖形的有效零次/少次 GAD。受此啟發，AnomalyGFM 被預先訓練以將與資料無關的可學習正常和異常類別原型與節點表示殘差（即節點與其鄰居的表示偏差）對齊。殘差特徵基本上將節點資訊投射到一個統一的特徵空間中，在這個空間中，我們可以有效地測量來自不同圖形的節點異常，並且方式一致。這為學習正常和異常類別的圖形不可知、有區別的原型提供了驅動力，這些原型可用於對新的圖形（包括非常大規模的圖形）啟用零次 GAD。如果新的圖形中有少量的標籤正常節點，AnomalyGFM 可以進一步支援提示調整，以利用這些節點進行更好的適應。在 11 個廣泛使用的具有真實異常值的 GAD 資料集上的綜合實驗表明，在零次和少次 GAD 設定下，AnomalyGFM 明顯優於最先進的競爭方法。

##### **The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**
2502.09247v1 by Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing

Joint entity-relation extraction is a critical task in transforming
unstructured or semi-structured text into triplets, facilitating the
construction of large-scale knowledge graphs, and supporting various downstream
applications. Despite its importance, research on Chinese text, particularly
with complex semantics in specialized domains like medicine, remains limited.
To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions
dataset designed to capture the intricacies of medical text. Leveraging the
strengths of attention mechanisms in capturing long-range dependencies, we
propose the SEA module, which enhances the extraction of complex contextual
semantic information, thereby improving entity recognition and relation
extraction. Additionally, to address the inefficiencies of existing methods in
facilitating information exchange between entity recognition and relation
extraction, we present an interactive fusion representation module. This module
employs Cross Attention for bidirectional information exchange between the
tasks and further refines feature extraction through BiLSTM. Experimental
results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that
our model exhibits strong generalization capabilities. On the CH-DDI dataset,
our model achieves an F1-score of 96.73% for entity recognition and 78.43% for
relation extraction. On the CoNLL04 dataset, it attains an entity recognition
precision of 89.54% and a relation extraction accuracy of 71.64%.

摘要：聯合實體關係抽取是將非結構化或半結構化文字轉換為三元組的重要任務，有助於建構大規模知識圖譜，並支援各種下游應用程式。儘管其重要性，但針對中文文本的研究，特別是醫學等專業領域中具有複雜語義的研究仍十分有限。為了解決這個差距，我們引入了 CH-DDI，一個中文藥物-藥物交互作用資料集，旨在擷取醫學文本的複雜性。利用注意力機制在擷取長程依賴關係方面的優勢，我們提出了 SEA 模組，增強了複雜脈絡語義資訊的抽取，從而改進了實體辨識和關係抽取。此外，為了解決現有方法在促進實體辨識和關係抽取之間資訊交換方面的低效率問題，我們提出了互動式融合表示模組。此模組採用交叉注意力，在任務之間進行雙向資訊交換，並透過 BiLSTM 進一步精煉特徵抽取。在我們的 CH-DDI 資料集和公開的 CoNLL04 資料集上的實驗結果表明，我們的模型展現出強大的泛化能力。在 CH-DDI 資料集上，我們的模型在實體辨識方面達到了 96.73% 的 F1 分數，在關係抽取方面達到了 78.43% 的 F1 分數。在 CoNLL04 資料集上，它在實體辨識方面達到了 89.54% 的準確度，在關係抽取方面達到了 71.64% 的準確度。

##### **You Do Not Fully Utilize Transformer's Representation Capacity**
2502.09245v1 by Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov

In contrast to RNNs, which compress previous tokens into a single hidden
state, Transformers can attend to all previous tokens directly. However,
standard Transformers only use representations from the immediately preceding
layer. In this paper, we show that this design choice causes representation
collapse and leads to suboptimal performance. To address this issue, we
introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that
preserves the model's overall memory footprint while expanding its
representational capacity by allowing access to hidden states from earlier
layers. Through extensive experiments across various architectures and
different lookup mechanisms, we demonstrate consistent performance improvements
on a wide range of tasks. Moreover, our analysis of the learned representation
dynamics and our exploration of depthwise circuits reveal how LIMe integrates
information across layers, pointing to promising directions for future
research.

摘要：與將先前符號壓縮成單一隱藏狀態的遞迴神經網路不同，Transformer 可以直接關注所有先前的符號。然而，標準 Transformer 僅使用緊鄰前一層的表示。在本文中，我們說明此設計選擇會導致表示崩潰，並導致次優效能。為了解決此問題，我們引入了「層整合式記憶體」(LIMe)，這是一種簡單但強大的方法，可在擴充表示能力的同時，保留模型的整體記憶體使用量，方法是允許存取來自較早層的隱藏狀態。透過各種架構和不同查詢機制的廣泛實驗，我們展示了在各種任務上的一致效能提升。此外，我們對已學習表示動態的分析和對深度電路的探討，揭示了 LIMe 如何整合跨層資訊，並指出未來研究有望發展的方向。

##### **From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**
2502.09242v1 by Lukas Buess, Matthias Keicher, Nassir Navab, Andreas Maier, Soroosh Tayebi Arasteh

Generative artificial intelligence (AI) models, such as diffusion models and
OpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy
and automating clinical workflows. The field has advanced rapidly, evolving
from text-only large language models for tasks such as clinical documentation
and decision support to multimodal AI systems capable of integrating diverse
data modalities, including imaging, text, and structured data, within a single
model. The diverse landscape of these technologies, along with rising interest,
highlights the need for a comprehensive review of their applications and
potential. This scoping review explores the evolution of multimodal AI,
highlighting its methods, applications, datasets, and evaluation in clinical
settings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,
IEEE Xplore, and Web of Science, prioritizing recent studies published up to
the end of 2024. After rigorous screening, 144 papers were included, revealing
key trends and challenges in this dynamic field. Our findings underscore a
shift from unimodal to multimodal approaches, driving innovations in diagnostic
support, medical report generation, drug discovery, and conversational AI.
However, critical challenges remain, including the integration of heterogeneous
data types, improving model interpretability, addressing ethical concerns, and
validating AI systems in real-world clinical settings. This review summarizes
the current state of the art, identifies critical gaps, and provides insights
to guide the development of scalable, trustworthy, and clinically impactful
multimodal AI solutions in healthcare.

摘要：生成式人工智能 (AI) 模型，例如扩散模型和 OpenAI 的 ChatGPT，通过提高诊断准确性和自动化临床工作流程，正在改变医学领域。该领域已迅速发展，从用于临床文件编制和决策支持等任务的纯文本大型语言模型，发展到能够在单个模型中整合包括影像、文本和结构化数据在内的多种数据方式的多模态 AI 系统。这些技术的多样化格局以及日益增长的兴趣，凸显了全面审查其应用和潜力的必要性。本范围审查探讨了多模态 AI 的演变，重点介绍了其方法、应用、数据集和在临床环境中的评估。遵循 PRISMA-ScR 指南，我们系统地查询了 PubMed、IEEE Xplore 和 Web of Science，优先考虑截至 2024 年底发表的最新研究。经过严格筛选，纳入了 144 篇论文，揭示了这一充满活力的领域的趋势和挑战。我们的研究结果强调了从单模态方法向多模态方法的转变，推动了诊断支持、医疗报告生成、药物发现和会话式 AI 的创新。然而，关键挑战仍然存在，包括异构数据类型的整合、提高模型可解释性、解决伦理问题以及在现实世界的临床环境中验证 AI 系统。本综述总结了当前的最新技术，确定了关键差距，并提供了见解，以指导在医疗保健领域开发可扩展、可信赖且具有临床影响力的多模态 AI 解决方案。

##### **Reliable Conversational Agents under ASP Control that Understand Natural Language**
2502.09237v1 by Yankai Zeng

Efforts have been made to make machines converse like humans in the past few
decades. The recent techniques of Large Language Models (LLMs) make it possible
to have human-like conversations with machines, but LLM's flaws of lacking
understanding and reliability are well documented. We believe that the best way
to eliminate this problem is to use LLMs only as parsers to translate text to
knowledge and vice versa and carry out the conversation by reasoning over this
knowledge using the answer set programming. I have been developing a framework
based on LLMs and ASP to realize reliable chatbots that "understand" human
conversation. This framework has been used to develop task-specific chatbots as
well as socialbots. My future research is focused on making these chatbots
scalable and trainable.

摘要：在過去的幾十年裡，人們一直努力讓機器像人類一樣對話。大型語言模型 (LLM) 的最新技術讓與機器進行類人對話成為可能，但 LLM 缺乏理解力和可靠性的缺陷已被充分記錄。我們相信消除這個問題的最佳方法是僅將 LLM 作為解析器，將文字轉換為知識，反之亦然，並使用答案集程式設計對此知識進行推理來進行對話。我一直在開發一個基於 LLM 和 ASP 的框架，以實現「理解」人類對話的可靠聊天機器人。這個框架已被用於開發特定任務的聊天機器人以及社交機器人。我未來的研究重點在於讓這些聊天機器人具有可擴充性和可訓練性。

##### **Commonsense Reasoning-Aided Autonomous Vehicle Systems**
2502.09233v1 by Keegan Kimbrell

Autonomous Vehicle (AV) systems have been developed with a strong reliance on
machine learning techniques. While machine learning approaches, such as deep
learning, are extremely effective at tasks that involve observation and
classification, they struggle when it comes to performing higher level
reasoning about situations on the road. This research involves incorporating
commonsense reasoning models that use image data to improve AV systems. This
will allow AV systems to perform more accurate reasoning while also making them
more adjustable, explainable, and ethical. This paper will discuss the findings
so far and motivate its direction going forward.

摘要：自動駕駛車輛 (AV) 系統的開發高度依賴機器學習技術。儘管機器學習方法（例如深度學習）在涉及觀察和分類的任務中非常有效，但它們在對路況進行更高層級推理時會遇到困難。本研究涉及整合使用影像資料的常識推理模型，以改善 AV 系統。這將使 AV 系統能夠執行更準確的推理，同時也讓它們更具可調整性、可解釋性和道德性。本文將探討迄今為止的發現，並說明其未來的發展方向。

##### **Logical foundations of Smart Contracts**
2502.09232v1 by Kalonji Kalala

Nowadays, sophisticated domains are emerging which require appropriate
formalisms to be specified accurately in order to reason about them. One such
domain is constituted of smart contracts that have emerged in cyber physical
systems as a way of enforcing formal agreements between components of these
systems. Smart contracts self-execute to run and share business processes
through blockchain, in decentralized systems, with many different participants.
Legal contracts are in many cases complex documents, with a number of
exceptions, and many subcontracts. The implementation of smart contracts based
on legal contracts is a long and laborious task, that needs to include all
actions, procedures, and the effects of actions related to the execution of the
contract. An ongoing open problem in this area is to formally account for smart
contracts using a uniform and somewhat universal formalism. This thesis
proposes logical foundations to smart contracts using the Situation Calculus, a
logic for reasoning about actions. Situation Calculus is one of the prominent
logic-based artificial intelligence approaches that provides enough logical
mechanism to specify and implement dynamic and complex systems such as
contracts. Situation Calculus is suitable to show how worlds dynamically
change. Smart contracts are going to be implement with Golog (written en
Prolog), a Situation Calculus-based programming language for modeling complex
and dynamic behaviors.

摘要：如今，正在出现需要适当形式化来准确指定以对其进行推理的复杂领域。此类领域之一由在网络物理系统中出现的智能合约构成，作为强制执行这些系统组件之间正式协议的一种方式。智能合约自执行以在去中心化系统中通过区块链运行和共享业务流程，并有许多不同的参与者。法律合约在许多情况下是复杂的文档，有许多例外和许多分包合同。基于法律合约实施智能合约是一项漫长而艰巨的任务，需要包括所有操作、程序以及与执行合约相关的操作效果。该领域的持续开放问题是使用统一且某种程度上通用的形式化来正式说明智能合约。本论文提出了使用情景演算（一种用于推理操作的逻辑）为智能合约提供逻辑基础。情景演算是基于逻辑的人工智能方法之一，提供了足够的逻辑机制来指定和实现动态且复杂的系统，例如合约。情景演算适用于展示世界如何动态变化。智能合约将使用 Golog（以 Prolog 编写的）实现，这是一种基于情景演算的编程语言，用于建模复杂且动态的行为。

##### **Relating Answer Set Programming and Many-sorted Logics for Formal Verification**
2502.09230v1 by Zachary Hansen

Answer Set Programming (ASP) is an important logic programming paradigm
within the field of Knowledge Representation and Reasoning. As a concise,
human-readable, declarative language, ASP is an excellent tool for developing
trustworthy (especially, artificially intelligent) software systems. However,
formally verifying ASP programs offers some unique challenges, such as
  1. a lack of modularity (the meanings of rules are difficult to define in
isolation from the enclosing program),
  2. the ground-and-solve semantics (the meanings of rules are dependent on the
input data with which the program is grounded), and
  3. limitations of existing tools.
  My research agenda has been focused on addressing these three issues with the
intention of making ASP verification an accessible, routine task that is
regularly performed alongside program development. In this vein, I have
investigated alternative semantics for ASP based on translations into the logic
of here-and-there and many-sorted first-order logic. These semantics promote a
modular understanding of logic programs, bypass grounding, and enable us to use
automated theorem provers to automatically verify properties of programs.

摘要：<paragraph>答案集程式設計 (ASP) 是知識表徵與推理領域中一個重要的邏輯程式設計範式。ASP 作為一種簡潔、人類可讀、宣告式的語言，是開發值得信賴的 (特別是人工智慧) 軟體系統的絕佳工具。然而，正式驗證 ASP 程式提供了一些獨特的挑戰，例如
  1. 缺乏模組化 (規則的含義難以與封閉程式隔離定義)，
  2. 基礎與求解語意 (規則的含義取決於程式基礎的輸入資料)，以及
  3. 現有工具的限制。
  我的研究議程一直專注於解決這三個問題，目的是讓 ASP 驗證成為一個可存取的、例行任務，並在程式開發過程中定期執行。在這個脈絡下，我研究了基於翻譯成此處和彼處邏輯以及多種排序一階邏輯的 ASP 替代語意。這些語意促進了邏輯程式的模組化理解，繞過基礎，並使我們能夠使用自動化定理證明器自動驗證程式的屬性。</paragraph>

##### **Computational methods for Dynamic Answer Set Programming**
2502.09228v1 by Susana Hahn

In our daily lives and industrial settings, we often encounter dynamic
problems that require reasoning over time and metric constraints. These include
tasks such as scheduling, routing, and production sequencing. Dynamic logics
have traditionally addressed these needs but often lack the flexibility and
integration required for comprehensive problem modeling. This research aims to
extend Answer Set Programming (ASP), a powerful declarative problem-solving
approach, to handle dynamic domains effectively. By integrating concepts from
dynamic, temporal, and metric logics into ASP, we seek to develop robust
systems capable of modeling complex dynamic problems and performing efficient
reasoning tasks, thereby enhancing ASPs applicability in industrial contexts.

摘要：在我們的日常生活和工業環境中，我們經常會遇到動態問題，需要隨著時間和公制約束進行推理。這些問題包括排程、路由和生產順序等任務。動態邏輯傳統上解決了這些需求，但通常缺乏全面問題建模所需的靈活性與整合性。本研究旨在擴展強大的宣告式問題解決方法「Answer Set Programming (ASP)」，以有效處理動態領域。透過將動態、時態和公制邏輯的概念整合到 ASP 中，我們尋求開發強健的系統，能夠建模複雜的動態問題並執行有效的推理任務，進而增強 ASP 在工業環境中的適用性。

##### **Generating Causally Compliant Counterfactual Explanations using ASP**
2502.09226v1 by Sopam Dasgupta

This research is focused on generating achievable counterfactual
explanations. Given a negative outcome computed by a machine learning model or
a decision system, the novel CoGS approach generates (i) a counterfactual
solution that represents a positive outcome and (ii) a path that will take us
from the negative outcome to the positive one, where each node in the path
represents a change in an attribute (feature) value. CoGS computes paths that
respect the causal constraints among features. Thus, the counterfactuals
computed by CoGS are realistic. CoGS utilizes rule-based machine learning
algorithms to model causal dependencies between features. The paper discusses
the current status of the research and the preliminary results obtained.

摘要：本研究重點在於產生可實現的反事實解釋。給定由機器學習模型或決策系統計算出的負面結果，創新的 CoGS 方法會產生 (i) 代表正面結果的反事實解，以及 (ii) 一條將我們從負面結果帶到正面結果的途徑，其中途徑中的每個節點代表屬性 (特徵) 值的變化。CoGS 計算出符合特徵之間因果關係的途徑。因此，CoGS 計算出的反事實是切合實際的。CoGS 利用基於規則的機器學習演算法來建模特徵之間的因果關係。本文探討了研究的現況和獲得的初步結果。

##### **Order-Sorted Intensional Logic: Expressing Subtyping Polymorphism with Typing Assertions and Quantification over Concepts**
2502.09224v1 by Đorđe Marković, Marc Denecker

Subtyping, also known as subtype polymorphism, is a concept extensively
studied in programming language theory, delineating the substitutability
relation among datatypes. This property ensures that programs designed for
supertype objects remain compatible with their subtypes.
  In this paper, we explore the capability of order-sorted logic for utilizing
these ideas in the context of Knowledge Representation. We recognize two
fundamental limitations: First, the inability of this logic to address the
concept rather than the value of non-logical symbols, and second, the lack of
language constructs for constraining the type of terms. Consequently, we
propose guarded order-sorted intensional logic, where guards are language
constructs for annotating typing information and intensional logic provides
support for quantification over concepts.

摘要：子類型化，也稱為子類型多態性，是一個在程式語言理論中廣泛研究的概念，用於描述資料類型之間的可替換關係。此特性可確保為超類型物件設計的程式與其子類型相容。
在本文中，我們探討了使用排序邏輯在知識表徵中運用這些想法的能力。我們發現了兩個基本限制：首先，此邏輯無法處理非邏輯符號的概念而非值，其次，缺乏約束項類型的語言結構。因此，我們提出了受保護的排序邏輯，其中保護是註解類型資訊的語言結構，而內涵邏輯則支援對概念量化。

##### **ASP-driven User-interaction with Clinguin**
2502.09222v1 by Alexander Beiser, Susana Hahn, Torsten Schaub

We present clinguin, a system for ASP-driven user interface design. Clinguin
streamlines the development of user interfaces for ASP developers by letting
them build interactive prototypes directly in ASP, eliminating the need for
separate frontend languages. To this end, clinguin uses a few dedicated
predicates to define user interfaces and the treatment of user-triggered
events. This simple design greatly facilitates the specification of user
interactions with an ASP system, in our case clingo.

摘要：我們提出 clinguin，一個用於 ASP 驅動使用者介面設計的系統。Clinguin 透過讓 ASP 開發人員直接在 ASP 中建立互動式原型，簡化了使用者介面的開發，消除了對個別前端語言的需求。為此，clinguin 使用一些專用的謂詞來定義使用者介面和處理使用者觸發的事件。這個簡單的設計極大地簡化了使用者與 ASP 系統互動的規範，在我們的案例中是 clingo。

##### **Pearce's Characterisation in an Epistemic Domain**
2502.09221v1 by Ezgi Iraz Su

Answer-set programming (ASP) is a successful problem-solving approach in
logic-based AI. In ASP, problems are represented as declarative logic programs,
and solutions are identified through their answer sets. Equilibrium logic (EL)
is a general-purpose nonmonotonic reasoning formalism, based on a monotonic
logic called here-and-there logic. EL was basically proposed by Pearce as a
foundational framework of ASP. Epistemic specifications (ES) are extensions of
ASP-programs with subjective literals. These new modal constructs in the
ASP-language make it possible to check whether a regular literal of ASP is true
in every (or some) answer-set of a program. ES-programs are interpreted by
world-views, which are essentially collections of answer-sets. (Reflexive)
autoepistemic logic is a nonmonotonic formalism, modeling self-belief
(knowledge) of ideally rational agents. A relatively new semantics for ES is
based on a combination of EL and (reflexive) autoepistemic logic. In this
paper, we first propose an overarching framework in the epistemic ASP domain.
We then establish a correspondence between existing (reflexive) (auto)epistemic
equilibrium logics and our easily-adaptable comprehensive framework, building
on Pearce's characterisation of answer-sets as equilibrium models. We achieve
this by extending Ferraris' work on answer sets for propositional theories to
the epistemic case and reveal the relationship between some ES-semantic
proposals.

摘要：<paragraph>答案集程式設計（ASP）是基於邏輯的人工智慧中一種成功的問題解決方法。在 ASP 中，問題表示為宣告式邏輯程式，並透過其答案集來找出解答。平衡邏輯（EL）是一種通用的非單調推理形式主義，基於一種稱為此處和彼處邏輯的單調邏輯。EL 基本是由 Pearce 作為 ASP 的基礎架構所提出。知識規範（ES）是 ASP 程式與主觀文字的延伸。ASP 語言中的這些新模態建構使得可以檢查 ASP 的常規文字是否在程式的每個（或某些）答案集中為真。ES 程式由世界觀來詮釋，其本質上是答案集的集合。（反身）自認識邏輯是一種非單調形式主義，用來建模理想理性主體的自信念（知識）。ES 的一種相對新的語意是基於 EL 和（反身）自認識邏輯的組合。在本文中，我們首先提出一個涵蓋知識 ASP 領域的架構。然後，我們建立現有（反身）（自）認識平衡邏輯與我們容易適應的綜合架構之間的對應關係，建立在 Pearce 將答案集描述為平衡模型的特性之上。我們透過將 Ferraris 在命題理論的答案集上的工作延伸到知識案例，並揭示一些 ES 語義提案之間的關係來達成這一點。</paragraph>

##### **Graphical Conditions for the Existence, Unicity and Number of Regular Models**
2502.09220v1 by Van-Giang Trinh, Belaid Benhamou, Sylvain Soliman, François Fages

The regular models of a normal logic program are a particular type of partial
(i.e. 3-valued) models which correspond to stable partial models with minimal
undefinedness. In this paper, we explore graphical conditions on the dependency
graph of a finite ground normal logic program to analyze the existence, unicity
and number of regular models for the program. We show three main results: 1) a
necessary condition for the existence of non-trivial (i.e. non-2-valued)
regular models, 2) a sufficient condition for the unicity of regular models,
and 3) two upper bounds for the number of regular models based on positive
feedback vertex sets. The first two conditions generalize the finite cases of
the two existing results obtained by You and Yuan (1994) for normal logic
programs with well-founded stratification. The third result is also new to the
best of our knowledge. Key to our proofs is a connection that we establish
between finite ground normal logic programs and Boolean network theory.

摘要：正规模型的常规模型是一种特殊类型的局部模型（即 3 值）模型，它对应于具有最小未定义性的稳定局部模型。在本文中，我们探索了有限接地正规逻辑程序的依赖图上的图形条件，以分析程序的正规模型的存在性、唯一性和数量。我们展示了三个主要结果：1) 非平凡（即非 2 值）正规模型存在的必要条件，2) 正规模型唯一性的充分条件，3) 基于正反馈顶点集的正规模型数目的两个上限。前两个条件概括了 You 和 Yuan (1994) 为具有良好基础分层的正规逻辑程序获得的两个现有结果的有限情况。据我们所知，第三个结果也是新的。我们证明的关键是我们在有限接地正规逻辑程序和布尔网络理论之间建立的联系。

##### **Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**
2502.09218v1 by Flavio Bertini, Alessandro Dal Palù, Federica Zaglio, Francesco Fabiano, Andrea Formisano

This paper presents a complete explainable system that interprets a set of
data, abstracts the underlying features and describes them in a natural
language of choice. The system relies on two crucial stages: (i) identifying
emerging properties from data and transforming them into abstract concepts, and
(ii) converting these concepts into natural language. Despite the impressive
natural language generation capabilities demonstrated by Large Language Models,
their statistical nature and the intricacy of their internal mechanism still
force us to employ these techniques as black boxes, forgoing trustworthiness.
Developing an explainable pipeline for data interpretation would allow
facilitating its use in safety-critical environments like processing medical
information and allowing non-experts and visually impaired people to access
narrated information. To this end, we believe that the fields of knowledge
representation and automated reasoning research could present a valid
alternative. Expanding on prior research that tackled the first stage (i), we
focus on the second stage, named Concept2Text. Being explainable, data
translation is easily modeled through logic-based rules, once again emphasizing
the role of declarative programming in achieving AI explainability. This paper
explores a Prolog/CLP-based rewriting system to interpret concepts-articulated
in terms of classes and relations, plus common knowledge-derived from a generic
ontology, generating natural language text. Its main features include
hierarchical tree rewritings, modular multilingual generation, support for
equivalent variants across semantic, grammar, and lexical levels, and a
transparent rule-based system. We outline the architecture and demonstrate its
flexibility through some examples capable of generating numerous diverse and
equivalent rewritings based on the input concept.

摘要：<paragraph>這篇論文提出了一個完整的可解釋系統，它可以解釋一組資料，抽象出基礎特徵，並以選擇的自然語言描述它們。系統依賴兩個關鍵階段：(i) 從資料中識別新興屬性，並將它們轉換為抽象概念，以及 (ii) 將這些概念轉換為自然語言。儘管大型語言模型展示了令人印象深刻的自然語言生成能力，但它們的統計性質和內部機制的複雜性仍然迫使我們將這些技術用作黑盒子，放棄可信度。開發一個可解釋的資料解釋管道將有助於促進在安全關鍵環境中使用它，例如處理醫療資訊，並允許非專家和視障人士存取敘述資訊。為此，我們相信知識表示和自動推理研究領域可以提出一個有效的替代方案。在擴展解決第一階段 (i) 的先前研究的基礎上，我們專注於第二階段，稱為 Concept2Text。由於具有可解釋性，資料翻譯很容易透過基於邏輯的規則建模，再次強調宣告式程式設計在實現 AI 可解釋性中的作用。本文探討了一個基於 Prolog/CLP 的重寫系統，以解釋概念，這些概念以類別和關係的形式表達，再加上從通用本体衍生的常識，產生自然語言文字。它的主要特點包括階層樹重寫、模組化多語言生成、支援語義、語法和詞彙層面的等效變體，以及一個透明的基於規則的系統。我們概述了架構，並透過一些範例展示了它的靈活性，這些範例能夠根據輸入概念生成許多不同的等效重寫。</paragraph>

##### **Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for Autonomous Vehicles**
2502.09216v1 by Galileo Sartor, Adam Wyner, Giuseppe Contissa

In this paper, we present a modular system for representing and reasoning
with legal aspects of traffic rules for autonomous vehicles. We focus on a
subset of the United Kingdom's Highway Code (HC) related to junctions. As human
drivers and automated vehicles (AVs) will interact on the roads, especially in
urban environments, we claim that an accessible, unitary, high-level
computational model should exist and be applicable to both users. Autonomous
vehicles introduce a shift in liability that should not bring disadvantages or
increased burden on human drivers. We develop a system "in silico" of the
model. The proposed system is built of three main components: a natural
language interface, using Logical English, which encodes the rules; an internal
representation of the rules in Prolog; and an multi-agent-based simulation
environment, built in NetLogo. The three components interact: Logical English
is translated into and out of Prolog (along with some support code); Prolog and
NetLogo interface via predicates. Such a modular approach enables the different
components to carry different "burdens" in the overall system; it also allows
swapping of modules. Given NetLogo, we can visualize the effect of the modeled
rules as well as validate the system with a simple dynamic running scenario.
Designated agents monitor the behaviour of the vehicles for compliance and
record potential violations where they occur. The information on potential
violations is then utilized by Validators, to determine whether the violation
is punishable, differentiating between exceptions and cases.

摘要：<paragraph>在本文中，我們提出了一個模組化系統，用於表示和推理自動駕駛車輛交通規則的法律層面。我們專注於與路口相關的英國公路法規 (HC) 子集。由於人類駕駛和自動駕駛車輛 (AV) 將在道路上互動，尤其是在城市環境中，我們主張應存在一個可存取、統一、高階的運算模型，並適用於這兩種使用者。自動駕駛車輛引入了責任轉移，不應給人類駕駛帶來劣勢或增加負擔。我們開發了一個模型的「電腦模擬」系統。所提出的系統由三個主要組成部分建構而成：使用邏輯英語的自然語言介面，用於編碼規則；使用 Prolog 的規則內部表示；以及使用 NetLogo 建構的多主體模擬環境。這三個組成部分會進行互動：邏輯英語會翻譯成 Prolog（以及一些支援程式碼），再從 Prolog 翻譯回來；Prolog 和 NetLogo 會透過謂詞進行介面。這種模組化方法讓不同的組成部分可以在整體系統中承擔不同的「負擔」；它也允許模組交換。有了 NetLogo，我們可以視覺化已建模規則的效果，並使用一個簡單的動態執行範例來驗證系統。指定的代理會監控車輛的行為，以確保遵守規定，並記錄發生的潛在違規行為。然後，驗證者會利用潛在違規行為的資訊，來確定違規行為是否應受懲罰，並區分例外情況和案例。</paragraph>

##### **Architecture for Simulating Behavior Mode Changes in Norm-Aware Autonomous Agents**
2502.09215v1 by Sean Glaze, Daniela Inclezan

This paper presents an architecture for simulating the actions of a
norm-aware intelligent agent whose behavior with respect to norm compliance is
set, and can later be changed, by a human controller. Updating an agent's
behavior mode from a norm-abiding to a riskier one may be relevant when the
agent is involved in time-sensitive rescue operations, for example. We base our
work on the Authorization and Obligation Policy Language AOPL designed by
Gelfond and Lobo for the specification of norms. We introduce an architecture
and a prototype software system that can be used to simulate an agent's plans
under different behavior modes that can later be changed by the controller. We
envision such software to be useful to policy makers, as they can more readily
understand how agents may act in certain situations based on the agents'
attitudes towards norm-compliance. Policy makers may then refine their policies
if simulations show unwanted consequences.

摘要：本文提出了一個架構，用於模擬一個規範感知智能代理的行為，其行為遵守規範，並可以由人類控制者設定，並可以在稍後進行更改。當代理參與時間敏感的救援行動時，將代理的行為模式從遵守規範更新為更冒險的行為模式可能是相關的。我們的工作基於 Gelfond 和 Lobo 為規範規範設計的授權和義務政策語言 AOPL。我們引入了一個架構和一個原型軟體系統，可用於模擬代理在不同行為模式下的計畫，這些行為模式稍後可以由控制者更改。我們預計此類軟體對政策制定者很有用，因為他們可以更容易地根據代理對規範遵守的態度了解代理在特定情況下的行為方式。如果模擬顯示出不希望的後果，政策制定者可以修改他們的政策。

##### **Neuro-Symbolic Contrastive Learning for Cross-domain Inference**
2502.09213v1 by Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks

Pre-trained language models (PLMs) have made significant advances in natural
language inference (NLI) tasks, however their sensitivity to textual
perturbations and dependence on large datasets indicate an over-reliance on
shallow heuristics. In contrast, inductive logic programming (ILP) excels at
inferring logical relationships across diverse, sparse and limited datasets,
but its discrete nature requires the inputs to be precisely specified, which
limits their application. This paper proposes a bridge between the two
approaches: neuro-symbolic contrastive learning. This allows for smooth and
differentiable optimisation that improves logical accuracy across an otherwise
discrete, noisy, and sparse topological space of logical functions. We show
that abstract logical relationships can be effectively embedded within a
neuro-symbolic paradigm, by representing data as logic programs and sets of
logic rules. The embedding space captures highly varied textual information
with similar semantic logical relations, but can also separate similar textual
relations that have dissimilar logical relations. Experimental results
demonstrate that our approach significantly improves the inference capabilities
of the models in terms of generalisation and reasoning.

摘要：預訓練語言模型 (PLM) 在自然語言推理 (NLI) 任務中取得了重大進展，然而它們對文本擾動的敏感性和對大型資料集的依賴性表明過度依賴於淺層啟發法。相比之下，歸納邏輯規劃 (ILP) 擅長推論跨越多樣化、稀疏和有限資料集的邏輯關係，但其離散性質要求輸入被精確指定，這限制了它們的應用。本文提出了兩種方法之間的橋樑：神經符號對比學習。這允許平滑且可微分的優化，從而提高邏輯函數的離散、嘈雜和稀疏拓撲空間中的邏輯準確性。我們展示了抽象邏輯關係可以通過將資料表示為邏輯程式和邏輯規則集，有效地嵌入到神經符號範例中。嵌入空間捕獲具有相似語義邏輯關係的高度多變的文本資訊，但也可以分離具有不同邏輯關係的相似文本關係。實驗結果表明，我們的做法在泛化和推理方面顯著提高了模型的推理能力。

##### **LP-LM: No Hallucinations in Question Answering with Logic Programming**
2502.09212v1 by Katherine Wu, Yanhong A. Liu

Large language models (LLMs) are able to generate human-like responses to
user queries. However, LLMs exhibit inherent limitations, especially because
they hallucinate. This paper introduces LP-LM, a system that grounds answers to
questions in known facts contained in a knowledge base (KB), facilitated
through semantic parsing in Prolog, and always produces answers that are
reliable.
  LP-LM generates a most probable constituency parse tree along with a
corresponding Prolog term for an input question via Prolog definite clause
grammar (DCG) parsing. The term is then executed against a KB of natural
language sentences also represented as Prolog terms for question answering. By
leveraging DCG and tabling, LP-LM runs in linear time in the size of input
sentences for sufficiently many grammar rules. Performing experiments comparing
LP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate
on even simple questions, unlike LP-LM.

摘要：大型語言模型 (LLM) 能產生類似人類的回應來回答使用者的問題。然而，LLM 顯示出內在的限制，特別是因為它們會產生幻覺。本文介紹 LP-LM，一個系統，它將問題的答案建立在知識庫 (KB) 中已知的事實上，透過 Prolog 中的語義解析來促進，並始終產生可靠的答案。
LP-LM 透過 Prolog 明確條款語法 (DCG) 解析產生一個最可能的成分解析樹，以及輸入問題對應的 Prolog 詞彙。然後，針對一個自然語言句子的 KB 執行該詞彙，也表示為 Prolog 詞彙，以進行問題解答。透過利用 DCG 和 tabling，LP-LM 在輸入句子的大小上以線性時間執行，對於足夠多的語法規則。執行實驗比較 LP-LM 與目前眾所周知的 LLM 在準確性上，我們顯示出 LLM 甚至會對簡單的問題產生幻覺，這與 LP-LM 不同。

##### **Visual Graph Question Answering with ASP and LLMs for Language Parsing**
2502.09211v1 by Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch

Visual Question Answering (VQA) is a challenging problem that requires to
process multimodal input. Answer-Set Programming (ASP) has shown great
potential in this regard to add interpretability and explainability to modular
VQA architectures. In this work, we address the problem of how to integrate ASP
with modules for vision and natural language processing to solve a new and
demanding VQA variant that is concerned with images of graphs (not graphs in
symbolic form). Images containing graph-based structures are an ubiquitous and
popular form of visualisation. Here, we deal with the particular problem of
graphs inspired by transit networks, and we introduce a novel dataset that
amends an existing one by adding images of graphs that resemble metro lines.
Our modular neuro-symbolic approach combines optical graph recognition for
graph parsing, a pretrained optical character recognition neural network for
parsing labels, Large Language Models (LLMs) for language processing, and ASP
for reasoning. This method serves as a first baseline and achieves an overall
average accuracy of 73% on the dataset. Our evaluation provides further
evidence of the potential of modular neuro-symbolic systems, in particular with
pretrained models that do not involve any further training and logic
programming for reasoning, to solve complex VQA tasks.

摘要：視覺問答（VQA）是一項具有挑戰性的問題，需要處理多模態輸入。答案集程式設計（ASP）在這方面顯示出巨大的潛力，可以為模組化 VQA 架構增加可解釋性和說明性。在這項工作中，我們探討如何將 ASP 與視覺和自然語言處理模組整合，以解決一個新的且要求嚴格的 VQA 變體，該變體與圖形影像（而非符號形式的圖形）有關。包含圖形結構的影像是一種普遍且流行的可視化形式。在這裡，我們處理受交通網路啟發的圖形特定問題，並引入一個新的資料集，透過新增類似地鐵路線的圖形影像來修正現有資料集。我們的模組化神經符號方法結合光學圖形辨識進行圖形解析、預先訓練的光學字元辨識神經網路進行標籤解析、大型語言模型（LLM）進行語言處理，以及 ASP 進行推理。此方法作為第一個基準，在資料集上達到 73% 的整體平均準確度。我們的評估進一步證明了模組化神經符號系統的潛力，特別是預先訓練的模型，這些模型不涉及任何進一步的訓練和邏輯程式設計進行推理，以解決複雜的 VQA 任務。

##### **On LLM-generated Logic Programs and their Inference Execution Methods**
2502.09209v1 by Paul Tarau

Large Language Models (LLMs) trained on petabytes of data are highly
compressed repositories of a significant proportion of the knowledge
accumulated and distilled so far. In this paper we study techniques to elicit
this knowledge in the form of several classes of logic programs, including
propositional Horn clauses, Dual Horn clauses, relational triplets and Definite
Clause Grammars. Exposing this knowledge as logic programs enables sound
reasoning methods that can verify alignment of LLM outputs to their intended
uses and extend their inference capabilities. We study new execution methods
for the generated programs, including soft-unification of abducible facts
against LLM-generated content stored in a vector database as well as GPU-based
acceleration of minimal model computation that supports inference with large
LLM-generated programs.

摘要：大型語言模型 (LLM) 在數位位元組的資料上受過訓練，是目前為止累積和提煉的知識中，高度濃縮的儲存庫。在本文中，我們研究了以數種邏輯程式類別的形式引出這些知識的技術，包括命題霍恩子句、雙重霍恩子句、關聯三元組和確定子句文法。將這些知識作為邏輯程式揭露，能啟用健全的推理方法，驗證 LLM 輸出的對齊方式，符合其預期的用途，並擴展其推論能力。我們研究了產生程式的新執行方法，包括對儲存在向量資料庫中的 LLM 產生內容，進行可約簡事實的軟統一，以及支援使用大型 LLM 產生程式進行推論的，基於 GPU 的最小模型計算加速。

##### **Efficient OWL2QL Meta-reasoning Using ASP-based Hybrid Knowledge Bases**
2502.09206v1 by Haya Majid Qureshi, Wolfgang Faber

Metamodeling refers to scenarios in ontologies in which classes and roles can
be members of classes or occur in roles. This is a desirable modelling feature
in several applications, but allowing it without restrictions is problematic
for several reasons, mainly because it causes undecidability. Therefore,
practical languages either forbid metamodeling explicitly or treat occurrences
of classes as instances to be semantically different from other occurrences,
thereby not allowing metamodeling semantically. Several extensions have been
proposed to provide metamodeling to some extent. Building on earlier work that
reduces metamodeling query answering to Datalog query answering, recently
reductions to query answering over hybrid knowledge bases were proposed with
the aim of using the Datalog transformation only where necessary. Preliminary
work showed that the approach works, but the hoped-for performance improvements
were not observed yet. In this work we expand on this body of work by improving
the theoretical basis of the reductions and by using alternative tools that
show competitive performance.

摘要：元建模是指本体中的場景，其中類別和角色可以是類別成員或出現在角色中。這是一個在多個應用中理想的建模功能，但允許它不受限制會因多個原因而產生問題，主要是因為它會導致無法決定。因此，實用的語言會明確禁止元建模，或將類別的出現視為與其他出現語義不同的實例，從而語義上不允許元建模。已經提出多個擴充功能，在一定程度上提供元建模。建立在將元建模查詢回答簡化為 Datalog 查詢回答的早期工作之上，最近提出了將查詢回答簡化為混合知識庫的簡化，目的是僅在必要時使用 Datalog 轉換。初步工作顯示該方法有效，但尚未觀察到預期的效能改善。在這項工作中，我們透過改善簡化的理論基礎和使用表現競爭力的替代工具，擴展了這項工作。

##### **Counterfactual Explanations as Plans**
2502.09205v1 by Vaishak Belle

There has been considerable recent interest in explainability in AI,
especially with black-box machine learning models. As correctly observed by the
planning community, when the application at hand is not a single-shot decision
or prediction, but a sequence of actions that depend on observations, a richer
notion of explanations are desirable.
  In this paper, we look to provide a formal account of ``counterfactual
explanations," based in terms of action sequences. We then show that this
naturally leads to an account of model reconciliation, which might take the
form of the user correcting the agent's model, or suggesting actions to the
agent's plan. For this, we will need to articulate what is true versus what is
known, and we appeal to a modal fragment of the situation calculus to formalise
these intuitions. We consider various settings: the agent knowing partial
truths, weakened truths and having false beliefs, and show that our definitions
easily generalize to these different settings.

摘要：最近在人工智能中對於可解釋性產生了相當大的興趣，
特別是對於黑盒機器學習模型。正如規劃社群正確觀察到的，當手邊的應用程式不是單次決策或預測，而是一連串依賴於觀察的動作時，一個更豐富的解釋概念是可取的。
在本文中，我們著眼於提供「反事實解釋」的一個正式說明，以動作序列為基礎。然後我們展示這自然會導致一個模型調和說明，其形式可能是使用者修正代理人的模型，或建議代理人的計畫採取行動。為此，我們需要說明什麼是真實的，什麼是已知的，我們訴諸情境演算的一個模態片段來形式化這些直覺。我們考慮各種設定：代理人知道部分真實、虛弱真實和擁有錯誤信念，並展示我們的定義輕鬆地概括到這些不同的設定。

##### **Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**
2502.09204v1 by Sanskar Sehgal, Yanhong A. Liu

Legal cases require careful logical reasoning following the laws, whereas
interactions with non- technical users must be in natural language. As an
application combining logical reasoning using Prolog and natural language
processing using large language models (LLMs), this paper presents a novel
approach and system, LogicLease, to automate the analysis of landlord-tenant
legal cases in the state of New York. LogicLease determines compliance with
relevant legal requirements by analyzing case descriptions and citing all
relevant laws. It leverages LLMs for information extraction and Prolog for
legal reasoning. By separating information extraction from legal reasoning,
LogicLease achieves greater transparency and control over the legal logic
applied to each case. We evaluate the accuracy, efficiency, and robustness of
LogicLease through a series of tests, achieving 100% accuracy and an average
processing time of 2.57 seconds. LogicLease presents advantages over
state-of-the-art LLM- based legal analysis systems by providing clear,
step-by-step reasoning, citing specific laws, and distinguishing itself by its
ability to avoid hallucinations - a common issue in LLMs.

摘要：法律案件需要遵循法律进行谨慎的逻辑推理，而与非技术用户的互动必须使用自然语言。作为结合使用 Prolog 进行逻辑推理和使用大型语言模型 (LLM) 进行自然语言处理的应用程序，本文提出了一种新颖的方法和系统 LogicLease，以自动分析纽约州的房东与租户法律案件。LogicLease 通过分析案例描述并引用所有相关法律来确定是否符合相关法律要求。它利用 LLM 进行信息提取，并利用 Prolog 进行法律推理。通过将信息提取与法律推理分开，LogicLease 实现了对应用于每个案例的法律逻辑的更高透明度和控制力。我们通过一系列测试评估了 LogicLease 的准确性、效率和鲁棒性，实现了 100% 的准确性和 2.57 秒的平均处理时间。LogicLease 通过提供清晰、分步的推理，引用具体法律，并以其避免幻觉的能力而区别于最先进的基于 LLM 的法律分析系统，从而显示出优势——这是 LLM 中的常见问题。

##### **Thinking beyond the anthropomorphic paradigm benefits LLM research**
2502.09192v1 by Lujain Ibrahim, Myra Cheng

Anthropomorphism, or the attribution of human traits to technology, is an
automatic and unconscious response that occurs even in those with advanced
technical expertise. In this position paper, we analyze hundreds of thousands
of computer science research articles from the past decade and present
empirical evidence of the prevalence and growth of anthropomorphic terminology
in research on large language models (LLMs). This terminology reflects deeper
anthropomorphic conceptualizations which shape how we think about and conduct
LLM research. We argue these conceptualizations may be limiting, and that
challenging them opens up new pathways for understanding and improving LLMs
beyond human analogies. To illustrate this, we identify and analyze five core
anthropomorphic assumptions shaping prominent methodologies across the LLM
development lifecycle, from the assumption that models must use natural
language for reasoning tasks to the assumption that model capabilities should
be evaluated through human-centric benchmarks. For each assumption, we
demonstrate how non-anthropomorphic alternatives can open new directions for
research and development.

摘要：擬人化，或將人類特質歸因於科技，是一種自動且無意識的反應，即使是那些擁有進階技術專業知識的人也會發生。在本文中，我們分析了過去十年數十萬篇電腦科學研究文章，並提出實證證據證明擬人化術語在大型語言模型 (LLM) 研究中的普遍性和增長。這些術語反映了更深層的擬人化概念化，塑造了我們思考和進行 LLM 研究的方式。我們認為這些概念化可能是有限制的，並且挑戰它們為超越人類類比來理解和改進 LLM 開闢了新的途徑。為了說明這一點，我們識別並分析了五個核心擬人化假設，這些假設塑造了 LLM 開發生命週期中的顯著方法論，從模型必須使用自然語言進行推理任務的假設到模型能力應該通過以人為中心的基準進行評估的假設。對於每個假設，我們展示了非擬人化替代方案如何為研究和開發打開新方向。

##### **Matina: A Large-Scale 73B Token Persian Text Corpus**
2502.09188v1 by Sara Bourbour Hosseinbeigi, Fatemeh Taherinezhad, Heshaam Faili, Hamed Baghbani, Fatemeh Nadi, Mostafa Amiri

Text corpora are essential for training models used in tasks like
summarization, translation, and large language models (LLMs). While various
efforts have been made to collect monolingual and multilingual datasets in many
languages, Persian has often been underrepresented due to limited resources for
data collection and preprocessing. Existing Persian datasets are typically
small and lack content diversity, consisting mainly of weblogs and news
articles. This shortage of high-quality, varied data has slowed the development
of NLP models and open-source LLMs for Persian. Since model performance depends
heavily on the quality of training data, we address this gap by introducing the
Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed
and deduplicated to ensure high data quality. We further assess its
effectiveness by training and evaluating transformer-based models on key NLP
tasks. Both the dataset and preprocessing codes are publicly available,
enabling researchers to build on and improve this resource for future Persian
NLP advancements.

摘要：文字語料庫對於訓練用於摘要、翻譯和大型語言模型 (LLM) 等任務的模型至關重要。儘管已做出各種努力來收集許多語言中的單語和多語言資料集，但由於資料收集和預處理資源有限，波斯語常常代表性不足。現有的波斯語資料集通常很小，而且缺乏內容多樣性，主要由網誌和新聞文章組成。這種優質、多樣化資料的短缺減緩了波斯語的 NLP 模型和開源 LLM 的開發。由於模型效能高度依賴訓練資料的品質，我們透過推出 Matina 語料庫來解決這個差距，Matina 語料庫是一個新的波斯語資料集，包含 72.9B 個字元，經過仔細預處理和去重，以確保資料品質。我們進一步透過在關鍵 NLP 任務上訓練和評估基於轉換器的模型來評估其有效性。資料集和預處理程式碼都是公開的，使研究人員能夠建立和改善這個資源，以促進未來的波斯語 NLP 進展。

##### **RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation**
2502.09183v1 by Changzhi Zhou, Xinyu Zhang, Dandan Song, Xiancai Chen, Wanli Gu, Huipeng Ma, Yuhang Tian, Mengdi Zhang, Linmei Hu

Code generation has attracted increasing attention with the rise of Large
Language Models (LLMs). Many studies have developed powerful code LLMs by
synthesizing code-related instruction data and applying supervised fine-tuning.
However, these methods are limited by teacher model distillation and ignore the
potential of iterative refinement by self-generated code. In this paper, we
propose Adaptive Critique Refinement (ACR), which enables the model to refine
itself by self-generated code and external critique, rather than directly
imitating the code responses of the teacher model. Concretely, ACR includes a
composite scoring system with LLM-as-a-Judge to evaluate the quality of code
responses and a selective critique strategy with LLM-as-a-Critic to critique
self-generated low-quality code responses. We develop the RefineCoder series by
iteratively applying ACR, achieving continuous performance improvement on
multiple code generation benchmarks. Compared to the baselines of the same
size, our proposed RefineCoder series can achieve comparable or even superior
performance using less data.

摘要：隨著大型語言模型 (LLM) 的興起，程式碼生成備受關注。許多研究透過綜合與程式碼相關的指令資料並應用監督式微調來開發強大的程式碼 LLM。然而，這些方法受到教師模型蒸餾的限制，且忽略了透過自行產生的程式碼進行反覆改進的潛力。在本文中，我們提出適應性批判改進 (ACR)，它使模型能夠透過自行產生的程式碼和外部批判來改進自身，而不是直接模仿教師模型的程式碼回應。具體來說，ACR 包含一個複合評分系統，其中 LLM 作為評審員來評估程式碼回應的品質，以及一個選擇性批判策略，其中 LLM 作為批判者來批判自行產生的低品質程式碼回應。我們透過反覆套用 ACR 來開發 RefineCoder 系列，在多個程式碼生成基準上實現持續的效能改善。與相同規模的基準相比，我們提出的 RefineCoder 系列可以使用較少資料來實現相當甚至更優異的效能。

##### **FLAME: Flexible LLM-Assisted Moderation Engine**
2502.09175v1 by Ivan Bakulin, Ilia Kopanichuk, Iaroslav Bespalov, Nikita Radchenko, Vladimir Shaposhnikov, Dmitry Dylov, Ivan Oseledets

The rapid advancement of Large Language Models (LLMs) has introduced
significant challenges in moderating user-model interactions. While LLMs
demonstrate remarkable capabilities, they remain vulnerable to adversarial
attacks, particularly ``jailbreaking'' techniques that bypass content safety
measures. Current content moderation systems, which primarily rely on input
prompt filtering, have proven insufficient, with techniques like Best-of-N
(BoN) jailbreaking achieving success rates of 80% or more against popular LLMs.
In this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a
new approach that shifts the focus from input filtering to output moderation.
Unlike traditional circuit-breaking methods that analyze user queries, FLAME
evaluates model responses, offering several key advantages: (1) computational
efficiency in both training and inference, (2) enhanced resistance to BoN
jailbreaking attacks, and (3) flexibility in defining and updating safety
criteria through customizable topic filtering. Our experiments demonstrate that
FLAME significantly outperforms current moderation systems. For example, FLAME
reduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9,
while maintaining low computational overhead. We provide comprehensive
evaluation on various LLMs and analyze the engine's efficiency against the
state-of-the-art jailbreaking. This work contributes to the development of more
robust and adaptable content moderation systems for LLMs.

摘要：大型語言模型 (LLM) 的快速進步為調節使用者與模型互動帶來重大挑戰。儘管 LLM 展現出非凡的能力，但它們仍然容易受到對抗性攻擊，特別是繞過內容安全措施的「越獄」技術。目前的內容審核系統主要依賴輸入提示過濾，已被證明不足，例如 Best-of-N (BoN) 越獄對抗熱門 LLM 的成功率達到 80% 以上。在本文中，我們介紹了靈活的 LLM 輔助審核引擎 (FLAME)：一種新的方法，將重點從輸入過濾轉移到輸出審核。與分析使用者查詢的傳統電路中斷方法不同，FLAME 評估模型回應，提供幾個關鍵優勢：(1) 訓練和推理中的計算效率，(2) 增強對 BoN 越獄攻擊的抵抗力，以及 (3) 透過可自訂主題過濾定義和更新安全標準的靈活性。我們的實驗證明，FLAME 明顯優於目前的審核系統。例如，FLAME 將 GPT-4o-mini 和 DeepSeek-v3 的攻擊成功率降低了約 9 倍，同時保持較低的計算負擔。我們對各種 LLM 進行了全面的評估，並分析了引擎對抗最新越獄的效率。這項工作有助於開發更強大且適應性更強的 LLM 內容審核系統。

##### **Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**
2502.09173v1 by Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott

In remote healthcare monitoring, time series representation learning reveals
critical patient behavior patterns from high-frequency data. This study
analyzes home activity data from individuals living with dementia by proposing
a two-stage, self-supervised learning approach tailored to uncover low-rank
structures. The first stage converts time-series activities into text sequences
encoded by a pre-trained language model, providing a rich, high-dimensional
latent state space using a PageRank-based method. This PageRank vector captures
latent state transitions, effectively compressing complex behaviour data into a
succinct form that enhances interpretability. This low-rank representation not
only enhances model interpretability but also facilitates clustering and
transition analysis, revealing key behavioral patterns correlated with
clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the
framework's potential in supporting cognitive status prediction, personalized
care interventions, and large-scale health monitoring.

摘要：在遠程醫療監控中，時間序列表示學習揭示了高頻率數據中的關鍵患者行為模式。本研究通過提出一個兩階段、自我監督的學習方法來分析痴呆症患者的家庭活動數據，該方法專門用於發現低秩結構。第一階段將時間序列活動轉換為由預訓練語言模型編碼的文本序列，使用基於 PageRank 的方法提供了一個豐富、高維的潛在狀態空間。此 PageRank 向量捕獲潛在狀態轉換，有效地將複雜的行為數據壓縮成簡潔的形式，從而增強了解力。此低秩表示不僅增強了模型的可解釋性，還促進了聚類和轉換分析，揭示了與臨床指標（例如 MMSE 和 ADAS-COG 分數）相關的關鍵行為模式。我們的研究結果證明了該框架在支持認知狀態預測、個性化護理干預和大型健康監控方面的潛力。

##### **Musical Heritage Historical Entity Linking**
2502.09168v1 by Arianna Graciotti, Nicolas Lazzari, Valentina Presutti, Rocco Tripodi

Linking named entities occurring in text to their corresponding entity in a
Knowledge Base (KB) is challenging, especially when dealing with historical
texts. In this work, we introduce Musical Heritage named Entities Recognition,
Classification and Linking (MHERCL), a novel benchmark consisting of manually
annotated sentences extrapolated from historical periodicals of the music
domain. MHERCL contains named entities under-represented or absent in the most
famous KBs. We experiment with several State-of-the-Art models on the Entity
Linking (EL) task and show that MHERCL is a challenging dataset for all of
them. We propose a novel unsupervised EL model and a method to extend
supervised entity linkers by using Knowledge Graphs (KGs) to tackle the main
difficulties posed by historical documents. Our experiments reveal that relying
on unsupervised techniques and improving models with logical constraints based
on KGs and heuristics to predict NIL entities (entities not represented in the
KB of reference) results in better EL performance on historical documents.

摘要：將文本中出現的名稱實體連結到知識庫 (KB) 中對應的實體具有挑戰性，尤其是在處理歷史文本時。在這項工作中，我們引入了音樂遺產命名實體識別、分類和連結 (MHERCL)，這是一個由從音樂領域的歷史期刊中外推的手動標註句子組成的全新基準。MHERCL 包含在最著名的 KB 中代表性不足或不存在的名稱實體。我們在實體連結 (EL) 任務中對多個最先進的模型進行了實驗，並表明 MHERCL 對所有模型來說都是一個具有挑戰性的資料集。我們提出了一個新的無監督 EL 模型和一個通過使用知識圖 (KG) 來擴充監督式實體連結器的的方法，以解決歷史文件提出的主要難題。我們的實驗表明，依賴無監督技術並使用基於 KG 和啟發法的邏輯約束來改善模型以預測 NIL 實體（未在參考 KB 中表示的實體）會在歷史文件中產生更好的 EL 效能。

##### **Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs**
2502.09156v1 by Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin

Objectives: Large language models (LLMs) can harness medical knowledge for
intelligent question answering (Q&A), promising support for auxiliary diagnosis
and medical talent cultivation. However, there is a deficiency of highly
efficient retrieval-augmented generation (RAG) frameworks within the domain of
Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the
Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A
tasks.
  Materials and Methods: We introduce the novel approach of knowledge
organization, constructing a tree structure knowledge base with hierarchy. At
inference time, our self-reflection framework retrieves from this knowledge
base, integrating information across chapters. Questions from the TCM Medical
Licensing Examination (MLE) and the college Classics Course Exam (CCE) were
randomly selected as benchmark datasets.
  Results: By coupling with GPT-4, the framework can improve the best
performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and
improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,
the framework improves a total of 18.52 points across dimensions of safety,
consistency, explainability, compliance, and coherence.
  Conclusion: The TOSRR framework can effectively improve LLM's capability in
Q&A tasks of TCM.

摘要：目標：大型語言模型（LLM）可以利用醫療知識進行智能問答（Q&A），承諾支持輔助診斷和醫療人才培養。然而，在中醫領域內缺乏高效的檢索增強生成（RAG）框架。我們的目的是觀察樹組織自省檢索（TOSRR）框架對中醫問答任務中 LLM 的影響。
材料和方法：我們引入了知識組織的新方法，構建了一個具有層次的樹結構知識庫。在推理時間，我們的自省框架從這個知識庫中檢索，整合章節中的信息。中醫醫師資格考試（MLE）和大學經典課程考試（CCE）中的問題被隨機選為基準數據集。
結果：通過與 GPT-4 結合，該框架可以將中醫 MLE 基準上的最佳性能提高 19.85% 的絕對準確度，並將 CCE 數據集上的召回準確度從 27% 提高到 38%。在手動評估中，該框架在安全性、一致性、可解釋性、合規性和連貫性方面總共提高了 18.52 分。
結論：TOSRR 框架可以有效提升 LLM 在中醫問答任務中的能力。

##### **A Novel Dialect-Aware Framework for the Classification of Arabic Dialects and Emotions**
2502.09128v1 by Nasser A Alsadhan

Arabic is one of the oldest languages still in use today. As a result,
several Arabic-speaking regions have developed dialects that are unique to
them. Dialect and emotion recognition have various uses in Arabic text
analysis, such as determining an online customer's origin based on their
comments. Furthermore, intelligent chatbots that are aware of a user's emotions
can respond appropriately to the user. Current research in emotion detection in
the Arabic language lacks awareness of how emotions are exhibited in different
dialects, which motivates the work found in this study. This research addresses
the problems of dialect and emotion classification in Arabic. Specifically,
this is achieved by building a novel framework that can identify and predict
Arabic dialects and emotions from a given text. The framework consists of three
modules: A text-preprocessing module, a classification module, and a clustering
module with the novel capability of building new dialect-aware emotion
lexicons. The proposed framework generated a new emotional lexicon for
different dialects. It achieved an accuracy of 88.9% in classifying Arabic
dialects, which outperforms the state-of-the-art results by 6.45 percentage
points. Furthermore, the framework achieved 89.1-79% accuracy in detecting
emotions in the Egyptian and Gulf dialects, respectively.

摘要：阿拉伯語是現今仍在使用中最古老的語言之一。因此，幾個講阿拉伯語的地區發展出獨特的方言。方言和情緒辨識在阿拉伯語文本分析中有多種用途，例如根據在線客戶的評論來確定其來源。此外，知道使用者情緒的智慧聊天機器人可以適當地回應使用者。目前對阿拉伯語情緒偵測的研究缺乏對不同方言如何表現情緒的認識，這激勵了本研究中的工作。本研究探討了阿拉伯語中的方言和情緒分類問題。具體而言，這是通過建立一個新的框架來實現的，該框架可以識別和預測給定文本中的阿拉伯方言和情緒。該框架包含三個模組：文字預處理模組、分類模組和聚類模組，具有建立新的方言感知情緒詞彙表的新功能。所提出的框架為不同的方言生成了新的情緒詞彙表。它在分類阿拉伯方言方面達到了 88.9% 的準確率，比最先進的結果高出 6.45 個百分點。此外，該框架在檢測埃及和海灣方言的情緒方面分別達到了 89.1-79% 的準確率。

##### **Automatic Pruning via Structured Lasso with Class-wise Information**
2502.09125v1 by Xiang Liu, Mingchen Li, Xia Li, Leigang Qu, Zifan Peng, Yijun Song, Zemin Liu, Linshan Jiang, Jialin Li

Most pruning methods concentrate on unimportant filters of neural networks.
However, they face the loss of statistical information due to a lack of
consideration for class-wise data. In this paper, from the perspective of
leveraging precise class-wise information for model pruning, we utilize
structured lasso with guidance from Information Bottleneck theory. Our approach
ensures that statistical information is retained during the pruning process.
With these techniques, we introduce two innovative adaptive network pruning
schemes: sparse graph-structured lasso pruning with Information Bottleneck
(\textbf{sGLP-IB}) and sparse tree-guided lasso pruning with Information
Bottleneck (\textbf{sTLP-IB}). The key aspect is pruning model filters using
sGLP-IB and sTLP-IB to better capture class-wise relatedness. Compared to
multiple state-of-the-art methods, our approaches demonstrate superior
performance across three datasets and six model architectures in extensive
experiments. For instance, using the VGG16 model on the CIFAR-10 dataset, we
achieve a parameter reduction of 85%, a decrease in FLOPs by 61%, and maintain
an accuracy of 94.10% (0.14% higher than the original model); we reduce the
parameters by 55% with the accuracy at 76.12% using the ResNet architecture on
ImageNet (only drops 0.03%). In summary, we successfully reduce model size and
computational resource usage while maintaining accuracy. Our codes are at
https://anonymous.4open.science/r/IJCAI-8104.

摘要：大多數剪枝方法都集中在神經網路中不重要的濾波器上。
然而，由於缺乏對類別資料的考量，它們面臨統計資訊的遺失。在本文中，我們從利用精確類別資訊進行模型剪枝的角度，利用結構化套索搭配資訊瓶頸理論的指導。我們的做法確保在剪枝過程中保留統計資訊。藉由這些技術，我們引入了兩個創新的自適應網路剪枝方案：帶有資訊瓶頸的稀疏圖形結構套索剪枝（sGLP-IB）和帶有資訊瓶頸的稀疏樹導引套索剪枝（sTLP-IB）。關鍵方面是使用 sGLP-IB 和 sTLP-IB 剪枝模型濾波器，以更好地擷取類別關聯性。與多種最先進的方法相比，我們的做法在廣泛的實驗中展現出跨三個資料集和六個模型架構的卓越效能。例如，在 CIFAR-10 資料集上使用 VGG16 模型，我們達到了 85% 的參數減少、61% 的 FLOP 減少，並維持 94.10% 的準確度（比原始模型高 0.14%）；我們在 ImageNet 上使用 ResNet 架構將參數減少了 55%，準確度為 76.12%（僅下降 0.03%）。總之，我們成功地減少了模型大小和計算資源使用，同時維持準確度。我們的程式碼位於 https://anonymous.4open.science/r/IJCAI-8104。

##### **The influence of visual and linguistic cues on ignorance inference in Vision-Language Models (VLMs)**
2502.09120v1 by Ye-eun Cho, Yunho Maeng

This study explored how Vision-Language Models (VLMs) process ignorance
implicatures with visual and linguistic cues. Particularly, we focused on the
effects of contexts (precise and approximate contexts) and modifier types (bare
numerals, superlative, and comparative modifiers), which were considered
pragmatic and semantic factors respectively. Methodologically, we conducted a
truth-value judgment task in visually grounded settings using GPT-4o and Gemini
1.5 Pro. The results indicate that while both models exhibited sensitivity to
linguistic cues (modifier), they failed to process ignorance implicatures with
visual cues (context) as humans do. Specifically, the influence of context was
weaker and inconsistent across models, indicating challenges in pragmatic
reasoning for VLMs. On the other hand, superlative modifiers were more strongly
associated with ignorance implicatures as compared to comparative modifiers,
supporting the semantic view. These findings highlight the need for further
advancements in VLMs to process language-vision information in a
context-dependent way to achieve human-like pragmatic inference.

摘要：本研究探討了視覺語言模型 (VLM) 如何處理視覺和語言線索中的無知含義。特別是，我們專注於語境（精確和近似語境）和修飾語類型（裸數字、最高級和比較級修飾語）的影響，這些分別被視為語用和語義因素。在方法論上，我們使用 GPT-4o 和 Gemini 1.5 Pro 在視覺基礎設置中進行了真值判斷任務。結果表明，儘管這兩個模型都對語言線索（修飾語）表現出敏感性，但它們未能像人類那樣處理帶有視覺線索（語境）的無知含義。具體來說，語境的影響在各個模型中較弱且不一致，表明 VLM 在語用推理方面存在挑戰。另一方面，與比較級修飾語相比，最高級修飾語與無知含義的關聯性更強，這支持了語義觀點。這些發現強調了 VLM 進一步發展的必要性，以以語境依賴的方式處理語言視覺信息，以實現類人語用推理。

##### **One-shot Federated Learning Methods: A Practical Guide**
2502.09104v1 by Xiang Liu, Zhenheng Tang, Xia Li, Yijun Song, Sijie Ji, Zemin Liu, Bo Han, Linshan Jiang, Jialin Li

One-shot Federated Learning (OFL) is a distributed machine learning paradigm
that constrains client-server communication to a single round, addressing
privacy and communication overhead issues associated with multiple rounds of
data exchange in traditional Federated Learning (FL). OFL demonstrates the
practical potential for integration with future approaches that require
collaborative training models, such as large language models (LLMs). However,
current OFL methods face two major challenges: data heterogeneity and model
heterogeneity, which result in subpar performance compared to conventional FL
methods. Worse still, despite numerous studies addressing these limitations, a
comprehensive summary is still lacking. To address these gaps, this paper
presents a systematic analysis of the challenges faced by OFL and thoroughly
reviews the current methods. We also offer an innovative categorization method
and analyze the trade-offs of various techniques. Additionally, we discuss the
most promising future directions and the technologies that should be integrated
into the OFL field. This work aims to provide guidance and insights for future
research.

摘要：單次聯邦學習 (OFL) 是一種分散式機器學習範例，將客戶端與伺服器通訊限制在單一輪次中，解決傳統聯邦學習 (FL) 中多輪次資料交換相關的隱私和通訊負擔問題。OFL 展示了與需要協作訓練模型的未來方法整合的實際潛力，例如大型語言模型 (LLM)。然而，目前的 OFL 方法面臨兩大挑戰：資料異質性和模型異質性，這導致與傳統 FL 方法相比，效能較差。更糟的是，儘管有許多研究探討這些限制，但仍缺乏全面的摘要。為了解決這些差距，本文對 OFL 面臨的挑戰進行系統分析，並徹底檢視目前的方法。我們還提供創新的分類方法，並分析各種技術的權衡取捨。此外，我們討論最有希望的未來方向，以及應整合到 OFL 領域的技術。這項工作旨在為未來的研究提供指導和見解。

##### **Logical Reasoning in Large Language Models: A Survey**
2502.09100v1 by Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang

With the emergence of advanced reasoning models like OpenAI o3 and
DeepSeek-R1, large language models (LLMs) have demonstrated remarkable
reasoning capabilities. However, their ability to perform rigorous logical
reasoning remains an open question. This survey synthesizes recent advancements
in logical reasoning within LLMs, a critical area of AI research. It outlines
the scope of logical reasoning in LLMs, its theoretical foundations, and the
benchmarks used to evaluate reasoning proficiency. We analyze existing
capabilities across different reasoning paradigms - deductive, inductive,
abductive, and analogical - and assess strategies to enhance reasoning
performance, including data-centric tuning, reinforcement learning, decoding
strategies, and neuro-symbolic approaches. The review concludes with future
directions, emphasizing the need for further exploration to strengthen logical
reasoning in AI systems.

摘要：隨著 OpenAI o3 和 DeepSeek-R1 等先進推理模型的出現，大型語言模型 (LLM) 已展現出非凡的推理能力。然而，它們執行嚴謹邏輯推理的能力仍是一個開放性的問題。此調查綜合了 LLM 中邏輯推理的最新進展，這是 AI 研究的一個關鍵領域。它概述了 LLM 中邏輯推理的範圍、其理論基礎，以及用於評估推理能力的基準。我們分析了不同推理範例（演繹、歸納、外推和類比）中的現有能力，並評估增強推理效能的策略，包括以數據為中心的調整、強化學習、解碼策略和神經符號方法。此評論以未來的方向作為結論，強調需要進一步探索以強化 AI 系統中的邏輯推理。

##### **A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian Optimization and Bidirectional Recurrent Unit**
2502.09097v1 by Tianyi Huang, Zeqiu Xu, Peiyang Yu, Jingyuan Yi, Xiaochuan Xu

In this paper, we propose an optimized Transformer model that integrates
Bayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and
apply it to fake news classification for the first time. First, we employ the
TF-IDF method to extract features from news texts and transform them into
numeric representations to facilitate subsequent machine learning tasks. Two
sets of experiments are then conducted for fake news detection and
classification: one using a Transformer model optimized only with BiGRU, and
the other incorporating Bayesian algorithms into the BiGRU-based Transformer.
Experimental results show that the BiGRU-optimized Transformer achieves 100%
accuracy on the training set and 99.67% on the test set, while the addition of
the Bayesian algorithm maintains 100% accuracy on the training set and slightly
improves test-set accuracy to 99.73%. This indicates that the Bayesian
algorithm boosts model accuracy by 0.06%, further enhancing the detection
capability for fake news. Moreover, the proposed algorithm converges rapidly at
around the 10th training epoch with accuracy nearing 100%, demonstrating both
its effectiveness and its fast classification ability. Overall, the optimized
Transformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits
excellent continuous learning and detection performance, offering a robust
technical means to combat the spread of fake news in the current era of
information overload.

摘要：<paragraph>在本文中，我們提出了一個最佳化的 Transformer 模型，它將貝氏演算法與雙向門控遞迴單元 (BiGRU) 整合在一起，並首次將其應用於假新聞分類。首先，我們採用 TF-IDF 方法從新聞文本中提取特徵，並將它們轉換為數值表示，以利於後續的機器學習任務。接著進行兩組實驗，分別針對假新聞偵測和分類：一組使用僅使用 BiGRU 最佳化的 Transformer 模型，另一組將貝氏演算法納入基於 BiGRU 的 Transformer 中。實驗結果顯示，BiGRU 最佳化的 Transformer 在訓練組上達到 100% 的準確度，在測試組上達到 99.67%，而加入貝氏演算法後，在訓練組上維持 100% 的準確度，並將測試組的準確度略微提升至 99.73%。這表示貝氏演算法將模型準確度提升了 0.06%，進一步增強了對假新聞的偵測能力。此外，所提出的演算法在約第 10 個訓練週期時快速收斂，準確度接近 100%，證明了它的有效性和快速的分類能力。總的來說，由貝氏演算法和 BiGRU 增強的最佳化 Transformer 模型展現出絕佳的持續學習和偵測效能，提供了一個強健的技術手段來對抗在當前資訊過載時代中假新聞的散布。</paragraph>

##### **A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning**
2502.09086v1 by Jia Gao, Shuangquan Lyu, Guiran Liu, Binrong Zhu, Hongye Zheng, Xiaoxuan Liao

With the continuous development of natural language processing (NLP)
technology, text classification tasks have been widely used in multiple
application fields. However, obtaining labeled data is often expensive and
difficult, especially in few-shot learning scenarios. To solve this problem,
this paper proposes a few-shot text classification model based on transfer
learning and meta-learning. The model uses the knowledge of the pre-trained
model for transfer and optimizes the model's rapid adaptability in few-sample
tasks through a meta-learning mechanism. Through a series of comparative
experiments and ablation experiments, we verified the effectiveness of the
proposed method. The experimental results show that under the conditions of few
samples and medium samples, the model based on transfer learning and
meta-learning significantly outperforms traditional machine learning and deep
learning methods. In addition, ablation experiments further analyzed the
contribution of each component to the model performance and confirmed the key
role of transfer learning and meta-learning in improving model accuracy.
Finally, this paper discusses future research directions and looks forward to
the potential of this method in practical applications.

摘要：隨著自然語言處理 (NLP) 技術的持續發展，文本分類任務已廣泛應用於多個應用領域。然而，獲取標記資料通常既昂貴又困難，特別是在小樣本學習場景中。為了解決這個問題，本文提出了一個基於遷移學習和元學習的少樣本文本分類模型。該模型利用預訓練模型的知識進行遷移，並透過元學習機制最佳化模型在少樣本任務中的快速適應性。透過一系列的比較實驗和消融實驗，我們驗證了所提出方法的有效性。實驗結果表明，在少樣本和中等樣本的條件下，基於遷移學習和元學習的模型明顯優於傳統機器學習和深度學習方法。此外，消融實驗進一步分析了各個組成部分對模型效能的貢獻，並確認了遷移學習和元學習在提升模型準確度中的關鍵作用。最後，本文探討了未來的研究方向，並期待此方法在實際應用中的潛力。

##### **Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking**
2502.09083v1 by Greta Warren, Irina Shklovski, Isabelle Augenstein

The pervasiveness of large language models and generative AI in online media
has amplified the need for effective automated fact-checking to assist
fact-checkers in tackling the increasing volume and sophistication of
misinformation. The complex nature of fact-checking demands that automated
fact-checking systems provide explanations that enable fact-checkers to
scrutinise their outputs. However, it is unclear how these explanations should
align with the decision-making and reasoning processes of fact-checkers to be
effectively integrated into their workflows. Through semi-structured interviews
with fact-checking professionals, we bridge this gap by: (i) providing an
account of how fact-checkers assess evidence, make decisions, and explain their
processes; (ii) examining how fact-checkers use automated tools in practice;
and (iii) identifying fact-checker explanation requirements for automated
fact-checking tools. The findings show unmet explanation needs and identify
important criteria for replicable fact-checking explanations that trace the
model's reasoning path, reference specific evidence, and highlight uncertainty
and information gaps.

摘要：大型語言模型和生成式 AI 在線上媒體的普及
放大了對有效自動查核事實的需求，以協助查核員應對日益增加的錯誤資訊量和複雜性。查核事實的複雜性質要求自動查核事實系統提供說明，讓查核員能夠仔細審查他們的輸出。然而，目前尚不清楚這些說明應如何與查核員的決策制定和推理過程保持一致，才能有效整合到他們的流程中。透過與查核事實專業人士進行半結構式訪談，我們透過以下方式彌補這個差距：(i) 提供查核員如何評估證據、做出決策和解釋其流程的說明；(ii) 檢視查核員如何實際使用自動化工具；以及 (iii) 找出查核員對自動查核事實工具的說明需求。研究結果顯示未滿足的說明需求，並找出可複製查核事實說明的重要準則，這些準則追蹤模型的推理路徑、參考具體證據，並強調不確定性和資訊差距。

##### **CoSER: Coordinating LLM-Based Persona Simulation of Established Roles**
2502.09082v1 by Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, Yanghua Xiao, Shuchang Zhou

Role-playing language agents (RPLAs) have emerged as promising applications
of large language models (LLMs). However, simulating established characters
presents a challenging task for RPLAs, due to the lack of authentic character
datasets and nuanced evaluation methods using such data. In this paper, we
present CoSER, a collection of a high-quality dataset, open models, and an
evaluation protocol towards effective RPLAs of established characters. The
CoSER dataset covers 17,966 characters from 771 renowned books. It provides
authentic dialogues with real-world intricacies, as well as diverse data types
such as conversation setups, character experiences and internal thoughts.
Drawing from acting methodology, we introduce given-circumstance acting for
training and evaluating role-playing LLMs, where LLMs sequentially portray
multiple characters in book scenes. Using our dataset, we develop CoSER 8B and
CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models.
Extensive experiments demonstrate the value of the CoSER dataset for RPLA
training, evaluation and retrieval. Moreover, CoSER 70B exhibits
state-of-the-art performance surpassing or matching GPT-4o on our evaluation
and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on
the InCharacter and LifeChoice benchmarks respectively.

摘要：角色扮演語言代理（RPLA）已成為大型語言模型（LLM）的有前途的應用。然而，由於缺乏真實角色資料集和使用此類資料的細緻評估方法，模擬既有角色對 RPLA 來說是一項具有挑戰性的任務。在本文中，我們提出了 CoSER，這是一個高品質資料集、開放模型和評估協議的集合，用於有效地扮演既有角色的 RPLA。CoSER 資料集涵蓋了來自 771 本著名書籍的 17,966 個角色。它提供了具有真實世界複雜性的真實對話，以及對話設定、角色體驗和內心想法等多種資料類型。借鑑表演方法，我們引入了既定情境表演，用於訓練和評估角色扮演 LLM，其中 LLM 在書籍場景中依次扮演多個角色。使用我們的資料集，我們開發了 CoSER 8B 和 CoSER 70B，即建立在 LLaMA-3.1 模型上的先進開放角色扮演 LLM。大量的實驗證明了 CoSER 資料集對於 RPLA 訓練、評估和檢索的價值。此外，CoSER 70B 在我們的評估和三個現有基準上展現了超越或匹配 GPT-4o 的最先進效能，即分別在 InCharacter 和 LifeChoice 基準上達到了 75.80% 和 93.47% 的準確率。

##### **Enhancing RAG with Active Learning on Conversation Records: Reject Incapables and Answer Capables**
2502.09073v1 by Xuzhao Geng, Haozhao Wang, Jun Wang, Wei Liu, Ruixuan Li

Retrieval-augmented generation (RAG) is a key technique for leveraging
external knowledge and reducing hallucinations in large language models (LLMs).
However, RAG still struggles to fully prevent hallucinated responses. To
address this, it is essential to identify samples prone to hallucination or
guide LLMs toward correct responses, which experts then annotate to develop
high-quality datasets for refining LLMs. However, the growing scarcity of such
datasets makes their creation challenging. This paper proposes using the vast
amount of conversations from widespread LLM usage to build these datasets,
training LLMs to avoid hallucination-prone questions while accurately
responding to manageable ones. Given the impracticality of expert-annotating
all conversation records, the paper introduces AL4RAG, which uses active
learning to select the most suitable conversation samples for annotation,
optimizing performance within an annotation budget. Additionally, recognizing
that traditional active learning methods are not fully compatible with RAG due
to unsuitable distance metrics, we develop a novel sample distance measurement
for RAG active learning. Extensive experiments show that our method
consistently outperforms baselines across multiple metrics.

摘要：檢索增強生成 (RAG) 是一種關鍵技術，用於利用外部知識並減少大型語言模型 (LLM) 中的幻覺。然而，RAG 仍難以完全防止幻覺反應。為了解決這個問題，必須找出容易產生幻覺的範例，或引導 LLM 朝向正確的反應，然後由專家註解以開發用於精煉 LLM 的高品質資料集。然而，此類資料集日益稀少，使得其建立極具挑戰性。本文提出使用來自廣泛 LLM 使用的大量對話來建立這些資料集，訓練 LLM 以避免容易產生幻覺的問題，同時準確回應可管理的問題。鑑於由專家為所有對話記錄加上註解並不切實際，本文引入了 AL4RAG，它使用主動學習來選擇最適合註解的對話範例，在註解預算內最佳化效能。此外，認識到傳統主動學習方法由於不適當的距離度量而無法與 RAG 完全相容，我們為 RAG 主動學習開發了一種新穎的範例距離度量。廣泛的實驗表明，我們的模型在多種度量標準上始終優於基準。

##### **An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging**
2502.09056v1 by Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai

This paper investigates data selection and model merging methodologies aimed
at incorporating advanced reasoning capabilities such as those of DeepSeek R1
into language-specific large language models (LLMs), with a particular focus on
the Thai LLM. Our goal is to enhance the reasoning capabilities of
language-specific LLMs while maintaining their target language abilities.
DeepSeek R1 excels in reasoning but primarily benefits high-resource languages
such as English and Chinese. However, low-resource languages remain underserved
due to the dominance of English-centric training data and model optimizations,
which limit performance in these languages. This limitation results in
unreliable code-switching and diminished effectiveness on tasks in low-resource
languages. Meanwhile, local and regional LLM initiatives have attempted to
bridge this gap by developing language-specific LLMs that focus on improving
local linguistic fidelity. We demonstrate that, with only publicly available
datasets and a computational budget of $120, it is possible to enhance the
reasoning capabilities of language-specific LLMs to match the level of DeepSeek
R1, without compromising their performance on target language tasks.

摘要：本文探討資料選取與模型合併方法，旨在將深度搜尋 R1 等先進推理能力整合至特定語言的大型語言模型 (LLM)，特別著重於泰語 LLM。我們的目標是提升特定語言 LLM 的推理能力，同時維持其目標語言能力。深度搜尋 R1 在推理方面表現出色，但主要受益於英語和中文等資源豐富的語言。然而，由於以英語為中心的訓練資料和模型最佳化佔據主導地位，資源貧乏的語言仍未獲得充分服務，這限制了這些語言的效能。此限制導致不可靠的代碼切換，並降低了資源貧乏語言任務的效能。與此同時，在地區 LLM 計畫已嘗試透過開發專注於改善在地語言忠實度的特定語言 LLM 來彌合此差距。我們證明，僅使用公開可用的資料集和 120 美元的運算預算，即可提升特定語言 LLM 的推理能力，使其達到深度搜尋 R1 的水準，同時不損及它們在目標語言任務上的效能。

##### **Cost-Saving LLM Cascades with Early Abstention**
2502.09054v1 by Michael J. Zellinger, Rex Liu, Matt Thomson

LLM cascades are based on the idea that processing all queries with the
largest and most expensive LLMs is inefficient. Instead, cascades deploy small
LLMs to answer the majority of queries, limiting the use of large and expensive
LLMs to only the most difficult queries. This approach can significantly reduce
costs without impacting performance. However, risk-sensitive domains such as
finance or medicine place an additional premium on avoiding model errors.
Recognizing that even the most expensive models may make mistakes, applications
in these domains benefit from allowing LLM systems to completely abstain from
answering a query when the chance of making a mistake is significant. However,
giving a cascade the ability to abstain poses an immediate design question for
LLM cascades: should abstention only be allowed at the final model or also at
earlier models? Since the error patterns of small and large models are
correlated, the latter strategy may further reduce inference costs by letting
inexpensive models anticipate abstention decisions by expensive models, thereby
obviating the need to run the expensive models. We investigate the benefits of
"early abstention" in LLM cascades and find that it reduces the overall test
loss by 2.2% on average across six benchmarks (GSM8K, MedMCQA, MMLU, TriviaQA,
TruthfulQA, and XSum). These gains result from a more effective use of
abstention, which trades a 4.1% average increase in the overall abstention rate
for a 13.0% reduction in cost and a 5.0% reduction in error rate. Our findings
demonstrate that it is possible to leverage correlations between the error
patterns of different language models to drive performance improvements for LLM
systems with abstention.

摘要：<paragraph>LLM 級聯基於以下概念：使用最大且最昂貴的 LLM 處理所有查詢效率低下。相反，級聯會部署小型 LLM 來回答大部分查詢，將大型且昂貴的 LLM 的使用限制在最困難的查詢上。這種方法可以大幅降低成本，而不會影響效能。然而，像金融或醫學等對風險敏感的領域會額外重視避免模型錯誤。認識到即使是最昂貴的模型也可能會出錯，在這些領域中的應用程式可受益於允許 LLM 系統在出錯機率很大的情況下完全不回答查詢。然而，賦予級聯不回答的能力會對 LLM 級聯提出立即的設計問題：是否只允許在最終模型中不回答，還是也在較早的模型中不回答？由於小型和大型模型的錯誤模式相關，後一種策略可以讓便宜的模型預測昂貴模型的不回答決策，進而降低推論成本，從而避免執行昂貴的模型。我們調查了 LLM 級聯中「早期不回答」的好處，並發現它平均降低了六個基準測試（GSM8K、MedMCQA、MMLU、TriviaQA、TruthfulQA 和 XSum）的整體測試損失 2.2%。這些收益來自於更有效地使用不回答，以整體不回答率平均增加 4.1% 的代價換取成本降低 13.0% 和錯誤率降低 5.0%。我們的研究結果證明，可以利用不同語言模型的錯誤模式之間的關聯性，來推動具有不回答功能的 LLM 系統的效能改進。</paragraph>

##### **Game Theory Meets Large Language Models: A Systematic Survey**
2502.09053v1 by Haoran Sun, Yusen Wu, Yukun Cheng, Xu Chu

Game theory establishes a fundamental framework for analyzing strategic
interactions among rational decision-makers. The rapid advancement of large
language models (LLMs) has sparked extensive research exploring the
intersection of these two fields. Specifically, game-theoretic methods are
being applied to evaluate and enhance LLM capabilities, while LLMs themselves
are reshaping classic game models. This paper presents a comprehensive survey
of the intersection of these fields, exploring a bidirectional relationship
from three perspectives: (1) Establishing standardized game-based benchmarks
for evaluating LLM behavior; (2) Leveraging game-theoretic methods to improve
LLM performance through algorithmic innovations; (3) Characterizing the
societal impacts of LLMs through game modeling. Among these three aspects, we
also highlight how the equilibrium analysis for traditional game models is
impacted by LLMs' advanced language understanding, which in turn extends the
study of game theory. Finally, we identify key challenges and future research
directions, assessing their feasibility based on the current state of the
field. By bridging theoretical rigor with emerging AI capabilities, this survey
aims to foster interdisciplinary collaboration and drive progress in this
evolving research area.

摘要：博弈論建立一個基本架構，用來分析理性決策者之間的策略互動。大型語言模型 (LLM) 的快速進展，激發了廣泛的研究，探討這兩個領域的交集。具體來說，博弈論方法被應用於評估和增強 LLM 能力，而 LLM 本身正在重塑經典博弈模型。本文對這些領域的交集進行了全面的調查，從三個角度探討了雙向關係：(1) 建立標準化的基於博弈的基準，用於評估 LLM 行為；(2) 利用博弈論方法，通過演算法創新來改善 LLM 效能；(3) 透過博弈模型，描述 LLM 對社會的影響。在這三個方面中，我們還強調了 LLM 的先進語言理解如何影響傳統博弈模型的均衡分析，這反過來又擴展了博弈論的研究。最後，我們找出關鍵挑戰和未來的研究方向，根據該領域的現狀評估其可行性。透過將理論嚴謹性與新興的 AI 能力相結合，這項調查旨在促進跨學科合作，並推動這個不斷演變的研究領域的進展。

##### **AIDE: Agentically Improve Visual Language Model with Domain Experts**
2502.09051v1 by Ming-Chang Chiu, Fuxiao Liu, Karan Sapra, Andrew Tao, Yaser Jacoob, Xuezhe Ma, Zhiding Yu, Guilin Liu

The enhancement of Visual Language Models (VLMs) has traditionally relied on
knowledge distillation from larger, more capable models. This dependence
creates a fundamental bottleneck for improving state-of-the-art systems,
particularly when no superior models exist. We introduce AIDE (Agentic
Improvement through Domain Experts), a novel framework that enables VLMs to
autonomously enhance their capabilities by leveraging specialized domain expert
models. AIDE operates through a four-stage process: (1) identifying instances
for refinement, (2) engaging domain experts for targeted analysis, (3)
synthesizing expert outputs with existing data, and (4) integrating enhanced
instances into the training pipeline. Experiments on multiple benchmarks,
including MMMU, MME, MMBench, etc., demonstrate AIDE's ability to achieve
notable performance gains without relying on larger VLMs nor human supervision.
Our framework provides a scalable, resource-efficient approach to continuous
VLM improvement, addressing critical limitations in current methodologies,
particularly valuable when larger models are unavailable to access.

摘要：視覺語言模型 (VLM) 的增強傳統上依賴於從更大、功能更強大的模型中進行知識萃取。這種依賴性會造成改善最先進系統的基本瓶頸，尤其在沒有更優越的模型時。我們引進 AIDE（透過領域專家進行代理式改善），一個創新的架構，讓 VLM 能夠透過利用專業的領域專家模型，自主增強其功能。AIDE 透過四階段流程運作：(1) 識別需要改善的實例，(2) 聘請領域專家進行有針對性的分析，(3) 將專家輸出與現有資料綜合，以及 (4) 將增強的實例整合到訓練流程中。在多個基準測試上的實驗，包括 MMMU、MME、MMBench 等，證明了 AIDE 能夠在不依賴更大型的 VLM 或人工監督的情況下，實現顯著的效能提升。我們的架構提供了一個可擴充、資源效率高的持續 VLM 改進方法，解決了當前方法中的關鍵限制，特別是在無法取得大型模型時，這一點特別有價值。

##### **Leveraging Member-Group Relations via Multi-View Graph Filtering for Effective Group Recommendation**
2502.09050v1 by Chae-Hyun Kim, Yoon-Ryung Choi, Jin-Duk Park, Won-Yong Shin

Group recommendation aims at providing optimized recommendations tailored to
diverse groups, enabling groups to enjoy appropriate items. On the other hand,
most existing group recommendation methods are built upon deep neural network
(DNN) architectures designed to capture the intricate relationships between
member-level and group-level interactions. While these DNN-based approaches
have proven their effectiveness, they require complex and expensive training
procedures to incorporate group-level interactions in addition to member-level
interactions. To overcome such limitations, we introduce Group-GF, a new
approach for extremely fast recommendations of items to each group via
multi-view graph filtering (GF) that offers a holistic view of complex
member-group dynamics, without the need for costly model training.
Specifically, in Group-GF, we first construct three item similarity graphs
manifesting different viewpoints for GF. Then, we discover a distinct
polynomial graph filter for each similarity graph and judiciously aggregate the
three graph filters. Extensive experiments demonstrate the effectiveness of
Group-GF in terms of significantly reducing runtime and achieving
state-of-the-art recommendation accuracy.

摘要：群組推薦旨在提供針對不同群組量身打造的最佳推薦，讓群組可以享受適當的項目。另一方面，現有的群組推薦方法大多建立在深度神經網路 (DNN) 架構上，旨在捕捉成員層級和群組層級互動之間的複雜關係。雖然這些基於 DNN 的方法已證明其有效性，但它們需要複雜且昂貴的訓練程序，才能在成員層級互動之外納入群組層級互動。為了克服這些限制，我們引入了 Group-GF，這是一種透過多視圖圖形過濾 (GF) 為每個群組提供極快速項目推薦的新方法，它提供了複雜成員群組動態的整體視圖，而無需進行昂貴的模型訓練。具體來說，在 Group-GF 中，我們首先建構三個項目相似度圖形，展現 GF 的不同觀點。然後，我們為每個相似度圖形發現一個不同的多項式圖形過濾器，並明智地彙總這三個圖形過濾器。廣泛的實驗證明了 Group-GF 在顯著減少執行時間和達成最先進的推薦準確度方面的有效性。

##### **Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation**
2502.09046v1 by Jin-Duk Park, Jaemin Yoo, Won-Yong Shin

Multi-criteria (MC) recommender systems, which utilize MC rating information
for recommendation, are increasingly widespread in various e-commerce domains.
However, the MC recommendation using training-based collaborative filtering,
requiring consideration of multiple ratings compared to single-criterion
counterparts, often poses practical challenges in achieving state-of-the-art
performance along with scalable model training. To solve this problem, we
propose CA-GF, a training-free MC recommendation method, which is built upon
criteria-aware graph filtering for efficient yet accurate MC recommendations.
Specifically, first, we construct an item-item similarity graph using an MC
user-expansion graph. Next, we design CA-GF composed of the following key
components, including 1) criterion-specific graph filtering where the optimal
filter for each criterion is found using various types of polynomial low-pass
filters and 2) criteria preference-infused aggregation where the smoothed
signals from each criterion are aggregated. We demonstrate that CA-GF is (a)
efficient: providing the computational efficiency, offering the extremely fast
runtime of less than 0.2 seconds even on the largest benchmark dataset, (b)
accurate: outperforming benchmark MC recommendation methods, achieving
substantial accuracy gains up to 24% compared to the best competitor, and (c)
interpretable: providing interpretations for the contribution of each criterion
to the model prediction based on visualizations.

摘要：多準則 (MC) 推薦系統在各種電子商務領域中日益普及，該系統利用 MC 評分資訊進行推薦。
然而，與單準則對應項目相比，使用基於訓練的協同過濾的 MC 推薦，通常在達成最先進的效能以及可擴充模型訓練方面造成實務上的挑戰，需要考慮多個評分。為了解決這個問題，我們提出 CA-GF，一種無需訓練的 MC 推薦方法，它建立於準則感知圖形過濾之上，用於有效且準確的 MC 推薦。
具體來說，首先，我們使用 MC 使用者擴展圖形來建構一個項目相似度圖形。接下來，我們設計 CA-GF，它包含以下關鍵組成部分，包括 1) 準則特定圖形過濾，其中使用各種類型的多項式低通濾波器來找出每個準則的最佳濾波器，以及 2) 準則偏好注入聚合，其中來自每個準則的平滑訊號被聚合。我們證明 CA-GF 是 (a) 有效的：提供運算效率，即使在最大的基準資料集上，也能提供低於 0.2 秒的極快執行時間，(b) 準確的：優於基準 MC 推薦方法，與最佳競爭者相比，獲得高達 24% 的顯著準確性提升，以及 (c) 可解釋的：根據視覺化提供對每個準則對模型預測的貢獻的解釋。

##### **Typhoon T1: An Open Thai Reasoning Model**
2502.09042v1 by Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai, Kunat Pipatanakul

This paper introduces Typhoon T1, an open effort to develop an open Thai
reasoning model. A reasoning model is a relatively new type of generative model
built on top of large language models (LLMs). A reasoning model generates a
long chain of thought before arriving at a final answer, an approach found to
improve performance on complex tasks. However, details on developing such a
model are limited, especially for reasoning models that can generate traces in
a low-resource language. Typhoon T1 presents an open effort that dives into the
details of developing a reasoning model in a more cost-effective way by
leveraging supervised fine-tuning using open datasets, instead of reinforcement
learning. This paper shares the details about synthetic data generation and
training, as well as our dataset and model weights. Additionally, we provide
insights gained from developing a reasoning model that generalizes across
domains and is capable of generating reasoning traces in a low-resource
language, using Thai as an example. We hope this open effort provides a
foundation for further research in this field.

摘要：本文介紹 Typhoon T1，這是一個開放的計畫，旨在開發開放的泰語推理模型。推理模型是一種相對較新的生成模型，建構於大型語言模型 (LLM) 之上。推理模型會在得出最終答案之前產生一連串的思考，這種方法被發現可以改善複雜任務的效能。然而，關於如何開發這種模型的詳細資訊有限，特別是對於能夠以低資源語言產生軌跡的推理模型而言。Typhoon T1 提出了一個開放的計畫，深入探討如何以更具成本效益的方式開發推理模型，方法是利用開放式資料集進行監督微調，而不是強化學習。本文分享了關於合成資料產生和訓練的詳細資訊，以及我們的資料集和模型權重。此外，我們提供了從開發推理模型中獲得的見解，該模型可以跨領域概括，並能夠以低資源語言產生推理軌跡，以泰語為例。我們希望這個開放的計畫能為此領域的進一步研究奠定基礎。

##### **Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning**
2502.09022v1 by Lin Zhang, Lijie Hu, Di Wang

Transformer-based language models have achieved notable success, yet their
internal reasoning mechanisms remain largely opaque due to complex non-linear
interactions and high-dimensional operations. While previous research suggests
that these models implicitly encode reasoning structures, it is still unclear
which specific multi-step thought processes they employ to solve complex tasks.
To address this gap, we propose a novel mechanistic interpretability framework,
SICAF, designed to trace and analyze the reasoning strategies that language
models use in multi-step inference tasks. By employing circuit analysis and
self-influence functions, we quantify the evolving importance of each token
throughout the reasoning process, thereby mapping the pathways the model uses
for inference. Applying SICAF to the GPT-2 model on the Indirect Object
Identification (IOI) prediction task, we demonstrate how underlying circuits
can reveal a reasoning process that aligns with human interpretability,
offering new insights into the model's internal logic.

摘要：基於 Transformer 的語言模型已取得顯著的成功，但由於複雜的非線性交互和高維度運算，它們的內部推理機制在很大程度上仍然不透明。儘管先前的研究表明這些模型隱含地編碼推理結構，但目前仍不清楚它們採用哪些具體的多步驟思考過程來解決複雜任務。為了解決這個差距，我們提出了一個新穎的機制可解釋性框架 SICAF，旨在追蹤和分析語言模型在多步驟推理任務中使用的推理策略。通過採用電路分析和自影響函數，我們量化了推理過程中每個標記的演化重要性，從而繪製出模型用於推理的路徑。將 SICAF 應用於 GPT-2 模型上的間接賓語識別 (IOI) 預測任務，我們展示了底層電路如何揭示與人類可解釋性相符的推理過程，從而對模型的內部邏輯提供了新的見解。

##### **EventSTR: A Benchmark Dataset and Baselines for Event Stream based Scene Text Recognition**
2502.09020v1 by Xiao Wang, Jingtao Jiang, Dong Li, Futian Wang, Lin Zhu, Yaowei Wang, Yongyong Tian, Jin Tang

Mainstream Scene Text Recognition (STR) algorithms are developed based on RGB
cameras which are sensitive to challenging factors such as low illumination,
motion blur, and cluttered backgrounds. In this paper, we propose to recognize
the scene text using bio-inspired event cameras by collecting and annotating a
large-scale benchmark dataset, termed EventSTR. It contains 9,928
high-definition (1280 * 720) event samples and involves both Chinese and
English characters. We also benchmark multiple STR algorithms as the baselines
for future works to compare. In addition, we propose a new event-based scene
text recognition framework, termed SimC-ESTR. It first extracts the event
features using a visual encoder and projects them into tokens using a Q-former
module. More importantly, we propose to augment the vision tokens based on a
memory mechanism before feeding into the large language models. A
similarity-based error correction mechanism is embedded within the large
language model to correct potential minor errors fundamentally based on
contextual information. Extensive experiments on the newly proposed EventSTR
dataset and two simulation STR datasets fully demonstrate the effectiveness of
our proposed model. We believe that the dataset and algorithmic model can
innovatively propose an event-based STR task and are expected to accelerate the
application of event cameras in various industries. The source code and
pre-trained models will be released on https://github.com/Event-AHU/EventSTR

摘要：主流場景文字辨識（STR）演算法是基於對低光源、動態模糊和雜亂背景等挑戰性因素敏感的 RGB 相機開發的。在本文中，我們提出使用生物靈感事件相機辨識場景文字，方法是收集和標註一個稱為 EventSTR 的大規模基準資料集。它包含 9,928 個高畫質（1280 * 720）事件範例，並包含中文字和英文字元。我們也基準化多個 STR 演算法作為未來工作的基準，以進行比較。此外，我們提出一個新的基於事件的場景文字辨識架構，稱為 SimC-ESTR。它首先使用視覺編碼器萃取事件特徵，並使用 Q-former 模組將它們投影到代幣中。更重要的是，我們提出在輸入大型語言模型之前，基於記憶機制擴充視覺代幣。一個基於相似性的錯誤修正機制嵌入在大型語言模型中，以根據上下文資訊從根本上修正潛在的輕微錯誤。在最新提出的 EventSTR 資料集和兩個模擬 STR 資料集上進行的廣泛實驗充分證明了我們提出的模型的有效性。我們相信，該資料集和演算法模型可以創新地提出一個基於事件的 STR 任務，並有望加速事件相機在各個產業的應用。原始碼和預先訓練的模型將在 https://github.com/Event-AHU/EventSTR 上釋出

##### **Zero-shot Concept Bottleneck Models**
2502.09018v1 by Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa, Yasutoshi Ida

Concept bottleneck models (CBMs) are inherently interpretable and
intervenable neural network models, which explain their final label prediction
by the intermediate prediction of high-level semantic concepts. However, they
require target task training to learn input-to-concept and concept-to-label
mappings, incurring target dataset collections and training resources. In this
paper, we present \textit{zero-shot concept bottleneck models} (Z-CBMs), which
predict concepts and labels in a fully zero-shot manner without training neural
networks. Z-CBMs utilize a large-scale concept bank, which is composed of
millions of vocabulary extracted from the web, to describe arbitrary input in
various domains. For the input-to-concept mapping, we introduce concept
retrieval, which dynamically finds input-related concepts by the cross-modal
search on the concept bank. In the concept-to-label inference, we apply concept
regression to select essential concepts from the retrieved concepts by sparse
linear regression. Through extensive experiments, we confirm that our Z-CBMs
provide interpretable and intervenable concepts without any additional
training. Code will be available at https://github.com/yshinya6/zcbm.

摘要：概念瓶頸模型 (CBM) 本質上是可解釋且可干預的神經網路模型，它們透過對高階語意概念的中間預測來解釋其最終標籤預測。然而，它們需要目標任務訓練來學習輸入到概念和概念到標籤的對應，導致目標資料集收集和訓練資源。在本文中，我們展示了「零次學習概念瓶頸模型」(Z-CBM)，它以完全零次學習的方式預測概念和標籤，而無需訓練神經網路。Z-CBM 利用一個大型概念庫，其中包含從網路中擷取的數百萬個詞彙，來描述各種領域中的任意輸入。對於輸入到概念的對應，我們引入了概念擷取，它透過對概念庫的跨模態搜尋，動態地找出與輸入相關的概念。在概念到標籤的推論中，我們應用概念迴歸，透過稀疏線性迴歸從擷取的概念中選擇必要的概念。透過廣泛的實驗，我們確認我們的 Z-CBM 在沒有任何額外訓練的情況下提供了可解釋且可干預的概念。程式碼將可在 https://github.com/yshinya6/zcbm 取得。

##### **Diversity Enhances an LLM's Performance in RAG and Long-context Task**
2502.09017v1 by Zhchao Wang, Bin Bi, Yanqi Luo, Sitaram Asur, Claire Na Cheng

The rapid advancements in large language models (LLMs) have highlighted the
challenge of context window limitations, primarily due to the quadratic time
complexity of the self-attention mechanism (\(O(N^2)\), where \(N\) denotes the
context window length). This constraint impacts tasks such as
retrieval-augmented generation (RAG) in question answering (Q\&A) and long
context summarization. A common approach involves selecting content with the
highest similarity to the query; however, this often leads to redundancy and
the exclusion of diverse yet relevant information. Building on principles from
Maximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we
integrate diversity into the content selection process. Our findings reveal
that incorporating diversity substantially increases the recall of selecting
relevant sentences or chunks before LLM-based Q\&A and summarization. These
results highlight the importance of maintaining diversity in future LLM
applications to further improve summarization and Q\&A outcomes.

摘要：大型語言模型 (LLM) 的快速進步凸顯了上下文視窗限制的挑戰，這主要是由於自注意力機制的二次時間複雜度（\(O(N^2)\)），其中 \(N\) 表示上下文視窗長度。此限制會影響任務，例如問答 (Q&A) 中的檢索增強生成 (RAG) 和長文摘要。一種常見的方法涉及選擇與查詢最相似的內容；然而，這通常會導致冗餘，並排除多樣化但相關的資訊。我們根據最大邊際相關性 (MMR) 和最遠點取樣 (FPS) 的原則，將多樣性整合到內容選擇過程中。我們的研究結果顯示，在基於 LLM 的問答和摘要之前，納入多樣性會大幅增加選擇相關句子或區塊的召回率。這些結果突顯了在未來的 LLM 應用中維持多樣性的重要性，以進一步改善摘要和問答的結果。

##### **Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content in Mainstream US News Media through the Lens of Hope Speech**
2502.09004v1 by Jonathan Pofcher, Christopher M. Homan, Randall Sell, Ashiqur R. KhudaBukhsh

This paper makes three contributions. First, via a substantial corpus of
1,419,047 comments posted on 3,161 YouTube news videos of major US cable news
outlets, we analyze how users engage with LGBTQ+ news content. Our analyses
focus both on positive and negative content. In particular, we construct a
fine-grained hope speech classifier that detects positive (hope speech),
negative, neutral, and irrelevant content. Second, in consultation with a
public health expert specializing on LGBTQ+ health, we conduct an annotation
study with a balanced and diverse political representation and release a
dataset of 3,750 instances with fine-grained labels and detailed annotator
demographic information. Finally, beyond providing a vital resource for the
LGBTQ+ community, our annotation study and subsequent in-the-wild assessments
reveal (1) strong association between rater political beliefs and how they rate
content relevant to a marginalized community; (2) models trained on individual
political beliefs exhibit considerable in-the-wild disagreement; and (3)
zero-shot large language models (LLMs) align more with liberal raters.

摘要：本文做出了三項貢獻。首先，透過一個龐大的語料庫，其中包含 1,419,047 則評論，這些評論張貼在 3,161 部美國有線新聞頻道的 YouTube 新聞影片上，我們分析了使用者如何參與 LGBTQ+ 新聞內容。我們的分析重點在於正面和負面的內容。特別是，我們建構了一個細緻的希望言論分類器，用來偵測正面的（希望言論）、負面的、中立的和不相關的內容。其次，在諮詢了一位專門研究 LGBTQ+ 健康的公共衛生專家後，我們進行了一項標註研究，其中包含平衡且多元的政治代表性，並發布了一個包含 3,750 個實例的資料集，其中包含細緻的標籤和詳細的標註者人口統計資訊。最後，除了為 LGBTQ+ 社群提供重要的資源外，我們的標註研究和後續的實際評估揭示了：(1) 評分者的政治信仰與他們如何評分與邊緣化社群相關的內容之間有很強的關聯性；(2) 根據個人政治信仰訓練的模型在實際應用中表現出相當大的分歧；(3) 零次學習大型語言模型 (LLM) 與自由派評分者的看法更一致。

##### **RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models**
2502.09003v1 by Quan Wei, Chung-Yiu Yau, Hoi-To Wai, Yang, Zhao, Dongyeop Kang, Youngsuk Park, Mingyi Hong

Supervised fine-tuning is a standard method for adapting pre-trained large
language models (LLMs) to downstream tasks. Quantization has been recently
studied as a post-training technique for efficient LLM deployment. To obtain
quantized fine-tuned LLMs, conventional pipelines would first fine-tune the
pre-trained models, followed by post-training quantization. This often yields
suboptimal performance as it fails to leverage the synergy between fine-tuning
and quantization. To effectively realize low-bit quantization of weights,
activations, and KV caches in LLMs, we propose an algorithm named Rotated
Straight-Through-Estimator (RoSTE), which combines quantization-aware
supervised fine-tuning (QA-SFT) with an adaptive rotation strategy that
identifies an effective rotation configuration to reduce activation outliers.
We provide theoretical insights on RoSTE by analyzing its prediction error when
applied to an overparameterized least square quantized training problem. Our
findings reveal that the prediction error is directly proportional to the
quantization error of the converged weights, which can be effectively managed
through an optimized rotation configuration. Experiments on Pythia and Llama
models of different sizes demonstrate the effectiveness of RoSTE. Compared to
existing post-SFT quantization baselines, our method consistently achieves
superior performances across various tasks and different LLM architectures.

摘要：監督式微調是將預訓練的大型語言模型 (LLM) 適應至下游任務的標準方法。量化最近已被研究作為一種訓練後技術，用於高效部署 LLM。為了獲得量化的微調 LLM，傳統管道會先微調預訓練模型，然後再進行訓練後量化。這通常會產生次佳效能，因為它無法利用微調和量化之間的協同效應。為了有效實現 LLM 中權重、激活和 KV 快取的低位元量化，我們提出了一種名為旋轉直通估計器 (RoSTE) 的演算法，它結合了量化感知監督式微調 (QA-SFT) 和一種自適應旋轉策略，該策略會識別有效的旋轉組態以減少激活異常值。我們透過分析 RoSTE 在應用於過度參數化最小平方量化訓練問題時的預測誤差，提供了關於 RoSTE 的理論見解。我們的研究結果顯示，預測誤差與收斂權重的量化誤差成正比，而這可透過最佳化的旋轉組態有效地管理。在不同大小的 Pythia 和 Llama 模型上進行的實驗證明了 RoSTE 的有效性。與現有的訓練後 SFT 量化基準相比，我們的模型在各種任務和不同的 LLM 架構中持續獲得優異的效能。

##### **PixLift: Accelerating Web Browsing via AI Upscaling**
2502.08995v1 by Yonas Atinafu, Sarthak Malla, HyunSeok Daniel Jang, Nouar Aldahoul, Matteo Varvello, Yasir Zaki

Accessing the internet in regions with expensive data plans and limited
connectivity poses significant challenges, restricting information access and
economic growth. Images, as a major contributor to webpage sizes, exacerbate
this issue, despite advances in compression formats like WebP and AVIF. The
continued growth of complex and curated web content, coupled with suboptimal
optimization practices in many regions, has prevented meaningful reductions in
web page sizes. This paper introduces PixLift, a novel solution to reduce
webpage sizes by downscaling their images during transmission and leveraging AI
models on user devices to upscale them. By trading computational resources for
bandwidth, PixLift enables more affordable and inclusive web access. We address
key challenges, including the feasibility of scaled image requests on popular
websites, the implementation of PixLift as a browser extension, and its impact
on user experience. Through the analysis of 71.4k webpages, evaluations of
three mainstream upscaling models, and a user study, we demonstrate PixLift's
ability to significantly reduce data usage without compromising image quality,
fostering a more equitable internet.

摘要：在數據方案昂貴且連線有限的地區存取網路會造成重大挑戰，限制了資訊存取和經濟成長。圖像作為網頁大小的主要貢獻者，儘管 WebP 和 AVIF 等壓縮格式進步，但仍加劇了這個問題。複雜且經過策劃的網路內容持續成長，加上許多地區次佳的最佳化實務，已阻礙了網頁大小的顯著減少。本文介紹 PixLift，這是一種創新的解決方案，可在傳輸過程中縮小圖像大小，並利用使用者裝置上的 AI 模型來放大圖像，藉此縮小網頁大小。PixLift 透過以運算資源換取頻寬，讓網路存取更經濟實惠且更具包容性。我們解決了關鍵挑戰，包括熱門網站上縮放圖像要求的可行性、將 PixLift 實作為瀏覽器擴充功能，以及它對使用者體驗的影響。透過分析 71.4k 個網頁、評估三個主流放大模型，以及使用者研究，我們展示了 PixLift 在不影響影像品質的情況下顯著減少資料用量的能力，促進了更公平的網路。

##### **RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning**
2502.08989v1 by Nazatul H. Sultan, Yan Bo, Yansong Gao, Seyit Camtepe, Arash Mahboubi, Hang Thanh Bui, Aufeef Chauhan, Hamed Aboutorab, Michael Bewong, Praveen Gauravaram, Rafiqul Islam, Sharif Abuadbba

Federated Learning (FL) allows users to collaboratively train a global
machine learning model by sharing local model only, without exposing their
private data to a central server. This distributed learning is particularly
appealing in scenarios where data privacy is crucial, and it has garnered
substantial attention from both industry and academia. However, studies have
revealed privacy vulnerabilities in FL, where adversaries can potentially infer
sensitive information from the shared model parameters. In this paper, we
present an efficient masking-based secure aggregation scheme utilizing
lightweight cryptographic primitives to mitigate privacy risks. Our scheme
offers several advantages over existing methods. First, it requires only a
single setup phase for the entire FL training session, significantly reducing
communication overhead. Second, it minimizes user-side overhead by eliminating
the need for user-to-user interactions, utilizing an intermediate server layer
and a lightweight key negotiation method. Third, the scheme is highly resilient
to user dropouts, and the users can join at any FL round. Fourth, it can detect
and defend against malicious server activities, including recently discovered
model inconsistency attacks. Finally, our scheme ensures security in both
semi-honest and malicious settings. We provide security analysis to formally
prove the robustness of our approach. Furthermore, we implemented an end-to-end
prototype of our scheme. We conducted comprehensive experiments and
comparisons, which show that it outperforms existing solutions in terms of
communication and computation overhead, functionality, and security.

摘要：聯合式學習 (FL) 使用者可以透過僅分享本機模型，在不將其私人資料揭露給中央伺服器的情況下，共同訓練全球機器學習模型。這種分散式學習在資料隱私至關重要的場景中特別具有吸引力，並且已獲得業界和學術界的廣泛關注。然而，研究顯示 FL 中存在隱私漏洞，其中對手可能會從共享模型參數中推斷出敏感資訊。在本文中，我們提出了一種有效率的基於遮罩的安全聚合方案，利用輕量級的密碼原語來降低隱私風險。我們的方案相較於現有方法提供了多項優點。首先，它僅需要在整個 FL 訓練階段進行一次設定階段，大幅降低了通訊開銷。其次，透過消除使用者間互動的需要，利用中間伺服器層和輕量級金鑰協商方法，將使用者端的開銷降到最低。第三，該方案對使用者中斷具有高度的復原力，使用者可以在任何 FL 回合中加入。第四，它可以偵測和防禦惡意伺服器活動，包括最近發現的模型不一致攻擊。最後，我們的方案確保在半誠實和惡意設定中都能獲得安全性。我們提供了安全分析，以正式證明我們方法的穩健性。此外，我們實作了我們方案的端對端原型。我們進行了全面的實驗和比較，結果顯示，在通訊和運算開銷、功能和安全性方面，它優於現有的解決方案。

##### **Neural Force Field: Learning Generalized Physical Representation from a Few Examples**
2502.08987v1 by Shiqian Li, Ruihong Shen, Chi Zhang, Yixin Zhu

Physical reasoning is a remarkable human ability that enables rapid learning
and generalization from limited experience. Current AI models, despite
extensive training, still struggle to achieve similar generalization,
especially in Out-of-distribution (OOD) settings. This limitation stems from
their inability to abstract core physical principles from observations. A key
challenge is developing representations that can efficiently learn and
generalize physical dynamics from minimal data. Here we present Neural Force
Field (NFF) a modeling framework built on Neural Ordinary Differential Equation
(NODE) that learns interpretable force field representations which can be
efficiently integrated through an Ordinary Differential Equation ( ODE) solver
to predict object trajectories. Unlike existing approaches that rely on
high-dimensional latent spaces, NFF captures fundamental physical concepts such
as gravity, support, and collision in an interpretable manner. Experiments on
two challenging physical reasoning tasks demonstrate that NFF, trained with
only a few examples, achieves strong generalization to unseen scenarios. This
physics-grounded representation enables efficient forward-backward planning and
rapid adaptation through interactive refinement. Our work suggests that
incorporating physics-inspired representations into learning systems can help
bridge the gap between artificial and human physical reasoning capabilities.

摘要：物理推理是人类非凡的能力，它能从有限的经验中快速学习和概括。尽管经过广泛的训练，但当前的人工智能模型在实现类似的概括方面仍然存在困难，尤其是在分布外 (OOD) 设置中。这种限制源于它们无法从观察中抽象出核心物理原理。一个关键挑战是开发能够从最少数据中有效学习和概括物理动力学的表示。在这里，我们介绍了神经力场 (NFF)，这是一种建立在神经常微分方程 (NODE) 上的建模框架，它学习可解释的力场表示，这些表示可以通过常微分方程 (ODE) 求解器有效地进行积分，以预测物体轨迹。与依赖于高维潜在空间的现有方法不同，NFF 以可解释的方式捕获了诸如重力、支撑和碰撞等基本物理概念。在两个具有挑战性的物理推理任务上的实验表明，仅通过几个示例训练的 NFF 实现了对看不见场景的强大概括。这种基于物理的表示能够进行高效的前向后向规划，并通过交互式细化实现快速适应。我们的工作表明，将受物理启发的表示纳入学习系统可以帮助弥合人工智能和人类物理推理能力之间的差距。

##### **Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning**
2502.08972v1 by Hyundong Cho, Karishma Sharma, Nicolaas Jedema, Leonardo F. R. Ribeiro, Alessandro Moschitti, Ravi Krishnan, Jonathan May

Language models are aligned to the collective voice of many, resulting in
generic outputs that do not align with specific users' styles. In this work, we
present Trial-Error-Explain In-Context Learning (TICL), a tuning-free method
that personalizes language models for text generation tasks with fewer than 10
examples per user. TICL iteratively expands an in-context learning prompt via a
trial-error-explain process, adding model-generated negative samples and
explanations that provide fine-grained guidance towards a specific user's
style. TICL achieves favorable win rates on pairwise comparisons with
LLM-as-a-judge up to 91.5% against the previous state-of-the-art and
outperforms competitive tuning-free baselines for personalized alignment tasks
of writing emails, essays and news articles. Both lexical and qualitative
analyses show that the negative samples and explanations enable language models
to learn stylistic context more effectively and overcome the bias towards
structural and formal phrases observed in their zero-shot outputs. By
front-loading inference compute to create a user-specific in-context learning
prompt that does not require extra generation steps at test time, TICL presents
a novel yet simple approach for personalized alignment.

摘要：語言模型與眾人的集體聲音保持一致，導致產出內容流於一般，無法與特定使用者的風格相符。在這項工作中，我們提出了試驗錯誤解釋情境內學習 (TICL)，一種免調校方法，能為文字生成任務個人化語言模型，每個使用者少於 10 個範例。TICL 透過試驗錯誤解釋程序反覆擴充情境內學習提示，加入模型產生的負面範例和說明，提供細緻的指導，引導至特定使用者的風格。TICL 在與 LLM 作為評審的成對比較中獲得了高勝率，高達 91.5%，優於先前的技術水準，並在個人化對齊任務中超越了競爭性的免調校基準，包括撰寫電子郵件、論文和新聞文章。詞彙和質性分析皆顯示，負面範例和說明讓語言模型能更有效地學習風格脈絡，並克服零次學習產出中觀察到的結構性和正式詞組偏誤。透過預先加載推論運算，建立使用者特定的情境內學習提示，無需在測試時額外產生步驟，TICL 呈現一種新穎卻簡潔的方法，用於個人化對齊。

##### **RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage**
2502.08966v1 by Peter Yong Zhong, Siyuan Chen, Ruiqi Wang, McKenna McCall, Ben L. Titzer, Heather Miller

Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external
tools for tasks beyond their standalone capabilities, such as searching
websites, booking flights, or making financial transactions. However, these
tools greatly increase the risks of prompt injection attacks, where malicious
content hijacks the LM agent to leak confidential data or trigger harmful
actions. Existing defenses (OpenAI GPTs) require user confirmation before every
tool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS),
which automatically detects and executes tool calls that preserve integrity and
confidentiality, requiring user confirmation only when these safeguards cannot
be ensured. RTBAS adapts Information Flow Control to the unique challenges
presented by TBAS. We present two novel dependency screeners, using
LM-as-a-judge and attention-based saliency, to overcome these challenges.
Experimental results on the AgentDojo Prompt Injection benchmark show RTBAS
prevents all targeted attacks with only a 2% loss of task utility when under
attack, and further tests confirm its ability to obtain near-oracle performance
on detecting both subtle and direct privacy leaks.

摘要：基於工具的代理系統 (TBAS) 允許語言模型 (LM) 使用外部工具來執行超出其獨立功能的任務，例如搜尋網站、預訂航班或進行金融交易。然而，這些工具大幅增加了提示注入攻擊的風險，其中惡意內容劫持 LM 代理程式以洩露機密資料或觸發有害動作。現有的防禦措施 (OpenAI GPT) 在每次呼叫工具之前都需要使用者確認，這會對使用者造成沉重的負擔。我們引入了穩健的 TBAS (RTBAS)，它會自動偵測並執行保留完整性與機密性的工具呼叫，僅在無法確保這些防護措施時才需要使用者確認。RTBAS 將資訊流控制調整為 TBAS 呈現的獨特挑戰。我們提出兩種新穎的相依性篩選器，使用 LM 作為判斷者和基於注意力的顯著性，以克服這些挑戰。AgentDojo 提示注入基準上的實驗結果顯示，RTBAS 在受到攻擊時僅損失 2% 的任務效用，即可防止所有目標攻擊，進一步的測試證實了其在偵測細微和直接的隱私洩漏方面獲得接近神諭效能的能力。

##### **Biologically Plausible Brain Graph Transformer**
2502.08958v1 by Ciyuan Peng, Yuelong Huang, Qichao Dong, Shuo Yu, Feng Xia, Chengqi Zhang, Yaochu Jin

State-of-the-art brain graph analysis methods fail to fully encode the
small-world architecture of brain graphs (accompanied by the presence of hubs
and functional modules), and therefore lack biological plausibility to some
extent. This limitation hinders their ability to accurately represent the
brain's structural and functional properties, thereby restricting the
effectiveness of machine learning models in tasks such as brain disorder
detection. In this work, we propose a novel Biologically Plausible Brain Graph
Transformer (BioBGT) that encodes the small-world architecture inherent in
brain graphs. Specifically, we present a network entanglement-based node
importance encoding technique that captures the structural importance of nodes
in global information propagation during brain graph communication,
highlighting the biological properties of the brain structure. Furthermore, we
introduce a functional module-aware self-attention to preserve the functional
segregation and integration characteristics of brain graphs in the learned
representations. Experimental results on three benchmark datasets demonstrate
that BioBGT outperforms state-of-the-art models, enhancing biologically
plausible brain graph representations for various brain graph analytical tasks

摘要：目前最先进的大腦圖形分析方法無法完全編碼大腦圖形的小世界架構（伴隨著樞紐和功能模組的存在），因此在某種程度上缺乏生物學上的可信度。這種限制阻礙了它們準確表示大腦結構和功能特性的能力，從而限制了機器學習模型在腦部疾病檢測等任務中的有效性。在這項工作中，我們提出了一個新的生物學上可信的大腦圖形轉換器 (BioBGT)，它編碼了大腦圖形中固有的、小世界的架構。具體來說，我們提出了一種基於網路糾纏的節點重要性編碼技術，它捕捉了大腦圖形通信過程中節點在全球資訊傳播中的結構重要性，突出了大腦結構的生物學特性。此外，我們引入了一個功能模組感知自注意力，以保留學習表徵中大腦圖形的功能分離和整合特性。在三個基準資料集上的實驗結果表明，BioBGT 優於最先進的模型，增強了各種大腦圖形分析任務的生物學上可信的大腦圖形表徵

##### **Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs for Clinical Reasoning**
2502.08954v1 by Leon Nissen, Philipp Zagar, Vishnu Ravi, Aydin Zahedivash, Lara Marie Reimer, Stephan Jonas, Oliver Aalami, Paul Schmiedmayer

The deployment of Large Language Models (LLM) on mobile devices offers
significant potential for medical applications, enhancing privacy, security,
and cost-efficiency by eliminating reliance on cloud-based services and keeping
sensitive health data local. However, the performance and accuracy of on-device
LLMs in real-world medical contexts remain underexplored. In this study, we
benchmark publicly available on-device LLMs using the AMEGA dataset, evaluating
accuracy, computational efficiency, and thermal limitation across various
mobile devices. Our results indicate that compact general-purpose models like
Phi-3 Mini achieve a strong balance between speed and accuracy, while medically
fine-tuned models such as Med42 and Aloe attain the highest accuracy. Notably,
deploying LLMs on older devices remains feasible, with memory constraints
posing a greater challenge than raw processing power. Our study underscores the
potential of on-device LLMs for healthcare while emphasizing the need for more
efficient inference and models tailored to real-world clinical reasoning.

摘要：大型語言模型 (LLM) 在行動裝置上的部署為醫療應用程式提供了巨大的潛力，透過消除對雲端服務的依賴並將敏感的健康資料儲存在本地，進而提升隱私、安全性，並提高成本效益。然而，在實際的醫療環境中，裝置上 LLM 的效能和準確度仍未受到充分的探討。在此研究中，我們使用 AMEGA 資料集來評量公開可用的裝置上 LLM，並評估其在各種行動裝置上的準確度、運算效率和熱限制。我們的結果顯示，像 Phi-3 Mini 等精簡的一般用途模型在速度和準確度之間取得了良好的平衡，而經過醫學微調的模型，例如 Med42 和 Aloe，則達到了最高的準確度。值得注意的是，在較舊的裝置上部署 LLM 仍然可行，記憶體限制比原始處理能力構成更大的挑戰。我們的研究強調了裝置上 LLM 在醫療保健方面的潛力，同時強調了對更有效率的推理和針對實際臨床推理量身打造的模型的需求。

