{"2502.02779": {"publish_time": "2025-02-04", "title": "3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography", "paper_summary": "Head computed tomography (CT) imaging is a widely-used imaging modality with\nmultitudes of medical indications, particularly in assessing pathology of the\nbrain, skull, and cerebrovascular system. It is commonly the first-line imaging\nin neurologic emergencies given its rapidity of image acquisition, safety,\ncost, and ubiquity. Deep learning models may facilitate detection of a wide\nrange of diseases. However, the scarcity of high-quality labels and\nannotations, particularly among less common conditions, significantly hinders\nthe development of powerful models. To address this challenge, we introduce\nFM-CT: a Foundation Model for Head CT for generalizable disease detection,\ntrained using self-supervised learning. Our approach pre-trains a deep learning\nmodel on a large, diverse dataset of 361,663 non-contrast 3D head CT scans\nwithout the need for manual annotations, enabling the model to learn robust,\ngeneralizable features. To investigate the potential of self-supervised\nlearning in head CT, we employed both discrimination with self-distillation and\nmasked image modeling, and we construct our model in 3D rather than at the\nslice level (2D) to exploit the structure of head CT scans more comprehensively\nand efficiently. The model's downstream classification performance is evaluated\nusing internal and three external datasets, encompassing both in-distribution\n(ID) and out-of-distribution (OOD) data. Our results demonstrate that the\nself-supervised foundation model significantly improves performance on\ndownstream diagnostic tasks compared to models trained from scratch and\nprevious 3D CT foundation models on scarce annotated datasets. This work\nhighlights the effectiveness of self-supervised learning in medical imaging and\nsets a new benchmark for head CT image analysis in 3D, enabling broader use of\nartificial intelligence for head CT-based diagnosis.", "paper_summary_zh": "\u982d\u90e8\u96fb\u8166\u65b7\u5c64\u6383\u63cf\uff08CT\uff09\u5f71\u50cf\u662f\u4e00\u7a2e\u5ee3\u6cdb\u4f7f\u7528\u7684\u5f71\u50cf\u6a21\u5f0f\uff0c\u5177\u6709\n\u5927\u91cf\u7684\u91ab\u7642\u9069\u61c9\u75c7\uff0c\u7279\u5225\u662f\u5728\u8a55\u4f30\u8166\u90e8\u3001\u982d\u9aa8\u548c\u8166\u8840\u7ba1\u7cfb\u7d71\u7684\u75c5\u7406\u6642\u3002\u7531\u65bc\u5176\u5f71\u50cf\u64f7\u53d6\u901f\u5ea6\u5feb\u3001\u5b89\u5168\u6027\u3001\u6210\u672c\u4f4e\u548c\u666e\u904d\u6027\uff0c\u901a\u5e38\u662f\u795e\u7d93\u7dca\u6025\u60c5\u6cc1\u4e0b\u7684\u7b2c\u4e00\u7dda\u5f71\u50cf\u3002\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u53ef\u4ee5\u4fc3\u9032\u5c0d\u5404\u7a2e\u75be\u75c5\u7684\u6aa2\u6e2c\u3002\u7136\u800c\uff0c\u9ad8\u54c1\u8cea\u6a19\u7c64\u548c\u8a3b\u91cb\u7684\u7a00\u7f3a\uff0c\u7279\u5225\u662f\u5728\u8f03\u4e0d\u5e38\u898b\u7684\u75be\u75c5\u4e2d\uff0c\u986f\u8457\u5730\u963b\u7919\u4e86\u5f37\u5927\u6a21\u578b\u7684\u767c\u5c55\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 FM-CT\uff1a\u4e00\u500b\u7528\u65bc\u982d\u90e8 CT \u7684\u57fa\u790e\u6a21\u578b\uff0c\u7528\u65bc\u53ef\u6982\u5316\u7684\u75be\u75c5\u6aa2\u6e2c\uff0c\u4e26\u4f7f\u7528\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u7684\u505a\u6cd5\u5728\u4e00\u500b\u5305\u542b 361,663 \u500b\u975e\u5c0d\u6bd4 3D \u982d\u90e8 CT \u6383\u63cf\u7684\u5927\u578b\u3001\u591a\u6a23\u5316\u7684\u6578\u64da\u96c6\u4e0a\u9810\u8a13\u7df4\u4e00\u500b\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\uff0c\u800c\u7121\u9700\u624b\u52d5\u8a3b\u91cb\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u5b78\u7fd2\u5f37\u5065\u3001\u53ef\u6982\u5316\u7684\u7279\u5fb5\u3002\u70ba\u4e86\u63a2\u8a0e\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u5728\u982d\u90e8 CT \u4e2d\u7684\u6f5b\u529b\uff0c\u6211\u5011\u540c\u6642\u63a1\u7528\u4e86\u5e36\u6709\u81ea\u6211\u84b8\u993e\u7684\u5224\u5225\u548c\u906e\u7f69\u5f71\u50cf\u5efa\u6a21\uff0c\u4e26\u4e14\u6211\u5011\u4ee5 3D \u800c\u4e0d\u662f\u5207\u7247\u5c64\u7d1a\uff082D\uff09\u69cb\u5efa\u6211\u5011\u7684\u6a21\u578b\uff0c\u4ee5\u66f4\u5168\u9762\u3001\u6709\u6548\u5730\u5229\u7528\u982d\u90e8 CT \u6383\u63cf\u7684\u7d50\u69cb\u3002\u8a72\u6a21\u578b\u7684\u4e0b\u6e38\u5206\u985e\u6548\u80fd\u4f7f\u7528\u5167\u90e8\u548c\u4e09\u500b\u5916\u90e8\u6578\u64da\u96c6\u9032\u884c\u8a55\u4f30\uff0c\u5305\u62ec\u5206\u4f48\u5167 (ID) \u548c\u5206\u4f48\u5916 (OOD) \u8cc7\u6599\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u8207\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\u7684\u6a21\u578b\u548c\u5148\u524d\u5728\u7a00\u758f\u8a3b\u91cb\u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u7684 3D CT \u57fa\u790e\u6a21\u578b\u76f8\u6bd4\uff0c\u81ea\u6211\u76e3\u7763\u57fa\u790e\u6a21\u578b\u986f\u8457\u6539\u5584\u4e86\u4e0b\u6e38\u8a3a\u65b7\u4efb\u52d9\u7684\u6548\u80fd\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u5728\u91ab\u5b78\u5f71\u50cf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e26\u70ba 3D \u982d\u90e8 CT \u5f71\u50cf\u5206\u6790\u8a2d\u5b9a\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96\uff0c\u8b93\u4eba\u5de5\u667a\u6167\u80fd\u5920\u66f4\u5ee3\u6cdb\u5730\u7528\u65bc\u57fa\u65bc\u982d\u90e8 CT \u7684\u8a3a\u65b7\u3002", "author": "Weicheng Zhu et.al.", "authors": "Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell, Seena Dehkharghani, Jennifer A. Frontera, Arjun V. Masurkar, Kara Melmed, Narges Razavian", "id": "2502.02779v1", "paper_url": "http://arxiv.org/abs/2502.02779v1", "repo": "null"}}