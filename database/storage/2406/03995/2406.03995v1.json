{"2406.03995": {"publish_time": "2024-06-06", "title": "AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control", "paper_summary": "\\Ac{MPC} and \\ac{RL} are two powerful control strategies with, arguably,\ncomplementary advantages. In this work, we show how actor-critic \\ac{RL}\ntechniques can be leveraged to improve the performance of \\ac{MPC}. The \\ac{RL}\ncritic is used as an approximation of the optimal value function, and an actor\nroll-out provides an initial guess for primal variables of the \\ac{MPC}. A\nparallel control architecture is proposed where each \\ac{MPC} instance is\nsolved twice for different initial guesses. Besides the actor roll-out\ninitialization, a shifted initialization from the previous solution is used.\nThereafter, the actor and the critic are again used to approximately evaluate\nthe infinite horizon cost of these trajectories. The control actions from the\nlowest-cost trajectory are applied to the system at each time step. We\nestablish that the proposed algorithm is guaranteed to outperform the original\n\\ac{RL} policy plus an error term that depends on the accuracy of the critic\nand decays with the horizon length of the \\ac{MPC} formulation. Moreover, we do\nnot require globally optimal solutions for these guarantees to hold. The\napproach is demonstrated on an illustrative toy example and an \\ac{AD}\novertaking scenario.", "paper_summary_zh": "\\Ac{MPC} \u548c \\ac{RL} \u662f\u4e24\u79cd\u5f3a\u5927\u7684\u63a7\u5236\u7b56\u7565\uff0c\u53ef\u4ee5\u4e89\u8fa9\u8bf4\uff0c\u5177\u6709\u4e92\u8865\u7684\u4f18\u52bf\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528 actor-critic \\ac{RL} \u6280\u672f\u6765\u63d0\u9ad8 \\ac{MPC} \u7684\u6027\u80fd\u3002\\ac{RL} \u8bc4\u8bba\u8005\u7528\u4f5c\u6700\u4f18\u503c\u51fd\u6570\u7684\u8fd1\u4f3c\u503c\uff0c\u5e76\u4e14 actor roll-out \u4e3a \\ac{MPC} \u7684\u539f\u59cb\u53d8\u91cf\u63d0\u4f9b\u521d\u59cb\u731c\u6d4b\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u63a7\u5236\u67b6\u6784\uff0c\u5176\u4e2d\u6bcf\u4e2a \\ac{MPC} \u5b9e\u4f8b\u9488\u5bf9\u4e0d\u540c\u7684\u521d\u59cb\u731c\u6d4b\u6c42\u89e3\u4e24\u6b21\u3002\u9664\u4e86 actor roll-out \u521d\u59cb\u5316\u4e4b\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86\u524d\u4e00\u4e2a\u89e3\u7684\u504f\u79fb\u521d\u59cb\u5316\u3002\u6b64\u540e\uff0cactor \u548c\u8bc4\u8bba\u8005\u518d\u6b21\u7528\u4e8e\u8fd1\u4f3c\u8bc4\u4f30\u8fd9\u4e9b\u8f68\u8ff9\u7684\u65e0\u9650\u8303\u56f4\u6210\u672c\u3002\u6765\u81ea\u6700\u4f4e\u6210\u672c\u8f68\u8ff9\u7684\u63a7\u5236\u52a8\u4f5c\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u957f\u5e94\u7528\u4e8e\u7cfb\u7edf\u3002\u6211\u4eec\u786e\u5b9a\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4fdd\u8bc1\u4f18\u4e8e\u539f\u59cb \\ac{RL} \u7b56\u7565\uff0c\u52a0\u4e0a\u4e00\u4e2a\u8bef\u5dee\u9879\uff0c\u8be5\u8bef\u5dee\u9879\u53d6\u51b3\u4e8e\u8bc4\u8bba\u8005\u7684\u51c6\u786e\u6027\uff0c\u5e76\u968f\u7740 \\ac{MPC} \u516c\u5f0f\u7684\u8303\u56f4\u957f\u5ea6\u800c\u8870\u51cf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u5168\u5c40\u6700\u4f18\u89e3\u6765\u4fdd\u6301\u8fd9\u4e9b\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u5728\u4e00\u4e2a\u8bf4\u660e\u6027\u73a9\u5177\u793a\u4f8b\u548c\u4e00\u4e2a \\ac{AD} \u8d85\u8f66\u573a\u666f\u4e2d\u5f97\u5230\u8bc1\u660e\u3002", "author": "Rudolf Reiter et.al.", "authors": "Rudolf Reiter, Andrea Ghezzi, Katrin Baumg\u00e4rtner, Jasper Hoffmann, Robert D. McAllister, Moritz Diehl", "id": "2406.03995v1", "paper_url": "http://arxiv.org/abs/2406.03995v1", "repo": "null"}}