{"2412.06540": {"publish_time": "2024-12-09", "title": "Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families", "paper_summary": "Scaling laws for large language models (LLMs) predict model performance based\non parameters like size and training data. However, differences in training\nconfigurations and data processing across model families lead to significant\nvariations in benchmark performance, making it difficult for a single scaling\nlaw to generalize across all LLMs. On the other hand, training family-specific\nscaling laws requires training models of varying sizes for every family. In\nthis work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a\nnovel scaling law that leverages publicly available benchmark data and assumes\nLLM performance is driven by low-dimensional latent skills, such as reasoning\nand instruction following. These latent skills are influenced by computational\nresources like model size and training tokens but with varying efficiencies\nacross model families. Sloth exploits correlations across benchmarks to provide\nmore accurate and interpretable predictions while alleviating the need to train\nmultiple LLMs per family. We present both theoretical results on parameter\nidentification and empirical evaluations on 12 prominent benchmarks, from Open\nLLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance\nefficiently and offers insights into scaling behaviors for downstream tasks\nsuch as coding and emotional intelligence applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u898f\u6a21\u5b9a\u5f8b\u9810\u6e2c\u6a21\u578b\u6548\u80fd\u57fa\u65bc\u5927\u5c0f\u548c\u8a13\u7df4\u8cc7\u6599\u7b49\u53c3\u6578\u3002\u7136\u800c\uff0c\u5728\u6a21\u578b\u5bb6\u65cf\u4e2d\u8a13\u7df4\u7d44\u614b\u548c\u8cc7\u6599\u8655\u7406\u7684\u5dee\u7570\u5c0e\u81f4\u57fa\u6e96\u6548\u80fd\u6709\u986f\u8457\u7684\u8b8a\u5316\uff0c\u4f7f\u5f97\u55ae\u4e00\u898f\u6a21\u5b9a\u5f8b\u96e3\u4ee5\u6982\u62ec\u6240\u6709 LLM\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u8a13\u7df4\u7279\u5b9a\u65bc\u5bb6\u65cf\u7684\u898f\u6a21\u5b9a\u5f8b\u9700\u8981\u70ba\u6bcf\u500b\u5bb6\u65cf\u8a13\u7df4\u4e0d\u540c\u898f\u6a21\u7684\u6a21\u578b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u6280\u80fd\u898f\u6a21\u5b9a\u5f8b (SSLaws\uff0c\u767c\u97f3\u70ba Sloth)\uff0c\u4e00\u7a2e\u5275\u65b0\u7684\u898f\u6a21\u5b9a\u5f8b\uff0c\u5229\u7528\u516c\u958b\u53ef\u7528\u7684\u57fa\u6e96\u8cc7\u6599\uff0c\u4e26\u5047\u8a2d LLM \u6548\u80fd\u662f\u7531\u4f4e\u7dad\u5ea6\u6f5b\u5728\u6280\u80fd\u9a45\u52d5\u7684\uff0c\u4f8b\u5982\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u3002\u9019\u4e9b\u6f5b\u5728\u6280\u80fd\u53d7\u5230\u6a21\u578b\u5927\u5c0f\u548c\u8a13\u7df4\u6a19\u8a18\u7b49\u8a08\u7b97\u8cc7\u6e90\u7684\u5f71\u97ff\uff0c\u4f46\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e2d\u6548\u7387\u4e0d\u540c\u3002Sloth \u5229\u7528\u57fa\u6e96\u4e4b\u9593\u7684\u95dc\u806f\u6027\u63d0\u4f9b\u66f4\u6e96\u78ba\u4e14\u53ef\u89e3\u91cb\u7684\u9810\u6e2c\uff0c\u540c\u6642\u6e1b\u8f15\u8a13\u7df4\u6bcf\u500b\u5bb6\u65cf\u591a\u500b LLM \u7684\u9700\u6c42\u3002\u6211\u5011\u5728\u53c3\u6578\u8fa8\u8b58\u4e0a\u63d0\u51fa\u7406\u8ad6\u7d50\u679c\uff0c\u4e26\u5728 12 \u500b Open LLM Leaderboard v1/v2 \u4e2d\u9032\u884c\u5be6\u8b49\u8a55\u4f30\uff0c\u8b49\u660e Sloth \u6709\u6548\u9810\u6e2c LLM \u6548\u80fd\uff0c\u4e26\u63d0\u4f9b\u5c0d\u4e0b\u6e38\u4efb\u52d9\uff08\u4f8b\u5982\u7de8\u78bc\u548c\u60c5\u7dd2\u667a\u529b\u61c9\u7528\uff09\u7684\u898f\u6a21\u884c\u70ba\u898b\u89e3\u3002", "author": "Felipe Maia Polo et.al.", "authors": "Felipe Maia Polo, Seamus Somerstep, Leshem Choshen, Yuekai Sun, Mikhail Yurochkin", "id": "2412.06540v1", "paper_url": "http://arxiv.org/abs/2412.06540v1", "repo": "null"}}