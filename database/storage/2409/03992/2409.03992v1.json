{"2409.03992": {"publish_time": "2024-09-06", "title": "Confidential Computing on nVIDIA H100 GPU: A Performance Benchmark Study", "paper_summary": "This report evaluates the performance impact of enabling Trusted Execution\nEnvironments (TEE) on NVIDIA H100 GPUs for large language model (LLM) inference\ntasks. We benchmark the overhead introduced by TEE mode across various models\nand token lengths, focusing on the bottleneck caused by CPU-GPU data transfers\nvia PCIe. Our results show that while there is minimal computational overhead\nwithin the GPU, the overall performance penalty is primarily due to data\ntransfer. For most typical LLM queries, the overhead remains below 5%, with\nlarger models and longer sequences experiencing near-zero overhead.", "paper_summary_zh": "\u672c\u5831\u544a\u8a55\u4f30\u5728 NVIDIA H100 GPU \u4e0a\u555f\u7528\u53ef\u4fe1\u57f7\u884c\u74b0\u5883 (TEE) \u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63a8\u8ad6\u4efb\u52d9\u7684\u6548\u80fd\u5f71\u97ff\u3002\u6211\u5011\u6bd4\u8f03\u4e86 TEE \u6a21\u5f0f\u5728\u5404\u7a2e\u6a21\u578b\u548c\u4ee4\u724c\u9577\u5ea6\u4e0b\u7522\u751f\u7684\u984d\u5916\u8ca0\u64d4\uff0c\u91cd\u9ede\u5728\u65bc CPU-GPU \u8cc7\u6599\u50b3\u8f38\u900f\u904e PCIe \u9020\u6210\u7684\u74f6\u9838\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5118\u7ba1 GPU \u5167\u90e8\u904b\u7b97\u8ca0\u64d4\u5f88\u5c0f\uff0c\u6574\u9ad4\u6548\u80fd\u640d\u5931\u4e3b\u8981\u4f86\u81ea\u8cc7\u6599\u50b3\u8f38\u3002\u5c0d\u65bc\u5927\u591a\u6578\u5178\u578b\u7684 LLM \u67e5\u8a62\uff0c\u984d\u5916\u8ca0\u64d4\u4f4e\u65bc 5%\uff0c\u800c\u8f03\u5927\u7684\u6a21\u578b\u548c\u8f03\u9577\u7684\u5e8f\u5217\u5247\u5e7e\u4e4e\u6c92\u6709\u984d\u5916\u8ca0\u64d4\u3002", "author": "Jianwei Zhu et.al.", "authors": "Jianwei Zhu, Hang Yin, Shunfan Zhou", "id": "2409.03992v1", "paper_url": "http://arxiv.org/abs/2409.03992v1", "repo": "null"}}