{"2406.07327": {"publish_time": "2024-06-11", "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward", "paper_summary": "Aligning large language models (LLMs) with human preference has recently\ngained tremendous attention, with the canonical yet costly RLHF-PPO and the\nsimple and straightforward Direct Preference Optimization (DPO) as two\nexamples. Despite the efficiency, DPO has rarely be used in the\nstate-of-the-art production-level LLMs, implying its potential pathologies. In\nthis work, we revisit DPO with a comprehensive examination of its empirical\nefficacy and a systematic comparison with RLHF-PPO. We identify the\n\\textbf{3D}-properties of DPO's learning outcomes: the \\textbf{D}rastic drop in\nthe likelihood of rejected responses, the \\textbf{D}egradation into LLM\nunlearning, and the \\textbf{D}ispersion effect on unseen responses through\nexperiments with both a carefully designed toy model and practical LLMs on\ntasks including mathematical problem-solving and instruction following. These\nfindings inherently connect to some observations made by related works and we\nadditionally contribute a plausible theoretical explanation for them.\nAccordingly, we propose easy regularization methods to mitigate the issues\ncaused by \\textbf{3D}-properties, improving the training stability and final\nperformance of DPO. Our contributions also include an investigation into how\nthe distribution of the paired preference data impacts the effectiveness of\nDPO. We hope this work could offer research directions to narrow the gap\nbetween reward-free preference learning methods and reward-based ones.", "paper_summary_zh": "<paragraph>\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u504f\u597d\u4e00\u81f4\u5316\u6700\u8fd1\u53d7\u5230\u6975\u5927\u7684\u95dc\u6ce8\uff0c\u5176\u4e2d\u5178\u578b\u7684\u4f46\u4ee3\u50f9\u9ad8\u6602\u7684 RLHF-PPO \u548c\u7c21\u55ae\u76f4\u63a5\u7684\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u5c31\u662f\u5169\u500b\u7bc4\u4f8b\u3002\u5118\u7ba1\u6548\u7387\u9ad8\uff0c\u4f46 DPO \u5728\u6700\u5148\u9032\u7684\u751f\u7522\u7d1a LLM \u4e2d\u5f88\u5c11\u4f7f\u7528\uff0c\u9019\u610f\u5473\u8457\u5176\u6f5b\u5728\u7684\u75c5\u7406\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ee5\u5168\u9762\u6aa2\u8996\u5176\u7d93\u9a57\u6548\u80fd\u548c\u8207 RLHF-PPO \u7684\u7cfb\u7d71\u6bd4\u8f03\uff0c\u91cd\u65b0\u63a2\u8a0e DPO\u3002\u6211\u5011\u627e\u51fa DPO \u5b78\u7fd2\u6210\u679c\u7684\u300c3D\u300d\u7279\u6027\uff1a\u88ab\u62d2\u7d55\u56de\u61c9\u7684\u6a5f\u7387\u5927\u5e45\u4e0b\u964d (Drastic drop)\u3001\u60e1\u5316\u6210 LLM \u5931\u5b78 (Degradation) \u4ee5\u53ca\u900f\u904e\u4ed4\u7d30\u8a2d\u8a08\u7684\u73a9\u5177\u6a21\u578b\u548c\u5be6\u969b LLM \u9032\u884c\u7684\u5be6\u9a57\uff0c\u5c0d\u672a\u898b\u904e\u56de\u61c9\u7522\u751f\u5206\u6563\u6548\u61c9 (Dispersion effect)\uff0c\u9019\u4e9b\u4efb\u52d9\u5305\u62ec\u6578\u5b78\u554f\u984c\u6c42\u89e3\u548c\u9075\u5faa\u6307\u4ee4\u3002\u9019\u4e9b\u767c\u73fe\u8207\u76f8\u95dc\u5de5\u4f5c\u6240\u505a\u7684\u67d0\u4e9b\u89c0\u5bdf\u672c\u8cea\u4e0a\u76f8\u95dc\u806f\uff0c\u800c\u4e14\u6211\u5011\u9032\u4e00\u6b65\u70ba\u5b83\u5011\u63d0\u4f9b\u5408\u7406\u7684\u7406\u8ad6\u89e3\u91cb\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u7c21\u55ae\u7684\u6b63\u5247\u5316\u65b9\u6cd5\u4f86\u6e1b\u8f15\u7531\u300c3D\u300d\u7279\u6027\u6240\u9020\u6210\u7684\u8b70\u984c\uff0c\u6539\u5584 DPO \u7684\u8a13\u7df4\u7a69\u5b9a\u6027\u548c\u6700\u7d42\u6548\u80fd\u3002\u6211\u5011\u7684\u8ca2\u737b\u9084\u5305\u62ec\u8abf\u67e5\u914d\u5c0d\u504f\u597d\u8cc7\u6599\u7684\u5206\u914d\u5982\u4f55\u5f71\u97ff DPO \u7684\u6548\u80fd\u3002\u6211\u5011\u5e0c\u671b\u9019\u9805\u5de5\u4f5c\u53ef\u4ee5\u63d0\u4f9b\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u7e2e\u5c0f\u7121\u734e\u52f5\u504f\u597d\u5b78\u7fd2\u65b9\u6cd5\u548c\u57fa\u65bc\u734e\u52f5\u7684\u504f\u597d\u5b78\u7fd2\u65b9\u6cd5\u4e4b\u9593\u7684\u5dee\u8ddd\u3002</paragraph>", "author": "Yuzi Yan et.al.", "authors": "Yuzi Yan, Yibo Miao, Jialian Li, Yipin Zhang, Jian Xie, Zhijie Deng, Dong Yan", "id": "2406.07327v1", "paper_url": "http://arxiv.org/abs/2406.07327v1", "repo": "null"}}