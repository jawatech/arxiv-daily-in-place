{"2411.18179": {"publish_time": "2024-11-27", "title": "Prediction with Action: Visual Policy Learning via Joint Denoising Process", "paper_summary": "Diffusion models have demonstrated remarkable capabilities in image\ngeneration tasks, including image editing and video creation, representing a\ngood understanding of the physical world. On the other line, diffusion models\nhave also shown promise in robotic control tasks by denoising actions, known as\ndiffusion policy. Although the diffusion generative model and diffusion policy\nexhibit distinct capabilities--image prediction and robotic action,\nrespectively--they technically follow a similar denoising process. In robotic\ntasks, the ability to predict future images and generate actions is highly\ncorrelated since they share the same underlying dynamics of the physical world.\nBuilding on this insight, we introduce PAD, a novel visual policy learning\nframework that unifies image Prediction and robot Action within a joint\nDenoising process. Specifically, PAD utilizes Diffusion Transformers (DiT) to\nseamlessly integrate images and robot states, enabling the simultaneous\nprediction of future images and robot actions. Additionally, PAD supports\nco-training on both robotic demonstrations and large-scale video datasets and\ncan be easily extended to other robotic modalities, such as depth images. PAD\noutperforms previous methods, achieving a significant 26.3% relative\nimprovement on the full Metaworld benchmark, by utilizing a single\ntext-conditioned visual policy within a data-efficient imitation learning\nsetting. Furthermore, PAD demonstrates superior generalization to unseen tasks\nin real-world robot manipulation settings with 28.0% success rate increase\ncompared to the strongest baseline. Project page at\nhttps://sites.google.com/view/pad-paper", "paper_summary_zh": "\u64f4\u6563\u6a21\u578b\u5df2\u5728\u5f71\u50cf\u751f\u6210\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u5305\u62ec\u5f71\u50cf\u7de8\u8f2f\u548c\u5f71\u7247\u5275\u4f5c\uff0c\u4ee3\u8868\u8457\u5c0d\u7269\u7406\u4e16\u754c\u7684\u826f\u597d\u7406\u89e3\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u64f4\u6563\u6a21\u578b\u4e5f\u5df2\u5728\u6a5f\u5668\u4eba\u63a7\u5236\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u524d\u666f\uff0c\u900f\u904e\u6d88\u9664\u52d5\u4f5c\u96dc\u8a0a\uff0c\u7a31\u70ba\u64f4\u6563\u7b56\u7565\u3002\u5118\u7ba1\u64f4\u6563\u751f\u6210\u6a21\u578b\u548c\u64f4\u6563\u7b56\u7565\u5c55\u73fe\u51fa\u4e0d\u540c\u7684\u80fd\u529b\u2014\u2014\u5206\u5225\u70ba\u5f71\u50cf\u9810\u6e2c\u548c\u6a5f\u5668\u4eba\u52d5\u4f5c\uff0c\u4f46\u5728\u6280\u8853\u4e0a\uff0c\u5b83\u5011\u9075\u5faa\u985e\u4f3c\u7684\u53bb\u96dc\u8a0a\u7a0b\u5e8f\u3002\u5728\u6a5f\u5668\u4eba\u4efb\u52d9\u4e2d\uff0c\u9810\u6e2c\u672a\u4f86\u5f71\u50cf\u548c\u7522\u751f\u52d5\u4f5c\u7684\u80fd\u529b\u9ad8\u5ea6\u76f8\u95dc\uff0c\u56e0\u70ba\u5b83\u5011\u5171\u7528\u7269\u7406\u4e16\u754c\u7684\u76f8\u540c\u57fa\u790e\u52d5\u614b\u3002\u57fa\u65bc\u6b64\u898b\u89e3\uff0c\u6211\u5011\u5f15\u9032 PAD\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u8996\u89ba\u7b56\u7565\u5b78\u7fd2\u67b6\u69cb\uff0c\u5728\u806f\u5408\u53bb\u96dc\u8a0a\u7a0b\u5e8f\u4e2d\u7d71\u4e00\u5f71\u50cf\u9810\u6e2c\u548c\u6a5f\u5668\u4eba\u52d5\u4f5c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cPAD \u4f7f\u7528\u64f4\u6563Transformer (DiT) \u4f86\u7121\u7e2b\u6574\u5408\u5f71\u50cf\u548c\u6a5f\u5668\u4eba\u72c0\u614b\uff0c\u540c\u6642\u9810\u6e2c\u672a\u4f86\u5f71\u50cf\u548c\u6a5f\u5668\u4eba\u52d5\u4f5c\u3002\u6b64\u5916\uff0cPAD \u652f\u63f4\u5728\u6a5f\u5668\u4eba\u793a\u7bc4\u548c\u5927\u578b\u5f71\u7247\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5171\u540c\u8a13\u7df4\uff0c\u4e26\u4e14\u53ef\u4ee5\u8f15\u9b06\u5ef6\u4f38\u5230\u5176\u4ed6\u6a5f\u5668\u4eba\u6a21\u5f0f\uff0c\u4f8b\u5982\u6df1\u5ea6\u5f71\u50cf\u3002PAD \u512a\u65bc\u5148\u524d\u7684\u5404\u7a2e\u65b9\u6cd5\uff0c\u5728\u5b8c\u6574\u7684 Metaworld \u57fa\u6e96\u4e0a\u5be6\u73fe\u986f\u8457\u7684 26.3% \u76f8\u5c0d\u9032\u6b65\uff0c\u65b9\u6cd5\u662f\u5728\u8cc7\u6599\u6709\u6548\u7387\u7684\u6a21\u4eff\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u4f7f\u7528\u55ae\u4e00\u6587\u5b57\u689d\u4ef6\u8996\u89ba\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8207\u6700\u5f37\u5927\u7684\u57fa\u6e96\u76f8\u6bd4\uff0cPAD \u5728\u771f\u5be6\u4e16\u754c\u6a5f\u5668\u4eba\u64cd\u4f5c\u8a2d\u5b9a\u4e2d\u5c55\u73fe\u51fa\u5c0d\u672a\u898b\u4efb\u52d9\u7684\u512a\u7570\u6cdb\u5316\u80fd\u529b\uff0c\u6210\u529f\u7387\u589e\u52a0\u4e86 28.0%\u3002\u5c08\u6848\u9801\u9762\u5728 https://sites.google.com/view/pad-paper", "author": "Yanjiang Guo et.al.", "authors": "Yanjiang Guo, Yucheng Hu, Jianke Zhang, Yen-Jen Wang, Xiaoyu Chen, Chaochao Lu, Jianyu Chen", "id": "2411.18179v1", "paper_url": "http://arxiv.org/abs/2411.18179v1", "repo": "null"}}