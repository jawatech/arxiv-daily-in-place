{"2502.04392": {"publish_time": "2025-02-06", "title": "Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents", "paper_summary": "The rapid expansion of web content has made on-device AI assistants\nindispensable for helping users manage the increasing complexity of online\ntasks. The emergent reasoning ability in large language models offer a\npromising path for next-generation on-device AI agents. However, deploying\nfull-scale Large Language Models (LLMs) on resource-limited local devices is\nchallenging. In this paper, we propose Division-of-Thoughts (DoT), a\ncollaborative reasoning framework leveraging the synergy between locally\ndeployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT\nleverages a Task Decomposer to elicit the inherent planning abilities in\nlanguage models to decompose user queries into smaller sub-tasks, which allows\nhybrid language models to fully exploit their respective strengths. Besides,\nDoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks\nand create a dependency graph, facilitating parallel reasoning of sub-tasks and\nthe identification of key steps. To allocate the appropriate model based on the\ndifficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an\nadditional task head attached to the SLM that does not alter the SLM's\nparameters. To boost adapter's task allocation capability, we propose a\nself-reinforced training method that relies solely on task execution feedback.\nExtensive experiments on various benchmarks demonstrate that our DoT\nsignificantly reduces LLM costs while maintaining competitive reasoning\naccuracy. Specifically, DoT reduces the average reasoning time and API costs by\n66.12% and 83.57%, while achieving comparable reasoning accuracy with the best\nbaseline methods.", "paper_summary_zh": "<paragraph>\u7db2\u9801\u5167\u5bb9\u5feb\u901f\u64f4\u5145\uff0c\u4f7f\u5f97\u884c\u52d5\u88dd\u7f6e\u4e0a\u7684 AI \u52a9\u7406\u5728\u5354\u52a9\u4f7f\u7528\u8005\u7ba1\u7406\u65e5\u76ca\u8907\u96dc\u7684\u7dda\u4e0a\u5de5\u4f5c\u4e0a\u8b8a\u5f97\u4e0d\u53ef\u6216\u7f3a\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\u6d6e\u73fe\u7684\u63a8\u7406\u80fd\u529b\u70ba\u65b0\u4e00\u4ee3\u884c\u52d5\u88dd\u7f6e\u4e0a\u7684 AI \u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u689d\u6709\u5e0c\u671b\u7684\u9014\u5f91\u3002\u7136\u800c\uff0c\u5728\u8cc7\u6e90\u6709\u9650\u7684\u672c\u6a5f\u88dd\u7f6e\u4e0a\u90e8\u7f72\u5168\u898f\u6a21\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u4e00\u9805\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u601d\u60f3\u5206\u5de5 (DoT)\uff0c\u4e00\u500b\u5354\u4f5c\u63a8\u7406\u6846\u67b6\uff0c\u5229\u7528\u4e86\u672c\u5730\u90e8\u7f72\u7684\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b (SLM) \u8207\u96f2\u7aef LLM \u4e4b\u9593\u7684\u5354\u540c\u6548\u61c9\u3002DoT \u5229\u7528\u4efb\u52d9\u5206\u89e3\u5668\u5f15\u51fa\u8a9e\u8a00\u6a21\u578b\u4e2d\u56fa\u6709\u7684\u898f\u5283\u80fd\u529b\uff0c\u5c07\u4f7f\u7528\u8005\u67e5\u8a62\u5206\u89e3\u6210\u8f03\u5c0f\u7684\u5b50\u4efb\u52d9\uff0c\u9019\u5141\u8a31\u6df7\u5408\u8a9e\u8a00\u6a21\u578b\u5145\u5206\u767c\u63ee\u5176\u5404\u81ea\u7684\u512a\u52e2\u3002\u6b64\u5916\uff0cDoT \u96c7\u7528\u4e86\u4e00\u500b\u4efb\u52d9\u6392\u7a0b\u5668\u4f86\u5206\u6790\u5b50\u4efb\u52d9\u7684\u6210\u5c0d\u4f9d\u8cf4\u6027\u4e26\u5efa\u7acb\u4e00\u500b\u4f9d\u8cf4\u6027\u5716\uff0c\u4fc3\u9032\u5b50\u4efb\u52d9\u7684\u4e26\u884c\u63a8\u7406\u548c\u95dc\u9375\u6b65\u9a5f\u7684\u8b58\u5225\u3002\u70ba\u4e86\u6839\u64da\u5b50\u4efb\u52d9\u7684\u96e3\u5ea6\u5206\u914d\u9069\u7576\u7684\u6a21\u578b\uff0cDoT \u5229\u7528\u4e86\u5373\u63d2\u5373\u7528\u9069\u914d\u5668\uff0c\u9019\u662f\u4e00\u500b\u9644\u52a0\u5728 SLM \u4e0a\u7684\u4efb\u52d9\u982d\uff0c\u4e0d\u6703\u6539\u8b8a SLM \u7684\u53c3\u6578\u3002\u70ba\u4e86\u63d0\u5347\u9069\u914d\u5668\u7684\u4efb\u52d9\u5206\u914d\u80fd\u529b\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u81ea\u6211\u5f37\u5316\u8a13\u7df4\u65b9\u6cd5\uff0c\u5b83\u50c5\u4f9d\u8cf4\u65bc\u4efb\u52d9\u57f7\u884c\u56de\u994b\u3002\u5728\u5404\u7a2e\u57fa\u6e96\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684 DoT \u5927\u5e45\u964d\u4f4e\u4e86 LLM \u6210\u672c\uff0c\u540c\u6642\u7dad\u6301\u4e86\u6709\u7af6\u722d\u529b\u7684\u63a8\u7406\u6e96\u78ba\u5ea6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cDoT \u5c07\u5e73\u5747\u63a8\u7406\u6642\u9593\u548c API \u6210\u672c\u5206\u5225\u964d\u4f4e\u4e86 66.12% \u548c 83.57%\uff0c\u540c\u6642\u9054\u5230\u4e86\u8207\u6700\u4f73\u57fa\u6e96\u65b9\u6cd5\u76f8\u7576\u7684\u63a8\u7406\u6e96\u78ba\u5ea6\u3002</paragraph>", "author": "Chenyang Shao et.al.", "authors": "Chenyang Shao, Xinyuan Hu, Yutang Lin, Fengli Xu", "id": "2502.04392v1", "paper_url": "http://arxiv.org/abs/2502.04392v1", "repo": "null"}}