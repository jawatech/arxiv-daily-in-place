
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-13**|**4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**|Mijeong Kim et.al.|[2411.08879v1](http://arxiv.org/abs/2411.08879v1)|null|
|**2024-11-13**|**The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**|Daniel P. Jeong et.al.|[2411.08870v1](http://arxiv.org/abs/2411.08870v1)|null|
|**2024-11-13**|**CamemBERT 2.0: A Smarter French Language Model Aged to Perfection**|Wissam Antoun et.al.|[2411.08868v1](http://arxiv.org/abs/2411.08868v1)|null|
|**2024-11-13**|**Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale**|Alberto Carpentieri et.al.|[2411.08843v1](http://arxiv.org/abs/2411.08843v1)|null|
|**2024-11-13**|**AstroM$^3$: A self-supervised multimodal model for astronomy**|Mariia Rizhko et.al.|[2411.08842v1](http://arxiv.org/abs/2411.08842v1)|null|
|**2024-11-13**|**Offline Adaptation of Quadruped Locomotion using Diffusion Models**|Reece O'Mahoney et.al.|[2411.08832v1](http://arxiv.org/abs/2411.08832v1)|null|
|**2024-11-13**|**Process-aware Human Activity Recognition**|Jiawei Zheng et.al.|[2411.08814v1](http://arxiv.org/abs/2411.08814v1)|null|
|**2024-11-13**|**Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique**|Suhas Hariharan et.al.|[2411.08813v1](http://arxiv.org/abs/2411.08813v1)|null|
|**2024-11-13**|**Evaluating World Models with LLM for Decision Making**|Chang Yang et.al.|[2411.08794v1](http://arxiv.org/abs/2411.08794v1)|null|
|**2024-11-13**|**Can sparse autoencoders be used to decompose and interpret steering vectors?**|Harry Mayne et.al.|[2411.08790v1](http://arxiv.org/abs/2411.08790v1)|[link](https://github.com/harrymayne/sv_interpretability)|
|**2024-11-13**|**Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training**|Nghia Trung Ngo et.al.|[2411.08785v1](http://arxiv.org/abs/2411.08785v1)|null|
|**2024-11-13**|**Sharingan: Extract User Action Sequence from Desktop Recordings**|Yanting Chen et.al.|[2411.08768v1](http://arxiv.org/abs/2411.08768v1)|null|
|**2024-11-13**|**SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate**|Yifei Jin et.al.|[2411.08767v1](http://arxiv.org/abs/2411.08767v1)|null|
|**2024-11-13**|**Flow reconstruction in time-varying geometries using graph neural networks**|Bogdan A. Danciu et.al.|[2411.08764v1](http://arxiv.org/abs/2411.08764v1)|null|
|**2024-11-13**|**Multi-Perspective Stance Detection**|Benedetta Muscato et.al.|[2411.08752v1](http://arxiv.org/abs/2411.08752v1)|[link](https://github.com/praveensonu/Multi-perspective-Stance-Detection)|
|**2024-11-13**|**Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers**|Clément Dumas et.al.|[2411.08745v1](http://arxiv.org/abs/2411.08745v1)|[link](https://github.com/butanium/llm-lang-agnostic)|
|**2024-11-13**|**A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models**|Dingdong Wang et.al.|[2411.08742v1](http://arxiv.org/abs/2411.08742v1)|null|
|**2024-11-13**|**Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models**|Somanshu Singla et.al.|[2411.08733v1](http://arxiv.org/abs/2411.08733v1)|null|
|**2024-11-13**|**Polymetis:Large Language Modeling for Multiple Material Domains**|Chao Huang et.al.|[2411.08728v1](http://arxiv.org/abs/2411.08728v1)|null|
|**2024-11-13**|**Analyst Reports and Stock Performance: Evidence from the Chinese Market**|Rui Liu et.al.|[2411.08726v1](http://arxiv.org/abs/2411.08726v1)|null|
|**2024-11-13**|**Are Triggers Needed for Document-Level Event Extraction?**|Shaden Shaar et.al.|[2411.08708v1](http://arxiv.org/abs/2411.08708v1)|null|
|**2024-11-13**|**Searching Latent Program Spaces**|Clément Bonnet et.al.|[2411.08706v1](http://arxiv.org/abs/2411.08706v1)|[link](https://github.com/clement-bonnet/lpn)|
|**2024-11-13**|**Rethinking negative sampling in content-based news recommendation**|Miguel Ângelo Rebelo et.al.|[2411.08700v1](http://arxiv.org/abs/2411.08700v1)|null|
|**2024-11-13**|**Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs**|Nandana Mihindukulasooriya et.al.|[2411.08696v1](http://arxiv.org/abs/2411.08696v1)|null|
|**2024-11-13**|**Theoretical Analysis of Byte-Pair Encoding**|László Kozma et.al.|[2411.08671v1](http://arxiv.org/abs/2411.08671v1)|null|
|**2024-11-13**|**A Survey on Vision Autoregressive Model**|Kai Jiang et.al.|[2411.08666v1](http://arxiv.org/abs/2411.08666v1)|null|
|**2024-11-13**|**Estimating unknown parameters in differential equations with a reinforcement learning based PSO method**|Wenkui Sun et.al.|[2411.08651v1](http://arxiv.org/abs/2411.08651v1)|null|
|**2024-11-13**|**A System Level Performance Evaluation for Superconducting Digital Systems**|Joyjit Kundu et.al.|[2411.08645v1](http://arxiv.org/abs/2411.08645v1)|null|
|**2024-11-13**|**Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models**|Chengdong Dong et.al.|[2411.08642v1](http://arxiv.org/abs/2411.08642v1)|null|
|**2024-11-13**|**Precision-Focused Reinforcement Learning Model for Robotic Object Pushing**|Lara Bergmann et.al.|[2411.08622v1](http://arxiv.org/abs/2411.08622v1)|[link](https://github.com/ubi-coro/precise_pushing)|
|**2024-11-13**|**Dynamic Subset Tuning: Expanding the Operational Range of Parameter-Efficient Training for Large Language Models**|Felix Stahlberg et.al.|[2411.08610v1](http://arxiv.org/abs/2411.08610v1)|null|
|**2024-11-13**|**XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL**|Yingqi Gao et.al.|[2411.08599v1](http://arxiv.org/abs/2411.08599v1)|null|
|**2024-11-13**|**DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods**|Rebecca Nevin et.al.|[2411.08587v1](http://arxiv.org/abs/2411.08587v1)|[link](https://github.com/deepskies/deepuq-neurips-ws-2024)|
|**2024-11-13**|**Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**|Guoqing Zhang et.al.|[2411.08586v1](http://arxiv.org/abs/2411.08586v1)|null|
|**2024-11-13**|**Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors**|Stepan Svirin et.al.|[2411.08582v1](http://arxiv.org/abs/2411.08582v1)|null|
|**2024-11-13**|**Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions**|Micha Kaiser et.al.|[2411.08563v1](http://arxiv.org/abs/2411.08563v1)|null|
|**2024-11-13**|**Neural Corrective Machine Unranking**|Jingrui Hou et.al.|[2411.08562v1](http://arxiv.org/abs/2411.08562v1)|null|
|**2024-11-13**|**LogLLM: Log-based Anomaly Detection Using Large Language Models**|Wei Guan et.al.|[2411.08561v1](http://arxiv.org/abs/2411.08561v1)|[link](https://github.com/guanwei49/logllm)|
|**2024-11-13**|**CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs**|Suhas S Kowshik et.al.|[2411.08553v1](http://arxiv.org/abs/2411.08553v1)|null|
|**2024-11-13**|**Deeper Insights into Learning Performance of Stochastic Configuration Networks**|Xiufeng Yan et.al.|[2411.08544v1](http://arxiv.org/abs/2411.08544v1)|null|
|**2024-11-13**|**MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation**|Fabian Bongratz et.al.|[2411.08537v1](http://arxiv.org/abs/2411.08537v1)|[link](https://github.com/ai-med/mlv2-net)|
|**2024-11-13**|**Neural Topic Modeling with Large Language Models in the Loop**|Xiaohao Yang et.al.|[2411.08534v1](http://arxiv.org/abs/2411.08534v1)|null|
|**2024-11-13**|**Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System**|Deborah Gerhardt et.al.|[2411.08526v1](http://arxiv.org/abs/2411.08526v1)|null|
|**2024-11-13**|**SAD-TIME: a Spatiotemporal-fused network for depression detection with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor**|Han-Guang Wang et.al.|[2411.08521v1](http://arxiv.org/abs/2411.08521v1)|null|
|**2024-11-13**|**Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding**|Deyi Ji et.al.|[2411.08516v1](http://arxiv.org/abs/2411.08516v1)|null|
|**2024-11-13**|**Explainers' Mental Representations of Explainees' Needs in Everyday Explanations**|Michael Erol Schaffer et.al.|[2411.08514v1](http://arxiv.org/abs/2411.08514v1)|null|
|**2024-11-13**|**An Information Theoretic Approach to Operationalize Right to Data Protection**|Abhinav Java et.al.|[2411.08506v1](http://arxiv.org/abs/2411.08506v1)|null|
|**2024-11-13**|**Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks**|Junhua Liu et.al.|[2411.08504v1](http://arxiv.org/abs/2411.08504v1)|null|
|**2024-11-13**|**Learning Model Agnostic Explanations via Constraint Programming**|Frederic Koriche et.al.|[2411.08478v1](http://arxiv.org/abs/2411.08478v1)|null|
|**2024-11-13**|**Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)**|Fadi Al Machot et.al.|[2411.08469v1](http://arxiv.org/abs/2411.08469v1)|null|
|**2024-11-13**|**Crystal Structure Generation Based On Material Properties**|Chao Huang et.al.|[2411.08464v1](http://arxiv.org/abs/2411.08464v1)|null|
|**2024-11-13**|**Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach**|Fadi Al Machot et.al.|[2411.08463v1](http://arxiv.org/abs/2411.08463v1)|null|
|**2024-11-13**|**Trap-MID: Trapdoor-based Defense against Model Inversion Attacks**|Zhen-Ting Liu et.al.|[2411.08460v1](http://arxiv.org/abs/2411.08460v1)|[link](https://github.com/ntuaislab/trap-mid)|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v1](http://arxiv.org/abs/2411.08449v1)|null|
|**2024-11-13**|**Learning Dynamic Cognitive Map with Autonomous Navigation**|Daria de Tinguy et.al.|[2411.08447v1](http://arxiv.org/abs/2411.08447v1)|null|
|**2024-11-13**|**Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data**|Anum Afzal et.al.|[2411.08438v1](http://arxiv.org/abs/2411.08438v1)|null|
|**2024-11-13**|**3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter**|Xiaoxiang Wang et.al.|[2411.08433v1](http://arxiv.org/abs/2411.08433v1)|null|
|**2024-11-13**|**One STEP at a time: Language Agents are Stepwise Planners**|Minh Nguyen et.al.|[2411.08432v1](http://arxiv.org/abs/2411.08432v1)|null|
|**2024-11-13**|**Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models**|Yun Long et.al.|[2411.08418v1](http://arxiv.org/abs/2411.08418v1)|null|
|**2024-11-13**|**Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning**|Chao Huang et.al.|[2411.08414v1](http://arxiv.org/abs/2411.08414v1)|null|
|**2024-11-13**|**DiVR: incorporating context from diverse VR scenes for human trajectory prediction**|Franz Franco Gallo et.al.|[2411.08409v1](http://arxiv.org/abs/2411.08409v1)|null|
|**2024-11-13**|**CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision**|Aoi Ito et.al.|[2411.08397v1](http://arxiv.org/abs/2411.08397v1)|null|
|**2024-11-13**|**RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm**|Geetansh Kalra et.al.|[2411.08392v1](http://arxiv.org/abs/2411.08392v1)|null|
|**2024-11-13**|**Physics Informed Distillation for Diffusion Models**|Joshua Tian Jin Tee et.al.|[2411.08378v1](http://arxiv.org/abs/2411.08378v1)|[link](https://github.com/pantheon5100/pid_diffusion)|
|**2024-11-13**|**Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems**|Rawad Melhem et.al.|[2411.08375v1](http://arxiv.org/abs/2411.08375v1)|null|
|**2024-11-13**|**A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**|Siwei Li et.al.|[2411.08370v1](http://arxiv.org/abs/2411.08370v1)|null|
|**2024-11-13**|**Surprisingly Popular Voting for Concentric Rank-Order Models**|Hadi Hosseini et.al.|[2411.08367v1](http://arxiv.org/abs/2411.08367v1)|null|
|**2024-11-13**|**Refining Translations with LLMs: A Constraint-Aware Iterative Prompting Approach**|Shangfeng Chen et.al.|[2411.08348v1](http://arxiv.org/abs/2411.08348v1)|null|
|**2024-11-13**|**A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users**|Jingyi Zhou et.al.|[2411.08347v1](http://arxiv.org/abs/2411.08347v1)|[link](https://github.com/yeaso/chinese-affective-computing-dataset)|
|**2024-11-13**|**Bangla Grammatical Error Detection Leveraging Transformer-based Token Classification**|Shayekh Bin Islam et.al.|[2411.08344v1](http://arxiv.org/abs/2411.08344v1)|null|
|**2024-11-13**|**Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study**|Jinbo Wen et.al.|[2411.08341v1](http://arxiv.org/abs/2411.08341v1)|null|
|**2024-11-13**|**DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios**|Muttahirul Islam et.al.|[2411.08335v1](http://arxiv.org/abs/2411.08335v1)|null|
|**2024-11-13**|**Enhancing Multimodal Query Representation via Visual Dialogues for End-to-End Knowledge Retrieval**|Yeong-Joon Ju et.al.|[2411.08334v1](http://arxiv.org/abs/2411.08334v1)|[link](https://github.com/yeongjoonju/ret_xknow)|
|**2024-11-13**|**Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle**|Hui Dai et.al.|[2411.08324v1](http://arxiv.org/abs/2411.08324v1)|null|
|**2024-11-13**|**Responsible AI in Construction Safety: Systematic Evaluation of Large Language Models and Prompt Engineering**|Farouq Sammour et.al.|[2411.08320v1](http://arxiv.org/abs/2411.08320v1)|null|
|**2024-11-13**|**PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation**|Yungang Yi et.al.|[2411.08307v1](http://arxiv.org/abs/2411.08307v1)|null|
|**2024-11-13**|**R3HF: Reward Redistribution for Enhancing Reinforcement Learning from Human Feedback**|Jiahui Li et.al.|[2411.08302v1](http://arxiv.org/abs/2411.08302v1)|null|
|**2024-11-13**|**DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multi-Agent Reinforcement Learning Approach**|Xin Tang et.al.|[2411.08299v1](http://arxiv.org/abs/2411.08299v1)|null|
|**2024-11-13**|**TowerDebias: A Novel Debiasing Method based on the Tower Property**|Norman Matloff et.al.|[2411.08297v1](http://arxiv.org/abs/2411.08297v1)|null|
|**2024-11-13**|**RESOLVE: Relational Reasoning with Symbolic and Object-Level Features Using Vector Symbolic Processing**|Mohamed Mejri et.al.|[2411.08290v1](http://arxiv.org/abs/2411.08290v1)|[link](https://github.com/mmejri3/resolve)|
|**2024-11-13**|**Hashing for Protein Structure Similarity Search**|Jin Han et.al.|[2411.08286v1](http://arxiv.org/abs/2411.08286v1)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v1](http://arxiv.org/abs/2411.08278v1)|null|
|**2024-11-13**|**A Large-Scale Study of Relevance Assessments with Large Language Models: An Initial Look**|Shivani Upadhyay et.al.|[2411.08275v1](http://arxiv.org/abs/2411.08275v1)|null|
|**2024-11-13**|**GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees**|Sichao Xiong et.al.|[2411.08257v1](http://arxiv.org/abs/2411.08257v1)|null|
|**2024-11-13**|**VALTEST: Automated Validation of Language Model Generated Test Cases**|Hamed Taherkhani et.al.|[2411.08254v1](http://arxiv.org/abs/2411.08254v1)|[link](https://github.com/hamedtaherkhani/valtest)|
|**2024-11-12**|**Retrieval Augmented Time Series Forecasting**|Kutay Tire et.al.|[2411.08249v1](http://arxiv.org/abs/2411.08249v1)|[link](https://github.com/kutaytire/retrieval-augmented-time-series-forecasting)|
|**2024-11-12**|**Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial Approach**|Jiyao Li et.al.|[2411.08248v1](http://arxiv.org/abs/2411.08248v1)|[link](https://github.com/utsjiyaoli/qa-attack)|
|**2024-11-12**|**Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset**|Khaoula Chehbouni et.al.|[2411.08243v1](http://arxiv.org/abs/2411.08243v1)|null|
|**2024-11-12**|**DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection**|Shawn Li et.al.|[2411.08227v1](http://arxiv.org/abs/2411.08227v1)|[link](https://github.com/lili0415/dpu-ood-detection)|
|**2024-11-12**|**PERFT: Parameter-Efficient Routed Fine-Tuning for Mixture-of-Expert Model**|Yilun Liu et.al.|[2411.08212v1](http://arxiv.org/abs/2411.08212v1)|null|
|**2024-11-12**|**What Representational Similarity Measures Imply about Decodable Information**|Sarah E. Harvey et.al.|[2411.08197v1](http://arxiv.org/abs/2411.08197v1)|null|
|**2024-11-12**|**An Explainable Machine Learning Approach for Age and Gender Estimation in Living Individuals Using Dental Biometrics**|Mohsin Ali et.al.|[2411.08195v1](http://arxiv.org/abs/2411.08195v1)|null|
|**2024-11-12**|**SCORE: Syntactic Code Representations for Static Script Malware Detection**|Ecenaz Erdemir et.al.|[2411.08182v1](http://arxiv.org/abs/2411.08182v1)|null|
|**2024-11-12**|**Challenges in Guardrailing Large Language Models for Science**|Nishan Pantha et.al.|[2411.08181v1](http://arxiv.org/abs/2411.08181v1)|null|
|**2024-11-12**|**Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection**|Aditya V. Jonnalagadda et.al.|[2411.08171v1](http://arxiv.org/abs/2411.08171v1)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization**|Dinesh Srivasthav P et.al.|[2411.08148v1](http://arxiv.org/abs/2411.08148v1)|[link](https://github.com/dineshsrivasthav/adaptive_meta_learning_with_multi_agent_framework)|
|**2024-11-12**|**Large Language Models Can Self-Improve in Long-context Reasoning**|Siheng Li et.al.|[2411.08147v1](http://arxiv.org/abs/2411.08147v1)|[link](https://github.com/sihengli99/sealong)|
|**2024-11-12**|**Scaling Properties of Diffusion Models for Perceptual Tasks**|Rahul Ravishankar et.al.|[2411.08034v2](http://arxiv.org/abs/2411.08034v2)|null|
|**2024-11-12**|**GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation**|Yushi Lan et.al.|[2411.08033v1](http://arxiv.org/abs/2411.08033v1)|null|

#### Abstracts
##### **4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**
2411.08879v1 by Mijeong Kim, Jongwoo Lim, Bohyung Han

Novel view synthesis of dynamic scenes is becoming important in various
applications, including augmented and virtual reality. We propose a novel 4D
Gaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded
monocular videos. To overcome the overfitting problem of existing work for
these real-world videos, we introduce an uncertainty-aware regularization that
identifies uncertain regions with few observations and selectively imposes
additional priors based on diffusion models and depth smoothness on such
regions. This approach improves both the performance of novel view synthesis
and the quality of training image reconstruction. We also identify the
initialization problem of 4DGS in fast-moving dynamic regions, where the
Structure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.
To initialize Gaussian primitives in such regions, we present a dynamic region
densification method using the estimated depth maps and scene flow. Our
experiments show that the proposed method improves the performance of 4DGS
reconstruction from a video captured by a handheld monocular camera and also
exhibits promising results in few-shot static scene reconstruction.

摘要：動態場景的新穎視圖合成在各種應用中變得重要，包括擴增實境和虛擬實境。我們提出一個用於動態場景的新穎 4D 高斯點繪 (4DGS) 演算法，從隨意記錄的單眼影片中取得。為了克服現有工作對這些真實世界影片的過度擬合問題，我們引入了不確定性感知正則化，它會識別觀察次數較少的不明確區域，並根據擴散模型和深度平滑有選擇性地對此類區域施加額外的先驗。這種方法同時改善了新穎視圖合成的效能和訓練影像重建的品質。我們也識別出 4DGS 在快速移動動態區域中的初始化問題，在這些區域中，運動結構 (SfM) 演算法無法提供可靠的 3D 地標。為了在這些區域中初始化高斯基元，我們提出一個動態區域增密方法，使用估計的深度圖和場景流。我們的實驗顯示，所提出的方法改善了從手持單眼相機拍攝的影片中重建 4DGS 的效能，而且在少量靜態場景重建中也展現出有希望的結果。

##### **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**
2411.08870v1 by Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare ten
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting and supervised fine-tuning regimes for medical question-answering
(QA). For instance, across all tasks and model pairs we consider in the 3-shot
setting, medical LLMs only outperform their base models in 22.7% of cases,
reach a (statistical) tie in 36.8% of cases, and are significantly worse than
their base models in the remaining 40.5% of cases. Our conclusions are based on
(i) comparing each medical model head-to-head, directly against the
corresponding base model; (ii) optimizing the prompts for each model separately
in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty
in comparisons. While these basic practices are not consistently adopted in the
literature, our ablations show that they substantially impact conclusions.
Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs
can show performance improvements, but the benefits do not carry over to tasks
based on clinical notes. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

摘要：<paragraph>最近有許多研究專門開發醫療應用基礎模型，透過持續預訓練公開的生物醫學語料庫，改編通用大型語言模型 (LLM) 和視覺語言模型 (VLM)。這些研究通常聲稱此類領域自適應預訓練 (DAPT) 能提升下游醫療任務的效能，例如回答醫療執照考試題目。在本文中，我們比較了十個公開的「醫療」LLM 和兩個 VLM，並將其與對應的基本模型進行比較，得出了不同的結論：所有醫療 VLM 和幾乎所有醫療 LLM 都無法在醫療問題解答 (QA) 的零次/小樣本提示和監督微調機制中持續優於其基本模型。例如，在我們在 3 次取樣設定中考量的所有任務和模型配對中，醫療 LLM 僅在 22.7% 的案例中優於其基本模型，在 36.8% 的案例中達到（統計）平手，而在其餘 40.5% 的案例中則顯著低於其基本模型。我們的結論基於 (i) 將每個醫療模型與對應的基本模型進行一對一比較；(ii) 在零次/小樣本提示中分別針對每個模型最佳化提示；以及 (iii) 在比較中考量統計不確定性。儘管這些基本做法並未在文獻中一致採用，但我們的消融研究顯示，它們對結論有重大影響。同時，我們發現，在針對特定 QA 任務進行微調後，醫療 LLM 可以展現效能提升，但這些好處並未延續到基於臨床筆記的任務。我們的研究結果表明，最先進的通用領域模型可能已經展現出強大的醫療知識和推理能力，並提供建議以強化未來研究的結論。</paragraph>

##### **CamemBERT 2.0: A Smarter French Language Model Aged to Perfection**
2411.08868v1 by Wissam Antoun, Francis Kulumba, Rian Touchent, Éric de la Clergerie, Benoît Sagot, Djamé Seddah

French language models, such as CamemBERT, have been widely adopted across
industries for natural language processing (NLP) tasks, with models like
CamemBERT seeing over 4 million downloads per month. However, these models face
challenges due to temporal concept drift, where outdated training data leads to
a decline in performance, especially when encountering new topics and
terminology. This issue emphasizes the need for updated models that reflect
current linguistic trends. In this paper, we introduce two new versions of the
CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these
challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use
of the Replaced Token Detection (RTD) objective for better contextual
understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked
Language Modeling (MLM) objective. Both models are trained on a significantly
larger and more recent dataset with longer context length and an updated
tokenizer that enhances tokenization performance for French. We evaluate the
performance of these models on both general-domain NLP tasks and
domain-specific applications, such as medical field tasks, demonstrating their
versatility and effectiveness across a range of use cases. Our results show
that these updated models vastly outperform their predecessors, making them
valuable tools for modern NLP systems. All our new models, as well as
intermediate checkpoints, are made openly available on Huggingface.

摘要：法語語言模型，例如 CamemBERT，已在各產業廣泛採用於自然語言處理 (NLP) 任務，而 CamemBERT 等模型每月下載量超過 400 萬次。然而，這些模型會因時間概念漂移而面臨挑戰，過時的訓練資料會導致效能下降，特別是在遇到新主題和術語時。此問題強調了需要更新的模型來反映當前的語言趨勢。在本文中，我們介紹了 CamemBERT 基礎模型的兩個新版本，CamemBERTav2 和 CamemBERTv2，旨在解決這些挑戰。CamemBERTav2 基於 DeBERTaV3 架構，並利用替換代幣偵測 (RTD) 目標，以獲得更好的脈絡理解，而 CamemBERTv2 則建構在 RoBERTa 上，使用遮蔽語言模型 (MLM) 目標。這兩個模型都訓練於一個顯著更大且更新的資料集，具有較長的脈絡長度和一個更新的 tokenizer，可增強法語的 tokenization 效能。我們評估了這些模型在一般領域 NLP 任務和特定領域應用程式（例如醫學領域任務）上的效能，展示了它們在各種使用案例中的多功能性和有效性。我們的結果顯示，這些更新的模型大幅優於它們的前身，使其成為現代 NLP 系統的寶貴工具。我們所有的新模型，以及中間檢查點，都公開在 Huggingface 上。

##### **Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale**
2411.08843v1 by Alberto Carpentieri, Jussi Leinonen, Jeff Adie, Boris Bonev, Doris Folini, Farah Hariri

Accurate surface solar irradiance (SSI) forecasting is essential for
optimizing renewable energy systems, particularly in the context of long-term
energy planning on a global scale. This paper presents a pioneering approach to
solar radiation forecasting that leverages recent advancements in numerical
weather prediction (NWP) and data-driven machine learning weather models. These
advances facilitate long, stable rollouts and enable large ensemble forecasts,
enhancing the reliability of predictions. Our flexible model utilizes variables
forecast by these NWP and AI weather models to estimate 6-hourly SSI at global
scale. Developed using NVIDIA Modulus, our model represents the first adaptive
global framework capable of providing long-term SSI forecasts. Furthermore, it
can be fine-tuned using satellite data, which significantly enhances its
performance in the fine-tuned regions, while maintaining accuracy elsewhere.
The improved accuracy of these forecasts has substantial implications for the
integration of solar energy into power grids, enabling more efficient energy
management and contributing to the global transition to renewable energy
sources.

摘要：精準的太陽表面輻照度 (SSI) 預測對於最佳化再生能源系統至關重要，特別是在全球規模的長期能源規劃中。本文提出了一種創新的太陽輻射預測方法，它利用了數值天氣預報 (NWP) 和資料驅動機器學習天氣模型的最新進展。這些進展促成了長期、穩定的推出，並實現了大型集合預測，進而提高了預測的可靠性。我們的彈性模型利用這些 NWP 和 AI 天氣模型預測的變數來估計全球範圍內的 6 小時 SSI。我們的模型使用 NVIDIA Modulus 開發，代表了第一個能夠提供長期 SSI 預測的適應性全球架構。此外，它可以使用衛星資料進行微調，這顯著增強了它在微調區域的效能，同時在其他地方保持準確性。這些預測精度的提高對太陽能整合到電網中具有重大影響，實現了更有效的能源管理，並有助於全球轉向再生能源。

##### **AstroM$^3$: A self-supervised multimodal model for astronomy**
2411.08842v1 by Mariia Rizhko, Joshua S. Bloom

While machine-learned models are now routinely employed to facilitate
astronomical inquiry, model inputs tend to be limited to a primary data source
(namely images or time series) and, in the more advanced approaches, some
metadata. Yet with the growing use of wide-field, multiplexed observational
resources, individual sources of interest often have a broad range of
observational modes available. Here we construct an astronomical multimodal
dataset and propose AstroM$^3$, a self-supervised pre-training approach that
enables a model to learn from multiple modalities simultaneously. Specifically,
we extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodal
setting, allowing the integration of time-series photometry data, spectra, and
astrophysical metadata. In a fine-tuning supervised setting, our results
demonstrate that CLIP pre-training improves classification performance for
time-series photometry, where accuracy increases from 84.6% to 91.5%.
Furthermore, CLIP boosts classification accuracy by up to 12.6% when the
availability of labeled data is limited, showing the effectiveness of
leveraging larger corpora of unlabeled data. In addition to fine-tuned
classification, we can use the trained model in other downstream tasks that are
not explicitly contemplated during the construction of the self-supervised
model. In particular we show the efficacy of using the learned embeddings for
misclassifications identification, similarity search, and anomaly detection.
One surprising highlight is the "rediscovery" of Mira subtypes and two
Rotational variable subclasses using manifold learning and dimension reduction
algorithm. To our knowledge this is the first construction of an $n>2$ mode
model in astronomy. Extensions to $n>3$ modes is naturally anticipated with
this approach.

摘要：<paragraph>雖然機器學習模型現在例行用於促進天文學探究，但模型輸入往往僅限於主要的資料來源（即影像或時間序列），而在更進階的方法中，則為一些元資料。但隨著廣視場、多工觀測資源的使用增加，個別感興趣的來源通常有廣泛的觀測模式可用。在此，我們建構一個天文學多模態資料集，並提出 AstroM$^3$，一種自我監督預訓練方法，使模型能夠同時從多種模態中學習。具體來說，我們將 CLIP（對比式語言影像預訓練）模型擴充到三模態設定，允許整合時間序列光度測量資料、光譜和天體物理元資料。在微調監督設定中，我們的結果證明 CLIP 預訓練改善了時間序列光度測量的分類效能，其中準確度從 84.6% 提升至 91.5%。此外，當標記資料的可用性受限時，CLIP 可將分類準確度提高多達 12.6%，顯示出利用較大規模的未標記資料的有效性。除了微調分類外，我們可以在其他下游任務中使用訓練好的模型，這些任務並未在自我監督模型的建構過程中明確考慮。特別是，我們展示了使用已學習嵌入進行錯誤分類識別、相似性搜尋和異常偵測的效能。一個令人驚訝的亮點是使用流形學習和降維演算法「重新發現」米拉子類型和兩個旋轉變數子類別。據我們所知，這是天文學中第一個建構 $n>2$ 模式模型。使用這種方法自然會預期擴充至 $n>3$ 模式。</paragraph>

##### **Offline Adaptation of Quadruped Locomotion using Diffusion Models**
2411.08832v1 by Reece O'Mahoney, Alexander L. Mitchell, Wanming Yu, Ingmar Posner, Ioannis Havoutis

We present a diffusion-based approach to quadrupedal locomotion that
simultaneously addresses the limitations of learning and interpolating between
multiple skills and of (modes) offline adapting to new locomotion behaviours
after training. This is the first framework to apply classifier-free guided
diffusion to quadruped locomotion and demonstrate its efficacy by extracting
goal-conditioned behaviour from an originally unlabelled dataset. We show that
these capabilities are compatible with a multi-skill policy and can be applied
with little modification and minimal compute overhead, i.e., running entirely
on the robots onboard CPU. We verify the validity of our approach with hardware
experiments on the ANYmal quadruped platform.

摘要：我們提出了一種基於擴散的四足步態方法，它同時解決了在多種技能之間學習和內插的限制，以及在訓練後離線適應新的運動行為的限制（模式）。這是第一個將無分類器引導擴散應用於四足運動的框架，並通過從最初未標記的數據集中提取目標條件行為來證明其功效。我們展示了這些能力與多技能策略相容，並且可以應用於很少的修改和最小的計算開銷，即完全在機器人板載 CPU 上運行。我們在 ANYmal 四足平台上進行的硬體實驗驗證了我們方法的有效性。

##### **Process-aware Human Activity Recognition**
2411.08814v1 by Jiawei Zheng, Petros Papapanagiotou, Jacques D. Fleuriot, Jane Hillston

Humans naturally follow distinct patterns when conducting their daily
activities, which are driven by established practices and processes, such as
production workflows, social norms and daily routines. Human activity
recognition (HAR) algorithms usually use neural networks or machine learning
techniques to analyse inherent relationships within the data. However, these
approaches often overlook the contextual information in which the data are
generated, potentially limiting their effectiveness. We propose a novel
approach that incorporates process information from context to enhance the HAR
performance. Specifically, we align probabilistic events generated by machine
learning models with process models derived from contextual information. This
alignment adaptively weighs these two sources of information to optimise HAR
accuracy. Our experiments demonstrate that our approach achieves better
accuracy and Macro F1-score compared to baseline models.

摘要：人類在進行日常活動時自然會遵循不同的模式，這些模式是由既定的實務和流程所驅動，例如生產工作流程、社會規範和日常例行公事。人類活動辨識 (HAR) 演算法通常使用神經網路或機器學習技術來分析資料中的內在關係。然而，這些方法經常忽略資料產生的脈絡資訊，這可能會限制其效能。我們提出了一種創新的方法，它將來自脈絡的流程資訊納入其中，以增強 HAR 的效能。具體來說，我們將機器學習模型產生的機率事件與從脈絡資訊衍生的流程模型對齊。這種對齊會根據這兩個資訊來源調整權重，以最佳化 HAR 的準確度。我們的實驗證明，與基線模型相比，我們的做法達到了更好的準確度和巨觀 F1 分數。

##### **Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique**
2411.08813v1 by Suhas Hariharan, Zainab Ali Majid, Jaime Raldua Veuthey, Jacob Haimes

A key development in the cybersecurity evaluations space is the work carried
out by Meta, through their CyberSecEval approach. While this work is
undoubtedly a useful contribution to a nascent field, there are notable
features that limit its utility. Key drawbacks focus on the insecure code
detection part of Meta's methodology. We explore these limitations, and use our
exploration as a test case for LLM-assisted benchmark analysis.

摘要：網路安全評估領域的一項關鍵發展是 Meta 透過其 CyberSecEval 方法所進行的工作。儘管這項工作無疑對新興領域有所貢獻，但仍有一些顯著特點限制了其效用。主要缺點集中在 Meta 方法論的不安全程式碼偵測部分。我們探討這些限制，並將我們的探討用作 LLM 輔助基準分析的測試案例。

##### **Evaluating World Models with LLM for Decision Making**
2411.08794v1 by Chang Yang, Xinrun Wang, Junzhe Jiang, Qinggang Zhang, Xiao Huang

World model emerges as a key module in decision making, where MuZero and
Dreamer achieve remarkable successes in complex tasks. Recent work leverages
Large Language Models (LLMs) as general world simulators to simulate the
dynamics of the world due to their generalizability. LLMs also serve as the
world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree
of Thought (ToT). However, the world models are either evaluated as a general
world simulator, or as a functional module of the agent, i.e., predicting the
transitions to assist the planning. In this work, we propose a comprehensive
evaluation of the world models with LLMs from the decision making perspective.
Specifically, we leverage the 31 diverse environments from (Wang et al.,
2023;2024) and curate the rule-based policy of each environment for the diverse
evaluation. Then, we design three main tasks, i.e., policy verification, action
proposal, and policy planning, where the world models can be used for decision
making solely. Finally, we conduct the comprehensive evaluation of the advanced
LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main
tasks under various settings. The key observations include: i) GPT-4o
significantly outperforms GPT-4o-mini on the three main tasks, especially for
the tasks which require the domain knowledge, ii) the performance of the world
model with LLM will be decreased for long-term decision-making tasks, and iii)
the combination of different functionalities of the world model will brings
additional unstabilities of the performance.

摘要：世界模型成為決策中的一個關鍵模組，其中 MuZero 和 Dreamer 在複雜任務中取得顯著成功。最近的研究利用大型語言模型 (LLM) 作為通用的世界模擬器，模擬世界的動態，因為它們具有普遍性。LLM 也可用作規劃推理 (RAP) 和思考樹 (ToT) 中審議推理的世界模型。然而，世界模型要么被評估為一個通用的世界模擬器，要么作為代理的一個功能模組，即預測過渡以協助規劃。在這項工作中，我們提出了從決策制定角度對使用 LLM 的世界模型進行全面評估。具體來說，我們利用了來自 (Wang et al., 2023;2024) 的 31 個不同的環境，並為不同的評估整理了每個環境的基於規則的策略。然後，我們設計了三個主要任務，即策略驗證、動作建議和策略規劃，世界模型可以僅用於決策制定。最後，我們對先進的 LLM（即 GPT-4o 和 GPT-4o-mini）在不同環境下進行了三個主要任務的綜合評估。關鍵觀察結果包括：i) GPT-4o 在三個主要任務上明顯優於 GPT-4o-mini，特別是對於需要領域知識的任務，ii) 使用 LLM 的世界模型的性能會因長期決策制定任務而降低，以及 iii) 世界模型的不同功能的結合會帶來額外的性能不穩定性。

##### **Can sparse autoencoders be used to decompose and interpret steering vectors?**
2411.08790v1 by Harry Mayne, Yushi Yang, Adam Mahdi

Steering vectors are a promising approach to control the behaviour of large
language models. However, their underlying mechanisms remain poorly understood.
While sparse autoencoders (SAEs) may offer a potential method to interpret
steering vectors, recent findings show that SAE-reconstructed vectors often
lack the steering properties of the original vectors. This paper investigates
why directly applying SAEs to steering vectors yields misleading
decompositions, identifying two reasons: (1) steering vectors fall outside the
input distribution for which SAEs are designed, and (2) steering vectors can
have meaningful negative projections in feature directions, which SAEs are not
designed to accommodate. These limitations hinder the direct use of SAEs for
interpreting steering vectors.

摘要：引導向量是一種控制大型語言模型行為的有前途方法。然而，它們的底層機制仍然知之甚少。儘管稀疏自動編碼器 (SAE) 可能提供一種解釋引導向量的潛在方法，但最近的研究結果表明，SAE 重建的向量通常缺乏原始向量的引導屬性。本文探討了為什麼直接將 SAE 應用於引導向量會產生誤導性的分解，並找出兩個原因：(1) 引導向量超出 SAE 設計的輸入分佈，以及 (2) 引導向量在特徵方向上可能具有有意義的負投影，而 SAE 並未設計為適應這種情況。這些限制阻礙了直接使用 SAE 來解釋引導向量。

##### **Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training**
2411.08785v1 by Nghia Trung Ngo, Thien Huu Nguyen

The majority of previous researches addressing multi-lingual IE are limited
to zero-shot cross-lingual single-transfer (one-to-one) setting, with
high-resource languages predominantly as source training data. As a result,
these works provide little understanding and benefit for the realistic goal of
developing a multi-lingual IE system that can generalize to as many languages
as possible. Our study aims to fill this gap by providing a detailed analysis
on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for
the recent IE corpora that cover a diverse set of languages. Specifically, we
first determine the correlation between single-transfer performance and a wide
range of linguistic-based distances. From the obtained insights, a combined
language distance metric can be developed that is not only highly correlated
but also robust across different tasks and model scales. Next, we investigate
the more general zero-shot multi-lingual transfer settings where multiple
languages are involved in the training and evaluation processes. Language
clustering based on the newly defined distance can provide directions for
achieving the optimal cost-performance trade-off in data (languages) selection
problem. Finally, a relational-transfer setting is proposed to further
incorporate multi-lingual unlabeled data based on adversarial training using
the relation induced from the above linguistic distance.

摘要：過去針對多語言資訊萃取（IE）的研究多半侷限於零次學習跨語言單一轉移（一對一）的設定，且以資源豐富的語言作為來源訓練資料。因此，這些研究對於開發一個能盡可能推廣至多種語言的多語言 IE 系統這個實際目標，幾乎沒有提供理解或幫助。我們的研究旨在透過提供對跨語言多重可轉移性（多對多轉移學習）的詳細分析，來填補這個缺口，以涵蓋各種語言的近期 IE 語料庫。具體來說，我們首先確定單一轉移效能與各種基於語言的距離之間的關聯性。從獲得的見解中，可以開發出一種綜合語言距離指標，不僅高度相關，而且在不同的任務和模型規模中也很穩健。接下來，我們研究更通用的零次學習多語言轉移設定，其中多種語言參與訓練和評估過程。根據新定義的距離進行語言群集，可以提供在資料（語言）選擇問題中達成最佳成本效益權衡的方向。最後，提出了一個關係轉移設定，以進一步根據對抗式訓練中從上述語言距離中推導出的關係，來納入多語言未標記資料。

##### **Sharingan: Extract User Action Sequence from Desktop Recordings**
2411.08768v1 by Yanting Chen, Yi Ren, Xiaoting Qin, Jue Zhang, Kehong Yuan, Lu Han, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

Video recordings of user activities, particularly desktop recordings, offer a
rich source of data for understanding user behaviors and automating processes.
However, despite advancements in Vision-Language Models (VLMs) and their
increasing use in video analysis, extracting user actions from desktop
recordings remains an underexplored area. This paper addresses this gap by
proposing two novel VLM-based methods for user action extraction: the Direct
Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and
the Differential Frame-Based Approach (DiffF), which incorporates explicit
frame differences detected via computer vision techniques. We evaluate these
methods using a basic self-curated dataset and an advanced benchmark adapted
from prior work. Our results show that the DF approach achieves an accuracy of
70% to 80% in identifying user actions, with the extracted action sequences
being re-playable though Robotic Process Automation. We find that while VLMs
show potential, incorporating explicit UI changes can degrade performance,
making the DF approach more reliable. This work represents the first
application of VLMs for extracting user action sequences from desktop
recordings, contributing new methods, benchmarks, and insights for future
research.

摘要：使用者活動的影片錄製，特別是桌面錄製，提供了豐富的資料來源，可用於了解使用者行為並自動化流程。然而，儘管視覺語言模型 (VLM) 有所進步，且在影片分析中使用越來越廣泛，從桌面錄製中擷取使用者動作仍然是一個尚未充分探討的領域。本文透過提出兩種基於 VLM 的使用者動作擷取新穎方法來解決這個問題：直接基於畫面的方法 (DF)，它將取樣的畫面直接輸入 VLM，以及差異化基於畫面的方法 (DiffF)，它結合了透過電腦視覺技術偵測到的明確畫面差異。我們使用一個基本的自訂資料集和一個從先前工作中改編的高階基準來評估這些方法。我們的結果顯示，DF 方法在識別使用者動作時達到了 70% 到 80% 的準確度，而擷取的動作序列可透過機器人流程自動化重新播放。我們發現，儘管 VLM 具有潛力，但結合明確的 UI 變更可能會降低效能，使 DF 方法更可靠。這項工作代表了首次應用 VLM 從桌面錄製中擷取使用者動作序列，為未來的研究提供了新的方法、基準和見解。

##### **SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate**
2411.08767v1 by Yifei Jin, Ali Maatouk, Sarunas Girdzijauskas, Shugong Xu, Leandros Tassiulas, Rex Ying

Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional
(3D) wireless channel modeling, driven by advances in graphical rendering.
Current approaches struggle to accurately model beyond 5G (B5G) network
signaling, which often operates at higher frequencies and is more susceptible
to environmental conditions and changes. Existing online learning solutions
require real-time environmental supervision during training, which is both
costly and incompatible with GPU-based processing. In response, we propose a
novel approach that redefines ray trajectory generation as a sequential
decision-making problem, leveraging generative models to jointly learn the
optical, physical, and signal properties within each designated environment.
Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing
Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that
can be trained entirely on GPUs. SANDWICH offers superior performance compared
to existing online learning methods, outperforms the baseline by 4e^-2 radian
in RT accuracy, and only fades 0.5 dB away from toplined channel gain
estimation.

摘要：無線射線追蹤 (RT) 在圖形渲染的進步帶動下，正成為三維 (3D) 無線通道建模的一項關鍵工具。
目前的方法難以準確建模 5G (B5G) 網路訊號之外的訊號，而這些訊號通常以更高的頻率運作，且更容易受到環境條件和變化的影響。現有的線上學習解決方案需要在訓練期間進行即時的環境監控，這既昂貴又不相容於基於 GPU 的處理。為了解決這個問題，我們提出了一種新穎的方法，將射線軌跡生成重新定義為一個順序決策問題，利用生成模型來共同學習每個指定環境中的光學、物理和訊號特性。我們的研究引入了場景感知神經決策無線通道射線追蹤階層 (SANDWICH)，這是一種創新的離線、完全可微分的做法，可以在 GPU 上完全訓練。與現有的線上學習方法相比，SANDWICH 提供了卓越的效能，在 RT 精確度上優於基準 4e^-2 弧度，且僅在頂線通道增益估計中衰減 0.5 dB。

##### **Flow reconstruction in time-varying geometries using graph neural networks**
2411.08764v1 by Bogdan A. Danciu, Vito A. Pagone, Benjamin Böhm, Marius Schmidt, Christos E. Frouzakis

The paper presents a Graph Attention Convolutional Network (GACN) for flow
reconstruction from very sparse data in time-varying geometries. The model
incorporates a feature propagation algorithm as a preprocessing step to handle
extremely sparse inputs, leveraging information from neighboring nodes to
initialize missing features. In addition, a binary indicator is introduced as a
validity mask to distinguish between the original and propagated data points,
enabling more effective learning from sparse inputs. Trained on a unique data
set of Direct Numerical Simulations (DNS) of a motored engine at a technically
relevant operating condition, the GACN shows robust performance across
different resolutions and domain sizes and can effectively handle unstructured
data and variable input sizes. The model is tested on previously unseen DNS
data as well as on an experimental data set from Particle Image Velocimetry
(PIV) measurements that were not considered during training. A comparative
analysis shows that the GACN consistently outperforms both a conventional
Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS
and PIV test sets by achieving lower reconstruction errors and better capturing
fine-scale turbulent structures. In particular, the GACN effectively
reconstructs flow fields from domains up to 14 times larger than those observed
during training, with the performance advantage increasing for larger domains.

摘要：本文提出了一种图注意力卷积网络 (GACN)，用于从时变几何中的极稀疏数据重建流动。该模型将特征传播算法作为预处理步骤，以处理极稀疏输入，利用来自相邻节点的信息来初始化缺失特征。此外，引入了一个二进制指示符作为有效掩码，以区分原始数据点和传播数据点，从而能够更有效地从稀疏输入中学习。在技术相关操作条件下对电机引擎的直接数值模拟 (DNS) 的唯一数据集上进行训练后，GACN 在不同的分辨率和域大小上显示出稳健的性能，并且可以有效地处理非结构化数据和可变输入大小。该模型在以前未见过的 DNS 数据以及在训练期间未考虑的粒子图像测速 (PIV) 测量实验数据集上进行了测试。比较分析表明，GACN 在 DNS 和 PIV 测试集上始终优于传统的卷积神经网络 (CNN) 和三次插值方法，通过实现较低的重建误差和更好地捕获小尺度湍流结构。特别是，GACN 有效地从比训练期间观测到的域大 14 倍的域重建流场，并且随着域的增大，性能优势也随之增加。

##### **Multi-Perspective Stance Detection**
2411.08752v1 by Benedetta Muscato, Praveen Bushipaka, Gizem Gezici, Lucia Passaro, Fosca Giannotti

Subjective NLP tasks usually rely on human annotations provided by multiple
annotators, whose judgments may vary due to their diverse backgrounds and life
experiences. Traditional methods often aggregate multiple annotations into a
single ground truth, disregarding the diversity in perspectives that arises
from annotator disagreement. In this preliminary study, we examine the effect
of including multiple annotations on model accuracy in classification. Our
methodology investigates the performance of perspective-aware classification
models in stance detection task and further inspects if annotator disagreement
affects the model confidence. The results show that multi-perspective approach
yields better classification performance outperforming the baseline which uses
the single label. This entails that designing more inclusive perspective-aware
AI models is not only an essential first step in implementing responsible and
ethical AI, but it can also achieve superior results than using the traditional
approaches.

摘要：主觀 NLP 任務通常依賴於多位註解者提供的標註，其判斷可能會因其不同的背景和生活經驗而有所不同。傳統方法通常將多個標註彙總成一個基本事實，而忽略了註解者意見分歧所產生的觀點差異。在這項初步研究中，我們探討了在分類中包含多個標註對模型準確性的影響。我們的研究方法探討了觀點感知分類模型在立場檢測任務中的表現，並進一步檢查了註解者意見分歧是否會影響模型的信心。結果表明，多觀點方法產生的分類表現優於使用單一標籤的基準。這意味著，設計更具包容性的觀點感知 AI 模型不僅是實現負責任和合乎道德的 AI 的第一步，而且還可以取得比使用傳統方法更好的結果。

##### **Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers**
2411.08745v1 by Clément Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West

A central question in multilingual language modeling is whether large
language models (LLMs) develop a universal concept representation, disentangled
from specific languages. In this paper, we address this question by analyzing
latent representations (latents) during a word translation task in
transformer-based LLMs. We strategically extract latents from a source
translation prompt and insert them into the forward pass on a target
translation prompt. By doing so, we find that the output language is encoded in
the latent at an earlier layer than the concept to be translated. Building on
this insight, we conduct two key experiments. First, we demonstrate that we can
change the concept without changing the language and vice versa through
activation patching alone. Second, we show that patching with the mean over
latents across different languages does not impair and instead improves the
models' performance in translating the concept. Our results provide evidence
for the existence of language-agnostic concept representations within the
investigated models.

摘要：多語言語言模型中的核心問題是大型語言模型 (LLM) 是否發展出一個通用的概念表徵，與特定語言脫鉤。在本文中，我們透過分析Transformer式 LLM 中字詞翻譯任務中的潛在表徵 (latents) 來探討這個問題。我們策略性地從原始翻譯提示中擷取潛在表徵，並將它們插入目標翻譯提示的正向傳遞中。透過這麼做，我們發現輸出語言在潛在表徵中編碼的層級比要翻譯的概念還早。基於這個見解，我們進行了兩個關鍵實驗。首先，我們證明我們可以單獨透過啟動程序修補來改變概念，而不用改變語言，反之亦然。其次，我們表明，使用不同語言的潛在表徵的平均值進行修補不會損害，反而會提升模型翻譯概念的效能。我們的結果提供了證據，證明在調查的模型中存在與語言無關的概念表徵。

##### **A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models**
2411.08742v1 by Dingdong Wang, Mingyu Cui, Dongchao Yang, Xueyuan Chen, Helen Meng

With the rise of Speech Large Language Models (Speech LLMs), there has been
growing interest in discrete speech tokens for their ability to integrate with
text-based tokens seamlessly. Compared to most studies that focus on continuous
speech features, although discrete-token based LLMs have shown promising
results on certain tasks, the performance gap between these two paradigms is
rarely explored. In this paper, we present a fair and thorough comparison
between discrete and continuous features across a variety of semantic-related
tasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that
continuous features generally outperform discrete tokens, particularly in tasks
requiring fine-grained semantic understanding. Moreover, this study goes beyond
surface-level comparison by identifying key factors behind the
under-performance of discrete tokens, such as limited token granularity and
inefficient information retention. To enhance the performance of discrete
tokens, we explore potential aspects based on our analysis. We hope our results
can offer new insights into the opportunities for advancing discrete speech
tokens in Speech LLMs.

摘要：隨著大型語言模型（LLM）的興起，人們越來越關注離散式語音符號，因為它們能夠與基於文字的符號無縫整合。儘管基於離散符號的 LLM 在某些任務上已展現出令人滿意的成果，但與大多數專注於連續語音特徵的研究相比，這兩種範例之間的效能差距卻鮮少被探討。在本文中，我們將使用輕量級 LLM（Qwen1.5-0.5B）在各種語義相關任務中，對離散特徵和連續特徵進行公平且徹底的比較。我們的研究結果顯示，連續特徵通常優於離散符號，特別是在需要細緻語義理解的任務中。此外，本研究不僅止於表面比較，還找出離散符號效能不佳背後的主要因素，例如符號粒度受限和資訊保留效率不佳。為了提升離散符號的效能，我們根據分析結果探討了潛在面向。我們希望我們的研究結果能為提升語音 LLM 中離散語音符號的機會提供新的見解。

##### **Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models**
2411.08733v1 by Somanshu Singla, Zhen Wang, Tianyang Liu, Abdullah Ashfaq, Zhiting Hu, Eric P. Xing

Aligning Large Language Models (LLMs) traditionally relies on costly training
and human preference annotations. Self-alignment seeks to reduce these expenses
by enabling models to align themselves. To further lower costs and achieve
alignment without any expensive tuning or annotations, we introduce a new
tuning-free approach for self-alignment, Dynamic Rewarding with Prompt
Optimization (\ours). Our approach leverages a search-based optimization
framework that allows LLMs to iteratively self-improve and craft the optimal
alignment instructions, all without additional training or human intervention.
The core of \ours is a dynamic rewarding mechanism, which identifies and
rectifies model-specific alignment weaknesses, allowing LLMs to adapt
efficiently to diverse alignment challenges. Empirical evaluations on eight
recent LLMs, both open- and closed-sourced, demonstrate that \ours
significantly enhances alignment performance, with base models outperforming
their SFT/RLHF-tuned counterparts. Moreover, the prompts automatically
optimized by \ours surpass those curated by human experts, further validating
the effectiveness of our approach. Our findings highlight the great potential
of current LLMs to achieve adaptive self-alignment through inference-time
optimization, complementing tuning-based alignment methods.

摘要：大型語言模型（LLM）的對齊傳統上依賴於昂貴的訓練和人工偏好註解。自我對齊試圖通過使模型能夠自我對齊來降低這些費用。為了進一步降低成本並在沒有任何昂貴的調整或註解的情況下實現對齊，我們引入了一種新的無調整自我對齊方法，即帶提示優化的動態獎勵（\ours）。我們的做法利用了一個基於搜索的優化框架，允許 LLM 迭代式地自我改進並制定最佳對齊指令，所有這些都不需要額外的訓練或人工干預。\ours 的核心是一個動態獎勵機制，它識別和糾正特定於模型的對齊弱點，允許 LLM 有效地適應不同的對齊挑戰。對八種最近的 LLM（包括開源和閉源）進行的經驗評估表明，\ours顯著提高了對齊性能，基本模型優於經過 SFT/RLHF 調整的模型。此外，由 \ours 自動優化的提示優於由人類專家策劃的提示，進一步驗證了我們方法的有效性。我們的發現強調了當前 LLM 通過推理時間優化實現自適應自我對齊的巨大潛力，補充了基於調整的對齊方法。

##### **Polymetis:Large Language Modeling for Multiple Material Domains**
2411.08728v1 by Chao Huang, Huichen Xiao, Chen Chen, Chunyan Chen, Yi Zhao, Shiyu Du, Yiming Zhang, He Sha, Ruixin Gu

As the application of large language models in various fields continues to
expand, materials science also ushers in opportunities for AI-driven
innovation. The traditional way of relying on manual search for materials
science-related information is now using artificial intelligence technology as
an auxiliary tool to improve the efficiency of materials science research. To
accelerate researchers' knowledge acquisition and intelligent decision-making
support in materials science research, this paper proposes a large language
model Polymetis model for a variety of materials fields, aiming to provide
highly professional knowledge answers in the field of materials, covering
energy materials, functional materials, alloy materials, physical chemistry,
biology, and other material directions. The model uses a dataset of about 2
million material knowledge instructions, and in the process of building the
dataset, we developed the Intelligent Extraction Large Model (IELM), which is
specially used to extract and form structured knowledge from scientific texts,
avoiding a large number of costs that need to be manually annotated, and
improving efficiency. We inject this data into the GLM4-9B model for learning
to enhance its inference capabilities in a variety of material domains. In
addition, we have introduced enhanced prompt strategies to ensure that the
answers to the model are more organized and comprehensive, providing efficient
and comprehensive intelligent support for the diverse needs of materials
science exploration, and promoting the development of material science.

摘要：隨著大型語言模型在各領域的應用持續擴展，材料科學也迎來 AI 驅動創新的契機。傳統仰賴人工搜尋材料科學相關資訊的方式，如今正以人工智慧技術作為輔助工具，提升材料科學研究的效率。為了加速研究人員在材料科學研究中的知識獲取，以及提供智慧決策支援，本文提出一個適用於各種材料領域的大型語言模型 Polymetis 模型，旨在提供材料領域高度專業的知識解答，涵蓋能源材料、功能材料、合金材料、物理化學、生物等材料方向。該模型使用約 2 千萬筆材料知識說明的資料集，且在建構資料集的過程中，我們開發了智慧萃取大型模型（IELM），專門用於從科學文獻中萃取並形成結構化的知識，避免大量需要人工標註的成本，提升效率。我們將此資料注入 GLM4-9B 模型中進行學習，以提升其在各種材料領域的推理能力。此外，我們引入了增強式提示策略，確保模型的回答更具組織性與全面性，為材料科學探索的多元需求提供高效且全面的智慧支援，並促進材料科學的發展。

##### **Analyst Reports and Stock Performance: Evidence from the Chinese Market**
2411.08726v1 by Rui Liu, Jiayou Liang, Haolong Chen, Yujia Hu

This article applies natural language processing (NLP) to extract and
quantify textual information to predict stock performance. Using an extensive
dataset of Chinese analyst reports and employing a customized BERT deep
learning model for Chinese text, this study categorizes the sentiment of the
reports as positive, neutral, or negative. The findings underscore the
predictive capacity of this sentiment indicator for stock volatility, excess
returns, and trading volume. Specifically, analyst reports with strong positive
sentiment will increase excess return and intraday volatility, and vice versa,
reports with strong negative sentiment also increase volatility and trading
volume, but decrease future excess return. The magnitude of this effect is
greater for positive sentiment reports than for negative sentiment reports.
This article contributes to the empirical literature on sentiment analysis and
the response of the stock market to news in the Chinese stock market.

摘要：本文應用自然語言處理 (NLP) 來擷取和量化文本資訊，以預測股票表現。本研究使用廣泛的中文分析師報告資料集，並採用客製化的中文文本 BERT 深度學習模型，將報告的情緒分類為正面、中立或負面。研究結果強調此情緒指標對於股票波動、超額報酬和交易量的預測能力。具體來說，具有強烈正面情緒的分析師報告將增加超額報酬和盤中波動，反之，具有強烈負面情緒的報告也會增加波動和交易量，但會減少未來的超額報酬。這種效應的幅度對於正面情緒報告來說大於負面情緒報告。本文有助於關於情緒分析的實證文獻，以及中國股市中股市對新聞的反應。

##### **Are Triggers Needed for Document-Level Event Extraction?**
2411.08708v1 by Shaden Shaar, Wayne Chen, Maitreyi Chatterjee, Barry Wang, Wenting Zhao, Claire Cardie

Most existing work on event extraction has focused on sentence-level texts
and presumes the identification of a trigger-span -- a word or phrase in the
input that evokes the occurrence of an event of interest. Event arguments are
then extracted with respect to the trigger. Indeed, triggers are treated as
integral to, and trigger detection as an essential component of, event
extraction. In this paper, we provide the first investigation of the role of
triggers for the more difficult and much less studied task of document-level
event extraction. We analyze their usefulness in multiple end-to-end and
pipelined neural event extraction models for three document-level event
extraction datasets, measuring performance using triggers of varying quality
(human-annotated, LLM-generated, keyword-based, and random). Our research shows
that trigger effectiveness varies based on the extraction task's
characteristics and data quality, with basic, automatically-generated triggers
serving as a viable alternative to human-annotated ones. Furthermore, providing
detailed event descriptions to the extraction model helps maintain robust
performance even when trigger quality degrades. Perhaps surprisingly, we also
find that the mere existence of trigger input, even random ones, is important
for prompt-based LLM approaches to the task.

摘要：現有關於事件抽取的大多數研究都集中在句子層級的文本，並假設識別觸發範圍——輸入中的一個字詞或詞組，它會引發感興趣事件的發生。然後根據觸發器抽取事件參數。事實上，觸發器被視為事件抽取的組成部分，觸發器檢測被視為事件抽取的必要組成部分。在本文中，我們首次探討觸發器在更困難且鮮少研究的文件層級事件抽取任務中的作用。我們分析了它們在三個文件層級事件抽取資料集的多個端對端和管道式神經事件抽取模型中的效用，使用不同品質的觸發器（人工標註、LLM 生成、基於關鍵字和隨機）來衡量效能。我們的研究表明，觸發器效能會根據抽取任務的特徵和資料品質而有所不同，基本、自動生成的觸發器可用於替代人工標註的觸發器。此外，向抽取模型提供詳細的事件描述有助於在觸發器品質下降時維持穩健的效能。令人驚訝的是，我們還發現，觸發器輸入的存在，即使是隨機的，對於基於提示的 LLM 處理任務的方法也很重要。

##### **Searching Latent Program Spaces**
2411.08706v1 by Clément Bonnet, Matthew V Macfarlane

Program synthesis methods aim to automatically generate programs restricted
to a language that can explain a given specification of input-output pairs.
While purely symbolic approaches suffer from a combinatorial search space,
recent methods leverage neural networks to learn distributions over program
structures to narrow this search space significantly, enabling more efficient
search. However, for challenging problems, it remains difficult to train models
to perform program synthesis in one shot, making test-time search essential.
Most neural methods lack structured search mechanisms during inference, relying
instead on stochastic sampling or gradient updates, which can be inefficient.
In this work, we propose the Latent Program Network (LPN), a general algorithm
for program induction that learns a distribution over latent programs in a
continuous space, enabling efficient search and test-time adaptation. We
explore how to train these networks to optimize for test-time computation and
demonstrate the use of gradient-based search both during training and at test
time. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates
performance by generalizing programs to new inputs rather than explaining the
underlying specification. We show that LPN can generalize beyond its training
distribution and adapt to unseen tasks by utilizing test-time computation,
outperforming algorithms without test-time adaptation mechanisms.

摘要：程式合成方法旨在自動產生受限於語言的程式，該語言可以解釋輸入輸出對的特定說明。
雖然純符號方法會受到組合搜尋空間的影響，
最近的方法利用神經網路學習程式結構的分配，以顯著縮小這個搜尋空間，讓搜尋更有效率。
然而，對於具有挑戰性的問題，訓練模型以一次執行程式合成仍然很困難，這使得測試時間搜尋至關重要。
大多數的神經方法在推論期間缺乏結構化的搜尋機制，而是依賴於隨機抽樣或梯度更新，這可能會很低效。
在這項工作中，我們提出潛在程式網路 (LPN)，一種用於程式歸納的通用演算法，它學習連續空間中潛在程式上的分配，從而實現高效搜尋和測試時間適應。我們探討如何訓練這些網路以最佳化測試時間計算，並展示在訓練期間和測試時間使用基於梯度的搜尋。我們在 ARC-AGI 上評估 LPN，這是一個程式合成基準，它透過將程式概括到新的輸入，而不是解釋基礎說明，來評估效能。我們表明 LPN 可以概括到其訓練分配之外，並透過利用測試時間計算來適應未見任務，優於沒有測試時間適應機制的演算法。

##### **Rethinking negative sampling in content-based news recommendation**
2411.08700v1 by Miguel Ângelo Rebelo, João Vinagre, Ivo Pereira, Álvaro Figueira

News recommender systems are hindered by the brief lifespan of articles, as
they undergo rapid relevance decay. Recent studies have demonstrated the
potential of content-based neural techniques in tackling this problem. However,
these models often involve complex neural architectures and often lack
consideration for negative examples. In this study, we posit that the careful
sampling of negative examples has a big impact on the model's outcome. We
devise a negative sampling technique that not only improves the accuracy of the
model but also facilitates the decentralization of the recommendation system.
The experimental results obtained using the MIND dataset demonstrate that the
accuracy of the method under consideration can compete with that of
State-of-the-Art models. The utilization of the sampling technique is essential
in reducing model complexity and accelerating the training process, while
maintaining a high level of accuracy. Finally, we discuss how decentralized
models can help improve privacy and scalability.

摘要：新聞推薦系統受到文章生命週期短暫的阻礙，因為它們會快速衰退。最近的研究已證明基於內容的神經技術在解決這個問題上的潛力。然而，這些模型通常涉及複雜的神經架構，而且常常缺乏對負面範例的考量。在這項研究中，我們假設負面範例的仔細抽樣對模型的結果有很大的影響。我們設計了一種負面抽樣技術，它不僅提高了模型的準確性，還促进了推薦系統的分散化。使用 MIND 資料集獲得的實驗結果證明，所考慮方法的準確性可以與最先進的模型相媲美。抽樣技術的使用對於降低模型複雜性和加速訓練過程至關重要，同時保持高準確度。最後，我們討論了分散式模型如何有助於改善隱私和可擴展性。

##### **Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs**
2411.08696v1 by Nandana Mihindukulasooriya, Sanju Tiwari, Daniil Dobriy, Finn Årup Nielsen, Tek Raj Chhetri, Axel Polleres

Several initiatives have been undertaken to conceptually model the domain of
scholarly data using ontologies and to create respective Knowledge Graphs. Yet,
the full potential seems unleashed, as automated means for automatic population
of said ontologies are lacking, and respective initiatives from the Semantic
Web community are not necessarily connected: we propose to make scholarly data
more sustainably accessible by leveraging Wikidata's infrastructure and
automating its population in a sustainable manner through LLMs by tapping into
unstructured sources like conference Web sites and proceedings texts as well as
already existing structured conference datasets. While an initial analysis
shows that Semantic Web conferences are only minimally represented in Wikidata,
we argue that our methodology can help to populate, evolve and maintain
scholarly data as a community within Wikidata. Our main contributions include
(a) an analysis of ontologies for representing scholarly data to identify gaps
and relevant entities/properties in Wikidata, (b) semi-automated extraction --
requiring (minimal) manual validation -- of conference metadata (e.g.,
acceptance rates, organizer roles, programme committee members, best paper
awards, keynotes, and sponsors) from websites and proceedings texts using LLMs.
Finally, we discuss (c) extensions to visualization tools in the Wikidata
context for data exploration of the generated scholarly data. Our study focuses
on data from 105 Semantic Web-related conferences and extends/adds more than
6000 entities in Wikidata. It is important to note that the method can be more
generally applicable beyond Semantic Web-related conferences for enhancing
Wikidata's utility as a comprehensive scholarly resource.
  Source Repository: https://github.com/scholarly-wikidata/
  DOI: https://doi.org/10.5281/zenodo.10989709
  License: Creative Commons CC0 (Data), MIT (Code)

摘要：<paragraph>已經有許多計畫使用本体模型化學術資料的領域，並建立相關的知識圖譜。然而，由於缺乏自動化手段來自動填充這些本体，因此其全部潛力尚未發揮，而語意網社群的相關計畫也未必有所關聯：我們建議利用 Wikidata 的基礎架構，並透過利用大型語言模型 (LLM) 從會議網站、會議論文和現有的結構化會議資料集等非結構化來源自動化填充資料，讓學術資料更容易持續取得。雖然初步分析顯示語意網會議在 Wikidata 中的代表性很低，但我們認為我們的做法有助於在 Wikidata 內部建立、發展和維護學術資料社群。我們的貢獻主要包括：(a) 分析用於表示學術資料的本体，以找出 Wikidata 中的差距和相關實體/屬性；(b) 半自動化萃取——需要(最少)手動驗證——使用大型語言模型從網站和會議論文中萃取會議元資料(例如，接受率、組織者角色、計畫委員會成員、最佳論文獎、主題演講和贊助商)。最後，我們討論(c) Wikidata 語境中視覺化工具的擴充，以探索所產生的學術資料。我們的研究著重於來自 105 場語意網相關會議的資料，並在 Wikidata 中擴充/新增超過 6000 個實體。值得注意的是，此方法不只適用於語意網相關會議，還可更廣泛地應用於提升 Wikidata 作為全面學術資源的效用。
原始程式碼存放庫：https://github.com/scholarly-wikidata/
DOI：https://doi.org/10.5281/zenodo.10989709
授權：創用 CC0（資料）、MIT（程式碼）</paragraph>

##### **Theoretical Analysis of Byte-Pair Encoding**
2411.08671v1 by László Kozma, Johannes Voderholzer

Byte-Pair Encoding (BPE) is a widely used method for subword tokenization,
with origins in grammar-based text compression. It is employed in a variety of
language processing tasks such as machine translation or large language model
(LLM) pretraining, to create a token dictionary of a prescribed size. Most
evaluations of BPE to date are empirical, and the reasons for its good
practical performance are not well understood.
  In this paper we focus on the optimization problem underlying BPE: finding a
pair encoding that achieves optimal compression utility. We show that this
problem is APX-complete, indicating that it is unlikely to admit a
polynomial-time approximation scheme. This answers, in a stronger form, a
question recently raised by Zouhar et al.
  On the positive side, we show that BPE approximates the compression utility
of the optimal pair encoding to a worst-case factor between $0.333$ and
$0.625$. Our results aim to explain the ongoing success of BPE and are, to our
knowledge, the first rigorous guarantees on its compression utility that hold
for all inputs.

摘要：位元組對編碼 (BPE) 是一種廣泛用於子字詞符號化的方式，
起源於基於語法的文字壓縮。它被用於各種
語言處理任務，例如機器翻譯或大型語言模型
(LLM) 預訓練，以建立一個特定大小的符號字典。大多數
迄今為止對 BPE 的評估都是經驗性的，而其良好的
實際效能原因尚未得到很好的理解。
  在本文中，我們專注於 BPE 背後的最佳化問題：尋找
一個能達到最佳壓縮效用的對編碼。我們證明這個
問題是 APX 完全的，這表示它不太可能承認
一個多項式時間近似方案。這以更強的形式回答了，Zouhar 等人最近提出的
一個問題。
  在積極的一面，我們證明 BPE 近似最佳對編碼的壓縮效用，在 $0.333$ 和
$0.625$ 之間的最壞情況因子。我們的結果旨在解釋 BPE 持續的成功，而且，據我們所知，是對其對所有輸入都有效的壓縮效用的第一個嚴格保證。

##### **A Survey on Vision Autoregressive Model**
2411.08666v1 by Kai Jiang, Jiaxing Huang

Autoregressive models have demonstrated great performance in natural language
processing (NLP) with impressive scalability, adaptability and
generalizability. Inspired by their notable success in NLP field,
autoregressive models have been intensively investigated recently for computer
vision, which perform next-token predictions by representing visual data as
visual tokens and enables autoregressive modelling for a wide range of vision
tasks, ranging from visual generation and visual understanding to the very
recent multimodal generation that unifies visual generation and understanding
with a single autoregressive model. This paper provides a systematic review of
vision autoregressive models, including the development of a taxonomy of
existing methods and highlighting their major contributions, strengths, and
limitations, covering various vision tasks such as image generation, video
generation, image editing, motion generation, medical image analysis, 3D
generation, robotic manipulation, unified multimodal generation, etc. Besides,
we investigate and analyze the latest advancements in autoregressive models,
including thorough benchmarking and discussion of existing methods across
various evaluation datasets. Finally, we outline key challenges and promising
directions for future research, offering a roadmap to guide further
advancements in vision autoregressive models.

摘要：自回歸模型在自然語言處理 (NLP) 中展現出極佳的效能，具有令人印象深刻的可擴充性、適應性和概括性。受到其在 NLP 領域的顯著成功啟發，自回歸模型最近已廣泛用於電腦視覺，透過將視覺資料表示為視覺符號，執行下一個符號預測，並針對廣泛的視覺任務啟用自回歸建模，從視覺產生和視覺理解，到最近結合視覺產生和理解的單一自回歸模型的多模態產生。本文系統性地探討視覺自回歸模型，包括制定現有方法的分類，並重點說明其主要貢獻、優點和限制，涵蓋各種視覺任務，例如影像產生、影片產生、影像編輯、動作產生、醫學影像分析、3D 產生、機器人操作、統一多模態產生等。此外，我們探討並分析自回歸模型的最新進展，包括徹底的基準測試和跨各種評估資料集的現有方法討論。最後，我們概述視覺自回歸模型未來研究的主要挑戰和有前景的方向，提供一個路線圖，以引導自回歸模型進一步的進展。

##### **Estimating unknown parameters in differential equations with a reinforcement learning based PSO method**
2411.08651v1 by Wenkui Sun, Xiaoya Fan, Lijuan Jia, Tinyi Chu, Shing-Tung Yau, Rongling Wu, Zhong Wang

Differential equations offer a foundational yet powerful framework for
modeling interactions within complex dynamic systems and are widely applied
across numerous scientific fields. One common challenge in this area is
estimating the unknown parameters of these dynamic relationships. However,
traditional numerical optimization methods rely on the selection of initial
parameter values, making them prone to local optima. Meanwhile, deep learning
and Bayesian methods require training models on specific differential
equations, resulting in poor versatility. This paper reformulates the parameter
estimation problem of differential equations as an optimization problem by
introducing the concept of particles from the particle swarm optimization
algorithm. Building on reinforcement learning-based particle swarm optimization
(RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown
parameters of differential equations. We compared its performance on three
typical ordinary differential equations with the state-of-the-art methods,
including the RLLPSO algorithm, traditional numerical methods, deep learning
approaches, and Bayesian methods. The experimental results demonstrate that our
DERLPSO consistently outperforms other methods in terms of performance,
achieving an average Mean Square Error of 1.13e-05, which reduces the error by
approximately 4 orders of magnitude compared to other methods. Apart from
ordinary differential equations, our DERLPSO also show great promise for
estimating unknown parameters of partial differential equations. The DERLPSO
method proposed in this paper has high accuracy, is independent of initial
parameter values, and possesses strong versatility and stability. This work
provides new insights into unknown parameter estimation for differential
equations.

摘要：微分方程提供了一个基础但强大的框架，用于对复杂动态系统内的交互进行建模，并广泛应用于众多科学领域。这一领域中的一个常见挑战是估计这些动态关系的未知参数。然而，传统的数值优化方法依赖于初始参数值的选取，这使得它们容易陷入局部最优。与此同时，深度学习和贝叶斯方法需要针对特定的微分方程训练模型，导致通用性较差。本文通过引入粒子群优化算法中的粒子概念，将微分方程的参数估计问题重新表述为一个优化问题。本文基于强化学习驱动的粒子群优化 (RLLPSO)，提出了一种新方法 DERLPSO，用于估计微分方程的未知参数。我们将其在三个典型常微分方程上的性能与最先进的方法进行了比较，包括 RLLPSO 算法、传统数值方法、深度学习方法和贝叶斯方法。实验结果表明，我们的 DERLPSO 在性能方面始终优于其他方法，实现了 1.13e-05 的平均均方误差，与其他方法相比，将误差降低了大约 4 个数量级。除了常微分方程外，我们的 DERLPSO 在估计偏微分方程的未知参数方面也显示出了巨大的前景。本文提出的 DERLPSO 方法具有较高的精度，与初始参数值无关，并且具有很强的通用性和稳定性。这项工作为微分方程的未知参数估计提供了新的见解。

##### **A System Level Performance Evaluation for Superconducting Digital Systems**
2411.08645v1 by Joyjit Kundu, Debjyoti Bhattacharjee, Nathan Josephsen, Ankit Pokhrel, Udara De Silva, Wenzhe Guo, Steven Van Winckel, Steven Brebels, Manu Perumkunnil, Quentin Herr, Anna Herr

Superconducting Digital (SCD) technology offers significant potential for
enhancing the performance of next generation large scale compute workloads. By
leveraging advanced lithography and a 300 mm platform, SCD devices can reduce
energy consumption and boost computational power. This paper presents a
cross-layer modeling approach to evaluate the system-level performance benefits
of SCD architectures for Large Language Model (LLM) training and inference. Our
findings, based on experimental data and Pulse Conserving Logic (PCL) design
principles, demonstrate substantial performance gain in both training and
inference. We are, thus, able to convincingly show that the SCD technology can
address memory and interconnect limitations of present day solutions for
next-generation compute systems.

摘要：超導數位 (SCD) 技術為提升次世代大型運算工作負載效能提供了顯著的潛力。藉由先進的光刻技術和 300 毫米平台，SCD 裝置可降低能源消耗並提升運算能力。本文提出了一種跨層級建模方法，用於評估 SCD 架構在大型語言模型 (LLM) 訓練和推論方面的系統級效能優勢。我們的發現基於實驗數據和脈衝節能邏輯 (PCL) 設計原則，證明了在訓練和推論方面都有顯著的效能提升。因此，我們得以令人信服地證明 SCD 技術可以解決現今解決方案在記憶體和互連方面的限制，以用於次世代運算系統。

##### **Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models**
2411.08642v1 by Chengdong Dong, Vijayakumar Bhagavatula, Zhenyu Zhou, Ajay Kumar

The remarkable progress in neural-network-driven visual data generation,
especially with neural rendering techniques like Neural Radiance Fields and 3D
Gaussian splatting, offers a powerful alternative to GANs and diffusion models.
These methods can produce high-fidelity images and lifelike avatars,
highlighting the need for robust detection methods. In response, an
unsupervised training technique is proposed that enables the model to extract
comprehensive features from the Fourier spectrum magnitude, thereby overcoming
the challenges of reconstructing the spectrum due to its centrosymmetric
properties. By leveraging the spectral domain and dynamically combining it with
spatial domain information, we create a robust multimodal detector that
demonstrates superior generalization capabilities in identifying challenging
synthetic images generated by the latest image synthesis techniques. To address
the absence of a 3D neural rendering-based fake image database, we develop a
comprehensive database that includes images generated by diverse neural
rendering techniques, providing a robust foundation for evaluating and
advancing detection methods.

摘要：神經網路驅動的視覺資料生成技術進展顯著，
特別是像神經輻照場和 3D 高斯噴射等神經渲染技術，為 GAN 和擴散模型提供了強而有力的替代方案。
這些方法可以產生高保真影像和逼真的頭像，
突顯了對穩健檢測方法的需求。為此，
提出了一種無監督訓練技術，使模型能夠從傅立葉頻譜幅度中提取全面的特徵，從而克服了由於其中心對稱性質而重建頻譜的挑戰。通過利用頻譜域並動態地將其與空間域資訊相結合，我們創造了一個穩健的多模態檢測器，在識別最新影像合成技術生成的具有挑戰性的合成影像方面表現出卓越的泛化能力。為了解決基於 3D 神經渲染的假影像資料庫的缺失問題，我們開發了一個全面的資料庫，其中包括由各種神經渲染技術生成的影像，為評估和推進檢測方法提供了穩健的基礎。

##### **Precision-Focused Reinforcement Learning Model for Robotic Object Pushing**
2411.08622v1 by Lara Bergmann, David Leins, Robert Haschke, Klaus Neumann

Non-prehensile manipulation, such as pushing objects to a desired target
position, is an important skill for robots to assist humans in everyday
situations. However, the task is challenging due to the large variety of
objects with different and sometimes unknown physical properties, such as
shape, size, mass, and friction. This can lead to the object overshooting its
target position, requiring fast corrective movements of the robot around the
object, especially in cases where objects need to be precisely pushed. In this
paper, we improve the state-of-the-art by introducing a new memory-based
vision-proprioception RL model to push objects more precisely to target
positions using fewer corrective movements.

摘要：非抓取式操作，例如將物體推到目標位置，是機器人在日常生活中協助人類的一項重要技能。然而，由於形狀、大小、質量和摩擦力等不同且有時未知的物理特性，物體種類繁多，因此這項任務具有挑戰性。這可能會導致物體超出其目標位置，需要機器人快速修正物體周圍的動作，尤其是在需要精確推動物體的情況下。在本文中，我們通過引入新的基於記憶的視覺本體感覺 RL 模型來改進現有技術，使用更少的修正動作將物體更精確地推到目標位置。

##### **Dynamic Subset Tuning: Expanding the Operational Range of Parameter-Efficient Training for Large Language Models**
2411.08610v1 by Felix Stahlberg, Jared Lichtarge, Shankar Kumar

We propose a novel parameter-efficient training (PET) method for large
language models that adapts models to downstream tasks by optimizing a small
subset of the existing model parameters. Unlike prior methods, this subset is
not fixed in location but rather which parameters are modified evolves over the
course of training. This dynamic parameter selection can yield good performance
with many fewer parameters than extant methods. Our method enables a seamless
scaling of the subset size across an arbitrary proportion of the total model
size, while popular PET approaches like prompt tuning and LoRA cover only a
small part of this spectrum. We match or outperform prompt tuning and LoRA in
most cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given
parameter budget across different model families and sizes.

摘要：我們提出一個新穎的參數有效訓練 (PET) 方法，用於大型語言模型，該方法透過最佳化現有模型參數的一個小部分，來調整模型以執行下游任務。與先前的做法不同，這個子集並未固定在位置上，而是修改哪些參數會隨著訓練過程而演變。這種動態參數選取可以產生良好的效能，而參數比現有方法少很多。我們的做法能讓子集大小在總模型大小的任意比例中無縫縮放，而像提示調整和 LoRA 之類的熱門 PET 方法只涵蓋了這個範圍的一小部分。在不同的模型系列和大小的各種 NLP 任務 (MT、QA、GSM8K、SuperGLUE) 中，我們在給定的參數預算下，與提示調整和 LoRA 相匹配或表現得更好。

##### **XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL**
2411.08599v1 by Yingqi Gao, Yifu Liu, Xiaoxia Li, Xiaorong Shi, Yin Zhu, Yiming Wang, Shiqi Li, Wei Li, Yuntao Hong, Zhiling Luo, Jinyang Gao, Liyu Mou, Yu Li

To tackle the challenges of large language model performance in natural
language to SQL tasks, we introduce XiYan-SQL, an innovative framework that
employs a multi-generator ensemble strategy to improve candidate generation. We
introduce M-Schema, a semi-structured schema representation method designed to
enhance the understanding of database structures. To enhance the quality and
diversity of generated candidate SQL queries, XiYan-SQL integrates the
significant potential of in-context learning (ICL) with the precise control of
supervised fine-tuning. On one hand, we propose a series of training strategies
to fine-tune models to generate high-quality candidates with diverse
preferences. On the other hand, we implement the ICL approach with an example
selection method based on named entity recognition to prevent overemphasis on
entities. The refiner optimizes each candidate by correcting logical or
syntactical errors. To address the challenge of identifying the best candidate,
we fine-tune a selection model to distinguish nuances of candidate SQL queries.
The experimental results on multiple dialect datasets demonstrate the
robustness of XiYan-SQL in addressing challenges across different scenarios.
Overall, our proposed XiYan-SQL achieves the state-of-the-art execution
accuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on
NL2GQL, and a competitive score of 72.23% on the Bird development benchmark.
The proposed framework not only enhances the quality and diversity of SQL
queries but also outperforms previous methods.

摘要：<paragraph>為了應對大型語言模型在自然語言轉換成 SQL 任務中的效能挑戰，我們引入了 XiYan-SQL，一個創新的架構，它採用多產生器組合策略來改善候選產生。我們引入了 M-Schema，一種半結構化架構表示方法，旨在加強對資料庫結構的理解。為了提升所產生的候選 SQL 查詢的品質和多樣性，XiYan-SQL 整合了脈絡中學習 (ICL) 的重大潛力，以及監督微調的精準控制。一方面，我們提出了一系列訓練策略，微調模型以產生具有多樣化偏好的高品質候選。另一方面，我們實作了 ICL 方法，採用基於命名實體辨識的範例選取方法，以防止過度強調實體。精煉器透過修正邏輯或語法錯誤，來最佳化每個候選。為了應對找出最佳候選的挑戰，我們微調了一個選取模型，以區分候選 SQL 查詢的細微差別。在多個方言資料集上的實驗結果，證明了 XiYan-SQL 在因應不同場景的挑戰時具有穩健性。總體而言，我們提出的 XiYan-SQL 在 Spider 測試集上達到了 89.65% 的最新執行準確度，在 SQL-Eval 上達到了 69.86%，在 NL2GQL 上達到了 41.20%，在 Bird 開發基準上達到了 72.23% 的競爭力分數。所提出的架構不僅提升了 SQL 查詢的品質和多樣性，也優於先前的各種方法。</paragraph>

##### **DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods**
2411.08587v1 by Rebecca Nevin, Aleksandra Ćiprijanović, Brian D. Nord

Assessing the quality of aleatoric uncertainty estimates from uncertainty
quantification (UQ) deep learning methods is important in scientific contexts,
where uncertainty is physically meaningful and important to characterize and
interpret exactly. We systematically compare aleatoric uncertainty measured by
two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).
Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data,
to explore how the UQ methods function for different data dimensionalities. We
investigate uncertainty injected on the input and output variables and include
a method to propagate uncertainty in the case of input uncertainty so that we
can compare the predicted aleatoric uncertainty to the known values. We
experiment with three levels of noise. The aleatoric uncertainty predicted
across all models and experiments scales with the injected noise level.
However, the predicted uncertainty is miscalibrated to $\rm{std}(\sigma_{\rm
al})$ with the true uncertainty for half of the DE experiments and almost all
of the DER experiments. The predicted uncertainty is the least accurate for
both UQ methods for the 2D input uncertainty experiment and the high-noise
level. While these results do not apply to more complex data, they highlight
that further research on post-facto calibration for these methods would be
beneficial, particularly for high-noise and high-dimensional settings.

摘要：<paragraph>在科學背景下，評估不確定量化 (UQ) 深度學習方法的不確定性估計品質非常重要，其中不確定性具有物理意義，且對於準確地描述和解釋至關重要。我們系統性地比較了兩種 UQ 技術（深度集成 (DE) 和深度證據回歸 (DER)）所測量的不確定性。我們的研究方法同時專注於 0 維 (0D) 和 2 維 (2D) 資料，以探討 UQ 方法如何針對不同的資料維度運作。我們調查注入輸入和輸出變數的不確定性，並包含一種方法，在輸入不確定性的情況下傳播不確定性，以便我們可以將預測的不確定性與已知值進行比較。我們使用三個層級的雜訊進行實驗。所有模型和實驗中預測的不確定性會隨著注入的雜訊層級而改變。然而，預測的不確定性會失準為 $\rm{std}(\sigma_{\rm al})$，其中一半的 DE 實驗和幾乎所有 DER 實驗的真實不確定性。對於 2D 輸入不確定性實驗和高雜訊層級，兩種 UQ 方法預測的不確定性最不準確。雖然這些結果不適用於更複雜的資料，但它們強調進一步研究這些方法的事後校正將是有益的，特別是對於高雜訊和高維度設定。</paragraph>

##### **Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**
2411.08586v1 by Guoqing Zhang, Keita Fukuyama, Kazumasa Kishimoto, Tomohiro Kuroda

Summarizing patient clinical notes is vital for reducing documentation
burdens. Current manual summarization makes medical staff struggle. We propose
an automatic method using LLMs, but long inputs cause LLMs to lose context,
reducing output quality especially in small size model. We used a 7B model,
open-calm-7b, enhanced with Native Bayes Context Extend and a redesigned
decoding mechanism to reference one sentence at a time, keeping inputs within
context windows, 2048 tokens. Our improved model achieved near parity with
Google's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating
strong performance using less resources, enhancing automated EMR summarization
feasibility.

摘要：摘要病歷臨床記錄對於減少文件負擔至關重要。當前的摘要手冊讓醫療人員難以應付。我們提出使用 LLM 的自動化方法，但長輸入會導致 LLM 失去上下文，降低輸出品質，特別是在小型模型中。我們使用了一個 7B 模型，open-calm-7b，並透過 Native Bayes Context Extend 和重新設計的解碼機制進行增強，一次參考一個句子，將輸入保留在上下文視窗中，2048 個符號。我們改良的模型在 ROUGE-L 指標上與 Google 超過 175B 的 Gemini 達到接近同等水準，樣本數為 200，表示使用較少資源就能有強勁的表現，增強了自動化電子病歷摘要的可行性。

##### **Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors**
2411.08582v1 by Stepan Svirin, Artem Ryzhikov, Saraa Ali, Denis Derkach

The application of machine learning (ML) algorithms in the intelligent
diagnosis of three-phase engines has the potential to significantly enhance
diagnostic performance and accuracy. Traditional methods largely rely on
signature analysis, which, despite being a standard practice, can benefit from
the integration of advanced ML techniques. In our study, we innovate by
combining state of the art algorithms with a novel unsupervised anomaly
generation methodology that takes into account physics model of the engine.
This hybrid approach leverages the strengths of both supervised ML and
unsupervised signature analysis, achieving superior diagnostic accuracy and
reliability along with a wide industrial application. Our experimental results
demonstrate that this method significantly outperforms existing ML and non-ML
state-of-the-art approaches while retaining the practical advantages of an
unsupervised methodology. The findings highlight the potential of our approach
to significantly contribute to the field of engine diagnostics, offering a
robust and efficient solution for real-world applications.

摘要：機器學習 (ML) 演算法應用於三相引擎的智慧診斷，具有大幅提升診斷效能與精準度的潛力。傳統方法主要依賴特徵分析，儘管這是一個標準作法，但仍可從進階 ML 技術的整合中受益。在我們的研究中，我們創新地結合了最先進的演算法與一種新穎的非監督異常生成方法，該方法考慮了引擎的物理模型。這種混合方法同時利用了監督式 ML 和非監督特徵分析的優點，達到了優異的診斷準確度和可靠性，並具有廣泛的產業應用。我們的實驗結果證明，這種方法顯著優於現有的 ML 和非 ML 最先進方法，同時保留了非監督方法的實用優勢。研究結果突顯了我們的方法在引擎診斷領域做出重大貢獻的潛力，為實際應用提供了一個強健且有效率的解決方案。

##### **Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions**
2411.08563v1 by Micha Kaiser, Paul Lohmann, Peter Ochieng, Billy Shi, Cass R. Sunstein, Lucia A. Reisch

Food consumption and production contribute significantly to global greenhouse
gas emissions, making them crucial entry points for mitigating climate change
and maintaining a liveable planet. Over the past two decades, food policy
initiatives have explored interventions to reshape production and consumption
patterns, focusing on reducing food waste and curbing ruminant meat
consumption. While the evidence of "what works" improves, evaluating which
policies are appropriate and effective in specific contexts remains difficult
due to external validity challenges. This paper demonstrates that a fine-tuned
large language model (LLM) can accurately predict the direction of outcomes in
approximately 80\% of empirical studies measuring dietary-based impacts (e.g.
food choices, sales, waste) resulting from behavioral interventions and
policies. Approximately 75 prompts were required to achieve optimal results,
with performance showing signs of catastrophic loss beyond this point. Our
findings indicate that greater input detail enhances predictive accuracy,
although the model still faces challenges with unseen studies, underscoring the
importance of a representative training sample. As LLMs continue to improve and
diversify, they hold promise for advancing data-driven, evidence-based
policymaking.

摘要：食品消費和生產對全球溫室氣體排放有顯著影響，這使其成為減輕氣候變遷和維持宜居地球的重要切入點。在過去二十年來，食品政策倡議探索了重塑生產和消費模式的干預措施，重點在於減少食物浪費和遏制反芻動物肉類消費。儘管「有效方法」的證據有所改善，但由於外部效度挑戰，評估哪些政策在特定背景下適當且有效仍然很困難。本文證明，經過微調的大型語言模型 (LLM) 可以準確預測約 80% 測量飲食影響的實證研究結果的方向（例如，食物選擇、銷售、浪費），這些影響是由行為干預和政策造成的。大約需要 75 個提示才能達到最佳結果，而效能在此點之後顯示出災難性損失的跡象。我們的研究結果表明，輸入的詳細資料越多，預測準確性就越高，儘管該模型在面對未見過的研究時仍面臨挑戰，這強調了具有代表性的訓練樣本的重要性。隨著 LLM 持續改善和多元化，它們有望推進資料驅動的、基於證據的政策制定。

##### **Neural Corrective Machine Unranking**
2411.08562v1 by Jingrui Hou, Axel Finke, Georgina Cosma

Machine unlearning in neural information retrieval (IR) systems requires
removing specific data whilst maintaining model performance. Applying existing
machine unlearning methods to IR may compromise retrieval effectiveness or
inadvertently expose unlearning actions due to the removal of particular items
from the retrieved results presented to users. We formalise corrective
unranking, which extends machine unlearning in (neural) IR context by
integrating substitute documents to preserve ranking integrity, and propose a
novel teacher-student framework, Corrective unRanking Distillation (CuRD), for
this task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR
model such that its output relevance scores of to-be-forgotten samples mimic
those of low-ranking, non-retrievable samples; (2) enables correction by
fine-tuning the relevance scores for the substitute samples to match those of
corresponding to-be-forgotten samples closely; (3) seeks to preserve
performance on samples that are not targeted for forgetting. We evaluate CuRD
on four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and
TREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the
training dataset demonstrate that CuRD outperforms seven state-of-the-art
baselines in terms of forgetting and correction while maintaining model
retention and generalisation capabilities.

摘要：神經資訊檢索 (IR) 系統中的機器去學習需要在維持模型效能的同時移除特定資料。將現有的機器去學習方法套用於 IR 可能會損害檢索效能，或由於從提供給使用者的檢索結果中移除特定項目而意外地揭露去學習動作。我們正式化修正性取消排名，這透過整合替代文件來保留排名完整性，以擴充 (神經) IR 背景中的機器去學習，並為此任務提出一個創新的師生架構，修正性取消排名蒸餾 (CuRD)。CuRD (1) 透過調整 (已訓練的) 神經 IR 模型，讓其輸出待遺忘範例的相關性分數模仿低排名、不可檢索範例的相關性分數，以促進遺忘；(2) 透過微調替代範例的相關性分數，使其與對應待遺忘範例的相關性分數緊密匹配，以進行修正；(3) 尋求保留未針對遺忘的範例的效能。我們使用 MS MARCO 和 TREC CAR 資料集，在四個神經 IR 模型 (BERTcat、BERTdot、ColBERT、PARADE) 上評估 CuRD。使用佔訓練資料集 1% 和 20% 的遺忘集大小的實驗證明，CuRD 在遺忘和修正方面優於七個最先進的基準，同時維持模型保留和概化能力。

##### **LogLLM: Log-based Anomaly Detection Using Large Language Models**
2411.08561v1 by Wei Guan, Jian Cao, Shiyou Qian, Jianqi Gao

Software systems often record important runtime information in logs to help
with troubleshooting. Log-based anomaly detection has become a key research
area that aims to identify system issues through log data, ultimately enhancing
the reliability of software systems. Traditional deep learning methods often
struggle to capture the semantic information embedded in log data, which is
typically organized in natural language. In this paper, we propose LogLLM, a
log-based anomaly detection framework that leverages large language models
(LLMs). LogLLM employs BERT for extracting semantic vectors from log messages,
while utilizing Llama, a transformer decoder-based model, for classifying log
sequences. Additionally, we introduce a projector to align the vector
representation spaces of BERT and Llama, ensuring a cohesive understanding of
log semantics. Unlike conventional methods that require log parsers to extract
templates, LogLLM preprocesses log messages with regular expressions,
streamlining the entire process. Our framework is trained through a novel
three-stage procedure designed to enhance performance and adaptability.
Experimental results across four public datasets demonstrate that LogLLM
outperforms state-of-the-art methods. Even when handling unstable logs, it
effectively captures the semantic meaning of log messages and detects anomalies
accurately.

摘要：軟體系統通常會在記錄檔中記錄重要的執行時間資訊，以協助進行疑難排解。基於記錄檔的異常偵測已成為一個重要的研究領域，其目標是透過記錄檔資料找出系統問題，最終提升軟體系統的可靠性。傳統的深度學習方法通常難以擷取嵌入在記錄檔資料中的語意資訊，而這些資訊通常以自然語言組織。在本文中，我們提出 LogLLM，一個基於記錄檔的異常偵測架構，它利用大型語言模型 (LLM)。LogLLM 使用 BERT 從記錄檔訊息中萃取語意向量，同時利用 Llama，一個基於轉換器解碼器的模型，來分類記錄檔序列。此外，我們引入一個投影機來對齊 BERT 和 Llama 的向量表示空間，確保對記錄檔語意的理解具有一致性。與需要記錄檔解析器來萃取範本的傳統方法不同，LogLLM 使用正規表示式預處理記錄檔訊息，簡化了整個流程。我們的架構透過一個創新的三階段程序進行訓練，旨在提升效能和適應性。在四個公開資料集上的實驗結果證明，LogLLM 優於最先進的方法。即使在處理不穩定的記錄檔時，它也能有效地擷取記錄檔訊息的語意意義，並準確地偵測異常。

##### **CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs**
2411.08553v1 by Suhas S Kowshik, Abhishek Divekar, Vijit Malik

Large language models (LLMs) have demonstrated remarkable performance in
diverse tasks using zero-shot and few-shot prompting. Even though their
capabilities of data synthesis have been studied well in recent years, the
generated data suffers from a lack of diversity, less adherence to the prompt,
and potential biases that creep into the data from the generator model. In this
work, we tackle the challenge of generating datasets with high diversity, upon
which a student model is trained for downstream tasks. Taking the route of
decoding-time guidance-based approaches, we propose CorrSynth, which generates
data that is more diverse and faithful to the input prompt using a correlated
sampling strategy. Further, our method overcomes the complexity drawbacks of
some other guidance-based techniques like classifier-based guidance. With
extensive experiments, we show the effectiveness of our approach and
substantiate our claims. In particular, we perform intrinsic evaluation to show
the improvements in diversity. Our experiments show that CorrSynth improves
both student metrics and intrinsic metrics upon competitive baselines across
four datasets, showing the innate advantage of our method.

摘要：大型語言模型 (LLM) 已在使用零次和少量提示的各種任務中展示出卓越的效能。儘管近年來它們的資料合成能力已獲得廣泛研究，但產生的資料缺乏多樣性、較不符合提示，且潛在偏見會從生成器模型滲入資料中。在這項工作中，我們解決了生成具有高度多樣性資料集的挑戰，學生模型會根據這些資料集針對下游任務進行訓練。我們採用解碼時間指導方法，提出 CorrSynth，它使用相關抽樣策略產生更多樣化且忠實於輸入提示的資料。此外，我們的方法克服了其他一些基於指導的技術（如基於分類器的指導）的複雜性缺點。透過廣泛的實驗，我們展示了我們方法的有效性並證實了我們的說法。特別是，我們執行內在評估以顯示多樣性方面的改進。我們的實驗顯示，CorrSynth 在四個資料集上改善了學生指標和內在指標，顯示了我們方法的內在優勢。

##### **Deeper Insights into Learning Performance of Stochastic Configuration Networks**
2411.08544v1 by Xiufeng Yan, Dianhui Wang

Stochastic Configuration Networks (SCNs) are a class of randomized neural
networks that integrate randomized algorithms within an incremental learning
framework. A defining feature of SCNs is the supervisory mechanism, which
adaptively adjusts the distribution to generate effective random basis
functions, thereby enabling error-free learning. In this paper, we present a
comprehensive analysis of the impact of the supervisory mechanism on the
learning performance of SCNs. Our findings reveal that the current SCN
framework evaluates the effectiveness of each random basis function in reducing
residual errors using a lower bound on its error reduction potential, which
constrains SCNs' overall learning efficiency. Specifically, SCNs may fail to
consistently select the most effective random candidate as the new basis
function during each training iteration. To overcome this problem, we propose a
novel method for evaluating the hidden layer's output matrix, supported by a
new supervisory mechanism that accurately assesses the error reduction
potential of random basis functions without requiring the computation of the
Moore-Penrose inverse of the output matrix. This approach enhances the
selection of basis functions, reducing computational complexity and improving
the overall scalability and learning capabilities of SCNs. We introduce a
Recursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new
supervisory mechanism and demonstrate its effectiveness through simulations
over some benchmark datasets. Experiments show that RMPI-SCN outperforms the
conventional SCN in terms of learning capability, underscoring its potential to
advance the SCN framework for large-scale data modeling applications.

摘要：隨機組態網路 (SCN) 是一類隨機神經網路，它在增量學習架構中整合了隨機演算法。SCN 的一個定義特徵是監督機制，它能適應性調整分佈以產生有效的隨機基底函數，從而實現無錯誤學習。在本文中，我們對監督機制對 SCN 學習效能的影響進行了全面分析。我們的研究結果表明，當前 SCN 框架使用其誤差減少潛力的下界來評估每個隨機基底函數在減少殘差誤差方面的有效性，這限制了 SCN 的整體學習效率。具體而言，SCN 可能無法在每次訓練迭代期間始終如一地選擇最有效的隨機候選作為新的基底函數。為了克服這個問題，我們提出了一種新穎的方法來評估隱藏層的輸出矩陣，並得到一種新的監督機制的支援，它準確評估隨機基底函數的誤差減少潛力，而不需要計算輸出矩陣的 Moore-Penrose 逆矩陣。這種方法增強了基底函數的選擇，降低了計算複雜度，並提高了 SCN 的整體可擴充性和學習能力。我們引入了基於新的監督機制的遞迴 Moore-Penrose 逆 SCN (RMPI-SCN) 訓練方案，並通過一些基準資料集上的模擬證明了它的有效性。實驗表明，RMPI-SCN 在學習能力方面優於傳統 SCN，這凸顯了其在促進 SCN 框架用於大規模資料建模應用方面的潛力。

##### **MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation**
2411.08537v1 by Fabian Bongratz, Markus Karmann, Adrian Holz, Moritz Bonhoeffer, Viktor Neumaier, Sarah Deli, Benita Schmitz-Koep, Claus Zimmer, Christian Sorg, Melissa Thalhammer, Dennis M Hedderich, Christian Wachinger

Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste
products from the human brain. An impairment in their functionality has been
associated with aging as well as brain disorders like multiple sclerosis and
Alzheimer's disease. However, MLVs have only recently been described for the
first time in magnetic resonance imaging (MRI), and their ramified structure
renders manual segmentation particularly difficult. Further, as there is no
consistent notion of their appearance, human-annotated MLV structures contain a
high inter-rater variability that most automatic segmentation methods cannot
take into account. In this work, we propose a new rater-aware training scheme
for the popular nnU-Net model, and we explore rater-based ensembling strategies
for accurate and consistent segmentation of MLVs. This enables us to boost
nnU-Net's performance while obtaining explicit predictions in different
annotation styles and a rater-based uncertainty estimation. Our final model,
MLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to
the human reference standard. The model further matches the human inter-rater
reliability and replicates age-related associations with MLV volume.

摘要：腦膜淋巴管 (MLV) 負責排出人腦中的廢物。其功能受損與老化以及多發性硬化症和阿茲海默症等腦部疾病有關。然而，MLV 直到最近才在磁共振成像 (MRI) 中首次被描述，其分枝結構使得手動分割特別困難。此外，由於對其外觀沒有統一的概念，人為註解的 MLV 結構包含很高的評分者間變異性，大多數自動分割方法無法考慮到這一點。在這項工作中，我們為流行的 nnU-Net 模型提出了一種新的評分者感知訓練方案，並探索了基於評分者的集成策略，以準確且一致地分割 MLV。這使我們能夠提升 nnU-Net 的性能，同時獲得不同註解樣式中的明確預測和基於評分者的不確定性估計。我們的最終模型 MLV^2-Net 在人類參考標準方面實現了 0.806 的 Dice 相似性係數。該模型進一步匹配了人類評分者間的可靠性，並複製了與 MLV 體積相關的年齡相關關聯。

##### **Neural Topic Modeling with Large Language Models in the Loop**
2411.08534v1 by Xiaohao Yang, He Zhao, Weijie Xu, Yuanyuan Qi, Jueqing Lu, Dinh Phung, Lan Du

Topic modeling is a fundamental task in natural language processing, allowing
the discovery of latent thematic structures in text corpora. While Large
Language Models (LLMs) have demonstrated promising capabilities in topic
discovery, their direct application to topic modeling suffers from issues such
as incomplete topic coverage, misalignment of topics, and inefficiency. To
address these limitations, we propose LLM-ITL, a novel LLM-in-the-loop
framework that integrates LLMs with many existing Neural Topic Models (NTMs).
In LLM-ITL, global topics and document representations are learned through the
NTM, while an LLM refines the topics via a confidence-weighted Optimal
Transport (OT)-based alignment objective. This process enhances the
interpretability and coherence of the learned topics, while maintaining the
efficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help
NTMs significantly improve their topic interpretability while maintaining the
quality of document representation.

摘要：主題模型建立是自然語言處理中的一項基本任務，允許在文本語料庫中發現潛在的主題結構。雖然大型語言模型 (LLM) 已在主題發現方面展現出有前途的能力，但將其直接應用於主題模型會產生不完整的主題涵蓋範圍、主題錯位和效率低落等問題。為了解決這些限制，我們提出了 LLM-ITL，這是一個新的 LLM 循環架構，將 LLM 與許多現有的神經主題模型 (NTM) 整合在一起。在 LLM-ITL 中，透過 NTM 學習全局主題和文件表示，而 LLM 則透過基於信心加權的最適傳輸 (OT) 對齊目標來優化這些主題。此程序增強了學習主題的可解釋性和一致性，同時維持了 NTM 的效率。廣泛的實驗證明，LLM-ITL 可以幫助 NTM 大幅提升其主題可解釋性，同時維持文件表示的品質。

##### **Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System**
2411.08526v1 by Deborah Gerhardt, Miriam Marcowitz-Bitton, W. Michael Schuster, Avshalom Elmalech, Omri Suissa, Moshe Mash

This study examines gender disparities in patent law by analyzing the textual
content of patent applications. While prior research has primarily focused on
the study of metadata (i.e., filing year or technological class), we employ
machine learning and natural language processing techniques to derive latent
information from patent texts. In particular, these methods are used to predict
inventor gender based on textual characteristics. We find that gender can be
identified with notable accuracy - even without knowing the inventor's name.
This ability to discern gender through text suggests that anonymized patent
examination - often proposed as a solution to mitigate disparities in patent
grant rate - may not fully address gender-specific outcomes in securing a
patent. Our analysis additionally identifies gendered differences in textual
choices within patent documents and the fields in which inventors choose to
work. These findings highlight the complex interaction between textual choices,
gender, and success in securing a patent. As discussed herein, this raises
critical questions about the efficacy of current proposals aimed at achieving
gender parity and efficiency in the patent system.

摘要：本研究透過分析專利申請案的文字內容，來探討專利法中的性別差異。雖然先前的研究主要集中在探討元資料（例如申請年份或技術類別），我們採用機器學習和自然語言處理技術，從專利文字中衍生出潛在資訊。特別是，這些方法用來根據文字特徵預測發明者的性別。我們發現，即使不知道發明者的姓名，也能以顯著的準確度識別性別。透過文字辨別性別的能力表明，匿名專利審查（通常被提出作為減輕專利授予率差異的解決方案）可能無法完全解決取得專利的性別特定結果。我們的分析進一步識別出專利文件中文字選擇中的性別差異，以及發明者選擇工作的領域。這些發現突顯出文字選擇、性別和取得專利成功之間的複雜互動。正如本文所述，這引發了關於專利制度中實現性別平等和效率的當前提案效能的關鍵問題。

##### **SAD-TIME: a Spatiotemporal-fused network for depression detection with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor**
2411.08521v1 by Han-Guang Wang, Hui-Rang Hou, Li-Cheng Jin, Chen-Yang Xu, Zhong-Yi Zhang, Qing-Hao Meng

Background and Objective: Depression is a severe mental disorder, and
accurate diagnosis is pivotal to the cure and rehabilitation of people with
depression. However, the current questionnaire-based diagnostic methods could
bring subjective biases and may be denied by subjects. In search of a more
objective means of diagnosis, researchers have begun to experiment with deep
learning-based methods for identifying depressive disorders in recent years.
Methods: In this study, a novel Spatiotemporal-fused network with Automated
multi-scale Depth-wise and TIME-interval-related common feature extractor
(SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common
features extractor (CFE), a spatial sector (SpS), a modified temporal sector
(TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale
depth-wise 1D-convolutional neural network and a time-interval embedding
generator, where the unique information of each channel is preserved. The SpS
fuses the functional connectivity with the distance-based connectivity
containing spatial position of EEG electrodes. A multi-head-attention graph
convolutional network is also applied in the SpS to fuse the features from
different EEG channels. The TeS is based on long short-term memory and graph
transformer networks, where the temporal information of different time-windows
is fused. Moreover, the DAL is used after the SpS to obtain the
domain-invariant feature. Results: Experimental results under tenfold
cross-validation show that the proposed SAD-TIME method achieves 92.00% and
94.00% depression classification accuracies on two datasets, respectively, in
cross-subject mode. Conclusion: SAD-TIME is a robust depression detection
model, where the automatedly-generated features, the SpS and the TeS assist the
classification performance with the fusion of the innate spatiotemporal
information in the EEG signals.

摘要：<paragraph>背景與目標：憂鬱症是一種嚴重的精神疾病，而準確的診斷對於憂鬱症患者的治療和復健至關重要。然而，目前基於問卷的診斷方法可能會帶來主觀偏誤，且可能遭到受試者否認。為了尋求更客觀的診斷方式，研究人員近年來開始嘗試使用基於深度學習的方法來識別憂鬱症。方法：本研究提出了一個結合自動化多尺度深度和時間間隔相關共用特徵萃取器的時空融合網路（SAD-TIME）。SAD-TIME 整合了一個自動化節點共用特徵萃取器（CFE）、一個空間區塊（SpS）、一個修改過的時間區塊（TeS）和一個領域對抗學習器（DAL）。CFE 包含一個多尺度深度 1D 捲積神經網路和一個時間間隔嵌入產生器，其中每個通道的獨特資訊都被保留下來。SpS 將功能連接與包含腦電圖電極空間位置的基於距離連接融合在一起。一個多頭注意力圖形卷積網路也應用於 SpS 中，以融合來自不同腦電圖通道的特徵。TeS 基於長期短期記憶和圖形Transformer網路，其中不同時間窗的時間資訊被融合在一起。此外，DAL 在 SpS 之後被用於獲取領域不變特徵。結果：在十倍交叉驗證下的實驗結果顯示，所提出的 SAD-TIME 方法在跨主體模式下分別在兩個資料集上達到了 92.00% 和 94.00% 的憂鬱症分類準確度。結論：SAD-TIME 是一個強大的憂鬱症檢測模型，其中自動產生的特徵、SpS 和 TeS 透過融合腦電圖訊號中固有的時空資訊來協助分類表現。</paragraph>

##### **Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding**
2411.08516v1 by Deyi Ji, Lanyun Zhu, Siqi Gao, Peng Xu, Hongtao Lu, Jieping Ye, Feng Zhao

The ubiquity and value of tables as semi-structured data across various
domains necessitate advanced methods for understanding their complexity and
vast amounts of information. Despite the impressive capabilities of large
language models (LLMs) in advancing the natural language understanding
frontier, their application to large-scale tabular data presents significant
challenges, specifically regarding table size and complex intricate
relationships. Existing works have shown promise with small-scale tables but
often flounder when tasked with the complex reasoning required by larger,
interconnected tables found in real-world scenarios. To address this gap, we
introduce "Tree-of-Table", a novel approach designed to enhance LLMs' reasoning
capabilities over large and complex tables. Our method employs Table
Condensation and Decomposition to distill and reorganize relevant data into a
manageable format, followed by the construction of a hierarchical Table-Tree
that facilitates tree-structured reasoning. Through a meticulous Table-Tree
Execution process, we systematically unravel the tree-structured reasoning
chain to derive the solutions. Experiments across diverse datasets, including
WikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new
benchmark with superior performance, showcasing remarkable efficiency and
generalization capabilities in large-scale table reasoning.

摘要：由於表格在各種領域中作為半結構化資料的普遍性和價值，因此需要進階的方法來了解其複雜性和大量的資訊。儘管大型語言模型 (LLM) 在推進自然語言理解領域方面具有令人印象深刻的能力，但它們在應用於大規模表格資料時會出現重大挑戰，特別是在表格大小和複雜的錯綜關係方面。現有研究已在小規模表格上展現出前景，但當面對現實世界場景中較大型、相互連結的表格所需的複雜推理時，通常會陷入困境。為了解決這個差距，我們引入了「表格樹」，這是一種新穎的方法，旨在增強 LLM 對大型且複雜表格的推理能力。我們的模型採用表格濃縮和分解，將相關資料提煉並重新組織成易於管理的格式，接著建構一個層級式的表格樹，以利進行樹狀結構推理。透過一絲不苟的表格樹執行程序，我們系統性地解開樹狀結構推理鏈，以推導出解決方案。在各種資料集上的實驗，包括 WikiTQ、TableFact、FeTaQA 和 BIRD，證明表格樹樹立了一個新的基準，具有優異的效能，在大型表格推理中展現出卓越的效率和泛化能力。

##### **Explainers' Mental Representations of Explainees' Needs in Everyday Explanations**
2411.08514v1 by Michael Erol Schaffer, Lutz Terfloth, Carsten Schulte, Heike M. Buhl

In explanations, explainers have mental representations of explainees'
developing knowledge and shifting interests regarding the explanandum. These
mental representations are dynamic in nature and develop over time, thereby
enabling explainers to react to explainees' needs by adapting and customizing
the explanation. XAI should be able to react to explainees' needs in a similar
manner. Therefore, a component that incorporates aspects of explainers' mental
representations of explainees is required. In this study, we took first steps
by investigating explainers' mental representations in everyday explanations of
technological artifacts. According to the dual nature theory, technological
artifacts require explanations with two distinct perspectives, namely
observable and measurable features addressing "Architecture" or interpretable
aspects addressing "Relevance". We conducted extended semi structured pre-,
post- and video recall-interviews with explainers (N=9) in the context of an
explanation. The transcribed interviews were analyzed utilizing qualitative
content analysis. The explainers' answers regarding the explainees' knowledge
and interests with regard to the technological artifact emphasized the
vagueness of early assumptions of explainers toward strong beliefs in the
course of explanations. The assumed knowledge of explainees in the beginning is
centered around Architecture and develops toward knowledge with regard to both
Architecture and Relevance. In contrast, explainers assumed higher interests in
Relevance in the beginning to interests regarding both Architecture and
Relevance in the further course of explanations. Further, explainers often
finished the explanation despite their perception that explainees still had
gaps in knowledge. These findings are transferred into practical implications
relevant for user models for adaptive explainable systems.

摘要：<paragraph>在說明中，說明者會在心智中建構被說明者的知識發展與對被說明對象的興趣轉變。這些心智建構本質上是動態的，並會隨著時間發展，因此能讓說明者透過調整和客製化說明來回應被說明者的需求。XAI 應能以類似的方式回應被說明者的需求。因此，需要一個元件將說明者對被說明者的心智建構面向納入其中。在這項研究中，我們透過探討說明者在日常技術製品說明中的心智建構，踏出了第一步。根據二元本質理論，技術製品需要從兩個不同觀點來進行說明，也就是說明「架構」的可觀察和可衡量特徵，或說明「關聯性」的可詮釋面向。我們在說明的脈絡中，對說明者 (N=9) 進行了擴充的半結構化事前、事後和影片回憶訪談。我們利用定性內容分析法來分析轉錄後的訪談。說明者針對被說明者對技術製品的知識和興趣的回答，強調了說明者在說明過程中，從早期的模糊假設轉變為堅定信念的過程。說明者在開始時假設的知識以架構為中心，並發展為同時具備架構和關聯性的知識。相反地，說明者在開始時假設較高的關聯性興趣，而在說明的過程中轉變為同時對架構和關聯性感興趣。此外，說明者即使認為被說明者在知識上仍有落差，也常常會結束說明。這些發現轉化為與適應性可解釋系統使用者模型相關的實務意涵。</paragraph>

##### **An Information Theoretic Approach to Operationalize Right to Data Protection**
2411.08506v1 by Abhinav Java, Simra Shahid, Chirag Agarwal

The widespread practice of indiscriminate data scraping to fine-tune language
models (LMs) raises significant legal and ethical concerns, particularly
regarding compliance with data protection laws such as the General Data
Protection Regulation (GDPR). This practice often results in the unauthorized
use of personal information, prompting growing debate within the academic and
regulatory communities. Recent works have introduced the concept of generating
unlearnable datasets (by adding imperceptible noise to the clean data), such
that the underlying model achieves lower loss during training but fails to
generalize to the unseen test setting. Though somewhat effective, these
approaches are predominantly designed for images and are limited by several
practical constraints like requiring knowledge of the target model. To this
end, we introduce RegText, a framework that injects imperceptible spurious
correlations into natural language datasets, effectively rendering them
unlearnable without affecting semantic content. We demonstrate RegText's
utility through rigorous empirical analysis of small and large LMs. Notably,
RegText can restrict newer models like GPT-4o and Llama from learning on our
generated data, resulting in a drop in their test accuracy compared to their
zero-shot performance and paving the way for generating unlearnable text to
protect public data.

摘要：濫用資料擷取來微調語言模型（LM）的普遍做法引發了重大的法律和道德問題，特別是在遵守資料保護法規（例如一般資料保護規範 (GDPR)）方面。這種做法經常導致未經授權使用個人資訊，並在學術和法規社群中引發越來越多的爭議。最近的研究引入了產生無法學習的資料集（透過在乾淨資料中加入難以察覺的雜訊）的概念，使得基礎模型在訓練期間能獲得較低的損失，但無法推廣到未見的測試設定。儘管這些方法有些有效，但它們主要設計用於影像，並受到多項實務限制，例如需要知道目標模型。為此，我們引入了 RegText，這是一個框架，它會將難以察覺的虛假關聯注入到自然語言資料集中，有效地讓它們無法被學習，同時不會影響語意內容。我們透過對小型和大型 LM 進行嚴謹的實證分析，展示了 RegText 的效用。值得注意的是，RegText 能夠限制 GPT-4o 和 Llama 等較新的模型學習我們的產生資料，導致它們的測試準確度下降，與它們的零次學習效能相比，並為產生無法學習的文字以保護公開資料鋪路。

##### **Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks**
2411.08504v1 by Junhua Liu, Kwan Hui Lim, Roy Ka-Wei Lee

How objective and unbiased are we while making decisions? This work
investigates cognitive bias identification in high-stake decision making
process by human experts, questioning its effectiveness in real-world settings,
such as candidates assessments for university admission. We begin with a
statistical analysis assessing correlations among different decision points
among in the current process, which discovers discrepancies that imply
cognitive bias and inconsistency in decisions. This motivates our exploration
of bias-aware AI-augmented workflow that surpass human judgment. We propose
BGM-HAN, a hierarchical attention network enhanced by byte-pair encoding,
multi-head attention and gated residual connection. Using it as backbone model,
we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which
simulate real-world decision-making. In our experiments, both the proposed
model and the agentic workflow significantly improves on both human judgment
and alternative models, validated with real-world data.

摘要：在做決策時，我們有多客觀公正？這項研究探討了人類專家在高風險決策過程中認知偏差的辨識，質疑其在現實世界中的有效性，例如大學入學的候選人評估。我們從統計分析開始，評估當前流程中不同決策點之間的相關性，發現了暗示認知偏差和決策不一致的差異。這激勵我們探索超越人類判斷的具備偏差感知的人工智慧增強工作流程。我們提出了 BGM-HAN，一個由位元組對編碼、多頭注意力和閘控殘差連接增強的分層注意力網路。使用它作為骨幹模型，我們進一步提出了模擬現實世界決策的候選名單分析推薦 (SAR) 代理工作流程。在我們的實驗中，提出的模型和代理工作流程都顯著優於人類判斷和替代模型，並使用現實世界資料驗證。

##### **Learning Model Agnostic Explanations via Constraint Programming**
2411.08478v1 by Frederic Koriche, Jean-Marie Lagniez, Stefan Mengel, Chi Tran

Interpretable Machine Learning faces a recurring challenge of explaining the
predictions made by opaque classifiers such as ensemble models, kernel methods,
or neural networks in terms that are understandable to humans. When the model
is viewed as a black box, the objective is to identify a small set of features
that jointly determine the black box response with minimal error. However,
finding such model-agnostic explanations is computationally demanding, as the
problem is intractable even for binary classifiers. In this paper, the task is
framed as a Constraint Optimization Problem, where the constraint solver seeks
an explanation of minimum error and bounded size for an input data instance and
a set of samples generated by the black box. From a theoretical perspective,
this constraint programming approach offers PAC-style guarantees for the output
explanation. We evaluate the approach empirically on various datasets and show
that it statistically outperforms the state-of-the-art heuristic Anchors
method.

摘要：可解釋機器學習面臨一項反覆出現的挑戰，即用人類可以理解的術語解釋不透明分類器（例如集成模型、核方法或神經網路）做出的預測。當模型被視為黑盒子時，目標是識別一組小特徵，這些特徵共同決定黑盒子回應，且誤差最小。然而，找到這種與模型無關的解釋在計算上要求很高，因為即使對於二進制分類器，這個問題也是難以處理的。在本文中，任務被構建為一個約束最佳化問題，其中約束求解器尋求一個輸入資料實例和黑盒子生成的樣本集的最小誤差和有界大小的解釋。從理論角度來看，這種約束程式設計方法為輸出解釋提供了 PAC 式保證。我們在各種資料集上對該方法進行了經驗評估，結果表明，在統計上，它優於最先進的啟發式 Anchors 方法。

##### **Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)**
2411.08469v1 by Fadi Al Machot, Martin Thomas Horsch, Habib Ullah

Growing concerns over the lack of transparency in AI, particularly in
high-stakes fields like healthcare and finance, drive the need for explainable
and trustworthy systems. While Large Language Models (LLMs) perform
exceptionally well in generating accurate outputs, their "black box" nature
poses significant challenges to transparency and trust. To address this, the
paper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs.
By leveraging domain expert knowledge, retrieval-augmented generation (RAG),
and formal reasoning frameworks like Answer Set Programming (ASP), TranspNet
enhances LLM outputs with structured reasoning and verification. This approach
ensures that AI systems deliver not only accurate but also explainable and
trustworthy results, meeting regulatory demands for transparency and
accountability. TranspNet provides a comprehensive solution for developing AI
systems that are reliable and interpretable, making it suitable for real-world
applications where trust is critical.

摘要：由於對 AI 缺乏透明度的擔憂日益加劇，尤其是在醫療保健和金融等高風險領域，因此需要可解釋且可信賴的系統。雖然大型語言模型 (LLM) 在產生準確輸出方面表現得非常好，但其「黑盒子」性質對透明度和信任構成了重大挑戰。為了解決此問題，本文提出了 TranspNet 管道，它將符號 AI 與 LLM 整合在一起。TranspNet 透過利用領域專家知識、檢索增強產生 (RAG) 和形式推理框架（例如 Answer Set Programming (ASP)），使用結構化推理和驗證來增強 LLM 輸出。此方法可確保 AI 系統不僅能提供準確的結果，還能提供可解釋且可信賴的結果，以滿足法規對透明度和問責制的需求。TranspNet 為開發可靠且可解釋的 AI 系統提供了一個全面的解決方案，使其適用於信任至關重要的實際應用。

##### **Crystal Structure Generation Based On Material Properties**
2411.08464v1 by Chao Huang, JiaHui Chen, HongRui Liang, ChunYan Chen, Chen Chen

The discovery of new materials is very important to the field of materials
science. When researchers explore new materials, they often have expected
performance requirements for their crystal structure. In recent years,
data-driven methods have made great progress in the direction plane of crystal
structure generation, but there is still a lack of methods that can effectively
map material properties to crystal structure. In this paper, we propose a
Crystal DiT model to generate the crystal structure from the expected material
properties by embedding the material properties and combining the symmetry
information predicted by the large language model. Experimental verification
shows that our proposed method has good performance.

摘要：新材料的發現對於材料科學領域非常重要。當研究人員探索新材料時，他們通常對其晶體結構有預期的性能要求。近年來，數據驅動的方法在晶體結構生成的晶面方向取得了很大進展，但仍然缺乏能夠有效將材料屬性映射到晶體結構的方法。在本文中，我們提出一個 Crystal DiT 模型，通過嵌入材料屬性並結合大型語言模型預測的對稱性信息，從預期的材料屬性生成晶體結構。實驗驗證表明，我們提出的方法具有良好的性能。

##### **Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach**
2411.08463v1 by Fadi Al Machot, Martin Thomas Horsch, Habib Ullah

This paper presents a hybrid methodology that enhances the training process
of deep learning (DL) models by embedding domain expert knowledge using
ontologies and answer set programming (ASP). By integrating these symbolic AI
methods, we encode domain-specific constraints, rules, and logical reasoning
directly into the model's learning process, thereby improving both performance
and trustworthiness. The proposed approach is flexible and applicable to both
regression and classification tasks, demonstrating generalizability across
various fields such as healthcare, autonomous systems, engineering, and battery
manufacturing applications. Unlike other state-of-the-art methods, the strength
of our approach lies in its scalability across different domains. The design
allows for the automation of the loss function by simply updating the ASP
rules, making the system highly scalable and user-friendly. This facilitates
seamless adaptation to new domains without significant redesign, offering a
practical solution for integrating expert knowledge into DL models in
industrial settings such as battery manufacturing.

摘要：本文提出一個混合方法，透過使用本體論和答案設定程式 (ASP) 來嵌入領域專家知識，以增強深度學習 (DL) 模型的訓練過程。透過整合這些符號式 AI 方法，我們將特定領域的限制、規則和邏輯推理直接編碼到模型的學習過程中，從而同時改善效能和可信度。所提出的方法靈活，且適用於迴歸和分類任務，證明了在醫療保健、自主系統、工程和電池製造應用等各種領域中的一般化能力。與其他最先進的方法不同，我們的方法優勢在於它在不同領域中的可擴充性。此設計允許透過簡單更新 ASP 規則來自動化損失函數，使系統高度可擴充且使用者友善。這有助於在不大幅度重新設計的情況下無縫適應新領域，為在工業環境（例如電池製造）中將專家知識整合到 DL 模型中提供一個實用的解決方案。

##### **Trap-MID: Trapdoor-based Defense against Model Inversion Attacks**
2411.08460v1 by Zhen-Ting Liu, Shang-Tse Chen

Model Inversion (MI) attacks pose a significant threat to the privacy of Deep
Neural Networks by recovering training data distribution from well-trained
models. While existing defenses often rely on regularization techniques to
reduce information leakage, they remain vulnerable to recent attacks. In this
paper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to
mislead MI attacks. A trapdoor is integrated into the model to predict a
specific label when the input is injected with the corresponding trigger.
Consequently, this trapdoor information serves as the "shortcut" for MI
attacks, leading them to extract trapdoor triggers rather than private data. We
provide theoretical insights into the impacts of trapdoor's effectiveness and
naturalness on deceiving MI attacks. In addition, empirical experiments
demonstrate the state-of-the-art defense performance of Trap-MID against
various MI attacks without the requirements for extra data or large
computational overhead. Our source code is publicly available at
https://github.com/ntuaislab/Trap-MID.

摘要：模型反演 (MI) 攻擊對深度神經網路的隱私構成重大威脅，因為它可以從訓練良好的模型中恢復訓練資料的分布。雖然現有的防禦措施通常依賴正則化技術來減少資訊外洩，但它們仍然容易受到最近的攻擊。在本文中，我們提出了基於活板門的模型反演防禦 (Trap-MID) 來誤導 MI 攻擊。一個活板門被整合到模型中，以便在輸入注入對應的觸發器時預測一個特定的標籤。因此，這個活板門資訊作為 MI 攻擊的「捷徑」，導致它們提取活板門觸發器而不是私人資料。我們提供了關於活板門的有效性和自然性對欺騙 MI 攻擊的影響的理論見解。此外，實證實驗證明了 Trap-MID 在沒有額外資料或大量運算開銷的要求下，對抗各種 MI 攻擊的最新防禦效能。我們的原始碼公開於 https://github.com/ntuaislab/Trap-MID。

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v1 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

摘要：大型語言模型 (LLM) 正在革新生成式人工智能 (GenAI) 的格局，創新的 LLM 支持解決方案迅速湧現。然而，當應用於資料庫技術，特別是圖形資料庫和知識圖譜 (KG) 的查詢生成時，LLM 仍面臨重大挑戰。雖然存在針對結構化查詢語言 (SQL) 的 LLM 驅動查詢生成的相關研究，但圖形資料庫的類似系統仍未得到充分發展。本文提出了一項比較研究，以解決使用開放式 LLM 生成 Cypher 查詢的挑戰，Cypher 查詢是一種與圖形資料庫互動的強大語言。我們使用設計的少次學習提示和由思考鏈 (CoT) 推理支持的檢索擴增生成 (RAG) 嚴格評估了多個 LLM 代理（OpenAI ChatGPT 4o、Claude Sonnet 3.5、Google Gemini Pro 1.5 和本地部署的 Llama 3.1 8B）。我們對查詢生成準確性的實證分析表明，Claude Sonnet 3.5 在這個特定領域優於其他模型。此外，我們重點介紹了有希望的未來研究方向，以解決已識別的限制並推進 LLM 驅動的圖形資料庫查詢生成。

##### **Learning Dynamic Cognitive Map with Autonomous Navigation**
2411.08447v1 by Daria de Tinguy, Tim Verbelen, Bart Dhoedt

Inspired by animal navigation strategies, we introduce a novel computational
model to navigate and map a space rooted in biologically inspired principles.
Animals exhibit extraordinary navigation prowess, harnessing memory,
imagination, and strategic decision-making to traverse complex and aliased
environments adeptly. Our model aims to replicate these capabilities by
incorporating a dynamically expanding cognitive map over predicted poses within
an Active Inference framework, enhancing our agent's generative model
plasticity to novelty and environmental changes. Through structure learning and
active inference navigation, our model demonstrates efficient exploration and
exploitation, dynamically expanding its model capacity in response to
anticipated novel un-visited locations and updating the map given new evidence
contradicting previous beliefs. Comparative analyses in mini-grid environments
with the Clone-Structured Cognitive Graph model (CSCG), which shares similar
objectives, highlight our model's ability to rapidly learn environmental
structures within a single episode, with minimal navigation overlap. Our model
achieves this without prior knowledge of observation and world dimensions,
underscoring its robustness and efficacy in navigating intricate environments.

摘要：受動物導航策略的啟發，我們引進了一個新穎的運算模型，以導航和繪製一個植根於生物靈感原則的空間。動物展現出非凡的導航能力，利用記憶、想像力和策略決策來靈巧地穿越複雜和別名的環境。我們的模型旨在透過在主動推理框架中納入一個動態擴展的認知地圖，在預測的姿勢上複製這些能力，增強我們代理的生成模型對新奇事物和環境變化的可塑性。透過結構學習和主動推理導航，我們的模型展示了有效的探索和利用，動態擴展其模型容量以響應預期的未拜訪新地點，並根據與先前信念相矛盾的新證據更新地圖。在與具有類似目標的 Clone-Structured Cognitive Graph 模型 (CSCG) 的迷你網格環境中進行比較分析，突顯了我們的模型在單一情節中快速學習環境結構的能力，導航重疊最少。我們的模型在沒有事先了解觀察和世界維度的知識下實現了這一點，強調了它在導航複雜環境中的穩健性和有效性。

##### **Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data**
2411.08438v1 by Anum Afzal, Juraj Vladika, Gentrit Fazlija, Andrei Staradubets, Florian Matthes

Given the growing trend of many organizations integrating Retrieval Augmented
Generation (RAG) into their operations, we assess RAG on domain-specific data
and test state-of-the-art models across various optimization techniques. We
incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble
Retriever, and In-Context-Learning, to enhance the functionality and
performance in the academic domain. We focus on data retrieval, specifically
targeting various study programs at a large technical university. We
additionally introduce a novel evaluation approach, the RAG Confusion Matrix
designed to assess the effectiveness of various configurations within the RAG
framework. By exploring the integration of both open-source (e.g., Llama2,
Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer
valuable insights into the application and optimization of RAG frameworks in
domain-specific contexts. Our experiments show a significant performance
increase when including multi-query in the retrieval phase.

摘要：鉴于许多组织将检索增强生成 (RAG) 集成到其运营中的趋势不断增长，我们在特定领域的资料上评估 RAG，并跨各种优化技术测试最先进的模型。我们结合了四项优化：多查询、子父检索器、集成检索器和情境内学习，以增强学术领域的实用性和性能。我们专注于数据检索，特别是针对大型技术大学的各种学习计划。我们还引入了一种新颖的评估方法，即 RAG 混淆矩阵，旨在评估 RAG 框架内各种配置的有效性。通过探索开源（例如，Llama2、Mistral）和闭源（GPT-3.5 和 GPT-4）大型语言模型的集成，我们提供了有关在特定领域上下文中应用和优化 RAG 框架的宝贵见解。我们的实验表明，在检索阶段加入多查询时，性能显著提升。

##### **3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter**
2411.08433v1 by Xiaoxiang Wang, Jiaxin Liu, Miaojie Feng, Zhaoxing Zhang, Xin Yang

3D Multi-Object Tracking (MOT), a fundamental component of environmental
perception, is essential for intelligent systems like autonomous driving and
robotic sensing. Although Tracking-by-Detection frameworks have demonstrated
excellent performance in recent years, their application in real-world
scenarios faces significant challenges. Object movement in complex environments
is often highly nonlinear, while existing methods typically rely on linear
approximations of motion. Furthermore, system noise is frequently modeled as a
Gaussian distribution, which fails to capture the true complexity of the noise
dynamics. These oversimplified modeling assumptions can lead to significant
reductions in tracking precision. To address this, we propose a GRU-based MOT
method, which introduces a learnable Kalman filter into the motion module. This
approach is able to learn object motion characteristics through data-driven
learning, thereby avoiding the need for manual model design and model error. At
the same time, to avoid abnormal supervision caused by the wrong association
between annotations and trajectories, we design a semi-supervised learning
strategy to accelerate the convergence speed and improve the robustness of the
model. Evaluation experiment on the nuScenes and Argoverse2 datasets
demonstrates that our system exhibits superior performance and significant
potential compared to traditional TBD methods.

摘要：3D 多目標追蹤 (MOT) 是環境感知的基本組成部分，對於自動駕駛和機器人感測等智慧系統至關重要。儘管近幾年追蹤偵測架構已展現出色的效能，但在現實世界場景中的應用仍面臨重大挑戰。複雜環境中的物體移動通常高度非線性，而現有方法通常依賴線性運動近似值。此外，系統雜訊經常被建模為高斯分布，無法捕捉雜訊動態的真實複雜性。這些過度簡化的建模假設可能會導致追蹤精確度大幅降低。為了解決這個問題，我們提出一個基於 GRU 的 MOT 方法，在運動模組中引入可學習的卡爾曼濾波器。此方法能夠透過資料驅動學習來學習物體運動特性，從而避免手動模型設計和模型誤差的需要。同時，為了避免錯誤關聯註解和軌跡所造成的異常監督，我們設計了一個半監督學習策略來加速收斂速度並提高模型的穩健性。在 nuScenes 和 Argoverse2 資料集上的評估實驗表明，與傳統 TBD 方法相比，我們的系統展現出優異的效能和顯著的潛力。

##### **One STEP at a time: Language Agents are Stepwise Planners**
2411.08432v1 by Minh Nguyen, Ehsan Shareghi

Language agents have shown promising adaptability in dynamic environments to
perform complex tasks. However, despite the versatile knowledge embedded in
large language models, these agents still fall short when it comes to tasks
that require planning. We introduce STEP, a novel framework designed to
efficiently learn from previous experiences to enhance the planning
capabilities of language agents in future steps. Concretely, STEP functions
through four interconnected components. First, the Planner takes on the task,
breaks it down into subtasks and provides relevant insights. Then the Executor
generates action candidates, while the Evaluator ensures the actions align with
learned rules from previous experiences. Lastly, Memory stores experiences to
inform future decisions. In the ScienceWorld benchmark, our results show that
STEP consistently outperforms state-of-the-art models, achieving an overall
score of 67.4 and successfully completing 12 out of 18 tasks. These findings
highlight STEP's potential as a framework for enhancing planning capabilities
in language agents, paving the way for more sophisticated task-solving in
dynamic environments.

摘要：語言代理已在動態環境中展現出良好的適應性，可執行複雜的任務。然而，儘管大型語言模型中嵌入了多樣化的知識，但這些代理在需要規劃的任務中仍然表現不佳。我們介紹 STEP，這是一個新穎的框架，旨在有效地從先前的經驗中學習，以增強語言代理在後續步驟中的規劃能力。具體來說，STEP 透過四個相互連接的元件運作。首先，規劃器承擔任務，將任務分解成子任務，並提供相關見解。然後，執行器產生動作候選，而評估器確保動作與先前經驗中學到的規則一致。最後，記憶體儲存經驗，以提供資訊做為未來的決策依據。在 ScienceWorld 基準測試中，我們的結果顯示 STEP 持續優於最先進的模型，達到 67.4 的總分，並成功完成 18 項任務中的 12 項。這些發現突顯了 STEP 作為增強語言代理規劃能力的框架的潛力，為在動態環境中解決更複雜的任務鋪路。

##### **Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models**
2411.08418v1 by Yun Long, Yu Zhang

Classroom dialogue plays a crucial role in fostering student engagement and
deeper learning. However, analysing dialogue sequences has traditionally relied
on either theoretical frameworks or empirical descriptions of practice, with
limited integration between the two. This study addresses this gap by
developing a comprehensive rule base of dialogue sequences and an Artificial
Intelligence (AI) agent that combines expert-informed rule-based systems with a
large language model (LLM). The agent applies expert knowledge while adapting
to the complexities of natural language, enabling accurate and flexible
categorisation of classroom dialogue sequences. By synthesising findings from
over 30 studies, we established a comprehensive framework for dialogue
analysis. The agent was validated against human expert coding, achieving high
levels of precision and reliability. The results demonstrate that the agent
provides theory-grounded and adaptive functions, tremendously enhancing the
efficiency and scalability of classroom dialogue analysis, offering significant
potential in improving classroom teaching practices and supporting teacher
professional development.

摘要：課堂對話在促進學生參與和深度學習方面發揮著至關重要的作用。然而，對話序列的分析傳統上依賴於理論框架或實踐的經驗描述，兩者之間的整合有限。本研究通過開發對話序列的綜合規則庫和一個將專家知識規則系統與大型語言模型 (LLM) 相結合的人工智慧 (AI) 代理來解決這一差距。該代理在適應自然語言的複雜性的同時應用專家知識，從而能夠對課堂對話序列進行準確而靈活的分類。通過綜合來自 30 多項研究的發現，我們建立了一個用於對話分析的綜合框架。該代理經過與人類專家編碼的驗證，達到了很高的準確性和可靠性。結果表明，該代理提供了理論依據和適應性功能，極大地提高了課堂對話分析的效率和可擴展性，在改進課堂教學實踐和支持教師專業發展方面具有顯著的潛力。

##### **Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning**
2411.08414v1 by Chao Huang, Chunyan Chen, Ling Shi, Chen Chen

Machine learning has become a crucial tool for predicting the properties of
crystalline materials. However, existing methods primarily represent material
information by constructing multi-edge graphs of crystal structures, often
overlooking the chemical and physical properties of elements (such as atomic
radius, electronegativity, melting point, and ionization energy), which have a
significant impact on material performance. To address this limitation, we
first constructed an element property knowledge graph and utilized an embedding
model to encode the element attributes within the knowledge graph. Furthermore,
we propose a multimodal fusion framework, ESNet, which integrates element
property features with crystal structure features to generate joint multimodal
representations. This provides a more comprehensive perspective for predicting
the performance of crystalline materials, enabling the model to consider both
microstructural composition and chemical characteristics of the materials. We
conducted experiments on the Materials Project benchmark dataset, which showed
leading performance in the bandgap prediction task and achieved results on a
par with existing benchmarks in the formation energy prediction task.

摘要：機器學習已成為預測結晶材料特性的關鍵工具。然而，現有方法主要透過建立晶體結構的多邊圖來表示材料資訊，常常忽略元素的化學和物理特性（例如原子半徑、電負性、熔點和電離能），而這些特性對材料效能有顯著影響。為了解決這個限制，我們首先建構了一個元素屬性知識圖譜，並利用嵌入模型對知識圖譜中的元素屬性進行編碼。此外，我們提出了一個多模態融合框架 ESNet，它將元素屬性特徵與晶體結構特徵整合起來，以產生聯合的多模態表示。這為預測結晶材料的效能提供了更全面的觀點，使模型能夠同時考慮材料的微結構組成和化學特性。我們對 Materials Project 基準資料集進行了實驗，結果顯示在能隙預測任務中表現出色，並且在形成能預測任務中取得了與現有基準相當的結果。

##### **DiVR: incorporating context from diverse VR scenes for human trajectory prediction**
2411.08409v1 by Franz Franco Gallo, Hui-Yin Wu, Lucile Sassatelli

Virtual environments provide a rich and controlled setting for collecting
detailed data on human behavior, offering unique opportunities for predicting
human trajectories in dynamic scenes. However, most existing approaches have
overlooked the potential of these environments, focusing instead on static
contexts without considering userspecific factors. Employing the CREATTIVE3D
dataset, our work models trajectories recorded in virtual reality (VR) scenes
for diverse situations including road-crossing tasks with user interactions and
simulated visual impairments. We propose Diverse Context VR Human Motion
Prediction (DiVR), a cross-modal transformer based on the Perceiver
architecture that integrates both static and dynamic scene context using a
heterogeneous graph convolution network. We conduct extensive experiments
comparing DiVR against existing architectures including MLP, LSTM, and
transformers with gaze and point cloud context. Additionally, we also stress
test our model's generalizability across different users, tasks, and scenes.
Results show that DiVR achieves higher accuracy and adaptability compared to
other models and to static graphs. This work highlights the advantages of using
VR datasets for context-aware human trajectory modeling, with potential
applications in enhancing user experiences in the metaverse. Our source code is
publicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.

摘要：虛擬環境提供了一個豐富且受控的設定，用於收集人類行為的詳細資料，為預測動態場景中的人類軌跡提供獨特的機會。然而，現有的方法大多忽略了這些環境的潛力，而是專注於靜態情境，而不考慮使用者特定的因素。透過使用 CREATTIVE3D 資料集，我們的模型會針對虛擬實境 (VR) 場景中記錄的軌跡進行建模，適用於各種情況，包括與使用者互動的道路穿越任務和模擬視覺障礙。我們提出多元情境 VR 人類動作預測 (DiVR)，這是一種基於感知器架構的跨模態轉換器，使用異質圖形捲積網路整合靜態和動態場景情境。我們進行了廣泛的實驗，將 DiVR 與現有的架構進行比較，包括 MLP、LSTM 和具有視線和點雲情境的轉換器。此外，我們還強調測試了我們的模型在不同使用者、任務和場景中的泛化性。結果顯示，與其他模型和靜態圖形相比，DiVR 達到了更高的準確度和適應性。這項工作突顯了使用 VR 資料集進行情境感知人類軌跡建模的優點，在增強元宇宙中的使用者體驗方面具有潛在應用。我們的原始程式碼可在 https://gitlab.inria.fr/ffrancog/creattive3d-divr-model 公開取得。

##### **CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision**
2411.08397v1 by Aoi Ito, Kota Dohi, Yohei Kawaguchi

This paper proposes a foundation model called "CLaSP" that can search time
series signals using natural language that describes the characteristics of the
signals as queries. Previous efforts to represent time series signal data in
natural language have had challenges in designing a conventional class of time
series signal characteristics, formulating their quantification, and creating a
dictionary of synonyms. To overcome these limitations, the proposed method
introduces a neural network based on contrastive learning. This network is
first trained using the datasets TRUCE and SUSHI, which consist of time series
signals and their corresponding natural language descriptions. Previous studies
have proposed vocabularies that data analysts use to describe signal
characteristics, and SUSHI was designed to cover these terms. We believe that a
neural network trained on these datasets will enable data analysts to search
using natural language vocabulary. Furthermore, our method does not require a
dictionary of predefined synonyms, and it leverages common sense knowledge
embedded in a large-scale language model (LLM). Experimental results
demonstrate that CLaSP enables natural language search of time series signal
data and can accurately learn the points at which signal data changes.

摘要：本文提出一個名為「CLaSP」的基礎模型，它可以使用描述訊號特徵的自然語言來搜尋時間序列訊號，作為查詢。先前將時間序列訊號資料表示為自然語言的嘗試，在設計時間序列訊號特徵的傳統分類、制定其量化方法，以及建立同義詞詞典方面面臨挑戰。為了克服這些限制，所提出的方法引入了一個基於對比學習的神經網路。此網路首先使用包含時間序列訊號及其對應自然語言描述的資料集 TRUCE 和 SUSHI 進行訓練。先前的研究提出了資料分析師用來描述訊號特徵的詞彙，而 SUSHI 則旨在涵蓋這些術語。我們相信在這些資料集上訓練的神經網路將使資料分析師能夠使用自然語言詞彙進行搜尋。此外，我們的方法不需要預先定義的同義詞詞典，它利用嵌入在大規模語言模型 (LLM) 中的常識知識。實驗結果證明，CLaSP 能夠對時間序列訊號資料進行自然語言搜尋，並能準確地找出訊號資料變化的點。

##### **RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm**
2411.08392v1 by Geetansh Kalra, Divye Singh, Justin Jose

Reinforcement Learning (RL) is a rapidly growing area of machine learning
that finds its application in a broad range of domains, from finance and
healthcare to robotics and gaming. Compared to other machine learning
techniques, RL agents learn from their own experiences using trial and error,
and improve their performance over time. However, assessing RL models can be
challenging, which makes it difficult to interpret their behaviour. While
reward is a widely used metric to evaluate RL models, it may not always provide
an accurate measure of training performance. In some cases, the reward may seem
increasing while the model's performance is actually decreasing, leading to
misleading conclusions about the effectiveness of the training. To overcome
this limitation, we have developed RLInspect - an interactive visual analytic
tool, that takes into account different components of the RL model - state,
action, agent architecture and reward, and provides a more comprehensive view
of the RL training. By using RLInspect, users can gain insights into the
model's behaviour, identify issues during training, and potentially correct
them effectively, leading to a more robust and reliable RL system.

摘要：強化學習 (RL) 是機器學習快速成長的領域，在廣泛的領域中找到應用，從金融、醫療保健到機器人和遊戲。與其他機器學習技術相比，RL 代理從自己的經驗中透過嘗試和錯誤學習，並隨著時間推移改善其效能。然而，評估 RL 模型可能具有挑戰性，這使得難以解釋其行為。雖然獎勵是廣泛用於評估 RL 模型的指標，但它可能並不總是提供訓練效能的準確衡量標準。在某些情況下，獎勵可能看似增加，而模型的效能實際上正在下降，導致對訓練有效性的誤導性結論。為了克服這個限制，我們開發了 RLInspect，這是一個互動式視覺分析工具，它考慮了 RL 模型的不同組成部分，例如狀態、動作、代理架構和獎勵，並提供了 RL 訓練的更全面檢視。透過使用 RLInspect，使用者可以深入了解模型的行為，在訓練期間找出問題，並可能有效地修正它們，從而建立更強大且可靠的 RL 系統。

##### **Physics Informed Distillation for Diffusion Models**
2411.08378v1 by Joshua Tian Jin Tee, Kang Zhang, Hee Suk Yoon, Dhananjaya Nagaraja Gowda, Chanwoo Kim, Chang D. Yoo

Diffusion models have recently emerged as a potent tool in generative
modeling. However, their inherent iterative nature often results in sluggish
image generation due to the requirement for multiple model evaluations. Recent
progress has unveiled the intrinsic link between diffusion models and
Probability Flow Ordinary Differential Equations (ODEs), thus enabling us to
conceptualize diffusion models as ODE systems. Simultaneously, Physics Informed
Neural Networks (PINNs) have substantiated their effectiveness in solving
intricate differential equations through implicit modeling of their solutions.
Building upon these foundational insights, we introduce Physics Informed
Distillation (PID), which employs a student model to represent the solution of
the ODE system corresponding to the teacher diffusion model, akin to the
principles employed in PINNs. Through experiments on CIFAR 10 and ImageNet
64x64, we observe that PID achieves performance comparable to recent
distillation methods. Notably, it demonstrates predictable trends concerning
method-specific hyperparameters and eliminates the need for synthetic dataset
generation during the distillation process. Both of which contribute to its
easy-to-use nature as a distillation approach for Diffusion Models. Our code
and pre-trained checkpoint are publicly available at:
https://github.com/pantheon5100/pid_diffusion.git.

摘要：擴散模型最近已成為生成模型中強而有力的工具。然而，它們固有的迭代特性通常會因為需要進行多重模型評估而導致緩慢的影像產生。最近的進展揭示了擴散模型與機率流常微分方程式 (ODE) 之間的內在關聯，因此使我們能將擴散模型概念化為 ODE 系統。同時，物理資訊神經網路 (PINN) 已證實其透過隱式建模其解來解決複雜微分方程式的有效性。奠基於這些基礎見解，我們引入了物理資訊蒸餾 (PID)，它採用一個學生模型來表示與教師擴散模型對應的 ODE 系統的解，類似於 PINN 中所採用的原理。透過在 CIFAR 10 和 ImageNet 64x64 上進行的實驗，我們觀察到 PID 達到了與最近的蒸餾方法相當的效能。值得注意的是，它展示了關於特定於方法的超參數的可預測趨勢，並消除了在蒸餾過程中對合成資料集產生的需求。這兩者都有助於它作為擴散模型的蒸餾方法易於使用的特性。我們的程式碼和預訓練檢查點可在以下網址公開取得：https://github.com/pantheon5100/pid_diffusion.git。

##### **Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems**
2411.08375v1 by Rawad Melhem, Assef Jafar, Oumayma Al Dakkak

This paper addresses the challenge of speaker separation, which remains an
active research topic despite the promising results achieved in recent years.
These results, however, often degrade in real recording conditions due to the
presence of noise, echo, and other interferences. This is because neural models
are typically trained on synthetic datasets consisting of mixed audio signals
and their corresponding ground truths, which are generated using computer
software and do not fully represent the complexities of real-world recording
scenarios. The lack of realistic training sets for speaker separation remains a
major hurdle, as obtaining individual sounds from mixed audio signals is a
nontrivial task. To address this issue, we propose a novel method for
constructing a realistic training set that includes mixture signals and
corresponding ground truths for each speaker. We evaluate this dataset on a
deep learning model and compare it to a synthetic dataset. We got a 1.65 dB
improvement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker
separation accuracy in realistic mixing. Our findings highlight the potential
of realistic training sets for enhancing the performance of speaker separation
models in real-world scenarios.

摘要：本文探讨了说话者分离的挑战，儘管近年取得了有希望的结果，它仍然是一个活跃的研究课题。然而，这些结果在实际录音条件下常常会因噪音、回音和其他干扰而降低。这是因为神经模型通常在由混合音频信号及其对应地面实况组成的合成数据集上进行训练，这些信号和地面实况是使用计算机软件生成的，并且不能完全代表现实世界录音场景的复杂性。缺乏用于说话者分离的真实训练集仍然是一个主要障碍，因为从混合音频信号中获取各个声音是一项非平凡的任务。为了解决这个问题，我们提出了一种新颖的方法来构建一个真实的训练集，其中包括混合信号和每个说话者的对应地面实况。我们在深度学习模型上评估了这个数据集，并将其与合成数据集进行了比较。在真实的混合中，我们在说话者分离准确性的尺度不变信号失真比（SI-SDR）中获得了 1.65 dB 的改进。我们的研究结果突出了真实训练集在增强说话者分离模型在现实世界场景中的性能方面的潜力。

##### **A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**
2411.08370v1 by Siwei Li, Jiayan Fang, Yichun Wua, Wei Wang, Chengxin Li, Jiangwen Chen

Early fault detection and timely maintenance scheduling can significantly
mitigate operational risks in NPPs and enhance the reliability of operator
decision-making. Therefore, it is necessary to develop an efficient Prognostics
and Health Management (PHM) multi-step prediction model for predicting of
system health status and prompt execution of maintenance operations. In this
study, we propose a novel predictive model that integrates reinforcement
learning with Long Short-Term Memory (LSTM) neural networks and the Expert
Fuzzy Evaluation Method. The model is validated using parameter data for 20
different breach sizes in the Main Steam Line Break (MSLB) accident condition
of the CPR1000 pressurized water reactor simulation model and it demonstrates a
remarkable capability in accurately forecasting NPP parameter changes up to 128
steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),
thereby satisfying the temporal advance requirement for fault prognostics in
NPPs. Furthermore, this method provides an effective reference solution for PHM
applications such as anomaly detection and remaining useful life prediction.

摘要：早期故障偵測和及時維護排程可以顯著降低核能電廠的營運風險，並提升操作人員決策的可靠性。因此，有必要開發一個高效的預測與健康管理 (PHM) 多步驟預測模型，用於預測系統健康狀態和及時執行維護作業。在此研究中，我們提出一個創新的預測模型，它整合了強化學習與長期短期記憶 (LSTM) 神經網路和專家模糊評估方法。該模型使用 CPR1000 加壓水反應爐模擬模型中主蒸汽管破裂 (MSLB) 事故條件下 20 種不同破裂尺寸的參數資料進行驗證，它展現出準確預測核能電廠參數變化長達 128 個步驟（每個步驟的時間間隔為 10 秒，即 1280 秒）的卓越能力，從而滿足核能電廠故障預測的時間提前需求。此外，此方法為異常偵測和剩餘使用壽命預測等 PHM 應用提供了一個有效的參考解決方案。

##### **Surprisingly Popular Voting for Concentric Rank-Order Models**
2411.08367v1 by Hadi Hosseini, Debmalya Mandal, Amrit Puhan

An important problem on social information sites is the recovery of ground
truth from individual reports when the experts are in the minority. The wisdom
of the crowd, i.e. the collective opinion of a group of individuals fails in
such a scenario. However, the surprisingly popular (SP)
algorithm~\cite{prelec2017solution} can recover the ground truth even when the
experts are in the minority, by asking the individuals to report additional
prediction reports--their beliefs about the reports of others. Several recent
works have extended the surprisingly popular algorithm to an equivalent voting
rule (SP-voting) to recover the ground truth ranking over a set of $m$
alternatives. However, we are yet to fully understand when SP-voting can
recover the ground truth ranking, and if so, how many samples (votes and
predictions) it needs. We answer this question by proposing two rank-order
models and analyzing the sample complexity of SP-voting under these models. In
particular, we propose concentric mixtures of Mallows and Plackett-Luce models
with $G (\ge 2)$ groups. Our models generalize previously proposed concentric
mixtures of Mallows models with $2$ groups, and we highlight the importance of
$G > 2$ groups by identifying three distinct groups (expert, intermediate, and
non-expert) from existing datasets. Next, we provide conditions on the
parameters of the underlying models so that SP-voting can recover ground-truth
rankings with high probability, and also derive sample complexities under the
same. We complement the theoretical results by evaluating SP-voting on
simulated and real datasets.

摘要：<paragraph>在社交資訊網站上，一個重要問題是在專家為少數時，如何從個別報告中恢復基本事實。群眾的智慧，也就是一群個人的集體意見，在這種情況下會失效。然而，令人驚訝地流行的 (SP) 演算法~\cite{prelec2017solution} 即使在專家為少數時，也能透過要求個人回報其他預測報告，也就是他們對他人報告的看法，來恢復基本事實。最近有許多研究將令人驚訝地流行的演算法擴充到等值的投票規則 (SP-voting)，以恢復一組 $m$ 個替代方案的基本事實排名。然而，我們尚未完全了解 SP-voting 何時可以恢復基本事實排名，如果可以，需要多少樣本（投票和預測）。我們透過提出兩個等級順序模型，並分析在這些模型下 SP-voting 的樣本複雜度，來回答這個問題。特別是，我們提出馬洛斯和普拉契特-魯斯模型的同心混合，其中有 $G (\ge 2)$ 個群組。我們的模型概括了先前提出的具有 $2$ 個群組的馬洛斯模型的同心混合，並且透過從現有資料集中找出三個不同的群組（專家、中級和非專家），強調了 $G > 2$ 個群組的重要性。接下來，我們提供底層模型參數的條件，以便 SP-voting 可以高機率恢復基本事實排名，並在相同條件下推導出樣本複雜度。我們透過評估模擬和真實資料集上的 SP-voting 來補充理論結果。</paragraph>

##### **Refining Translations with LLMs: A Constraint-Aware Iterative Prompting Approach**
2411.08348v1 by Shangfeng Chen, Xiayang Shi, Pu Li, Yinlin Li, Jingjing Liu

Large language models (LLMs) have demonstrated remarkable proficiency in
machine translation (MT), even without specific training on the languages in
question. However, translating rare words in low-resource or domain-specific
contexts remains challenging for LLMs. To address this issue, we propose a
multi-step prompt chain that enhances translation faithfulness by prioritizing
key terms crucial for semantic accuracy. Our method first identifies these
keywords and retrieves their translations from a bilingual dictionary,
integrating them into the LLM's context using Retrieval-Augmented Generation
(RAG). We further mitigate potential output hallucinations caused by long
prompts through an iterative self-checking mechanism, where the LLM refines its
translations based on lexical and semantic constraints. Experiments using Llama
and Qwen as base models on the FLORES-200 and WMT datasets demonstrate
significant improvements over baselines, highlighting the effectiveness of our
approach in enhancing translation faithfulness and robustness, particularly in
low-resource scenarios.

摘要：大型語言模型 (LLM) 已展現出在機器翻譯 (MT) 方面的卓越能力，即使沒有針對特定語言進行特定訓練。然而，在低資源或特定領域的語境中翻譯罕見字詞對 LLM 來說仍然具有挑戰性。為了解決這個問題，我們提出了一個多步驟提示鏈，透過優先考慮對語意準確性至關重要的關鍵術語，來增強翻譯的忠實度。我們的做法首先識別這些關鍵字，並從雙語詞典中擷取其翻譯，使用檢索增強生成 (RAG) 將它們整合到 LLM 的語境中。我們進一步透過一個反覆自我檢查機制，來減輕長提示所造成的潛在輸出幻覺，其中 LLM 會根據詞彙和語義約束來調整其翻譯。使用 Llama 和 Qwen 作為基礎模型，在 FLORES-200 和 WMT 資料集上的實驗證明了與基準相比有顯著的改進，突顯了我們的方法在增強翻譯忠實度和穩健性方面的有效性，特別是在低資源場景中。

##### **A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users**
2411.08347v1 by Jingyi Zhou, Senlin Luo, Haofan Chen

Emotion and personality are central elements in understanding human
psychological states. Emotions reflect an individual subjective experiences,
while personality reveals relatively stable behavioral and cognitive patterns.
Existing affective computing datasets often annotate emotion and personality
traits separately, lacking fine-grained labeling of micro-emotions and emotion
intensity in both single-label and multi-label classifications. Chinese emotion
datasets are extremely scarce, and datasets capturing Chinese user personality
traits are even more limited. To address these gaps, this study collected data
from the major social media platform Weibo, screening 11,338 valid users from
over 50,000 individuals with diverse MBTI personality labels and acquiring
566,900 posts along with the user MBTI personality tags. Using the EQN method,
we compiled a multi-label Chinese affective computing dataset that integrates
the same user's personality traits with six emotions and micro-emotions, each
annotated with intensity levels. Validation results across multiple NLP
classification models demonstrate the dataset strong utility. This dataset is
designed to advance machine recognition of complex human emotions and provide
data support for research in psychology, education, marketing, finance, and
politics.

摘要：情感和人格是理解人類心理狀態的核心元素。情感反映了一個體的主觀體驗，而人格揭示了相對穩定的行為和認知模式。現有的情感計算數據集通常單獨註釋情感和人格特質，缺乏對微觀情感和情感強度的細粒度標註，無論是在單標籤還是多標籤分類中。中文情感數據集極為稀缺，而捕捉中文用戶人格特質的數據集更是少之又少。為了彌補這些差距，本研究從主流社交媒體平台微博收集數據，從 50,000 多名具有不同 MBTI 人格標籤的個體中篩選出 11,338 名有效用戶，並獲取 566,900 篇帖子以及用戶 MBTI 人格標籤。使用 EQN 方法，我們編制了一個多標籤中文情感計算數據集，將同一用戶的人格特質與六種情緒和微觀情緒相整合，每個情緒都註釋了強度級別。跨多個 NLP 分類模型的驗證結果證明了該數據集的強大效用。此數據集旨在推進對複雜人類情感的機器識別，並為心理學、教育、市場行銷、金融和政治等領域的研究提供數據支持。

##### **Bangla Grammatical Error Detection Leveraging Transformer-based Token Classification**
2411.08344v1 by Shayekh Bin Islam, Ridwanul Hasan Tanvir, Sihat Afnan

Bangla is the seventh most spoken language by a total number of speakers in
the world, and yet the development of an automated grammar checker in this
language is an understudied problem. Bangla grammatical error detection is a
task of detecting sub-strings of a Bangla text that contain grammatical,
punctuation, or spelling errors, which is crucial for developing an automated
Bangla typing assistant. Our approach involves breaking down the task as a
token classification problem and utilizing state-of-the-art transformer-based
models. Finally, we combine the output of these models and apply rule-based
post-processing to generate a more reliable and comprehensive result. Our
system is evaluated on a dataset consisting of over 25,000 texts from various
sources. Our best model achieves a Levenshtein distance score of 1.04. Finally,
we provide a detailed analysis of different components of our system.

摘要：孟加拉語是全球第七大語言，但自動文法檢查器的開發在該語言中仍是一個研究不足的問題。孟加拉語文法錯誤偵測是一項任務，用於偵測孟加拉語文本中包含文法、標點符號或拼寫錯誤的子字串，這對於開發自動化孟加拉語輸入助理至關重要。我們的做法包括將任務分解為一個標記分類問題，並利用最先進的基於轉換器的模型。最後，我們結合這些模型的輸出並套用基於規則的後處理，以產生更可靠且全面的結果。我們的系統根據來自各種來源的 25,000 多個文本組成的資料集進行評估。我們最好的模型達到 Levenshtein 距離分數 1.04。最後，我們對系統的不同組成部分進行了詳細分析。

##### **Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study**
2411.08341v1 by Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Jiacheng Wang, Biplab Sikdar, Ping Zhang

Data augmentation is a powerful technique to mitigate data scarcity. However,
owing to fundamental differences in wireless data structures, traditional data
augmentation techniques may not be suitable for wireless data. Fortunately,
Generative Artificial Intelligence (GenAI) can be an effective alternative to
wireless data augmentation due to its excellent data generation capability.
This article systemically explores the potential and effectiveness of
GenAI-driven data augmentation in wireless networks. We first briefly review
data augmentation techniques, discuss their limitations in wireless networks,
and introduce generative data augmentation, including reviewing GenAI models
and their applications in data augmentation. We then explore the application
prospects of GenAI-driven data augmentation in wireless networks from the
physical, network, and application layers, which provides a GenAI-driven data
augmentation architecture for each application. Subsequently, we propose a
general generative diffusion model-based data augmentation framework for Wi-Fi
gesture recognition, which uses transformer-based diffusion models to generate
high-quality channel state information data. Furthermore, we develop residual
neural network models for Wi-Fi gesture recognition to evaluate the role of
augmented data and conduct a case study based on a real dataset. Simulation
results demonstrate the effectiveness of the proposed framework. Finally, we
discuss research directions for generative data augmentation.

摘要：資料擴充是一種減輕資料稀少的強大技術。然而，由於無線資料結構的根本差異，傳統的資料擴充技術可能不適合於無線資料。幸運的是，生成式人工智慧 (GenAI) 由於其優異的資料產生能力，可以成為無線資料擴充的有效替代方案。本文系統性地探討了 GenAI 驅動的資料擴充在無線網路中的潛力和有效性。我們首先簡要回顧資料擴充技術，討論它們在無線網路中的限制，並介紹生成式資料擴充，包括回顧 GenAI 模型及其在資料擴充中的應用。然後，我們從物理、網路和應用層面探討 GenAI 驅動的資料擴充在無線網路中的應用前景，這為每個應用提供了 GenAI 驅動的資料擴充架構。隨後，我們針對 Wi-Fi 手勢辨識提出了一個基於生成式擴散模型的資料擴充架構，該架構使用基於轉換器的擴散模型來產生高品質的信道狀態資訊資料。此外，我們開發了殘差神經網路模型進行 Wi-Fi 手勢辨識，以評估擴充資料的作用，並根據真實資料集進行案例研究。模擬結果證明了所提出架構的有效性。最後，我們討論了生成式資料擴充的研究方向。

##### **DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios**
2411.08335v1 by Muttahirul Islam, Nazmul Haque, Md. Hadiuzzaman

This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State
Measurement), a comprehensive framework that leverages state-of-the-art
convolutional neural network (CNN) techniques to accurately and rapidly detect
vehicles and pedestrians, as well as to measure traffic states in challenging
scenarios (i.e., congestion, occlusion). In this study, we enhance the training
dataset through data fusion, enabling simultaneous detection of vehicles and
pedestrians. Image preprocessing and augmentation are subsequently performed to
improve the quality and quantity of the dataset. Transfer learning is applied
on the YOLOv8 pretrained model to increase the model's capability to identify a
diverse array of vehicles. Optimal hyperparameters are obtained using the Grid
Search algorithm, with the Stochastic Gradient Descent (SGD) optimizer
outperforming other optimizers under these settings. Extensive experimentation
and evaluation demonstrate substantial accuracy within the detection framework,
with the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5
on the test set, surpassing previous benchmarks on similar datasets. The
DeepSORT multi-object tracking algorithm is incorporated to track detected
vehicles and pedestrians in this study. Finally, the framework is tested to
measure heterogeneous traffic states in mixed traffic conditions. Two locations
with differing traffic compositions and congestion levels are selected: one
motorized-dominant location with moderate density and one
non-motorized-dominant location with higher density. Errors are statistically
insignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91
to 0.97 for heterogeneous traffic flow and speed measurements, respectively.

摘要：<paragraph>本文提出了 DEEGITS（深度學習異質交通狀態測量），這是一個全面的框架，利用最先進的卷積神經網路 (CNN) 技術準確且快速地偵測車輛和行人，以及測量具有挑戰性的場景（例如擁塞、遮擋）中的交通狀態。在本研究中，我們透過資料融合來增強訓練資料集，同時偵測車輛和行人。隨後執行影像預處理和擴充，以提高資料集的品質和數量。將轉移學習應用於 YOLOv8 預訓練模型，以增加模型識別各種車輛的能力。使用網格搜尋演算法取得最佳超參數，其中隨機梯度下降 (SGD) 優化器在這些設定下優於其他優化器。廣泛的實驗和評估證明了偵測框架中的實質準確性，模型在驗證集上達到 0.794 mAP@0.5，在測試集上達到 0.786 mAP@0.5，超越了類似資料集上的先前基準。本研究中整合了 DeepSORT 多目標追蹤演算法，用於追蹤偵測到的車輛和行人。最後，測試框架以測量混合交通狀況中的異質交通狀態。選擇了兩個交通組成和擁塞程度不同的地點：一個機動車輛佔優的地點，密度中等，另一個非機動車輛佔優的地點，密度較高。在兩種情況下，誤差在統計上都無顯著差異，異質交通流和速度測量的相關性分別為 0.99 到 0.88 和 0.91 到 0.97。</paragraph>

##### **Enhancing Multimodal Query Representation via Visual Dialogues for End-to-End Knowledge Retrieval**
2411.08334v1 by Yeong-Joon Ju, Ho-Joong Kim, Seong-Whan Lee

Existing multimodal retrieval systems often rely on disjointed models for
image comprehension, such as object detectors and caption generators, leading
to cumbersome implementations and training processes. To overcome this
limitation, we propose an end-to-end retrieval system, Ret-XKnow, to endow a
text retriever with the ability to understand multimodal queries via dynamic
modality interaction. Ret-XKnow leverages a partial convolution mechanism to
focus on visual information relevant to the given textual query, thereby
enhancing multimodal query representations. To effectively learn multimodal
interaction, we also introduce the Visual Dialogue-to-Retrieval (ViD2R) dataset
automatically constructed from visual dialogue datasets. Our dataset
construction process ensures that the dialogues are transformed into suitable
information retrieval tasks using a text retriever. We demonstrate that our
approach not only significantly improves retrieval performance in zero-shot
settings but also achieves substantial improvements in fine-tuning scenarios.
Our code is publicly available: https://github.com/yeongjoonJu/Ret_XKnow.

摘要：現有的多模態檢索系統通常依賴於不連貫的模型來理解影像，例如物件偵測器和標題產生器，導致實作和訓練過程繁瑣。為了克服這個限制，我們提出一個端到端的檢索系統 Ret-XKnow，賦予文字檢索器透過動態模態互動來理解多模態查詢的能力。Ret-XKnow 利用部分卷積機制來專注於與給定文字查詢相關的視覺資訊，進而增強多模態查詢表示。為了有效地學習多模態互動，我們還引入了視覺對話到檢索 (ViD2R) 資料集，該資料集是自動從視覺對話資料集中建構的。我們的資料集建構過程可確保對話使用文字檢索器轉換成合適的資訊檢索任務。我們證明我們的做法不僅顯著改善了零次學習設定中的檢索效能，而且在微調場景中也獲得了顯著的改善。我們的程式碼已公開：https://github.com/yeongjoonJu/Ret_XKnow。

##### **Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle**
2411.08324v1 by Hui Dai, Ryan Teehan, Mengye Ren

Many existing evaluation benchmarks for Large Language Models (LLMs) quickly
become outdated due to the emergence of new models and training data. These
benchmarks also fall short in assessing how LLM performance changes over time,
as they consist of static questions without a temporal dimension. To address
these limitations, we propose using future event prediction as a continuous
evaluation method to assess LLMs' temporal generalization and forecasting
abilities. Our benchmark, Daily Oracle, automatically generates question-answer
(QA) pairs from daily news, challenging LLMs to predict "future" event
outcomes. Our findings reveal that as pre-training data becomes outdated, LLM
performance degrades over time. While Retrieval Augmented Generation (RAG) has
the potential to enhance prediction accuracy, the performance degradation
pattern persists, highlighting the need for continuous model updates.

摘要：許多現有的大型語言模型（LLM）評量基準由於新模型和訓練資料的出現，很快就會過時。這些基準在評估 LLM 效能隨著時間推移而產生的變化方面也有所不足，因為它們包含沒有時間維度的靜態問題。為了解決這些限制，我們建議使用未來事件預測作為一種持續評估方法，以評估 LLM 的時間概化和預測能力。我們的基準 Daily Oracle 從每日新聞中自動產生問題解答 (QA) 配對，挑戰 LLM 預測「未來」事件結果。我們的研究結果顯示，隨著預訓練資料過時，LLM 效能會隨著時間推移而下降。儘管檢索擴充生成（RAG）具有增強預測精準度的潛力，但效能下降的模式仍然存在，這突顯了持續模型更新的必要性。

##### **Responsible AI in Construction Safety: Systematic Evaluation of Large Language Models and Prompt Engineering**
2411.08320v1 by Farouq Sammour, Jia Xu, Xi Wang, Mo Hu, Zhenyu Zhang

Construction remains one of the most hazardous sectors. Recent advancements
in AI, particularly Large Language Models (LLMs), offer promising opportunities
for enhancing workplace safety. However, responsible integration of LLMs
requires systematic evaluation, as deploying them without understanding their
capabilities and limitations risks generating inaccurate information, fostering
misplaced confidence, and compromising worker safety. This study evaluates the
performance of two widely used LLMs, GPT-3.5 and GPT-4o, across three
standardized exams administered by the Board of Certified Safety Professionals
(BCSP). Using 385 questions spanning seven safety knowledge areas, the study
analyzes the models' accuracy, consistency, and reliability. Results show that
both models consistently exceed the BCSP benchmark, with GPT-4o achieving an
accuracy rate of 84.6% and GPT-3.5 reaching 73.8%. Both models demonstrate
strengths in safety management systems and hazard identification and control,
but exhibit weaknesses in science, mathematics, emergency response, and fire
prevention. An error analysis identifies four primary limitations affecting LLM
performance: lack of knowledge, reasoning flaws, memory issues, and calculation
errors. Our study also highlights the impact of prompt engineering strategies,
with variations in accuracy reaching 13.5% for GPT-3.5 and 7.9% for GPT-4o.
However, no single prompt configuration proves universally effective. This
research advances knowledge in three ways: by identifying areas where LLMs can
support safety practices and where human oversight remains essential, by
offering practical insights into improving LLM implementation through prompt
engineering, and by providing evidence-based direction for future research and
development. These contributions support the responsible integration of AI in
construction safety management toward achieving zero injuries.

摘要：<paragraph>營造業仍然是最危險的行業之一。AI 的最新進展，特別是大型語言模型 (LLM)，為提升職場安全提供了絕佳的機會。然而，LLM 的負責任整合需要系統性的評估，因為在不了解其能力和限制的情況下部署它們會產生不準確的資訊，助長錯誤的信心，並危害工作人員的安全。本研究評估了兩個廣泛使用的 LLM，GPT-3.5 和 GPT-4o，在由認證安全專業人員委員會 (BCSP) 管理的三項標準化考試中的表現。本研究使用涵蓋七個安全知識領域的 385 個問題，分析了模型的準確性、一致性和可靠性。結果顯示，這兩個模型都持續超越 BCSP 基準，GPT-4o 的準確率達到 84.6%，而 GPT-3.5 則達到 73.8%。這兩個模型在安全管理系統和危害識別和控制方面表現出優勢，但在科學、數學、緊急應變和防火方面表現出不足。錯誤分析找出影響 LLM 效能的四個主要限制：知識不足、推理缺陷、記憶問題和計算錯誤。我們的研究也強調了提示工程策略的影響，GPT-3.5 的準確性變化達到 13.5%，而 GPT-4o 則達到 7.9%。然而，沒有單一的提示配置被證明具有普遍的效力。這項研究透過以下三種方式推進知識：找出 LLM 可以支援安全實務和人類監督仍然至關重要的領域，提供透過提示工程改善 LLM 實作的實務見解，並為未來的研究和發展提供循證的方向。這些貢獻支援在營造業安全管理中負責任地整合 AI，以達成零傷害的目標。</paragraph>

##### **PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation**
2411.08307v1 by Yungang Yi, Weihua Li, Matthew Kuo, Quan Bai

Music generation has progressed significantly, especially in the domain of
audio generation. However, generating symbolic music that is both
long-structured and expressive remains a significant challenge. In this paper,
we propose PerceiverS (Segmentation and Scale), a novel architecture designed
to address this issue by leveraging both Effective Segmentation and Multi-Scale
attention mechanisms. Our approach enhances symbolic music generation by
simultaneously learning long-term structural dependencies and short-term
expressive details. By combining cross-attention and self-attention in a
Multi-Scale setting, PerceiverS captures long-range musical structure while
preserving performance nuances. The proposed model, evaluated on datasets like
Maestro, demonstrates improvements in generating coherent and diverse music
with both structural consistency and expressive variation. The project demos
and the generated music samples can be accessed through the link:
https://perceivers.github.io.

摘要：音樂生成技術已大幅進步，尤其在音訊生成領域。然而，生成結構長且富含表現力的符號音樂仍然是一項重大挑戰。在本文中，我們提出感知器 (分段與縮放)，一種新穎的架構，旨在透過利用有效分段與多尺度注意力機制來解決此問題。我們的做法透過同時學習長期的結構依賴性與短期的表現細節，來增強符號音樂生成。透過在多尺度設定中結合交叉注意力與自我注意力，感知器能捕捉長程音樂結構，同時保留演奏的細微差別。所提出的模型在 Maestro 等資料集上經過評估，證明了在生成連貫且多樣化的音樂方面有顯著進步，同時具備結構一致性和表現變化。專案展示與生成的音樂範例可透過以下連結取得：https://perceivers.github.io。

##### **R3HF: Reward Redistribution for Enhancing Reinforcement Learning from Human Feedback**
2411.08302v1 by Jiahui Li, Tai-wei Chang, Fengda Zhang, Kun Kuang, Long Chen

Reinforcement learning from human feedback (RLHF) provides a paradigm for
aligning large language models (LLMs) with human preferences. This involves the
initial training of a reward model based on pairwise human feedback. The reward
model is subsequently utilized in reinforcement learning to assess the scores
of each generated sentence as a whole, further guiding the optimization of
LLMs. However, current approaches have a significant shortcoming: \emph{They
allocate a single, sparse, and delayed reward to an entire sequence of output}.
This may overlook some significant individual contributions of each token
towards the desired outcome. To overcome this limitation, our paper proposes a
novel reward redistribution method called R3HF, which facilitates a more
fine-grained, token-level reward allocation. Specifically, our method treats
the reward prediction task of the reward model as a regression problem. As a
result, the redistributed rewards are computed by evaluating the specific
contribution of each token to the reward model's output. This detailed approach
improves the model's understanding of language nuances, leading to more precise
enhancements in its performance. Our method is crafted to integrate seamlessly
with most current techniques while incurring minimal computational costs.
Through comprehensive experiments across diverse datasets and tasks, we have
verified the effectiveness and superiority of our approach.

摘要：人類回饋的強化學習 (RLHF) 提供了一個典範，可以將大型語言模型 (LLM) 與人類偏好相結合。這包括根據人類成對回饋，對獎勵模型進行初始訓練。隨後在強化學習中利用獎勵模型來評估每個生成句子的整體分數，進一步指導 LLM 的最佳化。然而，目前的做法有一個重大的缺點：\emph{它們將單一、稀疏且延遲的獎勵分配給整個輸出序列}。這可能會忽略每個符號對所需結果的一些重要個別貢獻。為了克服這個限制，我們的論文提出了一種名為 R3HF 的新獎勵重新分配方法，它有助於更細緻的符號級別獎勵分配。具體來說，我們的模型將獎勵模型的獎勵預測任務視為回歸問題。因此，重新分配的獎勵是通過評估每個符號對獎勵模型輸出的具體貢獻來計算的。這種詳細的方法改進了模型對語言細微差的理解，從而更精確地提升了它的性能。我們的模型被設計成與大多數當前技術無縫整合，同時產生最小的計算成本。通過對不同資料集和任務進行全面的實驗，我們驗證了我們方法的有效性和優越性。

##### **DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multi-Agent Reinforcement Learning Approach**
2411.08299v1 by Xin Tang, Qian Chen, Wenjie Weng, Binhan Liao, Jiacheng Wang, Xianbin Cao, Xiaohuan Li

Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment
capabilities, prompting the development of UAVs for various application
scenarios within the Internet of Things (IoT). The unique capabilities of UAVs
give rise to increasingly critical and complex tasks in uncertain and
potentially harsh environments. The substantial amount of data generated from
these applications necessitates processing and analysis through deep neural
networks (DNNs). However, UAVs encounter challenges due to their limited
computing resources when managing DNN models. This paper presents a joint
approach that combines multiple-agent reinforcement learning (MARL) and
generative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed
at reducing latency from task capture to result output. To address these
challenges, we first consider the task size of the target area to be inspected
and the shortest flying path as optimization constraints, employing a greedy
algorithm to resolve the subproblem with a focus on minimizing the UAV's flying
path and the overall system cost. In the second stage, we introduce a novel DNN
task assignment algorithm, termed GDM-MADDPG, which utilizes the reverse
denoising process of GDM to replace the actor network in multi-agent deep
deterministic policy gradient (MADDPG). This approach generates specific DNN
task assignment actions based on agents' observations in a dynamic environment.
Simulation results indicate that our algorithm performs favorably compared to
benchmarks in terms of path planning, Age of Information (AoI), energy
consumption, and task load balancing.

摘要：無人機 (UAV) 擁有高度的機動性和靈活的部署能力，促使無人機在物聯網 (IoT) 的各種應用場景中得到發展。無人機的獨特能力在不確定和潛在惡劣的環境中產生越來越關鍵且複雜的任務。這些應用程式產生的龐大數據量需要透過深度神經網路 (DNN) 進行處理和分析。然而，無人機在管理 DNN 模型時會遇到挑戰，因為其運算資源有限。本文提出了一種結合多重代理強化學習 (MARL) 和生成擴散模型 (GDM) 的聯合方法，用於將 DNN 任務分配給無人機群，旨在減少從任務擷取到結果輸出的延遲。為了應對這些挑戰，我們首先考慮要檢查的目標區域的任務大小和最短飛行路徑作為最佳化約束，採用貪婪演算法來解決子問題，重點在於最小化無人機的飛行路徑和整體系統成本。在第二階段，我們引入了一種新穎的 DNN 任務分配演算法，稱為 GDM-MADDPG，它利用 GDM 的反向去噪過程來替換多重代理深度確定性策略梯度 (MADDPG) 中的動作網路。這種方法根據代理在動態環境中的觀察，產生特定的 DNN 任務分配動作。模擬結果表明，與基準相比，我們的演算法在路徑規劃、資訊年齡 (AoI)、能耗和任務負載平衡方面表現良好。

##### **TowerDebias: A Novel Debiasing Method based on the Tower Property**
2411.08297v1 by Norman Matloff, Aditya Mittal

Decision-making processes have increasingly come to rely on sophisticated
machine learning tools, raising concerns about the fairness of their
predictions with respect to any sensitive groups. The widespread use of
commercial black-box machine learning models necessitates careful consideration
of their legal and ethical implications on consumers. In situations where users
have access to these "black-box" models, a key question emerges: how can we
mitigate or eliminate the influence of sensitive attributes, such as race or
gender? We propose towerDebias (tDB), a novel approach designed to reduce the
influence of sensitive variables in predictions made by black-box models. Using
the Tower Property from probability theory, tDB aims to improve prediction
fairness during the post-processing stage in a manner amenable to the
Fairness-Utility Tradeoff. This method is highly flexible, requiring no prior
knowledge of the original model's internal structure, and can be extended to a
range of different applications. We provide a formal improvement theorem for
tDB and demonstrate its effectiveness in both regression and classification
tasks, underscoring its impact on the fairness-utility tradeoff.

摘要：決策制定過程越來越依賴於先進機器學習工具，這引起了人們對其預測的公平性是否會對任何敏感群體造成影響的擔憂。商業黑盒機器學習模型的廣泛使用需要仔細考慮其對消費者的法律和道德影響。在使用者能夠使用這些「黑盒」模型的情況下，一個關鍵問題浮現：我們如何減輕或消除敏感屬性（例如種族或性別）的影響？我們提出 towerDebias (tDB)，這是一種新穎的方法，旨在減少黑盒模型所做預測中敏感變數的影響。tDB 使用機率論中的 Tower 屬性，旨在以有利於公平性-效用權衡的方式在後處理階段改善預測公平性。此方法非常靈活，不需要事先了解原始模型的內部結構，並且可以擴展到各種不同的應用程式。我們為 tDB 提供了正式的改進定理，並展示了它在迴歸和分類任務中的有效性，強調了它對公平性-效用權衡的影響。

##### **RESOLVE: Relational Reasoning with Symbolic and Object-Level Features Using Vector Symbolic Processing**
2411.08290v1 by Mohamed Mejri, Chandramouli Amarnath, Abhijit Chatterjee

Modern transformer-based encoder-decoder architectures struggle with
reasoning tasks due to their inability to effectively extract relational
information between input objects (data/tokens). Recent work introduced the
Abstractor module, embedded between transformer layers, to address this gap.
However, the Abstractor layer while excelling at capturing relational
information (pure relational reasoning), faces challenges in tasks that require
both object and relational-level reasoning (partial relational reasoning). To
address this, we propose RESOLVE, a neuro-vector symbolic architecture that
combines object-level features with relational representations in
high-dimensional spaces, using fast and efficient operations such as bundling
(summation) and binding (Hadamard product) allowing both object-level features
and relational representations to coexist within the same structure without
interfering with one another. RESOLVE is driven by a novel attention mechanism
that operates in a bipolar high dimensional space, allowing fast attention
score computation compared to the state-of-the-art. By leveraging this design,
the model achieves both low compute latency and memory efficiency. RESOLVE also
offers better generalizability while achieving higher accuracy in purely
relational reasoning tasks such as sorting as well as partial relational
reasoning tasks such as math problem-solving compared to state-of-the-art
methods.

摘要：<paragraph>現代基於轉換器的編碼器-解碼器架構由於無法有效提取輸入物件（資料/符號）之間的關係資訊，因此在推理任務中會遇到困難。最近的工作引入了嵌入在轉換器層之間的抽象器模組，以解決這個差距。然而，抽象器層雖然在擷取關係資訊（純關係推理）方面表現出色，但在需要物件和關係層次推理（部分關係推理）的任務中會遇到挑戰。為了解決這個問題，我們提出了 RESOLVE，一種神經向量符號架構，它結合了物件層次特徵和高維空間中的關係表示，使用快速且有效率的操作，例如綑綁（求和）和繫結（Hadamard 乘積），讓物件層次特徵和關係表示能夠在同一個結構中並存，而不會互相干擾。RESOLVE 由一種新穎的注意力機制驅動，該機制在雙極高維空間中運作，與現有技術相比，可以快速計算注意力分數。透過利用此設計，該模型同時達到了低運算延遲和記憶體效率。與現有技術相比，RESOLVE 在純關係推理任務（例如排序）以及部分關係推理任務（例如數學問題求解）中提供了更好的泛化能力，同時實現了更高的準確度。</paragraph>

##### **Hashing for Protein Structure Similarity Search**
2411.08286v1 by Jin Han, Wu-Jun Li

Protein structure similarity search (PSSS), which tries to search proteins
with similar structures, plays a crucial role across diverse domains from drug
design to protein function prediction and molecular evolution. Traditional
alignment-based PSSS methods, which directly calculate alignment on the protein
structures, are highly time-consuming with high memory cost. Recently,
alignment-free methods, which represent protein structures as fixed-length
real-valued vectors, are proposed for PSSS. Although these methods have lower
time and memory cost than alignment-based methods, their time and memory cost
is still too high for large-scale PSSS, and their accuracy is unsatisfactory.
In this paper, we propose a novel method, called
$\underline{\text{p}}$r$\underline{\text{o}}$tein
$\underline{\text{s}}$tructure $\underline{\text{h}}$ashing (POSH), for PSSS.
POSH learns a binary vector representation for each protein structure, which
can dramatically reduce the time and memory cost for PSSS compared with
real-valued vector representation based methods. Furthermore, in POSH we also
propose expressive hand-crafted features and a structure encoder to well model
both node and edge interactions in proteins. Experimental results on real
datasets show that POSH can outperform other methods to achieve
state-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more
than six times and speed improvement of more than four times, compared with
other methods.

摘要：<paragraph>蛋白質結構相似性搜尋 (PSSS) 嘗試搜尋具有類似結構的蛋白質，在從藥物設計到蛋白質功能預測和分子演化的不同領域中扮演著至關重要的角色。傳統的基於比對的 PSSS 方法直接計算蛋白質結構上的比對，非常耗時且記憶體成本高。最近，將蛋白質結構表示為固定長度的實值向量的非比對方法被提議用於 PSSS。儘管這些方法比基於比對的方法具有較低的時間和記憶體成本，但它們的時間和記憶體成本對於大規模 PSSS 來說仍然太高，而且它們的準確度並不令人滿意。在本文中，我們提出了一種稱為
$\underline{\text{p}}$r$\underline{\text{o}}$tein
$\underline{\text{s}}$tructure $\underline{\text{h}}$ashing (POSH) 的新方法，用於 PSSS。POSH 為每個蛋白質結構學習一個二進位向量表示，與基於實值向量表示的方法相比，可以大幅減少 PSSS 的時間和記憶體成本。此外，在 POSH 中，我們還提出了表達性的手工特徵和一個結構編碼器，以很好地對蛋白質中的節點和邊緣交互進行建模。在真實資料集上的實驗結果表明，POSH 可以優於其他方法，以達到最先進的準確度。此外，與其他方法相比，POSH 的記憶體節省超過六倍，速度提升超過四倍。</paragraph>

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v1 by Yihe Zhang, Nabin Pakka, Nian-feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

摘要：大型語言模型 (LLM) 近來在廣泛的應用中獲得相當大的關注。在透過大量資料集進行預訓練期間，此類模型會在其隱藏參數中隱含地記憶訓練資料集的事實知識。然而，隱含在參數中的知識通常會因缺乏常識推理而導致下游應用無法有效使用。在本文中，我們介紹了一個通用架構，允許在 LLM 的幫助下建立知識庫，專門用於處理網路新聞。該架構將基於規則的新聞資訊萃取器 (NewsIE) 應用於新聞項目，以萃取其關係元組，稱為知識庫，然後將其與 LLM 取得的新聞項目的隱含知識事實進行圖形卷積，以進行分類。它包含兩個輕量級組成部分：1) NewsIE：用於萃取每個新聞項目的結構化資訊，以關係元組的形式；2) BERTGraph：用於對 NewsIE 萃取的關係元組進行隱含知識事實的圖形卷積。我們已在不同的與新聞相關的資料集下評估我們的架構，用於新聞類別分類，並獲得有希望的實驗結果。

##### **A Large-Scale Study of Relevance Assessments with Large Language Models: An Initial Look**
2411.08275v1 by Shivani Upadhyay, Ronak Pradeep, Nandan Thakur, Daniel Campos, Nick Craswell, Ian Soboroff, Hoa Trang Dang, Jimmy Lin

The application of large language models to provide relevance assessments
presents exciting opportunities to advance information retrieval, natural
language processing, and beyond, but to date many unknowns remain. This paper
reports on the results of a large-scale evaluation (the TREC 2024 RAG Track)
where four different relevance assessment approaches were deployed in situ: the
"standard" fully manual process that NIST has implemented for decades and three
different alternatives that take advantage of LLMs to different extents using
the open-source UMBRELA tool. This setup allows us to correlate system rankings
induced by the different approaches to characterize tradeoffs between cost and
quality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system
rankings induced by automatically generated relevance assessments from UMBRELA
correlate highly with those induced by fully manual assessments across a
diverse set of 77 runs from 19 teams. Our results suggest that automatically
generated UMBRELA judgments can replace fully manual judgments to accurately
capture run-level effectiveness. Surprisingly, we find that LLM assistance does
not appear to increase correlation with fully manual assessments, suggesting
that costs associated with human-in-the-loop processes do not bring obvious
tangible benefits. Overall, human assessors appear to be stricter than UMBRELA
in applying relevance criteria. Our work validates the use of LLMs in academic
TREC-style evaluations and provides the foundation for future studies.

摘要：<paragraph>將大型語言模型應用於提供相關性評估，為推進資訊檢索、自然語言處理等領域提供了令人興奮的機會，但迄今仍有許多未知數。本文報告了大規模評估（TREC 2024 RAG 軌道）的結果，其中在現場部署了四種不同的相關性評估方法：NIST 已實施數十年的「標準」完全手動流程，以及利用開放原始碼 UMBRELA 工具在不同程度上利用 LLM 的三種不同替代方案。此設定讓我們能夠關聯由不同方法產生的系統排名，以描述成本和品質之間的取捨。我們發現，在 nDCG@20、nDCG@100 和 Recall@100 方面，由 UMBRELA 自動產生的相關性評估所產生的系統排名與 19 個團隊的 77 次執行中完全手動評估所產生的排名高度相關。我們的結果表明，自動產生的 UMBRELA 判斷可以取代完全手動判斷，以準確掌握執行層級的有效性。令人驚訝的是，我們發現 LLM 協助似乎並未增加與完全手動評估的相關性，這表示與人工參與流程相關的成本並未帶來顯著的具體好處。整體而言，人類評估者在應用相關性標準時似乎比 UMBRELA 更加嚴格。我們的研究驗證了在學術 TREC 風格評估中使用 LLM，並為未來的研究奠定了基礎。</paragraph>

##### **GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees**
2411.08257v1 by Sichao Xiong, Yigit Ihlamur, Fuat Alican, Aaron Ontoyin Yin

Traditional decision tree algorithms are explainable but struggle with
non-linear, high-dimensional data, limiting its applicability in complex
decision-making. Neural networks excel at capturing complex patterns but
sacrifice explainability in the process. In this work, we present GPTree, a
novel framework combining explainability of decision trees with the advanced
reasoning capabilities of LLMs. GPTree eliminates the need for feature
engineering and prompt chaining, requiring only a task-specific prompt and
leveraging a tree-based structure to dynamically split samples. We also
introduce an expert-in-the-loop feedback mechanism to further enhance
performance by enabling human intervention to refine and rebuild decision
paths, emphasizing the harmony between human expertise and machine
intelligence. Our decision tree achieved a 7.8% precision rate for identifying
"unicorn" startups at the inception stage of a startup, surpassing gpt-4o with
few-shot learning as well as the best human decision-makers (3.1% to 5.6%).

摘要：傳統決策樹演算法具有可解釋性，但難以處理非線性、高維度資料，限制了其在複雜決策中的應用性。神經網路擅長擷取複雜模式，但在此過程中犧牲了可解釋性。在這項工作中，我們提出了 GPTree，這是一個新穎的架構，結合了決策樹的可解釋性與 LLM 的先進推理能力。GPTree 消除了對特徵工程和提示鏈接的需求，只需要一個特定於任務的提示，並利用基於樹的結構動態分割樣本。我們還引入了一個專家參與的回饋機制，以進一步增強效能，讓人類干預來改善和重建決策路徑，強調人類專業知識與機器智慧之間的和諧。我們的決策樹在辨識「獨角獸」新創公司在創立階段時，達到了 7.8% 的精確度，超越了使用少量學習的 gpt-4o，以及最佳的人類決策者（3.1% 至 5.6%）。

##### **VALTEST: Automated Validation of Language Model Generated Test Cases**
2411.08254v1 by Hamed Taherkhani, Hadi Hemmati

Large Language Models (LLMs) have demonstrated significant potential in
automating software testing, specifically in generating unit test cases.
However, the validation of LLM-generated test cases remains a challenge,
particularly when the ground truth is unavailable. This paper introduces
VALTEST, a novel framework designed to automatically validate test cases
generated by LLMs by leveraging token probabilities. We evaluate VALTEST using
nine test suites generated from three datasets (HumanEval, MBPP, and LeetCode)
across three LLMs (GPT-4o, GPT-3.5-turbo, and LLama3.1 8b). By extracting
statistical features from token probabilities, we train a machine learning
model to predict test case validity. VALTEST increases the validity rate of
test cases by 6.2% to 24%, depending on the dataset and LLM. Our results
suggest that token probabilities are reliable indicators for distinguishing
between valid and invalid test cases, which provides a robust solution for
improving the correctness of LLM-generated test cases in software testing. In
addition, we found that replacing the identified invalid test cases by VALTEST,
using a Chain-of-Thought prompting results in a more effective test suite while
keeping the high validity rates.

摘要：大型語言模型 (LLM) 已證明在自動化軟體測試中具有顯著的潛力，特別是在產生單元測試案例中。然而，LLM 生成的測試案例的驗證仍然是一個挑戰，特別是在沒有基本事實的情況下。本文介紹 VALTEST，這是一個新穎的框架，旨在透過利用 token 機率自動驗證 LLM 生成的測試案例。我們使用從三個資料集（HumanEval、MBPP 和 LeetCode）生成的九個測試套件，透過三個 LLM（GPT-4o、GPT-3.5-turbo 和 LLama3.1 8b）來評估 VALTEST。透過從 token 機率中萃取統計特徵，我們訓練機器學習模型來預測測試案例的有效性。VALTEST 將測試案例的有效性率提高了 6.2% 至 24%，具體取決於資料集和 LLM。我們的結果表明，token 機率是區分有效和無效測試案例的可靠指標，這為改善軟體測試中 LLM 生成的測試案例的正確性提供了一個穩健的解決方案。此外，我們發現透過 VALTEST 替換識別出的無效測試案例，使用思想鏈提示會在保持高有效性率的同時產生更有效的測試套件。

##### **Retrieval Augmented Time Series Forecasting**
2411.08249v1 by Kutay Tire, Ege Onur Taga, Muhammed Emrullah Ildiz, Samet Oymak

Retrieval-augmented generation (RAG) is a central component of modern LLM
systems, particularly in scenarios where up-to-date information is crucial for
accurately responding to user queries or when queries exceed the scope of the
training data. The advent of time-series foundation models (TSFM), such as
Chronos, and the need for effective zero-shot forecasting performance across
various time-series domains motivates the question: Do benefits of RAG
similarly carry over to time series forecasting? In this paper, we advocate
that the dynamic and event-driven nature of time-series data makes RAG a
crucial component of TSFMs and introduce a principled RAG framework for
time-series forecasting, called Retrieval Augmented Forecasting (RAF). Within
RAF, we develop efficient strategies for retrieving related time-series
examples and incorporating them into forecast. Through experiments and
mechanistic studies, we demonstrate that RAF indeed improves the forecasting
accuracy across diverse time series domains and the improvement is more
significant for larger TSFM sizes.

摘要：檢索增強生成 (RAG) 是現代 LLM 系統的核心組成部分，特別是在即時資訊對於準確回應使用者查詢或查詢超出訓練資料範圍至關重要的場景中。時序基礎模型 (TSFM) 的出現，例如 Chronos，以及跨各種時序領域的有效零次學習預測效能需求，激發了一個問題：RAG 的好處是否也同樣適用於時序預測？在本文中，我們主張時序資料的動態和事件驅動特性使 RAG 成為 TSFM 的關鍵組成部分，並介紹了一個用於時序預測的原則性 RAG 架構，稱為檢索增強預測 (RAF)。在 RAF 中，我們開發了有效的策略來檢索相關的時序範例，並將它們納入預測中。透過實驗和機制研究，我們證明 RAF 確實改善了不同時序領域的預測準確度，而且對於較大的 TSFM 規模來說，改善更顯著。

##### **Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial Approach**
2411.08248v1 by Jiyao Li, Mingze Ni, Yongshun Gong, Wei Liu

Deep learning underpins most of the currently advanced natural language
processing (NLP) tasks such as textual classification, neural machine
translation (NMT), abstractive summarization and question-answering (QA).
However, the robustness of the models, particularly QA models, against
adversarial attacks is a critical concern that remains insufficiently explored.
This paper introduces QA-Attack (Question Answering Attack), a novel word-level
adversarial strategy that fools QA models. Our attention-based attack exploits
the customized attention mechanism and deletion ranking strategy to identify
and target specific words within contextual passages. It creates deceptive
inputs by carefully choosing and substituting synonyms, preserving grammatical
integrity while misleading the model to produce incorrect responses. Our
approach demonstrates versatility across various question types, particularly
when dealing with extensive long textual inputs. Extensive experiments on
multiple benchmark datasets demonstrate that QA-Attack successfully deceives
baseline QA models and surpasses existing adversarial techniques regarding
success rate, semantics changes, BLEU score, fluency and grammar error rate.

摘要：深度學習支撐了目前大部分進階的自然語言處理 (NLP) 任務，例如文本分類、神經機器翻譯 (NMT)、摘要摘要和問答 (QA)。然而，模型的穩健性，特別是問答模型，對於對抗攻擊的抵抗力是一個重要的問題，仍然沒有得到充分的探討。本文介紹了問答攻擊 (QA-Attack)，這是一種新穎的詞級對抗策略，可以欺騙問答模型。我們基於注意力的攻擊利用了自訂的注意力機制和刪除排名策略來識別和鎖定上下文段落中的特定詞彙。它通過仔細選擇和替換同義詞來創建具有欺騙性的輸入，在誤導模型產生不正確的回應的同時，保持語法的完整性。我們的做法證明了在各種問題類型中具有多樣性，特別是在處理廣泛的長文本輸入時。在多個基準資料集上進行的廣泛實驗表明，QA-Attack 成功地欺騙了基準問答模型，並在成功率、語義變化、BLEU 分數、流暢性和語法錯誤率方面超越了現有的對抗技術。

##### **Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset**
2411.08243v1 by Khaoula Chehbouni, Jonathan Colaço-Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

In an effort to mitigate the harms of large language models (LLMs), learning
from human feedback (LHF) has been used to steer LLMs towards outputs that are
intended to be both less harmful and more helpful. Despite the widespread
adoption of LHF in practice, the quality of this feedback and its effectiveness
as a safety mitigation technique remain unclear. This study addresses these
issues by auditing the widely-used Helpful and Harmless (HH) dataset by
Anthropic. Our work includes: (1) a thorough investigation of the dataset's
content through both manual and automated evaluation; (2) experiments
demonstrating the dataset's impact on models' safety; and (3) an analysis of
the 100 most influential papers citing this dataset. Through our audit, we
showcase how conceptualization failures and quality issues identified in the HH
dataset can create additional harms by leading to disparate safety behaviors
across demographic groups. Our findings highlight the need for more nuanced,
context-sensitive approaches to safety mitigation in LLMs.

摘要：為了減輕大型語言模型 (LLM) 的危害，從人類回饋 (LHF) 學習已被用於引導 LLM 產生既不那麼有害又有幫助的輸出。儘管 LHF 在實務中被廣泛採用，但此回饋的品質及其作為安全緩解技術的有效性仍不清楚。本研究透過審查 Anthropic 廣泛使用的有益且無害 (HH) 資料集來探討這些問題。我們的研究包括：(1) 透過手動和自動評估徹底調查資料集的內容；(2) 實驗證明資料集對模型安全性的影響；以及 (3) 分析引用此資料集的 100 篇最具影響力的論文。透過我們的審查，我們展示了 HH 資料集中識別出的概念化失敗和品質問題如何透過導致不同人口群體間的安全性行為差異而造成額外的危害。我們的研究結果強調需要針對 LLM 的安全緩解採取更細緻且對情境敏感的方法。

##### **DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection**
2411.08227v1 by Shawn Li, Huixian Gong, Hao Dong, Tiankai Yang, Zhengzhong Tu, Yue Zhao

Out-of-distribution (OOD) detection is essential for ensuring the robustness
of machine learning models by identifying samples that deviate from the
training distribution. While traditional OOD detection has primarily focused on
single-modality inputs, such as images, recent advances in multimodal models
have demonstrated the potential of leveraging multiple modalities (e.g., video,
optical flow, audio) to enhance detection performance. However, existing
methods often overlook intra-class variability within in-distribution (ID)
data, assuming that samples of the same class are perfectly cohesive and
consistent. This assumption can lead to performance degradation, especially
when prediction discrepancies are uniformly amplified across all samples. To
address this issue, we propose Dynamic Prototype Updating (DPU), a novel
plug-and-play framework for multimodal OOD detection that accounts for
intra-class variations. Our method dynamically updates class center
representations for each class by measuring the variance of similar samples
within each batch, enabling adaptive adjustments. This approach allows us to
amplify prediction discrepancies based on the updated class centers, thereby
improving the model's robustness and generalization across different
modalities. Extensive experiments on two tasks, five datasets, and nine base
OOD algorithms demonstrate that DPU significantly improves OOD detection
performance, setting a new state-of-the-art in multimodal OOD detection, with
improvements of up to 80 percent in Far-OOD detection. To facilitate
accessibility and reproducibility, our code is publicly available on GitHub.

摘要：異常偵測（OOD）對於確保機器學習模型的穩健性至關重要，它可以識別偏離訓練分佈的樣本。雖然傳統的 OOD 偵測主要集中在單一模態輸入，例如影像，但多模態模型的最新進展已展示了利用多種模態（例如影片、光流、音訊）來增強偵測效能的潛力。然而，現有方法通常忽略了分佈內 (ID) 資料中的類內變異性，假設同類別的樣本是完全內聚且一致的。此假設可能會導致效能下降，特別是在所有樣本中均勻放大預測差異時。為了解決這個問題，我們提出了動態原型更新 (DPU)，這是一個用於多模態 OOD 偵測的新穎即插即用架構，它考慮了類內變異。我們的模型透過量測每一批次中相似樣本的變異，動態更新每個類別的類別中心表示，從而實現自適應調整。此方法允許我們根據更新後的類別中心放大預測差異，從而改善模型在不同模態下的穩健性和泛化性。在兩個任務、五個資料集和九個基本 OOD 演算法上的大量實驗證明，DPU 大幅改善了 OOD 偵測效能，在多模態 OOD 偵測中樹立了新的技術水準，遠離 OOD 偵測的改善幅度高達 80%。為了促進可及性和可重製性，我們的程式碼已公開在 GitHub 上。

##### **PERFT: Parameter-Efficient Routed Fine-Tuning for Mixture-of-Expert Model**
2411.08212v1 by Yilun Liu, Yunpu Ma, Shuo Chen, Zifeng Ding, Bailan He, Zhen Han, Volker Tresp

The Mixture-of-Experts (MoE) paradigm has emerged as a powerful approach for
scaling transformers with improved resource utilization. However, efficiently
fine-tuning MoE models remains largely underexplored. Inspired by recent works
on Parameter-Efficient Fine-Tuning (PEFT), we present a unified framework for
integrating PEFT modules directly into the MoE mechanism. Aligning with the
core principles and architecture of MoE, our framework encompasses a set of
design dimensions including various functional and composition strategies. By
combining design choices within our framework, we introduce Parameter-Efficient
Routed Fine-Tuning (PERFT) as a flexible and scalable family of PEFT strategies
tailored for MoE models. Extensive experiments on adapting OLMoE-1B-7B and
Mixtral-8$\times$7B for commonsense and arithmetic reasoning tasks demonstrate
the effectiveness, scalability, and intriguing dynamics of PERFT. Additionally,
we provide empirical findings for each specific design choice to facilitate
better application of MoE and PEFT.

摘要：混合專家 (MoE) 典範已成為一種強大的方法，可用於縮放具有改善資源利用率的Transformer。然而，有效微調 MoE 模型在很大程度上仍未被充分探討。受到最近關於參數有效微調 (PEFT) 的研究啟發，我們提出了一個統一框架，用於將 PEFT 模組直接整合到 MoE 機制中。我們的框架與 MoE 的核心原則和架構保持一致，包含一組設計維度，其中包括各種功能和組成策略。透過結合我們框架內的設計選擇，我們引入參數有效路由微調 (PERFT) 作為專門針對 MoE 模型設計的 PEFT 策略的靈活且可擴充的系列。針對適應 OLMoE-1B-7B 和 Mixtral-8$\times$7B 以進行常識和算術推理任務的廣泛實驗證明了 PERFT 的有效性、可擴充性和有趣的動態特性。此外，我們提供每個特定設計選擇的經驗發現，以促進 MoE 和 PEFT 的更好應用。

##### **What Representational Similarity Measures Imply about Decodable Information**
2411.08197v1 by Sarah E. Harvey, David Lipshutz, Alex H. Williams

Neural responses encode information that is useful for a variety of
downstream tasks. A common approach to understand these systems is to build
regression models or ``decoders'' that reconstruct features of the stimulus
from neural responses. Popular neural network similarity measures like centered
kernel alignment (CKA), canonical correlation analysis (CCA), and Procrustes
shape distance, do not explicitly leverage this perspective and instead
highlight geometric invariances to orthogonal or affine transformations when
comparing representations. Here, we show that many of these measures can, in
fact, be equivalently motivated from a decoding perspective. Specifically,
measures like CKA and CCA quantify the average alignment between optimal linear
readouts across a distribution of decoding tasks. We also show that the
Procrustes shape distance upper bounds the distance between optimal linear
readouts and that the converse holds for representations with low participation
ratio. Overall, our work demonstrates a tight link between the geometry of
neural representations and the ability to linearly decode information. This
perspective suggests new ways of measuring similarity between neural systems
and also provides novel, unifying interpretations of existing measures.

摘要：神經反應編碼對各種下游任務有用的資訊。了解這些系統的常見方法是建立回歸模型或「解碼器」，從神經反應中重建刺激的特徵。流行的神經網路相似度測量，例如中心化核對齊 (CKA)、典型相關分析 (CCA) 和 Procrustes 形狀距離，並未明確利用此觀點，而是在比較表示時強調幾何不變性以正交或仿射轉換。在此，我們展示其中許多測量實際上可以從解碼角度等效地激勵。具體來說，CKA 和 CCA 等測量量化在解碼任務分佈中最佳線性讀數之間的平均對齊。我們也展示 Procrustes 形狀距離上界最佳線性讀數之間的距離，而反之則適用於參與率較低的表示。總的來說，我們的研究展示了神經表示的幾何形狀與線性解碼資訊的能力之間的緊密連結。此觀點提出了測量神經系統之間相似性的新方法，並提供了對現有測量的創新統一詮釋。

##### **An Explainable Machine Learning Approach for Age and Gender Estimation in Living Individuals Using Dental Biometrics**
2411.08195v1 by Mohsin Ali, Haider Raza, John Q Gan, Ariel Pokhojaev, Matanel Katz, Esra Kosan, Dian Agustin Wahjuningrum, Omnina Saleh, Rachel Sarig, Akhilanada Chaurasia

Objectives: Age and gender estimation is crucial for various applications,
including forensic investigations and anthropological studies. This research
aims to develop a predictive system for age and gender estimation in living
individuals, leveraging dental measurements such as Coronal Height (CH),
Coronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI). Methods:
Machine learning models were employed in our study, including Cat Boost
Classifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier
(AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient
Boosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental
data from 862 living individuals (459 males and 403 females). Specifically,
periapical radiographs from six teeth per individual were utilized, including
premolars and molars from both maxillary and mandibular. A novel ensemble
learning technique was developed, which uses multiple models each tailored to
distinct dental metrics, to estimate age and gender accurately. Furthermore, an
explainable AI model has been created utilizing SHAP, enabling dental experts
to make judicious decisions based on comprehensible insight. Results: The RF
and XGB models were particularly effective, yielding the highest F1 score for
age and gender estimation. Notably, the XGB model showed a slightly better
performance in age estimation, achieving an F1 score of 73.26%. A similar trend
for the RF model was also observed in gender estimation, achieving a F1 score
of 77.53%. Conclusions: This study marks a significant advancement in dental
forensic methods, showcasing the potential of machine learning to automate age
and gender estimation processes with improved accuracy.

摘要：目標：年齡和性別估計對於各種應用至關重要，包括法醫調查和人類學研究。本研究旨在開發一個預測系統，用於活體年齡和性別估計，利用牙科測量值，例如冠高 (CH)、冠髓腔高度 (CPCH) 和牙冠指數 (TCI)。方法：我們的研究採用了機器學習模型，包括 Cat Boost 分類器 (Catboost)、梯度提升機 (GBM)、Ada Boost 分類器 (AdaBoost)、隨機森林 (RF)、eXtreme 梯度提升 (XGB)、Light 梯度提升機 (LGB) 和 Extra Trees 分類器 (ETC)，分析來自 862 名活體個體（459 名男性和 403 名女性）的牙科數據。具體而言，利用了每個個體六顆牙齒的近心根尖 X 光片，包括上頜和下頜的雙尖牙和磨牙。開發了一種新穎的集成學習技術，它使用多個模型，每個模型都針對不同的牙科指標進行調整，以準確估計年齡和性別。此外，已經利用 SHAP 創建了一個可解釋的 AI 模型，使牙科專家能夠根據易於理解的見解做出明智的決策。結果：RF 和 XGB 模型特別有效，產生了年齡和性別估計的最高 F1 分數。值得注意的是，XGB 模型在年齡估計中表現略好，F1 分數達到 73.26%。在性別估計中也觀察到了 RF 模型的類似趨勢，F1 分數達到 77.53%。結論：這項研究標誌著牙科法醫方法的重大進步，展示了機器學習在自動化年齡和性別估計過程中提高準確性的潛力。

##### **SCORE: Syntactic Code Representations for Static Script Malware Detection**
2411.08182v1 by Ecenaz Erdemir, Kyuhong Park, Michael J. Morais, Vianne R. Gao, Marion Marschalek, Yi Fan

As businesses increasingly adopt cloud technologies, they also need to be
aware of new security challenges, such as server-side script attacks, to ensure
the integrity of their systems and data. These scripts can steal data,
compromise credentials, and disrupt operations. Unlike executables with
standardized formats (e.g., ELF, PE), scripts are plaintext files with diverse
syntax, making them harder to detect using traditional methods. As a result,
more sophisticated approaches are needed to protect cloud infrastructures from
these evolving threats. In this paper, we propose novel feature extraction and
deep learning (DL)-based approaches for static script malware detection,
targeting server-side threats. We extract features from plain-text code using
two techniques: syntactic code highlighting (SCH) and abstract syntax tree
(AST) construction. SCH leverages complex regexes to parse syntactic elements
of code, such as keywords, variable names, etc. ASTs generate a hierarchical
representation of a program's syntactic structure. We then propose a sequential
and a graph-based model that exploits these feature representations to detect
script malware. We evaluate our approach on more than 400K server-side scripts
in Bash, Python and Perl. We use a balanced dataset of 90K scripts for
training, validation, and testing, with the remaining from 400K reserved for
further analysis. Experiments show that our method achieves a true positive
rate (TPR) up to 81% higher than leading signature-based antivirus solutions,
while maintaining a low false positive rate (FPR) of 0.17%. Moreover, our
approach outperforms various neural network-based detectors, demonstrating its
effectiveness in learning code maliciousness for accurate detection of script
malware.

摘要：<paragraph>隨著企業日益採用雲端技術，他們也需要意識到新的安全挑戰，例如伺服器端腳本攻擊，以確保其系統和資料的完整性。這些腳本可以竊取資料、危害憑證並中斷作業。與具有標準化格式的可執行檔（例如 ELF、PE）不同，腳本是具有不同語法的純文字檔案，這使得它們更難使用傳統方法進行偵測。因此，需要更精密的技術來保護雲端基礎設施免於這些不斷演變的威脅。在本文中，我們提出新穎的特徵萃取和基於深度學習 (DL) 的方法，用於靜態腳本惡意軟體偵測，鎖定伺服器端威脅。我們使用兩種技術從純文字程式碼中萃取特徵：語法程式碼突顯 (SCH) 和抽象語法樹 (AST) 建構。SCH 利用複雜的正規表示式來解析程式碼的語法元素，例如關鍵字、變數名稱等。AST 產生程式的語法結構的階層式表示。然後，我們提出一個序列和一個基於圖形的模型，利用這些特徵表示來偵測腳本惡意軟體。我們針對超過 40 萬個 Bash、Python 和 Perl 中的伺服器端腳本評估我們的技術。我們使用一個平衡的 9 萬個腳本資料集進行訓練、驗證和測試，其餘 40 萬個保留作進一步分析。實驗表明，我們的技術比領先的基於簽章的防毒軟體解決方案高出 81% 的真正陽性率 (TPR)，同時將誤報率 (FPR) 維持在 0.17% 的低水準。此外，我們的技術優於各種基於神經網路的偵測器，證明其在學習程式碼惡意性以準確偵測腳本惡意軟體方面的有效性。</paragraph>

##### **Challenges in Guardrailing Large Language Models for Science**
2411.08181v1 by Nishan Pantha, Muthukumaran Ramasubramanian, Iksha Gurung, Manil Maskey, Rahul Ramachandran

The rapid development in large language models (LLMs) has transformed the
landscape of natural language processing and understanding (NLP/NLU), offering
significant benefits across various domains. However, when applied to
scientific research, these powerful models exhibit critical failure modes
related to scientific integrity and trustworthiness. Existing general-purpose
LLM guardrails are insufficient to address these unique challenges in the
scientific domain. We provide comprehensive guidelines for deploying LLM
guardrails in the scientific domain. We identify specific challenges --
including time sensitivity, knowledge contextualization, conflict resolution,
and intellectual property concerns -- and propose a guideline framework for the
guardrails that can align with scientific needs. These guardrail dimensions
include trustworthiness, ethics & bias, safety, and legal aspects. We also
outline in detail the implementation strategies that employ white-box,
black-box, and gray-box methodologies that can be enforced within scientific
contexts.

摘要：大型語言模型 (LLM) 的快速發展已轉變自然語言處理和理解 (NLP/NLU) 的格局，在各個領域提供顯著的優勢。然而，當應用於科學研究時，這些強大的模型會展現與科學誠信和可信度相關的重大失敗模式。現有的通用 LLM 防護措施不足以應對科學領域中這些獨特的挑戰。我們提供在科學領域中部署 LLM 防護措施的全面指南。我們找出特定挑戰，包括時間敏感性、知識脈絡化、衝突解決和智慧財產權問題，並提出一個可與科學需求一致的防護措施指南架構。這些防護措施面向包括可信度、道德與偏見、安全和法律層面。我們也詳細說明在科學脈絡中可執行的白盒、黑盒和灰盒方法論的實作策略。

##### **Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection**
2411.08171v1 by Aditya V. Jonnalagadda, Hashim A. Hashim, Andrew Harris

Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research
places a significant emphasis on transfer learning, showcasing its
transformative potential in enhancing model performance across diverse domains.
This paper examines the efficiency and effectiveness of transfer learning in
the context of wildfire detection. Three purpose-built models -- Visual
Geometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support
Vector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained
models -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. We
trained and evaluated these models using a dataset that captures the
complexities of wildfires, incorporating variables such as varying lighting
conditions, time of day, and diverse terrains. The objective is to discern how
transfer learning performs against models trained from scratch in addressing
the intricacies of the wildfire detection problem. By assessing the performance
metrics, including accuracy, precision, recall, and F1 score, a comprehensive
understanding of the advantages and disadvantages of transfer learning in this
specific domain is obtained. This study contributes valuable insights to the
ongoing discourse, guiding future directions in AI and ML research. Keywords:
Wildfire prediction, deep learning, machine learning fire, detection

摘要：現代人工智慧（AI）和機器學習（ML）研究
非常重視遷移學習，展示其在提升不同領域模型效能的轉型潛力。
本文探討遷移學習在野火偵測背景下的效率和效能。三個專門建構的模型——視覺
幾何群組（VGG）-7、VGG-10 和卷積神經網路（CNN）-支援向量機（SVM）CNN-SVM——與三個預先訓練的
模型——VGG-16、VGG-19 和殘差神經網路（ResNet）ResNet101 嚴格比較。我們
使用捕捉野火複雜性的資料集訓練並評估這些模型，納入變數，例如不同的光照
條件、時間和不同的地形。目標是辨別遷移學習如何針對從頭訓練的模型執行，以解決
野火偵測問題的複雜性。透過評估效能指標，包括準確度、精確度、召回率和 F1 分數，獲得對遷移學習在此
特定領域的優缺點的全面了解。本研究為持續的討論提供寶貴的見解，引導 AI 和 ML 研究的未來方向。關鍵字：
野火預測、深度學習、機器學習火災、偵測

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

摘要：知識圖譜完成功能 (KGC) 的任務旨在從不完整的 3 元組中推斷出遺失的實體。現有的嵌入式方法僅依賴於 KG 中的 3 元組，這容易受到虛假關係模式和長尾實體的影響。另一方面，基於文本的方法難以處理 KG 3 元組和自然語言之間的語義差距。除了 3 元組之外，實體上下文（例如標籤、描述、別名）在擴充 KG 中也扮演著重要的角色。為了解決這些限制，我們提出了 KGR3，一個用於 KGC 的上下文豐富架構。KGR3 由三個模組組成。首先，檢索模組從 KG 中收集支援 3 元組，從基礎嵌入模型中收集可能的候選答案，並為每個相關實體檢索上下文。接著，推理模組採用大型語言模型為每個查詢 3 元組生成潛在答案。最後，重新排名模組將上述兩個模組的候選答案結合起來，並微調 LLM 以提供最佳答案。在廣泛使用的資料集上進行的廣泛實驗證明，KGR3 持續改進各種 KGC 方法。具體來說，KGR3 的最佳變體在 FB15k237 和 WN18RR 資料集上分別實現了 12.3% 和 5.6% 的絕對 Hits@1 改進。

##### **Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization**
2411.08148v1 by Dinesh Srivasthav P, Badri Narayan Subudhi

Pioneering advancements in artificial intelligence, especially in genAI, have
enabled significant possibilities for content creation, but also led to
widespread misinformation and false content. The growing sophistication and
realism of deepfakes is raising concerns about privacy invasion, identity
theft, and has societal, business impacts, including reputational damage and
financial loss. Many deepfake detectors have been developed to tackle this
problem. Nevertheless, as for every AI model, the deepfake detectors face the
wrath of lack of considerable generalization to unseen scenarios and
cross-domain deepfakes. Besides, adversarial robustness is another critical
challenge, as detectors drastically underperform to the slightest imperceptible
change. Most state-of-the-art detectors are trained on static datasets and lack
the ability to adapt to emerging deepfake attack trends. These three crucial
challenges though hold paramount importance for reliability in practise,
particularly in the deepfake domain, are also the problems with any other AI
application. This paper proposes an adversarial meta-learning algorithm using
task-specific adaptive sample synthesis and consistency regularization, in a
refinement phase. By focussing on the classifier's strengths and weaknesses, it
boosts both robustness and generalization of the model. Additionally, the paper
introduces a hierarchical multi-agent retrieval-augmented generation workflow
with a sample synthesis module to dynamically adapt the model to new data
trends by generating custom deepfake samples. The paper further presents a
framework integrating the meta-learning algorithm with the hierarchical
multi-agent workflow, offering a holistic solution for enhancing
generalization, robustness, and adaptability. Experimental results demonstrate
the model's consistent performance across various datasets, outperforming the
models in comparison.

摘要：人工智慧的先驅進展，特別是在生成式 AI 中，為內容創作提供了顯著的可能性，但也導致了廣泛的錯誤訊息和虛假內容。深度偽造的複雜性和真實性日益提升，引發了人們對隱私入侵、身分盜竊的擔憂，並對社會和企業造成影響，包括聲譽受損和財務損失。許多深度偽造偵測器已被開發出來以解決這個問題。儘管如此，對於每一個 AI 模型而言，深度偽造偵測器都面臨著對未見過場景和跨領域深度偽造缺乏相當概括性的憤怒。此外，對抗魯棒性是另一個關鍵挑戰，因為偵測器對最輕微的難以察覺的變化表現得極差。大多數最先進的偵測器都是在靜態資料集上訓練的，並且缺乏適應新興深度偽造攻擊趨勢的能力。儘管這三個關鍵挑戰對實務中的可靠性至關重要，特別是在深度偽造領域，但它們也是任何其他 AI 應用程式所存在的問題。本文提出了一種對抗元學習演算法，在精煉階段使用特定於任務的自適應樣本合成和一致性正則化。透過專注於分類器的優點和缺點，它提升了模型的魯棒性和概括性。此外，本文還引入了一個分層多代理檢索增強生成工作流程，其中包含一個樣本合成模組，透過生成自訂的深度偽造樣本，動態地使模型適應新的資料趨勢。本文進一步提出了將元學習演算法與分層多代理工作流程整合的架構，提供了一個全面的解決方案，以增強概括性、魯棒性和適應性。實驗結果證明了該模型在各種資料集上的一致效能，優於比較中的模型。

##### **Large Language Models Can Self-Improve in Long-context Reasoning**
2411.08147v1 by Siheng Li, Cheng Yang, Zesen Cheng, Lemao Liu, Mo Yu, Yujiu Yang, Wai Lam

Large language models (LLMs) have achieved substantial progress in processing
long contexts but still struggle with long-context reasoning. Existing
approaches typically involve fine-tuning LLMs with synthetic data, which
depends on annotations from human experts or advanced models like GPT-4, thus
restricting further advancements. To address this issue, we investigate the
potential for LLMs to self-improve in long-context reasoning and propose \ours,
an approach specifically designed for this purpose. This approach is
straightforward: we sample multiple outputs for each question, score them with
Minimum Bayes Risk, and then apply supervised fine-tuning or preference
optimization based on these outputs. Extensive experiments on several leading
LLMs demonstrate the effectiveness of \ours, with an absolute improvement of
$4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \ours achieves superior
performance compared to prior approaches that depend on data produced by human
experts or advanced models. We anticipate that this work will open new avenues
for self-improvement techniques in long-context scenarios, which are essential
for the continual advancement of LLMs.

摘要：大型語言模型 (LLM) 在處理長語境方面取得了顯著進展，但仍難以應對長語境推理。現有方法通常涉及使用合成資料微調 LLM，這依賴於人類專家的註解或 GPT-4 等進階模型，因此限制了進一步的進展。為了解決這個問題，我們探討了 LLM 在長語境推理中自我提升的潛力，並提出 \ours，一種專門為此目的設計的方法。這種方法很簡單：我們為每個問題抽取多個輸出，使用最小貝葉斯風險對它們進行評分，然後根據這些輸出應用監督微調或偏好最佳化。對幾個領先的 LLM 進行的廣泛實驗證明了 \ours 的有效性，Llama-3.1-8B-Instruct 的絕對改進為 4.2 分。此外，\ours 與依賴人類專家或進階模型產生的資料的先前方法相比，取得了更好的效能。我們預期這項工作將為長語境場景中的自我提升技術開啟新途徑，這對於 LLM 的持續進步至關重要。

##### **Scaling Properties of Diffusion Models for Perceptual Tasks**
2411.08034v2 by Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik

In this paper, we argue that iterative computation with diffusion models
offers a powerful paradigm for not only generation but also visual perception
tasks. We unify tasks such as depth estimation, optical flow, and amodal
segmentation under the framework of image-to-image translation, and show how
diffusion models benefit from scaling training and test-time compute for these
perceptual tasks. Through a careful analysis of these scaling properties, we
formulate compute-optimal training and inference recipes to scale diffusion
models for visual perception tasks. Our models achieve competitive performance
to state-of-the-art methods using significantly less data and compute. To
access our code and models, see https://scaling-diffusion-perception.github.io .

摘要：在本文中，我們主張使用擴散模型進行反覆運算，提供了一個強大的範例，不僅適用於生成，也適用於視覺感知任務。我們統一了深度估計、光流和非模態分割等任務，在圖像到圖像轉換的框架下，並展示了擴散模型如何受益於擴展訓練和測試時間計算，以執行這些感知任務。透過仔細分析這些縮放屬性，我們制定了計算最佳訓練和推論配方，以擴展擴散模型，用於視覺感知任務。我們的模型使用顯著更少數據和計算，達到了與最先進方法相當的效能。若要存取我們的程式碼和模型，請參閱 https://scaling-diffusion-perception.github.io。

##### **GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation**
2411.08033v1 by Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, Shuai Yang, Bo Dai, Xingang Pan, Chen Change Loy

While 3D content generation has advanced significantly, existing methods
still face challenges with input formats, latent space design, and output
representations. This paper introduces a novel 3D generation framework that
addresses these challenges, offering scalable, high-quality 3D generation with
an interactive Point Cloud-structured Latent space. Our framework employs a
Variational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)
renderings as input, using a unique latent space design that preserves 3D shape
information, and incorporates a cascaded latent diffusion model for improved
shape-texture disentanglement. The proposed method, GaussianAnything, supports
multi-modal conditional 3D generation, allowing for point cloud, caption, and
single/multi-view image inputs. Notably, the newly proposed latent space
naturally enables geometry-texture disentanglement, thus allowing 3D-aware
editing. Experimental results demonstrate the effectiveness of our approach on
multiple datasets, outperforming existing methods in both text- and
image-conditioned 3D generation.

摘要：儘管 3D 內容生成已大幅進展，但現有方法仍面臨輸入格式、潛在空間設計和輸出表示的挑戰。本文介紹了一個新穎的 3D 生成架構，可解決這些挑戰，提供可擴充、高品質的 3D 生成，並具備互動式點雲結構潛在空間。我們的架構採用變異自動編碼器 (VAE)，以多視圖姿勢 RGB-D(深度)-N(法線) 渲染作為輸入，使用獨特的潛在空間設計來保留 3D 形狀資訊，並結合串聯潛在擴散模型以改善形狀紋理分離。所提出的方法 GaussianAnything 支援多模式條件式 3D 生成，允許點雲、標題和單/多視圖影像輸入。值得注意的是，新提出的潛在空間自然能實現幾何紋理分離，因此允許 3D 感知編輯。實驗結果證明了我們的方法在多個資料集上的有效性，在文字和影像條件式 3D 生成方面都優於現有方法。

