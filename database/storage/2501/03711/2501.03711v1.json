{"2501.03711": {"publish_time": "2025-01-07", "title": "Unsupervised Speech Segmentation: A General Approach Using Speech Language Models", "paper_summary": "In this paper, we introduce an unsupervised approach for Speech Segmentation,\nwhich builds on previously researched approaches, e.g., Speaker Diarization,\nwhile being applicable to an inclusive set of acoustic-semantic distinctions,\npaving a path towards a general Unsupervised Speech Segmentation approach.\nUnlike traditional speech and audio segmentation, which mainly focuses on\nspectral changes in the input signal, e.g., phone segmentation, our approach\ntries to segment the spoken utterance into chunks with differing\nacoustic-semantic styles, focusing on acoustic-semantic information that does\nnot translate well into text, e.g., emotion or speaker. While most Speech\nSegmentation tasks only handle one style change, e.g., emotion diarization, our\napproach tries to handle multiple acoustic-semantic style changes. Leveraging\nrecent advances in Speech Language Models (SLMs), we propose a simple\nunsupervised method to segment a given speech utterance. We empirically\ndemonstrate the effectiveness of the proposed approach by considering several\nsetups. Results suggest that the proposed method is superior to the evaluated\nbaselines on boundary detection, segment purity, and over-segmentation. Code is\navailable at\nhttps://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm.", "paper_summary_zh": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u7528\u65bc\u8a9e\u97f3\u5206\u5272\u7684\u975e\u76e3\u7763\u5f0f\u65b9\u6cd5\uff0c\n\u9019\u5efa\u7acb\u5728\u5148\u524d\u7814\u7a76\u7684\u65b9\u6cd5\u4e4b\u4e0a\uff0c\u4f8b\u5982\u8aaa\u8a71\u8005\u5340\u5206\uff0c\n\u540c\u6642\u9069\u7528\u65bc\u4e00\u7d44\u5305\u5bb9\u6027\u7684\u8072\u5b78\u8a9e\u7fa9\u5340\u5225\uff0c\n\u70ba\u901a\u7528\u7684\u975e\u76e3\u7763\u5f0f\u8a9e\u97f3\u5206\u5272\u65b9\u6cd5\u92ea\u5e73\u9053\u8def\u3002\n\u8207\u50b3\u7d71\u7684\u8a9e\u97f3\u548c\u97f3\u8a0a\u5206\u5272\u4e0d\u540c\uff0c\u50b3\u7d71\u7684\u8a9e\u97f3\u548c\u97f3\u8a0a\u5206\u5272\u4e3b\u8981\u95dc\u6ce8\n\u8f38\u5165\u8a0a\u865f\u4e2d\u7684\u983b\u8b5c\u8b8a\u5316\uff0c\u4f8b\u5982\u97f3\u7d20\u5206\u5272\uff0c\u6211\u5011\u7684\u505a\u6cd5\n\u8a66\u5716\u5c07\u53e3\u8a9e\u8a9e\u53e5\u5206\u5272\u6210\u5177\u6709\u4e0d\u540c\n\u8072\u5b78\u8a9e\u7fa9\u98a8\u683c\u7684\u5340\u584a\uff0c\u5c08\u6ce8\u65bc\u7121\u6cd5\u9806\u5229\u8f49\u63db\u70ba\u6587\u5b57\u7684\u8072\u5b78\u8a9e\u7fa9\u8cc7\u8a0a\uff0c\u4f8b\u5982\u60c5\u7dd2\u6216\u8aaa\u8a71\u8005\u3002\u96d6\u7136\u5927\u591a\u6578\u8a9e\u97f3\n\u5206\u5272\u4efb\u52d9\u53ea\u8655\u7406\u4e00\u7a2e\u98a8\u683c\u8b8a\u5316\uff0c\u4f8b\u5982\u60c5\u7dd2\u5340\u5206\uff0c\u6211\u5011\u7684\n\u65b9\u6cd5\u8a66\u5716\u8655\u7406\u591a\u7a2e\u8072\u5b78\u8a9e\u7fa9\u98a8\u683c\u8b8a\u5316\u3002\u5229\u7528\n\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b (SLM) \u7684\u6700\u65b0\u9032\u5c55\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7c21\u55ae\u7684\n\u975e\u76e3\u7763\u5f0f\u65b9\u6cd5\u4f86\u5206\u5272\u7d66\u5b9a\u7684\u8a9e\u97f3\u8a9e\u53e5\u3002\u6211\u5011\u900f\u904e\u8003\u616e\u6578\u500b\n\u8a2d\u5b9a\uff0c\u4ee5\u7d93\u9a57\u65b9\u5f0f\u8b49\u660e\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u908a\u754c\u5075\u6e2c\u3001\u5340\u6bb5\u7d14\u5ea6\u548c\u904e\u5ea6\u5206\u5272\u65b9\u9762\u512a\u65bc\u8a55\u4f30\u7684\u57fa\u6e96\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\nhttps://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm \u53d6\u5f97\u3002", "author": "Avishai Elmakies et.al.", "authors": "Avishai Elmakies, Omri Abend, Yossi Adi", "id": "2501.03711v1", "paper_url": "http://arxiv.org/abs/2501.03711v1", "repo": "https://github.com/avishaielmakies/unsupervised_speech_segmentation_using_slm"}}