{"2411.12882": {"publish_time": "2024-11-19", "title": "ProSec: Fortifying Code LLMs with Proactive Security Alignment", "paper_summary": "Recent advances in code-specific large language models (LLMs) have greatly\nenhanced code generation and refinement capabilities. However, the safety of\ncode LLMs remains under-explored, posing potential risks as insecure code\ngenerated by these models may introduce vulnerabilities into real-world\nsystems. Previous work proposes to collect security-focused instruction-tuning\ndataset from real-world vulnerabilities. It is constrained by the data sparsity\nof vulnerable code, and has limited applicability in the iterative\npost-training workflows of modern LLMs. In this paper, we propose ProSec, a\nnovel proactive security alignment approach designed to align code LLMs with\nsecure coding practices. ProSec systematically exposes the vulnerabilities in a\ncode LLM by synthesizing error-inducing coding scenarios from Common Weakness\nEnumerations (CWEs), and generates fixes to vulnerable code snippets, allowing\nthe model to learn secure practices through advanced preference learning\nobjectives. The scenarios synthesized by ProSec triggers 25 times more\nvulnerable code than a normal instruction-tuning dataset, resulting in a\nsecurity-focused alignment dataset 7 times larger than the previous work.\nExperiments show that models trained with ProSec is 29.2% to 35.5% more secure\ncompared to previous work, with a marginal negative effect of less than 2\npercentage points on model's utility.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u5728\u7279\u5b9a\u4ee3\u7801\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u65b9\u9762\u7684\u8fdb\u5c55\u6781\u5927\u5730\u589e\u5f3a\u4e86\u4ee3\u7801\u751f\u6210\u548c\u4f18\u5316\u80fd\u529b\u3002\u7136\u800c\uff0c\u4ee3\u7801 LLM \u7684\u5b89\u5168\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6a21\u578b\u751f\u6210\u7684\u975e\u5b89\u5168\u4ee3\u7801\u53ef\u80fd\u4f1a\u7ed9\u73b0\u5b9e\u4e16\u754c\u7684\u7cfb\u7edf\u5f15\u5165\u6f0f\u6d1e\uff0c\u4ece\u800c\u5e26\u6765\u6f5c\u5728\u98ce\u9669\u3002\u4ee5\u524d\u7684\u5de5\u4f5c\u5efa\u8bae\u4ece\u73b0\u5b9e\u4e16\u754c\u7684\u6f0f\u6d1e\u4e2d\u6536\u96c6\u4ee5\u5b89\u5168\u6027\u4e3a\u91cd\u70b9\u7684\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u3002\u5b83\u53d7\u5230\u6613\u53d7\u653b\u51fb\u4ee3\u7801\u6570\u636e\u7a00\u758f\u6027\u7684\u9650\u5236\uff0c\u5e76\u4e14\u5728\u73b0\u4ee3 LLM \u7684\u8fed\u4ee3\u540e\u8bad\u7ec3\u5de5\u4f5c\u6d41\u4e2d\u7684\u9002\u7528\u6027\u6709\u9650\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 ProSec\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4e3b\u52a8\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e8\u5728\u5c06\u4ee3\u7801 LLM \u4e0e\u5b89\u5168\u7f16\u7801\u5b9e\u8df5\u76f8\u4e00\u81f4\u3002ProSec \u901a\u8fc7\u4ece\u901a\u7528\u5f31\u70b9\u679a\u4e3e (CWE) \u4e2d\u5408\u6210\u8bf1\u53d1\u9519\u8bef\u7684\u7f16\u7801\u573a\u666f\uff0c\u7cfb\u7edf\u5730\u63ed\u793a\u4e86\u4ee3\u7801 LLM \u4e2d\u7684\u6f0f\u6d1e\uff0c\u5e76\u751f\u6210\u6613\u53d7\u653b\u51fb\u7684\u4ee3\u7801\u7247\u6bb5\u7684\u4fee\u590d\u7a0b\u5e8f\uff0c\u4ece\u800c\u4f7f\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u9ad8\u7ea7\u504f\u597d\u5b66\u4e60\u76ee\u6807\u6765\u5b66\u4e60\u5b89\u5168\u5b9e\u8df5\u3002ProSec \u5408\u6210\u7684\u573a\u666f\u89e6\u53d1\u6bd4\u666e\u901a\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u591a 25 \u500d\u7684\u6613\u53d7\u653b\u51fb\u4ee3\u7801\uff0c\u4ece\u800c\u751f\u6210\u7684\u5b89\u5168\u91cd\u70b9\u5bf9\u9f50\u6570\u636e\u96c6\u6bd4\u4ee5\u524d\u7684\u5de5\u4f5c\u5927 7 \u500d\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4ee5\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u4f7f\u7528 ProSec \u8bad\u7ec3\u7684\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u9ad8\u4e86 29.2% \u81f3 35.5%\uff0c\u5bf9\u6a21\u578b\u6548\u7528\u7684\u8d1f\u9762\u5f71\u54cd\u4e0d\u5230 2 \u4e2a\u767e\u5206\u70b9\u3002</paragraph>", "author": "Xiangzhe Xu et.al.", "authors": "Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang", "id": "2411.12882v1", "paper_url": "http://arxiv.org/abs/2411.12882v1", "repo": "null"}}