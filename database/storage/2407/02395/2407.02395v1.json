{"2407.02395": {"publish_time": "2024-07-02", "title": "Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval", "paper_summary": "Large language models (LLMs) have brought significant advancements to code\ngeneration and code repair, benefiting both novice and experienced developers.\nHowever, their training using unsanitized data from open-source repositories,\nlike GitHub, raises the risk of inadvertently propagating security\nvulnerabilities. Despite numerous studies investigating the safety of code\nLLMs, there remains a gap in comprehensively addressing their security\nfeatures. In this work, we aim to present a comprehensive study aimed at\nprecisely evaluating and enhancing the security aspects of code LLMs. To\nsupport our research, we introduce CodeSecEval, a meticulously curated dataset\ndesigned to address 44 critical vulnerability types with 180 distinct samples.\nCodeSecEval serves as the foundation for the automatic evaluation of code\nmodels in two crucial tasks: code generation and code repair, with a strong\nemphasis on security. Our experimental results reveal that current models\nfrequently overlook security issues during both code generation and repair\nprocesses, resulting in the creation of vulnerable code. In response, we\npropose different strategies that leverage vulnerability-aware information and\ninsecure code explanations to mitigate these security vulnerabilities.\nFurthermore, our findings highlight that certain vulnerability types\nparticularly challenge model performance, influencing their effectiveness in\nreal-world applications. Based on these findings, we believe our study will\nhave a positive impact on the software engineering community, inspiring the\ndevelopment of improved methods for training and utilizing LLMs, thereby\nleading to safer and more trustworthy model deployment.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u70ba\u7a0b\u5f0f\u78bc\u7522\u751f\u548c\u4fee\u5fa9\u5e36\u4f86\u4e86\u986f\u8457\u7684\u9032\u6b65\uff0c\u9020\u798f\u4e86\u65b0\u624b\u548c\u7d93\u9a57\u8c50\u5bcc\u7684\u958b\u767c\u4eba\u54e1\u3002\u7136\u800c\uff0c\u4f7f\u7528\u4f86\u81ea\u958b\u653e\u539f\u59cb\u78bc\u5132\u5b58\u5eab\uff08\u5982 GitHub\uff09\u4e2d\u672a\u7d93\u6e05\u7406\u7684\u8cc7\u6599\u9032\u884c\u8a13\u7df4\uff0c\u6703\u589e\u52a0\u7121\u610f\u9593\u50b3\u64ad\u5b89\u5168\u6f0f\u6d1e\u7684\u98a8\u96aa\u3002\u5118\u7ba1\u6709\u8a31\u591a\u7814\u7a76\u63a2\u8a0e\u7a0b\u5f0f\u78bc LLM \u7684\u5b89\u5168\u6027\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u5168\u9762\u89e3\u6c7a\u5176\u5b89\u5168\u529f\u80fd\u7684\u8fa6\u6cd5\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u63d0\u51fa\u4e00\u500b\u5168\u9762\u7684\u7814\u7a76\uff0c\u4ee5\u7cbe\u78ba\u8a55\u4f30\u548c\u589e\u5f37\u7a0b\u5f0f\u78bc LLM \u7684\u5b89\u5168\u5c64\u9762\u3002\u70ba\u4e86\u652f\u6301\u6211\u5011\u7684\u7814\u7a76\uff0c\u6211\u5011\u5f15\u5165\u4e86 CodeSecEval\uff0c\u9019\u662f\u4e00\u500b\u7d93\u904e\u7cbe\u5fc3\u7b56\u5283\u7684\u8cc7\u6599\u96c6\uff0c\u65e8\u5728\u89e3\u6c7a 44 \u7a2e\u95dc\u9375\u6f0f\u6d1e\u985e\u578b\uff0c\u4e26\u6709 180 \u500b\u4e0d\u540c\u7684\u7bc4\u4f8b\u3002CodeSecEval \u4f5c\u70ba\u81ea\u52d5\u8a55\u4f30\u7a0b\u5f0f\u78bc\u6a21\u578b\u5728\u5169\u500b\u95dc\u9375\u4efb\u52d9\u4e2d\u7684\u57fa\u790e\uff1a\u7a0b\u5f0f\u78bc\u7522\u751f\u548c\u7a0b\u5f0f\u78bc\u4fee\u5fa9\uff0c\u4e26\u7279\u5225\u5f37\u8abf\u5b89\u5168\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u76ee\u524d\u7684\u6a21\u578b\u5728\u7a0b\u5f0f\u78bc\u7522\u751f\u548c\u4fee\u5fa9\u904e\u7a0b\u4e2d\u7d93\u5e38\u5ffd\u7565\u5b89\u5168\u554f\u984c\uff0c\u5c0e\u81f4\u7522\u751f\u6709\u6f0f\u6d1e\u7684\u7a0b\u5f0f\u78bc\u3002\u91dd\u5c0d\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u5229\u7528\u6f0f\u6d1e\u611f\u77e5\u8cc7\u8a0a\u548c\u4e0d\u5b89\u5168\u7684\u7a0b\u5f0f\u78bc\u8aaa\u660e\u4f86\u6e1b\u8f15\u9019\u4e9b\u5b89\u5168\u6f0f\u6d1e\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\uff0c\u67d0\u4e9b\u985e\u578b\u7684\u6f0f\u6d1e\u7279\u5225\u6703\u5f71\u97ff\u6a21\u578b\u6548\u80fd\uff0c\u5f71\u97ff\u5176\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002\u6839\u64da\u9019\u4e9b\u767c\u73fe\uff0c\u6211\u5011\u76f8\u4fe1\u6211\u5011\u7684\u7814\u7a76\u5c07\u5c0d\u8edf\u9ad4\u5de5\u7a0b\u793e\u7fa4\u7522\u751f\u6b63\u9762\u7684\u5f71\u97ff\uff0c\u6fc0\u52f5\u958b\u767c\u6539\u9032\u7684 LLM \u8a13\u7df4\u548c\u4f7f\u7528\u65b9\u5f0f\uff0c\u5f9e\u800c\u5c0e\u81f4\u66f4\u5b89\u5168\u548c\u66f4\u503c\u5f97\u4fe1\u8cf4\u7684\u6a21\u578b\u90e8\u7f72\u3002", "author": "Jiexin Wang et.al.", "authors": "Jiexin Wang, Xitong Luo, Liuwen Cao, Hongkui He, Hailin Huang, Jiayuan Xie, Adam Jatowt, Yi Cai", "id": "2407.02395v1", "paper_url": "http://arxiv.org/abs/2407.02395v1", "repo": "null"}}