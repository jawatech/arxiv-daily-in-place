{"2501.08631": {"publish_time": "2025-01-15", "title": "SWSC: Shared Weight for Similar Channel in LLM", "paper_summary": "Large language models (LLMs) have spurred development in multiple industries.\nHowever, the growing number of their parameters brings substantial storage and\ncomputing burdens, making it essential to explore model compression techniques\nfor parameter reduction and easier deployment. We propose SWSC, an LLM\ncompression method based on the concept of Shared Weight for Similar Channel.\nIt uses the K-Means clustering algorithm to cluster model weights\nchannel-by-channel, generating clusters with highly similar vectors within\neach. A representative vector from each cluster is selected to approximately\nreplace all vectors in the cluster, significantly reducing the number of model\nweight parameters. However, approximate restoration will inevitably cause\ndamage to the performance of the model. To tackle this issue, we perform\nsingular value decomposition on the weight error values before and after\ncompression and retain the larger singular values and their corresponding\nsingular vectors to compensate for the accuracy. The experimental results show\nthat our method can effectively ensure the performance of the compressed LLM\neven under low-precision conditions.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u4fc3\u4f7f\u591a\u500b\u7522\u696d\u767c\u5c55\u3002\n\u7136\u800c\uff0c\u5176\u53c3\u6578\u6578\u91cf\u4e0d\u65b7\u589e\u52a0\uff0c\u5e36\u4f86\u9f90\u5927\u7684\u5132\u5b58\u548c\u904b\u7b97\u8ca0\u64d4\uff0c\u56e0\u6b64\u63a2\u7d22\u6a21\u578b\u58d3\u7e2e\u6280\u8853\u4ee5\u6e1b\u5c11\u53c3\u6578\u4e26\u7c21\u5316\u90e8\u7f72\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u63d0\u51fa SWSC\uff0c\u4e00\u7a2e\u57fa\u65bc\u76f8\u4f3c\u901a\u9053\u5171\u4eab\u6b0a\u91cd\u7684 LLM \u58d3\u7e2e\u65b9\u6cd5\u3002\n\u5b83\u4f7f\u7528 K-Means \u805a\u985e\u6f14\u7b97\u6cd5\u5c0d\u6a21\u578b\u6b0a\u91cd\u9010\u901a\u9053\u805a\u985e\uff0c\u5728\u6bcf\u500b\u901a\u9053\u5167\u7522\u751f\u5177\u6709\u9ad8\u5ea6\u76f8\u4f3c\u5411\u91cf\u7684\u805a\u985e\u3002\u5f9e\u6bcf\u500b\u805a\u985e\u4e2d\u9078\u53d6\u4e00\u500b\u4ee3\u8868\u5411\u91cf\u4f86\u8fd1\u4f3c\u66ff\u63db\u805a\u985e\u4e2d\u7684\u6240\u6709\u5411\u91cf\uff0c\u5927\u5e45\u6e1b\u5c11\u6a21\u578b\u6b0a\u91cd\u53c3\u6578\u7684\u6578\u91cf\u3002\u7136\u800c\uff0c\u8fd1\u4f3c\u9084\u539f\u4e0d\u53ef\u907f\u514d\u5730\u6703\u640d\u5bb3\u6a21\u578b\u7684\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5728\u58d3\u7e2e\u524d\u5f8c\u5c0d\u6b0a\u91cd\u8aa4\u5dee\u503c\u57f7\u884c\u5947\u7570\u503c\u5206\u89e3\uff0c\u4e26\u4fdd\u7559\u8f03\u5927\u7684\u5947\u7570\u503c\u53ca\u5176\u5c0d\u61c9\u7684\u5947\u7570\u5411\u91cf\u4ee5\u88dc\u511f\u6e96\u78ba\u5ea6\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u4f4e\u7cbe\u5ea6\u689d\u4ef6\u4e0b\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u4e5f\u80fd\u6709\u6548\u78ba\u4fdd\u58d3\u7e2e LLM \u7684\u6548\u80fd\u3002", "author": "Binrui Zeng et.al.", "authors": "Binrui Zeng, Yongtao Tang, Xiaodong Liu, Xiaopeng Li", "id": "2501.08631v1", "paper_url": "http://arxiv.org/abs/2501.08631v1", "repo": "null"}}