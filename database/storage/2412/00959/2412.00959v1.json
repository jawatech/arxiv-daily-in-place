{"2412.00959": {"publish_time": "2024-12-01", "title": "Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations", "paper_summary": "Traditional language models have been extensively evaluated for software\nengineering domain, however the potential of ChatGPT and Gemini have not been\nfully explored. To fulfill this gap, the paper in hand presents a comprehensive\ncase study to investigate the potential of both language models for development\nof diverse types of requirement engineering applications. It deeply explores\nimpact of varying levels of expert knowledge prompts on the prediction\naccuracies of both language models. Across 4 different public benchmark\ndatasets of requirement engineering tasks, it compares performance of both\nlanguage models with existing task specific machine/deep learning predictors\nand traditional language models. Specifically, the paper utilizes 4 benchmark\ndatasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,\nrequirements classification), REQuestA (300 question answer (QA) pairs) and\nAerospace datasets (6347 words, requirements NER tagging). Our experiments\nreveal that, in comparison to ChatGPT, Gemini requires more careful prompt\nengineering to provide accurate predictions. Moreover, across requirement\nextraction benchmark dataset the state-of-the-art F1-score is 0.86 while\nChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art\nF1-score on requirements classification dataset is 0.96 and both language\nmodels 0.78. In name entity recognition (NER) task the state-of-the-art\nF1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.\nSimilarly, across question answering dataset the state-of-the-art F1-score is\n0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our\nexperiments show that Gemini requires more precise prompt engineering than\nChatGPT. Except for question-answering, both models under-perform compared to\ncurrent state-of-the-art predictors across other tasks.", "paper_summary_zh": "\u50b3\u7d71\u8a9e\u8a00\u6a21\u578b\u5df2\u5ee3\u6cdb\u8a55\u4f30\u8edf\u9ad4\u5de5\u7a0b\u9818\u57df\uff0c\u4f46 ChatGPT \u548c Gemini \u7684\u6f5b\u529b\u5c1a\u672a\u88ab\u5b8c\u5168\u63a2\u7d22\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u5168\u9762\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u4ee5\u63a2\u8a0e\u9019\u5169\u7a2e\u8a9e\u8a00\u6a21\u578b\u5728\u958b\u767c\u5404\u7a2e\u9700\u6c42\u5de5\u7a0b\u61c9\u7528\u7a0b\u5f0f\u65b9\u9762\u7684\u6f5b\u529b\u3002\u5b83\u6df1\u5165\u63a2\u8a0e\u4e86\u4e0d\u540c\u5c64\u7d1a\u5c08\u5bb6\u77e5\u8b58\u63d0\u793a\u5c0d\u9019\u5169\u7a2e\u8a9e\u8a00\u6a21\u578b\u9810\u6e2c\u7cbe\u5ea6\u7684\u5f71\u97ff\u3002\u5728 4 \u500b\u4e0d\u540c\u7684\u9700\u6c42\u5de5\u7a0b\u4efb\u52d9\u516c\u5171\u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u5b83\u6bd4\u8f03\u4e86\u9019\u5169\u7a2e\u8a9e\u8a00\u6a21\u578b\u8207\u73fe\u6709\u4efb\u52d9\u7279\u5b9a\u6a5f\u5668/\u6df1\u5ea6\u5b78\u7fd2\u9810\u6e2c\u5668\u548c\u50b3\u7d71\u8a9e\u8a00\u6a21\u578b\u7684\u6548\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u672c\u6587\u5229\u7528 4 \u500b\u57fa\u6e96\u8cc7\u6599\u96c6\uff1bPure\uff087,445 \u500b\u6a23\u672c\uff0c\u9700\u6c42\u8403\u53d6\uff09\u3001PROMISE\uff08622 \u500b\u6a23\u672c\uff0c\u9700\u6c42\u5206\u985e\uff09\u3001REQuestA\uff08300 \u500b\u554f\u7b54 (QA) \u5c0d\uff09\u548c\u822a\u592a\u8cc7\u6599\u96c6\uff086347 \u500b\u5b57\uff0c\u9700\u6c42 NER \u6a19\u8a18\uff09\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u8207 ChatGPT \u76f8\u6bd4\uff0cGemini \u9700\u8981\u66f4\u4ed4\u7d30\u7684\u63d0\u793a\u5de5\u7a0b\u624d\u80fd\u63d0\u4f9b\u6e96\u78ba\u7684\u9810\u6e2c\u3002\u6b64\u5916\uff0c\u5728\u9700\u6c42\u8403\u53d6\u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u6700\u5148\u9032\u7684 F1 \u5206\u6578\u70ba 0.86\uff0c\u800c ChatGPT \u548c Gemini \u5206\u5225\u9054\u5230 0.76 \u548c 0.77\u3002\u9700\u6c42\u5206\u985e\u8cc7\u6599\u96c6\u7684\u6700\u5148\u9032 F1 \u5206\u6578\u70ba 0.96\uff0c\u800c\u9019\u5169\u7a2e\u8a9e\u8a00\u6a21\u578b\u90fd\u70ba 0.78\u3002\u5728\u547d\u540d\u5be6\u9ad4\u8b58\u5225 (NER) \u4efb\u52d9\u4e2d\uff0c\u6700\u5148\u9032\u7684 F1 \u5206\u6578\u70ba 0.92\uff0c\u800c ChatGPT \u7522\u751f 0.36\uff0cGemini \u7522\u751f 0.25\u3002\u985e\u4f3c\u5730\uff0c\u5728\u554f\u7b54\u8cc7\u6599\u96c6\uff0c\u6700\u5148\u9032\u7684 F1 \u5206\u6578\u70ba 0.90\uff0c\u800c ChatGPT \u548c Gemini \u5206\u5225\u7522\u751f 0.91 \u548c 0.88\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cGemini \u9700\u8981\u6bd4 ChatGPT \u66f4\u7cbe\u78ba\u7684\u63d0\u793a\u5de5\u7a0b\u3002\u9664\u4e86\u554f\u7b54\u4e4b\u5916\uff0c\u9019\u5169\u500b\u6a21\u578b\u5728\u5176\u4ed6\u4efb\u52d9\u7684\u8868\u73fe\u90fd\u4f4e\u65bc\u76ee\u524d\u7684\u6700\u65b0\u9810\u6e2c\u5668\u3002", "author": "Summra Saleem et.al.", "authors": "Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel", "id": "2412.00959v1", "paper_url": "http://arxiv.org/abs/2412.00959v1", "repo": "null"}}