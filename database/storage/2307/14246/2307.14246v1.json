{"2307.14246": {"publish_time": "2023-07-26", "title": "A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)", "paper_summary": "Within the field of Requirements Engineering (RE), the increasing\nsignificance of Explainable Artificial Intelligence (XAI) in aligning\nAI-supported systems with user needs, societal expectations, and regulatory\nstandards has garnered recognition. In general, explainability has emerged as\nan important non-functional requirement that impacts system quality. However,\nthe supposed trade-off between explainability and performance challenges the\npresumed positive influence of explainability. If meeting the requirement of\nexplainability entails a reduction in system performance, then careful\nconsideration must be given to which of these quality aspects takes precedence\nand how to compromise between them. In this paper, we critically examine the\nalleged trade-off. We argue that it is best approached in a nuanced way that\nincorporates resource availability, domain characteristics, and considerations\nof risk. By providing a foundation for future research and best practices, this\nwork aims to advance the field of RE for AI.", "paper_summary_zh": "", "author": "Timo Speith et.al.", "authors": "Timo Speith,Markus Langer", "id": "2307.14246v1", "paper_url": "http://arxiv.org/abs/2307.14246v1", "repo": "null"}}