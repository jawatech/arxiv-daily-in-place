{"2412.15595": {"publish_time": "2024-12-20", "title": "Mask-RadarNet: Enhancing Transformer With Spatial-Temporal Semantic Context for Radar Object Detection in Autonomous Driving", "paper_summary": "As a cost-effective and robust technology, automotive radar has seen steady\nimprovement during the last years, making it an appealing complement to\ncommonly used sensors like camera and LiDAR in autonomous driving. Radio\nfrequency data with rich semantic information are attracting more and more\nattention. Most current radar-based models take radio frequency image sequences\nas the input. However, these models heavily rely on convolutional neural\nnetworks and leave out the spatial-temporal semantic context during the\nencoding stage. To solve these problems, we propose a model called\nMask-RadarNet to fully utilize the hierarchical semantic features from the\ninput radar data. Mask-RadarNet exploits the combination of interleaved\nconvolution and attention operations to replace the traditional architecture in\ntransformer-based models. In addition, patch shift is introduced to the\nMask-RadarNet for efficient spatial-temporal feature learning. By shifting part\nof patches with a specific mosaic pattern in the temporal dimension,\nMask-RadarNet achieves competitive performance while reducing the computational\nburden of the spatial-temporal modeling. In order to capture the\nspatial-temporal semantic contextual information, we design the class masking\nattention module (CMAM) in our encoder. Moreover, a lightweight auxiliary\ndecoder is added to our model to aggregate prior maps generated from the CMAM.\nExperiments on the CRUW dataset demonstrate the superiority of the proposed\nmethod to some state-of-the-art radar-based object detection algorithms. With\nrelatively lower computational complexity and fewer parameters, the proposed\nMask-RadarNet achieves higher recognition accuracy for object detection in\nautonomous driving.", "paper_summary_zh": "\u4f5c\u70ba\u4e00\u7a2e\u7d93\u6fdf\u4e14\u5f37\u5927\u7684\u6280\u8853\uff0c\u6c7d\u8eca\u96f7\u9054\u5728\u904e\u53bb\u5e7e\u5e74\u4e2d\u7a69\u6b65\u6539\u9032\uff0c\u4f7f\u5176\u6210\u70ba\u81ea\u52d5\u99d5\u99db\u4e2d\u76f8\u6a5f\u548c LiDAR \u7b49\u5e38\u7528\u611f\u6e2c\u5668\u7684\u8a98\u4eba\u88dc\u5145\u3002\u5177\u6709\u8c50\u5bcc\u8a9e\u7fa9\u8cc7\u8a0a\u7684\u7121\u7dda\u96fb\u983b\u7387\u6578\u64da\u6b63\u5438\u5f15\u8d8a\u4f86\u8d8a\u591a\u7684\u95dc\u6ce8\u3002\u76ee\u524d\u5927\u591a\u6578\u57fa\u65bc\u96f7\u9054\u7684\u6a21\u578b\u5c07\u7121\u7dda\u96fb\u983b\u7387\u5f71\u50cf\u5e8f\u5217\u4f5c\u70ba\u8f38\u5165\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u56b4\u91cd\u4f9d\u8cf4\u5377\u7a4d\u795e\u7d93\u7db2\u8def\uff0c\u4e26\u5728\u7de8\u78bc\u968e\u6bb5\u907a\u6f0f\u4e86\u6642\u7a7a\u8a9e\u7fa9\u80cc\u666f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba Mask-RadarNet \u7684\u6a21\u578b\uff0c\u4ee5\u5145\u5206\u5229\u7528\u8f38\u5165\u96f7\u9054\u6578\u64da\u4e2d\u7684\u968e\u5c64\u8a9e\u7fa9\u7279\u5fb5\u3002Mask-RadarNet \u5229\u7528\u4ea4\u932f\u5377\u7a4d\u548c\u6ce8\u610f\u529b\u904b\u7b97\u7684\u7d44\u5408\u4f86\u66ff\u63db\u57fa\u65bcTransformer\u7684\u6a21\u578b\u4e2d\u7684\u50b3\u7d71\u67b6\u69cb\u3002\u6b64\u5916\uff0cPatch Shift \u88ab\u5f15\u5165 Mask-RadarNet \u4ee5\u9032\u884c\u6709\u6548\u7684\u6642\u7a7a\u7279\u5fb5\u5b78\u7fd2\u3002\u901a\u904e\u5728\u6642\u9593\u7dad\u5ea6\u4e2d\u4f7f\u7528\u7279\u5b9a\u7684\u99ac\u8cfd\u514b\u6a21\u5f0f\u8f49\u79fb\u90e8\u5206 Patch\uff0cMask-RadarNet \u5728\u964d\u4f4e\u6642\u7a7a\u5efa\u6a21\u7684\u8a08\u7b97\u8ca0\u64d4\u7684\u540c\u6642\u5be6\u73fe\u4e86\u6709\u7af6\u722d\u529b\u7684\u6027\u80fd\u3002\u70ba\u4e86\u64f7\u53d6\u6642\u7a7a\u8a9e\u7fa9\u80cc\u666f\u8cc7\u8a0a\uff0c\u6211\u5011\u5728\u7de8\u78bc\u5668\u4e2d\u8a2d\u8a08\u4e86\u985e\u5225\u906e\u7f69\u6ce8\u610f\u529b\u6a21\u7d44 (CMAM)\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e2d\u9084\u65b0\u589e\u4e86\u4e00\u500b\u8f15\u91cf\u7d1a\u8f14\u52a9\u89e3\u78bc\u5668\uff0c\u4ee5\u805a\u5408\u5f9e CMAM \u751f\u6210\u7684\u5148\u9a57\u5730\u5716\u3002CRUW \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u512a\u65bc\u4e00\u4e9b\u6700\u5148\u9032\u7684\u57fa\u65bc\u96f7\u9054\u7684\u7269\u9ad4\u5075\u6e2c\u6f14\u7b97\u6cd5\u3002\u5728\u8a08\u7b97\u8907\u96dc\u5ea6\u548c\u53c3\u6578\u76f8\u5c0d\u8f03\u4f4e\u7684\u60c5\u6cc1\u4e0b\uff0c\u6240\u63d0\u51fa\u7684 Mask-RadarNet \u5728\u81ea\u52d5\u99d5\u99db\u4e2d\u7684\u7269\u9ad4\u5075\u6e2c\u4e2d\u5be6\u73fe\u4e86\u66f4\u9ad8\u7684\u8fa8\u8b58\u6e96\u78ba\u5ea6\u3002", "author": "Yuzhi Wu et.al.", "authors": "Yuzhi Wu, Jun Liu, Guangfeng Jiang, Weijian Liu, Danilo Orlando", "id": "2412.15595v1", "paper_url": "http://arxiv.org/abs/2412.15595v1", "repo": "null"}}