{"2405.20900": {"publish_time": "2024-05-31", "title": "Large Language Models: A New Approach for Privacy Policy Analysis at Scale", "paper_summary": "The number and dynamic nature of web and mobile applications presents\nsignificant challenges for assessing their compliance with data protection\nlaws. In this context, symbolic and statistical Natural Language Processing\n(NLP) techniques have been employed for the automated analysis of these\nsystems' privacy policies. However, these techniques typically require\nlabor-intensive and potentially error-prone manually annotated datasets for\ntraining and validation. This research proposes the application of Large\nLanguage Models (LLMs) as an alternative for effectively and efficiently\nextracting privacy practices from privacy policies at scale. Particularly, we\nleverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the\noptimal design of prompts, parameters, and models, incorporating advanced\nstrategies such as few-shot learning. We further illustrate its capability to\ndetect detailed and varied privacy practices accurately. Using several renowned\ndatasets in the domain as a benchmark, our evaluation validates its exceptional\nperformance, achieving an F1 score exceeding 93%. Besides, it does so with\nreduced costs, faster processing times, and fewer technical knowledge\nrequirements. Consequently, we advocate for LLM-based solutions as a sound\nalternative to traditional NLP techniques for the automated analysis of privacy\npolicies at scale.", "paper_summary_zh": "\u7db2\u8def\u548c\u884c\u52d5\u61c9\u7528\u7a0b\u5f0f\u7684\u6578\u91cf\u548c\u52d5\u614b\u7279\u6027\u5c0d\u8a55\u4f30\u5176\u662f\u5426\u7b26\u5408\u8cc7\u6599\u4fdd\u8b77\u6cd5\u898f\u69cb\u6210\u91cd\u5927\u6311\u6230\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u7b26\u865f\u548c\u7d71\u8a08\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u6280\u8853\u5df2\u88ab\u7528\u65bc\u81ea\u52d5\u5316\u5206\u6790\u9019\u4e9b\u7cfb\u7d71\u7684\u96b1\u79c1\u653f\u7b56\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6280\u8853\u901a\u5e38\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6a19\u8a3b\u7684\u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\u548c\u9a57\u8b49\uff0c\u4e14\u5bb9\u6613\u51fa\u932f\u3002\u672c\u7814\u7a76\u63d0\u51fa\u61c9\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f5c\u70ba\u4e00\u7a2e\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u6709\u6548\u4e14\u9ad8\u6548\u5730\u5927\u898f\u6a21\u5f9e\u96b1\u79c1\u653f\u7b56\u4e2d\u8403\u53d6\u96b1\u79c1\u5be6\u52d9\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u5229\u7528\u773e\u6240\u5468\u77e5\u7684 LLM\uff0c\u4f8b\u5982 ChatGPT \u548c Llama 2\uff0c\u4e26\u63d0\u4f9b\u63d0\u793a\u3001\u53c3\u6578\u548c\u6a21\u578b\u7684\u6700\u4f73\u8a2d\u8a08\u6307\u5357\uff0c\u4e26\u7d50\u5408\u5c11\u91cf\u5b78\u7fd2\u7b49\u5148\u9032\u7b56\u7565\u3002\u6211\u5011\u9032\u4e00\u6b65\u8aaa\u660e\u5176\u6e96\u78ba\u5075\u6e2c\u8a73\u7d30\u4e14\u591a\u6a23\u5316\u96b1\u79c1\u5be6\u52d9\u7684\u80fd\u529b\u3002\u4f7f\u7528\u8a72\u9818\u57df\u4e2d\u5e7e\u500b\u8457\u540d\u7684\u8cc7\u6599\u96c6\u4f5c\u70ba\u57fa\u6e96\uff0c\u6211\u5011\u7684\u8a55\u4f30\u9a57\u8b49\u5176\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u9054\u6210\u8d85\u904e 93% \u7684 F1 \u5206\u6578\u3002\u6b64\u5916\uff0c\u5b83\u4ee5\u964d\u4f4e\u6210\u672c\u3001\u66f4\u5feb\u7684\u8655\u7406\u6642\u9593\u548c\u8f03\u5c11\u7684\u6280\u8853\u77e5\u8b58\u9700\u6c42\u4f86\u9054\u6210\u6b64\u76ee\u6a19\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u5021\u57fa\u65bc LLM \u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4f5c\u70ba\u50b3\u7d71 NLP \u6280\u8853\u7684\u5408\u7406\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u5927\u898f\u6a21\u81ea\u52d5\u5316\u5206\u6790\u96b1\u79c1\u653f\u7b56\u3002", "author": "David Rodriguez et.al.", "authors": "David Rodriguez, Ian Yang, Jose M. Del Alamo, Norman Sadeh", "id": "2405.20900v1", "paper_url": "http://arxiv.org/abs/2405.20900v1", "repo": "null"}}