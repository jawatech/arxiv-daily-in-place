{"2406.09770": {"publish_time": "2024-06-14", "title": "Towards Efficient Pareto Set Approximation via Mixture of Experts Based Model Fusion", "paper_summary": "Solving multi-objective optimization problems for large deep neural networks\nis a challenging task due to the complexity of the loss landscape and the\nexpensive computational cost of training and evaluating models. Efficient\nPareto front approximation of large models enables multi-objective optimization\nfor various tasks such as multi-task learning and trade-off analysis. Existing\nalgorithms for learning Pareto set, including (1) evolutionary, hypernetworks,\nand hypervolume-maximization methods, are computationally expensive and have\nrestricted scalability to large models; (2) Scalarization algorithms, where a\nseparate model is trained for each objective ray, which is inefficient for\nlearning the entire Pareto set and fails to capture the objective trade-offs\neffectively. Inspired by the recent success of model merging, we propose a\npractical and scalable approach to Pareto set learning problem via mixture of\nexperts (MoE) based model fusion. By ensembling the weights of specialized\nsingle-task models, the MoE module can effectively capture the trade-offs\nbetween multiple objectives and closely approximate the entire Pareto set of\nlarge neural networks. Once the routers are learned and a preference vector is\nset, the MoE module can be unloaded, thus no additional computational cost is\nintroduced during inference. We conduct extensive experiments on vision and\nlanguage tasks using large-scale models such as CLIP-ViT and GPT-2. The\nexperimental results demonstrate that our method efficiently approximates the\nentire Pareto front of large models. Using only hundreds of trainable\nparameters of the MoE routers, our method even has lower memory usage compared\nto linear scalarization and algorithms that learn a single Pareto optimal\nsolution, and are scalable to both the number of objectives and the size of the\nmodel.", "paper_summary_zh": "<paragraph>\u89e3\u6c7a\u5927\u578b\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u7684\u591a\u76ee\u6a19\u6700\u4f73\u5316\u554f\u984c\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u539f\u56e0\u5728\u65bc\u640d\u5931\u60c5\u6cc1\u7684\u8907\u96dc\u6027\u4ee5\u53ca\u8a13\u7df4\u548c\u8a55\u4f30\u6a21\u578b\u7684\u9ad8\u6602\u904b\u7b97\u6210\u672c\u3002\u5927\u578b\u6a21\u578b\u7684\u6709\u6548 Pareto \u524d\u7de3\u8fd1\u4f3c\u503c\u80fd\u91dd\u5c0d\u5404\u7a2e\u4efb\u52d9\uff08\u4f8b\u5982\u591a\u4efb\u52d9\u5b78\u7fd2\u548c\u6b0a\u8861\u5206\u6790\uff09\u9032\u884c\u591a\u76ee\u6a19\u6700\u4f73\u5316\u3002\u73fe\u6709\u7684\u5b78\u7fd2 Pareto \u96c6\u5408\u6f14\u7b97\u6cd5\uff0c\u5305\u62ec\uff081\uff09\u6f14\u5316\u3001\u8d85\u7db2\u8def\u548c\u8d85\u9ad4\u7a4d\u6700\u5927\u5316\u65b9\u6cd5\uff0c\u5728\u904b\u7b97\u4e0a\u6210\u672c\u6602\u8cb4\uff0c\u4e14\u5728\u5927\u578b\u6a21\u578b\u4e2d\u5177\u6709\u53d7\u9650\u7684\u53ef\u64f4\u5145\u6027\uff1b\uff082\uff09\u6a19\u91cf\u5316\u6f14\u7b97\u6cd5\uff0c\u5176\u4e2d\u91dd\u5c0d\u6bcf\u500b\u76ee\u6a19\u5c04\u7dda\u8a13\u7df4\u4e00\u500b\u55ae\u7368\u7684\u6a21\u578b\uff0c\u9019\u5c0d\u65bc\u5b78\u7fd2\u6574\u500b Pareto \u96c6\u5408\u6c92\u6709\u6548\u7387\uff0c\u4e14\u7121\u6cd5\u6709\u6548\u6355\u6349\u76ee\u6a19\u6b0a\u8861\u3002\u53d7\u5230\u6700\u8fd1\u6a21\u578b\u5408\u4f75\u6210\u529f\u7684\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u900f\u904e\u57fa\u65bc\u6df7\u5408\u5c08\u5bb6\uff08MoE\uff09\u6a21\u578b\u878d\u5408\u7684\u5be6\u7528\u4e14\u53ef\u64f4\u5145\u7684 Pareto \u96c6\u5408\u5b78\u7fd2\u554f\u984c\u65b9\u6cd5\u3002\u900f\u904e\u5c07\u5c08\u696d\u55ae\u4efb\u52d9\u6a21\u578b\u7684\u6b0a\u91cd\u96c6\u6210\uff0cMoE \u6a21\u7d44\u80fd\u6709\u6548\u6355\u6349\u591a\u500b\u76ee\u6a19\u4e4b\u9593\u7684\u6b0a\u8861\uff0c\u4e26\u8fd1\u4f3c\u5927\u578b\u795e\u7d93\u7db2\u8def\u7684\u6574\u500b Pareto \u96c6\u5408\u3002\u4e00\u65e6\u8def\u7531\u5668\u88ab\u5b78\u7fd2\u4e14\u504f\u597d\u5411\u91cf\u88ab\u8a2d\u5b9a\uff0cMoE \u6a21\u7d44\u5c31\u80fd\u5378\u8f09\uff0c\u56e0\u6b64\u5728\u63a8\u8ad6\u671f\u9593\u4e0d\u6703\u7522\u751f\u984d\u5916\u7684\u904b\u7b97\u6210\u672c\u3002\u6211\u5011\u91dd\u5c0d\u4f7f\u7528 CLIP-ViT \u548c GPT-2 \u7b49\u5927\u898f\u6a21\u6a21\u578b\u7684\u8996\u89ba\u548c\u8a9e\u8a00\u4efb\u52d9\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u80fd\u6709\u6548\u8fd1\u4f3c\u5927\u578b\u6a21\u578b\u7684\u6574\u500b Pareto \u524d\u7de3\u3002\u6211\u5011\u7684\u6a21\u578b\u50c5\u4f7f\u7528 MoE \u8def\u7531\u5668\u7684\u6578\u767e\u500b\u53ef\u8a13\u7df4\u53c3\u6578\uff0c\u8207\u7dda\u6027\u6a19\u91cf\u5316\u548c\u5b78\u7fd2\u55ae\u4e00 Pareto \u6700\u4f73\u89e3\u7684\u6f14\u7b97\u6cd5\u76f8\u6bd4\uff0c\u751a\u81f3\u5177\u6709\u8f03\u4f4e\u7684\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\uff0c\u4e14\u80fd\u64f4\u5145\u5230\u76ee\u6a19\u6578\u91cf\u548c\u6a21\u578b\u5927\u5c0f\u3002</paragraph>", "author": "Anke Tang et.al.", "authors": "Anke Tang, Li Shen, Yong Luo, Shiwei Liu, Han Hu, Bo Du", "id": "2406.09770v1", "paper_url": "http://arxiv.org/abs/2406.09770v1", "repo": "https://github.com/tanganke/pareto_set_learning"}}