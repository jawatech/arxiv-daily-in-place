{"2405.04135": {"publish_time": "2024-05-07", "title": "In-context Learning for Automated Driving Scenarios", "paper_summary": "One of the key challenges in current Reinforcement Learning (RL)-based\nAutomated Driving (AD) agents is achieving flexible, precise, and human-like\nbehavior cost-effectively. This paper introduces an innovative approach\nutilizing Large Language Models (LLMs) to intuitively and effectively optimize\nRL reward functions in a human-centric way. We developed a framework where\ninstructions and dynamic environment descriptions are input into the LLM. The\nLLM then utilizes this information to assist in generating rewards, thereby\nsteering the behavior of RL agents towards patterns that more closely resemble\nhuman driving. The experimental results demonstrate that this approach not only\nmakes RL agents more anthropomorphic but also reaches better performance.\nAdditionally, various strategies for reward-proxy and reward-shaping are\ninvestigated, revealing the significant impact of prompt design on shaping an\nAD vehicle's behavior. These findings offer a promising direction for the\ndevelopment of more advanced and human-like automated driving systems. Our\nexperimental data and source code can be found here.", "paper_summary_zh": "\u5728\u7576\u524d\u57fa\u65bc\u5f37\u5316\u5b78\u7fd2 (RL) \u7684\u81ea\u52d5\u99d5\u99db (AD) \u4ee3\u7406\u4e2d\uff0c\u95dc\u9375\u6311\u6230\u4e4b\u4e00\u662f\u4ee5\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u65b9\u5f0f\u5be6\u73fe\u9748\u6d3b\u3001\u7cbe\u78ba\u4e14\u985e\u4eba\u7684\u884c\u70ba\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u76f4\u89c0\u4e14\u6709\u6548\u7684\u65b9\u5f0f\u4ee5\u4eba\u70ba\u4e2d\u5fc3\u7684\u65b9\u5f0f\u6700\u4f73\u5316 RL \u734e\u52f5\u51fd\u6578\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u6846\u67b6\uff0c\u5176\u4e2d\u5c07\u6307\u4ee4\u548c\u52d5\u614b\u74b0\u5883\u63cf\u8ff0\u8f38\u5165\u5230 LLM \u4e2d\u3002\u7136\u5f8c\uff0cLLM \u5229\u7528\u9019\u4e9b\u8cc7\u8a0a\u4f86\u5354\u52a9\u7522\u751f\u734e\u52f5\uff0c\u5f9e\u800c\u5f15\u5c0e RL \u4ee3\u7406\u7684\u884c\u70ba\u671d\u66f4\u63a5\u8fd1\u4eba\u985e\u99d5\u99db\u7684\u6a21\u5f0f\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u9019\u7a2e\u65b9\u6cd5\u4e0d\u50c5\u4f7f RL \u4ee3\u7406\u66f4\u64ec\u4eba\u5316\uff0c\u800c\u4e14\u9084\u9054\u5230\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4e86\u5404\u7a2e\u734e\u52f5\u4ee3\u7406\u548c\u734e\u52f5\u5851\u9020\u7b56\u7565\uff0c\u63ed\u793a\u4e86\u63d0\u793a\u8a2d\u8a08\u5c0d\u5851\u9020 AD \u8eca\u8f1b\u884c\u70ba\u7684\u91cd\u5927\u5f71\u97ff\u3002\u9019\u4e9b\u767c\u73fe\u70ba\u958b\u767c\u66f4\u5148\u9032\u3001\u66f4\u985e\u4eba\u7684\u81ea\u52d5\u99d5\u99db\u7cfb\u7d71\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002\u6211\u5011\u7684\u5be6\u9a57\u6578\u64da\u548c\u6e90\u4ee3\u78bc\u53ef\u4ee5\u5728\u9019\u88e1\u627e\u5230\u3002", "author": "Ziqi Zhou et.al.", "authors": "Ziqi Zhou, Jingyue Zhang, Jingyuan Zhang, Boyue Wang, Tianyu Shi, Alaa Khamis", "id": "2405.04135v1", "paper_url": "http://arxiv.org/abs/2405.04135v1", "repo": "null"}}