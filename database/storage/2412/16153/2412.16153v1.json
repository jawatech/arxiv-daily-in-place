{"2412.16153": {"publish_time": "2024-12-20", "title": "MotiF: Making Text Count in Image Animation with Motion Focal Loss", "paper_summary": "Text-Image-to-Video (TI2V) generation aims to generate a video from an image\nfollowing a text description, which is also referred to as text-guided image\nanimation. Most existing methods struggle to generate videos that align well\nwith the text prompts, particularly when motion is specified. To overcome this\nlimitation, we introduce MotiF, a simple yet effective approach that directs\nthe model's learning to the regions with more motion, thereby improving the\ntext alignment and motion generation. We use optical flow to generate a motion\nheatmap and weight the loss according to the intensity of the motion. This\nmodified objective leads to noticeable improvements and complements existing\nmethods that utilize motion priors as model inputs. Additionally, due to the\nlack of a diverse benchmark for evaluating TI2V generation, we propose TI2V\nBench, a dataset consists of 320 image-text pairs for robust evaluation. We\npresent a human evaluation protocol that asks the annotators to select an\noverall preference between two videos followed by their justifications. Through\na comprehensive evaluation on TI2V Bench, MotiF outperforms nine open-sourced\nmodels, achieving an average preference of 72%. The TI2V Bench is released in\nhttps://wang-sj16.github.io/motif/.", "paper_summary_zh": "\u6587\u672c\u5f71\u50cf\u8f49\u5f71\u7247 (TI2V) \u751f\u6210\u65e8\u5728\u6839\u64da\u6587\u5b57\u63cf\u8ff0\u5f9e\u5f71\u50cf\u7522\u751f\u5f71\u7247\uff0c\u9019\u4e5f\u7a31\u70ba\u6587\u5b57\u5f15\u5c0e\u5f71\u50cf\u52d5\u756b\u3002\u73fe\u6709\u7684\u65b9\u6cd5\u5927\u591a\u96e3\u4ee5\u7522\u751f\u8207\u6587\u5b57\u63d0\u793a\u76f8\u7b26\u7684\u5f71\u7247\uff0c\u7279\u5225\u662f\u5728\u6307\u5b9a\u52d5\u4f5c\u6642\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86 MotiF\uff0c\u9019\u662f\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5c07\u6a21\u578b\u7684\u5b78\u7fd2\u5f15\u5c0e\u81f3\u52d5\u4f5c\u8f03\u591a\u7684\u5340\u57df\uff0c\u5f9e\u800c\u6539\u5584\u6587\u5b57\u5c0d\u9f4a\u548c\u52d5\u4f5c\u7522\u751f\u3002\u6211\u5011\u4f7f\u7528\u5149\u6d41\u4f86\u7522\u751f\u52d5\u4f5c\u71b1\u5716\uff0c\u4e26\u6839\u64da\u52d5\u4f5c\u5f37\u5ea6\u52a0\u6b0a\u640d\u5931\u3002\u9019\u500b\u4fee\u6539\u904e\u7684\u76ee\u6a19\u5c0e\u81f4\u660e\u986f\u7684\u6539\u5584\uff0c\u4e26\u88dc\u5145\u4e86\u5c07\u52d5\u4f5c\u5148\u9a57\u7528\u4f5c\u6a21\u578b\u8f38\u5165\u7684\u73fe\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7531\u65bc\u7f3a\u4e4f\u7528\u65bc\u8a55\u4f30 TI2V \u751f\u6210\u7684\u591a\u5143\u57fa\u6e96\uff0c\u6211\u5011\u63d0\u51fa\u4e86 TI2V Bench\uff0c\u4e00\u500b\u7531 320 \u500b\u5f71\u50cf\u6587\u5b57\u5c0d\u7d44\u6210\u7684\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u7a69\u5065\u8a55\u4f30\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u4eba\u985e\u8a55\u4f30\u5354\u5b9a\uff0c\u8981\u6c42\u8a3b\u89e3\u8005\u5728\u5169\u500b\u5f71\u7247\u4e4b\u9593\u9078\u64c7\u4e00\u500b\u6574\u9ad4\u504f\u597d\uff0c\u7136\u5f8c\u8aaa\u660e\u5176\u7406\u7531\u3002\u900f\u904e\u5c0d TI2V Bench \u7684\u5168\u9762\u8a55\u4f30\uff0cMotiF \u512a\u65bc\u4e5d\u500b\u958b\u6e90\u6a21\u578b\uff0c\u5e73\u5747\u504f\u597d\u9054\u5230 72%\u3002TI2V Bench \u5df2\u5728 https://wang-sj16.github.io/motif/ \u4e2d\u767c\u5e03\u3002", "author": "Shijie Wang et.al.", "authors": "Shijie Wang, Samaneh Azadi, Rohit Girdhar, Saketh Rambhatla, Chen Sun, Xi Yin", "id": "2412.16153v1", "paper_url": "http://arxiv.org/abs/2412.16153v1", "repo": "null"}}