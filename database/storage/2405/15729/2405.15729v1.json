{"2405.15729": {"publish_time": "2024-05-24", "title": "Optimizing Large Language Models for OpenAPI Code Completion", "paper_summary": "Recent advancements in Large Language Models (LLMs) and their utilization in\ncode generation tasks have significantly reshaped the field of software\ndevelopment. Despite the remarkable efficacy of code completion solutions in\nmainstream programming languages, their performance lags when applied to less\nubiquitous formats such as OpenAPI definitions. This study evaluates the\nOpenAPI completion performance of GitHub Copilot, a prevalent commercial code\ncompletion tool, and proposes a set of task-specific optimizations leveraging\nMeta's open-source model Code Llama. A semantics-aware OpenAPI completion\nbenchmark proposed in this research is used to perform a series of experiments\nthrough which the impact of various prompt-engineering and fine-tuning\ntechniques on the Code Llama model's performance is analyzed. The fine-tuned\nCode Llama model reaches a peak correctness improvement of 55.2% over GitHub\nCopilot despite utilizing 25 times fewer parameters than the commercial\nsolution's underlying Codex model. Additionally, this research proposes an\nenhancement to a widely used code infilling training technique, addressing the\nissue of underperformance when the model is prompted with context sizes smaller\nthan those used during training.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u53ca\u5176\u5728\u7a0b\u5f0f\u78bc\u7522\u751f\u4efb\u52d9\u4e2d\u7684\u61c9\u7528\u5df2\u5927\u5e45\u6539\u8b8a\u8edf\u9ad4\u958b\u767c\u9818\u57df\u3002\u5118\u7ba1\u4e3b\u6d41\u7a0b\u5f0f\u8a9e\u8a00\u4e2d\u7684\u7a0b\u5f0f\u78bc\u5b8c\u6210\u89e3\u6c7a\u65b9\u6848\u5177\u6709\u986f\u8457\u7684\u6548\u80fd\uff0c\u4f46\u7576\u61c9\u7528\u65bc\u8f03\u4e0d\u666e\u904d\u7684\u683c\u5f0f\uff0c\u4f8b\u5982 OpenAPI \u5b9a\u7fa9\u6642\uff0c\u5176\u6548\u80fd\u5c31\u6703\u843d\u5f8c\u3002\u672c\u7814\u7a76\u8a55\u4f30\u4e86 GitHub Copilot\uff08\u4e00\u7a2e\u6d41\u884c\u7684\u5546\u7528\u7a0b\u5f0f\u78bc\u5b8c\u6210\u5de5\u5177\uff09\u7684 OpenAPI \u5b8c\u6210\u6548\u80fd\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u7d44\u5229\u7528 Meta \u958b\u6e90\u6a21\u578b Code Llama \u7684\u7279\u5b9a\u4efb\u52d9\u6700\u4f73\u5316\u3002\u672c\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u8a9e\u7fa9\u611f\u77e5 OpenAPI \u5b8c\u6210\u57fa\u6e96\u7528\u65bc\u57f7\u884c\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u900f\u904e\u9019\u4e9b\u5be6\u9a57\u5206\u6790\u5404\u7a2e\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8abf\u6280\u8853\u5c0d Code Llama \u6a21\u578b\u6548\u80fd\u7684\u5f71\u97ff\u3002\u5fae\u8abf\u5f8c\u7684 Code Llama \u6a21\u578b\u7684\u6b63\u78ba\u6027\u63d0\u5347\u5e45\u5ea6\u9054\u5230 55.2%\uff0c\u512a\u65bc GitHub Copilot\uff0c\u5118\u7ba1\u5176\u4f7f\u7528\u7684\u53c3\u6578\u6bd4\u5546\u7528\u89e3\u6c7a\u65b9\u6848\u7684\u57fa\u790e Codex \u6a21\u578b\u5c11\u4e86 25 \u500d\u3002\u6b64\u5916\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7a2e\u5c0d\u5ee3\u6cdb\u4f7f\u7528\u7684\u7a0b\u5f0f\u78bc\u586b\u88dc\u8a13\u7df4\u6280\u8853\u7684\u5f37\u5316\uff0c\u89e3\u6c7a\u4e86\u7576\u6a21\u578b\u63d0\u793a\u7684\u5167\u5bb9\u5927\u5c0f\u5c0f\u65bc\u8a13\u7df4\u671f\u9593\u4f7f\u7528\u7684\u5167\u5bb9\u5927\u5c0f\u6642\u6548\u80fd\u4e0d\u4f73\u7684\u554f\u984c\u3002", "author": "Bohdan Petryshyn et.al.", "authors": "Bohdan Petryshyn, Mantas Luko\u0161evi\u010dius", "id": "2405.15729v1", "paper_url": "http://arxiv.org/abs/2405.15729v1", "repo": "null"}}