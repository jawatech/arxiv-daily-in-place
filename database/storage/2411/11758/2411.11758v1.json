{"2411.11758": {"publish_time": "2024-11-18", "title": "The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning", "paper_summary": "Large Multimodal Models (LMMs) exhibit impressive performance across various\nmultimodal tasks. However, their effectiveness in cross-cultural contexts\nremains limited due to the predominantly Western-centric nature of most data\nand models. Conversely, multi-agent models have shown significant capability in\nsolving complex tasks. Our study evaluates the collective performance of LMMs\nin a multi-agent interaction setting for the novel task of cultural image\ncaptioning. Our contributions are as follows: (1) We introduce MosAIC, a\nMulti-Agent framework to enhance cross-cultural Image Captioning using LMMs\nwith distinct cultural personas; (2) We provide a dataset of culturally\nenriched image captions in English for images from China, India, and Romania\nacross three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable\nmetric for evaluating cultural information within image captions; and (4) We\nshow that the multi-agent interaction outperforms single-agent models across\ndifferent metrics, and offer valuable insights for future research. Our dataset\nand models can be accessed at https://github.com/MichiganNLP/MosAIC.", "paper_summary_zh": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b (LMM) \u5728\u5404\u79cd\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5927\u591a\u6570\u6570\u636e\u548c\u6a21\u578b\u672c\u8d28\u4e0a\u4ee5\u897f\u65b9\u4e3a\u4e2d\u5fc3\uff0c\u5b83\u4eec\u5728\u8de8\u6587\u5316\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u4ecd\u7136\u53d7\u5230\u9650\u5236\u3002\u76f8\u53cd\uff0c\u591a\u4e3b\u4f53\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u7684\u80fd\u529b\u3002\u6211\u4eec\u7684\u7814\u7a76\u8bc4\u4f30\u4e86 LMM \u5728\u591a\u4e3b\u4f53\u4ea4\u4e92\u8bbe\u7f6e\u4e2d\u5bf9\u6587\u5316\u56fe\u50cf\u5b57\u5e55\u7684\u65b0\u9896\u4efb\u52a1\u7684\u96c6\u4f53\u8868\u73b0\u3002\u6211\u4eec\u7684\u8d21\u732e\u5982\u4e0b\uff1a(1) \u6211\u4eec\u5f15\u5165\u4e86 MosAIC\uff0c\u4e00\u4e2a\u591a\u4e3b\u4f53\u6846\u67b6\uff0c\u4f7f\u7528\u5177\u6709\u4e0d\u540c\u6587\u5316\u89d2\u8272\u7684 LMM \u589e\u5f3a\u8de8\u6587\u5316\u56fe\u50cf\u5b57\u5e55\uff1b(2) \u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u6765\u81ea\u4e2d\u56fd\u3001\u5370\u5ea6\u548c\u7f57\u9a6c\u5c3c\u4e9a\u7684\u56fe\u50cf\u7684\u6587\u5316\u4e30\u5bcc\u7684\u56fe\u50cf\u5b57\u5e55\uff0c\u8de8\u8d8a\u4e09\u4e2a\u6570\u636e\u96c6\uff1aGeoDE\u3001GD-VCR\u3001CVQA\uff1b(3) \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u6587\u5316\u9002\u5e94\u6027\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u56fe\u50cf\u5b57\u5e55\u4e2d\u7684\u6587\u5316\u4fe1\u606f\uff1b(4) \u6211\u4eec\u8868\u660e\uff0c\u591a\u4e3b\u4f53\u4ea4\u4e92\u5728\u4e0d\u540c\u6307\u6807\u4e0a\u4f18\u4e8e\u5355\u4e3b\u4f53\u6a21\u578b\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002\u6211\u4eec\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u53ef\u5728 https://github.com/MichiganNLP/MosAIC \u83b7\u5f97\u3002", "author": "Longju Bai et.al.", "authors": "Longju Bai, Angana Borah, Oana Ignat, Rada Mihalcea", "id": "2411.11758v1", "paper_url": "http://arxiv.org/abs/2411.11758v1", "repo": "null"}}