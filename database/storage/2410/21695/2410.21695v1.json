{"2410.21695": {"publish_time": "2024-10-29", "title": "CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs", "paper_summary": "As large language models (LLMs) rapidly evolve, they bring significant\nconveniences to our work and daily lives, but also introduce considerable\nsafety risks. These models can generate texts with social biases or unethical\ncontent, and under specific adversarial instructions, may even incite illegal\nactivities. Therefore, rigorous safety assessments of LLMs are crucial. In this\nwork, we introduce a safety assessment benchmark, CFSafety, which integrates 5\nclassic safety scenarios and 5 types of instruction attacks, totaling 10\ncategories of safety questions, to form a test set with 25k prompts. This test\nset was used to evaluate the natural language generation (NLG) capabilities of\nLLMs, employing a combination of simple moral judgment and a 1-5 safety rating\nscale for scoring. Using this benchmark, we tested eight popular LLMs,\nincluding the GPT series. The results indicate that while GPT-4 demonstrated\nsuperior safety performance, the safety effectiveness of LLMs, including this\nmodel, still requires improvement. The data and code associated with this study\nare available on GitHub.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5feb\u901f\u767c\u5c55\uff0c\u5b83\u5011\u70ba\u6211\u5011\u7684\u5de5\u4f5c\u548c\u65e5\u5e38\u751f\u6d3b\u5e36\u4f86\u6975\u5927\u7684\u4fbf\u5229\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u76f8\u7576\u5927\u7684\u5b89\u5168\u98a8\u96aa\u3002\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u7522\u751f\u5177\u6709\u793e\u6703\u504f\u898b\u6216\u4e0d\u9053\u5fb7\u5167\u5bb9\u7684\u6587\u5b57\uff0c\u4e26\u4e14\u5728\u7279\u5b9a\u5c0d\u6297\u6027\u6307\u4ee4\u4e0b\uff0c\u751a\u81f3\u53ef\u80fd\u717d\u52d5\u975e\u6cd5\u6d3b\u52d5\u3002\u56e0\u6b64\uff0c\u5c0d LLM \u9032\u884c\u56b4\u683c\u7684\u5b89\u5168\u8a55\u4f30\u81f3\u95dc\u91cd\u8981\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u5b89\u5168\u8a55\u4f30\u57fa\u6e96 CFSafety\uff0c\u5b83\u6574\u5408\u4e86 5 \u500b\u7d93\u5178\u5b89\u5168\u5834\u666f\u548c 5 \u7a2e\u985e\u578b\u7684\u6307\u4ee4\u653b\u64ca\uff0c\u7e3d\u5171 10 \u985e\u5b89\u5168\u554f\u984c\uff0c\u5f62\u6210\u4e86\u4e00\u500b\u5305\u542b 25k \u63d0\u793a\u7684\u6e2c\u8a66\u96c6\u3002\u6b64\u6e2c\u8a66\u96c6\u7528\u65bc\u8a55\u4f30 LLM \u7684\u81ea\u7136\u8a9e\u8a00\u751f\u6210 (NLG) \u80fd\u529b\uff0c\u63a1\u7528\u7c21\u55ae\u7684\u9053\u5fb7\u5224\u65b7\u548c 1-5 \u5b89\u5168\u8a55\u5206\u91cf\u8868\u9032\u884c\u8a55\u5206\u3002\u4f7f\u7528\u6b64\u57fa\u6e96\uff0c\u6211\u5011\u6e2c\u8a66\u4e86\u516b\u7a2e\u6d41\u884c\u7684 LLM\uff0c\u5305\u62ec GPT \u7cfb\u5217\u3002\u7d50\u679c\u8868\u660e\uff0c\u96d6\u7136 GPT-4 \u8868\u73fe\u51fa\u5353\u8d8a\u7684\u5b89\u5168\u6027\u80fd\uff0c\u4f46\u5305\u62ec\u6b64\u6a21\u578b\u5728\u5167\u7684 LLM \u7684\u5b89\u5168\u6709\u6548\u6027\u4ecd\u9700\u8981\u6539\u9032\u3002\u8207\u672c\u7814\u7a76\u76f8\u95dc\u7684\u6578\u64da\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 GitHub \u4e0a\u53d6\u5f97\u3002", "author": "Zhihao Liu et.al.", "authors": "Zhihao Liu, Chenhui Hu", "id": "2410.21695v1", "paper_url": "http://arxiv.org/abs/2410.21695v1", "repo": "null"}}