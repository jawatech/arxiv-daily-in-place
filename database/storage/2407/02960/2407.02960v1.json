{"2407.02960": {"publish_time": "2024-07-03", "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets", "paper_summary": "This work addresses the timely yet underexplored problem of performing\ninference and finetuning of a proprietary LLM owned by a model provider entity\non the confidential/private data of another data owner entity, in a way that\nensures the confidentiality of both the model and the data. Hereby, the\nfinetuning is conducted offsite, i.e., on the computation infrastructure of a\nthird-party cloud provider. We tackle this problem by proposing ObfuscaTune, a\nnovel, efficient and fully utility-preserving approach that combines a simple\nyet effective obfuscation technique with an efficient usage of confidential\ncomputing (only 5% of the model parameters are placed on TEE). We empirically\ndemonstrate the effectiveness of ObfuscaTune by validating it on GPT-2 models\nwith different sizes on four NLP benchmark datasets. Finally, we compare to a\nna\\\"ive version of our approach to highlight the necessity of using random\nmatrices with low condition numbers in our approach to reduce errors induced by\nthe obfuscation.", "paper_summary_zh": "\u672c\u7814\u7a76\u89e3\u6c7a\u4e86\u4e00\u500b\u53ca\u6642\u4f46\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u7684\u554f\u984c\uff0c\u5373\u4ee5\u4e00\u7a2e\u78ba\u4fdd\u6a21\u578b\u548c\u6578\u64da\u6a5f\u5bc6\u6027\u7684\u65b9\u5f0f\uff0c\u5728\u53e6\u4e00\u500b\u6578\u64da\u6240\u6709\u8005\u5be6\u9ad4\u7684\u6a5f\u5bc6/\u79c1\u4eba\u6578\u64da\u4e0a\u57f7\u884c\u6a21\u578b\u63d0\u4f9b\u8005\u5be6\u9ad4\u64c1\u6709\u7684\u5c08\u6709 LLM \u7684\u63a8\u7406\u548c\u5fae\u8abf\u3002\u5728\u6b64\uff0c\u5fae\u8abf\u662f\u5728\u5834\u5916\u9032\u884c\u7684\uff0c\u5373\u5728\u7b2c\u4e09\u65b9\u96f2\u63d0\u4f9b\u5546\u7684\u8a08\u7b97\u57fa\u790e\u8a2d\u65bd\u4e0a\u3002\u6211\u5011\u901a\u904e\u63d0\u51fa ObfuscaTune \u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u3001\u9ad8\u6548\u4e14\u5b8c\u5168\u4fdd\u7559\u6548\u7528\u7684\u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u7684\u6df7\u6dc6\u6280\u8853\u8207\u6a5f\u5bc6\u8a08\u7b97\u7684\u6709\u6548\u4f7f\u7528\uff08\u53ea\u6709 5% \u7684\u6a21\u578b\u53c3\u6578\u88ab\u653e\u7f6e\u5728 TEE \u4e0a\uff09\u3002\u6211\u5011\u901a\u904e\u5728\u56db\u500b NLP \u57fa\u6e96\u6578\u64da\u96c6\u4e0a\u9a57\u8b49\u4e0d\u540c\u5927\u5c0f\u7684 GPT-2 \u6a21\u578b\uff0c\u7d93\u9a57\u6027\u5730\u8b49\u660e\u4e86 ObfuscaTune \u7684\u6709\u6548\u6027\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c07\u5176\u8207\u6211\u5011\u65b9\u6cd5\u7684\u300c\u5929\u771f\u300d\u7248\u672c\u9032\u884c\u6bd4\u8f03\uff0c\u4ee5\u5f37\u8abf\u5728\u6211\u5011\u7684\u904e\u7a0b\u4e2d\u4f7f\u7528\u689d\u4ef6\u6578\u4f4e\u7684\u96a8\u6a5f\u77e9\u9663\u4ee5\u6e1b\u5c11\u6df7\u6dc6\u5f15\u8d77\u7684\u932f\u8aa4\u7684\u5fc5\u8981\u6027\u3002", "author": "Ahmed Frikha et.al.", "authors": "Ahmed Frikha, Nassim Walha, Ricardo Mendes, Krishna Kanth Nakka, Xue Jiang, Xuebing Zhou", "id": "2407.02960v1", "paper_url": "http://arxiv.org/abs/2407.02960v1", "repo": "null"}}