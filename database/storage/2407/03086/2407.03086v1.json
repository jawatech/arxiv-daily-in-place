{"2407.03086": {"publish_time": "2024-07-03", "title": "Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation", "paper_summary": "While federated learning leverages distributed client resources, it faces\nchallenges due to heterogeneous client capabilities. This necessitates\nallocating models suited to clients' resources and careful parameter\naggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel\nfederated learning framework for supporting client heterogeneity by combining a\nmulti-exit network architecture with hypernetwork-based model weight\ngeneration. This approach aligns the feature spaces of heterogeneous model\nlayers and resolves per-layer information disparity during weight aggregation.\nTo practically realize HypeMeFed, we also propose a low-rank factorization\napproach to minimize computation and memory overhead associated with\nhypernetworks. Our evaluations on a real-world heterogeneous device testbed\nindicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the\nhypernetwork memory requirements by 98.22%, and accelerates its operations by\n1.86 times compared to a naive hypernetwork approach. These results demonstrate\nHypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for\nfederated learning.", "paper_summary_zh": "\u96d6\u7136\u806f\u5408\u5b78\u7fd2\u5229\u7528\u5206\u6563\u5f0f\u7528\u6236\u7aef\u8cc7\u6e90\uff0c\u4f46\u7531\u65bc\u7528\u6236\u7aef\u80fd\u529b\u7570\u8cea\uff0c\u56e0\u6b64\u9762\u81e8\u6311\u6230\u3002\u9019\u9700\u8981\u5206\u914d\u9069\u5408\u7528\u6236\u7aef\u8cc7\u6e90\u7684\u6a21\u578b\uff0c\u4e26\u4ed4\u7d30\u53c3\u6578\u805a\u5408\u4ee5\u5bb9\u7d0d\u9019\u7a2e\u7570\u8cea\u6027\u3002\u6211\u5011\u63d0\u51fa HypeMeFed\uff0c\u4e00\u7a2e\u65b0\u7684\u806f\u5408\u5b78\u7fd2\u6846\u67b6\uff0c\u901a\u904e\u5c07\u591a\u51fa\u53e3\u7db2\u8def\u67b6\u69cb\u8207\u57fa\u65bc\u8d85\u7db2\u8def\u7684\u6a21\u578b\u6b0a\u91cd\u751f\u6210\u76f8\u7d50\u5408\u4f86\u652f\u63f4\u7528\u6236\u7aef\u7570\u8cea\u6027\u3002\u6b64\u65b9\u6cd5\u5c0d\u9f4a\u7570\u8cea\u6a21\u578b\u5c64\u7684\u7279\u5fb5\u7a7a\u9593\uff0c\u4e26\u5728\u6b0a\u91cd\u805a\u5408\u671f\u9593\u89e3\u6c7a\u9010\u5c64\u8cc7\u8a0a\u5dee\u7570\u3002\u70ba\u4e86\u5be6\u969b\u5be6\u73fe HypeMeFed\uff0c\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u7a2e\u4f4e\u79e9\u5206\u89e3\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u6e1b\u5c11\u8207\u8d85\u7db2\u8def\u76f8\u95dc\u7684\u8a08\u7b97\u548c\u8a18\u61b6\u9ad4\u958b\u92b7\u3002\u6211\u5011\u5728\u771f\u5be6\u4e16\u754c\u7570\u8cea\u8a2d\u5099\u6e2c\u8a66\u5e73\u53f0\u4e0a\u7684\u8a55\u4f30\u8868\u660e\uff0c\u8207 FedAvg \u76f8\u6bd4\uff0cHypeMeFed \u5c07\u6e96\u78ba\u7387\u63d0\u9ad8\u4e86 5.12%\uff0c\u5c07\u8d85\u7db2\u8def\u8a18\u61b6\u9ad4\u9700\u6c42\u6e1b\u5c11\u4e86 98.22%\uff0c\u4e26\u4e14\u8207\u5929\u771f\u7684\u8d85\u7db2\u8def\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5176\u904b\u7b97\u901f\u5ea6\u63d0\u9ad8\u4e86 1.86 \u500d\u3002\u9019\u4e9b\u7d50\u679c\u8b49\u660e\u4e86 HypeMeFed \u5728\u5229\u7528\u548c\u5438\u5f15\u7570\u8cea\u7528\u6236\u7aef\u9032\u884c\u806f\u5408\u5b78\u7fd2\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "author": "Yujin Shin et.al.", "authors": "Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko", "id": "2407.03086v1", "paper_url": "http://arxiv.org/abs/2407.03086v1", "repo": "null"}}