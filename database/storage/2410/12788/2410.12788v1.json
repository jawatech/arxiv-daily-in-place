{"2410.12788": {"publish_time": "2024-10-16", "title": "Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception", "paper_summary": "Retrieval-Augmented Generation (RAG), while serving as a viable complement to\nlarge language models (LLMs), often overlooks the crucial aspect of text\nchunking within its pipeline, which impacts the quality of knowledge-intensive\ntasks. This paper introduces the concept of Meta-Chunking, which refers to a\ngranularity between sentences and paragraphs, consisting of a collection of\nsentences within a paragraph that have deep linguistic logical connections. To\nimplement Meta-Chunking, we designed two strategies based on LLMs: Margin\nSampling Chunking and Perplexity Chunking. The former employs LLMs to perform\nbinary classification on whether consecutive sentences need to be segmented,\nmaking decisions based on the probability difference obtained from margin\nsampling. The latter precisely identifies text chunk boundaries by analyzing\nthe characteristics of perplexity distribution. Additionally, considering the\ninherent complexity of different texts, we propose a strategy that combines\nMeta-Chunking with dynamic merging to achieve a balance between fine-grained\nand coarse-grained text chunking. Experiments conducted on eleven datasets\ndemonstrate that Meta-Chunking can more efficiently improve the performance of\nsingle-hop and multi-hop question answering based on RAG. For instance, on the\n2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only\nconsuming 45.8% of the time. Our code is available at\nhttps://github.com/IAAR-Shanghai/Meta-Chunking.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u96d6\u7136\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u53ef\u884c\u88dc\u5145\uff0c\u4f46\u5176\u7ba1\u9053\u4e2d\u7d93\u5e38\u5ffd\u7565\u6587\u672c\u5206\u584a\u7684\u95dc\u9375\u65b9\u9762\uff0c\u9019\u6703\u5f71\u97ff\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u7684\u54c1\u8cea\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u5143\u5206\u584a\u7684\u6982\u5ff5\uff0c\u5b83\u6307\u7684\u662f\u53e5\u5b50\u548c\u6bb5\u843d\u4e4b\u9593\u7684\u7c92\u5ea6\uff0c\u7531\u6bb5\u843d\u4e2d\u5177\u5099\u6df1\u5165\u8a9e\u8a00\u908f\u8f2f\u95dc\u806f\u7684\u4e00\u7cfb\u5217\u53e5\u5b50\u7d44\u6210\u3002\u70ba\u4e86\u5be6\u4f5c\u5143\u5206\u584a\uff0c\u6211\u5011\u57fa\u65bc LLM \u8a2d\u8a08\u4e86\u5169\u7a2e\u7b56\u7565\uff1a\u908a\u7de3\u53d6\u6a23\u5206\u584a\u548c\u56f0\u60d1\u5ea6\u5206\u584a\u3002\u524d\u8005\u63a1\u7528 LLM \u5c0d\u9023\u7e8c\u7684\u53e5\u5b50\u662f\u5426\u9700\u8981\u5206\u6bb5\u9032\u884c\u4e8c\u5143\u5206\u985e\uff0c\u6839\u64da\u908a\u7de3\u53d6\u6a23\u7372\u5f97\u7684\u6a5f\u7387\u5dee\u7570\u505a\u51fa\u6c7a\u7b56\u3002\u5f8c\u8005\u900f\u904e\u5206\u6790\u56f0\u60d1\u5ea6\u5206\u4f48\u7684\u7279\u5fb5\u7cbe\u78ba\u8b58\u5225\u6587\u672c\u584a\u754c\u7dda\u3002\u6b64\u5916\uff0c\u8003\u91cf\u5230\u4e0d\u540c\u6587\u672c\u7684\u56fa\u6709\u8907\u96dc\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7d50\u5408\u5143\u5206\u584a\u8207\u52d5\u614b\u5408\u4f75\u7684\u7b56\u7565\uff0c\u4ee5\u5728\u7d30\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u6587\u672c\u5206\u584a\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u5728 11 \u500b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u5143\u5206\u584a\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u63d0\u5347\u57fa\u65bc RAG \u7684\u55ae\u8df3\u548c\u591a\u8df3\u554f\u984c\u89e3\u7b54\u6548\u80fd\u3002\u4f8b\u5982\uff0c\u5728 2WikiMultihopQA \u8cc7\u6599\u96c6\u4e0a\uff0c\u5b83\u6bd4\u76f8\u4f3c\u6027\u5206\u584a\u9ad8\u51fa 1.32 \u500b\u767e\u5206\u9ede\uff0c\u540c\u6642\u50c5\u8017\u8cbb 45.8% \u7684\u6642\u9593\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/IAAR-Shanghai/Meta-Chunking \u53d6\u5f97\u3002", "author": "Jihao Zhao et.al.", "authors": "Jihao Zhao, Zhiyuan Ji, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li", "id": "2410.12788v1", "paper_url": "http://arxiv.org/abs/2410.12788v1", "repo": "null"}}