{"2412.09817": {"publish_time": "2024-12-13", "title": "Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation", "paper_summary": "Multimodal large language models have experienced rapid growth, and numerous\ndifferent models have emerged. The interpretability of LVLMs remains an\nunder-explored area. Especially when faced with more complex tasks such as\nchain-of-thought reasoning, its internal mechanisms still resemble a black box\nthat is difficult to decipher. By studying the interaction and information flow\nbetween images and text, we noticed that in models such as LLaVA1.5, image\ntokens that are semantically related to text are more likely to have\ninformation flow convergence in the LLM decoding layer, and these image tokens\nreceive higher attention scores. However, those image tokens that are less\nrelevant to the text do not have information flow convergence, and they only\nget very small attention scores. To efficiently utilize the image information,\nwe propose a new image token reduction method, Simignore, which aims to improve\nthe complex reasoning ability of LVLMs by computing the similarity between\nimage and text embeddings and ignoring image tokens that are irrelevant and\nunimportant to the text. Through extensive experiments, we demonstrate the\neffectiveness of our method for complex reasoning tasks. The paper's source\ncode can be accessed from \\url{https://github.com/FanshuoZeng/Simignore}.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5386\u4e86\u5feb\u901f\u53d1\u5c55\uff0c\u5e76\u4e14\u51fa\u73b0\u4e86\u8bb8\u591a\u4e0d\u540c\u7684\u6a21\u578b\u3002LLVM \u7684\u53ef\u89e3\u91ca\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002\u7279\u522b\u662f\u5f53\u9762\u4e34\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u7b49\u66f4\u590d\u6742\u7684\u4efb\u52a1\u65f6\uff0c\u5176\u5185\u90e8\u673a\u5236\u4ecd\u7136\u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u96be\u4ee5\u7834\u8bd1\u7684\u9ed1\u5323\u5b50\u3002\u901a\u8fc7\u7814\u7a76\u56fe\u50cf\u548c\u6587\u672c\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u4fe1\u606f\u6d41\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u5728 LLaVA1.5 \u7b49\u6a21\u578b\u4e2d\uff0c\u4e0e\u6587\u672c\u8bed\u4e49\u76f8\u5173\u7684\u56fe\u50cf\u6807\u8bb0\u66f4\u6709\u53ef\u80fd\u5728 LLM \u89e3\u7801\u5c42\u4e2d\u5177\u6709\u4fe1\u606f\u6d41\u6536\u655b\uff0c\u5e76\u4e14\u8fd9\u4e9b\u56fe\u50cf\u6807\u8bb0\u63a5\u6536\u66f4\u9ad8\u7684\u6ce8\u610f\u529b\u5206\u6570\u3002\u7136\u800c\uff0c\u90a3\u4e9b\u4e0e\u6587\u672c\u76f8\u5173\u6027\u8f83\u4f4e\u7684\u56fe\u50cf\u6807\u8bb0\u6ca1\u6709\u4fe1\u606f\u6d41\u6536\u655b\uff0c\u800c\u4e14\u5b83\u4eec\u53ea\u83b7\u5f97\u975e\u5e38\u5c0f\u7684\u6ce8\u610f\u529b\u5206\u6570\u3002\u4e3a\u4e86\u6709\u6548\u5229\u7528\u56fe\u50cf\u4fe1\u606f\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u50cf\u6807\u8bb0\u7b80\u5316\u65b9\u6cd5 Simignore\uff0c\u5176\u65e8\u5728\u901a\u8fc7\u8ba1\u7b97\u56fe\u50cf\u548c\u6587\u672c\u5d4c\u5165\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u5e76\u5ffd\u7565\u4e0e\u6587\u672c\u65e0\u5173\u4e14\u4e0d\u91cd\u8981\u7684\u56fe\u50cf\u6807\u8bb0\u6765\u63d0\u9ad8 LLVMs \u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u5bf9\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6709\u6548\u6027\u3002\u672c\u6587\u7684\u6e90\u4ee3\u7801\u53ef\u4ee5\u4ece \\url{https://github.com/FanshuoZeng/Simignore} \u8bbf\u95ee\u3002", "author": "Xiaofeng Zhang et.al.", "authors": "Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao", "id": "2412.09817v1", "paper_url": "http://arxiv.org/abs/2412.09817v1", "repo": "https://github.com/fanshuozeng/simignore"}}