{"2406.02253": {"publish_time": "2024-06-04", "title": "PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models", "paper_summary": "The recently proposed facial cloaking attacks add invisible perturbation\n(cloaks) to facial images to protect users from being recognized by\nunauthorized facial recognition models. However, we show that the \"cloaks\" are\nnot robust enough and can be removed from images.\n  This paper introduces PuFace, an image purification system leveraging the\ngeneralization ability of neural networks to diminish the impact of cloaks by\npushing the cloaked images towards the manifold of natural (uncloaked) images\nbefore the training process of facial recognition models. Specifically, we\ndevise a purifier that takes all the training images including both cloaked and\nnatural images as input and generates the purified facial images close to the\nmanifold where natural images lie. To meet the defense goal, we propose to\ntrain the purifier on particularly amplified cloaked images with a loss\nfunction that combines image loss and feature loss. Our empirical experiment\nshows PuFace can effectively defend against two state-of-the-art facial\ncloaking attacks and reduces the attack success rate from 69.84\\% to 7.61\\% on\naverage without degrading the normal accuracy for various facial recognition\nmodels. Moreover, PuFace is a model-agnostic defense mechanism that can be\napplied to any facial recognition model without modifying the model structure.", "paper_summary_zh": "\u6700\u8fd1\u63d0\u51fa\u7684\u9762\u90e8\u96b1\u5f62\u653b\u64ca\u6703\u5728\u9762\u90e8\u5f71\u50cf\u4e2d\u52a0\u5165\u4e0d\u53ef\u898b\u7684\u64fe\u52d5\uff08\u96b1\u5f62\u6597\u7bf7\uff09\uff0c\u4ee5\u4fdd\u8b77\u4f7f\u7528\u8005\u4e0d\u88ab\u672a\u7d93\u6388\u6b0a\u7684\u9762\u90e8\u8fa8\u8b58\u6a21\u578b\u8fa8\u8b58\u51fa\u4f86\u3002\u7136\u800c\uff0c\u6211\u5011\u8b49\u660e\u300c\u96b1\u5f62\u6597\u7bf7\u300d\u4e0d\u5920\u5f37\u5927\uff0c\u800c\u4e14\u53ef\u4ee5\u5f9e\u5f71\u50cf\u4e2d\u79fb\u9664\u3002\n\u9019\u7bc7\u8ad6\u6587\u4ecb\u7d39\u4e86 PuFace\uff0c\u9019\u662f\u4e00\u500b\u5f71\u50cf\u6de8\u5316\u7cfb\u7d71\uff0c\u5b83\u5229\u7528\u795e\u7d93\u7db2\u8def\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u9762\u90e8\u8fa8\u8b58\u6a21\u578b\u7684\u8a13\u7df4\u8655\u7406\u524d\uff0c\u5c07\u96b1\u5f62\u6597\u7bf7\u7684\u5f71\u50cf\u63a8\u5411\u81ea\u7136\uff08\u672a\u96b1\u5f62\uff09\u5f71\u50cf\u7684\u591a\u6a23\u9ad4\uff0c\u4ee5\u6e1b\u8f15\u96b1\u5f62\u6597\u7bf7\u7684\u5f71\u97ff\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u6de8\u5316\u5668\uff0c\u5b83\u5c07\u6240\u6709\u8a13\u7df4\u5f71\u50cf\uff08\u5305\u62ec\u96b1\u5f62\u6597\u7bf7\u548c\u81ea\u7136\u5f71\u50cf\uff09\u4f5c\u70ba\u8f38\u5165\uff0c\u4e26\u7522\u751f\u63a5\u8fd1\u81ea\u7136\u5f71\u50cf\u6240\u5728\u591a\u6a23\u9ad4\u7684\u6de8\u5316\u9762\u90e8\u5f71\u50cf\u3002\u70ba\u4e86\u9054\u5230\u9632\u79a6\u76ee\u6a19\uff0c\u6211\u5011\u5efa\u8b70\u5728\u7279\u5225\u653e\u5927\u7684\u96b1\u5f62\u6597\u7bf7\u5f71\u50cf\u4e0a\u8a13\u7df4\u6de8\u5316\u5668\uff0c\u4e26\u4f7f\u7528\u7d50\u5408\u4e86\u5f71\u50cf\u640d\u5931\u548c\u7279\u5fb5\u640d\u5931\u7684\u640d\u5931\u51fd\u6578\u3002\u6211\u5011\u7684\u5be6\u8b49\u5be6\u9a57\u986f\u793a\uff0cPuFace \u53ef\u4ee5\u6709\u6548\u9632\u79a6\u5169\u7a2e\u6700\u5148\u9032\u7684\u9762\u90e8\u96b1\u5f62\u653b\u64ca\uff0c\u4e26\u4e14\u5c07\u653b\u64ca\u6210\u529f\u7387\u5f9e 69.84% \u964d\u4f4e\u5230 7.61%\uff0c\u5e73\u5747\u800c\u8a00\uff0c\u4e0d\u6703\u964d\u4f4e\u5404\u7a2e\u9762\u90e8\u8fa8\u8b58\u6a21\u578b\u7684\u6b63\u5e38\u6e96\u78ba\u5ea6\u3002\u6b64\u5916\uff0cPuFace \u662f\u4e00\u7a2e\u8207\u6a21\u578b\u7121\u95dc\u7684\u9632\u79a6\u6a5f\u5236\uff0c\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u7d50\u69cb\u7684\u60c5\u6cc1\u4e0b\u61c9\u7528\u65bc\u4efb\u4f55\u9762\u90e8\u8fa8\u8b58\u6a21\u578b\u3002", "author": "Jing Wen et.al.", "authors": "Jing Wen", "id": "2406.02253v1", "paper_url": "http://arxiv.org/abs/2406.02253v1", "repo": "null"}}