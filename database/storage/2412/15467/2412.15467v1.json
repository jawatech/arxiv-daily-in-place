{"2412.15467": {"publish_time": "2024-12-20", "title": "Non-Uniform Parameter-Wise Model Merging", "paper_summary": "Combining multiple machine learning models has long been a technique for\nenhancing performance, particularly in distributed settings. Traditional\napproaches, such as model ensembles, work well, but are expensive in terms of\nmemory and compute. Recently, methods based on averaging model parameters have\nachieved good results in some settings and have gained popularity. However,\nmerging models initialized differently that do not share a part of their\ntraining trajectories can yield worse results than simply using the base\nmodels, even after aligning their neurons. In this paper, we introduce a novel\napproach, Non-uniform Parameter-wise Model Merging, or NP Merge, which merges\nmodels by learning the contribution of each parameter to the final model using\ngradient-based optimization. We empirically demonstrate the effectiveness of\nour method for merging models of various architectures in multiple settings,\noutperforming past methods. We also extend NP Merge to handle the merging of\nmultiple models, showcasing its scalability and robustness.", "paper_summary_zh": "\u5c07\u591a\u500b\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7d50\u5408\u5728\u4e00\u8d77\uff0c\u4e00\u76f4\u4ee5\u4f86\u90fd\u662f\u4e00\u7a2e\u589e\u5f37\u6548\u80fd\u7684\u6280\u8853\uff0c\u7279\u5225\u662f\u5728\u5206\u6563\u5f0f\u8a2d\u5b9a\u4e2d\u3002\u50b3\u7d71\u65b9\u6cd5\uff0c\u4f8b\u5982\u6a21\u578b\u7d44\u5408\uff0c\u6548\u679c\u5f88\u597d\uff0c\u4f46\u5728\u8a18\u61b6\u9ad4\u548c\u904b\u7b97\u65b9\u9762\u6210\u672c\u5f88\u9ad8\u3002\u6700\u8fd1\uff0c\u57fa\u65bc\u5e73\u5747\u6a21\u578b\u53c3\u6578\u7684\u65b9\u6cd5\u5728\u67d0\u4e9b\u8a2d\u5b9a\u4e2d\u53d6\u5f97\u4e86\u4e0d\u932f\u7684\u6210\u679c\uff0c\u4e26\u7372\u5f97\u4e86\u666e\u53ca\u3002\u7136\u800c\uff0c\u5408\u4f75\u521d\u59cb\u5316\u4e0d\u540c\u7684\u6a21\u578b\uff0c\u9019\u4e9b\u6a21\u578b\u6c92\u6709\u5171\u7528\u5176\u8a13\u7df4\u8ecc\u8de1\u7684\u4e00\u90e8\u5206\uff0c\u53ef\u80fd\u6703\u7522\u751f\u6bd4\u50c5\u4f7f\u7528\u57fa\u790e\u6a21\u578b\u66f4\u5dee\u7684\u7d50\u679c\uff0c\u5373\u4f7f\u5728\u8abf\u6574\u5176\u795e\u7d93\u5143\u4e4b\u5f8c\u4e5f\u662f\u5982\u6b64\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u975e\u5747\u52fb\u53c3\u6578\u6a21\u578b\u5408\u4f75\uff0c\u6216 NP Merge\uff0c\u5b83\u901a\u904e\u4f7f\u7528\u57fa\u65bc\u68af\u5ea6\u7684\u6700\u4f73\u5316\u4f86\u5b78\u7fd2\u6bcf\u500b\u53c3\u6578\u5c0d\u6700\u7d42\u6a21\u578b\u7684\u8ca2\u737b\uff0c\u5f9e\u800c\u5408\u4f75\u6a21\u578b\u3002\u6211\u5011\u5be6\u8b49\u5c55\u793a\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u591a\u7a2e\u8a2d\u5b9a\u4e2d\u5408\u4f75\u5404\u7a2e\u67b6\u69cb\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5176\u6548\u80fd\u512a\u65bc\u904e\u53bb\u7684\u65b9\u6cd5\u3002\u6211\u5011\u9084\u64f4\u5145\u4e86 NP Merge \u4ee5\u8655\u7406\u591a\u500b\u6a21\u578b\u7684\u5408\u4f75\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u64f4\u5145\u6027\u548c\u7a69\u5065\u6027\u3002", "author": "Albert Manuel Orozco Camacho et.al.", "authors": "Albert Manuel Orozco Camacho, Stefan Horoi, Guy Wolf, Eugene Belilovsky", "id": "2412.15467v1", "paper_url": "http://arxiv.org/abs/2412.15467v1", "repo": "null"}}