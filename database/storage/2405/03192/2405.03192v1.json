{"2405.03192": {"publish_time": "2024-05-06", "title": "QuadraNet V2: Efficient and Sustainable Training of High-Order Neural Networks with Quadratic Adaptation", "paper_summary": "Machine learning is evolving towards high-order models that necessitate\npre-training on extensive datasets, a process associated with significant\noverheads. Traditional models, despite having pre-trained weights, are becoming\nobsolete due to architectural differences that obstruct the effective transfer\nand initialization of these weights. To address these challenges, we introduce\na novel framework, QuadraNet V2, which leverages quadratic neural networks to\ncreate efficient and sustainable high-order learning models. Our method\ninitializes the primary term of the quadratic neuron using a standard neural\nnetwork, while the quadratic term is employed to adaptively enhance the\nlearning of data non-linearity or shifts. This integration of pre-trained\nprimary terms with quadratic terms, which possess advanced modeling\ncapabilities, significantly augments the information characterization capacity\nof the high-order network. By utilizing existing pre-trained weights, QuadraNet\nV2 reduces the required GPU hours for training by 90\\% to 98.4\\% compared to\ntraining from scratch, demonstrating both efficiency and effectiveness.", "paper_summary_zh": "", "author": "Chenhui Xu et.al.", "authors": "Chenhui Xu,Xinyao Wang,Fuxun Yu,JInjun Xiong,Xiang Chen", "id": "2405.03192v1", "paper_url": "http://arxiv.org/abs/2405.03192v1", "repo": "null"}}