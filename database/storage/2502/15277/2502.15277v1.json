{"2502.15277": {"publish_time": "2025-02-21", "title": "Analyzing the Inner Workings of Transformers in Compositional Generalization", "paper_summary": "The compositional generalization abilities of neural models have been sought\nafter for human-like linguistic competence. The popular method to evaluate such\nabilities is to assess the models' input-output behavior. However, that does\nnot reveal the internal mechanisms, and the underlying competence of such\nmodels in compositional generalization remains unclear. To address this\nproblem, we explore the inner workings of a Transformer model by finding an\nexisting subnetwork that contributes to the generalization performance and by\nperforming causal analyses on how the model utilizes syntactic features. We\nfind that the model depends on syntactic features to output the correct answer,\nbut that the subnetwork with much better generalization performance than the\nwhole model relies on a non-compositional algorithm in addition to the\nsyntactic features. We also show that the subnetwork improves its\ngeneralization performance relatively slowly during the training compared to\nthe in-distribution one, and the non-compositional solution is acquired in the\nearly stages of the training.", "paper_summary_zh": "\u795e\u7ecf\u6a21\u578b\u7684\u7d44\u5408\u6982\u5316\u80fd\u529b\u4e00\u76f4\u662f\u4eba\u985e\u8a9e\u8a00\u80fd\u529b\u7684\u8ffd\u6c42\u3002\u8a55\u4f30\u9019\u7a2e\u80fd\u529b\u7684\u6d41\u884c\u65b9\u6cd5\u662f\u8a55\u4f30\u6a21\u578b\u7684\u8f38\u5165\u8f38\u51fa\u884c\u70ba\u3002\u7136\u800c\uff0c\u9019\u4e26\u672a\u63ed\u793a\u5167\u90e8\u6a5f\u5236\uff0c\u800c\u9019\u7a2e\u6a21\u578b\u5728\u7d44\u5408\u6982\u5316\u4e2d\u7684\u57fa\u672c\u80fd\u529b\u4ecd\u7136\u4e0d\u660e\u78ba\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u900f\u904e\u5c0b\u627e\u4e00\u500b\u6709\u52a9\u65bc\u6982\u5316\u6548\u80fd\u7684\u73fe\u6709\u5b50\u7db2\u8def\uff0c\u4e26\u5c0d\u6a21\u578b\u5982\u4f55\u5229\u7528\u53e5\u6cd5\u7279\u5fb5\u9032\u884c\u56e0\u679c\u5206\u6790\uff0c\u4f86\u63a2\u8a0e Transformer \u6a21\u578b\u7684\u5167\u90e8\u904b\u4f5c\u3002\u6211\u5011\u767c\u73fe\u6a21\u578b\u4f9d\u8cf4\u65bc\u53e5\u6cd5\u7279\u5fb5\u4f86\u8f38\u51fa\u6b63\u78ba\u7684\u7b54\u6848\uff0c\u4f46\u6982\u5316\u6548\u80fd\u9060\u512a\u65bc\u6574\u500b\u6a21\u578b\u7684\u5b50\u7db2\u8def\u4f9d\u8cf4\u65bc\u975e\u7d44\u5408\u6f14\u7b97\u6cd5\u4ee5\u53ca\u53e5\u6cd5\u7279\u5fb5\u3002\u6211\u5011\u9084\u8868\u660e\uff0c\u8207\u5206\u4f48\u5167\u5b50\u7db2\u8def\u76f8\u6bd4\uff0c\u5b50\u7db2\u8def\u5728\u8a13\u7df4\u671f\u9593\u63d0\u9ad8\u5176\u6982\u5316\u6548\u80fd\u7684\u901f\u5ea6\u76f8\u5c0d\u8f03\u6162\uff0c\u4e26\u4e14\u5728\u8a13\u7df4\u7684\u65e9\u671f\u968e\u6bb5\u7372\u5f97\u975e\u7d44\u5408\u89e3\u3002", "author": "Ryoma Kumon et.al.", "authors": "Ryoma Kumon, Hitomi Yanaka", "id": "2502.15277v1", "paper_url": "http://arxiv.org/abs/2502.15277v1", "repo": "null"}}