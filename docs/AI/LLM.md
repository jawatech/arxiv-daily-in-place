
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-31**|**Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach**|Yingdan Shi et.al.|[2501.19403v1](http://arxiv.org/abs/2501.19403v1)|null|
|**2025-01-31**|**Vintix: Action Model via In-Context Reinforcement Learning**|Andrey Polubarov et.al.|[2501.19400v1](http://arxiv.org/abs/2501.19400v1)|[link](https://github.com/dunnolab/vintix)|
|**2025-01-31**|**Scalable-Softmax Is Superior for Attention**|Ken M. Nakanishi et.al.|[2501.19399v1](http://arxiv.org/abs/2501.19399v1)|null|
|**2025-01-31**|**Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game**|Mustafa O. Karabag et.al.|[2501.19398v1](http://arxiv.org/abs/2501.19398v1)|[link](https://github.com/mustafakarabag/llmchameleon)|
|**2025-01-31**|**s1: Simple test-time scaling**|Niklas Muennighoff et.al.|[2501.19393v2](http://arxiv.org/abs/2501.19393v2)|[link](https://github.com/simplescaling/s1)|
|**2025-01-31**|**Decoding-based Regression**|Xingyou Song et.al.|[2501.19383v1](http://arxiv.org/abs/2501.19383v1)|[link](https://github.com/google-research/optformer)|
|**2025-01-31**|**TableMaster: A Recipe to Advance Table Understanding with Language Models**|Lang Cao et.al.|[2501.19378v1](http://arxiv.org/abs/2501.19378v1)|null|
|**2025-01-31**|**SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions**|Dominik Wagner et.al.|[2501.19377v2](http://arxiv.org/abs/2501.19377v2)|null|
|**2025-01-31**|**CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation**|Javier Solís-García et.al.|[2501.19364v1](http://arxiv.org/abs/2501.19364v1)|[link](https://github.com/javiersgjavi/costi)|
|**2025-01-31**|**We're Different, We're the Same: Creative Homogeneity Across LLMs**|Emily Wenger et.al.|[2501.19361v1](http://arxiv.org/abs/2501.19361v1)|null|
|**2025-01-31**|**Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023**|Ting-Yao E. Hsu et.al.|[2501.19353v1](http://arxiv.org/abs/2501.19353v1)|null|
|**2025-01-31**|**PixelWorld: Towards Perceiving Everything as Pixels**|Zhiheng Lyu et.al.|[2501.19339v1](http://arxiv.org/abs/2501.19339v1)|null|
|**2025-01-31**|**Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**|Misha P. T Kaandorp et.al.|[2501.19338v1](http://arxiv.org/abs/2501.19338v1)|null|
|**2025-01-31**|**Homogeneity Bias as Differential Sampling Uncertainty in Language Models**|Messi H. J. Lee et.al.|[2501.19337v1](http://arxiv.org/abs/2501.19337v1)|null|
|**2025-01-31**|**What is causal about causal models and representations?**|Frederik Hytting Jørgensen et.al.|[2501.19335v2](http://arxiv.org/abs/2501.19335v2)|null|
|**2025-01-31**|**Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation**|Jan Pauls et.al.|[2501.19328v1](http://arxiv.org/abs/2501.19328v1)|null|
|**2025-01-31**|**Reward-Guided Speculative Decoding for Efficient LLM Reasoning**|Baohao Liao et.al.|[2501.19324v1](http://arxiv.org/abs/2501.19324v1)|null|
|**2025-01-31**|**Language Bias in Self-Supervised Learning For Automatic Speech Recognition**|Edward Storey et.al.|[2501.19321v1](http://arxiv.org/abs/2501.19321v1)|null|
|**2025-01-31**|**MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems**|Anirudh Chari et.al.|[2501.19318v1](http://arxiv.org/abs/2501.19318v1)|null|
|**2025-01-31**|**LLM-based Affective Text Generation Quality Based on Different Quantization Values**|Yarik Menchaca Resendiz et.al.|[2501.19317v1](http://arxiv.org/abs/2501.19317v1)|null|
|**2025-01-31**|**Reverse Probing: Evaluating Knowledge Transfer via Finetuned Task Embeddings for Coreference Resolution**|Tatiana Anikina et.al.|[2501.19316v1](http://arxiv.org/abs/2501.19316v1)|null|
|**2025-01-31**|**An Efficient Approach for Machine Translation on Low-resource Languages: A Case Study in Vietnamese-Chinese**|Tran Ngoc Son et.al.|[2501.19314v1](http://arxiv.org/abs/2501.19314v1)|null|
|**2025-01-31**|**Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment**|Gregor Bachmann et.al.|[2501.19309v1](http://arxiv.org/abs/2501.19309v1)|null|
|**2025-01-31**|**SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling**|Jiefeng Chen et.al.|[2501.19306v2](http://arxiv.org/abs/2501.19306v2)|null|
|**2025-01-31**|**Beyond checkmate: exploring the creative chokepoints in AI text**|Nafis Irtiza Tripto et.al.|[2501.19301v1](http://arxiv.org/abs/2501.19301v1)|[link](https://github.com/tripto03/chess_inspired_human_ai_text_distinction)|
|**2025-01-31**|**Synthetic User Behavior Sequence Generation with Large Language Models for Smart Homes**|Zhiyao Xu et.al.|[2501.19298v1](http://arxiv.org/abs/2501.19298v1)|null|
|**2025-01-31**|**Analysis of LLMs vs Human Experts in Requirements Engineering**|Cory Hymel et.al.|[2501.19297v1](http://arxiv.org/abs/2501.19297v1)|null|
|**2025-01-31**|**Pheromone-based Learning of Optimal Reasoning Paths**|Anirudh Chari et.al.|[2501.19278v1](http://arxiv.org/abs/2501.19278v1)|null|
|**2025-01-31**|**Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**|Halil Ibrahim Aysel et.al.|[2501.19271v1](http://arxiv.org/abs/2501.19271v1)|null|
|**2025-01-31**|**Jackpot! Alignment as a Maximal Lottery**|Roberto-Rafael Maura-Rivero et.al.|[2501.19266v1](http://arxiv.org/abs/2501.19266v1)|null|
|**2025-01-31**|**mFollowIR: a Multilingual Benchmark for Instruction Following in Retrieval**|Orion Weller et.al.|[2501.19264v1](http://arxiv.org/abs/2501.19264v1)|[link](https://github.com/orionw/followir)|
|**2025-01-31**|**VisualSpeech: Enhance Prosody with Visual Context in TTS**|Shumin Que et.al.|[2501.19258v1](http://arxiv.org/abs/2501.19258v1)|null|
|**2025-01-31**|**SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments**|Hüseyin Aydın et.al.|[2501.19245v2](http://arxiv.org/abs/2501.19245v2)|null|
|**2025-01-31**|**A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation**|Yunzhe Li et.al.|[2501.19232v1](http://arxiv.org/abs/2501.19232v1)|null|
|**2025-01-31**|**Integrating Semi-Supervised and Active Learning for Semantic Segmentation**|Wanli Ma et.al.|[2501.19227v1](http://arxiv.org/abs/2501.19227v1)|null|
|**2025-01-31**|**Improving the Robustness of Representation Misdirection for Large Language Model Unlearning**|Dang Huu-Tien et.al.|[2501.19202v2](http://arxiv.org/abs/2501.19202v2)|[link](https://github.com/rebelsnlu-jaist/llmu-robustness)|
|**2025-01-31**|**Efficient Reasoning with Hidden Thinking**|Xuan Shen et.al.|[2501.19201v1](http://arxiv.org/abs/2501.19201v1)|[link](https://github.com/shawnricecake/heima)|
|**2025-01-31**|**Secured Communication Schemes for UAVs in 5G: CRYSTALS-Kyber and IDS**|Taneya Sharma et.al.|[2501.19191v1](http://arxiv.org/abs/2501.19191v1)|[link](https://github.com/taneya1987/crystals-kyber-and-ids)|
|**2025-01-31**|**Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning**|Xianglin Yang et.al.|[2501.19180v1](http://arxiv.org/abs/2501.19180v1)|null|
|**2025-01-31**|**Improving Multi-Label Contrastive Learning by Leveraging Label Distribution**|Ning Chen et.al.|[2501.19145v1](http://arxiv.org/abs/2501.19145v1)|null|
|**2025-01-31**|**Imitation Game for Adversarial Disillusion with Multimodal Generative Chain-of-Thought Role-Play**|Ching-Chun Chang et.al.|[2501.19143v1](http://arxiv.org/abs/2501.19143v1)|null|
|**2025-01-31**|**A Metric for the Balance of Information in Graph Learning**|Alex O. Davies et.al.|[2501.19137v1](http://arxiv.org/abs/2501.19137v1)|null|
|**2025-01-31**|**Mixed Feelings: Cross-Domain Sentiment Classification of Patient Feedback**|Egil Rønningstad et.al.|[2501.19134v1](http://arxiv.org/abs/2501.19134v1)|null|
|**2025-01-31**|**FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling**|Hong Huang et.al.|[2501.19122v1](http://arxiv.org/abs/2501.19122v1)|null|
|**2025-01-31**|**Principal Components for Neural Network Initialization**|Nhan Phan et.al.|[2501.19114v1](http://arxiv.org/abs/2501.19114v1)|null|
|**2025-01-31**|**PathE: Leveraging Entity-Agnostic Paths for Parameter-Efficient Knowledge Graph Embeddings**|Ioannis Reklos et.al.|[2501.19095v1](http://arxiv.org/abs/2501.19095v1)|[link](https://github.com/ireklos/pathe)|
|**2025-01-31**|**Improving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations**|Peichao Lai et.al.|[2501.19093v1](http://arxiv.org/abs/2501.19093v1)|null|
|**2025-01-31**|**Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**|Xiangyu Sun et.al.|[2501.19086v1](http://arxiv.org/abs/2501.19086v1)|null|
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-31**|**BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting**|Zhixuan Li et.al.|[2501.19065v1](http://arxiv.org/abs/2501.19065v1)|null|
|**2025-01-31**|**Enabling Autonomic Microservice Management through Self-Learning Agents**|Fenglin Yu et.al.|[2501.19056v1](http://arxiv.org/abs/2501.19056v1)|null|
|**2025-01-31**|**Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer**|Lingwei Zhu et.al.|[2501.19055v1](http://arxiv.org/abs/2501.19055v1)|null|
|**2025-01-31**|**Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)**|Maja Pavlovic et.al.|[2501.19047v2](http://arxiv.org/abs/2501.19047v2)|null|
|**2025-01-31**|**Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors**|Simon Idoko et.al.|[2501.19042v1](http://arxiv.org/abs/2501.19042v1)|[link](https://github.com/cisimon7/swarmgen)|
|**2025-01-31**|**On the Impact of Noise in Differentially Private Text Rewriting**|Stephen Meisenbacher et.al.|[2501.19022v1](http://arxiv.org/abs/2501.19022v1)|[link](https://github.com/sjmeis/privfill)|
|**2025-01-31**|**Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses**|Ahmed K. Kadhim et.al.|[2501.19018v2](http://arxiv.org/abs/2501.19018v2)|null|
|**2025-01-31**|**Calling a Spade a Heart: Gaslighting Multimodal Large Language Models via Negation**|Bin Zhu et.al.|[2501.19017v1](http://arxiv.org/abs/2501.19017v1)|null|
|**2025-01-31**|**Importing Phantoms: Measuring LLM Package Hallucination Vulnerabilities**|Arjun Krishna et.al.|[2501.19012v1](http://arxiv.org/abs/2501.19012v1)|null|
|**2025-01-31**|**DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition**|Wonjun Lee et.al.|[2501.19010v2](http://arxiv.org/abs/2501.19010v2)|null|
|**2025-01-31**|**Virtual airways heatmaps to optimize point of entry location in lung biopsy planning systems**|Debora Gil et.al.|[2501.19003v1](http://arxiv.org/abs/2501.19003v1)|null|
|**2025-01-31**|**Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings**|Ahmed K. Kadhim et.al.|[2501.18998v1](http://arxiv.org/abs/2501.18998v1)|null|
|**2025-01-31**|**VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian Extended Kalman Filter Integration**|Jian-Yu Chen et.al.|[2501.18994v1](http://arxiv.org/abs/2501.18994v1)|[link](https://github.com/ipclab/vkfpos)|
|**2025-01-31**|**Symmetric Pruning of Large Language Models**|Kai Yi et.al.|[2501.18980v1](http://arxiv.org/abs/2501.18980v1)|null|
|**2025-01-31**|**GPO-VAE: Modeling Explainable Gene Perturbation Responses utilizing GRN-Aligned Parameter Optimization**|Seungheun Baek et.al.|[2501.18973v1](http://arxiv.org/abs/2501.18973v1)|[link](https://github.com/dmis-lab/gpo-vae)|
|**2025-01-31**|**Intrinsic Tensor Field Propagation in Large Language Models: A Novel Approach to Contextual Information Flow**|Alfred Bexley et.al.|[2501.18957v1](http://arxiv.org/abs/2501.18957v1)|null|
|**2025-01-31**|**Deep Learning based Quasi-consciousness Training for Robot Intelligent Model**|Yuchun Li et.al.|[2501.18955v1](http://arxiv.org/abs/2501.18955v1)|null|
|**2025-01-31**|**Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them**|Anh Bui et.al.|[2501.18950v1](http://arxiv.org/abs/2501.18950v1)|[link](https://github.com/tuananhbui89/adaptive-guided-erasure)|
|**2025-01-31**|**Language Games as the Pathway to Artificial Superhuman Intelligence**|Ying Wen et.al.|[2501.18924v1](http://arxiv.org/abs/2501.18924v1)|null|
|**2025-01-31**|**KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search**|Haoran Luo et.al.|[2501.18922v1](http://arxiv.org/abs/2501.18922v1)|[link](https://github.com/lhrlab/kbqa-o1)|
|**2025-01-31**|**Deepfake Detection of Singing Voices With Whisper Encodings**|Falguni Sharma et.al.|[2501.18919v1](http://arxiv.org/abs/2501.18919v1)|null|
|**2025-01-31**|**Lightspeed Geometric Dataset Distance via Sliced Optimal Transport**|Khai Nguyen et.al.|[2501.18901v1](http://arxiv.org/abs/2501.18901v1)|null|
|**2025-01-31**|**Efficient Supernet Training with Orthogonal Softmax for Scalable ASR Model Compression**|Jingjing Xu et.al.|[2501.18895v1](http://arxiv.org/abs/2501.18895v1)|null|
|**2025-01-31**|**Building Bridges, Not Walls -- Advancing Interpretability by Unifying Feature, Data, and Model Component Attribution**|Shichang Zhang et.al.|[2501.18887v1](http://arxiv.org/abs/2501.18887v1)|null|
|**2025-01-31**|**UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent**|Jianke Zhang et.al.|[2501.18867v2](http://arxiv.org/abs/2501.18867v2)|null|
|**2025-01-31**|**REG: Rectified Gradient Guidance for Conditional Diffusion Models**|Zhengqi Gao et.al.|[2501.18865v1](http://arxiv.org/abs/2501.18865v1)|null|
|**2025-01-31**|**BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning**|Han Zhong et.al.|[2501.18858v1](http://arxiv.org/abs/2501.18858v1)|null|
|**2025-01-31**|**Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities**|Yaping Chai et.al.|[2501.18845v1](http://arxiv.org/abs/2501.18845v1)|null|
|**2025-01-31**|**Partially Rewriting a Transformer in Natural Language**|Gonçalo Paulo et.al.|[2501.18838v1](http://arxiv.org/abs/2501.18838v1)|[link](https://github.com/eleutherai/sae-auto-interp)|
|**2025-01-31**|**Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming**|Mrinank Sharma et.al.|[2501.18837v1](http://arxiv.org/abs/2501.18837v1)|null|
|**2025-01-31**|**Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential**|Chenyu Gao et.al.|[2501.18834v1](http://arxiv.org/abs/2501.18834v1)|null|
|**2025-01-31**|**Structural Embedding Projection for Contextual Large Language Model Inference**|Vincent Enoasmo et.al.|[2501.18826v1](http://arxiv.org/abs/2501.18826v1)|null|
|**2025-01-31**|**Memory-Efficient Fine-Tuning of Transformers via Token Selection**|Antoine Simoulin et.al.|[2501.18824v1](http://arxiv.org/abs/2501.18824v1)|null|
|**2025-01-31**|**An Optimal Cascade Feature-Level Spatiotemporal Fusion Strategy for Anomaly Detection in CAN Bus**|Mohammad Fatahi et.al.|[2501.18821v1](http://arxiv.org/abs/2501.18821v1)|null|
|**2025-01-31**|**Bridging the Reasoning Gap: Small LLMs Can Plan with Generalised Strategies**|Andrey Borro et.al.|[2501.18817v1](http://arxiv.org/abs/2501.18817v1)|[link](https://github.com/andrey-borro/reasoning-gap)|
|**2025-01-31**|**Large Language Models as Common-Sense Heuristics**|Andrey Borro et.al.|[2501.18816v1](http://arxiv.org/abs/2501.18816v1)|null|
|**2025-01-31**|**An Adversarial Approach to Register Extreme Resolution Tissue Cleared 3D Brain Images**|Abdullah Naziba et.al.|[2501.18815v1](http://arxiv.org/abs/2501.18815v1)|[link](https://github.com/BioMedIA/IRTK)|
|**2025-01-30**|**Every Image Listens, Every Image Dances: Music-Driven Image Animation**|Zhikang Dong et.al.|[2501.18801v1](http://arxiv.org/abs/2501.18801v1)|null|
|**2025-01-30**|**Compositional Generalization Requires More Than Disentangled Representations**|Qiyao Liang et.al.|[2501.18797v1](http://arxiv.org/abs/2501.18797v1)|null|
|**2025-01-30**|**Rope to Nope and Back Again: A New Hybrid Attention Strategy**|Bowen Yang et.al.|[2501.18795v1](http://arxiv.org/abs/2501.18795v1)|null|
|**2025-01-30**|**Survey and Improvement Strategies for Gene Prioritization with Large Language Models**|Matthew Neeley et.al.|[2501.18794v1](http://arxiv.org/abs/2501.18794v1)|null|
|**2025-01-30**|**OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization**|Kelvin Kan et.al.|[2501.18793v1](http://arxiv.org/abs/2501.18793v1)|null|
|**2025-01-30**|**LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?**|Alexander Tuisov et.al.|[2501.18784v1](http://arxiv.org/abs/2501.18784v1)|null|
|**2025-01-30**|**Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation**|Muhammed Yusuf Kocyigit et.al.|[2501.18771v1](http://arxiv.org/abs/2501.18771v1)|null|
|**2025-01-30**|**Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization**|Michael S. Yao et.al.|[2501.18768v1](http://arxiv.org/abs/2501.18768v1)|[link](https://github.com/michael-s-yao/dynamo)|
|**2025-01-30**|**Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language**|Pronoy Kumar Mondal et.al.|[2501.18766v1](http://arxiv.org/abs/2501.18766v1)|null|
|**2025-01-30**|**Revisiting Projection-based Data Transfer for Cross-Lingual Named Entity Recognition in Low-Resource Languages**|Andrei Politov et.al.|[2501.18750v1](http://arxiv.org/abs/2501.18750v1)|[link](https://github.com/cross-lingual-ner/projection-data-transfer-cross-lingual-ner)|
|**2025-01-30**|**Synthetic Data Generation for Augmenting Small Samples**|Dan Liu et.al.|[2501.18741v1](http://arxiv.org/abs/2501.18741v1)|null|
|**2025-01-30**|**Neural Graph Pattern Machine**|Zehong Wang et.al.|[2501.18739v1](http://arxiv.org/abs/2501.18739v1)|null|
|**2025-01-30**|**Examining the Robustness of Large Language Models across Language Complexity**|Jiayi Zhang et.al.|[2501.18738v1](http://arxiv.org/abs/2501.18738v1)|null|
|**2025-01-30**|**Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation**|Yuelei Li et.al.|[2501.18733v1](http://arxiv.org/abs/2501.18733v1)|null|

#### Abstracts
##### **Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach**
2501.19403v1 by Yingdan Shi, Ren Wang

Machine unlearning seeks to systematically remove specified data from a
trained model, effectively achieving a state as though the data had never been
encountered during training. While metrics such as Unlearning Accuracy (UA) and
Membership Inference Attack (MIA) provide a baseline for assessing unlearning
performance, they fall short of evaluating the completeness and reliability of
forgetting. This is because the ground truth labels remain potential candidates
within the scope of uncertainty quantification, leaving gaps in the evaluation
of true forgetting. In this paper, we identify critical limitations in existing
unlearning metrics and propose enhanced evaluation metrics inspired by
conformal prediction. Our metrics can effectively capture the extent to which
ground truth labels are excluded from the prediction set. Furthermore, we
observe that many existing machine unlearning methods do not achieve
satisfactory forgetting performance when evaluated with our new metrics. To
address this, we propose an unlearning framework that integrates conformal
prediction insights into Carlini & Wagner adversarial attack loss. Extensive
experiments on the image classification task demonstrate that our enhanced
metrics offer deeper insights into unlearning effectiveness, and that our
unlearning framework significantly improves the forgetting quality of
unlearning methods.

摘要：機器去學習旨在系統性地從訓練好的模型中移除指定的資料，有效地達成一種狀態，就好像在訓練過程中從未遇到過資料一樣。雖然指標例如去學習準確度 (UA) 和成員推論攻擊 (MIA) 提供了一個評估去學習效能的基準，但他們無法評估遺忘的完整性和可靠性。這是因為基本事實標籤仍然是未確定量化範圍內的潛在候選者，在評估真正的遺忘時留下了空白。在本文中，我們找出現有去學習指標中的關鍵限制，並提出受共形預測啟發的增強評估指標。我們的指標可以有效捕捉基本事實標籤從預測集合中被排除的程度。此外，我們觀察到許多現有的機器去學習方法在使用我們的新指標評估時，無法達成令人滿意的遺忘效能。為了解決這個問題，我們提出一個去學習架構，將共形預測見解整合到 Carlini & Wagner 對抗攻擊損失中。在影像分類任務上的廣泛實驗證明，我們增強的指標對去學習有效性提供了更深入的見解，而且我們的去學習架構顯著地改善了去學習方法的遺忘品質。

##### **Vintix: Action Model via In-Context Reinforcement Learning**
2501.19400v1 by Andrey Polubarov, Nikita Lyubaykin, Alexander Derevyagin, Ilya Zisman, Denis Tarasov, Alexander Nikulin, Vladislav Kurenkov

In-Context Reinforcement Learning (ICRL) represents a promising paradigm for
developing generalist agents that learn at inference time through
trial-and-error interactions, analogous to how large language models adapt
contextually, but with a focus on reward maximization. However, the scalability
of ICRL beyond toy tasks and single-domain settings remains an open challenge.
In this work, we present the first steps toward scaling ICRL by introducing a
fixed, cross-domain model capable of learning behaviors through in-context
reinforcement learning. Our results demonstrate that Algorithm Distillation, a
framework designed to facilitate ICRL, offers a compelling and competitive
alternative to expert distillation to construct versatile action models. These
findings highlight the potential of ICRL as a scalable approach for generalist
decision-making systems. Code to be released at
https://github.com/dunnolab/vintix

摘要：情境強化學習 (ICRL) 代表一種有前途的典範，用於開發在推理時間透過試錯互動進行學習的通才代理，類似於大型語言模型如何根據情境進行調整，但重點在於獎勵最大化。然而，ICRL 的可擴展性超越玩具任務和單一領域設定仍然是一個公開的挑戰。在這項工作中，我們介紹了擴展 ICRL 的第一步，方法是引入一個固定的跨領域模型，能夠透過情境強化學習學習行為。我們的結果證明了演算法蒸餾（一種旨在促進 ICRL 的架構）提供了一個引人注目且具有競爭力的替代方案，可以用於專家蒸餾來建構多功能動作模型。這些發現突顯了 ICRL 作為通才決策系統的可擴展方法的潛力。程式碼將在 https://github.com/dunnolab/vintix 發布

##### **Scalable-Softmax Is Superior for Attention**
2501.19399v1 by Ken M. Nakanishi

The maximum element of the vector output by the Softmax function approaches
zero as the input vector size increases. Transformer-based language models rely
on Softmax to compute attention scores, causing the attention distribution to
flatten as the context size grows. This reduces the model's ability to
prioritize key information effectively and potentially limits its length
generalization. To address this problem, we propose Scalable-Softmax (SSMax),
which replaces Softmax in scenarios where the input vector size varies. SSMax
can be seamlessly integrated into existing Transformer-based architectures.
Experimental results in language modeling show that models using SSMax not only
achieve faster loss reduction during pretraining but also significantly improve
performance in long contexts and key information retrieval. Furthermore, an
analysis of attention scores reveals that SSMax enables the model to focus
attention on key information even in long contexts. Additionally, although
models that use SSMax from the beginning of pretraining achieve better length
generalization, those that have already started pretraining can still gain some
of this ability by replacing Softmax in the attention layers with SSMax, either
during or after pretraining.

摘要：随着输入向量大小的增加，Softmax 函数输出向量的最大元素接近于零。基于 Transformer 的语言模型依赖 Softmax 来计算注意力分数，导致注意力分布在上下文大小增长时趋于平坦。这降低了模型有效优先考虑关键信息的的能力，并可能限制其长度泛化。为了解决这个问题，我们提出了可扩展 Softmax (SSMax)，它在输入向量大小变化的情况下替换 Softmax。SSMax 可以无缝集成到现有的基于 Transformer 的架构中。语言建模的实验结果表明，使用 SSMax 的模型不仅在预训练期间实现了更快的损失降低，而且在长上下文和关键信息检索方面也显著提高了性能。此外，对注意力分数的分析表明，SSMax 使模型能够即使在长上下文中也能将注意力集中在关键信息上。此外，尽管从预训练开始就使用 SSMax 的模型实现了更好的长度泛化，但已经开始预训练的模型仍然可以通过在注意力层中用 SSMax 替换 Softmax（在预训练期间或之后）来获得一些这种能力。

##### **Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game**
2501.19398v1 by Mustafa O. Karabag, Ufuk Topcu

Large language model-based (LLM-based) agents have become common in settings
that include non-cooperative parties. In such settings, agents' decision-making
needs to conceal information from their adversaries, reveal information to
their cooperators, and infer information to identify the other agents'
characteristics. To investigate whether LLMs have these information control and
decision-making capabilities, we make LLM agents play the language-based
hidden-identity game, The Chameleon. In the game, a group of non-chameleon
agents who do not know each other aim to identify the chameleon agent without
revealing a secret. The game requires the aforementioned information control
capabilities both as a chameleon and a non-chameleon. The empirical results
show that while non-chameleon LLM agents identify the chameleon, they fail to
conceal the secret from the chameleon, and their winning probability is far
from the levels of even trivial strategies. To formally explain this behavior,
we give a theoretical analysis for a spectrum of strategies, from concealing to
revealing, and provide bounds on the non-chameleons' winning probability. Based
on the empirical results and theoretical analysis of different strategies, we
deduce that LLM-based non-chameleon agents reveal excessive information to
agents of unknown identities. Our results point to a weakness of contemporary
LLMs, including GPT-4, GPT-4o, Gemini 1.5, and Claude 3.5 Sonnet, in strategic
interactions.

摘要：<paragraph>基於大型語言模型 (LLM) 的代理已在包含非合作方的設定中變得常見。在這種設定中，代理的決策制定需要對其對手隱藏資訊、向其合作夥伴揭露資訊，並推論資訊以識別其他代理的特徵。為了調查 LLM 是否具備這些資訊控制和決策制定能力，我們讓 LLM 代理玩基於語言的隱藏身分遊戲，變色龍。在遊戲中，一群互不認識的非變色龍代理旨在識別變色龍代理，同時不透露秘密。該遊戲需要上述資訊控制能力，無論是作為變色龍還是非變色龍。實證結果表明，雖然非變色龍 LLM 代理識別出變色龍，但他們未能對變色龍隱藏秘密，而且他們的獲勝機率遠低於甚至微不足道的策略。為了正式解釋這種行為，我們對一系列策略進行了理論分析，從隱藏到揭露，並對非變色龍的獲勝機率提供了界限。根據不同策略的實證結果和理論分析，我們推論出基於 LLM 的非變色龍代理會向身分不明的代理透露過多資訊。我們的結果指出，當代 LLM 的一個弱點，包括 GPT-4、GPT-4o、Gemini 1.5 和 Claude 3.5 Sonnet，在策略互動中。</paragraph>

##### **s1: Simple test-time scaling**
2501.19393v2 by Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, Tatsunori Hashimoto

Test-time scaling is a promising new approach to language modeling that uses
extra test-time compute to improve performance. Recently, OpenAI's o1 model
showed this capability but did not publicly share its methodology, leading to
many replication efforts. We seek the simplest approach to achieve test-time
scaling and strong reasoning performance. First, we curate a small dataset s1K
of 1,000 questions paired with reasoning traces relying on three criteria we
validate through ablations: difficulty, diversity, and quality. Second, we
develop budget forcing to control test-time compute by forcefully terminating
the model's thinking process or lengthening it by appending "Wait" multiple
times to the model's generation when it tries to end. This can lead the model
to double-check its answer, often fixing incorrect reasoning steps. After
supervised finetuning the Qwen2.5-32B-Instruct language model on s1K and
equipping it with budget forcing, our model s1-32B exceeds o1-preview on
competition math questions by up to 27% (MATH and AIME24). Further, scaling
s1-32B with budget forcing allows extrapolating beyond its performance without
test-time intervention: from 50% to 57% on AIME24. Our model, data, and code
are open-source at https://github.com/simplescaling/s1

摘要：測試時間縮放是語言建模的一種有前途的新方法，它使用額外的測試時間計算來提升效能。最近，OpenAI 的 o1 模型展示了這種能力，但沒有公開分享其方法，導致許多複製工作。我們尋求最簡單的方法來實現測試時間縮放和強大的推理效能。首先，我們整理一個包含 1,000 個問題的小型資料集 s1K，並根據我們透過消融驗證的三個準則配對推理追蹤：難度、多樣性和品質。其次，我們開發預算強制來控制測試時間計算，方法是強制終止模型的思考過程，或在模型嘗試結束時多次附加「等待」來延長思考過程。這可能會導致模型仔細檢查其答案，通常會修正不正確的推理步驟。在對 Qwen2.5-32B-Instruct 語言模型進行監督微調並配備預算強制後，我們的模型 s1-32B 在競賽數學問題上超過 o1-preview，最多達 27%（MATH 和 AIME24）。此外，使用預算強制縮放 s1-32B 可以推演出超越其效能的表現，而無需測試時間介入：在 AIME24 上從 50% 提升到 57%。我們的模型、資料和程式碼在 https://github.com/simplescaling/s1 以開放原始碼形式提供

##### **Decoding-based Regression**
2501.19383v1 by Xingyou Song, Dara Bahri

Language models have recently been shown capable of performing regression
tasks wherein numeric predictions are represented as decoded strings. In this
work, we provide theoretical grounds for this capability and furthermore
investigate the utility of causal auto-regressive sequence models when they are
applied to any feature representation. We find that, despite being trained in
the usual way - for next-token prediction via cross-entropy loss -
decoding-based regression is as performant as traditional approaches for
tabular regression tasks, while being flexible enough to capture arbitrary
distributions, such as in the task of density estimation.

摘要：最近已證明語言模型有能力執行回歸任務，其中數值預測表示為解碼字串。在這項工作中，我們為此能力提供理論基礎，並進一步探討因果自回歸序列模型在應用於任何特徵表示時之效用。我們發現，儘管以傳統方式進行訓練（透過交叉熵損失進行下一個符號預測），但基於解碼的回歸與傳統方法一樣適用於表格回歸任務，同時足夠靈活以捕捉任意分佈，例如在密度估計任務中。

##### **TableMaster: A Recipe to Advance Table Understanding with Language Models**
2501.19378v1 by Lang Cao

Tables serve as a fundamental format for representing structured relational
data. While current language models (LMs) excel at many text-based tasks, they
still face challenges in table understanding due to the complex characteristics
of tabular data, such as their structured nature. In this paper, we aim to
enhance LMs for improved table understanding. We identify four key challenges:
1) difficulty in locating target data, 2) deficiency in table semantics, 3)
numerical inaccuracies in textual reasoning, and 4) semantic inflexibility in
symbolic reasoning. To address these issues, we propose TableMaster, a recipe
and comprehensive framework that integrates multiple solutions to overcome
these obstacles. TableMaster first extracts relevant table content and
verbalizes it with enriched semantic context. Additionally, we introduce
adaptive reasoning, a flexible approach that dynamically adjusts between
textual and symbolic reasoning, tailoring the reasoning process to each query.
Extensive analyses and experiments demonstrate our findings and the
effectiveness of TableMaster. On the WikiTQ dataset, TableMaster achieves an
accuracy of 78.13% using GPT-4o-mini, surpassing existing baselines.

摘要：表格作為表示結構化關係數據的基本格式。雖然目前的語言模型 (LM) 在許多基於文字的任務中表現出色，但由於表格數據的複雜特性（例如其結構化性質），它們在表格理解方面仍然面臨挑戰。在本文中，我們旨在增強 LM 以改善表格理解。我們確定了四個關鍵挑戰：1) 難以找到目標數據，2) 表格語義的不足，3) 文本推理中的數值不準確，以及 4) 符號推理中的語義不靈活性。為了解決這些問題，我們提出了 TableMaster，這是一個食譜和綜合框架，它整合了多種解決方案來克服這些障礙。TableMaster 首先提取相關的表格內容，並用豐富的語義上下文對其進行口頭化。此外，我們引入了自適應推理，這是一種靈活的方法，可在文本推理和符號推理之間動態調整，根據每個查詢定制推理過程。廣泛的分析和實驗證明了我們的發現和 TableMaster 的有效性。在 WikiTQ 數據集上，TableMaster 使用 GPT-4o-mini 達到了 78.13% 的準確度，超過了現有的基準。

##### **SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions**
2501.19377v2 by Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Erik Marchi

In this work, we present and evaluate SELMA, a Speech-Enabled Language Model
for virtual Assistant interactions that integrates audio and text as inputs to
a Large Language Model (LLM). SELMA is designed to handle three primary and two
auxiliary tasks related to interactions with virtual assistants simultaneously
within a single end-to-end model. We employ low-rank adaptation modules for
parameter-efficient training of both the audio encoder and the LLM.
Additionally, we implement a feature pooling strategy enabling the system to
recognize global patterns and improve accuracy on tasks less reliant on
individual sequence elements. Experimental results on Voice Trigger (VT)
detection, Device-Directed Speech Detection (DDSD), and Automatic Speech
Recognition (ASR), demonstrate that our approach both simplifies the typical
input processing pipeline of virtual assistants significantly and also improves
performance compared to dedicated models for each individual task. SELMA yields
relative Equal-Error Rate improvements of 64% on the VT detection task, and 22%
on DDSD, while also achieving word error rates close to the baseline.

摘要：在這項工作中，我們提出並評估了 SELMA，一個語音啟用語言模型，用於虛擬助理互動，它將音訊和文字整合為大型語言模型 (LLM) 的輸入。SELMA 被設計為同時處理與虛擬助理互動相關的三個主要任務和兩個輔助任務，所有任務都在單一端到端模型中進行。我們採用低秩適應模組，用於音訊編碼器和 LLM 的參數有效率訓練。此外，我們實作了一個特徵池化策略，讓系統能辨識全域模式，並提升對不太依賴個別序列元素的任務的準確度。語音觸發 (VT) 偵測、裝置導向語音偵測 (DDSD) 和自動語音辨識 (ASR) 的實驗結果顯示，我們的做法大幅簡化了虛擬助理的典型輸入處理管線，而且也提升了效能，優於針對每個個別任務的專用模型。SELMA 在 VT 偵測任務上產生了 64% 的相對等錯誤率改進，在 DDSD 上產生了 22% 的改進，同時也在字元錯誤率上達到接近基線的表現。

##### **CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation**
2501.19364v1 by Javier Solís-García, Belén Vega-Márquez, Juan A. Nepomuceno, Isabel A. Nepomuceno-Chamorro

Multivariate Time Series Imputation (MTSI) is crucial for many applications,
such as healthcare monitoring and traffic management, where incomplete data can
compromise decision-making. Existing state-of-the-art methods, like Denoising
Diffusion Probabilistic Models (DDPMs), achieve high imputation accuracy;
however, they suffer from significant computational costs and are notably
time-consuming due to their iterative nature. In this work, we propose CoSTI,
an innovative adaptation of Consistency Models (CMs) for the MTSI domain. CoSTI
employs Consistency Training to achieve comparable imputation quality to DDPMs
while drastically reducing inference times, making it more suitable for
real-time applications. We evaluate CoSTI across multiple datasets and missing
data scenarios, demonstrating up to a 98% reduction in imputation time with
performance on par with diffusion-based models. This work bridges the gap
between efficiency and accuracy in generative imputation tasks, providing a
scalable solution for handling missing data in critical spatio-temporal
systems.

摘要：多變量時序插補 (MTSI) 對許多應用至關重要，例如醫療保健監測和交通管理，其中不完整數據可能會影響決策制定。現有的最先進方法，例如去噪擴散機率模型 (DDPM)，可實現高插補準確度；然而，它們的運算成本很高，而且由於其迭代性質，顯著耗時。在這項工作中，我們提出 CoSTI，這是相容性模型 (CM) 在 MTSI 領域的創新改編。CoSTI 使用相容性訓練來實現與 DDPM 相當的插補品質，同時大幅減少推理時間，使其更適合於即時應用。我們在多個資料集和缺失數據場景中評估 CoSTI，證明插補時間最多減少 98%，且效能與基於擴散的模型相當。這項工作彌合了生成插補任務中效率和準確性之間的差距，為處理關鍵時空系統中的缺失數據提供了可擴充的解決方案。

##### **We're Different, We're the Same: Creative Homogeneity Across LLMs**
2501.19361v1 by Emily Wenger, Yoed Kenett

Numerous powerful large language models (LLMs) are now available for use as
writing support tools, idea generators, and beyond. Although these LLMs are
marketed as helpful creative assistants, several works have shown that using an
LLM as a creative partner results in a narrower set of creative outputs.
However, these studies only consider the effects of interacting with a single
LLM, begging the question of whether such narrowed creativity stems from using
a particular LLM -- which arguably has a limited range of outputs -- or from
using LLMs in general as creative assistants. To study this question, we elicit
creative responses from humans and a broad set of LLMs using standardized
creativity tests and compare the population-level diversity of responses. We
find that LLM responses are much more similar to other LLM responses than human
responses are to each other, even after controlling for response structure and
other key variables. This finding of significant homogeneity in creative
outputs across the LLMs we evaluate adds a new dimension to the ongoing
conversation about creativity and LLMs. If today's LLMs behave similarly, using
them as a creative partners -- regardless of the model used -- may drive all
users towards a limited set of "creative" outputs.

摘要：現今有許多功能強大的大型語言模型 (LLM) 可用於書寫輔助工具、點子產生器等用途。儘管這些 LLM 被標榜為有用的創意助手，但多項研究顯示，將 LLM 用作創意夥伴會導致創意產出範圍較窄。然而，這些研究僅考慮與單一 LLM 互動的影響，因此引發了一個問題，即這種狹隘的創意是否源自使用特定 LLM（其產出範圍可能有限），或源自普遍將 LLM 用作創意助手。為了研究這個問題，我們使用標準化的創意測試從人類和廣泛的 LLM 中引出創意回應，並比較回應的族群層級多樣性。我們發現，即使在控制回應結構和其他關鍵變數後，LLM 回應與其他 LLM 回應的相似程度遠高於人類回應彼此的相似程度。我們評估的 LLM 在創意產出方面具有顯著同質性的發現，為關於創意和 LLM 的持續對話增添了一個新面向。如果現今的 LLM 行為類似，將它們用作創意夥伴（無論使用哪個模型）可能會驅使所有使用者朝著有限的「創意」產出邁進。

##### **Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023**
2501.19353v1 by Ting-Yao E. Hsu, Yi-Li Hsu, Shaurya Rohatgi, Chieh-Yang Huang, Ho Yin Sam Ng, Ryan Rossi, Sungchul Kim, Tong Yu, Lun-Wei Ku, C. Lee Giles, Ting-Hao K. Huang

Since the SCICAP datasets launch in 2021, the research community has made
significant progress in generating captions for scientific figures in scholarly
articles. In 2023, the first SCICAP Challenge took place, inviting global teams
to use an expanded SCICAP dataset to develop models for captioning diverse
figure types across various academic fields. At the same time, text generation
models advanced quickly, with many powerful pre-trained large multimodal models
(LMMs) emerging that showed impressive capabilities in various
vision-and-language tasks. This paper presents an overview of the first SCICAP
Challenge and details the performance of various models on its data, capturing
a snapshot of the fields state. We found that professional editors
overwhelmingly preferred figure captions generated by GPT-4V over those from
all other models and even the original captions written by authors. Following
this key finding, we conducted detailed analyses to answer this question: Have
advanced LMMs solved the task of generating captions for scientific figures?

摘要：自 2021 年 SCICAP 資料集推出以來，研究社群在為學術期刊中的科學圖表產生標題方面取得了顯著進展。2023 年，第一屆 SCICAP 挑戰賽舉行，邀請全球團隊使用擴充的 SCICAP 資料集，為各個學術領域中不同的圖表類型開發標題模型。同時，文字生成模型快速進步，出現許多功能強大的預訓練大型多模態模型 (LMM)，在各種視覺和語言任務中展現出令人印象深刻的能力。本文概述了第一屆 SCICAP 挑戰賽，並詳細說明了各種模型在其資料上的表現，捕捉了該領域的現況。我們發現，專業編輯人員普遍偏好由 GPT-4V 生成的圖表標題，勝過所有其他模型，甚至勝過作者撰寫的原始標題。根據這一關鍵發現，我們進行了詳細分析，以回答這個問題：先進的 LMM 是否已解決為科學圖表產生標題的任務？

##### **PixelWorld: Towards Perceiving Everything as Pixels**
2501.19339v1 by Zhiheng Lyu, Xueguang Ma, Wenhu Chen

Existing foundation models typically process visual input as pixels and
textual input as tokens, a paradigm that contrasts with human perception, where
both modalities are processed in a unified manner. With the rise of embodied
and agentic AI, where inputs primarily come from camera pixels, the need for a
unified perception framework becomes increasingly evident. In this paper, we
propose to unify all modalities (text, tables, code, diagrams, images, etc) as
pixel inputs, i.e. "Perceive Everything as Pixels" (PEAP). We introduce
PixelWorld, a novel evaluation suite that unifies all the mentioned modalities
into pixel space to gauge the existing models' performance. Our findings show
that (1) PEAP outperforms baseline with token-based input in multimodal
datasets, benefiting from unified input for better disambiguation, (2)
significant declines in reasoning and coding capabilities across all models
when processing pixel-based input, underscoring the need to enhance foundation
models' perceptual abilities, (3) larger models can maintain strong performance
on non-reasoning tasks under PEAP, while smaller models like Phi-3.5-V suffer
significant performance degradation, (4) the attention pattern of PEAP is
highly aligned with text token input, (5) PEAP can be accelerated significantly
by exploiting the spatial sparsity. We conclude that the existing frontier
models are competent in pixel perception, however, there is still headroom for
improvement. Our code, dataset will be released upon acceptance.

摘要：現有的基礎模型通常將視覺輸入處理為像素，將文本輸入處理為符號，這種範例與人類感知形成對比，人類以統一的方式處理這兩種模式。隨著具身和能動 AI 的興起，其輸入主要來自相機像素，對統一感知架構的需求變得越來越明顯。在本文中，我們建議將所有模式（文本、表格、代碼、圖表、圖像等）統一為像素輸入，即「將所有內容視為像素」（PEAP）。我們介紹了 PixelWorld，這是一個新穎的評估套件，它將所有提到的模式統一到像素空間中，以評估現有模型的效能。我們的發現顯示：(1) PEAP 在多模式資料集中的表現優於基於符號輸入的基準，受益於統一輸入以獲得更好的消歧義，(2) 在處理基於像素的輸入時，所有模型的推理和編碼能力均大幅下降，這強調了增強基礎模型感知能力的必要性，(3) 較大的模型可以在 PEAP 下維持非推理任務的強勁效能，而較小的模型（如 Phi-3.5-V）則會遭受顯著的效能下降，(4) PEAP 的注意力模式與文本符號輸入高度一致，(5) PEAP 可以透過利用空間稀疏性來顯著加速。我們得出結論，現有的前沿模型在像素感知方面是勝任的，然而，仍有進步的空間。我們的程式碼和資料集將在獲得接受後釋出。

##### **Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**
2501.19338v1 by Misha P. T Kaandorp, Damola Agbelese, Hosna Asma-ull, Hyun-Gi Kim, Kelly Payette, Patrice Grehten, Gennari Antonio Giulio, Levente István Lánczi, Andras Jakab

Developing new methods for the automated analysis of clinical fetal and
neonatal MRI data is limited by the scarcity of annotated pathological datasets
and privacy concerns that often restrict data sharing, hindering the
effectiveness of deep learning models. We address this in two ways. First, we
introduce Fetal&Neonatal-DDPM, a novel diffusion model framework designed to
generate high-quality synthetic pathological fetal and neonatal MRIs from
semantic label images. Second, we enhance training data by modifying healthy
label images through morphological alterations to simulate conditions such as
ventriculomegaly, cerebellar and pontocerebellar hypoplasia, and microcephaly.
By leveraging Fetal&Neonatal-DDPM, we synthesize realistic pathological MRIs
from these modified pathological label images. Radiologists rated the synthetic
MRIs as significantly (p < 0.05) superior in quality and diagnostic value
compared to real MRIs, demonstrating features such as blood vessels and choroid
plexus, and improved alignment with label annotations. Synthetic pathological
data enhanced state-of-the-art nnUNet segmentation performance, particularly
for severe ventriculomegaly cases, with the greatest improvements achieved in
ventricle segmentation (Dice scores: 0.9253 vs. 0.7317). This study underscores
the potential of generative AI as transformative tool for data augmentation,
offering improved segmentation performance in pathological cases. This
development represents a significant step towards improving analysis and
segmentation accuracy in prenatal imaging, and also offers new ways for data
anonymization through the generation of pathologic image data.

摘要：<paragraph>開發用於自動分析臨床胎兒和新生兒 MRI 資料的新方法受到標註病理資料集稀少和隱私問題的限制，這些問題通常會限制資料共享，從而阻礙深度學習模型的有效性。我們以兩種方式解決這個問題。首先，我們引入了 Fetal&Neonatal-DDPM，這是一個新穎的擴散模型架構，旨在從語義標籤影像生成高品質的合成病理胎兒和新生兒 MRI。其次，我們透過形態改變來修改健康的標籤影像，以模擬腦室擴大、小腦和橋腦小腦發育不全以及小頭畸形等情況，從而增強訓練資料。透過利用 Fetal&Neonatal-DDPM，我們從這些修改後的病理標籤影像中合成了逼真的病理 MRI。放射科醫師評估合成 MRI 的品質和診斷價值顯著優於真實 MRI（p < 0.05），展示了血管和脈絡叢等特徵，並改善了與標籤註解的一致性。合成病理資料增強了最先進的 nnUNet 分割效能，特別是對於嚴重的腦室擴大病例，其中腦室分割（Dice 分數：0.9253 對 0.7317）的改善最大。這項研究強調了生成式 AI 作為資料擴充轉型工具的潛力，在病理病例中提供了改善的分割效能。這項發展代表了改善產前影像分析和分割準確性的重要一步，也為透過生成病理影像資料來進行資料匿名化提供了新方法。</paragraph>

##### **Homogeneity Bias as Differential Sampling Uncertainty in Language Models**
2501.19337v1 by Messi H. J. Lee, Soyeon Jeon

Prior research show that Large Language Models (LLMs) and Vision-Language
Models (VLMs) represent marginalized groups more homogeneously than dominant
groups. However, the mechanisms underlying this homogeneity bias remain
relatively unexplored. We propose that this bias emerges from systematic
differences in the probability distributions from which tokens are sampled at
inference-time. Analyzing three measures of uncertainty in token sampling
distributions-entropy, perplexity, and probability of differentiation-we find
that in some models, specifically GPT-4 Turbo and Llama-3.2, tokens are sampled
more deterministically when generating texts about marginalized groups (i.e.,
Black Americans and women) compared to their dominant group counterparts (i.e.,
White Americans and men). While these findings may help explain homogeneity
bias in certain models, the patterns did not replicate across all VLMs tested,
suggesting multiple mechanisms may contribute to homogeneity bias in AI.

摘要：先前的研究表明，大型語言模型 (LLM) 和視覺語言模型 (VLM) 以比主流群體更同質的方式呈現邊緣群體。然而，這種同質性偏誤的底層機制仍然相對未被探討。我們提出這種偏誤源於在推論時間對令牌進行抽樣的機率分佈中的系統性差異。分析令牌抽樣分佈中的三個不確定性測量值——熵、困惑度和差異機率——我們發現，在某些模型中，特別是 GPT-4 Turbo 和 Llama-3.2，與其主流群體對應者（即白人美國人和男性）相比，在生成有關邊緣群體（即黑人美國人和女性）的文本時，令牌的抽樣更具確定性。雖然這些發現可能有助於解釋某些模型中的同質性偏誤，但這些模式並未在所有測試的 VLM 中複製，這表明多種機制可能導致 AI 中的同質性偏誤。

##### **What is causal about causal models and representations?**
2501.19335v2 by Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald

Causal Bayesian networks are 'causal' models since they make predictions
about interventional distributions. To connect such causal model predictions to
real-world outcomes, we must determine which actions in the world correspond to
which interventions in the model. For example, to interpret an action as an
intervention on a treatment variable, the action will presumably have to a)
change the distribution of treatment in a way that corresponds to the
intervention, and b) not change other aspects, such as how the outcome depends
on the treatment; while the marginal distributions of some variables may change
as an effect. We introduce a formal framework to make such requirements for
different interpretations of actions as interventions precise. We prove that
the seemingly natural interpretation of actions as interventions is circular:
Under this interpretation, every causal Bayesian network that correctly models
the observational distribution is trivially also interventionally valid, and no
action yields empirical data that could possibly falsify such a model. We prove
an impossibility result: No interpretation exists that is non-circular and
simultaneously satisfies a set of natural desiderata. Instead, we examine
non-circular interpretations that may violate some desiderata and show how this
may in turn enable the falsification of causal models. By rigorously examining
how a causal Bayesian network could be a 'causal' model of the world instead of
merely a mathematical object, our formal framework contributes to the
conceptual foundations of causal representation learning, causal discovery, and
causal abstraction, while also highlighting some limitations of existing
approaches.

摘要：因果貝氏網路是「因果」模型，因為它們會對介入分佈做出預測。為了將此類因果模型預測與真實世界的結果連結，我們必須確定世界中的哪些動作對應於模型中的哪些介入。例如，要將動作解讀為對治療變數的介入，則該動作可能必須 a) 以對應於介入的方式來改變治療分佈，以及 b) 不改變其他面向，例如結果如何取決於治療；而某些變數的邊際分佈可能會因為效應而改變。我們引入一個正式架構來對動作作為介入的不同解讀做出此類要求。我們證明，將動作解讀為介入的看似自然解讀是循環的：在此解讀下，正確建模觀察分佈的每個因果貝氏網路在介入上也微不足道地有效，而且沒有動作會產生經驗資料，可能證偽此類模型。我們證明了一個不可能的結果：沒有解讀是非循環的，同時滿足一組自然的理想。相反地，我們檢視可能違反某些理想的非循環解讀，並展示這反過來如何能夠證偽因果模型。透過嚴謹地檢視因果貝氏網路如何成為世界的「因果」模型，而不是僅僅是一個數學物件，我們的正式架構有助於因果表徵學習、因果發現和因果抽象的概念基礎，同時也突顯了現有方法的一些限制。

##### **Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation**
2501.19328v1 by Jan Pauls, Max Zimmer, Berkant Turan, Sassan Saatchi, Philippe Ciais, Sebastian Pokutta, Fabian Gieseke

With the rise in global greenhouse gas emissions, accurate large-scale tree
canopy height maps are essential for understanding forest structure, estimating
above-ground biomass, and monitoring ecological disruptions. To this end, we
present a novel approach to generate large-scale, high-resolution canopy height
maps over time. Our model accurately predicts canopy height over multiple years
given Sentinel-2 time series satellite data. Using GEDI LiDAR data as the
ground truth for training the model, we present the first 10m resolution
temporal canopy height map of the European continent for the period 2019-2022.
As part of this product, we also offer a detailed canopy height map for 2020,
providing more precise estimates than previous studies. Our pipeline and the
resulting temporal height map are publicly available, enabling comprehensive
large-scale monitoring of forests and, hence, facilitating future research and
ecological analyses. For an interactive viewer, see
https://europetreemap.projects.earthengine.app/view/temporalcanopyheight.

摘要：隨著全球溫室氣體排放量的增加，準確的大規模樹冠高度圖對於理解森林結構、估計地上生物量和監測生態破壞至關重要。為此，我們提出了一種新的方法來生成大規模、高解析度的樹冠高度圖。我們的模型準確預測了多年來給定 Sentinel-2 時間序列衛星數據的樹冠高度。使用 GEDI LiDAR 數據作為訓練模型的真實情況，我們展示了第一個 2019-2022 年期間歐洲大陸 10m 解析度的時間樹冠高度圖。作為該產品的一部分，我們還提供 2020 年的詳細樹冠高度圖，提供比以前的研究更精確的估計。我們的管道和生成的時態高度圖是公開的，可以對森林進行全面的大規模監控，從而促進未來的研究和生態分析。有關互動查看器，請參閱 https://europetreemap.projects.earthengine.app/view/temporalcanopyheight。

##### **Reward-Guided Speculative Decoding for Efficient LLM Reasoning**
2501.19324v1 by Baohao Liao, Yuhui Xu, Hanze Dong, Junnan Li, Christof Monz, Silvio Savarese, Doyen Sahoo, Caiming Xiong

We introduce Reward-Guided Speculative Decoding (RSD), a novel framework
aimed at improving the efficiency of inference in large language models (LLMs).
RSD synergistically combines a lightweight draft model with a more powerful
target model, incorporating a controlled bias to prioritize high-reward
outputs, in contrast to existing speculative decoding methods that enforce
strict unbiasedness. RSD employs a process reward model to evaluate
intermediate decoding steps and dynamically decide whether to invoke the target
model, optimizing the trade-off between computational cost and output quality.
We theoretically demonstrate that a threshold-based mixture strategy achieves
an optimal balance between resource utilization and performance. Extensive
evaluations on challenging reasoning benchmarks, including Olympiad-level
tasks, show that RSD delivers significant efficiency gains against decoding
with the target model only (up to 4.4x fewer FLOPs), while achieving
significant better accuracy than parallel decoding method on average (up to
+3.5). These results highlight RSD as a robust and cost-effective approach for
deploying LLMs in resource-intensive scenarios.

摘要：<paragraph>我們引入了獎勵引導式推測解碼 (RSD)，一種旨在提高大型語言模型 (LLM) 推論效率的新框架。RSD 協同結合輕量級草稿模型和更強大的目標模型，並納入受控偏差以優先考慮高獎勵輸出，這與現有的推測解碼方法形成對比，後者強制執行嚴格的無偏差性。RSD 使用過程獎勵模型來評估中間解碼步驟，並動態決定是否調用目標模型，從而優化計算成本和輸出質量之間的權衡。我們在理論上證明，基於閾值的混合策略在資源利用和性能之間實現了最佳平衡。在具有挑戰性的推理基準上的廣泛評估，包括奧林匹克級別的任務，表明 RSD 在僅使用目標模型進行解碼的情況下提供了顯著的效率提升（最多減少 4.4 倍的 FLOP），同時比並行解碼方法平均獲得顯著更好的準確度（最多 +3.5）。這些結果突出了 RSD 作為一種強大且經濟高效的方法，用於在資源密集型場景中部署 LLM。</paragraph>

##### **Language Bias in Self-Supervised Learning For Automatic Speech Recognition**
2501.19321v1 by Edward Storey, Naomi Harte, Peter Bell

Self-supervised learning (SSL) is used in deep learning to train on large
datasets without the need for expensive labelling of the data. Recently, large
Automatic Speech Recognition (ASR) models such as XLS-R have utilised SSL to
train on over one hundred different languages simultaneously. However, deeper
investigation shows that the bulk of the training data for XLS-R comes from a
small number of languages. Biases learned through SSL have been shown to exist
in multiple domains, but language bias in multilingual SSL ASR has not been
thoroughly examined. In this paper, we utilise the Lottery Ticket Hypothesis
(LTH) to identify language-specific subnetworks within XLS-R and test the
performance of these subnetworks on a variety of different languages. We are
able to show that when fine-tuning, XLS-R bypasses traditional linguistic
knowledge and builds only on weights learned from the languages with the
largest data contribution to the pretraining data.

摘要：自監督學習 (SSL) 用於深度學習，在無需昂貴資料標籤的情況下，訓練大型資料集。最近，大型自動語音辨識 (ASR) 模型（例如 XLS-R）已利用 SSL 同時訓練超過一百種不同的語言。然而，更深入的研究顯示，XLS-R 的大部分訓練資料來自少數語言。已證明透過 SSL 學習的偏見存在於多個領域，但尚未徹底檢驗多語言 SSL ASR 中的語言偏見。在本文中，我們利用樂透券假說 (LTH) 來識別 XLS-R 中特定語言的子網路，並測試這些子網路在各種不同語言上的效能。我們能夠證明，在微調時，XLS-R 繞過傳統語言知識，僅建構在從對預訓練資料貢獻最大資料的語言中學習到的權重上。

##### **MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems**
2501.19318v1 by Anirudh Chari, Suraj Reddy, Aditya Tiwari, Richard Lian, Brian Zhou

While large language models (LLMs) have shown promising capabilities as
zero-shot planners for embodied agents, their inability to learn from
experience and build persistent mental models limits their robustness in
complex open-world environments like Minecraft. We introduce MINDSTORES, an
experience-augmented planning framework that enables embodied agents to build
and leverage mental models through natural interaction with their environment.
Drawing inspiration from how humans construct and refine cognitive mental
models, our approach extends existing zero-shot LLM planning by maintaining a
database of past experiences that informs future planning iterations. The key
innovation is representing accumulated experiences as natural language
embeddings of (state, task, plan, outcome) tuples, which can then be
efficiently retrieved and reasoned over by an LLM planner to generate insights
and guide plan refinement for novel states and tasks. Through extensive
experiments in the MineDojo environment, a simulation environment for agents in
Minecraft that provides low-level controls for Minecraft, we find that
MINDSTORES learns and applies its knowledge significantly better than existing
memory-based LLM planners while maintaining the flexibility and generalization
benefits of zero-shot approaches, representing an important step toward more
capable embodied AI systems that can learn continuously through natural
experience.

摘要：儘管大型語言模型 (LLM) 已展現出作為具身代理人的零次規劃器的潛在能力，但它們無法從經驗中學習和建立持續的心理模型，限制了它們在 Minecraft 等複雜的開放世界環境中的穩健性。我們引入了 MINDSTORES，一個經驗增強規劃框架，讓具身代理人能夠透過與環境的自然互動建立和利用心理模型。我們的做法汲取了人類建構和精進認知心理模型的方式，透過維護一個過去經驗的資料庫，為未來的規劃迭代提供資訊，來擴充現有的零次 LLM 規劃。關鍵創新是將累積的經驗表示為 (狀態、任務、計畫、結果) 元組的自然語言嵌入，然後 LLM 規劃器可以有效地擷取和推理這些嵌入，以產生見解並引導新狀態和任務的計畫精進。透過在 MineDojo 環境中進行廣泛的實驗，這是一個為 Minecraft 中的代理人提供的模擬環境，提供 Minecraft 的低階控制，我們發現 MINDSTORES 的學習和應用知識顯著優於現有的基於記憶的 LLM 規劃器，同時保持零次方法的靈活性與泛化優點，代表著邁向更強大的具身 AI 系統的重要一步，這些系統可以透過自然經驗持續學習。

##### **LLM-based Affective Text Generation Quality Based on Different Quantization Values**
2501.19317v1 by Yarik Menchaca Resendiz, Roman Klinger

Large language models exhibit a remarkable capacity in language generation
and comprehension. These advances enable AI systems to produce more human-like
and emotionally engaging text. However, these models rely on a large number of
parameters, requiring significant computational resources for training and
inference. In some scenarios, accessing these resources can be challenging
(e.g., budget or hardware limitations). Techniques like reducing precision bits
can make models more memory-efficient, reducing the computational resources
needed, at the cost of reduced accuracy. This paper addresses the trade-off
between different quantization values, GPU RAM utilization, and text quality in
affective text generation (e.g., "I really enjoy running in the snow-covered
forest"). To evaluate, we use an emotion classifier and ten seed prompts to
generate affective text. We test three setups of precision bits (8, 16, and 32)
across five open-weight language models from two different families. Our
findings demonstrate that bit reductions lead to memory savings, achieving a
reduction of 76%. However, this optimization comes with a trade-off, leading to
a decrease of up to 10 pp in F1 score for larger models and an increase of 10
pp for smaller models, along with roughly double the inference time. In terms
of text quality, larger models at lower quantization levels generally
outperform smaller, higher-precision models -- while requiring similar memory.

摘要：大型語言模型在語言生成和理解方面表現出非凡的能力。這些進展使 AI 系統能夠產生更接近人類語言和情感參與度更高的文字。然而，這些模型依賴於大量的參數，需要大量的計算資源進行訓練和推論。在某些情況下，存取這些資源可能具有挑戰性（例如，預算或硬體限制）。像降低精確度位元數這樣的技術可以使模型更省記憶體，減少所需的計算資源，但代價是降低準確度。本文探討了在情感文字生成（例如，「我真的很享受在白雪覆蓋的森林中跑步」）中不同量化值、GPU RAM 使用率和文字品質之間的取捨。為了評估，我們使用情緒分類器和十個種子提示來生成情感文字。我們測試了來自兩個不同系列的五個開放權重語言模型的精確度位元數（8、16 和 32）的三種設定。我們的研究結果表明，位元數減少會導致記憶體節省，節省幅度達到 76%。然而，這種最佳化是有代價的，導致較大模型的 F1 分數降低多達 10 個百分點，較小模型的 F1 分數增加 10 個百分點，同時推論時間大約增加一倍。在文字品質方面，量化等級較低的較大模型通常優於量化等級較高的較小模型——同時需要類似的記憶體。

##### **Reverse Probing: Evaluating Knowledge Transfer via Finetuned Task Embeddings for Coreference Resolution**
2501.19316v1 by Tatiana Anikina, Arne Binder, David Harbecke, Stalin Varanasi, Leonhard Hennig, Simon Ostermann, Sebastian Möller, Josef van Genabith

In this work, we reimagine classical probing to evaluate knowledge transfer
from simple source to more complex target tasks. Instead of probing frozen
representations from a complex source task on diverse simple target probing
tasks (as usually done in probing), we explore the effectiveness of embeddings
from multiple simple source tasks on a single target task. We select
coreference resolution, a linguistically complex problem requiring contextual
understanding, as focus target task, and test the usefulness of embeddings from
comparably simpler tasks tasks such as paraphrase detection, named entity
recognition, and relation extraction. Through systematic experiments, we
evaluate the impact of individual and combined task embeddings.
  Our findings reveal that task embeddings vary significantly in utility for
coreference resolution, with semantic similarity tasks (e.g., paraphrase
detection) proving most beneficial. Additionally, representations from
intermediate layers of fine-tuned models often outperform those from final
layers. Combining embeddings from multiple tasks consistently improves
performance, with attention-based aggregation yielding substantial gains. These
insights shed light on relationships between task-specific representations and
their adaptability to complex downstream tasks, encouraging further exploration
of embedding-level task transfer.

摘要：在這項工作中，我們重新構想經典探查，以評估從簡單來源到更複雜目標任務的知識轉移。我們沒有在各種簡單目標探查任務中探查來自複雜來源任務的凍結表示（如探查中通常所做的那樣），而是探討來自多個簡單來源任務的嵌入在單一目標任務上的有效性。我們選擇了指稱消解，這是一個需要上下文理解的語言複雜問題，作為重點目標任務，並測試了來自相對簡單任務（例如語句改寫偵測、命名實體辨識和關係萃取）的嵌入的效用。透過系統性的實驗，我們評估了個別和組合任務嵌入的影響。我們的發現表明，任務嵌入在指稱消解的效用上差異很大，其中語義相似性任務（例如語句改寫偵測）被證明最有益。此外，微調模型的中間層表示通常優於最後一層的表示。結合來自多個任務的嵌入始終能改善效能，其中基於注意力的聚合產生了顯著的增益。這些見解闡明了特定任務表示與其對複雜下游任務的適應性之間的關係，鼓勵進一步探索嵌入層級任務轉移。

##### **An Efficient Approach for Machine Translation on Low-resource Languages: A Case Study in Vietnamese-Chinese**
2501.19314v1 by Tran Ngoc Son, Nguyen Anh Tu, Nguyen Minh Tri

Despite the rise of recent neural networks in machine translation, those
networks do not work well if the training data is insufficient. In this paper,
we proposed an approach for machine translation in low-resource languages such
as Vietnamese-Chinese. Our proposed method leveraged the power of the
multilingual pre-trained language model (mBART) and both Vietnamese and Chinese
monolingual corpus. Firstly, we built an early bird machine translation model
using the bilingual training dataset. Secondly, we used TF-IDF technique to
select sentences from the monolingual corpus which are the most related to
domains of the parallel dataset. Finally, the first model was used to
synthesize the augmented training data from the selected monolingual corpus for
the translation model. Our proposed scheme showed that it outperformed 8%
compared to the transformer model. The augmented dataset also pushed the model
performance.

摘要：儘管最近機器翻譯中的神經網路興起，如果訓練資料不足，這些網路就無法順利運作。在本文中，我們提出了一個用於低資源語言（例如越南語-中文）的機器翻譯方法。我們提出的方法利用了多語言預訓練語言模型 (mBART) 和越南語和中文單語語料庫的力量。首先，我們使用雙語訓練資料集建立了一個早期機器翻譯模型。其次，我們使用 TF-IDF 技術從單語語料庫中選擇與平行資料集領域最相關的句子。最後，第一個模型用於從所選的單語語料庫中合成擴充訓練資料，以供翻譯模型使用。我們提出的方案顯示，與Transformer模型相比，它的表現優異 8%。擴充資料集也提升了模型效能。

##### **Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment**
2501.19309v1 by Gregor Bachmann, Sotiris Anagnostidis, Albert Pumarola, Markos Georgopoulos, Artsiom Sanakoyeu, Yuming Du, Edgar Schönfeld, Ali Thabet, Jonas Kohler

The performance of large language models (LLMs) is closely linked to their
underlying size, leading to ever-growing networks and hence slower inference.
Speculative decoding has been proposed as a technique to accelerate
autoregressive generation, leveraging a fast draft model to propose candidate
tokens, which are then verified in parallel based on their likelihood under the
target model. While this approach guarantees to reproduce the target output, it
incurs a substantial penalty: many high-quality draft tokens are rejected, even
when they represent objectively valid continuations. Indeed, we show that even
powerful draft models such as GPT-4o, as well as human text cannot achieve high
acceptance rates under the standard verification scheme. This severely limits
the speedup potential of current speculative decoding methods, as an early
rejection becomes overwhelmingly likely when solely relying on alignment of
draft and target.
  We thus ask the following question: Can we adapt verification to recognize
correct, but non-aligned replies? To this end, we draw inspiration from the
LLM-as-a-judge framework, which demonstrated that LLMs are able to rate answers
in a versatile way. We carefully design a dataset to elicit the same capability
in the target model by training a compact module on top of the embeddings to
produce ``judgements" of the current continuation. We showcase our strategy on
the Llama-3.1 family, where our 8b/405B-Judge achieves a speedup of 9x over
Llama-405B, while maintaining its quality on a large range of benchmarks. These
benefits remain present even in optimized inference frameworks, where our
method reaches up to 141 tokens/s for 8B/70B-Judge and 129 tokens/s for 8B/405B
on 2 and 8 H100s respectively.

摘要：大型語言模型 (LLM) 的效能與其基礎大小密切相關，導致網路不斷擴大，進而降低推理速度。
推測性解碼已被提出作為一種加速自迴歸生成的技術，利用快速草稿模型來建議候選詞元，然後根據目標模型下的可能性並行驗證這些詞元。雖然這種方法保證重現目標輸出，但它會產生大量的懲罰：許多高品質的草稿詞元會被拒絕，即使它們代表客觀有效的延續。事實上，我們證明了即使是強大的草稿模型，例如 GPT-4o，以及人類文字，在標準驗證方案下也無法達到高接受率。這嚴重限制了當前推測性解碼方法的加速潛力，因為當僅依賴草稿和目標的一致性時，早期拒絕的可能性會變得極大。
因此，我們提出以下問題：我們能調整驗證以識別正確但未對齊的回覆嗎？為此，我們從 LLM 作為評判者框架中汲取靈感，該框架證明 LLM 能夠以多樣化的方式評分答案。我們仔細設計了一個數據集，以在目標模型中引發相同的性能，方法是在嵌入之上訓練一個精簡模組，以對當前延續產生「判斷」。我們在 Llama-3.1 系列中展示了我們的策略，其中我們的 8b/405B-Judge 在 Llama-405B 上實現了 9 倍的加速，同時在大量的基準測試中保持其品質。這些優點即使在最佳化的推理框架中仍然存在，其中我們的方法分別在 2 個和 8 個 H100 上，針對 8B/70B-Judge 達到了每秒 141 個詞元，針對 8B/405B 達到了每秒 129 個詞元。

##### **SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling**
2501.19306v2 by Jiefeng Chen, Jie Ren, Xinyun Chen, Chengrun Yang, Ruoxi Sun, Sercan Ö Arık

Recent advancements in Large Language Models (LLMs) have created new
opportunities to enhance performance on complex reasoning tasks by leveraging
test-time computation. However, conventional approaches such as repeated
sampling with majority voting or reward model scoring, often face diminishing
returns as test-time compute scales, in addition to requiring costly
task-specific reward model training. In this paper, we present Self-Enhanced
Test-Time Scaling (SETS), a novel method that leverages the self-verification
and self-correction capabilities of recent advanced LLMs to overcome these
limitations. SETS integrates sampling, self-verification, and self-correction
into a unified framework, enabling efficient and scalable test-time computation
for improved capabilities at complex tasks. Through extensive experiments on
challenging planning and reasoning benchmarks, compared to the alternatives, we
demonstrate that SETS achieves significant performance improvements and more
favorable test-time scaling laws.

摘要：大型語言模型 (LLM) 的近期進展創造了新的機會，可透過利用測試時間運算來增強複雜推理任務的效能。然而，傳統方法（例如重複抽樣搭配多數決或獎勵模型評分）通常會面臨報酬遞減，因為測試時間運算會擴展，而且需要代價高昂的特定任務獎勵模型訓練。在本文中，我們提出自我增強測試時間擴展 (SETS)，這是一種新方法，可利用近期進階 LLM 的自我驗證和自我修正功能來克服這些限制。SETS 將抽樣、自我驗證和自我修正整合到統一架構中，讓複雜任務的測試時間運算得以有效率且具擴充性，進而提升功能。透過在具挑戰性的規劃和推理基準上進行廣泛實驗，與其他方法相比，我們證明 SETS 可達成顯著的效能提升，並有更理想的測試時間擴展定律。

##### **Beyond checkmate: exploring the creative chokepoints in AI text**
2501.19301v1 by Nafis Irtiza Tripto, Saranya Venkatraman, Mahjabin Nahar, Dongwon Lee

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) and Artificial Intelligence (AI), unlocking unprecedented capabilities.
This rapid advancement has spurred research into various aspects of LLMs, their
text generation & reasoning capability, and potential misuse, fueling the
necessity for robust detection methods. While numerous prior research has
focused on detecting LLM-generated text (AI text) and thus checkmating them,
our study investigates a relatively unexplored territory: portraying the
nuanced distinctions between human and AI texts across text segments. Whether
LLMs struggle with or excel at incorporating linguistic ingenuity across
different text segments carries substantial implications for determining their
potential as effective creative assistants to humans. Through an analogy with
the structure of chess games-comprising opening, middle, and end games-we
analyze text segments (introduction, body, and conclusion) to determine where
the most significant distinctions between human and AI texts exist. While AI
texts can approximate the body segment better due to its increased length, a
closer examination reveals a pronounced disparity, highlighting the importance
of this segment in AI text detection. Additionally, human texts exhibit higher
cross-segment differences compared to AI texts. Overall, our research can shed
light on the intricacies of human-AI text distinctions, offering novel insights
for text detection and understanding.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理 (NLP) 和人工智慧 (AI)，釋放了前所未有的能力。
這項快速進展促使對 LLM 的各個方面進行研究，包括它們的文本生成和推理能力，以及潛在的誤用，進而推動了對健全偵測方法的需求。雖然許多先前的研究都專注於偵測 LLM 生成的文字 (AI 文字)，並因此將它們將死，但我們的研究探討了一個相對未開發的領域：描繪人類和 AI 文字在不同文字區段之間的細微差異。LLM 是否難以或擅長在不同的文字區段中融入語言創意，對於確定它們作為人類有效創意助理的潛力具有重大影響。透過類比於西洋棋比賽的結構，包括開局、中局和殘局，我們分析文字區段（引言、內文和結論），以確定人類和 AI 文字之間最顯著的差異存在於何處。雖然 AI 文字由於長度較長而能更接近內文區段，但更仔細的檢查揭示了明顯的差異，突顯了這個區段在 AI 文字偵測中的重要性。此外，與 AI 文字相比，人類文字展現出更高的跨區段差異。總體而言，我們的研究可以闡明人類和 AI 文字區分的複雜性，為文字偵測和理解提供新的見解。

##### **Synthetic User Behavior Sequence Generation with Large Language Models for Smart Homes**
2501.19298v1 by Zhiyao Xu, Dan Zhao, Qingsong Zou, Jingyu Xiao, Yong Jiang, Zhenhui Yuan, Qing Li

In recent years, as smart home systems have become more widespread, security
concerns within these environments have become a growing threat. Currently,
most smart home security solutions, such as anomaly detection and behavior
prediction models, are trained using fixed datasets that are precollected.
However, the process of dataset collection is time-consuming and lacks the
flexibility needed to adapt to the constantly evolving smart home environment.
Additionally, the collection of personal data raises significant privacy
concerns for users. Lately, large language models (LLMs) have emerged as a
powerful tool for a wide range of tasks across diverse application domains,
thanks to their strong capabilities in natural language processing, reasoning,
and problem-solving. In this paper, we propose an LLM-based synthetic dataset
generation IoTGen framework to enhance the generalization of downstream smart
home intelligent models. By generating new synthetic datasets that reflect
changes in the environment, smart home intelligent models can be retrained to
overcome the limitations of fixed and outdated data, allowing them to better
align with the dynamic nature of real-world home environments. Specifically, we
first propose a Structure Pattern Perception Compression (SPPC) method tailored
for IoT behavior data, which preserves the most informative content in the data
while significantly reducing token consumption. Then, we propose a systematic
approach to create prompts and implement data generation to automatically
generate IoT synthetic data with normative and reasonable properties, assisting
task models in adaptive training to improve generalization and real-world
performance.

摘要：<paragraph>近年來，隨著智慧家庭系統日益普及，這些環境中的安全問題已成為日益嚴重的威脅。目前，大多數智慧家庭安全解決方案（例如異常偵測和行為預測模型）都是使用預先收集的固定資料集進行訓練。然而，資料集收集的過程耗時，且缺乏適應不斷變化的智慧家庭環境所需的靈活性。此外，個人資料的收集也對使用者造成重大的隱私問題。最近，大型語言模型 (LLM) 已成為各種應用領域中廣泛任務的強大工具，這要歸功於它們在自然語言處理、推理和問題解決方面的強大功能。在本文中，我們提出了一個基於 LLM 的合成資料集生成 IoTGen 架構，以增強下游智慧家庭智慧模型的泛化。透過產生反映環境變化的新合成資料集，可以重新訓練智慧家庭智慧模型，以克服固定和過時資料的限制，讓它們能更好地與真實世界家庭環境的動態性質保持一致。具體來說，我們首先提出針對 IoT 行為資料量身打造的結構模式感知壓縮 (SPPC) 方法，它保留了資料中最具資訊性的內容，同時大幅減少符號消耗。然後，我們提出了一種系統化方法來建立提示並實作資料生成，以自動產生具有規範性和合理性的 IoT 合成資料，協助任務模型進行適應性訓練，以改善泛化和真實世界效能。</paragraph>

##### **Analysis of LLMs vs Human Experts in Requirements Engineering**
2501.19297v1 by Cory Hymel, Hiroe Johnson

The majority of research around Large Language Models (LLM) application to
software development has been on the subject of code generation. There is
little literature on LLMs' impact on requirements engineering (RE), which deals
with the process of developing and verifying the system requirements. Within
RE, there is a subdiscipline of requirements elicitation, which is the practice
of discovering and documenting requirements for a system from users, customers,
and other stakeholders. In this analysis, we compare LLM's ability to elicit
requirements of a software system, as compared to that of a human expert in a
time-boxed and prompt-boxed study. We found LLM-generated requirements were
evaluated as more aligned (+1.12) than human-generated requirements with a
trend of being more complete (+10.2%). Conversely, we found users tended to
believe that solutions they perceived as more aligned had been generated by
human experts. Furthermore, while LLM-generated documents scored higher and
performed at 720x the speed, their cost was, on average, only 0.06% that of a
human expert. Overall, these findings indicate that LLMs will play an
increasingly important role in requirements engineering by improving
requirements definitions, enabling more efficient resource allocation, and
reducing overall project timelines.

摘要：大型語言模型 (LLM) 應用於軟體開發的研究大部分都集中在程式碼生成的主題上。關於 LLM 對需求工程 (RE) 的影響，也就是處理開發和驗證系統需求的流程，則鮮少有文獻探討。在 RE 中，有一個需求引導的子領域，其做法是從使用者、客戶和其他利害關係人找出並記錄系統的需求。在這個分析中，我們比較了 LLM 引導軟體系統需求的能力，以及在時間限制和提示限制的研究中，人類專家的能力。我們發現 LLM 生成的需求被評為比人類生成的更一致 (+1.12)，且有趨勢顯示更完整 (+10.2%)。相反地，我們發現使用者傾向於相信他們認為比較一致的解決方案是由人類專家產生的。此外，雖然 LLM 生成的文件得分較高，且執行速度快 720 倍，但其成本平均來說僅為人類專家的 0.06%。整體而言，這些發現顯示 LLM 將在需求工程中扮演越來越重要的角色，方法是改善需求定義、讓資源配置更有效率，以及縮短整體專案時程。

##### **Pheromone-based Learning of Optimal Reasoning Paths**
2501.19278v1 by Anirudh Chari, Aditya Tiwari, Richard Lian, Suraj Reddy, Brian Zhou

Large Language Models (LLMs) have demonstrated remarkable reasoning
capabilities through chain-of-thought prompting, yet discovering effective
reasoning methods for complex problems remains challenging due to the vast
space of possible intermediate steps. We introduce Ant Colony
Optimization-guided Tree of Thought (ACO-ToT), a novel algorithm that combines
ACO with LLMs to discover optimal reasoning paths for complex problems
efficiently. Drawing inspiration from Hebbian learning in neurological systems,
our method employs a collection of distinctly fine-tuned LLM "ants" to traverse
and lay pheromone trails through a centralized tree of thought, with each ant's
movement governed by a weighted combination of existing pheromone trails and
its own specialized expertise. The algorithm evaluates complete reasoning paths
using a mixture-of-experts-based scoring function, with pheromones reinforcing
productive reasoning paths across iterations. Experiments on three challenging
reasoning tasks (GSM8K, ARC-Challenge, and MATH) demonstrate that ACO-ToT
performs significantly better than existing chain-of-thought optimization
approaches, suggesting that incorporating biologically inspired collective
search mechanisms into LLM inference can substantially enhance reasoning
capabilities.

摘要：大型語言模型 (LLM) 已透過思考鏈提示展現出非凡的推理能力，但由於可能的步驟空間龐大，因此找出複雜問題的有效推理方法仍然具有挑戰性。我們引入了螞蟻群最佳化引導的思考樹 (ACO-ToT)，這是一種新穎的演算法，它將 ACO 與 LLM 結合，以有效找出複雜問題的最佳推理路徑。我們的演算法從神經系統中的赫布學習中汲取靈感，採用一組經過微調的 LLM「螞蟻」來穿越並在集中式思考樹中留下費洛蒙軌跡，每個螞蟻的移動都受到既有費洛蒙軌跡和其自身專業知識的加權組合所控制。該演算法使用基於專家混合的評分函數來評估完整的推理路徑，費洛蒙會在反覆運算中強化有成效的推理路徑。在三項具有挑戰性的推理任務（GSM8K、ARC-Challenge 和 MATH）上的實驗證明，ACO-ToT 的表現明顯優於現有的思考鏈最佳化方法，這表明將受生物啟發的集體搜尋機制納入 LLM 推論可以大幅提升推理能力。

##### **Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**
2501.19271v1 by Halil Ibrahim Aysel, Xiaohao Cai, Adam Prugel-Bennett

Concept-based explanation methods, such as concept bottleneck models (CBMs),
aim to improve the interpretability of machine learning models by linking their
decisions to human-understandable concepts, under the critical assumption that
such concepts can be accurately attributed to the network's feature space.
However, this foundational assumption has not been rigorously validated, mainly
because the field lacks standardised metrics and benchmarks to assess the
existence and spatial alignment of such concepts. To address this, we propose
three metrics: the concept global importance metric, the concept existence
metric, and the concept location metric, including a technique for visualising
concept activations, i.e., concept activation mapping. We benchmark post-hoc
CBMs to illustrate their capabilities and challenges. Through qualitative and
quantitative experiments, we demonstrate that, in many cases, even the most
important concepts determined by post-hoc CBMs are not present in input images;
moreover, when they are present, their saliency maps fail to align with the
expected regions by either activating across an entire object or misidentifying
relevant concept-specific regions. We analyse the root causes of these
limitations, such as the natural correlation of concepts. Our findings
underscore the need for more careful application of concept-based explanation
techniques especially in settings where spatial interpretability is critical.

摘要：基於概念的解釋方法，例如概念瓶頸模型 (CBM)，旨在透過將機器學習模型的決策與人類可理解的概念連結，來提升機器學習模型的可解釋性，其關鍵假設為此類概念可以準確地歸因於網路的特徵空間。然而，此項基礎假設尚未經過嚴格驗證，主要是因為該領域缺乏標準化指標和基準來評估此類概念的存在和空間對齊。為了解決這個問題，我們提出三項指標：概念整體重要性指標、概念存在指標和概念位置指標，包括一種用於視覺化概念活化，即概念活化對應的技術。我們對事後 CBM 進行基準測試，以說明它們的能力和挑戰。透過定性和定量實驗，我們證明，在許多情況下，即使是由事後 CBM 確定的最重要概念也不存在於輸入影像中；此外，當它們存在時，它們的顯著性圖無法與預期的區域對齊，原因可能是它們在整個物件中活化，或錯誤辨識出相關的概念特定區域。我們分析了這些限制的根本原因，例如概念的自然相關性。我們的研究結果強調需要更小心地應用基於概念的解釋技術，特別是在空間可解釋性至關重要的設定中。

##### **Jackpot! Alignment as a Maximal Lottery**
2501.19266v1 by Roberto-Rafael Maura-Rivero, Marc Lanctot, Francesco Visin, Kate Larson

Reinforcement Learning from Human Feedback (RLHF), the standard for aligning
Large Language Models (LLMs) with human values, is known to fail to satisfy
properties that are intuitively desirable, such as respecting the preferences
of the majority \cite{ge2024axioms}. To overcome these issues, we propose the
use of a probabilistic Social Choice rule called \emph{maximal lotteries} as a
replacement for RLHF. We show that a family of alignment techniques, namely
Nash Learning from Human Feedback (NLHF) \cite{munos2023nash} and variants,
approximate maximal lottery outcomes and thus inherit its beneficial
properties.
  We confirm experimentally that our proposed methodology handles situations
that arise when working with preferences more robustly than standard RLHF,
including supporting the preferences of the majority, providing principled ways
of handling non-transitivities in the preference data, and robustness to
irrelevant alternatives. This results in systems that better incorporate human
values and respect human intentions.

摘要：人類回饋強化學習 (RLHF) 是調整大型語言模型 (LLM) 與人類價值觀的標準，已知無法滿足直觀上理想的屬性，例如尊重大多數人的偏好 \cite{ge2024axioms}。為了克服這些問題，我們建議使用稱為「最大樂透」的機率性社會選擇規則，作為 RLHF 的替代方案。我們證明了一系列調整技術，即人類回饋納許學習 (NLHF) \cite{munos2023nash} 及其變體，近似於最大樂透結果，因此繼承了其有益屬性。
我們透過實驗確認，我們提出的方法比標準 RLHF 更穩健地處理使用偏好時出現的情況，包括支持大多數人的偏好、提供處理偏好資料中非遞移性的原則性方法，以及對無關選項的穩健性。這會產生更好的納入人類價值觀並尊重人類意圖的系統。

##### **mFollowIR: a Multilingual Benchmark for Instruction Following in Retrieval**
2501.19264v1 by Orion Weller, Benjamin Chang, Eugene Yang, Mahsa Yarmohammadi, Sam Barham, Sean MacAvaney, Arman Cohan, Luca Soldaini, Benjamin Van Durme, Dawn Lawrie

Retrieval systems generally focus on web-style queries that are short and
underspecified. However, advances in language models have facilitated the
nascent rise of retrieval models that can understand more complex queries with
diverse intents. However, these efforts have focused exclusively on English;
therefore, we do not yet understand how they work across languages. We
introduce mFollowIR, a multilingual benchmark for measuring
instruction-following ability in retrieval models. mFollowIR builds upon the
TREC NeuCLIR narratives (or instructions) that span three diverse languages
(Russian, Chinese, Persian) giving both query and instruction to the retrieval
models. We make small changes to the narratives and isolate how well retrieval
models can follow these nuanced changes. We present results for both
multilingual (XX-XX) and cross-lingual (En-XX) performance. We see strong
cross-lingual performance with English-based retrievers that trained using
instructions, but find a notable drop in performance in the multilingual
setting, indicating that more work is needed in developing data for
instruction-based multilingual retrievers.

摘要：檢索系統通常專注於簡短且未指定之網路式查詢。然而，語言模型的進展促成了檢索模型的初步興起，這些模型能夠理解具有不同意圖的更複雜查詢。然而，這些努力專注於英文；因此，我們尚未了解它們如何跨語言運作。我們引入了 mFollowIR，這是一個多語言基準，用於衡量檢索模型中遵循指令的能力。mFollowIR 建立在 TREC NeuCLIR 敘事（或指令）之上，這些敘事跨越三種不同的語言（俄語、中文、波斯語），為檢索模型提供查詢和指令。我們對敘事進行了微小的更改，並隔離檢索模型遵循這些細微更改的程度。我們針對多語言 (XX-XX) 和跨語言 (En-XX) 效能呈現結果。我們看到使用指令訓練的基於英文的檢索器具有強大的跨語言效能，但在多語言環境中發現效能顯著下降，這表明需要在開發用於基於指令的多語言檢索器的資料方面投入更多工作。

##### **VisualSpeech: Enhance Prosody with Visual Context in TTS**
2501.19258v1 by Shumin Que, Anton Ragni

Text-to-Speech (TTS) synthesis faces the inherent challenge of producing
multiple speech outputs with varying prosody from a single text input. While
previous research has addressed this by predicting prosodic information from
both text and speech, additional contextual information, such as visual
features, remains underutilized. This paper investigates the potential of
integrating visual context to enhance prosody prediction. We propose a novel
model, VisualSpeech, which incorporates both visual and textual information for
improved prosody generation. Empirical results demonstrate that visual features
provide valuable prosodic cues beyond the textual input, significantly
enhancing the naturalness and accuracy of the synthesized speech. Audio samples
are available at https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/.

摘要：文字轉語音（TTS）合成面臨著一個固有挑戰，即從單一文字輸入產生具有不同語調的多個語音輸出。雖然先前的研究已透過從文字和語音預測語調資訊來解決這個問題，但額外的脈絡資訊（例如視覺特徵）仍未得到充分利用。本文探討了整合視覺脈絡以增強語調預測的潛力。我們提出了一個創新的模型 VisualSpeech，它結合了視覺和文字資訊，以改善語調產生。實證結果表明，視覺特徵提供了超越文字輸入的寶貴語調線索，顯著提高了合成語音的自然性和準確性。音訊範例可在 https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/ 取得。

##### **SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments**
2501.19245v2 by Hüseyin Aydın, Kevin Godin-Dubois, Libio Goncalvez Braz, Floris den Hengst, Kim Baraka, Mustafa Mert Çelikok, Andreas Sauter, Shihan Wang, Frans A. Oliehoek

Reinforcement learning (RL) offers a general approach for modeling and
training AI agents, including human-AI interaction scenarios. In this paper, we
propose SHARPIE (Shared Human-AI Reinforcement Learning Platform for
Interactive Experiments) to address the need for a generic framework to support
experiments with RL agents and humans. Its modular design consists of a
versatile wrapper for RL environments and algorithm libraries, a
participant-facing web interface, logging utilities, deployment on popular
cloud and participant recruitment platforms. It empowers researchers to study a
wide variety of research questions related to the interaction between humans
and RL agents, including those related to interactive reward specification and
learning, learning from human feedback, action delegation, preference
elicitation, user-modeling, and human-AI teaming. The platform is based on a
generic interface for human-RL interactions that aims to standardize the field
of study on RL in human contexts.

摘要：強化學習 (RL) 提供一種通用方法，用於建模和訓練 AI 代理，包括人機互動場景。在本文中，我們提出 SHARPIE（共享人機強化學習平台，用於互動式實驗），以滿足支援 RL 代理和人類實驗的通用框架需求。其模組化設計包含一個通用包裝器，用於 RL 環境和演算法函式庫、一個與參與者互動的網路介面、記錄公用程式、部署在熱門雲端和參與者招募平台上。它讓研究人員能夠研究各種與人類和 RL 代理互動相關的研究問題，包括與互動式獎勵規格和學習、從人類回饋中學習、動作委派、偏好引導、使用者建模和人機團隊合作相關的問題。該平台基於人機 RL 互動的通用介面，旨在標準化人類環境中 RL 的研究領域。

##### **A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation**
2501.19232v1 by Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu

Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions
in unseen domains without the need for additional training or fine-tuning,
making it particularly valuable in data-sparse environments where traditional
models struggle. Recent advancements in large language models (LLMs) have
greatly improved ZCDSR by leveraging rich pretrained representations to
facilitate cross-domain knowledge transfer. However, a key challenge persists:
domain semantic bias, which arises from variations in vocabulary and content
focus across domains. This misalignment leads to inconsistencies in item
embeddings and hinders generalization.
  To address this issue, we propose a novel framework designed to enhance
LLM-based ZCDSR by improving cross-domain alignment at both the item and
sequential levels. At the item level, we introduce a generalization loss that
promotes inter-domain compactness by aligning embeddings of similar items
across domains while maintaining intra-domain diversity to preserve unique item
characteristics. This prevents embeddings from becoming overly generic while
ensuring effective transferability. At the sequential level, we develop a
method for transferring user behavioral patterns by clustering user sequences
in the source domain and applying attention-based aggregation for target domain
inference. This dynamic adaptation of user embeddings allows effective
zero-shot recommendations without requiring target-domain interactions.
  Comprehensive experiments across multiple datasets and domains demonstrate
that our framework significantly improves sequential recommendation performance
in the ZCDSR setting. By mitigating domain bias and enhancing the
transferability of sequential patterns, our method provides a scalable and
robust approach for achieving more effective zero-shot recommendations across
domains.

摘要：<paragraph>零次學習跨網域序貫推薦 (ZCDSR) 可在無需額外訓練或微調的情況下對不可見網域進行預測，這使其在傳統模型難以應付的資料稀疏環境中特別有價值。大型語言模型 (LLM) 的最新進展已大幅改善 ZCDSR，方法是利用豐富的預訓練表示來促進跨網域知識轉移。然而，一個關鍵挑戰仍然存在：網域語義偏差，這源於網域間詞彙和內容焦點的變化。這種錯位導致項目嵌入的不一致，並阻礙概括。
  為了解決這個問題，我們提出了一個新穎的框架，旨在透過改善項目和序貫層級的跨網域對齊來增強基於 LLM 的 ZCDSR。在項目層級，我們引入一個概括損失，透過在網域間對齊相似項目的嵌入來促進網域間的緊密性，同時維持網域內的差異性以保留獨特的項目特徵。這可防止嵌入變得過於通用，同時確保有效的可轉移性。在序貫層級，我們開發了一種方法來轉移使用者行為模式，方法是在來源網域中對使用者序列進行分群，並對目標網域推論應用基於注意力的聚合。這種使用者嵌入的動態適應允許有效的零次學習推薦，而不需要目標網域互動。
  跨多個資料集和網域的全面實驗證明，我們的框架顯著改善了 ZCDSR 設定中的序貫推薦效能。透過減輕網域偏差並增強序貫模式的可轉移性，我們的模型提供了一個可擴充且穩健的方法，用於在網域間實現更有效的零次學習推薦。</paragraph>

##### **Integrating Semi-Supervised and Active Learning for Semantic Segmentation**
2501.19227v1 by Wanli Ma, Oktay Karakus, Paul L. Rosin

In this paper, we propose a novel active learning approach integrated with an
improved semi-supervised learning framework to reduce the cost of manual
annotation and enhance model performance. Our proposed approach effectively
leverages both the labelled data selected through active learning and the
unlabelled data excluded from the selection process. The proposed active
learning approach pinpoints areas where the pseudo-labels are likely to be
inaccurate. Then, an automatic and efficient pseudo-label auto-refinement
(PLAR) module is proposed to correct pixels with potentially erroneous
pseudo-labels by comparing their feature representations with those of labelled
regions. This approach operates without increasing the labelling budget and is
based on the cluster assumption, which states that pixels belonging to the same
class should exhibit similar representations in feature space. Furthermore,
manual labelling is only applied to the most difficult and uncertain areas in
unlabelled data, where insufficient information prevents the PLAR module from
making a decision. We evaluated the proposed hybrid semi-supervised active
learning framework on two benchmark datasets, one from natural and the other
from remote sensing imagery domains. In both cases, it outperformed
state-of-the-art methods in the semantic segmentation task.

摘要：在本文中，我们提出了一种新穎主動學習方法，並與一個改良的半監督學習框架整合，以降低人工標註的成本並提升模型效能。我們提出的方法有效地利用了主動學習中選取的標籤資料，以及從選擇過程中排除的未標籤資料。所提出的主動學習方法精確指出偽標籤可能不準確的地方。然後，提出一個自動且有效率的偽標籤自動精煉 (PLAR) 模組，透過將其特徵表示與標籤區域的特徵表示進行比較來修正具有潛在錯誤偽標籤的像素。此方法在不增加標籤預算的情況下運作，並基於叢集假設，該假設指出屬於同一類別的像素應在特徵空間中呈現類似的表示。此外，人工標籤僅用於未標籤資料中最困難且最不確定的區域，在這些區域中，資訊不足以讓 PLAR 模組做出決定。我們在兩個基準資料集上評估了所提出的混合半監督主動學習框架，一個來自自然，另一個來自遙感影像領域。在兩種情況下，它在語意分割任務中都優於最先進的方法。

##### **Improving the Robustness of Representation Misdirection for Large Language Model Unlearning**
2501.19202v2 by Dang Huu-Tien, Hoang Thanh-Tung, Le-Minh Nguyen, Naoya Inoue

Representation Misdirection (RM) and variants are established large language
model (LLM) unlearning methods with state-of-the-art performance. In this
paper, we show that RM methods inherently reduce models' robustness, causing
them to misbehave even when a single non-adversarial forget-token is in the
retain-query. Toward understanding underlying causes, we reframe the unlearning
process as backdoor attacks and defenses: forget-tokens act as backdoor
triggers that, when activated in retain-queries, cause disruptions in RM
models' behaviors, similar to successful backdoor attacks. To mitigate this
vulnerability, we propose Random Noise Augmentation -- a model and method
agnostic approach with theoretical guarantees for improving the robustness of
RM methods. Extensive experiments demonstrate that RNA significantly improves
the robustness of RM models while enhancing the unlearning performances.

摘要：表徵誤導 (RM) 及其變體是已建立的大型語言模型 (LLM) 忘記方法，具有最先進的效能。在本文中，我們展示 RM 方法本質上會降低模型的穩健性，導致它們在保留查詢中即使只有一個非對抗性的遺忘代碼也會出現異常行為。為了理解背後的原因，我們將忘記過程重新定義為後門攻擊和防禦：遺忘代碼充當後門觸發器，當在保留查詢中被啟動時，會造成 RM 模型行為的中斷，類似於成功的後門攻擊。為了減輕此漏洞，我們提出隨機雜訊擴充——一種模型和方法不可知的方法，具有提高 RM 方法穩健性的理論保證。廣泛的實驗表明，RNA 在增強忘記效能的同時，顯著提高了 RM 模型的穩健性。

##### **Efficient Reasoning with Hidden Thinking**
2501.19201v1 by Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, Jiuxiang Gu

Chain-of-Thought (CoT) reasoning has become a powerful framework for
improving complex problem-solving capabilities in Multimodal Large Language
Models (MLLMs). However, the verbose nature of textual reasoning introduces
significant inefficiencies. In this work, we propose $\textbf{Heima}$ (as
hidden llama), an efficient reasoning framework that leverages reasoning CoTs
at hidden latent space. We design the Heima Encoder to condense each
intermediate CoT into a compact, higher-level hidden representation using a
single thinking token, effectively minimizing verbosity and reducing the
overall number of tokens required during the reasoning process. Meanwhile, we
design corresponding Heima Decoder with traditional Large Language Models
(LLMs) to adaptively interpret the hidden representations into variable-length
textual sequence, reconstructing reasoning processes that closely resemble the
original CoTs. Experimental results across diverse reasoning MLLM benchmarks
demonstrate that Heima model achieves higher generation efficiency while
maintaining or even better zero-shot task accuracy. Moreover, the effective
reconstruction of multimodal reasoning processes with Heima Decoder validates
both the robustness and interpretability of our approach.

摘要：鏈式思考 (CoT) 推理已成為一種強大的框架，用於改善多模態大型語言模型 (MLLM) 中的複雜問題解決能力。然而，文本推理的冗長性質會造成顯著的低效率。在這項工作中，我們提出了 $\textbf{Heima}$（作為隱藏的羊駝），這是一個高效的推理框架，它利用隱藏潛在空間中的推理 CoT。我們設計了 Heima 編碼器，使用單一的思考標記將每個中間 CoT 壓縮成一個緊湊、更高級別的隱藏表示，有效地最小化冗長並減少推理過程中所需的總標記數。同時，我們設計了對應的 Heima 解碼器與傳統的大型語言模型 (LLM) 一起，自適應地將隱藏表示解釋為可變長度的文本序列，重建與原始 CoT 非常相似的推理過程。跨不同推理 MLLM 基準的實驗結果表明，Heima 模型在保持或甚至提高零次任務準確性的同時，實現了更高的生成效率。此外，使用 Heima 解碼器有效重建多模態推理過程驗證了我們方法的魯棒性和可解釋性。

##### **Secured Communication Schemes for UAVs in 5G: CRYSTALS-Kyber and IDS**
2501.19191v1 by Taneya Sharma, Seyed Ahmad Soleymani, Mohammad Shojafar, Rahim Tafazolli

This paper introduces a secure communication architecture for Unmanned Aerial
Vehicles (UAVs) and ground stations in 5G networks, addressing critical
challenges in network security. The proposed solution integrates the Advanced
Encryption Standard (AES) with Elliptic Curve Cryptography (ECC) and
CRYSTALS-Kyber for key encapsulation, offering a hybrid cryptographic approach.
By incorporating CRYSTALS-Kyber, the framework mitigates vulnerabilities in ECC
against quantum attacks, positioning it as a quantum-resistant alternative. The
architecture is based on a server-client model, with UAVs functioning as
clients and the ground station acting as the server. The system was rigorously
evaluated in both VPN and 5G environments. Experimental results confirm that
CRYSTALS-Kyber delivers strong protection against quantum threats with minimal
performance overhead, making it highly suitable for UAVs with resource
constraints. Moreover, the proposed architecture integrates an Artificial
Intelligence (AI)-based Intrusion Detection System (IDS) to further enhance
security. In performance evaluations, the IDS demonstrated strong results
across multiple models with XGBoost, particularly in more demanding scenarios,
outperforming other models with an accuracy of 97.33% and an AUC of 0.94. These
findings underscore the potential of combining quantum-resistant encryption
mechanisms with AI-driven IDS to create a robust, scalable, and secure
communication framework for UAV networks, particularly within the
high-performance requirements of 5G environments.

摘要：本文介紹了一個適用於 5G 網路中的無人機 (UAV) 和地面站的安全性通訊架構，用於解決網路安全中的重大挑戰。建議的解決方案將進階加密標準 (AES) 與橢圓曲線密碼學 (ECC) 和 CRYSTALS-Kyber 整合，用於金鑰封裝，提供混合式密碼學方法。透過整合 CRYSTALS-Kyber，架構可減輕 ECC 在量子攻擊中的漏洞，將其定位為抗量子替代方案。此架構基於伺服器-用戶端模型，其中無人機運作為用戶端，而地面站則作為伺服器。此系統在 VPN 和 5G 環境中都經過嚴格評估。實驗結果證實，CRYSTALS-Kyber 能在效能負擔最小的情況下提供強大的量子威脅防護，使其非常適合具有資源限制的無人機。此外，建議的架構整合了一個基於人工智慧 (AI) 的入侵偵測系統 (IDS)，以進一步增強安全性。在效能評估中，IDS 在多個模型中展現強勁的結果，尤其是在更嚴苛的場景中，以 97.33% 的準確率和 0.94 的 AUC 優於其他模型。這些發現強調了將抗量子加密機制與 AI 驅動的 IDS 結合起來的潛力，以建立一個強固、可擴充且安全的無人機網路通訊架構，特別是在 5G 環境的高效能需求中。

##### **Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning**
2501.19180v1 by Xianglin Yang, Gelei Deng, Jieming Shi, Tianwei Zhang, Jin Song Dong

Large language models (LLMs) are vital for a wide range of applications yet
remain susceptible to jailbreak threats, which could lead to the generation of
inappropriate responses. Conventional defenses, such as refusal and adversarial
training, often fail to cover corner cases or rare domains, leaving LLMs still
vulnerable to more sophisticated attacks. We propose a novel defense strategy,
Safety Chain-of-Thought (SCoT), which harnesses the enhanced \textit{reasoning
capabilities} of LLMs for proactive assessment of harmful inputs, rather than
simply blocking them. SCoT augments any refusal training datasets to critically
analyze the intent behind each request before generating answers. By employing
proactive reasoning, SCoT enhances the generalization of LLMs across varied
harmful queries and scenarios not covered in the safety alignment corpus.
Additionally, it generates detailed refusals specifying the rules violated.
Comparative evaluations show that SCoT significantly surpasses existing
defenses, reducing vulnerability to out-of-distribution issues and adversarial
manipulations while maintaining strong general capabilities.

摘要：大型語言模型 (LLM) 對廣泛的應用至關重要，但仍容易受到越獄威脅，這可能會導致產生不適當的回應。傳統防禦措施，例如拒絕和對抗訓練，通常無法涵蓋邊緣案例或罕見領域，這使得 LLM 仍然容易受到更複雜的攻擊。我們提出了一種新穎的防禦策略，即安全思考鏈 (SCoT)，它利用 LLM 增強的推理能力來主動評估有害輸入，而不是簡單地阻止它們。SCoT 擴充任何拒絕訓練資料集，以便在產生答案之前批判性地分析每個請求背後的意圖。通過採用主動推理，SCoT 增強了 LLM 對安全對齊語料庫中未涵蓋的各種有害查詢和場景的概括。此外，它還會產生詳細的拒絕，說明所違反的規則。比較評估表明，SCoT 明顯優於現有防禦措施，降低了對分佈外問題和對抗操作的脆弱性，同時保持了強大的通用能力。

##### **Improving Multi-Label Contrastive Learning by Leveraging Label Distribution**
2501.19145v1 by Ning Chen, Shen-Huan Lyu, Tian-Shuang Wu, Yanyan Wang, Bin Tang

In multi-label learning, leveraging contrastive learning to learn better
representations faces a key challenge: selecting positive and negative samples
and effectively utilizing label information. Previous studies selected positive
and negative samples based on the overlap between labels and used them for
label-wise loss balancing. However, these methods suffer from a complex
selection process and fail to account for the varying importance of different
labels. To address these problems, we propose a novel method that improves
multi-label contrastive learning through label distribution. Specifically, when
selecting positive and negative samples, we only need to consider whether there
is an intersection between labels. To model the relationships between labels,
we introduce two methods to recover label distributions from logical labels,
based on Radial Basis Function (RBF) and contrastive loss, respectively. We
evaluate our method on nine widely used multi-label datasets, including image
and vector datasets. The results demonstrate that our method outperforms
state-of-the-art methods in six evaluation metrics.

摘要：在多標籤學習中，利用對比學習來學習更好的表示會面臨一個關鍵挑戰：選擇正負樣本並有效利用標籤資訊。先前的研究根據標籤之間的重疊來選擇正負樣本，並將它們用於標籤明智的損失平衡。然而，這些方法會產生複雜的選擇過程，而且無法考量不同標籤的重要性差異。為了解決這些問題，我們提出了一種新方法，透過標籤分佈來改善多標籤對比學習。具體來說，在選擇正負樣本時，我們只需要考慮標籤之間是否有交集。為了建立標籤之間的關係，我們引入了兩種方法，分別根據徑向基函數 (RBF) 和對比損失從邏輯標籤中恢復標籤分佈。我們在九個廣泛使用的多標籤資料集上評估了我們的方法，包括影像和向量資料集。結果表明，我們的模型在六個評估指標上優於最先進的方法。

##### **Imitation Game for Adversarial Disillusion with Multimodal Generative Chain-of-Thought Role-Play**
2501.19143v1 by Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen

As the cornerstone of artificial intelligence, machine perception confronts a
fundamental threat posed by adversarial illusions. These adversarial attacks
manifest in two primary forms: deductive illusion, where specific stimuli are
crafted based on the victim model's general decision logic, and inductive
illusion, where the victim model's general decision logic is shaped by specific
stimuli. The former exploits the model's decision boundaries to create a
stimulus that, when applied, interferes with its decision-making process. The
latter reinforces a conditioned reflex in the model, embedding a backdoor
during its learning phase that, when triggered by a stimulus, causes aberrant
behaviours. The multifaceted nature of adversarial illusions calls for a
unified defence framework, addressing vulnerabilities across various forms of
attack. In this study, we propose a disillusion paradigm based on the concept
of an imitation game. At the heart of the imitation game lies a multimodal
generative agent, steered by chain-of-thought reasoning, which observes,
internalises and reconstructs the semantic essence of a sample, liberated from
the classic pursuit of reversing the sample to its original state. As a proof
of concept, we conduct experimental simulations using a multimodal generative
dialogue agent and evaluates the methodology under a variety of attack
scenarios.

摘要：作為人工智慧的基石，機器感知面臨對抗性幻覺所帶來的根本威脅。這些對抗性攻擊主要表現為兩種形式：演繹幻覺，其中特定刺激是根據受害者模型的通用決策邏輯而設計的，以及歸納幻覺，其中受害者模型的通用決策邏輯是由特定刺激形成的。前者利用模型的決策邊界來創建一個刺激，當應用時會干擾其決策過程。後者在模型中強化條件反射，在其學習階段嵌入一個後門，當被刺激觸發時，會導致異常行為。對抗性幻覺的多方面性質需要一個統一的防禦框架，以解決各種形式的攻擊中的漏洞。在本研究中，我們提出了一個基於模仿遊戲概念的幻滅範例。模仿遊戲的核心是一個多模態生成代理，由思想鏈推理引導，它觀察、內化和重建樣本的語義本質，擺脫了將樣本恢復到其原始狀態的經典追求。作為概念驗證，我們使用多模態生成對話代理進行實驗模擬，並在各種攻擊場景下評估該方法。

##### **A Metric for the Balance of Information in Graph Learning**
2501.19137v1 by Alex O. Davies, Nirav S. Ajmeri, Telmo de Menezes e Silva Filho

Graph learning on molecules makes use of information from both the molecular
structure and the features attached to that structure. Much work has been
conducted on biasing either towards structure or features, with the aim that
bias bolsters performance. Identifying which information source a dataset
favours, and therefore how to approach learning that dataset, is an open issue.
Here we propose Noise-Noise Ratio Difference (NNRD), a quantitative metric for
whether there is more useful information in structure or features. By employing
iterative noising on features and structure independently, leaving the other
intact, NNRD measures the degradation of information in each. We employ NNRD
over a range of molecular tasks, and show that it corresponds well to a loss of
information, with intuitive results that are more expressive than simple
performance aggregates. Our future work will focus on expanding data domains,
tasks and types, as well as refining our choice of baseline model.

摘要：分子上的圖形學習利用分子結構和附加到該結構上的特徵中的資訊。許多工作已針對結構或特徵進行偏向，目的是偏向能增強效能。識別資料集偏好的資訊來源，因此如何著手學習該資料集，是一個開放性的問題。在此，我們提出雜訊雜訊比差異 (NNRD)，一個量化指標，用於判斷結構或特徵中是否有更多有用的資訊。透過獨立地對特徵和結構進行反覆雜訊處理，讓另一個保持完整，NNRD 測量每個資訊的劣化程度。我們在各種分子任務上採用 NNRD，並顯示它與資訊損失非常吻合，其直觀的結果比簡單的效能彙總更具表達力。我們的未來工作將專注於擴充資料領域、任務和類型，以及精進我們對基線模型的選擇。

##### **Mixed Feelings: Cross-Domain Sentiment Classification of Patient Feedback**
2501.19134v1 by Egil Rønningstad, Lilja Charlotte Storset, Petter Mæhlum, Lilja Øvrelid, Erik Velldal

Sentiment analysis of patient feedback from the public health domain can aid
decision makers in evaluating the provided services. The current paper focuses
on free-text comments in patient surveys about general practitioners and
psychiatric healthcare, annotated with four sentence-level polarity classes --
positive, negative, mixed and neutral -- while also attempting to alleviate
data scarcity by leveraging general-domain sources in the form of reviews. For
several different architectures, we compare in-domain and out-of-domain
effects, as well as the effects of training joint multi-domain models.

摘要：從公共衛生領域收集的患者回饋意見的情緒分析，可以協助決策者評估所提供的服務。本篇論文重點關注患者針對一般科醫師和精神科醫療保健所進行的調查中的自由文字評論，並註記了四種句子層級的極性分類 -- 正面、負面、混合和中立 -- 同時也試圖透過利用評論形式的通用領域來源來緩解資料的稀少性。對於幾個不同的架構，我們比較了領域內和領域外的影響，以及訓練聯合多領域模型的影響。

##### **FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling**
2501.19122v1 by Hong Huang, Hai Yang, Yuan Chen, Jiaxun Ye, Dapeng Wu

Federated Learning (FL) enables collaborative model training across
distributed clients without data sharing, but its high computational and
communication demands strain resource-constrained devices. While existing
methods use dynamic pruning to improve efficiency by periodically adjusting
sparse model topologies while maintaining sparsity, these approaches suffer
from issues such as greedy adjustments, unstable topologies, and communication
inefficiency, resulting in less robust models and suboptimal performance under
data heterogeneity and partial client availability. To address these
challenges, we propose Federated Robust pruning via combinatorial Thompson
Sampling (FedRTS), a novel framework designed to develop robust sparse models.
FedRTS enhances robustness and performance through its Thompson Sampling-based
Adjustment (TSAdj) mechanism, which uses probabilistic decisions informed by
stable, farsighted information instead of deterministic decisions reliant on
unstable and myopic information in previous methods. Extensive experiments
demonstrate that FedRTS achieves state-of-the-art performance in computer
vision and natural language processing tasks while reducing communication
costs, particularly excelling in scenarios with heterogeneous data
distributions and partial client participation. Our codes are available at:
https://github.com/Little0o0/FedRTS

摘要：聯邦學習 (FL) 能在無資料分享的情況下，讓分散式客戶端進行協作模型訓練，但其高運算和通訊需求會對資源受限裝置造成負擔。現有方法使用動態剪枝，透過定期調整稀疏模型拓撲並維持稀疏性來提升效率，但這些方法有貪婪調整、拓撲不穩定、通訊效率低落等問題，導致模型穩健性較低，且在資料異質性和部分客戶端可用性的情況下，效能不佳。為了應對這些挑戰，我們提出透過組合式 Thompson 採樣進行聯邦穩健剪枝 (FedRTS)，這是一個旨在開發穩健稀疏模型的新穎架構。FedRTS 透過其基於 Thompson 採樣的調整 (TSAdj) 機制提升穩健性和效能，此機制使用由穩定、有遠見的資訊所提供的機率決策，而非仰賴先前方法中不穩定且短視的資訊所做的確定性決策。大量的實驗證明 FedRTS 在電腦視覺和自然語言處理任務中達到最先進的效能，同時降低通訊成本，特別是在資料分佈異質且客戶端參與度不完整的情況下表現出色。我們的程式碼可於以下網址取得：https://github.com/Little0o0/FedRTS

##### **Principal Components for Neural Network Initialization**
2501.19114v1 by Nhan Phan, Thu Nguyen, Pål Halvorsen, Michael A. Riegler

Principal Component Analysis (PCA) is a commonly used tool for dimension
reduction and denoising. Therefore, it is also widely used on the data prior to
training a neural network. However, this approach can complicate the
explanation of explainable AI (XAI) methods for the decision of the model. In
this work, we analyze the potential issues with this approach and propose
Principal Components-based Initialization (PCsInit), a strategy to incorporate
PCA into the first layer of a neural network via initialization of the first
layer in the network with the principal components, and its two variants
PCsInit-Act and PCsInit-Sub. Explanations using these strategies are as direct
and straightforward as for neural networks and are simpler than using PCA prior
to training a neural network on the principal components. Moreover, as will be
illustrated in the experiments, such training strategies can also allow further
improvement of training via backpropagation.

摘要：主成分分析 (PCA) 是一種常用的降維和去噪工具。因此，它也廣泛用於訓練神經網路之前對資料進行處理。然而，這種方法會使可解釋 AI (XAI) 方法對模型決策的解釋變得複雜。在這項工作中，我們分析了這種方法的潛在問題，並提出了基於主成分的初始化 (PCsInit)，這是一種通過使用主成分對網路中的第一層進行初始化，將 PCA 納入神經網路第一層的策略，以及它的兩個變體 PCsInit-Act 和 PCsInit-Sub。使用這些策略的解釋與神經網路一樣直接且簡潔，並且比在對主成分訓練神經網路之前使用 PCA 更簡單。此外，正如實驗中所展示的那樣，這種訓練策略還可以進一步提高通過反向傳播進行的訓練。

##### **PathE: Leveraging Entity-Agnostic Paths for Parameter-Efficient Knowledge Graph Embeddings**
2501.19095v1 by Ioannis Reklos, Jacopo de Berardinis, Elena Simperl, Albert Meroño-Peñuela

Knowledge Graphs (KGs) store human knowledge in the form of entities (nodes)
and relations, and are used extensively in various applications. KG embeddings
are an effective approach to addressing tasks like knowledge discovery, link
prediction, and reasoning. This is often done by allocating and learning
embedding tables for all or a subset of the entities. As this scales linearly
with the number of entities, learning embedding models in real-world KGs with
millions of nodes can be computationally intractable. To address this
scalability problem, our model, PathE, only allocates embedding tables for
relations (which are typically orders of magnitude fewer than the entities) and
requires less than 25% of the parameters of previous parameter efficient
methods. Rather than storing entity embeddings, we learn to compute them by
leveraging multiple entity-relation paths to contextualise individual entities
within triples. Evaluated on four benchmarks, PathE achieves state-of-the-art
performance in relation prediction, and remains competitive in link prediction
on path-rich KGs while training on consumer-grade hardware. We perform ablation
experiments to test our design choices and analyse the sensitivity of the model
to key hyper-parameters. PathE is efficient and cost-effective for relationally
diverse and well-connected KGs commonly found in real-world applications.

摘要：知識圖譜 (KG) 以實體 (節點) 和關係的形式儲存人類知識，並廣泛用於各種應用程式中。KG 嵌入是一種有效的方法，可解決知識發現、連結預測和推理等任務。這通常透過配置和學習所有實體或實體子集的嵌入式表格來完成。由於這會隨著實體數量線性擴充，在擁有數百萬個節點的真實世界 KG 中學習嵌入式模型在計算上可能難以處理。為了解決這個可擴充性問題，我們的模型 PathE 只配置關係的嵌入式表格 (通常數量比實體少幾個數量級)，並且所需參數少於先前參數有效率方法的 25%。我們並非儲存實體嵌入，而是學習透過利用多個實體關係路徑來計算它們，以將個別實體在三元組中脈絡化。在四個基準上進行評估，PathE 在關係預測中達到最先進的效能，並在路徑豐富的 KG 上的連結預測中保持競爭力，同時在消費級硬體上進行訓練。我們執行消融實驗來測試我們的設計選擇，並分析模型對關鍵超參數的敏感性。PathE 對於在真實世界應用中常見的關係多樣且連線良好的 KG 而言，既有效率又具有成本效益。

##### **Improving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations**
2501.19093v1 by Peichao Lai, Jiaxin Gan, Feiyang Ye, Yilei Wang, Bin Cui

Sequence labeling remains a significant challenge in low-resource,
domain-specific scenarios, particularly for character-dense languages like
Chinese. Existing methods primarily focus on enhancing model comprehension and
improving data diversity to boost performance. However, these approaches still
struggle with inadequate model applicability and semantic distribution biases
in domain-specific contexts. To overcome these limitations, we propose a novel
framework that combines an LLM-based knowledge enhancement workflow with a
span-based Knowledge Fusion for Rich and Efficient Extraction (KnowFREE) model.
Our workflow employs explanation prompts to generate precise contextual
interpretations of target entities, effectively mitigating semantic biases and
enriching the model's contextual understanding. The KnowFREE model further
integrates extension label features, enabling efficient nested entity
extraction without relying on external knowledge during inference. Experiments
on multiple Chinese domain-specific sequence labeling datasets demonstrate that
our approach achieves state-of-the-art performance, effectively addressing the
challenges posed by low-resource settings.

摘要：序列標籤在低資源、特定領域場景中仍然是一個重大的挑戰，特別是對於像中文這樣的字元密集語言而言。現有方法主要著重於增強模型理解並改善資料多樣性以提升效能。然而，這些方法在特定領域脈絡中仍受限於模型適用性不足和語義分佈偏差。為了克服這些限制，我們提出一個新的框架，結合基於 LLM 的知識增強工作流程和基於 span 的豐富且有效抽取知識融合 (KnowFREE) 模型。我們的流程採用解釋提示來產生目標實體的精確脈絡詮釋，有效減輕語義偏差並豐富模型的脈絡理解。KnowFREE 模型進一步整合延伸標籤功能，在推理期間無需依賴外部知識即可進行有效的巢狀實體抽取。在多個中文特定領域序列標籤資料集上的實驗表明，我們的做法達到了最先進的效能，有效地應對了低資源設定所帶來的挑戰。

##### **Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**
2501.19086v1 by Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang

X-ray imaging is pivotal in medical diagnostics, offering non-invasive
insights into a range of health conditions. Recently, vision-language models,
such as the Contrastive Language-Image Pretraining (CLIP) model, have
demonstrated potential in improving diagnostic accuracy by leveraging
large-scale image-text datasets. However, since CLIP was not initially designed
for medical images, several CLIP-like models trained specifically on medical
images have been developed. Despite their enhanced performance, issues of
fairness - particularly regarding demographic attributes - remain largely
unaddressed. In this study, we perform a comprehensive fairness analysis of
CLIP-like models applied to X-ray image classification. We assess their
performance and fairness across diverse patient demographics and disease
categories using zero-shot inference and various fine-tuning techniques,
including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation
(LoRA), and full fine-tuning. Our results indicate that while fine-tuning
improves model accuracy, fairness concerns persist, highlighting the need for
further fairness interventions in these foundational models.

摘要：X 光影像在醫療診斷中至關重要，能提供各種健康狀況的非侵入性見解。最近，視覺語言模型（例如對比語言影像預訓練 (CLIP) 模型）已證明有潛力透過利用大規模影像文字資料集來改善診斷準確性。然而，由於 CLIP 最初並非設計用於醫療影像，因此已經開發了數個特別針對醫療影像訓練的類似 CLIP 模型。儘管它們的效能有所提升，但公平性的問題（特別是關於人口統計屬性）仍大多未獲解決。在本研究中，我們對應用於 X 光影像分類的類似 CLIP 模型執行全面的公平性分析。我們使用零次學習推論和各種微調技術（包括線性探查、多層感知器 (MLP)、低秩適應 (LoRA) 和完整微調）來評估它們在不同患者人口統計和疾病類別中的效能和公平性。我們的結果表明，雖然微調會改善模型準確性，但公平性問題仍然存在，強調需要在這些基礎模型中進一步採取公平性干預措施。

##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

摘要：<paragraph>為了彌合視覺和語言 (VL) 之間的語意差距，必須制定良好的對齊策略，其中包括處理語意多樣性、視覺資訊的抽象表示以及模型的泛化能力。最近的研究使用基於偵測器的邊界框或具有規則分割的區塊來表示視覺語意。雖然目前的範例已取得進展，但對於完全捕捉各種物件之間的細微脈絡關係仍不足夠。本文提出了一個全面的視覺語意表示模組，需要利用全景分割來產生連貫的細粒度語意特徵。此外，我們提出了一個新穎的圖形脈衝混合網路 (GSHN)，它整合了脈衝神經網路 (SNN) 和圖形注意力網路 (GAT) 的互補優勢來編碼視覺語意資訊。有趣的是，該模型不僅編碼實例的離散和連續潛在變數，還能巧妙地捕捉局部和全域脈絡特徵，從而顯著增強語意表示的豐富性和多樣性。利用 SNN 中固有的時空特性，我們採用對比學習 (CL) 來增強嵌入的基於相似性的表示。此策略減輕了模型的計算負擔，並透過建構正負樣本對來豐富有意義的視覺表示。我們設計了一個創新的預訓練方法，脈衝文本學習 (STL)，它使用文本特徵來提高離散語意的編碼能力。實驗表明，所提出的 GSHN 在多個 VL 下游任務上展現出有希望的結果。</paragraph>

##### **BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting**
2501.19065v1 by Zhixuan Li, Naipeng Chen, Seonghwa Choi, Sanghoon Lee, Weisi Lin

Time-series forecasting is crucial for numerous real-world applications
including weather prediction and financial market modeling. While
temporal-domain methods remain prevalent, frequency-domain approaches can
effectively capture multi-scale periodic patterns, reduce sequence
dependencies, and naturally denoise signals. However, existing approaches
typically train model components for all frequencies under a unified training
objective, often leading to mismatched learning speeds: high-frequency
components converge faster and risk overfitting, while low-frequency components
underfit due to insufficient training time. To deal with this challenge, we
propose BEAT (Balanced frEquency Adaptive Tuning), a novel framework that
dynamically monitors the training status for each frequency and adaptively
adjusts their gradient updates. By recognizing convergence, overfitting, or
underfitting for each frequency, BEAT dynamically reallocates learning
priorities, moderating gradients for rapid learners and increasing those for
slower ones, alleviating the tension between competing objectives across
frequencies and synchronizing the overall learning process. Extensive
experiments on seven real-world datasets demonstrate that BEAT consistently
outperforms state-of-the-art approaches.

摘要：時序預測對於許多實際應用至關重要，包括天氣預測和金融市場建模。雖然時域方法仍然普遍，但頻域方法可以有效捕捉多尺度週期模式，減少序列依賴性，並自然地對訊號進行去雜訊。然而，現有方法通常在統一訓練目標下為所有頻率訓練模型組件，這通常會導致學習速度不匹配：高頻組件收斂得更快，有過擬合的風險，而低頻組件由於訓練時間不足而欠擬合。為了應對這一挑戰，我們提出了 BEAT（平衡頻率自適應調整），這是一個新的框架，可以動態監控每個頻率的訓練狀態，並自適應地調整它們的梯度更新。通過識別每個頻率的收斂、過擬合或欠擬合，BEAT 動態重新分配學習優先級，調節快速學習者的梯度，並增加慢速學習者的梯度，緩解了跨頻率競爭目標之間的緊張關係，並同步了整體學習過程。在七個真實世界資料集上的大量實驗表明，BEAT 持續優於最先進的方法。

##### **Enabling Autonomic Microservice Management through Self-Learning Agents**
2501.19056v1 by Fenglin Yu, Fangkai Yang, Xiaoting Qin, Zhiyang Zhang, Jue Zhang, Qingwei Lin, Hongyu Zhang, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

The increasing complexity of modern software systems necessitates robust
autonomic self-management capabilities. While Large Language Models (LLMs)
demonstrate potential in this domain, they often face challenges in adapting
their general knowledge to specific service contexts. To address this
limitation, we propose ServiceOdyssey, a self-learning agent system that
autonomously manages microservices without requiring prior knowledge of
service-specific configurations. By leveraging curriculum learning principles
and iterative exploration, ServiceOdyssey progressively develops a deep
understanding of operational environments, reducing dependence on human input
or static documentation. A prototype built with the Sock Shop microservice
demonstrates the potential of this approach for autonomic microservice
management.

摘要：現代軟體系統日益複雜，需要強大的自主自我管理能力。儘管大型語言模型 (LLM) 在此領域展現潛力，但它們在將一般知識調整至特定服務情境時，經常面臨挑戰。為了解決此限制，我們提出 ServiceOdyssey，一個自學代理系統，可自主管理微服務，而無需事先了解特定服務的組態。透過利用課程學習原則和反覆探索，ServiceOdyssey 逐步培養對作業環境的深入了解，減少對人工輸入或靜態文件依賴。使用 Sock Shop 微服務建構的原型展示了此方法在自主微服務管理方面的潛力。

##### **Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer**
2501.19055v1 by Lingwei Zhu, Zheng Chen, Yukie Nagai, Jimeng Sun

This paper adds to the growing literature of reinforcement learning (RL) for
healthcare by proposing a novel paradigm: augmenting any predictor with
Rule-based RL Layer (RRLL) that corrects the model's physiologically impossible
predictions. Specifically, RRLL takes as input states predicted labels and
outputs corrected labels as actions. The reward of the state-action pair is
evaluated by a set of general rules. RRLL is efficient, general and
lightweight: it does not require heavy expert knowledge like prior work but
only a set of impossible transitions. This set is much smaller than all
possible transitions; yet it can effectively reduce physiologically impossible
mistakes made by the state-of-the-art predictor models. We verify the utility
of RRLL on a variety of important healthcare classification problems and
observe significant improvements using the same setup, with only the
domain-specific set of impossibility changed. In-depth analysis shows that RRLL
indeed improves accuracy by effectively reducing the presence of
physiologically impossible predictions.

摘要：這篇論文透過提出一個新的範例，為醫療保健的強化學習 (RL) 不斷增加的文獻增添內容：用基於規則的 RL 層 (RRLL) 來擴充任何預測器，以修正模型在生理上不可能的預測。具體來說，RRLL 以預測標籤作為輸入狀態，並輸出修正標籤作為動作。狀態動作對的獎勵是由一組一般規則所評估。RRLL 既有效率、一般性又輕量級：它不需要像先前的研究那樣具備大量的專家知識，而只需要一組不可能的轉換。這組轉換比所有可能的轉換小得多；但它可以有效減少最先進的預測器模型所產生的生理上不可能的錯誤。我們驗證了 RRLL 在各種重要的醫療保健分類問題上的效用，並觀察到在使用相同設定的情況下，只有特定領域的不可能性集有所改變，便有顯著的改善。深入分析顯示，RRLL 確實透過有效減少生理上不可能的預測，來提升準確度。

##### **Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)**
2501.19047v2 by Maja Pavlovic

To be considered reliable, a model must be calibrated so that its confidence
in each decision closely reflects its true outcome. In this blogpost we'll take
a look at the most commonly used definition for calibration and then dive into
a frequently used evaluation measure for model calibration. We'll then cover
some of the drawbacks of this measure and how these surfaced the need for
additional notions of calibration, which require their own new evaluation
measures. This post is not intended to be an in-depth dissection of all works
on calibration, nor does it focus on how to calibrate models. Instead, it is
meant to provide a gentle introduction to the different notions and their
evaluation measures as well as to re-highlight some issues with a measure that
is still widely used to evaluate calibration.

摘要：要被認為是可靠的，模型必須經過校準，以便它在每個決策中的信心準確反映其真實結果。在這個部落格文章中，我們將探討校準最常用的定義，然後深入探討模型校準常用的評估指標。然後，我們將涵蓋此指標的一些缺點，以及這些缺點如何浮現出對校準的其他概念的需求，這些概念需要自己的新評估指標。這篇文章並非旨在深入探討所有關於校準的作品，也不著重於如何校準模型。相反，它的目的是溫和地介紹不同的概念及其評估指標，並重新強調一個仍然廣泛用於評估校準的指標的一些問題。

##### **Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors**
2501.19042v1 by Simon Idoko, B. Bhanu Teja, K. Madhava Krishna, Arun Kumar Singh

Coordination behavior in robot swarms is inherently multi-modal in nature.
That is, there are numerous ways in which a swarm of robots can avoid
inter-agent collisions and reach their respective goals. However, the problem
of generating diverse and feasible swarm behaviors in a scalable manner remains
largely unaddressed. In this paper, we fill this gap by combining generative
models with a safety-filter (SF). Specifically, we sample diverse trajectories
from a learned generative model which is subsequently projected onto the
feasible set using the SF. We experiment with two choices for generative
models, namely: Conditional Variational Autoencoder (CVAE) and Vector-Quantized
Variational Autoencoder (VQ-VAE). We highlight the trade-offs these two models
provide in terms of computation time and trajectory diversity. We develop a
custom solver for our SF and equip it with a neural network that predicts
context-specific initialization. Thecinitialization network is trained in a
self-supervised manner, taking advantage of the differentiability of the SF
solver. We provide two sets of empirical results. First, we demonstrate that we
can generate a large set of multi-modal, feasible trajectories, simulating
diverse swarm behaviors, within a few tens of milliseconds. Second, we show
that our initialization network provides faster convergence of our SF solver
vis-a-vis other alternative heuristics.

摘要：機器人蜂群中的協調行為本質上是多模態的。
也就是說，機器人蜂群有許多方法可以避免機器人之間的碰撞並到達各自的目標。然而，以可擴充的方式產生多樣化且可行的蜂群行為的問題在很大程度上仍未解決。在本文中，我們透過結合生成模型和安全過濾器 (SF) 來填補此空白。具體來說，我們從一個學習的生成模型中取樣多樣化的軌跡，然後使用 SF 將其投影到可行集合上。我們實驗了兩種生成模型的選擇，即條件變異自動編碼器 (CVAE) 和向量量化變異自動編碼器 (VQ-VAE)。我們強調了這兩個模型在計算時間和軌跡多樣性方面的權衡取捨。我們為我們的 SF 開發了一個自訂求解器，並配備了一個預測特定於情境初始化的神經網路。初始化網路以自監督的方式進行訓練，利用 SF 求解器的可微分性。我們提供了兩組經驗結果。首先，我們證明我們可以在幾十毫秒內生成大量多模態、可行的軌跡，模擬多樣化的蜂群行為。其次，我們證明我們的初始化網路提供比其他替代啟發式方法更快的 SF 求解器收斂性。

##### **On the Impact of Noise in Differentially Private Text Rewriting**
2501.19022v1 by Stephen Meisenbacher, Maulik Chevli, Florian Matthes

The field of text privatization often leverages the notion of
$\textit{Differential Privacy}$ (DP) to provide formal guarantees in the
rewriting or obfuscation of sensitive textual data. A common and nearly
ubiquitous form of DP application necessitates the addition of calibrated noise
to vector representations of text, either at the data- or model-level, which is
governed by the privacy parameter $\varepsilon$. However, noise addition almost
undoubtedly leads to considerable utility loss, thereby highlighting one major
drawback of DP in NLP. In this work, we introduce a new sentence infilling
privatization technique, and we use this method to explore the effect of noise
in DP text rewriting. We empirically demonstrate that non-DP privatization
techniques excel in utility preservation and can find an acceptable empirical
privacy-utility trade-off, yet cannot outperform DP methods in empirical
privacy protections. Our results highlight the significant impact of noise in
current DP rewriting mechanisms, leading to a discussion of the merits and
challenges of DP in NLP, as well as the opportunities that non-DP methods
present.

摘要：文本私有化领域通常利用
$\textit{差分隐私}$ (DP) 的概念在敏感文本数据的重写或混淆中提供正式保证。一种常见且几乎无处不在的 DP 应用形式需要在文本的向量表示中添加校准噪声，无论是在数据级还是模型级，这由隐私参数 $\varepsilon$ 控制。然而，添加噪声几乎毫无疑问地会导致相当大的效用损失，从而突出了 DP 在 NLP 中的一个主要缺点。在这项工作中，我们引入了一种新的句子填充私有化技术，并使用这种方法来探索噪声在 DP 文本重写中的影响。我们凭经验证明，非 DP 私有化技术在效用保留方面表现出色，并且可以找到可接受的经验隐私效用权衡，但无法在经验隐私保护中优于 DP 方法。我们的结果突出了噪声在当前 DP 重写机制中的重大影响，从而引发了对 DP 在 NLP 中的优点和挑战的讨论，以及非 DP 方法带来的机会。

##### **Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses**
2501.19018v2 by Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo, Bimal Bhattarai

The Tsetlin Machine (TM) architecture has recently demonstrated effectiveness
in Machine Learning (ML), particularly within Natural Language Processing
(NLP). It has been utilized to construct word embedding using conjunctive
propositional clauses, thereby significantly enhancing our understanding and
interpretation of machine-derived decisions. The previous approach performed
the word embedding over a sequence of input words to consolidate the
information into a cohesive and unified representation. However, that approach
encounters scalability challenges as the input size increases. In this study,
we introduce a novel approach incorporating two-phase training to discover
contextual embeddings of input sequences. Specifically, this method
encapsulates the knowledge for each input word within the dataset's vocabulary,
subsequently constructing embeddings for a sequence of input words utilizing
the extracted knowledge. This technique not only facilitates the design of a
scalable model but also preserves interpretability. Our experimental findings
revealed that the proposed method yields competitive performance compared to
the previous approaches, demonstrating promising results in contrast to
human-generated benchmarks. Furthermore, we applied the proposed approach to
sentiment analysis on the IMDB dataset, where the TM embedding and the TM
classifier, along with other interpretable classifiers, offered a transparent
end-to-end solution with competitive performance.

摘要：Tsetlin 機器 (TM) 架構最近在機器學習 (ML) 中展現了其效能，特別是在自然語言處理 (NLP) 領域。它已被用於建構詞嵌入，使用連接命題子句，從而顯著增強我們對機器衍生決策的理解和詮釋。先前的做法對輸入字詞的序列執行詞嵌入，將資訊整合到一個有凝聚力和統一性的表徵中。然而，隨著輸入大小的增加，該做法會遇到可擴充性的挑戰。在本研究中，我們介紹一種新穎的做法，結合兩階段訓練來發現輸入序列的脈絡嵌入。具體來說，此方法將資料集詞彙中每個輸入字詞的知識封裝起來，然後利用提取的知識為輸入字詞的序列建構嵌入。此技術不僅有助於設計可擴充性的模型，還能保留可解釋性。我們的實驗結果顯示，與先前的做法相比，所提出的方法產出了有競爭力的效能，與人為產生的基準相比，展現了有希望的結果。此外，我們將所提出的做法應用於 IMDB 資料集的情緒分析，其中 TM 嵌入和 TM 分類器，以及其他可解釋的分類器，提供了一個透明的端到端解決方案，具有競爭力的效能。

##### **Calling a Spade a Heart: Gaslighting Multimodal Large Language Models via Negation**
2501.19017v1 by Bin Zhu, Hui yan Qi, Yinxuan Gui, Jingjing Chen, Chong-Wah Ngo, Ee Peng Lim

Multimodal Large Language Models (MLLMs) have exhibited remarkable
advancements in integrating different modalities, excelling in complex
understanding and generation tasks. Despite their success, MLLMs remain
vulnerable to conversational adversarial inputs, particularly negation
arguments. This paper systematically evaluates state-of-the-art MLLMs across
diverse benchmarks, revealing significant performance drops when negation
arguments are introduced to initially correct responses. We show critical
vulnerabilities in the reasoning and alignment mechanisms of these models.
Proprietary models such as GPT-4o and Claude-3.5-Sonnet demonstrate better
resilience compared to open-source counterparts like Qwen2-VL and LLaVA.
However, all evaluated MLLMs struggle to maintain logical consistency under
negation arguments during conversation. This paper aims to offer valuable
insights for improving the robustness of MLLMs against adversarial inputs,
contributing to the development of more reliable and trustworthy multimodal AI
systems.

摘要：多模态大型语言模型 (MLLM) 在整合不同模态方面表现出显着的进步，在复杂的理解和生成任务中表现出色。尽管取得了成功，但 MLLM 仍然容易受到会话对抗输入的影响，尤其是否定论证。本文系统地评估了最先进的 MLLM 在不同基准上的表现，揭示了在最初正确的响应中引入否定论证时性能大幅下降。我们展示了这些模型在推理和对齐机制中的关键漏洞。与 Qwen2-VL 和 LLaVA 等开源对应项相比，GPT-4o 和 Claude-3.5-Sonnet 等专有模型表现出更好的弹性。然而，所有评估过的 MLLM 在对话中都难以在否定论证下保持逻辑一致性。本文旨在为提高 MLLM 对对抗输入的鲁棒性提供有价值的见解，为开发更可靠、更可信的多模态 AI 系统做出贡献。

##### **Importing Phantoms: Measuring LLM Package Hallucination Vulnerabilities**
2501.19012v1 by Arjun Krishna, Erick Galinkin, Leon Derczynski, Jeffrey Martin

Large Language Models (LLMs) have become an essential tool in the
programmer's toolkit, but their tendency to hallucinate code can be used by
malicious actors to introduce vulnerabilities to broad swathes of the software
supply chain. In this work, we analyze package hallucination behaviour in LLMs
across popular programming languages examining both existing package references
and fictional dependencies. By analyzing this package hallucination behaviour
we find potential attacks and suggest defensive strategies to defend against
these attacks. We discover that package hallucination rate is predicated not
only on model choice, but also programming language, model size, and
specificity of the coding task request. The Pareto optimality boundary between
code generation performance and package hallucination is sparsely populated,
suggesting that coding models are not being optimized for secure code.
Additionally, we find an inverse correlation between package hallucination rate
and the HumanEval coding benchmark, offering a heuristic for evaluating the
propensity of a model to hallucinate packages. Our metrics, findings and
analyses provide a base for future models, securing AI-assisted software
development workflows against package supply chain attacks.

摘要：大型語言模型 (LLM) 已成為程式設計師工具箱中不可或缺的工具，但惡意行為者可能會利用其產生代碼的傾向，在軟體供應鏈的廣泛範圍內引入漏洞。在本文中，我們分析了 LLM 中的套件產生行為，探討了現有套件參考和虛構依賴關係，並涵蓋了多種流行的程式語言。透過分析這個套件產生行為，我們發現潛在的攻擊，並提出防禦策略來抵禦這些攻擊。我們發現，套件產生率不僅取決於模型選擇，還取決於程式語言、模型大小和編碼任務請求的具體性。代碼產生效能和套件產生之間的帕累托最優邊界人口稀少，這表示編碼模型並未針對安全代碼進行最佳化。此外，我們發現套件產生率與 HumanEval 編碼基準之間存在反比關係，這提供了一個評估模型產生套件傾向的啟發式方法。我們的指標、發現和分析為未來的模型提供了基礎，確保了 AI 協助的軟體開發工作流程免於套件供應鏈攻擊。

##### **DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition**
2501.19010v2 by Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee

Dysarthric speech recognition often suffers from performance degradation due
to the intrinsic diversity of dysarthric severity and extrinsic disparity from
normal speech. To bridge these gaps, we propose a Dynamic Phoneme-level
Contrastive Learning (DyPCL) method, which leads to obtaining invariant
representations across diverse speakers. We decompose the speech utterance into
phoneme segments for phoneme-level contrastive learning, leveraging dynamic
connectionist temporal classification alignment. Unlike prior studies focusing
on utterance-level embeddings, our granular learning allows discrimination of
subtle parts of speech. In addition, we introduce dynamic curriculum learning,
which progressively transitions from easy negative samples to
difficult-to-distinguishable negative samples based on phonetic similarity of
phoneme. Our approach to training by difficulty levels alleviates the inherent
variability of speakers, better identifying challenging speeches. Evaluated on
the UASpeech dataset, DyPCL outperforms baseline models, achieving an average
22.10\% relative reduction in word error rate (WER) across the overall
dysarthria group.

摘要：構音障礙的語音辨識常常會因為構音障礙嚴重程度的內在差異和與正常語音的外在差異而導致效能下降。為了彌補這些差距，我們提出了一個動態音素層對比學習 (DyPCL) 方法，這會導致獲得不同說話者之間的不變表示。我們將語音話語分解成音素片段，以進行音素層對比學習，利用動態連接主義時序分類對齊。與專注於話語層級嵌入的先前研究不同，我們的細粒度學習允許區分語音的細微部分。此外，我們引入了動態課程學習，它會根據音素的語音相似性，從容易的負面樣本逐漸過渡到難以區分的負面樣本。我們透過難度等級進行訓練的方法減輕了說話者的內在變異性，能更好地識別有挑戰性的語音。在 UASpeech 資料集上進行評估，DyPCL 優於基線模型，在整體構音障礙組中，字元錯誤率 (WER) 平均降低了 22.10%。

##### **Virtual airways heatmaps to optimize point of entry location in lung biopsy planning systems**
2501.19003v1 by Debora Gil, Pere Lloret, Marta Diez-Ferrer, Carles Sanchez

Purpose: We present a virtual model to optimize point of entry (POE) in lung
biopsy planning systems. Our model allows to compute the quality of a biopsy
sample taken from potential POE, taking into account the margin of error that
arises from discrepancies between the orientation in the planning simulation
and the actual orientation during the operation. Additionally, the study
examines the impact of the characteristics of the lesion. Methods: The quality
of the biopsy is given by a heatmap projected onto the skeleton of a
patient-specific model of airways. The skeleton provides a 3D representation of
airways structure, while the heatmap intensity represents the potential amount
of tissue that it could be extracted from each POE. This amount of tissue is
determined by the intersection of the lesion with a cone that represents the
uncertainty area in the introduction of biopsy instruments. The cone, lesion,
and skeleton are modelled as graphical objects that define a 3D scene of the
intervention. Results: We have simulated different settings of the intervention
scene from a single anatomy extracted from a CT scan and two lesions with
regular and irregular shapes. The different scenarios are simulated by
systematic rotation of each lesion placed at different distances from airways.
Analysis of the heatmaps for the different settings show a strong impact of
lesion orientation for irregular shape and the distance for both shapes.
Conclusion: The proposed heatmaps help to visually assess the optimal POE and
identify whether multiple optimal POEs exist in different zones of the bronchi.
They also allow us to model the maximum allowable error in navigation systems
and study which variables have the greatest influence on the success of the
operation. Additionally, they help determine at what point this influence could
potentially jeopardize the operation.

摘要：<paragraph>目的：我們提出一個虛擬模型來優化肺部活檢計畫系統中的切入點 (POE)。我們的模型可以計算從潛在 POE 採集的活檢樣本品質，考量到計畫模擬與實際操作期間方向之間的誤差範圍。此外，這項研究探討病灶特徵的影響。方法：活檢品質由熱圖提供，投影到特定患者氣道模型的骨架上。骨架提供氣道結構的 3D 表示，而熱圖強度表示從每個 POE 能萃取的潛在組織量。此組織量由病灶與錐體的交集決定，錐體表示活檢器械導入的不確定區域。錐體、病灶和骨架建模為圖形物件，定義介入的 3D 場景。結果：我們模擬了從電腦斷層掃描中萃取的單一解剖結構，以及兩個形狀規則和不規則的病灶，模擬了介入場景的不同設定。不同的場景是透過系統性旋轉置於不同氣道距離的每個病灶來模擬。針對不同設定的熱圖分析顯示，不規則形狀的病灶方向和兩種形狀的距離有很大的影響。結論：建議的熱圖有助於視覺評估最佳 POE，並找出支氣管不同區域中是否存在多個最佳 POE。它們也讓我們能夠建模導航系統中最大的容許誤差，並研究哪個變數對手術成功有最大的影響。此外，它們有助於確定在什麼時候這種影響可能會危害手術。</paragraph>

##### **Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings**
2501.18998v1 by Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo

In recent years, text generation tools utilizing Artificial Intelligence (AI)
have occasionally been misused across various domains, such as generating
student reports or creative writings. This issue prompts plagiarism detection
services to enhance their capabilities in identifying AI-generated content.
Adversarial attacks are often used to test the robustness of AI-text generated
detectors. This work proposes a novel textual adversarial attack on the
detection models such as Fast-DetectGPT. The method employs embedding models
for data perturbation, aiming at reconstructing the AI generated texts to
reduce the likelihood of detection of the true origin of the texts.
Specifically, we employ different embedding techniques, including the Tsetlin
Machine (TM), an interpretable approach in machine learning for this purpose.
By combining synonyms and embedding similarity vectors, we demonstrates the
state-of-the-art reduction in detection scores against Fast-DetectGPT.
Particularly, in the XSum dataset, the detection score decreased from 0.4431 to
0.2744 AUROC, and in the SQuAD dataset, it dropped from 0.5068 to 0.3532 AUROC.

摘要：近年来，利用人工智能 (AI) 的文本生成工具偶尔会遭到滥用，例如生成学生报告或创意写作。这个问题促使剽窃检测服务增强其识别 AI 生成的内容的能力。对抗性攻击通常用于测试 AI 文本生成检测器的鲁棒性。这项工作提出了一种针对 Fast-DetectGPT 等检测模型的新型文本对抗性攻击。该方法采用嵌入模型进行数据扰动，旨在重建 AI 生成的文本，以降低检测文本真实来源的可能性。具体来说，我们采用了不同的嵌入技术，包括 Tsetlin 机器 (TM)，这是一种机器学习中可解释的方法。通过结合同义词和嵌入相似度向量，我们展示了针对 Fast-DetectGPT 的检测分数的最新减少。特别是，在 XSum 数据集中，检测分数从 0.4431 下降到 0.2744 AUROC，在 SQuAD 数据集中，它从 0.5068 下降到 0.3532 AUROC。

##### **VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian Extended Kalman Filter Integration**
2501.18994v1 by Jian-Yu Chen, Yi-Ru Chen, Yin-Qiao Chang, Che-Ming Li, Jann-Long Chern, Chih-Wei Huang

This paper addresses the challenges in learning-based monocular positioning
by proposing VKFPos, a novel approach that integrates Absolute Pose Regression
(APR) and Relative Pose Regression (RPR) via an Extended Kalman Filter (EKF)
within a variational Bayesian inference framework. Our method shows that the
essential posterior probability of the monocular positioning problem can be
decomposed into APR and RPR components. This decomposition is embedded in the
deep learning model by predicting covariances in both APR and RPR branches,
allowing them to account for associated uncertainties. These covariances
enhance the loss functions and facilitate EKF integration. Experimental
evaluations on both indoor and outdoor datasets show that the single-shot APR
branch achieves accuracy on par with state-of-the-art methods. Furthermore, for
temporal positioning, where consecutive images allow for RPR and EKF
integration, VKFPos outperforms temporal APR and model-based integration
methods, achieving superior accuracy.

摘要：本論文探討了基於學習的單眼定位挑戰，提出 VKFPos，一種透過擴展卡爾曼濾波器 (EKF) 在變分貝氏推論框架內整合絕對位姿回歸 (APR) 和相對位姿回歸 (RPR) 的新方法。我們的模型顯示，單眼定位問題的基本後驗機率可以分解成 APR 和 RPR 組成。此分解透過預測 APR 和 RPR 分支中的共變異數來嵌入深度學習模型，讓它們能考量相關的不確定性。這些共變異數增強了損失函數並促進 EKF 整合。在室內和室外資料集上的實驗評估顯示，單次 APR 分支達到了與最先進方法同等的準確度。此外，對於時序定位，連續影像允許 RPR 和 EKF 整合，VKFPos 優於時序 APR 和基於模型的整合方法，達到了更高的準確度。

##### **Symmetric Pruning of Large Language Models**
2501.18980v1 by Kai Yi, Peter Richtárik

Popular post-training pruning methods such as Wanda and RIA are known for
their simple, yet effective, designs that have shown exceptional empirical
performance. Wanda optimizes performance through calibrated activations during
pruning, while RIA emphasizes the relative, rather than absolute, importance of
weight elements. Despite their practical success, a thorough theoretical
foundation explaining these outcomes has been lacking. This paper introduces
new theoretical insights that redefine the standard minimization objective for
pruning, offering a deeper understanding of the factors contributing to their
success. Our study extends beyond these insights by proposing complementary
strategies that consider both input activations and weight significance. We
validate these approaches through rigorous experiments, demonstrating
substantial enhancements over existing methods. Furthermore, we introduce a
novel training-free fine-tuning approach $R^2$-DSnoT that incorporates relative
weight importance and a regularized decision boundary within a dynamic
pruning-and-growing framework, significantly outperforming strong baselines and
establishing a new state of the art.

摘要：常見的後訓練剪枝方法，例如 Wanda 和 RIA，以其簡單但有效的設計而聞名，這些設計已展現出卓越的經驗效能。Wanda 在剪枝期間透過校準激活來最佳化效能，而 RIA 則強調權重元素的相對重要性，而非絕對重要性。儘管在實務上獲得成功，但缺乏徹底的理論基礎來解釋這些結果。本文介紹新的理論見解，重新定義剪枝的標準最小化目標，提供對促成其成功的因素更深入的了解。我們的研究超越這些見解，提出考量輸入激活和權重顯著性的互補策略。我們透過嚴謹的實驗驗證這些方法，證明其大幅優於現有方法。此外，我們介紹一種新穎的免訓練微調方法 $R^2$-DSnoT，它在動態剪枝與成長架構中納入相對權重重要性和正規化的決策邊界，顯著優於強大的基準，並建立新的技術水準。

##### **GPO-VAE: Modeling Explainable Gene Perturbation Responses utilizing GRN-Aligned Parameter Optimization**
2501.18973v1 by Seungheun Baek, Soyon Park, Yan Ting Chok, Mogan Gim, Jaewoo Kang

Motivation: Predicting cellular responses to genetic perturbations is
essential for understanding biological systems and developing targeted
therapeutic strategies. While variational autoencoders (VAEs) have shown
promise in modeling perturbation responses, their limited explainability poses
a significant challenge, as the learned features often lack clear biological
meaning. Nevertheless, model explainability is one of the most important
aspects in the realm of biological AI. One of the most effective ways to
achieve explainability is incorporating the concept of gene regulatory networks
(GRNs) in designing deep learning models such as VAEs. GRNs elicit the
underlying causal relationships between genes and are capable of explaining the
transcriptional responses caused by genetic perturbation treatments. Results:
We propose GPO-VAE, an explainable VAE enhanced by GRN-aligned Parameter
Optimization that explicitly models gene regulatory networks in the latent
space. Our key approach is to optimize the learnable parameters related to
latent perturbation effects towards GRN-aligned explainability. Experimental
results on perturbation prediction show our model achieves state-of-the-art
performance in predicting transcriptional responses across multiple benchmark
datasets. Furthermore, additional results on evaluating the GRN inference task
reveal our model's ability to generate meaningful GRNs compared to other
methods. According to qualitative analysis, GPO-VAE posseses the ability to
construct biologically explainable GRNs that align with experimentally
validated regulatory pathways. GPO-VAE is available at
https://github.com/dmis-lab/GPO-VAE

摘要：**動機：**預測細胞對遺傳擾動的反應對於理解生物系統和開發目標治療策略至關重要。儘管變分自動編碼器 (VAE) 在建模擾動反應方面已展現前景，但其解釋力有限，這是一個重大挑戰，因為學習到的特徵經常缺乏明確的生物學意義。儘管如此，模型的可解釋性是生物 AI 領域中最重要的方面之一。實現可解釋性的最有效方法之一是在設計深度學習模型（例如 VAE）時納入基因調控網路 (GRN) 的概念。GRN 引發基因之間的潛在因果關係，並能夠解釋由遺傳擾動治療引起的轉錄反應。**結果：**我們提出 GPO-VAE，一種可解釋的 VAE，通過 GRN 對齊參數優化增強，在潛在空間中明確建模基因調控網路。我們的關鍵方法是針對 GRN 對齊的可解釋性，優化與潛在擾動效應相關的可學習參數。擾動預測的實驗結果表明，我們的模型在預測多個基準資料集的轉錄反應方面達到了最先進的效能。此外，評估 GRN 推論任務的額外結果揭示了我們的模型與其他方法相比，具備產生有意義 GRN 的能力。根據定性分析，GPO-VAE 具有構建生物可解釋 GRN 的能力，這些 GRN 與經過實驗驗證的調控途徑一致。GPO-VAE 可在 https://github.com/dmis-lab/GPO-VAE 獲得

##### **Intrinsic Tensor Field Propagation in Large Language Models: A Novel Approach to Contextual Information Flow**
2501.18957v1 by Alfred Bexley, Lukas Radcliffe, Giles Weatherstone, Joseph Sakau

Context propagation remains a central challenge in language model
architectures, particularly in tasks requiring the retention of long-range
dependencies. Conventional attention mechanisms, while effective in many
applications, exhibit limitations in maintaining coherent contextual
representations over extended sequences due to their reliance on discrete token
interactions. A novel approach is introduced through the formulation of
Intrinsic Tensor Field Propagation (ITFP), which models contextual
relationships as continuous tensor fields distributed across token embeddings.
The propagation dynamics are governed through differential equations that
enable a structured flow of contextual information, augmenting the standard
attention mechanism to enhance coherence and recall. A series of experiments
conducted on an open-source transformer-based model demonstrate that ITFP
provides measurable improvements in contextual retention, dependency
resolution, and inference stability across various linguistic structures.
Comparisons with baseline models reveal a reduction in syntactic
inconsistencies and factual errors, while ablation studies indicate that the
choice of propagation depth and integration strength significantly impacts
model performance. Additional evaluations assessing domain generalization
suggest that ITFP effectively adapts across different text genres, reinforcing
its applicability beyond conventional language modeling tasks. Although
computational trade-offs are introduced through the inclusion of tensor field
computations, empirical findings suggest that the benefits in accuracy and
coherence outweigh the increased processing demands.

摘要：語境傳播在語言模型架構中仍然是一個核心挑戰，特別是在需要保留長程依賴關係的任務中。傳統的注意力機制雖然在許多應用中很有效，但由於依賴離散的符號交互作用，在維持擴展序列上連貫的語境表示方面表現出局限性。通過制定內在張量場傳播 (ITFP) 來引入一種新方法，它將語境關係建模為分佈在符號嵌入中的連續張量場。傳播動態由微分方程式控制，這些方程式能夠結構化語境資訊的流動，加強標準注意力機制以增強連貫性和召回率。在一系列在開源Transformer模型上進行的實驗中證明，ITFP 在各種語言結構中提供了語境保留、依賴關係解析和推論穩定性的可測量改進。與基線模型的比較顯示句法不一致性和事實錯誤減少，而消融研究表明，傳播深度和整合強度的選擇會顯著影響模型效能。評估領域泛化的其他評估表明，ITFP 能夠有效地適應不同的文字類型，加強其適用性，超越傳統的語言建模任務。儘管透過納入張量場計算引入了計算權衡，但經驗發現，準確性和連貫性方面的優點大於增加的處理需求。

##### **Deep Learning based Quasi-consciousness Training for Robot Intelligent Model**
2501.18955v1 by Yuchun Li, Fang Zhang

This paper explores a deep learning based robot intelligent model that
renders robots learn and reason for complex tasks. First, by constructing a
network of environmental factor matrix to stimulate the learning process of the
robot intelligent model, the model parameters must be subjected to coarse &
fine tuning to optimize the loss function for minimizing the loss score,
meanwhile robot intelligent model can fuse all previously known concepts
together to represent things never experienced before, which need robot
intelligent model can be generalized extensively. Secondly, in order to
progressively develop a robot intelligent model with primary consciousness,
every robot must be subjected to at least 1~3 years of special school for
training anthropomorphic behaviour patterns to understand and process complex
environmental information and make rational decisions. This work explores and
delivers the potential application of deep learning-based quasi-consciousness
training in the field of robot intelligent model.

摘要：本文探討一個基於深度學習的機器人智能模型，它能讓機器人學習並推理複雜的任務。首先，透過建構一個環境因子矩陣網路來刺激機器人智能模型的學習過程，模型參數必須經過粗調和微調，以最佳化損失函數以最小化損失分數，同時機器人智能模型可以將所有先前已知的概念融合在一起，以表示以前從未經歷過的事物，這需要機器人智能模型可以廣泛地概括。其次，為了逐步開發具有基本意識的機器人智能模型，每個機器人都必須接受至少 1~3 年的特殊學校訓練，以訓練擬人化的行為模式，以了解和處理複雜的環境資訊並做出合理的決策。這項工作探討並提供了基於深度學習的類意識訓練在機器人智能模型領域的潛在應用。

##### **Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them**
2501.18950v1 by Anh Bui, Trang Vu, Long Vuong, Trung Le, Paul Montague, Tamas Abraham, Junae Kim, Dinh Phung

Concept erasure has emerged as a promising technique for mitigating the risk
of harmful content generation in diffusion models by selectively unlearning
undesirable concepts. The common principle of previous works to remove a
specific concept is to map it to a fixed generic concept, such as a neutral
concept or just an empty text prompt. In this paper, we demonstrate that this
fixed-target strategy is suboptimal, as it fails to account for the impact of
erasing one concept on the others. To address this limitation, we model the
concept space as a graph and empirically analyze the effects of erasing one
concept on the remaining concepts. Our analysis uncovers intriguing geometric
properties of the concept space, where the influence of erasing a concept is
confined to a local region. Building on this insight, we propose the Adaptive
Guided Erasure (AGE) method, which \emph{dynamically} selects optimal target
concepts tailored to each undesirable concept, minimizing unintended side
effects. Experimental results show that AGE significantly outperforms
state-of-the-art erasure methods on preserving unrelated concepts while
maintaining effective erasure performance. Our code is published at
{https://github.com/tuananhbui89/Adaptive-Guided-Erasure}.

摘要：概念擦除已成為一種有前途的技術，可用於透過選擇性地取消學習不良概念，來減輕擴散模型中產生有害內容的風險。先前移除特定概念的共同原則，是將其對應到一個固定的通用概念，例如中立概念或僅為一個空文字提示。在本文中，我們證明此一固定目標策略並非最佳，因為它無法考量到擦除一個概念對其他概念的影響。為了解決此一限制，我們將概念空間建模為一個圖形，並實證分析擦除一個概念對其餘概念的影響。我們的分析揭示了概念空間的有趣幾何特性，其中擦除一個概念的影響侷限於一個區域。根據此一洞見，我們提出自適應引導擦除 (AGE) 方法，此方法會根據每個不良概念，動態選擇最佳目標概念，將意外的副作用降至最低。實驗結果顯示，AGE 在保留無關概念的同時，在維持有效擦除效能方面，明顯優於最先進的擦除方法。我們的程式碼已發布於 {https://github.com/tuananhbui89/Adaptive-Guided-Erasure}。

##### **Language Games as the Pathway to Artificial Superhuman Intelligence**
2501.18924v1 by Ying Wen, Ziyu Wan, Shao Zhang

The evolution of large language models (LLMs) toward artificial superhuman
intelligence (ASI) hinges on data reproduction, a cyclical process in which
models generate, curate and retrain on novel data to refine capabilities.
Current methods, however, risk getting stuck in a data reproduction trap:
optimizing outputs within fixed human-generated distributions in a closed loop
leads to stagnation, as models merely recombine existing knowledge rather than
explore new frontiers. In this paper, we propose language games as a pathway to
expanded data reproduction, breaking this cycle through three mechanisms: (1)
\textit{role fluidity}, which enhances data diversity and coverage by enabling
multi-agent systems to dynamically shift roles across tasks; (2) \textit{reward
variety}, embedding multiple feedback criteria that can drive complex
intelligent behaviors; and (3) \textit{rule plasticity}, iteratively evolving
interaction constraints to foster learnability, thereby injecting continual
novelty. By scaling language games into global sociotechnical ecosystems,
human-AI co-evolution generates unbounded data streams that drive open-ended
exploration. This framework redefines data reproduction not as a closed loop
but as an engine for superhuman intelligence.

摘要：大型語言模型 (LLM) 朝向人工超人類智慧 (ASI) 的演進，取決於資料複製，這是一個循環過程，模型在其中生成、策展和重新訓練新資料，以改善能力。然而，目前的技術有陷入資料複製陷阱的風險：在封閉迴路中最佳化固定的人類產生分配中的輸出，導致停滯，因為模型只是重新組合既有知識，而不是探索新領域。在本文中，我們提出語言遊戲作為擴展資料複製的途徑，透過三種機制打破這個循環：(1) \textit{角色流動性}，透過讓多重代理系統在任務中動態地轉換角色，來提升資料的多樣性和涵蓋範圍；(2) \textit{獎勵多樣性}，嵌入多重回饋準則，可以驅動複雜的智慧行為；以及 (3) \textit{規則可塑性}，反覆地演化互動限制，以促進可學習性，進而注入持續的新穎性。透過將語言遊戲擴展到全球社會技術生態系統，人類與 AI 的共同演化產生無邊界資料串流，驅動開放式探索。此架構重新定義資料複製，使其不再是封閉迴路，而是超人類智慧的引擎。

##### **KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search**
2501.18922v1 by Haoran Luo, Haihong E, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu Anh Tuan

Knowledge Base Question Answering (KBQA) aims to answer natural language
questions with a large-scale structured knowledge base (KB). Despite
advancements with large language models (LLMs), KBQA still faces challenges in
weak KB awareness, imbalance between effectiveness and efficiency, and high
reliance on annotated data. To address these challenges, we propose KBQA-o1, a
novel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a
ReAct-based agent process for stepwise logical form generation with KB
environment exploration. Moreover, it employs MCTS, a heuristic search method
driven by policy and reward models, to balance agentic exploration's
performance and search space. With heuristic exploration, KBQA-o1 generates
high-quality annotations for further improvement by incremental fine-tuning.
Experimental results show that KBQA-o1 outperforms previous low-resource KBQA
methods with limited annotated data, boosting Llama-3.1-8B model's GrailQA F1
performance to 78.5% compared to 48.5% of the previous sota method with
GPT-3.5-turbo.

摘要：知識庫問答 (KBQA) 的目標是使用大規模結構化知識庫 (KB) 來回答自然語言問題。儘管大型語言模型 (LLM) 已有進展，但 KBQA 仍面臨 KB 意識薄弱、效能與效率失衡，以及高度依賴註釋資料的挑戰。為了應對這些挑戰，我們提出 KBQA-o1，一種結合蒙地卡羅樹狀搜尋 (MCTS) 的新穎智能 KBQA 方法。它引入了基於 ReAct 的代理程序流程，用於逐步產生邏輯形式並探索 KB 環境。此外，它採用 MCTS，一種由策略和獎勵模型驅動的啟發式搜尋方法，以平衡代理探索的效能和搜尋空間。透過啟發式探索，KBQA-o1 會產生高品質的註釋，以便透過漸進式微調進一步改善。實驗結果顯示，KBQA-o1 在註釋資料有限的情況下，優於先前的低資源 KBQA 方法，將 Llama-3.1-8B 模型的 GrailQA F1 效能提升至 78.5%，而先前使用 GPT-3.5-turbo 的 sota 方法僅為 48.5%。

##### **Deepfake Detection of Singing Voices With Whisper Encodings**
2501.18919v1 by Falguni Sharma, Priyanka Gupta

The deepfake generation of singing vocals is a concerning issue for artists
in the music industry. In this work, we propose a singing voice deepfake
detection (SVDD) system, which uses noise-variant encodings of open-AI's
Whisper model. As counter-intuitive as it may sound, even though the Whisper
model is known to be noise-robust, the encodings are rich in non-speech
information, and are noise-variant. This leads us to evaluate Whisper encodings
as feature representations for the SVDD task. Therefore, in this work, the SVDD
task is performed on vocals and mixtures, and the performance is evaluated in
\%EER over varying Whisper model sizes and two classifiers- CNN and ResNet34,
under different testing conditions.

摘要：人聲歌唱的深度偽造生成對音樂產業的藝術家來說是一個令人擔憂的問題。在這項工作中，我們提出了一個歌唱聲音深度偽造偵測 (SVDD) 系統，它使用 open-AI 的 Whisper 模型的雜訊變異編碼。儘管 Whisper 模型已知對雜訊具有魯棒性，但編碼富含非語音資訊，而且是雜訊變異的，這聽起來可能違反直覺。這使得我們可以評估 Whisper 編碼作為 SVDD 任務的特徵表示。因此，在這項工作中，SVDD 任務在人聲和混合音上執行，並在不同的測試條件下評估在不同的 Whisper 模型大小和兩個分類器（CNN 和 ResNet34）上 \%EER 的效能。

##### **Lightspeed Geometric Dataset Distance via Sliced Optimal Transport**
2501.18901v1 by Khai Nguyen, Hai Nguyen, Tuan Pham, Nhat Ho

We introduce sliced optimal transport dataset distance (s-OTDD), a
model-agnostic, embedding-agnostic approach for dataset comparison that
requires no training, is robust to variations in the number of classes, and can
handle disjoint label sets. The core innovation is Moment Transform Projection
(MTP), which maps a label, represented as a distribution over features, to a
real number. Using MTP, we derive a data point projection that transforms
datasets into one-dimensional distributions. The s-OTDD is defined as the
expected Wasserstein distance between the projected distributions, with respect
to random projection parameters. Leveraging the closed form solution of
one-dimensional optimal transport, s-OTDD achieves (near-)linear computational
complexity in the number of data points and feature dimensions and is
independent of the number of classes. With its geometrically meaningful
projection, s-OTDD strongly correlates with the optimal transport dataset
distance while being more efficient than existing dataset discrepancy measures.
Moreover, it correlates well with the performance gap in transfer learning and
classification accuracy in data augmentation.

摘要：我們引入了切片最優傳輸資料集距離 (s-OTDD)，這是一種與模型無關、與嵌入無關的方法，用於資料集比較，不需要訓練，對類別數量的變化具有魯棒性，並且可以處理不相交的標籤集。核心的創新是矩轉換投影 (MTP)，它將標籤（表示為特徵上的分佈）映射到實數。使用 MTP，我們推導出一個資料點投影，將資料集轉換為一維分佈。s-OTDD 被定義為投影分佈之間的預期 Wasserstein 距離，相對於隨機投影參數。利用一維最優傳輸的閉合形式解，s-OTDD 在資料點數和特徵維度上實現了（接近）線性計算複雜度，並且與類別數無關。通過其幾何意義明確的投影，s-OTDD 與最優傳輸資料集距離密切相關，同時比現有的資料集差異度量更有效率。此外，它與傳輸學習中的效能差距和資料擴充中的分類準確度密切相關。

##### **Efficient Supernet Training with Orthogonal Softmax for Scalable ASR Model Compression**
2501.18895v1 by Jingjing Xu, Eugen Beck, Zijian Yang, Ralf Schlüter

ASR systems are deployed across diverse environments, each with specific
hardware constraints. We use supernet training to jointly train multiple
encoders of varying sizes, enabling dynamic model size adjustment to fit
hardware constraints without redundant training. Moreover, we introduce a novel
method called OrthoSoftmax, which applies multiple orthogonal softmax functions
to efficiently identify optimal subnets within the supernet, avoiding
resource-intensive search. This approach also enables more flexible and precise
subnet selection by allowing selection based on various criteria and levels of
granularity. Our results with CTC on Librispeech and TED-LIUM-v2 show that
FLOPs-aware component-wise selection achieves the best overall performance.
With the same number of training updates from one single job, WERs for all
model sizes are comparable to or slightly better than those of individually
trained models. Furthermore, we analyze patterns in the selected components and
reveal interesting insights.

摘要：ASR 系統部署在各種環境中，每個環境都有特定的硬體限制。我們使用超網路訓練來聯合訓練各種大小的編碼器，從而能夠根據硬體限制動態調整模型大小，而無需進行冗餘訓練。此外，我們引入了一種稱為 OrthoSoftmax 的新方法，該方法應用多個正交 softmax 函數來有效識別超網路中的最佳子網路，從而避免資源密集型搜索。這種方法還允許根據各種標準和粒度級別進行選擇，從而實現更靈活和精確的子網路選擇。我們在 Librispeech 和 TED-LIUM-v2 上使用 CTC 獲得的結果表明，考慮 FLOP 的組件級別選擇可實現最佳整體效能。在同一個工作中進行相同次數的訓練更新，所有模型大小的 WER 都與單獨訓練的模型相當或略好。此外，我們分析了所選組件中的模式，並揭示了有趣的見解。

##### **Building Bridges, Not Walls -- Advancing Interpretability by Unifying Feature, Data, and Model Component Attribution**
2501.18887v1 by Shichang Zhang, Tessa Han, Usha Bhalla, Hima Lakkaraju

The increasing complexity of AI systems has made understanding their behavior
a critical challenge. Numerous methods have been developed to attribute model
behavior to three key aspects: input features, training data, and internal
model components. However, these attribution methods are studied and applied
rather independently, resulting in a fragmented landscape of approaches and
terminology. This position paper argues that feature, data, and component
attribution methods share fundamental similarities, and bridging them can
benefit interpretability research. We conduct a detailed analysis of successful
methods across three domains and present a unified view to demonstrate that
these seemingly distinct methods employ similar approaches, such as
perturbations, gradients, and linear approximations, differing primarily in
their perspectives rather than core techniques. Our unified perspective
enhances understanding of existing attribution methods, identifies shared
concepts and challenges, makes this field more accessible to newcomers, and
highlights new directions not only for attribution and interpretability but
also for broader AI research, including model editing, steering, and
regulation.

摘要：隨著人工智慧系統日益複雜，理解其行為已成為一項關鍵挑戰。許多方法已被開發出來，用於將模型行為歸因於三個關鍵面向：輸入特徵、訓練資料和內部模型組件。然而，這些歸因方法的研究和應用相當獨立，導致方法和術語的應用環境支離破碎。本文認為特徵、資料和組件歸因方法有根本上的相似性，而將它們連結起來有助於可解釋性研究。我們對三個領域的成功方法進行詳細分析，並提出一個統一的觀點，以證明這些看似不同的方法採用了類似的途徑，例如擾動、梯度和線性近似，其差異主要在於觀點，而非核心技術。我們統一的觀點增強了對現有歸因方法的理解，找出共同的概念和挑戰，讓這個領域更容易讓新手理解，並不僅標示出歸因和可解釋性的新方向，也標示出更廣泛的人工智慧研究的新方向，包括模型編輯、引導和法規。

##### **UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent**
2501.18867v2 by Jianke Zhang, Yanjiang Guo, Yucheng Hu, Xiaoyu Chen, Xiang Zhu, Jianyu Chen

Recent advancements in Vision-Language-Action (VLA) models have leveraged
pre-trained Vision-Language Models (VLMs) to improve the generalization
capabilities. VLMs, typically pre-trained on vision-language understanding
tasks, provide rich semantic knowledge and reasoning abilities. However, prior
research has shown that VLMs often focus on high-level semantic content and
neglect low-level features, limiting their ability to capture detailed spatial
information and understand physical dynamics. These aspects, which are crucial
for embodied control tasks, remain underexplored in existing pre-training
paradigms. In this paper, we investigate the training paradigm for VLAs, and
introduce \textbf{UP-VLA}, a \textbf{U}nified VLA model training with both
multi-modal \textbf{U}nderstanding and future \textbf{P}rediction objectives,
enhancing both high-level semantic comprehension and low-level spatial
understanding. Experimental results show that UP-VLA achieves a 33% improvement
on the Calvin ABC-D benchmark compared to the previous state-of-the-art method.
Additionally, UP-VLA demonstrates improved success rates in real-world
manipulation tasks, particularly those requiring precise spatial information.

摘要：近期在視覺語言動作 (VLA) 模型的進展中，利用預先訓練好的視覺語言模型 (VLM) 來提升概化能力。VLM 通常預先訓練於視覺語言理解任務，提供豐富的語義知識和推理能力。然而，先前的研究顯示，VLM 通常專注於高層級的語義內容，而忽略低層級特徵，限制了其擷取詳細空間資訊和理解物理動態的能力。這些面向對於具體控制任務至關重要，但在現有的預先訓練範例中仍未獲得充分探討。在本文中，我們探討 VLA 的訓練範例，並介紹 UP-VLA，一個統一的 VLA 模型訓練，同時具備多模態理解和未來預測目標，提升高層級語義理解和低層級空間理解。實驗結果顯示，與先前的最先進方法相比，UP-VLA 在 Calvin ABC-D 基準上獲得了 33% 的提升。此外，UP-VLA 在真實世界操作任務中展現出更高的成功率，特別是那些需要精確空間資訊的任務。

##### **REG: Rectified Gradient Guidance for Conditional Diffusion Models**
2501.18865v1 by Zhengqi Gao, Kaiwen Zha, Tianyuan Zhang, Zihui Xue, Duane S. Boning

Guidance techniques are simple yet effective for improving conditional
generation in diffusion models. Albeit their empirical success, the practical
implementation of guidance diverges significantly from its theoretical
motivation. In this paper, we reconcile this discrepancy by replacing the
scaled marginal distribution target, which we prove theoretically invalid, with
a valid scaled joint distribution objective. Additionally, we show that the
established guidance implementations are approximations to the intractable
optimal solution under no future foresight constraint. Building on these
theoretical insights, we propose rectified gradient guidance (REG), a versatile
enhancement designed to boost the performance of existing guidance methods.
Experiments on 1D and 2D demonstrate that REG provides a better approximation
to the optimal solution than prior guidance techniques, validating the proposed
theoretical framework. Extensive experiments on class-conditional ImageNet and
text-to-image generation tasks show that incorporating REG consistently
improves FID and Inception/CLIP scores across various settings compared to its
absence.

摘要：引導技術對於改善擴散模型中的條件生成簡單卻有效。儘管它們在經驗上取得成功，但引導的實際實作與其理論動機有顯著差異。在本文中，我們透過替換經證明在理論上無效的縮放邊際分布目標，以有效的縮放聯合分布目標，來調和這種差異。此外，我們表明既定的引導實作是在沒有未來預見約束的情況下，對難以處理的最佳解的近似值。根據這些理論見解，我們提出修正梯度引導 (REG)，這是一種旨在提升現有引導方法效能的多功能強化技術。1D 和 2D 的實驗證明，與先前的引導技術相比，REG 提供了對最佳解的更好近似，驗證了所提出的理論架構。對類條件 ImageNet 和文字轉圖像生成任務的廣泛實驗表明，與沒有 REG 相比，加入 REG 在各種設定中持續改善 FID 和 Inception/CLIP 分數。

##### **BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning**
2501.18858v1 by Han Zhong, Yutong Yin, Shenao Zhang, Xiaojun Xu, Yuanxin Liu, Yifei Zuo, Zhihan Liu, Boyi Liu, Sirui Zheng, Hongyi Guo, Liwei Wang, Mingyi Hong, Zhaoran Wang

Large Language Models (LLMs) have demonstrated remarkable capabilities in
complex reasoning tasks, yet generating reliable reasoning processes remains a
significant challenge. We present a unified probabilistic framework that
formalizes LLM reasoning through a novel graphical model incorporating latent
thinking processes and evaluation signals. Within this framework, we introduce
the Bootstrapping Reinforced Thinking Process (BRiTE) algorithm, which works in
two steps. First, it generates high-quality rationales by approximating the
optimal thinking process through reinforcement learning, using a novel reward
shaping mechanism. Second, it enhances the base LLM by maximizing the joint
probability of rationale generation with respect to the model's parameters.
Theoretically, we demonstrate BRiTE's convergence at a rate of $1/T$ with $T$
representing the number of iterations. Empirical evaluations on math and coding
benchmarks demonstrate that our approach consistently improves performance
across different base models without requiring human-annotated thinking
processes. In addition, BRiTE demonstrates superior performance compared to
existing algorithms that bootstrap thinking processes use alternative methods
such as rejection sampling, and can even match or exceed the results achieved
through supervised fine-tuning with human-annotated data.

摘要：大型語言模型 (LLM) 已在複雜推理任務中展現出非凡的能力，但產生可靠的推理過程仍然是一項重大挑戰。我們提出一個統一的機率架構，透過一個結合潛在思考過程和評估訊號的新穎圖形模型，將 LLM 推理形式化。在此架構中，我們引入了自舉強化思考過程 (BRiTE) 演算法，其運作分為兩個步驟。首先，它透過強化學習近似最佳思考過程來產生高品質的基本原理，並使用新穎的獎勵塑造機制。其次，它透過最大化基本原理產生和模型參數相關的聯合機率，來增強基礎 LLM。在理論上，我們證明了 BRiTE 以 $1/T$ 的速率收斂，其中 $T$ 代表迭代次數。在數學和編碼基準上的經驗評估表明，我們的做法持續改善了不同基礎模型的效能，而無需人工標註的思考過程。此外，與使用拒絕採樣等替代方法來自舉思考過程的現有演算法相比，BRiTE 展現出優異的效能，甚至可以達到或超越透過有人工標註資料的監督微調所獲得的結果。

##### **Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities**
2501.18845v1 by Yaping Chai, Haoran Xie, Joe S. Qin

The increasing size and complexity of pre-trained language models have
demonstrated superior performance in many applications, but they usually
require large training datasets to be adequately trained. Insufficient training
sets could unexpectedly make the model overfit and fail to cope with complex
tasks. Large language models (LLMs) trained on extensive corpora have prominent
text generation capabilities, which improve the quality and quantity of data
and play a crucial role in data augmentation. Specifically, distinctive prompt
templates are given in personalised tasks to guide LLMs in generating the
required content. Recent promising retrieval-based techniques further improve
the expressive performance of LLMs in data augmentation by introducing external
knowledge to enable them to produce more grounded-truth data. This survey
provides an in-depth analysis of data augmentation in LLMs, classifying the
techniques into Simple Augmentation, Prompt-based Augmentation, Retrieval-based
Augmentation and Hybrid Augmentation. We summarise the post-processing
approaches in data augmentation, which contributes significantly to refining
the augmented data and enabling the model to filter out unfaithful content.
Then, we provide the common tasks and evaluation metrics. Finally, we introduce
existing challenges and future opportunities that could bring further
improvement to data augmentation.

摘要：隨著預訓練語言模型規模和複雜性的提升，已在許多應用中展現出優異的效能，但它們通常需要龐大的訓練資料集才能獲得充分的訓練。不足的訓練集可能意外地使模型過度擬合，而無法應付複雜的任務。在廣泛語料庫上訓練的大型語言模型 (LLM) 具有突出的文字生成能力，這能提升資料的品質和數量，並在資料擴充中扮演至關重要的角色。具體來說，在個人化任務中給予獨特的提示範本，以引導 LLM 產生所需的內容。最近有前途的基於檢索的技術進一步提升了 LLM 在資料擴充中的表達效能，透過引入外部知識，讓它們能產生更多真實的資料。這份調查提供了 LLM 中資料擴充的深入分析，將技術分類為：簡單擴充、基於提示的擴充、基於檢索的擴充和混合擴充。我們總結了資料擴充中的後處理方法，這對精煉擴充資料和讓模型過濾掉不忠實的內容有顯著的貢獻。接著，我們提供了常見的任務和評估指標。最後，我們介紹了現有的挑戰和未來的機會，這些都有可能進一步改善資料擴充。

##### **Partially Rewriting a Transformer in Natural Language**
2501.18838v1 by Gonçalo Paulo, Nora Belrose

The greatest ambition of mechanistic interpretability is to completely
rewrite deep neural networks in a format that is more amenable to human
understanding, while preserving their behavior and performance. In this paper,
we attempt to partially rewrite a large language model using simple natural
language explanations. We first approximate one of the feedforward networks in
the LLM with a wider MLP with sparsely activating neurons - a transcoder - and
use an automated interpretability pipeline to generate explanations for these
neurons. We then replace the first layer of this sparse MLP with an LLM-based
simulator, which predicts the activation of each neuron given its explanation
and the surrounding context. Finally, we measure the degree to which these
modifications distort the model's final output. With our pipeline, the model's
increase in loss is statistically similar to entirely replacing the sparse MLP
output with the zero vector. We employ the same protocol, this time using a
sparse autoencoder, on the residual stream of the same layer and obtain similar
results. These results suggest that more detailed explanations are needed to
improve performance substantially above the zero ablation baseline.

摘要：機械可解釋性的最大目標是將深度神經網路完全改寫成更適合人類理解的格式，同時保留其行為和效能。在本文中，我們嘗試使用簡單的自然語言解釋部分改寫大型語言模型。我們首先使用具有稀疏激活神經元的較寬 MLP（轉碼器）近似 LLM 中的一個前饋網路，並使用自動化可解釋性管道為這些神經元生成解釋。然後，我們用基於 LLM 的模擬器替換這個稀疏 MLP 的第一層，該模擬器會根據每個神經元的解釋和周圍的上下文預測其激活。最後，我們測量這些修改在多大程度上扭曲了模型的最終輸出。使用我們的管道，模型損失的增加在統計上與將稀疏 MLP 輸出完全替換為零向量相似。我們使用相同的協定，這次在同一層的殘差串流上使用稀疏自動編碼器，並獲得類似的結果。這些結果表明，需要更詳細的解釋才能將效能顯著提高到零消融基準線之上。

##### **Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming**
2501.18837v1 by Mrinank Sharma, Meg Tong, Jesse Mu, Jerry Wei, Jorrit Kruthoff, Scott Goodfriend, Euan Ong, Alwin Peng, Raj Agarwal, Cem Anil, Amanda Askell, Nathan Bailey, Joe Benton, Emma Bluemke, Samuel R. Bowman, Eric Christiansen, Hoagy Cunningham, Andy Dau, Anjali Gopal, Rob Gilson, Logan Graham, Logan Howard, Nimit Kalra, Taesung Lee, Kevin Lin, Peter Lofgren, Francesco Mosconi, Clare O'Hara, Catherine Olsson, Linda Petrini, Samir Rajani, Nikhil Saxena, Alex Silverstein, Tanya Singh, Theodore Sumers, Leonard Tang, Kevin K. Troy, Constantin Weisser, Ruiqi Zhong, Giulio Zhou, Jan Leike, Jared Kaplan, Ethan Perez

Large language models (LLMs) are vulnerable to universal jailbreaks-prompting
strategies that systematically bypass model safeguards and enable users to
carry out harmful processes that require many model interactions, like
manufacturing illegal substances at scale. To defend against these attacks, we
introduce Constitutional Classifiers: safeguards trained on synthetic data,
generated by prompting LLMs with natural language rules (i.e., a constitution)
specifying permitted and restricted content. In over 3,000 estimated hours of
red teaming, no red teamer found a universal jailbreak that could extract
information from an early classifier-guarded LLM at a similar level of detail
to an unguarded model across most target queries. On automated evaluations,
enhanced classifiers demonstrated robust defense against held-out
domain-specific jailbreaks. These classifiers also maintain deployment
viability, with an absolute 0.38% increase in production-traffic refusals and a
23.7% inference overhead. Our work demonstrates that defending against
universal jailbreaks while maintaining practical deployment viability is
tractable.

摘要：大型語言模型 (LLM) 容易受到通用越獄的影響，這些策略系統性地繞過模型防護措施，讓使用者得以執行需要許多模型互動的有害程序，例如大規模製造非法物質。為了防禦這些攻擊，我們引入了憲法分類器：在合成資料上訓練的防護措施，透過提示 LLM 自然語言規則（即憲法）來產生，說明允許和限制的內容。在超過 3,000 小時估計的紅隊演練中，沒有紅隊成員找到一個通用越獄，能夠從早期分類器保護的 LLM 中提取資訊，其詳細程度與大多數目標查詢中未受保護的模型類似。在自動化評估中，增強的分類器展現了對特定領域越獄的強大防禦力。這些分類器也維持部署可行性，生產流量拒絕率絕對增加 0.38%，推論負擔增加 23.7%。我們的研究證明，在維持實際部署可行性的同時防禦通用越獄是可行的。

##### **Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential**
2501.18834v1 by Chenyu Gao, Kaiwen Xu, Michael E. Kim, Lianrui Zuo, Zhiyuan Li, Derek B. Archer, Timothy J. Hohman, Ann Zenobia Moore, Luigi Ferrucci, Lori L. Beason-Held, Susan M. Resnick, Christos Davatzikos, Jerry L. Prince, Bennett A. Landman

Defacing is often applied to head magnetic resonance image (MRI) datasets
prior to public release to address privacy concerns. The alteration of facial
and nearby voxels has provoked discussions about the true capability of these
techniques to ensure privacy as well as their impact on downstream tasks. With
advancements in deep generative models, the extent to which defacing can
protect privacy is uncertain. Additionally, while the altered voxels are known
to contain valuable anatomical information, their potential to support research
beyond the anatomical regions directly affected by defacing remains uncertain.
To evaluate these considerations, we develop a refacing pipeline that recovers
faces in defaced head MRIs using cascaded diffusion probabilistic models
(DPMs). The DPMs are trained on images from 180 subjects and tested on images
from 484 unseen subjects, 469 of whom are from a different dataset. To assess
whether the altered voxels in defacing contain universally useful information,
we also predict computed tomography (CT)-derived skeletal muscle radiodensity
from facial voxels in both defaced and original MRIs. The results show that
DPMs can generate high-fidelity faces that resemble the original faces from
defaced images, with surface distances to the original faces significantly
smaller than those of a population average face (p < 0.05). This performance
also generalizes well to previously unseen datasets. For skeletal muscle
radiodensity predictions, using defaced images results in significantly weaker
Spearman's rank correlation coefficients compared to using original images (p <
10-4). For shin muscle, the correlation is statistically significant (p < 0.05)
when using original images but not statistically significant (p > 0.05) when
any defacing method is applied, suggesting that defacing might not only fail to
protect privacy but also eliminate valuable information.

摘要：<paragraph>在公開發布前，通常會對頭部磁振造影 (MRI) 資料集進行去識別化處理，以解決隱私問題。面部和附近體素的變更引發了關於這些技術確保隱私的真正能力及其對下游任務的影響的討論。隨著深度生成模型的進步，去識別化在多大程度上可以保護隱私尚不確定。此外，儘管已知被改變的體素包含有價值的解剖學資訊，但它們在支持超越去識別化直接影響的解剖區域的研究方面的潛力仍不確定。為了評估這些考量，我們開發了一個重新識別管道，使用串聯擴散機率模型 (DPM) 在去識別化的頭部 MRI 中恢復面部。DPM 在來自 180 個受試者的影像上進行訓練，並在來自 484 個未見受試者的影像上進行測試，其中 469 個來自不同的資料集。為了評估去識別化中被改變的體素是否包含普遍有用的資訊，我們也從去識別化和原始 MRI 中的面部體素預測電腦斷層掃描 (CT) 衍生的骨骼肌放射密度。結果顯示，DPM 可以生成高保真面部，這些面部與去識別化影像中的原始面部相似，與原始面部的表面距離顯著小於一般人臉 (p < 0.05)。此效能也很好地概括到先前未見的資料集。對於骨骼肌放射密度預測，與使用原始影像相比，使用去識別化影像會導致顯著較弱的斯皮爾曼等級相關係數 (p < 10-4)。對於小腿肌肉，在使用原始影像時，相關性具有統計顯著性 (p < 0.05)，但當應用任何去識別化方法時，相關性沒有統計顯著性 (p > 0.05)，這表明去識別化不僅可能無法保護隱私，還會消除有價值的資訊。</paragraph>

##### **Structural Embedding Projection for Contextual Large Language Model Inference**
2501.18826v1 by Vincent Enoasmo, Cedric Featherstonehaugh, Xavier Konstantinopoulos, Zacharias Huntington

Structured embedding transformations offer a promising approach for enhancing
the efficiency and coherence of language model inference. The introduction of
Structural Embedding Projection (SEP) provides a mechanism for refining token
representations through projection matrices that integrate hierarchical and
relational dependencies. The mathematical formulation of SEP enables embedding
spaces to capture structured contextual relationships, thereby improving
semantic fidelity without significantly increasing computational overhead.
Experimental evaluations conducted on a range of linguistic datasets revealed
that SEP contributed to reductions in perplexity and enhanced contextual
coherence, demonstrating its potential to refine language model outputs.
Computational efficiency assessments highlighted variations across different
datasets, suggesting that the integration of structured embeddings introduced
dataset-dependent trade-offs between inference speed and representational
richness. The qualitative analysis of generated responses indicated that SEP
enhanced narrative consistency and topic alignment, leading to improved fluency
in multi-sentence text generation. The modifications to embedding layers
required precise optimization to ensure stable training dynamics, as the
introduction of structured transformations altered the traditional
representation-learning process. The architectural adjustments necessary for
SEP implementation influenced inference latency and memory consumption,
requiring a balance between efficiency gains and additional processing demands.
The impact of SEP on lexical diversity suggested that embedding modifications
influenced the model's vocabulary usage, reflecting a more context-aware
selection of generated tokens.

摘要：結構化嵌入轉換提供了一種有前途的方法，用於增強語言模型推理的效率和一致性。結構嵌入投影 (SEP) 的引入提供了一種通過投影矩陣改進令牌表示的機制，該矩陣整合了層級和關係依賴性。SEP 的數學公式使嵌入空間能夠捕捉結構化上下文關係，從而提高語義保真度，而不會顯著增加計算開銷。在各種語言數據集上進行的實驗評估表明，SEP 有助於降低困惑度並增強上下文一致性，展示了其改進語言模型輸出的潛力。計算效率評估突出了不同數據集之間的差異，表明結構化嵌入的整合引入了推理速度和表示豐富性之間依賴於數據集的權衡。對生成響應的定性分析表明，SEP 增強了敘事一致性和主題對齊，從而提高了多句文本生成的流暢性。嵌入層的修改需要精確的優化，以確保穩定的訓練動態，因為結構化轉換的引入改變了傳統的表示學習過程。SEP 實施所需的架構調整影響了推理延遲和內存消耗，需要在效率提升和額外的處理需求之間取得平衡。SEP 對詞彙多樣性的影響表明，嵌入修改影響了模型的詞彙使用，反映了對生成令牌更具上下文感知的選擇。

##### **Memory-Efficient Fine-Tuning of Transformers via Token Selection**
2501.18824v1 by Antoine Simoulin, Namyong Park, Xiaoyi Liu, Grey Yang

Fine-tuning provides an effective means to specialize pre-trained models for
various downstream tasks. However, fine-tuning often incurs high memory
overhead, especially for large transformer-based models, such as LLMs. While
existing methods may reduce certain parts of the memory required for
fine-tuning, they still require caching all intermediate activations computed
in the forward pass to update weights during the backward pass. In this work,
we develop TokenTune, a method to reduce memory usage, specifically the memory
to store intermediate activations, in the fine-tuning of transformer-based
models. During the backward pass, TokenTune approximates the gradient
computation by backpropagating through just a subset of input tokens. Thus,
with TokenTune, only a subset of intermediate activations are cached during the
forward pass. Also, TokenTune can be easily combined with existing methods like
LoRA, further reducing the memory cost. We evaluate our approach on pre-trained
transformer models with up to billions of parameters, considering the
performance on multiple downstream tasks such as text classification and
question answering in a few-shot learning setup. Overall, TokenTune achieves
performance on par with full fine-tuning or representative memory-efficient
fine-tuning methods, while greatly reducing the memory footprint, especially
when combined with other methods with complementary memory reduction
mechanisms. We hope that our approach will facilitate the fine-tuning of large
transformers, in specializing them for specific domains or co-training them
with other neural components from a larger system. Our code is available at
https://github.com/facebookresearch/tokentune.

摘要：微调提供了一种有效的方法，可针对各种下游任务专门化预训练模型。然而，微调通常会产生较高的内存开销，特别是对于基于大型转换器的模型，例如 LLM。虽然现有方法可以减少微调所需的某些内存部分，但它们仍然需要缓存正向传递中计算的所有中间激活，以便在反向传递期间更新权重。在这项工作中，我们开发了 TokenTune，这是一种减少内存使用量的方法，特别是存储中间激活的内存，用于基于转换器的模型的微调。在反向传递期间，TokenTune 通过仅反向传播输入令牌的子集来逼近梯度计算。因此，使用 TokenTune，仅在正向传递期间缓存中间激活的子集。此外，TokenTune 可以轻松地与现有方法（如 LoRA）相结合，进一步降低内存成本。我们对拥有数十亿个参数的预训练转换器模型评估了我们的方法，考虑了在少数镜头学习设置中对文本分类和问题解答等多个下游任务的性能。总体而言，TokenTune 在与完全微调或具有代表性的节能微调方法相当的性能上取得了成就，同时大幅减少了内存占用，尤其是在与其他具有互补内存减少机制的方法相结合时。我们希望我们的方法将有助于对大型转换器进行微调，使它们专门用于特定领域或与来自更大系统中的其他神经组件进行联合训练。我们的代码可在 https://github.com/facebookresearch/tokentune 中获得。

##### **An Optimal Cascade Feature-Level Spatiotemporal Fusion Strategy for Anomaly Detection in CAN Bus**
2501.18821v1 by Mohammad Fatahi, Danial Sadrian Zadeh, Benyamin Ghojogh, Behzad Moshiri, Otman Basir

Autonomous vehicles represent a revolutionary advancement driven by the
integration of artificial intelligence within intelligent transportation
systems. However, they remain vulnerable due to the absence of robust security
mechanisms in the Controller Area Network (CAN) bus. In order to mitigate the
security issue, many machine learning models and strategies have been proposed,
which primarily focus on a subset of dominant patterns of anomalies and lack
rigorous evaluation in terms of reliability and robustness. Therefore, to
address the limitations of previous works and mitigate the security
vulnerability in CAN bus, the current study develops a model based on the
intrinsic nature of the problem to cover all dominant patterns of anomalies. To
achieve this, a cascade feature-level fusion strategy optimized by a
two-parameter genetic algorithm is proposed to combine temporal and spatial
information. Subsequently, the model is evaluated using a paired t-test to
ensure reliability and robustness. Finally, a comprehensive comparative
analysis conducted on two widely used datasets advocates that the proposed
model outperforms other models and achieves superior accuracy and F1-score,
demonstrating the best performance among all models presented to date.

摘要：自動駕駛車輛代表著一項革命性的進展，它是由在智慧運輸系統中整合人工智慧所推動的。然而，由於控制器區域網路 (CAN) 總線中缺乏強大的安全機制，它們仍然容易受到攻擊。為了減輕安全問題，已經提出了許多機器學習模型和策略，這些模型和策略主要關注異常的主要模式子集，並且缺乏在可靠性和穩健性方面的嚴格評估。因此，為了解決先前工作的限制並減輕 CAN 總線中的安全漏洞，目前的研究基於問題的內在性質開發了一個模型，以涵蓋所有主要的異常模式。為此，提出了一個由兩參數遺傳演算法最佳化的串聯特徵層級融合策略，以結合時間和空間資訊。隨後，使用配對 t 檢定評估模型，以確保可靠性和穩健性。最後，在兩個廣泛使用的資料集上進行的全面比較分析證明，所提出的模型優於其他模型，並實現了更高的準確度和 F1 分數，展示了迄今為止提出的所有模型中最佳的效能。

##### **Bridging the Reasoning Gap: Small LLMs Can Plan with Generalised Strategies**
2501.18817v1 by Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock

Recent advancements in the reasoning skills of Large Language Models (LLMs)
demonstrate an increase in the ability of LLMs to solve simple planning tasks.
However, as long as the driving force behind improved reasoning capability is
the size and complexity of the model, the financial and computational costs
associated with running them will also increase. This trend raises questions
about continued accessibility and whether these improvements will increase at
the same pace as models continue to grow in size and expense. We propose two
approaches to enhance the reasoning ability of less resource-intensive LLMs.
(1) Provide them with a generalised strategy for solving tasks within a given
domain, generated by a more resource-intensive LLM. (2) Exploit their
cost-effectiveness by iteratively prompting these models to correct errors in
their proposed solutions. Our empirical results from planning and mathematical
reasoning tasks demonstrate that these methods improve the performance of less
resource-intensive LLMs to levels comparable with their more resource-intensive
counterparts, at a fraction of the cost. Additionally, we show that the
utilisation of generalised strategies in our experiments reduced the cost of
the less resource-intensive model by nearly 30 percent on average.

摘要：大型語言模型 (LLM) 推理技能的最新進展
展示了 LLM 解決簡單規劃任務的能力提升。
然而，只要改進推理能力的驅動力是
模型的大小和複雜性，運行它們的財務和計算成本也會增加。這個趨勢引發了關於持續可及性的問題，以及這些改進是否會隨著模型規模和成本的持續增長而以相同的步伐增加。我們提出了兩種方法來增強資源密集度較低 LLM 的推理能力。
(1) 為他們提供在特定領域內解決任務的概括策略，由資源密集度較高的 LLM 生成。(2) 利用他們的成本效益，反覆提示這些模型糾正其提出的解決方案中的錯誤。我們從規劃和數學推理任務中獲得的實證結果表明，這些方法將資源密集度較低 LLM 的性能提升到與資源密集度較高的同類產品相當的水平，成本卻只是後者的零頭。此外，我們展示了在我們的實驗中利用概括策略平均將資源密集度較低模型的成本降低了近 30%。

##### **Large Language Models as Common-Sense Heuristics**
2501.18816v1 by Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock

While systems designed for solving planning tasks vastly outperform Large
Language Models (LLMs) in this domain, they usually discard the rich semantic
information embedded within task descriptions. In contrast, LLMs possess
parametrised knowledge across a wide range of topics, enabling them to leverage
the natural language descriptions of planning tasks in their solutions.
However, current research in this direction faces challenges in generating
correct and executable plans. Furthermore, these approaches depend on the LLM
to output solutions in an intermediate language, which must be translated into
the representation language of the planning task. We introduce a novel planning
method, which leverages the parametrised knowledge of LLMs by using their
output as a heuristic for Hill-Climbing Search. This approach is further
enhanced by prompting the LLM to generate a solution estimate to guide the
search. Our method outperforms the task success rate of similar systems within
a common household environment by 22 percentage points, with consistently
executable plans. All actions are encoded in their original representation,
demonstrating that strong results can be achieved without an intermediate
language, thus eliminating the need for a translation step.

摘要：儘管為了解決規劃任務而設計的系統在這個領域中大大優於大型語言模型 (LLM)，但它們通常會捨棄任務描述中嵌入的豐富語義資訊。相比之下，LLM 擁有跨越廣泛主題的參數化知識，使它們能夠在解決方案中利用規劃任務的自然語言描述。然而，目前朝這個方向進行的研究在產生正確且可執行的計畫時會面臨挑戰。此外，這些方法依賴於 LLM 以中間語言輸出解決方案，而該解決方案必須轉換為規劃任務的表示語言。我們引入了一種新穎的規劃方法，透過使用 LLM 的輸出作為爬山搜尋的啟發式方法來利用 LLM 的參數化知識。這種方法進一步透過提示 LLM 產生解決方案估計值來引導搜尋而得到加強。我們的 method 在常見家庭環境中，以始終可執行的計畫將類似系統的任務成功率提高了 22 個百分點。所有動作都以其原始表示進行編碼，證明無需中間語言也能獲得強大的結果，從而消除了轉換步驟的需要。

##### **An Adversarial Approach to Register Extreme Resolution Tissue Cleared 3D Brain Images**
2501.18815v1 by Abdullah Naziba, Clinton Fookes, Dimitri Perrin

We developed a generative patch based 3D image registration model that can
register very high resolution images obtained from a biochemical process name
tissue clearing. Tissue clearing process removes lipids and fats from the
tissue and make the tissue transparent. When cleared tissues are imaged with
Light-sheet fluorescent microscopy, the resulting images give a clear window to
the cellular activities and dynamics inside the tissue.Thus the images obtained
are very rich with cellular information and hence their resolution is extremely
high (eg .2560x2160x676). Analyzing images with such high resolution is a
difficult task for any image analysis pipeline.Image registration is a common
step in image analysis pipeline when comparison between images are required.
Traditional image registration methods fail to register images with such
extant. In this paper we addressed this very high resolution image registration
issue by proposing a patch-based generative network named InvGAN. Our proposed
network can register very high resolution tissue cleared images. The tissue
cleared dataset used in this paper are obtained from a tissue clearing protocol
named CUBIC. We compared our method both with traditional and deep-learning
based registration methods.Two different versions of CUBIC dataset are used,
representing two different resolutions 25% and 100% respectively. Experiments
on two different resolutions clearly show the impact of resolution on the
registration quality. At 25% resolution, our method achieves comparable
registration accuracy with very short time (7 minutes approximately). At 100%
resolution, most of the traditional registration methods fail except Elastix
registration tool.Elastix takes 28 hours to register where proposed InvGAN
takes only 10 minutes.

摘要：<paragraph>我們開發了一個基於生成性補丁的 3D 影像配準模型，可以配準從名為組織透明化的生化過程中獲得的極高解析度影像。組織透明化過程會去除組織中的脂質和脂肪，並使組織透明。當以光片螢光顯微鏡對透明化組織進行成像時，產生的影像會提供一個清晰的視窗，以觀察組織內部的細胞活動和動力。因此，獲得的影像非常豐富細胞資訊，因此其解析度極高 (例如 .2560x2160x676)。使用如此高解析度分析影像對任何影像分析管道而言都是一項艱鉅的任務。影像配準是影像分析管道中的一個常見步驟，當需要比較影像時。傳統的影像配準方法無法配準具有如此程度的影像。在本文中，我們透過提出名為 InvGAN 的基於補丁的生成網路，來解決這個極高解析度影像配準問題。我們提出的網路可以配準極高解析度的組織透明化影像。本文中使用的組織透明化資料集是從名為 CUBIC 的組織透明化協定中獲得的。我們將我們的方法與傳統和基於深度學習的配準方法進行比較。使用了兩個不同版本的 CUBIC 資料集，分別代表兩個不同的解析度 25% 和 100%。在兩個不同解析度上進行的實驗清楚地顯示了解析度對配準品質的影響。在 25% 解析度下，我們的的方法在極短的時間內 (大約 7 分鐘) 達到了相當的配準精度。在 100% 解析度下，除了 Elastix 配準工具外，大多數傳統配準方法都失敗了。Elastix 花費 28 小時進行配準，而所提出的 InvGAN 只花了 10 分鐘。</paragraph>

##### **Every Image Listens, Every Image Dances: Music-Driven Image Animation**
2501.18801v1 by Zhikang Dong, Weituo Hao, Ju-Chiang Wang, Peng Zhang, Pawel Polak

Image animation has become a promising area in multimodal research, with a
focus on generating videos from reference images. While prior work has largely
emphasized generic video generation guided by text, music-driven dance video
generation remains underexplored. In this paper, we introduce MuseDance, an
innovative end-to-end model that animates reference images using both music and
text inputs. This dual input enables MuseDance to generate personalized videos
that follow text descriptions and synchronize character movements with the
music. Unlike existing approaches, MuseDance eliminates the need for complex
motion guidance inputs, such as pose or depth sequences, making flexible and
creative video generation accessible to users of all expertise levels. To
advance research in this field, we present a new multimodal dataset comprising
2,904 dance videos with corresponding background music and text descriptions.
Our approach leverages diffusion-based methods to achieve robust
generalization, precise control, and temporal consistency, setting a new
baseline for the music-driven image animation task.

摘要：影像動畫已成為多模態研究中一個有前景的領域，重點在於從參考影像中產生影片。儘管先前的研究在很大程度上強調由文字引導的通用影片產生，但由音樂驅動的舞蹈影片產生仍未被充分探討。在本文中，我們介紹了 MuseDance，一個創新的端到端模型，它使用音樂和文字輸入對參考影像進行動畫處理。這種雙重輸入使 MuseDance 能夠產生符合文字描述並將角色動作與音樂同步的個人化影片。與現有方法不同，MuseDance 消除了對複雜動作指導輸入（例如姿勢或深度序列）的需求，讓各個專業水準的使用者都能輕鬆進行靈活且有創意的影片產生。為了推進此領域的研究，我們提出了包含 2,904 個舞蹈影片的新多模態資料集，其中包含對應的背景音樂和文字描述。我們的做法利用基於擴散的方法來實現穩健的泛化、精確控制和時間一致性，為由音樂驅動的影像動畫任務設定了新的基準。

##### **Compositional Generalization Requires More Than Disentangled Representations**
2501.18797v1 by Qiyao Liang, Daoyuan Qian, Liu Ziyin, Ila Fiete

Composition-the ability to generate myriad variations from finite means-is
believed to underlie powerful generalization. However, compositional
generalization remains a key challenge for deep learning. A widely held
assumption is that learning disentangled (factorized) representations naturally
supports this kind of extrapolation. Yet, empirical results are mixed, with
many generative models failing to recognize and compose factors to generate
out-of-distribution (OOD) samples. In this work, we investigate a controlled 2D
Gaussian "bump" generation task, demonstrating that standard generative
architectures fail in OOD regions when training with partial data, even when
supplied with fully disentangled $(x, y)$ coordinates, re-entangling them
through subsequent layers. By examining the model's learned kernels and
manifold geometry, we show that this failure reflects a "memorization" strategy
for generation through the superposition of training data rather than by
combining the true factorized features. We show that models forced-through
architectural modifications with regularization or curated training data-to
create disentangled representations in the full-dimensional representational
(pixel) space can be highly data-efficient and effective at learning to compose
in OOD regions. These findings underscore that bottlenecks with
factorized/disentangled representations in an abstract representation are
insufficient: the model must actively maintain or induce factorization directly
in the representational space in order to achieve robust compositional
generalization.

摘要：組合性——從有限手段產生無數變化的能力——被認為是強大泛化的基礎。然而，組合泛化仍然是深度學習的一項關鍵挑戰。一個廣泛的假設是學習解開（分解）表示自然地支持這種外推。然而，經驗結果好壞參半，許多生成模型無法識別和組合因子來生成分布外 (OOD) 樣本。在這項工作中，我們研究了一個受控的 2D 高斯「凸起」生成任務，證明了標準生成架構在使用部分數據訓練時會在 OOD 區域中失敗，即使提供了完全解開的 $(x, y)$ 坐標，也會通過後續層重新糾纏它們。通過檢查模型學習的核和流形幾何，我們表明這種失敗反映了通過訓練數據的疊加而不是通過組合真實分解特徵來生成「記憶」策略。我們表明，通過架構修改強制通過正則化或策劃訓練數據的模型——在全維表示（像素）空間中創建解開的表示——在學習 OOD 區域中的組合方面可以具有很高的數據效率和有效性。這些發現強調，抽象表示中具有分解/解開表示的瓶頸是不夠的：模型必須主動維護或直接在表示空間中誘導分解，才能實現穩健的組合泛化。

##### **Rope to Nope and Back Again: A New Hybrid Attention Strategy**
2501.18795v1 by Bowen Yang, Bharat Venkitesh, Dwarak Talupuru, Hangyu Lin, David Cairuz, Phil Blunsom, Acyr Locatelli

Long-context large language models (LLMs) have achieved remarkable
advancements, driven by techniques like Rotary Position Embedding (RoPE) (Su et
al., 2023) and its extensions (Chen et al., 2023; Liu et al., 2024c; Peng et
al., 2023). By adjusting RoPE parameters and incorporating training data with
extended contexts, we can train performant models with considerably longer
input sequences. However, existing RoPE-based methods exhibit performance
limitations when applied to extended context lengths. This paper presents a
comprehensive analysis of various attention mechanisms, including RoPE, No
Positional Embedding (NoPE), and Query-Key Normalization (QK-Norm), identifying
their strengths and shortcomings in long-context modeling. Our investigation
identifies distinctive attention patterns in these methods and highlights their
impact on long-context performance, providing valuable insights for
architectural design. Building on these findings, we propose a novel
architectural based on a hybrid attention mechanism that not only surpasses
conventional RoPE-based transformer models in long context tasks but also
achieves competitive performance on benchmarks requiring shorter context
lengths.

摘要：長文本大型語言模型 (LLM) 已取得顯著進展，這歸功於旋轉位置嵌入 (RoPE) (Su 等人，2023 年) 及其延伸技術 (Chen 等人，2023 年；Liu 等人，2024c；Peng 等人，2023 年)。透過調整 RoPE 參數並結合具有延伸文本的訓練資料，我們可以訓練出具有相當長輸入序列的效能模型。然而，現有的基於 RoPE 的方法在應用於延伸文本長度時會出現效能限制。本文針對各種注意力機制進行全面分析，包括 RoPE、無位置嵌入 (NoPE) 和查詢鍵正規化 (QK-Norm)，找出它們在長文本建模中的優點和缺點。我們的調查找出這些方法中獨特的注意力模式，並強調它們對長文本效能的影響，為架構設計提供寶貴的見解。根據這些發現，我們提出一個新穎的架構，基於一種混合注意力機制，它不僅在長文本任務中超越傳統的基於 RoPE 的 Transformer 模型，而且在需要較短文本長度的基準測試中也取得競爭力的效能。

##### **Survey and Improvement Strategies for Gene Prioritization with Large Language Models**
2501.18794v1 by Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu

Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.

摘要：罕見疾病由於患者數據有限和遺傳多樣性，診斷起來具有挑戰性。儘管變異優先級排序技術進步，但許多病例仍未得到診斷。儘管大型語言模型 (LLM) 在醫學考試中表現良好，但它們在診斷罕見遺傳疾病方面的有效性尚未得到評估。為了識別致病基因，我們對各種 LLM 進行了基因優先級排序基準測試。使用多智能體和人類表型本体 (HPO) 分類，我們根據表型和可解決性對患者進行了分類。隨著基因組大小的增加，LLM 性能下降，因此我們使用分而治之策略將任務分解為更小的子集。在基線中，GPT-4 優於其他 LLM，在正確排序致病基因方面達到近 30% 的準確度。多智能體和 HPO 方法有助於區分解決有信心的病例和具有挑戰性的病例，強調已知基因-表型關聯和表型特異性的重要性。我們發現具有特定表型或明確關聯的病例得到更準確的解決。然而，我們觀察到對研究充分的基因和輸入順序敏感性的偏差，這阻礙了基因優先級排序。我們的分而治之策略通過克服這些偏差來提高準確性。通過利用 HPO 分類、新穎的多智能體技術和我們的 LLM 策略，我們與我們的基線評估相比提高了致病基因識別準確性。這種方法簡化了罕見疾病的診斷，促進了對未解決病例的重新分析，並加速了基因發現，支持了靶向診斷和治療的開發。

##### **OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization**
2501.18793v1 by Kelvin Kan, Xingjian Li, Stanley Osher

Transformers have achieved state-of-the-art performance in numerous tasks. In
this paper, we propose a continuous-time formulation of transformers.
Specifically, we consider a dynamical system whose governing equation is
parametrized by transformer blocks. We leverage optimal transport theory to
regularize the training problem, which enhances stability in training and
improves generalization of the resulting model. Moreover, we demonstrate in
theory that this regularization is necessary as it promotes uniqueness and
regularity of solutions. Our model is flexible in that almost any existing
transformer architectures can be adopted to construct the dynamical system with
only slight modifications to the existing code. We perform extensive numerical
experiments on tasks motivated by natural language processing, image
classification, and point cloud classification. Our experimental results show
that the proposed method improves the performance of its discrete counterpart
and outperforms relevant comparing models.

摘要：Transformer在許多任務中都達到了最先進的表現。在本文中，我們提出Transformer的連續時間公式。具體來說，我們考慮一個動態系統，其控制方程式由Transformer塊參數化。我們利用最優傳輸理論來規範訓練問題，這增強了訓練的穩定性，並改進了所得模型的泛化能力。此外，我們在理論上證明了這種規範化是必要的，因為它促进了解的唯一性和規律性。我們的模型很靈活，因為幾乎任何現有的Transformer架構都可以採用來構建動態系統，而現有代碼只需稍作修改。我們對自然語言處理、圖像分類和點雲分類等任務進行了廣泛的數值實驗。我們的實驗結果表明，所提出的方法改進了其離散對應項的性能，並且優於相關的比較模型。

##### **LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?**
2501.18784v1 by Alexander Tuisov, Yonatan Vernik, Alexander Shleyfman

Domain-independent heuristics have long been a cornerstone of AI planning,
offering general solutions applicable across a wide range of tasks without
requiring domain-specific engineering. However, the advent of large language
models (LLMs) presents an opportunity to generate heuristics tailored to
specific planning problems, potentially challenging the necessity of domain
independence as a strict design principle. In this paper, we explore the use of
LLMs to automatically derive planning heuristics from task descriptions
represented as successor generators and goal tests written in general purpose
programming language. We investigate the trade-offs between domain-specific
LLM-generated heuristics and traditional domain-independent methods in terms of
computational efficiency and explainability. Our experiments demonstrate that
LLMs can create heuristics that achieve state-of-the-art performance on some
standard IPC domains, as well as their ability to solve problems that lack an
adequate Planning Domain Definition Language ({\sc pddl}) representation. We
discuss whether these results signify a paradigm shift and how they can
complement existing approaches.

摘要：領域無關的啟發式方法一直是 AI 規劃的基石，提供適用於各種任務的通用解決方案，而無需領域特定的工程。然而，大型語言模型 (LLM) 的出現提供了一個機會來生成針對特定規劃問題量身定制的啟發式方法，這可能會挑戰領域獨立性作為嚴格設計原則的必要性。在本文中，我們探討了使用 LLM 從後繼生成器和目標測試中自動推導規劃啟發式方法，這些後繼生成器和目標測試是用通用程式語言編寫的。我們研究了領域特定的 LLM 生成的啟發式方法和傳統的領域無關方法在計算效率和可解釋性方面的取捨。我們的實驗表明，LLM 可以建立啟發式方法，在一些標準 IPC 領域上實現最先進的效能，以及它們解決缺少適當規劃領域定義語言 ({\sc pddl}) 表示的問題的能力。我們討論這些結果是否表示範例轉移，以及它們如何補充現有方法。

##### **Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation**
2501.18771v1 by Muhammed Yusuf Kocyigit, Eleftheria Briakou, Daniel Deutsch, Jiaming Luo, Colin Cherry, Markus Freitag

Data contamination -- the accidental consumption of evaluation examples
within the pre-training data -- can undermine the validity of evaluation
benchmarks. In this paper, we present a rigorous analysis of the effects of
contamination on language models at 1B and 8B scales on the machine translation
task. Starting from a carefully decontaminated train-test split, we
systematically introduce contamination at various stages, scales, and data
formats to isolate its effect and measure its impact on performance metrics.
Our experiments reveal that contamination with both source and target
substantially inflates BLEU scores, and this inflation is 2.5 times larger (up
to 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and
target-only contamination generally produce smaller, less consistent
over-estimations. Finally, we study how the temporal distribution and frequency
of contaminated samples influence performance over-estimation across languages
with varying degrees of data resources.

摘要：資料污染 -- 在預訓練資料中意外使用評估範例 -- 可能會破壞評估基準的效度。在本文中，我們提出對 1B 和 8B 規模語言模型在機器翻譯任務中受到污染影響的嚴謹分析。從仔細去汙的訓練測試分割開始，我們系統性地引進不同階段、規模和資料格式的污染，以孤立其影響並衡量其對效能指標的衝擊。我們的實驗顯示，來源和目標的污染都會大幅提升 BLEU 分數，而 8B 模型的這種提升比 1B 模型大了 2.5 倍（最多 30 個 BLEU 點）。相較之下，只有來源或只有目標的污染通常會產生較小、較不一致的高估。最後，我們研究受污染樣本的時間分佈和頻率如何影響不同資料資源程度的語言效能高估。

##### **Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization**
2501.18768v1 by Michael S. Yao, James C. Gee, Osbert Bastani

The goal of offline model-based optimization (MBO) is to propose new designs
that maximize a reward function given only an offline dataset. However, an
important desiderata is to also propose a diverse set of final candidates that
capture many optimal and near-optimal design configurations. We propose
Diversity in Adversarial Model-based Optimization (DynAMO) as a novel method to
introduce design diversity as an explicit objective into any MBO problem. Our
key insight is to formulate diversity as a distribution matching problem where
the distribution of generated designs captures the inherent diversity contained
within the offline dataset. Extensive experiments spanning multiple scientific
domains show that DynAMO can be used with common optimization methods to
significantly improve the diversity of proposed designs while still discovering
high-quality candidates.

摘要：離線模型優化 (MBO) 的目標是提出新的設計，在僅提供離線資料集的情況下最大化回報函數。然而，一個重要的條件是提出多樣化的最終候選集，其中包含許多最佳和接近最佳的設計配置。我們提出在對抗模型優化 (DynAMO) 中的多樣性，作為一種新穎的方法，將設計多樣性作為明確的目標引入任何 MBO 問題。我們的關鍵見解是將多樣性表述為一個分佈匹配問題，其中生成設計的分佈捕捉了離線資料集中包含的固有多樣性。跨越多個科學領域的廣泛實驗表明，DynAMO 可與常見的最佳化方法一起使用，以顯著提高所提出設計的多樣性，同時仍能發現高品質的候選者。

##### **Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language**
2501.18766v1 by Pronoy Kumar Mondal, Sadman Sadik Khan, Md. Masud Rana, Shahriar Sultan Ramit, Abdus Sattar, Md. Sadekur Rahman

The rapid development of digital stages has greatly compounded the dispersal
of untrue data, dissolving certainty and judgment in society, especially among
the Bengali-speaking community. Our ponder addresses this critical issue by
presenting an interesting strategy that utilizes a profound learning
innovation, particularly the Gated Repetitive Unit (GRU), to recognize fake
news within the Bangla dialect. The strategy of our proposed work incorporates
intensive information preprocessing, which includes lemmatization,
tokenization, and tending to course awkward nature by oversampling. This comes
about in a dataset containing 58,478 passages. We appreciate the creation of a
demonstration based on GRU (Gated Repetitive Unit) that illustrates remarkable
execution with a noteworthy precision rate of 94%. This ponder gives an
intensive clarification of the methods included in planning the information,
selecting the show, preparing it, and assessing its execution. The performance
of the model is investigated by reliable metrics like precision, recall, F1
score, and accuracy. The commitment of the work incorporates making a huge fake
news dataset in Bangla and a demonstration that has outperformed other Bangla
fake news location models.

摘要：數位舞台的快速發展極大地加劇了不實資料的散播，消解了社會中的確定性和判斷力，特別是在講孟加拉語的社群中。我們的思考透過提出一個有趣的策略來解決這個關鍵問題，該策略利用了深度學習創新，特別是門控迴圈單元 (GRU)，來辨識孟加拉方言中的假新聞。我們提出的工作策略包含密集的資料前處理，其中包括詞形還原、標記化和透過過度抽樣來處理課程不平衡。這產生了一個包含 58,478 段落之資料集。我們很欣賞基於 GRU (門控迴圈單元) 的示範的建立，它以 94% 的顯著精確度率說明了非凡的執行。這項思考提供了對規劃資料、選擇特徵、準備資料和評估其執行的所包含方法的深入說明。該模型的效能是由精確度、召回率、F1 分數和準確度等可靠指標來調查的。這項工作的承諾包括製作一個龐大的孟加拉語假新聞資料集，以及一個表現優於其他孟加拉語假新聞定位模型的示範。

##### **Revisiting Projection-based Data Transfer for Cross-Lingual Named Entity Recognition in Low-Resource Languages**
2501.18750v1 by Andrei Politov, Oleh Shkalikov, René Jäkel, Michael Färber

Cross-lingual Named Entity Recognition (NER) leverages knowledge transfer
between languages to identify and classify named entities, making it
particularly useful for low-resource languages. We show that the data-based
cross-lingual transfer method is an effective technique for crosslingual NER
and can outperform multilingual language models for low-resource languages.
This paper introduces two key enhancements to the annotation projection step in
cross-lingual NER for low-resource languages. First, we explore refining word
alignments using back-translation to improve accuracy. Second, we present a
novel formalized projection approach of matching source entities with extracted
target candidates. Through extensive experiments on two datasets spanning 57
languages, we demonstrated that our approach surpasses existing projectionbased
methods in low-resource settings. These findings highlight the robustness of
projection-based data transfer as an alternative to model-based methods for
crosslingual named entity recognition in lowresource languages.

摘要：跨語言命名實體辨識 (NER) 利用語言之間的知識轉移來辨識和分類命名實體，這對於低資源語言特別有用。我們展示基於資料的跨語言轉移方法是跨語言 NER 的一種有效技術，並且可以優於多語言語言模型的低資源語言。本文介紹了低資源語言跨語言 NER 中註解投影步驟的兩項關鍵改進。首先，我們探討使用反向翻譯來改善準確度，以改善詞彙對齊。其次，我們提出一個新的形式化投影方法，用於將來源實體與提取的目標候選項目相匹配。透過對橫跨 57 種語言的兩個資料集進行廣泛的實驗，我們證明了我們的做法在低資源設定中超越了現有的基於投影的方法。這些發現突顯了基於投影的資料轉移作為低資源語言中基於模型方法的跨語言命名實體辨識的替代方案的穩健性。

##### **Synthetic Data Generation for Augmenting Small Samples**
2501.18741v1 by Dan Liu, Samer El Kababji, Nicholas Mitsakakis, Lisa Pilgram, Thomas Walters, Mark Clemons, Greg Pond, Alaa El-Hussuna, Khaled El Emam

Small datasets are common in health research. However, the generalization
performance of machine learning models is suboptimal when the training datasets
are small. To address this, data augmentation is one solution. Augmentation
increases sample size and is seen as a form of regularization that increases
the diversity of small datasets, leading them to perform better on unseen data.
We found that augmentation improves prognostic performance for datasets that:
have fewer observations, with smaller baseline AUC, have higher cardinality
categorical variables, and have more balanced outcome variables. No specific
generative model consistently outperformed the others. We developed a decision
support model that can be used to inform analysts if augmentation would be
useful. For seven small application datasets, augmenting the existing data
results in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%
(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,
demonstrating the nontrivial impact of augmentation on small datasets
(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The
diversity of augmented datasets was higher than the diversity of resampled
datasets (p=0.046).

摘要：在健康研究中，小型数据集很常见。然而，当训练数据集较小时，机器学习模型的泛化性能并不理想。为了解决这个问题，数据增强是一种解决方案。增强增加了样本量，并被视为一种正则化形式，它增加了小型数据集的多样性，从而使其在未见数据上表现得更好。我们发现，增强提高了以下数据集的预测性能：具有较少的观测值、较小的基线 AUC、较高的基数分类变量以及更平衡的结果变量。没有特定的生成模型始终优于其他模型。我们开发了一个决策支持模型，可用于告知分析师增强是否有用。对于七个小型应用程序数据集，增强现有数据导致 AUC 增加 4.31%（AUC 从 0.71 增加到 0.75）和 43.23%（AUC 从 0.51 增加到 0.73），平均相对改进 15.55%，这表明了增强对小型数据集的非平凡影响（p=0.0078）。增强 AUC 高于仅重新采样的 AUC（p=0.016）。增强数据集的多样性高于重新采样数据集的多样性（p=0.046）。

##### **Neural Graph Pattern Machine**
2501.18739v1 by Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Graph learning tasks require models to comprehend essential substructure
patterns relevant to downstream tasks, such as triadic closures in social
networks and benzene rings in molecular graphs. Due to the non-Euclidean nature
of graphs, existing graph neural networks (GNNs) rely on message passing to
iteratively aggregate information from local neighborhoods. Despite their
empirical success, message passing struggles to identify fundamental
substructures, such as triangles, limiting its expressiveness. To overcome this
limitation, we propose the Neural Graph Pattern Machine (GPM), a framework
designed to learn directly from graph patterns. GPM efficiently extracts and
encodes substructures while identifying the most relevant ones for downstream
tasks. We also demonstrate that GPM offers superior expressivity and improved
long-range information modeling compared to message passing. Empirical
evaluations on node classification, link prediction, graph classification, and
regression show the superiority of GPM over state-of-the-art baselines. Further
analysis reveals its desirable out-of-distribution robustness, scalability, and
interpretability. We consider GPM to be a step toward going beyond message
passing.

摘要：圖形學習任務需要模型理解與下游任務相關的基本子結構模式，例如社交網路中的三元封閉和分子圖形中的苯環。由於圖形的非歐幾何性質，現有的圖形神經網路 (GNN) 依賴訊息傳遞來反覆聚合來自局部鄰域的資訊。儘管在經驗上獲得成功，訊息傳遞仍難以識別基本子結構，例如三角形，這限制了其表達能力。為了克服這個限制，我們提出神經圖形模式機器 (GPM)，一個旨在直接從圖形模式學習的框架。GPM 在識別對下游任務最相關的子結構時，有效地提取並編碼子結構。我們也證明，與訊息傳遞相比，GPM 提供了卓越的表達能力和改進的長距離資訊建模。在節點分類、連結預測、圖形分類和回歸上的經驗評估顯示，GPM 優於最先進的基準。進一步的分析揭示了其理想的分布外穩健性、可擴充性和可解釋性。我們認為 GPM 是超越訊息傳遞的一步。

##### **Examining the Robustness of Large Language Models across Language Complexity**
2501.18738v1 by Jiayi Zhang

With the advancement of large language models (LLMs), an increasing number of
student models have leveraged LLMs to analyze textual artifacts generated by
students to understand and evaluate their learning. These student models
typically employ pre-trained LLMs to vectorize text inputs into embeddings and
then use the embeddings to train models to detect the presence or absence of a
construct of interest. However, how reliable and robust are these models at
processing language with different levels of complexity? In the context of
learning where students may have different language backgrounds with various
levels of writing skills, it is critical to examine the robustness of such
models to ensure that these models work equally well for text with varying
levels of language complexity. Coincidentally, a few (but limited) research
studies show that the use of language can indeed impact the performance of
LLMs. As such, in the current study, we examined the robustness of several
LLM-based student models that detect student self-regulated learning (SRL) in
math problem-solving. Specifically, we compared how the performance of these
models vary using texts with high and low lexical, syntactic, and semantic
complexity measured by three linguistic measures.

摘要：隨著大型語言模型 (LLM) 的進步，越來越多的學生模型利用 LLM 來分析學生產生的文本製品，以了解和評估他們的學習情況。這些學生模型通常採用預先訓練的 LLM，將文本輸入向量化為嵌入，然後使用嵌入來訓練模型，以檢測目標結構是否存在。然而，這些模型在處理不同複雜程度的語言時，其可靠性和穩健性如何？在學生可能具有不同語言背景和各種寫作技能的學習背景下，審查此類模型的穩健性至關重要，以確保這些模型對語言複雜程度不同的文本同樣有效。巧合的是，一些（但有限的）研究表明，語言的使用確實會影響 LLM 的效能。因此，在當前的研究中，我們檢驗了幾個基於 LLM 的學生模型的穩健性，這些模型可以檢測數學問題解決中的學生自我調節學習 (SRL)。具體來說，我們比較了這些模型使用語言複雜度由三種語言測量測得的高低詞彙、句法和語義複雜度的文本時，效能如何變化。

##### **Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation**
2501.18733v1 by Yuelei Li, Ge Yan, Annabella Macaluso, Mazeyu Ji, Xueyan Zou, Xiaolong Wang

The recent advancements in visual reasoning capabilities of large multimodal
models (LMMs) and the semantic enrichment of 3D feature fields have expanded
the horizons of robotic capabilities. These developments hold significant
potential for bridging the gap between high-level reasoning from LMMs and
low-level control policies utilizing 3D feature fields. In this work, we
introduce LMM-3DP, a framework that can integrate LMM planners and 3D skill
Policies. Our approach consists of three key perspectives: high-level planning,
low-level control, and effective integration. For high-level planning, LMM-3DP
supports dynamic scene understanding for environment disturbances, a critic
agent with self-feedback, history policy memorization, and reattempts after
failures. For low-level control, LMM-3DP utilizes a semantic-aware 3D feature
field for accurate manipulation. In aligning high-level and low-level control
for robot actions, language embeddings representing the high-level policy are
jointly attended with the 3D feature field in the 3D transformer for seamless
integration. We extensively evaluate our approach across multiple skills and
long-horizon tasks in a real-world kitchen environment. Our results show a
significant 1.45x success rate increase in low-level control and an approximate
1.5x improvement in high-level planning accuracy compared to LLM-based
baselines. Demo videos and an overview of LMM-3DP are available at
https://lmm-3dp-release.github.io.

摘要：<paragraph>大型多模態模型 (LMM) 的視覺推理能力和 3D 特徵場的語義豐富化最近的進展擴展了機器人能力的視野。這些發展具有巨大的潛力，可以彌合 LMM 的高階推理和利用 3D 特徵場的低階控制策略之間的差距。在這項工作中，我們介紹了 LMM-3DP，一個可以整合 LMM 計畫器和 3D 技能策略的框架。我們的做法包含三個關鍵觀點：高階規劃、低階控制和有效整合。對於高階規劃，LMM-3DP 支援環境干擾的動態場景理解、具有自我回饋的批評代理、歷史策略記憶以及失敗後的重試。對於低階控制，LMM-3DP 利用語義感知的 3D 特徵場進行準確的操縱。在調整機器人動作的高階和低階控制時，表示高階策略的語言嵌入與 3D 特徵場在 3D 轉換器中共同關注，以實現無縫整合。我們在真實世界的廚房環境中廣泛評估了我們的方法，涉及多項技能和長時程任務。我們的結果顯示，與基於 LLM 的基線相比，低階控制的成功率顯著提升了 1.45 倍，高階規劃準確度提升了約 1.5 倍。展示影片和 LMM-3DP 的概述可以在 https://lmm-3dp-release.github.io/ 取得。</paragraph>

