{"2411.07140": {"publish_time": "2024-11-11", "title": "Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models", "paper_summary": "New LLM evaluation benchmarks are important to align with the rapid\ndevelopment of Large Language Models (LLMs). In this work, we present Chinese\nSimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality\nability of language models to answer short questions, and Chinese SimpleQA\nmainly has five properties (i.e., Chinese, Diverse, High-quality, Static,\nEasy-to-evaluate). Specifically, first, we focus on the Chinese language over 6\nmajor topics with 99 diverse subtopics. Second, we conduct a comprehensive\nquality control process to achieve high-quality questions and answers, where\nthe reference answers are static and cannot be changed over time. Third,\nfollowing SimpleQA, the questions and answers are very short, and the grading\nprocess is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we\nperform a comprehensive evaluation on the factuality abilities of existing\nLLMs. Finally, we hope that Chinese SimpleQA could guide the developers to\nbetter understand the Chinese factuality abilities of their models and\nfacilitate the growth of foundation models.", "paper_summary_zh": "\u65b0\u7684 LLM \u8a55\u4f30\u57fa\u6e96\u5c0d\u65bc\u8207\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\u4fdd\u6301\u4e00\u81f4\u975e\u5e38\u91cd\u8981\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e2d\u6587 SimpleQA\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5168\u9762\u7684\u4e2d\u6587\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30\u8a9e\u8a00\u6a21\u578b\u56de\u7b54\u7c21\u77ed\u554f\u984c\u7684\u4e8b\u5be6\u80fd\u529b\uff0c\u800c\u4e2d\u6587 SimpleQA \u4e3b\u8981\u6709\u4e94\u500b\u7279\u6027\uff08\u5373\u4e2d\u6587\u3001\u591a\u5143\u5316\u3001\u9ad8\u54c1\u8cea\u3001\u975c\u614b\u3001\u6613\u65bc\u8a55\u4f30\uff09\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u9996\u5148\uff0c\u6211\u5011\u5c08\u6ce8\u65bc 6 \u500b\u4e3b\u8981\u4e3b\u984c\u7684\u4e2d\u6587\uff0c\u4ee5\u53ca 99 \u500b\u4e0d\u540c\u7684\u5b50\u4e3b\u984c\u3002\u5176\u6b21\uff0c\u6211\u5011\u9032\u884c\u5168\u9762\u7684\u54c1\u8cea\u63a7\u7ba1\u6d41\u7a0b\uff0c\u4ee5\u7372\u5f97\u9ad8\u54c1\u8cea\u7684\u554f\u984c\u548c\u7b54\u6848\uff0c\u5176\u4e2d\u53c3\u8003\u7b54\u6848\u662f\u975c\u614b\u7684\uff0c\u4e26\u4e14\u4e0d\u6703\u96a8\u8457\u6642\u9593\u800c\u6539\u8b8a\u3002\u7b2c\u4e09\uff0c\u9075\u5faa SimpleQA\uff0c\u554f\u984c\u548c\u7b54\u6848\u975e\u5e38\u7c21\u77ed\uff0c\u8a55\u5206\u904e\u7a0b\u57fa\u65bc OpenAI API\uff0c\u6613\u65bc\u8a55\u4f30\u3002\u6839\u64da\u4e2d\u6587 SimpleQA\uff0c\u6211\u5011\u5c0d\u73fe\u6709 LLM \u7684\u4e8b\u5be6\u80fd\u529b\u9032\u884c\u5168\u9762\u8a55\u4f30\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5e0c\u671b\u4e2d\u6587 SimpleQA \u53ef\u4ee5\u5f15\u5c0e\u958b\u767c\u4eba\u54e1\u66f4\u597d\u5730\u4e86\u89e3\u5176\u6a21\u578b\u7684\u4e2d\u6587\u4e8b\u5be6\u80fd\u529b\uff0c\u4e26\u4fc3\u9032\u57fa\u790e\u6a21\u578b\u7684\u767c\u5c55\u3002", "author": "Yancheng He et.al.", "authors": "Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Hui Huang, Weixun Wang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Xuepeng Liu, Dekai Sun, Wenbo Su, Bo Zheng", "id": "2411.07140v1", "paper_url": "http://arxiv.org/abs/2411.07140v1", "repo": "null"}}