{"2411.16502": {"publish_time": "2024-11-25", "title": "Interpreting Language Reward Models via Contrastive Explanations", "paper_summary": "Reward models (RMs) are a crucial component in the alignment of large\nlanguage models' (LLMs) outputs with human values. RMs approximate human\npreferences over possible LLM responses to the same prompt by predicting and\ncomparing reward scores. However, as they are typically modified versions of\nLLMs with scalar output heads, RMs are large black boxes whose predictions are\nnot explainable. More transparent RMs would enable improved trust in the\nalignment of LLMs. In this work, we propose to use contrastive explanations to\nexplain any binary response comparison made by an RM. Specifically, we generate\na diverse set of new comparisons similar to the original one to characterise\nthe RM's local behaviour. The perturbed responses forming the new comparisons\nare generated to explicitly modify manually specified high-level evaluation\nattributes, on which analyses of RM behaviour are grounded. In quantitative\nexperiments, we validate the effectiveness of our method for finding\nhigh-quality contrastive explanations. We then showcase the qualitative\nusefulness of our method for investigating global sensitivity of RMs to each\nevaluation attribute, and demonstrate how representative examples can be\nautomatically extracted to explain and compare behaviours of different RMs. We\nsee our method as a flexible framework for RM explanation, providing a basis\nfor more interpretable and trustworthy LLM alignment.", "paper_summary_zh": "\u734e\u52f5\u6a21\u578b (RM) \u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8f38\u51fa\u8207\u4eba\u985e\u50f9\u503c\u89c0\u4e00\u81f4\u6027\u7684\u95dc\u9375\u7d44\u6210\u90e8\u5206\u3002RM \u900f\u904e\u9810\u6e2c\u548c\u6bd4\u8f03\u734e\u52f5\u5206\u6578\u4f86\u8fd1\u4f3c\u4eba\u985e\u5c0d\u76f8\u540c\u63d0\u793a\u7684 LLM \u56de\u61c9\u7684\u504f\u597d\u3002\u7136\u800c\uff0c\u7531\u65bc\u5b83\u5011\u901a\u5e38\u662f\u5177\u6709\u6a19\u91cf\u8f38\u51fa\u982d\u7684 LLM \u7684\u4fee\u6539\u7248\u672c\uff0c\u56e0\u6b64 RM \u662f\u5927\u578b\u9ed1\u76d2\u5b50\uff0c\u5176\u9810\u6e2c\u7121\u6cd5\u89e3\u91cb\u3002\u66f4\u900f\u660e\u7684 RM \u53ef\u4ee5\u63d0\u9ad8\u5c0d LLM \u4e00\u81f4\u6027\u7684\u4fe1\u4efb\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u5c0d\u6bd4\u89e3\u91cb\u4f86\u89e3\u91cb RM \u505a\u51fa\u7684\u4efb\u4f55\u4e8c\u5143\u56de\u61c9\u6bd4\u8f03\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u751f\u6210\u4e00\u7d44\u8207\u539f\u59cb\u6bd4\u8f03\u985e\u4f3c\u7684\u591a\u6a23\u5316\u65b0\u6bd4\u8f03\uff0c\u4ee5\u8868\u5fb5 RM \u7684\u5c40\u90e8\u884c\u70ba\u3002\u5f62\u6210\u65b0\u6bd4\u8f03\u7684\u64fe\u52d5\u56de\u61c9\u88ab\u751f\u6210\u4ee5\u660e\u78ba\u4fee\u6539\u624b\u52d5\u6307\u5b9a\u7684\u8a55\u4f30\u9ad8\u5c64\u7d1a\u5c6c\u6027\uff0cRM \u884c\u70ba\u5206\u6790\u4ee5\u6b64\u70ba\u57fa\u790e\u3002\u5728\u5b9a\u91cf\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u9a57\u8b49\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u5c0b\u627e\u9ad8\u54c1\u8cea\u5c0d\u6bd4\u89e3\u91cb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u7814\u7a76 RM \u5c0d\u6bcf\u500b\u8a55\u4f30\u5c6c\u6027\u7684\u5168\u5c40\u654f\u611f\u6027\u65b9\u9762\u7684\u5b9a\u6027\u6709\u7528\u6027\uff0c\u4e26\u5c55\u793a\u4e86\u5982\u4f55\u81ea\u52d5\u63d0\u53d6\u4ee3\u8868\u6027\u7bc4\u4f8b\u4f86\u89e3\u91cb\u548c\u6bd4\u8f03\u4e0d\u540c RM \u7684\u884c\u70ba\u3002\u6211\u5011\u5c07\u6211\u5011\u7684\u7684\u65b9\u6cd5\u8996\u70ba RM \u89e3\u91cb\u7684\u5f48\u6027\u6846\u67b6\uff0c\u70ba\u66f4\u5177\u53ef\u89e3\u91cb\u6027\u548c\u53ef\u4fe1\u8cf4\u6027\u7684 LLM \u4e00\u81f4\u6027\u63d0\u4f9b\u57fa\u790e\u3002", "author": "Junqi Jiang et.al.", "authors": "Junqi Jiang, Tom Bewley, Saumitra Mishra, Freddy Lecue, Manuela Veloso", "id": "2411.16502v1", "paper_url": "http://arxiv.org/abs/2411.16502v1", "repo": "null"}}