{"2406.09175": {"publish_time": "2024-06-13", "title": "ReMI: A Dataset for Reasoning with Multiple Images", "paper_summary": "With the continuous advancement of large language models (LLMs), it is\nessential to create new benchmarks to effectively evaluate their expanding\ncapabilities and identify areas for improvement. This work focuses on\nmulti-image reasoning, an emerging capability in state-of-the-art LLMs. We\nintroduce ReMI, a dataset designed to assess LLMs' ability to Reason with\nMultiple Images. This dataset encompasses a diverse range of tasks, spanning\nvarious reasoning domains such as math, physics, logic, code, table/chart\nunderstanding, and spatial and temporal reasoning. It also covers a broad\nspectrum of characteristics found in multi-image reasoning scenarios. We have\nbenchmarked several cutting-edge LLMs using ReMI and found a substantial gap\nbetween their performance and human-level proficiency. This highlights the\nchallenges in multi-image reasoning and the need for further research. Our\nanalysis also reveals the strengths and weaknesses of different models,\nshedding light on the types of reasoning that are currently attainable and\nareas where future models require improvement. To foster further research in\nthis area, we are releasing ReMI publicly:\nhttps://huggingface.co/datasets/mehrankazemi/ReMI.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6301\u7e8c\u9032\u6b65\uff0c\u5efa\u7acb\u65b0\u7684\u57fa\u6e96\u4ee5\u6709\u6548\u8a55\u4f30\u5176\u64f4\u5c55\u80fd\u529b\u4e26\u627e\u51fa\u6539\u9032\u9818\u57df\u81f3\u95dc\u91cd\u8981\u3002\u9019\u9805\u5de5\u4f5c\u91cd\u9ede\u5728\u65bc\u591a\u5716\u50cf\u63a8\u7406\uff0c\u9019\u662f\u6700\u5148\u9032\u7684 LLM \u4e2d\u51fa\u73fe\u7684\u80fd\u529b\u3002\u6211\u5011\u63a8\u51fa ReMI\uff0c\u4e00\u500b\u65e8\u5728\u8a55\u4f30 LLM \u4f7f\u7528\u591a\u500b\u5716\u50cf\u63a8\u7406\u80fd\u529b\u7684\u8cc7\u6599\u96c6\u3002\u6b64\u8cc7\u6599\u96c6\u5305\u542b\u5404\u7a2e\u4efb\u52d9\uff0c\u6db5\u84cb\u5404\u7a2e\u63a8\u7406\u9818\u57df\uff0c\u4f8b\u5982\u6578\u5b78\u3001\u7269\u7406\u3001\u908f\u8f2f\u3001\u7a0b\u5f0f\u78bc\u3001\u8868\u683c/\u5716\u8868\u7406\u89e3\uff0c\u4ee5\u53ca\u7a7a\u9593\u548c\u6642\u9593\u63a8\u7406\u3002\u5b83\u9084\u6db5\u84cb\u4e86\u591a\u5716\u50cf\u63a8\u7406\u5834\u666f\u4e2d\u767c\u73fe\u7684\u5ee3\u6cdb\u7279\u5fb5\u3002\u6211\u5011\u5df2\u4f7f\u7528 ReMI \u5c0d\u5e7e\u500b\u5c16\u7aef\u7684 LLM \u9032\u884c\u57fa\u6e96\u6e2c\u8a66\uff0c\u767c\u73fe\u5176\u6027\u80fd\u8207\u4eba\u985e\u6c34\u6e96\u4e4b\u9593\u5b58\u5728\u986f\u8457\u5dee\u8ddd\u3002\u9019\u51f8\u986f\u4e86\u591a\u5716\u50cf\u63a8\u7406\u4e2d\u7684\u6311\u6230\u548c\u9032\u4e00\u6b65\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002\u6211\u5011\u7684\u5206\u6790\u4e5f\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u512a\u7f3a\u9ede\uff0c\u95e1\u660e\u4e86\u7576\u524d\u53ef\u5be6\u73fe\u7684\u63a8\u7406\u985e\u578b\u548c\u672a\u4f86\u6a21\u578b\u9700\u8981\u6539\u9032\u7684\u9818\u57df\u3002\u70ba\u4e86\u4fc3\u9032\u6b64\u9818\u57df\u7684\u9032\u4e00\u6b65\u7814\u7a76\uff0c\u6211\u5011\u516c\u958b\u767c\u4f48 ReMI\uff1a\nhttps://huggingface.co/datasets/mehrankazemi/ReMI\u3002", "author": "Mehran Kazemi et.al.", "authors": "Mehran Kazemi, Nishanth Dikkala, Ankit Anand, Petar Devic, Ishita Dasgupta, Fangyu Liu, Bahare Fatemi, Pranjal Awasthi, Dee Guo, Sreenivas Gollapudi, Ahmed Qureshi", "id": "2406.09175v1", "paper_url": "http://arxiv.org/abs/2406.09175v1", "repo": "null"}}