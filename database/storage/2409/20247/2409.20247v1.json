{"2409.20247": {"publish_time": "2024-09-30", "title": "Resource Allocation for Stable LLM Training in Mobile Edge Computing", "paper_summary": "As mobile devices increasingly become focal points for advanced applications,\nedge computing presents a viable solution to their inherent computational\nlimitations, particularly in deploying large language models (LLMs). However,\ndespite the advancements in edge computing, significant challenges remain in\nefficient training and deploying LLMs due to the computational demands and data\nprivacy concerns associated with these models. This paper explores a\ncollaborative training framework that integrates mobile users with edge servers\nto optimize resource allocation, thereby enhancing both performance and\nefficiency. Our approach leverages parameter-efficient fine-tuning (PEFT)\nmethods, allowing mobile users to adjust the initial layers of the LLM while\nedge servers handle the more demanding latter layers. Specifically, we\nformulate a multi-objective optimization problem to minimize the total energy\nconsumption and delay during training. We also address the common issue of\ninstability in model performance by incorporating stability enhancements into\nour objective function. Through novel fractional programming technique, we\nachieve a stationary point for the formulated problem. Simulations demonstrate\nthat our method reduces the energy consumption as well as the latency, and\nincreases the reliability of LLMs across various mobile settings.", "paper_summary_zh": "\u96a8\u8457\u884c\u52d5\u88dd\u7f6e\u65e5\u76ca\u6210\u70ba\u9032\u968e\u61c9\u7528\u7a0b\u5f0f\u7684\u91cd\u9ede\uff0c\n\u908a\u7de3\u904b\u7b97\u70ba\u5176\u56fa\u6709\u7684\u904b\u7b97\u9650\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u7279\u5225\u662f\u5728\u90e8\u7f72\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6642\u3002\u7136\u800c\uff0c\u5118\u7ba1\u908a\u7de3\u904b\u7b97\u6709\u9032\u5c55\uff0c\u7531\u65bc\u9019\u4e9b\u6a21\u578b\u76f8\u95dc\u7684\u904b\u7b97\u9700\u6c42\u548c\u8cc7\u6599\u96b1\u79c1\u554f\u984c\uff0c\u5728\u8a13\u7df4\u548c\u90e8\u7f72 LLM \u6642\u4ecd\u6709\u91cd\u5927\u7684\u6311\u6230\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u4e00\u500b\u5354\u4f5c\u8a13\u7df4\u67b6\u69cb\uff0c\u5c07\u884c\u52d5\u88dd\u7f6e\u4f7f\u7528\u8005\u8207\u908a\u7de3\u4f3a\u670d\u5668\u6574\u5408\uff0c\u4ee5\u6700\u4f73\u5316\u8cc7\u6e90\u914d\u7f6e\uff0c\u9032\u800c\u63d0\u5347\u6548\u80fd\u548c\u6548\u7387\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u4e86\u53c3\u6578\u6709\u6548\u5fae\u8abf (PEFT) \u65b9\u6cd5\uff0c\u8b93\u884c\u52d5\u88dd\u7f6e\u4f7f\u7528\u8005\u8abf\u6574 LLM \u7684\u521d\u59cb\u5c64\uff0c\u800c\u908a\u7de3\u4f3a\u670d\u5668\u5247\u8655\u7406\u8981\u6c42\u8f03\u9ad8\u7684\u5f8c\u7e8c\u5c64\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5236\u5b9a\u4e86\u4e00\u500b\u591a\u76ee\u6a19\u6700\u4f73\u5316\u554f\u984c\uff0c\u4ee5\u6700\u5c0f\u5316\u8a13\u7df4\u671f\u9593\u7684\u7e3d\u80fd\u8017\u548c\u5ef6\u9072\u3002\u6211\u5011\u4e5f\u900f\u904e\u5c07\u7a69\u5b9a\u6027\u5f37\u5316\u7d0d\u5165\u6211\u5011\u7684\u76ee\u6a19\u51fd\u6578\uff0c\u4f86\u89e3\u6c7a\u6a21\u578b\u6548\u80fd\u4e0d\u7a69\u5b9a\u7684\u5e38\u898b\u554f\u984c\u3002\u900f\u904e\u5275\u65b0\u7684\u5206\u6578\u898f\u5283\u6280\u8853\uff0c\u6211\u5011\u70ba\u5236\u5b9a\u7684\u554f\u984c\u9054\u5230\u4e86\u5e73\u7a69\u9ede\u3002\u6a21\u64ec\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u505a\u6cd5\u6e1b\u5c11\u4e86\u80fd\u8017\u548c\u5ef6\u9072\uff0c\u4e26\u63d0\u9ad8\u4e86 LLM \u5728\u5404\u7a2e\u884c\u52d5\u88dd\u7f6e\u8a2d\u5b9a\u4e2d\u7684\u53ef\u9760\u6027\u3002", "author": "Chang Liu et.al.", "authors": "Chang Liu, Jun Zhao", "id": "2409.20247v1", "paper_url": "http://arxiv.org/abs/2409.20247v1", "repo": "null"}}