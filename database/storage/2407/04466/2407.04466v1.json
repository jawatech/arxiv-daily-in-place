{"2407.04466": {"publish_time": "2024-07-05", "title": "Using LLMs to label medical papers according to the CIViC evidence model", "paper_summary": "We introduce the sequence classification problem CIViC Evidence to the field\nof medical NLP. CIViC Evidence denotes the multi-label classification problem\nof assigning labels of clinical evidence to abstracts of scientific papers\nwhich have examined various combinations of genomic variants, cancer types, and\ntreatment approaches. We approach CIViC Evidence using different language\nmodels: We fine-tune pretrained checkpoints of BERT and RoBERTa on the CIViC\nEvidence dataset and challenge their performance with models of the same\narchitecture which have been pretrained on domain-specific text. In this\ncontext, we find that BiomedBERT and BioLinkBERT can outperform BERT on CIViC\nEvidence (+0.8% and +0.9% absolute improvement in class-support weighted F1\nscore). All transformer-based models show a clear performance edge when\ncompared to a logistic regression trained on bigram tf-idf scores (+1.5 - 2.7%\nimproved F1 score). We compare the aforementioned BERT-like models to OpenAI's\nGPT-4 in a few-shot setting (on a small subset of our original test dataset),\ndemonstrating that, without additional prompt-engineering or fine-tuning, GPT-4\nperforms worse on CIViC Evidence than our six fine-tuned models (66.1% weighted\nF1 score compared to 71.8% for the best fine-tuned model). However, performance\ngets reasonably close to the benchmark of a logistic regression model trained\non bigram tf-idf scores (67.7% weighted F1 score).", "paper_summary_zh": "<paragraph>\u6211\u5011\u5c07\u5e8f\u5217\u5206\u985e\u554f\u984c CIViC Evidence \u5f15\u5165\u91ab\u5b78 NLP \u9818\u57df\u3002CIViC Evidence \u8868\u793a\u5c07\u81e8\u5e8a\u8b49\u64da\u6a19\u7c64\u6307\u6d3e\u7d66\u5df2\u6aa2\u67e5\u904e\u5404\u7a2e\u57fa\u56e0\u7d44\u8b8a\u7570\u3001\u764c\u75c7\u985e\u578b\u548c\u6cbb\u7642\u65b9\u6cd5\u7684\u79d1\u5b78\u8ad6\u6587\u6458\u8981\u7684\u591a\u6a19\u7c64\u5206\u985e\u554f\u984c\u3002\u6211\u5011\u4f7f\u7528\u4e0d\u540c\u7684\u8a9e\u8a00\u6a21\u578b\u4f86\u8655\u7406 CIViC Evidence\uff1a\u6211\u5011\u5fae\u8abf BERT \u548c RoBERTa \u7684\u9810\u8a13\u7df4\u6aa2\u67e5\u9ede\uff0c\u4e26\u4f7f\u7528\u5728\u7279\u5b9a\u9818\u57df\u6587\u672c\u4e0a\u9810\u8a13\u7df4\u7684\u76f8\u540c\u67b6\u69cb\u6a21\u578b\u6311\u6230\u5b83\u5011\u7684\u6548\u80fd\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u6211\u5011\u767c\u73fe BiomedBERT \u548c BioLinkBERT \u53ef\u4ee5\u512a\u65bc BERT \u5728 CIViC Evidence \u4e0a\u7684\u8868\u73fe\uff08\u985e\u5225\u652f\u63f4\u52a0\u6b0a F1 \u5206\u6578\u7d55\u5c0d\u6539\u5584 +0.8% \u548c +0.9%\uff09\u3002\u8207\u5728\u4e8c\u5143\u8a5e\u7d44 tf-idf \u5206\u6578\u4e0a\u8a13\u7df4\u7684\u908f\u8f2f\u8ff4\u6b78\u76f8\u6bd4\uff0c\u6240\u6709\u57fa\u65bc Transformer \u7684\u6a21\u578b\u90fd\u986f\u793a\u51fa\u660e\u986f\u7684\u6548\u80fd\u512a\u52e2\uff08\u6539\u5584 F1 \u5206\u6578 +1.5 - 2.7%\uff09\u3002\u6211\u5011\u5728\u4e00\u500b\u5c0f\u7bc4\u570d\u8a2d\u5b9a\uff08\u5728\u6211\u5011\u539f\u59cb\u6e2c\u8a66\u8cc7\u6599\u96c6\u7684\u4e00\u500b\u5c0f\u90e8\u5206\u4e0a\uff09\u4e2d\u6bd4\u8f03\u524d\u8ff0\u985e BERT \u6a21\u578b\u8207 OpenAI \u7684 GPT-4\uff0c\u8b49\u660e\u5728\u6c92\u6709\u984d\u5916\u7684\u63d0\u793a\u5de5\u7a0b\u6216\u5fae\u8abf\u7684\u60c5\u6cc1\u4e0b\uff0cGPT-4 \u5728 CIViC Evidence \u4e0a\u7684\u8868\u73fe\u6bd4\u6211\u5011\u516d\u500b\u5fae\u8abf\u6a21\u578b\u5dee\uff08\u52a0\u6b0a F1 \u5206\u6578\u70ba 66.1%\uff0c\u800c\u6700\u4f73\u5fae\u8abf\u6a21\u578b\u70ba 71.8%\uff09\u3002\u7136\u800c\uff0c\u6548\u80fd\u76f8\u7576\u63a5\u8fd1\u5728\u4e8c\u5143\u8a5e\u7d44 tf-idf \u5206\u6578\u4e0a\u8a13\u7df4\u7684\u908f\u8f2f\u8ff4\u6b78\u6a21\u578b\u7684\u57fa\u6e96\uff08\u52a0\u6b0a F1 \u5206\u6578\u70ba 67.7%\uff09\u3002</paragraph>", "author": "Markus Hisch et.al.", "authors": "Markus Hisch, Xing David Wang", "id": "2407.04466v1", "paper_url": "http://arxiv.org/abs/2407.04466v1", "repo": "null"}}