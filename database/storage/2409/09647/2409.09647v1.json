{"2409.09647": {"publish_time": "2024-09-15", "title": "Self-supervised Learning for Acoustic Few-Shot Classification", "paper_summary": "Labelled data are limited and self-supervised learning is one of the most\nimportant approaches for reducing labelling requirements. While it has been\nextensively explored in the image domain, it has so far not received the same\namount of attention in the acoustic domain. Yet, reducing labelling is a key\nrequirement for many acoustic applications. Specifically in bioacoustic, there\nare rarely sufficient labels for fully supervised learning available. This has\nled to the widespread use of acoustic recognisers that have been pre-trained on\nunrelated data for bioacoustic tasks. We posit that training on the actual task\ndata and combining self-supervised pre-training with few-shot classification is\na superior approach that has the ability to deliver high accuracy even when\nonly a few labels are available. To this end, we introduce and evaluate a new\narchitecture that combines CNN-based preprocessing with feature extraction\nbased on state space models (SSMs). This combination is motivated by the fact\nthat CNN-based networks alone struggle to capture temporal information\neffectively, which is crucial for classifying acoustic signals. SSMs,\nspecifically S4 and Mamba, on the other hand, have been shown to have an\nexcellent ability to capture long-range dependencies in sequence data. We\npre-train this architecture using contrastive learning on the actual task data\nand subsequent fine-tuning with an extremely small amount of labelled data. We\nevaluate the performance of this proposed architecture for ($n$-shot,\n$n$-class) classification on standard benchmarks as well as real-world data.\nOur evaluation shows that it outperforms state-of-the-art architectures on the\nfew-shot classification problem.", "paper_summary_zh": "<paragraph>\u6a19\u7c64\u8cc7\u6599\u6709\u9650\uff0c\u800c\u81ea\u76e3\u7763\u5b78\u7fd2\u662f\u6e1b\u5c11\u6a19\u7c64\u9700\u6c42\u6700\u91cd\u8981\u7684\u9014\u5f91\u4e4b\u4e00\u3002\u96d6\u7136\u5b83\u5df2\u5728\u5f71\u50cf\u9818\u57df\u5ee3\u6cdb\u63a2\u7d22\uff0c\u4f46\u5230\u76ee\u524d\u70ba\u6b62\uff0c\u5728\u8072\u5b78\u9818\u57df\u5c1a\u672a\u7372\u5f97\u76f8\u540c\u7684\u95dc\u6ce8\u3002\u7136\u800c\uff0c\u6e1b\u5c11\u6a19\u7c64\u662f\u8a31\u591a\u8072\u5b78\u61c9\u7528\u7684\u4e00\u9805\u95dc\u9375\u9700\u6c42\u3002\u7279\u5225\u662f\u5728\u751f\u7269\u8072\u5b78\u4e2d\uff0c\u5f88\u5c11\u6709\u8db3\u5920\u7684\u6a19\u7c64\u53ef\u4f9b\u5b8c\u5168\u76e3\u7763\u5b78\u7fd2\u4f7f\u7528\u3002\u9019\u5c0e\u81f4\u5ee3\u6cdb\u4f7f\u7528\u8072\u5b78\u8fa8\u8b58\u5668\uff0c\u9019\u4e9b\u8fa8\u8b58\u5668\u5df2\u91dd\u5c0d\u751f\u7269\u8072\u5b78\u4efb\u52d9\u5728\u4e0d\u76f8\u95dc\u8cc7\u6599\u4e0a\u9032\u884c\u9810\u8a13\u7df4\u3002\u6211\u5011\u5047\u8a2d\u5728\u5be6\u969b\u4efb\u52d9\u8cc7\u6599\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u4e26\u5c07\u81ea\u76e3\u7763\u9810\u8a13\u7df4\u8207\u5c11\u6a23\u672c\u5206\u985e\u76f8\u7d50\u5408\uff0c\u662f\u4e00\u7a2e\u512a\u8d8a\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u53ea\u6709\u5c11\u6578\u6a19\u7c64\u53ef\u7528\uff0c\u4e5f\u80fd\u63d0\u4f9b\u9ad8\u6e96\u78ba\u5ea6\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e26\u8a55\u4f30\u4e86\u4e00\u7a2e\u65b0\u7684\u67b6\u69cb\uff0c\u5b83\u7d50\u5408\u4e86\u57fa\u65bc CNN \u7684\u9810\u8655\u7406\u8207\u57fa\u65bc\u72c0\u614b\u7a7a\u9593\u6a21\u578b (SSM) \u7684\u7279\u5fb5\u8403\u53d6\u3002\u9019\u7a2e\u7d50\u5408\u7684\u52d5\u6a5f\u5728\u65bc\uff0c\u50c5\u57fa\u65bc CNN \u7684\u7db2\u8def\u96e3\u4ee5\u6709\u6548\u64f7\u53d6\u6642\u9593\u8cc7\u8a0a\uff0c\u800c\u9019\u5c0d\u65bc\u5206\u985e\u8072\u5b78\u8a0a\u865f\u81f3\u95dc\u91cd\u8981\u3002\u53e6\u4e00\u65b9\u9762\uff0cSSM\uff0c\u7279\u5225\u662f S4 \u548c Mamba\uff0c\u5df2\u88ab\u8b49\u660e\u5177\u6709\u64f7\u53d6\u5e8f\u5217\u8cc7\u6599\u4e2d\u9577\u7a0b\u4f9d\u8cf4\u6027\u7684\u51fa\u8272\u80fd\u529b\u3002\u6211\u5011\u4f7f\u7528\u5c0d\u6bd4\u5b78\u7fd2\u5728\u5be6\u969b\u4efb\u52d9\u8cc7\u6599\u4e0a\u9810\u8a13\u7df4\u6b64\u67b6\u69cb\uff0c\u4e26\u96a8\u5f8c\u4f7f\u7528\u6975\u5c11\u91cf\u6a19\u7c64\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u3002\u6211\u5011\u8a55\u4f30\u4e86\u6b64\u63d0\u8b70\u67b6\u69cb\u5728\u6a19\u6e96\u57fa\u6e96\u6e2c\u8a66\u548c\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u4e0a\u7684 ($n$-\u6a23\u672c\uff0c$n$-\u985e\u5225) \u5206\u985e\u6548\u80fd\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u5b83\u5728\u5c11\u6a23\u672c\u5206\u985e\u554f\u984c\u4e0a\u512a\u65bc\u6700\u5148\u9032\u7684\u67b6\u69cb\u3002</paragraph>", "author": "Jingyong Liang et.al.", "authors": "Jingyong Liang, Bernd Meyer, Issac Ning Lee, Thanh-Toan Do", "id": "2409.09647v1", "paper_url": "http://arxiv.org/abs/2409.09647v1", "repo": "null"}}