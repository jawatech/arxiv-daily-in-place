{"2411.05451": {"publish_time": "2024-11-08", "title": "WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models", "paper_summary": "Recent advancements in large language models (LLMs) have driven a\nrevolutionary paradigm shift in process automation from Robotic Process\nAutomation to Agentic Process Automation by automating the workflow\norchestration procedure based on LLMs. However, existing LLMs (even the\nadvanced OpenAI GPT-4o) are confined to achieving satisfactory capability in\nworkflow orchestration. To address this limitation, we present WorkflowLLM, a\ndata-centric framework elaborately designed to enhance the capability of LLMs\nin workflow orchestration. It first constructs a large-scale fine-tuning\ndataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83\napplications across 28 categories. Specifically, the construction process can\nbe divided into three phases: (1) Data Collection: we collect real-world\nworkflow data from Apple Shortcuts and RoutineHub, transcribing them into\nPython-style code. We further equip them with generated hierarchical thought\nvia ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task\nqueries to enrich the diversity and complexity of workflows. (3) Workflow\nGeneration: we leverage an annotator model trained on collected data to\ngenerate workflows for synthesized queries. Finally, we merge the synthetic\nsamples that pass quality confirmation with the collected samples to obtain the\nWorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain\nWorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong\ncapacity to orchestrate complex workflows, while also achieving notable\ngeneralization performance on previously unseen APIs. Additionally,\nWorkflowBench exhibits robust zero-shot generalization capabilities on an\nout-of-distribution task planning dataset, T-Eval. Our data and code are\navailable at https://github.com/OpenBMB/WorkflowLLM.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u63a8\u52d5\u4e86\u6d41\u7a0b\u81ea\u52d5\u5316\u7684\u9769\u547d\u6027\u5178\u7bc4\u8f49\u79fb\uff0c\u5f9e\u6a5f\u5668\u4eba\u6d41\u7a0b\u81ea\u52d5\u5316\u5230\u4ee3\u7406\u6d41\u7a0b\u81ea\u52d5\u5316\uff0c\u900f\u904e\u57fa\u65bc LLM \u81ea\u52d5\u5316\u5de5\u4f5c\u6d41\u7a0b\u7de8\u6392\u7a0b\u5e8f\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 LLM\uff08\u751a\u81f3\u9032\u968e\u7684 OpenAI GPT-4o\uff09\u50c5\u9650\u65bc\u5728\u5de5\u4f5c\u6d41\u7a0b\u7de8\u6392\u4e2d\u5be6\u73fe\u4ee4\u4eba\u6eff\u610f\u7684\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 WorkflowLLM\uff0c\u4e00\u500b\u7cbe\u5fc3\u8a2d\u8a08\u7684\u4ee5\u6578\u64da\u70ba\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u7528\u65bc\u589e\u5f37 LLM \u5728\u5de5\u4f5c\u6d41\u7a0b\u7de8\u6392\u4e2d\u7684\u80fd\u529b\u3002\u5b83\u9996\u5148\u69cb\u5efa\u4e00\u500b\u5305\u542b 106,763 \u500b\u7bc4\u4f8b\u7684\u5927\u898f\u6a21\u5fae\u8abf\u8cc7\u6599\u96c6 WorkflowBench\uff0c\u6db5\u84cb\u4f86\u81ea 28 \u500b\u985e\u5225\u7684 83 \u500b\u61c9\u7528\u7a0b\u5f0f\u7684 1,503 \u500b API\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u69cb\u5efa\u904e\u7a0b\u53ef\u5206\u70ba\u4e09\u500b\u968e\u6bb5\uff1a(1) \u6578\u64da\u6536\u96c6\uff1a\u6211\u5011\u5f9e Apple Shortcuts \u548c RoutineHub \u6536\u96c6\u771f\u5be6\u4e16\u754c\u7684\u6d41\u7a0b\u6578\u64da\uff0c\u4e26\u5c07\u5b83\u5011\u8f49\u9304\u6210 Python \u98a8\u683c\u7684\u7a0b\u5f0f\u78bc\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e ChatGPT \u751f\u6210\u7684\u968e\u5c64\u5f0f\u601d\u8003\u4f86\u88dd\u5099\u5b83\u5011\u3002(2) \u67e5\u8a62\u64f4\u5145\uff1a\u6211\u5011\u63d0\u793a ChatGPT \u7522\u751f\u66f4\u591a\u4efb\u52d9\u67e5\u8a62\uff0c\u4ee5\u8c50\u5bcc\u5de5\u4f5c\u6d41\u7a0b\u7684\u591a\u6a23\u6027\u548c\u8907\u96dc\u6027\u3002(3) \u5de5\u4f5c\u6d41\u7a0b\u7522\u751f\uff1a\u6211\u5011\u5229\u7528\u5728\u6536\u96c6\u7684\u6578\u64da\u4e0a\u8a13\u7df4\u7684\u8a3b\u89e3\u5668\u6a21\u578b\uff0c\u70ba\u5408\u6210\u7684\u67e5\u8a62\u7522\u751f\u5de5\u4f5c\u6d41\u7a0b\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c07\u901a\u904e\u54c1\u8cea\u78ba\u8a8d\u7684\u5408\u6210\u7bc4\u4f8b\u8207\u6536\u96c6\u7684\u7bc4\u4f8b\u5408\u4f75\uff0c\u4ee5\u53d6\u5f97 WorkflowBench\u3002\u6839\u64da WorkflowBench\uff0c\u6211\u5011\u5fae\u8abf Llama-3.1-8B \u4ee5\u53d6\u5f97 WorkflowLlama\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0cWorkflowLlama \u5c55\u793a\u51fa\u7de8\u6392\u8907\u96dc\u5de5\u4f5c\u6d41\u7a0b\u7684\u5f37\u5927\u80fd\u529b\uff0c\u540c\u6642\u5728\u4ee5\u524d\u672a\u898b\u7684 API \u4e0a\u5be6\u73fe\u986f\u8457\u7684\u6cdb\u5316\u6548\u80fd\u3002\u6b64\u5916\uff0cWorkflowBench \u5728 out-of-distribution \u4efb\u52d9\u898f\u5283\u8cc7\u6599\u96c6 T-Eval \u4e0a\u5c55\u73fe\u4e86\u5f37\u5065\u7684\u96f6\u6b21\u5b78\u7fd2\u6cdb\u5316\u80fd\u529b\u3002\u6211\u5011\u7684\u6578\u64da\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/OpenBMB/WorkflowLLM \u53d6\u5f97\u3002", "author": "Shengda Fan et.al.", "authors": "Shengda Fan, Xin Cong, Yuepeng Fu, Zhong Zhang, Shuyan Zhang, Yuanwei Liu, Yesai Wu, Yankai Lin, Zhiyuan Liu, Maosong Sun", "id": "2411.05451v1", "paper_url": "http://arxiv.org/abs/2411.05451v1", "repo": "https://github.com/openbmb/workflowllm"}}