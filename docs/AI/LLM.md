
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-21**|**A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick**|Nishant Balepur et.al.|[2406.15352v1](http://arxiv.org/abs/2406.15352v1)|null|
|**2024-06-21**|**Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**|Chengzhe Piao et.al.|[2406.15346v1](http://arxiv.org/abs/2406.15346v1)|[link](https://github.com/chengzhepiao/coldstartbglp)|
|**2024-06-21**|**GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians**|Haoyang Liu et.al.|[2406.15341v1](http://arxiv.org/abs/2406.15341v1)|[link](https://github.com/liu-hy/genotex)|
|**2024-06-21**|**Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning**|Brandon Huang et.al.|[2406.15334v1](http://arxiv.org/abs/2406.15334v1)|null|
|**2024-06-21**|**Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance**|Haoling Li et.al.|[2406.15330v1](http://arxiv.org/abs/2406.15330v1)|null|
|**2024-06-21**|**An End-to-End, Segmentation-Free, Arabic Handwritten Recognition Model on KHATT**|Sondos Aabed et.al.|[2406.15329v1](http://arxiv.org/abs/2406.15329v1)|null|
|**2024-06-21**|**Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks**|Hokyung Lee et.al.|[2406.15325v1](http://arxiv.org/abs/2406.15325v1)|null|
|**2024-06-21**|**LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs**|Ziyan Jiang et.al.|[2406.15319v1](http://arxiv.org/abs/2406.15319v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v1](http://arxiv.org/abs/2406.15294v1)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Grants4Companies: Applying Declarative Methods for Recommending and Reasoning About Business Grants in the Austrian Public Administration (System Description)**|Björn Lellmann et.al.|[2406.15293v1](http://arxiv.org/abs/2406.15293v1)|null|
|**2024-06-21**|**The Greek podcast corpus: Competitive speech models for low-resourced languages with weakly supervised data**|Georgios Paraskevopoulos et.al.|[2406.15284v1](http://arxiv.org/abs/2406.15284v1)|null|
|**2024-06-21**|**Cross-Modality Safety Alignment**|Siyin Wang et.al.|[2406.15279v1](http://arxiv.org/abs/2406.15279v1)|[link](https://github.com/sinwang20/siuo)|
|**2024-06-21**|**Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model**|Doyoung Kim et.al.|[2406.15275v1](http://arxiv.org/abs/2406.15275v1)|null|
|**2024-06-21**|**Towards Robust Training Datasets for Machine Learning with Ontologies: A Case Study for Emergency Road Vehicle Detection**|Lynn Vonderhaar et.al.|[2406.15268v1](http://arxiv.org/abs/2406.15268v1)|null|
|**2024-06-21**|**Evaluating Diversity in Automatic Poetry Generation**|Yanran Chen et.al.|[2406.15267v1](http://arxiv.org/abs/2406.15267v1)|null|
|**2024-06-21**|**Perception of Phonological Assimilation by Neural Speech Recognition Models**|Charlotte Pouw et.al.|[2406.15265v1](http://arxiv.org/abs/2406.15265v1)|null|
|**2024-06-21**|**Towards Fine-Grained Citation Evaluation in Generated Text: A Comparative Analysis of Faithfulness Metrics**|Weijia Zhang et.al.|[2406.15264v1](http://arxiv.org/abs/2406.15264v1)|null|
|**2024-06-21**|**V-RECS, a Low-Cost LLM4VIS Recommender with Explanations, Captioning and Suggestions**|Luca Podo et.al.|[2406.15259v1](http://arxiv.org/abs/2406.15259v1)|null|
|**2024-06-21**|**MantisScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation**|Xuan He et.al.|[2406.15252v1](http://arxiv.org/abs/2406.15252v1)|null|
|**2024-06-21**|**Unsupervised Morphological Tree Tokenizer**|Qingyang Zhu et.al.|[2406.15245v1](http://arxiv.org/abs/2406.15245v1)|null|
|**2024-06-21**|**Detecting Synthetic Lyrics with Few-Shot Inference**|Yanis Labrak et.al.|[2406.15231v1](http://arxiv.org/abs/2406.15231v1)|null|
|**2024-06-21**|**A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation**|Irune Zubiaga et.al.|[2406.15227v1](http://arxiv.org/abs/2406.15227v1)|null|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Injecting Bias in Text-To-Image Models via Composite-Trigger Backdoors**|Ali Naseh et.al.|[2406.15213v1](http://arxiv.org/abs/2406.15213v1)|null|
|**2024-06-21**|**Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**|Santiago Berrezueta-Guzman et.al.|[2406.15198v1](http://arxiv.org/abs/2406.15198v1)|null|
|**2024-06-21**|**Reward Steering with Evolutionary Heuristics for Decoding-time Alignment**|Chia-Yu Hung et.al.|[2406.15193v1](http://arxiv.org/abs/2406.15193v1)|null|
|**2024-06-21**|**UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis**|Yulong Hui et.al.|[2406.15187v1](http://arxiv.org/abs/2406.15187v1)|[link](https://github.com/qinchuanhui/uda-benchmark)|
|**2024-06-21**|**Hybrid Alignment Training for Large Language Models**|Chenglong Wang et.al.|[2406.15178v1](http://arxiv.org/abs/2406.15178v1)|null|
|**2024-06-21**|**Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss**|Wei He et.al.|[2406.15175v1](http://arxiv.org/abs/2406.15175v1)|null|
|**2024-06-21**|**Évaluation des capacités de réponse de larges modèles de langage (LLM) pour des questions d'historiens**|Mathieu Chartier et.al.|[2406.15173v1](http://arxiv.org/abs/2406.15173v1)|null|
|**2024-06-21**|**This actually looks like that: Proto-BagNets for local and global interpretability-by-design**|Kerol Djoumessi et.al.|[2406.15168v1](http://arxiv.org/abs/2406.15168v1)|[link](https://github.com/kdjoumessi/proto-bagnets)|
|**2024-06-21**|**A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis**|Muhammad Imran et.al.|[2406.15163v1](http://arxiv.org/abs/2406.15163v1)|null|
|**2024-06-21**|**Generative Topological Networks**|Alona Levy-Jurgenson et.al.|[2406.15152v1](http://arxiv.org/abs/2406.15152v1)|null|
|**2024-06-21**|**Gaussian Splatting to Real World Flight Navigation Transfer with Liquid Networks**|Alex Quach et.al.|[2406.15149v1](http://arxiv.org/abs/2406.15149v1)|null|
|**2024-06-21**|**Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks**|Victor Hugo Nascimento Rocha et.al.|[2406.15130v1](http://arxiv.org/abs/2406.15130v1)|[link](https://github.com/c4ai/argpt)|
|**2024-06-21**|**A Wavelet Guided Attention Module for Skin Cancer Classification with Gradient-based Feature Fusion**|Ayush Roy et.al.|[2406.15128v1](http://arxiv.org/abs/2406.15128v1)|[link](https://github.com/ayushroy2001/wagf-fusion)|
|**2024-06-21**|**Speech Emotion Recognition under Resource Constraints with Data Distillation**|Yi Chang et.al.|[2406.15119v1](http://arxiv.org/abs/2406.15119v1)|null|
|**2024-06-21**|**FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**|Ayush Roy et.al.|[2406.15117v1](http://arxiv.org/abs/2406.15117v1)|[link](https://github.com/ayushroy2001/fa-net)|
|**2024-06-21**|**A Dual Attention-aided DenseNet-121 for Classification of Glaucoma from Fundus Images**|Soham Chakraborty et.al.|[2406.15113v1](http://arxiv.org/abs/2406.15113v1)|[link](https://github.com/soham2004github/dadgc)|
|**2024-06-21**|**Investigating the impact of 2D gesture representation on co-speech gesture generation**|Teo Guichoux et.al.|[2406.15111v1](http://arxiv.org/abs/2406.15111v1)|null|
|**2024-06-21**|**Brain-Like Language Processing via a Shallow Untrained Multihead Attention Network**|Badr AlKhamissi et.al.|[2406.15109v1](http://arxiv.org/abs/2406.15109v1)|null|
|**2024-06-21**|**A Unified Framework for Input Feature Attribution Analysis**|Jingyi Sun et.al.|[2406.15085v1](http://arxiv.org/abs/2406.15085v1)|null|
|**2024-06-21**|**KnobTree: Intelligent Database Parameter Configuration via Explainable Reinforcement Learning**|Jiahan Chen et.al.|[2406.15073v1](http://arxiv.org/abs/2406.15073v1)|null|
|**2024-06-21**|**Cross-lingual paraphrase identification**|Inessa Fedorova et.al.|[2406.15066v1](http://arxiv.org/abs/2406.15066v1)|null|
|**2024-06-21**|**PARIKSHA : A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data**|Ishaan Watts et.al.|[2406.15053v1](http://arxiv.org/abs/2406.15053v1)|null|
|**2024-06-21**|**Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**|Lin Fan et.al.|[2406.15050v1](http://arxiv.org/abs/2406.15050v1)|null|
|**2024-06-21**|**Harnessing Knowledge Retrieval with Large Language Models for Clinical Report Error Correction**|Jinge Wu et.al.|[2406.15045v1](http://arxiv.org/abs/2406.15045v1)|null|
|**2024-06-21**|**From Overfitting to Robustness: Quantity, Quality, and Variety Oriented Negative Sample Selection in Graph Contrastive Learning**|Adnan Ali et.al.|[2406.15044v1](http://arxiv.org/abs/2406.15044v1)|null|
|**2024-06-21**|**Behaviour Distillation**|Andrei Lupu et.al.|[2406.15042v1](http://arxiv.org/abs/2406.15042v1)|[link](https://github.com/flairox/behaviour-distillation)|
|**2024-06-21**|**GiusBERTo: A Legal Language Model for Personal Data De-identification in Italian Court of Auditors Decisions**|Giulio Salierno et.al.|[2406.15032v1](http://arxiv.org/abs/2406.15032v1)|null|
|**2024-06-21**|**MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens**|Yongqi Fan et.al.|[2406.15019v1](http://arxiv.org/abs/2406.15019v1)|[link](https://github.com/johnny-fans/medodyssey)|
|**2024-06-21**|**Evolution of Rewards for Food and Motor Action by Simulating Birth and Death**|Yuji Kanagawa et.al.|[2406.15016v1](http://arxiv.org/abs/2406.15016v1)|null|
|**2024-06-21**|**GraLMatch: Matching Groups of Entities with Graphs and Language Models**|Fernando De Meer Pardo et.al.|[2406.15015v1](http://arxiv.org/abs/2406.15015v1)|null|
|**2024-06-21**|**RouteFinder: Towards Foundation Models for Vehicle Routing Problems**|Federico Berto et.al.|[2406.15007v1](http://arxiv.org/abs/2406.15007v1)|null|
|**2024-06-21**|**Unveiling the Impact of Multi-Modal Interactions on User Engagement: A Comprehensive Evaluation in AI-driven Conversations**|Lichao Zhang et.al.|[2406.15000v1](http://arxiv.org/abs/2406.15000v1)|null|
|**2024-06-21**|**Disability Representations: Finding Biases in Automatic Image Generation**|Yannis Tevissen et.al.|[2406.14993v1](http://arxiv.org/abs/2406.14993v1)|null|
|**2024-06-21**|**SpreadsheetBench: Towards Challenging Real World Spreadsheet Manipulation**|Zeyao Ma et.al.|[2406.14991v1](http://arxiv.org/abs/2406.14991v1)|null|
|**2024-06-21**|**Introducing the Biomechanics-Function Relationship in Glaucoma: Improved Visual Field Loss Predictions from intraocular pressure-induced Neural Tissue Strains**|Thanadet Chuangsuwanich et.al.|[2406.14988v1](http://arxiv.org/abs/2406.14988v1)|null|
|**2024-06-21**|**Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers**|Manuel Mondal et.al.|[2406.14986v1](http://arxiv.org/abs/2406.14986v1)|null|
|**2024-06-21**|**Human-AI collectives produce the most accurate differential diagnoses**|N. Zöller et.al.|[2406.14981v1](http://arxiv.org/abs/2406.14981v1)|null|
|**2024-06-21**|**Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation**|Yuanjie Lyu et.al.|[2406.14979v1](http://arxiv.org/abs/2406.14979v1)|null|
|**2024-06-21**|**A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems**|Florin Cuconasu et.al.|[2406.14972v1](http://arxiv.org/abs/2406.14972v1)|null|
|**2024-06-21**|**Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging: A Comprehensive Evaluation**|Shamane Siriwardhana et.al.|[2406.14971v1](http://arxiv.org/abs/2406.14971v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v1](http://arxiv.org/abs/2406.14969v1)|null|
|**2024-06-21**|**Unlocking the Global Synergies in Low-Rank Adapters**|Zixi Zhang et.al.|[2406.14956v1](http://arxiv.org/abs/2406.14956v1)|null|
|**2024-06-21**|**ICLEval: Evaluating In-Context Learning Ability of Large Language Models**|Wentong Chen et.al.|[2406.14955v1](http://arxiv.org/abs/2406.14955v1)|[link](https://github.com/yiye3/icleval)|
|**2024-06-21**|**Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**|Guangkun Nie et.al.|[2406.14953v1](http://arxiv.org/abs/2406.14953v1)|null|
|**2024-06-21**|**ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models**|Haiquan Zhao et.al.|[2406.14952v1](http://arxiv.org/abs/2406.14952v1)|[link](https://github.com/haidequanbu/esc-eval)|
|**2024-06-21**|**Towards Retrieval Augmented Generation over Large Video Libraries**|Yannis Tevissen et.al.|[2406.14938v1](http://arxiv.org/abs/2406.14938v1)|null|
|**2024-06-21**|**Autonomous Agents for Collaborative Task under Information Asymmetry**|Wei Liu et.al.|[2406.14928v1](http://arxiv.org/abs/2406.14928v1)|null|
|**2024-06-21**|**LLM2FEA: Discover Novel Designs with Generative Evolutionary Multitasking**|Melvin Wong et.al.|[2406.14917v1](http://arxiv.org/abs/2406.14917v1)|null|
|**2024-06-21**|**MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression**|Tianyu Fu et.al.|[2406.14909v1](http://arxiv.org/abs/2406.14909v1)|[link](https://github.com/thu-nics/moa)|
|**2024-06-21**|**GIEBench: Towards Holistic Evaluation of Group Indentity-based Empathy for Large Language Models**|Leyan Wang et.al.|[2406.14903v1](http://arxiv.org/abs/2406.14903v1)|[link](https://github.com/giebench/giebench)|
|**2024-06-21**|**Safely Learning with Private Data: A Federated Learning Framework for Large Language Model**|JiaYing Zheng et.al.|[2406.14898v1](http://arxiv.org/abs/2406.14898v1)|null|
|**2024-06-21**|**Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition**|Candida M. Greco et.al.|[2406.14894v1](http://arxiv.org/abs/2406.14894v1)|null|
|**2024-06-21**|**Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering**|Zhengliang Shi et.al.|[2406.14891v1](http://arxiv.org/abs/2406.14891v1)|null|
|**2024-06-21**|**InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate Predictions**|Yu Nakagome et.al.|[2406.14890v1](http://arxiv.org/abs/2406.14890v1)|null|
|**2024-06-21**|**InternLM-Law: An Open Source Chinese Legal Large Language Model**|Zhiwei Fei et.al.|[2406.14887v1](http://arxiv.org/abs/2406.14887v1)|null|
|**2024-06-21**|**FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents**|Ruixuan Xiao et.al.|[2406.14884v1](http://arxiv.org/abs/2406.14884v1)|null|
|**2024-06-21**|**OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants**|Jaspreet Ranjit et.al.|[2406.14883v1](http://arxiv.org/abs/2406.14883v1)|null|
|**2024-06-21**|**70B-parameter large language models in Japanese medical question-answering**|Issey Sukeda et.al.|[2406.14882v1](http://arxiv.org/abs/2406.14882v1)|null|
|**2024-06-21**|**Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video**|Zhengbang Yang et.al.|[2406.14877v1](http://arxiv.org/abs/2406.14877v1)|null|
|**2024-06-21**|**I don't trust you (anymore)! -- The effect of students' LLM use on Lecturer-Student-Trust in Higher Education**|Simon Kloker et.al.|[2406.14871v1](http://arxiv.org/abs/2406.14871v1)|null|
|**2024-06-21**|**Direct Multi-Turn Preference Optimization for Language Agents**|Wentao Shi et.al.|[2406.14868v1](http://arxiv.org/abs/2406.14868v1)|null|
|**2024-06-21**|**DistiLRR: Transferring Code Repair for Low-Resource Programming Languages**|Kyle Wong et.al.|[2406.14867v1](http://arxiv.org/abs/2406.14867v1)|[link](https://github.com/kylewong288/distilrr)|
|**2024-06-21**|**AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**|Jonas Dippel et.al.|[2406.14866v1](http://arxiv.org/abs/2406.14866v1)|null|
|**2024-06-21**|**LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models**|Mengdan Zhu et.al.|[2406.14862v1](http://arxiv.org/abs/2406.14862v1)|null|
|**2024-06-21**|**From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking**|Siyuan Wang et.al.|[2406.14859v1](http://arxiv.org/abs/2406.14859v1)|null|
|**2024-06-21**|**Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models**|Jiayu Wang et.al.|[2406.14852v1](http://arxiv.org/abs/2406.14852v1)|null|
|**2024-06-21**|**Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models**|Qi Liu et.al.|[2406.14848v1](http://arxiv.org/abs/2406.14848v1)|[link](https://github.com/liuqi6777/pe_rank)|
|**2024-06-21**|**DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning**|Jingyi Liu et.al.|[2406.14844v1](http://arxiv.org/abs/2406.14844v1)|null|
|**2024-06-21**|**Automated architectural space layout planning using a physics-inspired generative design framework**|Zhipeng Li et.al.|[2406.14840v1](http://arxiv.org/abs/2406.14840v1)|null|
|**2024-06-21**|**ToVo: Toxicity Taxonomy via Voting**|Tinh Son Luong et.al.|[2406.14835v1](http://arxiv.org/abs/2406.14835v1)|null|
|**2024-06-21**|**Efficient Continual Pre-training by Mitigating the Stability Gap**|Yiduo Guo et.al.|[2406.14833v1](http://arxiv.org/abs/2406.14833v1)|null|
|**2024-06-21**|**Is this a bad table? A Closer Look at the Evaluation of Table Generation from Text**|Pritika Ramu et.al.|[2406.14829v1](http://arxiv.org/abs/2406.14829v1)|null|
|**2024-06-21**|**Word Matters: What Influences Domain Adaptation in Summarization?**|Yinghao Li et.al.|[2406.14828v1](http://arxiv.org/abs/2406.14828v1)|null|
|**2024-06-21**|**Self-supervised Brain Lesion Generation for Effective Data Augmentation of Medical Images**|Jiayu Huo et.al.|[2406.14826v1](http://arxiv.org/abs/2406.14826v1)|null|
|**2024-06-21**|**TemPrompt: Multi-Task Prompt Learning for Temporal Relation Extraction in RAG-based Crowdsourcing Systems**|Jing Yang et.al.|[2406.14825v1](http://arxiv.org/abs/2406.14825v1)|null|
|**2024-06-21**|**Latent diffusion models for parameterization and data assimilation of facies-based geomodels**|Guido Di Federico et.al.|[2406.14815v1](http://arxiv.org/abs/2406.14815v1)|null|
|**2024-06-21**|**How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions**|Julia Kharchenko et.al.|[2406.14805v1](http://arxiv.org/abs/2406.14805v1)|null|

#### Abstracts
##### **A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick**
2406.15352v1 by Nishant Balepur, Matthew Shu, Alexander Hoyle, Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Boyd-Graber

Keyword mnemonics are memorable explanations that link new terms to simpler
keywords. Prior works generate mnemonics for students, but they do not guide
models toward mnemonics students prefer and aid learning. We build SMART, a
mnemonic generator trained on feedback from real students learning new terms.
To train SMART, we first fine-tune LLaMA-2 on a curated set of user-written
mnemonics. We then use LLM alignment to enhance SMART: we deploy mnemonics
generated by SMART in a flashcard app to find preferences on mnemonics students
favor. We gather 2684 preferences from 45 students across two types: expressed
(inferred from ratings) and observed (inferred from student learning), yielding
three key findings. First, expressed and observed preferences disagree; what
students think is helpful does not fully capture what is truly helpful. Second,
Bayesian models can synthesize complementary data from multiple preference
types into a single effectiveness signal. SMART is tuned via Direct Preference
Optimization on this signal, which we show resolves ties and missing labels in
the typical method of pairwise comparisons, augmenting data for LLM output
quality gains. Third, mnemonic experts assess SMART as matching GPT-4, at much
lower deployment costs, showing the utility of capturing diverse student
feedback to align LLMs in education.

摘要：關鍵字助記法是將新術語連結到較簡單的關鍵字，以產生令人難忘的解釋。先前的研究會為學生產生助記法，但它們並未引導模型朝向學生偏好的助記法，也未協助學習。我們建構了 SMART，這是一個助記法產生器，經過真實學生學習新術語的回饋訓練。為了訓練 SMART，我們首先在使用者撰寫的助記法精選集上微調 LLaMA-2。然後，我們使用 LLM 對齊來增強 SMART：我們在一個快閃卡應用程式中部署 SMART 產生的助記法，以找出學生偏好的助記法。我們從 45 名學生中收集了 2684 個偏好，分為兩種：表達的（從評分中推斷）和觀察的（從學生學習中推斷），產生三個主要發現。首先，表達的偏好和觀察到的偏好不同；學生認為有幫助的，並不能完全掌握真正有幫助的。其次，貝氏模型可以將來自多種偏好類型的互補資料合成為單一的有效性訊號。SMART 是透過此訊號上的直接偏好最佳化進行調整，我們顯示這會解決成對比較典型方法中的平手和遺失標籤，並擴充資料以獲得 LLM 輸出品質提升。第三，助記法專家評估 SMART 與 GPT-4 相符，但部署成本低得多，顯示出捕捉多樣化的學生回饋以在教育中對齊 LLM 的效用。

##### **Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**
2406.15346v1 by Chengzhe Piao, Taiyu Zhu, Yu Wang, Stephanie E Baldeweg, Paul Taylor, Pantelis Georgiou, Jiahao Sun, Jun Wang, Kezhi Li

Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtain
effective Blood Glucose (BG) prediction models due to the lack of sufficient BG
data from Continuous Glucose Monitoring (CGM), presenting a significant "cold
start" problem in patient care. Utilizing population models to address this
challenge is a potential solution, but collecting patient data for training
population models in a privacy-conscious manner is challenging, especially
given that such data is often stored on personal devices. Considering the
privacy protection and addressing the "cold start" problem in diabetes care, we
propose "GluADFL", blood Glucose prediction by Asynchronous Decentralized
Federated Learning. We compared GluADFL with eight baseline methods using four
distinct T1D datasets, comprising 298 participants, which demonstrated its
superior performance in accurately predicting BG levels for cross-patient
analysis. Furthermore, patients' data might be stored and shared across various
communication networks in GluADFL, ranging from highly interconnected (e.g.,
random, performs the best among others) to more structured topologies (e.g.,
cluster and ring), suitable for various social networks. The asynchronous
training framework supports flexible participation. By adjusting the ratios of
inactive participants, we found it remains stable if less than 70% are
inactive. Our results confirm that GluADFL offers a practical,
privacy-preserving solution for BG prediction in T1D, significantly enhancing
the quality of diabetes management.

摘要：新診斷的 1 型糖尿病 (T1D) 患者由於缺乏來自連續血糖監測 (CGM) 的足夠血糖 (BG) 資料，因此常常難以取得有效的血糖預測模型，這在患者照護中呈現出顯著的「冷啟動」問題。利用族群模型來應對此挑戰是一種潛在的解決方案，但以注重隱私的方式收集患者資料來訓練族群模型具有挑戰性，特別是在此類資料通常儲存在個人裝置中。考量到隱私保護並解決糖尿病照護中的「冷啟動」問題，我們提出「GluADFL」，透過非同步分散式聯合學習來預測血糖。我們使用四個不同的 T1D 資料集（包含 298 位參與者）將 GluADFL 與八種基準方法進行比較，這證明了其在準確預測跨患者分析的 BG 值方面的優異效能。此外，患者的資料可能儲存在 GluADFL 中並透過各種通訊網路分享，範圍從高度互連（例如，隨機，在其他網路中表現最佳）到更結構化的拓撲（例如，叢集和環），適用於各種社群網路。非同步訓練架構支援彈性參與。透過調整非活躍參與者的比率，我們發現如果非活躍參與者少於 70%，它仍然保持穩定。我們的結果證實 GluADFL 提供了一個實用的、保護隱私的 T1D BG 預測解決方案，大幅提升了糖尿病管理的品質。

##### **GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians**
2406.15341v1 by Haoyang Liu, Haohan Wang

Recent advancements in machine learning have significantly improved the
identification of disease-associated genes from gene expression datasets.
However, these processes often require extensive expertise and manual effort,
limiting their scalability. Large Language Model (LLM)-based agents have shown
promise in automating these tasks due to their increasing problem-solving
abilities. To support the evaluation and development of such methods, we
introduce GenoTEX, a benchmark dataset for the automatic exploration of gene
expression data, involving the tasks of dataset selection, preprocessing, and
statistical analysis. GenoTEX provides annotated code and results for solving a
wide range of gene identification problems, in a full analysis pipeline that
follows the standard of computational genomics. These annotations are curated
by human bioinformaticians who carefully analyze the datasets to ensure
accuracy and reliability. To provide baselines for these tasks, we present
GenoAgents, a team of LLM-based agents designed with context-aware planning,
iterative correction, and domain expert consultation to collaboratively explore
gene datasets. Our experiments with GenoAgents demonstrate the potential of
LLM-based approaches in genomics data analysis, while error analysis highlights
the challenges and areas for future improvement. We propose GenoTEX as a
promising resource for benchmarking and enhancing AI-driven methods for
genomics data analysis. We make our benchmark publicly available at
\url{https://github.com/Liu-Hy/GenoTex}.

摘要：機器學習最近的進展已大幅提升從基因表現資料集中辨識與疾病相關基因的能力。
然而，這些程序通常需要廣泛的專業知識和手動操作，限制了它們的可擴充性。大型語言模型 (LLM) 基礎代理已展現出自動化這些任務的潛力，因為它們的問題解決能力日益提升。為了支援此類方法的評估和開發，我們引入了 GenoTEX，這是一個基準資料集，用於自動探索基因表現資料，涉及資料集選取、前處理和統計分析的任務。GenoTEX 提供了註解程式碼和結果，用於解決廣泛的基因辨識問題，並採用遵循計算基因組學標準的完整分析流程。這些註解是由人類生物資訊學家策展的，他們仔細分析資料集以確保準確性和可靠性。為了提供這些任務的基準，我們提出了 GenoAgents，這是一個 LLM 基礎代理團隊，設計時具備情境感知規劃、反覆修正和領域專家諮詢功能，以協作探索基因資料集。我們對 GenoAgents 的實驗展示了 LLM 基礎方法在基因組資料分析中的潛力，而錯誤分析則突顯了挑戰和未來改進的領域。我們提出 GenoTEX 作為一個有前途的資源，用於對基因組資料分析的人工智慧驅動方法進行基準測試和強化。我們在 \url{https://github.com/Liu-Hy/GenoTex} 公開提供我們的基準。

##### **Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning**
2406.15334v1 by Brandon Huang, Chancharik Mitra, Assaf Arbelle, Leonid Karlinsky, Trevor Darrell, Roei Herzig

The recent success of interleaved Large Multimodal Models (LMMs) in few-shot
learning suggests that in-context learning (ICL) with many examples can be
promising for learning new tasks. However, this many-shot multimodal ICL
setting has one crucial problem: it is fundamentally limited by the model's
context length set at pretraining. The problem is especially prominent in the
multimodal domain, which processes both text and images, requiring additional
tokens. This motivates the need for a multimodal method to compress many shots
into fewer tokens without finetuning. In this work, we enable LMMs to perform
multimodal, many-shot in-context learning by leveraging Multimodal Task Vectors
(MTV)--compact implicit representations of in-context examples compressed in
the model's attention heads. Specifically, we first demonstrate the existence
of such MTV in LMMs and then leverage these extracted MTV to enable many-shot
in-context learning for various vision-and-language tasks. Our experiments
suggest that MTV can scale in performance with the number of compressed shots
and generalize to similar out-of-domain tasks without additional context length
for inference.

摘要：最近在少样本學習中交錯的大型多模態模型 (LMM) 取得成功，這表示使用大量範例的脈絡中學習 (ICL) 對於學習新任務而言可能是很有希望的。然而，這種多樣本多模態 ICL 設定有一個關鍵問題：它基本上受到預訓練時設定的模型脈絡長度限制。這個問題在需要處理文字和影像的多模態領域中特別明顯，需要額外的符號。這促使需要一種多模態方法，在不進行微調的情況下將多個樣本壓縮成更少的符號。在這項工作中，我們讓 LMM 能夠執行多模態、多樣本脈絡中學習，方法是利用多模態任務向量 (MTV) - 模型注意力權重中壓縮的脈絡中範例的緊湊隱式表示。具體來說，我們首先證明了 LMM 中存在這種 MTV，然後利用這些提取的 MTV 來讓多樣本脈絡中學習能夠用於各種視覺和語言任務。我們的實驗表明，MTV 可以隨著壓縮樣本的數量而擴展效能，並在沒有額外脈絡長度的情況下泛化到類似的領域外任務以進行推論。

##### **Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance**
2406.15330v1 by Haoling Li, Xin Zhang, Xiao Liu, Yeyun Gong, Yifan Wang, Yujiu Yang, Qi Chen, Peng Cheng

Large language models (LLMs) have revolutionized lots of fields of research.
Although it is well-known that fine-tuning is essential for enhancing the
capabilities of LLMs, existing research suggests that there is potential
redundancy in the fine-tuning process and therefore proposes to update only a
subset of parameters. However, these methods fail to leverage the task-specific
information to identify important parameters during training. Based on the
insight that gradients inherently contain information on task-specific data, we
propose Gradient-Mask Tuning (GMT), a method that selectively updates
parameters during training based on their gradient information. Specifically,
we compute the absolute values of the gradients and apply masking to those with
relatively smaller magnitudes. Our empirical results across various tasks
demonstrate that GMT not only outperforms traditional fine-tuning methods but
also elevates the upper limits of LLM performance. Further analysis indicates
that GMT exhibits insensitivity to mask ratio and possesses computational
efficiency comparable to vanilla SFT.

摘要：大型語言模型 (LLM) 徹底改變了許多研究領域。
儘管眾所周知微調對於提升 LLM 的能力至關重要，但現有研究表明微調過程中存在潛在的冗餘，因此建議僅更新參數子集。然而，這些方法未能利用特定任務的資訊來識別訓練期間的重要參數。基於梯度本質上包含特定任務資料的資訊的見解，我們提出梯度遮罩調整 (GMT)，這是一種在訓練期間根據其梯度資訊選擇性更新參數的方法。具體來說，我們計算梯度的絕對值，並對幅度相對較小的梯度套用遮罩。我們在各種任務中的實證結果表明，GMT 不僅優於傳統的微調方法，而且還提升了 LLM 效能的上限。進一步的分析表明，GMT 對遮罩比例不敏感，並且具有與香草 SFT 相當的運算效率。

##### **An End-to-End, Segmentation-Free, Arabic Handwritten Recognition Model on KHATT**
2406.15329v1 by Sondos Aabed, Ahmad Khairaldin

An end-to-end, segmentation-free, deep learning model trained from scratch is
proposed, leveraging DCNN for feature extraction, alongside Bidirectional
Long-Short Term Memory (BLSTM) for sequence recognition and Connectionist
Temporal Classification (CTC) loss function on the KHATT database. The training
phase yields remarkable results 84% recognition rate on the test dataset at the
character level and 71% on the word level, establishing an image-based sequence
recognition framework that operates without segmentation only at the line
level. The analysis and preprocessing of the KFUPM Handwritten Arabic TexT
(KHATT) database are also presented. Finally, advanced image processing
techniques, including filtering, transformation, and line segmentation are
implemented. The importance of this work is highlighted by its wide-ranging
applications. Including digitizing, documentation, archiving, and text
translation in fields such as banking. Moreover, AHR serves as a pivotal tool
for making images searchable, enhancing information retrieval capabilities, and
enabling effortless editing. This functionality significantly reduces the time
and effort required for tasks such as Arabic data organization and
manipulation.

摘要：<paragraph>提出了一個端到端、無分段的深度學習模型，從頭開始訓練，利用 DCNN 進行特徵提取，同時利用雙向長短期記憶 (BLSTM) 進行序列識別和連接主義時間分類 (CTC) 損失函數在 KHATT 數據庫上。訓練階段在測試數據集上的字元級別和詞彙級別分別產生了顯著的 84% 識別率和 71%，建立了一個僅在行級別操作而無需分段的基於圖像的序列識別框架。還介紹了 KFUPM 手寫阿拉伯語文本 (KHATT) 數據庫的分析和預處理。最後，實施了先進的圖像處理技術，包括濾波、變換和線段分割。這項工作的意義在於其廣泛的應用。包括銀行等領域的數位化、文件化、歸檔和文本翻譯。此外，AHR 作為一個關鍵工具，可用於使圖像可搜索、增強資訊檢索能力，並實現輕鬆編輯。此功能顯著減少了阿拉伯語數據組織和處理等任務所需的時間和精力。</paragraph>

##### **Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks**
2406.15325v1 by Hokyung Lee, Sumanyu Sharma, Bing Hu

Recent research in Needle-in-a-Haystack (NIAH) benchmarks has explored the
capabilities of Large Language Models (LLMs) in retrieving contextual
information from large text documents. However, as LLMs become increasingly
integrated into software development processes, it is crucial to evaluate their
performance in code-based environments. As LLMs are further developed for
program synthesis, we need to ensure that LLMs can understand syntax and write
syntactically correct code. As a step in ensuring LLMs understand syntax, LLMs
can be evaluated in their ability to find and detect syntax bugs. Our
benchmark, Bug In The Code Stack (BICS), is designed to assess the ability of
LLMs to identify simple syntax bugs within large source code. Our findings
reveal three key insights: (1) code-based environments pose significantly more
challenge compared to text-based environments for retrieval tasks, (2) there is
a substantial performance disparity among different models, and (3) there is a
notable correlation between longer context lengths and performance degradation,
though the extent of this degradation varies between models.

摘要：最近在針頭在草堆（NIAH）基準測試中的研究探索了大型語言模型（LLM）從大型文本文件中檢索上下文資訊的能力。然而，隨著 LLM 愈來愈整合到軟體開發流程中，評估它們在基於程式碼的環境中的效能至關重要。由於 LLM 進一步開發用於程式合成，我們需要確保 LLM 能夠理解語法並撰寫語法正確的程式碼。作為確保 LLM 理解語法的步驟，可以評估 LLM 找出和偵測語法錯誤的能力。我們的基準測試，程式碼堆疊中的錯誤（BICS），旨在評估 LLM 識別大型原始碼中簡單語法錯誤的能力。我們的發現揭示了三個關鍵見解：(1) 與基於文字的環境相比，基於程式碼的環境對檢索任務構成更大的挑戰，(2) 不同模型之間存在顯著的效能差異，以及 (3) 較長的上下文長度和效能下降之間存在顯著相關性，雖然這種下降的程度在不同模型之間有所不同。

##### **LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs**
2406.15319v1 by Ziyan Jiang, Xueguang Ma, Wenhu Chen

In traditional RAG framework, the basic retrieval units are normally short.
The common retrievers like DPR normally work with 100-word Wikipedia
paragraphs. Such a design forces the retriever to search over a large corpus to
find the `needle' unit. In contrast, the readers only need to extract answers
from the short retrieved units. Such an imbalanced `heavy' retriever and
`light' reader design can lead to sub-optimal performance. In order to
alleviate the imbalance, we propose a new framework LongRAG, consisting of a
`long retriever' and a `long reader'. LongRAG processes the entire Wikipedia
into 4K-token units, which is 30x longer than before. By increasing the unit
size, we significantly reduce the total units from 22M to 700K. This
significantly lowers the burden of retriever, which leads to a remarkable
retrieval score: answer recall@1=71% on NQ (previously 52%) and answer
recall@2=72% (previously 47%) on HotpotQA (full-wiki). Then we feed the top-k
retrieved units ($\approx$ 30K tokens) to an existing long-context LLM to
perform zero-shot answer extraction. Without requiring any training, LongRAG
achieves an EM of 62.7% on NQ, which is the best known result. LongRAG also
achieves 64.3% on HotpotQA (full-wiki), which is on par of the SoTA model. Our
study offers insights into the future roadmap for combining RAG with
long-context LLMs.

摘要：在傳統的 RAG 框架中，基本的檢索單元通常很短。
像 DPR 這樣的常見檢索器通常處理 100 字的維基百科段落。
這種設計迫使檢索器在大型語料庫中搜尋以找到「針頭」單元。
相反地，讀者只需要從檢索到的短單元中提取答案。
這種不平衡的「重」檢索器和「輕」讀取器設計可能會導致次優的效能。
為了緩解這種不平衡，我們提出了一個新的框架 LongRAG，它由一個「長檢索器」和一個「長讀取器」組成。
LongRAG 將整個維基百科處理成 4K 令牌單元，比以前長 30 倍。
透過增加單元大小，我們將總單元數從 22M 大幅減少到 700K。
這顯著降低了檢索器的負擔，從而產生了顯著的檢索分數：
NQ 上的答案召回率@1=71%（以前為 52%），HotpotQA（全維基）上的答案召回率@2=72%（以前為 47%）。
然後，我們將前 k 個檢索到的單元（大約 30K 個令牌）提供給現有的長語境 LLM，以執行零次學習答案提取。
LongRAG 無需任何訓練，在 NQ 上實現了 62.7% 的 EM，這是已知最好的結果。
LongRAG 在 HotpotQA（全維基）上也達到了 64.3%，這與 SoTA 模型相當。
我們的研究為結合 RAG 與長語境 LLM 的未來路線圖提供了見解。

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v1 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

摘要：科學文獻搜尋通常帶有探索性質，使用者可能尚未熟悉特定領域或概念，但有興趣進一步了解。然而，現有的科學文獻搜尋系統通常針對基於關鍵字的查詢搜尋進行調整，限制了探索的可能性。我們提出 NLP-KG，這是一個功能豐富的系統，旨在支援在不熟悉的自然語言處理 (NLP) 領域探索研究文獻。除了語義搜尋外，NLP-KG 使用者可以輕鬆找到提供特定領域快速入門的調查論文。此外，研究領域階層圖表使用戶能夠熟悉一個領域及其相關領域。最後，聊天介面使用戶可以詢問有關 NLP 中不熟悉概念或特定文章的問題，並取得植基於從科學出版品中擷取的知識的答案。我們的系統為使用者提供全面的探索可能性，支援他們調查不同領域之間的關係，了解 NLP 中不熟悉概念，並找到相關的研究文獻。示範、影片和程式碼可於下列網址取得：https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp。

##### **Grants4Companies: Applying Declarative Methods for Recommending and Reasoning About Business Grants in the Austrian Public Administration (System Description)**
2406.15293v1 by Björn Lellmann, Philipp Marek, Markus Triska

We describe the methods and technologies underlying the application
Grants4Companies. The application uses a logic-based expert system to display a
list of business grants suitable for the logged-in business. To evaluate
suitability of the grants, formal representations of their conditions are
evaluated against properties of the business, taken from the registers of the
Austrian public administration. The logical language for the representations of
the grant conditions is based on S-expressions. We further describe a Proof of
Concept implementation of reasoning over the formalised grant conditions. The
proof of concept is implemented in Common Lisp and interfaces with a reasoning
engine implemented in Scryer Prolog. The application has recently gone live and
is provided as part of the Business Service Portal by the Austrian Federal
Ministry of Finance.

摘要：我們描述了 Grants4Companies 應用程式背後的方法和技術。此應用程式使用基於邏輯的專家系統來顯示適合已登入企業的商業補助清單。為了評估補助金的合適性，會針對從奧地利公共行政機關的登記中取得的企業屬性評估其條件的正式表述。補助金條件表述的邏輯語言是基於 S-expression。我們進一步描述了對形式化補助金條件進行推理的概念驗證實作。概念驗證是以 Common Lisp 實作，並與以 Scryer Prolog 實作的推理引擎介接。此應用程式最近已上線，並由奧地利聯邦財政部提供為商業服務入口網站的一部分。

##### **The Greek podcast corpus: Competitive speech models for low-resourced languages with weakly supervised data**
2406.15284v1 by Georgios Paraskevopoulos, Chara Tsoukala, Athanasios Katsamanis, Vassilis Katsouros

The development of speech technologies for languages with limited digital
representation poses significant challenges, primarily due to the scarcity of
available data. This issue is exacerbated in the era of large, data-intensive
models. Recent research has underscored the potential of leveraging weak
supervision to augment the pool of available data. In this study, we compile an
800-hour corpus of Modern Greek from podcasts and employ Whisper large-v3 to
generate silver transcriptions. This corpus is utilized to fine-tune our
models, aiming to assess the efficacy of this approach in enhancing ASR
performance. Our analysis spans 16 distinct podcast domains, alongside
evaluations on established datasets for Modern Greek. The findings indicate
consistent WER improvements, correlating with increases in both data volume and
model size. Our study confirms that assembling large, weakly supervised corpora
serves as a cost-effective strategy for advancing speech technologies in
under-resourced languages.

摘要：對於數位化表示有限的語言來說，語音技術的發展面臨重大挑戰，這主要是由於可用資料的稀少所致。這個問題在大量資料密集模型的時代更加嚴重。最近的研究強調了利用弱監督來擴充可用資料庫的潛力。在這項研究中，我們從播客中編制了一個 800 小時的現代希臘語語料庫，並使用 Whisper large-v3 來產生銀色轉錄。這個語料庫用於微調我們的模型，目的是評估這種方法在增強 ASR 效能方面的效力。我們的分析涵蓋 16 個不同的播客領域，以及對現代希臘語既有資料集的評估。研究結果顯示 WER 持續改善，與資料量和模型大小的增加相關。我們的研究證實，組建大型、弱監督的語料庫是推進資源不足語言中語音技術的具成本效益策略。

##### **Cross-Modality Safety Alignment**
2406.15279v1 by Siyin Wang, Xingsong Ye, Qinyuan Cheng, Junwen Duan, Shimin Li, Jinlan Fu, Xipeng Qiu, Xuanjing Huang

As Artificial General Intelligence (AGI) becomes increasingly integrated into
various facets of human life, ensuring the safety and ethical alignment of such
systems is paramount. Previous studies primarily focus on single-modality
threats, which may not suffice given the integrated and complex nature of
cross-modality interactions. We introduce a novel safety alignment challenge
called Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safety
alignment. Specifically, it considers cases where single modalities are safe
independently but could potentially lead to unsafe or unethical outputs when
combined. To empirically investigate this problem, we developed the SIUO, a
cross-modality benchmark encompassing 9 critical safety domains, such as
self-harm, illegal activities, and privacy violations. Our findings reveal
substantial safety vulnerabilities in both closed- and open-source LVLMs, such
as GPT-4V and LLaVA, underscoring the inadequacy of current models to reliably
interpret and respond to complex, real-world scenarios.

摘要：隨著人工通用智慧 (AGI) 日益融入人類生活的各個方面，確保此類系統的安全性和道德一致性至關重要。先前的研究主要著重於單一模式的威脅，但這可能不足以應對跨模式互動的整合和複雜性質。我們引入了一個名為「安全輸入但輸出不安全」(SIUO) 的新安全一致性挑戰，以評估跨模式安全一致性。具體來說，它考慮了單一模式獨立安全，但組合時可能會導致不安全或不道德輸出的情況。為了實證研究此問題，我們開發了 SIUO，這是一個跨模式基準測試，涵蓋 9 個關鍵安全領域，例如自殘、非法活動和隱私侵犯。我們的研究結果揭示了閉源和開源 LVLMs（例如 GPT-4V 和 LLaVA）中存在大量安全漏洞，這凸顯了當前模型在可靠地解釋和回應複雜的現實世界場景方面的不足。

##### **Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model**
2406.15275v1 by Doyoung Kim, Jongwon Lee, Jinho Park, Minjoon Seo

Language models have demonstrated impressive capabilities across various
natural language processing tasks, yet they struggle with planning tasks
requiring multi-step simulations. Inspired by human cognitive processes, this
paper investigates the optimal planning power of language models that can
construct a cognitive map of a given environment. Our experiments demonstrate
that cognitive map significantly enhances the performance of both optimal and
reachable planning generation ability in the Gridworld path planning task. We
observe that our method showcases two key characteristics similar to human
cognition: \textbf{generalization of its planning ability to extrapolated
environments and rapid adaptation with limited training data.} We hope our
findings in the Gridworld task provide insights into modeling human cognitive
processes in language models, potentially leading to the development of more
advanced and robust systems that better resemble human cognition.

摘要：語言模型已在各種自然語言處理任務中展現令人印象深刻的能力，但它們在需要多步驟模擬的規劃任務中仍有困難。本文受到人類認知過程的啟發，探討了能夠建構給定環境認知地圖的語言模型的最佳規劃能力。我們的實驗證明，認知地圖顯著提升了網格世界路徑規劃任務中最佳規劃和可達規劃生成能力的表現。我們觀察到，我們的方法展示了兩個與人類認知相似的關鍵特徵：\textbf{將其規劃能力概化到外推環境和利用有限訓練資料快速適應。}我們希望我們在網格世界任務中的發現能為語言模型中的人類認知過程建模提供見解，進而可能導致開發出更進階且穩健的系統，這些系統更能類似人類認知。

##### **Towards Robust Training Datasets for Machine Learning with Ontologies: A Case Study for Emergency Road Vehicle Detection**
2406.15268v1 by Lynn Vonderhaar, Timothy Elvira, Tyler Procko, Omar Ochoa

Countless domains rely on Machine Learning (ML) models, including
safety-critical domains, such as autonomous driving, which this paper focuses
on. While the black box nature of ML is simply a nuisance in some domains, in
safety-critical domains, this makes ML models difficult to trust. To fully
utilize ML models in safety-critical domains, it would be beneficial to have a
method to improve trust in model robustness and accuracy without human experts
checking each decision. This research proposes a method to increase trust in ML
models used in safety-critical domains by ensuring the robustness and
completeness of the model's training dataset. Because ML models embody what
they are trained with, ensuring the completeness of training datasets can help
to increase the trust in the training of ML models. To this end, this paper
proposes the use of a domain ontology and an image quality characteristic
ontology to validate the domain completeness and image quality robustness of a
training dataset. This research also presents an experiment as a proof of
concept for this method, where ontologies are built for the emergency road
vehicle domain.

摘要：無數領域都依賴機器學習 (ML) 模型，包括本文重點關注的自動駕駛等安全關鍵領域。儘管 ML 的黑箱性質在某些領域僅僅是一種麻煩，但在安全關鍵領域，這使得 ML 模型難以讓人信賴。為在安全關鍵領域充分利用 ML 模型，最好有一種方法來提高對模型健壯性和準確性的信賴，而無需人工專家檢查每個決策。本研究提出了一種方法，通過確保模型訓練資料集的健壯性和完整性，來提高對用於安全關鍵領域的 ML 模型的信賴。由於 ML 模型體現了它們的訓練內容，因此確保訓練資料集的完整性有助於提高對 ML 模型訓練的信賴。為此，本文提出了使用領域本体和圖像品質特徵本体來驗證訓練資料集的領域完整性和圖像品質健壯性。本研究還提出了一個實驗作為此方法的概念驗證，其中為緊急道路車輛領域構建了本体。

##### **Evaluating Diversity in Automatic Poetry Generation**
2406.15267v1 by Yanran Chen, Hannes Gröner, Sina Zarrieß, Steffen Eger

Natural Language Generation (NLG), and more generally generative AI, are
among the currently most impactful research fields. Creative NLG, such as
automatic poetry generation, is a fascinating niche in this area. While most
previous research has focused on forms of the Turing test when evaluating
automatic poetry generation - can humans distinguish between automatic and
human generated poetry - we evaluate the diversity of automatically generated
poetry, by comparing distributions of generated poetry to distributions of
human poetry along structural, lexical, semantic and stylistic dimensions,
assessing different model types (word vs. character-level, general purpose LLMs
vs. poetry-specific models), including the very recent LLaMA3, and types of
fine-tuning (conditioned vs. unconditioned). We find that current automatic
poetry systems are considerably underdiverse along multiple dimensions - they
often do not rhyme sufficiently, are semantically too uniform and even do not
match the length distribution of human poetry. Our experiments reveal, however,
that style-conditioning and character-level modeling clearly increases
diversity across virtually all dimensions we explore. Our identified
limitations may serve as the basis for more genuinely diverse future poetry
generation models.

摘要：自然語言生成 (NLG)，更廣泛地說是生成式 AI，是目前影響力最大的研究領域之一。創意 NLG，例如自動詩歌生成，是這個領域中一個迷人的利基市場。雖然大多數先前的研究在評估自動詩歌生成時都專注於圖靈測試的形式 - 人類可以區分自動生成和人類生成的詩歌嗎 - 我們透過將生成詩歌的分布與人類詩歌在結構、詞彙、語義和風格維度的分布進行比較來評估自動生成詩歌的多樣性，評估不同的模型類型（單字與字元層級、通用 LLM 與特定於詩歌的模型），包括最新的 LLaMA3，以及微調類型（條件式與非條件式）。我們發現目前的自動詩歌系統在多個維度上顯著不足 - 它們通常押韻不足、語義過於單調，甚至不符合人類詩歌的長度分佈。然而，我們的實驗表明，風格條件化和字元層級建模顯著增加了我們探索的幾乎所有維度上的多樣性。我們發現的限制可能作為更真實多樣化的未來詩歌生成模型的基礎。

##### **Perception of Phonological Assimilation by Neural Speech Recognition Models**
2406.15265v1 by Charlotte Pouw, Marianne de Heer Kloots, Afra Alishahi, Willem Zuidema

Human listeners effortlessly compensate for phonological changes during
speech perception, often unconsciously inferring the intended sounds. For
example, listeners infer the underlying /n/ when hearing an utterance such as
"clea[m] pan", where [m] arises from place assimilation to the following labial
[p]. This article explores how the neural speech recognition model Wav2Vec2
perceives assimilated sounds, and identifies the linguistic knowledge that is
implemented by the model to compensate for assimilation during Automatic Speech
Recognition (ASR). Using psycholinguistic stimuli, we systematically analyze
how various linguistic context cues influence compensation patterns in the
model's output. Complementing these behavioral experiments, our probing
experiments indicate that the model shifts its interpretation of assimilated
sounds from their acoustic form to their underlying form in its final layers.
Finally, our causal intervention experiments suggest that the model relies on
minimal phonological context cues to accomplish this shift. These findings
represent a step towards better understanding the similarities and differences
in phonological processing between neural ASR models and humans.

摘要：人類聽眾在言語感知過程中毫不費力地彌補音韻變化，通常無意識地推論出預期的聲音。例如，聽眾在聽到「clea[m] pan」這樣的語句時會推論出底層的 /n/，其中 [m] 來自於同化到後面的唇音 [p]。本文探討神經語言識別模型 Wav2Vec2 如何感知同化音，並找出模型在自動語音辨識 (ASR) 期間為彌補同化而實作的語言知識。我們使用心理語言學刺激，系統性地分析各種語言脈絡線索如何影響模型輸出的補償模式。這些行為實驗的補充，我們的探測實驗指出模型在其最後的層次中將其對同化音的詮釋從其音響形式轉換為其底層形式。最後，我們的因果介入實驗建議模型依賴於最小的音韻脈絡線索來完成此轉換。這些發現代表朝著更了解神經 ASR 模型和人類之間在音韻處理上的相似性和差異邁進了一步。

##### **Towards Fine-Grained Citation Evaluation in Generated Text: A Comparative Analysis of Faithfulness Metrics**
2406.15264v1 by Weijia Zhang, Mohammad Aliannejadi, Yifei Yuan, Jiahuan Pei, Jia-Hong Huang, Evangelos Kanoulas

Large language models (LLMs) often produce unsupported or unverifiable
information, known as "hallucinations." To mitigate this, retrieval-augmented
LLMs incorporate citations, grounding the content in verifiable sources.
Despite such developments, manually assessing how well a citation supports the
associated statement remains a major challenge. Previous studies use
faithfulness metrics to estimate citation support automatically but are limited
to binary classification, overlooking fine-grained citation support in
practical scenarios. To investigate the effectiveness of faithfulness metrics
in fine-grained scenarios, we propose a comparative evaluation framework that
assesses the metric effectiveness in distinguishinging citations between
three-category support levels: full, partial, and no support. Our framework
employs correlation analysis, classification evaluation, and retrieval
evaluation to measure the alignment between metric scores and human judgments
comprehensively. Our results show no single metric consistently excels across
all evaluations, revealing the complexity of assessing fine-grained support.
Based on the findings, we provide practical recommendations for developing more
effective metrics.

摘要：大型語言模型 (LLM) 經常產生不受支持或無法驗證的資訊，稱為「幻覺」。為了減輕此問題，檢索增強型 LLM 會納入引文，將內容建立在可驗證的來源上。儘管有這些發展，手動評估引文如何支援相關陳述仍然是一項重大挑戰。先前的研究使用忠實度指標自動評估引文支援，但僅限於二元分類，忽略了實際情況中的細粒度引文支援。為了調查忠實度指標在細粒度情境中的有效性，我們提出了一個比較評估架構，用於評估指標在區分三類支援層級（完全、部分和無支援）引文中的有效性。我們的架構採用相關性分析、分類評估和檢索評估來全面衡量指標分數與人類判斷之間的一致性。我們的結果顯示，沒有單一指標在所有評估中都持續表現出色，這揭示了評估細粒度支援的複雜性。根據這些發現，我們提供了實用的建議，以開發更有效的指標。

##### **V-RECS, a Low-Cost LLM4VIS Recommender with Explanations, Captioning and Suggestions**
2406.15259v1 by Luca Podo, Marco Angelini, Paola Velardi

NL2VIS (natural language to visualization) is a promising and recent research
area that involves interpreting natural language queries and translating them
into visualizations that accurately represent the underlying data. As we
navigate the era of big data, NL2VIS holds considerable application potential
since it greatly facilitates data exploration by non-expert users. Following
the increasingly widespread usage of generative AI in NL2VIS applications, in
this paper we present V-RECS, the first LLM-based Visual Recommender augmented
with explanations(E), captioning(C), and suggestions(S) for further data
exploration. V-RECS' visualization narratives facilitate both response
verification and data exploration by non-expert users. Furthermore, our
proposed solution mitigates computational, controllability, and cost issues
associated with using powerful LLMs by leveraging a methodology to effectively
fine-tune small models. To generate insightful visualization narratives, we use
Chain-of-Thoughts (CoT), a prompt engineering technique to help LLM identify
and generate the logical steps to produce a correct answer. Since CoT is
reported to perform poorly with small LLMs, we adopted a strategy in which a
large LLM (GPT-4), acting as a Teacher, generates CoT-based instructions to
fine-tune a small model, Llama-2-7B, which plays the role of a Student.
Extensive experiments-based on a framework for the quantitative evaluation of
AI-based visualizations and on manual assessment by a group of
participants-show that V-RECS achieves performance scores comparable to GPT-4,
at a much lower cost. The efficacy of the V-RECS teacher-student paradigm is
also demonstrated by the fact that the un-tuned Llama fails to perform the task
in the vast majority of test cases. We release V-RECS for the visualization
community to assist visualization designers throughout the entire visualization
generation process.

摘要：<paragraph>NL2VIS（自然語言轉視覺化）是一個有前途且新興的研究領域，涉及解讀自然語言查詢，並將其轉換成精確呈現底層資料的視覺化。隨著我們進入大數據時代，NL2VIS 擁有相當大的應用潛力，因為它極大地促進了非專家使用者探索資料。隨著生成式 AI 在 NL2VIS 應用中越來越廣泛地使用，我們在這篇論文中提出了 V-RECS，這是第一個基於 LLM 的視覺推薦系統，並擴充了解釋 (E)、標題 (C) 和建議 (S) 以進一步探索資料。V-RECS 的視覺化敘述有助於非專家使用者驗證回應和探索資料。此外，我們提出的解決方案透過採用一種方法來有效微調小型模型，從而減輕與使用強大 LLM 相關的運算、可控性和成本問題。為了產生有見地的視覺化敘述，我們使用思想鏈 (CoT)，這是一種提示工程技術，可幫助 LLM 識別和產生產生正確答案的邏輯步驟。由於據報導，CoT 在小型 LLM 中表現不佳，因此我們採用了一種策略，其中大型 LLM (GPT-4) 扮演老師的角色，生成基於 CoT 的指令來微調小型模型 Llama-2-7B，後者扮演學生的角色。廣泛的實驗基於一個用於評估基於 AI 的視覺化的量化框架，以及一組參與者的手動評估，表明 V-RECS 達到了與 GPT-4 相當的效能分數，但成本卻低得多。V-RECS 師生範式的有效性也由以下事實證明：未調整的 Llama 在絕大多數測試案例中無法執行任務。我們釋出 V-RECS 給視覺化社群，以協助視覺化設計師完成整個視覺化生成過程。</paragraph>

##### **MantisScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation**
2406.15252v1 by Xuan He, Dongfu Jiang, Ge Zhang, Max Ku, Achint Soni, Sherman Siu, Haonan Chen, Abhranil Chandra, Ziyan Jiang, Aaran Arulraj, Kai Wang, Quy Duc Do, Yuansheng Ni, Bohan Lyu, Yaswanth Narsupalli, Rongqi Fan, Zhiheng Lyu, Yuchen Lin, Wenhu Chen

The recent years have witnessed great advances in video generation. However,
the development of automatic video metrics is lagging significantly behind.
None of the existing metric is able to provide reliable scores over generated
videos. The main barrier is the lack of large-scale human-annotated dataset. In
this paper, we release VideoFeedback, the first large-scale dataset containing
human-provided multi-aspect score over 37.6K synthesized videos from 11
existing video generative models. We train MantisScore (initialized from
Mantis) based on VideoFeedback to enable automatic video quality assessment.
Experiments show that the Spearman correlation between MantisScore and humans
can reach 77.1 on VideoFeedback-test, beating the prior best metrics by about
50 points. Further result on other held-out EvalCrafter, GenAI-Bench, and
VBench show that MantisScore has consistently much higher correlation with
human judges than other metrics. Due to these results, we believe MantisScore
can serve as a great proxy for human raters to (1) rate different video models
to track progress (2) simulate fine-grained human feedback in Reinforcement
Learning with Human Feedback (RLHF) to improve current video generation models.

摘要：近年来，视频生成领域取得了巨大进展。然而，自动视频指标的发展却远远落后。现有的指标都无法对生成的视频提供可靠的分数。主要障碍是缺乏大规模的人工标注数据集。在本文中，我们发布了 VideoFeedback，这是第一个包含来自 11 个现有视频生成模型的 37.6K 合成视频的人工提供的多方面分数的大规模数据集。我们基于 VideoFeedback 训练 MantisScore（从 Mantis 初始化），以实现自动视频质量评估。实验表明，MantisScore 与人类之间的 Spearman 相关性在 VideoFeedback-test 上可以达到 77.1，比之前的最佳指标高出约 50 个点。在其他保留的 EvalCrafter、GenAI-Bench 和 VBench 上的进一步结果表明，MantisScore 与人类评委的一致性始终远高于其他指标。根据这些结果，我们相信 MantisScore 可以作为人类评估者的一个很好的代理，以 (1) 对不同的视频模型进行评分以跟踪进度 (2) 在人类反馈强化学习 (RLHF) 中模拟细粒度的人类反馈以改进当前的视频生成模型。

##### **Unsupervised Morphological Tree Tokenizer**
2406.15245v1 by Qingyang Zhu, Xiang Hu, Pengyu Ji, Wei Wu, Kewei Tu

As a cornerstone in language modeling, tokenization involves segmenting text
inputs into pre-defined atomic units. Conventional statistical tokenizers often
disrupt constituent boundaries within words, thereby corrupting semantic
information. To address this drawback, we introduce morphological structure
guidance to tokenization and propose a deep model to induce character-level
structures of words. Specifically, the deep model jointly encodes internal
structures and representations of words with a mechanism named
$\textit{MorphOverriding}$ to ensure the indecomposability of morphemes. By
training the model with self-supervised objectives, our method is capable of
inducing character-level structures that align with morphological rules without
annotated training data. Based on the induced structures, our algorithm
tokenizes words through vocabulary matching in a top-down manner. Empirical
results indicate that the proposed method effectively retains complete
morphemes and outperforms widely adopted methods such as BPE and WordPiece on
both morphological segmentation tasks and language modeling tasks. The code
will be released later.

摘要：作為語言模型的基石，分詞涉及將文字輸入分段成預先定義的原子單位。傳統的統計分詞器經常會破壞字詞內的組成界線，進而損害語義資訊。為了解決這個缺點，我們在分詞中加入形態結構指引，並提出一個深度模型來誘導字詞的字元級結構。具體來說，深度模型會透過一種稱為「MorphOverriding」的機制，聯合編碼字詞的內部結構與表徵，以確保形態素的不可分解性。透過以自我監督目標訓練模型，我們的模型能夠在沒有標註訓練資料的情況下，誘導出與形態規則相符的字元級結構。我們的演算法根據誘導出的結構，從上而下地透過詞彙比對對字詞進行分詞。實證結果顯示，所提出的方法有效保留了完整的形態素，並且在形態分詞任務和語言模型任務上都優於廣泛採用的方法，例如 BPE 和 WordPiece。程式碼將在稍後釋出。

##### **Detecting Synthetic Lyrics with Few-Shot Inference**
2406.15231v1 by Yanis Labrak, Gabriel Meseguer-Brocal, Elena V. Epure

In recent years, generated content in music has gained significant
popularity, with large language models being effectively utilized to produce
human-like lyrics in various styles, themes, and linguistic structures. This
technological advancement supports artists in their creative processes but also
raises issues of authorship infringement, consumer satisfaction and content
spamming. To address these challenges, methods for detecting generated lyrics
are necessary. However, existing works have not yet focused on this specific
modality or on creative text in general regarding machine-generated content
detection methods and datasets. In response, we have curated the first dataset
of high-quality synthetic lyrics and conducted a comprehensive quantitative
evaluation of various few-shot content detection approaches, testing their
generalization capabilities and complementing this with a human evaluation. Our
best few-shot detector, based on LLM2Vec, surpasses stylistic and statistical
methods, which are shown competitive in other domains at distinguishing
human-written from machine-generated content. It also shows good generalization
capabilities to new artists and models, and effectively detects post-generation
paraphrasing. This study emphasizes the need for further research on creative
content detection, particularly in terms of generalization and scalability with
larger song catalogs. All datasets, pre-processing scripts, and code are
available publicly on GitHub and Hugging Face under the Apache 2.0 license.

摘要：近年來，音樂領域的生成內容獲得了顯著的普及，大型語言模型被有效地利用來產生各種風格、主題和語言結構的人類化歌詞。這項技術進步支持藝術家進行創作，但也引發了作者侵權、消費者滿意度和內容濫發的問題。為了應對這些挑戰，有必要採用檢測生成歌詞的方法。然而，現有作品尚未專注於這種特定模式或關於機器生成內容檢測方法和資料集的創意文字。為了解決此問題，我們策劃了第一個高品質合成歌詞資料集，並對各種少次數內容檢測方法進行了全面的定量評估，測試了它們的泛化能力，並以人工評估作為補充。我們基於 LLM2Vec 的最佳少次數檢測器超越了風格和統計方法，這些方法在其他領域中表現出競爭力，可以區分人類編寫和機器生成的內容。它還對新的藝術家和模型表現出良好的泛化能力，並有效地檢測出後生成的改寫。這項研究強調了進一步研究創意內容檢測的必要性，特別是在泛化和可擴展性方面，以及在較大的歌曲目錄中。所有資料集、預處理腳本和程式碼都公開發佈在 GitHub 和 Hugging Face 上，並採用 Apache 2.0  Lizenz。

##### **A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation**
2406.15227v1 by Irune Zubiaga, Aitor Soroa, Rodrigo Agerri

The proliferation of misinformation and harmful narratives in online
discourse has underscored the critical need for effective Counter Narrative
(CN) generation techniques. However, existing automatic evaluation methods
often lack interpretability and fail to capture the nuanced relationship
between generated CNs and human perception. Aiming to achieve a higher
correlation with human judgments, this paper proposes a novel approach to asses
generated CNs that consists on the use of a Large Language Model (LLM) as a
evaluator. By comparing generated CNs pairwise in a tournament-style format, we
establish a model ranking pipeline that achieves a correlation of $0.88$ with
human preference. As an additional contribution, we leverage LLMs as zero-shot
(ZS) CN generators and conduct a comparative analysis of chat, instruct, and
base models, exploring their respective strengths and limitations. Through
meticulous evaluation, including fine-tuning experiments, we elucidate the
differences in performance and responsiveness to domain-specific data. We
conclude that chat-aligned models in ZS are the best option for carrying out
the task, provided they do not refuse to generate an answer due to security
concerns.

摘要：網路論述中錯誤資訊和有害敘述的擴散凸顯了有效反敘述 (CN) 生成技術的重要需求。然而，現有的自動評估方法通常缺乏可解釋性，且無法捕捉生成的 CN 與人類認知之間的細微關係。為了達到與人類判斷更高的相關性，本文提出了一種新的方法來評估生成的 CN，其中包含使用大型語言模型 (LLM) 作為評估器。透過以錦標賽形式成對比較生成的 CN，我們建立了一個模型排名管道，與人類偏好的相關性達到 0.88 美元。作為額外的貢獻，我們利用 LLM 作為零次學習 (ZS) CN 生成器，並對聊天、指令和基礎模型進行比較分析，探討它們各自的優點和限制。透過細緻的評估，包括微調實驗，我們闡明了在效能和對特定領域資料的反應上的差異。我們得出結論，ZS 中的聊天對齊模型是在執行任務的最佳選擇，前提是它們不會因安全問題而拒絕產生答案。

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

摘要：對話政策在開發任務導向對話系統中扮演著至關重要的角色，然而它們的開發和維護具有挑戰性，且通常需要對話建模專家的大量工作。雖然在許多情況下，大量對話資料可用於手邊的工作，但人們缺乏一種有效的解決方案，無法從這些資料中提取對話政策。在本文中，我們透過首先說明大型語言模型 (LLM) 如何透過將對話轉換成由規範形式組成的統一中間表示，從資料集中提取對話政策，來說明如何解決這個差距。然後，我們提出了一種利用可控且可解釋的基於圖形的方法來產生對話政策的新方法。透過將對話中的規範形式組合成流網路，我們發現執行圖形遍歷演算法有助於提取對話流。這些流比透過提示 LLM 提取的流更能代表底層互動。我們的技術專注於讓對話設計師擁有更大的控制權，提供一種生產力工具來改善開發對話政策的過程。

##### **Injecting Bias in Text-To-Image Models via Composite-Trigger Backdoors**
2406.15213v1 by Ali Naseh, Jaechul Roh, Eugene Bagdasaryan, Amir Houmansadr

Recent advances in large text-conditional image generative models such as
Stable Diffusion, Midjourney, and DALL-E 3 have revolutionized the field of
image generation, allowing users to produce high-quality, realistic images from
textual prompts. While these developments have enhanced artistic creation and
visual communication, they also present an underexplored attack opportunity:
the possibility of inducing biases by an adversary into the generated images
for malicious intentions, e.g., to influence society and spread propaganda. In
this paper, we demonstrate the possibility of such a bias injection threat by
an adversary who backdoors such models with a small number of malicious data
samples; the implemented backdoor is activated when special triggers exist in
the input prompt of the backdoored models. On the other hand, the model's
utility is preserved in the absence of the triggers, making the attack highly
undetectable. We present a novel framework that enables efficient generation of
poisoning samples with composite (multi-word) triggers for such an attack. Our
extensive experiments using over 1 million generated images and against
hundreds of fine-tuned models demonstrate the feasibility of the presented
backdoor attack. We illustrate how these biases can bypass conventional
detection mechanisms, highlighting the challenges in proving the existence of
biases within operational constraints. Our cost analysis confirms the low
financial barrier to executing such attacks, underscoring the need for robust
defensive strategies against such vulnerabilities in text-to-image generation
models.

摘要：最近，诸如 Stable Diffusion、Midjourney 和 DALL-E 3 等大型文本条件图像生成模型的进步彻底改变了图像生成领域，使用户能够根据文本提示生成高质量的真实图像。虽然这些发展增强了艺术创作和视觉传达，但也带来了一个尚未探索的攻击机会：由对手在生成图像中引入偏见以进行恶意意图，例如影响社会和传播宣传。在本文中，我们展示了这种偏见注入威胁的可能性，对手用少量恶意数据样本对这些模型进行后门攻击；当后门模型的输入提示中存在特殊触发器时，实施的后门就会被激活。另一方面，在没有触发器的情况下，模型的实用性得以保留，这使得攻击极难被检测到。我们提出了一个新框架，该框架能够为这种攻击高效生成具有复合（多词）触发器的中毒样本。我们使用超过 100 万张生成图像并针对数百个微调模型进行的广泛实验证明了所提出的后门攻击的可行性。我们说明了这些偏见如何绕过传统的检测机制，突出了在操作约束内证明偏见存在的挑战。我们的成本分析证实了执行此类攻击的财务障碍低，这凸显了对文本到图像生成模型中此类漏洞采取稳健防御策略的必要性。

##### **Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**
2406.15198v1 by Santiago Berrezueta-Guzman, Mohanad Kandil, María-Luisa Martín-Ruiz, Iván Pau-de-la-Cruz, Stephan Krusche

Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental
condition characterized by inattention, hyperactivity, and impulsivity, which
can significantly impact an individual's daily functioning and quality of life.
Occupational therapy plays a crucial role in managing ADHD by fostering the
development of skills needed for daily living and enhancing an individual's
ability to participate fully in school, home, and social situations. Recent
studies highlight the potential of integrating Large Language Models (LLMs)
like ChatGPT and Socially Assistive Robots (SAR) to improve psychological
treatments. This integration aims to overcome existing limitations in mental
health therapy by providing tailored support and adapting to the unique needs
of this sensitive group. However, there remains a significant gap in research
exploring the combined use of these advanced technologies in ADHD therapy,
suggesting an opportunity for novel therapeutic approaches.
  Thus, we integrated two advanced language models, ChatGPT-4 Turbo and
Claude-3 Opus, into a robotic assistant to explore how well each model performs
in robot-assisted interactions. Additionally, we have compared their
performance in a simulated therapy scenario to gauge their effectiveness
against a clinically validated customized model. The results of this study show
that ChatGPT-4 Turbo excelled in performance and responsiveness, making it
suitable for time-sensitive applications. Claude-3 Opus, on the other hand,
showed strengths in understanding, coherence, and ethical considerations,
prioritizing safe and engaging interactions. Both models demonstrated
innovation and adaptability, but ChatGPT-4 Turbo offered greater ease of
integration and broader language support. The selection between them hinges on
the specific demands of ADHD therapy.

摘要：注意力不足過動症 (ADHD) 是一種神經發展狀況，其特徵為注意力不集中、過動和衝動，可能會對個人的日常生活功能和生活品質造成重大影響。職能治療在管理 ADHD 方面發揮著至關重要的作用，通過培養日常生活所需的技能並增強個人在學校、家庭和社交場合充分參與的能力。最近的研究強調了整合大型語言模型 (LLM)（如 ChatGPT）和社交輔助機器人 (SAR) 以改善心理治療的潛力。這種整合旨在通過提供量身定制的支持並適應這一敏感群體的獨特需求，來克服心理健康治療中現有的限制。然而，在探索這些先進技術在 ADHD 治療中的綜合應用方面，研究仍存在顯著差距，這表明有機會採用新的治療方法。因此，我們將兩個先進的語言模型 ChatGPT-4 Turbo 和 Claude-3 Opus 整合到機器人助手，以探索每個模型在機器人輔助互動中的表現。此外，我們比較了它們在模擬治療場景中的表現，以評估它們對臨床驗證的自訂模型的有效性。本研究的結果表明，ChatGPT-4 Turbo 在性能和響應能力方面表現出色，使其適用於對時間敏感的應用。另一方面，Claude-3 Opus 在理解、連貫性和道德考量方面表現出優勢，優先考慮安全和引人入勝的互動。這兩個模型都展示了創新和適應性，但 ChatGPT-4 Turbo 提供了更輕鬆的整合和更廣泛的語言支持。它們之間的選擇取決於 ADHD 治療的具體需求。

##### **Reward Steering with Evolutionary Heuristics for Decoding-time Alignment**
2406.15193v1 by Chia-Yu Hung, Navonil Majumder, Ambuj Mehrish, Soujanya Poria

The widespread applicability and increasing omnipresence of LLMs have
instigated a need to align LLM responses to user and stakeholder preferences.
Many preference optimization approaches have been proposed that fine-tune LLM
parameters to achieve good alignment. However, such parameter tuning is known
to interfere with model performance on many tasks. Moreover, keeping up with
shifting user preferences is tricky in such a situation. Decoding-time
alignment with reward model guidance solves these issues at the cost of
increased inference time. However, most of such methods fail to strike the
right balance between exploration and exploitation of reward -- often due to
the conflated formulation of these two aspects - to give well-aligned
responses. To remedy this we decouple these two aspects and implement them in
an evolutionary fashion: exploration is enforced by decoding from mutated
instructions and exploitation is represented as the periodic replacement of
poorly-rewarded generations with well-rewarded ones. Empirical evidences
indicate that this strategy outperforms many preference optimization and
decode-time alignment approaches on two widely accepted alignment benchmarks
AlpacaEval 2 and MT-Bench. Our implementation will be available at:
https://darwin-alignment.github.io.

摘要：广泛的适用性和 LLM 日益普及的无所不在性引发了将 LLM 响应与用户和利益相关者偏好保持一致的需求。已经提出了许多偏好优化方法，这些方法可以对 LLM 参数进行微调以实现良好的对齐。然而，众所周知，这种参数调整会干扰模型在许多任务上的性能。此外，在这种情况下，跟上不断变化的用户偏好是一件棘手的事情。使用奖励模型指导进行解码时对齐解决了这些问题，但代价是增加了推理时间。然而，大多数此类方法未能很好地平衡探索和利用奖励——通常是由于这两个方面的混淆表述——以给出很好地对齐的响应。为了解决这个问题，我们将这两个方面解耦，并以进化方式实现它们：通过从突变指令中解码来强制执行探索，并表示为定期用奖励较好的世代替换奖励较差的世代。经验证据表明，该策略在两个广泛接受的对齐基准 AlpacaEval 2 和 MT-Bench 上优于许多偏好优化和解码时对齐方法。我们的实现将在以下位置提供：https://darwin-alignment.github.io。

##### **UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis**
2406.15187v1 by Yulong Hui, Yao Lu, Huanchen Zhang

The use of Retrieval-Augmented Generation (RAG) has improved Large Language
Models (LLMs) in collaborating with external data, yet significant challenges
exist in real-world scenarios. In areas such as academic literature and finance
question answering, data are often found in raw text and tables in HTML or PDF
formats, which can be lengthy and highly unstructured. In this paper, we
introduce a benchmark suite, namely Unstructured Document Analysis (UDA), that
involves 2,965 real-world documents and 29,590 expert-annotated Q&A pairs. We
revisit popular LLM- and RAG-based solutions for document analysis and evaluate
the design choices and answer qualities across multiple document domains and
diverse query types. Our evaluation yields interesting findings and highlights
the importance of data parsing and retrieval. We hope our benchmark can shed
light and better serve real-world document analysis applications. The benchmark
suite and code can be found at https://github.com/qinchuanhui/UDA-Benchmark.

摘要：擷取增強生成（RAG）的使用已改善大型語言模型（LLM）與外部資料的協作，但實際場景中仍存在重大挑戰。在學術文獻和財務問答等領域，資料通常以 HTML 或 PDF 格式的原始文字和表格呈現，可能很長且高度非結構化。在本文中，我們介紹了一個基準套件，即非結構化文件分析（UDA），其中包含 2,965 份真實世界文件和 29,590 個專家註解的問答配對。我們重新檢視了流行的基於 LLM 和 RAG 的文件分析解決方案，並評估了跨多個文件領域和不同查詢類型的設計選擇和答案品質。我們的評估產生了有趣的發現，並強調了資料解析和擷取的重要性。我們希望我們的基準能為實際世界的文件分析應用程式提供啟示並提供更好的服務。基準套件和程式碼可以在 https://github.com/qinchuanhui/UDA-Benchmark 找到。

##### **Hybrid Alignment Training for Large Language Models**
2406.15178v1 by Chenglong Wang, Hang Zhou, Kaiyan Chang, Bei Li, Yongyu Mu, Tong Xiao, Tongran Liu, Jingbo Zhu

Alignment training is crucial for enabling large language models (LLMs) to
cater to human intentions and preferences. It is typically performed based on
two stages with different objectives: instruction-following alignment and
human-preference alignment. However, aligning LLMs with these objectives in
sequence suffers from an inherent problem: the objectives may conflict, and the
LLMs cannot guarantee to simultaneously align with the instructions and human
preferences well. To response to these, in this work, we propose a Hybrid
Alignment Training (Hbat) approach, based on alternating alignment and modified
elastic weight consolidation methods. The basic idea is to alternate between
different objectives during alignment training, so that better collaboration
can be achieved between the two alignment tasks.We experiment with Hbat on
summarization and dialogue tasks. Experimental results show that the proposed
\textsc{Hbat} can significantly outperform all baselines. Notably, Hbat yields
consistent performance gains over the traditional two-stage alignment training
when using both proximal policy optimization and direct preference
optimization.

摘要：對齊訓練對於讓大型語言模型 (LLM) 迎合人類意圖和偏好至關重要。它通常基於兩個具有不同目標的階段執行：遵循指令的對齊和人類偏好的對齊。然而，按順序使用這些目標對齊 LLM 會產生一個固有的問題：這些目標可能會衝突，而 LLM 無法保證同時與指令和人類偏好很好地對齊。為了回應這些問題，在這項工作中，我們提出了一種混合對齊訓練 (Hbat) 方法，它基於交替對齊和修改的彈性權重合併方法。基本想法是在對齊訓練期間在不同的目標之間交替，以便在兩個對齊任務之間實現更好的協作。我們在摘要和對話任務中對 Hbat 進行了實驗。實驗結果表明，所提出的\textsc{Hbat} 可以顯著優於所有基準。值得注意的是，在使用近端策略優化和直接偏好優化時，Hbat 在傳統兩階段對齊訓練中產生了一致的性能提升。

##### **Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss**
2406.15175v1 by Wei He, Marco Idiart, Carolina Scarton, Aline Villavicencio

Accurately modeling idiomatic or non-compositional language has been a
longstanding challenge in Natural Language Processing (NLP). This is partly
because these expressions do not derive their meanings solely from their
constituent words, but also due to the scarcity of relevant data resources, and
their impact on the performance of downstream tasks such as machine translation
and simplification. In this paper we propose an approach to model idiomaticity
effectively using a triplet loss that incorporates the asymmetric contribution
of components words to an idiomatic meaning for training language models by
using adaptive contrastive learning and resampling miners to build an
idiomatic-aware learning objective. Our proposed method is evaluated on a
SemEval challenge and outperforms previous alternatives significantly in many
metrics.

摘要：在自然語言處理 (NLP) 中，準確建模慣用語或非組合語言一直是一個長期的挑戰。這部分是因為這些表達式並非完全從其組成詞彙中提取其含義，也由於相關資料資源的稀少，以及它們對機器翻譯和簡化等下游任務的執行效能所造成的影響。在本文中，我們提出了一個方法，使用三元組損失來有效建模慣用語，該損失將組成詞彙對慣用語含義的不對稱貢獻納入語言模型的訓練中，方法是使用自適應對比學習和重新抽樣礦工來建立一個慣用語感知學習目標。我們在 SemEval 挑戰中評估了我們提出的方法，並且在許多指標中都明顯優於先前的替代方案。

##### **Évaluation des capacités de réponse de larges modèles de langage (LLM) pour des questions d'historiens**
2406.15173v1 by Mathieu Chartier, Nabil Dakkoune, Guillaume Bourgeois, Stéphane Jean

Large Language Models (LLMs) like ChatGPT or Bard have revolutionized
information retrieval and captivated the audience with their ability to
generate custom responses in record time, regardless of the topic. In this
article, we assess the capabilities of various LLMs in producing reliable,
comprehensive, and sufficiently relevant responses about historical facts in
French. To achieve this, we constructed a testbed comprising numerous
history-related questions of varying types, themes, and levels of difficulty.
Our evaluation of responses from ten selected LLMs reveals numerous
shortcomings in both substance and form. Beyond an overall insufficient
accuracy rate, we highlight uneven treatment of the French language, as well as
issues related to verbosity and inconsistency in the responses provided by
LLMs.

摘要：大型語言模型 (LLM)，例如 ChatGPT 或 Bard，徹底革新了資訊檢索，並以其在創紀錄的時間內生成自訂回應的能力，無論主題為何，都讓受眾著迷。在本文中，我們評估了各種 LLM 在產生可靠、全面且足夠相關的法國歷史事實回應方面的能力。為此，我們構建了一個測試平台，其中包含許多不同類型、主題和難度等級的與歷史相關的問題。我們對十個選定的 LLM 的回應進行評估，揭示了實質和形式上的眾多缺點。除了整體準確率不足之外，我們還強調了法語處理的不均衡，以及 LLM 提供的回應中冗長和不一致的問題。

##### **This actually looks like that: Proto-BagNets for local and global interpretability-by-design**
2406.15168v1 by Kerol Djoumessi, Bubacarr Bah, Laura Kühlewein, Philipp Berens, Lisa Koch

Interpretability is a key requirement for the use of machine learning models
in high-stakes applications, including medical diagnosis. Explaining black-box
models mostly relies on post-hoc methods that do not faithfully reflect the
model's behavior. As a remedy, prototype-based networks have been proposed, but
their interpretability is limited as they have been shown to provide coarse,
unreliable, and imprecise explanations.In this work, we introduce
Proto-BagNets, an interpretable-by-design prototype-based model that combines
the advantages of bag-of-local feature models and prototype learning to provide
meaningful, coherent, and relevant prototypical parts needed for accurate and
interpretable image classification tasks. We evaluated the Proto-BagNet for
drusen detection on publicly available retinal OCT data. The Proto-BagNet
performed comparably to the state-of-the-art interpretable and
non-interpretable models while providing faithful, accurate, and clinically
meaningful local and global explanations. The code is available at
https://github.com/kdjoumessi/Proto-BagNets.

摘要：可解釋性是機器學習模型在高風險應用中（包括醫療診斷）使用的關鍵需求。解釋黑箱模型主要依賴於事後方法，而這些方法無法忠實反映模型的行為。作為補救措施，已經提出了基於原型的網路，但它們的可解釋性受到限制，因為它們已被證明提供粗略、不可靠和不精確的解釋。在這項工作中，我們引入了 Proto-BagNets，這是一個可解釋的基於原型的模型，它結合了局部特徵模型和原型學習的優點，以提供準確且可解釋的影像分類任務所需的有意義、連貫且相關的原型部分。我們評估了 Proto-BagNet 在公開可用的視網膜 OCT 資料上的黃斑沉積物檢測。Proto-BagNet 的表現與最先進的可解釋和不可解釋模型相當，同時提供了忠實、準確和臨床上有意義的局部和全局解釋。程式碼可在 https://github.com/kdjoumessi/Proto-BagNets 取得。

##### **A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis**
2406.15163v1 by Muhammad Imran, Olga Kellert, Carlos Gómez-Rodríguez

Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing
(NLP), addressing subjective assessments in textual content. Syntactic parsing
is useful in SA because explicit syntactic information can improve accuracy
while providing explainability, but it tends to be a computational bottleneck
in practice due to the slowness of parsing algorithms. This paper addresses
said bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject
syntax into SA. By treating dependency parsing as a sequence labeling problem,
we greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated
on a ternary polarity classification task, demonstrating its faster performance
and better accuracy in polarity prediction tasks compared to conventional
parsers like Stanza and to heuristic approaches that use shallow syntactic
rules for SA like VADER. This increased speed and improved accuracy make SELSP
particularly appealing to SA practitioners in both research and industry. In
addition, we test several sentiment dictionaries on our SELSP to see which one
improves the performance in polarity prediction tasks. Moreover, we compare the
SELSP with Transformer-based models trained on a 5-label classification task.
The results show that dictionaries that capture polarity judgment variation
provide better results than dictionaries that ignore polarity judgment
variation. Moreover, we show that SELSP is considerably faster than
Transformer-based models in polarity prediction tasks.

摘要：情緒分析 (SA) 是自然語言處理 (NLP) 的一個關鍵面向，用於處理文本內容中的主觀評估。句法分析在 SA 中很有用，因為明確的句法資訊可以提高準確性，同時提供可解釋性，但由於分析演算法的速度慢，在實務上往往會成為運算瓶頸。本文透過使用序列標籤句法分析器 (SELSP) 來將句法注入 SA，以解決上述瓶頸。透過將依存句法分析視為序列標籤問題，我們大幅提升了基於句法的 SA 速度。SELSP 接受三元極性分類任務的訓練和評估，證明其在極性預測任務中的執行速度較快，且準確度較高，優於 Stanza 等傳統分析器和使用淺層句法規則進行 SA 的啟發式方法，例如 VADER。這種速度提升和準確度改善讓 SELSP 特別受到研究和產業中 SA 從業人員的青睞。此外，我們在 SELSP 上測試了多個情緒詞典，以找出哪一個詞典能改善極性預測任務中的表現。此外，我們將 SELSP 與訓練在 5 標籤分類任務上的 Transformer-based 模型進行比較。結果顯示，能捕捉極性判斷變化的詞典，其提供的結果優於忽略極性判斷變化的詞典。此外，我們證明了 SELSP 在極性預測任務中比 Transformer-based 模型快上許多。

##### **Generative Topological Networks**
2406.15152v1 by Alona Levy-Jurgenson, Zohar Yakhini

Generative models have seen significant advancements in recent years, yet
often remain challenging and costly to train and use. We introduce Generative
Topological Networks (GTNs) -- a new class of generative models that addresses
these shortcomings. GTNs are trained deterministically using a simple
supervised learning approach grounded in topology theory. GTNs are fast to
train, and require only a single forward pass in a standard feedforward neural
network to generate samples. We demonstrate the strengths of GTNs in several
datasets, including MNIST, celebA and the Hands and Palm Images dataset.
Finally, the theory behind GTNs offers insights into how to train generative
models for improved performance.

摘要：生成模型近年來取得顯著進展，但訓練和使用仍然具有挑戰性且成本高昂。我們引入了生成拓撲網路 (GTN)，這是一種新的生成模型類別，可解決這些缺點。GTN 使用基於拓撲理論的簡單監督式學習方法進行確定性訓練。GTN 訓練速度快，且只需在標準前饋神經網路中進行一次前向傳遞即可生成樣本。我們在多個資料集中展示了 GTN 的優點，包括 MNIST、celebA 以及 Hands and Palm Images 資料集。最後，GTN 背後的理論提供了如何訓練生成模型以提高效能的見解。

##### **Gaussian Splatting to Real World Flight Navigation Transfer with Liquid Networks**
2406.15149v1 by Alex Quach, Makram Chahine, Alexander Amini, Ramin Hasani, Daniela Rus

Simulators are powerful tools for autonomous robot learning as they offer
scalable data generation, flexible design, and optimization of trajectories.
However, transferring behavior learned from simulation data into the real world
proves to be difficult, usually mitigated with compute-heavy domain
randomization methods or further model fine-tuning. We present a method to
improve generalization and robustness to distribution shifts in sim-to-real
visual quadrotor navigation tasks. To this end, we first build a simulator by
integrating Gaussian Splatting with quadrotor flight dynamics, and then, train
robust navigation policies using Liquid neural networks. In this way, we obtain
a full-stack imitation learning protocol that combines advances in 3D Gaussian
splatting radiance field rendering, crafty programming of expert demonstration
training data, and the task understanding capabilities of Liquid networks.
Through a series of quantitative flight tests, we demonstrate the robust
transfer of navigation skills learned in a single simulation scene directly to
the real world. We further show the ability to maintain performance beyond the
training environment under drastic distribution and physical environment
changes. Our learned Liquid policies, trained on single target manoeuvres
curated from a photorealistic simulated indoor flight only, generalize to
multi-step hikes onboard a real hardware platform outdoors.

摘要：模擬器是強大的自動化機器人學習工具，因為它們提供可擴展的資料產生、靈活的設計和軌跡最佳化。然而，將從模擬資料學習到的行為轉移到真實世界中被證明是困難的，通常透過計算密集的網域隨機化方法或進一步的模型微調來減輕。我們提出了一種方法來改善在 sim-to-real 視覺四旋翼導航任務中對分佈轉移的泛化和穩健性。為此，我們首先透過將高斯散射與四旋翼飛行動力學整合來建立模擬器，然後使用 Liquid 神經網路訓練穩健的導航策略。透過這種方式，我們獲得了一個完整的堆疊式模仿學習協定，它結合了 3D 高斯散射輻射場渲染、專家示範訓練資料的精巧程式設計以及 Liquid 網路的任務理解能力。透過一系列的定量飛行測試，我們展示了將在單一模擬場景中學習到的導航技能直接轉移到真實世界的強大能力。我們進一步展示了在劇烈的分佈和物理環境變化下，在訓練環境之外維持效能的能力。我們學習到的 Liquid 策略僅從寫實的模擬室內飛行中策劃的單一目標機動訓練，並推廣到在真實硬體平台上戶外進行的多步驟遠足。

##### **Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks**
2406.15130v1 by Victor Hugo Nascimento Rocha, Igor Cataneo Silveira, Paulo Pirozelli, Denis Deratani Mauá, Fabio Gagliardi Cozman

The recent success of Large Language Models (LLMs) has sparked concerns about
their potential to spread misinformation. As a result, there is a pressing need
for tools to identify ``fake arguments'' generated by such models. To create
these tools, examples of texts generated by LLMs are needed. This paper
introduces a methodology to obtain good, bad and ugly arguments from
argumentative essays produced by ChatGPT, OpenAI's LLM. We then describe a
novel dataset containing a set of diverse arguments, ArGPT. We assess the
effectiveness of our dataset and establish baselines for several
argumentation-related tasks. Finally, we show that the artificially generated
data relates well to human argumentation and thus is useful as a tool to train
and test systems for the defined tasks.

摘要：大型語言模型 (LLM) 近期的成功引起人們對其散布錯誤訊息潛力的擔憂。因此，迫切需要有工具來識別此類模型產生的「虛假論證」。要建立這些工具，需要有 LLM 生成的文本範例。本文介紹一種方法，從 ChatGPT（OpenAI 的 LLM）產生的論證性文章中取得好、壞和醜陋的論證。然後，我們描述一個包含一組多元論證的新穎資料集 ArGPT。我們評估我們資料集的有效性，並為幾個與論證相關的任務建立基準。最後，我們表明人工產生的資料與人類論證有很好的關聯性，因此可用作訓練和測試定義任務系統的工具。

##### **A Wavelet Guided Attention Module for Skin Cancer Classification with Gradient-based Feature Fusion**
2406.15128v1 by Ayush Roy, Sujan Sarkar, Sohom Ghosal, Dmitrii Kaplun, Asya Lyanova, Ram Sarkar

Skin cancer is a highly dangerous type of cancer that requires an accurate
diagnosis from experienced physicians. To help physicians diagnose skin cancer
more efficiently, a computer-aided diagnosis (CAD) system can be very helpful.
In this paper, we propose a novel model, which uses a novel attention mechanism
to pinpoint the differences in features across the spatial dimensions and
symmetry of the lesion, thereby focusing on the dissimilarities of various
classes based on symmetry, uniformity in texture and color, etc. Additionally,
to take into account the variations in the boundaries of the lesions for
different classes, we employ a gradient-based fusion of wavelet and soft
attention-aided features to extract boundary information of skin lesions. We
have tested our model on the multi-class and highly class-imbalanced dataset,
called HAM10000, and achieved promising results, with a 91.17\% F1-score and
90.75\% accuracy. The code is made available at:
https://github.com/AyushRoy2001/WAGF-Fusion.

摘要：皮膚癌是一種非常危險的癌症類型，需要有經驗的醫生準確診斷。為了幫助醫生更有效地診斷皮膚癌，電腦輔助診斷 (CAD) 系統可以提供很大的幫助。在本文中，我們提出了一個新穎的模型，它使用一種新穎的注意力機制來精確找出跨空間維度和病灶對稱性的特徵差異，從而專注於基於對稱性、紋理和顏色的一致性等方面的各種類別的差異。此外，為了考慮不同類別病灶邊界的變化，我們採用基於梯度的波段融合和軟注意力輔助特徵來提取皮膚病灶的邊界信息。我們在多類且類別極不平衡名為 HAM10000 的數據集上測試了我們的模型，並取得了令人滿意的結果，F1 分數為 91.17%，準確率為 90.75%。代碼可在以下位置獲得：
https://github.com/AyushRoy2001/WAGF-Fusion。

##### **Speech Emotion Recognition under Resource Constraints with Data Distillation**
2406.15119v1 by Yi Chang, Zhao Ren, Zhonghao Zhao, Thanh Tam Nguyen, Kun Qian, Tanja Schultz, Björn W. Schuller

Speech emotion recognition (SER) plays a crucial role in human-computer
interaction. The emergence of edge devices in the Internet of Things (IoT)
presents challenges in constructing intricate deep learning models due to
constraints in memory and computational resources. Moreover, emotional speech
data often contains private information, raising concerns about privacy leakage
during the deployment of SER models. To address these challenges, we propose a
data distillation framework to facilitate efficient development of SER models
in IoT applications using a synthesised, smaller, and distilled dataset. Our
experiments demonstrate that the distilled dataset can be effectively utilised
to train SER models with fixed initialisation, achieving performances
comparable to those developed using the original full emotional speech dataset.

摘要：語音情緒辨識 (SER) 在人機互動中扮演著至關重要的角色。物聯網 (IoT) 中的邊緣裝置興起，由於記憶體和運算資源的限制，在建構複雜的深度學習模型時面臨挑戰。此外，情緒化語音資料通常包含個人隱私資訊，這在部署 SER 模型時引發了隱私外洩的疑慮。為了應對這些挑戰，我們提出一個資料萃取架構，以利於使用合成、較小且經過萃取的資料集，在 IoT 應用中有效地開發 SER 模型。我們的實驗證明，萃取的資料集可有效用於訓練具備固定初始化的 SER 模型，其效能可與使用原始完整情緒化語音資料集開發的模型相媲美。

##### **FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**
2406.15117v1 by Ayush Roy, Anurag Bhattacharjee, Diego Oliva, Oscar Ramos-Soto, Francisco J. Alvarez-Padilla, Ram Sarkar

Pneumonia is a respiratory infection caused by bacteria, fungi, or viruses.
It affects many people, particularly those in developing or underdeveloped
nations with high pollution levels, unhygienic living conditions, overcrowding,
and insufficient medical infrastructure. Pneumonia can cause pleural effusion,
where fluids fill the lungs, leading to respiratory difficulty. Early diagnosis
is crucial to ensure effective treatment and increase survival rates. Chest
X-ray imaging is the most commonly used method for diagnosing pneumonia.
However, visual examination of chest X-rays can be difficult and subjective. In
this study, we have developed a computer-aided diagnosis system for automatic
pneumonia detection using chest X-ray images. We have used DenseNet-121 and
ResNet50 as the backbone for the binary class (pneumonia and normal) and
multi-class (bacterial pneumonia, viral pneumonia, and normal) classification
tasks, respectively. We have also implemented a channel-specific spatial
attention mechanism, called Fuzzy Channel Selective Spatial Attention Module
(FCSSAM), to highlight the specific spatial regions of relevant channels while
removing the irrelevant channels of the extracted features by the backbone. We
evaluated the proposed approach on a publicly available chest X-ray dataset,
using binary and multi-class classification setups. Our proposed method
achieves accuracy rates of 97.15\% and 79.79\% for the binary and multi-class
classification setups, respectively. The results of our proposed method are
superior to state-of-the-art (SOTA) methods. The code of the proposed model
will be available at: https://github.com/AyushRoy2001/FA-Net.

摘要：肺炎是一種由細菌、真菌或病毒引起的呼吸道感染。
它影響許多人，特別是發展中國家或未開發國家，這些國家污染程度高、生活條件不衛生、人口過於稠密，且醫療基礎設施不足。肺炎會導致胸腔積液，液體會充滿肺部，導致呼吸困難。早期診斷對於確保有效治療和提高存活率至關重要。胸部 X 光影像檢查是診斷肺炎最常用的方法。
然而，胸部 X 光的視覺檢查可能困難且主觀。在本研究中，我們開發了一個電腦輔助診斷系統，用於使用胸部 X 光影像自動偵測肺炎。我們使用 DenseNet-121 和 ResNet50 作為二元類別（肺炎和正常）和多類別（細菌性肺炎、病毒性肺炎和正常）分類任務的主幹。我們還實作了一個通道特定的空間注意力機制，稱為模糊通道選擇性空間注意力模組 (FCSSAM)，以突顯相關通道的特定空間區域，同時移除主幹提取特徵的無關通道。我們在公開的胸部 X 光資料集上評估所提出的方法，使用二元和多類別分類設定。我們提出的方法在二元和多類別分類設定中分別達到 97.15% 和 79.79% 的準確率。我們提出的方法的結果優於最先進 (SOTA) 的方法。所提出模型的程式碼將可在以下位置取得：https://github.com/AyushRoy2001/FA-Net。

##### **A Dual Attention-aided DenseNet-121 for Classification of Glaucoma from Fundus Images**
2406.15113v1 by Soham Chakraborty, Ayush Roy, Payel Pramanik, Daria Valenkova, Ram Sarkar

Deep learning and computer vision methods are nowadays predominantly used in
the field of ophthalmology. In this paper, we present an attention-aided
DenseNet-121 for classifying normal and glaucomatous eyes from fundus images.
It involves the convolutional block attention module to highlight relevant
spatial and channel features extracted by DenseNet-121. The channel
recalibration module further enriches the features by utilizing edge
information along with the statistical features of the spatial dimension. For
the experiments, two standard datasets, namely RIM-ONE and ACRIMA, have been
used. Our method has shown superior results than state-of-the-art models. An
ablation study has also been conducted to show the effectiveness of each of the
components. The code of the proposed work is available at:
https://github.com/Soham2004GitHub/DADGC.

摘要：深度学习和计算机视觉方法现今主要用于眼科领域。在本文中，我们提出了一种注意力辅助的 DenseNet-121，用于对眼底图像中的正常和青光眼进行分类。它涉及卷积块注意力模块，以突出 DenseNet-121 提取的相关空间和通道特征。通道重新校准模块通过利用边缘信息以及空间维度的统计特征进一步丰富了特征。对于实验，已经使用了两个标准数据集，即 RIM-ONE 和 ACRIMA。我们的方法已经显示出优于最先进模型的结果。还进行了一项消融研究，以显示每个组件的有效性。所提出工作的代码可在以下位置获得：
https://github.com/Soham2004GitHub/DADGC。

##### **Investigating the impact of 2D gesture representation on co-speech gesture generation**
2406.15111v1 by Teo Guichoux, Laure Soulier, Nicolas Obin, Catherine Pelachaud

Co-speech gestures play a crucial role in the interactions between humans and
embodied conversational agents (ECA). Recent deep learning methods enable the
generation of realistic, natural co-speech gestures synchronized with speech,
but such approaches require large amounts of training data. "In-the-wild"
datasets, which compile videos from sources such as YouTube through human pose
detection models, offer a solution by providing 2D skeleton sequences that are
paired with speech. Concurrently, innovative lifting models have emerged,
capable of transforming these 2D pose sequences into their 3D counterparts,
leading to large and diverse datasets of 3D gestures. However, the derived 3D
pose estimation is essentially a pseudo-ground truth, with the actual ground
truth being the 2D motion data. This distinction raises questions about the
impact of gesture representation dimensionality on the quality of generated
motions, a topic that, to our knowledge, remains largely unexplored. In this
work, we evaluate the impact of the dimensionality of the training data, 2D or
3D joint coordinates, on the performance of a multimodal speech-to-gesture deep
generative model. We use a lifting model to convert 2D-generated sequences of
body pose to 3D. Then, we compare the sequence of gestures generated directly
in 3D to the gestures generated in 2D and lifted to 3D as post-processing.

摘要：共語手勢在人類和具身對話代理 (ECA) 之間的互動中扮演著至關重要的角色。最近的深度學習方法能夠產生與語音同步的逼真、自然的共語手勢，但此類方法需要大量的訓練數據。透過人類姿勢偵測模型從 YouTube 等來源彙編影片的「野外」資料集提供了一個解決方案，方法是提供與語音配對的 2D 骨架序列。同時，創新的提升模型應運而生，能夠將這些 2D 姿勢序列轉換為其 3D 對應物，從而產生龐大且多樣化的 3D 手勢資料集。然而，衍生的 3D 姿勢估計本質上是一個偽基礎真實值，而實際的基礎真實值是 2D 運動數據。這種區別引發了關於手勢表示維度對生成動作品質的影響問題，這個主題據我們所知仍未得到廣泛探討。在這項工作中，我們評估了訓練數據的維度（2D 或 3D 關節座標）對多模態語音到手勢深度生成模型效能的影響。我們使用提升模型將 2D 生成的身體姿勢序列轉換為 3D。然後，我們將直接在 3D 中生成的動作序列與在 2D 中生成並提升到 3D 作為後處理的動作進行比較。

##### **Brain-Like Language Processing via a Shallow Untrained Multihead Attention Network**
2406.15109v1 by Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf

Large Language Models (LLMs) have been shown to be effective models of the
human language system, with some models predicting most explainable variance of
brain activity in current datasets. Even in untrained models, the
representations induced by architectural priors can exhibit reasonable
alignment to brain data. In this work, we investigate the key architectural
components driving the surprising alignment of untrained models. To estimate
LLM-to-brain similarity, we first select language-selective units within an
LLM, similar to how neuroscientists identify the language network in the human
brain. We then benchmark the brain alignment of these LLM units across five
different brain recording datasets. By isolating critical components of the
Transformer architecture, we identify tokenization strategy and multihead
attention as the two major components driving brain alignment. A simple form of
recurrence further improves alignment. We further demonstrate this quantitative
brain alignment of our model by reproducing landmark studies in the language
neuroscience field, showing that localized model units -- just like language
voxels measured empirically in the human brain -- discriminate more reliably
between lexical than syntactic differences, and exhibit similar response
profiles under the same experimental conditions. Finally, we demonstrate the
utility of our model's representations for language modeling, achieving
improved sample and parameter efficiency over comparable architectures. Our
model's estimates of surprisal sets a new state-of-the-art in the behavioral
alignment to human reading times. Taken together, we propose a highly brain-
and behaviorally-aligned model that conceptualizes the human language system as
an untrained shallow feature encoder, with structural priors, combined with a
trained decoder to achieve efficient and performant language processing.

摘要：大型語言模型 (LLM) 已被證明是人類語言系統的有效模型，其中一些模型預測了當前數據集中大多數可解釋的腦部活動變異。即使在未經訓練的模型中，由架構先驗誘導的表徵也會表現出與腦部數據的合理一致性。在這項工作中，我們探討了驅動未經訓練模型驚人一致性的關鍵架構組成部分。為了估計 LLM 與大腦的相似性，我們首先在 LLM 中選擇語言選擇性單位，類似於神經科學家識別人類大腦中的語言網路的方式。然後，我們對這些 LLM 單元的大腦對齊在五個不同的腦部記錄數據集中進行基準測試。通過分離 Transformer 架構的關鍵組成部分，我們將標記化策略和多頭注意力識別為驅動大腦對齊的兩個主要組成部分。一種簡單的遞迴形式進一步改善了對齊。我們通過重現語言神經科學領域的標誌性研究進一步展示了我們模型的這種定量大腦對齊，表明局部模型單元——就像在大腦中經驗測量的人類語言體素一樣——在詞彙差異和句法差異之間進行更可靠的區分，並且在相同的實驗條件下表現出相似的響應特徵。最後，我們展示了我們模型的表徵在語言建模中的效用，與可比較的架構相比，實現了改進的樣本和參數效率。我們模型對驚訝的估計在與人類閱讀時間的行為對齊方面設定了一個新的最先進水平。綜上所述，我們提出了一個高度與大腦和行為對齊的模型，它將人類語言系統概念化为一個未經訓練的淺層特徵編碼器，具有結構先驗，並與一個訓練過的解碼器相結合，以實現高效和高性能的語言處理。

##### **A Unified Framework for Input Feature Attribution Analysis**
2406.15085v1 by Jingyi Sun, Pepa Atanasova, Isabelle Augenstein

Explaining the decision-making process of machine learning models is crucial
for ensuring their reliability and fairness. One popular explanation form
highlights key input features, such as i) tokens (e.g., Shapley Values and
Integrated Gradients), ii) interactions between tokens (e.g., Bivariate Shapley
and Attention-based methods), or iii) interactions between spans of the input
(e.g., Louvain Span Interactions). However, these explanation types have only
been studied in isolation, making it difficult to judge their respective
applicability. To bridge this gap, we propose a unified framework that
facilitates a direct comparison between highlight and interactive explanations
comprised of four diagnostic properties. Through extensive analysis across
these three types of input feature explanations--each utilizing three different
explanation techniques--across two datasets and two models, we reveal that each
explanation type excels in terms of different diagnostic properties. In our
experiments, highlight explanations are the most faithful to a model's
prediction, and interactive explanations provide better utility for learning to
simulate a model's predictions. These insights further highlight the need for
future research to develop combined methods that enhance all diagnostic
properties.

摘要：解釋機器學習模型的決策過程對於確保它們的可靠性和公平性至關重要。一種流行的解釋形式突出了關鍵輸入特徵，例如 i) 代幣（例如，Shapley 值和積分梯度）、ii) 代幣之間的交互（例如，雙變量 Shapley 和基於注意力的方法），或 iii) 輸入跨度的交互（例如，魯汶跨度交互）。然而，這些解釋類型僅在孤立的環境中進行了研究，這使得難以判斷它們各自的適用性。為了彌合這一差距，我們提出了一個統一的框架，該框架促進了由四個診斷屬性組成的亮點和互動解釋之間的直接比較。通過對這三種類型的輸入特徵解釋（每種類型都使用三種不同的解釋技術）在兩個數據集和兩個模型中進行廣泛分析，我們發現每種類型的解釋在不同的診斷屬性方面都非常出色。在我們的實驗中，亮點解釋最忠實於模型的預測，而互動解釋則提供了更好的效用，用於模擬模型的預測。這些見解進一步強調了未來研究需要開發結合方法以增強所有診斷屬性的必要性。

##### **KnobTree: Intelligent Database Parameter Configuration via Explainable Reinforcement Learning**
2406.15073v1 by Jiahan Chen, Shuhan Qi, Yifan Li, Zeyu Dong, Mingfeng Ding, Yulin Wu, Xuan Wang

Databases are fundamental to contemporary information systems, yet
traditional rule-based configuration methods struggle to manage the complexity
of real-world applications with hundreds of tunable parameters. Deep
reinforcement learning (DRL), which combines perception and decision-making,
presents a potential solution for intelligent database configuration tuning.
However, due to black-box property of RL-based method, the generated database
tuning strategies still face the urgent problem of lack explainability.
Besides, the redundant parameters in large scale database always make the
strategy learning become unstable. This paper proposes KnobTree, an
interpertable framework designed for the optimization of database parameter
configuration. In this framework, an interpertable database tuning algorithm
based on RL-based differentatial tree is proposed, which building a transparent
tree-based model to generate explainable database tuning strategies. To address
the problem of large-scale parameters, We also introduce a explainable method
for parameter importance assessment, by utilizing Shapley Values to identify
parameters that have significant impacts on database performance. Experiments
conducted on MySQL and Gbase8s databases have verified exceptional transparency
and interpretability of the KnobTree model. The good property makes generated
strategies can offer practical guidance to algorithm designers and database
administrators. Moreover, our approach also slightly outperforms the existing
RL-based tuning algorithms in aspects such as throughput, latency, and
processing time.

摘要：<paragraph>資料庫是當代資訊系統的基礎，但傳統的基於規則的配置方法難以管理具有數百個可調參數的真實世界應用程式的複雜性。深度強化學習 (DRL) 結合了感知和決策制定，為智慧資料庫配置調整提供了潛在的解決方案。然而，由於基於 RL 的方法的黑盒屬性，產生的資料庫調整策略仍然面臨缺乏可解釋性的迫切問題。此外，大規模資料庫中的冗餘參數總是讓策略學習變得不穩定。本文提出了 KnobTree，一個可解釋的框架，專為最佳化資料庫參數配置而設計。在這個框架中，提出了一個基於 RL-based differentatial tree 的可解釋資料庫調整演算法，它建立了一個透明的樹狀模型來產生可解釋的資料庫調整策略。為了解決大規模參數的問題，我們還引入了一種可解釋的方法來評估參數重要性，通過利用 Shapley 值來識別對資料庫效能有重大影響的參數。在 MySQL 和 Gbase8s 資料庫上進行的實驗驗證了 KnobTree 模型的出色透明性和可解釋性。良好的屬性使得產生的策略可以為演算法設計人員和資料庫管理員提供實用的指導。此外，我們的做法在吞吐量、延遲和處理時間等方面也略勝於現有的基於 RL 的調整演算法。</paragraph>

##### **Cross-lingual paraphrase identification**
2406.15066v1 by Inessa Fedorova, Aleksei Musatow

The paraphrase identification task involves measuring semantic similarity
between two short sentences. It is a tricky task, and multilingual paraphrase
identification is even more challenging. In this work, we train a bi-encoder
model in a contrastive manner to detect hard paraphrases across multiple
languages. This approach allows us to use model-produced embeddings for various
tasks, such as semantic search. We evaluate our model on downstream tasks and
also assess embedding space quality. Our performance is comparable to
state-of-the-art cross-encoders, with only a minimal relative drop of 7-10% on
the chosen dataset, while keeping decent quality of embeddings.

摘要：同義詞辨識任務涉及測量兩個短句之間的語義相似度。這是一項棘手的任務，而多語言同義詞辨識更具挑戰性。在這項工作中，我們以對比的方式訓練一個雙編碼器模型，以跨多種語言偵測困難的同義詞。此方法允許我們將模型產生的嵌入用於各種任務，例如語義搜尋。我們在下游任務中評估我們的模型，並評估嵌入空間品質。我們的效能可與最先進的跨編碼器相媲美，在所選資料集上僅有 7-10% 的最小相對下降，同時保持嵌入的良好品質。

##### **PARIKSHA : A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data**
2406.15053v1 by Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri, Manohar Swaminathan, Sunayana Sitaram

Evaluation of multilingual Large Language Models (LLMs) is challenging due to
a variety of factors -- the lack of benchmarks with sufficient linguistic
diversity, contamination of popular benchmarks into LLM pre-training data and
the lack of local, cultural nuances in translated benchmarks. In this work, we
study human and LLM-based evaluation in a multilingual, multi-cultural setting.
We evaluate 30 models across 10 Indic languages by conducting 90K human
evaluations and 30K LLM-based evaluations and find that models such as GPT-4o
and Llama-3 70B consistently perform best for most Indic languages. We build
leaderboards for two evaluation settings - pairwise comparison and direct
assessment and analyse the agreement between humans and LLMs. We find that
humans and LLMs agree fairly well in the pairwise setting but the agreement
drops for direct assessment evaluation especially for languages such as Bengali
and Odia. We also check for various biases in human and LLM-based evaluation
and find evidence of self-bias in the GPT-based evaluator. Our work presents a
significant step towards scaling up multilingual evaluation of LLMs.

摘要：多語言大型語言模型 (LLM) 的評估具有挑戰性，原因在於各種因素，包括缺乏具有足夠語言多樣性的基準、流行基準滲透到 LLM 預訓練資料中，以及翻譯基準中缺乏當地文化細微差別。在這項工作中，我們在多語言、多文化環境中研究了基於人類和 LLM 的評估。我們通過進行 90K 人類評估和 30K 基於 LLM 的評估，在 10 種印度語言中評估了 30 種模型，發現 GPT-4o 和 Llama-3 70B 等模型始終對大多數印度語言表現最佳。我們為兩個評估設定建立了排行榜，分別是成對比較和直接評估，並分析了人類和 LLM 之間的一致性。我們發現人類和 LLM 在成對設定中相當一致，但對直接評估評估的一致性下降，特別是對於孟加拉語和奧迪亞語等語言。我們還檢查了人類和基於 LLM 的評估中的各種偏差，並發現基於 GPT 的評估器中存在自我偏差的證據。我們的這項工作朝著擴大 LLM 的多語言評估邁出了重要一步。

##### **Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**
2406.15050v1 by Lin Fan, Xun Gong, Cenyang Zheng, Yafei Ou

The intersection of medical Visual Question Answering (Med-VQA) is a
challenging research topic with advantages including patient engagement and
clinical expert involvement for second opinions. However, existing Med-VQA
methods based on joint embedding fail to explain whether their provided results
are based on correct reasoning or coincidental answers, which undermines the
credibility of VQA answers. In this paper, we investigate the construction of a
more cohesive and stable Med-VQA structure. Motivated by causal effect, we
propose a novel Triangular Reasoning VQA (Tri-VQA) framework, which constructs
reverse causal questions from the perspective of "Why this answer?" to
elucidate the source of the answer and stimulate more reasonable forward
reasoning processes. We evaluate our method on the Endoscopic Ultrasound (EUS)
multi-attribute annotated dataset from five centers, and test it on medical VQA
datasets. Experimental results demonstrate the superiority of our approach over
existing methods. Our codes and pre-trained models are available at
https://anonymous.4open.science/r/Tri_VQA.

摘要：醫學視覺問答 (Med-VQA) 的交叉領域是一個具有挑戰性的研究主題，其優點包括患者參與和臨床專家的參與以提供第二意見。然而，現有的基於聯合嵌入的 Med-VQA 方法無法解釋其提供的結果是基於正確的推理還是巧合的答案，這會損害 VQA 答案的可信度。在本文中，我們探討了構建更緊密且穩定的 Med-VQA 結構。受到因果關係的啟發，我們提出了一個新穎的三角推理 VQA (Tri-VQA) 框架，該框架從「為什麼這個答案？」的角度構建反向因果問題，以闡明答案的來源並激發更合理的正向推理過程。我們在來自五個中心的內視鏡超音波 (EUS) 多屬性註釋資料集上評估了我們的模型，並在醫學 VQA 資料集上對其進行測試。實驗結果證明了我們的方法優於現有方法。我們的程式碼和預先訓練的模型可在 https://anonymous.4open.science/r/Tri_VQA 取得。

##### **Harnessing Knowledge Retrieval with Large Language Models for Clinical Report Error Correction**
2406.15045v1 by Jinge Wu, Zhaolong Wu, Abul Hasan, Yunsoo Kim, Jason P. Y. Cheung, Teng Zhang, Honghan Wu

This study proposes an approach for error correction in clinical radiology
reports, leveraging large language models (LLMs) and retrieval-augmented
generation (RAG) techniques. The proposed framework employs internal and
external retrieval mechanisms to extract relevant medical entities and
relations from the report and external knowledge sources. A three-stage
inference process is introduced, decomposing the task into error detection,
localization, and correction subtasks, which enhances the explainability and
performance of the system. The effectiveness of the approach is evaluated using
a benchmark dataset created by corrupting real-world radiology reports with
realistic errors, guided by domain experts. Experimental results demonstrate
the benefits of the proposed methods, with the combination of internal and
external retrieval significantly improving the accuracy of error detection,
localization, and correction across various state-of-the-art LLMs. The findings
contribute to the development of more robust and reliable error correction
systems for clinical documentation.

摘要：本研究提出了一種臨床放射科報告中的錯誤校正方法，利用大型語言模型 (LLM) 和檢索增強生成 (RAG) 技術。所提出的框架採用內部和外部檢索機制從報告和外部知識來源中提取相關的醫療實體和關係。引入了三階段推理過程，將任務分解為錯誤檢測、定位和校正子任務，這增強了系統的可解釋性和性能。該方法的有效性使用基於領域專家的指導，通過破壞真實世界的放射科報告並加入實際錯誤而建立的基準資料集進行評估。實驗結果證明了所提出方法的優點，內部和外部檢索的結合顯著提高了各種最先進的 LLM 的錯誤檢測、定位和校正的準確性。這些發現有助於開發更強大、更可靠的臨床文件錯誤校正系統。

##### **From Overfitting to Robustness: Quantity, Quality, and Variety Oriented Negative Sample Selection in Graph Contrastive Learning**
2406.15044v1 by Adnan Ali, Jinlong Li, Huanhuan Chen, Ali Kashif Bashir

Graph contrastive learning (GCL) aims to contrast positive-negative
counterparts to learn the node embeddings, whereas graph data augmentation
methods are employed to generate these positive-negative samples. The
variation, quantity, and quality of negative samples compared to positive
samples play crucial roles in learning meaningful embeddings for node
classification downstream tasks. Less variation, excessive quantity, and
low-quality negative samples cause the model to be overfitted for particular
nodes, resulting in less robust models. To solve the overfitting problem in the
GCL paradigm, this study proposes a novel Cumulative Sample Selection (CSS)
algorithm by comprehensively considering negative samples' quality, variations,
and quantity. Initially, three negative sample pools are constructed: easy,
medium, and hard negative samples, which contain 25%, 50%, and 25% of the total
available negative samples, respectively. Then, 10% negative samples are
selected from each of these three negative sample pools for training the model.
After that, a decision agent module evaluates model training results and
decides whether to explore more negative samples from three negative sample
pools by increasing the ratio or keep exploiting the current sampling ratio.
The proposed algorithm is integrated into a proposed graph contrastive learning
framework named NegAmplify. NegAmplify is compared with the SOTA methods on
nine graph node classification datasets, with seven achieving better node
classification accuracy with up to 2.86% improvement.

摘要：圖形對比學習 (GCL) 旨在對比正負對應物以學習節點嵌入，而圖形數據擴充方法則用於生成這些正負範例。與正範例相比，負範例的變化、數量和品質在為節點分類下游任務學習有意義的嵌入中扮演著至關重要的角色。較少的變化、過多的數量和低品質的負範例會導致模型對特定節點過度擬合，從而導致模型的穩健性降低。為了解決 GCL 典範中的過度擬合問題，本研究提出了一種新穎的累積範例選取 (CSS) 演算法，全面考慮負範例的品質、變化和數量。最初，構建了三個負範例池：容易、中等和困難負範例，分別包含總可用負範例的 25%、50% 和 25%。然後，從這三個負範例池中的每個範例池中選取 10% 的負範例來訓練模型。在那之後，決策代理模組會評估模型訓練結果，並決定是否透過增加比率從三個負範例池中探索更多負範例，或繼續利用目前的抽樣比率。所提出的演算法整合到一個名為 NegAmplify 的提議圖形對比學習架構中。NegAmplify 與 SOTA 方法在九個圖形節點分類資料集上進行比較，其中七個節點分類準確度提高，改進幅度最高達 2.86%。

##### **Behaviour Distillation**
2406.15042v1 by Andrei Lupu, Chris Lu, Jarek Liesen, Robert Tjarko Lange, Jakob Foerster

Dataset distillation aims to condense large datasets into a small number of
synthetic examples that can be used as drop-in replacements when training new
models. It has applications to interpretability, neural architecture search,
privacy, and continual learning. Despite strong successes in supervised
domains, such methods have not yet been extended to reinforcement learning,
where the lack of a fixed dataset renders most distillation methods unusable.
Filling the gap, we formalize behaviour distillation, a setting that aims to
discover and then condense the information required for training an expert
policy into a synthetic dataset of state-action pairs, without access to expert
data. We then introduce Hallucinating Datasets with Evolution Strategies
(HaDES), a method for behaviour distillation that can discover datasets of just
four state-action pairs which, under supervised learning, train agents to
competitive performance levels in continuous control tasks. We show that these
datasets generalize out of distribution to training policies with a wide range
of architectures and hyperparameters. We also demonstrate application to a
downstream task, namely training multi-task agents in a zero-shot fashion.
Beyond behaviour distillation, HaDES provides significant improvements in
neuroevolution for RL over previous approaches and achieves SoTA results on one
standard supervised dataset distillation task. Finally, we show that
visualizing the synthetic datasets can provide human-interpretable task
insights.

摘要：<paragraph>資料集蒸餾旨在將大型資料集濃縮成少量的合成範例，這些範例可用作訓練新模型時的立即替換。它可應用於可解釋性、神經架構搜尋、隱私和持續學習。儘管在監督式領域取得了顯著的成功，但這些方法尚未擴展到強化學習，因為缺乏固定資料集，導致大多數蒸餾方法無法使用。為了填補這一空白，我們正式制定了行為蒸餾，這是一個旨在發現並濃縮訓練專家策略所需的資訊，並將其濃縮成狀態動作對的合成資料集，而無需存取專家資料。然後，我們引入了使用進化策略（HaDES）的幻覺資料集，這是一種行為蒸餾方法，可以發現僅包含四個狀態動作對的資料集，在監督式學習下，訓練代理程式以競爭的效能等級執行連續控制任務。我們表明，這些資料集可以推廣到具有廣泛架構和超參數的訓練策略的分配之外。我們還展示了對下游任務的應用，即以零次學習的方式訓練多任務代理程式。除了行為蒸餾之外，HaDES 還顯著改進了 RL 的神經演化，超越了以前的方法，並在一個標準的監督式資料集蒸餾任務中取得了 SoTA 結果。最後，我們表明，將合成資料集視覺化可以提供人類可解釋的任務見解。</paragraph>

##### **GiusBERTo: A Legal Language Model for Personal Data De-identification in Italian Court of Auditors Decisions**
2406.15032v1 by Giulio Salierno, Rosamaria Bertè, Luca Attias, Carla Morrone, Dario Pettazzoni, Daniela Battisti

Recent advances in Natural Language Processing have demonstrated the
effectiveness of pretrained language models like BERT for a variety of
downstream tasks. We present GiusBERTo, the first BERT-based model specialized
for anonymizing personal data in Italian legal documents. GiusBERTo is trained
on a large dataset of Court of Auditors decisions to recognize entities to
anonymize, including names, dates, locations, while retaining contextual
relevance. We evaluate GiusBERTo on a held-out test set and achieve 97%
token-level accuracy. GiusBERTo provides the Italian legal community with an
accurate and tailored BERT model for de-identification, balancing privacy and
data protection.

摘要：自然語言處理的最新進展已證明，像 BERT 等預訓練語言模型對各種下游任務都很有效。我們提出 GiusBERTo，這是第一個專門用於匿名化義大利法律文件中的個人資料的 BERT-based 模型。GiusBERTo 接受過大量審計法院判決資料集的訓練，以識別要匿名的實體，包括姓名、日期、地點，同時保留上下文相關性。我們在持有的測試集上評估 GiusBERTo，並達到 97% 的代幣級準確度。GiusBERTo 為義大利法律界提供了一個準確且量身定制的 BERT 模型，用於去識別，平衡隱私和資料保護。

##### **MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens**
2406.15019v1 by Yongqi Fan, Hongli Sun, Kui Xue, Xiaofan Zhang, Shaoting Zhang, Tong Ruan

Numerous advanced Large Language Models (LLMs) now support context lengths up
to 128K, and some extend to 200K. Some benchmarks in the generic domain have
also followed up on evaluating long-context capabilities. In the medical
domain, tasks are distinctive due to the unique contexts and need for domain
expertise, necessitating further evaluation. However, despite the frequent
presence of long texts in medical scenarios, evaluation benchmarks of
long-context capabilities for LLMs in this field are still rare. In this paper,
we propose MedOdyssey, the first medical long-context benchmark with seven
length levels ranging from 4K to 200K tokens. MedOdyssey consists of two
primary components: the medical-context "needles in a haystack" task and a
series of tasks specific to medical applications, together comprising 10
datasets. The first component includes challenges such as counter-intuitive
reasoning and novel (unknown) facts injection to mitigate knowledge leakage and
data contamination of LLMs. The second component confronts the challenge of
requiring professional medical expertise. Especially, we design the ``Maximum
Identical Context'' principle to improve fairness by guaranteeing that
different LLMs observe as many identical contexts as possible. Our experiment
evaluates advanced proprietary and open-source LLMs tailored for processing
long contexts and presents detailed performance analyses. This highlights that
LLMs still face challenges and need for further research in this area. Our code
and data are released in the repository:
\url{https://github.com/JOHNNY-fans/MedOdyssey.}

摘要：目前許多進階大型語言模型 (LLM) 支援長達 128K 的脈絡長度，有些甚至延伸至 200K。通用領域中的一些基準也開始評估長脈絡能力。在醫療領域，由於脈絡獨特且需要領域專業知識，因此任務具有獨特性，需要進一步評估。然而，儘管醫療場景中經常出現長篇文字，但針對此領域中 LLM 長脈絡能力的評估基準仍然很少見。在本文中，我們提出 MedOdyssey，這是第一個醫療長脈絡基準，包含七個長度等級，範圍從 4K 到 200K 個符號。MedOdyssey 包含兩個主要組成部分：醫療脈絡「大海撈針」任務和一系列特定於醫療應用程式的任務，共包含 10 個資料集。第一個組成部分包含反直覺推理和新穎（未知）事實注入等挑戰，以減輕 LLM 的知識外洩和資料污染。第二個組成部分則應對需要專業醫療專業知識的挑戰。特別是，我們設計了「最大相同脈絡」原則，透過確保不同的 LLM 觀察到盡可能多的相同脈絡來提升公平性。我們的實驗評估了專為處理長脈絡而量身打造的進階專有和開放原始碼 LLM，並提供詳細的效能分析。這突顯了 LLM 仍面臨挑戰，並需要進一步研究這個領域。我們的程式碼和資料已在儲存庫中釋出：\url{https://github.com/JOHNNY-fans/MedOdyssey.}

##### **Evolution of Rewards for Food and Motor Action by Simulating Birth and Death**
2406.15016v1 by Yuji Kanagawa, Kenji Doya

The reward system is one of the fundamental drivers of animal behaviors and
is critical for survival and reproduction. Despite its importance, the problem
of how the reward system has evolved is underexplored. In this paper, we try to
replicate the evolution of biologically plausible reward functions and
investigate how environmental conditions affect evolved rewards' shape. For
this purpose, we developed a population-based decentralized evolutionary
simulation framework, where agents maintain their energy level to live longer
and produce more children. Each agent inherits its reward function from its
parent subject to mutation and learns to get rewards via reinforcement learning
throughout its lifetime. Our results show that biologically reasonable positive
rewards for food acquisition and negative rewards for motor action can evolve
from randomly initialized ones. However, we also find that the rewards for
motor action diverge into two modes: largely positive and slightly negative.
The emergence of positive motor action rewards is surprising because it can
make agents too active and inefficient in foraging. In environments with poor
and poisonous foods, the evolution of rewards for less important foods tends to
be unstable, while rewards for normal foods are still stable. These results
demonstrate the usefulness of our simulation environment and energy-dependent
birth and death model for further studies of the origin of reward systems.

摘要：獎勵系統是動物行為的基本驅動力之一，對生存和繁殖至關重要。儘管其重要性，但獎勵系統如何演化的問題卻鮮少被探討。在本文中，我們嘗試複製生物上合理的獎勵函數的演化，並探討環境條件如何影響演化獎勵的形狀。為此，我們開發了一個基於族群的分散式演化模擬架構，其中代理人維持其能量水平以延長壽命並生下更多孩子。每個代理人都從其父母那裡繼承其獎勵函數，但會發生突變，並在一生中透過強化學習學會獲得獎勵。我們的結果表明，生物上合理的正向食物獲取獎勵和負向運動動作獎勵可以從隨機初始化的獎勵演化而來。然而，我們也發現運動動作的獎勵分歧為兩種模式：大部分為正向和略為負向。正向運動動作獎勵的出現令人驚訝，因為它可能使代理人過於活躍且在覓食中效率低下。在食物貧乏且有毒的環境中，對不太重要的食物的獎勵演化趨於不穩定，而對正常食物的獎勵仍然穩定。這些結果證明了我們的模擬環境和能量依賴型出生死亡模型對進一步研究獎勵系統的起源很有用。

##### **GraLMatch: Matching Groups of Entities with Graphs and Language Models**
2406.15015v1 by Fernando De Meer Pardo, Claude Lehmann, Dennis Gehrig, Andrea Nagy, Stefano Nicoli, Branka Hadji Misheva, Martin Braschler, Kurt Stockinger

In this paper, we present an end-to-end multi-source Entity Matching problem,
which we call entity group matching, where the goal is to assign to the same
group, records originating from multiple data sources but representing the same
real-world entity. We focus on the effects of transitively matched records,
i.e. the records connected by paths in the graph G = (V,E) whose nodes and
edges represent the records and whether they are a match or not. We present a
real-world instance of this problem, where the challenge is to match records of
companies and financial securities originating from different data providers.
We also introduce two new multi-source benchmark datasets that present similar
matching challenges as real-world records. A distinctive characteristic of
these records is that they are regularly updated following real-world events,
but updates are not applied uniformly across data sources. This phenomenon
makes the matching of certain groups of records only possible through the use
of transitive information.
  In our experiments, we illustrate how considering transitively matched
records is challenging since a limited amount of false positive pairwise match
predictions can throw off the group assignment of large quantities of records.
Thus, we propose GraLMatch, a method that can partially detect and remove false
positive pairwise predictions through graph-based properties. Finally, we
showcase how fine-tuning a Transformer-based model (DistilBERT) on a reduced
number of labeled samples yields a better final entity group matching than
training on more samples and/or incorporating fine-tuning optimizations,
illustrating how precision becomes the deciding factor in the entity group
matching of large volumes of records.

摘要：<paragraph>在本文中，我們提出了端到端的跨來源實體比對問題，
我們稱之為實體群組比對，目標是將來自多個資料來源但代表同一個
真實世界實體的記錄指派到同一個群組。我們專注於傳遞比對記錄的影響，
也就是說，在圖形 G = (V,E) 中由路徑連接的記錄，其節點和邊緣代表記錄以及它們是否相符。我們提出這個問題的一個真實世界實例，其中挑戰在於比對來自不同資料提供者的公司和金融證券的記錄。
我們還引入了兩個新的跨來源基準資料集，它們呈現與真實世界記錄相似的比對挑戰。
這些記錄的一個顯著特徵是它們會定期更新以遵循真實世界的事件，
但更新並未在所有資料來源中均勻套用。這種現象使得只有透過使用
傳遞資訊才能比對某些群組的記錄。
在我們的實驗中，我們說明考量傳遞比對記錄具有挑戰性，因為有限量的假陽性成對比對預測可能會影響大量記錄的群組指派。
因此，我們提出 GraLMatch，一種可透過基於圖形的屬性部分偵測並移除假陽性成對預測的方法。最後，我們展示如何針對減少的標籤樣本微調基於 Transformer 的模型 (DistilBERT) 會產生比在更多樣本上訓練和/或納入微調最佳化更好的最終實體群組比對，說明精確度如何成為大量記錄的實體群組比對中的決定因素。</paragraph>

##### **RouteFinder: Towards Foundation Models for Vehicle Routing Problems**
2406.15007v1 by Federico Berto, Chuanbo Hua, Nayeli Gast Zepeda, André Hottung, Niels Wouda, Leon Lan, Kevin Tierney, Jinkyoo Park

Vehicle Routing Problems (VRPs) are optimization problems with significant
real-world implications in logistics, transportation, and supply chain
management. Despite the recent progress made in learning to solve individual
VRP variants, there is a lack of a unified approach that can effectively tackle
a wide range of tasks, which is crucial for real-world impact. This paper
introduces RouteFinder, a framework for developing foundation models for VRPs.
Our key idea is that a foundation model for VRPs should be able to model
variants by treating each variant as a subset of a larger VRP problem, equipped
with different attributes. We introduce a parallelized environment that can
handle any combination of attributes at the same time in a batched manner, and
an efficient sampling procedure to train on a mix of problems at each
optimization step that can greatly improve convergence robustness. We also
introduce novel Global Feature Embeddings that project instance-wise attributes
efficiently onto the latent space and help the model understand different VRP
variants. Finally, we introduce Efficient Adapter Layers, a simple yet
effective technique to finetune pre-trained RouteFinder models to solve novel
variants with previously unseen attributes outside of the original feature
space. We validate our approach through extensive experiments on 24 VRP
variants, demonstrating competitive results over recent multi-task learning
models. We make our code openly available at
https://github.com/ai4co/routefinder.

摘要：車輛路線問題 (VRP) 是最佳化問題，在物流、運輸和供應鏈管理中具有重要的現實世界意義。儘管在學習解決個別 VRP 變體方面取得了進展，但缺乏統一的方法來有效應對廣泛的任務，這對於現實世界的影響至關重要。本文介紹了 RouteFinder，一個用於開發 VRP 基礎模型的框架。我們的關鍵思想是，VRP 的基礎模型應該能夠通過將每個變體視為具有不同屬性的較大 VRP 問題的子集來建模變體。我們引入了一個並行環境，它可以同時以批次方式處理任何屬性組合，並在每個最佳化步驟中引入一個有效的採樣程序來訓練混合問題，這可以大大提高收斂魯棒性。我們還引入了新的全局特徵嵌入，它將實例屬性有效地投影到潛在空間，並幫助模型理解不同的 VRP 變體。最後，我們引入了高效適配層，這是一種簡單但有效的技術，用於微調預先訓練的 RouteFinder 模型，以解決原始特徵空間之外具有以前未見屬性的新變體。我們通過對 24 個 VRP 變體進行廣泛的實驗驗證了我們的做法，展示了優於近期多任務學習模型的競爭結果。我們在 https://github.com/ai4co/routefinder 上公開我們的代碼。

##### **Unveiling the Impact of Multi-Modal Interactions on User Engagement: A Comprehensive Evaluation in AI-driven Conversations**
2406.15000v1 by Lichao Zhang, Jia Yu, Shuai Zhang, Long Li, Yangyang Zhong, Guanbao Liang, Yuming Yan, Qing Ma, Fangsheng Weng, Fayu Pan, Jing Li, Renjun Xu, Zhenzhong Lan

Large Language Models (LLMs) have significantly advanced user-bot
interactions, enabling more complex and coherent dialogues. However, the
prevalent text-only modality might not fully exploit the potential for
effective user engagement. This paper explores the impact of multi-modal
interactions, which incorporate images and audio alongside text, on user
engagement in chatbot conversations. We conduct a comprehensive analysis using
a diverse set of chatbots and real-user interaction data, employing metrics
such as retention rate and conversation length to evaluate user engagement. Our
findings reveal a significant enhancement in user engagement with multi-modal
interactions compared to text-only dialogues. Notably, the incorporation of a
third modality significantly amplifies engagement beyond the benefits observed
with just two modalities. These results suggest that multi-modal interactions
optimize cognitive processing and facilitate richer information comprehension.
This study underscores the importance of multi-modality in chatbot design,
offering valuable insights for creating more engaging and immersive AI
communication experiences and informing the broader AI community about the
benefits of multi-modal interactions in enhancing user engagement.

摘要：大型語言模型 (LLM) 已顯著提升使用者機器人互動，促成更複雜、更連貫的對話。然而，普遍僅使用文字的方式可能無法充分發揮有效使用者參與的潛力。本文探討多模態互動的影響，其中在文字之外納入影像和音訊，對於聊天機器人對話中的使用者參與。我們使用多元的聊天機器人及真實使用者互動資料進行全面分析，採用保留率和對話長度等指標來評估使用者參與。我們的研究結果顯示，與僅使用文字的對話相比，多模態互動顯著提升了使用者參與。值得注意的是，加入第三個模態會大幅提升參與度，超越僅使用兩個模態時觀察到的效益。這些結果顯示，多模態互動最佳化了認知處理，並促進更豐富的資訊理解。本研究強調了多模態在聊天機器人設計中的重要性，提供了寶貴的見解，用於創造更具吸引力和身歷其境的 AI 溝通體驗，並讓更廣泛的 AI 社群了解多模態互動在提升使用者參與方面的優點。

##### **Disability Representations: Finding Biases in Automatic Image Generation**
2406.14993v1 by Yannis Tevissen

Recent advancements in image generation technology have enabled widespread
access to AI-generated imagery, prominently used in advertising, entertainment,
and progressively in every form of visual content. However, these technologies
often perpetuate societal biases. This study investigates the representation
biases in popular image generation models towards people with disabilities
(PWD). Through a comprehensive experiment involving several popular
text-to-image models, we analyzed the depiction of disability. The results
indicate a significant bias, with most generated images portraying disabled
individuals as old, sad, and predominantly using manual wheelchairs. These
findings highlight the urgent need for more inclusive AI development, ensuring
diverse and accurate representation of PWD in generated images. This research
underscores the importance of addressing and mitigating biases in AI models to
foster equitable and realistic representations.

摘要：最近影像生成技術的進步使大眾能廣泛接觸到 AI 生成的影像，這些影像在廣告、娛樂產業中廣泛使用，並逐漸運用於各種視覺內容中。然而，這些技術常常會強化社會偏見。本研究探討了熱門影像生成模型對於身障人士 (PWD) 的表徵偏見。我們透過一項包含多種熱門文字轉影像模型的綜合實驗，分析了身障人士的描繪方式。結果顯示了顯著的偏見，大多數產生的影像都將身障人士描繪成年老、悲傷，且主要使用手動輪椅。這些發現突顯了更具包容性的 AI 開發的迫切需求，以確保在產生的影像中對 PWD 進行多元且準確的表徵。這項研究強調了在 AI 模型中解決和減輕偏見以促進公平且真實的表徵的重要性。

##### **SpreadsheetBench: Towards Challenging Real World Spreadsheet Manipulation**
2406.14991v1 by Zeyao Ma, Bohan Zhang, Jing Zhang, Jifan Yu, Xiaokang Zhang, Xiaohan Zhang, Sijia Luo, Xi Wang, Jie Tang

We introduce SpreadsheetBench, a challenging spreadsheet manipulation
benchmark exclusively derived from real-world scenarios, designed to immerse
current large language models (LLMs) in the actual workflow of spreadsheet
users. Unlike existing benchmarks that rely on synthesized queries and
simplified spreadsheet files, SpreadsheetBench is built from 912 real questions
gathered from online Excel forums, which reflect the intricate needs of users.
The associated spreadsheets from the forums contain a variety of tabular data
such as multiple tables, non-standard relational tables, and abundant
non-textual elements. Furthermore, we propose a more reliable evaluation metric
akin to online judge platforms, where multiple spreadsheet files are created as
test cases for each instruction, ensuring the evaluation of robust solutions
capable of handling spreadsheets with varying values. Our comprehensive
evaluation of various LLMs under both single-round and multi-round inference
settings reveals a substantial gap between the state-of-the-art (SOTA) models
and human performance, highlighting the benchmark's difficulty.

摘要：我們介紹 SpreadsheetBench，這是一個具有挑戰性的試算表操作基準測試，專門從真實世界的場景中衍生而來，旨在讓當前的巨量語言模型 (LLM) 沉浸在試算表使用者的實際工作流程中。與依賴於合成查詢和簡化試算表檔案的現有基準測試不同，SpreadsheetBench 是從線上 Excel 論壇中收集的 912 個真實問題所建構而成，這些問題反映了使用者的複雜需求。論壇中的相關試算表包含各種表格資料，例如多個表格、非標準關聯表格和豐富的非文字元素。此外，我們提出了一個更可靠的評估指標，類似於線上評審平台，其中多個試算表檔案被建立為每個指令的測試案例，確保評估健全的解決方案，能夠處理具有不同值的試算表。我們對各種 LLM 在單回合和多回合推理設定下的全面評估，揭示了最先進 (SOTA) 模型與人類效能之間的顯著差距，突顯了基準測試的難度。

##### **Introducing the Biomechanics-Function Relationship in Glaucoma: Improved Visual Field Loss Predictions from intraocular pressure-induced Neural Tissue Strains**
2406.14988v1 by Thanadet Chuangsuwanich, Monisha E. Nongpiur, Fabian A. Braeu, Tin A. Tun, Alexandre Thiery, Shamira Perera, Ching Lin Ho, Martin Buist, George Barbastathis, Tin Aung, Michaël J. A. Girard

Objective. (1) To assess whether neural tissue structure and biomechanics
could predict functional loss in glaucoma; (2) To evaluate the importance of
biomechanics in making such predictions. Design, Setting and Participants. We
recruited 238 glaucoma subjects. For one eye of each subject, we imaged the
optic nerve head (ONH) using spectral-domain OCT under the following
conditions: (1) primary gaze and (2) primary gaze with acute IOP elevation.
Main Outcomes: We utilized automatic segmentation of optic nerve head (ONH)
tissues and digital volume correlation (DVC) analysis to compute intraocular
pressure (IOP)-induced neural tissue strains. A robust geometric deep learning
approach, known as Point-Net, was employed to predict the full Humphrey 24-2
pattern standard deviation (PSD) maps from ONH structural and biomechanical
information. For each point in each PSD map, we predicted whether it exhibited
no defect or a PSD value of less than 5%. Predictive performance was evaluated
using 5-fold cross-validation and the F1-score. We compared the model's
performance with and without the inclusion of IOP-induced strains to assess the
impact of biomechanics on prediction accuracy. Results: Integrating
biomechanical (IOP-induced neural tissue strains) and structural (tissue
morphology and neural tissues thickness) information yielded a significantly
better predictive model (F1-score: 0.76+-0.02) across validation subjects, as
opposed to relying only on structural information, which resulted in a
significantly lower F1-score of 0.71+-0.02 (p < 0.05). Conclusion: Our study
has shown that the integration of biomechanical data can significantly improve
the accuracy of visual field loss predictions. This highlights the importance
of the biomechanics-function relationship in glaucoma, and suggests that
biomechanics may serve as a crucial indicator for the development and
progression of glaucoma.

摘要：<paragraph>目的。 (1) 評估神經組織結構和生物力學是否能預測青光眼的視力喪失；(2) 評估生物力學在做出此類預測中的重要性。設計、環境和參與者。我們招募了 238 名青光眼患者。對於每位患者的一隻眼睛，我們在以下條件下使用光譜域 OCT 對視神經盤 (ONH) 進行影像： (1) 初級凝視和 (2) 初級凝視伴急性 IOP 升高。主要結果：我們利用視神經盤 (ONH) 組織的自動分割和數位體積相關 (DVC) 分析來計算眼內壓 (IOP) 誘發的神經組織應變。一種稱為 Point-Net 的強健幾何深度學習方法被用於從 ONH 結構和生物力學資訊預測完全的 Humphrey 24-2 模式標準差 (PSD) 圖。對於每個 PSD 圖中的每個點，我們預測它是否沒有缺陷或 PSD 值小於 5%。預測性能使用 5 倍交叉驗證和 F1 分數進行評估。我們比較了模型在包含和不包含 IOP 誘發應變的情況下的性能，以評估生物力學對預測精度的影響。結果：整合生物力學（IOP 誘發的神經組織應變）和結構（組織形態和神經組織厚度）資訊產生了一個顯著更好的預測模型（F1 分數：0.76+-0.02），跨驗證受試者，而不是僅依賴結構資訊，這導致 F1 分數顯著降低，為 0.71+-0.02（p < 0.05）。結論：我們的研究表明，整合生物力學數據可以顯著提高視野喪失預測的準確性。這突出了生物力學功能關係在青光眼中的重要性，並表明生物力學可以作為青光眼發展和進展的一個關鍵指標。</paragraph>

##### **Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers**
2406.14986v1 by Manuel Mondal, Ljiljana Dolamic, Gérôme Bovet, Philippe Cudré-Mauroux

Prompting and Multiple Choices Questions (MCQ) have become the preferred
approach to assess the capabilities of Large Language Models (LLMs), due to
their ease of manipulation and evaluation. Such experimental appraisals have
pointed toward the LLMs' apparent ability to perform causal reasoning or to
grasp uncertainty. In this paper, we investigate whether these abilities are
measurable outside of tailored prompting and MCQ by reformulating these issues
as direct text completion - the foundation of LLMs. To achieve this goal, we
define scenarios with multiple possible outcomes and we compare the prediction
made by the LLM through prompting (their Stated Answer) to the probability
distributions they compute over these outcomes during next token prediction
(their Revealed Belief). Our findings suggest that the Revealed Belief of LLMs
significantly differs from their Stated Answer and hint at multiple biases and
misrepresentations that their beliefs may yield in many scenarios and outcomes.
As text completion is at the core of LLMs, these results suggest that common
evaluation methods may only provide a partial picture and that more research is
needed to assess the extent and nature of their capabilities.

摘要：提示和多選題 (MCQ) 已成為評估大型語言模型 (LLM) 能力的首選方法，因為它們易於操作和評估。此類實驗評估已指向 LLM 執行因果推理或掌握不確定性的明顯能力。在本文中，我們探討這些能力是否可以在量身定制的提示和 MCQ 之外進行測量，方法是將這些問題重新表述為直接文本完成 - LLM 的基礎。為了實現這一目標，我們定義了具有多種可能結果的場景，並且我們將 LLM 通過提示做出的預測（他們的陳述答案）與他們在下一代幣預測期間在這些結果上計算的機率分佈（他們的已揭示信念）進行比較。我們的研究結果表明，LLM 的已揭示信念與他們的陳述答案有顯著差異，並暗示他們的信念在許多場景和結果中可能產生的多種偏見和錯誤陳述。由於文本完成是 LLM 的核心，這些結果表明常見的評估方法可能只提供部分畫面，並且需要更多的研究來評估其能力的程度和性質。

##### **Human-AI collectives produce the most accurate differential diagnoses**
2406.14981v1 by N. Zöller, J. Berger, I. Lin, N. Fu, J. Komarneni, G. Barabucci, K. Laskowski, V. Shia, B. Harack, E. A. Chu, V. Trianni, R. H. J. M. Kurvers, S. M. Herzog

Artificial intelligence systems, particularly large language models (LLMs),
are increasingly being employed in high-stakes decisions that impact both
individuals and society at large, often without adequate safeguards to ensure
safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are
biased - shortcomings that may reflect LLMs' inherent limitations and thus may
not be remedied by more sophisticated architectures, more data, or more human
feedback. Relying solely on LLMs for complex, high-stakes decisions is
therefore problematic. Here we present a hybrid collective intelligence system
that mitigates these risks by leveraging the complementary strengths of human
experience and the vast information processed by LLMs. We apply our method to
open-ended medical diagnostics, combining 40,762 differential diagnoses made by
physicians with the diagnoses of five state-of-the art LLMs across 2,133
medical cases. We show that hybrid collectives of physicians and LLMs
outperform both single physicians and physician collectives, as well as single
LLMs and LLM ensembles. This result holds across a range of medical specialties
and professional experience, and can be attributed to humans' and LLMs'
complementary contributions that lead to different kinds of errors. Our
approach highlights the potential for collective human and machine intelligence
to improve accuracy in complex, open-ended domains like medical diagnostics.

摘要：人工智慧系統，尤其是大型語言模型 (LLM)，
越來越常被用於影響個人和整個社會的高風險決策，但通常沒有足夠的防護措施來確保
安全、品質和公平性。然而，LLM 會產生幻覺、缺乏常識，並且有偏見 - 這些缺點可能反映出 LLM 固有的限制，因此可能無法透過更精密的架構、更多資料或更多人類回饋來補救。因此，僅依賴 LLM 來做出複雜、高風險的決策是有問題的。在此，我們提出一個混合集體智慧系統，透過利用人類經驗和 LLM 處理的龐大資訊的互補優勢來降低這些風險。我們將方法應用於開放式醫療診斷，結合醫師做出的 40,762 個鑑別診斷，以及五個最先進的 LLM 在 2,133 個醫療案例中的診斷。我們證明，醫師和 LLM 的混合集體優於單一醫師和醫師集體，以及單一 LLM 和 LLM 整合。這個結果適用於各種醫療專科和專業經驗，並且可以歸因於人類和 LLM 的互補貢獻，導致不同類型的錯誤。我們的做法突顯了集體人類和機器智慧在改善醫療診斷等複雜、開放式領域中的準確性的潛力。

##### **Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation**
2406.14979v1 by Yuanjie Lyu, Zihan Niu, Zheyong Xie, Chao Zhang, Tong Xu, Yang Wang, Enhong Chen

Despite the significant progress of large language models (LLMs) in various
tasks, they often produce factual errors due to their limited internal
knowledge. Retrieval-Augmented Generation (RAG), which enhances LLMs with
external knowledge sources, offers a promising solution. However, these methods
can be misled by irrelevant paragraphs in retrieved documents. Due to the
inherent uncertainty in LLM generation, inputting the entire document may
introduce off-topic information, causing the model to deviate from the central
topic and affecting the relevance of the generated content. To address these
issues, we propose the Retrieve-Plan-Generation (RPG) framework. RPG generates
plan tokens to guide subsequent generation in the plan stage. In the answer
stage, the model selects relevant fine-grained paragraphs based on the plan and
uses them for further answer generation. This plan-answer process is repeated
iteratively until completion, enhancing generation relevance by focusing on
specific topics. To implement this framework efficiently, we utilize a simple
but effective multi-task prompt-tuning method, enabling the existing LLMs to
handle both planning and answering. We comprehensively compare RPG with
baselines across 5 knowledge-intensive generation tasks, demonstrating the
effectiveness of our approach.

摘要：儘管大型語言模型 (LLM) 在各種任務中取得顯著進展，但由於其內部知識有限，它們經常會產生事實性錯誤。擷取增強生成 (RAG) 透過外部知識來源增強 LLM，提供了一個有前途的解決方案。然而，這些方法可能會被擷取文件中不相關的段落誤導。由於 LLM 生成中固有的不確定性，輸入整個文件可能會引入離題資訊，導致模型偏離中心主題並影響所生成內容的相關性。為了解決這些問題，我們提出了擷取-規劃-生成 (RPG) 架構。RPG 會在規劃階段產生規劃代碼，以引導後續生成。在回答階段，模型會根據規劃選擇相關的細緻段落，並使用它們進一步生成答案。此規劃-回答程序會反覆執行，直到完成，透過專注於特定主題來增強生成相關性。為了有效地實作此架構，我們利用一種簡單但有效的多任務提示調整方法，讓現有的 LLM 能夠處理規劃和回答。我們全面比較了 RPG 與 5 項知識密集型生成任務的基準，證明了我們方法的有效性。

##### **A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems**
2406.14972v1 by Florin Cuconasu, Giovanni Trappolini, Nicola Tonellotto, Fabrizio Silvestri

Retrieval Augmented Generation (RAG) represents a significant advancement in
artificial intelligence combining a retrieval phase with a generative phase,
with the latter typically being powered by large language models (LLMs). The
current common practices in RAG involve using "instructed" LLMs, which are
fine-tuned with supervised training to enhance their ability to follow
instructions and are aligned with human preferences using state-of-the-art
techniques. Contrary to popular belief, our study demonstrates that base models
outperform their instructed counterparts in RAG tasks by 20% on average under
our experimental settings. This finding challenges the prevailing assumptions
about the superiority of instructed LLMs in RAG applications. Further
investigations reveal a more nuanced situation, questioning fundamental aspects
of RAG and suggesting the need for broader discussions on the topic; or, as
Fromm would have it, "Seldom is a glance at the statistics enough to understand
the meaning of the figures".

摘要：檢索增強生成（RAG）代表人工智慧的一大進步，它結合檢索階段和生成階段，後者通常由大型語言模型（LLM）提供支援。目前 RAG 的常見做法包括使用「指示式」LLM，這些 LLM 經過監督式訓練進行微調，以增強其遵循指示的能力，並使用最先進的技術與人類偏好保持一致。與普遍的看法相反，我們的研究表明，在我們的實驗設定下，基礎模型在 RAG 任務中平均比其指示式對應模型高出 20%。這一發現挑戰了關於指示式 LLM 在 RAG 應用中優越性的普遍假設。進一步的調查揭示了一個更為細緻的情況，質疑了 RAG 的基本方面，並表明需要對這個主題進行更廣泛的討論；或者，正如 Fromm 所說的，「僅僅看一眼統計數據是不足以理解數字含義的」。

##### **Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging: A Comprehensive Evaluation**
2406.14971v1 by Shamane Siriwardhana, Mark McQuade, Thomas Gauthier, Lucas Atkins, Fernando Fernandes Neto, Luke Meyers, Anneketh Vij, Tyler Odenthal, Charles Goddard, Mary MacCarthy, Jacob Solawetz

We conducted extensive experiments on domain adaptation of the
Meta-Llama-3-70B-Instruct model on SEC data, exploring its performance on both
general and domain-specific benchmarks. Our focus included continual
pre-training (CPT) and model merging, aiming to enhance the model's
domain-specific capabilities while mitigating catastrophic forgetting. Through
this study, we evaluated the impact of integrating financial regulatory data
into a robust language model and examined the effectiveness of our model
merging techniques in preserving and improving the model's instructive
abilities. The model is accessible at hugging face:
https://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base.
This is an intermediate checkpoint of our final model, which has seen 20B
tokens so far. The full model is still in the process of training. This is a
preprint technical report with thorough evaluations to understand the entire
process.

摘要：我們對 Meta-Llama-3-70B-Instruct 模型在 SEC 數據上的領域適應進行了廣泛的實驗，探討了它在通用和特定領域基準上的效能。我們的重點包括持續預訓練 (CPT) 和模型合併，目的是增強模型的特定領域能力，同時減輕災難性遺忘。透過這項研究，我們評估了將金融監管數據整合到強大的語言模型中的影響，並檢視了我們的模型合併技術在保留和改善模型指導能力方面的有效性。模型可以在 hugging face 取得：
https://huggingface.co/arcee-ai/Llama-3-SEC-Base, arcee-ai/Llama-3-SEC-Base。
這是我們最終模型的其中一個中間檢查點，到目前為止已經看到 20B 個代幣。完整模型仍在訓練過程中。這是一份預印本技術報告，包含深入的評估，以了解整個過程。

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v1 by Xiaohong Ji, Wang Zhen, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

摘要：近年來，預訓練模型在自然語言處理 (NLP)、電腦視覺 (CV) 和生命科學領域取得了顯著進展。NLP 和 CV 的顯著進展主要由模型參數和資料大小的擴充所推動，這種現象現在被認為是規模化定律。然而，探索分子預訓練模型中規模化定律的研究仍然未被探索。在這項工作中，我們提出了 Uni-Mol2，一種創新的分子預訓練模型，它利用雙軌Transformer在原子層級、圖層級和幾何結構層級有效地整合特徵。除此之外，我們系統性地研究了分子預訓練模型中的規模化定律，描述了驗證損失與模型大小、資料集大小和計算資源之間的冪律相關性。因此，我們成功地將 Uni-Mol2 擴展到 11 億個參數，並通過對 8 億個構形進行預訓練，使其成為迄今為止最大的分子預訓練模型。大量的實驗表明，隨著模型大小的增長，下游任務的表現持續改善。擁有 11B 參數的 Uni-Mol2 也優於現有方法，在 QM9 上平均改善了 27%，在 COMPAS-1D 資料集上改善了 14%。

##### **Unlocking the Global Synergies in Low-Rank Adapters**
2406.14956v1 by Zixi Zhang, Cheng Zhang, Xitong Gao, Robert D. Mullins, George A. Constantinides, Yiren Zhao

Low-rank Adaption (LoRA) has been the de-facto parameter-efficient
fine-tuning technique for large language models. We present HeteroLoRA, a
light-weight search algorithm that leverages zero-cost proxies to allocate the
limited LoRA trainable parameters across the model for better fine-tuned
performance. In addition to the allocation for the standard LoRA-adapted
models, we also demonstrate the efficacy of HeteroLoRA by performing the
allocation in a more challenging search space that includes LoRA modules and
LoRA-adapted shortcut connections. Experiments show that HeteroLoRA enables
improvements in model performance given the same parameter budge. For example,
on MRPC, we see an improvement of 1.6% in accuracy with similar training
parameter budget. We will open-source our algorithm once the paper is accepted.

摘要：低秩適應 (LoRA) 一直是針對大型語言模型的實際參數有效微調技術。我們提出 HeteroLoRA，這是一種輕量的搜尋演算法，它利用零成本代理在模型中配置有限的 LoRA 可訓練參數，以獲得更好的微調效能。除了分配標準 LoRA 適應模型外，我們還透過在包含 LoRA 模組和 LoRA 適應捷徑連線的更具挑戰性搜尋空間中執行配置，來展示 HeteroLoRA 的效能。實驗顯示，HeteroLoRA 能在給定相同參數預算的情況下，提升模型效能。例如，在 MRPC 上，我們看到準確度提升了 1.6%，而訓練參數預算類似。一旦論文被接受，我們將開放原始碼演算法。

##### **ICLEval: Evaluating In-Context Learning Ability of Large Language Models**
2406.14955v1 by Wentong Chen, Yankai Lin, ZhenHao Zhou, HongYun Huang, Yantao Jia, Zhao Cao, Ji-Rong Wen

In-Context Learning (ICL) is a critical capability of Large Language Models
(LLMs) as it empowers them to comprehend and reason across interconnected
inputs. Evaluating the ICL ability of LLMs can enhance their utilization and
deepen our understanding of how this ability is acquired at the training stage.
However, existing evaluation frameworks primarily focus on language abilities
and knowledge, often overlooking the assessment of ICL ability. In this work,
we introduce the ICLEval benchmark to evaluate the ICL abilities of LLMs, which
encompasses two key sub-abilities: exact copying and rule learning. Through the
ICLEval benchmark, we demonstrate that ICL ability is universally present in
different LLMs, and model size is not the sole determinant of ICL efficacy.
Surprisingly, we observe that ICL abilities, particularly copying, develop
early in the pretraining process and stabilize afterward. Our source codes and
benchmark are released at https://github.com/yiye3/ICLEval.

摘要：語境學習 (ICL) 是大型語言模型 (LLM) 的一項關鍵能力，因為它能讓 LLM 理解和推理相互關聯的輸入。評估 LLM 的 ICL 能力可以提升其應用，並加深我們對此能力如何在訓練階段習得的理解。然而，現有的評估框架主要關注語言能力和知識，往往忽略了對 ICL 能力的評估。在這項工作中，我們引入了 ICLEval 基準來評估 LLM 的 ICL 能力，其中包含了兩個關鍵子能力：精確複製和規則學習。透過 ICLEval 基準，我們證明了 ICL 能力普遍存在於不同的 LLM 中，而模型大小並非 ICL 效能的唯一決定因素。令人驚訝的是，我們觀察到 ICL 能力，特別是複製，在預訓練過程中會及早發展，並在之後穩定下來。我們的原始碼和基準已在 https://github.com/yiye3/ICLEval 中發布。

##### **Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**
2406.14953v1 by Guangkun Nie, Qinghao Zhao, Gongzheng Tang, Jun Li, Shenda Hong

Photoplethysmography (PPG) is emerging as a crucial tool for monitoring human
hemodynamics, with recent studies highlighting its potential in assessing
vascular aging through deep learning. However, real-world age distributions are
often imbalanced, posing significant challenges for deep learning models. In
this paper, we introduce a novel, simple, and effective loss function named the
Dist Loss to address deep imbalanced regression tasks. We trained a
one-dimensional convolutional neural network (Net1D) incorporating the Dist
Loss on the extensive UK Biobank dataset (n=502,389) to estimate vascular age
from PPG signals and validate its efficacy in characterizing cardiovascular
health. The model's performance was validated on a 40% held-out test set,
achieving state-of-the-art results, especially in regions with small sample
sizes. Furthermore, we divided the population into three subgroups based on the
difference between predicted vascular age and chronological age: less than -10
years, between -10 and 10 years, and greater than 10 years. We analyzed the
relationship between predicted vascular age and several cardiovascular events
over a follow-up period of up to 10 years, including death, coronary heart
disease, and heart failure. Our results indicate that the predicted vascular
age has significant potential to reflect an individual's cardiovascular health
status. Our code will be available at https://github.com/Ngk03/AI-vascular-age.

摘要：光電容積描記法 (PPG) 正逐漸成為監測人體血流動力學的一項重要工具，最近的研究強調其透過深度學習評估血管老化的潛力。然而，真實世界的年齡分佈通常不平衡，對深度學習模型構成重大挑戰。在本文中，我們引入一個新穎、簡單且有效的損失函數，稱為 Dist Loss，以解決深度不平衡迴歸任務。我們在龐大的英國生物銀行資料集 (n=502,389) 上訓練了一個一維卷積神經網路 (Net1D)，結合 Dist Loss 從 PPG 訊號估計血管年齡，並驗證其在表徵心血管健康的效能。該模型的效能經過 40% 的留出測試集驗證，獲得了最先進的結果，特別是在樣本量小的區域。此外，我們根據預測的血管年齡和實際年齡之間的差異將人群分為三個子群：小於 -10 歲、介於 -10 到 10 歲之間，以及大於 10 歲。我們分析了預測的血管年齡與後續長達 10 年的數個心血管事件之間的關係，包括死亡、冠心病和心衰竭。我們的結果表明，預測的血管年齡具有反映個人心血管健康狀況的顯著潛力。我們的程式碼將在 https://github.com/Ngk03/AI-vascular-age 提供。

##### **ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models**
2406.14952v1 by Haiquan Zhao, Lingyu Li, Shisong Chen, Shuqi Kong, Jiaan Wang, Kexing Huang, Tianle Gu, Yixu Wang, Dandan Liang, Zhixu Li, Tan Teng, Yanghua Xiao, Yingchun Wang

Emotion Support Conversation (ESC) is a crucial application, which aims to
reduce human stress, offer emotional guidance, and ultimately enhance human
mental and physical well-being. With the advancement of Large Language Models
(LLMs), many researchers have employed LLMs as the ESC models. However, the
evaluation of these LLM-based ESCs remains uncertain. Inspired by the awesome
development of role-playing agents, we propose an ESC Evaluation framework
(ESC-Eval), which uses a role-playing agent to interact with ESC models,
followed by a manual evaluation of the interactive dialogues. In detail, we
first re-organize 2,801 role-playing cards from seven existing datasets to
define the roles of the role-playing agent. Second, we train a specific
role-playing model called ESC-Role which behaves more like a confused person
than GPT-4. Third, through ESC-Role and organized role cards, we systematically
conduct experiments using 14 LLMs as the ESC models, including general
AI-assistant LLMs (ChatGPT) and ESC-oriented LLMs (ExTES-Llama). We conduct
comprehensive human annotations on interactive multi-turn dialogues of
different ESC models. The results show that ESC-oriented LLMs exhibit superior
ESC abilities compared to general AI-assistant LLMs, but there is still a gap
behind human performance. Moreover, to automate the scoring process for future
ESC models, we developed ESC-RANK, which trained on the annotated data,
achieving a scoring performance surpassing 35 points of GPT-4. Our data and
code are available at https://github.com/haidequanbu/ESC-Eval.

摘要：情緒支持對話 (ESC) 是一項重要的應用程式，旨在減輕人類壓力、提供情緒指導，並最終增進人類的心理和生理健康。隨著大型語言模型 (LLM) 的進步，許多研究人員已採用 LLM 作為 ESC 模型。然而，這些基於 LLM 的 ESC 評估仍不確定。受到角色扮演代理的驚人發展啟發，我們提出一個 ESC 評估架構 (ESC-Eval)，它使用角色扮演代理與 ESC 模型互動，然後手動評估互動對話。詳細來說，我們首先從七個現有資料集重新組織 2,801 張角色扮演卡，以定義角色扮演代理的角色。其次，我們訓練一個稱為 ESC-Role 的特定角色扮演模型，其行為比 GPT-4 更像一個困惑的人。第三，透過 ESC-Role 和組織化的角色卡，我們系統性地進行實驗，使用 14 個 LLM 作為 ESC 模型，包括一般 AI 助理 LLM（ChatGPT）和以 ESC 為導向的 LLM（ExTES-Llama）。我們對不同 ESC 模型的互動多輪對話進行全面的手動註解。結果顯示，以 ESC 為導向的 LLM 展現出優於一般 AI 助理 LLM 的 ESC 能力，但仍落後於人類表現。此外，為了自動化未來 ESC 模型的評分流程，我們開發了 ESC-RANK，它訓練於註解資料，其評分表現超越 GPT-4 的 35 分。我們的資料和程式碼可在 https://github.com/haidequanbu/ESC-Eval 取得。

##### **Towards Retrieval Augmented Generation over Large Video Libraries**
2406.14938v1 by Yannis Tevissen, Khalil Guetari, Frédéric Petitpont

Video content creators need efficient tools to repurpose content, a task that
often requires complex manual or automated searches. Crafting a new video from
large video libraries remains a challenge. In this paper we introduce the task
of Video Library Question Answering (VLQA) through an interoperable
architecture that applies Retrieval Augmented Generation (RAG) to video
libraries. We propose a system that uses large language models (LLMs) to
generate search queries, retrieving relevant video moments indexed by speech
and visual metadata. An answer generation module then integrates user queries
with this metadata to produce responses with specific video timestamps. This
approach shows promise in multimedia content retrieval, and AI-assisted video
content creation.

摘要：影片內容創作者需要有效率的工具來重新利用內容，這項任務通常需要複雜的人工或自動化搜尋。從大型影片庫中製作新的影片仍然是一項挑戰。在本文中，我們透過一個可互操作的架構介紹影片庫問答 (VLQA) 任務，該架構將檢索擴充產生 (RAG) 應用於影片庫。我們提出一個使用大型語言模型 (LLM) 來產生搜尋查詢的系統，擷取由語音和視覺元資料索引的相關影片片段。然後，一個答案產生模組將使用者查詢與這些元資料整合，以產生具有特定影片時間戳記的回應。此方法在多媒體內容擷取和 AI 輔助影片內容創作中顯示出前景。

##### **Autonomous Agents for Collaborative Task under Information Asymmetry**
2406.14928v1 by Wei Liu, Chenxi Wang, Yifei Wang, Zihao Xie, Rennai Qiu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Chen Qian

Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great
progress in solving complex tasks. It performs communication among agents
within the system to collaboratively solve tasks, under the premise of shared
information. However, when agents' communication is leveraged to enhance human
cooperation, a new challenge arises due to information asymmetry, since each
agent can only access the information of its human user. Previous MAS struggle
to complete tasks under this condition. To address this, we propose a new MAS
paradigm termed iAgents, which denotes Informative Multi-Agent Systems. In
iAgents, the human social network is mirrored in the agent network, where
agents proactively exchange human information necessary for task resolution,
thereby overcoming information asymmetry. iAgents employs a novel agent
reasoning mechanism, InfoNav, to navigate agents' communication towards
effective information exchange. Together with InfoNav, iAgents organizes human
information in a mixed memory to provide agents with accurate and comprehensive
information for exchange. Additionally, we introduce InformativeBench, the
first benchmark tailored for evaluating LLM agents' task-solving ability under
information asymmetry. Experimental results show that iAgents can collaborate
within a social network of 140 individuals and 588 relationships, autonomously
communicate over 30 turns, and retrieve information from nearly 70,000 messages
to complete tasks within 3 minutes.

摘要：大型語言模型多智能體系統 (LLM-MAS) 在解決複雜任務方面取得了巨大的進展。它在系統內的智能體之間進行溝通，在共享資訊的前提下協作解決任務。然而，當智能體的溝通被用於增強人類合作時，由於資訊不對稱，一個新的挑戰出現了，因為每個智能體只能存取其人類使用者的資訊。先前的 MAS 在這種情況下難以完成任務。為了解決這個問題，我們提出了一個新的 MAS 典範，稱為 iAgents，它表示資訊性多智能體系統。在 iAgents 中，人類社交網路反映在智能體網路中，智能體主動交換任務解決所需的資訊，從而克服資訊不對稱。iAgents 使用一種新穎的智能體推理機制 InfoNav，引導智能體的溝通朝向有效的資訊交換。與 InfoNav 一起，iAgents 在混合記憶體中組織人類資訊，為智能體提供準確且全面的資訊進行交換。此外，我們引入了 InformativeBench，這是第一個專門用於評估 LLM 智能體在資訊不對稱下的任務解決能力的基準測試。實驗結果表明，iAgents 能夠在一個由 140 個人和 588 個關係組成的社交網路中協作，在 30 輪中自主溝通，並從近 70,000 條訊息中檢索資訊，在 3 分鐘內完成任務。

##### **LLM2FEA: Discover Novel Designs with Generative Evolutionary Multitasking**
2406.14917v1 by Melvin Wong, Jiao Liu, Thiago Rios, Stefan Menzel, Yew Soon Ong

The rapid research and development of generative artificial intelligence has
enabled the generation of high-quality images, text, and 3D models from text
prompts. This advancement impels an inquiry into whether these models can be
leveraged to create digital artifacts for both creative and engineering
applications. Drawing on innovative designs from other domains may be one
answer to this question, much like the historical practice of ``bionics", where
humans have sought inspiration from nature's exemplary designs. This raises the
intriguing possibility of using generative models to simultaneously tackle
design tasks across multiple domains, facilitating cross-domain learning and
resulting in a series of innovative design solutions. In this paper, we propose
LLM2FEA as the first attempt to discover novel designs in generative models by
transferring knowledge across multiple domains. By utilizing a multi-factorial
evolutionary algorithm (MFEA) to drive a large language model, LLM2FEA
integrates knowledge from various fields to generate prompts that guide the
generative model in discovering novel and practical objects. Experimental
results in the context of 3D aerodynamic design verify the discovery
capabilities of the proposed LLM2FEA. The designs generated by LLM2FEA not only
satisfy practicality requirements to a certain degree but also feature novel
and aesthetically pleasing shapes, demonstrating the potential applications of
LLM2FEA in discovery tasks.

摘要：生成式人工智能的快速研究和發展，
促使了從文字提示中生成高品質影像、文字和 3D 模型。
此進展促使我們探討這些模型是否能用於為創意和工程應用程式建立數位人工製品。
從其他領域汲取創新設計可能是此問題的解答之一，
很像過去「仿生學」的實務，人類從大自然的範例設計中尋求靈感。
這提出了使用生成式模型同時處理多個領域的設計任務的迷人可能性，
促進跨領域學習，並產生一系列創新的設計解決方案。
在本文中，我們提出 LLM2FEA 作為首次嘗試，
透過在多個領域傳遞知識，在生成式模型中發現新穎的設計。
透過使用多因子演化演算法 (MFEA) 來驅動大型語言模型，
LLM2FEA 整合來自各個領域的知識，以產生提示，
引導生成式模型發現新穎且實用的物件。
在 3D 空氣動力設計脈絡下的實驗結果驗證了所提出的 LLM2FEA 的發現能力。
LLM2FEA 生成的設計不僅在一定程度上滿足了實用性要求，
還具有新穎且美觀的形狀，展示了 LLM2FEA 在發現任務中的潛在應用。

##### **MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression**
2406.14909v1 by Tianyu Fu, Haofeng Huang, Xuefei Ning, Genghan Zhang, Boju Chen, Tianqi Wu, Hongyi Wang, Zixiao Huang, Shiyao Li, Shengen Yan, Guohao Dai, Huazhong Yang, Yu Wang

Sparse attention can effectively mitigate the significant memory and
throughput demands of Large Language Models (LLMs) in long contexts. Existing
methods typically employ a uniform sparse attention mask, applying the same
sparse pattern across different attention heads and input lengths. However,
this uniform approach fails to capture the diverse attention patterns inherent
in LLMs, ignoring their distinct accuracy-latency trade-offs. To address this
challenge, we propose the Mixture of Attention (MoA), which automatically
tailors distinct sparse attention configurations to different heads and layers.
MoA constructs and navigates a search space of various attention patterns and
their scaling rules relative to input sequence lengths. It profiles the model,
evaluates potential configurations, and pinpoints the optimal sparse attention
compression plan. MoA adapts to varying input sizes, revealing that some
attention heads expand their focus to accommodate longer sequences, while other
heads consistently concentrate on fixed-length local contexts. Experiments show
that MoA increases the effective context length by $3.9\times$ with the same
average attention span, boosting retrieval accuracy by $1.5-7.1\times$ over the
uniform-attention baseline across Vicuna-7B, Vicuna-13B, and Llama3-8B models.
Moreover, MoA narrows the capability gaps between sparse and dense models,
reducing the maximum relative performance drop from $9\%-36\%$ to within $5\%$
across two long-context understanding benchmarks. MoA achieves a
$1.2-1.4\times$ GPU memory reduction and boosts decode throughput by $5.5-6.7
\times$ for 7B and 13B dense models on a single GPU, with minimal impact on
performance.

摘要：<paragraph>稀疏注意力可以有效缓解大型语言模型 (LLM) 在长文本中对内存和吞吐量的巨大需求。现有的方法通常采用统一的稀疏注意力掩码，对不同的注意力头和输入长度应用相同的稀疏模式。然而，这种统一的方法无法捕捉到 LLM 中固有的多样化注意力模式，忽视了它们不同的准确性-延迟权衡。为了应对这一挑战，我们提出了注意力混合 (MoA)，它可以自动为不同的头和层定制不同的稀疏注意力配置。MoA 构建并遍历了各种注意力模式的搜索空间，以及它们相对于输入序列长度的缩放规则。它对模型进行分析，评估潜在配置，并找出最佳的稀疏注意力压缩计划。MoA 适应不同的输入大小，揭示了一些注意力头会扩展它们的焦点以适应更长的序列，而其他注意力头则始终集中在固定长度的局部上下文中。实验表明，MoA 将有效上下文长度增加了 $3.9\times$，同时保持相同的平均注意力跨度，在 Vicuna-7B、Vicuna-13B 和 Llama3-8B 模型上，检索准确度比统一注意力基线提高了 $1.5-7.1\times$。此外，MoA 缩小了稀疏模型和稠密模型之间的能力差距，将两个长上下文理解基准的最大相对性能下降从 $9\%-36\%$ 降低到 $5\%$ 以内。MoA 在单个 GPU 上为 7B 和 13B 稠密模型实现了 $1.2-1.4\times$ 的 GPU 内存减少，并将解码吞吐量提高了 $5.5-6.7\times$，对性能的影响最小。</paragraph>

##### **GIEBench: Towards Holistic Evaluation of Group Indentity-based Empathy for Large Language Models**
2406.14903v1 by Leyan Wang, Yonggang Jin, Tianhao Shen, Tianyu Zheng, Xinrun Du, Chenchen Zhang, Wenhao Huang, Jiaheng Liu, Shi Wang, Ge Zhang, Liuyu Xiang, Zhaofeng He

As large language models (LLMs) continue to develop and gain widespread
application, the ability of LLMs to exhibit empathy towards diverse group
identities and understand their perspectives is increasingly recognized as
critical. Most existing benchmarks for empathy evaluation of LLMs focus
primarily on universal human emotions, such as sadness and pain, often
overlooking the context of individuals' group identities. To address this gap,
we introduce GIEBench, a comprehensive benchmark that includes 11 identity
dimensions, covering 97 group identities with a total of 999 single-choice
questions related to specific group identities. GIEBench is designed to
evaluate the empathy of LLMs when presented with specific group identities such
as gender, age, occupation, and race, emphasizing their ability to respond from
the standpoint of the identified group. This supports the ongoing development
of empathetic LLM applications tailored to users with different identities. Our
evaluation of 23 LLMs revealed that while these LLMs understand different
identity standpoints, they fail to consistently exhibit equal empathy across
these identities without explicit instructions to adopt those perspectives.
This highlights the need for improved alignment of LLMs with diverse values to
better accommodate the multifaceted nature of human identities. Our datasets
are available at https://github.com/GIEBench/GIEBench.

摘要：隨著大型語言模型 (LLM) 持續發展並廣泛應用，LLM 對不同群體身分展現同理心和理解其觀點的能力愈發被視為至關重要。現有的 LLM 同理心評估基準主要集中於普遍的人類情緒，例如悲傷和痛苦，往往忽略了個人群體身分的背景。為了解決這個差距，我們引入了 GIEBench，這是一個包含 11 個身分維度的綜合基準，涵蓋 97 個群體身分，共有 999 個與特定群體身分相關的單選題。GIEBench 旨在評估 LLM 在面對特定群體身分時，例如性別、年齡、職業和種族，展現同理心的能力，強調它們從所識別群體的立場做出回應的能力。這支持了針對具有不同身分的使用者量身打造的同理心 LLM 應用程式的持續開發。我們對 23 個 LLM 的評估顯示，雖然這些 LLM 了解不同的身分立場，但它們無法在這些身分之間始終如一地展現同等的同理心，除非明確指示採用這些觀點。這突顯了 LLM 與多元價值觀保持一致性的需求，以更好地適應人類身分的複雜本質。我們的資料集可在 https://github.com/GIEBench/GIEBench 取得。

##### **Safely Learning with Private Data: A Federated Learning Framework for Large Language Model**
2406.14898v1 by JiaYing Zheng, HaiNan Zhang, LingXiang Wang, WangJie Qiu, HongWei Zheng, ZhiMing Zheng

Private data, being larger and quality-higher than public data, can greatly
improve large language models (LLM). However, due to privacy concerns, this
data is often dispersed in multiple silos, making its secure utilization for
LLM training a challenge. Federated learning (FL) is an ideal solution for
training models with distributed private data, but traditional frameworks like
FedAvg are unsuitable for LLM due to their high computational demands on
clients. An alternative, split learning, offloads most training parameters to
the server while training embedding and output layers locally, making it more
suitable for LLM. Nonetheless, it faces significant challenges in security and
efficiency. Firstly, the gradients of embeddings are prone to attacks, leading
to potential reverse engineering of private data. Furthermore, the server's
limitation of handle only one client's training request at a time hinders
parallel training, severely impacting training efficiency. In this paper, we
propose a Federated Learning framework for LLM, named FL-GLM, which prevents
data leakage caused by both server-side and peer-client attacks while improving
training efficiency. Specifically, we first place the input block and output
block on local client to prevent embedding gradient attacks from server.
Secondly, we employ key-encryption during client-server communication to
prevent reverse engineering attacks from peer-clients. Lastly, we employ
optimization methods like client-batching or server-hierarchical, adopting
different acceleration methods based on the actual computational capabilities
of the server. Experimental results on NLU and generation tasks demonstrate
that FL-GLM achieves comparable metrics to centralized chatGLM model,
validating the effectiveness of our federated learning framework.

摘要：<paragraph>私人數據比公開數據更大且品質更高，可以大幅改善大型語言模型 (LLM)。然而，由於隱私問題，這些數據通常分散在多個資料孤島中，使得其安全利用成為 LLM 訓練的一項挑戰。聯合學習 (FL) 是使用分散的私人數據訓練模型的理想解決方案，但 FedAvg 等傳統框架由於對用戶端的高運算需求而不適合 LLM。一種替代方案，分割式學習，將大多數訓練參數卸載到伺服器，同時在本地訓練嵌入和輸出層，使其更適合 LLM。儘管如此，它在安全性和效率方面面臨著重大挑戰。首先，嵌入的梯度容易受到攻擊，導致潛在的私人數據逆向工程。此外，伺服器一次只能處理一個用戶端的訓練請求的限制阻礙了並行訓練，嚴重影響了訓練效率。在本文中，我們提出了一個名為 FL-GLM 的 LLM 聯邦學習框架，它可以防止伺服器端和對等用戶端攻擊造成的數據洩漏，同時提高訓練效率。具體來說，我們首先將輸入區塊和輸出區塊放置在本地用戶端，以防止伺服器發起的嵌入梯度攻擊。其次，我們在用戶端-伺服器通信期間採用密鑰加密，以防止對等用戶端發起的逆向工程攻擊。最後，我們採用用戶端批次處理或伺服器分層等最佳化方法，根據伺服器的實際運算能力採用不同的加速方法。NLU 和生成任務的實驗結果表明，FL-GLM 達到了與集中式 chatGLM 模型相當的指標，驗證了我們聯合學習框架的有效性。</paragraph>

##### **Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition**
2406.14894v1 by Candida M. Greco, Lucio La Cava, Andrea Tagarelli

Verbs form the backbone of language, providing the structure and meaning to
sentences. Yet, their intricate semantic nuances pose a longstanding challenge.
Understanding verb relations through the concept of lexical entailment is
crucial for comprehending sentence meanings and grasping verb dynamics. This
work investigates the capabilities of eight Large Language Models in
recognizing lexical entailment relations among verbs through differently
devised prompting strategies and zero-/few-shot settings over verb pairs from
two lexical databases, namely WordNet and HyperLex. Our findings unveil that
the models can tackle the lexical entailment recognition task with moderately
good performance, although at varying degree of effectiveness and under
different conditions. Also, utilizing few-shot prompting can enhance the
models' performance. However, perfectly solving the task arises as an unmet
challenge for all examined LLMs, which raises an emergence for further research
developments on this topic.

摘要：動詞構成語言的骨幹，提供句子結構和意義。然而，它們複雜的語義細微差別長期以來一直是一個挑戰。透過詞彙蘊涵的概念來理解動詞關係對於理解句子意義和掌握動態非常重要。本研究探討了八個大型語言模型在透過不同的提示策略和來自 WordNet 和 HyperLex 這兩個詞彙資料庫的動詞對的零次／少次學習設定中辨識動詞之間的詞彙蘊涵關係的能力。我們的研究結果揭示，這些模型可以處理詞彙蘊涵辨識任務，並有適度的良好表現，儘管在不同的條件下有效性程度不同。此外，利用少次學習提示可以增強模型的表現。然而，完美地解決這個任務對於所有受檢的 LLM 來說都是一個尚未達成的挑戰，這引發了進一步研究發展這個主題的必要性。

##### **Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering**
2406.14891v1 by Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, Zhaochun Ren

Multi-Hop Question Answering (MHQA) tasks present a significant challenge for
large language models (LLMs) due to the intensive knowledge required. Current
solutions, like Retrieval-Augmented Generation, typically retrieve potential
documents from an external corpus to read an answer. However, the performance
of this retrieve-then-read paradigm is constrained by the retriever and the
inevitable noise in the retrieved documents. To mitigate these challenges, we
introduce a novel generate-then-ground (GenGround) framework, synergizing the
parametric knowledge of LLMs and external documents to solve a multi-hop
question. GenGround empowers LLMs to alternate two phases until the final
answer is derived: (1) formulate a simpler, single-hop question and directly
generate the answer; (2) ground the question-answer pair in retrieved
documents, amending any wrong predictions in the answer. We also propose an
instructional grounding distillation method to generalize our method into
smaller models. Extensive experiments conducted on four datasets illustrate the
superiority of our method.

摘要：多跳問答 (MHQA) 任務由於需要大量的知識，因此對大型語言模型 (LLM) 來說是一個重大的挑戰。目前的解決方案，例如檢索增強生成，通常會從外部語料庫中檢索潛在文件來讀取答案。然而，這種先檢索後閱讀的範例效能受到檢索器和檢索文件中不可避免的雜訊所限制。為了減輕這些挑戰，我們引入了一個新穎的先生成後接地的 (GenGround) 框架，協同利用 LLM 和外部文件的參數化知識來解決多跳問題。GenGround 賦予 LLM 能力，讓其交替執行兩個階段，直到推導出最終答案：(1) 構建一個更簡單的單跳問題並直接生成答案；(2) 將問答對接地於檢索文件中，修正答案中的任何錯誤預測。我們還提出了一種教學接地蒸餾方法，將我們的模型推廣到較小的模型中。在四個資料集上進行的廣泛實驗說明了我們方法的優越性。

##### **InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate Predictions**
2406.14890v1 by Yu Nakagome, Michael Hentschel

Despite recent advances in end-to-end speech recognition methods, their
output is biased to the training data's vocabulary, resulting in inaccurate
recognition of unknown terms or proper nouns. To improve the recognition
accuracy for a given set of such terms, we propose an adaptation parameter-free
approach based on Self-conditioned CTC. Our method improves the recognition
accuracy of misrecognized target keywords by substituting their intermediate
CTC predictions with corrected labels, which are then passed on to the
subsequent layers. First, we create pairs of correct labels and recognition
error instances for a keyword list using Text-to-Speech and a recognition
model. We use these pairs to replace intermediate prediction errors by the
labels. Conditioning the subsequent layers of the encoder on the labels, it is
possible to acoustically evaluate the target keywords. Experiments conducted in
Japanese demonstrated that our method successfully improved the F1 score for
unknown words.

摘要：儘管端對端語音辨識方法近期有進展，但其輸出結果偏向訓練資料的詞彙，導致無法精準辨識未知詞彙或專有名詞。為了提升特定詞彙集合的辨識精準度，我們提出一個基於自條件 CTC 的適應無參數方法。我們的做法透過將錯誤辨識的目標關鍵字的中間 CTC 預測值替換為修正標籤，再傳遞到後續層級，進而提升辨識精準度。首先，我們使用文字轉語音和辨識模型，針對關鍵字清單建立正確標籤和辨識錯誤實例的配對。我們使用這些配對來取代中間預測錯誤的標籤。透過讓編碼器的後續層級以標籤為條件，可以對目標關鍵字進行聲學評估。在日文進行的實驗顯示，我們的做法成功提升了未知詞彙的 F1 分數。

##### **InternLM-Law: An Open Source Chinese Legal Large Language Model**
2406.14887v1 by Zhiwei Fei, Songyang Zhang, Xiaoyu Shen, Dawei Zhu, Xiao Wang, Maosong Cao, Fengzhe Zhou, Yining Li, Wenwei Zhang, Dahua Lin, Kai Chen, Jidong Ge

While large language models (LLMs) have showcased impressive capabilities,
they struggle with addressing legal queries due to the intricate complexities
and specialized expertise required in the legal field. In this paper, we
introduce InternLM-Law, a specialized LLM tailored for addressing diverse legal
queries related to Chinese laws, spanning from responding to standard legal
questions (e.g., legal exercises in textbooks) to analyzing complex real-world
legal situations. We meticulously construct a dataset in the Chinese legal
domain, encompassing over 1 million queries, and implement a data filtering and
processing pipeline to ensure its diversity and quality. Our training approach
involves a novel two-stage process: initially fine-tuning LLMs on both
legal-specific and general-purpose content to equip the models with broad
knowledge, followed by exclusive fine-tuning on high-quality legal data to
enhance structured output generation. InternLM-Law achieves the highest average
performance on LawBench, outperforming state-of-the-art models, including
GPT-4, on 13 out of 20 subtasks. We make InternLM-Law and our dataset publicly
available to facilitate future research in applying LLMs within the legal
domain.

摘要：儘管大型語言模型 (LLM) 展示了令人印象深刻的能力，但由於法律領域所需的複雜性和專業知識，它們在處理法律查詢時仍有困難。在本文中，我們介紹了 InternLM-Law，這是一個專門針對處理與中國法律相關的各種法律查詢的 LLM，範圍從回答標準法律問題（例如教科書中的法律練習）到分析複雜的現實世界法律情況。我們在中國法律領域精心構建了一個包含 100 多萬個查詢的資料集，並實施了資料過濾和處理管道，以確保其多樣性和品質。我們的訓練方法涉及一個新穎的兩階段過程：最初針對法律特定和一般用途內容微調 LLM，以讓模型具備廣泛的知識，然後針對高品質的法律資料進行獨家微調，以增強結構化輸出生成。InternLM-Law 在 LawBench 上取得了最高的平均效能，在 20 個子任務中有 13 個子任務的表現優於最先進的模型，包括 GPT-4。我們公開 InternLM-Law 和我們的資料集，以促進未來在法律領域應用 LLM 的研究。

##### **FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents**
2406.14884v1 by Ruixuan Xiao, Wentao Ma, Ke Wang, Yuchuan Wu, Junbo Zhao, Haobo Wang, Fei Huang, Yongbin Li

LLM-based agents have emerged as promising tools, which are crafted to
fulfill complex tasks by iterative planning and action. However, these agents
are susceptible to undesired planning hallucinations when lacking specific
knowledge for expertise-intensive tasks. To address this, preliminary attempts
are made to enhance planning reliability by incorporating external
workflow-related knowledge. Despite the promise, such infused knowledge is
mostly disorganized and diverse in formats, lacking rigorous formalization and
comprehensive comparisons. Motivated by this, we formalize different formats of
workflow knowledge and present FlowBench, the first benchmark for
workflow-guided planning. FlowBench covers 51 different scenarios from 6
domains, with knowledge presented in diverse formats. To assess different LLMs
on FlowBench, we design a multi-tiered evaluation framework. We evaluate the
efficacy of workflow knowledge across multiple formats, and the results
indicate that current LLM agents need considerable improvements for
satisfactory planning. We hope that our challenging benchmark can pave the way
for future agent planning research.

摘要：基於 LLM 的代理已成為有前途的工具，它們被設計為通過反覆的規劃和行動來完成複雜任務。然而，這些代理在缺乏專業密集型任務的具體知識時，容易受到不必要的規劃幻覺的影響。為了解決這個問題，有人初步嘗試通過納入外部工作流程相關知識來增強規劃的可靠性。儘管有希望，但這種注入的知識大多是雜亂無章且格式多樣，缺乏嚴謹的形式化和全面的比較。受此激勵，我們形式化了不同格式的工作流程知識，並提出了 FlowBench，這是第一個工作流程引導規劃的基準。FlowBench 涵蓋了來自 6 個領域的 51 個不同的場景，知識以不同的格式呈現。為了評估 FlowBench 上的不同 LLM，我們設計了一個多層評估框架。我們評估了多種格式的工作流程知識的功效，結果表明當前的 LLM 代理需要大幅改進才能進行令人滿意的規劃。我們希望我們具有挑戰性的基準測試可以為未來的代理規劃研究鋪平道路。

##### **OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants**
2406.14883v1 by Jaspreet Ranjit, Brihi Joshi, Rebecca Dorn, Laura Petry, Olga Koumoundouros, Jayne Bottarini, Peichen Liu, Eric Rice, Swabha Swayamdipta

Warning: Contents of this paper may be upsetting.
  Public attitudes towards key societal issues, expressed on online media, are
of immense value in policy and reform efforts, yet challenging to understand at
scale. We study one such social issue: homelessness in the U.S., by leveraging
the remarkable capabilities of large language models to assist social work
experts in analyzing millions of posts from Twitter. We introduce a framing
typology: Online Attitudes Towards Homelessness (OATH) Frames: nine
hierarchical frames capturing critiques, responses and perceptions. We release
annotations with varying degrees of assistance from language models, with
immense benefits in scaling: 6.5x speedup in annotation time while only
incurring a 3 point F1 reduction in performance with respect to the domain
experts. Our experiments demonstrate the value of modeling OATH-Frames over
existing sentiment and toxicity classifiers. Our large-scale analysis with
predicted OATH-Frames on 2.4M posts on homelessness reveal key trends in
attitudes across states, time periods and vulnerable populations, enabling new
insights on the issue. Our work provides a general framework to understand
nuanced public attitudes at scale, on issues beyond homelessness.

摘要：警告：本文內容可能令人不安。
在線上媒體上表達的對社會議題的公眾態度，在政策和改革工作中具有極高的價值，但難以大規模理解。我們研究了一個這樣的社會議題：美國的無家可歸問題，利用大型語言模型的非凡能力來協助社會工作專家分析來自 Twitter 的數百萬條貼文。我們引入了一個框架類型：對無家可歸者的線上態度（OATH）框架：九個層級框架，涵蓋批評、回應和觀點。我們發布了在語言模型的幫助下不同程度的註解，在擴展方面具有巨大的好處：註解時間加快了 6.5 倍，而對領域專家的執行效能僅降低了 3 點 F1。我們的實驗證明了對 OATH 框架建模比現有的情緒和毒性分類器更有價值。我們對 240 萬篇關於無家可歸者的貼文進行大規模分析，並預測了 OATH 框架，揭示了各州、時間段和弱勢群體在態度方面的關鍵趨勢，從而對這個問題有了新的見解。我們的研究提供了一個通用的框架，可以大規模理解對無家可歸問題以外的議題的微妙的公眾態度。

##### **70B-parameter large language models in Japanese medical question-answering**
2406.14882v1 by Issey Sukeda, Risa Kishikawa, Satoshi Kodera

Since the rise of large language models (LLMs), the domain adaptation has
been one of the hot topics in various domains. Many medical LLMs trained with
English medical dataset have made public recently. However, Japanese LLMs in
medical domain still lack its research. Here we utilize multiple 70B-parameter
LLMs for the first time and show that instruction tuning using Japanese medical
question-answering dataset significantly improves the ability of Japanese LLMs
to solve Japanese medical license exams, surpassing 50\% in accuracy. In
particular, the Japanese-centric models exhibit a more significant leap in
improvement through instruction tuning compared to their English-centric
counterparts. This underscores the importance of continual pretraining and the
adjustment of the tokenizer in our local language. We also examine two slightly
different prompt formats, resulting in non-negligible performance improvement.

摘要：自大型語言模型 (LLM) 興起以來，領域適應已成為各個領域的熱門話題。許多使用英語醫療資料集訓練的醫療 LLM 近期已公開。然而，醫療領域的日語 LLM 仍缺乏研究。在此，我們首次利用多個 70B 參數 LLM，並證明使用日語醫療問答資料集進行指令微調可顯著提升日語 LLM 解決日語醫療執照考試的能力，準確度超過 50%。特別是，以日語為中心的模型在指令微調後展現出比以英語為中心的對應模型更顯著的進步。這強調了持續預訓練和調整我們當地語言中分詞器的重要性。我們也檢視了兩種略有不同的提示格式，進而產生顯著的效能提升。

##### **Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video**
2406.14877v1 by Zhengbang Yang, Haotian Xia, Jingxi Li, Zezhi Chen, Zhuangdi Zhu, Weining Shen

Understanding sports is crucial for the advancement of Natural Language
Processing (NLP) due to its intricate and dynamic nature. Reasoning over
complex sports scenarios has posed significant challenges to current NLP
technologies which require advanced cognitive capabilities. Toward addressing
the limitations of existing benchmarks on sports understanding in the NLP
field, we extensively evaluated mainstream large language models for various
sports tasks. Our evaluation spans from simple queries on basic rules and
historical facts to complex, context-specific reasoning, leveraging strategies
from zero-shot to few-shot learning, and chain-of-thought techniques. In
addition to unimodal analysis, we further assessed the sports reasoning
capabilities of mainstream video language models to bridge the gap in
multimodal sports understanding benchmarking. Our findings highlighted the
critical challenges of sports understanding for NLP. We proposed a new
benchmark based on a comprehensive overview of existing sports datasets and
provided extensive error analysis which we hope can help identify future
research priorities in this field.

摘要：了解運動對於自然語言處理 (NLP) 的進步至關重要，因為運動具有複雜且動態的本質。對複雜運動情境的推理對目前的 NLP 技術構成重大挑戰，這些技術需要進階的認知能力。為了解決 NLP 領域中現有運動理解基準的限制，我們廣泛評估了各種運動任務的主流大型語言模型。我們的評估涵蓋從基本規則和歷史事實的簡單查詢到複雜的特定情境推理，利用從零次學習到少量學習的策略，以及思考鏈技術。除了單模態分析之外，我們進一步評估了主流視訊語言模型的運動推理能力，以彌補多模態運動理解基準的差距。我們的發現突出了運動理解對於 NLP 的關鍵挑戰。我們根據現有運動資料集的全面概觀提出了新的基準，並提供了廣泛的錯誤分析，我們希望這有助於找出此領域未來的研究重點。

##### **I don't trust you (anymore)! -- The effect of students' LLM use on Lecturer-Student-Trust in Higher Education**
2406.14871v1 by Simon Kloker, Matthew Bazanya, Twaha Kateete

Trust plays a pivotal role in Lecturer-Student-Collaboration, encompassing
teaching and research aspects. The advent of Large Language Models (LLMs) in
platforms like Open AI's ChatGPT, coupled with their cost-effectiveness and
high-quality results, has led to their rapid adoption among university
students. However, discerning genuine student input from LLM-generated output
poses a challenge for lecturers. This dilemma jeopardizes the trust
relationship between lecturers and students, potentially impacting university
downstream activities, particularly collaborative research initiatives. Despite
attempts to establish guidelines for student LLM use, a clear framework
mutually beneficial for lecturers and students in higher education remains
elusive. This study addresses the research question: How does the use of LLMs
by students impact Informational and Procedural Justice, influencing Team Trust
and Expected Team Performance? Methodically, we applied a quantitative
construct-based survey, evaluated using techniques of Structural Equation
Modelling (PLS- SEM) to examine potential relationships among these constructs.
Our findings based on 23 valid respondents from Ndejje University indicate that
lecturers are less concerned about the fairness of LLM use per se but are more
focused on the transparency of student utilization, which significantly
influences Team Trust positively. This research contributes to the global
discourse on integrating and regulating LLMs and subsequent models in
education. We propose that guidelines should support LLM use while enforcing
transparency in Lecturer-Student- Collaboration to foster Team Trust and
Performance. The study contributes valuable insights for shaping policies
enabling ethical and transparent LLMs usage in education to ensure
effectiveness of collaborative learning environments.

摘要：<paragraph>信任在講師與學生的合作中扮演著關鍵角色，涵蓋教學和研究層面。大型語言模型（LLM）在 Open AI 的 ChatGPT 等平台的出現，加上其成本效益和高品質的成果，導致大學生迅速採用。然而，對於講師來說，要從 LLM 生成的輸出中辨別出真正的學生輸入是一項挑戰。這種困境危及講師與學生之間的信任關係，可能會影響大學的後續活動，特別是合作研究計畫。儘管已嘗試為學生的 LLM 使用制定準則，但一個對高等教育中的講師和學生都有利的明確架構仍難以捉摸。本研究探討以下研究問題：學生使用 LLM 如何影響資訊和程序正義，進而影響團隊信任和預期的團隊績效？在方法上，我們應用基於建構的量化調查，使用結構方程模型（PLS-SEM）的技術進行評估，以檢驗這些建構之間的潛在關係。我們根據恩德傑大學 23 位有效受訪者的研究結果指出，講師不太關心 LLM 使用的公平性本身，但更注重學生使用過程的透明度，這會顯著地對團隊信任產生正面影響。本研究有助於全球關於整合和規範 LLM 及其後續模型在教育中的論述。我們建議準則應支援 LLM 的使用，同時在講師與學生合作中加強透明度，以促進團隊信任和績效。本研究提供了有價值的見解，有助於制定政策，讓教育中使用 LLM 符合倫理且透明，以確保協作學習環境的有效性。</paragraph>

##### **Direct Multi-Turn Preference Optimization for Language Agents**
2406.14868v1 by Wentao Shi, Mengqi Yuan, Junkang Wu, Qifan Wang, Fuli Feng

Adapting Large Language Models (LLMs) for agent tasks is critical in
developing language agents. Direct Preference Optimization (DPO) is a promising
technique for this adaptation with the alleviation of compounding errors,
offering a means to directly optimize Reinforcement Learning (RL) objectives.
However, applying DPO to multi-turn tasks presents challenges due to the
inability to cancel the partition function. Overcoming this obstacle involves
making the partition function independent of the current state and addressing
length disparities between preferred and dis-preferred trajectories. In this
light, we replace the policy constraint with the state-action occupancy measure
constraint in the RL objective and add length normalization to the
Bradley-Terry model, yielding a novel loss function named DMPO for multi-turn
agent tasks with theoretical explanations. Extensive experiments on three
multi-turn agent task datasets confirm the effectiveness and superiority of the
DMPO loss.

摘要：調整大型語言模型 (LLM) 以適應代理人任務，對於開發語言代理人至關重要。直接偏好最佳化 (DPO) 是一種有前途的技術，可透過緩解複合錯誤來進行此調整，提供直接最佳化強化學習 (RL) 目標的方法。然而，由於無法取消分割函數，將 DPO 應用於多輪任務會產生挑戰。克服此障礙涉及讓分割函數獨立於當前狀態，並解決首選和非首選軌跡之間的長度差異。有鑑於此，我們在 RL 目標中用狀態動作佔用測量約束取代政策約束，並將長度正規化加入 Bradley-Terry 模型，產生一個名為 DMPO 的新損失函數，用於多輪代理人任務，並附有理論說明。在三個多輪代理人任務資料集上的廣泛實驗證實了 DMPO 損失的有效性和優越性。

##### **DistiLRR: Transferring Code Repair for Low-Resource Programming Languages**
2406.14867v1 by Kyle Wong, Alfonso Amayuelas, Liangming Pan, William Yang Wang

Large language models (LLMs) have shown remarkable performance on code
generation tasks. A recent application of LLMs for code generation is iterative
code repair, where a model fixes an incorrect program by rationalizing about
errors and generating a new program. However, code repair is primarily studied
on high-resource languages like Python, and the framework's efficacy is
under-explored on low-resource languages. To apply code repair for low-resource
languages, we propose Distilling Low-Resource Repairs (DistiLRR), an approach
that transfers the reasoning and code generation ability from a teacher model
to a student model. Our results show that DistiLRR consistently outperforms
baselines on low-resource languages, but has similar performance on
high-resource languages. To investigate this behavior, we perform a further
analysis and find that the correlation between rationale quality and code
correctness is weaker than previously perceived. We hypothesize this weakness
is magnified in low-resource settings where base models lack deep knowledge of
a programming language, leading to wavering benefits of code repair between
high-resource and low-resource languages.

摘要：大型語言模型 (LLM) 在程式碼產生任務上展現了非凡的效能。LLM 在程式碼產生上的最新應用是反覆程式碼修復，其中模型透過對錯誤進行合理化並產生新的程式碼來修復不正確的程式。然而，程式碼修復主要在 Python 等高資源語言上進行研究，而該架構在低資源語言上的效能則尚未充分探討。為了將程式碼修復應用於低資源語言，我們提出了蒸餾低資源修復 (DistiLRR)，這是一種將推理和程式碼產生能力從教師模型轉移到學生模型的方法。我們的結果顯示，DistiLRR 在低資源語言上始終優於基準，但在高資源語言上則有類似的效能。為了探討這種行為，我們進一步進行分析，發現依據品質和程式碼正確性之間的關聯性比先前認知的要弱。我們假設這種弱點在低資源設定中會被放大，其中基礎模型缺乏對程式語言的深入了解，導致程式碼修復在高資源和低資源語言之間的效益搖擺不定。

##### **AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**
2406.14866v1 by Jonas Dippel, Niklas Prenißl, Julius Hense, Philipp Liznerski, Tobias Winterhoff, Simon Schallenberg, Marius Kloft, Oliver Buchstab, David Horst, Maximilian Alber, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen

While previous studies have demonstrated the potential of AI to diagnose
diseases in imaging data, clinical implementation is still lagging behind. This
is partly because AI models require training with large numbers of examples
only available for common diseases. In clinical reality, however, only few
diseases are common, whereas the majority of diseases are less frequent
(long-tail distribution). Current AI models overlook or misclassify these
diseases. We propose a deep anomaly detection approach that only requires
training data from common diseases to detect also all less frequent diseases.
We collected two large real-world datasets of gastrointestinal biopsies, which
are prototypical of the problem. Herein, the ten most common findings account
for approximately 90% of cases, whereas the remaining 10% contained 56 disease
entities, including many cancers. 17 million histological images from 5,423
cases were used for training and evaluation. Without any specific training for
the diseases, our best-performing model reliably detected a broad spectrum of
infrequent ("anomalous") pathologies with 95.0% (stomach) and 91.0% (colon)
AUROC and generalized across scanners and hospitals. By design, the proposed
anomaly detection can be expected to detect any pathological alteration in the
diagnostic tail of gastrointestinal biopsies, including rare primary or
metastatic cancers. This study establishes the first effective clinical
application of AI-based anomaly detection in histopathology that can flag
anomalous cases, facilitate case prioritization, reduce missed diagnoses and
enhance the general safety of AI models, thereby driving AI adoption and
automation in routine diagnostics and beyond.

摘要：儘管先前的研究已經證明 AI 在影像資料中診斷疾病的潛力，但臨床實務仍落後許多。這是部分原因在於 AI 模型需要大量範例進行訓練，而這些範例僅適用於常見疾病。然而，在臨床現實中，只有少數疾病是常見的，而大多數疾病較不常見（長尾分佈）。目前的 AI 模型會忽略或錯誤分類這些疾病。我們提出一個深度異常偵測方法，它只需要來自常見疾病的訓練資料，就能偵測所有較不常見的疾病。我們收集了兩個大型的胃腸道切片真實世界資料集，它們是此問題的典型範例。在此，最常見的十種發現約佔病例的 90%，而其餘 10% 則包含 56 種疾病實體，包括許多癌症。1700 萬張來自 5,423 個病例的組織學影像用於訓練和評估。我們的最佳效能模型在沒有針對這些疾病進行任何特定訓練的情況下，可靠地偵測到廣泛的罕見（「異常」）病理，其 AUROC 分別為 95.0%（胃）和 91.0%（結腸），並廣泛應用於掃描儀和醫院。依據設計，所提出的異常偵測預計可以偵測胃腸道切片診斷尾端的任何病理性改變，包括罕見的原發性或轉移性癌症。這項研究建立了第一個有效的 AI 異常偵測臨床應用，它可以在組織病理學中標記異常病例、促進病例優先順序、減少漏診並提升 AI 模型的整體安全性，從而推動 AI 在常規診斷及其他領域的採用和自動化。

##### **LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models**
2406.14862v1 by Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao

Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
LatentExplainer, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
LatentExplainer tackles three main challenges: inferring the meaning of latent
variables, aligning explanations with inductive biases, and handling varying
degrees of explainability. By perturbing latent variables and interpreting
changes in generated data, the framework provides a systematic approach to
understanding and controlling the data generation process, enhancing the
transparency and interpretability of deep generative models. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations of
latent variables.

摘要：深度生成模型（如 VAE 和扩散模型）通过利用潜在变量学习数据分布并生成高质量样本，促进了各种生成任务的发展。尽管可解释 AI 领域在解释机器学习模型方面取得了进展，但理解生成模型中的潜在变量仍然具有挑战性。本文介绍了 LatentExplainer，这是一个用于自动生成深度生成模型中潜在变量的语义有意义解释的框架。LatentExplainer 解决了三个主要挑战：推断潜在变量的含义、使解释与归纳偏差保持一致，以及处理不同程度的可解释性。通过扰动潜在变量并解释生成数据中的变化，该框架提供了一种理解和控制数据生成过程的系统方法，从而增强了深度生成模型的透明度和可解释性。我们在几个真实世界和合成数据集上评估了我们提出的方法，结果表明在生成潜在变量的高质量解释方面具有卓越的性能。

##### **From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking**
2406.14859v1 by Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei

The rapid development of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) has exposed vulnerabilities to various adversarial
attacks. This paper provides a comprehensive overview of jailbreaking research
targeting both LLMs and MLLMs, highlighting recent advancements in evaluation
benchmarks, attack techniques and defense strategies. Compared to the more
advanced state of unimodal jailbreaking, multimodal domain remains
underexplored. We summarize the limitations and potential research directions
of multimodal jailbreaking, aiming to inspire future research and further
enhance the robustness and security of MLLMs.

摘要：大型語言模型 (LLM) 和多模態大型語言模型 (MLLM) 的快速發展，暴露了各種對抗性攻擊的漏洞。本文提供了針對 LLM 和 MLLM 的越獄研究的全面概述，重點介紹了評估基準、攻擊技術和防禦策略的最新進展。與單模態越獄的更先進狀態相比，多模態領域仍未得到充分探索。我們總結了多模態越獄的局限性和潛在研究方向，旨在激勵未來的研究並進一步增強 MLLM 的穩健性和安全性。

##### **Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models**
2406.14852v1 by Jiayu Wang, Yifei Ming, Zhenmei Shi, Vibhav Vineet, Xin Wang, Neel Joshi

Large language models (LLMs) and vision-language models (VLMs) have
demonstrated remarkable performance across a wide range of tasks and domains.
Despite this promise, spatial understanding and reasoning -- a fundamental
component of human cognition -- remains under-explored. We develop novel
benchmarks that cover diverse aspects of spatial reasoning such as relationship
understanding, navigation, and counting. We conduct a comprehensive evaluation
of competitive language and vision-language models. Our findings reveal several
counter-intuitive insights that have been overlooked in the literature: (1)
Spatial reasoning poses significant challenges where competitive models can
fall behind random guessing; (2) Despite additional visual input, VLMs often
under-perform compared to their LLM counterparts; (3) When both textual and
visual information is available, multi-modal language models become less
reliant on visual information if sufficient textual clues are provided.
Additionally, we demonstrate that leveraging redundancy between vision and text
can significantly enhance model performance. We hope our study will inform the
development of multimodal models to improve spatial intelligence and further
close the gap with human intelligence.

摘要：大型語言模型 (LLM) 和視覺語言模型 (VLM) 已展現出在廣泛任務和領域的卓越效能。儘管有此承諾，但空間理解和推理——人類認知的基本組成部分——仍未得到充分探討。我們開發出新穎的基準，涵蓋空間推理的不同面向，例如關係理解、導航和計數。我們對競爭語言和視覺語言模型進行了全面的評估。我們的研究結果揭示了文獻中被忽略的幾個反直覺見解：(1) 空間推理帶來重大挑戰，競爭模型可能落後於隨機猜測；(2) 儘管有額外的視覺輸入，但 VLM 的表現通常不如其 LLM 對應模型；(3) 當文本和視覺資訊都可用時，如果提供了足夠的文字線索，多模式語言模型將不太依賴視覺資訊。此外，我們證明了利用視覺和文字之間的冗餘可以顯著提升模型效能。我們希望我們的研究將有助於多模式模型的開發，以提升空間智慧，並進一步縮小與人類智慧的差距。

##### **Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models**
2406.14848v1 by Qi Liu, Bo Wang, Nan Wang, Jiaxin Mao

Recent studies have demonstrated the effectiveness of using large language
language models (LLMs) in passage ranking. The listwise approaches, such as
RankGPT, have become new state-of-the-art in this task. However, the efficiency
of RankGPT models is limited by the maximum context length and relatively high
latency of LLM inference. To address these issues, in this paper, we propose
PE-Rank, leveraging the single passage embedding as a good context compression
for efficient listwise passage reranking. By treating each passage as a special
token, we can directly input passage embeddings into LLMs, thereby reducing
input length. Additionally, we introduce an inference method that dynamically
constrains the decoding space to these special tokens, accelerating the
decoding process. For adapting the model to reranking, we employ listwise
learning to rank loss for training. Evaluation results on multiple benchmarks
demonstrate that PE-Rank significantly improves efficiency in both prefilling
and decoding, while maintaining competitive ranking effectiveness. {The Code is
available at \url{https://github.com/liuqi6777/pe_rank}.}

摘要：最近的研究展示了在段落排序中使用大型语言模型 (LLM) 的有效性。列表式方法（例如 RankGPT）已成为此任务中的新技术。然而，RankGPT 模型的效率受到最大上下文长度和 LLM 推断的相对高延迟的限制。为了解决这些问题，我们在本文中提出了 PE-Rank，利用单个段落嵌入作为高效列表式段落重新排序的良好上下文压缩。通过将每个段落视为一个特殊标记，我们可以直接将段落嵌入输入到 LLM 中，从而减少输入长度。此外，我们引入了一种推理方法，该方法动态地将解码空间限制在这些特殊标记上，从而加速解码过程。为了使模型适应重新排序，我们采用列表式学习来对训练进行排序损失。在多个基准上的评估结果表明，PE-Rank 在预填充和解码方面都显着提高了效率，同时保持了有竞争力的排名有效性。{代码可在 \url{https://github.com/liuqi6777/pe_rank} 中找到。}

##### **DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning**
2406.14844v1 by Jingyi Liu, Yanjie Li, Lina Yu, Min Wu, Weijun Li, Wenqiang Li, Meilan Hao, Yusong Deng, Shu Wei

Noise ubiquitously exists in signals due to numerous factors including
physical, electronic, and environmental effects. Traditional methods of
symbolic regression, such as genetic programming or deep learning models, aim
to find the most fitting expressions for these signals. However, these methods
often overlook the noise present in real-world data, leading to reduced fitting
accuracy. To tackle this issue, we propose \textit{\textbf{D}eep Symbolic
Regression against \textbf{N}oise via \textbf{C}ontrastive \textbf{L}earning
(DN-CL)}. DN-CL employs two parameter-sharing encoders to embed data points
from various data transformations into feature shields against noise. This
model treats noisy data and clean data as different views of the ground-truth
mathematical expressions. Distances between these features are minimized,
utilizing contrastive learning to distinguish between 'positive'
noise-corrected pairs and 'negative' contrasting pairs. Our experiments
indicate that DN-CL demonstrates superior performance in handling both noisy
and clean data, presenting a promising method of symbolic regression.

摘要：雜訊由於許多因素而普遍存在於訊號中，包括物理、電子和環境效應。傳統的符號回歸方法，例如遺傳程式設計或深度學習模型，旨在為這些訊號找出最合適的表達式。然而，這些方法通常會忽略真實世界資料中存在的雜訊，導致擬合準確度降低。為了解決這個問題，我們提出透過對比學習對抗雜訊的深度符號回歸 (DN-CL)。DN-CL 使用兩個參數共享編碼器，將來自各種資料轉換的資料點嵌入到抗雜訊的特徵防護罩中。此模型將雜訊資料和乾淨資料視為基本事實數學表達式的不同觀點。這些特徵之間的距離會被最小化，利用對比學習來區分「正向」雜訊校正對和「負向」對比對。我們的實驗表明，DN-CL 在處理雜訊和乾淨資料方面表現出優異的效能，提供了一種有前途的符號回歸方法。

##### **Automated architectural space layout planning using a physics-inspired generative design framework**
2406.14840v1 by Zhipeng Li, Sichao Li, Geoff Hinchcliffe, Noam Maitless, Nick Birbilis

The determination of space layout is one of the primary activities in the
schematic design stage of an architectural project. The initial layout planning
defines the shape, dimension, and circulation pattern of internal spaces; which
can also affect performance and cost of the construction. When carried out
manually, space layout planning can be complicated, repetitive and time
consuming. In this work, a generative design framework for the automatic
generation of spatial architectural layout has been developed. The proposed
approach integrates a novel physics-inspired parametric model for space layout
planning and an evolutionary optimisation metaheuristic. Results revealed that
such a generative design framework can generate a wide variety of design
suggestions at the schematic design stage, applicable to complex design
problems.

摘要：空間配置的決定是建築專案草圖設計階段的主要活動之一。最初的配置規劃定義了內部空間的形狀、尺寸和循環模式；這也可能會影響施工的性能和成本。當手動執行時，空間配置規劃可能會很複雜、重複且耗時。在這項工作中，已開發出一個用於自動產生空間建築配置的生成式設計架構。所提出的方法整合了一個新穎的物理啟發參數模型，用於空間配置規劃和進化優化元啟發法。結果顯示，這樣的生成式設計架構可以在草圖設計階段產生各種設計建議，適用於複雜的設計問題。

##### **ToVo: Toxicity Taxonomy via Voting**
2406.14835v1 by Tinh Son Luong, Thanh-Thien Le, Thang Viet Doan, Linh Ngo Van, Thien Huu Nguyen, Diep Thi-Ngoc Nguyen

Existing toxic detection models face significant limitations, such as lack of
transparency, customization, and reproducibility. These challenges stem from
the closed-source nature of their training data and the paucity of explanations
for their evaluation mechanism. To address these issues, we propose a dataset
creation mechanism that integrates voting and chain-of-thought processes,
producing a high-quality open-source dataset for toxic content detection. Our
methodology ensures diverse classification metrics for each sample and includes
both classification scores and explanatory reasoning for the classifications.
  We utilize the dataset created through our proposed mechanism to train our
model, which is then compared against existing widely-used detectors. Our
approach not only enhances transparency and customizability but also
facilitates better fine-tuning for specific use cases. This work contributes a
robust framework for developing toxic content detection models, emphasizing
openness and adaptability, thus paving the way for more effective and
user-specific content moderation solutions.

摘要：現有的毒性檢測模型面臨重大限制，例如缺乏透明度、自訂性和可複製性。這些挑戰源於其訓練資料的封閉原始碼性質，以及其評估機制的解釋不足。為了解決這些問題，我們提出一個整合投票和思考鏈流程的資料集建立機制，產生一個高品質的開放原始碼資料集，用於毒性內容檢測。我們的做法確保每個範例都有不同的分類指標，並包含分類分數和分類說明。
我們利用透過我們提出的機制建立的資料集來訓練我們的模型，然後將其與現有廣泛使用的檢測器進行比較。我們的做法不僅增強了透明度和自訂性，還促進了針對特定使用案例進行更好的微調。這項工作為開發毒性內容檢測模型提供了一個強大的架構，強調開放性和適應性，為更有效和使用者特定的內容管理解決方案鋪平道路。

##### **Efficient Continual Pre-training by Mitigating the Stability Gap**
2406.14833v1 by Yiduo Guo, Jie Fu, Huishuai Zhang, Dongyan Zhao, Yikang Shen

Continual pre-training has increasingly become the predominant approach for
adapting Large Language Models (LLMs) to new domains. This process involves
updating the pre-trained LLM with a corpus from a new domain, resulting in a
shift in the training distribution. To study the behavior of LLMs during this
shift, we measured the model's performance throughout the continual
pre-training process. we observed a temporary performance drop at the
beginning, followed by a recovery phase, a phenomenon known as the "stability
gap," previously noted in vision models classifying new classes. To address
this issue and enhance LLM performance within a fixed compute budget, we
propose three effective strategies: (1) Continually pre-training the LLM on a
subset with a proper size for multiple epochs, resulting in faster performance
recovery than pre-training the LLM on a large corpus in a single epoch; (2)
Pre-training the LLM only on high-quality sub-corpus, which rapidly boosts
domain performance; and (3) Using a data mixture similar to the pre-training
data to reduce distribution gap. We conduct various experiments on Llama-family
models to validate the effectiveness of our strategies in both medical
continual pre-training and instruction tuning. For example, our strategies
improve the average medical task performance of the OpenLlama-3B model from
36.2% to 40.7% with only 40% of the original training budget and enhance the
average general task performance without causing forgetting. Furthermore, we
apply our strategies to the Llama-3-8B model. The resulting model,
Llama-3-Physician, achieves the best medical performance among current
open-source models, and performs comparably to or even better than GPT-4 on
several medical benchmarks. We release our models at
\url{https://huggingface.co/YiDuo1999/Llama-3-Physician-8B-Instruct}.

摘要：持續預訓練已逐漸成為將大型語言模型 (LLM) 適應到新領域的主要方法。此程序涉及使用新領域的語料庫更新預先訓練的 LLM，導致訓練分佈發生轉變。為了研究 LLM 在此轉變期間的行為，我們在整個持續預訓練過程中測量模型的效能。我們觀察到一開始效能暫時下降，接著是復原階段，這種現象稱為「穩定性差距」，先前在分類新類別的視覺模型中發現。為了解決此問題並在固定的運算預算內提升 LLM 效能，我們提出三種有效的策略：(1) 持續在適當大小的子集上對 LLM 進行多個時期的預訓練，比在大型語料庫上對 LLM 進行單一時期的預訓練能更快復原效能；(2) 僅在高品質的子語料庫上對 LLM 進行預訓練，這能快速提升領域效能；(3) 使用類似預訓練資料的資料混合，以縮小分佈差距。我們在 Llama 家族模型上進行各種實驗，以驗證我們的策略在醫學持續預訓練和指令調整中的有效性。例如，我們的策略將 OpenLlama-3B 模型的平均醫學任務效能從 36.2% 提升至 40.7%，僅使用原先訓練預算的 40%，並提升平均一般任務效能，且不會造成遺忘。此外，我們將我們的策略應用於 Llama-3-8B 模型。產生的模型 Llama-3-Physician 在目前開放原始碼模型中獲得最佳醫學效能，且在幾個醫學基準上與 GPT-4 相當甚至更好。我們在 \url{https://huggingface.co/YiDuo1999/Llama-3-Physician-8B-Instruct} 發布我們的模型。

##### **Is this a bad table? A Closer Look at the Evaluation of Table Generation from Text**
2406.14829v1 by Pritika Ramu, Aparna Garimella, Sambaran Bandyopadhyay

Understanding whether a generated table is of good quality is important to be
able to use it in creating or editing documents using automatic methods. In
this work, we underline that existing measures for table quality evaluation
fail to capture the overall semantics of the tables, and sometimes unfairly
penalize good tables and reward bad ones. We propose TabEval, a novel table
evaluation strategy that captures table semantics by first breaking down a
table into a list of natural language atomic statements and then compares them
with ground truth statements using entailment-based measures. To validate our
approach, we curate a dataset comprising of text descriptions for 1,250 diverse
Wikipedia tables, covering a range of topics and structures, in contrast to the
limited scope of existing datasets. We compare TabEval with existing metrics
using unsupervised and supervised text-to-table generation methods,
demonstrating its stronger correlation with human judgments of table quality
across four datasets.

摘要：了解生成的表格是否具有良好的品質對於能夠使用自動化方法建立或編輯文件來說非常重要。在這項工作中，我們強調現有的表格品質評估措施無法掌握表格的整體語意，有時還會不公平地懲罰好的表格並獎勵壞的表格。我們提出 TabEval，這是一種新穎的表格評估策略，它透過先將表格分解成自然語言原子陳述的清單，然後使用基於蘊涵的措施與真實陳述進行比較，來掌握表格語意。為了驗證我們的做法，我們整理了一個資料集，其中包含 1,250 個不同的維基百科表格的文字說明，涵蓋各種主題和結構，與現有資料集的範圍有限不同。我們使用非監督式和監督式文字轉表格生成方法，將 TabEval 與現有的指標進行比較，證明它與人類對四個資料集中表格品質的判斷具有更強的相關性。

##### **Word Matters: What Influences Domain Adaptation in Summarization?**
2406.14828v1 by Yinghao Li, Siyu Miao, Heyan Huang, Yang Gao

Domain adaptation aims to enable Large Language Models (LLMs) to generalize
domain datasets unseen effectively during the training phase. However, factors
such as the size of the model parameters and the scale of training data are
general influencers and do not reflect the nuances of domain adaptation
performance. This paper investigates the fine-grained factors affecting domain
adaptation performance, analyzing the specific impact of `words' in training
data on summarization tasks. We propose quantifying dataset learning difficulty
as the learning difficulty of generative summarization, which is determined by
two indicators: word-based compression rate and abstraction level. Our
experiments conclude that, when considering dataset learning difficulty, the
cross-domain overlap and the performance gain in summarization tasks exhibit an
approximate linear relationship, which is not directly related to the number of
words. Based on this finding, predicting a model's performance on unknown
domain datasets is possible without undergoing training.

摘要：領域適應旨在讓大型語言模型 (LLM) 在訓練階段有效概括未見過的領域資料集。然而，模型參數的大小和訓練資料的規模等因素是通用的影響因素，無法反映領域適應效能的細微差別。本文探討影響領域適應效能的細微因素，分析訓練資料中「字詞」對摘要任務的具體影響。我們提出將資料集學習難度量化為生成式摘要的學習難度，而這取決於兩個指標：基於字詞的壓縮率和抽象層級。我們的實驗結論是，在考慮資料集學習難度時，跨領域重疊和摘要任務中的效能提升呈現近似線性關係，這與字詞數量無直接關係。根據此發現，可以在不進行訓練的情況下預測模型在未知領域資料集上的效能。

##### **Self-supervised Brain Lesion Generation for Effective Data Augmentation of Medical Images**
2406.14826v1 by Jiayu Huo, Sebastien Ourselin, Rachel Sparks

Accurate brain lesion delineation is important for planning neurosurgical
treatment. Automatic brain lesion segmentation methods based on convolutional
neural networks have demonstrated remarkable performance. However, neural
network performance is constrained by the lack of large-scale well-annotated
training datasets. In this manuscript, we propose a comprehensive framework to
efficiently generate new, realistic samples for training a brain lesion
segmentation model. We first train a lesion generator, based on an adversarial
autoencoder, in a self-supervised manner. Next, we utilize a novel image
composition algorithm, Soft Poisson Blending, to seamlessly combine synthetic
lesions and brain images to obtain training samples. Finally, to effectively
train the brain lesion segmentation model with augmented images we introduce a
new prototype consistence regularization to align real and synthetic features.
Our framework is validated by extensive experiments on two public brain lesion
segmentation datasets: ATLAS v2.0 and Shift MS. Our method outperforms existing
brain image data augmentation schemes. For instance, our method improves the
Dice from 50.36% to 60.23% compared to the U-Net with conventional data
augmentation techniques for the ATLAS v2.0 dataset.

摘要：準確的腦病灶描繪對於規劃神經外科治療很重要。基於卷積神經網路的自動腦病灶分割方法已展現出卓越的成效。然而，神經網路的效能受到缺乏大量標註良好的訓練資料集的限制。在此手稿中，我們提出一個全面的架構，以有效產生新的、逼真的樣本來訓練腦病灶分割模型。我們首先以自監督的方式訓練一個基於對抗自動編碼器的病灶生成器。接下來，我們利用一種新穎的影像合成演算法，Soft Poisson Blending，將合成病灶和腦影像無縫結合，以取得訓練樣本。最後，為了有效地使用擴充影像訓練腦病灶分割模型，我們引入一種新的原型一致正則化，以對齊真實和合成的特徵。我們的架構經過兩個公開的腦病灶分割資料集：ATLAS v2.0 和 Shift MS 的廣泛實驗驗證。我們的模型優於現有的腦影像資料擴充方法。例如，與採用傳統資料擴充技術的 ATLAS v2.0 資料集的 U-Net 相比，我們的模型將 Dice 從 50.36% 提升到 60.23%。

##### **TemPrompt: Multi-Task Prompt Learning for Temporal Relation Extraction in RAG-based Crowdsourcing Systems**
2406.14825v1 by Jing Yang, Yu Zhao, Yang Linyao, Xiao Wang, Fei-Yue Wang

Temporal relation extraction (TRE) aims to grasp the evolution of events or
actions, and thus shape the workflow of associated tasks, so it holds promise
in helping understand task requests initiated by requesters in crowdsourcing
systems. However, existing methods still struggle with limited and unevenly
distributed annotated data. Therefore, inspired by the abundant global
knowledge stored within pre-trained language models (PLMs), we propose a
multi-task prompt learning framework for TRE (TemPrompt), incorporating prompt
tuning and contrastive learning to tackle these issues. To elicit more
effective prompts for PLMs, we introduce a task-oriented prompt construction
approach that thoroughly takes the myriad factors of TRE into consideration for
automatic prompt generation. In addition, we present temporal event reasoning
as a supplement to bolster the model's focus on events and temporal cues. The
experimental results demonstrate that TemPrompt outperforms all compared
baselines across the majority of metrics under both standard and few-shot
settings. A case study is provided to validate its effectiveness in
crowdsourcing scenarios.

摘要：時序關係萃取 (TRE) 的目標是掌握事件或動作的演變，並由此塑造關聯任務的工作流程，因此它有望幫助理解群眾外包系統中請求者發起的任務請求。然而，現有方法仍然難以應對有限且分佈不均的標註資料。因此，在預訓練語言模型 (PLM) 中儲存的豐富全球知識的啟發下，我們提出了一個用於 TRE 的多任務提示學習框架 (TemPrompt)，結合提示調整和對比學習來解決這些問題。為了引出更有效的 PLM 提示，我們引入一種任務導向的提示建構方法，該方法全面考慮了 TRE 的無數因素以進行自動提示生成。此外，我們提出時序事件推理作為補充，以加強模型對事件和時序線索的關注。實驗結果表明，在標準和少樣本設定下的大多數指標中，TemPrompt 的表現都優於所有比較基準。提供了一個案例研究來驗證其在群眾外包場景中的有效性。

##### **Latent diffusion models for parameterization and data assimilation of facies-based geomodels**
2406.14815v1 by Guido Di Federico, Louis J. Durlofsky

Geological parameterization entails the representation of a geomodel using a
small set of latent variables and a mapping from these variables to grid-block
properties such as porosity and permeability. Parameterization is useful for
data assimilation (history matching), as it maintains geological realism while
reducing the number of variables to be determined. Diffusion models are a new
class of generative deep-learning procedures that have been shown to outperform
previous methods, such as generative adversarial networks, for image generation
tasks. Diffusion models are trained to "denoise", which enables them to
generate new geological realizations from input fields characterized by random
noise. Latent diffusion models, which are the specific variant considered in
this study, provide dimension reduction through use of a low-dimensional latent
variable. The model developed in this work includes a variational autoencoder
for dimension reduction and a U-net for the denoising process. Our application
involves conditional 2D three-facies (channel-levee-mud) systems. The latent
diffusion model is shown to provide realizations that are visually consistent
with samples from geomodeling software. Quantitative metrics involving spatial
and flow-response statistics are evaluated, and general agreement between the
diffusion-generated models and reference realizations is observed. Stability
tests are performed to assess the smoothness of the parameterization method.
The latent diffusion model is then used for ensemble-based data assimilation.
Two synthetic "true" models are considered. Significant uncertainty reduction,
posterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and
consistent posterior geomodels, are achieved in both cases.

摘要：<paragraph>地質參數化涉及使用一組潛在變數和從這些變數到網格塊屬性的對應關係（例如孔隙度和滲透率）來表示地質模型。參數化對於資料同化（歷史比對）很有用，因為它在減少待確定變數數量的同時，還維持了地質的真實性。擴散模型是一種新的生成式深度學習程序，已被證明優於先前的生成式對抗網路等方法，用於影像生成任務。擴散模型經過訓練以「去噪」，這使它們能夠從具有隨機噪聲特性的輸入欄位中生成新的地質實現。潛在擴散模型是本研究中考慮的特定變體，它透過使用低維潛在變數提供維度簡化。本研究中開發的模型包括一個用於維度簡化的變分自動編碼器和一個用於去噪程序的 U-net。我們的應用涉及條件式 2D 三相（河道-堤岸-泥岩）系統。潛在擴散模型被證明可以提供與地質建模軟體範例視覺一致的實現。評估了涉及空間和流動反應統計的量化指標，並觀察到擴散生成的模型和參考實現之間的一致性。執行穩定性測試以評估參數化方法的平滑度。然後將潛在擴散模型用於基於集合的資料同化。考慮了兩個合成的「真實」模型。在兩種情況下都實現了顯著的不確定性降低、通常括住觀測資料的後驗 P$_{10}$-P$_{90}$ 預測，以及一致的後驗地質模型。</paragraph>

##### **How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions**
2406.14805v1 by Julia Kharchenko, Tanya Roosta, Aman Chadha, Chirag Shah

Large Language Models (LLMs) attempt to imitate human behavior by responding
to humans in a way that pleases them, including by adhering to their values.
However, humans come from diverse cultures with different values. It is
critical to understand whether LLMs showcase different values to the user based
on the stereotypical values of a user's known country. We prompt different LLMs
with a series of advice requests based on 5 Hofstede Cultural Dimensions -- a
quantifiable way of representing the values of a country. Throughout each
prompt, we incorporate personas representing 36 different countries and,
separately, languages predominantly tied to each country to analyze the
consistency in the LLMs' cultural understanding. Through our analysis of the
responses, we found that LLMs can differentiate between one side of a value and
another, as well as understand that countries have differing values, but will
not always uphold the values when giving advice, and fail to understand the
need to answer differently based on different cultural values. Rooted in these
findings, we present recommendations for training value-aligned and culturally
sensitive LLMs. More importantly, the methodology and the framework developed
here can help further understand and mitigate culture and language alignment
issues with LLMs.

摘要：大型語言模型 (LLM) 嘗試模仿人類行為，以取悅人類的方式回應人類，包括遵守人類的價值觀。然而，人類來自不同的文化，擁有不同的價值觀。至關重要的是要了解 LLM 是否根據使用者已知國家的刻板價值觀向使用者展示不同的價值觀。我們根據 5 個霍夫斯泰德文化維度向不同的 LLM 發出一些建議請求——一種量化表示國家價值觀的方式。在每個提示中，我們加入了代表 36 個不同國家的人格，以及與每個國家主要相關的語言，以分析 LLM 文化理解的一致性。通過對回應的分析，我們發現 LLM 可以區分一個價值觀的一面和另一面，以及了解不同的國家有不同的價值觀，但在提供建議時並不總是堅持這些價值觀，並且無法理解根據不同的文化價值觀做出不同回答的必要性。基於這些發現，我們提出了培訓價值觀一致且文化敏感的 LLM 的建議。更重要的是，這裡開發的方法和框架可以幫助進一步了解和緩解 LLM 的文化和語言對齊問題。

