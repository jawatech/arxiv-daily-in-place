{"2410.23277": {"publish_time": "2024-10-30", "title": "SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation", "paper_summary": "Human beings are endowed with a complementary learning system, which bridges\nthe slow learning of general world dynamics with fast storage of episodic\nmemory from a new experience. Previous video generation models, however,\nprimarily focus on slow learning by pre-training on vast amounts of data,\noverlooking the fast learning phase crucial for episodic memory storage. This\noversight leads to inconsistencies across temporally distant frames when\ngenerating longer videos, as these frames fall beyond the model's context\nwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learning\nsystem for action-driven long video generation. Our approach incorporates a\nmasked conditional video diffusion model for the slow learning of world\ndynamics, alongside an inference-time fast learning strategy based on a\ntemporal LoRA module. Specifically, the fast learning process updates its\ntemporal LoRA parameters based on local inputs and outputs, thereby efficiently\nstoring episodic memory in its parameters. We further propose a slow-fast\nlearning loop algorithm that seamlessly integrates the inner fast learning loop\ninto the outer slow learning loop, enabling the recall of prior multi-episode\nexperiences for context-aware skill learning. To facilitate the slow learning\nof an approximate world model, we collect a large-scale dataset of 200k videos\nwith language action annotations, covering a wide range of scenarios. Extensive\nexperiments show that SlowFast-VGen outperforms baselines across various\nmetrics for action-driven video generation, achieving an FVD score of 514\ncompared to 782, and maintaining consistency in longer videos, with an average\nof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm\nsignificantly enhances performances on long-horizon planning tasks as well.\nProject Website: https://slowfast-vgen.github.io", "paper_summary_zh": "<paragraph>\u4eba\u985e\u88ab\u8ce6\u4e88\u4e00\u500b\u4e92\u88dc\u7684\u5b78\u7fd2\u7cfb\u7d71\uff0c\u5b83\u5c07\u4e00\u822c\u4e16\u754c\u52d5\u614b\u7684\u7de9\u6162\u5b78\u7fd2\u8207\u4f86\u81ea\u65b0\u7d93\u9a57\u7684\u5feb\u901f\u60c5\u7bc0\u8a18\u61b6\u5132\u5b58\u806f\u7e6b\u8d77\u4f86\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u5f71\u7247\u751f\u6210\u6a21\u578b\u4e3b\u8981\u900f\u904e\u5927\u91cf\u8cc7\u6599\u7684\u9810\u5148\u8a13\u7df4\u4f86\u5c08\u6ce8\u65bc\u7de9\u6162\u5b78\u7fd2\uff0c\u5ffd\u8996\u4e86\u5c0d\u60c5\u7bc0\u8a18\u61b6\u5132\u5b58\u81f3\u95dc\u91cd\u8981\u7684\u5feb\u901f\u5b78\u7fd2\u968e\u6bb5\u3002\u9019\u7a2e\u758f\u5ffd\u5c0e\u81f4\u5728\u751f\u6210\u8f03\u9577\u5f71\u7247\u6642\uff0c\u6642\u9593\u4e0a\u76f8\u8ddd\u751a\u9060\u7684\u5f71\u683c\u4e4b\u9593\u51fa\u73fe\u4e0d\u4e00\u81f4\uff0c\u56e0\u70ba\u9019\u4e9b\u5f71\u683c\u8d85\u51fa\u4e86\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u8996\u7a97\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 SlowFast-VGen\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u52d5\u4f5c\u9a45\u52d5\u7684\u9577\u5f71\u7247\u751f\u6210\u7684\u65b0\u578b\u96d9\u901f\u5b78\u7fd2\u7cfb\u7d71\u3002\u6211\u5011\u7684\u505a\u6cd5\u7d50\u5408\u4e86\u4e00\u500b\u7528\u65bc\u4e16\u754c\u52d5\u614b\u7de9\u6162\u5b78\u7fd2\u7684\u906e\u7f69\u689d\u4ef6\u5f71\u7247\u64f4\u6563\u6a21\u578b\uff0c\u4ee5\u53ca\u4e00\u500b\u57fa\u65bc\u6642\u9593 LoRA \u6a21\u7d44\u7684\u63a8\u8ad6\u6642\u9593\u5feb\u901f\u5b78\u7fd2\u7b56\u7565\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5feb\u901f\u5b78\u7fd2\u904e\u7a0b\u6839\u64da\u5c40\u90e8\u8f38\u5165\u548c\u8f38\u51fa\u66f4\u65b0\u5176\u6642\u9593 LoRA \u53c3\u6578\uff0c\u5f9e\u800c\u6709\u6548\u5730\u5c07\u60c5\u7bc0\u8a18\u61b6\u5132\u5b58\u5728\u5176\u53c3\u6578\u4e2d\u3002\u6211\u5011\u9032\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u500b\u7de9\u6162-\u5feb\u901f\u5b78\u7fd2\u8ff4\u5708\u6f14\u7b97\u6cd5\uff0c\u5b83\u5c07\u5167\u90e8\u7684\u5feb\u901f\u5b78\u7fd2\u8ff4\u5708\u7121\u7e2b\u6574\u5408\u5230\u5916\u90e8\u7684\u7de9\u6162\u5b78\u7fd2\u8ff4\u5708\u4e2d\uff0c\u4f7f\u80fd\u5920\u56de\u60f3\u8d77\u5148\u524d\u7684\u591a\u60c5\u7bc0\u7d93\u9a57\u4ee5\u9032\u884c\u60c5\u5883\u611f\u77e5\u6280\u80fd\u5b78\u7fd2\u3002\u70ba\u4e86\u4fc3\u9032\u8fd1\u4f3c\u4e16\u754c\u6a21\u578b\u7684\u7de9\u6162\u5b78\u7fd2\uff0c\u6211\u5011\u6536\u96c6\u4e86\u4e00\u500b\u5305\u542b 200k \u500b\u5f71\u7247\u7684\u5927\u898f\u6a21\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u8a9e\u8a00\u52d5\u4f5c\u8a3b\u89e3\uff0c\u6db5\u84cb\u4e86\u5ee3\u6cdb\u7684\u5834\u666f\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0cSlowFast-VGen \u5728\u52d5\u4f5c\u9a45\u52d5\u5f71\u7247\u751f\u6210\u7684\u5404\u7a2e\u6307\u6a19\u4e0a\u512a\u65bc\u57fa\u6e96\uff0c\u8207 782 \u76f8\u6bd4\uff0cFVD \u5f97\u5206\u9054\u5230 514\uff0c\u4e26\u4e14\u5728\u8f03\u9577\u7684\u5f71\u7247\u4e2d\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5e73\u5747\u5834\u666f\u5207\u63db\u70ba 0.37\uff0c\u800c 0.89\u3002\u7de9\u6162-\u5feb\u901f\u5b78\u7fd2\u8ff4\u5708\u6f14\u7b97\u6cd5\u4e5f\u986f\u8457\u63d0\u5347\u4e86\u9577\u671f\u898f\u5283\u4efb\u52d9\u7684\u6548\u80fd\u3002\u5c08\u6848\u7db2\u7ad9\uff1ahttps://slowfast-vgen.github.io</paragraph>", "author": "Yining Hong et.al.", "authors": "Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang", "id": "2410.23277v1", "paper_url": "http://arxiv.org/abs/2410.23277v1", "repo": "null"}}