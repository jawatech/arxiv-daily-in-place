{"2405.17976": {"publish_time": "2024-05-28", "title": "Yuan 2.0-M32: Mixture of Experts with Attention Router", "paper_summary": "Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a\nmixture-of-experts architecture with 32 experts of which 2 experts are active.\nA new router network, Attention Router, is proposed and adopted for a more\nefficient selection of experts, which improves the accuracy compared to the\nmodel with classical router network. Yuan 2.0-M32 is trained with 2000B tokens\nfrom scratch, and the training computation consumption is only 9.25% of a dense\nmodel at the same parameter scale. Yuan 2.0-M32 demonstrates competitive\ncapability on coding, math, and various domains of expertise, with only 3.7B\nactive parameters of 40B in total, and 7.4 GFlops forward computation per\ntoken, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass\nLlama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8\nrespectively. The models and source codes of Yuan 2.0-M32 are released at\nGithub1.", "paper_summary_zh": "Yuan 2.0-M32\uff0c\u5176\u57fa\u672c\u67b6\u69cb\u8207 Yuan-2.0 2B \u985e\u4f3c\uff0c\u4f7f\u7528\u6df7\u5408\u5c08\u5bb6\u67b6\u69cb\uff0c\u64c1\u6709 32 \u4f4d\u5c08\u5bb6\uff0c\u5176\u4e2d 2 \u4f4d\u5c08\u5bb6\u8655\u65bc\u6d3b\u8e8d\u72c0\u614b\u3002\u63d0\u51fa\u4e26\u63a1\u7528\u4e00\u7a2e\u65b0\u7684\u8def\u7531\u5668\u7db2\u8def\uff0c\u6ce8\u610f\u8def\u7531\u5668\uff0c\u4ee5\u66f4\u6709\u6548\u7387\u5730\u9078\u64c7\u5c08\u5bb6\uff0c\u8207\u63a1\u7528\u50b3\u7d71\u8def\u7531\u5668\u7db2\u8def\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u9019\u9805\u6280\u8853\u6539\u9032\u4e86\u6e96\u78ba\u5ea6\u3002Yuan 2.0-M32 \u4f7f\u7528 2000B \u4ee4\u724c\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\uff0c\u800c\u8a13\u7df4\u904b\u7b97\u6d88\u8017\u50c5\u70ba\u76f8\u540c\u53c3\u6578\u898f\u6a21\u4e0b\u5bc6\u96c6\u6a21\u578b\u7684 9.25%\u3002Yuan 2.0-M32 \u5728\u7de8\u78bc\u3001\u6578\u5b78\u548c\u5404\u7a2e\u5c08\u696d\u9818\u57df\u5c55\u793a\u51fa\u7af6\u722d\u529b\uff0c\u7e3d\u5171\u50c5\u6709 40B \u4e2d\u7684 3.7B \u500b\u6d3b\u8e8d\u53c3\u6578\uff0c\u4e14\u6bcf\u500b\u4ee4\u724c\u7684\u6b63\u5411\u904b\u7b97\u70ba 7.4 GFlops\uff0c\u9019\u5169\u8005\u90fd\u50c5\u70ba Llama3-70B \u7684 1/19\u3002Yuan 2.0-M32 \u5728 MATH \u548c ARC-Challenge \u57fa\u6e96\u6e2c\u8a66\u4e2d\u8d85\u8d8a Llama3-70B\uff0c\u6e96\u78ba\u5ea6\u5206\u5225\u70ba 55.89 \u548c 95.8\u3002Yuan 2.0-M32 \u7684\u6a21\u578b\u548c\u539f\u59cb\u7a0b\u5f0f\u78bc\u5df2\u5728 Github1 \u4e0a\u767c\u5e03\u3002", "author": "Shaohua Wu et.al.", "authors": "Shaohua Wu, Jiangang Luo, Xi Chen, Lingjun Li, Xudong Zhao, Tong Yu, Chao Wang, Yue Wang, Fei Wang, Weixu Qiao, Houbo He, Zeru Zhang, Zeyu Sun, Junxiong Mao, Chong Shen", "id": "2405.17976v2", "paper_url": "http://arxiv.org/abs/2405.17976v2", "repo": "https://github.com/ieit-yuan/yuan2.0-m32"}}