{"2411.19064": {"publish_time": "2024-11-28", "title": "Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph", "paper_summary": "Large language models (LLMs) have demonstrated exceptional performance across\na wide variety of domains. Nonetheless, generalist LLMs continue to fall short\nin reasoning tasks necessitating specialized knowledge. Prior investigations\ninto specialized LLMs focused on domain-specific training, which entails\nsubstantial efforts in domain data acquisition and model parameter fine-tuning.\nTo address these challenges, this paper proposes the Way-to-Specialist (WTS)\nframework, which synergizes retrieval-augmented generation with knowledge\ngraphs (KGs) to enhance the specialized capability of LLMs in the absence of\nspecialized training. In distinction to existing paradigms that merely utilize\nexternal knowledge from general KGs or static domain KGs to prompt LLM for\nenhanced domain-specific reasoning, WTS proposes an innovative\n\"LLM$\\circlearrowright$KG\" paradigm, which achieves bidirectional enhancement\nbetween specialized LLM and domain knowledge graph (DKG). The proposed paradigm\nencompasses two closely coupled components: the DKG-Augmented LLM and the\nLLM-Assisted DKG Evolution. The former retrieves question-relevant domain\nknowledge from DKG and uses it to prompt LLM to enhance the reasoning\ncapability for domain-specific tasks; the latter leverages LLM to generate new\ndomain knowledge from processed tasks and use it to evolve DKG. WTS closes the\nloop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling\ncontinuous improvement in the domain specialization as it progressively answers\nand learns from domain-specific questions. We validate the performance of WTS\non 6 datasets spanning 5 domains. The experimental results show that WTS\nsurpasses the previous SOTA in 4 specialized domains and achieves a maximum\nperformance improvement of 11.3%.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u500b\u9818\u57df\u5c55\u73fe\u51fa\u512a\u7570\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u901a\u624d LLM \u5728\u9700\u8981\u5c08\u696d\u77e5\u8b58\u7684\u63a8\u7406\u4efb\u52d9\u4e2d\u4ecd\u8868\u73fe\u4e0d\u4f73\u3002\u5148\u524d\u5c0d\u5c08\u696d LLM \u7684\u7814\u7a76\u96c6\u4e2d\u5728\u7279\u5b9a\u9818\u57df\u8a13\u7df4\uff0c\u9019\u9700\u8981\u5927\u91cf\u9818\u57df\u8cc7\u6599\u53d6\u5f97\u548c\u6a21\u578b\u53c3\u6578\u5fae\u8abf\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u672c\u6587\u63d0\u51fa Way-to-Specialist (WTS) \u67b6\u69cb\uff0c\u5b83\u5c07\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u8207\u77e5\u8b58\u5716\u8b5c (KG) \u7d50\u5408\u8d77\u4f86\uff0c\u4ee5\u63d0\u5347 LLM \u5728\u6c92\u6709\u5c08\u696d\u8a13\u7df4\u60c5\u6cc1\u4e0b\u7684\u5c08\u696d\u80fd\u529b\u3002\u8207\u50c5\u5229\u7528\u4f86\u81ea\u4e00\u822c KG \u6216\u975c\u614b\u9818\u57df KG \u7684\u5916\u90e8\u77e5\u8b58\u63d0\u793a LLM \u4ee5\u589e\u5f37\u7279\u5b9a\u9818\u57df\u63a8\u7406\u7684\u65e2\u6709\u7bc4\u4f8b\u4e0d\u540c\uff0cWTS \u63d0\u51fa\u4e00\u500b\u5275\u65b0\u7684\u300cLLM$\\circlearrowright$KG\u300d\u7bc4\u4f8b\uff0c\u5b83\u5728\u5c08\u696d LLM \u548c\u9818\u57df\u77e5\u8b58\u5716\u8b5c (DKG) \u4e4b\u9593\u5be6\u73fe\u96d9\u5411\u589e\u5f37\u3002\u6240\u63d0\u51fa\u7684\u7bc4\u4f8b\u5305\u542b\u5169\u500b\u7dca\u5bc6\u7d50\u5408\u7684\u7d44\u6210\u90e8\u5206\uff1aDKG \u589e\u5f37 LLM \u548c LLM \u8f14\u52a9 DKG \u6f14\u5316\u3002\u524d\u8005\u5f9e DKG \u4e2d\u6aa2\u7d22\u8207\u554f\u984c\u76f8\u95dc\u7684\u9818\u57df\u77e5\u8b58\uff0c\u4e26\u4f7f\u7528\u5b83\u63d0\u793a LLM \u4ee5\u589e\u5f37\u7279\u5b9a\u9818\u57df\u4efb\u52d9\u7684\u63a8\u7406\u80fd\u529b\uff1b\u5f8c\u8005\u5229\u7528 LLM \u5f9e\u8655\u7406\u904e\u7684\u4efb\u52d9\u4e2d\u7522\u751f\u65b0\u7684\u9818\u57df\u77e5\u8b58\uff0c\u4e26\u4f7f\u7528\u5b83\u4f86\u6f14\u5316 DKG\u3002WTS \u9589\u5408\u4e86 DKG \u589e\u5f37 LLM \u548c LLM \u8f14\u52a9 DKG \u6f14\u5316\u4e4b\u9593\u7684\u8ff4\u8def\uff0c\u96a8\u8457\u5b83\u9010\u6f38\u56de\u7b54\u548c\u5b78\u7fd2\u7279\u5b9a\u9818\u57df\u554f\u984c\uff0c\u80fd\u5920\u6301\u7e8c\u6539\u5584\u9818\u57df\u5c08\u696d\u5316\u3002\u6211\u5011\u5728\u6a6b\u8de8 5 \u500b\u9818\u57df\u7684 6 \u500b\u8cc7\u6599\u96c6\u4e0a\u9a57\u8b49 WTS \u7684\u6548\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cWTS \u5728 4 \u500b\u5c08\u696d\u9818\u57df\u4e2d\u8d85\u8d8a\u5148\u524d\u7684 SOTA\uff0c\u4e26\u9054\u5230 11.3% \u7684\u6700\u5927\u6548\u80fd\u63d0\u5347\u3002", "author": "Yutong Zhang et.al.", "authors": "Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai", "id": "2411.19064v1", "paper_url": "http://arxiv.org/abs/2411.19064v1", "repo": "null"}}