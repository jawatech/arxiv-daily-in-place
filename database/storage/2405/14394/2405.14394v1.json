{"2405.14394": {"publish_time": "2024-05-23", "title": "Instruction Tuning With Loss Over Instructions", "paper_summary": "Instruction tuning plays a crucial role in shaping the outputs of language\nmodels (LMs) to desired styles. In this work, we propose a simple yet effective\nmethod, Instruction Modelling (IM), which trains LMs by applying a loss\nfunction to the instruction and prompt part rather than solely to the output\npart. Through experiments across 21 diverse benchmarks, we show that, in many\nscenarios, IM can effectively improve the LM performance on both NLP tasks\n(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks\n(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM\nboosts model performance on AlpacaEval 1.0 by over 100%. We identify two key\nfactors influencing the effectiveness of IM: (1) The ratio between instruction\nlength and output length in the training data; and (2) The number of training\nexamples. We observe that IM is especially beneficial when trained on datasets\nwith lengthy instructions paired with brief outputs, or under the Superficial\nAlignment Hypothesis (SAH) where a small amount of training examples are used\nfor instruction tuning. Further analysis substantiates our hypothesis that the\nimprovement can be attributed to reduced overfitting to instruction tuning\ndatasets. Our work provides practical guidance for instruction tuning LMs,\nespecially in low-resource scenarios.", "paper_summary_zh": "\u6307\u4ee4\u5fae\u8c03\u5728\u5851\u9020\u8bed\u8a00\u6a21\u578b (LM) \u7684\u8f93\u51fa\u4ee5\u8fbe\u5230\u6240\u9700\u7684\u98ce\u683c\u65b9\u9762\u53d1\u6325\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u6307\u4ee4\u5efa\u6a21 (IM)\uff0c\u5b83\u901a\u8fc7\u5bf9\u6307\u4ee4\u548c\u63d0\u793a\u90e8\u5206\u5e94\u7528\u635f\u5931\u51fd\u6570\u6765\u8bad\u7ec3 LM\uff0c\u800c\u4e0d\u662f\u4ec5\u5bf9\u8f93\u51fa\u90e8\u5206\u5e94\u7528\u635f\u5931\u51fd\u6570\u3002\u901a\u8fc7\u5bf9 21 \u4e2a\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u8868\u660e\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0cIM \u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8 LM \u5728 NLP \u4efb\u52a1\uff08\u4f8b\u5982\uff0cMMLU\u3001TruthfulQA \u548c HumanEval\uff09\u548c\u5f00\u653e\u5f0f\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\uff08\u4f8b\u5982\uff0cMT-Bench \u548c AlpacaEval\uff09\u4e0a\u7684\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6700\u6709\u5229\u7684\u60c5\u51b5\u4e0b\uff0cIM \u5c06 AlpacaEval 1.0 \u4e0a\u7684\u6a21\u578b\u6027\u80fd\u63d0\u5347\u4e86 100% \u4ee5\u4e0a\u3002\u6211\u4eec\u786e\u5b9a\u4e86\u5f71\u54cd IM \u6709\u6548\u6027\u7684\u4e24\u4e2a\u5173\u952e\u56e0\u7d20\uff1a(1) \u8bad\u7ec3\u6570\u636e\u4e2d\u6307\u4ee4\u957f\u5ea6\u4e0e\u8f93\u51fa\u957f\u5ea6\u4e4b\u95f4\u7684\u6bd4\u7387\uff1b(2) \u8bad\u7ec3\u793a\u4f8b\u7684\u6570\u91cf\u3002\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5f53\u5728\u6307\u4ee4\u4e0e\u7b80\u77ed\u8f93\u51fa\u914d\u5bf9\u7684\u957f\u6307\u4ee4\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0cIM \u7279\u522b\u6709\u76ca\uff0c\u6216\u8005\u5728\u4f7f\u7528\u5c11\u91cf\u8bad\u7ec3\u793a\u4f8b\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u7684\u8868\u9762\u5bf9\u9f50\u5047\u8bbe (SAH) \u4e0b\u3002\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u8bc1\u5b9e\u4e86\u6211\u4eec\u7684\u5047\u8bbe\uff0c\u5373\u6539\u8fdb\u53ef\u4ee5\u5f52\u56e0\u4e8e\u5bf9\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u7684\u8fc7\u5ea6\u62df\u5408\u51cf\u5c11\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u6307\u4ee4\u5fae\u8c03 LM \u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u532e\u4e4f\u7684\u60c5\u51b5\u4e0b\u3002", "author": "Zhengyan Shi et.al.", "authors": "Zhengyan Shi, Adam X. Yang, Bin Wu, Laurence Aitchison, Emine Yilmaz, Aldo Lipani", "id": "2405.14394v1", "paper_url": "http://arxiv.org/abs/2405.14394v1", "repo": "null"}}