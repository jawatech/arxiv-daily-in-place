{"2409.13731": {"publish_time": "2024-09-10", "title": "KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation", "paper_summary": "The recently developed retrieval-augmented generation (RAG) technology has\nenabled the efficient construction of domain-specific applications. However, it\nalso has limitations, including the gap between vector similarity and the\nrelevance of knowledge reasoning, as well as insensitivity to knowledge logic,\nsuch as numerical values, temporal relations, expert rules, and others, which\nhinder the effectiveness of professional knowledge services. In this work, we\nintroduce a professional domain knowledge service framework called Knowledge\nAugmented Generation (KAG). KAG is designed to address the aforementioned\nchallenges with the motivation of making full use of the advantages of\nknowledge graph(KG) and vector retrieval, and to improve generation and\nreasoning performance by bidirectionally enhancing large language models (LLMs)\nand KGs through five key aspects: (1) LLM-friendly knowledge representation,\n(2) mutual-indexing between knowledge graphs and original chunks, (3)\nlogical-form-guided hybrid reasoning engine, (4) knowledge alignment with\nsemantic reasoning, and (5) model capability enhancement for KAG. We compared\nKAG with existing RAG methods in multihop question answering and found that it\nsignificantly outperforms state-of-theart methods, achieving a relative\nimprovement of 19.6% on 2wiki and 33.5% on hotpotQA in terms of F1 score. We\nhave successfully applied KAG to two professional knowledge Q&A tasks of Ant\nGroup, including E-Government Q&A and E-Health Q&A, achieving significant\nimprovement in professionalism compared to RAG methods.", "paper_summary_zh": "\u6700\u8fd1\u958b\u767c\u7684\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u6280\u8853\u5df2\u80fd\u6709\u6548\u5efa\u69cb\u7279\u5b9a\u9818\u57df\u7684\u61c9\u7528\u7a0b\u5f0f\u3002\u7136\u800c\uff0c\u5b83\u4e5f\u6709\u4e00\u4e9b\u9650\u5236\uff0c\u5305\u62ec\u5411\u91cf\u76f8\u4f3c\u6027\u8207\u77e5\u8b58\u63a8\u7406\u95dc\u806f\u6027\u4e4b\u9593\u7684\u5dee\u8ddd\uff0c\u4ee5\u53ca\u5c0d\u77e5\u8b58\u908f\u8f2f\u7684\u4e0d\u654f\u611f\u6027\uff0c\u4f8b\u5982\u6578\u503c\u3001\u6642\u9593\u95dc\u4fc2\u3001\u5c08\u5bb6\u898f\u5247\u7b49\uff0c\u9019\u4e9b\u90fd\u963b\u7919\u4e86\u5c08\u696d\u77e5\u8b58\u670d\u52d9\u7684\u6548\u80fd\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u500b\u540d\u70ba\u77e5\u8b58\u589e\u5f37\u751f\u6210 (KAG) \u7684\u5c08\u696d\u9818\u57df\u77e5\u8b58\u670d\u52d9\u67b6\u69cb\u3002KAG \u7684\u8a2d\u8a08\u76ee\u7684\u662f\u70ba\u4e86\u900f\u904e\u5145\u5206\u5229\u7528\u77e5\u8b58\u5716\u8b5c (KG) \u548c\u5411\u91cf\u6aa2\u7d22\u7684\u512a\u52e2\uff0c\u4e26\u900f\u904e\u96d9\u5411\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c KG \u4f86\u6539\u5584\u751f\u6210\u548c\u63a8\u7406\u6548\u80fd\uff0c\u5f9e\u800c\u89e3\u6c7a\u4e0a\u8ff0\u6311\u6230\uff0c\u5177\u9ad4\u505a\u6cd5\u5305\u62ec\u4e94\u500b\u95dc\u9375\u65b9\u9762\uff1a(1) LLM \u53cb\u5584\u7684\u77e5\u8b58\u8868\u5fb5\uff0c(2) \u77e5\u8b58\u5716\u8b5c\u548c\u539f\u59cb\u5340\u584a\u4e4b\u9593\u7684\u76f8\u4e92\u7d22\u5f15\uff0c(3) \u908f\u8f2f\u5f62\u5f0f\u5c0e\u5411\u7684\u6df7\u5408\u63a8\u7406\u5f15\u64ce\uff0c(4) \u5177\u6709\u8a9e\u610f\u63a8\u7406\u7684\u77e5\u8b58\u5c0d\u9f4a\uff0c\u4ee5\u53ca (5) KAG \u7684\u6a21\u578b\u80fd\u529b\u589e\u5f37\u3002\u6211\u5011\u5c07 KAG \u8207\u73fe\u6709\u7684 RAG \u65b9\u6cd5\u9032\u884c\u591a\u8df3\u5f0f\u554f\u7b54\u6bd4\u8f03\uff0c\u767c\u73fe\u5b83\u986f\u8457\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u5728 F1 \u5206\u6578\u65b9\u9762\u5206\u5225\u5728 2wiki \u4e0a\u63d0\u5347\u4e86 19.6%\uff0c\u5728 hotpotQA \u4e0a\u63d0\u5347\u4e86 33.5%\u3002\u6211\u5011\u5df2\u6210\u529f\u5c07 KAG \u61c9\u7528\u65bc\u879e\u87fb\u96c6\u5718\u7684\u5169\u500b\u5c08\u696d\u77e5\u8b58\u554f\u7b54\u4efb\u52d9\uff0c\u5305\u62ec\u96fb\u5b50\u653f\u52d9\u554f\u7b54\u548c\u96fb\u5b50\u5065\u5eb7\u554f\u7b54\uff0c\u8207 RAG \u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u5c08\u696d\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u7684\u9032\u6b65\u3002", "author": "Lei Liang et.al.", "authors": "Lei Liang, Mengshu Sun, Zhengke Gui, Zhongshu Zhu, Zhouyu Jiang, Ling Zhong, Yuan Qu, Peilong Zhao, Zhongpu Bo, Jin Yang, Huaidong Xiong, Lin Yuan, Jun Xu, Zaoyang Wang, Zhiqiang Zhang, Wen Zhang, Huajun Chen, Wenguang Chen, Jun Zhou", "id": "2409.13731v2", "paper_url": "http://arxiv.org/abs/2409.13731v2", "repo": "null"}}