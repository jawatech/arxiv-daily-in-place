{"2409.10502": {"publish_time": "2024-09-16", "title": "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles", "paper_summary": "Causal language modeling using the Transformer architecture has yielded\nremarkable capabilities in Large Language Models (LLMs) over the last few\nyears. However, the extent to which fundamental search and reasoning\ncapabilities emerged within LLMs remains a topic of ongoing debate. In this\nwork, we study if causal language modeling can learn a complex task such as\nsolving Sudoku puzzles. To solve a Sudoku, the model is first required to\nsearch over all empty cells of the puzzle to decide on a cell to fill and then\napply an appropriate strategy to fill the decided cell. Sometimes, the\napplication of a strategy only results in thinning down the possible values in\na cell rather than concluding the exact value of the cell. In such cases,\nmultiple strategies are applied one after the other to fill a single cell. We\nobserve that Transformer models trained on this synthetic task can indeed learn\nto solve Sudokus (our model solves $94.21\\%$ of the puzzles fully correctly)\nwhen trained on a logical sequence of steps taken by a solver. We find that\ntraining Transformers with the logical sequence of steps is necessary and\nwithout such training, they fail to learn Sudoku. We also extend our analysis\nto Zebra puzzles (known as Einstein puzzles) and show that the model solves\n$92.04 \\%$ of the puzzles fully correctly. In addition, we study the internal\nrepresentations of the trained Transformer and find that through linear\nprobing, we can decode information about the set of possible values in any\ngiven cell from them, pointing to the presence of a strong reasoning engine\nimplicit in the Transformer weights.", "paper_summary_zh": "<paragraph>\u5728\u8fc7\u53bb\u51e0\u5e74\u4e2d\uff0c\u4f7f\u7528 Transformer \u67b6\u6784\u7684\u56e0\u679c\u8bed\u8a00\u5efa\u6a21\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e2d\u4ea7\u751f\u4e86\u975e\u51e1\u7684\u80fd\u529b\u3002\u7136\u800c\uff0cLLM \u4e2d\u57fa\u672c\u641c\u7d22\u548c\u63a8\u7406\u80fd\u529b\u7684\u7a0b\u5ea6\u5982\u4f55\u4ecd\u7136\u662f\u4e00\u4e2a\u6301\u7eed\u4e89\u8bba\u7684\u8bdd\u9898\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u56e0\u679c\u8bed\u8a00\u5efa\u6a21\u662f\u5426\u53ef\u4ee5\u5b66\u4e60\u4e00\u9879\u590d\u6742\u7684\u4efb\u52a1\uff0c\u4f8b\u5982\u89e3\u51b3\u6570\u72ec\u8c1c\u9898\u3002\u8981\u89e3\u51b3\u6570\u72ec\u8c1c\u9898\uff0c\u9996\u5148\u8981\u6c42\u6a21\u578b\u641c\u7d22\u8c1c\u9898\u7684\u6240\u6709\u7a7a\u5355\u5143\u683c\uff0c\u4ee5\u51b3\u5b9a\u8981\u586b\u5199\u7684\u5355\u5143\u683c\uff0c\u7136\u540e\u5e94\u7528\u9002\u5f53\u7684\u7b56\u7565\u6765\u586b\u5145\u5206\u914d\u7684\u5355\u5143\u683c\u3002\u6709\u65f6\uff0c\u7b56\u7565\u7684\u5e94\u7528\u53ea\u4f1a\u51cf\u5c11\u5355\u5143\u683c\u4e2d\u7684\u53ef\u80fd\u503c\uff0c\u800c\u4e0d\u662f\u5f97\u51fa\u5355\u5143\u683c\u7684\u786e\u5207\u503c\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u591a\u4e2a\u7b56\u7565\u4e00\u4e2a\u63a5\u4e00\u4e2a\u5730\u5e94\u7528\u4e8e\u586b\u5145\u5355\u4e2a\u5355\u5143\u683c\u3002\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5728\u6b64\u5408\u6210\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684 Transformer \u6a21\u578b\u786e\u5b9e\u53ef\u4ee5\u5b66\u4f1a\u89e3\u51b3\u6570\u72ec\u8c1c\u9898\uff08\u6211\u4eec\u7684\u6a21\u578b\u5b8c\u5168\u6b63\u786e\u5730\u89e3\u51b3\u4e86 94.21% \u7684\u8c1c\u9898\uff09\uff0c\u5f53\u6839\u636e\u89e3\u51b3\u8005\u91c7\u53d6\u7684\u903b\u8f91\u6b65\u9aa4\u5e8f\u5217\u8fdb\u884c\u8bad\u7ec3\u65f6\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u4f7f\u7528\u903b\u8f91\u6b65\u9aa4\u5e8f\u5217\u8bad\u7ec3 Transformer \u662f\u5fc5\u8981\u7684\uff0c\u5982\u679c\u6ca1\u6709\u8fd9\u6837\u7684\u8bad\u7ec3\uff0c\u5b83\u4eec\u5c06\u65e0\u6cd5\u5b66\u4e60\u6570\u72ec\u3002\u6211\u4eec\u8fd8\u5c06\u6211\u4eec\u7684\u5206\u6790\u6269\u5c55\u5230\u6591\u9a6c\u8c1c\u9898\uff08\u79f0\u4e3a\u7231\u56e0\u65af\u5766\u8c1c\u9898\uff09\uff0c\u5e76\u8868\u660e\u8be5\u6a21\u578b\u5b8c\u5168\u6b63\u786e\u5730\u89e3\u51b3\u4e86 92.04% \u7684\u8c1c\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u7ecf\u8fc7\u8bad\u7ec3\u7684 Transformer \u7684\u5185\u90e8\u8868\u793a\uff0c\u5e76\u53d1\u73b0\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\uff0c\u6211\u4eec\u53ef\u4ee5\u4ece\u4e2d\u89e3\u7801\u6709\u5173\u4efb\u4f55\u7ed9\u5b9a\u5355\u5143\u683c\u4e2d\u53ef\u80fd\u503c\u96c6\u5408\u7684\u4fe1\u606f\uff0c\u8fd9\u8868\u660e Transformer \u6743\u91cd\u4e2d\u5b58\u5728\u4e00\u4e2a\u5f3a\u5927\u7684\u63a8\u7406\u5f15\u64ce\u3002</paragraph>", "author": "Kulin Shah et.al.", "authors": "Kulin Shah, Nishanth Dikkala, Xin Wang, Rina Panigrahy", "id": "2409.10502v1", "paper_url": "http://arxiv.org/abs/2409.10502v1", "repo": "null"}}