{"2409.04272": {"publish_time": "2024-09-06", "title": "Cycle Pixel Difference Network for Crisp Edge Detection", "paper_summary": "Edge detection, as a fundamental task in computer vision, has garnered\nincreasing attention. The advent of deep learning has significantly advanced\nthis field. However, recent deep learning-based methods which rely on\nlarge-scale pre-trained weights cannot be trained from scratch, with very\nlimited research addressing this issue. This paper proposes a novel cycle pixel\ndifference convolution (CPDC), which effectively integrates image gradient\ninformation with modern convolution operations. Based on the CPDC, we develop a\nU-shape encoder-decoder model named CPD-Net, which is a purely end-to-end\nnetwork. Additionally, to address the issue of edge thickness produced by most\nexisting methods, we construct a multi-scale information enhancement module\n(MSEM) to enhance the discriminative ability of the model, thereby generating\ncrisp and clean contour maps. Comprehensive experiments conducted on three\nstandard benchmarks demonstrate that our method achieves competitive\nperformance on the BSDS500 dataset (ODS=0.813), NYUD-V2 (ODS=0.760), and BIPED\ndataset (ODS=0.898). Our approach provides a novel perspective for addressing\nthese challenges in edge detection.", "paper_summary_zh": "\u908a\u7de3\u6aa2\u6e2c\u4f5c\u70ba\u96fb\u8166\u8996\u89ba\u4e2d\u7684\u4e00\u9805\u57fa\u672c\u4efb\u52d9\uff0c\u5df2\u7372\u5f97\u8d8a\u4f86\u8d8a\u591a\u7684\u95dc\u6ce8\u3002\u6df1\u5ea6\u5b78\u7fd2\u7684\u51fa\u73fe\u986f\u8457\u63a8\u52d5\u4e86\u9019\u4e00\u9818\u57df\u7684\u767c\u5c55\u3002\u7136\u800c\uff0c\u4f9d\u8cf4\u65bc\u5927\u898f\u6a21\u9810\u8a13\u7df4\u6b0a\u91cd\u7684\u8fd1\u671f\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u7121\u6cd5\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\uff0c\u800c\u91dd\u5c0d\u6b64\u554f\u984c\u7684\u7814\u7a76\u975e\u5e38\u6709\u9650\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5faa\u74b0\u50cf\u7d20\u5dee\u5206\u5377\u7a4d (CPDC)\uff0c\u5b83\u6709\u6548\u5730\u5c07\u5716\u50cf\u68af\u5ea6\u8cc7\u8a0a\u8207\u73fe\u4ee3\u5377\u7a4d\u904b\u7b97\u6574\u5408\u5728\u4e00\u8d77\u3002\u57fa\u65bc CPDC\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u540d\u70ba CPD-Net \u7684 U \u5f62\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u6a21\u578b\uff0c\u5b83\u662f\u4e00\u500b\u7d14\u7cb9\u7684\u7aef\u5230\u7aef\u7db2\u8def\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u89e3\u6c7a\u5927\u591a\u6578\u73fe\u6709\u65b9\u6cd5\u7522\u751f\u7684\u908a\u7de3\u7c97\u7d30\u554f\u984c\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u4e00\u500b\u591a\u5c3a\u5ea6\u8cc7\u8a0a\u589e\u5f37\u6a21\u7d44 (MSEM) \u4f86\u589e\u5f37\u6a21\u578b\u7684\u8fa8\u5225\u80fd\u529b\uff0c\u5f9e\u800c\u751f\u6210\u6e05\u6670\u4e7e\u6de8\u7684\u8f2a\u5ed3\u5716\u3002\u5728\u4e09\u500b\u6a19\u6e96\u57fa\u6e96\u4e0a\u9032\u884c\u7684\u7d9c\u5408\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728 BSDS500 \u8cc7\u6599\u96c6 (ODS=0.813)\u3001NYUD-V2 (ODS=0.760) \u548c BIPED \u8cc7\u6599\u96c6 (ODS=0.898) \u4e0a\u53d6\u5f97\u4e86\u6709\u7af6\u722d\u529b\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u6a21\u578b\u70ba\u89e3\u6c7a\u908a\u7de3\u6aa2\u6e2c\u4e2d\u7684\u9019\u4e9b\u6311\u6230\u63d0\u4f9b\u4e86\u4e00\u500b\u65b0\u7684\u8996\u89d2\u3002", "author": "Changsong Liu et.al.", "authors": "Changsong Liu, Wei Zhang, Yanyan Liu, Mingyang Li, Wenlin Li, Yimeng Fan, Xiangnan Bai, Liang Zhangd", "id": "2409.04272v1", "paper_url": "http://arxiv.org/abs/2409.04272v1", "repo": "null"}}