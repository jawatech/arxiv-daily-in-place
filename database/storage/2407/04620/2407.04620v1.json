{"2407.04620": {"publish_time": "2024-07-05", "title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States", "paper_summary": "Self-attention performs well in long context but has quadratic complexity.\nExisting RNN layers have linear complexity, but their performance in long\ncontext is limited by the expressive power of their hidden state. We propose a\nnew class of sequence modeling layers with linear complexity and an expressive\nhidden state. The key idea is to make the hidden state a machine learning model\nitself, and the update rule a step of self-supervised learning. Since the\nhidden state is updated by training even on test sequences, our layers are\ncalled Test-Time Training (TTT) layers. We consider two instantiations:\nTTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer\nMLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B\nparameters, comparing with a strong Transformer and Mamba, a modern RNN. Both\nTTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer,\nthey can keep reducing perplexity by conditioning on more tokens, while Mamba\ncannot after 16k context. With preliminary systems optimization, TTT-Linear is\nalready faster than Transformer at 8k context and matches Mamba in wall-clock\ntime. TTT-MLP still faces challenges in memory I/O, but shows larger potential\nin long context, pointing to a promising direction for future research.", "paper_summary_zh": "\u81ea\u6ce8\u610f\u529b\u5728\u9577\u8a9e\u5883\u4e2d\u8868\u73fe\u826f\u597d\uff0c\u4f46\u5177\u6709\u4e8c\u6b21\u8907\u96dc\u5ea6\u3002\n\u73fe\u6709\u7684 RNN \u5c64\u5177\u6709\u7dda\u6027\u8907\u96dc\u5ea6\uff0c\u4f46\u5b83\u5011\u5728\u9577\u8a9e\u5883\u4e2d\u7684\u8868\u73fe\u53d7\u5230\u5176\u96b1\u85cf\u72c0\u614b\u8868\u9054\u80fd\u529b\u7684\u9650\u5236\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u985e\u5177\u6709\u7dda\u6027\u8907\u96dc\u5ea6\u548c\u8868\u9054\u6027\u96b1\u85cf\u72c0\u614b\u7684\u65b0\u578b\u5e8f\u5217\u5efa\u6a21\u5c64\u3002\u95dc\u9375\u601d\u60f3\u662f\u5c07\u96b1\u85cf\u72c0\u614b\u672c\u8eab\u4f5c\u70ba\u4e00\u500b\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\uff0c\u4e26\u5c07\u66f4\u65b0\u898f\u5247\u4f5c\u70ba\u81ea\u76e3\u7763\u5b78\u7fd2\u7684\u4e00\u500b\u6b65\u9a5f\u3002\u7531\u65bc\u96b1\u85cf\u72c0\u614b\u901a\u904e\u8a13\u7df4\u5373\u4f7f\u5728\u6e2c\u8a66\u5e8f\u5217\u4e0a\u4e5f\u6703\u66f4\u65b0\uff0c\u56e0\u6b64\u6211\u5011\u7684\u5c64\u88ab\u7a31\u70ba\u6e2c\u8a66\u6642\u8a13\u7df4 (TTT) \u5c64\u3002\u6211\u5011\u8003\u616e\u4e86\u5169\u500b\u5be6\u4f8b\uff1aTTT-Linear \u548c TTT-MLP\uff0c\u5b83\u5011\u7684\u96b1\u85cf\u72c0\u614b\u5206\u5225\u662f\u4e00\u500b\u7dda\u6027\u6a21\u578b\u548c\u4e00\u500b\u5169\u5c64 MLP\u3002\u6211\u5011\u5728 125M \u5230 1.3B \u53c3\u6578\u7684\u898f\u6a21\u4e0a\u8a55\u4f30\u6211\u5011\u7684\u5be6\u4f8b\uff0c\u4e26\u8207\u4e00\u500b\u5f37\u5927\u7684 Transformer \u548c\u4e00\u500b\u73fe\u4ee3 RNN Mamba \u9032\u884c\u6bd4\u8f03\u3002TTT-Linear \u548c TTT-MLP \u90fd\u5339\u914d\u6216\u8d85\u904e\u4e86\u57fa\u6e96\u3002\u8207 Transformer \u985e\u4f3c\uff0c\u5b83\u5011\u53ef\u4ee5\u901a\u904e\u5c0d\u66f4\u591a\u4ee4\u724c\u9032\u884c\u689d\u4ef6\u5316\u4f86\u6301\u7e8c\u964d\u4f4e\u56f0\u60d1\u5ea6\uff0c\u800c Mamba \u5728 16k \u8a9e\u5883\u5f8c\u5247\u4e0d\u80fd\u3002\u901a\u904e\u521d\u6b65\u7684\u7cfb\u7d71\u512a\u5316\uff0cTTT-Linear \u5728 8k \u8a9e\u5883\u4e0b\u5df2\u7d93\u6bd4 Transformer \u66f4\u5feb\uff0c\u4e26\u4e14\u5728\u6642\u9418\u6642\u9593\u4e0a\u8207 Mamba \u5339\u914d\u3002TTT-MLP \u4ecd\u7136\u9762\u81e8\u5167\u5b58 I/O \u7684\u6311\u6230\uff0c\u4f46\u5728\u9577\u8a9e\u5883\u4e2d\u986f\u793a\u51fa\u66f4\u5927\u7684\u6f5b\u529b\uff0c\u9019\u70ba\u672a\u4f86\u7684\u7814\u7a76\u6307\u660e\u4e86\u4e00\u500b\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "author": "Yu Sun et.al.", "authors": "Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin", "id": "2407.04620v1", "paper_url": "http://arxiv.org/abs/2407.04620v1", "repo": "https://github.com/test-time-training/ttt-lm-jax"}}