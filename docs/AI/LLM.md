
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-26**|**StableAnimator: High-Quality Identity-Preserving Human Image Animation**|Shuyuan Tu et.al.|[2411.17697v1](http://arxiv.org/abs/2411.17697v1)|[link](https://github.com/Francis-Rings/StableAnimator)|
|**2024-11-26**|**Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats**|Jiaxin Wen et.al.|[2411.17693v1](http://arxiv.org/abs/2411.17693v1)|null|
|**2024-11-26**|**Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens**|Xu Ouyang et.al.|[2411.17691v1](http://arxiv.org/abs/2411.17691v1)|null|
|**2024-11-26**|**Attamba: Attending To Multi-Token States**|Yash Akhauri et.al.|[2411.17685v1](http://arxiv.org/abs/2411.17685v1)|null|
|**2024-11-26**|**Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning**|Zhu Xu et.al.|[2411.17679v1](http://arxiv.org/abs/2411.17679v1)|null|
|**2024-11-26**|**Push the Limit of Multi-modal Emotion Recognition by Prompting LLMs with Receptive-Field-Aware Attention Weighting**|Liyun Zhang et.al.|[2411.17674v1](http://arxiv.org/abs/2411.17674v1)|null|
|**2024-11-26**|**Linguistic Laws Meet Protein Sequences: A Comparative Analysis of Subword Tokenization Methods**|Burak Suyunu et.al.|[2411.17669v1](http://arxiv.org/abs/2411.17669v1)|[link](https://github.com/boun-tabi-lifelu/linguistics-meet-proteins)|
|**2024-11-26**|**How do Multimodal Foundation Models Encode Text and Speech? An Analysis of Cross-Lingual and Cross-Modal Representations**|Hyunji Lee et.al.|[2411.17666v1](http://arxiv.org/abs/2411.17666v1)|null|
|**2024-11-26**|**BERT or FastText? A Comparative Analysis of Contextual as well as Non-Contextual Embeddings**|Abhay Shanbhag et.al.|[2411.17661v1](http://arxiv.org/abs/2411.17661v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-26**|**On Limitations of LLM as Annotator for Low Resource Languages**|Suramya Jadhav et.al.|[2411.17637v1](http://arxiv.org/abs/2411.17637v1)|null|
|**2024-11-26**|**MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation**|Harsh Singh et.al.|[2411.17636v1](http://arxiv.org/abs/2411.17636v1)|null|
|**2024-11-26**|**Learning Chemical Reaction Representation with Reactant-Product Alignment**|Kaipeng Zeng et.al.|[2411.17629v1](http://arxiv.org/abs/2411.17629v1)|null|
|**2024-11-26**|**Mixed-State Quantum Denoising Diffusion Probabilistic Model**|Gino Kwun et.al.|[2411.17608v1](http://arxiv.org/abs/2411.17608v1)|null|
|**2024-11-26**|**Scaling Speech-Text Pre-training with Synthetic Interleaved Data**|Aohan Zeng et.al.|[2411.17607v1](http://arxiv.org/abs/2411.17607v1)|null|
|**2024-11-26**|**Making History Readable**|Bipasha Banerjee et.al.|[2411.17600v1](http://arxiv.org/abs/2411.17600v1)|null|
|**2024-11-26**|**Agentic AI for Improving Precision in Identifying Contributions to Sustainable Development Goals**|William A. Ingram et.al.|[2411.17598v1](http://arxiv.org/abs/2411.17598v1)|null|
|**2024-11-26**|**What Differentiates Educational Literature? A Multimodal Fusion Approach of Transformers and Computational Linguistics**|Jordan J. Bird et.al.|[2411.17593v1](http://arxiv.org/abs/2411.17593v1)|null|
|**2024-11-26**|**Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey**|Jiayi Kuang et.al.|[2411.17558v1](http://arxiv.org/abs/2411.17558v1)|null|
|**2024-11-26**|**A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**|Mengqian Dinga et.al.|[2411.17557v1](http://arxiv.org/abs/2411.17557v1)|null|
|**2024-11-26**|**Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search**|Andor Diera et.al.|[2411.17538v1](http://arxiv.org/abs/2411.17538v1)|[link](https://github.com/drndr/code_isotropy)|
|**2024-11-26**|**HSI-Drive v2.0: More Data for New Challenges in Scene Understanding for Autonomous Driving**|Jon Gutiérrez-Zaballa et.al.|[2411.17530v1](http://arxiv.org/abs/2411.17530v1)|null|
|**2024-11-26**|**On Statistical Rates of Conditional Diffusion Transformers: Approximation, Estimation and Minimax Optimality**|Jerry Yao-Chieh Hu et.al.|[2411.17522v1](http://arxiv.org/abs/2411.17522v1)|null|
|**2024-11-26**|**Inference Scaling $\scriptsize\mathtt{F}$Laws: The Limits of LLM Resampling with Imperfect Verifiers**|Benedikt Stroebl et.al.|[2411.17501v1](http://arxiv.org/abs/2411.17501v1)|[link](https://github.com/benediktstroebl/inference-scaling-limits)|
|**2024-11-26**|**What's in the Image? A Deep-Dive into the Vision of Vision Language Models**|Omri Kaduri et.al.|[2411.17491v1](http://arxiv.org/abs/2411.17491v1)|null|
|**2024-11-26**|**Puzzle Similarity: A Perceptually-guided No-Reference Metric for Artifact Detection in 3D Scene Reconstructions**|Nicolai Hermann et.al.|[2411.17489v1](http://arxiv.org/abs/2411.17489v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**SoK: Decentralized AI (DeAI)**|Zhipeng Wang et.al.|[2411.17461v1](http://arxiv.org/abs/2411.17461v1)|null|
|**2024-11-26**|**WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model**|Zongjian Li et.al.|[2411.17459v1](http://arxiv.org/abs/2411.17459v1)|[link](https://github.com/pku-yuangroup/wf-vae)|
|**2024-11-26**|**Spatially Visual Perception for End-to-End Robotic Learning**|Travis Davies et.al.|[2411.17458v1](http://arxiv.org/abs/2411.17458v1)|null|
|**2024-11-26**|**FLEX-CLIP: Feature-Level GEneration Network Enhanced CLIP for X-shot Cross-modal Retrieval**|Jingyou Xie et.al.|[2411.17454v1](http://arxiv.org/abs/2411.17454v1)|null|
|**2024-11-26**|**VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models**|Lei Li et.al.|[2411.17451v1](http://arxiv.org/abs/2411.17451v1)|null|
|**2024-11-26**|**Object-centric proto-symbolic behavioural reasoning from pixels**|Ruben van Bergen et.al.|[2411.17438v1](http://arxiv.org/abs/2411.17438v1)|[link](https://github.com/neuro-ai-robotics/OBR)|
|**2024-11-26**|**"Stupid robot, I want to speak to a human!" User Frustration Detection in Task-Oriented Dialog Systems**|Mireia Hernandez Caralt et.al.|[2411.17437v1](http://arxiv.org/abs/2411.17437v1)|null|
|**2024-11-26**|**LC-SVD-DLinear: A low-cost physics-based hybrid machine learning model for data forecasting using sparse measurements**|Ashton Hetherington et.al.|[2411.17433v1](http://arxiv.org/abs/2411.17433v1)|null|
|**2024-11-26**|**CLOVER: Constrained Learning with Orthonormal Vectors for Eliminating Redundancy**|Fanxu Meng et.al.|[2411.17426v1](http://arxiv.org/abs/2411.17426v1)|null|
|**2024-11-26**|**BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving**|Teng Wang et.al.|[2411.17404v1](http://arxiv.org/abs/2411.17404v1)|null|
|**2024-11-26**|**One Mind, Many Tongues: A Deep Dive into Language-Agnostic Knowledge Neurons in Large Language Models**|Pengfei Cao et.al.|[2411.17401v1](http://arxiv.org/abs/2411.17401v1)|null|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**The Extractive-Abstractive Spectrum: Uncovering Verifiability Trade-offs in LLM Generations**|Theodora Worledge et.al.|[2411.17375v1](http://arxiv.org/abs/2411.17375v1)|[link](https://github.com/guestrin-lab/extractive-abstractive-spectrum)|
|**2024-11-26**|**Fairness And Performance In Harmony: Data Debiasing Is All You Need**|Junhua Liu et.al.|[2411.17374v1](http://arxiv.org/abs/2411.17374v1)|null|
|**2024-11-26**|**Knowledge-aware Evolutionary Graph Neural Architecture Search**|Chao Wang et.al.|[2411.17339v1](http://arxiv.org/abs/2411.17339v1)|[link](https://github.com/xiaofangxd/KEGNAS)|
|**2024-11-26**|**Different Bias Under Different Criteria: Assessing Bias in LLMs with a Fact-Based Approach**|Changgeon Ko et.al.|[2411.17338v1](http://arxiv.org/abs/2411.17338v1)|[link](https://github.com/pencaty/Different-Bias-Under-Different-Criteria)|
|**2024-11-26**|**Towards Intention Recognition for Robotic Assistants Through Online POMDP Planning**|Juan Carlos Saborio et.al.|[2411.17326v1](http://arxiv.org/abs/2411.17326v1)|null|
|**2024-11-26**|**PIM-AI: A Novel Architecture for High-Efficiency LLM Inference**|Cristobal Ortega et.al.|[2411.17309v1](http://arxiv.org/abs/2411.17309v1)|null|
|**2024-11-26**|**Meaningless is better: hashing bias-inducing words in LLM prompts improves performance in logical reasoning and statistical learning**|Milena Chadimová et.al.|[2411.17304v1](http://arxiv.org/abs/2411.17304v1)|null|
|**2024-11-26**|**ER2Score: LLM-based Explainable and Customizable Metric for Assessing Radiology Reports with Reward-Control Loss**|Yunyi Liu et.al.|[2411.17301v1](http://arxiv.org/abs/2411.17301v1)|null|
|**2024-11-26**|**2D Matryoshka Training for Information Retrieval**|Shuai Wang et.al.|[2411.17299v1](http://arxiv.org/abs/2411.17299v1)|[link](https://github.com/ielab/2dmse-reproduce)|
|**2024-11-26**|**GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers**|Guoguo Ai et.al.|[2411.17296v1](http://arxiv.org/abs/2411.17296v1)|[link](https://github.com/GGA23/GrokFormer)|
|**2024-11-26**|**Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**|Om Ramakisan Varma et.al.|[2411.17282v1](http://arxiv.org/abs/2411.17282v1)|null|
|**2024-11-26**|**An Attempt to Develop a Neural Parser based on Simplified Head-Driven Phrase Structure Grammar on Vietnamese**|Duc-Vu Nguyen et.al.|[2411.17270v1](http://arxiv.org/abs/2411.17270v1)|null|
|**2024-11-26**|**A Topic-level Self-Correctional Approach to Mitigate Hallucinations in MLLMs**|Lehan He et.al.|[2411.17265v1](http://arxiv.org/abs/2411.17265v1)|null|
|**2024-11-26**|**HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator**|Fan Yang et.al.|[2411.17261v1](http://arxiv.org/abs/2411.17261v1)|null|
|**2024-11-26**|**MiceBoneChallenge: Micro-CT public dataset and six solutions for automatic growth plate detection in micro-CT mice bone scans**|Nikolay Burlutskiy et.al.|[2411.17260v1](http://arxiv.org/abs/2411.17260v1)|null|
|**2024-11-26**|**APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents**|Jun Yu Chen et.al.|[2411.17255v1](http://arxiv.org/abs/2411.17255v1)|[link](https://github.com/spearsheep/APT-Architectural-Planning-LLM-Agent)|
|**2024-11-26**|**Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors**|Zhengfei Kuang et.al.|[2411.17249v1](http://arxiv.org/abs/2411.17249v1)|null|
|**2024-11-26**|**From Graph Diffusion to Graph Classification**|Jia Jun Cheng Xian et.al.|[2411.17236v1](http://arxiv.org/abs/2411.17236v1)|null|
|**2024-11-26**|**Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**|Ratnesh Kumar Joshi et.al.|[2411.17204v1](http://arxiv.org/abs/2411.17204v1)|null|
|**2024-11-26**|**Learning Hierarchical Polynomials of Multiple Nonlinear Features with Three-Layer Networks**|Hengyu Fu et.al.|[2411.17201v1](http://arxiv.org/abs/2411.17201v1)|null|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-26**|**A Novel Word Pair-based Gaussian Sentence Similarity Algorithm For Bengali Extractive Text Summarization**|Fahim Morshed et.al.|[2411.17181v1](http://arxiv.org/abs/2411.17181v1)|[link](https://github.com/FMOpee/WGSS)|
|**2024-11-26**|**ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting**|Chengyou Jia et.al.|[2411.17176v1](http://arxiv.org/abs/2411.17176v1)|null|
|**2024-11-26**|**Learning Monotonic Attention in Transducer for Streaming Generation**|Zhengrui Ma et.al.|[2411.17170v1](http://arxiv.org/abs/2411.17170v1)|[link](https://github.com/ictnlp/monoattn-transducer)|
|**2024-11-26**|**LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble**|Yujeong Lee et.al.|[2411.17135v1](http://arxiv.org/abs/2411.17135v1)|null|
|**2024-11-26**|**DOGE: Towards Versatile Visual Document Grounding and Referring**|Yinan Zhou et.al.|[2411.17125v1](http://arxiv.org/abs/2411.17125v1)|null|
|**2024-11-26**|**Advancing Content Moderation: Evaluating Large Language Models for Detecting Sensitive Content Across Text, Images, and Videos**|Nouar AlDahoul et.al.|[2411.17123v1](http://arxiv.org/abs/2411.17123v1)|null|
|**2024-11-26**|**Star Attention: Efficient LLM Inference over Long Sequences**|Shantanu Acharya et.al.|[2411.17116v1](http://arxiv.org/abs/2411.17116v1)|[link](https://github.com/NVIDIA/Star-Attention)|
|**2024-11-26**|**Contrastive CFG: Improving CFG in Diffusion Models by Contrasting Positive and Negative Concepts**|Jinho Chang et.al.|[2411.17077v1](http://arxiv.org/abs/2411.17077v1)|null|
|**2024-11-26**|**Don't Command, Cultivate: An Exploratory Study of System-2 Alignment**|Yuhang Wang et.al.|[2411.17075v1](http://arxiv.org/abs/2411.17075v1)|null|
|**2024-11-26**|**Path-RAG: Knowledge-Guided Key Region Retrieval for Open-ended Pathology Visual Question Answering**|Awais Naeem et.al.|[2411.17073v1](http://arxiv.org/abs/2411.17073v1)|[link](https://github.com/embedded-robotics/path-rag)|
|**2024-11-26**|**Relations, Negations, and Numbers: Looking for Logic in Generative Text-to-Image Models**|Colin Conwell et.al.|[2411.17066v1](http://arxiv.org/abs/2411.17066v1)|[link](https://github.com/colinconwell/t2i-probology)|
|**2024-11-26**|**Creative Agents: Simulating the Systems Model of Creativity with Generative Agents**|Naomi Imasato et.al.|[2411.17065v1](http://arxiv.org/abs/2411.17065v1)|null|
|**2024-11-26**|**Graph Structure Learning with Bi-level Optimization**|Nan Yin et.al.|[2411.17062v1](http://arxiv.org/abs/2411.17062v1)|null|
|**2024-11-26**|**ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System**|Shuiqiao Yang et.al.|[2411.17058v1](http://arxiv.org/abs/2411.17058v1)|null|
|**2024-11-26**|**Free$^2$Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models**|Jaemin Kim et.al.|[2411.17041v1](http://arxiv.org/abs/2411.17041v1)|null|
|**2024-11-26**|**g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks**|Zihan Wang et.al.|[2411.17030v1](http://arxiv.org/abs/2411.17030v1)|[link](https://github.com/MrZihan/g3D-LF)|
|**2024-11-26**|**SatVision-TOA: A Geospatial Foundation Model for Coarse-Resolution All-Sky Remote Sensing Imagery**|Caleb S. Spradlin et.al.|[2411.17000v1](http://arxiv.org/abs/2411.17000v1)|[link](https://github.com/nasa-nccs-hpda/pytorch-caney)|
|**2024-11-25**|**Tree Transformers are an Ineffective Model of Syntactic Constituency**|Michael Ginn et.al.|[2411.16993v1](http://arxiv.org/abs/2411.16993v1)|null|
|**2024-11-25**|**Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning Small Language Models**|Yao Fu et.al.|[2411.16991v1](http://arxiv.org/abs/2411.16991v1)|null|
|**2024-11-25**|**Teaching Smaller Language Models To Generalise To Unseen Compositional Questions (Full Thesis)**|Tim Hartill et.al.|[2411.16985v1](http://arxiv.org/abs/2411.16985v1)|null|
|**2024-11-25**|**Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach**|Xiaoteng et.al.|[2411.16954v1](http://arxiv.org/abs/2411.16954v1)|[link](https://github.com/pavlyhalim/gpperf)|
|**2024-11-25**|**Harnessing LLMs for Educational Content-Driven Italian Crossword Generation**|Kamyar Zeinalipour et.al.|[2411.16936v1](http://arxiv.org/abs/2411.16936v1)|null|
|**2024-11-25**|**ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code**|Mohammad Jalili Torkamani et.al.|[2411.16927v1](http://arxiv.org/abs/2411.16927v1)|null|
|**2024-11-25**|**Boundless Socratic Learning with Language Games**|Tom Schaul et.al.|[2411.16905v1](http://arxiv.org/abs/2411.16905v1)|null|
|**2024-11-25**|**Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with Differential Transformer Based Deep Learning Model Incorporating Pixelwise Instrument Response Function**|Ismail Erbas et.al.|[2411.16896v1](http://arxiv.org/abs/2411.16896v1)|null|
|**2024-11-25**|**Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**|Margaret Capetz et.al.|[2411.16872v1](http://arxiv.org/abs/2411.16872v1)|null|
|**2024-11-25**|**Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering**|Federico Cocchi et.al.|[2411.16863v1](http://arxiv.org/abs/2411.16863v1)|[link](https://github.com/aimagelab/reflectiva)|
|**2024-11-25**|**Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**|Sohee Yang et.al.|[2411.16679v1](http://arxiv.org/abs/2411.16679v1)|null|
|**2024-11-25**|**Towards Precise Scaling Laws for Video Diffusion Transformers**|Yuanyang Yin et.al.|[2411.17470v1](http://arxiv.org/abs/2411.17470v1)|null|
|**2024-11-25**|**Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing**|Hanhui Wang et.al.|[2411.16832v1](http://arxiv.org/abs/2411.16832v1)|null|
|**2024-11-25**|**CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**|Jiaan Han et.al.|[2411.16666v2](http://arxiv.org/abs/2411.16666v2)|null|
|**2024-11-25**|**DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**|Zun Wang et.al.|[2411.16657v1](http://arxiv.org/abs/2411.16657v1)|null|
|**2024-11-25**|**Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge**|Yaqi Zhao et.al.|[2411.16824v1](http://arxiv.org/abs/2411.16824v1)|null|
|**2024-11-25**|**Self-Generated Critiques Boost Reward Modeling for Language Models**|Yue Yu et.al.|[2411.16646v1](http://arxiv.org/abs/2411.16646v1)|null|
|**2024-11-25**|**Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**|Dietmar Jannach et.al.|[2411.16645v1](http://arxiv.org/abs/2411.16645v1)|null|
|**2024-11-25**|**Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**|Jean Marie Tshimula et.al.|[2411.16642v1](http://arxiv.org/abs/2411.16642v1)|null|
|**2024-11-25**|**Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**|Sanjana Ramprasad et.al.|[2411.16638v2](http://arxiv.org/abs/2411.16638v2)|null|
|**2024-11-25**|**Imperceptible Adversarial Examples in the Physical World**|Weilin Xu et.al.|[2411.16622v1](http://arxiv.org/abs/2411.16622v1)|null|
|**2024-11-25**|**StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**|Kaustubh Ponkshe et.al.|[2411.16618v1](http://arxiv.org/abs/2411.16618v1)|null|
|**2024-11-25**|**Recent Trends in Linear Text Segmentation: a Survey**|Iacopo Ghinassi et.al.|[2411.16613v1](http://arxiv.org/abs/2411.16613v1)|null|

#### Abstracts
##### **StableAnimator: High-Quality Identity-Preserving Human Image Animation**
2411.17697v1 by Shuyuan Tu, Zhen Xing, Xintong Han, Zhi-Qi Cheng, Qi Dai, Chong Luo, Zuxuan Wu

Current diffusion models for human image animation struggle to ensure
identity (ID) consistency. This paper presents StableAnimator, the first
end-to-end ID-preserving video diffusion framework, which synthesizes
high-quality videos without any post-processing, conditioned on a reference
image and a sequence of poses. Building upon a video diffusion model,
StableAnimator contains carefully designed modules for both training and
inference striving for identity consistency. In particular, StableAnimator
begins by computing image and face embeddings with off-the-shelf extractors,
respectively and face embeddings are further refined by interacting with image
embeddings using a global content-aware Face Encoder. Then, StableAnimator
introduces a novel distribution-aware ID Adapter that prevents interference
caused by temporal layers while preserving ID via alignment. During inference,
we propose a novel Hamilton-Jacobi-Bellman (HJB) equation-based optimization to
further enhance the face quality. We demonstrate that solving the HJB equation
can be integrated into the diffusion denoising process, and the resulting
solution constrains the denoising path and thus benefits ID preservation.
Experiments on multiple benchmarks show the effectiveness of StableAnimator
both qualitatively and quantitatively.

摘要：目前的人像動畫擴散模型難以確保身分 (ID) 的一致性。本文提出 StableAnimator，第一個端對端的 ID 保留影片擴散架構，可以在不進行任何後處理的情況下，根據參考影像和一連串姿勢合成高品質影片。在影片擴散模型的基礎上，StableAnimator 包含仔細設計的模組，用於訓練和推論，以追求身分一致性。特別是，StableAnimator 先使用現成的萃取器分別計算影像和臉部嵌入，而臉部嵌入會進一步透過與影像嵌入互動，使用全球內容感知臉部編碼器進行改善。接著，StableAnimator 提出一個新穎的分布感知 ID 適配器，可防止時間層造成的干擾，同時透過對齊保留 ID。在推論期間，我們提出一個新穎的 Hamilton-Jacobi-Bellman (HJB) 方程式最佳化，以進一步提升臉部品質。我們證明了解決 HJB 方程式可以整合到擴散去噪過程中，而產生的解會限制去噪路徑，進而有利於 ID 保留。在多個基準測試上的實驗顯示，StableAnimator 在質量和量化上都展現出其有效性。

##### **Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats**
2411.17693v1 by Jiaxin Wen, Vivek Hebbar, Caleb Larson, Aryan Bhatt, Ansh Radhakrishnan, Mrinank Sharma, Henry Sleight, Shi Feng, He He, Ethan Perez, Buck Shlegeris, Akbir Khan

As large language models (LLMs) become increasingly capable, it is prudent to
assess whether safety measures remain effective even if LLMs intentionally try
to bypass them. Previous work introduced control evaluations, an adversarial
framework for testing deployment strategies of untrusted models (i.e., models
which might be trying to bypass safety measures). While prior work treats a
single failure as unacceptable, we perform control evaluations in a
"distributed threat setting" -- a setting where no single action is
catastrophic and no single action provides overwhelming evidence of
misalignment. We approach this problem with a two-level deployment framework
that uses an adaptive macro-protocol to choose between micro-protocols.
Micro-protocols operate on a single task, using a less capable, but extensively
tested (trusted) model to harness and monitor the untrusted model. Meanwhile,
the macro-protocol maintains an adaptive credence on the untrusted model's
alignment based on its past actions, using it to pick between safer and riskier
micro-protocols. We evaluate our method in a code generation testbed where a
red team attempts to generate subtly backdoored code with an LLM whose
deployment is safeguarded by a blue team. We plot Pareto frontiers of safety (#
of non-backdoored solutions) and usefulness (# of correct solutions). At a
given level of usefulness, our adaptive deployment strategy reduces the number
of backdoors by 80% compared to non-adaptive baselines.

摘要：隨著大型語言模型 (LLM) 變得越來越強大，審慎評估安全措施是否有效，即使 LLM 故意嘗試繞過它們，也是明智的。先前的研究引入了控制評估，這是一種對抗性框架，用於測試不受信任模型（即可能嘗試繞過安全措施的模型）的部署策略。雖然先前的研究將單一失敗視為不可接受，但我們在「分散威脅設定」中執行控制評估——在這種設定中，單一動作並非災難性的，而且單一動作不會提供明顯的錯位證據。我們以一個兩級部署框架來解決這個問題，該框架使用自適應巨量協定在微協定之間進行選擇。微協定在單一任務上執行，使用功能較弱但經過廣泛測試（受信任）的模型來利用和監控不受信任的模型。同時，巨量協定根據過去的行為維持對不受信任模型對齊的適應性信任，使用它來選擇較安全和較冒險的微協定。我們在一個程式碼產生測試環境中評估我們的模型，在該環境中，紅隊嘗試使用 LLM 產生微妙的後門程式碼，而藍隊則保護其部署。我們繪製了安全性的帕累托前緣（# 無後門解決方案）和實用性（# 正確解決方案）。在給定的實用性水準下，與非自適應基線相比，我們的自適應部署策略將後門數量減少了 80%。

##### **Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens**
2411.17691v1 by Xu Ouyang, Tao Ge, Thomas Hartvigsen, Zhisong Zhang, Haitao Mi, Dong Yu

We reveal that low-bit quantization favors undertrained large language models
(LLMs) by observing that models with larger sizes or fewer training tokens
experience less quantization-induced degradation (QiD) when applying low-bit
quantization, whereas smaller models with extensive training tokens suffer
significant QiD. To gain deeper insights into this trend, we study over 1500
quantized LLM checkpoints of various sizes and at different training levels
(undertrained or fully trained) in a controlled setting, deriving scaling laws
for understanding the relationship between QiD and factors such as the number
of training tokens, model size and bit width.
  With the derived scaling laws, we propose a novel perspective that we can use
QiD to measure an LLM's training levels and determine the number of training
tokens required for fully training LLMs of various sizes. Moreover, we use the
scaling laws to predict the quantization performance of different-sized LLMs
trained with 100 trillion tokens. Our projection shows that the low-bit
quantization performance of future models, which are expected to be trained
with over 100 trillion tokens, may NOT be desirable. This poses a potential
challenge for low-bit quantization in the future and highlights the need for
awareness of a model's training level when evaluating low-bit quantization
research. To facilitate future research on this problem, we release all the
1500+ quantized checkpoints used in this work at
https://huggingface.co/Xu-Ouyang.

摘要：<paragraph>我們揭示了低位元量化有利於訓練不足的大型語言模型（LLM），透過觀察具有較大規模或較少訓練代幣的模型在應用低位元量化時，會經歷較少的量化誘發的退化（QiD），而具有大量訓練代幣的較小模型則會遭受顯著的 QiD。為了更深入地了解此趨勢，我們在受控環境中研究了 1500 多個各種規模和不同訓練層級（訓練不足或完全訓練）的量化 LLM 檢查點，推導出比例定律，以了解 QiD 與訓練代幣數量、模型規模和位元寬度等因素之間的關係。
有了推導出的比例定律，我們提出了一個新觀點，即我們可以使用 QiD 來衡量 LLM 的訓練層級，並確定完全訓練各種規模的 LLM 所需的訓練代幣數量。此外，我們使用比例定律來預測使用 100 兆個代幣訓練的不同規模 LLM 的量化效能。我們的預測顯示，預計將使用超過 100 兆個代幣訓練的未來模型的低位元量化效能可能並非理想。這對未來的低位元量化構成潛在挑戰，並強調在評估低位元量化研究時需要了解模型的訓練層級。為了促進未來對此問題的研究，我們在 https://huggingface.co/Xu-Ouyang 上發布了這項工作中使用的所有 1500 多個量化檢查點。</paragraph>

##### **Attamba: Attending To Multi-Token States**
2411.17685v1 by Yash Akhauri, Safeen Huda, Mohamed S. Abdelfattah

When predicting the next token in a sequence, vanilla transformers compute
attention over all previous tokens, resulting in quadratic scaling of compute
with sequence length. State-space models compress the entire sequence of tokens
into a fixed-dimensional representation to improve efficiency, while other
architectures achieve sub-quadratic complexity via low-rank projections or
sparse attention patterns over the sequence. In this paper, we introduce
Attamba, a novel architecture that uses state-space models to compress chunks
of tokens and applies attention on these compressed key-value representations.
We find that replacing key and value projections in a transformer with SSMs can
improve model quality and enable flexible token chunking, resulting in 24%
improved perplexity with transformer of similar KV-Cache and attention
footprint, and ~4 times smaller KV-Cache and Attention FLOPs for 5% perplexity
trade-off. Attamba can perform attention on chunked-sequences of variable
length, enabling a smooth transition between quadratic and linear scaling,
offering adaptable efficiency gains.

摘要：在预测序列中的下一个标记时，香草转换器会计算对所有先前标记的注意力，从而导致计算与序列长度的二次缩放。状态空间模型将整个标记序列压缩成一个固定维度的表示，以提高效率，而其他架构通过低秩投影或序列上的稀疏注意力模式实现了次二次复杂度。在本文中，我们介绍了 Attamba，这是一种使用状态空间模型压缩标记块并对这些压缩的键值表示应用注意力的新颖架构。我们发现用 SSM 替换变压器中的键和值投影可以提高模型质量并实现灵活的标记块划分，从而使具有类似 KV 缓存和注意力占用空间的变压器的困惑度提高了 24%，而 KV 缓存和注意力 FLOP 则小约 4 倍，以实现 5% 的困惑度权衡。Attamba 可以在可变长度的块序列上执行注意力，从而实现二次缩放和线性缩放之间的平滑过渡，提供可适应的效率提升。

##### **Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning**
2411.17679v1 by Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang

Tokenization techniques such as Byte-Pair Encoding (BPE) and Byte-Level BPE
(BBPE) have significantly improved the computational efficiency and vocabulary
representation stability of large language models (LLMs) by segmenting text
into tokens. However, this segmentation often obscures the internal character
structures and sequences within tokens, preventing models from fully learning
these intricate details during training. Consequently, LLMs struggle to
comprehend the character compositions and positional relationships within
tokens, especially when fine-tuned on downstream tasks with limited data. In
this paper, we introduce Token Internal Position Awareness (TIPA), a novel
approach that enhances LLMs' understanding of internal token structures by
training them on reverse character prediction tasks using the tokenizer's own
vocabulary. This method enables models to effectively learn and generalize
character positions and internal structures. Experimental results demonstrate
that LLMs trained with TIPA outperform baseline models in predicting character
positions at the token level. Furthermore, when applied to the downstream task
of Chinese Spelling Correction (CSC), TIPA not only accelerates model
convergence but also significantly improves task performance.

摘要：字节对编码 (BPE) 和字节级 BPE (BBPE) 等标记化技术通过将文本分割成标记，显著提高了大语言模型 (LLM) 的计算效率和词汇表表示稳定性。然而，这种分割常常会模糊标记内的内部字符结构和序列，从而妨碍模型在训练期间充分学习这些错综复杂的细节。因此，LLM 难以理解标记内的字符构成和位置关系，尤其是在针对数据有限的下游任务进行微调时。在本文中，我们引入了标记内部位置感知 (TIPA)，这是一种通过使用标记器自己的词汇表对逆向字符预测任务进行训练来增强 LLM 对内部标记结构理解的新方法。这种方法使模型能够有效地学习和概括字符位置和内部结构。实验结果表明，使用 TIPA 训练的 LLM 在标记级别预测字符位置时优于基线模型。此外，当应用于中文拼写纠正 (CSC) 的下游任务时，TIPA 不仅可以加速模型收敛，还可以显著提高任务性能。

##### **Push the Limit of Multi-modal Emotion Recognition by Prompting LLMs with Receptive-Field-Aware Attention Weighting**
2411.17674v1 by Liyun Zhang, Dian Ding, Yu Lu, Yi-Chao Chen, Guangtao Xue

Understanding the emotions in a dialogue usually requires external knowledge
to accurately understand the contents. As the LLMs become more and more
powerful, we do not want to settle on the limited ability of the pre-trained
language model. However, the LLMs either can only process text modality or are
too expensive to process the multimedia information. We aim to utilize both the
power of LLMs and the supplementary features from the multimedia modalities. In
this paper, we present a framework, Lantern, that can improve the performance
of a certain vanilla model by prompting large language models with
receptive-field-aware attention weighting. This framework trained a multi-task
vanilla model to produce probabilities of emotion classes and dimension scores.
These predictions are fed into the LLMs as references to adjust the predicted
probabilities of each emotion class with its external knowledge and contextual
understanding. We slice the dialogue into different receptive fields, and each
sample is included in exactly t receptive fields. Finally, the predictions of
LLMs are merged with a receptive-field-aware attention-driven weighting module.
In the experiments, vanilla models CORECT and SDT are deployed in Lantern with
GPT-4 or Llama-3.1-405B. The experiments in IEMOCAP with 4-way and 6-way
settings demonstrated that the Lantern can significantly improve the
performance of current vanilla models by up to 1.23% and 1.80%.

摘要：理解對話中的情緒通常需要外部知識才能準確理解內容。隨著 LLM 變得越來越強大，我們不希望滿足於預先訓練的語言模型的有限能力。然而，LLM 要嘛只能處理文字模式，要嘛處理多媒體資訊的成本太高。我們的目標是利用 LLM 的強大功能和多媒體模式的補充功能。在本文中，我們提出了一個框架 Lantern，它可以通過提示具有感受野感知注意權重的 LLM 來提升特定香草模型的性能。此框架訓練了一個多任務香草模型來產生情緒類別的機率和維度分數。這些預測被輸入到 LLM 中作為參考，以調整每個情緒類別的預測機率及其外部知識和上下文理解。我們將對話切成不同的感受野，每個樣本都包含在恰好 t 個感受野中。最後，將 LLM 的預測與感受野感知注意力驅動加權模組合併。在實驗中，香草模型 CORECT 和 SDT 與 GPT-4 或 Llama-3.1-405B 一起部署在 Lantern 中。在 IEMOCAP 中進行的 4 向和 6 向設定的實驗表明，Lantern 可以將當前香草模型的性能顯著提升至 1.23% 和 1.80%。

##### **Linguistic Laws Meet Protein Sequences: A Comparative Analysis of Subword Tokenization Methods**
2411.17669v1 by Burak Suyunu, Enes Taylan, Arzucan Özgür

Tokenization is a crucial step in processing protein sequences for machine
learning models, as proteins are complex sequences of amino acids that require
meaningful segmentation to capture their functional and structural properties.
However, existing subword tokenization methods, developed primarily for human
language, may be inadequate for protein sequences, which have unique patterns
and constraints. This study evaluates three prominent tokenization approaches,
Byte-Pair Encoding (BPE), WordPiece, and SentencePiece, across varying
vocabulary sizes (400-6400), analyzing their effectiveness in protein sequence
representation, domain boundary preservation, and adherence to established
linguistic laws. Our comprehensive analysis reveals distinct behavioral
patterns among these tokenizers, with vocabulary size significantly influencing
their performance. BPE demonstrates better contextual specialization and
marginally better domain boundary preservation at smaller vocabularies, while
SentencePiece achieves better encoding efficiency, leading to lower fertility
scores. WordPiece offers a balanced compromise between these characteristics.
However, all tokenizers show limitations in maintaining protein domain
integrity, particularly as vocabulary size increases. Analysis of linguistic
law adherence shows partial compliance with Zipf's and Brevity laws but notable
deviations from Menzerath's law, suggesting that protein sequences may follow
distinct organizational principles from natural languages. These findings
highlight the limitations of applying traditional NLP tokenization methods to
protein sequences and emphasize the need for developing specialized
tokenization strategies that better account for the unique characteristics of
proteins.

摘要：<paragraph>在處理蛋白質序列以供機器學習模型使用時，分詞是一個至關重要的步驟，因為蛋白質是複雜的胺基酸序列，需要有意義的分段才能捕捉其功能和結構特性。
然而，現有的子詞分詞方法主要為人類語言而開發，可能不適合蛋白質序列，因為蛋白質序列有獨特的模式和約束。本研究評估了三種主要的標記化方法，即位元組對編碼 (BPE)、WordPiece 和 SentencePiece，在不同的詞彙大小 (400-6400) 中，分析它們在蛋白質序列表示、網域邊界保留和對已建立語言定律的遵守方面的有效性。我們全面的分析揭示了這些標記器之間不同的行為模式，詞彙大小顯著影響其性能。BPE 在較小的詞彙中表現出更好的上下文專業化和略微更好的網域邊界保留，而 SentencePiece 則實現了更好的編碼效率，導致較低的生育率分數。WordPiece 在這些特徵之間提供了平衡的折衷。
然而，所有標記器在維護蛋白質網域完整性方面都表現出局限性，特別是隨著詞彙大小的增加。對語言定律遵守情況的分析顯示部分符合齊夫定律和簡潔定律，但明顯偏離門澤拉特定律，這表明蛋白質序列可能遵循與自然語言不同的組織原則。這些發現強調了將傳統 NLP 標記化方法應用於蛋白質序列的局限性，並強調了開發專門的標記化策略的必要性，這些策略可以更好地說明蛋白質的獨特特徵。</paragraph>

##### **How do Multimodal Foundation Models Encode Text and Speech? An Analysis of Cross-Lingual and Cross-Modal Representations**
2411.17666v1 by Hyunji Lee, Danni Liu, Supriti Sinhamahapatra, Jan Niehues

Multimodal foundation models aim to create a unified representation space
that abstracts away from surface features like language syntax or modality
differences. To investigate this, we study the internal representations of
three recent models, analyzing the model activations from semantically
equivalent sentences across languages in the text and speech modalities. Our
findings reveal that: 1) Cross-modal representations converge over model
layers, except in the initial layers specialized at text and speech processing.
2) Length adaptation is crucial for reducing the cross-modal gap between text
and speech, although current approaches' effectiveness is primarily limited to
high-resource languages. 3) Speech exhibits larger cross-lingual differences
than text. 4) For models not explicitly trained for modality-agnostic
representations, the modality gap is more prominent than the language gap.

摘要：多模态基础模型的目标是创建一个统一的表示空间，该空间抽象化了语言语法或模态差异等表面特征。为了研究这一点，我们研究了三个最近模型的内部表示，分析了跨语言在文本和语音模式中语义等价句子的模型激活。我们的发现表明：1) 跨模态表示在模型层中收敛，除了专门用于文本和语音处理的初始层。2) 长度适应对于缩小文本和语音之间的跨模态差距至关重要，尽管当前方法的有效性主要限于资源丰富的语言。3) 语音表现出比文本更大的跨语言差异。4) 对于未针对模态不可知表示显式训练的模型，模态差距比语言差距更突出。

##### **BERT or FastText? A Comparative Analysis of Contextual as well as Non-Contextual Embeddings**
2411.17661v1 by Abhay Shanbhag, Suramya Jadhav, Amogh Thakurdesai, Ridhima Sinare, Raviraj Joshi

Natural Language Processing (NLP) for low-resource languages presents
significant challenges, particularly due to the scarcity of high-quality
annotated data and linguistic resources. The choice of embeddings plays a
critical role in enhancing the performance of NLP tasks, such as news
classification, sentiment analysis, and hate speech detection, especially for
low-resource languages like Marathi. In this study, we investigate the impact
of various embedding techniques- Contextual BERT-based, Non-Contextual
BERT-based, and FastText-based on NLP classification tasks specific to the
Marathi language. Our research includes a thorough evaluation of both
compressed and uncompressed embeddings, providing a comprehensive overview of
how these embeddings perform across different scenarios. Specifically, we
compare two BERT model embeddings, Muril and MahaBERT, as well as two FastText
model embeddings, IndicFT and MahaFT. Our evaluation includes applying
embeddings to a Multiple Logistic Regression (MLR) classifier for task
performance assessment, as well as TSNE visualizations to observe the spatial
distribution of these embeddings. The results demonstrate that contextual
embeddings outperform non-contextual embeddings. Furthermore, BERT-based
non-contextual embeddings extracted from the first BERT embedding layer yield
better results than FastText-based embeddings, suggesting a potential
alternative to FastText embeddings.

摘要：自然語言處理 (NLP) 對於低資源語言來說是一個重大的挑戰，特別是因為缺乏高品質的註解資料和語言資源。嵌入式的選擇在提升 NLP 任務的效能上扮演著關鍵的角色，例如新聞分類、情緒分析和仇恨言論偵測，特別是對於像馬拉提語這類的低資源語言。在本研究中，我們探討各種嵌入式技術對馬拉提語特定 NLP 分類任務的影響，包括基於脈絡的 BERT、非基於脈絡的 BERT 和基於 FastText。我們的研究包含對壓縮和未壓縮嵌入式的全面評估，提供這些嵌入式在不同場景下的效能表現的全面概觀。具體來說，我們比較了兩個 BERT 模型嵌入式，Muril 和 MahaBERT，以及兩個 FastText 模型嵌入式，IndicFT 和 MahaFT。我們的評估包括將嵌入式應用於多重邏輯迴歸 (MLR) 分類器，以進行任務效能評估，以及使用 t-SNE 視覺化來觀察這些嵌入式的空間分佈。結果表明，基於脈絡的嵌入式優於非基於脈絡的嵌入式。此外，從第一個 BERT 嵌入式層中提取的非基於脈絡的 BERT 嵌入式比基於 FastText 的嵌入式產生更好的結果，這表明了 FastText 嵌入式的潛在替代方案。

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

摘要：機器學習和人工智慧在電子健康紀錄 (EHR) 上的應用具有
臨床見解的巨大潛力。然而，這種方法由於資料異質性、稀疏性、時間錯位和標記結果有限，因此面臨重大挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特郡和南格洛斯特郡的大約一百萬名去識別化個人的連結式 EHR 資料集，以描述泌尿道感染 (UTI) 並開發專注於資料品質、公平性和透明度的預測模型。全面的資料前處理和整理管道將原始 EHR 資料轉換為適合 AI 建模的結構化格式。鑑於實際 UTI 結果的可用性有限和偏見，我們引入了一個由臨床專業知識提供資訊的 UTI 風險評估架構，以估計個人患者時間線上的 UTI 風險。使用此架構，我們建立了成對的 XGBoost 模型，以區分 UTI 風險類別，並使用可解釋的 AI 技術來識別關鍵預測因子，同時確保可解釋性。我們的研究結果揭示了不同風險群組的臨床和人口統計因素的差異，提供了對 UTI 風險分層和進展的見解。本研究展示了 AI 驅動的見解在 UTI 臨床決策中的附加價值，同時優先考慮可解釋性、透明度和公平性，強調了健全資料實務在促進健康結果中的重要性。

##### **On Limitations of LLM as Annotator for Low Resource Languages**
2411.17637v1 by Suramya Jadhav, Abhay Shanbhag, Amogh Thakurdesai, Ridhima Sinare, Raviraj Joshi

Low-resource languages face significant challenges due to the lack of
sufficient linguistic data, resources, and tools for tasks such as supervised
learning, annotation, and classification. This shortage hinders the development
of accurate models and datasets, making it difficult to perform critical NLP
tasks like sentiment analysis or hate speech detection. To bridge this gap,
Large Language Models (LLMs) present an opportunity for potential annotators,
capable of generating datasets and resources for these underrepresented
languages. In this paper, we focus on Marathi, a low-resource language, and
evaluate the performance of both closed-source and open-source LLMs as
annotators. We assess models such as GPT-4o and Gemini 1.0 Pro, Gemma 2 (2B and
9B), and Llama 3.1 (8B) on classification tasks including sentiment analysis,
news classification, and hate speech detection. Our findings reveal that while
LLMs excel in annotation tasks for high-resource languages like English, they
still fall short when applied to Marathi. Even advanced closed models like
Gemini and GPT underperform in comparison to BERT-based baselines, highlighting
the limitations of LLMs as annotators for low-resource languages.

摘要：低資源語言因缺乏足夠的語言資料、資源和工具，而面臨重大挑戰，這些任務包括監督式學習、註解和分類。這種短缺阻礙了準確模型和資料集的開發，使得難以執行關鍵的 NLP 任務，例如情緒分析或仇恨言論偵測。為了彌補這個差距，大型語言模型 (LLM) 為潛在註解者提供了機會，能夠為這些代表性不足的語言產生資料集和資源。在本文中，我們專注於低資源語言馬拉地語，並評估閉源和開源 LLM 作為註解者的效能。我們評估 GPT-4o 和 Gemini 1.0 Pro、Gemma 2（2B 和 9B）和 Llama 3.1（8B）等模型在分類任務上的表現，包括情緒分析、新聞分類和仇恨言論偵測。我們的研究結果顯示，雖然 LLM 在英語等高資源語言的註解任務中表現出色，但應用於馬拉地語時仍有不足。即使是 Gemini 和 GPT 等進階閉源模型，與基於 BERT 的基準相比，表現也較差，突顯了 LLM 作為低資源語言註解者的限制。

##### **MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation**
2411.17636v1 by Harsh Singh, Rocktim Jyoti Das, Mingfei Han, Preslav Nakov, Ivan Laptev

Large Language Models (LLMs) have demonstrated remarkable planning abilities
across various domains, including robotics manipulation and navigation. While
recent efforts in robotics have leveraged LLMs both for high-level and
low-level planning, these approaches often face significant challenges, such as
hallucinations in long-horizon tasks and limited adaptability due to the
generation of plans in a single pass without real-time feedback. To address
these limitations, we propose a novel multi-agent LLM framework, Multi-Agent
Large Language Model for Manipulation (MALMM) that distributes high-level
planning and low-level control code generation across specialized LLM agents,
supervised by an additional agent that dynamically manages transitions. By
incorporating observations from the environment after each step, our framework
effectively handles intermediate failures and enables adaptive re-planning.
Unlike existing methods, our approach does not rely on pre-trained skill
policies or in-context learning examples and generalizes to a variety of new
tasks. We evaluate our approach on nine RLBench tasks, including long-horizon
tasks, and demonstrate its ability to solve robotics manipulation in a
zero-shot setting, thereby overcoming key limitations of existing LLM-based
manipulation methods.

摘要：大型語言模型 (LLM) 已展現出在各種領域中卓越的規劃能力，包括機器人操作和導航。儘管機器人領域的最新努力已針對高階和低階規劃利用 LLM，但這些方法通常會面臨重大挑戰，例如長時間任務中的幻覺和由於在單次傳遞中產生計畫而導致的可適應性受限，且沒有即時回饋。為了解決這些限制，我們提出了一種新穎的多代理人 LLM 架構，即用於操作的多代理人大型語言模型 (MALMM)，它將高階規劃和低階控制碼產生分佈在專業 LLM 代理人中，並由動態管理轉換的額外代理人監督。透過在每個步驟後納入來自環境的觀察，我們的架構有效地處理中間失敗並啟用適應性重新規劃。與現有方法不同，我們的做法不依賴於預先訓練的技能策略或情境學習範例，且能概括到各種新任務。我們在九項 RLBench 任務（包括長時間任務）上評估我們的做法，並展示其在零次學習設定中解決機器人操作的能力，從而克服了現有基於 LLM 的操作方法的主要限制。

##### **Learning Chemical Reaction Representation with Reactant-Product Alignment**
2411.17629v1 by Kaipeng Zeng, Xianbin Liu, Yu Zhang, Xiaokang Yang, Yaohui Jin, Yanyan Xu

Organic synthesis stands as a cornerstone of chemical industry. The
development of robust machine learning models to support tasks associated with
organic reactions is of significant interest. However, current methods rely on
hand-crafted features or direct adaptations of model architectures from other
domains, which lacks feasibility as data scales increase or overlook the rich
chemical information inherent in reactions. To address these issues, this paper
introduces {\modelname}, a novel chemical reaction representation learning
model tailored for a variety of organic-reaction-related tasks. By integrating
atomic correspondence between reactants and products, our model discerns the
molecular transformations that occur during the reaction, thereby enhancing the
comprehension of the reaction mechanism. We have designed an adapter structure
to incorporate reaction conditions into the chemical reaction representation,
allowing the model to handle diverse reaction conditions and adapt to various
datasets and downstream tasks, e.g., reaction performance prediction.
Additionally, we introduce a reaction-center aware attention mechanism that
enables the model to concentrate on key functional groups, thereby generating
potent representations for chemical reactions. Our model has been evaluated on
a range of downstream tasks, including reaction condition prediction, reaction
yield prediction, and reaction selectivity prediction. Experimental results
indicate that our model markedly outperforms existing chemical reaction
representation learning architectures across all tasks. Notably, our model
significantly outperforms all the baselines with up to 25\% (top-1) and 16\%
(top-10) increased accuracy over the strongest baseline on USPTO\_CONDITION
dataset for reaction condition prediction. We plan to open-source the code
contingent upon the acceptance of the paper.

摘要：<paragraph>有機合成是化學工業的基石。開發強大的機器學習模型以支援與有機反應相關的任務具有重大的意義。然而，目前的技術依賴於手工製作的特徵或直接採用其他領域的模型架構，這在資料擴增或忽略反應中固有的豐富化學資訊時缺乏可行性。為了解決這些問題，本文介紹了 {\modelname}，一種新穎的化學反應表示學習模型，專門針對各種有機反應相關任務。透過整合反應物和產物之間的原子對應關係，我們的模型辨識出反應過程中發生的分子轉化，從而增強對反應機制的理解。我們設計了一個適配器結構，將反應條件納入化學反應表示中，讓模型能夠處理各種反應條件並適應不同的資料集和下游任務，例如反應效能預測。此外，我們引入了一個反應中心感知注意力機制，使模型能夠專注於關鍵官能基，從而為化學反應產生強有力的表示。我們的模型已在各種下游任務上進行評估，包括反應條件預測、反應產率預測和反應選擇性預測。實驗結果表明，我們的模型在所有任務上都明顯優於現有的化學反應表示學習架構。值得注意的是，我們的模型在 USPTO\_CONDITION 資料集上，反應條件預測的準確率比最強的基線高出 25%（前 1）和 16%（前 10），顯著優於所有基線。我們計畫在論文被接受後開源程式碼。</paragraph>

##### **Mixed-State Quantum Denoising Diffusion Probabilistic Model**
2411.17608v1 by Gino Kwun, Bingzhi Zhang, Quntao Zhuang

Generative quantum machine learning has gained significant attention for its
ability to produce quantum states with desired distributions. Among various
quantum generative models, quantum denoising diffusion probabilistic models
(QuDDPMs) [Phys. Rev. Lett. 132, 100602 (2024)] provide a promising approach
with stepwise learning that resolves the training issues. However, the
requirement of high-fidelity scrambling unitaries in QuDDPM poses a challenge
in near-term implementation. We propose the \textit{mixed-state quantum
denoising diffusion probabilistic model} (MSQuDDPM) to eliminate the need for
scrambling unitaries. Our approach focuses on adapting the quantum noise
channels to the model architecture, which integrates depolarizing noise
channels in the forward diffusion process and parameterized quantum circuits
with projective measurements in the backward denoising steps. We also introduce
several techniques to improve MSQuDDPM, including a cosine-exponent schedule of
noise interpolation, the use of single-qubit random ancilla, and
superfidelity-based cost functions to enhance the convergence. We evaluate
MSQuDDPM on quantum ensemble generation tasks, demonstrating its successful
performance.

摘要：生成量子機器學習因其產生具有所需分佈的量子態的能力而備受關注。在各種量子生成模型中，量子去噪擴散概率模型 (QuDDPM) [Phys. Rev. Lett. 132, 100602 (2024)] 提供了一種有前途的方法，它採用逐步學習來解決訓練問題。然而，QuDDPM 中對高保真擾動酉算子的要求在近期實作中構成了一項挑戰。我們提出「混合態量子去噪擴散概率模型」(MSQuDDPM) 來消除對擾動酉算子的需求。我們的做法重點在於將量子雜訊通道調整到模型架構，它在正向擴散過程中整合了去極化雜訊通道，並在反向去噪步驟中使用帶有投影測量的參數化量子電路。我們還引入了幾種技術來改進 MSQuDDPM，包括雜訊插值的餘弦指數時程、使用單量子位隨機輔助量子位，以及基於超保真的成本函數來增強收斂。我們在量子系綜生成任務上評估 MSQuDDPM，證明了其成功的效能。

##### **Scaling Speech-Text Pre-training with Synthetic Interleaved Data**
2411.17607v1 by Aohan Zeng, Zhengxiao Du, Mingdao Liu, Lei Zhang, Shengmin Jiang, Yuxiao Dong, Jie Tang

Speech language models (SpeechLMs) accept speech input and produce speech
output, allowing for more natural human-computer interaction compared to
text-based large language models (LLMs). Traditional approaches for developing
SpeechLMs are constrained by the limited availability of unsupervised speech
data and parallel speech-text data, which are significantly less abundant than
text pre-training data, thereby limiting their scalability as LLMs. We propose
a novel approach to scaling speech-text pre-training by leveraging large-scale
synthetic interleaved data derived from text corpora, eliminating the need for
parallel speech-text datasets. Our method efficiently constructs speech-text
interleaved data by sampling text spans from existing text corpora and
synthesizing corresponding speech spans using a text-to-token model, bypassing
the need to generate actual speech. We also employ a supervised speech
tokenizer derived from an automatic speech recognition (ASR) model by
incorporating a vector-quantized bottleneck into the encoder. This supervised
training approach results in discrete speech tokens with strong semantic
preservation even at lower sampling rates (e.g. 12.5Hz), while still
maintaining speech reconstruction quality. Starting from a pre-trained language
model and scaling our pre-training to 1 trillion tokens (with 600B synthetic
interleaved speech-text data), we achieve state-of-the-art performance in
speech language modeling and spoken question answering, improving performance
on spoken questions tasks from the previous SOTA of 13% (Moshi) to 31%. We
further demonstrate that by fine-tuning the pre-trained model with speech
dialogue data, we can develop an end-to-end spoken chatbot that achieves
competitive performance comparable to existing baselines in both conversational
abilities and speech quality, even operating exclusively in the speech domain.

摘要：語音語言模型 (SpeechLM) 接受語音輸入並產生語音輸出，與基於文字的大型語言模型 (LLM) 相比，允許更自然的電腦互動。開發 SpeechLM 的傳統方法受到無監督語音資料和平行語音文字資料有限的可用性所限制，這些資料遠少於文字預訓練資料，從而限制了它們作為 LLM 的可擴充性。我們提出了一種新的方法來擴充語音文字預訓練，方法是利用從文字語料庫中衍生的、大規模的合成交錯資料，從而消除了對平行語音文字資料集的需求。我們的模型透過從現有的文字語料庫中抽樣文字跨度，並使用文字轉換標記模型合成對應的語音跨度，有效地建構語音文字交錯資料，而無需產生實際語音。我們還透過在編碼器中加入向量量化瓶頸，採用了源自自動語音辨識 (ASR) 模型的監督式語音標記器。這種監督式訓練方法產生了離散的語音標記，即使在較低的取樣率（例如 12.5Hz）下，也能強有力地保留語意，同時還能維持語音重建品質。從預訓練的語言模型開始，並將我們的預訓練擴充到 1 兆個標記（使用 600B 合成交錯語音文字資料），我們在語音語言建模和口說問題回答中取得了最先進的效能，將口說問題任務的效能從先前的 SOTA 13%（Moshi）提升至 31%。我們進一步證明，透過使用語音對話資料微調預訓練模型，我們可以開發一個端到端的口說聊天機器人，在對話能力和語音品質方面都能達到與現有基準相當的競爭力，甚至完全在語音領域中運作。

##### **Making History Readable**
2411.17600v1 by Bipasha Banerjee, Jennifer Goyne, William A. Ingram

The Virginia Tech University Libraries (VTUL) Digital Library Platform (DLP)
hosts digital collections that offer our users access to a wide variety of
documents of historical and cultural importance. These collections are not only
of academic importance but also provide our users with a glance at local
historical events. Our DLP contains collections comprising digital objects
featuring complex layouts, faded imagery, and hard-to-read handwritten text,
which makes providing online access to these materials challenging. To address
these issues, we integrate AI into our DLP workflow and convert the text in the
digital objects into a machine-readable format. To enhance the user experience
with our historical collections, we use custom AI agents for handwriting
recognition, text extraction, and large language models (LLMs) for
summarization. This poster highlights three collections focusing on handwritten
letters, newspapers, and digitized topographic maps. We discuss the challenges
with each collection and detail our approaches to address them. Our proposed
methods aim to enhance the user experience by making the contents in these
collections easier to search and navigate.

摘要：維吉尼亞理工大學圖書館 (VTUL) 數位圖書館平台 (DLP)
承載數位典藏，提供使用者存取各式各樣具有歷史和文化重要性的文件。這些典藏不僅具有學術重要性，也提供使用者一窺當地的歷史事件。我們的 DLP 包含由數位物件組成的典藏，特色為複雜的版面、褪色的圖像和難以辨識的手寫文字，這使得線上存取這些資料具有挑戰性。為了解決這些問題，我們將 AI 整合到我們的 DLP 工作流程中，並將數位物件中的文字轉換成機器可讀的格式。為了提升使用者使用我們歷史典藏的體驗，我們使用客製化 AI 代理進行手寫辨識、文字萃取，以及大型語言模型 (LLM) 進行摘要。這份海報重點介紹了三個以手寫信件、報紙和數位化地形圖為主的典藏。我們討論每個典藏的挑戰，並詳細說明我們解決這些挑戰的方法。我們提出的方法旨在透過讓這些典藏中的內容更容易搜尋和瀏覽，來提升使用者體驗。

##### **Agentic AI for Improving Precision in Identifying Contributions to Sustainable Development Goals**
2411.17598v1 by William A. Ingram, Bipasha Banerjee, Edward A. Fox

As research institutions increasingly commit to supporting the United
Nations' Sustainable Development Goals (SDGs), there is a pressing need to
accurately assess their research output against these goals. Current
approaches, primarily reliant on keyword-based Boolean search queries, conflate
incidental keyword matches with genuine contributions, reducing retrieval
precision and complicating benchmarking efforts. This study investigates the
application of autoregressive Large Language Models (LLMs) as evaluation agents
to identify relevant scholarly contributions to SDG targets in scholarly
publications. Using a dataset of academic abstracts retrieved via SDG-specific
keyword queries, we demonstrate that small, locally-hosted LLMs can
differentiate semantically relevant contributions to SDG targets from documents
retrieved due to incidental keyword matches, addressing the limitations of
traditional methods. By leveraging the contextual understanding of LLMs, this
approach provides a scalable framework for improving SDG-related research
metrics and informing institutional reporting.

摘要：隨著研究機構日益致力於支持聯合國永續發展目標 (SDG)，準確評估其研究成果是否符合這些目標的需求日益迫切。目前的做法主要依賴於基於關鍵字的布林搜尋查詢，將偶然的關鍵字比對與真實的貢獻混為一談，降低了檢索精準度，並使基準測試工作複雜化。本研究探討了將自迴歸大型語言模型 (LLM) 作為評估代理，用於識別學術刊物中與 SDG 目標相關的學術貢獻。我們使用透過 SDG 特定關鍵字查詢檢索的學術摘要資料集，證明小型的、本地託管的 LLM 可以區分與 SDG 目標語義相關的貢獻，以及由於偶然關鍵字比對而檢索到的文件，從而解決傳統方法的限制。透過利用 LLM 的脈絡理解，此方法提供了一個可擴充的架構，用於改善與 SDG 相關的研究指標，並提供機構報告資訊。

##### **What Differentiates Educational Literature? A Multimodal Fusion Approach of Transformers and Computational Linguistics**
2411.17593v1 by Jordan J. Bird

The integration of new literature into the English curriculum remains a
challenge since educators often lack scalable tools to rapidly evaluate
readability and adapt texts for diverse classroom needs. This study proposes to
address this gap through a multimodal approach that combines transformer-based
text classification with linguistic feature analysis to align texts with UK Key
Stages. Eight state-of-the-art Transformers were fine-tuned on segmented text
data, with BERT achieving the highest unimodal F1 score of 0.75. In parallel,
500 deep neural network topologies were searched for the classification of
linguistic characteristics, achieving an F1 score of 0.392. The fusion of these
modalities shows a significant improvement, with every multimodal approach
outperforming all unimodal models. In particular, the ELECTRA Transformer fused
with the neural network achieved an F1 score of 0.996. The proposed approach is
finally encapsulated in a stakeholder-facing web application, providing
non-technical stakeholder access to real-time insights on text complexity,
reading difficulty, curriculum alignment, and recommendations for learning age
range. The application empowers data-driven decision making and reduces manual
workload by integrating AI-based recommendations into lesson planning for
English literature.

摘要：將新文學融入英語課程仍然是一項挑戰，因為教育者通常缺乏可擴充的工具來快速評估可讀性並根據不同的教室需求調整文本。本研究提出透過多模態方法來解決這個差距，該方法結合基於Transformer的文本分類與語言特徵分析，以將文本與英國關鍵階段對齊。對分段文本資料微調了八個最先進的Transformer，其中 BERT 達到了最高的單模態 F1 分數 0.75。同時，搜尋了 500 個深度神經網路拓撲以進行語言特徵分類，達到了 0.392 的 F1 分數。這些模態的融合顯示出顯著的進步，每個多模態方法都優於所有單模態模型。特別是，與神經網路融合的 ELECTRA Transformer達到了 0.996 的 F1 分數。最後，將所提出的方法封裝在一個面向利害關係人的網路應用程式中，讓非技術利害關係人可以即時深入了解文本複雜性、閱讀難度、課程對齊，以及學習年齡範圍的建議。該應用程式賦予資料驅動決策制定能力，並透過將基於 AI 的建議整合到英語文學的課程規劃中來減少手動工作量。

##### **Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey**
2411.17558v1 by Jiayi Kuang, Jingyou Xie, Haohao Luo, Ronghao Li, Zhe Xu, Xianfeng Cheng, Yinghui Li, Xika Lin, Ying Shen

Visual Question Answering (VQA) is a challenge task that combines natural
language processing and computer vision techniques and gradually becomes a
benchmark test task in multimodal large language models (MLLMs). The goal of
our survey is to provide an overview of the development of VQA and a detailed
description of the latest models with high timeliness. This survey gives an
up-to-date synthesis of natural language understanding of images and text, as
well as the knowledge reasoning module based on image-question information on
the core VQA tasks. In addition, we elaborate on recent advances in extracting
and fusing modal information with vision-language pretraining models and
multimodal large language models in VQA. We also exhaustively review the
progress of knowledge reasoning in VQA by detailing the extraction of internal
knowledge and the introduction of external knowledge. Finally, we present the
datasets of VQA and different evaluation metrics and discuss possible
directions for future work.

摘要：視覺問答 (VQA) 是一項結合自然語言處理和電腦視覺技術的挑戰性任務，並逐漸成為多模態大型語言模型 (MLLM) 的基準測試任務。我們的調查目標是提供 VQA 發展的概觀，並詳細描述具有高度時效性的最新模型。這項調查提供了圖像和文字自然語言理解的最新綜合，以及基於核心 VQA 任務中圖像問題資訊的知識推理模組。此外，我們闡述了在 VQA 中使用視覺語言預訓練模型和多模態大型語言模型提取和融合模態資訊的最新進展。我們也詳盡地回顧了 VQA 中知識推理的進展，詳細說明內部知識的提取和外部知識的引入。最後，我們介紹了 VQA 的資料集和不同的評估指標，並討論未來工作的可能方向。

##### **A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**
2411.17557v1 by Mengqian Dinga, Jun Liua, Yang Luo, Jinshan Tang

Caenorhabditis elegans (C. elegans) is an excellent model organism because of
its short lifespan and high degree of homology with human genes, and it has
been widely used in a variety of human health and disease models. However, the
segmentation of C. elegans remains challenging due to the following reasons: 1)
the activity trajectory of C. elegans is uncontrollable, and multiple nematodes
often overlap, resulting in blurred boundaries of C. elegans. This makes it
impossible to clearly study the life trajectory of a certain nematode; and 2)
in the microscope images of overlapping C. elegans, the translucent tissues at
the edges obscure each other, leading to inaccurate boundary segmentation. To
solve these problems, a Bilayer Segmentation-Recombination Network (BR-Net) for
the segmentation of C. elegans instances is proposed. The network consists of
three parts: A Coarse Mask Segmentation Module (CMSM), a Bilayer Segmentation
Module (BSM), and a Semantic Consistency Recombination Module (SCRM). The CMSM
is used to extract the coarse mask, and we introduce a Unified Attention Module
(UAM) in CMSM to make CMSM better aware of nematode instances. The Bilayer
Segmentation Module (BSM) segments the aggregated C. elegans into overlapping
and non-overlapping regions. This is followed by integration by the SCRM, where
semantic consistency regularization is introduced to segment nematode instances
more accurately. Finally, the effectiveness of the method is verified on the C.
elegans dataset. The experimental results show that BR-Net exhibits good
competitiveness and outperforms other recently proposed instance segmentation
methods in processing C. elegans occlusion images.

摘要：秀麗隱桿線蟲 (C. elegans) 是一種極佳的模式生物，原因在於其壽命短且與人類基因有高度同源性，且已廣泛用於各種人類健康與疾病模式中。然而，C. elegans 的分割仍然具有挑戰性，原因如下：1) C. elegans 的活動軌跡無法控制，且多個線蟲經常重疊，導致 C. elegans 的邊界模糊。這使得無法清楚地研究某個線蟲的生命軌跡；2) 在重疊的 C. elegans 的顯微鏡影像中，邊緣的半透明組織彼此遮蔽，導致邊界分割不準確。為了解決這些問題，提出了一個用於分割 C. elegans 個體的雙層分割重組網路 (BR-Net)。該網路包含三個部分：粗略遮罩分割模組 (CMSM)、雙層分割模組 (BSM) 和語意一致性重組模組 (SCRM)。CMSM 用於提取粗略遮罩，我們在 CMSM 中引入了一個統一注意力模組 (UAM)，以使 CMSM 更能感知線蟲個體。雙層分割模組 (BSM) 將聚集的 C. elegans 分割成重疊和非重疊區域。接著由 SCRM 整合，其中引入了語意一致性正則化，以更準確地分割線蟲個體。最後，在 C. elegans 資料集上驗證了該方法的有效性。實驗結果顯示，BR-Net 展現出良好的競爭力，且在處理 C. elegans 遮蔽影像時優於其他最近提出的個體分割方法。

##### **Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search**
2411.17538v1 by Andor Diera, Lukas Galke, Ansgar Scherp

Low isotropy in an embedding space impairs performance on tasks involving
semantic inference. Our study investigates the impact of isotropy on semantic
code search performance and explores post-processing techniques to mitigate
this issue. We analyze various code language models, examine isotropy in their
embedding spaces, and its influence on search effectiveness. We propose a
modified ZCA whitening technique to control isotropy levels in embeddings. Our
results demonstrate that Soft-ZCA whitening improves the performance of
pre-trained code language models and can complement contrastive fine-tuning.
The code for our experiments is available at
https://github.com/drndr/code\_isotropy

摘要：嵌入空間中的低各向同性會損害涉及語義推理的任務效能。我們的研究探討各向同性對語義程式碼搜尋效能的影響，並探索後處理技術以減輕此問題。我們分析各種程式碼語言模型，檢查其嵌入空間中的各向同性，以及其對搜尋有效性的影響。我們提出修改後的 ZCA 白化技術來控制嵌入中的各向同性等級。我們的結果證明，Soft-ZCA 白化可提升預先訓練的程式碼語言模型效能，並可補充對比微調。我們實驗的程式碼可在 https://github.com/drndr/code\_isotropy 取得

##### **HSI-Drive v2.0: More Data for New Challenges in Scene Understanding for Autonomous Driving**
2411.17530v1 by Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe, M. Victoria Martínez, Unai Martínez-Corral

We present the updated version of the HSI-Drive dataset aimed at developing
automated driving systems (ADS) using hyperspectral imaging (HSI). The v2.0
version includes new annotated images from videos recorded during winter and
fall in real driving scenarios. Added to the spring and summer images included
in the previous v1.1 version, the new dataset contains 752 images covering the
four seasons. In this paper, we show the improvements achieved over previously
published results obtained on the v1.1 dataset, showcasing the enhanced
performance of models trained on the new v2.0 dataset. We also show the
progress made in comprehensive scene understanding by experimenting with more
capable image segmentation models. These models include new segmentation
categories aimed at the identification of essential road safety objects such as
the presence of vehicles and road signs, as well as highly vulnerable groups
like pedestrians and cyclists. In addition, we provide evidence of the
performance and robustness of the models when applied to segmenting HSI video
sequences captured in various environments and conditions. Finally, for a
correct assessment of the results described in this work, the constraints
imposed by the processing platforms that can sensibly be deployed in vehicles
for ADS must be taken into account. Thus, and although implementation details
are out of the scope of this paper, we focus our research on the development of
computationally efficient, lightweight ML models that can eventually operate at
high throughput rates. The dataset and some examples of segmented videos are
available in https://ipaccess.ehu.eus/HSI-Drive/.

摘要：<paragraph>我們提供 HSI-Drive 資料集的更新版本，目標是使用超光譜影像 (HSI) 開發自動駕駛系統 (ADS)。v2.0 版本包含在真實駕駛場景中於冬季和秋季期間錄製影片的新註解影像。新增至先前 v1.1 版本中包含的春季和夏季影像，新的資料集包含涵蓋四季的 752 張影像。在本文中，我們展示在 v1.1 資料集上獲得的先前已發布結果的改進，展示在新的 v2.0 資料集上訓練的模型的增強效能。我們也展示了透過使用更強大的影像分割模型在全面場景理解方面所做的進展。這些模型包含新的分割類別，旨在識別必要的道路安全物件，例如車輛和道路標誌的存在，以及高度脆弱的群體，例如行人和自行車騎士。此外，我們提供模型在用於分割在各種環境和條件下擷取的 HSI 影片序列時效能和穩健性的證據。最後，為了正確評估本文中描述的結果，必須考慮在車輛中部署於 ADS 的處理平台所施加的限制。因此，儘管實作細節不在本文的範圍內，我們將研究重點放在開發計算效率高、輕量化的 ML 模型，這些模型最終可以在高通量率下運作。資料集和一些分割影片範例可以在 https://ipaccess.ehu.eus/HSI-Drive/ 中取得。</paragraph>

##### **On Statistical Rates of Conditional Diffusion Transformers: Approximation, Estimation and Minimax Optimality**
2411.17522v1 by Jerry Yao-Chieh Hu, Weimin Wu, Yi-Chen Lee, Yu-Chao Huang, Minshuo Chen, Han Liu

We investigate the approximation and estimation rates of conditional
diffusion transformers (DiTs) with classifier-free guidance. We present a
comprehensive analysis for ``in-context'' conditional DiTs under four common
data assumptions. We show that both conditional DiTs and their latent variants
lead to the minimax optimality of unconditional DiTs under identified settings.
Specifically, we discretize the input domains into infinitesimal grids and then
perform a term-by-term Taylor expansion on the conditional diffusion score
function under H\"older smooth data assumption. This enables fine-grained use
of transformers' universal approximation through a more detailed piecewise
constant approximation and hence obtains tighter bounds. Additionally, we
extend our analysis to the latent setting under the linear latent subspace
assumption. We not only show that latent conditional DiTs achieve lower bounds
than conditional DiTs both in approximation and estimation, but also show the
minimax optimality of latent unconditional DiTs. Our findings establish
statistical limits for conditional and unconditional DiTs, and offer practical
guidance toward developing more efficient and accurate DiT models.

摘要：我們研究了使用無分類器指導的條件擴散Transformer (DiT) 的逼近和估計率。我們對「情境內」條件 DiT 在四個常見資料假設下進行了全面分析。我們表明，在已識別的設定下，條件 DiT 及其潛在變體都會導致無條件 DiT 的極小極大最優性。具體來說，我們將輸入域離散化為無限小的網格，然後在 Hölder 平滑資料假設下對條件擴散分數函數執行逐項泰勒展開。這能夠通過更詳細的分段常數逼近來精細地使用Transformer的通用逼近，從而獲得更嚴格的界限。此外，我們將我們的分析擴展到線性潛在子空間假設下的潛在設定。我們不僅表明潛在條件 DiT 在逼近和估計中都比條件 DiT 達到較低的界限，而且還表明潛在無條件 DiT 的極小極大最優性。我們的發現為條件和無條件 DiT 建立了統計限制，並為開發更有效率和準確的 DiT 模型提供了實用的指導。

##### **Inference Scaling $\scriptsize\mathtt{F}$Laws: The Limits of LLM Resampling with Imperfect Verifiers**
2411.17501v1 by Benedikt Stroebl, Sayash Kapoor, Arvind Narayanan

Recent research has generated hope that inference scaling could allow weaker
language models to match or exceed the accuracy of stronger models, such as by
repeatedly sampling solutions to a coding problem until it passes unit tests.
The central thesis of this paper is that there is no free lunch for inference
scaling: indefinite accuracy improvement through resampling can only be
realized if the "verifier" (in this case, a set of unit tests) is perfect. When
the verifier is imperfect, as it almost always is in domains such as reasoning
or coding (for example, unit tests have imperfect coverage), there is a nonzero
probability of false positives: incorrect solutions that pass the verifier.
Resampling cannot decrease this probability, so it imposes an upper bound to
the accuracy of resampling-based inference scaling even with an infinite
compute budget. We find that there is a very strong correlation between the
model's single-sample accuracy (i.e. accuracy without unit tests) and its false
positive rate on coding benchmarks HumanEval and MBPP, whose unit tests have
limited coverage. Therefore, no amount of inference scaling of weaker models
can enable them to match the single-sample accuracy of a sufficiently strong
model (Fig. 1a). When we consider that false positives have a negative utility
compared to abstaining from producing a solution, it bends the inference
scaling curve further downward. Empirically, we find that the optimal number of
samples can be less than 10 under realistic assumptions (Fig. 1b). Finally, we
show that beyond accuracy, false positives may have other undesirable
qualities, such as poor adherence to coding style conventions.

摘要：最近的研究激發了希望，即推論規模化可以讓較弱的語言模型匹配或超越較強模型的準確度，例如通過重複採樣編碼問題的解決方案，直到通過單元測試。本文的中心論點是推論規模化沒有免費的午餐：只有當「驗證器」（在這種情況下，是一組單元測試）是完美的，才能實現通過重新採樣的不斷提高準確度。當驗證器不完美時，就像在推理或編碼等領域中幾乎總是這樣（例如，單元測試的覆蓋率不完美），就有非零的假陽性機率：通過驗證器的不正確解決方案。重新採樣無法降低此機率，因此即使在無限的運算預算下，它也會對基於重新採樣的推論規模化的準確度施加上限。我們發現模型的單樣本準確度（即沒有單元測試的準確度）與其在編碼基準 HumanEval 和 MBPP 上的假陽性率有很強的相關性，其單元測試的覆蓋率有限。因此，對較弱模型進行任何程度的推論規模化都無法讓它們匹配足夠強模型的單樣本準確度（圖 1a）。當我們考慮到與不產生解決方案相比，假陽性具有負面效用時，它會進一步向下彎曲推論規模化曲線。根據經驗，我們發現樣本的最佳數量在現實的假設下可以小於 10（圖 1b）。最後，我們表明，除了準確度之外，假陽性可能還有其他不良品質，例如對編碼風格慣例的遵守程度差。

##### **What's in the Image? A Deep-Dive into the Vision of Vision Language Models**
2411.17491v1 by Omri Kaduri, Shai Bagon, Tali Dekel

Vision-Language Models (VLMs) have recently demonstrated remarkable
capabilities in comprehending complex visual content. However, the mechanisms
underlying how VLMs process visual information remain largely unexplored. In
this paper, we conduct a thorough empirical analysis, focusing on attention
modules across layers. We reveal several key insights about how these models
process visual data: (i) the internal representation of the query tokens (e.g.,
representations of "describe the image"), is utilized by VLMs to store global
image information; we demonstrate that these models generate surprisingly
descriptive responses solely from these tokens, without direct access to image
tokens. (ii) Cross-modal information flow is predominantly influenced by the
middle layers (approximately 25% of all layers), while early and late layers
contribute only marginally.(iii) Fine-grained visual attributes and object
details are directly extracted from image tokens in a spatially localized
manner, i.e., the generated tokens associated with a specific object or
attribute attend strongly to their corresponding regions in the image. We
propose novel quantitative evaluation to validate our observations, leveraging
real-world complex visual scenes. Finally, we demonstrate the potential of our
findings in facilitating efficient visual processing in state-of-the-art VLMs.

摘要：視覺語言模型 (VLM) 最近在理解複雜視覺內容方面展現了非凡的能力。然而，VLM 如何處理視覺資訊的機制在很大程度上仍未被探索。在本文中，我們進行了徹底的實證分析，重點關注跨層級的注意力模組。我們揭示了這些模型如何處理視覺資料的幾個關鍵見解：(i) 查詢代碼的內部表示 (例如，"描述影像" 的表示) 被 VLM 用來儲存全域影像資訊；我們證明了這些模型僅從這些代碼產生令人驚訝的描述性回應，而無需直接存取影像代碼。(ii) 跨模態資訊流主要受中間層影響 (約佔所有層級的 25%)，而早期和晚期層級只貢獻了一小部分。(iii) 細微的視覺屬性和物件細節以空間局部化的方式直接從影像代碼中提取，即與特定物件或屬性相關的生成代碼強烈關注影像中對應的區域。我們提出新穎的量化評估來驗證我們的觀察，利用真實世界的複雜視覺場景。最後，我們展示了我們的發現促進了最先進的 VLM 中高效視覺處理的潛力。

##### **Puzzle Similarity: A Perceptually-guided No-Reference Metric for Artifact Detection in 3D Scene Reconstructions**
2411.17489v1 by Nicolai Hermann, Jorge Condor, Piotr Didyk

Modern reconstruction techniques can effectively model complex 3D scenes from
sparse 2D views. However, automatically assessing the quality of novel views
and identifying artifacts is challenging due to the lack of ground truth images
and the limitations of no-reference image metrics in predicting detailed
artifact maps. The absence of such quality metrics hinders accurate predictions
of the quality of generated views and limits the adoption of post-processing
techniques, such as inpainting, to enhance reconstruction quality. In this
work, we propose a new no-reference metric, Puzzle Similarity, which is
designed to localize artifacts in novel views. Our approach utilizes image
patch statistics from the input views to establish a scene-specific
distribution that is later used to identify poorly reconstructed regions in the
novel views. We test and evaluate our method in the context of 3D
reconstruction; to this end, we collected a novel dataset of human quality
assessment in unseen reconstructed views. Through this dataset, we demonstrate
that our method can not only successfully localize artifacts in novel views,
correlating with human assessment, but do so without direct references.
Surprisingly, our metric outperforms both no-reference metrics and popular
full-reference image metrics. We can leverage our new metric to enhance
applications like automatic image restoration, guided acquisition, or 3D
reconstruction from sparse inputs.

摘要：現代重建技術可以有效地從稀疏的 2D 視圖建構出複雜的 3D 場景。然而，由於缺乏地面實況影像和無參考影像評量指標在預測詳細的人工製品地圖上的限制，自動評估新視圖的品質和辨識人工製品是一項挑戰。缺乏此類品質評量指標會阻礙對生成視圖品質的準確預測，並限制採用後處理技術（例如內插）來提升重建品質。在這項研究中，我們提出了一個新的無參考評量指標，即拼圖相似性，其設計用於在新的視圖中定位人工製品。我們的做法利用輸入視圖中的影像區塊統計資料來建立場景特定的分佈，稍後用於辨識新視圖中重建不良的區域。我們在 3D 重建的背景下測試和評估我們的做法；為此，我們收集了一組人類品質評估的新資料集，用於未見的重建視圖。透過這組資料集，我們證明了我們的做法不僅能成功定位新視圖中的人工製品，並與人類評估結果相關，而且無需直接參考。令人驚訝的是，我們的評量指標優於無參考評量指標和流行的全參考影像評量指標。我們可以利用我們的新指標來增強應用程式，例如自動影像修復、引導式擷取或從稀疏輸入進行 3D 重建。

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

摘要：<paragraph>建構圖形使用者介面 (GUI) 助理極有望提升人類工作流程的生產力。雖然大多數代理都是基於語言，仰賴具有豐富文字元資訊封閉原始碼 API（例如 HTML 或無障礙樹），但它們在感知使用者介面視覺效果方面顯示出限制，這凸顯了對 GUI 視覺代理的需求。在這項工作中，我們在數位世界中開發了一個視覺語言動作模型，即 ShowUI，其具有以下創新功能：(i) UI 引導視覺代幣選擇，透過將螢幕截圖表述為 UI 連接圖，自適應地識別其冗餘關係，並作為自注意力區塊中代幣選擇的準則，以降低運算成本；(ii) 交錯視覺語言動作串流，靈活地統一 GUI 任務中的各種需求，在導覽中有效管理視覺動作歷程，或配對每個螢幕截圖的多輪查詢動作序列，以提升訓練效率；(iii) 小規模高品質 GUI 指令遵循資料集，透過仔細的資料整理和採用再抽樣策略，來解決顯著的資料類型不平衡。ShowUI 是一個使用 256K 資料的輕量級 2B 模型，具備上述組成部分，在零次方螢幕截圖接地中達到強勁的 75.1% 精確度。其 UI 引導代幣選擇進一步減少了訓練期間 33% 的冗餘視覺代幣，並將效能提升了 1.4 倍。跨網路 Mind2Web、行動 AITW 和線上 MiniWob 環境的導覽實驗進一步強調了我們的模型在推進 GUI 視覺代理方面的有效性和潛力。這些模型可在 https://github.com/showlab/ShowUI 取得。</paragraph>

##### **SoK: Decentralized AI (DeAI)**
2411.17461v1 by Zhipeng Wang, Rui Sun, Elizabeth Lui, Vatsal Shah, Xihan Xiong, Jiahao Sun, Davide Crapis, William Knottenbelt

The centralization of Artificial Intelligence (AI) poses significant
challenges, including single points of failure, inherent biases, data privacy
concerns, and scalability issues. These problems are especially prevalent in
closed-source large language models (LLMs), where user data is collected and
used without transparency. To mitigate these issues, blockchain-based
decentralized AI (DeAI) has emerged as a promising solution. DeAI combines the
strengths of both blockchain and AI technologies to enhance the transparency,
security, decentralization, and trustworthiness of AI systems. However, a
comprehensive understanding of state-of-the-art DeAI development, particularly
for active industry solutions, is still lacking. In this work, we present a
Systematization of Knowledge (SoK) for blockchain-based DeAI solutions. We
propose a taxonomy to classify existing DeAI protocols based on the model
lifecycle. Based on this taxonomy, we provide a structured way to clarify the
landscape of DeAI protocols and identify their similarities and differences. We
analyze the functionalities of blockchain in DeAI, investigating how blockchain
features contribute to enhancing the security, transparency, and
trustworthiness of AI processes, while also ensuring fair incentives for AI
data and model contributors. In addition, we identify key insights and research
gaps in developing DeAI protocols, highlighting several critical avenues for
future research.

摘要：人工智能 (AI) 的集中化帶來重大挑戰，包括單點故障、固有偏見、資料隱私疑慮和可擴充性問題。這些問題在封閉原始碼大型語言模型 (LLM) 中特別普遍，其中使用者資料會被收集並在不透明的情況下使用。為了減輕這些問題，基於區塊鏈的分散式 AI (DeAI) 已成為一個有前途的解決方案。DeAI 結合了區塊鏈和 AI 技術的優勢，以增強 AI 系統的透明度、安全性、分散性和可信度。然而，對於最先進的 DeAI 開發，特別是對於積極的產業解決方案，仍缺乏全面的了解。在這項工作中，我們提出了一個基於區塊鏈的 DeAI 解決方案的知識系統化 (SoK)。我們提出了一個分類法，以根據模型生命週期對現有的 DeAI 協定進行分類。基於這個分類法，我們提供了一個結構化的方式來釐清 DeAI 協定的現況，並找出它們的相似性和差異性。我們分析了區塊鏈在 DeAI 中的功能，探討區塊鏈功能如何有助於增強 AI 程序的安全性、透明度和可信度，同時也確保 AI 資料和模型貢獻者的公平誘因。此外，我們找出開發 DeAI 協定的關鍵見解和研究差距，重點指出未來研究的幾個關鍵途徑。

##### **WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model**
2411.17459v1 by Zongjian Li, Bin Lin, Yang Ye, Liuhan Chen, Xinhua Cheng, Shenghai Yuan, Li Yuan

Video Variational Autoencoder (VAE) encodes videos into a low-dimensional
latent space, becoming a key component of most Latent Video Diffusion Models
(LVDMs) to reduce model training costs. However, as the resolution and duration
of generated videos increase, the encoding cost of Video VAEs becomes a
limiting bottleneck in training LVDMs. Moreover, the block-wise inference
method adopted by most LVDMs can lead to discontinuities of latent space when
processing long-duration videos. The key to addressing the computational
bottleneck lies in decomposing videos into distinct components and efficiently
encoding the critical information. Wavelet transform can decompose videos into
multiple frequency-domain components and improve the efficiency significantly,
we thus propose Wavelet Flow VAE (WF-VAE), an autoencoder that leverages
multi-level wavelet transform to facilitate low-frequency energy flow into
latent representation. Furthermore, we introduce a method called Causal Cache,
which maintains the integrity of latent space during block-wise inference.
Compared to state-of-the-art video VAEs, WF-VAE demonstrates superior
performance in both PSNR and LPIPS metrics, achieving 2x higher throughput and
4x lower memory consumption while maintaining competitive reconstruction
quality. Our code and models are available at
https://github.com/PKU-YuanGroup/WF-VAE.

摘要：影片变异自动编码器 (VAE) 将影片编码成低维潜在空间，成为大多数潜在影片扩散模型 (LVDM) 的关键组件，以降低模型训练成本。然而，随着生成影片的分辨率和长度增加，影片 VAE 的编码成本成为训练 LVDM 的限制性瓶颈。此外，大多数 LVDM 采用的区块式推理方法在处理长时间影片时可能导致潜在空间的不连续性。解决计算瓶颈的关键在于将影片分解成不同的组件，并有效编码关键信息。小波变换可以将影片分解成多个频域组件，并显著提高效率，因此我们提出了小波流 VAE (WF-VAE)，这是一种利用多级小波变换促进低频能量流入潜在表示的自动编码器。此外，我们引入了一种称为因果缓存的方法，它在区块式推理期间保持潜在空间的完整性。与最先进的影片 VAE 相比，WF-VAE 在 PSNR 和 LPIPS 指标方面表现出优异的性能，在保持竞争性重建质量的同时，实现了 2 倍更高的吞吐量和 4 倍更低的内存消耗。我们的代码和模型可在 https://github.com/PKU-YuanGroup/WF-VAE 获得。

##### **Spatially Visual Perception for End-to-End Robotic Learning**
2411.17458v1 by Travis Davies, Jiahuan Yan, Xiang Chen, Yu Tian, Yueting Zhuang, Yiqi Huang, Luhui Hu

Recent advances in imitation learning have shown significant promise for
robotic control and embodied intelligence. However, achieving robust
generalization across diverse mounted camera observations remains a critical
challenge. In this paper, we introduce a video-based spatial perception
framework that leverages 3D spatial representations to address environmental
variability, with a focus on handling lighting changes. Our approach integrates
a novel image augmentation technique, AugBlender, with a state-of-the-art
monocular depth estimation model trained on internet-scale data. Together,
these components form a cohesive system designed to enhance robustness and
adaptability in dynamic scenarios. Our results demonstrate that our approach
significantly boosts the success rate across diverse camera exposures, where
previous models experience performance collapse. Our findings highlight the
potential of video-based spatial perception models in advancing robustness for
end-to-end robotic learning, paving the way for scalable, low-cost solutions in
embodied intelligence.

摘要：最近在模仿學習上的進展顯示出對機器人控制和具身智能的重大前景。然而，在不同的安裝相機觀測中實現穩健的泛化仍然是一個關鍵挑戰。在本文中，我們引入了一個基於視頻的空間感知框架，利用 3D 空間表示來解決環境變異性，重點是處理光線變化。我們的做法結合了一種新穎的圖像擴充技術 AugBlender，以及一個在網際網路規模數據上訓練的最先進的單眼深度估計模型。這些組成部分共同形成了一個內聚的系統，旨在增強動態場景中的穩健性和適應性。我們的結果表明，我們的做法顯著提高了不同相機曝光下的成功率，而先前的模型會出現效能崩潰。我們的發現突顯了基於影片的空間感知模型在推進端到端機器人學習的穩健性中的潛力，為具身智能中的可擴充、低成本解決方案鋪平了道路。

##### **FLEX-CLIP: Feature-Level GEneration Network Enhanced CLIP for X-shot Cross-modal Retrieval**
2411.17454v1 by Jingyou Xie, Jiayi Kuang, Zhenzhou Lin, Jiarui Ouyang, Zishuo Zhao, Ying Shen

Given a query from one modality, few-shot cross-modal retrieval (CMR)
retrieves semantically similar instances in another modality with the target
domain including classes that are disjoint from the source domain. Compared
with classical few-shot CMR methods, vision-language pretraining methods like
CLIP have shown great few-shot or zero-shot learning performance. However, they
still suffer challenges due to (1) the feature degradation encountered in the
target domain and (2) the extreme data imbalance. To tackle these issues, we
propose FLEX-CLIP, a novel Feature-level Generation Network Enhanced CLIP.
FLEX-CLIP includes two training stages. In multimodal feature generation, we
propose a composite multimodal VAE-GAN network to capture real feature
distribution patterns and generate pseudo samples based on CLIP features,
addressing data imbalance. For common space projection, we develop a gate
residual network to fuse CLIP features with projected features, reducing
feature degradation in X-shot scenarios. Experimental results on four benchmark
datasets show a 7%-15% improvement over state-of-the-art methods, with ablation
studies demonstrating enhancement of CLIP features.

摘要：给定一个来自一个模态的查询，少样本跨模态检索（CMR）
在另一个模态中检索语义相似的实例，目标
域包括与源域不相交的类别。与经典的少样本 CMR 方法相比，视觉语言预训练方法（如
CLIP）已经展示了极好的少样本或零样本学习性能。然而，它们
仍然面临挑战，原因在于（1）在目标域中遇到的特征退化和（2）极端的数据不平衡。为了解决这些问题，我们
提出了 FLEX-CLIP，一种新颖的特征级生成网络增强 CLIP。
FLEX-CLIP 包括两个训练阶段。在多模态特征生成中，我们
提出了一种复合多模态 VAE-GAN 网络来捕获真实的特征
分布模式并基于 CLIP 特征生成伪样本，解决数据不平衡。对于公共空间投影，我们开发了一个门
残差网络来融合 CLIP 特征和投影特征，减少
在 X-shot 场景中的特征退化。在四个基准数据集上的实验结果显示出比最先进的方法有 7%-15% 的改进，消融
研究证明了 CLIP 特征的增强。

##### **VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models**
2411.17451v1 by Lei Li, Yuancheng Wei, Zhihui Xie, Xuqing Yang, Yifan Song, Peiyi Wang, Chenxin An, Tianyu Liu, Sujian Li, Bill Yuchen Lin, Lingpeng Kong, Qi Liu

Vision-language generative reward models (VL-GenRMs) play a crucial role in
aligning and evaluating multimodal AI systems, yet their own evaluation remains
under-explored. Current assessment methods primarily rely on AI-annotated
preference labels from traditional VL tasks, which can introduce biases and
often fail to effectively challenge state-of-the-art models. To address these
limitations, we introduce VL-RewardBench, a comprehensive benchmark spanning
general multimodal queries, visual hallucination detection, and complex
reasoning tasks. Through our AI-assisted annotation pipeline combining sample
selection with human verification, we curate 1,250 high-quality examples
specifically designed to probe model limitations. Comprehensive evaluation
across 16 leading large vision-language models, demonstrates VL-RewardBench's
effectiveness as a challenging testbed, where even GPT-4o achieves only 65.4%
accuracy, and state-of-the-art open-source models such as Qwen2-VL-72B,
struggle to surpass random-guessing. Importantly, performance on VL-RewardBench
strongly correlates (Pearson's r > 0.9) with MMMU-Pro accuracy using Best-of-N
sampling with VL-GenRMs. Analysis experiments uncover three critical insights
for improving VL-GenRMs: (i) models predominantly fail at basic visual
perception tasks rather than reasoning tasks; (ii) inference-time scaling
benefits vary dramatically by model capacity; and (iii) training VL-GenRMs to
learn to judge substantially boosts judgment capability (+14.7% accuracy for a
7B VL-GenRM). We believe VL-RewardBench along with the experimental insights
will become a valuable resource for advancing VL-GenRMs.

摘要：視覺語言生成獎勵模型 (VL-GenRM) 在調整和評估多模態 AI 系統中扮演著關鍵角色，但它們自己的評估仍然未被充分探討。目前的評估方法主要依賴於傳統 VL 任務中 AI 標註的偏好標籤，這可能會引入偏差，而且常常無法有效挑戰最先進的模型。為了解決這些限制，我們引入了 VL-RewardBench，這是一個涵蓋一般多模態查詢、視覺幻覺偵測和複雜推理任務的綜合基準測試。透過我們將樣本選擇與人工驗證相結合的 AI 輔助標註管道，我們策劃了 1,250 個高品質範例，專門用於探測模型限制。對 16 個領先的大型視覺語言模型進行的綜合評估證明了 VL-RewardBench 作為一個具有挑戰性的測試平台的有效性，其中即使 GPT-4o 也只達到了 65.4% 的準確度，而最先進的開源模型，例如 Qwen2-VL-72B，則難以超越隨機猜測。重要的是，VL-RewardBench 上的表現與使用 VL-GenRM 的 Best-of-N 採樣 MMMU-Pro 準確度密切相關（Pearson's r > 0.9）。分析實驗揭示了三項改進 VL-GenRM 的關鍵見解：(i) 模型主要在基本的視覺感知任務中失敗，而不是推理任務；(ii) 推論時間縮放的效益因模型容量而異；(iii) 訓練 VL-GenRM 學習判斷會大幅提升判斷能力（7B VL-GenRM 的準確度提高了 +14.7%）。我們相信 VL-RewardBench 連同實驗見解將成為推進 VL-GenRM 的寶貴資源。

##### **Object-centric proto-symbolic behavioural reasoning from pixels**
2411.17438v1 by Ruben van Bergen, Justus Hübotter, Pablo Lanillos

Autonomous intelligent agents must bridge computational challenges at
disparate levels of abstraction, from the low-level spaces of sensory input and
motor commands to the high-level domain of abstract reasoning and planning. A
key question in designing such agents is how best to instantiate the
representational space that will interface between these two levels -- ideally
without requiring supervision in the form of expensive data annotations. These
objectives can be efficiently achieved by representing the world in terms of
objects (grounded in perception and action). In this work, we present a novel,
brain-inspired, deep-learning architecture that learns from pixels to
interpret, control, and reason about its environment, using object-centric
representations. We show the utility of our approach through tasks in synthetic
environments that require a combination of (high-level) logical reasoning and
(low-level) continuous control. Results show that the agent can learn emergent
conditional behavioural reasoning, such as $(A \to B) \land (\neg A \to C)$, as
well as logical composition $(A \to B) \land (A \to C) \vdash A \to (B \land
C)$ and XOR operations, and successfully controls its environment to satisfy
objectives deduced from these logical rules. The agent can adapt online to
unexpected changes in its environment and is robust to mild violations of its
world model, thanks to dynamic internal desired goal generation. While the
present results are limited to synthetic settings (2D and 3D activated versions
of dSprites), which fall short of real-world levels of complexity, the proposed
architecture shows how to manipulate grounded object representations, as a key
inductive bias for unsupervised learning, to enable behavioral reasoning.

摘要：自主智能代理必須彌合不同抽象層級的計算挑戰，從感官輸入和運動命令的低階層級空間到抽象推理和規劃的高階層級領域。在設計此類代理時，一個關鍵問題是如何最佳實例化介於這兩個層級之間的表徵空間，理想情況下不需要以昂貴的資料註釋形式進行監督。這些目標可透過以物件（以感知和動作為基礎）來表徵世界來有效達成。在這項工作中，我們提出一個新穎、受大腦啟發的深度學習架構，它從像素學習來詮釋、控制和推理其環境，使用以物件為中心的表徵。我們透過合成環境中的任務展示我們方法的效用，這些任務需要（高階）邏輯推理和（低階）連續控制的組合。結果顯示代理可以學習新興的條件行為推理，例如 $(A \to B) \land (\neg A \to C)$，以及邏輯組合 $(A \to B) \land (A \to C) \vdash A \to (B \land C)$ 和 XOR 運算，並成功控制其環境以滿足從這些邏輯規則推導出的目標。代理可以線上適應其環境中的意外變化，並且由於動態的內部目標產生，因此對其世界模型的輕微違規具有魯棒性。雖然目前的結果僅限於合成設定（dSprites 的 2D 和 3D 啟動版本），其複雜性低於真實世界，但所提出的架構展示了如何操作接地的物件表徵，作為無監督學習的主要歸納偏差，以實現行為推理。

##### **"Stupid robot, I want to speak to a human!" User Frustration Detection in Task-Oriented Dialog Systems**
2411.17437v1 by Mireia Hernandez Caralt, Ivan Sekulić, Filip Carević, Nghia Khau, Diana Nicoleta Popa, Bruna Guedes, Victor Guimarães, Zeyu Yang, Andre Manso, Meghana Reddy, Paolo Rosso, Roland Mathis

Detecting user frustration in modern-day task-oriented dialog (TOD) systems
is imperative for maintaining overall user satisfaction, engagement, and
retention. However, most recent research is focused on sentiment and emotion
detection in academic settings, thus failing to fully encapsulate implications
of real-world user data. To mitigate this gap, in this work, we focus on user
frustration in a deployed TOD system, assessing the feasibility of
out-of-the-box solutions for user frustration detection. Specifically, we
compare the performance of our deployed keyword-based approach, open-source
approaches to sentiment analysis, dialog breakdown detection methods, and
emerging in-context learning LLM-based detection. Our analysis highlights the
limitations of open-source methods for real-world frustration detection, while
demonstrating the superior performance of the LLM-based approach, achieving a
16\% relative improvement in F1 score on an internal benchmark. Finally, we
analyze advantages and limitations of our methods and provide an insight into
user frustration detection task for industry practitioners.

摘要：在現代以任務為導向的對話（TOD）系統中檢測使用者的沮喪情緒，對於維持整體使用者滿意度、參與度和保留率至關重要。然而，最近的研究大多集中在學術環境中的情緒檢測，因此未能完全涵蓋真實世界使用者資料的影響。為了彌補此差距，我們在這項工作中專注於已部署 TOD 系統中的使用者沮喪情緒，評估現成解決方案對使用者沮喪情緒檢測的可行性。具體來說，我們比較了我們已部署的基於關鍵字的方法、開放原始碼情緒分析方法、對話故障檢測方法和新興的語境學習 LLM 為基礎的檢測的效能。我們的分析突顯了開放原始碼方法在現實世界沮喪情緒檢測方面的限制，同時證明了基於 LLM 的方法的優異效能，在內部基準上 F1 分數提高了 16%。最後，我們分析了我們方法的優點和限制，並為業界從業人員提供了對使用者沮喪情緒檢測任務的見解。

##### **LC-SVD-DLinear: A low-cost physics-based hybrid machine learning model for data forecasting using sparse measurements**
2411.17433v1 by Ashton Hetherington, Javier López Leonés, Soledad Le Clainche

This article introduces a novel methodology that integrates singular value
decomposition (SVD) with a shallow linear neural network for forecasting high
resolution fluid mechanics data. The method, termed LC-SVD-DLinear, combines a
low-cost variant of singular value decomposition (LC-SVD) with the DLinear
architecture, which decomposes the input features-specifically, the temporal
coefficients-into trend and seasonality components, enabling a shallow neural
network to capture the non-linear dynamics of the temporal data. This
methodology uses under-resolved data, which can either be input directly into
the hybrid model or downsampled from high resolution using two distinct
techniques provided by the methodology. Working with under-resolved cases helps
reduce the overall computational cost. Additionally, we present a variant of
the method, LC-HOSVD-DLinear, which combines a low-cost version of the
high-order singular value decomposition (LC-HOSVD) algorithm with the DLinear
network, designed for high-order data. These approaches have been validated
using two datasets: first, a numerical simulation of three-dimensional flow
past a circular cylinder at $Re = 220$; and second, an experimental dataset of
turbulent flow passing a circular cylinder at $Re = 2600$. The combination of
these datasets demonstrates the robustness of the method. The forecasting and
reconstruction results are evaluated through various error metrics, including
uncertainty quantification. The work developed in this article will be included
in the next release of ModelFLOWs-app

摘要：本文介紹一種創新的方法，結合奇異值分解 (SVD) 與淺層線性神經網路，用於預測高解析流體力學資料。此方法稱為 LC-SVD-DLinear，結合奇異值分解 (LC-SVD) 的低成本變體與 DLinear 架構，將輸入特徵（特別是時間係數）分解為趨勢和季節性組成，使淺層神經網路能夠擷取時間資料的非線性動態。此方法使用解析度不足的資料，這些資料可以直接輸入混合模型，或使用此方法提供的兩種不同技術從高解析度資料中進行降採樣。處理解析度不足的情況有助於降低整體運算成本。此外，我們提出此方法的變體 LC-HOSVD-DLinear，它結合高階奇異值分解 (LC-HOSVD) 演算法的低成本版本與 DLinear 網路，專為高階資料設計。這些方法已使用兩個資料集驗證：首先，在 $Re = 220$ 時，對三維流體流過圓柱體的數值模擬；其次，在 $Re = 2600$ 時，對湍流流過圓柱體的實驗資料集。這些資料集的組合證明了此方法的穩健性。預測和重建結果透過各種誤差指標進行評估，包括不確定性量化。本文中開發的工作將包含在 ModelFLOWs 應用程式的下一個版本中

##### **CLOVER: Constrained Learning with Orthonormal Vectors for Eliminating Redundancy**
2411.17426v1 by Fanxu Meng, Muhan Zhang

To adapt a well-trained large model to downstream tasks, we propose
constraining learning within its original latent space by leveraging linear
combinations of its basis vectors. This approach ensures stable training
without compromising the model's capabilities. Traditionally, constructing
orthonormal bases from a matrix requires a transfer matrix, which significantly
increases storage and computational overhead for parameters and feature maps.
In this paper, we introduce Absorb and Decompose for Q, K, V, and O matrices,
enabling their orthogonalization without the need for transfer matrices.
Furthermore, the Absorb-Decompose operation eliminates redundant vectors,
reducing the encoder attention parameters of Whisper-large-v3 by 46.42% without
requiring additional training. For parameter-efficient and stable fine-tuning,
we orthonormalized Q, K, V, and O and fine-tuned only the singular values,
allowing efficient adaptation while constraining changes to the original latent
space. When fine-tuning LLaMA-2-7B on eight commonsense reasoning datasets, our
method outperforms LoRA by 5.4% and DoRA by 4.4%.

摘要：為了將訓練良好的大型模型適應到下游任務，我們提出透過利用其基底向量的線性組合，限制在原本潛在空間內的學習。此方法確保穩定的訓練，且不會損害模型的能力。傳統上，從矩陣建構正交標準正交基需要轉移矩陣，這會大幅增加參數和特徵圖的儲存和運算負擔。在本文中，我們引入了 Q、K、V 和 O 矩陣的吸收分解，讓它們正交化，而不需要轉移矩陣。此外，吸收分解運算消除了多餘的向量，將 Whisper-large-v3 的編碼器注意力參數減少了 46.42%，且不需要額外的訓練。為了參數效率和穩定的微調，我們正交化了 Q、K、V 和 O，並只微調奇異值，允許有效率的適應，同時限制對原本潛在空間的變更。在八個常識推理資料集上微調 LLaMA-2-7B 時，我們的模型比 LoRA 高出 5.4%，比 DoRA 高出 4.4%。

##### **BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving**
2411.17404v1 by Teng Wang, Wing-Yin Yu, Zhenqi He, Zehua Liu, Xiongwei Han, Hailei Gong, Han Wu, Wei Shi, Ruifeng She, Fangzhou Zhu, Tao Zhong

LLMs exhibit advanced reasoning capabilities, offering the potential to
transform natural language questions into mathematical models. However,
existing open-source operations research datasets lack detailed annotations of
the modeling process, such as variable definitions, focusing solely on
objective values, which hinders reinforcement learning applications. To address
this, we release the StructuredOR dataset, annotated with comprehensive labels
that capture the complete mathematical modeling process. We further propose
BPP-Search, a algorithm that integrates reinforcement learning into a
tree-of-thought structure using Beam search, a Process reward model, and a
pairwise Preference algorithm. This approach enables efficient exploration of
tree structures, avoiding exhaustive search while improving accuracy. Extensive
experiments on StructuredOR, NL4OPT, and MAMO-ComplexLP datasets show that
BPP-Search significantly outperforms state-of-the-art methods, including
Chain-of-Thought, Self-Consistency, and Tree-of-Thought. In tree-based
reasoning, BPP-Search also surpasses Process Reward Model combined with Greedy
or Beam Search, demonstrating superior accuracy and efficiency, and enabling
faster retrieval of correct solutions.

摘要：大型語言模型展現出先進的推理能力，提供將自然語言問題轉換為數學模型的可能性。然而，現有的開源運算研究資料集缺乏建模過程的詳細註解，例如變數定義，僅專注於目標值，這阻礙了強化學習的應用。為了解決這個問題，我們發布了 StructuredOR 資料集，其中附有全面標籤，涵蓋完整的數學建模過程。我們進一步提出了 BPP-Search，一種演算法，它使用 Beam 搜尋、過程獎勵模型和成對偏好演算法，將強化學習整合到思想樹結構中。這種方法能有效探索樹狀結構，避免窮舉搜尋，同時提高準確度。在 StructuredOR、NL4OPT 和 MAMO-ComplexLP 資料集上進行的廣泛實驗表明，BPP-Search 明顯優於最先進的方法，包括思想鏈、自洽性和思想樹。在基於樹的推理中，BPP-Search 也超越了與貪婪或 Beam 搜尋相結合的過程獎勵模型，展現出卓越的準確度和效率，並能更快地檢索正確的解。

##### **One Mind, Many Tongues: A Deep Dive into Language-Agnostic Knowledge Neurons in Large Language Models**
2411.17401v1 by Pengfei Cao, Yuheng Chen, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

Large language models (LLMs) have learned vast amounts of factual knowledge
through self-supervised pre-training on large-scale corpora. Meanwhile, LLMs
have also demonstrated excellent multilingual capabilities, which can express
the learned knowledge in multiple languages. However, the knowledge storage
mechanism in LLMs still remains mysterious. Some researchers attempt to
demystify the factual knowledge in LLMs from the perspective of knowledge
neurons, and subsequently discover language-agnostic knowledge neurons that
store factual knowledge in a form that transcends language barriers. However,
the preliminary finding suffers from two limitations: 1) High Uncertainty in
Localization Results. Existing study only uses a prompt-based probe to localize
knowledge neurons for each fact, while LLMs cannot provide consistent answers
for semantically equivalent queries. Thus, it leads to inaccurate localization
results with high uncertainty. 2) Lack of Analysis in More Languages. The study
only analyzes language-agnostic knowledge neurons on English and Chinese data,
without exploring more language families and languages. Naturally, it limits
the generalizability of the findings. To address aforementioned problems, we
first construct a new benchmark called Rephrased Multilingual LAMA (RML-LAMA),
which contains high-quality cloze-style multilingual parallel queries for each
fact. Then, we propose a novel method named Multilingual Integrated Gradients
with Uncertainty Estimation (MATRICE), which quantifies the uncertainty across
queries and languages during knowledge localization. Extensive experiments show
that our method can accurately localize language-agnostic knowledge neurons. We
also further investigate the role of language-agnostic knowledge neurons in
cross-lingual knowledge editing, knowledge enhancement and new knowledge
injection.

摘要：大型語言模型（LLM）透過在大型語料庫上進行自我監督預訓練，學習了大量的知識事實。同時，LLM 也展現了優異的多語言能力，能夠用多種語言表達所學的知識。然而，LLM 中的知識儲存機制仍然很神秘。有些研究人員嘗試從知識神經元的角度，揭開 LLM 中的知識事實，並進而發現了語言不可知論的知識神經元，它以超越語言障礙的形式儲存知識事實。然而，初步的發現有兩個限制：1) 定位結果的不確定性高。現有的研究僅使用基於提示的探測，為每個事實定位知識神經元，而 LLM 無法對語義等效的查詢提供一致的答案。因此，這導致定位結果不準確且不確定性高。2) 缺乏更多語言的分析。該研究僅分析了英語和中文資料上的語言不可知論知識神經元，而沒有探索更多語言族群和語言。自然地，這限制了研究結果的普遍性。為了解決上述問題，我們首先建構了一個名為改寫多語言 LAMA（RML-LAMA）的新基準，它包含了針對每個事實的高品質完形填空式多語言平行查詢。然後，我們提出了一種名為多語言整合梯度與不確定性估計（MATRICE）的新方法，它量化了在知識定位過程中跨查詢和語言的不確定性。大量的實驗顯示，我們的方法可以準確地定位語言不可知論的知識神經元。我們還進一步探討了語言不可知論知識神經元在跨語言知識編輯、知識增強和新知識注入中的作用。

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

摘要：<paragraph>在現實世界的場景中，從資訊檢索 (IR) 系統取得的大部分資料都是非結構化的。將自然語言句子轉換為結構化的知識圖譜 (KG) 仍然是一項重大的挑戰。已建構的 KG 品質也可能影響某些依賴 KG 的領域，例如 GraphRAG 系統和推薦系統的效能。最近，大型語言模型 (LLM) 已展現出令人印象深刻的能力，能處理廣泛的自然語言處理任務。然而，當利用 LLM 來處理產生結構化 KG 的任務時，仍然存在挑戰。我們已針對現有的 KG 建構方法找出三個限制。(1) 在現實世界的文件中有大量的資訊和過多的雜訊，這可能會導致萃取雜亂的資訊。(2) 原生 LLM 難以從某些特定領域的文件中有效萃取精確的知識。(3) 在將 LLM 直接用作建構 KG 的非監督式方法時，無法忽略幻覺現象。在本文中，我們提出 GraphJudger，這是一個知識圖譜建構架構，用於解決上述挑戰。我們在方法中引入了三個創新的模組，分別是實體為中心的反覆文字去雜訊、知識感知指令微調和圖形判斷。我們尋求利用 LLM 的能力，使其發揮圖形判斷者的功能，這項能力優於其僅作為 KG 建構問題預測者的角色。在兩個一般文字圖形配對資料集和一個特定領域文字圖形配對資料集上進行的實驗顯示，與基線方法相比，其效能優異。我們提出的方法的程式碼可於 https://github.com/hhy-huang/GraphJudger 取得。</paragraph>

##### **The Extractive-Abstractive Spectrum: Uncovering Verifiability Trade-offs in LLM Generations**
2411.17375v1 by Theodora Worledge, Tatsunori Hashimoto, Carlos Guestrin

Across all fields of academic study, experts cite their sources when sharing
information. While large language models (LLMs) excel at synthesizing
information, they do not provide reliable citation to sources, making it
difficult to trace and verify the origins of the information they present. In
contrast, search engines make sources readily accessible to users and place the
burden of synthesizing information on the user. Through a survey, we find that
users prefer search engines over LLMs for high-stakes queries, where concerns
regarding information provenance outweigh the perceived utility of LLM
responses. To examine the interplay between verifiability and utility of
information-sharing tools, we introduce the extractive-abstractive spectrum, in
which search engines and LLMs are extreme endpoints encapsulating multiple
unexplored intermediate operating points. Search engines are extractive because
they respond to queries with snippets of sources with links (citations) to the
original webpages. LLMs are abstractive because they address queries with
answers that synthesize and logically transform relevant information from
training and in-context sources without reliable citation. We define five
operating points that span the extractive-abstractive spectrum and conduct
human evaluations on seven systems across four diverse query distributions that
reflect real-world QA settings: web search, language simplification, multi-step
reasoning, and medical advice. As outputs become more abstractive, we find that
perceived utility improves by as much as 200%, while the proportion of properly
cited sentences decreases by as much as 50% and users take up to 3 times as
long to verify cited information. Our findings recommend distinct operating
points for domain-specific LLM systems and our failure analysis informs
approaches to high-utility LLM systems that empower users to verify
information.

摘要：<paragraph>在所有學術研究領域中，專家在分享資訊時都會引用他們的來源。儘管大型語言模型 (LLM) 在綜合資訊方面表現優異，但它們並未提供可靠的來源引用，這使得追蹤和驗證他們所提供的資訊來源變得困難。相比之下，搜尋引擎讓使用者可以輕易取得來源，並將綜合資訊的負擔交給使用者。透過一項調查，我們發現使用者在高風險查詢中偏好搜尋引擎而非 LLM，因為對於資訊來源的疑慮大於對 LLM 回應的感知效用。為了探討驗證性和資訊分享工具效用之間的交互作用，我們引入了萃取式-抽象式光譜，其中搜尋引擎和 LLM 是涵蓋多個未探索的中間操作點的極端端點。搜尋引擎是萃取式的，因為它們會以來源片段回應查詢，並附有連結 (引文) 至原始網頁。LLM 是抽象式的，因為它們會以答案回應查詢，這些答案綜合並邏輯性地轉換來自訓練和情境來源的相關資訊，但沒有可靠的引文。我們定義了五個操作點，涵蓋萃取式-抽象式光譜，並對七個系統進行了人為評估，這些系統涵蓋四種不同的查詢分佈，反映了真實世界的問答設定：網路搜尋、語言簡化、多步驟推理和醫療建議。隨著輸出變得更抽象，我們發現感知效用提高了多達 200%，而適當引用的句子比例則減少了多達 50%，使用者驗證引文資訊的時間也增加了 3 倍。我們的研究結果建議針對特定領域的 LLM 系統採用不同的操作點，我們的失敗分析為高效用 LLM 系統提供了方法，讓使用者能夠驗證資訊。</paragraph>

##### **Fairness And Performance In Harmony: Data Debiasing Is All You Need**
2411.17374v1 by Junhua Liu, Wendy Wan Yee Hui, Roy Ka-Wei Lee, Kwan Hui Lim

Fairness in both machine learning (ML) predictions and human decisions is
critical, with ML models prone to algorithmic and data bias, and human
decisions affected by subjectivity and cognitive bias. This study investigates
fairness using a real-world university admission dataset with 870 profiles,
leveraging three ML models, namely XGB, Bi-LSTM, and KNN. Textual features are
encoded with BERT embeddings. For individual fairness, we assess decision
consistency among experts with varied backgrounds and ML models, using a
consistency score. Results show ML models outperform humans in fairness by
14.08% to 18.79%. For group fairness, we propose a gender-debiasing pipeline
and demonstrate its efficacy in removing gender-specific language without
compromising prediction performance. Post-debiasing, all models maintain or
improve their classification accuracy, validating the hypothesis that fairness
and performance can coexist. Our findings highlight ML's potential to enhance
fairness in admissions while maintaining high accuracy, advocating a hybrid
approach combining human judgement and ML models.

摘要：在機器學習 (ML) 預測和人類決策中，公平性至關重要，ML 模型容易出現演算法和資料偏差，而人類決策則會受到主觀性和認知偏差的影響。本研究使用包含 870 個個人資料的真實大學入學資料集來調查公平性，並利用 XGB、Bi-LSTM 和 KNN 三種 ML 模型。文字特徵使用 BERT 嵌入進行編碼。對於個人公平性，我們使用一致性評分來評估不同背景的專家和 ML 模型之間的決策一致性。結果顯示，ML 模型在公平性方面優於人類，達到 14.08% 至 18.79%。對於群體公平性，我們提出了一個性別去偏管道，並證明了其在消除特定性別語言方面的有效性，同時不影響預測效能。在去偏處理後，所有模型都維持或提高了其分類準確度，驗證了公平性和效能可以共存的假設。我們的研究結果突顯了 ML 在提高入學公平性方面的潛力，同時維持高準確度，倡導一種結合人類判斷和 ML 模型的混合方法。

##### **Knowledge-aware Evolutionary Graph Neural Architecture Search**
2411.17339v1 by Chao Wang, Jiaxuan Zhao, Lingling Li, Licheng Jiao, Fang Liu, Xu Liu, Shuyuan Yang

Graph neural architecture search (GNAS) can customize high-performance graph
neural network architectures for specific graph tasks or datasets. However,
existing GNAS methods begin searching for architectures from a zero-knowledge
state, ignoring the prior knowledge that may improve the search efficiency. The
available knowledge base (e.g. NAS-Bench-Graph) contains many rich
architectures and their multiple performance metrics, such as the accuracy
(#Acc) and number of parameters (#Params). This study proposes exploiting such
prior knowledge to accelerate the multi-objective evolutionary search on a new
graph dataset, named knowledge-aware evolutionary GNAS (KEGNAS). KEGNAS employs
the knowledge base to train a knowledge model and a deep multi-output Gaussian
process (DMOGP) in one go, which generates and evaluates transfer architectures
in only a few GPU seconds. The knowledge model first establishes a
dataset-to-architecture mapping, which can quickly generate candidate transfer
architectures for a new dataset. Subsequently, the DMOGP with architecture and
dataset encodings is designed to predict multiple performance metrics for
candidate transfer architectures on the new dataset. According to the predicted
metrics, non-dominated candidate transfer architectures are selected to
warm-start the multi-objective evolutionary algorithm for optimizing the #Acc
and #Params on a new dataset. Empirical studies on NAS-Bench-Graph and five
real-world datasets show that KEGNAS swiftly generates top-performance
architectures, achieving 4.27% higher accuracy than advanced evolutionary
baselines and 11.54% higher accuracy than advanced differentiable baselines. In
addition, ablation studies demonstrate that the use of prior knowledge
significantly improves the search performance.

摘要：<paragraph>圖神經架構搜尋 (GNAS) 可以為特定圖形任務或資料集自訂高性能圖形神經網路架構。然而，現有的 GNAS 方法會從零知識狀態開始搜尋架構，忽略可能改善搜尋效率的先驗知識。可用的知識庫 (例如 NAS-Bench-Graph) 包含許多豐富的架構及其多項效能指標，例如準確度 (#Acc) 和參數數量 (#Params)。本研究提出一種利用此類先驗知識來加速在名為知識感知演化 GNAS (KEGNAS) 的新圖形資料集上進行多目標演化搜尋。KEGNAS 使用知識庫一次訓練知識模型和深度多輸出高斯過程 (DMOGP)，僅在幾秒的 GPU 時間內產生和評估轉移架構。知識模型首先建立資料集對架構的對應，可以快速產生候選轉移架構，以供新的資料集使用。隨後，設計具有架構和資料集編碼的 DMOGP，以預測候選轉移架構在新的資料集上的多項效能指標。根據預測的指標，會選擇非支配的候選轉移架構，以作為多目標演化演算法的熱啟動，以便針對新的資料集最佳化 #Acc 和 #Params。在 NAS-Bench-Graph 和五個實際資料集上的實證研究顯示，KEGNAS 快速產生頂尖效能的架構，準確度比進階的演化基準高出 4.27%，比進階的可微分基準高出 11.54%。此外，消融研究顯示，使用先驗知識可顯著改善搜尋效能。</paragraph>

##### **Different Bias Under Different Criteria: Assessing Bias in LLMs with a Fact-Based Approach**
2411.17338v1 by Changgeon Ko, Jisu Shin, Hoyun Song, Jeongyeon Seo, Jong C. Park

Large language models (LLMs) often reflect real-world biases, leading to
efforts to mitigate these effects and make the models unbiased. Achieving this
goal requires defining clear criteria for an unbiased state, with any deviation
from these criteria considered biased. Some studies define an unbiased state as
equal treatment across diverse demographic groups, aiming for balanced outputs
from LLMs. However, differing perspectives on equality and the importance of
pluralism make it challenging to establish a universal standard. Alternatively,
other approaches propose using fact-based criteria for more consistent and
objective evaluations, though these methods have not yet been fully applied to
LLM bias assessments. Thus, there is a need for a metric with objective
criteria that offers a distinct perspective from equality-based approaches.
Motivated by this need, we introduce a novel metric to assess bias using
fact-based criteria and real-world statistics. In this paper, we conducted a
human survey demonstrating that humans tend to perceive LLM outputs more
positively when they align closely with real-world demographic distributions.
Evaluating various LLMs with our proposed metric reveals that model bias varies
depending on the criteria used, highlighting the need for multi-perspective
assessment.

摘要：大型語言模型 (LLM) 通常反映現實世界的偏見，導致人們努力減輕這些影響並使模型不帶偏見。實現此目標需要定義公正狀態的明確標準，任何偏離這些標準的行為都被視為有偏見。一些研究將公正狀態定義為不同人口群體之間的平等對待，旨在從 LLM 獲得平衡的輸出。然而，對平等的不同觀點和多元化重要性的不同看法使得建立統一標準具有挑戰性。或者，其他方法建議使用基於事實的標準進行更一致和客觀的評估，儘管這些方法尚未完全應用於 LLM 偏差評估。因此，需要一個具有客觀標準的指標，以提供不同於基於平等的方法的獨特觀點。出於這種需要，我們引入了一種新的指標，使用基於事實的標準和現實世界的統計數據來評估偏差。在本文中，我們進行了一項人類調查，證明人類傾向於在 LLM 輸出與現實世界人口分佈密切相關時更積極地感知 LLM 輸出。使用我們提出的指標評估各種 LLM 揭示了模型偏差因所使用的標準而異，這凸顯了多角度評估的必要性。

##### **Towards Intention Recognition for Robotic Assistants Through Online POMDP Planning**
2411.17326v1 by Juan Carlos Saborio, Joachim Hertzberg

Intention recognition, or the ability to anticipate the actions of another
agent, plays a vital role in the design and development of automated assistants
that can support humans in their daily tasks. In particular, industrial
settings pose interesting challenges that include potential distractions for a
decision-maker as well as noisy or incomplete observations. In such a setting,
a robotic assistant tasked with helping and supporting a human worker must
interleave information gathering actions with proactive tasks of its own, an
approach that has been referred to as active goal recognition. In this paper we
describe a partially observable model for online intention recognition, show
some preliminary experimental results and discuss some of the challenges
present in this family of problems.

摘要：意圖識別，或預測另一個動作的能力
代理在設計和開發自動化助理中扮演著至關重要的角色
這可以協助人類執行日常任務。特別是，工業
設定會帶來有趣的挑戰，包括決策者潛在的注意力分散，以及嘈雜或不完整的觀察。在這樣的設定中，
一個機器人助理負責幫助和支援人類工作者必須
交錯資訊收集動作與其自己的主動任務，一種
被稱為主動目標識別的方法。在本文中，我們
描述了一個線上意圖識別的部分可觀察模型，顯示
一些初步的實驗結果，並討論了這個問題家族中存在的一些挑戰。

##### **PIM-AI: A Novel Architecture for High-Efficiency LLM Inference**
2411.17309v1 by Cristobal Ortega, Yann Falevoz, Renaud Ayrignac

Large Language Models (LLMs) have become essential in a variety of
applications due to their advanced language understanding and generation
capabilities. However, their computational and memory requirements pose
significant challenges to traditional hardware architectures.
Processing-in-Memory (PIM), which integrates computational units directly into
memory chips, offers several advantages for LLM inference, including reduced
data transfer bottlenecks and improved power efficiency.
  This paper introduces PIM-AI, a novel DDR5/LPDDR5 PIM architecture designed
for LLM inference without modifying the memory controller or DDR/LPDDR memory
PHY. We have developed a simulator to evaluate the performance of PIM-AI in
various scenarios and demonstrate its significant advantages over conventional
architectures. In cloud-based scenarios, PIM-AI reduces the 3-year TCO per
queries-per-second by up to 6.94x compared to state-of-the-art GPUs, depending
on the LLM model used. In mobile scenarios, PIM-AI achieves a 10- to 20-fold
reduction in energy per token compared to state-of-the-art mobile SoCs,
resulting in 25 to 45~\% more queries per second and 6.9x to 13.4x less energy
per query, extending battery life and enabling more inferences per charge.
  These results highlight PIM-AI's potential to revolutionize LLM deployments,
making them more efficient, scalable, and sustainable.

摘要：大型語言模型 (LLM) 由於其先進的語言理解和生成能力，已成為各種應用程式中不可或缺的一部分。然而，它們的運算和記憶體需求對傳統硬體架構構成重大挑戰。處理記憶體 (PIM) 將運算單元直接整合到記憶體晶片中，為 LLM 推論提供了多項優點，包括減少資料傳輸瓶頸和提升電力效率。這篇論文介紹了 PIM-AI，一種新穎的 DDR5/LPDDR5 PIM 架構，設計用於 LLM 推論，且不修改記憶體控制器或 DDR/LPDDR 記憶體 PHY。我們開發了一個模擬器來評估 PIM-AI 在各種場景中的效能，並展示其相較於傳統架構的顯著優勢。在雲端場景中，PIM-AI 將每秒查詢的 3 年 TCO 降低了多達 6.94 倍，具體取決於所使用的 LLM 模型，與最先進的 GPU 相比。在行動場景中，PIM-AI 每個代幣的能耗降低了 10 到 20 倍，與最先進的行動 SoC 相比，每秒查詢數量增加了 25% 到 45%，每項查詢的能耗降低了 6.9 倍到 13.4 倍，延長了電池續航力，並在每次充電時能進行更多推論。這些結果突顯了 PIM-AI 徹底變革 LLM 部署的潛力，使其更有效率、更具可擴充性和永續性。

##### **Meaningless is better: hashing bias-inducing words in LLM prompts improves performance in logical reasoning and statistical learning**
2411.17304v1 by Milena Chadimová, Eduard Jurášek, Tomáš Kliegr

This paper introduces a novel method, referred to as "hashing", which
involves masking potentially bias-inducing words in large language models
(LLMs) with hash-like meaningless identifiers to reduce cognitive biases and
reliance on external knowledge. The method was tested across three sets of
experiments involving a total of 490 prompts. Statistical analysis using
chi-square tests showed significant improvements in all tested scenarios, which
covered LLama, ChatGPT, Copilot, Gemini and Mixtral models. In the first
experiment, hashing decreased the fallacy rate in a modified version of the
"Linda" problem aimed at evaluating susceptibility to cognitive biases. In the
second experiment, it improved LLM results on the frequent itemset extraction
task. In the third experiment, we found hashing is also effective when the
Linda problem is presented in a tabular format rather than text, indicating
that the technique works across various input representations. Overall, the
method was shown to improve bias reduction and incorporation of external
knowledge. Despite bias reduction, hallucination rates were inconsistently
reduced across types of LLM models. These findings suggest that masking
bias-inducing terms can improve LLM performance, although its effectiveness is
model- and task-dependent.

摘要：這篇論文介紹了一種新方法，稱為「雜湊」，它涉及在大型語言模型 (LLM) 中使用雜湊類型的無意義識別碼來遮蔽潛在會引起偏見的字詞，以減少認知偏見和對外部知識的依賴。這種方法在三組實驗中進行了測試，總共涉及 490 個提示。使用卡方檢定的統計分析顯示，所有測試情境都有顯著的改善，其中涵蓋了 LLama、ChatGPT、Copilot、Gemini 和 Mixtral 模型。在第一個實驗中，雜湊降低了「Linda」問題修改版本中的謬誤率，目的是評估對認知偏見的敏感性。在第二個實驗中，它改善了 LLM 在頻繁項目集萃取任務中的結果。在第三個實驗中，我們發現雜湊在以表格格式而非文字呈現 Linda 問題時也同樣有效，這表示這種技術適用於各種輸入表示。總體而言，這種方法已被證明可以改善偏見的減少和外部知識的納入。儘管減少了偏見，但幻覺率在不同類型的 LLM 模型中減少的情況並不一致。這些發現表明，遮蔽會引起偏見的術語可以改善 LLM 的效能，儘管其有效性取決於模型和任務。

##### **ER2Score: LLM-based Explainable and Customizable Metric for Assessing Radiology Reports with Reward-Control Loss**
2411.17301v1 by Yunyi Liu, Yingshu Li, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Luping Zhou

Automated radiology report generation (R2Gen) has advanced significantly,
introducing challenges in accurate evaluation due to its complexity.
Traditional metrics often fall short by relying on rigid word-matching or
focusing only on pathological entities, leading to inconsistencies with human
assessments. To bridge this gap, we introduce ER2Score, an automatic evaluation
metric designed specifically for R2Gen. Our metric utilizes a reward model,
guided by our margin-based reward enforcement loss, along with a tailored
training data design that enables customization of evaluation criteria to suit
user-defined needs. It not only scores reports according to user-specified
criteria but also provides detailed sub-scores, enhancing interpretability and
allowing users to adjust the criteria between different aspects of reports.
Leveraging GPT-4, we designed an easy-to-use data generation pipeline, enabling
us to produce extensive training data based on two distinct scoring systems,
each containing reports of varying quality along with corresponding scores.
These GPT-generated reports are then paired as accepted and rejected samples
through our pairing rule to train an LLM towards our fine-grained reward model,
which assigns higher rewards to the report with high quality. Our
reward-control loss enables this model to simultaneously output multiple
individual rewards corresponding to the number of evaluation criteria, with
their summation as our final ER2Score. Our experiments demonstrate ER2Score's
heightened correlation with human judgments and superior performance in model
selection compared to traditional metrics. Notably, our model provides both an
overall score and individual scores for each evaluation item, enhancing
interpretability. We also demonstrate its flexible training across various
evaluation systems.

摘要：自動放射報告生成 (R2Gen) 已大幅進展，由於其複雜性，在準確評估方面引入了挑戰。傳統指標經常因依賴於嚴格的字詞匹配或僅關注病理實體而有所不足，導致與人類評估不一致。為了彌補這個差距，我們引入了 ER2Score，這是一種專門為 R2Gen 設計的自動評估指標。我們的指標利用獎勵模型，在我們的基於邊際的獎勵執行損失的指導下，以及量身打造的訓練數據設計，可以自訂評估標準以滿足使用者定義的需求。它不僅根據使用者指定的標準對報告進行評分，還提供詳細的子分數，增強了解度，並允許使用者調整報告中不同面向的標準。利用 GPT-4，我們設計了一個易於使用的數據生成管道，使我們能夠根據兩個不同的評分系統產生廣泛的訓練數據，每個系統都包含不同品質的報告以及對應的分數。這些 GPT 生成的報告隨後透過我們的配對規則配對為已接受和已拒絕的樣本，以訓練 LLM 朝向我們細緻的獎勵模型，該模型會將較高的獎勵分配給品質較高的報告。我們的獎勵控制損失使這個模型能夠同時輸出多個個別獎勵，對應於評估標準的數量，其總和為我們的最終 ER2Score。我們的實驗證明 ER2Score 與人類判斷的高度相關性，以及在模型選擇中優於傳統指標的卓越效能。值得注意的是，我們的模型提供了總體分數和每個評估項目的個別分數，增強了可解釋性。我們也展示了它在各種評估系統中的靈活訓練。

##### **2D Matryoshka Training for Information Retrieval**
2411.17299v1 by Shuai Wang, Shengyao Zhuang, Bevan Koopman, Guido Zuccon

2D Matryoshka Training is an advanced embedding representation training
approach designed to train an encoder model simultaneously across various
layer-dimension setups. This method has demonstrated higher effectiveness in
Semantic Text Similarity (STS) tasks over traditional training approaches when
using sub-layers for embeddings. Despite its success, discrepancies exist
between two published implementations, leading to varied comparative results
with baseline models. In this reproducibility study, we implement and evaluate
both versions of 2D Matryoshka Training on STS tasks and extend our analysis to
retrieval tasks. Our findings indicate that while both versions achieve higher
effectiveness than traditional Matryoshka training on sub-dimensions, and
traditional full-sized model training approaches, they do not outperform models
trained separately on specific sub-layer and sub-dimension setups. Moreover,
these results generalize well to retrieval tasks, both in supervised (MSMARCO)
and zero-shot (BEIR) settings. Further explorations of different loss
computations reveals more suitable implementations for retrieval tasks, such as
incorporating full-dimension loss and training on a broader range of target
dimensions. Conversely, some intuitive approaches, such as fixing document
encoders to full model outputs, do not yield improvements. Our reproduction
code is available at https://github.com/ielab/2DMSE-Reproduce.

摘要：2D Matryoshka 訓練是一種先進的嵌入式表徵訓練方法，旨在跨各種層級維度設定同時訓練編碼器模型。這種方法在使用子層進行嵌入時，已證明在語義文字相似度 (STS) 任務中比傳統訓練方法更有效。儘管它成功，但兩個已發布的實作之間存在差異，導致與基準模型的比較結果不同。在此可複製性研究中，我們實作並評估 STS 任務中 2D Matryoshka 訓練的兩個版本，並將我們的分析延伸到檢索任務。我們的研究結果表明，雖然兩個版本在子維度和傳統全尺寸模型訓練方法上都比傳統的 Matryoshka 訓練更有效，但它們並未優於在特定子層和子維度設定上分別訓練的模型。此外，這些結果在監督式 (MSMARCO) 和零次學習 (BEIR) 設定中都能很好地推廣到檢索任務。進一步探索不同的損失計算，揭示了更適合檢索任務的實作，例如納入全維度損失和在更廣泛的目標維度上進行訓練。相反地，一些直觀的方法，例如將文件編碼器固定到完整模型輸出，並沒有帶來改進。我們的複製程式碼可在 https://github.com/ielab/2DMSE-Reproduce 取得。

##### **GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers**
2411.17296v1 by Guoguo Ai, Guansong Pang, Hezhe Qiao, Yuan Gao, Hui Yan

Graph Transformers (GTs) have demonstrated remarkable performance in
incorporating various graph structure information, e.g., long-range structural
dependency, into graph representation learning. However, self-attention -- the
core module of GTs -- preserves only low-frequency signals on graph features,
retaining only homophilic patterns that capture similar features among the
connected nodes. Consequently, it has insufficient capacity in modeling complex
node label patterns, such as the opposite of homophilic patterns --
heterophilic patterns. Some improved GTs deal with the problem by learning
polynomial filters or performing self-attention over the first-order graph
spectrum. However, these GTs either ignore rich information contained in the
whole spectrum or neglect higher-order spectrum information, resulting in
limited flexibility and frequency response in their spectral filters. To tackle
these challenges, we propose a novel GT network, namely Graph Fourier
Kolmogorov-Arnold Transformers (GrokFormer), to go beyond the self-attention in
GTs. GrokFormer leverages learnable activation functions in order-$K$ graph
spectrum through Fourier series modeling to i) learn eigenvalue-targeted filter
functions producing learnable base that can capture a broad range of frequency
signals flexibly, and ii) extract first- and higher-order graph spectral
information adaptively. In doing so, GrokFormer can effectively capture
intricate patterns hidden across different orders and levels of frequency
signals, learning expressive, order-and-frequency-adaptive graph
representations. Comprehensive experiments conducted on 10 node classification
datasets across various domains, scales, and levels of graph heterophily, as
well as 5 graph classification datasets, demonstrate that GrokFormer
outperforms state-of-the-art GTs and other advanced graph neural networks.

摘要：圖形Transformer (GT) 在整合各種圖形結構資訊時展現出顯著的效能，例如長程結構相依性，轉化為圖形表徵學習。然而，自注意力 -- GT 的核心模組 -- 僅保留圖形特徵中的低頻訊號，僅保留捕捉連接節點間相似特徵的同質模式。因此，它在建模複雜的節點標籤模式時能力不足，例如同質模式的相反模式 -- 異質模式。一些改良的 GT 處理此問題的方法是學習多項式濾波器或對一階圖形頻譜執行自注意力。然而，這些 GT 不是忽略整個頻譜中包含的豐富資訊，就是忽略高階頻譜資訊，導致其頻譜濾波器的靈活性與頻率響應受限。為了應對這些挑戰，我們提出一個新穎的 GT 網路，稱為圖形傅立葉柯爾莫哥洛夫-阿諾德Transformer (GrokFormer)，以超越 GT 中的自注意力。GrokFormer 利用可學習的活化函數在第-$K$ 階圖形頻譜中透過傅立葉級數建模，以 i) 學習目標特徵值濾波器函數，產生可學習的基底，能夠靈活捕捉廣泛的頻率訊號，以及 ii) 自適應地提取一階和高階圖形頻譜資訊。透過這種方式，GrokFormer 可以有效捕捉隱藏在不同頻率訊號階次和層級中的複雜模式，學習表達性、階次和頻率自適應的圖形表徵。在 10 個橫跨各種領域、規模和圖形異質性層級的節點分類資料集上進行的全面實驗，以及 5 個圖形分類資料集，證明 GrokFormer 優於最先進的 GT 和其他先進的圖形神經網路。

##### **Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**
2411.17282v1 by Om Ramakisan Varma, Mala Kalra

The metaheuristic optimization technique attained more awareness for handling
complex optimization problems. Over the last few years, numerous optimization
techniques have been developed that are inspired by natural phenomena.
Recently, the propagation of the new COVID-19 implied a burden on the public
health system to suffer several deaths. Vaccination, masks, and social
distancing are the major steps taken to minimize the spread of the deadly
COVID-19 virus. Considering the social distance to combat the coronavirus
epidemic, a novel bio-inspired metaheuristic optimization model is proposed in
this work, and it is termed as Social Distancing Induced Coronavirus
Optimization Algorithm (COVO). The pace of propagation of the coronavirus can
indeed be slowed by maintaining social distance. Thirteen benchmark functions
are used to evaluate the COVO performance for discrete, continuous, and complex
problems, and the COVO model performance is compared with other well-known
optimization algorithms. The main motive of COVO optimization is to obtain a
global solution to various applications by solving complex problems with faster
convergence. At last, the validated results depict that the proposed COVO
optimization has a reasonable and acceptable performance.

摘要：元启发式优化技术在处理复杂优化问题方面获得了更多的关注。在过去的几年中，已经开发出许多受自然现象启发的优化技术。最近，新型冠状病毒肺炎的传播给公共卫生系统带来了沉重负担，导致多人死亡。接种疫苗、戴口罩和保持社交距离是为最大程度减少致命的新冠病毒传播而采取的主要措施。考虑到保持社交距离以对抗冠状病毒疫情，这项工作提出了一种新的受生物启发的元启发式优化模型，并将其称为社交距离诱导冠状病毒优化算法 (COVO)。保持社交距离确实可以减缓冠状病毒的传播速度。十三项基准函数用于评估 COVO 在离散、连续和复杂问题上的性能，并将 COVO 模型的性能与其他众所周知的优化算法进行了比较。COVO 优化算法的主要目的是通过解决复杂问题以更快的收敛速度为各种应用获取全局解决方案。最后，验证结果表明，所提出的 COVO 优化算法具有合理且可接受的性能。

##### **An Attempt to Develop a Neural Parser based on Simplified Head-Driven Phrase Structure Grammar on Vietnamese**
2411.17270v1 by Duc-Vu Nguyen, Thang Chau Phan, Quoc-Nam Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen

In this paper, we aimed to develop a neural parser for Vietnamese based on
simplified Head-Driven Phrase Structure Grammar (HPSG). The existing corpora,
VietTreebank and VnDT, had around 15% of constituency and dependency tree pairs
that did not adhere to simplified HPSG rules. To attempt to address the issue
of the corpora not adhering to simplified HPSG rules, we randomly permuted
samples from the training and development sets to make them compliant with
simplified HPSG. We then modified the first simplified HPSG Neural Parser for
the Penn Treebank by replacing it with the PhoBERT or XLM-RoBERTa models, which
can encode Vietnamese texts. We conducted experiments on our modified
VietTreebank and VnDT corpora. Our extensive experiments showed that the
simplified HPSG Neural Parser achieved a new state-of-the-art F-score of 82%
for constituency parsing when using the same predicted part-of-speech (POS)
tags as the self-attentive constituency parser. Additionally, it outperformed
previous studies in dependency parsing with a higher Unlabeled Attachment Score
(UAS). However, our parser obtained lower Labeled Attachment Score (LAS) scores
likely due to our focus on arc permutation without changing the original
labels, as we did not consult with a linguistic expert. Lastly, the research
findings of this paper suggest that simplified HPSG should be given more
attention to linguistic expert when developing treebanks for Vietnamese natural
language processing.

摘要：<paragraph>在本文中，我們旨在根據簡化的頭驅動短語結構語法 (HPSG) 為越南語開發一個神經解析器。現有的語料庫 VietTreebank 和 VnDT 約有 15% 的成分和依存樹對不符合簡化的 HPSG 規則。為了嘗試解決語料庫不符合簡化的 HPSG 規則的問題，我們隨機排列了訓練和開發集中的樣本，以使其符合簡化的 HPSG。然後，我們通過用 PhoBERT 或 XLM-RoBERTa 模型替換它來修改第一個簡化的 HPSG 神經解析器，這些模型可以編碼越南語文本。我們對修改後的 VietTreebank 和 VnDT 語料庫進行了實驗。我們的廣泛實驗表明，簡化的 HPSG 神經解析器在使用與自注意力成分解析器相同的預測詞性 (POS) 標籤時，成分解析的 F 值達到了 82% 的新技術水平。此外，它在依存解析中優於之前的研究，具有更高的未標記依附分數 (UAS)。然而，我們的解析器獲得了較低的標記依附分數 (LAS)，這可能是由於我們專注於弧排列而沒有更改原始標籤，因為我們沒有諮詢語言專家。最後，本文的研究結果表明，在為越南語自然語言處理開發樹庫時，簡化的 HPSG 應得到語言專家的更多關注。</paragraph>

##### **A Topic-level Self-Correctional Approach to Mitigate Hallucinations in MLLMs**
2411.17265v1 by Lehan He, Zeren Chen, Zhelun Shi, Tianyu Yu, Jing Shao, Lu Sheng

Aligning the behaviors of Multimodal Large Language Models (MLLMs) with human
preferences is crucial for developing robust and trustworthy AI systems. While
recent attempts have employed human experts or powerful auxiliary AI systems to
provide more accurate preference feedback, such as determining the preferable
responses from MLLMs or directly rewriting hallucination-free responses,
extensive resource overhead compromise the scalability of the feedback
collection. In this work, we introduce Topic-level Preference Overwriting
(TPO), a self-correctional approach that guide the model itself to mitigate its
own hallucination at the topic level. Through a deconfounded strategy that
replaces each topic within the response with the best or worst alternatives
generated by the model itself, TPO creates more contrasting pairwise preference
feedback, enhancing the feedback quality without human or proprietary model
intervention. Notably, the experimental results demonstrate proposed TPO
achieves state-of-the-art performance in trustworthiness, significantly
reducing the object hallucinations by 92% and overall hallucinations by 38%.
Code, model and data will be released.

摘要：對齊多模態大型語言模型 (MLLM) 的行為與人類偏好對於開發強健且值得信賴的 AI 系統至關重要。雖然近期嘗試已採用人類專家或強大的輔助 AI 系統提供更準確的偏好回饋，例如從 MLLM 中決定較佳的回應或直接改寫沒有幻覺的回應，但廣泛的資源開銷會影響回饋收集的可擴充性。在這項工作中，我們引入了主題層級偏好覆寫 (TPO)，這是一種自我修正方法，可引導模型本身在主題層級減輕其幻覺。透過一種去混淆的策略，用模型本身產生的最佳或最差的替代方案取代回應中的每個主題，TPO 會創造出更多對比的成對偏好回饋，在沒有人類或專有模型介入的情況下提升回饋品質。值得注意的是，實驗結果證明所提出的 TPO 在值得信賴度方面達到了最先進的效能，大幅減少了 92% 的物件幻覺和 38% 的整體幻覺。程式碼、模型和資料將會釋出。

##### **HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator**
2411.17261v1 by Fan Yang, Ru Zhen, Jianing Wang, Yanhao Zhang, Haoxiang Chen, Haonan Lu, Sicheng Zhao, Guiguang Ding

AIGC images are prevalent across various fields, yet they frequently suffer
from quality issues like artifacts and unnatural textures. Specialized models
aim to predict defect region heatmaps but face two primary challenges: (1) lack
of explainability, failing to provide reasons and analyses for subtle defects,
and (2) inability to leverage common sense and logical reasoning, leading to
poor generalization. Multimodal large language models (MLLMs) promise better
comprehension and reasoning but face their own challenges: (1) difficulty in
fine-grained defect localization due to the limitations in capturing tiny
details; and (2) constraints in providing pixel-wise outputs necessary for
precise heatmap generation. To address these challenges, we propose HEIE: a
novel MLLM-Based Hierarchical Explainable image Implausibility Evaluator. We
introduce the CoT-Driven Explainable Trinity Evaluator, which integrates
heatmaps, scores, and explanation outputs, using CoT to decompose complex tasks
into subtasks of increasing difficulty and enhance interpretability. Our
Adaptive Hierarchical Implausibility Mapper synergizes low-level image features
with high-level mapper tokens from LLMs, enabling precise local-to-global
hierarchical heatmap predictions through an uncertainty-based adaptive token
approach. Moreover, we propose a new dataset: Expl-AIGI-Eval, designed to
facilitate interpretable implausibility evaluation of AIGC images. Our method
demonstrates state-of-the-art performance through extensive experiments.

摘要：AIGC 影像在各個領域中十分普遍，但經常會遇到品質問題，例如人為痕跡和不自然的紋理。專門的模型旨在預測缺陷區域熱點圖，但面臨兩個主要的挑戰：(1) 缺乏可解釋性，無法提供微妙缺陷的原因和分析，以及 (2) 無法利用常識和邏輯推理，導致泛化性不佳。多模態大型語言模型 (MLLM) 承諾提供更好的理解和推理，但面臨其自身的挑戰：(1) 由於捕捉微小細節的限制，難以進行細緻的缺陷定位；以及 (2) 提供準確熱點圖生成所需的逐像素輸出的限制。為了應對這些挑戰，我們提出 HEIE：一種新穎的基於 MLLM 的分層可解釋影像不合理性評估器。我們引入了 CoT 驅動的可解釋三位一體評估器，它整合了熱點圖、分數和解釋輸出，使用 CoT 將複雜任務分解為難度越來越高的子任務，並增強可解釋性。我們的自適應分層不合理性對應器將低階影像特徵與來自 LLM 的高階對應器代幣協同作用，透過基於不確定性的自適應代幣方法實現精確的局部到全局分層熱點圖預測。此外，我們提出了一個新資料集：Expl-AIGI-Eval，旨在促進對 AIGC 影像的可解釋不合理性評估。我們的模型透過廣泛的實驗證明了最先進的效能。

##### **MiceBoneChallenge: Micro-CT public dataset and six solutions for automatic growth plate detection in micro-CT mice bone scans**
2411.17260v1 by Nikolay Burlutskiy, Marija Kekic, Jordi de la Torre, Philipp Plewa, Mehdi Boroumand, Julia Jurkowska, Borjan Venovski, Maria Chiara Biagi, Yeman Brhane Hagos, Roksana Malinowska-Traczyk, Yibo Wang, Jacek Zalewski, Paula Sawczuk, Karlo Pintarić, Fariba Yousefi, Leif Hultin

Detecting and quantifying bone changes in micro-CT scans of rodents is a
common task in preclinical drug development studies. However, this task is
manual, time-consuming and subject to inter- and intra-observer variability. In
2024, Anonymous Company organized an internal challenge to develop models for
automatic bone quantification. We prepared and annotated a high-quality dataset
of 3D $\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI
scientists from around the globe who formed $23$ teams. The participants were
tasked with developing a solution to identify the plane where the bone growth
happens, which is essential for fully automatic segmentation of trabecular
bone. As a result, six computer vision solutions were developed that can
accurately identify the location of the growth plate plane. The solutions
achieved the mean absolute error of $1.91\pm0.87$ planes from the ground truth
on the test set, an accuracy level acceptable for practical use by a
radiologist. The annotated 3D scans dataset along with the six solutions and
source code, is being made public, providing researchers with opportunities to
develop and benchmark their own approaches. The code, trained models, and the
data will be shared.

摘要：在微電腦斷層掃描中偵測和量化嚙齒動物的骨骼變化，是臨床前藥物開發研究中常見的任務。然而，這項任務是手動的、耗時的，且受觀察者間和觀察者內的變異影響。2024 年，Anonymous Company 舉辦了一場內部挑戰，以開發自動化骨骼量化的模型。我們準備並註釋了一個高品質的資料集，其中包含來自 83 隻小鼠的 3D $\mu$CT 骨骼掃描。這項挑戰吸引了來自全球超過 80 位 AI 科學家組成的 23 個團隊。參與者被賦予開發一個解決方案，以識別骨骼生長的平面，這對於完全自動化分割小樑骨至關重要。因此，開發了六個電腦視覺解決方案，可以準確識別生長板平面的位置。這些解決方案在測試集中實現了與實際情況相比平均絕對誤差為 $1.91\pm0.87$ 個平面的準確度，這對於放射科醫師的實際使用來說是可以接受的。已公開註釋的 3D 掃描資料集以及六個解決方案和原始程式碼，為研究人員提供了開發和評估其自身方法的機會。程式碼、訓練模型和資料都將分享。

##### **APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents**
2411.17255v1 by Jun Yu Chen, Tao Gao

We present APT, an advanced Large Language Model (LLM)-driven framework that
enables autonomous agents to construct complex and creative structures within
the Minecraft environment. Unlike previous approaches that primarily
concentrate on skill-based open-world tasks or rely on image-based diffusion
models for generating voxel-based structures, our method leverages the
intrinsic spatial reasoning capabilities of LLMs. By employing chain-of-thought
decomposition along with multimodal inputs, the framework generates detailed
architectural layouts and blueprints that the agent can execute under zero-shot
or few-shot learning scenarios. Our agent incorporates both memory and
reflection modules to facilitate lifelong learning, adaptive refinement, and
error correction throughout the building process. To rigorously evaluate the
agent's performance in this emerging research area, we introduce a
comprehensive benchmark consisting of diverse construction tasks designed to
test creativity, spatial reasoning, adherence to in-game rules, and the
effective integration of multimodal instructions. Experimental results using
various GPT-based LLM backends and agent configurations demonstrate the agent's
capacity to accurately interpret extensive instructions involving numerous
items, their positions, and orientations. The agent successfully produces
complex structures complete with internal functionalities such as
Redstone-powered systems. A/B testing indicates that the inclusion of a memory
module leads to a significant increase in performance, emphasizing its role in
enabling continuous learning and the reuse of accumulated experience.
Additionally, the agent's unexpected emergence of scaffolding behavior
highlights the potential of future LLM-driven agents to utilize subroutine
planning and leverage the emergence ability of LLMs to autonomously develop
human-like problem-solving techniques.

摘要：<paragraph>我們提出 APT，一個由先進大型語言模型 (LLM) 驅動的框架，使自主代理能夠在 Minecraft 環境中構建複雜且具創意的結構。與主要專注於基於技能的開放世界任務或依賴基於影像的擴散模型來生成基於體素的結構的先前方法不同，我們的模型利用了 LLM 的內在空間推理能力。透過採用思想鏈分解以及多模態輸入，該框架會生成詳細的建築佈局和藍圖，代理可以在零次學習或少次學習場景中執行這些佈局和藍圖。我們的代理整合了記憶和反思模組，以促進終身學習、適應性改進和整個建築過程中的錯誤修正。為了嚴格評估代理在這個新興研究領域中的表現，我們引入了一個綜合基準，其中包含各種建築任務，旨在測試創造力、空間推理、對遊戲規則的遵守以及多模態指令的有效整合。使用各種基於 GPT 的 LLM 後端和代理配置的實驗結果證明了代理準確詮釋涉及大量物品、其位置和方向的廣泛指令的能力。代理成功產生了複雜的結構，包括內部功能，例如紅石供電系統。A/B 測試表明，記憶模組的納入導致效能顯著提升，強調了其在實現持續學習和重複使用累積經驗中的作用。此外，代理預期之外的鷹架行為的出現突顯了未來由 LLM 驅動的代理利用子程式規劃並利用 LLM 的出現能力自主開發類似人類的解決問題技術的潛力。</paragraph>

##### **Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors**
2411.17249v1 by Zhengfei Kuang, Tianyuan Zhang, Kai Zhang, Hao Tan, Sai Bi, Yiwei Hu, Zexiang Xu, Milos Hasan, Gordon Wetzstein, Fujun Luan

We present Buffer Anytime, a framework for estimation of depth and normal
maps (which we call geometric buffers) from video that eliminates the need for
paired video--depth and video--normal training data. Instead of relying on
large-scale annotated video datasets, we demonstrate high-quality video buffer
estimation by leveraging single-image priors with temporal consistency
constraints. Our zero-shot training strategy combines state-of-the-art image
estimation models based on optical flow smoothness through a hybrid loss
function, implemented via a lightweight temporal attention architecture.
Applied to leading image models like Depth Anything V2 and Marigold-E2E-FT, our
approach significantly improves temporal consistency while maintaining
accuracy. Experiments show that our method not only outperforms image-based
approaches but also achieves results comparable to state-of-the-art video
models trained on large-scale paired video datasets, despite using no such
paired video data.

摘要：我們提出 Buffer Anytime，一個用於從影片中估計深度和法線貼圖（我們稱之為幾何緩衝區）的架構，它消除了對配對影片深度和影片法線訓練資料的需求。我們透過利用單一影像先驗與時間一致性約束，展示高品質影片緩衝區估計，而不是依賴於大規模標記影片資料集。我們的零次學習策略結合了基於光流平滑性的最新影像估計模型，透過一個混合損失函數，並透過一個輕量級時間注意力架構進行實作。我們的做法應用於 Depth Anything V2 和 Marigold-E2E-FT 等領先的影像模型，它顯著改善了時間一致性，同時維持準確度。實驗顯示，我們的模型不僅優於基於影像的做法，而且還達到了與最新影片模型相當的結果，這些影片模型是在大規模配對影片資料集上訓練的，儘管沒有使用此類配對影片資料。

##### **From Graph Diffusion to Graph Classification**
2411.17236v1 by Jia Jun Cheng Xian, Sadegh Mahdavi, Renjie Liao, Oliver Schulte

Generative models such as diffusion models have achieved remarkable success
in state-of-the-art image and text tasks. Recently, score-based diffusion
models have extended their success beyond image generation, showing competitive
performance with discriminative methods in image {\em classification}
tasks~\cite{zimmermann2021score}. However, their application to classification
in the {\em graph} domain, which presents unique challenges such as complex
topologies, remains underexplored. We show how graph diffusion models can be
applied for graph classification. We find that to achieve competitive
classification accuracy, score-based graph diffusion models should be trained
with a novel training objective that is tailored to graph classification. In
experiments with a sampling-based inference method, our discriminative training
objective achieves state-of-the-art graph classification accuracy.

摘要：生成式模型，例如擴散模型，在最先進的影像和文字任務中已取得顯著的成功。最近，基於分數的擴散模型已將其成功擴展到影像生成之外，在影像分類任務中展現出與判別式方法相抗衡的效能~\cite{zimmermann2021score}。然而，它們在圖形領域的分類應用，這提出了複雜拓撲等獨特挑戰，仍然未被充分探索。我們展示了圖形擴散模型如何應用於圖形分類。我們發現，為了達成有競爭力的分類準確度，基於分數的圖形擴散模型應使用針對圖形分類量身打造的新穎訓練目標進行訓練。在使用基於抽樣的推論方法進行的實驗中，我們的判別式訓練目標達到了最先進的圖形分類準確度。

##### **Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**
2411.17204v1 by Ratnesh Kumar Joshi, Priyanshu Priya, Vishesh Desai, Saurav Dudhate, Siddhant Senapati, Asif Ekbal, Roshni Ramnani, Anutosh Maitra

Given the advancements in conversational artificial intelligence, the
evaluation and assessment of Large Language Models (LLMs) play a crucial role
in ensuring optimal performance across various conversational tasks. In this
paper, we present a comprehensive study that thoroughly evaluates the
capabilities and limitations of five prevalent LLMs: Llama, OPT, Falcon,
Alpaca, and MPT. The study encompasses various conversational tasks, including
reservation, empathetic response generation, mental health and legal
counseling, persuasion, and negotiation. To conduct the evaluation, an
extensive test setup is employed, utilizing multiple evaluation criteria that
span from automatic to human evaluation. This includes using generic and
task-specific metrics to gauge the LMs' performance accurately. From our
evaluation, no single model emerges as universally optimal for all tasks.
Instead, their performance varies significantly depending on the specific
requirements of each task. While some models excel in certain tasks, they may
demonstrate comparatively poorer performance in others. These findings
emphasize the importance of considering task-specific requirements and
characteristics when selecting the most suitable LM for conversational
applications.

摘要：隨著對話式人工智慧的進步，大型語言模型 (LLM) 的評估和評量在確保各種對話式任務的最佳效能中扮演著至關重要的角色。在本文中，我們提出了一項全面的研究，徹底評估了五種流行 LLM 的能力和限制：Llama、OPT、Falcon、Alpaca 和 MPT。這項研究涵蓋了各種對話式任務，包括預約、同理心回應產生、心理健康和法律諮詢、說服和協商。為了進行評估，採用了廣泛的測試設定，利用了從自動到人工評估的多項評估標準。這包括使用一般性和任務特定的指標來準確衡量 LLM 的效能。從我們的評估來看，沒有單一模型在所有任務中都普遍最佳。相反地，它們的效能會根據每項任務的特定需求而有顯著差異。雖然某些模型在特定任務中表現出色，但在其他任務中表現可能相對較差。這些發現強調了在為對話式應用程式選擇最合適的 LLM 時，考量任務特定需求和特性的重要性。

##### **Learning Hierarchical Polynomials of Multiple Nonlinear Features with Three-Layer Networks**
2411.17201v1 by Hengyu Fu, Zihao Wang, Eshaan Nichani, Jason D. Lee

In deep learning theory, a critical question is to understand how neural
networks learn hierarchical features. In this work, we study the learning of
hierarchical polynomials of \textit{multiple nonlinear features} using
three-layer neural networks. We examine a broad class of functions of the form
$f^{\star}=g^{\star}\circ \bp$, where $\bp:\mathbb{R}^{d} \rightarrow
\mathbb{R}^{r}$ represents multiple quadratic features with $r \ll d$ and
$g^{\star}:\mathbb{R}^{r}\rightarrow \mathbb{R}$ is a polynomial of degree $p$.
This can be viewed as a nonlinear generalization of the multi-index model
\citep{damian2022neural}, and also an expansion upon previous work that focused
only on a single nonlinear feature, i.e. $r = 1$
\citep{nichani2023provable,wang2023learning}.
  Our primary contribution shows that a three-layer neural network trained via
layerwise gradient descent suffices for
  \begin{itemize}\item complete recovery of the space spanned by the nonlinear
features
  \item efficient learning of the target function $f^{\star}=g^{\star}\circ
\bp$ or transfer learning of $f=g\circ \bp$ with a different link function
  \end{itemize} within $\widetilde{\cO}(d^4)$ samples and polynomial time. For
such hierarchical targets, our result substantially improves the sample
complexity ${\Theta}(d^{2p})$ of the kernel methods, demonstrating the power of
efficient feature learning. It is important to highlight that{ our results
leverage novel techniques and thus manage to go beyond all prior settings} such
as single-index and multi-index models as well as models depending just on one
nonlinear feature, contributing to a more comprehensive understanding of
feature learning in deep learning.

摘要：在深度學習理論中，一個關鍵問題是了解神經網路如何學習分層特徵。在這項工作中，我們研究使用三層神經網路學習具有多個非線性特徵的分層多項式。我們探討了一類廣泛的函數形式 $f^{\star}=g^{\star}\circ \bp$，其中 $\bp:\mathbb{R}^{d} \rightarrow \mathbb{R}^{r}$ 表示具有 $r \ll d$ 的多個二次特徵，而 $g^{\star}:\mathbb{R}^{r}\rightarrow \mathbb{R}$ 是 $p$ 次多項式。這可以視為多指標模型的非線性概括 \citep{damian2022neural}，也是對先前僅關注單一非線性特徵（即 $r = 1$）工作的擴展 \citep{nichani2023provable,wang2023learning}。我們的首要貢獻表明，透過逐層梯度下降訓練的三層神經網路足以用於
  \begin{itemize}\item 完全恢復非線性特徵所跨越的空間
  \item 有效學習目標函數 $f^{\star}=g^{\star}\circ \bp$ 或使用不同的連結函數傳輸學習 $f=g\circ \bp$
  \end{itemize} 在 $\widetilde{\cO}(d^4)$ 個樣本和多項式時間內。對於此類分層目標，我們的結果大幅改善了核方法的樣本複雜度 ${\Theta}(d^{2p})$，展示了有效特徵學習的強大功能。重要的是要強調，我們的結果利用了新穎的技術，因此能夠超越所有先前的設定，例如單指標和多指標模型以及僅依賴於一個非線性特徵的模型，有助於更全面地了解深度學習中的特徵學習。

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

摘要：許多真實世界的使用者查詢（例如「如何製作蛋炒飯？」）可以受益於能夠產生包含文字步驟和附帶圖片的回應的系統，類似於食譜。專門用於產生交錯文本和圖片的模型面臨確保這些方式內部和之間的一致性的挑戰。為了應對這些挑戰，我們提出了 ISG，一個用於交錯文本和圖片產生的綜合評估架構。ISG 利用場景圖結構來捕捉文本和圖片區塊之間的關係，在四個層級的粒度上評估回應：整體、結構、區塊層級和圖片特定。這種多層評估允許對一致性、連貫性和準確性進行細緻的評估，並提供可解釋的問題解答回饋。結合 ISG，我們引入了基準 ISG-Bench，涵蓋 8 個類別和 21 個子類別中的 1,150 個範例。這個基準資料集包含複雜的語言視覺依賴關係和黃金答案，以有效評估模型在以視覺為中心的任務（例如風格轉移）上的表現，這是當前模型面臨的挑戰領域。使用 ISG-Bench，我們證明了最近的統一視覺語言模型在產生交錯內容上的表現不佳。雖然結合單獨語言和圖片模型的組合方法在整體層級上比統一模型提升了 111%，但它們在區塊和圖片層級上的表現仍然不佳。為了促進後續工作，我們開發了 ISG-Agent，一個採用「計畫執行修正」管線的基準代理，用於呼叫工具，實現了 122% 的效能提升。

##### **A Novel Word Pair-based Gaussian Sentence Similarity Algorithm For Bengali Extractive Text Summarization**
2411.17181v1 by Fahim Morshed, Md. Abdur Rahman, Sumon Ahmed

Extractive Text Summarization is the process of selecting the most
representative parts of a larger text without losing any key information.
Recent attempts at extractive text summarization in Bengali, either relied on
statistical techniques like TF-IDF or used naive sentence similarity measures
like the word averaging technique. All of these strategies suffer from
expressing semantic relationships correctly. Here, we propose a novel Word
pair-based Gaussian Sentence Similarity (WGSS) algorithm for calculating the
semantic relation between two sentences. WGSS takes the geometric means of
individual Gaussian similarity values of word embedding vectors to get the
semantic relationship between sentences. It compares two sentences on a
word-to-word basis which rectifies the sentence representation problem faced by
the word averaging method. The summarization process extracts key sentences by
grouping semantically similar sentences into clusters using the Spectral
Clustering algorithm. After clustering, we use TF-IDF ranking to pick the best
sentence from each cluster. The proposed method is validated using four
different datasets, and it outperformed other recent models by 43.2\% on
average ROUGE scores (ranging from 2.5\% to 95.4\%). It is also experimented on
other low-resource languages i.e. Turkish, Marathi, and Hindi language, where
we find that the proposed method performs as similar as Bengali for these
languages. In addition, a new high-quality Bengali dataset is curated which
contains 250 articles and a pair of summaries for each of them. We believe this
research is a crucial addition to Bengali Natural Language Processing (NLP)
research and it can easily be extended into other low-resource languages. We
made the implementation of the proposed model and data public on
\href{https://github.com/FMOpee/WGSS}{https://github.com/FMOpee/WGSS}.

摘要：萃取式文字摘要是選擇較大型文字中具代表性的部分的過程，同時不遺失任何關鍵資訊。
最近以孟加拉語進行萃取式文字摘要的嘗試，依賴於像 TF-IDF 的統計技術，或使用像字詞平均技術的樸素句子相似度測量。這些策略都會有正確表達語意關係的問題。在此，我們提出一個新的基於字詞對的 Gaussian 句子相似度 (WGSS) 演算法，用於計算兩個句子之間的語意關係。WGSS 取字詞嵌入向量的個別 Gaussian 相似度值的幾何平均值，以取得句子之間的語意關係。它在字詞對字詞的基礎上比較兩個句子，修正了字詞平均法所面臨的句子表示問題。摘要處理會使用 Spectral Clustering 演算法，將語意相似的句子分組成群集，以萃取關鍵句子。在分群後，我們使用 TF-IDF 排名從每個群集中選取最佳句子。我們使用四個不同的資料集驗證所提出的方法，而它在 ROUGE 分數上平均優於其他最近的模型 43.2%（範圍從 2.5% 到 95.4%）。它也用於其他低資源語言的實驗，例如土耳其語、馬拉地語和印地語，我們發現所提出的方法在這些語言中的表現與孟加拉語類似。此外，我們策劃了一個新的高品質孟加拉語資料集，其中包含 250 篇文章，以及每篇文章的一對摘要。我們相信這項研究對於孟加拉語自然語言處理 (NLP) 研究至關重要，而且可以輕鬆延伸到其他低資源語言。我們已將所提出的模型和資料的實作公開在 \href{https://github.com/FMOpee/WGSS}{https://github.com/FMOpee/WGSS}。

##### **ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting**
2411.17176v1 by Chengyou Jia, Changliang Xia, Zhuohang Dang, Weijia Wu, Hangwei Qian, Minnan Luo

Despite the significant advancements in text-to-image (T2I) generative
models, users often face a trial-and-error challenge in practical scenarios.
This challenge arises from the complexity and uncertainty of tedious steps such
as crafting suitable prompts, selecting appropriate models, and configuring
specific arguments, making users resort to labor-intensive attempts for desired
images. This paper proposes Automatic T2I generation, which aims to automate
these tedious steps, allowing users to simply describe their needs in a
freestyle chatting way. To systematically study this problem, we first
introduce ChatGenBench, a novel benchmark designed for Automatic T2I. It
features high-quality paired data with diverse freestyle inputs, enabling
comprehensive evaluation of automatic T2I models across all steps.
Additionally, recognizing Automatic T2I as a complex multi-step reasoning task,
we propose ChatGen-Evo, a multi-stage evolution strategy that progressively
equips models with essential automation skills. Through extensive evaluation
across step-wise accuracy and image quality, ChatGen-Evo significantly enhances
performance over various baselines. Our evaluation also uncovers valuable
insights for advancing automatic T2I. All our data, code, and models will be
available in \url{https://chengyou-jia.github.io/ChatGen-Home}

摘要：儘管文字轉影像 (T2I) 生成模型有顯著進展，但在實際情況中，使用者經常面臨試錯的挑戰。這個挑戰源於繁瑣步驟的複雜性和不確定性，例如製作合適的提示、選擇適當的模型，以及設定特定參數，使得使用者必須耗費大量心力才能得到想要的影像。本文提出自動 T2I 生成，目的是自動化這些繁瑣的步驟，讓使用者能用自由聊天的方式簡單描述他們的需求。為了系統性地探討這個問題，我們首先介紹 ChatGenBench，一個專為自動 T2I 設計的新基準測試。它具有高品質的配對資料，並有各種自由輸入，能全面評估所有步驟中的自動 T2I 模型。此外，我們將自動 T2I 視為一個複雜的多步驟推理任務，並提出 ChatGen-Evo，一種多階段的進化策略，逐漸讓模型具備必要的自動化技能。透過逐步精確度和影像品質的廣泛評估，ChatGen-Evo 在各種基線上顯著提升效能。我們的評估也揭示了推進自動 T2I 的寶貴見解。我們所有的資料、程式碼和模型都可以在 \url{https://chengyou-jia.github.io/ChatGen-Home} 取得

##### **Learning Monotonic Attention in Transducer for Streaming Generation**
2411.17170v1 by Zhengrui Ma, Yang Feng, Min Zhang

Streaming generation models are increasingly utilized across various fields,
with the Transducer architecture being particularly popular in industrial
applications. However, its input-synchronous decoding mechanism presents
challenges in tasks requiring non-monotonic alignments, such as simultaneous
translation, leading to suboptimal performance in these contexts. In this
research, we address this issue by tightly integrating Transducer's decoding
with the history of input stream via a learnable monotonic attention mechanism.
Our approach leverages the forward-backward algorithm to infer the posterior
probability of alignments between the predictor states and input timestamps,
which is then used to estimate the context representations of monotonic
attention in training. This allows Transducer models to adaptively adjust the
scope of attention based on their predictions, avoiding the need to enumerate
the exponentially large alignment space. Extensive experiments demonstrate that
our MonoAttn-Transducer significantly enhances the handling of non-monotonic
alignments in streaming generation, offering a robust solution for
Transducer-based frameworks to tackle more complex streaming generation tasks.

摘要：串流生成模型在各個領域中使用越來越廣泛，其中 Transducer 架構在產業應用中特別受到歡迎。然而，它的輸入同步解碼機制在需要非單調對齊的任務中（例如同步翻譯）會遇到挑戰，導致在這些情境中表現不佳。在本研究中，我們透過一個可學習的單調注意力機制，緊密整合 Transducer 的解碼與輸入串流的歷史記錄來解決這個問題。我們的做法利用前進後退演算法來推論預測狀態與輸入時間戳記之間對齊的後驗機率，然後用於估計訓練中單調注意力的背景表示。這讓 Transducer 模型能夠根據其預測動態調整注意力的範圍，避免需要列舉指數級大的對齊空間。廣泛的實驗證明，我們的 MonoAttn-Transducer 大幅提升串流生成中非單調對齊的處理，為基於 Transducer 的架構提供一個強健的解決方案，以應對更複雜的串流生成任務。

##### **LLM-Based Offline Learning for Embodied Agents via Consistency-Guided Reward Ensemble**
2411.17135v1 by Yujeong Lee, Sangwoo Shin, Wei-Jin Park, Honguk Woo

Employing large language models (LLMs) to enable embodied agents has become
popular, yet it presents several limitations in practice. In this work, rather
than using LLMs directly as agents, we explore their use as tools for embodied
agent learning. Specifically, to train separate agents via offline
reinforcement learning (RL), an LLM is used to provide dense reward feedback on
individual actions in training datasets. In doing so, we present a
consistency-guided reward ensemble framework (CoREN), designed for tackling
difficulties in grounding LLM-generated estimates to the target environment
domain. The framework employs an adaptive ensemble of spatio-temporally
consistent rewards to derive domain-grounded rewards in the training datasets,
thus enabling effective offline learning of embodied agents in different
environment domains. Experiments with the VirtualHome benchmark demonstrate
that CoREN significantly outperforms other offline RL agents, and it also
achieves comparable performance to state-of-the-art LLM-based agents with 8B
parameters, despite CoREN having only 117M parameters for the agent policy
network and using LLMs only for training.

摘要：利用大型语言模型 (LLM) 来启用具身代理已变得很流行，但它在实践中存在一些限制。在这项工作中，我们不是直接将 LLM 用作代理，而是探索将其用作具身代理学习的工具。具体来说，为了通过离线强化学习 (RL) 训练单独的代理，LLM 用于对训练数据集中的各个动作提供密集的奖励反馈。在此过程中，我们提出了一个一致性引导奖励集成框架 (CoREN)，旨在解决将 LLM 生成的估计与目标环境域联系起来时的困难。该框架采用时空一致奖励的自适应集成，在训练数据集中推导出域基础奖励，从而能够在不同的环境域中有效地离线学习具身代理。使用 VirtualHome 基准的实验表明，CoREN 明显优于其他离线 RL 代理，并且尽管 CoREN 的代理策略网络只有 1.17 亿个参数，并且只将 LLM 用于训练，但它也实现了与基于 LLM 的最先进代理相当的性能，后者有 80 亿个参数。

##### **DOGE: Towards Versatile Visual Document Grounding and Referring**
2411.17125v1 by Yinan Zhou, Yuxin Chen, Haokun Lin, Shuyu Yang, Li Zhu, Zhongang Qi, Chen Ma, Ying Shan

In recent years, Multimodal Large Language Models (MLLMs) have increasingly
emphasized grounding and referring capabilities to achieve detailed
understanding and flexible user interaction. However, in the realm of visual
document understanding, these capabilities lag behind due to the scarcity of
fine-grained datasets and comprehensive benchmarks. To fill this gap, we
propose the DOcument Grounding and Eferring data engine (DOGE-Engine), which
produces two types of high-quality fine-grained document data: multi-granular
parsing data for enhancing fundamental text localization and recognition
capabilities; and instruction-tuning data to activate MLLM's grounding and
referring capabilities during dialogue and reasoning. Additionally, using our
engine, we construct DOGE-Bench, which encompasses 7 grounding and referring
tasks across 3 document types (chart, poster, PDF document), providing
comprehensive evaluations for fine-grained document understanding. Furthermore,
leveraging the data generated by our engine, we develop a strong baseline
model, DOGE. This pioneering MLLM is capable of accurately referring and
grounding texts at multiple granularities within document images. Our code,
data, and model will be open-sourced for community development.

摘要：近年來，多模態大型語言模型 (MLLM) 愈來愈強調基礎和指涉能力，以達成詳細理解和彈性的使用者互動。然而，在視覺文件理解領域中，這些能力由於細粒度資料集和綜合基準的稀少而落後。為了填補這個差距，我們提出了文件基礎和指涉資料引擎 (DOGE-Engine)，它產生了兩種高品質的細粒度文件資料：多粒度解析資料，用於增強基本的文字定位和辨識能力；以及指令微調資料，用於在對話和推理期間啟動 MLLM 的基礎和指涉能力。此外，使用我們的引擎，我們建構了 DOGE-Bench，它包含了跨越 3 種文件類型（圖表、海報、PDF 文件）的 7 個基礎和指涉任務，提供細粒度文件理解的綜合評估。此外，利用我們的引擎產生的資料，我們開發了一個強大的基準模型 DOGE。這個開創性的 MLLM 能夠準確地指涉和基礎文件影像中的多重粒度文字。我們的程式碼、資料和模型將會開放原始碼，以供社群開發。

##### **Advancing Content Moderation: Evaluating Large Language Models for Detecting Sensitive Content Across Text, Images, and Videos**
2411.17123v1 by Nouar AlDahoul, Myles Joshua Toledo Tan, Harishwar Reddy Kasireddy, Yasir Zaki

The widespread dissemination of hate speech, harassment, harmful and sexual
content, and violence across websites and media platforms presents substantial
challenges and provokes widespread concern among different sectors of society.
Governments, educators, and parents are often at odds with media platforms
about how to regulate, control, and limit the spread of such content.
Technologies for detecting and censoring the media contents are a key solution
to addressing these challenges. Techniques from natural language processing and
computer vision have been used widely to automatically identify and filter out
sensitive content such as offensive languages, violence, nudity, and addiction
in both text, images, and videos, enabling platforms to enforce content
policies at scale. However, existing methods still have limitations in
achieving high detection accuracy with fewer false positives and false
negatives. Therefore, more sophisticated algorithms for understanding the
context of both text and image may open rooms for improvement in content
censorship to build a more efficient censorship system. In this paper, we
evaluate existing LLM-based content moderation solutions such as OpenAI
moderation model and Llama-Guard3 and study their capabilities to detect
sensitive contents. Additionally, we explore recent LLMs such as GPT, Gemini,
and Llama in identifying inappropriate contents across media outlets. Various
textual and visual datasets like X tweets, Amazon reviews, news articles, human
photos, cartoons, sketches, and violence videos have been utilized for
evaluation and comparison. The results demonstrate that LLMs outperform
traditional techniques by achieving higher accuracy and lower false positive
and false negative rates. This highlights the potential to integrate LLMs into
websites, social media platforms, and video-sharing services for regulatory and
content moderation purposes.

摘要：仇恨言論、騷擾、有害和性內容以及暴力在網站和媒體平台上的廣泛傳播對社會各個階層提出了重大的挑戰，並引起了廣泛的關注。政府、教育工作者和家長經常與媒體平台就如何規範、控制和限制此類內容的傳播發生分歧。檢測和審查媒體內容的技術是應對這些挑戰的關鍵解決方案。自然語言處理和電腦視覺技術已被廣泛用於自動識別和過濾敏感內容，例如攻擊性語言、暴力、裸露和成癮，無論是文本、圖像還是影片，使平台能夠大規模執行內容政策。然而，現有方法在以較少的誤報和漏報實現高檢測準確性方面仍然存在局限性。因此，更複雜的演算法用於理解文本和圖像的背景，可能會為內容審查的改進打開空間，以建立更有效的審查系統。在本文中，我們評估了現有的基於 LLM 的內容審核解決方案，例如 OpenAI 審核模型和 Llama-Guard3，並研究它們檢測敏感內容的能力。此外，我們探索了 GPT、Gemini 和 Llama 等最近的 LLM，以識別媒體機構中不適當的內容。各種文本和視覺資料集，例如 X 推文、亞馬遜評論、新聞文章、人像照片、卡通、素描和暴力影片已被用於評估和比較。結果表明，LLM 通過實現更高的準確性和更低的誤報和漏報率，優於傳統技術。這突出了將 LLM 整合到網站、社交媒體平台和影片分享服務中以進行監管和內容審核目的的潛力。

##### **Star Attention: Efficient LLM Inference over Long Sequences**
2411.17116v1 by Shantanu Acharya, Fei Jia, Boris Ginsburg

Inference with Transformer-based Large Language Models (LLMs) on long
sequences is both costly and slow due to the quadratic complexity of the
self-attention mechanism. We introduce Star Attention, a two-phase block-sparse
approximation that improves computational efficiency by sharding attention
across multiple hosts while minimizing communication overhead. In the first
phase, the context is processed using blockwise-local attention across hosts,
in parallel. In the second phase, query and response tokens attend to all prior
cached tokens through sequence-global attention. Star Attention integrates
seamlessly with most Transformer-based LLMs trained with global attention,
reducing memory requirements and inference time by up to 11x while preserving
95-100% of accuracy.

摘要：基於 Transformer 的大型語言模型 (LLM) 對長序列進行推論，由於自注意力機制的二次複雜度，既昂貴又緩慢。我們引入了 Star Attention，這是一種兩階段區塊稀疏近似，透過在多個主機上分片注意力，同時最大程度地減少通訊開銷，來提升運算效率。在第一階段，使用區塊局部注意力跨主機並行處理內容。在第二階段，查詢和回應權杖透過序列全局注意力關注所有先前快取的權杖。Star Attention 可與大多數使用全局注意力訓練的基於 Transformer 的 LLM 無縫整合，將記憶體需求和推論時間減少多達 11 倍，同時保留 95-100% 的準確度。

##### **Contrastive CFG: Improving CFG in Diffusion Models by Contrasting Positive and Negative Concepts**
2411.17077v1 by Jinho Chang, Hyungjin Chung, Jong Chul Ye

As Classifier-Free Guidance (CFG) has proven effective in conditional
diffusion model sampling for improved condition alignment, many applications
use a negated CFG term to filter out unwanted features from samples. However,
simply negating CFG guidance creates an inverted probability distribution,
often distorting samples away from the marginal distribution. Inspired by
recent advances in conditional diffusion models for inverse problems, here we
present a novel method to enhance negative CFG guidance using contrastive loss.
Specifically, our guidance term aligns or repels the denoising direction based
on the given condition through contrastive loss, achieving a nearly identical
guiding direction to traditional CFG for positive guidance while overcoming the
limitations of existing negative guidance methods. Experimental results
demonstrate that our approach effectively removes undesirable concepts while
maintaining sample quality across diverse scenarios, from simple class
conditions to complex and overlapping text prompts.

摘要：由於分類器自由引導 (CFG) 已證明在條件擴散模型取樣中有效，以改善條件對齊，許多應用程式使用否定的 CFG 項來過濾出樣本中不需要的特徵。然而，僅僅否定 CFG 引導會產生反向的機率分佈，通常會使樣本偏離邊際分佈。受到條件擴散模型在反向問題中最新進展的啟發，我們在此提出一個新方法，使用對比損失來增強負面的 CFG 引導。具體來說，我們的引導項透過對比損失，根據給定的條件對齊或排斥去噪方向，在正向引導中實現與傳統 CFG 近乎相同的引導方向，同時克服現有負向引導方法的限制。實驗結果證明，我們的做法有效地消除了不必要的概念，同時在各種情況下維持樣本品質，從簡單的類別條件到複雜且重疊的文字提示。

##### **Don't Command, Cultivate: An Exploratory Study of System-2 Alignment**
2411.17075v1 by Yuhang Wang, Jitao Sang

The o1 system card identifies the o1 models as the most robust within OpenAI,
with their defining characteristic being the progression from rapid, intuitive
thinking to slower, more deliberate reasoning. This observation motivated us to
investigate the influence of System-2 thinking patterns on model safety. In our
preliminary research, we conducted safety evaluations of the o1 model,
including complex jailbreak attack scenarios using adversarial natural language
prompts and mathematical encoding prompts. Our findings indicate that the o1
model demonstrates relatively improved safety performance; however, it still
exhibits vulnerabilities, particularly against jailbreak attacks employing
mathematical encoding. Through detailed case analysis, we identified specific
patterns in the o1 model's responses. We also explored the alignment of
System-2 safety in open-source models using prompt engineering and supervised
fine-tuning techniques. Experimental results show that some simple methods to
encourage the model to carefully scrutinize user requests are beneficial for
model safety. Additionally, we proposed a implementation plan for process
supervision to enhance safety alignment. The implementation details and
experimental results will be provided in future versions.

摘要：o1 系統卡將 o1 模型識別為 OpenAI 中最健全的模型，
其定義特徵是從快速、直觀的思考轉變為更慢、更深思熟慮的推理。這項觀察促使我們調查系統 2 思考模式對模型安全性的影響。在我們的
初步研究中，我們對 o1 模型進行了安全性評估，
包括使用對抗性自然語言提示和數學編碼提示的複雜越獄攻擊場景。我們的研究結果表明，o1
模型表現出相對改善的安全性；然而，它仍然存在漏洞，特別是針對採用
數學編碼的越獄攻擊。通過詳細的案例分析，我們識別出 o1 模型回應中的特定模式。我們還使用提示工程和監督微調技術探索了開放原始碼模型中系統 2 安全性的對齊方式。實驗結果表明，一些簡單的方法可以鼓勵模型仔細審查使用者要求，這有助於模型安全性。此外，我們提出了一個流程監督的實施計畫，以增強安全性對齊。實施細節和
實驗結果將在後續版本中提供。

##### **Path-RAG: Knowledge-Guided Key Region Retrieval for Open-ended Pathology Visual Question Answering**
2411.17073v1 by Awais Naeem, Tianhao Li, Huang-Ru Liao, Jiawei Xu, Aby M. Mathew, Zehao Zhu, Zhen Tan, Ajay Kumar Jaiswal, Raffi A. Salibian, Ziniu Hu, Tianlong Chen, Ying Ding

Accurate diagnosis and prognosis assisted by pathology images are essential
for cancer treatment selection and planning. Despite the recent trend of
adopting deep-learning approaches for analyzing complex pathology images, they
fall short as they often overlook the domain-expert understanding of tissue
structure and cell composition. In this work, we focus on a challenging
Open-ended Pathology VQA (PathVQA-Open) task and propose a novel framework
named Path-RAG, which leverages HistoCartography to retrieve relevant domain
knowledge from pathology images and significantly improves performance on
PathVQA-Open. Admitting the complexity of pathology image analysis, Path-RAG
adopts a human-centered AI approach by retrieving domain knowledge using
HistoCartography to select the relevant patches from pathology images. Our
experiments suggest that domain guidance can significantly boost the accuracy
of LLaVA-Med from 38% to 47%, with a notable gain of 28% for H&E-stained
pathology images in the PathVQA-Open dataset. For longer-form question and
answer pairs, our model consistently achieves significant improvements of 32.5%
in ARCH-Open PubMed and 30.6% in ARCH-Open Books on H\&E images. Our code and
dataset is available here (https://github.com/embedded-robotics/path-rag).

摘要：準確的診斷和預後有助於病理圖像的癌症治療選擇和規劃。儘管最近採用深度學習方法分析複雜的病理圖像的趨勢，但它們往往忽視了組織結構和細胞組成的領域專家理解。在這項工作中，我們專注於一個具有挑戰性的開放式病理 VQA（PathVQA-Open）任務，並提出了一個名為 Path-RAG 的新框架，它利用組織細胞繪圖法從病理圖像中檢索相關的領域知識，並顯著提高了 PathVQA-Open 的性能。承認病理圖像分析的複雜性，Path-RAG 採用以人為中心的 AI 方法，通過使用組織細胞繪圖法檢索領域知識，從病理圖像中選擇相關的貼片。我們的實驗表明，領域指導可以將 LLaVA-Med 的準確度從 38% 大幅提升至 47%，在 PathVQA-Open 數據集中，H&E 染色的病理圖像獲得了 28% 的顯著增益。對於較長的問答對，我們的模型在 ARCH-Open PubMed 中持續獲得 32.5% 的顯著改進，在 H&E 圖像上的 ARCH-Open Books 中獲得 30.6% 的改進。我們的代碼和數據集可在此處獲得（https://github.com/embedded-robotics/path-rag）。

##### **Relations, Negations, and Numbers: Looking for Logic in Generative Text-to-Image Models**
2411.17066v1 by Colin Conwell, Rupert Tawiah-Quashie, Tomer Ullman

Despite remarkable progress in multi-modal AI research, there is a salient
domain in which modern AI continues to lag considerably behind even human
children: the reliable deployment of logical operators. Here, we examine three
forms of logical operators: relations, negations, and discrete numbers. We
asked human respondents (N=178 in total) to evaluate images generated by a
state-of-the-art image-generating AI (DALL-E 3) prompted with these `logical
probes', and find that none reliably produce human agreement scores greater
than 50\%. The negation probes and numbers (beyond 3) fail most frequently. In
a 4th experiment, we assess a `grounded diffusion' pipeline that leverages
targeted prompt engineering and structured intermediate representations for
greater compositional control, but find its performance is judged even worse
than that of DALL-E 3 across prompts. To provide further clarity on potential
sources of success and failure in these text-to-image systems, we supplement
our 4 core experiments with multiple auxiliary analyses and schematic diagrams,
directly quantifying, for example, the relationship between the N-gram
frequency of relational prompts and the average match to generated images; the
success rates for 3 different prompt modification strategies in the rendering
of negation prompts; and the scalar variability / ratio dependence
(`approximate numeracy') of prompts involving integers. We conclude by
discussing the limitations inherent to `grounded' multimodal learning systems
whose grounding relies heavily on vector-based semantics (e.g. DALL-E 3), or
under-specified syntactical constraints (e.g. `grounded diffusion'), and
propose minimal modifications (inspired by development, based in imagery) that
could help to bridge the lingering compositional gap between scale and
structure. All data and code is available at
https://github.com/ColinConwell/T2I-Probology

摘要：儘管多模態 AI 研究取得顯著進展，但現代 AI 在一個顯著領域仍遠遠落後於人類兒童：邏輯運算子的可靠部署。在此，我們探討三種形式的邏輯運算子：關係、否定和離散數字。我們要求人類受訪者（總數 N=178）評估由最先進的影像生成 AI（DALL-E 3）產生的影像，並提示這些「邏輯探針」，結果發現沒有任何一種可靠地產生高於 50% 的人類同意分數。否定探針和數字（超過 3）最常失敗。在第四個實驗中，我們評估一個「接地擴散」管道，它利用目標提示工程和結構化中間表示來獲得更大的組成控制，但發現它的表現被評為比 DALL-E 3 在所有提示中的表現還要差。為了進一步釐清這些文字轉影像系統中成功和失敗的潛在來源，我們用多個輔助分析和示意圖補充我們的 4 個核心實驗，直接量化例如關係提示的 N-gram 頻率與生成影像的平均匹配之間的關係；在否定提示的呈現中 3 種不同提示修改策略的成功率；以及涉及整數的提示的標量變異性/比率依賴性（「近似數學能力」）。最後，我們討論了「接地」多模態學習系統固有的限制，這些系統的接地嚴重依賴於基於向量的語義（例如 DALL-E 3）或未指定的句法約束（例如「接地擴散」），並提出最小的修改（受發展啟發，基於影像），這有助於彌合規模和結構之間持續存在的組成差距。所有資料和程式碼都可以在 https://github.com/ColinConwell/T2I-Probology 取得

##### **Creative Agents: Simulating the Systems Model of Creativity with Generative Agents**
2411.17065v1 by Naomi Imasato, Kazuki Miyazawa, Takayuki Nagai, Takato Horii

With the growing popularity of generative AI for images, video, and music, we
witnessed models rapidly improve in quality and performance. However, not much
attention is paid towards enabling AI's ability to "be creative". In this
study, we implemented and simulated the systems model of creativity (proposed
by Csikszentmihalyi) using virtual agents utilizing large language models
(LLMs) and text prompts. For comparison, the simulations were conducted with
the "virtual artists" being: 1)isolated and 2)placed in a multi-agent system.
Both scenarios were compared by analyzing the variations and overall
"creativity" in the generated artifacts (measured via a user study and LLM).
Our results suggest that the generative agents may perform better in the
framework of the systems model of creativity.

摘要：隨著生成式 AI 在影像、影片和音樂領域的普及，我們見證了模型在品質和效能上的快速進步。然而，對於賦予 AI「創造力」的能力，並沒有受到太多關注。在這個研究中，我們實作並模擬了創造力的系統模型（由 Csikszentmihalyi 提出），使用虛擬代理人，利用大型語言模型 (LLM) 和文字提示。為了比較，模擬是以「虛擬藝術家」進行，分別為：1) 孤立的，2) 置於多代理人系統中。透過分析產生的作品中變異和整體「創造力」（經由使用者研究和 LLM 測量），比較了這兩種情境。我們的結果顯示，生成式代理人可能在創造力的系統模型架構中表現得更好。

##### **Graph Structure Learning with Bi-level Optimization**
2411.17062v1 by Nan Yin

Currently, most Graph Structure Learning (GSL) methods, as a means of
learning graph structure, improve the robustness of GNN merely from a local
view by considering the local information related to each edge and
indiscriminately applying the mechanism across edges, which may suffer from the
local structure heterogeneity of the graph (\ie the uneven distribution of
inter-class connections over nodes). To overcome the cons, we extract the graph
structure as a learnable parameter and jointly learn the structure and common
parameters of GNN from the global view. Excitingly, the common parameters
contain the global information for nodes features mapping, which is also
crucial for structure optimization (\ie optimizing the structure relies on
global mapping information). Mathematically, we apply a generic structure
extractor to abstract the graph structure and transform GNNs in the form of
learning structure and common parameters. Then, we model the learning process
as a novel bi-level optimization, \ie \textit{Generic Structure Extraction with
Bi-level Optimization for Graph Structure Learning (GSEBO)}, which optimizes
GNN parameters in the upper level to obtain the global mapping information and
graph structure is optimized in the lower level with the global information
learned from the upper level. We instantiate the proposed GSEBO on classical
GNNs and compare it with the state-of-the-art GSL methods. Extensive
experiments validate the effectiveness of the proposed GSEBO on four real-world
datasets.

摘要：目前，大多數圖結構學習 (GSL) 方法，作為學習圖結構的手段，僅從局部觀點，透過考量與每個邊緣相關的局部資訊，以及不加區別地將機制應用於邊緣，來改善 GNN 的穩健性，這可能會受到圖形局部結構異質性的影響（即節點間類間連接的不均勻分佈）。為了克服缺點，我們將圖形結構提取為可學習參數，並從全局觀點共同學習 GNN 的結構和共同參數。令人興奮的是，共同參數包含節點特徵對應的全局資訊，這對於結構最佳化也很重要（即最佳化結構依賴於全局對應資訊）。在數學上，我們應用通用結構提取器來抽象圖形結構，並將 GNN 轉換為學習結構和共同參數的形式。然後，我們將學習過程建模為新穎的雙層最佳化，即「用於圖形結構學習的雙層最佳化通用結構提取 (GSEBO)」，它最佳化上層的 GNN 參數以取得全局對應資訊，並在下層最佳化圖形結構，使用從上層學習的全局資訊。我們在傳統 GNN 上實例化所提出的 GSEBO，並將其與最先進的 GSL 方法進行比較。廣泛的實驗驗證了所提出的 GSEBO 在四個真實世界資料集上的有效性。

##### **ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System**
2411.17058v1 by Shuiqiao Yang, Tingmin Wu, Shigang Liu, David Nguyen, Seung Jang, Alsharif Abuadbba

Threat modeling is a crucial component of cybersecurity, particularly for
industries such as banking, where the security of financial data is paramount.
Traditional threat modeling approaches require expert intervention and manual
effort, often leading to inefficiencies and human error. The advent of Large
Language Models (LLMs) offers a promising avenue for automating these
processes, enhancing both efficiency and efficacy. However, this transition is
not straightforward due to three main challenges: (1) the lack of publicly
available, domain-specific datasets, (2) the need for tailored models to handle
complex banking system architectures, and (3) the requirement for real-time,
adaptive mitigation strategies that align with compliance standards like NIST
800-53.
  In this paper, we introduce ThreatModeling-LLM, a novel and adaptable
framework that automates threat modeling for banking systems using LLMs.
ThreatModeling-LLM operates in three stages: 1) dataset creation, 2) prompt
engineering and 3) model fine-tuning. We first generate a benchmark dataset
using Microsoft Threat Modeling Tool (TMT). Then, we apply Chain of Thought
(CoT) and Optimization by PROmpting (OPRO) on the pre-trained LLMs to optimize
the initial prompt. Lastly, we fine-tune the LLM using Low-Rank Adaptation
(LoRA) based on the benchmark dataset and the optimized prompt to improve the
threat identification and mitigation generation capabilities of pre-trained
LLMs.

摘要：威脅建模是網路安全中至關重要的部分，特別是對金融數據安全至上的銀行業等產業。傳統的威脅建模方法需要專家介入和手動操作，這通常會導致低效率和人為錯誤。大型語言模型 (LLM) 的出現為自動化這些流程提供了有前景的途徑，既能提高效率又能提高效能。然而，由於以下三個主要挑戰，這種轉型並不容易：(1) 缺乏公開可用的特定領域資料集，(2) 需要量身打造的模型來處理複雜的銀行系統架構，以及 (3) 需要與 NIST 800-53 等合規標準相符的即時適應性緩解策略。在這篇論文中，我們介紹了 ThreatModeling-LLM，這是一個新穎且適應性強的架構，它使用 LLM 自動化銀行系統的威脅建模。ThreatModeling-LLM 分三個階段運作：1) 資料集建立，2) 提示工程，以及 3) 模型微調。我們首先使用 Microsoft 威脅建模工具 (TMT) 產生一個基準資料集。然後，我們在預先訓練好的 LLM 上應用思考鏈 (CoT) 和提示最佳化 (OPRO) 來最佳化初始提示。最後，我們根據基準資料集和最佳化提示，使用低秩適應 (LoRA) 微調 LLM，以改善預先訓練好的 LLM 的威脅識別和緩解產生能力。

##### **Free$^2$Guide: Gradient-Free Path Integral Control for Enhancing Text-to-Video Generation with Large Vision-Language Models**
2411.17041v1 by Jaemin Kim, Bryan S Kim, Jong Chul Ye

Diffusion models have achieved impressive results in generative tasks like
text-to-image (T2I) and text-to-video (T2V) synthesis. However, achieving
accurate text alignment in T2V generation remains challenging due to the
complex temporal dependency across frames. Existing reinforcement learning
(RL)-based approaches to enhance text alignment often require differentiable
reward functions or are constrained to limited prompts, hindering their
scalability and applicability. In this paper, we propose Free$^2$Guide, a novel
gradient-free framework for aligning generated videos with text prompts without
requiring additional model training. Leveraging principles from path integral
control, Free$^2$Guide approximates guidance for diffusion models using
non-differentiable reward functions, thereby enabling the integration of
powerful black-box Large Vision-Language Models (LVLMs) as reward model.
Additionally, our framework supports the flexible ensembling of multiple reward
models, including large-scale image-based models, to synergistically enhance
alignment without incurring substantial computational overhead. We demonstrate
that Free$^2$Guide significantly improves text alignment across various
dimensions and enhances the overall quality of generated videos.

摘要：擴散模型在生成式任務中取得了令人印象深刻的成果，例如文字轉圖像 (T2I) 和文字轉影片 (T2V) 合成。然而，由於跨幀的複雜時間依賴性，在 T2V 生成中實現精確的文字對齊仍然具有挑戰性。現有的強化學習 (RL) 方法來增強文字對齊通常需要可微分的回饋函數，或受到提示限制，這阻礙了它們的可擴展性和適用性。在本文中，我們提出了 Free$^2$Guide，這是一個新穎的無梯度框架，用於將生成的影片與文字提示對齊，而不需要額外的模型訓練。利用路徑積分控制的原理，Free$^2$Guide 使用不可微分的回饋函數近似擴散模型的引導，從而能夠整合強大的黑盒大型視覺語言模型 (LVLMs) 作為回饋模型。此外，我們的框架支援多個回饋模型的彈性集成，包括大型基於影像的模型，以協同增強對齊，而不會造成大量的運算負擔。我們展示了 Free$^2$Guide 在各種維度上顯著改善了文字對齊，並提升了生成影片的整體品質。

##### **g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks**
2411.17030v1 by Zihan Wang, Gim Hee Lee

We introduce Generalizable 3D-Language Feature Fields (g3D-LF), a 3D
representation model pre-trained on large-scale 3D-language dataset for
embodied tasks. Our g3D-LF processes posed RGB-D images from agents to encode
feature fields for: 1) Novel view representation predictions from any position
in the 3D scene; 2) Generations of BEV maps centered on the agent; 3) Querying
targets using multi-granularity language within the above-mentioned
representations. Our representation can be generalized to unseen environments,
enabling real-time construction and dynamic updates. By volume rendering latent
features along sampled rays and integrating semantic and spatial relationships
through multiscale encoders, our g3D-LF produces representations at different
scales and perspectives, aligned with multi-granularity language, via
multi-level contrastive learning. Furthermore, we prepare a large-scale
3D-language dataset to align the representations of the feature fields with
language. Extensive experiments on Vision-and-Language Navigation under both
Panorama and Monocular settings, Zero-shot Object Navigation, and Situated
Question Answering tasks highlight the significant advantages and effectiveness
of our g3D-LF for embodied tasks.

摘要：我們引入了通用 3D 語言特徵場 (g3D-LF)，一種針對體現任務預先訓練於大型 3D 語言資料集上的 3D 表示模型。我們的 g3D-LF 處理來自代理的姿勢 RGB-D 影像，以編碼特徵場：1) 從 3D 場景中的任何位置進行新穎視圖表示預測；2) 以代理為中心的 BEV 地圖生成；3) 在上述表示中使用多粒度語言查詢目標。我們的表示可以推廣到未見過的環境，實現即時建構和動態更新。通過沿採樣光線體積渲染潛在特徵，並透過多尺度編碼器整合語義和空間關係，我們的 g3D-LF 透過多層對比學習，產生不同尺度和觀點的表示，與多粒度語言對齊。此外，我們準備了一個大型 3D 語言資料集，以將特徵場的表示與語言對齊。在全景和單眼設定、零次物體導航以及情境問答任務下的視覺和語言導航任務的廣泛實驗突顯了我們的 g3D-LF 在體現任務中的顯著優勢和有效性。

##### **SatVision-TOA: A Geospatial Foundation Model for Coarse-Resolution All-Sky Remote Sensing Imagery**
2411.17000v1 by Caleb S. Spradlin, Jordan A. Caraballo-Vega, Jian Li, Mark L. Carroll, Jie Gong, Paul M. Montesano

Foundation models have the potential to transform the landscape of remote
sensing (RS) data analysis by enabling large computer vision models to be
pre-trained on vast amounts of remote sensing data. These models can then be
fine-tuned with small amounts of labeled training and applied to a variety of
applications. Most existing foundation models are designed for high spatial
resolution, cloud-free satellite imagery or photos, limiting their
applicability in scenarios that require frequent temporal monitoring or broad
spectral profiles. As a result, foundation models trained solely on cloud-free
images have limited utility for applications that involve atmospheric variables
or require atmospheric corrections. We introduce SatVision-TOA, a novel
foundation model pre-trained on 14-band MODIS L1B Top-Of-Atmosphere (TOA)
radiance imagery, addressing the need for models pre-trained to handle
moderate- and coarse-resolution all-sky remote sensing data. The SatVision-TOA
model is pre-trained using a Masked-Image-Modeling (MIM) framework and the
SwinV2 architecture, and learns detailed contextual representations through
self-supervised learning without the need for labels. It is a 3 billion
parameter model that is trained on 100 million images. To our knowledge this is
the largest foundation model trained solely on satellite RS imagery. Results
show that SatVision-TOA achieves superior performance over baseline methods on
downstream tasks such as 3D cloud retrieval. Notably, the model achieves a mean
intersection over union (mIOU) of 0.46, a substantial improvement over the
baseline mIOU of 0.22. Additionally, the rate of false negative results in the
fine-tuning task were reduced by over 50% compared to the baseline. Our work
advances pre-trained vision modeling for multispectral RS by learning from a
variety of atmospheric and aerosol conditions to improve cloud and land surface
monitoring.

摘要：基礎模型有潛力透過讓大型電腦視覺模型在大量的遙測資料上進行預訓練，來轉變遙測 (RS) 資料分析的領域。這些模型接著可以用少量的標籤訓練進行微調，並應用於各種應用程式。大多數現有的基礎模型都是設計用於高空間解析度、無雲的衛星影像或照片，限制了它們在需要頻繁時間監控或廣泛光譜特徵的情況下的適用性。因此，僅在無雲影像上訓練的基礎模型對於涉及大氣變數或需要大氣校正的應用程式而言，其效用有限。我們引入了 SatVision-TOA，這是一個創新的基礎模型，預先訓練於 14 波段 MODIS L1B 大氣層頂端 (TOA) 輻射影像上，滿足了預先訓練模型來處理中解析度和低解析度的全天遙測資料的需求。SatVision-TOA 模型使用遮罩影像建模 (MIM) 架構和 SwinV2 架構進行預訓練，並透過自監督學習來學習詳細的脈絡表徵，而不需要標籤。它是一個 30 億個參數的模型，訓練於 1 億張影像上。據我們所知，這是僅在衛星 RS 影像上訓練的最大基礎模型。結果顯示，在 3D 雲擷取等下游任務上，SatVision-TOA 達到了優於基準方法的效能。值得注意的是，該模型在聯集上的平均交集 (mIOU) 達到了 0.46，大幅優於基準 mIOU 的 0.22。此外，與基準相比，微調任務中的假陰性結果率降低了 50% 以上。我們的研究透過學習各種大氣和氣溶膠條件來改善雲和地表監控，推動了多光譜 RS 的預訓練視覺建模。

##### **Tree Transformers are an Ineffective Model of Syntactic Constituency**
2411.16993v1 by Michael Ginn

Linguists have long held that a key aspect of natural language syntax is the
recursive organization of language units into constituent structures, and
research has suggested that current state-of-the-art language models lack an
inherent bias towards this feature. A number of alternative models have been
proposed to provide inductive biases towards constituency, including the Tree
Transformer, which utilizes a modified attention mechanism to organize tokens
into constituents.
  We investigate Tree Transformers to study whether they utilize meaningful
and/or useful constituent structures. We pretrain a large Tree Transformer on
language modeling in order to investigate the learned constituent tree
representations of sentences, finding little evidence for meaningful
structures. Next, we evaluate Tree Transformers with similar transformer models
on error detection tasks requiring constituent structure. We find that while
the Tree Transformer models may slightly outperform at these tasks, there is
little evidence to suggest a meaningful improvement. In general, we conclude
that there is little evidence to support Tree Transformer as an effective model
of syntactic constituency.

摘要：語言學家長期以來認為自然語言句法的關鍵方面是語言單位遞迴組織成組成結構，而研究表明，當前最先進的語言模型缺乏對此特徵的內在偏見。已經提出了許多替代模型來提供對組成成分的歸納偏見，包括 Tree Transformer，它利用修改後的注意力機制將令牌組織成組成成分。
我們研究 Tree Transformer 以研究它們是否利用有意義和/或有用的組成結構。我們在語言建模中預訓練一個大型 Tree Transformer，以研究句子的學習組成樹表示，發現很少有有意義的結構證據。接下來，我們使用類似的Transformer模型對 Tree Transformer 進行評估，對需要組成結構的錯誤檢測任務進行評估。我們發現，雖然 Tree Transformer 模型在這些任務上可能表現略好，但幾乎沒有證據表明有意義的改進。總的來說，我們得出結論，幾乎沒有證據支持 Tree Transformer 作為句法組成的有效模型。

##### **Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning Small Language Models**
2411.16991v1 by Yao Fu, Yin Yu, Xiaotian Han, Runchao Li, Xianxuan Long, Haotian Yu, Pan Li

Knowledge distillation (KD) has become a widely adopted approach for
compressing large language models (LLMs) to reduce computational costs and
memory footprints. However, the availability of complex teacher models is a
prerequisite for running most KD pipelines. Thus, the traditional KD procedure
can be unachievable or budget-unfriendly, particularly when relying on
commercial LLMs like GPT4. In this regard, Self-distillation (SelfD) emerges as
an advisable alternative, enabling student models to learn without teachers'
guidance. Nonetheless, existing SelfD approaches for LMs often involve
architectural modifications, assuming the models are open-source, which may not
always be practical. In this work, we introduce a model-agnostic and
task-agnostic method named dynamic SelfD from the previous minibatch (DynSDPB),
which realizes current iterations' distillation from the last ones' generated
logits. Additionally, to address prediction inaccuracies during the early
iterations, we dynamically adjust the distillation influence and temperature
values to enhance the adaptability of fine-tuning. Furthermore, DynSDPB is a
novel fine-tuning policy that facilitates the seamless integration of existing
self-correction and self-training techniques for small language models (SLMs)
because they all require updating SLMs' parameters. We demonstrate the superior
performance of DynSDPB on both encoder-only LMs (e.g., BERT model families) and
decoder-only LMs (e.g., LLaMA model families), validating its effectiveness
across natural language understanding (NLU) and natural language generation
(NLG) benchmarks.

摘要：知識蒸餾 (KD) 已成為廣泛採用的方法，用於壓縮大型語言模型 (LLM)，以降低運算成本和記憶體使用量。然而，複雜教師模型的可用性是執行大多數 KD 管線的先決條件。因此，傳統的 KD 程序可能無法實現或不符合預算，特別是在依賴 GPT4 等商業 LLM 時。在這方面，自蒸餾 (SelfD) 成為建議的替代方案，使學生模型能夠在沒有教師指導的情況下學習。儘管如此，現有的 LLM 自蒸餾方法通常涉及架構修改，假設模型是開源的，這可能並不總是實用的。在這項工作中，我們介紹了一種與模型無關且與任務無關的方法，稱為動態自蒸餾來自前一個小批次 (DynSDPB)，它實現了從最後一個生成的邏輯中蒸餾當前反覆運算。此外，為了解決早期反覆運算期間的預測不準確性，我們動態調整蒸餾影響和溫度值，以增強微調的適應性。此外，DynSDPB 是一項新穎的微調策略，它促進了現有自校正和自訓練技術與小型語言模型 (SLM) 的無縫整合，因為它們都需要更新 SLM 的參數。我們在僅編碼器 LLM（例如 BERT 模型系列）和僅解碼器 LLM（例如 LLaMA 模型系列）上展示了 DynSDPB 的卓越效能，驗證了其在自然語言理解 (NLU) 和自然語言生成 (NLG) 基準中的有效性。

##### **Teaching Smaller Language Models To Generalise To Unseen Compositional Questions (Full Thesis)**
2411.16985v1 by Tim Hartill

Pretrained large Language Models (LLMs) are able to answer questions that are
unlikely to have been encountered during training. However a diversity of
potential applications exist in the broad domain of reasoning systems and
considerations such as latency, cost, available compute resource and internet
connectivity are relevant in determining an appropriate approach. We consider
the setting where some local compute capacity is available at inference time
but internet connectivity is not.
  Similar to a general-purpose LLM, we assume that our much smaller Reasoning
Models may be asked arbitrary questions from unknown distributions, so we focus
on evaluation in an unseen setting. We train our models to answer diverse
questions by instilling an ability to reason over a retrieved context. We
acquire context from two knowledge sources; a Wikipedia corpus queried using a
multi-hop dense retrieval system with novel extensions, and from rationales
generated from a larger Language Model optimised to run in a lower resource
environment.
  Our main contributions: We propose novel methods to show that our model is
capable of answering contextualised questions without memorisation. We
establish a comprehensive set of baseline results on unseen evaluation
datasets. We show that the addition of novel retrieval-augmented training
datasets (RATD) to the training regime of the Reasoning Model significantly
improves results. We demonstrate further significant improvement through the
application of methods for combining knowledge from two sources. The first
method (RR) involves training a novel Rationale Ranking model to score both
generated rationales and retrieved contexts with respect to relevance and
truthfulness. We use the scores to derive combined contexts. We also show that
utilising the RATD datasets enables our model to become proficient at utilising
combined noisy contexts.

摘要：<paragraph>預先訓練的大語言模型 (LLM) 能回答訓練期間不太可能遇到的問題。然而，在廣泛的推理系統領域中存在各種潛在應用，而考量因素（例如延遲、成本、可用計算資源和網路連線）與決定適當的方法有關。我們考慮在推理時間有部分可用本機運算能力但沒有網路連線的情況。
與通用 LLM 類似，我們假設我們小得多的推理模型可能會被問到來自未知分佈的任意問題，因此我們專注於在未見過的情況下進行評估。我們訓練模型回答各種問題，方法是灌輸在擷取的內容中推理的能力。我們從兩個知識來源獲取內容：使用具有新穎多重跳躍密集檢索系統查詢的維基百科語料庫，以及從經過最佳化以在低資源環境中執行的較大語言模型產生的依據。
我們的貢獻：我們提出新穎的方法來證明我們的模型有能力在沒有記憶的情況下回答情境化問題。我們在未見過的評估資料集上建立了一套全面的基準結果。我們證明在推理模型的訓練過程中加入新穎的檢索擴充訓練資料集 (RATD)，會顯著改善結果。我們透過應用結合來自兩個來源的知識的方法，進一步展示顯著的改善。第一個方法 (RR) 涉及訓練一個新穎的依據排名模型，針對相關性和真實性為產生的依據和擷取的內容評分。我們使用分數來推導組合內容。我們也證明利用 RATD 資料集能使我們的模型熟練利用組合的雜訊內容。</paragraph>

##### **Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach**
2411.16954v1 by Xiaoteng, Liu, Pavly Halim

Analytical framework for predicting General Matrix Multiplication (GEMM)
performance on modern GPUs, focusing on runtime, power consumption, and energy
efficiency. Our study employs two approaches: a custom-implemented tiled matrix
multiplication kernel for fundamental analysis, and NVIDIA's CUTLASS library
for comprehensive performance data collection across advanced configurations.
Using the NVIDIA RTX 4070 as our experimental platform, we developed a Random
Forest-based prediction model with multi-output regression capability. Through
analysis of both naive tiled matrix multiplication with varying tile sizes (1
to 32) and 16,128 CUTLASS GEMM operations across diverse configurations, we
identified critical performance patterns related to matrix dimensions, thread
block configurations, and memory access patterns. Our framework achieved
exceptional accuracy with an R^2 score of 0.98 for runtime prediction (mean
error 15.57%) and 0.78 for power prediction (median error 5.42%). The system
successfully predicts performance across matrix sizes, demonstrating robust
scaling behavior. Our results show that optimal tile size selection can improve
performance by up to 3.2x while reducing power consumption by 22% compared to
baseline configurations. Analysis of shared memory utilization and SM occupancy
reveals that tile sizes of 16x16 achieve the best balance between parallelism
and resource usage. The implementation of our framework, including prediction
models and analysis tools, is available as an open-source project at GPPerf
[https://github.com/pavlyhalim/GPPerf].

摘要：分析框架用于预测通用矩阵乘法 (GEMM) 在现代 GPU 上的性能，重点关注运行时、功耗和能效。我们的研究采用两种方法：一个自定义实现的平铺矩阵乘法内核用于基本分析，以及 NVIDIA 的 CUTLASS 库用于跨高级配置收集全面的性能数据。使用 NVIDIA RTX 4070 作为我们的实验平台，我们开发了一个基于随机森林的预测模型，具有多输出回归能力。通过分析具有不同平铺大小（1 到 32）的朴素平铺矩阵乘法和跨不同配置的 16,128 个 CUTLASS GEMM 操作，我们识别出与矩阵维度、线程块配置和内存访问模式相关的关键性能模式。我们的框架在运行时预测（平均误差 15.57%）和功率预测（中位数误差 5.42%）方面取得了卓越的准确性，R^2 得分为 0.98。该系统成功预测了跨矩阵大小的性能，展示了稳健的缩放行为。我们的结果表明，与基线配置相比，最佳平铺大小选择可以将性能提高多达 3.2 倍，同时将功耗降低 22%。对共享内存利用率和 SM 占用率的分析表明，16x16 的平铺大小在并行性和资源使用之间实现了最佳平衡。我们框架的实现，包括预测模型和分析工具，作为 GPPerf 中的一个开源项目提供 [https://github.com/pavlyhalim/GPPerf]。

##### **Harnessing LLMs for Educational Content-Driven Italian Crossword Generation**
2411.16936v1 by Kamyar Zeinalipour, Achille Fusco, Asya Zanollo, Marco Maggini, Marco Gori

In this work, we unveil a novel tool for generating Italian crossword puzzles
from text, utilizing advanced language models such as GPT-4o,
Mistral-7B-Instruct-v0.3, and Llama3-8b-Instruct. Crafted specifically for
educational applications, this cutting-edge generator makes use of the
comprehensive Italian-Clue-Instruct dataset, which comprises over 30,000
entries including diverse text, solutions, and types of clues. This carefully
assembled dataset is designed to facilitate the creation of contextually
relevant clues in various styles associated with specific texts and keywords.
The study delves into four distinctive styles of crossword clues: those without
format constraints, those formed as definite determiner phrases, copular
sentences, and bare noun phrases. Each style introduces unique linguistic
structures to diversify clue presentation. Given the lack of sophisticated
educational tools tailored to the Italian language, this project seeks to
enhance learning experiences and cognitive development through an engaging,
interactive platform. By meshing state-of-the-art AI with contemporary
educational strategies, our tool can dynamically generate crossword puzzles
from Italian educational materials, thereby providing an enjoyable and
interactive learning environment. This technological advancement not only
redefines educational paradigms but also sets a new benchmark for interactive
and cognitive language learning solutions.

摘要：在這項工作中，我們揭示了一個新穎的工具，用於從文本生成義大利文填字謎，利用先進的語言模型，例如 GPT-4o、Mistral-7B-Instruct-v0.3 和 Llama3-8b-Instruct。專門為教育應用程式打造，這個尖端的產生器利用了全面的義大利文提示指令資料集，其中包含超過 30,000 個條目，包括不同的文字、解答和提示類型。這個經過仔細彙編的資料集旨在促進在與特定文字和關鍵字相關的不同風格中建立上下文相關的提示。這項研究深入探討了四種獨特的填字謎提示風格：沒有格式限制的、以定冠詞短語形式的、系表句和名詞短語。每種風格都引入了獨特的語言結構，以使提示呈現多樣化。鑑於缺乏針對義大利語量身打造的精緻教育工具，這個專案旨在透過一個引人入勝的互動式平台來增強學習體驗和認知發展。透過將最先進的人工智慧與當代教育策略相結合，我們的工具可以動態地從義大利文教育材料中產生填字謎，從而提供一個愉快且互動的學習環境。這項技術進步不僅重新定義了教育範例，也為互動式和認知式語言學習解決方案設定了新的基準。

##### **ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code**
2411.16927v1 by Mohammad Jalili Torkamani, Abhinav Sharma, Nikita Mehrotra, Rahul Purandare

Production assertions are statements embedded in the code to help developers
validate their assumptions about the code. They assist developers in debugging,
provide valuable documentation, and enhance code comprehension. Current
research in this area primarily focuses on assertion generation for unit tests
using techniques, such as static analysis and deep learning. While these
techniques have shown promise, they fall short when it comes to generating
production assertions, which serve a different purpose.
  This preprint addresses the gap by introducing Assertify, an automated
end-to-end tool that leverages Large Language Models (LLMs) and prompt
engineering with few-shot learning to generate production assertions. By
creating context-rich prompts, the tool emulates the approach developers take
when creating production assertions for their code. To evaluate our approach,
we compiled a dataset of 2,810 methods by scraping 22 mature Java repositories
from GitHub. Our experiments demonstrate the effectiveness of few-shot learning
by producing assertions with an average ROUGE-L score of 0.526, indicating
reasonably high structural similarity with the assertions written by
developers. This research demonstrates the potential of LLMs in automating the
generation of production assertions that resemble the original assertions.

摘要：生產斷言是嵌入在程式碼中的陳述，用於協助開發人員驗證他們對程式碼的假設。它們協助開發人員進行除錯、提供有價值的文件，並增強程式碼理解。目前這方面的研究主要集中於使用靜態分析和深度學習等技術針對單元測試產生斷言。雖然這些技術已展現出前景，但在產生生產斷言時卻有所不足，因為生產斷言服務於不同的目的。
  本預印本透過引入 Assertify 來解決這個差距，Assertify 是一個自動化端到端工具，它利用大型語言模型 (LLM) 和提示工程，並透過少量學習來產生生產斷言。透過建立豐富的提示，此工具模擬開發人員在為其程式碼建立生產斷言時採取的方法。為了評估我們的做法，我們透過從 GitHub 中擷取 22 個成熟的 Java 儲存庫，編譯了一個包含 2,810 個方法的資料集。我們的實驗證明了少量學習的有效性，它產生斷言的平均 ROUGE-L 分數為 0.526，表示與開發人員編寫的斷言具有相當高的結構相似性。這項研究展示了 LLM 在自動化產生類似原始斷言的生產斷言方面的潛力。

##### **Boundless Socratic Learning with Language Games**
2411.16905v1 by Tom Schaul

An agent trained within a closed system can master any desired capability, as
long as the following three conditions hold: (a) it receives sufficiently
informative and aligned feedback, (b) its coverage of experience/data is broad
enough, and (c) it has sufficient capacity and resource. In this position
paper, we justify these conditions, and consider what limitations arise from
(a) and (b) in closed systems, when assuming that (c) is not a bottleneck.
Considering the special case of agents with matching input and output spaces
(namely, language), we argue that such pure recursive self-improvement, dubbed
"Socratic learning", can boost performance vastly beyond what is present in its
initial data or knowledge, and is only limited by time, as well as gradual
misalignment concerns. Furthermore, we propose a constructive framework to
implement it, based on the notion of language games.

摘要：在封閉系統內訓練出的代理程式，只要符合以下三個條件，就能掌握任何所需的技能：(a) 接收充分的資訊且一致的回饋，(b) 經驗/資料的涵蓋範圍夠廣，(c) 擁有足夠的能力和資源。在本文中，我們會說明這些條件，並思考在假設 (c) 不是瓶頸的情況下，封閉系統中的 (a) 和 (b) 會產生什麼限制。考量輸入和輸出空間相符的代理程式（也就是語言）的特殊情況，我們主張這種純粹的遞迴式自我提升，稱為「蘇格拉底學習法」，可以大幅提升效能，遠遠超出其初始資料或知識，而且僅受限於時間，以及逐漸失衡的問題。此外，我們提出一個建構性的架構來實作它，這個架構是基於語言遊戲的概念。

##### **Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with Differential Transformer Based Deep Learning Model Incorporating Pixelwise Instrument Response Function**
2411.16896v1 by Ismail Erbas, Vikas Pandey, Navid Ibtehaj Nizam, Nanxue Yuan, Amit Verma, Margarida Barosso, Xavier Intes

Fluorescence lifetime imaging (FLI) is an important molecular imaging
modality that can provide unique information for biomedical applications. FLI
is based on acquiring and processing photon time of arrival histograms. The
shape and temporal offset of these histograms depends on many factors, such as
the instrument response function (IRF), optical properties, and the topographic
profile of the sample. Several inverse solver analytical methods have been
developed to compute the underlying fluorescence lifetime parameters, but most
of them are computationally expensive and time-consuming. Thus, deep learning
(DL) algorithms have progressively replaced computation methods in fluorescence
lifetime parameter estimation. Often, DL models are trained with simple
datasets either generated through simulation or a simple experiment where the
fluorophore surface profile is mostly flat; therefore, DL models often do not
perform well on samples with complex surface profiles such as ex-vivo organs or
in-vivo whole intact animals. Herein, we introduce a new DL architecture using
state-of-the-art Differential Transformer encoder-decoder architecture, MFliNet
(Macroscopic FLI Network), that takes an additional input of IRF together with
TPSF, addressing discrepancies in the photon time-of-arrival distribution. We
demonstrate the model's performance through carefully designed, complex
tissue-mimicking phantoms and preclinical in-vivo cancer xenograft experiments.

摘要：螢光生命期影像 (FLI) 是一種重要的分子影像模式，可提供生物醫學應用之獨特資訊。FLI 是基於獲取和處理光子抵達時間的直方圖。這些直方圖的形狀和時間偏移取決於許多因素，例如儀器反應函數 (IRF)、光學特性和樣品的形貌輪廓。已經開發了幾種反向求解器分析方法來計算基礎螢光生命期參數，但其中大多數在計算上很昂貴且耗時。因此，深度學習 (DL) 演算法已逐漸取代計算方法來估計螢光生命期參數。通常，DL 模型會使用簡單的資料集進行訓練，這些資料集是透過模擬或簡單的實驗產生，其中螢光團表面輪廓大多是平坦的；因此，DL 模型通常無法在具有複雜表面輪廓的樣品上表現良好，例如離體器官或活體完整動物。在此，我們介紹一種使用最先進的 Differential Transformer 編碼器-解碼器架構的新 DL 架構，MFliNet (巨觀 FLI 網路)，它與 TPSF 一起採用 IRF 作為額外的輸入，解決光子抵達時間分佈的差異。我們透過精心設計的複雜組織模擬體和臨床前活體癌異種移植實驗，展示模型的效能。

##### **Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**
2411.16872v1 by Margaret Capetz, Swati Sharma, Rafael Padilha, Peder Olsen, Emre Kiciman, Ranveer Chandra

Mitigating climate change requires transforming agriculture to minimize
environ mental impact and build climate resilience. Regenerative agricultural
practices enhance soil organic carbon (SOC) levels, thus improving soil health
and sequestering carbon. A challenge to increasing regenerative agriculture
practices is cheaply measuring SOC over time and understanding how SOC is
affected by regenerative agricultural practices and other environmental factors
and farm management practices. To address this challenge, we introduce an
AI-driven Soil Organic Carbon Copilot that automates the ingestion of complex
multi-resolution, multi-modal data to provide large-scale insights into soil
health and regenerative practices. Our data includes extreme weather event data
(e.g., drought and wildfire incidents), farm management data (e.g., cropland
information and tillage predictions), and SOC predictions. We find that
integrating public data and specialized models enables large-scale, localized
analysis for sustainable agriculture. In comparisons of agricultural practices
across California counties, we find evidence that diverse agricultural activity
may mitigate the negative effects of tillage; and that while extreme weather
conditions heavily affect SOC, composting may mitigate SOC loss. Finally,
implementing role-specific personas empowers agronomists, farm consultants,
policymakers, and other stakeholders to implement evidence-based strategies
that promote sustainable agriculture and build climate resilience.

摘要：減緩氣候變遷需要轉型農業，以最大程度地減少環境影響並建立氣候韌性。再生農業實務增強土壤有機碳 (SOC) 含量，進而改善土壤健康並封存碳。擴大再生農業實務的一項挑戰是隨著時間推移廉價地測量 SOC，並了解 SOC 如何受到再生農業實務和其他環境因素以及農場管理實務的影響。為了應對這項挑戰，我們引進了 AI 驅動的土壤有機碳副駕駛，它自動彙整複雜的多解析度、多模態資料，以提供大規模的土壤健康和再生實務見解。我們的資料包括極端天氣事件資料（例如乾旱和野火事件）、農場管理資料（例如農田資訊和整地預測）以及 SOC 預測。我們發現整合公共資料和專門模型能針對永續農業進行大規模、在地化的分析。在加州各郡的農業實務比較中，我們發現證據顯示多樣化的農業活動可以減輕耕作的負面影響；而且極端天氣條件雖然會嚴重影響 SOC，但堆肥可以減輕 SOC 流失。最後，實施特定角色的化身賦能農藝師、農場顧問、政策制定者和其他利害關係人，以實施基於證據的策略，以促進永續農業並建立氣候韌性。

##### **Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering**
2411.16863v1 by Federico Cocchi, Nicholas Moratelli, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara

Multimodal LLMs (MLLMs) are the natural extension of large language models to
handle multimodal inputs, combining text and image data. They have recently
garnered attention due to their capability to address complex tasks involving
both modalities. However, their effectiveness is limited to the knowledge
acquired during training, which restricts their practical utility. In this
work, we introduce a novel method to enhance the adaptability of MLLMs by
integrating external knowledge sources. Our proposed model, Reflective LLaVA
(ReflectiVA), utilizes reflective tokens to dynamically determine the need for
external knowledge and predict the relevance of information retrieved from an
external database. Tokens are trained following a two-stage two-model training
recipe. This ultimately enables the MLLM to manage external knowledge while
preserving fluency and performance on tasks where external knowledge is not
needed. Through our experiments, we demonstrate the efficacy of ReflectiVA for
knowledge-based visual question answering, highlighting its superior
performance compared to existing methods. Source code and trained models are
publicly available at https://github.com/aimagelab/ReflectiVA.

摘要：多模態 LLM（MLLM）是大語言模型的自然延伸，用於處理多模態輸入，結合文字和影像資料。由於它們有能力處理涉及這兩種模態的複雜任務，因此最近備受關注。然而，它們的效能僅限於訓練期間獲得的知識，這限制了它們的實用性。在這項工作中，我們介紹了一種新方法，透過整合外部知識來源來增強 MLLM 的適應性。我們提出的模型 Reflective LLaVA（ReflectiVA）利用反射符號動態地確定對外部知識的需求，並預測從外部資料庫中檢索到的資訊相關性。符號是按照兩階段兩模型訓練配方進行訓練的。這最終使 MLLM 能夠管理外部知識，同時在不需要外部知識的任務中保持流暢性和效能。透過我們的實驗，我們展示了 ReflectiVA 在基於知識的視覺問題解答方面的效能，突顯了它與現有方法相比的優異效能。原始碼和訓練好的模型可以在 https://github.com/aimagelab/ReflectiVA 公共取得。

##### **Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**
2411.16679v1 by Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

We evaluate how well Large Language Models (LLMs) latently recall and compose
facts to answer multi-hop queries like "In the year Scarlett Johansson was
born, the Summer Olympics were hosted in the country of". One major challenge
in evaluating this ability is that LLMs may have developed shortcuts by
encounters of the head entity "Scarlett Johansson" and the answer entity
"United States" in the same training sequences or merely guess the answer based
on frequency-based priors. To prevent shortcuts, we exclude test queries where
the head and answer entities co-appear in pretraining corpora. Through careful
selection of relations and facts and systematic removal of cases where models
might guess answers or exploit partial matches, we construct an evaluation
dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs
demonstrate promising latent multi-hop reasoning abilities without exploiting
shortcuts, but only for certain types of queries. For queries requiring latent
recall of countries as the intermediate answer, the best models achieve 80%
latent composability, but this drops to just 5% for the recall of years.
Comparisons with Chain-of-Thought composability highlight a significant gap
between the ability of models to reason latently versus explicitly. Analysis
reveals that latent representations of the intermediate answer are constructed
more often in queries with higher latent composability, and shows the emergence
of latent multi-hop reasoning during pretraining.

摘要：我們評估大型語言模型 (LLM) 在潛在回憶和組合事實方面表現如何，以回答多重跳躍查詢，例如「史嘉蕾喬韓森出生的那一年，夏季奧運會在國家舉辦」。評估此能力的一項重大挑戰在於，LLM 可能透過在相同的訓練序列中遭遇頭部實體「史嘉蕾喬韓森」和答案實體「美國」而開發出捷徑，或僅根據基於頻率的先驗猜測答案。為了防止捷徑，我們排除了頭部和答案實體在預訓練語料庫中共同出現的測試查詢。透過仔細選擇關係和事實，並系統性地移除模型可能猜測答案或利用部分匹配的案例，我們建構了一個評估資料集 SOCRATES（ShOrtCut-fRee lATent rEaSoning）。我們觀察到，LLM 在不利用捷徑的情況下展現出潛在的多重跳躍推理能力，但僅限於特定類型的查詢。對於需要潛在回憶國家作為中間答案的查詢，最佳模型達到 80% 的潛在可組合性，但這對於回憶年份來說僅下降到 5%。與思考鏈可組合性的比較突顯了模型潛在推理與明確推理能力之間的顯著差距。分析顯示，在潛在可組合性較高的查詢中，中間答案的潛在表示更常被建構，並顯示在預訓練期間出現潛在的多重跳躍推理。

##### **Towards Precise Scaling Laws for Video Diffusion Transformers**
2411.17470v1 by Yuanyang Yin, Yaqi Zhao, Mingwu Zheng, Ke Lin, Jiarong Ou, Rui Chen, Victor Shea-Jay Huang, Jiahao Wang, Xin Tao, Pengfei Wan, Di Zhang, Baoqun Yin, Wentao Zhang, Kun Gai

Achieving optimal performance of video diffusion transformers within given
data and compute budget is crucial due to their high training costs. This
necessitates precisely determining the optimal model size and training
hyperparameters before large-scale training. While scaling laws are employed in
language models to predict performance, their existence and accurate derivation
in visual generation models remain underexplored. In this paper, we
systematically analyze scaling laws for video diffusion transformers and
confirm their presence. Moreover, we discover that, unlike language models,
video diffusion models are more sensitive to learning rate and batch size, two
hyperparameters often not precisely modeled. To address this, we propose a new
scaling law that predicts optimal hyperparameters for any model size and
compute budget. Under these optimal settings, we achieve comparable performance
and reduce inference costs by 40.1% compared to conventional scaling methods,
within a compute budget of 1e10 TFlops. Furthermore, we establish a more
generalized and precise relationship among validation loss, any model size, and
compute budget. This enables performance prediction for non-optimal model
sizes, which may also be appealed under practical inference cost constraints,
achieving a better trade-off.

摘要：由於視訊擴散Transformer的訓練成本高昂，因此在既定的資料和運算預算內，達成最佳效能至關重要。這需要在進行大規模訓練之前，精準地決定最佳模型大小和訓練超參數。雖然語言模型中採用了比例定律來預測效能，但視覺生成模型中比例定律的存在和精確推導仍未被充分探討。在本文中，我們系統性地分析了視訊擴散Transformer的比例定律，並確認了它們的存在。此外，我們發現與語言模型不同，視訊擴散模型對學習率和批次大小更敏感，這兩個超參數通常沒有精確建模。為了解決這個問題，我們提出了一個新的比例定律，可以預測任何模型大小和運算預算的最佳超參數。在這些最佳設定下，我們達到了可比較的效能，並在 1e10 TFlops 的運算預算內，將推論成本降低了 40.1%，優於傳統的比例定律方法。此外，我們建立了驗證損失、任何模型大小和運算預算之間更廣泛且精確的關係。這使得可以預測非最佳模型大小的效能，在實際的推論成本限制下，這也可能受到青睞，從而實現更好的權衡。

##### **Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing**
2411.16832v1 by Hanhui Wang, Yihua Zhang, Ruizheng Bai, Yue Zhao, Sijia Liu, Zhengzhong Tu

Recent advancements in diffusion models have made generative image editing
more accessible, enabling creative edits but raising ethical concerns,
particularly regarding malicious edits to human portraits that threaten privacy
and identity security. Existing protection methods primarily rely on
adversarial perturbations to nullify edits but often fail against diverse
editing requests. We propose FaceLock, a novel approach to portrait protection
that optimizes adversarial perturbations to destroy or significantly alter
biometric information, rendering edited outputs biometrically unrecognizable.
FaceLock integrates facial recognition and visual perception into perturbation
optimization to provide robust protection against various editing attempts. We
also highlight flaws in commonly used evaluation metrics and reveal how they
can be manipulated, emphasizing the need for reliable assessments of
protection. Experiments show FaceLock outperforms baselines in defending
against malicious edits and is robust against purification techniques. Ablation
studies confirm its stability and broad applicability across diffusion-based
editing algorithms. Our work advances biometric defense and sets the foundation
for privacy-preserving practices in image editing. The code is available at:
https://github.com/taco-group/FaceLock.

摘要：擴散模型的最新進展使生成式影像編輯更易於使用，能進行具創意的編輯，但也引發了道德問題，特別是針對人像的惡意編輯，威脅到隱私和身分安全。現有的保護方法主要依賴對抗性擾動來消除編輯，但對於不同的編輯請求常常會失敗。我們提出 FaceLock，一種新穎的人像保護方法，可以最佳化對抗性擾動來破壞或顯著改變生物特徵資訊，使編輯後的輸出在生物特徵上無法辨識。FaceLock 將臉部辨識和視覺感知整合到擾動最佳化中，以提供對各種編輯嘗試的強大保護。我們也強調了常用評估指標的缺陷，並揭示它們如何被操縱，強調對保護進行可靠評估的必要性。實驗顯示，FaceLock 在防禦惡意編輯方面優於基準，並且對淨化技術具有魯棒性。消融研究證實了其穩定性和在基於擴散的編輯演算法中的廣泛適用性。我們的研究推動了生物特徵防禦，並為影像編輯中的隱私保護實務奠定了基礎。程式碼可在以下網址取得：https://github.com/taco-group/FaceLock。

##### **CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**
2411.16666v2 by Jiaan Han, Junxiao Chen, Yanzhe Fu

We introduce CatNet, an algorithm that effectively controls False Discovery
Rate (FDR) and selects significant features in LSTM with the Gaussian Mirror
(GM) method. To evaluate the feature importance of LSTM in time series, we
introduce a vector of the derivative of the SHapley Additive exPlanations
(SHAP) to measure feature importance. We also propose a new kernel-based
dependence measure to avoid multicollinearity in the GM algorithm, to make a
robust feature selection with controlled FDR. We use simulated data to evaluate
CatNet's performance in both linear models and LSTM models with different link
functions. The algorithm effectively controls the FDR while maintaining a high
statistical power in all cases. We also evaluate the algorithm's performance in
different low-dimensional and high-dimensional cases, demonstrating its
robustness in various input dimensions. To evaluate CatNet's performance in
real world applications, we construct a multi-factor investment portfolio to
forecast the prices of S\&P 500 index components. The results demonstrate that
our model achieves superior predictive accuracy compared to traditional LSTM
models without feature selection and FDR control. Additionally, CatNet
effectively captures common market-driving features, which helps informed
decision-making in financial markets by enhancing the interpretability of
predictions. Our study integrates of the Gaussian Mirror algorithm with LSTM
models for the first time, and introduces SHAP values as a new feature
importance metric for FDR control methods, marking a significant advancement in
feature selection and error control for neural networks.

摘要：<paragraph>我們引進 CatNet，一種有效控制假發現率 (FDR) 的演算法，並利用高斯鏡像 (GM) 方法在 LSTM 中選取顯著特徵。為了評估 LSTM 在時間序列中的特徵重要性，我們引進 SHapley 加成解釋 (SHAP) 的導數向量來衡量特徵重要性。我們也提出一個新的基於核心的依賴度量，以避免 GM 演算法中的多重共線性，並在受控 FDR 中進行穩健的特徵選取。我們使用模擬資料來評估 CatNet 在線性模型和具有不同連結函數的 LSTM 模型中的效能。該演算法在所有情況下都能有效控制 FDR，同時維持高統計效能。我們也評估該演算法在不同低維和高維情況下的效能，證明了它在各種輸入維度中的穩健性。為了評估 CatNet 在實際應用中的效能，我們建構了一個多因子投資組合，以預測 S&P 500 指數成分的價格。結果證明，與沒有特徵選取和 FDR 控制的傳統 LSTM 模型相比，我們的模型達到了更高的預測準確度。此外，CatNet 有效地捕捉了共同的市場驅動特徵，這有助於透過增強預測的可解釋性，在金融市場中做出明智的決策。我們的研究首次整合了高斯鏡像演算法與 LSTM 模型，並將 SHAP 值作為 FDR 控制方法的新特徵重要性指標，這標誌著神經網路特徵選取和錯誤控制的重大進展。</paragraph>

##### **DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**
2411.16657v1 by Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal

Storytelling video generation (SVG) has recently emerged as a task to create
long, multi-motion, multi-scene videos that consistently represent the story
described in the input text script. SVG holds great potential for diverse
content creation in media and entertainment; however, it also presents
significant challenges: (1) objects must exhibit a range of fine-grained,
complex motions, (2) multiple objects need to appear consistently across
scenes, and (3) subjects may require multiple motions with seamless transitions
within a single scene. To address these challenges, we propose DreamRunner, a
novel story-to-video generation method: First, we structure the input script
using a large language model (LLM) to facilitate both coarse-grained scene
planning as well as fine-grained object-level layout and motion planning. Next,
DreamRunner presents retrieval-augmented test-time adaptation to capture target
motion priors for objects in each scene, supporting diverse motion
customization based on retrieved videos, thus facilitating the generation of
new videos with complex, scripted motions. Lastly, we propose a novel
spatial-temporal region-based 3D attention and prior injection module SR3AI for
fine-grained object-motion binding and frame-by-frame semantic control. We
compare DreamRunner with various SVG baselines, demonstrating state-of-the-art
performance in character consistency, text alignment, and smooth transitions.
Additionally, DreamRunner exhibits strong fine-grained condition-following
ability in compositional text-to-video generation, significantly outperforming
baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to
generate multi-object interactions with qualitative examples.

摘要：故事敘述影片生成 (SVG) 最近成為了產生長篇、多動作、多場景影片的任務，這些影片能持續呈現輸入文字腳本中所描述的故事。SVG 在媒體和娛樂中擁有廣泛的內容創造潛力；然而，它也帶來了重大的挑戰：(1) 物件必須展現一系列細緻、複雜的動作，(2) 多個物件需要在場景中持續出現，(3) 主題可能需要在單一場景中進行多個動作，並進行無縫轉換。為了應對這些挑戰，我們提出了 DreamRunner，一種新穎的故事到影片生成方法：首先，我們使用大型語言模型 (LLM) 來建構輸入腳本，以促進粗略的場景規劃以及細緻的物件級別佈局和動作規劃。接下來，DreamRunner 提出檢索增強的測試時間適應，以擷取每個場景中物件的目標動作先驗，支援基於檢索影片的多樣化動作自訂，從而促進產生具有複雜、腳本動作的新影片。最後，我們提出了一個新穎的基於時空區域的 3D 注意力和先驗注入模組 SR3AI，用於細緻的物件動作繫結和逐幀語義控制。我們將 DreamRunner 與各種 SVG 基準進行比較，證明了其在角色一致性、文字對齊和流暢過渡方面的最先進效能。此外，DreamRunner 在組合式文字到影片生成中展現出強大的細緻條件遵循能力，在 T2V-ComBench 上明顯優於基準。最後，我們驗證了 DreamRunner 產生多物件互動的強大能力，並提供了定性範例。

##### **Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge**
2411.16824v1 by Yaqi Zhao, Yuanyang Yin, Lin Li, Mingan Lin, Victor Shea-Jay Huang, Siwei Chen, Weipeng Chen, Baoqun Yin, Zenan Zhou, Wentao Zhang

Does seeing always mean knowing? Large Vision-Language Models (LVLMs)
integrate separately pre-trained vision and language components, often using
CLIP-ViT as vision backbone. However, these models frequently encounter a core
issue of "cognitive misalignment" between the vision encoder (VE) and the large
language model (LLM). Specifically, the VE's representation of visual
information may not fully align with LLM's cognitive framework, leading to a
mismatch where visual features exceed the language model's interpretive range.
To address this, we investigate how variations in VE representations influence
LVLM comprehension, especially when the LLM faces VE-Unknown data-images whose
ambiguous visual representations challenge the VE's interpretive precision.
Accordingly, we construct a multi-granularity landmark dataset and
systematically examine the impact of VE-Known and VE-Unknown data on
interpretive abilities. Our results show that VE-Unknown data limits LVLM's
capacity for accurate understanding, while VE-Known data, rich in distinctive
features, helps reduce cognitive misalignment. Building on these insights, we
propose Entity-Enhanced Cognitive Alignment (EECA), a method that employs
multi-granularity supervision to generate visually enriched, well-aligned
tokens that not only integrate within the LLM's embedding space but also align
with the LLM's cognitive framework. This alignment markedly enhances LVLM
performance in landmark recognition. Our findings underscore the challenges
posed by VE-Unknown data and highlight the essential role of cognitive
alignment in advancing multimodal systems.

摘要：<paragraph>看到就一定知道嗎？大型視覺語言模型 (LVLMs)
整合了單獨預先訓練好的視覺和語言組件，通常使用
CLIP-ViT 作為視覺主幹。然而，這些模型經常遇到一個核心
問題，即視覺編碼器 (VE) 和大型語言模型 (LLM) 之間的「認知失調」。具體來說，VE 對視覺
資訊的表示可能無法完全與 LLM 的認知架構對齊，導致視覺特徵超出語言模型的詮釋範圍，從而產生失配。
為了解決這個問題，我們探討 VE 表示的變化如何影響
LVLM 的理解，特別是在 LLM 面對 VE-Unknown 數據時，其模稜兩可的視覺表示挑戰了 VE 的詮釋精確度。
因此，我們構建了一個多粒度的標誌性數據集，並
系統地檢驗 VE-Known 和 VE-Unknown 數據對詮釋能力的影響。我們的結果表明，VE-Unknown 數據限制了 LVLM 準確理解的能力，而 VE-Known 數據富含獨特特徵，有助於減少認知失調。基於這些見解，我們
提出了實體增強認知對齊 (EECA)，這是一種使用多粒度監督來生成視覺豐富、對齊良好的
標記的方法，這些標記不僅整合在 LLM 的嵌入空間中，而且還與 LLM 的認知架構對齊。這種對齊顯著增強了 LVLM
在標誌性識別中的性能。我們的發現強調了 VE-Unknown 數據帶來的挑戰，並突出了認知
對齊在推進多模態系統中發揮的重要作用。</paragraph>

##### **Self-Generated Critiques Boost Reward Modeling for Language Models**
2411.16646v1 by Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou

Reward modeling is crucial for aligning large language models (LLMs) with
human preferences, especially in reinforcement learning from human feedback
(RLHF). However, current reward models mainly produce scalar scores and
struggle to incorporate critiques in a natural language format. We hypothesize
that predicting both critiques and the scalar reward would improve reward
modeling ability. Motivated by this, we propose Critic-RM, a framework that
improves reward models using self-generated critiques without extra
supervision. Critic-RM employs a two-stage process: generating and filtering
high-quality critiques, followed by joint fine-tuning on reward prediction and
critique generation. Experiments across benchmarks show that Critic-RM improves
reward modeling accuracy by 3.7%-7.3% compared to standard reward models and
LLM judges, demonstrating strong performance and data efficiency. Additional
studies further validate the effectiveness of generated critiques in rectifying
flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.

摘要：獎勵建模對於將大型語言模型 (LLM) 與人類偏好保持一致至關重要，特別是在人類回饋的強化學習 (RLHF) 中。然而，目前的獎勵模型主要產生標量分數，並且難以以自然語言格式納入批評。我們假設預測批評和標量獎勵都會提高獎勵建模能力。基於此，我們提出了 Critic-RM，這是一個利用自我生成的批評來改進獎勵模型的框架，而無需額外的監督。Critic-RM 採用兩階段流程：生成和過濾高品質的批評，然後在獎勵預測和批評生成上進行聯合微調。基準測試的實驗表明，與標準獎勵模型和 LLM 評審相比，Critic-RM 將獎勵建模準確度提高了 3.7%-7.3%，展示了強大的性能和數據效率。進一步的研究進一步驗證了生成的批評在糾正有缺陷的推理步驟中的有效性，推理準確度提高了 2.5%-3.2%。

##### **Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**
2411.16645v1 by Dietmar Jannach, Alan Said, Marko Tkalčič, Markus Zanker

In the area of recommender systems, the vast majority of research efforts is
spent on developing increasingly sophisticated recommendation models, also
using increasingly more computational resources. Unfortunately, most of these
research efforts target a very small set of application domains, mostly
e-commerce and media recommendation. Furthermore, many of these models are
never evaluated with users, let alone put into practice. The scientific,
economic and societal value of much of these efforts by scholars therefore
remains largely unclear. To achieve a stronger positive impact resulting from
these efforts, we posit that we as a research community should more often
address use cases where recommender systems contribute to societal good
(RS4Good). In this opinion piece, we first discuss a number of examples where
the use of recommender systems for problems of societal concern has been
successfully explored in the literature. We then proceed by outlining a
paradigmatic shift that is needed to conduct successful RS4Good research, where
the key ingredients are interdisciplinary collaborations and longitudinal
evaluation approaches with humans in the loop.

摘要：在推薦系統領域，絕大多數的研究工作都花在開發日益精密的推薦模型，同時也使用越來越多運算資源。不幸的是，這些研究工作大多針對非常小的一組應用領域，主要是電子商務和媒體推薦。此外，這些模型中的許多模型從未經過使用者評估，更不用說付諸實踐了。因此，學者們在這些工作上的科學、經濟和社會價值在很大程度上仍不清楚。為了讓這些工作產生更強大的正面影響，我們認為我們作為一個研究社群應該更常解決推薦系統對社會有益的用例（RS4Good）。在這篇意見文章中，我們首先討論了一些範例，其中在文獻中已成功探索了將推薦系統用於社會關注的問題。然後，我們接著概述進行成功的 RS4Good 研究所需的典範轉移，其中關鍵要素是跨領域合作和人類參與的縱向評估方法。

##### **Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**
2411.16642v1 by Jean Marie Tshimula, Xavier Ndona, D'Jeff K. Nkashama, Pierre-Martin Tardif, Froduald Kabanza, Marc Frappier, Shengrui Wang

Jailbreak prompts pose a significant threat in AI and cybersecurity, as they
are crafted to bypass ethical safeguards in large language models, potentially
enabling misuse by cybercriminals. This paper analyzes jailbreak prompts from a
cyber defense perspective, exploring techniques like prompt injection and
context manipulation that allow harmful content generation, content filter
evasion, and sensitive information extraction. We assess the impact of
successful jailbreaks, from misinformation and automated social engineering to
hazardous content creation, including bioweapons and explosives. To address
these threats, we propose strategies involving advanced prompt analysis,
dynamic safety protocols, and continuous model fine-tuning to strengthen AI
resilience. Additionally, we highlight the need for collaboration among AI
researchers, cybersecurity experts, and policymakers to set standards for
protecting AI systems. Through case studies, we illustrate these cyber defense
approaches, promoting responsible AI practices to maintain system integrity and
public trust. \textbf{\color{red}Warning: This paper contains content which the
reader may find offensive.}

摘要：越獄提示在 AI 和網路安全領域中構成重大威脅，因為它們被設計成繞過大型語言模型中的道德防護措施，這可能會讓網路犯罪分子得以濫用。本文從網路防禦角度分析越獄提示，探討提示注入和內容操縱等技術，這些技術允許產生有害內容、規避內容過濾器和提取敏感資訊。我們評估成功越獄的影響，從錯誤資訊和自動化社會工程到危險內容的建立，包括生物武器和炸藥。為了應對這些威脅，我們提出涉及進階提示分析、動態安全協定和持續模型微調的策略，以強化 AI 的韌性。此外，我們強調 AI 研究人員、網路安全專家和政策制定者之間需要合作，以制定保護 AI 系統的標準。透過案例研究，我們說明這些網路防禦方法，推廣負責任的 AI 實務，以維護系統完整性和公眾信任。\textbf{\color{red}警告：本文包含讀者可能覺得令人反感的內容。}

##### **Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**
2411.16638v2 by Sanjana Ramprasad, Byron C. Wallace

Modern LLMs can now produce highly readable abstractive summaries, to the
point where traditional automated metrics for evaluating summary quality, such
as ROUGE, have become saturated. However, LLMs still sometimes introduce
unwanted content into summaries, i.e., information inconsistent with or
unsupported by their source. Measuring the occurrence of these often subtle
``hallucinations'' automatically has proved to be challenging. This in turn has
motivated development of a variety of metrics intended to measure the factual
consistency of generated summaries against their source. But are these
approaches measuring what they purport to do? In this work, we stress-test
automatic factuality metrics. Specifically, we investigate whether and to what
degree superficial attributes of summary texts suffice to predict
``factuality'', finding that a (supervised) model using only such shallow
features is reasonably competitive with SOTA factuality scoring methods. We
then evaluate how factuality metrics respond to factual corrections in
inconsistent summaries and find that only a few show meaningful improvements.
In contrast, some metrics are more sensitive to benign, non-factual edits.
Motivated by these insights, we show that one can ``game'' (most) automatic
factuality metrics, i.e., reliably inflate ``factuality'' scores by appending
innocuous sentences to generated summaries.Taken together, our results raise
questions about the degree to which we should rely on existing automated
factuality metrics and what exactly we want ``factuality metrics'' to measure.

摘要：現代 LLM 現在可以產生高度可讀的抽象摘要，以至於用於評估摘要品質的傳統自動化指標，例如 ROUGE，已經飽和。然而，LLM 有時仍會在摘要中引入不必要的內容，也就是與其來源不一致或不受其來源支持的資訊。自動測量這些通常很微妙的「幻覺」的發生已被證明具有挑戰性。這反過來又促使開發各種指標，旨在衡量所產生摘要與其來源的事實一致性。但這些方法是否測量了它們聲稱要做的？在這項工作中，我們對自動真實性指標進行壓力測試。具體來說，我們調查摘要文字的表面屬性是否足夠預測「真實性」，以及在多大程度上，發現僅使用這種淺層特徵的（監督）模型與 SOTA 真實性評分方法具有合理的競爭力。然後我們評估真實性指標如何對不一致摘要中的事實更正做出回應，並發現只有少數顯示出有意義的改進。相反，有些指標對良性的、非事實的編輯更敏感。受這些見解的啟發，我們表明可以「玩弄」大多數自動真實性指標，也就是說，透過在產生的摘要中附加無害的句子來可靠地提高「真實性」評分。綜合起來，我們的結果引發了關於我們應在多大程度上依賴現有的自動真實性指標，以及我們究竟希望「真實性指標」測量什麼的問題。

##### **Imperceptible Adversarial Examples in the Physical World**
2411.16622v1 by Weilin Xu, Sebastian Szyller, Cory Cornelius, Luis Murillo Rojas, Marius Arvinte, Alvaro Velasquez, Jason Martin, Nageen Himayat

Adversarial examples in the digital domain against deep learning-based
computer vision models allow for perturbations that are imperceptible to human
eyes. However, producing similar adversarial examples in the physical world has
been difficult due to the non-differentiable image distortion functions in
visual sensing systems. The existing algorithms for generating physically
realizable adversarial examples often loosen their definition of adversarial
examples by allowing unbounded perturbations, resulting in obvious or even
strange visual patterns. In this work, we make adversarial examples
imperceptible in the physical world using a straight-through estimator (STE,
a.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying
exact, non-differentiable distortions in the forward pass of the
backpropagation step, and using the identity function in the backward pass. Our
differentiable rendering extension to STE also enables imperceptible
adversarial patches in the physical world. Using printout photos, and
experiments in the CARLA simulator, we show that STE enables fast generation of
$\ell_\infty$ bounded adversarial examples despite the non-differentiable
distortions. To the best of our knowledge, this is the first work demonstrating
imperceptible adversarial examples bounded by small $\ell_\infty$ norms in the
physical world that force zero classification accuracy in the global
perturbation threat model and cause near-zero ($4.22\%$) AP50 in object
detection in the patch perturbation threat model. We urge the community to
re-evaluate the threat of adversarial examples in the physical world.

摘要：<paragraph>針對基於深度學習的電腦視覺模型的數位領域對抗範例允許人眼無法察覺的擾動。然而，由於視覺感測系統中不可微分的影像失真函數，在物理世界中產生類似的對抗範例一直很困難。現有的演算法用於產生物理上可實現的對抗範例，通常透過允許無界的擾動來放寬對抗範例的定義，導致明顯甚至奇怪的視覺模式。在這項工作中，我們使用直通估計器 (STE，又稱 BPDA) 在物理世界中製作無法察覺的對抗範例。我們採用 STE 來克服不可微分性，在反向傳播步驟的前向傳遞中應用精確的不可微分失真，並在反向傳遞中使用恆等函數。我們對 STE 的可微分渲染延伸也讓物理世界中的對抗性貼片無法察覺。透過列印照片，以及在 CARLA 模擬器中的實驗，我們展示了 STE 能夠快速產生 $\ell_\infty$ 有界對抗範例，儘管有不可微分的失真。據我們所知，這是第一個在物理世界中展示由小 $\ell_\infty$ 規格限制的無法察覺對抗範例的工作，在全域擾動威脅模型中強制零分類準確度，並在貼片擾動威脅模型中導致接近零 ($4.22\%$) 的 AP50 物件偵測。我們敦促社群重新評估物理世界中對抗範例的威脅。</paragraph>

##### **StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**
2411.16618v1 by Kaustubh Ponkshe, Venkatapathy Subramanian, Natwar Modani, Ganesh Ramakrishnan

Most state-of-the-art techniques for Language Models (LMs) today rely on
transformer-based architectures and their ubiquitous attention mechanism.
However, the exponential growth in computational requirements with longer input
sequences confines Transformers to handling short passages. Recent efforts have
aimed to address this limitation by introducing selective attention mechanisms,
notably local and global attention. While sparse attention mechanisms, akin to
full attention in being Turing-complete, have been theoretically established,
their practical impact on pre-training remains unexplored. This study focuses
on empirically assessing the influence of global attention on BERT
pre-training. The primary steps involve creating an extensive corpus of
structure-aware text through arXiv data, alongside a text-only counterpart. We
carry out pre-training on these two datasets, investigate shifts in attention
patterns, and assess their implications for downstream tasks. Our analysis
underscores the significance of incorporating document structure into LM
models, demonstrating their capacity to excel in more abstract tasks, such as
document understanding.

摘要：現今多數語言模型 (LM) 的最先進技術仰賴於基於轉換器的架構及其普遍的注意力機制。
然而，隨著輸入序列變長，運算需求呈指數成長，將轉換器限制在處理短篇章節。最近的努力旨在透過引入選擇性注意力機制來解決此限制，特別是局部和全局注意力。雖然稀疏注意力機制類似於在圖靈完備性中的完整注意力，已在理論上建立，但其對預訓練的實際影響仍未探討。本研究專注於經驗評估全局注意力對 BERT 預訓練的影響。主要步驟包括透過 arXiv 資料建立廣泛的結構感知文字語料庫，以及純文字對應版本。我們對這兩個資料集進行預訓練，探討注意力模式的轉變，並評估其對下游任務的影響。我們的分析強調將文件結構納入 LM 模型的重要性，證明其在更抽象任務（例如文件理解）中表現優異的能力。

##### **Recent Trends in Linear Text Segmentation: a Survey**
2411.16613v1 by Iacopo Ghinassi, Lin Wang, Chris Newell, Matthew Purver

Linear Text Segmentation is the task of automatically tagging text documents
with topic shifts, i.e. the places in the text where the topics change. A
well-established area of research in Natural Language Processing, drawing from
well-understood concepts in linguistic and computational linguistic research,
the field has recently seen a lot of interest as a result of the surge of text,
video, and audio available on the web, which in turn require ways of
summarising and categorizing the mole of content for which linear text
segmentation is a fundamental step. In this survey, we provide an extensive
overview of current advances in linear text segmentation, describing the state
of the art in terms of resources and approaches for the task. Finally, we
highlight the limitations of available resources and of the task itself, while
indicating ways forward based on the most recent literature and under-explored
research directions.

摘要：線性文本分段是自動標記文本文件
主題轉換，即文本中主題變更的地方。自然語言處理中一個建立良好的研究領域，汲取
語言學和計算語言學研究中理解良好的概念，該領域最近因網路上大量湧現的文字、
影片和音訊而備受關注，而這些內容需要總結和分類，而線性文本分段正是基本步驟。在這項調查中，我們提供線性文本分段當前進展的廣泛概述，說明任務在資源和方法方面的最新進展。最後，我們強調可用資源和任務本身的限制，同時根據最新文獻和尚未探索的研究方向指出前進的方向。

