{"2405.03004": {"publish_time": "2024-05-05", "title": "Exploring prompts to elicit memorization in masked language model-based named entity recognition", "paper_summary": "Training data memorization in language models impacts model capability\n(generalization) and safety (privacy risk). This paper focuses on analyzing\nprompts' impact on detecting the memorization of 6 masked language model-based\nnamed entity recognition models. Specifically, we employ a diverse set of 400\nautomatically generated prompts, and a pairwise dataset where each pair\nconsists of one person's name from the training set and another name out of the\nset. A prompt completed with a person's name serves as input for getting the\nmodel's confidence in predicting this name. Finally, the prompt performance of\ndetecting model memorization is quantified by the percentage of name pairs for\nwhich the model has higher confidence for the name from the training set. We\nshow that the performance of different prompts varies by as much as 16\npercentage points on the same model, and prompt engineering further increases\nthe gap. Moreover, our experiments demonstrate that prompt performance is\nmodel-dependent but does generalize across different name sets. A comprehensive\nanalysis indicates how prompt performance is influenced by prompt properties,\ncontained tokens, and the model's self-attention weights on the prompt.", "paper_summary_zh": "", "author": "Yuxi Xia et.al.", "authors": "Yuxi Xia,Anastasiia Sedova,Pedro Henrique Luz de Araujo,Vasiliki Kougia,Lisa Nu\u00dfbaumer,Benjamin Roth", "id": "2405.03004v1", "paper_url": "http://arxiv.org/abs/2405.03004v1", "repo": "null"}}