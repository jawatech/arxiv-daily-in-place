{"2410.12761": {"publish_time": "2024-10-16", "title": "SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation", "paper_summary": "Recent advances in diffusion models have significantly enhanced their ability\nto generate high-quality images and videos, but they have also increased the\nrisk of producing unsafe content. Existing unlearning/editing-based methods for\nsafe generation remove harmful concepts from models but face several\nchallenges: (1) They cannot instantly remove harmful concepts without training.\n(2) Their safe generation capabilities depend on collected training data. (3)\nThey alter model weights, risking degradation in quality for content unrelated\nto toxic concepts. To address these, we propose SAFREE, a novel, training-free\napproach for safe T2I and T2V, that does not alter the model's weights.\nSpecifically, we detect a subspace corresponding to a set of toxic concepts in\nthe text embedding space and steer prompt embeddings away from this subspace,\nthereby filtering out harmful content while preserving intended semantics. To\nbalance the trade-off between filtering toxicity and preserving safe concepts,\nSAFREE incorporates a novel self-validating filtering mechanism that\ndynamically adjusts the denoising steps when applying the filtered embeddings.\nAdditionally, we incorporate adaptive re-attention mechanisms within the\ndiffusion latent space to selectively diminish the influence of features\nrelated to toxic concepts at the pixel level. In the end, SAFREE ensures\ncoherent safety checking, preserving the fidelity, quality, and safety of the\noutput. SAFREE achieves SOTA performance in suppressing unsafe content in T2I\ngeneration compared to training-free baselines and effectively filters targeted\nconcepts while maintaining high-quality images. It also shows competitive\nresults against training-based methods. We extend SAFREE to various T2I\nbackbones and T2V tasks, showcasing its flexibility and generalization. SAFREE\nprovides a robust and adaptable safeguard for ensuring safe visual generation.", "paper_summary_zh": "\u6700\u8fd1\u64f4\u6563\u6a21\u578b\u7684\u9032\u5c55\u986f\u8457\u63d0\u5347\u4e86\u5b83\u5011\u751f\u6210\u9ad8\u54c1\u8cea\u5f71\u50cf\u548c\u5f71\u7247\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4e5f\u589e\u52a0\u4e86\u7522\u751f\u4e0d\u5b89\u5168\u5167\u5bb9\u7684\u98a8\u96aa\u3002\u73fe\u6709\u7684\u57fa\u65bc\u907a\u5fd8/\u7de8\u8f2f\u7684\u65b9\u6cd5\u7528\u65bc\u5b89\u5168\u751f\u6210\uff0c\u6703\u5f9e\u6a21\u578b\u4e2d\u79fb\u9664\u6709\u5bb3\u7684\u6982\u5ff5\uff0c\u4f46\u9762\u81e8\u5e7e\u500b\u6311\u6230\uff1a(1) \u5b83\u5011\u7121\u6cd5\u5728\u6c92\u6709\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u7acb\u5373\u79fb\u9664\u6709\u5bb3\u6982\u5ff5\u3002(2) \u5b83\u5011\u7684\u5b89\u5168\u751f\u6210\u80fd\u529b\u53d6\u6c7a\u65bc\u6536\u96c6\u5230\u7684\u8a13\u7df4\u8cc7\u6599\u3002(3) \u5b83\u5011\u6703\u6539\u8b8a\u6a21\u578b\u6b0a\u91cd\uff0c\u5192\u8457\u8207\u6709\u6bd2\u6982\u5ff5\u7121\u95dc\u7684\u5167\u5bb9\u54c1\u8cea\u4e0b\u964d\u7684\u98a8\u96aa\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa SAFREE\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u3001\u514d\u8a13\u7df4\u7684\u5b89\u5168 T2I \u548c T2V \u65b9\u6cd5\uff0c\u4e0d\u6703\u6539\u8b8a\u6a21\u578b\u7684\u6b0a\u91cd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5728\u6587\u5b57\u5d4c\u5165\u7a7a\u9593\u4e2d\u5075\u6e2c\u4e00\u500b\u5c0d\u61c9\u65bc\u4e00\u7d44\u6709\u6bd2\u6982\u5ff5\u7684\u5b50\u7a7a\u9593\uff0c\u4e26\u5f15\u5c0e\u63d0\u793a\u5d4c\u5165\u9060\u96e2\u9019\u500b\u5b50\u7a7a\u9593\uff0c\u5f9e\u800c\u904e\u6ffe\u6389\u6709\u5bb3\u5167\u5bb9\uff0c\u540c\u6642\u4fdd\u7559\u9810\u671f\u7684\u8a9e\u7fa9\u3002\u70ba\u4e86\u5e73\u8861\u904e\u6ffe\u6bd2\u6027\u548c\u4fdd\u7559\u5b89\u5168\u6982\u5ff5\u4e4b\u9593\u7684\u53d6\u6368\uff0cSAFREE \u7d50\u5408\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u81ea\u9a57\u8b49\u904e\u6ffe\u6a5f\u5236\uff0c\u5728\u61c9\u7528\u904e\u6ffe\u5d4c\u5165\u6642\u52d5\u614b\u8abf\u6574\u53bb\u566a\u6b65\u9a5f\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u64f4\u6563\u6f5b\u5728\u7a7a\u9593\u4e2d\u7d50\u5408\u4e86\u81ea\u9069\u61c9\u91cd\u65b0\u6ce8\u610f\u6a5f\u5236\uff0c\u4ee5\u9078\u64c7\u6027\u5730\u6e1b\u5f31\u8207\u50cf\u7d20\u7d1a\u5225\u7684\u6709\u6bd2\u6982\u5ff5\u76f8\u95dc\u7279\u5fb5\u7684\u5f71\u97ff\u3002\u6700\u5f8c\uff0cSAFREE \u78ba\u4fdd\u4e86\u4e00\u81f4\u7684\u5b89\u5168\u6aa2\u67e5\uff0c\u4fdd\u7559\u4e86\u8f38\u51fa\u7684\u4fdd\u771f\u5ea6\u3001\u54c1\u8cea\u548c\u5b89\u5168\u6027\u3002\u8207\u514d\u8a13\u7df4\u57fa\u7dda\u76f8\u6bd4\uff0cSAFREE \u5728\u6291\u5236 T2I \u751f\u6210\u4e2d\u7684\u4e0d\u5b89\u5168\u5167\u5bb9\u65b9\u9762\u5be6\u73fe\u4e86 SOTA \u6548\u80fd\uff0c\u4e26\u6709\u6548\u904e\u6ffe\u76ee\u6a19\u6982\u5ff5\uff0c\u540c\u6642\u4fdd\u6301\u9ad8\u54c1\u8cea\u7684\u5f71\u50cf\u3002\u5b83\u4e5f\u986f\u793a\u51fa\u8207\u57fa\u65bc\u8a13\u7df4\u7684\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002\u6211\u5011\u5c07 SAFREE \u5ef6\u4f38\u5230\u5404\u7a2e T2I \u4e3b\u5e79\u548c T2V \u4efb\u52d9\uff0c\u5c55\u793a\u4e86\u5b83\u7684\u9748\u6d3b\u6027\u8207\u6cdb\u5316\u6027\u3002SAFREE \u70ba\u78ba\u4fdd\u5b89\u5168\u7684\u8996\u89ba\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u500b\u5f37\u5065\u4e14\u9069\u61c9\u6027\u5f37\u7684\u4fdd\u969c\u3002", "author": "Jaehong Yoon et.al.", "authors": "Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal", "id": "2410.12761v1", "paper_url": "http://arxiv.org/abs/2410.12761v1", "repo": "null"}}