
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-05**|**Seeing World Dynamics in a Nutshell**|Qiuhong Shen et.al.|[2502.03465v1](http://arxiv.org/abs/2502.03465v1)|null|
|**2025-02-05**|**Do Large Language Model Benchmarks Test Reliability?**|Joshua Vendrow et.al.|[2502.03461v1](http://arxiv.org/abs/2502.03461v1)|null|
|**2025-02-05**|**Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training**|Boyao Wang et.al.|[2502.03460v1](http://arxiv.org/abs/2502.03460v1)|null|
|**2025-02-05**|**A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**|Yiye Chen et.al.|[2502.03450v1](http://arxiv.org/abs/2502.03450v1)|null|
|**2025-02-05**|**Masked Autoencoders Are Effective Tokenizers for Diffusion Models**|Hao Chen et.al.|[2502.03444v1](http://arxiv.org/abs/2502.03444v1)|null|
|**2025-02-05**|**BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving**|Ran Xin et.al.|[2502.03438v1](http://arxiv.org/abs/2502.03438v1)|null|
|**2025-02-05**|**On Fairness of Unified Multimodal Large Language Model for Image Generation**|Ming Liu et.al.|[2502.03429v1](http://arxiv.org/abs/2502.03429v1)|null|
|**2025-02-05**|**TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer**|Zhihong Xu et.al.|[2502.03426v1](http://arxiv.org/abs/2502.03426v1)|null|
|**2025-02-05**|**Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts**|Nikta Gohari Sadr et.al.|[2502.03418v1](http://arxiv.org/abs/2502.03418v1)|null|
|**2025-02-05**|**SPRI: Aligning Large Language Models with Context-Situated Principles**|Hongli Zhan et.al.|[2502.03397v1](http://arxiv.org/abs/2502.03397v1)|null|
|**2025-02-05**|**Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**|Sarah Al-Shareeda et.al.|[2502.03396v1](http://arxiv.org/abs/2502.03396v1)|null|
|**2025-02-05**|**Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications**|Issar Arab et.al.|[2502.03395v1](http://arxiv.org/abs/2502.03395v1)|null|
|**2025-02-05**|**LIMO: Less is More for Reasoning**|Yixin Ye et.al.|[2502.03387v1](http://arxiv.org/abs/2502.03387v1)|null|
|**2025-02-05**|**High-Fidelity Simultaneous Speech-To-Speech Translation**|Tom Labiausse et.al.|[2502.03382v1](http://arxiv.org/abs/2502.03382v1)|null|
|**2025-02-05**|**Transformers and Their Roles as Time Series Foundation Models**|Dennis Wu et.al.|[2502.03383v1](http://arxiv.org/abs/2502.03383v1)|null|
|**2025-02-05**|**Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality**|Shiyi Tan et.al.|[2502.03381v1](http://arxiv.org/abs/2502.03381v1)|null|
|**2025-02-05**|**Demystifying Long Chain-of-Thought Reasoning in LLMs**|Edward Yeo et.al.|[2502.03373v1](http://arxiv.org/abs/2502.03373v1)|null|
|**2025-02-05**|**PalimpChat: Declarative and Interactive AI analytics**|Chunwei Liu et.al.|[2502.03368v1](http://arxiv.org/abs/2502.03368v1)|null|
|**2025-02-05**|**GHOST: Gaussian Hypothesis Open-Set Technique**|Ryan Rabinowitz et.al.|[2502.03359v1](http://arxiv.org/abs/2502.03359v1)|null|
|**2025-02-05**|**Minerva: A Programmable Memory Test Benchmark for Language Models**|Menglin Xia et.al.|[2502.03358v1](http://arxiv.org/abs/2502.03358v1)|null|
|**2025-02-05**|**Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies**|Harald Leisenberger et.al.|[2502.03341v1](http://arxiv.org/abs/2502.03341v1)|null|
|**2025-02-05**|**RadVLM: A Multitask Conversational Vision-Language Model for Radiology**|Nicolas Deperrois et.al.|[2502.03333v1](http://arxiv.org/abs/2502.03333v1)|null|
|**2025-02-05**|**Controllable GUI Exploration**|Aryan Garg et.al.|[2502.03330v1](http://arxiv.org/abs/2502.03330v1)|null|
|**2025-02-05**|**ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model**|Qiguang Chen et.al.|[2502.03325v1](http://arxiv.org/abs/2502.03325v1)|null|
|**2025-02-05**|**Out-of-Distribution Detection using Synthetic Data Generation**|Momin Abbas et.al.|[2502.03323v1](http://arxiv.org/abs/2502.03323v1)|null|
|**2025-02-05**|**Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques**|Sangjun Han et.al.|[2502.03321v1](http://arxiv.org/abs/2502.03321v1)|null|
|**2025-02-05**|**Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning**|Qitao Tan et.al.|[2502.03304v1](http://arxiv.org/abs/2502.03304v1)|null|
|**2025-02-05**|**MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**|Amin Dada et.al.|[2502.03298v1](http://arxiv.org/abs/2502.03298v1)|null|
|**2025-02-05**|**ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages**|Aida Halitaj et.al.|[2502.03292v1](http://arxiv.org/abs/2502.03292v1)|null|
|**2025-02-05**|**STEM: Spatial-Temporal Mapping Tool For Spiking Neural Networks**|Sherif Eissa et.al.|[2502.03287v1](http://arxiv.org/abs/2502.03287v1)|null|
|**2025-02-05**|**SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**|Ben Liu et.al.|[2502.03283v1](http://arxiv.org/abs/2502.03283v1)|null|
|**2025-02-05**|**Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning**|DiJia Su et.al.|[2502.03275v1](http://arxiv.org/abs/2502.03275v1)|null|
|**2025-02-05**|**Efficient extraction of medication information from clinical notes: an evaluation in two languages**|Thibaut Fabacher et.al.|[2502.03257v1](http://arxiv.org/abs/2502.03257v1)|null|
|**2025-02-05**|**How do Humans and Language Models Reason About Creativity? A Comparative Analysis**|Antonio Laverghetta Jr. et.al.|[2502.03253v1](http://arxiv.org/abs/2502.03253v1)|null|
|**2025-02-05**|**A scale of conceptual orality and literacy: Automatic text categorization in the tradition of "Nähe und Distanz"**|Volker Emmrich et.al.|[2502.03252v1](http://arxiv.org/abs/2502.03252v1)|null|
|**2025-02-05**|**The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective**|Guogang Zhu et.al.|[2502.03231v1](http://arxiv.org/abs/2502.03231v1)|null|
|**2025-02-05**|**Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform Perspective**|Napat Laosaengpha et.al.|[2502.03220v1](http://arxiv.org/abs/2502.03220v1)|null|
|**2025-02-05**|**iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs**|Julius Mayer et.al.|[2502.03214v1](http://arxiv.org/abs/2502.03214v1)|null|
|**2025-02-05**|**CORTEX: A Cost-Sensitive Rule and Tree Extraction Method**|Marija Kopanja et.al.|[2502.03200v1](http://arxiv.org/abs/2502.03200v1)|null|
|**2025-02-05**|**Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models**|Jialiang Wu et.al.|[2502.03199v1](http://arxiv.org/abs/2502.03199v1)|null|
|**2025-02-05**|**EuskañolDS: A Naturally Sourced Corpus for Basque-Spanish Code-Switching**|Maite Heredia et.al.|[2502.03188v1](http://arxiv.org/abs/2502.03188v1)|null|
|**2025-02-05**|**Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models**|Xumeng Wen et.al.|[2502.03147v1](http://arxiv.org/abs/2502.03147v1)|null|
|**2025-02-05**|**Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales**|Zhen Qian et.al.|[2502.03129v1](http://arxiv.org/abs/2502.03129v1)|null|
|**2025-02-05**|**Metis: A Foundation Speech Generation Model with Masked Generative Pre-training**|Yuancheng Wang et.al.|[2502.03128v1](http://arxiv.org/abs/2502.03128v1)|null|
|**2025-02-05**|**Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences**|Xingshen Zhang et.al.|[2502.03123v1](http://arxiv.org/abs/2502.03123v1)|null|
|**2025-02-05**|**At the Mahakumbh, Faith Met Tragedy: Computational Analysis of Stampede Patterns Using Machine Learning and NLP**|Abhinav Pratap et.al.|[2502.03120v1](http://arxiv.org/abs/2502.03120v1)|null|
|**2025-02-05**|**Tell2Reg: Establishing spatial correspondence between images by the same language prompts**|Wen Yan et.al.|[2502.03118v1](http://arxiv.org/abs/2502.03118v1)|null|
|**2025-02-05**|**Policies and Evaluation for Online Meeting Summarization**|Felix Schneider et.al.|[2502.03111v1](http://arxiv.org/abs/2502.03111v1)|null|
|**2025-02-05**|**Structured Token Retention and Computational Memory Paths in Large Language Models**|Jonathan Delena et.al.|[2502.03102v1](http://arxiv.org/abs/2502.03102v1)|null|
|**2025-02-05**|**E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing**|Yuhao Zhou et.al.|[2502.03092v1](http://arxiv.org/abs/2502.03092v1)|null|
|**2025-02-05**|**Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing**|Salvatore Sinno et.al.|[2502.03086v1](http://arxiv.org/abs/2502.03086v1)|null|
|**2025-02-05**|**IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates**|Aissatou Diallo et.al.|[2502.03080v1](http://arxiv.org/abs/2502.03080v1)|null|
|**2025-02-05**|**DOLFIN -- Document-Level Financial test set for Machine Translation**|Mariam Nakhlé et.al.|[2502.03053v1](http://arxiv.org/abs/2502.03053v1)|null|
|**2025-02-05**|**Kozax: Flexible and Scalable Genetic Programming in JAX**|Sigur de Vries et.al.|[2502.03047v1](http://arxiv.org/abs/2502.03047v1)|null|
|**2025-02-05**|**Knowledge Distillation from Large Language Models for Household Energy Modeling**|Mohannad Takrouri et.al.|[2502.03034v1](http://arxiv.org/abs/2502.03034v1)|null|
|**2025-02-05**|**Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**|Daniil Laptev et.al.|[2502.03032v1](http://arxiv.org/abs/2502.03032v1)|null|
|**2025-02-05**|**xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods**|Pratinav Seth et.al.|[2502.03014v1](http://arxiv.org/abs/2502.03014v1)|null|
|**2025-02-05**|**Scaling Laws for Upcycling Mixture-of-Experts Language Models**|Seng Pei Liew et.al.|[2502.03009v1](http://arxiv.org/abs/2502.03009v1)|null|
|**2025-02-05**|**MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**|Seonok Kim et.al.|[2502.03004v1](http://arxiv.org/abs/2502.03004v1)|null|
|**2025-02-05**|**Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons**|Renjun Hu et.al.|[2502.02988v1](http://arxiv.org/abs/2502.02988v1)|null|
|**2025-02-05**|**FedMobileAgent: Training Mobile Agents Using Decentralized Self-Sourced Data from Diverse Users**|Wenhao Wang et.al.|[2502.02982v1](http://arxiv.org/abs/2502.02982v1)|null|
|**2025-02-05**|**TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics**|Lu Yi et.al.|[2502.02975v1](http://arxiv.org/abs/2502.02975v1)|null|
|**2025-02-05**|**FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for Enabling Fair LLM-Based Recommender Systems**|Arya Fayyazi et.al.|[2502.02966v1](http://arxiv.org/abs/2502.02966v1)|null|
|**2025-02-05**|**(Neural-Symbolic) Machine Learning for Inconsistency Measurement**|Sven Weinzierl et.al.|[2502.02963v1](http://arxiv.org/abs/2502.02963v1)|null|
|**2025-02-05**|**Position: Editing Large Language Models Poses Serious Safety Risks**|Paul Youssef et.al.|[2502.02958v1](http://arxiv.org/abs/2502.02958v1)|null|
|**2025-02-05**|**LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction**|Ziwei Wang et.al.|[2502.02945v1](http://arxiv.org/abs/2502.02945v1)|null|
|**2025-02-05**|**LLaVAC: Fine-tuning LLaVA as a Multimodal Sentiment Classifier**|T. Chay-intr et.al.|[2502.02938v1](http://arxiv.org/abs/2502.02938v1)|null|
|**2025-02-05**|**Large Language Model Guided Self-Debugging Code Generation**|Muntasir Adnan et.al.|[2502.02928v1](http://arxiv.org/abs/2502.02928v1)|null|
|**2025-02-05**|**Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework**|Yuan Tian et.al.|[2502.02917v1](http://arxiv.org/abs/2502.02917v1)|null|
|**2025-02-05**|**MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations**|Namwoo Kim et.al.|[2502.02912v1](http://arxiv.org/abs/2502.02912v1)|null|
|**2025-02-05**|**SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs**|Dinithi Jayasuriya et.al.|[2502.02909v1](http://arxiv.org/abs/2502.02909v1)|null|
|**2025-02-05**|**ScholaWrite: A Dataset of End-to-End Scholarly Writing Process**|Linghe Wang et.al.|[2502.02904v1](http://arxiv.org/abs/2502.02904v1)|null|
|**2025-02-05**|**What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization**|Sahil Manchanda et.al.|[2502.02903v1](http://arxiv.org/abs/2502.02903v1)|null|
|**2025-02-05**|**Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO**|Christine Konicki et.al.|[2502.02901v1](http://arxiv.org/abs/2502.02901v1)|null|
|**2025-02-05**|**A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**|Bradley P. Allen et.al.|[2502.02896v1](http://arxiv.org/abs/2502.02896v1)|null|
|**2025-02-05**|**Lowering the Barrier of Machine Learning: Achieving Zero Manual Labeling in Review Classification Using LLMs**|Yejian Zhang et.al.|[2502.02893v1](http://arxiv.org/abs/2502.02893v1)|null|
|**2025-02-05**|**Expertized Caption Auto-Enhancement for Video-Text Retrieval**|Junxiang Chen et.al.|[2502.02885v1](http://arxiv.org/abs/2502.02885v1)|null|
|**2025-02-05**|**SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions**|Xiaofan Yu et.al.|[2502.02883v1](http://arxiv.org/abs/2502.02883v1)|null|
|**2025-02-05**|**Vertical Federated Learning for Failure-Cause Identification in Disaggregated Microwave Networks**|Fatih Temiz et.al.|[2502.02874v1](http://arxiv.org/abs/2502.02874v1)|null|
|**2025-02-05**|**Achieving Operational Universality through a Turing Complete Chemputer**|Daniel Gahler et.al.|[2502.02872v1](http://arxiv.org/abs/2502.02872v1)|null|
|**2025-02-05**|**Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning**|Yibo Yan et.al.|[2502.02871v1](http://arxiv.org/abs/2502.02871v1)|null|
|**2025-02-05**|**OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds**|Fan Wang et.al.|[2502.02869v1](http://arxiv.org/abs/2502.02869v1)|null|
|**2025-02-05**|**A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability**|Hung-Fu Chang et.al.|[2502.02866v1](http://arxiv.org/abs/2502.02866v1)|null|
|**2025-02-05**|**OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change**|Pat Pataranutaporn et.al.|[2502.02863v1](http://arxiv.org/abs/2502.02863v1)|null|
|**2025-02-05**|**Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations**|Peiyan Yue et.al.|[2502.02862v1](http://arxiv.org/abs/2502.02862v1)|null|
|**2025-02-05**|**Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**|Chanhui Lee et.al.|[2502.02810v1](http://arxiv.org/abs/2502.02810v1)|null|
|**2025-02-05**|**CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration**|Yizhe Yang et.al.|[2502.02807v1](http://arxiv.org/abs/2502.02807v1)|null|
|**2025-02-05**|**Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting**|Sunny Sanyal et.al.|[2502.02797v1](http://arxiv.org/abs/2502.02797v1)|null|
|**2025-02-05**|**Leveraging the true depth of LLMs**|Ramón Calvo González et.al.|[2502.02790v1](http://arxiv.org/abs/2502.02790v1)|null|
|**2025-02-05**|**Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation**|Jingyu Liu et.al.|[2502.02789v1](http://arxiv.org/abs/2502.02789v1)|null|
|**2025-02-05**|**Inducing Diversity in Differentiable Search Indexing**|Abhijeet Phatak et.al.|[2502.02788v1](http://arxiv.org/abs/2502.02788v1)|null|
|**2025-02-05**|**SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models**|Amirhossein Dabiriaghdam et.al.|[2502.02787v1](http://arxiv.org/abs/2502.02787v1)|null|
|**2025-02-04**|**Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation**|Songlin Xu et.al.|[2502.02780v1](http://arxiv.org/abs/2502.02780v1)|null|
|**2025-02-04**|**3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**|Weicheng Zhu et.al.|[2502.02779v1](http://arxiv.org/abs/2502.02779v1)|null|
|**2025-02-04**|**Cross-Modality Embedding of Force and Language for Natural Human-Robot Communication**|Ravi Tejwani et.al.|[2502.02772v1](http://arxiv.org/abs/2502.02772v1)|null|
|**2025-02-04**|**Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning**|Chaofan Lin et.al.|[2502.02770v1](http://arxiv.org/abs/2502.02770v1)|null|
|**2025-02-04**|**Planning with affordances: Integrating learned affordance models and symbolic planning**|Rajesh Mangannavar et.al.|[2502.02768v1](http://arxiv.org/abs/2502.02768v1)|null|
|**2025-02-04**|**Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**|Obed Korshie Dzikunu et.al.|[2502.02756v1](http://arxiv.org/abs/2502.02756v1)|null|
|**2025-02-04**|**PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework**|Hongwei Li et.al.|[2502.02747v1](http://arxiv.org/abs/2502.02747v1)|null|
|**2025-02-04**|**Vision-Language Model Dialog Games for Self-Improvement**|Ksenia Konyushkova et.al.|[2502.02740v1](http://arxiv.org/abs/2502.02740v1)|null|

#### Abstracts
##### **Seeing World Dynamics in a Nutshell**
2502.03465v1 by Qiuhong Shen, Xuanyu Yi, Mingbao Lin, Hanwang Zhang, Shuicheng Yan, Xinchao Wang

We consider the problem of efficiently representing casually captured
monocular videos in a spatially- and temporally-coherent manner. While existing
approaches predominantly rely on 2D/2.5D techniques treating videos as
collections of spatiotemporal pixels, they struggle with complex motions,
occlusions, and geometric consistency due to absence of temporal coherence and
explicit 3D structure. Drawing inspiration from monocular video as a projection
of the dynamic 3D world, we explore representing videos in their intrinsic 3D
form through continuous flows of Gaussian primitives in space-time. In this
paper, we propose NutWorld, a novel framework that efficiently transforms
monocular videos into dynamic 3D Gaussian representations in a single forward
pass. At its core, NutWorld introduces a structured spatial-temporal aligned
Gaussian (STAG) representation, enabling optimization-free scene modeling with
effective depth and flow regularization. Through comprehensive experiments, we
demonstrate that NutWorld achieves high-fidelity video reconstruction quality
while enabling various downstream applications in real-time. Demos and code
will be available at https://github.com/Nut-World/NutWorld.

摘要：<paragraph>我们考虑以空间和时间一致的方式有效表示随意捕捉的单眼视频的问题。虽然现有方法主要依赖于将视频视为时空像素集合的 2D/2.5D 技术，但由于缺乏时间一致性和显式 3D 结构，它们难以处理复杂运动、遮挡和几何一致性。从单眼视频作为动态 3D 世界投影中汲取灵感，我们探索通过时空中的高斯基元的连续流以其内在 3D 形式表示视频。在本文中，我们提出了 NutWorld，这是一个新颖的框架，可以有效地将单眼视频转换为动态 3D 高斯表示，只需一次正向传递。从本质上讲，NutWorld 引入了结构化的时空对齐高斯 (STAG) 表示，通过有效的深度和流正则化实现无优化场景建模。通过全面的实验，我们证明 NutWorld 实现了高保真视频重建质量，同时支持各种下游应用程序实时运行。演示和代码将在 https://github.com/Nut-World/NutWorld 上提供。</paragraph>

##### **Do Large Language Model Benchmarks Test Reliability?**
2502.03461v1 by Joshua Vendrow, Edward Vendrow, Sara Beery, Aleksander Madry

When deploying large language models (LLMs), it is important to ensure that
these models are not only capable, but also reliable. Many benchmarks have been
created to track LLMs' growing capabilities, however there has been no similar
focus on measuring their reliability. To understand the potential ramifications
of this gap, we investigate how well current benchmarks quantify model
reliability. We find that pervasive label errors can compromise these
evaluations, obscuring lingering model failures and hiding unreliable behavior.
  Motivated by this gap in the evaluation of reliability, we then propose the
concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to
minimize label errors and ambiguity. As a first attempt at constructing such
benchmarks, we revise examples from fifteen existing popular benchmarks. We
evaluate a wide range of models on these platinum benchmarks and find that,
indeed, frontier LLMs still exhibit failures on simple tasks such as
elementary-level math word problems. Analyzing these failures further reveals
previously unidentified patterns of problems on which frontier models
consistently struggle. We provide code at
https://github.com/MadryLab/platinum-benchmarks

摘要：在部署大型语言模型 (LLM) 时，重要的是要确保这些模型不仅有能力，而且可靠。已经创建了许多基准来跟踪 LLM 不断增长的能力，然而，没有类似的重点来衡量它们的可靠性。为了了解这一差距的潜在影响，我们调查了当前基准对模型可靠性的量化程度。我们发现普遍的标签错误会损害这些评估，掩盖持续的模型故障并隐藏不可靠的行为。受评估可靠性差距的启发，我们提出了所谓的铂金基准的概念，即精心策划以最大程度减少标签错误和歧义的基准。作为构建此类基准的首次尝试，我们修改了十五个现有流行基准中的示例。我们在这些铂金基准上评估了广泛的模型，并发现最前沿的 LLM 确实仍然在简单的任务上表现出失败，例如小学数学文字题。进一步分析这些失败揭示了以前未识别的模型问题模式，最前沿的模型始终在这些问题上苦苦挣扎。我们在 https://github.com/MadryLab/platinum-benchmarks 提供代码

##### **Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training**
2502.03460v1 by Boyao Wang, Rui Pan, Shizhe Diao, Xingyuan Pan, Jipeng Zhang, Renjie Pi, Tong Zhang

Small language models (SLMs) have attracted considerable attention from both
academia and industry due to their broad range of applications in edge devices.
To obtain SLMs with strong performance, conventional approaches either
pre-train the models from scratch, which incurs substantial computational
costs, or compress/prune existing large language models (LLMs), which results
in performance drops and falls short in comparison to pre-training. In this
paper, we investigate the family of acceleration methods that involve both
structured pruning and model training. We found 1) layer-wise adaptive pruning
(Adapt-Pruner) is extremely effective in LLMs and yields significant
improvements over existing pruning techniques, 2) adaptive pruning equipped
with further training leads to models comparable to those pre-training from
scratch, 3) incremental pruning brings non-trivial performance gain by
interleaving pruning with training and only removing a small portion of neurons
($\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate that
Adapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner,
FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsense
benchmarks. Additionally, Adapt-Pruner restores the performance of
MobileLLM-125M to 600M on the MMLU benchmark with 200$\times$ fewer tokens via
pruning from its larger counterparts, and discovers a new 1B model that
surpasses LLaMA-3.2-1B in multiple benchmarks.

摘要：小型语言模型 (SLM) 因其在边缘设备的广泛应用而备受学术界和产业界的关注。为了获得具有强大性能的 SLM，传统方法要么从头开始预训练模型，这会产生大量的计算成本，要么压缩/剪枝现有的超大语言模型 (LLM)，这会导致性能下降并且与预训练相比有所不足。在本文中，我们研究了一系列加速方法，这些方法既涉及结构化剪枝，又涉及模型训练。我们发现 1) 分层自适应剪枝 (Adapt-Pruner) 在 LLM 中非常有效，并且比现有的剪枝技术有显著的改进，2) 自适应剪枝配备进一步的训练，导致模型与从头开始预训练的模型相当，3) 渐进剪枝通过将剪枝与训练交错进行，并且一次仅移除一小部分神经元（约 5%），从而带来了非平凡的性能提升。在 LLaMA-3.1-8B 上的实验结果表明，Adapt-Pruner 在常识基准测试中的准确度方面比 LLM-Pruner、FLAP 和 SliceGPT 等传统剪枝方法平均高出 1%-7%。此外，Adapt-Pruner 通过从其更大的对应模型中剪枝，将 MobileLLM-125M 在 MMLU 基准测试上的性能恢复到 600M，并且发现了在多个基准测试中都超过 LLaMA-3.2-1B 的新 1B 模型。

##### **A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**
2502.03450v1 by Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell

Scene graphs have emerged as a structured and serializable environment
representation for grounded spatial reasoning with Large Language Models
(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason
framework for reasoning and planning with scene graphs. Our approach employs
two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and
information queries generation, and a (2) Retriever for extracting
corresponding graph information following the queries. Two agents collaborate
iteratively, enabling sequential reasoning and adaptive attention to graph
information. Unlike prior works, both agents are prompted only with the scene
graph schema rather than the full graph data, which reduces the hallucination
by limiting input tokens, and drives the Reasoner to generate reasoning trace
abstractly.Following the trace, the Retriever programmatically query the scene
graph data based on the schema understanding, allowing dynamic and global
attention on the graph that enhances alignment between reasoning and retrieval.
Through experiments in multiple simulation environments, we show that our
framework surpasses existing LLM-based approaches in numerical Q\&A and
planning tasks, and can benefit from task-level few-shot examples, even in the
absence of agent-level demonstrations. Project code will be released.

摘要：場景圖表已成為大型語言模型 (LLM) 以基礎空間推理為基礎的結構化且可序列化的環境表徵。在這項工作中，我們提出 SG-RwR，一個以綱要為導向的檢索與推理框架，用於場景圖表的推理和規劃。我們的做法採用了兩個協作的、編寫程式碼的 LLM 代理：一個 (1) 推論器，用於任務規劃和資訊查詢產生，以及一個 (2) 檢索器，用於根據查詢提取對應的圖形資訊。兩個代理反覆合作，實現對圖形資訊的順序推理和適應性關注。與先前的作品不同，兩個代理僅提示場景圖表綱要，而不是完整的圖形資料，這透過限制輸入代碼減少了幻覺，並驅使推論器抽象地產生推理軌跡。根據軌跡，檢索器根據綱要理解以程式化方式查詢場景圖形資料，允許對圖形進行動態和整體關注，增強推理和檢索之間的一致性。透過在多個模擬環境中的實驗，我們表明我們的框架在數值問答和規劃任務中超越了現有的基於 LLM 的方法，並且可以受益於任務級別的少次範例，即使在沒有代理級別示範的情況下也是如此。專案程式碼將會釋出。

##### **Masked Autoencoders Are Effective Tokenizers for Diffusion Models**
2502.03444v1 by Hao Chen, Yujin Han, Fangyi Chen, Xiang Li, Yidong Wang, Jindong Wang, Ze Wang, Zicheng Liu, Difan Zou, Bhiksha Raj

Recent advances in latent diffusion models have demonstrated their
effectiveness for high-resolution image synthesis. However, the properties of
the latent space from tokenizer for better learning and generation of diffusion
models remain under-explored. Theoretically and empirically, we find that
improved generation quality is closely tied to the latent distributions with
better structure, such as the ones with fewer Gaussian Mixture modes and more
discriminative features. Motivated by these insights, we propose MAETok, an
autoencoder (AE) leveraging mask modeling to learn semantically rich latent
space while maintaining reconstruction fidelity. Extensive experiments validate
our analysis, demonstrating that the variational form of autoencoders is not
necessary, and a discriminative latent space from AE alone enables
state-of-the-art performance on ImageNet generation using only 128 tokens.
MAETok achieves significant practical improvements, enabling a gFID of 1.69
with 76x faster training and 31x higher inference throughput for 512x512
generation. Our findings show that the structure of the latent space, rather
than variational constraints, is crucial for effective diffusion models. Code
and trained models are released.

摘要：最近在潜在扩散模型方面的進展已證明其在高解析度影像合成方面的有效性。然而，用於更好的學習和生成擴散模型的標記器所產生的潛在空間的特性仍未被充分探討。在理論和經驗上，我們發現改進的生成品質與具有更好結構的潛在分佈密切相關，例如具有較少高斯混合模式和更多判別特徵的潛在分佈。受這些見解的啟發，我們提出了 MAETok，一種利用遮罩建模學習語義豐富潛在空間並同時維持重建保真度的自動編碼器 (AE)。廣泛的實驗驗證了我們的分析，證明了自動編碼器的變分形式並非必要，而且僅來自 AE 的判別潛在空間就能使用僅 128 個標記在 ImageNet 生成方面實現最先進的效能。MAETok 實現了顯著的實際改進，讓 512x512 生成能夠以 76 倍更快的訓練速度和 31 倍更高的推論處理量實現 1.69 的 gFID。我們的發現表明，潛在空間的結構，而非變分約束，對於有效的擴散模型至關重要。程式碼和訓練好的模型已發布。

##### **BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving**
2502.03438v1 by Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Kai Shen

Recent advancements in large language models (LLMs) have spurred growing
interest in automatic theorem proving using Lean4, where effective tree search
methods are crucial for navigating proof search spaces. While the existing
approaches primarily rely on value functions and Monte Carlo Tree Search
(MCTS), the potential of simpler methods like Best-First Search (BFS) remains
underexplored. This paper investigates whether BFS can achieve competitive
performance in large-scale theorem proving tasks. We present
\texttt{BFS-Prover}, a scalable expert iteration framework, featuring three key
innovations. First, we implement strategic data filtering at each expert
iteration round, excluding problems solvable via beam search node expansion to
focus on harder cases. Second, we improve the sample efficiency of BFS through
Direct Preference Optimization (DPO) applied to state-tactic pairs
automatically annotated with compiler error feedback, refining the LLM's policy
to prioritize productive expansions. Third, we employ length normalization in
BFS to encourage exploration of deeper proof paths. \texttt{BFS-Prover}
achieves a score of $71.31$ on the MiniF2F test set and therefore challenges
the perceived necessity of complex tree search methods, demonstrating that BFS
can achieve competitive performance when properly scaled.

摘要：最近在大型语言模型 (LLM) 上的进展激发了人们对使用 Lean4 进行自动定理证明的兴趣，其中有效的树搜索方法对于导航证明搜索空间至关重要。虽然现有方法主要依赖于值函数和蒙特卡罗树搜索 (MCTS)，但像最佳优先搜索 (BFS) 这样更简单的方法的潜力仍然没有得到充分探索。本文研究了 BFS 是否可以在大规模定理证明任务中实现有竞争力的性能。我们展示了\texttt{BFS-Prover}，一个可扩展的专家迭代框架，具有三个关键创新。首先，我们在每次专家迭代回合中实施战略数据过滤，排除可以通过波束搜索节点扩展来解决的问题，以专注于更困难的情况。其次，我们通过直接偏好优化 (DPO) 提高了 BFS 的样本效率，该优化应用于自动注释有编译器错误反馈的状态策略对，以优化 LLM 的策略以优先考虑富有成效的扩展。第三，我们在 BFS 中采用长度归一化来鼓励探索更深入的证明路径。\texttt{BFS-Prover}在 MiniF2F 测试集中获得了 $71.31$ 的分数，因此对复杂树搜索方法的必要性提出了质疑，证明了在适当扩展时 BFS 可以实现有竞争力的性能。

##### **On Fairness of Unified Multimodal Large Language Model for Image Generation**
2502.03429v1 by Ming Liu, Hao Chen, Jindong Wang, Liwen Wang, Bhiksha Raj Ramakrishnan, Wensheng Zhang

Unified multimodal large language models (U-MLLMs) have demonstrated
impressive performance in visual understanding and generation in an end-to-end
pipeline. Compared with generation-only models (e.g., Stable Diffusion),
U-MLLMs may raise new questions about bias in their outputs, which can be
affected by their unified capabilities. This gap is particularly concerning
given the under-explored risk of propagating harmful stereotypes. In this
paper, we benchmark the latest U-MLLMs and find that most exhibit significant
demographic biases, such as gender and race bias. To better understand and
mitigate this issue, we propose a locate-then-fix strategy, where we audit and
show how the individual model component is affected by bias. Our analysis shows
that bias originates primarily from the language model. More interestingly, we
observe a "partial alignment" phenomenon in U-MLLMs, where understanding bias
appears minimal, but generation bias remains substantial. Thus, we propose a
novel balanced preference model to balance the demographic distribution with
synthetic data. Experiments demonstrate that our approach reduces demographic
bias while preserving semantic fidelity. We hope our findings underscore the
need for more holistic interpretation and debiasing strategies of U-MLLMs in
the future.

摘要：統一多模態大型語言模型 (U-MLLM) 已展現出在端到端管線中視覺理解和生成方面的驚人效能。與僅生成模型 (例如 Stable Diffusion) 相比，U-MLLM 可能會對其輸出中的偏見提出新的問題，而這些偏見可能會受到其統一功能的影響。由於對傳播有害刻板印象的風險探索不足，因此這個差距特別令人擔憂。在本文中，我們對最新的 U-MLLM 進行基準測試，發現大多數 U-MLLM 都表現出顯著的人口統計偏見，例如性別和種族偏見。為了更深入地了解和緩解這個問題，我們提出了一個先定位再修正的策略，我們在其中稽核並展示個別模型組成部分如何受到偏見影響。我們的分析顯示，偏見主要源自語言模型。更有趣的是，我們在 U-MLLM 中觀察到「部分對齊」現象，其中理解偏見似乎很小，但生成偏見仍然很大。因此，我們提出了一個新穎的平衡偏好模型，以平衡人口統計分佈和合成資料。實驗證明，我們的做法減少了人口統計偏見，同時保留了語義保真度。我們希望我們的發現強調未來對 U-MLLM 進行更全面的詮釋和去偏策略的必要性。

##### **TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer**
2502.03426v1 by Zhihong Xu, Dongxia Wang, Peng Du, Yang Cao, Qing Guo

Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain a
subject's identity from a source image while adopting a specified target pose
(e.g., skeleton). While diffusion-based PGPIS methods effectively preserve
facial features during pose transformation, they often struggle to accurately
maintain clothing details from the source image throughout the diffusion
process. This limitation becomes particularly problematic when there is a
substantial difference between the source and target poses, significantly
impacting PGPIS applications in the fashion industry where clothing style
preservation is crucial for copyright protection. Our analysis reveals that
this limitation primarily stems from the conditional diffusion model's
attention modules failing to adequately capture and preserve clothing patterns.
To address this limitation, we propose human-parsing-guided attention
diffusion, a novel approach that effectively preserves both facial and clothing
appearance while generating high-quality results. We propose a
human-parsing-aware Siamese network that consists of three key components: dual
identical UNets (TargetNet for diffusion denoising and SourceNet for source
image embedding extraction), a human-parsing-guided fusion attention (HPFA),
and a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embed
the face and clothes patterns into the target image generation adaptively and
effectively. Extensive experiments on both the in-shop clothes retrieval
benchmark and the latest in-the-wild human editing dataset demonstrate our
method's significant advantages over 13 baseline approaches for preserving both
facial and clothes appearance in the source image.

摘要：姿勢引導人物影像合成 (PGPIS) 會產生影像，在採用指定目標姿勢 (例如骨架) 的同時，維持來源影像中主體的身份。雖然基於擴散的 PGPIS 方法在姿勢轉換期間有效地保留了面部特徵，但它們通常難以在整個擴散過程中準確地保留來源影像中的服飾細節。當來源姿勢和目標姿勢之間存在實質性差異時，這個限制會變得特別有問題，這會嚴重影響時尚產業中的 PGPIS 應用，在時尚產業中，服裝風格的保留對於版權保護至關重要。我們的分析顯示，這個限制主要源於條件擴散模型的注意力模組無法充分捕捉和保留服裝樣式。為了解決這個限制，我們提出了人體解析引導的注意力擴散，這是一種新穎的方法，可以在產生高品質結果的同時有效地保留面部和服裝的外觀。我們提出了一個感知人體解析的 Siamese 網路，它包含三個關鍵組成部分：雙重相同的 UNet (用於擴散去噪的 TargetNet 和用於來源影像嵌入提取的 SourceNet)、人體解析引導的融合注意力 (HPFA) 和 CLIP 引導的注意力對齊 (CAA)。HPFA 和 CAA 模組可以適應性地且有效地將臉部和服裝樣式嵌入目標影像生成中。在商店內服飾檢索基準和最新的野外人像編輯資料集上的大量實驗證明了我們的方法在保留來源影像中的面部和服裝外觀方面，相較於 13 種基準方法具有顯著的優勢。

##### **Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts**
2502.03418v1 by Nikta Gohari Sadr, Sangmitra Madhusudan, Ali Emami

Zero-shot prompting techniques have significantly improved the performance of
Large Language Models (LLMs). However, we lack a clear understanding of why
zero-shot prompts are so effective. For example, in the prompt "Let's think
step-by-step," is "think" or "step-by-step" more crucial to its success?
Existing interpretability methods, such as gradient-based and attention-based
approaches, are computationally intensive and restricted to open-source models.
We introduce the ZIP score (Zero-shot Importance of Perturbation score), a
versatile metric applicable to both open and closed-source models, based on
systematic input word perturbations. Our experiments across four recent LLMs,
seven widely-used prompts, and several tasks, reveal interesting patterns in
word importance. For instance, while both 'step-by-step' and 'think' show high
ZIP scores, which one is more influential depends on the model and task. We
validate our method using controlled experiments and compare our results with
human judgments, finding that proprietary models align more closely with human
intuition regarding word significance. These findings enhance our understanding
of LLM behavior and contribute to developing more effective zero-shot prompts
and improved model analysis.

摘要：零次提示技術大幅提升了大型語言模型 (LLM) 的效能。然而，我們對於零次提示為何如此有效仍缺乏明確的理解。例如，在提示「讓我們一步一步思考」中，「思考」或「一步一步」哪個對其成功更為關鍵？現有的可解釋性方法（例如基於梯度和基於注意力的方法）計算密集，且僅限於開源模型。我們引入了 ZIP 分數（零次擾動重要性分數），這是一個通用的指標，適用於開源和閉源模型，基於系統性輸入詞彙擾動。我們針對四個最近的 LLM、七個廣泛使用的提示和多項任務進行的實驗，揭示了詞彙重要性的有趣模式。例如，雖然「一步一步」和「思考」都顯示出很高的 ZIP 分數，但哪一個更有影響力取決於模型和任務。我們使用受控實驗驗證了我們的模型，並將我們的結果與人類判斷進行比較，發現專有模型與人類對詞彙重要性的直覺更為一致。這些發現增進了我們對 LLM 行為的理解，並有助於開發更有效的零次提示和改進模型分析。

##### **SPRI: Aligning Large Language Models with Context-Situated Principles**
2502.03397v1 by Hongli Zhan, Muneeza Azmat, Raya Horesh, Junyi Jessy Li, Mikhail Yurochkin

Aligning Large Language Models to integrate and reflect human values,
especially for tasks that demand intricate human oversight, is arduous since it
is resource-intensive and time-consuming to depend on human expertise for
context-specific guidance. Prior work has utilized predefined sets of rules or
principles to steer the behavior of models (Bai et al., 2022; Sun et al.,
2023). However, these principles tend to be generic, making it challenging to
adapt them to each individual input query or context. In this work, we present
Situated-PRInciples (SPRI), a framework requiring minimal or no human effort
that is designed to automatically generate guiding principles in real-time for
each input query and utilize them to align each response. We evaluate SPRI on
three tasks, and show that 1) SPRI can derive principles in a complex
domain-specific task that leads to on-par performance as expert-crafted ones;
2) SPRI-generated principles lead to instance-specific rubrics that outperform
prior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data
leads to substantial improvement on truthfulness. We release our code and model
generations at https://github.com/honglizhan/SPRI-public.

摘要：將大型語言模型調整為整合和反映人類價值觀，
特別是對於需要複雜的人類監督的任務，由於依賴人類專業知識來進行特定於情境的指導是耗費資源且耗時的，因此很艱難。先前的研究利用預定義的規則或原則集來指導模型的行為（Bai et al., 2022; Sun et al., 2023）。然而，這些原則往往是通用的，這使得它們難以適應每個單獨的輸入查詢或情境。在這項工作中，我們提出了情境原則 (SPRI)，這是一個需要極少或不需要人工努力的框架，旨在為每個輸入查詢自動生成指導原則並利用它們來調整每個回應。我們在三項任務上評估 SPRI，並表明 1) SPRI 能夠在複雜的特定領域任務中推導出原則，從而導致與專家製作的原則同等的效能；2) SPRI 生成的原則導致特定於例證的評分標準，其效能優於先前的 LLM 作為評審框架；3) 使用 SPRI 生成合成 SFT 資料會大幅改善真實性。我們在 https://github.com/honglizhan/SPRI-public/ 發布我們的程式碼和模型生成。

##### **Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**
2502.03396v1 by Sarah Al-Shareeda, Yasar Celik, Bilge Bilgili, Ahmed Al-Dubai, Berk Canberk

Creating a Digital Twin (DT) for Healthcare Intelligent Transportation
Systems (HITS) is a hot research trend focusing on enhancing HITS management,
particularly in emergencies where ambulance vehicles must arrive at the crash
scene on time and track their real-time location is crucial to the medical
authorities. Despite the claim of real-time representation, a temporal
misalignment persists between the physical and virtual domains, leading to
discrepancies in the ambulance's location representation. This study proposes
integrating AI predictive models, specifically Support Vector Regression (SVR)
and Deep Neural Networks (DNN), within a constructed mock DT data pipeline
framework to anticipate the medical vehicle's next location in the virtual
world. These models align virtual representations with their physical
counterparts, i.e., metaphorically offsetting the synchronization delay between
the two worlds. Trained meticulously on a historical geospatial dataset, SVR
and DNN exhibit exceptional prediction accuracy in MATLAB and Python
environments. Through various testing scenarios, we visually demonstrate the
efficacy of our methodology, showcasing SVR and DNN's key role in significantly
reducing the witnessed gap within the HITS's DT. This transformative approach
enhances real-time synchronization in emergency HITS by approximately 88% to
93%.

摘要：建立醫療智慧交通系統（HITS）的數位分身（DT）是熱門的研究趨勢，其重點在於提升 HITS 管理，特別是在救護車必須準時抵達車禍現場的緊急情況中，追蹤其即時位置對於醫療單位至關重要。儘管聲稱即時呈現，但實體和虛擬領域之間仍存在時間上的錯位，導致救護車位置呈現上的差異。本研究建議在建構的虛擬 DT 資料管道架構中整合人工智慧預測模型，特別是支援向量回歸（SVR）和深度神經網路（DNN），以預測醫療車輛在虛擬世界的下一個位置。這些模型將虛擬呈現與其實體對應物對齊，也就是說，在兩個世界之間比喻性地抵銷同步延遲。在歷史地理空間資料集上經過仔細訓練，SVR 和 DNN 在 MATLAB 和 Python 環境中展現出卓越的預測準確性。透過各種測試情境，我們視覺化展示了我們方法論的效能，展示了 SVR 和 DNN 在顯著縮小 HITS 的 DT 中見證到的差距方面的關鍵作用。這種變革性的方法將緊急 HITS 中的即時同步提升了大約 88% 到 93%。

##### **Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications**
2502.03395v1 by Issar Arab, Rodrigo Benitez

Time series forecasting is essential for operational intelligence in the
hospitality industry, and particularly challenging in large-scale, distributed
systems. This study evaluates the performance of statistical, machine learning
(ML), deep learning, and foundation models in forecasting hourly sales over a
14-day horizon using real-world data from a network of thousands of restaurants
across Germany. The forecasting solution includes features such as weather
conditions, calendar events, and time-of-day patterns. Results demonstrate the
strong performance of ML-based meta-models and highlight the emerging potential
of foundation models like Chronos and TimesFM, which deliver competitive
performance with minimal feature engineering, leveraging only the pre-trained
model (zero-shot inference). Additionally, a hybrid PySpark-Pandas approach
proves to be a robust solution for achieving horizontal scalability in
large-scale deployments.

摘要：時序預測對於飯店業的營運情報至關重要，特別是在大型分布式系統中具有挑戰性。本研究評估了統計、機器學習 (ML)、深度學習和基礎模型在使用來自德國數千家餐廳網路的真實世界資料預測 14 天期限內每小時銷售額的效能。預測解決方案包括天氣狀況、日曆事件和時間模式等功能。結果證明了基於 ML 的元模型的強勁效能，並強調了 Chronos 和 TimesFM 等基礎模型的新興潛力，它們僅利用預先訓練的模型（零次學習推論）就能在最小的特徵工程下提供具有競爭力的效能。此外，混合 PySpark-Pandas 方法被證明是實現大規模部署中橫向擴充性的強大解決方案。

##### **LIMO: Less is More for Reasoning**
2502.03387v1 by Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu

We present a fundamental discovery that challenges our understanding of how
complex reasoning emerges in large language models. While conventional wisdom
suggests that sophisticated reasoning tasks demand extensive training data
(>100,000 examples), we demonstrate that complex mathematical reasoning
abilities can be effectively elicited with surprisingly few examples. Through
comprehensive experiments, our proposed model LIMO demonstrates unprecedented
performance in mathematical reasoning. With merely 817 curated training
samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from
previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of
the training data required by previous approaches. LIMO demonstrates
exceptional out-of-distribution generalization, achieving 40.5% absolute
improvement across 10 diverse benchmarks, outperforming models trained on 100x
more data, challenging the notion that SFT leads to memorization rather than
generalization. Based on these results, we propose the Less-Is-More Reasoning
Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has
been comprehensively encoded during pre-training, sophisticated reasoning
capabilities can emerge through minimal but precisely orchestrated
demonstrations of cognitive processes. This hypothesis posits that the
elicitation threshold for complex reasoning is determined by two key factors:
(1) the completeness of the model's encoded knowledge foundation during
pre-training, and (2) the effectiveness of post-training examples as "cognitive
templates" that show the model how to utilize its knowledge base to solve
complex reasoning tasks. To facilitate reproducibility and future research in
data-efficient reasoning, we release LIMO as a comprehensive open-source suite
at https://github.com/GAIR-NLP/LIMO.

摘要：<paragraph>我們提出了一項基本發現，挑戰了我們對大型語言模型中複雜推理如何出現的理解。雖然傳統智慧表明，複雜的推理任務需要大量的訓練數據（>100,000 個範例），但我們證明了複雜的數學推理能力可以用驚人的少數範例有效地引發。通過全面的實驗，我們提出的模型 LIMO 在數學推理中展示了前所未有的表現。LIMO 僅使用 817 個精心策劃的訓練樣本，在 AIME 上達到了 57.1% 的準確度，在 MATH 上達到了 94.8%，分別比以前的基於 SFT 的模型提高了 6.5% 和 59.2%，同時僅使用了以前方法所需訓練數據的 1%。LIMO 展示了出色的分布外泛化能力，在 10 個不同的基準測試中取得了 40.5% 的絕對改進，優於在 100 倍更多數據上訓練的模型，挑戰了 SFT 導致記憶而不是泛化的觀念。基於這些結果，我們提出了少即是多推理假設（LIMO 假設）：在預訓練過程中已全面編碼領域知識的基礎模型中，複雜的推理能力可以通過對認知過程進行最少的但精確安排的演示而出現。這個假設假設複雜推理的引發閾值是由兩個關鍵因素決定的：(1) 預訓練期間模型編碼知識基礎的完整性，以及 (2) 訓練後範例作為「認知模板」的有效性，向模型展示如何利用其知識庫來解決複雜的推理任務。為了促進數據有效推理的可複製性和未來研究，我們在 https://github.com/GAIR-NLP/LIMO 上發布 LIMO 作為一個全面的開源套件。</paragraph>

##### **High-Fidelity Simultaneous Speech-To-Speech Translation**
2502.03382v1 by Tom Labiausse, Laurent Mazaré, Edouard Grave, Patrick Pérez, Alexandre Défossez, Neil Zeghidour

We introduce Hibiki, a decoder-only model for simultaneous speech
translation. Hibiki leverages a multistream language model to synchronously
process source and target speech, and jointly produces text and audio tokens to
perform speech-to-text and speech-to-speech translation. We furthermore address
the fundamental challenge of simultaneous interpretation, which unlike its
consecutive counterpart, where one waits for the end of the source utterance to
start translating, adapts its flow to accumulate just enough context to produce
a correct translation in real-time, chunk by chunk. To do so, we introduce a
weakly-supervised method that leverages the perplexity of an off-the-shelf text
translation system to identify optimal delays on a per-word basis and create
aligned synthetic data. After supervised training, Hibiki performs adaptive,
simultaneous speech translation with vanilla temperature sampling. On a
French-English simultaneous speech translation task, Hibiki demonstrates
state-of-the-art performance in translation quality, speaker fidelity and
naturalness. Moreover, the simplicity of its inference process makes it
compatible with batched translation and even real-time on-device deployment. We
provide examples as well as models and inference code.

摘要：我們介紹 Hibiki，一種僅解碼器模型，用於同時語音翻譯。Hibiki 利用多串流語言模型同步處理來源和目標語音，並共同產生文字和音訊代碼，以執行語音轉文字和語音轉語音翻譯。我們進一步解決了同時口譯的基本挑戰，與其連續對應者不同，後者等待來源語句結束才開始翻譯，調整其流程以累積足夠的上下文，以產生正確的即時翻譯，逐塊進行。為此，我們引入一種弱監督方法，利用現成文字翻譯系統的困惑度，逐字識別最佳延遲，並建立對齊的合成資料。在監督式訓練後，Hibiki 執行適應性、同時語音翻譯，採用香草溫度抽樣。在法語-英語同時語音翻譯任務中，Hibiki 在翻譯品質、說話者保真度和自然度方面展示了最先進的性能。此外，其推理過程的簡潔性使其與批次翻譯甚至實時設備部署相容。我們提供範例、模型和推理碼。

##### **Transformers and Their Roles as Time Series Foundation Models**
2502.03383v1 by Dennis Wu, Yihan He, Yuan Cao, Jianqing Fan, Han Liu

We give a comprehensive analysis of transformers as time series foundation
models, focusing on their approximation and generalization capabilities. First,
we demonstrate that there exist transformers that fit an autoregressive model
on input univariate time series via gradient descent. We then analyze MOIRAI, a
multivariate time series foundation model capable of handling an arbitrary
number of covariates. We prove that it is capable of automatically fitting
autoregressive models with an arbitrary number of covariates, offering insights
into its design and empirical success. For generalization, we establish bounds
for pretraining when the data satisfies Dobrushin's condition. Experiments
support our theoretical findings, highlighting the efficacy of transformers as
time series foundation models.

摘要：我們對Transformer作為時間序列基礎模型進行了全面分析，重點關注其逼近和概化能力。首先，我們證明了存在Transformer，它們通過梯度下降來擬合輸入單變量時間序列上的自迴歸模型。然後我們分析了 MOIRAI，這是一個多變量時間序列基礎模型，能夠處理任意數量的協變量。我們證明它能夠自動擬合具有任意數量的協變量的自迴歸模型，從而深入了解其設計和經驗成功。對於概化，當數據滿足 Dobrushin 條件時，我們建立了預訓練的界限。實驗支持我們的理論發現，強調了Transformer作為時間序列基礎模型的功效。

##### **Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality**
2502.03381v1 by Shiyi Tan, Constantin Orăsan, Sabine Braun

This paper reports on the results from a pilot study investigating the impact
of automatic speech recognition (ASR) technology on interpreting quality in
remote healthcare interpreting settings. Employing a within-subjects experiment
design with four randomised conditions, this study utilises scripted medical
consultations to simulate dialogue interpreting tasks. It involves four trainee
interpreters with a language combination of Chinese and English. It also
gathers participants' experience and perceptions of ASR support through cued
retrospective reports and semi-structured interviews. Preliminary data suggest
that the availability of ASR, specifically the access to full ASR transcripts
and to ChatGPT-generated summaries based on ASR, effectively improved
interpreting quality. Varying types of ASR output had different impacts on the
distribution of interpreting error types. Participants reported similar
interactive experiences with the technology, expressing their preference for
full ASR transcripts. This pilot study shows encouraging results of applying
ASR to dialogue-based healthcare interpreting and offers insights into the
optimal ways to present ASR output to enhance interpreter experience and
performance. However, it should be emphasised that the main purpose of this
study was to validate the methodology and that further research with a larger
sample size is necessary to confirm these findings.

摘要：本論文報告了一項試驗研究的結果，探討自動語音辨識 (ASR) 技術對遠距醫療口譯環境中口譯品質的影響。本研究採用受試者內實驗設計，有四個隨機條件，利用有腳本的醫療諮詢模擬對話口譯任務。它涉及四位中英文語言組合的見習口譯員。它還透過線索式回顧報告和半結構式訪談，收集參與者對 ASR 支援的經驗和看法。初步資料顯示，ASR 的可用性，特別是可以存取完整的 ASR 謄本和根據 ASR 生成的 ChatGPT 摘要，有效地提升了口譯品質。不同類型的 ASR 輸出對口譯錯誤類型的分佈有不同的影響。參與者回報與該技術有類似的互動經驗，表達他們偏好完整的 ASR 謄本。這項試驗研究顯示將 ASR 應用於基於對話的醫療口譯有令人振奮的結果，並提供洞見，說明呈現 ASR 輸出的最佳方式，以提升口譯員的經驗和表現。然而，應該強調的是，本研究的主要目的是驗證方法，且需要進一步進行更大樣本規模的研究，以確認這些發現。

##### **Demystifying Long Chain-of-Thought Reasoning in LLMs**
2502.03373v1 by Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, Xiang Yue

Scaling inference compute enhances reasoning in large language models (LLMs),
with long chains-of-thought (CoTs) enabling strategies like backtracking and
error correction. Reinforcement learning (RL) has emerged as a crucial method
for developing these capabilities, yet the conditions under which long CoTs
emerge remain unclear, and RL training requires careful design choices. In this
study, we systematically investigate the mechanics of long CoT reasoning,
identifying the key factors that enable models to generate long CoT
trajectories. Through extensive supervised fine-tuning (SFT) and RL
experiments, we present four main findings: (1) While SFT is not strictly
necessary, it simplifies training and improves efficiency; (2) Reasoning
capabilities tend to emerge with increased training compute, but their
development is not guaranteed, making reward shaping crucial for stabilizing
CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We
find that leveraging noisy, web-extracted solutions with filtering mechanisms
shows strong potential, particularly for out-of-distribution (OOD) tasks such
as STEM reasoning; and (4) Core abilities like error correction are inherently
present in base models, but incentivizing these skills effectively for complex
tasks via RL demands significant compute, and measuring their emergence
requires a nuanced approach. These insights provide practical guidance for
optimizing training strategies to enhance long CoT reasoning in LLMs. Our code
is available at: https://github.com/eddycmu/demystify-long-cot.

摘要：<paragraph>擴展推理運算能增強大型語言模型 (LLM) 中的推理，
具備長思維鏈 (CoT) 能啟用回溯和
錯誤修正等策略。強化學習 (RL) 已成為開發這些能力的一種重要方法，
但長 CoT 浮現的條件仍不清晰，而 RL 訓練需要謹慎的設計選擇。在這個
研究中，我們系統性地探討長 CoT 推理的機制，
找出讓模型產生長 CoT 軌跡的主要因素。透過廣泛的監督微調 (SFT) 和 RL
實驗，我們提出四項主要發現：(1) 雖然 SFT 並非絕對必要，但它簡化了訓練並提升效率；(2) 推理
能力傾向於隨著訓練運算增加而浮現，但其發展並非有保證，因此獎勵塑造對於穩定
CoT 長度增長至關重要；(3) 擴展可驗證的獎勵訊號對於 RL 至關重要。我們
發現利用帶有過濾機制的 noisy 網路提取解決方案顯示出強大的潛力，特別是對於 STEM 推理等
非分佈 (OOD) 任務；(4) 錯誤修正等核心能力本質上存在於基礎模型中，但透過 RL 有效地激勵這些技能以執行複雜
任務需要大量的運算，而衡量它們的浮現需要一種細緻的方法。這些見解為最佳化訓練策略以增強 LLM 中的長 CoT 推理提供了實用的指導。我們的程式碼可在以下網址取得：https://github.com/eddycmu/demystify-long-cot。</paragraph>

##### **PalimpChat: Declarative and Interactive AI analytics**
2502.03368v1 by Chunwei Liu, Gerardo Vitagliano, Brandon Rose, Matt Prinz, David Andrew Samson, Michael Cafarella

Thanks to the advances in generative architectures and large language models,
data scientists can now code pipelines of machine-learning operations to
process large collections of unstructured data. Recent progress has seen the
rise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to
build optimized and increasingly complex pipelines, but these systems often
remain accessible only to expert programmers. In this demonstration, we present
PalimpChat, a chat-based interface to Palimpzest that bridges this gap by
letting users create and run sophisticated AI pipelines through natural
language alone. By integrating Archytas, a ReAct-based reasoning agent, and
Palimpzest's suite of relational and LLM-based operators, PalimpChat provides a
practical illustration of how a chat interface can make declarative AI
frameworks truly accessible to non-experts.
  Our demo system is publicly available online. At SIGMOD'25, participants can
explore three real-world scenarios--scientific discovery, legal discovery, and
real estate search--or apply PalimpChat to their own datasets. In this paper,
we focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies
complex AI workflows such as extracting and analyzing biomedical data.

摘要：由於生成式架構和大型語言模型的進步，資料科學家現在可以編寫機器學習運算的管線，以處理大量非結構化資料。最近的進展見證了宣告式 AI 框架的興起（例如 Palimpzest、Lotus 和 DocETL），用於建置最佳化且日益複雜的管線，但這些系統通常僅供專家程式設計師使用。在此示範中，我們展示了 PalimpChat，一個基於聊天界面的 Palimpzest，透過讓使用者僅使用自然語言就能建立和執行精密的 AI 管線，來彌合此差距。透過整合基於 ReAct 的推理代理程式 Archytas，以及 Palimpzest 的關係式和基於 LLM 的運算元套件，PalimpChat 提供了一個實用的範例，說明聊天介面如何能讓宣告式 AI 框架真正地供非專家使用。我們的示範系統已公開在線上。在 SIGMOD'25，參與者可以探索三種真實世界的場景——科學發現、法律發現和房地產搜尋——或將 PalimpChat 套用至他們自己的資料集。在本文中，我們專注於 PalimpChat 在 Palimpzest 最佳化器的支援下，如何簡化複雜的 AI 工作流程，例如萃取和分析生物醫學資料。

##### **GHOST: Gaussian Hypothesis Open-Set Technique**
2502.03359v1 by Ryan Rabinowitz, Steve Cruz, Manuel Günther, Terrance E. Boult

Evaluations of large-scale recognition methods typically focus on overall
performance. While this approach is common, it often fails to provide insights
into performance across individual classes, which can lead to fairness issues
and misrepresentation. Addressing these gaps is crucial for accurately
assessing how well methods handle novel or unseen classes and ensuring a fair
evaluation. To address fairness in Open-Set Recognition (OSR), we demonstrate
that per-class performance can vary dramatically. We introduce Gaussian
Hypothesis Open Set Technique (GHOST), a novel hyperparameter-free algorithm
that models deep features using class-wise multivariate Gaussian distributions
with diagonal covariance matrices. We apply Z-score normalization to logits to
mitigate the impact of feature magnitudes that deviate from the model's
expectations, thereby reducing the likelihood of the network assigning a high
score to an unknown sample. We evaluate GHOST across multiple ImageNet-1K
pre-trained deep networks and test it with four different unknown datasets.
Using standard metrics such as AUOSCR, AUROC and FPR95, we achieve
statistically significant improvements, advancing the state-of-the-art in
large-scale OSR. Source code is provided online.

摘要：大規模辨識方法的評估通常著重於整體效能。雖然這種方法很常見，但它通常無法提供個別類別效能的見解，這可能會導致公平性問題和錯誤陳述。解決這些差距對於準確評估方法處理新穎或未見類別的程度以及確保公平評估至關重要。為了解決開放式辨識 (OSR) 中的公平性，我們證明每個類別的效能可能會大幅度變化。我們引入了高斯假設開放式技術 (GHOST)，這是一種新穎的無超參數演算法，它使用具有對角共變數矩陣的類別多元高斯分佈對深度特徵進行建模。我們對 logits 應用 Z 分數標準化，以減輕特徵大小偏離模型預期的影響，從而降低網路將高分數分配給未知樣本的可能性。我們在多個 ImageNet-1K 預訓練深度網路中評估了 GHOST，並使用四個不同的未知資料集對其進行了測試。使用 AUOSCR、AUROC 和 FPR95 等標準指標，我們取得了具有統計意義的改進，推動了大規模 OSR 的最新進展。原始碼已在線上提供。

##### **Minerva: A Programmable Memory Test Benchmark for Language Models**
2502.03358v1 by Menglin Xia, Victor Ruehle, Saravan Rajmohan, Reza Shokri

How effectively can LLM-based AI assistants utilize their memory (context) to
perform various tasks? Traditional data benchmarks, which are often manually
crafted, suffer from several limitations: they are static, susceptible to
overfitting, difficult to interpret, and lack actionable insights--failing to
pinpoint the specific capabilities a model lacks when it does not pass a test.
In this paper, we present a framework for automatically generating a
comprehensive set of tests to evaluate models' abilities to use their memory
effectively. Our framework extends the range of capability tests beyond the
commonly explored (passkey, key-value, needle in the haystack) search, a
dominant focus in the literature. Specifically, we evaluate models on atomic
tasks such as searching, recalling, editing, matching, comparing information in
context memory, and performing basic operations when inputs are structured into
distinct blocks, simulating real-world data. Additionally, we design composite
tests to investigate the models' ability to maintain state while operating on
memory. Our benchmark enables an interpretable, detailed assessment of memory
capabilities of LLMs.

摘要：LLM 為基礎的人工智慧助理能多有效率地運用其記憶力（背景）來執行各種任務？傳統資料基準通常是人工打造的，有許多限制：它們是靜態的、容易過度擬合、難以詮釋，而且缺乏可行的見解，無法精確找出模型在未通過測試時所欠缺的特定能力。在本文中，我們提出一個架構，用於自動產生一組全面的測試，以評估模型有效使用其記憶力的能力。我們的架構將能力測試的範圍擴展到常見的探索（密鑰、鍵值、大海撈針）搜尋之外，這是文獻中的主要重點。具體來說，我們在原子任務上評估模型，例如在背景記憶體中搜尋、回憶、編輯、比對、比較資訊，以及在輸入結構化為不同區塊時執行基本操作，模擬真實世界的資料。此外，我們設計了組合測試，以調查模型在對記憶體操作時維持狀態的能力。我們的基準能對 LLM 的記憶力能力進行可詮釋、詳細的評估。

##### **Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies**
2502.03341v1 by Harald Leisenberger, Franz Pernkopf

Variational inference in probabilistic graphical models aims to approximate
fundamental quantities such as marginal distributions and the partition
function. Popular approaches are the Bethe approximation, tree-reweighted, and
other types of convex free energies. These approximations are efficient but can
fail if the model is complex and highly interactive. In this work, we analyze
two classes of approximations that include the above methods as special cases:
first, if the model parameters are changed; and second, if the entropy
approximation is changed. We discuss benefits and drawbacks of either approach,
and deduce from this analysis how a free energy approximation should ideally be
constructed. Based on our observations, we propose approximations that
automatically adapt to a given model and demonstrate their effectiveness for a
range of difficult problems.

摘要：變異推論中的機率圖形模型旨在近似基本量，例如邊際分布和分配函數。熱門的方法包括貝氏近似、樹重新加權以及其他類型的凸自由能。這些近似很有效率，但如果模型很複雜且互動性很高，則可能會失敗。在這項工作中，我們分析了兩類近似，其中包括上述方法作為特殊情況：首先，如果模型參數已變更；其次，如果熵近似已變更。我們討論了這兩種方法的優缺點，並從這個分析中推論出自由能近似應如何理想地建構。根據我們的觀察，我們提出了可以自動適應給定模型的近似，並展示了它們對一系列困難問題的有效性。

##### **RadVLM: A Multitask Conversational Vision-Language Model for Radiology**
2502.03333v1 by Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Blüthgen, Farhad Nooralahzadeh, Michael Krauthammer

The widespread use of chest X-rays (CXRs), coupled with a shortage of
radiologists, has driven growing interest in automated CXR analysis and
AI-assisted reporting. While existing vision-language models (VLMs) show
promise in specific tasks such as report generation or abnormality detection,
they often lack support for interactive diagnostic capabilities. In this work
we present RadVLM, a compact, multitask conversational foundation model
designed for CXR interpretation. To this end, we curate a large-scale
instruction dataset comprising over 1 million image-instruction pairs
containing both single-turn tasks -- such as report generation, abnormality
classification, and visual grounding -- and multi-turn, multi-task
conversational interactions. After fine-tuning RadVLM on this instruction
dataset, we evaluate it across different tasks along with re-implemented
baseline VLMs. Our results show that RadVLM achieves state-of-the-art
performance in conversational capabilities and visual grounding while remaining
competitive in other radiology tasks. Ablation studies further highlight the
benefit of joint training across multiple tasks, particularly for scenarios
with limited annotated data. Together, these findings highlight the potential
of RadVLM as a clinically relevant AI assistant, providing structured CXR
interpretation and conversational capabilities to support more effective and
accessible diagnostic workflows.

摘要：胸部 X 光 (CXR) 的广泛使用，加上放射科醫師短缺，促使人們對自動化 CXR 分析和 AI 輔助報告產生越來越濃厚的興趣。雖然現有的視覺語言模型 (VLM) 在特定任務中顯示出前景，例如報告生成或異常偵測，但它們通常缺乏對互動式診斷功能的支持。在這項工作中，我們提出 RadVLM，這是一個緊湊的多任務對話式基礎模型，專為 CXR 解釋而設計。為此，我們策劃了一個大型指令資料集，包含超過 100 萬個影像指令對，其中包含單輪任務（例如報告生成、異常分類和視覺基礎），以及多輪、多任務對話互動。在對這個指令資料集進行微調後，我們對 RadVLM 進行評估，並與重新實作的基準 VLM 一起執行不同的任務。我們的結果顯示，RadVLM 在對話能力和視覺基礎方面取得了最先進的效能，同時在其他放射學任務中仍具有競爭力。消融研究進一步突顯了跨多個任務進行聯合訓練的好處，特別是對於帶有標註資料有限的場景。這些發現共同突顯了 RadVLM 作為臨床相關 AI 助理的潛力，提供結構化的 CXR 解釋和對話能力，以支援更有效且可存取的診斷工作流程。

##### **Controllable GUI Exploration**
2502.03330v1 by Aryan Garg, Yue Jiang, Antti Oulasvirta

During the early stages of interface design, designers need to produce
multiple sketches to explore a design space. Design tools often fail to support
this critical stage, because they insist on specifying more details than
necessary. Although recent advances in generative AI have raised hopes of
solving this issue, in practice they fail because expressing loose ideas in a
prompt is impractical. In this paper, we propose a diffusion-based approach to
the low-effort generation of interface sketches. It breaks new ground by
allowing flexible control of the generation process via three types of inputs:
A) prompts, B) wireframes, and C) visual flows. The designer can provide any
combination of these as input at any level of detail, and will get a diverse
gallery of low-fidelity solutions in response. The unique benefit is that large
design spaces can be explored rapidly with very little effort in
input-specification. We present qualitative results for various combinations of
input specifications. Additionally, we demonstrate that our model aligns more
accurately with these specifications than other models.

摘要：在介面設計的早期階段，設計師需要製作多個草圖來探索設計空間。設計工具常常無法支援這個關鍵階段，因為它們堅持要比必要時指定更多細節。儘管生成式 AI 的最新進展已提高了解決此問題的希望，但實際上它們會失敗，因為在提示中表達鬆散的想法是不切實際的。在本文中，我們提出了一個基於擴散的方法來低成本生成介面草圖。它透過允許透過三種類型的輸入靈活控制生成過程來創新：A) 提示、B) 線框圖，以及 C) 視覺流程。設計師可以在任何詳細層級提供這些內容的任何組合作為輸入，並將獲得回應的低保真度解決方案的各種圖庫。獨特的好處是可以透過輸入規格中的極少成本快速探索大型設計空間。我們針對各種輸入規格組合呈現定性結果。此外，我們證明我們的模型比其他模型更準確地與這些規格對齊。

##### **ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model**
2502.03325v1 by Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiaqi Wang, Mengkang Hu, Zhi Chen, Wanxiang Che, Ting Liu

Recent advancements in large language models (LLMs) have led to significant
successes across various applications, where the most noticeable is to a series
of emerging capabilities, particularly in the areas of In-Context Learning
(ICL) and Chain-of-Thought (CoT). To better understand and control model
performance, many studies have begun investigating the underlying causes of
these phenomena and their impact on task outcomes. However, existing
explanatory frameworks predominantly focus on isolating and explaining ICL and
CoT independently, leading to an incomplete understanding of their combined
influence on model performance. To address this gap, we propose the Electronic
Circuit Model (ECM), which provides a foundation for developing scalable,
learnable policies and improving the management of AI-generated content.
Specifically, ECM conceptualizes model behavior as an electronic circuit: ICL
is represented as semantic magnetic field to providing an additional voltage
following Faraday's Law, while CoT is modeled as series resistors to constrain
the model output performance following Ohm's Law. Experimental results
demonstrate that the ECM effectively predicts and explains LLM performance
across a variety of prompting strategies. Furthermore, we apply ECM to advanced
reasoning strategy optimization on a series of tasks, such as the International
Olympiad in Informatics (IOI) and the International Mathematical Olympiad
(IMO), achieving competitive performance that surpasses nearly 80% of top human
competitors.

摘要：大型語言模型 (LLM) 的最新進展已在各種應用中取得顯著成功，其中最顯著的是一系列新興能力，特別是在情境學習 (ICL) 和思維鏈 (CoT) 領域。為了更好地理解和控制模型效能，許多研究已開始探討這些現象的根本原因及其對任務結果的影響。然而，現有的解釋性框架主要著重於獨立隔離和解釋 ICL 和 CoT，導致對它們對模型效能的綜合影響了解不完整。為了解決此差距，我們提出電子電路模型 (ECM)，它提供了一個開發可擴充、可學習政策和改進 AI 生成內容管理的基礎。具體來說，ECM 將模型行為概念化為電子電路：ICL 被表示為語義磁場，根據法拉第定律提供額外電壓，而 CoT 則建模為串聯電阻，以根據歐姆定律約束模型輸出效能。實驗結果表明，ECM 有效預測和解釋了 LLM 在各種提示策略中的效能。此外，我們將 ECM 應用於一系列任務的高級推理策略最佳化，例如國際資訊奧林匹克競賽 (IOI) 和國際數學奧林匹克競賽 (IMO)，取得了優於近 80% 頂尖人類競爭者的競爭性效能。

##### **Out-of-Distribution Detection using Synthetic Data Generation**
2502.03323v1 by Momin Abbas, Muneeza Azmat, Raya Horesh, Mikhail Yurochkin

Distinguishing in- and out-of-distribution (OOD) inputs is crucial for
reliable deployment of classification systems. However, OOD data is typically
unavailable or difficult to collect, posing a significant challenge for
accurate OOD detection. In this work, we present a method that harnesses the
generative capabilities of Large Language Models (LLMs) to create high-quality
synthetic OOD proxies, eliminating the dependency on any external OOD data
source. We study the efficacy of our method on classical text classification
tasks such as toxicity detection and sentiment classification as well as
classification tasks arising in LLM development and deployment, such as
training a reward model for RLHF and detecting misaligned generations.
Extensive experiments on nine InD-OOD dataset pairs and various model sizes
show that our approach dramatically lowers false positive rates (achieving a
perfect zero in some cases) while maintaining high accuracy on in-distribution
tasks, outperforming baseline methods by a significant margin.

摘要：區分分佈內和分佈外 (OOD) 輸入對於分類系統的可靠部署至關重要。然而，OOD 資料通常不可用或難以收集，對準確的 OOD 偵測構成重大挑戰。在這項工作中，我們提出了一種利用大型語言模型 (LLM) 的生成能力來建立高品質的合成 OOD 代理的方法，消除了對任何外部 OOD 資料來源的依賴。我們研究了我們的方法在經典文字分類任務上的功效，例如毒性偵測和情緒分類，以及在 LLM 開發和部署中出現的分類任務，例如訓練 RLHF 的獎勵模型和偵測錯誤對齊的生成。在九個 InD-OOD 資料集配對和各種模型大小上的廣泛實驗表明，我們的做法大幅降低了假陽性率（在某些情況下達到完美的零），同時在分佈內任務上保持高準確度，大幅優於基準方法。

##### **Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques**
2502.03321v1 by Sangjun Han, Taeil Hur, Youngmi Hur, Kathy Sangkyung Lee, Myungyoon Lee, Hyojae Lim

The challenge of formal proof generation has a rich history, but with modern
techniques, we may finally be at the stage of making actual progress in
real-life mathematical problems. This paper explores the integration of ChatGPT
and basic searching techniques to simplify generating formal proofs, with a
particular focus on the miniF2F dataset. We demonstrate how combining a large
language model like ChatGPT with a formal language such as Lean, which has the
added advantage of being verifiable, enhances the efficiency and accessibility
of formal proof generation. Despite its simplicity, our best-performing
Lean-based model surpasses all known benchmarks with a 31.15% pass rate. We
extend our experiments to include other datasets and employ alternative
language models, showcasing our models' comparable performance in diverse
settings and allowing for a more nuanced analysis of our results. Our findings
offer insights into AI-assisted formal proof generation, suggesting a promising
direction for future research in formal mathematical proof.

摘要：形式化證明產生的挑戰有著豐富的歷史，但透過現代技術，我們可能終於能實際進展到解決現實生活中數學問題的階段。本文探討了整合 ChatGPT 和基本搜尋技術以簡化形式化證明產生的方法，特別專注於 miniF2F 資料集。我們展示了如何將大型語言模型（例如 ChatGPT）與形式語言（例如 Lean）結合，而 Lean 的額外優勢在於可驗證，這能提升形式化證明產生的效率和可及性。儘管我們的模型很簡單，但我們效能最好的基於 Lean 的模型超越了所有已知基準，通過率達 31.15%。我們擴展我們的實驗，納入其他資料集，並採用其他語言模型，展示了我們的模型在不同設定中的可比效能，並允許對我們的結果進行更細緻的分析。我們的研究結果提供了對 AI 輔助形式化證明產生的見解，為形式化數學證明中的未來研究指出了有希望的方向。

##### **Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning**
2502.03304v1 by Qitao Tan, Jun Liu, Zheng Zhan, Caiwei Ding, Yanzhi Wang, Jin Lu, Geng Yuan

Large language models (LLMs) excel across various tasks, but standard
first-order (FO) fine-tuning demands considerable memory, significantly
limiting real-world deployment. Recently, zeroth-order (ZO) optimization stood
out as a promising memory-efficient training paradigm, avoiding backward passes
and relying solely on forward passes for gradient estimation, making it
attractive for resource-constrained scenarios. However, ZO method lags far
behind FO method in both convergence speed and accuracy. To bridge the gap, we
introduce a novel layer-wise divergence analysis that uncovers the distinct
update pattern of FO and ZO optimization. Aiming to resemble the learning
capacity of FO method from the findings, we propose \textbf{Di}vergence-driven
\textbf{Z}eroth-\textbf{O}rder (\textbf{DiZO}) optimization. DiZO conducts
divergence-driven layer adaptation by incorporating projections to ZO updates,
generating diverse-magnitude updates precisely scaled to layer-wise individual
optimization needs. Our results demonstrate that DiZO significantly reduces the
needed iterations for convergence without sacrificing throughput, cutting
training GPU hours by up to 48\% on various datasets. Moreover, DiZO
consistently outperforms the representative ZO baselines in fine-tuning
RoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some
cases, even surpasses memory-intensive FO fine-tuning.

摘要：大型语言模型 (LLM) 在各种任务中表现出色，但标准
一阶 (FO) 微调需要大量的内存，极大地
限制了实际部署。最近，零阶 (ZO) 优化作为一种有前途的省内存训练范例脱颖而出，它避免了反向传递
并且仅依靠前向传递进行梯度估计，使其
适用于资源受限的场景。然而，ZO 方法在收敛速度和准确性方面都远远落后于 FO 方法。为了弥补这一差距，我们
引入了一种新颖的逐层差异分析，揭示了 FO 和 ZO 优化不同的更新模式。为了从研究结果中体现 FO 方法的学习能力，我们提出了\textbf{Di}vergence-driven
\textbf{Z}eroth-\textbf{O}rder (\textbf{DiZO}) 优化。DiZO 通过将投影合并到 ZO 更新中来进行差异驱动的层适应，
生成与逐层个体优化需求精确匹配的不同幅度更新。我们的结果表明，DiZO 显着减少了收敛所需的迭代次数，而不会牺牲吞吐量，将各种数据集上的训练 GPU 小时数减少了 48%。此外，DiZO
在对 RoBERTa-large、OPT 系列和 Llama 系列进行微调时，始终优于有代表性的 ZO 基线
在下游任务中，在某些情况下，甚至超过了需要大量内存的 FO 微调。

##### **MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**
2502.03298v1 by Amin Dada, Osman Alperen Koras, Marie Bauer, Amanda Butler, Kaleb E. Smith, Jens Kleesiek, Julian Friedrich

While increasing patients' access to medical documents improves medical care,
this benefit is limited by varying health literacy levels and complex medical
terminology. Large language models (LLMs) offer solutions by simplifying
medical information. However, evaluating LLMs for safe and patient-friendly
text generation is difficult due to the lack of standardized evaluation
resources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset
created from MIMIC-IV discharge summaries through an automated pipeline
combining LLM-based question-answer generation with manual quality checks. We
use this dataset to evaluate various LLMs on patient-oriented
question-answering. Our findings reveal that general-purpose LLMs frequently
surpass biomedical-adapted models, while automated metrics correlate with human
judgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the
development of LLMs to enhance patient understanding and ultimately improve
care outcomes.

摘要：儘管讓患者更能取得醫療文件有助於改善醫療照護，
但此優點受到不同的健康素養程度和複雜的醫療術語所限制。大型語言模型 (LLM) 提供了簡化醫療資訊的解決方案。然而，由於缺乏標準化的評估資源，因此難以評估 LLM 以確保其安全且對患者友善的文字產生。為了填補此缺口，我們開發了 MeDiSumQA。MeDiSumQA 是透過自動化流程從 MIMIC-IV 出院摘要中建立的資料集，結合了基於 LLM 的問答產生和手動品質檢查。我們使用此資料集來評估各種 LLM 在以患者為導向的問答中。我們的發現顯示，通用 LLM 經常超越生物醫學適應模型，而自動化指標與人類判斷相關。透過在 PhysioNet 上發布 MeDiSumQA，我們旨在推動 LLM 的發展，以增進患者理解，並最終改善照護成果。

##### **ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages**
2502.03292v1 by Aida Halitaj, Arkaitz Zubiaga

Citation Worthiness Detection (CWD) consists in determining which sentences,
within an article or collection, should be backed up with a citation to
validate the information it provides. This study, introduces ALPET, a framework
combining Active Learning (AL) and Pattern-Exploiting Training (PET), to
enhance CWD for languages with limited data resources. Applied to Catalan,
Basque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCW
baseline while reducing the amount of labeled data in some cases above 80\%.
ALPET's performance plateaus after 300 labeled samples, showing it suitability
for low-resource scenarios where large, labeled datasets are not common. While
specific active learning query strategies, like those employing K-Means
clustering, can offer advantages, their effectiveness is not universal and
often yields marginal gains over random sampling, particularly with smaller
datasets. This suggests that random sampling, despite its simplicity, remains a
strong baseline for CWD in constraint resource environments. Overall, ALPET's
ability to achieve high performance with fewer labeled samples makes it a
promising tool for enhancing the verifiability of online content in
low-resource language settings.

摘要：引文價值檢測 (CWD) 包含在文章或彙編中，決定哪些句子應以引文佐證，以驗證其提供的資訊。本研究引入了 ALPET，一個結合主動學習 (AL) 和模式開發訓練 (PET) 的架構，以加強資料資源有限的語言的 CWD。應用於加泰隆尼亞語、巴斯克語和阿爾巴尼亞語維基百科資料集，ALPET 在某些情況下優於現有的 CCW 基準，同時減少了標記資料的數量超過 80%。ALPET 的效能於 300 個標記範例後達到平穩期，顯示其適用於大型標記資料集不常見的低資源場景。雖然具體的主動學習查詢策略，例如採用 K-Means 聚類的策略，可以提供優勢，但其有效性並非普遍，而且通常會在隨機抽樣中產生邊際收益，特別是在較小的資料集中。這表明隨機抽樣，儘管其簡單性，仍然是約束資源環境中 CWD 的強大基準。總體而言，ALPET 在較少的標記範例中就能實現高效能的能力，使其成為在低資源語言設定中增強線上內容可驗證性的有前途的工具。

##### **STEM: Spatial-Temporal Mapping Tool For Spiking Neural Networks**
2502.03287v1 by Sherif Eissa, Sander Stuijk, Floran De Putter, Andrea Nardi-Dei, Federico Corradi, Henk Corporaal

Spiking Neural Networks (SNNs) are promising bio-inspired third-generation
neural networks. Recent research has trained deep SNN models with accuracy on
par with Artificial Neural Networks (ANNs). Although the event-driven and
sparse nature of SNNs show potential for more energy efficient computation than
ANNs, SNN neurons have internal states which evolve over time. Keeping track of
SNN states can significantly increase data movement and storage requirements,
potentially losing its advantages with respect to ANNs. This paper investigates
the energy effects of having neuron states, and how it is influenced by the
chosen mapping to realistic hardware architectures with advanced memory
hierarchies. Therefore, we develop STEMS, a mapping design space exploration
tool for SNNs. STEMS models SNN's stateful behavior and explores intra-layer
and inter-layer mapping optimizations to minimize data movement, considering
both spatial and temporal SNN dimensions. Using STEMS, we show up to 12x
reduction in off-chip data movement and 5x reduction in energy (on top of
intra-layer optimizations), on two event-based vision SNN benchmarks. Finally,
neuron states may not be needed for all SNN layers. By optimizing neuron states
for one of our benchmarks, we show 20x reduction in neuron states and 1.4x
better performance without accuracy loss.

摘要：尖峰神经網路 (SNN) 是有前途的生物啟發第三代神經網路。最近的研究已經訓練出具有與人工神經網路 (ANN) 相當精確度的深度 SNN 模型。儘管 SNN 的事件驅動和稀疏性質顯示出比 ANN 更節能運算的潛力，但 SNN 神經元具有會隨著時間演變的內部狀態。追蹤 SNN 狀態會顯著增加資料移動和儲存需求，可能會失去其相對於 ANN 的優勢。本文探討了神經元狀態的能量效應，以及它如何受到映射到具有先進記憶體層級結構的實際硬體架構的影響。因此，我們開發了 STEMS，這是一個 SNN 的映射設計空間探索工具。STEMS 對 SNN 的狀態行為建模，並探索層內和層間映射最佳化，以最小化資料移動，同時考慮空間和時間 SNN 維度。使用 STEMS，我們展示了在兩個基於事件的視覺 SNN 基準上，晶片外資料移動減少了 12 倍，能量減少了 5 倍（在層內最佳化之上）。最後，並非所有 SNN 層都需要神經元狀態。通過最佳化其中一個基準的神經元狀態，我們展示了神經元狀態減少了 20 倍，效能提升了 1.4 倍，而沒有準確度損失。

##### **SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**
2502.03283v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng, Wotao Yin

Recent advancements have highlighted that Large Language Models (LLMs) are
prone to hallucinations when solving complex reasoning problems, leading to
erroneous results. To tackle this issue, researchers incorporate Knowledge
Graphs (KGs) to improve the reasoning ability of LLMs. However, existing
methods face two limitations: 1) they typically assume that all answers to the
questions are contained in KGs, neglecting the incompleteness issue of KGs, and
2) they treat the KG as a static repository and overlook the implicit logical
reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an
innovative neural-symbolic agent framework that achieves collaborative
augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments
and transform complex reasoning tasks into a multi-step interactive process,
enabling KGs to participate deeply in the reasoning process. SymAgent consists
of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages
LLM's inductive reasoning capability to extract symbolic rules from KGs,
guiding efficient question decomposition. The Agent-Executor autonomously
invokes predefined action tools to integrate information from KGs and external
documents, addressing the issues of KG incompleteness. Furthermore, we design a
self-learning framework comprising online exploration and offline iterative
policy updating phases, enabling the agent to automatically synthesize
reasoning trajectories and improve performance. Experimental results
demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields
better or comparable performance compared to various strong baselines. Further
analysis reveals that our agent can identify missing triples, facilitating
automatic KG updates.

摘要：<paragraph>最近的研究表明，大型语言模型 (LLM) 在解决复杂的推理问题时容易出现幻觉，从而导致错误的结果。为了解决这个问题，研究人员结合了知识图谱 (KG) 来提高 LLM 的推理能力。然而，现有方法面临两个局限性：1) 它们通常假设问题的答案都包含在 KG 中，忽略了 KG 不完整的问题，2) 它们将 KG 视为一个静态存储库，而忽略了 KG 中固有的隐式逻辑推理结构。在本文中，我们介绍了 SymAgent，这是一个创新的神经符号代理框架，可以在 KG 和 LLM 之间实现协作增强。我们将 KG 概念化为动态环境，并将复杂的推理任务转化为一个多步骤的交互过程，使 KG 能够深入参与推理过程。SymAgent 由两个模块组成：Agent-Planner 和 Agent-Executor。Agent-Planner 利用 LLM 的归纳推理能力从 KG 中提取符号规则，指导高效的问题分解。Agent-Executor 自主调用预定义的动作工具来整合来自 KG 和外部文档的信息，解决 KG 不完整的问题。此外，我们设计了一个自学习框架，包括在线探索和离线迭代策略更新阶段，使代理能够自动合成推理轨迹并提高性能。实验结果表明，具有弱 LLM 主干的 SymAgent（即 7B 系列）与各种强大的基线相比，产生了更好或相当的性能。进一步的分析表明，我们的代理可以识别缺失的三元组，促进自动 KG 更新。</paragraph>

##### **Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning**
2502.03275v1 by DiJia Su, Hanlin Zhu, Yingchen Xu, Jiantao Jiao, Yuandong Tian, Qinqing Zheng

Large Language Models (LLMs) excel at reasoning and planning when trained on
chainof-thought (CoT) data, where the step-by-step thought process is
explicitly outlined by text tokens. However, this results in lengthy inputs
where many words support textual coherence rather than core reasoning
information, and processing these inputs consumes substantial computation
resources. In this work, we propose a hybrid representation of the reasoning
process, where we partially abstract away the initial reasoning steps using
latent discrete tokens generated by VQ-VAE, significantly reducing the length
of reasoning traces. We explore the use of latent trace abstractions in two
scenarios: 1) training the model from scratch for the Keys-Finding Maze
problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary
including unseen latent tokens, for both logical and mathematical reasoning
problems. To facilitate effective learning, we introduce a simple training
procedure that randomly mixes latent and text tokens, which enables fast
adaptation to new latent tokens. Our approach consistently outperforms the
baselines methods in various benchmarks.

摘要：大型語言模型 (LLM) 在鏈式思考 (CoT) 資料上訓練時，在推理和規劃方面表現出色，其中逐步的思考過程由文字符號明確概述。然而，這會導致冗長的輸入，其中許多字詞支持文字連貫性，而不是核心推理資訊，而處理這些輸入會消耗大量的計算資源。在這項工作中，我們提出了一種推理過程的混合表示，其中我們使用 VQ-VAE 生成的潛在離散符號部分抽象出最初的推理步驟，顯著減少了推理軌跡的長度。我們在兩個場景中探討了潛在軌跡抽象的用途：1) 從頭開始訓練模型以解決尋鑰迷宮問題，2) 使用包含未見潛在符號的擴充詞彙微調 LLM，用於邏輯和數學推理問題。為了促進有效學習，我們引入了一個簡單的訓練程序，隨機混合潛在符號和文字符號，這使得能夠快速適應新的潛在符號。我們的做法在各種基準測試中始終優於基準方法。

##### **Efficient extraction of medication information from clinical notes: an evaluation in two languages**
2502.03257v1 by Thibaut Fabacher, Erik-André Sauleau, Emmanuelle Arcay, Bineta Faye, Maxime Alter, Archia Chahard, Nathan Miraillet, Adrien Coulet, Aurélie Névéol

Objective: To evaluate the accuracy, computational cost and portability of a
new Natural Language Processing (NLP) method for extracting medication
information from clinical narratives. Materials and Methods: We propose an
original transformer-based architecture for the extraction of entities and
their relations pertaining to patients' medication regimen. First, we used this
approach to train and evaluate a model on French clinical notes, using a newly
annotated corpus from H\^opitaux Universitaires de Strasbourg. Second, the
portability of the approach was assessed by conducting an evaluation on
clinical documents in English from the 2018 n2c2 shared task. Information
extraction accuracy and computational cost were assessed by comparison with an
available method using transformers. Results: The proposed architecture
achieves on the task of relation extraction itself performance that are
competitive with the state-of-the-art on both French and English (F-measures
0.82 and 0.96 vs 0.81 and 0.95), but reduce the computational cost by 10.
End-to-end (Named Entity recognition and Relation Extraction) F1 performance is
0.69 and 0.82 for French and English corpus. Discussion: While an existing
system developed for English notes was deployed in a French hospital setting
with reasonable effort, we found that an alternative architecture offered
end-to-end drug information extraction with comparable extraction performance
and lower computational impact for both French and English clinical text
processing, respectively. Conclusion: The proposed architecture can be used to
extract medication information from clinical text with high performance and low
computational cost and consequently suits with usually limited hospital IT
resources

摘要：<paragraph>目標：評估一種新的自然語言處理 (NLP) 方法的準確度、計算成本和可移植性，以從臨床敘述中提取藥物資訊。材料和方法：我們提出一個基於變換器的原始架構，用於提取實體及其與患者用藥方案相關的關係。首先，我們使用此方法訓練並評估法語臨床筆記上的模型，使用來自史特拉斯堡大學醫院的新註釋語料庫。其次，通過對 2018 n2c2 共享任務中的英語臨床文件進行評估，評估了該方法的可移植性。透過與使用變換器的可用方法進行比較，評估資訊提取準確度和計算成本。結果：所提出的架構在關係提取任務本身的表現上，在法語和英語上都與最先進的技術競爭（F 值 0.82 和 0.96 對比 0.81 和 0.95），但將計算成本降低了 10。端到端（命名實體識別和關係提取）F1 效能對於法語和英語語料庫分別為 0.69 和 0.82。討論：儘管為英語筆記開發的現有系統已在法語醫院環境中部署，且付出了合理的努力，但我們發現一種替代架構提供了端到端的藥物資訊提取，且對於法語和英語臨床文本處理而言，具有可比較的提取效能和較低的計算影響。結論：所提出的架構可用於從臨床文本中提取藥物資訊，且效能高、計算成本低，因此適用於通常有限的醫院 IT 資源</paragraph>

##### **How do Humans and Language Models Reason About Creativity? A Comparative Analysis**
2502.03253v1 by Antonio Laverghetta Jr., Tuhin Chakrabarty, Tom Hope, Jimmy Pronchick, Krupa Bhawsar, Roger E. Beaty

Creativity assessment in science and engineering is increasingly based on
both human and AI judgment, but the cognitive processes and biases behind these
evaluations remain poorly understood. We conducted two experiments examining
how including example solutions with ratings impact creativity evaluation,
using a finegrained annotation protocol where raters were tasked with
explaining their originality scores and rating for the facets of remoteness
(whether the response is "far" from everyday ideas), uncommonness (whether the
response is rare), and cleverness. In Study 1, we analyzed creativity ratings
from 72 experts with formal science or engineering training, comparing those
who received example solutions with ratings (example) to those who did not (no
example). Computational text analysis revealed that, compared to experts with
examples, no-example experts used more comparative language (e.g.,
"better/worse") and emphasized solution uncommonness, suggesting they may have
relied more on memory retrieval for comparisons. In Study 2, parallel analyses
with state-of-the-art LLMs revealed that models prioritized uncommonness and
remoteness of ideas when rating originality, suggesting an evaluative process
rooted around the semantic similarity of ideas. In the example condition, while
LLM accuracy in predicting the true originality scores improved, the
correlations of remoteness, uncommonness, and cleverness with originality also
increased substantially - to upwards of 0.99 - suggesting a homogenization in
the LLMs evaluation of the individual facets. These findings highlight
important implications for how humans and AI reason about creativity and
suggest diverging preferences for what different populations prioritize when
rating.

摘要：科學和工程領域的創意評量越來越依賴人類和 AI 的判斷，但這些評量的認知過程和偏見仍鮮為人知。我們進行了兩個實驗，探討包含評分範例解題對創意評量的影響，並使用細緻的註解協定，要求評分者說明其獨創性分數，並評分其偏遠性（回應是否「遠離」日常想法）、罕見性（回應是否罕見）和靈巧性。在研究 1 中，我們分析了 72 位具有正式科學或工程訓練的專家的創意評分，比較了收到評分範例解題的專家（範例組）和未收到範例解題的專家（非範例組）。計算文本分析顯示，與有範例組專家相比，非範例組專家使用了更多的比較語言（例如「較好/較差」），並強調解題的罕見性，這表明他們可能更多地依賴記憶檢索進行比較。在研究 2 中，與最先進的 LLM 進行的平行分析顯示，模型在評分獨創性時優先考慮想法的罕見性和偏遠性，這表明評估過程植基於想法的語義相似性。在範例條件下，儘管 LLM 在預測真實獨創性分數方面的準確性有所提高，但偏遠性、罕見性和靈巧性與獨創性的相關性也大幅增加，高達 0.99，這表明 LLM 對個別方面的評估趨於同質化。這些發現突顯了人類和 AI 如何推理創意以及在評分時不同族群優先考量事項存在分歧的重要意義。

##### **A scale of conceptual orality and literacy: Automatic text categorization in the tradition of "Nähe und Distanz"**
2502.03252v1 by Volker Emmrich

Koch and Oesterreicher's model of "N\"ahe und Distanz" (N\"ahe = immediacy,
conceptual orality; Distanz = distance, conceptual literacy) is constantly used
in German linguistics. However, there is no statistical foundation for use in
corpus linguistic analyzes, while it is increasingly moving into empirical
corpus linguistics. Theoretically, it is stipulated, among other things, that
written texts can be rated on a scale of conceptual orality and literacy by
linguistic features. This article establishes such a scale based on PCA and
combines it with automatic analysis. Two corpora of New High German serve as
examples. When evaluating established features, a central finding is that
features of conceptual orality and literacy must be distinguished in order to
rank texts in a differentiated manner. The scale is also discussed with a view
to its use in corpus compilation and as a guide for analyzes in larger corpora.
With a theory-driven starting point and as a "tailored" dimension, the approach
compared to Biber's Dimension 1 is particularly suitable for these supporting,
controlling tasks.

摘要：Koch 和 Oesterreicher 的「N\"ahe und Distanz」模型（N\"ahe = 直接性、概念口語；Distanz = 距離、概念識字）在德語語言學中不斷被使用。然而，在語料庫語言分析中使用它並無統計基礎，而它卻日益進入經驗語料庫語言學。在理論上，規定了以下事項，其中包括，書面文本可透過語言特徵在概念口語和識字的範圍內評分。本文建立了一個基於 PCA 的量表，並將其與自動分析結合起來。兩個新高地德語語料庫作為範例。在評估既定特徵時，一個重要的發現是，必須區分概念口語和識字的特徵，才能以有差別的方式對文本進行排名。量表也針對其在語料庫編纂中的使用，以及作為大型語料庫中分析指南進行討論。與 Biber 的第 1 維度相比，這種方法以理論驅動的起點和「客製化」維度特別適合這些支援、控制任務。

##### **The Other Side of the Coin: Unveiling the Downsides of Model Aggregation in Federated Learning from a Layer-peeled Perspective**
2502.03231v1 by Guogang Zhu, Xuefeng Liu, Jianwei Niu, Shaojie Tang, Xinghao Wu

In federated learning (FL), model aggregation is a critical step by which
multiple clients share their knowledge with one another. However, it is also
widely recognized that the aggregated model, when sent back to each client,
performs poorly on local data until after several rounds of local training.
This temporary performance drop can potentially slow down the convergence of
the FL model. Most research in FL regards this performance drop as an inherent
cost of knowledge sharing among clients and does not give it special attention.
While some studies directly focus on designing techniques to alleviate the
issue, an in-depth investigation of the reasons behind this performance drop
has yet to be conducted.To address this gap, we conduct a layer-peeled analysis
of model aggregation across various datasets and model architectures. Our
findings reveal that the performance drop can be attributed to two major
consequences of the aggregation process: (1) it disrupts feature variability
suppression in deep neural networks (DNNs), and (2) it weakens the coupling
between features and subsequent parameters.Based on these findings, we propose
several simple yet effective strategies to mitigate the negative impacts of
model aggregation while still enjoying the benefit it brings. To the best of
our knowledge, our work is the first to conduct a layer-peeled analysis of
model aggregation, potentially paving the way for the development of more
effective FL algorithms.

摘要：在聯合學習 (FL) 中，模型聚合是一個關鍵步驟，多個客戶透過此步驟分享彼此的知識。然而，眾所周知，聚合模型在傳回給每個客戶時，在經過幾輪的本地訓練之前，在本地資料的表現不佳。這種暫時的效能下降可能會減緩 FL 模型的收斂速度。FL 中的大部分研究將此效能下降視為客戶間知識共享的固有成本，並沒有特別關注它。雖然有些研究直接專注於設計技術來緩解此問題，但對於效能下降背後原因的深入調查尚未進行。為了解決這個差距，我們對跨各種資料集和模型架構的模型聚合進行了逐層分析。我們的研究結果顯示，效能下降可歸因於聚合過程的兩個主要後果：(1) 它會中斷深度神經網路 (DNN) 中的特徵變異抑制，以及 (2) 它會削弱特徵與後續參數之間的耦合。根據這些發現，我們提出了幾個簡單但有效的策略，以減輕模型聚合的負面影響，同時仍享受它帶來的優點。據我們所知，我們的工作是第一個對模型聚合進行逐層分析，這可能會為開發更有效的 FL 演算法鋪路。

##### **Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform Perspective**
2502.03220v1 by Napat Laosaengpha, Thanit Tativannarat, Attapol Rutherford, Ekapol Chuangsuwanich

Understanding the textual components of resumes and job postings is critical
for improving job-matching accuracy and optimizing job search systems in online
recruitment platforms. However, existing works primarily focus on analyzing
individual components within this information, requiring multiple specialized
tools to analyze each aspect. Such disjointed methods could potentially hinder
overall generalizability in recruitment-related text processing. Therefore, we
propose a unified sentence encoder that utilized multi-task dual-encoder
framework for jointly learning multiple component into the unified sentence
encoder. The results show that our method outperforms other state-of-the-art
models, despite its smaller model size. Moreover, we propose a novel metric,
Language Bias Kullback-Leibler Divergence (LBKL), to evaluate language bias in
the encoder, demonstrating significant bias reduction and superior
cross-lingual performance.

摘要：了解履歷和職位發布的文字成分對於提升職缺配對的準確性，並最佳化線上徵才平台的職缺搜尋系統至關重要。然而，現有的研究主要專注於分析此資訊中的個別成分，需要多種專業工具來分析每個面向。這種不連貫的方法可能會阻礙與徵才相關的文字處理的整體概括性。因此，我們提出一個統一的句子編碼器，它利用多任務雙編碼器架構，將多個成分聯合學習到統一的句子編碼器中。結果顯示，儘管我們的模型較小，但其表現優於其他最先進的模型。此外，我們提出一個新穎的指標，語言偏誤 Kullback-Leibler 距離 (LBKL)，以評估編碼器中的語言偏誤，證明了顯著的偏誤降低和優異的跨語言效能。

##### **iVISPAR -- An Interactive Visual-Spatial Reasoning Benchmark for VLMs**
2502.03214v1 by Julius Mayer, Mohamad Ballout, Serwan Jassim, Farbod Nosrat Nezami, Elia Bruni

Vision-Language Models (VLMs) are known to struggle with spatial reasoning
and visual alignment. To help overcome these limitations, we introduce iVISPAR,
an interactive multi-modal benchmark designed to evaluate the spatial reasoning
capabilities of VLMs acting as agents. iVISPAR is based on a variant of the
sliding tile puzzle-a classic problem that demands logical planning, spatial
awareness, and multi-step reasoning. The benchmark supports visual 2D, 3D, and
text-based input modalities, enabling comprehensive assessments of VLMs'
planning and reasoning skills. We evaluate a broad suite of state-of-the-art
open-source and closed-source VLMs, comparing their performance while also
providing optimal path solutions and a human baseline to assess the task's
complexity and feasibility for humans. Results indicate that while some VLMs
perform well on simple spatial tasks, they encounter difficulties with more
complex configurations and problem properties. Notably, while VLMs generally
perform better in 2D vision compared to 3D or text-based representations, they
consistently fall short of human performance, illustrating the persistent
challenge of visual alignment. This highlights critical gaps in current VLM
capabilities, highlighting their limitations in achieving human-level
cognition.

摘要：視覺語言模型 (VLM) 已知在空間推理和視覺對齊方面有困難。為了幫助克服這些限制，我們引入了 iVISPAR，一個互動的多模態基準，用於評估作為代理的 VLM 的空間推理能力。iVISPAR 基於滑動拼圖的變體，這是一個經典問題，需要邏輯規劃、空間感知和多步驟推理。基準支持視覺 2D、3D 和基於文本的輸入模式，從而能夠全面評估 VLM 的規劃和推理技能。我們評估了一系列最先進的開源和閉源 VLM，比較了它們的性能，同時還提供了最佳路徑解決方案和人類基準，以評估任務對人類的複雜性和可行性。結果表明，雖然一些 VLM 在簡單的空間任務中表現良好，但它們在更複雜的配置和問題屬性中會遇到困難。值得注意的是，雖然 VLM 在 2D 視覺中通常比 3D 或基於文本的表示表現得更好，但它們始終低於人類表現，說明視覺對齊的持續挑戰。這突顯了當前 VLM 能力中的關鍵差距，突顯了它們在實現人類級認知方面的局限性。

##### **CORTEX: A Cost-Sensitive Rule and Tree Extraction Method**
2502.03200v1 by Marija Kopanja, Miloš Savić, Luca Longo

Tree-based and rule-based machine learning models play pivotal roles in
explainable artificial intelligence (XAI) due to their unique ability to
provide explanations in the form of tree or rule sets that are easily
understandable and interpretable, making them essential for applications in
which trust in model decisions is necessary. These transparent models are
typically used in surrogate modeling, a post-hoc XAI approach for explaining
the logic of black-box models, enabling users to comprehend and trust complex
predictive systems while maintaining competitive performance. This study
proposes the Cost-Sensitive Rule and Tree Extraction (CORTEX) method, a novel
rule-based XAI algorithm grounded in the multi-class cost-sensitive decision
tree (CSDT) method. The original version of the CSDT is extended to
classification problems with more than two classes by inducing the concept of
an n-dimensional class-dependent cost matrix. The performance of CORTEX as a
rule-extractor XAI method is compared to other post-hoc tree and rule
extraction methods across several datasets with different numbers of classes.
Several quantitative evaluation metrics are employed to assess the
explainability of generated rule sets. Our findings demonstrate that CORTEX is
competitive with other tree-based methods and can be superior to other
rule-based methods across different datasets. The extracted rule sets suggest
the advantages of using the CORTEX method over other methods by producing
smaller rule sets with shorter rules on average across datasets with a diverse
number of classes. Overall, the results underscore the potential of CORTEX as a
powerful XAI tool for scenarios that require the generation of clear,
human-understandable rules while maintaining good predictive performance.

摘要：<paragraph>基於樹和基於規則的機器學習模型在可解釋人工智慧 (XAI) 中扮演著舉足輕重的角色，因為它們有獨特的能力，可以提供樹或規則集形式的解釋，這些解釋容易理解和詮釋，這使得它們對於在其中需要信任模型決策的應用程式中至關重要。這些透明模型通常用於代理模型，這是一種事後 XAI 方法，用於解釋黑盒模型的邏輯，使用戶能夠理解和信任複雜的預測系統，同時保持競爭力。本研究提出成本敏感規則和樹萃取 (CORTEX) 方法，這是一種新的基於規則的 XAI 演算法，植基於多類成本敏感決策樹 (CSDT) 方法。CSDT 的原始版本已擴充到具有兩個以上類別的分類問題，方法是引入 n 維類別依賴成本矩陣的概念。將 CORTEX 作為規則萃取 XAI 方法的效能與其他事後樹和規則萃取方法進行比較，這些方法跨越了具有不同類別數量的幾個資料集。採用多個量化評估指標來評估所產生的規則集的可解釋性。我們的研究結果表明，CORTEX 與其他基於樹的方法具有競爭力，並且在不同的資料集上可以優於其他基於規則的方法。萃取的規則集建議，在具有不同類別數量的資料集上，與其他方法相比，使用 CORTEX 方法的優點是產生較小的規則集，且平均而言具有較短的規則。總體而言，這些結果強調了 CORTEX 作為一種強大的 XAI 工具的潛力，適用於需要產生清晰、人類可理解的規則，同時保持良好的預測效能的場景。</paragraph>

##### **Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large Language Models**
2502.03199v1 by Jialiang Wu, Yi Shen, Sijia Liu, Yi Tang, Sen Song, Xiaoyi Wang, Longjun Cai

Despite their impressive capacities, Large language models (LLMs) often
struggle with the hallucination issue of generating inaccurate or fabricated
content even when they possess correct knowledge. In this paper, we extend the
exploration of the correlation between hidden-state prediction changes and
output factuality into a deeper, token-wise level. Based on the insights , we
propose cross-layer Entropy eNhanced Decoding (END), a decoding method that
mitigates hallucinations without requiring extra training. END leverages inner
probability changes across layers to individually quantify the factual
knowledge required for each candidate token, and adjusts the final predicting
distribution to prioritize tokens with higher factuality. Experiments on both
hallucination and QA benchmarks demonstrate that END significantly enhances the
truthfulness and informativeness of generated content while maintaining robust
QA accuracy. Moreover, our work provides a deeper perspective on understanding
the correlations between inherent knowledge and output factuality.

摘要：儘管大型語言模型 (LLM) 具有令人印象深刻的能力，但即使擁有正確的知識，它們也常常難以解決產生不準確或虛構內容的幻覺問題。在本文中，我們將探索隱藏狀態預測變化與輸出事實性之間的關聯，並延伸到更深入的代幣層級。根據這些見解，我們提出了跨層熵增強解碼 (END)，這是一種解碼方法，無需額外訓練即可減輕幻覺。END 利用跨層的內部機率變化來個別量化每個候選代幣所需的實際知識，並調整最終預測分佈以優先考慮具有較高事實性的代幣。在幻覺和問答基準上的實驗表明，END 大幅提升了生成內容的真實性和資訊性，同時維持穩健的問答準確度。此外，我們的研究提供了更深入的觀點來了解內在知識與輸出事實性之間的關聯。

##### **EuskañolDS: A Naturally Sourced Corpus for Basque-Spanish Code-Switching**
2502.03188v1 by Maite Heredia, Jeremy Barnes, Aitor Soroa

Code-switching (CS) remains a significant challenge in Natural Language
Processing (NLP), mainly due a lack of relevant data. In the context of the
contact between the Basque and Spanish languages in the north of the Iberian
Peninsula, CS frequently occurs in both formal and informal spontaneous
interactions. However, resources to analyse this phenomenon and support the
development and evaluation of models capable of understanding and generating
code-switched language for this language pair are almost non-existent. We
introduce a first approach to develop a naturally sourced corpus for
Basque-Spanish code-switching. Our methodology consists of identifying CS texts
from previously available corpora using language identification models, which
are then manually validated to obtain a reliable subset of CS instances. We
present the properties of our corpus and make it available under the name
Euska\~nolDS.

摘要：代碼切換 (CS) 仍然是自然語言處理 (NLP) 中的一項重大挑戰，這主要是由於缺乏相關數據。在伊比利半島北部巴斯克語和西班牙語接觸的背景下，CS 經常出現在正式和非正式的自然互動中。然而，幾乎沒有資源可以分析這種現象並支持能夠理解和生成此語言對的代碼切換語言的模型的開發和評估。我們提出了一種開發巴斯克語-西班牙語代碼切換自然採集語料庫的第一種方法。我們的做法包括使用語言識別模型從以前可用的語料庫中識別 CS 文本，然後手動驗證這些文本以獲得可靠的 CS 實例子集。我們展示了我們語料庫的屬性，並以 Euska\~nolDS 的名稱提供該語料庫。

##### **Scalable In-Context Learning on Tabular Data via Retrieval-Augmented Large Language Models**
2502.03147v1 by Xumeng Wen, Shun Zheng, Zhen Xu, Yiming Sun, Jiang Bian

Recent studies have shown that large language models (LLMs), when customized
with post-training on tabular data, can acquire general tabular in-context
learning (TabICL) capabilities. These models are able to transfer effectively
across diverse data schemas and different task domains. However, existing
LLM-based TabICL approaches are constrained to few-shot scenarios due to the
sequence length limitations of LLMs, as tabular instances represented in plain
text consume substantial tokens. To address this limitation and enable scalable
TabICL for any data size, we propose retrieval-augmented LLMs tailored to
tabular data. Our approach incorporates a customized retrieval module, combined
with retrieval-guided instruction-tuning for LLMs. This enables LLMs to
effectively leverage larger datasets, achieving significantly improved
performance across 69 widely recognized datasets and demonstrating promising
scaling behavior. Extensive comparisons with state-of-the-art tabular models
reveal that, while LLM-based TabICL still lags behind well-tuned numeric models
in overall performance, it uncovers powerful algorithms under limited contexts,
enhances ensemble diversity, and excels on specific datasets. These unique
properties underscore the potential of language as a universal and accessible
interface for scalable tabular data learning.

摘要：最近的研究表明，大型語言模型 (LLM) 在針對表格資料進行訓練後，可以獲得一般的表格情境學習 (TabICL) 能力。這些模型能夠有效地轉移到不同的資料架構和不同的任務領域。然而，現有的基於 LLM 的 TabICL 方法由於 LLM 的序列長度限制而受到少樣本場景的限制，因為以純文字表示的表格實例會消耗大量的符號。為了解決這個限制並為任何資料大小啟用可擴充的 TabICL，我們提出了針對表格資料量身打造的檢索增強 LLM。我們的做法結合了自訂的檢索模組，以及針對 LLM 的檢索引導指令微調。這使 LLM 能夠有效地利用更大的資料集，在 69 個廣泛認可的資料集上實現顯著的效能提升，並展示出有希望的擴充行為。與最先進的表格模型進行廣泛的比較表明，儘管基於 LLM 的 TabICL 在整體效能上仍落後於經過良好微調的數值模型，但它在有限的語境下揭示了強大的演算法，增強了整體多樣性，並在特定資料集上表現出色。這些獨特的特性強調了語言作為可擴充表格資料學習的通用且可存取介面的潛力。

##### **Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales**
2502.03129v1 by Zhen Qian, Xiuzhen Zhang, Xiaofei Xu, Feng Xia

Number-focused headline generation is a summarization task requiring both
high textual quality and precise numerical accuracy, which poses a unique
challenge for Large Language Models (LLMs). Existing studies in the literature
focus only on either textual quality or numerical reasoning and thus are
inadequate to address this challenge. In this paper, we propose a novel
chain-of-thought framework for using rationales comprising key elements of the
Topic, Entities, and Numerical reasoning (TEN) in news articles to enhance the
capability for LLMs to generate topic-aligned high-quality texts with precise
numerical accuracy. Specifically, a teacher LLM is employed to generate TEN
rationales as supervision data, which are then used to teach and fine-tune a
student LLM. Our approach teaches the student LLM automatic generation of
rationales with enhanced capability for numerical reasoning and topic-aligned
numerical headline generation. Experiments show that our approach achieves
superior performance in both textual quality and numerical accuracy.

摘要：數字導向的標題生成是一種摘要任務，既需要高文字品質，又需要精確的數字準確度，這對大型語言模型 (LLM) 構成獨特的挑戰。現有文獻中的研究僅專注於文字品質或數字推理，因此無法解決此挑戰。在本文中，我們提出一個新穎的思考鏈架構，用於使用新聞文章中主題、實體和數字推理 (TEN) 的關鍵元素組成的依據，以增強 LLM 生成與主題一致的高品質文本和精確數字準確度的能力。具體來說，採用教師 LLM 生成 TEN 依據作為監督資料，然後用於教授和微調學生 LLM。我們的做法教導學生 LLM 自動生成具有增強數字推理能力和與主題一致的數字標題生成的依據。實驗表明，我們的做法在文字品質和數字準確度方面都取得優異的表現。

##### **Metis: A Foundation Speech Generation Model with Masked Generative Pre-training**
2502.03128v1 by Yuancheng Wang, Jiachen Zheng, Junan Zhang, Xueyao Zhang, Huan Liao, Zhizheng Wu

We introduce Metis, a foundation model for unified speech generation. Unlike
previous task-specific or multi-task models, Metis follows a pre-training and
fine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data
using masked generative modeling and then fine-tuned to adapt to diverse speech
generation tasks. Specifically, 1) Metis utilizes two discrete speech
representations: SSL tokens derived from speech self-supervised learning (SSL)
features, and acoustic tokens directly quantized from waveforms. 2) Metis
performs masked generative pre-training on SSL tokens, utilizing 300K hours of
diverse speech data, without any additional condition. 3) Through fine-tuning
with task-specific conditions, Metis achieves efficient adaptation to various
speech generation tasks while supporting multimodal input, even when using
limited data and trainable parameters. Experiments demonstrate that Metis can
serve as a foundation model for unified speech generation: Metis outperforms
state-of-the-art task-specific or multi-task systems across five speech
generation tasks, including zero-shot text-to-speech, voice conversion, target
speaker extraction, speech enhancement, and lip-to-speech, even with fewer than
20M trainable parameters or 300 times less training data. Audio samples are are
available at https://metis-demo.github.io/.

摘要：<paragraph>我們介紹 Metis，一個用於統一語音生成的基礎模型。與先前的特定任務或多任務模型不同，Metis 遵循預訓練和微調範例。它使用遮蔽生成式模型在大量未標記語音資料上進行預訓練，然後進行微調以適應各種語音生成任務。具體來說，1）Metis 利用兩種離散語音表示：來自語音自我監督式學習 (SSL) 特徵的 SSL 代幣，以及直接從波形量化的聲學代幣。2）Metis 對 SSL 代幣執行遮蔽生成式預訓練，利用 300K 小時的各種語音資料，而無需任何額外條件。3）透過使用特定於任務的條件進行微調，Metis 能有效適應各種語音生成任務，同時支援多模態輸入，即使在使用有限的資料和可訓練參數時也是如此。實驗證明 Metis 可作為統一語音生成的基礎模型：Metis 在五項語音生成任務中優於最先進的特定任務或多任務系統，包括零次學習文字轉語音、語音轉換、目標說話者提取、語音增強和唇形轉語音，即使可訓練參數少於 20M 或訓練資料少 300 倍。音訊範例可在 https://metis-demo.github.io/ 取得。</paragraph>

##### **Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences**
2502.03123v1 by Xingshen Zhang, Shuangrong Liu, Xintao Lu, Chaoran Pang, Lin Wang, Bo Yang

In this study, Disentanglement in Difference(DiD) is proposed to address the
inherent inconsistency between the statistical independence of latent variables
and the goal of semantic disentanglement in disentanglement representation
learning. Conventional disentanglement methods achieve disentanglement
representation by improving statistical independence among latent variables.
However, the statistical independence of latent variables does not necessarily
imply that they are semantically unrelated, thus, improving statistical
independence does not always enhance disentanglement performance. To address
the above issue, DiD is proposed to directly learn semantic differences rather
than the statistical independence of latent variables. In the DiD, a Difference
Encoder is designed to measure the semantic differences; a contrastive loss
function is established to facilitate inter-dimensional comparison. Both of
them allow the model to directly differentiate and disentangle distinct
semantic factors, thereby resolving the inconsistency between statistical
independence and semantic disentanglement. Experimental results on the dSprites
and 3DShapes datasets demonstrate that the proposed DiD outperforms existing
mainstream methods across various disentanglement metrics.

摘要：在這項研究中，提出了差異中的解開糾葛（DiD）來解決潛在變量統計獨立性與解開糾葛表示學習中語義解開糾葛的目標之間的內在不一致性。傳統的解開糾葛方法通過改善潛在變量之間的統計獨立性來實現解開糾葛表示。然而，潛在變量的統計獨立性並不一定意味著它們在語義上無關，因此，改善統計獨立性並不總是能增強解開糾葛的性能。為了解決上述問題，提出了 DiD 來直接學習語義差異，而不是潛在變量的統計獨立性。在 DiD 中，設計了一個差異編碼器來測量語義差異；建立了一個對比損失函數來促進維度間比較。兩者都允許模型直接區分和解開糾葛不同的語義因素，從而解決統計獨立性和語義解開糾葛之間的不一致性。在 dSprites 和 3DShapes 數據集上的實驗結果表明，所提出的 DiD 在各種解開糾葛指標上優於現有的主流方法。

##### **At the Mahakumbh, Faith Met Tragedy: Computational Analysis of Stampede Patterns Using Machine Learning and NLP**
2502.03120v1 by Abhinav Pratap

This study employs machine learning, historical analysis, and natural
language processing (NLP) to examine recurring lethal stampedes at Indias mass
religious gatherings, focusing on the 2025 Mahakumbh tragedy in Prayagraj (48+
deaths) and its 1954 predecessor (700+ casualties). Through computational
modeling of crowd dynamics and administrative records, it investigates how
systemic vulnerabilities contribute to these disasters. Temporal trend analysis
identifies persistent choke points, with narrow riverbank access routes linked
to 92% of past stampede sites and lethal crowd densities (eight or more persons
per square meter) recurring during spiritually significant moments like Mauni
Amavasya. NLP analysis of seven decades of inquiry reports reveals cyclical
administrative failures, where VIP route prioritization diverted safety
resources in both 1954 and 2025, exacerbating fatalities. Statistical modeling
demonstrates how ritual urgency overrides risk perception, leading to panic
propagation patterns that mirror historical incidents. Findings support the
Institutional Amnesia Theory, highlighting how disaster responses remain
reactionary rather than preventive. By correlating archival patterns with
computational crowd behavior analysis, this study frames stampedes as a
collision of infrastructure limitations, socio spiritual urgency, and
governance inertia, challenging disaster discourse to address how spiritual
economies normalize preventable mortality.

摘要：本研究採用機器學習、歷史分析和自然語言處理 (NLP) 來檢視印度群眾宗教集會中反覆發生的致命踩踏事件，重點在於 2025 年普拉亞格大壺節悲劇（48 人以上死亡）及其 1954 年的前例（700 多人傷亡）。透過群眾動態的計算模型和行政記錄，它探討系統性漏洞如何導致這些災難。時間趨勢分析找出持續的瓶頸，其中狹窄的河岸通道與過去 92% 的踩踏地點有關，而致命的群眾密度（每平方公尺八人或更多）在靈性重要時刻（如毛尼阿瑪瓦斯亞）反覆發生。對七十年來的調查報告進行 NLP 分析，揭示了週期性的行政失靈，其中貴賓路線優先權在 1954 年和 2025 年都轉移了安全資源，加劇了死亡人數。統計模型說明了儀式緊迫性如何凌駕於風險認知，導致恐慌傳播模式反映歷史事件。研究結果支持制度失憶理論，強調災難應變仍是消極被動的，而非預防性的。透過將檔案模式與計算群眾行為分析相關聯，本研究將踩踏事件視為基礎設施限制、社會靈性緊迫性和治理慣性的碰撞，挑戰災難論述，以說明靈性經濟如何常態化可預防的死亡率。

##### **Tell2Reg: Establishing spatial correspondence between images by the same language prompts**
2502.03118v1 by Wen Yan, Qianye Yang, Shiqi Huang, Yipei Wang, Shonit Punwani, Mark Emberton, Vasilis Stavrinides, Yipeng Hu, Dean Barratt

Spatial correspondence can be represented by pairs of segmented regions, such
that the image registration networks aim to segment corresponding regions
rather than predicting displacement fields or transformation parameters. In
this work, we show that such a corresponding region pair can be predicted by
the same language prompt on two different images using the pre-trained large
multimodal models based on GroundingDINO and SAM. This enables a fully
automated and training-free registration algorithm, potentially generalisable
to a wide range of image registration tasks. In this paper, we present
experimental results using one of the challenging tasks, registering
inter-subject prostate MR images, which involves both highly variable intensity
and morphology between patients. Tell2Reg is training-free, eliminating the
need for costly and time-consuming data curation and labelling that was
previously required for this registration task. This approach outperforms
unsupervised learning-based registration methods tested, and has a performance
comparable to weakly-supervised methods. Additional qualitative results are
also presented to suggest that, for the first time, there is a potential
correlation between language semantics and spatial correspondence, including
the spatial invariance in language-prompted regions and the difference in
language prompts between the obtained local and global correspondences. Code is
available at https://github.com/yanwenCi/Tell2Reg.git.

摘要：空間對應可以用成對的分段區域表示，圖像配準網路旨在區分對應區域，而不是預測位移場或轉換參數。在本文中，我們展示了這種對應區域對可以使用預先訓練的基於 GroundingDINO 和 SAM 的大型多模態模型在兩個不同圖像上由相同的語言提示預測。這實現了一個完全自動且無需訓練的配準演算法，潛在地可概括到廣泛的圖像配準任務。在本文中，我們展示了使用其中一項具有挑戰性的任務，配準主體間前列腺 MR 影像的實驗結果，其中涉及患者之間高度可變的強度和形態。Tell2Reg 無需訓練，消除了此配準任務先前所需的昂貴且耗時的資料整理和標記。此方法優於已測試的無監督學習為基礎的配準方法，並且效能與弱監督方法相當。還提供了其他定性結果，表明首次存在語言語意和空間對應之間的潛在關聯性，包括語言提示區域中的空間不變性以及獲得的局部和全局對應之間的語言提示差異。程式碼可在 https://github.com/yanwenCi/Tell2Reg.git 取得。

##### **Policies and Evaluation for Online Meeting Summarization**
2502.03111v1 by Felix Schneider, Marco Turchi, Alex Waibel

With more and more meetings moving to a digital domain, meeting summarization
has recently gained interest in both academic and commercial research. However,
prior academic research focuses on meeting summarization as an offline task,
performed after the meeting concludes. In this paper, we perform the first
systematic study of online meeting summarization. For this purpose, we propose
several policies for conducting online summarization. We discuss the unique
challenges of this task compared to the offline setting and define novel
metrics to evaluate latency and partial summary quality. The experiments on the
AutoMin dataset show that 1) online models can produce strong summaries, 2) our
metrics allow a detailed analysis of different systems' quality-latency
trade-off, also taking into account intermediate outputs and 3) adaptive
policies perform better than fixed scheduled ones. These findings provide a
starting point for the wider research community to explore this important task.

摘要：隨著越來越多的會議轉移到數位領域，會議摘要最近在學術和商業研究中都引起興趣。然而，先前的學術研究將會議摘要視為離線任務，在會議結束後執行。在本文中，我們執行第一個線上會議摘要的系統性研究。為此，我們提出幾項進行線上摘要的政策。我們討論了與離線設定相比此任務的獨特挑戰，並定義了評估延遲和部分摘要品質的新穎指標。在 AutoMin 資料集上的實驗顯示，1) 線上模型可以產生強大的摘要，2) 我們的指標允許詳細分析不同系統的品質延遲權衡，同時也考慮中間輸出，以及 3) 適應性政策比固定的排程政策執行得更好。這些發現為廣大的研究社群提供一個起點，以探索這項重要的任務。

##### **Structured Token Retention and Computational Memory Paths in Large Language Models**
2502.03102v1 by Jonathan Delena, Augustin Moreau, Dominic Ravensdale, Frederick Chatterton

Memory retention mechanisms play a central role in determining the efficiency
of computational architectures designed for processing extended sequences.
Conventional methods for token management often impose fixed retention
thresholds or rely on uniform attention weight distributions, leading to
inefficient memory utilization and premature information loss in extended
sequence modeling. Structured Token Retention (STR) introduces a probabilistic
selection framework that dynamically adjusts token persistence based on
contextual significance, ensuring that computational resources are allocated to
semantically relevant elements. Computational Memory Paths (CMP) extend this
framework through hierarchical memory allocation, refining retention efficiency
through structured reallocation of token embeddings. Comparative assessments
against baseline models demonstrate that STR and CMP improve token survival
rates across long input sequences while reducing cumulative error propagation
across processing layers. Experimental results further indicate reductions in
computational overhead, improving inference speed without degrading contextual
coherence. Token distribution analyses reveal that structured memory allocation
prevents excessive redundancy in attention weight calculations, optimizing
information retrieval efficiency in large-scale generative architectures. The
integration of STR and CMP into an open-source model illustrates the
adaptability of structured memory retention methodologies, highlighting their
applicability in generative text processing, long-context comprehension, and
scalable sequence modeling.

摘要：記憶保留機制在決定為處理延伸序列而設計的計算架構的效率上扮演著核心角色。
用於代碼管理的傳統方法通常會施加固定的保留閾值或依賴於均勻的注意力權重分配，導致在延伸序列建模中記憶體使用效率低下和資訊過早流失。結構化代碼保留 (STR) 引進了一個機率性選擇架構，它會根據脈絡意義動態調整代碼持續性，確保計算資源被分配給具有語義相關性的元素。計算記憶體路徑 (CMP) 透過階層式記憶體配置延伸這個架構，透過代碼嵌入的結構化再配置提升保留效率。針對基準模型的比較評估顯示，STR 和 CMP 提升了在長輸入序列中代碼的存活率，同時減少了在處理層中累積的錯誤傳播。實驗結果進一步指出計算開銷的減少，在不降低脈絡一致性的情況下提升了推論速度。代碼分佈分析顯示，結構化記憶體配置防止了注意力權重計算中過度的冗餘，最佳化了大型生成架構中的資訊擷取效率。STR 和 CMP 整合到開源模型中說明了結構化記憶體保留方法的適應性，突顯了它們在生成文字處理、長脈絡理解和可擴充序列建模中的適用性。

##### **E-3SFC: Communication-Efficient Federated Learning with Double-way Features Synthesizing**
2502.03092v1 by Yuhao Zhou, Yuxin Tian, Mingjia Shi, Yuanxi Li, Yanan Sun, Qing Ye, Jiancheng Lv

The exponential growth in model sizes has significantly increased the
communication burden in Federated Learning (FL). Existing methods to alleviate
this burden by transmitting compressed gradients often face high compression
errors, which slow down the model's convergence. To simultaneously achieve high
compression effectiveness and lower compression errors, we study the gradient
compression problem from a novel perspective. Specifically, we propose a
systematical algorithm termed Extended Single-Step Synthetic Features
Compressing (E-3SFC), which consists of three sub-components, i.e., the
Single-Step Synthetic Features Compressor (3SFC), a double-way compression
algorithm, and a communication budget scheduler. First, we regard the process
of gradient computation of a model as decompressing gradients from
corresponding inputs, while the inverse process is considered as compressing
the gradients. Based on this, we introduce a novel gradient compression method
termed 3SFC, which utilizes the model itself as a decompressor, leveraging
training priors such as model weights and objective functions. 3SFC compresses
raw gradients into tiny synthetic features in a single-step simulation,
incorporating error feedback to minimize overall compression errors. To further
reduce communication overhead, 3SFC is extended to E-3SFC, allowing double-way
compression and dynamic communication budget scheduling. Our theoretical
analysis under both strongly convex and non-convex conditions demonstrates that
3SFC achieves linear and sub-linear convergence rates with aggregation noise.
Extensive experiments across six datasets and six models reveal that 3SFC
outperforms state-of-the-art methods by up to 13.4% while reducing
communication costs by 111.6 times. These findings suggest that 3SFC can
significantly enhance communication efficiency in FL without compromising model
performance.

摘要：<paragraph>模型規模的指數成長大幅增加了聯邦學習 (FL) 中的通訊負擔。現有方法透過傳輸壓縮梯度來減輕此負擔，但經常會面臨高壓縮錯誤，這會減緩模型的收斂速度。為了同時達成高壓縮效率和較低壓縮錯誤，我們從新穎的角度研究梯度壓縮問題。具體來說，我們提出了一種稱為擴展單步合成特徵壓縮 (E-3SFC) 的系統演算法，它包含三個子元件，即單步合成特徵壓縮器 (3SFC)、雙向壓縮演算法和通訊預算排程器。首先，我們將模型的梯度計算過程視為從對應輸入解壓縮梯度，而反向過程則視為壓縮梯度。基於此，我們引入了稱為 3SFC 的新穎梯度壓縮方法，它利用模型本身作為解壓縮器，並利用訓練先驗（例如模型權重和目標函數）。3SFC 在單步模擬中將原始梯度壓縮為微小的合成特徵，並結合錯誤回饋以將整體壓縮錯誤降至最低。為了進一步降低通訊開銷，3SFC 已擴展至 E-3SFC，允許雙向壓縮和動態通訊預算排程。我們在強凸和非凸條件下的理論分析證明，3SFC 在聚合雜訊下實現線性和次線性收斂率。在六個資料集和六個模型的廣泛實驗中發現，3SFC 的效能比最先進的方法高出 13.4%，同時將通訊成本降低了 111.6 倍。這些發現表明，3SFC 可以顯著提高 FL 中的通訊效率，而不會損害模型效能。</paragraph>

##### **Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing**
2502.03086v1 by Salvatore Sinno, Markus Bertl, Arati Sahoo, Bhavika Bhalgamiya, Thomas Groß, Nicholas Chancellor

This study explores the implementation of large Quantum Restricted Boltzmann
Machines (QRBMs), a key advancement in Quantum Machine Learning (QML), as
generative models on D-Wave's Pegasus quantum hardware to address dataset
imbalance in Intrusion Detection Systems (IDS). By leveraging Pegasus's
enhanced connectivity and computational capabilities, a QRBM with 120 visible
and 120 hidden units was successfully embedded, surpassing the limitations of
default embedding tools. The QRBM synthesized over 1.6 million attack samples,
achieving a balanced dataset of over 4.2 million records. Comparative
evaluations with traditional balancing methods, such as SMOTE and
RandomOversampler, revealed that QRBMs produced higher-quality synthetic
samples, significantly improving detection rates, precision, recall, and F1
score across diverse classifiers. The study underscores the scalability and
efficiency of QRBMs, completing balancing tasks in milliseconds. These findings
highlight the transformative potential of QML and QRBMs as next-generation
tools in data preprocessing, offering robust solutions for complex
computational challenges in modern information systems.

摘要：本研究探討了大型量子限制玻爾茲曼機 (QRBM) 的實作，量子機器學習 (QML) 的一項關鍵進展，作為 D-Wave 的 Pegasus 量子硬體上的生成模型，以解決入侵偵測系統 (IDS) 中的資料集不平衡問題。透過利用 Pegasus 增強的連線性和運算能力，成功嵌入了一個具有 120 個可見和 120 個隱藏單元的 QRBM，超越了預設嵌入工具的限制。QRBM 合成了超過 160 萬個攻擊樣本，達到了超過 420 萬筆記錄的平衡資料集。與傳統平衡方法（例如 SMOTE 和 RandomOversampler）的比較評估顯示，QRBM 產生了更高品質的合成樣本，顯著提高了不同分類器的偵測率、精確度、召回率和 F1 分數。這項研究強調了 QRBM 的可擴充性和效率，在毫秒內完成平衡任務。這些發現突顯了 QML 和 QRBM 作為資料預處理中下一代工具的轉型潛力，為現代資訊系統中複雜的運算挑戰提供強大的解決方案。

##### **IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured Reasoning Templates**
2502.03080v1 by Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller

While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, understanding and validating their knowledge utilization remains
challenging. Chain-of-thought (CoT) prompting partially addresses this by
revealing intermediate reasoning steps, but the knowledge flow and application
remain implicit. We introduce IAO (Input-Action-Output) prompting, a structured
template-based method that explicitly models how LLMs access and apply their
knowledge during complex reasoning tasks. IAO decomposes problems into
sequential steps, each clearly identifying the input knowledge being used, the
action being performed, and the resulting output. This structured decomposition
enables us to trace knowledge flow, verify factual consistency, and identify
potential knowledge gaps or misapplications. Through experiments across diverse
reasoning tasks, we demonstrate that IAO not only improves zero-shot
performance but also provides transparency in how LLMs leverage their stored
knowledge. Human evaluation confirms that this structured approach enhances our
ability to verify knowledge utilization and detect potential hallucinations or
reasoning errors. Our findings provide insights into both knowledge
representation within LLMs and methods for more reliable knowledge application.

摘要：儘管大型語言模型 (LLM) 展現出令人印象深刻的推理能力，但了解和驗證其知識應用仍然具有挑戰性。思想鏈 (CoT) 提示透過揭示中間推理步驟來部分解決此問題，但知識流和應用仍然是隱含的。我們引入了 IAO（輸入-動作-輸出）提示，一種結構化的基於範本的方法，用於明確建模 LLM 在複雜推理任務期間如何存取和應用其知識。IAO 將問題分解為連續步驟，每個步驟清楚地識別所使用的輸入知識、執行的動作和產生的輸出。這種結構化分解使我們能夠追蹤知識流、驗證事實一致性，並找出潛在的知識差距或誤用。透過在各種推理任務中進行實驗，我們證明 IAO 不僅改善了零次學習效能，還提供了 LLM 如何利用其儲存知識的透明度。人類評估證實，這種結構化方法增強了我們驗證知識利用和偵測潛在幻覺或推理錯誤的能力。我們的發現提供了對 LLM 內部知識表示和更可靠知識應用方法的見解。

##### **DOLFIN -- Document-Level Financial test set for Machine Translation**
2502.03053v1 by Mariam Nakhlé, Marco Dinarelli, Raheel Qader, Emmanuelle Esperança-Rodier, Hervé Blanchon

Despite the strong research interest in document-level Machine Translation
(MT), the test sets dedicated to this task are still scarce. The existing test
sets mainly cover topics from the general domain and fall short on specialised
domains, such as legal and financial. Also, in spite of their document-level
aspect, they still follow a sentence-level logic that does not allow for
including certain linguistic phenomena such as information reorganisation. In
this work, we aim to fill this gap by proposing a novel test set: DOLFIN. The
dataset is built from specialised financial documents, and it makes a step
towards true document-level MT by abandoning the paradigm of perfectly aligned
sentences, presenting data in units of sections rather than sentences. The test
set consists of an average of 1950 aligned sections for five language pairs. We
present a detailed data collection pipeline that can serve as inspiration for
aligning new document-level datasets. We demonstrate the usefulness and quality
of this test set by evaluating a number of models. Our results show that the
test set is able to discriminate between context-sensitive and context-agnostic
models and shows the weaknesses when models fail to accurately translate
financial texts. The test set is made public for the community.

摘要：儘管對於文件層級機器翻譯 (MT) 有強烈的研究興趣，但專門用於此任務的測試集仍然稀少。現有的測試集主要涵蓋一般領域的主題，在法律和金融等專業領域則有不足。此外，儘管它們具有文件層級的方面，但它們仍然遵循句子層級的邏輯，不允許包含某些語言現象，例如資訊重組。在這項工作中，我們旨在透過提出一個新的測試集：DOLFIN 來填補此空白。此資料集建構自專業的金融文件，且透過放棄完美對齊句子的模式，朝向真正的文件層級 MT 邁進，以區塊而非句子的單位呈現資料。此測試集包含五組語言配對，平均有 1950 個對齊區塊。我們提供一個詳細的資料收集流程，可以用作對齊新的文件層級資料集的靈感。我們透過評估多個模型來證明此測試集的實用性和品質。我們的結果顯示，此測試集能夠區分對上下文敏感和與上下文無關的模型，並在模型無法準確翻譯財務文本時顯示其弱點。此測試集已公開供社群使用。

##### **Kozax: Flexible and Scalable Genetic Programming in JAX**
2502.03047v1 by Sigur de Vries, Sander W. Keemink, Marcel A. J. van Gerven

Genetic programming is an optimization algorithm inspired by natural
selection which automatically evolves the structure of computer programs. The
resulting computer programs are interpretable and efficient compared to
black-box models with fixed structure. The fitness evaluation in genetic
programming suffers from high computational requirements, limiting the
performance on difficult problems. To reduce the runtime, many implementations
of genetic programming require a specific data format, making the applicability
limited to specific problem classes. Consequently, there is no efficient
genetic programming framework that is usable for a wide range of tasks. To this
end, we developed Kozax, a genetic programming framework that evolves symbolic
expressions for arbitrary problems. We implemented Kozax using JAX, a framework
for high-performance and scalable machine learning, which allows the fitness
evaluation to scale efficiently to large populations or datasets on GPU.
Furthermore, Kozax offers constant optimization, custom operator definition and
simultaneous evolution of multiple trees. We demonstrate successful
applications of Kozax to discover equations of natural laws, recover equations
of hidden dynamic variables and evolve a control policy. Overall, Kozax
provides a general, fast, and scalable library to optimize white-box solutions
in the realm of scientific computing.

摘要：遺傳程式設計是一種最佳化演算法，其靈感來自自然選擇，它能自動演化電腦程式的結構。與結構固定的黑盒子模型相比，產生的電腦程式可解讀且有效率。遺傳程式設計中的適應度評估需要很高的運算需求，這限制了在困難問題上的效能。為了縮短執行時間，遺傳程式設計的許多實作都需要特定的資料格式，這使得其適用性僅限於特定的問題類別。因此，沒有任何高效的遺傳程式設計架構可用於廣泛的任務。有鑑於此，我們開發了 Kozax，這是一個遺傳程式設計架構，它能演化任意問題的符號表達式。我們使用 JAX 實作 Kozax，這是一個用於高性能和可擴充機器學習的架構，它允許適應度評估有效率地擴充到 GPU 上的大型族群或資料集。此外，Kozax 提供持續最佳化、自訂運算子定義和多個樹的同時演化。我們展示了 Kozax 成功應用於發現自然定律方程式、復原隱藏動態變數方程式和演化控制策略。總體而言，Kozax 提供了一個通用、快速且可擴充的函式庫，用於最佳化科學運算領域中的白盒解決方案。

##### **Knowledge Distillation from Large Language Models for Household Energy Modeling**
2502.03034v1 by Mohannad Takrouri, Nicolás M. Cuadrado, Martin Takáč

Machine learning (ML) is increasingly vital for smart-grid research, yet
restricted access to realistic, diverse data - often due to privacy concerns -
slows progress and fuels doubts within the energy sector about adopting
ML-based strategies. We propose integrating Large Language Models (LLMs) in
energy modeling to generate realistic, culturally sensitive, and
behavior-specific data for household energy usage across diverse geographies.
In this study, we employ and compare five different LLMs to systematically
produce family structures, weather patterns, and daily consumption profiles for
households in six distinct countries. A four-stage methodology synthesizes
contextual daily data, including culturally nuanced activities, realistic
weather ranges, HVAC operations, and distinct `energy signatures' that capture
unique consumption footprints. Additionally, we explore an alternative strategy
where external weather datasets can be directly integrated, bypassing
intermediate weather modeling stages while ensuring physically consistent data
inputs. The resulting dataset provides insights into how cultural, climatic,
and behavioral factors converge to shape carbon emissions, offering a
cost-effective avenue for scenario-based energy optimization. This approach
underscores how prompt engineering, combined with knowledge distillation, can
advance sustainable energy research and climate mitigation efforts. Source code
is available at
https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation .

摘要：機器學習 (ML) 對於智慧電網研究越來越重要，但
由於隱私問題，對真實且多元的資料存取受限，這
會減緩進度，並讓能源產業對採用
基於 ML 的策略產生疑慮。我們建議將大型語言模型 (LLM) 整合到
能源建模中，以產生真實、具文化敏感度且
針對不同地理區域家庭能源使用量產生特定行為的資料。
在本研究中，我們採用並比較五種不同的 LLM 來系統性
產生六個不同國家的家庭結構、天氣模式和每日用量概況。一個四階段的方法綜合
情境每日資料，包括具文化差異的活動、真實
天氣範圍、暖通空調運作，以及捕捉
獨特用量足跡的特定「能源特徵」。此外，我們探索一種替代策略
其中外部天氣資料集可以直接整合，繞過
中間天氣建模階段，同時確保實體一致的資料
輸入。產生的資料集提供深入見解，說明文化、氣候，
以及行為因素如何會聚以塑造碳排放，提供一個
針對情境進行能源最佳化的具成本效益途徑。這種方法
強調提示工程如何結合知識萃取，可以
推進永續能源研究和氣候減緩工作。原始碼可於
https://github.com/Singularity-AI-Lab/LLM-Energy-Knowledge-Distillation 取得。

##### **Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**
2502.03032v1 by Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov

We introduce a new approach to systematically map features discovered by
sparse autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.

摘要：我們提出了一種新的方法，可以系統性地對大型語言模型中連續層中稀疏自動編碼器發現的功能進行對應，擴展了先前檢視層間功能連結的研究。透過使用無資料的餘弦相似性技術，我們追蹤特定功能如何持續、轉換或首次出現在每個階段。此方法產生了功能演化的細粒度流程圖，能精細地解釋模型運算並提供機制見解。至關重要的是，我們展示了這些跨層功能對應如何透過放大或抑制所選功能來促進直接引導模型行為，在文字生成中實現目標主題控制。我們的研究結果共同突出了因果、跨層可解釋性架構的效用，它不僅闡明了功能如何透過前向傳遞而發展，還提供了透明操作大型語言模型的新方法。

##### **xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods**
2502.03014v1 by Pratinav Seth, Yashwardhan Rathore, Neeraj Kumar Singh, Chintan Chitroda, Vinay Kumar Sankarapu

The growing complexity of machine learning and deep learning models has led
to an increased reliance on opaque "black box" systems, making it difficult to
understand the rationale behind predictions. This lack of transparency is
particularly challenging in high-stakes applications where interpretability is
as important as accuracy. Post-hoc explanation methods are commonly used to
interpret these models, but they are seldom rigorously evaluated, raising
concerns about their reliability. The Python package xai_evals addresses this
by providing a comprehensive framework for generating, benchmarking, and
evaluating explanation methods across both tabular and image data modalities.
It integrates popular techniques like SHAP, LIME, Grad-CAM, Integrated
Gradients (IG), and Backtrace, while supporting evaluation metrics such as
faithfulness, sensitivity, and robustness. xai_evals enhances the
interpretability of machine learning models, fostering transparency and trust
in AI systems. The library is open-sourced at
https://pypi.org/project/xai-evals/ .

摘要：機器學習和深度學習模型的複雜性日益增加，導致對不透明的「黑盒子」系統的依賴性提高，使得難以理解預測背後的依據。這種缺乏透明性的狀況在高風險應用中特別具有挑戰性，因為可解釋性與準確性同樣重要。事後解釋方法通常用於解釋這些模型，但它們很少經過嚴格評估，引發了對其可靠性的擔憂。Python 套件 xai_evals 透過提供一個全面的架構來產生、評比和評估表格和影像資料模式的解釋方法，來解決這個問題。它整合了 SHAP、LIME、Grad-CAM、整合梯度 (IG) 和回溯等熱門技術，同時支援忠實度、敏感度和穩健性等評估指標。xai_evals 增強了機器學習模型的可解釋性，促進了對 AI 系統的透明度和信任。這個函式庫在 https://pypi.org/project/xai-evals/ 開源。

##### **Scaling Laws for Upcycling Mixture-of-Experts Language Models**
2502.03009v1 by Seng Pei Liew, Takuya Kato, Sho Takase

Pretraining large language models (LLMs) is resource-intensive, often
requiring months of training time even with high-end GPU clusters. There are
two approaches of mitigating such computational demands: reusing smaller models
to train larger ones (upcycling), and training computationally efficient models
like mixture-of-experts (MoE). In this paper, we study the upcycling of LLMs to
MoE models, of which the scaling behavior remains underexplored. Through
extensive experiments, we identify empirical scaling laws that describe how
performance depends on dataset size and model configuration. Particularly, we
show that, while scaling these factors improves performance, there is a novel
interaction term between the dense and upcycled training dataset that limits
the efficiency of upcycling at large computational budgets. Based on these
findings, we provide guidance to scale upcycling, and establish conditions
under which upcycling outperforms from-scratch trainings within budget
constraints.

摘要：預訓練大型語言模型 (LLM) 需要大量的資源，即使使用高階 GPU 集群，也常常需要數個月的訓練時間。有兩種方法可以減輕這種運算需求：重複使用較小的模型來訓練較大的模型（升級），以及訓練運算效率高的模型，例如專家混合（MoE）。在本文中，我們研究了 LLM 到 MoE 模型的升級，其中規模行為仍未得到充分探索。透過廣泛的實驗，我們找出經驗性規模定律，說明效能如何取決於資料集大小和模型組態。特別是，我們展示了在擴展這些因素時會改善效能，但密集和升級訓練資料集之間有一個新的交互作用項，會限制在大型運算預算中升級的效率。根據這些發現，我們提供了擴展升級的指導方針，並建立了在預算限制內，升級優於從頭開始訓練的條件。

##### **MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**
2502.03004v1 by Seonok Kim

Large Language Models (LLMs) have demonstrated impressive capabilities across
natural language processing tasks. However, their application to specialized
domains such as medicine and biology requires further optimization to ensure
factual accuracy, reliability, and contextual depth. We introduce MedBioLM, a
domain-adapted biomedical question-answering model designed to enhance both
short-form and long-form queries. By integrating fine-tuning and
retrieval-augmented generation (RAG), MedBioLM dynamically incorporates
domain-specific knowledge, improving reasoning abilities and factual accuracy.
To evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA
datasets, covering structured multiple-choice assessments and complex clinical
reasoning tasks. Fine-tuning significantly improves accuracy on benchmark
datasets, while RAG enhances factual consistency. These results highlight the
potential of domain-optimized LLMs in advancing biomedical research, medical
education, and clinical decision support.

摘要：大型語言模型 (LLM) 已展現出在自然語言處理任務中令人印象深刻的能力。然而，要將其應用於醫學和生物學等特定領域，需要進一步最佳化，以確保事實的準確性、可靠性以及脈絡的深度。我們引進了 MedBioLM，這是一個適應領域的生物醫學問答模型，旨在增強短式和長式查詢。透過整合微調和檢索增強生成 (RAG)，MedBioLM 能動態地納入領域特定的知識，從而提升推理能力和事實準確性。為了評估其有效性，我們對模型進行微調，使其涵蓋結構化的多重選擇評量和複雜的臨床推理任務等多樣化的生物醫學問答資料集。微調顯著提升了基準資料集的準確性，而 RAG 則增強了事實的一致性。這些結果突顯了領域最佳化的 LLM 在推進生物醫學研究、醫學教育和臨床決策支援方面的潛力。

##### **Training an LLM-as-a-Judge Model: Pipeline, Insights, and Practical Lessons**
2502.02988v1 by Renjun Hu, Yi Cheng, Libin Meng, Jiaxin Xia, Yi Zong, Xing Shi, Wei Lin

The rapid advancement of large language models (LLMs) has opened new
possibilities for their adoption as evaluative judges. This paper introduces
Themis, a fine-tuned LLM judge that delivers sophisticated context-aware
evaluations. We provide a comprehensive overview of the development pipeline
for Themis, highlighting its scenario-dependent evaluation prompts and two
novel methods for controlled instruction generation. These designs enable
Themis to effectively distill evaluative skills from teacher models, while
retaining flexibility for continuous development. We introduce two
human-labeled benchmarks for meta-evaluation, demonstrating that Themis can
achieve high alignment with human preferences in an economical manner.
Additionally, we explore insights into the LLM-as-a-judge paradigm, revealing
nuances in performance and the varied effects of reference answers. Notably, we
observe that pure knowledge distillation from strong LLMs, though common, does
not guarantee performance improvement through scaling. We propose a mitigation
strategy based on instruction-following difficulty. Furthermore, we provide
practical guidelines covering data balancing, prompt customization,
multi-objective training, and metric aggregation. We aim for our method and
findings, along with the fine-tuning data, benchmarks, and model checkpoints,
to support future research and development in this area.

摘要：大型語言模型 (LLM) 的快速進展為其作為評估評審的採用開啟了新的可能性。本文介紹 Themis，一個經過微調的 LLM 評審，可提供複雜的、具備語境感知的評估。我們提供了 Themis 開發管線的全面概述，重點介紹了其依據情境的評估提示和兩種控制式教學產生方法。這些設計讓 Themis 能有效地從教師模型中提煉評估技能，同時保持持續發展的靈活性。我們引入了兩個由人類標記的元評估基準，證明 Themis 能以經濟的方式與人類偏好達成高度一致。此外，我們探討了 LLM 作為評審典範的見解，揭示了效能的細微差別和參考答案的各種影響。值得注意的是，我們觀察到儘管常見，但從強大的 LLM 中進行純粹的知識萃取並不能保證透過擴充來提升效能。我們提出了一種基於遵循教學難度的緩解策略。此外，我們提供了涵蓋資料平衡、提示自訂、多目標訓練和指標聚合的實用指南。我們的目標是我們的 method 和發現，以及微調資料、基準和模型檢查點，以支援此領域的未來研究和發展。

##### **FedMobileAgent: Training Mobile Agents Using Decentralized Self-Sourced Data from Diverse Users**
2502.02982v1 by Wenhao Wang, Zijie Yu, William Liu, Rui Ye, Tian Jin, Siheng Chen, Yanfeng Wang

The advancement of mobile agents has opened new opportunities for automating
tasks on mobile devices. Training these agents requires large-scale
high-quality data, which is costly using human labor. Given the vast number of
mobile phone users worldwide, if automated data collection from them is
feasible, the resulting data volume and the subsequently trained mobile agents
could reach unprecedented levels. Nevertheless, two major challenges arise: (1)
extracting high-level and low-level user instructions without involving human
and (2) utilizing distributed data from diverse users while preserving privacy.
  To tackle these challenges, we propose FedMobileAgent, a collaborative
framework that trains mobile agents using self-sourced data from diverse users.
Specifically, it includes two techniques. First, we propose Auto-Annotation,
which enables the automatic collection of high-quality datasets during users'
routine phone usage with minimal cost. Second, we introduce adapted aggregation
to improve federated training of mobile agents on non-IID user data, by
incorporating both episode- and step-level distributions. In distributed
settings, FedMobileAgent achieves performance comparable to centralized
human-annotated models at less than 0.02\% of the cost, highlighting its
potential for real-world applications.

摘要：行動裝置代理的進步為自動化行動裝置任務開啟了新契機。訓練這些代理需要大量高品質的資料，而使用人力進行收集成本過高。考量到全球行動裝置使用者的龐大數量，如果能從他們身上自動收集資料，其資料量和隨後訓練出的行動裝置代理將會達到前所未有的水準。然而，有兩個主要的挑戰：（1）在不使用人力的情況下擷取高層級和低層級的使用者指令，以及（2）在維護隱私的同時，使用來自不同使用者的分散式資料。為了解決這些挑戰，我們提出了 FedMobileAgent，一個使用來自不同使用者的自有資料來訓練行動裝置代理的協作架構。具體來說，它包含兩種技術。首先，我們提出了自動註解，這能以最小的成本在使用者例行使用手機的過程中自動收集高品質的資料集。其次，我們引入了適應性聚合，藉由納入情節和步驟層級的分配，來改善行動裝置代理在非 IID 使用者資料上的聯合訓練。在分散式設定中，FedMobileAgent 達到了與集中式人工註釋模型相當的效能，成本卻不到 0.02%，突顯了它在實際應用中的潛力。

##### **TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics**
2502.02975v1 by Lu Yi, Jie Peng, Yanping Zheng, Fengran Mo, Zhewei Wei, Yuhang Ye, Yue Zixuan, Zengfeng Huang

Future link prediction is a fundamental challenge in various real-world
dynamic systems. To address this, numerous temporal graph neural networks
(temporal GNNs) and benchmark datasets have been developed. However, these
datasets often feature excessive repeated edges and lack complex sequential
dynamics, a key characteristic inherent in many real-world applications such as
recommender systems and ``Who-To-Follow'' on social networks. This oversight
has led existing methods to inadvertently downplay the importance of learning
sequential dynamics, focusing primarily on predicting repeated edges.
  In this study, we demonstrate that existing methods, such as GraphMixer and
DyGFormer, are inherently incapable of learning simple sequential dynamics,
such as ``a user who has followed OpenAI and Anthropic is more likely to follow
AI at Meta next.'' Motivated by this issue, we introduce the Temporal Graph
Benchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curated
to minimize repeated edges, challenging models to learn sequential dynamics and
generalize to unseen edges. TGB-Seq comprises large real-world datasets
spanning diverse domains, including e-commerce interactions, movie ratings,
business reviews, social networks, citation networks and web link networks.
Benchmarking experiments reveal that current methods usually suffer significant
performance degradation and incur substantial training costs on TGB-Seq, posing
new challenges and opportunities for future research. TGB-Seq datasets,
leaderboards, and example codes are available at https://tgb-seq.github.io/.

摘要：未來連結預測是各種真實世界動態系統中的一項基本挑戰。為了解決這個問題，已經開發了許多時序圖神經網路（時序 GNN）和基準資料集。然而，這些資料集通常具有過多的重複邊，並且缺乏複雜的順序動態，這是許多真實世界應用中固有的關鍵特徵，例如推薦系統和社群網路上的「誰來追蹤」。這種疏忽導致現有方法無意中淡化了學習順序動態的重要性，主要專注於預測重複的邊。
在本研究中，我們證明了現有方法，例如 GraphMixer 和 DyGFormer，本質上無法學習簡單的順序動態，例如「一個追蹤 OpenAI 和 Anthropic 的使用者更有可能在 Meta 上追蹤 AI」。受到這個問題的啟發，我們引入了具有順序動態的時序圖基準（TGB-Seq），這是一個經過仔細策劃的新基準，用於最小化重複的邊，挑戰模型學習順序動態並推廣到未見的邊。TGB-Seq 包含涵蓋不同領域的大型真實世界資料集，包括電子商務互動、電影評分、商業評論、社群網路、引文網路和網路連結網路。基準實驗表明，目前的方法通常在 TGB-Seq 上遭受顯著的效能下降，並產生大量的訓練成本，為未來的研究提出新的挑戰和機會。TGB-Seq 資料集、排行榜和範例程式碼可在 https://tgb-seq.github.io/ 取得。

##### **FACTER: Fairness-Aware Conformal Thresholding and Prompt Engineering for Enabling Fair LLM-Based Recommender Systems**
2502.02966v1 by Arya Fayyazi, Mehdi Kamal, Massoud Pedram

We propose FACTER, a fairness-aware framework for LLM-based recommendation
systems that integrates conformal prediction with dynamic prompt engineering.
By introducing an adaptive semantic variance threshold and a
violation-triggered mechanism, FACTER automatically tightens fairness
constraints whenever biased patterns emerge. We further develop an adversarial
prompt generator that leverages historical violations to reduce repeated
demographic biases without retraining the LLM. Empirical results on MovieLens
and Amazon show that FACTER substantially reduces fairness violations (up to
95.5%) while maintaining strong recommendation accuracy, revealing semantic
variance as a potent proxy of bias.

摘要：我們提出 FACTER，一個基於 LLM 的推薦系統的公平感知框架，它將共形預測與動態提示工程整合在一起。通過引入自適應語義變異閾值和違反觸發機制，當出現偏差模式時，FACTER 會自動收緊公平性約束。我們進一步開發了一個對抗提示生成器，它利用歷史違規行為來減少重複的人口統計偏差，而無需重新訓練 LLM。在 MovieLens 和 Amazon 上的實證結果表明，FACTER 大幅減少了公平性違規（高達 95.5%），同時保持了強大的推薦準確性，揭示了語義變異作為偏差的有效代理。

##### **(Neural-Symbolic) Machine Learning for Inconsistency Measurement**
2502.02963v1 by Sven Weinzierl, Carl Cora

We present machine-learning-based approaches for determining the
\emph{degree} of inconsistency -- which is a numerical value -- for
propositional logic knowledge bases. Specifically, we present regression- and
neural-based models that learn to predict the values that the inconsistency
measures $\incmi$ and $\incat$ would assign to propositional logic knowledge
bases. Our main motivation is that computing these values conventionally can be
hard complexity-wise. As an important addition, we use specific postulates,
that is, properties, of the underlying inconsistency measures to infer symbolic
rules, which we combine with the learning-based models in the form of
constraints. We perform various experiments and show that a) predicting the
degree values is feasible in many situations, and b) including the symbolic
constraints deduced from the rationality postulates increases the prediction
quality.

摘要：我們提出基於機器學習的方法來確定不一致性的程度，這是一個數值，用於命題邏輯知識庫。具體來說，我們提出回歸和基於神經網路的模型，用於學習預測不一致性測量 $\incmi$ 和 $\incat$ 會指派給命題邏輯知識庫的值。我們的動機主要是，傳統上計算這些值在複雜度上可能很困難。作為一個重要的補充，我們使用基礎不一致性測量的特定假設，也就是屬性，來推論符號規則，我們將其與學習模型結合在約束的形式中。我們執行各種實驗，並顯示 a) 在許多情況下預測程度值是可行的，以及 b) 包含從合理性假設中推論出的符號約束會提高預測品質。

##### **Position: Editing Large Language Models Poses Serious Safety Risks**
2502.02958v1 by Paul Youssef, Zhixue Zhao, Daniel Braun, Jörg Schlötterer, Christin Seifert

Large Language Models (LLMs) contain large amounts of facts about the world.
These facts can become outdated over time, which has led to the development of
knowledge editing methods (KEs) that can change specific facts in LLMs with
limited side effects. This position paper argues that editing LLMs poses
serious safety risks that have been largely overlooked. First, we note the fact
that KEs are widely available, computationally inexpensive, highly performant,
and stealthy makes them an attractive tool for malicious actors. Second, we
discuss malicious use cases of KEs, showing how KEs can be easily adapted for a
variety of malicious purposes. Third, we highlight vulnerabilities in the AI
ecosystem that allow unrestricted uploading and downloading of updated models
without verification. Fourth, we argue that a lack of social and institutional
awareness exacerbates this risk, and discuss the implications for different
stakeholders. We call on the community to (i) research tamper-resistant models
and countermeasures against malicious model editing, and (ii) actively engage
in securing the AI ecosystem.

摘要：大型語言模型 (LLM) 包含大量關於世界的事實。
這些事實會隨著時間過時，這導致了知識編輯方法 (KE) 的發展，它可以在 LLM 中更改特定的事實，且副作用有限。此立場文件認為，編輯 LLM 會造成嚴重的安全風險，而這在很大程度上被忽視了。首先，我們注意到，KE 廣泛可用、計算成本低、效能高且隱蔽，這使得它們成為惡意行為者的誘人工具。其次，我們討論了 KE 的惡意使用案例，說明 KE 如何能輕易地適應各種惡意目的。第三，我們強調了 AI 生態系統中的漏洞，允許在未經驗證的情況下無限制地上傳和下載更新的模型。第四，我們認為缺乏社會和制度意識會加劇這種風險，並討論對不同利害關係人的影響。我們呼籲社群 (i) 研究防篡改模型和針對惡意模型編輯的反制措施，以及 (ii) 積極參與保護 AI 生態系統。

##### **LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction**
2502.02945v1 by Ziwei Wang, Jie Zhou, Qin Chen, Min Zhang, Bo Jiang, Aimin Zhou, Qinchun Bai, Liang He

The knowledge tracing (KT) problem is an extremely important topic in
personalized education, which aims to predict whether students can correctly
answer the next question based on their past question-answer records. Prior
work on this task mainly focused on learning the sequence of behaviors based on
the IDs or textual information. However, these studies usually fail to capture
students' sufficient behavioral patterns without reasoning with rich world
knowledge about questions. In this paper, we propose a large language models
(LLMs)-based framework for KT, named \texttt{\textbf{LLM-KT}}, to integrate the
strengths of LLMs and traditional sequence interaction models. For task-level
alignment, we design Plug-and-Play instruction to align LLMs with KT,
leveraging LLMs' rich knowledge and powerful reasoning capacity. For
modality-level alignment, we design the plug-in context and sequence to
integrate multiple modalities learned by traditional methods. To capture the
long context of history records, we present a plug-in context to flexibly
insert the compressed context embedding into LLMs using question-specific and
concept-specific tokens. Furthermore, we introduce a plug-in sequence to
enhance LLMs with sequence interaction behavior representation learned by
traditional sequence models using a sequence adapter. Extensive experiments
show that \texttt{\textbf{LLM-KT}} obtains state-of-the-art performance on four
typical datasets by comparing it with approximately 20 strong baselines.

摘要：知識追蹤 (KT) 問題是個人化教育中一個非常重要的主題，其目標是根據學生的過去問題回答記錄預測學生是否能正確回答下一個問題。先前針對此任務的研究主要集中於根據 ID 或文字資訊學習行為序列。然而，這些研究通常無法在不推論出關於問題的豐富世界知識的情況下捕捉到學生的足夠行為模式。在本文中，我們提出了一個基於大型語言模型 (LLM) 的 KT 框架，稱為 \texttt{\textbf{LLM-KT}}，以整合 LLM 和傳統序列互動模型的優勢。對於任務層級對齊，我們設計了即插即用的指令，以將 LLM 與 KT 對齊，利用 LLM 豐富的知識和強大的推理能力。對於模態層級對齊，我們設計了外掛式內容和序列，以整合傳統方法學習到的多種模態。為了捕捉歷史記錄的長內容，我們提出了一個外掛式內容，以使用特定於問題和特定於概念的標記彈性地將壓縮內容嵌入插入 LLM 中。此外，我們引入了外掛式序列，以使用序列適配器增強 LLM 的序列互動行為表示，該表示是由傳統序列模型學習的。大量實驗表明，與大約 20 個強大的基線進行比較時，\texttt{\textbf{LLM-KT}} 在四個典型數據集上獲得了最先進的效能。

##### **LLaVAC: Fine-tuning LLaVA as a Multimodal Sentiment Classifier**
2502.02938v1 by T. Chay-intr, Y. Chen, K. Viriyayudhakorn, T. Theeramunkong

We present LLaVAC, a method for constructing a classifier for multimodal
sentiment analysis. This method leverages fine-tuning of the Large Language and
Vision Assistant (LLaVA) to predict sentiment labels across both image and text
modalities. Our approach involves designing a structured prompt that
incorporates both unimodal and multimodal labels to fine-tune LLaVA, enabling
it to perform sentiment classification effectively. Experiments on the
MVSA-Single dataset demonstrate that LLaVAC outperforms existing methods in
multimodal sentiment analysis across three data processing procedures. The
implementation of LLaVAC is publicly available at
https://github.com/tchayintr/llavac.

摘要：我們提出 LLaVAC，這是一種建構多模態情緒分析分類器的演算法。此演算法利用大型語言和視覺助理 (LLaVA) 的微調，來預測影像和文字這兩種模態的情緒標籤。我們的做法是設計一個結構化的提示，結合單模態和多模態標籤來微調 LLaVA，讓它能夠有效執行情緒分類。在 MVSA-Single 資料集上的實驗證明，LLaVAC 在三種資料處理程序中，在多模態情緒分析方面優於現有演算法。LLaVAC 的實作已公開發布於 https://github.com/tchayintr/llavac。

##### **Large Language Model Guided Self-Debugging Code Generation**
2502.02928v1 by Muntasir Adnan, Zhiwei Xu, Carlos C. N. Kuhn

Automated code generation is gaining significant importance in intelligent
computer programming and system deployment. However, current approaches often
face challenges in computational efficiency and lack robust mechanisms for code
parsing and error correction. In this work, we propose a novel framework,
PyCapsule, with a simple yet effective two-agent pipeline and efficient
self-debugging modules for Python code generation. PyCapsule features
sophisticated prompt inference, iterative error handling, and case testing,
ensuring high generation stability, safety, and correctness. Empirically,
PyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3%
on HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art
methods. We also observe a decrease in normalized success rate given more
self-debugging attempts, potentially affected by limited and noisy error
feedback in retention. PyCapsule demonstrates broader impacts on advancing
lightweight and efficient code generation for artificial intelligence systems.

摘要：自動化程式碼生成在智慧型電腦程式設計與系統部署中獲得顯著的重要性。然而，目前的作法通常在運算效率上遇到挑戰，並且缺乏健全的程式碼剖析與錯誤修正機制。在這項工作中，我們提出一個新的架構 PyCapsule，它具有一個簡單卻有效的雙代理管線，以及用於 Python 程式碼生成的有效自我除錯模組。PyCapsule 具備精密的提示推論、反覆的錯誤處理和案例測試，確保高生成穩定性、安全性與正確性。根據經驗，與現有技術相比，PyCapsule 在 HumanEval 上的成功率提高了 5.7%，在 HumanEval-ET 上提高了 10.3%，在 BigCodeBench 上提高了 24.4%。我們還觀察到，在更多自我除錯嘗試的情況下，標準化成功率會降低，這可能是受到保留中有限且有雜訊的錯誤回饋影響。PyCapsule 證明了對推進人工智慧系統的輕量且高效程式碼生成具有更廣泛的影響。

##### **Interactive Symbolic Regression through Offline Reinforcement Learning: A Co-Design Framework**
2502.02917v1 by Yuan Tian, Wenqi Zhou, Michele Viscione, Hao Dong, David Kammer, Olga Fink

Symbolic Regression (SR) holds great potential for uncovering underlying
mathematical and physical relationships from observed data. However, the vast
combinatorial space of possible expressions poses significant challenges for
both online search methods and pre-trained transformer models. Additionally,
current state-of-the-art approaches typically do not consider the integration
of domain experts' prior knowledge and do not support iterative interactions
with the model during the equation discovery process. To address these
challenges, we propose the Symbolic Q-network (Sym-Q), an advanced interactive
framework for large-scale symbolic regression. Unlike previous large-scale
transformer-based SR approaches, Sym-Q leverages reinforcement learning without
relying on a transformer-based decoder. This formulation allows the agent to
learn through offline reinforcement learning using any type of tree encoder,
enabling more efficient training and inference. Furthermore, we propose a
co-design mechanism, where the reinforcement learning-based Sym-Q facilitates
effective interaction with domain experts at any stage of the equation
discovery process. Users can dynamically modify generated nodes of the
expression, collaborating with the agent to tailor the mathematical expression
to best fit the problem and align with the assumed physical laws, particularly
when there is prior partial knowledge of the expected behavior. Our experiments
demonstrate that the pre-trained Sym-Q surpasses existing SR algorithms on the
challenging SSDNC benchmark. Moreover, we experimentally show on real-world
cases that its performance can be further enhanced by the interactive co-design
mechanism, with Sym-Q achieving greater performance gains than other
state-of-the-art models. Our reproducible code is available at
https://github.com/EPFL-IMOS/Sym-Q.

摘要：符號回歸 (SR) 在從觀測資料中揭露底層數學和物理關係方面具有巨大潛力。然而，可能的表達式的龐大組合空間對線上搜尋方法和預先訓練的轉換器模型都構成重大挑戰。此外，目前的先進方法通常不考慮整合領域專家的先驗知識，也不支援在方程式發現過程中與模型進行反覆互動。為了應對這些挑戰，我們提出符號 Q 網路 (Sym-Q)，一個用於大規模符號回歸的先進互動框架。與先前的基於轉換器的大規模 SR 方法不同，Sym-Q 利用強化學習，而不依賴基於轉換器的解碼器。此公式允許代理透過使用任何類型的樹狀編碼器進行離線強化學習，從而實現更有效率的訓練和推論。此外，我們提出一個協同設計機制，其中基於強化學習的 Sym-Q 能在方程式發現過程的任何階段促進與領域專家的有效互動。使用者可以動態修改表達式的生成節點，與代理合作，調整數學表達式以最適合問題並與假設的物理定律保持一致，特別是在對預期的行為有先驗部分知識時。我們的實驗證明，預先訓練的 Sym-Q 在具有挑戰性的 SSDNC 基準上超越現有的 SR 演算法。此外，我們在實際案例中透過實驗表明，其效能可以透過互動協同設計機制進一步提升，Sym-Q 的效能提升優於其他先進模型。我們可重製的程式碼可在 https://github.com/EPFL-IMOS/Sym-Q 取得。

##### **MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations**
2502.02912v1 by Namwoo Kim, Takahiro Yabe, Chanyoung Park, Yoonjin Yoon

Recently, learning effective representations of urban regions has gained
significant attention as a key approach to understanding urban dynamics and
advancing smarter cities. Existing approaches have demonstrated the potential
of leveraging mobility data to generate latent representations, providing
valuable insights into the intrinsic characteristics of urban areas. However,
incorporating the temporal dynamics and detailed semantics inherent in human
mobility patterns remains underexplored. To address this gap, we propose a
novel urban region representation learning model, Mobility Time Series
Contrastive Learning for Urban Region Representations (MobiCLR), designed to
capture semantically meaningful embeddings from inflow and outflow mobility
patterns. MobiCLR uses contrastive learning to enhance the discriminative power
of its representations, applying an instance-wise contrastive loss to capture
distinct flow-specific characteristics. Additionally, we develop a regularizer
to align output features with these flow-specific representations, enabling a
more comprehensive understanding of mobility dynamics. To validate our model,
we conduct extensive experiments in Chicago, New York, and Washington, D.C. to
predict income, educational attainment, and social vulnerability. The results
demonstrate that our model outperforms state-of-the-art models.

摘要：近期，学习城市区域的有效表示已获得广泛关注，成为理解城市动态和推进更智能城市的关键方法。现有方法已证明了利用移动性数据生成潜在表示的潜力，为城市区域的内在特征提供了宝贵的见解。然而，在人类移动模式中固有的时间动态和详细语义的整合仍未得到充分探索。为了解决这一差距，我们提出了一种新颖的城市区域表示学习模型，即城市区域表示的移动时间序列对比学习 (MobiCLR)，旨在从流入和流出移动模式中捕获语义有意义的嵌入。MobiCLR 使用对比学习来增强其表示的判别能力，应用逐例对比损失来捕获不同的特定流特征。此外，我们开发了一个正则化器，以将输出特征与这些特定流表示对齐，从而能够更全面地理解移动性动态。为了验证我们的模型，我们在芝加哥、纽约和华盛顿特区进行了广泛的实验，以预测收入、教育程度和社会脆弱性。结果表明，我们的模型优于最先进的模型。

##### **SPARC: Subspace-Aware Prompt Adaptation for Robust Continual Learning in LLMs**
2502.02909v1 by Dinithi Jayasuriya, Sina Tayebati, Davide Ettori, Ranganath Krishnan, Amit Ranjan Trivedi

We propose SPARC, a lightweight continual learning framework for large
language models (LLMs) that enables efficient task adaptation through prompt
tuning in a lower-dimensional space. By leveraging principal component analysis
(PCA), we identify a compact subspace of the training data. Optimizing prompts
in this lower-dimensional space enhances training efficiency, as it focuses
updates on the most relevant features while reducing computational overhead.
Furthermore, since the model's internal structure remains unaltered, the
extensive knowledge gained from pretraining is fully preserved, ensuring that
previously learned information is not compromised during adaptation. Our method
achieves high knowledge retention in both task-incremental and
domain-incremental continual learning setups while fine-tuning only 0.04% of
the model's parameters. Additionally, by integrating LoRA, we enhance
adaptability to computational constraints, allowing for a tradeoff between
accuracy and training cost. Experiments on the SuperGLUE benchmark demonstrate
that our PCA-based prompt tuning combined with LoRA maintains full knowledge
retention while improving accuracy, utilizing only 1% of the model's
parameters. These results establish our approach as a scalable and
resource-efficient solution for continual learning in LLMs.

摘要：我們提出 SPARC，一種適用於大型語言模型 (LLM) 的輕量級持續學習框架，它能透過在低維度空間中調整提示來有效進行任務適應。透過利用主成分分析 (PCA)，我們找出訓練資料的緊湊子空間。在這個低維度空間中最佳化提示能增強訓練效率，因為它會將更新集中在最相關的特徵上，同時減少運算負擔。此外，由於模型的內部結構保持不變，因此從預訓練中獲得的豐富知識得以完全保留，確保在適應過程中先前學習的資訊不會受到損害。我們的做法在任務遞增和領域遞增的持續學習設定中都能達成高知識保留率，同時只微調模型 0.04% 的參數。此外，透過整合 LoRA，我們增強了對運算限制的適應性，允許在準確度和訓練成本之間進行權衡。在 SuperGLUE 基準上的實驗證明，我們的基於 PCA 的提示調整結合 LoRA，在僅使用模型 1% 的參數時，能維持完全的知識保留，同時提高準確度。這些結果確立了我們的方法作為 LLM 中持續學習的可擴充且資源有效率的解決方案。

##### **ScholaWrite: A Dataset of End-to-End Scholarly Writing Process**
2502.02904v1 by Linghe Wang, Minhwa Lee, Ross Volkov, Luan Tuyen Chau, Dongyeop Kang

Writing is a cognitively demanding task involving continuous decision-making,
heavy use of working memory, and frequent switching between multiple
activities. Scholarly writing is particularly complex as it requires authors to
coordinate many pieces of multiform knowledge. To fully understand writers'
cognitive thought process, one should fully decode the end-to-end writing data
(from individual ideas to final manuscript) and understand their complex
cognitive mechanisms in scholarly writing. We introduce ScholaWrite dataset,
the first-of-its-kind keystroke logs of an end-to-end scholarly writing process
for complete manuscripts, with thorough annotations of cognitive writing
intentions behind each keystroke. Our dataset includes LaTeX-based keystroke
data from five preprints with nearly 62K total text changes and annotations
across 4 months of paper writing. ScholaWrite shows promising usability and
applications (e.g., iterative self-writing) for the future development of AI
writing assistants for academic research, which necessitate complex methods
beyond LLM prompting. Our experiments clearly demonstrated the importance of
collection of end-to-end writing data, rather than the final manuscript, for
the development of future writing assistants to support the cognitive thinking
process of scientists. Our de-identified dataset, demo, and code repository are
available on our project page.

摘要：<paragraph>寫作是一項認知要求很高的任務，涉及持續的決策制定、大量使用工作記憶，以及在多項活動之間頻繁切換。學術寫作尤其複雜，因為它要求作者協調許多形式多樣的知識。為了充分理解作家的認知思維過程，應該充分解碼端到端的寫作數據（從單個想法到最終手稿），並理解他們在學術寫作中的複雜認知機制。我們介紹了 ScholaWrite 數據集，這是第一個端到端學術寫作過程的鍵盤記錄，適用於完整手稿，並對每個鍵擊背後的認知寫作意圖進行了徹底註解。我們的數據集包括來自五篇預印本的基於 LaTeX 的鍵擊數據，在 4 個月的論文寫作過程中，總共進行了近 62K 次文本更改和註解。ScholaWrite 展示了有希望的可用性和應用（例如，迭代自寫），用於未來開發學術研究的 AI 寫作助手，這需要超越 LLM 提示的複雜方法。我們的實驗清楚地證明了收集端到端寫作數據（而不是最終手稿）對於開發未來的寫作助手以支持科學家的認知思維過程的重要性。我們的去識別數據集、演示和代碼存儲庫可在我們的項目頁面上找到。</paragraph>

##### **What is in a name? Mitigating Name Bias in Text Embeddings via Anonymization**
2502.02903v1 by Sahil Manchanda, Pannaga Shivaswamy

Text-embedding models often exhibit biases arising from the data on which
they are trained. In this paper, we examine a hitherto unexplored bias in
text-embeddings: bias arising from the presence of $\textit{names}$ such as
persons, locations, organizations etc. in the text. Our study shows how the
presence of $\textit{name-bias}$ in text-embedding models can potentially lead
to erroneous conclusions in assessment of thematic similarity.Text-embeddings
can mistakenly indicate similarity between texts based on names in the text,
even when their actual semantic content has no similarity or indicate
dissimilarity simply because of the names in the text even when the texts match
semantically. We first demonstrate the presence of name bias in different
text-embedding models and then propose $\textit{text-anonymization}$ during
inference which involves removing references to names, while preserving the
core theme of the text. The efficacy of the anonymization approach is
demonstrated on two downstream NLP tasks, achieving significant performance
gains. Our simple and training-optimization-free approach offers a practical
and easily implementable solution to mitigate name bias.

摘要：文本嵌入模型通常會表現出由訓練資料產生的偏差。在本文中，我們探討文本嵌入中一個迄今尚未探索的偏差：由文本中出現的人名、地點、組織等「名稱」產生的偏差。我們的研究顯示，文本嵌入模型中存在「名稱偏差」可能會導致主題相似性評估出現錯誤的結論。文本嵌入可能會錯誤地根據文本中的名稱指出文本之間的相似性，即使它們實際的語義內容沒有相似性，或者僅僅因為文本中的名稱而指出差異性，即使文本在語義上匹配。我們首先證明了不同文本嵌入模型中存在名稱偏差，然後在推論期間提出「文本匿名化」，其中涉及刪除對名稱的引用，同時保留文本的核心主題。匿名化方法的有效性在兩個下游 NLP 任務中得到證明，取得了顯著的性能提升。我們簡單且無需訓練優化的方法提供了一個實用且易於實作的解決方案，以減輕名稱偏差。

##### **Policy Abstraction and Nash Refinement in Tree-Exploiting PSRO**
2502.02901v1 by Christine Konicki, Mithun Chakraborty, Michael P. Wellman

Policy Space Response Oracles (PSRO) interleaves empirical game-theoretic
analysis with deep reinforcement learning (DRL) to solve games too complex for
traditional analytic methods. Tree-exploiting PSRO (TE-PSRO) is a variant of
this approach that iteratively builds a coarsened empirical game model in
extensive form using data obtained from querying a simulator that represents a
detailed description of the game. We make two main methodological advances to
TE-PSRO that enhance its applicability to complex games of imperfect
information. First, we introduce a scalable representation for the empirical
game tree where edges correspond to implicit policies learned through DRL.
These policies cover conditions in the underlying game abstracted in the game
model, supporting sustainable growth of the tree over epochs. Second, we
leverage extensive form in the empirical model by employing refined Nash
equilibria to direct strategy exploration. To enable this, we give a modular
and scalable algorithm based on generalized backward induction for computing a
subgame perfect equilibrium (SPE) in an imperfect-information game. We
experimentally evaluate our approach on a suite of games including an
alternating-offer bargaining game with outside offers; our results demonstrate
that TE-PSRO converges toward equilibrium faster when new strategies are
generated based on SPE rather than Nash equilibrium, and with reasonable
time/memory requirements for the growing empirical model.

摘要：策略空間回應神諭 (PSRO) 將經驗博弈論分析與深度強化學習 (DRL) 交織在一起，以解決對於傳統分析方法過於複雜的遊戲。樹木探索 PSRO (TE-PSRO) 是此方法的一種變體，它會反覆建構一個粗糙的經驗博弈模型，其廣泛形式使用從查詢模擬器取得的資料，而該模擬器代表遊戲的詳細描述。我們對 TE-PSRO 進行兩項主要方法學進展，以增強其適用於不完美資訊的複雜遊戲。首先，我們為經驗博弈樹引入一個可擴充的表示法，其中邊緣對應於透過 DRL 學習到的隱含策略。這些策略涵蓋遊戲模型中抽象出的底層遊戲條件，支援樹木在各個時期持續成長。其次，我們透過採用精緻的納許均衡來引導策略探索，以在經驗模型中利用廣泛形式。為此，我們提供一個基於廣義後向歸納的模組化且可擴充的演算法，用於在不完美資訊遊戲中計算子博弈完美均衡 (SPE)。我們在包括具有外部報價的輪替報價議價遊戲在內的一系列遊戲中，以實驗方式評估我們的做法；我們的結果證明，當根據 SPE 而不是納許均衡產生新策略時，TE-PSRO 會更快地收斂到均衡，而且對於成長中的經驗模型而言，具有合理的時間/記憶體需求。

##### **A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**
2502.02896v1 by Bradley P. Allen, Paul T. Groth

Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

摘要：評估大型語言模型 (LLM) 執行知識圖譜建構支援事實萃取等任務時，通常會使用基於知識圖譜 (KG) 的基準事實計算準確度指標。這些評估假設錯誤代表事實上的分歧。然而，人類話語經常出現元語言分歧，其中代理人之間的差異不在於事實，而在於用於表達事實的語言的含義。鑑於使用 LLM 處理和產生自然語言的複雜性，我們提出疑問：LLM 和 KG 之間是否會發生元語言分歧？根據使用 T-REx 知識比對資料集進行的調查，我們假設元語言分歧確實會發生在 LLM 和 KG 之間，並可能與知識圖譜工程實務有關。我們提出一個基準，用於評估 LLM 和 KG 之間的事實和元語言分歧的偵測。此基準的初步概念驗證可在 Github 上取得。

##### **Lowering the Barrier of Machine Learning: Achieving Zero Manual Labeling in Review Classification Using LLMs**
2502.02893v1 by Yejian Zhang, Shingo Takada

With the internet's evolution, consumers increasingly rely on online reviews
for service or product choices, necessitating that businesses analyze extensive
customer feedback to enhance their offerings. While machine learning-based
sentiment classification shows promise in this realm, its technical complexity
often bars small businesses and individuals from leveraging such advancements,
which may end up making the competitive gap between small and large businesses
even bigger in terms of improving customer satisfaction. This paper introduces
an approach that integrates large language models (LLMs), specifically
Generative Pre-trained Transformer (GPT) and Bidirectional Encoder
Representations from Transformers (BERT)-based models, making it accessible to
a wider audience. Our experiments across various datasets confirm that our
approach retains high classification accuracy without the need for manual
labeling, expert knowledge in tuning and data annotation, or substantial
computational power. By significantly lowering the barriers to applying
sentiment classification techniques, our methodology enhances competitiveness
and paves the way for making machine learning technology accessible to a
broader audience.

摘要：隨著網路的發展，消費者越來越依賴線上評論來選擇服務或產品，這使得企業必須分析大量的客戶回饋以提升他們的產品。儘管基於機器學習的情緒分類在這個領域中展現出前景，其技術複雜性常常阻礙小企業和個人利用這些進展，這可能會讓小企業和大企業在提升客戶滿意度方面的競爭差距變得更大。本文介紹了一種整合大型語言模型（LLM）的方法，特別是生成式預訓練轉換器（GPT）和基於轉換器的雙向編碼器表示（BERT）模型，使其可以讓更廣泛的受眾使用。我們在各種資料集上的實驗證實，我們的做法在無需手動標記、調整和資料標註的專業知識或大量的運算能力下，仍能保持高度的分類準確性。透過大幅降低應用情緒分類技術的障礙，我們的做法提升了競爭力，並為讓更廣泛的受眾能夠使用機器學習技術鋪路。

##### **Expertized Caption Auto-Enhancement for Video-Text Retrieval**
2502.02885v1 by Junxiang Chen, Baoyao yang, Wenbin Yao

The burgeoning field of video-text retrieval has witnessed significant
advancements with the advent of deep learning. However, the challenge of
matching text and video persists due to inadequate textual descriptions of
videos. The substantial information gap between the two modalities hinders a
comprehensive understanding of videos, resulting in ambiguous retrieval
results. While rewriting methods based on large language models have been
proposed to broaden text expressions, carefully crafted prompts are essential
to ensure the reasonableness and completeness of the rewritten texts. This
paper proposes an automatic caption enhancement method that enhances expression
quality and mitigates empiricism in augmented captions through self-learning.
Additionally, an expertized caption selection mechanism is designed and
introduced to customize augmented captions for each video, facilitating
video-text matching. Our method is entirely data-driven, which not only
dispenses with heavy data collection and computation workload but also improves
self-adaptability by circumventing lexicon dependence and introducing
personalized matching. The superiority of our method is validated by
state-of-the-art results on various benchmarks, specifically achieving Top-1
recall accuracy of 68.5% on MSR-VTT, 68.1% on MSVD, and 62.0% on DiDeMo.

摘要：蓬勃發展的影片文字檢索領域，隨著深度學習的出現，見證了顯著的進展。然而，由於影片的文字描述不足，文字和影片配對的挑戰依然存在。兩種模式之間的實質性資訊差距阻礙了對影片的全面理解，導致模糊的檢索結果。雖然已經提出基於大型語言模型的重寫方法來擴展文字表達，但精心設計的提示對於確保重寫文字的合理性和完整性至關重要。本文提出了一種自動字幕增強方法，該方法通過自學習增強表達品質，並減輕擴增字幕中的經驗主義。此外，設計並引進了一種專家字幕選擇機制，以針對每個影片自訂擴增字幕，促進影片文字配對。我們的做法完全由資料驅動，不僅省去了繁重的資料收集和運算工作負載，還通過規避詞彙依賴並引入個性化配對，提高了自適應性。我們的做法的優越性通過各種基準上的最新結果得到驗證，特別是在 MSR-VTT 上實現了 68.5% 的 Top-1 召回率準確度，在 MSVD 上實現了 68.1%，在 DiDeMo 上實現了 62.0%。

##### **SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions**
2502.02883v1 by Xiaofan Yu, Lanxiang Hu, Benjamin Reichman, Dylan Chu, Rushil Chandrupatla, Xiyuan Zhang, Larry Heck, Tajana Rosing

Natural language interaction with sensing systems is crucial for enabling all
users to comprehend sensor data and its impact on their everyday lives.
However, existing systems, which typically operate in a Question Answering (QA)
manner, are significantly limited in terms of the duration and complexity of
sensor data they can handle. In this work, we introduce SensorChat, the first
end-to-end QA system designed for long-term sensor monitoring with multimodal
and high-dimensional data including time series. SensorChat effectively answers
both qualitative (requiring high-level reasoning) and quantitative (requiring
accurate responses derived from sensor data) questions in real-world scenarios.
To achieve this, SensorChat uses an innovative three-stage pipeline that
includes question decomposition, sensor data query, and answer assembly. The
first and third stages leverage Large Language Models (LLMs) for intuitive
human interactions and to guide the sensor data query process. Unlike existing
multimodal LLMs, SensorChat incorporates an explicit query stage to precisely
extract factual information from long-duration sensor data. We implement
SensorChat and demonstrate its capability for real-time interactions on a cloud
server while also being able to run entirely on edge platforms after
quantization. Comprehensive QA evaluations show that SensorChat achieves up to
26% higher answer accuracy than state-of-the-art systems on quantitative
questions. Additionally, a user study with eight volunteers highlights
SensorChat's effectiveness in handling qualitative and open-ended questions.

摘要：自然語言與感測系統的互動對於讓所有使用者理解感測器資料及其對他們日常生活中的影響至關重要。然而，現有的系統通常以問答 (QA) 的方式運作，在感測器資料的持續時間和複雜性方面受到顯著限制。在這項工作中，我們引入了 SensorChat，這是第一個端到端的 QA 系統，專為長期感測監控而設計，具有多模式和高維度資料，包括時間序列。SensorChat 有效地回答了現實世界場景中的定性（需要高層次推理）和定量（需要從感測器資料中衍生的準確回應）問題。為了實現這一點，SensorChat 使用了一個創新的三階段管道，包括問題分解、感測器資料查詢和答案組裝。第一和第三階段利用大型語言模型 (LLM) 進行直觀的人類互動，並指導感測器資料查詢過程。與現有的多模式 LLM 不同，SensorChat 結合了一個明確的查詢階段，以從長時間的感測器資料中精確地提取事實資訊。我們實作了 SensorChat，並展示了它在雲端伺服器上進行即時互動的能力，同時在量化後也能完全在邊緣平台上執行。全面的 QA 評估顯示，SensorChat 在定量問題上的回答準確度比最先進的系統高出 26%。此外，一項針對八位志願者的使用者研究突出了 SensorChat 在處理定性和開放式問題方面的有效性。

##### **Vertical Federated Learning for Failure-Cause Identification in Disaggregated Microwave Networks**
2502.02874v1 by Fatih Temiz, Memedhe Ibrahimi, Francesco Musumeci, Claudio Passera, Massimo Tornatore

Machine Learning (ML) has proven to be a promising solution to provide novel
scalable and efficient fault management solutions in modern 5G-and-beyond
communication networks. In the context of microwave networks, ML-based
solutions have received significant attention. However, current solutions can
only be applied to monolithic scenarios in which a single entity (e.g., an
operator) manages the entire network. As current network architectures move
towards disaggregated communication platforms in which multiple operators and
vendors collaborate to achieve cost-efficient and reliable network management,
new ML-based approaches for fault management must tackle the challenges of
sharing business-critical information due to potential conflicts of interest.
In this study, we explore the application of Federated Learning in
disaggregated microwave networks for failure-cause identification using a real
microwave hardware failure dataset. In particular, we investigate the
application of two Vertical Federated Learning (VFL), namely using Split Neural
Networks (SplitNNs) and Federated Learning based on Gradient Boosting Decision
Trees (FedTree), on different multi-vendor deployment scenarios, and we compare
them to a centralized scenario where data is managed by a single entity. Our
experimental results show that VFL-based scenarios can achieve F1-Scores
consistently within at most a 1% gap with respect to a centralized scenario,
regardless of the deployment strategies or model types, while also ensuring
minimal leakage of sensitive-data.

摘要：機器學習（ML）已被證明是一個有前途的解決方案，用於在現代 5G 及後續通訊網路中提供新穎、可擴充且高效的故障管理解決方案。在微波網路的背景下，基於 ML 的解決方案已受到顯著關注。然而，目前的解決方案只能應用於單一實體（例如，營運商）管理整個網路的單體式場景。隨著當前網路架構朝向分散式通訊平台發展，其中多個營運商和供應商合作以達成具成本效益且可靠的網路管理，基於 ML 的故障管理新方法必須應對由於潛在利益衝突而共享業務關鍵資訊的挑戰。在本研究中，我們探討了聯邦學習在分散式微波網路中應用於故障原因識別，並使用真實微波硬體故障資料集。特別是，我們探討了兩種垂直聯邦學習（VFL）的應用，即使用分割神經網路（SplitNN）和基於梯度提升決策樹的聯邦學習（FedTree），在不同的多供應商部署場景中，並將它們與由單一實體管理資料的集中式場景進行比較。我們的實驗結果表明，基於 VFL 的場景可以持續達成 F1 分數，與集中式場景相比，差距最多只有 1%，無論部署策略或模型類型如何，同時還能確保敏感資料的洩漏最小化。

##### **Achieving Operational Universality through a Turing Complete Chemputer**
2502.02872v1 by Daniel Gahler, Dean Thomas, Slawomir Lach, Leroy Cronin

The most fundamental abstraction underlying all modern computers is the
Turing Machine, that is if any modern computer can simulate a Turing Machine,
an equivalence which is called Turing completeness, it is theoretically
possible to achieve any task that can be algorithmically described by executing
a series of discrete unit operations. In chemistry, the ability to program
chemical processes is demanding because it is hard to ensure that the process
can be understood at a high level of abstraction, and then reduced to practice.
Herein we exploit the concept of Turing completeness applied to robotic
platforms for chemistry that can be used to synthesise complex molecules
through unit operations that execute chemical processes using a
chemically-aware programming language, XDL. We leverage the concept of
computability by computers to synthesizability of chemical compounds by
automated synthesis machines. The results of an interactive demonstration of
Turing completeness using the colour gamut and conditional logic are presented
and examples of chemical use-cases are discussed. Over 16.7 million
combinations of Red, Green, Blue (RGB) colour space were binned into 5 discrete
values and measured over 10 regions of interest (ROIs), affording 78 million
possible states per step and served as a proxy for conceptual, chemical space
exploration. This formal description establishes a formal framework in future
chemical programming languages to ensure complex logic operations are expressed
and executed correctly, with the possibility of error correction, in the
automated and autonomous pursuit of increasingly complex molecules.

摘要：最基本的抽象基礎在於所有現代電腦的圖靈機，也就是說，如果任何現代電腦可以模擬圖靈機，一個稱為圖靈完備性的等價性，理論上可以達成任何任務，這些任務可以透過執行一系列離散單元運算，以演算法方式描述。在化學中，程式化化學程序的能力很要求人，因為難以確保該程序可以在高層次抽象中理解，然後化繁為簡。在此，我們利用圖靈完備性的概念，應用於機器人平台，用於化學，可以使用化學感知程式語言 XDL，透過執行化學程序的單元運算，來合成複雜分子。我們利用電腦的運算能力來合成化學化合物，透過自動化合成機器。使用色域和條件邏輯，展示圖靈完備性的互動示範結果，並討論化學使用案例的範例。超過 1,670 萬種紅、綠、藍 (RGB) 色彩空間組合，被分組成 5 個離散值，並在 10 個感興趣區域 (ROI) 中測量，提供每一步驟 7,800 萬種可能的狀態，並作為概念性化學空間探索的代理。此正式說明建立一個正式架構，在未來的化學程式語言中，以確保複雜邏輯運算可以正確表達和執行，並在自動化和自主追求日益複雜的分子時，有錯誤修正的可能性。

##### **Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning**
2502.02871v1 by Yibo Yan, Shen Wang, Jiahao Huo, Jingheng Ye, Zhendong Chu, Xuming Hu, Philip S. Yu, Carla Gomes, Bart Selman, Qingsong Wen

Scientific reasoning, the process through which humans apply logic, evidence,
and critical thinking to explore and interpret scientific phenomena, is
essential in advancing knowledge reasoning across diverse fields. However,
despite significant progress, current scientific reasoning models still
struggle with generalization across domains and often fall short of multimodal
perception. Multimodal Large Language Models (MLLMs), which integrate text,
images, and other modalities, present an exciting opportunity to overcome these
limitations and enhance scientific reasoning. Therefore, this position paper
argues that MLLMs can significantly advance scientific reasoning across
disciplines such as mathematics, physics, chemistry, and biology. First, we
propose a four-stage research roadmap of scientific reasoning capabilities, and
highlight the current state of MLLM applications in scientific reasoning,
noting their ability to integrate and reason over diverse data types. Second,
we summarize the key challenges that remain obstacles to achieving MLLM's full
potential. To address these challenges, we propose actionable insights and
suggestions for the future. Overall, our work offers a novel perspective on
MLLM integration with scientific reasoning, providing the LLM community with a
valuable vision for achieving Artificial General Intelligence (AGI).

摘要：科學推理，即人類運用邏輯、證據和批判性思維探索和詮釋科學現象的過程，對於推進不同領域的知識推理至關重要。然而，儘管取得了顯著進展，當前的科學推理模型在跨領域概括方面仍面臨挑戰，並且常常無法達到多模態感知。整合文本、影像和其他模態的多模態大型語言模型 (MLLM) 為克服這些限制並增強科學推理提供了令人興奮的機會。因此，本立場文件認為，MLLM 可以顯著推進數學、物理、化學和生物學等學科的科學推理。首先，我們提出了科學推理能力的四階段研究路線圖，並重點介紹了 MLLM 在科學推理中的應用現狀，並指出了它們整合和推理不同數據類型的能力。其次，我們總結了阻礙 MLLM 充分發揮其潛力的關鍵挑戰。為了應對這些挑戰，我們提出了可行的見解和建議，以供未來參考。總的來說，我們的研究為 MLLM 與科學推理的整合提供了新的觀點，為 LLM 社群提供了實現人工通用智慧 (AGI) 的寶貴願景。

##### **OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds**
2502.02869v1 by Fan Wang, Pengtao Shao, Yiming Zhang, Bo Yu, Shaoshan Liu, Ning Ding, Yang Cao, Yu Kang, Haifeng Wang

We introduce OmniRL, a highly generalizable in-context reinforcement learning
(ICRL) model that is meta-trained on hundreds of thousands of diverse tasks.
These tasks are procedurally generated by randomizing state transitions and
rewards within Markov Decision Processes. To facilitate this extensive
meta-training, we propose two key innovations: 1. An efficient data synthesis
pipeline for ICRL, which leverages the interaction histories of diverse
behavior policies; and 2. A novel modeling framework that integrates both
imitation learning and reinforcement learning (RL) within the context, by
incorporating prior knowledge. For the first time, we demonstrate that
in-context learning (ICL) alone, without any gradient-based fine-tuning, can
successfully tackle unseen Gymnasium tasks through imitation learning, online
RL, or offline RL. Additionally, we show that achieving generalized ICRL
capabilities-unlike task identification-oriented few-shot learning-critically
depends on long trajectories generated by variant tasks and diverse behavior
policies. By emphasizing the potential of ICL and departing from pre-training
focused on acquiring specific skills, we further underscore the significance of
meta-training aimed at cultivating the ability of ICL itself.

摘要：我們介紹 OmniRL，這是一種高度可概化的情境內強 reinforcement learning
(ICRL) 模型，並針對數十萬個不同的任務進行元訓練。
這些任務是透過隨機化馬可夫決策程序中的狀態轉換和
獎勵來程序化生成的。為了促進這種廣泛的
元訓練，我們提出了兩個關鍵創新：1. 一個用於 ICRL 的高效數據合成
管道，它利用了不同
行為政策的互動歷史記錄；2. 一個新穎的建模框架，它透過
納入先驗知識，將模仿學習和強化學習 (RL) 整合到情境中。我們首次證明
情境內學習 (ICL) 本身，在沒有任何基於梯度的微調情況下，可以
透過模仿學習、線上
RL 或離線 RL 成功應對未見過的 Gymnasium 任務。此外，我們表明實現廣義的 ICRL
能力（與以任務識別為導向的少次學習不同）在很大程度上
取決於由變異任務和不同行為
政策生成的長軌跡。透過強調 ICL 的潛力並擺脫專注於獲取特定技能的預訓練，我們進一步強調了
旨在培養 ICL 本身能力的元訓練的重要性。

##### **A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability**
2502.02866v1 by Hung-Fu Chang, Mohammad Shokrolah Shirazi

Software testing ensures the quality and reliability of software products,
but manual test case creation is labor-intensive. With the rise of large
language models (LLMs), there is growing interest in unit test creation with
LLMs. However, effective assessment of LLM-generated test cases is limited by
the lack of standardized benchmarks that comprehensively cover diverse
programming scenarios. To address the assessment of LLM's test case generation
ability and lacking dataset for evaluation, we propose the Generated Benchmark
from Control-Flow Structure and Variable Usage Composition (GBCV) approach,
which systematically generates programs used for evaluating LLMs' test
generation capabilities. By leveraging basic control-flow structures and
variable usage, GBCV provides a flexible framework to create a spectrum of
programs ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are
publicly accessible models, to present real-world regular user's use case, we
use GBCV to assess LLM performance on them. Our findings indicate that GPT-4o
performs better on complex program structures, while all models effectively
detect boundary values in simple conditions but face challenges with arithmetic
computations. This study highlights the strengths and limitations of LLMs in
test generation, provides a benchmark framework, and suggests directions for
future improvement.

摘要：軟體測試確保軟體產品的品質和可靠性，
但手動測試案例的建立需要大量人力。隨著大型語言模型 (LLM) 的興起，使用 LLM 建立單元測試越來越受到關注。然而，由於缺乏全面涵蓋各種程式設計情境的標準化基準，對 LLM 生成的測試案例進行有效的評估受到限制。為了評估 LLM 的測試案例生成能力和缺乏評估用的資料集，我們提出從控制流程結構和變數使用組成 (GBCV) 方法產生的基準，它有系統地產生用於評估 LLM 測試生成能力的程式。透過利用基本的控制流程結構和變數使用，GBCV 提供一個彈性的架構來建立從簡單到複雜的程式範圍。由於 GPT-4o 和 GPT-3-Turbo 是公開存取的模型，為了呈現真實世界的常規使用者的使用案例，我們使用 GBCV 來評估 LLM 在它們上的效能。我們的研究結果指出，GPT-4o 在複雜的程式結構上表現得更好，而所有模型都能有效地偵測簡單條件中的邊界值，但在算術運算方面則面臨挑戰。這項研究突顯了 LLM 在測試生成中的優缺點，提供了一個基準架構，並建議未來改進的方向。

##### **OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change**
2502.02863v1 by Pat Pataranutaporn, Alexander Doudkin, Pattie Maes

Marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. This paper presents OceanChat, an
interactive system leveraging large language models to create conversational AI
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)
and foster awareness through personalized dialogue. Through a between-subjects
experiment (N=900), we compared three conditions: (1) Static Scientific
Information, providing conventional environmental education through text and
images; (2) Static Character Narrative, featuring first-person storytelling
from 3D-rendered marine creatures; and (3) Conversational Character Narrative,
enabling real-time dialogue with AI-powered marine characters. Our analysis
revealed that the Conversational Character Narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. The beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. However, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. Our work extends research on
sustainability interfaces facilitating PEB and offers design principles for
creating emotionally resonant, context-aware AI characters. By balancing
anthropomorphism with species authenticity, OceanChat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change.

摘要：海洋生態系統面臨氣候變遷和塑膠污染空前的威脅，然而傳統的環境教育往往難以將認知轉化為持續的行為改變。本文提出 OceanChat，一個互動系統，利用大型語言模型創造出對話式 AI 代理，以動畫海洋生物呈現——特別是白鯨、水母和海馬——旨在透過個人化對話促進環境行為 (PEB) 並培養認知。透過受試者間實驗 (N=900)，我們比較了三種情況：(1) 靜態科學資訊，透過文字和圖片提供傳統的環境教育；(2) 靜態角色敘事，以 3D渲染的海洋生物的第一人稱敘事為特色；(3) 對話式角色敘事，與由 AI 驅動的海洋角色進行即時對話。我們的分析顯示，與靜態方法相比，對話式角色敘事情況顯著增加了行為意圖和永續選擇偏好。白鯨角色在多項指標中持續展現更強烈的情緒參與，包括感知擬人化和同理心。然而，對氣候政策支持和心理距離等更深層面的影響有限，突顯了改變根深蒂固信念的複雜性。我們的研究擴展了促進 PEB 的永續性介面，並提供了創造具有情緒共鳴、具備脈絡感知能力的 AI 角色的設計原則。透過平衡擬人化和物種真實性，OceanChat 示範了互動式敘事如何縮小環境知識和現實世界行為改變之間的差距。

##### **Learning Generalizable Features for Tibial Plateau Fracture Segmentation Using Masked Autoencoder and Limited Annotations**
2502.02862v1 by Peiyan Yue, Die Cai, Chu Guo, Mengxing Liu, Jun Xia, Yi Wang

Accurate automated segmentation of tibial plateau fractures (TPF) from
computed tomography (CT) requires large amounts of annotated data to train deep
learning models, but obtaining such annotations presents unique challenges. The
process demands expert knowledge to identify diverse fracture patterns, assess
severity, and account for individual anatomical variations, making the
annotation process highly time-consuming and expensive. Although
semi-supervised learning methods can utilize unlabeled data, existing
approaches often struggle with the complexity and variability of fracture
morphologies, as well as limited generalizability across datasets. To tackle
these issues, we propose an effective training strategy based on masked
autoencoder (MAE) for the accurate TPF segmentation in CT. Our method leverages
MAE pretraining to capture global skeletal structures and fine-grained fracture
details from unlabeled data, followed by fine-tuning with a small set of
labeled data. This strategy reduces the dependence on extensive annotations
while enhancing the model's ability to learn generalizable and transferable
features. The proposed method is evaluated on an in-house dataset containing
180 CT scans with TPF. Experimental results demonstrate that our method
consistently outperforms semi-supervised methods, achieving an average Dice
similarity coefficient (DSC) of 95.81%, average symmetric surface distance
(ASSD) of 1.91mm, and Hausdorff distance (95HD) of 9.42mm with only 20
annotated cases. Moreover, our method exhibits strong transferability when
applying to another public pelvic CT dataset with hip fractures, highlighting
its potential for broader applications in fracture segmentation tasks.

摘要：脛骨平台骨折 (TPF) 的精確自動分割來自電腦斷層掃描 (CT)，需要大量標註的資料來訓練深度學習模型，但取得這些標註會產生獨特的挑戰。這個過程需要專家知識來識別不同的骨折模式、評估嚴重程度，並考量個別的解剖學變異，這使得標註過程非常耗時且昂貴。雖然半監督式學習方法可以利用未標籤的資料，但現有的方法通常難以應付骨折形態的複雜性和變異性，以及跨資料集的通用性有限。為了解決這些問題，我們提出一個基於遮罩式自動編碼器 (MAE) 的有效訓練策略，用於 CT 中精確的 TPF 分割。我們的辦法利用 MAE 預訓練來擷取未標籤資料中的整體骨骼結構和細微骨折細節，然後使用一小組標籤資料進行微調。這個策略減少了對大量標註的依賴，同時增強了模型學習可概括和可轉移特徵的能力。所提出的方法在一個包含 180 個 TPF 的 CT 掃描的內部資料集上進行評估。實驗結果證明，我們的辦法始終優於半監督式方法，實現了平均 Dice 相似性係數 (DSC) 為 95.81%，平均對稱表面距離 (ASSD) 為 1.91mm，以及 Hausdorff 距離 (95HD) 為 9.42mm，僅有 20 個標註案例。此外，我們的辦法在應用於另一個有髖部骨折的公共骨盆 CT 資料集時展現出強大的可轉移性，突顯了其在骨折分割任務中更廣泛應用的潛力。

##### **Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**
2502.02810v1 by Chanhui Lee, Yuheon Song, YongJun Jeong, Hanbum Ko, Rodrigo Hormazabal, Sehui Han, Kyunghoon Bae, Sungbin Lim, Sungwoong Kim

Recent advances in Large Language Models (LLMs) have motivated the
development of general LLMs for molecular tasks. While several studies have
demonstrated that fine-tuned LLMs can achieve impressive benchmark
performances, they are far from genuine generalist molecular LLMs due to a lack
of fundamental understanding of molecular structure. Specifically, when given
molecular task instructions, LLMs trained with naive next-token prediction
training assign similar likelihood scores to both original and negatively
corrupted molecules, revealing their lack of molecular structure understanding
that is crucial for reliable and general molecular LLMs. To overcome this
limitation and obtain a true generalist molecular LLM, we introduce a novel
multi-modal training method based on a thorough multi-modal instruction tuning
as well as a molecular structure preference optimization between chosen and
rejected graphs. On various molecular benchmarks, the proposed generalist
molecular LLM, called Mol-LLM, achieves state-of-the-art performances among
generalist LLMs on most tasks, at the same time, surpassing or comparable to
state-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior
generalization performances in reaction prediction tasks, demonstrating the
effect of the molecular structure understanding for generalization perspective.

摘要：大型語言模型 (LLM) 的近期進展激勵了針對分子任務開發通用 LLM。雖然多項研究已證明微調 LLM 可實現令人印象深刻的基準效能，但由於缺乏對分子結構的基本理解，它們遠非真正的通才分子 LLM。具體來說，當給予分子任務說明時，使用天真的下一個符號預測訓練訓練的 LLM 會將類似的可能性評分分配給原始分子和負面損壞分子，這顯示出它們缺乏對分子結構的理解，而這對於可靠且通用的分子 LLM 至關重要。為了克服這個限制並獲得真正的通才分子 LLM，我們引入了一種新穎的多模態訓練方法，該方法基於徹底的多模態說明調整以及在所選和拒絕圖形之間的分子結構偏好最佳化。在各種分子基準測試中，所提出的通才分子 LLM（稱為 Mol-LLM）在多數任務中實現了通才 LLM 中的最新效能，同時超越或與最新的專家 LLM 相當。此外，Mol-LLM 在反應預測任務中也展現出優異的泛化效能，證明了分子結構理解對泛化觀點的影響。

##### **CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration**
2502.02807v1 by Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim

Conversational counselor agents have become essential tools for addressing
the rising demand for scalable and accessible mental health support. This paper
introduces CAMI, a novel automated counselor agent grounded in Motivational
Interviewing (MI) -- a client-centered counseling approach designed to address
ambivalence and facilitate behavior change. CAMI employs a novel STAR
framework, consisting of client's state inference, motivation topic
exploration, and response generation modules, leveraging large language models
(LLMs). These components work together to evoke change talk, aligning with MI
principles and improving counseling outcomes for clients from diverse
backgrounds. We evaluate CAMI's performance through both automated and manual
evaluations, utilizing simulated clients to assess MI skill competency,
client's state inference accuracy, topic exploration proficiency, and overall
counseling success. Results show that CAMI not only outperforms several
state-of-the-art methods but also shows more realistic counselor-like behavior.
Additionally, our ablation study underscores the critical roles of state
inference and topic exploration in achieving this performance.

摘要：對話式諮商代理已成為滿足可擴充且可取得心理健康支援日益增長需求的必要工具。本文介紹 CAMI，一種新型自動化諮商代理，其基礎是動機性訪談 (MI)，一種以客戶為中心的諮商方法，旨在解決猶豫不決並促進行為改變。CAMI 使用一種新型的 STAR 架構，包括客戶狀態推論、動機主題探討和回應產生模組，並利用大型語言模型 (LLM)。這些元件共同作用以引發改變對話，與 MI 原則保持一致，並改善來自不同背景的客戶的諮商成果。我們透過自動化和手動評估來評估 CAMI 的效能，利用模擬客戶來評估 MI 技能能力、客戶狀態推論準確度、主題探討熟練度和整體諮商成功率。結果顯示，CAMI 不僅優於多種最先進的方法，還表現出更逼真的諮商師行為。此外，我們的消融研究強調了狀態推論和主題探討在達成此效能中所扮演的關鍵角色。

##### **Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting**
2502.02797v1 by Sunny Sanyal, Hayden Prairie, Rudrajit Das, Ali Kavis, Sujay Sanghavi

Fine-tuning a pre-trained model on a downstream task often degrades its
original capabilities, a phenomenon known as "catastrophic forgetting". This is
especially an issue when one does not have access to the data and recipe used
to develop the pre-trained model. Under this constraint, most existing methods
for mitigating forgetting are inapplicable. To address this challenge, we
propose a sample weighting scheme for the fine-tuning data solely based on the
pre-trained model's losses. Specifically, we upweight the easy samples on which
the pre-trained model's loss is low and vice versa to limit the drift from the
pre-trained model. Our approach is orthogonal and yet complementary to existing
methods; while such methods mostly operate on parameter or gradient space, we
concentrate on the sample space. We theoretically analyze the impact of
fine-tuning with our method in a linear setting, showing that it stalls
learning in a certain subspace which inhibits overfitting to the target task.
We empirically demonstrate the efficacy of our method on both language and
vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our
method results in only a $0.8\%$ drop in accuracy on GSM8K (another math
dataset) compared to standard fine-tuning, while preserving $5.4\%$ more
accuracy on the pre-training datasets. Our code is publicly available at
https://github.com/sanyalsunny111/FLOW_finetuning .

摘要：<paragraph>微調預訓練模型於下游任務時，通常會降低其原始功能，此現象稱為「災難性遺忘」。當無法取得用於開發預訓練模型的資料和配方時，這尤其會成為一個問題。在此限制下，大多數現有減輕遺忘的方法都無法適用。為了應對此挑戰，我們提出一個樣本加權方案，用於微調資料，僅基於預訓練模型的損失。具體來說，我們會對預訓練模型損失較低的容易樣本進行加權，反之亦然，以限制與預訓練模型的偏差。我們的做法與現有方法正交且互補；雖然這些方法大多在參數或梯度空間中運作，但我們專注於樣本空間。我們在線性設定中理論分析微調我們方法的影響，表明它會在某個子空間中停止學習，從而抑制對目標任務的過度擬合。我們在語言和視覺任務中實證展示了我們方法的功效。舉例來說，當在 MetaMathQA 上微調 Gemma 2 2B 時，與標準微調相比，我們的做法僅導致 GSM8K（另一個數學資料集）的準確度下降 $0.8\%$，同時在預訓練資料集上保留了 $5.4\%$ 的準確度。我們的程式碼已公開於 https://github.com/sanyalsunny111/FLOW_finetuning。</paragraph>

##### **Leveraging the true depth of LLMs**
2502.02790v1 by Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

Large Language Models demonstrate remarkable capabilities at the cost of high
compute requirements. While recent research has shown that intermediate layers
can be removed or have their order shuffled without impacting performance
significantly, these findings have not been employed to reduce the
computational cost of inference. We investigate several potential ways to
reduce the depth of pre-trained LLMs without significantly affecting
performance. Leveraging our insights, we present a novel approach that exploits
this decoupling between layers by grouping some of them into pairs that can be
evaluated in parallel.
  This modification of the computational graph -- through better parallelism --
results in an average improvement of around 1.20x on the number of tokens
generated per second, without re-training nor fine-tuning, while retaining
95%-99% of the original accuracy. Empirical evaluation demonstrates that this
approach significantly improves serving efficiency while maintaining model
performance, offering a practical improvement for large-scale LLM deployment.

摘要：大型语言模型展示了其强大的功能，但代价是较高的计算需求。虽然最近的研究表明，中间层可以被移除或重新排列其顺序，而不会显著影响性能，但这些发现尚未被用来降低推理的计算成本。我们研究了几种潜在的方法来减少预训练 LLM 的深度，而不会显著影响性能。利用我们的见解，我们提出了一种新颖的方法，该方法通过将其中一些分组为可以并行评估的成对来利用层之间的这种解耦。
通过更好的并行性对计算图进行修改，平均而言，每秒生成的令牌数量提高了约 1.20 倍，而无需重新训练或微调，同时保留了 95%-99% 的原始准确性。经验评估表明，这种方法显著提高了服务效率，同时保持了模型性能，为大规模 LLM 部署提供了实际改进。

##### **Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation**
2502.02789v1 by Jingyu Liu, Beidi Chen, Ce Zhang

Improving time-to-first-token (TTFT) is an essentially important objective in
modern large language model (LLM) inference engines. Because optimizing TTFT
directly results in higher maximal QPS and meets the requirements of many
critical applications. However, boosting TTFT is notoriously challenging since
it is purely compute-bounded and the performance bottleneck shifts from the
self-attention to the MLP part. We present SpecPrefill, a training free
framework that accelerates the inference TTFT for both long and medium context
queries based on the following insight: LLMs are generalized enough to still
preserve the quality given only a carefully chosen subset of prompt tokens. At
its core, SpecPrefill leverages a lightweight model to speculate locally
important tokens based on the context. These tokens, along with the necessary
positional information, are then sent to the main model for processing. We
evaluate SpecPrefill with a diverse set of tasks, followed by a comprehensive
benchmarking of performance improvement both in a real end-to-end setting and
ablation studies. SpecPrefill manages to serve Llama-3.1-405B-Instruct-FP8 with
up to $7\times$ maximal end-to-end QPS on real downstream tasks and
$7.66\times$ TTFT improvement during benchmarking.

摘要：改善首次标记时间 (TTFT) 是现代大型语言模型 (LLM) 推理引擎中至关重要的目标。因为优化 TTFT 直接导致更高的最大 QPS，并满足许多关键应用程序的要求。然而，提升 TTFT 众所周知具有挑战性，因为它纯粹受计算限制，并且性能瓶颈从自注意力转移到 MLP 部分。我们提出了 SpecPrefill，这是一个训练免费的框架，它基于以下见解加速了长上下文和中等上下文查询的推理 TTFT：LLM 足够通用，即使只给定精心选择的提示标记子集，也能保持质量。从本质上讲，SpecPrefill 利用轻量级模型根据上下文推测局部重要标记。然后将这些标记连同必要的位置信息一起发送到主模型进行处理。我们使用各种任务评估 SpecPrefill，然后在真实端到端设置和消融研究中对性能改进进行了全面基准测试。SpecPrefill 能够为 Llama-3.1-405B-Instruct-FP8 提供高达 7 倍的最大端到端 QPS，用于实际下游任务，并在基准测试期间将 TTFT 提高 7.66 倍。

##### **Inducing Diversity in Differentiable Search Indexing**
2502.02788v1 by Abhijeet Phatak, Jayant Sachdev, Sean D Rosario, Swati Kirti, Chittaranjan Tripathy

Differentiable Search Indexing (DSI) is a recent paradigm for information
retrieval which uses a transformer-based neural network architecture as the
document index to simplify the retrieval process. A differentiable index has
many advantages enabling modifications, updates or extensions to the index. In
this work, we explore balancing relevance and novel information content
(diversity) for training DSI systems inspired by Maximal Marginal Relevance
(MMR), and show the benefits of our approach over the naive DSI training. We
present quantitative and qualitative evaluations of relevance and diversity
measures obtained using our method on NQ320K and MSMARCO datasets in comparison
to naive DSI. With our approach, it is possible to achieve diversity without
any significant impact to relevance. Since we induce diversity while training
DSI, the trained model has learned to diversify while being relevant. This
obviates the need for a post-processing step to induce diversity in the recall
set as typically performed using MMR. Our approach will be useful for
Information Retrieval problems where both relevance and diversity are important
such as in sub-topic retrieval. Our work can also be easily be extended to the
incremental DSI settings which would enable fast updates to the index while
retrieving a diverse recall set.

摘要：可微搜索索引 (DSI) 是資訊檢索的最新範例，它使用基於轉換器的類神經網路架構作為文件索引，以簡化檢索程序。可微索引具有許多優點，可修改、更新或延伸索引。在這項工作中，我們探討平衡相關性和新資訊內容 (多樣性) 以訓練 DSI 系統，靈感來自最大邊際相關性 (MMR)，並展示我們的方法優於天真的 DSI 訓練。我們提出使用我們的方法在 NQ320K 和 MSMARCO 資料集上獲得相關性和多樣性評量的量化和質化評估，以與天真的 DSI 進行比較。透過我們的方法，可以在不對相關性造成任何顯著影響的情況下實現多樣性。由於我們在訓練 DSI 時引發多樣性，因此受過訓練的模型已經學會在相關的同時進行多樣化。這消除了對後處理步驟的需求，以引發召回設定中的多樣性，就像通常使用 MMR 執行的那樣。我們的做法對於相關性和多樣性都很重要的資訊檢索問題很有用，例如子主題檢索。我們的作品也可以很容易地擴展到增量 DSI 設定，這將允許在檢索多樣化召回設定的同時快速更新索引。

##### **SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models**
2502.02787v1 by Amirhossein Dabiriaghdam, Lele Wang

The rapid proliferation of large language models (LLMs) has created an urgent
need for reliable methods to detect whether a text is generated by such models.
In this paper, we propose SimMark, a posthoc watermarking algorithm that makes
LLMs' outputs traceable without requiring access to the model's internal
logits, enabling compatibility with a wide range of LLMs, including API-only
models. By leveraging the similarity of semantic sentence embeddings and
rejection sampling to impose detectable statistical patterns imperceptible to
humans, and employing a soft counting mechanism, SimMark achieves robustness
against paraphrasing attacks. Experimental results demonstrate that SimMark
sets a new benchmark for robust watermarking of LLM-generated content,
surpassing prior sentence-level watermarking techniques in robustness, sampling
efficiency, and applicability across diverse domains, all while preserving the
text quality.

摘要：大型語言模型 (LLM) 的快速擴散創造了迫切需要可靠方法來檢測文本是否是由此類模型產生的。
在本文中，我們提出 SimMark，這是一種事後浮水印演算法，它使 LLM 的輸出可追蹤，而不需要存取模型的內部邏輯，從而能與各種 LLM 相容，包括僅限 API 的模型。透過利用語義句子嵌入的相似性，以及拒絕抽樣來施加人類無法察覺的可偵測統計模式，並採用軟計數機制，SimMark 對改寫攻擊具備穩健性。實驗結果表明，SimMark 為 LLM 產生的內容的穩健浮水印設定了新的基準，在穩健性、抽樣效率和跨不同領域的適用性方面都超越了先前的句子級浮水印技術，同時保留了文字品質。

##### **Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation**
2502.02780v1 by Songlin Xu, Hao-Ning Wen, Hongyi Pan, Dallas Dominguez, Dongyin Hu, Xinyu Zhang

Student simulation supports educators to improve teaching by interacting with
virtual students. However, most existing approaches ignore the modulation
effects of course materials because of two challenges: the lack of datasets
with granularly annotated course materials, and the limitation of existing
simulation models in processing extremely long textual data. To solve the
challenges, we first run a 6-week education workshop from N = 60 students to
collect fine-grained data using a custom built online education system, which
logs students' learning behaviors as they interact with lecture materials over
time. Second, we propose a transferable iterative reflection (TIR) module that
augments both prompting-based and finetuning-based large language models (LLMs)
for simulating learning behaviors. Our comprehensive experiments show that TIR
enables the LLMs to perform more accurate student simulation than classical
deep learning models, even with limited demonstration data. Our TIR approach
better captures the granular dynamism of learning performance and inter-student
correlations in classrooms, paving the way towards a ''digital twin'' for
online education.

摘要：學生模擬支持教育工作者透過與虛擬學生互動來改善教學。然而，現有的方法大多忽略課程材料的調節效應，原因有兩個挑戰：缺乏詳細標註課程材料的資料集，以及現有模擬模型在處理極長文字資料時的限制。為了解決這些挑戰，我們首先從 N = 60 名學生中進行為期 6 週的教育工作坊，使用自訂建置的線上教育系統收集細粒度的資料，記錄學生在一段時間內與講義材料互動時的學習行為。其次，我們提出一個可轉移的迭代反思 (TIR) 模組，用於擴充基於提示和微調的大語言模型 (LLM)，以模擬學習行為。我們的綜合實驗顯示，即使示範資料有限，TIR 也能讓 LLM 執行比傳統深度學習模型更精準的學生模擬。我們的 TIR 方法能更佳捕捉學習表現的細粒度動態以及教室中的學生間關聯，為線上教育的「數位雙胞胎」鋪路。

##### **3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**
2502.02779v1 by Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell, Seena Dehkharghani, Jennifer A. Frontera, Arjun V. Masurkar, Kara Melmed, Narges Razavian

Head computed tomography (CT) imaging is a widely-used imaging modality with
multitudes of medical indications, particularly in assessing pathology of the
brain, skull, and cerebrovascular system. It is commonly the first-line imaging
in neurologic emergencies given its rapidity of image acquisition, safety,
cost, and ubiquity. Deep learning models may facilitate detection of a wide
range of diseases. However, the scarcity of high-quality labels and
annotations, particularly among less common conditions, significantly hinders
the development of powerful models. To address this challenge, we introduce
FM-CT: a Foundation Model for Head CT for generalizable disease detection,
trained using self-supervised learning. Our approach pre-trains a deep learning
model on a large, diverse dataset of 361,663 non-contrast 3D head CT scans
without the need for manual annotations, enabling the model to learn robust,
generalizable features. To investigate the potential of self-supervised
learning in head CT, we employed both discrimination with self-distillation and
masked image modeling, and we construct our model in 3D rather than at the
slice level (2D) to exploit the structure of head CT scans more comprehensively
and efficiently. The model's downstream classification performance is evaluated
using internal and three external datasets, encompassing both in-distribution
(ID) and out-of-distribution (OOD) data. Our results demonstrate that the
self-supervised foundation model significantly improves performance on
downstream diagnostic tasks compared to models trained from scratch and
previous 3D CT foundation models on scarce annotated datasets. This work
highlights the effectiveness of self-supervised learning in medical imaging and
sets a new benchmark for head CT image analysis in 3D, enabling broader use of
artificial intelligence for head CT-based diagnosis.

摘要：頭部電腦斷層掃描（CT）影像是一種廣泛使用的影像模式，具有
大量的醫療適應症，特別是在評估腦部、頭骨和腦血管系統的病理時。由於其影像擷取速度快、安全性、成本低和普遍性，通常是神經緊急情況下的第一線影像。深度學習模型可以促進對各種疾病的檢測。然而，高品質標籤和註釋的稀缺，特別是在較不常見的疾病中，顯著地阻礙了強大模型的發展。為了應對這一挑戰，我們引入了 FM-CT：一個用於頭部 CT 的基礎模型，用於可概化的疾病檢測，並使用自我監督學習進行訓練。我們的做法在一個包含 361,663 個非對比 3D 頭部 CT 掃描的大型、多樣化的數據集上預訓練一個深度學習模型，而無需手動註釋，使模型能夠學習強健、可概化的特徵。為了探討自我監督學習在頭部 CT 中的潛力，我們同時採用了帶有自我蒸餾的判別和遮罩影像建模，並且我們以 3D 而不是切片層級（2D）構建我們的模型，以更全面、有效地利用頭部 CT 掃描的結構。該模型的下游分類效能使用內部和三個外部數據集進行評估，包括分佈內 (ID) 和分佈外 (OOD) 資料。我們的結果表明，與從頭開始訓練的模型和先前在稀疏註釋數據集上訓練的 3D CT 基礎模型相比，自我監督基礎模型顯著改善了下游診斷任務的效能。這項工作突顯了自我監督學習在醫學影像中的有效性，並為 3D 頭部 CT 影像分析設定了一個新的基準，讓人工智慧能夠更廣泛地用於基於頭部 CT 的診斷。

##### **Cross-Modality Embedding of Force and Language for Natural Human-Robot Communication**
2502.02772v1 by Ravi Tejwani, Karl Velazquez, John Payne, Paolo Bonato, Harry Asada

A method for cross-modality embedding of force profile and words is presented
for synergistic coordination of verbal and haptic communication. When two
people carry a large, heavy object together, they coordinate through verbal
communication about the intended movements and physical forces applied to the
object. This natural integration of verbal and physical cues enables effective
coordination. Similarly, human-robot interaction could achieve this level of
coordination by integrating verbal and haptic communication modalities. This
paper presents a framework for embedding words and force profiles in a unified
manner, so that the two communication modalities can be integrated and
coordinated in a way that is effective and synergistic. Here, it will be shown
that, although language and physical force profiles are deemed completely
different, the two can be embedded in a unified latent space and proximity
between the two can be quantified. In this latent space, a force profile and
words can a) supplement each other, b) integrate the individual effects, and c)
substitute in an exchangeable manner. First, the need for cross-modality
embedding is addressed, and the basic architecture and key building block
technologies are presented. Methods for data collection and implementation
challenges will be addressed, followed by experimental results and discussions.

摘要：<paragraph>提出一种力剖面和单词的跨模态嵌入方法，用于言语和触觉沟通的协同协调。当两个人一起搬运一个又大又重的物体时，他们会通过言语沟通来协调预期的动作和施加在物体上的物理力。言语和物理提示的这种自然整合实现了有效的协调。类似地，人机交互可以通过整合言语和触觉沟通方式来实现这种级别的协调。本文提出了一个以统一方式嵌入单词和力剖面的框架，以便以有效且协同的方式整合和协调两种沟通方式。这里将展示，尽管语言和物理力剖面被认为是完全不同的，但两者可以嵌入到一个统一的潜在空间中，并且可以量化两者之间的接近度。在这个潜在空间中，力剖面和单词可以 a) 相互补充，b) 整合个体效应，以及 c) 以可交换的方式替换。首先，解决了跨模态嵌入的需求，并介绍了基本架构和关键构建模块技术。将解决数据收集和实施挑战的方法，然后是实验结果和讨论。</paragraph>

##### **Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning**
2502.02770v1 by Chaofan Lin, Jiaming Tang, Shuo Yang, Hanshuo Wang, Tian Tang, Boyu Tian, Ion Stoica, Song Han, Mingyu Gao

Leveraging attention sparsity to accelerate long-context large language
models (LLMs) has been a hot research topic. However, current algorithms such
as sparse attention or key-value (KV) cache compression tend to use a fixed
budget, which presents a significant challenge during deployment because it
fails to account for the dynamic nature of real-world scenarios, where the
optimal balance between accuracy and efficiency can vary greatly. In this
paper, we find that borrowing top-$p$ sampling (nucleus sampling) to sparse
attention can surprisingly achieve adaptive budgeting. Based on this, we
propose Twilight, a framework to bring adaptive sparsity to any existing sparse
attention algorithm without sacrificing their accuracy. Empirical results show
that Twilight can adaptively prune at most 98% of redundant tokens, leading to
$15.4\times$ acceleration in self-attention operations and $3.9\times$
acceleration in end-to-end per token latency in long context LLM decoding.

摘要：利用注意力稀疏性來加速長文本大型語言模型 (LLM) 一直是熱門的研究主題。然而，當前演算法（例如稀疏注意力或鍵值 (KV) 快取壓縮）往往使用固定預算，這在部署期間會造成重大挑戰，因為它無法考量真實世界場景的動態特性，其中準確度和效率之間的最佳平衡可能差異很大。在本文中，我們發現將頂部-$p$ 取樣（核取樣）借用給稀疏注意力可以驚人地實現自適應預算編列。基於此，我們提出 Twilight，一個架構，用於將自適應稀疏性帶入任何現有的稀疏注意力演算法，而不會犧牲其準確度。實證結果顯示，Twilight 可以自適應地剪除最多 98% 的冗餘代碼，導致自注意力運算加速 $15.4\times$，以及長文本 LLM 解碼的端對端每個代碼延遲加速 $3.9\times$。

##### **Planning with affordances: Integrating learned affordance models and symbolic planning**
2502.02768v1 by Rajesh Mangannavar

Intelligent agents working in real-world environments must be able to learn
about the environment and its capabilities which enable them to take actions to
change to the state of the world to complete a complex multi-step task in a
photorealistic environment. Learning about the environment is especially
important to perform various multiple-step tasks without having to redefine an
agent's action set for different tasks or environment settings. In our work, we
augment an existing task and motion planning framework with learned affordance
models of objects in the world to enable planning and executing multi-step
tasks using learned models. Each task can be seen as changing the current state
of the world to a given goal state. The affordance models provide us with what
actions are possible and how to perform those actions in any given state. A
symbolic planning algorithm uses this information and the starting and goal
state to create a feasible plan to reach the desired goal state to complete a
given task. We demonstrate our approach in a virtual 3D photorealistic
environment, AI2-Thor, and evaluate it on real-world tasks. Our results show
that our agent quickly learns how to interact with the environment and is well
prepared to perform tasks such as "Moving an object out of the way to reach the
desired location."

摘要：在现实世界环境中工作的智能代理必须能够学习环境及其能力，使它们能够采取行动来改变世界状态，以便在逼真的环境中完成复杂的多步骤任务。了解环境对于执行各种多步骤任务尤其重要，而无需为不同的任务或环境设置重新定义代理的动作集。在我们的工作中，我们使用世界中对象的学习能力模型来增强现有的任务和运动规划框架，以使用学习模型来规划和执行多步骤任务。每个任务都可以看作是将当前世界状态更改为给定的目标状态。能力模型为我们提供了在任何给定状态下可能采取哪些动作以及如何执行这些动作。符号规划算法使用此信息以及开始和目标状态来创建可行的计划，以达到所需的最终状态以完成给定的任务。我们在虚拟 3D 逼真环境 AI2-Thor 中演示了我们的方法，并对现实世界任务进行了评估。我们的结果表明，我们的代理可以快速学会如何与环境交互，并且已经为执行诸如“将物体移开以到达所需位置”之类的任务做好了充分的准备。

##### **Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**
2502.02756v1 by Obed Korshie Dzikunu, Shadab Ahamed, Amirhossein Toosi, Xiaoxiao Li, Arman Rahmim

This study proposes a new loss function for deep neural networks, L1-weighted
Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of
voxels based on their classification difficulty, towards automated detection
and segmentation of metastatic prostate cancer lesions in PET/CT scans. We
obtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with
biochemical recurrence metastatic prostate cancer. We trained two 3D
convolutional neural networks, Attention U-Net and SegResNet, and concatenated
the PET and CT volumes channel-wise as input. The performance of our custom
loss function was evaluated against the Dice and Dice Focal Loss functions. For
clinical significance, we considered a detected region of interest (ROI) as a
true positive if at least the voxel with the maximum standardized uptake value
falls within the ROI. We assessed the models' performance based on the number
of lesions in an image, tumour volume, activity, and extent of spread. The
L1DFL outperformed the comparative loss functions by at least 13% on the test
set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were
lower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal
Loss yielded more false positives, whereas the Dice Loss was more sensitive to
smaller volumes and struggled to segment larger lesions accurately. They also
exhibited network-specific variations and yielded declines in segmentation
accuracy with increased tumour spread. Our results demonstrate the potential of
L1DFL to yield robust segmentation of metastatic prostate cancer lesions in
PSMA PET/CT images. The results further highlight potential complexities
arising from the variations in lesion characteristics that may influence
automated prostate cancer tumour detection and segmentation. The code is
publicly available at: https://github.com/ObedDzik/pca_segment.git.

摘要：<paragraph>本研究針對深度神經網路提出一個新的損失函數，L1 加權 Dice 焦點損失 (L1DFL)，它利用 L1 範數根據體素的分類難度進行自適應加權，用於自動偵測和分割 PET/CT 掃描中轉移性前列腺癌病灶。我們取得 380 個經診斷為生化復發轉移性前列腺癌的患者的 PSMA [18-F] DCFPyL PET/CT 掃描。我們訓練了兩個 3D 捲積神經網路，Attention U-Net 和 SegResNet，並將 PET 和 CT 體積按通道連接作為輸入。我們自訂的損失函數的效能與 Dice 和 Dice 焦點損失函數進行評估。為了臨床意義，我們將一個偵測到的感興趣區域 (ROI) 視為真陽性，如果至少具有最大標準攝取值的體素落在 ROI 內。我們根據影像中的病灶數量、腫瘤體積、活性，以及擴散程度評估模型的效能。L1DFL 在測試組中至少比比較損失函數高出 13%。此外，Dice 損失和 Dice 焦點損失的 F1 分數分別比 L1DFL 低至少 6% 和 34%。Dice 焦點損失產生更多假陽性，而 Dice 損失對較小體積較為敏感，且難以準確分割較大病灶。它們也展現出網路特定的變化，並隨著腫瘤擴散而導致分割準確度下降。我們的結果證明 L1DFL 具有在 PSMA PET/CT 影像中產生轉移性前列腺癌病灶的強健分割的潛力。結果進一步強調由病灶特徵變化所產生的潛在複雜性，這可能會影響自動化前列腺癌腫瘤偵測和分割。程式碼公開於：https://github.com/ObedDzik/pca_segment.git。</paragraph>

##### **PatchPilot: A Stable and Cost-Efficient Agentic Patching Framework**
2502.02747v1 by Hongwei Li, Yuheng Tang, Shiqi Wang, Wenbo Guo

Recent research builds various patching agents that combine large language
models (LLMs) with non-ML tools and achieve promising results on the
state-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to
determine the patching workflows, existing patching agents can be categorized
as agent-based planning methods, which rely on LLMs for planning, and
human-based planning methods, which follow a pre-defined workflow. At a high
level, agent-based planning methods achieve high patching performance but with
a high cost and limited stability. Human-based planning methods, on the other
hand, are more stable and efficient but have key workflow limitations that
compromise their patching performance. In this paper, we propose PatchPilot, an
agentic patcher that strikes a balance between patching efficacy, stability,
and cost-efficiency. PatchPilot proposes a novel human-based planning workflow
with five components: reproduction, localization, generation, validation, and
refinement (where refinement is unique to PatchPilot). We introduce novel and
customized designs to each component to optimize their effectiveness and
efficiency. Through extensive experiments on the SWE-Bench benchmarks,
PatchPilot shows a superior performance than existing open-source methods while
maintaining low cost (less than 1$ per instance) and ensuring higher stability.
We also conduct a detailed ablation study to validate the key designs in each
component.

摘要：近期研究建構了各種修補代理，結合大型語言模型 (LLM) 與非 ML 工具，並在軟體修補基準 SWE-Bench 的最新技術 (SOTA) 上取得了可觀的成果。根據如何確定修補工作流程，現有的修補代理可分為依賴 LLM 進行規劃的基於代理的規劃方法，以及遵循預定義工作流程的基於人力的規劃方法。總體而言，基於代理的規劃方法可達成高修補效能，但成本高且穩定性有限。另一方面，基於人力的規劃方法較為穩定且有效率，但有重要的工作流程限制，會影響其修補效能。在本文中，我們提出 PatchPilot，一個在修補效能、穩定性和成本效益之間取得平衡的代理修補程式。PatchPilot 提出一個創新的基於人力的規劃工作流程，包含五個組成部分：重製、定位、生成、驗證和精煉（精煉是 PatchPilot 獨有的）。我們為每個組成部分引入創新且客製化的設計，以最佳化其效能和效率。透過在 SWE-Bench 基準上的廣泛實驗，PatchPilot 展現出優於現有開源方法的效能，同時維持低成本（每個實例低於 1 美元）並確保更高的穩定性。我們也進行了詳細的消融研究，以驗證每個組成部分中的關鍵設計。

##### **Vision-Language Model Dialog Games for Self-Improvement**
2502.02740v1 by Ksenia Konyushkova, Christos Kaplanis, Serkan Cabi, Misha Denil

The increasing demand for high-quality, diverse training data poses a
significant bottleneck in advancing vision-language models (VLMs). This paper
presents VLM Dialog Games, a novel and scalable self-improvement framework for
VLMs. Our approach leverages self-play between two agents engaged in a
goal-oriented play centered around image identification. By filtering for
successful game interactions, we automatically curate a high-quality dataset of
interleaved images and text. We demonstrate that fine-tuning on this synthetic
data leads to performance gains on downstream tasks and generalises across
datasets. Moreover, as the improvements in the model lead to better game play,
this procedure can be applied iteratively. This work paves the way for
self-improving VLMs, with potential applications in various real-world
scenarios especially when the high-quality multimodal data is scarce.

摘要：隨著對高品質、多元訓練資料需求的增加，在推進視覺語言模型 (VLM) 方面出現一個重大的瓶頸。本文提出 VLM 對話遊戲，一個新穎且可擴充的自提升架構，用於 VLM。我們的做法利用兩個參與以影像辨識為中心的目標導向遊戲的代理之間的自我對弈。透過篩選成功的遊戲互動，我們自動策展一個高品質的交錯影像和文字資料集。我們展示在這個合成資料上進行微調，會提升下游任務的效能，並在資料集之間進行概化。此外，隨著模型的提升導致更好的遊戲玩法，這個程序可以反覆套用。這項工作為自我提升的 VLM 鋪路，在各種真實世界場景中具有潛在應用，尤其是在高品質多模態資料稀少的情況下。

