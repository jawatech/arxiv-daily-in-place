{"2504.10478": {"publish_time": "2025-04-14", "title": "Weight Ensembling Improves Reasoning in Language Models", "paper_summary": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades-off between bias and variance.", "paper_summary_zh": "<paragraph>\u6211\u5011\u7814\u7a76\u4e86\u4e00\u7a2e\u5728\u63a8\u7406\u6a21\u578b\u8a13\u7df4\u904e\u7a0b\u4e2d\u51fa\u73fe\u7684\u5931\u6548\u6a21\u5f0f\uff0c\u9019\u7a2e\u6a21\u5f0f\u6703\u5c0e\u81f4\u751f\u6210\u7684\u591a\u6a23\u6027\u958b\u59cb\u5d29\u6f70\uff0c\u6700\u7d42\u5f71\u97ff\u6e2c\u8a66\u6642\u7684 scaling \u6548\u679c\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u76e3\u7763\u5f0f\u5fae\u8abf\uff08SFT\uff09\u904e\u7a0b\u4e2d\uff0cPass@1 \u7684\u901a\u904e\u7387\u78ba\u5be6\u6709\u6240\u63d0\u9ad8\uff0c\u4f46 Pass@k \u537b\u8fc5\u901f\u60e1\u5316\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u4e00\u500b\u7c21\u55ae\u7684\u5e72\u9810\u63aa\u65bd\uff0c\u5373\u5c07\u6700\u65b0\u7684 SFT \u6aa2\u67e5\u9ede\u7684\u6b0a\u91cd\u8207\u65e9\u671f\u6aa2\u67e5\u9ede\u7684\u6b0a\u91cd\u9032\u884c\u63d2\u503c\uff08\u4e5f\u7a31\u70ba WiSE-FT\uff09\uff0c\u5e7e\u4e4e\u5b8c\u5168\u6062\u5fa9\u4e86 Pass@k\uff0c\u540c\u6642\u4e5f\u63d0\u9ad8\u4e86 Pass@1\u3002WiSE-FT \u8b8a\u9ad4\u5be6\u73fe\u4e86\u66f4\u597d\u7684\u6e2c\u8a66\u6642 scaling \u6548\u679c\uff08Best@k\uff0c\u591a\u6578\u6295\u7968\uff09\uff0c\u4e26\u4e14\u5728\u901a\u904e\u5f37\u5316\u5b78\u7fd2\u9032\u4e00\u6b65\u8abf\u6574\u6642\uff0c\u7528\u66f4\u5c11\u7684\u6578\u64da\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7d50\u679c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u767c\u73fe WiSE-FT \u63d0\u4f9b\u4e86\u50c5\u900f\u904e\u591a\u6a23\u6027\u89e3\u78bc\u7b56\u7565\uff08\u5982\u6eab\u5ea6\u7e2e\u653e\uff09\u7121\u6cd5\u5be6\u73fe\u7684\u984d\u5916\u6548\u80fd\u63d0\u5347\u3002\u6211\u5011\u5c07 Pass@k \u7684\u504f\u5dee-\u65b9\u5dee\u6b0a\u8861\u5f62\u5f0f\u5316\uff0c\u4e26\u8003\u616e\u4e86\u6e2c\u8a66\u5206\u4f48\u4e0a Pass@1 \u7684\u671f\u671b\u503c\u548c\u65b9\u5dee\u3002\u6211\u5011\u767c\u73fe WiSE-FT \u53ef\u4ee5\u540c\u6642\u6e1b\u5c11\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u800c\u6eab\u5ea6\u7e2e\u653e\u5247\u9700\u8981\u5728\u504f\u5dee\u548c\u65b9\u5dee\u4e4b\u9593\u9032\u884c\u6b0a\u8861\u3002</paragraph>\n", "author": "Xingyu Dang et.al.", "authors": "Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan", "id": "2504.10478v2", "paper_url": "http://arxiv.org/abs/2504.10478v2", "repo": "null"}}