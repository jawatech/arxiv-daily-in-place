{"2410.08968": {"publish_time": "2024-10-11", "title": "Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements", "paper_summary": "The current paradigm for safety alignment of large language models (LLMs)\nfollows a one-size-fits-all approach: the model refuses to interact with any\ncontent deemed unsafe by the model provider. This approach lacks flexibility in\nthe face of varying social norms across cultures and regions. In addition,\nusers may have diverse safety needs, making a model with static safety\nstandards too restrictive to be useful, as well as too costly to be re-aligned.\n  We propose Controllable Safety Alignment (CoSA), a framework designed to\nadapt models to diverse safety requirements without re-training. Instead of\naligning a fixed model, we align models to follow safety configs -- free-form\nnatural language descriptions of the desired safety behaviors -- that are\nprovided as part of the system prompt. To adjust model safety behavior,\nauthorized users only need to modify such safety configs at inference time. To\nenable that, we propose CoSAlign, a data-centric method for aligning LLMs to\neasily adapt to diverse safety configs. Furthermore, we devise a novel\ncontrollability evaluation protocol that considers both helpfulness and\nconfigured safety, summarizing them into CoSA-Score, and construct CoSApien, a\nhuman-authored benchmark that consists of real-world LLM use cases with diverse\nsafety requirements and corresponding evaluation prompts.\n  We show that CoSAlign leads to substantial gains of controllability over\nstrong baselines including in-context alignment. Our framework encourages\nbetter representation and adaptation to pluralistic human values in LLMs, and\nthereby increasing their practicality.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5b89\u5168\u5c0d\u9f4a\u7576\u524d\u7bc4\u4f8b\u9075\u5faa\u4e00\u9ad4\u9069\u7528\u7684\u65b9\u6cd5\uff1a\u6a21\u578b\u62d2\u7d55\u8207\u6a21\u578b\u4f9b\u61c9\u5546\u8996\u70ba\u4e0d\u5b89\u5168\u7684\u4efb\u4f55\u5167\u5bb9\u4e92\u52d5\u3002\u9019\u7a2e\u65b9\u6cd5\u5728\u9762\u5c0d\u4e0d\u540c\u6587\u5316\u548c\u5730\u5340\u7684\u793e\u6703\u898f\u7bc4\u8b8a\u5316\u6642\u7f3a\u4e4f\u9748\u6d3b\u6027\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u8005\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u5b89\u5168\u9700\u6c42\uff0c\u9019\u4f7f\u5f97\u5177\u6709\u975c\u614b\u5b89\u5168\u6a19\u6e96\u7684\u6a21\u578b\u904e\u65bc\u56b4\u683c\u800c\u7121\u6cd5\u4f7f\u7528\uff0c\u800c\u4e14\u91cd\u65b0\u5c0d\u9f4a\u7684\u6210\u672c\u4e5f\u904e\u9ad8\u3002\n\u6211\u5011\u63d0\u51fa\u53ef\u63a7\u5b89\u5168\u5c0d\u9f4a (CoSA)\uff0c\u4e00\u500b\u65e8\u5728\u8b93\u6a21\u578b\u9069\u61c9\u4e0d\u540c\u7684\u5b89\u5168\u9700\u6c42\u800c\u7121\u9700\u91cd\u65b0\u8a13\u7df4\u7684\u67b6\u69cb\u3002\u6211\u5011\u4e0d\u662f\u5c0d\u9f4a\u56fa\u5b9a\u6a21\u578b\uff0c\u800c\u662f\u5c0d\u9f4a\u6a21\u578b\u4ee5\u9075\u5faa\u5b89\u5168\u8a2d\u5b9a\u6a94\uff0c\u4e5f\u5c31\u662f\u7cfb\u7d71\u63d0\u793a\u4e00\u90e8\u5206\u7684\u6240\u9700\u5b89\u5168\u884c\u70ba\u7684\u81ea\u7531\u5f62\u5f0f\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u3002\u70ba\u4e86\u8abf\u6574\u6a21\u578b\u5b89\u5168\u884c\u70ba\uff0c\u6388\u6b0a\u4f7f\u7528\u8005\u53ea\u9700\u8981\u5728\u63a8\u8ad6\u6642\u9593\u4fee\u6539\u6b64\u985e\u5b89\u5168\u8a2d\u5b9a\u6a94\u3002\u70ba\u4e86\u5be6\u73fe\u9019\u500b\u76ee\u7684\uff0c\u6211\u5011\u63d0\u51fa CoSAlign\uff0c\u4e00\u7a2e\u4ee5\u8cc7\u6599\u70ba\u4e2d\u5fc3\u7684 LLM \u5c0d\u9f4a\u65b9\u6cd5\uff0c\u53ef\u8f15\u9b06\u9069\u61c9\u4e0d\u540c\u7684\u5b89\u5168\u8a2d\u5b9a\u6a94\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u53ef\u63a7\u6027\u8a55\u4f30\u5354\u5b9a\uff0c\u540c\u6642\u8003\u616e\u4e86\u6709\u76ca\u6027\u548c\u5df2\u914d\u7f6e\u7684\u5b89\u5168\uff0c\u5c07\u5b83\u5011\u7e3d\u7d50\u5230 CoSA-Score \u4e2d\uff0c\u4e26\u5efa\u69cb\u4e86 CoSApien\uff0c\u4e00\u500b\u7531\u4eba\u985e\u7de8\u5beb\u7684\u57fa\u6e96\uff0c\u5305\u542b\u4e86\u5177\u6709\u4e0d\u540c\u5b89\u5168\u9700\u6c42\u7684\u771f\u5be6\u4e16\u754c LLM \u4f7f\u7528\u6848\u4f8b\u548c\u5c0d\u61c9\u7684\u8a55\u4f30\u63d0\u793a\u3002\n\u6211\u5011\u5c55\u793a\u4e86 CoSAlign \u5c0e\u81f4\u4e86\u5c0d\u6bd4\u5f37\u5927\u7684\u57fa\u6e96\uff08\u5305\u62ec\u4e0a\u4e0b\u6587\u5c0d\u9f4a\uff09\u7684\u53ef\u63a7\u6027\u5927\u5e45\u63d0\u5347\u3002\u6211\u5011\u7684\u67b6\u69cb\u9f13\u52f5\u5728 LLM \u4e2d\u66f4\u597d\u5730\u8868\u793a\u548c\u9069\u61c9\u591a\u5143\u5316\u7684\u4eba\u985e\u50f9\u503c\u89c0\uff0c\u5f9e\u800c\u63d0\u9ad8\u5176\u5be6\u7528\u6027\u3002", "author": "Jingyu Zhang et.al.", "authors": "Jingyu Zhang, Ahmed Elgohary, Ahmed Magooda, Daniel Khashabi, Benjamin Van Durme", "id": "2410.08968v1", "paper_url": "http://arxiv.org/abs/2410.08968v1", "repo": "null"}}