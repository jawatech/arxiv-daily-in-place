{"2311.17133": {"publish_time": "2023-11-28", "title": "Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond", "paper_summary": "This study investigated the performance, explainability, and robustness of\ndeployed artificial intelligence (AI) models in predicting mortality during the\nCOVID-19 pandemic and beyond. The first study of its kind, we found that\nBayesian Neural Networks (BNNs) and intelligent training techniques allowed our\nmodels to maintain performance amidst significant data shifts. Our results\nemphasize the importance of developing robust AI models capable of matching or\nsurpassing clinician predictions, even under challenging conditions. Our\nexploration of model explainability revealed that stochastic models generate\nmore diverse and personalized explanations thereby highlighting the need for AI\nmodels that provide detailed and individualized insights in real-world clinical\nsettings. Furthermore, we underscored the importance of quantifying uncertainty\nin AI models which enables clinicians to make better-informed decisions based\non reliable predictions. Our study advocates for prioritizing implementation\nscience in AI research for healthcare and ensuring that AI solutions are\npractical, beneficial, and sustainable in real-world clinical environments. By\naddressing unique challenges and complexities in healthcare settings,\nresearchers can develop AI models that effectively improve clinical practice\nand patient outcomes.", "paper_summary_zh": "", "author": "Jacob R. Epifano et.al.", "authors": "Jacob R. Epifano,Stephen Glass,Ravi P. Ramachandran,Sharad Patel,Aaron J. Masino,Ghulam Rasool", "id": "2311.17133v1", "paper_url": "http://arxiv.org/abs/2311.17133v1", "repo": "null"}}