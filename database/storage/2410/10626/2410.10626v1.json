{"2410.10626": {"publish_time": "2024-10-14", "title": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts", "paper_summary": "Adapting medical Large Language Models to local languages can reduce barriers\nto accessing healthcare services, but data scarcity remains a significant\nchallenge, particularly for low-resource languages. To address this, we first\nconstruct a high-quality medical dataset and conduct analysis to ensure its\nquality. In order to leverage the generalization capability of multilingual\nLLMs to efficiently scale to more resource-constrained languages, we explore\nthe internal information flow of LLMs from a multilingual perspective using\nMixture of Experts (MoE) modularity. Technically, we propose a novel MoE\nrouting method that employs language-specific experts and cross-lingual\nrouting. Inspired by circuit theory, our routing analysis revealed a Spread Out\nin the End information flow mechanism: while earlier layers concentrate\ncross-lingual information flow, the later layers exhibit language-specific\ndivergence. This insight directly led to the development of the Post-MoE\narchitecture, which applies sparse routing only in the later layers while\nmaintaining dense others. Experimental results demonstrate that this approach\nenhances the generalization of multilingual models to other languages while\npreserving interpretability. Finally, to efficiently scale the model to 50\nlanguages, we introduce the concept of language family experts, drawing on\nlinguistic priors, which enables scaling the number of languages without adding\nadditional parameters.", "paper_summary_zh": "<paragraph>\u91dd\u5c0d\u7576\u5730\u8a9e\u8a00\u8abf\u6574\u5927\u578b\u91ab\u7642\u8a9e\u8a00\u6a21\u578b\u80fd\u6e1b\u5c11\u53d6\u5f97\u91ab\u7642\u4fdd\u5065\u670d\u52d9\u7684\u969c\u7919\uff0c\u4f46\u8cc7\u6599\u7a00\u5c11\u7684\u554f\u984c\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u4f86\u8aaa\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u9996\u5148\u5efa\u69cb\u4e00\u500b\u9ad8\u54c1\u8cea\u7684\u91ab\u7642\u8cc7\u6599\u96c6\uff0c\u4e26\u9032\u884c\u5206\u6790\u4ee5\u78ba\u4fdd\u5176\u54c1\u8cea\u3002\u70ba\u4e86\u5584\u7528\u591a\u8a9e\u8a00 LLM \u7684\u6982\u5316\u80fd\u529b\uff0c\u4ee5\u6709\u6548\u64f4\u5c55\u5230\u66f4\u591a\u8cc7\u6e90\u53d7\u9650\u7684\u8a9e\u8a00\uff0c\u6211\u5011\u5f9e\u591a\u8a9e\u8a00\u7684\u89d2\u5ea6\u63a2\u7d22 LLM \u7684\u5167\u90e8\u8cc7\u8a0a\u6d41\uff0c\u4e26\u4f7f\u7528\u5c08\u5bb6\u6df7\u5408 (MoE) \u6a21\u7d44\u5316\u3002\u5728\u6280\u8853\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684 MoE \u8def\u7531\u65b9\u6cd5\uff0c\u63a1\u7528\u7279\u5b9a\u8a9e\u8a00\u7684\u5c08\u5bb6\u548c\u8de8\u8a9e\u8a00\u8def\u7531\u3002\u53d7\u5230\u96fb\u8def\u7406\u8ad6\u7684\u555f\u767c\uff0c\u6211\u5011\u7684\u8def\u7531\u5206\u6790\u63ed\u793a\u4e86\u4e00\u500b\u5728\u6700\u5f8c\u5206\u6563\u7684\u8cc7\u8a0a\u6d41\u6a5f\u5236\uff1a\u65e9\u671f\u5c64\u96c6\u4e2d\u8de8\u8a9e\u8a00\u8cc7\u8a0a\u6d41\uff0c\u800c\u5f8c\u7e8c\u5c64\u5247\u5c55\u73fe\u51fa\u7279\u5b9a\u8a9e\u8a00\u7684\u5206\u6b67\u3002\u9019\u500b\u898b\u89e3\u76f4\u63a5\u5c0e\u81f4\u5f8c MoE \u67b6\u69cb\u7684\u767c\u5c55\uff0c\u5b83\u50c5\u5728\u5f8c\u7e8c\u5c64\u5957\u7528\u7a00\u758f\u8def\u7531\uff0c\u540c\u6642\u7dad\u6301\u5176\u4ed6\u5c64\u7684\u7a20\u5bc6\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u9019\u7a2e\u65b9\u6cd5\u589e\u5f37\u4e86\u591a\u8a9e\u8a00\u6a21\u578b\u5c0d\u5176\u4ed6\u8a9e\u8a00\u7684\u6982\u5316\u80fd\u529b\uff0c\u540c\u6642\u4fdd\u7559\u4e86\u89e3\u91cb\u80fd\u529b\u3002\u6700\u5f8c\uff0c\u70ba\u4e86\u6709\u6548\u5730\u5c07\u6a21\u578b\u64f4\u5c55\u5230 50 \u7a2e\u8a9e\u8a00\uff0c\u6211\u5011\u5f15\u5165\u4e86\u8a9e\u8a00\u5bb6\u65cf\u5c08\u5bb6\u7684\u6982\u5ff5\uff0c\u5229\u7528\u8a9e\u8a00\u5148\u9a57\uff0c\u9019\u4f7f\u5f97\u6211\u5011\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u984d\u5916\u53c3\u6578\u7684\u60c5\u6cc1\u4e0b\u64f4\u5c55\u8a9e\u8a00\u6578\u91cf\u3002</paragraph>", "author": "Guorui Zheng et.al.", "authors": "Guorui Zheng, Xidong Wang, Juhao Liang, Nuo Chen, Yuping Zheng, Benyou Wang", "id": "2410.10626v1", "paper_url": "http://arxiv.org/abs/2410.10626v1", "repo": "https://github.com/freedomintelligence/apollomoe"}}