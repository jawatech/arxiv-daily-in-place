{"2503.09091": {"publish_time": "2025-03-12", "title": "Multi-Modal Foundation Models for Computational Pathology: A Survey", "paper_summary": "Foundation models have emerged as a powerful paradigm in computational\npathology (CPath), enabling scalable and generalizable analysis of\nhistopathological images. While early developments centered on uni-modal models\ntrained solely on visual data, recent advances have highlighted the promise of\nmulti-modal foundation models that integrate heterogeneous data sources such as\ntextual reports, structured domain knowledge, and molecular profiles. In this\nsurvey, we provide a comprehensive and up-to-date review of multi-modal\nfoundation models in CPath, with a particular focus on models built upon\nhematoxylin and eosin (H&E) stained whole slide images (WSIs) and tile-level\nrepresentations. We categorize 32 state-of-the-art multi-modal foundation\nmodels into three major paradigms: vision-language, vision-knowledge graph, and\nvision-gene expression. We further divide vision-language models into\nnon-LLM-based and LLM-based approaches. Additionally, we analyze 28 available\nmulti-modal datasets tailored for pathology, grouped into image-text pairs,\ninstruction datasets, and image-other modality pairs. Our survey also presents\na taxonomy of downstream tasks, highlights training and evaluation strategies,\nand identifies key challenges and future directions. We aim for this survey to\nserve as a valuable resource for researchers and practitioners working at the\nintersection of pathology and AI.", "paper_summary_zh": "<paragraph>\u57fa\u790e\u6a21\u578b\u5df2\u6210\u70ba\u8a08\u7b97\u75c5\u7406\u5b78 (CPath) \u4e2d\u4e00\u500b\u5f37\u5927\u7684\u5178\u7bc4\uff0c\u4f7f\u5176\u80fd\u5920\u5c0d\u7d44\u7e54\u75c5\u7406\u5b78\u5f71\u50cf\u9032\u884c\u53ef\u64f4\u5c55\u4e14\u53ef\u6cdb\u5316\u7684\u5206\u6790\u3002\u96d6\u7136\u65e9\u671f\u767c\u5c55\u96c6\u4e2d\u5728\u50c5\u4f7f\u7528\u8996\u89ba\u6578\u64da\u8a13\u7df4\u7684\u55ae\u6a21\u614b\u6a21\u578b\uff0c\u4f46\u8fd1\u671f\u7684\u9032\u5c55\u7a81\u986f\u4e86\u6574\u5408\u7570\u8cea\u6578\u64da\u6e90\uff08\u5982\u6587\u672c\u5831\u544a\u3001\u7d50\u69cb\u5316\u9818\u57df\u77e5\u8b58\u548c\u5206\u5b50\u5716\u8b5c\uff09\u7684\u591a\u6a21\u614b\u57fa\u790e\u6a21\u578b\u7684\u6f5b\u529b\u3002 \u5728\u672c\u7d9c\u8ff0\u4e2d\uff0c\u6211\u5011\u5c0d CPath \u4e2d\u7684\u591a\u6a21\u614b\u57fa\u790e\u6a21\u578b\u9032\u884c\u4e86\u5168\u9762\u548c\u6700\u65b0\u7684\u56de\u9867\uff0c\u7279\u5225\u95dc\u6ce8\u5efa\u7acb\u5728\u8607\u6728\u7cbe\u548c\u4f0a\u7d05 (H&E) \u67d3\u8272\u7684\u5168\u73bb\u7247\u5f71\u50cf (WSIs) \u548c\u5207\u7247\u7d1a\u8868\u5fb5\u4e4b\u4e0a\u7684\u6a21\u578b\u3002\u6211\u5011\u5c07 32 \u500b\u6700\u5148\u9032\u7684\u591a\u6a21\u614b\u57fa\u790e\u6a21\u578b\u5206\u70ba\u4e09\u5927\u985e\uff1a\u8996\u89ba-\u8a9e\u8a00\u3001\u8996\u89ba-\u77e5\u8b58\u5716\u8b5c\u548c\u8996\u89ba-\u57fa\u56e0\u8868\u9054\u3002 \u6211\u5011\u9032\u4e00\u6b65\u5c07\u8996\u89ba-\u8a9e\u8a00\u6a21\u578b\u5206\u70ba\u975e\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u57fa\u65bc LLM \u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u5011\u5206\u6790\u4e86 28 \u500b\u53ef\u7528\u7684\u3001\u5c08\u70ba\u75c5\u7406\u5b78\u5b9a\u5236\u7684\u591a\u6a21\u614b\u6578\u64da\u96c6\uff0c\u5c07\u5176\u5206\u70ba\u5716\u50cf-\u6587\u672c\u5c0d\u3001\u6307\u4ee4\u6578\u64da\u96c6\u4ee5\u53ca\u5716\u50cf-\u5176\u4ed6\u6a21\u614b\u5c0d\u3002\u6211\u5011\u7684\u7d9c\u8ff0\u9084\u63d0\u51fa\u4e86\u4e0b\u6e38\u4efb\u52d9\u7684\u5206\u985e\uff0c\u91cd\u9ede\u4ecb\u7d39\u4e86\u8a13\u7df4\u548c\u8a55\u4f30\u7b56\u7565\uff0c\u4e26\u6307\u51fa\u4e86\u95dc\u9375\u6311\u6230\u548c\u672a\u4f86\u65b9\u5411\u3002\u6211\u5011\u7684\u76ee\u6a19\u662f\u4f7f\u672c\u7d9c\u8ff0\u6210\u70ba\u5728\u75c5\u7406\u5b78\u548c\u4eba\u5de5\u667a\u6167\u4ea4\u53c9\u9818\u57df\u5de5\u4f5c\u7684\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u4eba\u54e1\u7684\u5bf6\u8cb4\u8cc7\u6e90\u3002</paragraph>\n", "author": "Dong Li et.al.", "authors": "Dong Li, Guihong Wan, Xintao Wu, Xinyu Wu, Xiaohui Chen, Yi He, Christine G. Lian, Peter K. Sorger, Yevgeniy R. Semenov, Chen Zhao", "id": "2503.09091v1", "paper_url": "http://arxiv.org/abs/2503.09091v1", "repo": "null"}}