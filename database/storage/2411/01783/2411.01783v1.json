{"2411.01783": {"publish_time": "2024-11-04", "title": "Context Parallelism for Scalable Million-Token Inference", "paper_summary": "We present context parallelism for long-context large language model\ninference, which achieves near-linear scaling for long-context prefill latency\nwith up to 128 H100 GPUs across 16 nodes. Particularly, our method achieves 1M\ncontext prefill with Llama3 405B model in 77s (93% parallelization efficiency,\n63% FLOPS utilization) and 128K context prefill in 3.8s. We develop two\nlossless exact ring attention variants: pass-KV and pass-Q to cover a wide\nrange of use cases with the state-of-the-art performance: full prefill,\npersistent KV prefill and decode. Benchmarks on H100 GPU hosts inter-connected\nwith RDMA and TCP both show similar scalability for long-context prefill,\ndemonstrating that our method scales well using common commercial data center\nwith medium-to-low inter-host bandwidth.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u7528\u65bc\u9577\u8a9e\u5883\u5927\u8a9e\u8a00\u6a21\u578b\u63a8\u8ad6\u7684\u8a9e\u5883\u5e73\u884c\uff0c\u5728 16 \u500b\u7bc0\u9ede\u4e0a\u4f7f\u7528\u591a\u9054 128 \u500b H100 GPU\uff0c\u53ef\u5be6\u73fe\u9577\u8a9e\u5883\u9810\u586b\u8f09\u5ef6\u9072\u7684\u8fd1\u7dda\u6027\u7e2e\u653e\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728 77 \u79d2\u5167\u4f7f\u7528 Llama3 405B \u6a21\u578b\u5be6\u73fe\u4e86 100 \u842c\u8a9e\u5883\u9810\u586b\u8f09\uff0893% \u4e26\u884c\u6548\u7387\uff0c63% FLOPS \u5229\u7528\u7387\uff09\u548c\u5728 3.8 \u79d2\u5167\u5be6\u73fe\u4e86 128K \u8a9e\u5883\u9810\u586b\u8f09\u3002\u6211\u5011\u958b\u767c\u4e86\u5169\u500b\u7121\u640d\u8017\u7cbe\u78ba\u74b0\u6ce8\u610f\u8b8a\u9ad4\uff1apass-KV \u548c pass-Q\uff0c\u4ee5\u6db5\u84cb\u5ee3\u6cdb\u7684\u7528\u4f8b\uff0c\u4e26\u5177\u6709\u6700\u5148\u9032\u7684\u6027\u80fd\uff1a\u5b8c\u5168\u9810\u586b\u8f09\u3001\u6301\u7e8c KV \u9810\u586b\u8f09\u548c\u89e3\u78bc\u3002\u5728\u8207 RDMA \u548c TCP \u4e92\u9023\u7684 H100 GPU \u4e3b\u6a5f\u4e0a\u7684\u57fa\u6e96\u6e2c\u8a66\u90fd\u986f\u793a\u4e86\u9577\u8a9e\u5883\u9810\u586b\u8f09\u7684\u985e\u4f3c\u53ef\u64f4\u5c55\u6027\uff0c\u8b49\u660e\u4e86\u6211\u5011\u7684\u6a21\u578b\u4f7f\u7528\u5177\u6709\u4e2d\u4f4e\u4e3b\u6a5f\u9593\u983b\u5bec\u7684\u5e38\u898b\u5546\u7528\u6578\u64da\u4e2d\u5fc3\u6642\u53ef\u5f88\u597d\u5730\u64f4\u5c55\u3002", "author": "Amy et.al.", "authors": "Amy, Yang, Jingyi Yang, Aya Ibrahim, Xinfeng Xie, Bangsheng Tang, Grigory Sizov, Jongsoo Park, Jianyu Huang", "id": "2411.01783v1", "paper_url": "http://arxiv.org/abs/2411.01783v1", "repo": "null"}}