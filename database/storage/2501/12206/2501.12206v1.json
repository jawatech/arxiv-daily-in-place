{"2501.12206": {"publish_time": "2025-01-21", "title": "Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model", "paper_summary": "Large Vision Language Models (LVLMs) have demonstrated remarkable\ncapabilities in understanding and describing visual content, achieving\nstate-of-the-art performance across various vision-language tasks. However,\nthese models frequently exhibit hallucination behavior, where they generate\ndescriptions containing objects or details absent in the input image. Our work\ninvestigates this phenomenon by analyzing attention patterns across transformer\nlayers and heads, revealing that hallucinations often stem from progressive\ndegradation of visual grounding in deeper layers. We propose a novel attention\nmodification approach that combines selective token emphasis and head-specific\nmodulation to maintain visual grounding throughout the generation process. Our\nmethod introduces two key components: (1) a dual-stream token selection\nmechanism that identifies and prioritizes both locally informative and\nspatially significant visual tokens, and (2) an attention head-specific\nmodulation strategy that differentially amplifies visual information processing\nbased on measured visual sensitivity of individual attention heads. Through\nextensive experimentation on the MSCOCO dataset, we demonstrate that our\napproach reduces hallucination rates by up to 62.3\\% compared to baseline\nmodels while maintaining comparable task performance. Our analysis reveals that\nselectively modulating tokens across attention heads with varying levels of\nvisual sensitivity can significantly improve visual grounding without requiring\nmodel retraining.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u5c55\u73fe\u51fa\u5728\u7406\u89e3\u548c\u63cf\u8ff0\u8996\u89ba\u5167\u5bb9\u65b9\u9762\u7684\u5353\u8d8a\u80fd\u529b\uff0c\u5728\u5404\u7a2e\u8996\u89ba\u8a9e\u8a00\u4efb\u52d9\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u7d93\u5e38\u8868\u73fe\u51fa\u5e7b\u89ba\u884c\u70ba\uff0c\u5b83\u5011\u6703\u7522\u751f\u5305\u542b\u8f38\u5165\u5f71\u50cf\u4e2d\u4e0d\u5b58\u5728\u7684\u7269\u4ef6\u6216\u7d30\u7bc0\u7684\u63cf\u8ff0\u3002\u6211\u5011\u7684\u7814\u7a76\u900f\u904e\u5206\u6790Transformer\u5c64\u548c\u982d\u90e8\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u4f86\u63a2\u8a0e\u9019\u7a2e\u73fe\u8c61\uff0c\u63ed\u793a\u5e7b\u89ba\u901a\u5e38\u6e90\u65bc\u8f03\u6df1\u5c64\u7684\u8996\u89ba\u57fa\u790e\u9010\u6f38\u9000\u5316\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u6ce8\u610f\u529b\u4fee\u6539\u65b9\u6cd5\uff0c\u7d50\u5408\u9078\u64c7\u6027\u7684\u6b0a\u6a19\u5f37\u8abf\u548c\u7279\u5b9a\u65bc\u982d\u90e8\u7684\u8abf\u8b8a\uff0c\u4ee5\u5728\u6574\u500b\u751f\u6210\u904e\u7a0b\u4e2d\u7dad\u6301\u8996\u89ba\u57fa\u790e\u3002\u6211\u5011\u7684\u6280\u8853\u5f15\u5165\u4e86\u5169\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff1a(1) \u4e00\u7a2e\u96d9\u4e32\u6d41\u6b0a\u6a19\u9078\u64c7\u6a5f\u5236\uff0c\u7528\u65bc\u8b58\u5225\u548c\u512a\u5148\u8655\u7406\u5c40\u90e8\u8cc7\u8a0a\u6027\u548c\u7a7a\u9593\u986f\u8457\u6027\u7684\u8996\u89ba\u6b0a\u6a19\uff0c\u4ee5\u53ca (2) \u4e00\u7a2e\u6ce8\u610f\u529b\u982d\u90e8\u7279\u5b9a\u8abf\u8b8a\u7b56\u7565\uff0c\u6839\u64da\u500b\u5225\u6ce8\u610f\u529b\u982d\u90e8\u7684\u6e2c\u91cf\u8996\u89ba\u654f\u611f\u5ea6\uff0c\u5c0d\u8996\u89ba\u8cc7\u8a0a\u8655\u7406\u9032\u884c\u4e0d\u540c\u7684\u653e\u5927\u3002\u900f\u904e\u5728 MSCOCO \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e\u4e86\u8207\u57fa\u6e96\u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6280\u8853\u5c07\u5e7b\u89ba\u7387\u964d\u4f4e\u4e86\u591a\u9054 62.3%\uff0c\u540c\u6642\u7dad\u6301\u4e86\u76f8\u7576\u7684\u4efb\u52d9\u8868\u73fe\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\uff0c\u9078\u64c7\u6027\u5730\u8abf\u8b8a\u5177\u6709\u4e0d\u540c\u8996\u89ba\u654f\u611f\u5ea6\u5c64\u7d1a\u7684\u6ce8\u610f\u529b\u982d\u90e8\u7684\u6b0a\u6a19\uff0c\u53ef\u4ee5\u5728\u4e0d\u9700\u91cd\u65b0\u8a13\u7df4\u6a21\u578b\u7684\u60c5\u6cc1\u4e0b\uff0c\u986f\u8457\u6539\u5584\u8996\u89ba\u57fa\u790e\u3002", "author": "Kazi Hasan Ibn Arif et.al.", "authors": "Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas", "id": "2501.12206v1", "paper_url": "http://arxiv.org/abs/2501.12206v1", "repo": "null"}}