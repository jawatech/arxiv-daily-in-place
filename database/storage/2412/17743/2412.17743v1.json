{"2412.17743": {"publish_time": "2024-12-23", "title": "YuLan-Mini: An Open Data-efficient Language Model", "paper_summary": "Effective pre-training of large language models (LLMs) has been challenging\ndue to the immense resource demands and the complexity of the technical\nprocesses involved. This paper presents a detailed technical report on\nYuLan-Mini, a highly capable base model with 2.42B parameters that achieves\ntop-tier performance among models of similar parameter scale. Our pre-training\napproach focuses on enhancing training efficacy through three key technical\ncontributions: an elaborate data pipeline combines data cleaning with data\nschedule strategies, a robust optimization method to mitigate training\ninstability, and an effective annealing approach that incorporates targeted\ndata selection and long context training. Remarkably, YuLan-Mini, trained on\n1.08T tokens, achieves performance comparable to industry-leading models that\nrequire significantly more data. To facilitate reproduction, we release the\nfull details of the data composition for each training phase. Project details\ncan be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.", "paper_summary_zh": "\u7531\u65bc\u9f90\u5927\u7684\u8cc7\u6e90\u9700\u6c42\u548c\u6280\u8853\u6d41\u7a0b\u7684\u8907\u96dc\u6027\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6709\u6548\u9810\u8a13\u7df4\u4e00\u76f4\u5177\u6709\u6311\u6230\u6027\u3002\u672c\u6587\u91dd\u5c0d YuLan-Mini \u63d0\u51fa\u4e86\u4e00\u4efd\u8a73\u7d30\u7684\u6280\u8853\u5831\u544a\uff0c\u9019\u662f\u4e00\u500b\u529f\u80fd\u5f37\u5927\u7684\u57fa\u790e\u6a21\u578b\uff0c\u64c1\u6709 2.42B \u500b\u53c3\u6578\uff0c\u5728\u985e\u4f3c\u53c3\u6578\u898f\u6a21\u7684\u6a21\u578b\u4e2d\u53d6\u5f97\u4e86\u9802\u5c16\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u9810\u8a13\u7df4\u65b9\u6cd5\u5c08\u6ce8\u65bc\u900f\u904e\u4e09\u500b\u95dc\u9375\u6280\u8853\u8ca2\u737b\u4f86\u589e\u5f37\u8a13\u7df4\u6548\u80fd\uff1a\u7cbe\u7dfb\u7684\u8cc7\u6599\u7ba1\u9053\u5c07\u8cc7\u6599\u6e05\u7406\u8207\u8cc7\u6599\u6392\u7a0b\u7b56\u7565\u7d50\u5408\u5728\u4e00\u8d77\uff0c\u7a69\u5065\u7684\u6700\u4f73\u5316\u65b9\u6cd5\u4f86\u6e1b\u8f15\u8a13\u7df4\u7684\u4e0d\u7a69\u5b9a\u6027\uff0c\u4ee5\u53ca\u7d50\u5408\u76ee\u6a19\u8cc7\u6599\u9078\u53d6\u548c\u9577\u8108\u7d61\u8a13\u7df4\u7684\u6709\u6548\u9000\u706b\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 1.08T \u500b\u7b26\u865f\u4e0a\u8a13\u7df4\u7684 YuLan-Mini\uff0c\u5176\u6548\u80fd\u53ef\u8207\u9700\u8981\u66f4\u591a\u8cc7\u6599\u7684\u696d\u754c\u9818\u5148\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002\u70ba\u4e86\u4fc3\u9032\u91cd\u73fe\uff0c\u6211\u5011\u516c\u958b\u4e86\u6bcf\u500b\u8a13\u7df4\u968e\u6bb5\u7684\u8cc7\u6599\u7d44\u6210\u7684\u5b8c\u6574\u8a73\u7d30\u8cc7\u6599\u3002\u5c08\u6848\u8a73\u7d30\u8cc7\u8a0a\u53ef\u900f\u904e\u4ee5\u4e0b\u9023\u7d50\u53d6\u5f97\uff1ahttps://github.com/RUC-GSAI/YuLan-Mini\u3002", "author": "Yiwen Hu et.al.", "authors": "Yiwen Hu, Huatong Song, Jia Deng, Jiapeng Wang, Jie Chen, Kun Zhou, Yutao Zhu, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Ji-Rong Wen", "id": "2412.17743v1", "paper_url": "http://arxiv.org/abs/2412.17743v1", "repo": "https://github.com/ruc-gsai/yulan-mini"}}