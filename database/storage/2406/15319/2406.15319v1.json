{"2406.15319": {"publish_time": "2024-06-21", "title": "LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs", "paper_summary": "In traditional RAG framework, the basic retrieval units are normally short.\nThe common retrievers like DPR normally work with 100-word Wikipedia\nparagraphs. Such a design forces the retriever to search over a large corpus to\nfind the `needle' unit. In contrast, the readers only need to extract answers\nfrom the short retrieved units. Such an imbalanced `heavy' retriever and\n`light' reader design can lead to sub-optimal performance. In order to\nalleviate the imbalance, we propose a new framework LongRAG, consisting of a\n`long retriever' and a `long reader'. LongRAG processes the entire Wikipedia\ninto 4K-token units, which is 30x longer than before. By increasing the unit\nsize, we significantly reduce the total units from 22M to 700K. This\nsignificantly lowers the burden of retriever, which leads to a remarkable\nretrieval score: answer recall@1=71% on NQ (previously 52%) and answer\nrecall@2=72% (previously 47%) on HotpotQA (full-wiki). Then we feed the top-k\nretrieved units ($\\approx$ 30K tokens) to an existing long-context LLM to\nperform zero-shot answer extraction. Without requiring any training, LongRAG\nachieves an EM of 62.7% on NQ, which is the best known result. LongRAG also\nachieves 64.3% on HotpotQA (full-wiki), which is on par of the SoTA model. Our\nstudy offers insights into the future roadmap for combining RAG with\nlong-context LLMs.", "paper_summary_zh": "\u5728\u50b3\u7d71\u7684 RAG \u6846\u67b6\u4e2d\uff0c\u57fa\u672c\u7684\u6aa2\u7d22\u55ae\u5143\u901a\u5e38\u5f88\u77ed\u3002\n\u50cf DPR \u9019\u6a23\u7684\u5e38\u898b\u6aa2\u7d22\u5668\u901a\u5e38\u8655\u7406 100 \u5b57\u7684\u7dad\u57fa\u767e\u79d1\u6bb5\u843d\u3002\n\u9019\u7a2e\u8a2d\u8a08\u8feb\u4f7f\u6aa2\u7d22\u5668\u5728\u5927\u578b\u8a9e\u6599\u5eab\u4e2d\u641c\u5c0b\u4ee5\u627e\u5230\u300c\u91dd\u982d\u300d\u55ae\u5143\u3002\n\u76f8\u53cd\u5730\uff0c\u8b80\u8005\u53ea\u9700\u8981\u5f9e\u6aa2\u7d22\u5230\u7684\u77ed\u55ae\u5143\u4e2d\u63d0\u53d6\u7b54\u6848\u3002\n\u9019\u7a2e\u4e0d\u5e73\u8861\u7684\u300c\u91cd\u300d\u6aa2\u7d22\u5668\u548c\u300c\u8f15\u300d\u8b80\u53d6\u5668\u8a2d\u8a08\u53ef\u80fd\u6703\u5c0e\u81f4\u6b21\u512a\u7684\u6548\u80fd\u3002\n\u70ba\u4e86\u7de9\u89e3\u9019\u7a2e\u4e0d\u5e73\u8861\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u6846\u67b6 LongRAG\uff0c\u5b83\u7531\u4e00\u500b\u300c\u9577\u6aa2\u7d22\u5668\u300d\u548c\u4e00\u500b\u300c\u9577\u8b80\u53d6\u5668\u300d\u7d44\u6210\u3002\nLongRAG \u5c07\u6574\u500b\u7dad\u57fa\u767e\u79d1\u8655\u7406\u6210 4K \u4ee4\u724c\u55ae\u5143\uff0c\u6bd4\u4ee5\u524d\u9577 30 \u500d\u3002\n\u900f\u904e\u589e\u52a0\u55ae\u5143\u5927\u5c0f\uff0c\u6211\u5011\u5c07\u7e3d\u55ae\u5143\u6578\u5f9e 22M \u5927\u5e45\u6e1b\u5c11\u5230 700K\u3002\n\u9019\u986f\u8457\u964d\u4f4e\u4e86\u6aa2\u7d22\u5668\u7684\u8ca0\u64d4\uff0c\u5f9e\u800c\u7522\u751f\u4e86\u986f\u8457\u7684\u6aa2\u7d22\u5206\u6578\uff1a\nNQ \u4e0a\u7684\u7b54\u6848\u53ec\u56de\u7387@1=71%\uff08\u4ee5\u524d\u70ba 52%\uff09\uff0cHotpotQA\uff08\u5168\u7dad\u57fa\uff09\u4e0a\u7684\u7b54\u6848\u53ec\u56de\u7387@2=72%\uff08\u4ee5\u524d\u70ba 47%\uff09\u3002\n\u7136\u5f8c\uff0c\u6211\u5011\u5c07\u524d k \u500b\u6aa2\u7d22\u5230\u7684\u55ae\u5143\uff08\u5927\u7d04 30K \u500b\u4ee4\u724c\uff09\u63d0\u4f9b\u7d66\u73fe\u6709\u7684\u9577\u8a9e\u5883 LLM\uff0c\u4ee5\u57f7\u884c\u96f6\u6b21\u5b78\u7fd2\u7b54\u6848\u63d0\u53d6\u3002\nLongRAG \u7121\u9700\u4efb\u4f55\u8a13\u7df4\uff0c\u5728 NQ \u4e0a\u5be6\u73fe\u4e86 62.7% \u7684 EM\uff0c\u9019\u662f\u5df2\u77e5\u6700\u597d\u7684\u7d50\u679c\u3002\nLongRAG \u5728 HotpotQA\uff08\u5168\u7dad\u57fa\uff09\u4e0a\u4e5f\u9054\u5230\u4e86 64.3%\uff0c\u9019\u8207 SoTA \u6a21\u578b\u76f8\u7576\u3002\n\u6211\u5011\u7684\u7814\u7a76\u70ba\u7d50\u5408 RAG \u8207\u9577\u8a9e\u5883 LLM \u7684\u672a\u4f86\u8def\u7dda\u5716\u63d0\u4f9b\u4e86\u898b\u89e3\u3002", "author": "Ziyan Jiang et.al.", "authors": "Ziyan Jiang, Xueguang Ma, Wenhu Chen", "id": "2406.15319v1", "paper_url": "http://arxiv.org/abs/2406.15319v1", "repo": "null"}}