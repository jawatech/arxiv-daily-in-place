{"2409.08887": {"publish_time": "2024-09-13", "title": "Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark", "paper_summary": "Visual Language Tracking (VLT) enhances tracking by mitigating the\nlimitations of relying solely on the visual modality, utilizing high-level\nsemantic information through language. This integration of the language enables\nmore advanced human-machine interaction. The essence of interaction is\ncognitive alignment, which typically requires multiple information exchanges,\nespecially in the sequential decision-making process of VLT. However, current\nVLT benchmarks do not account for multi-round interactions during tracking.\nThey provide only an initial text and bounding box (bbox) in the first frame,\nwith no further interaction as tracking progresses, deviating from the original\nmotivation of the VLT task. To address these limitations, we propose a novel\nand robust benchmark, VLT-MI (Visual Language Tracking with Multi-modal\nInteraction), which introduces multi-round interaction into the VLT task for\nthe first time. (1) We generate diverse, multi-granularity texts for\nmulti-round, multi-modal interaction based on existing mainstream VLT\nbenchmarks using DTLLM-VLT, leveraging the world knowledge of LLMs. (2) We\npropose a new VLT interaction paradigm that achieves multi-round interaction\nthrough text updates and object recovery. When multiple tracking failures\noccur, we provide the tracker with more aligned texts and corrected bboxes\nthrough interaction, thereby expanding the scope of VLT downstream tasks. (3)\nWe conduct comparative experiments on both traditional VLT benchmarks and\nVLT-MI, evaluating and analyzing the accuracy and robustness of trackers under\nthe interactive paradigm. This work offers new insights and paradigms for the\nVLT task, enabling a fine-grained evaluation of multi-modal trackers. We\nbelieve this approach can be extended to additional datasets in the future,\nsupporting broader evaluations and comparisons of video-language model\ncapabilities.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u8ffd\u8e64 (VLT) \u900f\u904e\u8a9e\u8a00\u5229\u7528\u9ad8\u5c64\u7d1a\u8a9e\u7fa9\u8cc7\u8a0a\uff0c\u6e1b\u8f15\u50c5\u4f9d\u8cf4\u8996\u89ba\u6a21\u5f0f\u7684\u9650\u5236\uff0c\u9032\u800c\u589e\u5f37\u8ffd\u8e64\u3002\u9019\u7a2e\u8a9e\u8a00\u6574\u5408\u80fd\u4fc3\u6210\u66f4\u9032\u968e\u7684\u4eba\u6a5f\u4e92\u52d5\u3002\u4e92\u52d5\u7684\u672c\u8cea\u5728\u65bc\u8a8d\u77e5\u5c0d\u9f4a\uff0c\u9019\u901a\u5e38\u9700\u8981\u591a\u91cd\u8cc7\u8a0a\u4ea4\u63db\uff0c\u7279\u5225\u662f\u5728 VLT \u7684\u5faa\u5e8f\u6c7a\u7b56\u904e\u7a0b\u4e2d\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684 VLT \u57fa\u6e96\u4e26\u672a\u8003\u91cf\u8ffd\u8e64\u671f\u9593\u7684\u591a\u8f2a\u4e92\u52d5\u3002\u5b83\u5011\u50c5\u5728\u7b2c\u4e00\u500b\u756b\u683c\u4e2d\u63d0\u4f9b\u521d\u59cb\u6587\u5b57\u548c\u908a\u754c\u6846 (bbox)\uff0c\u800c\u96a8\u8457\u8ffd\u8e64\u7684\u9032\u884c\u4e26\u672a\u9032\u4e00\u6b65\u4e92\u52d5\uff0c\u9019\u504f\u96e2\u4e86 VLT \u4efb\u52d9\u7684\u539f\u59cb\u52d5\u6a5f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u4e14\u7a69\u5065\u7684\u57fa\u6e96 VLT-MI\uff08\u591a\u6a21\u5f0f\u4e92\u52d5\u8996\u89ba\u8a9e\u8a00\u8ffd\u8e64\uff09\uff0c\u9019\u9996\u6b21\u5728 VLT \u4efb\u52d9\u4e2d\u5f15\u5165\u591a\u8f2a\u4e92\u52d5\u3002\uff081\uff09\u6211\u5011\u4f7f\u7528 DTLLM-VLT \u6839\u64da\u73fe\u6709\u7684\u4e3b\u6d41 VLT \u57fa\u6e96\uff0c\u70ba\u591a\u8f2a\u3001\u591a\u6a21\u5f0f\u4e92\u52d5\u7522\u751f\u591a\u6a23\u5316\u3001\u591a\u7c92\u5ea6\u7684\u6587\u5b57\uff0c\u4e26\u5229\u7528 LLM \u7684\u4e16\u754c\u77e5\u8b58\u3002\uff082\uff09\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684 VLT \u4e92\u52d5\u7bc4\u4f8b\uff0c\u900f\u904e\u6587\u5b57\u66f4\u65b0\u548c\u7269\u4ef6\u5fa9\u539f\u4f86\u9054\u6210\u591a\u8f2a\u4e92\u52d5\u3002\u7576\u767c\u751f\u591a\u500b\u8ffd\u8e64\u5931\u6557\u6642\uff0c\u6211\u5011\u900f\u904e\u4e92\u52d5\u70ba\u8ffd\u8e64\u5668\u63d0\u4f9b\u66f4\u4e00\u81f4\u7684\u6587\u5b57\u548c\u4fee\u6b63\u7684 bbox\uff0c\u5f9e\u800c\u64f4\u5c55 VLT \u4e0b\u6e38\u4efb\u52d9\u7684\u7bc4\u570d\u3002\uff083\uff09\u6211\u5011\u5728\u50b3\u7d71 VLT \u57fa\u6e96\u548c VLT-MI \u4e0a\u9032\u884c\u6bd4\u8f03\u5be6\u9a57\uff0c\u8a55\u4f30\u548c\u5206\u6790\u5728\u4e92\u52d5\u7bc4\u4f8b\u4e0b\u8ffd\u8e64\u5668\u7684\u6e96\u78ba\u6027\u548c\u7a69\u5065\u6027\u3002\u9019\u9805\u5de5\u4f5c\u70ba VLT \u4efb\u52d9\u63d0\u4f9b\u4e86\u65b0\u7684\u898b\u89e3\u548c\u7bc4\u4f8b\uff0c\u80fd\u5c0d\u591a\u6a21\u5f0f\u8ffd\u8e64\u5668\u9032\u884c\u7d30\u7dfb\u7684\u8a55\u4f30\u3002\u6211\u5011\u76f8\u4fe1\u9019\u7a2e\u65b9\u6cd5\u672a\u4f86\u53ef\u4ee5\u64f4\u5c55\u5230\u5176\u4ed6\u8cc7\u6599\u96c6\uff0c\u652f\u63f4\u66f4\u5ee3\u6cdb\u7684\u8a55\u4f30\u548c\u5f71\u7247\u8a9e\u8a00\u6a21\u578b\u529f\u80fd\u7684\u6bd4\u8f03\u3002", "author": "Xuchen Li et.al.", "authors": "Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang", "id": "2409.08887v1", "paper_url": "http://arxiv.org/abs/2409.08887v1", "repo": "null"}}