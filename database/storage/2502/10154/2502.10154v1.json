{"2502.10154": {"publish_time": "2025-02-14", "title": "Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries", "paper_summary": "We introduce EMSYNC, a video-based symbolic music generation model that\naligns music with a video's emotional content and temporal boundaries. It\nfollows a two-stage framework, where a pretrained video emotion classifier\nextracts emotional features, and a conditional music generator produces MIDI\nsequences guided by both emotional and temporal cues. We introduce boundary\noffsets, a novel temporal conditioning mechanism that enables the model to\nanticipate and align musical chords with scene cuts. Unlike existing models,\nour approach retains event-based encoding, ensuring fine-grained timing control\nand expressive musical nuances. We also propose a mapping scheme to bridge the\nvideo emotion classifier, which produces discrete emotion categories, with the\nemotion-conditioned MIDI generator, which operates on continuous-valued\nvalence-arousal inputs. In subjective listening tests, EMSYNC outperforms\nstate-of-the-art models across all subjective metrics, for music theory-aware\nparticipants as well as the general listeners.", "paper_summary_zh": "\u6211\u5011\u4ecb\u7d39 EMSYNC\uff0c\u9019\u662f\u4e00\u500b\u57fa\u65bc\u5f71\u7247\u7684\u7b26\u865f\u97f3\u6a02\u751f\u6210\u6a21\u578b\uff0c\u5b83\u6703\u5c07\u97f3\u6a02\u8207\u5f71\u7247\u7684\u60c5\u7dd2\u5167\u5bb9\u548c\u6642\u9593\u754c\u7dda\u5c0d\u9f4a\u3002\u5b83\u9075\u5faa\u4e00\u500b\u5169\u968e\u6bb5\u67b6\u69cb\uff0c\u5176\u4e2d\u4e00\u500b\u9810\u5148\u8a13\u7df4\u597d\u7684\u5f71\u7247\u60c5\u7dd2\u5206\u985e\u5668\u6703\u8403\u53d6\u60c5\u7dd2\u7279\u5fb5\uff0c\u800c\u4e00\u500b\u689d\u4ef6\u5f0f\u97f3\u6a02\u7522\u751f\u5668\u6703\u6839\u64da\u60c5\u7dd2\u548c\u6642\u9593\u63d0\u793a\u7522\u751f MIDI \u5e8f\u5217\u3002\u6211\u5011\u4ecb\u7d39\u908a\u754c\u504f\u79fb\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u6642\u9593\u689d\u4ef6\u6a5f\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u9810\u6e2c\u4e26\u5c07\u97f3\u6a02\u548c\u5f26\u8207\u5834\u666f\u5207\u63db\u5c0d\u9f4a\u3002\u8207\u73fe\u6709\u6a21\u578b\u4e0d\u540c\uff0c\u6211\u5011\u7684\u505a\u6cd5\u4fdd\u7559\u4e86\u57fa\u65bc\u4e8b\u4ef6\u7684\u7de8\u78bc\uff0c\u78ba\u4fdd\u4e86\u7d30\u7dfb\u7684\u6642\u5e8f\u63a7\u5236\u548c\u8868\u73fe\u529b\u7684\u97f3\u6a02\u7d30\u5fae\u5dee\u5225\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e86\u5c0d\u61c9\u6a5f\u5236\uff0c\u4ee5\u5c07\u7522\u751f\u96e2\u6563\u60c5\u7dd2\u985e\u5225\u7684\u5f71\u7247\u60c5\u7dd2\u5206\u985e\u5668\uff0c\u8207\u4ee5\u9023\u7e8c\u503c\u6548\u50f9\u559a\u9192\u8f38\u5165\u904b\u4f5c\u7684\u60c5\u7dd2\u689d\u4ef6 MIDI \u7522\u751f\u5668\u806f\u7e6b\u8d77\u4f86\u3002\u5728\u4e3b\u89c0\u8046\u807d\u6e2c\u8a66\u4e2d\uff0cEMSYNC \u5728\u6240\u6709\u4e3b\u89c0\u6307\u6a19\u4e0a\u90fd\u512a\u65bc\u6700\u5148\u9032\u7684\u6a21\u578b\uff0c\u7121\u8ad6\u662f\u5c0d\u97f3\u6a02\u7406\u8ad6\u6709\u8a8d\u77e5\u7684\u53c3\u8207\u8005\uff0c\u9084\u662f\u666e\u901a\u807d\u773e\u3002", "author": "Serkan Sulun et.al.", "authors": "Serkan Sulun, Paula Viana, Matthew E. P. Davies", "id": "2502.10154v1", "paper_url": "http://arxiv.org/abs/2502.10154v1", "repo": "null"}}