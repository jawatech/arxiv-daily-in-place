
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-20**|**Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**|Rushuang Zhou et.al.|[2406.14377v1](http://arxiv.org/abs/2406.14377v1)|null|
|**2024-06-20**|**Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**|Niccolò Marini et.al.|[2406.14351v1](http://arxiv.org/abs/2406.14351v1)|null|
|**2024-06-20**|**Infusing clinical knowledge into tokenisers for language models**|Abul Hasan et.al.|[2406.14312v1](http://arxiv.org/abs/2406.14312v1)|null|
|**2024-06-20**|**Enhancing robustness of data-driven SHM models: adversarial training with circle loss**|Xiangli Yang et.al.|[2406.14232v1](http://arxiv.org/abs/2406.14232v1)|null|
|**2024-06-20**|**A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning**|Panagiotis Kaliosis et.al.|[2406.14164v1](http://arxiv.org/abs/2406.14164v1)|[link](https://github.com/nlpaueb/dmmcs)|
|**2024-06-20**|**Resource-efficient Medical Image Analysis with Self-adapting Forward-Forward Networks**|Johanna P. Müller et.al.|[2406.14038v1](http://arxiv.org/abs/2406.14038v1)|null|
|**2024-06-20**|**Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment**|Kaishuai Xu et.al.|[2406.13934v1](http://arxiv.org/abs/2406.13934v1)|[link](https://github.com/kaishxu/emulation)|
|**2024-06-19**|**ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World**|Weixiang Yan et.al.|[2406.13890v1](http://arxiv.org/abs/2406.13890v1)|[link](https://github.com/weixiangyan/clinicallab)|
|**2024-06-19**|**MAMA-MIA: A Large-Scale Multi-Center Breast Cancer DCE-MRI Benchmark Dataset with Expert Segmentations**|Lidia Garrucho et.al.|[2406.13844v1](http://arxiv.org/abs/2406.13844v1)|[link](https://github.com/lidiagarrucho/mama-mia)|
|**2024-06-19**|**IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being**|Amelie Gyrard et.al.|[2406.13791v1](http://arxiv.org/abs/2406.13791v1)|null|
|**2024-06-19**|**BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes**|Vansh Nagpal et.al.|[2406.13714v1](http://arxiv.org/abs/2406.13714v1)|null|
|**2024-06-19**|**EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy**|Long Bai et.al.|[2406.13705v1](http://arxiv.org/abs/2406.13705v1)|[link](https://github.com/longbai1006/endouic)|
|**2024-06-19**|**Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health**|Bo Wen et.al.|[2406.13659v1](http://arxiv.org/abs/2406.13659v1)|null|
|**2024-06-19**|**Enhance the Image: Super Resolution using Artificial Intelligence in MRI**|Ziyu Li et.al.|[2406.13625v1](http://arxiv.org/abs/2406.13625v1)|null|
|**2024-06-19**|**Optimizing Psychological Counseling with Instruction-Tuned Large Language Models**|Wenjie Li et.al.|[2406.13617v1](http://arxiv.org/abs/2406.13617v1)|null|
|**2024-06-19**|**Certificates of Differential Privacy and Unlearning for Gradient-Based Training**|Matthew Wicker et.al.|[2406.13433v1](http://arxiv.org/abs/2406.13433v1)|null|
|**2024-06-19**|**Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing**|Martin Lebourdais et.al.|[2406.13385v1](http://arxiv.org/abs/2406.13385v1)|null|
|**2024-06-19**|**Biomedical Visual Instruction Tuning with Clinician Preference Alignment**|Hejie Cui et.al.|[2406.13173v1](http://arxiv.org/abs/2406.13173v1)|null|
|**2024-06-19**|**Cardiac Copilot: Automatic Probe Guidance for Echocardiography with World Model**|Haojun Jiang et.al.|[2406.13165v1](http://arxiv.org/abs/2406.13165v1)|null|
|**2024-06-19**|**Oralytics Reinforcement Learning Algorithm**|Anna L. Trella et.al.|[2406.13127v1](http://arxiv.org/abs/2406.13127v1)|null|
|**2024-06-18**|**Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer**|Ahmed Abdeen Hamed et.al.|[2406.13106v1](http://arxiv.org/abs/2406.13106v1)|null|
|**2024-06-18**|**Deriving Hematological Disease Classes Using Fuzzy Logic and Expert Knowledge: A Comprehensive Machine Learning Approach with CBC Parameters**|Salem Ameen et.al.|[2406.13015v1](http://arxiv.org/abs/2406.13015v1)|null|
|**2024-06-18**|**Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation**|Nikolas Koutsoubis et.al.|[2406.12815v1](http://arxiv.org/abs/2406.12815v1)|[link](https://github.com/niko-k98/awesome-list-federated-learning-review)|
|**2024-06-18**|**Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs**|Joshua Durso-Finley et.al.|[2406.12807v1](http://arxiv.org/abs/2406.12807v1)|null|
|**2024-06-18**|**Large Language Model as a Universal Clinical Multi-task Decoder**|Yujiang Wu et.al.|[2406.12738v1](http://arxiv.org/abs/2406.12738v1)|null|
|**2024-06-18**|**Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly**|Siddhant Shete et.al.|[2406.12698v1](http://arxiv.org/abs/2406.12698v1)|null|
|**2024-06-18**|**Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics**|Huan Xu et.al.|[2406.12651v1](http://arxiv.org/abs/2406.12651v1)|null|
|**2024-06-18**|**An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation**|Qin Li et.al.|[2406.12646v1](http://arxiv.org/abs/2406.12646v1)|null|
|**2024-06-18**|**Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine**|Rui Yang et.al.|[2406.12449v1](http://arxiv.org/abs/2406.12449v1)|null|
|**2024-06-18**|**Adversarial Attacks on Large Language Models in Medicine**|Yifan Yang et.al.|[2406.12259v1](http://arxiv.org/abs/2406.12259v1)|null|
|**2024-06-18**|**Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers**|Haowei Ni et.al.|[2406.12199v1](http://arxiv.org/abs/2406.12199v1)|null|
|**2024-06-18**|**Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models**|Lulu Zhao et.al.|[2406.12182v1](http://arxiv.org/abs/2406.12182v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v1](http://arxiv.org/abs/2406.12142v1)|null|
|**2024-06-17**|**WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions**|Seyedali Mohammadi et.al.|[2406.12058v2](http://arxiv.org/abs/2406.12058v2)|null|
|**2024-06-17**|**MedCalc-Bench: Evaluating Large Language Models for Medical Calculations**|Nikhil Khandekar et.al.|[2406.12036v1](http://arxiv.org/abs/2406.12036v1)|[link](https://github.com/ncbi-nlp/medcalc-bench)|
|**2024-06-17**|**Socially Interactive Agents for Robotic Neurorehabilitation Training: Conceptualization and Proof-of-concept Study**|Rhythm Arora et.al.|[2406.12035v1](http://arxiv.org/abs/2406.12035v1)|null|
|**2024-06-17**|**Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**|Artur Jurgas et.al.|[2406.11538v1](http://arxiv.org/abs/2406.11538v1)|null|
|**2024-06-17**|**FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction**|Muhao Xu et.al.|[2406.11928v1](http://arxiv.org/abs/2406.11928v1)|[link](https://github.com/mhxu1998/flexcare)|
|**2024-06-17**|**Formally Certified Approximate Model Counting**|Yong Kiam Tan et.al.|[2406.11414v2](http://arxiv.org/abs/2406.11414v2)|null|
|**2024-06-17**|**Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**|Sungwon Park et.al.|[2406.11260v1](http://arxiv.org/abs/2406.11260v1)|null|
|**2024-06-17**|**Scorecards for Synthetic Medical Data Evaluation and Reporting**|Ghada Zamzmi et.al.|[2406.11143v1](http://arxiv.org/abs/2406.11143v1)|null|
|**2024-06-17**|**Diffusion Models in Low-Level Vision: A Survey**|Chunming He et.al.|[2406.11138v1](http://arxiv.org/abs/2406.11138v1)|null|
|**2024-06-17**|**Towards Understanding Emotions for Engaged Mental Health Conversations**|Kellie Yu Hui Sim et.al.|[2406.11135v1](http://arxiv.org/abs/2406.11135v1)|null|
|**2024-06-16**|**Boosting Medical Image Classification with Segmentation Foundation Model**|Pengfei Gu et.al.|[2406.11026v1](http://arxiv.org/abs/2406.11026v1)|null|
|**2024-06-16**|**ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**|Song Zhang et.al.|[2406.10855v1](http://arxiv.org/abs/2406.10855v1)|[link](https://github.com/strivezs/alps)|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**|Onyekachukwu R. Okonji et.al.|[2406.10632v1](http://arxiv.org/abs/2406.10632v1)|null|
|**2024-06-15**|**Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**|Anil Bhujel et.al.|[2406.10628v1](http://arxiv.org/abs/2406.10628v1)|null|
|**2024-06-15**|**Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**|Pengfei Gu et.al.|[2406.10519v1](http://arxiv.org/abs/2406.10519v1)|null|
|**2024-06-14**|**A Benchmark for Maximum Cut: Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization**|Ankur Nath et.al.|[2406.11897v1](http://arxiv.org/abs/2406.11897v1)|null|
|**2024-06-14**|**Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**|Chongmin Lee et.al.|[2406.10087v1](http://arxiv.org/abs/2406.10087v1)|null|
|**2024-06-14**|**FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in Biomedical Domain**|Jin Liu et.al.|[2406.10040v1](http://arxiv.org/abs/2406.10040v1)|[link](https://github.com/jens5588/fzi-wim-nli4ct)|
|**2024-06-14**|**CliBench: Multifaceted Evaluation of Large Language Models in Clinical Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions**|Mingyu Derek Ma et.al.|[2406.09923v1](http://arxiv.org/abs/2406.09923v1)|[link](https://github.com/clibench/clibench)|
|**2024-06-14**|**A Survey on Large Language Models from General Purpose to Medical Applications: Datasets, Methodologies, and Evaluations**|Jinqiang Wang et.al.|[2406.10303v1](http://arxiv.org/abs/2406.10303v1)|null|
|**2024-06-13**|**Investigating potential causes of Sepsis with Bayesian network structure learning**|Bruno Petrungaro et.al.|[2406.09207v1](http://arxiv.org/abs/2406.09207v1)|null|
|**2024-06-13**|**INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance**|Chenwei Lin et.al.|[2406.09105v1](http://arxiv.org/abs/2406.09105v1)|[link](https://github.com/fdu-ins/ins-mmbench)|
|**2024-06-13**|**Deep learning empowered sensor fusion to improve infant movement classification**|Tomas Kulvicius et.al.|[2406.09014v2](http://arxiv.org/abs/2406.09014v2)|null|
|**2024-06-13**|**Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals**|Qihan Hu et.al.|[2406.08930v1](http://arxiv.org/abs/2406.08930v1)|null|
|**2024-06-13**|**Computer Vision Approaches for Automated Bee Counting Application**|Simon Bilik et.al.|[2406.08898v1](http://arxiv.org/abs/2406.08898v1)|null|
|**2024-06-13**|**Automatically Labeling $200B Life-Saving Datasets: A Large Clinical Trial Outcome Benchmark**|Chufan Gao et.al.|[2406.10292v1](http://arxiv.org/abs/2406.10292v1)|null|
|**2024-06-12**|**Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis**|Attrayee Chakraborty et.al.|[2406.08695v1](http://arxiv.org/abs/2406.08695v1)|null|
|**2024-06-12**|**Advancing High Resolution Vision-Language Models in Biomedicine**|Zekai Chen et.al.|[2406.09454v1](http://arxiv.org/abs/2406.09454v1)|[link](https://github.com/standardmodelbio/llama3-med)|
|**2024-06-12**|**AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**|Ayush Roy et.al.|[2406.08425v1](http://arxiv.org/abs/2406.08425v1)|[link](https://github.com/ayushroy2001/awgunet)|
|**2024-06-12**|**2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**|Tianqi Chen et.al.|[2406.08374v2](http://arxiv.org/abs/2406.08374v2)|null|
|**2024-06-12**|**Making AI Intelligible: Philosophical Foundations**|Herman Cappelen et.al.|[2406.08134v1](http://arxiv.org/abs/2406.08134v1)|null|
|**2024-06-12**|**Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**|Peizhi Niu et.al.|[2406.07917v1](http://arxiv.org/abs/2406.07917v1)|null|
|**2024-06-11**|**Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis**|Matteo Esposito et.al.|[2406.10273v1](http://arxiv.org/abs/2406.10273v1)|null|
|**2024-06-11**|**Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**|David Ortiz-Perez et.al.|[2406.07542v1](http://arxiv.org/abs/2406.07542v1)|[link](https://github.com/davidorp/taukadial)|
|**2024-06-11**|**CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**|Frederic Kirstein et.al.|[2406.07494v2](http://arxiv.org/abs/2406.07494v2)|null|
|**2024-06-11**|**Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**|Che Liu et.al.|[2406.07146v2](http://arxiv.org/abs/2406.07146v2)|null|
|**2024-06-11**|**Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v1](http://arxiv.org/abs/2406.07114v1)|null|
|**2024-06-11**|**Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**|Chenxia Tang et.al.|[2406.07028v1](http://arxiv.org/abs/2406.07028v1)|null|
|**2024-06-10**|**Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**|Kiran Kokilepersaud et.al.|[2406.06848v1](http://arxiv.org/abs/2406.06848v1)|null|
|**2024-06-10**|**SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**|David Wadden et.al.|[2406.07835v1](http://arxiv.org/abs/2406.07835v1)|null|
|**2024-06-10**|**BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**|June-Woo Kim et.al.|[2406.06786v2](http://arxiv.org/abs/2406.06786v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Merlin: A Vision Language Foundation Model for 3D Computed Tomography**|Louis Blankemeier et.al.|[2406.06512v1](http://arxiv.org/abs/2406.06512v1)|null|
|**2024-06-10**|**Towards a Personal Health Large Language Model**|Justin Cosentino et.al.|[2406.06474v1](http://arxiv.org/abs/2406.06474v1)|null|
|**2024-06-10**|**Transforming Wearable Data into Health Insights using Large Language Model Agents**|Mike A. Merrill et.al.|[2406.06464v2](http://arxiv.org/abs/2406.06464v2)|null|
|**2024-06-10**|**A Large Language Model Pipeline for Breast Cancer Oncology**|Tristen Pool et.al.|[2406.06455v2](http://arxiv.org/abs/2406.06455v2)|null|
|**2024-06-10**|**Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**|Brian Hu et.al.|[2406.06435v1](http://arxiv.org/abs/2406.06435v1)|[link](https://github.com/itm-kitware/llm-alignable-dm)|
|**2024-06-10**|**Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**|Marek Wodzinski et.al.|[2406.06372v1](http://arxiv.org/abs/2406.06372v1)|null|
|**2024-06-10**|**MedExQA: Medical Question Answering Benchmark with Multiple Explanations**|Yunsoo Kim et.al.|[2406.06331v1](http://arxiv.org/abs/2406.06331v1)|null|
|**2024-06-10**|**BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**|Wanaiu Huang et.al.|[2406.07584v1](http://arxiv.org/abs/2406.07584v1)|null|
|**2024-06-10**|**A Dual-View Approach to Classifying Radiology Reports by Co-Training**|Yutong Han et.al.|[2406.05995v1](http://arxiv.org/abs/2406.05995v1)|[link](https://github.com/manga-uofa/radiology-cotrain)|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-10**|**Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**|Jingru Jia et.al.|[2406.05972v1](http://arxiv.org/abs/2406.05972v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-09**|**From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**|Ran Xu et.al.|[2406.05682v1](http://arxiv.org/abs/2406.05682v1)|null|
|**2024-06-09**|**CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**|Sana Ayromlou et.al.|[2406.05631v1](http://arxiv.org/abs/2406.05631v1)|[link](https://github.com/ubc-tea/continual-impression-ccsi)|
|**2024-06-09**|**Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**|Pranav Jeevan et.al.|[2406.05612v1](http://arxiv.org/abs/2406.05612v1)|[link](https://github.com/pranavphoenix/Backbones)|
|**2024-06-08**|**I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**|Mohit Kumar Singh et.al.|[2406.05505v1](http://arxiv.org/abs/2406.05505v1)|null|
|**2024-06-08**|**DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**|Miriam Farrington et.al.|[2406.05307v1](http://arxiv.org/abs/2406.05307v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**|Jorden Lam et.al.|[2406.05189v1](http://arxiv.org/abs/2406.05189v1)|null|
|**2024-06-07**|**Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**|Deepa Tilwani et.al.|[2406.05002v1](http://arxiv.org/abs/2406.05002v1)|[link](https://github.com/lina-usc/jansen-rit-model-benchmarking-deep-learning)|
|**2024-06-07**|**DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**|Weiqi Zhang et.al.|[2406.06620v1](http://arxiv.org/abs/2406.06620v1)|null|
|**2024-06-07**|**CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**|Matthew Fortier et.al.|[2406.04940v1](http://arxiv.org/abs/2406.04940v1)|null|
|**2024-06-07**|**PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**|Shuo Yu et.al.|[2406.06618v1](http://arxiv.org/abs/2406.06618v1)|null|

#### Abstracts
##### **Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**
2406.14377v1 by Rushuang Zhou, Zijun Liu, Lei Clifton, David A. Clifton, Kannie W. Y. Chan, Yuan-Ting Zhang, Yining Dong

Label scarcity problem is the main challenge that hinders the wide
application of deep learning systems in automatic cardiovascular diseases
(CVDs) detection using electrocardiography (ECG). Tuning pre-trained models
alleviates this problem by transferring knowledge learned from large datasets
to downstream small datasets. However, bottlenecks in computational efficiency
and CVDs detection performance limit its clinical applications. It is difficult
to improve the detection performance without significantly sacrificing model
computational efficiency. Here, we propose a computation-efficient
semi-supervised learning paradigm (FastECG) for robust and
computation-efficient CVDs detection using ECG. It enables a robust adaptation
of pre-trained models on downstream datasets with limited supervision and high
computational efficiency. First, a random-deactivation technique is developed
to achieve robust and fast low-rank adaptation of pre-trained weights.
Subsequently, we propose a one-shot rank allocation module to determine the
optimal ranks for the update matrices of the pre-trained weights. Finally, a
lightweight semi-supervised learning pipeline is introduced to enhance model
performance by leveraging labeled and unlabeled data with high computational
efficiency. Extensive experiments on four downstream ECG datasets demonstrate
that FastECG not only outperforms the state-of-the-art methods in multi-label
CVDs detection but also consumes fewer GPU footprints, training time, and
parameter storage space. As such, this paradigm provides an effective solution
for achieving high computational efficiency and robust detection performance in
the clinical applications of pre-trained models under limited supervision.

摘要：標籤稀缺問題是阻礙深度學習系統在自動心血管疾病 (CVD) 使用心電圖 (ECG) 檢測中廣泛應用之主要挑戰。調整預訓練模型透過將從大型資料集學到的知識轉移到下游小型資料集，來緩解此問題。然而，運算效率和 CVD 檢測效能的瓶頸限制了其臨床應用。在不顯著犧牲模型運算效率的情況下，難以改善檢測效能。在此，我們提出一個運算效率的半監督學習範例 (FastECG)，用於使用 ECG 進行穩健且運算效率高的 CVD 檢測。它能讓預訓練模型在監督有限且運算效率高的下游資料集上進行穩健的調整。首先，開發出一種隨機停用技術，以達成預訓練權重的穩健且快速的低秩調整。接著，我們提出一個一次性秩配置模組，用於確定預訓練權重的更新矩陣之最佳秩。最後，引入一個輕量級的半監督學習管線，以利用標籤和未標籤資料，並在高運算效率下提升模型效能。在四個下游 ECG 資料集上的廣泛實驗證明，FastECG 不僅在多標籤 CVD 檢測中優於最先進的方法，而且消耗更少的 GPU 占用空間、訓練時間和參數儲存空間。因此，此範例提供了一個有效的解決方案，用於在監督有限的情況下，於預訓練模型的臨床應用中達成高運算效率和穩健的檢測效能。

##### **Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**
2406.14351v1 by Niccolò Marini, Stefano Marchesin, Lluis Borras Ferris, Simon Püttmann, Marek Wodzinski, Riccardo Fratti, Damian Podareanu, Alessandro Caputo, Svetla Boytcheva, Simona Vatrano, Filippo Fraggetta, Iris Nagtegaal, Gianmaria Silvello, Manfredo Atzori, Henning Müller

The increasing availability of biomedical data is helping to design more
robust deep learning (DL) algorithms to analyze biomedical samples. Currently,
one of the main limitations to train DL algorithms to perform a specific task
is the need for medical experts to label data. Automatic methods to label data
exist, however automatic labels can be noisy and it is not completely clear
when automatic labels can be adopted to train DL models. This paper aims to
investigate under which circumstances automatic labels can be adopted to train
a DL model on the classification of Whole Slide Images (WSI). The analysis
involves multiple architectures, such as Convolutional Neural Networks (CNN)
and Vision Transformer (ViT), and over 10000 WSIs, collected from three use
cases: celiac disease, lung cancer and colon cancer, which one including
respectively binary, multiclass and multilabel data. The results allow
identifying 10% as the percentage of noisy labels that lead to train
competitive models for the classification of WSIs. Therefore, an algorithm
generating automatic labels needs to fit this criterion to be adopted. The
application of the Semantic Knowledge Extractor Tool (SKET) algorithm to
generate automatic labels leads to performance comparable to the one obtained
with manual labels, since it generates a percentage of noisy labels between
2-5%. Automatic labels are as effective as manual ones, reaching solid
performance comparable to the one obtained training models with manual labels.

摘要：隨著生物醫學資料的日益普及，有助於設計更穩健的深度學習 (DL) 演算法來分析生物醫學樣本。目前，訓練 DL 演算法執行特定任務的主要限制之一在於醫學專家標記資料的需求。標記資料的自動化方法確實存在，然而自動化標籤可能會產生雜訊，而且尚不清楚何時可以採用自動化標籤來訓練 DL 模型。本文旨在探討在何種情況下可以採用自動化標籤來訓練 DL 模型對全切片影像 (WSI) 進行分類。分析涉及多種架構，例如卷積神經網路 (CNN) 和視覺Transformer (ViT)，以及超過 10000 個 WSI，這些 WSI 來自三種使用案例：乳糜瀉、肺癌和結腸癌，其中一個分別包括二元、多類和多標籤資料。結果可以將產生雜訊標籤的比例確定為 10%，這將導致訓練出具有競爭力的 WSI 分類模型。因此，產生自動化標籤的演算法需要符合此準則才能被採用。將語義知識萃取工具 (SKET) 演算法應用於產生自動化標籤，其效能可與使用人工標籤獲得的效能相媲美，因為它產生的雜訊標籤比例在 2-5% 之間。自動化標籤與人工標籤一樣有效，可達到與使用人工標籤訓練模型所獲得的效能相當的穩健效能。

##### **Infusing clinical knowledge into tokenisers for language models**
2406.14312v1 by Abul Hasan, Jinge Wu, Quang Ngoc Nguyen, Salomé Andres, Imane Guellil, Huayu Zhang, Arlene Casey, Beatrice Alex, Bruce Guthrie, Honghan Wu

This study introduces a novel knowledge enhanced tokenisation mechanism,
K-Tokeniser, for clinical text processing. Technically, at initialisation
stage, K-Tokeniser populates global representations of tokens based on semantic
types of domain concepts (such as drugs or diseases) from either a domain
ontology like Unified Medical Language System or the training data of the task
related corpus. At training or inference stage, sentence level localised
context will be utilised for choosing the optimal global token representation
to realise the semantic-based tokenisation. To avoid pretraining using the new
tokeniser, an embedding initialisation approach is proposed to generate
representations for new tokens. Using three transformer-based language models,
a comprehensive set of experiments are conducted on four real-world datasets
for evaluating K-Tokeniser in a wide range of clinical text analytics tasks
including clinical concept and relation extraction, automated clinical coding,
clinical phenotype identification, and clinical research article
classification. Overall, our models demonstrate consistent improvements over
their counterparts in all tasks. In particular, substantial improvements are
observed in the automated clinical coding task with 13\% increase on Micro
$F_1$ score. Furthermore, K-Tokeniser also shows significant capacities in
facilitating quicker converge of language models. Specifically, using
K-Tokeniser, the language models would only require 50\% of the training data
to achieve the best performance of the baseline tokeniser using all training
data in the concept extraction task and less than 20\% of the data for the
automated coding task. It is worth mentioning that all these improvements
require no pre-training process, making the approach generalisable.

摘要：本研究引入一種新穎的知識增強標記化機制，K-Tokeniser，用於臨床文本處理。技術上，在初始化階段，K-Tokeniser 會根據來自領域概念（例如藥物或疾病）的語義類型，從統一醫學語言系統或任務相關語料庫的訓練資料中，填充標記的全局表示。在訓練或推論階段，句子級別的局部化上下文將被用於選擇最佳的全局標記表示，以實現基於語義的標記化。為了避免使用新的標記化器進行預訓練，提出了一種嵌入初始化方法，以產生新標記的表示。使用三種基於Transformer的語言模型，對四個真實世界數據集進行了一組全面的實驗，以評估 K-Tokeniser 在廣泛的臨床文本分析任務中的表現，包括臨床概念和關係提取、自動臨床編碼、臨床表型識別和臨床研究文章分類。總體而言，我們的模型在所有任務中都展示出比其對應模型更一致的改進。特別是，在自動臨床編碼任務中觀察到了顯著的改進，Micro $F_1$ 得分提高了 13%。此外，K-Tokeniser 還顯示出顯著的能力，可以促進語言模型更快的收斂。具體來說，使用 K-Tokeniser，語言模型只需要 50% 的訓練數據即可在概念提取任務中達到基線標記化器使用所有訓練數據的最佳性能，而自動編碼任務則不到 20% 的數據。值得一提的是，所有這些改進都不需要預訓練過程，這使得該方法具有普遍性。

##### **Enhancing robustness of data-driven SHM models: adversarial training with circle loss**
2406.14232v1 by Xiangli Yang, Xijie Deng, Hanwei Zhang, Yang Zou, Jianxi Yang

Structural health monitoring (SHM) is critical to safeguarding the safety and
reliability of aerospace, civil, and mechanical infrastructure. Machine
learning-based data-driven approaches have gained popularity in SHM due to
advancements in sensors and computational power. However, machine learning
models used in SHM are vulnerable to adversarial examples -- even small changes
in input can lead to different model outputs. This paper aims to address this
problem by discussing adversarial defenses in SHM. In this paper, we propose an
adversarial training method for defense, which uses circle loss to optimize the
distance between features in training to keep examples away from the decision
boundary. Through this simple yet effective constraint, our method demonstrates
substantial improvements in model robustness, surpassing existing defense
mechanisms.

摘要：結構健康監測 (SHM) 對保障航太、土木和機械基礎設施的安全和可靠性至關重要。機器學習為基礎的資料驅動方法由於感測器和計算能力的進步，在 SHM 中獲得普及。然而，用於 SHM 的機器學習模型容易受到對抗性範例的影響——輸入的微小變更甚至可能導致不同的模型輸出。本文旨在透過討論 SHM 中的對抗性防禦來解決此問題。在本文中，我們提出了一種用於防禦的對抗性訓練方法，該方法使用圓形損失來最佳化訓練中特徵之間的距離，以使範例遠離決策邊界。透過這個簡單但有效的約束，我們的模型展示了模型穩健性的顯著改善，超越了現有的防禦機制。

##### **A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning**
2406.14164v1 by Panagiotis Kaliosis, John Pavlopoulos, Foivos Charalampakos, Georgios Moschovis, Ion Androutsopoulos

Diagnostic Captioning (DC) automatically generates a diagnostic text from one
or more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft,
the generated text may assist clinicians, by providing an initial estimation of
the patient's condition, speeding up and helping safeguard the diagnostic
process. The accuracy of a diagnostic text, however, strongly depends on how
well the key medical conditions depicted in the images are expressed. We
propose a new data-driven guided decoding method that incorporates medical
information, in the form of existing tags capturing key conditions of the
image(s), into the beam search of the diagnostic text generation process. We
evaluate the proposed method on two medical datasets using four DC systems that
range from generic image-to-text systems with CNN encoders and RNN decoders to
pre-trained Large Language Models. The latter can also be used in few- and
zero-shot learning scenarios. In most cases, the proposed mechanism improves
performance with respect to all evaluation measures. We provide an open-source
implementation of the proposed method at https://github.com/nlpaueb/dmmcs.

摘要：診斷標題 (DC) 會自動從一位或多位病患的醫療影像 (例如 X 光、磁振造影) 中產生一則診斷文字。產生的文字視為草稿，可協助臨床醫生提供病患狀況的初步估計，加速並協助保障診斷程序。然而，診斷文字的準確性高度仰賴影像中所描繪的主要醫療狀況如何表達。我們提出一個新的資料驅動引導解碼方法，該方法將醫療資訊以現有標籤的形式納入診斷文字產生過程的波束搜尋中，用以擷取影像的主要狀況。我們使用四個 DC 系統在兩個醫療資料集上評估所提出的方法，這些系統的範圍從具備 CNN 編碼器和 RNN 解碼器的通用影像轉文字系統到預先訓練的大型語言模型。後者也可在少樣本和零樣本學習情境中使用。在大部分情況下，所提出的機制在所有評量指標方面均提升了效能。我們在 https://github.com/nlpaueb/dmmcs 中提供了所提出方法的開源實作。

##### **Resource-efficient Medical Image Analysis with Self-adapting Forward-Forward Networks**
2406.14038v1 by Johanna P. Müller, Bernhard Kainz

We introduce a fast Self-adapting Forward-Forward Network (SaFF-Net) for
medical imaging analysis, mitigating power consumption and resource
limitations, which currently primarily stem from the prevalent reliance on
back-propagation for model training and fine-tuning. Building upon the recently
proposed Forward-Forward Algorithm (FFA), we introduce the Convolutional
Forward-Forward Algorithm (CFFA), a parameter-efficient reformulation that is
suitable for advanced image analysis and overcomes the speed and generalisation
constraints of the original FFA. To address hyper-parameter sensitivity of FFAs
we are also introducing a self-adapting framework SaFF-Net fine-tuning
parameters during warmup and training in parallel. Our approach enables more
effective model training and eliminates the previously essential requirement
for an arbitrarily chosen Goodness function in FFA. We evaluate our approach on
several benchmarking datasets in comparison with standard Back-Propagation (BP)
neural networks showing that FFA-based networks with notably fewer parameters
and function evaluations can compete with standard models, especially, in
one-shot scenarios and large batch sizes. The code will be available at the
time of the conference.

摘要：<paragraph>我們介紹一種用於醫療影像分析的快速自適應前饋前饋網路 (SaFF-Net)，以減輕目前主要源自於過度依賴反向傳播進行模型訓練和微調的功耗和資源限制。在最近提出的前饋前饋演算法 (FFA) 的基礎上，我們介紹了卷積前饋前饋演算法 (CFFA)，這是一種參數有效率的重新制定，適用於進階影像分析，並克服了原始 FFA 的速度和概括限制。為了解決 FFA 的超參數敏感性，我們還在熱身和訓練期間並行引入了自適應架構 SaFF-Net 微調參數。我們的做法能更有效地進行模型訓練，並消除了 FFA 中先前對任意選擇的優良函數的基本需求。我們在幾個基準資料集上評估我們的做法，並與標準反向傳播 (BP) 神經網路進行比較，結果顯示基於 FFA 的網路具有明顯較少的參數和函數評估，可以與標準模型競爭，特別是在單次場景和大批次大小中。程式碼將在會議期間提供。</paragraph>

##### **Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment**
2406.13934v1 by Kaishuai Xu, Yi Cheng, Wenjun Hou, Qiaoyu Tan, Wenjie Li

Medical dialogue systems have attracted significant attention for their
potential to act as medical assistants. Enabling these medical systems to
emulate clinicians' diagnostic reasoning process has been the long-standing
research focus. Previous studies rudimentarily realized the simulation of
clinicians' diagnostic process by fine-tuning language models on high-quality
dialogue datasets. Nonetheless, they overly focus on the outcomes of the
clinician's reasoning process while ignoring their internal thought processes
and alignment with clinician preferences. Our work aims to build a medical
dialogue system that aligns with clinicians' diagnostic reasoning processes. We
propose a novel framework, Emulation, designed to generate an appropriate
response that relies on abductive and deductive diagnostic reasoning analyses
and aligns with clinician preferences through thought process modeling.
Experimental results on two datasets confirm the efficacy of Emulation.
Crucially, our framework furnishes clear explanations for the generated
responses, enhancing its transparency in medical consultations.

摘要：醫療對話系統因其作為醫療助理的潛力而備受關注。讓這些醫療系統模擬臨床醫生的診斷推理過程一直是長期的研究重點。先前的研究通過微調高品質對話資料集上的語言模型，初步實現了對臨床醫生診斷過程的模擬。儘管如此，他們過於關注臨床醫生推理過程的結果，而忽視了他們的內部思考過程以及與臨床醫生偏好的對齊。我們的研究旨在建立一個與臨床醫生的診斷推理過程保持一致的醫療對話系統。我們提出了一個新穎的框架，稱為 Emulation，旨在產生適當的回應，這些回應依賴於演繹和歸納診斷推理分析，並通過思考過程建模與臨床醫生的偏好保持一致。在兩個資料集上的實驗結果證實了 Emulation 的功效。至關重要的是，我們的框架為生成的回應提供了清晰的解釋，增強了其在醫療諮詢中的透明度。

##### **ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World**
2406.13890v1 by Weixiang Yan, Haitian Liu, Tengxiao Wu, Qian Chen, Wen Wang, Haoyuan Chai, Jiayi Wang, Weishan Zhao, Yixin Zhang, Renjun Zhang, Li Zhu

LLMs have achieved significant performance progress in various NLP
applications. However, LLMs still struggle to meet the strict requirements for
accuracy and reliability in the medical field and face many challenges in
clinical applications. Existing clinical diagnostic evaluation benchmarks for
evaluating medical agents powered by LLMs have severe limitations. Firstly,
most existing medical evaluation benchmarks face the risk of data leakage or
contamination. Secondly, existing benchmarks often neglect the characteristics
of multiple departments and specializations in modern medical practice.
Thirdly, existing evaluation methods are limited to multiple-choice questions,
which do not align with the real-world diagnostic scenarios. Lastly, existing
evaluation methods lack comprehensive evaluations of end-to-end real clinical
scenarios. These limitations in benchmarks in turn obstruct advancements of
LLMs and agents for medicine. To address these limitations, we introduce
ClinicalLab, a comprehensive clinical diagnosis agent alignment suite.
ClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical
diagnostic evaluation benchmark for evaluating medical agents and LLMs.
ClinicalBench is based on real cases that cover 24 departments and 150
diseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for
evaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate
17 LLMs and find that their performance varies significantly across different
departments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,
an end-to-end clinical agent that aligns with real-world clinical diagnostic
practices. We systematically investigate the performance and applicable
scenarios of variants of ClinicalAgent on ClinicalBench. Our findings
demonstrate the importance of aligning with modern medical practices in
designing medical agents.

摘要：大型語言模型在各種自然語言處理應用中取得顯著的進展。然而，大型語言模型仍難以滿足醫療領域對準確性和可靠性的嚴格要求，並在臨床應用中面臨許多挑戰。現有的臨床診斷評估基準用於評估由大型語言模型驅動的醫療代理，但存在嚴重的限制。首先，現有的醫療評估基準大多面臨數據洩露或污染的風險。其次，現有的基準通常忽略現代醫療實務中多個部門和專科的特徵。第三，現有的評估方法僅限於選擇題，與現實世界的診斷情境不符。最後，現有的評估方法缺乏對端到端真實臨床情境的全面評估。基準的這些限制反過來阻礙了大型語言模型和醫學代理的進步。為了解決這些限制，我們引入了 ClinicalLab，一個全面的臨床診斷代理對齊套件。ClinicalLab 包含 ClinicalBench，一個端到端的多部門臨床診斷評估基準，用於評估醫療代理和大型語言模型。ClinicalBench 基於涵蓋 24 個部門和 150 種疾病的真實案例。ClinicalLab 還包括四項新指標（ClinicalMetrics），用於評估大型語言模型在臨床診斷任務中的有效性。我們評估了 17 個大型語言模型，發現它們在不同部門的表現差異很大。根據這些發現，我們在 ClinicalLab 中提出了 ClinicalAgent，一個與現實世界臨床診斷實務相符的端到端臨床代理。我們系統地研究了 ClinicalAgent 變體在 ClinicalBench 上的效能和適用情境。我們的發現證明了在設計醫療代理時與現代醫療實務相符的重要性。

##### **MAMA-MIA: A Large-Scale Multi-Center Breast Cancer DCE-MRI Benchmark Dataset with Expert Segmentations**
2406.13844v1 by Lidia Garrucho, Claire-Anne Reidel, Kaisar Kushibar, Smriti Joshi, Richard Osuala, Apostolia Tsirikoglou, Maciej Bobowicz, Javier del Riego, Alessandro Catanese, Katarzyna Gwoździewicz, Maria-Laura Cosaka, Pasant M. Abo-Elhoda, Sara W. Tantawy, Shorouq S. Sakrana, Norhan O. Shawky-Abdelfatah, Amr Muhammad Abdo-Salem, Androniki Kozana, Eugen Divjak, Gordana Ivanac, Katerina Nikiforaki, Michail E. Klontzas, Rosa García-Dosdá, Meltem Gulsun-Akpinar, Oğuz Lafcı, Ritse Mann, Carlos Martín-Isla, Fred Prior, Kostas Marias, Martijn P. A. Starmans, Fredrik Strand, Oliver Díaz, Laura Igual, Karim Lekadir

Current research in breast cancer Magnetic Resonance Imaging (MRI),
especially with Artificial Intelligence (AI), faces challenges due to the lack
of expert segmentations. To address this, we introduce the MAMA-MIA dataset,
comprising 1506 multi-center dynamic contrast-enhanced MRI cases with expert
segmentations of primary tumors and non-mass enhancement areas. These cases
were sourced from four publicly available collections in The Cancer Imaging
Archive (TCIA). Initially, we trained a deep learning model to automatically
segment the cases, generating preliminary segmentations that significantly
reduced expert segmentation time. Sixteen experts, averaging 9 years of
experience in breast cancer, then corrected these segmentations, resulting in
the final expert segmentations. Additionally, two radiologists conducted a
visual inspection of the automatic segmentations to support future quality
control studies. Alongside the expert segmentations, we provide 49 harmonized
demographic and clinical variables and the pretrained weights of the well-known
nnUNet architecture trained using the DCE-MRI full-images and expert
segmentations. This dataset aims to accelerate the development and benchmarking
of deep learning models and foster innovation in breast cancer diagnostics and
treatment planning.

摘要：乳腺癌磁共振成像 (MRI) 的現今研究，特別是與人工智慧 (AI) 相關的研究，由於缺乏專家分段而面臨挑戰。為了解決此問題，我們引入了 MAMA-MIA 資料集，其中包含 1506 例多中心動態對比增強 MRI 案例，以及原發腫瘤和非腫塊增強區域的專家分段。這些案例來自癌症影像檔案館 (TCIA) 中的四個公開可取得的集合。最初，我們訓練了一個深度學習模型來自動分段案例，產生初步分段，大幅減少了專家分段時間。16 位專家，平均擁有 9 年乳腺癌經驗，然後修正這些分段，產生最終的專家分段。此外，兩位放射科醫師對自動分段進行視覺檢查，以支援未來的品質控管研究。除了專家分段外，我們還提供了 49 個調和的人口統計和臨床變數，以及使用 DCE-MRI 全影像和專家分段訓練的著名 nnUNet 架構的預訓練權重。此資料集旨在加速深度學習模型的開發和基準測試，並促進乳腺癌診斷和治療計畫的創新。

##### **IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being**
2406.13791v1 by Amelie Gyrard, Seyedali Mohammadi, Manas Gaur, Antonio Kung

Sustainable Development Goals (SDGs) give the UN a road map for development
with Agenda 2030 as a target. SDG3 "Good Health and Well-Being" ensures healthy
lives and promotes well-being for all ages. Digital technologies can support
SDG3. Burnout and even depression could be reduced by encouraging better
preventive health. Due to the lack of patient knowledge and focus to take care
of their health, it is necessary to help patients before it is too late. New
trends such as positive psychology and mindfulness are highly encouraged in the
USA. Digital Twin (DT) can help with the continuous monitoring of emotion using
physiological signals (e.g., collected via wearables). Digital twins facilitate
monitoring and provide constant health insight to improve quality of life and
well-being with better personalization. Healthcare DT challenges are
standardizing data formats, communication protocols, and data exchange
mechanisms. To achieve those data integration and knowledge challenges, we
designed the Mental Health Knowledge Graph (ontology and dataset) to boost
mental health. The Knowledge Graph (KG) acquires knowledge from ontology-based
mental health projects classified within the LOV4IoT ontology catalog (Emotion,
Depression, and Mental Health). Furthermore, the KG is mapped to standards
(e.g., ontologies) when possible. Standards from ETSI SmartM2M, ITU/WHO, ISO,
W3C, NIST, and IEEE are relevant to mental health.

摘要：永續發展目標（SDG）為聯合國提供了一個發展路線圖，目標為 2030 年議程。SDG3「良好健康與福祉」確保所有年齡層的健康生活並促進福祉。數位科技可以支援 SDG3。透過鼓勵更好的預防性保健，可以減少倦怠甚至憂鬱症。由於患者缺乏健康知識和關注自身健康的焦點，因此有必要在為時已晚之前幫助患者。積極心理學和正念等新趨勢在美國受到高度鼓勵。數位雙胞胎（DT）可以透過生理訊號（例如透過穿戴式裝置收集）協助持續監控情緒。數位雙胞胎促進監控並提供持續的健康見解，以透過更好的個人化改善生活品質和福祉。醫療保健 DT 的挑戰在於標準化資料格式、通訊協定和資料交換機制。為了達成這些資料整合和知識挑戰，我們設計了心理健康知識圖譜（本体和資料集）來提升心理健康。知識圖譜（KG）從 LOV4IoT 本体目錄（情緒、憂鬱症和心理健康）中分類的基於本体的心理健康專案中獲取知識。此外，KG 盡可能對應到標準（例如本体）。ETSI SmartM2M、ITU/WHO、ISO、W3C、NIST 和 IEEE 的標準與心理健康相關。

##### **BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes**
2406.13714v1 by Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Biplav Srivastava

A common, yet regular, decision made by people, whether healthy or with any
health condition, is to decide what to have in meals like breakfast, lunch, and
dinner, consisting of a combination of foods for appetizer, main course, side
dishes, desserts, and beverages. However, often this decision is seen as a
trade-off between nutritious choices (e.g., low salt and sugar) or convenience
(e.g., inexpensive, fast to prepare/obtain, taste better). In this preliminary
work, we present a data-driven approach for the novel meal recommendation
problem that can explore and balance choices for both considerations while also
reasoning about a food's constituents and cooking process. Beyond the problem
formulation, our contributions also include a goodness measure, a recipe
conversion method from text to the recently introduced multimodal rich recipe
representation (R3) format, and learning methods using contextual bandits that
show promising results.

摘要：人們常規且定期做出的決定，無論是健康的人或是有任何健康狀況的人，就是決定早餐、午餐和晚餐要吃什麼，包括開胃菜、主菜、配菜、甜點和飲料等食物的組合。然而，這個決定通常被視為營養選擇（例如低鹽和低糖）或便利性（例如便宜、快速準備/取得、味道較好）之間的權衡。在這項初步工作中，我們提出了一種資料驅動的方法，用於新穎的餐點推薦問題，該方法可以探索和平衡這兩方面的選擇，同時也能推理食物的成分和烹飪過程。除了問題的表述外，我們的貢獻還包括一個優良度量度、一種從文字轉換為最近推出的多模態豐富食譜表示法 (R3) 格式的食譜轉換方法，以及使用情境強盜的學習方法，這些方法顯示出有希望的結果。

##### **EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy**
2406.13705v1 by Long Bai, Qiaozhi Tan, Tong Chen, Wan Jun Nah, Yanheng Li, Zhicheng He, Sishen Yuan, Zhen Chen, Jinlin Wu, Mobarakol Islam, Zhen Li, Hongbin Liu, Hongliang Ren

Wireless Capsule Endoscopy (WCE) is highly valued for its non-invasive and
painless approach, though its effectiveness is compromised by uneven
illumination from hardware constraints and complex internal dynamics, leading
to overexposed or underexposed images. While researchers have discussed the
challenges of low-light enhancement in WCE, the issue of correcting for
different exposure levels remains underexplored. To tackle this, we introduce
EndoUIC, a WCE unified illumination correction solution using an end-to-end
promptable diffusion transformer (DFT) model. In our work, the illumination
prompt module shall navigate the model to adapt to different exposure levels
and perform targeted image enhancement, in which the Adaptive Prompt
Integration (API) and Global Prompt Scanner (GPS) modules shall further boost
the concurrent representation learning between the prompt parameters and
features. Besides, the U-shaped restoration DFT model shall capture the
long-range dependencies and contextual information for unified illumination
restoration. Moreover, we present a novel Capsule-endoscopy Exposure Correction
(CEC) dataset, including ground-truth and corrupted image pairs annotated by
expert photographers. Extensive experiments against a variety of
state-of-the-art (SOTA) methods on four datasets showcase the effectiveness of
our proposed method and components in WCE illumination restoration, and the
additional downstream experiments further demonstrate its utility for clinical
diagnosis and surgical assistance.

摘要：無線膠囊內視鏡（WCE）因其非侵入性和無痛的方法而備受重視，儘管其有效性受到硬體限制和複雜內部動力學導致照明不均的影響，導致影像曝光過度或曝光不足。儘管研究人員已討論 WCE 中低光增強的挑戰，但針對不同曝光等級進行校正的問題仍未得到充分探討。為了解決這個問題，我們引入了 EndoUIC，這是一個使用端到端可提示擴散轉換器 (DFT) 模型的 WCE 統一照明校正解決方案。在我們的研究中，照明提示模組應引導模型適應不同的曝光等級並執行目標影像增強，其中自適應提示整合 (API) 和全局提示掃描器 (GPS) 模組應進一步提升提示參數和特徵之間的並發表示學習。此外，U 形復原 DFT 模型應捕捉長距離依賴關係和脈絡資訊，以進行統一照明復原。此外，我們提出了創新的膠囊內視鏡曝光校正 (CEC) 資料集，其中包括由專業攝影師註解的真實和損壞影像對。針對四個資料集的各種最新 (SOTA) 方法進行的廣泛實驗展示了我們提出的方法和組成在 WCE 照明復原中的有效性，而額外的下游實驗進一步證明了其在臨床診斷和手術輔助中的效用。

##### **Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health**
2406.13659v1 by Bo Wen, Raquel Norel, Julia Liu, Thaddeus Stappenbeck, Farhana Zulkernine, Huamin Chen

The rapid advancements in large language models (LLMs) have opened up new
opportunities for transforming patient engagement in healthcare through
conversational AI. This paper presents an overview of the current landscape of
LLMs in healthcare, specifically focusing on their applications in analyzing
and generating conversations for improved patient engagement. We showcase the
power of LLMs in handling unstructured conversational data through four case
studies: (1) analyzing mental health discussions on Reddit, (2) developing a
personalized chatbot for cognitive engagement in seniors, (3) summarizing
medical conversation datasets, and (4) designing an AI-powered patient
engagement system. These case studies demonstrate how LLMs can effectively
extract insights and summarizations from unstructured dialogues and engage
patients in guided, goal-oriented conversations. Leveraging LLMs for
conversational analysis and generation opens new doors for many
patient-centered outcomes research opportunities. However, integrating LLMs
into healthcare raises important ethical considerations regarding data privacy,
bias, transparency, and regulatory compliance. We discuss best practices and
guidelines for the responsible development and deployment of LLMs in healthcare
settings. Realizing the full potential of LLMs in digital health will require
close collaboration between the AI and healthcare professionals communities to
address technical challenges and ensure these powerful tools' safety, efficacy,
and equity.

摘要：大型語言模型 (LLM) 的快速進展為透過對話式 AI 轉變醫療保健中的患者參與度開啟了新的機會。本文概述了醫療保健中 LLM 的現況，特別專注於它們在分析和產生對話以改善患者參與度的應用。我們透過四個案例研究展示了 LLM 在處理非結構化對話資料方面的能力：(1) 分析 Reddit 上的心理健康討論，(2) 為老年人的認知參與開發個人化聊天機器人，(3) 總結醫療對話資料集，以及 (4) 設計 AI 驅動的患者參與系統。這些案例研究展示了 LLM 如何從非結構化對話中有效地提取見解和摘要，並讓患者參與有指導性的、以目標為導向的對話。利用 LLM 進行對話分析和產生為以患者為中心的成果研究機會開啟了新的途徑。然而，將 LLM 整合到醫療保健中會引發有關資料隱私、偏差、透明度和法規遵循的重要倫理考量。我們討論了在醫療保健環境中負責任地開發和部署 LLM 的最佳實務和準則。要實現 LLM 在數位健康中的全部潛力，需要 AI 和醫療保健專業人員社群密切合作，以應對技術挑戰並確保這些強大工具的安全、效能和公平性。

##### **Enhance the Image: Super Resolution using Artificial Intelligence in MRI**
2406.13625v1 by Ziyu Li, Zihan Li, Haoxiang Li, Qiuyun Fan, Karla L. Miller, Wenchuan Wu, Akshay S. Chaudhari, Qiyuan Tian

This chapter provides an overview of deep learning techniques for improving
the spatial resolution of MRI, ranging from convolutional neural networks,
generative adversarial networks, to more advanced models including
transformers, diffusion models, and implicit neural representations. Our
exploration extends beyond the methodologies to scrutinize the impact of
super-resolved images on clinical and neuroscientific assessments. We also
cover various practical topics such as network architectures, image evaluation
metrics, network loss functions, and training data specifics, including
downsampling methods for simulating low-resolution images and dataset
selection. Finally, we discuss existing challenges and potential future
directions regarding the feasibility and reliability of deep learning-based MRI
super-resolution, with the aim to facilitate its wider adoption to benefit
various clinical and neuroscientific applications.

摘要：本章概述了用於改善 MRI 空間解析度的深度學習技術，涵蓋了從卷積神經網路、生成對抗網路到更先進的模型，包括Transformer、擴散模型和隱式神經表示。我們的探討不僅限於方法論，還審查了超解析影像對臨床和神經科學評估的影響。我們也涵蓋了各種實務主題，例如網路架構、影像評估指標、網路損失函數和訓練資料規範，包括用於模擬低解析度影像的下採樣方法和資料集選擇。最後，我們討論了基於深度學習的 MRI 超解析技術的可行性和可靠性方面的現有挑戰和潛在未來方向，目的是促進其更廣泛的採用，以造福各種臨床和神經科學應用。

##### **Optimizing Psychological Counseling with Instruction-Tuned Large Language Models**
2406.13617v1 by Wenjie Li, Tianyu Sun, Kun Qian, Wenhong Wang

The advent of large language models (LLMs) has significantly advanced various
fields, including natural language processing and automated dialogue systems.
This paper explores the application of LLMs in psychological counseling,
addressing the increasing demand for mental health services. We present a
method for instruction tuning LLMs with specialized prompts to enhance their
performance in providing empathetic, relevant, and supportive responses. Our
approach involves developing a comprehensive dataset of counseling-specific
prompts, refining them through feedback from professional counselors, and
conducting rigorous evaluations using both automatic metrics and human
assessments. The results demonstrate that our instruction-tuned model
outperforms several baseline LLMs, highlighting its potential as a scalable and
accessible tool for mental health support.

摘要：大型語言模型 (LLM) 的出現顯著提升了各種領域，包括自然語言處理和自動對話系統。這篇論文探討了 LLM 在心理諮商中的應用，以解決對心理健康服務日益增長的需求。我們提出了一種使用專門提示來調整 LLM 指令的方法，以增強它們在提供同理、相關和支持性回應方面的表現。我們的做法包括開發一個全面的諮商特定提示資料集，透過專業諮商師的回饋來改善提示，並使用自動化指標和人工評估進行嚴謹的評估。結果表明，我們調整指令的模型優於幾個基準 LLM，突顯了它作為心理健康支援的可擴充且可存取工具的潛力。

##### **Certificates of Differential Privacy and Unlearning for Gradient-Based Training**
2406.13433v1 by Matthew Wicker, Philip Sosnin, Adrianna Janik, Mark N. Müller, Adrian Weller, Calvin Tsay

Proper data stewardship requires that model owners protect the privacy of
individuals' data used during training. Whether through anonymization with
differential privacy or the use of unlearning in non-anonymized settings, the
gold-standard techniques for providing privacy guarantees can come with
significant performance penalties or be too weak to provide practical
assurances. In part, this is due to the fact that the guarantee provided by
differential privacy represents the worst-case privacy leakage for any
individual, while the true privacy leakage of releasing the prediction for a
given individual might be substantially smaller or even, as we show,
non-existent. This work provides a novel framework based on convex relaxations
and bounds propagation that can compute formal guarantees (certificates) that
releasing specific predictions satisfies $\epsilon=0$ privacy guarantees or do
not depend on data that is subject to an unlearning request. Our framework
offers a new verification-centric approach to privacy and unlearning
guarantees, that can be used to further engender user trust with tighter
privacy guarantees, provide formal proofs of robustness to certain membership
inference attacks, identify potentially vulnerable records, and enhance current
unlearning approaches. We validate the effectiveness of our approach on tasks
from financial services, medical imaging, and natural language processing.

摘要：適當的資料管理要求模型擁有者保護個人在訓練期間所使用資料的隱私。無論是透過具有差分隱私的匿名化或是在非匿名化設定中使用忘記，提供隱私保證的黃金標準技術都可能伴隨著顯著的效能損失，或過於薄弱而無法提供實際保證。部分原因在於，差分隱私提供的保證代表任何個人的最差情況隱私洩漏，而釋出給定個人預測的真實隱私洩漏可能大幅減少，甚至如我們所展示的，不存在。這項工作提供一個新的架構，基於凸弛豫和邊界傳播，可以計算形式化保證（證明），釋出特定預測滿足 $\epsilon=0$ 隱私保證，或不依賴於受忘記要求約束的資料。我們的架構提供一個新的以驗證為中心的隱私和忘記保證方法，可用於進一步提升使用者對更嚴格隱私保證的信任，提供對特定成員推論攻擊的正式穩健性證明，識別潛在的脆弱記錄，並增強目前的忘記方法。我們在金融服務、醫學影像和自然語言處理的任務中驗證了我們方法的有效性。

##### **Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing**
2406.13385v1 by Martin Lebourdais, Théo Mariotte, Antonio Almudévar, Marie Tahon, Alfonso Ortega

Audio segmentation is a key task for many speech technologies, most of which
are based on neural networks, usually considered as black boxes, with
high-level performances. However, in many domains, among which health or
forensics, there is not only a need for good performance but also for
explanations about the output decision. Explanations derived directly from
latent representations need to satisfy "good" properties, such as
informativeness, compactness, or modularity, to be interpretable. In this
article, we propose an explainable-by-design audio segmentation model based on
non-negative matrix factorization (NMF) which is a good candidate for the
design of interpretable representations. This paper shows that our model
reaches good segmentation performances, and presents deep analyses of the
latent representation extracted from the non-negative matrix. The proposed
approach opens new perspectives toward the evaluation of interpretable
representations according to "good" properties.

摘要：音訊區段化是許多語音技術的關鍵任務，其中大部分基於神經網路，通常被視為黑盒子，具有高階效能。然而，在許多領域中，其中包含健康或法醫學，不僅需要良好的效能，也需要對輸出決策進行說明。直接從潛在表徵中衍生的說明需要滿足「良好」的特性，例如資訊性、緊湊性或模組化，才能被解釋。在本文中，我們提出一個可解釋的音訊區段化模型，該模型基於非負矩陣分解 (NMF)，這是非負表徵設計的良好候選者。本文顯示我們的模型達到良好的區段化效能，並對從非負矩陣中提取的潛在表徵進行深入分析。所提出的方法為根據「良好」特性評估可解釋的表徵開啟新的觀點。

##### **Biomedical Visual Instruction Tuning with Clinician Preference Alignment**
2406.13173v1 by Hejie Cui, Lingjun Mao, Xin Liang, Jieyu Zhang, Hui Ren, Quanzheng Li, Xiang Li, Carl Yang

Recent advancements in multimodal foundation models have showcased impressive
capabilities in understanding and reasoning with visual and textual
information. Adapting these foundation models trained for general usage to
specialized domains like biomedicine requires large-scale domain-specific
instruction datasets. While existing works have explored curating such datasets
automatically, the resultant datasets are not explicitly aligned with domain
expertise. In this work, we propose a data-centric framework, Biomedical Visual
Instruction Tuning with Clinician Preference Alignment (BioMed-VITAL), that
incorporates clinician preferences into both stages of generating and selecting
instruction data for tuning biomedical multimodal foundation models. First,
during the generation stage, we prompt the GPT-4V generator with a diverse set
of clinician-selected demonstrations for preference-aligned data candidate
generation. Then, during the selection phase, we train a separate selection
model, which explicitly distills clinician and policy-guided model preferences
into a rating function to select high-quality data for medical instruction
tuning. Results show that the model tuned with the instruction-following data
from our method demonstrates a significant improvement in open visual chat
(18.5% relatively) and medical VQA (win rate up to 81.73%). Our
instruction-following data and models are available at BioMed-VITAL.github.io.

摘要：多模态基础模型的最新进展展示了令人印象深刻的能力，能够理解和推理视觉和文本信息。将这些针对一般用途训练的基础模型调整到生物医学等专业领域需要大规模的特定领域指导数据集。虽然现有工作已经探索了自动整理此类数据集，但结果数据集并未明确与领域专业知识保持一致。在这项工作中，我们提出了一个以数据为中心框架，即生物医学视觉指令调整与临床医生偏好对齐 (BioMed-VITAL)，它将临床医生偏好纳入生成和选择用于调整生物医学多模态基础模型的指令数据的两个阶段。首先，在生成阶段，我们使用一组由临床医生选择的演示提示 GPT-4V 生成器，以生成偏好对齐的数据候选。然后，在选择阶段，我们训练一个单独的选择模型，该模型明确地将临床医生和政策指导的模型偏好提炼成一个评级函数，以选择用于医学指令调整的高质量数据。结果表明，使用我们方法中的指令遵循数据调整的模型在开放式视觉聊天（相对提高 18.5%）和医学 VQA（获胜率高达 81.73%）方面表现出显着提升。我们的指令遵循数据和模型可在 BioMed-VITAL.github.io 获得。

##### **Cardiac Copilot: Automatic Probe Guidance for Echocardiography with World Model**
2406.13165v1 by Haojun Jiang, Zhenguo Sun, Ning Jia, Meng Li, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

Echocardiography is the only technique capable of real-time imaging of the
heart and is vital for diagnosing the majority of cardiac diseases. However,
there is a severe shortage of experienced cardiac sonographers, due to the
heart's complex structure and significant operational challenges. To mitigate
this situation, we present a Cardiac Copilot system capable of providing
real-time probe movement guidance to assist less experienced sonographers in
conducting freehand echocardiography. This system can enable non-experts,
especially in primary departments and medically underserved areas, to perform
cardiac ultrasound examinations, potentially improving global healthcare
delivery. The core innovation lies in proposing a data-driven world model,
named Cardiac Dreamer, for representing cardiac spatial structures. This world
model can provide structure features of any cardiac planes around the current
probe position in the latent space, serving as an precise navigation map for
autonomous plane localization. We train our model with real-world ultrasound
data and corresponding probe motion from 110 routine clinical scans with 151K
sample pairs by three certified sonographers. Evaluations on three standard
planes with 37K sample pairs demonstrate that the world model can reduce
navigation errors by up to 33\% and exhibit more stable performance.

摘要：超音波心動圖是唯一能即時影像化心臟的技術，對於診斷大部分的心臟疾病至關重要。然而，由於心臟結構複雜且操作上有相當的挑戰，因此經驗豐富的心臟超音波檢查員嚴重短缺。為了緩解這種情況，我們提出了一套心臟輔助駕駛系統，能夠提供即時的探頭移動引導，協助經驗較少的超音波檢查員進行徒手超音波心動圖檢查。此系統讓非專家，特別是在基層部門和醫療資源不足的地區，也能執行心臟超音波檢查，有潛力改善全球的醫療保健服務。核心的創新在於提出一個資料驅動的世界模型，稱為心臟夢幻家，用於表示心臟的空間結構。此世界模型能提供任何心臟平面的結構特徵，圍繞著潛在空間中的當前探頭位置，作為自主平面定位的精確導航地圖。我們利用 110 次例行臨床掃描的真實世界超音波數據和對應的探頭運動，由三位認證的超音波檢查員提供 151K 個樣本對，來訓練我們的模型。在三個標準平面上，使用 37K 個樣本對進行的評估顯示，世界模型可以將導航誤差減少多達 33%，且表現出更穩定的效能。

##### **Oralytics Reinforcement Learning Algorithm**
2406.13127v1 by Anna L. Trella, Kelly W. Zhang, Stephanie M. Carpenter, David Elashoff, Zara M. Greer, Inbal Nahum-Shani, Dennis Ruenger, Vivek Shetty, Susan A. Murphy

Dental disease is still one of the most common chronic diseases in the United
States. While dental disease is preventable through healthy oral self-care
behaviors (OSCB), this basic behavior is not consistently practiced. We have
developed Oralytics, an online, reinforcement learning (RL) algorithm that
optimizes the delivery of personalized intervention prompts to improve OSCB. In
this paper, we offer a full overview of algorithm design decisions made using
prior data, domain expertise, and experiments in a simulation test bed. The
finalized RL algorithm was deployed in the Oralytics clinical trial, conducted
from fall 2023 to summer 2024.

摘要：牙科疾病仍然是美國最常見的慢性疾病之一。雖然牙科疾病可透過健康的口腔自我保健行為（OSCB）預防，但這種基本行為並未持續實行。我們開發出 Oralytics，一種線上強化學習（RL）演算法，可最佳化個人化介入提示的傳遞，以改善 OSCB。在本文中，我們將全面概述演算法設計決策，這些決策是使用先前的資料、領域專業知識和模擬測試平台中的實驗所做出的。最終的 RL 演算法已部署在 Oralytics 臨床試驗中，該試驗於 2023 年秋季至 2024 年夏季進行。

##### **Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer**
2406.13106v1 by Ahmed Abdeen Hamed, Tamer E. Fandy, Xindong Wu

The objective of this research is to introduce a network specialized in
predicting drugs that can be repurposed by investigating real-world evidence
sources, such as clinical trials and biomedical literature. Specifically, it
aims to generate drug combination therapies for complex diseases (e.g., cancer,
Alzheimer's). We present a multilayered network medicine approach, empowered by
a highly configured ChatGPT prompt engineering system, which is constructed on
the fly to extract drug mentions in clinical trials. Additionally, we introduce
a novel algorithm that connects real-world evidence with disease-specific
signaling pathways (e.g., KEGG database). This sheds light on the
repurposability of drugs if they are found to bind with one or more protein
constituents of a signaling pathway. To demonstrate, we instantiated the
framework for breast cancer and found that, out of 46 breast cancer signaling
pathways, the framework identified 38 pathways that were covered by at least
two drugs. This evidence signals the potential for combining those drugs.
Specifically, the most covered signaling pathway, ID hsa:2064, was covered by
108 drugs, some of which can be combined. Conversely, the signaling pathway ID
hsa:1499 was covered by only two drugs, indicating a significant gap for
further research. Our network medicine framework, empowered by GenAI, shows
promise in identifying drug combinations with a high degree of specificity,
knowing the exact signaling pathways and proteins that serve as targets. It is
noteworthy that ChatGPT successfully accelerated the process of identifying
drug mentions in clinical trials, though further investigations are required to
determine the relationships among the drug mentions.

摘要：本研究的目的是建立一個專門預測可透過調查真實世界證據來源（例如臨床試驗和生物醫學文獻）來重新利用的藥物的網路。具體來說，其目的是為複雜疾病（例如癌症、阿茲海默症）產生藥物組合療法。我們提出了一種多層網路醫學方法，由高度配置的 ChatGPT 提示工程系統提供支援，該系統會即時建構以萃取臨床試驗中的藥物提及。此外，我們還引入了一種新的演算法，將真實世界證據與特定疾病的訊號通路（例如 KEGG 資料庫）連結起來。如果發現藥物與訊號通路的某一種或多種蛋白質成分結合，這將有助於了解藥物的可再利用性。為了示範，我們為乳癌建立了架構，並發現，在 46 條乳癌訊號通路中，該架構識別出 38 條至少被兩種藥物涵蓋的通路。此證據表明將這些藥物結合起來的可能性。具體來說，涵蓋範圍最廣的訊號通路 ID hsa:2064 被 108 種藥物涵蓋，其中一些可以組合。相反地，訊號通路 ID hsa:1499 僅被兩種藥物涵蓋，這表示有很大的研究空缺。我們的網路醫學架構由 GenAI 提供支援，在識別具有高度特異性的藥物組合方面顯示出前景，了解作為目標的精確訊號通路和蛋白質。值得注意的是，儘管需要進一步的調查來確定藥物提及之間的關係，但 ChatGPT 成功地加速了在臨床試驗中識別藥物提及的過程。

##### **Deriving Hematological Disease Classes Using Fuzzy Logic and Expert Knowledge: A Comprehensive Machine Learning Approach with CBC Parameters**
2406.13015v1 by Salem Ameen, Ravivarman Balachandran, Theodoros Theodoridis

In the intricate field of medical diagnostics, capturing the subtle
manifestations of diseases remains a challenge. Traditional methods, often
binary in nature, may not encapsulate the nuanced variances that exist in
real-world clinical scenarios. This paper introduces a novel approach by
leveraging Fuzzy Logic Rules to derive disease classes based on expert domain
knowledge from a medical practitioner. By recognizing that diseases do not
always fit into neat categories, and that expert knowledge can guide the
fuzzification of these boundaries, our methodology offers a more sophisticated
and nuanced diagnostic tool.
  Using a dataset procured from a prominent hospital, containing detailed
patient blood count records, we harness Fuzzy Logic Rules, a computational
technique celebrated for its ability to handle ambiguity. This approach, moving
through stages of fuzzification, rule application, inference, and ultimately
defuzzification, produces refined diagnostic predictions. When combined with
the Random Forest classifier, the system adeptly predicts hematological
conditions using Complete Blood Count (CBC) parameters.
  Preliminary results showcase high accuracy levels, underscoring the
advantages of integrating fuzzy logic into the diagnostic process. When
juxtaposed with traditional diagnostic techniques, it becomes evident that
Fuzzy Logic, especially when guided by medical expertise, offers significant
advancements in the realm of hematological diagnostics. This paper not only
paves the path for enhanced patient care but also beckons a deeper dive into
the potentialities of fuzzy logic in various medical diagnostic applications.

摘要：在複雜的醫療診斷領域中，捕捉疾病的細微表現仍是一項挑戰。傳統方法通常本質上是二元的，可能無法概括現實世界臨床情境中存在的細微差異。本文透過利用模糊邏輯規則，根據醫療從業人員的專業領域知識推導疾病類別，引入了一種新穎的方法。我們的做法承認疾病並不總是符合明確的類別，而且專家知識可以指導這些邊界的模糊化，從而提供更精緻且細緻的診斷工具。
使用從一家知名醫院取得的資料集，其中包含詳細的患者血球計數記錄，我們利用模糊邏輯規則，這是一種以處理模糊性能力而著稱的計算技術。這種方法經過模糊化、規則應用、推論和最終去模糊化的階段，產生精煉的診斷預測。與隨機森林分類器結合使用時，該系統使用全血細胞計數 (CBC) 參數熟練地預測血液學狀況。
初步結果展示了高準確度，強調了將模糊邏輯整合到診斷過程中的優點。與傳統診斷技術並置時，顯然模糊邏輯，尤其是在醫療專業知識的指導下，為血液學診斷領域提供了顯著的進展。本文不僅為增強的患者照護鋪平了道路，也呼籲更深入地探討模糊邏輯在各種醫療診斷應用中的潛力。

##### **Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation**
2406.12815v1 by Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable
advancements, particularly in healthcare. Within medical imaging, ML models
hold the promise of improving disease diagnoses, treatment planning, and
post-treatment monitoring. Various computer vision tasks like image
classification, object detection, and image segmentation are poised to become
routine in clinical analysis. However, privacy concerns surrounding patient
data hinder the assembly of large training datasets needed for developing and
training accurate, robust, and generalizable models. Federated Learning (FL)
emerges as a compelling solution, enabling organizations to collaborate on ML
model training by sharing model training information (gradients) rather than
data (e.g., medical images). FL's distributed learning framework facilitates
inter-institutional collaboration while preserving patient privacy. However,
FL, while robust in privacy preservation, faces several challenges. Sensitive
information can still be gleaned from shared gradients that are passed on
between organizations during model training. Additionally, in medical imaging,
quantifying model confidence\uncertainty accurately is crucial due to the noise
and artifacts present in the data. Uncertainty estimation in FL encounters
unique hurdles due to data heterogeneity across organizations. This paper
offers a comprehensive review of FL, privacy preservation, and uncertainty
estimation, with a focus on medical imaging. Alongside a survey of current
research, we identify gaps in the field and suggest future directions for FL
research to enhance privacy and address noisy medical imaging data challenges.

摘要：機器學習 (ML) 和人工智慧 (AI) 已推動顯著的進展，特別是在醫療保健方面。在醫學影像中，ML 模型有望改善疾病診斷、治療規劃和治療後監控。各種電腦視覺任務，例如影像分類、物件偵測和影像分割，都準備好在臨床分析中成為常規。然而，圍繞患者資料的隱私問題阻礙了組建大型訓練資料集，而這對於開發和訓練準確、強健且可概化的模型是必要的。聯邦學習 (FL) 成為一個引人注目的解決方案，使組織能夠透過分享模型訓練資訊 (梯度) 而不是資料（例如醫學影像）來協作進行 ML 模型訓練。FL 的分散式學習架構促進了機構間的協作，同時保護了患者隱私。然而，FL 雖然在隱私保護方面很強大，但仍面臨許多挑戰。敏感資訊仍然可以從組織在模型訓練期間傳遞的共享梯度中收集。此外，在醫學影像中，由於資料中存在雜訊和人工製品，因此準確量化模型信心/不確定性至關重要。由於組織間資料異質性，FL 中的不確定性估計會遇到獨特障礙。本文全面回顧了 FL、隱私保護和不確定性估計，重點放在醫學影像上。除了對當前研究進行調查外，我們還找出該領域的差距，並提出 FL 研究的未來方向，以增強隱私並解決雜訊醫學影像資料的挑戰。

##### **Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs**
2406.12807v1 by Joshua Durso-Finley, Berardino Barile, Jean-Pierre Falet, Douglas L. Arnold, Nick Pawlowski, Tal Arbel

Personalized medicine based on medical images, including predicting future
individualized clinical disease progression and treatment response, would have
an enormous impact on healthcare and drug development, particularly for
diseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneous
evolutions and no cure. In this work, we present the first stochastic causal
temporal framework to model the continuous temporal evolution of disease
progression via Neural Stochastic Differential Equations (NSDE). The proposed
causal inference model takes as input the patient's high dimensional images
(MRI) and tabular data, and predicts both factual and counterfactual
progression trajectories on different treatments in latent space. The NSDE
permits the estimation of high-confidence personalized trajectories and
treatment effects. Extensive experiments were performed on a large,
multi-centre, proprietary dataset of patient 3D MRI and clinical data acquired
during several randomized clinical trials for MS treatments. Our results
present the first successful uncertainty-based causal Deep Learning (DL) model
to: (a) accurately predict future patient MS disability evolution (e.g. EDSS)
and treatment effects leveraging baseline MRI, and (b) permit the discovery of
subgroups of patients for which the model has high confidence in their response
to treatment even in clinical trials which did not reach their clinical
endpoints.

摘要：基於醫學影像的個人化醫療，包括預測未來個人化臨床疾病進程和治療反應，將對醫療保健和藥物開發產生巨大影響，特別是對於長期、複雜、異質性演化且無法治癒的疾病（例如多發性硬化症 (MS)）。在這項工作中，我們提出了第一個隨機因果時間框架，透過神經隨機微分方程式 (NSDE) 對疾病進程的連續時間演化進行建模。所提出的因果推論模型以病患的高維度影像（MRI）和表格資料作為輸入，並預測潛在空間中不同治療的實際和反事實進程軌跡。NSDE 允許估計高可信度的個人化軌跡和治療效果。在針對 MS 治療進行的幾項隨機臨床試驗中，對一個大型、多中心、專有資料集的病患 3D MRI 和臨床資料進行了廣泛的實驗。我們的結果展示了第一個成功的基於不確定性的因果深度學習 (DL) 模型：(a) 準確預測未來的病患 MS 殘疾演化（例如 EDSS）和利用基線 MRI 的治療效果，以及 (b) 允許發現即使在未達到臨床終點的臨床試驗中，模型對其治療反應具有高度信心的病患子群。

##### **Large Language Model as a Universal Clinical Multi-task Decoder**
2406.12738v1 by Yujiang Wu, Hongjian Song, Jiawen Zhang, Xumeng Wen, Shun Zheng, Jiang Bian

The development of effective machine learning methodologies for enhancing the
efficiency and accuracy of clinical systems is crucial. Despite significant
research efforts, managing a plethora of diversified clinical tasks and
adapting to emerging new tasks remain significant challenges. This paper
presents a novel paradigm that employs a pre-trained large language model as a
universal clinical multi-task decoder. This approach leverages the flexibility
and diversity of language expressions to handle task topic variations and
associated arguments. The introduction of a new task simply requires the
addition of a new instruction template. We validate this framework across
hundreds of tasks, demonstrating its robustness in facilitating multi-task
predictions, performing on par with traditional multi-task learning and
single-task learning approaches. Moreover, it shows exceptional adaptability to
new tasks, with impressive zero-shot performance in some instances and superior
data efficiency in few-shot scenarios. This novel approach offers a unified
solution to manage a wide array of new and emerging tasks in clinical
applications.

摘要：<paragraph>開發有效的機器學習方法，以提升臨床系統的效率和準確性至關重要。儘管研究付出相當大的努力，管理大量多樣化的臨床任務和適應新興任務仍然是重大的挑戰。本文提出了一種新的範例，採用預先訓練的大型語言模型作為通用的臨床多任務解碼器。此方法利用語言表達的靈活性與多樣性來處理任務主題變化和相關論點。引入新任務只需要新增一個新的指令範本。我們驗證了這個架構在數百個任務中，證明了它在促進多任務預測方面的穩健性，執行與傳統多任務學習和單任務學習方法相當。此外，它展現出對新任務的卓越適應性，在某些情況下具有令人印象深刻的零次學習效能，在少量學習場景中具有優異的資料效率。這種新方法提供了一個統一的解決方案，來管理臨床應用中各種新的和新興任務。</paragraph>

##### **Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly**
2406.12698v1 by Siddhant Shete, Dennis Mronga, Ankita Jadhav, Frank Kirchner

Anomaly detection deals with detecting deviations from established patterns
within data. It has various applications like autonomous driving, predictive
maintenance, and medical diagnosis. To improve anomaly detection accuracy,
transfer learning can be applied to large, pre-trained models and adapt them to
the specific application context. In this paper, we propose a novel framework
for online-adaptive anomaly detection using transfer learning. The approach
adapts to different environments by selecting visually similar training images
and online fitting a normality model to EfficientNet features extracted from
the training subset. Anomaly detection is then performed by computing the
Mahalanobis distance between the normality model and the test image features.
Different similarity measures (SIFT/FLANN, Cosine) and normality models (MVG,
OCSVM) are employed and compared with each other. We evaluate the approach on
different anomaly detection benchmarks and data collected in controlled
laboratory settings. Experimental results showcase a detection accuracy
exceeding 0.975, outperforming the state-of-the-art ET-NET approach.

摘要：異常偵測處理偵測資料中既有模式的偏差。它有各種應用，例如自動駕駛、預測性維護和醫療診斷。為了改善異常偵測的準確性，轉移學習可以應用於大型預訓練模型，並將它們適應到特定的應用情境中。在本文中，我們提出了一個新的框架，用於使用轉移學習進行線上自適應異常偵測。此方法透過選擇視覺上相似的訓練影像，並線上擬合一個常態模型到從訓練子集中萃取的 EfficientNet 特徵，來適應不同的環境。然後透過計算常態模型和測試影像特徵之間的馬氏距離來執行異常偵測。採用不同的相似性度量（SIFT/FLANN、餘弦）和常態模型（MVG、OCSVM），並相互比較。我們在不同的異常偵測基準和受控實驗室設定中收集的資料上評估此方法。實驗結果顯示偵測準確度超過 0.975，優於最先進的 ET-NET 方法。

##### **Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics**
2406.12651v1 by Huan Xu, Jinlin Wu, Guanglin Cao, Zhen Chen, Zhen Lei, Hongbin Liu

Ultrasonography has revolutionized non-invasive diagnostic methodologies,
significantly enhancing patient outcomes across various medical domains.
Despite its advancements, integrating ultrasound technology with robotic
systems for automated scans presents challenges, including limited command
understanding and dynamic execution capabilities. To address these challenges,
this paper introduces a novel Ultrasound Embodied Intelligence system that
synergistically combines ultrasound robots with large language models (LLMs)
and domain-specific knowledge augmentation, enhancing ultrasound robots'
intelligence and operational efficiency. Our approach employs a dual strategy:
firstly, integrating LLMs with ultrasound robots to interpret doctors' verbal
instructions into precise motion planning through a comprehensive understanding
of ultrasound domain knowledge, including APIs and operational manuals;
secondly, incorporating a dynamic execution mechanism, allowing for real-time
adjustments to scanning plans based on patient movements or procedural errors.
We demonstrate the effectiveness of our system through extensive experiments,
including ablation studies and comparisons across various models, showcasing
significant improvements in executing medical procedures from verbal commands.
Our findings suggest that the proposed system improves the efficiency and
quality of ultrasound scans and paves the way for further advancements in
autonomous medical scanning technologies, with the potential to transform
non-invasive diagnostics and streamline medical workflows.

摘要：超音波徹底改變了非侵入性診斷方法，大幅提升各種醫療領域的患者治療成果。儘管有這些進展，但將超音波技術與機器人系統整合以進行自動化掃描會產生挑戰，包括有限的指令理解和動態執行能力。為了應對這些挑戰，本文介紹了一種創新的超音波具身智慧系統，該系統將超音波機器人與大型語言模型 (LLM) 和特定領域的知識擴充結合在一起，增強超音波機器人的智慧和操作效率。我們的做法採用雙重策略：首先，將 LLM 與超音波機器人整合，透過全面理解超音波領域知識（包括 API 和操作手冊），將醫生的口頭指示轉換為精確的動作規劃；其次，加入動態執行機制，允許根據患者移動或程序錯誤即時調整掃描計畫。我們透過廣泛的實驗（包括消融研究和各種模型的比較）證明了我們系統的有效性，展示了根據口頭指令執行醫療程序的顯著進步。我們的研究結果表明，所提出的系統改善了超音波掃描的效率和品質，並為自主醫療掃描技術的進一步發展鋪路，有潛力轉型非侵入性診斷並簡化醫療工作流程。

##### **An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation**
2406.12646v1 by Qin Li, Yizhe Zhang, Yan Li, Jun Lyu, Meng Liu, Longyu Sun, Mengting Sun, Qirong Li, Wenyue Mao, Xinran Wu, Yajing Zhang, Yinghua Chu, Shuo Wang, Chengyan Wang

The segmentation foundation model, e.g., Segment Anything Model (SAM), has
attracted increasing interest in the medical image community. Early pioneering
studies primarily concentrated on assessing and improving SAM's performance
from the perspectives of overall accuracy and efficiency, yet little attention
was given to the fairness considerations. This oversight raises questions about
the potential for performance biases that could mirror those found in
task-specific deep learning models like nnU-Net. In this paper, we explored the
fairness dilemma concerning large segmentation foundation models. We
prospectively curate a benchmark dataset of 3D MRI and CT scans of the organs
including liver, kidney, spleen, lung and aorta from a total of 1056 healthy
subjects with expert segmentations. Crucially, we document demographic details
such as gender, age, and body mass index (BMI) for each subject to facilitate a
nuanced fairness analysis. We test state-of-the-art foundation models for
medical image segmentation, including the original SAM, medical SAM and SAT
models, to evaluate segmentation efficacy across different demographic groups
and identify disparities. Our comprehensive analysis, which accounts for
various confounding factors, reveals significant fairness concerns within these
foundational models. Moreover, our findings highlight not only disparities in
overall segmentation metrics, such as the Dice Similarity Coefficient but also
significant variations in the spatial distribution of segmentation errors,
offering empirical evidence of the nuanced challenges in ensuring fairness in
medical image segmentation.

摘要：例如，任何分割模型（SAM）等分割基础模型在医学影像社群中已引起越来越多的兴趣。早期开创性研究主要集中于从整体准确性和效率的角度评估和改进 SAM 的性能，但很少关注公平性考量。这种疏忽引起了人们对性能偏差的质疑，这些偏差可能反映在 nnU-Net 等特定任务深度学习模型中发现的偏差。在本文中，我们探讨了与大型分割基础模型有关的公平性困境。我们前瞻性地整理了一个基准数据集，其中包含来自 1056 名健康受试者的器官（包括肝脏、肾脏、脾脏、肺和主动脉）的 3D MRI 和 CT 扫描，并由专家进行分割。至关重要的是，我们记录了每个受试者的性别、年龄和体重指数 (BMI) 等人口统计详细信息，以促进细致入微的公平性分析。我们测试了用于医学图像分割的最新基础模型，包括原始 SAM、医学 SAM 和 SAT 模型，以评估不同人口群体的分割效果并找出差异。我们的综合分析考虑了各种混杂因素，揭示了这些基础模型中存在的重大公平性问题。此外，我们的研究结果不仅突出了整体分割指标（例如骰子相似系数）的差异，还突出了分割错误的空间分布的显着差异，为确保医学图像分割中的公平性提供了细微挑战的经验证据。

##### **Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine**
2406.12449v1 by Rui Yang, Yilin Ning, Emilia Keppo, Mingxuan Liu, Chuan Hong, Danielle S Bitterman, Jasmine Chiat Ling Ong, Daniel Shu Wei Ting, Nan Liu

Generative artificial intelligence (AI) has brought revolutionary innovations
in various fields, including medicine. However, it also exhibits limitations.
In response, retrieval-augmented generation (RAG) provides a potential
solution, enabling models to generate more accurate contents by leveraging the
retrieval of external knowledge. With the rapid advancement of generative AI,
RAG can pave the way for connecting this transformative technology with medical
applications and is expected to bring innovations in equity, reliability, and
personalization to health care.

摘要：生成式人工智能 (AI) 已為包括醫學在內的各個領域帶來革命性的創新。然而，它也表現出局限性。為了解決這個問題，檢索增強生成 (RAG) 提供了一個潛在的解決方案，使模型能夠透過利用外部知識的檢索來產生更準確的內容。隨著生成式 AI 的快速進展，RAG 可以為將這項轉型技術與醫療應用相連鋪路，並有望為醫療保健帶來公平性、可靠性和個人化的創新。

##### **Adversarial Attacks on Large Language Models in Medicine**
2406.12259v1 by Yifan Yang, Qiao Jin, Furong Huang, Zhiyong Lu

The integration of Large Language Models (LLMs) into healthcare applications
offers promising advancements in medical diagnostics, treatment
recommendations, and patient care. However, the susceptibility of LLMs to
adversarial attacks poses a significant threat, potentially leading to harmful
outcomes in delicate medical contexts. This study investigates the
vulnerability of LLMs to two types of adversarial attacks in three medical
tasks. Utilizing real-world patient data, we demonstrate that both open-source
and proprietary LLMs are susceptible to manipulation across multiple tasks.
This research further reveals that domain-specific tasks demand more
adversarial data in model fine-tuning than general domain tasks for effective
attack execution, especially for more capable models. We discover that while
integrating adversarial data does not markedly degrade overall model
performance on medical benchmarks, it does lead to noticeable shifts in
fine-tuned model weights, suggesting a potential pathway for detecting and
countering model attacks. This research highlights the urgent need for robust
security measures and the development of defensive mechanisms to safeguard LLMs
in medical applications, to ensure their safe and effective deployment in
healthcare settings.

摘要：大型語言模型 (LLM) 整合到醫療保健應用程式中，在醫療診斷、治療建議和病人照護方面提供了有希望的進展。然而，LLM 對對抗性攻擊的敏感性構成重大威脅，可能導致在微妙的醫療環境中造成有害的後果。本研究調查了 LLM 在三項醫療任務中對兩種對抗性攻擊的脆弱性。利用真實世界的病人資料，我們證明開源和專有 LLM 都容易受到多項任務的操縱。這項研究進一步揭示，與一般領域任務相比，特定領域任務需要在模型微調中更多對抗性資料才能有效執行攻擊，特別是對於功能更強大的模型。我們發現，雖然整合對抗性資料並不會顯著降低醫療基準上的整體模型效能，但它確實會導致微調模型權重發生明顯的轉變，這表明有潛在途徑可以偵測和反制模型攻擊。本研究強調了對健全安全措施和防禦機制開發的迫切需求，以保護醫療應用程式中的 LLM，確保它們在醫療保健環境中安全有效地部署。

##### **Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers**
2406.12199v1 by Haowei Ni, Shuchen Meng, Xieming Geng, Panfeng Li, Zhuoying Li, Xupeng Chen, Xiaotong Wang, Shiyao Zhang

Cardiovascular disease (CVD) is a leading cause of death globally,
necessitating precise forecasting models for monitoring vital signs like heart
rate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,
are limited by their need for manual parameter tuning and challenges in
handling noisy, sparse, and highly variable medical data. This study
investigates advanced deep learning models, including LSTM, and
transformer-based architectures, for predicting heart rate time series from the
MIT-BIH Database. Results demonstrate that deep learning models, particularly
PatchTST, significantly outperform traditional models across multiple metrics,
capturing complex patterns and dependencies more effectively. This research
underscores the potential of deep learning to enhance patient monitoring and
CVD management, suggesting substantial clinical benefits. Future work should
extend these findings to larger, more diverse datasets and real-world clinical
applications to further validate and optimize model performance.

摘要：心血管疾病 (CVD) 是全球主要的死亡原因，
需要精準的預測模型來監控心率、血壓和心電圖等生命徵象。傳統模型，例如 ARIMA 和 Prophet，
受到手動參數調整需求和處理雜訊、稀疏和高度變異的醫療資料的挑戰所限制。本研究
探討進階深度學習模型，包括 LSTM 和
基於轉換器的架構，用於從
MIT-BIH 資料庫預測心率時間序列。結果表明，深度學習模型，特別是
PatchTST，在多項指標上顯著優於傳統模型，更有效地捕捉複雜模式和依賴關係。這項研究
強調了深度學習在增強患者監控和
CVD 管理方面的潛力，表明了顯著的臨床益處。未來的研究應將這些發現擴展到更大、更多樣化的資料集和真實世界的臨床
應用，以進一步驗證和最佳化模型效能。

##### **Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models**
2406.12182v1 by Lulu Zhao, Weihao Zeng, Xiaofeng Shi, Hua Zhou, Donglin Hao, Yonghua Lin

Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional fields such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. We propose Aquila-Med, a bilingual medical LLM based on
Aquila, addressing these challenges through continue pre-training, supervised
fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We
construct a large-scale Chinese and English medical dataset for continue
pre-training and a high-quality SFT dataset, covering extensive medical
specialties. Additionally, we develop a high-quality Direct Preference
Optimization (DPO) dataset for further alignment. Aquila-Med achieves notable
results across single-turn, multi-turn dialogues, and medical multiple-choice
questions, demonstrating the effectiveness of our approach. We open-source the
datasets and the entire training process, contributing valuable resources to
the research community. Our models and datasets will released at
https://huggingface.co/BAAI/AquilaMed-RL.

摘要：近来，闭源 LLM 和开源社区都取得了重大进展，在各种通用领域的表现都优于人类。然而，它们在医学等特定专业领域的性能，尤其是在开源社区中，由于医学知识的复杂性，仍然不够理想。我们提出了 Aquila-Med，一个基于 Aquila 的双语医学 LLM，通过持续预训练、监督微调 (SFT) 和人类反馈强化学习 (RLHF) 来应对这些挑战。我们构建了一个大规模的中英文医学数据集，用于持续预训练和高质量的 SFT 数据集，涵盖广泛的医学专业。此外，我们开发了一个高质量的直接偏好优化 (DPO) 数据集，以进一步对齐。Aquila-Med 在单轮、多轮对话和医学多项选择题中取得了显著的成果，证明了我们方法的有效性。我们开源数据集和整个训练过程，为研究社区贡献了宝贵的资源。我们的模型和数据集将在 https://huggingface.co/BAAI/AquilaMed-RL 发布。

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v1 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中獲得了很高的整體準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知和未標記的群體。此外，這種觀察到的效能差異的根本原因通常難以發現，阻礙了改善措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳的子集，並針對觀察到的效能差異原因制定假設。我們引入了一種新的 SDM，並在胸部 X 光片中肺炎和肺不張的分類案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對在廣泛使用的胸部 X 光片資料集和模型中男性和女性患者之間先前觀察到但無法解釋的效能差異提供了解釋。我們的研究結果表明，在分類任務中，透過胸腔引流管和 ECG 線路的存在，存在捷徑學習。這些捷徑特徵在患病率上的基於性別的差異似乎導致了觀察到的分類效能差距，這代表了捷徑學習和模型公平性分析之間先前未被重視的交互作用。

##### **WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions**
2406.12058v2 by Seyedali Mohammadi, Edward Raff, Jinendra Malekar, Vedant Palit, Francis Ferraro, Manas Gaur

Language Models (LMs) are being proposed for mental health applications where
the heightened risk of adverse outcomes means predictive performance may not be
a sufficient litmus test of a model's utility in clinical practice. A model
that can be trusted for practice should have a correspondence between
explanation and clinical determination, yet no prior research has examined the
attention fidelity of these models and their effect on ground truth
explanations. We introduce an evaluation design that focuses on the robustness
and explainability of LMs in identifying Wellness Dimensions (WD). We focus on
two mental health and well-being datasets: (a) Multi-label Classification-based
MultiWD, and (b) WellXplain for evaluating attention mechanism veracity against
expert-labeled explanations. The labels are based on Halbert Dunn's theory of
wellness, which gives grounding to our evaluation. We reveal four surprising
results about LMs/LLMs: (1) Despite their human-like capabilities, GPT-3.5/4
lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM fails to deliver any
remarkable improvements in performance or explanations. (2) Re-examining LMs'
predictions based on a confidence-oriented loss function reveals a significant
performance drop. (3) Across all LMs/LLMs, the alignment between attention and
explanations remains low, with LLMs scoring a dismal 0.0. (4) Most mental
health-specific LMs/LLMs overlook domain-specific knowledge and undervalue
explanations, causing these discrepancies. This study highlights the need for
further research into their consistency and explanations in mental health and
well-being.

摘要：語言模型 (LM) 已被提議用於心理健康應用，在這些應用中，不良結果的風險升高意味著預測性表現可能不足以作為臨床實務中模型效用的試金石。可信賴實務的模型應在解釋和臨床判斷之間有對應關係，但沒有先前的研究探討過這些模型的注意力保真度及其對真實解釋的影響。我們介紹了一種評估設計，專注於 LM 在識別健康維度 (WD) 時的穩健性和可解釋性。我們專注於兩個心理健康和福祉數據集：(a) 基於多標籤分類的多 WD，以及 (b) WellXplain，用於評估注意力機制真實性與專家標記的解釋。這些標籤基於 Halbert Dunn 的健康理論，為我們的評估提供了依據。我們揭示了有關 LM/LLM 的四個驚人結果：(1) 儘管具有類人的能力，GPT-3.5/4 仍落後於 RoBERTa 和 MedAlpaca，而微調的 LLM 在效能或解釋方面並未帶來任何顯著的進步。(2) 根據以信心為導向的損失函數重新檢查 LM 的預測，顯示效能大幅下降。(3) 在所有 LM/LLM 中，注意力和解釋之間的一致性仍然很低，LLM 的得分慘不忍睹，僅為 0.0。(4) 大多數心理健康專用 LM/LLM 忽視特定領域的知識，並低估解釋，導致這些差異。本研究強調需要進一步研究它們在心理健康和福祉方面的一致性和解釋。

##### **MedCalc-Bench: Evaluating Large Language Models for Medical Calculations**
2406.12036v1 by Nikhil Khandekar, Qiao Jin, Guangzhi Xiong, Soren Dunn, Serina S Applebaum, Zain Anwar, Maame Sarfo-Gyamfi, Conrad W Safranek, Abid A Anwar, Andrew Zhang, Aidan Gilson, Maxwell B Singer, Amisha Dave, Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu

As opposed to evaluating computation and logic-based reasoning, current
bench2 marks for evaluating large language models (LLMs) in medicine are
primarily focused on question-answering involving domain knowledge and
descriptive rea4 soning. While such qualitative capabilities are vital to
medical diagnosis, in real5 world scenarios, doctors frequently use clinical
calculators that follow quantitative equations and rule-based reasoning
paradigms for evidence-based decision support. To this end, we propose
MedCalc-Bench, a first-of-its-kind dataset focused on evaluating the medical
calculation capability of LLMs. MedCalc-Bench contains an evaluation set of
over 1000 manually reviewed instances from 55 different medical calculation
tasks. Each instance in MedCalc-Bench consists of a patient note, a question
requesting to compute a specific medical value, a ground truth answer, and a
step-by-step explanation showing how the answer is obtained. While our
evaluation results show the potential of LLMs in this area, none of them are
effective enough for clinical settings. Common issues include extracting the
incorrect entities, not using the correct equation or rules for a calculation
task, or incorrectly performing the arithmetic for the computation. We hope our
study highlights the quantitative knowledge and reasoning gaps in LLMs within
medical settings, encouraging future improvements of LLMs for various clinical
calculation tasks.

摘要：與評估運算和基於邏輯的推理相反，目前用於評估大型語言模型 (LLM) 在醫學中的基準，主要集中在涉及領域知識和描述性推理的問答上。雖然這些定性能力對醫療診斷至關重要，但在實際情況中，醫生經常使用遵循定量方程式和基於規則的推理範式的臨床計算器，以進行循證決策支援。為此，我們提出了 MedCalc-Bench，這是一個首創的資料集，專注於評估 LLM 的醫療計算能力。MedCalc-Bench 包含一個評估集，其中包含來自 55 種不同醫療計算任務的 1000 多個人工審查實例。MedCalc-Bench 中的每個實例都包含一個患者備註、一個計算特定醫療數值的請求問題、一個基本事實答案，以及一個分步說明，說明如何獲得答案。雖然我們的評估結果顯示了 LLM 在這方面的潛力，但它們都不足以用於臨床環境。常見問題包括提取不正確的實體、未針對計算任務使用正確的方程式或規則，或計算算術時執行不正確。我們希望我們的研究能強調 LLM 在醫療環境中的量化知識和推理差距，並鼓勵未來改進 LLM，以應付各種臨床計算任務。

##### **Socially Interactive Agents for Robotic Neurorehabilitation Training: Conceptualization and Proof-of-concept Study**
2406.12035v1 by Rhythm Arora, Pooja Prajod, Matteo Lavit Nicora, Daniele Panzeri, Giovanni Tauro, Rocco Vertechy, Matteo Malosio, Elisabeth André, Patrick Gebhard

Individuals with diverse motor abilities often benefit from intensive and
specialized rehabilitation therapies aimed at enhancing their functional
recovery. Nevertheless, the challenge lies in the restricted availability of
neurorehabilitation professionals, hindering the effective delivery of the
necessary level of care. Robotic devices hold great potential in reducing the
dependence on medical personnel during therapy but, at the same time, they
generally lack the crucial human interaction and motivation that traditional
in-person sessions provide. To bridge this gap, we introduce an AI-based system
aimed at delivering personalized, out-of-hospital assistance during
neurorehabilitation training. This system includes a rehabilitation training
device, affective signal classification models, training exercises, and a
socially interactive agent as the user interface. With the assistance of a
professional, the envisioned system is designed to be tailored to accommodate
the unique rehabilitation requirements of an individual patient. Conceptually,
after a preliminary setup and instruction phase, the patient is equipped to
continue their rehabilitation regimen autonomously in the comfort of their
home, facilitated by a socially interactive agent functioning as a virtual
coaching assistant. Our approach involves the integration of an interactive
socially-aware virtual agent into a neurorehabilitation robotic framework, with
the primary objective of recreating the social aspects inherent to in-person
rehabilitation sessions. We also conducted a feasibility study to test the
framework with healthy patients. The results of our preliminary investigation
indicate that participants demonstrated a propensity to adapt to the system.
Notably, the presence of the interactive agent during the proposed exercises
did not act as a source of distraction; instead, it positively impacted users'
engagement.

摘要：肢體能力不同的個人往往受益於密集且專業的復健療法，目的是增進其功能性復原。儘管如此，挑戰在於神經復健專業人員數量有限，阻礙了必要照護等級的有效提供。機器人裝置在降低治療期間對醫療人員的依賴方面具有極大的潛力，但同時，它們通常缺乏傳統面對面療程提供的關鍵人際互動和動機。為了彌補這個差距，我們引進了一個基於人工智慧的系統，旨在於神經復健訓練期間提供個人化、院外的協助。此系統包含復健訓練裝置、情感訊號分類模型、訓練練習和一個作為使用者介面的社會互動代理人。在專業人員的協助下，預想中的系統旨在量身打造，以適應個別病患獨特的神經復健需求。在概念上，在初步設定和說明階段後，病患具備在舒適的家中自主持續其復健計畫的條件，並由一個作為虛擬教練助理的社會互動代理人提供協助。我們的做法涉及將一個互動且具社會意識的虛擬代理人整合到神經復健機器人架構中，其主要目的是重建面對面復健療程中固有的社會面向。我們也進行了一項可行性研究，以健康病患測試此架構。我們初步調查的結果顯示，參與者表現出適應此系統的傾向。值得注意的是，在所建議的練習期間，互動代理人的存在並未成為分心的來源；相反地，它對使用者的參與產生了正面的影響。

##### **Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**
2406.11538v1 by Artur Jurgas, Marek Wodzinski, Marina D'Amato, Jeroen van der Laak, Manfredo Atzori, Henning Müller

The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research.

摘要：在臨床上或研究中，全幻燈片影像擷取時產生的偽像問題，需要人為介入和重新掃描。克服這個挑戰需要開發品質控管演算法，但組織病理學中相關註解資料有限，阻礙了演算法的發展。人工註解偽像偵測方法的真實情況既昂貴又費時。本研究提出一個方法來解決這個問題，這個方法專門用來增加全幻燈片影像中的偽像。這個工具可以無縫地從外部資料庫產生並混合偽像到給定的組織病理學資料集。然後使用擴充後的資料集來訓練偽像分類方法。評估顯示出它們在偽像分類中的效用，在不同的偽像類型中，它們的 AUROC 從 0.10 進步到 0.01。這個架構、模型、權重和真實註解是免費釋出的，以利於開放科學和可重製的研究。

##### **FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction**
2406.11928v1 by Muhao Xu, Zhenfeng Zhu, Youru Li, Shuai Zheng, Yawei Zhao, Kunlun He, Yao Zhao

Multimodal electronic health record (EHR) data can offer a holistic
assessment of a patient's health status, supporting various predictive
healthcare tasks. Recently, several studies have embraced the multitask
learning approach in the healthcare domain, exploiting the inherent
correlations among clinical tasks to predict multiple outcomes simultaneously.
However, existing methods necessitate samples to possess complete labels for
all tasks, which places heavy demands on the data and restricts the flexibility
of the model. Meanwhile, within a multitask framework with multimodal inputs,
how to comprehensively consider the information disparity among modalities and
among tasks still remains a challenging problem. To tackle these issues, a
unified healthcare prediction model, also named by \textbf{FlexCare}, is
proposed to flexibly accommodate incomplete multimodal inputs, promoting the
adaption to multiple healthcare tasks. The proposed model breaks the
conventional paradigm of parallel multitask prediction by decomposing it into a
series of asynchronous single-task prediction. Specifically, a task-agnostic
multimodal information extraction module is presented to capture decorrelated
representations of diverse intra- and inter-modality patterns. Taking full
account of the information disparities between different modalities and
different tasks, we present a task-guided hierarchical multimodal fusion module
that integrates the refined modality-level representations into an individual
patient-level representation. Experimental results on multiple tasks from
MIMIC-IV/MIMIC-CXR/MIMIC-NOTE datasets demonstrate the effectiveness of the
proposed method. Additionally, further analysis underscores the feasibility and
potential of employing such a multitask strategy in the healthcare domain. The
source code is available at https://github.com/mhxu1998/FlexCare.

摘要：多模态电子健康记录（EHR）数据可以提供患者健康状况的全面评估，支持各种预测性医疗保健任务。最近，一些研究采用了医疗保健领域的多分任务学习方法，利用临床任务之间固有的相关性来同时预测多个结果。然而，现有方法需要样本为所有任务都拥有完整的标签，这对数据提出了很高的要求，并限制了模型的灵活性。同时，在具有多模态输入的多任务框架中，如何全面考虑模态之间和任务之间的信息差异仍然是一个具有挑战性的问题。为了解决这些问题，提出了一个统一的医疗保健预测模型，也称为\textbf{FlexCare}，以灵活地适应不完整的多模态输入，促进对多个医疗保健任务的适应。所提出的模型打破了并行多任务预测的传统范式，将其分解为一系列异步单任务预测。具体而言，提出了一种与任务无关的多模态信息提取模块，以捕获不同模态内和模态间模式的去相关表示。充分考虑不同模态和不同任务之间信息差异，我们提出了一个任务指导的分层多模态融合模块，将精炼的模态级表示集成到一个单独的患者级表示中。MIMIC-IV/MIMIC-CXR/MIMIC-NOTE 数据集中多个任务的实验结果证明了所提出方法的有效性。此外，进一步的分析强调了在医疗保健领域采用这种多任务策略的可行性和潜力。源代码可在 https://github.com/mhxu1998/FlexCare 获得。

##### **Formally Certified Approximate Model Counting**
2406.11414v2 by Yong Kiam Tan, Jiong Yang, Mate Soos, Magnus O. Myreen, Kuldeep S. Meel

Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter.

摘要：近似模型计数是近似输入布林公式的解的数量的任务。针对合取范式 (CNF) 中的公式的最新近似模型计数器 ApproxMC，提供了一种可扩展的方法来获取具有近似正确 (PAC) 风格保证的模型计数。然而，ApproxMC 的近似的有效性依赖于对其随机算法的仔细理论分析以及其高度优化的实现的正确性，特别是后者与能够原生处理奇偶校验 (XOR) 约束的增量 CNF 可满足性求解器的有状态交互。
我们提出了第一个近似模型计数认证框架，对输出近似的质量提供形式验证的保证。我们的方法结合了：(i) 算法的 PAC 保证在 Isabelle/HOL 证明助手中的静态、一次性、形式证明；以及 (ii) 使用证明证书对 ApproxMC 对外部 CNF-XOR 求解器的调用进行动态、每次运行验证。我们详细介绍了我们建立验证这两部分之间严格联系的一般方法，包括我们用于将形式化的随机算法转换为经过验证的证明检查器的蓝图，以及我们为 ApproxMC 及其内部 CNF-XOR 求解步骤设计的证明证书。在实验中，我们表明证书生成几乎不会给近似计数器实现增加开销，并且我们的证书检查器能够在与计数器相同的时间和内存限制下完全验证 84.7% 的具有生成证书的实例。

##### **Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**
2406.11260v1 by Sungwon Park, Sungwon Han, Meeyoung Cha

The spread of fake news negatively impacts individuals and is regarded as a
significant social challenge that needs to be addressed. A number of
algorithmic and insightful features have been identified for detecting fake
news. However, with the recent LLMs and their advanced generation capabilities,
many of the detectable features (e.g., style-conversion attacks) can be
altered, making it more challenging to distinguish from real news. This study
proposes adversarial style augmentation, AdStyle, to train a fake news detector
that remains robust against various style-conversion attacks. Our model's key
mechanism is the careful use of LLMs to automatically generate a diverse yet
coherent range of style-conversion attack prompts. This improves the generation
of prompts that are particularly difficult for the detector to handle.
Experiments show that our augmentation strategy improves robustness and
detection performance when tested on fake news benchmark datasets.

摘要：假新聞的散布對個人造成負面影響，並被視為需要解決的重大社會挑戰。已經找出許多演算法和有見地的功能來偵測假新聞。然而，隨著近期大型語言模型 (LLM) 及其先進的產生能力，許多可偵測的功能（例如風格轉換攻擊）都可能被改變，使得與真實新聞的區別更具挑戰性。本研究提出對抗式風格擴充，AdStyle，來訓練一個對各種風格轉換攻擊保持穩健的假新聞偵測器。我們模型的關鍵機制是小心地使用 LLM 自動產生多樣且連貫的風格轉換攻擊提示範圍。這改善了提示的產生，特別是對於偵測器難以處理的提示。實驗顯示，當在假新聞基準資料集上進行測試時，我們的擴充策略改善了穩健性和偵測效能。

##### **Scorecards for Synthetic Medical Data Evaluation and Reporting**
2406.11143v1 by Ghada Zamzmi, Adarsh Subbaswamy, Elena Sizikova, Edward Margerrison, Jana Delfino, Aldo Badano

The growing utilization of synthetic medical data (SMD) in training and
testing AI-driven tools in healthcare necessitates a systematic framework for
assessing SMD quality. The current lack of a standardized methodology to
evaluate SMD, particularly in terms of its applicability in various medical
scenarios, is a significant hindrance to its broader acceptance and utilization
in healthcare applications. Here, we outline an evaluation framework designed
to meet the unique requirements of medical applications, and introduce the
concept of SMD scorecards, which can serve as comprehensive reports that
accompany artificially generated datasets. This can help standardize evaluation
and enable SMD developers to assess and further enhance the quality of SMDs by
identifying areas in need of attention and ensuring that the synthetic data
more accurately approximate patient data.

摘要：隨著合成醫療資料 (SMD) 在訓練和測試醫療保健中的人工智慧驅動工具的利用率日益提高，需要一個系統性的架構來評估 SMD 的品質。目前缺乏標準化的評估 SMD 的方法，特別是在其於各種醫療場景中的適用性方面，這嚴重阻礙了其在醫療保健應用中的更廣泛接受和利用。在此，我們概述了一個評估架構，旨在滿足醫療應用的獨特需求，並引入了 SMD 記分卡的概念，它可以作為人工生成資料集的綜合報告。這有助於標準化評估，並使 SMD 開發人員能夠評估和進一步提高 SMD 的品質，方法是找出需要關注的領域，並確保合成資料更準確地近似於患者資料。

##### **Diffusion Models in Low-Level Vision: A Survey**
2406.11138v1 by Chunming He, Yuqi Shen, Chengyu Fang, Fengyang Xiao, Longxiang Tang, Yulun Zhang, Wangmeng Zuo, Zhenhua Guo, Xiu Li

Deep generative models have garnered significant attention in low-level
vision tasks due to their generative capabilities. Among them, diffusion
model-based solutions, characterized by a forward diffusion process and a
reverse denoising process, have emerged as widely acclaimed for their ability
to produce samples of superior quality and diversity. This ensures the
generation of visually compelling results with intricate texture information.
Despite their remarkable success, a noticeable gap exists in a comprehensive
survey that amalgamates these pioneering diffusion model-based works and
organizes the corresponding threads. This paper proposes the comprehensive
review of diffusion model-based techniques. We present three generic diffusion
modeling frameworks and explore their correlations with other deep generative
models, establishing the theoretical foundation. Following this, we introduce a
multi-perspective categorization of diffusion models, considering both the
underlying framework and the target task. Additionally, we summarize extended
diffusion models applied in other tasks, including medical, remote sensing, and
video scenarios. Moreover, we provide an overview of commonly used benchmarks
and evaluation metrics. We conduct a thorough evaluation, encompassing both
performance and efficiency, of diffusion model-based techniques in three
prominent tasks. Finally, we elucidate the limitations of current diffusion
models and propose seven intriguing directions for future research. This
comprehensive examination aims to facilitate a profound understanding of the
landscape surrounding denoising diffusion models in the context of low-level
vision tasks. A curated list of diffusion model-based techniques in over 20
low-level vision tasks can be found at
https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.

摘要：深度生成模型在低层次视觉任务中获得了显著的关注，因为它们具有生成能力。其中，以正向扩散过程和反向去噪过程为特征的基于扩散模型的解决方案，因其生成更高质量和多样性样本的能力而备受赞誉。这确保了生成视觉上引人注目的结果，并具有复杂纹理信息。尽管取得了显著的成功，但在将这些开创性的基于扩散模型的工作汇集起来并组织相应的线程的综合调查中，仍然存在明显的差距。本文提出了基于扩散模型的技术的全面综述。我们提出了三个通用的扩散建模框架，并探讨了它们与其他深度生成模型的相关性，建立了理论基础。在此基础上，我们介绍了扩散模型的多视角分类，同时考虑了底层框架和目标任务。此外，我们总结了应用于其他任务的扩展扩散模型，包括医学、遥感和视频场景。此外，我们概述了常用的基准和评估指标。我们对基于扩散模型的技术在三个突出的任务中的性能和效率进行了彻底的评估。最后，我们阐明了当前扩散模型的局限性，并提出了七个未来研究的有趣方向。这次全面检查旨在促进对低层次视觉任务背景下去噪扩散模型周围环境的深入理解。可以在 https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision 找到超过 20 个低层次视觉任务中基于扩散模型的技术的精选列表。

##### **Towards Understanding Emotions for Engaged Mental Health Conversations**
2406.11135v1 by Kellie Yu Hui Sim, Kohleen Tijing Fortuno, Kenny Tsu Wei Choo

Providing timely support and intervention is crucial in mental health
settings. As the need to engage youth comfortable with texting increases,
mental health providers are exploring and adopting text-based media such as
chatbots, community-based forums, online therapies with licensed professionals,
and helplines operated by trained responders. To support these text-based media
for mental health--particularly for crisis care--we are developing a system to
perform passive emotion-sensing using a combination of keystroke dynamics and
sentiment analysis. Our early studies of this system posit that the analysis of
short text messages and keyboard typing patterns can provide emotion
information that may be used to support both clients and responders. We use our
preliminary findings to discuss the way forward for applying AI to support
mental health providers in providing better care.

摘要：在心理健康環境中提供及時的支援和介入至關重要。隨著與青少年互動時，使用文字訊息的需求增加，心理健康服務提供者正在探索和採用基於文字訊息的媒體，例如聊天機器人、社群論壇、由持照專業人員提供的線上療法，以及由受過訓練的回應者營運的求助專線。為了支援這些用於心理健康的基於文字訊息的媒體——特別是危機照護——我們正在開發一個系統，使用按鍵動力學和情緒分析的組合來執行被動情緒感測。我們對這個系統的早期研究假設，對簡短文字訊息和鍵盤輸入模式的分析可以提供情緒資訊，可用於支援個案和回應者。我們使用我們的初步發現來討論將 AI 應用於支援心理健康服務提供者提供更好照護的未來方向。

##### **Boosting Medical Image Classification with Segmentation Foundation Model**
2406.11026v1 by Pengfei Gu, Zihan Zhao, Hongxiao Wang, Yaopeng Peng, Yizhe Zhang, Nishchal Sapkota, Chaoli Wang, Danny Z. Chen

The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach.

摘要：任何區段模型 (SAM) 在自然影像的零發射區段中展現令人印象深刻的能力。最近，SAM 因其在醫學影像區段中的應用而備受關注。然而，據我們所知，沒有研究顯示如何利用 SAM 的力量進行醫學影像分類。為了填補這個空白，並讓 SAM 成為醫學影像分析的真正「基礎模型」，非常希望針對醫學影像分類客製化 SAM。在本文中，我們介紹 SAMAug-C，一種創新的擴充方法，基於 SAM，透過產生原始影像的變體來擴充分類資料集。擴充的資料集可用於訓練深度學習分類模型，從而提升分類效能。此外，我們提出一個新穎的架構，同時處理原始和 SAMAug-C 擴充影像輸入，利用兩者提供的互補資訊。在三個公開資料集上的實驗驗證了我們新方法的有效性。

##### **ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**
2406.10855v1 by Song Zhang, Qingzhong Wang, Junyi Liu, Haoyi Xiong

In the fast-growing field of Remote Sensing (RS) image analysis, the gap
between massive unlabeled datasets and the ability to fully utilize these
datasets for advanced RS analytics presents a significant challenge. To fill
the gap, our work introduces an innovative auto-labeling framework named ALPS
(Automatic Labeling for Pre-training in Segmentation), leveraging the Segment
Anything Model (SAM) to predict precise pseudo-labels for RS images without
necessitating prior annotations or additional prompts. The proposed pipeline
significantly reduces the labor and resource demands traditionally associated
with annotating RS datasets. By constructing two comprehensive pseudo-labeled
RS datasets via ALPS for pre-training purposes, our approach enhances the
performance of downstream tasks across various benchmarks, including iSAID and
ISPRS Potsdam. Experiments demonstrate the effectiveness of our framework,
showcasing its ability to generalize well across multiple tasks even under the
scarcity of extensively annotated datasets, offering a scalable solution to
automatic segmentation and annotation challenges in the field. In addition, the
proposed a pipeline is flexible and can be applied to medical image
segmentation, remarkably boosting the performance. Note that ALPS utilizes
pre-trained SAM to semi-automatically annotate RS images without additional
manual annotations. Though every component in the pipeline has bee well
explored, integrating clustering algorithms with SAM and novel pseudo-label
alignment significantly enhances RS segmentation, as an off-the-shelf tool for
pre-training data preparation. Our source code is available at:
https://github.com/StriveZs/ALPS.

摘要：<paragraph>在快速發展的遙感 (RS) 影像分析領域中，海量未標籤資料集與充分利用這些資料集進行進階 RS 分析的能力之間的差距，是一個重大的挑戰。為了填補這個差距，我們的研究引入了名為 ALPS (分段預訓練自動標籤) 的創新自動標籤框架，利用任何分段模型 (SAM) 來預測 RS 影像的精確偽標籤，而不需要事先註解或額外的提示。所提出的管線大幅減少了傳統上與註解 RS 資料集相關的人力和資源需求。透過 ALPS 為預訓練目的建構兩個全面的偽標籤 RS 資料集，我們的做法增強了各種基準（包括 iSAID 和 ISPRS Potsdam）中下游任務的效能。實驗證明了我們框架的有效性，展示了其即使在廣泛註解資料集稀缺的情況下，也能跨多個任務進行良好概化的能力，為該領域的自動分段和註解挑戰提供了可擴充的解決方案。此外，所提出的管線具有彈性，且可應用於醫學影像分段，顯著提升效能。請注意，ALPS 利用預訓練的 SAM 來半自動註解 RS 影像，而不需要額外的標籤。儘管管線中的每個元件都已充分探討，但將分群演算法與 SAM 整合，以及新穎的偽標籤比對，顯著增強了 RS 分段，作為預訓練資料準備的現成工具。我們的原始程式碼可在以下網址取得：https://github.com/StriveZs/ALPS。</paragraph>

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

摘要：基礎模型 (FM) 是使用自我監督技術在廣泛數據集上訓練的大規模深度學習模型。這些模型作為各種下游任務的基礎，包括醫療保健。FM 已在醫療保健的各種領域中被廣泛採用，包括自然語言處理 (NLP)、電腦視覺、圖形學習、生物學和組學。現有的基於醫療保健的調查尚未涵蓋所有這些領域。因此，本調查提供了 FM 在醫療保健中的全面概述。我們專注於 FM 的歷史、學習策略、旗艦模型、應用和挑戰。我們探討了 BERT 和 GPT 家族等 FM 如何重塑各種醫療保健領域，包括臨床大型語言模型、醫學影像分析和組學數據。此外，我們提供了由 FM 促進的醫療保健應用詳細分類法，例如臨床 NLP、醫學電腦視覺、圖形學習和其他與生物相關的任務。儘管 FM 提供了有希望的機會，但它們也面臨著一些相關的挑戰，這些挑戰在文中都有詳細說明。我們還概述了潛在的未來方向，為研究人員和從業者提供有關 FM 在醫療保健中的潛力和局限性的見解，以推進其部署並減輕相關風險。

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

摘要：<paragraph>將大型語言模型 (LLM) 與現有的知識圖譜 (KG) 資料庫整合，提供了一個提升 LLM 效能並減輕其「幻覺」的途徑。由於大多數 KG 都存在於僅能透過專用查詢語言（例如 Cypher）存取的圖形資料庫中，因此迫切需要自動化將自然語言轉換為 Cypher 查詢，以彌合 LLM 與 KG 資料庫之間的鴻溝（通常稱為「Text2Cypher」任務）。先前的努力嘗試透過監督微調來提升 LLM 在 Cypher 生成方面的能力。然而，這些探索受到缺乏查詢-Cypher 配對的註解資料集的阻礙，這是因為此類資料集的註解需要大量人力且具有特定領域的性質。在本研究中，我們提出了 SyntheT2C，這是一種用於建構合成查詢-Cypher 配對資料集的方法，包含兩個不同的管道：(1) 基於 LLM 的提示和 (2) 範本填寫。SyntheT2C 促進了大量查詢-Cypher 配對的產生，其值取樣自基礎的 Neo4j 圖形資料庫。隨後，將 SyntheT2C 應用於兩個醫療資料庫，最終建立了一個合成資料集 MedT2C。全面的實驗證明，MedT2C 資料集有效提升了主幹 LLM 在 Text2Cypher 任務上的效能。SyntheT2C 程式碼庫和 MedT2C 資料集都將很快釋出。</paragraph>

##### **Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**
2406.10632v1 by Onyekachukwu R. Okonji, Kamol Yunusov, Bonnie Gordon

Generative AI is rapidly transforming medical imaging and text analysis,
offering immense potential for enhanced diagnosis and personalized care.
However, this transformative technology raises crucial ethical, societal, and
legal questions. This paper delves into these complexities, examining issues of
accuracy, informed consent, data privacy, and algorithmic limitations in the
context of generative AI's application to medical imaging and text. We explore
the legal landscape surrounding liability and accountability, emphasizing the
need for robust regulatory frameworks. Furthermore, we dissect the algorithmic
challenges, including data biases, model limitations, and workflow integration.
By critically analyzing these challenges and proposing responsible solutions,
we aim to foster a roadmap for ethical and responsible implementation of
generative AI in healthcare, ensuring its transformative potential serves
humanity with utmost care and precision.

摘要：生成式 AI 正在快速轉變醫學影像和文字分析，
提供增強診斷和個人化照護的巨大潛力。
然而，這項變革性技術提出了關鍵的倫理、社會和
法律問題。本文深入探討這些複雜性，審查準確性、知情同意、資料隱私和演算法限制等問題
在生成式 AI 應用於醫學影像和文字的背景下。我們探討
責任和問責的法律環境，強調健全監管架構的必要性。此外，我們剖析演算法
挑戰，包括資料偏差、模型限制和工作流程整合。
通過批判性分析這些挑戰並提出負責任的解決方案，
我們旨在培養生成式 AI 在醫療保健中道德和負責任實施的路線圖，確保其變革潛力服務
人類以最大的關懷和精確度。

##### **Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**
2406.10628v1 by Anil Bhujel, Yibin Wang, Yuzhen Lu, Daniel Morris, Mukesh Dangol

Technology-driven precision livestock farming (PLF) empowers practitioners to
monitor and analyze animal growth and health conditions for improved
productivity and welfare. Computer vision (CV) is indispensable in PLF by using
cameras and computer algorithms to supplement or supersede manual efforts for
livestock data acquisition. Data availability is crucial for developing
innovative monitoring and analysis systems through artificial
intelligence-based techniques. However, data curation processes are tedious,
time-consuming, and resource intensive. This study presents the first
systematic survey of publicly available livestock CV datasets
(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).
Among 58 public datasets identified and analyzed, encompassing different
species of livestock, almost half of them are for cattle, followed by swine,
poultry, and other animals. Individual animal detection and color imaging are
the dominant application and imaging modality for livestock. The
characteristics and baseline applications of the datasets are discussed,
emphasizing the implications for animal welfare advocates. Challenges and
opportunities are also discussed to inspire further efforts in developing
livestock CV datasets. This study highlights that the limited quantity of
high-quality annotated datasets collected from diverse environments, animals,
and applications, the absence of contextual metadata, are a real bottleneck in
PLF.

摘要：<paragraph>以科技為主的精準畜牧養殖 (PLF) 讓從業人員得以監控和分析動物的生長和健康狀況，以提高生產力和福利。電腦視覺 (CV) 在 PLF 中不可或缺，它利用相機和電腦演算法來補充或取代人工收集畜牧資料的工作。資料取得對於透過人工智慧技術開發創新的監控和分析系統至關重要。然而，資料整理的程序繁瑣、耗時且耗費資源。本研究提出公開取得的畜牧 CV 資料集的首次系統性調查 (https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey)。在辨識和分析的 58 個公開資料集中，涵蓋不同種類的牲畜，其中將近一半是牛隻，其次是豬隻、家禽和其他動物。個別動物偵測和彩色影像處理是畜牧業中主要的應用和影像模式。本文討論了這些資料集的特徵和基礎應用，並強調其對動物福利倡導者的意義。也討論了挑戰和機會，以激勵進一步開發畜牧 CV 資料集。本研究強調，從各種環境、動物和應用中收集的高品質註解資料集數量有限，以及缺乏脈絡性元資料，是 PLF 中真正的瓶頸。</paragraph>

##### **Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**
2406.10519v1 by Pengfei Gu, Yejia Zhang, Huimin Li, Hongxiao Wang, Yizhe Zhang, Chaoli Wang, Danny Z. Chen

Masked Autoencoders (MAEs) have been shown to be effective in pre-training
Vision Transformers (ViTs) for natural and medical image analysis problems. By
reconstructing missing pixel/voxel information in visible patches, a ViT
encoder can aggregate contextual information for downstream tasks. But,
existing MAE pre-training methods, which were specifically developed with the
ViT architecture, lack the ability to capture geometric shape and spatial
information, which is critical for medical image segmentation tasks. In this
paper, we propose a novel extension of known MAEs for self pre-training (i.e.,
models pre-trained on the same target dataset) for 3D medical image
segmentation. (1) We propose a new topological loss to preserve geometric shape
information by computing topological signatures of both the input and
reconstructed volumes, learning geometric shape information. (2) We introduce a
pre-text task that predicts the positions of the centers and eight corners of
3D crops, enabling the MAE to aggregate spatial information. (3) We extend the
MAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image
segmentation architecture and co-pretrain it alongside the ViT. (4) We develop
a fine-tuned model for downstream segmentation tasks by complementing the
pre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments
on five public 3D segmentation datasets show the effectiveness of our new
approach.

摘要：蒙面自動編碼器 (MAE) 已被證明可有效用於自然和醫學影像分析問題的 Vision Transformer (ViT) 預訓練。透過重建可見補丁中遺失的像素/體素資訊，ViT 編碼器可以彙總下游任務的脈絡資訊。但是，專門針對 ViT 架構開發的現有 MAE 預訓練方法缺乏擷取幾何形狀和空間資訊的能力，而這對於醫學影像分割任務至關重要。在本文中，我們提出已知 MAE 的新延伸，用於 3D 醫學影像分割的自預訓練（即在同一目標資料集上預訓練的模型）。（1）我們提出新的拓撲損失來保留幾何形狀資訊，方法是計算輸入和重建體積的拓撲特徵，學習幾何形狀資訊。（2）我們引入預文本任務，用於預測 3D 裁剪的中心和八個角的位置，使 MAE 能夠彙總空間資訊。（3）我們將 MAE 預訓練策略延伸到混合的最新 (SOTA) 醫學影像分割架構，並與 ViT 一起預訓練它。（4）我們透過補充預訓練的 ViT 編碼器與我們的預訓練 SOTA 模型，為下游分割任務開發微調模型。在五個公開 3D 分割資料集上進行的廣泛實驗顯示了我們新方法的有效性。

##### **A Benchmark for Maximum Cut: Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization**
2406.11897v1 by Ankur Nath, Alan Kuhnle

Recently, there has been much work on the design of general heuristics for
graph-based, combinatorial optimization problems via the incorporation of Graph
Neural Networks (GNNs) to learn distribution-specific solution
structures.However, there is a lack of consistency in the evaluation of these
heuristics, in terms of the baselines and instances chosen, which makes it
difficult to assess the relative performance of the algorithms. In this paper,
we propose an open-source benchmark suite MaxCut-Bench dedicated to the NP-hard
Maximum Cut problem in both its weighted and unweighted variants, based on a
careful selection of instances curated from diverse graph datasets. The suite
offers a unified interface to various heuristics, both traditional and machine
learning-based. Next, we use the benchmark in an attempt to systematically
corroborate or reproduce the results of several, popular learning-based
approaches, including S2V-DQN [31], ECO-DQN [4], among others, in terms of
three dimensions: objective value, generalization, and scalability. Our
empirical results show that several of the learned heuristics fail to
outperform a naive greedy algorithm, and that only one of them consistently
outperforms Tabu Search, a simple, general heuristic based upon local search.
Furthermore, we find that the performance of ECO-DQN remains the same or is
improved if the GNN is replaced by a simple linear regression on a subset of
the features that are related to Tabu Search. Code, data, and pretrained models
are available at: \url{https://github.com/ankurnath/MaxCut-Bench}.

摘要：<paragraph>最近，通过整合图神经网络 (GNN) 来学习特定于分布的解决方案结构，在基于图的组合优化问题的通用启发式设计的相关研究中取得了许多进展。然而，在评估这些启发式算法时，在所选基准和实例方面缺乏一致性，这使得难以评估算法的相对性能。在本文中，我们提出了一套开源基准测试套件 MaxCut-Bench，专门用于 NP 困难的最大切割问题，包括其加权和未加权变体，该套件基于从各种图数据集精心挑选的实例。该套件为各种启发式算法提供了一个统一的界面，包括传统的和基于机器学习的启发式算法。接下来，我们尝试使用该基准系统地证实或重现几种流行的基于学习的方法的结果，包括 S2V-DQN [31]、ECO-DQN [4] 等，涉及三个维度：目标值、泛化和可扩展性。我们的经验结果表明，一些学习到的启发式算法未能优于朴素的贪婪算法，并且其中只有一个算法始终优于基于局部搜索的简单通用启发式算法 Tabu Search。此外，我们发现，如果用一个简单的线性回归模型（该模型基于与 Tabu Search 相关的部分特征）来替换 GNN，则 ECO-DQN 的性能将保持不变或得到改善。代码、数据和预训练模型可在此处获得：\url{https://github.com/ankurnath/MaxCut-Bench}。</paragraph>

##### **Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**
2406.10087v1 by Chongmin Lee, Jihie Kim

Certain cancer types, namely pancreatic cancer is difficult to detect at an
early stage; sparking the importance of discovering the causal relationship
between biomarkers and cancer to identify cancer efficiently. By allowing for
the detection and monitoring of specific biomarkers through a non-invasive
method, liquid biopsies enhance the precision and efficacy of medical
interventions, advocating the move towards personalized healthcare. Several
machine learning algorithms such as Random Forest, SVM are utilized for
classification, yet causing inefficiency due to the need for conducting
hyperparameter tuning. We leverage a meta-trained Hyperfast model for
classifying cancer, accomplishing the highest AUC of 0.9929 and simultaneously
achieving robustness especially on highly imbalanced datasets compared to other
ML algorithms in several binary classification tasks (e.g. breast invasive
carcinoma; BRCA vs. non-BRCA). We also propose a novel ensemble model combining
pre-trained Hyperfast model, XGBoost, and LightGBM for multi-class
classification tasks, achieving an incremental increase in accuracy (0.9464)
while merely using 500 PCA features; distinguishable from previous studies
where they used more than 2,000 features for similar results.

摘要：某些类型的癌症，例如胰臟癌，在早期階段難以檢測出來；這點凸顯了找出生物標記與癌症之間的因果關係以有效辨識癌症的重要性。液態切片透過非侵入性方法檢測和監控特定生物標記，進而提升醫療介入的精準度和效能，並倡導朝向個人化醫療保健邁進。隨機森林、SVM 等多種機器學習演算法用於分類，但由於需要進行超參數調整，因此造成效率不彰。我們利用經過元訓練的 Hyperfast 模型來分類癌症，達到了 0.9929 的最高 AUC，同時在多項二元分類任務中（例如乳房浸潤性癌；BRCA 與非 BRCA）實現了穩健性，特別是在高度不平衡的資料集上，優於其他 ML 演算法。我們還提出了一個新穎的整合模型，結合預先訓練的 Hyperfast 模型、XGBoost 和 LightGBM，用於多類別分類任務，僅使用 500 個 PCA 特徵便達到了精準度的增量提升（0.9464）；這點有別於先前的研究，它們使用超過 2,000 個特徵來獲得類似的結果。

##### **FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in Biomedical Domain**
2406.10040v1 by Jin Liu, Steffen Thoma

This paper describes the inference system of FZI-WIM at the SemEval-2024 Task
2: Safe Biomedical Natural Language Inference for Clinical Trials. Our system
utilizes the chain of thought (CoT) paradigm to tackle this complex reasoning
problem and further improves the CoT performance with self-consistency. Instead
of greedy decoding, we sample multiple reasoning chains with the same prompt
and make the final verification with majority voting. The self-consistent CoT
system achieves a baseline F1 score of 0.80 (1st), faithfulness score of 0.90
(3rd), and consistency score of 0.73 (12th). We release the code and data
publicly https://github.com/jens5588/FZI-WIM-NLI4CT.

摘要：這篇論文描述了 FZI-WIM 在 SemEval-2024 任務 2：臨床試驗的安全生物醫學自然語言推論中的推論系統。我們的系統利用思考鏈（CoT）範例來解決這個複雜的推理問題，並進一步透過自洽性來提升 CoT 的效能。我們使用相同的提示取樣多個推理鏈，而非貪婪解碼，並透過多數決進行最終驗證。自洽的 CoT 系統達到基線 F1 分數 0.80（第 1 名）、忠實度分數 0.90（第 3 名）和一致性分數 0.73（第 12 名）。我們公開發布程式碼和資料 https://github.com/jens5588/FZI-WIM-NLI4CT。

##### **CliBench: Multifaceted Evaluation of Large Language Models in Clinical Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions**
2406.09923v1 by Mingyu Derek Ma, Chenchen Ye, Yu Yan, Xiaoxuan Wang, Peipei Ping, Timothy S Chang, Wei Wang

The integration of Artificial Intelligence (AI), especially Large Language
Models (LLMs), into the clinical diagnosis process offers significant potential
to improve the efficiency and accessibility of medical care. While LLMs have
shown some promise in the medical domain, their application in clinical
diagnosis remains underexplored, especially in real-world clinical practice,
where highly sophisticated, patient-specific decisions need to be made. Current
evaluations of LLMs in this field are often narrow in scope, focusing on
specific diseases or specialties and employing simplified diagnostic tasks. To
bridge this gap, we introduce CliBench, a novel benchmark developed from the
MIMIC IV dataset, offering a comprehensive and realistic assessment of LLMs'
capabilities in clinical diagnosis. This benchmark not only covers diagnoses
from a diverse range of medical cases across various specialties but also
incorporates tasks of clinical significance: treatment procedure
identification, lab test ordering and medication prescriptions. Supported by
structured output ontologies, CliBench enables a precise and multi-granular
evaluation, offering an in-depth understanding of LLM's capability on diverse
clinical tasks of desired granularity. We conduct a zero-shot evaluation of
leading LLMs to assess their proficiency in clinical decision-making. Our
preliminary results shed light on the potential and limitations of current LLMs
in clinical settings, providing valuable insights for future advancements in
LLM-powered healthcare.

摘要：人工智能（AI），尤其是大型語言模型（LLM），整合到臨床診斷過程中，提供了顯著的潛力，可以提高醫療保健的效率和可及性。雖然 LLM 在醫療領域顯示出一些前景，但它們在臨床診斷中的應用仍未得到充分探索，尤其是在現實世界的臨床實務中，需要做出高度複雜、針對特定患者的決策。目前在這個領域對 LLM 的評估通常範圍狹窄，著重於特定疾病或專科，並採用簡化的診斷任務。為了彌補這個差距，我們引入了 CliBench，這是一個從 MIMIC IV 資料集開發的新基準，提供了對 LLM 在臨床診斷中能力的全面且實際的評估。此基準不僅涵蓋了各種專科中各種醫療案例的診斷，還納入了具有臨床意義的任務：治療程序識別、實驗室檢驗訂購和藥物處方。在結構化輸出本体的支持下，CliBench 能夠進行精確且多粒度的評估，提供對 LLM 在各種所需粒度的臨床任務上的能力的深入了解。我們對領先的 LLM 進行了零次學習評估，以評估它們在臨床決策中的熟練程度。我們的初步結果揭示了當前 LLM 在臨床環境中的潛力和局限性，為 LLM 驅動的醫療保健的未來進展提供了寶貴的見解。

##### **A Survey on Large Language Models from General Purpose to Medical Applications: Datasets, Methodologies, and Evaluations**
2406.10303v1 by Jinqiang Wang, Huansheng Ning, Yi Peng, Qikai Wei, Daniel Tesfai, Wenwei Mao, Tao Zhu, Runhe Huang

Large Language Models (LLMs) have demonstrated surprising performance across
various natural language processing tasks. Recently, medical LLMs enhanced with
domain-specific knowledge have exhibited excellent capabilities in medical
consultation and diagnosis. These models can smoothly simulate doctor-patient
dialogues and provide professional medical advice. Most medical LLMs are
developed through continued training of open-source general LLMs, which require
significantly fewer computational resources than training LLMs from scratch.
Additionally, this approach offers better protection of patient privacy
compared to API-based solutions. This survey systematically explores how to
train medical LLMs based on general LLMs. It covers: (a) how to acquire
training corpus and construct customized medical training sets, (b) how to
choose a appropriate training paradigm, (c) how to choose a suitable evaluation
benchmark, and (d) existing challenges and promising future research directions
are discussed. This survey can provide guidance for the development of LLMs
focused on various medical applications, such as medical education, diagnostic
planning, and clinical assistants.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展現出驚人的表現。最近，增強了特定領域知識的醫療 LLM 已在醫療諮詢和診斷方面展現出優異的能力。這些模型可以順利模擬醫病對話並提供專業的醫療建議。大多數醫療 LLM 都是透過持續訓練開源的一般 LLM 而開發的，與從頭訓練 LLM 相比，所需運算資源明顯較少。此外，與基於 API 的解決方案相比，這種方法提供了更好的病患隱私保護。這項調查系統性地探討如何根據一般 LLM 訓練醫療 LLM。它涵蓋：(a) 如何取得訓練語料庫並建構客製化的醫療訓練組，(b) 如何選擇適當的訓練範例，(c) 如何選擇合適的評量基準，以及 (d) 討論現有的挑戰和有前景的未來研究方向。這項調查可以為針對各種醫療應用（例如醫學教育、診斷規劃和臨床助理）的 LLM 開發提供指導。

##### **Investigating potential causes of Sepsis with Bayesian network structure learning**
2406.09207v1 by Bruno Petrungaro, Neville K. Kitson, Anthony C. Constantinou

Sepsis is a life-threatening and serious global health issue. This study
combines knowledge with available hospital data to investigate the potential
causes of Sepsis that can be affected by policy decisions. We investigate the
underlying causal structure of this problem by combining clinical expertise
with score-based, constraint-based, and hybrid structure learning algorithms. A
novel approach to model averaging and knowledge-based constraints was
implemented to arrive at a consensus structure for causal inference. The
structure learning process highlighted the importance of exploring data-driven
approaches alongside clinical expertise. This includes discovering unexpected,
although reasonable, relationships from a clinical perspective. Hypothetical
interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and
Diabetes suggest that the presence of any of these risk factors in patients
increases the likelihood of Sepsis. This finding, alongside measuring the
effect of these risk factors on Sepsis, has potential policy implications.
Recognising the importance of prediction in improving Sepsis related health
outcomes, the model built is also assessed in its ability to predict Sepsis.
The predictions generated by the consensus model were assessed for their
accuracy, sensitivity, and specificity. These three indicators all had results
around 70%, and the AUC was 80%, which means the causal structure of the model
is reasonably accurate given that the models were trained on data available for
commissioning purposes only.

摘要：敗血症是一個危及生命且嚴重的全球性健康問題。本研究結合知識與現有的醫院資料，探討可受政策決策影響的敗血症潛在成因。我們結合臨床專業知識與基於分數、基於約束和混合結構學習演算法，探討這個問題的根本因果結構。實作了一種模型平均和基於知識的約束的新方法，以達成因果推論的共識結構。結構學習過程強調了在臨床專業知識的基礎上探索資料驅動方法的重要性。這包括從臨床觀點發現出乎意料，但合理的關係。對慢性阻塞性肺疾病、酒精依賴和糖尿病的假設性干預表明，患者存在任何這些風險因素都會增加敗血症的可能性。這個發現，以及測量這些風險因素對敗血症的影響，具有潛在的政策影響。認識到預測在改善敗血症相關健康結果中的重要性，所建立的模型也評估了其預測敗血症的能力。評估共識模型產生的預測的準確性、敏感性和特異性。這三個指標的結果都在 70% 左右，而 AUC 為 80%，這表示模型的因果結構相當準確，因為模型僅根據可用於委託目的的資料進行訓練。

##### **INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance**
2406.09105v1 by Chenwei Lin, Hanjia Lyu, Xian Xu, Jiebo Luo

Large Vision-Language Models (LVLMs) have demonstrated outstanding
performance in various general multimodal applications such as image
recognition and visual reasoning, and have also shown promising potential in
specialized domains. However, the application potential of LVLMs in the
insurance domain-characterized by rich application scenarios and abundant
multimodal data-has not been effectively explored. There is no systematic
review of multimodal tasks in the insurance domain, nor a benchmark
specifically designed to evaluate the capabilities of LVLMs in insurance. This
gap hinders the development of LVLMs within the insurance domain. In this
paper, we systematically review and distill multimodal tasks for four
representative types of insurance: auto insurance, property insurance, health
insurance, and agricultural insurance. We propose INS-MMBench, the first
comprehensive LVLMs benchmark tailored for the insurance domain. INS-MMBench
comprises a total of 2.2K thoroughly designed multiple-choice questions,
covering 12 meta-tasks and 22 fundamental tasks. Furthermore, we evaluate
multiple representative LVLMs, including closed-source models such as GPT-4o
and open-source models like BLIP-2. This evaluation not only validates the
effectiveness of our benchmark but also provides an in-depth performance
analysis of current LVLMs on various multimodal tasks in the insurance domain.
We hope that INS-MMBench will facilitate the further application of LVLMs in
the insurance domain and inspire interdisciplinary development. Our dataset and
evaluation code are available at https://github.com/FDU-INS/INS-MMBench.

摘要：大型视觉语言模型 (LVLMs) 已在图像识别和视觉推理等各种通用多模态应用程序中展示了出色的性能，并且在专门的领域中也显示出有希望的潜力。然而，LVLMs 在保险领域（以丰富的应用场景和大量多模态数据为特征）的应用潜力尚未得到有效探索。目前还没有对保险领域的模态任务进行系统的审查，也没有专门设计用来评估 LVLMs 在保险中的能力的基准。这种差距阻碍了 LVLMs 在保险领域的开发。在本文中，我们系统地审查和提炼了四种代表性保险类型的多模态任务：汽车保险、财产保险、健康保险和农业保险。我们提出了 INS-MMBench，这是第一个针对保险领域定制的综合 LVLMs 基准。INS-MMBench 包含总共 2.2K 个经过精心设计的单选题，涵盖 12 个元任务和 22 个基本任务。此外，我们评估了多种代表性 LVLMs，包括封闭源模型（如 GPT-4o）和开放源模型（如 BLIP-2）。此评估不仅验证了我们基准的有效性，还提供了当前 LVLMs 在保险领域各种多模态任务上的深入性能分析。我们希望 INS-MMBench 将促进 LVLMs 在保险领域的进一步应用，并激发跨学科发展。我们的数据集和评估代码可在 https://github.com/FDU-INS/INS-MMBench 获得。

##### **Deep learning empowered sensor fusion to improve infant movement classification**
2406.09014v2 by Tomas Kulvicius, Dajie Zhang, Luise Poustka, Sven Bölte, Lennart Jahn, Sarah Flügge, Marc Kraft, Markus Zweckstetter, Karin Nielsen-Saines, Florentin Wörgötter, Peter B Marschik

There is a recent boom in the development of AI solutions to facilitate and
enhance diagnostic procedures for established clinical tools. To assess the
integrity of the developing nervous system, the Prechtl general movement
assessment (GMA) is recognized for its clinical value in diagnosing
neurological impairments in early infancy. GMA has been increasingly augmented
through machine learning approaches intending to scale-up its application,
circumvent costs in the training of human assessors and further standardize
classification of spontaneous motor patterns. Available deep learning tools,
all of which are based on single sensor modalities, are however still
considerably inferior to that of well-trained human assessors. These approaches
are hardly comparable as all models are designed, trained and evaluated on
proprietary/silo-data sets. With this study we propose a sensor fusion approach
for assessing fidgety movements (FMs) comparing three different sensor
modalities (pressure, inertial, and visual sensors). Various combinations and
two sensor fusion approaches (late and early fusion) for infant movement
classification were tested to evaluate whether a multi-sensor system
outperforms single modality assessments. The performance of the three-sensor
fusion (classification accuracy of 94.5\%) was significantly higher than that
of any single modality evaluated, suggesting the sensor fusion approach is a
promising avenue for automated classification of infant motor patterns. The
development of a robust sensor fusion system may significantly enhance AI-based
early recognition of neurofunctions, ultimately facilitating automated early
detection of neurodevelopmental conditions.

摘要：近來，促進並提升既有臨床工具的診斷程序的人工智慧解決方案發展蓬勃。為了評估發育中神經系統的完整性，Prechtl 全般動作評估 (GMA) 因其在診斷嬰兒早期神經損傷的臨床價值而受到肯定。GMA 已透過機器學習方法持續擴充，旨在擴大其應用範圍，規避人類評估人員培訓的成本，並進一步標準化自發性動作模式的分類。現有的深度學習工具，全部都基於單一感測器模式，但仍遠遜於訓練有素的人類評估人員。這些方法難以比較，因為所有模型都是在專有/孤立資料集上設計、訓練和評估的。透過這項研究，我們提出了一種感測器融合方法，用於評估坐立不安的動作 (FM)，並比較三種不同的感測器模式（壓力、慣性和視覺感測器）。測試了各種組合和兩種感測器融合方法（後融合和早融合），用於嬰兒動作分類，以評估多感測器系統是否優於單一模式評估。三感測器融合的效能（分類準確度為 94.5%）顯著高於評估的任何單一模式，這表示感測器融合方法是自動化分類嬰兒動作模式的一個有前途的方法。健全的感測器融合系統的發展可能會顯著提升基於人工智慧的早期神經功能辨識，最終促進神經發展狀況的自動化早期偵測。

##### **Efficient Multi-View Fusion and Flexible Adaptation to View Missing in Cardiovascular System Signals**
2406.08930v1 by Qihan Hu, Daomiao Wang, Hong Wu, Jian Liu, Cuiwei Yang

The progression of deep learning and the widespread adoption of sensors have
facilitated automatic multi-view fusion (MVF) about the cardiovascular system
(CVS) signals. However, prevalent MVF model architecture often amalgamates CVS
signals from the same temporal step but different views into a unified
representation, disregarding the asynchronous nature of cardiovascular events
and the inherent heterogeneity across views, leading to catastrophic view
confusion. Efficient training strategies specifically tailored for MVF models
to attain comprehensive representations need simultaneous consideration.
Crucially, real-world data frequently arrives with incomplete views, an aspect
rarely noticed by researchers. Thus, the View-Centric Transformer (VCT) and
Multitask Masked Autoencoder (M2AE) are specifically designed to emphasize the
centrality of each view and harness unlabeled data to achieve superior fused
representations. Additionally, we systematically define the missing-view
problem for the first time and introduce prompt techniques to aid pretrained
MVF models in flexibly adapting to various missing-view scenarios. Rigorous
experiments involving atrial fibrillation detection, blood pressure estimation,
and sleep staging-typical health monitoring tasks-demonstrate the remarkable
advantage of our method in MVF compared to prevailing methodologies. Notably,
the prompt technique requires finetuning less than 3% of the entire model's
data, substantially fortifying the model's resilience to view missing while
circumventing the need for complete retraining. The results demonstrate the
effectiveness of our approaches, highlighting their potential for practical
applications in cardiovascular health monitoring. Codes and models are released
at URL.

摘要：深度學習的進展和感測器的廣泛採用，促進了心血管系統 (CVS) 訊號的自動多視角融合 (MVF)。然而，普遍的 MVF 模型架構經常將來自相同時間步驟但不同視角的 CVS 訊號融合為統一的表示，忽視了心血管事件的非同步性質和視角之間的內在異質性，導致災難性的視角混淆。需要同時考慮專門針對 MVF 模型量身打造的有效訓練策略，以獲得全面的表示。至關重要的是，真實世界的資料經常會出現不完整的視角，研究人員很少注意到這個面向。因此，視角中心Transformer (VCT) 和多任務遮罩式自動編碼器 (M2AE) 被特別設計為強調每個視角的中心性，並利用未標記的資料來實現優越的融合表示。此外，我們系統性地首次定義了缺失視角問題，並引入了提示技術，以幫助預訓練的 MVF 模型靈活適應各種缺失視角場景。涉及心房顫動偵測、血壓估計和睡眠分期的嚴謹實驗（典型的健康監測任務）證明了我們的方法在 MVF 中與現有方法相比具有顯著優勢。值得注意的是，提示技術需要微調不到整個模型資料的 3%，這大大加強了模型對視角缺失的復原力，同時避免了重新訓練的需要。結果證明了我們方法的有效性，突出了它們在心血管健康監測中的實際應用潛力。程式碼和模型已在 URL 中發布。

##### **Computer Vision Approaches for Automated Bee Counting Application**
2406.08898v1 by Simon Bilik, Ilona Janakova, Adam Ligocki, Dominik Ficek, Karel Horak

Many application from the bee colony health state monitoring could be
efficiently solved using a computer vision techniques. One of such challenges
is an efficient way for counting the number of incoming and outcoming bees,
which could be used to further analyse many trends, such as the bee colony
health state, blooming periods, or for investigating the effects of
agricultural spraying. In this paper, we compare three methods for the
automated bee counting over two own datasets. The best performing method is
based on the ResNet-50 convolutional neural network classifier, which achieved
accuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2
dataset.

摘要：許多應用程式從蜜蜂群體健康狀態監控中，能有效率地使用電腦視覺技術解決。其中一個挑戰是有效率地計算進出蜂群的數量，這能用來進一步分析許多趨勢，例如蜜蜂群體健康狀態、開花期，或用於調查農業噴灑的影響。在本文中，我們比較了三個自動化計算蜜蜂數量的方法，使用兩個我們自己的資料集。表現最好的方法是基於 ResNet-50 捲積神經網路分類器，在 BUT1 資料集上達到 87% 的準確度，在 BUT2 資料集上達到 93% 的準確度。

##### **Automatically Labeling $200B Life-Saving Datasets: A Large Clinical Trial Outcome Benchmark**
2406.10292v1 by Chufan Gao, Jathurshan Pradeepkumar, Trisha Das, Shivashankar Thati, Jimeng Sun

The global cost of drug discovery and development exceeds $200 billion
annually. The main results of drug discovery and development are the outcomes
of clinical trials, which directly influence the regulatory approval of new
drug candidates and ultimately affect patient outcomes. Despite their
significance, large-scale, high-quality clinical trial outcome data are not
readily available to the public. Suppose a large clinical trial outcome dataset
is provided; machine learning researchers can potentially develop accurate
prediction models using past trials and outcome labels, which could help
prioritize and optimize therapeutic programs, ultimately benefiting patients.
This paper introduces Clinical Trial Outcome (CTO) dataset, the largest trial
outcome dataset with around 479K clinical trials, aggregating outcomes from
multiple sources of weakly supervised labels, minimizing the noise from
individual sources, and eliminating the need for human annotation. These
sources include large language model (LLM) decisions on trial-related
documents, news headline sentiments, stock prices of trial sponsors, trial
linkages across phases, and other signals such as patient dropout rates and
adverse events. CTO's labels show unprecedented agreement with supervised
clinical trial outcome labels from test split of the supervised TOP dataset,
with a 91 F1.

摘要：全球藥物發現和開發的成本每年超過 2000 億美元。藥物發現和開發的主要成果是臨床試驗的結果，它直接影響新藥候選者的法規核准，並最終影響患者的結果。儘管它們很重要，但大型、高品質的臨床試驗結果數據並不容易讓公眾取得。假設提供了大型臨床試驗結果數據集；機器學習研究人員有可能使用過去的試驗和結果標籤開發準確的預測模型，這有助於優先考慮和最佳化治療計畫，最終使患者受益。本文介紹了臨床試驗結果 (CTO) 數據集，這是最大的試驗結果數據集，包含約 479K 個臨床試驗，彙總了來自多個來源的弱監督標籤的結果，最大限度地減少了來自個別來源的雜訊，並消除了人工註解的需要。這些來源包括大型語言模型 (LLM) 對試驗相關文件的決定、新聞標題情緒、試驗贊助商的股票價格、跨階段試驗連結，以及其他信號，例如患者輟學率和不良事件。CTO 的標籤顯示出與來自監督式 TOP 數據集測試分割的監督式臨床試驗結果標籤前所未有的吻合度，F1 為 91。

##### **Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis**
2406.08695v1 by Attrayee Chakraborty, Mandar Karhade

Artificial Intelligence (AI) is being adopted across the world and promises a
new revolution in healthcare. While AI-enabled medical devices in North America
dominate 42.3% of the global market, the use of AI-enabled medical devices in
other countries is still a story waiting to be unfolded. We aim to delve deeper
into global regulatory approaches towards AI use in healthcare, with a focus on
how common themes are emerging globally. We compare these themes to the World
Health Organization's (WHO) regulatory considerations and principles on ethical
use of AI for healthcare applications. Our work seeks to take a global
perspective on AI policy by analyzing 14 legal jurisdictions including
countries representative of various regions in the world (North America, South
America, South East Asia, Middle East, Africa, Australia, and the
Asia-Pacific). Our eventual goal is to foster a global conversation on the
ethical use of AI in healthcare and the regulations that will guide it. We
propose solutions to promote international harmonization of AI regulations and
examine the requirements for regulating generative AI, using China and
Singapore as examples of countries with well-developed policies in this area.

摘要：人工智能（AI）正在全球范围内得到採用，並承諾在醫療保健領域掀起一場新的革命。儘管北美的人工智慧醫療設備主導了全球市場的 42.3%，但其他國家/地區的人工智慧醫療設備的使用情況仍是一個有待展開的故事。我們旨在深入探討全球對醫療保健中 AI 使用的法規方法，重點關注全球範圍內如何出現共同的主題。我們將這些主題與世界衛生組織 (WHO) 對醫療保健應用中 AI 道德使用的法規考量和原則進行比較。我們的研究旨在通過分析 14 個法域（包括代表世界各地不同地區的國家/地區（北美、南美、東南亞、中東、非洲、澳大利亞和亞太地區））來對 AI 政策採取全球觀點。我們的最終目標是促進關於醫療保健中 AI 道德使用和將指導它的法規的全球對話。我們提出解決方案以促進 AI 法規的國際協調，並以中國和新加坡為例，探討了對生成式 AI 進行監管的要求，這些國家/地區在這一領域擁有完善的政策。

##### **Advancing High Resolution Vision-Language Models in Biomedicine**
2406.09454v1 by Zekai Chen, Arda Pekis, Kevin Brown

Multi-modal learning has significantly advanced generative AI, especially in
vision-language modeling. Innovations like GPT-4V and open-source projects such
as LLaVA have enabled robust conversational agents capable of zero-shot task
completions. However, applying these technologies in the biomedical field
presents unique challenges. Recent initiatives like LLaVA-Med have started to
adapt instruction-tuning for biomedical contexts using large datasets such as
PMC-15M. Our research offers three key contributions: (i) we present a new
instruct dataset enriched with medical image-text pairs from Claude3-Opus and
LLaMA3 70B, (ii) we propose a novel image encoding strategy using hierarchical
representations to improve fine-grained biomedical visual comprehension, and
(iii) we develop the Llama3-Med model, which achieves state-of-the-art
zero-shot performance on biomedical visual question answering benchmarks, with
an average performance improvement of over 10% compared to previous methods.
These advancements provide more accurate and reliable tools for medical
professionals, bridging gaps in current multi-modal conversational assistants
and promoting further innovations in medical AI.

摘要：多模态学习已大幅提升生成式 AI，尤其是在视觉语言建模方面。GPT-4V 等创新和 LLaVA 等开源项目已让健全的对话代理能够完成零次学习任务。然而，在生物医学领域应用这些技术提出了独特的挑战。LLaVA-Med 等近期计划已开始使用 PMC-15M 等大型数据集，为生物医学语境调整指令。我们的研究提供了三个关键贡献：(i) 我们展示了一个新的指令数据集，其中包含来自 Claude3-Opus 和 LLaMA3 70B 的医学图像-文本对，(ii) 我们提出了一种新的图像编码策略，使用分层表示来改善细粒度的生物医学视觉理解，以及 (iii) 我们开发了 Llama3-Med 模型，该模型在生物医学视觉问答基准上实现了最先进的零次学习性能，与之前的方法相比，平均性能提升了 10% 以上。这些进步为医学专业人士提供了更准确和可靠的工具，弥补了当前多模态对话助理中的差距，并促进了医学 AI 的进一步创新。

##### **AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**
2406.08425v1 by Ayush Roy, Payel Pramanik, Dmitrii Kaplun, Sergei Antonov, Ram Sarkar

Accurate nuclei segmentation in histopathological images is crucial for
cancer diagnosis. Automating this process offers valuable support to clinical
experts, as manual annotation is time-consuming and prone to human errors.
However, automating nuclei segmentation presents challenges due to uncertain
cell boundaries, intricate staining, and diverse structures. In this paper, we
present a segmentation approach that combines the U-Net architecture with a
DenseNet-121 backbone, harnessing the strengths of both to capture
comprehensive contextual and spatial information. Our model introduces the
Wavelet-guided channel attention module to enhance cell boundary delineation,
along with a learnable weighted global attention module for channel-specific
attention. The decoder module, composed of an upsample block and convolution
block, further refines segmentation in handling staining patterns. The
experimental results conducted on two publicly accessible histopathology
datasets, namely Monuseg and TNBC, underscore the superiority of our proposed
model, demonstrating its potential to advance histopathological image analysis
and cancer diagnosis. The code is made available at:
https://github.com/AyushRoy2001/AWGUNET.

摘要：組織病理學影像中精確的細胞核分割對於癌症診斷至關重要。自動化此程序可為臨床專家提供有價值的支援，因為手動註解既耗時又容易發生人為錯誤。然而，由於細胞邊界不確定、染色複雜且結構多樣，自動化細胞核分割會產生挑戰。在本文中，我們提出了一種分割方法，將 U-Net 架構與 DenseNet-121 主幹結合，利用兩者的優勢來擷取全面的上下文和空間資訊。我們的模型引入了小波導向通道注意模組，以增強細胞邊界的描繪，以及一個可學習的加權全局注意模組，用於特定通道的注意。解碼器模組由上採樣區塊和卷積區塊組成，進一步優化了處理染色模式的分割。在兩個公開可用的組織病理學資料集（即 Monuseg 和 TNBC）上進行的實驗結果，突顯了我們提出的模型的優越性，證明了其在推進組織病理學影像分析和癌症診斷方面的潛力。程式碼可在以下位置取得：https://github.com/AyushRoy2001/AWGUNET。

##### **2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**
2406.08374v2 by Tianqi Chen, Jun Hou, Yinchi Zhou, Huidong Xie, Xiongchao Chen, Qiong Liu, Xueqi Guo, Menghua Xia, James S. Duncan, Chi Liu, Bo Zhou

Positron Emission Tomography (PET) is an important clinical imaging tool but
inevitably introduces radiation hazards to patients and healthcare providers.
Reducing the tracer injection dose and eliminating the CT acquisition for
attenuation correction can reduce the overall radiation dose, but often results
in PET with high noise and bias. Thus, it is desirable to develop 3D methods to
translate the non-attenuation-corrected low-dose PET (NAC-LDPET) into
attenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models
have emerged as a new state-of-the-art deep learning method for image-to-image
translation, better than traditional CNN-based methods. However, due to the
high computation cost and memory burden, it is largely limited to 2D
applications. To address these challenges, we developed a novel 2.5D Multi-view
Averaging Diffusion Model (MADM) for 3D image-to-image translation with
application on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs
separate diffusion models for axial, coronal, and sagittal views, whose outputs
are averaged in each sampling step to ensure the 3D generation quality from
multiple views. To accelerate the 3D sampling process, we also proposed a
strategy to use the CNN-based 3D generation as a prior for the diffusion model.
Our experimental results on human patient studies suggested that MADM can
generate high-quality 3D translation images, outperforming previous CNN-based
and Diffusion-based baseline methods.

摘要：正子發射斷層攝影 (PET) 是一種重要的臨床影像工具，但不可避免地會對患者和醫療保健提供者造成輻射危害。降低示蹤劑注射劑量並消除衰減校正的 CT 採集可以降低整體輻射劑量，但通常會導致 PET 雜訊和偏差過高。因此，需要開發 3D 方法，將非衰減校正低劑量 PET (NAC-LDPET) 轉換為衰減校正標準劑量 PET (AC-SDPET)。最近，擴散模型已成為一種新的最先進深度學習方法，用於影像到影像轉換，優於傳統的基於 CNN 的方法。然而，由於運算成本和記憶體負擔過高，它在很大程度上僅限於 2D 應用。為了應對這些挑戰，我們開發了一種新穎的 2.5D 多視圖平均擴散模型 (MADM)，用於 3D 影像到影像轉換，並應用於 NAC-LDPET 到 AC-SDPET 的轉換。具體來說，MADM 對軸向、冠狀和矢狀視圖採用了單獨的擴散模型，其輸出在每個採樣步驟中取平均值，以確保從多個視圖生成 3D 的品質。為了加速 3D 採樣過程，我們還提出了一種策略，使用基於 CNN 的 3D 生成作為擴散模型的先驗。我們在人體患者研究中進行的實驗結果表明，MADM 可以生成高品質的 3D 轉換影像，優於先前的基於 CNN 和基於擴散的基準方法。

##### **Making AI Intelligible: Philosophical Foundations**
2406.08134v1 by Herman Cappelen, Josh Dever

Can humans and artificial intelligences share concepts and communicate?
'Making AI Intelligible' shows that philosophical work on the metaphysics of
meaning can help answer these questions. Herman Cappelen and Josh Dever use the
externalist tradition in philosophy to create models of how AIs and humans can
understand each other. In doing so, they illustrate ways in which that
philosophical tradition can be improved.
  The questions addressed in the book are not only theoretically interesting,
but the answers have pressing practical implications. Many important decisions
about human life are now influenced by AI. In giving that power to AI, we
presuppose that AIs can track features of the world that we care about (for
example, creditworthiness, recidivism, cancer, and combatants). If AIs can
share our concepts, that will go some way towards justifying this reliance on
AI. This ground-breaking study offers insight into how to take some first steps
towards achieving Interpretable AI.

摘要：人類與人工智慧能共享概念並溝通嗎？
「讓人工智慧易於理解」一書表明，關於意義的形上學哲學著作有助於回答這些問題。赫爾曼·卡佩倫和喬希·德弗利用哲學中的外在主義傳統，建立了關於人工智慧和人類如何理解彼此的模型。在這樣做的過程中，他們說明了哲學傳統可以得到改善的方式。
書中探討的問題不僅在理論上很有趣，而且答案具有迫切的實際意義。許多關於人類生活的重要決定現在都受到人工智慧的影響。在將這種力量賦予人工智慧時，我們預設人工智慧可以追蹤我們關心的世界特徵（例如，信用評分、累犯率、癌症和戰鬥人員）。如果人工智慧能共享我們的概念，這將有助於證明依賴人工智慧的合理性。這項開創性的研究提供了如何採取一些第一步來實現可解釋人工智慧的見解。

##### **Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**
2406.07917v1 by Peizhi Niu, Chao Pan, Siheng Chen, Olgica Milenkovic

Graph neural networks (GNNs) have become instrumental in diverse real-world
applications, offering powerful graph learning capabilities for tasks such as
social networks and medical data analysis. Despite their successes, GNNs are
vulnerable to adversarial attacks, including membership inference attacks
(MIA), which threaten privacy by identifying whether a record was part of the
model's training data. While existing research has explored MIA in GNNs under
graph inductive learning settings, the more common and challenging graph
transductive learning setting remains understudied in this context. This paper
addresses this gap and proposes an effective two-stage defense, Graph
Transductive Defense (GTD), tailored to graph transductive learning
characteristics. The gist of our approach is a combination of a train-test
alternate training schedule and flattening strategy, which successfully reduces
the difference between the training and testing loss distributions. Extensive
empirical results demonstrate the superior performance of our method (a
decrease in attack AUROC by $9.42\%$ and an increase in utility performance by
$18.08\%$ on average compared to LBP), highlighting its potential for seamless
integration into various classification models with minimal overhead.

摘要：圖形神經網路 (GNN) 已成為各種真實世界應用中不可或缺的工具，為社交網路和醫療數據分析等任務提供強大的圖形學習能力。儘管取得成功，GNN 仍容易受到對抗性攻擊，包括成員推論攻擊 (MIA)，這會透過辨識記錄是否為模型訓練資料的一部分來威脅隱私。雖然現有研究已探討圖形歸納學習設定下的 GNN 中的 MIA，但更常見且更具挑戰性的圖形轉導學習設定在此背景下仍未獲得充分研究。本文探討此差距，並提出一個有效的分兩階段防禦機制，圖形轉導防禦 (GTD)，專門針對圖形轉導學習特性量身打造。我們方法的要點是結合訓練測試交替訓練時程和扁平化策略，成功縮小訓練和測試損失分佈之間的差異。廣泛的實證結果證明我們方法的優異效能（與 LBP 相比，攻擊 AUROC 減少 9.42%，效用效能平均增加 18.08%），突顯其在各種分類模型中無縫整合的潛力，且開銷極小。

##### **Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis**
2406.10273v1 by Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi

Context. Risk analysis assesses potential risks in specific scenarios. Risk
analysis principles are context-less; the same methodology can be applied to a
risk connected to health and information technology security. Risk analysis
requires a vast knowledge of national and international regulations and
standards and is time and effort-intensive. A large language model can quickly
summarize information in less time than a human and can be fine-tuned to
specific tasks. Aim. Our empirical study aims to investigate the effectiveness
of Retrieval-Augmented Generation and fine-tuned LLM in Risk analysis. To our
knowledge, no prior study has explored its capabilities in risk analysis.
Method. We manually curated \totalscenarios unique scenarios leading to
\totalsamples representative samples from over 50 mission-critical analyses
archived by the industrial context team in the last five years. We compared the
base GPT-3.5 and GPT-4 models versus their Retrieval-Augmented Generation and
fine-tuned counterparts. We employ two human experts as competitors of the
models and three other three human experts to review the models and the former
human expert's analysis. The reviewers analyzed 5,000 scenario analyses.
Results and Conclusions. HEs demonstrated higher accuracy, but LLMs are quicker
and more actionable. Moreover, our findings show that RAG-assisted LLMs have
the lowest hallucination rates, effectively uncovering hidden risks and
complementing human expertise. Thus, the choice of model depends on specific
needs, with FTMs for accuracy, RAG for hidden risks discovery, and base models
for comprehensiveness and actionability. Therefore, experts can leverage LLMs
for an effective complementing companion in risk analysis within a condensed
timeframe. They can also save costs by averting unnecessary expenses associated
with implementing unwarranted countermeasures.

摘要：<paragraph>背景。風險分析評估特定情境中的潛在風險。風險分析原則與情境無關；相同的分析方法可以應用於與健康和資訊技術安全相關的風險。風險分析需要具備廣泛的國家和國際法規及標準知識，而且需要耗費大量時間和精力。大型語言模型可以在比人類更短的時間內快速摘要資訊，並且可以針對特定任務進行微調。目標。我們的實證研究旨在探討檢索增強式生成和微調 LLM 在風險分析中的有效性。據我們所知，沒有先前的研究探討其在風險分析中的能力。方法。我們手動策劃了 \totalscenarios 個導致 \totalsamples 個代表性樣本的獨特情境，這些樣本來自產業情境小組在過去五年中歸檔的 50 多項任務關鍵分析。我們比較了基本 GPT-3.5 和 GPT-4 模型與其檢索增強式生成和微調的對應模型。我們聘請兩位人類專家作為模型的競爭者，並聘請另外三位人類專家來審查模型和前一位人類專家的分析。審查人員分析了 5,000 個情境分析。結果和結論。人類專家展現出較高的準確度，但 LLM 較快且更具可操作性。此外，我們的研究結果顯示，RAG 輔助的 LLM 具有最低的幻覺率，能有效揭露隱藏風險並補充人類專業知識。因此，模型的選擇取決於特定需求，FTM 適用於準確性，RAG 適用於隱藏風險發現，而基本模型適用於全面性和可操作性。因此，專家可以在風險分析中利用 LLM 作為一個有效的補充夥伴，並在縮短的時間範圍內。他們還可以透過避免與實施不必要的對策相關的不必要開支來節省成本。</paragraph>

##### **Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**
2406.07542v1 by David Ortiz-Perez, Jose Garcia-Rodriguez, David Tomás

Cognitive decline is a natural process that occurs as individuals age. Early
diagnosis of anomalous decline is crucial for initiating professional treatment
that can enhance the quality of life of those affected. To address this issue,
we propose a multimodal model capable of predicting Mild Cognitive Impairment
and cognitive scores. The TAUKADIAL dataset is used to conduct the evaluation,
which comprises audio recordings of clinical interviews. The proposed model
demonstrates the ability to transcribe and differentiate between languages used
in the interviews. Subsequently, the model extracts audio and text features,
combining them into a multimodal architecture to achieve robust and generalized
results. Our approach involves in-depth research to implement various features
obtained from the proposed modalities.

摘要：認知能力下降是個人隨著年齡增長而發生的自然過程。及早診斷異常下降對於啟動專業治療至關重要，可提升受影響者的生活品質。為了解決此問題，我們提出一個多模態模型，能夠預測輕度認知障礙和認知評分。TAUKADIAL 資料集用於進行評估，其中包含臨床訪談的音訊錄製。所提出的模型展示了轉錄和區分訪談中所用語言的能力。隨後，模型會擷取音訊和文字特徵，將它們組合成多模態架構，以達成穩健且廣泛的結果。我們的做法涉及深入研究，以實作從所提出的模態中取得的各種特徵。

##### **CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**
2406.07494v2 by Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas

Abstractive dialogue summarization is the task of distilling conversations
into informative and concise summaries. Although reviews have been conducted on
this topic, there is a lack of comprehensive work detailing the challenges of
dialogue summarization, unifying the differing understanding of the task, and
aligning proposed techniques, datasets, and evaluation metrics with the
challenges. This article summarizes the research on Transformer-based
abstractive summarization for English dialogues by systematically reviewing
1262 unique research papers published between 2019 and 2024, relying on the
Semantic Scholar and DBLP databases. We cover the main challenges present in
dialog summarization (i.e., language, structure, comprehension, speaker,
salience, and factuality) and link them to corresponding techniques such as
graph-based approaches, additional training tasks, and planning strategies,
which typically overly rely on BART-based encoder-decoder models. We find that
while some challenges, like language, have seen considerable progress, mainly
due to training methods, others, such as comprehension, factuality, and
salience, remain difficult and hold significant research opportunities. We
investigate how these approaches are typically assessed, covering the datasets
for the subdomains of dialogue (e.g., meeting, medical), the established
automatic metrics and human evaluation approaches for assessing scores and
annotator agreement. We observe that only a few datasets span across all
subdomains. The ROUGE metric is the most used, while human evaluation is
frequently reported without sufficient detail on inner-annotator agreement and
annotation guidelines. Additionally, we discuss the possible implications of
the recently explored large language models and conclude that despite a
potential shift in relevance and difficulty, our described challenge taxonomy
remains relevant.

摘要：<paragraph>抽象式對話摘要是將對話濃縮成具有資訊性且簡潔的摘要。儘管已針對此主題進行審查，但仍缺乏詳細說明對話摘要挑戰、統一對任務的不同理解，以及將建議的技術、資料集和評估指標與挑戰相符的全面性研究。本文透過系統性地檢閱 2019 年至 2024 年間發表的 1262 篇獨特研究論文，依賴語義學者和 DBLP 資料庫，總結了基於 Transformer 的英語對話抽象式摘要的研究。我們涵蓋對話摘要中出現的主要挑戰（即語言、結構、理解、說話者、顯著性和真實性），並將它們連結到對應的技術，例如基於圖形的方法、額外的訓練任務和規劃策略，這些策略通常過度依賴於基於 BART 的編碼器-解碼器模型。我們發現，雖然語言等一些挑戰在很大程度上取得了進展，這主要是由於訓練方法，但其他挑戰，例如理解、真實性和顯著性，仍然很困難，並具有重大的研究機會。我們探討了通常如何評估這些方法，涵蓋了對話子領域（例如會議、醫療）的資料集，既定的自動化指標和用於評估分數和註解者一致性的評估方法。我們觀察到，只有少數資料集跨越所有子領域。ROUGE 指標使用最頻繁，而人類評估通常在沒有足夠的註解者內部一致性和註解指南的詳細資訊下進行報告。此外，我們討論了近期探索的大語言模型的可能影響，並得出結論，儘管相關性和難度可能發生轉變，但我們所描述的挑戰分類法仍然相關。</paragraph>

##### **Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**
2406.07146v2 by Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

Automatic radiology report generation can significantly benefit the
labor-intensive process of report writing by radiologists, especially for 3D
radiographs like CT scans, which are crucial for broad clinical diagnostics yet
underexplored compared to 2D radiographs. Existing methods often handle 3D
volumes either slice-wise or with aggressive downsampling due to current GPU
memory limitations, which results in a loss of the inherent 3D nature and
critical details. To overcome these issues, we introduce a novel framework that
efficiently and effectively generates radiology reports for high-resolution
(HR) 3D volumes, based on large language models (LLMs). Specifically, our
framework utilizes low-resolution (LR) visual tokens as queries to mine
information from HR tokens, preserving detailed HR information while reducing
computational costs by only processing HR informed LR visual queries. Further
benefiting the field, we curate and release BIMCV-RG, a new dataset with 5,328
HR 3D volumes and paired reports, establishing the first benchmarks for report
generation from 3D HR medical images. Our method consistently surpasses
existing methods on this benchmark across three different settings:
normal-resolution, high-resolution inputs, and zero-shot domain transfer, all
at an acceptable computational cost, trainable on a single A100-80G.

摘要：自動放射線報告生成可以大幅降低放射科醫師撰寫報告的勞力密集程序，特別是對於 3D 射線照片（例如電腦斷層掃描），這對廣泛的臨床診斷至關重要，但與 2D 射線照片相比，仍未被充分探索。現有方法通常會以切片方式或透過激進的降採樣來處理 3D 體積，這是因為目前的 GPU 記憶體有限，這會導致固有的 3D 特性和關鍵細節遺失。為了克服這些問題，我們引入了一個新架構，可有效率且有效地為高解析度 (HR) 3D 體積生成放射線報告，其基礎是大語言模型 (LLM)。具體來說，我們的架構利用低解析度 (LR) 視覺標記作為查詢，從 HR 標記中挖掘資訊，同時保留詳細的 HR 資訊，並透過僅處理 HR 資訊的 LR 視覺查詢來降低運算成本。我們整理並發布 BIMCV-RG，一個包含 5,328 個 HR 3D 體積和配對報告的新資料集，進一步造福這個領域，為從 3D HR 醫學影像生成報告建立了第一個基準。我們的模型在三個不同的設定中持續超越現有的模型：正常解析度、高解析度輸入和零次學習領域轉移，所有設定的運算成本都在可接受的範圍內，且可以在單個 A100-80G 上訓練。

##### **Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**
2406.07114v1 by Fatemeh Ebrahimzadeh, Ramin Safa

The Metaverse, a persistent, immersive virtual environment, has the immense
potential to revolutionize healthcare by transforming patient care, medical
education, and research. This paper explores the applications, benefits, and
challenges associated with this transformative technology, highlighting its
ability to improve patient engagement, communication, access to information,
and health outcomes. The paper also examines how the analysis of Metaverse data
using machine learning techniques can unlock insights to further enhance
healthcare applications. The discussion summarizes key findings, analyzes the
significance and practical implications of Metaverse integration, and
identifies areas for future research. It underscores the role of major tech
companies in developing Metaverse-based solutions and the importance of
addressing emerging opportunities and challenges to unlock the transformative
potential of this technology in healthcare. The paper concludes by emphasizing
the need for collaboration between stakeholders to ensure the ethical and
effective implementation of these technologies, ultimately leading to a more
accessible, personalized, and efficient healthcare system.

摘要：元宇宙，一個持續性的沉浸式虛擬環境，具有通過轉變患者照護、醫療教育和研究來徹底改變醫療保健的巨大潛力。本文探討了與這項變革性技術相關的應用、優點和挑戰，重點說明其改善患者參與度、溝通、獲取資訊和健康結果的能力。本文還探討了如何使用機器學習技術分析元宇宙資料，以解鎖見解，進一步增強醫療保健應用。討論總結了主要發現，分析了元宇宙整合的意義和實際影響，並找出未來研究領域。它強調了大型科技公司在開發基於元宇宙的解決方案中的作用，以及解決新興機會和挑戰以釋放這項技術在醫療保健中的轉型潛力的重要性。本文最後強調了利益相關者之間合作的必要性，以確保這些技術的道德和有效實施，最終建立一個更易於使用、更個性化和更有效的醫療保健系統。

##### **Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**
2406.07028v1 by Chenxia Tang

In this paper, we attempt to address the challenge of applying Neural
Architecture Search (NAS) algorithms, specifically the Differentiable
Architecture Search (DARTS), to long-tailed datasets where class distribution
is highly imbalanced. We observe that traditional re-sampling and re-weighting
techniques, which are effective in standard classification tasks, lead to
performance degradation when combined with DARTS. To mitigate this, we propose
a novel adaptive learning rate scheduling strategy tailored for the
architecture parameters of DARTS when integrated with the Bilateral Branch
Network (BBN) for handling imbalanced datasets. Our approach dynamically
adjusts the learning rate of the architecture parameters based on the training
epoch, preventing the disruption of well-trained representations in the later
stages of training. Additionally, we explore the impact of branch mixing
factors on the algorithm's performance. Through extensive experiments on the
CIFAR-10 dataset with an artificially induced long-tailed distribution, we
demonstrate that our method achieves comparable accuracy to using DARTS alone.
And the experiment results suggest that re-sampling methods inherently harm the
performance of the DARTS algorithm. Our findings highlight the importance of
careful data augment when applying DNAS to imbalanced learning scenarios.

摘要：<paragraph>在本文中，我们尝试解决将神经架构搜索 (NAS) 算法（特别是可微架构搜索 (DARTS)）应用于长尾数据集的挑战，其中类分布高度不平衡。我们观察到传统的重新采样和重新加权技术（在标准分类任务中有效）与 DARTS 结合使用时会导致性能下降。为了缓解这个问题，我们提出了一种新的自适应学习率调度策略，该策略针对 DARTS 的架构参数量身定制，并与双边分支网络 (BBN) 集成以处理不平衡数据集。我们的方法根据训练时期动态调整架构参数的学习率，防止在训练后期破坏训练良好的表示。此外，我们探讨了分支混合因子对算法性能的影响。通过在人工诱导的长尾分布的 CIFAR-10 数据集上进行广泛的实验，我们证明了我们的方法与单独使用 DARTS 实现了相当的准确性。实验结果表明，重新采样方法本质上会损害 DARTS 算法的性能。我们的研究结果突出了在将 DNAS 应用于不平衡学习场景时仔细进行数据扩充的重要性。</paragraph>

##### **Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**
2406.06848v1 by Kiran Kokilepersaud, Yavuz Yarici, Mohit Prabhushankar, Ghassan AlRegib

In this work, we propose a novel supervised contrastive loss that enables the
integration of taxonomic hierarchy information during the representation
learning process. A supervised contrastive loss operates by enforcing that
images with the same class label (positive samples) project closer to each
other than images with differing class labels (negative samples). The advantage
of this approach is that it directly penalizes the structure of the
representation space itself. This enables greater flexibility with respect to
encoding semantic concepts. However, the standard supervised contrastive loss
only enforces semantic structure based on the downstream task (i.e. the class
label). In reality, the class label is only one level of a \emph{hierarchy of
different semantic relationships known as a taxonomy}. For example, the class
label is oftentimes the species of an animal, but between different classes
there are higher order relationships such as all animals with wings being
``birds". We show that by explicitly accounting for these relationships with a
weighting penalty in the contrastive loss we can out-perform the supervised
contrastive loss. Additionally, we demonstrate the adaptability of the notion
of a taxonomy by integrating our loss into medical and noise-based settings
that show performance improvements by as much as 7%.

摘要：在這項工作中，我們提出了一種新穎的監督對比損失，它可以在表示學習過程中整合分類層級資訊。監督對比損失透過強制具有相同類別標籤（正樣本）的影像比具有不同類別標籤（負樣本）的影像更接近彼此來運作。這種方法的優點是它直接懲罰表示空間本身的結構。這使得在編碼語意概念方面具有更大的靈活性。然而，標準的監督對比損失僅根據下游任務（即類別標籤）來強制語意結構。實際上，類別標籤只是稱為分類法的一種不同語意關係層級中的其中一層。例如，類別標籤通常是動物的物種，但在不同的類別之間存在更高階的關係，例如所有有翅膀的動物都是「鳥類」。我們表明，透過在對比損失中使用加權懲罰來明確說明這些關係，我們可以優於監督對比損失。此外，我們展示了分類法概念的適應性，方法是將我們的損失整合到醫療和基於雜訊的設定中，這些設定顯示效能提升了 7%。

##### **SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**
2406.07835v1 by David Wadden, Kejian Shi, Jacob Morrison, Aakanksha Naik, Shruti Singh, Nitzan Barzilay, Kyle Lo, Tom Hope, Luca Soldaini, Shannon Zejiang Shen, Doug Downey, Hannaneh Hajishirzi, Arman Cohan

We present SciRIFF (Scientific Resource for Instruction-Following and
Finetuning), a dataset of 137K instruction-following demonstrations for 54
tasks covering five essential scientific literature understanding capabilities:
information extraction, summarization, question answering, claim verification,
and classification. SciRIFF demonstrations are notable for their long input
contexts, detailed task specifications, and complex structured outputs. While
instruction-following resources are available in specific domains such as
clinical medicine and chemistry, SciRIFF is the first dataset focused on
extracting and synthesizing information from research literature across a wide
range of scientific fields. To demonstrate the utility of SciRIFF, we develop a
sample-efficient strategy to adapt a general instruction-following model for
science by performing additional finetuning on a mix of general-domain and
SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our
model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and
6.5% at the 7B and 70B scales respectively, while maintaining general
instruction-following performance within 2% of the baseline. We are optimistic
that SciRIFF will facilitate the development and evaluation of LLMs to help
researchers navigate the ever-growing body of scientific literature. We release
our dataset, model checkpoints, and data processing and evaluation code to
enable further research.

摘要：<paragraph>我們提出 SciRIFF（科學資源，用於遵循說明和微調），這是一個包含 137K 遵循說明的示範資料集，涵蓋 54 項任務，涵蓋五項重要的科學文獻理解能力：資訊擷取、摘要、問答、聲明驗證和分類。SciRIFF 示範以其長的輸入內容、詳細的任務規格和複雜的結構化輸出而聞名。雖然特定領域（例如臨床醫學和化學）有遵循說明的資源，但 SciRIFF 是第一個專注於從各種科學領域的研究文獻中提取和綜合資訊的資料集。為了展示 SciRIFF 的效用，我們制定了一種樣本有效率的策略，透過在一般領域和 SciRIFF 示範的組合上執行額外的微調，來調整一般遵循說明的模型以適應科學。在九項已暫停的科學任務的評估中，我們的模型（稱為 SciTulu）在 7B 和 70B 規模分別比強大的 LLM 基準提高了 28.1% 和 6.5%，同時將一般遵循說明的效能維持在基準的 2% 以內。我們樂觀地認為 SciRIFF 將有助於開發和評估 LLM，以幫助研究人員瀏覽不斷增長的科學文獻。我們釋出我們的資料集、模型檢查點，以及資料處理和評估程式碼，以利進一步的研究。</paragraph>

##### **BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**
2406.06786v2 by June-Woo Kim, Miika Toikkanen, Yera Choi, Seoung-Eun Moon, Ho-Young Jung

Respiratory sound classification (RSC) is challenging due to varied acoustic
signatures, primarily influenced by patient demographics and recording
environments. To address this issue, we introduce a text-audio multimodal model
that utilizes metadata of respiratory sounds, which provides useful
complementary information for RSC. Specifically, we fine-tune a pretrained
text-audio multimodal model using free-text descriptions derived from the sound
samples' metadata which includes the gender and age of patients, type of
recording devices, and recording location on the patient's body. Our method
achieves state-of-the-art performance on the ICBHI dataset, surpassing the
previous best result by a notable margin of 1.17%. This result validates the
effectiveness of leveraging metadata and respiratory sound samples in enhancing
RSC performance. Additionally, we investigate the model performance in the case
where metadata is partially unavailable, which may occur in real-world clinical
setting.

摘要：呼吸音分類 (RSC) 由於不同的聲學特徵而具有挑戰性，主要受患者人口統計資料和錄音環境影響。為了解決此問題，我們引入一個文本音訊多模態模型，它利用呼吸音的元資料，提供有用的補充資訊以進行 RSC。具體來說，我們使用從音訊範例元資料中衍生的自由文字描述，微調預先訓練好的文本音訊多模態模型，其中包括患者的性別和年齡、錄音裝置類型以及患者身體上的錄音位置。我們的模型在 ICBHI 資料集上取得了最先進的效能，以 1.17% 的顯著幅度超越了先前的最佳結果。此結果驗證了利用元資料和呼吸音範例來增強 RSC 效能的有效性。此外，我們探討了在元資料部分不可用的情況下模型效能，這可能會發生在現實世界的臨床環境中。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Merlin: A Vision Language Foundation Model for 3D Computed Tomography**
2406.06512v1 by Louis Blankemeier, Joseph Paul Cohen, Ashwin Kumar, Dave Van Veen, Syed Jamal Safdar Gardezi, Magdalini Paschali, Zhihong Chen, Jean-Benoit Delbrouck, Eduardo Reis, Cesar Truyts, Christian Bluethgen, Malte Engmann Kjeldskov Jensen, Sophie Ostmeier, Maya Varma, Jeya Maria Jose Valanarasu, Zhongnan Fang, Zepeng Huo, Zaid Nabulsi, Diego Ardila, Wei-Hung Weng, Edson Amaro Junior, Neera Ahuja, Jason Fries, Nigam H. Shah, Andrew Johnston, Robert D. Boutin, Andrew Wentland, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, Akshay S. Chaudhari

Over 85 million computed tomography (CT) scans are performed annually in the
US, of which approximately one quarter focus on the abdomen. Given the current
radiologist shortage, there is a large impetus to use artificial intelligence
to alleviate the burden of interpreting these complex imaging studies. Prior
state-of-the-art approaches for automated medical image interpretation leverage
vision language models (VLMs). However, current medical VLMs are generally
limited to 2D images and short reports, and do not leverage electronic health
record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train
using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes
(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate
Merlin on 6 task types and 752 individual tasks. The non-adapted
(off-the-shelf) tasks include zero-shot findings classification (31 findings),
phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval
(image to findings and image to impressions), while model adapted tasks include
5-year disease prediction (6 diseases), radiology report generation, and 3D
semantic segmentation (20 organs). We perform internal validation on a test set
of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public
CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant
evaluations, we assess the efficacy of various network architectures and
training strategies to depict that Merlin has favorable performance to existing
task-specific baselines. We derive data scaling laws to empirically assess
training data needs for requisite downstream task performance. Furthermore,
unlike conventional VLMs that require hundreds of GPUs for training, we perform
all training on a single GPU.

摘要：<paragraph>美國每年執行超過 8500 萬次電腦斷層掃描 (CT)，其中約四分之一針對腹部。鑑於目前放射科醫師短缺，因此有很大的動力使用人工智慧來減輕詮釋這些複雜影像研究的負擔。先前自動化醫學影像詮釋的最新方法利用視覺語言模型 (VLM)。然而，目前的醫學 VLM 通常僅限於 2D 影像和簡短報告，而且不會利用電子健康紀錄 (EHR) 資料進行監督。我們介紹 Merlin，這是一個 3D VLM，我們使用配對的 CT 掃描（來自 15,331 個 CT 的 600 多萬張影像）、EHR 診斷碼（180 多萬個碼）和放射科報告（600 多萬個代碼）來訓練它。我們在 6 個任務類型和 752 個個別任務上評估 Merlin。非適應型（現成的）任務包括零次學習結果分類（31 個結果）、表型分類（692 個表型）和零次學習跨模態檢索（影像到結果和影像到印象），而模型適應任務包括 5 年疾病預測（6 種疾病）、放射科報告產生和 3D 語意分割（20 個器官）。我們在 5,137 個 CT 的測試集上執行內部驗證，並在 7,000 個臨床 CT 和兩個公開 CT 資料集（VerSe、TotalSegmentator）上執行外部驗證。除了這些與臨床相關的評估之外，我們還評估各種網路架構和訓練策略的效能，以說明 Merlin 在現有的特定任務基線上具有良好的效能。我們推導出資料擴充法則，以根據經驗評估下游任務效能所需的訓練資料需求。此外，與需要數百個 GPU 才能進行訓練的傳統 VLM 不同，我們在單一 GPU 上執行所有訓練。</paragraph>

##### **Towards a Personal Health Large Language Model**
2406.06474v1 by Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean

In health, most large language model (LLM) research has focused on clinical
tasks. However, mobile and wearable devices, which are rarely integrated into
such tasks, provide rich, longitudinal data for personal health monitoring.
Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from
Gemini for understanding and reasoning over numerical time-series personal
health data. We created and curated three datasets that test 1) production of
personalized insights and recommendations from sleep patterns, physical
activity, and physiological responses, 2) expert domain knowledge, and 3)
prediction of self-reported sleep outcomes. For the first task we designed 857
case studies in collaboration with domain experts to assess real-world
scenarios in sleep and fitness. Through comprehensive evaluation of
domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not
statistically different from expert performance in fitness and, while experts
remain superior for sleep, fine-tuning PH-LLM provided significant improvements
in using relevant domain knowledge and personalizing information for sleep
insights. We evaluated PH-LLM domain knowledge using multiple choice sleep
medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on
fitness, exceeding average scores from a sample of human experts. Finally, we
trained PH-LLM to predict self-reported sleep quality outcomes from textual and
multimodal encoding representations of wearable data, and demonstrate that
multimodal encoding is required to match performance of specialized
discriminative models. Although further development and evaluation are
necessary in the safety-critical personal health domain, these results
demonstrate both the broad knowledge and capabilities of Gemini models and the
benefit of contextualizing physiological data for personal health applications
as done with PH-LLM.

摘要：在健康領域，大多數大型語言模型 (LLM) 研究都專注於臨床任務。然而，行動裝置和穿戴式裝置很少整合到此類任務中，但它們會提供豐富的縱向資料，用於個人健康監控。在這裡，我們提出個人健康大型語言模型 (PH-LLM)，經過 Gemini 微調，用於理解和推理數值時間序列個人健康資料。我們建立並策劃了三個測試資料集，用於測試 1) 從睡眠模式、身體活動和生理反應中產生個人化見解和建議，2) 專家領域知識，以及 3) 預測自我報告的睡眠結果。對於第一個任務，我們與領域專家合作設計了 857 個案例研究，以評估睡眠和健身的真實情況。透過對特定領域評分標準的全面評估，我們觀察到 Gemini Ultra 1.0 和 PH-LLM 在健身方面的表現與專家表現沒有統計學差異，而專家在睡眠方面的表現仍然較佳，但微調 PH-LLM 在使用相關領域知識和個人化睡眠見解資訊方面提供了顯著改進。我們使用多選題睡眠醫學和健身檢查評估 PH-LLM 領域知識。PH-LLM 在睡眠方面達到 79%，在健身方面達到 88%，超過了部分人類專家的平均分數。最後，我們訓練 PH-LLM 從可穿戴資料的文字和多模態編碼表示中預測自我報告的睡眠品質結果，並證明多模態編碼對於匹配特殊辨別模型的效能是必要的。儘管在安全關鍵的個人健康領域中需要進一步的開發和評估，但這些結果證明了 Gemini 模型的廣泛知識和功能，以及使用 PH-LLM 對生理資料進行情境化以用於個人健康應用程式的優點。

##### **Transforming Wearable Data into Health Insights using Large Language Model Agents**
2406.06464v2 by Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, Kumar Ayush, Hao-Wei Su, Qian He, Cory Y. McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu

Despite the proliferation of wearable health trackers and the importance of
sleep and exercise to health, deriving actionable personalized insights from
wearable data remains a challenge because doing so requires non-trivial
open-ended analysis of these data. The recent rise of large language model
(LLM) agents, which can use tools to reason about and interact with the world,
presents a promising opportunity to enable such personalized analysis at scale.
Yet, the application of LLM agents in analyzing personal health is still
largely untapped. In this paper, we introduce the Personal Health Insights
Agent (PHIA), an agent system that leverages state-of-the-art code generation
and information retrieval tools to analyze and interpret behavioral health data
from wearables. We curate two benchmark question-answering datasets of over
4000 health insights questions. Based on 650 hours of human and expert
evaluation we find that PHIA can accurately address over 84% of factual
numerical questions and more than 83% of crowd-sourced open-ended questions.
This work has implications for advancing behavioral health across the
population, potentially enabling individuals to interpret their own wearable
data, and paving the way for a new era of accessible, personalized wellness
regimens that are informed by data-driven insights.

摘要：儘管穿戴式健康追蹤器大量普及，且睡眠和運動對健康至關重要，但從穿戴式資料中衍生出可操作的個人化見解仍然是一項挑戰，因為這樣做需要對這些資料進行非平凡的開放式分析。大型語言模型 (LLM) 代理程式近來崛起，它可以使用工具對世界進行推理和互動，提供了大規模啟用此類個人化分析的絕佳機會。然而，LLM 代理程式在分析個人健康方面的應用仍未得到充分開發。在本文中，我們介紹了個人健康見解代理程式 (PHIA)，這是一個代理系統，它利用最先進的程式碼生成和資訊檢索工具來分析和詮釋來自穿戴式裝置的行為健康資料。我們整理了兩個基准問答資料集，其中包含超過 4000 個健康見解問題。根據 650 小時的人類和專家評估，我們發現 PHIA 能夠準確回答超過 84% 的事實性數字問題和超過 83% 的群眾外包開放式問題。這項工作對促進全體人口的行為健康具有影響，潛在地使個人能夠詮釋自己的穿戴式資料，並為一個由資料驅動的見解所告知的可存取、個人化健康養生法的新時代鋪路。

##### **A Large Language Model Pipeline for Breast Cancer Oncology**
2406.06455v2 by Tristen Pool, Dennis Trujillo

Large language models (LLMs) have demonstrated potential in the innovation of
many disciplines. However, how they can best be developed for oncology remains
underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical
dataset and clinical guidelines text corpus for two important cancer treatment
factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain
prompt engineering pipeline. A high accuracy (0.85+) was achieved in the
classification of adjuvant radiation therapy and chemotherapy for breast cancer
patients. Furthermore, a confidence interval was formed from observational data
on the quality of treatment from human oncologists to estimate the proportion
of scenarios in which the model must outperform the original oncologist in its
treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to
indeterminacy in the outcomes of cancer treatment decisions, future
investigation, potentially a clinical trial, would be required to determine if
this threshold was met by the models. Nevertheless, with 85% of U.S. cancer
patients receiving treatment at local community facilities, these kinds of
models could play an important part in expanding access to quality care with
outcomes that lie, at minimum, close to a human oncologist.

摘要：大型語言模型 (LLM) 已展示出在許多學科創新方面的潛力。然而，如何才能最佳開發它們以應用於腫瘤學仍未成熟。最先進的 OpenAI 模型經過微調，針對臨床數據集和臨床指南文本語料庫，使用新穎的 Langchain 提示工程管道，針對兩個重要的癌症治療因素，輔助放射治療和化療。在乳腺癌患者的輔助放射治療和化療分類中，達到了很高的準確度 (0.85+)。此外，根據人類腫瘤學家對治療品質的觀察數據形成了一個信心區間，以估計模型必須在其治療預測中優於原始腫瘤學家的情境比例，才能整體上成為更好的解決方案，為 8.2% 至 13.3%。由於癌症治療決策結果的不確定性，需要進一步調查，可能是臨床試驗，以確定模型是否達到此門檻。儘管如此，由於 85% 的美國癌症患者在當地社區設施接受治療，這些模型可以在擴大獲得優質照護的機會中扮演重要角色，其結果至少接近人類腫瘤學家。

##### **Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**
2406.06435v1 by Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat

In difficult decision-making scenarios, it is common to have conflicting
opinions among expert human decision-makers as there may not be a single right
answer. Such decisions may be guided by different attributes that can be used
to characterize an individual's decision. We introduce a novel dataset for
medical triage decision-making, labeled with a set of decision-maker attributes
(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,
including ethical principles such as fairness and moral desert. We present a
novel software framework for human-aligned decision-making by utilizing these
DMAs, paving the way for trustworthy AI with better guardrails. Specifically,
we demonstrate how large language models (LLMs) can serve as ethical
decision-makers, and how their decisions can be aligned to different DMAs using
zero-shot prompting. Our experiments focus on different open-source models with
varying sizes and training techniques, such as Falcon, Mistral, and Llama 2.
Finally, we also introduce a new form of weighted self-consistency that
improves the overall quantified performance. Our results provide new research
directions in the use of LLMs as alignable decision-makers. The dataset and
open-source software are publicly available at:
https://github.com/ITM-Kitware/llm-alignable-dm.

摘要：在困難的決策情境中，專家人類決策者之間產生相互衝突的意見是很常見的，因為可能沒有單一的正確答案。此類決策可能受到用於描述個人決策的不同屬性的指導。我們引入了一個新穎的醫療分流決策制定資料集，並標記了一組決策者屬性 (DMA)。此資料集包含 62 個情境，涵蓋六個不同的 DMA，包括公平性和道德沙漠等道德原則。我們提出了一個新穎的軟體架構，用於透過利用這些 DMA 進行與人類一致的決策制定，為具有更好護欄的值得信賴的 AI 鋪平道路。具體來說，我們展示了大型語言模型 (LLM) 如何作為道德決策者，以及如何使用零次提示將其決策與不同的 DMA 對齊。我們的實驗重點關注具有不同大小和訓練技術的不同開源模型，例如 Falcon、Mistral 和 Llama 2。最後，我們還引入了一種新的加權自一致性形式，它改進了整體量化效能。我們的結果為 LLM 作為可對齊決策者的使用提供了新的研究方向。資料集和開源軟體可在以下位置公開取得：
https://github.com/ITM-Kitware/llm-alignable-dm。

##### **Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**
2406.06372v1 by Marek Wodzinski, Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling

Modeling and manufacturing of personalized cranial implants are important
research areas that may decrease the waiting time for patients suffering from
cranial damage. The modeling of personalized implants may be partially
automated by the use of deep learning-based methods. However, this task suffers
from difficulties with generalizability into data from previously unseen
distributions that make it difficult to use the research outcomes in real
clinical settings. Due to difficulties with acquiring ground-truth annotations,
different techniques to improve the heterogeneity of datasets used for training
the deep networks have to be considered and introduced. In this work, we
present a large-scale study of several augmentation techniques, varying from
classical geometric transformations, image registration, variational
autoencoders, and generative adversarial networks, to the most recent advances
in latent diffusion models. We show that the use of heavy data augmentation
significantly increases both the quantitative and qualitative outcomes,
resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96
for the SkullFix datasets. Moreover, we show that the synthetically augmented
network successfully reconstructs real clinical defects. The work is a
considerable contribution to the field of artificial intelligence in the
automatic modeling of personalized cranial implants.

摘要：客製化顱骨植入物的建模和製造是重要的研究領域，可能會縮短遭受顱骨損傷患者的等待時間。客製化植入物的建模可以透過使用基於深度學習的方法來部分自動化。然而，此任務會受到先前未見過分佈資料的概括性困難影響，這使得在實際臨床環境中使用研究結果變得困難。由於難以取得地面實況註解，必須考量並引入不同的技術來改善用於訓練深度網路的資料集異質性。在這項工作中，我們提出多種擴充技術的大規模研究，從古典幾何轉換、影像配準、變異自動編碼器和生成對抗網路，到潛在擴散模型的最新進展。我們顯示使用大量資料擴充會顯著增加量化和質化結果，導致 SkullBreak 的平均 Dice 分數高於 0.94，而 SkullFix 資料集則高於 0.96。此外，我們顯示合成擴充網路成功重建真實的臨床缺陷。這項工作為人工智慧在客製化顱骨植入物自動建模領域做出了重大貢獻。

##### **MedExQA: Medical Question Answering Benchmark with Multiple Explanations**
2406.06331v1 by Yunsoo Kim, Jinge Wu, Yusuf Abdulle, Honghan Wu

This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.

摘要：本文介绍了 MedExQA，这是一个医学问答领域的新基准，用于通过解释评估大型语言模型 (LLM) 对医学知识的理解。通过在当前数据集中的五个代表性不足的不同医学专业领域构建数据集，并为每个问题-答案对进一步纳入多个解释，我们解决了当前医学问答基准中的一大缺陷，即缺乏对 LLM 生成细微医学解释的能力的全面评估。我们的工作强调了可解释性在医学 LLM 中的重要性，提出了一种超越分类准确度来评估模型的有效方法，并阐明了一个特定领域，即语言病理学，其中包括 GPT4 在内的当前 LLM 缺乏良好的理解。我们的结果表明，使用多个解释进行生成评估与人类评估更一致，突显了对 LLM 进行更稳健的自动理解评估的机会。为了使开源医学 LLM 多样化（目前主要基于 Llama2），这项工作还提出了一种新的医学模型 MedPhi-2，基于 Phi-2 (2.7B)。该模型在生成解释方面优于基于 Llama2-70B 的医学 LLM，显示了其在资源受限的医学领域的有效性。我们将分享我们的基准数据集和训练好的模型。

##### **BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**
2406.07584v1 by Wanaiu Huang

Semantic information is vital for human interaction, and decoding it from
brain activity enables non-invasive clinical augmentative and alternative
communication. While there has been significant progress in reconstructing
visual images, few studies have focused on the language aspect. To address this
gap, leveraging the powerful capabilities of the decoder-based vision-language
pretrained model CoCa, this paper proposes BrainChat, a simple yet effective
generative framework aimed at rapidly accomplishing semantic information
decoding tasks from brain activity, including fMRI question answering and fMRI
captioning. BrainChat employs the self-supervised approach of Masked Brain
Modeling to encode sparse fMRI data, obtaining a more compact embedding
representation in the latent space. Subsequently, BrainChat bridges the gap
between modalities by applying contrastive loss, resulting in aligned
representations of fMRI, image, and text embeddings. Furthermore, the fMRI
embeddings are mapped to the generative Brain Decoder via cross-attention
layers, where they guide the generation of textual content about fMRI in a
regressive manner by minimizing caption loss. Empirically, BrainChat exceeds
the performance of existing state-of-the-art methods in the fMRI captioning
task and, for the first time, implements fMRI question answering. Additionally,
BrainChat is highly flexible and can achieve high performance without image
data, making it better suited for real-world scenarios with limited data.

摘要：語義資訊對於人類互動至關重要，而從大腦活動中解碼語義資訊則能實現非侵入性的臨床擴增和替代溝通。儘管在重建視覺影像方面已取得顯著進展，但鮮少有研究關注語言面向。為了解決這個落差，本文利用編碼器為基礎的視覺語言預訓練模型 CoCa 的強大功能，提出 BrainChat，這是一個簡單但有效的生成式架構，旨在快速完成大腦活動的語義資訊解碼任務，包括 fMRI 問答和 fMRI 標題。BrainChat 採用遮罩大腦建模的自我監督方法來編碼稀疏的 fMRI 資料，在潛在空間中取得更緊湊的嵌入表示。隨後，BrainChat 透過套用對比損失來彌合模態之間的差距，產生 fMRI、影像和文字嵌入的對齊表示。此外，fMRI 嵌入透過交叉注意力層對應到生成式大腦解碼器，其中它們以遞減方式引導產生有關 fMRI 的文字內容，藉此最小化標題損失。根據經驗，BrainChat 在 fMRI 標題任務中超越現有最先進方法的效能，並首次實作 fMRI 問答。此外，BrainChat 具有高度彈性，且無需影像資料就能達成高效能，使其更適合資料有限的真實世界場景。

##### **A Dual-View Approach to Classifying Radiology Reports by Co-Training**
2406.05995v1 by Yutong Han, Yan Yuan, Lili Mou

Radiology report analysis provides valuable information that can aid with
public health initiatives, and has been attracting increasing attention from
the research community. In this work, we present a novel insight that the
structure of a radiology report (namely, the Findings and Impression sections)
offers different views of a radiology scan. Based on this intuition, we further
propose a co-training approach, where two machine learning models are built
upon the Findings and Impression sections, respectively, and use each other's
information to boost performance with massive unlabeled data in a
semi-supervised manner. We conducted experiments in a public health
surveillance study, and results show that our co-training approach is able to
improve performance using the dual views and surpass competing supervised and
semi-supervised methods.

摘要：放射學報告分析提供有價值的資訊，有助於公共衛生計畫，並已吸引研究社群越來越多的關注。在這項工作中，我們提出一個新的見解，即放射學報告的結構（即「發現」和「印象」部分）提供放射學掃描的不同觀點。基於這個直覺，我們進一步提出一個共同訓練方法，其中兩個機器學習模型分別建立在「發現」和「印象」部分之上，並使用彼此的資訊以大量未標記資料以半監督的方式提升效能。我們在公共衛生監測研究中進行實驗，結果顯示我們的共同訓練方法能夠使用雙重觀點來提升效能，並超越競爭的監督式和半監督式方法。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**
2406.05972v1 by Jingru Jia, Zehua Yuan, Junhao Pan, Paul McNamara, Deming Chen

When making decisions under uncertainty, individuals often deviate from
rational behavior, which can be evaluated across three dimensions: risk
preference, probability weighting, and loss aversion. Given the widespread use
of large language models (LLMs) in decision-making processes, it is crucial to
assess whether their behavior aligns with human norms and ethical expectations
or exhibits potential biases. Several empirical studies have investigated the
rationality and social behavior performance of LLMs, yet their internal
decision-making tendencies and capabilities remain inadequately understood.
This paper proposes a framework, grounded in behavioral economics, to evaluate
the decision-making behaviors of LLMs. Through a multiple-choice-list
experiment, we estimate the degree of risk preference, probability weighting,
and loss aversion in a context-free setting for three commercial LLMs:
ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that
LLMs generally exhibit patterns similar to humans, such as risk aversion and
loss aversion, with a tendency to overweight small probabilities. However,
there are significant variations in the degree to which these behaviors are
expressed across different LLMs. We also explore their behavior when embedded
with socio-demographic features, uncovering significant disparities. For
instance, when modeled with attributes of sexual minority groups or physical
disabilities, Claude-3-Opus displays increased risk aversion, leading to more
conservative choices. These findings underscore the need for careful
consideration of the ethical implications and potential biases in deploying
LLMs in decision-making scenarios. Therefore, this study advocates for
developing standards and guidelines to ensure that LLMs operate within ethical
boundaries while enhancing their utility in complex decision-making
environments.

摘要：<paragraph>在不確定情況下做出決策時，個人通常會偏離理性行為，這可以用三個面向來評估：風險偏好、機率加權和損失規避。鑒於大型語言模型 (LLM) 在決策過程中被廣泛使用，因此評估其行為是否符合人類規範和道德期望或表現出潛在偏見至關重要。多項實證研究調查了 LLM 的理性與社會行為表現，但其內部決策傾向和能力仍未被充分理解。本文提出了一個基於行為經濟學的架構，用於評估 LLM 的決策行為。透過多選題實驗，我們估計了三個商業 LLM：ChatGPT-4.0-Turbo、Claude-3-Opus 和 Gemini-1.0-pro 在無背景設定下的風險偏好、機率加權和損失規避程度。我們的結果顯示，LLM 通常表現出類似於人類的模式，例如風險規避和損失規避，並傾向於高估小機率。然而，這些行為在不同 LLM 中表現的程度存在顯著差異。我們也探討了它們在嵌入社會人口特徵時的行為，發現了顯著的差異。例如，當以性少數群體或身體殘疾的屬性建模時，Claude-3-Opus 會表現出更高的風險規避，導致更保守的選擇。這些發現強調了在決策場景中部署 LLM 時，需要仔細考量其道德意涵和潛在偏見。因此，本研究主張制定標準和準則，以確保 LLM 在道德界限內運作，同時提升其在複雜決策環境中的效用。</paragraph>

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**
2406.05682v1 by Ran Xu, Yiwen Lu, Chang Liu, Yong Chen, Yan Sun, Xiao Hu, Joyce C Ho, Carl Yang

Electronic Health Records (EHRs) contain rich patient information and are
crucial for clinical research and practice. In recent years, deep learning
models have been applied to EHRs, but they often rely on massive features,
which may not be readily available for all patients. We propose HTP-Star, which
leverages hypergraph structures with a pretrain-then-finetune framework for
modeling EHR data, enabling seamless integration of additional features.
Additionally, we design two techniques, namely (1) Smoothness-inducing
Regularization and (2) Group-balanced Reweighting, to enhance the model's
robustness during fine-tuning. Through experiments conducted on two real EHR
datasets, we demonstrate that HTP-Star consistently outperforms various
baselines while striking a balance between patients with basic and extra
features.

摘要：電子健康紀錄 (EHR) 包含豐富的患者資訊，對於臨床研究和實務至關重要。近年來，深度學習模型已應用於 EHR，但它們通常依賴大量特徵，而這些特徵可能並非所有患者都能輕易取得。我們提出 HTP-Star，它利用超圖結構搭配預訓練再微調架構來建模 EHR 資料，讓額外特徵能無縫整合。此外，我們設計了兩種技術，即 (1) 平滑誘導正則化和 (2) 群組平衡重新加權，以增強模型在微調期間的穩健性。透過在兩個真實 EHR 資料集上進行的實驗，我們證明 HTP-Star 在為具有基本和額外特徵的患者取得平衡的同時，始終優於各種基線。

##### **CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**
2406.05631v1 by Sana Ayromlou, Teresa Tsang, Purang Abolmaesumi, Xiaoxiao Li

In real-world clinical settings, traditional deep learning-based
classification methods struggle with diagnosing newly introduced disease types
because they require samples from all disease classes for offline training.
Class incremental learning offers a promising solution by adapting a deep
network trained on specific disease classes to handle new diseases. However,
catastrophic forgetting occurs, decreasing the performance of earlier classes
when adapting the model to new data. Prior proposed methodologies to overcome
this require perpetual storage of previous samples, posing potential practical
concerns regarding privacy and storage regulations in healthcare. To this end,
we propose a novel data-free class incremental learning framework that utilizes
data synthesis on learned classes instead of data storage from previous
classes. Our key contributions include acquiring synthetic data known as
Continual Class-Specific Impression (CCSI) for previously inaccessible trained
classes and presenting a methodology to effectively utilize this data for
updating networks when introducing new classes. We obtain CCSI by employing
data inversion over gradients of the trained classification model on previous
classes starting from the mean image of each class inspired by common landmarks
shared among medical images and utilizing continual normalization layers
statistics as a regularizer in this pixel-wise optimization process.
Subsequently, we update the network by combining the synthesized data with new
class data and incorporate several losses, including an intra-domain
contrastive loss to generalize the deep network trained on the synthesized data
to real data, a margin loss to increase separation among previous classes and
new ones, and a cosine-normalized cross-entropy loss to alleviate the adverse
effects of imbalanced distributions in training data.

摘要：<paragraph>在真實世界臨床環境中，傳統的深度學習分類方法難以診斷新引入的疾病類型，因為它們需要離線訓練所有疾病類別的樣本。類別增量學習提供了一個有前途的解決方案，通過調整在特定疾病類別上訓練的深度網路來處理新疾病。然而，會發生災難性遺忘，在將模型調整到新數據時降低早期類別的性能。先前提出的克服此問題的方法論需要持續儲存先前的樣本，對醫療保健中的隱私和儲存法規造成潛在的實際問題。為此，我們提出一個新穎的無數據類別增量學習框架，利用已學習類別的數據合成，而不是先前類別的數據儲存。我們的關鍵貢獻包括獲取合成數據，稱為連續類別特定印象 (CCSI)，用於先前無法存取的已訓練類別，並提出一個方法論，在引入新類別時有效地利用此數據來更新網路。我們通過對先前類別的訓練分類模型的梯度進行數據反演來獲取 CCSI，從每個類別的平均影像開始，靈感來自醫學影像中共享的共同地標，並利用連續正規化層統計作為此逐像素最佳化過程中的正則化器。隨後，我們通過將合成數據與新類別數據結合來更新網路，並結合多種損失，包括域內對比損失，以將在合成數據上訓練的深度網路推廣到真實數據，邊際損失以增加先前類別和新類別之間的分離，以及餘弦正規化交叉熵損失以減輕訓練數據中不平衡分佈的不利影響。</paragraph>

##### **Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**
2406.05612v1 by Pranav Jeevan, Amit Sethi

In contemporary computer vision applications, particularly image
classification, architectural backbones pre-trained on large datasets like
ImageNet are commonly employed as feature extractors. Despite the widespread
use of these pre-trained convolutional neural networks (CNNs), there remains a
gap in understanding the performance of various resource-efficient backbones
across diverse domains and dataset sizes. Our study systematically evaluates
multiple lightweight, pre-trained CNN backbones under consistent training
settings across a variety of datasets, including natural images, medical
images, galaxy images, and remote sensing images. This comprehensive analysis
aims to aid machine learning practitioners in selecting the most suitable
backbone for their specific problem, especially in scenarios involving small
datasets where fine-tuning a pre-trained network is crucial. Even though
attention-based architectures are gaining popularity, we observed that they
tend to perform poorly under low data finetuning tasks compared to CNNs. We
also observed that some CNN architectures such as ConvNeXt, RegNet and
EfficientNet performs well compared to others on a diverse set of domains
consistently. Our findings provide actionable insights into the performance
trade-offs and effectiveness of different backbones, facilitating informed
decision-making in model selection for a broad spectrum of computer vision
domains. Our code is available here: https://github.com/pranavphoenix/Backbones

摘要：<paragraph>在當代電腦視覺應用中，特別是影像分類，預先在大型資料集（例如 ImageNet）上訓練的架構主幹通常用作特徵萃取器。儘管廣泛使用這些預先訓練的卷積神經網路 (CNN)，但對於各種資源效率主幹在不同網域和資料集大小上的效能仍缺乏了解。我們的研究系統性地評估多個輕量級、預先訓練的 CNN 主幹，在各種資料集（包括自然影像、醫學影像、星系影像和遙測影像）上採用一致的訓練設定。這項全面的分析旨在協助機器學習從業人員為其特定問題選擇最合適的主幹，特別是在涉及小型資料集的情況下，其中微調預先訓練的網路至關重要。儘管基於注意力的架構越來越受歡迎，但我們觀察到，與 CNN 相比，它們在低資料量微調任務中的表現往往較差。我們還觀察到，與其他架構相比，某些 CNN 架構（例如 ConvNeXt、RegNet 和 EfficientNet）在各種網域上表現良好且一致。我們的研究結果提供了可操作的見解，說明不同主幹的效能取捨和有效性，有助於在廣泛的電腦視覺網域中進行模型選擇的明智決策。我們的程式碼可在此取得：https://github.com/pranavphoenix/Backbones</paragraph>

##### **I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**
2406.05505v1 by Mohit Kumar Singh, Georgina Cosma, Patrick Waterson, Jonathan Back, Gyuchan Thomas Jun

Maternity care is a complex system involving treatments and interactions
between patients, providers, and the care environment. To improve patient
safety and outcomes, understanding the human factors (e.g. individuals
decisions, local facilities) influencing healthcare delivery is crucial.
However, most current tools for analysing healthcare data focus only on
biomedical concepts (e.g. health conditions, procedures and tests), overlooking
the importance of human factors. We developed a new approach called I-SIRch,
using artificial intelligence to automatically identify and label human factors
concepts in maternity healthcare investigation reports describing adverse
maternity incidents produced by England's Healthcare Safety Investigation
Branch (HSIB). These incident investigation reports aim to identify
opportunities for learning and improving maternal safety across the entire
healthcare system. I-SIRch was trained using real data and tested on both real
and simulated data to evaluate its performance in identifying human factors
concepts. When applied to real reports, the model achieved a high level of
accuracy, correctly identifying relevant concepts in 90\% of the sentences from
97 reports. Applying I-SIRch to analyse these reports revealed that certain
human factors disproportionately affected mothers from different ethnic groups.
Our work demonstrates the potential of using automated tools to identify human
factors concepts in maternity incident investigation reports, rather than
focusing solely on biomedical concepts. This approach opens up new
possibilities for understanding the complex interplay between social,
technical, and organisational factors influencing maternal safety and
population health outcomes. By taking a more comprehensive view of maternal
healthcare delivery, we can develop targeted interventions to address
disparities and improve maternal outcomes.

摘要：產科照護是一個複雜的系統，涉及患者、提供者和照護環境之間的治療和互動。為了改善患者安全和照護結果，了解影響醫療保健服務的人為因素（例如個人決策、當地設施）至關重要。然而，目前大多數用於分析醫療保健資料的工具只關注生物醫學概念（例如健康狀況、程序和檢驗），而忽略了人為因素的重要性。我們開發了一種稱為 I-SIRch 的新方法，利用人工智慧自動識別和標記英國醫療安全調查部門 (HSIB) 產生的描述不良產科事件的產科醫療保健調查報告中的人為因素概念。這些事件調查報告旨在找出機會，以學習並改善整個醫療保健系統中的產婦安全。I-SIRch 使用真實資料進行訓練，並在真實和模擬資料上進行測試，以評估其在識別人為因素概念方面的表現。當應用於真實報告時，該模型達到了很高的準確度，在 97 份報告的 90% 的句子中正確識別了相關概念。將 I-SIRch 應用於分析這些報告顯示，某些人為因素對不同種族群體的母親產生了不成比例的影響。我們的研究證明了使用自動化工具來識別人為因素概念在產科事件調查報告中的潛力，而不是僅關注生物醫學概念。這種方法為理解影響產婦安全和人口健康結果的社會、技術和組織因素之間的複雜相互作用開闢了新的可能性。通過更全面地了解產科醫療保健服務，我們可以制定有針對性的干預措施來解決差異並改善產婦結果。

##### **DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**
2406.05307v1 by Miriam Farrington

FDA Medical Device recalls are critical and time-sensitive events, requiring
swift identification of impacted devices to inform the public of a recall event
and ensure patient safety. The OpenFDA device recall dataset contains valuable
information about ongoing device recall actions, but manually extracting
relevant device information from the recall action summaries is a
time-consuming task. Named Entity Recognition (NER) is a task in Natural
Language Processing (NLP) that involves identifying and categorizing named
entities in unstructured text. Existing NER models, including domain-specific
models like BioBERT, struggle to correctly identify medical device trade names,
part numbers and component terms within these summaries. To address this, we
propose DeviceBERT, a medical device annotation, pre-processing and enrichment
pipeline, which builds on BioBERT to identify and label medical device
terminology in the device recall summaries with improved accuracy. Furthermore,
we demonstrate that our approach can be applied effectively for performing
entity recognition tasks where training data is limited or sparse.

摘要：食品藥物管理局醫療器材召回是關鍵且時間敏感的事件，需要迅速找出受影響的器材，以告知大眾召回事件並確保病患安全。OpenFDA 器材召回資料集包含有關持續進行器材召回行動的寶貴資訊，但手動從召回行動摘要中擷取相關器材資訊是一項耗時的任務。命名實體辨識 (NER) 是自然語言處理 (NLP) 中的一項任務，涉及在非結構化文字中辨識和分類命名實體。現有的 NER 模型（包括像 BioBERT 這類特定領域模型）難以正確辨識這些摘要中的醫療器材商品名、零件編號和組成術語。為了解決這個問題，我們提出 DeviceBERT，這是一個醫療器材註解、前處理和豐富處理管線，它建構於 BioBERT 之上，以更高的準確度辨識和標記器材召回摘要中的醫療器材術語。此外，我們證明我們的做法可以有效應用於執行訓練資料受限或稀疏的實體辨識任務。

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**
2406.05189v1 by Jorden Lam, Kunpeng Xu

The paper investigates the escalating concerns surrounding the surge in
diabetes cases, exacerbated by the COVID-19 pandemic, and the subsequent strain
on medical resources. The research aims to construct a predictive model
quantifying factors influencing inpatient hospital stay durations for diabetes
patients, offering insights to hospital administrators for improved patient
management strategies. The literature review highlights the increasing
prevalence of diabetes, emphasizing the need for continued attention and
analysis of urban-rural disparities in healthcare access. International studies
underscore the financial implications and healthcare burden associated with
diabetes-related hospitalizations and complications, emphasizing the
significance of effective management strategies. The methodology involves a
quantitative approach, utilizing a dataset comprising 10,000 observations of
diabetic inpatient encounters in U.S. hospitals from 1999 to 2008. Predictive
modeling techniques, particularly Generalized Linear Models (GLM), are employed
to develop a model predicting hospital stay durations based on patient
demographics, admission types, medical history, and treatment regimen. The
results highlight the influence of age, medical history, and treatment regimen
on hospital stay durations for diabetes patients. Despite model limitations,
such as heteroscedasticity and deviations from normality in residual analysis,
the findings offer valuable insights for hospital administrators in patient
management. The paper concludes with recommendations for future research to
address model limitations and explore the implications of predictive models on
healthcare management strategies, ensuring equitable patient care and resource
allocation.

摘要：本文探討了糖尿病病例激增引發的日益嚴重的問題，而 COVID-19 大流行使問題更加惡化，並對醫療資源造成後續負擔。本研究旨在建構一個預測模型，量化影響糖尿病患者住院天數的因素，並提供見解給醫院管理員，以改善病患管理策略。文獻回顧強調了糖尿病患病率的上升，並強調需要持續關注和分析城鄉之間在醫療保健取得方面的差異。國際研究強調了與糖尿病相關的住院和併發症所帶來的財務影響和醫療負擔，並強調了有效管理策略的重要性。方法涉及一種量化方法，利用一個資料集，其中包含了 1999 年至 2008 年間美國醫院中 10,000 筆糖尿病住院患者的觀察結果。預測模型技術，尤其是廣義線性模型 (GLM)，被用於開發一個模型，根據患者人口統計資料、入院類型、病史和治療方案來預測住院天數。結果重點說明了年齡、病史和治療方案對糖尿病患者住院天數的影響。儘管模型有其限制，例如殘差分析中的異質變異數和常態分佈偏差，但研究結果仍為醫院管理員在病患管理方面提供了寶貴的見解。本文最後提出了未來研究建議，以解決模型限制並探討預測模型對醫療管理策略的影響，確保公平的病患照護和資源分配。

##### **Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**
2406.05002v1 by Deepa Tilwani, Christian O'Reilly

The study of effective connectivity (EC) is essential in understanding how
the brain integrates and responds to various sensory inputs. Model-driven
estimation of EC is a powerful approach that requires estimating global and
local parameters of a generative model of neural activity. Insights gathered
through this process can be used in various applications, such as studying
neurodevelopmental disorders. However, accurately determining EC through
generative models remains a significant challenge due to the complexity of
brain dynamics and the inherent noise in neural recordings, e.g., in
electroencephalography (EEG). Current model-driven methods to study EC are
computationally complex and cannot scale to all brain regions as required by
whole-brain analyses. To facilitate EC assessment, an inference algorithm must
exhibit reliable prediction of parameters in the presence of noise. Further,
the relationship between the model parameters and the neural recordings must be
learnable. To progress toward these objectives, we benchmarked the performance
of a Bi-LSTM model for parameter inference from the Jansen-Rit neural mass
model (JR-NMM) simulated EEG under various noise conditions. Additionally, our
study explores how the JR-NMM reacts to changes in key biological parameters
(i.e., sensitivity analysis) like synaptic gains and time constants, a crucial
step in understanding the connection between neural mechanisms and observed
brain activity. Our results indicate that we can predict the local JR-NMM
parameters from EEG, supporting the feasibility of our deep-learning-based
inference approach. In future work, we plan to extend this framework to
estimate local and global parameters from real EEG in clinically relevant
applications.

摘要：有效连通性 (EC) 的研究对于理解大脑如何整合和响应各种感官输入至关重要。EC 的模型驱动估计是一种强大的方法，需要估计神经活动生成模型的全局和局部参数。通过此过程收集的见解可用于各种应用中，例如研究神经发育障碍。然而，由于大脑动力学复杂且神经记录中固有噪声（例如脑电图 (EEG) 中的噪声），通过生成模型准确确定 EC 仍然是一项重大挑战。当前用于研究 EC 的模型驱动方法计算复杂，并且无法扩展到全脑分析所需的所有大脑区域。为了促进 EC 评估，推理算法必须在存在噪声的情况下对参数进行可靠预测。此外，模型参数与神经记录之间的关系必须是可学习的。为了实现这些目标，我们对双向 LSTM 模型在各种噪声条件下从 Jansen-Rit 神经质量模型 (JR-NMM) 模拟脑电图中进行参数推理的性能进行了基准测试。此外，我们的研究探索了 JR-NMM 如何对关键生物学参数（即敏感性分析）的变化做出反应，例如突触增益和时间常数，这是理解神经机制与观察到的脑活动之间联系的关键步骤。我们的结果表明，我们可以从脑电图中预测局部 JR-NMM 参数，从而支持我们基于深度学习的推理方法的可行性。在未来的工作中，我们计划将此框架扩展到从临床相关应用中的真实脑电图估计局部和全局参数。

##### **DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**
2406.06620v1 by Weiqi Zhang, Jiexia Ye, Ziyue Li, Jia Li, Fugee Tsung

The recent rapid development of language models (LMs) has attracted attention
in the field of time series, including multimodal time series modeling.
However, we note that current time series multimodal methods are biased, often
assigning a primary role to one modality while the other assumes a secondary
role. They overlook the mutual benefits and complementary of different
modalities. For example, in seizure diagnosis, relying solely on textual
clinical reports makes it difficult to pinpoint the area and type of the
disease, while electroencephalograms (EEGs) alone cannot provide an accurate
diagnosis without considering the symptoms. In this study, based on the
complementary information mining of time series multimodal data, we propose
DualTime, a Dual-adapter multimodal language model for Time series
representation implementing temporal-primary and textual-primary modeling
simultaneously. By injecting lightweight adaption tokens, the LM pipeline
shared by dual adapters encourages embedding alignment and achieves efficient
fine-tuning. Empirically, our method outperforms state-of-the-art models in
both supervised and unsupervised settings, highlighting the complementary
benefits of different modalities. In addition, we conduct few-shot label
transfer experiments, which further verifies the transferability and
expressiveness of our proposed DualTime.

摘要：近期語言模型 (LM) 的快速發展，吸引了時間序列領域的關注，包括多模態時間序列建模。然而，我們注意到目前的時間序列多模態方法有偏見，通常將主要角色分配給一種模態，而另一種則扮演次要角色。它們忽視了不同模態的互惠利益和互補性。例如，在癲癇診斷中，僅依賴文字臨床報告很難精確指出疾病的區域和類型，而單獨的腦電圖 (EEG) 在不考慮症狀的情況下無法提供準確的診斷。在本研究中，基於時間序列多模態資料的互補資訊探勘，我們提出了 DualTime，一種用於時間序列表示的雙適配器多模態語言模型，同時實作時間優先和文字優先建模。透過注入輕量級適應權杖，由雙適配器共用的 LM 管線鼓勵嵌入對齊，並實現有效率的微調。根據經驗，我們的模型在監督式和非監督式設定中都優於最先進的模型，突顯了不同模態的互補優勢。此外，我們進行了小樣本標籤轉移實驗，進一步驗證了我們提出的 DualTime 的可轉移性和表達能力。

##### **CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**
2406.04940v1 by Matthew Fortier, Mats L. Richter, Oliver Sonnentag, Chris Pal

Terrestrial carbon fluxes provide vital information about our biosphere's
health and its capacity to absorb anthropogenic CO$_2$ emissions. The
importance of predicting carbon fluxes has led to the emerging field of
data-driven carbon flux modelling (DDCFM), which uses statistical techniques to
predict carbon fluxes from biophysical data. However, the field lacks a
standardized dataset to promote comparisons between models. To address this
gap, we present CarbonSense, the first machine learning-ready dataset for
DDCFM. CarbonSense integrates measured carbon fluxes, meteorological
predictors, and satellite imagery from 385 locations across the globe, offering
comprehensive coverage and facilitating robust model training. Additionally, we
provide a baseline model using a current state-of-the-art DDCFM approach and a
novel transformer based model. Our experiments illustrate the potential gains
that multimodal deep learning techniques can bring to this domain. By providing
these resources, we aim to lower the barrier to entry for other deep learning
researchers to develop new models and drive new advances in carbon flux
modelling.

摘要：陸地碳通量提供我們生物圈健康和吸收人為 CO$_2$ 排放的能力的重要資訊。預測碳通量的重要性導致資料驅動碳通量建模 (DDCFM) 新興領域的出現，它使用統計技術從生物物理資料預測碳通量。然而，該領域缺乏標準化資料集來促進模型之間的比較。為了解決這個差距，我們提出 CarbonSense，這是第一個適用於 DDCFM 的機器學習準備資料集。CarbonSense 整合了來自全球 385 個地點的測量碳通量、氣象預測因子和衛星影像，提供全面的涵蓋範圍並促進穩健的模型訓練。此外，我們使用當前最先進的 DDCFM 方法和基於新穎Transformer的模型提供基準模型。我們的實驗說明了多模態深度學習技術可以為這個領域帶來的潛在收益。透過提供這些資源，我們旨在降低其他深度學習研究人員進入門檻，以開發新模型並推動碳通量建模的新進展。

##### **PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**
2406.06618v1 by Shuo Yu, Feng Xia, Yueru Wang, Shihao Li, Falih Febrinanto, Madhu Chetty

COVID-19 as a global pandemic causes a massive disruption to social stability
that threatens human life and the economy. Policymakers and all elements of
society must deliver measurable actions based on the pandemic's severity to
minimize the detrimental impact of COVID-19. A proper forecasting system is
arguably important to provide an early signal of the risk of COVID-19 infection
so that the authorities are ready to protect the people from the worst.
However, making a good forecasting model for infection risks in different
cities or regions is not an easy task, because it has a lot of influential
factors that are difficult to be identified manually. To address the current
limitations, we propose a deep graph learning model, called PANDORA, to predict
the infection risks of COVID-19, by considering all essential factors and
integrating them into a geographical network. The framework uses geographical
position relations and transportation frequency as higher-order structural
properties formulated by higher-order network structures (i.e., network
motifs). Moreover, four significant node attributes (i.e., multiple features of
a particular area, including climate, medical condition, economy, and human
mobility) are also considered. We propose three different aggregators to better
aggregate node attributes and structural features, namely, Hadamard, Summation,
and Connection. Experimental results over real data show that PANDORA
outperforms the baseline method with higher accuracy and faster convergence
speed, no matter which aggregator is chosen. We believe that PANDORA using deep
graph learning provides a promising approach to get superior performance in
infection risk level forecasting and help humans battle the COVID-19 crisis.

摘要：COVID-19 作為全球大流行病對社會穩定造成大規模的破壞，威脅到人類生命和經濟。政策制定者和社會各階層必須根據疫情的嚴重程度採取可衡量的行動，以將 COVID-19 的不利影響降到最低。一個適當的預測系統無疑對於提供 COVID-19 感染風險的早期信號非常重要，以便當局做好準備保護人民免於最壞的狀況。然而，為不同城市或地區的感染風險建立一個良好的預測模型並非易事，因為它有許多影響因素，難以人工識別。為了解決目前的局限性，我們提出了一個名為 PANDORA 的深度圖學習模型，通過考慮所有必要因素並將它們整合到一個地理網路中，來預測 COVID-19 的感染風險。該框架使用地理位置關係和運輸頻率作為由高階網路結構（即網路主題）制定的高階結構屬性。此外，還考慮了四個重要的節點屬性（即特定區域的氣候、醫療條件、經濟和人類流動性等多種特徵）。我們提出了三個不同的聚合器來更好地聚合節點屬性和結構特徵，即 Hadamard、Summation 和 Connection。在真實資料上的實驗結果表明，無論選擇哪個聚合器，PANDORA 都以更高的準確性和更快的收斂速度優於基線方法。我們相信使用深度圖學習的 PANDORA 提供了一種有前景的方法，可以在感染風險等級預測中獲得卓越的性能，並幫助人類戰勝 COVID-19 危機。

