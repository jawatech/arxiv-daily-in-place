{"2412.15726": {"publish_time": "2024-12-20", "title": "Fine-tuning Whisper on Low-Resource Languages for Real-World Applications", "paper_summary": "This paper presents a new approach to fine-tuning OpenAI's Whisper model for\nlow-resource languages by introducing a novel data generation method that\nconverts sentence-level data into a long-form corpus, using Swiss German as a\ncase study. Non-sentence-level data, which could improve the performance of\nlong-form audio, is difficult to obtain and often restricted by copyright laws.\nOur method bridges this gap by transforming more accessible sentence-level data\ninto a format that preserves the model's ability to handle long-form audio and\nperform segmentation without requiring non-sentence-level data. Our data\ngeneration process improves performance in several real-world applications and\nleads to the development of a new state-of-the-art speech-to-text (STT) model\nfor Swiss German. We compare our model with a non-fine-tuned Whisper and our\nprevious state-of-the-art Swiss German STT models, where our new model achieves\nhigher BLEU scores. Our results also indicate that the proposed method is\nadaptable to other low-resource languages, supported by written guidance and\ncode that allows the creation of fine-tuned Whisper models, which keep\nsegmentation capabilities and allow the transcription of longer audio files\nusing only sentence-level data with high quality.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u5fae\u8abf OpenAI \u7684 Whisper \u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u9069\u7528\u65bc\u8cc7\u6e90\u5331\u4e4f\u7684\u8a9e\u8a00\uff0c\u65b9\u6cd5\u662f\u5f15\u5165\u4e00\u7a2e\u65b0\u7a4e\u7684\u8cc7\u6599\u7522\u751f\u65b9\u6cd5\uff0c\u5c07\u53e5\u5b50\u5c64\u7d1a\u7684\u8cc7\u6599\u8f49\u63db\u70ba\u9577\u7bc7\u8a9e\u6599\u5eab\uff0c\u4e26\u4ee5\u745e\u58eb\u5fb7\u8a9e\u4f5c\u70ba\u6848\u4f8b\u7814\u7a76\u3002\u975e\u53e5\u5b50\u5c64\u7d1a\u7684\u8cc7\u6599\u53ef\u80fd\u6703\u6539\u5584\u9577\u7bc7\u97f3\u8a0a\u7684\u6548\u80fd\uff0c\u4f46\u96e3\u4ee5\u53d6\u5f97\uff0c\u4e14\u901a\u5e38\u53d7\u5230\u8457\u4f5c\u6b0a\u6cd5\u7684\u9650\u5236\u3002\u6211\u5011\u7684\u505a\u6cd5\u900f\u904e\u5c07\u8f03\u5bb9\u6613\u53d6\u5f97\u7684\u53e5\u5b50\u5c64\u7d1a\u8cc7\u6599\u8f49\u63db\u70ba\u4e00\u7a2e\u683c\u5f0f\uff0c\u4f86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u9019\u7a2e\u683c\u5f0f\u80fd\u4fdd\u7559\u6a21\u578b\u8655\u7406\u9577\u7bc7\u97f3\u8a0a\u548c\u57f7\u884c\u5206\u6bb5\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u9700\u8981\u975e\u53e5\u5b50\u5c64\u7d1a\u7684\u8cc7\u6599\u3002\u6211\u5011\u7684\u8cc7\u6599\u7522\u751f\u7a0b\u5e8f\u6539\u5584\u4e86\u591a\u7a2e\u771f\u5be6\u4e16\u754c\u61c9\u7528\u7a0b\u5f0f\u7684\u6548\u80fd\uff0c\u4e26\u5c0e\u81f4\u958b\u767c\u51fa\u4e00\u500b\u65b0\u7684\u745e\u58eb\u5fb7\u8a9e\u8a9e\u97f3\u8f49\u6587\u5b57 (STT) \u6700\u5148\u9032\u6a21\u578b\u3002\u6211\u5011\u5c07\u6211\u5011\u7684\u6a21\u578b\u8207\u672a\u5fae\u8abf\u7684 Whisper \u548c\u6211\u5011\u5148\u524d\u6700\u5148\u9032\u7684\u745e\u58eb\u5fb7\u8a9e STT \u6a21\u578b\u9032\u884c\u6bd4\u8f03\uff0c\u6211\u5011\u7684\u6a21\u578b\u7372\u5f97\u66f4\u9ad8\u7684 BLEU \u5206\u6578\u3002\u6211\u5011\u7684\u7d50\u679c\u9084\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u9069\u7528\u65bc\u5176\u4ed6\u8cc7\u6e90\u5331\u4e4f\u7684\u8a9e\u8a00\uff0c\u4e26\u53d7\u66f8\u9762\u6307\u5357\u548c\u7a0b\u5f0f\u78bc\u652f\u63f4\uff0c\u9019\u4e9b\u6307\u5357\u548c\u7a0b\u5f0f\u78bc\u5141\u8a31\u5efa\u7acb\u5fae\u8abf\u7684 Whisper \u6a21\u578b\uff0c\u9019\u4e9b\u6a21\u578b\u4fdd\u7559\u5206\u6bb5\u529f\u80fd\uff0c\u4e26\u5141\u8a31\u50c5\u4f7f\u7528\u9ad8\u54c1\u8cea\u7684\u53e5\u5b50\u5c64\u7d1a\u8cc7\u6599\u8f49\u9304\u8f03\u9577\u7684\u97f3\u8a0a\u6a94\u6848\u3002", "author": "Vincenzo Timmel et.al.", "authors": "Vincenzo Timmel, Claudio Paonessa, Reza Kakooee, Manfred Vogel, Daniel Perruchoud", "id": "2412.15726v1", "paper_url": "http://arxiv.org/abs/2412.15726v1", "repo": "https://github.com/i4ds/whisper-finetune"}}