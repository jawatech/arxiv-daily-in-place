{"2408.13739": {"publish_time": "2024-08-25", "title": "Literary and Colloquial Tamil Dialect Identification", "paper_summary": "Culture and language evolve together. The old literary form of Tamil is used\ncommonly for writing and the contemporary colloquial Tamil is used for\nspeaking. Human-computer interaction applications require Colloquial Tamil (CT)\nto make it more accessible and easy for the everyday user and, it requires\nLiterary Tamil (LT) when information is needed in a formal written format.\nContinuing the use of LT alongside CT in computer aided language learning\napplications will both preserve LT, and provide ease of use via CT, at the same\ntime. Hence there is a need for the conversion between LT and CT dialects,\nwhich demands as a first step, dialect identification. Dialect Identification\n(DID) of LT and CT is an unexplored area of research. In the current work,\nkeeping the nuances of both these dialects in mind, five methods are explored\nwhich include two implicit methods - Gaussian Mixture Model (GMM) and\nConvolutional Neural Network (CNN); two explicit methods - Parallel Phone\nRecognition (PPR) and Parallel Large Vocabulary Continuous Speech Recognition\n(P-LVCSR); two versions of the proposed explicit Unified Phone Recognition\nmethod (UPR-1 and UPR-2). These methods vary based on: the need for annotated\ndata, the size of the unit, the way in which modelling is carried out, and the\nway in which the final decision is made. Even though the average duration of\nthe test utterances is less - 4.9s for LT and 2.5s for CT - the systems\nperformed well, offering the following identification accuracies: 87.72% (GMM),\n93.97% (CNN), 89.24% (PPR), 94.21% (P-LVCSR), 88.57% (UPR-1), 93.53% (UPR-1\nwith P-LVCSR), 94.55% (UPR-2), and 95.61% (UPR-2 with P-LVCSR).", "paper_summary_zh": "\u6587\u5316\u548c\u8a9e\u8a00\u5171\u540c\u6f14\u5316\u3002\u6cf0\u7c73\u723e\u8a9e\u7684\u820a\u6587\u5b78\u5f62\u5f0f\u901a\u5e38\u7528\u65bc\u5beb\u4f5c\uff0c\u800c\u73fe\u4ee3\u53e3\u8a9e\u6cf0\u7c73\u723e\u8a9e\u5247\u7528\u65bc\u53e3\u8a9e\u3002\u4eba\u6a5f\u4e92\u52d5\u61c9\u7528\u7a0b\u5f0f\u9700\u8981\u53e3\u8a9e\u6cf0\u7c73\u723e\u8a9e (CT)\uff0c\u4ee5\u4f7f\u5176\u66f4\u6613\u65bc\u65e5\u5e38\u4f7f\u7528\u8005\u5b58\u53d6\u548c\u4f7f\u7528\uff0c\u4e26\u4e14\u5728\u9700\u8981\u4ee5\u6b63\u5f0f\u66f8\u9762\u683c\u5f0f\u63d0\u4f9b\u8cc7\u8a0a\u6642\uff0c\u9700\u8981\u4f7f\u7528\u66f8\u9762\u6cf0\u7c73\u723e\u8a9e (LT)\u3002\u5728\u96fb\u8166\u8f14\u52a9\u8a9e\u8a00\u5b78\u7fd2\u61c9\u7528\u7a0b\u5f0f\u4e2d\u6301\u7e8c\u4f7f\u7528 LT \u548c CT\uff0c\u65e2\u53ef\u4ee5\u4fdd\u7559 LT\uff0c\u53c8\u53ef\u4ee5\u900f\u904e CT \u63d0\u4f9b\u6613\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5728 LT \u548c CT \u65b9\u8a00\u4e4b\u9593\u9032\u884c\u8f49\u63db\uff0c\u9019\u9996\u5148\u9700\u8981\u65b9\u8a00\u8b58\u5225\u3002LT \u548c CT \u7684\u65b9\u8a00\u8b58\u5225 (DID) \u662f\u5c1a\u672a\u63a2\u7d22\u7684\u7814\u7a76\u9818\u57df\u3002\u5728\u76ee\u524d\u7684\u5de5\u4f5c\u4e2d\uff0c\u8003\u616e\u5230\u9019\u5169\u7a2e\u65b9\u8a00\u7684\u7d30\u5fae\u5dee\u5225\uff0c\u63a2\u7d22\u4e86\u4e94\u7a2e\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u62ec\u5169\u7a2e\u96b1\u5f0f\u65b9\u6cd5 - \u9ad8\u65af\u6df7\u5408\u6a21\u578b (GMM) \u548c\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN)\uff1b\u5169\u7a2e\u986f\u5f0f\u65b9\u6cd5 - \u5e73\u884c\u97f3\u7d20\u8fa8\u8b58 (PPR) \u548c\u5e73\u884c\u5927\u8a5e\u5f59\u9023\u7e8c\u8a9e\u97f3\u8fa8\u8b58 (P-LVCSR)\uff1b\u5169\u7a2e\u7248\u672c\u7684\u5efa\u8b70\u986f\u5f0f\u7d71\u4e00\u97f3\u7d20\u8fa8\u8b58\u65b9\u6cd5 (UPR-1 \u548c UPR-2)\u3002\u9019\u4e9b\u65b9\u6cd5\u6839\u64da\u4ee5\u4e0b\u689d\u4ef6\u800c\u6709\u6240\u4e0d\u540c\uff1a\u5c0d\u8a3b\u89e3\u8cc7\u6599\u7684\u9700\u6c42\u3001\u55ae\u5143\u7684\u898f\u6a21\u3001\u5efa\u6a21\u7684\u65b9\u5f0f\u4ee5\u53ca\u505a\u51fa\u6700\u7d42\u6c7a\u5b9a\u7684\u65b9\u5f0f\u3002\u5118\u7ba1\u6e2c\u8a66\u8a9e\u53e5\u7684\u5e73\u5747\u6301\u7e8c\u6642\u9593\u8f03\u77ed - LT \u70ba 4.9 \u79d2\uff0cCT \u70ba 2.5 \u79d2 - \u4f46\u7cfb\u7d71\u8868\u73fe\u826f\u597d\uff0c\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u8b58\u5225\u6e96\u78ba\u5ea6\uff1a87.72% (GMM)\u300193.97% (CNN)\u300189.24% (PPR)\u300194.21% (P-LVCSR)\u300188.57% (UPR-1)\u300193.53% (UPR-1 \u8207 P-LVCSR)\u300194.55% (UPR-2) \u548c 95.61% (UPR-2 \u8207 P-LVCSR)\u3002", "author": "M. Nanmalar et.al.", "authors": "M. Nanmalar, P. Vijayalakshmi, T. Nagarajan", "id": "2408.13739v1", "paper_url": "http://arxiv.org/abs/2408.13739v1", "repo": "null"}}