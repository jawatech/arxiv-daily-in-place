{"2410.22689": {"publish_time": "2024-10-30", "title": "Multi-Task Interactive Robot Fleet Learning with Visual World Models", "paper_summary": "Recent advancements in large-scale multi-task robot learning offer the\npotential for deploying robot fleets in household and industrial settings,\nenabling them to perform diverse tasks across various environments. However,\nAI-enabled robots often face challenges with generalization and robustness when\nexposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a\nmulti-task interactive robot fleet learning framework to address these\nchallenges. Sirius-Fleet monitors robot performance during deployment and\ninvolves humans to correct the robot's actions when necessary. We employ a\nvisual world model to predict the outcomes of future actions and build anomaly\npredictors to predict whether they will likely result in anomalies. As the\nrobot autonomy improves, the anomaly predictors automatically adapt their\nprediction criteria, leading to fewer requests for human intervention and\ngradually reducing human workload over time. Evaluations on large-scale\nbenchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task\npolicy performance and monitoring accuracy. We demonstrate Sirius-Fleet's\nperformance in both RoboCasa in simulation and Mutex in the real world, two\ndiverse, large-scale multi-task benchmarks. More information is available on\nthe project website: https://ut-austin-rpl.github.io/sirius-fleet", "paper_summary_zh": "\u5927\u578b\u591a\u4efb\u52a1\u673a\u5668\u4eba\u5b66\u4e60\u7684\u8fd1\u671f\u8fdb\u5c55\u63d0\u4f9b\u4e86\u5728\u5bb6\u5ead\u548c\u5de5\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u673a\u5668\u4eba\u8f66\u961f\u7684\u6f5c\u529b\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u5728\u5404\u79cd\u73af\u5883\u4e2d\u6267\u884c\u4e0d\u540c\u7684\u4efb\u52a1\u3002\u7136\u800c\uff0c\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u673a\u5668\u4eba\u7ecf\u5e38\u9762\u4e34\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u5f53\u66b4\u9732\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u53ef\u53d8\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u65f6\u3002\u6211\u4eec\u5f15\u5165\u4e86 Sirius-Fleet\uff0c\u4e00\u4e2a\u591a\u4efb\u52a1\u4ea4\u4e92\u5f0f\u673a\u5668\u4eba\u8f66\u961f\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002Sirius-Fleet \u5728\u90e8\u7f72\u671f\u95f4\u76d1\u63a7\u673a\u5668\u4eba\u6027\u80fd\uff0c\u5e76\u5728\u5fc5\u8981\u65f6\u8ba9\u4eba\u7c7b\u6765\u7ea0\u6b63\u673a\u5668\u4eba\u7684\u52a8\u4f5c\u3002\u6211\u4eec\u91c7\u7528\u4e86\u4e00\u4e2a\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u6765\u9884\u6d4b\u672a\u6765\u52a8\u4f5c\u7684\u7ed3\u679c\uff0c\u5e76\u6784\u5efa\u5f02\u5e38\u9884\u6d4b\u5668\u6765\u9884\u6d4b\u5b83\u4eec\u662f\u5426\u53ef\u80fd\u5bfc\u81f4\u5f02\u5e38\u3002\u968f\u7740\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u7684\u63d0\u9ad8\uff0c\u5f02\u5e38\u9884\u6d4b\u5668\u4f1a\u81ea\u52a8\u8c03\u6574\u5176\u9884\u6d4b\u6807\u51c6\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u4eba\u7c7b\u5e72\u9884\u7684\u8bf7\u6c42\uff0c\u5e76\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u9010\u6e10\u51cf\u5c11\u4eba\u7c7b\u7684\u5de5\u4f5c\u91cf\u3002\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8bc4\u4f30\u8bc1\u660e\u4e86 Sirius-Fleet \u5728\u63d0\u9ad8\u591a\u4efb\u52a1\u7b56\u7565\u6027\u80fd\u548c\u76d1\u63a7\u51c6\u786e\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u5c55\u793a\u4e86 Sirius-Fleet \u5728\u6a21\u62df\u4e2d\u7684 RoboCasa \u548c\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684 Mutex \u4e2d\u7684\u6027\u80fd\uff0c\u8fd9\u4e24\u4e2a\u5927\u578b\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u5177\u6709\u591a\u6837\u6027\u3002\u66f4\u591a\u4fe1\u606f\u53ef\u5728\u9879\u76ee\u7f51\u7ad9\u4e0a\u627e\u5230\uff1ahttps://ut-austin-rpl.github.io/sirius-fleet", "author": "Huihan Liu et.al.", "authors": "Huihan Liu, Yu Zhang, Vaarij Betala, Evan Zhang, James Liu, Crystal Ding, Yuke Zhu", "id": "2410.22689v1", "paper_url": "http://arxiv.org/abs/2410.22689v1", "repo": "null"}}