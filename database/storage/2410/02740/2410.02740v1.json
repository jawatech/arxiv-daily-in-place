{"2410.02740": {"publish_time": "2024-10-03", "title": "Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models", "paper_summary": "Recent advancements in multimodal models highlight the value of rewritten\ncaptions for improving performance, yet key challenges remain. For example,\nwhile synthetic captions often provide superior quality and image-text\nalignment, it is not clear whether they can fully replace AltTexts: the role of\nsynthetic captions and their interaction with original web-crawled AltTexts in\npre-training is still not well understood. Moreover, different multimodal\nfoundation models may have unique preferences for specific caption formats, but\nefforts to identify the optimal captions for each model remain limited. In this\nwork, we propose a novel, controllable, and scalable captioning pipeline\ndesigned to generate diverse caption formats tailored to various multimodal\nmodels. By examining Short Synthetic Captions (SSC) towards Dense Synthetic\nCaptions (DSC+) as case studies, we systematically explore their effects and\ninteractions with AltTexts across models such as CLIP, multimodal LLMs, and\ndiffusion models. Our findings reveal that a hybrid approach that keeps both\nsynthetic captions and AltTexts can outperform the use of synthetic captions\nalone, improving both alignment and performance, with each model demonstrating\npreferences for particular caption formats. This comprehensive analysis\nprovides valuable insights into optimizing captioning strategies, thereby\nadvancing the pre-training of multimodal foundation models.", "paper_summary_zh": "\u591a\u6a21\u614b\u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\u7a81\u986f\u4e86\u6539\u5beb\u5b57\u5e55\u5728\u63d0\u5347\u6548\u80fd\u65b9\u9762\u7684\u50f9\u503c\uff0c\u4f46\u4ecd\u6709\u91cd\u8981\u7684\u6311\u6230\u5b58\u5728\u3002\u4f8b\u5982\uff0c\u5118\u7ba1\u5408\u6210\u5b57\u5e55\u901a\u5e38\u63d0\u4f9b\u512a\u7570\u7684\u54c1\u8cea\u548c\u5f71\u50cf\u6587\u5b57\u5c0d\u9f4a\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u5b83\u5011\u662f\u5426\u80fd\u5b8c\u5168\u53d6\u4ee3 AltText\uff1a\u5408\u6210\u5b57\u5e55\u7684\u89d2\u8272\u53ca\u5176\u8207\u539f\u59cb\u7db2\u8def\u722c\u53d6\u7684 AltText \u5728\u9810\u8a13\u7df4\u4e2d\u7684\u4e92\u52d5\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u7684\u591a\u6a21\u614b\u57fa\u790e\u6a21\u578b\u53ef\u80fd\u5c0d\u7279\u5b9a\u7684\u5b57\u5e55\u683c\u5f0f\u6709\u7368\u7279\u7684\u504f\u597d\uff0c\u4f46\u627e\u51fa\u6bcf\u500b\u6a21\u578b\u6700\u4f73\u5b57\u5e55\u7684\u52aa\u529b\u4ecd\u7136\u6709\u9650\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u3001\u53ef\u63a7\u4e14\u53ef\u64f4\u5145\u7684\u5b57\u5e55\u8655\u7406\u7a0b\u5e8f\uff0c\u65e8\u5728\u7522\u751f\u91dd\u5c0d\u5404\u7a2e\u591a\u6a21\u614b\u6a21\u578b\u91cf\u8eab\u6253\u9020\u7684\u4e0d\u540c\u5b57\u5e55\u683c\u5f0f\u3002\u900f\u904e\u6aa2\u8996\u7c21\u77ed\u5408\u6210\u5b57\u5e55 (SSC) \u5230\u5bc6\u96c6\u5408\u6210\u5b57\u5e55 (DSC+) \u4f5c\u70ba\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u63a2\u8a0e\u5b83\u5011\u5c0d CLIP\u3001\u591a\u6a21\u614b LLM \u548c\u64f4\u6563\u6a21\u578b\u7b49\u6a21\u578b\u4e2d AltText \u7684\u5f71\u97ff\u548c\u4e92\u52d5\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u4fdd\u7559\u5408\u6210\u5b57\u5e55\u548c AltText \u7684\u6df7\u5408\u65b9\u6cd5\u53ef\u4ee5\u512a\u65bc\u50c5\u4f7f\u7528\u5408\u6210\u5b57\u5e55\uff0c\u540c\u6642\u6539\u5584\u5c0d\u9f4a\u548c\u6548\u80fd\uff0c\u6bcf\u500b\u6a21\u578b\u90fd\u5c55\u73fe\u51fa\u5c0d\u7279\u5b9a\u5b57\u5e55\u683c\u5f0f\u7684\u504f\u597d\u3002\u9019\u9805\u5168\u9762\u7684\u5206\u6790\u63d0\u4f9b\u4e86\u512a\u5316\u5b57\u5e55\u7b56\u7565\u7684\u5bf6\u8cb4\u898b\u89e3\uff0c\u5f9e\u800c\u63a8\u52d5\u591a\u6a21\u614b\u57fa\u790e\u6a21\u578b\u7684\u9810\u8a13\u7df4\u3002", "author": "Zhengfeng Lai et.al.", "authors": "Zhengfeng Lai, Vasileios Saveris, Chen Chen, Hong-You Chen, Haotian Zhang, Bowen Zhang, Juan Lao Tebar, Wenze Hu, Zhe Gan, Peter Grasch, Meng Cao, Yinfei Yang", "id": "2410.02740v1", "paper_url": "http://arxiv.org/abs/2410.02740v1", "repo": "null"}}