{"2406.19292": {"publish_time": "2024-06-27", "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data", "paper_summary": "Recent studies have shown that Large Language Models (LLMs) struggle to\naccurately retrieve information and maintain reasoning capabilities when\nprocessing long-context inputs. To address these limitations, we propose a\nfinetuning approach utilizing a carefully designed synthetic dataset comprising\nnumerical key-value retrieval tasks. Our experiments on models like GPT-3.5\nTurbo and Mistral 7B demonstrate that finetuning LLMs on this dataset\nsignificantly improves LLMs' information retrieval and reasoning capabilities\nin longer-context settings. We present an analysis of the finetuned models,\nillustrating the transfer of skills from synthetic to real task evaluations\n(e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5\nTurbo). We also find that finetuned LLMs' performance on general benchmarks\nremains almost constant while LLMs finetuned on other baseline long-context\naugmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B\nfinetuned on our synthetic data cause no performance drop while other baseline\ndata can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study\nhighlights the potential of finetuning on synthetic data for improving the\nperformance of LLMs on longer-context tasks.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728\u5904\u7406\u957f\u6587\u672c\u8f93\u5165\u65f6\u96be\u4ee5\u51c6\u786e\u5730\u68c0\u7d22\u4fe1\u606f\u5e76\u7ef4\u6301\u63a8\u7406\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5fae\u8c03\u65b9\u6cd5\uff0c\u5229\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u6570\u5b57\u952e\u503c\u68c0\u7d22\u4efb\u52a1\u3002\u6211\u4eec\u5bf9 GPT-3.5 Turbo \u548c Mistral 7B \u7b49\u6a21\u578b\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5bf9 LLM \u8fdb\u884c\u5fae\u8c03\u53ef\u4ee5\u663e\u7740\u63d0\u9ad8 LLM \u5728\u8f83\u957f\u6587\u672c\u73af\u5883\u4e2d\u7684\u4fe1\u606f\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\u3002\u6211\u4eec\u5bf9\u5fae\u8c03\u540e\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u8bf4\u660e\u4e86\u4ece\u5408\u6210\u4efb\u52a1\u5230\u771f\u5b9e\u4efb\u52a1\u8bc4\u4f30\u7684\u6280\u80fd\u8f6c\u79fb\uff08\u4f8b\u5982\uff0c\u5728 GPT-3.5 Turbo \u7684 20 \u4e2a\u6587\u6863 MDQA \u4e2d\uff0c\u5728\u4f4d\u7f6e 10 \u4e0a\u63d0\u9ad8\u4e86 10.5%\uff09\u3002\u6211\u4eec\u8fd8\u53d1\u73b0\uff0c\u5fae\u8c03\u540e\u7684 LLM \u5728\u4e00\u822c\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u51e0\u4e4e\u4fdd\u6301\u4e0d\u53d8\uff0c\u800c\u4f7f\u7528\u5176\u4ed6\u57fa\u7ebf\u957f\u6587\u672c\u589e\u5f3a\u6570\u636e\u5bf9 LLM \u8fdb\u884c\u5fae\u8c03\u53ef\u80fd\u4f1a\u5bfc\u81f4\u51fa\u73b0\u5e7b\u89c9\uff08\u4f8b\u5982\uff0c\u5728 TriviaQA \u4e0a\uff0c\u5728\u6211\u4eec\u7684\u5408\u6210\u6570\u636e\u4e0a\u5fae\u8c03\u7684 Mistral 7B \u4e0d\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u5176\u4ed6\u57fa\u7ebf\u6570\u636e\u4f1a\u5bfc\u81f4\u4e0b\u964d 2.33% \u81f3 6.19%\uff09\u3002\u6211\u4eec\u7684\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u4ee5\u63d0\u9ad8 LLM \u5728\u8f83\u957f\u6587\u672c\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u7684\u6f5c\u529b\u3002</paragraph>", "author": "Zheyang Xiong et.al.", "authors": "Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, Dimitris Papailiopoulos", "id": "2406.19292v1", "paper_url": "http://arxiv.org/abs/2406.19292v1", "repo": "null"}}