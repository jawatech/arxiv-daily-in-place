{"2406.19774": {"publish_time": "2024-06-28", "title": "Direct Preference Knowledge Distillation for Large Language Models", "paper_summary": "In the field of large language models (LLMs), Knowledge Distillation (KD) is\na critical technique for transferring capabilities from teacher models to\nstudent models. However, existing KD methods face limitations and challenges in\ndistillation of LLMs, including efficiency and insufficient measurement\ncapabilities of traditional KL divergence. It is shown that LLMs can serve as\nan implicit reward function, which we define as a supplement to KL divergence.\nIn this work, we propose Direct Preference Knowledge Distillation (DPKD) for\nLLMs. DPKD utilizes distribution divergence to represent the preference loss\nand implicit reward function. We re-formulate KD of LLMs into two stages: first\noptimizing and objective consisting of implicit reward and reverse KL\ndivergence and then improving the preference probability of teacher outputs\nover student outputs. We conducted experiments and analysis on various datasets\nwith LLM parameters ranging from 120M to 13B and demonstrate the broad\napplicability and effectiveness of our DPKD approach. Meanwhile, we prove the\nvalue and effectiveness of the introduced implicit reward and output preference\nin KD through experiments and theoretical analysis. The DPKD method outperforms\nthe baseline method in both output response precision and exact match\npercentage. Code and data are available at https://aka.ms/dpkd.", "paper_summary_zh": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9886\u57df\uff0c\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u662f\u4e00\u79cd\u5c06\u529f\u80fd\u4ece\u6559\u5e08\u6a21\u578b\u8f6c\u79fb\u5230\u5b66\u751f\u6a21\u578b\u7684\u5173\u952e\u6280\u672f\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684 KD \u65b9\u6cd5\u5728 LLM \u7684\u84b8\u998f\u4e2d\u9762\u4e34\u7740\u5c40\u9650\u6027\u548c\u6311\u6218\uff0c\u5305\u62ec\u6548\u7387\u548c\u4f20\u7edf KL \u6563\u5ea6\u7684\u6d4b\u91cf\u80fd\u529b\u4e0d\u8db3\u3002\u7ed3\u679c\u8868\u660e\uff0cLLM \u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u9690\u5f0f\u5956\u52b1\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u5176\u5b9a\u4e49\u4e3a KL \u6563\u5ea6\u7684\u8865\u5145\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u7528\u4e8e LLM \u7684\u76f4\u63a5\u504f\u597d\u77e5\u8bc6\u84b8\u998f (DPKD)\u3002DPKD \u5229\u7528\u5206\u5e03\u6563\u5ea6\u6765\u8868\u793a\u504f\u597d\u635f\u5931\u548c\u9690\u5f0f\u5956\u52b1\u51fd\u6570\u3002\u6211\u4eec\u5c06 LLM \u7684 KD \u91cd\u65b0\u8868\u8ff0\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u4f18\u5316\u7531\u9690\u5f0f\u5956\u52b1\u548c\u53cd\u5411 KL \u6563\u5ea6\u7ec4\u6210\u7684\u76ee\u6807\uff0c\u7136\u540e\u63d0\u9ad8\u6559\u5e08\u8f93\u51fa\u76f8\u5bf9\u4e8e\u5b66\u751f\u8f93\u51fa\u7684\u504f\u597d\u6982\u7387\u3002\u6211\u4eec\u5bf9\u5177\u6709\u4ece 120M \u5230 13B \u7684 LLM \u53c2\u6570\u7684\u5404\u79cd\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5b9e\u9a8c\u548c\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u6211\u4eec DPKD \u65b9\u6cd5\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002\u540c\u65f6\uff0c\u6211\u4eec\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u5f15\u5165\u7684\u9690\u5f0f\u5956\u52b1\u548c\u8f93\u51fa\u504f\u597d\u5728 KD \u4e2d\u7684\u4ef7\u503c\u548c\u6709\u6548\u6027\u3002DPKD \u65b9\u6cd5\u5728\u8f93\u51fa\u54cd\u5e94\u7cbe\u5ea6\u548c\u5b8c\u5168\u5339\u914d\u767e\u5206\u6bd4\u65b9\u9762\u90fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u4ee3\u7801\u548c\u6570\u636e\u53ef\u5728 https://aka.ms/dpkd \u83b7\u5f97\u3002", "author": "Yixing Li et.al.", "authors": "Yixing Li, Yuxian Gu, Li Dong, Dequan Wang, Yu Cheng, Furu Wei", "id": "2406.19774v1", "paper_url": "http://arxiv.org/abs/2406.19774v1", "repo": "null"}}