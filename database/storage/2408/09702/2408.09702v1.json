{"2408.09702": {"publish_time": "2024-08-19", "title": "Photorealistic Object Insertion with Diffusion-Guided Inverse Rendering", "paper_summary": "The correct insertion of virtual objects in images of real-world scenes\nrequires a deep understanding of the scene's lighting, geometry and materials,\nas well as the image formation process. While recent large-scale diffusion\nmodels have shown strong generative and inpainting capabilities, we find that\ncurrent models do not sufficiently \"understand\" the scene shown in a single\npicture to generate consistent lighting effects (shadows, bright reflections,\netc.) while preserving the identity and details of the composited object. We\npropose using a personalized large diffusion model as guidance to a physically\nbased inverse rendering process. Our method recovers scene lighting and\ntone-mapping parameters, allowing the photorealistic composition of arbitrary\nvirtual objects in single frames or videos of indoor or outdoor scenes. Our\nphysically based pipeline further enables automatic materials and tone-mapping\nrefinement.", "paper_summary_zh": "\u8981\u5c07\u865b\u64ec\u7269\u4ef6\u6b63\u78ba\u63d2\u5165\u771f\u5be6\u5834\u666f\u7684\u5f71\u50cf\u4e2d\uff0c\u9700\u8981\u6df1\u5165\u4e86\u89e3\u5834\u666f\u7684\u71c8\u5149\u3001\u5e7e\u4f55\u5f62\u72c0\u548c\u6750\u8cea\uff0c\u4ee5\u53ca\u5f71\u50cf\u5f62\u6210\u904e\u7a0b\u3002\u5118\u7ba1\u6700\u8fd1\u7684\u5927\u578b\u64f4\u6563\u6a21\u578b\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u751f\u6210\u548c\u4fee\u5fa9\u529f\u80fd\uff0c\u6211\u5011\u767c\u73fe\u76ee\u524d\u7684\u6a21\u578b\u4e26\u4e0d\u8db3\u4ee5\u300c\u7406\u89e3\u300d\u55ae\u5f35\u5716\u7247\u4e2d\u986f\u793a\u7684\u5834\u666f\uff0c\u7121\u6cd5\u7522\u751f\u4e00\u81f4\u7684\u71c8\u5149\u6548\u679c\uff08\u9670\u5f71\u3001\u660e\u4eae\u7684\u53cd\u5149\u7b49\uff09\uff0c\u540c\u6642\u4fdd\u7559\u5408\u6210\u7269\u4ef6\u7684\u8eab\u5206\u548c\u7d30\u7bc0\u3002\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u500b\u4eba\u5316\u5927\u578b\u64f4\u6563\u6a21\u578b\u4f5c\u70ba\u6307\u5c0e\uff0c\u9032\u884c\u57fa\u65bc\u7269\u7406\u7684\u53cd\u5411\u6e32\u67d3\u8655\u7406\u3002\u6211\u5011\u7684\u505a\u6cd5\u6703\u9084\u539f\u5834\u666f\u7684\u71c8\u5149\u548c\u8272\u8abf\u5c0d\u61c9\u53c3\u6578\uff0c\u8b93\u865b\u64ec\u7269\u4ef6\u80fd\u5beb\u5be6\u5730\u5408\u6210\u5728\u5ba4\u5167\u6216\u6236\u5916\u5834\u666f\u7684\u55ae\u4e00\u5f71\u50cf\u6216\u5f71\u7247\u4e2d\u3002\u6211\u5011\u7684\u57fa\u65bc\u7269\u7406\u7684\u7ba1\u9053\u9032\u4e00\u6b65\u652f\u63f4\u81ea\u52d5\u6750\u8cea\u548c\u8272\u8abf\u5c0d\u61c9\u7684\u7cbe\u7149\u3002", "author": "Ruofan Liang et.al.", "authors": "Ruofan Liang, Zan Gojcic, Merlin Nimier-David, David Acuna, Nandita Vijaykumar, Sanja Fidler, Zian Wang", "id": "2408.09702v1", "paper_url": "http://arxiv.org/abs/2408.09702v1", "repo": "null"}}