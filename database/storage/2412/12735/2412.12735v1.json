{"2412.12735": {"publish_time": "2024-12-17", "title": "GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models", "paper_summary": "Visual Language Models (VLMs) demonstrate impressive capabilities in\nprocessing multimodal inputs, yet applications such as visual agents, which\nrequire handling multiple images and high-resolution videos, demand enhanced\nlong-range modeling. Moreover, existing open-source VLMs lack systematic\nexploration into extending their context length, and commercial models often\nprovide limited details. To tackle this, we aim to establish an effective\nsolution that enhances long context performance of VLMs while preserving their\ncapacities in short context scenarios. Towards this goal, we make the best\ndesign choice through extensive experiment settings from data curation to\ncontext window extending and utilizing: (1) we analyze data sources and length\ndistributions to construct ETVLM - a data recipe to balance the performance\nacross scenarios; (2) we examine existing position extending methods, identify\ntheir limitations and propose M-RoPE++ as an enhanced approach; we also choose\nto solely instruction-tune the backbone with mixed-source data; (3) we discuss\nhow to better utilize extended context windows and propose hybrid-resolution\ntraining. Built on the Qwen-VL series model, we propose Giraffe, which is\neffectively extended to 128K lengths. Evaluated on extensive long context VLM\nbenchmarks such as VideoMME and Viusal Haystacks, our Giraffe achieves\nstate-of-the-art performance among similarly sized open-source long VLMs and is\ncompetitive with commercial model GPT-4V. We will open-source the code, data,\nand models.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5728\u8655\u7406\u591a\u6a21\u614b\u8f38\u5165\u65b9\u9762\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u9700\u8981\u8655\u7406\u591a\u5f35\u5f71\u50cf\u548c\u9ad8\u89e3\u6790\u5ea6\u5f71\u7247\u7684\u8996\u89ba\u4ee3\u7406\u7b49\u61c9\u7528\u7a0b\u5f0f\u9700\u8981\u589e\u5f37\u9060\u8ddd\u5efa\u6a21\u3002\u6b64\u5916\uff0c\u73fe\u6709\u7684\u958b\u653e\u539f\u59cb\u78bc VLM \u7f3a\u4e4f\u7cfb\u7d71\u6027\u63a2\u7d22\u4ee5\u5ef6\u4f38\u5176\u5167\u5bb9\u9577\u5ea6\uff0c\u800c\u5546\u696d\u6a21\u5f0f\u901a\u5e38\u63d0\u4f9b\u6709\u9650\u7684\u7d30\u7bc0\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u65e8\u5728\u5efa\u7acb\u4e00\u500b\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u5728\u4fdd\u7559 VLM \u5728\u77ed\u5167\u5bb9\u60c5\u5883\u4e2d\u7684\u80fd\u529b\u4e0b\uff0c\u589e\u5f37\u5176\u5728\u9577\u5167\u5bb9\u60c5\u5883\u4e2d\u7684\u8868\u73fe\u3002\u70ba\u4e86\u9054\u6210\u9019\u500b\u76ee\u6a19\uff0c\u6211\u5011\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\u8a2d\u5b9a\uff0c\u5f9e\u8cc7\u6599\u6574\u7406\u5230\u5167\u5bb9\u8996\u7a97\u5ef6\u4f38\u548c\u5229\u7528\uff0c\u505a\u51fa\u6700\u4f73\u8a2d\u8a08\u9078\u64c7\uff1a(1) \u6211\u5011\u5206\u6790\u8cc7\u6599\u4f86\u6e90\u548c\u9577\u5ea6\u5206\u4f48\uff0c\u4ee5\u5efa\u69cb ETVLM - \u4e00\u7a2e\u8cc7\u6599\u914d\u65b9\uff0c\u4ee5\u5e73\u8861\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u8868\u73fe\uff1b(2) \u6211\u5011\u6aa2\u8996\u73fe\u6709\u7684\u4f4d\u7f6e\u5ef6\u4f38\u65b9\u6cd5\uff0c\u627e\u51fa\u5176\u9650\u5236\uff0c\u4e26\u63d0\u51fa M-RoPE++ \u4f5c\u70ba\u4e00\u7a2e\u589e\u5f37\u7684\u65b9\u6cd5\uff1b\u6211\u5011\u4e5f\u9078\u64c7\u50c5\u4f7f\u7528\u6df7\u5408\u4f86\u6e90\u8cc7\u6599\u5c0d\u4e3b\u5e79\u9032\u884c\u6307\u4ee4\u8abf\u6574\uff1b(3) \u6211\u5011\u8a0e\u8ad6\u5982\u4f55\u66f4\u597d\u5730\u5229\u7528\u5ef6\u4f38\u7684\u5167\u5bb9\u8996\u7a97\uff0c\u4e26\u63d0\u51fa\u6df7\u5408\u89e3\u6790\u5ea6\u8a13\u7df4\u3002\u5efa\u69cb\u5728 Qwen-VL \u7cfb\u5217\u6a21\u578b\u4e0a\uff0c\u6211\u5011\u63d0\u51fa Giraffe\uff0c\u5b83\u6709\u6548\u5730\u5ef6\u4f38\u5230 128K \u7684\u9577\u5ea6\u3002\u5728\u5ee3\u6cdb\u7684\u9577\u5167\u5bb9 VLM \u57fa\u6e96\u4e0a\u9032\u884c\u8a55\u4f30\uff0c\u4f8b\u5982 VideoMME \u548c Viusal Haystacks\uff0c\u6211\u5011\u7684 Giraffe \u5728\u76f8\u4f3c\u5927\u5c0f\u7684\u958b\u653e\u539f\u59cb\u78bc\u9577 VLM \u4e2d\u53d6\u5f97\u6700\u5148\u9032\u7684\u8868\u73fe\uff0c\u4e26\u4e14\u8207\u5546\u696d\u6a21\u578b GPT-4V \u7af6\u722d\u3002\u6211\u5011\u5c07\u958b\u653e\u539f\u59cb\u78bc\u3001\u8cc7\u6599\u548c\u6a21\u578b\u3002", "author": "Mukai Li et.al.", "authors": "Mukai Li, Lei Li, Shansan Gong, Qi Liu", "id": "2412.12735v1", "paper_url": "http://arxiv.org/abs/2412.12735v1", "repo": "null"}}