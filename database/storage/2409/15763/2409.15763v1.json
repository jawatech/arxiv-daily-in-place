{"2409.15763": {"publish_time": "2024-09-24", "title": "IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios", "paper_summary": "In Retrieval-Augmented Generation (RAG) tasks using Large Language Models\n(LLMs), the quality of retrieved information is critical to the final output.\nThis paper introduces the IRSC benchmark for evaluating the performance of\nembedding models in multilingual RAG tasks. The benchmark encompasses five\nretrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval,\nkeyword retrieval, and summary retrieval. Our research addresses the current\nlack of comprehensive testing and effective comparison methods for embedding\nmodels in RAG scenarios. We introduced new metrics: the Similarity of Semantic\nComprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI),\nand evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our\ncontributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and\n3) insights into the cross-lingual limitations of embedding models. The IRSC\nbenchmark aims to enhance the understanding and development of accurate\nretrieval systems in RAG tasks. All code and datasets are available at:\nhttps://github.com/Jasaxion/IRSC\\_Benchmark", "paper_summary_zh": "\u5728\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210 (RAG) \u4efb\u52a1\u4e2d\uff0c\u68c0\u7d22\u4fe1\u606f\u7684\u8d28\u91cf\u5bf9\u6700\u7ec8\u8f93\u51fa\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86 IRSC \u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5d4c\u5165\u6a21\u578b\u5728\u591a\u8bed\u8a00 RAG \u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u8be5\u57fa\u51c6\u5305\u542b\u4e94\u4e2a\u68c0\u7d22\u4efb\u52a1\uff1a\u67e5\u8be2\u68c0\u7d22\u3001\u6807\u9898\u68c0\u7d22\u3001\u6bb5\u843d\u90e8\u5206\u68c0\u7d22\u3001\u5173\u952e\u8bcd\u68c0\u7d22\u548c\u6458\u8981\u68c0\u7d22\u3002\u6211\u4eec\u7684\u7814\u7a76\u89e3\u51b3\u4e86\u5f53\u524d RAG \u573a\u666f\u4e2d\u5d4c\u5165\u6a21\u578b\u7f3a\u4e4f\u5168\u9762\u6d4b\u8bd5\u548c\u6709\u6548\u6bd4\u8f83\u65b9\u6cd5\u7684\u95ee\u9898\u3002\u6211\u4eec\u5f15\u5165\u4e86\u65b0\u7684\u6307\u6807\uff1a\u8bed\u4e49\u7406\u89e3\u76f8\u4f3c\u6027\u6307\u6570 (SSCI) \u548c\u68c0\u7d22\u80fd\u529b\u7ade\u8d5b\u6307\u6570 (RCCI)\uff0c\u5e76\u8bc4\u4f30\u4e86 Snowflake-Arctic\u3001BGE\u3001GTE \u548c M3E \u7b49\u6a21\u578b\u3002\u6211\u4eec\u7684\u8d21\u732e\u5305\u62ec\uff1a1) IRSC \u57fa\u51c6\uff0c2) SSCI \u548c RCCI \u6307\u6807\uff0c\u4ee5\u53ca 3) \u5bf9\u5d4c\u5165\u6a21\u578b\u8de8\u8bed\u8a00\u9650\u5236\u7684\u89c1\u89e3\u3002IRSC \u57fa\u51c6\u65e8\u5728\u589e\u5f3a\u5bf9 RAG \u4efb\u52a1\u4e2d\u51c6\u786e\u68c0\u7d22\u7cfb\u7edf\u7684\u7406\u89e3\u548c\u5f00\u53d1\u3002\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u96c6\u90fd\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u83b7\u5f97\uff1ahttps://github.com/Jasaxion/IRSC\\_Benchmark", "author": "Hai Lin et.al.", "authors": "Hai Lin, Shaoxiong Zhan, Junyou Su, Haitao Zheng, Hui Wang", "id": "2409.15763v1", "paper_url": "http://arxiv.org/abs/2409.15763v1", "repo": "null"}}