{"2408.10573": {"publish_time": "2024-08-20", "title": "Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter", "paper_summary": "Large Language Models (LLMs) have demonstrated significant capabilities,\nparticularly in the domain of question answering (QA). However, their\neffectiveness in QA is often undermined by the vagueness of user questions. To\naddress this issue, we introduce single-round instance-level prompt\noptimization, referred to as question rewriter. By enhancing the\nintelligibility of human questions for black-box LLMs, our question rewriter\nimproves the quality of generated answers. The rewriter is optimized using\ndirect preference optimization based on feedback collected from automatic\ncriteria for evaluating generated answers; therefore, its training does not\nrequire costly human annotations. The experiments across multiple black-box\nLLMs and long-form question answering (LFQA) datasets demonstrate the efficacy\nof our method. This paper provides a practical framework for training question\nrewriters and sets a precedent for future explorations in prompt optimization\nwithin LFQA tasks. Code is available at\n\\url{https://github.com/3244we/Question-Rewriter}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u986f\u8457\u7684\u80fd\u529b\uff0c\u7279\u5225\u662f\u5728\u554f\u7b54 (QA) \u9818\u57df\u3002\u7136\u800c\uff0c\u5b83\u5011\u5728\u554f\u7b54\u4e2d\u7684\u6709\u6548\u6027\u7d93\u5e38\u53d7\u5230\u4f7f\u7528\u8005\u554f\u984c\u6a21\u7cca\u6027\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u55ae\u8f2a\u4f8b\u9805\u7d1a\u5225\u63d0\u793a\u6700\u4f73\u5316\uff0c\u7a31\u70ba\u554f\u984c\u6539\u5beb\u5668\u3002\u900f\u904e\u589e\u5f37\u9ed1\u76d2 LLM \u5c0d\u4eba\u985e\u554f\u984c\u7684\u53ef\u7406\u89e3\u6027\uff0c\u6211\u5011\u7684\u554f\u984c\u6539\u5beb\u5668\u6539\u5584\u4e86\u751f\u6210\u7b54\u6848\u7684\u54c1\u8cea\u3002\u6539\u5beb\u5668\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\u9032\u884c\u6700\u4f73\u5316\uff0c\u57fa\u790e\u662f\u5f9e\u7528\u65bc\u8a55\u4f30\u751f\u6210\u7b54\u6848\u7684\u81ea\u52d5\u6a19\u6e96\u4e2d\u6536\u96c6\u7684\u56de\u994b\uff1b\u56e0\u6b64\uff0c\u5b83\u7684\u8a13\u7df4\u4e0d\u9700\u8981\u6602\u8cb4\u7684\u4eba\u5de5\u8a3b\u89e3\u3002\u8de8\u591a\u500b\u9ed1\u76d2 LLM \u548c\u9577\u7bc7\u554f\u7b54 (LFQA) \u8cc7\u6599\u96c6\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6548\u529b\u3002\u9019\u7bc7\u8ad6\u6587\u63d0\u4f9b\u4e86\u4e00\u500b\u5be6\u7528\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u8a13\u7df4\u554f\u984c\u6539\u5beb\u5668\uff0c\u4e26\u70ba LFQA \u4efb\u52d9\u4e2d\u7684\u63d0\u793a\u6700\u4f73\u5316\u5efa\u7acb\u4e86\u672a\u4f86\u63a2\u7d22\u7684\u5148\u4f8b\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 \\url{https://github.com/3244we/Question-Rewriter} \u53d6\u5f97\u3002", "author": "Junhao Chen et.al.", "authors": "Junhao Chen, Bowen Wang, Zhouqiang jiang, Yuta Nakashima", "id": "2408.10573v1", "paper_url": "http://arxiv.org/abs/2408.10573v1", "repo": "https://github.com/3244we/question-rewriter"}}