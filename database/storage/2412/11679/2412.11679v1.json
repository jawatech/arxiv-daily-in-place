{"2412.11679": {"publish_time": "2024-12-16", "title": "Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach", "paper_summary": "The use of language models (LMs) has increased considerably in recent years,\nand the biases and stereotypes in training data that are reflected in the LM\noutputs are causing social problems. In this paper, inspired by the task\narithmetic, we propose the ``Bias Vector'' method for the mitigation of these\nLM biases. The Bias Vector method does not require manually created debiasing\ndata. The three main steps of our approach involve: (1) continual training the\npre-trained LMs on biased data using masked language modeling; (2) constructing\nthe Bias Vector as the difference between the weights of the biased LMs and\nthose of pre-trained LMs; and (3) subtracting the Bias Vector from the weights\nof the pre-trained LMs for debiasing. We evaluated the Bias Vector method on\nthe SEAT across three LMs and confirmed an average improvement of 0.177 points.\nWe demonstrated that the Bias Vector method does not degrade the LM performance\non downstream tasks in the GLUE benchmark. In addition, we examined the impact\nof scaling factors, which control the magnitudes of Bias Vectors, with effect\nsizes on the SEAT and conducted a comprehensive evaluation of our debiased LMs\nacross both the SEAT and GLUE benchmarks.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u8a9e\u8a00\u6a21\u578b (LM) \u7684\u4f7f\u7528\u5927\u5e45\u589e\u52a0\uff0c\u800c\u8a13\u7df4\u8cc7\u6599\u4e2d\u7684\u504f\u898b\u548c\u523b\u677f\u5370\u8c61\u53cd\u6620\u5728 LM \u8f38\u51fa\u4e2d\uff0c\u4e26\u9020\u6210\u793e\u6703\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u53d7\u5230\u7b97\u8853\u4efb\u52d9\u7684\u555f\u767c\uff0c\u63d0\u51fa\u300c\u504f\u898b\u5411\u91cf\u300d\u65b9\u6cd5\u4f86\u6e1b\u8f15\u9019\u4e9b LM \u504f\u898b\u3002\u504f\u898b\u5411\u91cf\u65b9\u6cd5\u4e0d\u9700\u8981\u624b\u52d5\u5efa\u7acb\u53bb\u504f\u898b\u8cc7\u6599\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u542b\u4e09\u500b\u4e3b\u8981\u6b65\u9a5f\uff1a(1) \u4f7f\u7528\u906e\u853d\u8a9e\u8a00\u6a21\u578b\u5728\u6709\u504f\u898b\u7684\u8cc7\u6599\u4e0a\u6301\u7e8c\u8a13\u7df4\u9810\u5148\u8a13\u7df4\u7684 LM\uff1b(2) \u5c07\u504f\u898b LM \u7684\u6b0a\u91cd\u8207\u9810\u5148\u8a13\u7df4\u7684 LM \u7684\u6b0a\u91cd\u4e4b\u9593\u7684\u5dee\u7570\u5efa\u69cb\u70ba\u504f\u898b\u5411\u91cf\uff1b(3) \u5f9e\u9810\u5148\u8a13\u7df4\u7684 LM \u7684\u6b0a\u91cd\u4e2d\u6e1b\u53bb\u504f\u898b\u5411\u91cf\u4ee5\u9032\u884c\u53bb\u504f\u898b\u3002\u6211\u5011\u5728\u4e09\u500b LM \u4e0a\u7684 SEAT \u8a55\u4f30\u504f\u898b\u5411\u91cf\u65b9\u6cd5\uff0c\u4e26\u78ba\u8a8d\u5e73\u5747\u6539\u5584 0.177 \u5206\u3002\u6211\u5011\u8b49\u660e\u504f\u898b\u5411\u91cf\u65b9\u6cd5\u4e0d\u6703\u964d\u4f4e GLUE \u57fa\u6e96\u4e2d\u4e0b\u6e38\u4efb\u52d9\u7684 LM \u6548\u80fd\u3002\u6b64\u5916\uff0c\u6211\u5011\u6aa2\u8996\u4e86\u63a7\u5236\u504f\u898b\u5411\u91cf\u5927\u5c0f\u7684\u7e2e\u653e\u56e0\u5b50\u7684\u5f71\u97ff\uff0c\u4ee5\u53ca\u5728 SEAT \u4e0a\u7684\u6548\u679c\u5927\u5c0f\uff0c\u4e26\u5c0d\u6211\u5011\u7684\u53bb\u504f\u898b LM \u5728 SEAT \u548c GLUE \u57fa\u6e96\u4e0a\u9032\u884c\u5168\u9762\u7684\u8a55\u4f30\u3002", "author": "Daiki Shirafuji et.al.", "authors": "Daiki Shirafuji, Makoto Takenaka, Shinya Taguchi", "id": "2412.11679v1", "paper_url": "http://arxiv.org/abs/2412.11679v1", "repo": "null"}}