# arxiv-daily
 Automated deployment @ 2024-07-13 20:20:58 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v1](http://arxiv.org/abs/2406.16908v1)|null|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|

#### Abstracts
##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v1 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最容易出現癲癇的時期。大腦尚未成熟時發生的癲癇會造成不良後果，因此需要提早診斷。目前新生兒癲癇檢測的黃金標準依賴於持續的視訊腦電圖 (EEG) 監控；其中包括在新生兒加護病房 (NICU) 內錄製多通道腦電圖 (EEG) 和進行即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇檢測流程，並減少腦電圖裝置，採用卷積神經網路、圖注意力層和全連接層。除了能夠即時偵測癲癇發作並減少裝置外，此模型還提供了即時可解釋性的獨特優勢。透過評估 Zenodo 資料集的 10 倍交叉驗證效能，提出的模型在曲線下面積 (AUC) 和召回率分別達到 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度學習正劇烈地轉變醫學影像和放射學領域，能識別醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探討了弱監督語意分割的能力。本研究的範圍是開發一種新穎的反事實內繪方法 (COIN)，它透過使用生成模型，將預測分類標籤從異常翻轉為正常。例如，如果分類器將輸入醫學影像 X 視為異常，表示存在病理，生成模型旨在內繪異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而不依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得得多。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超越了既定的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前景的 CT 影像中腫瘤語意分割方法，並在使深度學習應用在註解資料稀缺的醫療保健中更易於取得和更有效方面邁進了一步。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

摘要：<paragraph>人工智慧系統的說明很少能滿足受演算法決策 (ADM) 影響的人們的資訊需求。傳達的資訊與影響利害關係人重要的資訊之間的差距，可能會阻礙了解和遵守法規架構，例如人工智慧法案。為了解決這個差距，我們提出了「XAI 初學者問題庫」：受影響利害關係人資訊需求的目錄，涵蓋兩個 ADM 使用案例（就業預測和健康監測），涵蓋資料、系統脈絡、系統使用和系統規格類別。資訊需求是透過訪談研究收集的，參與者在詢問後收到說明。參與者進一步回報他們的理解和決策信心，顯示雖然在收到說明後信心傾向於增加，但參與者也遇到了理解挑戰，例如無法說明為什麼他們的理解感覺不完整。說明進一步影響參與者對系統風險和好處的看法，他們會根據使用案例確認或改變這些看法。當風險被認為很高時，參與者表示特別有興趣了解意圖的說明，例如為什麼以及為了什麼目的而建立系統。透過這項工作，我們旨在透過在決策採用 ADM 系統時提供相關資訊和挑戰的概覽，來支援將受影響的利害關係人納入可解釋性。我們最後總結我們的發現，列出六項關鍵影響，這些影響會告知未來針對受影響利害關係人受眾說明的設計。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 發展社群日益利用 Hugging Face 等託管中介，提供使用者上傳之模型與訓練資料的簡易取得管道。這些模型市集降低了數十萬名使用者的技術部署門檻，但卻可能被用於許多潛在有害且非法的用途。在本文中，我們說明了 AI 系統既可以「包含」內容，也可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以探討模型市集如何控管模型。根據此分析，我們概述了產業為回應控管需求而發展的重要（但仍有限）實務：授權、存取和使用限制、自動內容控管和開放式政策發展。儘管目前面臨的政策挑戰相當嚴峻，我們仍提出了一些想法，說明平台如何能更好地動員資源，作為謹慎、公平和適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋 AI (XAI) 是機器學習研究中日益重要的領域，其目標是讓黑箱模型透明且可解釋。在本文中，我們提出了一種新的 XAI 方法，該方法使用由特徵條件置換產生的所謂反事實路徑。該演算法透過識別特徵的順序置換來衡量特徵重要性，這些置換最能影響模型預測的變化。它特別適合根據包含領域知識的知識圖譜中的反事實路徑來產生解釋。反事實路徑在解釋和視覺化黑箱模型時，為目前的 XAI 方法引入了額外的圖形維度。使用合成和醫療資料進行的實驗證明了我們方法的實用適用性。

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

摘要：在人工智能 (AI) 的可解釋性領域中，已經看到越來越多的研究和學術興趣。然而，在解釋機器學習演算法的結果時缺乏人性化和個人化的詮釋，這顯著阻礙了臨床醫生在研究和臨床實務中接受這些方法。為了解決這個問題，我們的研究使用反事實解釋來探討「如果？」情境在醫學研究中的適用性。我們的目標是擴展我們對用於診斷小兒後顱窩腦腫瘤的磁共振成像 (MRI) 特徵的理解，超越現有的界線。在我們的案例研究中，所提出的概念提供了一種新穎的方法來檢視替代決策情境，提供個人化和特定於情境的見解，從而能夠驗證預測並釐清在不同情況下的差異。此外，我們探討了反事實用於資料擴充的潛在用途，並評估其作為我們醫學研究案例中替代方法的可行性。結果證明了使用反事實解釋來增強臨床研究中 AI 驅動方法的接受度的潛力。

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

摘要：目前人工智能領域的進展導致了各種類型的人工智慧驅動的失智症評估的發展，可用於識別處於失智症早期階段的患者。它可以徹底改變失智症護理設置。重要的是，醫療界要了解各種人工智能評估，並根據其有效性、效率、實用性、可靠性和準確性程度，考慮選擇它們來早期識別失智症患者 (PwD)。另一方面，人工智能開發人員也應該了解各種非人工智能評估以及最近開發的人工智能評估。因此，這篇臨床醫生和人工智能工程師都可以閱讀的論文填補了文獻中關於向臨床醫生解釋現有失智症識別解決方案以及向人工智能工程師解釋所用技術和最廣泛的失智症數據集的空白。它遵循對人工智能和非人工智能失智症評估論文的回顧，為人工智能和醫療界提供有關各種失智症評估的寶貴信息。討論和結論重點介紹了最突出的研究方向和現有解決方案的成熟度。

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

摘要：<paragraph>可解釋性對人工智慧 (AI) 技術構成一項重大挑戰。當前對可解釋 AI (XAI) 的研究缺乏提取學習任務整體知識的效率，因此存在不精確的顯著性、與情境無關的缺失和含糊意義等缺陷。在本文中，我們提出類別關聯嵌入 (CAE) 方法來解決這些問題。我們採用編碼器-解碼器架構來嵌入樣本特徵，並同時將它們分為類別相關和個體相關的樣式向量。將給定樣本的個體樣式代碼與另一個樣本的類別樣式代碼重新組合，會產生一個具有保留個體特徵但改變類別分配的合成樣本，遵循循環對抗學習策略。類別關聯嵌入將所有實例的全局類別相關特徵提煉到一個統一的領域中，並在類別之間有良好的區分。然後可以提取不同類別之間的轉換規則，並進一步應用於個別實例。然後，我們提出一個主動 XAI 框架，它沿著引導路徑操作特定樣本的類別樣式向量，朝著反類別移動，從而產生一系列具有相同個體特徵的反例合成樣本。將這些反事實樣本與原始樣本進行比較，可以對分類任務的性質提供全局、直觀的說明。我們採用該框架進行醫學影像分類任務，結果表明，與現有方法相比，可以獲得更精確的顯著性圖，並具有強大的與情境無關的表示。此外，疾病病理學可以直接通過在類別樣式空間中遍歷路徑來進行可視化。</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

摘要：提供基於機器學習的 AI 預測的高品質說明是一項具有挑戰性和複雜性的任務。要順利進行，它需要具備下列因素：選擇適當的說明普遍性/特殊性層級；考量說明受益人對所考慮的 AI 任務的熟悉程度假設；參照促成決策的特定元素；利用可能不屬於預測程序的一部分的額外知識（例如專家證據）；並提供支持否定假設的證據。最後，系統需要以清晰可解釋且可能令人信服的方式制定說明。基於這些考量，ANTIDOTE 促成了可解釋 AI 的整合願景，其中深度學習程序的低階特徵與人類論證能力的高階架構相結合。ANTIDOTE 將利用深度學習與論證的跨領域能力，來支持可解釋 AI 更廣泛且創新的觀點，其中對臨床案例審議的高品質說明需求至關重要。作為該專案的第一個成果，我們發布了 Antidote CasiMedicos 資料集，以利於一般可解釋 AI 的研究，特別是醫療領域的論證。

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

摘要：<paragraph>近年來，圖神經網路的進展迅速，在藥物發現、醫療診斷和推薦系統方面都有許多新發展。雖然這些進展很重要，但許多網路都是「黑盒子」，對於網路到底在學習「什麼」了解甚少。許多高風險應用，例如藥物發現，需要模型提供人類可以理解的解釋，以便使用者可以辨識錯誤並發現新知識。因此，可解釋 AI 演算法的開發對於我們獲取 AI 的好處至關重要。
我們提出了一種稱為 eXplainable Insight (XInsight) 的 GNN 可解釋性演算法，它使用 GFlowNets 產生模型解釋分佈。由於 GFlowNets 會產生機率與獎勵成正比的物件，因此與先前僅學習最大獎勵範例的方法相比，XInsight 可以產生多樣化的解釋集合。我們透過為在兩個圖形分類任務中訓練的 GNN 產生解釋來展示 XInsight：使用 MUTAG 資料集對致突變化合物進行分類，並使用我們已開放原始碼的合成資料集對非環狀圖形進行分類。我們透過使用 QSAR 建模分析產生的化合物來展示 XInsight 解釋的效用，我們發現 XInsight 會產生按親脂性（已知的致突變相關性）分群的化合物。我們的結果顯示 XInsight 會產生一個解釋分佈，揭示模型所展示的底層關係。它們也強調產生多樣化解釋集合的重要性，因為它使我們能夠發現模型中的隱藏關係，並為進一步分析提供有價值的指導。</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadıoğlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

摘要：我們提出並實作一個可解釋機器學習分類模型，用於基於表達式布林公式的可解釋 AI (XAI)。潛在應用包括信用評分和醫療狀況診斷。布林公式定義了一個具有可調整複雜性（或可解釋性）的規則，根據該規則對輸入數據進行分類。這樣的公式可以包含任何可應用於一個或多個布林變數的運算子，從而與更嚴格的基於規則和基於樹的方法相比，提供更高的表達能力。分類器使用原生局部最佳化技術進行訓練，有效地搜索可行公式的空間。淺層規則可以用快速的整數線性規劃 (ILP) 或二次無約束二元最佳化 (QUBO) 求解器來確定，這些求解器可能由特殊用途的硬體或量子裝置提供支援。我們將原生局部最佳化器的表達能力和效率與這些裝置的快速運算相結合，透過執行非局部移動來最佳化完整布林公式的子樹。我們提供廣泛的數值基準測試結果，其中包含在眾所周知的公共資料集上使用多個基線。根據結果，我們發現原生局部規則分類器通常與其他分類器具有競爭力。加入非局部移動以較少的反覆運算次數達成類似的結果，因此使用專用或量子硬體可能會透過快速提出非局部移動來加速。

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

摘要：為了解決心理健康問題的全球挑戰，我們提出一個基於邏輯神經網路 (LNN) 的神經符號 AI 方法來診斷心理疾病。由於缺乏有效的心理疾病治療涵蓋範圍，因此需要一種 AI 解決方案來協助治療師進行診斷。然而，目前的類神經網路模型缺乏可解釋性，治療師可能無法信任它們。LNN 是一種遞迴神經網路架構，它結合了神經網路的學習能力和基於經典邏輯的 AI 的推理能力。所提出的系統使用來自臨床訪談的輸入謂詞來輸出心理疾病類別，並使用不同的謂詞剪枝技術來實現可擴充性和更高的分數。此外，我們提供了一個見解提取方法來協助治療師進行診斷。所提出的系統解決了當前類神經網路模型缺乏可解釋性的問題，並為心理疾病診斷提供了更值得信賴的解決方案。

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

摘要：隨著機器學習模型在醫療診斷中越來越普遍，可解釋性和透明度的需求變得至關重要。XAI 復興標誌著該領域的重大轉變，旨在重新定義醫療診斷模型的可解釋性。本文探討了可解釋 AI (XAI) 領域內的創新方法和方法論，這些方法和方法論正在革新醫療診斷模型的可解釋性。通過闡明基礎決策制定過程，XAI 技術使醫療保健專業人員能夠理解、信任並有效地利用這些模型進行準確且可靠的醫療診斷。本綜述重點介紹了 XAI 在醫療診斷方面的關鍵進展及其轉變醫療保健領域的潛力，最終改善患者的治療效果並培養對 AI 驅動的診斷系統的信任。

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

摘要：<paragraph>在以高度連接性和流動性為特徵的環境中，加上心血管疾病的激增，通過遠程監控心血管健康來削減醫療保健支出的必要性變得更加明顯。準確檢測和分類心律不整對於診斷患有心臟不規則的人至關重要。本研究強調了在家中使用心電圖 (ECG) 測量進行實時心律不整檢測的可行性。本文提出了一種新的心律不整檢測應用，利用尖端的 You-Only-Look-Once (YOLO)v8 演算法對單導聯 ECG 訊號進行分類。我們引入了一個新穎的損失修改 YOLOv8 模型，並針對 MIT-BIH 心律不整資料集進行了微調，從而實現了實時的持續監控。獲得的結果證實了我們方法的有效性，該模型在 NVIDIA Tesla V100 上達到了 99.5% 的平均準確度和 0.992 mAP@50，以及 0.002 秒的快速檢測時間。我們的研究說明了實時心律不整檢測的潛力，使用戶能夠在家中舒適地視覺化解讀模型輸出。此外，本研究為擴展到實時可解釋 AI (XAI) 模型奠定了基礎，該模型能夠部署在醫療保健領域，從而顯著推進醫療保健解決方案的領域。</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

摘要：乳癌（BC）仍然是一個重大的健康威脅，目前尚無長期治癒的方法。早期發現至關重要，但乳房攝影的判讀卻受到高假陽性和假陰性的阻礙。由於乳癌的發生率預計將超過肺癌，因此改善早期檢測方法至關重要。熱像攝影使用高解析度紅外線相機，特別是在與人工智慧（AI）結合使用時，提供了希望。這項工作提出了一個基於注意力的卷積神經網路用於分割，在乳癌檢測和分類中提供了更高的速度和精度。該系統增強影像並執行可解釋的 AI 癌症分割。我們提出了一個基於Transformer注意力的卷積架構（UNet）用於故障識別，並使用梯度加權類激活映射（Grad-CAM）來分析 UNet 架構中偏見和弱點的區域，使用 IRT 影像。與現有的深度學習框架相比，我們提出的框架的優越性得到證實。

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

摘要：憂鬱症是最普遍且嚴重的精神疾病，會造成嚴重的財務和社會後果。憂鬱症的偵測對於早期介入以減輕這些後果至關重要。如此重大的決定本質上需要可解釋性。儘管一些憂鬱症偵測研究嘗試根據重要性分數或注意力權重來解釋這個決定，但這些解釋與基於憂鬱症狀的臨床憂鬱症診斷標準不一致。為了填補這個缺口，我們遵循計算設計科學範例來開發一個新穎的多尺度時間原型網路 (MSTPNet)。MSTPNet 創新地偵測並解釋憂鬱症狀以及它們持續多久。使用大規模資料集進行的廣泛實證分析顯示，MSTPNet 以 0.851 的 F1 分數優於最先進的憂鬱症偵測方法。此結果還揭示了調查方法中未注意到的新症狀，例如分享對不同生活的欽佩。我們進一步進行使用者研究，以證明其在可解釋性方面優於基準。本研究以一個新穎的可解釋深度學習模型為憂鬱症偵測在社群媒體中的 IS 文獻做出貢獻。在實務上，我們提出的方法可以實作在社群媒體平台中，以提供個人化的線上資源給被偵測出憂鬱症的患者。

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

摘要：電子健康紀錄 (EHR) 作為預想中由人工智慧 (AI) 推動的醫療保健轉型的重要資料來源。然而，反映在 EHR 備註中的臨床偏見可能導致 AI 模型繼承並擴大這些偏見，進而造成健康差異。本研究探討 EHR 備註中汙名化語言 (SL) 對使用基於 Transformer 的深度學習模型和可解釋 AI (XAI) 技術預測死亡率的影響。我們的研究結果表明，由臨床醫生撰寫的 SL 會對 AI 效能產生不利影響，特別是對黑人患者而言，突顯 SL 是 AI 模型開發中種族差異的來源。為了探索一種運作上有效率的方法來減輕 SL 的影響，我們透過臨床醫生的協作網路探討 SL 產生的模式，並找出核心臨床醫生對 AI 模型中的種族差異有較大的影響。我們發現，移除由核心臨床醫生撰寫的 SL 是比消除資料集中所有 SL 更有效率的偏見減少策略。本研究提供可行的見解，用於負責任的 AI 開發，並有助於了解臨床醫生行為和醫療保健中的 EHR 備註撰寫。

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

摘要：當代通過 AI 的自動化需要大量的幕後人力，這通常既不可見且薪資過低。由於不可見的勞動，包括標籤和維護工作，是當代 AI 系統的組成部分，因此讓使用者了解其角色仍然很重要。我們建議這可以透過可解釋的 AI（XAI）設計來完成，特別是女性主義交叉的 XAI。我們提出源自女性主義交叉研究的製圖方法，以提出 AI 的系統觀點，並納入與不可見勞動相關的 AI 維度。

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

摘要：虛擬心理健康助理 (VMHA) 持續進步，以支援每年有 6000 萬人次初級保健就診和 600 萬人次急診室 (ER) 就診的超負荷全球醫療保健系統。這些系統是由臨床心理學家、精神科醫師和人工智慧 (AI) 研究人員為認知行為療法 (CBT) 所建構。目前，VMHA 的角色是透過資訊提供情緒支持，較少著重於與患者發展反思性的對話。需要更全面、安全且可解釋的方法來建構負責任的 VMHA，以提出後續問題或提供充分的回應。這項調查提供了對心理健康中現有對話代理的系統性批判性回顧，接著深入探討了 VMHA 在脈絡知識、資料集和其在臨床決策支援中新興角色的改進。我們也提供了新的方向，以透過可解釋性、安全性與整體可信度來豐富 VMHA 的使用者體驗。最後，我們提供了評量指標和 VMHA 的實務考量，超越目前的文獻，在 VMHA 與患者的積極溝通中建立信任。

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

摘要：XAI 指的是用於建構 AI 應用程式的技術和方法，這些應用程式可協助最終使用者詮釋 AI 模型的輸出和預測。在高風險決策情境中，例如醫療領域，黑箱 AI 應用程式增加了透明度和可解釋性的需求，因為錯誤的預測可能會造成嚴重的後果。模型可解釋性和可詮釋性對於在醫療實務中成功部署 AI 模型至關重要。AI 應用程式的基本推理需要對臨床醫生透明，才能獲得他們的信任。本文提供了醫療領域中 XAI 面向和挑戰的系統性回顧。本研究的主要目標是回顧各種 XAI 方法、其挑戰，以及相關的醫療保健機器學習模型。這些方法分為六類討論：面向特徵的方法、整體方法、概念模型、代理模型、局部基於像素的方法，以及以人為中心的方法。最重要的是，本文探討了 XAI 在醫療保健問題中的角色，以釐清其在安全關鍵應用中的必要性。本文旨在透過回顧相關的實驗結果，建立對醫療保健領域中 XAI 相關應用程式的全面了解。為了促進未來研究填補研究差距，本文探討了 XAI 模型從不同觀點來看的重要性及其限制。

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

摘要：最先进的机器学习模型通常会学习训练数据中嵌入的虚假关联。这在将这些模型部署于高风险决策时会带来风险，例如在皮肤癌检测等医学应用中。为了解决这个问题，我们提出了 Reveal to Revise (R2R)，一个涵盖整个可解释人工智能 (XAI) 生命周期的框架，使从业者能够以最少的人工交互迭代识别、缓解和（重新）评估虚假模型行为。在第一步 (1) 中，R2R 通过找出归因中的异常值或通过检查模型学习的潜在概念来揭示模型的弱点。其次 (2)，检测负责的伪像并在输入数据中进行空间定位，然后利用它来 (3) 修改模型行为。具体来说，我们应用 RRR、CDEP 和 ClArC 的方法来进行模型校正，并 (4)（重新）评估模型的性能和对伪像的剩余敏感性。使用两个用于黑色素瘤检测和骨龄估计的医学基准数据集，我们将我们的 R2R 框架应用于 VGG、ResNet 和 EfficientNet 架构，从而揭示和纠正了真实数据集固有的伪像，以及受控设置中的合成变体。完成 XAI 生命周期，我们演示了多个 R2R 迭代以减轻不同的偏差。代码可在 https://github.com/maxdreyer/Reveal2Revise 上找到。

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, Grégoire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

摘要：可解釋人工智慧 (XAI) 領域在近年來取得長足進步，但進展主要是在電腦視覺和自然語言處理方面。對於輸入通常無法解釋的時間序列，只有有限的研究可供使用 XAI。在這項工作中，我們提出了一個虛擬檢查層，它將時間序列轉換為可解釋的表示，並允許通過層級相關性傳播 (LRP) 等局部 XAI 方法將相關性歸因傳播到此表示。藉此，我們將一系列 XAI 方法的適用性擴展到輸入僅在轉換後才能解釋的領域（例如語音）。在此，我們專注於傅立葉轉換，它主要應用於時間序列和 LRP 的解釋，並將我們的稱之為 DFT-LRP。我們展示了 DFT-LRP 在各種時間序列分類設定（例如音訊和電子健康紀錄）中的效用。我們展示了 DFT-LRP 如何揭示在不同領域（例如時間與頻率域）訓練的模型的分類策略差異，或有助於發現模型如何處理資料中的虛假關聯。

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

摘要：解釋深度學習模型預測結果的能力對最終使用者而言是一項重要功能，可利用人工智慧 (AI) 的力量進行醫療決策流程，這通常被認為是不透明且難以理解的。在本文中，我們運用最先進的可解釋人工智慧 (XAI) 方法來解釋黑盒 AI 模型在甲狀腺結節診斷應用中的預測結果。我們提出新的基於統計的 XAI 方法，即核密度估計和密度圖，來解釋未檢測到結節的情況。XAI 方法的效能會在定性和定量比較下被視為改善資料品質和模型效能的回饋。最後，我們進行調查以評估醫師和患者對 XAI 對模型在甲狀腺結節影像中決策的解釋的信任度。

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

摘要：醫療設備和人工智慧系統快速轉化醫療保健的提供方式。同時，由於其本質，醫療設備中或作為醫療設備的人工智慧可能會遭受網路攻擊，進而導致患者安全和安全風險。本章節分為三部分。第一部分從設定場景開始，說明網路安全在醫療保健中的角色。然後，我們簡要定義我們在談論被視為醫療設備本身或支援醫療設備的人工智慧時所指涉的內容。為了說明此類醫療設備帶來的風險，我們提供了三個範例：資料集中毒、社會工程和資料或原始碼萃取。在第二部分，本文概述了歐盟的監管架構，與確保醫療設備中或作為醫療設備的人工智慧的網路安全相關（醫療器材法規、網路與資訊安全指令、網路安全法、一般資料保護規範、人工智慧法提案和網路與資訊安全 2 指令提案）。最後，本文的第三部分探討源自歐盟監管架構的潛在挑戰。特別是，我們展望源自這兩項立法提案的挑戰，以及它們與現有關於人工智慧醫療設備網路安全的立法之間的互動。它們被架構為以下問題的解答：(1) 人工智慧法將如何與醫療器材法規互動，就網路安全和安全要求而言？(2) 我們應如何解讀網路與資訊安全 2 指令提案和醫療器材法規的事件通知要求？(3) 關鍵基礎設施演進的術語會帶來什麼後果？
[這是草稿章節。最終版本將刊載於 Barry Solaiman 和 I. Glenn Cohen 編輯的《健康、人工智慧與法律研究手冊》中，2023 年出版，Edward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

摘要：阿茲海默症 (AD) 是一種進行性的神經退化性疾病，也是導致失智症的主因。早期診斷對於患者接受潛在干預和治療至關重要。由於視網膜與大腦有解剖學上的連結，因此假設視網膜可以作為 AD 檢測的診斷部位。為此目的而開發的 AI 模型，尚未對決策提供合理的解釋，也無法推論疾病進展的階段。沿著這個方向，我們提出了一個新穎的模型不可知論可解釋 AI 架構，稱為顆粒神經元級別解釋器 (LAVA)，這是一個解釋原型，可以探測卷積神經網路 (CNN) 模型的中間層，以直接從視網膜影像評估 AD 連續體，而無需縱向或臨床評估。此方法用於驗證視網膜血管作為生物標記和阿茲海默症 (AD) 評估的診斷方式。英國生物資料庫的認知測試和血管形態特徵表明，LAVA 在識別進展連續體中的 AD 階段方面顯示出強大的前景和有效性。

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

摘要：許多視覺化已被開發用於可解釋的 AI (XAI)，但它們通常需要使用者進一步推理才能解讀。我們主張 XAI 應支援圖解和演繹推理，讓 AI 執行假設產生和評估以縮小可解釋性差距。我們提出圖解化以 i) 執行皮爾士演繹-演繹推理，ii) 遵循領域慣例，以及 iii) 以視覺或口語方式說明圖表。我們實作了 DiagramNet 進行臨床應用，以從心臟聽診預測心臟診斷，並以形狀為基礎的雜音圖說明。在建模研究中，我們發現 DiagramNet 不僅提供了忠實的雜音形狀說明，而且比基準模型具有更好的預測效能。我們進一步在與醫學生的質性使用者研究中展示了圖解說明的可解釋性和可信度，顯示出以臨床相關的圖解說明優於技術顯著性圖說明。這項工作有助於提供以使用者為中心的 XAI 的領域慣例演繹說明。

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna, Kundrapu Supriya, Mallikharjuna Rao K, Meetiksha Sorgile

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

摘要：皮膚癌是人類最普遍的癌症類型之一。它的識別主要依賴視覺，從臨床篩檢開始，接著是皮膚鏡檢查、組織學評估，以及檢體收集。深度卷積神經網路 (CNN) 可針對分類的細粒度物件執行高度區隔且潛在通用的任務。本研究提出一個新穎的多類別預測架構，它以 ViT 和 ViTGAN 為基礎對皮膚病灶進行分類。基於視覺轉換器的 GAN（生成對抗網路）用於解決類別不平衡問題。此架構包含四個主要階段：ViTGAN、影像處理和可解釋 AI。第一階段包括產生合成影像，以平衡資料集中的所有類別。第二階段包括應用不同的資料擴充技術和形態運算，以增加資料大小。第三和第四階段涉及開發適用於邊緣運算系統的 ViT 模型，該模型可以識別圖案，並對影像中用戶皮膚可見的皮膚病灶進行分類。在第三階段，在使用 ViT 將病灶分類到所需的類別後，我們將使用可解釋 AI (XAI)，它會產生更具可解釋性的結果（使用啟用圖等），同時確保高預測準確度。皮膚疾病的即時影像可以用行動應用程式的相機由醫生或患者擷取，以執行早期檢查並確定皮膚病灶的原因。整個架構與現有的皮膚病灶偵測架構進行比較。

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou, Mert Yuksekgonul, Zhuo Ran Cai, Roberto Novoa, James Zou

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

摘要：<paragraph>在高風險環境中部署人工智慧 (AI)（例如醫療保健），提供可解釋性/可說明性的方法或允許精細錯誤分析非常重要。許多近期用於可解釋性/可說明性和精細錯誤分析的方法都使用概念，這些概念是對人類具有語義意義的元標籤。然而，只有少數資料集包含概念層級的元標籤，而且這些元標籤大多與不需要領域專業知識的自然影像相關。專注於單一疾病（例如黑色素瘤）的元標籤的醫學密集標記資料集。在皮膚科中，皮膚疾病的描述使用既定的臨床詞彙，讓臨床醫生可以彼此描述身體檢查結果。為了提供由領域專家密集標記的醫學資料集，其中包含可跨多種疾病過程使用的標記，我們開發了 SkinCon：由皮膚科醫師密集標記的皮膚疾病資料集。SkinCon 包含來自 Fitzpatrick 17k 資料集的 3230 張影像，密集標記了 48 個臨床概念，其中 22 個概念至少有 50 張影像代表該概念。所使用的概念是由兩位皮膚科醫師在考量用於描述皮膚病變的臨床描述詞彙後選出的。範例包括「斑塊」、「鱗屑」和「糜爛」。相同的概念也用於標記來自 Diverse Dermatology Images 資料集的 656 張皮膚疾病影像，提供具有多樣膚色表示的額外外部資料集。我們檢視 SkinCon 資料集的潛在應用，例如探測模型、基於概念的說明和概念瓶頸。此外，我們使用 SkinCon 來展示這兩個使用案例：使用概念除錯現有皮膚科 AI 模型的錯誤，以及使用事後概念瓶頸模型開發可解釋的模型。</paragraph>

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma, Shresth Verma, Aditya Mate, Aparna Taneja, Milind Tambe

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

摘要：不安分的多臂強盜 (RMAB) 是一個流行的決策理論架構，已被用於模擬公共衛生、野生動物保育、通訊系統等領域的真實世界順序決策問題。已部署的 RMAB 系統通常分兩個階段運作：第一個階段預測定義 RMAB 執行個體的未知參數，第二個階段採用最佳化演算法來解決已建構的 RMAB 執行個體。
在本研究中，我們提供並分析了在公共衛生領域中首次部署 RMAB 系統的結果，目標是改善孕產婦和兒童健康。我們的分析著重於了解預測準確度與已部署 RMAB 系統的整體效能之間的關係。這對於決定投資於改善預測準確度以提升最終系統效能的價值至關重要，並且有助於診斷、監控已部署的 RMAB 系統。
使用我們已部署 RMAB 系統中的真實世界資料，我們證明了整體預測準確度的提升甚至可能伴隨著 RMAB 系統效能的下降——廣泛投入資源以改善整體預測準確度可能無法產生預期的結果。在此之後，我們開發了以決策為重點的評估指標來評估預測元件，並證明它更能解釋已部署 RMAB 系統的整體效能（無論是經驗上或理論上）。

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta, Riccardo Guidotti, Yuan Yin, Patrick Gallinari, Salvatore Rinzivillo

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

摘要：可解釋 AI 是在開發機制，讓決策系統與人類之間能互動，並讓前者的決策變得可以理解。這在敏感的脈絡中特別重要，例如在醫療領域。我們提出一個使用案例研究，用於皮膚病變診斷，說明如何讓執業醫師了解最先進的深度神經網路分類器在決策上的解釋，該分類器經過訓練，可以從範例中描述皮膚病變。我們的架構包含一個訓練過的分類器，解釋模組會在該分類器上運作。後者能夠為分類診斷提供執業醫師範例和反例，因此讓醫師可以與自動診斷系統互動。範例是透過對抗式自動編碼器產生的。我們說明系統在代表性範例上的行為。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-10**|**LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models**|Feng Li et.al.|[2407.07895v1](http://arxiv.org/abs/2407.07895v1)|[link](https://github.com/LLaVA-VL/LLaVA-NeXT)|
|**2024-07-10**|**Training on the Test Task Confounds Evaluation and Emergence**|Ricardo Dominguez-Olmedo et.al.|[2407.07890v1](http://arxiv.org/abs/2407.07890v1)|[link](https://github.com/socialfoundations/training-on-the-test-task)|
|**2024-07-10**|**Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization**|Junkang Wu et.al.|[2407.07880v1](http://arxiv.org/abs/2407.07880v1)|[link](https://github.com/junkangwu/dr_dpo)|
|**2024-07-10**|**Generative Image as Action Models**|Mohit Shridhar et.al.|[2407.07875v1](http://arxiv.org/abs/2407.07875v1)|null|
|**2024-07-10**|**Toto: Time Series Optimized Transformer for Observability**|Ben Cohen et.al.|[2407.07874v2](http://arxiv.org/abs/2407.07874v2)|null|
|**2024-07-10**|**FACTS About Building Retrieval Augmented Generation-based Chatbots**|Rama Akkiraju et.al.|[2407.07858v1](http://arxiv.org/abs/2407.07858v1)|null|
|**2024-07-10**|**Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers**|Cody Wild et.al.|[2407.07848v1](http://arxiv.org/abs/2407.07848v1)|null|
|**2024-07-10**|**Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison**|Qian Yang et.al.|[2407.07840v1](http://arxiv.org/abs/2407.07840v1)|null|
|**2024-07-10**|**RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation**|Tao Li et.al.|[2407.07835v1](http://arxiv.org/abs/2407.07835v1)|[link](https://github.com/tourlics/robus_dataset)|
|**2024-07-10**|**Transformer Alignment in Large Language Models**|Murdock Aubry et.al.|[2407.07810v1](http://arxiv.org/abs/2407.07810v1)|null|
|**2024-07-10**|**ROSA: Random Subspace Adaptation for Efficient Fine-Tuning**|Marawan Gamal Abdel Hameed et.al.|[2407.07802v1](http://arxiv.org/abs/2407.07802v1)|[link](https://github.com/rosa-paper/rosa)|
|**2024-07-10**|**AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning**|Jongsuk Kim et.al.|[2407.07801v2](http://arxiv.org/abs/2407.07801v2)|null|
|**2024-07-10**|**Attribute or Abstain: Large Language Models as Long Document Assistants**|Jan Buchmann et.al.|[2407.07799v1](http://arxiv.org/abs/2407.07799v1)|[link](https://github.com/ukplab/arxiv2024-attribute-or-abstain)|
|**2024-07-10**|**Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard**|Oguzhan Topsakal et.al.|[2407.07796v2](http://arxiv.org/abs/2407.07796v2)|[link](https://github.com/research-outcome/llm-game-benchmark)|
|**2024-07-10**|**Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities**|Tianjie Ju et.al.|[2407.07791v1](http://arxiv.org/abs/2407.07791v1)|[link](https://github.com/Jometeorie/KnowledgeSpread)|
|**2024-07-10**|**WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment**|Jiefu Ou et.al.|[2407.07778v1](http://arxiv.org/abs/2407.07778v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v1](http://arxiv.org/abs/2407.07775v1)|null|
|**2024-07-10**|**Learning Spatial-Semantic Features for Robust Video Object Segmentation**|Xin Li et.al.|[2407.07760v1](http://arxiv.org/abs/2407.07760v1)|null|
|**2024-07-10**|**Fine-Tuning Large Language Models with User-Level Differential Privacy**|Zachary Charles et.al.|[2407.07737v1](http://arxiv.org/abs/2407.07737v1)|null|
|**2024-07-10**|**SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis**|Zihao Wang et.al.|[2407.07728v2](http://arxiv.org/abs/2407.07728v2)|null|
|**2024-07-10**|**PaliGemma: A versatile 3B VLM for transfer**|Lucas Beyer et.al.|[2407.07726v1](http://arxiv.org/abs/2407.07726v1)|null|
|**2024-07-10**|**Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control**|Elahe Delavari et.al.|[2407.07684v1](http://arxiv.org/abs/2407.07684v1)|null|
|**2024-07-10**|**The Language of Weather: Social Media Reactions to Weather Accounting for Climatic and Linguistic Baselines**|James C. Young et.al.|[2407.07683v1](http://arxiv.org/abs/2407.07683v1)|null|
|**2024-07-10**|**Why should we ever automate moral decision making?**|Vincent Conitzer et.al.|[2407.07671v1](http://arxiv.org/abs/2407.07671v1)|null|
|**2024-07-10**|**How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning**|Giuseppe Serra et.al.|[2407.07668v1](http://arxiv.org/abs/2407.07668v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry**|Martin Lindström et.al.|[2407.07664v1](http://arxiv.org/abs/2407.07664v1)|[link](https://github.com/martinlindstrom/coding_theoretic_hpl)|
|**2024-07-10**|**Tuning Vision-Language Models with Candidate Labels by Prompt Alignment**|Zhifang Zhang et.al.|[2407.07638v2](http://arxiv.org/abs/2407.07638v2)|null|
|**2024-07-10**|**A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training**|Michał Perełkiewicz et.al.|[2407.07630v1](http://arxiv.org/abs/2407.07630v1)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**The Computational Learning of Construction Grammars: State of the Art and Prospective Roadmap**|Jonas Doumen et.al.|[2407.07606v1](http://arxiv.org/abs/2407.07606v1)|null|
|**2024-07-10**|**Early Explorations of Lightweight Models for Wound Segmentation on Mobile Devices**|Vanessa Borst et.al.|[2407.07605v2](http://arxiv.org/abs/2407.07605v2)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model**|Yatai Ji et.al.|[2407.07577v1](http://arxiv.org/abs/2407.07577v1)|[link](https://github.com/jiyt17/ida-vlm)|
|**2024-07-10**|**HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing**|Arnon Turetzky et.al.|[2407.07566v1](http://arxiv.org/abs/2407.07566v1)|null|
|**2024-07-10**|**On Leakage of Code Generation Evaluation Datasets**|Alexandre Matton et.al.|[2407.07565v2](http://arxiv.org/abs/2407.07565v2)|null|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|null|
|**2024-07-10**|**Disentangling Masked Autoencoders for Unsupervised Domain Generalization**|An Zhang et.al.|[2407.07544v1](http://arxiv.org/abs/2407.07544v1)|[link](https://github.com/rookiehb/dismae)|
|**2024-07-10**|**Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search**|Kirill Paramonov et.al.|[2407.07541v1](http://arxiv.org/abs/2407.07541v1)|null|
|**2024-07-10**|**Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models**|Jin Liu et.al.|[2407.07531v1](http://arxiv.org/abs/2407.07531v1)|null|
|**2024-07-10**|**How Aligned are Different Alignment Metrics?**|Jannis Ahlert et.al.|[2407.07530v1](http://arxiv.org/abs/2407.07530v1)|null|
|**2024-07-10**|**CHILLI: A data context-aware perturbation method for XAI**|Saif Anwar et.al.|[2407.07521v1](http://arxiv.org/abs/2407.07521v1)|null|
|**2024-07-10**|**Generative AI for RF Sensing in IoT systems**|Li Wang et.al.|[2407.07506v1](http://arxiv.org/abs/2407.07506v1)|null|
|**2024-07-10**|**Bucket Pre-training is All You Need**|Hongtao Liu et.al.|[2407.07495v1](http://arxiv.org/abs/2407.07495v1)|null|
|**2024-07-10**|**FUNAvg: Federated Uncertainty Weighted Averaging for Datasets with Diverse Labels**|Malte Tölle et.al.|[2407.07488v1](http://arxiv.org/abs/2407.07488v1)|[link](https://github.com/cardio-ai/funavg)|
|**2024-07-10**|**Review-LLM: Harnessing Large Language Models for Personalized Review Generation**|Qiyao Peng et.al.|[2407.07487v1](http://arxiv.org/abs/2407.07487v1)|null|
|**2024-07-10**|**Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations**|Luca Marzari et.al.|[2407.07482v1](http://arxiv.org/abs/2407.07482v1)|[link](https://github.com/lmarza/apas)|
|**2024-07-10**|**Rectifier: Code Translation with Corrector via LLMs**|Xin Yin et.al.|[2407.07472v1](http://arxiv.org/abs/2407.07472v1)|[link](https://github.com/vinci-grape/rectifier)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-10**|**Secondary Structure-Guided Novel Protein Sequence Generation with Latent Graph Diffusion**|Yutong Hu et.al.|[2407.07443v1](http://arxiv.org/abs/2407.07443v1)|[link](https://github.com/riacd/cpdiffusion-ss)|
|**2024-07-10**|**Controllable Navigation Instruction Generation with Chain of Thought Prompting**|Xianghao Kong et.al.|[2407.07433v1](http://arxiv.org/abs/2407.07433v1)|[link](https://github.com/refkxh/c-instructor)|
|**2024-07-10**|**Out-of-distribution generalisation in spoken language understanding**|Dejan Porjazovski et.al.|[2407.07425v1](http://arxiv.org/abs/2407.07425v1)|[link](https://github.com/aalto-speech/slurpfood)|
|**2024-07-10**|**KpopMT: Translation Dataset with Terminology for Kpop Fandom**|JiWoo Kim et.al.|[2407.07413v1](http://arxiv.org/abs/2407.07413v1)|[link](https://github.com/skswldndi/KpopMT)|
|**2024-07-10**|**Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**|Seonghoon Yu et.al.|[2407.07412v1](http://arxiv.org/abs/2407.07412v1)|[link](https://github.com/seonghoon-yu/pseudo-ris)|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems**|Chashi Mahiul Islam et.al.|[2407.07392v1](http://arxiv.org/abs/2407.07392v1)|null|
|**2024-07-10**|**Automatic Extraction of Disease Risk Factors from Medical Publications**|Maxim Rubchinsky et.al.|[2407.07373v1](http://arxiv.org/abs/2407.07373v1)|[link](https://github.com/maximrub/diseases-risk-factors)|
|**2024-07-10**|**LokiLM: Technical Report**|Justin Kiefel et.al.|[2407.07370v1](http://arxiv.org/abs/2407.07370v1)|null|
|**2024-07-10**|**Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?**|Zemian Ke et.al.|[2407.07364v1](http://arxiv.org/abs/2407.07364v1)|null|
|**2024-07-10**|**Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture**|Jiayang Song et.al.|[2407.07342v1](http://arxiv.org/abs/2407.07342v1)|null|
|**2024-07-10**|**MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization**|Gaurav Sahu et.al.|[2407.07341v1](http://arxiv.org/abs/2407.07341v1)|null|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models**|Messi H. J. Lee et.al.|[2407.07329v1](http://arxiv.org/abs/2407.07329v1)|null|
|**2024-07-10**|**Fuse, Reason and Verify: Geometry Problem Solving with Parsed Clauses from Diagram**|Ming-Liang Zhang et.al.|[2407.07327v1](http://arxiv.org/abs/2407.07327v1)|null|
|**2024-07-10**|**HiLight: Technical Report on the Motern AI Video Language Model**|Zhiting Wang et.al.|[2407.07325v2](http://arxiv.org/abs/2407.07325v2)|null|
|**2024-07-10**|**RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension**|Hung Phan et.al.|[2407.07321v1](http://arxiv.org/abs/2407.07321v1)|null|
|**2024-07-10**|**ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models**|Benjamin Ascoli et.al.|[2407.07313v1](http://arxiv.org/abs/2407.07313v1)|null|
|**2024-07-10**|**ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting**|Luoxiao Yang et.al.|[2407.07311v1](http://arxiv.org/abs/2407.07311v1)|[link](https://github.com/ikeyang/vitime)|
|**2024-07-10**|**Inference Performance Optimization for Large Language Models on CPUs**|Pujiang He et.al.|[2407.07304v1](http://arxiv.org/abs/2407.07304v1)|[link](https://github.com/intel/xfastertransformer)|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-10**|**Structural Design Through Reinforcement Learning**|Thomas Rochefort-Beaudoin et.al.|[2407.07288v1](http://arxiv.org/abs/2407.07288v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**Exploring Camera Encoder Designs for Autonomous Driving Perception**|Barath Lakshmanan et.al.|[2407.07276v1](http://arxiv.org/abs/2407.07276v1)|null|
|**2024-07-09**|**Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support**|Karn N. Watcharasupat et.al.|[2407.07275v1](http://arxiv.org/abs/2407.07275v1)|null|
|**2024-07-09**|**Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models**|Jupinder Parmar et.al.|[2407.07263v1](http://arxiv.org/abs/2407.07263v1)|null|
|**2024-07-09**|**Identification of emotions on Twitter during the 2022 electoral process in Colombia**|Juan Jose Iguaran Fernandez et.al.|[2407.07258v1](http://arxiv.org/abs/2407.07258v1)|null|
|**2024-07-09**|**Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models**|Yun Qi Li et.al.|[2407.07229v1](http://arxiv.org/abs/2407.07229v1)|[link](https://github.com/astrodatalab/li2024_public)|
|**2024-07-09**|**ConvNLP: Image-based AI Text Detection**|Suriya Prakash Jambunathan et.al.|[2407.07225v1](http://arxiv.org/abs/2407.07225v1)|null|
|**2024-07-09**|**AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**|Jiaxi Cui et.al.|[2407.07094v1](http://arxiv.org/abs/2407.07094v1)|[link](https://github.com/pandavt/datatager)|
|**2024-07-09**|**FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**|Liqun Ma et.al.|[2407.07093v1](http://arxiv.org/abs/2407.07093v1)|[link](https://github.com/liqunma/fbi-llm)|
|**2024-07-09**|**Safe and Reliable Training of Learning-Based Aerospace Controllers**|Udayan Mandal et.al.|[2407.07088v1](http://arxiv.org/abs/2407.07088v1)|[link](https://github.com/neuralnetworkverification/artifact-dasc-docking)|
|**2024-07-09**|**CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**|Tong Chen et.al.|[2407.07087v1](http://arxiv.org/abs/2407.07087v1)|[link](https://github.com/chentong0/copy-bench)|
|**2024-07-09**|**Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**|Logan Cross et.al.|[2407.07086v1](http://arxiv.org/abs/2407.07086v1)|[link](https://github.com/locross93/hypothetical-minds)|
|**2024-07-09**|**Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**|Shaltiel Shmidman et.al.|[2407.07080v1](http://arxiv.org/abs/2407.07080v1)|null|
|**2024-07-09**|**ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**|Shaozhe Hao et.al.|[2407.07077v1](http://arxiv.org/abs/2407.07077v1)|[link](https://github.com/haoosz/conceptexpress)|
|**2024-07-09**|**Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**|Yung-Sung Chuang et.al.|[2407.07071v1](http://arxiv.org/abs/2407.07071v1)|[link](https://github.com/voidism/lookback-lens)|
|**2024-07-09**|**Prompting Techniques for Secure Code Generation: A Systematic Investigation**|Catherine Tony et.al.|[2407.07064v1](http://arxiv.org/abs/2407.07064v1)|null|
|**2024-07-09**|**Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**|Weize Chen et.al.|[2407.07061v2](http://arxiv.org/abs/2407.07061v2)|[link](https://github.com/openbmb/ioa)|
|**2024-07-09**|**CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**|Yangmin Li et.al.|[2407.07046v1](http://arxiv.org/abs/2407.07046v1)|null|
|**2024-07-09**|**Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**|Christian Riefolo et.al.|[2407.07045v1](http://arxiv.org/abs/2407.07045v1)|[link](https://github.com/thescreamingmonkey/mbm-em)|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**|Yue Zhang et.al.|[2407.07035v1](http://arxiv.org/abs/2407.07035v1)|null|
|**2024-07-09**|**Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**|Daiqing Wu et.al.|[2407.07026v1](http://arxiv.org/abs/2407.07026v1)|null|
|**2024-07-09**|**Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**|Jeongseok Hyun et.al.|[2407.07024v1](http://arxiv.org/abs/2407.07024v1)|[link](https://github.com/hyunjs/stov-tal)|
|**2024-07-09**|**Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**|Haicheng Liao et.al.|[2407.07020v1](http://arxiv.org/abs/2407.07020v1)|null|
|**2024-07-09**|**Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**|Inwon Kang et.al.|[2407.07019v1](http://arxiv.org/abs/2407.07019v1)|null|

#### Abstracts
##### **LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models**
2407.07895v1 by Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, Chunyuan Li

Visual instruction tuning has made considerable strides in enhancing the
capabilities of Large Multimodal Models (LMMs). However, existing open LMMs
largely focus on single-image tasks, their applications to multi-image
scenarios remains less explored. Additionally, prior LMM research separately
tackles different scenarios, leaving it impossible to generalize cross
scenarios with new emerging capabilities. To this end, we introduce
LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame
(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To
enable these capabilities, we regard the interleaved data format as a general
template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4
primary domains with 14 tasks and 41 datasets. We also curate the
LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance
of LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading
results in multi-image, video, and 3D benchmarks, while maintaining the
performance of single-image tasks. Besides, our model also exhibits several
emerging capabilities, e.g., transferring tasks across different settings and
modalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT

摘要：視覺指令調整已在提升大型多模態模型 (LMM) 能力方面取得顯著進展。然而，現有的開放式 LMM 主要專注於單一影像任務，其在多影像場景中的應用仍較少探索。此外，先前的 LMM 研究分別處理不同的場景，導致無法透過新興能力對跨場景進行概括。為此，我們引入了 LLaVA-NeXT-Interleave，它同時處理 LMM 中的多影像、多幀（影片）、多視角（3D）和多區塊（單一影像）場景。為了啟用這些能力，我們將交錯資料格式視為一般範本，並編譯包含 1,177.6k 個樣本的 M4-Instruct 資料集，涵蓋 4 個主要領域，包含 14 個任務和 41 個資料集。我們也策劃了 LLaVA-Interleave Bench，以全面評估 LMM 的多影像效能。透過廣泛的實驗，LLaVA-NeXT-Interleave 在多影像、影片和 3D 基準測試中取得領先的結果，同時維持單一影像任務的效能。此外，我們的模型也展現了多項新興能力，例如在不同設定和模態之間轉移任務。程式碼可在 https://github.com/LLaVA-VL/LLaVA-NeXT 取得

##### **Training on the Test Task Confounds Evaluation and Emergence**
2407.07890v1 by Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt

We study a fundamental problem in the evaluation of large language models
that we call training on the test task. Unlike wrongful practices like training
on the test data, leakage, or data contamination, training on the test task is
not a malpractice. Rather, the term describes a growing set of techniques to
include task-relevant data in the pretraining stage of a language model. We
demonstrate that training on the test task confounds both relative model
evaluations and claims about emergent capabilities. We argue that the seeming
superiority of one model family over another may be explained by a different
degree of training on the test task. To this end, we propose an effective
method to adjust for training on the test task by fine-tuning each model under
comparison on the same task-relevant data before evaluation. We then show that
instances of emergent behavior largely vanish once we adjust for training on
the test task. This also applies to reported instances of emergent behavior
that cannot be explained by the choice of evaluation metric. Our work promotes
a new perspective on the evaluation of large language models with broad
implications for benchmarking and the study of emergent capabilities.

摘要：我們研究大型語言模型評估中一個基本的難題，我們稱之為測試任務訓練。與訓練測試資料、洩漏或資料污染等不當做法不同，訓練測試任務並非一種不正當行為。反之，此術語描述了一組日益增長的技術，用於在語言模型的預訓練階段納入與任務相關的資料。我們證明，訓練測試任務會混淆相對模型評估和關於新興能力的主張。我們認為，一個模型家族看似優於另一個模型家族，可能是由於訓練測試任務的程度不同。為此，我們提出了一種有效的方法來調整訓練測試任務，方法是在評估之前使用相同的任務相關資料對每個模型進行微調。然後，我們表明，一旦我們調整訓練測試任務，新興行為的實例就會在很大程度上消失。這也適用於無法用評估指標的選擇來解釋的新興行為的報告實例。我們的研究促進了對大型語言模型評估的新觀點，對基準測試和新興能力的研究具有廣泛的影響。

##### **Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization**
2407.07880v1 by Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He

This study addresses the challenge of noise in training datasets for Direct
Preference Optimization (DPO), a method for aligning Large Language Models
(LLMs) with human preferences. We categorize noise into pointwise noise, which
includes low-quality data points, and pairwise noise, which encompasses
erroneous data pair associations that affect preference rankings. Utilizing
Distributionally Robust Optimization (DRO), we enhance DPO's resilience to
these types of noise. Our theoretical insights reveal that DPO inherently
embeds DRO principles, conferring robustness to pointwise noise, with the
regularization coefficient $\beta$ playing a critical role in its noise
resistance. Extending this framework, we introduce Distributionally
Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing
against worst-case pairwise scenarios. The novel hyperparameter $\beta'$ in Dr.
DPO allows for fine-tuned control over data pair reliability, providing a
strategic balance between exploration and exploitation in noisy training
environments. Empirical evaluations demonstrate that Dr. DPO substantially
improves the quality of generated text and response accuracy in preference
datasets, showcasing enhanced performance in both noisy and noise-free
settings. The code is available at https://github.com/junkangwu/Dr_DPO.

摘要：本研究探讨了直接偏好优化 (DPO) 训练数据集中的噪声挑战，DPO 是一种将大型语言模型 (LLM) 与人类偏好相匹配的方法。我们将噪声分为逐点噪声，其中包括低质量数据点，以及成对噪声，其中包括影响偏好排名的错误数据对关联。利用分布鲁棒优化 (DRO)，我们增强了 DPO 对这些类型噪声的弹性。我们的理论见解表明，DPO 本质上嵌入了 DRO 原则，赋予了对逐点噪声的鲁棒性，其中正则化系数 $\beta$ 在其抗噪声中起着至关重要的作用。扩展此框架，我们引入了分布鲁棒化 DPO (Dr. DPO)，它通过针对最坏情况成对场景进行优化来集成成对鲁棒性。Dr. DPO 中的新型超参数 $\beta'$ 允许对数据对可靠性进行微调控制，在嘈杂的训练环境中提供探索和利用之间的战略平衡。经验评估表明，Dr. DPO 在首选数据集中的生成文本质量和响应准确性方面有了实质性的提高，在有噪声和无噪声设置中都展示了增强的性能。代码可在 https://github.com/junkangwu/Dr_DPO 获得。

##### **Generative Image as Action Models**
2407.07875v1 by Mohit Shridhar, Yat Long Lo, Stephen James

Image-generation diffusion models have been fine-tuned to unlock new
capabilities such as image-editing and novel view synthesis. Can we similarly
unlock image-generation models for visuomotor control? We present GENIMA, a
behavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'
as targets on RGB images. These images are fed into a controller that maps the
visual targets into a sequence of joint-positions. We study GENIMA on 25
RLBench and 9 real-world manipulation tasks. We find that, by lifting actions
into image-space, internet pre-trained diffusion models can generate policies
that outperform state-of-the-art visuomotor approaches, especially in
robustness to scene perturbations and generalizing to novel objects. Our method
is also competitive with 3D agents, despite lacking priors such as depth,
keypoints, or motion-planners.

摘要：影像產生擴散模型已經經過微調以解鎖新的能力，例如影像編輯和新視圖合成。我們能用類似的方式解鎖影像產生模型用於視動控制嗎？我們提出 GENIMA，一種行為複製代理，它微調 Stable Diffusion 以在 RGB 影像上「繪製關節動作」作為目標。這些影像會輸入到控制器中，控制器會將視覺目標對應到一系列關節位置。我們在 25 個 RLBench 和 9 個真實世界的操作任務中研究 GENIMA。我們發現，透過將動作提升到影像空間，網際網路預訓練擴散模型可以產生策略，其表現優於最先進的視動控制方法，尤其是在場景擾動的穩健性以及對新物體的泛化方面。我們的模型即使缺乏深度、關鍵點或動作規劃器等先驗知識，也能與 3D 代理競爭。

##### **Toto: Time Series Optimized Transformer for Observability**
2407.07874v2 by Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal

This technical report describes the Time Series Optimized Transformer for
Observability (Toto), a new state of the art foundation model for time series
forecasting developed by Datadog. In addition to advancing the state of the art
on generalized time series benchmarks in domains such as electricity and
weather, this model is the first general-purpose time series forecasting
foundation model to be specifically tuned for observability metrics.
  Toto was trained on a dataset of one trillion time series data points, the
largest among all currently published time series foundation models. Alongside
publicly available time series datasets, 75% of the data used to train Toto
consists of fully anonymous numerical metric data points from the Datadog
platform.
  In our experiments, Toto outperforms existing time series foundation models
on observability data. It does this while also excelling at general-purpose
forecasting tasks, achieving state-of-the-art zero-shot performance on multiple
open benchmark datasets.

摘要：這份技術報告描述了觀測時間序列最佳化Transformer (Toto)，這是一個由 Datadog 開發的新型時間序列預測基礎模型。除了提升電力和天氣等領域的廣泛時間序列基準的技術水準外，這個模型也是第一個專門針對可觀察性指標調整的通用時間序列預測基礎模型。

Toto 是以一個擁有 1 兆筆時間序列資料點的資料集訓練而成的，在目前已發布的所有時間序列基礎模型中規模最大。除了公開的時間序列資料集，用於訓練 Toto 的資料有 75% 來自 Datadog 平台的完全匿名數值指標資料點。

在我們的實驗中，Toto 在可觀察性資料上勝過現有的時間序列基礎模型。它在執行此操作的同時，也在通用預測任務中表現出色，在多個開放基準資料集上達成最先進的零次學習效能。

##### **FACTS About Building Retrieval Augmented Generation-based Chatbots**
2407.07858v1 by Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano

Enterprise chatbots, powered by generative AI, are emerging as key
applications to enhance employee productivity. Retrieval Augmented Generation
(RAG), Large Language Models (LLMs), and orchestration frameworks like
Langchain and Llamaindex are crucial for building these chatbots. However,
creating effective enterprise chatbots is challenging and requires meticulous
RAG pipeline engineering. This includes fine-tuning embeddings and LLMs,
extracting documents from vector databases, rephrasing queries, reranking
results, designing prompts, honoring document access controls, providing
concise responses, including references, safeguarding personal information, and
building orchestration agents. We present a framework for building RAG-based
chatbots based on our experience with three NVIDIA chatbots: for IT/HR
benefits, financial earnings, and general content. Our contributions are
three-fold: introducing the FACTS framework (Freshness, Architectures, Cost,
Testing, Security), presenting fifteen RAG pipeline control points, and
providing empirical results on accuracy-latency tradeoffs between large and
small LLMs. To the best of our knowledge, this is the first paper of its kind
that provides a holistic view of the factors as well as solutions for building
secure enterprise-grade chatbots."

摘要：由生成式 AI 驅動的企業聊天機器人，正作為提升員工生產力的關鍵應用程式浮現。檢索擴充生成 (RAG)、大型語言模型 (LLM) 和 Langchain 與 Llamaindex 等編排架構對於建構這些聊天機器人至關重要。然而，建立有效的企業聊天機器人具有挑戰性，需要細緻的 RAG 管道工程。這包括微調嵌入和 LLM、從向量資料庫中萃取文件、改寫查詢、重新排列結果、設計提示、遵守文件存取控制、提供簡潔的回應、包括參考資料、保障個人資訊，以及建構編排代理。我們根據在 NVIDIA 的三個聊天機器人（針對 IT/HR 福利、財務收益和一般內容）的經驗，提出了一個建構基於 RAG 的聊天機器人的架構。我們的貢獻有三方面：引入 FACTS 架構（新鮮度、架構、成本、測試、安全性）、提出十五個 RAG 管道控制點，以及提供大型和小型 LLM 之間準確度-延遲權衡的經驗結果。據我們所知，這是第一篇提供全面觀點的論文，探討建構安全企業級聊天機器人的因素和解決方案。

##### **Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers**
2407.07848v1 by Cody Wild, Jesper Anderson

Previous work has demonstrated that MLPs within ReLU Transformers exhibit
high levels of sparsity, with many of their activations equal to zero for any
given token. We build on that work to more deeply explore how token-level
sparsity evolves over the course of training, and how it connects to broader
sparsity patterns over the course of a sequence or batch, demonstrating that
the different layers within small transformers exhibit distinctly
layer-specific patterns on both of these fronts. In particular, we demonstrate
that the first and last layer of the network have distinctive and in many ways
inverted relationships to sparsity, and explore implications for the structure
of feature representations being learned at different depths of the model. We
additionally explore the phenomenon of ReLU dimensions "turning off", and show
evidence suggesting that "neuron death" is being primarily driven by the
dynamics of training, rather than simply occurring randomly or accidentally as
a result of outliers.

摘要：先前的研究表明，ReLU Transformer 中的 MLP 具有高度的稀疏性，其中许多激活对于任何给定的标记都等于零。我们基于这项研究更深入地探讨标记级稀疏性如何在训练过程中演变，以及它如何连接到序列或批次过程中的更广泛稀疏性模式，证明小 Transformer 中的不同层在这些方面都表现出明显不同的特定于层的模式。特别是，我们证明网络的第一层和最后一层具有独特且在许多方面与稀疏性成反比的关系，并探讨对在模型的不同深度处学习的特征表示的结构的影响。我们还探讨了 ReLU 维度“关闭”的现象，并展示了证据表明“神经元死亡”主要是由训练动态驱动的，而不是仅仅由于异常值而随机或偶然发生的。

##### **Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison**
2407.07840v1 by Qian Yang, Weixiang Yan, Aishwarya Agrawal

Despite tremendous advancements, current state-of-the-art Vision-Language
Models (VLMs) are still far from perfect. They tend to hallucinate and may
generate biased responses. In such circumstances, having a way to assess the
reliability of a given response generated by a VLM is quite useful. Existing
methods, such as estimating uncertainty using answer likelihoods or
prompt-based confidence generation, often suffer from overconfidence. Other
methods use self-consistency comparison but are affected by confirmation
biases. To alleviate these, we propose \textbf{De}compose and \textbf{C}ompare
\textbf{C}onsistency (\texttt{DeCC}) for reliability measurement. By comparing
the consistency between the direct answer generated using the VLM's internal
reasoning process, and the indirect answers obtained by decomposing the
question into sub-questions and reasoning over the sub-answers produced by the
VLM, \texttt{DeCC} measures the reliability of VLM's direct answer. Experiments
across six vision-language tasks with three VLMs show \texttt{DeCC}'s
reliability estimation achieves better correlation with task accuracy compared
to the existing methods.

摘要：儘管有長足的進展，目前的最新視覺語言模型（VLM）仍遠未完美。它們傾向於產生幻覺，並且可能會產生有偏見的回應。在這種情況下，有一種方法可以評估 VLM 生成的特定回應的可靠性非常有用。現有的方法，例如使用答案可能性估計不確定性或基於提示的信心生成，通常會過於自信。其他方法使用自我一致性比較，但會受到確認偏誤的影響。為了緩解這些問題，我們提出\textbf{分}解和\textbf{比}較\textbf{一}致性（\texttt{DeCC}）以進行可靠性測量。透過比較使用 VLM 內部推理過程產生的直接答案與透過將問題分解成子問題並對 VLM 產生的子答案進行推理而獲得的間接答案之間的一致性，\texttt{DeCC} 測量 VLM 直接答案的可靠性。使用三個 VLM 進行的六項視覺語言任務的實驗表明，與現有方法相比，\texttt{DeCC} 的可靠性估計與任務準確性具有更好的相關性。

##### **RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation**
2407.07835v1 by Tao Li, Ruihang Li, Huangnan Zheng, Shanding Ye, Shijian Li, Zhijie Pan

Automated 3D city generation, focusing on road networks and building layouts,
is in high demand for applications in urban design, multimedia games and
autonomous driving simulations. The surge of generative AI facilitates
designing city layouts based on deep learning models. However, the lack of
high-quality datasets and benchmarks hinders the progress of these data-driven
methods in generating road networks and building layouts. Furthermore, few
studies consider urban characteristics, which generally take graphics as
analysis objects and are crucial for practical applications, to control the
generative process. To alleviate these problems, we introduce a multimodal
dataset with accompanying evaluation metrics for controllable generation of
Road networks and Building layouts (RoBus), which is the first and largest
open-source dataset in city generation so far. RoBus dataset is formatted as
images, graphics and texts, with $72,400$ paired samples that cover around
$80,000km^2$ globally. We analyze the RoBus dataset statistically and validate
the effectiveness against existing road networks and building layouts
generation methods. Additionally, we design new baselines that incorporate
urban characteristics, such as road orientation and building density, in the
process of generating road networks and building layouts using the RoBus
dataset, enhancing the practicality of automated urban design. The RoBus
dataset and related codes are published at
https://github.com/tourlics/RoBus_Dataset.

摘要：自動化 3D 城市生成，專注於道路網路和建築物配置，
在城市設計、多媒體遊戲和自動駕駛模擬中廣受歡迎。生成式 AI 的激增促進
基於深度學習模型設計城市配置。然而，缺乏
高品質的資料集和基準阻礙了這些資料驅動
方法在生成道路網路和建築物配置方面的進展。此外，很少
研究考慮城市特徵，這些特徵通常將圖形作為
分析物件，並且對於實際應用至關重要，以控制
生成過程。為了緩解這些問題，我們引入了多模式
資料集，並附有評估指標，用於可控生成
道路網路和建築物配置 (RoBus)，這是目前第一個也是最大的
開放原始碼城市生成資料集。RoBus 資料集格式化為
影像、圖形和文字，配對樣本數為 $72,400$，涵蓋全球約
$80,000km^2$。我們對 RoBus 資料集進行統計分析，並驗證
其對現有道路網路和建築物配置的有效性
生成方法。此外，我們設計了新的基準，將
城市特徵，例如道路方向和建築物密度，納入
使用 RoBus 生成道路網路和建築物配置的過程中
資料集，增強自動化城市設計的實用性。 RoBus
資料集和相關程式碼已發布於
https://github.com/tourlics/RoBus_Dataset。

##### **Transformer Alignment in Large Language Models**
2407.07810v1 by Murdock Aubry, Haoming Meng, Anton Sugolov, Vardan Papyan

Large Language Models (LLMs) have made significant strides in natural
language processing, and a precise understanding of the internal mechanisms
driving their success is essential. We regard LLMs as transforming embeddings
via a discrete, coupled, nonlinear, dynamical system in high dimensions. This
perspective motivates tracing the trajectories of individual tokens as they
pass through transformer blocks, and linearizing the system along these
trajectories through their Jacobian matrices. In our analysis of 38 openly
available LLMs, we uncover the alignment of top left and right singular vectors
of Residual Jacobians, as well as the emergence of linearity and layer-wise
exponential growth. Notably, we discover that increased alignment
$\textit{positively correlates}$ with model performance. Metrics evaluated
post-training show significant improvement in comparison to measurements made
with randomly initialized weights, highlighting the significant effects of
training in transformers. These findings reveal a remarkable level of
regularity that has previously been overlooked, reinforcing the dynamical
interpretation and paving the way for deeper understanding and optimization of
LLM architectures.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了重大進展，而準確理解推動其成功的內部機制至關重要。我們將 LLM 視為通過高維度的離散、耦合、非線性動態系統轉換嵌入。這種觀點激勵我們追蹤個別符號在通過變換器區塊時的軌跡，並通過其雅可比矩陣沿這些軌跡對系統進行線性化。在我們對 38 個公開可用的 LLM 的分析中，我們發現了殘差雅可比矩陣的左奇異向量和右奇異向量的對齊，以及線性和逐層指數增長的出現。值得注意的是，我們發現增加對齊度會與模型性能呈正相關。與使用隨機初始化權重進行的測量相比，訓練後評估的指標顯示出顯著改進，突出了Transformer訓練的顯著影響。這些發現揭示了一個以前被忽視的顯著規律性，加強了動態解釋，並為 LLM 架構的更深入理解和優化鋪平了道路。

##### **ROSA: Random Subspace Adaptation for Efficient Fine-Tuning**
2407.07802v1 by Marawan Gamal Abdel Hameed, Aristides Milios, Siva Reddy, Guillaume Rabusseau

Model training requires significantly more memory, compared with inference.
Parameter efficient fine-tuning (PEFT) methods provide a means of adapting
large models to downstream tasks using less memory. However, existing methods
such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce
latency overhead at inference time or achieve subpar downstream performance
compared with full fine-tuning. In this work we propose Random Subspace
Adaptation (ROSA), a method that outperforms previous PEFT methods by a
significant margin, while maintaining a zero latency overhead during inference
time. In contrast to previous methods, ROSA is able to adapt subspaces of
arbitrarily large dimension, better approximating full-finetuning. We
demonstrate both theoretically and experimentally that this makes ROSA strictly
more expressive than LoRA, without consuming additional memory during runtime.
As PEFT methods are especially useful in the natural language processing
domain, where models operate on scales that make full fine-tuning very
expensive, we evaluate ROSA in two common NLP scenarios: natural language
generation (NLG) and natural language understanding (NLU) with GPT-2 and
RoBERTa, respectively. We show that on almost every GLUE task ROSA outperforms
LoRA by a significant margin, while also outperforming LoRA on NLG tasks. Our
code is available at https://github.com/rosa-paper/rosa

摘要：模型訓練需要顯著更多的記憶體，與推理相比。
參數高效微調 (PEFT) 方法提供了一種使用較少記憶體將大型模型適應於下游任務的方法。然而，現有的方法，例如適配器、提示調整或低秩適應 (LoRA)，會在推理時引入延遲開銷，或與完全微調相比，達到次佳的下游效能。在這項工作中，我們提出隨機子空間適應 (ROSA)，一種方法，它在顯著的幅度上優於先前的 PEFT 方法，同時在推理時維持零延遲開銷。與先前的 PEFT 方法不同，ROSA 能夠適應任意大維度的子空間，更好地近似完全微調。我們在理論上和實驗上證明，這使得 ROSA 在不消耗額外執行時間記憶體的情況下，比 LoRA 更具表現力。由於 PEFT 方法在自然語言處理領域特別有用，在該領域模型在規模上運作，使得完全微調非常昂貴，我們在兩種常見的 NLP 場景中評估 ROSA：自然語言生成 (NLG) 和自然語言理解 (NLU)，分別使用 GPT-2 和 RoBERTa。我們表明，在幾乎每個 GLUE 任務中，ROSA 都以顯著的幅度優於 LoRA，同時也在 NLG 任務中優於 LoRA。我們的程式碼可在 https://github.com/rosa-paper/rosa 取得

##### **AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning**
2407.07801v2 by Jongsuk Kim, Jiwon Shin, Junmo Kim

In recent years, advancements in representation learning and language models
have propelled Automated Captioning (AC) to new heights, enabling the
generation of human-level descriptions. Leveraging these advancements, we
propose AVCap, an Audio-Visual Captioning framework, a simple yet powerful
baseline approach applicable to audio-visual captioning. AVCap utilizes
audio-visual features as text tokens, which has many advantages not only in
performance but also in the extensibility and scalability of the model. AVCap
is designed around three pivotal dimensions: the exploration of optimal
audio-visual encoder architectures, the adaptation of pre-trained models
according to the characteristics of generated text, and the investigation into
the efficacy of modality fusion in captioning. Our method outperforms existing
audio-visual captioning methods across all metrics and the code is available on
https://github.com/JongSuk1/AVCap

摘要：近年來，表示學習和語言模型的進展已將自動字幕 (AC) 推升至新的高度，實現了人類等級描述的產生。利用這些進展，我們提出 AVCap，一個音訊視覺字幕框架，一個適用於音訊視覺字幕的簡單但強大的基線方法。AVCap 利用音訊視覺特徵作為文字符號，這不僅在效能方面，而且在模型的可擴充性和可擴充性方面都有許多優點。AVCap 的設計圍繞三個關鍵面向：最佳音訊視覺編碼器架構的探索、根據產生文字的特徵調整預先訓練的模型，以及調查字幕中模態融合的效能。我們的模型在所有指標上都優於現有的音訊視覺字幕方法，且程式碼可於 https://github.com/JongSuk1/AVCap 取得

##### **Attribute or Abstain: Large Language Models as Long Document Assistants**
2407.07799v1 by Jan Buchmann, Xiao Liu, Iryna Gurevych

LLMs can help humans working with long documents, but are known to
hallucinate. Attribution can increase trust in LLM responses: The LLM provides
evidence that supports its response, which enhances verifiability. Existing
approaches to attribution have only been evaluated in RAG settings, where the
initial retrieval confounds LLM performance. This is crucially different from
the long document setting, where retrieval is not needed, but could help. Thus,
a long document specific evaluation of attribution is missing. To fill this
gap, we present LAB, a benchmark of 6 diverse long document tasks with
attribution, and experiment with different approaches to attribution on 4 LLMs
of different sizes, both prompted and fine-tuned. We find that citation, i.e.
response generation and evidence extraction in one step, mostly performs best.
We investigate whether the ``Lost in the Middle'' phenomenon exists for
attribution, but do not find this. We also find that evidence quality can
predict response quality on datasets with simple responses, but not so for
complex responses, as models struggle with providing evidence for complex
claims. We release code and data for further investigation.

摘要：大型語言模型可以幫助人類處理長篇文件，但它們會出現幻覺。標示出處可以增加對大型語言模型回應的信任：大型語言模型提供了支持其回應的證據，這增強了可驗證性。現有的歸因方法僅在 RAG 設定中進行評估，其中初始檢索會混淆大型語言模型的效能。這與不需要檢索但可能有所幫助的長篇文件設定有根本上的不同。因此，缺少針對長篇文件的特定歸因評估。為了填補這個空白，我們提出了 LAB，這是一個包含 6 項不同長篇文件任務的基準，並在 4 個不同規模的大型語言模型上嘗試不同的歸因方法，包括提示式和微調。我們發現引文，即一步完成回應產生和證據提取，通常表現最佳。我們探討了「迷失在中間」現象是否存在於歸因中，但沒有發現。我們還發現，在回應簡單的資料集上，證據品質可以預測回應品質，但對於複雜的回應則不然，因為模型難以提供複雜說法的證據。我們釋出程式碼和資料以供進一步探討。

##### **Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard**
2407.07796v2 by Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper

We introduce a novel and extensible benchmark for large language models
(LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.
The open-source game simulation code, available on GitHub, allows LLMs to
compete and generates detailed data files in JSON, CSV, TXT, and PNG formats
for leaderboard rankings and further analysis. We present the results of games
among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by
Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and
GPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of
results from other LLMs. In total, we simulated 2,310 matches (5 sessions for
each pair among 7 LLMs and a random player) across three types of games, using
three distinct prompt types: list, illustration, and image. The results
revealed significant variations in LLM performance across different games and
prompt types, with analysis covering win and disqualification rates, missed
opportunity analysis, and invalid move analysis. The details of the leaderboard
and result matrix data are available as open-access data on GitHub. This study
enhances our understanding of LLMs' capabilities in playing games they were not
specifically trained for, helping to assess their rule comprehension and
strategic thinking. On the path to Artificial General Intelligence (AGI), this
study lays the groundwork for future exploration into their utility in complex
decision-making scenarios, illuminating their strategic thinking abilities and
offering directions for further inquiry into the limits of LLMs within
game-based frameworks.

摘要：<paragraph>我們透過格線遊戲，例如井字遊戲、四連線和五子棋，為大型語言模型 (LLM) 引入一個新穎且可擴充的基準。
開放原始碼的遊戲模擬程式碼，可在 GitHub 上取得，允許 LLM 競爭並產生 JSON、CSV、TXT 和 PNG 格式的詳細資料檔案，以供排行榜排名和進一步分析。我們展示了領先 LLM 之間的遊戲結果，包括 Anthropic 的 Claude 3.5 Sonnet 和 Claude 3 Sonnet、Google 的 Gemini 1.5 Pro 和 Gemini 1.5 Flash、OpenAI 的 GPT-4 Turbo 和 GPT-4o，以及 Meta 的 Llama3-70B。我們也鼓勵提交其他 LLM 的結果。總計，我們模擬了 2,310 場比賽（7 個 LLM 和一位隨機玩家之間的 5 場比賽），使用三種不同類型的遊戲和三種不同的提示類型：清單、插圖和影像。結果顯示，不同遊戲和提示類型之間的 LLM 效能存在顯著差異，分析涵蓋獲勝率和取消資格率、錯失機會分析和無效移動分析。排行榜和結果矩陣資料的詳細資訊以開放取用的資料形式在 GitHub 上提供。這項研究增進了我們對 LLM 在未針對其進行特定訓練的遊戲中進行遊戲的能力的了解，有助於評估其規則理解和策略思考。在通往人工通用智慧 (AGI) 的道路上，這項研究為未來探索其在複雜決策情境中的效用奠定了基礎，闡明了其策略思考能力，並為進一步探究 LLM 在基於遊戲的架構中的限制提供了方向。</paragraph>

##### **Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities**
2407.07791v1 by Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu

The rapid adoption of large language models (LLMs) in multi-agent systems has
highlighted their impressive capabilities in various applications, such as
collaborative problem-solving and autonomous negotiation. However, the security
implications of these LLM-based multi-agent systems have not been thoroughly
investigated, particularly concerning the spread of manipulated knowledge. In
this paper, we investigate this critical issue by constructing a detailed
threat model and a comprehensive simulation environment that mirrors real-world
multi-agent deployments in a trusted platform. Subsequently, we propose a novel
two-stage attack method involving Persuasiveness Injection and Manipulated
Knowledge Injection to systematically explore the potential for manipulated
knowledge (i.e., counterfactual and toxic knowledge) spread without explicit
prompt manipulation.
  Our method leverages the inherent vulnerabilities of LLMs in handling world
knowledge, which can be exploited by attackers to unconsciously spread
fabricated information. Through extensive experiments, we demonstrate that our
attack method can successfully induce LLM-based agents to spread both
counterfactual and toxic knowledge without degrading their foundational
capabilities during agent communication. Furthermore, we show that these
manipulations can persist through popular retrieval-augmented generation
frameworks, where several benign agents store and retrieve manipulated chat
histories for future interactions. This persistence indicates that even after
the interaction has ended, the benign agents may continue to be influenced by
manipulated knowledge. Our findings reveal significant security risks in
LLM-based multi-agent systems, emphasizing the imperative need for robust
defenses against manipulated knowledge spread, such as introducing ``guardian''
agents and advanced fact-checking tools.

摘要：大型語言模型 (LLM) 在多主體系統中的快速採用突顯了它們在各種應用中的驚人功能，例如協作問題解決和自主協商。然而，這些基於 LLM 的多主體系統的安全性影響尚未得到徹底調查，特別是關於操縱知識的傳播。在本文中，我們通過構建一個詳細的威脅模型和一個全面的模擬環境來調查這個關鍵問題，該環境反映了在受信任平台中真實世界的多主體部署。隨後，我們提出了一種新穎的兩階段攻擊方法，涉及說服力注入和操縱知識注入，以系統地探索操縱知識（即反事實和有毒知識）在沒有明確提示操縱的情況下傳播的可能性。
我們的辦法利用了 LLM 在處理世界知識時固有的漏洞，攻擊者可以利用這些漏洞無意識地傳播虛假信息。通過廣泛的實驗，我們證明了我們的攻擊方法可以成功地誘導基於 LLM 的代理傳播反事實和有毒知識，而不會在代理通信過程中降低其基礎能力。此外，我們表明，這些操縱可以通過流行的檢索增強生成框架持續存在，在該框架中，幾個良性代理存儲和檢索操縱的聊天記錄以供將來交互。這種持續性表明，即使在交互結束後，良性代理仍可能繼續受到操縱知識的影響。我們的發現揭示了基於 LLM 的多主體系統中存在的重大安全風險，強調了對抗操縱知識傳播的強大防禦措施的迫切需要，例如引入``守護者''代理和先進的事實核查工具。

##### **WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment**
2407.07778v1 by Jiefu Ou, Arda Uzunoglu, Benjamin Van Durme, Daniel Khashabi

AI systems make decisions in physical environments through primitive actions
or affordances that are accessed via API calls. While deploying AI agents in
the real world involves numerous high-level actions, existing embodied
simulators offer a limited set of domain-salient APIs. This naturally brings up
the questions: how many primitive actions (APIs) are needed for a versatile
embodied agent, and what should they look like? We explore this via a thought
experiment: assuming that wikiHow tutorials cover a wide variety of
human-written tasks, what is the space of APIs needed to cover these
instructions? We propose a framework to iteratively induce new APIs by
grounding wikiHow instruction to situated agent policies. Inspired by recent
successes in large language models (LLMs) for embodied planning, we propose a
few-shot prompting to steer GPT-4 to generate Pythonic programs as agent
policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and
then 2) fabricate new API calls when necessary. The focus of this thought
experiment is on defining these APIs rather than their executability. We apply
the proposed pipeline on instructions from wikiHow tutorials. On a small
fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary
for capturing the rich variety of tasks in the physical world. A detailed
automatic and human analysis of the induction output reveals that the proposed
pipeline enables effective reuse and creation of APIs. Moreover, a manual
review revealed that existing simulators support only a small subset of the
induced APIs (9 of the top 50 frequent APIs), motivating the development of
action-rich embodied environments.

摘要：人工智能系統透過基本動作或可透過 API 呼叫存取的便利功能在實際環境中做出決策。雖然在現實世界中部署 AI 代理會涉及許多高階動作，但現有的具體模擬器僅提供有限的領域顯著 API。這自然會引發疑問：一個多功能的具體代理需要多少基本動作 (API)，它們應該是什麼樣子？我們透過一個思想實驗來探討這一點：假設 wikiHow 教學涵蓋了各種各樣的人類書寫任務，那麼涵蓋這些說明所需的 API 空間是什麼？我們提出一個架構，透過將 wikiHow 說明與具體代理政策相結合，反覆誘導出新的 API。受到大型語言模型 (LLM) 在具體規劃中近期成功的啟發，我們提出一個少次提示，引導 GPT-4 生成 Pythonic 程式作為代理政策，並透過 1) 重複使用一組種子 API，然後 2) 在必要時捏造新的 API 呼叫來引導大量的 API。這個思想實驗的重點在於定義這些 API，而不是它們的可執行性。我們將提議的管道應用於 wikiHow 教學的說明。在教學的一小部分 (0.5%) 中，我們誘導出一個包含 300 多個 API 的動作空間，這些 API 對於捕捉現實世界中豐富多樣的任務是必要的。對誘導輸出的詳細自動和人工分析顯示，提議的管道可以有效地重複使用和建立 API。此外，手動檢閱顯示現有的模擬器僅支援誘導 API 的一小部分 (前 50 個頻繁 API 中的 9 個)，這促使開發動作豐富的具體環境。

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v1 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin.

摘要：<paragraph>導航研究中一個難以捉摸的目標是建立一個智慧代理，它
可以理解包含自然語言和影像的多模態指令，並執行有用的導航。為了達成這個目標，我們研究了一個廣泛有用的導航任務類別，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的最新進展在實現這個目標方面展現了一條有希望的道路，因為它展示了感知和推理多模態輸入的能力。
然而，VLM 通常被訓練來預測文字輸出，而如何最佳地將它們用於導航是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它將示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標畫面。接下來，低階政策使用目標畫面和離線建構的拓撲圖在每個時間步產生機器人動作。我們在一個 836 平方公尺的真實世界環境中評估了 Mobility VLA，並顯示 Mobility VLA 在以前無法解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」並拿著一個塑膠箱）上具有很高的端到端成功率。</paragraph>

##### **Learning Spatial-Semantic Features for Robust Video Object Segmentation**
2407.07760v1 by Xin Li, Deshui Miao, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang

Tracking and segmenting multiple similar objects with complex or separate
parts in long-term videos is inherently challenging due to the ambiguity of
target parts and identity confusion caused by occlusion, background clutter,
and long-term variations. In this paper, we propose a robust video object
segmentation framework equipped with spatial-semantic features and
discriminative object queries to address the above issues. Specifically, we
construct a spatial-semantic network comprising a semantic embedding block and
spatial dependencies modeling block to associate the pretrained ViT features
with global semantic features and local spatial features, providing a
comprehensive target representation. In addition, we develop a masked
cross-attention module to generate object queries that focus on the most
discriminative parts of target objects during query propagation, alleviating
noise accumulation and ensuring effective long-term query propagation. The
experimental results show that the proposed method set a new state-of-the-art
performance on multiple datasets, including the DAVIS2017 test (89.1%),
YoutubeVOS 2019 (88.5%), MOSE (75.1%), LVOS test (73.0%), and LVOS val (75.1%),
which demonstrate the effectiveness and generalization capacity of the proposed
method. We will make all source code and trained models publicly available.

摘要：由於目標部分的模糊性以及遮擋、背景雜訊和長期變化造成的身份混淆，在長期影片中追蹤和區分多個相似物體（具有複雜或分開的部分）本質上具有挑戰性。在本文中，我們提出了一個穩健的影片物件分割架構，配備了空間語義特徵和辨別式物件查詢，以解決上述問題。具體來說，我們建構了一個空間語義網路，包括語義嵌入區塊和空間依賴性建模區塊，以將預訓練的 ViT 特徵與全域語義特徵和局部空間特徵關聯起來，提供全面的目標表示。此外，我們開發了一個遮罩交叉注意力模組，以產生在查詢傳播期間專注於目標物件最具辨別力的部分的物件查詢，減輕雜訊累積並確保有效的長期查詢傳播。實驗結果顯示，所提出的方法在多個資料集上設定了新的最先進效能，包括 DAVIS2017 測試 (89.1%)、YoutubeVOS 2019 (88.5%)、MOSE (75.1%)、LVOS 測試 (73.0%) 和 LVOS val (75.1%)，證明了所提出方法的有效性和泛化能力。我們將公開所有原始碼和訓練過的模型。

##### **Fine-Tuning Large Language Models with User-Level Differential Privacy**
2407.07737v1 by Zachary Charles, Arun Ganesh, Ryan McKenna, H. Brendan McMahan, Nicole Mitchell, Krishna Pillutla, Keith Rush

We investigate practical and scalable algorithms for training large language
models (LLMs) with user-level differential privacy (DP) in order to provably
safeguard all the examples contributed by each user. We study two variants of
DP-SGD with: (1) example-level sampling (ELS) and per-example gradient
clipping, and (2) user-level sampling (ULS) and per-user gradient clipping. We
derive a novel user-level DP accountant that allows us to compute provably
tight privacy guarantees for ELS. Using this, we show that while ELS can
outperform ULS in specific settings, ULS generally yields better results when
each user has a diverse collection of examples. We validate our findings
through experiments in synthetic mean estimation and LLM fine-tuning tasks
under fixed compute budgets. We find that ULS is significantly better in
settings where either (1) strong privacy guarantees are required, or (2) the
compute budget is large. Notably, our focus on LLM-compatible training
algorithms allows us to scale to models with hundreds of millions of parameters
and datasets with hundreds of thousands of users.

摘要：我們探討了用使用者層級差分隱私 (DP) 訓練大型語言模型 (LLM) 的實用且可擴充的演算法，以證明保護每個使用者貢獻的所有範例。我們研究了 DP-SGD 的兩個變體：(1) 範例層級抽樣 (ELS) 和每個範例梯度裁剪，以及 (2) 使用者層級抽樣 (ULS) 和每個使用者梯度裁剪。我們推導了一個新穎的使用者層級 DP 會計員，允許我們計算出 ELS 的可證明嚴格隱私保證。使用這個方法，我們顯示 ELS 可以在特定設定中優於 ULS，而當每個使用者都有多樣化的範例集合時，ULS 通常會產生更好的結果。我們透過在固定運算預算下的合成平均估計和 LLM 微調任務中進行實驗來驗證我們的發現。我們發現 ULS 在 (1) 需要強隱私保證或 (2) 運算預算很大的設定中顯著較好。值得注意的是，我們專注於 LLM 相容的訓練演算法，使我們能夠擴充到具有數億個參數和數十萬使用者的資料集的模型。

##### **SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis**
2407.07728v2 by Zihao Wang, Le Ma, Yan Liu, Kejun Zhang

Singing voice conversion (SVC) aims to convert a singer's voice in a given
music piece to another singer while keeping the original content. We propose an
end-to-end feature disentanglement-based model, which we named SaMoye, to
enable zero-shot many-to-many singing voice conversion. SaMoye disentangles the
features of the singing voice into content features, timbre features, and pitch
features respectively. The content features are enhanced using a GPT-based
model to perform cross-prediction with the phoneme of the lyrics. SaMoye can
generate the music with converted voice by replacing the timbre features with
the target singer. We also establish an unparalleled large-scale dataset to
guarantee zero-shot performance. The dataset consists of 1500k pure singing
vocal clips containing at least 10,000 singers.

摘要：歌唱聲音轉換 (SVC) 旨在將給定音樂片段中的歌手聲音轉換為另一位歌手，同時保留原始內容。我們提出了一個端到端的特徵解糾纏模型，我們將其命名為 SaMoye，以實現零次學習多對多歌唱聲音轉換。SaMoye 將歌唱聲音的特徵解糾纏為內容特徵、音色特徵和音高特徵。內容特徵使用基於 GPT 的模型進行增強，以對歌詞音素執行交叉預測。SaMoye 可以通過用目標歌手的音色特徵替換音色特徵來生成轉換聲音的音樂。我們還建立了一個無與倫比的大規模數據集，以保證零次學習性能。該數據集包含 1500k 個純歌唱聲樂片段，包含至少 10,000 名歌手。

##### **PaliGemma: A versatile 3B VLM for transfer**
2407.07726v1 by Lucas Beyer, Andreas Steiner, André Susano Pinto, Alexander Kolesnikov, Xiao Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael Tschannen, Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula, Fangyu Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby, Manoj Kumar, Keran Rong, Julian Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bošnjak, Xi Chen, Matthias Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic, Joan Puigcerver, Pinelopi Papalampidi, Olivier Henaff, Xi Xiong, Radu Soricut, Jeremiah Harmsen, Xiaohua Zhai

PaliGemma is an open Vision-Language Model (VLM) that is based on the
SigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to
be a versatile and broadly knowledgeable base model that is effective to
transfer. It achieves strong performance on a wide variety of open-world tasks.
We evaluate PaliGemma on almost 40 diverse tasks including standard VLM
benchmarks, but also more specialized tasks such as remote-sensing and
segmentation.

摘要：PaliGemma 是一種開放的視覺語言模型 (VLM)，它基於 SigLIP-So400m 視覺編碼器和 Gemma-2B 語言模型。它的訓練目標是成為一個通用且知識淵博的基本模型，能夠有效轉移。它在廣泛的開放世界任務中都取得了強勁的表現。我們在近 40 項不同的任務中評估 PaliGemma，包括標準 VLM 基準，以及更專業的任務，例如遙感和分割。

##### **Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control**
2407.07684v1 by Elahe Delavari, John Moore, Junho Hong, Jaerock Kwon

This paper presents a novel approach to Autonomous Vehicle (AV) control
through the application of active inference, a theory derived from neuroscience
that conceptualizes the brain as a predictive machine. Traditional autonomous
driving systems rely heavily on Modular Pipelines, Imitation Learning, or
Reinforcement Learning, each with inherent limitations in adaptability,
generalization, and computational efficiency. Active inference addresses these
challenges by minimizing prediction error (termed "surprise") through a dynamic
model that balances perception and action. Our method integrates active
inference with deep learning to manage lateral control in AVs, enabling them to
perform lane following maneuvers within a simulated urban environment. We
demonstrate that our model, despite its simplicity, effectively learns and
generalizes from limited data without extensive retraining, significantly
reducing computational demands. The proposed approach not only enhances the
adaptability and performance of AVs in dynamic scenarios but also aligns
closely with human-like driving behavior, leveraging a generative model to
predict and adapt to environmental changes. Results from extensive experiments
in the CARLA simulator show promising outcomes, outperforming traditional
methods in terms of adaptability and efficiency, thereby advancing the
potential of active inference in real-world autonomous driving applications.

摘要：本論文提出了一種自駕車 (AV) 控制的新方法，透過主動推論的應用，主動推論是一種源自神經科學的理論，將大腦概念化為一個預測機器。傳統的自動駕駛系統嚴重依賴模組化管線、模仿學習或強化學習，每種方法在適應性、概括性和計算效率方面都有其固有的限制。主動推論透過一個平衡感知和動作的動態模型，將預測誤差（稱為「驚喜」）最小化，來解決這些挑戰。我們的模型將主動推論與深度學習整合，以管理自駕車的橫向控制，讓它們能夠在模擬的城市環境中執行車道追蹤操作。我們證明了我們的模型儘管很簡單，但能有效學習和概括有限的資料，而無需廣泛的重新訓練，大幅減少了計算需求。所提出的方法不僅增強了自駕車在動態場景中的適應性和效能，而且與類人駕駛行為緊密結合，利用生成模型來預測和適應環境變化。在 CARLA 模擬器中進行的廣泛實驗結果顯示了有希望的結果，在適應性和效率方面優於傳統方法，從而提升了主動推論在實際自駕車應用中的潛力。

##### **The Language of Weather: Social Media Reactions to Weather Accounting for Climatic and Linguistic Baselines**
2407.07683v1 by James C. Young, Rudy Arthur, Hywel T. P. Williams

This study explores how different weather conditions influence public
sentiment on social media, focusing on Twitter data from the UK. By considering
climate and linguistic baselines, we improve the accuracy of weather-related
sentiment analysis. Our findings show that emotional responses to weather are
complex, influenced by combinations of weather variables and regional language
differences. The results highlight the importance of context-sensitive methods
for better understanding public mood in response to weather, which can enhance
impact-based forecasting and risk communication in the context of climate
change.

摘要：本研究探討不同天氣狀況如何影響公眾在社群媒體上的情緒，重點放在英國的 Twitter 資料。透過考慮氣候和語言基準，我們改善了與天氣相關的情緒分析的準確性。我們的研究結果顯示，對天氣的情緒反應很複雜，受到天氣變數組合和區域語言差異的影響。這些結果強調了情境敏感方法在更了解公眾對天氣反應的情緒的重要性，這可以加強基於影響的預測和氣候變遷背景下的風險溝通。

##### **Why should we ever automate moral decision making?**
2407.07671v1 by Vincent Conitzer

While people generally trust AI to make decisions in various aspects of their
lives, concerns arise when AI is involved in decisions with significant moral
implications. The absence of a precise mathematical framework for moral
reasoning intensifies these concerns, as ethics often defies simplistic
mathematical models. Unlike fields such as logical reasoning, reasoning under
uncertainty, and strategic decision-making, which have well-defined
mathematical frameworks, moral reasoning lacks a broadly accepted framework.
This absence raises questions about the confidence we can place in AI's moral
decision-making capabilities.
  The environments in which AI systems are typically trained today seem
insufficiently rich for such a system to learn ethics from scratch, and even if
we had an appropriate environment, it is unclear how we might bring about such
learning. An alternative approach involves AI learning from human moral
decisions. This learning process can involve aggregating curated human
judgments or demonstrations in specific domains, or leveraging a foundation
model fed with a wide range of data. Still, concerns persist, given the
imperfections in human moral decision making.
  Given this, why should we ever automate moral decision making -- is it not
better to leave all moral decision making to humans? This paper lays out a
number of reasons why we should expect AI systems to engage in decisions with a
moral component, with brief discussions of the associated risks.

摘要：儘管人們普遍相信 AI 能在生活各方面做出決策，但當 AI 參與涉及重大道德意義的決策時，就會產生疑慮。由於缺乏精確的數學框架來進行道德推理，因此加劇了這些疑慮，因為道德通常不符合簡化的數學模型。與邏輯推理、不確定性推理和策略決策制定等領域不同，這些領域有明確的數學框架，而道德推理卻缺乏廣泛接受的框架。這種缺失引發了我們對 AI 道德決策能力的信心提出質疑。
  AI 系統在當今接受訓練的環境似乎不足以讓此類系統從頭學習道德，即使我們有適當的環境，也不清楚我們如何能實現這種學習。另一種方法涉及 AI 從人類道德決策中學習。此學習過程可能涉及彙整特定領域中經過策劃的人類判斷或示範，或利用提供大量資料的基礎模型。儘管如此，由於人類道德決策制定中的缺陷，疑慮仍然存在。
  有鑑於此，我們為什麼要自動化道德決策制定——難道將所有道德決策制定留給人類不是更好的選擇嗎？本文列出了我們應期待 AI 系統參與具有道德成分的決策的若干原因，並簡要討論相關風險。

##### **How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning**
2407.07668v1 by Giuseppe Serra, Ben Werner, Florian Buettner

Many real-world applications require machine-learning models to be able to
deal with non-stationary data distributions and thus learn autonomously over an
extended period of time, often in an online setting. One of the main challenges
in this scenario is the so-called catastrophic forgetting (CF) for which the
learning model tends to focus on the most recent tasks while experiencing
predictive degradation on older ones. In the online setting, the most effective
solutions employ a fixed-size memory buffer to store old samples used for
replay when training on new tasks. Many approaches have been presented to
tackle this problem. However, it is not clear how predictive uncertainty
information for memory management can be leveraged in the most effective manner
and conflicting strategies are proposed to populate the memory. Are the
easiest-to-forget or the easiest-to-remember samples more effective in
combating CF? Starting from the intuition that predictive uncertainty provides
an idea of the samples' location in the decision space, this work presents an
in-depth analysis of different uncertainty estimates and strategies for
populating the memory. The investigation provides a better understanding of the
characteristics data points should have for alleviating CF. Then, we propose an
alternative method for estimating predictive uncertainty via the generalised
variance induced by the negative log-likelihood. Finally, we demonstrate that
the use of predictive uncertainty measures helps in reducing CF in different
settings.

摘要：許多實際應用都需要機器學習模型能夠處理非平穩資料分佈，並在一段長時間內自主學習，通常是在線上設定中。在這種情況下，主要的挑戰之一是所謂的災難性遺忘 (CF)，學習模型傾向於專注於最新的任務，同時在舊任務上遇到預測性退化。在線上設定中，最有效的解決方案採用固定大小的記憶體緩衝區來儲存用於在訓練新任務時重播的舊範例。已經提出了許多方法來解決這個問題。然而，目前尚不清楚如何以最有效的方式利用預測不確定性資訊進行記憶體管理，並且提出了相互衝突的策略來填充記憶體。最容易遺忘或最容易記住的範例在對抗 CF 中哪個更有效？從預測不確定性提供決策空間中範例位置的想法這個直覺出發，這項工作提出了一個對不同不確定性估計和策略的深入分析，以填充記憶體。這項調查提供了對資料點應具有的特徵以減輕 CF 的更深入了解。然後，我們提出了一種透過負對數似然引發的廣義變異來估計預測不確定性的替代方法。最後，我們證明了使用預測不確定性測量有助於在不同的設定中減少 CF。

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

摘要：一個全面的定性評估架構，適用於醫療保健領域的大型語言模型 (LLM)，其範圍超越傳統的準確度和定量指標。我們提出用於評估 LLM 的 5 個關鍵面向：安全性、共識、客觀性、可複製性和可解釋性 (S.C.O.R.E.)。我們建議 S.C.O.R.E. 可以作為評估架構的基礎，適用於未來的基於 LLM 的模型，這些模型對於醫療保健和臨床應用來說是安全、可靠、值得信賴且合乎道德的。

##### **A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry**
2407.07664v1 by Martin Lindström, Borja Rodríguez-Gálvez, Ragnar Thobaben, Mikael Skoglund

Hyperspherical Prototypical Learning (HPL) is a supervised approach to
representation learning that designs class prototypes on the unit hypersphere.
The prototypes bias the representations to class separation in a scale
invariant and known geometry. Previous approaches to HPL have either of the
following shortcomings: (i) they follow an unprincipled optimisation procedure;
or (ii) they are theoretically sound, but are constrained to only one possible
latent dimension. In this paper, we address both shortcomings. To address (i),
we present a principled optimisation procedure whose solution we show is
optimal. To address (ii), we construct well-separated prototypes in a wide
range of dimensions using linear block codes. Additionally, we give a full
characterisation of the optimal prototype placement in terms of achievable and
converse bounds, showing that our proposed methods are near-optimal.

摘要：超球原型學習 (HPL) 是表示學習的一種監督式方法，它在單位超球面上設計類原型。
原型將表示偏向於類分離，在一個尺度不變且已知的幾何結構中。
先前的 HPL 方法有以下缺點：(i) 它們遵循一個沒有原則的最佳化程序；
或 (ii) 它們在理論上是合理的，但僅限於一個可能的潛在維度。
在本文中，我們將解決這兩個缺點。為了解決 (i)，
我們提出一個有原則的最佳化程序，我們展示其解是最優的。
為了解決 (ii)，我們使用線性區塊碼在廣泛的維度中構建出分離良好的原型。
此外，我們對可實現和相反界限方面的最佳原型放置給出了一個完整的表徵，
表明我們提出的方法接近最佳。

##### **Tuning Vision-Language Models with Candidate Labels by Prompt Alignment**
2407.07638v2 by Zhifang Zhang, Beibei Li

Vision-language models (VLMs) can learn high-quality representations from a
large-scale training dataset of image-text pairs. Prompt learning is a popular
approach to fine-tuning VLM to adapt them to downstream tasks. Despite the
satisfying performance, a major limitation of prompt learning is the demand for
labelled data. In real-world scenarios, we may only obtain candidate labels
(where the true label is included) instead of the true labels due to data
privacy or sensitivity issues. In this paper, we provide the first study on
prompt learning with candidate labels for VLMs. We empirically demonstrate that
prompt learning is more advantageous than other fine-tuning methods, for
handling candidate labels. Nonetheless, its performance drops when the label
ambiguity increases. In order to improve its robustness, we propose a simple
yet effective framework that better leverages the prior knowledge of VLMs to
guide the learning process with candidate labels. Specifically, our framework
disambiguates candidate labels by aligning the model output with the mixed
class posterior jointly predicted by both the learnable and the handcrafted
prompt. Besides, our framework can be equipped with various off-the-shelf
training objectives for learning with candidate labels to further improve their
performance. Extensive experiments demonstrate the effectiveness of our
proposed framework.

摘要：視覺語言模型 (VLM) 能從大型影像文字配對訓練資料集中學習到高品質的表徵。提示學習是一種流行的方法，用於微調 VLM 以適應下游任務。儘管有令人滿意的表現，但提示學習的一大限制是對標記資料的需求。在實際場景中，我們可能只能取得候選標籤（其中包含真實標籤），而不是由於資料隱私或敏感性問題而取得真實標籤。在本文中，我們提供了第一個關於使用候選標籤進行 VLM 提示學習的研究。我們憑經驗證明，對於處理候選標籤而言，提示學習比其他微調方法更有優勢。儘管如此，當標籤模糊性增加時，其效能會下降。為了提高其穩健性，我們提出了一個簡單但有效的架構，它能更好地利用 VLM 的先驗知識來指導使用候選標籤的學習過程。具體來說，我們的架構透過將模型輸出與可學習提示和手工提示共同預測的混合類別後驗機率對齊，來消除候選標籤的歧義。此外，我們的架構可以配備各種現成的訓練目標，以使用候選標籤進行學習，以進一步提高其效能。廣泛的實驗證明了我們提出的架構的有效性。

##### **A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training**
2407.07630v1 by Michał Perełkiewicz, Rafał Poświata

This article presents a comprehensive review of the challenges associated
with using massive web-mined corpora for the pre-training of large language
models (LLMs). This review identifies key challenges in this domain, including
challenges such as noise (irrelevant or misleading information), duplication of
content, the presence of low-quality or incorrect information, biases, and the
inclusion of sensitive or personal information in web-mined corpora. Addressing
these issues is crucial for the development of accurate, reliable, and
ethically responsible language models. Through an examination of current
methodologies for data cleaning, pre-processing, bias detection and mitigation,
we highlight the gaps in existing approaches and suggest directions for future
research. Our discussion aims to catalyze advancements in developing more
sophisticated and ethically responsible LLMs.

摘要：這篇文章全面回顧了使用大量網頁挖掘語料庫預訓練大型語言模型 (LLM) 所面臨的挑戰。此回顧辨識出此領域中的主要挑戰，包括雜訊（不相關或誤導資訊）、內容重複、存在低品質或不正確的資訊、偏見，以及網頁挖掘語料庫中包含敏感或個人資訊。解決這些問題對於開發精確、可靠且符合道德規範的語言模型至關重要。透過檢視現行資料清理、前處理、偏見偵測和緩解的方法，我們強調現有方法的差距，並建議未來研究的方向。我們的討論旨在催化開發更精緻且符合道德規範的 LLM。

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **The Computational Learning of Construction Grammars: State of the Art and Prospective Roadmap**
2407.07606v1 by Jonas Doumen, Veronica Juliana Schmalz, Katrien Beuls, Paul Van Eecke

This paper documents and reviews the state of the art concerning
computational models of construction grammar learning. It brings together prior
work on the computational learning of form-meaning pairings, which has so far
been studied in several distinct areas of research. The goal of this paper is
threefold. First of all, it aims to synthesise the variety of methodologies
that have been proposed to date and the results that have been obtained.
Second, it aims to identify those parts of the challenge that have been
successfully tackled and reveal those that require further research. Finally,
it aims to provide a roadmap which can help to boost and streamline future
research efforts on the computational learning of large-scale, usage-based
construction grammars.

摘要：本文档记录并检视了有关建构语法学习的计算模型的最新技术。它汇集了先前关于形式-意义配对的计算学习工作，该工作迄今已在几个不同的研究领域中得到研究。本文的目标有三方面。首先，它旨在综合迄今为止提出的各种方法以及获得的结果。其次，它旨在找出已成功解决的挑战部分，并揭示需要进一步研究的部分。最后，它旨在提供一个路线图，该路线图可以帮助促进和简化未来在基于使用的大规模建构语法的计算学习上的研究工作。

##### **Early Explorations of Lightweight Models for Wound Segmentation on Mobile Devices**
2407.07605v2 by Vanessa Borst, Timo Dittus, Konstantin Müller, Samuel Kounev

The aging population poses numerous challenges to healthcare, including the
increase in chronic wounds in the elderly. The current approach to wound
assessment by therapists based on photographic documentation is subjective,
highlighting the need for computer-aided wound recognition from smartphone
photos. This offers objective and convenient therapy monitoring, while being
accessible to patients from their home at any time. However, despite research
in mobile image segmentation, there is a lack of focus on mobile wound
segmentation. To address this gap, we conduct initial research on three
lightweight architectures to investigate their suitability for smartphone-based
wound segmentation. Using public datasets and UNet as a baseline, our results
are promising, with both ENet and TopFormer, as well as the larger UNeXt
variant, showing comparable performance to UNet. Furthermore, we deploy the
models into a smartphone app for visual assessment of live segmentation, where
results demonstrate the effectiveness of TopFormer in distinguishing wounds
from wound-coloured objects. While our study highlights the potential of
transformer models for mobile wound segmentation, future work should aim to
further improve the mask contours.

摘要：人口老齡化對醫療保健構成許多挑戰，包括老年人慢性傷口增加。治療師根據照片文件進行傷口評估的現有方法是主觀的，這凸顯了從智慧型手機照片進行電腦輔助傷口識別的需求。這提供了客觀且便利的治療監控，同時患者隨時都可以在家使用。然而，儘管有行動影像分割的研究，但缺乏對行動傷口分割的關注。為了解決這個差距，我們對三種輕量級架構進行初步研究，以調查它們是否適合用於基於智慧型手機的傷口分割。使用公開資料集和 UNet 作為基準，我們的結果很有希望，ENet 和 TopFormer 以及較大的 UNeXt 變體都顯示出與 UNet 相當的效能。此外，我們將模型部署到智慧型手機應用程式中，以進行即時分割的視覺評估，結果證明了 TopFormer 在區分傷口和傷口顏色物體方面的有效性。雖然我們的研究突顯了Transformer模型在行動傷口分割方面的潛力，但未來的研究應旨在進一步改善遮罩輪廓。

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

摘要：咬合接觸是上顎和下顎後牙咬合面相遇的位置。咬合接觸偵測是恢復咀嚼功能喪失的必要工具，也是牙科領域中的一項強制性評估，特別是在贋復牙科和修復牙科中具有重要意義。最常見的咬合接觸偵測方法是使用咬合紙。然而，此方法可能會顯示出顯著的醫學假陽性和醫學假陰性接觸區域，讓臨床醫師難以找出真正的咬合跡象。為了解決這個問題，我們提出一個多類別的 Vision Transformer 和全卷積網路集合語意分割模型，並結合分層損失函數，我們將其命名為分層全卷積分支轉換器 (H-FCBFormer)。我們還提出了一種生成醫學真陽性語意分割遮罩的方法，該方法源自專家註解的咬合紙遮罩和金標準遮罩。所提出的模型在偵測醫學真陽性接觸方面優於其他機器學習方法，並且在準確識別物件式咬合接觸區域方面優於牙醫師，同時識別所需時間卻顯著減少。程式碼可在 https://github.com/Banksylel/H-FCBFormer 取得。

##### **IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model**
2407.07577v1 by Yatai Ji, Shilong Zhang, Jie Wu, Peize Sun, Weifeng Chen, Xuefeng Xiao, Sidi Yang, Yujiu Yang, Ping Luo

The rapid advancement of Large Vision-Language models (LVLMs) has
demonstrated a spectrum of emergent capabilities. Nevertheless, current models
only focus on the visual content of a single scenario, while their ability to
associate instances across different scenes has not yet been explored, which is
essential for understanding complex visual content, such as movies with
multiple characters and intricate plots. Towards movie understanding, a
critical initial step for LVLMs is to unleash the potential of character
identities memory and recognition across multiple visual scenarios. To achieve
the goal, we propose visual instruction tuning with ID reference and develop an
ID-Aware Large Vision-Language Model, IDA-VLM. Furthermore, our research
introduces a novel benchmark MM-ID, to examine LVLMs on instance IDs memory and
recognition across four dimensions: matching, location, question-answering, and
captioning. Our findings highlight the limitations of existing LVLMs in
recognizing and associating instance identities with ID reference. This paper
paves the way for future artificial intelligence systems to possess
multi-identity visual inputs, thereby facilitating the comprehension of complex
visual narratives like movies.

摘要：大型視覺語言模型 (LVLMs) 的快速進展已展現一系列新興能力。然而，目前的模型僅專注於單一場景的視覺內容，而它們跨不同場景關聯實例的能力尚未被探索，這對於理解複雜的視覺內容（例如具有多個角色和複雜情節的電影）至關重要。為了理解電影，LVLMs 的關鍵第一步是發揮角色身分記憶和跨多個視覺場景識別的潛力。為達成目標，我們提出使用 ID 參考進行視覺指令調整，並開發出 ID 感知大型視覺語言模型 IDA-VLM。此外，我們的研究引入了一個新基準 MM-ID，以在四個面向（匹配、位置、問答和字幕）上檢驗 LVLMs 在實例 ID 記憶和識別方面的表現。我們的研究結果突顯了現有 LVLMs 在識別和關聯實例身分與 ID 參考方面的限制。本文為未來的 AI 系統鋪平了道路，讓它們擁有多重身分視覺輸入，從而促進對電影等複雜視覺敘事的理解。

##### **HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing**
2407.07566v1 by Arnon Turetzky, Or Tal, Yael Segal-Feldman, Yehoshua Dissen, Ella Zeldes, Amit Roth, Eyal Cohen, Yosi Shrem, Bronya R. Chernyak, Olga Seleznova, Joseph Keshet, Yossi Adi

We present HebDB, a weakly supervised dataset for spoken language processing
in the Hebrew language. HebDB offers roughly 2500 hours of natural and
spontaneous speech recordings in the Hebrew language, consisting of a large
variety of speakers and topics. We provide raw recordings together with a
pre-processed, weakly supervised, and filtered version. The goal of HebDB is to
further enhance research and development of spoken language processing tools
for the Hebrew language. Hence, we additionally provide two baseline systems
for Automatic Speech Recognition (ASR): (i) a self-supervised model; and (ii) a
fully supervised model. We present the performance of these two methods
optimized on HebDB and compare them to current multi-lingual ASR alternatives.
Results suggest the proposed method reaches better results than the evaluated
baselines considering similar model sizes. Dataset, code, and models are
publicly available under https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/.

摘要：我們提出 HebDB，一個希伯來語口語處理的弱監督資料集。HebDB 提供大約 2500 小時的希伯來語自然且自發的語音錄音，包含各種講者和主題。我們提供原始錄音以及經過預處理、弱監督和過濾的版本。HebDB 的目標是進一步增強希伯來語口語處理工具的研究和開發。因此，我們另外提供了兩個自動語音辨識 (ASR) 的基準系統：(i) 自我監督模型；(ii) 完全監督模型。我們展示了這兩種方法在 HebDB 上最佳化的效能，並將它們與目前的多分語言 ASR 替代方案進行比較。結果表明，所提出的方法在考慮類似模型大小的情況下，比評估的基準線獲得更好的結果。資料集、程式碼和模型可在 https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/ 下公開取得。

##### **On Leakage of Code Generation Evaluation Datasets**
2407.07565v2 by Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen Gilsenan-McMahon, Matthias Gallé

In this paper we consider contamination by code generation test sets, in
particular in their use in modern large language models. We discuss three
possible sources of such contamination and show findings supporting each of
them: (i) direct data leakage, (ii) indirect data leakage through the use of
synthetic data and (iii) overfitting to evaluation sets during model selection.
Key to our findings is a new dataset of 161 prompts with their associated
python solutions, dataset which is released at
https://huggingface.co/datasets/CohereForAI/lbpp .

摘要：在本文中，我們考慮了由程式碼生成測試集造成的污染，特別是在它們在現代大型語言模型中的使用。我們討論了這種污染的三個可能來源，並展示了支持每個來源的發現：(i) 直接資料外洩，(ii) 通過使用合成資料進行間接資料外洩，以及 (iii) 在模型選擇期間過度擬合評估集。我們的發現的關鍵是一個新的資料集，其中包含 161 個提示及其關聯的 Python 程式碼，該資料集已在 https://huggingface.co/datasets/CohereForAI/lbpp 發布。

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

摘要：機器人輔助進食有潛力改善行動不便、無法自行進食的個人生活品質。然而，現有的進食系統所能處理的均質、精選餐盤與實際的餐點之間存在著很大的差距。進食實際的餐點極具挑戰性，因為機器人可能遇到的食物種類繁多，每種食物都需要特定的操作策略，而這些策略必須在一個長期的範圍內進行排序，才能進食一整餐。一個輔助進食系統不僅應該能夠有效地對不同的策略進行排序，以便進食一整餐，還應該在任務的個性化性質下，考量使用者的偏好。我們透過 FLAIR 來解決這個問題，FLAIR 是針對長時程進食的系統，它利用基礎模型的常識和少量推理能力，以及一個參數化技能庫，來規劃和執行使用者偏好且有效的進食順序。在 6 個實際餐盤的真實世界評估中，我們發現 FLAIR 可以有效地利用各種技能庫進行有效的食物取用，同時遵守 42 位行動不便參與者的不同偏好，這是在使用者研究中評估的。我們展示了 FLAIR 與現有進食轉移方法 [19, 28] 的無縫整合，並在 2 個機構和 3 個機器人中部署它，說明了它的適應性。最後，我們透過成功餵食一位行動不便的受照護者來說明我們系統在真實世界中的功效。補充材料和影片可以在這裡找到：https://emprise.cs.cornell.edu/flair。

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

摘要：大型語言模型（LLM）最近已成為各種語言生成任務的強大工具。儘管如此，這項進展在阿拉伯語中較為緩慢。在這項工作中，我們專注於從 LLM 生成故事的任務。對於我們的訓練，我們使用通過機器翻譯（MT）以及 GPT-4 獲得的故事。對於 MT 資料，我們開發了一個仔細的管道，以確保我們獲得高品質的故事。對於我們的 GPT-41 資料，我們引入了精心製作的提示，使我們能夠生成非常適合阿拉伯語環境的資料，包括現代標準阿拉伯語（MSA）和兩種阿拉伯語方言（埃及語和摩洛哥語）。例如，我們生成針對各種阿拉伯國家的故事，主題廣泛。我們的評估顯示，我們針對這些訓練資料集進行微調的模型可以生成符合我們指示的連貫故事。我們還進行了廣泛的自動和人工評估，將我們的模型與最先進的專有和開放原始碼模型進行比較。我們的資料集和模型將在 https: //github.com/UBC-NLP/arastories 公開。

##### **Disentangling Masked Autoencoders for Unsupervised Domain Generalization**
2407.07544v1 by An Zhang, Han Wang, Xiang Wang, Tat-Seng Chua

Domain Generalization (DG), designed to enhance out-of-distribution (OOD)
generalization, is all about learning invariance against domain shifts
utilizing sufficient supervision signals. Yet, the scarcity of such labeled
data has led to the rise of unsupervised domain generalization (UDG) - a more
important yet challenging task in that models are trained across diverse
domains in an unsupervised manner and eventually tested on unseen domains. UDG
is fast gaining attention but is still far from well-studied. To close the
research gap, we propose a novel learning framework designed for UDG, termed
the Disentangled Masked Auto Encoder (DisMAE), aiming to discover the
disentangled representations that faithfully reveal the intrinsic features and
superficial variations without access to the class label. At its core is the
distillation of domain-invariant semantic features, which cannot be
distinguished by domain classifier, while filtering out the domain-specific
variations (for example, color schemes and texture patterns) that are unstable
and redundant. Notably, DisMAE co-trains the asymmetric dual-branch
architecture with semantic and lightweight variation encoders, offering dynamic
data manipulation and representation level augmentation capabilities. Extensive
experiments on four benchmark datasets (i.e., DomainNet, PACS, VLCS, Colored
MNIST) with both DG and UDG tasks demonstrate that DisMAE can achieve
competitive OOD performance compared with the state-of-the-art DG and UDG
baselines, which shed light on potential research line in improving the
generalization ability with large-scale unlabeled data.

摘要：領域泛化 (DG) 旨在增強非分佈 (OOD) 泛化，其關鍵在於利用足夠的監督訊號來學習對抗領域轉移的不變性。然而，此類標記資料的稀缺性導致無監督領域泛化 (UDG) 的興起，這是一項更重要但更具挑戰性的任務，因為模型是以無監督的方式在不同的領域中訓練，並最終在未見過的領域中進行測試。UDG 迅速受到關注，但仍遠未得到充分的研究。為了縮小研究差距，我們提出了一個專為 UDG 設計的新穎學習架構，稱為分離遮罩自動編碼器 (DisMAE)，旨在發現分離的表徵，這些表徵忠實地揭示了內在特徵和表面變化，而無需存取類別標籤。其核心是對領域不變語義特徵的萃取，這些特徵無法被領域分類器區分，同時過濾掉不穩定且冗餘的領域特定變化（例如，配色方案和紋理模式）。值得注意的是，DisMAE 使用語義和輕量級變異編碼器共同訓練不對稱的雙分支架構，提供動態資料處理和表徵層級擴充功能。在四個基準資料集（即 DomainNet、PACS、VLCS、Colored MNIST）上進行的廣泛實驗，包括 DG 和 UDG 任務，證明 DisMAE 能夠與最先進的 DG 和 UDG 基準相比，取得具有競爭力的 OOD 效能，這為利用大規模未標記資料改善泛化能力的潛在研究方向提供了啟示。

##### **Swiss DINO: Efficient and Versatile Vision Framework for On-device Personal Object Search**
2407.07541v1 by Kirill Paramonov, Jia-Xing Zhong, Umberto Michieli, Jijoong Moon, Mete Ozay

In this paper, we address a recent trend in robotic home appliances to
include vision systems on personal devices, capable of personalizing the
appliances on the fly. In particular, we formulate and address an important
technical task of personal object search, which involves localization and
identification of personal items of interest on images captured by robotic
appliances, with each item referenced only by a few annotated images. The task
is crucial for robotic home appliances and mobile systems, which need to
process personal visual scenes or to operate with particular personal objects
(e.g., for grasping or navigation). In practice, personal object search
presents two main technical challenges. First, a robot vision system needs to
be able to distinguish between many fine-grained classes, in the presence of
occlusions and clutter. Second, the strict resource requirements for the
on-device system restrict the usage of most state-of-the-art methods for
few-shot learning and often prevent on-device adaptation. In this work, we
propose Swiss DINO: a simple yet effective framework for one-shot personal
object search based on the recent DINOv2 transformer model, which was shown to
have strong zero-shot generalization properties. Swiss DINO handles challenging
on-device personalized scene understanding requirements and does not require
any adaptation training. We show significant improvement (up to 55%) in
segmentation and recognition accuracy compared to the common lightweight
solutions, and significant footprint reduction of backbone inference time (up
to 100x) and GPU consumption (up to 10x) compared to the heavy
transformer-based solutions.

摘要：<paragraph>在本文中，我們探討機器人家庭電器的一項最新趨勢，在個人裝置上包含視覺系統，能夠即時個人化電器。特別是，我們制定並解決了一個重要的技術任務，即個人物品搜尋，其中涉及在機器人電器拍攝的影像中，定位和辨識個人感興趣的物品，每個物品僅由少數標註影像作為參考。此任務對於機器人家庭電器和行動系統至關重要，這些系統需要處理個人視覺場景或使用特定個人物品（例如，用於抓取或導航）。在實務上，個人物品搜尋呈現兩個主要的技術挑戰。首先，機器人視覺系統需要能夠區分許多細緻的類別，即使在有遮擋和雜亂的情況下。其次，對裝置系統的嚴格資源需求限制了使用大多數最先進的少樣本學習方法，並且經常會妨礙裝置上的適應。在這項工作中，我們提出 Swiss DINO：一個簡單但有效的框架，用於基於最近的 DINOv2 轉換器模型進行一次性個人物品搜尋，該模型被證明具有強大的零樣本泛化特性。Swiss DINO 處理具有挑戰性的裝置上個人化場景理解需求，並且不需要任何適應訓練。與常見的輕量化解決方案相比，我們在分割和辨識準確度方面展示了顯著的提升（高達 55%），並且與基於轉換器的重型解決方案相比，顯著減少了主幹推論時間（高達 100 倍）和 GPU 消耗（高達 10 倍）。</paragraph>

##### **Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models**
2407.07531v1 by Jin Liu, Qingquan Li, Wenlong Du

In current benchmarks for evaluating large language models (LLMs), there are
issues such as evaluation content restriction, untimely updates, and lack of
optimization guidance. In this paper, we propose a new paradigm for the
measurement of LLMs: Benchmarking-Evaluation-Assessment. Our paradigm shifts
the "location" of LLM evaluation from the "examination room" to the "hospital".
Through conducting a "physical examination" on LLMs, it utilizes specific
task-solving as the evaluation content, performs deep attribution of existing
problems within LLMs, and provides recommendation for optimization.

摘要：在當前用於評估大型語言模型 (LLM) 的基準中，存在評估內容限制、更新不即時以及缺乏最佳化指導等問題。在本文中，我們提出一個新的範例來測量 LLM：基準評估。我們的範例將 LLM 評估的「位置」從「考場」轉移到「醫院」。透過對 LLM 進行「身體檢查」，它利用具體的任務解決作為評估內容，對 LLM 內部現有問題進行深入歸因，並提供最佳化建議。

##### **How Aligned are Different Alignment Metrics?**
2407.07530v1 by Jannis Ahlert, Thomas Klein, Felix Wichmann, Robert Geirhos

In recent years, various methods and benchmarks have been proposed to
empirically evaluate the alignment of artificial neural networks to human
neural and behavioral data. But how aligned are different alignment metrics? To
answer this question, we analyze visual data from Brain-Score (Schrimpf et al.,
2018), including metrics from the model-vs-human toolbox (Geirhos et al.,
2021), together with human feature alignment (Linsley et al., 2018; Fel et al.,
2022) and human similarity judgements (Muttenthaler et al., 2022). We find that
pairwise correlations between neural scores and behavioral scores are quite low
and sometimes even negative. For instance, the average correlation between
those 80 models on Brain-Score that were fully evaluated on all 69 alignment
metrics we considered is only 0.198. Assuming that all of the employed metrics
are sound, this implies that alignment with human perception may best be
thought of as a multidimensional concept, with different methods measuring
fundamentally different aspects. Our results underline the importance of
integrative benchmarking, but also raise questions about how to correctly
combine and aggregate individual metrics. Aggregating by taking the arithmetic
average, as done in Brain-Score, leads to the overall performance currently
being dominated by behavior (95.25% explained variance) while the neural
predictivity plays a less important role (only 33.33% explained variance). As a
first step towards making sure that different alignment metrics all contribute
fairly towards an integrative benchmark score, we therefore conclude by
comparing three different aggregation options.

摘要：近年来，已提出各种方法和基准来凭经验评估人工神经网络与人类神经和行为数据的一致性。但不同的对齐度量标准有多一致？为了回答这个问题，我们分析了 Brain-Score（Schrimpf 等人，2018 年）中的视觉数据，包括来自模型与人类工具箱（Geirhos 等人，2021 年）的度量标准，以及人类特征对齐（Linsley 等人，2018 年；Fel 等人，2022 年）和人类相似性判断（Muttenthaler 等人，2022 年）。我们发现神经分数和行为分数之间的成对相关性相当低，有时甚至为负。例如，在 Brain-Score 上经过所有 69 个对齐度量标准全面评估的 80 个模型之间的平均相关性仅为 0.198。假设所有采用的度量标准都是合理的，这意味着与人类感知的对齐可能最好被认为是一个多维概念，不同的方法测量着根本不同的方面。我们的结果强调了综合基准测试的重要性，但也提出了有关如何正确组合和汇总各个度量标准的问题。通过取算术平均值进行汇总，如 Brain-Score 中所做的那样，导致整体性能目前主要受行为支配（解释方差 95.25%），而神经预测性所起的作用较小（仅解释方差 33.33%）。作为确保不同的对齐度量标准都能公平地为综合基准分数做出贡献的第一步，我们因此通过比较三个不同的汇总选项来结束。

##### **CHILLI: A data context-aware perturbation method for XAI**
2407.07521v1 by Saif Anwar, Nathan Griffiths, Abhir Bhalerao, Thomas Popham

The trustworthiness of Machine Learning (ML) models can be difficult to
assess, but is critical in high-risk or ethically sensitive applications. Many
models are treated as a `black-box' where the reasoning or criteria for a final
decision is opaque to the user. To address this, some existing Explainable AI
(XAI) approaches approximate model behaviour using perturbed data. However,
such methods have been criticised for ignoring feature dependencies, with
explanations being based on potentially unrealistic data. We propose a novel
framework, CHILLI, for incorporating data context into XAI by generating
contextually aware perturbations, which are faithful to the training data of
the base model being explained. This is shown to improve both the soundness and
accuracy of the explanations.

摘要：機器學習 (ML) 模型的信賴度難以評估，但在高風險或道德敏感的應用中至關重要。許多模型被視為「黑盒子」，使用者無法了解最終決策的推理或標準。為了解決這個問題，一些現有的可解釋人工智慧 (XAI) 方法使用擾動資料來近似模型行為。然而，這些方法因忽略特徵依賴性而受到批評，因為解釋是基於潛在不切實際的資料。我們提出一個創新的架構 CHILLI，透過產生符合被解釋基礎模型訓練資料的脈絡感知擾動，將資料脈絡納入 XAI。這已被證明可以改善解釋的健全性和準確性。

##### **Generative AI for RF Sensing in IoT systems**
2407.07506v1 by Li Wang, Chao Zhang, Qiyang Zhao, Hang Zou, Samson Lasaulce, Giuseppe Valenzise, Zhuo He, Merouane Debbah

The development of wireless sensing technologies, using signals such as
Wi-Fi, infrared, and RF to gather environmental data, has significantly
advanced within Internet of Things (IoT) systems. Among these, Radio Frequency
(RF) sensing stands out for its cost-effective and non-intrusive monitoring of
human activities and environmental changes. However, traditional RF sensing
methods face significant challenges, including noise, interference, incomplete
data, and high deployment costs, which limit their effectiveness and
scalability. This paper investigates the potential of Generative AI (GenAI) to
overcome these limitations within the IoT ecosystem. We provide a comprehensive
review of state-of-the-art GenAI techniques, focusing on their application to
RF sensing problems. By generating high-quality synthetic data, enhancing
signal quality, and integrating multi-modal data, GenAI offers robust solutions
for RF environment reconstruction, localization, and imaging. Additionally,
GenAI's ability to generalize enables IoT devices to adapt to new environments
and unseen tasks, improving their efficiency and performance. The main
contributions of this article include a detailed analysis of the challenges in
RF sensing, the presentation of innovative GenAI-based solutions, and the
proposal of a unified framework for diverse RF sensing tasks. Through case
studies, we demonstrate the effectiveness of integrating GenAI models, leading
to advanced, scalable, and intelligent IoT systems.

摘要：無線感測技術的發展，使用 Wi-Fi、紅外線和射頻等訊號來收集環境資料，在物聯網 (IoT) 系統中已顯著進步。其中，射頻 (RF) 感測以其具成本效益且非侵入性的方式監控人類活動和環境變化而脫穎而出。然而，傳統的射頻感測方法面臨著重大的挑戰，包括噪音、干擾、資料不完整和部署成本高，這些限制了其有效性和可擴充性。本文探討了生成式 AI (GenAI) 在 IoT 生態系統中克服這些限制的潛力。我們提供了對最新 GenAI 技術的全面回顧，重點關注其在射頻感測問題中的應用。透過生成高品質的合成資料、增強訊號品質和整合多模式資料，GenAI 為射頻環境重建、定位和影像提供強大的解決方案。此外，GenAI 的泛化能力使 IoT 裝置能夠適應新的環境和未知的任務，從而提高其效率和效能。本文的主要貢獻包括對射頻感測挑戰的詳細分析、創新的基於 GenAI 的解決方案的展示，以及統一架構的提議，以應對多樣化的射頻感測任務。透過案例研究，我們展示了整合 GenAI 模型的有效性，從而實現先進、可擴充和智慧的 IoT 系統。

##### **Bucket Pre-training is All You Need**
2407.07495v1 by Hongtao Liu, Qiyao Peng, Qing Yang, Kai Liu, Hongyan Xu

Large language models (LLMs) have demonstrated exceptional performance across
various natural language processing tasks. However, the conventional
fixed-length data composition strategy for pretraining, which involves
concatenating and splitting documents, can introduce noise and limit the
model's ability to capture long-range dependencies. To address this, we first
introduce three metrics for evaluating data composition quality: padding ratio,
truncation ratio, and concatenation ratio. We further propose a multi-bucket
data composition method that moves beyond the fixed-length paradigm, offering a
more flexible and efficient approach to pretraining. Extensive experiments
demonstrate that our proposed method could significantly improving both the
efficiency and efficacy of LLMs pretraining. Our approach not only reduces
noise and preserves context but also accelerates training, making it a
promising solution for LLMs pretraining.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展現出卓越的效能。然而，預訓練的傳統固定長度資料組合策略（涉及串接和分割文件）可能會引入雜訊並限制模型擷取長程依賴關係的能力。為了解決這個問題，我們首先提出三個用於評估資料組合品質的指標：填充率、截斷率和串接率。我們進一步提出一個超越固定長度範例的多儲存區資料組合方法，提供一種更靈活且更有效率的預訓練方法。廣泛的實驗證明，我們提出的方法可以顯著提高 LLM 預訓練的效率和效能。我們的做法不僅減少雜訊並保留上下文，還能加速訓練，使其成為 LLM 預訓練的有前途的解決方案。

##### **FUNAvg: Federated Uncertainty Weighted Averaging for Datasets with Diverse Labels**
2407.07488v1 by Malte Tölle, Fernando Navarro, Sebastian Eble, Ivo Wolf, Bjoern Menze, Sandy Engelhardt

Federated learning is one popular paradigm to train a joint model in a
distributed, privacy-preserving environment. But partial annotations pose an
obstacle meaning that categories of labels are heterogeneous over clients. We
propose to learn a joint backbone in a federated manner, while each site
receives its own multi-label segmentation head. By using Bayesian techniques we
observe that the different segmentation heads although only trained on the
individual client's labels also learn information about the other labels not
present at the respective site. This information is encoded in their predictive
uncertainty. To obtain a final prediction we leverage this uncertainty and
perform a weighted averaging of the ensemble of distributed segmentation heads,
which allows us to segment "locally unknown" structures. With our method, which
we refer to as FUNAvg, we are even on-par with the models trained and tested on
the same dataset on average. The code is publicly available at
https://github.com/Cardio-AI/FUNAvg.

摘要：联邦学习是一种流行的范例，用于在分布式、保护隐私的环境中训练联合模型。但是，部分注释构成了一个障碍，这意味着标签类别在客户端之间是异构的。我们建议以联邦方式学习联合主干，同时每个站点接收自己的多标签分割头。通过使用贝叶斯技术，我们观察到不同的分割头虽然只针对各个客户端的标签进行训练，但也会学习有关其他标签的信息，而这些标签并不存在于各个站点中。此信息编码在它们的预测不确定性中。为了获得最终预测，我们利用这种不确定性，并对分布式分割头的集合执行加权平均，这使我们能够分割“局部未知”结构。通过我们的方法（我们称之为 FUNAvg），我们甚至可以与在同一数据集上平均训练和测试的模型相提并论。代码已公开发布在 https://github.com/Cardio-AI/FUNAvg。

##### **Review-LLM: Harnessing Large Language Models for Personalized Review Generation**
2407.07487v1 by Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang

Product review generation is an important task in recommender systems, which
could provide explanation and persuasiveness for the recommendation. Recently,
Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling
and generating ability, which could be applied in review generation. However,
directly applying the LLMs for generating reviews might be troubled by the
``polite'' phenomenon of the LLMs and could not generate personalized reviews
(e.g., negative reviews). In this paper, we propose Review-LLM that customizes
LLMs for personalized review generation. Firstly, we construct the prompt input
by aggregating user historical behaviors, which include corresponding item
titles and reviews. This enables the LLMs to capture user interest features and
review writing style. Secondly, we incorporate ratings as indicators of
satisfaction into the prompt, which could further improve the model's
understanding of user preferences and the sentiment tendency control of
generated reviews. Finally, we feed the prompt text into LLMs, and use
Supervised Fine-Tuning (SFT) to make the model generate personalized reviews
for the given user and target item. Experimental results on the real-world
dataset show that our fine-tuned model could achieve better review generation
performance than existing close-source LLMs.

摘要：產品評論生成在推薦系統中是一項重要的任務，它可以為推薦提供解釋和說服力。最近，大型語言模型（LLM，例如 ChatGPT）展示了出色的文本建模和生成能力，可以應用於評論生成。然而，直接應用 LLM 來生成評論可能會受到 LLM 的「禮貌」現象的困擾，並且無法生成個性化評論（例如負面評論）。在本文中，我們提出了 Review-LLM，它自訂了 LLM 以進行個性化評論生成。首先，我們通過彙總用戶歷史行為（包括對應的商品標題和評論）來構建提示輸入。這使 LLM 能夠捕捉用戶興趣特徵和評論寫作風格。其次，我們將評分作為滿意度的指標納入提示中，這可以進一步提高模型對用戶偏好和生成評論的情緒傾向控制的理解。最後，我們將提示文本輸入 LLM，並使用監督微調 (SFT) 使模型為給定的用戶和目標商品生成個性化評論。在真實世界數據集上的實驗結果表明，我們微調的模型可以比現有的閉源 LLM 獲得更好的評論生成性能。

##### **Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations**
2407.07482v1 by Luca Marzari, Francesco Leofante, Ferdinando Cicalese, Alessandro Farinelli

We study the problem of assessing the robustness of counterfactual
explanations for deep learning models. We focus on $\textit{plausible model
shifts}$ altering model parameters and propose a novel framework to reason
about the robustness property in this setting. To motivate our solution, we
begin by showing for the first time that computing the robustness of
counterfactuals with respect to plausible model shifts is NP-complete. As this
(practically) rules out the existence of scalable algorithms for exactly
computing robustness, we propose a novel probabilistic approach which is able
to provide tight estimates of robustness with strong guarantees while
preserving scalability. Remarkably, and differently from existing solutions
targeting plausible model shifts, our approach does not impose requirements on
the network to be analyzed, thus enabling robustness analysis on a wider range
of architectures. Experiments on four binary classification datasets indicate
that our method improves the state of the art in generating robust
explanations, outperforming existing methods on a range of metrics.

摘要：我們研究評估深度學習模型的反事實解釋的穩健性的問題。我們專注於改變模型參數的「合理的模型轉移」，並提出一個新的框架，來推論這種設定中的穩健性屬性。為了激勵我們的解決方案，我們首先展示了計算反事實的穩健性，對於合理的模型轉移來說是 NP 完全的。由於這（實際上）排除了精確計算穩健性的可擴充演算法的存在，我們提出了一種新的機率方法，它能夠在保留可擴充性的同時，提供具有強大保證的穩健性緊密估計。值得注意的是，與針對合理的模型轉移的現有解決方案不同，我們的解決方案不會對要分析的網路施加要求，因此可以在更廣泛的架構上進行穩健性分析。在四個二元分類資料集上的實驗表明，我們的模型改進了產生穩健解釋的最新技術，在各種指標上優於現有模型。

##### **Rectifier: Code Translation with Corrector via LLMs**
2407.07472v1 by Xin Yin, Chao Ni, Tien N. Nguyen, Shaohua Wang, Xiaohu Yang

Software migration is garnering increasing attention with the evolution of
software and society. Early studies mainly relied on handcrafted translation
rules to translate between two languages, the translation process is
error-prone and time-consuming. In recent years, researchers have begun to
explore the use of pre-trained large language models (LLMs) in code
translation. However, code translation is a complex task that LLMs would
generate mistakes during code translation, they all produce certain types of
errors when performing code translation tasks, which include (1) compilation
error, (2) runtime error, (3) functional error, and (4) non-terminating
execution. We found that the root causes of these errors are very similar (e.g.
failure to import packages, errors in loop boundaries, operator errors, and
more). In this paper, we propose a general corrector, namely Rectifier, which
is a micro and universal model for repairing translation errors. It learns from
errors generated by existing LLMs and can be widely applied to correct errors
generated by any LLM. The experimental results on translation tasks between
C++, Java, and Python show that our model has effective repair ability, and
cross experiments also demonstrate the robustness of our method.

摘要：隨著軟體和社會的演進，軟體遷移正獲得越來越多的關注。早期研究主要依賴於人工翻譯規則在兩種語言之間進行翻譯，翻譯過程容易出錯且耗時。近年來，研究人員已開始探索在程式碼翻譯中使用預先訓練的大語言模型 (LLM)。然而，程式碼翻譯是一項複雜的任務，LLM 在程式碼翻譯過程中會產生錯誤，它們在執行程式碼翻譯任務時都會產生特定類型的錯誤，包括 (1) 編譯錯誤、(2) 執行時期錯誤、(3) 功能錯誤和 (4) 非終止執行。我們發現這些錯誤的根本原因非常相似 (例如，無法匯入套件、迴圈邊界錯誤、運算子錯誤等等)。在本文中，我們提出了一種通用校正器，即 Rectifier，它是一個用於修復翻譯錯誤的微型且通用的模型。它從現有 LLM 產生的錯誤中學習，並且可以廣泛應用於修正任何 LLM 產生的錯誤。在 C++、Java 和 Python 之間的翻譯任務上的實驗結果表明，我們的模型具有有效的修復能力，並且交叉實驗也證明了我們方法的穩健性。

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Secondary Structure-Guided Novel Protein Sequence Generation with Latent Graph Diffusion**
2407.07443v1 by Yutong Hu, Yang Tan, Andi Han, Lirong Zheng, Liang Hong, Bingxin Zhou

The advent of deep learning has introduced efficient approaches for de novo
protein sequence design, significantly improving success rates and reducing
development costs compared to computational or experimental methods. However,
existing methods face challenges in generating proteins with diverse lengths
and shapes while maintaining key structural features. To address these
challenges, we introduce CPDiffusion-SS, a latent graph diffusion model that
generates protein sequences based on coarse-grained secondary structural
information. CPDiffusion-SS offers greater flexibility in producing a variety
of novel amino acid sequences while preserving overall structural constraints,
thus enhancing the reliability and diversity of generated proteins.
Experimental analyses demonstrate the significant superiority of the proposed
method in producing diverse and novel sequences, with CPDiffusion-SS surpassing
popular baseline methods on open benchmarks across various quantitative
measurements. Furthermore, we provide a series of case studies to highlight the
biological significance of the generation performance by the proposed method.
The source code is publicly available at
https://github.com/riacd/CPDiffusion-SS

摘要：深度学习的出现为从头蛋白质序列设计引入了高效方法，与计算或实验方法相比，显著提高了成功率并降低了开发成本。然而，现有方法在生成具有不同长度和形状且同时保持关键结构特征的蛋白质时面临挑战。为了应对这些挑战，我们引入了 CPDiffusion-SS，这是一种基于粗粒度二级结构信息的潜图扩散模型，用于生成蛋白质序列。CPDiffusion-SS 在生成各种新型氨基酸序列时提供了更大的灵活性，同时保留了整体结构约束，从而增强了生成蛋白质的可靠性和多样性。实验分析表明，所提出的方法在生成多样且新颖的序列方面具有显着的优势，在各种定量测量中，CPDiffusion-SS 超越了开放基准测试中的流行基线方法。此外，我们提供了一系列案例研究，以突出所提出的方法的生成性能的生物学意义。源代码可在 https://github.com/riacd/CPDiffusion-SS 公开获得

##### **Controllable Navigation Instruction Generation with Chain of Thought Prompting**
2407.07433v1 by Xianghao Kong, Jinyu Chen, Wenguan Wang, Hang Su, Xiaolin Hu, Yi Yang, Si Liu

Instruction generation is a vital and multidisciplinary research area with
broad applications. Existing instruction generation models are limited to
generating instructions in a single style from a particular dataset, and the
style and content of generated instructions cannot be controlled. Moreover,
most existing instruction generation methods also disregard the spatial
modeling of the navigation environment. Leveraging the capabilities of Large
Language Models (LLMs), we propose C-Instructor, which utilizes the
chain-of-thought-style prompt for style-controllable and content-controllable
instruction generation. Firstly, we propose a Chain of Thought with Landmarks
(CoTL) mechanism, which guides the LLM to identify key landmarks and then
generate complete instructions. CoTL renders generated instructions more
accessible to follow and offers greater controllability over the manipulation
of landmark objects. Furthermore, we present a Spatial Topology Modeling Task
to facilitate the understanding of the spatial structure of the environment.
Finally, we introduce a Style-Mixed Training policy, harnessing the prior
knowledge of LLMs to enable style control for instruction generation based on
different prompts within a single model instance. Extensive experiments
demonstrate that instructions generated by C-Instructor outperform those
generated by previous methods in text metrics, navigation guidance evaluation,
and user studies.

摘要：指令生成是一个至关重要的多学科研究领域，具有广泛的应用。现有的指令生成模型仅限于从特定数据集生成单一风格的指令，并且无法控制生成指令的风格和内容。此外，大多数现有的指令生成方法也忽略了导航环境的空间建模。利用大型语言模型 (LLM) 的功能，我们提出了 C-Instructor，它利用思想链风格的提示进行风格可控和内容可控的指令生成。首先，我们提出了带有地标的思想链 (CoTL) 机制，它指导 LLM 识别关键地标，然后生成完整的指令。CoTL 使生成的指令更容易遵循，并提供了对地标对象操作的更大可控性。此外，我们提出了空间拓扑建模任务，以促进对环境空间结构的理解。最后，我们引入了一种风格混合训练策略，利用 LLM 的先验知识，以便在单个模型实例中基于不同的提示启用指令生成的风格控制。大量的实验表明，C-Instructor 生成的指令在文本指标、导航指导评估和用户研究中优于以前方法生成的指令。

##### **Out-of-distribution generalisation in spoken language understanding**
2407.07425v1 by Dejan Porjazovski, Anssi Moisio, Mikko Kurimo

Test data is said to be out-of-distribution (OOD) when it unexpectedly
differs from the training data, a common challenge in real-world use cases of
machine learning. Although OOD generalisation has gained interest in recent
years, few works have focused on OOD generalisation in spoken language
understanding (SLU) tasks. To facilitate research on this topic, we introduce a
modified version of the popular SLU dataset SLURP, featuring data splits for
testing OOD generalisation in the SLU task. We call our modified dataset SLURP
For OOD generalisation, or SLURPFOOD. Utilising our OOD data splits, we find
end-to-end SLU models to have limited capacity for generalisation. Furthermore,
by employing model interpretability techniques, we shed light on the factors
contributing to the generalisation difficulties of the models. To improve the
generalisation, we experiment with two techniques, which improve the results on
some, but not all the splits, emphasising the need for new techniques.

摘要：測試資料被認為是 out-of-distribution (OOD)，當它不同於訓練資料時，這是機器學習在實際使用案例中常見的挑戰。儘管 OOD generalization 在近年來引起興趣，但很少有研究專注於口語理解 (SLU) 任務中的 OOD generalization。為了促進對此主題的研究，我們引入了廣受歡迎的 SLU 資料集 SLURP 的修改版本，其中包含用於測試 SLU 任務中 OOD generalization 的資料分割。我們將修改後的資料集稱為 SLURP for OOD generalization，或 SLURPFOOD。利用我們的 OOD 資料分割，我們發現端到端 SLU 模型的 generalization 能力有限。此外，透過採用模型可解釋性技術，我們闡明了導致模型 generalization 困難的因素。為了改善 generalization，我們嘗試了兩種技術，它們改善了一些分割的結果，但並非所有分割，強調了對新技術的需求。

##### **KpopMT: Translation Dataset with Terminology for Kpop Fandom**
2407.07413v1 by JiWoo Kim, Yunsu Kim, JinYeong Bak

While machines learn from existing corpora, humans have the unique capability
to establish and accept new language systems. This makes human form unique
language systems within social groups. Aligning with this, we focus on a gap
remaining in addressing translation challenges within social groups, where
in-group members utilize unique terminologies. We propose KpopMT dataset, which
aims to fill this gap by enabling precise terminology translation, choosing
Kpop fandom as an initiative for social groups given its global popularity.
Expert translators provide 1k English translations for Korean posts and
comments, each annotated with specific terminology within social groups'
language systems. We evaluate existing translation systems including GPT models
on KpopMT to identify their failure cases. Results show overall low scores,
underscoring the challenges of reflecting group-specific terminologies and
styles in translation. We make KpopMT publicly available.

摘要：機器從現有語料庫中學習，而人類擁有建立和接受新語言系統的獨特能力。這使得人類在社會群體中形成獨特的語言系統。與此一致，我們專注於解決社會群體內翻譯挑戰的差距，在群組成員使用獨特術語的情況下。我們提出 KpopMT 資料集，旨在通過啟用精確術語翻譯來填補這一空白，選擇 Kpop 粉絲群作為社會群體的倡議，因為它在全球範圍內很受歡迎。專家翻譯人員為韓語帖子和評論提供了 1k 個英文翻譯，每個翻譯都註釋了社會群體語言系統中的特定術語。我們評估了包括 GPT 模型在內的現有翻譯系統在 KpopMT 上，以找出它們的失敗案例。結果顯示總體得分較低，強調了在翻譯中反映特定群體術語和風格的挑戰。我們公開了 KpopMT。

##### **Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**
2407.07412v1 by Seonghoon Yu, Paul Hongsuck Seo, Jeany Son

We propose a new framework that automatically generates high-quality
segmentation masks with their referring expressions as pseudo supervisions for
referring image segmentation (RIS). These pseudo supervisions allow the
training of any supervised RIS methods without the cost of manual labeling. To
achieve this, we incorporate existing segmentation and image captioning
foundation models, leveraging their broad generalization capabilities. However,
the naive incorporation of these models may generate non-distinctive
expressions that do not distinctively refer to the target masks. To address
this challenge, we propose two-fold strategies that generate distinctive
captions: 1) 'distinctive caption sampling', a new decoding method for the
captioning model, to generate multiple expression candidates with detailed
words focusing on the target. 2) 'distinctiveness-based text filtering' to
further validate the candidates and filter out those with a low level of
distinctiveness. These two strategies ensure that the generated text
supervisions can distinguish the target from other objects, making them
appropriate for the RIS annotations. Our method significantly outperforms both
weakly and zero-shot SoTA methods on the RIS benchmark datasets. It also
surpasses fully supervised methods in unseen domains, proving its capability to
tackle the open-world challenge within RIS. Furthermore, integrating our method
with human annotations yields further improvements, highlighting its potential
in semi-supervised learning applications.

摘要：我們提出一個新的架構，它會自動生成高品質的分割遮罩，並將其參照表達式作為偽監督，以進行參照影像分割 (RIS)。這些偽監督允許訓練任何受監督的 RIS 方法，而無需手動標記的成本。為達成此目的，我們整合現有的分割和影像字幕基礎模型，利用其廣泛的概括能力。然而，天真地整合這些模型可能會產生不具區別性的表達式，而無法明確地參照目標遮罩。為了解決這個挑戰，我們提出兩方面的策略來產生有區別性的字幕：1)「有區別性的字幕取樣」，一種新的字幕模型解碼方法，用於產生多個表達式候選，並使用詳細的字詞專注於目標。2)「基於區別性的文字過濾」，用於進一步驗證候選並過濾掉區別性較低的候選。這兩種策略可確保產生的文字監督可以將目標與其他物件區分開來，使其適用於 RIS 標註。我們的模型在 RIS 基準資料集上明顯優於弱標註和零次學習的 SoTA 模型。它也超越了在未見領域中的完全監督模型，證明了它在 RIS 中應對開放世界挑戰的能力。此外，將我們的模型與人工標註整合，會產生進一步的改進，突顯了它在半監督學習應用中的潛力。

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

摘要：人类观察模式的眼球注视已越来越多地融入视觉任务的解决方案中。尽管最近探索了利用注视来辅助深度网络，但很少有研究利用注视作为医学图像分割的有效注释方法，这通常需要大量的注释成本。在本文中，我们提出收集密集的弱监督，用于具有凝视注释方案的医学图像分割。为了用注视进行训练，我们提出了一个多级框架，该框架从区分性人类注意力训练多个网络，并通过在凝视热图上应用分层阈值来模拟一组伪掩码。此外，为了减轻注视噪声，利用跨级一致性来正则化过度拟合的噪声标签，将模型引导至由对等网络学习的干净模式。所提出的方法已在两个公共医学数据集的多息肉和前列腺分割任务上得到验证。我们贡献了一个名为 GazeMedSeg 的高质量凝视数据集，作为流行医学分割数据集的扩展。据我们所知，这是医学图像分割的第一个凝视数据集。我们的实验表明，在性能和注释时间方面，凝视注释优于以前的标签高效注释方案。我们收集的凝视数据和代码可在以下位置获得：https://github.com/med-air/GazeMedSeg。

##### **Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems**
2407.07392v1 by Chashi Mahiul Islam, Shaeke Salman, Montasir Shams, Xiuwen Liu, Piyush Kumar

Building on the unprecedented capabilities of large language models for
command understanding and zero-shot recognition of multi-modal vision-language
transformers, visual language navigation (VLN) has emerged as an effective way
to address multiple fundamental challenges toward a natural language interface
to robot navigation. However, such vision-language models are inherently
vulnerable due to the lack of semantic meaning of the underlying embedding
space. Using a recently developed gradient based optimization procedure, we
demonstrate that images can be modified imperceptibly to match the
representation of totally different images and unrelated texts for a
vision-language model. Building on this, we develop algorithms that can
adversarially modify a minimal number of images so that the robot will follow a
route of choice for commands that require a number of landmarks. We demonstrate
that experimentally using a recently proposed VLN system; for a given
navigation command, a robot can be made to follow drastically different routes.
We also develop an efficient algorithm to detect such malicious modifications
reliably based on the fact that the adversarially modified images have much
higher sensitivity to added Gaussian noise than the original images.

摘要：建立在大语言模型对命令理解和多模态视觉语言转换器的零样本识别能力的基础上，视觉语言导航 (VLN) 已成为解决面向机器人导航的自然语言界面的多个基本挑战的有效方法。然而，由于底层嵌入空间缺乏语义意义，此类视觉语言模型本质上是脆弱的。使用最近开发的基于梯度的优化程序，我们证明可以对图像进行不可察觉的修改，以匹配视觉语言模型中完全不同图像和无关文本的表示。在此基础上，我们开发了对抗性修改最小数量图像的算法，以便机器人按照需要多个地标的命令选择一条路线。我们使用最近提出的 VLN 系统进行了实验性演示；对于给定的导航命令，可以使机器人按照截然不同的路线前进。我们还开发了一种有效的算法来可靠地检测此类恶意修改，事实是，对抗性修改的图像对添加的高斯噪声的敏感性远高于原始图像。

##### **Automatic Extraction of Disease Risk Factors from Medical Publications**
2407.07373v1 by Maxim Rubchinsky, Ella Rabinovich, Adi Shraibman, Netanel Golan, Tali Sahar, Dorit Shweiki

We present a novel approach to automating the identification of risk factors
for diseases from medical literature, leveraging pre-trained models in the
bio-medical domain, while tuning them for the specific task. Faced with the
challenges of the diverse and unstructured nature of medical articles, our
study introduces a multi-step system to first identify relevant articles, then
classify them based on the presence of risk factor discussions and, finally,
extract specific risk factor information for a disease through a
question-answering model.
  Our contributions include the development of a comprehensive pipeline for the
automated extraction of risk factors and the compilation of several datasets,
which can serve as valuable resources for further research in this area. These
datasets encompass a wide range of diseases, as well as their associated risk
factors, meticulously identified and validated through a fine-grained
evaluation scheme. We conducted both automatic and thorough manual evaluation,
demonstrating encouraging results. We also highlight the importance of
improving models and expanding dataset comprehensiveness to keep pace with the
rapidly evolving field of medical research.

摘要：我們提出了一種新穎的方法，用於自動化從醫學文獻中識別疾病風險因素，利用生物醫學領域中預先訓練的模型，同時針對特定任務對其進行調整。面對醫學文章多樣化和非結構化的挑戰，我們的研究引入了一個多步驟系統，首先識別相關文章，然後根據風險因素討論的存在對其進行分類，最後，通過問答模型提取特定疾病的風險因素信息。
我們的貢獻包括開發了一個用於自動提取風險因素的綜合管道，以及編制了幾個數據集，這些數據集可以用作進一步研究該領域的寶貴資源。這些數據集涵蓋了廣泛的疾病及其相關的風險因素，並通過細粒度的評估方案進行了細緻的識別和驗證。我們進行了自動和徹底的手動評估，展示了令人鼓舞的結果。我們還強調了改進模型和擴展數據集全面性的重要性，以跟上快速發展的醫學研究領域。

##### **LokiLM: Technical Report**
2407.07370v1 by Justin Kiefel, Shrey Shah

In this work, we introduce LokiLM, a 1.4B parameter large language model
trained on 500B tokens. Our model performs strongly in natural language
reasoning tasks and achieves state-of-the-art performance among models with
1.5B parameters or less. LokiLM is trained using multi-teacher knowledge
distillation and high-quality training data to achieve benchmark results
competitive with larger models trained on significantly more tokens. We support
these findings by introducing steps to avoid benchmark contamination and
overfitting throughout our development process. Despite its promising
performance, LokiLM exhibits a concerning amount of hallucinations and scores
poorly on the TruthfulQA benchmark, so we do not release the model publicly.

摘要：在這項工作中，我們介紹了 LokiLM，一個擁有 1.4B 參數的大型語言模型，並以 500B 個符號進行訓練。我們的模型在自然語言推理任務中表現出色，並且在參數少於或等於 1.5B 的模型中取得了最先進的效能。LokiLM 使用多教師知識蒸餾和高品質訓練資料進行訓練，以取得與在更多符號上訓練的大型模型相競爭的基準結果。我們透過在整個開發過程中引入步驟來避免基準污染和過度擬合，來支持這些發現。儘管 LokiLM 具有令人滿意的效能，但它展現出令人擔憂的幻覺數量，且在 TruthfulQA 基準測試中得分不佳，因此我們不會公開發布該模型。

##### **Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?**
2407.07364v1 by Zemian Ke, Qiling Zou, Jiachao Liu, Sean Qian

System optimal traffic routing can mitigate congestion by assigning routes
for a portion of vehicles so that the total travel time of all vehicles in the
transportation system can be reduced. However, achieving real-time optimal
routing poses challenges due to uncertain demands and unknown system dynamics,
particularly in expansive transportation networks. While physics model-based
methods are sensitive to uncertainties and model mismatches, model-free
reinforcement learning struggles with learning inefficiencies and
interpretability issues. Our paper presents TransRL, a novel algorithm that
integrates reinforcement learning with physics models for enhanced performance,
reliability, and interpretability. TransRL begins by establishing a
deterministic policy grounded in physics models, from which it learns from and
is guided by a differentiable and stochastic teacher policy. During training,
TransRL aims to maximize cumulative rewards while minimizing the Kullback
Leibler (KL) divergence between the current policy and the teacher policy. This
approach enables TransRL to simultaneously leverage interactions with the
environment and insights from physics models. We conduct experiments on three
transportation networks with up to hundreds of links. The results demonstrate
TransRL's superiority over traffic model-based methods for being adaptive and
learning from the actual network data. By leveraging the information from
physics models, TransRL consistently outperforms state-of-the-art reinforcement
learning algorithms such as proximal policy optimization (PPO) and soft actor
critic (SAC). Moreover, TransRL's actions exhibit higher reliability and
interpretability compared to baseline reinforcement learning approaches like
PPO and SAC.

摘要：<paragraph>系統最佳交通路線規劃可以透過分配車輛路線，減少交通壅塞，進而減少運輸系統中所有車輛的總體行駛時間。然而，由於不確定的需求和未知的系統動態，特別是在廣大的運輸網路中，要達成即時的最佳路線規劃會遇到挑戰。雖然基於物理模型的方法對不確定性和模型不匹配很敏感，但無模型的強化學習則在學習效率低落和可解釋性問題上掙扎。我們的論文提出了 TransRL，一種創新的演算法，它將強化學習與物理模型整合，以提升效能、可靠性和可解釋性。TransRL 首先建立一個基於物理模型的確定性政策，從中學習並由一個可微分且隨機的老師政策指導。在訓練期間，TransRL 旨在最大化累積獎勵，同時最小化當前政策與老師政策之間的 Kullback Leibler (KL) 距離。這種方法使 TransRL 能同時利用與環境的互動和物理模型的見解。我們在三個具有數百個連結的運輸網路中進行實驗。結果證明 TransRL 優於基於交通模型的方法，因為它具有適應性，並能從實際網路資料中學習。透過利用物理模型中的資訊，TransRL 持續優於最先進的強化學習演算法，例如近端政策最佳化 (PPO) 和軟性動作評論家 (SAC)。此外，與 PPO 和 SAC 等基線強化學習方法相比，TransRL 的動作展現出更高的可靠性和可解釋性。</paragraph>

##### **Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture**
2407.07342v1 by Jiayang Song, Yuheng Huang, Zhehua Zhou, Lei Ma

As safety remains a crucial concern throughout the development lifecycle of
Large Language Models (LLMs), researchers and industrial practitioners have
increasingly focused on safeguarding and aligning LLM behaviors with human
preferences and ethical standards. LLMs, trained on extensive multilingual
corpora, exhibit powerful generalization abilities across diverse languages and
domains. However, current safety alignment practices predominantly focus on
single-language scenarios, which leaves their effectiveness in complex
multilingual contexts, especially for those complex mixed-language formats,
largely unexplored. In this study, we introduce Multilingual Blending, a
mixed-language query-response scheme designed to evaluate the safety alignment
of various state-of-the-art LLMs (e.g., GPT-4o, GPT-3.5, Llama3) under
sophisticated, multilingual conditions. We further investigate language
patterns such as language availability, morphology, and language family that
could impact the effectiveness of Multilingual Blending in compromising the
safeguards of LLMs. Our experimental results show that, without meticulously
crafted prompt templates, Multilingual Blending significantly amplifies the
detriment of malicious queries, leading to dramatically increased bypass rates
in LLM safety alignment (67.23% on GPT-3.5 and 40.34% on GPT-4o), far exceeding
those of single-language baselines. Moreover, the performance of Multilingual
Blending varies notably based on intrinsic linguistic properties, with
languages of different morphology and from diverse families being more prone to
evading safety alignments. These findings underscore the necessity of
evaluating LLMs and developing corresponding safety alignment strategies in a
complex, multilingual context to align with their superior cross-language
generalization capabilities.

摘要：由於安全性在大型語言模型 (LLM) 的整個開發週期中仍然是一個至關重要的問題，因此研究人員和產業從業者越來越專注於保障和調整 LLM 行為，以符合人類偏好和道德標準。LLM 在廣泛的多語言語料庫上訓練，展現出跨越不同語言和領域的強大泛化能力。然而，目前的安全性調整實務主要專注於單一語言場景，這使得它們在複雜的多語言環境中，特別是那些複雜的混合語言格式中的有效性，在很大程度上仍未得到探討。在這項研究中，我們引入了多語言混合，這是一種混合語言查詢回應機制，旨在評估各種最先進的 LLM（例如 GPT-4o、GPT-3.5、Llama3）在複雜的多語言條件下的安全性調整。我們進一步研究了語言模式，例如語言可用性、形態和語言系，這些模式可能會影響多語言混合在破壞 LLM 保障措施方面的有效性。我們的實驗結果表明，在沒有精心製作的提示範本的情況下，多語言混合會顯著放大惡意查詢的損害，導致 LLM 安全性調整的繞過率大幅增加（GPT-3.5 上為 67.23%，GPT-4o 上為 40.34%），遠遠超過單一語言基線。此外，多語言混合的效能會根據內在語言特性而有顯著差異，不同形態和來自不同語言系的語言更容易規避安全性調整。這些發現強調了在複雜的多語言環境中評估 LLM 並制定相應的安全性調整策略的必要性，以符合它們卓越的跨語言泛化能力。

##### **MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization**
2407.07341v1 by Gaurav Sahu, Issam H. Laradji

Low-resource extractive text summarization is a vital but heavily
underexplored area of research. Prior literature either focuses on abstractive
text summarization or prompts a large language model (LLM) like GPT-3 directly
to generate summaries. In this work, we propose MixSumm for low-resource
extractive text summarization. Specifically, MixSumm prompts an open-source
LLM, LLaMA-3-70b, to generate documents that mix information from multiple
topics as opposed to generating documents without mixup, and then trains a
summarization model on the generated dataset. We use ROUGE scores and L-Eval, a
reference-free LLaMA-3-based evaluation method to measure the quality of
generated summaries. We conduct extensive experiments on a challenging text
summarization benchmark comprising the TweetSumm, WikiHow, and ArXiv/PubMed
datasets and show that our LLM-based data augmentation framework outperforms
recent prompt-based approaches for low-resource extractive summarization.
Additionally, our results also demonstrate effective knowledge distillation
from LLaMA-3-70b to a small BERT-based extractive summarizer.

摘要：低資源萃取式文字摘要是一個重要但嚴重未被探索的研究領域。先前的文獻要么專注於摘要式文字摘要，要么直接提示大型語言模型 (LLM) 如 GPT-3 來產生摘要。在這項工作中，我們提出 MixSumm 用於低資源萃取式文字摘要。具體來說，MixSumm 提示開源 LLM、LLaMA-3-70b，產生混合來自多個主題的資訊的文件，而不是產生沒有混淆的文件，然後在產生的資料集上訓練摘要模型。我們使用 ROUGE 分數和 L-Eval，一種基於 LLaMA-3 的無參考評估方法來衡量產生摘要的品質。我們在一個具有挑戰性的文字摘要基準上進行廣泛的實驗，包括 TweetSumm、WikiHow 和 ArXiv/PubMed 資料集，並展示我們的基於 LLM 的資料擴充架構優於最近的基於提示的方法，用於低資源萃取式摘要。此外，我們的結果還展示了從 LLaMA-3-70b 到小型基於 BERT 的萃取式摘要器的有效知識提煉。

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

摘要：方法學的進展自動化生成差異診斷 (DDx)，以預測給定患者症狀描述的潛在疾病清單，對於臨床推理和決策支援等應用至關重要。然而，提供這些差異診斷的推理或解釋更有意義。幸運的是，大型語言模型 (LLM) 擁有強大的語言處理能力，並已被證明在各種相關任務中有效。受此潛力的激勵，我們研究了 LLM 在可解釋的 DDx 中的應用。首先，我們開發了一個新的 DDx 數據集，其中包含專家對 570 個公共臨床筆記的解釋。其次，我們提出了一個名為 Dual-Inf 的新框架，它使 LLM 能夠進行雙向推理以進行解釋。人類和自動化評估都證明了 Dual-Inf 在預測差異和診斷解釋方面的有效性。具體來說，Dual-Inf 在 DDx 解釋中超過基線方法的性能改進超過 32% w.r.t. BERTScore。此外，實驗驗證了 Dual-Inf (1) 在解釋中產生較少的錯誤，(2) 具有很好的概括性，(3) 對罕見疾病的診斷和解釋很有前景。

##### **Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models**
2407.07329v1 by Messi H. J. Lee, Calvin K. Lai

Homogeneity bias in Large Language Models (LLMs) refers to their tendency to
homogenize the representations of some groups compared to others. Previous
studies documenting this bias have predominantly used encoder models, which may
have inadvertently introduced biases. To address this limitation, we prompted
GPT-4 to generate single word/expression completions associated with 18
situation cues - specific, measurable elements of environments that influence
how individuals perceive situations and compared the variability of these
completions using probability of differentiation. This approach directly
assessed homogeneity bias from the model's outputs, bypassing encoder models.
Across five studies, we find that homogeneity bias is highly volatile across
situation cues and writing prompts, suggesting that the bias observed in past
work may reflect those within encoder models rather than LLMs. Furthermore,
these results suggest that homogeneity bias in LLMs is brittle, as even minor
and arbitrary changes in prompts can significantly alter the expression of
biases. Future work should further explore how variations in syntactic features
and topic choices in longer text generations influence homogeneity bias in
LLMs.

摘要：大型語言模型 (LLM) 中的同質性偏差是指它們傾向於將某些群體的表徵同質化，而與其他群體相比。先前記錄這種偏差的研究主要使用編碼器模型，這可能會無意中引入偏差。為了解決這個限制，我們提示 GPT-4 生成與 18 個情境線索相關的單字/表達式完成——環境中具體可衡量的元素，會影響個人如何感知情境，並使用差異機率比較這些完成的變異性。此方法直接評估模型輸出的同質性偏差，繞過編碼器模型。在五項研究中，我們發現同質性偏差在情境線索和寫作提示中高度不穩定，這表明過去工作中觀察到的偏差可能反映編碼器模型中的偏差，而不是 LLM。此外，這些結果表明 LLM 中的同質性偏差很脆弱，因為提示中的微小且隨意的更改會顯著改變偏差的表達。未來的研究應進一步探討語法特徵的變化以及較長文本生成中的主題選擇如何影響 LLM 中的同質性偏差。

##### **Fuse, Reason and Verify: Geometry Problem Solving with Parsed Clauses from Diagram**
2407.07327v1 by Ming-Liang Zhang, Zhong-Zhi Li, Fei Yin, Liang Lin, Cheng-Lin Liu

Geometry problem solving (GPS) requires capacities of multi-modal
understanding, multi-hop reasoning and theorem knowledge application. In this
paper, we propose a neural-symbolic model for plane geometry problem solving
(PGPS), named PGPSNet-v2, with three key steps: modal fusion, reasoning process
and knowledge verification. In modal fusion, we leverage textual clauses to
express fine-grained structural and semantic content of geometry diagram, and
fuse diagram with textual problem efficiently through structural-semantic
pre-training. For reasoning, we design an explicable solution program to
describe the geometric reasoning process, and employ a self-limited decoder to
generate solution program autoregressively. To reduce solution errors, a
multi-level theorem verifier is proposed to eliminate solutions that do not
match geometric principles, alleviating the hallucination of the neural model.
We also construct a large-scale geometry problem dataset called PGPS9K,
containing fine-grained annotations of textual clauses, solution program and
involved knowledge tuples. Extensive experiments on datasets Geometry3K and
PGPS9K show that our PGPSNet solver outperforms existing symbolic and neural
solvers in GPS performance, while maintaining good explainability and
reliability, and the solver components (fusion, reasoning, verification) are
all justified effective.

摘要：<paragraph>几何問題求解 (GPS) 需要具備多模態理解、多跳推理和定理知識應用能力。在本文中，我們提出了平面幾何問題求解 (PGPS) 的神經符號模型，名為 PGPSNet-v2，它包含三個關鍵步驟：模態融合、推理過程和知識驗證。在模態融合中，我們利用文本子句表達幾何圖形的細粒度結構和語義內容，並通過結構語義預訓練有效地將圖形與文本問題融合。對於推理，我們設計了一個可解釋的求解程式來描述幾何推理過程，並採用自限解碼器自迴歸生成求解程式。為了減少求解錯誤，提出了一個多級定理驗證器來消除不符合幾何原理的求解方案，從而減輕神經模型的幻覺。我們還構建了一個名為 PGPS9K 的大型幾何問題數據集，其中包含文本子句、求解程式和涉及的知識元組的細粒度註解。在數據集 Geometry3K 和 PGPS9K 上進行的廣泛實驗表明，我們的 PGPSNet 求解器在 GPS 性能方面優於現有的符號和神經求解器，同時保持良好的可解釋性和可靠性，並且求解器組件（融合、推理、驗證）都被證明是有效的。</paragraph>

##### **HiLight: Technical Report on the Motern AI Video Language Model**
2407.07325v2 by Zhiting Wang, Qiangong Zhou, Kangjie Yang, Zongyang Liu, Xin Mao

This technical report presents the implementation of a state-of-the-art video
encoder for video-text modal alignment and a video conversation framework
called HiLight, which features dual visual towers. The work is divided into two
main parts: 1.alignment of video and text modalities; 2.convenient and
efficient way to interact with users. Our goal is to address the task of video
comprehension in the context of billiards. The report includes a discussion of
the concepts and the final solution developed during the task's implementation.

摘要：本技術報告介紹了一個最先進的影片編碼器的實作，用於影片文字模態對齊，以及一個名為 HiLight 的影片對話架構，其特色是具有雙重視覺塔。這項工作分為兩個主要部分：1.影片與文字模態對齊；2.與使用者互動的便利且有效率的方式。我們的目標是解決在撞球背景下影片理解的任務。報告包含在任務實作期間發展的概念和最終解決方案的討論。

##### **RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension**
2407.07321v1 by Hung Phan, Anurag Acharya, Sarthak Chaturvedi, Shivam Sharma, Mike Parker, Dan Nally, Ali Jannesari, Karl Pazdernik, Mahantesh Halappanavar, Sai Munikoti, Sameera Horawalavithana

Large Language Models (LLMs) have been applied to many research problems
across various domains. One of the applications of LLMs is providing
question-answering systems that cater to users from different fields. The
effectiveness of LLM-based question-answering systems has already been
established at an acceptable level for users posing questions in popular and
public domains such as trivia and literature. However, it has not often been
established in niche domains that traditionally require specialized expertise.
To this end, we construct the NEPAQuAD1.0 benchmark to evaluate the performance
of three frontier LLMs -- Claude Sonnet, Gemini, and GPT-4 -- when answering
questions originating from Environmental Impact Statements prepared by U.S.
federal government agencies in accordance with the National Environmental
Environmental Act (NEPA). We specifically measure the ability of LLMs to
understand the nuances of legal, technical, and compliance-related information
present in NEPA documents in different contextual scenarios. For example, we
test the LLMs' internal prior NEPA knowledge by providing questions without any
context, as well as assess how LLMs synthesize the contextual information
present in long NEPA documents to facilitate the question/answering task. We
compare the performance of the long context LLMs and RAG powered models in
handling different types of questions (e.g., problem-solving, divergent). Our
results suggest that RAG powered models significantly outperform the long
context models in the answer accuracy regardless of the choice of the frontier
LLM. Our further analysis reveals that many models perform better answering
closed questions than divergent and problem-solving questions.

摘要：大型語言模型 (LLM) 已應用於各種領域的許多研究問題。LLM 的應用之一是提供針對不同領域使用者的問答系統。基於 LLM 的問答系統的有效性已在熱門和公共領域（例如瑣事和文學）中提出問題的使用者中達到可接受的水平。然而，它並未經常在傳統上需要專業知識的利基領域中建立。為此，我們構建了 NEPAQuAD1.0 基準來評估三個前沿 LLM 的性能——Claude Sonnet、Gemini 和 GPT-4——在回答由美國聯邦政府機構根據國家環境環境法 (NEPA) 編製的環境影響報告書中產生的問題時。我們特別衡量了 LLM 在不同語境場景中理解 NEPA 文件中存在的法律、技術和合規相關資訊細微差別的能力。例如，我們通過提供沒有任何背景的問題來測試 LLM 的內部先驗 NEPA 知識，並評估 LLM 如何綜合 NEPA 長文件中存在的語境資訊以促進問答任務。我們比較了長語境 LLM 和 RAG 驅動模型在處理不同類型問題（例如，問題解決、發散）方面的性能。我們的結果表明，無論選擇哪個前沿 LLM，RAG 驅動模型在回答準確性方面都顯著優於長語境模型。我們的進一步分析表明，許多模型在回答封閉式問題方面的表現優於發散式和問題解決問題。

##### **ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models**
2407.07313v1 by Benjamin Ascoli, Ram Kandikonda, Jinho D. Choi

The task of Text-to-SQL enables anyone to retrieve information from SQL
databases using natural language. Despite several challenges, recent models
have made remarkable advancements in this task using large language models
(LLMs). Interestingly, we find that LLM-based models without fine-tuning
exhibit distinct natures compared to their fine-tuned counterparts, leading to
inadequacies in current evaluation metrics to accurately convey their
performance. Thus, we analyze the two primary metrics, Test Suite Execution
Accuracy (EXE) and Exact Set Matching Accuracy (ESM), to examine their
robustness for this task and address shortcomings. We compare the performance
of 9 LLM-based models using EXE, the original ESM, and our improved ESM (called
ESM+). Our results show that EXE and ESM have high false positive and negative
rates of 11.3% and 13.9%, while ESM+ gives those of 0.1% and 2.6% respectively,
providing a significantly more stable evaluation. We release the ESM+ script as
open-source for the community to contribute, while enjoying a more reliable
assessment of Text-to-SQL.

摘要：文字轉 SQL 的任務讓任何人能夠使用自然語言從 SQL 資料庫中擷取資訊。儘管有許多挑戰，最近的模型使用大型語言模型 (LLM) 在這項任務中取得了顯著的進展。有趣的是，我們發現沒有微調的基於 LLM 的模型與經過微調的模型相比展現出截然不同的特性，導致目前的評估指標無法準確傳達其效能。因此，我們分析了兩個主要的指標，測試套件執行準確度 (EXE) 和完全集合匹配準確度 (ESM)，以檢查它們對這項任務的穩健性並解決缺點。我們使用 EXE、原始 ESM 和我們改進的 ESM（稱為 ESM+）比較了 9 個基於 LLM 的模型的效能。我們的結果顯示，EXE 和 ESM 的假陽性和假陰性比率分別高達 11.3% 和 13.9%，而 ESM+ 的比率分別為 0.1% 和 2.6%，提供了顯著更穩定的評估。我們將 ESM+ 腳本釋出為開源，供社群貢獻，同時享有對文字轉 SQL 的更可靠評估。

##### **ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting**
2407.07311v1 by Luoxiao Yang, Yun Wang, Xinqi Fan, Israel Cohen, Yue Zhao, Zijun Zhang

The success of large pretrained models in natural language processing (NLP)
and computer vision (CV) has opened new avenues for constructing foundation
models for time series forecasting (TSF). Traditional TSF foundation models
rely heavily on numerical data fitting. In contrast, the human brain is
inherently skilled at processing visual information, prefer predicting future
trends by observing visualized sequences. From a biomimetic perspective,
utilizing models to directly process numerical sequences might not be the most
effective route to achieving Artificial General Intelligence (AGI). This paper
proposes ViTime, a novel Visual Intelligence-based foundation model for TSF.
ViTime overcomes the limitations of numerical time series data fitting by
utilizing visual data processing paradigms and employs a innovative data
synthesis method during training, called Real Time Series (RealTS). Experiments
on a diverse set of previously unseen forecasting datasets demonstrate that
ViTime achieves state-of-the-art zero-shot performance, even surpassing the
best individually trained supervised models in some situations. These findings
suggest that visual intelligence can significantly enhance time series analysis
and forecasting, paving the way for more advanced and versatile models in the
field. The code for our framework is accessible at
https://github.com/IkeYang/ViTime.

摘要：大型預訓練模型在自然語言處理 (NLP) 和電腦視覺 (CV) 中的成功，為建構時間序列預測 (TSF) 的基礎模型開啟了新途徑。傳統的 TSF 基礎模型嚴重依賴數字資料擬合。相反地，人腦天生擅長處理視覺資訊，偏好透過觀察視覺化序列來預測未來趨勢。從仿生學的角度來看，使用模型直接處理數字序列可能不是實現人工通用智慧 (AGI) 的最有效途徑。本文提出 ViTime，一種基於視覺智慧的新型 TSF 基礎模型。ViTime 透過利用視覺資料處理範例，克服了數字時間序列資料擬合的限制，並在訓練期間採用創新的資料合成方法，稱為 Real Time Series (RealTS)。在各種先前未見過的預測資料集上進行的實驗證明，ViTime 達到了最先進的零次學習效能，甚至在某些情況下超越了個別訓練的最佳監督模型。這些發現表明，視覺智慧可以顯著增強時間序列分析和預測，為該領域更先進且多功能的模型鋪平道路。我們架構的程式碼可於 https://github.com/IkeYang/ViTime 取得。

##### **Inference Performance Optimization for Large Language Models on CPUs**
2407.07304v1 by Pujiang He, Shan Zhou, Wenhuan Huang, Changqing Li, Duyi Wang, Bin Guo, Chen Meng, Sheng Gui, Weifei Yu, Yi Xie

Large language models (LLMs) have shown exceptional performance and vast
potential across diverse tasks. However, the deployment of LLMs with high
performance in low-resource environments has garnered significant attention in
the industry. When GPU hardware resources are limited, we can explore
alternative options on CPUs. To mitigate the financial burden and alleviate
constraints imposed by hardware resources, optimizing inference performance is
necessary. In this paper, we introduce an easily deployable inference
performance optimization solution aimed at accelerating LLMs on CPUs. In this
solution, we implement an effective way to reduce the KV cache size while
ensuring precision. We propose a distributed inference optimization approach
and implement it based on oneAPI Collective Communications Library.
Furthermore, we propose optimization approaches for LLMs on CPU, and conduct
tailored optimizations for the most commonly used models. The code is
open-sourced at https://github.com/intel/xFasterTransformer.

摘要：大型語言模型 (LLM) 在各種任務中展現出非凡的效能和廣泛的潛力。然而，在低資源環境中部署高效能的 LLM 已引起業界的極大關注。當 GPU 硬體資源有限時，我們可以在 CPU 上探索其他選項。為了減輕財務負擔並緩解硬體資源帶來的限制，最佳化推理效能是必要的。在本文中，我們介紹了一個易於部署的推理效能最佳化解決方案，旨在加速 CPU 上的 LLM。在此解決方案中，我們實作了一種有效的方法來減少 KV 快取大小，同時確保精確度。我們提出了一種分散式推理最佳化方法，並根據 oneAPI Collective Communications Library 來實作它。此外，我們提出了針對 CPU 上 LLM 的最佳化方法，並針對最常用的模型進行客製化最佳化。程式碼已在 https://github.com/intel/xFasterTransformer 開源。

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

摘要：放射治療 (RT) 是最有效的癌症治療方法之一，其成功有賴於目標的準確描繪。然而，目標描繪是一項全面的醫療決策，目前完全依賴人類專家的手動程序。手動描繪耗時、費力，且受觀察者間差異影響。儘管人工智慧 (AI) 技術的進步已顯著增強正常組織的自動輪廓描繪，但 RT 目標體積的準確描繪仍是一項挑戰。在本研究中，我們提出一個基於視覺語言模型的 RT 目標體積自動描繪網路，稱為 Radformer。Radformer 利用階層式視覺Transformer作為主幹，並整合大型語言模型從臨床資料中提取豐富文字特徵。我們引入一個視覺語言注意力模組 (VLAM)，用於整合視覺和語言特徵，以進行語言感知視覺編碼 (LAVE)。Radformer 已在一個包含 2985 名接受 RT 治療的頭頸癌患者的資料集上進行評估。指標，包括 Dice 相似係數 (DSC)、聯集比 (IOU) 和第 95 個百分位數 Hausdorff 距離 (HD95)，用於定量評估模型的效能。我們的結果表明，與其他最先進的模型相比，Radformer 具有優異的分割效能，驗證了其在 RT 實務中應用的潛力。

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

摘要：在不作平穩假設的情況下從觀測時間序列中發現因果關係是一項重大挑戰。在實務中，這個挑戰在許多領域中很常見，例如零售銷售、運輸系統和醫學科學。在此，我們考慮非平穩時間序列類別的這個問題。這種類型的時間序列的結構因果模型 (SCM)，稱為半平穩時間序列，展示了有限數量的不同因果機制會隨著時間順序且週期性地發生。這個模型具有相當大的實用性，因為它可以表示週期性，包括季節性和晝夜變化等常見現象。我們提出了一個基於約束的非參數演算法，用於發現這個設定中的因果關係。產生的演算法 PCMCI$_{\Omega}$ 可以捕捉因果機制中的交替和重複變化，然後藉由條件獨立 (CI) 檢定來識別基礎因果圖。我們證明這個演算法在識別離散時間序列上的因果關係時是合理的。我們使用連續和離散模擬資料進行廣泛的實驗，以驗證演算法。我們也將我們的演算法應用於真實世界的氣候資料集。

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

摘要：時間序列的變異點偵測旨在找出時間序列的機率分佈改變的時間。它廣泛應用於許多領域，例如人類活動感測與醫學科學。在多變量時間序列的背景中，這通常涉及檢視高維度資料的聯合分佈：如果任何一個變數改變，則假設整個時間序列已經改變。然而，在實際應用中，我們可能只對時間序列的特定組成部分感興趣，探索它們的分佈在其他時間序列存在的情況下突然改變。在這裡，假設一個基礎的結構因果模型支配著時間序列資料的生成，我們透過提出一個兩階段非參數演算法來解決這個問題，該演算法首先透過基於約束的發現方法來學習因果結構的部分。然後，該演算法使用條件相對 Pearson 差異估計來找出變異點。條件相對 Pearson 差異量化時間序列中連續區段之間的分佈差異，而因果發現方法可以專注於因果機制，促進取得獨立且同分布 (IID) 的樣本。理論上，樣本為 IID 的典型假設在傳統變異點偵測方法中可以根據因果馬可夫條件放寬。透過在合成和真實世界資料集上進行實驗，我們驗證了我們方法的正確性和實用性。

##### **Structural Design Through Reinforcement Learning**
2407.07288v1 by Thomas Rochefort-Beaudoin, Aurelian Vadean, Niels Aage, Sofiane Achiche

This paper introduces the Structural Optimization gym (SOgym), a novel
open-source reinforcement learning environment designed to advance the
application of machine learning in topology optimization. SOgym aims for RL
agents to learn to generate physically viable and structurally robust designs
by integrating the physics of TO directly into the reward function. To enhance
scalability, SOgym leverages feature mapping methods as a mesh-independent
interface between the environment and the agent, allowing for efficient
interaction with the design variables regardless of the mesh resolution.
Baseline results are presented using a model-free proximal policy optimization
agent and a model-based DreamerV3 agent. Three observation space configurations
were tested. The TopOpt game inspired configuration, an interactive educational
tool that improves students' intuition in designing structures to minimize
compliance under volume constraints, performed best in terms of performance and
sample efficiency. The 100M parameter version of DreamerV3 produced structures
within 54% of the baseline compliance achieved by traditional optimization
methods as well as a 0% disconnection rate, an improvement over supervised
learning approaches that often struggle with disconnected load paths. When
comparing the learning rates of the agents to those of engineering students
from the TopOpt game experiment, the DreamerV3-100M model shows a learning rate
approximately four orders of magnitude lower, an impressive feat for a policy
trained from scratch through trial and error. These results suggest RL's
potential to solve continuous TO problems and its capacity to explore and learn
from diverse design solutions. SOgym provides a platform for developing RL
agents for complex structural design challenges and is publicly available to
support further research in the field.

摘要：<paragraph>本文介绍了结构优化健身房 (SOgym)，这是一个新颖的开源强化学习环境，旨在推进机器学习在拓扑优化中的应用。SOgym 的目标是让 RL 代理学习生成物理可行且结构稳健的设计，方法是将 TO 的物理特性直接整合到奖励函数中。为了提高可扩展性，SOgym 利用特征映射方法作为环境和代理之间的网格无关接口，从而可以与设计变量进行高效交互，而不管网格分辨率如何。使用无模型近端策略优化代理和基于模型的 DreamerV3 代理展示了基准结果。测试了三种观察空间配置。受 TopOpt 游戏启发的配置是一种交互式教育工具，可以提高学生在设计结构以最大限度地减少体积约束下的柔顺性方面的直觉，在性能和样本效率方面表现最佳。DreamerV3 的 100M 参数版本产生的结构在传统优化方法实现的基准柔顺性范围内为 54%，并且断开率为 0%，这比通常难以处理断开负载路径的监督学习方法有所改进。当将代理的学习率与来自 TopOpt 游戏实验的工程学生的学习率进行比较时，DreamerV3-100M 模型显示的学习率大约低四个数量级，对于通过反复试验从头开始训练的策略来说，这是一个令人印象深刻的壮举。这些结果表明 RL 有可能解决连续 TO 问题，并有能力探索和学习各种设计解决方案。SOgym 为开发用于复杂结构设计挑战的 RL 代理提供了一个平台，并且公开可用以支持该领域的进一步研究。</paragraph>

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

摘要：血液生物標記是醫療保健提供者用於診斷、監測和治療各種疾病的重要工具。目前的參考值和建議範圍通常依賴於人群統計數據，而這些數據可能無法充分說明由生活方式和基因等因素驅動的個體間變異的影響。在這項工作中，我們引入了一個新的框架來預測未來的血液生物標記值，並通過從生活方式數據（身體活動和睡眠）和血液生物標記中學習到的表徵來定義個性化參考。我們提出的方法學習了一個基於相似性的嵌入空間，該空間捕捉了生物標記和生活方式因素之間的複雜關係。使用英國生物銀行（257K 參與者），我們的結果表明，我們深度學習的嵌入優於傳統和當前最先進的表徵學習技術，可以預測臨床診斷。使用擁有後續訪視的 6440 名參與者的英國生物銀行子集，我們驗證了在血液生物標記模型中直接包含這些嵌入和生活方式因素可以改善從單次實驗室訪問中預測未來實驗室值。這種個性化建模方法為開發更準確的風險分層工具和定制預防保健策略提供了基礎。在臨床環境中，這轉化為早期疾病檢測、更及時的干預，最終轉向個性化醫療保健的潛力。

##### **Exploring Camera Encoder Designs for Autonomous Driving Perception**
2407.07276v1 by Barath Lakshmanan, Joshua Chen, Shiyi Lan, Maying Shen, Zhiding Yu, Jose M. Alvarez

The cornerstone of autonomous vehicles (AV) is a solid perception system,
where camera encoders play a crucial role. Existing works usually leverage
pre-trained Convolutional Neural Networks (CNN) or Vision Transformers (ViTs)
designed for general vision tasks, such as image classification, segmentation,
and 2D detection. Although those well-known architectures have achieved
state-of-the-art accuracy in AV-related tasks, e.g., 3D Object Detection, there
remains significant potential for improvement in network design due to the
nuanced complexities of industrial-level AV dataset. Moreover, existing public
AV benchmarks usually contain insufficient data, which might lead to inaccurate
evaluation of those architectures.To reveal the AV-specific model insights, we
start from a standard general-purpose encoder, ConvNeXt and progressively
transform the design. We adjust different design parameters including width and
depth of the model, stage compute ratio, attention mechanisms, and input
resolution, supported by systematic analysis to each modifications. This
customization yields an architecture optimized for AV camera encoder achieving
8.79% mAP improvement over the baseline. We believe our effort could become a
sweet cookbook of image encoders for AV and pave the way to the next-level
drive system.

摘要：自動駕駛車輛 (AV) 的基石是一個穩固的感知系統，其中相機編碼器扮演著至關重要的角色。現有的作品通常利用為一般視覺任務（例如影像分類、分割和 2D 偵測）設計的預先訓練的卷積神經網路 (CNN) 或視覺Transformer (ViT)。雖然這些著名的架構在 AV 相關任務（例如 3D 物件偵測）中已達到最先進的準確度，但由於產業級 AV 資料集的細微複雜性，網路設計仍有顯著的改進潛力。此外，現有的公開 AV 基準通常包含不足的資料，這可能會導致這些架構的評估不準確。為了揭示 AV 特定的模型見解，我們從一個標準的通用編碼器 ConvNeXt 開始，並逐步轉換設計。我們調整不同的設計參數，包括模型的寬度和深度、階段運算比、注意力機制和輸入解析度，並透過系統分析支援每個修改。此自訂化產生了一個針對 AV 相機編碼器最佳化的架構，與基準相比，mAP 提升了 8.79%。我們相信我們的努力可以成為 AV 影像編碼器的甜蜜食譜，並為下一級的驅動系統鋪路。

##### **Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support**
2407.07275v1 by Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife

Cinematic audio source separation (CASS) is a relatively new subtask of audio
source separation, concerned with the separation of a mixture into the
dialogue, music, and effects stems. To date, only one publicly available
dataset exists for CASS, that is, the Divide and Remaster (DnR) dataset, which
is currently at version 2. While DnR v2 has been an incredibly useful resource
for CASS, several areas of improvement have been identified, particularly
through its use in the 2023 Sound Demixing Challenge. In this work, we develop
version 3 of the DnR dataset, addressing issues relating to vocal content in
non-dialogue stems, loudness distributions, mastering process, and linguistic
diversity. In particular, the dialogue stem of DnR v3 includes speech content
from more than 30 languages from multiple families including but not limited to
the Germanic, Romance, Indo-Aryan, Dravidian, Malayo-Polynesian, and Bantu
families. Benchmark results using the Bandit model indicated that training on
multilingual data yields significant generalizability to the model even in
languages with low data availability. Even in languages with high data
availability, the multilingual model often performs on par or better than
dedicated models trained on monolingual CASS datasets.

摘要：電影音訊來源分離 (CASS) 是音訊來源分離的相對較新的子任務，關注於將混合音訊分離為對話、音樂和效果音源。迄今為止，CASS 僅有一個公開可用的資料集，即 Divide and Remaster (DnR) 資料集，目前為版本 2。雖然 DnR v2 一直是 CASS 的一個非常有用的資源，但已經找出幾個改善領域，特別是透過在 2023 年 Sound Demixing Challenge 中使用它。在此工作中，我們開發了 DnR 資料集的版本 3，解決了與非對話音源中的語音內容、響度分佈、母帶處理和語言多樣性相關的問題。特別是，DnR v3 的對話音源包含來自 30 多種語言的語音內容，這些語言來自多個語系，包括但不限於日耳曼語系、羅曼語系、印度-雅利安語系、達羅毗荼語系、馬來-波利尼西亞語系和班圖語系。使用 Bandit 模型的基準結果表明，即使在資料可用性低的語言中，在多語言資料上進行訓練也會對模型產生顯著的泛化性。即使在資料可用性高的語言中，多語言模型的表現通常與在單語言 CASS 資料集上訓練的專用模型相當或更好。

##### **Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models**
2407.07263v1 by Jupinder Parmar, Sanjev Satheesh, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

As language models have scaled both their number of parameters and
pretraining dataset sizes, the computational cost for pretraining has become
intractable except for the most well-resourced teams. This increasing cost
makes it ever more important to be able to reuse a model after it has completed
pretraining; allowing for a model's abilities to further improve without
needing to train from scratch. In this work, we detail a set of guidelines that
cover how to design efficacious data distributions and learning rate schedules
for continued pretraining of language models. When applying these findings
within a continued pretraining run on top of a well-trained 15B parameter
model, we show an improvement of 9\% in average model accuracy compared to the
baseline of continued training on the pretraining set. The resulting recipe
provides a practical starting point with which to begin developing language
models through reuse rather than retraining.

摘要：隨著語言模型擴展其參數數量和預訓練資料集大小，預訓練的運算成本已變得難以處理，除了資源最豐富的團隊外。這種成本的增加使得在預訓練完成後能夠重複使用模型變得更加重要；允許模型的能力進一步提升，而無需從頭開始訓練。在這項工作中，我們詳細說明了一組準則，涵蓋如何設計有效的資料分佈和學習率時間表，以持續預訓練語言模型。在訓練有素的 15B 參數模型上應用這些發現時，我們展示了與在預訓練集上持續訓練的基準相比，平均模型準確度提高了 9%。由此產生的方法提供了一個實用的起點，可以開始通過重複使用而不是重新訓練來開發語言模型。

##### **Identification of emotions on Twitter during the 2022 electoral process in Colombia**
2407.07258v1 by Juan Jose Iguaran Fernandez, Juan Manuel Perez, German Rosati

The study of Twitter as a means for analyzing social phenomena has gained
interest in recent years due to the availability of large amounts of data in a
relatively spontaneous environment. Within opinion-mining tasks, emotion
detection is specially relevant, as it allows for the identification of
people's subjective responses to different social events in a more granular way
than traditional sentiment analysis based on polarity. In the particular case
of political events, the analysis of emotions in social networks can provide
valuable information on the perception of candidates, proposals, and other
important aspects of the public debate. In spite of this importance, there are
few studies on emotion detection in Spanish and, to the best of our knowledge,
few resources are public for opinion mining in Colombian Spanish, highlighting
the need for generating resources addressing the specific cultural
characteristics of this variety. In this work, we present a small corpus of
tweets in Spanish related to the 2022 Colombian presidential elections,
manually labeled with emotions using a fine-grained taxonomy. We perform
classification experiments using supervised state-of-the-art models (BERT
models) and compare them with GPT-3.5 in few-shot learning settings. We make
our dataset and code publicly available for research purposes.

摘要：近年來，由於在相對自發的環境中獲得大量資料，將 Twitter 視為分析社會現象的一種手段的研究引起了興趣。在輿論挖掘任務中，情緒偵測特別相關，因為它允許以比傳統基於極性的情緒分析更細緻的方式，來識別人們對不同社會事件的主觀反應。特別是在政治事件中，社交網路中情緒的分析可以提供有關候選人、提案和其他重要公共辯論面向的觀感的有價值資訊。儘管如此重要，但對於西班牙語的情緒偵測研究卻很少，並且就我們所知，針對哥倫比亞西班牙語的輿論挖掘，公開的資源也很少，這突顯了產生針對此變體的特定文化特徵的資源的需求。在這項工作中，我們提出了一個與 2022 年哥倫比亞總統選舉相關的西班牙語推文語料庫，使用細緻的分類法手動標記情緒。我們使用監督最先進的模型（BERT 模型）執行分類實驗，並在少次學習設定中將它們與 GPT-3.5 進行比較。我們將我們的資料集和程式碼公開供研究用途。

##### **Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models**
2407.07229v1 by Yun Qi Li, Tuan Do, Evan Jones, Bernie Boscoe, Kevin Alfaro, Zooey Nguyen

Generative models producing images have enormous potential to advance
discoveries across scientific fields and require metrics capable of quantifying
the high dimensional output. We propose that astrophysics data, such as galaxy
images, can test generative models with additional physics-motivated ground
truths in addition to human judgment. For example, galaxies in the Universe
form and change over billions of years, following physical laws and
relationships that are both easy to characterize and difficult to encode in
generative models. We build a conditional denoising diffusion probabilistic
model (DDPM) and a conditional variational autoencoder (CVAE) and test their
ability to generate realistic galaxies conditioned on their redshifts (galaxy
ages). This is one of the first studies to probe these generative models using
physically motivated metrics. We find that both models produce comparable
realistic galaxies based on human evaluation, but our physics-based metrics are
better able to discern the strengths and weaknesses of the generative models.
Overall, the DDPM model performs better than the CVAE on the majority of the
physics-based metrics. Ultimately, if we can show that generative models can
learn the physics of galaxy evolution, they have the potential to unlock new
astrophysical discoveries.

摘要：生成影像的生成模型具有促進科學領域發現的巨大潛力，並且需要能夠量化高維度輸出的指標。我們提出，天文物理數據（例如星系影像）可以使用額外的物理激勵基準真值以及人為判斷來測試生成模型。舉例來說，宇宙中的星系在數十億年來形成並改變，遵循物理定律和關係，這些定律和關係既容易描述，又難以編碼在生成模型中。我們建構條件式去噪擴散機率模型 (DDPM) 和條件式變異自動編碼器 (CVAE)，並測試它們在以紅移（星系年齡）為條件下產生逼真星系的能力。這是第一批使用物理激勵指標探測這些生成模型的研究之一。我們發現，根據人為評估，這兩個模型都能產生可比較的逼真星系，但我們的基於物理的指標更能辨別生成模型的優缺點。總體而言，DDPM 模型在大部分基於物理的指標上表現優於 CVAE。最終，如果我們能證明生成模型可以學習星系演化的物理，它們就有可能解鎖新的天體物理發現。

##### **ConvNLP: Image-based AI Text Detection**
2407.07225v1 by Suriya Prakash Jambunathan, Ashwath Shankarnarayan, Parijat Dube

The potentials of Generative-AI technologies like Large Language models
(LLMs) to revolutionize education are undermined by ethical considerations
around their misuse which worsens the problem of academic dishonesty. LLMs like
GPT-4 and Llama 2 are becoming increasingly powerful in generating
sophisticated content and answering questions, from writing academic essays to
solving complex math problems. Students are relying on these LLMs to complete
their assignments and thus compromising academic integrity. Solutions to detect
LLM-generated text are compute-intensive and often lack generalization. This
paper presents a novel approach for detecting LLM-generated AI-text using a
visual representation of word embedding. We have formulated a novel
Convolutional Neural Network called ZigZag ResNet, as well as a scheduler for
improving generalization, named ZigZag Scheduler. Through extensive evaluation
using datasets of text generated by six different state-of-the-art LLMs, our
model demonstrates strong intra-domain and inter-domain generalization
capabilities. Our best model detects AI-generated text with an impressive
average detection rate (over inter- and intra-domain test data) of 88.35%.
Through an exhaustive ablation study, our ZigZag ResNet and ZigZag Scheduler
provide a performance improvement of nearly 4% over the vanilla ResNet. The
end-to-end inference latency of our model is below 2.5ms per sentence. Our
solution offers a lightweight, computationally efficient, and faster
alternative to existing tools for AI-generated text detection, with better
generalization performance. It can help academic institutions in their fight
against the misuse of LLMs in academic settings. Through this work, we aim to
contribute to safeguarding the principles of academic integrity and ensuring
the trustworthiness of student work in the era of advanced LLMs.

摘要：<paragraph>大型語言模型 (LLM) 等生成式 AI 技術的潛力，可能會因為其誤用所帶來的道德考量而受到削弱，這會惡化學術不誠實的問題。GPT-4 和 Llama 2 等 LLM 在產生精緻內容和回答問題方面變得越來越強大，從撰寫學術論文到解決複雜的數學問題。學生依賴這些 LLM 來完成作業，因此損害了學術誠信。偵測 LLM 生成的文字的解決方案需要大量的運算，而且通常缺乏概括性。本文提出了一個新穎的方法，使用詞嵌入的視覺表示來偵測 LLM 生成的 AI 文字。我們制定了一個名為 ZigZag ResNet 的新卷積神經網路，以及一個名為 ZigZag Scheduler 的排程器，以改善概括性。透過使用六個不同的最先進 LLM 生成的文字資料集進行廣泛的評估，我們的模型展示了強大的領域內和領域間概括能力。我們最好的模型以令人印象深刻的平均檢測率 (超過領域間和領域內測試資料) 88.35% 檢測到 AI 生成的文字。透過詳盡的消融研究，我們的 ZigZag ResNet 和 ZigZag Scheduler 提供了比香草 ResNet 幾乎提升 4% 的效能。我們模型的端到端推論延遲低於每句 2.5 毫秒。我們的解決方案提供了一個輕量級、計算效率高且比現有 AI 生成的文字偵測工具更快的替代方案，並具有更好的概括效能。它可以幫助學術機構對抗在學術環境中濫用 LLM 的行為。透過這項工作，我們旨在為維護學術誠信的原則做出貢獻，並確保在先進 LLM 的時代中學生作業的可信度。</paragraph>

##### **AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning**
2407.07094v1 by Jiaxi Cui, Wentao Zhang, Jing Tang, Xudong Tong, Zhenwei Zhang, Amie, Jing Wen, Rongsheng Wang, Pengfei Wu

The pervasive deployment of Large Language Models-LLMs in various sectors
often neglects the nuanced requirements of individuals and small organizations,
who benefit more from models precisely tailored to their specific business
contexts rather than those with broadly superior general capabilities. This
work introduces \textbf{AnyTaskTune}, a novel fine-tuning methodology coined as
\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on
a diverse array of domain-specific tasks. This method involves a meticulous
process to identify and define targeted sub-tasks within a domain, followed by
the creation of specialized enhancement datasets for fine-tuning, thereby
optimizing task-specific model performance. We conducted comprehensive
fine-tuning experiments not only in the legal domain for tasks such as keyword
extraction and sentence prediction but across over twenty different sub-tasks
derived from the domains of finance, healthcare, law, psychology, consumer
services, and human resources. To substantiate our approach and facilitate
community engagement, we will open-source these bilingual task datasets. Our
findings demonstrate that models fine-tuned using the \textbf{Task-Fine-Tune}
methodology not only achieve superior performance on these specific tasks but
also significantly outperform models with higher general capabilities in their
respective domains. Our work is publicly available at
\url{https://github.com/PandaVT/DataTager}.

摘要：各種產業中普遍部署大型語言模型 (LLM) 時，常常忽略個人和小型組織的細微需求，而這些對象較能從精準調整到其特定商業脈絡的模型中獲益，而非具備廣泛卓越一般能力的模型。本研究介紹一種新穎的微調方法，稱為「任務微調」(Task-Fine-Tune)，專門開發用於提升模型在各種特定領域任務上的效能。此方法包含一個細緻的程序，用於識別和定義領域內的目標子任務，然後建立專門的強化資料集進行微調，進而最佳化特定任務的模型效能。我們不僅在法律領域進行全面的微調實驗，針對關鍵字萃取和句子預測等任務，還涵蓋從金融、醫療保健、法律、心理學、消費者服務和人力資源等領域衍生的二十多個不同子任務。為了證實我們的做法並促進社群參與，我們將開放這些雙語任務資料集的原始碼。我們的研究結果顯示，使用「任務微調」方法微調的模型不僅在這些特定任務上達到卓越效能，而且在各自領域中也明顯優於具備較高一般能力的模型。我們的研究成果已於 https://github.com/PandaVT/DataTager 公開。

##### **FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation**
2407.07093v1 by Liqun Ma, Mingjie Sun, Zhiqiang Shen

This work presents a Fully BInarized Large Language Model (FBI-LLM),
demonstrating for the first time how to train a large-scale binary language
model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to
match the performance of its full-precision counterparts (e.g., FP16 or BF16)
in transformer-based LLMs. It achieves this by employing an autoregressive
distillation (AD) loss with maintaining equivalent model dimensions (130M,
1.3B, 7B) and training data volume as regular LLM pretraining, while delivering
competitive results in terms of perplexity and task-specific effectiveness.
Intriguingly, by analyzing the training trajectory, we find that the pretrained
weight is not necessary for training binarized LLMs from scratch. This research
encourages a new computational framework and may facilitate the future design
of specialized hardware tailored for fully 1-bit LLMs. We make all models,
code, and training dataset fully accessible and transparent to support further
research (Code: https://github.com/LiqunMa/FBI-LLM. Model:
https://huggingface.co/LiqunMa/).

摘要：本研究提出了一個全二值化大型語言模型 (FBI-LLM)，首次展示如何從頭訓練一個大型二值語言模型（不是像 BitNet b1.58 那樣的局部二值或三值 LLM），以匹配其全精度對應項（例如，FP16 或 BF16）在基於Transformer的 LLM 中的性能。它通過採用自迴歸蒸餾 (AD) 損失來實現這一點，同時保持等效的模型維度（130M、1.3B、7B）和訓練數據量作為常規 LLM 預訓練，同時在困惑度和特定任務的有效性方面提供有競爭力的結果。有趣的是，通過分析訓練軌跡，我們發現預訓練權重對於從頭訓練二值化 LLM 並非必要。這項研究鼓勵新的計算框架，並可能促進專門針對全 1 位元 LLM 量身打造的硬體的未來設計。我們讓所有模型、程式碼和訓練資料集完全公開且透明，以支持進一步的研究（程式碼：https://github.com/LiqunMa/FBI-LLM。模型：https://huggingface.co/LiqunMa/）。

##### **Safe and Reliable Training of Learning-Based Aerospace Controllers**
2407.07088v1 by Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee Newell, Umberto Ravaioli, Baoluo Meng, Michael Durling, Kerianne Hobbs, Milan Ganai, Tobey Shim, Guy Katz, Clark Barrett

In recent years, deep reinforcement learning (DRL) approaches have generated
highly successful controllers for a myriad of complex domains. However, the
opaque nature of these models limits their applicability in aerospace systems
and safety-critical domains, in which a single mistake can have dire
consequences. In this paper, we present novel advancements in both the training
and verification of DRL controllers, which can help ensure their safe behavior.
We showcase a design-for-verification approach utilizing k-induction and
demonstrate its use in verifying liveness properties. In addition, we also give
a brief overview of neural Lyapunov Barrier certificates and summarize their
capabilities on a case study. Finally, we describe several other novel
reachability-based approaches which, despite failing to provide guarantees of
interest, could be effective for verification of other DRL systems, and could
be of further interest to the community.

摘要：近年來，深度強化學習 (DRL) 方法已產生了許多複雜領域的極為成功的控制器。然而，這些模型的不透明性質限制了它們在航空太空系統和安全關鍵領域中的應用性，在這些領域中，一個錯誤可能會導致可怕的後果。在本文中，我們展示了 DRL 控制器的訓練和驗證方面的最新進展，這有助於確保其安全行為。我們展示了一個利用 k 感應的設計驗證方法，並展示了它在驗證活性屬性中的用途。此外，我們還簡要概述了神經李亞普諾夫障礙證書，並總結了它們在案例研究中的能力。最後，我們描述了幾種其他新穎的可達性方法，儘管這些方法未能提供感興趣的保證，但它們對於驗證其他 DRL 系統可能是有效的，並且可能對社區進一步感興趣。

##### **CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation**
2407.07087v1 by Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh

Evaluating the degree of reproduction of copyright-protected content by
language models (LMs) is of significant interest to the AI and legal
communities. Although both literal and non-literal similarities are considered
by courts when assessing the degree of reproduction, prior research has focused
only on literal similarities. To bridge this gap, we introduce CopyBench, a
benchmark designed to measure both literal and non-literal copying in LM
generations. Using copyrighted fiction books as text sources, we provide
automatic evaluation protocols to assess literal and non-literal copying,
balanced against the model utility in terms of the ability to recall facts from
the copyrighted works and generate fluent completions. We find that, although
literal copying is relatively rare, two types of non-literal copying -- event
copying and character copying -- occur even in models as small as 7B
parameters. Larger models demonstrate significantly more copying, with literal
copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3%
to 6.9% when comparing Llama3-8B and 70B models, respectively. We further
evaluate the effectiveness of current strategies for mitigating copying and
show that (1) training-time alignment can reduce literal copying but may
increase non-literal copying, and (2) current inference-time mitigation methods
primarily reduce literal but not non-literal copying.

摘要：評估語言模型 (LM) 複製受版權保護內容的程度，對 AI 和法律社群而言意義重大。儘管法院在評估複製程度時會考慮文字和非文字的相似性，但先前的研究僅關注文字相似性。為了彌補這個差距，我們引入了 CopyBench，一個基準測試，旨在衡量 LM 生成中的文字和非文字複製。使用受版權保護的小說書籍作為文本來源，我們提供了自動評估協定，以評估文字和非文字複製，並根據從受版權保護的作品中提取事實和產生流暢完成的能力，來衡量模型實用性。我們發現，儘管文字複製相對罕見，但即使在參數小至 7B 的模型中，也會發生兩種非文字複製——事件複製和角色複製。較大的模型顯示出顯著更多的複製，當比較 Llama3-8B 和 70B 模型時，文字複製率從 0.2% 增加到 10.5%，非文字複製從 2.3% 增加到 6.9%。我們進一步評估了當前減輕複製策略的有效性，並表明 (1) 訓練時間校準可以減少文字複製，但可能會增加非文字複製，以及 (2) 當前的推論時間減輕方法主要減少文字複製，但不會減少非文字複製。

##### **Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models**
2407.07086v1 by Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber

Multi-agent reinforcement learning (MARL) methods struggle with the
non-stationarity of multi-agent systems and fail to adaptively learn online
when tested with novel agents. Here, we leverage large language models (LLMs)
to create an autonomous agent that can handle these challenges. Our agent,
Hypothetical Minds, consists of a cognitively-inspired architecture, featuring
modular components for perception, memory, and hierarchical planning over two
levels of abstraction. We introduce the Theory of Mind module that scaffolds
the high-level planning process by generating hypotheses about other agents'
strategies in natural language. It then evaluates and iteratively refines these
hypotheses by reinforcing hypotheses that make correct predictions about the
other agents' behavior. Hypothetical Minds significantly improves performance
over previous LLM-agent and RL baselines on a range of competitive, mixed
motive, and collaborative domains in the Melting Pot benchmark, including both
dyadic and population-based environments. Additionally, comparisons against
LLM-agent baselines and ablations reveal the importance of hypothesis
evaluation and refinement for succeeding on complex scenarios.

摘要：多智能體強化學習 (MARL) 方法難以應對多智能體系統的不穩定性，並且在使用新智能體進行測試時無法適應性地線上學習。在這裡，我們利用大型語言模型 (LLM) 來創建一個可以應對這些挑戰的自主智能體。我們的智能體 Hypothetical Minds 由認知啟發的架構組成，具有用於感知、記憶和分層規劃的模組化組件，涵蓋兩個抽象層級。我們引入了心智理論模組，該模組透過以自然語言生成關於其他智能體策略的假設，來支撐高階規劃流程。然後，它會評估並反覆優化這些假設，方法是強化對其他智能體行為做出正確預測的假設。在 Melting Pot 基準中的一系列競爭、混合動機和協作領域（包括二元和基於群體的環境），Hypothetical Minds 的效能顯著優於先前的 LLM 智能體和 RL 基準。此外，與 LLM 智能體基線和消融的比較顯示了假設評估和優化對於在複雜場景中取得成功的重要性。

##### **Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities**
2407.07080v1 by Shaltiel Shmidman, Avi Shmidman, Amir DN Cohen, Moshe Koppel

Training large language models (LLMs) in low-resource languages such as
Hebrew poses unique challenges. In this paper, we introduce DictaLM2.0 and
DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a
substantial corpus of approximately 200 billion tokens in both Hebrew and
English. Adapting a pre-trained model to a new language involves specialized
techniques that differ significantly from training a model from scratch or
further training existing models on well-resourced languages such as English.
We outline these novel training methodologies, which facilitate effective
learning and adaptation to the linguistic properties of Hebrew. Additionally,
we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to
enhance its performance on task-specific instructions. To rigorously evaluate
our models, we introduce a new benchmark suite for Hebrew LLM evaluation,
covering a diverse set of tasks including Question Answering, Sentiment
Analysis, Winograd Schema Challenge, Translation, and Summarization. Our work
not only addresses the intricacies of training LLMs in low-resource languages
but also proposes a framework that can be leveraged for adapting other LLMs to
various non-English languages, contributing to the broader field of
multilingual NLP.

摘要：在希伯來語等低資源語言中訓練大型語言模型 (LLM) 會帶來獨特的挑戰。在本文中，我們介紹了 DictaLM2.0 和 DictaLM2.0-Instruct，這兩個 LLM 是從 Mistral 模型衍生的，並在包含約 2,000 億個希伯來語和英語詞彙的龐大語料庫中訓練。將預訓練模型適應到新語言涉及專業技術，這與從頭開始訓練模型或進一步訓練現有模型（例如英語等資源豐富的語言）有顯著不同。我們概述了這些新穎的訓練方法，有助於有效學習和適應希伯來語的語言特性。此外，我們針對全面的指導資料集微調 DictaLM2.0-Instruct，以提升其在特定任務指示上的效能。為了嚴格評估我們的模型，我們為希伯來語 LLM 評估引入了新的基準組，涵蓋了多樣化的任務集，包括問答、情緒分析、Winograd 模式挑戰、翻譯和摘要。我們的研究不僅解決了在低資源語言中訓練 LLM 的複雜性，還提出了可用於將其他 LLM 適應到各種非英語語言的架構，為多語言 NLP 的廣泛領域做出貢獻。

##### **ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction**
2407.07077v1 by Shaozhe Hao, Kai Han, Zhengyao Lv, Shihao Zhao, Kwan-Yee K. Wong

While personalized text-to-image generation has enabled the learning of a
single concept from multiple images, a more practical yet challenging scenario
involves learning multiple concepts within a single image. However, existing
works tackling this scenario heavily rely on extensive human annotations. In
this paper, we introduce a novel task named Unsupervised Concept Extraction
(UCE) that considers an unsupervised setting without any human knowledge of the
concepts. Given an image that contains multiple concepts, the task aims to
extract and recreate individual concepts solely relying on the existing
knowledge from pretrained diffusion models. To achieve this, we present
ConceptExpress that tackles UCE by unleashing the inherent capabilities of
pretrained diffusion models in two aspects. Specifically, a concept
localization approach automatically locates and disentangles salient concepts
by leveraging spatial correspondence from diffusion self-attention; and based
on the lookup association between a concept and a conceptual token, a
concept-wise optimization process learns discriminative tokens that represent
each individual concept. Finally, we establish an evaluation protocol tailored
for the UCE task. Extensive experiments demonstrate that ConceptExpress is a
promising solution to the UCE task. Our code and data are available at:
https://github.com/haoosz/ConceptExpress

摘要：<paragraph>雖然個人化的文字轉圖像生成已能從多張圖像中學習單一概念，但更實際且具挑戰性的場景是學習單一圖像中的多個概念。然而，現有的處理此場景的作品極度依賴於大量的標註。在本文中，我們引入了一個名為無監督概念萃取 (UCE) 的新任務，它考慮了在沒有人類概念知識的情況下的無監督設定。給定包含多個概念的圖像，此任務旨在僅依賴於預訓練擴散模型的現有知識來萃取和重建個別概念。為達成此目的，我們提出了 ConceptExpress，它透過釋放預訓練擴散模型在兩個方面的固有能力來處理 UCE。具體來說，概念定位方法透過利用擴散自注意力中的空間對應自動定位和解開顯著概念；而基於概念和概念 token 之間的查詢關聯，概念優化程序會學習表示每個個別概念的區分 token。最後，我們建立了一個專門針對 UCE 任務的評估協定。廣泛的實驗證明 ConceptExpress 是 UCE 任務的有前途的解決方案。我們的程式碼和資料可在以下取得：https://github.com/haoosz/ConceptExpress</paragraph>

##### **Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps**
2407.07071v1 by Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James Glass

When asked to summarize articles or answer questions given a passage, large
language models (LLMs) can hallucinate details and respond with unsubstantiated
answers that are inaccurate with respect to the input context. This paper
describes a simple approach for detecting such contextual hallucinations. We
hypothesize that contextual hallucinations are related to the extent to which
an LLM attends to information in the provided context versus its own
generations. Based on this intuition, we propose a simple hallucination
detection model whose input features are given by the ratio of attention
weights on the context versus newly generated tokens (for each attention head).
We find that a linear classifier based on these lookback ratio features is as
effective as a richer detector that utilizes the entire hidden states of an LLM
or a text-based entailment model. The lookback ratio-based detector -- Lookback
Lens -- is found to transfer across tasks and even models, allowing a detector
that is trained on a 7B model to be applied (without retraining) to a larger
13B model. We further apply this detector to mitigate contextual
hallucinations, and find that a simple classifier-guided decoding approach is
able to reduce the amount of hallucination, for example by 9.6% in the XSum
summarization task.

摘要：當要求大型語言模型 (LLM) 總結文章或回答給定段落的題目時，它們可能會產生幻覺細節，並以與輸入內容無關的不實答案回應。本論文描述了一種檢測此類語境幻覺的簡單方法。我們假設語境幻覺與 LLM 關注所提供語境中的資訊與其自身產生的資訊的程度有關。基於此直覺，我們提出了一個簡單的幻覺檢測模型，其輸入特徵由語境與新產生的權標 (對於每個注意力頭) 上的注意力權重比率給出。我們發現基於這些回顧比率特徵的線性分類器與利用 LLM 的整個隱藏狀態或基於文字的蘊涵模型的更豐富的檢測器一樣有效。發現基於回顧比率的檢測器——回顧鏡頭——可以跨任務甚至跨模型傳輸，允許在 7B 模型上訓練的檢測器應用於更大的 13B 模型 (無需重新訓練)。我們進一步應用此檢測器來減輕語境幻覺，並發現一個簡單的分類器引導的解碼方法能夠減少幻覺量，例如在 XSum 摘要任務中減少 9.6%。

##### **Prompting Techniques for Secure Code Generation: A Systematic Investigation**
2407.07064v1 by Catherine Tony, Nicolás E. Díaz Ferreyra, Markus Mutas, Salem Dhiff, Riccardo Scandariato

Large Language Models (LLMs) are gaining momentum in software development
with prompt-driven programming enabling developers to create code from natural
language (NL) instructions. However, studies have questioned their ability to
produce secure code and, thereby, the quality of prompt-generated software.
Alongside, various prompting techniques that carefully tailor prompts have
emerged to elicit optimal responses from LLMs. Still, the interplay between
such prompting strategies and secure code generation remains under-explored and
calls for further investigations. OBJECTIVE: In this study, we investigate the
impact of different prompting techniques on the security of code generated from
NL instructions by LLMs. METHOD: First we perform a systematic literature
review to identify the existing prompting techniques that can be used for code
generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,
and GPT-4 models for secure code generation. For this, we used an existing
dataset consisting of 150 NL security-relevant code-generation prompts.
RESULTS: Our work (i) classifies potential prompting techniques for code
generation (ii) adapts and evaluates a subset of the identified techniques for
secure code generation tasks and (iii) observes a reduction in security
weaknesses across the tested LLMs, especially after using an existing technique
called Recursive Criticism and Improvement (RCI), contributing valuable
insights to the ongoing discourse on LLM-generated code security.

摘要：大型語言模型 (LLM) 在軟體開發中獲得了動能，提示驅動程式讓開發人員能夠從自然語言 (NL) 指令建立程式碼。然而，研究質疑它們產生安全程式碼的能力，從而質疑提示產生的軟體品質。此外，出現了各種仔細調整提示的提示技術，從 LLM 引發最佳回應。儘管如此，這種提示策略與安全程式碼產生之間的交互作用仍然未被充分探討，並需要進一步調查。目標：在本研究中，我們調查了不同提示技術對 LLM 從 NL 指令產生的程式碼安全性的影響。方法：首先，我們執行系統性的文獻回顧，以找出可用於程式碼產生任務的現有提示技術。在 GPT-3、GPT-3.5 和 GPT-4 模型上評估這些技術的子集，以產生安全程式碼。為此，我們使用了一個現有的資料集，其中包含 150 個與 NL 安全相關的程式碼產生提示。結果：我們的研究 (i) 分類了程式碼產生的潛在提示技術 (ii) 調整並評估了一部分已識別的技術，以進行安全的程式碼產生任務，以及 (iii) 觀察到在測試的 LLM 中，特別是在使用現有的技術，稱為遞迴批評和改進 (RCI) 之後，安全性弱點減少，為 LLM 產生的程式碼安全性持續討論提供了有價值的見解。

##### **Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence**
2407.07061v2 by Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun

The rapid advancement of large language models (LLMs) has paved the way for
the development of highly capable autonomous agents. However, existing
multi-agent frameworks often struggle with integrating diverse capable
third-party agents due to reliance on agents defined within their own
ecosystems. They also face challenges in simulating distributed environments,
as most frameworks are limited to single-device setups. Furthermore, these
frameworks often rely on hard-coded communication pipelines, limiting their
adaptability to dynamic task requirements. Inspired by the concept of the
Internet, we propose the Internet of Agents (IoA), a novel framework that
addresses these limitations by providing a flexible and scalable platform for
LLM-based multi-agent collaboration. IoA introduces an agent integration
protocol, an instant-messaging-like architecture design, and dynamic mechanisms
for agent teaming and conversation flow control. Through extensive experiments
on general assistant tasks, embodied AI tasks, and retrieval-augmented
generation benchmarks, we demonstrate that IoA consistently outperforms
state-of-the-art baselines, showcasing its ability to facilitate effective
collaboration among heterogeneous agents. IoA represents a step towards linking
diverse agents in an Internet-like environment, where agents can seamlessly
collaborate to achieve greater intelligence and capabilities. Our codebase has
been released at \url{https://github.com/OpenBMB/IoA}.

摘要：大型語言模型 (LLM) 的快速進展為高度自主代理的發展鋪平了道路。然而，現有的多代理架構通常難以整合多樣化的第三方代理，因為它們依賴於在自身生態系統中定義的代理。它們在模擬分散式環境時也面臨挑戰，因為大多數架構僅限於單設備設置。此外，這些架構通常依賴於硬編碼的通信管道，限制了它們適應動態任務需求的能力。受互聯網概念的啟發，我們提出了代理互聯網 (IoA)，這是一個新穎的框架，通過提供一個靈活且可擴展的 LLM 多代理協作平台來解決這些限制。IoA 引入了代理整合協議、即時訊息類架構設計以及代理組隊和對話流程控制的動態機制。通過對一般助理任務、具體化 AI 任務和檢索增強生成基準的廣泛實驗，我們證明 IoA 始終優於最先進的基準，展示了其促進異質代理之間有效協作的能力。IoA 代表了在類互聯網環境中連結不同代理的一步，在該環境中，代理可以無縫協作以實現更高的智慧和能力。我們的代碼庫已發布於 \url{https://github.com/OpenBMB/IoA}。

##### **CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis**
2407.07046v1 by Yangmin Li, Ruiqi Zhu, Wengen Li

Multimodal sentiment analysis is an active research area that combines
multiple data modalities, e.g., text, image and audio, to analyze human
emotions and benefits a variety of applications. Existing multimodal sentiment
analysis methods can be classified as modality interaction-based methods,
modality transformation-based methods and modality similarity-based methods.
However, most of these methods highly rely on the strong correlations between
modalities, and cannot fully uncover and utilize the correlations between
modalities to enhance sentiment analysis. Therefore, these methods usually
achieve bad performance for identifying the sentiment of multimodal data with
weak correlations. To address this issue, we proposed a two-stage
semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)
which consists pre-training stage and prediction stage. At the pre-training
stage, a modality correlation contrastive learning module is designed to
efficiently learn modality correlation coefficients between different
modalities. At the prediction stage, the learned correlation coefficients are
fused with modality representations to make the sentiment prediction. According
to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT
obviously surpasses state-of-the-art multimodal sentiment analysis methods.

摘要：多模态情感分析是一个活跃的研究领域，它结合了多种数据模式，例如文本、图像和音频，来分析人类情绪，并使各种应用程序受益。现有的多模态情感分析方法可以分为基于模态交互的方法、基于模态转换的方法和基于模态相似性的方法。然而，这些方法大多高度依赖于模态之间的强相关性，并且无法充分发现和利用模态之间的相关性来增强情感分析。因此，这些方法通常在识别弱相关性多模态数据的语义时表现不佳。为了解决这个问题，我们提出了一个两阶段的半监督模型，称为相关感知多模态转换器 (CorMulT)，它由预训练阶段和预测阶段组成。在预训练阶段，设计了一个模态相关对比学习模块，以有效地学习不同模态之间的模态相关系数。在预测阶段，学习到的相关系数与模态表示融合，以进行情感预测。根据流行的多模态数据集 CMU-MOSEI 上的实验，CorMulT 明显超越了最先进的多模态情感分析方法。

##### **Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs**
2407.07045v1 by Christian Riefolo, Nicola Fanizzi, Claudia d'Amato

Tackling the problem of learning probabilistic classifiers from incomplete
data in the context of Knowledge Graphs expressed in Description Logics, we
describe an inductive approach based on learning simple belief networks.
Specifically, we consider a basic probabilistic model, a Naive Bayes
classifier, based on multivariate Bernoullis and its extension to a two-tier
network in which this classification model is connected to a lower layer
consisting of a mixture of Bernoullis. We show how such models can be converted
into (probabilistic) axioms (or rules) thus ensuring more interpretability.
Moreover they may be also initialized exploiting expert knowledge. We present
and discuss the outcomes of an empirical evaluation which aimed at testing the
effectiveness of the models on a number of random classification problems with
different ontologies.

摘要：針對在描述邏輯中表示的知識圖表中從不完整資料學習機率分類器的問題，我們描述一種基於學習簡單信念網路的歸納方法。具體來說，我們考慮一個基本的機率模型，一個樸素貝氏分類器，它基於多變量伯努利分布及其擴展到一個兩層網路，其中這個分類模型連接到由伯努利混合組成的下層。我們展示如何將這些模型轉換為（機率）公理（或規則），從而確保更高的可解釋性。此外，它們還可以利用專家知識進行初始化。我們提出並討論了實證評估的結果，其目的是測試這些模型在具有不同本體的多個隨機分類問題上的有效性。

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models**
2407.07035v1 by Yue Zhang, Ziqiao Ma, Jialu Li, Yanyuan Qiao, Zun Wang, Joyce Chai, Qi Wu, Mohit Bansal, Parisa Kordjamshidi

Vision-and-Language Navigation (VLN) has gained increasing attention over
recent years and many approaches have emerged to advance their development. The
remarkable achievements of foundation models have shaped the challenges and
proposed methods for VLN research. In this survey, we provide a top-down review
that adopts a principled framework for embodied planning and reasoning, and
emphasizes the current methods and future opportunities leveraging foundation
models to address VLN challenges. We hope our in-depth discussions could
provide valuable resources and insights: on one hand, to milestone the progress
and explore opportunities and potential roles for foundation models in this
field, and on the other, to organize different challenges and solutions in VLN
to foundation model researchers.

摘要：視覺語言導航 (VLN) 近年來備受關注，許多方法也應運而生，以推進其發展。基礎模型的顯著成就塑造了 VLN 研究的挑戰和提出的方法。在這項調查中，我們提供了一項自上而下的回顧，採用了具體的框架進行具體規劃和推理，並強調了當前的方法和未來的機會，利用基礎模型來應對 VLN 挑戰。我們希望我們的深入討論能提供有價值的資源和見解：一方面，記錄進度並探索基礎模型在這一領域的機會和潛在作用，另一方面，組織 VLN 中不同的挑戰和解決方案，以供基礎模型研究人員參考。

##### **Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition**
2407.07026v1 by Daiqing Wu, Dongbao Yang, Huawen Shen, Can Ma, Yu Zhou

With the proliferation of social media posts in recent years, the need to
detect sentiments in multimodal (image-text) content has grown rapidly. Since
posts are user-generated, the image and text from the same post can express
different or even contradictory sentiments, leading to potential
\textbf{sentiment discrepancy}. However, existing works mainly adopt a
single-branch fusion structure that primarily captures the consistent sentiment
between image and text. The ignorance or implicit modeling of discrepant
sentiment results in compromised unimodal encoding and limited performances. In
this paper, we propose a semantics Completion and Decomposition (CoDe) network
to resolve the above issue. In the semantics completion module, we complement
image and text representations with the semantics of the OCR text embedded in
the image, helping bridge the sentiment gap. In the semantics decomposition
module, we decompose image and text representations with exclusive projection
and contrastive learning, thereby explicitly capturing the discrepant sentiment
between modalities. Finally, we fuse image and text representations by
cross-attention and combine them with the learned discrepant sentiment for
final classification. Extensive experiments conducted on four multimodal
sentiment datasets demonstrate the superiority of CoDe against SOTA methods.

摘要：隨著近年來社群媒體貼文的激增，偵測多模態（圖像文字）內容的情緒的需求也迅速增長。由於貼文是由使用者產生的，來自同一個貼文的圖像和文字可能表達出不同甚至矛盾的情緒，導致潛在的**情緒差異**。然而，現有的作品主要採用單分支融合結構，主要擷取圖像和文字之間一致的情緒。對矛盾情緒的忽略或隱式建模導致受損的單模態編碼和有限的效能。在本文中，我們提出語義完成和分解 (CoDe) 網路來解決上述問題。在語義完成模組中，我們以嵌入在圖像中的 OCR 文字的語義來補充圖像和文字表示，有助於縮小情緒差距。在語義分解模組中，我們使用獨家投影和對比學習來分解圖像和文字表示，從而明確擷取模態之間的矛盾情緒。最後，我們透過交叉注意力融合圖像和文字表示，並將它們與學習到的矛盾情緒結合起來進行最終分類。在四個多模態情緒資料集上進行的廣泛實驗證明了 CoDe 優於 SOTA 方法。

##### **Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization**
2407.07024v1 by Jeongseok Hyun, Su Ho Han, Hyolim Kang, Joon-Young Lee, Seon Joo Kim

The vocabulary size in temporal action localization (TAL) is constrained by
the scarcity of large-scale annotated datasets. To address this, recent works
incorporate powerful pre-trained vision-language models (VLMs), such as CLIP,
to perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on
extensive image/video-text pairs, existing OV-TAL methods still rely on small,
fully labeled TAL datasets for training an action localizer. In this paper, we
explore the scalability of self-training with unlabeled YouTube videos for
OV-TAL. Our self-training approach consists of two stages. First, a
class-agnostic action localizer is trained on a human-labeled TAL dataset and
used to generate pseudo-labels for unlabeled videos. Second, the large-scale
pseudo-labeled dataset is combined with the human-labeled dataset to train the
localizer. Extensive experiments demonstrate that leveraging web-scale videos
in self-training significantly enhances the generalizability of an action
localizer. Additionally, we highlighted issues with existing OV-TAL evaluation
schemes and proposed a new evaluation protocol. Code is released at
https://github.com/HYUNJS/STOV-TAL

摘要：時序動作定位 (TAL) 中的詞彙量受到大規模標註資料集稀少的限制。為了解決這個問題，最近的研究結合了強大的預訓練視覺語言模型 (VLM)，例如 CLIP，來執行開放詞彙 TAL (OV-TAL)。然而，與在大量的影像/影片-文字配對上訓練的 VLM 不同，現有的 OV-TAL 方法仍然依賴於小型、完全標註的 TAL 資料集來訓練動作定位器。在本文中，我們探討了使用未標註的 YouTube 影片進行自訓練在 OV-TAL 中的可擴充性。我們的自訓練方法包含兩個階段。首先，在人工標註的 TAL 資料集上訓練一個與類別無關的動作定位器，並用於為未標註的影片產生偽標籤。其次，將大規模的偽標籤資料集與人工標註的資料集結合起來訓練定位器。大量的實驗證明，在自訓練中利用網路規模的影片可以顯著增強動作定位器的泛化能力。此外，我們強調了現有 OV-TAL 評估方案的問題，並提出了一個新的評估協定。程式碼已發布於 https://github.com/HYUNJS/STOV-TAL

##### **Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction**
2407.07020v1 by Haicheng Liao, Yongkang Li, Zhenning Li, Chengyue Wang, Chunlin Tian, Yuming Huang, Zilin Bian, Kaiqun Zhu, Guofa Li, Ziyuan Pu, Jia Hu, Zhiyong Cui, Chengzhong Xu

Accurately and safely predicting the trajectories of surrounding vehicles is
essential for fully realizing autonomous driving (AD). This paper presents the
Human-Like Trajectory Prediction model (HLTP++), which emulates human cognitive
processes to improve trajectory prediction in AD. HLTP++ incorporates a novel
teacher-student knowledge distillation framework. The "teacher" model equipped
with an adaptive visual sector, mimics the dynamic allocation of attention
human drivers exhibit based on factors like spatial orientation, proximity, and
driving speed. On the other hand, the "student" model focuses on real-time
interaction and human decision-making, drawing parallels to the human memory
storage mechanism. Furthermore, we improve the model's efficiency by
introducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for
faster and more precise predictions with fewer parameters. Evaluated using the
NGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance
compared to existing models, which reduces the predicted trajectory error with
over 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++
demonstrates strong adaptability in challenging environments with incomplete
input data. This marks a significant stride in the journey towards fully AD
systems.

摘要：準確且安全地預測周圍車輛的軌跡對於完全實現自動駕駛 (AD) 至關重要。本文提出類人軌跡預測模型 (HLTP++)，模擬人類認知過程以改善 AD 中的軌跡預測。HLTP++ 採用新穎的師生知識蒸餾框架。配備自適應視覺扇區的「教師」模型，模擬人類駕駛員根據空間方向、接近度和行駛速度等因素動態分配注意力。另一方面，「學生」模型專注於即時互動和人類決策，與人類記憶儲存機制形成對應。此外，我們通過引入新的傅立葉自適應尖峰神經網路 (FA-SNN) 來提高模型的效率，從而使用更少的參數進行更快速、更準確的預測。使用 NGSIM、HighD 和 MoCAD 基準進行評估，HLTP++ 表現出優於現有模型的卓越性能，在 NGSIM 資料集上將預測軌跡誤差降低了 11% 以上，在 HighD 資料集上降低了 25%。此外，HLTP++ 在輸入資料不完整的情況下表現出強大的適應性。這標誌著朝著完全 AD 系統邁出了重要的一步。

##### **Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies**
2407.07019v1 by Inwon Kang, William Van Woensel, Oshani Seneviratne

We explore using Large Language Models (LLMs) to generate application code
that automates health insurance processes from text-based policies. We target
blockchain-based smart contracts as they offer immutability, verifiability,
scalability, and a trustless setting: any number of parties can use the smart
contracts, and they need not have previously established trust relationships
with each other. Our methodology generates outputs at increasing levels of
technical detail: (1) textual summaries, (2) declarative decision logic, and
(3) smart contract code with unit tests. We ascertain LLMs are good at the task
(1), and the structured output is useful to validate tasks (2) and (3).
Declarative languages (task 2) are often used to formalize healthcare policies,
but their execution on blockchain is non-trivial. Hence, task (3) attempts to
directly automate the process using smart contracts. To assess the LLM output,
we propose completeness, soundness, clarity, syntax, and functioning code as
metrics. Our evaluation employs three health insurance policies (scenarios)
with increasing difficulty from Medicare's official booklet. Our evaluation
uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our
findings confirm that LLMs perform quite well in generating textual summaries.
Although outputs from tasks (2)-(3) are useful starting points, they require
human oversight: in multiple cases, even "runnable" code will not yield sound
results; the popularity of the target language affects the output quality; and
more complex scenarios still seem a bridge too far. Nevertheless, our
experiments demonstrate the promise of LLMs for translating textual process
descriptions into smart contracts.

摘要：<paragraph>我們探討使用大型語言模型 (LLM) 來產生應用程式程式碼，以自動化基於文字政策的健康保險流程。我們以區塊鏈智慧合約為目標，因為它們提供不可變性、可驗證性、可擴充性，以及無需信任的設定：任何數量的參與方都可以使用智慧合約，而且他們不必事先建立彼此的信任關係。我們的做法會產生技術細節程度越來越高的輸出：(1) 文字摘要，(2) 宣告式決策邏輯，以及 (3) 具備單元測試的智慧合約程式碼。我們確定 LLM 擅長任務 (1)，而結構化輸出有助於驗證任務 (2) 和 (3)。宣告式語言 (任務 2) 通常用於將醫療保健政策形式化，但它們在區塊鏈上的執行並非易事。因此，任務 (3) 嘗試直接使用智慧合約自動化流程。為了評估 LLM 輸出，我們提出完整性、健全性、清晰性、語法和運作程式碼作為指標。我們的評估採用了三項醫療保險政策（場景），其難度從 Medicare 的官方手冊中逐漸增加。我們的評估使用 GPT-3.5 Turbo、GPT-3.5 Turbo 16K、GPT-4、GPT-4 Turbo 和 CodeLLaMA。我們的發現證實，LLM 在產生文字摘要方面表現得非常好。儘管任務 (2)-(3) 的輸出是有用的起點，但它們需要人工監督：在多種情況下，即使是「可執行」的程式碼也不會產生健全的結果；目標語言的普及程度會影響輸出品質；而且更複雜的場景似乎仍遙不可及。儘管如此，我們的實驗證明了 LLM 在將文字流程描述轉換為智慧合約方面的潛力。</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-10**|**The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**|Alice Qian Zhang et.al.|[2407.07786v1](http://arxiv.org/abs/2407.07786v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**|Chuanpu Li et.al.|[2407.07660v1](http://arxiv.org/abs/2407.07660v1)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|null|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-09**|**Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**|Krzysztof Kutt et.al.|[2407.06972v1](http://arxiv.org/abs/2407.06972v1)|null|
|**2024-07-09**|**TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**|Jacob Thrasher et.al.|[2407.06852v1](http://arxiv.org/abs/2407.06852v1)|[link](https://github.com/jacob-thrasher/te-ssl)|
|**2024-07-09**|**VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**|Thanh-Dat Nguyen et.al.|[2407.06826v1](http://arxiv.org/abs/2407.06826v1)|null|
|**2024-07-09**|**iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**|Anastasia Krithara et.al.|[2407.06748v1](http://arxiv.org/abs/2407.06748v1)|null|
|**2024-07-09**|**TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**|Fanglin Dong et.al.|[2407.06560v1](http://arxiv.org/abs/2407.06560v1)|null|
|**2024-07-08**|**AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**|You Wu et.al.|[2407.06405v1](http://arxiv.org/abs/2407.06405v1)|null|
|**2024-07-08**|**Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**|Chuanbo Hu et.al.|[2407.06309v1](http://arxiv.org/abs/2407.06309v1)|null|
|**2024-07-08**|**Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**|Pedro Ruas et.al.|[2407.06292v1](http://arxiv.org/abs/2407.06292v1)|null|
|**2024-07-08**|**Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**|Avinash Anand et.al.|[2407.06125v1](http://arxiv.org/abs/2407.06125v1)|null|
|**2024-07-08**|**Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**|Tommaso Mario Buonocore et.al.|[2407.06011v1](http://arxiv.org/abs/2407.06011v1)|null|
|**2024-07-08**|**Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**|Sanjeet Singh et.al.|[2407.05887v1](http://arxiv.org/abs/2407.05887v1)|null|
|**2024-07-08**|**Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**|Xinrui Song et.al.|[2407.05810v1](http://arxiv.org/abs/2407.05810v1)|null|
|**2024-07-08**|**FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**|Pranab Sahoo et.al.|[2407.05800v1](http://arxiv.org/abs/2407.05800v1)|[link](https://github.com/pranabiitp/fedmrl)|
|**2024-07-08**|**Large Language Models for Judicial Entity Extraction: A Comparative Study**|Atin Sakkeer Hussain et.al.|[2407.05786v1](http://arxiv.org/abs/2407.05786v1)|null|
|**2024-07-08**|**Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**|Yutong Zhang et.al.|[2407.05758v1](http://arxiv.org/abs/2407.05758v1)|null|
|**2024-07-08**|**RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**|Inye Na et.al.|[2407.05683v1](http://arxiv.org/abs/2407.05683v1)|[link](https://github.com/nainye/radiomicsfill)|
|**2024-07-08**|**WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**|Pingyi Chen et.al.|[2407.05603v1](http://arxiv.org/abs/2407.05603v1)|[link](https://github.com/cpystan/wsi-vqa)|
|**2024-07-07**|**Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**|Zehuan Zhang et.al.|[2407.05521v1](http://arxiv.org/abs/2407.05521v1)|null|
|**2024-07-07**|**A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**|Fei Wang et.al.|[2407.05458v1](http://arxiv.org/abs/2407.05458v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-07**|**FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**|Juzheng Miao et.al.|[2407.05412v1](http://arxiv.org/abs/2407.05412v1)|[link](https://github.com/juzhengmiao/fm-osd)|
|**2024-07-06**|**BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**|Weimin Lyu et.al.|[2407.05213v1](http://arxiv.org/abs/2407.05213v1)|null|
|**2024-07-06**|**RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**|Peng Xia et.al.|[2407.05131v1](http://arxiv.org/abs/2407.05131v1)|[link](https://github.com/richard-peng-xia/rule)|
|**2024-07-06**|**Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**|Xiao Siyao et.al.|[2407.05087v1](http://arxiv.org/abs/2407.05087v1)|null|
|**2024-07-05**|**Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**|Iman Kianian et.al.|[2407.04808v1](http://arxiv.org/abs/2407.04808v1)|[link](https://github.com/iman2693/gdsm)|
|**2024-07-05**|**Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**|Reza Averly et.al.|[2407.04629v1](http://arxiv.org/abs/2407.04629v1)|null|
|**2024-07-05**|**Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**|Tianshu Feng et.al.|[2407.04486v1](http://arxiv.org/abs/2407.04486v1)|null|
|**2024-07-05**|**Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**|Saeed Shurrab et.al.|[2407.04449v1](http://arxiv.org/abs/2407.04449v1)|[link](https://github.com/nyuad-cai/cxr-ehr-msn)|
|**2024-07-04**|**Query-Guided Self-Supervised Summarization of Nursing Notes**|Ya Gao et.al.|[2407.04125v1](http://arxiv.org/abs/2407.04125v1)|null|
|**2024-07-04**|**MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**|Asma Alkhaldi et.al.|[2407.04106v1](http://arxiv.org/abs/2407.04106v1)|[link](https://github.com/vision-cair/minigpt-med)|
|**2024-07-04**|**Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**|Mehmet Yigit Avci et.al.|[2407.03863v1](http://arxiv.org/abs/2407.03863v1)|[link](https://github.com/ci-ber/morphade)|
|**2024-07-04**|**Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**|Andrew Bouras et.al.|[2407.03582v1](http://arxiv.org/abs/2407.03582v1)|[link](https://github.com/andrewbouras/randomnesspaper)|
|**2024-07-03**|**Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**|Sijie Xu et.al.|[2407.03308v1](http://arxiv.org/abs/2407.03308v1)|[link](https://github.com/minipuding/fastmrt)|
|**2024-07-03**|**MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**|Yanjie Cui et.al.|[2407.03131v2](http://arxiv.org/abs/2407.03131v2)|null|
|**2024-07-03**|**Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**|Yujin Shin et.al.|[2407.03086v1](http://arxiv.org/abs/2407.03086v1)|null|
|**2024-07-03**|**Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**|Siying Xu et.al.|[2407.03034v1](http://arxiv.org/abs/2407.03034v1)|[link](https://github.com/midas-tum/a-liknet)|
|**2024-07-03**|**SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**|Meghal Dani et.al.|[2407.03004v1](http://arxiv.org/abs/2407.03004v1)|null|
|**2024-07-03**|**MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**|Irene Siragusa et.al.|[2407.02994v1](http://arxiv.org/abs/2407.02994v1)|[link](https://github.com/chilab1/medpix-2.0)|
|**2024-07-03**|**Membership Inference Attacks Against Time-Series Models**|Noam Koren et.al.|[2407.02870v1](http://arxiv.org/abs/2407.02870v1)|null|
|**2024-07-03**|**Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**|Negin Ashrafi et.al.|[2407.02821v1](http://arxiv.org/abs/2407.02821v1)|null|
|**2024-07-03**|**MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**|Zishan Gu et.al.|[2407.02730v1](http://arxiv.org/abs/2407.02730v1)|[link](https://github.com/dongzizhu/medvh)|
|**2024-07-02**|**D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**|Hareem Nisar et.al.|[2407.02604v1](http://arxiv.org/abs/2407.02604v1)|null|
|**2024-07-02**|**MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**|Binxu Li et.al.|[2407.02483v1](http://arxiv.org/abs/2407.02483v1)|null|
|**2024-07-02**|**CALICO: Confident Active Learning with Integrated Calibration**|Lorenzo S. Querol et.al.|[2407.02335v1](http://arxiv.org/abs/2407.02335v1)|null|
|**2024-07-02**|**A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**|Minghao Zhou et.al.|[2407.02283v1](http://arxiv.org/abs/2407.02283v1)|[link](https://github.com/zmhhmz/resfu)|
|**2024-07-02**|**FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**|Yangyang Xiang et.al.|[2407.02280v2](http://arxiv.org/abs/2407.02280v2)|[link](https://github.com/hustxyy/fedia)|
|**2024-07-02**|**Generative Monoculture in Large Language Models**|Fan Wu et.al.|[2407.02209v1](http://arxiv.org/abs/2407.02209v1)|[link](https://github.com/GeMoLLM/GeMO)|
|**2024-07-02**|**Abstract Dialectical Frameworks are Boolean Networks (full version)**|Jesse Heyninck et.al.|[2407.02055v1](http://arxiv.org/abs/2407.02055v1)|null|
|**2024-07-02**|**A Method to Facilitate Membership Inference Attacks in Deep Learning Models**|Zitao Chen et.al.|[2407.01919v1](http://arxiv.org/abs/2407.01919v1)|[link](https://github.com/DependableSystemsLab/code_poison_MIA)|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-07-01**|**Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**|Sebastian A. Cruz Romero et.al.|[2407.01705v1](http://arxiv.org/abs/2407.01705v1)|null|
|**2024-07-01**|**Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**|Ana Carolina Alves et.al.|[2407.01318v1](http://arxiv.org/abs/2407.01318v1)|null|
|**2024-07-01**|**MIRAI: Evaluating LLM Agents for Event Forecasting**|Chenchen Ye et.al.|[2407.01231v1](http://arxiv.org/abs/2407.01231v1)|null|
|**2024-07-01**|**Integrated feature analysis for deep learning interpretation and class activation maps**|Yanli Li et.al.|[2407.01142v1](http://arxiv.org/abs/2407.01142v1)|[link](https://github.com/yanlili27/ifa)|
|**2024-07-01**|**An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**|Laifa Tao et.al.|[2407.03374v1](http://arxiv.org/abs/2407.03374v1)|null|
|**2024-07-01**|**Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**|Wenqiang Zu et.al.|[2407.01003v2](http://arxiv.org/abs/2407.01003v2)|[link](https://github.com/zuwenqiang/ept)|
|**2024-07-01**|**Individual brain parcellation: Review of methods, validations and applications**|Chengyi Li et.al.|[2407.00984v1](http://arxiv.org/abs/2407.00984v1)|null|
|**2024-07-01**|**Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**|Cheng Su et.al.|[2407.00978v1](http://arxiv.org/abs/2407.00978v1)|null|
|**2024-07-01**|**Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**|Parviz Ghafariasl et.al.|[2407.01647v1](http://arxiv.org/abs/2407.01647v1)|null|
|**2024-07-01**|**Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**|Sepehr Salem Ghahfarokhi et.al.|[2407.00967v1](http://arxiv.org/abs/2407.00967v1)|null|
|**2024-06-30**|**Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**|Stefan Arnold et.al.|[2407.00764v1](http://arxiv.org/abs/2407.00764v1)|null|
|**2024-06-30**|**Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**|Peng Huang et.al.|[2407.00752v1](http://arxiv.org/abs/2407.00752v1)|null|
|**2024-06-30**|**Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**|Qiuhao Lu et.al.|[2407.00731v1](http://arxiv.org/abs/2407.00731v1)|null|
|**2024-06-30**|**SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**|Zekang Yang et.al.|[2407.00664v1](http://arxiv.org/abs/2407.00664v1)|[link](https://github.com/yang-ze-kang/scmil)|
|**2024-06-30**|**TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**|Jintai Chen et.al.|[2407.00631v1](http://arxiv.org/abs/2407.00631v1)|[link](https://github.com/ml2health/ml2clinicaltrials)|
|**2024-06-29**|**Answering real-world clinical questions using large language model based systems**|Yen Sia Low et.al.|[2407.00541v1](http://arxiv.org/abs/2407.00541v1)|null|
|**2024-06-29**|**Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**|Kiarash Sedghighadikolaei et.al.|[2407.00538v1](http://arxiv.org/abs/2407.00538v1)|null|
|**2024-06-29**|**Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**|Hok-Shing Lau et.al.|[2407.00531v1](http://arxiv.org/abs/2407.00531v1)|null|
|**2024-06-29**|**ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**|Zhiyuan Wang et.al.|[2407.00499v1](http://arxiv.org/abs/2407.00499v1)|null|
|**2024-06-29**|**MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**|Luyuan Xie et.al.|[2407.00474v1](http://arxiv.org/abs/2407.00474v1)|null|
|**2024-06-29**|**pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**|Luyuan Xie et.al.|[2407.00462v1](http://arxiv.org/abs/2407.00462v1)|null|
|**2024-06-29**|**Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**|Omer Goldman et.al.|[2407.00402v2](http://arxiv.org/abs/2407.00402v2)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-28**|**Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**|Dat Hong et.al.|[2407.00147v1](http://arxiv.org/abs/2407.00147v1)|null|
|**2024-06-28**|**BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**|Noel Crawford et.al.|[2406.20041v3](http://arxiv.org/abs/2406.20041v3)|null|
|**2024-06-28**|**Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**|Christopher Irwin et.al.|[2407.00142v1](http://arxiv.org/abs/2407.00142v1)|null|
|**2024-06-28**|**Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**|Haojun Jiang et.al.|[2406.19756v1](http://arxiv.org/abs/2406.19756v1)|null|
|**2024-06-28**|**Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**|Akash Awasthi et.al.|[2407.00129v1](http://arxiv.org/abs/2407.00129v1)|null|
|**2024-06-28**|**ACES: Automatic Cohort Extraction System for Event-Stream Datasets**|Justin Xu et.al.|[2406.19653v1](http://arxiv.org/abs/2406.19653v1)|[link](https://github.com/justin13601/aces)|
|**2024-06-28**|**Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**|Huajun Zhou et.al.|[2406.19611v1](http://arxiv.org/abs/2406.19611v1)|null|
|**2024-06-27**|**PathAlign: A vision-language model for whole slide images in histopathology**|Faruk Ahmed et.al.|[2406.19578v1](http://arxiv.org/abs/2406.19578v1)|null|
|**2024-06-27**|**Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**|Abraham G Taye et.al.|[2407.00120v1](http://arxiv.org/abs/2407.00120v1)|[link](https://github.com/abrahamgenetu/Automated_Malaria_Detection_System)|
|**2024-06-27**|**HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**|Junying Chen et.al.|[2406.19280v1](http://arxiv.org/abs/2406.19280v1)|[link](https://github.com/freedomintelligence/huatuogpt-vision)|
|**2024-06-27**|**Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**|Mahmoud Ibrahim et.al.|[2407.00116v2](http://arxiv.org/abs/2407.00116v2)|null|
|**2024-06-27**|**Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**|Fuseini Mumuni et.al.|[2406.19057v2](http://arxiv.org/abs/2406.19057v2)|null|
|**2024-06-27**|**FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**|Alexander Herzog et.al.|[2406.19050v1](http://arxiv.org/abs/2406.19050v1)|null|

#### Abstracts
##### **The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**
2407.07786v1 by Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray

Rapid progress in general-purpose AI has sparked significant interest in "red
teaming," a practice of adversarial testing originating in military and
cybersecurity applications. AI red teaming raises many questions about the
human factor, such as how red teamers are selected, biases and blindspots in
how tests are conducted, and harmful content's psychological effects on red
teamers. A growing body of HCI and CSCW literature examines related
practices-including data labeling, content moderation, and algorithmic
auditing. However, few, if any, have investigated red teaming itself. This
workshop seeks to consider the conceptual and empirical challenges associated
with this practice, often rendered opaque by non-disclosure agreements. Future
studies may explore topics ranging from fairness to mental health and other
areas of potential harm. We aim to facilitate a community of researchers and
practitioners who can begin to meet these challenges with creativity,
innovation, and thoughtful reflection.

摘要：一般用途 AI 的快速進展引發了對「紅隊」的濃厚興趣，紅隊是一種源自軍事和網路安全應用中的對抗性測試實務。AI 紅隊對人類因素提出了許多問題，例如紅隊成員如何選拔、測試執行方式中的偏見和盲點，以及有害內容對紅隊成員的心理影響。越來越多的人機互動和 CSCW 文獻探討了相關實務，包括資料標記、內容審核和演算法稽核。然而，鮮少有人探討紅隊本身。本工作坊旨在探討與此實務相關的概念和經驗挑戰，這些挑戰通常因保密協議而變得模糊不清。未來的研究可能會探討從公平性到心理健康和其他潛在危害領域的主題。我們的目標是促進研究人員和實務工作者的社群，他們可以開始運用創意、創新和深思熟慮的反思來應對這些挑戰。

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

摘要：一個全面的定性評估架構，適用於醫療保健領域的大型語言模型 (LLM)，其範圍超越傳統的準確度和定量指標。我們提出用於評估 LLM 的 5 個關鍵面向：安全性、共識、客觀性、可複製性和可解釋性 (S.C.O.R.E.)。我們建議 S.C.O.R.E. 可以作為評估架構的基礎，適用於未來的基於 LLM 的模型，這些模型對於醫療保健和臨床應用來說是安全、可靠、值得信賴且合乎道德的。

##### **Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**
2407.07660v1 by Chuanpu Li, Zeli Chen, Yiwen Zhang, Liming Zhong, Wei Yang

Medical image synthesis remains challenging due to misalignment noise during
training. Existing methods have attempted to address this challenge by
incorporating a registration-guided module. However, these methods tend to
overlook the task-specific constraints on the synthetic and registration
modules, which may cause the synthetic module to still generate spatially
aligned images with misaligned target images during training, regardless of the
registration module's function. Therefore, this paper proposes
registration-guided consistency and incorporates disentanglement learning for
medical image synthesis. The proposed registration-guided consistency
architecture fosters task-specificity within the synthetic and registration
modules by applying identical deformation fields before and after synthesis,
while enforcing output consistency through an alignment loss. Moreover, the
synthetic module is designed to possess the capability of disentangling
anatomical structures and specific styles across various modalities. An anatomy
consistency loss is introduced to further compel the synthetic module to
preserve geometrical integrity within latent spaces. Experiments conducted on
both an in-house abdominal CECT-CT dataset and a publicly available pelvic
MR-CT dataset have demonstrated the superiority of the proposed method.

摘要：由於訓練期間的錯位雜訊，醫學影像合成仍然具有挑戰性。現有方法已嘗試透過納入註冊導引模組來解決此挑戰。然而，這些方法往往忽略合成與註冊模組的特定任務約束，這可能會導致合成模組在訓練期間仍產生與錯位目標影像空間對齊的影像，而與註冊模組的功能無關。因此，本文提出註冊導引一致性，並結合解糾纏學習用於醫學影像合成。所提出的註冊導引一致性架構透過在合成前後應用相同的變形場，並透過對齊損失來強制執行輸出一致性，來促進合成與註冊模組中的任務特異性。此外，合成模組被設計為具備在各種模態中解開解剖結構和特定樣式的能力。引入了解剖一致性損失，以進一步強制合成模組在潛在空間中保留幾何完整性。在內部腹部 CECT-CT 資料集和公開可用的骨盆 MR-CT 資料集上進行的實驗已證明了所提出方法的優越性。

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

摘要：咬合接觸是上顎和下顎後牙咬合面相遇的位置。咬合接觸偵測是恢復咀嚼功能喪失的必要工具，也是牙科領域中的一項強制性評估，特別是在贋復牙科和修復牙科中具有重要意義。最常見的咬合接觸偵測方法是使用咬合紙。然而，此方法可能會顯示出顯著的醫學假陽性和醫學假陰性接觸區域，讓臨床醫師難以找出真正的咬合跡象。為了解決這個問題，我們提出一個多類別的 Vision Transformer 和全卷積網路集合語意分割模型，並結合分層損失函數，我們將其命名為分層全卷積分支轉換器 (H-FCBFormer)。我們還提出了一種生成醫學真陽性語意分割遮罩的方法，該方法源自專家註解的咬合紙遮罩和金標準遮罩。所提出的模型在偵測醫學真陽性接觸方面優於其他機器學習方法，並且在準確識別物件式咬合接觸區域方面優於牙醫師，同時識別所需時間卻顯著減少。程式碼可在 https://github.com/Banksylel/H-FCBFormer 取得。

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

摘要：機器人輔助進食有潛力改善行動不便、無法自行進食的個人生活品質。然而，現有的進食系統所能處理的均質、精選餐盤與實際的餐點之間存在著很大的差距。進食實際的餐點極具挑戰性，因為機器人可能遇到的食物種類繁多，每種食物都需要特定的操作策略，而這些策略必須在一個長期的範圍內進行排序，才能進食一整餐。一個輔助進食系統不僅應該能夠有效地對不同的策略進行排序，以便進食一整餐，還應該在任務的個性化性質下，考量使用者的偏好。我們透過 FLAIR 來解決這個問題，FLAIR 是針對長時程進食的系統，它利用基礎模型的常識和少量推理能力，以及一個參數化技能庫，來規劃和執行使用者偏好且有效的進食順序。在 6 個實際餐盤的真實世界評估中，我們發現 FLAIR 可以有效地利用各種技能庫進行有效的食物取用，同時遵守 42 位行動不便參與者的不同偏好，這是在使用者研究中評估的。我們展示了 FLAIR 與現有進食轉移方法 [19, 28] 的無縫整合，並在 2 個機構和 3 個機器人中部署它，說明了它的適應性。最後，我們透過成功餵食一位行動不便的受照護者來說明我們系統在真實世界中的功效。補充材料和影片可以在這裡找到：https://emprise.cs.cornell.edu/flair。

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

摘要：大型語言模型（LLM）最近已成為各種語言生成任務的強大工具。儘管如此，這項進展在阿拉伯語中較為緩慢。在這項工作中，我們專注於從 LLM 生成故事的任務。對於我們的訓練，我們使用通過機器翻譯（MT）以及 GPT-4 獲得的故事。對於 MT 資料，我們開發了一個仔細的管道，以確保我們獲得高品質的故事。對於我們的 GPT-41 資料，我們引入了精心製作的提示，使我們能夠生成非常適合阿拉伯語環境的資料，包括現代標準阿拉伯語（MSA）和兩種阿拉伯語方言（埃及語和摩洛哥語）。例如，我們生成針對各種阿拉伯國家的故事，主題廣泛。我們的評估顯示，我們針對這些訓練資料集進行微調的模型可以生成符合我們指示的連貫故事。我們還進行了廣泛的自動和人工評估，將我們的模型與最先進的專有和開放原始碼模型進行比較。我們的資料集和模型將在 https: //github.com/UBC-NLP/arastories 公開。

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

摘要：人类观察模式的眼球注视已越来越多地融入视觉任务的解决方案中。尽管最近探索了利用注视来辅助深度网络，但很少有研究利用注视作为医学图像分割的有效注释方法，这通常需要大量的注释成本。在本文中，我们提出收集密集的弱监督，用于具有凝视注释方案的医学图像分割。为了用注视进行训练，我们提出了一个多级框架，该框架从区分性人类注意力训练多个网络，并通过在凝视热图上应用分层阈值来模拟一组伪掩码。此外，为了减轻注视噪声，利用跨级一致性来正则化过度拟合的噪声标签，将模型引导至由对等网络学习的干净模式。所提出的方法已在两个公共医学数据集的多息肉和前列腺分割任务上得到验证。我们贡献了一个名为 GazeMedSeg 的高质量凝视数据集，作为流行医学分割数据集的扩展。据我们所知，这是医学图像分割的第一个凝视数据集。我们的实验表明，在性能和注释时间方面，凝视注释优于以前的标签高效注释方案。我们收集的凝视数据和代码可在以下位置获得：https://github.com/med-air/GazeMedSeg。

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

摘要：方法學的進展自動化生成差異診斷 (DDx)，以預測給定患者症狀描述的潛在疾病清單，對於臨床推理和決策支援等應用至關重要。然而，提供這些差異診斷的推理或解釋更有意義。幸運的是，大型語言模型 (LLM) 擁有強大的語言處理能力，並已被證明在各種相關任務中有效。受此潛力的激勵，我們研究了 LLM 在可解釋的 DDx 中的應用。首先，我們開發了一個新的 DDx 數據集，其中包含專家對 570 個公共臨床筆記的解釋。其次，我們提出了一個名為 Dual-Inf 的新框架，它使 LLM 能夠進行雙向推理以進行解釋。人類和自動化評估都證明了 Dual-Inf 在預測差異和診斷解釋方面的有效性。具體來說，Dual-Inf 在 DDx 解釋中超過基線方法的性能改進超過 32% w.r.t. BERTScore。此外，實驗驗證了 Dual-Inf (1) 在解釋中產生較少的錯誤，(2) 具有很好的概括性，(3) 對罕見疾病的診斷和解釋很有前景。

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

摘要：放射治療 (RT) 是最有效的癌症治療方法之一，其成功有賴於目標的準確描繪。然而，目標描繪是一項全面的醫療決策，目前完全依賴人類專家的手動程序。手動描繪耗時、費力，且受觀察者間差異影響。儘管人工智慧 (AI) 技術的進步已顯著增強正常組織的自動輪廓描繪，但 RT 目標體積的準確描繪仍是一項挑戰。在本研究中，我們提出一個基於視覺語言模型的 RT 目標體積自動描繪網路，稱為 Radformer。Radformer 利用階層式視覺Transformer作為主幹，並整合大型語言模型從臨床資料中提取豐富文字特徵。我們引入一個視覺語言注意力模組 (VLAM)，用於整合視覺和語言特徵，以進行語言感知視覺編碼 (LAVE)。Radformer 已在一個包含 2985 名接受 RT 治療的頭頸癌患者的資料集上進行評估。指標，包括 Dice 相似係數 (DSC)、聯集比 (IOU) 和第 95 個百分位數 Hausdorff 距離 (HD95)，用於定量評估模型的效能。我們的結果表明，與其他最先進的模型相比，Radformer 具有優異的分割效能，驗證了其在 RT 實務中應用的潛力。

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

摘要：在不作平穩假設的情況下從觀測時間序列中發現因果關係是一項重大挑戰。在實務中，這個挑戰在許多領域中很常見，例如零售銷售、運輸系統和醫學科學。在此，我們考慮非平穩時間序列類別的這個問題。這種類型的時間序列的結構因果模型 (SCM)，稱為半平穩時間序列，展示了有限數量的不同因果機制會隨著時間順序且週期性地發生。這個模型具有相當大的實用性，因為它可以表示週期性，包括季節性和晝夜變化等常見現象。我們提出了一個基於約束的非參數演算法，用於發現這個設定中的因果關係。產生的演算法 PCMCI$_{\Omega}$ 可以捕捉因果機制中的交替和重複變化，然後藉由條件獨立 (CI) 檢定來識別基礎因果圖。我們證明這個演算法在識別離散時間序列上的因果關係時是合理的。我們使用連續和離散模擬資料進行廣泛的實驗，以驗證演算法。我們也將我們的演算法應用於真實世界的氣候資料集。

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

摘要：時間序列的變異點偵測旨在找出時間序列的機率分佈改變的時間。它廣泛應用於許多領域，例如人類活動感測與醫學科學。在多變量時間序列的背景中，這通常涉及檢視高維度資料的聯合分佈：如果任何一個變數改變，則假設整個時間序列已經改變。然而，在實際應用中，我們可能只對時間序列的特定組成部分感興趣，探索它們的分佈在其他時間序列存在的情況下突然改變。在這裡，假設一個基礎的結構因果模型支配著時間序列資料的生成，我們透過提出一個兩階段非參數演算法來解決這個問題，該演算法首先透過基於約束的發現方法來學習因果結構的部分。然後，該演算法使用條件相對 Pearson 差異估計來找出變異點。條件相對 Pearson 差異量化時間序列中連續區段之間的分佈差異，而因果發現方法可以專注於因果機制，促進取得獨立且同分布 (IID) 的樣本。理論上，樣本為 IID 的典型假設在傳統變異點偵測方法中可以根據因果馬可夫條件放寬。透過在合成和真實世界資料集上進行實驗，我們驗證了我們方法的正確性和實用性。

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

摘要：血液生物標記是醫療保健提供者用於診斷、監測和治療各種疾病的重要工具。目前的參考值和建議範圍通常依賴於人群統計數據，而這些數據可能無法充分說明由生活方式和基因等因素驅動的個體間變異的影響。在這項工作中，我們引入了一個新的框架來預測未來的血液生物標記值，並通過從生活方式數據（身體活動和睡眠）和血液生物標記中學習到的表徵來定義個性化參考。我們提出的方法學習了一個基於相似性的嵌入空間，該空間捕捉了生物標記和生活方式因素之間的複雜關係。使用英國生物銀行（257K 參與者），我們的結果表明，我們深度學習的嵌入優於傳統和當前最先進的表徵學習技術，可以預測臨床診斷。使用擁有後續訪視的 6440 名參與者的英國生物銀行子集，我們驗證了在血液生物標記模型中直接包含這些嵌入和生活方式因素可以改善從單次實驗室訪問中預測未來實驗室值。這種個性化建模方法為開發更準確的風險分層工具和定制預防保健策略提供了基礎。在臨床環境中，這轉化為早期疾病檢測、更及時的干預，最終轉向個性化醫療保健的潛力。

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**
2407.06972v1 by Krzysztof Kutt, Jakub Gomułka, Luiz do Valle Miranda, Grzegorz J. Nalepa

In response to several cultural heritage initiatives at the Jagiellonian
University, we have developed a new digitization workflow in collaboration with
the Jagiellonian Library (JL). The solution is based on easy-to-access
technological solutions -- Microsoft 365 cloud with MS Excel files as metadata
acquisition interfaces, Office Script for validation, and MS Sharepoint for
storage -- that allows metadata acquisition by domain experts (philologists,
historians, philosophers, librarians, archivists, curators, etc.) regardless of
their experience with information systems. The ultimate goal is to create a
knowledge graph that describes the analyzed holdings, linked to general
knowledge bases, as well as to other cultural heritage collections, so careful
attention is paid to the high accuracy of metadata and proper links to external
sources. The workflow has already been evaluated in two pilots in the DiHeLib
project focused on digitizing the so-called "Berlin Collection" and in two
workshops with international guests, which allowed for its refinement and
confirmation of its correctness and usability for JL. As the proposed workflow
does not interfere with existing systems or domain guidelines regarding
digitization and basic metadata collection in a given institution (e.g., file
type, image quality, use of Dublin Core/MARC-21), but extends them in order to
enable rich metadata collection, not previously possible, we believe that it
could be of interest to all GLAMs (galleries, libraries, archives, and
museums).

摘要：<paragraph>為回應 Jagiello 大學的數個文化遺產倡議，我們與 Jagiello 圖書館 (JL) 合作開發一個新的數位化工作流程。此解決方案基於易於存取的技術解決方案，包括：作為元資料擷取介面的 Microsoft 365 雲端與 MS Excel 檔案、用於驗證的 Office Script，以及用於儲存的 MS Sharepoint，它允許領域專家（語言學家、歷史學家、哲學家、圖書館員、檔案管理員、策展人等）擷取元資料，而無須具備資訊系統方面的經驗。最終目標是建立一個知識圖譜，用以描述所分析的館藏，並連結至一般知識庫，以及其他文化遺產館藏，因此我們非常重視元資料的高準確性，以及與外部來源的適當連結。此工作流程已在 DiHeLib 專案中兩個試點計畫中進行評估，該專案專注於數位化所謂的「柏林館藏」，以及與國際訪客進行的兩個工作坊，這讓我們得以改善工作流程，並確認其正確性，以及對 JL 的可用性。由於所提出的工作流程不會干擾既有系統或關於數位化和基本元資料蒐集的領域指南（例如，檔案類型、影像品質、使用 Dublin Core/MARC-21），而是擴充這些系統，以支援以前無法進行的豐富元資料蒐集，因此我們相信它可能會引起所有 GLAM（畫廊、圖書館、檔案館和博物館）的興趣。</paragraph>

##### **TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**
2407.06852v1 by Jacob Thrasher, Alina Devkota, Ahmed Tafti, Binod Bhattarai, Prashnna Gyawali

Alzheimer's Dementia (AD) represents one of the most pressing challenges in
the field of neurodegenerative disorders, with its progression analysis being
crucial for understanding disease dynamics and developing targeted
interventions. Recent advancements in deep learning and various representation
learning strategies, including self-supervised learning (SSL), have shown
significant promise in enhancing medical image analysis, providing innovative
ways to extract meaningful patterns from complex data. Notably, the computer
vision literature has demonstrated that incorporating supervisory signals into
SSL can further augment model performance by guiding the learning process with
additional relevant information. However, the application of such supervisory
signals in the context of disease progression analysis remains largely
unexplored. This gap is particularly pronounced given the inherent challenges
of incorporating both event and time-to-event information into the learning
paradigm. Addressing this, we propose a novel framework, Time and Even-aware
SSL (TE-SSL), which integrates time-to-event and event data as supervisory
signals to refine the learning process. Our comparative analysis with existing
SSL-based methods in the downstream task of survival analysis shows superior
performance across standard metrics.

摘要：阿茲海默症失智症 (AD) 是神經退化性疾病領域中最迫切的挑戰之一，其進程分析對於了解疾病動態和開發目標性干預措施至關重要。深度學習和各種表示學習策略（包括自監督學習 (SSL)）的最新進展，已在增強醫學影像分析方面展現顯著前景，提供從複雜資料中提取有意義模式的創新方法。值得注意的是，電腦視覺文獻已證明將監督訊號納入 SSL 可以透過提供額外相關資訊來指導學習過程，進一步增強模型效能。然而，此類監督訊號在疾病進程分析中的應用仍未得到充分探討。由於將事件和事件時間資訊納入學習範例的固有挑戰，此差距特別明顯。針對此問題，我們提出一個創新的架構，時間和事件感知 SSL (TE-SSL)，它整合事件時間和事件資料作為監督訊號，以優化學習過程。我們在生存分析的下游任務中，對其與現有基於 SSL 的方法進行比較分析，顯示其在標準指標上的效能優異。

##### **VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**
2407.06826v1 by Thanh-Dat Nguyen, Tung Do-Viet, Hung Nguyen-Duy, Tuan-Hai Luu, Hung Le, Bach Le, Patanamon, Thongtanunam

Businesses need to query visually rich documents (VRDs) like receipts,
medical records, and insurance forms to make decisions. Existing techniques for
extracting entities from VRDs struggle with new layouts or require extensive
pre-training data. We introduce VRDSynth, a program synthesis method to
automatically extract entity relations from multilingual VRDs without
pre-training data. To capture the complexity of VRD domain, we design a
domain-specific language (DSL) to capture spatial and textual relations to
describe the synthesized programs. Along with this, we also derive a new
synthesis algorithm utilizing frequent spatial relations, search space pruning,
and a combination of positive, negative, and exclusive programs to improve
coverage.
  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity
linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms
state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and
XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the
F1 score by 42% over LayoutXLM in English. To test the extensibility of the
model, we further improve VRDSynth with automated table recognition, creating
VRDSynth(Table), and compare it with extended versions of the pre-trained
models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these
baselines in 4 out of 8 languages and in average F1 score. VRDSynth also
significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for
LayoutXLM) while maintaining similar time efficiency.

摘要：<paragraph>企業需要查詢視覺豐富的文件 (VRD)，例如收據、醫療記錄和保險單據，才能做出決策。現有的技術用於從 VRD 中提取實體，會遇到新的版面問題，或者需要大量的預訓練數據。我們介紹 VRDSynth，這是一種程式合成方法，可以在沒有預訓練數據的情況下自動從多語言 VRD 中提取實體關係。為了捕捉 VRD 領域的複雜性，我們設計了一個特定領域語言 (DSL)，用於捕捉空間和文字關係，以描述合成的程式。除此之外，我們還推導出一個新的合成演算法，利用頻繁的空間關係、搜尋空間剪枝，以及正、負和排他程式的組合，以改善涵蓋範圍。
我們在 FUNSD 和 XFUND 基準上評估 VRDSynth，用於語義實體連結，包含 8 種語言的 1,592 個表單。VRDSynth 在 8 種語言中的 5、6 和 7 種語言中優於最先進的預訓練模型 (LayoutXLM、InfoXLMBase 和 XLMRobertaBase)，分別將英文中的 F1 分數提高了 42%，高於 LayoutXLM。為了測試模型的可擴充性，我們進一步改進 VRDSynth，採用自動化表格識別，建立 VRDSynth(Table)，並將其與預訓練模型 InfoXLM(Large) 和 XLMRoberta(Large) 的延伸版本進行比較。VRDSynth(Table) 在 8 種語言中的 4 種語言和平均 F1 分數中優於這些基準。VRDSynth 還顯著減少了記憶體使用量 (1M 和 380MB，而 LayoutXLM 為 1.48GB 和 3GB)，同時維持類似的時間效率。</paragraph>

##### **iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**
2407.06748v1 by Anastasia Krithara, Fotis Aisopos, Vassiliki Rentoumi, Anastasios Nentidis, Konstantinos Bougatiotis, Maria-Esther Vidal, Ernestina Menasalvas, Alejandro Rodriguez-Gonzalez, Eleftherios G. Samaras, Peter Garrard, Maria Torrente, Mariano Provencio Pulla, Nikos Dimakopoulos, Rui Mauricio, Jordi Rambla De Argila, Gian Gaetano Tartaglia, George Paliouras

The vision of IASIS project is to turn the wave of big biomedical data
heading our way into actionable knowledge for decision makers. This is achieved
by integrating data from disparate sources, including genomics, electronic
health records and bibliography, and applying advanced analytics methods to
discover useful patterns. The goal is to turn large amounts of available data
into actionable information to authorities for planning public health
activities and policies. The integration and analysis of these heterogeneous
sources of information will enable the best decisions to be made, allowing for
diagnosis and treatment to be personalised to each individual. The project
offers a common representation schema for the heterogeneous data sources. The
iASiS infrastructure is able to convert clinical notes into usable data,
combine them with genomic data, related bibliography, image data and more, and
create a global knowledge base. This facilitates the use of intelligent methods
in order to discover useful patterns across different resources. Using semantic
integration of data gives the opportunity to generate information that is rich,
auditable and reliable. This information can be used to provide better care,
reduce errors and create more confidence in sharing data, thus providing more
insights and opportunities. Data resources for two different disease categories
are explored within the iASiS use cases, dementia and lung cancer.

摘要：IASIS 項目的願景是將朝我們而來的龐大生物醫學數據浪潮轉變為決策者的可行知識。這是透過整合來自不同來源的數據（包括基因組學、電子健康記錄和書目），並應用先進的分析方法來發現有用的模式來實現的。目標是將大量可用數據轉化為可行的資訊，供當局規劃公共衛生活動和政策。整合和分析這些異質的資訊來源將使最佳決策得以制定，並允許對每個人的診斷和治療進行個人化。該專案為異質數據來源提供了一個共同的表示架構。iASiS 基礎設施能夠將臨床筆記轉換為可用數據，將其與基因組數據、相關書目、影像數據等結合起來，並建立一個全球知識庫。這有助於使用智慧方法來發現不同資源之間的有用模式。使用數據的語義整合提供了產生豐富、可稽核且可靠資訊的機會。這些資訊可用於提供更好的照護、減少錯誤，並對資料共享建立更多信心，從而提供更多見解和機會。在 iASiS 的使用案例中，探討了兩種不同疾病類別的數據資源，即失智症和肺癌。

##### **TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**
2407.06560v1 by Fanglin Dong

Sepsis poses a major global health threat, accounting for millions of deaths
annually and significant economic costs. Accurate predictions of mortality risk
in sepsis patients facilitate the efficient allocation of medical resources,
thereby enhancing patient survival and quality of life. Through precise risk
assessments, healthcare facilities can effectively distribute intensive care
beds, medical equipment, and staff, ensuring high-risk patients receive timely
and appropriate care. Early identification and intervention significantly
decrease mortality rates and improve patient outcomes. Current methods
typically utilize only one type of data--either constant, temporal, or ICD
codes. This study introduces the Time-Constant KAN Integrated Network(TCKIN),
an innovative model that enhances the accuracy of sepsis mortality risk
predictions by integrating both temporal and constant data from electronic
health records and ICD codes. Validated against the MIMIC-III and MIMIC-IV
datasets, TCKIN surpasses existing machine learning and deep learning methods
in accuracy, sensitivity, and specificity. Notably, TCKIN achieved AUCs of
87.76% and 88.07%, demonstrating superior capability in identifying high-risk
patients. Additionally, TCKIN effectively combats the prevalent issue of data
imbalance in clinical settings, improving the detection of patients at elevated
risk of mortality and facilitating timely interventions. These results confirm
the model's effectiveness and its potential to transform patient management and
treatment optimization in clinical practice. With this advanced risk assessment
tool, healthcare providers can devise more tailored treatment plans, optimize
resource utilization, and ultimately enhance survival rates and quality of life
for sepsis patients.

摘要：<paragraph>敗血症構成全球主要的健康威脅，每年造成數百萬人死亡，並帶來龐大的經濟成本。準確預測敗血症患者的死亡風險，有助於有效分配醫療資源，從而提升患者存活率和生活品質。透過精確的風險評估，醫療機構可以有效分配加護病房病床、醫療設備和人員，確保高風險患者能及時獲得適當的照護。早期發現和介入可以顯著降低死亡率，並改善患者預後。目前的方法通常僅使用一種類型的資料，例如常數、時間或 ICD 編碼。本研究引入了時間常數 KAN 整合網路 (TCKIN)，這是一個創新的模型，透過整合電子健康紀錄和 ICD 編碼中的時間和常數資料，來提升敗血症死亡風險預測的準確性。在 MIMIC-III 和 MIMIC-IV 資料集驗證下，TCKIN 在準確性、敏感性和特異性方面都超越了現有的機器學習和深度學習方法。值得注意的是，TCKIN 達到了 87.76% 和 88.07% 的 AUC，顯示出優異的識別高風險患者能力。此外，TCKIN 有效地解決了臨床環境中普遍存在的資料不平衡問題，改善了對死亡風險較高的患者的檢測，並促進及時介入。這些結果證實了該模型的有效性，以及其在臨床實務中轉化患者管理和優化治療的潛力。有了這個進階的風險評估工具，醫療保健提供者可以制定更客製化的治療計畫，最佳化資源利用，並最終提升敗血症患者的存活率和生活品質。</paragraph>

##### **AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**
2407.06405v1 by You Wu, Lei Xie

Despite the wealth of single-cell multi-omics data, it remains challenging to
predict the consequences of novel genetic and chemical perturbations in the
human body. It requires knowledge of molecular interactions at all biological
levels, encompassing disease models and humans. Current machine learning
methods primarily establish statistical correlations between genotypes and
phenotypes but struggle to identify physiologically significant causal factors,
limiting their predictive power. Key challenges in predictive modeling include
scarcity of labeled data, generalization across different domains, and
disentangling causation from correlation. In light of recent advances in
multi-omics data integration, we propose a new artificial intelligence
(AI)-powered biology-inspired multi-scale modeling framework to tackle these
issues. This framework will integrate multi-omics data across biological
levels, organism hierarchies, and species to predict causal
genotype-environment-phenotype relationships under various conditions. AI
models inspired by biology may identify novel molecular targets, biomarkers,
pharmaceutical agents, and personalized medicines for presently unmet medical
needs.

摘要：儘管有豐富的單細胞多組學資料，但預測人體中新的遺傳和化學擾動的後果仍然具有挑戰性。這需要了解所有生物層級的分子交互作用，包括疾病模型和人類。目前的機器學習方法主要建立基因型和表型之間的統計相關性，但難以識別生理上重要的因果因素，從而限制了其預測能力。預測建模中的主要挑戰包括標記資料的稀缺性、跨不同領域的概化，以及將因果關係從相關性中解開。鑑於多組學資料整合的最新進展，我們提出了一個新的由人工智慧 (AI) 驅動的、受生物啟發的多尺度建模框架來解決這些問題。此框架將整合跨生物層級、生物體層級和物種的多組學資料，以預測在各種條件下的因果基因型-環境-表型關係。受生物啟發的 AI 模型可能會識別出新的分子靶標、生物標記、藥物和個性化藥物，以滿足目前尚未滿足的醫療需求。

##### **Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**
2407.06309v1 by Chuanbo Hu, Bin Liu, Minglei Yin, Yilu Zhou, Xin Li

Mobile applications (Apps) could expose children to inappropriate themes such
as sexual content, violence, and drug use. Maturity rating offers a quick and
effective method for potential users, particularly guardians, to assess the
maturity levels of apps. Determining accurate maturity ratings for mobile apps
is essential to protect children's health in today's saturated digital
marketplace. Existing approaches to maturity rating are either inaccurate
(e.g., self-reported rating by developers) or costly (e.g., manual
examination). In the literature, there are few text-mining-based approaches to
maturity rating. However, each app typically involves multiple modalities,
namely app description in the text, and screenshots in the image. In this
paper, we present a framework for determining app maturity levels that utilize
multimodal large language models (MLLMs), specifically ChatGPT-4 Vision.
Powered by Chain-of-Thought (CoT) reasoning, our framework systematically
leverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions
and screenshots) and guide the MLLM model through a step-by-step reasoning
pathway from initial content analysis to final maturity rating determination.
As a result, through explicitly incorporating CoT reasoning, our framework
enables ChatGPT to understand better and apply maturity policies to facilitate
maturity rating. Experimental results indicate that the proposed method
outperforms all baseline models and other fusion strategies.

摘要：行動應用程式 (App) 可能讓兒童接觸到不適當的主題，例如性內容、暴力和藥物使用。成熟度評分提供一種快速且有效的方法，讓潛在使用者，尤其是監護人，評估應用程式的成熟度等級。在當今飽和的數位市場中，為行動應用程式確定準確的成熟度評分對於保護兒童健康至關重要。現有的成熟度評分方法不是不準確（例如，開發人員自行報告的評分），就是成本高昂（例如，人工審查）。在文獻中，很少有基於文字探勘的方法來評估成熟度。然而，每個應用程式通常涉及多種模式，即文字中的應用程式說明和影像中的螢幕截圖。在本文中，我們提出一個框架，用於確定應用程式的成熟度等級，該框架利用多模態大型語言模型 (MLLM)，特別是 ChatGPT-4 Vision。我們的框架採用思維鏈 (CoT) 推理為基礎，系統性地利用 ChatGPT-4 處理多模態應用程式資料（即文字說明和螢幕截圖），並引導 MLLM 模型逐步進行推理路徑，從初始內容分析到最終成熟度評分確定。因此，透過明確納入 CoT 推理，我們的框架使 ChatGPT 能夠更深入地了解並應用成熟度政策來促進成熟度評分。實驗結果表明，所提出的方法優於所有基線模型和其他融合策略。

##### **Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**
2407.06292v1 by Pedro Ruas, Fernando Gallego, Francisco J. Veredas, Francisco M. Couto

State-of-the-art deep learning entity linking methods rely on extensive
human-labelled data, which is costly to acquire. Current datasets are limited
in size, leading to inadequate coverage of biomedical concepts and diminished
performance when applied to new data. In this work, we propose to automatically
generate data to create large-scale training datasets, which allows the
exploration of approaches originally developed for the task of extreme
multi-label ranking in the biomedical entity linking task. We propose the
hybrid X-Linker pipeline that includes different modules to link disease and
chemical entity mentions to concepts in the MEDIC and the CTD-Chemical
vocabularies, respectively. X-Linker was evaluated on several biomedical
datasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical,
BioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969,
0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated
superior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and
BioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining
three datasets. Both models rely only on the mention string for their
operations. The source code of X-Linker and its associated data are publicly
available for performing biomedical entity linking without requiring
pre-labelled entities with identifiers from specific knowledge organization
systems.

摘要：最先進的深度學習實體連結方法依賴於大量的
人工標籤資料，而這類資料的取得成本很高。目前的資料集
大小有限，導致生物醫學概念涵蓋不足，在應用於新資料時效能降低。在這項工作中，我們提議自動
產生資料，以建立大規模的訓練資料集，這允許探索原本是為生物醫學實體連結任務中極端多標籤排名任務而開發的方法。我們提議混合 X-Linker 管線，其中包含不同的模組，分別將疾病和化學實體提及連結到 MEDIC 和 CTD-Chemical 字彙中的概念。X-Linker 已在多個生物醫學資料集上進行評估：BC5CDR-Disease、BioRED-Disease、NCBI-Disease、BC5CDR-Chemical、BioRED-Chemical 和 NLM-Chem，分別達到 0.8307、0.7969、0.8271、0.9511、0.9248 和 0.7895 的 top-1 準確度。X-Linker 在三個資料集：BC5CDR-Disease、NCBI-Disease 和 BioRED-Chemical 中表現出優異的效能。相反地，SapBERT 在其餘三個資料集中優於 X-Linker。兩個模型僅依賴於它們操作的提及字串。X-Linker 和其相關資料的原始程式碼公開提供，可執行生物醫學實體連結，而無需特定知識組織系統中識別符號的預先標籤實體。

##### **Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**
2407.06125v1 by Avinash Anand, Chayan Tank, Sarthak Pol, Vinayak Katoch, Shaina Mehta, Rajiv Ratn Shah

Depression has proven to be a significant public health issue, profoundly
affecting the psychological well-being of individuals. If it remains
undiagnosed, depression can lead to severe health issues, which can manifest
physically and even lead to suicide. Generally, Diagnosing depression or any
other mental disorder involves conducting semi-structured interviews alongside
supplementary questionnaires, including variants of the Patient Health
Questionnaire (PHQ) by Clinicians and mental health professionals. This
approach places significant reliance on the experience and judgment of trained
physicians, making the diagnosis susceptible to personal biases. Given that the
underlying mechanisms causing depression are still being actively researched,
physicians often face challenges in diagnosing and treating the condition,
particularly in its early stages of clinical presentation. Recently,
significant strides have been made in Artificial neural computing to solve
problems involving text, image, and speech in various domains. Our analysis has
aimed to leverage these state-of-the-art (SOTA) models in our experiments to
achieve optimal outcomes leveraging multiple modalities. The experiments were
performed on the Extended Distress Analysis Interview Corpus Wizard of Oz
dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC)
2019 Challenge. The proposed solutions demonstrate better results achieved by
Proprietary and Open-source Large Language Models (LLMs), which achieved a Root
Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC
2019 challenge baseline results and current SOTA regression analysis
architectures. Additionally, the proposed solution achieved an accuracy of
71.43% in the classification task. The paper also includes a novel audio-visual
multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.

摘要：憂鬱症已被證實是一個重大的公共衛生議題，深刻影響個人心理健康。如果憂鬱症未經診斷，可能會導致嚴重的健康問題，這些問題可能在生理上顯現，甚至導致自殺。通常，診斷憂鬱症或任何其他精神疾病都涉及進行半結構化訪談，以及補充問卷，包括臨床醫生和心理健康專業人員所使用的患者健康問卷 (PHQ) 變體。這種方法非常依賴受過訓練的醫師的經驗和判斷，使診斷容易受到個人偏見的影響。由於導致憂鬱症的潛在機制仍在積極研究中，因此醫師在診斷和治療這種疾病時經常面臨挑戰，尤其是在臨床表現的早期階段。最近，人工神經運算在解決涉及文本、影像和語言的各種領域問題方面取得了重大進展。我們的分析旨在利用這些最先進 (SOTA) 模型在我們的實驗中，透過利用多種模式來達成最佳結果。這些實驗是在 Audio/Visual Emotion Challenge (AVEC) 2019 Challenge 中提出的 Extended Distress Analysis Interview Corpus Wizard of Oz 資料集 (E-DAIC) 語料庫上進行的。所提出的解決方案證明了專有和開放原始碼大型語言模型 (LLM) 所取得的較佳結果，這些模型在文本模式上達到了 3.98 的均方根誤差 (RMSE) 分數，優於 AVEC 2019 挑戰基準結果和目前的 SOTA 回歸分析架構。此外，所提出的解決方案在分類任務中達到了 71.43% 的準確率。本文還包括一個新穎的音訊視覺多模式網路，其使用 6.51 的 RMSE 預測 PHQ-8 分數。

##### **Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**
2407.06011v1 by Tommaso Mario Buonocore, Simone Rancati, Enea Parimbelli

The development of domain-specific language models has significantly advanced
natural language processing applications in various specialized fields,
particularly in biomedicine. However, the focus has largely been on
English-language models, leaving a gap for less-resourced languages such as
Italian. This paper introduces Igea, the first decoder-only language model
designed explicitly for biomedical text generation in Italian. Built on the
Minerva model and continually pretrained on a diverse corpus of Italian medical
texts, Igea is available in three model sizes: 350 million, 1 billion, and 3
billion parameters. The models aim to balance computational efficiency and
performance, addressing the challenges of managing the peculiarities of medical
terminology in Italian. We evaluate Igea using a mix of in-domain biomedical
corpora and general-purpose benchmarks, highlighting its efficacy and retention
of general knowledge even after the domain-specific training. This paper
discusses the model's development and evaluation, providing a foundation for
future advancements in Italian biomedical NLP.

摘要：特定領域語言模型的發展已大幅提升了各種專業領域的自然語言處理應用，特別是在生物醫學領域。然而，目前的研究重點主要放在英語語言模型上，這對義大利語等資源較少的語言來說是一大缺憾。本文介紹了 Igea，這是第一個專門設計用於義大利語生物醫學文本生成的僅解碼器語言模型。Igea 建構在 Minerva 模型上，並持續在大量義大利醫學文本語料庫上進行預訓練，提供三種模型大小：3.5 億、10 億和 30 億個參數。這些模型旨在平衡運算效率和效能，解決處理義大利語醫學術語特性的挑戰。我們使用混合領域生物醫學語料庫和通用基準對 Igea 進行評估，強調了其功效和在特定領域訓練後仍能保留一般知識。本文探討了模型的開發和評估，為義大利語生物醫學自然語言處理的未來進展奠定了基礎。

##### **Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**
2407.05887v1 by Sanjeet Singh, Shreya Gupta, Niralee Gupta, Naimish Sharma, Lokesh Srivastava, Vibhu Agarwal, Ashutosh Modi

The consequences of a healthcare data breach can be devastating for the
patients, providers, and payers. The average financial impact of a data breach
in recent months has been estimated to be close to USD 10 million. This is
especially significant for healthcare organizations in India that are managing
rapid digitization while still establishing data governance procedures that
align with the letter and spirit of the law. Computer-based systems for
de-identification of personal information are vulnerable to data drift, often
rendering them ineffective in cross-institution settings. Therefore, a rigorous
assessment of existing de-identification against local health datasets is
imperative to support the safe adoption of digital health initiatives in India.
Using a small set of de-identified patient discharge summaries provided by an
Indian healthcare institution, in this paper, we report the nominal performance
of de-identification algorithms (based on language models) trained on publicly
available non-Indian datasets, pointing towards a lack of cross-institutional
generalization. Similarly, experimentation with off-the-shelf de-identification
systems reveals potential risks associated with the approach. To overcome data
scarcity, we explore generating synthetic clinical reports (using publicly
available and Indian summaries) by performing in-context learning over Large
Language Models (LLMs). Our experiments demonstrate the use of generated
reports as an effective strategy for creating high-performing de-identification
systems with good generalization capabilities.

摘要：醫療保健資料外洩的後果對患者、提供者和付款者來說可能是毀滅性的。最近幾個月資料外洩的平均財務影響估計接近 1,000 萬美元。這對印度的醫療保健組織來說尤其重要，這些組織在管理快速數位化的同時，仍在建立符合法律條文和精神的資料治理程序。用於去識別個人資訊的電腦系統容易受到資料漂移的影響，通常導致它們在跨機構設定中無效。因此，必須嚴格評估現有的去識別與當地健康資料集，才能支援印度安全採用數位健康計畫。本文使用印度醫療保健機構提供的一小組去識別患者出院摘要，報告了在公開可用的非印度資料集上訓練的去識別演算法（基於語言模型）的標稱效能，指出缺乏跨機構概化。同樣地，對現成的去識別系統進行實驗揭示了與該方法相關的潛在風險。為了克服資料稀少的問題，我們探討透過在大語言模型 (LLM) 上執行情境學習來產生合成臨床報告（使用公開可用的印度摘要）。我們的實驗證明了使用產生的報告作為建立具有良好概化能力的高效能去識別系統的有效策略。

##### **Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**
2407.05810v1 by Xinrui Song, Jiajin Zhang, Pingkun Yan, Juergen Hahn, Uwe Kruger, Hisham Mohamed, Ge Wang

The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.

摘要：人工智能（AI）聊天機器人整合到高等教育中，標誌著新一代教學工具的轉變，反映了網路等里程碑的到來。隨著 ChatGPT-4 Turbo 在 2023 年 11 月推出，我們開發了一個基於 ChatGPT 的教學應用程式（https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging），並在 2024 年春季學期將其整合到我們的醫學影像學本科課程中。本研究調查了在一個學期長的試驗中使用 ChatGPT 的情況，深入了解學生的參與度、看法和技術的整體教育效果。我們系統地收集和分析了有關學生與 ChatGPT 互動的資料，重點關注他們的態度、疑慮和使用模式。研究結果表明，ChatGPT 提供了顯著的優勢，例如改進資訊的取得和增加互動性，但其採用也伴隨著對所提供資訊準確性的疑慮，以及最佳化其使用的明確準則的必要性。

##### **FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**
2407.05800v1 by Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

Despite recent advancements in federated learning (FL) for medical image
diagnosis, addressing data heterogeneity among clients remains a significant
challenge for practical implementation. A primary hurdle in FL arises from the
non-IID nature of data samples across clients, which typically results in a
decline in the performance of the aggregated global model. In this study, we
introduce FedMRL, a novel federated multi-agent deep reinforcement learning
framework designed to address data heterogeneity. FedMRL incorporates a novel
loss function to facilitate fairness among clients, preventing bias in the
final global model. Additionally, it employs a multi-agent reinforcement
learning (MARL) approach to calculate the proximal term $(\mu)$ for the
personalized local objective function, ensuring convergence to the global
optimum. Furthermore, FedMRL integrates an adaptive weight adjustment method
using a Self-organizing map (SOM) on the server side to counteract distribution
shifts among clients' local data distributions. We assess our approach using
two publicly available real-world medical datasets, and the results demonstrate
that FedMRL significantly outperforms state-of-the-art techniques, showing its
efficacy in addressing data heterogeneity in federated learning. The code can
be found here~{\url{https://github.com/Pranabiitp/FedMRL}}.

摘要：儘管在用於醫學影像診斷的聯邦學習 (FL) 方面有近期的進展，但解決客戶端之間的資料異質性仍然是實際執行的重大挑戰。聯邦學習的主要障礙來自於客戶端之間資料樣本的非獨立同分布 (non-IID) 特性，這通常會導致彙總的全球模型效能下降。在本研究中，我們引入了 FedMRL，一個新穎的聯邦多智能體深度強化學習框架，旨在解決資料異質性。FedMRL 結合了一個新穎的損失函數，以促進客戶端之間的公平性，防止最終全球模型中的偏差。此外，它採用多智能體強化學習 (MARL) 方法來計算個性化局部目標函數的近端項 (μ)，確保收斂到全局最優值。此外，FedMRL 整合了一種自適應權重調整方法，在伺服器端使用自組織化對應 (SOM)，以抵消客戶端本地資料分佈之間的分布轉移。我們使用兩個公開可用的真實世界醫學資料集評估我們的做法，結果表明 FedMRL 明顯優於最先進的技術，顯示其在解決聯邦學習中資料異質性方面的效能。程式碼可以在這裡找到~{\url{https://github.com/Pranabiitp/FedMRL}}。

##### **Large Language Models for Judicial Entity Extraction: A Comparative Study**
2407.05786v1 by Atin Sakkeer Hussain, Anu Thomas

Domain-specific Entity Recognition holds significant importance in legal
contexts, serving as a fundamental task that supports various applications such
as question-answering systems, text summarization, machine translation,
sentiment analysis, and information retrieval specifically within case law
documents. Recent advancements have highlighted the efficacy of Large Language
Models in natural language processing tasks, demonstrating their capability to
accurately detect and classify domain-specific facts (entities) from
specialized texts like clinical and financial documents. This research
investigates the application of Large Language Models in identifying
domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,
FIR nos.) within case law documents, with a specific focus on their aptitude
for handling domain-specific language complexity and contextual variations. The
study evaluates the performance of state-of-the-art Large Language Model
architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in
the context of extracting judicial facts tailored to Indian judicial texts.
Mistral and Gemma emerged as the top-performing models, showcasing balanced
precision and recall crucial for accurate entity identification. These findings
confirm the value of Large Language Models in judicial documents and
demonstrate how they can facilitate and quicken scientific research by
producing precise, organised data outputs that are appropriate for in-depth
examination.

摘要：領域特定實體辨識在法律脈絡中至關重要，作為支援各種應用程式的基礎任務，例如在案例法文件中進行問答系統、文字摘要、機器翻譯、情緒分析和資訊檢索。最近的進展突顯了大型語言模型在自然語言處理任務中的效能，展示了它們準確偵測和分類來自專業文本（例如臨床和財務文件）的領域特定事實（實體）的能力。本研究探討了大型語言模型在案例法文件中辨識領域特定實體（例如法院、請願人、法官、律師、答辯人、FIR 編號）的應用，特別關注它們處理領域特定語言複雜性和脈絡變化的能力。本研究評估了最先進的大型語言模型架構（包括 Large Language Model Meta AI 3、Mistral 和 Gemma）在提取針對印度司法文本量身打造的司法事實方面的效能。Mistral 和 Gemma 成為表現最佳的模型，展示了準確實體辨識至關重要的平衡精確度和召回率。這些發現證實了大型語言模型在司法文件中的價值，並展示了它們如何透過產生適用於深入檢驗的精確、有組織的資料輸出，來促進和加速科學研究。

##### **Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**
2407.05758v1 by Yutong Zhang, Yi Pan, Tianyang Zhong, Peixin Dong, Kangni Xie, Yuxiao Liu, Hanqi Jiang, Zhengliang Liu, Shijie Zhao, Tuo Zhang, Xi Jiang, Dinggang Shen, Tianming Liu, Xin Zhang

Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.

摘要：<paragraph>醫學影像和放射科報告對診斷醫療狀況至關重要，突顯了定量分析在臨床決策中的重要性。然而，這些數據的多樣性和跨來源異質性挑戰了當前數據挖掘方法的概括性。多模態大型語言模型 (MLLM) 近來已轉變許多領域，對醫學領域影響重大。值得注意的是，Gemini-Vision 系列 (Gemini) 和 GPT-4 系列 (GPT-4) 模型已成為電腦視覺中人工通用智慧 (AGI) 的典範轉移，展示了它們在生物醫學領域的潛力。在這項研究中，我們評估了 Gemini、GPT-4 和 4 個熱門大型模型在 14 個醫療影像數據集上的廣泛評估表現，包括 5 個醫療影像類別（皮膚科、放射科、牙科、眼科和內視鏡檢查），以及 3 個放射科報告數據集。所調查的任務包括疾病分類、病灶分割、解剖定位、疾病診斷、報告生成和病灶檢測。我們的實驗結果表明，Gemini 系列模型在報告生成和病灶檢測方面表現出色，但在疾病分類和解剖定位方面面臨挑戰。相反，GPT 系列模型在病灶分割和解剖定位方面表現出熟練度，但在疾病診斷和病灶檢測方面遇到困難。此外，Gemini 系列和 GPT 系列都包含已證明具有可取生成效率的模型。儘管這兩種模型都有望減少醫師的工作量，減輕有限醫療保健資源的壓力，並促進臨床從業人員與人工智慧技術之間的合作，但在臨床部署之前，實質性的增強和全面的驗證仍然勢在必行。</paragraph>

##### **RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**
2407.05683v1 by Inye Na, Jonghun Kim, Eun Sook Ko, Hyunjin Park

Motivated by the question, "Can we generate tumors with desired attributes?''
this study leverages radiomics features to explore the feasibility of
generating synthetic tumor images. Characterized by its low-dimensional yet
biologically meaningful markers, radiomics bridges the gap between complex
medical imaging data and actionable clinical insights. We present
RadiomicsFill-Mammo, the first of the RadiomicsFill series, an innovative
technique that generates realistic mammogram mass images mirroring specific
radiomics attributes using masked images and opposite breast images, leveraging
a recent stable diffusion model. This approach also allows for the
incorporation of essential clinical variables, such as BI-RADS and breast
density, alongside radiomics features as conditions for mass generation.
Results indicate that RadiomicsFill-Mammo effectively generates diverse and
realistic tumor images based on various radiomics conditions. Results also
demonstrate a significant improvement in mass detection capabilities,
leveraging RadiomicsFill-Mammo as a strategy to generate simulated samples.
Furthermore, RadiomicsFill-Mammo not only advances medical imaging research but
also opens new avenues for enhancing treatment planning and tumor simulation.
Our code is available at https://github.com/nainye/RadiomicsFill.

摘要：<paragraph>本研究以「我們能生成具有所需屬性的腫瘤嗎？」這個問題為動機，利用放射特徵來探討生成合成腫瘤影像的可行性。放射特徵以其低維度且具有生物意義的標記為特徵，彌補了複雜醫學影像資料與可操作臨床見解之間的差距。我們提出 RadiomicsFill-Mammo，RadiomicsFill 系列的第一個，這是一種創新的技術，利用遮罩影像和對側乳房影像，並利用最近的穩定擴散模型，生成反映特定放射特徵屬性的逼真乳房攝影腫塊影像。這種方法還允許將基本臨床變數，例如 BI-RADS 和乳房密度，與放射特徵一起作為生成腫塊的條件。結果表明，RadiomicsFill-Mammo 能有效地根據各種放射條件生成多樣化且逼真的腫瘤影像。結果還證明了腫塊檢測能力的顯著提升，利用 RadiomicsFill-Mammo 作為生成模擬樣本的策略。此外，RadiomicsFill-Mammo 不僅推動了醫學影像研究，還為增強治療規劃和腫瘤模擬開闢了新途徑。我們的程式碼可在 https://github.com/nainye/RadiomicsFill 取得。</paragraph>

##### **WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**
2407.05603v1 by Pingyi Chen, Chenglu Zhu, Sunyi Zheng, Honglin Li, Lin Yang

Whole slide imaging is routinely adopted for carcinoma diagnosis and
prognosis. Abundant experience is required for pathologists to achieve accurate
and reliable diagnostic results of whole slide images (WSI). The huge size and
heterogeneous features of WSIs make the workflow of pathological reading
extremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)
to interpret WSIs by generative visual question answering. WSI-VQA shows
universality by reframing various kinds of slide-level tasks in a
question-answering pattern, in which pathologists can achieve
immunohistochemical grading, survival prediction, and tumor subtyping following
human-machine interaction. Furthermore, we establish a WSI-VQA dataset which
contains 8672 slide-level question-answering pairs with 977 WSIs. Besides the
ability to deal with different slide-level tasks, our generative model which is
named Wsi2Text Transformer (W2T) outperforms existing discriminative models in
medical correctness, which reveals the potential of our model to be applied in
the clinical scenario. Additionally, we also visualize the co-attention mapping
between word embeddings and WSIs as an intuitive explanation for diagnostic
results. The dataset and related code are available at
https://github.com/cpystan/WSI-VQA.

摘要：全切片影像通常用於癌症的診斷和預後。病理學家需要有豐富的經驗才能對全切片影像 (WSI) 做出準確且可靠的診斷結果。WSI 的尺寸龐大且特徵異質，使得病理學判讀的工作流程極為耗時。在本文中，我們提出了一個新的框架 (WSI-VQA)，透過生成式視覺問答來詮釋 WSI。WSI-VQA 透過在問答模式中重新定義各種切片層級任務，展現其通用性，病理學家可以在人機互動後，完成免疫組織化學分級、存活預測和腫瘤亞型分類。此外，我們建立了一個 WSI-VQA 資料集，其中包含 8672 個切片層級問答對，以及 977 個 WSI。除了能夠處理不同的切片層級任務外，我們名為 Wsi2Text Transformer (W2T) 的生成模型在醫學正確性方面優於現有的判別模型，這揭示了我們的模型在臨床場景中應用的潛力。此外，我們還將詞嵌入和 WSI 之間的共同注意映射視覺化，作為診斷結果的直觀解釋。資料集和相關程式碼可在 https://github.com/cpystan/WSI-VQA 取得。

##### **Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**
2407.05521v1 by Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk

Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is
particularly important for adaptive radiotherapy, a recent medical advance
capable of improving cancer diagnosis and treatment. Recent studies have shown
that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI
analysis, indicating the potential of deep learning to enhance diagnostic
capabilities in healthcare. However, IVIM-NET does not provide calibrated
uncertainty information needed for reliable and trustworthy predictions in
healthcare. Moreover, the expensive computation and memory demands of IVIM-NET
reduce hardware performance, hindering widespread adoption in realistic
scenarios. To address these challenges, this paper proposes an
algorithm-hardware co-optimization flow for high-performance and reliable MRI
analysis. At the algorithm level, a transformation design flow is introduced to
convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN),
facilitating reliable and efficient uncertainty estimation. At the hardware
level, we propose an FPGA-based accelerator with several hardware
optimizations, such as mask-zero skipping and operation reordering.
Experimental results demonstrate that our co-design approach can satisfy the
uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5
times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations
with reduced power consumption.

摘要：精準可靠的磁振造影 (MRI) 分析對於適應性放射治療特別重要，這是一種近期醫療進展，能夠改善癌症診斷和治療。最近的研究顯示，深度神經網路 (DNN) 的 IVIM-NET 能在 MRI 分析中達到高準確度，顯示深度學習有潛力增強醫療保健中的診斷能力。然而，IVIM-NET 沒有提供在醫療保健中進行可靠且值得信賴的預測所需的校準不確定性資訊。此外，IVIM-NET 昂貴的運算和記憶體需求降低了硬體效能，阻礙了在實際場景中的廣泛採用。為了解決這些挑戰，本文提出了一種演算法與硬體共同最佳化的流程，以進行高性能且可靠的 MRI 分析。在演算法層級，引入了轉換設計流程，將 IVIM-NET 轉換為基於遮罩的貝氏神經網路 (BayesNN)，促進可靠且有效的非確定性估計。在硬體層級，我們提出了一種基於 FPGA 的加速器，具備多項硬體最佳化，例如遮罩零跳過和運算重新排序。實驗結果證明，我們的共同設計方法可以滿足 MRI 分析的不確定性需求，同時在 Xilinx VU13P FPGA 上實現比 GPU 和 CPU 實作快上 7.5 倍和 32.5 倍的速度，且功耗降低。

##### **A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**
2407.05458v1 by Fei Wang, Weibo Gao, Qi Liu, Jiatong Li, Guanhao Zhao, Zheng Zhang, Zhenya Huang, Mengxiao Zhu, Shijin Wang, Wei Tong, Enhong Chen

Cognitive diagnosis has been developed for decades as an effective
measurement tool to evaluate human cognitive status such as ability level and
knowledge mastery. It has been applied to a wide range of fields including
education, sport, psychological diagnosis, etc. By providing better awareness
of cognitive status, it can serve as the basis for personalized services such
as well-designed medical treatment, teaching strategy and vocational training.
This paper aims to provide a survey of current models for cognitive diagnosis,
with more attention on new developments using machine learning-based methods.
By comparing the model structures, parameter estimation algorithms, model
evaluation methods and applications, we provide a relatively comprehensive
review of the recent trends in cognitive diagnosis models. Further, we discuss
future directions that are worthy of exploration. In addition, we release two
Python libraries: EduData for easy access to some relevant public datasets we
have collected, and EduCDM that implements popular CDMs to facilitate both
applications and research purposes.

摘要：認知診斷已發展數十年，作為評估人類認知狀態（例如能力水平和知識掌握）的有效測量工具。它已被應用於廣泛的領域，包括教育、體育、心理診斷等。透過提供對認知狀態的更好認識，它可以作為個人化服務的基礎，例如精心設計的醫療治療、教學策略和職業訓練。本文旨在提供認知診斷當前模型的綜述，並更關注使用基於機器學習的方法的新發展。透過比較模型結構、參數估計演算法、模型評估方法和應用，我們對認知診斷模型的最新趨勢提供了相對全面的回顧。此外，我們討論了值得探索的未來方向。此外，我們發布了兩個 Python 程式庫：EduData，用於輕鬆存取我們收集的一些相關公開資料集，以及 EduCDM，用於實作熱門的 CDM，以促進應用和研究目的。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**
2407.05412v1 by Juzheng Miao, Cheng Chen, Keli Zhang, Jie Chuai, Quanzheng Li, Pheng-Ann Heng

One-shot detection of anatomical landmarks is gaining significant attention
for its efficiency in using minimal labeled data to produce promising results.
However, the success of current methods heavily relies on the employment of
extensive unlabeled data to pre-train an effective feature extractor, which
limits their applicability in scenarios where a substantial amount of unlabeled
data is unavailable. In this paper, we propose the first foundation
model-enabled one-shot landmark detection (FM-OSD) framework for accurate
landmark detection in medical images by utilizing solely a single template
image without any additional unlabeled data. Specifically, we use the frozen
image encoder of visual foundation models as the feature extractor, and
introduce dual-branch global and local feature decoders to increase the
resolution of extracted features in a coarse to fine manner. The introduced
feature decoders are efficiently trained with a distance-aware similarity
learning loss to incorporate domain knowledge from the single template image.
Moreover, a novel bidirectional matching strategy is developed to improve both
robustness and accuracy of landmark detection in the case of scattered
similarity map obtained by foundation models. We validate our method on two
public anatomical landmark detection datasets. By using solely a single
template image, our method demonstrates significant superiority over strong
state-of-the-art one-shot landmark detection methods.

摘要：解剖標誌的一發偵測因其使用最少標籤資料產生有前景結果的效率而獲得顯著關注。然而，目前方法的成功極度依賴運用廣泛的未標籤資料來預先訓練一個有效特徵萃取器，這限制了其在大量未標籤資料不可用的情況下的適用性。在本文中，我們提出第一個基礎模型啟用的單發標誌偵測 (FM-OSD) 架構，藉由僅僅利用單一範本影像而無任何其他未標籤資料，在醫學影像中進行精確標誌偵測。具體來說，我們使用視覺基礎模型的凍結影像編碼器作為特徵萃取器，並引入雙分支全局和局部特徵解碼器，以粗到細的方式增加萃取特徵的分辨率。引入的特徵解碼器利用距離感知相似性學習損失函數進行有效訓練，以納入單一範本影像的領域知識。此外，開發了一種新穎的雙向匹配策略，以提高基礎模型取得的散佈相似性圖在標誌偵測中的穩健性和準確性。我們在兩個公開的解剖標誌偵測資料集驗證我們的模型。我們的模型僅使用單一範本影像，證明其優於現有技術中強大的單發標誌偵測方法。

##### **BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**
2407.05213v1 by Weimin Lyu, Zexin Bi, Fusheng Wang, Chao Chen

The advent of clinical language models integrated into electronic health
records (EHR) for clinical decision support has marked a significant
advancement, leveraging the depth of clinical notes for improved
decision-making. Despite their success, the potential vulnerabilities of these
models remain largely unexplored. This paper delves into the realm of backdoor
attacks on clinical language models, introducing an innovative attention-based
backdoor attack method, BadCLM (Bad Clinical Language Models). This technique
clandestinely embeds a backdoor within the models, causing them to produce
incorrect predictions when a pre-defined trigger is present in inputs, while
functioning accurately otherwise. We demonstrate the efficacy of BadCLM through
an in-hospital mortality prediction task with MIMIC III dataset, showcasing its
potential to compromise model integrity. Our findings illuminate a significant
security risk in clinical decision support systems and pave the way for future
endeavors in fortifying clinical language models against such vulnerabilities.

摘要：臨床語言模型整合到電子健康紀錄 (EHR) 中以進行臨床決策支援，標誌著一項重大的進展，利用臨床筆記的深度來改善決策制定。儘管這些模型取得了成功，但它們的潛在漏洞在很大程度上仍未得到探索。本文深入探討了針對臨床語言模型的後門攻擊領域，介紹了一種創新的基於注意力的後門攻擊方法 BadCLM（不良臨床語言模型）。這種技術秘密地在模型中嵌入了一個後門，導致它們在輸入中存在預定義觸發器時產生不正確的預測，而其他情況下則準確運作。我們通過使用 MIMIC III 資料集進行院內死亡率預測任務來證明 BadCLM 的效力，展示了其損害模型完整性的潛力。我們的發現揭示了臨床決策支援系統中的一個重大安全風險，並為未來加強臨床語言模型以應對此類漏洞的努力鋪平了道路。

##### **RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**
2407.05131v1 by Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao

The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has
enhanced medical diagnosis. However, current Med-LVLMs frequently encounter
factual issues, often generating responses that do not align with established
medical facts. Retrieval-Augmented Generation (RAG), which utilizes external
knowledge, can improve the factual accuracy of these models but introduces two
major challenges. First, limited retrieved contexts might not cover all
necessary information, while excessive retrieval can introduce irrelevant and
inaccurate references, interfering with the model's generation. Second, in
cases where the model originally responds correctly, applying RAG can lead to
an over-reliance on retrieved contexts, resulting in incorrect answers. To
address these issues, we propose RULE, which consists of two components. First,
we introduce a provably effective strategy for controlling factuality risk
through the calibrated selection of the number of retrieved contexts. Second,
based on samples where over-reliance on retrieved contexts led to errors, we
curate a preference dataset to fine-tune the model, balancing its dependence on
inherent knowledge and retrieved contexts for generation. We demonstrate the
effectiveness of RULE on three medical VQA datasets, achieving an average
improvement of 20.8% in factual accuracy. We publicly release our benchmark and
code in https://github.com/richard-peng-xia/RULE.

摘要：最近出現的醫療大型語言模型 (Med-LVLMs) 提升了醫療診斷。然而，目前的 Med-LVLMs 經常遇到事實問題，通常會產生與已確立的醫療事實不符的回應。利用外部知識的檢索增強生成 (RAG) 可以改善這些模型的事實準確性，但引入了兩個主要挑戰。首先，有限的檢索內容可能無法涵蓋所有必要的資訊，而過度的檢索可能會引入不相關和不準確的參考，干擾模型的生成。其次，在模型原本正確回應的情況下，應用 RAG 可能會過度依賴檢索到的內容，導致不正確的答案。為了解決這些問題，我們提出了 RULE，它包含兩個組成部分。首先，我們引入了一種可證明有效的策略，透過校準檢索到的內容數量來控制事實風險。其次，根據過度依賴檢索到的內容導致錯誤的範例，我們策劃了一個偏好資料集來微調模型，平衡其在生成時對內在知識和檢索到的內容的依賴性。我們在三個醫療 VQA 資料集上展示了 RULE 的有效性，在事實準確性方面平均提升了 20.8%。我們在 https://github.com/richard-peng-xia/RULE 中公開發布我們的基準和程式碼。

##### **Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**
2407.05087v1 by Xiao Siyao, Huang Libing, Zhang Shunsheng

Multiplicative noise widely exists in radar images, medical images and other
important fields' images. Compared to normal noises, multiplicative noise has a
generally stronger effect on the visual expression of images. Aiming at the
denoising problem of multiplicative noise, we linearize the nonlocal means
algorithm with deep learning and propose a linear attention mechanism based
deep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal
means filtering, we employ deep channel convolution neural networks to extract
the information of the neighborhood matrix and obtain representation vectors of
every pixel. Then we replace the similarity calculation and weighted averaging
processes with the inner operations of the attention mechanism. To reduce the
computational overhead, through the formula of similarity calculation and
weighted averaging, we derive a nonlocal filter with linear complexity.
Experiments on both simulated and real multiplicative noise demonstrate that
the LDNLM is more competitive compared with the state-of-the-art methods.
Additionally, we prove that the LDNLM possesses interpretability close to
traditional NLM.

摘要：乘性雜訊廣泛存在於雷達影像、醫學影像等重要領域的影像中。相較於一般雜訊，乘性雜訊對影像的視覺表現具有普遍更強的影響。針對乘性雜訊的去雜訊問題，我們以深度學習線性化非局部均值演算法，並提出基於線性注意力機制的深度非局部均值濾波（LDNLM）。從傳統非局部均值濾波出發，我們採用深度通道卷積神經網路提取鄰域矩陣的資訊，並取得每個畫素的表示向量。接著，我們以注意力機制的內部運算取代相似度計算與加權平均的程序。為了降低運算負擔，我們透過相似度計算與加權平均的公式，推導出具有線性複雜度的非局部濾波器。在模擬與真實乘性雜訊上的實驗均證實，LDNLM 與目前最先進的方法相比更具競爭力。此外，我們證明 LDNLM 具備接近傳統 NLM 的可解釋性。

##### **Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**
2407.04808v1 by Iman Kianian, Hedieh Sajedi

Brain age estimation involves predicting the biological age of individuals
from their brain images, which offers valuable insights into the aging process
and the progression of neurodegenerative diseases. Conducting large-scale
datasets for medical image analysis is a challenging and time-consuming task.
Existing approaches mostly depend on large datasets, which are hard to come by
and expensive. These approaches also require sophisticated, resource-intensive
models with a large number of parameters, necessitating a considerable amount
of processing power. As a result, there is a vital need to develop innovative
methods that can achieve robust performance with limited datasets and efficient
use of computational resources. This paper proposes a novel slice-based
dual-stream method called GDSM (Greedy Dual-Stream Model) for brain age
estimation. This method addresses the limitations of large dataset requirements
and computational resource intensiveness. The proposed method incorporates
local and global aspects of the brain, thereby refining the focus on specific
target regions. The approach employs four backbones to predict ages based on
local and global features, complemented by a final model for age correction.
Our method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test
set of IBID, which only contains 289 subjects. To demonstrate the robustness of
our approach for any small dataset, we analyzed the proposed method with the
IXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By
leveraging dual-stream and greedy strategies, this approach achieves efficiency
and robust performance, making it comparable with other state-of-the-art
methods. The code for the GDSM model is available at
https://github.com/iman2693/GDSM.

摘要：大腦年齡估計涉及從大腦影像預測個體的生物年齡，這對老化過程和神經退化性疾病的進展提供了寶貴的見解。對醫學影像分析進行大規模的數據集處理是一項具有挑戰性且耗時的任務。現有的方法大多依賴於大型數據集，而這些數據集難以獲得且昂貴。這些方法還需要複雜的、資源密集型的模型，這些模型具有大量的參數，需要大量的處理能力。因此，迫切需要開發創新的方法，這些方法可以在有限的數據集和高效利用計算資源的情況下實現穩健的性能。本文提出了一種稱為 GDSM（貪婪雙流模型）的新型基於切片的雙流方法，用於大腦年齡估計。這種方法解決了對大型數據集需求和計算資源密集性的限制。所提出的方法結合了大腦的局部和全局方面，從而精確關注具體的目標區域。該方法採用四個主幹根據局部和全局特徵預測年齡，並輔以一個最終模型進行年齡校正。我們的模型在僅包含 289 個受試者的 IBID 測試集中展示了 3.25 年的平均絕對誤差 (MAE)。為了證明我們的模型對任何小型數據集的穩健性，我們使用 IXI 數據集分析了所提出的方法，並在 IXI 的測試集中實現了 4.18 年的 MAE。通過利用雙流和貪婪策略，這種方法實現了高效和穩健的性能，使其與其他最先進的方法相當。GDSM 模型的代碼可在 https://github.com/iman2693/GDSM 上獲得。

##### **Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**
2407.04629v1 by Reza Averly, Xia Ning

Clinical named entity recognition (NER) aims to retrieve important entities
within clinical narratives. Recent works have demonstrated that large language
models (LLMs) can achieve strong performance in this task. While previous works
focus on proprietary LLMs, we investigate how open NER LLMs, trained
specifically for entity recognition, perform in clinical NER. In this paper, we
aim to improve them through a novel framework, entity decomposition with
filtering, or EDF. Our key idea is to decompose the entity recognition task
into several retrievals of sub-entity types. We also introduce a filtering
mechanism to remove incorrect entities. Our experimental results demonstrate
the efficacy of our framework across all metrics, models, datasets, and entity
types. Our analysis reveals that entity decomposition can recognize previously
missed entities with substantial improvement. We further provide a
comprehensive evaluation of our framework and an in-depth error analysis to
pave future works.

摘要：臨床命名實體識別 (NER) 旨在擷取臨床敘述中的重要實體。最近的研究表明，大型語言模型 (LLM) 可以在此任務中實現強大的效能。雖然先前的研究專注於專有的 LLM，但我們探討了專門針對實體識別訓練的開放式 NER LLM 在臨床 NER 中的表現。在本文中，我們旨在透過一個新穎的架構來改善它們，即帶有過濾的實體分解，或 EDF。我們的關鍵想法是將實體識別任務分解為多個子實體類型的擷取。我們還引入了一個過濾機制來移除不正確的實體。我們的實驗結果證明了我們架構在所有指標、模型、資料集和實體類型中的效能。我們的分析顯示，實體分解可以識別先前遺漏的實體，並有顯著的改善。我們進一步提供了我們架構的全面評估和深入的錯誤分析，為未來的研究鋪路。

##### **Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**
2407.04486v1 by Tianshu Feng, Rohan Gnanaolivu, Abolfazl Safikhani, Yuanhang Liu, Jun Jiang, Nicholas Chia, Alexander Partin, Priyanka Vasanthakumari, Yitan Zhu, Chen Wang

Human cancers present a significant public health challenge and require the
discovery of novel drugs through translational research. Transcriptomics
profiling data that describes molecular activities in tumors and cancer cell
lines are widely utilized for predicting anti-cancer drug responses. However,
existing AI models face challenges due to noise in transcriptomics data and
lack of biological interpretability. To overcome these limitations, we
introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel
neural network framework that incorporates a variational component to mitigate
noise effects and integrates traceable gene ontology into the neural network
architecture for encoding cancer transcriptomics data. Key innovations include
a local interpretability-guided method for identifying ontology paths, a
visualization tool to elucidate biological mechanisms of drug responses, and
the application of centralized large scale hyperparameter optimization. VETE
demonstrated robust accuracy in cancer cell line classification and drug
response prediction. Additionally, it provided traceable biological
explanations for both tasks and offers insights into the mechanisms underlying
its predictions. VETE bridges the gap between AI-driven predictions and
biologically meaningful insights in cancer research, which represents a
promising advancement in the field.

摘要：人類癌症對公共衛生構成重大挑戰，需要透過轉譯研究發現新藥物。描述腫瘤和癌細胞株分子活動的轉錄組學分析資料廣泛用於預測抗癌藥物反應。然而，現有的 AI 模型因轉錄組學資料中的雜訊和缺乏生物學可解釋性而面臨挑戰。為了克服這些限制，我們引入了 VETE（變異和解釋性轉錄組學編碼器），這是一種新穎的神經網路架構，它結合了變異組成以減輕雜訊效應，並將可追蹤的基因本體整合到神經網路架構中以編碼癌症轉錄組學資料。關鍵創新包括一種局部可解釋性引導方法，用於識別本體路徑，一種用於闡明藥物反應的生物機制的視覺化工具，以及集中式大規模超參數最佳化的應用。VETE 在癌細胞株分類和藥物反應預測方面表現出穩健的準確性。此外，它為這兩個任務提供了可追蹤的生物學解釋，並提供了對其預測背後機制的見解。VETE 彌合了 AI 驅動預測與癌症研究中具有生物學意義的見解之間的差距，這代表了該領域的一項有前途的進展。

##### **Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**
2407.04449v1 by Saeed Shurrab, Alejandro Guerra-Manzanares, Farah E. Shamout

Self-supervised learning methods for medical images primarily rely on the
imaging modality during pretraining. While such approaches deliver promising
results, they do not leverage associated patient or scan information collected
within Electronic Health Records (EHR). Here, we propose to incorporate EHR
data during self-supervised pretraining with a Masked Siamese Network (MSN) to
enhance the quality of chest X-ray representations. We investigate three types
of EHR data, including demographic, scan metadata, and inpatient stay
information. We evaluate our approach on three publicly available chest X-ray
datasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)
backbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the
representations via linear evaluation, our proposed method demonstrates
significant improvement compared to vanilla MSN and state-of-the-art
self-supervised learning baselines. Our work highlights the potential of
EHR-enhanced self-supervised pre-training for medical imaging. The code is
publicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN

摘要：用於醫學影像的自監督式學習方法主要依賴於預訓練期間的影像模式。雖然此類方法提供了有前景的結果，但它們並未利用電子健康記錄 (EHR) 中收集的相關患者或掃描資訊。在此，我們建議在使用蒙面連體網路 (MSN) 進行自監督預訓練期間納入 EHR 資料，以提升胸部 X 光片表徵的品質。我們探討三種類型的 EHR 資料，包括人口統計資料、掃描元資料和住院期間資訊。我們在三個公開的胸部 X 光片資料集（MIMIC-CXR、CheXpert 和 NIH-14）上評估我們的做法，使用兩個視覺轉換器 (ViT) 主幹，特別是 ViT-Tiny 和 ViT-Small。在透過線性評估來評量表徵的品質時，我們提出的方法與傳統 MSN 和最先進的自監督式學習基準相比，表現出顯著的進步。我們的研究重點說明了 EHR 增強的自監督預訓練在醫學影像方面的潛力。此程式碼可於以下網址公開取得：https://github.com/nyuad-cai/CXR-EHR-MSN

##### **Query-Guided Self-Supervised Summarization of Nursing Notes**
2407.04125v1 by Ya Gao, Hans Moen, Saila Koivusalo, Miika Koskinen, Pekka Marttinen

Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.

摘要：護理記錄是電子健康紀錄 (EHR) 的重要組成部分，
在照護過程中追蹤病患的健康狀態進展。利用文字摘要技術提煉護理記錄中的關鍵資訊，可以提升臨床醫師在檢視護理記錄時了解病患狀況的效率。然而，現有的臨床摘要方法常常忽略護理記錄，且需要建立參考摘要作為監督訊號，這非常耗時。在這項工作中，我們提出 QGSumm，一個用於護理記錄摘要的查詢引導式自我監督領域適應架構。我們的做法使用與病患相關的臨床查詢作為指引，在訓練中不依賴參考摘要，就能產生高品質、以病患為中心的摘要。透過專家臨床醫師的自動和手動評估，我們展示了我們的方法與最先進的大語言模型 (LLM) 相比在零次學習和少次學習設定中的優勢。最終，我們的做法為條件式文字摘要提供了新的觀點，專門針對臨床人員的特定興趣量身打造。

##### **MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**
2407.04106v1 by Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny

Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.

摘要：隨著人工智慧 (AI) 的最新進展，醫療保健領域出現了顯著的突破，特別是在改善診斷程序方面。然而，先前的研究通常僅限於有限的功能。這項研究引入了 MiniGPT-Med，這是一種源自大規模語言模型且專為醫療應用而設計的視覺語言模型。MiniGPT-Med 在各種影像模式中展現出非凡的多功能性，包括 X 光、電腦斷層掃描和 MRI，進而增強其效用。該模型能夠執行諸如醫療報告生成、視覺問答 (VQA) 和醫療影像中的疾病識別等任務。它將影像和文字臨床資料整合處理，顯著提高了診斷準確性。我們的實證評估證實了 MiniGPT-Med 在疾病基礎、醫療報告生成和 VQA 基準上的優異表現，這代表了縮小協助放射診斷實務差距的重要一步。此外，它在醫療報告生成方面達到了最先進的表現，比先前的最佳模型高出 19% 的準確度。MiniGPT-Med 有望成為放射診斷的通用介面，進而提升各種醫療影像應用中的診斷效率。

##### **Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**
2407.03863v1 by Mehmet Yigit Avci, Emily Chan, Veronika Zimmer, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea

With the increasing incidence of neurodegenerative diseases such as
Alzheimer's Disease (AD), there is a need for further research that enhances
detection and monitoring of the diseases. We present MORPHADE (Morphological
Autoencoders for Alzheimer's Disease Detection), a novel unsupervised learning
approach which uses deformations to allow the analysis of 3D T1-weighted brain
images. To the best of our knowledge, this is the first use of deformations
with deep unsupervised learning to not only detect, but also localize and
assess the severity of structural changes in the brain due to AD. We obtain
markedly higher anomaly scores in clinically important areas of the brain in
subjects with AD compared to healthy controls, showcasing that our method is
able to effectively locate AD-related atrophy. We additionally observe a visual
correlation between the severity of atrophy highlighted in our anomaly maps and
medial temporal lobe atrophy scores evaluated by a clinical expert. Finally,
our method achieves an AUROC of 0.80 in detecting AD, out-performing several
supervised and unsupervised baselines. We believe our framework shows promise
as a tool towards improved understanding, monitoring and detection of AD. To
support further research and application, we have made our code publicly
available at github.com/ci-ber/MORPHADE.

摘要：隨著神經退行性疾病（例如阿茲海默症）的發生率增加，需要進一步的研究來加強對這些疾病的偵測和監控。我們提出 MORPHADE（阿茲海默症偵測的形態自動編碼器），這是一種新穎的無監督學習方法，它使用變形來分析 3D T1 加權腦部影像。據我們所知，這是首次將變形與深度無監督學習結合使用，不僅可以偵測，還可以定位和評估阿茲海默症導致的腦部結構變化嚴重程度。我們在阿茲海默症受試者的腦部臨床上重要區域獲得顯著更高的異常分數，與健康對照組相比，顯示我們的模型能夠有效定位與阿茲海默症相關的萎縮。此外，我們觀察到異常圖中突出的萎縮嚴重程度與臨床專家評估的內側顳葉萎縮分數之間存在視覺相關性。最後，我們的模型在偵測阿茲海默症方面達到了 0.80 的 AUROC，優於多個監督式和無監督式基準。我們相信我們的架構顯示出有望成為改善阿茲海默症理解、監控和偵測的工具。為了支持進一步的研究和應用，我們已在 github.com/ci-ber/MORPHADE 公開我們的程式碼。

##### **Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**
2407.03582v1 by Andrew Bouras

Generating diverse, high-quality outputs from language models is crucial for
applications in education and content creation. Achieving true randomness and
avoiding repetition remains a significant challenge. This study uses the Linear
Congruential Generator method for systematic fact selection, combined with
AI-powered content generation. We ensured unique combinations of
gastrointestinal physiology and pathology facts across multiple rounds,
integrating these facts into prompts for GPT-4o to create clinically relevant,
vignette-style outputs. Over 14 rounds, 98 unique outputs were generated,
demonstrating LCG's effectiveness in producing diverse and high-quality
content. This method addresses key issues of randomness and repetition,
enhancing the quality and efficiency of language model-generated content for
various applications.

摘要：在教育和內容創作的應用中，從語言模型產生多樣化、高品質的輸出至關重要。實現真正的隨機性和避免重複仍然是一項重大的挑戰。本研究使用線性同餘產生器方法進行系統性事實選擇，並結合 AI 驅動的內容生成。我們確保了在多輪中胃腸生理和病理事實的獨特組合，將這些事實整合到 GPT-4o 的提示中，以創建具有臨床相關性的短篇故事風格輸出。在 14 輪中，生成了 98 個獨特輸出，證明了 LCG 在產生多樣化和高品質內容方面的有效性。此方法解決了隨機性和重複性的關鍵問題，提高了語言模型生成的內容在各種應用中的品質和效率。

##### **Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**
2407.03308v1 by Sijie Xu, Shenyan Zong, Chang-Sheng Mei, Guofeng Shen, Yueran Zhao, He Wang

Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.

摘要：基於質子共振頻率 (PRF) 的 MR 溫度測量對於聚焦超音波 (FUS) 熱消融療法至關重要。這項研究旨在透過改善深度學習方法，提升動態 MR 溫度圖重建中的時間解析度。在 2 倍和 4 倍的 k-space 資料不足採樣中，將訓練最佳化方法和五個傳統神經網路應用於重建溫度圖。增強的訓練模組包括離線/線上資料擴充、知識萃取，以及振幅相位解耦損失函數。加熱實驗分別由 FUS 換能器在模擬人體和離體組織上執行。這些資料經過手動不足採樣以模擬加速程序，並在我們的模型中進行訓練以取得重建模型。額外的十幾個測試資料集則另外取得，用於評估即時效能和溫度準確度。在 2 倍和 4 倍 k-space 不足採樣策略中，發現加速因子為 1.9 和 3.7，而基於 ResUNet 的深度學習重建表現得非常好。在 2 倍加速情境中，溫度圖區塊的 RMSE 在模擬人體和離體測試資料集上提供 0.888 度攝氏和 1.145 度攝氏的值。溫度區域的 DICE 值，以 43 度攝氏等溫線包覆，為 0.809，而 Bland-Altman 分析顯示偏差為 -0.253 度攝氏，加上或減去 2.16 度攝氏。在 4 倍不足採樣案例中，這些評估值減少了大約 10%。這項研究證明，基於深度學習的重建可以大幅提升臨床 FUS 熱療中 MR 溫度測量的準確度和效率。

##### **MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**
2407.03131v2 by Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu

Electroencephalography (EEG), a medical imaging technique that captures scalp
electrical activity of brain structures via electrodes, has been widely used in
affective computing. The spatial domain of EEG is rich in affective
information. However, few of the existing studies have simultaneously analyzed
EEG signals from multiple perspectives of geometric and anatomical structures
in spatial domain. In this paper, we propose a multi-view Graph Transformer
(MVGT) based on spatial relations, which integrates information from the
temporal, frequency and spatial domains, including geometric and anatomical
structures, so as to enhance the expressive power of the model comprehensively.
We incorporate the spatial information of EEG channels into the model as
encoding, thereby improving its ability to perceive the spatial structure of
the channels. Meanwhile, experimental results based on publicly available
datasets demonstrate that our proposed model outperforms state-of-the-art
methods in recent years. In addition, the results also show that the MVGT could
extract information from multiple domains and capture inter-channel
relationships in EEG emotion recognition tasks effectively.

摘要：腦電圖（EEG）是一種醫學影像技術，透過電極擷取頭皮上腦部結構的電氣活動，已廣泛用於情感運算中。EEG 的空間域蘊藏豐富的情感資訊。然而，現有的研究鮮少同時從空間域中的幾何結構和解剖結構等多重面向分析 EEG 訊號。本文提出一個基於空間關係的多視圖圖形轉換器（MVGT），它整合了時間、頻率和空間域（包括幾何結構和解剖結構）的資訊，以全面提升模型的表現力。我們將 EEG 通道的空間資訊編碼後納入模型中，進而提升其感知通道空間結構的能力。同時，基於公開資料集的實驗結果顯示，我們提出的模型優於近年來的現有技術。此外，結果也顯示 MVGT 能有效從多重域中擷取資訊，並在 EEG 情緒辨識任務中捕捉到通道間的關係。

##### **Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**
2407.03086v1 by Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko

While federated learning leverages distributed client resources, it faces
challenges due to heterogeneous client capabilities. This necessitates
allocating models suited to clients' resources and careful parameter
aggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel
federated learning framework for supporting client heterogeneity by combining a
multi-exit network architecture with hypernetwork-based model weight
generation. This approach aligns the feature spaces of heterogeneous model
layers and resolves per-layer information disparity during weight aggregation.
To practically realize HypeMeFed, we also propose a low-rank factorization
approach to minimize computation and memory overhead associated with
hypernetworks. Our evaluations on a real-world heterogeneous device testbed
indicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the
hypernetwork memory requirements by 98.22%, and accelerates its operations by
1.86 times compared to a naive hypernetwork approach. These results demonstrate
HypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for
federated learning.

摘要：雖然聯合學習利用分散式用戶端資源，但由於用戶端能力異質，因此面臨挑戰。這需要分配適合用戶端資源的模型，並仔細參數聚合以容納這種異質性。我們提出 HypeMeFed，一種新的聯合學習框架，通過將多出口網路架構與基於超網路的模型權重生成相結合來支援用戶端異質性。此方法對齊異質模型層的特徵空間，並在權重聚合期間解決逐層資訊差異。為了實際實現 HypeMeFed，我們還提出了一種低秩分解方法，以最大限度地減少與超網路相關的計算和記憶體開銷。我們在真實世界異質設備測試平台上的評估表明，與 FedAvg 相比，HypeMeFed 將準確率提高了 5.12%，將超網路記憶體需求減少了 98.22%，並且與天真的超網路方法相比，其運算速度提高了 1.86 倍。這些結果證明了 HypeMeFed 在利用和吸引異質用戶端進行聯合學習方面的有效性。

##### **Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**
2407.03034v1 by Siying Xu, Kerstin Hammernik, Andreas Lingg, Jens Kuebler, Patrick Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Kuestner

Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment
of heart morphology and function in clinical practice. However, MRI requires
long acquisition times, with recent deep learning-based methods showing great
promise to accelerate imaging and enhance reconstruction quality. Existing
networks exhibit some common limitations that constrain further acceleration
possibilities, including single-domain learning, reliance on a single
regularization term, and equal feature contribution. To address these
limitations, we propose to embed information from multiple domains, including
low-rank, image, and k-space, in a novel deep learning network for MRI
reconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch
structure, enabling independent learning in the k-space and image domain.
Coupled information sharing layers realize the information exchange between
domains. Furthermore, we introduce attention mechanisms into the network to
assign greater weights to more critical coils or important temporal frames.
Training and testing were conducted on an in-house dataset, including 91
cardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine
using retrospective undersampling. Additionally, we evaluated A-LIKNet on the
real-time 8x prospectively undersampled data from the OCMR dataset. The results
demonstrate that our proposed A-LIKNet outperforms existing methods and
provides high-quality reconstructions. The network can effectively reconstruct
highly retrospectively undersampled dynamic MR images up to 24x accelerations,
indicating its potential for single breath-hold imaging.

摘要：<paragraph>心臟動態磁共振影像 (MRI) 提供了心臟形態和功能在臨床實務上的精準評估。然而，MRI 需要較長的擷取時間，而最近基於深度學習的方法顯示出極佳的潛力，用於加速影像並增強重建品質。現有的網路展現了一些常見的限制，限制了進一步的加速可能性，包括單一領域學習、依賴單一正則化項，以及相等的特徵貢獻。為了解決這些限制，我們提議將來自多個領域的資訊嵌入一個用於 MRI 重建的新穎深度學習網路中，包括低秩、影像，以及 k 空間，我們將其表示為 A-LIKNet。A-LIKNet 採用平行分支結構，在 k 空間和影像領域中實現獨立學習。耦合資訊共享層實現了領域之間的資訊交換。此外，我們將注意力機制引入網路中，以將較大的權重分配給更重要的線圈或重要的時間幀。訓練和測試是在內部資料集上進行的，其中包括 91 位心血管疾病患者和 38 位健康受試者，他們使用 2D 心臟動態影像進行掃描，並使用回溯式欠採樣。此外，我們在 OCMR 資料集中的即時 8 倍前瞻性欠採樣資料上評估了 A-LIKNet。結果證明，我們提出的 A-LIKNet 優於現有方法，並提供了高品質的重建。該網路可以有效重建高回溯性欠採樣的動態 MR 影像，加速率高達 24 倍，這表示其具有單次閉氣影像的潛力。</paragraph>

##### **SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**
2407.03004v1 by Meghal Dani, Muthu Jeyanthi Prakash, Zeynep Akata, Stefanie Liebe

Large Language Models have shown promising results in their ability to encode
general medical knowledge in standard medical question-answering datasets.
However, their potential application in clinical practice requires evaluation
in domain-specific tasks, where benchmarks are largely missing. In this study
semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral
8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for
epilepsy diagnosis. Specifically, we obtain likelihood estimates linking
unstructured text descriptions of seizures to seizure-generating brain regions,
using an annotated clinical database containing 1269 entries. We evaluate the
LLM's performance, confidence, reasoning, and citation abilities in comparison
to clinical evaluation. Models achieve above-chance classification performance
with prompt engineering significantly improving their outcome, with some models
achieving close-to-clinical performance and reasoning. However, our analyses
also reveal significant pitfalls with several models being overly confident
while showing poor performance, as well as exhibiting citation errors and
hallucinations. In summary, our work provides the first extensive benchmark
comparing current SOTA LLMs in the medical domain of epilepsy and highlights
their ability to leverage unstructured texts from patients' medical history to
aid diagnostic processes in health care.

摘要：大型語言模型在標準醫療問答資料集中編碼一般醫療知識的能力方面已展現出可觀的成果。然而，它們在臨床實務中的潛在應用需要在特定領域任務中進行評估，而基準量測在很大程度上仍付之闕如。在本研究 semioLLM 中，我們測試了最先進的 LLM（GPT-3.5、GPT-4、Mixtral 8x7B 和 Qwen-72chat）利用其內部知識和推理進行癲癇診斷的能力。具體來說，我們取得了連結癲癇發作非結構化文字描述至癲癇發作生成腦區的可能性估計值，使用包含 1269 個條目的註解式臨床資料庫。我們評估了 LLM 的表現、信心、推理和引述能力，並與臨床評估進行比較。模型達到了高於機率的分類表現，提示工程顯著改善了其結果，有些模型達到了接近臨床表現和推理。然而，我們的分析也揭露了幾個模型的重大缺陷，它們過度自信，同時表現不佳，並出現引述錯誤和幻覺。總之，我們的研究提供了第一個廣泛的基準，比較了癲癇醫療領域中目前的 SOTA LLM，並突出了它們利用患者病史中的非結構化文字來協助醫療保健中的診斷程序的能力。

##### **MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**
2407.02994v1 by Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone

The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality dataset, mainly due
to privacy-related issues. Moreover, the recent rising of Multimodal Large
Language Models (MLLM) leads to a need for multimodal medical datasets, where
clinical reports and findings are attached to the corresponding CT or MR scans.
This paper illustrates the entire workflow for building the data set MedPix
2.0. Starting from the well-known multimodal dataset
MedPix\textsuperscript{\textregistered}, mainly used by physicians, nurses and
healthcare students for Continuing Medical Education purposes, a semi-automatic
pipeline was developed to extract visual and textual data followed by a manual
curing procedure where noisy samples were removed, thus creating a MongoDB
database. Along with the dataset, we developed a GUI aimed at navigating
efficiently the MongoDB instance, and obtaining the raw data that can be easily
used for training and/or fine-tuning MLLMs. To enforce this point, we also
propose a CLIP-based model trained on MedPix 2.0 for scan classification tasks.

摘要：隨著在醫療領域開發人工智慧應用程式的興趣日益增加，但由於隱私相關問題，導致缺乏高品質的資料集。此外，多模態大型語言模型 (MLLM) 的興起，需要建立多模態醫療資料集，其中臨床報告和發現會附加到對應的電腦斷層掃描或核磁共振掃描。本文說明建立資料集 MedPix 2.0 的完整工作流程。從廣為人知的由醫師、護理師和醫療保健學生主要用於持續醫療教育目的的多模態資料集 MedPix\textsuperscript{\textregistered} 開始，開發了一個半自動化管道來萃取視覺和文字資料，接著進行手動清理程序移除雜訊樣本，進而建立一個 MongoDB 資料庫。隨著資料集，我們開發了一個 GUI，旨在有效率地瀏覽 MongoDB 執行個體，並取得可用於訓練和/或微調 MLLM 的原始資料。為了強調這一點，我們也提出一個在 MedPix 2.0 上訓練的基於 CLIP 的模型，用於掃描分類任務。

##### **Membership Inference Attacks Against Time-Series Models**
2407.02870v1 by Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit

Analyzing time-series data that may contain personal information,
particularly in the medical field, presents serious privacy concerns. Sensitive
health data from patients is often used to train machine-learning models for
diagnostics and ongoing care. Assessing the privacy risk of such models is
crucial to making knowledgeable decisions on whether to use a model in
production, share it with third parties, or deploy it in patients homes.
Membership Inference Attacks (MIA) are a key method for this kind of
evaluation, however time-series prediction models have not been thoroughly
studied in this context. We explore existing MIA techniques on time-series
models, and introduce new features, focusing on the seasonality and trend
components of the data. Seasonality is estimated using a multivariate Fourier
transform, and a low-degree polynomial is used to approximate trends. We
applied these techniques to various types of time-series models, using datasets
from the health domain. Our results demonstrate that these new features enhance
the effectiveness of MIAs in identifying membership, improving the
understanding of privacy risks in medical data applications.

摘要：分析可能包含个人信息的時間序列資料，特別是在醫療領域，會引發嚴重的隱私問題。病患的敏感健康資料經常被用於訓練機器學習模型，以進行診斷和持續照護。評估此類模型的隱私風險，對於在生產中使用模型、與第三方分享，或在病患家中部署模型時做出明智的決定至關重要。成員推論攻擊 (MIA) 是進行此類評估的一種關鍵方法，然而，在此背景下尚未徹底研究時序預測模型。我們探討了時序模型上現有的 MIA 技術，並引入了新的功能，重點關注資料的季節性和趨勢組成。季節性使用多變數傅立葉轉換來估計，低次多項式用於近似趨勢。我們將這些技術應用於各種類型的時序模型，使用來自健康領域的資料集。我們的結果表明，這些新功能增強了 MIA 在識別成員資格方面的效能，進而提升了對醫療資料應用中隱私風險的理解。

##### **Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**
2407.02821v1 by Negin Ashrafi, Armin Abdollahi, Greg Placencia, Maryam Pishgar

Predicting critical health outcomes such as patient mortality and hospital
readmission is essential for improving survivability. However, healthcare
datasets have many concurrences that create complexities, leading to poor
predictions. Consequently, pre-processing the data is crucial to improve its
quality. In this study, we use an existing pre-processing algorithm,
concatenation, to improve data quality by decreasing the complexity of
datasets. Sixteen healthcare datasets were extracted from two databases - MIMIC
III and University of Illinois Hospital - converted to the event logs, they
were then fed into the concatenation algorithm. The pre-processed event logs
were then fed to the Split Miner (SM) algorithm to produce a process model.
Process model quality was evaluated before and after concatenation using the
following metrics: fitness, precision, F-Measure, and complexity. The
pre-processed event logs were also used as inputs to the Decay Replay Mining
(DREAM) algorithm to predict critical outcomes. We compared predicted results
before and after applying the concatenation algorithm using Area Under the
Curve (AUC) and Confidence Intervals (CI). Results indicated that the
concatenation algorithm improved the quality of the process models and
predictions of the critical health outcomes.

摘要：預測病患死亡率和醫院再入院等重大的健康結果，對於提升存活率至關重要。然而，醫療保健資料集有許多同時發生的事件，會造成複雜性，導致預測不佳。因此，預先處理資料對於提升資料品質至關重要。在本研究中，我們使用現有的預先處理演算法，連接，藉由降低資料集的複雜性來提升資料品質。從兩個資料庫中萃取出十六個醫療保健資料集 - MIMIC III 和伊利諾大學醫院 - 轉換成事件記錄，然後將其輸入連接演算法。接著將預先處理的事件記錄輸入 Split Miner (SM) 演算法，以產生流程模型。使用以下指標評估連接前後的流程模型品質：適用性、精確度、F-量測和複雜性。預先處理的事件記錄也用作衰減重播探勘 (DREAM) 演算法的輸入，以預測重大的結果。我們使用曲線下面積 (AUC) 和信心區間 (CI) 比較套用連接演算法前後的預測結果。結果顯示連接演算法提升了流程模型的品質和對重大健康結果的預測。

##### **MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**
2407.02730v1 by Zishan Gu, Changchang Yin, Fenglin Liu, Ping Zhang

Large Vision Language Models (LVLMs) have recently achieved superior
performance in various tasks on natural image and text data, which inspires a
large amount of studies for LVLMs fine-tuning and training. Despite their
advancements, there has been scant research on the robustness of these models
against hallucination when fine-tuned on smaller datasets. In this study, we
introduce a new benchmark dataset, the Medical Visual Hallucination Test
(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH
comprises five tasks to evaluate hallucinations in LVLMs within the medical
context, which includes tasks for comprehensive understanding of textual and
visual input, as well as long textual response generation. Our extensive
experiments with both general and medical LVLMs reveal that, although medical
LVLMs demonstrate promising performance on standard medical tasks, they are
particularly susceptible to hallucinations, often more so than the general
models, raising significant concerns about the reliability of these
domain-specific models. For medical LVLMs to be truly valuable in real-world
applications, they must not only accurately integrate medical knowledge but
also maintain robust reasoning abilities to prevent hallucination. Our work
paves the way for future evaluations of these studies.

摘要：大型視覺語言模型 (LVLMs) 最近在自然影像和文字資料的各種任務中取得了卓越的表現，這激勵了大量的研究進行 LVLMs 的微調和訓練。儘管它們進步了，但對於在較小的資料集上微調時，這些模型對幻覺的魯棒性卻鮮有研究。在這項研究中，我們引入了新的基準資料集，即醫學視覺幻覺測試 (MedVH)，以評估特定領域 LVLMs 的幻覺。MedVH 包含五項任務，用於評估醫學背景下 LVLMs 中的幻覺，其中包括全面理解文字和視覺輸入的任務，以及長文字回應生成。我們對一般和醫學 LVLMs 進行的廣泛實驗表明，儘管醫學 LVLMs 在標準醫學任務上表現出令人滿意的表現，但它們特別容易產生幻覺，通常比一般模型更容易產生幻覺，這引起了對這些特定領域模型的可靠性的重大疑慮。為了讓醫學 LVLMs 在現實世界的應用中真正有價值，它們不僅必須準確整合醫學知識，還必須具備強大的推理能力以防止幻覺。我們的研究為未來對這些研究的評估鋪平了道路。

##### **D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**
2407.02604v1 by Hareem Nisar, Syed Muhammad Anwar, Zhifan Jiang, Abhijeet Parida, Vishwesh Nath, Holger R. Roth, Marius George Linguraru

Large vision language models (VLMs) have progressed incredibly from research
to applicability for general-purpose use cases. LLaVA-Med, a pioneering large
language and vision assistant for biomedicine, can perform multi-modal
biomedical image and data analysis to provide a natural language interface for
radiologists. While it is highly generalizable and works with multi-modal data,
it is currently limited by well-known challenges that exist in the large
language model space. Hallucinations and imprecision in responses can lead to
misdiagnosis which currently hinder the clinical adaptability of VLMs. To
create precise, user-friendly models in healthcare, we propose D-Rax -- a
domain-specific, conversational, radiologic assistance tool that can be used to
gain insights about a particular radiologic image. In this study, we enhance
the conversational analysis of chest X-ray (CXR) images to support radiological
reporting, offering comprehensive insights from medical imaging and aiding in
the formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the
LLaVA-Med architecture on our curated enhanced instruction-following data,
comprising of images, instructions, as well as disease diagnosis and
demographic predictions derived from MIMIC-CXR imaging data, CXR-related visual
question answer (VQA) pairs, and predictive outcomes from multiple expert AI
models. We observe statistically significant improvement in responses when
evaluated for both open and close-ended conversations. Leveraging the power of
state-of-the-art diagnostic models combined with VLMs, D-Rax empowers
clinicians to interact with medical images using natural language, which could
potentially streamline their decision-making process, enhance diagnostic
accuracy, and conserve their time.

摘要：大型視覺語言模型（VLM）已從研究進展到可適用於一般用途案例。LLaVA-Med 是一個開創性的生物醫學大型語言和視覺助理，可以執行多模態生物醫學影像和資料分析，為放射科醫師提供自然語言介面。儘管它具有高度的概括性，並且適用於多模態資料，但目前受到大型語言模型空間中眾所周知挑戰的限制。回應中的幻覺和不精確可能會導致誤診，這會阻礙 VLM 的臨床適應性。為了在醫療保健中建立精確、使用者友善的模型，我們提出了 D-Rax——一種特定於領域的對話式放射協助工具，可用於深入了解特定放射影像。在這項研究中，我們增強了胸部 X 光（CXR）影像的對話式分析，以支援放射報告，從醫學影像中提供全面的見解，並協助制定準確的診斷。D-Rax 是透過微調 LLaVA-Med 架構在我們整理的增強式指令遵循資料上實現的，包括影像、指令，以及從 MIMIC-CXR 影像資料、CXR 相關視覺問答（VQA）配對和多個專家 AI 模型的預測結果中得出的疾病診斷和人口統計預測。我們觀察到，在針對開放式和封閉式對話進行評估時，回應有顯著的統計改善。透過結合最先進的診斷模型和 VLM 的力量，D-Rax 使臨床醫生能夠使用自然語言與醫學影像互動，這可能會簡化他們的決策過程、提高診斷準確性並節省他們的時間。

##### **MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**
2407.02483v1 by Binxu Li, Tiankai Yan, Yuanting Pan, Zhe Xu, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang

Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks, enabling the agent to
choose the most suitable tools for a given task. Comprehensive experiments
demonstrate that MMedAgent achieves superior performance across a variety of
medical tasks compared to state-of-the-art open-source methods and even the
closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in
updating and integrating new medical tools.

摘要：儘管多模態大型語言模型 (MLLM) 成功，但其普遍性有限，與專用模型相比時常有所不足。
最近，基於 LLM 的代理已被開發出來，以透過根據使用者輸入選擇適當的專用模型作為工具來解決這些挑戰。
然而，此類進展尚未在醫療領域中廣泛探討。為了彌補此差距，本文介紹了第一個專門為醫療領域設計的代理，名為**M**ulti-modal **Med**ical **Agent** (MMedAgent)。我們整理了一個由六種解決七項任務的醫療工具組成的指令調整資料集，讓代理能夠為特定任務選擇最合適的工具。全面的實驗證明，與最先進的開源方法，甚至閉源模型 GPT-4o 相比，MMedAgent 在各種醫療任務中都取得了優異的表現。此外，MMedAgent 在更新和整合新的醫療工具方面展現出效率。

##### **CALICO: Confident Active Learning with Integrated Calibration**
2407.02335v1 by Lorenzo S. Querol, Hajime Nagahara, Hideaki Hayashi

The growing use of deep learning in safety-critical applications, such as
medical imaging, has raised concerns about limited labeled data, where this
demand is amplified as model complexity increases, posing hurdles for domain
experts to annotate data. In response to this, active learning (AL) is used to
efficiently train models with limited annotation costs. In the context of deep
neural networks (DNNs), AL often uses confidence or probability outputs as a
score for selecting the most informative samples. However, modern DNNs exhibit
unreliable confidence outputs, making calibration essential. We propose an AL
framework that self-calibrates the confidence used for sample selection during
the training process, referred to as Confident Active Learning with Integrated
CalibratiOn (CALICO). CALICO incorporates the joint training of a classifier
and an energy-based model, instead of the standard softmax-based classifier.
This approach allows for simultaneous estimation of the input data distribution
and the class probabilities during training, improving calibration without
needing an additional labeled dataset. Experimental results showcase improved
classification performance compared to a softmax-based classifier with fewer
labeled samples. Furthermore, the calibration stability of the model is
observed to depend on the prior class distribution of the data.

摘要：深度學習在安全關鍵應用中使用日益廣泛，例如醫學影像，這引發了對標籤數據有限的擔憂，隨著模型複雜性的增加，這種需求會被放大，這對領域專家註解數據構成了障礙。為了應對這一問題，主動學習 (AL) 被用於以有限的註解成本有效地訓練模型。在深度神經網路 (DNN) 的背景下，AL 經常使用置信度或機率輸出作為選擇最有資訊性的樣本的分數。然而，現代 DNN 表現出不可靠的置信度輸出，這使得校準至關重要。我們提出了一個 AL 框架，它會在訓練過程中自行校準用於樣本選擇的置信度，稱為具有整合校準的自信主動學習 (CALICO)。CALICO 結合了分類器和基於能量的模型的聯合訓練，而不是標準的基於 softmax 的分類器。這種方法允許在訓練期間同時估計輸入數據分佈和類別機率，從而改進校準，而無需額外的標籤數據集。實驗結果表明，與基於 softmax 的分類器相比，在標籤樣本較少的情況下，分類性能得到了改善。此外，觀察到模型的校準穩定性取決於數據的先驗類別分佈。

##### **A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**
2407.02283v1 by Minghao Zhou, Hong Wang, Yefeng Zheng, Deyu Meng

Feature upsampling is a fundamental and indispensable ingredient of almost
all current network structures for image segmentation tasks. Recently, a
popular similarity-based feature upsampling pipeline has been proposed, which
utilizes a high-resolution feature as guidance to help upsample the
low-resolution deep feature based on their local similarity. Albeit achieving
promising performance, this pipeline has specific limitations: 1) HR query and
LR key features are not well aligned; 2) the similarity between query-key
features is computed based on the fixed inner product form; 3) neighbor
selection is coarsely operated on LR features, resulting in mosaic artifacts.
These shortcomings make the existing methods along this pipeline primarily
applicable to hierarchical network architectures with iterative features as
guidance and they are not readily extended to a broader range of structures,
especially for a direct high-ratio upsampling. Against the issues, we
meticulously optimize every methodological design. Specifically, we firstly
propose an explicitly controllable query-key feature alignment from both
semantic-aware and detail-aware perspectives, and then construct a
parameterized paired central difference convolution block for flexibly
calculating the similarity between the well-aligned query-key features.
Besides, we develop a fine-grained neighbor selection strategy on HR features,
which is simple yet effective for alleviating mosaic artifacts. Based on these
careful designs, we systematically construct a refreshed similarity-based
feature upsampling framework named ReSFU. Extensive experiments substantiate
that our proposed ReSFU is finely applicable to various types of architectures
in a direct high-ratio upsampling manner, and consistently achieves
satisfactory performance on different segmentation applications, showing
superior generality and ease of deployment.

摘要：特徵上採樣是目前幾乎所有用於影像分割任務的網路結構中不可或缺的基本要素。最近，有人提出了一種基於相似度的特徵上採樣管道，它利用高解析度特徵作為指引，根據其局部相似度幫助上採樣低解析度深度特徵。儘管取得了有希望的效能，但此管道有特定的限制：1）HR 查詢和 LR 關鍵特徵未對齊；2）查詢鍵特徵之間的相似度是根據固定的內積形式計算的；3）鄰居選擇是粗略地對 LR 特徵進行操作，導致馬賽克偽影。這些缺點使得沿著此管道的現有方法主要適用於具有迭代特徵作為指引的分層網路架構，並且它們不容易擴充套件到更廣泛的結構，特別是對於直接的高比率上採樣。針對這些問題，我們仔細優化了每一個方法論設計。具體來說，我們首先提出了從語義感知和細節感知的角度進行明確可控的查詢鍵特徵對齊，然後構建一個參數化的配對中心差分卷積塊，以靈活地計算對齊良好的查詢鍵特徵之間的相似度。此外，我們在 HR 特徵上開發了一個細粒度的鄰居選擇策略，它對於減輕馬賽克偽影既簡單又有效。根據這些仔細的設計，我們系統地構建了一個名為 ReSFU 的更新的基於相似度的特徵上採樣框架。大量的實驗證實，我們提出的 ReSFU 精細地適用於各種類型的架構，採用直接的高比率上採樣方式，並且在不同的分割應用中始終如一地取得令人滿意的效能，展現出優越的通用性和易於部署性。

##### **FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**
2407.02280v2 by Yangyang Xiang, Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(i.e., low-quality data), with a focus on mitigating their adverse effects. We
begin by evaluating the completeness of annotations at the client level using a
designed indicator. Subsequently, we enhance the influence of clients with more
comprehensive annotations and implement corrections for incomplete ones,
thereby ensuring that models are trained on accurate data. Our method's
effectiveness is validated through its superior performance on two extensively
used medical image segmentation datasets, outperforming existing solutions. The
code is available at https://github.com/HUSTxyy/FedIA.

摘要：联邦学习已成为医学图像分割中一种引人注目的范例，尤其是在隐私问题日益受到关注的情况下。然而，现有的大多数研究都依赖于关于跨客户端注释一致性和完整性的相对严格的假设。与此相反，本文重点介绍了医学实践中普遍存在的挑战：不完整的注释。此类注释可能会引入错误标记的像素，从而可能损害神经网络在监督学习中的性能。为了解决这个问题，我们引入了一种名为 FedIA 的新颖解决方案。我们的见解是将不完整的注释概念化为噪声数据（即低质量数据），重点在于减轻其不利影响。我们首先使用设计的指标评估客户端级别的注释完整性。随后，我们增强了具有更全面注释的客户端的影响力，并对不完整的注释实施了更正，从而确保模型在准确的数据上进行训练。我们方法的有效性通过其在两个广泛使用的医学图像分割数据集上的卓越性能得到验证，优于现有的解决方案。代码可在 https://github.com/HUSTxyy/FedIA 获得。

##### **Generative Monoculture in Large Language Models**
2407.02209v1 by Fan Wu, Emily Black, Varun Chandrasekaran

We introduce {\em generative monoculture}, a behavior observed in large
language models (LLMs) characterized by a significant narrowing of model output
diversity relative to available training data for a given task: for example,
generating only positive book reviews for books with a mixed reception. While
in some cases, generative monoculture enhances performance (e.g., LLMs more
often produce efficient code), the dangers are exacerbated in others (e.g.,
LLMs refuse to share diverse opinions). As LLMs are increasingly used in
high-impact settings such as education and web search, careful maintenance of
LLM output diversity is essential to ensure a variety of facts and perspectives
are preserved over time. We experimentally demonstrate the prevalence of
generative monoculture through analysis of book review and code generation
tasks, and find that simple countermeasures such as altering sampling or
prompting strategies are insufficient to mitigate the behavior. Moreover, our
results suggest that the root causes of generative monoculture are likely
embedded within the LLM's alignment processes, suggesting a need for developing
fine-tuning paradigms that preserve or promote diversity.

摘要：<paragraph>我們介紹了「生成單一文化」，這是一種在大型語言模型 (LLM) 中觀察到的行為，其特徵是模型輸出多樣性相對於給定任務的可用訓練資料顯著變窄：例如，只為評價褒貶不一的書籍生成正面的書評。雖然在某些情況下，生成單一文化會增強效能（例如，LLM 更常產生高效的程式碼），但其危險性在其他情況下會加劇（例如，LLM 拒絕分享不同的意見）。由於 LLM 愈來愈多地用於教育和網路搜尋等高影響力的環境中，仔細維護 LLM 輸出的多樣性對於確保隨著時間推移，各種事實和觀點都能被保留下來至關重要。我們透過分析書評和程式碼生成任務，以實驗方式證明了生成單一文化的普遍性，並發現簡單的對策，例如改變抽樣或提示策略，不足以減輕這種行為。此外，我們的結果表明，生成單一文化的根本原因可能存在於 LLM 的比對過程中，這表明需要開發能保留或促進多樣性的微調範例。</paragraph>

##### **Abstract Dialectical Frameworks are Boolean Networks (full version)**
2407.02055v1 by Jesse Heyninck, Matthias Knorr, João Leite

Dialectical frameworks are a unifying model of formal argumentation, where
argumentative relations between arguments are represented by assigning
acceptance conditions to atomic arguments. Their generality allow them to cover
a number of different approaches with varying forms of representing the
argumentation structure. Boolean regulatory networks are used to model the
dynamics of complex biological processes, taking into account the interactions
of biological compounds, such as proteins or genes. These models have proven
highly useful for comprehending such biological processes, allowing to
reproduce known behaviour and testing new hypotheses and predictions in silico,
for example in the context of new medical treatments. While both these
approaches stem from entirely different communities, it turns out that there
are striking similarities in their appearence. In this paper, we study the
relation between these two formalisms revealing their communalities as well as
their differences, and introducing a correspondence that allows to establish
novel results for the individual formalisms.

摘要：辯證框架是形式論證的統一模型，其中論證之間的論證關係是透過指派接受條件給原子論證來表示。它們的普遍性允許它們涵蓋許多不同的方法，並以不同的形式表示論證結構。布林法規網路用於模擬複雜生物過程的動態，考量生物化合物（例如蛋白質或基因）的交互作用。這些模型已被證明對於理解此類生物過程非常有用，允許複製已知的行為並在電腦模擬中測試新的假設和預測，例如在新的醫療治療的背景下。儘管這兩種方法完全來自不同的社群，但事實證明它們的外觀有驚人的相似性。在本文中，我們研究這兩種形式主義之間的關係，揭示它們的共性以及它們的差異，並引入一種對應關係，允許為個別形式主義建立新的結果。

##### **A Method to Facilitate Membership Inference Attacks in Deep Learning Models**
2407.01919v1 by Zitao Chen, Karthik Pattabiraman

Modern machine learning (ML) ecosystems offer a surging number of ML
frameworks and code repositories that can greatly facilitate the development of
ML models. Today, even ordinary data holders who are not ML experts can apply
off-the-shelf codebase to build high-performance ML models on their data, many
of which are sensitive in nature (e.g., clinical records).
  In this work, we consider a malicious ML provider who supplies model-training
code to the data holders, does not have access to the training process, and has
only black-box query access to the resulting model. In this setting, we
demonstrate a new form of membership inference attack that is strictly more
powerful than prior art. Our attack empowers the adversary to reliably
de-identify all the training samples (average >99% attack TPR@0.1% FPR), and
the compromised models still maintain competitive performance as their
uncorrupted counterparts (average <1% accuracy drop). Moreover, we show that
the poisoned models can effectively disguise the amplified membership leakage
under common membership privacy auditing, which can only be revealed by a set
of secret samples known by the adversary.
  Overall, our study not only points to the worst-case membership privacy
leakage, but also unveils a common pitfall underlying existing privacy auditing
methods, which calls for future efforts to rethink the current practice of
auditing membership privacy in machine learning models.

摘要：現代機器學習 (ML) 生態系統提供了大量的 ML 框架和程式碼儲存庫，可以極大地促進 ML 模型的開發。如今，即使不是 ML 專家的普通資料持有者也可以套用現成的程式碼庫，根據其資料建立高性能 ML 模型，其中許多資料本質上很敏感（例如：臨床紀錄）。
  在這項工作中，我們考慮了一個惡意的 ML 提供者，他向資料持有者提供模型訓練程式碼，無法存取訓練程序，而且只能透過黑盒子查詢存取產生的模型。在此設定中，我們展示了一種新的成員推論攻擊形式，它比先前的技術更強大。我們的攻擊讓對手能夠可靠地取消識別所有訓練範例（平均 >99% 攻擊 TPR@0.1% FPR），而且受損的模型仍然保持與未受損的模型一樣的競爭力（平均 <1% 準確度下降）。此外，我們展示了中毒的模型可以有效地隱藏在常見成員隱私稽核下的擴增成員洩漏，這只能由對手知道的秘密範例集揭露。
  總的來說，我們的研究不僅指出最壞情況的成員隱私洩漏，還揭示了現有隱私稽核方法中的一個常見陷阱，這需要未來的努力來重新思考目前在機器學習模型中稽核成員隱私的做法。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**
2407.01705v1 by Sebastian A. Cruz Romero, Ivanelyz Rivera de Jesus, Dariana J. Troche Quinones, Wilson Rivera Gallego

X-ray image-based disease diagnosis lies in ensuring the precision of
identifying afflictions within the sample, a task fraught with challenges
stemming from the occurrence of false positives and false negatives. False
positives introduce the risk of erroneously identifying non-existent
conditions, leading to misdiagnosis and a decline in patient care quality.
Conversely, false negatives pose the threat of overlooking genuine
abnormalities, potentially causing delays in treatment and interventions,
thereby resulting in adverse patient outcomes. The urgency to overcome these
challenges compels ongoing efforts to elevate the precision and reliability of
X-ray image analysis algorithms within the computational framework. This study
introduces modified pre-trained ResNet models tailored for multi-class disease
diagnosis of X-ray images, incorporating advanced optimization strategies to
reduce the execution runtime of training and inference tasks. The primary
objective is to achieve tangible performance improvements through accelerated
implementations of PyTorch, CUDA, Mixed- Precision Training, and Learning Rate
Scheduler. While outcomes demonstrate substantial improvements in execution
runtimes between normal training and CUDA-accelerated training, negligible
differences emerge between various training optimization modalities. This
research marks a significant advancement in optimizing computational approaches
to reduce training execution time for larger models. Additionally, we explore
the potential of effective parallel data processing using MPI4Py for the
distribution of gradient descent optimization across multiple nodes and
leverage multiprocessing to expedite data preprocessing for larger datasets.

摘要：X 光影像疾病診斷在於確保識別樣本中疾病的精確性，這項任務充滿了挑戰，源自於假陽性和假陰性的發生。假陽性會帶來錯誤識別不存在的疾病的風險，導致誤診和患者照護品質下降。相反地，假陰性會帶來忽略真正異常的威脅，可能會導致治療和介入延誤，從而導致患者預後不良。克服這些挑戰的迫切性促使持續努力提升計算架構中 X 光影像分析演算法的精確度和可靠性。本研究引入了針對 X 光影像的多類疾病診斷量身打造的修改後預先訓練的 ResNet 模型，並結合先進的最佳化策略以減少訓練和推論任務的執行執行時間。主要目標是透過加速實作 PyTorch、CUDA、混合精度訓練和學習率排程器，來達成具體的效能提升。雖然結果顯示正常訓練和 CUDA 加速訓練之間的執行執行時間有大幅改善，但各種訓練最佳化模式之間的差異可以忽略不計。這項研究標誌著最佳化計算方法以減少較大型模型訓練執行時間的重大進展。此外，我們探索使用 MPI4Py 進行有效平行資料處理的可能性，以在多個節點上進行梯度下降最佳化，並利用多處理來加速較大型資料集的資料前處理。

##### **Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**
2407.01318v1 by Ana Carolina Alves, André Ferreira, Behrus Puladi, Jan Egger, Victor Alves

The development of magnetic resonance imaging (MRI) for medical imaging has
provided a leap forward in diagnosis, providing a safe, non-invasive
alternative to techniques involving ionising radiation exposure for diagnostic
purposes. It was described by Block and Purcel in 1946, and it was not until
1980 that the first clinical application of MRI became available. Since that
time the MRI has gone through many advances and has altered the way diagnosing
procedures are performed. Due to its ability to improve constantly, MRI has
become a commonly used practice among several specialisations in medicine.
Particularly starting 0.55T and 7T MRI technologies have pointed out enhanced
preservation of image detail and advanced tissue characterisation. This review
examines the integration of deep learning (DL) techniques into these MRI
modalities, disseminating and exploring the study applications. It highlights
how DL contributes to 0.55T and 7T MRI data, showcasing the potential of DL in
improving and refining these technologies. The review ends with a brief
overview of how MRI technology will evolve in the coming years.

摘要：磁共振成像 (MRI) 在医学影像上的發展，為診斷技術帶來重大進展，提供一種安全、非侵入性的替代方案，以取代使用電離輻射進行診斷的技術。此技術由布洛克與珀塞爾於 1946 年提出，直到 1980 年，MRI 才首次應用於臨床。自那時起，MRI 經歷了許多進步，並改變了診斷程序的執行方式。由於 MRI 能持續改進，因此已成為醫學中多種專科的常用技術。特別是從 0.55T 和 7T MRI 技術開始，已指出增強影像細節的保存和進階組織表徵。本篇評論探討深度學習 (DL) 技術整合到這些 MRI 模式中，傳播並探討研究應用。它強調 DL 如何貢獻於 0.55T 和 7T MRI 資料，展示 DL 在改善和精進這些技術的潛力。本評論最後簡要概述 MRI 技術在未來幾年的發展方式。

##### **MIRAI: Evaluating LLM Agents for Event Forecasting**
2407.01231v1 by Chenchen Ye, Ziniu Hu, Yihe Deng, Zijie Huang, Mingyu Derek Ma, Yanqiao Zhu, Wei Wang

Recent advancements in Large Language Models (LLMs) have empowered LLM agents
to autonomously collect world information, over which to conduct reasoning to
solve complex problems. Given this capability, increasing interests have been
put into employing LLM agents for predicting international events, which can
influence decision-making and shape policy development on an international
scale. Despite such a growing interest, there is a lack of a rigorous benchmark
of LLM agents' forecasting capability and reliability. To address this gap, we
introduce MIRAI, a novel benchmark designed to systematically evaluate LLM
agents as temporal forecasters in the context of international events. Our
benchmark features an agentic environment with tools for accessing an extensive
database of historical, structured events and textual news articles. We refine
the GDELT event database with careful cleaning and parsing to curate a series
of relational prediction tasks with varying forecasting horizons, assessing LLM
agents' abilities from short-term to long-term forecasting. We further
implement APIs to enable LLM agents to utilize different tools via a code-based
interface. In summary, MIRAI comprehensively evaluates the agents' capabilities
in three dimensions: 1) autonomously source and integrate critical information
from large global databases; 2) write codes using domain-specific APIs and
libraries for tool-use; and 3) jointly reason over historical knowledge from
diverse formats and time to accurately predict future events. Through
comprehensive benchmarking, we aim to establish a reliable framework for
assessing the capabilities of LLM agents in forecasting international events,
thereby contributing to the development of more accurate and trustworthy models
for international relation analysis.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展賦予了 LLM 代理自主收集世界資訊的能力，並基於這些資訊進行推理以解決複雜問題。鑑於此功能，將 LLM 代理用於預測國際事件的興趣日益濃厚，這可能會影響決策制定並在國際層面上塑造政策發展。儘管有如此濃厚的興趣，但缺乏對 LLM 代理預測能力和可靠性的嚴格基準。為了解決這一差距，我們引入了 MIRAI，這是一個新基準，旨在系統地評估 LLM 代理作為國際事件時間預測者的能力。我們的基準特點是提供一個代理環境，其中包含訪問大量歷史結構化事件和文字新聞文章的工具。我們通過仔細清理和解析 GDELT 事件資料庫，策劃了一系列具有不同預測範圍的關係預測任務，評估 LLM 代理從短期到長期預測的能力。我們進一步實作 API，使 LLM 代理能夠透過基於程式碼的介面使用不同的工具。總之，MIRAI 全面評估了代理在三個維度上的能力：1) 自主地從大型全球資料庫中獲取和整合關鍵資訊；2) 使用特定領域的 API 和程式庫編寫程式碼以使用工具；3) 共同推理來自不同格式和時間的歷史知識，以準確預測未來事件。透過全面的基準測試，我們旨在建立一個可靠的框架，用於評估 LLM 代理在預測國際事件方面的能力，從而為國際關係分析的更準確和值得信賴的模型的開發做出貢獻。</paragraph>

##### **Integrated feature analysis for deep learning interpretation and class activation maps**
2407.01142v1 by Yanli Li, Tahereh Hassanzadeh, Denis P. Shamonin, Monique Reijnierse, Annette H. M. van der Helm-van Mil, Berend C. Stoel

Understanding the decisions of deep learning (DL) models is essential for the
acceptance of DL to risk-sensitive applications. Although methods, like class
activation maps (CAMs), give a glimpse into the black box, they do miss some
crucial information, thereby limiting its interpretability and merely providing
the considered locations of objects. To provide more insight into the models
and the influence of datasets, we propose an integrated feature analysis
method, which consists of feature distribution analysis and feature
decomposition, to look closer into the intermediate features extracted by DL
models. This integrated feature analysis could provide information on
overfitting, confounders, outliers in datasets, model redundancies and
principal features extracted by the models, and provide distribution
information to form a common intensity scale, which are missing in current CAM
algorithms. The integrated feature analysis was applied to eight different
datasets for general validation: photographs of handwritten digits, two
datasets of natural images and five medical datasets, including skin
photography, ultrasound, CT, X-rays and MRIs. The method was evaluated by
calculating the consistency between the CAMs average class activation levels
and the logits of the model. Based on the eight datasets, the correlation
coefficients through our method were all very close to 100%, and based on the
feature decomposition, 5%-25% of features could generate equally informative
saliency maps and obtain the same model performances as using all features.
This proves the reliability of the integrated feature analysis. As the proposed
methods rely on very few assumptions, this is a step towards better model
interpretation and a useful extension to existing CAM algorithms. Codes:
https://github.com/YanliLi27/IFA

摘要：<paragraph>了解深度學習（DL）模型的決策對於風險敏感應用程式接受 DL 至關重要。儘管方法（如類別激勵映射 (CAM)）讓黑盒子得以一窺究竟，但它們仍遺漏了一些關鍵資訊，因而限制了解釋能力，僅提供物件被考慮的位置。為了更深入瞭解模型和資料集的影響，我們提出了一種整合特徵分析方法，包括特徵分佈分析和特徵分解，以更仔細地檢視 DL 模型提取的中間特徵。這種整合特徵分析可以提供有關過度擬合、混淆變數、資料集中的異常值、模型冗餘和模型提取的主要特徵的資訊，並提供分佈資訊以形成共同的強度量表，這是目前 CAM 演算法所缺少的。整合特徵分析已應用於八個不同的資料集以進行一般驗證：手寫數字照片、兩個自然影像資料集和五個醫學資料集，包括皮膚攝影、超音波、電腦斷層掃描、X 光和 MRI。該方法透過計算 CAM 平均類別激勵層級與模型的 logit 值之間的一致性來評估。根據這八個資料集，我們的方法得出的相關係數都非常接近 100%，根據特徵分解，5%-25% 的特徵可以產生同樣具有資訊性的顯著性圖，並獲得與使用所有特徵相同的模型效能。這證明了整合特徵分析的可靠性。由於所提出的方法依賴的假設很少，因此這是朝向更好的模型解釋邁出的一步，也是對現有 CAM 演算法有用的延伸。程式碼：https://github.com/YanliLi27/IFA</paragraph>

##### **An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**
2407.03374v1 by Laifa Tao, Shangyu Li, Haifei Liu, Qixuan Huang, Liang Ma, Guoao Ning, Yiling Chen, Yunlong Wu, Bin Li, Weiwei Zhang, Zhengduo Zhao, Wenchao Zhan, Wenyan Cao, Chao Wang, Hongmei Liu, Jian Ma, Mingliang Suo, Yujie Cheng, Yu Ding, Dengwei Song, Chen Lu

Prognosis and Health Management (PHM), critical for ensuring task completion
by complex systems and preventing unexpected failures, is widely adopted in
aerospace, manufacturing, maritime, rail, energy, etc. However, PHM's
development is constrained by bottlenecks like generalization, interpretation
and verification abilities. Presently, generative artificial intelligence (AI),
represented by Large Model, heralds a technological revolution with the
potential to fundamentally reshape traditional technological fields and human
production methods. Its capabilities, including strong generalization,
reasoning, and generative attributes, present opportunities to address PHM's
bottlenecks. To this end, based on a systematic analysis of the current
challenges and bottlenecks in PHM, as well as the research status and
advantages of Large Model, we propose a novel concept and three progressive
paradigms of Prognosis and Health Management Large Model (PHM-LM) through the
integration of the Large Model with PHM. Subsequently, we provide feasible
technical approaches for PHM-LM to bolster PHM's core capabilities within the
framework of the three paradigms. Moreover, to address core issues confronting
PHM, we discuss a series of technical challenges of PHM-LM throughout the
entire process of construction and application. This comprehensive effort
offers a holistic PHM-LM technical framework, and provides avenues for new PHM
technologies, methodologies, tools, platforms and applications, which also
potentially innovates design, research & development, verification and
application mode of PHM. And furthermore, a new generation of PHM with AI will
also capably be realized, i.e., from custom to generalized, from discriminative
to generative, and from theoretical conditions to practical applications.

摘要：預測與健康管理 (PHM) 對於確保複雜系統任務完成和防止意外故障至關重要，廣泛應用於航空、製造、海事、鐵路、能源等領域。然而，PHM 的發展受到泛化、解釋和驗證能力等瓶頸的制約。目前，以大模型為代表的生成式人工智慧 (AI) 預示著一場技術革命，有潛力從根本上重塑傳統技術領域和人類生產方式。其包括強泛化、推理和生成屬性在內的能力，為解決 PHM 的瓶頸提供了機會。為此，我們基於對 PHM 現有挑戰和瓶頸的系統分析，以及大模型的研究現狀和優勢，通過將大模型與 PHM 相結合，提出了預測與健康管理大模型 (PHM-LM) 的新概念和三個進步範例。隨後，我們在三個範例的框架內為 PHM-LM 提供了可行的技術方法，以加強 PHM 的核心能力。此外，為了解決 PHM 面臨的核心問題，我們在整個構建和應用過程中討論了 PHM-LM 的一系列技術挑戰。這項綜合工作提供了一個整體的 PHM-LM 技術框架，並為新的 PHM 技術、方法、工具、平台和應用程式提供了途徑，也可能創新 PHM 的設計、研發、驗證和應用模式。此外，還將能夠實現新一代具備 AI 的 PHM，即從客製化到泛化、從判別式到生成式，以及從理論條件到實際應用。

##### **Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**
2407.01003v2 by Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma

Foundation models pre-trained on large-scale data have been widely witnessed
to achieve success in various natural imaging downstream tasks.
Parameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models
to new domains by updating only a small portion of parameters in order to
reduce computational overhead. However, the effectiveness of these PEFT
methods, especially in cross-domain few-shot scenarios, e.g., medical image
analysis, has not been fully explored. In this work, we facilitate the study of
the performance of PEFT when adapting foundation models to medical image
classification tasks. Furthermore, to alleviate the limitations of prompt
introducing ways and approximation capabilities on Transformer architectures of
mainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)
method by embedding prompt tokens into the expanded channels. We also find that
there are anomalies in the feature space distribution of foundation models
during pre-training process, and prompt tuning can help mitigate this negative
impact. To explain this phenomenon, we also introduce a novel perspective to
understand prompt tuning: Prompt tuning is a distribution calibrator. And we
support it by analyzing patch-wise scaling and feature separation operations
contained in EPT. Our experiments show that EPT outperforms several
state-of-the-art fine-tuning methods by a significant margin on few-shot
medical image classification tasks, and completes the fine-tuning process
within highly competitive time, indicating EPT is an effective PEFT method. The
source code is available at github.com/zuwenqiang/EPT.

摘要：<paragraph>在大規模資料上預先訓練的基礎模型已被廣泛證明
在各種自然影像下游任務中取得成功。
參數有效微調 (PEFT) 方法旨在通過僅更新一小部分參數來適應基礎模型
到新網域，以減少運算開銷。然而，這些 PEFT 的有效性
方法，特別是在跨網域少次拍攝場景中，例如醫學影像
分析尚未得到充分探討。在這項工作中，我們促進了
研究 PEFT 在適應基礎模型到醫學影像時的效果
分類任務。此外，為了緩解提示的限制
在主流提示調整方法的 Transformer 架構上引入方式和近似能力，我們提出了嵌入式提示調整 (EPT)
方法是將提示代幣嵌入到擴展的通道中。我們還發現
在預訓練過程中，基礎模型的特徵空間分佈存在異常，並且提示調整可以幫助減輕這種負面
影響。為了解釋這種現象，我們還引入了一個新穎的觀點來
了解提示調整：提示調整是一個分佈校準器。我們
通過分析 EPT 中包含的補丁式縮放和特徵分離操作來支持它。我們的實驗表明，EPT 在少次拍攝中優於幾種最先進的微調方法
醫學影像分類任務的邊際，並在極具競爭力的時間內完成微調過程，表明 EPT 是一種有效的 PEFT 方法。
源代碼可在 github.com/zuwenqiang/EPT 中獲得。</paragraph>

##### **Individual brain parcellation: Review of methods, validations and applications**
2407.00984v1 by Chengyi Li, Shan Yu, Yue Cui

Individual brains vary greatly in morphology, connectivity and organization.
The applicability of group-level parcellations is limited by the rapid
development of precision medicine today because they do not take into account
the variation of parcels at the individual level. Accurate mapping of brain
functional regions at the individual level is pivotal for a comprehensive
understanding of the variations in brain function and behaviors, early and
precise identification of brain abnormalities, as well as personalized
treatments for neuropsychiatric disorders. With the development of neuroimaging
and machine learning techniques, studies on individual brain parcellation are
booming. In this paper, we offer an overview of recent advances in the
methodologies of individual brain parcellation, including optimization- and
learning-based methods. Comprehensive evaluation metrics to validate individual
brain mapping have been introduced. We also review the studies of how
individual brain mapping promotes neuroscience research and clinical medicine.
Finally, we summarize the major challenges and important future directions of
individualized brain parcellation. Collectively, we intend to offer a thorough
overview of individual brain parcellation methods, validations, and
applications, along with highlighting the current challenges that call for an
urgent demand for integrated platforms that integrate datasets, methods, and
validations.

摘要：各個大腦在形態、連接性和組織上差異極大。
群體層級的區塊化適用性受到當今精準醫療的快速發展所限制，因為它們沒有考慮到個體層級的區塊變異。在個體層級準確繪製大腦功能區域對於全面了解大腦功能和行為的變異、早期且精確地識別大腦異常，以及神經精神疾病的個人化治療至關重要。隨著神經影像和機器學習技術的發展，關於個別大腦區塊化的研究正在蓬勃發展。在本文中，我們概述了個別大腦區塊化方法學的最新進展，包括基於最佳化和學習的方法。已經引入了全面的評估指標來驗證個別大腦對應。我們還回顧了個別大腦對應如何促進神經科學研究和臨床醫學的研究。最後，我們總結了個別化大腦區塊化的主要挑戰和重要的未來方向。總的來說，我們打算對個別大腦區塊化方法、驗證和應用提供全面的概述，同時強調當前挑戰，這些挑戰迫切需要整合數據集、方法和驗證的整合平台。

##### **Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**
2407.00978v1 by Cheng Su, Jinbo Wen, Jiawen Kang, Yonghua Wang, Hudan Pan, M. Shamim Hossain

Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape. The advancement of generative
artificial intelligence has positioned Multi-modal Large Language Models
(MLLMs) as crucial tools for managing healthcare data. MLLMs can support
multi-modal inputs and generate diverse types of content by leveraging
large-scale training on vast amounts of multi-modal data. However, critical
challenges persist in developing medical MLLMs, including healthcare data
security and freshness issues, affecting the output quality of MLLMs. In this
paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered
medical MLLMs framework for healthcare data management. This framework
leverages a hierarchical cross-chain architecture to facilitate secure data
training. Moreover, it enhances the output quality of MLLMs through hybrid RAG,
which employs multi-modal metrics to filter various unimodal RAG results and
incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share fresh data, mitigating information asymmetry in data
sharing. Finally, we utilize a generative diffusion model-based reinforcement
learning algorithm to identify the optimal contract for efficient data sharing.
Numerical results demonstrate the effectiveness of the proposed schemes, which
achieve secure and efficient healthcare data management.

摘要：在快速變化的醫療保健領域中，安全數據管理和有效數據共享已變得至關重要。生成式人工智慧的進步已將多模態大型語言模型 (MLLM) 定位為管理醫療保健數據的關鍵工具。MLLM 可支援多模態輸入，並透過利用大量多模態數據進行大規模訓練來產生各種類型的內容。然而，在開發醫療 MLLM 時仍存在關鍵挑戰，包括醫療保健數據安全性與新穎性問題，影響 MLLM 的輸出品質。在本文中，我們提出一個由檢索增強生成 (RAG) 賦能的混合醫療 MLLM 框架，用於醫療保健數據管理。此框架利用階層式跨鏈架構，以利於安全數據訓練。此外，它透過混合 RAG 來提升 MLLM 的輸出品質，此方法採用多模態指標來過濾各種單模態 RAG 結果，並將這些檢索結果作為額外輸入納入 MLLM。此外，我們採用資訊年齡來間接評估 MLLM 的數據新穎性影響，並利用契約理論來激勵醫療保健數據持有者共享新穎數據，從而減輕數據共享中的資訊不對稱。最後，我們利用生成擴散模型為基礎的強化學習演算法，以找出最佳契約，以進行有效率的數據共享。數值結果證明所提出的架構有效，可達成安全且有效率的醫療保健數據管理。

##### **Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**
2407.01647v1 by Parviz Ghafariasl, Masoomeh Zeinalnezhad, Amir Ahmadishokooh

Timely alerts about hazardous air pollutants are crucial for public health.
However, existing forecasting models often overlook key factors like baseline
parameters and missing data, limiting their accuracy. This study introduces a
hybrid approach to address these issues, focusing on forecasting hourly PM2.5
concentrations using Support Vector Regression (SVR). Meta-heuristic
algorithms, Grey Wolf Optimization (GWO) and Particle Swarm Optimization (PSO),
optimize SVR Hyper-parameters "C" and "Gamma" to enhance prediction accuracy.
Evaluation metrics include R-squared (R2), Root Mean Square Error (RMSE), and
Mean Absolute Error (MAE). Results show significant improvements with PSO-SVR
(R2: 0.9401, RMSE: 0.2390, MAE: 0.1368) and GWO-SVR (R2: 0.9408, RMSE: 0.2376,
MAE: 0.1373), indicating robust and accurate models suitable for similar
research applications.

摘要：及時發布有關有害空氣污染物的警報對公共衛生至關重要。
然而，現有的預測模型通常會忽略基線參數和缺失資料等關鍵因素，從而限制了其準確性。本研究引入了一種混合方法來解決這些問題，重點關注使用支持向量回歸 (SVR) 預測每小時 PM2.5 濃度。元啟發式演算法、灰狼優化 (GWO) 和粒子群優化 (PSO) 優化 SVR 超參數「C」和「Gamma」以提高預測準確度。評估指標包括 R 平方 (R2)、均方根誤差 (RMSE) 和平均絕對誤差 (MAE)。結果顯示 PSO-SVR (R2：0.9401、RMSE：0.2390、MAE：0.1368) 和 GWO-SVR (R2：0.9408、RMSE：0.2376、MAE：0.1373) 有顯著改善，表明適用於類似研究應用程式的穩健且準確的模型。

##### **Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**
2407.00967v1 by Sepehr Salem Ghahfarokhi, Tyrell To, Julie Jorns, Tina Yen, Bing Yu, Dong Hye Ye

Data limitation is a significant challenge in applying deep learning to
medical images. Recently, the diffusion probabilistic model (DPM) has shown the
potential to generate high-quality images by converting Gaussian random noise
into realistic images. In this paper, we apply the DPM to augment the deep
ultraviolet fluorescence (DUV) image dataset with an aim to improve breast
cancer classification for intraoperative margin assessment. For classification,
we divide the whole surface DUV image into small patches and extract
convolutional features for each patch by utilizing the pre-trained ResNet.
Then, we feed them into an XGBoost classifier for patch-level decisions and
then fuse them with a regional importance map computed by Grad-CAM++ for whole
surface-level prediction. Our experimental results show that augmenting the
training dataset with the DPM significantly improves breast cancer detection
performance in DUV images, increasing accuracy from 93% to 97%, compared to
using Affine transformations and ProGAN.

摘要：資料限制是應用深度學習於醫學影像的一大挑戰。最近，擴散機率模型 (DPM) 已展現將高斯隨機雜訊轉換為逼真影像的潛力，用以產生高品質影像。在本文中，我們將 DPM 應用於擴充深度紫外螢光 (DUV) 影像資料集，目標是改善乳癌分類，用於術中邊緣評估。對於分類，我們將整個表面 DUV 影像分割成小區塊，並利用預訓練的 ResNet 為每個區塊萃取卷積特徵。接著，我們將它們輸入 XGBoost 分類器，用於區塊層級的決策，然後將它們與 Grad-CAM++ 計算出的區域重要性圖融合，用於整個表面層級的預測。我們的實驗結果顯示，使用 DPM 擴充訓練資料集可顯著提升 DUV 影像的乳癌偵測效能，與使用仿射轉換和 ProGAN 相比，準確率從 93% 提升至 97%。

##### **Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**
2407.00764v1 by Stefan Arnold, Rene Gröbner, Annika Schreiner

Differential Privacy (DP) can be applied to raw text by exploiting the
spatial arrangement of words in an embedding space. We investigate the
implications of such text privatization on Language Models (LMs) and their
tendency towards stereotypical associations. Since previous studies documented
that linguistic proficiency correlates with stereotypical bias, one could
assume that techniques for text privatization, which are known to degrade
language modeling capabilities, would cancel out undesirable biases. By testing
BERT models trained on texts containing biased statements primed with varying
degrees of privacy, our study reveals that while stereotypical bias generally
diminishes when privacy is tightened, text privatization does not uniformly
equate to diminishing bias across all social domains. This highlights the need
for careful diagnosis of bias in LMs that undergo text privatization.

摘要：差分隱私 (DP) 可透過利用嵌入空間中字詞的空間排列來應用於原始文字。我們探討這種文字私有化對語言模型 (LM) 及其對刻板印象關聯的傾向所造成的影響。由於先前的研究記錄語言能力與刻板印象偏誤相關，因此可以假設已知會降低語言建模能力的文字私有化技術會消除不良偏誤。透過測試在包含以不同程度隱私為前提的偏見陳述的文字上訓練的 BERT 模型，我們的研究顯示，雖然在加強隱私時刻板印象偏誤通常會減少，但文字私有化並非在所有社會領域都等於減少偏誤。這突顯了在經過文字私有化的 LM 中仔細診斷偏誤的必要性。

##### **Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**
2407.00752v1 by Peng Huang, Xue Gao, Lihong Huang, Jing Jiao, Xiaokang Li, Yuanyuan Wang, Yi Guo

Text-to-image generation has important implications for generation of diverse
and controllable images. Several attempts have been made to adapt Stable
Diffusion (SD) to the medical domain. However, the large distribution
difference between medical reports and natural texts, as well as high
computational complexity in common stable diffusion limit the authenticity and
feasibility of the generated medical images. To solve above problems, we
propose a novel light-weight transformer-based diffusion model learning
framework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion
employs a domain-specific text encoder to obtain accurate and expressive text
features to guide image generation, improving the authenticity of the generated
images. Meanwhile, we introduce a light-weight transformer architecture as the
denoising model, reducing the computational complexity of the diffusion model.
Experiments demonstrate that our Chest-Diffusion achieves the lowest FID score
24.456, under the computation budget of 118.918 GFLOPs, which is nearly
one-third of the computational complexity of SD.

摘要：文本到图像生成对于生成多样且可控的图像具有重要意义。已经做出了一些尝试来将 Stable Diffusion (SD) 调整到医学领域。然而，医学报告和自然文本之间存在较大的分布差异，以及常见的稳定扩散中的高计算复杂度限制了生成医学图像的真实性和可行性。为了解决上述问题，我们提出了一种新颖的轻量级基于 transformer 的扩散模型学习框架 Chest-Diffusion，用于报告到 CXR 生成。Chest-Diffusion 使用特定于领域的文本编码器来获取准确且富有表现力的文本特征以指导图像生成，从而提高生成图像的真实性。同时，我们引入了一个轻量级的 transformer 架构作为去噪模型，降低了扩散模型的计算复杂度。实验表明，我们的 Chest-Diffusion 在 118.918 GFLOP 的计算预算下实现了最低的 FID 分数 24.456，这几乎是 SD 计算复杂度的三分之一。

##### **Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**
2407.00731v1 by Qiuhao Lu, Rui Li, Andrew Wen, Jinlian Wang, Liwei Wang, Hongfang Liu

Large Language Models (LLMs) have revolutionized various sectors, including
healthcare where they are employed in diverse applications. Their utility is
particularly significant in the context of rare diseases, where data scarcity,
complexity, and specificity pose considerable challenges. In the clinical
domain, Named Entity Recognition (NER) stands out as an essential task and it
plays a crucial role in extracting relevant information from clinical texts.
Despite the promise of LLMs, current research mostly concentrates on
document-level NER, identifying entities in a more general context across
entire documents, without extracting their precise location. Additionally,
efforts have been directed towards adapting ChatGPT for token-level NER.
However, there is a significant research gap when it comes to employing
token-level NER for clinical texts, especially with the use of local
open-source LLMs. This study aims to bridge this gap by investigating the
effectiveness of both proprietary and local LLMs in token-level clinical NER.
Essentially, we delve into the capabilities of these models through a series of
experiments involving zero-shot prompting, few-shot prompting,
retrieval-augmented generation (RAG), and instruction-fine-tuning. Our
exploration reveals the inherent challenges LLMs face in token-level NER,
particularly in the context of rare diseases, and suggests possible
improvements for their application in healthcare. This research contributes to
narrowing a significant gap in healthcare informatics and offers insights that
could lead to a more refined application of LLMs in the healthcare sector.

摘要：大型語言模型 (LLM) 已徹底改變了各個領域，包括醫療保健，它們在其中被用於各種應用程式。它們的實用性在罕見疾病的背景下尤其重要，因為資料稀少、複雜且具特異性，對此構成相當大的挑戰。在臨床領域中，命名實體識別 (NER) 是一個重要的任務，在從臨床文本中擷取相關資訊方面扮演至關重要的角色。儘管 LLM 前景看好，但目前的研究大多集中在文件層級的 NER，在整個文件中識別更通用的背景中的實體，而不會擷取它們精確的位置。此外，已將精力投入於調整 ChatGPT 以進行代幣層級的 NER。然而，在使用代幣層級的 NER 來處理臨床文本時，特別是在使用本地的開源 LLM 時，存在重大的研究差距。本研究旨在透過探討專有和本地 LLM 在代幣層級臨床 NER 中的有效性來彌補此差距。基本上，我們透過一系列涉及零次提示、少次提示、檢索增強生成 (RAG) 和指令微調的實驗，深入探討這些模型的能力。我們的探索揭示了 LLM 在代幣層級 NER 中面臨的固有挑戰，特別是在罕見疾病的背景下，並建議了它們在醫療保健應用中可能的改進。本研究有助於縮小醫療保健資訊學中的一個重大差距，並提供可望導致在醫療保健領域更精緻地應用 LLM 的見解。

##### **SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**
2407.00664v1 by Zekang Yang, Hong Liu, Xiangdong Wang

Cancer survival prediction is a challenging task that involves analyzing of
the tumor microenvironment within Whole Slide Image (WSI). Previous methods
cannot effectively capture the intricate interaction features among instances
within the local area of WSI. Moreover, existing methods for cancer survival
prediction based on WSI often fail to provide better clinically meaningful
predictions. To overcome these challenges, we propose a Sparse Context-aware
Multiple Instance Learning (SCMIL) framework for predicting cancer survival
probability distributions. SCMIL innovatively segments patches into various
clusters based on their morphological features and spatial location
information, subsequently leveraging sparse self-attention to discern the
relationships between these patches with a context-aware perspective.
Considering many patches are irrelevant to the task, we introduce a learnable
patch filtering module called SoftFilter, which ensures that only interactions
between task-relevant patches are considered. To enhance the clinical relevance
of our prediction, we propose a register-based mixture density network to
forecast the survival probability distribution for individual patients. We
evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas
(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal
clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL
outperforms current state-of-the-art methods for survival prediction, offering
more clinically meaningful and interpretable outcomes. Our code is accessible
at https://github.com/yang-ze-kang/SCMIL.

摘要：癌症存活預測是一項艱鉅的任務，涉及分析全幻燈片影像 (WSI) 中的腫瘤微環境。先前的研究方法無法有效擷取 WSI 局部區域內實例之間的複雜互動特徵。此外，現有的基於 WSI 的癌症存活預測方法通常無法提供更有意義的臨床預測。為了克服這些挑戰，我們提出了一個稀疏上下文感知多實例學習 (SCMIL) 框架，用於預測癌症存活機率分佈。SCMIL 創新地根據形態特徵和空間位置資訊將區塊分割成各種叢集，隨後利用稀疏自注意力來辨別這些區塊之間的關係，並具備上下文感知觀點。考量到許多區塊與任務無關，我們引入了一個可學習的區塊過濾模組 SoftFilter，以確保僅考慮與任務相關區塊之間的互動。為了增強我們預測的臨床相關性，我們提出了一個基於註冊的混合密度網路，以預測個別患者的存活機率分佈。我們在兩個來自癌症基因圖譜 (TCGA) 的公共 WSI 資料集上評估 SCMIL，特別關注肺腺癌 (LUAD) 和腎透明細胞癌 (KIRC)。我們的實驗結果表明，SCMIL 在存活預測方面優於當前最先進的方法，提供了更有意義且可解釋的臨床結果。我們的程式碼可在 https://github.com/yang-ze-kang/SCMIL 取得。

##### **TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**
2407.00631v1 by Jintai Chen, Yaojun Hu, Yue Wang, Yingzhou Lu, Xu Cao, Miao Lin, Hongxia Xu, Jian Wu, Cao Xiao, Jimeng Sun, Lucas Glass, Kexin Huang, Marinka Zitnik, Tianfan Fu

Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.

摘要：臨床試驗對於開發新的醫療療法至關重要，但它們通常會帶來一些風險，例如患者死亡率、不良事件和註冊失敗，這些風險會浪費長達十年的巨大努力。將人工智慧 (AI) 應用於預測或模擬臨床試驗中的關鍵事件，對於提供見解以指導試驗設計具有巨大的潛力。然而，需要醫學專業知識和對試驗設計的深入了解的複雜數據收集和問題定義，迄今為止阻礙了 AI 的參與。本文通過提供一套全面的精心策劃的 AIready 數據集來應對這些挑戰，涵蓋多模式數據（例如，藥物分子、疾病代碼、文本、分類/數值特徵）和臨床試驗設計中的 8 項關鍵預測挑戰，包括預測試驗持續時間、患者輟學率、嚴重不良事件、死亡率、試驗批准結果、試驗失敗原因、藥物劑量發現、資格標準的設計。此外，我們為每個任務提供基本的驗證方法，以確保數據集的可用性和可靠性。我們預計這些開放訪問數據集的可用性將催化先進 AI 方法在臨床試驗設計中的開發，最終推進臨床試驗研究並加速醫療解決方案的開發。策展的數據集、指標和基本模型在 https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial 上公開提供。

##### **Answering real-world clinical questions using large language model based systems**
2407.00541v1 by Yen Sia Low, Michael L. Jackson, Rebecca J. Hyde, Robert E. Brown, Neil M. Sanghavi, Julian D. Baldwin, C. William Pike, Jananee Muralidharan, Gavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V. Nene, Morgan Pike, Courtney J. Pokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R. Zipursky, Christina Dinh, Philip Ballentine, Dan C. Derieg, Vladimir Polony, Rehan N. Chawdry, Jordan Davies, Brigham B. Hyde, Nigam H. Shah, Saurabh Gombar

Evidence to guide healthcare decisions is often limited by a lack of relevant
and trustworthy literature as well as difficulty in contextualizing existing
research for a specific patient. Large language models (LLMs) could potentially
address both challenges by either summarizing published literature or
generating new studies based on real-world data (RWD). We evaluated the ability
of five LLM-based systems in answering 50 clinical questions and had nine
independent physicians review the responses for relevance, reliability, and
actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,
Gemini Pro 1.5) rarely produced answers that were deemed relevant and
evidence-based (2% - 10%). In contrast, retrieval augmented generation
(RAG)-based and agentic LLM systems produced relevant and evidence-based
answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic
ChatRWD was able to answer novel questions compared to other LLMs (65% vs.
0-9%). These results suggest that while general-purpose LLMs should not be used
as-is, a purpose-built system for evidence summarization based on RAG and one
for generating novel evidence working synergistically would improve
availability of pertinent evidence for patient care.

摘要：醫療保健決策的指導證據通常受到缺乏相關且可信賴文獻的限制，以及難以將現有研究背景化以適用於特定患者。大型語言模型 (LLM) 潛在可透過摘要已發表的文獻或根據真實世界資料 (RWD) 產生新的研究來解決這兩個挑戰。我們評估了五個基於 LLM 的系統回答 50 個臨床問題的能力，並讓九位獨立的醫師檢視回應的相關性、可靠性，以及可行性。目前，通用 LLM（ChatGPT-4、Claude 3 Opus、Gemini Pro 1.5）很少產生被認為相關且基於證據的答案（2% - 10%）。相反地，基於檢索增強生成（RAG）和代理 LLM 系統產生的答案，有 24%（OpenEvidence）至 58%（ChatRWD）的問題是相關且基於證據的。與其他 LLM 相比，只有代理 ChatRWD 能夠回答新問題（65% 對 0-9%）。這些結果表明，雖然不應按原樣使用通用 LLM，但一個基於 RAG 的專門建置系統，用於證據摘要，以及一個用於產生新證據的系統，協同運作，將可改善與患者照護相關證據的可用性。

##### **Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**
2407.00538v1 by Kiarash Sedghighadikolaei, Attila A Yavuz

The shift towards efficient and automated data analysis through Machine
Learning (ML) has notably impacted healthcare systems, particularly Radiomics.
Radiomics leverages ML to analyze medical images accurately and efficiently for
precision medicine. Current methods rely on Deep Learning (DL) to improve
performance and accuracy (Deep Radiomics). Given the sensitivity of medical
images, ensuring privacy throughout the Deep Radiomics pipeline-from data
generation and collection to model training and inference-is essential,
especially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are
crucial tools for Deep Radiomics. Previous studies and systematization efforts
have either broadly overviewed PETs and their applications or mainly focused on
subsets of PETs for ML algorithms. In Deep Radiomics, where efficiency,
accuracy, and privacy are crucial, many PETs, while theoretically applicable,
may not be practical without specialized optimizations or hybrid designs.
Additionally, not all DL models are suitable for Radiomics. Consequently, there
is a need for specialized studies that investigate and systematize the
effective and practical integration of PETs into the Deep Radiomics pipeline.
This work addresses this research gap by (1) classifying existing PETs,
presenting practical hybrid PETS constructions, and a taxonomy illustrating
their potential integration with the Deep Radiomics pipeline, with comparative
analyses detailing assumptions, architectural suitability, and security, (2)
Offering technical insights, describing potential challenges and means of
combining PETs into the Deep Radiomics pipeline, including integration
strategies, subtilities, and potential challenges, (3) Proposing potential
research directions, identifying challenges, and suggesting solutions to
enhance the PETs in Deep Radiomics.

摘要：機器學習（ML）朝向高效且自動化的資料分析轉變，顯著影響了醫療保健系統，尤其是放射組學。放射組學利用機器學習精準且有效地分析醫學影像，以進行精準醫療。目前的技術仰賴深度學習（DL）來提升效能和準確度（深度放射組學）。考量到醫學影像的敏感性，確保在深度放射組學流程中（從資料產生和收集到模型訓練和推論）的隱私至關重要，特別是在外包時。因此，隱私強化技術（PET）是深度放射組學的關鍵工具。先前的研究和系統化工作，不是廣泛概述 PET 和其應用，就是主要關注 PET 在機器學習演算法中的子集。在深度放射組學中，效率、準確度和隱私至關重要，許多 PET 雖然理論上適用，但若沒有專門的最佳化或混合設計，可能不切實際。此外，並非所有深度學習模型都適合放射組學。因此，需要專門的研究，調查和系統化 PET 在深度放射組學流程中的有效且實際整合。這項工作透過（1）分類現有的 PET，提出實際的混合 PET 建構，以及一個說明其與深度放射組學流程潛在整合的分類法，並提供詳細說明假設、架構適用性和安全性，（2）提供技術見解，說明將 PET 整合到深度放射組學流程中的潛在挑戰和方法，包括整合策略、細微差別和潛在挑戰，（3）提出潛在的研究方向，找出挑戰，並建議解決方案，以強化深度放射組學中的 PET。

##### **Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**
2407.00531v1 by Hok-Shing Lau, Mark Huntly, Nathon Morgan, Adesua Iyenoma, Biao Zeng, Tim Bashford

Speech contains information that is clinically relevant to some diseases,
which has the potential to be used for health assessment. Recent work shows an
interest in applying deep learning algorithms, especially pretrained large
speech models to the applications of Automatic Speech Assessment. One question
that has not been explored is how these models output the results based on
their inputs. In this work, we train and compare two configurations of Audio
Spectrogram Transformer in the context of Voice Disorder Detection and apply
the attention rollout method to produce model relevance maps, the computed
relevance of the spectrogram regions when the model makes predictions. We use
these maps to analyse how models make predictions in different conditions and
to show that the spread of attention is reduced as a model is finetuned, and
the model attention is concentrated on specific phoneme regions.

摘要：语音包含一些疾病的临床相关信息，
这有潜力用于健康评估。最近的研究表明有兴趣应用深度学习算法，尤其是预训练的大型
语音模型用于自动语音评估的应用。一个尚未探索的问题是这些模型如何根据
其输入输出结果。在这项工作中，我们在语音障碍检测的背景下训练和比较了两个音频
频谱图转换器的配置，并应用注意力展开方法来生成模型相关性图，即模型做出预测时频谱图区域的计算相关性。我们使用
这些图来分析模型如何在不同条件下做出预测，并表明随着模型的微调，注意力的分布会减少，并且
模型注意力集中在特定的音素区域。

##### **ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**
2407.00499v1 by Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu

Uncertainty quantification (UQ) in natural language generation (NLG) tasks
remains an open challenge, exacerbated by the intricate nature of the recent
large language models (LLMs). This study investigates adapting conformal
prediction (CP), which can convert any heuristic measure of uncertainty into
rigorous theoretical guarantees by constructing prediction sets, for black-box
LLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure
leveraging self-consistency and develop a conformal uncertainty criterion by
integrating the uncertainty condition aligned with correctness into the design
of the CP algorithm. Experimental results indicate that our uncertainty measure
generally surpasses prior state-of-the-art methods. Furthermore, we calibrate
the prediction sets within the model's unfixed answer distribution and achieve
strict control over the correctness coverage rate across 6 LLMs on 4 free-form
NLG datasets, spanning general-purpose and medical domains, while the small
average set size further highlights the efficiency of our method in providing
trustworthy guarantees for practical open-ended NLG applications.

摘要：自然語言生成 (NLG) 任務中的不確定性量化 (UQ) 仍然是一個開放性的挑戰，最近大型語言模型 (LLM) 的複雜性質加劇了這一挑戰。本研究探討了適應共形預測 (CP)，它可以通過構造預測集將任何不確定性的啟發式測量轉換為嚴格的理論保證，用於開放式 NLG 任務中的黑盒 LLM。我們提出了一種基於抽樣的測量不確定性的方法，利用了自洽性，並通過將與正確性一致的不確定性條件整合到 CP 演算法的設計中，開發了一個共形不確定性準則。實驗結果表明，我們的測量不確定性的方法通常優於先前的最先進方法。此外，我們在模型的未固定答案分佈內校正了預測集，並在 4 個自由形式 NLG 資料集上對 6 個 LLM 的正確性覆蓋率進行了嚴格控制，涵蓋了通用和醫療領域，而較小的平均集合大小進一步突出了我們的方法在為實用的開放式 NLG 應用提供可信保證方面的效率。

##### **MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**
2407.00474v1 by Luyuan Xie, Manqing Lin, ChenMing Xu, Tianyu Luan, Zhipeng Zeng, Wenjun Qian, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.

摘要：在醫療人工智慧的應用演進中，聯邦學習因其保護訓練資料隱私的能力而備受矚目。聯邦學習促進協作模型開發，無需分享醫療保健機構的本地資料。然而，這些機構之間的統計和系統異質性帶來了重大的挑戰，影響了聯邦學習的有效性，並阻礙了客戶端之間的資訊交換。為了解決這些問題，我們提出了一種新的方法 MH-pFLGB，它採用全球旁路策略來減輕對公共資料集的依賴，並應對非 IID 資料分佈的複雜性。我們的模型透過整合一個全球旁路模型來增強傳統的聯邦學習，該模型將在客戶端之間共享資訊，但也作為網路的一部分來增強每個客戶端的效能。此外，MH-pFLGB 提供了一個特徵融合模組，以更好地結合本地和全球特徵。我們透過在不同的醫療任務上進行廣泛的測試來驗證模型的有效性和適應性，證明其效能優於現有的最先進方法。

##### **pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**
2407.00462v1 by Luyuan Xie, Manqing Lin, Siyuan Liu, ChenMing Xu, Tianyu Luan, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In medical image segmentation, personalized cross-silo federated learning
(FL) is becoming popular for utilizing varied data across healthcare settings
to overcome data scarcity and privacy concerns. However, existing methods often
suffer from client drift, leading to inconsistent performance and delayed
training. We propose a new framework, Personalized Federated Learning via
Feature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE
consists of two main stages: feature enhancement and supervised learning. The
first stage improves differentiation between foreground and background
features, and the second uses these enhanced features for learning from
segmentation masks. We also design an alternative training approach that
requires fewer communication rounds without compromising segmentation quality,
even with limited communication resources. Through experiments on three medical
segmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art
methods.

摘要：在醫學影像分割中，個人化跨資料孤島的聯邦學習 (FL) 逐漸盛行，用於利用醫療保健環境中的各種資料來克服資料稀少和隱私問題。然而，現有方法經常會出現客戶端偏移，導致效能不一致且訓練延遲。我們提出一個新的架構，透過功能增強 (pFLFE) 進行個人化聯邦學習，旨在減輕這些挑戰。pFLFE 包含兩個主要階段：功能增強和監督式學習。第一個階段改善前景和背景功能之間的差異，而第二個階段使用這些增強的功能從分割遮罩中學習。我們還設計了一個備用訓練方法，即使在通訊資源有限的情況下，也不影響分割品質，只需要較少的通訊回合。透過在三個醫學分割任務中進行實驗，我們證明 pFLFE 優於最先進的方法。

##### **Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**
2407.00402v2 by Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty

Improvements in language models' capabilities have pushed their applications
towards longer contexts, making long-context evaluation and development an
active research area. However, many disparate use-cases are grouped together
under the umbrella term of "long-context", defined simply by the total length
of the model's input, including - for example - Needle-in-a-Haystack tasks,
book summarization, and information aggregation. Given their varied difficulty,
in this position paper we argue that conflating different tasks by their
context length is unproductive. As a community, we require a more precise
vocabulary to understand what makes long-context tasks similar or different. We
propose to unpack the taxonomy of long-context based on the properties that
make them more difficult with longer contexts. We propose two orthogonal axes
of difficulty: (I) Diffusion: How hard is it to find the necessary information
in the context? (II) Scope: How much necessary information is there to find? We
survey the literature on long-context, provide justification for this taxonomy
as an informative descriptor, and situate the literature with respect to it. We
conclude that the most difficult and interesting settings, whose necessary
information is very long and highly diffused within the input, is severely
under-explored. By using a descriptive vocabulary and discussing the relevant
properties of difficulty in long-context, we can implement more informed
research in this area. We call for a careful design of tasks and benchmarks
with distinctly long context, taking into account the characteristics that make
it qualitatively different from shorter context.

摘要：語言模型能力的進步已將其應用推向更長的脈絡，使得長脈絡評估和開發成為一個活躍的研究領域。然而，許多不同的用例被歸類在「長脈絡」這個總稱之下，僅以模型輸入的總長度定義，包括例如大海撈針任務、書籍摘要和資訊彙整。鑑於它們的難度差異，我們在這篇立場文件中主張，將不同任務混為一談是沒有建設性的。作為一個社群，我們需要更精確的詞彙來理解是什麼讓長脈絡任務相似或不同。我們提議根據讓它們在較長脈絡中更困難的特性來解開長脈絡的分類法。我們提出兩個正交的難度軸：(I) 擴散：在脈絡中找到必要資訊有多困難？(II) 範圍：有多少必要的資訊需要找到？我們調查了關於長脈絡的文獻，為這個分類法作為一個有意義的描述符提供依據，並根據它來定位文獻。我們得出結論，最困難且最有趣的設定，其必要資訊在輸入中非常長且高度分散，嚴重地未被探索。透過使用描述性詞彙並討論長脈絡中困難的相關特性，我們可以在這個領域實施更明智的研究。我們呼籲仔細設計具有明顯長脈絡的任務和基準，並考量讓它在質量上不同於較短脈絡的特性。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**
2407.00147v1 by Dat Hong, Philip M. Polgreen, Alberto Maria Segre

Hospitalizations that follow closely on the heels of one or more emergency
department visits are often symptoms of missed opportunities to form a proper
diagnosis. These diagnostic errors imply a failure to recognize the need for
hospitalization and deliver appropriate care, and thus also bear important
connotations for patient safety. In this paper, we show how data mining
techniques can be applied to a large existing hospitalization data set to learn
useful models that predict these upcoming hospitalizations with high accuracy.
Specifically, we use an ensemble of logistics regression, na\"ive Bayes and
association rule classifiers to successfully predict hospitalization within 3,
7 and 14 days of an emergency department discharge. Aside from high accuracy,
one of the advantages of the techniques proposed here is that the resulting
classifier is easily inspected and interpreted by humans so that the learned
rules can be readily operationalized. These rules can then be easily
distributed and applied directly by physicians in emergency department settings
to predict the risk of early admission prior to discharging their emergency
department patients.

摘要：緊接在一次或多次急診科就診後住院，通常是錯失適當診斷機會的徵兆。這些診斷錯誤意味著未能察覺住院需求並提供適當照護，因此也對病患安全造成重大影響。在本文中，我們將展示資料探勘技術如何應用於現有的大型住院資料集，以學習預測這些即將到來的住院事件且準確度極高的有用模型。具體來說，我們使用邏輯迴歸、樸素貝氏和關聯規則分類器的組合，成功預測急診科出院後 3、7 和 14 天內的住院。除了高準確度之外，本文提出的技術優勢之一是，產生的分類器容易被人類檢查和解讀，因此可以輕鬆地將學習到的規則付諸實行。然後，這些規則可以輕易地被分發，並由急診科的醫師直接應用，以在出院前預測急診科病患早期入院的風險。

##### **BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**
2406.20041v3 by Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski

Autonomous agents driven by Large Language Models (LLMs) offer enormous
potential for automation. Early proof of this technology can be found in
various demonstrations of agents solving complex tasks, interacting with
external systems to augment their knowledge, and triggering actions. In
particular, workflows involving multiple agents solving complex tasks in a
collaborative fashion exemplify their capacity to operate in less strict and
less well-defined environments. Thus, a multi-agent approach has great
potential for serving as a backbone in many industrial applications, ranging
from complex knowledge retrieval systems to next generation robotic process
automation. Given the reasoning abilities within the current generation of
LLMs, complex processes require a multi-step approach that includes a plan of
well-defined and modular tasks. Depending on the level of complexity, these
tasks can be executed either by a single agent or a group of agents. In this
work, we focus on designing a flexible agent engineering framework with careful
attention to planning and execution, capable of handling complex use case
applications across various domains. The proposed framework provides
reliability in industrial applications and presents techniques to ensure a
scalable, flexible, and collaborative workflow for multiple autonomous agents
working together towards solving tasks.

摘要：由大型語言模型 (LLM) 驅動的自主代理人提供了巨大的自動化潛力。此技術的早期證明可以在代理人解決複雜任務、與外部系統互動以擴充其知識，以及觸發動作的各種演示中找到。特別是，涉及多個代理人以協作方式解決複雜任務的工作流程，說明了它們在較不嚴格和定義較不完善的環境中運作的能力。因此，多代理人方法極有可能成為許多產業應用中的骨幹，範圍從複雜的知識檢索系統到下一代機器人流程自動化。鑑於當前一代 LLM 中的推理能力，複雜的流程需要多步驟的方法，其中包括明確且模組化的任務計畫。根據複雜程度，這些任務可以由單一代理人或一群代理人執行。在這項工作中，我們專注於設計一個靈活的代理人工程架構，仔細注意計畫和執行，能夠處理跨越各種領域的複雜用例應用。所提出的架構在產業應用中提供了可靠性，並提出了技術，以確保多個自主代理人共同努力解決任務的可擴充性、靈活性，以及協作工作流程。

##### **Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**
2407.00142v1 by Christopher Irwin, Flavio Mignone, Stefania Montani, Luigi Portinale

The gut microbiome, crucial for human health, presents challenges in
analyzing its complex metaomic data due to high dimensionality and sparsity.
Traditional methods struggle to capture its intricate relationships. We
investigate graph neural networks (GNNs) for this task, aiming to derive
meaningful representations of individual gut microbiomes. Unlike methods
relying solely on taxa abundance, we directly leverage phylogenetic
relationships, in order to obtain a generalized encoder for taxa networks. The
representation learnt from the encoder are then used to train a model for
phenotype prediction such as Inflammatory Bowel Disease (IBD).

摘要：腸道微生物組對於人類健康至關重要，由於其複雜的宏組數據具有高維度和稀疏性的特點，因此在分析時會面臨挑戰。傳統的方法難以捕捉其複雜的關係。我們研究了圖神經網路 (GNN)，旨在推導出個別腸道微生物組的意義表示。與僅依賴分類群豐度的其他方法不同，我們直接利用系統發生關係，以獲得分類群網路的廣義編碼器。然後，從編碼器學習到的表示用於訓練表型預測模型，例如炎症性腸病 (IBD)。

##### **Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**
2406.19756v1 by Haojun Jiang, Meng Li, Zhenguo Sun, Ning Jia, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

The complex structure of the heart leads to significant challenges in
echocardiography, especially in acquisition cardiac ultrasound images.
Successful echocardiography requires a thorough understanding of the structures
on the two-dimensional plane and the spatial relationships between planes in
three-dimensional space. In this paper, we innovatively propose a large-scale
self-supervised pre-training method to acquire a cardiac structure-aware world
model. The core innovation lies in constructing a self-supervised task that
requires structural inference by predicting masked structures on a 2D plane and
imagining another plane based on pose transformation in 3D space. To support
large-scale pre-training, we collected over 1.36 million echocardiograms from
ten standard views, along with their 3D spatial poses. In the downstream probe
guidance task, we demonstrate that our pre-trained model consistently reduces
guidance errors across the ten most common standard views on the test set with
0.29 million samples from 74 routine clinical scans, indicating that
structure-aware pre-training benefits the scanning.

摘要：心脏复杂的结构导致超音波心动图检查面临重大挑战，特别是在获取心脏超音波影像时。成功的超音波心动图检查需要透彻了解二维平面上的结构以及三维空间中各平面之间的空间关系。在本文中，我们创新性地提出了一种大规模自我监督预训练方法，以获取心脏结构感知的世界模型。核心创新在于构建一项自我监督任务，该任务需要通过预测 2D 平面上的遮罩结构并在 3D 空间中基于姿态转换想象另一个平面来进行结构推理。为了支持大规模预训练，我们从十个标准视图中收集了超过 136 万个超音波心动图，以及它们的 3D 空间姿态。在下游探头引导任务中，我们证明了我们的预训练模型在测试集上持续减少了十个最常见标准视图的引导误差，其中包含来自 74 个常规临床扫描的 0.29 百万个样本，表明感知结构的预训练有利于扫描。

##### **Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**
2407.00129v1 by Akash Awasthi, Ngan Le, Zhigang Deng, Rishi Agrawal, Carol C. Wu, Hien Van Nguyen

Predicting human gaze behavior within computer vision is integral for
developing interactive systems that can anticipate user attention, address
fundamental questions in cognitive science, and hold implications for fields
like human-computer interaction (HCI) and augmented/virtual reality (AR/VR)
systems. Despite methodologies introduced for modeling human eye gaze behavior,
applying these models to medical imaging for scanpath prediction remains
unexplored. Our proposed system aims to predict eye gaze sequences from
radiology reports and CXR images, potentially streamlining data collection and
enhancing AI systems using larger datasets. However, predicting human scanpaths
on medical images presents unique challenges due to the diverse nature of
abnormal regions. Our model predicts fixation coordinates and durations
critical for medical scanpath prediction, outperforming existing models in the
computer vision community. Utilizing a two-stage training process and large
publicly available datasets, our approach generates static heatmaps and eye
gaze videos aligned with radiology reports, facilitating comprehensive
analysis. We validate our approach by comparing its performance with
state-of-the-art methods and assessing its generalizability among different
radiologists, introducing novel strategies to model radiologists' search
patterns during CXR image diagnosis. Based on the radiologist's evaluation,
MedGaze can generate human-like gaze sequences with a high focus on relevant
regions over the CXR images. It sometimes also outperforms humans in terms of
redundancy and randomness in the scanpaths.

摘要：預測電腦視覺中的人類視線行為對於開發互動式系統至關重要，這些系統可以預測使用者注意力、解決認知科學中的基本問題，並對人機互動 (HCI) 和擴增/虛擬實境 (AR/VR) 系統等領域產生影響。儘管引入了用於建模人類視線行為的方法，但將這些模型應用於醫學影像以進行掃描路徑預測仍未得到探索。我們提出的系統旨在根據放射科報告和 CXR 影像預測視線序列，這有可能簡化資料收集並使用更大的資料集來增強 AI 系統。然而，由於異常區域的多樣性，預測醫學影像上的人類掃描路徑提出了獨特的挑戰。我們的模型預測了對醫學掃描路徑預測至關重要的注視坐標和持續時間，表現優於電腦視覺社群中現有的模型。利用兩階段訓練流程和大量的公開可用資料集，我們的做法產生了與放射科報告相符的靜態熱圖和視線影片，從而促成了全面的分析。我們透過將其效能與最先進的方法進行比較並評估其在不同放射科醫師之間的概括性來驗證我們的做法，引入了新的策略來建模放射科醫師在 CXR 影像診斷期間的搜尋模式。根據放射科醫師的評估，MedGaze 可以產生類似人類的視線序列，高度關注 CXR 影像上的相關區域。在掃描路徑的冗餘性和隨機性方面，它有時也優於人類。

##### **ACES: Automatic Cohort Extraction System for Event-Stream Datasets**
2406.19653v1 by Justin Xu, Jack Gallifant, Alistair E. W. Johnson, Matthew B. A. McDermott

Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.

摘要：機器學習 (ML) 在醫療保健領域中，可複製性仍然是一項重大挑戰。在這個領域中，資料集、模型管線，甚至任務/群組定義通常都是私有的，這導致在電子健康紀錄 (EHR) 資料集上分享、重複和理解 ML 結果時產生重大的障礙。在本文中，我們透過導入事件串流資料集的自動群組萃取系統 (ACES) 來解決這個問題的其中一個重要部分。此工具旨在同時簡化醫療保健中 ML 的任務/群組開發，並讓這些群組得以複製，無論是在單一資料集的精確層級，還是在跨資料集的概念層級上。為達成此目的，ACES 提供了 (1) 一種高度直覺且具表現力的組態語言，用於定義資料集特定的概念和與資料集無關的包含/排除標準，以及 (2) 一個管線，用於自動從真實世界資料中萃取符合這些定義標準的病患記錄。ACES 可以自動套用至醫療事件資料標準 (MEDS) 或 EventStreamGPT (ESGPT) 格式中的任何資料集，或套用至 *任何* 可以以事件串流形式萃取必要的特定任務謂詞的資料集。ACES 有可能大幅降低定義 ML 任務的進入門檻，重新定義研究人員與 EHR 資料集互動的方式，並顯著改善此方式中 ML 研究的可複製性。ACES 可在 https://github.com/justin13601/aces 取得。

##### **Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**
2406.19611v1 by Huajun Zhou, Fengtao Zhou, Chenyu Zhao, Yingxue Xu, Luyang Luo, Hao Chen

The essence of precision oncology lies in its commitment to tailor targeted
treatments and care measures to each patient based on the individual
characteristics of the tumor. The inherent heterogeneity of tumors necessitates
gathering information from diverse data sources to provide valuable insights
from various perspectives, fostering a holistic comprehension of the tumor.
Over the past decade, multimodal data integration technology for precision
oncology has made significant strides, showcasing remarkable progress in
understanding the intricate details within heterogeneous data modalities. These
strides have exhibited tremendous potential for improving clinical
decision-making and model interpretation, contributing to the advancement of
cancer care and treatment. Given the rapid progress that has been achieved, we
provide a comprehensive overview of about 300 papers detailing cutting-edge
multimodal data integration techniques in precision oncology. In addition, we
conclude the primary clinical applications that have reaped significant
benefits, including early assessment, diagnosis, prognosis, and biomarker
discovery. Finally, derived from the findings of this survey, we present an
in-depth analysis that explores the pivotal challenges and reveals essential
pathways for future research in the field of multimodal data integration for
precision oncology.

摘要：精準腫瘤學的精髓在於針對每位患者量身打造標靶治療和照護措施，而根據腫瘤的個別特徵。腫瘤的內在異質性需要從不同的資料來源蒐集資訊，以提供來自不同觀點的寶貴見解，促進對腫瘤的整體理解。在過去十年中，精準腫瘤學的多模式資料整合技術已取得顯著進展，在了解異質性資料模式中的複雜細節方面展現出顯著的進展。這些進展已展現出極大的潛力，可改善臨床決策制定和模型詮釋，有助於癌症照護和治療的進步。鑑於已取得的快速進展，我們提供了約 300 篇論文的全面概述，詳細說明精準腫瘤學中尖端的模態資料整合技術。此外，我們總結了已獲得顯著好處的主要臨床應用，包括早期評估、診斷、預後和生物標記發現。最後，根據這項調查結果，我們提出了一項深入分析，探討了關鍵挑戰，並揭示了精準腫瘤學中多模式資料整合領域未來研究的重要途徑。

##### **PathAlign: A vision-language model for whole slide images in histopathology**
2406.19578v1 by Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn

Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.

摘要：顯微組織病理學影像的微觀詮釋是許多重要的診斷和治療決策的基礎。雖然視覺語言模型的進展為此類影像的分析帶來了新的契機，但全切片影像 (WSI) 的千兆像素等級大小帶來了獨特的挑戰。此外，病理報告同時強調了小區域的關鍵發現，同時也彙總了多個切片的詮釋，這通常使得建立穩健的影像文字對變得困難。因此，病理報告仍然是計算病理學中一個很大程度上未開發的監督來源，大多數工作依賴於感興趣區域註解或在貼片的層級上進行自我監督。在這項工作中，我們基於 BLIP-2 框架開發了一個視覺語言模型，使用與來自病理報告的策展文字配對的 WSI。這使得應用程式能夠使用共享的影像文字嵌入空間，例如文字或影像檢索來尋找感興趣的案例，以及將 WSI 編碼器與凍結的大語言模型 (LLM) 整合，用於 WSI 基於生成文字的能力，例如報告產生或 AI 循環互動。我們利用了一個包含超過 350,000 個 WSI 和診斷文字對的去識別化資料集，涵蓋了廣泛的診斷、程序類型和組織類型。我們展示了病理學家對使用 WSI 嵌入的文字產生和文字檢索的評估，以及 WSI 分類和工作流程優先順序（切片級別分類）的結果。病理學家評估了 WSI 的模型產生的文字，平均而言，78% 的 WSI 準確無臨床顯著錯誤或遺漏。這項工作展示了語言對齊 WSI 嵌入的令人興奮的潛在能力。

##### **Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**
2407.00120v1 by Abraham G Taye, Sador Yemane, Eshetu Negash, Yared Minwuyelet, Moges Abebe, Melkamu Hunegnaw Asmare

Malaria parasites pose a significant global health burden, causing widespread
suffering and mortality. Detecting malaria infection accurately is crucial for
effective treatment and control. However, existing automated detection
techniques have shown limitations in terms of accuracy and generalizability.
Many studies have focused on specific features without exploring more
comprehensive approaches. In our case, we formulate a deep learning technique
for malaria-infected cell classification using traditional CNNs and transfer
learning models notably VGG19, InceptionV3, and Xception. The models were
trained using NIH datasets and tested using different performance metrics such
as accuracy, precision, recall, and F1-score. The test results showed that deep
CNNs achieved the highest accuracy -- 97%, followed by Xception with an
accuracy of 95%. A machine learning model SVM achieved an accuracy of 83%,
while an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can
be accessed through a web interface, where users can upload blood smear images
for malaria detection.

摘要：瘧疾寄生蟲對全球健康造成重大負擔，導致廣泛的痛苦和死亡。準確檢測瘧疾感染對於有效治療和控制至關重要。然而，現有的自動檢測技術在準確性和普遍性方面顯示出局限性。許多研究專注於特定特徵，而沒有探索更全面的方法。在我們的案例中，我們制定了一種深度學習技術，使用傳統的 CNN 和轉移學習模型，特別是 VGG19、InceptionV3 和 Xception，進行瘧疾感染細胞分類。這些模型使用 NIH 資料集進行訓練，並使用不同的效能指標進行測試，例如準確度、精確度、召回率和 F1 分數。測試結果表明，深度 CNN 達到了最高的準確度——97%，其次是 Xception，準確度為 95%。機器學習模型 SVM 達到了 83% 的準確度，而 Inception-V3 達到了 94% 的準確度。此外，該系統可透過網路介面存取，使用者可以在此介面中上傳血塗片影像以進行瘧疾檢測。

##### **HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**
2406.19280v1 by Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang

The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.

摘要：多模态大语言模型（MLLM）的快速发展，例如 GPT-4V，带来了重大的进步。然而，由于医疗视觉文本数据的数量和质量的限制，这些模型在医疗多模态能力方面仍然面临挑战，这源于数据隐私问题和高昂的标注成本。虽然开创性的方法利用 PubMed 的大规模、去标识化的医学图像文本对来解决这些限制，但由于固有的数据噪声，它们仍然存在不足。为了解决这个问题，我们从 PubMed 中优化了医学图像文本对，并以“非盲”的方式采用了 MLLM（GPT-4V）来对数据进行去噪和重新格式化，从而创建了包含 130 万个医学 VQA 样本的 PubMedVision 数据集。我们的验证表明：(1) PubMedVision 可以显著增强当前 MLLM 的医疗多模态能力，在包括 MMMU 健康与医学轨道在内的基准测试中显示出显著的改进；(2) 医学专家的手动检查和实证结果验证了我们数据集与其他数据构建方法相比的卓越数据质量。使用 PubMedVision，我们训练了一个 34B 医学 MLLM HuatuoGPT-Vision，它在开源 MLLM 中的医学多模态场景中表现出卓越的性能。

##### **Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**
2407.00116v2 by Mahmoud Ibrahim, Yasmina Al Khalil, Sina Amirrajab, Chang Sun, Marcel Breeuwer, Josien Pluim, Bart Elen, Gokhan Ertaylan, Michel Dumontier

This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.

摘要：<paragraph>本文提出了生成式模型（GAN、VAE、DM 和 LLM）的全面系统性回顾，这些模型用于合成各种医学数据类型，包括影像（皮肤镜、乳房 X 光检查、超声波、CT、MRI 和 X 射线）、文本、时间序列和表格数据（EHR）。与以往针对特定领域的狭窄综述不同，我们的研究涵盖了广泛的医学数据模式，并探讨了各种生成式模型。我们的搜索策略查询了 Scopus、PubMed 和 ArXiv 等数据库，重点关注 2021 年 1 月至 2023 年 11 月的近期作品，不包括评论和观点。该时段着重强调了 GAN 之外的最新进展，而 GAN 已在之前得到广泛介绍。
调查从三个关键方面揭示了见解：(1) 合成应用和合成的目的，(2) 生成技术，以及 (3) 评估方法。它突出了临床上有效的合成应用，展示了合成数据解决各种临床需求的潜力。虽然包含类别标签、分割掩模和图像转换的条件模型很普遍，但在利用先验临床知识和患者特定背景方面存在差距，这表明需要更多个性化的合成方法，并强调根据医学数据的独特特征定制生成方法的重要性。此外，在合成数据的应用中存在一个明显的差距，超出了增强之外，例如用于验证和评估下游医学 AI 模型。调查发现，缺乏针对医学图像定制的标准化评估方法是临床应用的障碍，这强调了对深入评估方法、基准测试和比较研究的需求，以促进开放性和协作。</paragraph>

##### **Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**
2406.19057v2 by Fuseini Mumuni, Alhassan Mumuni

Grounding DINO and the Segment Anything Model (SAM) have achieved impressive
performance in zero-shot object detection and image segmentation, respectively.
Together, they have a great potential to revolutionize applications in
zero-shot semantic segmentation or data annotation. Yet, in specialized domains
like medical image segmentation, objects of interest (e.g., organs, tissues,
and tumors) may not fall in existing class names. To address this problem, the
referring expression comprehension (REC) ability of Grounding DINO is leveraged
to detect arbitrary targets by their language descriptions. However, recent
studies have highlighted severe limitation of the REC framework in this
application setting owing to its tendency to make false positive predictions
when the target is absent in the given image. And, while this bottleneck is
central to the prospect of open-set semantic segmentation, it is still largely
unknown how much improvement can be achieved by studying the prediction errors.
To this end, we perform empirical studies on six publicly available datasets
across different domains and reveal that these errors consistently follow a
predictable pattern and can, thus, be mitigated by a simple strategy.
Specifically, we show that false positive detections with appreciable
confidence scores generally occupy large image areas and can usually be
filtered by their relative sizes. More importantly, we expect these
observations to inspire future research in improving REC-based detection and
automated segmentation. Meanwhile, we evaluate the performance of SAM on
multiple datasets from various specialized domains and report significant
improvements in segmentation performance and annotation time savings over
manual approaches.

摘要：Grounding DINO 和 Segment Anything Model (SAM) 分別在零次學習目標偵測和影像分割方面取得令人印象深刻的表現。兩者結合起來，極有可能徹底改變零次學習語意分割或資料標註的應用。然而，在醫療影像分割等專業領域中，感興趣的物體（例如器官、組織和腫瘤）可能不在現有的類別名稱中。為了解決這個問題，Grounding DINO 的指稱表達理解 (REC) 能力被用於透過語言描述來偵測任意目標。然而，最近的研究強調了 REC 框架在這種應用設定中的嚴重限制，因為當目標不存在於給定的影像中時，它傾向於做出錯誤的正向預測。而且，儘管這個瓶頸對於開放式語意分割的前景至關重要，但透過研究預測誤差可以獲得多少改進仍然 weitgehend未知。為此，我們對六個不同領域的公開可用資料集進行實證研究，並揭示這些誤差始終遵循可預測的模式，因此可以透過一個簡單的策略來減輕。具體來說，我們表明具有可觀置信度分數的錯誤正向偵測通常佔據較大的影像區域，通常可以透過它們的相對大小來過濾。更重要的是，我們預期這些觀察結果將激勵未來在改進基於 REC 的偵測和自動分割方面的研究。同時，我們評估了 SAM 在來自各種專業領域的多個資料集上的效能，並報告了分割效能和標註時間相較於手動方法有顯著的改善。

##### **FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**
2406.19050v1 by Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan

Federated Learning (FL) is a distributed machine learning approach that
enables training on decentralized data while preserving privacy. However, FL
systems often involve resource-constrained client devices with limited
computational power, memory, storage, and bandwidth. This paper introduces
FedMap, a novel method that aims to enhance the communication efficiency of FL
deployments by collaboratively learning an increasingly sparse global model
through iterative, unstructured pruning. Importantly, FedMap trains a global
model from scratch, unlike other methods reported in the literature, making it
ideal for privacy-critical use cases such as in the medical and finance
domains, where suitable pre-training data is often limited. FedMap adapts
iterative magnitude-based pruning to the FL setting, ensuring all clients prune
and refine the same subset of the global model parameters, therefore gradually
reducing the global model size and communication overhead. The iterative nature
of FedMap, forming subsequent models as subsets of predecessors, avoids
parameter reactivation issues seen in prior work, resulting in stable
performance. In this paper we provide an extensive evaluation of FedMap across
diverse settings, datasets, model architectures, and hyperparameters, assessing
performance in both IID and non-IID environments. Comparative analysis against
the baseline approach demonstrates FedMap's ability to achieve more stable
client model performance. For IID scenarios, FedMap achieves over $90$\%
pruning without significant performance degradation. In non-IID settings, it
achieves at least $~80$\% pruning while maintaining accuracy. FedMap offers a
promising solution to alleviate communication bottlenecks in FL systems while
retaining model accuracy.

摘要：联邦学习 (FL) 是一种分布式机器学习方法，可在保护隐私的同时对分散数据进行训练。然而，FL 系统通常涉及资源受限的客户端设备，其计算能力、内存、存储和带宽有限。本文介绍了 FedMap，这是一种新颖的方法，旨在通过协作学习一个不断稀疏的全局模型（通过迭代的非结构化剪枝）来提高 FL 部署的通信效率。重要的是，FedMap 从头开始训练一个全局模型，这与文献中报道的其他方法不同，使其非常适合隐私至关重要的用例，例如医疗和金融领域，其中合适的预训练数据通常有限。FedMap 将基于迭代幅度的剪枝调整到 FL 设置中，确保所有客户端都剪枝并优化全局模型参数的相同子集，从而逐渐减少全局模型大小和通信开销。FedMap 的迭代性质，将后续模型形成为前代模型的子集，避免了先前工作中看到的参数重新激活问题，从而产生了稳定的性能。在本文中，我们对 FedMap 在不同设置、数据集、模型架构和超参数中进行了广泛评估，评估了在 IID 和非 IID 环境中的性能。与基准方法的比较分析证明了 FedMap 能够实现更稳定的客户端模型性能。对于 IID 场景，FedMap 在不显着降低性能的情况下实现了超过 90% 的剪枝。在非 IID 设置中，它在保持准确性的同时实现了至少 80% 的剪枝。FedMap 为缓解 FL 系统中的通信瓶颈同时保持模型准确性提供了一个有希望的解决方案。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v1](http://arxiv.org/abs/2407.07775v1)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v1](http://arxiv.org/abs/2407.01406v1)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v1](http://arxiv.org/abs/2407.01245v1)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Cascading Large Language Models for Salient Event Graph Generation**|Xingwei Tan et.al.|[2406.18449v1](http://arxiv.org/abs/2406.18449v1)|[link](https://github.com/xingwei-warwick/callmsae)|
|**2024-06-26**|**Sanskrit Knowledge-based Systems: Annotation and Computational Tools**|Hrishikesh Terdalkar et.al.|[2406.18276v1](http://arxiv.org/abs/2406.18276v1)|null|
|**2024-06-26**|**Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**|Ran Song et.al.|[2406.18085v1](http://arxiv.org/abs/2406.18085v1)|[link](https://github.com/Maxpa1n/gcplm-kgc)|
|**2024-06-26**|**AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**|Yifan Yang et.al.|[2406.18060v1](http://arxiv.org/abs/2406.18060v1)|[link](https://github.com/yifanycc/adazeta)|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**|Tong Zhou et.al.|[2406.17231v1](http://arxiv.org/abs/2406.17231v1)|[link](https://github.com/tongzhou21/CogMG)|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|[link](https://github.com/MatNLP/KEHRL)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**|Qiming Wu et.al.|[2406.16176v1](http://arxiv.org/abs/2406.16176v1)|null|
|**2024-06-23**|**Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**|Yizhuo Zhang et.al.|[2406.15992v1](http://arxiv.org/abs/2406.15992v1)|null|
|**2024-06-22**|**LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**|Guangsi Shi et.al.|[2406.15859v2](http://arxiv.org/abs/2406.15859v2)|null|
|**2024-06-22**|**Large Language Models for Link Stealing Attacks Against Graph Neural Networks**|Faqian Guan et.al.|[2406.16963v1](http://arxiv.org/abs/2406.16963v1)|null|
|**2024-06-21**|**Inferring Pluggable Types with Machine Learning**|Kazi Amanul Islam Siddiqui et.al.|[2406.15676v1](http://arxiv.org/abs/2406.15676v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v2](http://arxiv.org/abs/2406.15294v2)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v2](http://arxiv.org/abs/2406.14969v2)|null|
|**2024-06-20**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745v2](http://arxiv.org/abs/2406.14745v2)|null|
|**2024-06-20**|**Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**|Seungbeen Lee et.al.|[2406.14703v1](http://arxiv.org/abs/2406.14703v1)|null|
|**2024-06-20**|**TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**|Jiarui Feng et.al.|[2406.14683v1](http://arxiv.org/abs/2406.14683v1)|[link](https://github.com/jiaruifeng/taglas)|
|**2024-06-20**|**HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**|Jin Wang et.al.|[2406.14655v1](http://arxiv.org/abs/2406.14655v1)|null|
|**2024-06-20**|**GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**|Shilong Li et.al.|[2406.14550v1](http://arxiv.org/abs/2406.14550v1)|null|
|**2024-06-20**|**medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**|Mingyi Jia et.al.|[2406.14326v1](http://arxiv.org/abs/2406.14326v1)|null|
|**2024-06-20**|**Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**|Junjie Wang et.al.|[2406.14282v1](http://arxiv.org/abs/2406.14282v1)|[link](https://github.com/zjukg/lpkg)|
|**2024-06-20**|**ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**|Zhiyu Mei et.al.|[2406.14088v1](http://arxiv.org/abs/2406.14088v1)|[link](https://github.com/openpsi-project/realhf)|
|**2024-06-20**|**HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**|Yongqiang Chen et.al.|[2406.14021v1](http://arxiv.org/abs/2406.14021v1)|null|
|**2024-06-19**|**A Pure Transformer Pretraining Framework on Text-attributed Graphs**|Yu Song et.al.|[2406.13873v1](http://arxiv.org/abs/2406.13873v1)|[link](https://github.com/songyyyy/gspt)|
|**2024-06-19**|**Knowledge Graph-Enhanced Large Language Models via Path Selection**|Haochen Liu et.al.|[2406.13862v1](http://arxiv.org/abs/2406.13862v1)|[link](https://github.com/haochenliu2000/kelp)|
|**2024-06-19**|**Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**|Haochen Liu et.al.|[2406.15507v1](http://arxiv.org/abs/2406.15507v1)|[link](https://github.com/HaochenLiu2000/SAFER)|
|**2024-06-19**|**Dr.E Bridges Graphs with Large Language Models through Words**|Zipeng Liu et.al.|[2406.15504v1](http://arxiv.org/abs/2406.15504v1)|null|
|**2024-06-19**|**Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**|Han-Cheng Yu et.al.|[2406.13578v1](http://arxiv.org/abs/2406.13578v1)|null|
|**2024-06-19**|**LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**|Zhong Guan et.al.|[2406.13250v1](http://arxiv.org/abs/2406.13250v1)|null|
|**2024-06-19**|**Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**|Zhong Guan et.al.|[2406.13235v1](http://arxiv.org/abs/2406.13235v1)|null|
|**2024-06-19**|**Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**|Xiaoxi Kang et.al.|[2406.13217v1](http://arxiv.org/abs/2406.13217v1)|null|
|**2024-06-19**|**PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**|He Cao et.al.|[2406.13193v1](http://arxiv.org/abs/2406.13193v1)|[link](https://github.com/idea-xl/presto)|
|**2024-06-19**|**QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**|Bo Wang et.al.|[2406.13167v1](http://arxiv.org/abs/2406.13167v1)|null|
|**2024-06-18**|**Bridging Local Details and Global Context in Text-Attributed Graphs**|Yaoke Wang et.al.|[2406.12608v1](http://arxiv.org/abs/2406.12608v1)|null|
|**2024-06-18**|**MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**|Yuyan Liu et.al.|[2406.12950v1](http://arxiv.org/abs/2406.12950v1)|[link](https://github.com/nyushcs/moleculargpt)|
|**2024-06-18**|**LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**|Masafumi Enomoto et.al.|[2406.12494v1](http://arxiv.org/abs/2406.12494v1)|null|
|**2024-06-18**|**Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**|Gangwei Jiang et.al.|[2406.12227v2](http://arxiv.org/abs/2406.12227v2)|null|
|**2024-06-17**|**DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**|Jiasheng Zhang et.al.|[2406.12072v2](http://arxiv.org/abs/2406.12072v2)|[link](https://github.com/zjs123/DTGB)|
|**2024-06-17**|**UniGLM: Training One Unified Language Model for Text-Attributed Graphs**|Yi Fang et.al.|[2406.12052v1](http://arxiv.org/abs/2406.12052v1)|[link](https://github.com/nyushcs/uniglm)|
|**2024-06-17**|**GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models**|Yi Fang et.al.|[2406.11945v1](http://arxiv.org/abs/2406.11945v1)|[link](https://github.com/nyushcs/gaugllm)|
|**2024-06-17**|**Input Conditioned Graph Generation for Language Agents**|Lukas Vierling et.al.|[2406.11555v1](http://arxiv.org/abs/2406.11555v1)|[link](https://github.com/lukasvierling/dynamicgptswarm)|
|**2024-06-17**|**Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**|Golnaz Shapurian et.al.|[2406.11400v1](http://arxiv.org/abs/2406.11400v1)|null|
|**2024-06-17**|**How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**|Dawulie Jinensibieke et.al.|[2406.11162v2](http://arxiv.org/abs/2406.11162v2)|[link](https://github.com/victor812-hub/entity_datasets)|
|**2024-06-17**|**Context Graph**|Chengjin Xu et.al.|[2406.11160v3](http://arxiv.org/abs/2406.11160v3)|null|
|**2024-06-17**|**Are Large Language Models a Good Replacement of Taxonomies?**|Yushi Sun et.al.|[2406.11131v2](http://arxiv.org/abs/2406.11131v2)|[link](https://github.com/ysunbp/taxoglimpse)|
|**2024-06-16**|**DocNet: Semantic Structure in Inductive Bias Detection Models**|Jessica Zhu et.al.|[2406.10965v1](http://arxiv.org/abs/2406.10965v1)|[link](https://github.com/nlpresearchanon/DocNet)|
|**2024-06-16**|**Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**|Yikai Zhang et.al.|[2406.10902v1](http://arxiv.org/abs/2406.10902v1)|[link](https://github.com/ykzhang721/COG)|
|**2024-06-16**|**KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**|Aihua Pei et.al.|[2406.10802v1](http://arxiv.org/abs/2406.10802v1)|[link](https://github.com/aika-wsd/KGPA)|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Large Language Models as Event Forecasters**|Libo Zhang et.al.|[2406.10492v1](http://arxiv.org/abs/2406.10492v1)|null|
|**2024-06-15**|**Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**|Wenjun Li et.al.|[2406.10479v1](http://arxiv.org/abs/2406.10479v1)|null|
|**2024-06-14**|**Precision Empowers, Excess Distracts: Visual Question Answering With Dynamically Infused Knowledge In Language Models**|Manas Jhalani et.al.|[2406.09994v1](http://arxiv.org/abs/2406.09994v1)|null|
|**2024-06-14**|**DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning**|Zeyu Gao et.al.|[2406.09953v2](http://arxiv.org/abs/2406.09953v2)|null|
|**2024-06-14**|**TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs**|Zhuofeng Li et.al.|[2406.10310v1](http://arxiv.org/abs/2406.10310v1)|null|

#### Abstracts
##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v1 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin.

摘要：<paragraph>導航研究中一個難以捉摸的目標是建立一個智慧代理，它
可以理解包含自然語言和影像的多模態指令，並執行有用的導航。為了達成這個目標，我們研究了一個廣泛有用的導航任務類別，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的最新進展在實現這個目標方面展現了一條有希望的道路，因為它展示了感知和推理多模態輸入的能力。
然而，VLM 通常被訓練來預測文字輸出，而如何最佳地將它們用於導航是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它將示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標畫面。接下來，低階政策使用目標畫面和離線建構的拓撲圖在每個時間步產生機器人動作。我們在一個 836 平方公尺的真實世界環境中評估了 Mobility VLA，並顯示 Mobility VLA 在以前無法解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」並拿著一個塑膠箱）上具有很高的端到端成功率。</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

摘要：<paragraph>人類使用簡單的文字描述，豐富的連結和關係，來描述複雜的場景。雖然視覺語言的研究旨在開發具有組合理解能力的模型，但現有的數據集尚未反映這一點，這些數據集在很大程度上仍使用純文本來描述圖像。在這項工作中，我們提出了一種新的註釋策略，基於圖表的標題 (GBC)，它使用標籤圖表結構來描述圖像，其中包含各種類型的節點。GBC 中的節點是使用物體檢測和密集標題工具在第一階段創建的，以遞迴嵌套的方式發現和描述實體節點，並在第二階段使用新類型的節點突出顯示，從而將它們進一步連結在一起，實體之間的組合和關係。由於所有 GBC 節點都包含純文本描述，因此 GBC 保留了自然語言中的靈活性，但也可以在其邊緣編碼分層信息。我們證明了 GBC 可以使用現成的多模態 LLM 和開放詞彙檢測模型自動生成，通過構建一個新的數據集 GBC10M，收集了大約 10M CC12M 數據集圖像的 GBC 註釋。我們使用 GBC10M 來展示 GBC 發現的豐富節點標題，並使用 CLIP 訓練進行測量。我們表明，與其他數據集格式相比，使用 GBC 節點的註釋——特別是存儲在組合和關係節點中的註釋——會顯著提升下游模型的性能。為了進一步探索 GBC 提供的機會，我們還提出了一種新的注意機制，它可以利用整個 GBC 圖表，並通過鼓勵性的實驗結果展示了結合圖表結構的額外好處。我們的數據集發布在 \url{https://huggingface.co/graph-based-captions}。</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

摘要：近年来，自然语言处理 (NLP) 在各种人工智能 (AI) 应用中发挥了重要作用，例如聊天机器人、文本生成和语言翻译。大语言模型 (LLM) 的出现极大地提高了这些应用程序的性能，在语言理解和生成方面显示出惊人的结果。然而，它们仍然表现出一些缺点，例如幻觉和缺乏特定领域的知识，这些缺点会影响它们在现实世界中的任务中的表现。通过纳入知识图谱 (KG) 可以有效地减轻这些问题，知识图谱以结构化格式组织信息，以多功能且可解释的方式捕获实体之间的关系。同样，KG 的构建和验证提出了 LLM 可以帮助解决的挑战。LLM 和 KG 之间的互补关系导致了一种将这些技术相结合以实现可信结果的趋势。这项工作收集了 28 篇概述了 KG 驱动的 LLM、基于 LLM 的 KG 和 LLM-KG 混合方法的方法的论文。我们系统地分析和比较了这些方法，以提供一个全面的概述，重点介绍关键趋势、创新技术和共同挑战。这种综合将使该领域的新研究人员和那些寻求加深对如何有效地将 KG 和 LLM 相结合以增强 AI 应用能力的理解的人受益。

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

摘要：知識圖表問答 (KGQA) 簡化了使用自然語言查詢儲存在圖形化模型中的大量知識。然而，研究主要集中在英文上，這對非英語使用者來說是不利的。同時，現有的多語言 KGQA 系統在達成與英文系統相媲美的效能方面面臨挑戰，突顯了從不同語言產生 SPARQL 查詢的困難性。在這項研究中，我們提出了一種簡化的方法，通過將語言學背景和實體資訊直接納入語言模型的處理管道，來增強多語言 KGQA 系統。與依賴於單獨編碼器來整合輔助資訊的現有方法不同，我們的策略利用單一的、預訓練的多語言轉換器語言模型來管理主要輸入和輔助資料。我們的技術顯著提升了語言模型準確地將自然語言查詢轉換為相關 SPARQL 查詢的能力。它在最新的 QALD 資料集，即 QALD-9-Plus 和 QALD-10 上展示了有希望的結果。此外，我們在中文和日文中引入並評估了我們的做法，從而擴展了現有資料集的語言多樣性。

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

摘要：辨識交通事故是任何自動駕駛或道路監控系統的必要部分。事故可能以各種形式出現，了解事故類型可能有助於防止再次發生。將交通事故場景分類為特定事故類型的任務是這項工作的重點。我們將交通事故場景比喻為圖形來解決問題，其中汽車等物體可以表示為節點，而它們之間的相對距離和方向則表示為邊緣。這種事故表示可以稱為場景圖，並用作事故分類器的輸入。使用將場景圖輸入與視覺和語言表示融合的分類器可以獲得更好的結果。這項工作引入了一個多階段、多模態管道，用於預處理交通事故影片、將其編碼為場景圖，以及將此表示與視覺和語言模式對齊以進行事故分類。當在 4 個類別上進行訓練時，我們的模型在熱門交通異常檢測 (DoTA) 基準的（不平衡）子集上實現了 57.77% 的平衡準確率，比不考慮場景圖資訊的情況提高了接近 5 個百分點。

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

摘要：基於 LLM 的代理已在視覺語言導航 (VLN) 任務中展示出令人印象深刻的零次學習效能。然而，這些零次學習方法僅專注於透過選擇預定義導航圖形中的節點來解決高階任務規劃，忽略了實際導航場景中的低階控制。為了彌合此差距，我們提出 AO-Planner，一個用於連續 VLN 任務的新型以可負擔性為導向的規劃架構。我們的 AO-Planner 整合各種基礎模型，以實現以可負擔性為導向的動作規劃和動作決策，兩者都以零次學習的方式執行。具體來說，我們採用視覺可負擔性提示 (VAP) 方法，其中利用 SAM 對可見地面進行分割，以提供導航可負擔性，LLM 根據這些可負擔性選擇潛在的下一個航點，並針對所選航點產生低階路徑規劃。我們進一步引入一個高階代理 PathAgent，以識別最可能的基於像素的路徑，並將其轉換為 3D 座標，以實現低階動作。在具有挑戰性的 R2R-CE 基準測試上的實驗結果表明，AO-Planner 達到了最先進的零次學習效能（SPL 提升 5.5%）。我們的模型在 LLM 和 3D 世界之間建立了一個有效的連結，以規避直接預測世界座標的難題，為在低階動作控制中採用基礎模型提供了新的前景。

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

摘要：最近的研究表明，大型语言模型 (LLM) 容易被错误前提问题 (FPQ) 误导，从而导致事实知识错误，即事实幻觉。用于评估此漏洞的现有基准主要依赖于手动构建，导致规模有限且缺乏可扩展性。在这项工作中，我们引入了一个基于知识图谱 (KG) 创建 FPQ 的自动化可扩展管道。第一步是修改从 KG 中提取的真三元组以创建错误前提。随后，利用 GPT 的最先进功能，我们生成了语义丰富的 FPQ。基于所提出的方法，我们提出了一个综合基准，即基于知识图谱的错误前提问题 (KG-FPQ)，它包含大约 178k 个 FPQ，涵盖三个知识域，六个混淆级别和两种任务格式。使用 KG-FPQ，我们对几个有代表性的 LLM 进行了广泛的评估，并提供了有价值的见解。KG-FPQ 数据集和代码可在~https://github.com/yanxuzhu/KG-FPQ 获得。

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

摘要：<paragraph>最近的研究實證表明，語言模型 (LM) 編碼豐富的世界知識，超越了單純的語義，吸引了各個領域的極大關注。然而，在推薦領域中，LM 是否隱含編碼使用者偏好資訊仍不確定。與普遍認知相反，LM 和傳統推薦模型由於語言和行為建模目標的巨大差距而學習兩個不同的表示空間，這項工作重新思考這種理解，並探索直接從語言表示空間中提取推薦空間。令人驚訝的是，我們的研究結果表明，當從先進的 LM 表示中線性映射時，項目表示會產生優異的推薦效能。此結果表明語言表示空間和有效的推薦空間之間存在同態性，這意味著協作訊號確實可能編碼在先進的 LM 中。受這些研究結果的啟發，我們提出了一個簡單但有效的協同過濾 (CF) 模型，名為 AlphaRec，它利用項目文字元資料（例如標題）的語言表示，而不是傳統基於 ID 的嵌入。具體來說，AlphaRec 由三個主要組成部分組成：多層感知器 (MLP)、圖形卷積和對比學習 (CL) 損失函數，使其極易於實作和訓練。我們的實證結果表明，AlphaRec 在多個資料集上優於領先的基於 ID 的 CF 模型，標誌著這種具有文字嵌入的推薦系統首次達到此效能水準。此外，AlphaRec 引入了一個新的基於語言表示的 CF 典範，具有多項理想的優點：易於實作、輕量級、快速收斂、在新的領域中具有優異的零次學習推薦能力，並且可以了解使用者的意圖。</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

摘要：時間推理 (TR) 是人工智慧的一項關鍵組成部分，
涵蓋了對時間資訊和事件之間關係的理解和處理。為了發現和研究大型語言模型 (LLM) 中的 TR 能力，已透過各種方式建構各種資料集，用於評估 TR 能力的各個面向。我們的工作提出了一種新穎的方法，用於設計和開發一個建構資料集的管道，以評估 LLM 的 TR 能力，方法是利用隨機有向圖生成、LTL 公式和 NuSMV 模型檢查器。根據這個管道，我們還建構了一個資料集作為基準，即 LTLBench，其中包含 2,000 個 TR 挑戰，並用它評估了六個 LLM。此外，我們還進行了額外的實驗，以發現增加事件數量和公式運算子對 TR 問題複雜性和 LLM 效能的影響。我們已經證明，儘管 LLM 在處理 TR 挑戰方面表現出一些希望，但它們仍然難以處理複雜的 TR。我們預期這項工作可以提供對 LLM 中 TR 能力的見解，同時也為未來的 TR 評估提供一個有價值的工具。

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

摘要：大型語言模型廣泛應用於各種任務中，例如客戶支援、內容創作、教育輔導和提供財務指導。然而，一個眾所周知的缺點是它們傾向於產生幻覺。這損害了這些模型所提供資訊的可信度，影響了決策制定和使用者信心。我們提出了一種透過觀察潛在空間的結構並找出幻覺和非幻覺生成中的關聯來偵測幻覺的方法。我們建立了一個圖形結構，連接在嵌入空間中緊密相連的生成。此外，我們採用了一個圖形注意力網路，它利用訊息傳遞來彙總來自相鄰節點的資訊，並根據每個相鄰節點的相關性為其指定不同程度的重要性。我們的研究結果顯示，1) 潛在空間中存在一個結構，可以區分幻覺和非幻覺生成，2) 圖形注意力網路可以學習這個結構並將其概括到未見的生成中，以及 3) 當納入對比學習時，我們方法的穩健性會得到增強。當根據基於證據的基準進行評估時，我們的模型在無法取得基於搜尋的方法的情況下，表現得類似。

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

摘要：生成式 AI 的進步擴展了大型語言模型 (LLM) 在自主代理開發中的潛在應用。實現真正的自主性需要累積和更新從與環境互動中獲得的知識，並有效利用它。當前的基於 LLM 的方法利用過去的經驗，使用完整的觀察、摘要或檢索擴充。然而，這些非結構化的記憶表徵並不能促進複雜決策制定中必不可少的推理和規劃。在我們的研究中，我們介紹了 AriGraph，這是一種新方法，其中代理構建了一個記憶圖，該圖在探索環境時整合了語義和情節記憶。這種圖形結構促進了相互聯繫的概念的有效關聯性檢索，與代理的當前狀態和目標相關，從而作為一個有效的環境模型，增強了代理的探索和規劃能力。我們展示了我們的 Ariadne LLM 代理，配備了這種提議的記憶架構，並增強了規劃和決策制定，有效地處理了 TextWorld 環境中零次學習的複雜任務。我們的做法顯著優於已建立的方法，例如完整歷史、摘要和檢索增強生成，在各種任務中，包括來自第一個 TextWorld 問題競賽的烹飪挑戰和房屋清潔和拼圖尋寶等新任務。

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

摘要：符號句子意義表徵，例如 AMR（抽象意義表徵），提供表達性和結構化的語義圖表，作為簡化下游 NLP 任務的中介。然而，大型語言模型 (LLM) 的指令遵循能力提供了一個捷徑來有效解決 NLP 任務，質疑語義圖表的效用。同時，最近的研究也表明僅將意義表徵用作 LLM 的輔助工具的難度。我們重新審視語義圖表在語法簡化中的位置，語法簡化的任務是在保留句子結構的同時簡化句子結構，這需要語義理解，並在一個新的複雜且自然的數據集上對其進行評估。我們提出的基於 AMR 的方法 AMRS$^3$ 證明了最先進的意義表徵可以導致易於實現的簡化方法，在成本、可解釋性和泛化方面具有競爭優勢和獨特優勢。以 AMRS$^3$ 為錨點，我們發現語法簡化是一項語義圖表有助於 LLM 提示的任務。我們提出 AMRCoC 提示，指導 LLM 模擬圖形演算法，對 AMR 圖形進行明確的符號推理，並展示其在改進 LLM 在以語義為中心的任務（如語法簡化）方面的潛力。

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

摘要：<paragraph>在本文中，我們介紹了對稱為電路發現任務的全面重新表述，以及 DiscoGP，一種基於可微遮罩的發現電路的新穎且有效的演算法。電路發現是透過將其功能和能力解剖成稀疏子網路（電路）來詮釋語言模型（LM）的運算機制的任務。我們在現有的電路發現工作中發現了兩個主要的限制：（1）基於權重和基於連接邊緣的方法之間的二分法迫使研究人員在修剪連接或權重之間進行選擇，從而限制了 LM 機制詮釋的範圍；（2）基於啟用修補的演算法傾向於識別在功能上既不忠實也不完整的電路。這些已識別電路的效能大幅降低，通常導致孤立的近乎隨機效能。此外，電路的補數——即移除已識別電路的原始 LM——仍保留了足夠的效能，這表示現有方法錯失了完整電路的基本組成部分。
DiscoGP 成功地解決了上述兩個問題，並展示了最先進的忠實度、完整性和稀疏性。該演算法的有效性和其新穎的結構為深入瞭解生成式 AI 的內部運作開闢了新的途徑。</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

摘要：本文提出 Bag-of-Concept Graph (BACON)，赋予语言能力有限的模型品尝视觉语言模型 (VLM) 的特权，并提升下游任务，例如检测、视觉问答 (VQA) 和图像生成。由于物理世界中的视觉场景是由对象之间的复杂关系构建而成的，因此 BACON 将注释分解为基本的最小元素，并以图形结构呈现它们。基于元素的风格便于理解，结构化组合解放了困难的定位。在公共可用 VLM 和分割方法的帮助下，精心设计的提示生成了 BACON 标题。通过这种方式，我们收集了一个包含 100K 张注释图像的数据集，该数据集赋予 VLM 显著的能力，例如准确生成 BACON、将提示转换为 BACON 格式、以 BACONr 的风格设想场景，以及通过交互式对话动态修改 BACON 中的元素等等。广泛的代表性实验，包括检测、VQA 和图像生成任务，表明 BACON 作为一条生命线，可以实现以前无法实现的任务，或在当前的尖端解决方案中表现出色。

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

摘要：評估大型語言模型 (LLM) 的圖形理解和推理能力具有挑戰性，且通常不完整。現有的基準主要著重於純粹的圖形理解，缺乏對所有圖形類型和詳細功能定義的全面評估。本文提出了 GraCoRe，一個用於系統評估 LLM 的圖形理解和推理的基準。GraCoRe 使用三層階層分類法對模型進行分類和測試，將功能細分為 10 個不同的領域，並通過 19 個任務進行測試。我們的基準包含 11 個數據集，其中包含 5,140 個不同複雜度的圖形。我們評估了三個閉源和七個開源 LLM，從能力和任務角度進行了徹底的分析。主要發現表明語義豐富化增強了推理性能，節點排序影響任務成功，而處理較長文本的能力並不一定能改善圖形理解或推理。GraCoRe 在 https://github.com/ZIKEYUAN/GraCoRe 開源

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

摘要：知識圖嵌入 (KGE) 是知識圖 (KG) 用於服務各種人工智慧任務的常見方法。嵌入的適當維度取決於特定應用場景的儲存和運算條件。一旦需要新的維度，就需要從頭訓練新的 KGE 模型，這大大增加了訓練成本，並限制了 KGE 在服務各種場景中的效率和靈活性。在這項工作中，我們提出了一種新穎的 KGE 訓練框架 MED，通過它，我們可以訓練一次以獲得適用於具有不同維度需求的多個場景的可裁剪 KGE 模型，可以從中裁剪出所需維度的子模型並直接使用，而無需任何額外訓練。在 MED 中，我們提出了一種相互學習機制，以提高低維子模型的效能，並使高維子模型保留低維子模型具有的能力，一種進化改進機制，以促進高維子模型掌握低維子模型無法學習的知識，以及一種動態損失權重，以自適應地平衡多重損失。在 4 個標準 KG 完成資料集上的 3 個 KGE 模型、一個真實世界大規模 KG 上的 3 個實際應用場景以及將 MED 擴展到語言模型 BERT 的實驗中，展示了 MED 的有效性、高效率和靈活的可擴充性。

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

摘要：大型語言模型 (LLM) 在實際應用中的進展，關鍵在於提升其推理能力。在這項工作中，我們透過大型語言模型 (LLM) 的幾何理解，探討其推理能力。我們建立了 LLM 的表達能力與其自注意力圖密度之間的關聯。我們的分析證明，這些圖的密度定義了 MLP 塊輸入的內在維度。我們透過理論分析和玩具範例證明，較高的內在維度意味著 LLM 具有更大的表達能力。我們進一步提供經驗證據，將這個幾何框架連結到最近在旨在增強 LLM 推理能力的方法中取得的進展。

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

摘要：鉴于出版商、报纸和其他受版权保护语料库的创造者最近对大型语言模型 (LLM) 开发者提出的剽窃指控，我们提出了一种新颖的系统，该系统是剽窃检测系统的一个变体，它评估知识源是否已用于大型语言模型的训练或微调。与当前方法不同，我们利用一种使用资源描述框架 (RDF) 三元组的方法从源文档和该文档的 LLM 延续中创建知识图谱。然后使用余弦相似性分析这些图谱的内容，并使用图编辑距离的标准化版本分析结构，该版本显示同构度。与专注于源语料库和目标语料库之间的内容匹配和关键词识别的传统系统不同，我们的方法能够对相似性进行更广泛的评估，从而更准确地比较源文档和 LLM 延续之间的相似性，方法是关注思想之间的关系以及它们与其他思想的关系。此外，我们的方法不需要访问 LLM 指标，例如困惑度，这些指标在封闭的大型语言建模“黑匣子”系统以及训练语料库中可能不可用。我们系统的原型将在超链接的 GitHub 存储库中找到。

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

摘要：肽在生物過程和治療中至關重要。在此研究中，我們介紹了多肽，這是一種創新的方法，結合了基於轉換器的語言模型和圖神經網絡 (GNN) 來預測肽的性質。我們結合了專門用於肽性質預測的轉換器模型 PeptideBERT 和 GNN 編碼器，以捕獲基於序列和結構的特徵。通過採用對比語言圖像預訓練 (CLIP)，多肽將來自兩種模態的嵌入對齊到一個共享的潛在空間中，從而增強模型的預測準確度。對溶血和抗污數據集的評估證明了多肽的穩健性，在溶血預測中實現了最先進的 86.185% 準確率。本研究強調了生物信息學中多模態學習的潛力，為基於肽的研究和應用中的準確且可靠的預測鋪平了道路。

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

摘要：大型视觉语言模型 (LVLMs) 在视觉指令遵循任务中会产生幻觉，这限制了它们的可靠性和现实世界的适用性。我们提出了 Pelican——一种旨在通过声明验证来检测和减轻幻觉的新型框架。Pelican 首先根据一阶谓词将视觉声明分解成一个子声明链。这些子声明由 (谓词、问题) 对组成，可以被概念化为计算图的节点。然后，我们使用思想计划提示来生成 Python 代码，通过外部工具的灵活组合来回答这些问题。Pelican 通过引入 (1) 用于对象实例精确接地的中间变量，以及 (2) 用于回答子问题以实现自适应校正和不一致性识别的共享计算，改进了之前的工作。我们最终使用 LLM 的推理能力，通过考虑每个子声明的 (问题、答案) 对的一致性和置信度来验证声明的正确性。我们的实验表明，在各种基线 LVLMs 中，幻觉率下降了约 8%-32%，与 MMHal-Bench 上提出的幻觉缓解方法相比，下降了 27%。在另外两个基准上的结果进一步证实了我们的结果。

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

摘要：最近的研究表明，大型语言模型 (LLM) 仅使用选项就能回答多项选择题，但这是否表示多项选择问答 (MCQA) 排行榜上的 LLM 主要受限于仅选项设置中的能力？为了回答这个问题，我们使用对比集来探查 LLM 在 MCQA 中是否过度依赖仅选项捷径。虽然先前的研究通过昂贵的人工注释或可能存在偏差的模型生成数据来构建对比集，但我们采用图挖掘从现有 MCQA 数据集中提取对比集。我们使用我们的方法在 UnifiedQA 上，这是一个由六个具有高仅选项准确率的常识推理数据集组成的组，构建了一个 820 题的对比集。在验证我们的对比集后，我们测试了 12 个 LLM，发现当同时给出问题和选项时，这些模型不会表现出对仅选项捷径的依赖。因此，尽管 MCQA 容易受到高仅选项准确率的影响，但我们认为 LLM 在 MCQA 排行榜上获得高排名并非仅仅因为它们利用仅选项捷径的能力。

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

摘要：自主代理的開發越來越依賴多模態語言模型 (MLM)，以在具有 GUI 環境（例如網站、桌上型電腦或手機）的自然語言中執行任務。現有的互動環境中 MLM 代理的基準受到以下限制：它們專注於單一環境、缺乏詳細且通用的評估方法，以及建構任務和評估器的複雜性。為了克服這些限制，我們引入了 Crab，這是第一個代理基準架構，旨在支援跨環境任務，並結合了基於圖形的細粒度評估方法和任務與評估器建構的有效機制。我們的架構支援多種裝置，並且可以輕鬆地擴充到任何具有 Python 介面的環境。利用 Crab，我們開發了一個跨平台的 Crab Benchmark-v0，其中包含電腦桌上型電腦和手機環境中的 100 個任務。我們使用不同的單一和多代理系統配置，在這個基準上評估了四種先進的 MLM。實驗結果表明，具有 GPT-4o 的單一代理實現了 35.26% 的最佳完成率。所有架構程式碼、代理程式碼和任務資料集都公開於 https://github.com/camel-ai/crab。

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

摘要：大型語言模型為知識圖譜（KGQA）的創新問答提供了機會。然而，它們並非天生就設計用於查詢生成。為了彌補這一差距，已提出依賴於微調或特定架構的解決方案，取得了良好的結果，但域外分佈泛化能力有限。在本研究中，我們引入了一種稱為動態小樣本學習（DFSL）的新方法。DFSL 集成了語境學習和語義相似性的效率，並為 KGQA 提供了一個普遍適用的解決方案，具有最先進的性能。我們對多個基準資料集和架構配置進行了廣泛的評估。

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v1 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

摘要：這篇論文探討了使用適配器將語言本體論中的圖形知識整合到多語言大型語言模型 (LLM) 中，以改善低資源語言 (LRL) 在情緒分析 (SA) 和命名實體辨識 (NER) 中的效能。建立在成功的參數有效微調技術上，例如 K-ADAPTER 和 MAD-X，我們提出了一種類似的方法，用於將來自多語言圖形、透過語言關係將各種語言中的概念彼此連接的知識整合到 LRL 的多語言 LLM 中。具體來說，我們專注於八種 LRL——馬爾他語、保加利亞語、印尼語、尼泊爾語、爪哇語、維吾爾語、藏語和僧伽羅語——並使用針對從 ConceptNet 的語言特定部分中萃取的資料進行微調的語言特定適配器，旨在讓知識在知識圖形涵蓋的語言之間轉移。我們比較了各種微調目標，包括標準的遮罩語言模型 (MLM)、帶有全詞遮罩的 MLM 和帶有目標遮罩的 MLM，以分析它們在學習和整合萃取的圖形資料方面的有效性。透過對語言特定任務的經驗評估，我們評估了結構化的圖形知識如何影響多語言 LLM 在 SA 和 NER 中的效能，並深入了解了為低資源場景調整語言模型的潛在好處。

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v1 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

摘要：知識追蹤 (KT) 旨在判斷學生是否會正確回答下一個問題，這在智慧型教學系統 (ITS) 中是一項至關重要的任務。在教育 KT 場景中，基於轉導 ID 的方法通常會面臨嚴重的資料稀疏性和冷啟動問題，其中個別學生與問題之間的互動很稀少，而且新的問題和概念會持續出現在資料庫中。此外，現有的 KT 模型僅隱含地考慮概念和問題之間的關聯性，缺乏對概念和問題異質圖中更複雜關係的直接建模。在本文中，我們提出了一個具有大型語言模型的結構感知歸納知識追蹤模型 (稱為 SINKT)，該模型首次引入了大型語言模型 (LLM) 並實現了歸納知識追蹤。首先，SINKT 利用 LLM 來引入概念之間的結構關係，並為概念和問題構建一個異質圖。其次，透過使用 LLM 編碼概念和問題，SINKT 納入了語義資訊以協助預測。最後，SINKT 透過與學生的知識狀態和問題表示進行互動來預測學生對目標問題的回應。在四個真實世界資料集上的實驗表明，SINKT 在 12 個現有轉導 KT 模型中達到了最先進的效能。此外，我們探討了 SINKT 在歸納 KT 任務中的效能，並深入了解各種模組。

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

摘要：<paragraph>我們重新審視圖形機器學習的一個簡單想法，其中圖形上的隨機遊走會產生機器可讀的記錄，而這個記錄會由深度神經網路處理，以直接進行頂點層級或圖形層級的預測。我們將這些隨機機器稱為隨機遊走神經網路，並展示我們可以將它們設計成同構不變，同時具備機率中圖形函數的通用近似能力。一個有用的發現是，只要頂點是匿名的，幾乎任何類型的隨機遊走記錄都可以保證機率不變性。這使我們能夠以純文字記錄隨機遊走，並採用語言模型來讀取這些文字記錄，以解決圖形任務。我們進一步建立了一個與訊息傳遞神經網路的平行性，使用馬可夫鏈理論的工具，並展示訊息傳遞中的過度平滑會因隨機遊走神經網路中的構造而得到緩解，而過度壓縮則表現為機率性不足。我們展示了基於預先訓練語言模型的隨機遊走神經網路可以解決圖形上的幾個困難問題，例如分離 3-WL 測試失敗的強正則圖形、計算子結構，以及在 arXiv 引文網路中進行轉導分類，而無需訓練。程式碼可在 https://github.com/jw9730/random-walk 取得。</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

摘要：大型語言模型 (LLM) 在各個領域的複雜任務中展現出卓越的能力，從基本的問答 (QA) 開始，它們現在被用作決策助理或不熟悉內容的說明者。然而，它們並不總是正確的，因為特定領域語料庫中的數據稀疏，或模型的幻覺問題。有鑑於此，我們應該多相信 LLM 的回應？本文提出了一種新的方法來評估捕捉方向不穩定性的不確定性，通過從蘊涵概率構造一個有向圖，並且我們創新地進行隨機遊走拉普拉斯算子，給定一個構造的有向圖的不對稱屬性，然後不確定性由拉普拉斯過程中的導出特徵值聚合。我們還提供了一種將現有工作的語義不確定性與我們提出的層結合起來的方法。此外，本文識別了原始回應集中模糊的問題，並提出了一種擴充方法來減輕這種問題，我們進行了廣泛的實證實驗，並展示了我們提出的解決方案的優越性。

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

摘要：網路威脅不斷演變。從非結構化的網路威脅情報 (CTI) 資料中萃取可採取行動的見解，對於引導網路安全決策至關重要。越來越多組織，例如 Microsoft、趨勢科技和 CrowdStrike，使用生成式 AI 來促進 CTI 萃取。本文探討了使用大型語言模型 (LLM) 和知識圖譜 (KG) 的進展，自動萃取可採取行動的 CTI 的挑戰。我們探討了最先進的開源 LLM 的應用，包括 Llama 2 系列、Mistral 7B Instruct 和 Zephyr，以從 CTI 文字中萃取有意義的三元組。我們的做法評估了提示工程、指導架構和微調等技術，以最佳化資訊萃取和結構化。然後，將萃取的資料用於建構 KG，提供威脅情報的結構化且可查詢的表示。實驗結果證明了我們方法在萃取相關資訊方面的有效性，指導和微調顯示出優於提示工程的效能。然而，雖然我們的做法在小規模測試中證明有效，但將 LLM 應用於大規模資料以進行 KG 建構和連結預測，仍存在持續的挑戰。

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中展現出驚人的能力，這些任務涉及越來越複雜的推理。知識推理作為推理的主要類型，旨在從既有知識中推導出新知識。儘管知識推理已在知識圖譜 (KG) 的背景下得到廣泛研究，但 LLM 中的知識推理仍處於探索階段。在本文中，我們介紹了知識推理的綜合框架知識鏈，其中包括用於資料集構建和模型學習的方法。對於資料集構建，我們透過在 KG 中進行規則挖掘來建立 KnowReason。對於模型學習，我們觀察到由天真訓練引發的規則過度擬合。因此，我們使用模擬人類內部知識探索過程的試錯機制來增強 CoK。我們對 KnowReason 進行了廣泛的實驗。我們的結果顯示 CoK 在精煉 LLM 不僅在知識推理方面，還包括一般推理基準方面都非常有效。

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

摘要：<paragraph>追求生物醫學科學的人工智慧，又稱 AI 科學家，
越來越受到關注，其中一種常見的方法是建立由大型語言模型 (LLM) 驅動的副駕駛代理。然而，要評估此類
系統，人們要么依賴 LLM 本身的直接問答 (QA)，要么依賴生物醫學實驗方式。如何從 AI 科學家的角度精確評量
生物醫學代理在很大程度上仍未探索。
為此，我們從科學家最重要的能力之一，即理解文獻中汲取靈感，並介紹 BioKGBench。與僅關注事實 QA 的傳統評量基準不同，已知 LLM 在事實 QA 中存在幻覺問題，我們首先將
「理解文獻」分解為兩種基本能力，i) 透過執行科學主張驗證來「理解」研究論文中的非結構化文字，以及 ii) 以「文獻」為基礎，與結構化的知識圖表問答 (KGQA) 互動的能力。然後
我們使用 KGQA 和基於網域的檢索擴充產生 (RAG) 制定了一項新穎的代理任務，稱為 KGCheck，以識別現有大型知識圖表資料庫的事實錯誤。我們為
兩個基本任務收集了兩千多個資料，以及 225 個高品質註解資料，以作為代理任務。令人驚訝的是，我們發現最先進的代理，無論是日常情境還是生物醫學，在我們的
基準上都表現不佳或表現較差。然後，我們引入了一個簡單但有效的基準，稱為 BKGAgent。在廣泛使用的熱門知識圖表上，我們發現超過 90 個事實錯誤，這些錯誤為代理提供了發現情境，並證明了我們方法的有效性。程式碼和資料可在
https://github.com/westlake-autolab/BioKGBench 取得。</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

摘要：大型語言模型 (LLM) 的「軍備競賽」需要新穎、具挑戰性且多樣化的基準來忠實檢驗其進度。我們推出 GraphArena，這是一個基準工具，旨在使用來自知識圖譜、社交網路和分子結構等多樣化情境的數百萬個真實世界圖形，針對圖形計算問題評估 LLM。GraphArena 提供一系列 10 個計算任務，包含四個多項式時間（例如，最短距離）和六個 NP 完全挑戰（例如，旅行推銷員問題）。它具有一個嚴謹的評估架構，將 LLM 輸出分類為正確、次佳（可行但非最佳）或幻覺（格式正確但不可行）。對包括 GPT-4o 和 LLaMA3-70B-Instruct 在內的 10 個領先 LLM 的評估顯示，即使是效能最佳的模型在處理更大、更複雜的圖形問題時仍會遇到困難，並出現幻覺問題。儘管應用了一系列策略，例如思考鏈提示，這些問題仍未解決。GraphArena 為現有的 LLM 基準提供了有價值的補充，並在 https://github.com/squareRoot3/GraphArena 開源。

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

摘要：大型語言模型 (LLM) 應用程式由 LLM 和非 LLM 元件組成，每個元件都會影響端對端延遲。儘管已針對最佳化 LLM 推論做出許多努力，但端對端工作流程最佳化卻遭到忽略。現有架構採用粗略的編排與任務模組，將最佳化限制在每個模組內，並產生次佳的排程決策。我們提出細緻的端對端編排，它使用任務原語作為基本單位，並將每個查詢的工作流程表示為原語層級資料流圖。這明確地揭露了更大的設計空間，在不同模組的原語之間啟用平行化和管線最佳化，並加強排程以改善應用程式層級效能。我們建構 Teola，一個實作此架構的 LLM 應用程式創新編排架構。全面的實驗顯示，Teola 能在各種熱門 LLM 應用程式中，比現有系統快上 2.09 倍。

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

摘要：類似於專注於彌合具體導航中視覺與語言差距的視覺語言導航 (VLN) 任務，新的會面 (RVS) 任務需要使用非順序導航指令和地圖推理異中心空間關係（與觀察者的觀點無關）。然而，在沒有訓練資料的新環境中，效能會大幅下降。使用與座標配對的開源說明（例如，維基百科）提供了訓練資料，但由於空間導向文字有限，導致地理位置解析度低。我們提出了一種大規模擴充方法，使用現成的地理空間資料為新環境產生高品質的合成資料。我們的建構方法建立了一個基礎知識圖，擷取實體關係。取樣的實體和關係（「商店在學校北邊」）透過以下方式產生導航指令：(i) 使用無關乎語境的文法 (CFG) 產生許多範本來嵌入特定實體和關係；(ii) 將實體和關係輸入大型語言模型 (LLM) 以產生指令。在 RVS 上的全面評估顯示，我們的做法將未見過環境中的 100 公尺準確度提升了 45.83%。此外，我們證明使用基於 CFG 的擴充所訓練的模型，在未見過和見過環境中，都比使用基於 LLM 的擴充所訓練的模型獲得了更好的效能。這些發現表明，在以前未知的環境中，明確建構用於基於文字的地理空間推理的空間資訊的潛在優勢，可以解鎖資料稀少的場景。

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

摘要：儘管有顯著的進展，但對於大型語言模型 (LLM) 如何利用知識進行推理的理解仍然有限。為了解決這個問題，我們提出了一種方法，將複雜的真實世界問題解構成一個圖形，將每個問題表示為一個節點，其中包含解決問題所需的背景知識的父節點。我們開發了 DepthQA 資料集，將問題解構成三個深度：(i) 回憶概念知識，(ii) 應用程序知識，以及 (iii) 分析策略知識。基於一個階層圖形，我們量化了正向差異，LLM 在較簡單的子問題和複雜問題上的效能差異。我們也測量了反向差異，其中 LLM 能回答複雜問題，但在較簡單的問題上卻有困難。我們的分析顯示，較小的模型比較大的模型有更多的差異。此外，透過多回合互動引導模型從較簡單到複雜的問題，可以改善所有模型規模的效能，突顯了結構化中間步驟在知識推理中的重要性。這項工作增進了我們對 LLM 推理的理解，並提出了改善其問題解決能力的方法。

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

摘要：<paragraph>雖然預訓練大型視訊語言模型 (VLM) 已展現出對各種下游視訊語言任務的顯著潛力，但現有的 VLM 仍可能受到某些常見限制的影響，例如粗粒度的跨模態對齊、對時間動態的建模不足、分離的視訊語言檢視。在這項工作中，我們以具備細粒度結構化時空對齊學習方法 (即 Finsta) 的增強 VLM 為目標。首先，我們以細粒度的場景圖 (SG) 結構表示輸入文字和視訊，兩者進一步統一到一個整體 SG (HSG) 中，以橋接兩個模態。然後，建立一個基於 SG 的框架，其中文字 SG (TSG) 使用圖形 Transformer 編碼，而視訊動態 SG (DSG) 和 HSG 則使用新穎的遞迴圖形 Transformer 建模，以進行空間和時間特徵傳播。進一步設計了一個時空高斯差分圖形 Transformer，以增強物體在時空維度中變化的感覺。接下來，根據 TSG 和 DSG 的細粒度結構特徵，我們分別執行以物件為中心的空間對齊和以謂詞為中心的時序對齊，增強視訊語言在空間和時間上的基礎。我們將方法設計為一個即插即用的系統，可以整合到現有的訓練良好的 VLM 中，以進一步擴充表示，而無需從頭開始訓練或依賴下游應用程式中的 SG 標註。在 12 個資料集上的 6 個代表性 VL 建模任務中，無論是在標準視訊場景還是長格式視訊場景中，Finsta 都持續改善現有的 13 個效能強大的 VLM，並在微調和零次學習設定中顯著更新目前的最新技術最終任務效能。</paragraph>

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

摘要：自然語言問答 (QA) 透過結構化資料來源（例如表格和知識圖譜 (KGs)）已廣泛研究，例如使用大型語言模型 (LLM)。主要解決方案包括問題轉換成形式化查詢解析和基於檢索的答案產生。然而，前者的現行方法通常會產生弱泛化，無法同時處理多個來源，而後者則受到可信度的限制。在本文中，我們提出 UnifiedTQA，一個可信賴的 QA 框架，能夠以統一的方式同時支援多種類型的結構化資料。為此，它採用了一種 LLM 友善且統一的知識表示方法，稱為條件圖 (CG)，並使用 LLM 和基於示範的二階方法進行 CG 查詢。為了加強，它還配備了動態示範檢索。我們已經使用涵蓋 3 種類型結構化資料的 5 個基準評估 UnifiedTQA。它優於 2 種現有的統一結構化資料 QA 方法，並且與特定於資料類型的基線相比，它在其中 2 個基準上達到了最先進的水平。此外，我們展示了我們的方法在更通用的 QA 任務、混合結構化資料的 QA 和跨結構化資料的 QA 中的潛力。

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias Bürger, Zacharias Häringer, Jörg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

摘要：在本文中，我們提出了快速優化器基準 (FOB)，這是一個用於在開發過程中評估深度學習優化器的工具。基準支持來自多個領域的任務，例如電腦視覺、自然語言處理和圖形學習。重點在於方便使用，具有人類可讀的 YAML 配置、SLURM 整合和繪圖程式。FOB 可以與現有的超參數優化 (HPO) 工具一起使用，因為它可以處理訓練和恢復運行。模組化設計能夠整合到自訂管線中，只需將其用作任務集合即可。我們展示了一個優化器比較作為我們工具的使用範例。FOB 可以從 GitHub 找到：https://github.com/automl/FOB。

##### **Cascading Large Language Models for Salient Event Graph Generation**
2406.18449v1 by Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He

Generating event graphs from long documents is challenging due to the
inherent complexity of multiple tasks involved such as detecting events,
identifying their relationships, and reconciling unstructured input with
structured graphs. Recent studies typically consider all events with equal
importance, failing to distinguish salient events crucial for understanding
narratives. This paper presents CALLMSAE, a CAscading Large Language Model
framework for SAlient Event graph generation, which leverages the capabilities
of LLMs and eliminates the need for costly human annotations. We first identify
salient events by prompting LLMs to generate summaries, from which salient
events are identified. Next, we develop an iterative code refinement prompting
strategy to generate event relation graphs, removing hallucinated relations and
recovering missing edges. Fine-tuning contextualised graph generation models on
the LLM-generated graphs outperforms the models trained on CAEVO-generated
data. Experimental results on a human-annotated test set show that the proposed
method generates salient and more accurate graphs, outperforming competitive
baselines.

摘要：由於涉及多項任務的內在複雜性，例如偵測事件、識別其關係，以及調和非結構化輸入與結構化圖表，因此從長篇文件產生事件圖表是一項挑戰。最近的研究通常將所有事件視為同等重要，未能區分對理解敘事至關重要的顯著事件。本文提出了 CALLMSAE，一個用於生成顯著事件圖表的層疊式大型語言模型框架，它利用了 LLM 的功能，並消除了對昂貴的人工標註的需求。我們首先透過提示 LLM 產生摘要來識別顯著事件，從中識別出顯著事件。接下來，我們開發了一種反覆的程式碼精煉提示策略來產生事件關係圖表，移除幻覺關係並恢復遺失的邊緣。在 LLM 生成的圖表上微調情境化圖表生成模型，其表現優於在 CAEVO 生成的資料上訓練的模型。在人工標註的測試集上的實驗結果顯示，所提出的方法產生了顯著且更準確的圖表，優於競爭性的基準。

##### **Sanskrit Knowledge-based Systems: Annotation and Computational Tools**
2406.18276v1 by Hrishikesh Terdalkar

We address the challenges and opportunities in the development of knowledge
systems for Sanskrit, with a focus on question answering. By proposing a
framework for the automated construction of knowledge graphs, introducing
annotation tools for ontology-driven and general-purpose tasks, and offering a
diverse collection of web-interfaces, tools, and software libraries, we have
made significant contributions to the field of computational Sanskrit. These
contributions not only enhance the accessibility and accuracy of Sanskrit text
analysis but also pave the way for further advancements in knowledge
representation and language processing. Ultimately, this research contributes
to the preservation, understanding, and utilization of the rich linguistic
information embodied in Sanskrit texts.

摘要：我們著手解決梵語知識系統開發中的挑戰和機會，重點在於問題解答。透過提出一個用於自動建構知識圖譜的架構，導入用於本體驅動和一般用途任務的註解工具，並提供多樣化的網路介面、工具和軟體函式庫，我們對計算梵語領域做出了重大貢獻。這些貢獻不僅增強了梵語文本分析的可存取性和準確性，也為知識表徵和語言處理的進一步進展鋪平了道路。最終，這項研究有助於保存、理解和利用梵語文本中蘊含的豐富語言資訊。

##### **Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**
2406.18085v1 by Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao

Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like
(h, r, ?) in different languages by reasoning a tail entity t thus improving
multilingual knowledge graphs. Previous studies leverage multilingual
pretrained language models (PLMs) and the generative paradigm to achieve mKGC.
Although multilingual pretrained language models contain extensive knowledge of
different languages, its pretraining tasks cannot be directly aligned with the
mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit
a pronounced English-centric bias. This makes it difficult for mKGC to achieve
good results, particularly in the context of low-resource languages. To
overcome previous problems, this paper introduces global and local knowledge
constraints for mKGC. The former is used to constrain the reasoning of answer
entities, while the latter is used to enhance the representation of query
contexts. The proposed method makes the pretrained model better adapt to the
mKGC task. Experimental results on public datasets demonstrate that our method
outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and
16.03%, which indicates that our proposed method has significant enhancement on
mKGC.

摘要：多語言知識圖譜完成 (mKGC) 旨在透過推理尾部實體 t 來解決不同語言中的查詢，例如 (h, r, ?)，進而改善多語言知識圖譜。先前的研究利用多語言預訓練語言模型 (PLM) 和生成範例來達成 mKGC。儘管多語言預訓練語言模型包含不同語言的廣泛知識，但其預訓練任務無法直接與 mKGC 任務對齊。此外，目前大多數的知識圖譜和 PLM 都展現出明顯的英語中心偏誤。這使得 mKGC 難以達成良好的結果，特別是在低資源語言的脈絡中。為了克服先前的問題，本文針對 mKGC 引入了全域與局部知識限制。前者用於限制答案實體的推理，而後者用於加強查詢脈絡的表示。所提出的方法使得預訓練模型能更好地適應 mKGC 任務。公開資料集上的實驗結果顯示，我們的模型在 Hits@1 和 Hits@10 上平均優於先前的 SOTA 12.32% 和 16.03%，這表示我們提出的方法顯著地增強了 mKGC。

##### **AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**
2406.18060v1 by Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang

Fine-tuning large language models (LLMs) has achieved remarkable performance
across various natural language processing tasks, yet it demands more and more
memory as model sizes keep growing. To address this issue, the recently
proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs
using only forward passes, thereby avoiding the need for a backpropagation
graph. However, significant performance drops and a high risk of divergence
have limited their widespread adoption. In this paper, we propose the Adaptive
Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed
to improve the performance and convergence of the ZO methods. To enhance
dimension-dependent ZO estimation accuracy, we introduce a fast-forward,
low-parameter tensorized adapter. To tackle the frequently observed divergence
issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number
schedule that guarantees convergence. Detailed theoretical analysis and
extensive experimental results on Roberta-Large and Llama-2-7B models
substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory
efficiency, and convergence speed.

摘要：微调大型语言模型 (LLM) 在各种自然语言处理任务中取得了显著的性能，但随着模型规模的不断扩大，它对内存的需求也越来越大。为了解决这个问题，最近提出的内存高效零阶 (MeZO) 方法试图仅使用前向传递来微调 LLM，从而避免了对反向传播图的需求。然而，严重的性能下降和发散的高风险限制了它们的广泛采用。在本文中，我们提出了自适应零阶张量训练自适应 (AdaZeta) 框架，专门设计用于提高 ZO 方法的性能和收敛性。为了增强维度相关的 ZO 估计精度，我们引入了一个快速前向、低参数张量化适配器。为了解决在大规模 ZO 微调任务中经常观察到的发散问题，我们提出了一个自适应查询数量计划，以保证收敛性。对 Roberta-Large 和 Llama-2-7B 模型的详细理论分析和广泛的实验结果证明了我们的 AdaZeta 框架在准确性、内存效率和收敛速度方面的有效性。

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

摘要：目前透過靜態基準評估大型語言模型 (LLM) 的範例伴隨著顯著的限制，例如容易受到資料污染，以及缺乏適應 LLM 不斷演進的能力。因此，迫切需要能夠適應並產生具有受控複雜性的評估資料的評估方法。在這項工作中，我們透過自適應推理圖形演化 (DARG) 引入 LLM 的動態評估，以動態延伸目前具有受控複雜性和多樣性的基準。具體來說，我們首先擷取目前基準中資料點的推理圖形，然後擾動推理圖形以產生新的測試資料。這些新產生的測試樣本可以有不同的複雜性層級，同時維持與原始基準類似的語言多樣性。我們進一步使用程式碼增強的 LLM 來確保新產生資料的標籤正確性。我們將 DARG 架構套用於四個領域中的各種推理任務，並使用 15 個最先進的 LLM。實驗結果顯示，幾乎所有 LLM 在複雜性增加的情況下都會出現效能下降，而某些 LLM 則表現出顯著的下降。此外，我們發現 LLM 在透過 DARG 產生具有較高複雜性層級的資料進行評估時，會表現出更多偏差。這些觀察結果提供了有用的見解，說明如何動態且自適應地評估 LLM。程式碼可在 https://github.com/SALT-NLP/DARG 取得。

##### **CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**
2406.17231v1 by Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao

Large language models have become integral to question-answering applications
despite their propensity for generating hallucinations and factually inaccurate
content. Querying knowledge graphs to reduce hallucinations in LLM meets the
challenge of incomplete knowledge coverage in knowledge graphs. On the other
hand, updating knowledge graphs by information extraction and knowledge graph
completion faces the knowledge update misalignment issue. In this work, we
introduce a collaborative augmentation framework, CogMG, leveraging knowledge
graphs to address the limitations of LLMs in QA scenarios, explicitly targeting
the problems of incomplete knowledge coverage and knowledge update
misalignment. The LLMs identify and decompose required knowledge triples that
are not present in the KG, enriching them and aligning updates with real-world
demands. We demonstrate the efficacy of this approach through a supervised
fine-tuned LLM within an agent framework, showing significant improvements in
reducing hallucinations and enhancing factual accuracy in QA responses. Our
code and video are publicly available.

摘要：大型語言模型已成為問答應用程式中不可或缺的一部分，儘管它們傾向於產生幻覺和事實不正確的內容。查詢知識圖表以減少 LLM 中的幻覺會遇到知識圖表中知識覆蓋不完整的挑戰。另一方面，通過資訊萃取和知識圖表完成來更新知識圖表會面臨知識更新錯位問題。在這項工作中，我們引入了協作擴充架構 CogMG，利用知識圖表來解決 LLM 在 QA 場景中的限制，明確針對不完整的知識覆蓋和知識更新錯位問題。LLM 識別並分解 KG 中不存在的所需知識三元組，豐富它們並將更新與現實世界的需求保持一致。我們透過代理架構中監督微調的 LLM 展示了這種方法的功效，顯示出在減少幻覺和增強 QA 回應中的事實準確性方面有顯著的改進。我們的程式碼和影片公開提供。

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

摘要：訊息傳遞神經網路 (MPNN) 透過交換鄰近節點之間的資訊來處理圖形。MPNN 已成功應用於各種節點、邊緣和圖形層級的任務，例如分子科學、電腦視覺、自然語言處理和組合最佳化。然而，大多數 MPNN 需要大量標籤資料才能進行訓練，這可能會很昂貴且耗時。在這項工作中，我們探討了在圖形神經網路中使用各種未訓練的訊息傳遞層，也就是說，我們移除了所有用於在訊息傳遞步驟中轉換節點特徵的可訓練參數，這是熱門訊息傳遞架構的變體。專注於連結預測，我們發現未訓練的訊息傳遞層可以產生具有競爭力，甚至優於完全訓練的 MPNN 的效能，尤其是在存在高維特徵的情況下。我們透過將未訓練的訊息傳遞層隱含產生的特徵的內積與基於路徑的拓撲節點相似度測量關聯，提供未訓練訊息傳遞的理論分析。因此，未訓練的訊息傳遞架構可以視為一種高度有效且可解釋的連結預測方法。

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

摘要：因果推理是人類詮釋世界的基石。為了對因果關係建模和推理，因果圖提供了一個簡潔而有效的解決方案。鑑於語言模型的驚人進步，一個關鍵問題出現了：它們真的能理解因果圖嗎？為此，我們率先對語言模型對因果圖的理解進行了調查。具體來說，我們開發了一個框架來定義因果圖理解，通過從不同學科（例如哲學和心理學）衍生的四個實用標準來評估語言模型的行為。然後，我們開發了 CLEAR，一個新的基準，它定義了三個複雜性級別，並涵蓋了這些級別中的 20 個基於因果圖的任務。最後，基於我們的框架和基準，我們對六個領先的語言模型進行了廣泛的實驗，並總結了五項實證發現。我們的結果表明，儘管語言模型展示了對因果圖的初步理解，但仍有很大的改進潛力。我們的項目網站位於 https://github.com/OpenCausaLab/CLEAR。

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

摘要：知識增強預訓練語言模型 (KEPLM) 利用知識圖譜 (KG) 中的關聯三元組，並透過自我監督式學習將這些外部資料來源整合到語言模型中。先前的研究將知識增強視為兩個獨立的操作，即知識注入和知識整合。在本文中，我們建議使用分層強化學習 (KEHRL) 學習知識增強語言表徵，這共同解決了偵測知識注入位置和將外部知識整合到模型中的問題，以避免注入不準確或不相關的知識。具體來說，高階強化學習 (RL) 代理使用內部和先驗知識，反覆偵測文字中知識注入的重要位置，這會過濾掉較不重要的實體，以避免轉移知識學習方向。一旦選定實體位置，就會觸發相關的三元組過濾模組，透過二進制動作動態精煉與多義實體相關的三元組。實驗驗證了 KEHRL 在探查事實知識和增強模型在各種自然語言理解任務上的效能。

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

摘要：文本到图像 (T2I) 生成模型的快速进步使得合成由文本描述引导的高质量图像成为可能。尽管取得了这些重大进展，但这些模型在生成与输入文本相矛盾的内容方面通常很敏感，这对它们的可靠性和实际部署提出了挑战。为了解决这个问题，我们引入了一个新颖的基于扩散的框架，以显着增强生成图像与其相应描述的一致性，解决视觉输出和文本输入之间的不一致性。我们的框架建立在对不一致现象的全面分析之上，根据它们在图像中的表现对它们进行分类。利用最先进的大型语言模块，我们首先提取对象并构建知识图谱来预测这些对象在潜在生成的图像中的位置。然后，我们将最先进的可控图像生成模型与视觉文本生成模块集成在一起，以生成与原始提示一致的图像，并由预测的对象位置引导。通过在高级多模态幻觉基准上进行广泛的实验，我们展示了我们的方法在准确生成图像方面的有效性，而不会与原始提示不一致。可以通过 https://github.com/TruthAI-Lab/PCIG 访问代码。

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

摘要：健康監控系統透過持續收集生理和行為資料，徹底改變了現代醫療保健，這些資料對於預防措施和早期健康干預至關重要。雖然將這些資料與大型語言模型 (LLM) 整合，已展現出提供互動式健康建議的潛力，但傳統方法（例如檢索擴充生成 (RAG) 和微調）通常無法充分利用穿戴式裝置中複雜、多面向且與時間相關的資料。這些傳統方法通常會提供有限的可行且個人化的健康見解，因為它們無法動態整合和詮釋不同的健康資料串流。為了解決這個問題，本文介紹了一個圖形擴充 LLM 架構，旨在大幅提升健康見解的個人化和清晰度。這個架構利用階層式圖形結構，擷取患者之間和患者內部的關係，並使用從 Random Forest 模型衍生的動態特徵重要性評分，豐富 LLM 提示。透過一項睡眠分析案例研究（在 COVID-19 封鎖期間針對 20 名大學生進行）證明了這個方法的有效性，突顯了我們的模型在有效產生可行且個人化的健康見解方面的潛力。我們利用另一個 LLM 評估見解的相關性、全面性、可行性和個人化，滿足了模型有效處理和詮釋複雜健康資料的關鍵需求。我們的研究結果顯示，使用我們的架構擴充提示，可以在所有 4 個標準中大幅改善。透過我們的架構，我們可以引發精心設計、更周全的回應，針對特定患者量身打造。

##### **GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**
2406.16176v1 by Qiming Wu, Zichen Chen, Will Corcoran, Misha Sra, Ambuj K. Singh

Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 中取得了顯著的成功，在處理和理解文本數據方面表現出顯著的能力。然而，最近的研究發現 LLM 在推理圖形結構數據的能力方面存在局限性。為了解決這個差距，我們引入了 GraphEval2000，第一個全面的圖形數據集，包含 40 個圖形數據結構問題以及 2000 個測試用例。此外，我們還引入了基於 GraphEval2000 的評估框架，旨在通過編碼挑戰評估 LLM 的圖形推理能力。我們的數據集將測試用例分為四個主要類別和四個子類別，確保進行全面的評估。我們在 GraphEval2000 上評估了八個流行的 LLM，結果表明，與無向圖相比，LLM 對有向圖的理解更好。雖然私有 LLM 持續優於開源模型，但性能差距正在縮小。此外，為了提高我們評估框架的可用性，我們提出了結構化符號分解 (SSD)，一種基於指令的方法，旨在增強 LLM 在 GraphEval2000 上的性能。結果表明，SSD 分別提高了 GPT-3.5、GPT-4 和 GPT-4o 在複雜圖形問題上的性能，分別增加了 11.11%、33.37% 和 33.37%。

##### **Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**
2406.15992v1 by Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov

Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question.

摘要：大型語言模型 (LLM) 對於具有隱式圖形結構的問題展現出巨大的潛力，而近期研究則透過專業指令調整來增強 LLM 的圖形推理能力。由此產生的「圖形 LLM」僅在分布內設定中進行評估，因此 LLM 是否學習到可概括的圖形推理技能，或僅僅記憶合成訓練資料中的模式，仍未獲得充分探討。為此，我們提出 NLGift 基準，這是一個 LLM 圖形推理概括評估套件：LLM 是否可以超越合成訓練資料中的語義、數值、結構推理模式，並提升在真實世界基於圖形的任務中的效用。透過兩個 LLM 在四個圖形推理任務中的廣泛實驗證明，儘管在簡單模式（語義、數值）上的概括令人滿意，但 LLM 難以在推理和真實世界模式中概括，對合成圖形調整對於具有基礎網路結構的真實世界任務的益處提出質疑。我們探討了三種策略來改善 LLM 圖形推理概括，我們發現，儘管訓練後對齊對真實世界任務最有希望，但賦能 LLM 圖形推理以超越模式記憶仍然是一個開放的研究問題。

##### **LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**
2406.15859v2 by Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao, Bei Ye, Fei Du, Shirui Pan, Yuxiao Li

Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust.

摘要：推薦系統在分析使用者與項目之間複雜的關係，提升各種網路應用程式的使用者體驗中扮演著關鍵角色。知識圖譜 (KG) 已被廣泛用於提升推薦系統的效能。然而，KG 眾所周知是有雜訊且不完整的，這使得難以提供可靠的推薦結果說明。一個可解釋的推薦系統對於產品開發和後續決策至關重要。為了應對這些挑戰，我們引入了一個新穎的推薦系統，它結合了大型語言模型 (LLM) 和 KG 來加強推薦並提供可解釋的結果。具體來說，我們首先利用 LLM 的力量來擴充 KG 重建。LLM 理解並將使用者評論分解成新的三元組，並將其新增到 KG 中。透過這種方式，我們可以用表達使用者偏好的可解釋路徑來豐富 KG。為了增強在擴充 KG 上的推薦，我們引入了一個新穎的子圖推理模組，它可以有效地衡量節點的重要性，並找出推薦的理由。最後，這些推理路徑被輸入到 LLM 中，以產生推薦結果的可解釋說明。我們的做法大幅提升了推薦系統的有效性和可解釋性，特別是在傳統方法失效的交叉銷售情境中。我們的做法的有效性已在四個開放的真實世界資料集上經過嚴格測試，我們的做法展示出比當代最先進技術更卓越的效能，平均提升了 12%。我們的模型在一家跨國工程和技術公司交叉銷售推薦系統中的應用進一步突顯了它的實用性，以及透過提升準確性和使用者信任來重新定義推薦實務的潛力。

##### **Large Language Models for Link Stealing Attacks Against Graph Neural Networks**
2406.16963v1 by Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu

Graph data contains rich node features and unique edge information, which
have been applied across various domains, such as citation networks or
recommendation systems. Graph Neural Networks (GNNs) are specialized for
handling such data and have shown impressive performance in many applications.
However, GNNs may contain of sensitive information and susceptible to privacy
attacks. For example, link stealing is a type of attack in which attackers
infer whether two nodes are linked or not. Previous link stealing attacks
primarily relied on posterior probabilities from the target GNN model,
neglecting the significance of node features. Additionally, variations in node
classes across different datasets lead to different dimensions of posterior
probabilities. The handling of these varying data dimensions posed a challenge
in using a single model to effectively conduct link stealing attacks on
different datasets. To address these challenges, we introduce Large Language
Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively
integrate textual features and exhibit strong generalizability, enabling
attacks to handle diverse data dimensions across various datasets. We design
two distinct LLM prompts to effectively combine textual features and posterior
probabilities of graph nodes. Through these designed prompts, we fine-tune the
LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the
LLM using multiple datasets and enable the LLM to learn features from different
datasets simultaneously. Experimental results show that our approach
significantly enhances the performance of existing link stealing attack tasks
in both white-box and black-box scenarios. Our method can execute link stealing
attacks across different datasets using only a single model, making link
stealing attacks more applicable to real-world scenarios.

摘要：圖形數據包含豐富的節點特徵和獨特的邊緣資訊，已應用於各種領域，例如引文網路或推薦系統。圖形神經網路 (GNN) 專門用於處理此類數據，並在許多應用中展現出令人印象深刻的效能。然而，GNN 可能包含敏感資訊，且容易受到隱私攻擊。例如，連結竊取是一種攻擊，攻擊者推斷兩個節點是否連結。先前的連結竊取攻擊主要依賴於目標 GNN 模型的後驗機率，忽略節點特徵的重要性。此外，不同資料集中的節點類別變化導致後驗機率的不同維度。處理這些不同的資料維度在使用單一模型對不同資料集執行連結竊取攻擊時構成一項挑戰。為了應對這些挑戰，我們引入了大型語言模型 (LLM) 來對 GNN 執行連結竊取攻擊。LLM 可以有效整合文字特徵並展現強大的泛化能力，使攻擊能夠處理不同資料集中的不同資料維度。我們設計了兩個不同的 LLM 提示，以有效結合文字特徵和圖形節點的後驗機率。透過這些設計的提示，我們微調 LLM 以適應連結竊取攻擊任務。此外，我們使用多個資料集微調 LLM，並使 LLM 能夠同時從不同的資料集中學習特徵。實驗結果顯示，我們的做法顯著提升了現有連結竊取攻擊任務在白盒和黑盒場景中的效能。我們的模型僅使用單一模型就能跨不同資料集執行連結竊取攻擊，使連結竊取攻擊更適用於實際場景。

##### **Inferring Pluggable Types with Machine Learning**
2406.15676v1 by Kazi Amanul Islam Siddiqui, Martin Kellogg

Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes.

摘要：可插拔类型系统允许程序员扩展编程语言的类型系统，以执行程序员定义的语义属性。可插拔类型系统难以部署在遗留代码库中，因为它们要求程序员手动编写类型注释。本文研究如何使用机器学习自动推断类型限定符。我们提出了一种新颖的表示形式 NaP-AST，它对类型限定符的有效推断编码了最小的数据流提示。我们评估了用于推断类型限定符的几种模型架构，包括图转换器网络、图卷积网络和大语言模型。我们通过将这些模型应用于 NullAway 可插拔类型检查器的先前评估中的 12 个开源程序，进一步验证了这些模型，除了一个未注释的项目外，降低了所有项目的警告。我们发现 GTN 表现最佳，召回率为 0.89，精确率为 0.6。此外，我们进行了一项研究，以估计训练模型良好性能所需的 Java 类数量。对于我们的可行性研究，性能提高了约 16k 个类，并且由于在 22k 个类左右过度拟合而恶化。

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v2 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

摘要：科學文獻的搜尋通常是探索性的，使用者可能還不熟悉某個特定領域或概念，但有興趣進一步了解它。然而，現有的科學文獻搜尋系統通常專門針對基於關鍵字的查詢搜尋，限制了探索的可能性。我們提出 NLP-KG，這是一個功能豐富的系統，旨在支援在不熟悉的自然語言處理 (NLP) 領域中探索研究文獻。除了語意搜尋之外，NLP-KG 使用者可以輕鬆找到提供對感興趣領域的快速介紹的綜述論文。此外，研究領域階層圖讓使用者能夠熟悉一個領域及其相關領域。最後，聊天介面允許使用者詢問有關不熟悉的概念或 NLP 中特定文章的問題，並獲得從科學出版物中擷取的知識為基礎的答案。我們的系統為使用者提供全面的探索可能性，協助他們調查不同領域之間的關係，理解 NLP 中不熟悉的概念，並找到相關的研究文獻。示範、影片和程式碼可在以下網址取得：
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp。

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

摘要：對話政策在開發任務導向對話系統中扮演著至關重要的角色，然而它們的開發和維護具有挑戰性，且通常需要對話建模專家的大量工作。雖然在許多情況下，大量對話資料可用於手邊的工作，但人們缺乏一種有效的解決方案，無法從這些資料中提取對話政策。在本文中，我們透過首先說明大型語言模型 (LLM) 如何透過將對話轉換成由規範形式組成的統一中間表示，從資料集中提取對話政策，來說明如何解決這個差距。然後，我們提出了一種利用可控且可解釋的基於圖形的方法來產生對話政策的新方法。透過將對話中的規範形式組合成流網路，我們發現執行圖形遍歷演算法有助於提取對話流。這些流比透過提示 LLM 提取的流更能代表底層互動。我們的技術專注於讓對話設計師擁有更大的控制權，提供一種生產力工具來改善開發對話政策的過程。

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v2 by Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

摘要：近年来，预训练模型在自然语言处理 (NLP)、计算机视觉 (CV) 和生命科学领域取得了重大进展。NLP 和 CV 的重大进步主要由模型参数和数据量的扩展推动，这一现象现在被认为是缩放定律。然而，探索分子预训练模型中缩放定律的研究仍未得到探索。在这项工作中，我们提出了 Uni-Mol2，一种创新的分子预训练模型，它利用双轨转换器有效地整合原子级、图级和几何结构级的特征。除此之外，我们系统地研究了分子预训练模型中的缩放定律，描述了验证损失与模型大小、数据集大小和计算资源之间的幂律相关性。因此，我们成功地将 Uni-Mol2 扩展到 11 亿个参数，通过对 8 亿个构象进行预训练，使其成为迄今为止最大的分子预训练模型。大量的实验表明，随着模型大小的增长，下游任务持续得到改善。具有 1.1B 参数的 Uni-Mol2 也优于现有方法，在 QM9 上实现了平均 27% 的改进，在 COMPAS-1D 数据集上实现了 14% 的改进。

##### **Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**
2406.14745v2 by Sefika Efeoglu, Adrian Paschke

Information Extraction (IE) is crucial for converting unstructured data into
structured formats like Knowledge Graphs (KGs). A key task within IE is
Relation Extraction (RE), which identifies relationships between entities in
text. Various RE methods exist, including supervised, unsupervised, weakly
supervised, and rule-based approaches. Recent studies leveraging pre-trained
language models (PLMs) have shown significant success in this area. In the
current era dominated by Large Language Models (LLMs), fine-tuning these models
can overcome limitations associated with zero-shot LLM prompting-based RE
methods, especially regarding domain adaptation challenges and identifying
implicit relations between entities in sentences. These implicit relations,
which cannot be easily extracted from a sentence's dependency tree, require
logical inference for accurate identification. This work explores the
performance of fine-tuned LLMs and their integration into the Retrieval
Augmented-based (RAG) RE approach to address the challenges of identifying
implicit relations at the sentence level, particularly when LLMs act as
generators within the RAG framework. Empirical evaluations on the TACRED,
TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant
performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,
and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,
where implicit relations are common, surpassing previous results on this
dataset. Additionally, our method outperforms previous works on TACRED, TACREV,
and Re-TACRED, demonstrating exceptional performance across diverse evaluation
scenarios.

摘要：資訊萃取（IE）對於將非結構化資料轉換成知識圖譜（KG）等結構化格式至關重要。IE 中的一項關鍵任務是關係萃取（RE），用於識別文字中實體之間的關係。RE 方法多種多樣，包括監督式、非監督式、弱監督式和基於規則的方法。最近利用預訓練語言模型（PLM）的研究已在此領域展現顯著成果。在大型語言模型（LLM）主導的當前時代，微調這些模型可以克服與零次學習 LLM 提示式 RE 方法相關的限制，特別是在領域適應挑戰和識別句子中實體之間的隱含關係方面。這些隱含關係無法輕易從句子的依賴樹中萃取，需要邏輯推論才能準確識別。這項工作探討了微調後的 LLM 的效能，以及它們整合到檢索增強式（RAG）RE 方法中以解決在句子層級識別隱含關係的挑戰，特別是在 LLM 在 RAG 框架中充當生成器的時後。在 TACRED、TACRED-Revisited（TACREV）、Re-TACRED 和 SemEVAL 資料集上的經驗評估顯示，微調後的 LLM，包括 Llama2-7B、Mistral-7B 和 T5（大型），大幅提升了效能。值得注意的是，我們的做法在 SemEVAL 上取得了顯著的進展，因為隱含關係很常見，超越了這個資料集上的先前結果。此外，我們的做法在 TACRED、TACREV 和 Re-TACRED 上優於先前的工作，證明了在不同的評估場景中表現出色的效能。

##### **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**
2406.14703v1 by Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

The idea of personality in descriptive psychology, traditionally defined
through observable behavior, has now been extended to Large Language Models
(LLMs) to better understand their behavior. This raises a question: do LLMs
exhibit distinct and consistent personality traits, similar to humans? Existing
self-assessment personality tests, while applicable, lack the necessary
validity and reliability for precise personality measurements. To address this,
we introduce TRAIT, a new tool consisting of 8K multi-choice questions designed
to assess the personality of LLMs with validity and reliability. TRAIT is built
on the psychometrically validated human questionnaire, Big Five Inventory (BFI)
and Short Dark Triad (SD-3), enhanced with the ATOMIC10X knowledge graph for
testing personality in a variety of real scenarios. TRAIT overcomes the
reliability and validity issues when measuring personality of LLM with
self-assessment, showing the highest scores across three metrics: refusal rate,
prompt sensitivity, and option order sensitivity. It reveals notable insights
into personality of LLM: 1) LLMs exhibit distinct and consistent personality,
which is highly influenced by their training data (i.e., data used for
alignment tuning), and 2) current prompting techniques have limited
effectiveness in eliciting certain traits, such as high psychopathy or low
conscientiousness, suggesting the need for further research in this direction.

摘要：在傳統心理學中，人格的概念是透過可觀察的行為來定義的，現在已擴展到大型語言模型 (LLM)，以更了解其行為。這引發了一個問題：LLM 是否像人類一樣表現出獨特且一致的人格特質？現有的自我評量人格測驗雖然適用，但缺乏精確人格測量所需的效度和信度。為了解決這個問題，我們引入了 TRAIT，這是一個由 8K 個多重選擇題組成的全新工具，旨在評估 LLM 的人格，並具備效度和信度。TRAIT 建構於經過心理測量驗證的人類問卷，大五人格量表 (BFI) 和簡短黑暗三元組 (SD-3)，並增強了 ATOMIC10X 知識圖譜，以便在各種實際場景中測試人格。TRAIT 克服了使用自我評量測量 LLM 人格時的信度和效度問題，在三項指標（拒絕率、提示敏感度和選項順序敏感度）中顯示出最高分。它揭示了 LLM 人格的重要見解：1) LLM 表現出獨特且一致的人格，這深受其訓練資料（即用於對齊調整的資料）影響，以及 2) 目前的提示技術在引發某些特質（例如高精神病質或低盡責性）方面效果有限，這表示需要進一步研究這個方向。

##### **TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**
2406.14683v1 by Jiarui Feng, Hao Liu, Lecheng Kong, Yixin Chen, Muhan Zhang

In this report, we present TAGLAS, an atlas of text-attributed graph (TAG)
datasets and benchmarks. TAGs are graphs with node and edge features
represented in text, which have recently gained wide applicability in training
graph-language or graph foundation models. In TAGLAS, we collect and integrate
more than 23 TAG datasets with domains ranging from citation graphs to molecule
graphs and tasks from node classification to graph question-answering. Unlike
previous graph datasets and benchmarks, all datasets in TAGLAS have a unified
node and edge text feature format, which allows a graph model to be
simultaneously trained and evaluated on multiple datasets from various domains.
Further, we provide a standardized, efficient, and simplified way to load all
datasets and tasks. We also provide useful utils like text-to-embedding
conversion, and graph-to-text conversion, which can facilitate different
evaluation scenarios. Finally, we also provide standard and easy-to-use
evaluation utils. The project is open-sourced at
https://github.com/JiaruiFeng/TAGLAS and is still under construction. Please
expect more datasets/features in the future.

摘要：<paragraph>在本文中，我们提出了 TAGLAS，一个文本属性图 (TAG)
数据集和基准的图集。TAG 是具有以文本表示的节点和边特征的图，最近在训练
图语言或图基础模型中获得了广泛的应用。在 TAGLAS 中，我们收集并整合
了 23 个以上的 TAG 数据集，其领域从引文图到分子
图和任务，从节点分类到图问答。与
以前的图数据集和基准不同，TAGLAS 中的所有数据集都具有统一的
节点和边文本特征格式，这允许图模型在来自不同领域的多个数据集上同时训练和评估。
此外，我们提供了一种标准化、高效且简化的方式来加载所有
数据集和任务。我们还提供有用的实用程序，如文本到嵌入
转换，以及图到文本转换，这可以促进不同的
评估场景。最后，我们还提供标准且易于使用的
评估实用程序。该项目在
https://github.com/JiaruiFeng/TAGLAS 开源，并且仍在建设中。请
期待未来有更多的数据集/功能。</paragraph>

##### **HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**
2406.14655v1 by Jin Wang, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis

Enabling robots to autonomously perform hybrid motions in diverse
environments can be beneficial for long-horizon tasks such as material
handling, household chores, and work assistance. This requires extensive
exploitation of intrinsic motion capabilities, extraction of affordances from
rich environmental information, and planning of physical interaction behaviors.
Despite recent progress has demonstrated impressive humanoid whole-body control
abilities, they struggle to achieve versatility and adaptability for new tasks.
In this work, we propose HYPERmotion, a framework that learns, selects and
plans behaviors based on tasks in different scenarios. We combine reinforcement
learning with whole-body optimization to generate motion for 38 actuated joints
and create a motion library to store the learned skills. We apply the planning
and reasoning features of the large language models (LLMs) to complex
loco-manipulation tasks, constructing a hierarchical task graph that comprises
a series of primitive behaviors to bridge lower-level execution with
higher-level planning. By leveraging the interaction of distilled spatial
geometry and 2D observation with a visual language model (VLM) to ground
knowledge into a robotic morphology selector to choose appropriate actions in
single- or dual-arm, legged or wheeled locomotion. Experiments in simulation
and real-world show that learned motions can efficiently adapt to new tasks,
demonstrating high autonomy from free-text commands in unstructured scenes.
Videos and website: hy-motion.github.io/

摘要：<paragraph>讓機器人能夠在不同環境中自主執行混合動作，對於材料搬運、家務和工作協助等長期任務可能是有益的。這需要廣泛利用內在運動能力，從豐富的環境資訊中提取可負擔性，以及規劃物理互動行為。儘管最近的進展已證明令人印象深刻的人形全身控制能力，但它們仍難以實現新任務的多功能性和適應性。在這項工作中，我們提出 HYPERmotion，一個基於不同場景中的任務來學習、選擇和規劃行為的框架。我們結合強化學習與全身最佳化，為 38 個動作關節產生動作，並建立一個動作庫來儲存學習到的技能。我們將大型語言模型 (LLM) 的規劃和推理功能應用於複雜的運動操縱任務，構建一個階層式任務圖，其中包含一系列基本行為，以橋接低階執行與高階規劃。透過利用蒸餾空間幾何和 2D 觀測與視覺語言模型 (VLM) 的互動，將知識基礎化為機器人形態選擇器，以在單臂或雙臂、腿部或輪式運動中選擇適當的動作。模擬和現實世界的實驗表明，學習到的動作可以有效適應新任務，證明了在非結構化場景中從自由文字指令中獲得高度自主性。影片和網站：hy-motion.github.io/</paragraph>

##### **GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**
2406.14550v1 by Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng

Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks.

摘要：長語境能力對於大型語言模型 (LLM) 來說至關重要，可應對複雜且輸入長度較長的任務。儘管已針對 LLM 進行許多最佳化工作以應對長語境，但強健地處理長輸入仍存在挑戰。在本文中，我們介紹 GraphReader，一個基於圖表的代理系統，旨在透過將長文本結構化成一個圖表，並使用代理程式自主探索此圖表，來處理長文本。在收到問題後，代理程式首先進行逐步分析，並擬定一個合理計畫。然後，它會呼叫一組預定義的函式來讀取節點內容和鄰近節點，促進對圖表的粗略到精細探索。在整個探索過程中，代理程式會持續記錄新的見解，並反思當前情況，以最佳化處理程序，直到收集到足夠的資訊來產生答案。在 LV-Eval 資料集上的實驗結果顯示，GraphReader 使用 4k 語境視窗，在 16k 到 256k 的語境長度中，始終大幅優於 GPT-4-128k。此外，我們的做法在四個具有挑戰性的單跳和多跳基準測試中展現出卓越的效能。

##### **medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**
2406.14326v1 by Mingyi Jia, Junwen Duan, Yan Song, Jianxin Wang

Electronic Medical Records (EMRs), while integral to modern healthcare,
present challenges for clinical reasoning and diagnosis due to their complexity
and information redundancy. To address this, we proposed medIKAL (Integrating
Knowledge Graphs as Assistants of LLMs), a framework that combines Large
Language Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic
capabilities. medIKAL assigns weighted importance to entities in medical
records based on their type, enabling precise localization of candidate
diseases within KGs. It innovatively employs a residual network-like approach,
allowing initial diagnosis by the LLM to be merged into KG search results.
Through a path-based reranking algorithm and a fill-in-the-blank style prompt
template, it further refined the diagnostic process. We validated medIKAL's
effectiveness through extensive experiments on a newly introduced open-sourced
Chinese EMR dataset, demonstrating its potential to improve clinical diagnosis
in real-world settings.

摘要：電子病歷 (EMR) 雖然是現代醫療保健不可或缺的一部分，但由於其複雜性和資訊冗餘，對臨床推理和診斷提出了挑戰。為了解決這個問題，我們提出了 medIKAL（將知識圖譜整合為 LLM 的助理），一個將大型語言模型 (LLM) 與知識圖譜 (KG) 結合的框架，以增強診斷能力。medIKAL 根據醫療記錄中實體的類型為其分配加權重要性，從而能夠精確定位 KG 中的候選疾病。它創新地採用了類似殘差網路的方法，允許 LLM 的初步診斷與 KG 搜尋結果合併。透過基於路徑的重新排序演算法和填空式提示範本，進一步優化了診斷過程。我們透過對新推出的開源中文 EMR 資料集進行廣泛的實驗，驗證了 medIKAL 的有效性，證明了其在現實世界中改善臨床診斷的潛力。

##### **Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**
2406.14282v1 by Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen

Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data.

摘要：<paragraph>改善大型語言模型 (LLM) 在複雜問答 (QA) 情境中的效能一直是研究重點。最近的研究嘗試透過結合逐步規劃與外部擷取來增強 LLM 的效能。雖然對於 GPT-3.5 等進階模型來說很有效，但較小的 LLM 在分解複雜問題時會面臨挑戰，因此需要監督微調。先前的研究仰賴人工標註和教師 LLM 的知識萃取，這耗時且不夠精確。在本文中，我們介紹一個創新的架構，透過使用從知識圖譜 (KG) 中衍生的規劃資料來增強 LLM 的規劃能力。使用此資料微調的 LLM 改善了規劃能力，讓它們更能處理涉及擷取的複雜 QA 任務。在多個資料集（包括我們新提出的基準）上的評估突顯了我們架構的有效性，以及 KG 衍生規劃資料的好處。</paragraph>

##### **ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**
2406.14088v1 by Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF .

摘要：強化學習來自人類回饋 (RLHF) 是一種關鍵技術，用於賦能大型語言模型 (LLM) 應用程式。由於 RLHF 涉及多種運算工作負載和多個 LLM 之間的複雜依賴關係，直接採用監督式訓練的平行化技術可能會導致次佳效能。為了克服這個限制，我們提出了一種名為參數重新配置的新方法，它會動態重新分配叢集中的 LLM 參數，並在訓練期間調整平行化策略。在此概念的基礎上，我們引入了 ReaLHF，這是一個開創性的系統，能夠自動發現並執行 RLHF 訓練的高效執行計畫，並考量所需的演算法和硬體組態。ReaLHF 將 RLHF 的執行計畫制定為一個擴增資料流圖。基於此制定，ReaLHF 採用量身打造的搜尋演算法，搭配輕量級成本估計器，以發現高效的執行計畫。隨後，執行時間引擎透過有效平行化運算和重新分配參數，來部署所選的計畫。我們在 LLaMA-2 模型上評估 ReaLHF，該模型最多有 $4\times70$0 億個參數和 128 個 GPU。實驗結果顯示，與基準相比，ReaLHF 的速度提升了 $2.0-10.6\times$。此外，ReaLHF 生成的執行計畫比基於 Megatron-LM 的啟發式方法，平均效能提升了 $26\%$。ReaLHF 的原始程式碼公開於 https://github.com/openpsi-project/ReaLHF。

##### **HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**
2406.14021v1 by Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian

Recently there has been a surge of interest in extending the success of large
language models (LLMs) to graph modality, such as social networks and
molecules. As LLMs are predominantly trained with 1D text data, most existing
approaches adopt a graph neural network to represent a graph as a series of
node tokens and feed these tokens to LLMs for graph-language alignment. Despite
achieving some successes, existing approaches have overlooked the hierarchical
structures that are inherent in graph data. Especially, in molecular graphs,
the high-order structural information contains rich semantics of molecular
functional groups, which encode crucial biochemical functionalities of the
molecules. We establish a simple benchmark showing that neglecting the
hierarchical information in graph tokenization will lead to subpar
graph-language alignment and severe hallucination in generated outputs. To
address this problem, we propose a novel strategy called HIerarchical GrapH
Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that
extracts and encodes the hierarchy of node, motif, and graph levels of
informative tokens to improve the graph perception of LLMs. HIGHT also adopts
an augmented graph-language supervised fine-tuning dataset, enriched with the
hierarchical graph information, to further enhance the graph-language
alignment. Extensive experiments on 7 molecule-centric benchmarks confirm the
effectiveness of HIGHT in reducing hallucination by 40%, as well as significant
improvements in various molecule-language downstream tasks.

摘要：<paragraph>最近，人们对将大型语言模型 (LLM) 的成功扩展到图模式（例如社交网络和分子）产生了浓厚的兴趣。由于 LLM 主要使用一维文本数据进行训练，因此大多数现有方法采用图神经网络将图表示为一系列节点标记，并将这些标记馈送至 LLM 以进行图语言对齐。尽管取得了一些成功，但现有方法却忽视了图数据中固有的层次结构。特别是在分子图中，高阶结构信息包含丰富的分子官能团语义，它对分子的关键生化功能进行编码。我们建立了一个简单的基准，表明在图标记化中忽略层次信息会导致次优的图语言对齐，并在生成的输出中出现严重的幻觉。为了解决这个问题，我们提出了一种称为分层图标记化 (HIGHT) 的新策略。HIGHT 采用分层图标记器，该标记器提取和编码信息标记的节点、主题和图级别层次结构，以改善 LLM 的图感知。HIGHT 还采用了一个经过扩充的图语言监督微调数据集，该数据集包含分层图信息，以进一步增强图语言对齐。在 7 个以分子为中心的基准上的大量实验证实了 HIGHT 在将幻觉减少 40% 方面的有效性，以及在各种分子语言下游任务中的显著改进。</paragraph>

##### **A Pure Transformer Pretraining Framework on Text-attributed Graphs**
2406.13873v1 by Yu Song, Haitao Mao, Jiachen Xiao, Jingzhe Liu, Zhikai Chen, Wei Jin, Carl Yang, Jiliang Tang, Hui Liu

Pretraining plays a pivotal role in acquiring generalized knowledge from
large-scale data, achieving remarkable successes as evidenced by large models
in CV and NLP. However, progress in the graph domain remains limited due to
fundamental challenges such as feature heterogeneity and structural
heterogeneity. Recently, increasing efforts have been made to enhance node
feature quality with Large Language Models (LLMs) on text-attributed graphs
(TAGs), demonstrating superiority to traditional bag-of-words or word2vec
techniques. These high-quality node features reduce the previously critical
role of graph structure, resulting in a modest performance gap between Graph
Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).
Motivated by this, we introduce a feature-centric pretraining perspective by
treating graph structure as a prior and leveraging the rich, unified feature
space to learn refined interaction patterns that generalizes across graphs. Our
framework, Graph Sequence Pretraining with Transformer (GSPT), samples node
contexts through random walks and employs masked feature reconstruction to
capture pairwise proximity in the LLM-unified feature space using a standard
Transformer. By utilizing unified text representations rather than varying
structures, our framework achieves significantly better transferability among
graphs within the same domain. GSPT can be easily adapted to both node
classification and link prediction, demonstrating promising empirical success
on various datasets.

摘要：預訓練在從大型資料中獲取廣泛知識方面發揮了關鍵作用，從 CV 和 NLP 中的大型模型所證明的顯著成功中即可見一斑。然而，由於特徵異質性和結構異質性等基本挑戰，圖形領域的進展仍然有限。最近，人們在文本屬性圖 (TAG) 上使用大型語言模型 (LLM) 來增強節點特徵品質，並已做出越來越多努力，證明其優於傳統的詞袋或 word2vec 技術。這些高品質節點特徵降低了圖形結構先前至關重要的作用，導致圖形神經網路 (GNN) 和與結構無關的多層感知器 (MLP) 之間的效能差距縮小。受到此啟發，我們透過將圖形結構視為先驗，並利用豐富的統一特徵空間來學習在圖形中概括的精緻互動模式，引入了以特徵為中心的預訓練觀點。我們的架構圖形序列預訓練與 Transformer (GSPT)，透過隨機遊走取樣節點脈絡，並採用遮蔽特徵重建，以使用標準 Transformer 在 LLM 統一特徵空間中擷取成對接近度。透過利用統一的文字表徵，而非變化的結構，我們的架構在同一個網域中的圖形之間達到了顯著更好的可傳遞性。GSPT 可以輕鬆地調整到節點分類和連結預測，在各種資料集上展現出有希望的實證成功。

##### **Knowledge Graph-Enhanced Large Language Models via Path Selection**
2406.13862v1 by Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li

Large Language Models (LLMs) have shown unprecedented performance in various
real-world applications. However, they are known to generate factually
inaccurate outputs, a.k.a. the hallucination problem. In recent years,
incorporating external knowledge extracted from Knowledge Graphs (KGs) has
become a promising strategy to improve the factual accuracy of LLM-generated
outputs. Nevertheless, most existing explorations rely on LLMs themselves to
perform KG knowledge extraction, which is highly inflexible as LLMs can only
provide binary judgment on whether a certain knowledge (e.g., a knowledge path
in KG) should be used. In addition, LLMs tend to pick only knowledge with
direct semantic relationship with the input text, while potentially useful
knowledge with indirect semantics can be ignored. In this work, we propose a
principled framework KELP with three stages to handle the above problems.
Specifically, KELP is able to achieve finer granularity of flexible knowledge
extraction by generating scores for knowledge paths with input texts via latent
semantic matching. Meanwhile, knowledge paths with indirect semantic
relationships with the input text can also be considered via trained encoding
between the selected paths in KG and the input text. Experiments on real-world
datasets validate the effectiveness of KELP.

摘要：大型語言模型 (LLM) 在各種實際應用中展現了前所未有的效能。然而，它們會產生事實上不準確的輸出，也就是所謂的幻覺問題。近年來，納入從知識圖譜 (KG) 中萃取的外部知識已成為改善 LLM 生成的輸出事實準確性的有前途策略。儘管如此，現有的探索大多依賴 LLM 本身來執行 KG 知識萃取，這非常不靈活，因為 LLM 只會對特定知識（例如，KG 中的知識路徑）是否應該使用提供二元判斷。此外，LLM 傾向僅挑選與輸入文字有直接語義關係的知識，而可能對語意有間接關聯的有用知識可能會被忽略。在這項工作中，我們提出一個有原則的 KELP 架構，包含三個階段來處理上述問題。具體來說，KELP 能夠透過隱含語義比對為知識路徑與輸入文字產生分數，進而達成更細緻的彈性知識萃取。同時，也可以透過在 KG 中選定的路徑與輸入文字之間訓練編碼的方式，考量與輸入文字有間接語義關係的知識路徑。在實際資料集上的實驗驗證了 KELP 的有效性。

##### **Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**
2406.15507v1 by Haochen Liu, Song Wang, Chen Chen, Jundong Li

Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen
triplets (i.e., query triplets) for rare relations in KGs, given only several
triplets of these relations as references (i.e., support triplets). This task
has gained significant traction due to the widespread use of knowledge graphs
in various natural language processing applications. Previous approaches have
utilized meta-training methods and manually constructed meta-relation sets to
tackle this task. Recent efforts have focused on edge-mask-based methods, which
exploit the structure of the contextualized graphs of target triplets (i.e., a
subgraph containing relevant triplets in the KG). However, existing
edge-mask-based methods have limitations in extracting insufficient information
from KG and are highly influenced by spurious information in KG. To overcome
these challenges, we propose SAFER (Subgraph Adaptation for Few-shot Relational
Reasoning), a novel approach that effectively adapts the information in
contextualized graphs to various subgraphs generated from support and query
triplets to perform the prediction. Specifically, SAFER enables the extraction
of more comprehensive information from support triplets while minimizing the
impact of spurious information when predicting query triplets. Experimental
results on three prevalent datasets demonstrate the superiority of our proposed
framework SAFER.

摘要：小样本知识图谱 (KG) 关系推理旨在预测 KG 中罕见关系的看不见三元组（即查询三元组），而仅给出几个三元组作为参考（即支持三元组）。由于知识图谱在各种自然语言处理应用程序中的广泛使用，这项任务获得了显著的关注。以前的方法利用元训练方法和手动构建的元关系集来解决此任务。最近的努力集中在基于边缘掩码的方法上，该方法利用目标三元组的上下文化图的结构（即包含 KG 中相关三元组的子图）。然而，现有的基于边缘掩码的方法在从 KG 中提取不足信息方面存在局限性，并且受 KG 中虚假信息的极大影响。为了克服这些挑战，我们提出了 SAFER（用于小样本关系推理的子图自适应），一种新颖的方法，它有效地将上下文化图中的信息适应从支持和查询三元组生成的不同子图以执行预测。具体来说，SAFER 能够从支持三元组中提取更全面的信息，同时在预测查询三元组时最大程度地减少虚假信息的影响。在三个流行数据集上的实验结果证明了我们提出的 SAFER 框架的优越性。

##### **Dr.E Bridges Graphs with Large Language Models through Words**
2406.15504v1 by Zipeng Liu, Likang Wu, Ming He, Zhong Guan, Hongke Zhao, Nan Feng

Significant efforts have been directed toward integrating powerful Large
Language Models (LLMs) with diverse modalities, particularly focusing on the
fusion of vision, language, and audio data. However, the graph-structured data,
inherently rich in structural and domain-specific knowledge, have not yet been
gracefully adapted to LLMs. Existing methods either describe the graph with raw
text, suffering the loss of graph structural information, or feed Graph Neural
Network (GNN) embeddings directly into LLM at the cost of losing semantic
representation. To bridge this gap, we introduce an innovative, end-to-end
modality-aligning framework, equipped with a pretrained Dual-Residual Vector
Quantized-Variational AutoEncoder (Dr.E). This framework is specifically
designed to facilitate token-level alignment with LLMs, enabling an effective
translation of the intrinsic `language' of graphs into comprehensible natural
language. Our experimental evaluations on standard GNN node classification
tasks demonstrate competitive performance against other state-of-the-art
approaches. Additionally, our framework ensures interpretability, efficiency,
and robustness, with its effectiveness further validated under both fine-tuning
and few-shot settings. This study marks the first successful endeavor to
achieve token-level alignment between GNNs and LLMs.

摘要：大量的努力已投入到將強大的大型語言模型 (LLM) 與不同的模態整合，特別是專注於視覺、語言和音訊資料的融合。然而，圖形結構化的資料本質上富含結構和領域特定的知識，但尚未優雅地適應 LLM。現有方法不是用原始文字描述圖形，導致圖形結構資訊遺失，就是將圖形神經網路 (GNN) 的嵌入直接饋入 LLM，代價是失去語義表示。為了彌補這個差距，我們引入了一個創新的端到端模態對齊框架，配備了一個預先訓練的雙殘差向量量化變分自編碼器 (Dr.E)。此框架特別設計用於促進與 LLM 的標記層級對齊，讓圖形的內在「語言」能有效轉換成易於理解的自然語言。我們在標準 GNN 節點分類任務上的實驗評估顯示，與其他最先進的方法相比，我們的表現具有競爭力。此外，我們的框架確保了解釋性、效率和穩健性，在微調和少樣本設定下進一步驗證其有效性。這項研究標誌著在 GNN 和 LLM 之間實現標記層級對齊的首次成功嘗試。

##### **Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**
2406.13578v1 by Han-Cheng Yu, Yu-An Shih, Kin-Man Law, Kai-Yu Hsieh, Yu-Chen Cheng, Hsin-Chih Ho, Zih-An Lin, Wen-Chuan Hsu, Yao-Chung Fan

In this paper, we tackle the task of distractor generation (DG) for
multiple-choice questions. Our study introduces two key designs. First, we
propose \textit{retrieval augmented pretraining}, which involves refining the
language model pretraining to align it more closely with the downstream task of
DG. Second, we explore the integration of knowledge graphs to enhance the
performance of DG. Through experiments with benchmarking datasets, we show that
our models significantly outperform the state-of-the-art results. Our
best-performing model advances the F1@3 score from 14.80 to 16.47 in MCQ
dataset and from 15.92 to 16.50 in Sciq dataset.

摘要：在本文中，我们處理多選題的干擾器生成 (DG) 任務。我們的研究引入了兩個關鍵設計。首先，我們提出「檢索增強預訓練」，其中包含優化語言模型預訓練，使其與 DG 的下游任務更緊密地對齊。其次，我們探討知識圖表的整合，以增強 DG 的效能。透過基準資料集的實驗，我們證明我們的模型明顯優於最先進的結果。我們效能最佳的模型將 MCQ 資料集中的 F1@3 分數從 14.80 提升到 16.47，在 Sciq 資料集中從 15.92 提升到 16.50。

##### **LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**
2406.13250v1 by Zhong Guan, Hongke Zhao, Likang Wu, Ming He, Jianpin Fan

Recently, large language models (LLMs) have been widely researched in the
field of graph machine learning due to their outstanding abilities in language
comprehension and learning. However, the significant gap between natural
language tasks and topological structure modeling poses a nonnegligible
challenge. Specifically, since natural language descriptions are not sufficient
for LLMs to understand and process graph-structured data, fine-tuned LLMs
perform even worse than some traditional GNN models on graph tasks, lacking
inherent modeling capabilities for graph structures. Existing research overly
emphasizes LLMs' understanding of semantic information captured by external
models, while inadequately exploring graph topological structure modeling,
thereby overlooking the genuine capabilities that LLMs lack. Consequently, in
this paper, we introduce a new framework, LangTopo, which aligns graph
structure modeling with natural language understanding at the token level.
LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs
by constructing a codebook for the graph modality and performs consistency
maximization. This process aligns the text description of LLM with the
topological modeling of GNN, allowing LLM to learn the ability of GNN to
capture graph structures, enabling LLM to handle graph-structured data
independently. We demonstrate the effectiveness of our proposed method on
multiple datasets.

摘要：<paragraph>最近，大语言模型 (LLM) 由于其在语言理解和学习方面的出色能力而在图机器学习领域受到广泛研究。然而，自然语言任务和拓扑结构建模之间的巨大差距构成了不可忽视的挑战。具体来说，由于自然语言描述不足以让 LLM 理解和处理图结构化数据，因此经过微调的 LLM 在图任务上的表现甚至比一些传统的 GNN 模型还要差，缺乏对图结构的固有建模能力。现有研究过分强调 LLM 对外部模型捕获的语义信息的理解，而对图拓扑结构建模的探索不足，从而忽视了 LLM 所缺乏的真正能力。因此，在本文中，我们引入了一个新的框架 LangTopo，它在标记级别将图结构建模与自然语言理解相结合。LangTopo 通过为图模态构建码本并执行一致性最大化来量化 GNN 和 LLM 的图结构建模能力。此过程将 LLM 的文本描述与 GNN 的拓扑建模相结合，使 LLM 能够学习 GNN 捕获图结构的能力，从而使 LLM 能够独立处理图结构化数据。我们在多个数据集上展示了我们提出的方法的有效性。</paragraph>

##### **Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**
2406.13235v1 by Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

Large Language Models (LLMs) are increasingly prominent in the recommendation
systems domain. Existing studies usually utilize in-context learning or
supervised fine-tuning on task-specific data to align LLMs into
recommendations. However, the substantial bias in semantic spaces between
language processing tasks and recommendation tasks poses a nonnegligible
challenge. Specifically, without the adequate capturing ability of
collaborative information, existing modeling paradigms struggle to capture
behavior patterns within community groups, leading to LLMs' ineffectiveness in
discerning implicit interaction semantic in recommendation scenarios. To
address this, we consider enhancing the learning capability of language
model-driven recommendation models for structured data, specifically by
utilizing interaction graphs rich in collaborative semantics. We propose a
Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec).
GAL-Rec enhances the understanding of user-item collaborative semantics by
imitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop
information, thereby fully exploiting the substantial learning capacity of LLMs
to independently address the complex graphs in the recommendation system.
Sufficient experimental results on three real-world datasets demonstrate that
GAL-Rec significantly enhances the comprehension of collaborative semantics,
and improves recommendation performance.

摘要：大型語言模型（LLM）在推薦系統領域中越來越突出。現有研究通常利用情境學習或在特定任務數據上進行監督微調，以將 LLM 調整為建議。然而，語言處理任務和推薦任務之間語義空間的實質性偏差構成了不可忽視的挑戰。具體來說，現有的建模範例在缺乏協作信息的充分捕獲能力的情況下，難以捕捉社群群組內的行為模式，導致 LLM 無法在推薦場景中辨識隱含的互動語義。為了解決這個問題，我們考慮增強語言模型驅動推薦模型對結構化數據的學習能力，特別是通過利用富含協作語義的交互圖。我們提出了一個圖感知語言模型驅動推薦學習（GAL-Rec）。GAL-Rec 通過模仿圖神經網路（GNN）聚合多跳信息的意圖來增強對使用者項目協作語義的理解，從而充分利用 LLM 的實質性學習能力來獨立處理推薦系統中的複雜圖。在三個真實世界數據集上進行的充分實驗結果表明，GAL-Rec 大大增強了對協作語義的理解，並改善了推薦性能。

##### **Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**
2406.13217v1 by Xiaoxi Kang, Lizhen Qu, Lay-Ki Soon, Zhuang Li, Adnan Trakic

The effectiveness of Large Language Models (LLMs) in legal reasoning is often
limited due to the unique legal terminologies and the necessity for highly
specialized knowledge. These limitations highlight the need for high-quality
data tailored for complex legal reasoning tasks. This paper introduces
LEGALSEMI, a benchmark specifically curated for legal scenario analysis.
LEGALSEMI comprises 54 legal scenarios, each rigorously annotated by legal
experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion)
framework. In addition, LEGALSEMI is accompanied by a structured knowledge
graph (SKG). A series of experiments were conducted to assess the usefulness of
LEGALSEMI for IRAC analysis. The experimental results demonstrate the
effectiveness of incorporating the SKG for issue identification, rule
retrieval, application and conclusion generation using four different LLMs.
LEGALSEMI will be publicly available upon acceptance of this paper.

摘要：大型語言模型 (LLM) 在法律推理中的有效性通常受到獨特的法律術語和高度專業知識的必要性的限制。這些限制突顯了針對複雜法律推理任務量身打造的高品質資料的需求。本文介紹 LEGALSEMI，這是一個專門為法律情境分析策劃的基準。LEGALSEMI 包含 54 個法律情境，每個情境都經過法律專家根據全面的 IRAC（問題、規則、應用、結論）架構嚴格註解。此外，LEGALSEMI 還附帶一個結構化的知識圖譜 (SKG)。進行了一系列實驗來評估 LEGALSEMI 對 IRAC 分析的有用性。實驗結果證明了將 SKG 納入問題識別、規則檢索、應用和結論生成中的有效性，使用了四種不同的 LLM。LEGALSEMI 將在本文獲接受後公開。

##### **PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**
2406.13193v1 by He Cao, Yanjun Shao, Zhiyuan Liu, Zijing Liu, Xiangru Tang, Yuan Yao, Yu Li

Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.

摘要：多模态大型语言模型（MLLM）在各个科学学科中逐渐被采用。这些进步促进了合成化学中分子文本建模的研究，合成化学致力于设计和进行化学反应以合成具有所需性质和应用的新化合物。然而，当前的方法通常忽略了多个分子图相互作用在理解化学反应中的关键作用，导致在合成化学任务中的性能不佳。本研究介绍了 PRESTO（渐进式预训练增强合成化学成果），这是一个新的框架，通过整合预训练策略和数据集配置的综合基准来弥合理分子文本模态差距。它通过跨模态对齐和多图理解逐步改进多模态 LLM。我们的广泛实验表明，PRESTO 在下游合成化学任务中提供了有竞争力的结果。代码可在 https://github.com/IDEA-XL/PRESTO 中找到。

##### **QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**
2406.13167v1 by Bo Wang, Heyan Huang, Yixin Cao, Jiahao Ying, Wei Tang, Chong Feng

While large language models (LLMs) have made notable advancements in natural
language processing, they continue to struggle with processing extensive text.
Memory mechanism offers a flexible solution for managing long contexts,
utilizing techniques such as compression, summarization, and structuring to
facilitate nuanced and efficient handling of large volumes of text. However,
existing techniques face challenges with static knowledge integration, leading
to insufficient adaptation to task-specific needs and missing
multi-segmentation relationships, which hinders the dynamic reorganization and
logical combination of relevant segments during the response process. To
address these issues, we introduce a novel strategy, Question then Reflection
Memory Mechanism (QRMeM), incorporating a dual-structured memory pool. This
pool synergizes static textual content with structured graph guidance,
fostering a reflective trial-and-error approach for navigating and identifying
relevant segments. Our evaluation across multiple-choice questions (MCQ) and
multi-document question answering (Multi-doc QA) benchmarks showcases QRMeM
enhanced performance compared to existing approaches.

摘要：儘管大型語言模型 (LLM) 在自然語言處理方面取得顯著進展，但它們在處理大量文字時仍面臨困難。記憶機制提供了一個靈活的解決方案，用於管理長篇脈絡，利用壓縮、摘要和結構化等技術，以促進對大量文字的細緻且有效率的處理。然而，現有技術在靜態知識整合方面面臨挑戰，導致無法充分適應特定任務的需求，且缺少多重分段關係，這阻礙了回應過程中相關區段的動態重組和邏輯組合。為了解決這些問題，我們引入了一種新策略，即問答反思記憶機制 (QRMeM)，並結合了雙結構化記憶池。此記憶池將靜態文本內容與結構化圖形指導結合起來，促進了一種反思性的試錯方法，用於導航和識別相關區段。我們在多選題 (MCQ) 和多文件問答 (Multi-doc QA) 基準上的評估顯示，與現有方法相比，QRMeM 增強了效能。

##### **Bridging Local Details and Global Context in Text-Attributed Graphs**
2406.12608v1 by Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, Yunfei Li, Siliang Tang

Representation learning on text-attributed graphs (TAGs) is vital for
real-world applications, as they combine semantic textual and contextual
structural information. Research in this field generally consist of two main
perspectives: local-level encoding and global-level aggregating, respectively
refer to textual node information unification (e.g., using Language Models) and
structure-augmented modeling (e.g., using Graph Neural Networks). Most existing
works focus on combining different information levels but overlook the
interconnections, i.e., the contextual textual information among nodes, which
provides semantic insights to bridge local and global levels. In this paper, we
propose GraphBridge, a multi-granularity integration framework that bridges
local and global perspectives by leveraging contextual textual information,
enhancing fine-grained understanding of TAGs. Besides, to tackle scalability
and efficiency challenges, we introduce a graphaware token reduction module.
Extensive experiments across various models and datasets show that our method
achieves state-of-theart performance, while our graph-aware token reduction
module significantly enhances efficiency and solves scalability issues.

摘要：文本属性图 (TAG) 上的表征学习对于实际应用至关重要，因为它们结合了语义文本和上下文结构信息。该领域的研究所涉及的两个主要观点：局部编码和全局聚合，分别指文本节点信息统一（例如，使用语言模型）和结构增强建模（例如，使用图神经网络）。大多数现有工作侧重于结合不同的信息级别，但忽略了相互联系，即节点之间的上下文文本信息，它提供了语义见解以桥接局部和全局级别。在本文中，我们提出了 GraphBridge，这是一个多粒度集成框架，它通过利用上下文文本信息来桥接局部和全局视角，增强了对 TAG 的细粒度理解。此外，为了解决可扩展性和效率挑战，我们引入了一个图感知令牌缩减模块。跨各种模型和数据集的广泛实验表明，我们的方法实现了最先进的性能，而我们的图感知令牌缩减模块显着提高了效率并解决了可扩展性问题。

##### **MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**
2406.12950v1 by Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan

Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 16.6% increase on classification accuracy and decrease of
199.17 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.

摘要：分子特性預測 (MPP) 是藥物發現中的一項基本且至關重要的任務。然而，先前的研究方法受到大量標記分子需求和概化到未見和新任務的能力受限的限制，這兩者對於實際應用都是必不可少的。為了應對這些挑戰，我們提出用於少樣本 MPP 的 MolecularGPT。從指令微調的角度來看，我們根據涵蓋 1000 多項特性預測任務的策劃分子指令微調大型語言模型 (LLM)。這使得構建一個多功能且專業的 LLM 成為可能，該 LLM 可以通過零樣本和少樣本情境學習 (ICL) 適應新的 MPP 任務，而無需任何微調。MolecularGPT 在 10 個下游評估資料集上展示了具有競爭力的情境推理能力，為少樣本分子預測任務設定了新的基準。更重要的是，僅使用兩樣本範例，MolecularGPT 就可以在 7 個資料集中的 4 個資料集上優於標準監督圖神經網路方法。它還在零樣本下，通過分類準確度提高了 16.6% 和回歸指標（例如 RMSE）減少了 199.17，從而優於最先進的 LLM 基準。這項研究證明了 LLM 作為有效少樣本分子特性預測器的潛力。程式碼可在 https://github.com/NYUSHCS/MolecularGPT 獲得。

##### **LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**
2406.12494v1 by Masafumi Enomoto, Kunihiro Takeoka, Kosuke Akimoto, Kiril Gashteovski, Masafumi Oyamada

Open-Domain Multi-Document Summarization (ODMDS) is crucial for addressing
diverse information needs, which aims to generate a summary as answer to user's
query, synthesizing relevant content from multiple documents in a large
collection. Existing approaches that first find relevant passages and then
generate a summary using a language model are inadequate for ODMDS. This is
because open-ended queries often require additional context for the retrieved
passages to cover the topic comprehensively, making it challenging to retrieve
all relevant passages initially. While iterative retrieval methods have been
explored for multi-hop question answering (MQA), they are impractical for ODMDS
due to high latency from repeated large language model (LLM) inference for
reasoning. To address this issue, we propose LightPAL, a lightweight passage
retrieval method for ODMDS that constructs a graph representing passage
relationships using an LLM during indexing and employs random walk instead of
iterative reasoning and retrieval at inference time. Experiments on ODMDS
benchmarks show that LightPAL outperforms baseline retrievers in summary
quality while being significantly more efficient than an iterative MQA
approach.

摘要：開放領域多文件摘要 (ODMDS) 對於解決不同的資訊需求至關重要，其目的是根據使用者的查詢產生摘要作為答案，綜合來自大型集合中多個文件的相關內容。現有的方法是先找到相關段落，然後使用語言模型產生摘要，對於 ODMDS 來說是不夠的。這是因為開放式查詢通常需要額外的內容，才能讓擷取的段落全面涵蓋主題，這使得一開始就擷取所有相關段落具有挑戰性。雖然已經探索了反覆擷取的方法用於多跳問題解答 (MQA)，但由於反覆進行大型語言模型 (LLM) 推論以進行推理，因此它們不適用於 ODMDS，因為這會導致高延遲。為了解決這個問題，我們提出了 LightPAL，這是一種針對 ODMDS 的輕量級段落擷取方法，它在索引時使用 LLM 建立表示段落關係的圖，並在推論時使用隨機遊走，而不是反覆推理和擷取。在 ODMDS 基準測試中的實驗顯示，LightPAL 在摘要品質上優於基線擷取器，同時比反覆 MQA 方法有效率得多。

##### **Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**
2406.12227v2 by Gangwei Jiang, Caigao Jiang, Zhaoyi Li, Siqiao Xue, Jun Zhou, Linqi Song, Defu Lian, Ying Wei

Fine-tuning large language models (LLMs) can cause them to lose their general
capabilities. However, the intrinsic mechanisms behind such forgetting remain
unexplored. In this paper, we begin by examining this phenomenon by focusing on
knowledge understanding and instruction following, with the latter identified
as the main contributor to forgetting during fine-tuning. Consequently, we
propose the Instruction Vector (IV) framework to capture model representations
highly related to specific instruction-following capabilities, thereby making
it possible to understand model-intrinsic forgetting. Through the analysis of
IV dynamics pre and post-training, we suggest that fine-tuning mostly adds
specialized reasoning patterns instead of erasing previous skills, which may
appear as forgetting. Building on this insight, we develop IV-guided training,
which aims to preserve original computation graph, thereby mitigating
catastrophic forgetting. Empirical tests on three benchmarks confirm the
efficacy of this new approach, supporting the relationship between IVs and
forgetting. Our code will be made available soon.

摘要：微调大型语言模型 (LLM) 可能导致它们丧失一般能力。然而，这种遗忘背后的内在机制仍未得到探索。在本文中，我们首先通过关注知识理解和指令遵循来检验这种现象，其中后者被认为是微调过程中遗忘的主要原因。因此，我们提出了指令向量 (IV) 框架来捕获与特定指令遵循能力高度相关的模型表示，从而可以理解模型内在的遗忘。通过对训练前后的 IV 动态进行分析，我们认为微调主要添加了专门的推理模式，而不是抹除先前的技能，这可能表现为遗忘。基于这一见解，我们开发了 IV 指导训练，其目标是保留原始计算图，从而减轻灾难性遗忘。在三个基准上的经验测试证实了这种新方法的有效性，支持了 IV 和遗忘之间的关系。我们的代码将很快提供。

##### **DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**
2406.12072v2 by Jiasheng Zhang, Jialin Chen, Menglin Yang, Aosong Feng, Shuang Liang, Jie Shao, Rex Ying

Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world
scenarios, where each node and edge are associated with text descriptions, and
both the graph structure and text descriptions evolve over time. Despite their
broad applicability, there is a notable scarcity of benchmark datasets tailored
to DyTAGs, which hinders the potential advancement in many research fields. To
address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB),
a collection of large-scale, time-evolving graphs from diverse domains, with
nodes and edges enriched by dynamically changing text attributes and
categories. To facilitate the use of DTGB, we design standardized evaluation
procedures based on four real-world use cases: future link prediction,
destination node retrieval, edge classification, and textual relation
generation. These tasks require models to understand both dynamic graph
structures and natural language, highlighting the unique challenges posed by
DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB,
evaluating 7 popular dynamic graph learning algorithms and their variants of
adapting to text attributes with LLM embeddings, along with 6 powerful large
language models (LLMs). Our results show the limitations of existing models in
handling DyTAGs. Our analysis also demonstrates the utility of DTGB in
investigating the incorporation of structural and textual dynamics. The
proposed DTGB fosters research on DyTAGs and their broad applications. It
offers a comprehensive benchmark for evaluating and advancing models to handle
the interplay between dynamic graph structures and natural language. The
dataset and source code are available at https://github.com/zjs123/DTGB.

摘要：<paragraph>動態文字屬性圖表 (DyTAGs) 普遍存在於各種真實世界的場景中，其中每個節點和邊緣都與文字描述相關聯，且圖表結構和文字描述會隨著時間演變。儘管其廣泛的適用性，但專門針對 DyTAGs 的基準資料集卻十分稀少，這阻礙了許多研究領域的潛在進展。為了解決這個差距，我們引入了動態文字屬性圖表基準 (DTGB)，它是一個來自不同領域的大型、時變圖表的集合，其節點和邊緣由動態變化的文字屬性和類別豐富化。為了便於使用 DTGB，我們根據四個真實世界的用例設計了標準化的評估程序：未來連結預測、目的地節點檢索、邊緣分類和文字關係生成。這些任務要求模型同時理解動態圖表結構和自然語言，突顯了 DyTAGs 帶來的獨特挑戰。此外，我們對 DTGB 進行了廣泛的基準實驗，評估了 7 種流行的動態圖表學習演算法及其使用 LLM 嵌入適應文字屬性的變體，以及 6 種強大的大型語言模型 (LLM)。我們的結果顯示了現有模型在處理 DyTAGs 方面的局限性。我們的分析也證明了 DTGB 在研究結構和文字動態的結合方面的效用。所提出的 DTGB 促進了對 DyTAGs 及其廣泛應用的研究。它為評估和推進模型以處理動態圖表結構和自然語言之間的交互作用提供了一個全面的基準。資料集和原始碼可在 https://github.com/zjs123/DTGB 取得。</paragraph>

##### **UniGLM: Training One Unified Language Model for Text-Attributed Graphs**
2406.12052v1 by Yi Fang, Dongzhe Fan, Sirui Ding, Ninghao Liu, Qiaoyu Tan

Representation learning on text-attributed graphs (TAGs), where nodes are
represented by textual descriptions, is crucial for textual and relational
knowledge systems and recommendation systems. Currently, state-of-the-art
embedding methods for TAGs primarily focus on fine-tuning language models
(e.g., BERT) using structure-aware training signals. While effective, these
methods are tailored for individual TAG and cannot generalize across various
graph scenarios. Given the shared textual space, leveraging multiple TAGs for
joint fine-tuning, aligning text and graph structure from different aspects,
would be more beneficial. Motivated by this, we introduce a novel Unified Graph
Language Model (UniGLM) framework, the first graph embedding model that
generalizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM
is trained over multiple TAGs with different domains and scales using
self-supervised contrastive learning. UniGLM includes an adaptive positive
sample selection technique for identifying structurally similar nodes and a
lazy contrastive module that is devised to accelerate training by minimizing
repetitive encoding calculations. Extensive empirical results across 9
benchmark TAGs demonstrate UniGLM's efficacy against leading embedding
baselines in terms of generalization (various downstream tasks and backbones)
and transfer learning (in and out of domain scenarios). The code is available
at https://github.com/NYUSHCS/UniGLM.

摘要：在文字属性图 (TAG) 上的表征学习，其中节点由文字描述表示，对于文字和关系知识系统以及推荐系统至关重要。目前，TAG 的最先进嵌入方法主要集中于使用结构感知训练信号微调语言模型（例如，BERT）。虽然有效，但这些方法是针对单个 TAG 量身定制的，并且无法概括到各种图场景。鉴于共享的文本空间，利用多个 TAG 进行联合微调，从不同方面调整文本和图结构，将更有益。受此启发，我们引入了一种新颖的统一图语言模型 (UniGLM) 框架，这是第一个在域内和跨域 TAG 中都能很好地概括的图嵌入模型。具体来说，UniGLM 使用自监督对比学习在具有不同域和规模的多个 TAG 上进行训练。UniGLM 包括一种自适应正样本选择技术，用于识别结构相似的节点，以及一个延迟对比模块，该模块旨在通过最小化重复编码计算来加速训练。跨 9 个基准 TAG 的广泛实证结果证明了 UniGLM 在泛化（各种下游任务和主干）和迁移学习（域内和域外场景）方面相对于领先嵌入基准的功效。代码可在 https://github.com/NYUSHCS/UniGLM 获得。

##### **GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models**
2406.11945v1 by Yi Fang, Dongzhe Fan, Daochen Zha, Qiaoyu Tan

This work studies self-supervised graph learning for text-attributed graphs
(TAGs) where nodes are represented by textual attributes. Unlike traditional
graph contrastive methods that perturb the numerical feature space and alter
the graph's topological structure, we aim to improve view generation through
language supervision. This is driven by the prevalence of textual attributes in
real applications, which complement graph structures with rich semantic
information. However, this presents challenges because of two major reasons.
First, text attributes often vary in length and quality, making it difficulty
to perturb raw text descriptions without altering their original semantic
meanings. Second, although text attributes complement graph structures, they
are not inherently well-aligned. To bridge the gap, we introduce GAugLLM, a
novel framework for augmenting TAGs. It leverages advanced large language
models like Mistral to enhance self-supervised graph learning. Specifically, we
introduce a mixture-of-prompt-expert technique to generate augmented node
features. This approach adaptively maps multiple prompt experts, each of which
modifies raw text attributes using prompt engineering, into numerical feature
space. Additionally, we devise a collaborative edge modifier to leverage
structural and textual commonalities, enhancing edge augmentation by examining
or building connections between nodes. Empirical results across five benchmark
datasets spanning various domains underscore our framework's ability to enhance
the performance of leading contrastive methods as a plug-in tool. Notably, we
observe that the augmented features and graph structure can also enhance the
performance of standard generative methods, as well as popular graph neural
networks. The open-sourced implementation of our GAugLLM is available at
Github.

摘要：<paragraph>本研究探討了文字屬性圖 (TAG) 的自我監督圖學習，其中節點由文字屬性表示。與擾動數值特徵空間和改變圖形拓撲結構的傳統圖形對比方法不同，我們旨在透過語言監督來改善視圖生成。這是因為文字屬性在實際應用中很普遍，它以豐富的語義資訊補充圖形結構。然而，這會帶來挑戰，原因有兩個。首先，文字屬性通常長度和品質不同，這使得在不改變原始語義意義的情況下擾動原始文字描述變得困難。其次，儘管文字屬性補充了圖形結構，但它們並非天生就很好地對齊。為了彌合差距，我們引入了 GAugLLM，這是一個用於擴充 TAG 的新框架。它利用了 Mistral 等先進的大型語言模型來增強自我監督圖形學習。具體來說，我們引入了一種混合提示專家的技術來生成擴充的節點特徵。這種方法自適應地將多個提示專家映射到數值特徵空間，每個提示專家都使用提示工程修改原始文字屬性。此外，我們設計了一個協作邊緣修改器來利用結構和文字的共性，通過檢查或建立節點之間的連接來增強邊緣擴充。跨越各種領域的五個基準資料集的經驗結果強調了我們的框架作為外掛工具增強領先對比方法效能的能力。值得注意的是，我們觀察到擴充的特徵和圖形結構也可以增強標準生成方法以及流行的圖形神經網路的效能。我們的 GAugLLM 的開源實現可以在 Github 上找到。</paragraph>

##### **Input Conditioned Graph Generation for Language Agents**
2406.11555v1 by Lukas Vierling, Jie Fu, Kai Chen

Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm.

摘要：大型语言模型 (LLM) 和语言代理最近的进展已展示出对跨多个学科的各种未来应用的重大前景。虽然传统的语言代理方法通常依赖于固定的手工设计，但我们的研究旨在开发可学习和动态的代理。我们的方法使用了一个现有的框架，将语言代理抽象为图。在这个图框架内，我们旨在学习一个模型，该模型可以为语言代理的每个给定输入生成边。这使我们能够生成代表图中基于给定输入的通信流的边，从而调整语言代理的内部通信。我们学习使用经过强化学习微调的预训练 LLM 来生成这些边。该 LLM 可以同时在多个数据集上进行微调，我们假设该模型在训练期间学习适应这些不同的域，在部署期间遇到来自不同域的数据时实现良好的整体性能。我们证明，我们的方法在 MMLU 和 CMMLU 的组合数据集上比先前的静态方法高出近 6% 的准确度，并且在使用稀疏性诱导损失进行训练时高出 10% 以上。它还在使用 MMLU 和迷你填字游戏数据集进行的其他实验中表现出色。代码可在 https://github.com/lukasVierling/DynamicGPTSwarm 获得。

##### **Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**
2406.11400v1 by Golnaz Shapurian

This paper presents an experiment conducted during a hackathon, focusing on
using large language models (LLMs) and knowledge graph clustering to extract
entities and relationships from astronomical text. The study demonstrates an
approach to disambiguate entities that can appear in various contexts within
the astronomical domain. By collecting excerpts around specific entities and
leveraging the GPT-4 language model, relevant entities and relationships are
extracted. The extracted information is then used to construct a knowledge
graph, which is clustered using the Leiden algorithm. The resulting Leiden
communities are utilized to identify the percentage of association of unknown
excerpts to each community, thereby enabling disambiguation. The experiment
showcases the potential of combining LLMs and knowledge graph clustering
techniques for information extraction in astronomical research. The results
highlight the effectiveness of the approach in identifying and disambiguating
entities, as well as grouping them into meaningful clusters based on their
relationships.

摘要：本文介紹了在黑客馬拉松中進行的實驗，重點在於使用大型語言模型 (LLM) 和知識圖譜聚類，從天文文本中提取實體和關係。這項研究展示了一種方法，可以消除在天文領域中各種語境中出現的實體歧義性。透過收集特定實體周圍的摘錄，並利用 GPT-4 語言模型，可以提取相關實體和關係。然後使用提取的資訊來建構知識圖譜，並使用 Leiden 演算法進行聚類。結果產生的 Leiden 社群用於識別未知摘錄與每個社群的關聯百分比，從而消除歧義性。該實驗展示了結合 LLM 和知識圖譜聚類技術在天文研究中進行資訊提取的潛力。結果突顯了該方法在識別和消除實體歧義性方面的有效性，以及根據實體之間的關係將實體分組到有意義的群集中。

##### **How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**
2406.11162v2 by Dawulie Jinensibieke, Mieradilijiang Maimaiti, Wentao Xiao, Yuanhang Zheng, Xiaobo Wang

Relation Extraction (RE) serves as a crucial technology for transforming
unstructured text into structured information, especially within the framework
of Knowledge Graph development. Its importance is emphasized by its essential
role in various downstream tasks. Besides the conventional RE methods which are
based on neural networks and pre-trained language models, large language models
(LLMs) are also utilized in the research field of RE. However, on low-resource
languages (LRLs), both conventional RE methods and LLM-based methods perform
poorly on RE due to the data scarcity issues. To this end, this paper
constructs low-resource relation extraction datasets in 10 LRLs in three
regions (Central Asia, Southeast Asia and Middle East). The corpora are
constructed by translating the original publicly available English RE datasets
(NYT10, FewRel and CrossRE) using an effective multilingual machine
translation. Then, we use the language perplexity (PPL) to filter out the
low-quality data from the translated datasets. Finally, we conduct an empirical
study and validate the performance of several open-source LLMs on these
generated LRL RE datasets.

摘要：關係抽取 (RE) 是一種將非結構化文字轉換為結構化資訊的關鍵技術，特別是在知識圖譜開發的架構中。其重要性在於它在各種下游任務中扮演著不可或缺的角色。除了基於神經網路和預訓練語言模型的傳統 RE 方法之外，大型語言模型 (LLM) 也被用於 RE 的研究領域。然而，在低資源語言 (LRL) 中，由於資料稀少的問題，傳統的 RE 方法和基於 LLM 的方法在 RE 上的表現都很差。有鑑於此，本文在三個地區（中亞、東南亞和中東）的 10 種 LRL 中建構了低資源關係抽取資料集。這些語料庫是透過使用一種有效的多語言機器翻譯來翻譯原始公開的英文 RE 資料集（NYT10、FewRel 和 CrossRE）而建構的。然後，我們使用語言困惑度 (PPL) 從翻譯後的資料集中篩選出低品質的資料。最後，我們進行一項實證研究，並驗證了幾個開源 LLM 在這些生成的 LRL RE 資料集上的效能。

##### **Context Graph**
2406.11160v3 by Chengjin Xu, Muzhi Li, Cehao Yang, Xuhui Jiang, Lumingyuan Tang, Yiyan Qi, Jian Guo

Knowledge Graphs (KGs) are foundational structures in many AI applications,
representing entities and their interrelations through triples. However,
triple-based KGs lack the contextual information of relational knowledge, like
temporal dynamics and provenance details, which are crucial for comprehensive
knowledge representation and effective reasoning. Instead, \textbf{Context
Graphs} (CGs) expand upon the conventional structure by incorporating
additional information such as time validity, geographic location, and source
provenance. This integration provides a more nuanced and accurate understanding
of knowledge, enabling KGs to offer richer insights and support more
sophisticated reasoning processes. In this work, we first discuss the inherent
limitations of triple-based KGs and introduce the concept of CGs, highlighting
their advantages in knowledge representation and reasoning. We then present a
context graph reasoning \textbf{CGR$^3$} paradigm that leverages large language
models (LLMs) to retrieve candidate entities and related contexts, rank them
based on the retrieved information, and reason whether sufficient information
has been obtained to answer a query. Our experimental results demonstrate that
CGR$^3$ significantly improves performance on KG completion (KGC) and KG
question answering (KGQA) tasks, validating the effectiveness of incorporating
contextual information on KG representation and reasoning.

摘要：知識圖譜 (KG) 是許多 AI 應用中的基礎結構，透過三元組來表示實體及其相互關係。然而，基於三元組的 KG 缺乏關係知識的脈絡資訊，例如時間動態和來源細節，這些資訊對於全面的知識表示和有效推理至關重要。取而代之的是，**脈絡圖譜** (CG) 透過納入時間有效性、地理位置和來源出處等額外資訊，擴展了傳統結構。這種整合提供了對知識更細緻且準確的理解，使 KG 能夠提供更豐富的見解，並支援更精密的推理過程。在這項工作中，我們首先討論了基於三元組的 KG 的內在限制，並介紹 CG 的概念，強調它們在知識表示和推理方面的優勢。接下來，我們提出一個脈絡圖譜推理**CGR$^3$**範例，它利用大型語言模型 (LLM) 來擷取候選實體和相關脈絡，根據擷取的資訊對它們進行排序，並推論是否已取得足夠的資訊來回答查詢。我們的實驗結果證明，CGR$^3$ 在 KG 完成 (KGC) 和 KG 問答 (KGQA) 任務上顯著提升了效能，驗證了在 KG 表示和推理中納入脈絡資訊的有效性。

##### **Are Large Language Models a Good Replacement of Taxonomies?**
2406.11131v2 by Yushi Sun, Hao Xin, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan Tang, Lei Chen

Large language models (LLMs) demonstrate an impressive ability to internalize
knowledge and answer natural language questions. Although previous studies
validate that LLMs perform well on general knowledge while presenting poor
performance on long-tail nuanced knowledge, the community is still doubtful
about whether the traditional knowledge graphs should be replaced by LLMs. In
this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made
obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies
and at taxonomy levels that are common to people. Unfortunately, there lacks a
comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies
from common to specialized domains and at levels from root to leaf so that we
can draw a confident conclusion. To narrow the research gap, we constructed a
novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to
evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten
representative taxonomies from common to specialized domains with in-depth
experiments of different levels of entities in this taxonomy from root to leaf.
Our comprehensive experiments of eighteen state-of-the-art LLMs under three
prompting settings validate that LLMs can still not well capture the knowledge
of specialized taxonomies and leaf-level entities.

摘要：大型語言模型 (LLM) 展示了將知識內化並回答自然語言問題的驚人能力。儘管先前的研究驗證了 LLM 在一般知識上表現良好，但在長尾細微知識上表現不佳，但社群仍然懷疑傳統知識圖譜是否應被 LLM 取代。在本文中，我們探討知識圖譜的架構 (即分類法) 是否被 LLM 取代。直觀上，LLM 應在常見分類法和對人們來說常見的分類法層級中表現良好。不幸的是，缺乏一個綜合基準來評估 LLM 在從一般到專業領域的廣泛分類法以及從根到葉的層級，以便我們可以得出確信的結論。為了縮小研究差距，我們構建了一個名為 TaxoGlimpse 的新分類法層級結構發現基準，以評估 LLM 在分類法上的表現。TaxoGlimpse 涵蓋了從一般到專業領域的十個代表性分類法，並對該分類法中從根到葉的不同層級實體進行深入實驗。我們對 18 個最先進的 LLM 在三種提示設定下的綜合實驗驗證了 LLM 仍然無法很好地掌握專業分類法和葉級實體的知識。

##### **DocNet: Semantic Structure in Inductive Bias Detection Models**
2406.10965v1 by Jessica Zhu, Iain Cruickshank, Michel Cukier

News will have biases so long as people have opinions. However, as social
media becomes the primary entry point for news and partisan gaps increase, it
is increasingly important for informed citizens to be able to identify bias.
People will be able to take action to avoid polarizing echo chambers if they
know how the news they are consuming is biased. In this paper, we explore an
often overlooked aspect of bias detection in documents: the semantic structure
of news articles. We present DocNet, a novel, inductive, and low-resource
document embedding and bias detection model that outperforms large language
models. We also demonstrate that the semantic structure of news articles from
opposing partisan sides, as represented in document-level graph embeddings,
have significant similarities. These results can be used to advance bias
detection in low-resource environments. Our code and data are made available at
https://github.com/nlpresearchanon.

摘要：新聞會存在偏見，只要人們有意見。然而，由於社群媒體成為新聞的主要入口，且黨派差距擴大，對於有知識的公民來說，能夠辨識偏見變得愈來愈重要。如果人們知道他們所接收的新聞如何偏頗，他們就能採取行動來避免兩極化的同溫層。在本文中，我們探討文件偏見偵測中經常被忽略的一面：新聞文章的語意結構。我們提出 DocNet，一個新穎、歸納且低資源的文件嵌入和偏見偵測模型，其表現優於大型語言模型。我們也證明，來自對立黨派陣營的新聞文章的語意結構，如文件層級圖嵌入中所呈現的，具有顯著的相似性。這些結果可用於推進低資源環境中的偏見偵測。我們的程式碼和資料可在 https://github.com/nlpresearchanon 取得。

##### **Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**
2406.10902v1 by Yikai Zhang, Qianyu He, Xintao Wang, Siyu Yuan, Jiaqing Liang, Yanghua Xiao

Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various
downstream tasks. However, scaling them up is challenging because building
large-scale MMKGs often introduces mismatched images (i.e., noise). Most
entities in KGs belong to the long tail, meaning there are few images of them
available online. This scarcity makes it difficult to determine whether a found
image matches the entity. To address this, we draw on the Triangle of Reference
Theory and suggest enhancing vision-language models with concept guidance.
Specifically, we introduce COG, a two-stage framework with COncept-Guided
vision-language models. The framework comprises a Concept Integration module,
which effectively identifies image-text pairs of long-tailed entities, and an
Evidence Fusion module, which offers explainability and enables human
verification. To demonstrate the effectiveness of COG, we create a dataset of
25k image-text pairs of long-tailed entities. Our comprehensive experiments
show that COG not only improves the accuracy of recognizing long-tailed
image-text pairs compared to baselines but also offers flexibility and
explainability.

摘要：多模态知识图谱 (MMKG) 已被证明对各种下游任务很有价值。然而，扩展它们具有挑战性，因为构建大规模 MMKG 经常会引入不匹配的图像（即噪声）。知识图谱中的大多数实体都属于长尾，这意味着网上很少有它们的图像。这种稀缺性使得难以确定找到的图像是否与实体匹配。为了解决这个问题，我们借鉴了三角参照理论，并建议用概念指导来增强视觉语言模型。具体来说，我们引入了 COG，这是一个带有概念指导视觉语言模型的两阶段框架。该框架包含一个概念集成模块，该模块有效地识别长尾实体的图像文本对，以及一个证据融合模块，该模块提供可解释性并支持人工验证。为了证明 COG 的有效性，我们创建了一个由 25k 个长尾实体的图像文本对组成的数据集。我们的综合实验表明，与基线相比，COG 不仅提高了识别长尾图像文本对的准确性，还提供了灵活性和可解释性。

##### **KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**
2406.10802v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia, Lina Wang

Existing frameworks for assessing robustness of large language models (LLMs)
overly depend on specific benchmarks, increasing costs and failing to evaluate
performance of LLMs in professional domains due to dataset limitations. This
paper proposes a framework that systematically evaluates the robustness of LLMs
under adversarial attack scenarios by leveraging knowledge graphs (KGs). Our
framework generates original prompts from the triplets of knowledge graphs and
creates adversarial prompts by poisoning, assessing the robustness of LLMs
through the results of these adversarial attacks. We systematically evaluate
the effectiveness of this framework and its modules. Experiments show that
adversarial robustness of the ChatGPT family ranks as GPT-4-turbo > GPT-4o >
GPT-3.5-turbo, and the robustness of large language models is influenced by the
professional domains in which they operate.

摘要：現有的用於評估大型語言模型 (LLM) 穩健性的框架過於依賴特定基準，這會增加成本，而且由於資料集的限制，無法評估 LLM 在專業領域的效能。本文提出了一個框架，利用知識圖譜 (KG) 系統性地評估 LLM 在對抗攻擊場景下的穩健性。我們的框架從知識圖譜的三元組中產生原始提示，並透過投毒建立對抗提示，透過這些對抗攻擊的結果來評估 LLM 的穩健性。我們系統性地評估了此框架及其模組的有效性。實驗顯示，ChatGPT 家族的對抗穩健性排名為 GPT-4-turbo > GPT-4o > GPT-3.5-turbo，而且大型語言模型的穩健性會受到其運作的專業領域影響。

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

摘要：基礎模型 (FM) 是使用自我監督技術在廣泛數據集上訓練的大規模深度學習模型。這些模型作為各種下游任務的基礎，包括醫療保健。FM 已在醫療保健的各種領域中被廣泛採用，包括自然語言處理 (NLP)、電腦視覺、圖形學習、生物學和組學。現有的基於醫療保健的調查尚未涵蓋所有這些領域。因此，本調查提供了 FM 在醫療保健中的全面概述。我們專注於 FM 的歷史、學習策略、旗艦模型、應用和挑戰。我們探討了 BERT 和 GPT 家族等 FM 如何重塑各種醫療保健領域，包括臨床大型語言模型、醫學影像分析和組學數據。此外，我們提供了由 FM 促進的醫療保健應用詳細分類法，例如臨床 NLP、醫學電腦視覺、圖形學習和其他與生物相關的任務。儘管 FM 提供了有希望的機會，但它們也面臨著一些相關的挑戰，這些挑戰在文中都有詳細說明。我們還概述了潛在的未來方向，為研究人員和從業者提供有關 FM 在醫療保健中的潛力和局限性的見解，以推進其部署並減輕相關風險。

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

摘要：<paragraph>將大型語言模型 (LLM) 與現有的知識圖譜 (KG) 資料庫整合，提供了一個提升 LLM 效能並減輕其「幻覺」的途徑。由於大多數 KG 都存在於僅能透過專用查詢語言（例如 Cypher）存取的圖形資料庫中，因此迫切需要自動化將自然語言轉換為 Cypher 查詢，以彌合 LLM 與 KG 資料庫之間的鴻溝（通常稱為「Text2Cypher」任務）。先前的努力嘗試透過監督微調來提升 LLM 在 Cypher 生成方面的能力。然而，這些探索受到缺乏查詢-Cypher 配對的註解資料集的阻礙，這是因為此類資料集的註解需要大量人力且具有特定領域的性質。在本研究中，我們提出了 SyntheT2C，這是一種用於建構合成查詢-Cypher 配對資料集的方法，包含兩個不同的管道：(1) 基於 LLM 的提示和 (2) 範本填寫。SyntheT2C 促進了大量查詢-Cypher 配對的產生，其值取樣自基礎的 Neo4j 圖形資料庫。隨後，將 SyntheT2C 應用於兩個醫療資料庫，最終建立了一個合成資料集 MedT2C。全面的實驗證明，MedT2C 資料集有效提升了主幹 LLM 在 Text2Cypher 任務上的效能。SyntheT2C 程式碼庫和 MedT2C 資料集都將很快釋出。</paragraph>

##### **Large Language Models as Event Forecasters**
2406.10492v1 by Libo Zhang, Yue Ning

Key elements of human events are extracted as quadruples that consist of
subject, relation, object, and timestamp. This representation can be extended
to a quintuple by adding a fifth element: a textual summary that briefly
describes the event. These quadruples or quintuples, when organized within a
specific domain, form a temporal knowledge graph (TKG). Current learning
frameworks focus on a few TKG-related tasks, such as predicting an object given
a subject and a relation or forecasting the occurrences of multiple types of
events (i.e., relation) in the next time window. They typically rely on complex
structural and sequential models like graph neural networks (GNNs) and
recurrent neural networks (RNNs) to update intermediate embeddings. However,
these methods often neglect the contextual information inherent in each
quintuple, which can be effectively captured through concise textual
descriptions. In this paper, we investigate how large language models (LLMs)
can streamline the design of TKG learning frameworks while maintaining
competitive accuracy in prediction and forecasting tasks. We develop multiple
prompt templates to frame the object prediction (OP) task as a standard
question-answering (QA) task, suitable for instruction fine-tuning with an
encoder-decoder generative LLM. For multi-event forecasting (MEF), we design
simple yet effective prompt templates for each TKG quintuple. This novel
approach removes the need for GNNs and RNNs, instead utilizing an encoder-only
LLM to generate fixed intermediate embeddings, which are subsequently processed
by a prediction head with a self-attention mechanism to forecast potential
future relations. Extensive experiments on multiple real-world datasets using
various evaluation metrics validate the effectiveness and robustness of our
approach.

摘要：<paragraph>人類事件的主要元素被萃取為由主詞、關係、受詞和時間戳組成的四元組。此表示法可透過新增第五個元素來延伸為五元組：簡要描述事件的文字摘要。這些四元組或五元組在特定領域中組織時，會形成時序知識圖譜 (TKG)。目前的學習架構專注於一些與 TKG 相關的任務，例如在給定主詞和關係的情況下預測受詞，或預測下一個時間視窗中多種類型事件（即關係）的發生。它們通常依賴於複雜的結構和序列模型，例如圖形神經網路 (GNN) 和遞迴神經網路 (RNN)，來更新中間嵌入。然而，這些方法經常忽略每個五元組中固有的脈絡資訊，而這些資訊可透過簡潔的文字描述有效擷取。在本文中，我們探討大型語言模型 (LLM) 如何簡化 TKG 學習架構的設計，同時在預測和預測任務中維持具競爭力的準確度。我們開發多個提示範本，將物件預測 (OP) 任務設定為標準問答 (QA) 任務，適用於使用編碼器-解碼器生成式 LLM 進行指令微調。對於多事件預測 (MEF)，我們為每個 TKG 五元組設計簡單但有效的提示範本。這種新穎的方法消除了對 GNN 和 RNN 的需求，而是利用僅編碼器 LLM 來產生固定的中間嵌入，然後由具有自注意力機制的預測頭處理這些嵌入，以預測潛在的未來關係。使用各種評估指標對多個真實世界資料集進行的廣泛實驗驗證了我們方法的有效性和穩健性。</paragraph>

##### **Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**
2406.10479v1 by Wenjun Li, Changyu Chen, Pradeep Varakantham

Large language models (LLMs) have demonstrated impressive task-solving
capabilities, achieved through either prompting techniques or system designs.
However, concerns have arisen regarding their proficiency in planning tasks, as
they often struggle to generate valid plans. This paper investigates the impact
of fine-tuning on LLMs' planning capabilities. Our findings indicate that LLMs
can achieve good performance in planning through substantial (thousands of
specific examples) fine-tuning. However, fine-tuning is associated with
significant economic and computational costs. To address this challenge, we
propose the Maximum Diversity Fine-Tuning (MDFT) strategy to improve the sample
efficiency of fine-tuning in the planning domain. Specifically, our algorithm,
referred to as MDFT-g, encodes the planning task instances with their graph
representations and selects a subset of samples in the vector space that
maximizes data diversity. We empirically demonstrate that MDFT-g consistently
outperforms existing baselines at various scales across multiple benchmark
domains.

摘要：大型語言模型 (LLM) 已展現出令人印象深刻的任務解決能力，這是透過提示技術或系統設計來達成。然而，對於 LLM 在規劃任務中的能力，已產生疑慮，因為它們經常難以產生有效的計畫。本文探討微調對 LLM 規劃能力的影響。我們的研究結果顯示，LLM 可以透過大量的微調（數千個具體範例）在規劃中獲得良好的表現。然而，微調與顯著的經濟和運算成本相關。為了應對此挑戰，我們提出最大多樣性微調 (MDFT) 策略，以提升規劃領域微調的樣本效率。具體來說，我們稱為 MDFT-g 的演算法，以圖形表示對規劃任務實例進行編碼，並在向量空間中選擇一個樣本子集，以最大化資料多樣性。我們實證證明，MDFT-g 在多個基準領域的不同規模中，始終優於現有的基準。

##### **Precision Empowers, Excess Distracts: Visual Question Answering With Dynamically Infused Knowledge In Language Models**
2406.09994v1 by Manas Jhalani, Annervaz K M, Pushpak Bhattacharyya

In the realm of multimodal tasks, Visual Question Answering (VQA) plays a
crucial role by addressing natural language questions grounded in visual
content. Knowledge-Based Visual Question Answering (KBVQA) advances this
concept by adding external knowledge along with images to respond to questions.
We introduce an approach for KBVQA, augmenting the existing vision-language
transformer encoder-decoder (OFA) model. Our main contribution involves
enhancing questions by incorporating relevant external knowledge extracted from
knowledge graphs, using a dynamic triple extraction method. We supply a
flexible number of triples from the knowledge graph as context, tailored to
meet the requirements for answering the question. Our model, enriched with
knowledge, demonstrates an average improvement of 4.75\% in Exact Match Score
over the state-of-the-art on three different KBVQA datasets. Through
experiments and analysis, we demonstrate that furnishing variable triples for
each question improves the reasoning capabilities of the language model in
contrast to supplying a fixed number of triples. This is illustrated even for
recent large language models. Additionally, we highlight the model's
generalization capability by showcasing its SOTA-beating performance on a small
dataset, achieved through straightforward fine-tuning.

摘要：在多模态任务领域，视觉问答（VQA）通过解决基于视觉内容的自然语言问题，扮演着至关重要的角色。基于知识的视觉问答（KBVQA）通过添加外部知识以及图像来回答问题，从而推进了这一概念。我们引入了一种用于 KBVQA 的方法，增强了现有的视觉语言 transformer 编码器解码器 (OFA) 模型。我们的主要贡献涉及通过使用动态三元组提取方法，整合从知识图谱中提取的相关外部知识来增强问题。我们提供来自知识图谱的灵活数量的三元组作为上下文，以满足回答问题的要求。我们经过知识丰富的模型在三个不同的 KBVQA 数据集上，在精确匹配分数方面展示了比最先进水平平均提高 4.75%。通过实验和分析，我们证明为每个问题提供可变三元组提高了语言模型的推理能力，这与提供固定数量的三元组形成对比。即使对于最近的大型语言模型，这一点也得到了说明。此外，我们通过展示模型在小型数据集上的 SOTA 击败性能，突出了模型的泛化能力，这是通过直接微调实现的。

##### **DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning**
2406.09953v2 by Zeyu Gao, Yao Mu, Jinye Qu, Mengkang Hu, Lingyue Guo, Ping Luo, Yanfeng Lu

Dual-arm robots offer enhanced versatility and efficiency over single-arm
counterparts by enabling concurrent manipulation of multiple objects or
cooperative execution of tasks using both arms. However, effectively
coordinating the two arms for complex long-horizon tasks remains a significant
challenge. Existing task planning methods predominantly focus on single-arm
robots or rely on predefined bimanual operations, failing to fully leverage the
capabilities of dual-arm systems. To address this limitation, we introduce
DAG-Plan, a structured task planning framework tailored for dual-arm robots.
DAG-Plan harnesses large language models (LLMs) to decompose intricate tasks
into actionable sub-tasks represented as nodes within a directed acyclic graph
(DAG). Critically, DAG-Plan dynamically assigns these sub-tasks to the
appropriate arm based on real-time environmental observations, enabling
parallel and adaptive execution. We evaluate DAG-Plan on the novel Dual-Arm
Kitchen Benchmark, comprising 9 sequential tasks with 78 sub-tasks and 26
objects. Extensive experiments demonstrate the superiority of DAG-Plan over
directly using LLM to generate plans, achieving nearly 50% higher efficiency
compared to the single-arm task planning baseline and nearly double the success
rate of the dual-arm task planning baseline.

摘要：雙臂機器人透過同時處理多個物件或使用兩隻手臂協作執行任務，提供比單臂機器人更高的多功能性和效率。然而，要有效協調兩隻手臂執行複雜且時間跨度長的任務，仍然是一項重大的挑戰。現有的任務規劃方法主要專注於單臂機器人，或依賴於預先定義的雙手操作，無法充分利用雙臂系統的能力。為了解決這個限制，我們引入了 DAG-Plan，一個專為雙臂機器人量身打造的結構化任務規劃框架。DAG-Plan 利用大型語言模型 (LLM) 將複雜的任務分解成可操作的子任務，並將其表示為有向無環圖 (DAG) 中的節點。更重要的是，DAG-Plan 會根據即時的環境觀察結果，動態地將這些子任務分配給適當的手臂，從而實現並行和自適應的執行。我們在創新的雙臂廚房基準測試中評估了 DAG-Plan，該基準測試包含 9 個連續任務、78 個子任務和 26 個物件。大量的實驗證明了 DAG-Plan 優於直接使用 LLM 來產生計畫，與單臂任務規劃基準線相比，效率提高了近 50%，與雙臂任務規劃基準線相比，成功率幾乎提高了一倍。

##### **TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs**
2406.10310v1 by Zhuofeng Li, Zixing Gou, Xiangnan Zhang, Zhongyuan Liu, Sirui Li, Yuntong Hu, Chen Ling, Zheng Zhang, Liang Zhao

Text-Attributed Graphs (TAGs) augment graph structures with natural language
descriptions, facilitating detailed depictions of data and their
interconnections across various real-world settings. However, existing TAG
datasets predominantly feature textual information only at the nodes, with
edges typically represented by mere binary or categorical attributes. This lack
of rich textual edge annotations significantly limits the exploration of
contextual relationships between entities, hindering deeper insights into
graph-structured data. To address this gap, we introduce Textual-Edge Graphs
Datasets and Benchmark (TEG-DB), a comprehensive and diverse collection of
benchmark textual-edge datasets featuring rich textual descriptions on nodes
and edges. The TEG-DB datasets are large-scale and encompass a wide range of
domains, from citation networks to social networks. In addition, we conduct
extensive benchmark experiments on TEG-DB to assess the extent to which current
techniques, including pre-trained language models, graph neural networks, and
their combinations, can utilize textual node and edge information. Our goal is
to elicit advancements in textual-edge graph research, specifically in
developing methodologies that exploit rich textual node and edge descriptions
to enhance graph analysis and provide deeper insights into complex real-world
networks. The entire TEG-DB project is publicly accessible as an open-source
repository on Github, accessible at
https://github.com/Zhuofeng-Li/TEG-Benchmark.

摘要：文字標註圖（TAG）以自然語言描述擴充圖形結構，協助詳細描繪資料及其在各種真實世界設定中的相互連結。然而，現有的 TAG 資料集主要僅在節點中呈現文字資訊，邊緣通常僅以二進位或分類屬性表示。這種缺乏豐富的文字邊緣註解，會大幅限制探索實體間的脈絡關係，阻礙深入了解圖形結構資料。為了解決此差距，我們引進文字邊緣圖形資料集與基準（TEG-DB），這是一個全面且多樣化的基準文字邊緣資料集集合，在節點和邊緣上具有豐富的文字描述。TEG-DB 資料集規模龐大，涵蓋從引文網路到社交網路的廣泛領域。此外，我們在 TEG-DB 上進行廣泛的基準實驗，以評估目前技術（包括預先訓練的語言模型、圖形神經網路及其組合）在何種程度上能利用文字節點和邊緣資訊。我們的目標是引發文字邊緣圖形研究的進展，特別是在開發利用豐富文字節點和邊緣描述來增強圖形分析並提供對複雜真實世界網路更深入見解的方法論。整個 TEG-DB 專案以開源儲存庫的形式公開於 Github，可於 https://github.com/Zhuofeng-Li/TEG-Benchmark 取得。

