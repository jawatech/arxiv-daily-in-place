
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v1](http://arxiv.org/abs/2409.17055v1)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v1](http://arxiv.org/abs/2409.16898v1)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**|Yishu Wei et.al.|[2409.16563v1](http://arxiv.org/abs/2409.16563v1)|null|
|**2024-09-24**|**To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**|Imra Aqeel et.al.|[2409.16486v1](http://arxiv.org/abs/2409.16486v1)|null|
|**2024-09-24**|**Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**|Gabriele De Vito et.al.|[2409.16395v1](http://arxiv.org/abs/2409.16395v1)|null|
|**2024-09-24**|**Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**|Nikolas Koutsoubis et.al.|[2409.16340v1](http://arxiv.org/abs/2409.16340v1)|null|
|**2024-09-24**|**Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**|Henry Musto et.al.|[2409.16231v1](http://arxiv.org/abs/2409.16231v1)|null|
|**2024-09-24**|**Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**|Mehtab Ur Rahman et.al.|[2409.16106v2](http://arxiv.org/abs/2409.16106v2)|null|
|**2024-09-24**|**The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**|África Periáñez et.al.|[2409.16098v1](http://arxiv.org/abs/2409.16098v1)|null|
|**2024-09-24**|**Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**|Kriti Agarwal et.al.|[2409.15910v1](http://arxiv.org/abs/2409.15910v1)|null|
|**2024-09-24**|**AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**|Adil Bahaj et.al.|[2409.15815v1](http://arxiv.org/abs/2409.15815v1)|null|
|**2024-09-24**|**Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2409.15814v1](http://arxiv.org/abs/2409.15814v1)|null|
|**2024-09-24**|**Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**|Yooseok Lim et.al.|[2409.15753v1](http://arxiv.org/abs/2409.15753v1)|null|
|**2024-09-24**|**dnaGrinder: a lightweight and high-capacity genomic foundation model**|Qihang Zhao et.al.|[2409.15697v1](http://arxiv.org/abs/2409.15697v1)|null|
|**2024-09-24**|**Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**|Min Tan et.al.|[2409.15688v1](http://arxiv.org/abs/2409.15688v1)|null|
|**2024-09-24**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses**|Abdelrahman Hanafi et.al.|[2409.15687v1](http://arxiv.org/abs/2409.15687v1)|null|
|**2024-09-23**|**TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**|Rosemary Y. He et.al.|[2409.15586v2](http://arxiv.org/abs/2409.15586v2)|null|
|**2024-09-23**|**MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**|Stanislav Kozák et.al.|[2409.16329v1](http://arxiv.org/abs/2409.16329v1)|null|
|**2024-09-23**|**Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**|Ziyu Su et.al.|[2409.15491v1](http://arxiv.org/abs/2409.15491v1)|null|
|**2024-09-23**|**A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**|Yunfei Xie et.al.|[2409.15277v1](http://arxiv.org/abs/2409.15277v1)|null|
|**2024-09-23**|**Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**|Yi-Fei Zhao et.al.|[2409.15260v1](http://arxiv.org/abs/2409.15260v1)|null|
|**2024-09-23**|**Boosting Healthcare LLMs Through Retrieved Context**|Jordi Bayarri-Planas et.al.|[2409.15127v1](http://arxiv.org/abs/2409.15127v1)|null|
|**2024-09-23**|**Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**|Sijia Du et.al.|[2409.15006v1](http://arxiv.org/abs/2409.15006v1)|null|
|**2024-09-23**|**DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**|Sangyeon Cho et.al.|[2409.14904v1](http://arxiv.org/abs/2409.14904v1)|[link](https://github.com/josangyeon/dsg-kd)|
|**2024-09-23**|**Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**|Shilong Yang et.al.|[2409.14876v1](http://arxiv.org/abs/2409.14876v1)|null|
|**2024-09-23**|**Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**|Ahjol Senbi et.al.|[2409.14874v2](http://arxiv.org/abs/2409.14874v2)|null|
|**2024-09-23**|**A-VL: Adaptive Attention for Large Vision-Language Models**|Junyang Zhang et.al.|[2409.14846v1](http://arxiv.org/abs/2409.14846v1)|null|
|**2024-09-22**|**Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**|Yuxing Zhi et.al.|[2409.14478v1](http://arxiv.org/abs/2409.14478v1)|null|
|**2024-09-22**|**Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**|Pablo Ramirez Amador et.al.|[2409.14446v1](http://arxiv.org/abs/2409.14446v1)|null|
|**2024-09-22**|**Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**|Xu Yan et.al.|[2409.14327v1](http://arxiv.org/abs/2409.14327v1)|null|
|**2024-09-22**|**PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**|Yuxuan Zhou et.al.|[2409.14302v1](http://arxiv.org/abs/2409.14302v1)|null|
|**2024-09-21**|**Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**|Rusham Elahi et.al.|[2409.14194v1](http://arxiv.org/abs/2409.14194v1)|null|
|**2024-09-21**|**Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**|Andre de Carvalho et.al.|[2409.14181v1](http://arxiv.org/abs/2409.14181v1)|null|
|**2024-09-20**|**CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**|Zhao Cheng et.al.|[2409.13903v1](http://arxiv.org/abs/2409.13903v1)|null|
|**2024-09-20**|**Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**|Aidan Gilson et.al.|[2409.13902v1](http://arxiv.org/abs/2409.13902v1)|null|
|**2024-09-20**|**A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**|Mengyun Qiao et.al.|[2409.13825v1](http://arxiv.org/abs/2409.13825v1)|null|
|**2024-09-20**|**Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**|Hadi Rezvani et.al.|[2409.13688v1](http://arxiv.org/abs/2409.13688v1)|null|
|**2024-09-20**|**Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**|Kunyao Lan et.al.|[2409.15084v1](http://arxiv.org/abs/2409.15084v1)|null|
|**2024-09-20**|**Toward Automated Clinical Transcriptions**|Mitchell A. Klusty et.al.|[2409.15378v1](http://arxiv.org/abs/2409.15378v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-20**|**Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**|Xiaowen Fu et.al.|[2409.13440v1](http://arxiv.org/abs/2409.13440v1)|null|
|**2024-09-20**|**FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**|Alberto Archetti et.al.|[2409.13363v1](http://arxiv.org/abs/2409.13363v1)|null|
|**2024-09-20**|**Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**|Annette Spooner et.al.|[2409.13791v1](http://arxiv.org/abs/2409.13791v1)|null|
|**2024-09-20**|**Recent Advancement of Emotion Cognition in Large Language Models**|Yuyan Chen et.al.|[2409.13354v1](http://arxiv.org/abs/2409.13354v1)|null|
|**2024-09-20**|**SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**|Jinge Wu et.al.|[2409.13321v1](http://arxiv.org/abs/2409.13321v1)|null|
|**2024-09-20**|**OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**|Yooseok Lim et.al.|[2409.13299v1](http://arxiv.org/abs/2409.13299v1)|null|
|**2024-09-20**|**Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**|Elisa Castagnari et.al.|[2409.15377v1](http://arxiv.org/abs/2409.15377v1)|null|
|**2024-09-20**|**An adapted large language model facilitates multiple medical tasks in diabetes care**|Lai Wei et.al.|[2409.13191v1](http://arxiv.org/abs/2409.13191v1)|[link](https://github.com/waltonfuture/Diabetica)|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**|Areej Alsaafin et.al.|[2409.13115v1](http://arxiv.org/abs/2409.13115v1)|null|
|**2024-09-19**|**DenoMamba: A fused state-space model for low-dose CT denoising**|Şaban Öztürk et.al.|[2409.13094v1](http://arxiv.org/abs/2409.13094v1)|null|
|**2024-09-19**|**AutoPET III Challenge: Tumor Lesion Segmentation using ResEnc-Model Ensemble**|Tanya Chutani et.al.|[2409.13779v1](http://arxiv.org/abs/2409.13779v1)|null|
|**2024-09-19**|**HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation**|Julián N. Acosta et.al.|[2409.13038v1](http://arxiv.org/abs/2409.13038v1)|null|
|**2024-09-19**|**iCost: A Novel Instance Complexity Based Cost-Sensitive Learning Framework for Imbalanced Classification**|Asif Newaz et.al.|[2409.13007v1](http://arxiv.org/abs/2409.13007v1)|null|
|**2024-09-19**|**Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing**|Shashi Shekhar Kumar et.al.|[2409.15372v1](http://arxiv.org/abs/2409.15372v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-19**|**Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences**|Ricky Sahu et.al.|[2409.13000v1](http://arxiv.org/abs/2409.13000v1)|null|
|**2024-09-19**|**Fine Tuning Large Language Models for Medicine: The Role and Importance of Direct Preference Optimization**|Thomas Savage et.al.|[2409.12741v2](http://arxiv.org/abs/2409.12741v2)|null|
|**2024-09-19**|**SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference**|Zhen Chen et.al.|[2409.12467v1](http://arxiv.org/abs/2409.12467v1)|[link](https://github.com/lxj22/surgplan-plus)|
|**2024-09-19**|**FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention Scaling**|Enze Shi et.al.|[2409.12454v1](http://arxiv.org/abs/2409.12454v1)|null|
|**2024-09-19**|**Domain Generalization for Endoscopic Image Segmentation by Disentangling Style-Content Information and SuperPixel Consistency**|Mansoor Ali Teevno et.al.|[2409.12450v1](http://arxiv.org/abs/2409.12450v1)|null|
|**2024-09-19**|**Bundle Fragments into a Whole: Mining More Complete Clusters via Submodular Selection of Interesting webpages for Web Topic Detection**|Junbiao Pang et.al.|[2409.12380v1](http://arxiv.org/abs/2409.12380v1)|null|
|**2024-09-18**|**Extracting Memorized Training Data via Decomposition**|Ellen Su et.al.|[2409.12367v1](http://arxiv.org/abs/2409.12367v1)|null|
|**2024-09-18**|**Axial Attention Transformer Networks: A New Frontier in Breast Cancer Detection**|Weijie He et.al.|[2409.12347v1](http://arxiv.org/abs/2409.12347v1)|null|
|**2024-09-18**|**Deep vessel segmentation with joint multi-prior encoding**|Amine Sadikine et.al.|[2409.12334v1](http://arxiv.org/abs/2409.12334v1)|null|
|**2024-09-18**|**MedCodER: A Generative AI Assistant for Medical Coding**|Krishanu Das Baksi et.al.|[2409.15368v1](http://arxiv.org/abs/2409.15368v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-18**|**EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**|Shaojie Li et.al.|[2409.11817v1](http://arxiv.org/abs/2409.11817v1)|null|
|**2024-09-18**|**Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**|Asad Aali et.al.|[2409.11686v1](http://arxiv.org/abs/2409.11686v1)|null|
|**2024-09-18**|**Agent Aggregator with Mask Denoise Mechanism for Histopathology Whole Slide Image Analysis**|Xitong Ling et.al.|[2409.11664v1](http://arxiv.org/abs/2409.11664v1)|null|
|**2024-09-18**|**A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**|Ari Gestetner et.al.|[2409.11631v1](http://arxiv.org/abs/2409.11631v1)|null|
|**2024-09-17**|**Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**|Qingqing Wang et.al.|[2409.11576v1](http://arxiv.org/abs/2409.11576v1)|null|
|**2024-09-17**|**Two Stage Segmentation of Cervical Tumors using PocketNet**|Awj Twam et.al.|[2409.11456v1](http://arxiv.org/abs/2409.11456v1)|null|
|**2024-09-17**|**Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification**|Fatema-E- Jannat et.al.|[2409.11375v1](http://arxiv.org/abs/2409.11375v1)|null|
|**2024-09-17**|**Clinical Validation of a Real-Time Machine Learning-based System for the Detection of Acute Myeloid Leukemia by Flow Cytometry**|Lauren M. Zuromski et.al.|[2409.11350v1](http://arxiv.org/abs/2409.11350v1)|null|
|**2024-09-17**|**TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation**|Rong Zhou et.al.|[2409.11299v2](http://arxiv.org/abs/2409.11299v2)|[link](https://github.com/rongzhou7/ttt-unet)|
|**2024-09-17**|**EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage**|Zeyi Liao et.al.|[2409.11295v1](http://arxiv.org/abs/2409.11295v1)|[link](https://github.com/osu-nlp-group/eia_against_webagent)|
|**2024-09-17**|**Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory**|Eunhae Lee et.al.|[2409.11192v1](http://arxiv.org/abs/2409.11192v1)|null|
|**2024-09-17**|**Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine Learning Approach**|Mehroush Banday et.al.|[2409.10932v1](http://arxiv.org/abs/2409.10932v1)|null|
|**2024-09-16**|**Self-supervised Speech Models for Word-Level Stuttered Speech Detection**|Yi-Jen Shih et.al.|[2409.10704v1](http://arxiv.org/abs/2409.10704v1)|null|
|**2024-09-16**|**A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**|Zhang Zheng et.al.|[2409.10403v1](http://arxiv.org/abs/2409.10403v1)|null|
|**2024-09-16**|**Robust image representations with counterfactual contrastive learning**|Mélanie Roschewitz et.al.|[2409.10365v1](http://arxiv.org/abs/2409.10365v1)|[link](https://github.com/biomedia-mira/counterfactual-contrastive)|
|**2024-09-16**|**Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search for COVID-19 Misinformation between the United States and South Africa**|Hayoung Jung et.al.|[2409.10168v1](http://arxiv.org/abs/2409.10168v1)|null|
|**2024-09-16**|**Machine listening in a neonatal intensive care unit**|Modan Tailleur et.al.|[2409.11439v1](http://arxiv.org/abs/2409.11439v1)|null|
|**2024-09-16**|**DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion**|Yuchen Guo et.al.|[2409.10080v1](http://arxiv.org/abs/2409.10080v1)|null|
|**2024-09-16**|**MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM**|Sijie Ji et.al.|[2409.10064v1](http://arxiv.org/abs/2409.10064v1)|null|
|**2024-09-16**|**HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making**|Sumera Anjum et.al.|[2409.10011v2](http://arxiv.org/abs/2409.10011v2)|[link](https://github.com/responsibleailab/halo)|
|**2024-09-16**|**Artificial Intelligence-Based Opportunistic Coronary Calcium Screening in the Veterans Affairs National Healthcare System**|Raffi Hagopian et.al.|[2409.09968v1](http://arxiv.org/abs/2409.09968v1)|null|
|**2024-09-15**|**GP-GPT: Large Language Model for Gene-Phenotype Mapping**|Yanjun Lyu et.al.|[2409.09825v1](http://arxiv.org/abs/2409.09825v1)|null|
|**2024-09-15**|**Veridical Data Science for Medical Foundation Models**|Ahmed Alaa et.al.|[2409.10580v1](http://arxiv.org/abs/2409.10580v1)|null|
|**2024-09-15**|**From Challenges and Pitfalls to Recommendations and Opportunities: Implementing Federated Learning in Healthcare**|Ming Li et.al.|[2409.09727v1](http://arxiv.org/abs/2409.09727v1)|null|
|**2024-09-15**|**ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models**|Inhwa Song et.al.|[2409.09662v2](http://arxiv.org/abs/2409.09662v2)|null|
|**2024-09-15**|**MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences**|Subigya Nepal et.al.|[2409.09570v1](http://arxiv.org/abs/2409.09570v1)|null|
|**2024-09-14**|**COMFORT: A Continual Fine-Tuning Framework for Foundation Models Targeted at Consumer Healthcare**|Chia-Hao Li et.al.|[2409.09549v1](http://arxiv.org/abs/2409.09549v1)|null|
|**2024-09-14**|**Enhancing Skin Disease Diagnosis: Interpretable Visual Concept Discovery with SAM Empowerment**|Xin Hu et.al.|[2409.09520v1](http://arxiv.org/abs/2409.09520v1)|null|

#### Abstracts
##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

摘要：在医学領域中，大規模數據集的可用性有限，且人工標註過程繁瑣，阻礙了深度模型的執行。基於擴散的生成式擴充方法為此問題提供了有前景的解決方案，已被證實能有效推進下游醫療識別任務。儘管如此，現有作品缺乏足夠的語義和序列可控性，難以進行具有挑戰性的視訊/3D 序列生成，且忽略了對有雜訊合成樣本的品質控制，導致合成式資料庫不可靠，並嚴重限制了下游任務的執行。在這項工作中，我們提出了 Ctrl-GenAug，一個新穎且通用的生成式擴充架構，能實現高度語義和序列自訂的序列合成，並抑制錯誤合成的樣本，以協助醫療序列分類。具體來說，我們首先設計了一個多模態條件引導序列生成器，用於可控地合成促進診斷的樣本。整合了一個序列擴充模組，以增強生成樣本的時間/立體一致性。然後，我們提出了一個有雜訊的合成資料濾波器，以抑制語義和序列層級中不可靠的案例。在 3 個醫療數據集上進行的廣泛實驗，使用在 3 個範例中訓練的 11 個網路，全面分析了 Ctrl-GenAug 的有效性和普遍性，特別是在代表性不足的高風險族群和領域外條件中。

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v1 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

摘要：真實生活中的醫療數據通常是多模態且不完整的，這使得對能夠有效整合它們的高級深度學習模型的需求不斷增長。使用多種形式，包括組織病理切片、核磁共振和遺傳數據，提供了前所未有的機會來改進預後預測並揭示新的治療途徑。對比學習廣泛用於從多模態任務中的配對數據中推導出表示，它假設不同的觀點包含相同的與任務相關的信息，並且僅利用共享信息。在處理醫療數據時，這一假設變得具有限制性，因為每種形式也包含與下游任務相關的具體知識。我們介紹了 DRIM，這是一種新的多模態方法，用於捕獲這些共享和唯一的表示，儘管數據稀疏。更具體地說，給定一組形式，我們旨在對每個形式編碼一個表示，該表示可以分為兩個組成部分：一個封裝跨形式的患者相關信息，另一個封裝形式特定的細節。這是通過增加不同患者形式之間的共享信息，同時最大程度地減少每個形式中共享和唯一組成部分之間的重疊來實現的。我們的算法在神經膠質瘤患者的生存預測任務中優於最先進的算法，同時對缺失的形式具有魯棒性。為了促進可重複性，代碼已在 https://github.com/Lucas-rbnt/DRIM 上公開。

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

摘要：<paragraph>導致 Puskesmas 效率低下的關鍵問題之一是，醫生和病人互動耗時。醫生需要進行徹底的諮詢，包括診斷病人的病情、提供治療建議，以及將詳細的筆記記錄在醫療記錄中。在語言背景多元的地區，醫生經常必須提出澄清問題，進一步延長流程。雖然診斷至關重要，但使用 AI 進行轉錄和摘要通常可以自動化，以提高時間效率，並幫助醫生提高護理品質，並實現早期診斷和干預。本文提出了一個使用本地化大型語言模型 (LLM) 來轉錄、翻譯和摘要醫生與病人對話的解決方案。我們利用 Whisper 模型進行轉錄，並使用 GPT-3 將其摘要成 ePuskemas 醫療記錄格式。此系統實作為現有網路瀏覽器擴充功能的附加元件，讓醫生可以在交談時填寫病患表單。透過利用此解決方案進行即時轉錄、翻譯和摘要，醫生可以改善病患照護的周轉時間，同時提升記錄品質，讓記錄變得更詳細且更有洞見，以利於後續就診。此創新解決了像醫療機構人滿為患和印尼醫療保健提供者的行政負擔等挑戰。我們相信此解決方案將幫助醫生節省時間、提供更好的照護，並產生更準確的醫療記錄，代表著現代化醫療保健並確保病人即使在資源受限的環境中也能獲得及時、高品質的照護的重要一步。</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

摘要：<paragraph>我們提供了一個資料集，用於在工程設計中啟用深度生成模型 (DGM)，並提出透過利用大規模基礎模型自動化資料標籤的方法。GeoBiked 經過策展，包含 4,355 張自行車影像，並附有結構和技術特徵註解，且用於調查兩種自動化標籤技術：利用影像生成模型的整合潛在特徵（超特徵）來偵測結構影像中的幾何對應（例如車輪中心的位子），以及為結構影像產生多樣化的文字描述。GPT-4o 是一個視覺語言模型 (VLM)，指示要分析影像並產生與系統提示一致的多樣化描述。透過將技術影像表示為擴散超特徵，就可以繪製它們之間的幾何對應。透過呈現多個帶註解的來源影像，可以改善在未見樣本中幾何點的偵測準確度。GPT-4o 具有足夠的能力來產生技術影像的準確描述。僅根據影像進行基礎會產生多樣化的描述，但會產生幻覺，而根據分類標籤進行基礎則會限制多樣性。將兩者都用作輸入，可以平衡創造力和準確性。成功地將超特徵用於幾何對應，表示這種方法可用於技術影像中的一般點偵測和註解任務。使用 VLM 標籤此類影像的文字描述是可行的，但取決於模型的偵測能力、仔細的提示工程和輸入資訊的選擇。在工程設計中應用基礎模型在很大程度上尚未探索。我們旨在透過一個資料集來填補這個空白，以探索在這個領域訓練、微調和調整 DGM，並建議引導基礎模型處理技術影像的方法。</paragraph>

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v1 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

摘要：心內超音波檢查 (ICE) 是一種關鍵的影像模式，用於電生理學 (EP) 和結構性心臟疾病 (SHD) 的介入治療，可從心臟內部提供即時、高解析度的影像。儘管有這些優點，但有效操作 ICE 導管需要相當的專業知識，這可能會導致不一致的結果，尤其是在經驗較少的操作員中。為了應對這個挑戰，我們提出一個以 AI 為驅動的閉環視圖引導系統，並結合人機環回饋，旨在協助使用者在不需要專業知識的情況下導航 ICE 影像。我們的模型模擬了任意視圖和臨床定義的 ICE 視圖之間的相對位置和方向向量，在一個空間座標系統中引導使用者如何操作 ICE 導管，以隨著時間從目前的視圖過渡到期望的視圖。在閉環配置中操作時，系統會持續預測和更新必要的導管操作，確保無縫整合到現有的臨床工作流程中。所提出的系統的有效性透過基於模擬的評估得到證明，在 6532 個測試資料集中達到 89% 的成功率，突顯其改善 ICE 影像程序的準確性和效率的潛力。

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

摘要：大型語言模型 (LLM) 在醫療保健中的應用已獲得顯著關注，因為它們能夠處理複雜的醫療數據並提供臨床決策的見解。這些模型已展示出在理解和產生自然語言方面的實質能力，這對於醫療文件、診斷和患者互動至關重要。本篇評論探討了語言模型從早期階段到當前最先進的 LLM 的軌跡，重點介紹了它們在醫療保健應用中的優勢，並討論了數據隱私、偏見和道德考量等挑戰。探討了 LLM 提升醫療保健服務的潛力，以及確保它們道德且有效整合到醫療實務中的必要步驟。

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

摘要：<paragraph>在當代醫療保健中，為了保護患者數據，電子健康記錄已成為無價的儲存庫，創造了利用深度學習技術進行預測分析的廣闊機會。視網膜眼底圖像、肝硬化分期和心臟病診斷預測已透過整合深度學習技術來分類不同的數據集，顯示出有希望的結果。本研究提出一個新的深度學習預測分析架構，透過預處理來自三個不同來源的數據來分類多個數據集。提出了一個結合殘差網路和人工神經網路的混合深度學習模型，用於檢測急性病和慢性病，例如心臟病、肝硬化和視網膜疾病，其效能優於現有的模型。數據集準備涉及範疇資料轉換、降維和遺失資料合成等方面。特徵萃取使用範疇資料集的縮放器轉換和影像資料集的 ResNet 架構來有效執行。產生的特徵被整合到一個統一的分類模型中。嚴謹的實驗和評估導致視網膜眼底圖像、肝硬化分期和心臟病診斷預測的準確度分別高達 93%、99% 和 95%。所提出方法的有效性透過對 F1 分數、精確度和召回率指標的詳細分析來證明。本研究提供了方法論和實驗的全面探討，深入了解電子健康記錄中的深度學習預測分析。</paragraph>

##### **Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**
2409.16563v1 by Yishu Wei, Xindi Wang, Hanley Ong, Yiliang Zhou, Adam Flanders, George Shih, Yifan Peng

Despite significant progress in applying large language models (LLMs) to the
medical domain, several limitations still prevent them from practical
applications. Among these are the constraints on model size and the lack of
cohort-specific labeled datasets. In this work, we investigated the potential
of improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with
datasets using synthetic labels. Two tasks are jointly trained by combining
their respective instruction datasets. When the quality of the task-specific
synthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B
achieves satisfactory performance on the open-ended disease detection task,
with a micro F1 score of 0.91. Conversely, when the quality of the
task-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR
dataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels
(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,
indicating the strong inherent underlying capability of the model. These
findings demonstrate the potential of fine-tuning LLMs with synthetic labels,
offering a promising direction for future research on LLM specialization in the
medical domain.

摘要：儘管將大型語言模型 (LLM) 應用於醫療領域已取得顯著進展，但仍有若干限制阻礙它們實際應用。其中包括模型大小的限制和缺乏特定於群體的標籤資料集。在這項工作中，我們探討了透過使用合成標籤微調資料集來改善輕量級 LLM（例如 Llama 3.1-8B）的潛力。透過結合各自的指令資料集，共同訓練兩個任務。當特定於任務的合成標籤品質相對較高時（例如，由 GPT4-o 產生），Llama 3.1-8B 在開放式疾病偵測任務中取得令人滿意的表現，微觀 F1 分數為 0.91。相反地，當與任務相關的合成標籤品質相對較低時（例如，來自 MIMIC-CXR 資料集），微調後的 Llama 3.1-8B 能夠超越其有雜訊的教師標籤（微觀 F1 分數為 0.67，相較於 0.63），並根據經過整理的標籤進行校準，這表示該模型具有強大的內在潛在能力。這些發現證明了使用合成標籤微調 LLM 的潛力，為未來針對 LLM 在醫療領域的專門化研究提供了有前景的方向。

##### **To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**
2409.16486v1 by Imra Aqeel

The global pandemic due to emergence of COVID 19 has created the unrivaled
public health crisis. It has huge morbidity rate never comprehended in the
recent decades. Researchers have made many efforts to find the optimal solution
of this pandemic. Progressively, drug repurposing is an emergent and powerful
strategy with saving cost, time, and labor. Lacking of identified repurposed
drug candidates against COVID 19 demands more efforts to explore the potential
inhibitors for effective cure. In this study, we used the combination of
molecular docking and machine learning regression approaches to explore the
potential inhibitors for the treatment of COVID 19. We calculated the binding
affinities of these drugs to multitarget proteins using molecular docking
process. We perform the QSAR modeling by employing various machine learning
regression approaches to identify the potential inhibitors against COVID 19.
Our findings with best scores of R2 and RMSE demonstrated that our proposed
Decision Tree Regression (DTR) model is the most appropriate model to explore
the potential inhibitors. We proposed five novel promising inhibitors with
their respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and
261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further
analyzed the physiochemical and pharmacokinetic properties of these most potent
inhibitors to examine their behavior. The analysis of these properties is the
key factor to promote an effective cure for public health. Our work constructs
an efficient structure with which to probe the potential inhibitors against
COVID-19, creating the combination of molecular docking with machine learning
regression approaches.

摘要：由於 COVID-19 的出現，全球大流行造成了無與倫比的公共衛生危機。它在最近幾十年來從未見過如此高的發病率。研究人員已做出許多努力來尋找此一流行病的最佳解決方案。漸進式藥物再利用是一種新興且強大的策略，可節省成本、時間和勞力。缺乏針對 COVID-19 的已識別再利用藥物候選藥物，需要更多努力來探索潛在的抑制劑以進行有效治療。在本研究中，我們結合了分子對接和機器學習回歸方法來探索治療 COVID-19 的潛在抑制劑。我們使用分子對接程序計算這些藥物與多目標蛋白的結合親和力。我們透過採用各種機器學習回歸方法來執行 QSAR 建模，以識別針對 COVID-19 的潛在抑制劑。我們在 R2 和 RMSE 中獲得的最佳分數發現，我們提出的決策樹回歸 (DTR) 模型是最合適的模型，可探索潛在的抑制劑。我們提出了五種新穎且有希望的抑制劑，它們各自的 Zinc ID 為 ZINC (3873365、85432544、8214470、85536956 和 261494640)，範圍在 -19.7 kcal/mol 至 -12.6 kcal/mol 之間。我們進一步分析了這些最強效抑制劑的理化和藥代動力學特性，以檢驗它們的行為。這些特性的分析是促進公共衛生有效治療的關鍵因素。我們的研究建立了一個有效的結構，可用於探測針對 COVID-19 的潛在抑制劑，結合分子對接與機器學習回歸方法。

##### **Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**
2409.16395v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

Medication errors significantly threaten patient safety, leading to adverse
drug events and substantial economic burdens on healthcare systems. Clinical
Decision Support Systems (CDSSs) aimed at mitigating these errors often face
limitations, including reliance on static databases and rule-based algorithms,
which can result in high false alert rates and alert fatigue among clinicians.
This paper introduces HELIOT, an innovative CDSS for drug allergy management,
integrating Large Language Models (LLMs) with a comprehensive pharmaceutical
data repository. HELIOT leverages advanced natural language processing
capabilities to interpret complex medical texts and synthesize unstructured
data, overcoming the limitations of traditional CDSSs. An empirical evaluation
using a synthetic patient dataset and expert-verified ground truth demonstrates
HELIOT's high accuracy, precision, recall, and F1 score, uniformly reaching
100\% across multiple experimental runs. The results underscore HELIOT's
potential to enhance decision support in clinical settings, offering a
scalable, efficient, and reliable solution for managing drug allergies.

摘要：藥物錯誤嚴重威脅患者安全，導致不良藥物事件和醫療系統的重大經濟負擔。旨在減輕這些錯誤的臨床決策支援系統 (CDSS) 經常面臨限制，包括依賴靜態資料庫和基於規則的演算法，這可能會導致臨床醫生之間的高誤報率和警報疲勞。本文介紹 HELIOT，一種創新的藥物過敏管理 CDSS，將大型語言模型 (LLM) 與全面的藥物資料庫整合在一起。HELIOT 利用先進的自然語言處理能力來解釋複雜的醫學文本並綜合非結構化資料，克服傳統 CDSS 的限制。使用合成患者資料集和專家驗證的地面實況進行的經驗評估證明了 HELIOT 的高準確度、精確度、召回率和 F1 分數，在多次實驗運行中均達到 100%。結果強調了 HELIOT 在臨床環境中增強決策支援的潛力，為管理藥物過敏提供可擴充、高效且可靠的解決方案。

##### **Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**
2409.16340v1 by Nikolas Koutsoubis, Asim Waqas, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.

摘要：人工智慧 (AI) 已在自動化各種醫學影像任務中展現出顯著的潛力，這可能很快就會在疾病診斷、預後、治療規劃和治療後監測的臨床實務中成為例行公事。然而，圍繞著病患資料的隱私疑慮對 AI 在醫學影像中的廣泛採用構成了一項重大的障礙，因為龐大且多樣化的訓練資料集對於開發準確、可概括且強健的人工智慧模型至關重要。聯合學習 (FL) 提供了一項解決方案，讓組織能夠在不共享敏感資料的情況下協同訓練 AI 模型。聯合學習會在參與的各個站點之間交換模型訓練資訊，例如梯度。儘管聯合學習前景看好，但它仍處於開發階段，並面臨著若干挑戰。值得注意的是，即使在模型訓練期間共享，敏感資訊仍可能被推斷出來。由於模型部署後潛在的資料分佈轉移可能會影響模型效能，因此量化 AI 模型的不確定性至關重要。由於參與站點之間資料的異質性，聯合學習中的不確定性量化 (UQ) 特別具有挑戰性。此篇評論對聯合學習、隱私保護聯合學習 (PPFL) 和聯合學習中的不確定性量化進行了全面的探討。我們找出目前聯合學習方法中的關鍵差距，並提出未來的研究方向，以增強醫學影像應用中的資料隱私和可信度。

##### **Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling**
2409.16231v1 by Henry Musto, Daniel Stamate, Doina Logofatu, Daniel Stahl

The paper proposes a novel approach of survival transformers and extreme
gradient boosting models in predicting cognitive deterioration in individuals
with mild cognitive impairment (MCI) using metabolomics data in the ADNI
cohort. By leveraging advanced machine learning and transformer-based
techniques applied in survival analysis, the proposed approach highlights the
potential of these techniques for more accurate early detection and
intervention in Alzheimer's dementia disease. This research also underscores
the importance of non-invasive biomarkers and innovative modelling tools in
enhancing the accuracy of dementia risk assessments, offering new avenues for
clinical practice and patient care. A comprehensive Monte Carlo simulation
procedure consisting of 100 repetitions of a nested cross-validation in which
models were trained and evaluated, indicates that the survival machine learning
models based on Transformer and XGBoost achieved the highest mean C-index
performances, namely 0.85 and 0.8, respectively, and that they are superior to
the conventional survival analysis Cox Proportional Hazards model which
achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of
the C-Index performances obtained in the Monte Carlo simulation, we established
that both survival machine learning models above are more stable than the
conventional statistical model.

摘要：這篇論文提出了一種新的方法，使用 ADNI 隊伍中的代謝組學資料，在認知功能輕微受損 (MCI) 的個體中預測認知惡化，這種方法結合了生存轉換器和極端梯度提升模型。透過利用進階機器學習和基於轉換器的技術，應用於存活分析，提出的方法突顯了這些技術在阿茲海默症失智症中更準確的早期檢測和干預的潛力。這項研究也強調了非侵入性生物標記和創新建模工具在提升失智症風險評估準確度中的重要性，為臨床實務和病人照護提供了新途徑。一個包含 100 次巢狀交叉驗證重複的綜合蒙地卡羅模擬程序，其中模型經過訓練和評估，顯示基於轉換器和 XGBoost 的生存機器學習模型達到了最高的平均 C 指數表現，分別為 0.85 和 0.8，而且它們優於傳統的生存分析 Cox 比例風險模型，後者的平均 C 指數為 0.77。此外，根據蒙地卡羅模擬中獲得的 C 指數表現的標準差，我們確立了上述兩種生存機器學習模型都比傳統的統計模型更穩定。

##### **Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain**
2409.16106v2 by Mehtab Ur Rahman, Martha Larson, Louis ten Bosch, Cristian Tejedor-García

Speech recordings are being more frequently used to detect and monitor
disease, leading to privacy concerns. Beyond cryptography, protection of speech
can be addressed by approaches, such as perturbation, disentanglement, and
re-synthesis, that eliminate sensitive information of the speaker, leaving the
information necessary for medical analysis purposes. In order for such privacy
protective approaches to be developed, clear and systematic specifications of
assumptions concerning medical settings and the needs of medical professionals
are necessary. In this paper, we propose a Scenario of Use Scheme that
incorporates an Attacker Model, which characterizes the adversary against whom
the speaker's privacy must be defended, and a Protector Model, which specifies
the defense. We discuss the connection of the scheme with previous work on
speech privacy. Finally, we present a concrete example of a specified Scenario
of Use and a set of experiments about protecting speaker data against gender
inference attacks while maintaining utility for Parkinson's detection.

摘要：語音錄音正越來越常被用於偵測和監測疾病，進而引發隱私疑慮。除了密碼學之外，語音保護還能透過擾動、解糾纏和重新合成等方法來達成，這些方法消除了說話者的敏感資訊，保留了醫療分析目的所需資訊。為了發展出此類保護隱私的方法，必須清楚且系統性地說明有關醫療環境的假設和醫療專業人員的需求。在本文中，我們提出了一個使用情境方案，其中包含攻擊者模型（用於描述必須保護說話者隱私的對手）和保護者模型（用於說明防禦措施）。我們探討了該方案與先前語音隱私研究的關聯。最後，我們提出了一個具體的使用情境範例，以及一組關於在維持帕金森氏症偵測效用的同時保護說話者資料免於性別推論攻擊的實驗。

##### **The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems**
2409.16098v1 by África Periáñez, Ana Fernández del Río, Ivan Nazarov, Enric Jané, Moiz Hassan, Aditya Rastogi, Dexian Tang

Mobile health has the potential to revolutionize health care delivery and
patient engagement. In this work, we discuss how integrating Artificial
Intelligence into digital health applications-focused on supply chain, patient
management, and capacity building, among other use cases-can improve the health
system and public health performance. We present an Artificial Intelligence and
Reinforcement Learning platform that allows the delivery of adaptive
interventions whose impact can be optimized through experimentation and
real-time monitoring. The system can integrate multiple data sources and
digital health applications. The flexibility of this platform to connect to
various mobile health applications and digital devices and send personalized
recommendations based on past data and predictions can significantly improve
the impact of digital tools on health system outcomes. The potential for
resource-poor settings, where the impact of this approach on health outcomes
could be more decisive, is discussed specifically. This framework is, however,
similarly applicable to improving efficiency in health systems where scarcity
is not an issue.

摘要：行動醫療具有革新醫療保健服務和患者參與的潛力。在這項工作中，我們討論如何將人工智慧整合到數位健康應用程式中，專注於供應鏈、患者管理和能力建構，以及其他使用案例，可以改善健康系統和公共衛生績效。我們提出一個人工智慧和強化學習平台，允許提供適應性介入措施，其影響可以透過實驗和即時監控進行最佳化。該系統可以整合多個資料來源和數位健康應用程式。此平台連接到各種行動醫療應用程式和數位裝置的靈活性，並根據過去的資料和預測發送個人化建議，可以顯著改善數位工具對健康系統成果的影響。特別討論了資源匱乏環境的潛力，在該環境中，這種方法對健康成果的影響可能更具決定性。然而，此架構同樣適用於改善健康系統的效率，其中稀缺性並非問題。

##### **Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications**
2409.15910v1 by Kriti Agarwal, Samhruth Ananthanarayanan, Srinitish Srinivasan, Abirami S

This paper presents the development of a novel plant communication
application that allows plants to "talk" to humans using real-time sensor data
and AI-powered language models. Utilizing soil sensors that track moisture,
temperature, and nutrient levels, the system feeds this data into the Gemini
API, where it is processed and transformed into natural language insights about
the plant's health and "mood." Developed using Flutter, Firebase, and
ThingSpeak, the app offers a seamless user experience with real-time
interaction capabilities. By fostering human-plant connectivity, this system
enhances plant care practices, promotes sustainability, and introduces
innovative applications for AI and IoT technologies in both personal and
agricultural contexts. The paper explores the technical architecture, system
integration, and broader implications of AI-driven plant communication.

摘要：本文介紹了一款新穎的植物溝通應用程式的開發，它允許植物利用即時感測器資料和 AI 語言模型與人類「對話」。系統利用追蹤水分、溫度和養分含量的土壤感測器，將這些資料輸入 Gemini API，並在其中進行處理，轉換成關於植物健康和「情緒」的自然語言見解。此應用程式使用 Flutter、Firebase 和 ThingSpeak 開發，提供與即時互動功能無縫接軌的使用者體驗。透過促進人與植物的連結，此系統提升了植物照護方式，促進永續性，並在個人和農業情境中引進了 AI 和 IoT 技術的創新應用。本文探討了 AI 驅動的植物溝通技術架構、系統整合和更廣泛的意涵。

##### **AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support**
2409.15815v1 by Adil Bahaj, Mounir Ghogho

Asthma rates have risen globally, driven by environmental and lifestyle
factors. Access to immediate medical care is limited, particularly in
developing countries, necessitating automated support systems. Large Language
Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have
advanced natural language processing in general and question answering in
particular, however, they are prone to producing factually incorrect responses
(i.e. hallucinations). Retrieval-augmented generation systems, integrating
curated documents, can improve large language models' performance and reduce
the incidence of hallucination. We introduce AsthmaBot, a multi-lingual,
multi-modal retrieval-augmented generation system for asthma support.
Evaluation of an asthma-related frequently asked questions dataset shows
AsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive
interface that integrates different data modalities (text, images, videos) to
make it accessible to the larger public. AsthmaBot is available online via
\url{asthmabot.datanets.org}.

摘要：氣喘發生率在全球上升，原因在於環境和生活方式的因素。立即獲得醫療照護的管道有限，特別是在開發中國家，這使得自動化支援系統變得必要。大型語言模型，例如 ChatGPT（Chat Generative Pre-trained Transformer）和 Gemini，已提升一般自然語言處理和特別是問答的進展，然而，它們容易產生事實上不正確的回應（即幻覺）。擷取增強生成系統，整合策展文件，可以提升大型語言模型的效能並減少幻覺發生的機率。我們介紹 AsthmaBot，一個多語言、多模態擷取增強生成系統，用於氣喘支援。評估與氣喘相關的常見問題資料集顯示 AsthmaBot 的效能。AsthmaBot 有一個額外的互動且直覺的介面，它整合不同的資料模式（文字、圖片、影片），使其能讓更多大眾使用。AsthmaBot 可透過 \url{asthmabot.datanets.org} 線上取得。

##### **Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making**
2409.15814v1 by Min Hun Lee, Renee Bao Xuan Ng, Silvana Xinyi Choo, Shamala Thilarajah

A growing research explores the usage of AI explanations on user's decision
phases for human-AI collaborative decision-making. However, previous studies
found the issues of overreliance on `wrong' AI outputs. In this paper, we
propose interactive example-based explanations to improve health professionals'
onboarding with AI for their better reliance on AI during AI-assisted
decision-making. We implemented an AI-based decision support system that
utilizes a neural network to assess the quality of post-stroke survivors'
exercises and interactive example-based explanations that systematically
surface the nearest neighborhoods of a test/task sample from the training set
of the AI model to assist users' onboarding with the AI model. To investigate
the effect of interactive example-based explanations, we conducted a study with
domain experts, health professionals to evaluate their performance and reliance
on AI. Our interactive example-based explanations during onboarding assisted
health professionals in having a better reliance on AI and making a higher
ratio of making `right' decisions and a lower ratio of `wrong' decisions than
providing only feature-based explanations during the decision-support phase.
Our study discusses new challenges of assisting user's onboarding with AI for
human-AI collaborative decision-making.

摘要：越來越多研究探討在人類與 AI 協作決策時，使用 AI 解釋對使用者決策階段的影響。然而，先前的研究發現過度依賴「錯誤」的 AI 輸出的問題。在本文中，我們提出互動式範例為基礎的解釋，以改善醫療專業人員與 AI 的整合，讓他們在 AI 輔助決策時能更依賴 AI。我們實作了一個基於 AI 的決策支援系統，它利用神經網路評估中風後倖存者運動的品質，並利用互動式範例為基礎的解釋，系統性地從 AI 模型的訓練集中找出測試/任務範例最近的鄰域，以協助使用者與 AI 模型整合。為了探討互動式範例為基礎的解釋的效果，我們進行了一項研究，找來領域專家和醫療專業人員評估他們的表現與對 AI 的依賴。我們在整合期間提供的互動式範例為基礎的解釋，協助醫療專業人員更依賴 AI，並且在決策支援階段中做出「正確」決策的比率較高，而做出「錯誤」決策的比率較低，優於只提供基於特徵的解釋。我們的研究探討了在人類與 AI 協作決策時，協助使用者與 AI 整合的新挑戰。

##### **Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm**
2409.15753v1 by Yooseok Lim, Inbeom Park, Sujee Lee

Appropriate medication dosages in the intensive care unit (ICU) are critical
for patient survival. Heparin, used to treat thrombosis and inhibit blood
clotting in the ICU, requires careful administration due to its complexity and
sensitivity to various factors, including patient clinical characteristics,
underlying medical conditions, and potential drug interactions. Incorrect
dosing can lead to severe complications such as strokes or excessive bleeding.
To address these challenges, this study proposes a reinforcement learning
(RL)-based personalized optimal heparin dosing policy that guides dosing
decisions reliably within the therapeutic range based on individual patient
conditions. A batch-constrained policy was implemented to minimize
out-of-distribution errors in an offline RL environment and effectively
integrate RL with existing clinician policies. The policy's effectiveness was
evaluated using weighted importance sampling, an off-policy evaluation method,
and the relationship between state representations and Q-values was explored
using t-SNE. Both quantitative and qualitative analyses were conducted using
the Medical Information Mart for Intensive Care III (MIMIC-III) database,
demonstrating the efficacy of the proposed RL-based medication policy.
Leveraging advanced machine learning techniques and extensive clinical data,
this research enhances heparin administration practices and establishes a
precedent for the development of sophisticated decision-support tools in
medicine.

摘要：在重症监护病房 (ICU) 中，适当的药物剂量对于患者的存活至关重要。肝素用于治疗血栓形成并抑制 ICU 中的血液凝结，由于其复杂性和对各种因素的敏感性，包括患者的临床特征、潜在的药物相互作用和基础疾病，因此需要谨慎给药。剂量不当会导致严重并发症，例如中风或过度出血。为了应对这些挑战，本研究提出了一种基于强化学习 (RL) 的个性化最佳肝素给药策略，该策略可以根据患者的个体情况在治疗范围内可靠地指导给药决策。实施了批约束策略以最大程度地减少离线 RL 环境中的分布外误差，并有效地将 RL 与现有的临床医生策略相结合。该策略的有效性使用加权重要性抽样（一种非策略评估方法）进行了评估，并使用 t-SNE 探索了状态表示和 Q 值之间的关系。使用重症监护 III（MIMIC-III）数据库进行了定量和定性分析，证明了所提出的基于 RL 的药物策略的有效性。利用先进的机器学习技术和广泛的临床数据，本研究增强了肝素给药实践，并为医学中复杂决策支持工具的开发树立了先例。

##### **dnaGrinder: a lightweight and high-capacity genomic foundation model**
2409.15697v1 by Qihang Zhao, Chi Zhang, Weixiong Zhang

The task of understanding and interpreting the complex information encoded
within genomic sequences remains a grand challenge in biological research and
clinical applications. In this context, recent advancements in large language
model research have led to the development of both encoder-only and
decoder-only foundation models designed to decode intricate information in DNA
sequences. However, several issues persist, particularly regarding the
efficient management of long-range dependencies inherent in genomic sequences,
the effective representation of nucleotide variations, and the considerable
computational costs associated with large model architectures and extensive
pretraining datasets. Current genomic foundation models often face a critical
tradeoff: smaller models with mediocre performance versus large models with
improved performance. To address these challenges, we introduce dnaGrinder, a
unique and efficient genomic foundation model. dnaGrinder excels at managing
long-range dependencies within genomic sequences while minimizing computational
costs without compromising performance. It achieves results that are not just
comparable but often superior to leading DNA models such as Nucleotide
Transformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy
fine-tuning on workstation-grade GPUs, accommodating input lengths exceeding
17,000 tokens. On a single high-performance GPU, it supports sequences longer
than 140,000 tokens, making it a highly efficient and accessible tool for both
basic biological research and clinical applications.

摘要：理解和詮釋編碼在基因組序列中的複雜資訊，在生物研究和臨床應用中仍是一項重大挑戰。在此背景下，大型語言模型研究的最新進展已導致編碼器專用和解碼器專用基礎模型的開發，旨在解碼 DNA 序列中的複雜資訊。然而，仍存在一些問題，特別是在基因組序列中固有的長距離依賴性的有效管理、核苷酸變異的有效表示，以及與大型模型架構和廣泛預訓練資料集相關的龐大計算成本。目前的基因組基礎模型通常面臨一個關鍵的權衡：效能平庸的小型模型與效能提升的大型模型。為了解決這些挑戰，我們引入了 dnaGrinder，一個獨特且高效的基因組基礎模型。dnaGrinder 擅長管理基因組序列中的長距離依賴性，同時最小化計算成本，而不會損害效能。它所取得的成果不僅與領先的 DNA 模型（例如 Nucleotide Transformer 和 DNABERT-2）相當，而且往往更勝一籌。此外，dnaGrinder 設計為可輕鬆在工作站級 GPU 上進行微調，可容納長度超過 17,000 個符號的輸入。在單一高效能 GPU 上，它支援長度超過 140,000 個符號的序列，使其成為基礎生物研究和臨床應用中高效且易於存取的工具。

##### **Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning**
2409.15688v1 by Min Tan, Yushun Tao, Boyun Zheng, GaoSheng Xie, Lijuan Feng, Zeyang Xia, Jing Xiong

With the increasing application of automated robotic digestive endoscopy
(RDE), ensuring safe and efficient navigation in the unstructured and narrow
digestive tract has become a critical challenge. Existing automated
reinforcement learning navigation algorithms, often result in potentially risky
collisions due to the absence of essential human intervention, which
significantly limits the safety and effectiveness of RDE in actual clinical
practice. To address this limitation, we proposed a Human Intervention
(HI)-based Proximal Policy Optimization (PPO) framework, dubbed HI-PPO, which
incorporates expert knowledge to enhance RDE's safety. Specifically, we
introduce an Enhanced Exploration Mechanism (EEM) to address the low
exploration efficiency of the standard PPO. Additionally, a reward-penalty
adjustment (RPA) is implemented to penalize unsafe actions during initial
interventions. Furthermore, Behavior Cloning Similarity (BCS) is included as an
auxiliary objective to ensure the agent emulates expert actions. Comparative
experiments conducted in a simulated platform across various anatomical colon
segments demonstrate that our model effectively and safely guides RDE.

摘要：隨著自動化機器人消化道內視鏡檢查 (RDE) 的應用日益廣泛，在結構化且狹窄的消化道中確保安全且有效率的導航已成為一項重大的挑戰。現有的自動化強化學習導航演算法，由於缺乏必要的介入，經常導致潛在的風險碰撞，這顯著限制了 RDE 在實際臨床實務中的安全性和有效性。為了解決此限制，我們提出了一個基於人類介入 (HI) 的近端策略最佳化 (PPO) 架構，稱為 HI-PPO，它結合了專家知識來增強 RDE 的安全性。具體來說，我們引入了一個增強探索機制 (EEM) 來解決標準 PPO 的低探索效率。此外，實施了獎勵懲罰調整 (RPA) 來懲罰在最初介入期間的不安全行為。此外，行為複製相似性 (BCS) 被納入作為輔助目標，以確保代理模擬專家行為。在模擬平台中進行的比較實驗，橫跨各種解剖結腸片段，證明我們的模型有效且安全地引導 RDE。

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses**
2409.15687v1 by Abdelrahman Hanafi, Mohammed Saad, Noureldin Zahran, Radwa J. Hanafy, Mohammed E. Fouda

Large language models have shown promise in various domains, including
healthcare. In this study, we conduct a comprehensive evaluation of LLMs in the
context of mental health tasks using social media data. We explore the
zero-shot (ZS) and few-shot (FS) capabilities of various LLMs, including GPT-4,
Llama 3, Gemini, and others, on tasks such as binary disorder detection,
disorder severity evaluation, and psychiatric knowledge assessment. Our
evaluation involved 33 models testing 9 main prompt templates across the tasks.
Key findings revealed that models like GPT-4 and Llama 3 exhibited superior
performance in binary disorder detection, with accuracies reaching up to 85% on
certain datasets. Moreover, prompt engineering played a crucial role in
enhancing model performance. Notably, the Mixtral 8x22b model showed an
improvement of over 20%, while Gemma 7b experienced a similar boost in
performance. In the task of disorder severity evaluation, we observed that FS
learning significantly improved the model's accuracy, highlighting the
importance of contextual examples in complex assessments. Notably, the
Phi-3-mini model exhibited a substantial increase in performance, with balanced
accuracy improving by over 6.80% and mean average error dropping by nearly 1.3
when moving from ZS to FS learning. In the psychiatric knowledge task, recent
models generally outperformed older, larger counterparts, with the Llama 3.1
405b achieving an accuracy of 91.2%. Despite promising results, our analysis
identified several challenges, including variability in performance across
datasets and the need for careful prompt engineering. Furthermore, the ethical
guards imposed by many LLM providers hamper the ability to accurately evaluate
their performance, due to tendency to not respond to potentially sensitive
queries.

摘要：大型語言模型已在醫療保健等各個領域展現潛力。在本研究中，我們使用社群媒體資料對 LLM 在心理健康任務中的表現進行全面評估。我們探討各種 LLM，包括 GPT-4、Llama 3、Gemini 等，在二元障礙偵測、障礙嚴重性評估和精神疾病知識評估等任務上的零次學習 (ZS) 和少次學習 (FS) 能力。我們的評估涉及 33 個模型，在各項任務中測試 9 個主要提示範本。主要發現顯示，GPT-4 和 Llama 3 等模型在二元障礙偵測中表現出優異的效能，在特定資料集上的準確率高達 85%。此外，提示工程在提升模型效能方面扮演至關重要的角色。值得注意的是，Mixtral 8x22b 模型的進步幅度超過 20%，而 Gemma 7b 的效能也獲得類似的提升。在障礙嚴重性評估任務中，我們觀察到 FS 學習顯著提升模型的準確度，突顯出背景範例在複雜評估中的重要性。值得注意的是，Phi-3-mini 模型的效能大幅提升，從 ZS 學習轉換到 FS 學習後，平衡準確度提升超過 6.80%，平均平均誤差降低近 1.3。在精神疾病知識任務中，較新的模型通常優於較舊、較大的模型，其中 Llama 3.1 405b 達到 91.2% 的準確度。儘管有令人振奮的結果，我們的分析發現了幾個挑戰，包括跨資料集的效能變異性，以及仔細提示工程的需求。此外，許多 LLM 提供者施加的道德守則阻礙了準確評估其效能的能力，因為它們傾向於不回應潛在的敏感查詢。

##### **TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**
2409.15586v2 by Rosemary Y. He, Jeffrey N. Chiang

Trajectory forecasting in healthcare data has been an important area of
research in precision care and clinical integration for computational methods.
In recent years, generative AI models have demonstrated promising results in
capturing short and long range dependencies in time series data. While these
models have also been applied in healthcare, most of them only predict one
value at a time, which is unrealistic in a clinical setting where multiple
measures are taken at once. In this work, we extend the framework temporal
fusion transformer (TFT), a multi-horizon time series prediction tool, and
propose TFT-multi, an end-to-end framework that can predict multiple vital
trajectories simultaneously. We apply TFT-multi to forecast 5 vital signs
recorded in the intensive care unit: blood pressure, pulse, SpO2, temperature
and respiratory rate. We hypothesize that by jointly predicting these measures,
which are often correlated with one another, we can make more accurate
predictions, especially in variables with large missingness. We validate our
model on the public MIMIC dataset and an independent institutional dataset, and
demonstrate that this approach outperforms state-of-the-art univariate
prediction tools including the original TFT and Prophet, as well as vector
regression modeling for multivariate prediction. Furthermore, we perform a
study case analysis by applying our pipeline to forecast blood pressure changes
in response to actual and hypothetical pressor administration.

摘要：醫療數據中的軌跡預測一直是精準照護和臨床整合中計算方法的重要研究領域。近年來，生成式 AI 模型在捕捉時間序列資料中的短程和長程依賴關係方面已展現出令人滿意的成果。儘管這些模型也已應用於醫療保健，但其中大多數一次只預測一個值，這在一次採取多項測量的臨床環境中是不切實際的。在這項工作中，我們擴充了時序融合Transformer (TFT) 這個多地平線時間序列預測工具，並提出 TFT-multi，這是一個可以同時預測多個重要軌跡的端對端框架。我們將 TFT-multi 應用於預測在加護病房中記錄的 5 個生命徵象：血壓、脈搏、SpO2、體溫和呼吸速率。我們假設透過共同預測這些通常彼此相關的測量值，我們可以做出更準確的預測，特別是在缺失值較多的變數中。我們在公開的 MIMIC 資料集和一個獨立的機構資料集上驗證我們的模型，並證明這種方法優於最先進的單變量預測工具，包括原始的 TFT 和 Prophet，以及用於多變量預測的向量回歸建模。此外，我們透過將我們的管道應用於預測對實際和假設的升壓劑給藥的反應，來執行案例分析研究血壓變化。

##### **MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis**
2409.16329v1 by Stanislav Kozák

Radiomics is a relatively new field which utilises automatically identified
features from radiological scans. It has found a widespread application,
particularly in oncology because many of the important oncological biomarkers
are not visible to the naked eye. The recent advent of big data, including in
medical imaging, and the development of new ML techniques brought the
possibility of faster and more accurate oncological diagnosis. Furthermore,
standardised mathematical feature extraction based on radiomics helps to
eliminate possible radiologist bias. This paper reviews the recent development
in the oncological use of MRI radiomic features. It focuses on the
identification of the isocitrate dehydrogenase (IDH) mutation status, which is
an important biomarker for the diagnosis of glioblastoma and grade IV
astrocytoma.

摘要：放射組學是一個相對較新的領域，它利用放射掃描自動識別的特徵。它已廣泛應用，特別是在腫瘤學中，因為許多重要的腫瘤生物標誌物肉眼不可見。包括醫學影像在內的大數據最近的出現以及新機器學習技術的發展帶來了更快、更準確的腫瘤學診斷的可能性。此外，基於放射組學的標準化數學特徵提取有助於消除可能的放射科醫師偏見。本文回顧了放射組學特徵在腫瘤學應用中的最新發展。它側重於異檸檬酸脫氫酶 (IDH) 突變狀態的識別，這是診斷膠質母細胞瘤和 IV 級星形細胞瘤的重要生物標誌物。

##### **Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool**
2409.15491v1 by Ziyu Su, Yongxin Guo, Robert Wesolowski, Gary Tozbikian, Nathaniel S. O'Connell, M. Khalid Khan Niazi, Metin N. Gurcan

Accurate recurrence risk stratification is crucial for optimizing treatment
plans for breast cancer patients. Current prognostic tools like Oncotype DX
(ODX) offer valuable genomic insights for HR+/HER2- patients but are limited by
cost and accessibility, particularly in underserved populations. In this study,
we present Deep-BCR-Auto, a deep learning-based computational pathology
approach that predicts breast cancer recurrence risk from routine H&E-stained
whole slide images (WSIs). Our methodology was validated on two independent
cohorts: the TCGA-BRCA dataset and an in-house dataset from The Ohio State
University (OSU). Deep-BCR-Auto demonstrated robust performance in stratifying
patients into low- and high-recurrence risk categories. On the TCGA-BRCA
dataset, the model achieved an area under the receiver operating characteristic
curve (AUROC) of 0.827, significantly outperforming existing weakly supervised
models (p=0.041). In the independent OSU dataset, Deep-BCR-Auto maintained
strong generalizability, achieving an AUROC of 0.832, along with 82.0%
accuracy, 85.0% specificity, and 67.7% sensitivity. These findings highlight
the potential of computational pathology as a cost-effective alternative for
recurrence risk assessment, broadening access to personalized treatment
strategies. This study underscores the clinical utility of integrating deep
learning-based computational pathology into routine pathological assessment for
breast cancer prognosis across diverse clinical settings.

摘要：精準的復發風險分層對於最佳化乳癌病患的治療計畫至關重要。目前的預後工具，例如 Oncotype DX (ODX)，為 HR+/HER2- 病患提供了有價值的基因體見解，但成本和可及性有限，特別是在服務不足的人群中。在本研究中，我們提出 Deep-BCR-Auto，一種基於深度學習的計算病理學方法，可從常規 H&E 染色的全玻片影像 (WSI) 預測乳癌復發風險。我們的技術在兩個獨立的群組中得到驗證：TCGA-BRCA 資料集和來自俄亥俄州立大學 (OSU) 的內部資料集。Deep-BCR-Auto 在將患者分層為低和高復發風險類別方面表現出強大的效能。在 TCGA-BRCA 資料集上，該模型在受試者作業特徵曲線 (AUROC) 下方達到了 0.827 的面積，顯著優於現有的弱監督模型 (p=0.041)。在獨立的 OSU 資料集中，Deep-BCR-Auto 保持了很強的泛化性，達到了 0.832 的 AUROC，以及 82.0% 的準確度、85.0% 的特異度和 67.7% 的敏感度。這些發現突顯了計算病理學作為復發風險評估的經濟有效替代方案的潛力，擴大了個人化治療策略的可及性。這項研究強調了將基於深度學習的計算病理學整合到乳癌預後的常規病理評估中，在不同的臨床環境中具有臨床效用。

##### **A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?**
2409.15277v1 by Yunfei Xie, Juncheng Wu, Haoqin Tu, Siwei Yang, Bingchen Zhao, Yongshuo Zong, Qiao Jin, Cihang Xie, Yuyin Zhou

Large language models (LLMs) have exhibited remarkable capabilities across
various domains and tasks, pushing the boundaries of our knowledge in learning
and cognition. The latest model, OpenAI's o1, stands out as the first LLM with
an internalized chain-of-thought technique using reinforcement learning
strategies. While it has demonstrated surprisingly strong capabilities on
various general language tasks, its performance in specialized fields such as
medicine remains unknown. To this end, this report provides a comprehensive
exploration of o1 on different medical scenarios, examining 3 key aspects:
understanding, reasoning, and multilinguality. Specifically, our evaluation
encompasses 6 tasks using data from 37 medical datasets, including two newly
constructed and more challenging question-answering (QA) tasks based on
professional medical quizzes from the New England Journal of Medicine (NEJM)
and The Lancet. These datasets offer greater clinical relevance compared to
standard medical QA benchmarks such as MedQA, translating more effectively into
real-world clinical utility. Our analysis of o1 suggests that the enhanced
reasoning ability of LLMs may (significantly) benefit their capability to
understand various medical instructions and reason through complex clinical
scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average
of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.
But meanwhile, we identify several weaknesses in both the model capability and
the existing evaluation protocols, including hallucination, inconsistent
multilingual ability, and discrepant metrics for evaluation. We release our raw
data and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future
research.

摘要：大型語言模型 (LLM) 在各種領域和任務中展現出非凡的能力，推動了我們在學習和認知方面的知識界限。最新的模型，OpenAI 的 o1，脫穎而出，成為第一個使用強化學習策略內化思想鏈技術的 LLM。雖然它在各種一般語言任務中展現出驚人強大的能力，但它在醫學等專業領域的表現仍然未知。為此，本報告全面探討了 o1 在不同醫療情境中的表現，檢視了 3 個關鍵面向：理解、推理和多語言能力。具體來說，我們的評估涵蓋了使用來自 37 個醫療資料集的資料的 6 項任務，包括兩個新建構且更具挑戰性的問答 (QA) 任務，這些任務是根據新英格蘭醫學期刊 (NEJM) 和刺胳針雜誌的專業醫療測驗而來。與 MedQA 等標準醫療 QA 基準相比，這些資料集提供了更高的臨床相關性，更有效地轉化為實際的臨床效用。我們對 o1 的分析表明，LLM 增強的推理能力可能（顯著地）提升它們理解各種醫療指示和推理複雜臨床情境的能力。值得注意的是，o1 在 19 個資料集和兩個新建立的複雜 QA 情境中的準確度平均比先前的 GPT-4 高出 6.2% 和 6.6%。但同時，我們發現模型能力和現有評估協定中存在若干弱點，包括幻覺、不一致的多語言能力和評估的差異化指標。我們在 https://ucsc-vlaa.github.io/o1_medicine/ 發布我們的原始資料和模型輸出，以供未來研究。

##### **Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation**
2409.15260v1 by Yi-Fei Zhao, Allyn Bove, David Thompson, James Hill, Yi Xu, Yufan Ren, Andrea Hassman, Leming Zhou, Yanshan Wang

Low back pain (LBP) is a leading cause of disability globally. Following the
onset of LBP and subsequent treatment, adequate patient education is crucial
for improving functionality and long-term outcomes. Despite advancements in
patient education strategies, significant gaps persist in delivering
personalized, evidence-based information to patients with LBP. Recent
advancements in large language models (LLMs) and generative artificial
intelligence (GenAI) have demonstrated the potential to enhance patient
education. However, their application and efficacy in delivering educational
content to patients with LBP remain underexplored and warrant further
investigation. In this study, we introduce a novel approach utilizing LLMs with
Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored
educational materials for patients with LBP. Physical therapists manually
evaluated our model responses for redundancy, accuracy, and completeness using
a Likert scale. In addition, the readability of the generated education
materials is assessed using the Flesch Reading Ease score. The findings
demonstrate that RAG-based LLMs outperform traditional LLMs, providing more
accurate, complete, and readable patient education materials with less
redundancy. Having said that, our analysis reveals that the generated materials
are not yet ready for use in clinical practice. This study underscores the
potential of AI-driven models utilizing RAG to improve patient education for
LBP; however, significant challenges remain in ensuring the clinical relevance
and granularity of content generated by these models.

摘要：下背痛 (LBP) 是全球導致殘疾的主要原因。在 LBP 發作和後續治療後，充分的患者教育對於改善功能和長期結果至關重要。儘管患者教育策略取得進展，但向 LBP 患者提供個性化、循證信息的過程中仍存在顯著差距。大型語言模型 (LLM) 和生成式人工智能 (GenAI) 的最新進展已證明有增強患者教育的潛力。然而，它們在向 LBP 患者傳遞教育內容方面的應用和功效仍未得到充分探索，有待進一步調查。在本研究中，我們引入一種新方法，利用具有檢索增強生成 (RAG) 和少次學習的 LLM，為 LBP 患者生成量身定制的教育材料。物理治療師使用李克特量表手動評估我們的模型反應的冗餘性、準確性和完整性。此外，使用弗萊施閱讀簡易度評分評估生成的教育材料的可讀性。研究結果表明，基於 RAG 的 LLM 優於傳統 LLM，提供更準確、完整且可讀的患者教育材料，且冗餘性更低。話雖如此，我們的分析表明，生成的材料還不適合在臨床實務中使用。本研究強調了利用 RAG 的 AI 驅動模型在改善 LBP 患者教育方面的潛力；然而，確保這些模型生成的內容的臨床相關性和精細度仍存在重大挑戰。

##### **Boosting Healthcare LLMs Through Retrieved Context**
2409.15127v1 by Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Dario Garcia-Gasulla

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language processing, and yet, their factual inaccuracies and
hallucinations limits their application, particularly in critical domains like
healthcare. Context retrieval methods, by introducing relevant information as
input, have emerged as a crucial approach for enhancing LLM factuality and
reliability. This study explores the boundaries of context retrieval methods
within the healthcare domain, optimizing their components and benchmarking
their performance against open and closed alternatives. Our findings reveal how
open LLMs, when augmented with an optimized retrieval system, can achieve
performance comparable to the biggest private solutions on established
healthcare benchmarks (multiple-choice question answering). Recognizing the
lack of realism of including the possible answers within the question (a setup
only found in medical exams), and after assessing a strong LLM performance
degradation in the absence of those options, we extend the context retrieval
system in that direction. In particular, we propose OpenMedPrompt a pipeline
that improves the generation of more reliable open-ended answers, moving this
technology closer to practical application.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現了卓越的能力，然而，它們的事實不準確和幻覺限制了它們的應用，特別是在醫療保健等關鍵領域。情境檢索方法透過引入相關資訊作為輸入，成為增強 LLM 事實性和可靠性的關鍵方法。本研究探討了情境檢索方法在醫療保健領域的界線，最佳化其元件，並根據開放和封閉的替代方案對其效能進行基準測試。我們的研究結果揭示了開放式 LLM 在結合最佳化檢索系統後，如何在既定的醫療保健基準（多選題答題）上達到與最大的私人解決方案相當的效能。認識到在問題中包含可能的答案（僅在醫學考試中發現的設定）缺乏現實性，並在評估在沒有這些選項的情況下 LLM 效能大幅下降後，我們將情境檢索系統擴展到該方向。特別是，我們提出 OpenMedPrompt，一個管道，用於改善更可靠的開放式答案的產生，讓這項技術更接近實際應用。

##### **Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network**
2409.15006v1 by Sijia Du, Chengfeng Zhou, Suncheng Xiang, Jianwei Xu, Dahong Qian

Objective: Depth estimation is crucial for endoscopic navigation and
manipulation, but obtaining ground-truth depth maps in real clinical scenarios,
such as the colon, is challenging. This study aims to develop a robust
framework that generalizes well to real colonoscopy images, overcoming
challenges like non-Lambertian surface reflection and diverse data
distributions. Methods: We propose a framework combining a convolutional neural
network (CNN) for capturing local features and a Transformer for capturing
global information. An uncertainty-based fusion block was designed to enhance
generalization by identifying complementary contributions from the CNN and
Transformer branches. The network can be trained with simulated datasets and
generalize directly to unseen clinical data without any fine-tuning. Results:
Our method is validated on multiple datasets and demonstrates an excellent
generalization ability across various datasets and anatomical structures.
Furthermore, qualitative analysis in real clinical scenarios confirmed the
robustness of the proposed method. Conclusion: The integration of local and
global features through the CNN-Transformer architecture, along with the
uncertainty-based fusion block, improves depth estimation performance and
generalization in both simulated and real-world endoscopic environments.
Significance: This study offers a novel approach to estimate depth maps for
endoscopy images despite the complex conditions in clinic, serving as a
foundation for endoscopic automatic navigation and other clinical tasks, such
as polyp detection and segmentation.

摘要：目標：深度估計對於內視鏡導航和操作至關重要，但在實際臨床場景中（例如結腸）取得真實深度圖非常具有挑戰性。本研究旨在開發一個強大的框架，可以很好地推廣到實際的結腸鏡檢查影像，克服非朗伯反射面和多樣化資料分佈等挑戰。方法：我們提出一個結合卷積神經網路（CNN）來擷取局部特徵和 Transformer 來擷取全局資訊的框架。設計了一個基於不確定性的融合區塊，透過識別 CNN 和 Transformer 分支的互補貢獻來增強泛化能力。網路可以用模擬資料集進行訓練，並直接推廣到未見過的臨床資料，而無需任何微調。結果：我們的模型在多個資料集上得到驗證，並展示出跨越各種資料集和解剖結構的出色泛化能力。此外，在實際臨床場景中的定性分析證實了所提出模型的穩健性。結論：透過 CNN-Transformer 架構整合局部和全局特徵，以及基於不確定性的融合區塊，改善了模擬和真實世界內視鏡環境中的深度估計效能和泛化能力。意義：本研究提供了一種新穎的方法來估計內視鏡影像的深度圖，儘管在臨床上有複雜的條件，但作為內視鏡自動導航和其他臨床任務（例如息肉檢測和分割）的基礎。

##### **DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models**
2409.14904v1 by Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim

The use of pre-trained language models fine-tuned to address specific
downstream tasks is a common approach in natural language processing (NLP).
However, acquiring domain-specific knowledge via fine-tuning is challenging.
Traditional methods involve pretraining language models using vast amounts of
domain-specific data before fine-tuning for particular tasks. This study
investigates emergency/non-emergency classification tasks based on electronic
medical record (EMR) data obtained from pediatric emergency departments (PEDs)
in Korea. Our findings reveal that existing domain-specific pre-trained
language models underperform compared to general language models in handling
N-lingual free-text data characteristics of non-English-speaking regions. To
address these limitations, we propose a domain knowledge transfer methodology
that leverages knowledge distillation to infuse general language models with
domain-specific knowledge via fine-tuning. This study demonstrates the
effective transfer of specialized knowledge between models by defining a
general language model as the student model and a domain-specific pre-trained
model as the teacher model. In particular, we address the complexities of EMR
data obtained from PEDs in non-English-speaking regions, such as Korea, and
demonstrate that the proposed method enhances classification performance in
such contexts. The proposed methodology not only outperforms baseline models on
Korean PED EMR data, but also promises broader applicability in various
professional and technical domains. In future works, we intend to extend this
methodology to include diverse non-English-speaking regions and address
additional downstream tasks, with the aim of developing advanced model
architectures using state-of-the-art KD techniques. The code is available in
https://github.com/JoSangYeon/DSG-KD.

摘要：<paragraph>使用針對特定下游任務進行微調的預先訓練語言模型是自然語言處理 (NLP) 中的常見方法。然而，透過微調來獲取特定領域的知識具有挑戰性。傳統方法涉及使用大量的特定領域資料來預訓練語言模型，然後針對特定任務進行微調。本研究調查了基於從韓國小兒急診科 (PED) 取得的電子醫療紀錄 (EMR) 資料的緊急/非緊急分類任務。我們的研究結果顯示，現有的特定領域預訓練語言模型在處理非英語系地區的 N 語言自由文字資料特性時，表現不如一般語言模型。為了解決這些限制，我們提出了一種領域知識轉移方法，該方法利用知識蒸餾，透過微調將一般語言模型注入特定領域的知識。本研究透過將一般語言模型定義為學生模型，將特定領域的預訓練模型定義為老師模型，展示了模型之間專業知識的有效轉移。特別是，我們解決了從非英語系地區（例如韓國）的 PED 取得的 EMR 資料的複雜性，並展示了所提出的方法增強了此類情境中的分類效能。所提出的方法不僅在韓文 PED EMR 資料上優於基準模型，還承諾在各種專業和技術領域中更廣泛的應用性。在未來的研究中，我們打算擴展此方法以納入不同的非英語系地區，並解決其他下游任務，目標是使用最先進的 KD 技術開發先進的模型架構。程式碼可在 https://github.com/JoSangYeon/DSG-KD 取得。</paragraph>

##### **Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography**
2409.14876v1 by Shilong Yang, Chulong Zhang, Qi Zang, Juan Yu, Liang Zeng, Xiao Luo, Yexuan Xing, Xin Pan, Qi Li, Xiaokun Liang, Yaoqin Xie

Breast cancer has long posed a significant threat to women's health, making
early screening crucial for mitigating its impact. However, mammography, the
preferred method for early screening, faces limitations such as the burden of
double reading by radiologists, challenges in widespread adoption in remote and
underdeveloped areas, and obstacles in intelligent early screening development
due to data constraints. To address these challenges, we propose a weakly
supervised multi-view mammography early screening model for breast cancer based
on context clustering. Context clustering, a feature extraction structure that
is neither CNN nor transformer, combined with multi-view learning for
information complementation, presents a promising approach. The weak
supervision design specifically addresses data limitations. Our model achieves
state-of-the-art performance with fewer parameters on two public datasets, with
an AUC of 0.828 on the Vindr-Mammo dataset and 0.805 on the CBIS-DDSM dataset.
Our model shows potential in reducing the burden on doctors and increasing the
feasibility of breast cancer screening for women in underdeveloped regions.

摘要：乳癌長期以來對女性健康構成重大威脅，及早篩檢對於減輕其影響至關重要。然而，乳房攝影術作為早期篩檢的首選方式，卻面臨放射科醫師雙重判讀的負擔、在偏遠和未開發地區廣泛採用所面臨的挑戰，以及由於資料限制而導致的智慧型早期篩檢開發障礙等限制。為了應對這些挑戰，我們提出一個基於脈絡聚類的乳癌弱監督多視角乳房攝影早期篩檢模型。脈絡聚類是一種既非 CNN 也非轉換器的特徵提取結構，結合多視角學習進行資訊互補，提供了一個有前景的方法。弱監督設計特別解決了資料限制的問題。我們的模型在兩個公開資料集上以較少的參數達到了最先進的效能，在 Vindr-Mammo 資料集上的 AUC 為 0.828，在 CBIS-DDSM 資料集上的 AUC 為 0.805。我們的模型顯示出減輕醫生負擔和增加未開發地區女性乳癌篩檢可行性的潛力。

##### **Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images**
2409.14874v2 by Ahjol Senbi, Tianyu Huang, Fei Lyu, Qing Li, Yuhui Tao, Wei Shao, Qiang Chen, Chengyan Wang, Shuo Wang, Tao Zhou, Yizhe Zhang

We explore the feasibility and potential of building a ground-truth-free
evaluation model to assess the quality of segmentations generated by the
Segment Anything Model (SAM) and its variants in medical imaging. This
evaluation model estimates segmentation quality scores by analyzing the
coherence and consistency between the input images and their corresponding
segmentation predictions. Based on prior research, we frame the task of
training this model as a regression problem within a supervised learning
framework, using Dice scores (and optionally other metrics) along with mean
squared error to compute the training loss. The model is trained utilizing a
large collection of public datasets of medical images with segmentation
predictions from SAM and its variants. We name this model EvanySeg (Evaluation
of Any Segmentation in Medical Images). Our exploration of convolution-based
models (e.g., ResNet) and transformer-based models (e.g., ViT) suggested that
ViT yields better performance for this task. EvanySeg can be employed for
various tasks, including: (1) identifying poorly segmented samples by detecting
low-percentile segmentation quality scores; (2) benchmarking segmentation
models without ground truth by averaging quality scores across test samples;
(3) alerting human experts to poor-quality segmentation predictions during
human-AI collaboration by applying a threshold within the score space; and (4)
selecting the best segmentation prediction for each test sample at test time
when multiple segmentation models are available, by choosing the prediction
with the highest quality score. Models and code will be made available at
https://github.com/ahjolsenbics/EvanySeg.

摘要：<paragraph>我們探討建立一個無地面實相的評估模型，以評估由 Segment Anything Model (SAM) 及其在醫學影像中的變體所產生的分割品質的可行性和潛力。此評估模型透過分析輸入影像與其對應分割預測之間的相干性和一致性來估計分割品質分數。根據先前的研究，我們將訓練此模型的任務設定為監督式學習架構中的回歸問題，使用 Dice 分數（以及其他指標，可選擇）與平均平方誤差一起計算訓練損失。此模型使用來自 SAM 及其變體的分割預測的大型公共醫學影像資料集進行訓練。我們將此模型命名為 EvanySeg（醫學影像中任何分割的評估）。我們對基於卷積的模型（例如 ResNet）和基於Transformer的模型（例如 ViT）的探討表明，ViT 在此任務中表現得更好。EvanySeg 可用於各種任務，包括：(1) 透過偵測低百分位數分割品質分數來識別分割不良的樣本；(2) 透過平均測試樣本的品質分數來對沒有地面實相的分割模型進行基準測試；(3) 在人機協作期間，透過在分數空間中應用閾值來提醒人類專家注意品質不佳的分割預測；(4) 在測試時間為每個測試樣本選擇最佳分割預測（當有多個分割模型可用時），透過選擇具有最高品質分數的預測。模型和程式碼將在 https://github.com/ahjolsenbics/EvanySeg 提供。</paragraph>

##### **A-VL: Adaptive Attention for Large Vision-Language Models**
2409.14846v1 by Junyang Zhang, Mu Yuan, Ruiguang Zhong, Puhan Luo, Huiyou Zhan, Ningkang Zhang, Chengchen Hu, Xiangyang Li

The Large Vision-Language Model (LVLM) integrates computer vision and natural
language processing techniques, offering substantial application potential.
However, these models demand extensive resources during inference. Adaptive
attention techniques can dynamically reduce computational redundancy and thus
improve efficiency. Although current adaptive attention methods significantly
reduce the memory requirements of Transformer-based language models, they are
not tailored for LVLMs. We observe that LVLMs generate responses from both
remote image tokens and local text tokens, and different modalities have
different attention patterns. This observation inspires us to manage the
attention for each modality separately. Specifically, for visual input, we
store the cache of potentially useful information but only compute the most
critical parts. For language input, we care more about local information. Based
on our observation and analysis of vision-language attention patterns, we
develop A-VL, a plug-and-play adaptive attention tailored for LVLM inference.
Extensive evaluations on three vision-language tasks and five datasets show the
effectiveness of our designs. Our approach A-VL outperforms existing adaptive
attention methods in reducing memory usage and computational load without
compromising performance.

摘要：大型视觉语言模型 (LVLM) 整合了计算机视觉和自然语言处理技术，提供了大量的应用潜力。然而，这些模型在推理过程中需要大量的资源。自适应注意力技术可以动态减少计算冗余，从而提高效率。虽然当前的自适应注意力方法显著减少了基于 Transformer 的语言模型的内存需求，但它们并不适合 LVLM。我们观察到，LVLM 从远程图像标记和局部文本标记生成响应，并且不同的模态具有不同的注意力模式。这一观察启发了我们分别管理每个模态的注意力。具体来说，对于视觉输入，我们存储潜在有用信息的缓存，但只计算最关键的部分。对于语言输入，我们更关心局部信息。基于我们对视觉语言注意力模式的观察和分析，我们开发了 A-VL，这是一种针对 LVLM 推理量身定制的即插即用自适应注意力。在三个视觉语言任务和五个数据集上的广泛评估表明了我们设计的有效性。我们的方法 A-VL 在减少内存使用和计算负载方面优于现有的自适应注意力方法，同时不影响性能。

##### **Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort**
2409.14478v1 by Yuxing Zhi, Yuan Guo, Kai Yuan, Hesong Wang, Heng Xu, Haina Yao, Albert C Yang, Guangrui Huang, Yuping Duan

Background: Large language models (LLMs) have seen extraordinary advances
with applications in clinical decision support. However, high-quality evidence
is urgently needed on the potential and limitation of LLMs in providing
accurate clinical decisions based on real-world medical data. Objective: To
evaluate quantitatively whether universal state-of-the-art LLMs (ChatGPT and
GPT-4) can predict the incidence risk of myocardial infarction (MI) with
logical inference, and to further make comparison between various models to
assess the performance of LLMs comprehensively. Methods: In this retrospective
cohort study, 482,310 participants recruited from 2006 to 2010 were initially
included in UK Biobank database and later on resampled into a final cohort of
690 participants. For each participant, tabular data of the risk factors of MI
were transformed into standardized textual descriptions for ChatGPT
recognition. Responses were generated by asking ChatGPT to select a score
ranging from 0 to 10 representing the risk. Chain of Thought (CoT) questioning
was used to evaluate whether LLMs make prediction logically. The predictive
performance of ChatGPT was compared with published medical indices, traditional
machine learning models and other large language models. Conclusions: Current
LLMs are not ready to be applied in clinical medicine fields. Future medical
LLMs are suggested to be expert in medical domain knowledge to understand both
natural languages and quantified medical data, and further make logical
inferences.

摘要：<paragraph>背景：大型語言模型 (LLM) 已在臨床決策支持應用中取得非凡進展。然而，迫切需要高品質的證據來證明 LLM 在根據現實世界醫療數據提供準確臨床決策方面的潛力和限制。目標：定量評估通用最先進的 LLM（ChatGPT 和 GPT-4）是否能通過邏輯推理預測心肌梗塞 (MI) 的發生風險，並進一步在各種模型之間進行比較，以全面評估 LLM 的效能。方法：在這項回顧性隊列研究中，最初將 2006 年至 2010 年招募的 482,310 名參與者納入英國生物銀行資料庫，並隨後重新抽樣成 690 名參與者的最終隊列。對於每位參與者，MI 風險因子的表格資料都轉換成 ChatGPT 辨識的標準文字描述。回應是透過要求 ChatGPT 選擇一個介於 0 到 10 之間的評分來代表風險。思想鏈 (CoT) 提問用於評估 LLM 是否以邏輯方式進行預測。將 ChatGPT 的預測效能與已發表的醫療指數、傳統機器學習模型和其他大型語言模型進行比較。結論：目前的 LLM 尚未準備好應用於臨床醫學領域。建議未來的醫療 LLM 專精於醫療領域知識，以了解自然語言和量化的醫療數據，並進一步進行邏輯推理。</paragraph>

##### **Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers**
2409.14446v1 by Pablo Ramirez Amador, Dinarle Milagro Ortega, Arnold Cesarano

Pulmonary diseases are a public health problem that requires accurate and
fast diagnostic techniques. In this paper, a method based on convolutional
neural networks (CNN), Data Augmentation, ResNet50 and Vision Transformers
(ViT) is proposed to detect lung pathologies from medical images. A dataset of
X-ray images and CT scans of patients with different lung diseases, such as
cancer, pneumonia, tuberculosis and fibrosis, is used. The results obtained by
the proposed method are compared with those of other existing methods, using
performance metrics such as accuracy, sensitivity, specificity and area under
the ROC curve. The results show that the proposed method outperforms the other
methods in all metrics, achieving an accuracy of 98% and an area under the ROC
curve of 99%. It is concluded that the proposed method is an effective and
promising tool for the diagnosis of pulmonary pathologies by medical imaging.

摘要：肺部疾病是一種公共衛生問題，需要準確且快速的診斷技術。在本文中，提出了一種基於卷積神經網路 (CNN)、資料擴充、ResNet50 和視覺Transformer (ViT) 的方法，以從醫學影像中偵測肺部病理。我們使用了一組 X 光影像和不同肺部疾病患者的電腦斷層掃描，例如癌症、肺炎、肺結核和纖維化。將所提出的方法獲得的結果與其他現有方法的結果進行比較，使用準確度、敏感度、特異度和 ROC 曲線下的面積等效能指標。結果顯示，所提出的方法在所有指標上都優於其他方法，準確度達到 98%，ROC 曲線下的面積為 99%。結論是，所提出的方法是一種有效且有前途的工具，可透過醫學影像診斷肺部病理。

##### **Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series**
2409.14327v1 by Xu Yan, Yaoting Jiang, Wenyi Liu, Didi Yi, Haoyang Sang, Jianjun Wei

This paper explores a new method for time series data analysis, aiming to
overcome the limitations of traditional mining techniques when dealing with
multidimensional time series data. Time series data are extensively utilized in
diverse fields, including backend services for monitoring and optimizing IT
infrastructure, medical diagnosis through continuous patient monitoring and
health trend analysis, and internet business for tracking user behavior and
forecasting sales. However, since the effective information in time series data
is often hidden in sequence fragments, the uncertainty of their length,
quantity, and morphological variables brings challenges to mining. To this end,
this paper proposes a new spatiotemporal feature representation method, which
converts multidimensional time series (MTS) into one-dimensional event
sequences by transforming spatially varying events, and uses a series of event
symbols to represent the spatial structural information of multidimensional
coupling in the sequence, which has good interpretability. Then, this paper
introduces a variable-length tuple mining method to extract non-redundant key
event subsequences in event sequences as spatiotemporal structural features of
motion sequences. This method is an unsupervised method that does not rely on
large-scale training samples and defines a new model for representing the
spatiotemporal structural features of multidimensional time series. The
superior performance of the STEM model is verified by pattern classification
experiments on a variety of motion sequences. The research results of this
paper provide an important theoretical basis and technical support for
understanding and predicting human behavior patterns, and have far-reaching
practical application value.

摘要：<paragraph>本文探討了一種新的時間序列資料分析方法，旨在克服傳統挖掘技術在處理多維時間序列資料時的限制。時間序列資料廣泛用於各種領域，包括用於監控和最佳化 IT 基礎架構的後端服務、透過持續監控患者和健康趨勢分析進行的醫療診斷，以及用於追蹤使用者行為和預測銷售的網路業務。然而，由於時間序列資料中的有效資訊通常隱藏在序列片段中，因此其長度、數量和形態變數的不確定性為挖掘帶來了挑戰。為此，本文提出了一種新的時空特徵表示方法，該方法透過轉換空間上變化的事件將多維時間序列 (MTS) 轉換為一維事件序列，並使用一系列事件符號來表示序列中多維耦合的空間結構資訊，具有良好的可解釋性。然後，本文引入一種變長元組挖掘方法，以提取事件序列中非冗餘的關鍵事件子序列，作為動作序列的時空結構特徵。此方法是一種無監督方法，不依賴於大規模訓練樣本，並定義了一個新的模型來表示多維時間序列的時空結構特徵。STEM 模型的優異效能已通過各種動作序列上的模式分類實驗得到驗證。本文的研究成果為理解和預測人類行為模式提供了重要的理論基礎和技術支援，並具有深遠的實用應用價值。</paragraph>

##### **PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation**
2409.14302v1 by Yuxuan Zhou, Xien Liu, Chen Ning, Ji Wu

In the study, we aim to investigate current LLMs' mastery of medical factual
knowledge with a dynamic evaluation schema, which can automatically generate
multiple test samples for each medical factual knowledge point. Test samples
produced directly by LLMs always introduce factual errors and lack diversity in
the manner of knowledge expression. To overcome the drawbacks, here we propose
a novel evaluation method, Predicate-text Dual Transformation (PretextTrans),
by introducing predicate transformations into the dynamic evaluation schema.
Specifically, each medical knowledge point is firstly transformed into a
predicate expression; then, the predicate expression derives a series of
variants through predicate transformations; lastly, the produced predicate
variants are transformed back into textual expressions, resulting in a series
of test samples with both factual reliability and expression diversity. Using
the proposed PretextTrans method, we systematically investigate 12 well-known
LLMs' mastery of medical factual knowledge based on two medical datasets. The
comparison results show that current LLMs still have significant deficiencies
in fully mastering medical knowledge, which may illustrate why current LLMs
still perform unsatisfactorily in real-world medical scenarios despite having
achieved considerable performance on public benchmarks. Our proposed method
serves as an effective solution for evaluation of LLMs in medical domain and
offers valuable insights for developing medical-specific LLMs.

摘要：<paragraph>在研究中，我們旨在使用動態評估架構來調查當前 LLM 對醫學事實知識的掌握情況，該架構可以自動為每個醫學事實知識點生成多個測試樣本。由 LLM 直接產生的測試樣本總是會引入事實錯誤，並且在知識表達方式上缺乏多樣性。為了克服這些缺點，我們在此提出了一種新的評估方法，即謂詞-文本雙重轉換 (PretextTrans)，通過將謂詞轉換引入動態評估架構中。具體來說，每個醫學知識點首先被轉換為謂詞表達式；然後，謂詞表達式通過謂詞轉換得到一系列變體；最後，產生的謂詞變體被轉換回文本表達式，從而產生一系列既具有事實可靠性又具有表達多樣性的測試樣本。使用所提出的 PretextTrans 方法，我們系統地調查了 12 個著名的 LLM 對基於兩個醫學數據集的醫學事實知識的掌握情況。比較結果表明，當前 LLM 在完全掌握醫學知識方面仍然存在顯著的缺陷，這可能說明了為什麼當前 LLM 在現實世界的醫學場景中表現仍然不令人滿意，儘管在公共基準上取得了顯著的表現。我們提出的方法作為一種有效的解決方案，用於評估醫學領域的 LLM，並為開發特定於醫學的 LLM 提供了寶貴的見解。</paragraph>

##### **Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia**
2409.14194v1 by Rusham Elahi, Zia Tahseen, Tehreem Fatima, Syed Wafa Zahra, Hafiz Muhammad Abubakar, Tehreem Zafar, Aqs Younas, Muhammad Talha Quddoos, Usman Nazir

Primary healthcare is a crucial strategy for achieving universal health
coverage. South Asian countries are working to improve their primary healthcare
system through their country specific policies designed in line with WHO health
system framework using the six thematic pillars: Health Financing, Health
Service delivery, Human Resource for Health, Health Information Systems,
Governance, Essential Medicines and Technology, and an addition area of
Cross-Sectoral Linkages. Measuring the current accessibility of healthcare
facilities and workforce availability is essential for improving healthcare
standards and achieving universal health coverage in developing countries.
Data-driven surveillance approaches are required that can provide rapid,
reliable, and geographically scalable solutions to understand a) which
communities and areas are most at risk of inequitable access and when, b) what
barriers to health access exist, and c) how they can be overcome in ways
tailored to the specific challenges faced by individual communities. We propose
to harness current breakthroughs in Earth-observation (EO) technology, which
provide the ability to generate accurate, up-to-date, publicly accessible, and
reliable data, which is necessary for equitable access planning and resource
allocation to ensure that vaccines, and other interventions reach everyone,
particularly those in greatest need, during normal and crisis times. This
requires collaboration among countries to identify evidence based solutions to
shape health policy and interventions, and drive innovations and research in
the region.

摘要：初級保健是實現全民健保的關鍵策略。南亞國家透過制定符合 WHO 健保系統架構的國家特定政策，使用六大主題支柱來改善其初級保健系統：健保融資、健保服務提供、健保人力資源、健保資訊系統、治理、基本藥物與技術，以及跨部門連結的附加領域。衡量當前健保設施的可及性和人力可得性，對於提升健保標準和在開發中國家實現全民健保至關重要。需要以資料為基礎的監控方法，才能提供快速、可靠且在地域上可擴充的解決方案，以了解 a) 哪些社區和地區最容易遭受不公平的醫療服務，以及何時會發生、b) 醫療服務存有哪方面的障礙，以及 c) 如何以針對各個社區所面臨特定挑戰的方式克服這些障礙。我們提議利用地球觀測 (EO) 技術的最新突破，這些技術能產生準確、最新、公開且可靠的資料，這對於公平的醫療服務規劃和資源分配至關重要，以確保疫苗和其他干預措施能惠及所有人，特別是在正常和危機時期最需要的人。這需要各國合作，找出證據為基礎的解決方案，以制定健保政策和干預措施，並推動該地區的創新和研究。

##### **Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries**
2409.14181v1 by Andre de Carvalho, Robson Bonidia, Jude Dzevela Kong, Mariana Dauhajre, Claudio Struchiner, Guilherme Goedert, Peter F. Stadler, Maria Emilia Walter, Danilo Sanches, Troy Day, Marcia Castro, John Edmunds, Manuel Colome-Hidalgo, Demian Arturo Herrera Morban, Edian F. Franco, Cesar Ugarte-Gil, Patricia Espinoza-Lopez, Gabriel Carrasco-Escobar, Ulisses Rocha

Infectious diseases, transmitted directly or indirectly, are among the
leading causes of epidemics and pandemics. Consequently, several open
challenges exist in predicting epidemic outbreaks, detecting variants, tracing
contacts, discovering new drugs, and fighting misinformation. Artificial
Intelligence (AI) can provide tools to deal with these scenarios, demonstrating
promising results in the fight against the COVID-19 pandemic. AI is becoming
increasingly integrated into various aspects of society. However, ensuring that
AI benefits are distributed equitably and that they are used responsibly is
crucial. Multiple countries are creating regulations to address these concerns,
but the borderless nature of AI requires global cooperation to define
regulatory and guideline consensus. Considering this, The Global South AI for
Pandemic & Epidemic Preparedness & Response Network (AI4PEP) has developed an
initiative comprising 16 projects across 16 countries in the Global South,
seeking to strengthen equitable and responsive public health systems that
leverage Southern-led responsible AI solutions to improve prevention,
preparedness, and response to emerging and re-emerging infectious disease
outbreaks. This opinion introduces our branches in Latin American and Caribbean
(LAC) countries and discusses AI governance in LAC in the light of
biotechnology. Our network in LAC has high potential to help fight infectious
diseases, particularly in low- and middle-income countries, generating
opportunities for the widespread use of AI techniques to improve the health and
well-being of their communities.

摘要：傳染病的直接或間接傳播是造成流行病和全球大流行的主要原因之一。因此，在預測流行病爆發、檢測變異株、追蹤接觸者、發現新藥物和對抗錯誤訊息方面存在許多未解決的挑戰。人工智慧 (AI) 可提供應對這些情境的工具，在對抗 COVID-19 大流行方面展現出令人振奮的成果。AI 正日益融入社會的各個層面。然而，確保 AI 的好處能公平分配且負責任地使用至關重要。許多國家正制定法規來解決這些問題，但 AI 的無國界性質需要全球合作才能定義法規和指導方針的共識。有鑑於此，全球南方 AI 防疫和流行病防範及應變網路 (AI4PEP) 已開發一項計畫，包含全球南方 16 個國家/地區的 16 個專案，旨在強化公平且具應變能力的公共衛生系統，並利用南方主導的負責任 AI 解決方案來改善對新興和再興傳染病爆發的預防、防範和應變。本意見書介紹我們在拉丁美洲和加勒比海 (LAC) 國家的分支機構，並根據生物技術探討 LAC 中的 AI 治理。我們在 LAC 的網路極具潛力，有助於對抗傳染病，特別是在低收入和中等收入國家，並為廣泛使用 AI 技術創造機會，以改善其社區的健康和福祉。

##### **CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data**
2409.13903v1 by Zhao Cheng, Diane Wan, Matthew Abueg, Sahra Ghalebikesabi, Ren Yi, Eugene Bagdasarian, Borja Balle, Stefan Mellem, Shawn O'Banion

Advances in generative AI point towards a new era of personalized
applications that perform diverse tasks on behalf of users. While general AI
assistants have yet to fully emerge, their potential to share personal data
raises significant privacy challenges. This paper introduces CI-Bench, a
comprehensive synthetic benchmark for evaluating the ability of AI assistants
to protect personal information during model inference. Leveraging the
Contextual Integrity framework, our benchmark enables systematic assessment of
information flow across important context dimensions, including roles,
information types, and transmission principles. We present a novel, scalable,
multi-step synthetic data pipeline for generating natural communications,
including dialogues and emails. Unlike previous work with smaller, narrowly
focused evaluations, we present a novel, scalable, multi-step data pipeline
that synthetically generates natural communications, including dialogues and
emails, which we use to generate 44 thousand test samples across eight domains.
Additionally, we formulate and evaluate a naive AI assistant to demonstrate the
need for further study and careful training towards personal assistant tasks.
We envision CI-Bench as a valuable tool for guiding future language model
development, deployment, system design, and dataset construction, ultimately
contributing to the development of AI assistants that align with users' privacy
expectations.

摘要：生成式 AI 的進展指向一個新的個人化應用程式時代，這些應用程式可以代表使用者執行各種任務。儘管通用 AI 助理尚未完全出現，但它們共享個人資料的潛力引發了重大的隱私挑戰。本文介紹 CI-Bench，一個全面的合成基準，用於評估 AI 助理在模型推論期間保護個人資訊的能力。利用情境完整性架構，我們的基準可以系統性地評估跨越重要情境維度的資訊流，包括角色、資訊類型和傳輸原則。我們提出了一個新穎、可擴充、多步驟的合成資料管道，用於產生自然溝通，包括對話和電子郵件。與先前針對較小、重點較窄的評估所做的工作不同，我們提出了一個新穎、可擴充、多步驟的資料管道，可以合成產生自然溝通，包括對話和電子郵件，我們使用這些資料在八個網域中產生了 44,000 個測試範例。此外，我們制定並評估了一個天真的 AI 助理，以證明需要進一步研究和仔細培訓，才能執行個人助理任務。我們將 CI-Bench 視為指導未來語言模型開發、部署、系統設計和資料集建構的寶貴工具，最終有助於開發符合使用者隱私預期的 AI 助理。

##### **Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology**
2409.13902v1 by Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen

Despite the potential of Large Language Models (LLMs) in medicine, they may
generate responses lacking supporting evidence or based on hallucinated
evidence. While Retrieval Augment Generation (RAG) is popular to address this
issue, few studies implemented and evaluated RAG in downstream domain-specific
applications. We developed a RAG pipeline with 70,000 ophthalmology-specific
documents that retrieve relevant documents to augment LLMs during inference
time. In a case study on long-form consumer health questions, we systematically
evaluated the responses including over 500 references of LLMs with and without
RAG on 100 questions with 10 healthcare professionals. The evaluation focuses
on factuality of evidence, selection and ranking of evidence, attribution of
evidence, and answer accuracy and completeness. LLMs without RAG provided 252
references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor
errors, and 20.6% were correct. In contrast, LLMs with RAG significantly
improved accuracy (54.5% being correct) and reduced error rates (18.8% with
minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents
retrieved by RAG were selected as the top references in the LLM response, with
an average ranking of 4.9. The use of RAG also improved evidence attribution
(increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight
decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47
to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited
hallucinated and erroneous evidence in the responses, raising concerns for
downstream applications in the medical domain. RAG substantially reduced the
proportion of such evidence but encountered challenges.

摘要：儘管大型語言模型（LLM）在醫學領域具有潛力，但它們可能會產生缺乏支持證據或基於虛構證據的回應。雖然檢索擴充生成（RAG）很受歡迎，用於解決此問題，但很少有研究在下游特定領域的應用中實施和評估 RAG。我們開發了一個 RAG 管線，其中包含 70,000 份特定於眼科的文件，這些文件會在推理時間檢索相關文件以擴充 LLM。在針對長篇消費者健康問題的案例研究中，我們系統性地評估了 LLM 的回應，包括 100 個問題中 500 多個引用，其中 10 個問題由 10 位醫療保健專業人員提出。評估重點在於證據的真實性、證據的選擇和排名、證據的歸因，以及答案的準確性和完整性。沒有 RAG 的 LLM 總共提供了 252 個參考。其中，45.3% 是虛構的，34.1% 包含輕微錯誤，20.6% 是正確的。相比之下，帶有 RAG 的 LLM 大幅提高了準確度（54.5% 是正確的）並降低了錯誤率（18.8% 有輕微虛構，26.7% 有錯誤）。RAG 檢索的前 10 份文件中有 62.5% 被選為 LLM 回應中的首要參考，平均排名為 4.9。RAG 的使用也改進了證據歸因（在 5 分量表上從 1.85 增加到 2.49，P<0.001），儘管準確度（從 3.52 降低到 3.23，P=0.03）和完整性（從 3.47 降低到 3.27，P=0.17）略有下降。結果表明，LLM 在回應中經常表現出虛構和錯誤的證據，這引起了對醫療領域下游應用程序的擔憂。RAG 大幅減少了此類證據的比例，但遇到了挑戰。

##### **A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics**
2409.13825v1 by Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai

Understanding the structure and motion of the heart is crucial for diagnosing
and managing cardiovascular diseases, the leading cause of global death. There
is wide variation in cardiac shape and motion patterns, that are influenced by
demographic, anthropometric and disease factors. Unravelling the normal
patterns of shape and motion, as well as understanding how each individual
deviates from the norm, would facilitate accurate diagnosis and personalised
treatment strategies. To this end, we developed a novel conditional generative
model, MeshHeart, to learn the distribution of cardiac shape and motion
patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences,
taking into account clinical factors such as age, sex, weight and height. To
model the high-dimensional and complex spatio-temporal mesh data, MeshHeart
employs a geometric encoder to represent cardiac meshes in a latent space,
followed by a temporal Transformer to model the motion dynamics of latent
representations. Based on MeshHeart, we investigate the latent space of 3D+t
cardiac mesh sequences and propose a novel distance metric termed latent delta,
which quantifies the deviation of a real heart from its personalised normative
pattern in the latent space. In experiments using a large dataset of 38,309
subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence
reconstruction and generation. Features defined in the latent space are highly
discriminative for cardiac disease classification, whereas the latent delta
exhibits strong correlation with clinical phenotypes in phenome-wide
association studies. The codes and models of this study will be released to
benefit further research on digital heart modelling.

摘要：<paragraph>了解心脏的结构和运动对于诊断和管理心血管疾病至关重要，而心血管疾病是全球主要的死亡原因。心脏的形状和运动模式有很大的差异，这些差异受人口统计学、人体测量学和疾病因素的影响。解开形状和运动的正常模式，以及了解每个人如何偏离常态，将有助于准确诊断和个性化治疗策略。为此，我们开发了一种新颖的条件生成模型 MeshHeart，以学习心脏形状和运动模式的分布。MeshHeart 能够生成 3D+t 心脏网格序列，同时考虑年龄、性别、体重和身高等临床因素。为了对高维和复杂的时空网格数据建模，MeshHeart 采用几何编码器在潜在空间中表示心脏网格，然后采用时间转换器对潜在表示的运动动态进行建模。基于 MeshHeart，我们研究了 3D+t 心脏网格序列的潜在空间，并提出了一个新颖的距离度量，称为潜在增量，该度量量化了真实心脏在其潜在空间中与其个性化规范模式的偏差。在使用包含 38,309 名受试者的庞大数据集进行的实验中，MeshHeart 在心脏网格序列重建和生成方面表现出很高的性能。在潜在空间中定义的特征对于心脏疾病分类具有很高的判别力，而潜在增量在全表型关联研究中与临床表型表现出很强的相关性。本研究的代码和模型将发布，以造福对数字心脏建模的进一步研究。</paragraph>

##### **Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning**
2409.13688v1 by Hadi Rezvani, Navid Zarrabi, Ishaan Mehta, Christopher Kolios, Hussein Ali Jaafar, Cheng-Hao Kao, Sajad Saeedi, Nariman Yousefi

Plastic pollution presents an escalating global issue, impacting health and
environmental systems, with micro- and nanoplastics found across mediums from
potable water to air. Traditional methods for studying these contaminants are
labor-intensive and time-consuming, necessitating a shift towards more
efficient technologies. In response, this paper introduces micro- and
nanoplastics (MiNa), a novel and open-source dataset engineered for the
automatic detection and classification of micro and nanoplastics using object
detection algorithms. The dataset, comprising scanning electron microscopy
images simulated under realistic aquatic conditions, categorizes plastics by
polymer type across a broad size spectrum. We demonstrate the application of
state-of-the-art detection algorithms on MiNa, assessing their effectiveness
and identifying the unique challenges and potential of each method. The dataset
not only fills a critical gap in available resources for microplastic research
but also provides a robust foundation for future advancements in the field.

摘要：塑膠污染是一個日益嚴重的全球議題，影響健康和環境系統，從飲用水到空氣中都發現了微塑膠和奈米塑膠。傳統研究這些污染物的技術費時費力，因此有必要轉向更有效率的技術。為了解決這個問題，本文介紹微塑膠和奈米塑膠 (MiNa)，這是一個新穎的開源資料集，專門用於使用物件偵測演算法自動偵測和分類微塑膠和奈米塑膠。該資料集包含在逼真的水生環境下模擬的掃描電子顯微鏡影像，並根據聚合物類型對塑膠進行分類，涵蓋廣泛的尺寸範圍。我們展示了在 MiNa 上應用最先進的偵測演算法，評估其有效性，並找出每種方法的獨特挑戰和潛力。該資料集不僅填補了微塑膠研究可用資源的關鍵缺口，也為該領域未來的進展奠定了穩固的基礎。

##### **Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory**
2409.15084v1 by Kunyao Lan, Bingui Jin, Zichen Zhu, Siyuan Chen, Shu Zhang, Kenny Q. Zhu, Mengyue Wu

Mental health issues, particularly depressive disorders, present significant
challenges in contemporary society, necessitating the development of effective
automated diagnostic methods. This paper introduces the Agent Mental Clinic
(AMC), a self-improving conversational agent system designed to enhance
depression diagnosis through simulated dialogues between patient and
psychiatrist agents. To enhance the dialogue quality and diagnosis accuracy, we
design a psychiatrist agent consisting of a tertiary memory structure, a
dialogue control and reflect plugin that acts as ``supervisor'' and a memory
sampling module, fully leveraging the skills reflected by the psychiatrist
agent, achieving great accuracy on depression risk and suicide risk diagnosis
via conversation. Experiment results on datasets collected in real-life
scenarios demonstrate that the system, simulating the procedure of training
psychiatrists, can be a promising optimization method for aligning LLMs with
real-life distribution in specific domains without modifying the weights of
LLMs, even when only a few representative labeled cases are available.

摘要：心理健康問題，尤其是憂鬱症，對現代社會構成重大挑戰，因此有必要開發有效的自動診斷方法。本文介紹了 Agent Mental Clinic (AMC)，這是一個自我提升的對話代理系統，旨在透過患者和精神科醫師代理之間的模擬對話來加強憂鬱症的診斷。為了提升對話品質和診斷準確度，我們設計了一個精神科醫師代理，它包含一個三級記憶結構、一個對話控制和反映插件（作為「監督者」）和一個記憶體抽樣模組，充分利用精神科醫師代理反映的技能，透過對話在憂鬱症風險和自殺風險診斷上取得極高的準確度。在現實生活中收集的資料集上的實驗結果表明，這個系統模擬了精神科醫師的訓練程序，可以成為一種有前途的最佳化方法，用於在不修改 LLM 權重的條件下，將 LLM 與特定領域的真實生活分佈對齊，即使只有少數具有代表性的標記案例可用。

##### **Toward Automated Clinical Transcriptions**
2409.15378v1 by Mitchell A. Klusty, W. Vaiden Logan, Samuel E. Armstrong, Aaron D. Mullen, Caroline N. Leach, Jeff Talbert, V. K. Cody Bumgardner

Administrative documentation is a major driver of rising healthcare costs and
is linked to adverse outcomes, including physician burnout and diminished
quality of care. This paper introduces a secure system that applies recent
advancements in speech-to-text transcription and speaker-labeling (diarization)
to patient-provider conversations. This system is optimized to produce accurate
transcriptions and highlight potential errors to promote rapid human
verification, further reducing the necessary manual effort. Applied to over 40
hours of simulated conversations, this system offers a promising foundation for
automating clinical transcriptions.

摘要：行政文件是醫療保健成本上升的主要驅動力，並與不良結果有關，包括醫師倦怠和醫療品質下降。本文介紹了一個安全的系統，該系統將語音轉文字轉錄和說話者標籤（日記）的最新進展應用於患者與提供者的對話。此系統經過最佳化，可產生準確的轉錄並強調潛在錯誤，以促進快速的人工驗證，進一步減少必要的作業。應用於超過 40 小時的模擬對話，此系統為自動化臨床轉錄提供了有希望的基礎。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning**
2409.13440v1 by Xiaowen Fu, Bingxin Wang, Xinzhou Guo, Guoqing Liu, Yang Xiang

Recently, multimodal electroencephalogram (EEG) learning has shown great
promise in disease detection. At the same time, ensuring privacy in clinical
studies has become increasingly crucial due to legal and ethical concerns. One
widely adopted scheme for privacy protection is differential privacy (DP)
because of its clear interpretation and ease of implementation. Although
numerous methods have been proposed under DP, it has not been extensively
studied for multimodal EEG data due to the complexities of models and signal
data considered there. In this paper, we propose a novel Differentially Private
Multimodal Laplacian Dropout (DP-MLD) scheme for multimodal EEG learning. Our
approach proposes a novel multimodal representative learning model that
processes EEG data by language models as text and other modal data by vision
transformers as images, incorporating well-designed cross-attention mechanisms
to effectively extract and integrate cross-modal features. To achieve DP, we
design a novel adaptive feature-level Laplacian dropout scheme, where
randomness allocation and performance are dynamically optimized within given
privacy budgets. In the experiment on an open-source multimodal dataset of
Freezing of Gait (FoG) in Parkinson's Disease (PD), our proposed method
demonstrates an approximate 4\% improvement in classification accuracy, and
achieves state-of-the-art performance in multimodal EEG learning under DP.

摘要：<paragraph>最近，多模态脑电图 (EEG) 学习在疾病检测方面显示出了巨大的前景。与此同时，由于法律和道德方面的考虑，在临床研究中确保隐私变得越来越重要。差分隐私 (DP) 是一种被广泛采用的隐私保护方案，因为它具有清晰的解释和易于实现的特点。尽管在 DP 下已经提出了许多方法，但由于所考虑的模型和信号数据的复杂性，尚未对其在多模态 EEG 数据中进行广泛的研究。在本文中，我们提出了一种新颖的差分隐私多模态拉普拉斯 Dropout（DP-MLD）方案，用于多模态 EEG 学习。我们的方法提出了一种新颖的多模态表示学习模型，该模型通过语言模型将 EEG 数据处理为文本，并将其他模态数据通过视觉转换器处理为图像，并结合精心设计的交叉注意力机制来有效提取和整合跨模态特征。为了实现 DP，我们设计了一种新颖的自适应特征级拉普拉斯 Dropout 方案，其中在给定的隐私预算内动态优化随机性分配和性能。在帕金森病 (PD) 中步态冻结 (FoG) 的开源多模态数据集上的实验中，我们提出的方法在分类准确性方面显示出约 4% 的提升，并在 DP 下的多模态 EEG 学习中实现了最先进的性能。</paragraph>

##### **FPBoost: Fully Parametric Gradient Boosting for Survival Analysis**
2409.13363v1 by Alberto Archetti, Eugenio Lomurno, Diego Piccinotti, Matteo Matteucci

Survival analysis is a critical tool for analyzing time-to-event data and
extracting valuable clinical insights. Recently, numerous machine learning
techniques leveraging neural networks and decision trees have been developed
for this task. Among these, the most successful approaches often rely on
specific assumptions about the shape of the modeled hazard function. These
assumptions include proportional hazard, accelerated failure time, or discrete
estimation at a predefined set of time points. In this study, we propose a
novel paradigm for survival model design based on the weighted sum of
individual fully parametric hazard contributions. We build upon well-known
ensemble techniques to deliver a novel contribution to the field by applying
additive hazard functions, improving over approaches based on survival or
cumulative hazard functions. Furthermore, the proposed model, which we call
FPBoost, is the first algorithm to directly optimize the survival likelihood
via gradient boosting. We evaluated our approach across a diverse set of
datasets, comparing it against a variety of state-of-the-art models. The
results demonstrate that FPBoost improves risk estimation, according to both
concordance and calibration metrics.

摘要：生存分析是分析事件发生时间数据和提取有价值的临床见解的关键工具。最近，已经开发出许多利用神经网络和决策树的机器学习技术来完成此任务。其中，最成功的做法通常依赖于对建模风险函数形状的特定假设。这些假设包括比例风险、加速失效时间或在预定义时间点进行离散估计。在这项研究中，我们提出了一种基于加权和的个体全参数风险贡献的新型生存模型设计范例。我们建立在众所周知的集成技术之上，通过应用加性风险函数，对该领域做出新的贡献，改进基于生存或累积风险函数的方法。此外，我们称之为 FPBoost 的提议模型是第一个直接通过梯度提升优化生存可能性的算法。我们对各种数据集评估了我们的方法，并将其与各种最先进的模型进行了比较。结果表明，根据一致性和校准指标，FPBoost 改进了风险估计。

##### **Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning**
2409.13791v1 by Annette Spooner, Mohammad Karimi Moridani, Azadeh Safarchi, Salim Maher, Fatemeh Vafaee, Amany Zekry, Arcot Sowmya

The complementary information found in different modalities of patient data
can aid in more accurate modelling of a patient's disease state and a better
understanding of the underlying biological processes of a disease. However, the
analysis of multi-modal, multi-omics data presents many challenges, including
high dimensionality and varying size, statistical distribution, scale and
signal strength between modalities. In this work we compare the performance of
a variety of ensemble machine learning algorithms that are capable of late
integration of multi-class data from different modalities. The ensemble methods
and their variations tested were i) a voting ensemble, with hard and soft vote,
ii) a meta learner, iii) a multi-modal Adaboost model using a hard vote, a soft
vote and a meta learner to integrate the modalities on each boosting round, the
PB-MVBoost model and a novel application of a mixture of experts model. These
were compared to simple concatenation as a baseline. We examine these methods
using data from an in-house study on hepatocellular carcinoma (HCC), along with
four validation datasets on studies from breast cancer and irritable bowel
disease (IBD). Using the area under the receiver operating curve as a measure
of performance we develop models that achieve a performance value of up to 0.85
and find that two boosted methods, PB-MVBoost and Adaboost with a soft vote
were the overall best performing models. We also examine the stability of
features selected, and the size of the clinical signature determined. Finally,
we provide recommendations for the integration of multi-modal multi-class data.

摘要：<paragraph>在不同模式的患者數據中發現的互補信息，有助於更準確地建立患者疾病狀態的模型，並更深入了解疾病的基礎生物過程。然而，多模態、多組學數據的分析提出了許多挑戰，包括高維度和不同的數據規模、統計分佈、比例和模態之間的信號強度。在這項工作中，我們比較了各種集成機器學習演算法的效能，這些演算法能夠對來自不同模態的多類別數據進行後整合。測試的集成方法及其變體為：i) 投票集成，採用硬投票和軟投票，ii) 元學習器，iii) 多模態 Adaboost 模型，使用硬投票、軟投票和元學習器在每次提升回合中整合模態，PB-MVBoost 模型和專家混合模型的新應用。這些方法與作為基準的簡單串接進行了比較。我們使用來自肝細胞癌 (HCC) 內部研究的數據，以及來自乳癌和腸躁症 (IBD) 研究的四個驗證數據集，來檢驗這些方法。使用受試者操作曲線下的面積作為效能衡量標準，我們開發了效能值高達 0.85 的模型，並發現兩種提升方法，PB-MVBoost 和採用軟投票的 Adaboost 是整體效能最佳的模型。我們還檢驗了所選特徵的穩定性，以及所確定的臨床特徵的大小。最後，我們針對多模態多類別數據的整合提供了建議。</paragraph>

##### **Recent Advancement of Emotion Cognition in Large Language Models**
2409.13354v1 by Yuyan Chen, Yanghua Xiao

Emotion cognition in large language models (LLMs) is crucial for enhancing
performance across various applications, such as social media, human-computer
interaction, and mental health assessment. We explore the current landscape of
research, which primarily revolves around emotion classification, emotionally
rich response generation, and Theory of Mind assessments, while acknowledge the
challenges like dependency on annotated data and complexity in emotion
processing. In this paper, we present a detailed survey of recent progress in
LLMs for emotion cognition. We explore key research studies, methodologies,
outcomes, and resources, aligning them with Ulric Neisser's cognitive stages.
Additionally, we outline potential future directions for research in this
evolving field, including unsupervised learning approaches and the development
of more complex and interpretable emotion cognition LLMs. We also discuss
advanced methods such as contrastive learning used to improve LLMs' emotion
cognition capabilities.

摘要：大型語言模型（LLM）的情緒認知對於增強各種應用程式的效能至關重要，例如社群媒體、人機互動和心理健康評估。我們探討了當前研究領域，其主要圍繞著情緒分類、情緒豐富的回應產生和心智理論評估，同時承認依賴註解資料和情緒處理的複雜性等挑戰。在本文中，我們對 LLM 在情緒認知方面的近期進展進行了詳細的調查。我們探討了關鍵的研究、方法、成果和資源，並將它們與烏爾里希·奈瑟的認知階段相結合。此外，我們概述了這個不斷演進的領域中未來研究的潛在方向，包括無監督學習方法和更複雜且可解釋的情緒認知 LLM 的開發。我們還討論了對比學習等先進方法，用於提升 LLM 的情緒認知能力。

##### **SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**
2409.13321v1 by Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu

Inspired by the success of large language models (LLMs), there is growing
research interest in developing LLMs in the medical domain to assist
clinicians. However, for hospitals, using closed-source commercial LLMs
involves privacy issues, and developing open-source public LLMs requires
large-scale computational resources, which are usually limited, especially in
resource-efficient regions and low-income countries. We propose an open-source
Small Language and Vision Assistant (SLaVA-CXR) that can be used for Chest
X-Ray report automation. To efficiently train a small assistant, we first
propose the Re$^3$Training method, which simulates the cognitive development of
radiologists and optimizes the model in the Recognition, Reasoning, and
Reporting training manner. Then, we introduce a data synthesis method, RADEX,
which can generate a high-quality and diverse training corpus with privacy
regulation compliance. The extensive experiments show that our SLaVA-CXR built
on a 2.7B backbone not only outperforms but also achieves 6 times faster
inference efficiency than previous state-of-the-art larger models.

摘要：受到大型語言模型 (LLM) 成功啟發，在醫療領域開發 LLM 以協助臨床醫生引起了越來越多的研究興趣。然而，對於醫院而言，使用封閉原始碼的商業 LLM 涉及隱私問題，而開發開放原始碼的公共 LLM 需要大規模的計算資源，這些資源通常有限，特別是在資源效率高的地區和低收入國家。我們提出了一個開放原始碼的小語言和視覺助理 (SLaVA-CXR)，可用於胸部 X 光報告自動化。為了有效訓練一個小型助理，我們首先提出了 Re$^3$Training 方法，它模擬了放射科醫生的認知發展，並以識別、推理和報告訓練方式優化模型。然後，我們引入了一種數據合成方法 RADEX，它可以在符合隱私法規的情況下生成一個高品質且多樣化的訓練語料庫。大量的實驗表明，我們建立在 2.7B 主幹上的 SLaVA-CXR 不僅表現出色，而且推理效率比以前最先進的較大模型快 6 倍。

##### **OMG-RL:Offline Model-based Guided Reward Learning for Heparin Treatment**
2409.13299v1 by Yooseok Lim, Sujee Lee

Accurate diagnosis of individual patient conditions and appropriate
medication dosing strategies are core elements of personalized medical
decision-making processes. This therapeutic procedure, which entails
recursively assessing the patient's condition and administering suitable
medications, can effectively be modeled as a reinforcement learning (RL)
problem. Crucially, the success of RL in this context depends on the
establishment of a well-defined reward function that accurately represents the
optimal treatment strategy. However, defining the learning direction in RL with
only a limited set of explicit indicators complicates the task due to the
inherent complexity of the required domain knowledge. This approach may also
increase the likelihood that the RL policy does not adequately reflect the
clinician's treatment intentions, which are determined by considering various
situations and indicators. In this study, we focus on developing a reward
function that reflects the clinician's intentions and introduce Offline
Model-based Guided Reward Learning (OMG-RL), which performs offline inverse
reinforcement learning (IRL) aligned with the offline RL environment. Through
OMG-RL, we learn a parameterized reward function that includes the expert's
intentions from limited data, thereby enhancing the agent's policy. We validate
the proposed approach on the heparin dosing task. The results demonstrate that
policy learning through OMG-RL is meaningful and confirm that the learned
policy is positively reinforced in terms of activated partial thromboplastin
time (aPTT), a key indicator for monitoring the effects of heparin. This
approach can be broadly utilized not only for the heparin dosing problem but
also for RL-based medication dosing tasks in general.

摘要：準確診斷個別病患狀況和適當的藥物給藥策略是個人化醫療決策過程中核心元素。這個治療程序包含反覆評估病患狀況和給予適當藥物，可以有效地建模為強化學習 (RL) 問題。至關重要的是，RL 在此脈絡中的成功取決於建立一個定義良好的回饋函數，能準確代表最佳治療策略。然而，僅使用有限的明確指標來定義 RL 中的學習方向會使任務複雜化，因為需要領域知識的複雜性。這種方法也可能增加 RL 政策無法充分反映臨床醫師治療意圖的可能性，而臨床醫師的治療意圖是由考量各種情況和指標來決定的。在本研究中，我們專注於開發一個反映臨床醫師意圖的回饋函數，並引入離線模型引導回饋學習 (OMG-RL)，它執行與離線 RL 環境一致的離線逆向強化學習 (IRL)。透過 OMG-RL，我們從有限的資料中學習一個參數化的回饋函數，其中包含專家的意圖，從而增強代理的政策。我們在肝素給藥任務中驗證了所提出的方法。結果表明，透過 OMG-RL 進行政策學習是有意義的，並確認所學習的政策在活化部分凝血活酶時間 (aPTT) 方面得到正向加強，而 aPTT 是監測肝素效果的關鍵指標。這種方法不僅可以廣泛用於肝素給藥問題，還可以用於一般的基於 RL 的藥物給藥任務。

##### **Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia**
2409.15377v1 by Elisa Castagnari, Lillian Muyama, Adrien Coulet

In practice, clinicians achieve a diagnosis by following a sequence of steps,
such as laboratory exams, observations, or imaging. The pathways to reach
diagnosis decisions are documented by guidelines authored by expert
organizations, which guide clinicians to reach a correct diagnosis through
these sequences of steps. While these guidelines are beneficial for following
medical reasoning and consolidating medical knowledge, they have some
drawbacks. They often fail to address patients with uncommon conditions due to
their focus on the majority population, and are slow and costly to update,
making them unsuitable for rapidly emerging diseases or new practices. Inspired
by clinical guidelines, our study aimed to develop pathways similar to those
that can be obtained in clinical guidelines. We tested three Large Language
Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language
Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to
differentially diagnose anemia and its subtypes. By using advanced prompting
techniques to enhance the decision-making process, we generated diagnostic
pathways using these models. Experimental results indicate that LLMs hold huge
potential in clinical pathway discovery from patient data, with GPT-4
exhibiting the best performance in all conducted experiments.

摘要：<paragraph>在實務上，臨床醫生會遵循一系列步驟來診斷，
例如實驗室檢查、觀察或影像。診斷決策的途徑由專家組織編寫的指南記錄下來，這些指南引導臨床醫生透過這些步驟序列得出正確的診斷。雖然這些指南有助於遵循醫療推理並彙整醫療知識，但它們有一些缺點。由於專注於大多數族群，它們常常無法針對罕見疾病的患者提供建議，而且更新既緩慢又昂貴，這使得它們不適合用於快速出現的疾病或新療法。受到臨床指南的啟發，我們的研究旨在開發出類似於臨床指南中可以獲得的途徑。我們在一個合成但逼真的資料集上測試了三個大型語言模型 (LLM) - 生成式預訓練Transformer 4 (GPT-4)、大型語言模型 Meta AI (LLaMA) 和 Mistral - 以區分診斷貧血及其亞型。透過使用進階提示技術來增強決策制定過程，我們使用這些模型生成了診斷途徑。實驗結果表明，LLM 在從患者資料中發現臨床途徑方面具有巨大的潛力，其中 GPT-4 在所有進行的實驗中表現最佳。</paragraph>

##### **An adapted large language model facilitates multiple medical tasks in diabetes care**
2409.13191v1 by Lai Wei, Zhen Ying, Muyang He, Yutong Chen, Qian Yang, Yanzhe Hong, Jiaping Lu, Xiaoying Li, Weiran Huang, Ying Chen

Diabetes is a chronic disease that poses a significant global health burden,
and optimizing diabetes management requires multi-stakeholder collaboration.
Large language models (LLMs) have shown promise in various healthcare
scenarios, but their effectiveness across a diverse range of diabetes tasks
remains unproven. In this study, we introduced a framework to train and
validate diabetes-specific LLMs. We first developed a comprehensive data
processing pipeline that includes data collection, filtering, augmentation and
refinement. This approach contributes to creating a high-quality,
diabetes-specific dataset, and several evaluation benchmarks entirely from
scratch. Utilizing the collected training dataset, we fine-tuned a
diabetes-specific LLM family that demonstrated state-of-the-art proficiency in
understanding and processing various diabetes tasks compared to other LLMs.
Furthermore, clinical studies showed the potential applications of our models
in diabetes care, including providing personalized healthcare, assisting
medical education, and streamlining clinical tasks. In conclusion, our study
introduced a framework to develop and evaluate a diabetes-specific LLM family,
and highlighted its potential to enhance clinical practice and provide
personalized, data-driven support for diabetes support when facing different
end users. The code is provided via GitHub at
https://github.com/waltonfuture/Diabetica.

摘要：糖尿病是一種慢性疾病，對全球健康造成重大負擔，而優化糖尿病管理需要多方利益相關者的合作。大型語言模型 (LLM) 已在各種醫療保健場景中展現出潛力，但它們在各種糖尿病任務中的有效性仍未得到證實。在這個研究中，我們引入了一個訓練和驗證糖尿病特定 LLM 的框架。我們首先開發了一個全面的數據處理管道，其中包括數據收集、過濾、擴充和優化。這種方法有助於創建一個高品質、特定於糖尿病的數據集，以及從頭開始的幾個評估基準。利用收集的訓練數據集，我們微調了一個特定於糖尿病的 LLM 家族，與其他 LLM 相比，在理解和處理各種糖尿病任務方面展示了最先進的熟練度。此外，臨床研究表明我們的模型在糖尿病護理中具有潛在應用，包括提供個性化醫療保健、協助醫學教育和簡化臨床任務。總之，我們的研究引入了一個開發和評估特定於糖尿病的 LLM 家族的框架，並強調了其增強臨床實務和在面對不同最終用戶時提供個性化、數據驅動的糖尿病支持的潛力。該程式碼透過 GitHub 提供，網址為 https://github.com/waltonfuture/Diabetica。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Personalized 2D Binary Patient Codes of Tissue Images and Immunogenomic Data Through Multimodal Self-Supervised Fusion**
2409.13115v1 by Areej Alsaafin, Abubakr Shafique, Saghir Alfasly, H. R. Tizhoosh

The field of medical diagnostics has witnessed a transformative convergence
of artificial intelligence (AI) and healthcare data, offering promising avenues
for enhancing patient care and disease comprehension. However, this integration
of multimodal data, specifically histopathology whole slide images (WSIs) and
genetic sequencing data, presents unique challenges due to modality disparities
and the need for scalable computational solutions. This paper addresses the
scarcity of multimodal solutions, primarily centered around unimodal data
solutions, thus limiting the realization of the rich insights that can be
derived from integrating images and genomic data. Here, we introduce MarbliX
``Multimodal Association and Retrieval with Binary Latent Indexed matriX,'' an
innovative multimodal framework that integrates histopathology images with
immunogenomic sequencing data, encapsulating them into a concise binary patient
code, referred to as ``monogram.'' This binary representation facilitates the
establishment of a comprehensive archive, enabling clinicians to match similar
cases. The experimental results demonstrate the potential of MarbliX to empower
healthcare professionals with in-depth insights, leading to more precise
diagnoses, reduced variability, and expanded personalized treatment options,
particularly in the context of cancer.

摘要：醫療診斷領域見證了人工智慧 (AI) 與醫療保健資料的變革性融合，為提升病患照護和疾病理解提供了有希望的途徑。然而，這種整合多模式資料，特別是組織病理學全切片影像 (WSI) 和基因定序資料，由於模式差異和對可擴充計算解決方案的需求，因此提出了獨特的挑戰。本文探討了多模式解決方案的稀缺性，主要集中在單模式資料解決方案，因此限制了從整合影像和基因體資料中獲得豐富見解的實現。在此，我們介紹 MarbliX ``使用二進制潛在索引矩陣的多模式關聯和擷取''，一個創新的多模式架構，它將組織病理學影像與免疫基因組定序資料整合，將它們封裝成一個簡潔的二進制病患代碼，稱為 ``單字''。這種二進制表示有助於建立一個全面的檔案，讓臨床醫生能夠比對類似的案例。實驗結果證明了 MarbliX 能夠讓醫療保健專業人員獲得深入見解的潛力，從而導致更精確的診斷、減少變異性，並擴展個人化治療選項，特別是在癌症的背景下。

##### **DenoMamba: A fused state-space model for low-dose CT denoising**
2409.13094v1 by Şaban Öztürk, Oğuz Can Duran, Tolga Çukur

Low-dose computed tomography (LDCT) lower potential risks linked to radiation
exposure while relying on advanced denoising algorithms to maintain diagnostic
quality in reconstructed images. The reigning paradigm in LDCT denoising is
based on neural network models that learn data-driven image priors to separate
noise evoked by dose reduction from underlying tissue signals. Naturally, the
fidelity of these priors depend on the model's ability to capture the broad
range of contextual features evident in CT images. Earlier convolutional neural
networks (CNN) are highly adept at efficiently capturing short-range spatial
context, but their limited receptive fields reduce sensitivity to interactions
over longer distances. Although transformers based on self-attention mechanisms
have recently been posed to increase sensitivity to long-range context, they
can suffer from suboptimal performance and efficiency due to elevated model
complexity, particularly for high-resolution CT images. For high-quality
restoration of LDCT images, here we introduce DenoMamba, a novel denoising
method based on state-space modeling (SSM), that efficiently captures short-
and long-range context in medical images. Following an hourglass architecture
with encoder-decoder stages, DenoMamba employs a spatial SSM module to encode
spatial context and a novel channel SSM module equipped with a secondary gated
convolution network to encode latent features of channel context at each stage.
Feature maps from the two modules are then consolidated with low-level input
features via a convolution fusion module (CFM). Comprehensive experiments on
LDCT datasets with 25\% and 10\% dose reduction demonstrate that DenoMamba
outperforms state-of-the-art denoisers with average improvements of 1.4dB PSNR,
1.1% SSIM, and 1.6% RMSE in recovered image quality.

摘要：低劑量電腦斷層掃描 (LDCT) 降低與輻射有關的潛在風險，同時依賴進階的去噪演算法，以維持重建影像的診斷品質。LDCT 去噪的主流典範基於神經網路模型，該模型會學習資料驅動的影像先驗，以區分劑量降低所產生的雜訊與底層組織訊號。自然而然，這些先驗的保真度取決於模型擷取 CT 影像中廣泛脈絡特徵的能力。較早的卷積神經網路 (CNN) 非常擅長有效擷取短程空間脈絡，但其有限的感受野會降低對較長距離交互作用的敏感度。儘管基於自我注意機制的Transformer最近被提出用於增加對長程脈絡的敏感度，但由於模型複雜度提高，它們可能會因次佳效能和效率而受限，特別是對於高解析度 CT 影像。為了高品質復原 LDCT 影像，我們在此介紹 DenoMamba，這是一種基於狀態空間模型 (SSM) 的創新去噪方法，它能有效擷取醫學影像中的短程和長程脈絡。DenoMamba 採用具有編碼器-解碼器階段的沙漏架構，並使用空間 SSM 模組來編碼空間脈絡，以及配備次要閘控卷積網路的新型通道 SSM 模組，以編碼各個階段中通道脈絡的潛在特徵。然後透過卷積融合模組 (CFM) 將兩個模組中的特徵圖與低階輸入特徵合併。在劑量降低 25% 和 10% 的 LDCT 資料集上進行的全面實驗證明，DenoMamba 的效能優於最先進的去噪器，在復原影像品質方面平均改善了 1.4dB PSNR、1.1% SSIM 和 1.6% RMSE。

##### **AutoPET III Challenge: Tumor Lesion Segmentation using ResEnc-Model Ensemble**
2409.13779v1 by Tanya Chutani, Saikiran Bonthu, Pranab Samanta, Nitin Singhal

Positron Emission Tomography (PET) /Computed Tomography (CT) is crucial for
diagnosing, managing, and planning treatment for various cancers. Developing
reliable deep learning models for the segmentation of tumor lesions in PET/CT
scans in a multi-tracer multicenter environment, is a critical area of
research. Different tracers, such as Fluorodeoxyglucose (FDG) and
Prostate-Specific Membrane Antigen (PSMA), have distinct physiological uptake
patterns and data from different centers often vary in terms of acquisition
protocols, scanner types, and patient populations. Because of this variability,
it becomes more difficult to design reliable segmentation algorithms and
generalization techniques due to variations in image quality and lesion
detectability. To address this challenge, We trained a 3D Residual encoder
U-Net within the no new U-Net framework, aiming to generalize the performance
of automatic lesion segmentation of whole body PET/CT scans, across different
tracers and clinical sites. Further, We explored several preprocessing
techniques and ultimately settled on using the Total Segmentator to crop our
training data. Additionally, we applied resampling during this process. During
inference, we leveraged test-time augmentations and other post-processing
techniques to enhance tumor lesion segmentation. Our team currently hold the
top position in the Auto-PET III challenge and outperformed the challenge
baseline model in the preliminary test set with Dice score of 0.9627.

摘要：正子斷層掃描 (PET)/電腦斷層掃描 (CT) 對於診斷、管理和規劃各種癌症的治療至關重要。開發可靠的深度學習模型，用於在多示蹤劑多中心環境中對 PET/CT 掃描中的腫瘤病灶進行分割，是一個重要的研究領域。不同的示蹤劑，例如氟代氧葡萄糖 (FDG) 和前列腺特異性膜抗原 (PSMA)，具有不同的生理攝取模式，來自不同中心的數據通常在採集協議、掃描儀類型和患者群體方面有所不同。由於這種變異性，由於圖像質量和病灶檢測能力的差異，設計可靠的分割演算法和泛化技術變得更加困難。為了應對這一挑戰，我們在沒有新的 U-Net 框架內訓練了一個 3D 殘差編碼器 U-Net，旨在概括全身上下 PET/CT 掃描自動病灶分割的性能，跨越不同的示蹤劑和臨床部位。此外，我們探索了幾種預處理技術，最終決定使用 Total Segmentator 來裁剪我們的訓練數據。此外，我們在此過程中應用重新採樣。在推理期間，我們利用測試時擴充和其他後處理技術來增強腫瘤病灶分割。我們的團隊目前在 Auto-PET III 挑戰中排名第一，並在預賽測試集中以 0.9627 的 Dice 分數優於挑戰基準模型。

##### **HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation**
2409.13038v1 by Julián N. Acosta, Xiaoman Zhang, Siddhant Dogra, Hong-Yu Zhou, Seyedmehdi Payabvash, Guido J. Falcone, Eric K. Oermann, Pranav Rajpurkar

We present Head CT Ontology Normalized Evaluation (HeadCT-ONE), a metric for
evaluating head CT report generation through ontology-normalized entity and
relation extraction. HeadCT-ONE enhances current information extraction derived
metrics (such as RadGraph F1) by implementing entity normalization through
domain-specific ontologies, addressing radiological language variability.
HeadCT-ONE compares normalized entities and relations, allowing for
controllable weighting of different entity types or specific entities. Through
experiments on head CT reports from three health systems, we show that
HeadCT-ONE's normalization and weighting approach improves the capture of
semantically equivalent reports, better distinguishes between normal and
abnormal reports, and aligns with radiologists' assessment of clinically
significant errors, while offering flexibility to prioritize specific aspects
of report content. Our results demonstrate how HeadCT-ONE enables more
flexible, controllable, and granular automated evaluation of head CT reports.

摘要：我們提出 Head CT Ontology Normalized Evaluation (HeadCT-ONE)，一種透過 ontology 正規化實體和關係萃取來評估頭部 CT 報告產生的指標。HeadCT-ONE 透過領域特定 ontology 實作實體正規化，來提升目前資訊萃取衍生的指標（例如 RadGraph F1），以解決放射科語言的可變性。HeadCT-ONE 比較正規化實體和關係，允許控制不同實體類型或特定實體的加權。透過對來自三個醫療系統的頭部 CT 報告進行實驗，我們展示 HeadCT-ONE 的正規化和加權方法改進了語義等效報告的擷取，更好地區分正常和異常報告，並與放射科醫師對臨床重大錯誤的評估保持一致，同時提供優先考慮報告內容特定層面的彈性。我們的結果展示 HeadCT-ONE 如何讓頭部 CT 報告的自動化評估更靈活、可控和細緻。

##### **iCost: A Novel Instance Complexity Based Cost-Sensitive Learning Framework for Imbalanced Classification**
2409.13007v1 by Asif Newaz, Asif Ur Rahman Adib, Taskeed Jabid

Class imbalance in data presents significant challenges for classification
tasks. It is fairly common and requires careful handling to obtain desirable
performance. Traditional classification algorithms become biased toward the
majority class. One way to alleviate the scenario is to make the classifiers
cost-sensitive. This is achieved by assigning a higher misclassification cost
to minority-class instances. One issue with this implementation is that all the
minority-class instances are treated equally, and assigned with the same
penalty value. However, the learning difficulties of all the instances are not
the same. Instances that are located near the decision boundary are harder to
classify, whereas those further away are easier. Without taking into
consideration the instance complexity and naively weighting all the
minority-class samples uniformly, results in an unwarranted bias and
consequently, a higher number of misclassifications of the majority-class
instances. This is undesirable and to overcome the situation, we propose a
novel instance complexity-based cost-sensitive approach in this study. We first
categorize all the minority-class instances based on their difficulty level and
then the instances are penalized accordingly. This ensures a more equitable
instance weighting and prevents excessive penalization. The performance of the
proposed approach is tested on 66 imbalanced datasets against the traditional
cost-sensitive learning frameworks and a significant improvement in performance
is noticeable, demonstrating the effectiveness of our method.

摘要：資料中的類別不平衡對於分類任務來說是一項重大的挑戰。這相當普遍，需要小心處理才能獲得理想的效能。傳統的分類演算法會偏向多數類別。一種緩解這種情況的方法是讓分類器對成本敏感。這是透過對少數類別的實例指定較高的錯誤分類成本來達成。這種實作的一個問題是，所有少數類別的實例都受到平等對待，並指定相同的懲罰值。然而，所有實例的學習難度並不相同。位於決策邊界附近的實例較難分類，而較遠的實例則較容易。在沒有考慮實例複雜性並天真地對所有少數類別樣本進行均勻加權的情況下，會導致不合理的偏差，進而導致對多數類別實例的誤分類數量增加。這是不可取的，為了克服這種情況，我們在這項研究中提出了一種新的基於實例複雜性的成本敏感方法。我們首先根據少數類別實例的難度等級對它們進行分類，然後對實例進行相應的懲罰。這確保了更公平的實例加權，並防止過度懲罰。所提出的方法的效能已在 66 個不平衡的資料集上針對傳統的成本敏感學習架構進行測試，並且效能有顯著的提升，證明了我們方法的有效性。

##### **Fuzzy Rule based Intelligent Cardiovascular Disease Prediction using Complex Event Processing**
2409.15372v1 by Shashi Shekhar Kumar, Anurag Harsh, Ritesh Chandra, Sonali Agarwal

Cardiovascular disease (CVDs) is a rapidly rising global concern due to
unhealthy diets, lack of physical activity, and other factors. According to the
World Health Organization (WHO), primary risk factors include elevated blood
pressure, glucose, blood lipids, and obesity. Recent research has focused on
accurate and timely disease prediction to reduce risk and fatalities, often
relying on predictive models trained on large datasets, which require intensive
training. An intelligent system for CVDs patients could greatly assist in
making informed decisions by effectively analyzing health parameters. Complex
Event Processing (CEP) has emerged as a valuable method for solving real-time
challenges by aggregating patterns of interest and their causes and effects on
end users. In this work, we propose a fuzzy rule-based system for monitoring
clinical data to provide real-time decision support. We designed fuzzy rules
based on clinical and WHO standards to ensure accurate predictions. Our
integrated approach uses Apache Kafka and Spark for data streaming, and the
Siddhi CEP engine for event processing. Additionally, we pass numerous
cardiovascular disease-related parameters through CEP engines to ensure fast
and reliable prediction decisions. To validate the effectiveness of our
approach, we simulated real-time, unseen data to predict cardiovascular
disease. Using synthetic data (1000 samples), we categorized it into "Very Low
Risk, Low Risk, Medium Risk, High Risk, and Very High Risk." Validation results
showed that 20% of samples were categorized as very low risk, 15-45% as low
risk, 35-65% as medium risk, 55-85% as high risk, and 75% as very high risk.

摘要：心血管疾病 (CVD) 由于不健康的饮食、缺乏身体活动和其他因素，正迅速成为全球关注的问题。根据世界卫生组织 (WHO) 的说法，主要危险因素包括血压升高、葡萄糖、血脂和肥胖。最近的研究重点在于准确及时地预测疾病，以降低风险和死亡率，通常依赖于在大数据集上训练的预测模型，这需要大量的训练。一个针对心血管疾病患者的智能系统可以通过有效分析健康参数来极大地帮助做出明智的决策。复杂事件处理 (CEP) 已成为通过聚合感兴趣的模式及其对最终用户的影响和原因来解决实时挑战的宝贵方法。在这项工作中，我们提出了一种基于模糊规则的系统来监控临床数据，以提供实时决策支持。我们基于临床和 WHO 标准设计了模糊规则，以确保准确的预测。我们的集成方法使用 Apache Kafka 和 Spark 进行数据流式传输，并使用 Siddhi CEP 引擎进行事件处理。此外，我们通过 CEP 引擎传递了许多与心血管疾病相关的参数，以确保快速且可靠的预测决策。为了验证我们方法的有效性，我们模拟了实时、不可见的数据来预测心血管疾病。使用合成数据（1000 个样本），我们将它们分类为“极低风险、低风险、中风险、高风险和极高风险”。验证结果表明，20% 的样本被归类为极低风险，15-45% 为低风险，35-65% 为中风险，55-85% 为高风险，75% 为极高风险。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences**
2409.13000v1 by Ricky Sahu, Eric Marriott, Ethan Siegel, David Wagner, Flore Uzan, Troy Yang, Asim Javed

With U.S. healthcare spending approaching $5T (NHE Fact Sheet 2024), and 25%
of it estimated to be wasteful (Waste in the US the health care system:
estimated costs and potential for savings, n.d.), the need to better predict
risk and optimal patient care is evermore important. This paper introduces the
Large Medical Model (LMM), a generative pre-trained transformer (GPT) designed
to guide and predict the broad facets of patient care and healthcare
administration. The model is trained on medical event sequences from over 140M
longitudinal patient claims records with a specialized vocabulary built from
medical terminology systems and demonstrates a superior capability to forecast
healthcare costs and identify potential risk factors. Through experimentation
and validation, we showcase the LMM's proficiency in not only in cost and risk
predictions, but also in discerning intricate patterns within complex medical
conditions and an ability to identify novel relationships in patient care. The
LMM is able to improve both cost prediction by 14.1% over the best commercial
models and chronic conditions prediction by 1.9% over the best transformer
models in research predicting a broad set of conditions. The LMM is a
substantial advancement in healthcare analytics, offering the potential to
significantly enhance risk assessment, cost management, and personalized
medicine.

摘要：隨著美國醫療保健支出逼近 5 兆美元（2024 年 NHE 事實表），其中估計有 25% 是浪費的（美國醫療保健系統中的浪費：估計成本和節約潛力，無日期），因此需要更好地預測風險和最佳患者照護變得越來越重要。本文介紹了大型醫療模型 (LMM)，一種生成式預訓練轉換器 (GPT)，旨在引導和預測患者照護和醫療保健管理的廣泛面向。該模型使用超過 1.4 億個縱向患者索賠記錄中的醫療事件序列進行訓練，並使用從醫療術語系統建立的專業詞彙，並展示出預測醫療保健成本和識別潛在風險因子的卓越能力。透過實驗和驗證，我們展示了 LMM 不僅在成本和風險預測方面具有專業知識，還展示了在複雜醫療狀況中辨別複雜模式和識別患者照護中新關係的能力。LMM 能夠將成本預測提高 14.1%，優於最佳商業模型，並將慢性病預測提高 1.9%，優於研究中預測廣泛病況的最佳轉換器模型。LMM 是醫療保健分析的一項重大進展，具有顯著提升風險評估、成本管理和個人化醫療的潛力。

##### **Fine Tuning Large Language Models for Medicine: The Role and Importance of Direct Preference Optimization**
2409.12741v2 by Thomas Savage, Stephen Ma, Abdessalem Boukil, Vishwesh Patel, Ekanath Rangan, Ivan Rodriguez, Jonathan H Chen

Large Language Model (LLM) fine tuning is underutilized in the field of
medicine. Two of the most common methods of fine tuning are Supervised Fine
Tuning (SFT) and Direct Preference Optimization (DPO), but there is little
guidance informing users when to use either technique. In this investigation,
we compare the performance of SFT and DPO for five common natural language
tasks in medicine: Classification with text data, Classification with numeric
data, Clinical Reasoning, Summarization, and Clinical Triage. We find that SFT
alone is sufficient for Classification with text data, whereas DPO improves
performance for the more complex tasks of Clinical Reasoning, Summarization and
Clinical Triage. Our results establish the role and importance of DPO fine
tuning within medicine, and consequently call attention to current software
gaps that prevent widespread deployment of this technique.

摘要：大型語言模型 (LLM) 微調在醫學領域的使用率不足。微調最常見的兩種方法是監督式微調 (SFT) 和直接偏好最佳化 (DPO)，但鮮少有指南告訴使用者何時使用這兩種技術。在此研究中，我們比較了 SFT 和 DPO 在醫學中五項常見自然語言任務的表現：文字資料分類、數字資料分類、臨床推理、摘要和臨床分流。我們發現，僅 SFT 就足以應付文字資料分類，而 DPO 則能提升臨床推理、摘要和臨床分流等較複雜任務的表現。我們的結果確立了 DPO 微調在醫學中的角色和重要性，並因此提醒目前軟體的不足之處，這些不足之處妨礙了此技術的廣泛部署。

##### **SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference**
2409.12467v1 by Zhen Chen, Xingjian Luo, Jinlin Wu, Long Bai, Zhen Lei, Hongliang Ren, Sebastien Ourselin, Hongbin Liu

Surgical phase recognition is critical for assisting surgeons in
understanding surgical videos. Existing studies focused more on online surgical
phase recognition, by leveraging preceding frames to predict the current frame.
Despite great progress, they formulated the task as a series of frame-wise
classification, which resulted in a lack of global context of the entire
procedure and incoherent predictions. Moreover, besides online analysis,
accurate offline surgical phase recognition is also in significant clinical
need for retrospective analysis, and existing online algorithms do not fully
analyze the entire video, thereby limiting accuracy in offline analysis. To
overcome these challenges and enhance both online and offline inference
capabilities, we propose a universal Surgical Phase Localization Network, named
SurgPLAN++, with the principle of temporal detection. To ensure a global
understanding of the surgical procedure, we devise a phase localization
strategy for SurgPLAN++ to predict phase segments across the entire video
through phase proposals. For online analysis, to generate high-quality phase
proposals, SurgPLAN++ incorporates a data augmentation strategy to extend the
streaming video into a pseudo-complete video through mirroring,
center-duplication, and down-sampling. For offline analysis, SurgPLAN++
capitalizes on its global phase prediction framework to continuously refine
preceding predictions during each online inference step, thereby significantly
improving the accuracy of phase recognition. We perform extensive experiments
to validate the effectiveness, and our SurgPLAN++ achieves remarkable
performance in both online and offline modes, which outperforms
state-of-the-art methods. The source code is available at
https://github.com/lxj22/SurgPLAN-Plus.

摘要：手術階段辨識對於協助外科醫生理解手術影片至關重要。現有研究較著重於線上手術階段辨識，藉由利用前一幀來預測當前幀。儘管進展顯著，但他們將任務制定為一系列逐幀分類，這導致缺乏整個過程的整體脈絡和不連貫的預測。此外，除了線上分析之外，精準的離線手術階段辨識在回顧性分析中也具有重要的臨床需求，而現有的線上演算法並未完全分析整個影片，因此限制了離線分析的準確性。為了克服這些挑戰並增強線上和離線推論能力，我們提出了一個名為 SurgPLAN++ 的通用手術階段定位網路，其原理為時間偵測。為了確保對手術過程有整體的了解，我們為 SurgPLAN++ 設計了一個階段定位策略，以透過階段提案預測整個影片中的階段區段。對於線上分析，為了產生高品質的階段提案，SurgPLAN++ 結合了一個資料擴充策略，透過鏡像、中心複製和降採樣將串流影片延伸為一個偽完成影片。對於離線分析，SurgPLAN++ 利用其全球階段預測架構，在每個線上推論步驟中持續改善前一預測，從而顯著提高階段辨識的準確性。我們進行了廣泛的實驗來驗證其有效性，而我們的 SurgPLAN++ 在線上和離線模式下都達到了顯著的效能，優於最先進的方法。原始程式碼可在 https://github.com/lxj22/SurgPLAN-Plus 取得。

##### **FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention Scaling**
2409.12454v1 by Enze Shi, Kui Zhao, Qilong Yuan, Jiaqi Wang, Huawen Hu, Sigang Yu, Shu Zhang

Electroencephalography (EEG) is a vital tool to measure and record brain
activity in neuroscience and clinical applications, yet its potential is
constrained by signal heterogeneity, low signal-to-noise ratios, and limited
labeled datasets. In this paper, we propose FoME (Foundation Model for EEG), a
novel approach using adaptive temporal-lateral attention scaling to address
above-mentioned challenges. FoME is pre-trained on a diverse 1.7TB dataset of
scalp and intracranial EEG recordings, comprising 745M parameters trained for
1,096k steps. Our model introduces two key innovations: a time-frequency fusion
embedding technique and an adaptive time-lateral attention scaling (ATLAS)
mechanism. These components synergistically capture complex temporal and
spectral EEG dynamics, enabling FoME to adapt to varying patterns across
diverse data streams and facilitate robust multi-channel modeling. Evaluations
across four downstream tasks demonstrate FoME's superior performance in
classification and forecasting applications, consistently achieving
state-of-the-art results. To conclude, FoME establishes a new paradigm for EEG
analysis, offering a versatile foundation that advances brain-computer
interfaces, clinical diagnostics, and cognitive research across neuroscience
and related fields. Our code will be available at
https://github.com/1061413241/FoME.

摘要：腦電圖（EEG）是神經科學和臨床應用中用於測量和記錄大腦活動的重要工具，但其潛力受到訊號異質性、低信噪比和標籤資料集有限的限制。在本文中，我們提出 FoME（EEG 基礎模型），一種使用適應性時間側向注意力調整來解決上述挑戰的新方法。FoME 在一個多樣化的 1.7TB 頭皮和顱內 EEG 紀錄資料集上進行預訓練，包含 7.45 億個參數，訓練了 1,096k 步驟。我們的模型引入了兩項關鍵創新：時頻融合嵌入技術和適應性時間側向注意力調整（ATLAS）機制。這些組成部分協同捕捉複雜的時間和頻譜 EEG 動態，使 FoME 能夠適應不同資料流中的不同模式，並促進穩健的多通道建模。在四項下游任務中的評估證明了 FoME 在分類和預測應用中的優異效能，始終達到最先進的結果。總之，FoME 為 EEG 分析建立了一個新的範例，提供了一個通用的基礎，推動了腦電腦介面、臨床診斷和神經科學及相關領域的認知研究。我們的程式碼將在 https://github.com/1061413241/FoME 上提供。

##### **Domain Generalization for Endoscopic Image Segmentation by Disentangling Style-Content Information and SuperPixel Consistency**
2409.12450v1 by Mansoor Ali Teevno, Rafael Martinez-Garcia-Pena, Gilberto Ochoa-Ruiz, Sharib Ali

Frequent monitoring is necessary to stratify individuals based on their
likelihood of developing gastrointestinal (GI) cancer precursors. In clinical
practice, white-light imaging (WLI) and complementary modalities such as
narrow-band imaging (NBI) and fluorescence imaging are used to assess risk
areas. However, conventional deep learning (DL) models show degraded
performance due to the domain gap when a model is trained on one modality and
tested on a different one. In our earlier approach, we used a superpixel-based
method referred to as "SUPRA" to effectively learn domain-invariant information
using color and space distances to generate groups of pixels. One of the main
limitations of this earlier work is that the aggregation does not exploit
structural information, making it suboptimal for segmentation tasks, especially
for polyps and heterogeneous color distributions. Therefore, in this work, we
propose an approach for style-content disentanglement using instance
normalization and instance selective whitening (ISW) for improved domain
generalization when combined with SUPRA. We evaluate our approach on two
datasets: EndoUDA Barrett's Esophagus and EndoUDA polyps, and compare its
performance with three state-of-the-art (SOTA) methods. Our findings
demonstrate a notable enhancement in performance compared to both baseline and
SOTA methods across the target domain data. Specifically, our approach
exhibited improvements of 14%, 10%, 8%, and 18% over the baseline and three
SOTA methods on the polyp dataset. Additionally, it surpassed the second-best
method (EndoUDA) on the Barrett's Esophagus dataset by nearly 2%.

摘要：為了根據個人罹患胃腸道 (GI) 癌前驅病變的可能性對其進行分層，頻繁監控是必要的。在臨床實務中，白光影像 (WLI) 和補充方式（例如窄頻影像 (NBI) 和螢光影像）用於評估風險區域。然而，當模型在一個方式上訓練並在不同的方式上測試時，傳統深度學習 (DL) 模型會因為領域差距而顯示出降低的效能。在我們之前的方法中，我們使用稱為「SUPRA」的超像素為基礎的方法，使用顏色和空間距離有效地學習領域不變資訊以產生像素群組。這項早期工作的其中一項主要限制是，聚合並未利用結構資訊，這使得它不適合分割任務，特別是對於息肉和異質性顏色分佈。因此，在這項工作中，我們提出一個使用實例正規化和實例選擇性白化 (ISW) 進行風格內容解開的方法，以在與 SUPRA 結合時改善領域概化。我們在兩個資料集上評估我們的方法：EndoUDA Barrett 食道和 EndoUDA 息肉，並將其效能與三種最先進 (SOTA) 方法進行比較。我們的研究結果顯示，與目標領域資料上的基線和 SOTA 方法相比，效能有顯著的提升。具體來說，我們的方法在息肉資料集上比基線和三種 SOTA 方法分別提升了 14%、10%、8% 和 18%。此外，它在 Barrett 食道資料集上比第二好的方法 (EndoUDA) 高出近 2%。

##### **Bundle Fragments into a Whole: Mining More Complete Clusters via Submodular Selection of Interesting webpages for Web Topic Detection**
2409.12380v1 by Junbiao Pang, Anjing Hu, Qingming Huang

Organizing interesting webpages into hot topics is one of key steps to
understand the trends of multimodal web data. A state-of-the-art solution is
firstly to organize webpages into a large volume of multi-granularity topic
candidates; hot topics are further identified by estimating their
interestingness. However, these topic candidates contain a large number of
fragments of hot topics due to both the inefficient feature representations and
the unsupervised topic generation. This paper proposes a bundling-refining
approach to mine more complete hot topics from fragments. Concretely, the
bundling step organizes the fragment topics into coarse topics; next, the
refining step proposes a submodular-based method to refine coarse topics in a
scalable approach. The propose unconventional method is simple, yet powerful by
leveraging submodular optimization, our approach outperforms the traditional
ranking methods which involve the careful design and complex steps. Extensive
experiments demonstrate that the proposed approach surpasses the
state-of-the-art method (i.e., latent Poisson deconvolution Pang et al. (2016))
20% accuracy and 10% one on two public data sets, respectively.

摘要：將有趣的網頁整理成熱門話題是了解多模態網路資料趨勢的關鍵步驟之一。最先進的解決方案首先是將網頁整理成大量的多粒度主題候選者；熱門話題進一步透過評估其趣味性來識別。然而，這些主題候選者包含大量的熱門話題片段，這是由於特徵表徵效率不彰和非監督式主題產生。本文提出一個成束精煉方法，從片段中挖掘出更完整的熱門話題。具體來說，成束步驟將片段主題整理成粗略主題；接著，精煉步驟提出一個基於次模組的方法，以可擴充的方式精煉粗略主題。所提出的非傳統方法很簡單，但透過利用次模組最佳化卻很強大，我們的做法優於涉及謹慎設計和複雜步驟的傳統排名方法。廣泛的實驗證明，所提出的方法超越了最先進的方法（即潛在的 Poisson 反摺疊 Pang 等人 (2016)）在兩個公開資料集上分別提升了 20% 的準確度和 10% 的一對一。

##### **Extracting Memorized Training Data via Decomposition**
2409.12367v1 by Ellen Su, Anu Vellore, Amy Chang, Raffaele Mura, Blaine Nelson, Paul Kassianik, Amin Karbasi

The widespread use of Large Language Models (LLMs) in society creates new
information security challenges for developers, organizations, and end-users
alike. LLMs are trained on large volumes of data, and their susceptibility to
reveal the exact contents of the source training datasets poses security and
safety risks. Although current alignment procedures restrict common risky
behaviors, they do not completely prevent LLMs from leaking data. Prior work
demonstrated that LLMs may be tricked into divulging training data by using
out-of-distribution queries or adversarial techniques. In this paper, we
demonstrate a simple, query-based decompositional method to extract news
articles from two frontier LLMs. We use instruction decomposition techniques to
incrementally extract fragments of training data. Out of 3723 New York Times
articles, we extract at least one verbatim sentence from 73 articles, and over
20% of verbatim sentences from 6 articles. Our analysis demonstrates that this
method successfully induces the LLM to generate texts that are reliable
reproductions of news articles, meaning that they likely originate from the
source training dataset. This method is simple, generalizable, and does not
fine-tune or change the production model. If replicable at scale, this training
data extraction methodology could expose new LLM security and safety
vulnerabilities, including privacy risks and unauthorized data leaks. These
implications require careful consideration from model development to its
end-use.

摘要：大型語言模型（LLM）在社會中的廣泛使用為開發人員、組織和最終用戶創造了新的資訊安全挑戰。LLM 在大量資料上訓練，它們容易揭露原始訓練資料集的精確內容，這會造成安全和隱私風險。儘管目前校準程序限制了常見的風險行為，但它們並不能完全防止 LLM 洩漏資料。先前的研究表明，LLM 可能被誘騙通過使用非分佈查詢或對抗技術來洩露訓練資料。在本文中，我們展示了一個簡單的、基於查詢的分解方法，從兩個前沿 LLM 中提取新聞文章。我們使用指令分解技術逐步提取訓練資料片段。在 3723 篇紐約時報文章中，我們從 73 篇文章中至少提取了一個逐字逐句的句子，並且從 6 篇文章中提取了 20% 以上的逐字逐句句子。我們的分析表明，此方法成功地誘導 LLM 生成可靠的新聞文章重現文字，這意味著它們很可能來自原始訓練資料集。此方法簡單、可概括，並且不會微調或更改生產模型。如果可以大規模複製，此訓練資料提取方法可能會暴露新的 LLM 安全和隱私漏洞，包括隱私風險和未經授權的資料洩漏。這些影響需要從模型開發到最終使用仔細考量。

##### **Axial Attention Transformer Networks: A New Frontier in Breast Cancer Detection**
2409.12347v1 by Weijie He, Runyuan Bao, Yiru Cang, Jianjun Wei, Yang Zhang, Jiacheng Hu

This paper delves into the challenges and advancements in the field of
medical image segmentation, particularly focusing on breast cancer diagnosis.
The authors propose a novel Transformer-based segmentation model that addresses
the limitations of traditional convolutional neural networks (CNNs), such as
U-Net, in accurately localizing and segmenting small lesions within breast
cancer images. The model introduces an axial attention mechanism to enhance the
computational efficiency and address the issue of global contextual information
that is often overlooked by CNNs. Additionally, the paper discusses
improvements tailored to the small dataset challenge, including the
incorporation of relative position information and a gated axial attention
mechanism to refine the model's focus on relevant features. The proposed model
aims to significantly improve the segmentation accuracy of breast cancer
images, offering a more efficient and effective tool for computer-aided
diagnosis.

摘要：本文探討了醫療影像分割領域的挑戰和進展，特別著重於乳癌診斷。作者提出了一個基於 Transformer 的新分割模型，它解決了傳統卷積神經網路 (CNN) 的限制，例如 U-Net 在準確定位和分割乳癌影像中小的病灶。該模型引入了一個軸向注意力機制來增強運算效率並解決 CNN 經常忽略的全局上下文資訊問題。此外，本文討論了針對小資料集挑戰量身打造的改進，包括整合相對位置資訊和門控軸向注意力機制，以改善模型對相關特徵的關注。所提出的模型旨在顯著提高乳癌影像的分割準確度，為電腦輔助診斷提供更有效率且更有效的工具。

##### **Deep vessel segmentation with joint multi-prior encoding**
2409.12334v1 by Amine Sadikine, Bogdan Badic, Enzo Ferrante, Vincent Noblet, Pascal Ballet, Dimitris Visvikis, Pierre-Henri Conze

The precise delineation of blood vessels in medical images is critical for
many clinical applications, including pathology detection and surgical
planning. However, fully-automated vascular segmentation is challenging because
of the variability in shape, size, and topology. Manual segmentation remains
the gold standard but is time-consuming, subjective, and impractical for
large-scale studies. Hence, there is a need for automatic and reliable
segmentation methods that can accurately detect blood vessels from medical
images. The integration of shape and topological priors into vessel
segmentation models has been shown to improve segmentation accuracy by offering
contextual information about the shape of the blood vessels and their spatial
relationships within the vascular tree. To further improve anatomical
consistency, we propose a new joint prior encoding mechanism which incorporates
both shape and topology in a single latent space. The effectiveness of our
method is demonstrated on the publicly available 3D-IRCADb dataset. More
globally, the proposed approach holds promise in overcoming the challenges
associated with automatic vessel delineation and has the potential to advance
the field of deep priors encoding.

摘要：在醫療影像中精確描繪血管對於許多臨床應用至關重要，包括病理偵測和手術規劃。然而，全自動血管分割具有挑戰性，因為形狀、大小和拓撲結構的變異性。手動分割仍然是黃金標準，但耗時、主觀且不適用於大規模研究。因此，需要自動且可靠的分割方法，可以從醫療影像中精確偵測血管。已證明將形狀和拓撲先驗整合到血管分割模型中，可以透過提供有關血管形狀及其在血管樹中的空間關係的脈絡資訊來提高分割準確度。為了進一步提高解剖一致性，我們提出了一種新的聯合先驗編碼機制，它在單一的潛在空間中整合了形狀和拓撲。我們的方法的有效性在公開的 3D-IRCADb 資料集上得到證明。更普遍地說，所提出的方法有望克服與自動血管描繪相關的挑戰，並有可能推進深度先驗編碼領域。

##### **MedCodER: A Generative AI Assistant for Medical Coding**
2409.15368v1 by Krishanu Das Baksi, Elijah Soba, John J. Higgins, Ravi Saini, Jaden Wood, Jane Cook, Jack Scott, Nirmala Pudota, Tim Weninger, Edward Bowen, Sanmitra Bhattacharya

Medical coding is essential for standardizing clinical data and communication
but is often time-consuming and prone to errors. Traditional Natural Language
Processing (NLP) methods struggle with automating coding due to the large label
space, lengthy text inputs, and the absence of supporting evidence annotations
that justify code selection. Recent advancements in Generative Artificial
Intelligence (AI) offer promising solutions to these challenges. In this work,
we introduce MedCodER, a Generative AI framework for automatic medical coding
that leverages extraction, retrieval, and re-ranking techniques as core
components. MedCodER achieves a micro-F1 score of 0.60 on International
Classification of Diseases (ICD) code prediction, significantly outperforming
state-of-the-art methods. Additionally, we present a new dataset containing
medical records annotated with disease diagnoses, ICD codes, and supporting
evidence texts (https://doi.org/10.5281/zenodo.13308316). Ablation tests
confirm that MedCodER's performance depends on the integration of each of its
aforementioned components, as performance declines when these components are
evaluated in isolation.

摘要：醫療編碼對於標準化臨床資料和溝通至關重要，但通常很耗時且容易出錯。傳統的自然語言處理 (NLP) 方法由於標籤空間大、文字輸入長且缺乏證明編碼選擇的佐證註解，因此難以自動化編碼。生成式人工智慧 (AI) 的最新進展為這些挑戰提供了有希望的解決方案。在這項工作中，我們介紹了 MedCodER，這是一個用於自動醫療編碼的生成式 AI 框架，它利用萃取、檢索和重新排序技術作為核心組成部分。MedCodER 在國際疾病分類 (ICD) 代碼預測上達到了 0.60 的微 F1 分數，顯著優於最先進的方法。此外，我們還提供了一個新的資料集，其中包含註有疾病診斷、ICD 代碼和佐證文字的新醫療記錄 (https://doi.org/10.5281/zenodo.13308316)。消融測試證實，MedCodER 的效能取決於其上述各組成部分的整合，因為當這些組成部分被孤立評估時，效能會下降。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政索賠資料的潛力，結合進階機器學習和深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析由一家大型健康保險組織提供的十年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）開發多個觀察時段的預測模型。我們的研究結果表明，LSTM 模型，特別是具有 24 個月的觀察時段，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 加法解釋 (SHAP) 分析來增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政索賠資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**
2409.11817v1 by Shaojie Li, Zhaoshuo Diao

The recent development of deep learning large models in medicine shows
remarkable performance in medical image analysis and diagnosis, but their large
number of parameters causes memory and inference latency challenges. Knowledge
distillation offers a solution, but the slide-level gradients cannot be
backpropagated for student model updates due to high-resolution pathological
images and slide-level labels. This study presents an Efficient Fine-tuning on
Compressed Models (EFCM) framework with two stages: unsupervised feature
distillation and fine-tuning. In the distillation stage, Feature Projection
Distillation (FPD) is proposed with a TransScan module for adaptive receptive
field adjustment to enhance the knowledge absorption capability of the student
model. In the slide-level fine-tuning stage, three strategies (Reuse CLAM,
Retrain CLAM, and End2end Train CLAM (ETC)) are compared. Experiments are
conducted on 11 downstream datasets related to three large medical models:
RETFound for retina, MRM for chest X-ray, and BROW for histopathology. The
experimental results demonstrate that the EFCM framework significantly improves
accuracy and efficiency in handling slide-level pathological image problems,
effectively addressing the challenges of deploying large medical models.
Specifically, it achieves a 4.33% increase in ACC and a 5.2% increase in AUC
compared to the large model BROW on the TCGA-NSCLC and TCGA-BRCA datasets. The
analysis of model inference efficiency highlights the high efficiency of the
distillation fine-tuning method.

摘要：<paragraph>最近在醫學領域中深度學習大型模型的發展，在醫學影像分析和診斷方面展現了卓越的表現，但其龐大的參數量卻導致記憶體和推論延遲的挑戰。知識蒸餾提供了一種解決方案，但由於高解析度的病理影像和幻燈片層級標籤，幻燈片層級的梯度無法反向傳播以更新學生模型。本研究提出了一個壓縮模型的有效微調 (EFCM) 架構，包含兩個階段：無監督特徵蒸餾和微調。在蒸餾階段，提出特徵投影蒸餾 (FPD) 與 TransScan 模組，以進行適應性感受野調整，以增強學生模型的知識吸收能力。在幻燈片層級微調階段，比較了三種策略（重複使用 CLAM、重新訓練 CLAM 和端對端訓練 CLAM (ETC)）。針對與三個大型醫學模型相關的 11 個下游資料集進行了實驗：針對視網膜的 RETFound、針對胸部 X 光的 MRM 和針對組織病理學的 BROW。實驗結果表明，EFCM 架構顯著提升了處理幻燈片層級病理影像問題的準確性和效率，有效應對了部署大型醫學模型的挑戰。具體來說，與大型模型 BROW 相比，它在 TCGA-NSCLC 和 TCGA-BRCA 資料集上分別提升了 4.33% 的 ACC 和 5.2% 的 AUC。模型推論效率的分析突出了蒸餾微調方法的高效率。</paragraph>

##### **Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**
2409.11686v1 by Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari

Abdominal computed tomography (CT) scans are frequently performed in clinical
settings. Opportunistic CT involves repurposing routine CT images to extract
diagnostic information and is an emerging tool for detecting underdiagnosed
conditions such as sarcopenia, hepatic steatosis, and ascites. This study
utilizes deep learning methods to promote accurate diagnosis and clinical
documentation. We analyze 2,674 inpatient CT scans to identify discrepancies
between imaging phenotypes (characteristics derived from opportunistic CT
scans) and their corresponding documentation in radiology reports and ICD
coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans
diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively)
through either opportunistic imaging or radiology reports were ICD-coded. Our
findings demonstrate opportunistic CT's potential to enhance diagnostic
precision and accuracy of risk adjustment models, offering advancements in
precision medicine.

摘要：腹部電腦斷層掃描 (CT) 在臨床環境中經常執行。機會性 CT 涉及將例行 CT 影像重新用於提取診斷資訊，並且是偵測未診斷疾病（例如肌肉減少症、肝臟脂肪變性、腹水）的新興工具。本研究利用深度學習方法促進準確診斷和臨床文件編寫。我們分析 2,674 個住院病人 CT 掃描，以找出影像表型（從機會性 CT 掃描衍生的特徵）與其在放射科報告和 ICD 編碼中對應的文件之間的差異。透過我們的分析，我們發現僅有 0.5%、3.2% 和 30.7% 的掃描被診斷為肌肉減少症、肝臟脂肪變性和腹水（分別）透過機會性影像或放射科報告進行 ICD 編碼。我們的研究結果證明了機會性 CT 增強診斷精準度和風險調整模型精確度的潛力，提供了精準醫療的進展。

##### **Agent Aggregator with Mask Denoise Mechanism for Histopathology Whole Slide Image Analysis**
2409.11664v1 by Xitong Ling, Minxi Ouyang, Yizhi Wang, Xinrui Chen, Renao Yan, Hongbo Chu, Junru Cheng, Tian Guan, Sufang Tian, Xiaoping Liu, Yonghong He

Histopathology analysis is the gold standard for medical diagnosis. Accurate
classification of whole slide images (WSIs) and region-of-interests (ROIs)
localization can assist pathologists in diagnosis. The gigapixel resolution of
WSI and the absence of fine-grained annotations make direct classification and
analysis challenging. In weakly supervised learning, multiple instance learning
(MIL) presents a promising approach for WSI classification. The prevailing
strategy is to use attention mechanisms to measure instance importance for
classification. However, attention mechanisms fail to capture inter-instance
information, and self-attention causes quadratic computational complexity. To
address these challenges, we propose AMD-MIL, an agent aggregator with a mask
denoise mechanism. The agent token acts as an intermediate variable between the
query and key for computing instance importance. Mask and denoising matrices,
mapped from agents-aggregated value, dynamically mask low-contribution
representations and eliminate noise. AMD-MIL achieves better attention
allocation by adjusting feature representations, capturing micro-metastases in
cancer, and improving interpretability. Extensive experiments on CAMELYON-16,
CAMELYON-17, TCGA-KIDNEY, and TCGA-LUNG show AMD-MIL's superiority over
state-of-the-art methods.

摘要：<paragraph>組織病理學分析是醫學診斷的金標準。準確分類全幻燈片影像 (WSI) 和感興趣區域 (ROI) 定位有助於病理學家進行診斷。WSI 的吉像素解析度和缺乏細粒度註解使得直接分類和分析具有挑戰性。在弱監督學習中，多例學習 (MIL) 為 WSI 分類提供了一種有前景的方法。普遍的策略是使用注意力機制來衡量例子的重要性以進行分類。然而，注意力機制無法捕捉例間資訊，而自注意力會導致二次計算複雜度。為了應對這些挑戰，我們提出了 AMD-MIL，一種具有遮罩去噪機制的代理聚合器。代理權杖充當查詢和鍵之間的中間變數，用於計算例子的重要性。從代理聚合值映射的遮罩和去噪矩陣，動態遮罩低貢獻表示並消除雜訊。AMD-MIL 透過調整特徵表示、捕捉癌症中的微轉移和提高可解釋性來實現更好的注意力分配。在 CAMELYON-16、CAMELYON-17、TCGA-KIDNEY 和 TCGA-LUNG 上的廣泛實驗顯示 AMD-MIL 優於最先進的方法。</paragraph>

##### **A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**
2409.11631v1 by Ari Gestetner, Buser Say

A pandemic is the spread of a disease across large regions, and can have
devastating costs to the society in terms of health, economic and social. As
such, the study of effective pandemic mitigation strategies can yield
significant positive impact on the society. A pandemic can be mathematically
described using a compartmental model, such as the Susceptible Infected Removed
(SIR) model. In this paper, we extend the solution equations of the SIR model
to a state transition model with lockdowns. We formalize a metric hybrid
planning problem based on this state transition model, and solve it using a
metric hybrid planner. We improve the runtime effectiveness of the metric
hybrid planner with the addition of valid inequalities, and demonstrate the
success of our approach both theoretically and experimentally under various
challenging settings.

摘要：流行病是指疾病在大範圍地區傳播，且可能對社會在健康、經濟和社會方面造成毀滅性的成本。因此，研究有效的流行病緩解策略可以對社會產生顯著的正面影響。流行病可以用區室模型來數學描述，例如易感者、感染者、移除者 (SIR) 模型。在本文中，我們將 SIR 模型的求解方程式擴展到帶封鎖的狀態轉換模型。我們根據此狀態轉換模型形式化了一個度量混合規劃問題，並使用度量混合規劃器來解決它。我們透過新增有效不等式來改善度量混合規劃器的執行時間效率，並在各種具有挑戰性的設定下理論上和實驗上證明了我們方法的成功。

##### **Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**
2409.11576v1 by Qingqing Wang, Chang Chang

Proton pencil beam scanning (PBS) treatment planning for head and neck (H&N)
cancers is a time-consuming and experience-demanding task where a large number
of planning objectives are involved. Deep reinforcement learning (DRL) has
recently been introduced to the planning processes of intensity-modulated
radiation therapy and brachytherapy for prostate, lung, and cervical cancers.
However, existing approaches are built upon the Q-learning framework and
weighted linear combinations of clinical metrics, suffering from poor
scalability and flexibility and only capable of adjusting a limited number of
planning objectives in discrete action spaces. We propose an automatic
treatment planning model using the proximal policy optimization (PPO) algorithm
and a dose distribution-based reward function for proton PBS treatment planning
of H&N cancers. Specifically, a set of empirical rules is used to create
auxiliary planning structures from target volumes and organs-at-risk (OARs),
along with their associated planning objectives. These planning objectives are
fed into an in-house optimization engine to generate the spot monitor unit (MU)
values. A decision-making policy network trained using PPO is developed to
iteratively adjust the involved planning objective parameters in a continuous
action space and refine the PBS treatment plans using a novel dose
distribution-based reward function. Proton H&N treatment plans generated by the
model show improved OAR sparing with equal or superior target coverage when
compared with human-generated plans. Moreover, additional experiments on liver
cancer demonstrate that the proposed method can be successfully generalized to
other treatment sites. To the best of our knowledge, this is the first
DRL-based automatic treatment planning model capable of achieving human-level
performance for H&N cancers.

摘要：質子筆狀束掃描（PBS）治療計畫的頭頸部（H&N）癌症是一個耗時且需要經驗的任務，其中涉及大量的計畫目標。深度強化學習（DRL）最近被引入強度調控放射治療和前列腺、肺和子宮頸癌的近接治療的計畫過程中。然而，現有的方法建立在 Q 學習架構和臨床指標的加權線性組合之上，存在可擴充性和靈活性差，只能在離散動作空間中調整有限數量的計畫目標。我們提出了一個使用近端策略最佳化（PPO）演算法和基於劑量分佈的獎勵函數的自動治療計畫模型，用於 H&N 癌症的質子 PBS 治療計畫。具體來說，使用一組經驗法則從目標體積和受風險器官（OAR）建立輔助計畫結構，連同它們相關的計畫目標。這些計畫目標被輸入到內部最佳化引擎中以產生點監測單位（MU）值。開發了一個使用 PPO 訓練的決策制定策略網路，以在連續動作空間中反覆調整所涉及的計畫目標參數，並使用新的基於劑量分佈的獎勵函數優化 PBS 治療計畫。與人為產生的計畫相比，模型產生的質子 H&N 治療計畫顯示出改善的 OAR 保護，同時具有相等或更好的目標覆蓋率。此外，對肝癌的額外實驗表明，所提出的方法可以成功地推廣到其他治療部位。據我們所知，這是第一個基於 DRL 的自動治療計畫模型，能夠為 H&N 癌症實現人類等級的效能。

##### **Two Stage Segmentation of Cervical Tumors using PocketNet**
2409.11456v1 by Awj Twam, Megan Jacobsen, Rachel Glenn, Ann Klopp, Aradhana M. Venkatesan, David Fuentes

Cervical cancer remains the fourth most common malignancy amongst women
worldwide.1 Concurrent chemoradiotherapy (CRT) serves as the mainstay
definitive treatment regimen for locally advanced cervical cancers and includes
external beam radiation followed by brachytherapy.2 Integral to radiotherapy
treatment planning is the routine contouring of both the target tumor at the
level of the cervix, associated gynecologic anatomy and the adjacent organs at
risk (OARs). However, manual contouring of these structures is both time and
labor intensive and associated with known interobserver variability that can
impact treatment outcomes. While multiple tools have been developed to
automatically segment OARs and the high-risk clinical tumor volume (HR-CTV)
using computed tomography (CT) images,3,4,5,6 the development of deep
learning-based tumor segmentation tools using routine T2-weighted (T2w)
magnetic resonance imaging (MRI) addresses an unmet clinical need to improve
the routine contouring of both anatomical structures and cervical cancers,
thereby increasing quality and consistency of radiotherapy planning. This work
applied a novel deep-learning model (PocketNet) to segment the cervix, vagina,
uterus, and tumor(s) on T2w MRI. The performance of the PocketNet architecture
was evaluated, when trained on data via 5-fold cross validation. PocketNet
achieved a mean Dice-Sorensen similarity coefficient (DSC) exceeding 70% for
tumor segmentation and 80% for organ segmentation. These results suggest that
PocketNet is robust to variations in contrast protocols, providing reliable
segmentation of the ROIs.

摘要：<paragraph>子宮頸癌在全球女性中仍然是第四常見的惡性腫瘤。1 同時進行的化學放射治療 (CRT) 是局部晚期子宮頸癌的主要明確治療方案，包括外部放射線治療後進行近接放射治療。2 放射治療計畫中不可或缺的是例行勾勒出子宮頸處的目標腫瘤、相關的婦科解剖結構和鄰近的危險器官 (OAR)。然而，手動勾勒這些結構既費時又費力，且與已知的觀察者間變異有關，這可能會影響治療結果。雖然已開發出多種工具，可使用電腦斷層掃描 (CT) 影像自動區隔 OAR 和高風險臨床腫瘤體積 (HR-CTV)，3、4、5、6 但使用例行 T2 加權 (T2w) 磁振造影 (MRI) 的深度學習腫瘤區隔工具的開發，解決了改善解剖結構和子宮頸癌例行勾勒的未滿足臨床需求，從而提高了放射治療計畫的品質和一致性。這項工作應用了一種新穎的深度學習模型 (PocketNet) 來區隔 T2w MRI 上的子宮頸、陰道、子宮和腫瘤。評估了 PocketNet 架構的效能，並透過 5 倍交叉驗證對資料進行訓練。PocketNet 在腫瘤區隔方面達到了平均 Dice-Sorensen 相似性係數 (DSC) 超過 70%，在器官區隔方面達到了 80%。這些結果表明 PocketNet 對對比度協定的變化具有穩健性，可提供可靠的 ROI 區隔。</paragraph>

##### **Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification**
2409.11375v1 by Fatema-E- Jannat, Sina Gholami, Jennifer I. Lim, Theodore Leng, Minhaj Nur Alam, Hamed Tabkhi

In the medical domain, acquiring large datasets poses significant challenges
due to privacy concerns. Nonetheless, the development of a robust deep-learning
model for retinal disease diagnosis necessitates a substantial dataset for
training. The capacity to generalize effectively on smaller datasets remains a
persistent challenge. The scarcity of data presents a significant barrier to
the practical implementation of scalable medical AI solutions. To address this
issue, we've combined a wide range of data sources to improve performance and
generalization to new data by giving it a deeper understanding of the data
representation from multi-modal datasets and developed a self-supervised
framework based on large language models (LLMs), SwinV2 to gain a deeper
understanding of multi-modal dataset representations, enhancing the model's
ability to extrapolate to new data for the detection of eye diseases using
optical coherence tomography (OCT) images. We adopt a two-phase training
methodology, self-supervised pre-training, and fine-tuning on a downstream
supervised classifier. An ablation study conducted across three datasets
employing various encoder backbones, without data fusion, with low data
availability setting, and without self-supervised pre-training scenarios,
highlights the robustness of our method. Our findings demonstrate consistent
performance across these diverse conditions, showcasing superior generalization
capabilities compared to the baseline model, ResNet-50.

摘要：在醫療領域，由於隱私問題，獲取大型資料集會造成重大挑戰。儘管如此，對於視網膜疾病診斷的強健深度學習模型的開發需要一個龐大的資料集進行訓練。對較小的資料集進行有效概括的能力仍然是一個持續的挑戰。資料的稀缺性對可擴充醫療 AI 解決方案的實際實施構成重大障礙。為了解決此問題，我們結合了各種資料來源，通過讓其更深入地了解多模式資料集的資料表示，來改善效能和對新資料的概括性，並開發了一個基於大型語言模型 (LLM) 的自監督框架，SwinV2，以更深入地了解多模式資料集表示，增強模型推斷新資料的能力，以使用光學相干斷層掃描 (OCT) 影像偵測眼疾。我們採用兩階段訓練方法，自監督預訓練和對下游監督分類器進行微調。在三個資料集上進行的消融研究，採用各種編碼主幹，沒有資料融合，在資料可用性設定較低的情況下，以及沒有自監督預訓練場景，突出了我們方法的穩健性。我們的研究結果證明了在這些不同條件下的一致效能，與基準模型 ResNet-50 相比，展示了卓越的概括能力。

##### **Clinical Validation of a Real-Time Machine Learning-based System for the Detection of Acute Myeloid Leukemia by Flow Cytometry**
2409.11350v1 by Lauren M. Zuromski, Jacob Durtschi, Aimal Aziz, Jeffrey Chumley, Mark Dewey, Paul English, Muir Morrison, Keith Simmon, Blaine Whipple, Brendan O'Fallon, David P. Ng

Machine-learning (ML) models in flow cytometry have the potential to reduce
error rates, increase reproducibility, and boost the efficiency of clinical
labs. While numerous ML models for flow cytometry data have been proposed, few
studies have described the clinical deployment of such models. Realizing the
potential gains of ML models in clinical labs requires not only an accurate
model, but infrastructure for automated inference, error detection, analytics
and monitoring, and structured data extraction. Here, we describe an ML model
for detection of Acute Myeloid Leukemia (AML), along with the infrastructure
supporting clinical implementation. Our infrastructure leverages the resilience
and scalability of the cloud for model inference, a Kubernetes-based workflow
system that provides model reproducibility and resource management, and a
system for extracting structured diagnoses from full-text reports. We also
describe our model monitoring and visualization platform, an essential element
for ensuring continued model accuracy. Finally, we present a post-deployment
analysis of impacts on turn-around time and compare production accuracy to the
original validation statistics.

摘要：機器學習 (ML) 模型在流式細胞術中具有降低錯誤率、提高可重現性和提升臨床實驗室效率的潛力。雖然已經提出許多用於流式細胞術數據的 ML 模型，但很少有研究描述此類模型的臨床部署。要實現 ML 模型在臨床實驗室中的潛在收益，不僅需要準確的模型，還需要用於自動推理、錯誤檢測、分析和監控以及結構化數據提取的基礎設施。在這裡，我們描述了一個用於檢測急性髓性白血病 (AML) 的 ML 模型，以及支持臨床實施的基礎設施。我們的基礎設施利用雲端的復原力和可擴充性進行模型推理，一個基於 Kubernetes 的工作流程系統提供模型可重現性和資源管理，以及一個從全文報告中提取結構化診斷的系統。我們還描述了我們的模型監控和視覺化平台，這是確保持續模型準確性的基本要素。最後，我們提出了對周轉時間影響的部署後分析，並將生產準確度與原始驗證統計數據進行比較。

##### **TTT-Unet: Enhancing U-Net with Test-Time Training Layers for Biomedical Image Segmentation**
2409.11299v2 by Rong Zhou, Zhengqing Yuan, Zhiling Yan, Weixiang Sun, Kai Zhang, Yiwei Li, Yanfang Ye, Xiang Li, Lifang He, Lichao Sun

Biomedical image segmentation is crucial for accurately diagnosing and
analyzing various diseases. However, Convolutional Neural Networks (CNNs) and
Transformers, the most commonly used architectures for this task, struggle to
effectively capture long-range dependencies due to the inherent locality of
CNNs and the computational complexity of Transformers. To address this
limitation, we introduce TTT-Unet, a novel framework that integrates Test-Time
Training (TTT) layers into the traditional U-Net architecture for biomedical
image segmentation. TTT-Unet dynamically adjusts model parameters during the
testing time, enhancing the model's ability to capture both local and
long-range features. We evaluate TTT-Unet on multiple medical imaging datasets,
including 3D abdominal organ segmentation in CT and MR images, instrument
segmentation in endoscopy images, and cell segmentation in microscopy images.
The results demonstrate that TTT-Unet consistently outperforms state-of-the-art
CNN-based and Transformer-based segmentation models across all tasks. The code
is available at https://github.com/rongzhou7/TTT-Unet.

摘要：生物医学影像分割对于准确诊断和分析各种疾病至关重要。然而，卷积神经网络 (CNN) 和 Transformer，是此任务最常用的架构，由于 CNN 的固有局部性和 Transformer 的计算复杂性，难以有效捕捉远程依赖关系。为了解决这一限制，我们引入了 TTT-Unet，这是一个新颖的框架，它将测试时训练 (TTT) 层集成到用于生物医学影像分割的传统 U-Net 架构中。TTT-Unet 在测试时动态调整模型参数，增强了模型捕捉局部和远程特征的能力。我们在多个医学影像数据集上评估了 TTT-Unet，包括 CT 和 MR 影像中的 3D 腹部器官分割、内窥镜影像中的仪器分割以及显微镜影像中的细胞分割。结果表明，TTT-Unet 在所有任务中始终优于最先进的基于 CNN 和基于 Transformer 的分割模型。代码可在 https://github.com/rongzhou7/TTT-Unet 获得。

##### **EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage**
2409.11295v1 by Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun

Generalist web agents have evolved rapidly and demonstrated remarkable
potential. However, there are unprecedented safety risks associated with these
them, which are nearly unexplored so far. In this work, we aim to narrow this
gap by conducting the first study on the privacy risks of generalist web agents
in adversarial environments. First, we present a threat model that discusses
the adversarial targets, constraints, and attack scenarios. Particularly, we
consider two types of adversarial targets: stealing users' specific personally
identifiable information (PII) or stealing the entire user request. To achieve
these objectives, we propose a novel attack method, termed Environmental
Injection Attack (EIA). This attack injects malicious content designed to adapt
well to different environments where the agents operate, causing them to
perform unintended actions. This work instantiates EIA specifically for the
privacy scenario. It inserts malicious web elements alongside persuasive
instructions that mislead web agents into leaking private information, and can
further leverage CSS and JavaScript features to remain stealthy. We collect 177
actions steps that involve diverse PII categories on realistic websites from
the Mind2Web dataset, and conduct extensive experiments using one of the most
capable generalist web agent frameworks to date, SeeAct. The results
demonstrate that EIA achieves up to 70% ASR in stealing users' specific PII.
Stealing full user requests is more challenging, but a relaxed version of EIA
can still achieve 16% ASR. Despite these concerning results, it is important to
note that the attack can still be detectable through careful human inspection,
highlighting a trade-off between high autonomy and security. This leads to our
detailed discussion on the efficacy of EIA under different levels of human
supervision as well as implications on defenses for generalist web agents.

摘要：<paragraph>通用網路代理快速演化，展現出驚人的潛力。然而，這些代理伴隨著前所未有的安全風險，而這些風險目前幾乎尚未被探索。在這項工作中，我們旨在透過執行通用網路代理在對抗環境中的隱私風險的第一個研究來縮小這個差距。首先，我們提出一個威脅模型，討論對抗目標、限制和攻擊情境。特別是，我們考慮兩種類型的對抗目標：竊取使用者的特定個人可識別資訊 (PII) 或竊取整個使用者要求。為了達成這些目標，我們提出了一種新穎的攻擊方法，稱為環境注入攻擊 (EIA)。此攻擊注入惡意內容，旨在適應代理運作的不同環境，導致代理執行非預期的動作。這項工作特別針對隱私情境實例化 EIA。它在具有說服力的指令旁插入惡意網路元素，誤導網路代理洩露私人資訊，並可進一步利用 CSS 和 JavaScript 功能保持隱密。我們從 Mind2Web 資料集的現實網站收集了 177 個涉及不同 PII 類別的動作步驟，並使用迄今為止功能最強大的通用網路代理框架 SeeAct 進行廣泛的實驗。結果證明，EIA 在竊取使用者的特定 PII 方面達到了 70% 的 ASR。竊取完整的使用者要求更具挑戰性，但 EIA 的放寬版本仍可達到 16% 的 ASR。儘管有這些令人擔憂的結果，但重要的是要注意，攻擊仍然可以透過仔細的人工檢查來偵測，突顯了高度自主性與安全性之間的權衡。這導致我們詳細討論了 EIA 在不同層級的人工監督下的效能，以及對通用網路代理防禦的影響。</paragraph>

##### **Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory**
2409.11192v1 by Eunhae Lee

One application area of long-term memory (LTM) capabilities with increasing
traction is personal AI companions and assistants. With the ability to retain
and contextualize past interactions and adapt to user preferences, personal AI
companions and assistants promise a profound shift in how we interact with AI
and are on track to become indispensable in personal and professional settings.
However, this advancement introduces new challenges and vulnerabilities that
require careful consideration regarding the deployment and widespread use of
these systems. The goal of this paper is to explore the broader implications of
building and deploying personal AI applications with LTM capabilities using a
holistic evaluation approach. This will be done in three ways: 1) reviewing the
technological underpinnings of LTM in Large Language Models, 2) surveying
current personal AI companions and assistants, and 3) analyzing critical
considerations and implications of deploying and using these applications.

摘要：長期記憶 (LTM) 能力的應用領域之一是個人 AI 伴侶和助理，其吸引力正與日俱增。個人 AI 伴侶和助理具備保留和將過去互動脈絡化，以及適應使用者偏好的能力，承諾將徹底改變我們與 AI 互動的方式，並有望在個人和專業領域中變得不可或缺。然而，這項進展帶來了新的挑戰和漏洞，需要仔細考量這些系統的部署和廣泛使用。本文的目標是利用整體評估方法探討建構和部署具備 LTM 能力的個人 AI 應用程式的廣泛影響。這將透過三種方式進行：1) 檢視大型語言模型中 LTM 的技術基礎，2) 調查目前的個人 AI 伴侶和助理，以及 3) 分析部署和使用這些應用程式的關鍵考量和影響。

##### **Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine Learning Approach**
2409.10932v1 by Mehroush Banday, Sherin Zafar, Parul Agarwal, M Afshar Alam, Abubeker K M

Coronary heart disease (CHD) is a severe cardiac disease, and hence, its
early diagnosis is essential as it improves treatment results and saves money
on medical care. The prevailing development of quantum computing and machine
learning (ML) technologies may bring practical improvement to the performance
of CHD diagnosis. Quantum machine learning (QML) is receiving tremendous
interest in various disciplines due to its higher performance and capabilities.
A quantum leap in the healthcare industry will increase processing power and
optimise multiple models. Techniques for QML have the potential to forecast
cardiac disease and help in early detection. To predict the risk of coronary
heart disease, a hybrid approach utilizing an ensemble machine learning model
based on QML classifiers is presented in this paper. Our approach, with its
unique ability to address multidimensional healthcare data, reassures the
method's robustness by fusing quantum and classical ML algorithms in a
multi-step inferential framework. The marked rise in heart disease and death
rates impacts worldwide human health and the global economy. Reducing cardiac
morbidity and mortality requires early detection of heart disease. In this
research, a hybrid approach utilizes techniques with quantum computing
capabilities to tackle complex problems that are not amenable to conventional
machine learning algorithms and to minimize computational expenses. The
proposed method has been developed in the Raspberry Pi 5 Graphics Processing
Unit (GPU) platform and tested on a broad dataset that integrates clinical and
imaging data from patients suffering from CHD and healthy controls. Compared to
classical machine learning models, the accuracy, sensitivity, F1 score, and
specificity of the proposed hybrid QML model used with CHD are manifold higher.

摘要：冠狀動脈心臟病 (CHD) 是一種嚴重的疾病，因此，早期診斷至關重要，因為它可以改善治療結果並節省醫療保健費用。量子計算和機器學習 (ML) 技術的盛行發展可能會對 CHD 診斷的性能帶來實際改善。量子機器學習 (QML) 由於其更高的性能和能力，在各個領域引起了極大的興趣。醫療保健行業的量子飛躍將增加處理能力並優化多個模型。QML 的技術有潛力預測心臟病並幫助早期發現。為了預測冠狀動脈心臟病的風險，本文提出了一種基於 QML 分類器的混合機器學習模型的混合方法。我們的這種方法具備處理多維醫療保健數據的獨特能力，通過在多步驟推理框架中融合量子和經典 ML 演算法，確保了該方法的穩健性。心臟病和死亡率的顯著上升影響了全球人類健康和全球經濟。降低心臟發病率和死亡率需要對心臟病進行早期發現。在這項研究中，一種混合方法利用具有量子計算能力的技術來解決傳統機器學習演算法無法解決的複雜問題，並最大程度地減少計算開銷。所提出的方法已在 Raspberry Pi 5 繪圖處理單元 (GPU) 平臺上開發，並在一個廣泛的資料集上進行了測試，該資料集整合了患有 CHD 和健康對照者的臨床和影像數據。與經典機器學習模型相比，所提出的混合 QML 模型與 CHD 一起使用的準確性、敏感性、F1 分數和特異性更高。

##### **Self-supervised Speech Models for Word-Level Stuttered Speech Detection**
2409.10704v1 by Yi-Jen Shih, Zoi Gkalitsiou, Alexandros G. Dimakis, David Harwath

Clinical diagnosis of stuttering requires an assessment by a licensed
speech-language pathologist. However, this process is time-consuming and
requires clinicians with training and experience in stuttering and fluency
disorders. Unfortunately, only a small percentage of speech-language
pathologists report being comfortable working with individuals who stutter,
which is inadequate to accommodate for the 80 million individuals who stutter
worldwide. Developing machine learning models for detecting stuttered speech
would enable universal and automated screening for stuttering, enabling speech
pathologists to identify and follow up with patients who are most likely to be
diagnosed with a stuttering speech disorder. Previous research in this area has
predominantly focused on utterance-level detection, which is not sufficient for
clinical settings where word-level annotation of stuttering is the norm. In
this study, we curated a stuttered speech dataset with word-level annotations
and introduced a word-level stuttering speech detection model leveraging
self-supervised speech models. Our evaluation demonstrates that our model
surpasses previous approaches in word-level stuttering speech detection.
Additionally, we conducted an extensive ablation analysis of our method,
providing insight into the most important aspects of adapting self-supervised
speech models for stuttered speech detection.

摘要：臨床口吃診斷需要由執照語言病理學家評估。然而，這個過程很耗時，需要受過口吃和流利障礙訓練和經驗的臨床醫生。不幸的是，只有一小部分語言病理學家表示願意與口吃者合作，這不足以容納全球 8000 萬名口吃者。開發用於檢測口吃語音的機器學習模型將能對口吃進行普遍且自動化的篩查，使語言病理學家能夠識別並追蹤最有可能被診斷出患有口吃言語障礙的患者。這方面的先前研究主要集中於話語層級的檢測，這不足以用於口吃的單字層級註解為常態的臨床環境。在本研究中，我們策劃了一個帶有單字層級註解的口吃語音資料集，並引入了一個利用自我監督語音模型的單字層級口吃語音檢測模型。我們的評估證明，我們的模型在單字層級口吃語音檢測中優於先前的做法。此外，我們對我們的方法進行了廣泛的消融分析，提供了對調整自我監督語音模型以進行口吃語音檢測的最重要面向的見解。

##### **A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**
2409.10403v1 by Zhang Zheng

This paper proposes a knowledge-enhanced disease diagnosis method based on a
prompt learning framework. The method retrieves structured knowledge from
external knowledge graphs related to clinical cases, encodes it, and injects it
into the prompt templates to enhance the language model's understanding and
reasoning capabilities for the task.We conducted experiments on three public
datasets: CHIP-CTC, IMCS-V2-NER, and KUAKE-QTR. The results show that the
proposed method significantly outperforms existing models across multiple
evaluation metrics, with an F1 score improvement of 2.4% on the CHIP-CTC
dataset, 3.1% on the IMCS-V2-NER dataset,and 4.2% on the KUAKE-QTR dataset.
Additionally,ablation studies confirmed the critical role of the knowledge
injection module,as the removal of this module resulted in a significant drop
in F1 score. The experimental results demonstrate that the proposed method not
only effectively improves the accuracy of disease diagnosis but also enhances
the interpretability of the predictions, providing more reliable support and
evidence for clinical diagnosis.

摘要：本文提出了一种基于提示学习框架的知识增强疾病诊断方法。该方法从与临床病例相关的外部知识图谱中检索结构化知识，对其进行编码，并将其注入到提示模板中，以增强语言模型对任务的理解和推理能力。我们在三个公共数据集上进行了实验：CHIP-CTC、IMCS-V2-NER 和 KUAKE-QTR。结果表明，所提出的方法在多个评估指标上明显优于现有模型，在 CHIP-CTC 数据集上的 F1 得分提高了 2.4%，在 IMCS-V2-NER 数据集上提高了 3.1%，在 KUAKE-QTR 数据集上提高了 4.2%。此外，消融研究证实了知识注入模块的关键作用，因为移除此模块会导致 F1 得分显着下降。实验结果表明，所提出的方法不仅有效提高了疾病诊断的准确性，而且增强了预测的可解释性，为临床诊断提供了更可靠的支持和证据。

##### **Robust image representations with counterfactual contrastive learning**
2409.10365v1 by Mélanie Roschewitz, Fabio De Sousa Ribeiro, Tian Xia, Galvin Khara, Ben Glocker

Contrastive pretraining can substantially increase model generalisation and
downstream performance. However, the quality of the learned representations is
highly dependent on the data augmentation strategy applied to generate positive
pairs. Positive contrastive pairs should preserve semantic meaning while
discarding unwanted variations related to the data acquisition domain.
Traditional contrastive pipelines attempt to simulate domain shifts through
pre-defined generic image transformations. However, these do not always mimic
realistic and relevant domain variations for medical imaging such as scanner
differences. To tackle this issue, we herein introduce counterfactual
contrastive learning, a novel framework leveraging recent advances in causal
image synthesis to create contrastive positive pairs that faithfully capture
relevant domain variations. Our method, evaluated across five datasets
encompassing both chest radiography and mammography data, for two established
contrastive objectives (SimCLR and DINO-v2), outperforms standard contrastive
learning in terms of robustness to acquisition shift. Notably, counterfactual
contrastive learning achieves superior downstream performance on both
in-distribution and on external datasets, especially for images acquired with
scanners under-represented in the training set. Further experiments show that
the proposed framework extends beyond acquisition shifts, with models trained
with counterfactual contrastive learning substantially improving subgroup
performance across biological sex.

摘要：對比預訓練可以大幅提升模型的泛化能力和下游效能。然而，學習到的表徵品質高度依賴於用來產生正向配對的資料擴充策略。正向對比配對應當保留語意意義，同時捨棄與資料擷取領域相關的不必要變異。傳統的對比管線會嘗試透過預先定義的通用影像轉換來模擬領域轉移。然而，這些轉換並不總是能模仿醫療影像的實際且相關領域變異，例如掃描儀的差異。為了解決這個問題，我們在此提出反事實對比學習，一個利用因果影像合成近期進展來建立忠實捕捉相關領域變異的對比正向配對的新穎架構。我們的做法在涵蓋胸部 X 光和乳房攝影資料的五個資料集上進行評估，對於兩個已建立的對比目標（SimCLR 和 DINO-v2），在對於擷取轉移的穩健性方面優於標準對比學習。值得注意的是，反事實對比學習在內部分佈和外部資料集上都能達成優異的下游效能，特別是對於訓練集中代表性不足的掃描儀所擷取的影像。進一步的實驗顯示，所提出的架構延伸到擷取轉移之外，使用反事實對比學習訓練的模型大幅提升了生物性別的子群效能。

##### **Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search for COVID-19 Misinformation between the United States and South Africa**
2409.10168v1 by Hayoung Jung, Prerna Juneja, Tanushree Mitra

Despite being an integral tool for finding health-related information online,
YouTube has faced criticism for disseminating COVID-19 misinformation globally
to its users. Yet, prior audit studies have predominantly investigated YouTube
within the Global North contexts, often overlooking the Global South. To
address this gap, we conducted a comprehensive 10-day geolocation-based audit
on YouTube to compare the prevalence of COVID-19 misinformation in search
results between the United States (US) and South Africa (SA), the countries
heavily affected by the pandemic in the Global North and the Global South,
respectively. For each country, we selected 3 geolocations and placed
sock-puppets, or bots emulating "real" users, that collected search results for
48 search queries sorted by 4 search filters for 10 days, yielding a dataset of
915K results. We found that 31.55% of the top-10 search results contained
COVID-19 misinformation. Among the top-10 search results, bots in SA faced
significantly more misinformative search results than their US counterparts.
Overall, our study highlights the contrasting algorithmic behaviors of YouTube
search between two countries, underscoring the need for the platform to
regulate algorithmic behavior consistently across different regions of the
Globe.

摘要：儘管 YouTube 是在網路上尋找與健康相關資訊的一項重要工具，但它也因為向全球使用者散播 COVID-19 錯誤資訊而受到批評。然而，先前的稽核研究主要在全球北方的背景下調查 YouTube，常常忽略了全球南方。為了解決這個差距，我們在 YouTube 上進行了一項為期 10 天的綜合地理位置稽核，以比較美國（美國）和南非（南非）搜尋結果中 COVID-19 錯誤資訊的盛行率，這兩個國家分別是全球北方和全球南方中受疫情嚴重影響的國家。對於每個國家，我們選擇了 3 個地理位置，並放置了模擬「真實」使用者的襪子傀儡或機器人，收集了 48 個搜尋查詢的搜尋結果，並根據 4 個搜尋篩選條件進行了 10 天的排序，產生了 915K 筆結果的資料集。我們發現，31.55% 的前 10 名搜尋結果包含 COVID-19 錯誤資訊。在排名前 10 名的搜尋結果中，南非的機器人面臨的錯誤資訊搜尋結果明顯多於美國的機器人。總體而言，我們的研究突出了 YouTube 搜尋在兩個國家之間對比的演算法行為，強調了該平台需要在全球不同地區一致地規範演算法行為。

##### **Machine listening in a neonatal intensive care unit**
2409.11439v1 by Modan Tailleur, Vincent Lostanlen, Jean-Philippe Rivière, Pierre Aumond

Oxygenators, alarm devices, and footsteps are some of the most common sound
sources in a hospital. Detecting them has scientific value for environmental
psychology but comes with challenges of its own: namely, privacy preservation
and limited labeled data. In this paper, we address these two challenges via a
combination of edge computing and cloud computing. For privacy preservation, we
have designed an acoustic sensor which computes third-octave spectrograms on
the fly instead of recording audio waveforms. For sample-efficient machine
learning, we have repurposed a pretrained audio neural network (PANN) via
spectral transcoding and label space adaptation. A small-scale study in a
neonatological intensive care unit (NICU) confirms that the time series of
detected events align with another modality of measurement: i.e., electronic
badges for parents and healthcare professionals. Hence, this paper demonstrates
the feasibility of polyphonic machine listening in a hospital ward while
guaranteeing privacy by design.

摘要：氧合器、警報裝置和腳步聲是醫院中最常見的聲音來源。偵測它們對環境心理學具有科學價值，但同時也面臨著挑戰：即隱私保護和標記資料有限。在本文中，我們通過結合邊緣運算和雲端運算來解決這兩個挑戰。對於隱私保護，我們設計了一個聲學感測器，它可以即時計算三分之一倍頻程譜圖，而不是記錄音訊波形。對於樣本效率高的機器學習，我們通過頻譜轉碼和標籤空間適應重新利用了一個預訓練的音訊神經網路 (PANN)。在新生兒重症監護病房 (NICU) 中進行的一項小規模研究證實，檢測到的事件的時間序列與另一種測量方式一致：即父母和醫療保健專業人員的電子證件。因此，本文展示了在醫院病房中進行多音機器聆聽的可行性，同時保證了隱私設計。

##### **DAE-Fuse: An Adaptive Discriminative Autoencoder for Multi-Modality Image Fusion**
2409.10080v1 by Yuchen Guo, Ruoxiang Xu, Rongcheng Li, Zhenghao Wu, Weifeng Su

Multi-modality image fusion aims to integrate complementary data information
from different imaging modalities into a single image. Existing methods often
generate either blurry fused images that lose fine-grained semantic information
or unnatural fused images that appear perceptually cropped from the inputs. In
this work, we propose a novel two-phase discriminative autoencoder framework,
termed DAE-Fuse, that generates sharp and natural fused images. In the
adversarial feature extraction phase, we introduce two discriminative blocks
into the encoder-decoder architecture, providing an additional adversarial loss
to better guide feature extraction by reconstructing the source images. While
the two discriminative blocks are adapted in the attention-guided
cross-modality fusion phase to distinguish the structural differences between
the fused output and the source inputs, injecting more naturalness into the
results. Extensive experiments on public infrared-visible, medical image
fusion, and downstream object detection datasets demonstrate our method's
superiority and generalizability in both quantitative and qualitative
evaluations.

摘要：多模態影像融合旨在將來自不同影像模態的互補資料資訊整合到單一影像中。現有方法通常會產生模糊的融合影像，失去細緻的語意資訊，或是不自然的融合影像，在感知上看起來像是從輸入中裁切出來的。在這項工作中，我們提出一個新穎的兩階段判別式自編碼器框架，稱為 DAE-Fuse，可產生清晰且自然的融合影像。在對抗特徵提取階段，我們在編碼器-解碼器架構中引入兩個判別式區塊，提供額外的對抗損失，藉由重建原始影像來更好地引導特徵提取。雖然兩個判別式區塊在注意力引導的跨模態融合階段中進行調整，以區分融合輸出與原始輸入之間的結構差異，為結果注入更多自然性。針對公開紅外線可見光、醫學影像融合和下游物件偵測資料集進行的廣泛實驗證明了我們的方法在量化和定性評估中的優越性和泛化性。

##### **MindGuard: Towards Accessible and Sitgma-free Mental Health First Aid via Edge LLM**
2409.10064v1 by Sijie Ji, Xinzhe Zheng, Jiawei Sun, Renqi Chen, Wei Gao, Mani Srivastava

Mental health disorders are among the most prevalent diseases worldwide,
affecting nearly one in four people. Despite their widespread impact, the
intervention rate remains below 25%, largely due to the significant cooperation
required from patients for both diagnosis and intervention. The core issue
behind this low treatment rate is stigma, which discourages over half of those
affected from seeking help. This paper presents MindGuard, an accessible,
stigma-free, and professional mobile mental healthcare system designed to
provide mental health first aid. The heart of MindGuard is an innovative edge
LLM, equipped with professional mental health knowledge, that seamlessly
integrates objective mobile sensor data with subjective Ecological Momentary
Assessment records to deliver personalized screening and intervention
conversations. We conduct a broad evaluation of MindGuard using open datasets
spanning four years and real-world deployment across various mobile devices
involving 20 subjects for two weeks. Remarkably, MindGuard achieves results
comparable to GPT-4 and outperforms its counterpart with more than 10 times the
model size. We believe that MindGuard paves the way for mobile LLM
applications, potentially revolutionizing mental healthcare practices by
substituting self-reporting and intervention conversations with passive,
integrated monitoring within daily life, thus ensuring accessible and
stigma-free mental health support.

摘要：心理健康疾病是全球最普遍的疾病之一，
影響了近四分之一的人。儘管其影響廣泛，
但介入率仍低於 25%，很大程度上是因為
患者在診斷和介入時需要大量配合。背後導致
治療率低下的核心問題是污名化，這讓超過一半的
受影響者不願意尋求幫助。本文提出了 MindGuard，一個
易於取得、無污名化且專業的手機心理保健系統，旨在
提供心理急救。MindGuard 的核心是一個創新的邊緣
大型語言模型 (LLM)，具備專業的心理健康知識，它能無縫
整合客觀的手機感測器資料與主觀的生態瞬時評估記錄，提供
個人化的篩檢和介入對話。我們使用橫跨四年的開放資料集
對 MindGuard 進行廣泛的評估，並在各種行動裝置上進行為期
兩週、涉及 20 位受試者的實際部署。值得注意的是，MindGuard
達到的結果與 GPT-4 相當，並且優於模型規模大於其 10 倍以上的
對應模型。我們相信 MindGuard 為行動 LLM 應用鋪平了道路，
有可能透過在日常生活中進行被動、整合的監控來取代自我報告
和介入對話，從而徹底改變心理保健實務，進而確保可取得且
無污名化的精神健康支持。

##### **HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making**
2409.10011v2 by Sumera Anjum, Hanzhi Zhang, Wenjun Zhou, Eun Jin Paek, Xiaopeng Zhao, Yunhe Feng

Large language models (LLMs) have significantly advanced natural language
processing tasks, yet they are susceptible to generating inaccurate or
unreliable responses, a phenomenon known as hallucination. In critical domains
such as health and medicine, these hallucinations can pose serious risks. This
paper introduces HALO, a novel framework designed to enhance the accuracy and
reliability of medical question-answering (QA) systems by focusing on the
detection and mitigation of hallucinations. Our approach generates multiple
variations of a given query using LLMs and retrieves relevant information from
external open knowledge bases to enrich the context. We utilize maximum
marginal relevance scoring to prioritize the retrieved context, which is then
provided to LLMs for answer generation, thereby reducing the risk of
hallucinations. The integration of LangChain further streamlines this process,
resulting in a notable and robust increase in the accuracy of both open-source
and commercial LLMs, such as Llama-3.1 (from 44% to 65%) and ChatGPT (from 56%
to 70%). This framework underscores the critical importance of addressing
hallucinations in medical QA systems, ultimately improving clinical
decision-making and patient care. The open-source HALO is available at:
https://github.com/ResponsibleAILab/HALO.

摘要：大型語言模型 (LLM) 已大幅提升自然語言處理任務，但它們容易產生不準確或不可靠的回應，這種現象稱為幻覺。在健康和醫學等關鍵領域，這些幻覺可能會造成嚴重的風險。這篇論文介紹了 HALO，一種新穎的架構，旨在透過專注於偵測和減輕幻覺，來提升醫療問答 (QA) 系統的準確性和可靠性。我們的做法是使用 LLM 產生給定查詢的各種變體，並從外部開放知識庫中擷取相關資訊來豐富內容。我們利用最大邊際相關性評分來優先處理擷取的內容，然後提供給 LLM 以產生答案，從而降低幻覺的風險。LangChain 的整合進一步簡化了這個過程，導致開放原始碼和商業 LLM 的準確性顯著且穩健地提升，例如 Llama-3.1（從 44% 提升到 65%）和 ChatGPT（從 56% 提升到 70%）。這個架構強調了在醫療問答系統中處理幻覺至關重要，最終改善臨床決策制定和患者照護。開放原始碼 HALO 可在以下網址取得：https://github.com/ResponsibleAILab/HALO。

##### **Artificial Intelligence-Based Opportunistic Coronary Calcium Screening in the Veterans Affairs National Healthcare System**
2409.09968v1 by Raffi Hagopian, Timothy Strebel, Simon Bernatz, Gregory A Myers, Erik Offerman, Eric Zuniga, Cy Y Kim, Angie T Ng, James A Iwaz, Sunny P Singh, Evan P Carey, Michael J Kim, R Spencer Schaefer, Jeannie Yu, Amilcare Gentili, Hugo JWL Aerts

Coronary artery calcium (CAC) is highly predictive of cardiovascular events.
While millions of chest CT scans are performed annually in the United States,
CAC is not routinely quantified from scans done for non-cardiac purposes. A
deep learning algorithm was developed using 446 expert segmentations to
automatically quantify CAC on non-contrast, non-gated CT scans (AI-CAC). Our
study differs from prior works as we leverage imaging data across the Veterans
Affairs national healthcare system, from 98 medical centers, capturing
extensive heterogeneity in imaging protocols, scanners, and patients. AI-CAC
performance on non-gated scans was compared against clinical standard ECG-gated
CAC scoring. Non-gated AI-CAC differentiated zero vs. non-zero and less than
100 vs. 100 or greater Agatston scores with accuracies of 89.4% (F1 0.93) and
87.3% (F1 0.89), respectively, in 795 patients with paired gated scans within a
year of a non-gated CT scan. Non-gated AI-CAC was predictive of 10-year
all-cause mortality (CAC 0 vs. >400 group: 25.4% vs. 60.2%, Cox HR 3.49, p <
0.005), and composite first-time stroke, MI, or death (CAC 0 vs. >400 group:
33.5% vs. 63.8%, Cox HR 3.00, p < 0.005). In a screening dataset of 8,052
patients with low-dose lung cancer-screening CTs (LDCT), 3,091/8,052 (38.4%)
individuals had AI-CAC >400. Four cardiologists qualitatively reviewed LDCT
images from a random sample of >400 AI-CAC patients and verified that 527/531
(99.2%) would benefit from lipid-lowering therapy. To the best of our
knowledge, this is the first non-gated CT CAC algorithm developed across a
national healthcare system, on multiple imaging protocols, without filtering
intra-cardiac hardware, and compared against a strong gated CT reference. We
report superior performance relative to previous CAC algorithms evaluated
against paired gated scans that included patients with intra-cardiac hardware.

摘要：冠狀動脈鈣化 (CAC) 極具預測心血管事件的能力。
雖然美國每年進行數百萬次胸部電腦斷層掃描，
但非心臟目的掃描通常不會對 CAC 進行量化。一
個深度學習演算法使用 446 個專家分段開發，以
在非對比、非門控電腦斷層掃描 (AI-CAC) 上自動量化 CAC。我們的
研究與先前的工作不同，因為我們利用退伍軍人事務部全國醫療保健系統中來自 98 個醫療中心的影像資料，捕捉
影像協定、掃描器和患者的廣泛異質性。AI-CAC
在非門控掃描上的表現與臨床標準 ECG 門控
CAC 評分進行比較。非門控 AI-CAC 區分零與非零，以及低於
100 與 100 或更高的 Agatston 分數，在一年內進行配對門控掃描的 795 名患者中準確率分別為 89.4% (F1 0.93) 和
87.3% (F1 0.89)。非門控 AI-CAC 可預測 10 年全因死亡率 (CAC 0 對比 >400 群組：25.4% 對比 60.2%，Cox HR 3.49，p <
0.005)，以及首次複合性中風、心肌梗塞或死亡 (CAC 0 對比 >400 群組：
33.5% 對比 63.8%，Cox HR 3.00，p < 0.005)。在 8,052 名接受低劑量肺癌篩檢電腦斷層掃描 (LDCT) 的患者的篩檢資料集中，3,091/8,052 (38.4%)
個體的 AI-CAC >400。四位心臟病專家對隨機抽取的 >400 AI-CAC 患者的 LDCT
影像進行質性審查，並驗證 527/531
(99.2%) 將受益於降血脂治療。據我們所知，這是第一個非門控電腦斷層 CAC 演算法，在全國醫療保健系統中開發，採用多種影像協定，不篩選
心內硬體，並與強大的門控電腦斷層參考進行比較。我們
報告的效能優於先前針對包含心內硬體患者的配對門控掃描進行評估的 CAC 演算法。

##### **GP-GPT: Large Language Model for Gene-Phenotype Mapping**
2409.09825v1 by Yanjun Lyu, Zihao Wu, Lu Zhang, Jing Zhang, Yiwei Li, Wei Ruan, Zhengliang Liu, Xiaowei Yu, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Xiang Li, Rongjie Liu, Chao Huang, Wentao Li, Tianming Liu, Dajiang Zhu

Pre-trained large language models(LLMs) have attracted increasing attention
in biomedical domains due to their success in natural language processing.
However, the complex traits and heterogeneity of multi-sources genomics data
pose significant challenges when adapting these models to the bioinformatics
and biomedical field. To address these challenges, we present GP-GPT, the first
specialized large language model for genetic-phenotype knowledge representation
and genomics relation analysis. Our model is fine-tuned in two stages on a
comprehensive corpus composed of over 3,000,000 terms in genomics, proteomics,
and medical genetics, derived from multiple large-scale validated datasets and
scientific publications. GP-GPT demonstrates proficiency in accurately
retrieving medical genetics information and performing common genomics analysis
tasks, such as genomics information retrieval and relationship determination.
Comparative experiments across domain-specific tasks reveal that GP-GPT
outperforms state-of-the-art LLMs, including Llama2, Llama3 and GPT-4. These
results highlight GP-GPT's potential to enhance genetic disease relation
research and facilitate accurate and efficient analysis in the fields of
genomics and medical genetics. Our investigation demonstrated the subtle
changes of bio-factor entities' representations in the GP-GPT, which suggested
the opportunities for the application of LLMs to advancing gene-phenotype
research.

摘要：預先訓練好的大型語言模型 (LLM) 由於在自然語言處理方面取得成功，因此在生物醫學領域中備受關注。
然而，多來源基因組數據的複雜特徵和異質性在將這些模型應用於生物資訊學和生物醫學領域時，構成了重大挑戰。為了應對這些挑戰，我們提出了 GP-GPT，這是第一個用於遺傳表型知識表徵和基因組關係分析的專業大型語言模型。我們的模型分兩個階段進行微調，一個綜合語料庫包含超過 3,000,000 個基因組學、蛋白質組學和醫學遺傳學中的術語，這些術語來自多個經過驗證的大規模數據集和科學出版物。GP-GPT 顯示出準確擷取醫學遺傳學資訊和執行常見基因組分析任務（例如基因組資訊擷取和關係確定）的能力。跨領域特定任務的比較實驗顯示，GP-GPT 優於最先進的 LLM，包括 Llama2、Llama3 和 GPT-4。這些結果突出了 GP-GPT 在加強遺傳疾病關係研究以及促進基因組學和醫學遺傳學領域中準確而有效分析的潛力。我們的調查證明了 GP-GPT 中生物因子實體表徵的細微變化，這表明了將 LLM 應用於推進基因表型研究的機會。

##### **Veridical Data Science for Medical Foundation Models**
2409.10580v1 by Ahmed Alaa, Bin Yu

The advent of foundation models (FMs) such as large language models (LLMs)
has led to a cultural shift in data science, both in medicine and beyond. This
shift involves moving away from specialized predictive models trained for
specific, well-defined domain questions to generalist FMs pre-trained on vast
amounts of unstructured data, which can then be adapted to various clinical
tasks and questions. As a result, the standard data science workflow in
medicine has been fundamentally altered; the foundation model lifecycle (FMLC)
now includes distinct upstream and downstream processes, in which computational
resources, model and data access, and decision-making power are distributed
among multiple stakeholders. At their core, FMs are fundamentally statistical
models, and this new workflow challenges the principles of Veridical Data
Science (VDS), hindering the rigorous statistical analysis expected in
transparent and scientifically reproducible data science practices. We
critically examine the medical FMLC in light of the core principles of VDS:
predictability, computability, and stability (PCS), and explain how it deviates
from the standard data science workflow. Finally, we propose recommendations
for a reimagined medical FMLC that expands and refines the PCS principles for
VDS including considering the computational and accessibility constraints
inherent to FMs.

摘要：大型語言模型 (LLM) 等基礎模型 (FM) 的出現，導致了資料科學的文化轉變，無論是在醫學領域或其他領域。這個轉變涉及從針對特定、定義明確的領域問題訓練的專門預測模型，轉移到預先在大量非結構化資料上訓練的泛用型 FM，然後可以調整這些 FM 以適應各種臨床任務和問題。因此，醫學中的標準資料科學工作流程已經發生了根本性的改變；基礎模型生命週期 (FMLC) 現在包括不同的上游和下游流程，其中運算資源、模型和資料存取，以及決策權力會分配給多個利害關係人。從本質上來說，FM 基本上是統計模型，而這個新的工作流程挑戰了真實資料科學 (VDS) 的原則，阻礙了透明且科學上可複製的資料科學實務中所預期的嚴謹統計分析。我們根據 VDS 的核心原則：可預測性、可運算性和穩定性 (PCS) 來批判性地檢視醫學 FMLC，並說明它如何偏離標準的資料科學工作流程。最後，我們提出了重新構想醫學 FMLC 的建議，以擴充和完善適用於 VDS 的 PCS 原則，包括考量 FM 固有的運算和可存取性限制。

##### **From Challenges and Pitfalls to Recommendations and Opportunities: Implementing Federated Learning in Healthcare**
2409.09727v1 by Ming Li, Pengcheng Xu, Junjie Hu, Zeyu Tang, Guang Yang

Federated learning holds great potential for enabling large-scale healthcare
research and collaboration across multiple centres while ensuring data privacy
and security are not compromised. Although numerous recent studies suggest or
utilize federated learning based methods in healthcare, it remains unclear
which ones have potential clinical utility. This review paper considers and
analyzes the most recent studies up to May 2024 that describe federated
learning based methods in healthcare. After a thorough review, we find that the
vast majority are not appropriate for clinical use due to their methodological
flaws and/or underlying biases which include but are not limited to privacy
concerns, generalization issues, and communication costs. As a result, the
effectiveness of federated learning in healthcare is significantly compromised.
To overcome these challenges, we provide recommendations and promising
opportunities that might be implemented to resolve these problems and improve
the quality of model development in federated learning with healthcare.

摘要：聯邦學習在確保資料隱私和安全不致受損的情況下，為大型醫療保健研究和跨多個中心合作提供了巨大潛力。儘管許多最近的研究建議或利用基於聯邦學習的方法進行醫療保健，但哪些具有潛在的臨床效用仍不清楚。本評論文章考慮並分析了截至 2024 年 5 月描述基於聯邦學習方法的醫療保健的最新研究。在徹底檢閱後，我們發現絕大多數不適合臨床使用，因為它們存在方法論缺陷和/或潛在偏差，包括但不限於隱私問題、概化問題和通訊成本。因此，聯邦學習在醫療保健中的效力受到顯著影響。為了克服這些挑戰，我們提供了建議和有希望的機會，這些機會可能會被實施以解決這些問題並提高醫療保健中聯邦學習模型開發的品質。

##### **ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models**
2409.09662v2 by Inhwa Song, SoHyun Park, Sachin R. Pendse, Jessica Lee Schleider, Munmun De Choudhury, Young-Ho Kim

Expressing stressful experiences in words is proven to improve mental and
physical health, but individuals often disengage with writing interventions as
they struggle to organize their thoughts and emotions. Reflective prompts have
been used to provide direction, and large language models (LLMs) have
demonstrated the potential to provide tailored guidance. Current systems often
limit users' flexibility to direct their reflections. We thus present
ExploreSelf, an LLM-driven application designed to empower users to control
their reflective journey. ExploreSelf allows users to receive adaptive support
through dynamically generated questions. Through an exploratory study with 19
participants, we examine how participants explore and reflect on personal
challenges using ExploreSelf. Our findings demonstrate that participants valued
the balance between guided support and freedom to control their reflective
journey, leading to deeper engagement and insight. Building on our findings, we
discuss implications for designing LLM-driven tools that promote user
empowerment through effective reflective practices.

摘要：已證實用言語表達壓力經驗有助於改善心理和身體健康，但個人常常放棄寫作介入，因為他們在整理思緒和情緒時會遇到困難。反思提示已被用來提供方向，而大型語言模型 (LLM) 已證明有提供客製化指導的潛力。目前的系統通常會限制使用者引導其反思的靈活性。因此，我們提出了 ExploreSelf，這是一個由 LLM 驅動的應用程式，旨在授權使用者控制其反思旅程。ExploreSelf 允許使用者透過動態產生的問題來接收適應性支援。透過一項與 19 位參與者進行的探索性研究，我們探討參與者如何使用 ExploreSelf 來探索和反思個人挑戰。我們的研究結果表明，參與者重視引導式支援與控制其反思旅程的自由之間的平衡，這會帶來更深入的參與和洞察力。根據我們的研究結果，我們討論了設計 LLM 驅動工具的含意，這些工具透過有效的反思實務促進使用者賦權。

##### **MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences**
2409.09570v1 by Subigya Nepal, Arvind Pillai, William Campbell, Talie Massachi, Michael V. Heinz, Ashmita Kunwar, Eunsol Soul Choi, Orson Xu, Joanna Kuc, Jeremy Huckins, Jason Holden, Sarah M. Preum, Colin Depp, Nicholas Jacobson, Mary Czerwinski, Eric Granholm, Andrew T. Campbell

Mental health concerns are prevalent among college students, highlighting the
need for effective interventions that promote self-awareness and holistic
well-being. MindScape pioneers a novel approach to AI-powered journaling by
integrating passively collected behavioral patterns such as conversational
engagement, sleep, and location with Large Language Models (LLMs). This
integration creates a highly personalized and context-aware journaling
experience, enhancing self-awareness and well-being by embedding behavioral
intelligence into AI. We present an 8-week exploratory study with 20 college
students, demonstrating the MindScape app's efficacy in enhancing positive
affect (7%), reducing negative affect (11%), loneliness (6%), and anxiety and
depression, with a significant week-over-week decrease in PHQ-4 scores (-0.25
coefficient), alongside improvements in mindfulness (7%) and self-reflection
(6%). The study highlights the advantages of contextual AI journaling, with
participants particularly appreciating the tailored prompts and insights
provided by the MindScape app. Our analysis also includes a comparison of
responses to AI-driven contextual versus generic prompts, participant feedback
insights, and proposed strategies for leveraging contextual AI journaling to
improve well-being on college campuses. By showcasing the potential of
contextual AI journaling to support mental health, we provide a foundation for
further investigation into the effects of contextual AI journaling on mental
health and well-being.

摘要：大學生普遍有心理健康問題，強調需要有效干預措施來促進自我覺察和整體福祉。MindScape 開創了 AI 驅動日誌的新方法，方法是將被動收集的行為模式（例如對話參與、睡眠和位置）與大型語言模型 (LLM) 整合在一起。這種整合創造了高度個人化且具備情境感知能力的日誌體驗，透過將行為智慧嵌入 AI 來增強自我覺察和福祉。我們提出了一項為期 8 週的探索性研究，有 20 名大學生參與，證明 MindScape 應用程式在增強正面影響 (7%)、減少負面影響 (11%)、孤獨感 (6%) 以及焦慮和憂鬱方面有效，PHQ-4 分數週週顯著下降 (-0.25 係數)，同時正念 (7%) 和自我反省 (6%) 也有所改善。這項研究強調了情境 AI 日誌的優點，參與者特別欣賞 MindScape 應用程式提供的客製化提示和見解。我們的分析還包括比較對 AI 驅動情境提示和一般提示的回應、參與者回饋見解，以及提出利用情境 AI 日誌來改善大學校園福祉的策略。透過展示情境 AI 日誌在支援心理健康的潛力，我們為進一步探討情境 AI 日誌對心理健康和福祉的影響奠定了基礎。

##### **COMFORT: A Continual Fine-Tuning Framework for Foundation Models Targeted at Consumer Healthcare**
2409.09549v1 by Chia-Hao Li, Niraj K. Jha

Wearable medical sensors (WMSs) are revolutionizing smart healthcare by
enabling continuous, real-time monitoring of user physiological signals,
especially in the field of consumer healthcare. The integration of WMSs and
modern machine learning (ML) enables unprecedented solutions to efficient
early-stage disease detection. Despite the success of Transformers in various
fields, their application to sensitive domains, such as smart healthcare,
remains underexplored due to limited data accessibility and privacy concerns.
To bridge the gap between Transformer-based foundation models and WMS-based
disease detection, we propose COMFORT, a continual fine-tuning framework for
foundation models targeted at consumer healthcare. COMFORT introduces a novel
approach for pre-training a Transformer-based foundation model on a large
dataset of physiological signals exclusively collected from healthy individuals
with commercially available WMSs. We adopt a masked data modeling (MDM)
objective to pre-train this health foundation model. We then fine-tune the
model using various parameter-efficient fine-tuning (PEFT) methods, such as
low-rank adaptation (LoRA) and its variants, to adapt it to various downstream
disease detection tasks that rely on WMS data. In addition, COMFORT continually
stores the low-rank decomposition matrices obtained from the PEFT algorithms to
construct a library for multi-disease detection. The COMFORT library enables
scalable and memory-efficient disease detection on edge devices. Our
experimental results demonstrate that COMFORT achieves highly competitive
performance while reducing memory overhead by up to 52% relative to
conventional methods. Thus, COMFORT paves the way for personalized and
proactive solutions to efficient and effective early-stage disease detection
for consumer healthcare.

摘要：<paragraph>可穿戴式醫療感測器 (WMS) 透過持續、即時監測使用者的生理訊號，特別是在消費者醫療保健領域，進而革新了智慧醫療保健。WMS 與現代機器學習 (ML) 的整合，讓有效率的早期疾病偵測有了前所未有的解決方案。儘管 Transformer 在各種領域皆獲得成功，但由於資料取得不易和隱私疑慮，其在智慧醫療保健等敏感領域的應用仍有待探索。為了彌合 Transformer 基礎模型與 WMS 基礎疾病偵測之間的差距，我們提出了 COMFORT，一個針對消費者醫療保健而設計的基礎模型持續微調架構。COMFORT 提出了一種創新的方法，可在一個龐大的生理訊號資料集上預訓練 Transformer 基礎模型，而這些資料皆是透過市售 WMS 從健康個人身上收集而來。我們採用遮罩資料建模 (MDM) 目標來預訓練這個健康基礎模型。接著，我們使用各種參數有效率的微調 (PEFT) 方法（例如低秩適應 (LoRA) 及其變體）微調模型，以使其適應依賴 WMS 資料的各種下游疾病偵測任務。此外，COMFORT 會持續儲存從 PEFT 演算法取得的低秩分解矩陣，以建構一個多疾病偵測函式庫。COMFORT 函式庫可在邊緣裝置上進行可擴充且記憶體使用率低下的疾病偵測。我們的實驗結果顯示，COMFORT 達到了極具競爭力的效能，同時將記憶體開銷相較於傳統方法降低了 52%。因此，COMFORT 為消費者醫療保健的有效且高效早期疾病偵測，開闢了個人化且主動的解決方案。</paragraph>

##### **Enhancing Skin Disease Diagnosis: Interpretable Visual Concept Discovery with SAM Empowerment**
2409.09520v1 by Xin Hu, Janet Wang, Jihun Hamm, Rie R Yotsu, Zhengming Ding

Current AI-assisted skin image diagnosis has achieved dermatologist-level
performance in classifying skin cancer, driven by rapid advancements in deep
learning architectures. However, unlike traditional vision tasks, skin images
in general present unique challenges due to the limited availability of
well-annotated datasets, complex variations in conditions, and the necessity
for detailed interpretations to ensure patient safety. Previous segmentation
methods have sought to reduce image noise and enhance diagnostic performance,
but these techniques require fine-grained, pixel-level ground truth masks for
training. In contrast, with the rise of foundation models, the Segment Anything
Model (SAM) has been introduced to facilitate promptable segmentation, enabling
the automation of the segmentation process with simple yet effective prompts.
Efforts applying SAM predominantly focus on dermatoscopy images, which present
more easily identifiable lesion boundaries than clinical photos taken with
smartphones. This limitation constrains the practicality of these approaches to
real-world applications. To overcome the challenges posed by noisy clinical
photos acquired via non-standardized protocols and to improve diagnostic
accessibility, we propose a novel Cross-Attentive Fusion framework for
interpretable skin lesion diagnosis. Our method leverages SAM to generate
visual concepts for skin diseases using prompts, integrating local visual
concepts with global image features to enhance model performance. Extensive
evaluation on two skin disease datasets demonstrates our proposed method's
effectiveness on lesion diagnosis and interpretability.

摘要：目前由 AI 輔助的皮膚影像診斷已在皮膚癌分類中達到皮膚科醫師等級的表現，這歸功於深度學習架構的快速進展。然而，與傳統的視覺任務不同，一般皮膚影像由於標註良好的資料集取得不易、狀況複雜多變，以及確保患者安全所需的詳細詮釋，因此呈現出獨特的挑戰。先前的分割方法試圖降低影像雜訊並提升診斷表現，但這些技術需要細緻的畫素級地面實況遮罩來訓練。相對地，隨著基礎模型的興起，已導入 Segment Anything Model (SAM) 以利於提示式分割，使用簡單卻有效的提示自動化分割流程。應用 SAM 的工作主要集中於皮膚鏡影像，其病灶邊界比使用智慧型手機拍攝的臨床照片更容易辨識。此限制會約束這些方法在實際應用中的實用性。為了克服非標準化程序取得的雜訊臨床照片所造成的挑戰，並改善診斷的可近性，我們提出一個新穎的跨注意力融合架構，用於可詮釋的皮膚病灶診斷。我們的方法利用 SAM 使用提示來產生皮膚疾病的視覺概念，將局部視覺概念與整體影像特徵整合，以提升模型表現。在兩個皮膚疾病資料集上的廣泛評估顯示，我們提出的方法在病灶診斷和可詮釋性上都具有成效。

