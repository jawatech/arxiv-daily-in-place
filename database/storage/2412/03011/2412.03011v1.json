{"2412.03011": {"publish_time": "2024-12-04", "title": "Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations", "paper_summary": "Generating multi-view human images from a single view is a complex and\nsignificant challenge. Although recent advancements in multi-view object\ngeneration have shown impressive results with diffusion models, novel view\nsynthesis for humans remains constrained by the limited availability of 3D\nhuman datasets. Consequently, many existing models struggle to produce\nrealistic human body shapes or capture fine-grained facial details accurately.\nTo address these issues, we propose an innovative framework that leverages\ntransferred body and facial representations for multi-view human synthesis.\nSpecifically, we use a single-view model pretrained on a large-scale human\ndataset to develop a multi-view body representation, aiming to extend the 2D\nknowledge of the single-view model to a multi-view diffusion model.\nAdditionally, to enhance the model's detail restoration capability, we\nintegrate transferred multimodal facial features into our trained human\ndiffusion model. Experimental evaluations on benchmark datasets demonstrate\nthat our approach outperforms the current state-of-the-art methods, achieving\nsuperior performance in multi-view human synthesis.", "paper_summary_zh": "\u5f9e\u55ae\u4e00\u8996\u89d2\u751f\u6210\u591a\u8996\u89d2\u7684\u4eba\u985e\u5f71\u50cf\u662f\u4e00\u9805\u8907\u96dc\u4e14\u91cd\u5927\u7684\u6311\u6230\u3002\u5118\u7ba1\u6700\u8fd1\u5728\u591a\u8996\u89d2\u7269\u4ef6\u751f\u6210\u65b9\u9762\u7684\u9032\u5c55\u5df2\u5728\u64f4\u6563\u6a21\u578b\u4e2d\u5c55\u73fe\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6210\u679c\uff0c\u4f46\u4eba\u985e\u7684\u65b0\u8996\u89d2\u5408\u6210\u4ecd\u53d7\u5230 3D \u4eba\u985e\u8cc7\u6599\u96c6\u6709\u9650\u7684\u53ef\u7528\u6027\u6240\u9650\u5236\u3002\u56e0\u6b64\uff0c\u8a31\u591a\u73fe\u6709\u6a21\u578b\u96e3\u4ee5\u7522\u751f\u903c\u771f\u7684\u4eba\u9ad4\u5f62\u72c0\u6216\u6e96\u78ba\u6355\u6349\u7d30\u7dfb\u7684\u9762\u90e8\u7d30\u7bc0\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u8a72\u67b6\u69cb\u5229\u7528\u8f49\u79fb\u7684\u8eab\u9ad4\u548c\u9762\u90e8\u8868\u793a\u4f86\u9032\u884c\u591a\u8996\u89d2\u4eba\u985e\u5408\u6210\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u4f7f\u7528\u5728\u5927\u578b\u4eba\u985e\u8cc7\u6599\u96c6\u4e0a\u9810\u5148\u8a13\u7df4\u7684\u55ae\u8996\u89d2\u6a21\u578b\u4f86\u958b\u767c\u591a\u8996\u89d2\u8eab\u9ad4\u8868\u793a\uff0c\u65e8\u5728\u5c07\u55ae\u8996\u89d2\u6a21\u578b\u7684 2D \u77e5\u8b58\u64f4\u5c55\u5230\u591a\u8996\u89d2\u64f4\u6563\u6a21\u578b\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u589e\u5f37\u6a21\u578b\u7684\u7d30\u7bc0\u9084\u539f\u80fd\u529b\uff0c\u6211\u5011\u5c07\u8f49\u79fb\u7684\u591a\u6a21\u614b\u9762\u90e8\u7279\u5fb5\u6574\u5408\u5230\u6211\u5011\u8a13\u7df4\u7684\u4eba\u985e\u64f4\u6563\u6a21\u578b\u4e2d\u3002\u5728\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8a55\u4f30\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u512a\u65bc\u76ee\u524d\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u8996\u89d2\u4eba\u985e\u5408\u6210\u4e2d\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002", "author": "Yu Feng et.al.", "authors": "Yu Feng, Shunsi Zhang, Jian Shu, Hanfeng Zhao, Guoliang Pang, Chi Zhang, Hao Wang", "id": "2412.03011v1", "paper_url": "http://arxiv.org/abs/2412.03011v1", "repo": "null"}}