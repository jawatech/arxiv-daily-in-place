{"2502.03014": {"publish_time": "2025-02-05", "title": "xai_evals : A Framework for Evaluating Post-Hoc Local Explanation Methods", "paper_summary": "The growing complexity of machine learning and deep learning models has led\nto an increased reliance on opaque \"black box\" systems, making it difficult to\nunderstand the rationale behind predictions. This lack of transparency is\nparticularly challenging in high-stakes applications where interpretability is\nas important as accuracy. Post-hoc explanation methods are commonly used to\ninterpret these models, but they are seldom rigorously evaluated, raising\nconcerns about their reliability. The Python package xai_evals addresses this\nby providing a comprehensive framework for generating, benchmarking, and\nevaluating explanation methods across both tabular and image data modalities.\nIt integrates popular techniques like SHAP, LIME, Grad-CAM, Integrated\nGradients (IG), and Backtrace, while supporting evaluation metrics such as\nfaithfulness, sensitivity, and robustness. xai_evals enhances the\ninterpretability of machine learning models, fostering transparency and trust\nin AI systems. The library is open-sourced at\nhttps://pypi.org/project/xai-evals/ .", "paper_summary_zh": "\u6a5f\u5668\u5b78\u7fd2\u548c\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u7684\u8907\u96dc\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u5c0e\u81f4\u5c0d\u4e0d\u900f\u660e\u7684\u300c\u9ed1\u76d2\u5b50\u300d\u7cfb\u7d71\u7684\u4f9d\u8cf4\u6027\u63d0\u9ad8\uff0c\u4f7f\u5f97\u96e3\u4ee5\u7406\u89e3\u9810\u6e2c\u80cc\u5f8c\u7684\u4f9d\u64da\u3002\u9019\u7a2e\u7f3a\u4e4f\u900f\u660e\u6027\u7684\u72c0\u6cc1\u5728\u9ad8\u98a8\u96aa\u61c9\u7528\u4e2d\u7279\u5225\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u53ef\u89e3\u91cb\u6027\u8207\u6e96\u78ba\u6027\u540c\u6a23\u91cd\u8981\u3002\u4e8b\u5f8c\u89e3\u91cb\u65b9\u6cd5\u901a\u5e38\u7528\u65bc\u89e3\u91cb\u9019\u4e9b\u6a21\u578b\uff0c\u4f46\u5b83\u5011\u5f88\u5c11\u7d93\u904e\u56b4\u683c\u8a55\u4f30\uff0c\u5f15\u767c\u4e86\u5c0d\u5176\u53ef\u9760\u6027\u7684\u64d4\u6182\u3002Python \u5957\u4ef6 xai_evals \u900f\u904e\u63d0\u4f9b\u4e00\u500b\u5168\u9762\u7684\u67b6\u69cb\u4f86\u7522\u751f\u3001\u8a55\u6bd4\u548c\u8a55\u4f30\u8868\u683c\u548c\u5f71\u50cf\u8cc7\u6599\u6a21\u5f0f\u7684\u89e3\u91cb\u65b9\u6cd5\uff0c\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u5b83\u6574\u5408\u4e86 SHAP\u3001LIME\u3001Grad-CAM\u3001\u6574\u5408\u68af\u5ea6 (IG) \u548c\u56de\u6eaf\u7b49\u71b1\u9580\u6280\u8853\uff0c\u540c\u6642\u652f\u63f4\u5fe0\u5be6\u5ea6\u3001\u654f\u611f\u5ea6\u548c\u7a69\u5065\u6027\u7b49\u8a55\u4f30\u6307\u6a19\u3002xai_evals \u589e\u5f37\u4e86\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4fc3\u9032\u4e86\u5c0d AI \u7cfb\u7d71\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u3002\u9019\u500b\u51fd\u5f0f\u5eab\u5728 https://pypi.org/project/xai-evals/ \u958b\u6e90\u3002", "author": "Pratinav Seth et.al.", "authors": "Pratinav Seth, Yashwardhan Rathore, Neeraj Kumar Singh, Chintan Chitroda, Vinay Kumar Sankarapu", "id": "2502.03014v1", "paper_url": "http://arxiv.org/abs/2502.03014v1", "repo": "null"}}