{"2410.09541": {"publish_time": "2024-10-12", "title": "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning", "paper_summary": "Large language models (LLMs) sometimes demonstrate poor performance on\nknowledge-intensive tasks, commonsense reasoning is one of them. Researchers\ntypically address these issues by retrieving related knowledge from knowledge\ngraphs or employing self-enhancement methods to elicit knowledge in LLMs.\nHowever, noisy knowledge and invalid reasoning issues hamper their ability to\nanswer questions accurately. To this end, we propose a novel method named\neliciting, filtering and integrating knowledge in large language model\n(LINKED). In it, we design a reward model to filter out the noisy knowledge and\ntake the marginal consistent reasoning module to reduce invalid reasoning. With\nour comprehensive experiments on two complex commonsense reasoning benchmarks,\nour method outperforms SOTA baselines (up to 9.0% improvement of accuracy).\nBesides, to measure the positive and negative impact of the injected knowledge,\nwe propose a new metric called effectiveness-preservation score for the\nknowledge enhancement works. Finally, through extensive experiments, we conduct\nan in-depth analysis and find many meaningful conclusions about LLMs in\ncommonsense reasoning tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u6709\u6642\u5728\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u4e0a\u8868\u73fe\u4e0d\u4f73\uff0c\u5e38\u8b58\u63a8\u7406\u5c31\u662f\u5176\u4e2d\u4e4b\u4e00\u3002\u7814\u7a76\u4eba\u54e1\u901a\u5e38\u901a\u904e\u5f9e\u77e5\u8b58\u5716\u8b5c\u4e2d\u6aa2\u7d22\u76f8\u95dc\u77e5\u8b58\u6216\u63a1\u7528\u81ea\u6211\u589e\u5f37\u65b9\u6cd5\u4f86\u5f15\u767c LLM \u4e2d\u7684\u77e5\u8b58\u4f86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\u3002\u7136\u800c\uff0c\u5608\u96dc\u7684\u77e5\u8b58\u548c\u7121\u6548\u7684\u63a8\u7406\u554f\u984c\u963b\u7919\u4e86\u5b83\u5011\u6e96\u78ba\u56de\u7b54\u554f\u984c\u7684\u80fd\u529b\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\u77e5\u8b58\u7684\u5f15\u51fa\u3001\u904e\u6ffe\u548c\u6574\u5408\uff08LINKED\uff09\u7684\u65b0\u65b9\u6cd5\u3002\u5728\u5176\u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u734e\u52f5\u6a21\u578b\u4f86\u904e\u6ffe\u6389\u5608\u96dc\u7684\u77e5\u8b58\uff0c\u4e26\u63a1\u7528\u908a\u969b\u4e00\u81f4\u63a8\u7406\u6a21\u7d44\u4f86\u6e1b\u5c11\u7121\u6548\u63a8\u7406\u3002\u901a\u904e\u6211\u5011\u5728\u5169\u500b\u8907\u96dc\u7684\u5e38\u8b58\u63a8\u7406\u57fa\u6e96\u4e0a\u7684\u5168\u9762\u5be6\u9a57\uff0c\u6211\u5011\u7684\u6a21\u578b\u512a\u65bc SOTA \u57fa\u6e96\uff08\u6e96\u78ba\u7387\u63d0\u9ad8\u4e86 9.0%\uff09\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u8861\u91cf\u6ce8\u5165\u77e5\u8b58\u7684\u6b63\u9762\u548c\u8ca0\u9762\u5f71\u97ff\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u6307\u6a19\uff0c\u7a31\u70ba\u77e5\u8b58\u589e\u5f37\u5de5\u4f5c\u7684\u6709\u6548\u6027\u4fdd\u7559\u5206\u6578\u3002\u6700\u5f8c\uff0c\u901a\u904e\u5927\u91cf\u7684\u5be6\u9a57\uff0c\u6211\u5011\u9032\u884c\u4e86\u6df1\u5165\u7684\u5206\u6790\uff0c\u4e26\u5728\u5e38\u8b58\u63a8\u7406\u4efb\u52d9\u4e2d\u767c\u73fe\u4e86\u8a31\u591a\u95dc\u65bc LLM \u7684\u6709\u610f\u7fa9\u7684\u7d50\u8ad6\u3002", "author": "Jiachun Li et.al.", "authors": "Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao", "id": "2410.09541v1", "paper_url": "http://arxiv.org/abs/2410.09541v1", "repo": "https://github.com/bugmakerzzz/linked_code"}}