{"2409.02474": {"publish_time": "2024-09-04", "title": "A Comparative Study on Large Language Models for Log Parsing", "paper_summary": "Background: Log messages provide valuable information about the status of\nsoftware systems. This information is provided in an unstructured fashion and\nautomated approaches are applied to extract relevant parameters. To ease this\nprocess, log parsing can be applied, which transforms log messages into\nstructured log templates. Recent advances in language models have led to\nseveral studies that apply ChatGPT to the task of log parsing with promising\nresults. However, the performance of other state-of-the-art large language\nmodels (LLMs) on the log parsing task remains unclear.\n  Aims: In this study, we investigate the current capability of\nstate-of-the-art LLMs to perform log parsing.\n  Method: We select six recent LLMs, including both paid proprietary (GPT-3.5,\nClaude 2.1) and four free-to-use open models, and compare their performance on\nsystem logs obtained from a selection of mature open-source projects. We design\ntwo different prompting approaches and apply the LLMs on 1, 354 log templates\nacross 16 different projects. We evaluate their effectiveness, in the number of\ncorrectly identified templates, and the syntactic similarity between the\ngenerated templates and the ground truth.\n  Results: We found that free-to-use models are able to compete with paid\nmodels, with CodeLlama extracting 10% more log templates correctly than\nGPT-3.5. Moreover, we provide qualitative insights into the usability of\nlanguage models (e.g., how easy it is to use their responses).\n  Conclusions: Our results reveal that some of the smaller, free-to-use LLMs\ncan considerably assist log parsing compared to their paid proprietary\ncompetitors, especially code-specialized models.", "paper_summary_zh": "<paragraph>\u80cc\u666f\uff1a\u8a18\u9304\u8a0a\u606f\u63d0\u4f9b\u6709\u95dc\u8edf\u9ad4\u7cfb\u7d71\u72c0\u614b\u7684\u5bf6\u8cb4\u8cc7\u8a0a\u3002\u6b64\u8cc7\u8a0a\u4ee5\u975e\u7d50\u69cb\u5316\u65b9\u5f0f\u63d0\u4f9b\uff0c\u4e26\u5957\u7528\u81ea\u52d5\u5316\u65b9\u6cd5\u4f86\u64f7\u53d6\u76f8\u95dc\u53c3\u6578\u3002\u70ba\u4e86\u7c21\u5316\u6b64\u6d41\u7a0b\uff0c\u53ef\u4ee5\u5957\u7528\u8a18\u9304\u5256\u6790\uff0c\u5c07\u8a18\u9304\u8a0a\u606f\u8f49\u63db\u6210\u7d50\u69cb\u5316\u7684\u8a18\u9304\u7bc4\u672c\u3002\u8a9e\u8a00\u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\u5df2\u5c0e\u81f4\u591a\u9805\u7814\u7a76\uff0c\u5c07 ChatGPT \u5957\u7528\u65bc\u8a18\u9304\u5256\u6790\u4efb\u52d9\uff0c\u4e26\u7372\u5f97\u6709\u5e0c\u671b\u7684\u7d50\u679c\u3002\u7136\u800c\uff0c\u5176\u4ed6\u6700\u5148\u9032\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8a18\u9304\u5256\u6790\u4efb\u52d9\u4e0a\u7684\u6548\u80fd\u4ecd\u4e0d\u6e05\u695a\u3002\n\u76ee\u6a19\uff1a\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u6700\u5148\u9032 LLM \u57f7\u884c\u8a18\u9304\u5256\u6790\u7684\u7576\u524d\u80fd\u529b\u3002\n\u65b9\u6cd5\uff1a\u6211\u5011\u9078\u51fa\u516d\u500b\u6700\u65b0\u7684 LLM\uff0c\u5305\u62ec\u4ed8\u8cbb\u5c08\u6709\uff08GPT-3.5\u3001Claude 2.1\uff09\u548c\u56db\u500b\u514d\u8cbb\u958b\u653e\u6a21\u578b\uff0c\u4e26\u6bd4\u8f03\u5b83\u5011\u5728\u5f9e\u4e00\u7cfb\u5217\u6210\u719f\u7684\u958b\u6e90\u5c08\u6848\u53d6\u5f97\u7684\u7cfb\u7d71\u8a18\u9304\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u8a2d\u8a08\u5169\u7a2e\u4e0d\u540c\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u4e26\u5c07 LLM \u5957\u7528\u65bc 16 \u500b\u4e0d\u540c\u5c08\u6848\u7684 1,354 \u500b\u8a18\u9304\u7bc4\u672c\u3002\u6211\u5011\u8a55\u4f30\u5176\u6709\u6548\u6027\uff0c\u5305\u62ec\u6b63\u78ba\u8fa8\u8b58\u7684\u7bc4\u672c\u6578\u91cf\uff0c\u4ee5\u53ca\u7522\u751f\u7684\u7bc4\u672c\u8207\u771f\u5be6\u7d50\u679c\u4e4b\u9593\u7684\u8a9e\u6cd5\u76f8\u4f3c\u6027\u3002\n\u7d50\u679c\uff1a\u6211\u5011\u767c\u73fe\u514d\u8cbb\u6a21\u578b\u80fd\u5920\u8207\u4ed8\u8cbb\u6a21\u578b\u7af6\u722d\uff0cCodeLlama \u6b63\u78ba\u64f7\u53d6\u7684\u8a18\u9304\u7bc4\u672c\u6bd4 GPT-3.5 \u591a 10%\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u8a9e\u8a00\u6a21\u578b\u53ef\u7528\u6027\u7684\u54c1\u8cea\u898b\u89e3\uff08\u4f8b\u5982\uff0c\u591a\u5bb9\u6613\u4f7f\u7528\u5176\u56de\u61c9\uff09\u3002\n\u7d50\u8ad6\uff1a\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u4e00\u4e9b\u8f03\u5c0f\u7684\u514d\u8cbb LLM \u8207\u4ed8\u8cbb\u5c08\u6709\u7af6\u722d\u8005\u76f8\u6bd4\uff0c\u53ef\u4ee5\u5927\u5e45\u5354\u52a9\u8a18\u9304\u5256\u6790\uff0c\u7279\u5225\u662f\u5c08\u9580\u7528\u65bc\u7a0b\u5f0f\u78bc\u7684\u6a21\u578b\u3002</paragraph>", "author": "Merve Astekin et.al.", "authors": "Merve Astekin, Max Hort, Leon Moonen", "id": "2409.02474v1", "paper_url": "http://arxiv.org/abs/2409.02474v1", "repo": "null"}}