{"2406.06443": {"publish_time": "2024-06-10", "title": "LLM Dataset Inference: Did you train on my dataset?", "paper_summary": "The proliferation of large language models (LLMs) in the real world has come\nwith a rise in copyright cases against companies for training their models on\nunlicensed data from the internet. Recent works have presented methods to\nidentify if individual text sequences were members of the model's training\ndata, known as membership inference attacks (MIAs). We demonstrate that the\napparent success of these MIAs is confounded by selecting non-members (text\nsequences not used for training) belonging to a different distribution from the\nmembers (e.g., temporally shifted recent Wikipedia articles compared with ones\nused to train the model). This distribution shift makes membership inference\nappear successful. However, most MIA methods perform no better than random\nguessing when discriminating between members and non-members from the same\ndistribution (e.g., in this case, the same period of time). Even when MIAs\nwork, we find that different MIAs succeed at inferring membership of samples\nfrom different distributions. Instead, we propose a new dataset inference\nmethod to accurately identify the datasets used to train large language models.\nThis paradigm sits realistically in the modern-day copyright landscape, where\nauthors claim that an LLM is trained over multiple documents (such as a book)\nwritten by them, rather than one particular paragraph. While dataset inference\nshares many of the challenges of membership inference, we solve it by\nselectively combining the MIAs that provide positive signal for a given\ndistribution, and aggregating them to perform a statistical test on a given\ndataset. Our approach successfully distinguishes the train and test sets of\ndifferent subsets of the Pile with statistically significant p-values < 0.1,\nwithout any false positives.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u6fc0\u589e\uff0c\u5c0e\u81f4\u5c0d\u516c\u53f8\u4f7f\u7528\u672a\u7d93\u6388\u6b0a\u7684\u7db2\u8def\u8cc7\u6599\u8a13\u7df4\u6a21\u578b\u7684\u8457\u4f5c\u6b0a\u6848\u4ef6\u589e\u52a0\u3002\u6700\u8fd1\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u65b9\u6cd5\u4f86\u8b58\u5225\u500b\u5225\u6587\u5b57\u5e8f\u5217\u662f\u5426\u70ba\u6a21\u578b\u8a13\u7df4\u8cc7\u6599\u7684\u6210\u54e1\uff0c\u7a31\u70ba\u6210\u54e1\u8eab\u5206\u63a8\u8ad6\u653b\u64ca (MIA)\u3002\u6211\u5011\u8b49\u660e\u4e86\u9019\u4e9b MIA \u7684\u660e\u986f\u6210\u529f\u662f\u56e0\u70ba\u9078\u64c7\u4e86\u4e0d\u5c6c\u65bc\u6210\u54e1\u7684\u975e\u6210\u54e1\uff08\u672a\u7528\u65bc\u8a13\u7df4\u7684\u6587\u5b57\u5e8f\u5217\uff09\uff0c\u9019\u4e9b\u975e\u6210\u54e1\u4f86\u81ea\u8207\u6210\u54e1\u4e0d\u540c\u7684\u5206\u4f48\uff08\u4f8b\u5982\uff0c\u8207\u7528\u65bc\u8a13\u7df4\u6a21\u578b\u7684\u7dad\u57fa\u767e\u79d1\u6587\u7ae0\u76f8\u6bd4\uff0c\u6642\u9593\u4e0a\u6709\u6240\u63a8\u79fb\u7684\u8fd1\u671f\u7dad\u57fa\u767e\u79d1\u6587\u7ae0\uff09\u3002\u9019\u7a2e\u5206\u4f48\u8f49\u79fb\u4f7f\u5f97\u6210\u54e1\u8eab\u5206\u63a8\u8ad6\u770b\u8d77\u4f86\u5f88\u6210\u529f\u3002\u7136\u800c\uff0c\u5927\u591a\u6578 MIA \u65b9\u6cd5\u5728\u5340\u5206\u4f86\u81ea\u76f8\u540c\u5206\u4f48\u7684\u6210\u54e1\u548c\u975e\u6210\u54e1\u6642\uff0c\u8868\u73fe\u4e0d\u6bd4\u96a8\u6a5f\u731c\u6e2c\u597d\uff08\u4f8b\u5982\uff0c\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u76f8\u540c\u6642\u9593\u6bb5\uff09\u3002\u5373\u4f7f MIA \u6709\u6548\uff0c\u6211\u5011\u4e5f\u767c\u73fe\u4e0d\u540c\u7684 MIA \u6210\u529f\u63a8\u8ad6\u4f86\u81ea\u4e0d\u540c\u5206\u4f48\u7684\u6a23\u672c\u7684\u8eab\u5206\u3002\u76f8\u53cd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u8cc7\u6599\u96c6\u63a8\u8ad6\u65b9\u6cd5\u4f86\u6e96\u78ba\u8b58\u5225\u7528\u65bc\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u8cc7\u6599\u96c6\u3002\u9019\u7a2e\u7bc4\u4f8b\u5207\u5408\u5be6\u969b\u5730\u5b58\u5728\u65bc\u73fe\u4ee3\u7684\u8457\u4f5c\u6b0a\u74b0\u5883\u4e2d\uff0c\u5728\u9019\u7a2e\u74b0\u5883\u4e2d\uff0c\u4f5c\u8005\u8072\u7a31 LLM \u662f\u6839\u64da\u4ed6\u5011\u64b0\u5beb\u7684\u591a\u500b\u6587\u4ef6\uff08\u4f8b\u5982\u4e00\u672c\u66f8\uff09\u9032\u884c\u8a13\u7df4\uff0c\u800c\u4e0d\u662f\u7279\u5b9a\u6bb5\u843d\u3002\u96d6\u7136\u8cc7\u6599\u96c6\u63a8\u8ad6\u8207\u6210\u54e1\u8eab\u5206\u63a8\u8ad6\u6709\u8a31\u591a\u76f8\u540c\u7684\u6311\u6230\uff0c\u4f46\u6211\u5011\u900f\u904e\u9078\u64c7\u6027\u5730\u7d50\u5408\u5c0d\u7279\u5b9a\u5206\u4f48\u63d0\u4f9b\u6b63\u5411\u8a0a\u865f\u7684 MIA\uff0c\u4e26\u5c07\u5b83\u5011\u5f59\u7e3d\u8d77\u4f86\u5c0d\u7279\u5b9a\u8cc7\u6599\u96c6\u57f7\u884c\u7d71\u8a08\u6aa2\u5b9a\uff0c\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u7684\u505a\u6cd5\u6210\u529f\u5340\u5206\u4e86 Pile \u4e0d\u540c\u5b50\u96c6\u7684\u8a13\u7df4\u96c6\u548c\u6e2c\u8a66\u96c6\uff0c\u4e14\u5177\u6709\u7d71\u8a08\u986f\u8457\u6027 p \u503c < 0.1\uff0c\u6c92\u6709\u4efb\u4f55\u8aa4\u5831\u3002</paragraph>", "author": "Pratyush Maini et.al.", "authors": "Pratyush Maini, Hengrui Jia, Nicolas Papernot, Adam Dziedzic", "id": "2406.06443v1", "paper_url": "http://arxiv.org/abs/2406.06443v1", "repo": "https://github.com/pratyushmaini/llm_dataset_inference"}}