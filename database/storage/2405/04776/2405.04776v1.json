{"2405.04776": {"publish_time": "2024-05-08", "title": "Chain of Thoughtlessness: An Analysis of CoT in Planning", "paper_summary": "Large language model (LLM) performance on reasoning problems typically does\nnot generalize out of distribution. Previous work has claimed that this can be\nmitigated by modifying prompts to include examples with chains of\nthought--demonstrations of solution procedures--with the intuition that it is\npossible to in-context teach an LLM an algorithm for solving the problem. This\npaper presents a case study of chain of thought on problems from Blocksworld, a\nclassical planning domain, and examine the performance of two state-of-the-art\nLLMs across two axes: generality of examples given in prompt, and complexity of\nproblems queried with each prompt. While our problems are very simple, we only\nfind meaningful performance improvements from chain of thought prompts when\nthose prompts are exceedingly specific to their problem class, and that those\nimprovements quickly deteriorate as the size n of the query-specified stack\ngrows past the size of stacks shown in the examples. Our results hint that,\ncontrary to previous claims in the literature, CoT's performance improvements\ndo not stem from the model learning general algorithmic procedures via\ndemonstrations and depend on carefully engineering highly problem specific\nprompts. This spotlights drawbacks of chain of thought, especially because of\nthe sharp tradeoff between possible performance gains and the amount of human\nlabor necessary to generate examples with correct reasoning traces.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u63a8\u7406\u554f\u984c\u4e0a\u7684\u8868\u73fe\u901a\u5e38\u4e0d\u6703\u63a8\u5ee3\u5230\u5206\u5e03\u4e4b\u5916\u3002\u5148\u524d\u7684\u7814\u7a76\u8072\u7a31\uff0c\u9019\u53ef\u4ee5\u7528\u4fee\u6539\u63d0\u793a\u4f86\u7de9\u89e3\uff0c\u5176\u4e2d\u5305\u62ec\u5e36\u6709\u601d\u8003\u93c8\u7684\u7bc4\u4f8b\u2014\u2014\u89e3\u6c7a\u7a0b\u5e8f\u7684\u793a\u7bc4\u2014\u2014\u76f4\u89ba\u4e0a\u8a8d\u70ba\u53ef\u4ee5\u91dd\u5c0d\u7279\u5b9a\u554f\u984c\u5728\u4e0a\u4e0b\u6587\u4e2d\u6559\u6388 LLM \u4e00\u7a2e\u6f14\u7b97\u6cd5\u3002\u672c\u6587\u91dd\u5c0d\u5340\u584a\u4e16\u754c\u554f\u984c\u7684\u601d\u8003\u93c8\u9032\u884c\u500b\u6848\u7814\u7a76\uff0c\u5340\u584a\u4e16\u754c\u662f\u4e00\u500b\u7d93\u5178\u7684\u898f\u5283\u9818\u57df\uff0c\u4e26\u5728\u5169\u500b\u8ef8\u7dda\u4e0a\u6aa2\u9a57\u5169\u500b\u6700\u5148\u9032\u7684 LLM \u7684\u8868\u73fe\uff1a\u63d0\u793a\u4e2d\u63d0\u4f9b\u7684\u7bc4\u4f8b\u7684\u4e00\u822c\u6027\uff0c\u4ee5\u53ca\u4f7f\u7528\u6bcf\u500b\u63d0\u793a\u67e5\u8a62\u7684\u554f\u984c\u7684\u8907\u96dc\u6027\u3002\u96d6\u7136\u6211\u5011\u7684\u554f\u984c\u975e\u5e38\u7c21\u55ae\uff0c\u4f46\u6211\u5011\u53ea\u5728\u601d\u8003\u93c8\u63d0\u793a\u6975\u5176\u7279\u5b9a\u65bc\u5176\u554f\u984c\u985e\u5225\u6642\uff0c\u624d\u767c\u73fe\u6709\u610f\u7fa9\u7684\u6548\u80fd\u63d0\u5347\uff0c\u800c\u4e14\u96a8\u8457\u67e5\u8a62\u6307\u5b9a\u7684\u5806\u758a\u5927\u5c0f n \u8d85\u904e\u7bc4\u4f8b\u4e2d\u986f\u793a\u7684\u5806\u758a\u5927\u5c0f\uff0c\u9019\u4e9b\u63d0\u5347\u6703\u8fc5\u901f\u60e1\u5316\u3002\u6211\u5011\u7684\u7d50\u679c\u6697\u793a\uff0c\u8207\u6587\u737b\u4e2d\u5148\u524d\u7684\u8aaa\u6cd5\u76f8\u53cd\uff0c\u601d\u8003\u93c8\u7684\u6548\u80fd\u63d0\u5347\u4e26\u975e\u6e90\u65bc\u6a21\u578b\u900f\u904e\u793a\u7bc4\u5b78\u7fd2\u4e00\u822c\u6f14\u7b97\u6cd5\u7a0b\u5e8f\uff0c\u800c\u662f\u53d6\u6c7a\u65bc\u4ed4\u7d30\u8a2d\u8a08\u9ad8\u5ea6\u7279\u5b9a\u65bc\u554f\u984c\u7684\u63d0\u793a\u3002\u9019\u7a81\u986f\u4e86\u601d\u8003\u93c8\u7684\u7f3a\u9ede\uff0c\u7279\u5225\u662f\u56e0\u70ba\u5728\u53ef\u80fd\u7684\u6548\u80fd\u63d0\u5347\u8207\u7522\u751f\u5177\u6709\u6b63\u78ba\u63a8\u7406\u8ffd\u8e64\u7684\u7bc4\u4f8b\u6240\u9700\u7684\u4eba\u529b\u4e4b\u9593\u5b58\u5728\u986f\u8457\u7684\u6b0a\u8861\u3002", "author": "Kaya Stechly et.al.", "authors": "Kaya Stechly, Karthik Valmeekam, Subbarao Kambhampati", "id": "2405.04776v1", "paper_url": "http://arxiv.org/abs/2405.04776v1", "repo": "null"}}