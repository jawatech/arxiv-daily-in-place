# arxiv-daily
 Automated deployment @ 2025-01-17 09:07:44 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v1](http://arxiv.org/abs/2501.08977v1)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**|Rewina Bedemariam et.al.|[2501.08167v1](http://arxiv.org/abs/2501.08167v1)|null|
|**2025-01-14**|**FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**|Nurit Cohen-Inger et.al.|[2501.08155v1](http://arxiv.org/abs/2501.08155v1)|null|
|**2025-01-14**|**Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**|E. Sarfati et.al.|[2501.08097v1](http://arxiv.org/abs/2501.08097v1)|null|
|**2025-01-14**|**Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**|Alvaro Pastor-Naranjo et.al.|[2501.08042v1](http://arxiv.org/abs/2501.08042v1)|null|
|**2025-01-14**|**Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**|Wentao Cui et.al.|[2501.07970v1](http://arxiv.org/abs/2501.07970v1)|null|
|**2025-01-14**|**Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**|Waqar Hussain et.al.|[2501.07931v1](http://arxiv.org/abs/2501.07931v1)|null|
|**2025-01-13**|**Large Language Models for Interpretable Mental Health Diagnosis**|Brian Hyeongseok Kim et.al.|[2501.07653v1](http://arxiv.org/abs/2501.07653v1)|null|
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**|Xuhui Guo et.al.|[2501.07017v1](http://arxiv.org/abs/2501.07017v1)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|
|**2025-01-12**|**PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**|Zhonghao Yan et.al.|[2501.06692v1](http://arxiv.org/abs/2501.06692v1)|null|
|**2025-01-12**|**Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**|Erjian Guo et.al.|[2501.06678v1](http://arxiv.org/abs/2501.06678v1)|[link](https://github.com/erjian96/clcs)|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v1](http://arxiv.org/abs/2501.06465v1)|null|
|**2025-01-11**|**Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**|Hojjat Salehinejad et.al.|[2501.06432v1](http://arxiv.org/abs/2501.06432v1)|null|
|**2025-01-10**|**Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**|Elizabeth Schaefer et.al.|[2501.06365v1](http://arxiv.org/abs/2501.06365v1)|null|
|**2025-01-10**|**Scale-up Unlearnable Examples Learning with High-Performance Computing**|Yanfan Zhu et.al.|[2501.06080v1](http://arxiv.org/abs/2501.06080v1)|[link](https://github.com/hrlblab/ue_hpc)|
|**2025-01-10**|**AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**|Johann Wenckstern et.al.|[2501.06039v1](http://arxiv.org/abs/2501.06039v1)|[link](https://github.com/bunnelab/virtues)|
|**2025-01-10**|**DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**|Yongfan Lai et.al.|[2501.05932v1](http://arxiv.org/abs/2501.05932v1)|[link](https://github.com/raiiyf/diffusets_exp)|
|**2025-01-10**|**AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**|Amit Kr Dey et.al.|[2501.05826v2](http://arxiv.org/abs/2501.05826v2)|null|
|**2025-01-10**|**Large Language Models for Bioinformatics**|Wei Ruan et.al.|[2501.06271v1](http://arxiv.org/abs/2501.06271v1)|null|
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Haozhi Qi et.al.|[2501.05439v1](http://arxiv.org/abs/2501.05439v1)|null|
|**2025-01-09**|**Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**|Jonathan Keane et.al.|[2501.05501v1](http://arxiv.org/abs/2501.05501v1)|null|
|**2025-01-09**|**Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charit√©, and Aignostics**|Maximilian Alber et.al.|[2501.05409v2](http://arxiv.org/abs/2501.05409v2)|null|
|**2025-01-09**|**An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**|Drago Plecko et.al.|[2501.05197v1](http://arxiv.org/abs/2501.05197v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|[link](https://github.com/yinghemedical/imbalance-aware_domain_adaptation)|
|**2025-01-09**|**Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**|Michail Ouroutzoglou et.al.|[2501.04896v1](http://arxiv.org/abs/2501.04896v1)|null|
|**2025-01-08**|**MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**|Daniele Molino et.al.|[2501.04614v2](http://arxiv.org/abs/2501.04614v2)|null|
|**2025-01-08**|**A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**|Zephan M. Enciso et.al.|[2501.04577v1](http://arxiv.org/abs/2501.04577v1)|null|
|**2025-01-08**|**Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**|Ren Tasai et.al.|[2501.04217v1](http://arxiv.org/abs/2501.04217v1)|null|
|**2025-01-07**|**Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**|Rancy Chepchirchir et.al.|[2501.04734v1](http://arxiv.org/abs/2501.04734v1)|[link](https://github.com/CAMERA-MRI/SPARK2023/tree/main/SPARK_BTS_KIFARU)|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v2](http://arxiv.org/abs/2501.03836v2)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**|Susu Sun et.al.|[2501.02922v1](http://arxiv.org/abs/2501.02922v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2025-01-06**|**IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**|Yiming Zhang et.al.|[2501.02869v1](http://arxiv.org/abs/2501.02869v1)|null|
|**2025-01-06**|**Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**|Naibo Wang et.al.|[2501.03292v1](http://arxiv.org/abs/2501.03292v1)|null|
|**2025-01-06**|**GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**|Niloufar Eghbali et.al.|[2501.02788v2](http://arxiv.org/abs/2501.02788v2)|[link](https://github.com/haail/glog-csunet)|
|**2025-01-06**|**Hybrid deep convolution model for lung cancer detection with transfer learning**|Sugandha Saxena et.al.|[2501.02785v1](http://arxiv.org/abs/2501.02785v1)|null|
|**2025-01-06**|**ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**|Binyu Zhang et.al.|[2501.02778v1](http://arxiv.org/abs/2501.02778v1)|[link](https://github.com/binging512/icfnet)|
|**2025-01-06**|**Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**|Yahe Yang et.al.|[2501.02727v1](http://arxiv.org/abs/2501.02727v1)|null|
|**2025-01-05**|**Representation Learning of Lab Values via Masked AutoEncoder**|David Restrepo et.al.|[2501.02648v2](http://arxiv.org/abs/2501.02648v2)|[link](https://github.com/dsrestrepo/lab-mae-foundation-tabular)|
|**2025-01-05**|**Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**|Ellis Solaiman et.al.|[2501.02647v1](http://arxiv.org/abs/2501.02647v1)|null|
|**2025-01-05**|**KM-UNet KAN Mamba UNet for medical image segmentation**|Yibo Zhang et.al.|[2501.02559v1](http://arxiv.org/abs/2501.02559v1)|[link](https://github.com/2760613195/km_unet)|
|**2025-01-05**|**Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**|Yishen Liu et.al.|[2501.02471v1](http://arxiv.org/abs/2501.02471v1)|null|
|**2025-01-05**|**Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**|Zijie Cheng et.al.|[2501.02451v1](http://arxiv.org/abs/2501.02451v1)|null|
|**2025-01-04**|**Enhancing Workplace Productivity and Well-being Using AI Agent**|Ravirajan K et.al.|[2501.02368v1](http://arxiv.org/abs/2501.02368v1)|null|
|**2025-01-04**|**Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**|Florian Putz et.al.|[2501.02346v1](http://arxiv.org/abs/2501.02346v1)|null|
|**2025-01-04**|**Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**|Ashiqur Rahman et.al.|[2501.02287v1](http://arxiv.org/abs/2501.02287v1)|null|
|**2025-01-04**|**The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**|Umar Safdar et.al.|[2501.02169v1](http://arxiv.org/abs/2501.02169v1)|null|
|**2025-01-03**|**Online Detection of Water Contamination Under Concept Drift**|Jin Li et.al.|[2501.02107v1](http://arxiv.org/abs/2501.02107v1)|null|
|**2025-01-03**|**METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**|Ollie Liu et.al.|[2501.02045v1](http://arxiv.org/abs/2501.02045v1)|null|
|**2025-01-03**|**Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**|Jianping He et.al.|[2501.02044v1](http://arxiv.org/abs/2501.02044v1)|null|
|**2025-01-03**|**Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**|Shivom Aggarwal et.al.|[2501.01732v1](http://arxiv.org/abs/2501.01732v1)|null|
|**2025-01-03**|**EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**|Wang Lituan et.al.|[2501.01658v1](http://arxiv.org/abs/2501.01658v1)|null|
|**2025-01-03**|**Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**|Ahmad Momani et.al.|[2501.01639v2](http://arxiv.org/abs/2501.01639v2)|null|
|**2025-01-03**|**Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**|Yun Zhu et.al.|[2501.01618v1](http://arxiv.org/abs/2501.01618v1)|[link](https://github.com/zymissy/ccvim)|
|**2025-01-03**|**PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**|Jingoo Lee et.al.|[2501.01594v1](http://arxiv.org/abs/2501.01594v1)|null|
|**2025-01-02**|**Model Checking in Medical Imaging for Tumor Detection and Segmentation**|Elhoucine Elfatimi et.al.|[2501.02024v2](http://arxiv.org/abs/2501.02024v2)|null|
|**2025-01-02**|**Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**|Yucheng Zhou et.al.|[2501.01377v1](http://arxiv.org/abs/2501.01377v1)|null|
|**2025-01-02**|**ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**|Neda Tavakoli et.al.|[2501.01372v1](http://arxiv.org/abs/2501.01372v1)|[link](https://github.com/nedatavakoli/scarnet)|
|**2025-01-02**|**Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**|Nathaniel Dennler et.al.|[2501.01367v1](http://arxiv.org/abs/2501.01367v1)|null|
|**2025-01-02**|**Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**|Bohang Sun et.al.|[2501.01311v2](http://arxiv.org/abs/2501.01311v2)|null|
|**2025-01-02**|**Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**|Masahiro Matsumoto et.al.|[2501.02014v1](http://arxiv.org/abs/2501.02014v1)|null|
|**2025-01-02**|**Data Augmentation Techniques for Chinese Disease Name Normalization**|Wenqian Cui et.al.|[2501.01195v1](http://arxiv.org/abs/2501.01195v1)|[link](https://github.com/dreamtheater123/disease_name_dataset)|
|**2025-01-02**|**Reasoning based on symbolic and parametric knowledge bases: a survey**|Mayi Xu et.al.|[2501.01030v1](http://arxiv.org/abs/2501.01030v1)|null|
|**2025-01-02**|**Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**|Federico Ravenda et.al.|[2501.00982v1](http://arxiv.org/abs/2501.00982v1)|[link](https://github.com/fede-stack/adaptive-rag-for-psychological-assessment)|
|**2025-01-01**|**Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**|Sagarnil Das et.al.|[2501.00954v1](http://arxiv.org/abs/2501.00954v1)|null|
|**2025-01-01**|**Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**|Yang Qi et.al.|[2501.02000v1](http://arxiv.org/abs/2501.02000v1)|[link](https://github.com/xiaqi7/fetal-ultrasound)|
|**2024-12-31**|**Efficient Standardization of Clinical Notes using Large Language Models**|Daniel B. Hier et.al.|[2501.00644v1](http://arxiv.org/abs/2501.00644v1)|null|
|**2024-12-31**|**LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models**|Hang Yang et.al.|[2501.05464v1](http://arxiv.org/abs/2501.05464v1)|null|
|**2024-12-31**|**Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**|Lingrui Zhang et.al.|[2501.01462v1](http://arxiv.org/abs/2501.01462v1)|null|
|**2024-12-31**|**A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**|Lahcen El Fatimi et.al.|[2501.01991v1](http://arxiv.org/abs/2501.01991v1)|null|
|**2024-12-31**|**GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**|George Yuanji Wang et.al.|[2501.01458v1](http://arxiv.org/abs/2501.01458v1)|[link](https://github.com/george-yuanji-wang/gan-tat)|
|**2024-12-31**|**Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**|Haibo Tong et.al.|[2501.00320v2](http://arxiv.org/abs/2501.00320v2)|[link](https://github.com/braincog-x/brain-cog)|
|**2024-12-31**|**A Systematic Review of Machine Learning Methods for Multimodal EEG Data in Clinical Application**|Siqi Zhao et.al.|[2501.08585v1](http://arxiv.org/abs/2501.08585v1)|null|
|**2024-12-31**|**A Fourfold Pathogen Reference Ontology Suite**|Shane Babcock et.al.|[2501.01454v1](http://arxiv.org/abs/2501.01454v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**An Empirical Evaluation of Large Language Models on Consumer Health Questions**|Moaiz Abrar et.al.|[2501.00208v1](http://arxiv.org/abs/2501.00208v1)|null|
|**2024-12-31**|**GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**|Giuliano Lorenzoni et.al.|[2501.00199v1](http://arxiv.org/abs/2501.00199v1)|null|
|**2024-12-31**|**SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**|Changchang Yin et.al.|[2501.00190v2](http://arxiv.org/abs/2501.00190v2)|[link](https://github.com/yinchangchang/sepsiscalc)|

#### Abstracts
##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v1 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high- versus low-quality summaries for discriminant validity. Seven
physician raters evaluated 779 summaries and answered 8,329 questions,
achieving over 80% power for inter-rater reliability. The PDSQI-9 demonstrated
strong internal consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and
high inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized (rho = -0.190, p = 0.037). Discriminant validity distinguished high-
from low-quality summaries (p < 0.001). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÔºåÈ©óË≠âÂ∑•ÂÖ∑Â∞çÊñºÂú®ÂØ¶ÊñΩÂâçË©ï‰º∞ÂÖ∂ÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÊèê‰æõËÄÖÊñá‰ª∂ÂìÅË≥™Â∑•ÂÖ∑ÈÄöÂ∏∏‰∏çÈÅ©Âêà LLM ÁîüÊàêÁöÑÊñáÂ≠óË§áÈõúÊÄßÔºå‰∏îÁº∫‰πèÂ∞çÁúüÂØ¶‰∏ñÁïåË≥áÊñôÁöÑÈ©óË≠â„ÄÇÊèê‰æõËÄÖÊñá‰ª∂ÊëòË¶ÅÂìÅË≥™Â∑•ÂÖ∑ (PDSQI-9) ÁöÑÈñãÁôºÁõÆÁöÑÊòØË©ï‰º∞ LLM ÁîüÊàêÁöÑËá®Â∫äÊëòË¶Å„ÄÇ‰ΩøÁî®Â§öÂÄã LLMÔºàGPT-4o„ÄÅMixtral 8x7b Âíå Llama 3-8bÔºâÂæûË∑®Â§öÂÄãÂ∞àÁßëÁöÑÁúüÂØ¶‰∏ñÁïå EHR Ë≥áÊñô‰∏≠Áî¢ÁîüÂ§öÊñá‰ª∂ÊëòË¶Å„ÄÇÈ©óË≠âÂåÖÊã¨ÂØ¶Ë≥™ÊïàÂ∫¶ÁöÑÁöÆÁàæÊ£ÆÁõ∏Èóú‰øÇÊï∏„ÄÅÁµêÊßãÊïàÂ∫¶ÁöÑÂõ†Â≠êÂàÜÊûêÂíåÂÖãÊúóÂ∑¥Ëµ´ Œ± ‰øÇÊï∏„ÄÅÊ¶ÇÊã¨ÊÄßÁöÑË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÔºàICC ÂíåÂÖãÈáåÂΩ≠Â§öÂ§´ Œ± ‰øÇÊï∏Ôºâ„ÄÅÂÖßÂÆπÊïàÂ∫¶ÁöÑÂçäÂæ∑ÁàæËè≤Á®ãÂ∫èÔºå‰ª•ÂèäÁî®ÊñºÂà§Âà•ÊïàÂ∫¶ÁöÑÂÑ™Ë≥™ËàáÂä£Ë≥™ÊëòË¶ÅÊØîËºÉ„ÄÇ‰∏É‰ΩçÈÜ´Â∏´Ë©ïÂàÜËÄÖË©ï‰º∞‰∫Ü 779 ‰ªΩÊëòË¶Å‰∏¶ÂõûÁ≠î‰∫Ü 8,329 ÂÄãÂïèÈ°åÔºåË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÈÅîÂà∞ 80% ‰ª•‰∏ä„ÄÇPDSQI-9 Ë°®ÁèæÂá∫Âº∑Â§ßÁöÑÂÖßÈÉ®‰∏ÄËá¥ÊÄßÔºàÂÖãÊúóÂ∑¥Ëµ´ Œ± ‰øÇÊï∏ = 0.879Ôºõ95% CIÔºö0.867-0.891ÔºâÂíåÈ´òË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÔºàICC = 0.867Ôºõ95% CIÔºö0.867-0.868ÔºâÔºåÊîØÊåÅÁµêÊßãÊïàÂ∫¶ÂíåÊ¶ÇÊã¨ÊÄß„ÄÇÂõ†Â≠êÂàÜÊûêËæ®Ë≠òÂá∫‰∏ÄÂÄã 4 Âõ†Â≠êÊ®°ÂûãÔºåËß£Èáã‰∫Ü 58% ÁöÑËÆäÁï∞Ôºå‰ª£Ë°®ÁµÑÁπî„ÄÅÊ∏ÖÊô∞Â∫¶„ÄÅÊ∫ñÁ¢∫ÊÄßÂíåÂØ¶Áî®ÊÄß„ÄÇÂØ¶Ë≥™ÊïàÂ∫¶ÂèóÂà∞ÊëòË¶ÅÈï∑Â∫¶ËàáÁ∞°ÊΩîÔºàrho = -0.200Ôºåp = 0.029ÔºâÂíåÁµÑÁπîÔºàrho = -0.190Ôºåp = 0.037ÔºâÂàÜÊï∏‰πãÈñìÁõ∏ÈóúÊÄßÁöÑÊîØÊåÅ„ÄÇÂà§Âà•ÊïàÂ∫¶ÂçÄÂàÜ‰∫ÜÂÑ™Ë≥™ÂíåÂä£Ë≥™ÊëòË¶ÅÔºàp < 0.001Ôºâ„ÄÇPDSQI-9 Ë°®ÁèæÂá∫Á©©ÂÅ•ÁöÑÂª∫ÊßãÊïàÂ∫¶ÔºåÊîØÊåÅÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠‰ΩøÁî®ÂÆÉ‰æÜË©ï‰º∞ LLM ÁîüÊàêÁöÑÊëòË¶ÅÔºå‰∏¶‰øÉÈÄ≤ LLM Êõ¥ÂÆâÂÖ®ÁöÑÊï¥ÂêàÂà∞ÈÜ´ÁôÇ‰øùÂÅ•Â∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇ

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, Jos√© Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, √ârico Moutinho, J√©ssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

ÊëòË¶ÅÔºöAI ÊºîÁÆóÊ≥ïÂ∑≤ÊàêÁÇ∫ÂçîÂä©ÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÁöÑÂØ∂Ë≤¥Â∑•ÂÖ∑„ÄÇÈÄô‰∫õÊ®°ÂûãÁç≤ÂæóÁöÑ‰ø°ÂøÉÊó•ÁõäÊèêÂçáÔºåÊúâÂä©ÊñºÈóúÈçµÊ±∫Á≠ñÈúÄÊ±Ç„ÄÇÂú®Ëá®Â∫äÁöÆËÜöÁßëÔºåÂàÜÈ°ûÊ®°ÂûãÂÉÖ‰ΩøÁî® RGB ÂΩ±ÂÉè‰ΩúÁÇ∫Ëº∏ÂÖ•ÔºåÂç≥ÂèØÂÅµÊ∏¨ÊÇ£ËÄÖÁöÆËÜö‰∏äÁöÑÊÉ°ÊÄßÁóÖÁÅ∂„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Âü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÊé°Áî®ÂæûÁöÆËÜöÈè°Ë≥áÊñôÈõÜÂèñÂæóÁöÑË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÔºåÈÄô‰∫õË≥áÊñôÈõÜÈæêÂ§ß‰∏îÂ∑≤ÈÄöÈÅéÈáëÊ®ôÊ∫ñÈ©óË≠â„ÄÇËá®Â∫äÊ®°ÂûãÊó®Âú®ËôïÁêÜ‰ΩøÁî®ËÄÖÊô∫ÊÖßÂûãÊâãÊ©üÁõ∏Ê©ü‰∏äÁöÑÂàÜÈ°ûÔºåÈÄô‰∫õÁõ∏Ê©ü‰∏çÂåÖÂê´ÁöÆËÜöÈè°Êèê‰æõÁöÑÂ∞çÊáâËß£ÊûêÂ∫¶„ÄÇÊ≠§Â§ñÔºåËá®Â∫äÊáâÁî®Á®ãÂºèÂ∏∂‰æÜÊñ∞ÁöÑÊåëÊà∞„ÄÇÂÆÉÂèØËÉΩÂåÖÂê´‰æÜËá™‰∏çÂèóÊéßÁí∞Â¢ÉÁöÑÊì∑Âèñ„ÄÅËÜöËâ≤ËÆäÂåñ„ÄÅË¶ñÈªûËÆäÊõ¥„ÄÅË≥áÊñôÂíåÊ®ôÁ±§‰∏≠ÁöÑÈõúË®äÔºå‰ª•Âèä‰∏çÂπ≥Ë°°ÁöÑÈ°ûÂà•„ÄÇ‰∏ÄÁ®ÆÂèØËÉΩÁöÑÊõø‰ª£ÊñπÊ°àÊòØ‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏Áøí‰æÜËôïÁêÜËá®Â∫äÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ®£Êú¨Êï∏ÈáèÂ∞ëÔºåÂèØËÉΩÊúÉÂ∞éËá¥Ê®°ÂûãÊïàËÉΩ‰∏ãÈôçÔºõË®ìÁ∑¥‰∏≠‰ΩøÁî®ÁöÑ‰æÜÊ∫êÂàÜ‰ΩàËàáÊ∏¨Ë©¶ÈõÜ‰∏çÂêå„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Ë©ï‰º∞ÁöÆËÜöÈè°ÂíåËá®Â∫äÊ®£Êú¨‰πãÈñìÁöÑÂ∑ÆË∑ùÔºå‰∏¶‰∫ÜËß£Ë≥áÊñôÈõÜËÆäÂåñÂ¶Ç‰ΩïÂΩ±ÈüøË®ìÁ∑¥„ÄÇÂÆÉË©ï‰º∞ÊúÉÂπ≤ÊìæÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰∏ªË¶ÅÂàÜ‰ΩàÂ∑ÆÁï∞„ÄÇÊúÄÂæåÔºåÂæû‰∏çÂêåÊû∂ÊßãÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëË´ñË≠âÂ¶Ç‰ΩïÁµêÂêà‰æÜËá™‰∏çÂêåÂàÜ‰ΩàÁöÑË≥áÊñôÔºåÈôç‰ΩéÂ∞çÊ®°ÂûãÊúÄÁµÇÊ∫ñÁ¢∫Â∫¶ÁöÑÂΩ±Èüø„ÄÇ

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÈùíÂ∞ëÂπ¥ÁâπÂà´ÂÆπÊòìÁΩπÊÇ£Á≤æÁ•ûÁñæÁóÖÔºå75% ‰ª•‰∏äÁöÑÁóÖ‰æãÂú® 25 Â≤Å‰πãÂâçÊòæÁé∞„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂè™Êúâ 18% Âà∞ 34% ÁªèÂéÜÈ´òÂ∫¶ÊäëÈÉÅÊàñÁÑ¶ËôëÁóáÁä∂ÁöÑÂπ¥ËΩª‰∫∫ÂØªÊ±ÇÊîØÊåÅ„ÄÇÂà©Áî®Êô∫ËÉΩÊâãÊú∫ÁöÑÊï∞‰ΩçÂ∑•ÂÖ∑Êèê‰æõÂèØÊâ©Â±ïÁöÑÊó©Êúü‰ªãÂÖ•Êú∫‰ºö„ÄÇÁõÆÊ†áÔºöÊú¨Á†îÁ©∂‰ΩøÁî®Êñ∞È¢ñÁöÑÊú∫Âô®Â≠¶‰π†Ê°ÜÊû∂ÔºåËØÑ‰º∞Â∞Ü‰∏ªÂä®ÂíåË¢´Âä®Êô∫ËÉΩÊâãÊú∫Êï∞ÊçÆÊï¥ÂêàÊù•È¢ÑÊµãÈùû‰∏¥Â∫äÈùíÂ∞ëÂπ¥Á≤æÁ•ûÁñæÁóÖÁöÑÂèØË°åÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫Ü Mindcraft Â∫îÁî®Á®ãÂ∫èÂú®È¢ÑÊµãÂÜÖÂåñÂíåÂ§ñÂåñÈöúÁ¢ç„ÄÅÈ•ÆÈ£üÂ§±Ë∞É„ÄÅÂ§±Áú†ÂíåËá™ÊùÄÊÑèÂøµÊñπÈù¢ÁöÑÊïàÁî®„ÄÇÊñπÊ≥ïÔºöÂèÇ‰∏éËÄÖÔºàN=103ÔºõÂπ≥ÂùáÂπ¥ÈæÑ 16.1 Â≤ÅÔºâÊù•Ëá™‰º¶Êï¶ÁöÑ‰∏âÊâÄÂ≠¶Ê†°„ÄÇÂèÇ‰∏éËÄÖÂÆåÊàê‰∫Ü‰ºòÂäøÂíåÂõ∞ÈöæÈóÆÂç∑„ÄÅËøõÈ£üÈöúÁ¢ç-15 ÈóÆÂç∑„ÄÅÁù°Áú†Áä∂ÂÜµÊåáÊ†áÈóÆÂç∑ÔºåÂπ∂ÊåáÂá∫‰∫ÜÊòØÂê¶Â≠òÂú®Ëá™ÊùÄÊÑèÂøµ„ÄÇ‰ªñ‰ª¨‰ΩøÁî® Mindcraft Â∫îÁî®Á®ãÂ∫è 14 Â§©ÔºåÈÄöËøáËá™ÊàëÊä•ÂëäÊèê‰æõ‰∏ªÂä®Êï∞ÊçÆÔºåÂπ∂‰ªéÊô∫ËÉΩÊâãÊú∫‰º†ÊÑüÂô®Êèê‰æõË¢´Âä®Êï∞ÊçÆ„ÄÇÂ∫îÁî®ÂØπÊØîÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊù•Â¢ûÂº∫ÁâπÂÆöÁî®Êà∑ÁöÑÁâπÂæÅÁ®≥ÂÆöÊÄßÔºåÁÑ∂ÂêéËøõË°åÁõëÁù£ÂæÆË∞É„ÄÇÊ®°ÂûãËØÑ‰º∞ÈááÁî®Áïô‰∏ÄÊ≥ï‰∫§ÂèâÈ™åËØÅÔºå‰ΩøÁî®Âπ≥Ë°°ÂáÜÁ°ÆÂ∫¶‰Ωú‰∏∫‰∏ªË¶ÅÊåáÊ†á„ÄÇÁªìÊûúÔºö‰∏é‰∏™Âà´Êï∞ÊçÆÊ∫êÁõ∏ÊØîÔºå‰∏ªÂä®ÂíåË¢´Âä®Êï∞ÊçÆÁöÑÊï¥ÂêàÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩÔºåSDQ È´òÈ£éÈô©ÁöÑÂπ≥ÂùáÂπ≥Ë°°ÂáÜÁ°ÆÂ∫¶‰∏∫ 0.71ÔºåÂ§±Áú†‰∏∫ 0.67ÔºåËá™ÊùÄÊÑèÂøµ‰∏∫ 0.77ÔºåÈ•ÆÈ£üÂ§±Ë∞É‰∏∫ 0.70„ÄÇÂØπÊØîÂ≠¶‰π†Ê°ÜÊû∂Á®≥ÂÆö‰∫ÜÊØèÊó•Ë°å‰∏∫Ë°®ÂæÅÔºåÂ¢ûÂº∫‰∫ÜÈ¢ÑÊµãÈ≤ÅÊ£íÊÄß„ÄÇÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫ÜÂ∞Ü‰∏ªÂä®ÂíåË¢´Âä®Êô∫ËÉΩÊâãÊú∫Êï∞ÊçÆ‰∏éÂÖàËøõÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁõ∏ÁªìÂêà‰ª•È¢ÑÊµãÂøÉÁêÜÂÅ•Â∫∑È£éÈô©ÁöÑÊΩúÂäõ„ÄÇ</paragraph>

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóáÂàÜÊûêÊ®°ÂûãÁîüÊàê 1 (ADAM) ÊòØ‰∏ÄÂÄãÂ§ö‰ª£ÁêÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êû∂ÊßãÔºåÊó®Âú®Êï¥ÂêàÂíåÂàÜÊûêÂ§öÊ®°ÂºèÊï∏ÊìöÔºåÂåÖÊã¨ÂæÆÁîüÁâ©ÁµÑÁâπÂæµ„ÄÅËá®Â∫äÊï∏ÊìöÈõÜÂíåÂ§ñÈÉ®Áü•Ë≠òÂ∫´Ôºå‰ª•Â¢ûÈÄ≤Â∞çÈòøËå≤Êµ∑ÈªòÁóá (AD) ÁöÑÁêÜËß£ÂíåÂÅµÊ∏¨„ÄÇÈÄèÈÅéÂà©Áî®Êì∑ÂèñÂ¢ûÂº∑ÁîüÊàê (RAG) ÊäÄË°ì‰ª•ÂèäÂÖ∂Â§ö‰ª£ÁêÜÊû∂ÊßãÔºåADAM-1 Âæû‰∏çÂêåÁöÑÊï∏Êìö‰æÜÊ∫ê‰∏≠Á∂úÂêàË¶ãËß£Ôºå‰∏¶‰ΩøÁî®ÊñáÁçªÈ©ÖÂãïÁöÑË≠âÊìöÂ∞çÁôºÁèæÈÄ≤Ë°åÊÉÖÂ¢ÉÂåñ„ÄÇËàá XGBoost ÁöÑÊØîËºÉË©ï‰º∞È°ØÁ§∫È°û‰ººÁöÑÂπ≥Âùá F1 ÂàÜÊï∏Ôºå‰ΩÜ ADAM-1 ÁöÑËÆäÁï∞È°ØËëóÈôç‰ΩéÔºåÁ™ÅÈ°ØÂÖ∂Á©©ÂÅ•ÊÄßÂíå‰∏ÄËá¥ÊÄßÔºåÁâπÂà•ÊòØÂú®Â∞èÂûãÂØ¶È©óÂÆ§Êï∏ÊìöÈõÜ‰∏≠„ÄÇÈõñÁÑ∂ÁõÆÂâçÈáùÂ∞ç‰∫åÂÖÉÂàÜÈ°û‰ªªÂãôÈÄ≤Ë°åË™øÊï¥Ôºå‰ΩÜÊú™‰æÜÁöÑËø≠‰ª£Êó®Âú®Á¥çÂÖ•ÂÖ∂‰ªñÊï∏ÊìöÊ®°ÂºèÔºå‰æãÂ¶ÇÁ•ûÁ∂ìÂΩ±ÂÉèÂíåÁîüÁâ©Ê®ôË®òÔºå‰ª•Êì¥Â§ßÈòøËå≤Êµ∑ÈªòÁóáÁ†îÁ©∂ÂíåË®∫Êñ∑ÁöÑÂèØÊì¥ÂÖÖÊÄßÂíåÈÅ©Áî®ÊÄß„ÄÇ

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

ÊëòË¶ÅÔºöÊñ∞ÂÜ†ËÇ∫ÁÇéÁñ´ÊÉÖÂ∑≤ÂØπÂÖ®ÁêÉÊï∞ÂçÅ‰∫ø‰∫∫‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇÁî±‰∫éÂÖ∂‰º†Êí≠ËøÖÈÄü‰∏îÂëºÂê∏ÈÅìÁóáÁä∂‰∏•ÈáçÔºåÂÆÉÂØπÂÖ¨ÂÖ±Âç´ÁîüÂíåÂåªÁñó‰øùÂÅ•Á≥ªÁªüÊûÑÊàêÊåëÊàò„ÄÇÂáèËΩªÊñ∞ÂÜ†ËÇ∫ÁÇéÁñ´ÊÉÖÁöÑÊúâÊïàÁ≠ñÁï•ÂåÖÊã¨Êï¥ÂêàÊ£ÄÊµã‰ª•ËØÜÂà´ÂèóÊÑüÊüìËÄÖ„ÄÇËôΩÁÑ∂ RT-PCR Ë¢´ËÆ§‰∏∫ÊòØËØäÊñ≠Êñ∞ÂÜ†ËÇ∫ÁÇéÁöÑÈªÑÈáëÊ†áÂáÜÔºå‰ΩÜÂÆÉ‰πüÊúâ‰∏Ä‰∫õÈôêÂà∂Ôºå‰æãÂ¶ÇÂÅáÈò¥ÊÄßÁöÑÈ£éÈô©„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ∑±Â∫¶Â≠¶‰π†ËØäÊñ≠Á≥ªÁªüÔºåËØ•Á≥ªÁªüÂ∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑÊ∑±Â∫¶Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (DCNN) ÈõÜÊàêÂà∞ÈõÜÊàêÂ≠¶‰π†Ê°ÜÊû∂‰∏≠Ôºå‰ª•‰ªéËÉ∏ÈÉ® X Â∞ÑÁ∫ø (CXR) ÂõæÂÉè‰∏≠Á≤æÁ°ÆËØÜÂà´Êñ∞ÂÜ†ËÇ∫ÁÇéÁóÖ‰æã„ÄÇÊàë‰ª¨‰ΩøÁî® Choquet ÁßØÂàÜÁªìÂêàÊù•Ëá™È¢ÑËÆ≠ÁªÉ DCNN ÁöÑÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑÁâπÂæÅÂêëÈáèÔºå‰ª•ÊçïËé∑Á∫øÊÄßÊñπÊ≥ïÊó†Ê≥ïÂÆûÁé∞ÁöÑ‰∏çÂêå DCNN ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÊàë‰ª¨ÈááÁî® Sugeno-$\lambda$ ÊµãÂ∫¶ÁêÜËÆ∫Êù•ÂØºÂá∫ÁΩëÁªúÂ≠êÈõÜÁöÑÊ®°Á≥äÊµãÂ∫¶‰ª•ÂÆûÁé∞ËÅöÂêà„ÄÇÊàë‰ª¨Âà©Áî®Â∑ÆÂàÜËøõÂåñÊù•‰º∞ËÆ°Ê®°Á≥äÂØÜÂ∫¶„ÄÇÁî±‰∫éËÅöÂêàÁâπÂæÅÂêëÈáèÁöÑÂ§çÊùÇÊÄßÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Âü∫‰∫é TensorFlow ÁöÑ Choquet Êìç‰ΩúÂ±Ç‰ª•‰øÉËøõÈ´òÊïàËÅöÂêà„ÄÇCOVIDx Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÈõÜÊàêÊ®°ÂûãÂú®‰∏âÁ±ªÂàÜÁ±ª‰∏≠ËææÂà∞ 98% ÁöÑÂáÜÁ°ÆÁéáÔºåÂú®‰∫åÂÖÉÂàÜÁ±ª‰∏≠ËææÂà∞ 99.50%Ôºå‰ºò‰∫éÂÖ∂ÁªÑ‰ª∂ DenseNet-201Ôºà‰∏âÁ±ª‰∏∫ 97%Ôºå‰∫åÂÖÉ‰∏∫ 98.75%Ôºâ„ÄÅInception-v3Ôºà‰∏âÁ±ª‰∏∫ 96.25%Ôºå‰∫åÂÖÉ‰∏∫ 98.50%ÔºâÂíå XceptionÔºà‰∏âÁ±ª‰∏∫ 94.50%Ôºå‰∫åÂÖÉ‰∏∫ 98%ÔºâÔºåÂπ∂Ë∂ÖË∂ä‰∫ÜËÆ∏Â§ö‰ª•ÂâçÁöÑÊñπÊ≥ï„ÄÇ

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá®Â∫äÂïèÁ≠î (QA) ‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊΩõÂäõÔºåÂÖ∂‰∏≠Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊàêÁÇ∫Á¢∫‰øùÊ®°ÂûãÂõûÊáâ‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÁöÑÈ†òÂÖàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËá™ÂãïÂåñ RAG ÊåáÊ®ôÂú®Ëá®Â∫äÂíåÂ∞çË©±ÂºèÁî®‰æã‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇ‰ΩøÁî®Ëá®Â∫ä‰∫∫È°ûÂ∞çÂõûÊáâÁöÑË©ï‰º∞Êó¢ÊòÇË≤¥Âèà‰∏çÂÖ∑ÂèØÊì¥ÂÖÖÊÄßÔºå‰πü‰∏çÂà©Êñº RAG Á≥ªÁµ±ÁöÑÊåÅÁ∫åËø≠‰ª£ÈñãÁôº„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ASTRID - ‰∏ÄÁ®ÆÁî®ÊñºË©ï‰º∞Âà©Áî® RAG ÁöÑËá®Â∫ä QA Á≥ªÁµ±ÁöÑËá™ÂãïÂåñ‰∏îÂèØÊì¥ÂÖÖÁöÑ TRIaD - ÂåÖÂê´‰∏âÂÄãÊåáÊ®ôÔºöËÑàÁµ°Áõ∏ÈóúÊÄß (CR)„ÄÅÊãíÁµïÊ∫ñÁ¢∫ÊÄß (RA) ÂíåÂ∞çË©±Âø†ÂØ¶Â∫¶ (CF)„ÄÇÊàëÂÄëÊñ∞Á©éÁöÑË©ï‰º∞ÊåáÊ®ô CF Êó®Âú®Êõ¥Â•ΩÂú∞ÊçïÊçâÊ®°ÂûãÂ∞çÁü•Ë≠òÂ∫´ÁöÑÂõûÊáâÁöÑÂø†ÂØ¶Â∫¶ÔºåÂêåÊôÇ‰∏çÊá≤ÁΩ∞Â∞çË©±ÂÖÉÁ¥†„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÁöÑ‰∏âÂÖÉÁµÑÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÂÄãÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®ÁôΩÂÖßÈöúÊâãË°ìË°ìÂæåÈö®Ë®™ÊúüÈñìÂêë LLM Âü∫Êñº QA ÁöÑ‰ª£ÁêÜÊèêÂá∫ÁöÑ 200 Â§öÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊÇ£ËÄÖÂïèÈ°å - ‰∏ñÁïå‰∏äÊâãË°ìÈáèÊúÄÂ§ßÁöÑÊâãË°ì - ‰∏¶Â¢ûÂä†‰∫ÜËá®Â∫äÈÜ´ÁîüÈÅ∏ÊìáÁöÑÂïèÈ°åÔºåÁî®ÊñºÁ∑äÊÄ•„ÄÅËá®Â∫äÂíåÈùûËá®Â∫äÈ†òÂüüÂ§ñÊÉÖÂ¢É„ÄÇÊàëÂÄëË≠âÊòéÔºåËàáÂ∞çË©±ÂºèÁî®‰æãÁèæÊúâÂÆöÁæ©Áõ∏ÊØîÔºåCF ÂèØ‰ª•Êõ¥Â•ΩÂú∞È†êÊ∏¨‰∫∫È°ûÂ∞çÂø†ÂØ¶Â∫¶ÁöÑË©ïÂàÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®Êòé‰ΩøÁî®Áî± CF„ÄÅRA Âíå CR ÁµÑÊàêÁöÑ‰∏âÂÖÉÁµÑÈÄ≤Ë°åË©ï‰º∞ËàáËá®Â∫äÈÜ´ÁîüÂ∞ç‰∏çÈÅ©Áï∂„ÄÅÊúâÂÆ≥ÊàñÁÑ°ÁõäÁöÑÂõûÊáâÁöÑË©ï‰º∞‰øùÊåÅ‰∏ÄËá¥„ÄÇÊúÄÂæåÔºå‰ΩøÁî®‰πùÁ®Æ‰∏çÂêåÁöÑ LLMÔºåÊàëÂÄëË≠âÊòéÈÄô‰∏âÂÄãÊåáÊ®ôÂèØ‰ª•Ëàá‰∫∫È°ûË©ï‰º∞Á∑äÂØÜ‰∏ÄËá¥ÔºåÁ™ÅÈ°Ø‰∫ÜÈÄô‰∫õÊåáÊ®ôÂú® LLM È©ÖÂãïÁöÑËá™ÂãïÂåñË©ï‰º∞ÁÆ°ÈÅì‰∏≠‰ΩøÁî®ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÈÇÑÂÖ¨‰Ωà‰∫ÜÈÄô‰∫õÂØ¶È©óÁöÑÊèêÁ§∫ÂíåÊï∏ÊìöÈõÜÔºåÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÂíåÈñãÁôºÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫ê„ÄÇ

##### **Potential and Perils of Large Language Models as Judges of Unstructured Textual Data**
2501.08167v1 by Rewina Bedemariam, Natalie Perez, Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Elizabeth Conjar, Ikkei Itoku, David Theil, Aman Chadha, Naumaan Nayyar

Rapid advancements in large language models have unlocked remarkable
capabilities when it comes to processing and summarizing unstructured text
data. This has implications for the analysis of rich, open-ended datasets, such
as survey responses, where LLMs hold the promise of efficiently distilling key
themes and sentiments. However, as organizations increasingly turn to these
powerful AI systems to make sense of textual feedback, a critical question
arises, can we trust LLMs to accurately represent the perspectives contained
within these text based datasets? While LLMs excel at generating human-like
summaries, there is a risk that their outputs may inadvertently diverge from
the true substance of the original responses. Discrepancies between the
LLM-generated outputs and the actual themes present in the data could lead to
flawed decision-making, with far-reaching consequences for organizations. This
research investigates the effectiveness of LLMs as judge models to evaluate the
thematic alignment of summaries generated by other LLMs. We utilized an
Anthropic Claude model to generate thematic summaries from open-ended survey
responses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as
LLM judges. The LLM-as-judge approach was compared to human evaluations using
Cohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable
alternative to traditional human centric evaluation methods. Our findings
reveal that while LLMs as judges offer a scalable solution comparable to human
raters, humans may still excel at detecting subtle, context-specific nuances.
This research contributes to the growing body of knowledge on AI assisted text
analysis. We discuss limitations and provide recommendations for future
research, emphasizing the need for careful consideration when generalizing LLM
judge models across various contexts and use cases.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂø´ÈÄüÈÄ≤Â±ïËß£Èéñ‰∫ÜÂú®ËôïÁêÜÂíåÁ∏ΩÁµêÈùûÁµêÊßãÂåñÊñáÊú¨Êï∏ÊìöÊñπÈù¢ÁöÑÈùûÂá°ËÉΩÂäõ„ÄÇÈÄôÂ∞çË±êÂØåÁöÑÈñãÊîæÂºèÊï∏ÊìöÈõÜÁöÑÂàÜÊûêÊúâÂΩ±ÈüøÔºå‰æãÂ¶ÇË™øÊü•ÂõûÊáâÔºåÂÖ∂‰∏≠ LLM ÊâøË´æÊúâÊïàÂú∞ÊèêÁÖâÈóúÈçµ‰∏ªÈ°åÂíåÊÉÖÁ∑í„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÁµÑÁπîË∂ä‰æÜË∂äÂ§öÂú∞Ê±ÇÂä©ÊñºÈÄô‰∫õÂº∑Â§ßÁöÑ AI Á≥ªÁµ±‰æÜÁêÜËß£ÊñáÊú¨ÂèçÈ•ãÔºå‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÂá∫Áèæ‰∫ÜÔºåÊàëÂÄëËÉΩÁõ∏‰ø° LLM ËÉΩÊ∫ñÁ¢∫Âú∞‰ª£Ë°®ÈÄô‰∫õÂü∫ÊñºÊñáÊú¨ÁöÑÊï∏ÊìöÈõÜÊâÄÂåÖÂê´ÁöÑËßÄÈªûÂóéÔºüÈõñÁÑ∂ LLM Âú®ÁîüÊàêÈ°û‰ºº‰∫∫È°ûÁöÑÊëòË¶ÅÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂ≠òÂú®ÂÖ∂Ëº∏Âá∫ÂèØËÉΩÁÑ°ÊÑèÈñìÂÅèÈõ¢ÂéüÂßãÂõûÊáâÁöÑÁúüÊ≠£ÂØ¶Ë≥™ÁöÑÈ¢®Èö™„ÄÇLLM ÁîüÊàêÁöÑËº∏Âá∫ËàáÊï∏Êìö‰∏≠Â≠òÂú®ÁöÑÂØ¶Èöõ‰∏ªÈ°å‰πãÈñìÁöÑÂ∑ÆÁï∞ÂèØËÉΩÂ∞éËá¥ÊúâÁº∫Èô∑ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÂ∞çÁµÑÁπîÁî¢ÁîüÊ∑±ÈÅ†ÁöÑÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂Ë™øÊü•‰∫Ü LLM ‰ΩúÁÇ∫Ë©ï‰º∞Ê®°ÂûãÁöÑÊúâÊïàÊÄßÔºå‰ª•Ë©ï‰º∞ÂÖ∂‰ªñ LLM ÁîüÊàêÁöÑÊëòË¶ÅÁöÑ‰∏ªÈ°å‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÂà©Áî® Anthropic Claude Ê®°ÂûãÂæûÈñãÊîæÂºèË™øÊü•ÂõûÊáâ‰∏≠ÁîüÊàê‰∏ªÈ°åÊëòË¶ÅÔºå‰∫ûÈ¶¨ÈÅúÁöÑ Titan Express„ÄÅNova Pro Âíå Meta ÁöÑ Llama ‰ΩúÁÇ∫ LLM Ë©ïÂØ©„ÄÇ‰ΩøÁî® Cohen's kappa„ÄÅSpearman's rho Âíå Krippendorff's alpha Â∞á LLM ‰ΩúÁÇ∫Ë©ïÂØ©ÁöÑÊñπÊ≥ïËàá‰∫∫È°ûË©ï‰º∞ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÈ©óË≠â‰∫ÜÂÇ≥Áµ±‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑË©ï‰º∞ÊñπÊ≥ïÁöÑÂèØÊì¥Â±ïÊõø‰ª£ÊñπÊ°à„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂ LLM ‰ΩúÁÇ∫Ë©ïÂØ©Êèê‰æõ‰∫Ü‰∏ÄÂÄãËàá‰∫∫È°ûË©ïÂàÜÂì°Áõ∏Áï∂ÁöÑÂèØÊì¥Â±ïËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜ‰∫∫È°û‰ªçÁÑ∂ÂèØËÉΩÊìÖÈï∑Ê™¢Ê∏¨ÂæÆÂ¶ôÁöÑ„ÄÅÁâπÂÆöÊñº‰∏ä‰∏ãÊñáÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•„ÄÇÊú¨Á†îÁ©∂ÊúâÂä©ÊñºÂ¢ûÂä†ÊúâÈóú AI ËºîÂä©ÊñáÊú¨ÂàÜÊûêÁöÑÁü•Ë≠òÈ´îÁ≥ª„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂ±ÄÈôêÊÄß‰∏¶Êèê‰æõ‰∫ÜÂ∞çÊú™‰æÜÁ†îÁ©∂ÁöÑÂª∫Ë≠∞ÔºåÂº∑Ë™øÂú®ÂêÑÁ®ÆËÉåÊôØÂíåÁî®‰æã‰∏≠Ê¶ÇÊã¨ LLM Ë©ïÂØ©Ê®°ÂûãÊôÇÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆ„ÄÇ

##### **FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification**
2501.08155v1 by Nurit Cohen-Inger, Lior Rokach, Bracha Shapira, Seffi Cohen

Algorithmic decision-making has become deeply ingrained in many domains, yet
biases in machine learning models can still produce discriminatory outcomes,
often harming unprivileged groups. Achieving fair classification is inherently
challenging, requiring a careful balance between predictive performance and
ethical considerations. We present FairTTTS, a novel post-processing bias
mitigation method inspired by the Tree Test Time Simulation (TTTS) method.
Originally developed to enhance accuracy and robustness against adversarial
inputs through probabilistic decision-path adjustments, TTTS serves as the
foundation for FairTTTS. By building on this accuracy-enhancing technique,
FairTTTS mitigates bias and improves predictive performance. FairTTTS uses a
distance-based heuristic to adjust decisions at protected attribute nodes,
ensuring fairness for unprivileged samples. This fairness-oriented adjustment
occurs as a post-processing step, allowing FairTTTS to be applied to
pre-trained models, diverse datasets, and various fairness metrics without
retraining. Extensive evaluation on seven benchmark datasets shows that
FairTTTS outperforms traditional methods in fairness improvement, achieving a
20.96% average increase over the baseline compared to 18.78% for related work,
and further enhances accuracy by 0.55%. In contrast, competing methods
typically reduce accuracy by 0.42%. These results confirm that FairTTTS
effectively promotes more equitable decision-making while simultaneously
improving predictive performance.

ÊëòË¶ÅÔºöÊºîÁÆóÊ≥ïÊ±∫Á≠ñÂà∂ÂÆöÂ∑≤Ê∑±Ê§çÊñºË®±Â§öÈ†òÂüü‰∏≠ÔºåÁÑ∂ËÄåÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏≠ÁöÑÂÅèË¶ã‰ªçÂèØËÉΩÁî¢ÁîüÊ≠ßË¶ñÊÄßÁöÑÁµêÊûúÔºåÈÄöÂ∏∏ÊúÉÂÇ∑ÂÆ≥Êú™Âèó‰øùÈöúÁöÑÁæ§È´î„ÄÇÈÅîÊàêÂÖ¨Âπ≥ÂàÜÈ°ûÊú¨Ë≥™‰∏äÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÈúÄË¶ÅÂú®È†êÊ∏¨ÊïàËÉΩËàáÈÅìÂæ∑ËÄÉÈáè‰πãÈñìÂèñÂæó‰ªîÁ¥∞ÁöÑÂπ≥Ë°°„ÄÇÊàëÂÄëÊèêÂá∫ FairTTTSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂæåËôïÁêÜÂÅèË™§Á∑©Ëß£ÊñπÊ≥ïÔºåÂÖ∂ÈùàÊÑü‰æÜËá™Ê®πÊ∏¨Ë©¶ÊôÇÈñìÊ®°Êì¨ (TTTS) ÊñπÊ≥ï„ÄÇTTTS ÊúÄÂàùÊòØÁÇ∫‰∫ÜÈÄèÈÅéÊ©üÁéáÊ±∫Á≠ñË∑ØÂæëË™øÊï¥‰æÜÂ¢ûÂº∑ÈáùÂ∞çÂ∞çÊäóËº∏ÂÖ•ÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÁ©©ÂÅ•ÊÄßËÄåÈñãÁôºÔºå‰∏¶‰ΩúÁÇ∫ FairTTTS ÁöÑÂü∫Á§é„ÄÇÈÄèÈÅéÂª∫Á´ãÂú®ÈÄôÁ®ÆÂ¢ûÂº∑Ê∫ñÁ¢∫Â∫¶ÁöÑÊäÄË°ì‰πã‰∏äÔºåFairTTTS ÂèØ‰ª•Ê∏õËºïÂÅèË™§‰∏¶ÊîπÂñÑÈ†êÊ∏¨ÊïàËÉΩ„ÄÇFairTTTS ‰ΩøÁî®Âü∫ÊñºË∑ùÈõ¢ÁöÑÂïüÁôºÊ≥ï‰æÜË™øÊï¥Âèó‰øùË≠∑Â±¨ÊÄßÁØÄÈªûÁöÑÊ±∫Á≠ñÔºåÁ¢∫‰øùÊú™Âèó‰øùÈöúÊ®£Êú¨ÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÈÄôÁ®Æ‰ª•ÂÖ¨Âπ≥ÊÄßÁÇ∫Â∞éÂêëÁöÑË™øÊï¥ÊúÉÂú®ÂæåËôïÁêÜÊ≠•È©ü‰∏≠ÁôºÁîüÔºåÂÖÅË®± FairTTTS Â•óÁî®Ëá≥È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÅÂ§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÂíåÂêÑÁ®ÆÂÖ¨Âπ≥ÊÄßÊåáÊ®ôÔºåËÄåÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÂú®‰∏ÉÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õË©ï‰º∞È°ØÁ§∫ÔºåFairTTTS Âú®ÂÖ¨Âπ≥ÊÄßÊîπÂñÑÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºåËàáÁõ∏ÈóúÂ∑•‰ΩúÁöÑ 18.78% Áõ∏ÊØîÔºåÂπ≥ÂùáÊèêÂçá‰∫Ü 20.96%Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 0.55%„ÄÇÁõ∏ÂèçÂú∞ÔºåÁ´∂Áà≠ÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂ∞áÊ∫ñÁ¢∫Â∫¶Èôç‰Ωé 0.42%„ÄÇÈÄô‰∫õÁµêÊûúË≠âÂØ¶ÔºåFairTTTS ÊúâÊïàÂú∞‰øÉÈÄ≤‰∫ÜÊõ¥ÂÖ¨Âπ≥ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÂêåÊôÇ‰πüÊîπÂñÑ‰∫ÜÈ†êÊ∏¨ÊïàËÉΩ„ÄÇ

##### **Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features**
2501.08097v1 by E. Sarfati, A. B√¥ne, M-M. Roh√©, C. Aub√©, M. Ronot, P. Gori, I. Bloch

Hepatocellular carcinoma is the most spread primary liver cancer across the
world ($\sim$80\% of the liver tumors). The gold standard for HCC diagnosis is
liver biopsy. However, in the clinical routine, expert radiologists provide a
visual diagnosis by interpreting hepatic CT-scans according to a standardized
protocol, the LI-RADS, which uses five radiological criteria with an associated
decision tree. In this paper, we propose an automatic approach to predict
histology-proven HCC from CT images in order to reduce radiologists'
inter-variability. We first show that standard deep learning methods fail to
accurately predict HCC from CT-scans on a challenging database, and propose a
two-step approach inspired by the LI-RADS system to improve the performance. We
achieve improvements from 6 to 18 points of AUC with respect to deep learning
baselines trained with different architectures. We also provide clinical
validation of our method, achieving results that outperform non-expert
radiologists and are on par with expert ones.

ÊëòË¶ÅÔºöËÇùÁ¥∞ËÉûÁôåÊòØÊúÄÂ∏∏Ë¶ãÁöÑÂéüÁôºÊÄßËÇùÁôåÔºåÈÅçÂ∏ÉÂÖ®ÁêÉÔºàÁ¥Ñ‰ΩîËÇùËáüËÖ´Áò§ÁöÑ 80%Ôºâ„ÄÇHCC Ë®∫Êñ∑ÁöÑÈªÉÈáëÊ®ôÊ∫ñÊòØËÇùËáüÊ¥ªÊ™¢„ÄÇÁÑ∂ËÄåÔºåÂú®Ëá®Â∫äÂ∏∏Ë¶è‰∏≠ÔºåÂ∞àÂÆ∂ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÊúÉÊ†πÊìöÊ®ôÊ∫ñÂåñÂçîÂÆö LI-RADS ‰æÜËß£ËÆÄËÇùËáüÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÔºåÊèê‰æõË¶ñË¶∫Ë®∫Êñ∑ÔºåÊ≠§ÂçîÂÆö‰ΩøÁî®‰∫îÈ†ÖÊîæÂ∞ÑÂ≠∏Ê®ôÊ∫ñÔºå‰∏¶ÈôÑÊúâÁõ∏ÈóúÊ±∫Á≠ñÊ®π„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÂåñÊñπÊ≥ïÔºåÁî®ÊñºÂæûÈõªËÖ¶Êñ∑Â±§ÂΩ±ÂÉèÈ†êÊ∏¨ÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≠âÂØ¶ÁöÑ HCCÔºå‰ª•Ê∏õÂ∞ëÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑËÆäÁï∞ÊÄß„ÄÇÊàëÂÄëÈ¶ñÂÖàË°®ÊòéÔºåÊ®ôÊ∫ñÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁÑ°Ê≥ïÊ∫ñÁ¢∫Âú∞ÂæûÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË≥áÊñôÂ∫´‰∏≠ÁöÑÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÈ†êÊ∏¨ HCCÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèó LI-RADS Á≥ªÁµ±ÂïüÁôºÁöÑÂÖ©Ê≠•È©üÊñπÊ≥ï‰æÜÊîπÂñÑÊïàËÉΩ„ÄÇÁõ∏ËºÉÊñº‰ΩøÁî®‰∏çÂêåÊû∂ÊßãË®ìÁ∑¥ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂü∫Ê∫ñÔºåÊàëÂÄëÂú® AUC ‰∏≠Áç≤Âæó‰∫Ü 6 Âà∞ 18 ÂÄãÈªûÁöÑÈÄ≤Ê≠•„ÄÇÊàëÂÄë‰πüÊèê‰æõ‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑËá®Â∫äÈ©óË≠âÔºåÊâÄÁç≤ÂæóÁöÑÁµêÊûúÂÑ™ÊñºÈùûÂ∞àÂÆ∂ÊîæÂ∞ÑÁßëÈÜ´Â∏´Ôºå‰∏îËàáÂ∞àÂÆ∂Áõ∏Áï∂„ÄÇ

##### **Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma**
2501.08042v1 by Alvaro Pastor-Naranjo, Pablo Meseguer, Roc√≠o del Amor, Jose Antonio Lopez-Guerrero, Samuel Navarro, Katia Scotlandi, Antonio Llombart-Bosch, Isidro Machado, Valery Naranjo

Ewing's sarcoma (ES), characterized by a high density of small round blue
cells without structural organization, presents a significant health concern,
particularly among adolescents aged 10 to 19. Artificial intelligence-based
systems for automated analysis of histopathological images are promising to
contribute to an accurate diagnosis of ES. In this context, this study explores
the feature extraction ability of different pre-training strategies for
distinguishing ES from other soft tissue or bone sarcomas with similar
morphology in digitized tissue microarrays for the first time, as far as we
know. Vision-language supervision (VLS) is compared to fully-supervised
ImageNet pre-training within a multiple instance learning paradigm. Our
findings indicate a substantial improvement in diagnostic accuracy with the
adaption of VLS using an in-domain dataset. Notably, these models not only
enhance the accuracy of predicted classes but also drastically reduce the
number of trainable parameters and computational costs.

ÊëòË¶ÅÔºöÂ∞§Âõ†Ê∞èËÇâÁò§ (ES) ÁöÑÁâπÂæÅÊòØÈ´òÂØÜÂ∫¶ÁöÑÊó†ÁªìÊûÑÁªÑÁªáÁöÑÂ∞èÂúÜÂΩ¢ËìùËâ≤ÁªÜËÉûÔºåÂØπÂÅ•Â∫∑ÊûÑÊàêÈáçÂ§ßÂ®ÅËÉÅÔºåÂ∞§ÂÖ∂ÊòØÂú® 10 Ëá≥ 19 Â≤ÅÁöÑÈùíÂ∞ëÂπ¥‰∏≠„ÄÇÂü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÁªÑÁªáÁóÖÁêÜÂ≠¶ÂõæÂÉèËá™Âä®ÂàÜÊûêÁ≥ªÁªüÊúâÊúõÊúâÂä©‰∫é ES ÁöÑÂáÜÁ°ÆËØäÊñ≠„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊú¨Á†îÁ©∂È¶ñÊ¨°Êé¢ËÆ®‰∫Ü‰∏çÂêåÈ¢ÑËÆ≠ÁªÉÁ≠ñÁï•ÁöÑÁâπÂæÅÊèêÂèñËÉΩÂäõÔºå‰ª•Âå∫ÂàÜ ES ‰∏éÊï∞Â≠óÂåñÁªÑÁªáÂæÆÈòµÂàó‰∏≠ÂΩ¢ÊÄÅÁõ∏‰ººÁöÑÂÖ∂‰ªñËΩØÁªÑÁªáÊàñÈ™®ËÇâÁò§ÔºåÊçÆÊàë‰ª¨ÊâÄÁü•„ÄÇËßÜËßâËØ≠Ë®ÄÁõëÁù£ (VLS) ‰∏éÂ§öÂÆû‰æãÂ≠¶‰π†ËåÉÂºè‰∏≠ÁöÑÂÆåÂÖ®ÁõëÁù£ ImageNet È¢ÑËÆ≠ÁªÉËøõË°å‰∫ÜÊØîËæÉ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®ÂüüÂÜÖÊï∞ÊçÆÈõÜË∞ÉÊï¥ VLS ÂèØÂ§ßÂπÖÊèêÈ´òËØäÊñ≠ÂáÜÁ°ÆÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËøô‰∫õÊ®°Âûã‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÈ¢ÑÊµãÁ±ªÂà´ÁöÑÂáÜÁ°ÆÊÄßÔºåËøòÂ§ßÂπÖÂáèÂ∞ë‰∫ÜÂèØËÆ≠ÁªÉÂèÇÊï∞ÂíåËÆ°ÁÆóÊàêÊú¨„ÄÇ

##### **Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction**
2501.07970v1 by Wentao Cui, Shoubo Li, Chen Fang, Qingqing Long, Chengrui Wang, Xuezhi Wang, Yuanchun Zhou

Discovering gene-disease associations is crucial for understanding disease
mechanisms, yet identifying these associations remains challenging due to the
time and cost of biological experiments. Computational methods are increasingly
vital for efficient and scalable gene-disease association prediction.
Graph-based learning models, which leverage node features and network
relationships, are commonly employed for biomolecular predictions. However,
existing methods often struggle to effectively integrate node features,
heterogeneous structures, and semantic information. To address these
challenges, we propose COmprehensive MEtapath-based heterogeneous graph
Transformer(COMET) for predicting gene-disease associations. COMET integrates
diverse datasets to construct comprehensive heterogeneous networks,
initializing node features with BioGPT. We define seven Metapaths and utilize a
transformer framework to aggregate Metapath instances, capturing global
contexts and long-distance dependencies. Through intra- and inter-metapath
aggregation using attention mechanisms, COMET fuses latent vectors from
multiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates
superior robustness compared to state-of-the-art approaches. Ablation studies
and visualizations validate COMET's effectiveness, providing valuable insights
for advancing human health research.

ÊëòË¶ÅÔºöÁôºÁèæÂü∫Âõ†ÁñæÁóÖÈóúËÅØÂ∞çÊñºÁêÜËß£ÁñæÁóÖÊ©üÂà∂Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÁîüÁâ©ÂØ¶È©óÁöÑÊôÇÈñìÂíåÊàêÊú¨ÔºåË≠òÂà•ÈÄô‰∫õÈóúËÅØ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇË®àÁÆóÊñπÊ≥ïÂ∞çÊñºÈ´òÊïà‰∏îÂèØÊì¥ÂÖÖÁöÑÂü∫Âõ†ÁñæÁóÖÈóúËÅØÈ†êÊ∏¨Ë∂ä‰æÜË∂äÈáçË¶Å„ÄÇÂü∫ÊñºÂúñÁöÑÂ≠∏ÁøíÊ®°ÂûãÂà©Áî®ÁØÄÈªûÁâπÂæµÂíåÁ∂≤Ë∑ØÈóú‰øÇÔºåÈÄöÂ∏∏Áî®ÊñºÁîüÁâ©ÂàÜÂ≠êÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Èõ£‰ª•ÊúâÊïàÊï¥ÂêàÁØÄÈªûÁâπÂæµ„ÄÅÁï∞Ë≥™ÁµêÊßãÂíåË™ûÁæ©Ë≥áË®ä„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂü∫ÊñºÁ∂úÂêàÂÖÉË∑ØÂæëÁöÑÁï∞Ë≥™ÂúñËΩâÊèõÂô® (COMET)ÔºåÁî®ÊñºÈ†êÊ∏¨Âü∫Âõ†ÁñæÁóÖÈóúËÅØ„ÄÇCOMET Êï¥Âêà‰∫Ü‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰æÜÊßãÂª∫ÂÖ®Èù¢ÁöÑÁï∞Ë≥™Á∂≤Ë∑ØÔºå‰ΩøÁî® BioGPT ÂàùÂßãÂåñÁØÄÈªûÁâπÂæµ„ÄÇÊàëÂÄëÂÆöÁæ©‰∫Ü‰∏ÉÂÄãÂÖÉË∑ØÂæëÔºå‰∏¶Âà©Áî®ËΩâÊèõÂô®Ê°ÜÊû∂‰æÜËÅöÂêàÂÖÉË∑ØÂæëÂØ¶‰æãÔºåÊì∑ÂèñÂÖ®Â±Ä‰∏ä‰∏ãÊñáÂíåÈï∑Ë∑ùÈõ¢‰æùË≥¥Èóú‰øÇ„ÄÇÈÄöÈÅé‰ΩøÁî®Ê≥®ÊÑèÊ©üÂà∂ÈÄ≤Ë°åÂÖÉË∑ØÂæëÂÖßÈÉ®ÂíåÂÖÉË∑ØÂæëÈñìËÅöÂêàÔºåCOMET ËûçÂêà‰∫Ü‰æÜËá™Â§öÂÄãÂÖÉË∑ØÂæëÁöÑÊΩõÂú®ÂêëÈáèÔºå‰ª•Â¢ûÂº∑ GDA È†êÊ∏¨Ê∫ñÁ¢∫ÊÄß„ÄÇËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊ∂àËûçÁ†îÁ©∂ÂíåË¶ñË¶∫ÂåñÈ©óË≠â‰∫Ü COMET ÁöÑÊúâÊïàÊÄßÔºåÁÇ∫Êé®ÈÄ≤‰∫∫È°ûÂÅ•Â∫∑Á†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇ

##### **Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations**
2501.07931v1 by Waqar Hussain, John Grundy

Given their ability for advanced reasoning, extensive contextual
understanding, and robust question-answering abilities, large language models
have become prominent in healthcare management research. Despite adeptly
handling a broad spectrum of healthcare inquiries, these models face
significant challenges in delivering accurate and practical advice for chronic
conditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5
and 4 to diabetes patient queries, assessing their depth of medical knowledge
and their capacity to deliver personalized, context-specific advice for
diabetes self-management. Our findings reveal discrepancies in accuracy and
embedded biases, emphasizing the models' limitations in providing tailored
advice unless activated by sophisticated prompting techniques. Additionally, we
observe that both models often provide advice without seeking necessary
clarification, a practice that can result in potentially dangerous advice. This
underscores the limited practical effectiveness of these models without human
oversight in clinical settings. To address these issues, we propose a
commonsense evaluation layer for prompt evaluation and incorporating
disease-specific external memory using an advanced Retrieval Augmented
Generation technique. This approach aims to improve information quality and
reduce misinformation risks, contributing to more reliable AI applications in
healthcare settings. Our findings seek to influence the future direction of AI
in healthcare, enhancing both the scope and quality of its integration.

ÊëòË¶ÅÔºöÁî±ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂÖ∑ÊúâÂÖàÈÄ≤Êé®ÁêÜËÉΩÂäõ„ÄÅÂª£Ê≥õÁöÑËÉåÊôØÁêÜËß£ËÉΩÂäõÂíåÂº∑Â§ßÁöÑÂïèÈ°åÂõûÁ≠îËÉΩÂäõÔºåÂõ†Ê≠§Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÁÆ°ÁêÜÁ†îÁ©∂‰∏≠ËÆäÂæóÁ™ÅÂá∫„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãËÉΩÁÜüÁ∑¥Âú∞ËôïÁêÜÂª£Ê≥õÁöÑÈÜ´ÁôÇ‰øùÂÅ•Êü•Ë©¢Ôºå‰ΩÜÂú®Êèê‰æõÊÖ¢ÊÄßÁñæÁóÖÔºà‰æãÂ¶ÇÁ≥ñÂ∞øÁóÖÔºâÁöÑÊ∫ñÁ¢∫‰∏îÂØ¶Áî®ÁöÑÂª∫Ë≠∞ÊñπÈù¢ÔºåÈÄô‰∫õÊ®°ÂûãÈù¢Ëá®ËëóÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü ChatGPT ÁâàÊú¨ 3.5 Âíå 4 Â∞çÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊü•Ë©¢ÁöÑÂõûÊáâÔºåË©ï‰º∞‰∫Ü‰ªñÂÄëÁöÑÈÜ´Â≠∏Áü•Ë≠òÊ∑±Â∫¶‰ª•ÂèäÊèê‰æõÈáùÂ∞çÁ≥ñÂ∞øÁóÖËá™ÊàëÁÆ°ÁêÜÁöÑÂÄãÊÄßÂåñ„ÄÅÁâπÂÆöÊñºËÉåÊôØÁöÑÂª∫Ë≠∞ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíåÂÖßÂµåÂÅèÂ∑ÆÁöÑÂ∑ÆÁï∞ÔºåÂº∑Ë™ø‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Êú™Á∂ìË§áÈõúÊèêÁ§∫ÊäÄË°ìÂïüÁî®ÊôÇÊèê‰æõÂÆöÂà∂Âª∫Ë≠∞ÁöÑÂ±ÄÈôêÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞ÈÄôÂÖ©ÂÄãÊ®°ÂûãÈÄöÂ∏∏Âú®‰∏çÂ∞ãÊ±ÇÂøÖË¶ÅÁöÑÊæÑÊ∏ÖÁöÑÊÉÖÊ≥Å‰∏ãÊèê‰æõÂª∫Ë≠∞ÔºåÈÄôÁ®ÆÂÅöÊ≥ïÂèØËÉΩÊúÉÂ∞éËá¥ÊΩõÂú®ÁöÑÂç±Èö™Âª∫Ë≠∞„ÄÇÈÄôÂá∏È°Ø‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Ê≤íÊúâËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑ‰∫∫Â∑•Áõ£Áù£ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áî®ÊúâÊïàÊÄßÊúâÈôê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∏∏Ë≠òË©ï‰º∞Â±§ÔºåÁî®ÊñºÊèêÁ§∫Ë©ï‰º∞Âíå‰ΩøÁî®ÂÖàÈÄ≤ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊäÄË°ìÊï¥ÂêàÁâπÂÆöÁñæÁóÖÁöÑÂ§ñÈÉ®Ë®òÊÜ∂È´î„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊó®Âú®ÊèêÈ´òË≥áË®äÂìÅË≥™‰∏¶Èôç‰ΩéÈåØË™§Ë≥áË®äÈ¢®Èö™ÔºåÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Âª∫Á´ãÊõ¥ÂèØÈù†ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºè„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊó®Âú®ÂΩ±Èüø‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÊñπÂêëÔºåÂêåÊôÇÊèêÂçáÂÖ∂Êï¥ÂêàÁöÑÁØÑÂúçÂíåÂìÅË≥™„ÄÇ

##### **Large Language Models for Interpretable Mental Health Diagnosis**
2501.07653v1 by Brian Hyeongseok Kim, Chao Wang

We propose a clinical decision support system (CDSS) for mental health
diagnosis that combines the strengths of large language models (LLMs) and
constraint logic programming (CLP). Having a CDSS is important because of the
high complexity of diagnostic manuals used by mental health professionals and
the danger of diagnostic errors. Our CDSS is a software tool that uses an LLM
to translate diagnostic manuals to a logic program and solves the program using
an off-the-shelf CLP engine to query a patient's diagnosis based on the encoded
rules and provided data. By giving domain experts the opportunity to inspect
the LLM-generated logic program, and making modifications when needed, our CDSS
ensures that the diagnosis is not only accurate but also interpretable. We
experimentally compare it with two baseline approaches of using LLMs:
diagnosing patients using the LLM-only approach, and using the LLM-generated
logic program but without expert inspection. The results show that, while LLMs
are extremely useful in generating candidate logic programs, these programs
still require expert inspection and modification to guarantee faithfulness to
the official diagnostic manuals. Additionally, ethical concerns arise from the
direct use of patient data in LLMs, underscoring the need for a safer hybrid
approach like our proposed method.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÂøÉÁêÜÂÅ•Â∫∑Ë®∫Êñ∑ÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS)ÔºåÂÆÉÁµêÂêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁ¥ÑÊùüÈÇèËºØÁ®ãÂºèË®≠Ë®à (CLP) ÁöÑÂÑ™Èªû„ÄÇÊìÅÊúâ CDSS ÂæàÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂøÉÁêÜÂÅ•Â∫∑Â∞àÊ•≠‰∫∫Â£´‰ΩøÁî®ÁöÑË®∫Êñ∑ÊâãÂÜäÈùûÂ∏∏Ë§áÈõúÔºåËÄå‰∏îË®∫Êñ∑ÈåØË™§ÂæàÂç±Èö™„ÄÇÊàëÂÄëÁöÑ CDSS ÊòØ‰∏ÄÂÄãËªüÈ´îÂ∑•ÂÖ∑ÔºåÂÆÉ‰ΩøÁî® LLM Â∞áË®∫Êñ∑ÊâãÂÜäËΩâÊèõÊàêÈÇèËºØÁ®ãÂºèÔºå‰∏¶‰ΩøÁî®ÁèæÊàêÁöÑ CLP ÂºïÊìéËß£Ê±∫Á®ãÂºèÔºå‰ª•Ê†πÊìöÁ∑®Á¢ºË¶èÂâáÂíåÊèê‰æõÁöÑË≥áÊñôÊü•Ë©¢ÁóÖ‰∫∫ÁöÑË®∫Êñ∑„ÄÇÈÄèÈÅéËÆìÈ†òÂüüÂ∞àÂÆ∂ÊúâÊ©üÊúÉÊ™¢Êü• LLM ÁîüÊàêÁöÑÈÇèËºØÁ®ãÂºèÔºå‰∏¶Âú®ÈúÄË¶ÅÊôÇÈÄ≤Ë°å‰øÆÊîπÔºåÊàëÂÄëÁöÑ CDSS ÂèØÁ¢∫‰øùË®∫Êñ∑‰∏çÂÉÖÊ∫ñÁ¢∫ÔºåËÄå‰∏îÂèØËß£ËÆÄ„ÄÇÊàëÂÄë‰ª•ÂØ¶È©óÁöÑÊñπÂºèÂ∞áÂÖ∂ËàáÂÖ©Á®Æ‰ΩøÁî® LLM ÁöÑÂü∫Á∑öÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉÔºöÂÉÖ‰ΩøÁî® LLM ÊñπÊ≥ïË®∫Êñ∑ÁóÖ‰∫∫Ôºå‰ª•Âèä‰ΩøÁî® LLM ÁîüÊàêÁöÑÈÇèËºØÁ®ãÂºèÔºå‰ΩÜÊ≤íÊúâÂ∞àÂÆ∂Ê™¢Êü•„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÈõñÁÑ∂ LLM Âú®Áî¢ÁîüÂÄôÈÅ∏ÈÇèËºØÁ®ãÂºèÊñπÈù¢ÈùûÂ∏∏ÊúâÁî®Ôºå‰ΩÜÈÄô‰∫õÁ®ãÂºè‰ªçÁÑ∂ÈúÄË¶ÅÂ∞àÂÆ∂Ê™¢Êü•Âíå‰øÆÊîπÔºå‰ª•Á¢∫‰øùÂ∞çÂÆòÊñπË®∫Êñ∑ÊâãÂÜäÁöÑÂø†ÂØ¶Â∫¶„ÄÇÊ≠§Â§ñÔºåÁõ¥Êé•Âú® LLM ‰∏≠‰ΩøÁî®ÁóÖ‰∫∫Ë≥áÊñôÊúÉÂºïÁôºÂÄ´ÁêÜÂïèÈ°åÔºåÈÄôÂº∑Ë™ø‰∫ÜÈúÄË¶Å‰∏ÄÁ®ÆÊõ¥ÂÆâÂÖ®ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÔºå‰æãÂ¶ÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇ</paragraph>

##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

ÊëòË¶ÅÔºöËá™ÂãïÂåñËÉ∏ÈÉ® X ÂÖâÁâáËß£ËÆÄÈúÄË¶ÅÁ≤æÊ∫ñÁöÑÁñæÁóÖÂàÜÈ°ûÂíåË©≥Á¥∞ÁöÑÊîæÂ∞ÑÁßëÂ†±ÂëäÁîüÊàêÔºåÈÄôÂ∞çËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁõÆÂâçÁöÑÂÅöÊ≥ïË¶Å‰∏çÂ∞±ÊòØ‰ª•ÁäßÁâ≤ÂèØËß£ËÆÄÊÄßÁÇ∫‰ª£ÂÉπÂ∞àÊ≥®ÊñºÂàÜÈ°ûÊ∫ñÁ¢∫ÊÄßÔºåË¶Å‰∏çÂ∞±ÊòØÈÄèÈÅéÂΩ±ÂÉèÊ®ôÈ°åÊäÄË°ìÁî¢ÁîüË©≥Á¥∞‰ΩÜÂèØËÉΩ‰∏çÂèØÈù†ÁöÑÂ†±Âëä„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ RadAlignÔºå‰∏ÄÂÄãÁµêÂêà‰∫ÜË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜËÉΩÂäõÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇÂèóÂà∞ÊîæÂ∞ÑÁßëÈÜ´Â∏´Â∑•‰ΩúÊµÅÁ®ãÁöÑÂïüÁôºÔºåRadAlign È¶ñÂÖàÊé°Áî®Â∞àÈñÄÁöÑ VLM Â∞áË¶ñË¶∫ÁâπÂæµËàáÈóúÈçµÈÜ´ÁôÇÊ¶ÇÂøµÂ∞çÈΩäÔºåÂú®Â§öÁ®ÆÁñæÁóÖ‰∏≠ÈÅîÊàêÂÑ™Áï∞ÁöÑÁñæÁóÖÂàÜÈ°ûÔºåÂπ≥Âùá AUC ÁÇ∫ 0.885„ÄÇÈÄô‰∫õË≠òÂà•Âá∫ÁöÑÈÜ´ÁôÇÁãÄÊ≥ÅÊúÉÂú®Â∞çÈΩäÁöÑË¶ñË¶∫Ë™ûË®ÄÁ©∫Èñì‰∏≠Ë°®Á§∫ÁÇ∫Âü∫ÊñºÊñáÂ≠óÁöÑÊ¶ÇÂøµÔºåÁÑ∂ÂæåÁî®‰æÜÊèêÁ§∫Âü∫Êñº LLM ÁöÑÂ†±ÂëäÁîüÊàê„ÄÇÈÄèÈÅé‰∏ÄÁ®ÆÂ∞áËº∏Âá∫ÁµêÊûúÂª∫Á´ãÂú®È°û‰ººÈÅéÂæÄÊ°à‰æã‰∏≠ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊ©üÂà∂ÔºåRadAlign Êèê‰æõÂÑ™Áï∞ÁöÑÂ†±ÂëäÂìÅË≥™ÔºåGREEN ÂàÜÊï∏ÁÇ∫ 0.678ÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑ 0.634„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÁ∂≠ÊåÅÂº∑Â§ßÁöÑËá®Â∫äÂèØËß£ËÆÄÊÄßÔºåÂêåÊôÇÊ∏õÂ∞ëÂπªË¶∫ÔºåÈÄèÈÅéÊï¥ÂêàÈ†êÊ∏¨ÂíåÁîüÊàêÂºè AIÔºåÊé®ÈÄ≤Ëá™ÂãïÂåñÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÂ†±ÂëäÂàÜÊûê„ÄÇÁ®ãÂºèÁ¢ºÂèØÊñº https://github.com/difeigu/RadAlign ÂèñÂæó„ÄÇ

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

ÊëòË¶ÅÔºö<paragraph>ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±Âú®ÊïàÁéá„ÄÅÂèØÂèäÊÄßÂíåÂÄã‰∫∫ÂåñÊñπÈù¢ÊåÅÁ∫åÈù¢Ëá®ÊåëÊà∞„ÄÇÈ´îÁèæÂºè AI (EmAI) Áî±Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂíå‰∏ñÁïåÊ®°ÂûãÁ≠âÁèæ‰ª£ AI ÊäÄË°ìÊèê‰æõÊîØÊåÅÔºå‰ª£Ë°®‰∫Ü‰∏ÄÂÄãËΩâÂûãÂâçÊ≤øÔºåÊèê‰æõÂ¢ûÂº∑ÁöÑËá™‰∏ªÊÄßÔºå‰ª•ÂèäËàáÁâ©ÁêÜ‰∏ñÁïå‰∫íÂãï‰ª•ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÁöÑËÉΩÂäõ„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãË∑®Â≠∏Áßë‰∏îÂø´ÈÄüÁôºÂ±ïÁöÑÁ†îÁ©∂È†òÂüüÔºå„ÄåÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ EmAI„ÄçÊ∂µËìã‰∫ÜÊºîÁÆóÊ≥ï„ÄÅÊ©üÂô®‰∫∫ÂíåÁîüÁâ©ÈÜ´Â≠∏Á≠âÂ§öÂÖÉÈ†òÂüü„ÄÇÈÄôÁ®ÆË§áÈõúÊÄßÁ™ÅÈ°Ø‰∫ÜÂèäÊôÇÂØ©Êü•ÂíåÂàÜÊûêÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ËøΩËπ§ÈÄ≤Â±ï„ÄÅÊáâÂ∞çÊåëÊà∞‰∏¶‰øÉÈÄ≤Ë∑®Â≠∏ÁßëÂêà‰Ωú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü EmAI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ„ÄåÂ§ßËÖ¶„ÄçÁöÑÂÖ®Èù¢Ê¶ÇËø∞ÔºåÊàëÂÄëÂú®ÂÖ∂‰∏≠‰ªãÁ¥π‰∫ÜÊÑüÁü•„ÄÅÂü∑Ë°å„ÄÅË¶èÂäÉÂíåË®òÊÜ∂ÁöÑÂü∫Êú¨ AI ÊºîÁÆóÊ≥ïÔºå‰∏¶Â∞àÊ≥®ÊñºÂëàÁèæÊ∂µËìãËá®Â∫äÂπ≤È†ê„ÄÅÊó•Â∏∏ÁÖßË≠∑ÂíåÈô™‰º¥„ÄÅÂü∫Á§éË®≠ÊñΩÊîØÊè¥ÂíåÁîüÁâ©ÈÜ´Â≠∏Á†îÁ©∂ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÂÑòÁÆ°ÂâçÊôØÁúãÂ•ΩÔºå‰ΩÜ EmAI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÁôºÂ±ïÂèóÂà∞ÈóúÈçµÊåëÊà∞ÁöÑÈòªÁ§ôÔºå‰æãÂ¶ÇÂÆâÂÖ®ÂïèÈ°å„ÄÅÊ®°Êì¨Âπ≥Âè∞ÂíåÂØ¶ÈöõÊáâÁî®‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÅÁº∫‰πèÊ®ôÊ∫ñÂåñÂü∫Ê∫ñÔºå‰ª•ÂèäË∑®Â≠∏ÁßëÈ†òÂüüÈÄ≤Â±ï‰∏çÂùá„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÊäÄË°ìÈöúÁ§ô‰∏¶Êé¢Ë®é‰∫ÜÈÅìÂæ∑ËÄÉÈáèÔºåÂ∞ç EmAI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÊèê‰æõ‰∫ÜÂâçÁûªÊÄßÁöÑËßÄÈªû„ÄÇÈÇÑÂºïÂÖ•‰∫Ü EmAI Á≥ªÁµ±ÁöÑÊô∫ÊÖßÂ±§Á¥öÊû∂ÊßãÔºå‰ª•ÊåáÂ∞éÈÄ≤‰∏ÄÊ≠•ÁöÑÁôºÂ±ï„ÄÇÈÄèÈÅéÊèê‰æõÁ≥ªÁµ±ÊÄßÁöÑË¶ãËß£ÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®ÊøÄÁôºÂâµÊñ∞ÂíåÂØ¶Áî®ÊáâÁî®ÔºåÁÇ∫Êô∫ÊÖß‰∏î‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Êñ∞ÊôÇ‰ª£Èã™Ë∑Ø„ÄÇ</paragraph>

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠È´îÁ©çÂà∞È´îÁ©çÁöÑÁøªË≠ØÂèñÂæóÊàêÂäüÔºå‰ΩÜÁèæÊúâÁöÑÊ®°ÂûãÂ§ßÂ§öÈõ£‰ª•ÊúâÊïàÂú∞‰ΩøÁî® 3D ÂëàÁèæ‰æÜÊì∑ÂèñÂõ∫ÊúâÁöÑÈ´îÁ©çÂàÜ‰Ωà„ÄÇÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÊòØÈÄèÈÅéÂä†Ê¨äÂπ≥Âùá‰æÜÁµêÂêàÂ§öÂÄãÂü∫Êñº 2D ÁöÑÁ∂≤Ë∑ØÔºåÂõ†Ê≠§ÂøΩÁï•‰∫Ü 3D Á©∫ÈñìÁµêÊßã„ÄÇÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Áõ¥Êé•Ë®ìÁ∑¥ 3D Ê®°ÂûãÊúÉÁî¢ÁîüÈ°ØËëóÁöÑÊåëÊà∞ÔºåÂéüÂõ†Âú®ÊñºÈ´òÈÅãÁÆóÈúÄÊ±ÇÂíåÂ§ßË¶èÊ®°Ë≥áÊñôÈõÜÁöÑÈúÄÊ±Ç„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Diff-EnsemblerÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ∑∑Âêà 2D-3D Ê®°ÂûãÔºåÂèØÈÄèÈÅéÂú®ÊØèÂÄãÊì¥Êï£Ê≠•È©ü‰∏≠Â∞áÂûÇÁõ¥Ë®ìÁ∑¥ÁöÑ 2D Êì¥Êï£Ê®°ÂûãËàá 3D Á∂≤Ë∑ØÁµêÂêàÔºå‰æÜÊúâÊïàÁéá‰∏îÊúâÊïàÂú∞ÈÄ≤Ë°åÈ´îÁ©çËΩâÊèõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Ëá™ÁÑ∂Âú∞Áî®ÊñºÁµêÂêàÂü∫Êñº‰∏çÂêåÂΩ¢ÂºèÁöÑÊì¥Êï£Ê®°ÂûãÔºåÂæûËÄåÈùàÊ¥ª‰∏îÊ∫ñÁ¢∫Âú∞ËûçÂêàËº∏ÂÖ•Ê¢ù‰ª∂„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåDiff-Ensembler Âú® 3D ÈÜ´Â≠∏ÂΩ±ÂÉèË∂ÖËß£ÊûêÂ∫¶ÂíåÂΩ¢ÂºèËΩâÊèõ‰∏≠ÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÈ´îÁ©çÁúüÂØ¶ÊÑü„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•‰ΩøÁî®ËÖ´Áò§ÂàÜÂâ≤‰ΩúÁÇ∫‰∏ãÊ∏∏‰ªªÂãôÔºå‰æÜË≠âÊòéÊàëÂÄëÊ®°ÂûãÁöÑÈ´îÁ©çÁúüÂØ¶ÊÑü„ÄÇ

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

ÊëòË¶ÅÔºöÁµÑÂêàÂºèËó•Áâ©Êé®Ëñ¶ (CMR) ÊòØÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÂÆÉÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõ‰∫ÜÈáùÂ∞çÂÖ∑ÊúâË§áÈõúÂÅ•Â∫∑ÁãÄÊ≥ÅÁöÑÊÇ£ËÄÖÊèê‰æõÊõ¥Á≤æÁ¢∫ËôïÊñπÁöÑÊ©üÊúÉÔºåÁâπÂà•ÊòØÂú®Èï∑ÊúüÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑•‰ΩúË©¶ÂúñÂæûÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ‰∏≠ÊèêÂèñÊúâÊÑèÁæ©ÁöÑË≥áË®äÔºå‰ª•‰øÉÈÄ≤ÁµÑÂêàÂºèËó•Áâ©Êé®Ëñ¶„ÄÇÁèæÊúâÁöÑÂü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÈÄ≤‰∏ÄÊ≠•ËÄÉÊÖÆ‰∫ÜËó•Áâ©ÁöÑÂåñÂ≠∏ÁµêÊßãÔºå‰ΩÜÂøΩÁï•‰∫ÜÂäüËÉΩÊ∏ÖÊ•öÊèèËø∞ÊñºÂÖ∂‰∏≠ÁöÑÊñáÊú¨Ëó•Áâ©Ë™™Êòé„ÄÇÊ≠§Â§ñÔºåÂæûÊÇ£ËÄÖÁöÑ EHR ‰∏≠Ë°çÁîüÁöÑÊñáÊú¨Áü•Ë≠òÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÂà©Áî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËºîÂä©Â§öÊ®°ÂºèËó•Áâ©Êé®Ëñ¶ (NLA-MMR)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊ®°ÂºèÂ∞çÈΩäÊ°ÜÊû∂ÔºåÊó®Âú®ÂæûÊÇ£ËÄÖË¶ñËßíÂíåËó•Áâ©Ë¶ñËßíÂÖ±ÂêåÂ≠∏ÁøíÁü•Ë≠ò„ÄÇÂÖ∑È´î‰æÜË™™ÔºåNLA-MMR Â∞á CMR ÊßãÂª∫ÁÇ∫ÊÇ£ËÄÖÂíåËó•Áâ©Ê®°ÂºèÁöÑÂ∞çÈΩäÂïèÈ°å„ÄÇÂú®Ê≠§ËÑàÁµ°‰∏≠ÔºåÊàëÂÄëÊé°Áî®È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ‰æÜÊèêÂèñÊúâÈóúÊÇ£ËÄÖÂíåËó•Áâ©ÁöÑÈ†òÂüüÂÖßÁü•Ë≠òÔºå‰ΩúÁÇ∫ÈÄôÂÖ©Á®ÆÊ®°ÂºèÁöÑÂü∫Êú¨Ë°®Á§∫„ÄÇÂú®Ëó•Áâ©Ê®°Âºè‰∏≠ÔºåÊàëÂÄëÂà©Áî®ÂåñÂ≠∏ÁµêÊßãÂíåÊñáÊú¨Ë™™Êòé‰æÜÂª∫Á´ãËó•Áâ©Ë°®Á§∫„ÄÇÂú®ÊÇ£ËÄÖÊ®°Âºè‰∏≠ÔºåÊàëÂÄëÊ†πÊìöË®∫Êñ∑„ÄÅÁ®ãÂ∫èÂíåÁóáÁãÄÁöÑÊñáÂ≠óË™™Êòé‰æÜÁîüÊàêÊÇ£ËÄÖË°®Á§∫„ÄÇÂú®‰∏âÂÄãÂÖ¨ÈñãÂ≠òÂèñÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåNLA-MMR ÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩÔºåÂÇëÂç°Âæ∑ÊåáÊï∏Âπ≥ÂùáÊîπÈÄ≤‰∫Ü 4.72%„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ¢ºÂÖ¨ÈñãÊñº https://github.com/jtan1102/NLA-MMR_CIKM_2024„ÄÇ

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

ÊëòË¶ÅÔºöÂú®ÈÑ∞ÈáåÂ±§Á¥öÊó©ÊúüÂÅµÊ∏¨ÂíåÈ†êÊ∏¨ËÄÅÂπ¥‰∫∫ÁöÑÂÅ•Â∫∑ÁãÄÊ≥Å‰∏ãÈôçÂ∞çÂüéÂ∏ÇË¶èÂäÉÂíåÂÖ¨ÂÖ±Ë°õÁîüÊîøÁ≠ñÂà∂ÂÆöÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇÂÑòÁÆ°ÁèæÊúâÁ†îÁ©∂ËÇØÂÆö‰∫ÜÁîüÊ¥ªÁí∞Â¢ÉËàáÂÅ•Â∫∑ÁµêÊûú‰πãÈñìÁöÑÈóúËÅØÊÄßÔºå‰ΩÜÂ§ßÂ§ö‰æùË≥¥ÂñÆ‰∏ÄË≥áÊñôÊ®°ÂºèÊàñÂ§öÊ®°ÂºèË≥áË®äÁöÑÁ∞°ÂåñÁâπÂæµ‰∏≤Êé•ÔºåÈôêÂà∂‰∫Ü‰ªñÂÄëÂÖ®Èù¢ÊèèÁπ™‰ª•ÂÅ•Â∫∑ÁÇ∫Â∞éÂêëÁöÑÂüéÂ∏ÇÁí∞Â¢ÉÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CureGraphÔºå‰∏ÄÂÄãÁî®ÊñºÂüéÂ∏ÇÂÅ•Â∫∑È†êÊ∏¨ÁöÑÂ∞çÊØîÂºèÂ§öÊ®°ÂºèË°®Á§∫Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÊé°Áî®Âü∫ÊñºÂúñÂΩ¢ÊäÄË°ì‰æÜÊé®Ë´ñÊØèÂÄãÈÑ∞ÈáåÂüéÂ∏ÇÁîüÊ¥ªÂúà‰∏≠ËÄÅÂπ¥‰∫∫Â∏∏Ë¶ãÊÖ¢ÊÄßÁñæÁóÖÁöÑÊµÅË°åÁéá„ÄÇCureGraph Âà©Áî®Ë±êÂØåÁöÑÂ§öÊ®°ÂºèË≥áË®äÔºåÂåÖÊã¨‰ΩèÂÆÖÂçÄÂèäÂÖ∂Âë®ÂúçÊôØÈªûÁöÑÁÖßÁâáÂíåÊñáÂ≠óË©ïË´ñÔºå‰æÜÁî¢ÁîüÂüéÂ∏ÇÈÑ∞ÈáåÂµåÂÖ•„ÄÇÈÄèÈÅéÊï¥ÂêàÈ†êÂÖàË®ìÁ∑¥ÁöÑË¶ñË¶∫ÂíåÊñáÂ≠óÁ∑®Á¢ºÂô®ËàáÂúñÂΩ¢Âª∫Ê®°ÊäÄË°ìÔºåCureGraph ÊçïÊçâË∑®Ê®°ÂºèÁ©∫Èñì‰æùË≥¥ÊÄßÔºåÊèê‰æõÂ∞çÂüéÂ∏ÇÁí∞Â¢ÉÁöÑÂÖ®Èù¢ÁêÜËß£ÔºåÂ∞àÈñÄÈáùÂ∞çËÄÅÂπ¥‰∫∫ÁöÑÂÅ•Â∫∑ËÄÉÈáè„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåCureGraph Âú®ËÄÅÂπ¥‰∫∫ÁñæÁóÖÈ¢®Èö™È†êÊ∏¨‰ªªÂãô‰∏≠ÔºåÂπ≥ÂùáÂú® R2 ÊñπÈù¢Â∞áÊúÄ‰Ω≥Âü∫Ê∫ñÁ∑öÊèêÈ´ò‰∫Ü 28%„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãËÉΩÂ§†Ë≠òÂà•ÈöéÊÆµÊÄßÁöÑÊÖ¢ÊÄßÁñæÁóÖÈÄ≤Á®ãÔºå‰∏¶ÊîØÊè¥Ë∑®ÈÑ∞ÈáåÁöÑÊØîËºÉÂÖ¨ÂÖ±Ë°õÁîüÂàÜÊûêÔºåÁÇ∫Ê∞∏Á∫åÁöÑÂüéÂ∏ÇÁôºÂ±ïÂíåÊèêÂçáÁîüÊ¥ªÂìÅË≥™Êèê‰æõÂèØË°åÁöÑË¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jinlin2021/CureGraph„ÄÇ

##### **UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM**
2501.07017v1 by Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi

3D medical image segmentation has progressed considerably due to
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these
methods struggle to balance long-range dependency acquisition with
computational efficiency. To address this challenge, we propose UNETVL (U-Net
Vision-LSTM), a novel architecture that leverages recent advancements in
temporal information processing. UNETVL incorporates Vision-LSTM (ViL) for
improved scalability and memory functions, alongside an efficient Chebyshev
Kolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency
patterns more effectively. We validated our method on the ACDC and AMOS2022
(post challenge Task 2) benchmark datasets, showing a significant improvement
in mean Dice score compared to recent state-of-the-art approaches, especially
over its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,
respectively. Extensive ablation studies were conducted to demonstrate the
impact of each component in UNETVL, providing a comprehensive understanding of
its architecture. Our code is available at https://github.com/tgrex6/UNETVL,
facilitating further research and applications in this domain.

ÊëòË¶ÅÔºö3D ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Â∑≤Âõ†Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåË¶ñË¶∫ËΩâÊèõÂô® (ViT) ËÄåÂ§ßÂπÖÈÄ≤Â±ïÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÈõ£‰ª•Âú®ÈÅ†Á®ã‰æùË≥¥ÂèñÂæóËàáÈÅãÁÆóÊïàÁéá‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ UNETVL (U-Net Vision-LSTM)Ôºå‰∏ÄÁ®ÆÂà©Áî®ÊôÇÈñìË≥áË®äËôïÁêÜÊúÄÊñ∞ÈÄ≤Â±ïÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇUNETVL ÁµêÂêàË¶ñË¶∫ LSTM (ViL) ‰ª•ÊîπÂñÑÂèØÊì¥ÂÖÖÊÄßÂíåË®òÊÜ∂È´îÂäüËÉΩÔºå‰∏¶ÁµêÂêàÈ´òÊïàÁöÑ Chebyshev Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN) ‰ª•Êõ¥ÊúâÊïàÂú∞ËôïÁêÜË§áÈõú‰∏îÈÅ†Á®ãÁöÑ‰æùË≥¥Ê®°Âºè„ÄÇÊàëÂÄëÂú® ACDC Âíå AMOS2022ÔºàÊåëÊà∞‰ªªÂãô 2ÔºâÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåËàáÊúÄËøëÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÈ°ØÁ§∫Âπ≥Âùá Dice ÂàÜÊï∏ÊúâÈ°ØËëóÊîπÂñÑÔºåÁâπÂà•ÊòØËàáÂÖ∂ÂâçË∫´ UNETR Áõ∏ÊØîÔºåÂú® ACDC ‰∏äÂ¢ûÂä†‰∫Ü 7.3%ÔºåÂú® AMOS ‰∏äÂ¢ûÂä†‰∫Ü 15.6%„ÄÇÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•Â±ïÁ§∫ UNETVL ‰∏≠ÊØèÂÄãÁµÑÊàêÁöÑÂΩ±ÈüøÔºåÊèê‰æõÂ∞çÂÖ∂Êû∂ÊßãÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/tgrex6/UNETVL ÂèñÂæóÔºå‰øÉÈÄ≤Ê≠§È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂíåÊáâÁî®„ÄÇ

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏ÁøíÔºàRLÔºâÂú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÊáâÁî®Êó•ÁõäÂª£Ê≥õÔºåÁâπÂà•ÊòØÁî®ÊñºÈñãÁôºÂÄã‰∫∫ÂåñÂÅ•Â∫∑ÈÅ©ÊáâÊÄßÂπ≤È†êÊé™ÊñΩ„ÄÇÂèóÂà∞Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊàêÂäüÁöÑÂïüÁôºÔºåÊàëÂÄëÊúâËààË∂£‰ΩøÁî® LLM Âç≥ÊôÇÊõ¥Êñ∞ RL ÊîøÁ≠ñÔºåÁõÆÊ®ôÊòØÂä†ÈÄüÂÄã‰∫∫Âåñ„ÄÇÊàëÂÄë‰ΩøÁî®Âü∫ÊñºÊñáÂ≠óÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•Ω‰æÜÂΩ±ÈüøË°åÂãïÈÅ∏ÊìáÔºå‰ª•‰æøÁ´ãÂç≥Á¥çÂÖ•‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÇÊàëÂÄë‰ΩøÁî®„Äå‰ΩøÁî®ËÄÖÂÅèÂ•Ω„Äç‰∏ÄË©û‰ΩúÁÇ∫Âª£Áæ©Ë©ûÔºåÁî®‰æÜÊåá‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫ÂÅèÂ•Ω„ÄÅÈôêÂà∂„ÄÅÂÅ•Â∫∑ÁãÄÊ≥ÅÊàñË°®ÈÅîÂ•ΩÊÉ°ÁöÑÈô≥Ëø∞Á≠â„ÄÇÊàëÂÄëÁöÑÊñ∞Á©éÊñπÊ≥ïÊòØ‰∏ÄÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÔºåÁµêÂêà‰∫Ü LLM ÂõûÊáâÂíå RL Ë°åÂãïÈÅ∏Êìá‰ª•ÊîπÂñÑ RL ÊîøÁ≠ñ„ÄÇÁµ¶ÂÆöÂåÖÂê´‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑ LLM ÊèêÁ§∫ÔºåLLM Âú®ÂÖ∏ÂûãÁöÑ RL Ë°åÂãïÈÅ∏Êìá‰∏≠ÂÖÖÁï∂ÈÅéÊøæÂô®„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•ÂíåË°åÂãïÈÅ∏ÊìáÁ≠ñÁï•„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÊ®°Êì¨Áí∞Â¢ÉÔºåÁî®ÊñºÁî¢ÁîüÂü∫ÊñºÊñáÂ≠óÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºå‰∏¶Â∞çÂΩ±ÈüøË°åÁÇ∫ÂãïÊÖãÁöÑÈôêÂà∂ÈÄ≤Ë°åÂª∫Ê®°„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïËÉΩÂ§†ËÄÉÈáèÂü∫ÊñºÊñáÂ≠óÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÂêåÊôÇÊîπÂñÑ RL ÊîøÁ≠ñÔºåÂæûËÄåÊîπÂñÑÈÅ©ÊáâÊÄßÂπ≤È†ê‰∏≠ÁöÑÂÄã‰∫∫Âåñ„ÄÇ

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ËßíËâ≤ÊâÆÊºîÂ†¥ÊôØ‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®Ê®°Êì¨ÁâπÂÆöÈ†òÂüüÁöÑÂ∞àÂÆ∂ÊôÇÔºåÊúÉ‰ΩøÁî®ÈáèË∫´ÊâìÈÄ†ÁöÑÊèêÁ§∫„ÄÇÈÄôÁ®ÆËÉΩÂäõ‰Ωø LLM ËÉΩÂ§†Êé°Áî®ÂÖ∑ÊúâÁâπÂÆöËÉåÊôØÁöÑÂÄã‰∫∫ËßíËâ≤ÔºåÊèê‰æõ‰∏ÄÁ®ÆÁ∂ìÊøüÂØ¶ÊÉ†‰∏îÊúâÊïàÁéáÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁî®ÊñºÂÇ≥Áµ±‰∏îË≥áÊ∫êÂØÜÈõÜÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂„ÄÇÈÄèÈÅéÊ®°Êì¨‰∫∫È°ûË°åÁÇ∫ÔºåLLM ËÉΩÂ§†Ê†πÊìöÂÖ∑È´îÁöÑ‰∫∫Âè£Áµ±Ë®àÊàñÂ∞àÊ•≠ÁâπÂæµÈ†êÊ∏¨ÂèçÊáâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü LLM Âú®Ê®°Êì¨ÂÖ∑Êúâ‰∏çÂêåËÉåÊôØÁöÑÂÄã‰∫∫ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºå‰∏¶ÂàÜÊûê‰∫ÜÈÄô‰∫õÊ®°Êì¨Ë°åÁÇ∫ËàáÂØ¶ÈöõÁµêÊûúÁõ∏ÊØîÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü LLM Ëß£ÈáãÂíåÂõûÊáâÊèê‰æõÁµ¶Èõ¢ÈñãÂä†Ë≠∑ÁóÖÊàø (ICU) ÊÇ£ËÄÖÁöÑÂá∫Èô¢ÊëòË¶ÅÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëË©ï‰º∞‰∏¶Ëàá‰∫∫È°ûÁöÑÂèçÊáâÊØîËºÉ‰∫Ü‰∏çÂêåÊïôËÇ≤ËÉåÊôØÁöÑÂÄã‰∫∫Â∞çÂá∫Èô¢ÊëòË¶ÅÁöÑÂèØÁêÜËß£ÊÄßÔºå‰∏¶‰ΩøÁî®Ê≠§ÂàÜÊûê‰æÜË©ï‰º∞ LLM È©ÖÂãïÊ®°Êì¨ÁöÑÂÑ™ÈªûÂíåÈôêÂà∂„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁï∂ LLM Ë¢´Ê§çÂÖ•ÊïôËÇ≤ËÉåÊôØË≥áË®äÊôÇÔºå‰ªñÂÄëÂú® 88% ÁöÑÊôÇÈñìÂÖßÈÉΩËÉΩÊèê‰æõÊ∫ñÁ¢∫‰∏îÂèØË°åÁöÑÈÜ´ÁôÇÊåáÂ∞é„ÄÇ‰ΩÜÊòØÔºåÁï∂Êèê‰æõÂÖ∂‰ªñË≥áË®äÊôÇÔºåÊïàËÉΩÊúÉÈ°ØËëó‰∏ãÈôçÔºå‰ΩéÊñºÈö®Ê©üÊ©üÊúÉÁöÑÁ≠âÁ¥ö„ÄÇÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂È°ØÁ§∫‰∫ÜËá™ÂãïÁî¢Áîü‰æÜËá™‰∏çÂêåÁæ§È´îÁöÑÁâπÂÆöÊñºÊÇ£ËÄÖÁöÑÂÅ•Â∫∑Ë≥áË®äÁöÑÊΩõÂú®Â•ΩËôïÂíåÁº∫Èªû„ÄÇÂÑòÁÆ° LLM Âú®Ê®°Êì¨ÂÅ•Â∫∑ËßíËâ≤ÊñπÈù¢È°ØÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÂá∫‰∫ÜÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÂèØÈù†‰ΩøÁî®‰πãÂâçÂøÖÈ†àËß£Ê±∫ÁöÑÈóúÈçµÂ∑ÆË∑ù„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂú®Êèê‰æõÂÅ•Â∫∑Ë≥áË®äÊñπÈù¢Ôºå‰∏ÄÂÄãÁõ¥Êé•ÁöÑÊü•Ë©¢ÂõûÊáâÊ®°ÂûãÂèØ‰ª•ÂÑ™Êñº‰∏ÄÂÄãÊõ¥ÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇÈÄôÊòØ‰∫ÜËß£Â¶Ç‰ΩïÈáùÂ∞çÂÄã‰∫∫ÂåñÂÅ•Â∫∑Ê∫ùÈÄöÂÑ™Âåñ LLM ÂêåÊôÇÁ∂≠ÊåÅÊ∫ñÁ¢∫ÊÄßÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

ÊëòË¶ÅÔºöÈöèÁùÄÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂú®ÂåªÂ≠¶Êï∞ÊçÆ‰∏≠Ëé∑ÂæóÂÖ≥Ê≥®ÔºåÁ°Æ‰øùÈÄèÊòé‰∏îÂÄºÂæó‰ø°ËµñÁöÑÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÁöÆËÇ§ÁôåËØäÊñ≠‰∏≠ÔºåËôΩÁÑ∂ÁóÖÁÅ∂Ê£ÄÊµãÂíåÂàÜÁ±ªÁöÑËøõÊ≠•ÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÔºå‰ΩÜËøô‰∫õÊñπÊ≥ïÁöÑÈªëÁõíÊÄßË¥®ÂØπÁêÜËß£ÂÖ∂ÂÜ≥Á≠ñËøáÁ®ãÊûÑÊàê‰∫ÜÊåëÊàòÔºåÂØºËá¥ÂåªÁîü‰πãÈó¥ÁöÑ‰ø°‰ªªÈóÆÈ¢ò„ÄÇÊú¨Á†îÁ©∂Âà©Áî®Âú®‰∏çÂêåÁöÆËÇ§ÁóÖÂèòÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑ CLIPÔºàÂØπÊØîËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉÔºâÊ®°ÂûãÔºå‰ª•ÊçïÊçâËßÜËßâÁâπÂæÅÂíåËØäÊñ≠Ê†áÂáÜÊúØËØ≠‰πãÈó¥ÁöÑÊúâÊÑè‰πâÂÖ≥Á≥ª„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÊèêÈ´òÈÄèÊòéÂ∫¶ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ MedGrad E-CLIP ÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈÄöËøáÁªìÂêà‰∏ì‰∏∫ÁöÆËÇ§ÁóÖÂèòÁ≠âÂ§çÊùÇÂåªÂ≠¶ÂΩ±ÂÉèËÆæËÆ°ÁöÑÂä†ÊùÉÁÜµÊú∫Âà∂ÔºåÂª∫Á´ãÂú®Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑ E-CLIP ‰πã‰∏ä„ÄÇÊ≠§ÊñπÊ≥ïÁ™ÅÂá∫‰∫Ü‰∏éÁâπÂÆöËØäÊñ≠ÊèèËø∞Áõ∏ÂÖ≥ËÅîÁöÑÂÖ≥ÈîÆÂõæÂÉèÂå∫Âüü„ÄÇÂºÄÂèëÁöÑÈõÜÊàêÁÆ°ÈÅì‰∏ç‰ªÖÈÄöËøáÂåπÈÖçÁõ∏Â∫îÁöÑÊèèËø∞ÂØπÁöÆËÇ§ÁóÖÂèòËøõË°åÂàÜÁ±ªÔºåËøòÊ∑ªÂä†‰∫Ü‰∏ÄÂ±Ç‰∏ìÈó®‰∏∫ÂåªÂ≠¶Êï∞ÊçÆÂºÄÂèëÁöÑÂü∫Êú¨ÂèØËß£ÈáäÊÄß„ÄÇÈÄöËøáÁõ¥ËßÇÂú∞Ëß£ÈáäÂõæÂÉè‰∏≠‰∏çÂêåÁâπÂæÅ‰∏éËØäÊñ≠Ê†áÂáÜÁöÑÂÖ≥Á≥ªÔºåËøôÁßçÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÈ´òÁ∫ßËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê‰∏≠ÁöÑÊΩúÂäõÔºåÊúÄÁªàÊèêÈ´ò‰∫ÜÈÄèÊòéÂ∫¶„ÄÅÁ®≥ÂÅ•ÊÄßÂíåÂØπ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑËØäÊñ≠Á≥ªÁªüÁöÑ‰ø°‰ªª„ÄÇ

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂ∑≤ÊàêÁÇ∫Ëß£Ê±∫Ëá®Â∫äÁí∞Â¢É‰∏≠ÂêÑÁ®Æ‰ªªÂãôÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®‰π≥ÊàøË∂ÖÈü≥Ê≥¢ÂàÜÊûêÁöÑÊΩõÂú®ÁôºÂ±ï‰ªçÊú™ÈñãÁôº„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ BUSGenÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÈñÄË®≠Ë®àÁî®Êñº‰π≥ÊàøË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂàÜÊûêÁöÑÂü∫Á§éÁîüÊàêÊ®°Âûã„ÄÇBUSGen Âú®Ë∂ÖÈÅé 350 Ëê¨Âºµ‰π≥ÊàøË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÂ∑≤Áç≤Âæó‰π≥ÊàøÁµêÊßã„ÄÅÁóÖÁêÜÁâπÂæµÂíåËá®Â∫äËÆäÁï∞ÁöÑÂª£Ê≥õÁü•Ë≠ò„ÄÇÈÄèÈÅéÂ∞ëÈáèÈÅ©ÊáâÔºåBUSGen ÂèØ‰ª•Áî¢ÁîüÈÄºÁúü‰∏îÂÖ∑ÊúâË≥áË®äÊÄßÁöÑÁâπÂÆö‰ªªÂãôË≥áÊñôÂÑ≤Â≠òÂ∫´Ôºå‰øÉÈÄ≤ÈñãÁôºÂª£Ê≥õÁöÑ‰∏ãÊ∏∏‰ªªÂãôÊ®°Âûã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁ™ÅÈ°Ø‰∫Ü BUSGen ÁöÑÂá∫Ëâ≤ÈÅ©ÊáâÊÄßÔºåÂú®‰π≥ÁôåÁØ©Ê™¢„ÄÅË®∫Êñ∑ÂíåÈ†êÂæåÊñπÈù¢È°ØËëóË∂ÖË∂ä‰ª•ÁúüÂØ¶Ë≥áÊñôË®ìÁ∑¥ÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÂú®‰π≥ÁôåÊó©ÊúüË®∫Êñ∑‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÊâÄÊúâÈÄöÈÅéË™çË≠âÁöÑÊîæÂ∞ÑÁßëÈÜ´Â∏´ (n=9)ÔºåÂπ≥ÂùáÊïèÊÑüÂ∫¶ÊèêÈ´ò‰∫Ü 16.5%ÔºàP ÂÄº <0.0001Ôºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèèËø∞‰∫Ü‰ΩøÁî®ÁîüÊàêË≥áÊñôÁöÑË¶èÊ®°ÊïàÊáâÔºåÂÖ∂ËàáÊî∂ÈõÜÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñô‰∏ÄÊ®£ÊúâÊïàÔºåÂèØÁî®ÊñºË®ìÁ∑¥Ë®∫Êñ∑Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊîπÂñÑ‰∫Ü‰∏ãÊ∏∏Ê®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåBUSGen ‰øùË≠∑‰∫ÜÊÇ£ËÄÖÈö±ÁßÅÔºåÂõ†ÁÇ∫ÂÆÉËÉΩÂ§†ÂÆåÂÖ®ÂéªË≠òÂà•Ë≥áÊñôÂÖ±‰∫´ÔºåÂú®ÂÆâÂÖ®ÈÜ´ÁôÇË≥áÊñôÂà©Áî®ÊñπÈù¢ÂèñÂæóÈÄ≤Â±ï„ÄÇBUSGen ÁöÑÁ∑ö‰∏äÁ§∫ÁØÑÂèØÂú® https://aibus.bio ÂèñÂæó„ÄÇ

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

ÊëòË¶ÅÔºö<paragraph>ÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÂú®ÈòøÊãâ‰ºØ‰∏ñÁïå‰∏≠ÊßãÊàêÊó•ÁõäÂö¥ÈáçÁöÑÂÖ¨ÂÖ±Ë°õÁîüÂïèÈ°åÔºåÂº∑Ë™ø‰∫ÜÂ∞çÂèØÂèäÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÂ∑•ÂÖ∑ÁöÑÈúÄÊ±Ç„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÂú®ÈòøÊãâ‰ºØË™ûÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®Èù¢Ëá®ËëóÊåëÊà∞ÔºåÂåÖÊã¨Ê®ôË®òË≥áÊñôÈõÜÊúâÈôê„ÄÅË™ûË®ÄË§áÈõúÊÄßÂíåÁøªË≠ØÂÅèÂ∑Æ„ÄÇÊú¨Á†îÁ©∂ÂÖ®Èù¢Ë©ï‰º∞‰∫Ü 8 ÂÄã LLMÔºåÂåÖÊã¨‰∏ÄËà¨Â§öË™ûË®ÄÊ®°ÂûãÂíåÈõôË™ûÊ®°ÂûãÔºåÂú®‰∏çÂêåÁöÑÂøÉÁêÜÂÅ•Â∫∑Ë≥áÊñôÈõÜÔºà‰æãÂ¶Ç AraDepSu„ÄÅDreaddit„ÄÅMedMCQAÔºâ‰∏äÔºåÊé¢Ë®éÊèêÁ§∫Ë®≠Ë®à„ÄÅË™ûË®ÄÈÖçÁΩÆÔºàÈòøÊãâ‰ºØË™ûÂéüÊñáËàáÁøªË≠ØÂæåÁöÑËã±Ë™ûÔºåÂèç‰πã‰∫¶ÁÑ∂ÔºâÂíåÂ∞ëÊ¨°ÊèêÁ§∫Â∞çË®∫Êñ∑Ë°®ÁèæÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæÊèêÁ§∫Â∑•Á®ãÈ°ØËëóÂΩ±Èüø LLM ÂàÜÊï∏Ôºå‰∏ªË¶ÅÊòØÁî±ÊñºÊ∏õÂ∞ë‰∫ÜË™™ÊòéÈÅµÂæ™ÔºåÊàëÂÄëÁöÑÁµêÊßãÂåñÊèêÁ§∫Âú®Â§öÈ°ûË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÁµêÊßãËºÉ‰∏çÂö¥Ë¨πÁöÑËÆäÈ´îÔºåÂπ≥ÂùáÂ∑ÆÁï∞ÁÇ∫ 14.5%„ÄÇÈõñÁÑ∂Ë™ûË®ÄÂ∞çË°®ÁèæÁöÑÂΩ±Èüø‰∏çÂ§ßÔºå‰ΩÜÊ®°ÂûãÈÅ∏ÊìáË¢´Ë≠âÊòéËá≥ÈóúÈáçË¶ÅÔºöPhi-3.5 MoE Âú®Âπ≥Ë°°Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºåÁâπÂà•ÊòØÂú®‰∫åÂÖÉÂàÜÈ°ûÊñπÈù¢ÔºåËÄå Mistral NeMo Âú®Âö¥ÈáçÊÄßÈ†êÊ∏¨‰ªªÂãôÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑ÆÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑË°®Áèæ„ÄÇÂ∞ëÊ¨°ÊèêÁ§∫ÂßãÁµÇÊîπÂñÑË°®ÁèæÔºåÁâπÂà•ÊòØÂú® GPT-4o Mini ‰∏äËßÄÂØüÂà∞Â§öÈ°ûÂàÜÈ°ûÁöÑÈ°ØËëóÂ¢ûÁõäÔºåÂ∞áÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫ÜÂπ≥Âùá 1.58 ÂÄç„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÊèêÁ§∫ÊúÄ‰Ω≥Âåñ„ÄÅÂ§öË™ûË®ÄÂàÜÊûêÂíåÂ∞ëÊ¨°Â≠∏ÁøíÂ∞çÊñºÈñãÁôºÈÅ©ÂêàÊñáÂåñ‰∏îÊúâÊïàÁöÑÂü∫Êñº LLM ÁöÑÂøÉÁêÜÂÅ•Â∫∑Â∑•ÂÖ∑‰ª•ÊúçÂãôÈòøÊãâ‰ºØË™û‰∫∫Âè£ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

ÊëòË¶ÅÔºöËá®Â∫äË©¶È©óÊòØË©ï‰º∞Ê≤ªÁôÇÁñæÁóÖÁöÑËó•Áâ©ÊúâÊïàÊÄßÂíåÂÆâÂÖ®ÊÄßÁöÑÈªÉÈáëÊ®ôÊ∫ñ„ÄÇÈëëÊñºËó•Áâ©ÂàÜÂ≠êÁöÑÂª£Ê≥õË®≠Ë®àÁ©∫Èñì„ÄÅÈ´òÊòÇÁöÑË≤°ÂãôÊàêÊú¨ÂíåÈÄô‰∫õË©¶È©óÂ§öÂπ¥ÁöÑÊôÇÈñìË°®ÔºåËá®Â∫äË©¶È©óÁµêÊûúÈ†êÊ∏¨ÁöÑÁ†îÁ©∂Áç≤Âæó‰∫ÜÂ∑®Â§ßÁöÑÈóúÊ≥®„ÄÇÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÂøÖÈ†àÂà©Áî®Ëó•Áâ©ÂàÜÂ≠ê„ÄÅÁõÆÊ®ôÁñæÁóÖÂíåÁ¨¶ÂêàË≥áÊ†ºÊ®ôÊ∫ñÁ≠âÂ§öÁ®ÆÊ®°ÂºèÁöÑÊï∏Êìö‰æÜÊé®Êñ∑ÊàêÂäüÂíåÂ§±Êïó„ÄÇÊ≠§‰ªªÂãôÁöÑÂÖàÂâçÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶Ç HINTÔºâÈÄöÂ∏∏ÈúÄË¶ÅÂêàÊàêÂàÜÂ≠êÁöÑÊøïÂØ¶È©óÂÆ§Êï∏ÊìöÂíå/Êàñ‰æùË≥¥ÊñºÂÖàÈ©óÁü•Ë≠òÂ∞á‰∫§‰∫íÁ∑®Á¢ºÁÇ∫Ê®°ÂûãÊû∂ÊßãÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËºïÈáèÁ¥öÁöÑÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊ®°Âûã MEXA-CTPÔºå‰ª•Êï¥ÂêàÁèæÊàêÁöÑÂ§öÊ®°ÂºèÊï∏Êìö‰∏¶ÈÄöÈÅéÁ®±ÁÇ∫„ÄåÊ®°ÂºèÂ∞àÂÆ∂„ÄçÁöÑÂ∞àÁî®Ê®°ÁµÑÁî¢ÁîüÊúâÊïàÁöÑË°®Á§∫ÔºåÂêåÊôÇÈÅøÂÖçÊ®°ÂûãË®≠Ë®à‰∏≠ÁöÑ‰∫∫ÁÇ∫ÂÅèÂ∑Æ„ÄÇÊàëÂÄë‰ΩøÁî®ÊüØË•øÊêçÂ§±ÂáΩÊï∏ÊúÄ‰Ω≥Âåñ MEXA-CTPÔºå‰ª•ÊçïÊçâË∑®Ê®°ÂºèÁõ∏ÈóúÁöÑ‰∫§‰∫í„ÄÇÊàëÂÄëÂú®Ë©¶È©óÁµêÊûúÈ†êÊ∏¨ (TOP) Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåËàá HINT Áõ∏ÊØîÔºåMEXA-CTP ÂàÜÂà•Âú® F1 ÂàÜÊï∏‰∏äÊèêÈ´ò‰∫Ü 11.3%„ÄÅPR-AUC ‰∏äÊèêÈ´ò‰∫Ü 12.2%„ÄÅROC-AUC ‰∏äÊèêÈ´ò‰∫Ü 2.5%„ÄÇÊèê‰æõ‰∫ÜÊ∂àËûçÁ†îÁ©∂‰æÜÈáèÂåñÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏≠ÊØèÂÄãÁµÑ‰ª∂ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation**
2501.06692v1 by Zhonghao Yan, Zijin Yin, Tianyu Lin, Xiangzhu Zeng, Kongming Liang, Zhanyu Ma

The Segment Anything Model (SAM) has demonstrated strong and versatile
segmentation capabilities, along with intuitive prompt-based interactions.
However, customizing SAM for medical image segmentation requires massive
amounts of pixel-level annotations and precise point- or box-based prompt
designs. To address these challenges, we introduce PGP-SAM, a novel
prototype-based few-shot tuning approach that uses limited samples to replace
tedious manual prompts. Our key idea is to leverage inter- and intra-class
prototypes to capture class-specific knowledge and relationships. We propose
two main components: (1) a plug-and-play contextual modulation module that
integrates multi-scale information, and (2) a class-guided cross-attention
mechanism that fuses prototypes and features for automatic prompt generation.
Experiments on a public multi-organ dataset and a private ventricle dataset
demonstrate that PGP-SAM achieves superior mean Dice scores compared with
existing prompt-free SAM variants, while using only 10\% of the 2D slices.

ÊëòË¶ÅÔºöÂàÜÊÆµ‰ªª‰ΩïÊ®°Âûã (SAM) Â∑≤Â±ïÁ§∫Âá∫Âº∫Â§ß‰∏îÂ§öÂäüËÉΩÁöÑÂàÜÊÆµËÉΩÂäõÔºå‰ª•ÂèäÁõ¥ËßÇÁöÑÂü∫‰∫éÊèêÁ§∫ÁöÑ‰∫§‰∫í„ÄÇ
ÁÑ∂ËÄåÔºåÈíàÂØπÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊÆµÂÆöÂà∂ SAM ÈúÄË¶ÅÂ§ßÈáèÂÉèÁ¥†Á∫ßÊ≥®ÈáäÂíåÁ≤æÁ°ÆÁöÑÂü∫‰∫éÁÇπÊàñÊ°ÜÁöÑÊèêÁ§∫ËÆæËÆ°„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü PGP-SAMÔºå‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫éÂéüÂûãÁöÑÂ∞ëÈáèÈïúÂ§¥ÂæÆË∞ÉÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®ÊúâÈôêÁöÑÊ†∑Êú¨Êù•ÊõøÊç¢ÁπÅÁêêÁöÑÊâãÂä®ÊèêÁ§∫„ÄÇÊàë‰ª¨ÁöÑÂÖ≥ÈîÆÊÄùÊÉ≥ÊòØÂà©Áî®Á±ªÈó¥ÂíåÁ±ªÂÜÖÂéüÂûãÊù•ÊçïÊçâÁâπÂÆö‰∫éÁ±ªÁöÑÁü•ËØÜÂíåÂÖ≥Á≥ª„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§‰∏™‰∏ªË¶ÅÁªÑ‰ª∂Ôºö(1) ‰∏Ä‰∏™Âç≥ÊèíÂç≥Áî®ÁöÑ‰∏ä‰∏ãÊñáË∞ÉÂà∂Ê®°ÂùóÔºåÂÆÉÈõÜÊàê‰∫ÜÂ§öÂ∞∫Â∫¶‰ø°ÊÅØÔºå‰ª•Âèä (2) ‰∏Ä‰∏™Á±ªÊåáÂØºÁöÑ‰∫§ÂèâÊ≥®ÊÑèÊú∫Âà∂ÔºåÂÆÉËûçÂêà‰∫ÜÂéüÂûãÂíåÁâπÂæÅ‰ª•ËøõË°åËá™Âä®ÊèêÁ§∫ÁîüÊàê„ÄÇÂú®ÂÖ¨ÂÖ±Â§öÂô®ÂÆòÊï∞ÊçÆÈõÜÂíåÁßÅ‰∫∫ÂøÉÂÆ§Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåPGP-SAM ‰∏éÁé∞ÊúâÁöÑÊó†ÊèêÁ§∫ SAM Âèò‰ΩìÁõ∏ÊØîÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÂπ≥Âùá Dice ÂàÜÊï∞ÔºåÂêåÊó∂‰ªÖ‰ΩøÁî®‰∫Ü 2D ÂàáÁâáÁöÑ 10%„ÄÇ

##### **Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels**
2501.06678v1 by Erjian Guo, Zicheng Wang, Zhen Zhao, Luping Zhou

Accurate medical image segmentation is often hindered by noisy labels in
training data, due to the challenges of annotating medical images. Prior
research works addressing noisy labels tend to make class-dependent
assumptions, overlooking the pixel-dependent nature of most noisy labels.
Furthermore, existing methods typically apply fixed thresholds to filter out
noisy labels, risking the removal of minority classes and consequently
degrading segmentation performance. To bridge these gaps, our proposed
framework, Collaborative Learning with Curriculum Selection (CLCS), addresses
pixel-dependent noisy labels with class imbalance. CLCS advances the existing
works by i) treating noisy labels as pixel-dependent and addressing them
through a collaborative learning framework, and ii) employing a curriculum
dynamic thresholding approach adapting to model learning progress to select
clean data samples to mitigate the class imbalance issue, and iii) applying a
noise balance loss to noisy data samples to improve data utilization instead of
discarding them outright. Specifically, our CLCS contains two modules:
Curriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In
the CNS module, we designed a two-branch network with discrepancy loss for
collaborative learning so that different feature representations of the same
instance could be extracted from distinct views and used to vote the class
probabilities of pixels. Besides, a curriculum dynamic threshold is adopted to
select clean-label samples through probability voting. In the NBL module,
instead of directly dropping the suspiciously noisy labels, we further adopt a
robust loss to leverage such instances to boost the performance.

ÊëòË¶ÅÔºö<paragraph>ÂáÜÁ°ÆÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÈÄöÂ∏∏‰ºöÂèóÂà∞ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠Ê†áÁ≠æÊúâÂô™Â£∞ÁöÑÈòªÁ¢çÔºåËøôÊòØÂõ†‰∏∫ÂØπÂåªÂ≠¶ÂΩ±ÂÉèËøõË°åÊ≥®ÈáäÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇËß£ÂÜ≥Ê†áÁ≠æÊúâÂô™Â£∞ÁöÑÂÖàÂâçÁ†îÁ©∂Â∑•‰ΩúÂÄæÂêë‰∫éÂÅöÂá∫Á±ªÁõ∏ÂÖ≥ÁöÑÂÅáËÆæÔºåËÄåÂøΩÁï•‰∫ÜÂ§ßÂ§öÊï∞Ê†áÁ≠æÊúâÂô™Â£∞ÁöÑÂÉèÁ¥†Áõ∏ÂÖ≥ÊÄßË¥®„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∫îÁî®Âõ∫ÂÆöÈòàÂÄºÊù•ËøáÊª§ÊéâÊ†áÁ≠æÊúâÂô™Â£∞ÔºåËøôÊúâÂ∞ÜÂ∞ëÊï∞Á±ªÂà´ÁöÑÊ†áÁ≠æÁßªÈô§ÁöÑÈ£éÈô©Ôºå‰ªéËÄåÈôç‰ΩéÂàÜÂâ≤ÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∫õÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊ°ÜÊû∂ÔºåÂç≥ÂÖ∑ÊúâËØæÁ®ãÈÄâÊã©ÁöÑÂçè‰ΩúÂ≠¶‰π† (CLCS)ÔºåËß£ÂÜ≥‰∫ÜÁ±ªÂà´‰∏çÂπ≥Ë°°ÁöÑÂÉèÁ¥†Áõ∏ÂÖ≥Ê†áÁ≠æÊúâÂô™Â£∞ÁöÑÈóÆÈ¢ò„ÄÇCLCS ÈÄöËøá‰ª•‰∏ãÊñπÂºèÊèêÂçá‰∫ÜÁé∞ÊúâÂ∑•‰ΩúÔºöi) Â∞ÜÊ†áÁ≠æÊúâÂô™Â£∞ËßÜ‰∏∫ÂÉèÁ¥†Áõ∏ÂÖ≥ÔºåÂπ∂ÈÄöËøáÂçè‰ΩúÂ≠¶‰π†Ê°ÜÊû∂Ëß£ÂÜ≥ÂÆÉ‰ª¨Ôºåii) ÈááÁî®ËØæÁ®ãÂä®ÊÄÅÈòàÂÄºÂåñÊñπÊ≥ïÔºåÈÄÇÂ∫îÊ®°ÂûãÂ≠¶‰π†ËøõÂ∫¶ÔºåÈÄâÊã©Âπ≤ÂáÄÁöÑÊï∞ÊçÆÊ†∑Êú¨‰ª•ÂáèËΩªÁ±ªÂà´‰∏çÂπ≥Ë°°ÈóÆÈ¢òÔºå‰ª•Âèä iii) ÂØπÊ†áÁ≠æÊúâÂô™Â£∞ÁöÑÊï∞ÊçÆÊ†∑Êú¨Â∫îÁî®Âô™Â£∞Âπ≥Ë°°ÊçüÂ§±Ôºå‰ª•ÊèêÈ´òÊï∞ÊçÆÂà©Áî®ÁéáÔºåËÄå‰∏çÊòØÁõ¥Êé•‰∏¢ÂºÉÂÆÉ‰ª¨„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÁöÑ CLCS ÂåÖÂê´‰∏§‰∏™Ê®°ÂùóÔºöËØæÁ®ãÊ†áÁ≠æÊúâÂô™Â£∞Ê†∑Êú¨ÈÄâÊã© (CNS) ÂíåÂô™Â£∞Âπ≥Ë°°ÊçüÂ§± (NBL)„ÄÇÂú® CNS Ê®°Âùó‰∏≠ÔºåÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂÖ∑ÊúâÂ∑ÆÂºÇÊçüÂ§±ÁöÑ‰∏§ÂàÜÊîØÁΩëÁªúÔºåÁî®‰∫éÂçè‰ΩúÂ≠¶‰π†Ôºå‰ª•‰æøÂèØ‰ª•‰ªé‰∏çÂêåÁöÑËßÜÂõæ‰∏≠ÊèêÂèñÂêå‰∏ÄÂÆû‰æãÁöÑ‰∏çÂêåÁâπÂæÅË°®Á§∫ÔºåÂπ∂Áî®‰∫éÊäïÁ•®ÂÉèÁ¥†ÁöÑÁ±ªÂà´Ê¶ÇÁéá„ÄÇÊ≠§Â§ñÔºåÈááÁî®ËØæÁ®ãÂä®ÊÄÅÈòàÂÄºÈÄöËøáÊ¶ÇÁéáÊäïÁ•®ÈÄâÊã©Âπ≤ÂáÄÊ†áÁ≠æÊ†∑Êú¨„ÄÇÂú® NBL Ê®°Âùó‰∏≠ÔºåÊàë‰ª¨Ê≤°ÊúâÁõ¥Êé•‰∏¢ÂºÉÂèØÁñëÁöÑÊ†áÁ≠æÊúâÂô™Â£∞ÔºåËÄåÊòØËøõ‰∏ÄÊ≠•ÈááÁî®È≤ÅÊ£íÊçüÂ§±Êù•Âà©Áî®Ê≠§Á±ªÂÆû‰æã‰ª•ÊèêÂçáÊÄßËÉΩ„ÄÇ</paragraph>

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v1 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁÇ∫‰∏≠ÊñáÈÜ´ÁôÇÁ§æÁæ§ÂºïÈÄ≤ÂÖ®ÁêÉÈ¶ñÂÄãËá®Â∫äË°ìË™ûÔºåÂç≥ MedCTÔºå‰∏¶ÈôÑÊúâËá®Â∫äÂü∫Á§éÊ®°Âûã MedBERT ÂíåÂØ¶È´îÈÄ£ÁµêÊ®°Âûã MedLink„ÄÇMedCT Á≥ªÁµ±ËÉΩÊ®ôÊ∫ñÂåñ‰∏¶‰ª•Á®ãÂºèÂåñÊñπÂºèÂëàÁèæ‰∏≠ÊñáËá®Â∫äË≥áÊñôÔºåÈÄ≤ËÄåÂà∫ÊøÄÊñ∞Ëó•Áâ©„ÄÅÊ≤ªÁôÇÈÄîÂæëÁöÑÈñãÁôºÔºå‰∏¶ÁÇ∫‰∫∫Âè£ÁúæÂ§öÁöÑËèØ‰∫∫Á§æÁæ§Â∏∂‰æÜÊõ¥Â•ΩÁöÑÈÜ´ÁôÇÁµêÊûú„ÄÇÊ≠§Â§ñÔºåMedCT Áü•Ë≠òÂúñË≠úÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂéüÂâáÊÄßÁöÑÊ©üÂà∂ÔºåÁî®‰ª•ÊúÄÂ∞èÂåñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫ÂïèÈ°åÔºåÂõ†Ê≠§Âú®Âü∫Êñº LLM ÁöÑËá®Â∫äÊáâÁî®‰∏≠ÂØ¶Áèæ‰∫ÜÈ°ØËëóÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÈÄèÈÅéÂà©Áî® LLM Âú®ÁîüÊàêÊÄßÂíåË°®ÈÅîÊÄßÊñπÈù¢ÁöÑÈ°ØËëóËÉΩÂäõÔºåÊàëÂÄëÂæó‰ª•Âø´ÈÄüÂª∫Êßã‰∏ÄÂÄãÁîüÁî¢ÂìÅË≥™ÁöÑË°ìË™ûÁ≥ªÁµ±Ôºå‰∏¶Âú®‰∏âÂÄãÊúàÂÖßÈÉ®ÁΩ≤Âà∞ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÈ†òÂüüÔºåËÄåÂÉè SNOMED CT Á≠âÂÇ≥Áµ±Ë°ìË™ûÂ∑≤Ê≠∑Á∂ì‰∫åÂçÅÂ§öÂπ¥ÁöÑÁôºÂ±ï„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåMedCT Á≥ªÁµ±Âú®Ë™ûÊÑèÈÖçÂ∞çÂíåÂØ¶È´îÈÄ£Áµê‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊïàËÉΩÔºå‰∏çÂÉÖÈÅ©Áî®Êñº‰∏≠ÊñáÔºå‰πüÈÅ©Áî®ÊñºËã±Êñá„ÄÇÊàëÂÄëÈÇÑÈÄèÈÅéÂú®ÂÖ∑‰ª£Ë°®ÊÄßÁöÑËá®Â∫ä‰ªªÂãôÁØÑÂúç‰∏≠ÊáâÁî® MedCT Âíå LLM ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∏±ÂêëÂØ¶Âú∞ÂØ¶È©óÔºåÂåÖÊã¨ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Ëá™ÂãïÁîüÊàêÂíåÁî®ÊñºË®∫Êñ∑Ê±∫Á≠ñÁöÑÈÜ´ÁôÇÊñá‰ª∂ÊêúÂ∞ã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ MedCT Â∞çËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÂíåÊÇ£ËÄÖÁµêÊûúÂÖ∑ÊúâÂ§öÈáçÂÉπÂÄºÔºåÁâπÂà•ÊòØÂú®Êñ∞È°ûÂûãÁöÑËá®Â∫ä LLM ÊáâÁî®‰∏≠„ÄÇÊàëÂÄë‰ª•ÂÖÖÂàÜÁöÑÂ∑•Á®ãÁ¥∞ÁØÄÂëàÁèæÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂõ†Ê≠§ÂØ¶‰ΩúÂÖ∂‰ªñÈùûËã±Ë™ûÁ§æÊúÉÁöÑËá®Â∫äË°ìË™ûÊáâÊòìÊñºË§áË£Ω„ÄÇÊàëÂÄëÈñãÊîæÁôºÂ∏ÉÊàëÂÄëÁöÑË°ìË™û„ÄÅÊ®°ÂûãÂíåÊºîÁÆóÊ≥ïÔºå‰ª•ÂèäÁî®ÊñºÈñãÁôºÁöÑÁèæÂØ¶‰∏ñÁïåËá®Â∫äË≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **Deep Learning on Hester Davis Scores for Inpatient Fall Prediction**
2501.06432v1 by Hojjat Salehinejad, Ricky Rojas, Kingsley Iheasirim, Mohammed Yousufuddin, Bijan Borah

Fall risk prediction among hospitalized patients is a critical aspect of
patient safety in clinical settings, and accurate models can help prevent
adverse events. The Hester Davis Score (HDS) is commonly used to assess fall
risk, with current clinical practice relying on a threshold-based approach. In
this method, a patient is classified as high-risk when their HDS exceeds a
predefined threshold. However, this approach may fail to capture dynamic
patterns in fall risk over time. In this study, we model the threshold-based
approach and propose two machine learning approaches for enhanced fall
prediction: One-step ahead fall prediction and sequence-to-point fall
prediction. The one-step ahead model uses the HDS at the current timestamp to
predict the risk at the next timestamp, while the sequence-to-point model
leverages all preceding HDS values to predict fall risk using deep learning. We
compare these approaches to assess their accuracy in fall risk prediction,
demonstrating that deep learning can outperform the traditional threshold-based
method by capturing temporal patterns and improving prediction reliability.
These findings highlight the potential for data-driven approaches to enhance
patient safety through more reliable fall prevention strategies.

ÊëòË¶ÅÔºö‰ΩèÈô¢ÊÇ£ËÄÖÁöÑË∑åÂÄíÈ¢®Èö™È†êÊ∏¨ÊòØËá®Â∫äÁí∞Â¢É‰∏≠ÊÇ£ËÄÖÂÆâÂÖ®ÁöÑÈáçË¶ÅÈù¢ÂêëÔºåÁ≤æÁ¢∫ÁöÑÊ®°ÂûãÊúâÂä©ÊñºÈ†êÈò≤‰∏çËâØ‰∫ã‰ª∂„ÄÇHester Davis Ë©ïÂàÜ (HDS) Â∏∏Áî®ÊñºË©ï‰º∞Ë∑åÂÄíÈ¢®Èö™ÔºåÁõÆÂâçÁöÑËá®Â∫äÂØ¶Âãô‰æùË≥¥ÊñºÂü∫ÊñºÈñæÂÄºÁöÑË©ï‰º∞ÊñπÂºè„ÄÇÂú®Ê≠§ÊñπÊ≥ï‰∏≠ÔºåÁï∂ÊÇ£ËÄÖÁöÑ HDS Ë∂ÖÈÅéÈ†êÂÖàÂÆöÁæ©ÁöÑÈñæÂÄºÊôÇÔºåÊúÉÂ∞áÂÖ∂Ê≠∏È°ûÁÇ∫È´òÈ¢®Èö™„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÊñπÊ≥ïÂèØËÉΩÁÑ°Ê≥ïÊçïÊçâÈö®ËëóÊôÇÈñìÊé®ÁßªËÄåÁî¢ÁîüÁöÑÂãïÊÖãË∑åÂÄíÈ¢®Èö™Ê®°Âºè„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÈñæÂÄºÁöÑË©ï‰º∞ÊñπÂºèÈÄ≤Ë°åÂª∫Ê®°Ôºå‰∏¶ÊèêÂá∫ÂÖ©Á®ÆÊ©üÂô®Â≠∏ÁøíË©ï‰º∞ÊñπÂºè‰ª•Âä†Âº∑Ë∑åÂÄíÈ†êÊ∏¨ÔºöÂñÆÊ≠•ÂâçÁûªË∑åÂÄíÈ†êÊ∏¨ÂíåÂ∫èÂàóÂ∞çÈªûË∑åÂÄíÈ†êÊ∏¨„ÄÇÂñÆÊ≠•ÂâçÁûªÊ®°Âûã‰ΩøÁî®Áï∂ÂâçÊôÇÈñìÊà≥Ë®òÁöÑ HDS È†êÊ∏¨‰∏ã‰∏ÄÂÄãÊôÇÈñìÊà≥Ë®òÁöÑÈ¢®Èö™ÔºåËÄåÂ∫èÂàóÂ∞çÈªûÊ®°ÂûãÂâáÂà©Áî®ÊâÄÊúâÂâç‰∏ÄÂÄã HDS ÂÄº‰ΩøÁî®Ê∑±Â∫¶Â≠∏Áøí‰æÜÈ†êÊ∏¨Ë∑åÂÄíÈ¢®Èö™„ÄÇÊàëÂÄëÊØîËºÉÈÄô‰∫õË©ï‰º∞ÊñπÂºè‰ª•Ë©ï‰º∞ÂÖ∂Âú®Ë∑åÂÄíÈ¢®Èö™È†êÊ∏¨‰∏≠ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåË≠âÊòéÊ∑±Â∫¶Â≠∏ÁøíÂèØ‰ª•ÈÄèÈÅéÊçïÊçâÊôÇÈñìÊ®°ÂºèÂíåÊèêÂçáÈ†êÊ∏¨ÂèØÈù†ÊÄßÔºåÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÂü∫ÊñºÈñæÂÄºÁöÑË©ï‰º∞ÊñπÂºè„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜË≥áÊñôÈ©ÖÂãïË©ï‰º∞ÊñπÂºèÂú®ÈÄèÈÅéÊõ¥ÂèØÈù†ÁöÑË∑åÂÄíÈ†êÈò≤Á≠ñÁï•‰æÜÂä†Âº∑ÊÇ£ËÄÖÂÆâÂÖ®ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts**
2501.06365v1 by Elizabeth Schaefer, Kirk Roberts

This paper presents a pipeline for mitigating gender bias in large language
models (LLMs) used in medical literature by neutralizing gendered occupational
pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to
identify and modify pronouns tied to professions. We developed a BERT-based
model, ``Modern Occupational Bias Elimination with Refined Training,'' or
``MOBERT,'' trained on these neutralized abstracts, and compared its
performance with ``1965Bert,'' trained on the original dataset. MOBERT achieved
a 70\% inclusive replacement rate, while 1965Bert reached only 4\%. A further
analysis of MOBERT revealed that pronoun replacement accuracy correlated with
the frequency of occupational terms in the training data. We propose expanding
the dataset and refining the pipeline to improve performance and ensure more
equitable language modeling in medical applications.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁÆ°ÈÅìÔºåÁî®ÊñºÁ∑©Ëß£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÊÄßÂà•ÂÅèË¶ãÔºåÈÄô‰∫õÊ®°ÂûãÈÄèÈÅé‰∏≠ÂíåÊÄßÂà•ËÅ∑Ê•≠‰ª£ÂêçË©ûÔºåÁî®ÊñºÈÜ´Â≠∏ÊñáÁçª‰∏≠„ÄÇÊàëÂÄëËôïÁêÜ‰∫Ü 1965 Âπ¥Ëá≥ 1980 Âπ¥Èñì 379,000 ÁØá PubMed ÊñáÊëòÁöÑË≥áÊñôÈõÜÔºå‰ª•Ë≠òÂà•Âíå‰øÆÊîπËàáËÅ∑Ê•≠Áõ∏ÈóúÁöÑ‰ª£ÂêçË©û„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã BERT-based Ê®°ÂûãÔºåÁ®±ÁÇ∫„ÄåÊé°Áî®Á≤æÁ∑ªË®ìÁ∑¥ÁöÑÁèæ‰ª£ËÅ∑Ê•≠ÂÅèË¶ãÊ∂àÈô§„ÄçÊàñ„ÄåMOBERT„ÄçÔºå‰∏¶Âú®ÈÄô‰∫õ‰∏≠ÂíåÁöÑÊñáÊëò‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàáÂú®ÂéüÂßãË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑ„Äå1965Bert„ÄçÈÄ≤Ë°åÊØîËºÉ„ÄÇMOBERT ÈÅîÂà∞‰∫Ü 70% ÁöÑÂåÖÂÆπÊÄßÊõøÊèõÁéáÔºåËÄå 1965Bert ÂÉÖÈÅîÂà∞ 4%„ÄÇÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê MOBERT È°ØÁ§∫Ôºå‰ª£ÂêçË©ûÊõøÊèõÁöÑÊ∫ñÁ¢∫ÊÄßËàáË®ìÁ∑¥Ë≥áÊñô‰∏≠ËÅ∑Ê•≠Ë°ìË™ûÁöÑÈ†ªÁéáÁõ∏Èóú„ÄÇÊàëÂÄëÂª∫Ë≠∞Êì¥ÂÖÖË≥áÊñôÈõÜ‰∏¶Á≤æÁ∑ªÂåñÁÆ°ÈÅìÔºå‰ª•ÊèêÂçáÊïàËÉΩ‰∏¶Á¢∫‰øùÂú®ÈÜ´Â≠∏ÊáâÁî®‰∏≠ÈÄ≤Ë°åÊõ¥ÂÖ¨Âπ≥ÁöÑË™ûË®ÄÂª∫Ê®°„ÄÇ

##### **Scale-up Unlearnable Examples Learning with High-Performance Computing**
2501.06080v1 by Yanfan Zhu, Issac Lyngaas, Murali Gopalakrishnan Meena, Mary Ellen I. Koran, Bradley Malin, Daniel Moyer, Shunxing Bao, Anuj Kapadia, Xiao Wang, Bennett Landman, Yuankai Huo

Recent advancements in AI models are structured to retain user interactions,
which could inadvertently include sensitive healthcare data. In the healthcare
field, particularly when radiologists use AI-driven diagnostic tools hosted on
online platforms, there is a risk that medical imaging data may be repurposed
for future AI training without explicit consent, spotlighting critical privacy
and intellectual property concerns around healthcare data usage. Addressing
these privacy challenges, a novel approach known as Unlearnable Examples (UEs)
has been introduced, aiming to make data unlearnable to deep learning models. A
prominent method within this area, called Unlearnable Clustering (UC), has
shown improved UE performance with larger batch sizes but was previously
limited by computational resources. To push the boundaries of UE performance
with theoretically unlimited resources, we scaled up UC learning across various
datasets using Distributed Data Parallel (DDP) training on the Summit
supercomputer. Our goal was to examine UE efficacy at high-performance
computing (HPC) levels to prevent unauthorized learning and enhance data
security, particularly exploring the impact of batch size on UE's
unlearnability. Utilizing the robust computational capabilities of the Summit,
extensive experiments were conducted on diverse datasets such as Pets,
MedMNist, Flowers, and Flowers102. Our findings reveal that both overly large
and overly small batch sizes can lead to performance instability and affect
accuracy. However, the relationship between batch size and unlearnability
varied across datasets, highlighting the necessity for tailored batch size
strategies to achieve optimal data protection. Our results underscore the
critical role of selecting appropriate batch sizes based on the specific
characteristics of each dataset to prevent learning and ensure data security in
deep learning applications.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÂú® AI Ê®°Âûã‰∏≠ÁöÑÈÄ≤Â±ïË¢´Âª∫ÊßãÁÇ∫‰øùÁïô‰ΩøÁî®ËÄÖ‰∫íÂãïÔºå
ÈÄôÂèØËÉΩÁÑ°ÊÑèÈñìÂåÖÂê´ÊïèÊÑüÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñô„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•
È†òÂüüÔºåÁâπÂà•ÊòØÁï∂ÊîæÂ∞ÑÁßëÈÜ´Â∏´‰ΩøÁî®Á∑ö‰∏äÂπ≥Âè∞‰∏äÊèê‰æõÁöÑ AI È©ÖÂãïË®∫Êñ∑Â∑•ÂÖ∑ÊôÇÔºåÊúâÈ¢®Èö™ÊòØÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÂèØËÉΩÊúÉË¢´ÈáçÊñ∞Áî®ÊñºÊú™‰æÜÁöÑ AI Ë®ìÁ∑¥ÔºåËÄåÊú™Á∂ìÊòéÁ¢∫ÂêåÊÑèÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜËàáÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñô‰ΩøÁî®Áõ∏ÈóúÁöÑÈö±ÁßÅÂíåÊô∫ÊÖßË≤°Áî¢Ê¨äÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞ç
ÈÄô‰∫õÈö±ÁßÅÊåëÊà∞ÔºåÂ∑≤Â∞éÂÖ•‰∏ÄÁ®ÆÁ®±ÁÇ∫‰∏çÂèØÂ≠∏ÁøíÁØÑ‰æã (UE) ÁöÑÊñ∞ÊñπÊ≥ïÔºåÊó®Âú®ËÆìË≥áÊñôÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏çÂèØÂ≠∏Áøí„ÄÇÈÄôÂÄãÈ†òÂüüÂÖß‰∏ÄÁ®ÆËëóÂêçÁöÑÁ®±ÁÇ∫‰∏çÂèØÂ≠∏ÁøíËÅöÈ°û (UC) ÁöÑÊñπÊ≥ïÔºåÂ∑≤È°ØÁ§∫Âá∫Âú®ËºÉÂ§ßÁöÑÊâπÊ¨°Â§ßÂ∞è‰∏ãÊúâÊîπÂñÑÁöÑ UE ÊïàËÉΩÔºå‰ΩÜÂÖàÂâçÂèóÂà∞ÈÅãÁÆóË≥áÊ∫êÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÂú®ÁêÜË´ñ‰∏äÁÑ°ÈôêÂà∂Ë≥áÊ∫êÁöÑÊÉÖÊ≥Å‰∏ãÊé®Âãï UE ÊïàËÉΩÁöÑÁïåÁ∑öÔºåÊàëÂÄëÂú® Summit Ë∂ÖÁ¥öÈõªËÖ¶‰∏ä‰ΩøÁî®ÂàÜÊï£ÂºèË≥áÊñôÂπ≥Ë°å (DDP) Ë®ìÁ∑¥ÔºåÊì¥Â§ß‰∫ÜÂêÑÁ®ÆË≥áÊñôÈõÜÁöÑ UC Â≠∏Áøí„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊ™¢Êü• UE Âú®È´òÊïàËÉΩÈÅãÁÆó (HPC) Â±§Á¥öÁöÑÊïàËÉΩÔºå‰ª•Èò≤Ê≠¢Êú™Á∂ìÊéàÊ¨äÁöÑÂ≠∏ÁøíÔºå‰∏¶Â¢ûÂº∑Ë≥áÊñôÂÆâÂÖ®ÊÄßÔºåÁâπÂà•ÊòØÊé¢Ë®éÊâπÊ¨°Â§ßÂ∞èÂ∞ç UE ‰∏çÂèØÂ≠∏ÁøíÊÄßÁöÑÂΩ±Èüø„ÄÇÂà©Áî® Summit Âº∑Â§ßÁöÑÈÅãÁÆóËÉΩÂäõÔºåÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰æãÂ¶Ç Pets„ÄÅMedMNist„ÄÅFlowers Âíå Flowers102„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈÅéÂ§ßÊàñÈÅéÂ∞èÁöÑÊâπÊ¨°Â§ßÂ∞èÈÉΩÂèØËÉΩÂ∞éËá¥ÊïàËÉΩ‰∏çÁ©©ÂÆöÔºå‰∏¶ÂΩ±ÈüøÊ∫ñÁ¢∫Â∫¶„ÄÇÁÑ∂ËÄåÔºåÊâπÊ¨°Â§ßÂ∞èËàá‰∏çÂèØÂ≠∏ÁøíÊÄß‰πãÈñìÁöÑÈóú‰øÇÂú®ÂêÑÂÄãË≥áÊñôÈõÜ‰πãÈñìÊúâÊâÄ‰∏çÂêåÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÊ†πÊìöÁâπÂÆöË≥áÊñôÈõÜÁöÑÁâπÂæµÈáèË∫´ÊâìÈÄ†ÊâπÊ¨°Â§ßÂ∞èÁ≠ñÁï•‰ª•ÈÅîÊàêÊúÄ‰Ω≥Ë≥áÊñô‰øùË≠∑ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫ÜÊ†πÊìöÊØèÂÄãË≥áÊñôÈõÜÁöÑÁâπÂÆöÁâπÂæµÈÅ∏ÊìáÈÅ©Áï∂ÊâπÊ¨°Â§ßÂ∞è‰ª•Èò≤Ê≠¢Â≠∏ÁøíÔºå‰∏¶Á¢∫‰øùÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Á®ãÂºè‰∏≠Ë≥áÊñôÂÆâÂÖ®ÊÄßÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇ</paragraph>

##### **AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery**
2501.06039v1 by Johann Wenckstern, Eeshaan Jain, Kiril Vasilev, Matteo Pariset, Andreas Wicki, Gabriele Gut, Charlotte Bunne

Spatial proteomics technologies have transformed our understanding of complex
tissue architectures by enabling simultaneous analysis of multiple molecular
markers and their spatial organization. The high dimensionality of these data,
varying marker combinations across experiments and heterogeneous study designs
pose unique challenges for computational analysis. Here, we present Virtual
Tissues (VirTues), a foundation model framework for biological tissues that
operates across the molecular, cellular and tissue scale. VirTues introduces
innovations in transformer architecture design, including a novel tokenization
scheme that captures both spatial and marker dimensions, and attention
mechanisms that scale to high-dimensional multiplex data while maintaining
interpretability. Trained on diverse cancer and non-cancer tissue datasets,
VirTues demonstrates strong generalization capabilities without task-specific
fine-tuning, enabling cross-study analysis and novel marker integration. As a
generalist model, VirTues outperforms existing approaches across clinical
diagnostics, biological discovery and patient case retrieval tasks, while
providing insights into tissue function and disease mechanisms.

ÊëòË¶ÅÔºöÁ©∫ÈñìËõãÁôΩË≥™ÁµÑÂ≠∏ÊäÄË°ìÈÄèÈÅéÂêåÊôÇÂàÜÊûêÂ§öÂÄãÂàÜÂ≠êÊ®ôË®òÂèäÂÖ∂Á©∫ÈñìÁµÑÁπîÔºåËΩâËÆä‰∫ÜÊàëÂÄëÂ∞çË§áÈõúÁµÑÁπîÁµêÊßãÁöÑÁêÜËß£„ÄÇÈÄô‰∫õÊï∏ÊìöÁöÑÈ´òÁ∂≠Â∫¶„ÄÅÂØ¶È©ó‰∏≠‰∏çÂêåÁöÑÊ®ôË®òÁµÑÂêàÂíåÁï∞Ë≥™ÁöÑÁ†îÁ©∂Ë®≠Ë®àÔºåÂ∞çË®àÁÆóÂàÜÊûêÊßãÊàê‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ËôõÊì¨ÁµÑÁπî (VirTues)Ôºå‰∏ÄÂÄãÈÅ©Áî®ÊñºÂàÜÂ≠ê„ÄÅÁ¥∞ËÉûÂíåÁµÑÁπîÂ±§Á¥öÁöÑÁîüÁâ©ÁµÑÁπîÂü∫Á§éÊ®°ÂûãÊû∂Êßã„ÄÇVirTues Âú®TransformerÊû∂ÊßãË®≠Ë®à‰∏≠ÂºïÈÄ≤ÂâµÊñ∞ÔºåÂåÖÊã¨‰∏ÄÁ®ÆÊñ∞ÁöÑÊ®ôË®òÂåñÊû∂ÊßãÔºåÂÆÉÊçïÊçâÁ©∫ÈñìÂíåÊ®ôË®òÁ∂≠Â∫¶Ôºå‰ª•ÂèäÂú®Á∂≠ÊåÅÂèØËß£ÈáãÊÄßÁöÑÂêåÊôÇÊì¥Â±ïÂà∞È´òÁ∂≠Â∫¶Â§öÈáçÊï∏ÊìöÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂„ÄÇVirTues Âú®Â§öÊ®£ÂåñÁöÑÁôåÁóáÂíåÈùûÁôåÁóáÁµÑÁπîÊï∏ÊìöÈõÜ‰∏äË®ìÁ∑¥ÔºåÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÁÑ°ÈúÄÁâπÂÆö‰ªªÂãôÂæÆË™øÔºåÂæûËÄåÂØ¶ÁèæË∑®Á†îÁ©∂ÂàÜÊûêÂíåÊñ∞ÁöÑÊ®ôË®òÊï¥Âêà„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÈÄöÊâçÊ®°ÂûãÔºåVirTues Âú®Ëá®Â∫äË®∫Êñ∑„ÄÅÁîüÁâ©ÁôºÁèæÂíåÊÇ£ËÄÖÁóÖ‰æãÊ™¢Á¥¢‰ªªÂãô‰∏≠ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÂêåÊôÇÊèê‰æõ‰∫ÜÁµÑÁπîÂäüËÉΩÂíåÁñæÁóÖÊ©üÂà∂ÁöÑË¶ãËß£„ÄÇ

##### **DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information**
2501.05932v1 by Yongfan Lai, Jiabo Chen, Deyun Zhang, Yue Wang, Shijia Geng, Hongyan Li, Shenda Hong

Heart disease remains a significant threat to human health. As a non-invasive
diagnostic tool, the electrocardiogram (ECG) is one of the most widely used
methods for cardiac screening. However, the scarcity of high-quality ECG data,
driven by privacy concerns and limited medical resources, creates a pressing
need for effective ECG signal generation. Existing approaches for generating
ECG signals typically rely on small training datasets, lack comprehensive
evaluation frameworks, and overlook potential applications beyond data
augmentation. To address these challenges, we propose DiffuSETS, a novel
framework capable of generating ECG signals with high semantic alignment and
fidelity. DiffuSETS accepts various modalities of clinical text reports and
patient-specific information as inputs, enabling the creation of clinically
meaningful ECG signals. Additionally, to address the lack of standardized
evaluation in ECG generation, we introduce a comprehensive benchmarking
methodology to assess the effectiveness of generative models in this domain.
Our model achieve excellent results in tests, proving its superiority in the
task of ECG generation. Furthermore, we showcase its potential to mitigate data
scarcity while exploring novel applications in cardiology education and medical
knowledge discovery, highlighting the broader impact of our work.

ÊëòË¶ÅÔºöÂøÉËÑèÁóÖ‰ªçÁÑ∂ÊòØ‰∫∫Á±ªÂÅ•Â∫∑ÁöÑ‰∏ÄÂ§ßÂ®ÅËÉÅ„ÄÇ‰Ωú‰∏∫‰∏ÄÁßçÈùû‰æµÂÖ•ÊÄßËØäÊñ≠Â∑•ÂÖ∑ÔºåÂøÉÁîµÂõæ (ECG) ÊòØÂøÉËÑèÁ≠õÊü•ÊúÄÂπøÊ≥õ‰ΩøÁî®ÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÈöêÁßÅÈóÆÈ¢òÂíåÂåªÁñóËµÑÊ∫êÊúâÈôêÔºåÈ´òË¥®Èáè ECG Êï∞ÊçÆÁöÑÁ®ÄÁº∫ÂØπÊúâÊïàÁöÑ ECG ‰ø°Âè∑ÁîüÊàêÊèêÂá∫‰∫ÜËø´ÂàáÈúÄÊ±Ç„ÄÇÁé∞ÊúâÁî®‰∫éÁîüÊàê ECG ‰ø°Âè∑ÁöÑÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂ∞èÂûãËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÁº∫‰πèÂÖ®Èù¢ÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÂπ∂‰∏îÂøΩËßÜ‰∫ÜÊï∞ÊçÆÂ¢ûÂº∫‰πãÂ§ñÁöÑÊΩúÂú®Â∫îÁî®„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü DiffuSETSÔºåËøôÊòØ‰∏Ä‰∏™ËÉΩÂ§üÁîüÊàêÂÖ∑ÊúâÈ´òÂ∫¶ËØ≠‰πâÂØπÈΩêÂíå‰øùÁúüÂ∫¶ÁöÑ ECG ‰ø°Âè∑ÁöÑÊñ∞Ê°ÜÊû∂„ÄÇDiffuSETS Êé•ÂèóÂêÑÁßçÂΩ¢ÂºèÁöÑ‰∏¥Â∫äÊñáÊú¨Êä•ÂëäÂíåÊÇ£ËÄÖÁâπÂÆö‰ø°ÊÅØ‰Ωú‰∏∫ËæìÂÖ•Ôºå‰ªéËÄåËÉΩÂ§üÂàõÂª∫ÂÖ∑Êúâ‰∏¥Â∫äÊÑè‰πâÁöÑ ECG ‰ø°Âè∑„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜËß£ÂÜ≥ ECG ÁîüÊàê‰∏≠Áº∫‰πèÊ†áÂáÜÂåñËØÑ‰º∞ÁöÑÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊµãËØïÊñπÊ≥ïÊù•ËØÑ‰º∞ÁîüÊàêÊ®°ÂûãÂú®Ê≠§È¢ÜÂüüÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®ÊµãËØï‰∏≠ÂèñÂæó‰∫Ü‰ºòÂºÇÁöÑÊàêÊûúÔºåËØÅÊòé‰∫ÜÂÖ∂Âú® ECG ÁîüÊàê‰ªªÂä°‰∏≠ÁöÑ‰ºòË∂äÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁºìËß£Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÂêåÊó∂Âú®ÂøÉËÑèÁóÖÂ≠¶ÊïôËÇ≤ÂíåÂåªÂ≠¶Áü•ËØÜÂèëÁé∞‰∏≠Êé¢Á¥¢Êñ∞Â∫îÁî®ÁöÑÊΩúÂäõÔºåÁ™ÅÂá∫‰∫ÜÊàë‰ª¨Â∑•‰ΩúÁöÑÊõ¥ÂπøÊ≥õÂΩ±Âìç„ÄÇ

##### **AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**
2501.05826v2 by Amit Kr Dey, Pradeep Walia, Girish Somvanshi, Abrar Ali, Sagarnil Das, Pallabi Paul, Minakhi Ghosh

Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,
particularly in India, where access to retina specialists is limited in rural
areas. This study aims to evaluate the Artificial Intelligence-based Diabetic
Retinopathy Screening System (AIDRSS) for DR detection and prevalence
assessment, addressing the growing need for scalable, automated screening
solutions in resource-limited settings.
  Approach: A multicentric, cross-sectional study was conducted in Kolkata,
India, involving 5,029 participants and 10,058 macula-centric retinal fundus
images. The AIDRSS employed a deep learning algorithm with 50 million trainable
parameters, integrated with Contrast Limited Adaptive Histogram Equalization
(CLAHE) preprocessing for enhanced image quality. DR was graded using the
International Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease
into five stages (DR0 to DR4). Statistical metrics including sensitivity,
specificity, and prevalence rates were evaluated against expert retina
specialist assessments.
  Results: The prevalence of DR in the general population was 13.7%, rising to
38.2% among individuals with elevated random blood glucose levels. The AIDRSS
achieved an overall sensitivity of 92%, specificity of 88%, and 100%
sensitivity for detecting referable DR (DR3 and DR4). These results demonstrate
the system's robust performance in accurately identifying and grading DR in a
diverse population.
  Conclusions: AIDRSS provides a reliable, scalable solution for early DR
detection in resource-constrained environments. Its integration of advanced AI
techniques ensures high diagnostic accuracy, with potential to significantly
reduce the burden of diabetes-related vision loss in underserved regions.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÁöÑÔºöÁ≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèò (DR) ÊòØËßÜÂäõ‰∏ßÂ§±ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÁâπÂà´ÊòØÂú®Âç∞Â∫¶ÔºåÈÇ£ÈáåÁöÑÂÜúÊùëÂú∞Âå∫ÁúºÁßë‰∏ìÂÆ∂Êï∞ÈáèÊúâÈôê„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ËØÑ‰º∞Âü∫‰∫é‰∫∫Â∑•Êô∫ËÉΩÁöÑÁ≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèòÁ≠õÊü•Á≥ªÁªü (AIDRSS) ÁöÑ DR Ê£ÄÊµãÂíåÊµÅË°åÊÉÖÂÜµËØÑ‰º∞Ôºå‰ª•Êª°Ë∂≥ËµÑÊ∫êÊúâÈôêÁöÑÁéØÂ¢É‰∏≠ÂØπÂèØÊâ©Â±ïËá™Âä®ÂåñÁ≠õÊü•Ëß£ÂÜ≥ÊñπÊ°à‰∏çÊñ≠Â¢ûÈïøÁöÑÈúÄÊ±Ç„ÄÇ
ÊñπÊ≥ïÔºöÂú®Âç∞Â∫¶Âä†Â∞îÂêÑÁ≠îËøõË°å‰∫Ü‰∏ÄÈ°πÂ§ö‰∏≠ÂøÉÊ®™Êñ≠Èù¢Á†îÁ©∂ÔºåÊ∂âÂèä 5,029 ÂêçÂèÇ‰∏éËÄÖÂíå 10,058 Âº†ÈªÑÊñë‰∏≠ÂøÉËßÜÁΩëËÜúÁúºÂ∫ïÂõæÂÉè„ÄÇAIDRSS ÈááÁî®‰∫Ü‰∏Ä‰∏™Ê∑±Â∫¶Â≠¶‰π†ÁÆóÊ≥ïÔºåÂÖ∑Êúâ 5000 ‰∏á‰∏™ÂèØËÆ≠ÁªÉÂèÇÊï∞ÔºåÂπ∂ÈõÜÊàê‰∫ÜÂØπÊØîÂ∫¶ÈôêÂà∂Ëá™ÈÄÇÂ∫îÁõ¥ÊñπÂõæÂùáË°°Âåñ (CLAHE) È¢ÑÂ§ÑÁêÜÔºå‰ª•ÊèêÈ´òÂõæÂÉèË¥®Èáè„ÄÇDR ‰ΩøÁî®ÂõΩÈôÖ‰∏¥Â∫äÁ≥ñÂ∞øÁóÖËßÜÁΩëËÜúÁóÖÂèò (ICDR) ÈáèË°®ËøõË°åÂàÜÁ∫ßÔºåÂ∞ÜÁñæÁóÖÂàÜ‰∏∫‰∫î‰∏™Èò∂ÊÆµÔºàDR0 Ëá≥ DR4Ôºâ„ÄÇÈíàÂØπ‰∏ìÂÆ∂ËßÜÁΩëËÜú‰∏ìÂÆ∂ËØÑ‰º∞ÔºåËØÑ‰º∞‰∫ÜÂåÖÊã¨ÊïèÊÑüÊÄß„ÄÅÁâπÂºÇÊÄßÂíåÊÇ£ÁóÖÁéáÂú®ÂÜÖÁöÑÁªüËÆ°ÊåáÊ†á„ÄÇ
ÁªìÊûúÔºö‰∏ÄËà¨‰∫∫Áæ§‰∏≠ DR ÁöÑÊÇ£ÁóÖÁéá‰∏∫ 13.7%ÔºåÂú®ÈöèÊú∫Ë°ÄÁ≥ñÊ∞¥Âπ≥ÂçáÈ´òÁöÑ‰∏™‰Ωì‰∏≠‰∏äÂçáËá≥ 38.2%„ÄÇAIDRSS ÁöÑÊÄª‰ΩìÊïèÊÑüÊÄßËææÂà∞ 92%ÔºåÁâπÂºÇÊÄßËææÂà∞ 88%ÔºåÊ£ÄÊµãÂèØËΩ¨ËØä DRÔºàDR3 Âíå DR4ÔºâÁöÑÊïèÊÑüÊÄßËææÂà∞ 100%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéËØ•Á≥ªÁªüÂú®ÂáÜÁ°ÆËØÜÂà´ÂíåÂàÜÁ∫ß‰∏çÂêå‰∫∫Áæ§‰∏≠ÁöÑ DR ÊñπÈù¢ÂÖ∑ÊúâÂº∫Â§ßÁöÑÊÄßËÉΩ„ÄÇ
ÁªìËÆ∫ÔºöAIDRSS ‰∏∫ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏≠ÁöÑÊó©Êúü DR Ê£ÄÊµãÊèê‰æõ‰∫Ü‰∏ÄÁßçÂèØÈù†‰∏îÂèØÊâ©Â±ïÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÂÆÉÈõÜÊàê‰∫ÜÂÖàËøõÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÔºåÁ°Æ‰øù‰∫ÜËæÉÈ´òÁöÑËØäÊñ≠ÂáÜÁ°ÆÊÄßÔºåÊúâÂèØËÉΩÊòæËëóÂáèÂ∞ëÊúçÂä°‰∏çË∂≥Âú∞Âå∫‰∏éÁ≥ñÂ∞øÁóÖÁõ∏ÂÖ≥ÁöÑËßÜÂäõ‰∏ßÂ§±Ë¥üÊãÖ„ÄÇ</paragraph>

##### **Large Language Models for Bioinformatics**
2501.06271v1 by Wei Ruan, Yanjun Lyu, Jing Zhang, Jiazhang Cai, Peng Shu, Yang Ge, Yao Lu, Shang Gao, Yue Wang, Peilong Wang, Lin Zhao, Tao Wang, Yufang Liu, Luyang Fang, Ziyu Liu, Zhengliang Liu, Yiwei Li, Zihao Wu, Junhao Chen, Hanqi Jiang, Yi Pan, Zhenyuan Yang, Jingyuan Chen, Shizhe Liang, Wei Zhang, Terry Ma, Yuan Dou, Jianli Zhang, Xinyu Gong, Qi Gan, Yusong Zou, Zebang Chen, Yuanxin Qian, Shuo Yu, Jin Lu, Kenan Song, Xianqiao Wang, Andrea Sikora, Gang Li, Xiang Li, Quanzheng Li, Yingfeng Wang, Lu Zhang, Yohannes Abate, Lifang He, Wenxuan Zhong, Rongjie Liu, Chao Huang, Wei Liu, Ye Shen, Ping Ma, Hongtu Zhu, Yajun Yan, Dajiang Zhu, Tianming Liu

With the rapid advancements in large language model (LLM) technology and the
emergence of bioinformatics-specific language models (BioLMs), there is a
growing need for a comprehensive analysis of the current landscape,
computational characteristics, and diverse applications. This survey aims to
address this need by providing a thorough review of BioLMs, focusing on their
evolution, classification, and distinguishing features, alongside a detailed
examination of training methodologies, datasets, and evaluation frameworks. We
explore the wide-ranging applications of BioLMs in critical areas such as
disease diagnosis, drug discovery, and vaccine development, highlighting their
impact and transformative potential in bioinformatics. We identify key
challenges and limitations inherent in BioLMs, including data privacy and
security concerns, interpretability issues, biases in training data and model
outputs, and domain adaptation complexities. Finally, we highlight emerging
trends and future directions, offering valuable insights to guide researchers
and clinicians toward advancing BioLMs for increasingly sophisticated
biological and clinical applications.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊäÄË°ìÁöÑÂø´ÈÄüÈÄ≤Â±ïÂíåÁîüÁâ©Ë≥áË®äÂ≠∏ÁâπÂÆöË™ûË®ÄÊ®°ÂûãÔºàBioLMÔºâÁöÑÂá∫ÁèæÔºåÂ∞çÊñºÁï∂ÂâçÊÉÖÂã¢„ÄÅË®àÁÆóÁâπÂæµÂíåÂ§öÂÖÉÊáâÁî®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÂä†„ÄÇÊú¨Ë™øÊü•Êó®Âú®ÈÄèÈÅéÊèê‰æõÂ∞ç BioLM ÁöÑÂÖ®Èù¢Ê™¢Ë¶ñÔºåËëóÈáçÊñºÂÖ∂ÊºîÈÄ≤„ÄÅÂàÜÈ°ûÂíåÂçÄÂà•ÁâπÂæµÔºå‰ª•ÂèäÂ∞çË®ìÁ∑¥ÊñπÊ≥ï„ÄÅË≥áÊñôÈõÜÂíåË©ï‰º∞Êû∂ÊßãÁöÑË©≥Á¥∞Êé¢Ë®éÔºå‰æÜÊªøË∂≥Ê≠§ÈúÄÊ±Ç„ÄÇÊàëÂÄëÊé¢Ë®é BioLM Âú®ÁñæÁóÖË®∫Êñ∑„ÄÅËó•Áâ©ÁôºÁèæÂíåÁñ´ËãóÈñãÁôºÁ≠âÈóúÈçµÈ†òÂüüÁöÑÂª£Ê≥õÊáâÁî®ÔºåÂº∑Ë™øÂÖ∂Âú®ÁîüÁâ©Ë≥áË®äÂ≠∏‰∏≠ÁöÑÂΩ±ÈüøÂíåËΩâÂûãÊΩõÂäõ„ÄÇÊàëÂÄëÊâæÂá∫ BioLM Âõ∫ÊúâÁöÑÈóúÈçµÊåëÊà∞ÂíåÈôêÂà∂ÔºåÂåÖÊã¨Ë≥áÊñôÈö±ÁßÅÂíåÂÆâÂÖ®ÊÄßÂïèÈ°å„ÄÅÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË®ìÁ∑¥Ë≥áÊñôÂíåÊ®°ÂûãËº∏Âá∫ÁöÑÂÅèÂ∑ÆÔºå‰ª•ÂèäÈ†òÂüüÈÅ©ÊáâÁöÑË§áÈõúÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáçÈªû‰ªãÁ¥πÊñ∞ËààË∂®Âã¢ÂíåÊú™‰æÜÊñπÂêëÔºåÊèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰ª•ÊåáÂ∞éÁ†îÁ©∂‰∫∫Âì°ÂíåËá®Â∫äÈÜ´ÁîüÂ∞á BioLM ÊáâÁî®ÊñºÊó•ÁõäË§áÈõúÁöÑÁîüÁâ©ÂíåËá®Â∫äÊáâÁî®„ÄÇ

##### **From Simple to Complex Skills: The Case of In-Hand Object Reorientation**
2501.05439v1 by Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik

Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.

ÊëòË¶ÅÔºöÂú®Ê®°Êì¨‰∏≠Â≠∏ÁøíÁ≠ñÁï•‰∏¶Â∞áÂÖ∂ËΩâÁßªÂà∞ÁèæÂØ¶‰∏ñÁïåÂ∑≤ÊàêÁÇ∫ÈùàÂ∑ßÊìç‰Ωú‰∏≠‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÊØèÈ†ÖÊñ∞‰ªªÂãô‰æÜË™™ÔºåÂΩåÂêàÊ®°Êì¨Âà∞ÁèæÂØ¶ÁöÑÂ∑ÆË∑ùÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫ÂäõÔºå‰æãÂ¶Ç‰ªîÁ¥∞ÁöÑÁçéÂãµÂ∑•Á®ã„ÄÅË∂ÖÂèÉÊï∏Ë™øÊï¥ÂíåÁ≥ªÁµ±Ë≠òÂà•„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂà©Áî®‰ΩéÂ±§ÊäÄËÉΩ‰æÜÊáâÂ∞çÊõ¥Ë§áÈõú‰ªªÂãôÁöÑÊåëÊà∞ÁöÑÁ≥ªÁµ±„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂÖàÂâçÁç≤ÂæóÁöÑÊóãËΩâÊäÄËÉΩÁöÑÊâã‰∏≠Áâ©È´îÈáçÊñ∞ÂÆöÂêëÁöÑÂàÜÂ±§Á≠ñÁï•„ÄÇÈÄôÁ®ÆÂàÜÂ±§Á≠ñÁï•Â≠∏ÁøíÊ†πÊìöÁí∞Â¢ÉÂíå‰ΩéÂ±§ÊäÄËÉΩÁ≠ñÁï•Êú¨Ë∫´ÁöÑÂõûÈ•ãÈÅ∏ÊìáÂü∑Ë°åÂì™Á®Æ‰ΩéÂ±§ÊäÄËÉΩ„ÄÇËàáÂæûÈ†≠ÈñãÂßãÂ≠∏ÁøíÁõ∏ÊØîÔºåÂàÜÂ±§Á≠ñÁï•Â∞çÂàÜ‰ΩàÂ§ñËÆäÂåñÊõ¥Âº∑ÂÅ•Ôºå‰∏¶‰∏îÂèØ‰ª•ËºïÈ¨ÜÂú∞ÂæûÊ®°Êì¨ËΩâÁßªÂà∞ÁèæÂØ¶‰∏ñÁïåÁí∞Â¢É„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØÊ≥õÂåñÁöÑÁâ©È´îÂßøÂã¢‰º∞Ë®àÂô®ÔºåÂÆÉ‰ΩøÁî® proprioceptive ‰ø°ÊÅØ„ÄÅ‰ΩéÂ±§ÊäÄËÉΩÈ†êÊ∏¨ÂíåÊéßÂà∂Ë™§Â∑Æ‰ΩúÁÇ∫Ëº∏ÂÖ•‰æÜ‰º∞Ë®àÁâ©È´îÂßøÂã¢„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÁ≥ªÁµ±ÂèØ‰ª•Â∞áÁâ©È´îÔºàÂåÖÊã¨Â∞çÁ®±ÂíåÁÑ°Á¥ãÁêÜÁöÑÁâ©È´îÔºâÈáçÊñ∞ÂÆöÂêëÂà∞ÊâÄÈúÄÁöÑÂßøÂã¢„ÄÇ

##### **Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents**
2501.05501v1 by Jonathan Keane, Sam Keyser, Jeremy Kedziora

The use of reward functions to structure AI learning and decision making is
core to the current reinforcement learning paradigm; however, without careful
design of reward functions, agents can learn to solve problems in ways that may
be considered ``undesirable" or ``unethical. Without thorough understanding of
the incentives a reward function creates, it can be difficult to impose
principled yet general control mechanisms over its behavior. In this paper, we
study methods for constructing guardrails for AI agents that use reward
functions to learn decision making. We introduce a novel approach, which we
call strategy masking, to explicitly learn and then suppress undesirable AI
agent behavior. We apply our method to study lying in AI agents and show that
strategy masking can effectively modify agent behavior by suppressing, or
actively penalizing, the reward dimension for lying such that agents act more
honestly while not compromising their ability to perform effectively.

ÊëòË¶ÅÔºö‰ΩøÁî®ÁçéÂãµÂáΩÊï∏‰æÜÂª∫Êßã AI Â≠∏ÁøíÂíåÊ±∫Á≠ñÂà∂ÂÆöÊòØÁï∂ÂâçÂº∑ÂåñÂ≠∏ÁøíÁØÑ‰æãÁöÑÊ†∏ÂøÉÔºõÁÑ∂ËÄåÔºåËã•ÁçéÂãµÂáΩÊï∏Ë®≠Ë®à‰∏çÂë®Ôºå‰ª£ÁêÜÁ®ãÂºèÂèØËÉΩÊúÉÂ≠∏ÊúÉ‰ª•„Äå‰∏çÂèØÂèñ„ÄçÊàñ„Äå‰∏çÈÅìÂæ∑„ÄçÁöÑÊñπÂºèËß£Ê±∫ÂïèÈ°å„ÄÇËã•‰∏çÂæπÂ∫ï‰∫ÜËß£ÁçéÂãµÂáΩÊï∏ÊâÄÂâµÈÄ†ÁöÑË™òÂõ†ÔºåÂ∞±Èõ£‰ª•Â∞çÂÖ∂Ë°åÁÇ∫ÊñΩÂä†ÊúâÂéüÂâá‰∏îÈÄöÁî®ÁöÑÊéßÂà∂Ê©üÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂª∫ÊßãÈò≤Ë≠∑Êé™ÊñΩÁöÑÊñπÊ≥ïÔºå‰ª•‰æõ‰ΩøÁî®ÁçéÂãµÂáΩÊï∏Â≠∏ÁøíÊ±∫Á≠ñÂà∂ÂÆöÁöÑ AI ‰ª£ÁêÜÁ®ãÂºè‰ΩøÁî®„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÁ®±ÁÇ∫Á≠ñÁï•ÈÅÆÁΩ©ÔºåÁî®ÊñºÊòéÁ¢∫Â≠∏Áøí‰∏¶ÊäëÂà∂‰∏çËâØÁöÑ AI ‰ª£ÁêÜÁ®ãÂºèË°åÁÇ∫„ÄÇÊàëÂÄëÂ∞áÊñπÊ≥ïÊáâÁî®ÊñºÁ†îÁ©∂ AI ‰ª£ÁêÜÁ®ãÂºè‰∏≠ÁöÑË™™Ë¨äË°åÁÇ∫Ôºå‰∏¶Ë≠âÊòéÁ≠ñÁï•ÈÅÆÁΩ©ÂèØ‰ª•ÊúâÊïà‰øÆÊîπ‰ª£ÁêÜÁ®ãÂºèË°åÁÇ∫ÔºåÊñπÊ≥ïÊòØÊäëÂà∂Êàñ‰∏ªÂãïÊá≤ÁΩ∞Ë™™Ë¨äÁöÑÁçéÂãµÁ∂≠Â∫¶ÔºåËÆì‰ª£ÁêÜÁ®ãÂºèÊõ¥Ë™†ÂØ¶ÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥ÂÖ∂ÊúâÊïàÂü∑Ë°å‰ªªÂãôÁöÑËÉΩÂäõ„ÄÇ

##### **Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charit√©, and Aignostics**
2501.05409v2 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timoth√©e Lesort, Panos Korfiatis, Moritz Kr√ºgener, Beatriz Perez Cancer, Neelay Shah, Alexander M√∂llers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert M√ºller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present
Atlas, a novel vision foundation model based on the RudolfV approach. Our model
was trained on a dataset comprising 1.2 million histopathology whole slide
images, collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves
state-of-the-art performance across twenty-one public benchmark datasets, even
though it is neither the largest model by parameter count nor by training
dataset size.

ÊëòË¶ÅÔºöÊúÄËøëÂú®Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÈÄ≤Â±ïÂ∑≤Â±ïÁèæÂü∫Á§éÊ®°ÂûãÂú®ÂêÑÁ®ÆÊáâÁî®‰∏äÁöÑÊúâÊïàÊÄß„ÄÇÂú®Ê≠§Â†±Âëä‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ AtlasÔºå‰∏ÄÁ®ÆÂü∫Êñº RudolfV ÊñπÊ≥ïÁöÑÊñ∞Á©éË¶ñË¶∫Âü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãË®ìÁ∑¥Êñº‰∏ÄÂÄãÂåÖÂê´ 120 Ëê¨ÂºµÁµÑÁπîÁóÖÁêÜÂÖ®ÁéªÁâáÂΩ±ÂÉèÁöÑË≥áÊñôÈõÜÔºåÈÄô‰∫õÂΩ±ÂÉèÊî∂ÈõÜËá™ÂÖ©ÂÄãÈÜ´ÁôÇÊ©üÊßãÔºöÊ¢ÖÁ¥ÑË®∫ÊâÄÂíåÊüèÊûóÂ§èÈáåÁâπÂ§ßÂ≠∏ÈÜ´Â≠∏‰∏≠ÂøÉ„ÄÇÂÖ®Èù¢ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåAtlas Âú® 21 ÂÄãÂÖ¨ÈñãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂç≥‰ΩøÂÆÉÊó¢‰∏çÊòØÂèÉÊï∏Êï∏ÈáèÊúÄÂ§ßÁöÑÊ®°ÂûãÔºå‰πü‰∏çÊòØË®ìÁ∑¥Ë≥áÊñôÈõÜË¶èÊ®°ÊúÄÂ§ßÁöÑÊ®°Âûã„ÄÇ

##### **An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes**
2501.05197v1 by Drago Plecko, Paul Secombe, Andrea Clarke, Amelia Fiske, Samarra Toby, Donisha Duff, David Pilcher, Leo Anthony Celi, Rinaldo Bellomo, Elias Bareinboim

The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.

ÊëòË¶ÅÔºöÂ§ßÂûãË≥áÊñôÊî∂ÈõÜÂíåÂàÜÊûêÁöÑÊñ∞ÊôÇ‰ª£ÔºåÊèê‰æõ‰∫ÜË®∫Êñ∑Âíå‰∫ÜËß£ÂÅ•Â∫∑‰∏çÂπ≥Á≠âÊàêÂõ†ÁöÑÊ©üÊúÉ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫Ü‰∏ÄÂÄã‰ΩøÁî®Âõ†ÊûúÊé®Ë´ñÁ≥ªÁµ±ÂàÜÊûêÂÅ•Â∫∑Â∑ÆË∑ùÁöÑÊû∂Êßã„ÄÇÈÄôÂÄãÊû∂ÊßãÈÄèÈÅéË™øÊü•Êæ≥Ê¥≤ÔºàÂéü‰ΩèÊ∞ëÂ∞çÈùûÂéü‰ΩèÊ∞ëÔºâÂíåÁæéÂúãÔºàÈùûË£îÁæéÂúã‰∫∫Â∞çÁôΩ‰∫∫Ôºâ‰∏≠ÔºåÈáçÁóáÂä†Ë≠∑ÁóÖÊàøÔºàICUÔºâÁµêÊûúÂú®Á®ÆÊóèÂíåÊóèÁæ§‰∏äÁöÑÂ∑ÆÁï∞‰æÜÂä†‰ª•Ë™™Êòé„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÈÄöÂ∏∏Áî®ÊñºÈáèÂåñ‰∏çÂπ≥Á≠âÁöÑÁµ±Ë®àÊ∏¨ÈáèÊòØ‰∏çÂ§†ÁöÑÔºå‰∏¶Â∞àÊ≥®ÊñºÂ∞áËßÄÂØüÂà∞ÁöÑÂ∑ÆÁï∞Ê≠∏Âõ†ÊñºÁî¢ÁîüÂÆÉÁöÑÂõ†ÊûúÊ©üÂà∂„ÄÇÊàëÂÄëÁôºÁèæÔºåÂ∞ëÊï∏ÊóèË£îÊÇ£ËÄÖÂú®ÂÖ•Èô¢ÊôÇËºÉÂπ¥ËºïÔºåÊÖ¢ÊÄßÂÅ•Â∫∑ÁãÄÊ≥ÅËºÉÂ∑ÆÔºåÊõ¥ÊúâÂèØËÉΩÂõ†Á∑äÊÄ•ÂíåÈùûÈÅ∏ÊìáÊÄßÂéüÂõ†ËÄåÂÖ•Èô¢Ôºå‰∏îÁñæÁóÖÂö¥ÈáçÁ®ãÂ∫¶ËºÉÈ´ò„ÄÇÁÑ∂ËÄåÔºåÂêåÊôÇÊàëÂÄëÁôºÁèæÂ±¨ÊñºÂ∞ëÊï∏ÊóèË£îÁæ§È´îÂÖ∑Êúâ‰øùË≠∑ÊÄßÁöÑÁõ¥Êé•ÂΩ±ÈüøÔºåËàáÂ§öÊï∏ÊóèË£îÁöÑÂ∞çÁÖßÁµÑÁõ∏ÊØîÔºåÂ∞ëÊï∏ÊóèË£îÊÇ£ËÄÖÂú®ÂÖ∂‰ªñÊâÄÊúâËÆäÊï∏‰øùÊåÅÁõ∏ÂêåÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ≠òÊ¥ªÁéáÊúâÊâÄÊîπÂñÑ„ÄÇÊàëÂÄëË≠âÊòéÈÄôÁ®Æ‰øùË≠∑ÊïàÊáâËàáË¢´ÈÄÅÈÄ≤ ICU ÁöÑÊ©üÁéáÂ¢ûÂä†ÊúâÈóúÔºåÂ∞ëÊï∏ÊóèË£îÊÇ£ËÄÖÁöÑ ICU ÂÖ•Èô¢È¢®Èö™Â¢ûÂä†„ÄÇÊàëÂÄë‰πüÁôºÁèæÔºåÂ∞ëÊï∏ÊóèË£îÊÇ£ËÄÖÈõñÁÑ∂Â≠òÊ¥ªÁéáÊúâÊâÄÊîπÂñÑÔºå‰ΩÜÊõ¥ÊúâÂèØËÉΩÂÜçÊ¨°ÂÖ•Èô¢Âà∞ ICU„ÄÇÂõ†Ê≠§ÔºåÁî±ÊñºËºÉÈõ£Áç≤ÂæóÂàùÁ¥öÈÜ´ÁôÇ‰øùÂÅ•ÔºåÂ∞ëÊï∏ÊóèË£îÊÇ£ËÄÖÊõ¥ÊúâÂèØËÉΩÂõ†ÂèØÈ†êÈò≤ÁöÑÁñæÁóÖËÄåÈÄ≤ÂÖ• ICUÔºåÂ∞éËá¥Ê≠ª‰∫°ÁéáÈôç‰Ωé‰∏¶Áî¢ÁîüÁúã‰ººÂÖ∑Êúâ‰øùË≠∑‰ΩúÁî®ÁöÑÊïàÊáâ„ÄÇÁî±Êñº ICU ÂÖ•Èô¢ÁöÑÂü∫Êú¨È¢®Èö™ÂèØËÉΩ‰ΩúÁÇ∫Áº∫‰πèÂàùÁ¥öÁÖßË≠∑ÁöÑÊåáÊ®ôÔºåÂõ†Ê≠§ÊàëÂÄëÈñãÁôº‰∫ÜÂéü‰ΩèÊ∞ëÈáçÁóáÁõ£Ë≠∑ÂÖ¨Âπ≥ÊÄßÔºàIICEÔºâÈõ∑ÈÅîÔºåÈÄôÊòØ‰∏ÄÂÄãÁõ£ÊéßÁ≥ªÁµ±ÔºåÁî®ÊñºËøΩËπ§Êæ≥Ê¥≤Âéü‰ΩèÊ∞ë‰∫∫Âè£Âú®‰∏çÂêåÂú∞ÁêÜÂçÄÂüüÈÅéÂ∫¶‰ΩøÁî® ICU Ë≥áÊ∫êÁöÑÊÉÖÊ≥Å„ÄÇ

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈù¢Ëá®ÈõôÈáçÊåëÊà∞ÔºöÈ†òÂüüËΩâÁßªÔºåÊ®°ÂûãÂú®ËàáÂÖ∂Ë®ìÁ∑¥Áí∞Â¢É‰∏çÂêåÁöÑË®≠ÂÆö‰∏≠ÈÉ®ÁΩ≤ÊôÇË°®Áèæ‰∏ç‰Ω≥Ôºå‰ª•ÂèäÈ°ûÂà•‰∏çÂπ≥Ë°°ÔºåÊüê‰∫õÁñæÁóÖÁãÄÊ≥ÅÂú®Ëá™ÁÑ∂Áïå‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥„ÄÇÊàëÂÄëÊèêÂá∫‰∏çÂπ≥Ë°°ÊÑüÁü•ÂüüÈÅ©Êáâ (IADA)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÈÄèÈÅé‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÂêåÊôÇÊáâÂ∞çÈÄôÂÖ©ÂÄãÊåëÊà∞Ôºö(1) ÂÖ∑ÊúâÈ°ûÂà•ÁâπÂÆöÊ≥®ÊÑèÂäõÊ©üÂà∂ÁöÑËá™ÈÅ©ÊáâÁâπÂæµÂ≠∏ÁøíÔºå(2) ÂÖ∑ÊúâÂãïÊÖãÂä†Ê¨äÁöÑÂπ≥Ë°°ÂüüÂ∞çÈΩäÔºå‰ª•Âèä (3) Ëá™ÈÅ©ÊáâÈñæÂÄºÊúÄ‰Ω≥Âåñ„ÄÇÊàëÂÄëÁöÑÁêÜË´ñÂàÜÊûêÂª∫Á´ã‰∫ÜÊî∂ÊñÇ‰øùË≠âÂíåË§áÈõúÂ∫¶ÁïåÈôê„ÄÇÈÄèÈÅéÂ∞çÂõõÁ®ÆÂΩ±ÂÉèÊ®°ÂºèÁöÑËÉöËÉéÁôºËÇ≤Ë©ï‰º∞ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåIADA Ë≠âÊòé‰∫ÜÂ∞çÁèæÊúâÊñπÊ≥ïÁöÑÈ°ØËëóÊîπÈÄ≤ÔºåÂú®Á∂≠ÊåÅÈ°ûÂà•ÈñìÂπ≥Ë°°ÊÄßËÉΩÁöÑÂêåÊôÇÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 25.19%„ÄÇÂú®‰ΩéÂìÅË≥™ÂΩ±ÂÉèÁ≥ªÁµ±ÁöÑÊåëÊà∞ÊÄßÂ†¥ÊôØ‰∏≠ÔºåIADA ‰ª•È´òÈÅî 12.56% ÁöÑ AUC ÊîπÈÄ≤È°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫Ü IADA Âú®ÁÇ∫‰∏çÂêåÁöÑËá®Â∫äË®≠ÂÆöÈñãÁôºÂèØÈù†‰∏îÂÖ¨Âπ≥ÁöÑÈÜ´ÁôÇÂΩ±ÂÉèÁ≥ªÁµ±ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals**
2501.04896v1 by Michail Ouroutzoglou, Mingmin Zhao, Joshua Hellerstein, Hariharan Rahul, Asima Badic, Brian S. Kim, Dina Katabi

Chronic itch affects 13% of the US population, is highly debilitating, and
underlies many medical conditions. A major challenge in clinical care and new
therapeutics development is the lack of an objective measure for quantifying
itch, leading to reliance on subjective measures like patients' self-assessment
of itch severity. In this paper, we show that a home radio device paired with
artificial intelligence (AI) can concurrently capture scratching and evaluate
its impact on sleep quality by analyzing radio signals bouncing in the
environment. The device eliminates the need for wearable sensors or skin
contact, enabling monitoring of chronic itch over extended periods at home
without burdening patients or interfering with their skin condition. To
validate the technology, we conducted an observational clinical study of
chronic pruritus patients, monitored at home for one month using both the radio
device and an infrared camera. Comparing the output of the device to ground
truth data from the camera demonstrates its feasibility and accuracy (ROC AUC =
0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a
significant correlation between scratching and low sleep quality, manifested as
a reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep
latency (R = 0.68, p < 0.001). Our study underscores the potential of passive,
long-term, at-home monitoring of chronic scratching and its sleep implications,
offering a valuable tool for both clinical care of chronic itch patients and
pharmaceutical clinical trials.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßÊêîÁô¢ÂΩ±ÈüøÁæéÂúã 13% ÁöÑ‰∫∫Âè£ÔºåÊúÉÂö¥ÈáçË°∞Âº±Ôºå‰∏îÊòØË®±Â§öÁñæÁóÖÁöÑÊ†πÊú¨ÂéüÂõ†„ÄÇËá®Â∫äË≠∑ÁêÜÂíåÊñ∞ÁôÇÊ≥ïÈñãÁôºÁöÑ‰∏ÄÂ§ßÊåëÊà∞ÊòØÁº∫‰πèÂÆ¢ËßÄÁöÑÊåáÊ®ô‰æÜÈáèÂåñÊêîÁô¢ÔºåÂ∞éËá¥‰æùË≥¥ÊñºÊÇ£ËÄÖËá™ÊàëË©ï‰º∞ÊêîÁô¢Âö¥ÈáçÁ®ãÂ∫¶Á≠â‰∏ªËßÄÊåáÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÁ®ÆËàá‰∫∫Â∑•Êô∫ÊÖß (AI) ÈÖçÂ∞çÁöÑÂÆ∂Áî®ÁÑ°Á∑öÈõªË£ùÁΩÆÔºåÂèØÈÄèÈÅéÂàÜÊûêÂú®Áí∞Â¢É‰∏≠ÂΩàË∑≥ÁöÑÁÑ°Á∑öÈõªË®äËôüÔºåÂêåÊôÇÊì∑ÂèñÊäìÊíì‰∏¶Ë©ï‰º∞ÂÖ∂Â∞çÁù°Áú†ÂìÅË≥™ÁöÑÂΩ±Èüø„ÄÇÊ≠§Ë£ùÁΩÆÊ∂àÈô§‰∫ÜÂ∞çÁ©øÊà¥ÂºèÊÑüÊ∏¨Âô®ÊàñÁöÆËÜöÊé•Ëß∏ÁöÑÈúÄÊ±ÇÔºåËÆìÊÇ£ËÄÖÂú®ÂÆ∂‰∏≠Èï∑ÊôÇÈñìÁõ£ÊéßÊÖ¢ÊÄßÊêîÁô¢ÔºåËÄå‰∏çÊúÉÈÄ†ÊàêË≤†ÊìîÊàñÂπ≤ÊìæÂÖ∂ÁöÆËÜöÁãÄÊ≥Å„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÈ†ÖÊäÄË°ìÔºåÊàëÂÄëÂ∞çÊÖ¢ÊÄßÊêîÁô¢ÁóáÊÇ£ËÄÖÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖËßÄÂØüÊÄßËá®Â∫äÁ†îÁ©∂Ôºå‰ΩøÁî®ÁÑ°Á∑öÈõªË£ùÁΩÆÂíåÁ¥ÖÂ§ñÁ∑öÊîùÂΩ±Ê©üÂú®ÂÆ∂‰∏≠Áõ£Êéß‰∏ÄÂÄãÊúà„ÄÇÂ∞áË£ùÁΩÆÁöÑËº∏Âá∫ËàáÊîùÂΩ±Ê©üÁöÑÁúüÂØ¶Êï∏ÊìöÈÄ≤Ë°åÊØîËºÉÔºåË≠âÊòé‰∫ÜÂÖ∂ÂèØË°åÊÄßÂíåÊ∫ñÁ¢∫ÊÄß (ROC AUC = 0.997ÔºåÈùàÊïèÂ∫¶ = 0.825ÔºåÁâπÁï∞Â∫¶ = 0.997)„ÄÇÁµêÊûúÈ°ØÁ§∫ÊäìÊíìËàáÁù°Áú†ÂìÅË≥™‰Ωé‰∏ã‰πãÈñìÂ≠òÂú®È°ØËëóÁõ∏ÈóúÊÄßÔºåË°®ÁèæÁÇ∫Áù°Áú†ÊïàÁéáÈôç‰Ωé (R = 0.6Ôºåp < 0.001) ÂíåÁù°Áú†ÊΩõ‰ºèÊúüÂ¢ûÂä† (R = 0.68Ôºåp < 0.001)„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜË¢´Âãï„ÄÅÈï∑Êúü„ÄÅÂú®ÂÆ∂‰∏≠Áõ£ÊéßÊÖ¢ÊÄßÊäìÊíìÂèäÂÖ∂Â∞çÁù°Áú†ÁöÑÂΩ±ÈüøÁöÑÊΩõÂäõÔºåÁÇ∫ÊÖ¢ÊÄßÊêîÁô¢ÁóáÊÇ£ËÄÖÁöÑËá®Â∫äË≠∑ÁêÜÂíåËó•Âª†Ëá®Â∫äË©¶È©óÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation**
2501.04614v2 by Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda

Artificial Intelligence is revolutionizing medical practice, enhancing
diagnostic accuracy and healthcare delivery. However, its adaptation in medical
settings still faces significant challenges, related to data availability and
privacy constraints. Synthetic data has emerged as a promising solution to
mitigate these issues, addressing data scarcity while preserving privacy.
Recently, Latent Diffusion Models have emerged as a powerful tool for
generating high-quality synthetic data. Meanwhile, the integration of different
modalities has gained interest, emphasizing the need of models capable of
handle multimodal medical data. Existing approaches struggle to integrate
complementary information and lack the ability to generate modalities
simultaneously. To address this challenge, we present MedCoDi-M, a
6.77-billion-parameter model, designed for multimodal medical data generation,
that, following Foundation Model paradigm, exploits contrastive learning and
large quantity of data to build a shared latent space which capture the
relationships between different data modalities. Further, we introduce the
Multi-Prompt training technique, which significantly boosts MedCoDi-M's
generation under different settings. We extensively validate MedCoDi-M: first
we benchmark it against five competitors on the MIMIC-CXR dataset, a
state-of-the-art dataset for Chest X-ray and radiological report generation.
Secondly, we perform a Visual Turing Test with expert radiologists to assess
the realism and clinical relevance of the generated data, ensuring alignment
with real-world scenarios. Finally, we assess the utility of MedCoDi-M in
addressing key challenges in the medical field, such as anonymization, data
scarcity and imbalance learning. The results are promising, demonstrating the
applicability of MedCoDi-M in medical contexts. Project page is at
https://cosbidev.github.io/MedCoDi-M/.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®Èù©Êñ∞ÈÜ´ÁôÇÂØ¶ÂãôÔºåÊèêÂçáË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂú®ÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÁöÑÊáâÁî®‰ªçÈù¢Ëá®ËëóÈáçÂ§ßÊåëÊà∞ÔºåÈÄôËàáË≥áÊñôÂèØÁî®ÊÄßÂíåÈö±ÁßÅÈôêÂà∂ÊúâÈóú„ÄÇÂêàÊàêË≥áÊñôÂ∑≤ÊàêÁÇ∫Á∑©Ëß£ÈÄô‰∫õÂïèÈ°åÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÔºåÂÆÉÂú®‰øùË≠∑Èö±ÁßÅÁöÑÂêåÊôÇËß£Ê±∫‰∫ÜË≥áÊñôÁü≠Áº∫ÁöÑÂïèÈ°å„ÄÇÊúÄËøëÔºåÊΩõÂú®Êì¥Êï£Ê®°ÂûãÂ∑≤ÊàêÁÇ∫Áî¢ÁîüÈ´òÂìÅË≥™ÂêàÊàêË≥áÊñôÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÂêåÊôÇÔºåÊï¥Âêà‰∏çÂêåÊ®°ÊÖãÂ∑≤ÂºïËµ∑ËààË∂£ÔºåÂº∑Ë™ø‰∫ÜÈúÄË¶ÅËÉΩÂ§†ËôïÁêÜÂ§öÊ®°ÊÖãÈÜ´ÁôÇË≥áÊñôÁöÑÊ®°Âûã„ÄÇÁèæÊúâÊñπÊ≥ïÈõ£‰ª•Êï¥ÂêàË£úÂÖÖË≥áË®äÔºå‰∏¶‰∏îÁº∫‰πèÂêåÊôÇÁî¢ÁîüÊ®°ÊÖãÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MedCoDi-MÔºåÈÄôÊòØ‰∏ÄÂÄã 67.7 ÂÑÑÂèÉÊï∏ÁöÑÊ®°ÂûãÔºåÂ∞àÁÇ∫Â§öÊ®°ÊÖãÈÜ´ÁôÇË≥áÊñôÁî¢ÁîüËÄåË®≠Ë®àÔºåÂÆÉÈÅµÂæ™Âü∫Á§éÊ®°ÂûãÁØÑ‰æãÔºåÂà©Áî®Â∞çÊØîÂ≠∏ÁøíÂíåÂ§ßÈáèÁöÑË≥áÊñô‰æÜÂª∫Á´ã‰∏ÄÂÄãÂÖ±‰∫´ÊΩõÂú®Á©∫ÈñìÔºå‰ª•ÊçïÊçâ‰∏çÂêåË≥áÊñôÊ®°ÊÖã‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§öÊèêÁ§∫Ë®ìÁ∑¥ÊäÄË°ìÔºåÂÆÉÈ°ØËëóÊèêÂçá‰∫Ü MedCoDi-M Âú®‰∏çÂêåË®≠ÂÆö‰∏ãÁöÑÁî¢Áîü„ÄÇÊàëÂÄëÂª£Ê≥õÈ©óË≠â‰∫Ü MedCoDi-MÔºöÈ¶ñÂÖàÔºåÊàëÂÄëÂú® MIMIC-CXR Ë≥áÊñôÈõÜ‰∏äÂ∞çÂÆÉËàá‰∫îÂÄãÁ´∂Áà≠ËÄÖÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÈÄôÊòØËÉ∏ÈÉ® X ÂÖâÂíåÊîæÂ∞ÑÂ†±ÂëäÁî¢ÁîüÈ†òÂüüÁöÑÊúÄÊñ∞Ë≥áÊñôÈõÜ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëËàáÊîæÂ∞ÑÁßëÂ∞àÂÆ∂ÈÄ≤Ë°å‰∫ÜË¶ñË¶∫ÂúñÈùàÊ∏¨Ë©¶Ôºå‰ª•Ë©ï‰º∞Áî¢ÁîüË≥áÊñôÁöÑÁúüÂØ¶ÊÄßÂíåËá®Â∫äÁõ∏ÈóúÊÄßÔºåÁ¢∫‰øùËàáÁúüÂØ¶Â†¥ÊôØ‰øùÊåÅ‰∏ÄËá¥„ÄÇÊúÄÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫Ü MedCoDi-M Âú®Ëß£Ê±∫ÈÜ´ÁôÇÈ†òÂüüÈóúÈçµÊåëÊà∞‰∏≠ÁöÑÊïàÁî®Ôºå‰æãÂ¶ÇÂåøÂêçÂåñ„ÄÅË≥áÊñôÁü≠Áº∫Âíå‰∏çÂπ≥Ë°°Â≠∏Áøí„ÄÇÁµêÊûú‰ª§‰∫∫ÊªøÊÑèÔºåË≠âÊòé‰∫Ü MedCoDi-M Âú®ÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÂ∞àÊ°àÈ†ÅÈù¢‰ΩçÊñº https://cosbidev.github.io/MedCoDi-M/„ÄÇ

##### **A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation**
2501.04577v1 by Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Ningyuan Cao, Michael Niemier

Uncertainty estimation is an indispensable capability for AI-enabled,
safety-critical applications, e.g. autonomous vehicles or medical diagnosis.
Bayesian neural networks (BNNs) use Bayesian statistics to provide both
classification predictions and uncertainty estimation, but they suffer from
high computational overhead associated with random number generation and
repeated sample iterations. Furthermore, BNNs are not immediately amenable to
acceleration through compute-in-memory architectures due to the frequent memory
writes necessary after each RNG operation. To address these challenges, we
present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the
SRAM memory words. This integration reduces RNG overhead and enables
fully-parallel compute-in-memory operations for BNNs. The prototype chip
achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput
while occupying 0.45 mm2, bringing AI uncertainty estimation to edge
computation.

ÊëòË¶ÅÔºö‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂ∞çÊñº AI È©ÖÂãï„ÄÅÂÆâÂÖ®ÈóúÈçµÁöÑÊáâÁî®Á®ãÂºè‰æÜË™™ÊòØ‰∏çÂèØÊàñÁº∫ÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõËªäËºõÊàñÈÜ´ÁôÇË®∫Êñ∑„ÄÇË≤ùÊ∞èÈ°ûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (BNN) ‰ΩøÁî®Ë≤ùÊ∞èÁµ±Ë®à‰æÜÊèê‰æõÂàÜÈ°ûÈ†êÊ∏¨Âíå‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºå‰ΩÜÂÆÉÂÄëÊúÉÂõ†Èö®Ê©üÊï∏ÁîüÊàêÂíåÈáçË§áÊ®£Êú¨Ëø≠‰ª£ËÄåÁî¢ÁîüÈ´òÈÅãÁÆóË≤†Êìî„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÊØèÊ¨° RNG Êìç‰ΩúÂæåÈÉΩÈúÄË¶ÅÈ†ªÁπÅÁöÑË®òÊÜ∂È´îÂØ´ÂÖ•ÔºåÂõ†Ê≠§ BNN ÁÑ°Ê≥ïÁ´ãÂç≥ÈÅ©Áî®ÊñºÈÄèÈÅéË®òÊÜ∂È´îÈÅãÁÆóÊû∂ÊßãÈÄ≤Ë°åÂä†ÈÄü„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÊ¨æ ASICÔºåÂ∞á 360 fJ/Sample Gaussian RNG Áõ¥Êé•Êï¥ÂêàÂà∞ SRAM Ë®òÊÜ∂È´îÂ≠óÂÖÉ‰∏≠„ÄÇÊ≠§Êï¥ÂêàÂèØÊ∏õÂ∞ë RNG Ë≤†ÊìîÔºå‰∏¶ÁÇ∫ BNN ÂïüÁî®ÂÆåÂÖ®‰∏¶Ë°åÁöÑË®òÊÜ∂È´îÈÅãÁÆóÊìç‰Ωú„ÄÇÂéüÂûãÊô∂ÁâáÂèØÈÅîÊàê 5.12 GSa/s RNG ËôïÁêÜÈáèÂíå 102 GOp/s Á•ûÁ∂ìÁ∂≤Ë∑ØËôïÁêÜÈáèÔºåÂêåÊôÇ‰ΩîÁî® 0.45 mm2ÔºåÂ∞á AI ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂ∏∂Âà∞ÈÇäÁ∑£ÈÅãÁÆó„ÄÇ

##### **Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images**
2501.04217v1 by Ren Tasai, Guang Li, Ren Togo, Minghui Tang, Takaaki Yoshimura, Hiroyuki Sugimori, Kenji Hirata, Takahiro Ogawa, Kohsuke Kudo, Miki Haseyama

We propose a novel continual self-supervised learning method (CSSL)
considering medical domain knowledge in chest CT images. Our approach addresses
the challenge of sequential learning by effectively capturing the relationship
between previously learned knowledge and new information at different stages.
By incorporating an enhanced DER into CSSL and maintaining both diversity and
representativeness within the rehearsal buffer of DER, the risk of data
interference during pretraining is reduced, enabling the model to learn more
richer and robust feature representations. In addition, we incorporate a mixup
strategy and feature distillation to further enhance the model's ability to
learn meaningful representations. We validate our method using chest CT images
obtained under two different imaging conditions, demonstrating superior
performance compared to state-of-the-art methods.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊåÅÁ∫åËá™ÊàëÁõ£Áù£Â≠∏ÁøíÊñπÊ≥ï (CSSL)ÔºåËÄÉÈáè‰∫ÜËÉ∏ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÂΩ±ÂÉè‰∏≠ÁöÑÈÜ´Â≠∏È†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéÊúâÊïàÊçïÊçâÂÖàÂâçÂ≠∏ÁøíÁöÑÁü•Ë≠òËàá‰∏çÂêåÈöéÊÆµÁöÑÊñ∞Ë≥áË®ä‰πãÈñìÁöÑÈóú‰øÇÔºå‰æÜËß£Ê±∫Âæ™Â∫èÂ≠∏ÁøíÁöÑÊåëÊà∞„ÄÇÈÄèÈÅéÂ∞áÂ¢ûÂº∑ÁöÑ DER Á¥çÂÖ• CSSLÔºå‰∏¶Âú® DER ÁöÑÊéíÁ∑¥Á∑©Ë°ùÂçÄÂÖßÁ∂≠ÊåÅÂ§öÊ®£ÊÄßÂíå‰ª£Ë°®ÊÄßÔºåÈ†êË®ìÁ∑¥ÊúüÈñìË≥áÊñôÂπ≤ÊìæÁöÑÈ¢®Èö™Èôç‰ΩéÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†Â≠∏ÁøíÊõ¥Ë±êÂØå‰∏îÂº∑ÂÅ•ÁöÑÁâπÂæµË°®Âæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ¥çÂÖ•Ê∑∑Ê∑ÜÁ≠ñÁï•ÂíåÁâπÂæµËêÉÂèñÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Ê®°ÂûãÂ≠∏ÁøíÊúâÊÑèÁæ©Ë°®ÂæµÁöÑËÉΩÂäõ„ÄÇÊàëÂÄë‰ΩøÁî®Âú®ÂÖ©Á®Æ‰∏çÂêåÂΩ±ÂÉèÊ¢ù‰ª∂‰∏ãÂèñÂæóÁöÑËÉ∏ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÂΩ±ÂÉèÈ©óË≠âÊàëÂÄëÁöÑÊ®°ÂûãÔºåË≠âÊòéËàáÁèæÊúâÊäÄË°ìÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ

##### **Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa**
2501.04734v1 by Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic
Resonance Imaging (MRI) technology raises questions about the applicability of
machine learning methods for clinical tasks. This study aims to provide a
robust deep learning-based brain tumor segmentation (BraTS) method tailored for
the SSA population using a threefold approach. Firstly, the impact of domain
shift from the SSA training data on model efficacy was examined, revealing no
significant effect. Secondly, a comparative analysis of 3D and 2D
full-resolution models using the nnU-Net framework indicates similar
performance of both the models trained for 300 epochs achieving a five-fold
cross-validation score of 0.93. Lastly, addressing the performance gap observed
in SSA validation as opposed to the relatively larger BraTS glioma (GLI)
validation set, two strategies are proposed: fine-tuning SSA cases using the
GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel
neural style transfer-based data augmentation technique for the SSA cases. This
investigation underscores the potential of enhancing brain tumor prediction
within SSA's unique healthcare landscape.

ÊëòË¶ÅÔºöÂú®ÊííÂìàÊãâ‰ª•ÂçóÈùûÊ¥≤ (SSA)Ôºå‰ΩéË¥®ÈáèÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) ÊäÄÊúØÁöÑ‰ΩøÁî®ÂºïÂèë‰∫ÜÊúâÂÖ≥Êú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÂú®‰∏¥Â∫ä‰ªªÂä°‰∏≠ÈÄÇÁî®ÊÄßÁöÑÈóÆÈ¢ò„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êèê‰æõ‰∏ÄÁßçÈíàÂØπ SSA ‰∫∫Áæ§ÈáèË∫´ÂÆöÂà∂ÁöÑÈ≤ÅÊ£íÊ∑±Â∫¶Â≠¶‰π†ËÑëËÇøÁò§ÂàÜÂâ≤ (BraTS) ÊñπÊ≥ïÔºåÈááÁî®‰∏âÈáçÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊ£ÄÊü•‰∫Ü SSA ËÆ≠ÁªÉÊï∞ÊçÆÂØπÊ®°ÂûãÊïàËÉΩÁöÑÂüüÂÅèÁßªÂΩ±ÂìçÔºåÁªìÊûúÊòæÁ§∫Ê≤°ÊúâÊòæÁùÄÂΩ±Âìç„ÄÇÂÖ∂Ê¨°Ôºå‰ΩøÁî® nnU-Net Ê°ÜÊû∂ÂØπ 3D Âíå 2D ÂÖ®ÂàÜËæ®ÁéáÊ®°ÂûãËøõË°åÊØîËæÉÂàÜÊûêÔºåË°®ÊòéÈíàÂØπ 300 ‰∏™ epoch ËÆ≠ÁªÉÁöÑ‰∏§‰∏™Ê®°ÂûãÁöÑÊÄßËÉΩÁõ∏‰ººÔºåÂÆûÁé∞‰∫Ü 0.93 ÁöÑ‰∫îÈáç‰∫§ÂèâÈ™åËØÅÂàÜÊï∞„ÄÇÊúÄÂêéÔºåÈíàÂØπ SSA È™åËØÅ‰∏≠ËßÇÂØüÂà∞ÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåËÄå‰∏çÊòØÁõ∏ÂØπËæÉÂ§ßÁöÑ BraTS Á•ûÁªèËÉ∂Ë¥®Áò§ (GLI) È™åËØÅÈõÜÔºåÊèêÂá∫‰∫Ü‰∏§ÁßçÁ≠ñÁï•Ôºö‰ΩøÁî® GLI+SSA ÊúÄ‰Ω≥È¢ÑËÆ≠ÁªÉÁöÑ 2D ÂÖ®ÂàÜËæ®ÁéáÊ®°ÂûãÂú® 300 ‰∏™ epoch ÂØπ SSA ÁóÖ‰æãËøõË°åÂæÆË∞ÉÔºåÂπ∂‰∏∫ SSA ÁóÖ‰æãÂºïÂÖ•‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ•ûÁªèÈ£éÊ†ºËøÅÁßªÊï∞ÊçÆÂ¢ûÂº∫ÊäÄÊúØ„ÄÇËøôÈ°πË∞ÉÊü•Âº∫Ë∞É‰∫ÜÂú® SSA Áã¨ÁâπÁöÑÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÊèêÈ´òËÑëËÇøÁò§È¢ÑÊµãÊΩúÂäõÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ÂÖ¨ÂÖ±‰∫§ÈÄöÁ≥ªÁµ±‰∏≠ÔºåÁÇ∫ÊèêÂçáÂüéÂ∏ÇÊµÅÂãïÊÄßÂ∏∂‰æÜËΩâÂûãÂ•ëÊ©ü„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é LLM Âú®ËÅñÂÆâÊù±Â∞ºÂ•ß‰∫§ÈÄöÁ≥ªÁµ±ËÑàÁµ°‰∏ãÔºåÈù©Êñ∞Â§ßÁúæÈÅãËº∏ÁÆ°ÁêÜÁöÑÊΩõÂäõ„ÄÇÂà©Áî® LLM Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåË≥áÊñôÂàÜÊûêÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊàëÂÄëÊé¢Ë®éÂÖ∂Âú®ÂÑ™ÂåñË∑ØÁ∑öË¶èÂäÉ„ÄÅÁ∏ÆÁü≠Á≠âÂÄôÊôÇÈñìÔºå‰ª•ÂèäÊèê‰æõÂÄã‰∫∫ÂåñÊóÖÈÅäÂçîÂä©ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÈÄèÈÅéÂà©Áî®ÈÄöÁî®Â§ßÁúæÈÅãËº∏Ë≥áÊñôË¶èÁØÑ (GTFS) ÂíåÂÖ∂‰ªñÁõ∏ÈóúË≥áÊñôÔºåÊú¨Á†îÁ©∂Êó®Âú®Ë≠âÊòé LLM Â¶Ç‰ΩïÊΩõÂú®ÊèêÂçáË≥áÊ∫êÈÖçÁΩÆ„ÄÅÊèêÂçá‰πòÂÆ¢ÊªøÊÑèÂ∫¶Ôºå‰ª•ÂèäÂú®‰∫§ÈÄöÁáüÈÅã‰∏≠Êèê‰æõË≥áÊñôÈ©ÖÂãïÁöÑÊ±∫Á≠ñ„ÄÇÈáùÂ∞ç‰∏çÂêåÁöÑ ChatGPT Ê®°ÂûãÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºå‰ª•Ë©ï‰º∞ÂÖ∂ÁêÜËß£‰∫§ÈÄöË≥áË®ä„ÄÅÊì∑ÂèñÁõ∏ÈóúË≥áÊñôÔºå‰ª•ÂèäÊèê‰æõÂÖ®Èù¢ÂõûÊáâÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåÂÑòÁÆ° LLM Â∞çÂ§ßÁúæÈÅãËº∏Ê•µÂÖ∑ÂâçÊôØÔºå‰ΩÜÁ≤æÂØÜÁöÑÂ∑•Á®ãÂíåÂæÆË™øÂ∞çÊñºÂØ¶ÁèæÂÖ∂ÂÖ®ÈÉ®ÊΩõÂäõËá≥ÈóúÈáçË¶Å„ÄÇËÅñÂÆâÊù±Â∞ºÂ•ß‰ΩúÁÇ∫‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÁÇ∫Âú®ÂÖ∂‰ªñÈÉΩÂ∏ÇÁí∞Â¢É‰∏≠ÈñãÁôºÁî± LLM È©ÖÂãïÁöÑ‰∫§ÈÄöÁ≥ªÁµ±Êèê‰æõÂèÉËÄÉ„ÄÇ

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v2 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

ÊëòË¶ÅÔºöËÖ¶Áò§ÂèØËÉΩÂ∞éËá¥Á•ûÁ∂ìÂäüËÉΩÈöúÁ§ô„ÄÅË™çÁü•ÂíåÂøÉÁêÜÁãÄÊÖãÊîπËÆä„ÄÅÈ°±ÂÖßÂ£ìÂçáÈ´òÂíåÁô≤ÁôáÁôº‰ΩúÔºåÂæûËÄåÂ∞ç‰∫∫È°ûÁîüÂëΩÂíåÂÅ•Â∫∑ÊßãÊàêÈáçÂ§ßÈ¢®Èö™„ÄÇYou Only Look Once (YOLO) Á≥ªÂàóÊ®°ÂûãÂ∑≤Ë≠âÊòéÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁõÆÊ®ôÊ™¢Ê∏¨‰∏≠ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÂ∞á SCConv Ê≥®ÊÑèÂäõÊ©üÂà∂Êï¥ÂêàÂà∞ YOLOv9 ‰∏≠ÔºåÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ SCC-YOLO Êû∂Êßã„ÄÇSCConv Ê®°ÁµÑÈÄöÈÅéÊ∏õÂ∞ëÁâπÂæµ‰πãÈñìÁöÑÁ©∫ÈñìÂíåÈÄöÈÅìÂÜóÈ§ò‰æÜÈáçÂª∫‰∏ÄÂÄãÈ´òÊïàÁöÑÂç∑Á©çÊ®°ÁµÑÔºåÂæûËÄåÂ¢ûÂº∑ÂΩ±ÂÉèÁâπÂæµÁöÑÂ≠∏Áøí„ÄÇÊàëÂÄë‰ΩøÁî® Br35H Ë≥áÊñôÈõÜÂíåÊàëÂÄëËá™Ë£ΩÁöÑË≥áÊñôÈõÜ (Brain_Tumor_Dataset) Ë™øÊü•‰∫ÜÂ∞á‰∏çÂêåÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂Ëàá YOLOv9 Ê®°ÂûãÊï¥ÂêàÂ∞çËÖ¶Áò§ÂΩ±ÂÉèÊ™¢Ê∏¨ÁöÑÂΩ±Èüø„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú® Br35H Ë≥áÊñôÈõÜ‰∏äÔºåËàá YOLOv9 Áõ∏ÊØîÔºåSCC-YOLO Âú® mAP50 ‰∏äÊèêÈ´ò‰∫Ü 0.3%ÔºåËÄåÂú®ÊàëÂÄëËá™Ë£ΩÁöÑË≥áÊñôÈõÜ‰∏äÔºåSCC-YOLO ÊØî YOLOv9 ÊèêÈ´ò‰∫Ü 0.5%„ÄÇSCC-YOLO Â∑≤ÈÅîÂà∞ËÖ¶Áò§Ê™¢Ê∏¨ÁöÑÊúÄÊñ∞ÊïàËÉΩ„ÄÇÂéüÂßãÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

ÊëòË¶ÅÔºöÂú®ÂØ¶ÈöõÁöÑÁù°Áú†ÈöéÊÆµÂàÜÈ°û‰∏≠Ôºå‰∏ÄÂÄãÈóúÈçµÁöÑÊåëÊà∞ÊòØËÖ¶ÈõªÂúñÊï∏ÊìöÂú®‰∏çÂêåÂèóË©¶ËÄÖÂíåÁí∞Â¢É‰∏≠ÁöÑËÆäÁï∞ÊÄß„ÄÇÁîüÁêÜ„ÄÅÂπ¥ÈΩ°„ÄÅÂÅ•Â∫∑ÁãÄÊ≥ÅÂíåË®òÈåÑÊ¢ù‰ª∂ÁöÑÂ∑ÆÁï∞ÂèØËÉΩÂ∞éËá¥Êï∏Êìö‰πãÈñìÁöÑÈ†òÂüüÂÅèÁßª„ÄÇÈÄô‰∫õÈ†òÂüüÂÅèÁßªÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄß‰∏ãÈôçÔºåÁâπÂà•ÊòØÁï∂Ê®°ÂûãÊáâÁî®ÊñºËàáÂÖ∂ÊúÄÂàùË®ìÁ∑¥ÊôÇ‰∏çÂêåÁöÑÁâπÂæµÁöÑÊñ∞Êï∏ÊìöÊôÇÔºåÈÄôÊòØË≤†ÈÅ∑ÁßªÁöÑÂÖ∏ÂûãË°®Áèæ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫ÈÅ∏ÊìáÊÄßÂæÆË™ø„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂà©Áî®È†êË®ìÁ∑¥ÁöÑÂ§öËß£ÊûêÂ∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MRCNN) ‰æÜÊèêÂèñËÖ¶ÈõªÂúñÁâπÂæµÔºåÊçïÊçâ‰∏çÂêåÁù°Áú†ÈöéÊÆµÁöÑÁç®ÁâπÁâπÂæµ„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈ†òÂüüÂÅèÁßªÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈ†òÂüüÂ∞çÈΩäÊ©üÂà∂ÔºåÂÆÉÊé°Áî®Âú∞ÁêÉÁßªÂãïË∑ùÈõ¢ (EMD) ‰æÜË©ï‰º∞ÂíåÈÅ∏ÊìáËàáÁõÆÊ®ôÈ†òÂüüÁ∑äÂØÜÂåπÈÖçÁöÑÊ∫êÈ†òÂüüÊï∏Êìö„ÄÇÈÄöÈÅé‰ΩøÁî®ÈÅ∏ÊìáÊÄßÊ∫êÊï∏ÊìöÂæÆË™øÊ®°ÂûãÔºåÊàëÂÄëÁöÑÈÅ∏ÊìáÊÄßÂæÆË™øÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÂú®ËàáÁî®ÊñºË®ìÁ∑¥ÁöÑÊï∏ÊìöÁõ∏ÊØîË°®ÁèæÂá∫È†òÂüüÂÅèÁßªÁöÑÁõÆÊ®ôÈ†òÂüü‰∏äÁöÑÊÄßËÉΩ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÔºåÂú®Êï∏ÊìöÂàÜ‰ΩàÈÄöÂ∏∏‰∏çÂèØÈ†êÊ∏¨ÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠Êèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÁ©©ÂÅ•ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇ

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫ÂàÜÂâ≤ËÇ∫ÈÉ®ÁµêÊßãÂú®Ëá®Â∫äË®∫Êñ∑„ÄÅÁñæÁóÖÁ†îÁ©∂ÂíåÊ≤ªÁôÇË®àÁï´‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂàÜÂâ≤ÊäÄË°ìÂ∑≤ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÂ§ßÂ§öÊï∏ÊäÄË°ìÂú®Ë®ìÁ∑¥ÊôÇÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôË®òË≥áÊñô„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÁ≤æÁ¢∫ÁöÑÂàÜÂâ≤ÊñπÊ≥ïÔºå‰ª•Ê∏õÂ∞ëÊ®ôË®òË≥áÊñôÈõÜÁöÑÈúÄÊ±ÇÔºåÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÈ†êË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÂü∫Á§éÊ®°ÂûãÔºà‰æãÂ¶Ç CLIPÔºâÁöÑÂá∫ÁèæÔºåÊúÄËøëÁÇ∫ÈÄöÁî®ÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãôÈñãÂïü‰∫ÜÂ§ßÈñÄ„ÄÇÂà©Áî®ÈÄô‰∫õÈ†êË®ìÁ∑¥Âü∫Á§éÊ®°ÂûãÂú®ÂàÜÂâ≤Á≠â‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂç≥‰ΩøÊ®ôË®òË≥áÊñôÈáèÁõ∏Â∞çËºÉÂ∞ëÔºå‰πüËÉΩÁî¢ÁîüÊÑèÊÉ≥‰∏çÂà∞ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊé¢Á¥¢ÈÄô‰∫õÊ®°ÂûãÂú®ËÇ∫ÂãïËÑàÈùúËÑàÂàÜÂâ≤‰∏≠ÁöÑÊáâÁî®‰ªçÁÑ∂ÊúâÈôê„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë™ûË®ÄÂºïÂ∞éËá™ÈÅ©Êáâ‰∫§ÂèâÊ≥®ÊÑèÂäõËûçÂêàÊ°ÜÊû∂ÁöÑÊñ∞Ê°ÜÊû∂„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊé°Áî®È†êË®ìÁ∑¥ÁöÑ CLIP ‰ΩúÁÇ∫Âº∑Â§ßÁöÑÁâπÂæµËêÉÂèñÂô®ÔºåÁî®ÊñºÁî¢Áîü 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁöÑÂàÜÂâ≤ÔºåÂêåÊôÇËá™ÈÅ©ÊáâÂú∞ËÅöÂêàÊñáÊú¨ÂíåÂΩ±ÂÉèË°®ÂæµÁöÑË∑®Ê®°ÊÖã„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁâπÂà•Ë®≠Ë®àÁöÑÈÅ©ÈÖçÂô®Ê®°ÁµÑÔºå‰ª•Ëá™ÈÅ©ÊáâÂ≠∏ÁøíÁ≠ñÁï•ÂæÆË™øÈ†êË®ìÁ∑¥ÁöÑ CLIPÔºå‰ª•ÊúâÊïàËûçÂêàÂÖ©Á®ÆÂµåÂÖ•Ê®°ÊÖã„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÊú¨Âú∞Ë≥áÊñôÈõÜ‰∏äÂª£Ê≥õÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÈÄôÊòØËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÂ§ßÁöÑËÇ∫ÂãïËÑàÈùúËÑàÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèË≥áÊñôÈõÜÔºåÁ∏ΩÂÖ±ÂåÖÂê´ 718 ÂÄãÊ®ôË®òË≥áÊñô„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°Âûã‰ª•Â§ßÂπÖÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤Ê®°Âûã„ÄÇÊàëÂÄëÁöÑË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÂ∞áÂú®Áç≤ÂæóÊé•ÂèóÂæåÂÖ¨Èñã„ÄÇ

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

ÊëòË¶ÅÔºöÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂà©Áî®Ë°åÂãïË£ùÁΩÆÁõ∏Ê©üÂΩ±ÂÉèË≥áÊñôÈÄ≤Ë°åÂç≥ÊôÇÁ©∫Ê∞£ÂìÅË≥™Ë©ï‰º∞ÂíåÂª∫Ë≠∞ÁöÑÂÖ®Èù¢ÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºËø¥Ê≠∏ÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºå‰∏¶ÈÄèÈÅéÂà©Áî®Ëº∏Âá∫ÂèÉÊï∏‰πãÈñìÁöÑÂÖßÂú®Èóú‰øÇÔºåÈáùÂ∞çÁ©∫Ê∞£ÂìÅË≥™È†êÊ∏¨ÈáèË∫´ÊâìÈÄ†„ÄÇÂõ†Ê≠§ÔºåÂàÜÂà•ÈáùÂ∞ç 2 Âíå 5 Á®ÆÊ±°ÊüìÁâ©ÂèñÂæóÁöÑÂπ≥ÂùáÂπ≥ÊñπË™§Â∑ÆÁÇ∫ 0.0077 Âíå 0.0112ÔºåÂÑ™ÊñºÁèæÊúâÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊó®Âú®È©óË≠âÊì¥ÂÖÖÂéüÂßãË≥áÊñôÈõÜÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÔºå‰ª•ÊúüÂú®Ë®ìÁ∑¥ÈöéÊÆµÂºïÂÖ•Êõ¥Â§öËÆäÁï∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÂéüÂßãË≥áÊñôÈõÜÂíåÊì¥ÂÖÖË≥áÊñôÈõÜ‰πãÈñìÁöÑÊ∫ñÁ¢∫Â∫¶Â∑ÆÁï∞Ê•µÂ∞èÔºåÈÄôÊòØÊàëÂÄëÊúÄÈáçË¶ÅÁöÑË≤¢Áçª‰πã‰∏Ä„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÂç≥ÊôÇ„ÄÅ‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑÂÑÄË°®ÊùøÔºåÂèØÂãïÊÖãÈ°ØÁ§∫ÂæûÊì∑ÂèñÁöÑË°åÂãïË£ùÁΩÆÁõ∏Ê©üÂΩ±ÂÉè‰∏≠Ë°çÁîüÁöÑÁ©∫Ê∞£ÂìÅË≥™ÊåáÊï∏ÂíåÊ±°ÊüìÁâ©Êï∏ÂÄº„ÄÇËÄÉÈáè‰ΩøÁî®ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂª∫Ë≠∞ÊòØÂê¶Ê†πÊìöÁõÆÂâçÁöÑÁ©∫Ê∞£ÂìÅË≥™ÊåáÊ®ôÈÅ∏ÊìáÈÅ©ÂêàÁöÑÂú∞Èªû„ÄÇÊï¥È´îËÄåË®ÄÔºåÈÄôÈ†ÖÁ†îÁ©∂ÊúâÂä©ÊñºÈ©óË≠âË≥áÊñôÊì¥ÂÖÖÊäÄË°ì„ÄÅÂü∫Êñº CNN ÁöÑËø¥Ê≠∏Ê®°ÂûãÔºàÁî®ÊñºÁ©∫Ê∞£ÂìÅË≥™È†êÊ∏¨Ôºâ‰ª•ÂèäÈÄèÈÅéË°åÂãïÊäÄË°ìÈÄ≤Ë°å‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁ©∫Ê∞£ÂìÅË≥™Áõ£Êéß„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁÇ∫ÂÄã‰∫∫Êèê‰æõÂØ¶ÈöõÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•‰æøÂÅöÂá∫ÊòéÊô∫ÁöÑÁí∞Â¢ÉÂÅ•Â∫∑ÂíåÁ¶èÁ•âÊ±∫Á≠ñ„ÄÇ

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂπ´Âä©‰∏ãÔºåÂü∫Êñº X ÂÖâÂΩ±ÂÉèÁöÑÈÜ´ÁôÇÂ†±ÂëäÁîüÊàêÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ïÔºåÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°Âûã‰∏¶Êú™ÂÖÖÂàÜÂà©Áî®Ë¶ñË¶∫ÂΩ±ÂÉèÂçÄÂüü‰∏≠ÁöÑÊúâÊïàË≥áË®äÔºåÂ∞éËá¥Â†±ÂëäÂú®Ë™ûË®Ä‰∏äÈõñÁÑ∂ÊµÅÊö¢Ôºå‰ΩÜÂú®ÊèèËø∞ÈóúÈçµÁñæÁóÖÊñπÈù¢Âçª‰∏çË∂≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËÅØÊÉ≥ÂºèË®òÊÜ∂Â¢ûÂº∑ X ÂÖâÂ†±ÂëäÁîüÊàêÊ®°ÂûãÔºåÊúâÊïàÂú∞Ê®°Êì¨Â∞àÊ•≠ÈÜ´ÁîüÊí∞ÂØ´ÈÜ´ÁôÇÂ†±ÂëäÁöÑÈÅéÁ®ã„ÄÇÂÆÉÂêåÊôÇËÄÉÊÖÆ‰∫ÜÂ∞çÂÖ®Â±ÄÂíåÂ±ÄÈÉ®Ë¶ñË¶∫Ë≥áË®äÁöÑÊåñÊéòÔºå‰∏¶ËÅØÁπ´Ê≠∑Âè≤Â†±ÂëäË≥áË®äÔºå‰ª•Êõ¥Â•ΩÂú∞ÂÆåÊàêÁï∂ÂâçÂ†±ÂëäÁöÑÊí∞ÂØ´„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÁµ¶ÂÆö‰∏ÄÂºµ X ÂÖâÂΩ±ÂÉèÔºåÊàëÂÄëÈ¶ñÂÖàÂà©Áî®ÂàÜÈ°ûÊ®°ÂûãÂèäÂÖ∂ÊøÄÊ¥ªÊò†Â∞Ñ‰æÜÂÆåÊàêËàáÁñæÁóÖÈ´òÂ∫¶Áõ∏ÈóúÁöÑË¶ñË¶∫ÂçÄÂüüÁöÑÊåñÊéòÂíåÁñæÁóÖÊü•Ë©¢‰ª§ÁâåÁöÑÂ≠∏Áøí„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°Áî®Ë¶ñË¶∫ÈúçÊôÆËè≤ÁàæÂæ∑Á∂≤Ë∑Ø‰æÜÂª∫Á´ãËàáÁñæÁóÖÁõ∏ÈóúÁöÑ‰ª§ÁâåÁöÑË®òÊÜ∂ËÅØÁπ´Ôºå‰∏¶Êé°Áî®Â†±ÂëäÈúçÊôÆËè≤ÁàæÂæ∑Á∂≤Ë∑Ø‰æÜÊ™¢Á¥¢Â†±ÂëäË®òÊÜ∂Ë≥áË®ä„ÄÇÈÄôÂÄãÈÅéÁ®ãÊúâÂä©ÊñºÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁîüÊàêÈ´òÂìÅË≥™ÁöÑÂ†±ÂëäÔºå‰∏¶Âú®ÂåÖÊã¨ IU X Â∞ÑÁ∑ö„ÄÅMIMIC-CXR Âíå Chexpert Plus Âú®ÂÖßÁöÑÂ§öÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊ≠§È†ÖÂ∑•‰ΩúÁöÑÂéüÂßãÁ¢ºÂ∑≤Áôº‰ΩàÂú®\url{https://github.com/Event-AHU/Medical_Image_Analysis}„ÄÇ

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

ÊëòË¶ÅÔºöÈö®ËëóÊ©üÂô®‰∫∫Âú®ÊàëÂÄëÊó•Â∏∏ÁîüÊ¥ª‰∏≠ÁöÑÈáçË¶ÅÊÄßÊó•ÁõäÊèêÂçáÔºåÂ∞çÊñº‰∫ÜËß£‰∫∫ÂÄëÂ¶Ç‰ΩïÊÑüÁü•Ê©üÂô®‰∫∫ÁöÑÈúÄÊ±Ç‰πüÊó•ÁõäÂ¢ûÂä†„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÊ©üÂô®‰∫∫ÁöÑ‰ΩøÁî®ËÄÖÊÑüÁü•Â¶Ç‰ΩïÂèóÂà∞‰∫∫Ê†ºË°®ÁèæÁöÑÂΩ±Èüø„ÄÇÊàëÂÄë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåË™ûÈü≥ËΩâÊñáÂ≠óÊäÄË°ìÔºåË®≠Ë®à‰∫Ü‰∏ÄÈ†ÖÂèóË©¶ËÄÖÂÖßÁ†îÁ©∂Ôºå‰ª•ÊØîËºÉÂÖ©Á®ÆÊÉÖÊ≥ÅÔºö‰∏ÄÁ®ÆÊòØ‰∫∫Ê†ºÈ©ÖÂãïÁöÑÊ©üÂô®‰∫∫ÔºåÂè¶‰∏ÄÁ®ÆÊòØÁ¥îÁ≤π‰ª•‰ªªÂãôÁÇ∫Â∞éÂêë„ÄÅ‰∫∫Ê†º‰∏≠Á´ãÁöÑÊ©üÂô®‰∫∫„ÄÇÊàëÂÄëÂæûÈòøÂßÜÊñØÁâπ‰∏πËá™Áî±Â§ßÂ≠∏ÁöÑÁ§æ‰∫§Êô∫ËÉΩÊ©üÂô®‰∫∫Ë™≤Á®ã‰∏≠ÊãõÂãü‰∫Ü 12 ÂêçÂèÉËàáËÄÖÔºå‰ªñÂÄëËàáÊ©üÂô®‰∫∫ Nao ‰∫íÂãïÔºåÂú®ÂÖ©Á®ÆÊÉÖÊ≥Å‰∏ãÈÉΩÂêë‰ªñÂÄëË©¢Âïè‰∏ÄÁ≥ªÂàóÈÜ´ÁôÇÂïèÈ°å„ÄÇÂú®ÂÆåÊàêÈÄôÂÖ©Á®Æ‰∫íÂãïÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏Ä‰ªΩ‰ΩøÁî®ËÄÖÈ´îÈ©óÂïèÂç∑Ôºå‰ΩøÁî®‰æÜËá™ SRI ÂíåÂøÉÁêÜÂ≠∏ÊñáÁçªÁöÑÊ®ôÊ∫ñÂåñÂïèÂç∑Ê∏¨Èáè‰ªñÂÄëÁöÑÊÉÖÁ∑íÁãÄÊÖãÂíåÊ©üÂô®‰∫∫ÊÑüÁü•„ÄÇ

##### **Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology**
2501.02922v1 by Susu Sun, Leslie Tessier, Fr√©d√©rique Meeuwsen, Cl√©ment Grisi, Dominique van Midden, Geert Litjens, Christian F. Baumgartner

Multiple Instance Learning (MIL) methods allow for gigapixel Whole-Slide
Image (WSI) analysis with only slide-level annotations. Interpretability is
crucial for safely deploying such algorithms in high-stakes medical domains.
Traditional MIL methods offer explanations by highlighting salient regions.
However, such spatial heatmaps provide limited insights for end users. To
address this, we propose a novel inherently interpretable WSI-classification
approach that uses human-understandable pathology concepts to generate
explanations. Our proposed Concept MIL model leverages recent advances in
vision-language models to directly predict pathology concepts based on image
features. The model's predictions are obtained through a linear combination of
the concepts identified on the top-K patches of a WSI, enabling inherent
explanations by tracing each concept's influence on the prediction. In contrast
to traditional concept-based interpretable models, our approach eliminates the
need for costly human annotations by leveraging the vision-language model. We
validate our method on two widely used pathology datasets: Camelyon16 and
PANDA. On both datasets, Concept MIL achieves AUC and accuracy scores over 0.9,
putting it on par with state-of-the-art models. We further find that 87.1\%
(Camelyon16) and 85.3\% (PANDA) of the top 20 patches fall within the tumor
region. A user study shows that the concepts identified by our model align with
the concepts used by pathologists, making it a promising strategy for
human-interpretable WSI classification.

ÊëòË¶ÅÔºöÂ§öÂØ¶‰æãÂ≠∏Áøí (MIL) ÊñπÊ≥ïÂÉÖ‰ΩøÁî®ÁéªÁâáÂ±§Á¥öË®ªËß£ÔºåÂç≥ÂèØÈÄ≤Ë°åÂêâÂÉèÁ¥†ÂÖ®ÁéªÁâáÂΩ±ÂÉè (WSI) ÂàÜÊûê„ÄÇÂèØËß£ÈáãÊÄßÂ∞çÊñºÂú®È´òÈ¢®Èö™ÈÜ´ÁôÇÈ†òÂüüÂÆâÂÖ®ÈÉ®ÁΩ≤Ê≠§È°ûÊºîÁÆóÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑ MIL ÊñπÊ≥ïÈÄèÈÅéÂº∑Ë™øÈ°ØËëóÂçÄÂüü‰æÜÊèê‰æõË™™Êòé„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÁ©∫ÈñìÁÜ±ÂúñÁÇ∫ÊúÄÁµÇ‰ΩøÁî®ËÄÖÊèê‰æõÁöÑË¶ãËß£ÊúâÈôê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊú¨Ë≥™‰∏äÂèØËß£ÈáãÁöÑ WSI ÂàÜÈ°ûÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®‰∫∫È°ûÂèØÁêÜËß£ÁöÑÁóÖÁêÜÊ¶ÇÂøµ‰æÜÁî¢ÁîüË™™Êòé„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ¶ÇÂøµ MIL Ê®°ÂûãÂà©Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÊ†πÊìöÂΩ±ÂÉèÁâπÂæµÁõ¥Êé•È†êÊ∏¨ÁóÖÁêÜÊ¶ÇÂøµ„ÄÇË©≤Ê®°ÂûãÁöÑÈ†êÊ∏¨ÊòØÈÄèÈÅéÁ∑öÊÄßÁµÑÂêà WSI È†ÇÈÉ® K ÂÄãÂçÄÂ°ä‰∏äË≠òÂà•ÁöÑÊ¶ÇÂøµËÄåÁç≤ÂæóÁöÑÔºåÈÄèÈÅéËøΩËπ§ÊØèÂÄãÊ¶ÇÂøµÂ∞çÈ†êÊ∏¨ÁöÑÂΩ±ÈüøÔºåÂèØ‰ª•Êèê‰æõÂÖßÂú®Ë™™Êòé„ÄÇËàáÂÇ≥Áµ±Âü∫ÊñºÊ¶ÇÂøµÁöÑÂèØËß£ÈáãÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéÂà©Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºåÊ∂àÈô§‰∫ÜÂ∞çÊòÇË≤¥ÁöÑ‰∫∫Â∑•Ë®ªËß£ÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÁóÖÁêÜË≥áÊñôÈõÜÔºöCamelyon16 Âíå PANDA ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÂú®ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÔºåÊ¶ÇÂøµ MIL ÁöÑ AUC ÂíåÊ∫ñÁ¢∫ÁéáÈÉΩË∂ÖÈÅé 0.9ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁôºÁèæÔºåÂâç 20 ÂÄãÂçÄÂ°ä‰∏≠Êúâ 87.1%ÔºàCamelyon16ÔºâÂíå 85.3%ÔºàPANDAÔºâËêΩÂú®ËÖ´Áò§ÂçÄÂüüÂÖß„ÄÇ‰∏ÄÈ†Ö‰ΩøÁî®ËÄÖÁ†îÁ©∂Ë°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãË≠òÂà•ÁöÑÊ¶ÇÂøµËàáÁóÖÁêÜÂ≠∏ÂÆ∂‰ΩøÁî®ÁöÑÊ¶ÇÂøµ‰∏ÄËá¥Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫‰∫∫È°ûÂèØËß£Èáã WSI ÂàÜÈ°ûÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÁ≠ñÁï•„ÄÇ

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

ÊëòË¶ÅÔºöÂπΩÈªòÈ¢®Ê†ºÂ∞çÂπ∏Á¶èÊÑüÂèØËÉΩÁî¢ÁîüË≤†Èù¢ÊàñÊ≠£Èù¢ÁöÑÂΩ±Èüø„ÄÇ
ÈëëÊñºÈÄô‰∫õÈ¢®Ê†ºÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÁöÑÈáçË¶ÅÊÄßÔºåÂ∑≤Á∂ìÂ∞çÂÖ∂Ëá™ÂãïË≠òÂà•ÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁî®ÊñºÊ≠§ÁõÆÁöÑÁöÑËá™ÂãïÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÊòØÈªëÁõíÂ≠êÔºå‰ΩøÂæóÂÖ∂È†êÊ∏¨Ê±∫Á≠ñ‰∏çÈÄèÊòé„ÄÇÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶Âú®ÂøÉÁêÜÂÅ•Â∫∑È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑ AI (XAI) Ê°ÜÊû∂ÔºåÁî®ÊñºÁêÜËß£ÂπΩÈªòÈ¢®Ê†ºÂàÜÈ°ûÔºåÂª∫Á´ãÂú®Ë®àÁÆóÂπΩÈªòÂàÜÊûêÁöÑÂÖàÂâçÂ∑•‰Ωú‰πã‰∏ä„ÄÇ‰ΩøÁî®ÂÖàÂâçÁ†îÁ©∂‰∏≠Ë°®ÁèæÊúÄÂ•ΩÁöÑÂñÆ‰∏ÄÊ®°Âûã (ALI+XGBoost)ÔºåÊàëÂÄëÊáâÁî®ÂÖ®Èù¢ÁöÑ XAI ÊäÄË°ì‰æÜÂàÜÊûêË™ûË®Ä„ÄÅÊÉÖÁ∑íÂíåË™ûÁæ©ÁâπÂæµÂ¶Ç‰ΩïÂΩ±ÈüøÂπΩÈªòÈ¢®Ê†ºÂàÜÈ°ûÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫Ü‰∏çÂêåÂπΩÈªòÈ¢®Ê†ºÂ¶Ç‰ΩïË¢´Ë°®ÂæµÂíåÈåØË™§ÂàÜÈ°ûÁöÑ‰∏çÂêåÊ®°ÂºèÔºåÁâπÂà•Âº∑Ë™ø‰∫ÜÂçÄÂàÜËÅØÂ±¨ÂπΩÈªòËàáÂÖ∂‰ªñÈ¢®Ê†ºÁöÑÊåëÊà∞„ÄÇÈÄöÈÅé‰ªîÁ¥∞Ê™¢Êü•ÁâπÂæµÈáçË¶ÅÊÄß„ÄÅÈåØË™§Ê®°ÂºèÂíåÈåØË™§ÂàÜÈ°ûÊ°à‰æãÔºåÊàëÂÄëÁ¢∫ÂÆö‰∫ÜÂΩ±ÈüøÊ®°ÂûãÊ±∫Á≠ñÁöÑÈóúÈçµÂõ†Á¥†ÔºåÂåÖÊã¨ÊÉÖÁ∑íÊ®°Á≥ä„ÄÅÊÉÖÂ¢ÉË™§Ëß£ÂíåÁõÆÊ®ôË≠òÂà•„ÄÇË©≤Ê°ÜÊû∂Â±ïÁ§∫‰∫ÜÂú®ÁêÜËß£Ê®°ÂûãË°åÁÇ∫ÊñπÈù¢ÁöÑÈ°ØËëóÊïàÁî®ÔºåÂØ¶Áèæ‰∫ÜÂ∞çÂÆöÁæ©‰∏çÂêåÂπΩÈªòÈ¢®Ê†ºÁöÑÁâπÂæµ‰πãÈñìË§áÈõúÁõ∏‰∫í‰ΩúÁî®ÁöÑÂèØËß£ÈáãË¶ãËß£„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊúâÂä©ÊñºË®àÁÆóÂπΩÈªòÂàÜÊûêÁöÑÁêÜË´ñÁêÜËß£ÂíåÂøÉÁêÜÂÅ•Â∫∑„ÄÅÂÖßÂÆπÂØ©Ê†∏ÂíåÊï∏Â≠ó‰∫∫ÊñáÁ†îÁ©∂‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇ

##### **IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks by Efficient Human Preference Alignment**
2501.02869v1 by Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding

Recent researches of large language models(LLM), which is pre-trained on
massive general-purpose corpora, have achieved breakthroughs in responding
human queries. However, these methods face challenges including limited data
insufficiency to support extensive pre-training and can not align responses
with users' instructions. To address these issues, we introduce a medical
instruction dataset, CMedINS, containing six medical instructions derived from
actual medical tasks, which effectively fine-tunes LLM in conjunction with
other data. Subsequently, We launch our medical model, IIMedGPT, employing an
efficient preference alignment method, Direct preference Optimization(DPO). The
results show that our final model outperforms existing medical models in
medical dialogue.Datsets, Code and model checkpoints will be released upon
acceptance.

ÊëòË¶ÅÔºöÊúÄËøëÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁ†îÁ©∂ÔºåË©≤Ê®°ÂûãÈ†êÂÖàË®ìÁ∑¥ÊñºÈæêÂ§ßÁöÑÈÄöÁî®Ë™ûÊñôÂ∫´‰∏≠ÔºåÂ∑≤Âú®ÂõûÊáâ‰∫∫È°ûÊü•Ë©¢ÊñπÈù¢ÂèñÂæóÁ™ÅÁ†¥„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈù¢Ëá®ÁöÑÊåëÊà∞ÂåÖÊã¨Ë≥áÊñô‰∏çË∂≥‰ª•ÊîØÊè¥Âª£Ê≥õÁöÑÈ†êË®ìÁ∑¥Ôºå‰∏îÁÑ°Ê≥ïÂ∞áÂõûÊáâËàá‰ΩøÁî®ËÄÖÁöÑÊåáÁ§∫‰øùÊåÅ‰∏ÄËá¥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÈÜ´ÁôÇÊåáÁ§∫Ë≥áÊñôÈõÜ CMedINSÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ≠È†ÖÂæûÂØ¶ÈöõÈÜ´ÁôÇ‰ªªÂãô‰∏≠Ë°çÁîüÁöÑÈÜ´ÁôÇÊåáÁ§∫ÔºåËàáÂÖ∂‰ªñË≥áÊñôÁµêÂêàÂæåËÉΩÊúâÊïàÂæÆË™ø LLM„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊé®Âá∫ÊàëÂÄëÁöÑÈÜ´ÁôÇÊ®°Âûã IIMedGPTÔºåÊé°Áî®‰∏ÄÁ®ÆÊúâÊïàÁéáÁöÑÂÅèÂ•ΩÂ∞çÈΩäÊñπÊ≥ïÔºåÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊúÄÁµÇÊ®°ÂûãÂú®ÈÜ´ÁôÇÂ∞çË©±‰∏≠ÂÑ™ÊñºÁèæÊúâÁöÑÈÜ´ÁôÇÊ®°Âûã„ÄÇË≥áÊñôÈõÜ„ÄÅÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÊ™¢Êü•ÈªûÂ∞áÂú®ÈÄöÈÅéÈ©óË≠âÂæåÈáãÂá∫„ÄÇ

##### **Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model**
2501.03292v1 by Naibo Wang, Yuchen Deng, Shichen Fan, Jianwei Yin, See-Kiong Ng

Federated learning (FL) has attracted considerable interest in the medical
domain due to its capacity to facilitate collaborative model training while
maintaining data privacy. However, conventional FL methods typically
necessitate multiple communication rounds, leading to significant communication
overhead and delays, especially in environments with limited bandwidth.
One-shot federated learning addresses these issues by conducting model training
and aggregation in a single communication round, thereby reducing communication
costs while preserving privacy. Among these, one-shot federated ensemble
learning combines independently trained client models using ensemble techniques
such as voting, further boosting performance in non-IID data scenarios. On the
other hand, existing machine learning methods in healthcare predominantly use
unimodal data (e.g., medical images or textual reports), which restricts their
diagnostic accuracy and comprehensiveness. Therefore, the integration of
multi-modal data is proposed to address these shortcomings. In this paper, we
introduce FedMME, an innovative one-shot multi-modal federated ensemble
learning framework that utilizes multi-modal data for medical image analysis.
Specifically, FedMME capitalizes on vision large language models to produce
textual reports from medical images, employs a BERT model to extract textual
features from these reports, and amalgamates these features with visual
features to improve diagnostic accuracy. Experimental results show that our
method demonstrated superior performance compared to existing one-shot
federated learning methods in healthcare scenarios across four datasets with
various data distributions. For instance, it surpasses existing one-shot
federated learning approaches by more than 17.5% in accuracy on the RSNA
dataset when applying a Dirichlet distribution with ($\alpha$ = 0.3).

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π† (FL) Áî±‰∫éÂÖ∂Âú®Áª¥Êä§Êï∞ÊçÆÈöêÁßÅÁöÑÂêåÊó∂‰øÉËøõÂçè‰ΩúÊ®°ÂûãËÆ≠ÁªÉÁöÑËÉΩÂäõÔºåÂú®ÂåªÂ≠¶È¢ÜÂüüÂºïËµ∑‰∫ÜÊûÅÂ§ßÁöÑÂÖ¥Ë∂£„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüÁöÑ FL ÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§öËΩÆÈÄö‰ø°ÔºåËøô‰ºöÂØºËá¥‰∏•ÈáçÁöÑÈÄö‰ø°ÂºÄÈîÄÂíåÂª∂ËøüÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∏¶ÂÆΩÂèóÈôêÁöÑÁéØÂ¢É‰∏≠„ÄÇÂçïÊ¨°ËÅîÈÇ¶Â≠¶‰π†ÈÄöËøáÂú®ÂçïÊ¨°ÈÄö‰ø°ËΩÆ‰∏≠ËøõË°åÊ®°ÂûãËÆ≠ÁªÉÂíåËÅöÂêàÊù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºå‰ªéËÄåÂú®‰øùÊä§ÈöêÁßÅÁöÑÂêåÊó∂Èôç‰ΩéÈÄö‰ø°ÊàêÊú¨„ÄÇÂÖ∂‰∏≠ÔºåÂçïÊ¨°ËÅîÈÇ¶ÈõÜÊàêÂ≠¶‰π†‰ΩøÁî®ÈõÜÊàêÊäÄÊúØÔºàÂ¶ÇÊäïÁ•®ÔºâÂ∞ÜÁã¨Á´ãËÆ≠ÁªÉÁöÑÂÆ¢Êà∑Á´ØÊ®°ÂûãÁªÑÂêàËµ∑Êù•ÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂú®Èùû IID Êï∞ÊçÆÂú∫ÊôØ‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÁé∞ÊúâÁöÑÂåªÁñó‰øùÂÅ•Êú∫Âô®Â≠¶‰π†ÊñπÊ≥ï‰∏ªË¶Å‰ΩøÁî®ÂçïÊ®°ÊÄÅÊï∞ÊçÆÔºà‰æãÂ¶ÇÂåªÂ≠¶ÂõæÂÉèÊàñÊñáÊú¨Êä•ÂëäÔºâÔºåËøôÈôêÂà∂‰∫ÜÂÆÉ‰ª¨ÁöÑËØäÊñ≠ÂáÜÁ°ÆÊÄßÂíåÂÖ®Èù¢ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑÈõÜÊàêÊù•Ëß£ÂÜ≥Ëøô‰∫õÁº∫ÁÇπ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü FedMMEÔºå‰∏ÄÁßçÂàõÊñ∞ÁöÑÂçïÊ¨°Â§öÊ®°ÊÄÅËÅîÈÇ¶ÈõÜÊàêÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§öÊ®°ÊÄÅÊï∞ÊçÆËøõË°åÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåFedMME Âà©Áî®ËßÜËßâÂ§ßËØ≠Ë®ÄÊ®°Âûã‰ªéÂåªÂ≠¶ÂõæÂÉè‰∏≠ÁîüÊàêÊñáÊú¨Êä•ÂëäÔºåÈááÁî® BERT Ê®°Âûã‰ªéËøô‰∫õÊä•Âëä‰∏≠ÊèêÂèñÊñáÊú¨ÁâπÂæÅÔºåÂπ∂Â∞ÜËøô‰∫õÁâπÂæÅ‰∏éËßÜËßâÁâπÂæÅÁõ∏ÁªìÂêà‰ª•ÊèêÈ´òËØäÊñ≠ÂáÜÁ°ÆÊÄß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏éÁé∞ÊúâÁöÑÂçïÊ¨°ËÅîÈÇ¶Â≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Âõõ‰∏™ÂÖ∑Êúâ‰∏çÂêåÊï∞ÊçÆÂàÜÂ∏ÉÁöÑÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÂåªÁñó‰øùÂÅ•Âú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂΩìÂ∫îÁî®ÂÖ∑Êúâ ($\alpha$ = 0.3) ÁöÑ Dirichlet ÂàÜÂ∏ÉÊó∂ÔºåÂÆÉÂú® RSNA Êï∞ÊçÆÈõÜ‰∏äÁöÑÂáÜÁ°ÆÁéáÊØîÁé∞ÊúâÁöÑÂçïÊ¨°ËÅîÈÇ¶Â≠¶‰π†ÊñπÊ≥ïÈ´òÂá∫ 17.5% ‰ª•‰∏ä„ÄÇ

##### **GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation**
2501.02788v2 by Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi

Vision Transformers (ViTs) have shown promise in medical image semantic
segmentation (MISS) by capturing long-range correlations. However, ViTs often
struggle to model local spatial information effectively, which is essential for
accurately segmenting fine anatomical details, particularly when applied to
small datasets without extensive pre-training. We introduce Gabor and Laplacian
of Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architecture
enhancing Transformer-based models by incorporating learnable radiomic
features. This approach integrates dynamically adaptive Gabor and Laplacian of
Gaussian (LoG) filters to capture texture, edge, and boundary information,
enhancing the feature representation processed by the Transformer model. Our
method uniquely combines the long-range dependency modeling of Transformers
with the texture analysis capabilities of Gabor and LoG features. Evaluated on
the Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnet
demonstrates significant improvements over state-of-the-art models, achieving a
1.14% increase in Dice score for Synapse and 0.99% for ACDC, with minimal
computational overhead (only 15 and 30 additional parameters, respectively).
GLoG-CSUnet's flexible design allows integration with various base models,
offering a promising approach for incorporating radiomics-inspired feature
extraction in Transformer architectures for medical image analysis. The code
implementation is available on GitHub at: https://github.com/HAAIL/GLoG-CSUnet.

ÊëòË¶ÅÔºö<paragraph>Ë¶ñË¶∫ËΩâÊèõÂô® (ViT) Â∑≤Âú®ÈÜ´ÁôÇÂΩ±ÂÉèË™ûÊÑèÂàÜÂâ≤ (MISS) ‰∏≠Â±ïÁèæÂâçÊôØÔºåËóâÁî±Êì∑ÂèñÈï∑Á®ãÈóúËÅØÊÄß„ÄÇÁÑ∂ËÄåÔºåViT Á∂ìÂ∏∏Èõ£‰ª•ÊúâÊïàÂú∞Âª∫Ê®°Â±ÄÈÉ®Á©∫ÈñìË≥áË®äÔºåÈÄôÂ∞çÊñºÁ≤æÁ¢∫ÂàÜÂâ≤Á≤æÁ¥∞Ëß£ÂâñÁ¥∞ÁØÄËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÊáâÁî®ÊñºÊ≤íÊúâÂª£Ê≥õÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ∞èÂûãË≥áÊñôÈõÜÊôÇ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÈ´òÊñØÂç∑Á©ç Swin Á∂≤Ë∑Ø (GLoG-CSUnet) ÁöÑ Gabor Âíå LaplacianÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÈÄèÈÅéÊï¥ÂêàÂèØÂ≠∏ÁøíÁöÑÊîæÂ∞ÑÁâπÂæµ‰æÜÂ¢ûÂº∑Âü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°Âûã„ÄÇÊ≠§ÊñπÊ≥ïÊï¥Âêà‰∫ÜÂãïÊÖãËá™ÈÅ©Êáâ Gabor ÂíåÈ´òÊñØ Laplacian (LoG) ÊøæÊ≥¢Âô®‰æÜÊì∑ÂèñÁ¥ãÁêÜ„ÄÅÈÇäÁ∑£ÂíåÈÇäÁïåË≥áË®äÔºåÂ¢ûÂº∑ËΩâÊèõÂô®Ê®°ÂûãËôïÁêÜÁöÑÁâπÂæµË°®Á§∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÁç®ÁâπÂú∞ÁµêÂêà‰∫ÜËΩâÊèõÂô®ÁöÑÈï∑Á®ã‰æùË≥¥ÊÄßÂª∫Ê®°Ëàá Gabor Âíå LoG ÁâπÂæµÁöÑÁ¥ãÁêÜÂàÜÊûêÂäüËÉΩ„ÄÇÂú® Synapse Â§öÂô®ÂÆòÂíå ACDC ÂøÉËáüÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåGLoG-CSUnet Â±ïÁ§∫Âá∫ÊØîÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÊúâÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåSynapse ÁöÑ Dice ÂàÜÊï∏Â¢ûÂä†‰∫Ü 1.14%ÔºåACDC ÁöÑ Dice ÂàÜÊï∏Â¢ûÂä†‰∫Ü 0.99%ÔºåË®àÁÆóË≤†ÊìîÊ•µÂ∞èÔºàÂàÜÂà•Âè™Êúâ 15 Âíå 30 ÂÄãÈ°çÂ§ñÁöÑÂèÉÊï∏Ôºâ„ÄÇGLoG-CSUnet ÁöÑÂΩàÊÄßË®≠Ë®àÂÖÅË®±ËàáÂêÑÁ®ÆÂü∫Á§éÊ®°ÂûãÊï¥ÂêàÔºåÁÇ∫Âú®ËΩâÊèõÂô®Êû∂Êßã‰∏≠Êï¥ÂêàÊîæÂ∞ÑÁµÑÂ≠∏ÂïüÁôºÁöÑÁâπÂæµËêÉÂèñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûê„ÄÇÁ®ãÂºèÁ¢ºÂØ¶‰ΩúÂèØÂú® GitHub ‰∏äÂèñÂæóÔºöhttps://github.com/HAAIL/GLoG-CSUnet„ÄÇ</paragraph>

##### **Hybrid deep convolution model for lung cancer detection with transfer learning**
2501.02785v1 by Sugandha Saxena, S. N. Prasad, Ashwin M Polnaya, Shweta Agarwala

Advances in healthcare research have significantly enhanced our understanding
of disease mechanisms, diagnostic precision, and therapeutic options. Yet, lung
cancer remains one of the leading causes of cancer-related mortality worldwide
due to challenges in early and accurate diagnosis. While current lung cancer
detection models show promise, there is considerable potential for further
improving the accuracy for timely intervention. To address this challenge, we
introduce a hybrid deep convolution model leveraging transfer learning, named
the Maximum Sensitivity Neural Network (MSNN). MSNN is designed to improve the
precision of lung cancer detection by refining sensitivity and specificity.
This model has surpassed existing deep learning approaches through experimental
validation, achieving an accuracy of 98% and a sensitivity of 97%. By
overlaying sensitivity maps onto lung Computed Tomography (CT) scans, it
enables the visualization of regions most indicative of malignant or benign
classifications. This innovative method demonstrates exceptional performance in
distinguishing lung cancer with minimal false positives, thereby enhancing the
accuracy of medical diagnoses.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂ÁöÑÈÄ≤Ê≠•È°ØËëóÂ¢ûÈÄ≤‰∫ÜÊàëÂÄëÂ∞çÁñæÁóÖÊ©üÂà∂„ÄÅË®∫Êñ∑Á≤æÊ∫ñÂ∫¶ÂíåÊ≤ªÁôÇÈÅ∏ÊìáÁöÑ‰∫ÜËß£„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊó©ÊúüÂíåÊ∫ñÁ¢∫Ë®∫Êñ∑ÁöÑÊåëÊà∞ÔºåËÇ∫Áôå‰ªçÁÑ∂ÊòØÂÖ®ÁêÉÁôåÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁöÑ‰∏ªË¶ÅÂéüÂõ†‰πã‰∏Ä„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑËÇ∫ÁôåÊ™¢Ê∏¨Ê®°ÂûãÈ°ØÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜ‰ªçÊúâÁõ∏Áï∂Â§ßÁöÑÊΩõÂäõÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊ∫ñÁ¢∫ÊÄßÔºå‰ª•‰æøÂèäÊôÇ‰ªãÂÖ•„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂà©Áî®ÈÅ∑ÁßªÂ≠∏ÁøíÁöÑÊ∑∑ÂêàÊ∑±Â∫¶Âç∑Á©çÊ®°ÂûãÔºåÂêçÁÇ∫ÊúÄÂ§ßÊïèÊÑüÂ∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (MSNN)„ÄÇMSNN Êó®Âú®ÈÄèÈÅéË™øÊï¥ÊïèÊÑüÂ∫¶ÂíåÁâπÁï∞ÊÄß‰æÜÊèêÈ´òËÇ∫ÁôåÊ™¢Ê∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Ê®°ÂûãÂ∑≤ÈÄèÈÅéÂØ¶È©óÈ©óË≠âË∂ÖË∂äÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÈÅîÂà∞ 98% ÁöÑÊ∫ñÁ¢∫Â∫¶Âíå 97% ÁöÑÊïèÊÑüÂ∫¶„ÄÇÈÄèÈÅéÂ∞áÊïèÊÑüÂ∫¶ÂúñÁñäÂä†Âà∞ËÇ∫ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) ‰∏äÔºåÂÆÉÂèØ‰ª•Ë¶ñË¶∫ÂåñÂá∫ÊúÄËÉΩ‰ª£Ë°®ÊÉ°ÊÄßÊàñËâØÊÄßÂàÜÈ°ûÁöÑÂçÄÂüü„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÂú®ÂçÄÂàÜËÇ∫ÁôåÊôÇË°®ÁèæÂá∫Ê•µ‰Ω≥ÁöÑÊïàËÉΩÔºå‰∏îË™§Âà§ÁÇ∫ÈôΩÊÄßÁöÑÊÉÖÊ≥ÅÊúÄÂ∞ëÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÈÜ´ÁôÇË®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇ

##### **ICFNet: Integrated Cross-modal Fusion Network for Survival Prediction**
2501.02778v1 by Binyu Zhang, Zhu Meng, Junhao Dong, Fei Su, Zhicheng Zhao

Survival prediction is a crucial task in the medical field and is essential
for optimizing treatment options and resource allocation. However, current
methods often rely on limited data modalities, resulting in suboptimal
performance. In this paper, we propose an Integrated Cross-modal Fusion Network
(ICFNet) that integrates histopathology whole slide images, genomic expression
profiles, patient demographics, and treatment protocols. Specifically, three
types of encoders, a residual orthogonal decomposition module and a unification
fusion module are employed to merge multi-modal features to enhance prediction
accuracy. Additionally, a balanced negative log-likelihood loss function is
designed to ensure fair training across different patients. Extensive
experiments demonstrate that our ICFNet outperforms state-of-the-art algorithms
on five public TCGA datasets, including BLCA, BRCA, GBMLGG, LUAD, and UCEC, and
shows its potential to support clinical decision-making and advance precision
medicine. The codes are available at: https://github.com/binging512/ICFNet.

ÊëòË¶ÅÔºöÂ≠òÊ¥ªÈ†êÊ∏¨ÊòØÈÜ´Â≠∏È†òÂüüÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãôÔºåÂ∞çÊñºÂÑ™ÂåñÊ≤ªÁôÇÈÅ∏È†ÖÂíåË≥áÊ∫êÂàÜÈÖçËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊäÄË°ìÈÄöÂ∏∏‰ª∞Ë≥¥ÊúâÈôêÁöÑÊï∏ÊìöÂΩ¢ÂºèÔºåÂ∞éËá¥Ê¨°‰Ω≥ÁöÑË°®Áèæ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÂºèË∑®ÂΩ¢ÂºèËûçÂêàÁ∂≤Ë∑Ø (ICFNet)ÔºåÂÆÉÊï¥Âêà‰∫ÜÁµÑÁπîÁóÖÁêÜÂ≠∏ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè„ÄÅÂü∫Âõ†È´îË°®ÁèæÁâπÂæµ„ÄÅÁóÖÊÇ£‰∫∫Âè£Áµ±Ë®àË≥áÊñôÂíåÊ≤ªÁôÇÂçîÂÆö„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰ΩøÁî®‰∏âÁ®ÆÈ°ûÂûãÁöÑÁ∑®Á¢ºÂô®„ÄÅ‰∏ÄÂÄãÊÆòÂ∑ÆÊ≠£‰∫§ÂàÜËß£Ê®°ÁµÑÂíå‰∏ÄÂÄãÁµ±‰∏ÄËûçÂêàÊ®°ÁµÑÔºå‰ª•Âêà‰ΩµÂ§öÂΩ¢ÂºèÁâπÂæµÔºå‰ª•Â¢ûÂº∑È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂπ≥Ë°°ÁöÑË≤†Â∞çÊï∏‰ººÁÑ∂ÊêçÂ§±ÂáΩÊï∏Ôºå‰ª•Á¢∫‰øù‰∏çÂêåÁóÖÊÇ£‰πãÈñìÁöÑÂÖ¨Âπ≥Ë®ìÁ∑¥„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑ ICFNet Âú®‰∫îÂÄãÂÖ¨ÈñãÁöÑ TCGA Ë≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÔºåÂåÖÊã¨ BLCA„ÄÅBRCA„ÄÅGBMLGG„ÄÅLUAD Âíå UCECÔºå‰∏¶Â±ïÁ§∫ÂÖ∂ÊîØÊè¥Ëá®Â∫äÊ±∫Á≠ñÂíåÊé®ÂãïÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/binging512/ICFNet„ÄÇ

##### **Tree-based RAG-Agent Recommendation System: A Case Study in Medical Test Data**
2501.02727v1 by Yahe Yang, Chengyue Huang

We present HiRMed (Hierarchical RAG-enhanced Medical Test Recommendation), a
novel tree-structured recommendation system that leverages Retrieval-Augmented
Generation (RAG) for intelligent medical test recommendations. Unlike
traditional vector similarity-based approaches, our system performs medical
reasoning at each tree node through a specialized RAG process. Starting from
the root node with initial symptoms, the system conducts step-wise medical
analysis to identify potential underlying conditions and their corresponding
diagnostic requirements. At each level, instead of simple matching, our
RAG-enhanced nodes analyze retrieved medical knowledge to understand
symptom-disease relationships and determine the most appropriate diagnostic
path. The system dynamically adjusts its recommendation strategy based on
medical reasoning results, considering factors such as urgency levels and
diagnostic uncertainty. Experimental results demonstrate that our approach
achieves superior performance in terms of coverage rate, accuracy, and miss
rate compared to conventional retrieval-based methods. This work represents a
significant advance in medical test recommendation by introducing medical
reasoning capabilities into the traditional tree-based retrieval structure.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ HiRMedÔºàÂàÜÂ±§ RAG Â¢ûÂº∑ÂûãÈÜ´ÁôÇÊ™¢Ê∏¨Âª∫Ë≠∞ÔºâÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ®πÁãÄÁµêÊßãÂª∫Ë≠∞Á≥ªÁµ±ÔºåÂÆÉÂà©Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ‰æÜÈÄ≤Ë°åÊô∫ËÉΩÈÜ´ÁôÇÊ™¢Ê∏¨Âª∫Ë≠∞„ÄÇËàáÂÇ≥Áµ±ÁöÑÂü∫ÊñºÂêëÈáèÁõ∏‰ººÊÄßÁöÑÊñπÊ≥ï‰∏çÂêåÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÈÄöÈÅé‰∏ÄÂÄãÂ∞àÈñÄÁöÑ RAG Á®ãÂ∫èÂú®ÊØèÂÄãÊ®πÁØÄÈªûÂü∑Ë°åÈÜ´ÁôÇÊé®ÁêÜ„ÄÇÂæûÂÖ∑ÊúâÂàùÂßãÁóáÁãÄÁöÑÊ†πÁØÄÈªûÈñãÂßãÔºåÁ≥ªÁµ±Âü∑Ë°åÈÄêÊ≠•ÈÜ´ÁôÇÂàÜÊûê‰ª•Ë≠òÂà•ÊΩõÂú®ÁöÑÊΩõÂú®ÁñæÁóÖÂèäÂÖ∂Â∞çÊáâÁöÑË®∫Êñ∑Ë¶ÅÊ±Ç„ÄÇÂú®ÊØèÂÄãÂ±§Á¥öÔºåÊàëÂÄëÁöÑ RAG Â¢ûÂº∑ÁØÄÈªûÊúÉÂàÜÊûêÊ™¢Á¥¢Âà∞ÁöÑÈÜ´ÁôÇÁü•Ë≠òÔºå‰ª•‰∫ÜËß£ÁóáÁãÄËàáÁñæÁóÖÁöÑÈóú‰øÇÔºå‰∏¶Á¢∫ÂÆöÊúÄÂêàÈÅ©ÁöÑË®∫Êñ∑Ë∑ØÂæëÔºåËÄå‰∏çÊòØÈÄ≤Ë°åÁ∞°ÂñÆÁöÑÂåπÈÖç„ÄÇÁ≥ªÁµ±Ê†πÊìöÈÜ´ÁôÇÊé®ÁêÜÁµêÊûúÂãïÊÖãË™øÊï¥ÂÖ∂Âª∫Ë≠∞Á≠ñÁï•ÔºåËÄÉÊÖÆÁ∑äÊÄ•Á®ãÂ∫¶ÂíåË®∫Êñ∑‰∏çÁ¢∫ÂÆöÊÄßÁ≠âÂõ†Á¥†„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ™¢Á¥¢ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Ë¶ÜËìãÁéá„ÄÅÊ∫ñÁ¢∫ÊÄßÂíåÈÅ∫ÊºèÁéáÊñπÈù¢ÂèñÂæó‰∫ÜÂÑ™Áï∞ÁöÑË°®Áèæ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈÄöÈÅéÂ∞áÈÜ´ÁôÇÊé®ÁêÜËÉΩÂäõÂºïÂÖ•ÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ®πÁöÑÊ™¢Á¥¢ÁµêÊßãÔºå‰ª£Ë°®‰∫ÜÈÜ´ÁôÇÊ™¢Ê∏¨Âª∫Ë≠∞ÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **Representation Learning of Lab Values via Masked AutoEncoder**
2501.02648v2 by David Restrepo, Chenwei Wu, Yueran Jia, Jaden K. Sun, Jack Gallifant, Catherine G. Bielick, Yugang Jia, Leo A. Celi

Accurate imputation of missing laboratory values in electronic health records
(EHRs) is critical to enable robust clinical predictions and reduce biases in
AI systems in healthcare. Existing methods, such as variational autoencoders
(VAEs) and decision tree-based approaches such as XGBoost, struggle to model
the complex temporal and contextual dependencies in EHR data, mainly in
underrepresented groups. In this work, we propose Lab-MAE, a novel
transformer-based masked autoencoder framework that leverages self-supervised
learning for the imputation of continuous sequential lab values. Lab-MAE
introduces a structured encoding scheme that jointly models laboratory test
values and their corresponding timestamps, enabling explicit capturing temporal
dependencies. Empirical evaluation on the MIMIC-IV dataset demonstrates that
Lab-MAE significantly outperforms the state-of-the-art baselines such as
XGBoost across multiple metrics, including root mean square error (RMSE),
R-squared (R2), and Wasserstein distance (WD). Notably, Lab-MAE achieves
equitable performance across demographic groups of patients, advancing fairness
in clinical predictions. We further investigate the role of follow-up
laboratory values as potential shortcut features, revealing Lab-MAE's
robustness in scenarios where such data is unavailable. The findings suggest
that our transformer-based architecture, adapted to the characteristics of the
EHR data, offers a foundation model for more accurate and fair clinical
imputation models. In addition, we measure and compare the carbon footprint of
Lab-MAE with the baseline XGBoost model, highlighting its environmental
requirements.

ÊëòË¶ÅÔºö<paragraph>Ê∫ñÁ¢∫‰º∞ÁÆóÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ‰∏≠ÈÅ∫Â§±ÁöÑÂØ¶È©óÂÆ§ÂÄºÂ∞çÊñºÂïüÁî®Á©©ÂÅ•ÁöÑËá®Â∫äÈ†êÊ∏¨ÂíåÊ∏õÂ∞ëÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ AI Á≥ªÁµ±ÁöÑÂÅèÂ∑ÆËá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÊñπÊ≥ïÔºà‰æãÂ¶ÇËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô® (VAE) ÂíåÂü∫ÊñºÊ±∫Á≠ñÊ®πÁöÑÊñπÊ≥ïÔºå‰æãÂ¶Ç XGBoostÔºâÈõ£‰ª•Âª∫Ê®° EHR Ë≥áÊñô‰∏≠Ë§áÈõúÁöÑÊôÇÈñìÂíå‰∏ä‰∏ãÊñá‰æùË≥¥ÊÄßÔºåÁâπÂà•ÊòØÂú®‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑÁæ§ÁµÑ‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ Lab-MAEÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫Êñº Transformer ÁöÑÈÅÆÁΩ©Ëá™ÂãïÁ∑®Á¢ºÂô®Ê°ÜÊû∂ÔºåÂÆÉÂà©Áî®Ëá™ÊàëÁõ£Áù£Â≠∏Áøí‰æÜ‰º∞ÁÆóÈÄ£Á∫åÈ†ÜÂ∫èÂØ¶È©óÂÆ§ÂÄº„ÄÇLab-MAE ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁ∑®Á¢ºÊñπÊ°àÔºåÂÆÉËÅØÂêàÂª∫Ê®°ÂØ¶È©óÂÆ§Ê∏¨Ë©¶ÂÄºÂèäÂÖ∂Â∞çÊáâÁöÑÊôÇÈñìÊà≥ÔºåÂæûËÄåËÉΩÂ§†ÊòéÁ¢∫ÊçïÊçâÊôÇÈñì‰æùË≥¥ÊÄß„ÄÇÂú® MIMIC-IV Ë≥áÊñôÈõÜ‰∏äÁöÑÁ∂ìÈ©óË©ï‰º∞Ë°®ÊòéÔºåLab-MAE Âú®ÂåÖÊã¨ÂùáÊñπÊ†πË™§Â∑Æ (RMSE)„ÄÅR Âπ≥Êñπ (R2) Âíå Wasserstein Ë∑ùÈõ¢ (WD) Âú®ÂÖßÁöÑÂ§öÈ†ÖÊåáÊ®ô‰∏äÈ°ØËëóÂÑ™Êñº XGBoost Á≠âÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLab-MAE Âú®ÊÇ£ËÄÖÁöÑ‰∫∫Âè£Áµ±Ë®àÁæ§ÁµÑ‰∏≠ÂèñÂæó‰∫ÜÂÖ¨Âπ≥ÁöÑË°®ÁèæÔºåÂæûËÄåÊèêÂçá‰∫ÜËá®Â∫äÈ†êÊ∏¨‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰∫ÜÂæåÁ∫åÂØ¶È©óÂÆ§ÂÄº‰ΩúÁÇ∫ÊΩõÂú®Êç∑ÂæëÁâπÂæµÁöÑ‰ΩúÁî®ÔºåÊè≠Á§∫‰∫Ü Lab-MAE Âú®Ê≠§È°ûË≥áÊñô‰∏çÂèØÁî®ÁöÑÊÉÖÊ≥Å‰∏ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂü∫Êñº Transformer ÁöÑÊû∂ÊßãÔºàË™øÊï¥ÁÇ∫ EHR Ë≥áÊñôÁöÑÁâπÂæµÔºâÁÇ∫Êõ¥Ê∫ñÁ¢∫ÂíåÂÖ¨Âπ≥ÁöÑËá®Â∫ä‰º∞ÁÆóÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂü∫Á§éÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ∏¨Èáè‰∏¶ÊØîËºÉ‰∫Ü Lab-MAE ËàáÂü∫Ê∫ñ XGBoost Ê®°ÂûãÁöÑÁ¢≥Ë∂≥Ë∑°ÔºåÁ™ÅÂá∫‰∫ÜÂÖ∂Áí∞Â¢ÉÈúÄÊ±Ç„ÄÇ</paragraph>

##### **Trust and Dependability in Blockchain & AI Based MedIoT Applications: Research Challenges and Future Directions**
2501.02647v1 by Ellis Solaiman, Christa Awad

This paper critically reviews the integration of Artificial Intelligence (AI)
and blockchain technologies in the context of Medical Internet of Things
(MedIoT) applications, where they collectively promise to revolutionize
healthcare delivery. By examining current research, we underscore AI's
potential in advancing diagnostics and patient care, alongside blockchain's
capacity to bolster data security and patient privacy. We focus particularly on
the imperative to cultivate trust and ensure reliability within these systems.
Our review highlights innovative solutions for managing healthcare data and
challenges such as ensuring scalability, maintaining privacy, and promoting
ethical practices within the MedIoT domain. We present a vision for integrating
AI-driven insights with blockchain security in healthcare, offering a
comprehensive review of current research and future directions. We conclude
with a set of identified research gaps and propose that addressing these is
crucial for achieving the dependable, secure, and patient -centric MedIoT
applications of tomorrow.

ÊëòË¶ÅÔºöÊú¨ÊñáÊâπÂà§ÊÄßÂú∞ÂõûÈ°ß‰∫Ü‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÂçÄÂ°äÈèàÊäÄË°ìÂú®ÈÜ´ÁôÇÁâ©ËÅØÁ∂≤ (MedIoT) ÊáâÁî®‰∏≠ÁöÑÊï¥ÂêàÔºåÈÄôÂÖ©ËÄÖÂÖ±ÂêåÊâøË´æÂ∞áÂæπÂ∫ïÊîπËÆäÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇÈÄèÈÅéÊ™¢Ë¶ñÁõÆÂâçÁöÑÁ†îÁ©∂ÊâÄÔºåÊàëÂÄëÂº∑Ë™ø AI Âú®Êé®ÈÄ≤Ë®∫Êñ∑ÂíåÊÇ£ËÄÖÁÖßË≠∑ÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰ª•ÂèäÂçÄÂ°äÈèàÂº∑ÂåñË≥áÊñôÂÆâÂÖ®ÂíåÊÇ£ËÄÖÈö±ÁßÅÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁâπÂà•ÈóúÊ≥®Âú®ÈÄô‰∫õÁ≥ªÁµ±ÂÖßÂüπÈ§ä‰ø°‰ªªÂíåÁ¢∫‰øùÂèØÈù†ÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊàëÂÄëÁöÑÂõûÈ°ßÈáçÈªûÂú®ÊñºÁÆ°ÁêÜÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÁöÑÂâµÊñ∞Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•ÂèäÁ¢∫‰øùÂèØÊì¥ÂÖÖÊÄß„ÄÅÁ∂≠Ë≠∑Èö±ÁßÅÂíåÂú® MedIoT È†òÂüüÂÖßÊé®Âª£ÈÅìÂæ∑ÂØ¶ÂãôÁ≠âÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ∞á AI È©ÖÂãïÁöÑË¶ãËß£ËàáÂçÄÂ°äÈèàÂÆâÂÖ®Êï¥ÂêàÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈ°òÊôØÔºåÊèê‰æõÁõÆÂâçÁöÑÁ†îÁ©∂ÊâÄÂíåÊú™‰æÜÊñπÂêëÁöÑÂÖ®Èù¢ÂõûÈ°ß„ÄÇÊàëÂÄë‰ª•‰∏ÄÁµÑÂ∑≤Ë≠òÂà•ÁöÑÁ†îÁ©∂Â∑ÆË∑ù‰ΩúÁÇ∫ÁµêË´ñÔºå‰∏¶ÊèêÂá∫Ëß£Ê±∫ÈÄô‰∫õÂ∑ÆË∑ùÂ∞çÊñºÈÅîÊàêÊú™‰æÜÂèØ‰ø°Ë≥¥„ÄÅÂÆâÂÖ®‰∏î‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑ MedIoT ÊáâÁî®Ëá≥ÈóúÈáçË¶Å„ÄÇ

##### **KM-UNet KAN Mamba UNet for medical image segmentation**
2501.02559v1 by Yibo Zhang

Medical image segmentation is a critical task in medical imaging analysis.
Traditional CNN-based methods struggle with modeling long-range dependencies,
while Transformer-based models, despite their success, suffer from quadratic
computational complexity. To address these limitations, we propose KM-UNet, a
novel U-shaped network architecture that combines the strengths of
Kolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet
leverages the Kolmogorov-Arnold representation theorem for efficient feature
representation and SSMs for scalable long-range modeling, achieving a balance
between accuracy and computational efficiency. We evaluate KM-UNet on five
benchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results
demonstrate that KM-UNet achieves competitive performance compared to
state-of-the-art methods in medical image segmentation tasks. To the best of
our knowledge, KM-UNet is the first medical image segmentation framework
integrating KANs and SSMs. This work provides a valuable baseline and new
insights for the development of more efficient and interpretable medical image
segmentation systems. The code is open source at
https://github.com/2760613195/KM_UNet
  Keywords:KAN,Manba, state-space models,UNet, Medical image segmentation, Deep
learning

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇ
ÂÇ≥Áµ±Âü∫Êñº CNN ÁöÑÊñπÊ≥ïÈõ£‰ª•Ê®°Êì¨Èï∑Ë∑ùÈõ¢‰æùË≥¥ÊÄßÔºå
ËÄåÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÂÑòÁÆ°ÊàêÂäüÔºåÂçªÊúâ‰∫åÊ¨°Ë®àÁÆóË§áÈõúÂ∫¶ÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü KM-UNetÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ U ÂΩ¢Á∂≤Ë∑ØÊû∂ÊßãÔºåÁµêÂêà‰∫Ü Kolmogorov-Arnold Á∂≤Ë∑Ø (KANs) ÂíåÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) ÁöÑÂÑ™Èªû„ÄÇKM-UNet Âà©Áî® Kolmogorov-Arnold Ë°®Á§∫ÂÆöÁêÜÈÄ≤Ë°åÈ´òÊïàÁâπÂæµË°®Á§∫ÔºåÂà©Áî® SSM ÈÄ≤Ë°åÂèØÊì¥ÂÖÖÈï∑Ë∑ùÈõ¢Ê®°Êì¨ÔºåÂú®Ê∫ñÁ¢∫Â∫¶ÂíåË®àÁÆóÊïàÁéá‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äË©ï‰º∞ KM-UNetÔºöISIC17„ÄÅISIC18„ÄÅCVC„ÄÅBUSI Âíå GLAS„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂãô‰∏≠ÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÔºåKM-UNet ÈÅîÂà∞‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåKM-UNet ÊòØÁ¨¨‰∏ÄÂÄãÊï¥Âêà KAN Âíå SSM ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ê°ÜÊû∂„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ÈñãÁôºÊõ¥ÊúâÊïàÁéá‰∏îÂèØËß£ÈáãÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Á≥ªÁµ±Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑÂü∫Á∑öÂíåÊñ∞Ë¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂú® https://github.com/2760613195/KM_UNet ÈñãÊ∫ê
ÈóúÈçµÂ≠óÔºöKAN„ÄÅManba„ÄÅÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã„ÄÅUNet„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤„ÄÅÊ∑±Â∫¶Â≠∏Áøí

##### **Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine**
2501.02471v1 by Yishen Liu, Shengda Luo, Zishao Zhong, Tongtong Wu, Jianguo Zhang, Peiyao Ou, Yong Liang, Liang Liu, Hudan Pan

Large language models (LLMs) primarily trained on English texts, often face
biases and inaccuracies in Chinese contexts. Their limitations are pronounced
in fields like Traditional Chinese Medicine (TCM), where cultural and clinical
subtleties are vital, further hindered by a lack of domain-specific data, such
as rheumatoid arthritis (RA). To address these issues, this paper introduces
Hengqin-RA-v1, the first large language model specifically tailored for TCM
with a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a
comprehensive RA-specific dataset curated from ancient Chinese medical
literature, classical texts, and modern clinical studies. This dataset empowers
Hengqin-RA-v1 to deliver accurate and culturally informed responses,
effectively bridging the gaps left by general-purpose models. Extensive
experiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,
even surpassing the diagnostic accuracy of TCM practitioners in certain cases.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏ªË¶Å‰ª•Ëã±ÊñáÊñáÊú¨ÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂú®‰∏≠ÊñáË™ûÂ¢É‰∏≠Á∂ìÂ∏∏Èù¢Ëá®ÂÅèË¶ãÂíå‰∏çÊ∫ñÁ¢∫ÁöÑÂïèÈ°å„ÄÇÂÆÉÂÄëÁöÑÂ±ÄÈôêÊÄßÂú®‰∏≠ÈÜ´Á≠âÈ†òÂüüÂ∞§ÁÇ∫ÊòéÈ°ØÔºåÂõ†ÁÇ∫‰∏≠ÈÜ´Ê∂âÂèäÊñáÂåñÂíåËá®Â∫ä‰∏äÁöÑÂæÆÂ¶ô‰πãËôïÔºåËÄå‰∏îÈÇÑÁº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑÊï∏ÊìöÔºå‰æãÂ¶ÇÈ°ûÈ¢®ÊøïÈóúÁØÄÁÇéÔºàRAÔºâ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü Hengqin-RA-v1ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÈñÄÈáùÂ∞ç‰∏≠ÈÜ´ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÈáçÈªûÊòØË®∫Êñ∑ÂíåÊ≤ªÁôÇ RA„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü HQ-GCM-RA-C1ÔºåÈÄôÊòØ‰∏ÄÂÄãÂæûÂè§‰ª£‰∏≠ÈÜ´ÊñáÁçª„ÄÅÂè§ÂÖ∏ÊñáÊú¨ÂíåÁèæ‰ª£Ëá®Â∫äÁ†îÁ©∂‰∏≠Êï¥ÁêÜÂá∫‰æÜÁöÑ„ÄÅÂÖ®Èù¢ÁöÑ RA ÁâπÂÆöÊï∏ÊìöÈõÜ„ÄÇÈÄôÂÄãÊï∏ÊìöÈõÜËÆì Hengqin-RA-v1 ËÉΩÂ§†Êèê‰æõÊ∫ñÁ¢∫‰∏îÁ¨¶ÂêàÊñáÂåñËÉåÊôØÁöÑÂõûÊáâÔºåÊúâÊïàÂú∞ÂΩåË£ú‰∫ÜÈÄöÁî®Ê®°ÂûãÁïô‰∏ãÁöÑÁ©∫ÁôΩ„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåHengqin-RA-v1 ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÁîöËá≥Ë∂ÖÈÅé‰∫Ü‰∏≠ÈÜ´ÂæûÊ•≠ËÄÖÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇ

##### **Enhancing Contrastive Learning for Retinal Imaging via Adjusted Augmentation Scales**
2501.02451v1 by Zijie Cheng, Boxuan Li, Andr√© Altmann, Pearse A Keane, Yukun Zhou

Contrastive learning, a prominent approach within self-supervised learning,
has demonstrated significant effectiveness in developing generalizable models
for various applications involving natural images. However, recent research
indicates that these successes do not necessarily extend to the medical imaging
domain. In this paper, we investigate the reasons for this suboptimal
performance and hypothesize that the dense distribution of medical images poses
challenges to the pretext tasks in contrastive learning, particularly in
constructing positive and negative pairs. We explore model performance under
different augmentation strategies and compare the results to those achieved
with strong augmentations. Our study includes six publicly available datasets
covering multiple clinically relevant tasks. We further assess the model's
generalizability through external evaluations. The model pre-trained with weak
augmentation outperforms those with strong augmentation, improving AUROC from
0.838 to 0.848 and AUPR from 0.523 to 0.597 on MESSIDOR2, and showing similar
enhancements across other datasets. Our findings suggest that optimizing the
scale of augmentation is critical for enhancing the efficacy of contrastive
learning in medical imaging.

ÊëòË¶ÅÔºöÂ∞çÊØîÂ≠∏ÁøíÊòØËá™Áõ£Áù£Â≠∏Áøí‰∏≠‰∏ÄÁ®ÆÈáçË¶ÅÁöÑÊñπÊ≥ïÔºåÂú®Ê∂âÂèäËá™ÁÑ∂ÂΩ±ÂÉèÁöÑÂêÑÁ®ÆÊáâÁî®‰∏≠ÔºåÂ∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÊúâÊïàÊÄßÔºåÂèØÈñãÁôºÂá∫ÂèØÊ¶ÇÂåñÁöÑÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÈÄô‰∫õÊàêÂäü‰∏¶Êú™ÂøÖÁÑ∂Âª∂‰º∏Ëá≥ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÈÄ†ÊàêÈÄôÁ®ÆÊ¨°‰Ω≥ÊïàËÉΩÁöÑÂéüÂõ†Ôºå‰∏¶ÂÅáË®≠ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂØÜÈõÜÂàÜ‰ΩàÂ∞çÊØîÂ≠∏Áøí‰∏≠ÁöÑËóâÂè£‰ªªÂãôÈÄ†ÊàêÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®Âª∫ÊßãÊ≠£Ë≤†Â∞çÊôÇ„ÄÇÊàëÂÄëÂú®‰∏çÂêåÁöÑÊì¥ÂÖÖÁ≠ñÁï•‰∏ãÊé¢Ë®éÊ®°ÂûãÊïàËÉΩÔºå‰∏¶Â∞áÁµêÊûúËàáÂº∑Êì¥ÂÖÖÊâÄÈÅîÊàêÁöÑÁµêÊûúÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ê∂µËìãÂÖ≠ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìãÂ§öÈ†ÖËá®Â∫äÁõ∏Èóú‰ªªÂãô„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂ§ñÈÉ®Ë©ï‰º∞‰æÜË©ï‰º∞Ê®°ÂûãÁöÑÂèØÊ¶ÇÂåñÊÄß„ÄÇ‰ΩøÁî®Âº±Êì¥ÂÖÖÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÂÑ™Êñº‰ΩøÁî®Âº∑Êì¥ÂÖÖÁöÑÊ®°ÂûãÔºåÂú® MESSIDOR2 ‰∏äÂ∞á AUROC Âæû 0.838 ÊèêÂçáËá≥ 0.848ÔºåÂ∞á AUPR Âæû 0.523 ÊèêÂçáËá≥ 0.597Ôºå‰∏¶Âú®ÂÖ∂‰ªñË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÈ°û‰ººÁöÑÊèêÂçá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÊúÄ‰Ω≥ÂåñÊì¥ÂÖÖË¶èÊ®°Â∞çÊñºÊèêÂçáÂ∞çÊØîÂ≠∏ÁøíÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Enhancing Workplace Productivity and Well-being Using AI Agent**
2501.02368v1 by Ravirajan K, Arvind Sundarajan

This paper discusses the use of Artificial Intelligence (AI) to enhance
workplace productivity and employee well-being. By integrating machine learning
(ML) techniques with neurobiological data, the proposed approaches ensure
alignment with human ethical standards through value alignment models and
Hierarchical Reinforcement Learning (HRL) for autonomous task management. The
system utilizes biometric feedback from employees to generate personalized
health prompts, fostering a supportive work environment that encourages
physical activity. Additionally, we explore decentralized multi-agent systems
for improved collaboration and decision-making frameworks that enhance
transparency. Various approaches using ML techniques in conjunction with AI
implementations are discussed. Together, these innovations aim to create a more
productive and health-conscious workplace. These outcomes assist HR management
and organizations in launching more rational career progression streams for
employees and facilitating organizational transformation.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÂà©Áî®‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâ‰æÜÊèêÂçáËÅ∑Â†¥ÁîüÁî¢ÂäõÂíåÂì°Â∑•Á¶èÁ•â„ÄÇÈÄèÈÅéÂ∞áÊ©üÂô®Â≠∏ÁøíÔºàMLÔºâÊäÄË°ìËàáÁ•ûÁ∂ìÁîüÁâ©Â≠∏Ë≥áÊñôÊï¥ÂêàÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁ¢∫‰øùÈÄèÈÅéÂÉπÂÄºÂ∞çÈΩäÊ®°ÂûãÂíåÁî®ÊñºËá™‰∏ª‰ªªÂãôÁÆ°ÁêÜÁöÑÂàÜÂ±§Âº∑ÂåñÂ≠∏ÁøíÔºàHRLÔºâËàá‰∫∫È°ûÂÄ´ÁêÜÊ®ôÊ∫ñ‰øùÊåÅ‰∏ÄËá¥„ÄÇË©≤Á≥ªÁµ±Âà©Áî®Âì°Â∑•ÁöÑÁîüÁâ©ÁâπÂæµÂõûÈ•ã‰æÜÁî¢ÁîüÂÄã‰∫∫ÂåñÂÅ•Â∫∑ÊèêÁ§∫ÔºåÁáüÈÄ†ÊîØÊåÅÊÄßÁöÑÂ∑•‰ΩúÁí∞Â¢ÉÔºåÈºìÂãµË∫´È´îÊ¥ªÂãï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éÂàÜÊï£ÂºèÂ§öÊô∫ËÉΩÈ´îÁ≥ªÁµ±Ôºå‰ª•ÊîπÂñÑÂçî‰ΩúÂíåÊ±∫Á≠ñÂà∂ÂÆöÊû∂ÊßãÔºåÈÄ≤ËÄåÊèêÂçáÈÄèÊòéÂ∫¶„ÄÇÊú¨ÊñáË®éË´ñ‰∫ÜÂêÑÁ®ÆÁµêÂêà ML ÊäÄË°ìËàá AI ÂØ¶‰ΩúÁöÑÊñπÊ≥ï„ÄÇÁ∏ΩËÄåË®Ä‰πãÔºåÈÄô‰∫õÂâµÊñ∞Êó®Âú®ÂâµÈÄ†‰∏ÄÂÄãÊõ¥ÂÖ∑ÁîüÁî¢Âäõ‰∏îÊ≥®ÈáçÂÅ•Â∫∑ÁöÑËÅ∑Â†¥„ÄÇÈÄô‰∫õÊàêÊûúÊúâÂä©Êñº‰∫∫ÂäõË≥áÊ∫êÁÆ°ÁêÜÂíåÁµÑÁπîÊ©üÊßãÁÇ∫Âì°Â∑•ÂïüÂãïÊõ¥ÂêàÁêÜÁöÑËÅ∑Ê∂ØÁôºÂ±ïÁÆ°ÈÅìÔºå‰∏¶‰øÉÈÄ≤ÁµÑÁπîËΩâÂûã„ÄÇ

##### **Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support**
2501.02346v1 by Florian Putz, Marlen Haderleina, Sebastian Lettmaier, Sabine Semrau, Rainer Fietkau, Yixing Huang

Thanks to the rapidly evolving integration of LLMs into decision-support
tools, a significant transformation is happening across large-scale systems.
Like other medical fields, the use of LLMs such as GPT-4 is gaining increasing
interest in radiation oncology as well. An attempt to assess GPT-4's
performance in radiation oncology was made via a dedicated 100-question
examination on the highly specialized topic of radiation oncology physics,
revealing GPT-4's superiority over other LLMs. GPT-4's performance on a broader
field of clinical radiation oncology is further benchmarked by the ACR
Radiation Oncology In-Training (TXIT) exam where GPT-4 achieved a high accuracy
of 74.57%. Its performance on re-labelling structure names in accordance with
the AAPM TG-263 report has also been benchmarked, achieving above 96%
accuracies. Such studies shed light on the potential of LLMs in radiation
oncology. As interest in the potential and constraints of LLMs in general
healthcare applications continues to rise5, the capabilities and limitations of
LLMs in radiation oncology decision support have not yet been fully explored.

ÊëòË¶ÅÔºöÈö®Ëëó LLM Âø´ÈÄüÊºîÈÄ≤Êï¥ÂêàÂà∞Ê±∫Á≠ñÊîØÊè¥Â∑•ÂÖ∑‰∏≠ÔºåÂ§ßË¶èÊ®°Á≥ªÁµ±Ê≠£Âú®ÁôºÁîüÈáçÂ§ßËΩâËÆä„ÄÇ
ËàáÂÖ∂‰ªñÈÜ´ÁôÇÈ†òÂüü‰∏ÄÊ®£ÔºåLLMÔºà‰æãÂ¶Ç GPT-4ÔºâÁöÑ‰ΩøÁî®‰πüÂú®ÊîæÂ∞ÑËÖ´Áò§Â≠∏‰∏≠Áç≤ÂæóË∂ä‰æÜË∂äÂ§öÁöÑËààË∂£„ÄÇÈÄèÈÅéÈáùÂ∞çÊîæÂ∞ÑËÖ´Áò§Â≠∏Áâ©ÁêÜÂ≠∏ÈÄôÂÄãÈ´òÂ∫¶Â∞àÊ•≠ÁöÑ‰∏ªÈ°åÈÄ≤Ë°å 100 È°åÂ∞àÈñÄËÄÉË©¶ÔºåË©¶ÂúñË©ï‰º∞ GPT-4 Âú®ÊîæÂ∞ÑËÖ´Áò§Â≠∏‰∏≠ÁöÑË°®ÁèæÔºåÊè≠Á§∫‰∫Ü GPT-4 ÂÑ™ÊñºÂÖ∂‰ªñ LLM„ÄÇGPT-4 Âú®Êõ¥Âª£Ê≥õÁöÑËá®Â∫äÊîæÂ∞ÑËÖ´Áò§Â≠∏È†òÂüüÁöÑË°®ÁèæÈÄ≤‰∏ÄÊ≠•Áî± ACR ÊîæÂ∞ÑËÖ´Áò§Â≠∏Âú®ËÅ∑Ë®ìÁ∑¥ (TXIT) ËÄÉË©¶ÈÄ≤Ë°åË©ïÈáèÔºåGPT-4 Âú®ÂÖ∂‰∏≠ÂèñÂæó 74.57% ÁöÑÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÂÆÉÊ†πÊìö AAPM TG-263 Â†±ÂëäÈáçÊñ∞Ê®ôË®òÁµêÊßãÂêçÁ®±ÁöÑË°®Áèæ‰πüÂ∑≤ÈÄ≤Ë°åË©ïÈáèÔºåÊ∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 96% ‰ª•‰∏ä„ÄÇÈÄô‰∫õÁ†îÁ©∂Êè≠Á§∫‰∫Ü LLM Âú®ÊîæÂ∞ÑËÖ´Áò§Â≠∏‰∏≠ÁöÑÊΩõÂäõ„ÄÇÁî±Êñº‰∫∫ÂÄëÊåÅÁ∫åÂ∞ç LLM Âú®‰∏ÄËà¨ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ÁöÑÊΩõÂäõÂíåÈôêÂà∂ÊÑüËààË∂£5ÔºåLLM Âú®ÊîæÂ∞ÑËÖ´Áò§Â≠∏Ê±∫Á≠ñÊîØÊè¥‰∏≠ÁöÑÂäüËÉΩÂíåÈôêÂà∂Â∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇ

##### **Deep Learning-Driven Segmentation of Ischemic Stroke Lesions Using Multi-Channel MRI**
2501.02287v1 by Ashiqur Rahman, Muhammad E. H. Chowdhury, Md Sharjis Ibne Wadud, Rusab Sarmun, Adam Mushtak, Sohaib Bassam Zoghoul, Israa Al-Hashimi

Ischemic stroke, caused by cerebral vessel occlusion, presents substantial
challenges in medical imaging due to the variability and subtlety of stroke
lesions. Magnetic Resonance Imaging (MRI) plays a crucial role in diagnosing
and managing ischemic stroke, yet existing segmentation techniques often fail
to accurately delineate lesions. This study introduces a novel deep
learning-based method for segmenting ischemic stroke lesions using
multi-channel MRI modalities, including Diffusion Weighted Imaging (DWI),
Apparent Diffusion Coefficient (ADC), and enhanced Diffusion Weighted Imaging
(eDWI). The proposed architecture integrates DenseNet121 as the encoder with
Self-Organized Operational Neural Networks (SelfONN) in the decoder, enhanced
by Channel and Space Compound Attention (CSCA) and Double
Squeeze-and-Excitation (DSE) blocks. Additionally, a custom loss function
combining Dice Loss and Jaccard Loss with weighted averages is introduced to
improve model performance. Trained and evaluated on the ISLES 2022 dataset, the
model achieved Dice Similarity Coefficients (DSC) of 83.88% using DWI alone,
85.86% with DWI and ADC, and 87.49% with the integration of DWI, ADC, and eDWI.
This approach not only outperforms existing methods but also addresses key
limitations in current segmentation practices. These advancements significantly
enhance diagnostic precision and treatment planning for ischemic stroke,
providing valuable support for clinical decision-making.

ÊëòË¶ÅÔºöÁº∫Ë°ÄÊÄß‰∏≠È¢®ÊòØÁî±ËÖ¶Ë°ÄÁÆ°ÈòªÂ°ûÊâÄÂºïËµ∑ÔºåÁî±Êñº‰∏≠È¢®ÁóÖÁÅ∂ÁöÑÂèØËÆäÊÄßÂíåÈö±ËîΩÊÄßÔºåÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÈÄ†ÊàêÁõ∏Áï∂Â§ßÁöÑÊåëÊà∞„ÄÇÁ£ÅÊåØÈÄ†ÂΩ± (MRI) Âú®Ë®∫Êñ∑ÂíåÊ≤ªÁôÇÁº∫Ë°ÄÊÄß‰∏≠È¢®‰∏≠ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰ΩÜÁèæÊúâÁöÑÂàÜÂâ≤ÊäÄË°ìÂ∏∏Â∏∏ÁÑ°Ê≥ïÊ∫ñÁ¢∫Âú∞ÊèèÁπ™ÁóÖÁÅ∂„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºå‰ΩøÁî®Â§öÈÄöÈÅì MRI Ê®°ÂºèÂ∞çÁº∫Ë°ÄÊÄß‰∏≠È¢®ÁóÖÁÅ∂ÈÄ≤Ë°åÂàÜÂâ≤ÔºåÂåÖÊã¨Êì¥Êï£Âä†Ê¨äÂΩ±ÂÉè (DWI)„ÄÅË°®ËßÄÊì¥Êï£‰øÇÊï∏ (ADC) ÂíåÂ¢ûÂº∑ÂûãÊì¥Êï£Âä†Ê¨äÂΩ±ÂÉè (eDWI)„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂ∞á DenseNet121 Êï¥ÂêàÁÇ∫Á∑®Á¢ºÂô®Ôºå‰∏¶Âú®Ëß£Á¢ºÂô®‰∏≠‰ΩøÁî®Ëá™ÁµÑÁπîÈÅãÁÆóÁ•ûÁ∂ìÁ∂≤Ë∑Ø (SelfONN)Ôºå‰∏¶Áî±ÈÄöÈÅìÂíåÁ©∫ÈñìË§áÂêàÊ≥®ÊÑèÂäõ (CSCA) ÂíåÈõôÈáçÊì†Â£ìÊøÄÂãµ (DSE) ÂçÄÂ°äÈÄ≤Ë°åÂä†Âº∑„ÄÇÊ≠§Â§ñÔºåÈÇÑÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãËá™Ë®ÇÁöÑÊêçÂ§±ÂáΩÊï∏ÔºåÁµêÂêà‰∫Ü Dice ÊêçÂ§±Âíå Jaccard ÊêçÂ§±‰ª•ÂèäÂä†Ê¨äÂπ≥ÂùáÔºå‰ª•ÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÂú® ISLES 2022 Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÂíåË©ï‰º∞ÔºåË©≤Ê®°Âûã‰ΩøÁî® DWI ÂñÆÁç®ÊôÇÈÅîÂà∞ 83.88% ÁöÑ Dice Áõ∏‰ººÊÄß‰øÇÊï∏ (DSC)Ôºå‰ΩøÁî® DWI Âíå ADC ÊôÇÈÅîÂà∞ 85.86%Ôºå‰ΩøÁî® DWI„ÄÅADC Âíå eDWI Êï¥ÂêàÊôÇÈÅîÂà∞ 87.49%„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÈÇÑËÉΩËß£Ê±∫Áï∂ÂâçÂàÜÂâ≤ÂØ¶Âãô‰∏≠ÁöÑ‰∏ªË¶ÅÈôêÂà∂„ÄÇÈÄô‰∫õÈÄ≤Â±ïÈ°ØËëóÊèêÂçá‰∫ÜÁº∫Ë°ÄÊÄß‰∏≠È¢®ÁöÑË®∫Êñ∑Á≤æÊ∫ñÂ∫¶ÂíåÊ≤ªÁôÇË¶èÂäÉÔºåÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõÊúâÂÉπÂÄºÁöÑÊîØÊè¥„ÄÇ

##### **The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems**
2501.02169v1 by Umar Safdar, Simon Gabrael

Verisign reported a 125 percent increase in data breaches within the
healthcare sector in the United States during 2022, with 18.2 million patient
records being impacted. Growing healthcare data volumes and diversification
mean that medical information is becoming more valuable. Many Health Centers
use various technologies to ease the classification, storage, and exchange of
big data. This use can also make the health data of the users at risk and
vulnerable. AI and blockchain are among the leading technologies at hand. With
AI, data-driven operations and big data efficiency have been improved with
respect to traditional techniques. Due to its potential to bring about
improvements in health services and lower medical costs, this AI technology is
regularly used in healthcare. Blockchain helps protect transactions on sharing
information and private privacy as long as the exchange of knowledge is that of
the standard. The objective of this analysis is to investigate the research and
unique contributions since 2008 regarding blockchain-integrated AI and
healthcare systems. The work sheds light on applied AI-based healthcare schemes
with machine, ballistic, and acrylic learning and disparate blockchain
structures. The use of technology in order to ensure patient data security and
manage medical information effectively in healthcare settings offers a highly
successful position for both healthcare providers and patients. From 2018 to
2021, the best year was 2021 to grow, enhancing everything to examine the
download of the device and the counting of Google Academies, for which the
joining perspective was borrowed; local research experts were asked, identified
articles in recent years, and read reviews of large research grants.

ÊëòË¶ÅÔºöVerisign Â†±Âëä 2022 Âπ¥ÁæéÂúãÈÜ´ÁôÇ‰øùÂÅ•ÈÉ®ÈñÄÁöÑË≥áÊñôÂ§ñÊ¥©‰∫ã‰ª∂Â¢ûÂä†‰∫Ü 125%ÔºåÂΩ±Èüø‰∫Ü 1,820 Ëê¨Á≠ÜÁóÖÊ≠∑„ÄÇÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈáè‰∏çÊñ∑Â¢ûÂä†‰∏îÂ§öÂÖÉÂåñÔºåÈÄôË°®Á§∫ÈÜ´ÁôÇË≥áË®äËÆäÂæóÊõ¥ÊúâÂÉπÂÄº„ÄÇË®±Â§öÈÜ´ÁôÇ‰∏≠ÂøÉ‰ΩøÁî®ÂêÑÁ®ÆÊäÄË°ìÔºå‰ª•Á∞°ÂåñÂ§ßÊï∏ÊìöÁöÑÂàÜÈ°û„ÄÅÂÑ≤Â≠òÂíå‰∫§Êèõ„ÄÇÈÄôÁ®Æ‰ΩøÁî®ÊñπÂºè‰πüÂèØËÉΩ‰Ωø‰ΩøÁî®ËÄÖÁöÑÂÅ•Â∫∑Ë≥áÊñôÈù¢Ëá®È¢®Èö™ÂíåËÑÜÂº±ÊÄß„ÄÇ‰∫∫Â∑•Êô∫ÊÖßÂíåÂçÄÂ°äÈèàÊòØÁèæÊúâÁöÑÈ†òÂÖàÊäÄË°ì„ÄÇÈÄèÈÅé‰∫∫Â∑•Êô∫ÊÖßÔºåË≥áÊñôÈ©ÖÂãïÁöÑÈÅã‰ΩúÂíåÂ§ßÊï∏ÊìöÊïàÁéáÂ∑≤Áõ∏ËºÉÊñºÂÇ≥Áµ±ÊäÄË°ìÁç≤ÂæóÊîπÂñÑ„ÄÇÁî±Êñº‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊúâÊΩõÂäõÊîπÂñÑÈÜ´ÁôÇÊúçÂãô‰∏¶Èôç‰ΩéÈÜ´ÁôÇÊàêÊú¨ÔºåÂõ†Ê≠§Á∂ìÂ∏∏Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®„ÄÇÂçÄÂ°äÈèàÊúâÂä©Êñº‰øùË≠∑‰∫§ÊòìÔºåÂú®Ë≥áË®äÂÖ±‰∫´ÂíåÈö±ÁßÅÊñπÈù¢ÔºåÂè™Ë¶ÅÁü•Ë≠òÁöÑ‰∫§ÊèõÊòØÊ®ôÊ∫ñÁöÑ„ÄÇÊú¨ÂàÜÊûêÁöÑÁõÆÊ®ôÊòØË™øÊü•Ëá™ 2008 Âπ¥‰ª•‰æÜËàáÂçÄÂ°äÈèàÊï¥Âêà‰∫∫Â∑•Êô∫ÊÖßÂíåÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±Áõ∏ÈóúÁöÑÁ†îÁ©∂ÂíåÁç®ÁâπË≤¢Áçª„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈó°Êòé‰∫ÜÊáâÁî®‰∫∫Â∑•Êô∫ÊÖßÁÇ∫Âü∫Á§éÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë®àÁï´ÔºåÂåÖÊã¨Ê©üÂô®„ÄÅÂΩàÈÅìÂíå‰∏ôÁÉØÈÖ∏Â≠∏Áøí‰ª•Âèä‰∏çÂêåÁöÑÂçÄÂ°äÈèàÁµêÊßã„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÁóÖÊÇ£Ë≥áÊñôÂÆâÂÖ®‰∏¶Âú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÊúâÊïàÁÆ°ÁêÜÈÜ´ÁôÇË≥áË®äÔºå‰ΩøÁî®ÊäÄË°ìÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÂíåÁóÖÊÇ£Êèê‰æõ‰∫ÜÊ•µÁÇ∫ÊàêÂäüÁöÑÂÆö‰Ωç„ÄÇÂæû 2018 Âπ¥Âà∞ 2021 Âπ¥ÔºåÊúÄÈÅ©ÂêàÊàêÈï∑ÁöÑÊòØ 2021 Âπ¥ÔºåÂä†Âº∑ÊâÄÊúâ‰∏ÄÂàáÔºå‰ª•Ê™¢Êü•Ë£ùÁΩÆÁöÑ‰∏ãËºâÂíå Google Â≠∏Ë°ìÁöÑË®àÊï∏ÔºåÂÄüÁî®‰∫ÜÂä†ÂÖ•ÁöÑËßÄÈªûÔºõË©¢Âïè‰∫ÜÁï∂Âú∞Á†îÁ©∂Â∞àÂÆ∂ÔºåÊâæÂá∫ËøëÂπ¥‰æÜÁöÑÊñáÁ´†Ôºå‰∏¶Èñ±ËÆÄÂ§ßÂûãÁ†îÁ©∂Ë£úÂä©ÈáëÁöÑË©ïË´ñ„ÄÇ

##### **Online Detection of Water Contamination Under Concept Drift**
2501.02107v1 by Jin Li, Kleanthis Malialis, Stelios G. Vrachimis, Marios M. Polycarpou

Water Distribution Networks (WDNs) are vital infrastructures, and
contamination poses serious public health risks. Harmful substances can
interact with disinfectants like chlorine, making chlorine monitoring essential
for detecting contaminants. However, chlorine sensors often become unreliable
and require frequent calibration. This study introduces the Dual-Threshold
Anomaly and Drift Detection (AD&DD) method, an unsupervised approach combining
a dual-threshold drift detection mechanism with an LSTM-based Variational
Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two
realistic WDNs, AD&DD effectively identifies anomalies with sensor offsets as
concept drift, and outperforms other methods. A proposed decentralized
architecture enables accurate contamination detection and localization by
deploying AD&DD on selected nodes.

ÊëòË¶ÅÔºöÈÖçÊ∞¥Á∂≤Ë∑Ø (WDN) ÊòØÈáçË¶ÅÁöÑÂü∫Á§éË®≠ÊñΩÔºåËÄåÊ±°ÊüìÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÂÖ¨ÂÖ±Ë°õÁîüÈ¢®Èö™„ÄÇÊúâÂÆ≥Áâ©Ë≥™ÂèØËÉΩÊúÉËàáÊ∂àÊØíÂäëÔºàÂ¶ÇÊ∞ØÊ∞£Ôºâ‰∫§‰∫í‰ΩúÁî®ÔºåÂõ†Ê≠§Áõ£Ê∏¨Ê∞ØÊ∞£Â∞çÊñºÂÅµÊ∏¨Ê±°ÊüìÁâ©Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊ∞ØÊ∞£ÊÑüÊ∏¨Âô®Â∏∏Â∏∏ËÆäÂæó‰∏çÂèØÈù†ÔºåÈúÄË¶ÅÈ†ªÁπÅÊ†°Ê≠£„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫ÈõôÈñæÂÄºÁï∞Â∏∏ËàáÊºÇÁßªÂÅµÊ∏¨ (AD&DD) ÊñπÊ≥ïÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈùûÁõ£Áù£ÂºèÊñπÊ≥ïÔºåÁµêÂêàÈõôÈñæÂÄºÊºÇÁßªÂÅµÊ∏¨Ê©üÂà∂ËàáÂü∫Êñº LSTM ÁöÑËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô® (LSTM-VAE)ÔºåÁî®ÊñºÂç≥ÊôÇÊ±°ÊüìÂÅµÊ∏¨„ÄÇÂú®ÂÖ©ÂÄãÂØ¶ÈöõÁöÑ WDN ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåAD&DD ËÉΩÊúâÊïàÂú∞Â∞áÊÑüÊ∏¨Âô®ÂÅèÁßªË¶ñÁÇ∫Ê¶ÇÂøµÊºÇÁßªÔºå‰∏¶ÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ï„ÄÇÊâÄÊèêÂá∫ÁöÑÂàÜÊï£ÂºèÊû∂ÊßãËÉΩÈÄèÈÅéÂú®ÈÅ∏ÂÆöÁöÑÁØÄÈªûÈÉ®ÁΩ≤ AD&DDÔºåÂØ¶ÁèæÁ≤æÁ¢∫ÁöÑÊ±°ÊüìÂÅµÊ∏¨ËàáÂÆö‰Ωç„ÄÇ

##### **METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring**
2501.02045v1 by Ollie Liu, Sami Jaghouar, Johannes Hagemann, Shangshang Wang, Jason Wiemels, Jeff Kaufman, Willie Neiswanger

We pretrain METAGENE-1, a 7-billion-parameter autoregressive transformer
model, which we refer to as a metagenomic foundation model, on a novel corpus
of diverse metagenomic DNA and RNA sequences comprising over 1.5 trillion base
pairs. This dataset is sourced from a large collection of human wastewater
samples, processed and sequenced using deep metagenomic (next-generation)
sequencing methods. Unlike genomic models that focus on individual genomes or
curated sets of specific species, the aim of METAGENE-1 is to capture the full
distribution of genomic information present within this wastewater, to aid in
tasks relevant to pandemic monitoring and pathogen detection. We carry out
byte-pair encoding (BPE) tokenization on our dataset, tailored for metagenomic
sequences, and then pretrain our model. In this paper, we first detail the
pretraining dataset, tokenization strategy, and model architecture,
highlighting the considerations and design choices that enable the effective
modeling of metagenomic data. We then show results of pretraining this model on
our metagenomic dataset, providing details about our losses, system metrics,
and training stability over the course of pretraining. Finally, we demonstrate
the performance of METAGENE-1, which achieves state-of-the-art results on a set
of genomic benchmarks and new evaluations focused on human-pathogen detection
and genomic sequence embedding, showcasing its potential for public health
applications in pandemic monitoring, biosurveillance, and early detection of
emerging health threats.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÈ†êË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂÖ∑Êúâ 70 ÂÑÑÂÄãÂèÉÊï∏ÁöÑËá™Ëø¥Ê≠∏ËΩâÊèõÂô®Ê®°Âûã METAGENE-1ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ÂÆèÂü∫Âõ†ÁµÑÂü∫Á§éÊ®°ÂûãÔºåÂÆÉÂª∫Á´ãÂú®‰∏ÄÂÄãÊñ∞Á©éÁöÑË™ûÊñôÂ∫´‰∏äÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë∂ÖÈÅé 1.5 ÂÖÜÂÄãÈπºÂü∫Â∞çÁöÑÂ§öÊ®£ÂåñÂÆèÂü∫Âõ†ÁµÑ DNA Âíå RNA Â∫èÂàó„ÄÇÊ≠§Êï∏ÊìöÈõÜ‰æÜËá™Â§ßÈáè‰∫∫È°ûÂª¢Ê∞¥Ê®£Êú¨Ôºå‰ΩøÁî®Ê∑±Â∫¶ÂÆèÂü∫Âõ†ÁµÑÔºà‰∏ã‰∏Ä‰ª£ÔºâÂÆöÂ∫èÊñπÊ≥ïÈÄ≤Ë°åËôïÁêÜÂíåÂÆöÂ∫è„ÄÇËàáÂ∞àÊ≥®ÊñºÂÄãÂà•Âü∫Âõ†ÁµÑÊàñÁâπÂÆöÁâ©Á®ÆÁ≠ñÂäÉÈõÜÂêàÁöÑÂü∫Âõ†ÁµÑÊ®°Âûã‰∏çÂêåÔºåMETAGENE-1 ÁöÑÁõÆÊ®ôÊòØÊì∑ÂèñÊ≠§Âª¢Ê∞¥‰∏≠Â≠òÂú®ÁöÑÂü∫Âõ†ÁµÑË≥áË®äÁöÑÂÆåÊï¥ÂàÜ‰ΩàÔºå‰ª•ÂçîÂä©ËàáÂ§ßÊµÅË°åÁõ£Ê∏¨ÂíåÁóÖÂéüÈ´îÊ™¢Ê∏¨Áõ∏ÈóúÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÂ∞çÊï∏ÊìöÈõÜÂü∑Ë°åÈáùÂ∞çÂÆèÂü∫Âõ†ÁµÑÂ∫èÂàóÈáèË∫´ÊâìÈÄ†ÁöÑ‰ΩçÂÖÉÁµÑÂ∞çÁ∑®Á¢º (BPE) Ê®ôË®òÂåñÔºåÁÑ∂ÂæåÈ†êË®ìÁ∑¥ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàË©≥Á¥∞Ë™™ÊòéÈ†êË®ìÁ∑¥Êï∏ÊìöÈõÜ„ÄÅÊ®ôË®òÂåñÁ≠ñÁï•ÂíåÊ®°ÂûãÊû∂ÊßãÔºåÈáçÈªûË™™ÊòéËÉΩÊúâÊïàÂª∫Ê®°ÂÆèÂü∫Âõ†ÁµÑÊï∏ÊìöÁöÑËÄÉÈáèÂíåË®≠Ë®àÈÅ∏Êìá„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®ÊàëÂÄëÁöÑÂÆèÂü∫Âõ†ÁµÑÊï∏ÊìöÈõÜ‰∏äÈ†êË®ìÁ∑¥Ê≠§Ê®°ÂûãÁöÑÁµêÊûúÔºåÊèê‰æõÊúâÈóúÊàëÂÄëÁöÑÊêçÂ§±„ÄÅÁ≥ªÁµ±ÊåáÊ®ôÂíåÂú®È†êË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Ë®ìÁ∑¥Á©©ÂÆöÊÄßÁöÑË©≥Á¥∞Ë≥áË®ä„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü METAGENE-1 ÁöÑÊïàËÉΩÔºåÂÆÉÂú®ÈáùÂ∞ç‰∫∫È°ûÁóÖÂéüÈ´îÊ™¢Ê∏¨ÂíåÂü∫Âõ†ÁµÑÂ∫èÂàóÂµåÂÖ•ÁöÑ‰∏ÄÁµÑÂü∫Âõ†ÁµÑÂü∫Ê∫ñÂíåÊñ∞Ë©ï‰º∞‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂÖ¨ÂÖ±Ë°õÁîüÊáâÁî®‰∏≠ÁöÑÊΩõÂäõÔºåÂåÖÊã¨Â§ßÊµÅË°åÁõ£Ê∏¨„ÄÅÁîüÁâ©Áõ£ÊéßÂíåÊñ∞ËààÂÅ•Â∫∑Â®ÅËÑÖÁöÑÊó©ÊúüÊ™¢Ê∏¨„ÄÇ</paragraph>

##### **Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT**
2501.02044v1 by Jianping He, Laila Rasmy, Degui Zhi, Cui Tao

Background: Recently, numerous foundation models pretrained on extensive data
have demonstrated efficacy in disease prediction using Electronic Health
Records (EHRs). However, there remains some unanswered questions on how to best
utilize such models especially with very small fine-tuning cohorts. Methods: We
utilized Med-BERT, an EHR-specific foundation model, and reformulated the
disease binary prediction task into a token prediction task and a next visit
mask token prediction task to align with Med-BERT's pretraining task format in
order to improve the accuracy of pancreatic cancer (PaCa) prediction in both
few-shot and fully supervised settings. Results: The reformulation of the task
into a token prediction task, referred to as Med-BERT-Sum, demonstrates
slightly superior performance in both few-shot scenarios and larger data
samples. Furthermore, reformulating the prediction task as a Next Visit Mask
Token Prediction task (Med-BERT-Mask) significantly outperforms the
conventional Binary Classification (BC) prediction task (Med-BERT-BC) by 3% to
7% in few-shot scenarios with data sizes ranging from 10 to 500 samples. These
findings highlight that aligning the downstream task with Med-BERT's
pretraining objectives substantially enhances the model's predictive
capabilities, thereby improving its effectiveness in predicting both rare and
common diseases. Conclusion: Reformatting disease prediction tasks to align
with the pretraining of foundation models enhances prediction accuracy, leading
to earlier detection and timely intervention. This approach improves treatment
effectiveness, survival rates, and overall patient outcomes for PaCa and
potentially other cancers.

ÊëòË¶ÅÔºöËÉåÊôØÔºöÊúÄËøëÔºåÂ§ßÈáèÂü∫‰∫éÂπøÊ≥õÊï∞ÊçÆËøõË°åÈ¢ÑËÆ≠ÁªÉÁöÑÂü∫Á°ÄÊ®°ÂûãÂ∑≤ËØÅÊòéÂú®‰ΩøÁî®ÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩï (EHR) È¢ÑÊµãÁñæÁóÖÊñπÈù¢ÊúâÊïà„ÄÇÁÑ∂ËÄåÔºåÂÖ≥‰∫éÂ¶Ç‰ΩïÊúÄÂ•ΩÂú∞Âà©Áî®Ê≠§Á±ªÊ®°ÂûãÔºàÂ∞§ÂÖ∂ÊòØÂú®ÊûÅÂ∞èÂæÆË∞ÉÈòüÂàó‰∏≠Ôºâ‰ªçÊúâ‰∏Ä‰∫õÊú™Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇÊñπÊ≥ïÔºöÊàë‰ª¨Âà©Áî®‰∫Ü EHR ÁâπÂÆöÁöÑÂü∫Á°ÄÊ®°Âûã Med-BERTÔºåÂπ∂Â∞ÜÁñæÁóÖ‰∫åÂÖÉÈ¢ÑÊµã‰ªªÂä°ÈáçÊñ∞Ë°®Ëø∞‰∏∫Ê†áËÆ∞È¢ÑÊµã‰ªªÂä°Âíå‰∏ãÊ¨°ËÆøÈóÆÊé©Á†ÅÊ†áËÆ∞È¢ÑÊµã‰ªªÂä°Ôºå‰ª•‰∏é Med-BERT ÁöÑÈ¢ÑËÆ≠ÁªÉ‰ªªÂä°Ê†ºÂºè‰øùÊåÅ‰∏ÄËá¥Ôºå‰ªéËÄåÊèêÈ´òËÉ∞ËÖ∫Áôå (PaCa) È¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÊó†ËÆ∫ÊòØÂú®Â∞èÊ†∑Êú¨ËøòÊòØÂÆåÂÖ®ÁõëÁù£ÁöÑËÆæÁΩÆ‰∏≠„ÄÇÁªìÊûúÔºöÂ∞Ü‰ªªÂä°ÈáçÊñ∞Ë°®Ëø∞‰∏∫Ê†áËÆ∞È¢ÑÊµã‰ªªÂä°ÔºàÁß∞‰∏∫ Med-BERT-SumÔºâÔºåÂú®Â∞èÊ†∑Êú¨Âú∫ÊôØÂíåËæÉÂ§ßÊï∞ÊçÆÊ†∑Êú¨‰∏≠ÂùáË°®Áé∞Âá∫Áï•ÂæÆ‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂ∞ÜÈ¢ÑÊµã‰ªªÂä°ÈáçÊñ∞Ë°®Ëø∞‰∏∫‰∏ã‰∏ÄÊ¨°ËÆøÈóÆÊé©Á†ÅÊ†áËÆ∞È¢ÑÊµã‰ªªÂä°ÔºàMed-BERT-MaskÔºâÂú®Â∞èÊ†∑Êú¨Âú∫ÊôØ‰∏≠ÊòéÊòæ‰ºò‰∫é‰º†ÁªüÁöÑ‰∫åÂÖÉÂàÜÁ±ª (BC) È¢ÑÊµã‰ªªÂä°ÔºàMed-BERT-BCÔºâÔºåÊï∞ÊçÆÂ§ßÂ∞è‰ªé 10 Âà∞ 500 ‰∏™Ê†∑Êú¨‰∏çÁ≠âÔºå‰ºòË∂äÂπÖÂ∫¶‰∏∫ 3% Âà∞ 7%„ÄÇËøô‰∫õÂèëÁé∞Âº∫Ë∞ÉÔºåÂ∞Ü‰∏ãÊ∏∏‰ªªÂä°‰∏é Med-BERT ÁöÑÈ¢ÑËÆ≠ÁªÉÁõÆÊ†á‰øùÊåÅ‰∏ÄËá¥ÔºåÂèØ‰ª•ÊòæÁùÄÂ¢ûÂº∫Ê®°ÂûãÁöÑÈ¢ÑÊµãËÉΩÂäõÔºå‰ªéËÄåÊèêÈ´òÂÖ∂È¢ÑÊµãÁΩïËßÅÁñæÁóÖÂíåÂ∏∏ËßÅÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÁªìËÆ∫ÔºöÈáçÊñ∞Ê†ºÂºèÂåñÁñæÁóÖÈ¢ÑÊµã‰ªªÂä°‰ª•‰∏éÂü∫Á°ÄÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉ‰øùÊåÅ‰∏ÄËá¥ÔºåÂèØÊèêÈ´òÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÔºå‰ªéËÄåÂÆûÁé∞Êó©ÊúüÊ£ÄÊµãÂíåÂèäÊó∂Âπ≤È¢Ñ„ÄÇËøôÁßçÊñπÊ≥ïÊèêÈ´ò‰∫Ü PaCa ÂíåÂÖ∂‰ªñÁôåÁóáÁöÑÊ≤ªÁñóÊïàÊûú„ÄÅÂ≠òÊ¥ªÁéáÂíåÊÇ£ËÄÖÊÄª‰ΩìÈ¢ÑÂêé„ÄÇ

##### **Combined Hyper-Extensible Extremely-Secured Zero-Trust CIAM-PAM architecture**
2501.01732v1 by Shivom Aggarwal, Shourya Mehra, Safeer Sathar

Customer Identity and Access Management (CIAM) systems play a pivotal role in
securing enterprise infrastructures. However, the complexity of implementing
these systems requires careful architectural planning to ensure positive Return
on Investment (RoI) and avoid costly delays. The proliferation of Active
Persistent cyber threats, coupled with advancements in AI, cloud computing, and
geographically distributed customer populations, necessitates a paradigm shift
towards adaptive and zero-trust security frameworks. This paper introduces the
Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM
architecture, designed specifically for large-scale enterprises. The CHEZ PL
CIAM-PAM framework addresses critical security gaps by integrating federated
identity management (private and public identities), password-less
authentication, adaptive multi-factor authentication (MFA), microservice-based
PEP (Policy Entitlement Point), multi-layer RBAC (Role Based Access Control)
and multi-level trust systems. This future-proof design also includes
end-to-end data encryption, and seamless integration with state-of-the-art
AI-based threat detection systems, while ensuring compliance with stringent
regulatory standards.

ÊëòË¶ÅÔºöÂÆ¢Êà∂Ë∫´ÂàÜËàáÂ≠òÂèñÁÆ°ÁêÜ (CIAM) Á≥ªÁµ±Âú®Á¢∫‰øù‰ºÅÊ•≠Âü∫Á§éË®≠ÊñΩÂÆâÂÖ®ÊñπÈù¢ÊâÆÊºîËëóÈóúÈçµËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÂØ¶‰ΩúÈÄô‰∫õÁ≥ªÁµ±ÁöÑË§áÈõúÊÄßÈúÄË¶Å‰ªîÁ¥∞ÁöÑÊû∂ÊßãË¶èÂäÉÔºå‰ª•Á¢∫‰øùÊäïË≥áÂ†±ÈÖ¨Áéá (RoI) ÁÇ∫Ê≠£Ôºå‰∏¶ÈÅøÂÖçÊàêÊú¨È´òÊòÇÁöÑÂª∂Ë™§„ÄÇ‰∏ªÂãïÊåÅÁ∫åÁöÑÁ∂≤Ë∑ØÂ®ÅËÑÖÁöÑÊì¥Êï£ÔºåÂä†‰∏ä‰∫∫Â∑•Êô∫ÊÖß„ÄÅÈõ≤Á´ØÈÅãÁÆóÂíåÂú∞ÁêÜÂàÜÂ∏ÉÁöÑÂÆ¢Êà∂Áæ§ÁöÑÈÄ≤Ê≠•ÔºåÈúÄË¶ÅÊúùÂêëÈÅ©ÊáâÊÄßÂíåÈõ∂‰ø°‰ªªÂÆâÂÖ®Êû∂ÊßãËΩâËÆä„ÄÇÊú¨Êñá‰ªãÁ¥πÂ∞àÁÇ∫Â§ßÂûã‰ºÅÊ•≠Ë®≠Ë®àÁöÑ Combined Hyper-Extensible Extremely-Secured Zero-Trust (CHEZ) CIAM-PAM Êû∂Êßã„ÄÇCHEZ PL CIAM-PAM Êû∂ÊßãÈÄèÈÅéÊï¥ÂêàËÅØÂêàË∫´ÂàÜÁÆ°ÁêÜÔºàÁßÅ‰∫∫ÂíåÂÖ¨Áî®Ë∫´ÂàÜÔºâ„ÄÅÁÑ°ÂØÜÁ¢ºÈ©óË≠â„ÄÅÈÅ©ÊáâÊÄßÂ§öÈáçË∫´ÂàÜÈ©óË≠â (MFA)„ÄÅÂü∫ÊñºÂæÆÊúçÂãôÁöÑ PEPÔºàÊîøÁ≠ñÊéàÊ¨äÈªûÔºâ„ÄÅÂ§öÂ±§ RBACÔºàÂü∫ÊñºËßíËâ≤ÁöÑÂ≠òÂèñÊéßÂà∂ÔºâÂíåÂ§öÂ±§Á¥ö‰ø°‰ªªÁ≥ªÁµ±‰æÜËß£Ê±∫ÈóúÈçµÁöÑÂÆâÂÖ®ÊºèÊ¥û„ÄÇÈÄôÁ®ÆÂÖ∑ÂÇôÊú™‰æÜÊÄßÁöÑË®≠Ë®à‰πüÂåÖÂê´Á´ØÂ∞çÁ´ØË≥áÊñôÂä†ÂØÜÔºå‰∏¶ËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖßÁöÑÂ®ÅËÑÖÂÅµÊ∏¨Á≥ªÁµ±ÁÑ°Á∏´Êï¥ÂêàÔºåÂêåÊôÇÁ¢∫‰øùÁ¨¶ÂêàÂö¥Ê†ºÁöÑÊ≥ïË¶èÊ®ôÊ∫ñ„ÄÇ

##### **EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical image segmentation**
2501.01658v1 by Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi

Weakly-supervised medical image segmentation is gaining traction as it
requires only rough annotations rather than accurate pixel-to-pixel labels,
thereby reducing the workload for specialists. Although some progress has been
made, there is still a considerable performance gap between the label-efficient
methods and fully-supervised one, which can be attributed to the uncertainty
nature of these weak labels. To address this issue, we propose a novel weak
annotation method coupled with its learning framework EAUWSeg to eliminate the
annotation uncertainty. Specifically, we first propose the Bounded Polygon
Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the
tailored learning mechanism that explicitly treat bounded polygons as two
separated annotations is proposed to learn invariant feature by providing
adversarial supervision signal for model training. Subsequently, a
confidence-auxiliary consistency learner incorporates with a
classification-guided confidence generator is designed to provide reliable
supervision signal for pixels in uncertain region by leveraging the feature
presentation consistency across pixels within the same category as well as
class-specific information encapsulated in bounded polygons annotation.
Experimental results demonstrate that EAUWSeg outperforms existing
weakly-supervised segmentation methods. Furthermore, compared to
fully-supervised counterparts, the proposed method not only delivers superior
performance but also costs much less annotation workload. This underscores the
superiority and effectiveness of our approach.

ÊëòË¶ÅÔºöÂº±ÁõëÁù£ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤Ê≠£Ëé∑ÂæóÂÖ≥Ê≥®ÔºåÂõ†‰∏∫ÂÆÉÂè™ÈúÄË¶ÅÁ≤óÁï•ÁöÑÊ≥®ÈáäÔºåËÄå‰∏çÊòØÁ≤æÁ°ÆÁöÑÂÉèÁ¥†Âà∞ÂÉèÁ¥†Ê†áÁ≠æÔºå‰ªéËÄåÂáèÂ∞ë‰∫Ü‰∏ìÂÆ∂ÁöÑÂ∑•‰ΩúÈáè„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫Ü‰∏Ä‰∫õËøõÂ±ïÔºå‰ΩÜÂú®Ê†áÁ≠æÈ´òÊïàÊñπÊ≥ïÂíåÂÆåÂÖ®ÁõëÁù£ÊñπÊ≥ï‰πãÈó¥‰ªçÁÑ∂Â≠òÂú®Áõ∏ÂΩìÂ§ßÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåËøôÂèØÂΩíÂõ†‰∫éËøô‰∫õÂº±Ê†áÁ≠æÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂº±Ê≥®ÈáäÊñπÊ≥ïÔºåÂπ∂ÁªìÂêàÂÖ∂Â≠¶‰π†Ê°ÜÊû∂ EAUWSeg Êù•Ê∂àÈô§Ê≥®ÈáäÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨È¶ñÂÖàÈÄöËøáÁÆÄÂçïÂú∞‰∏∫ÁóÖÁÅ∂Ê†áËÆ∞‰∏§‰∏™Â§öËæπÂΩ¢Êù•ÊèêÂá∫ÊúâÁïåÂ§öËæπÂΩ¢Ê≥®Èáä (BPAnno)„ÄÇÁÑ∂ÂêéÔºåÊèêÂá∫‰∫ÜÂ∞ÜÊúâÁïåÂ§öËæπÂΩ¢ÊòéÁ°ÆÂú∞ËßÜ‰∏∫‰∏§‰∏™ÂàÜÁ¶ªÊ≥®ÈáäÁöÑÂÆöÂà∂Â≠¶‰π†Êú∫Âà∂Ôºå‰ª•ÈÄöËøá‰∏∫Ê®°ÂûãËÆ≠ÁªÉÊèê‰æõÂØπÊäóÊÄßÁõëÁù£‰ø°Âè∑Êù•Â≠¶‰π†‰∏çÂèòÁâπÂæÅ„ÄÇÈöèÂêéÔºåÁΩÆ‰ø°ËæÖÂä©‰∏ÄËá¥ÊÄßÂ≠¶‰π†Âô®‰∏éÂàÜÁ±ªÂºïÂØºÁΩÆ‰ø°Â∫¶ÁîüÊàêÂô®ÁªìÂêàËÆæËÆ°Ôºå‰ª•ÈÄöËøáÂà©Áî®Âêå‰∏ÄÁ±ªÂà´ÂÜÖÂÉèÁ¥†ÁöÑÁâπÂæÅË°®Á§∫‰∏ÄËá¥ÊÄß‰ª•ÂèäÊúâÁïåÂ§öËæπÂΩ¢Ê≥®Èáä‰∏≠Â∞ÅË£ÖÁöÑÁâπÂÆö‰∫éÁ±ªÁöÑ‰ø°ÊÅØÔºå‰∏∫‰∏çÁ°ÆÂÆöÂå∫Âüü‰∏≠ÁöÑÂÉèÁ¥†Êèê‰æõÂèØÈù†ÁöÑÁõëÁù£‰ø°Âè∑„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEAUWSeg ‰ºò‰∫éÁé∞ÊúâÁöÑÂº±ÁõëÁù£ÂàÜÂâ≤ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºå‰∏éÂÆåÂÖ®ÁõëÁù£ÁöÑÂØπÂ∫îÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰∏ç‰ªÖÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÔºåËÄå‰∏îÊ≥®ÈáäÂ∑•‰ΩúÈáè‰πüÂ§ßÂ§ßÂáèÂ∞ë„ÄÇËøôÁ™ÅÂá∫‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑ‰ºòË∂äÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **Implications of Artificial Intelligence on Health Data Privacy and Confidentiality**
2501.01639v2 by Ahmad Momani

The rapid integration of artificial intelligence (AI) in healthcare is
revolutionizing medical diagnostics, personalized medicine, and operational
efficiency. However, alongside these advancements, significant challenges arise
concerning patient data privacy, ethical considerations, and regulatory
compliance. This paper examines the dual impact of AI on healthcare,
highlighting its transformative potential and the critical need for
safeguarding sensitive health information. It explores the role of the Health
Insurance Portability and Accountability Act (HIPAA) as a regulatory framework
for ensuring data privacy and security, emphasizing the importance of robust
safeguards and ethical standards in AI-driven healthcare. Through case studies,
including AI applications in diabetic retinopathy, oncology, and the
controversies surrounding data sharing, this study underscores the ethical and
legal complexities of AI implementation. A balanced approach that fosters
innovation while maintaining patient trust and privacy is imperative. The
findings emphasize the importance of continuous education, transparency, and
adherence to regulatory frameworks to harness AI's full potential responsibly
and ethically in healthcare.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÂø´ÈÄüÊï¥ÂêàÔºåÊ≠£Âú®ÂæπÂ∫ïËÆäÈù©ÈÜ´ÁôÇË®∫Êñ∑„ÄÅÂÄã‰∫∫ÂåñÈÜ´ÁôÇÂíåÁáüÈÅãÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÈÄô‰∫õÈÄ≤Ê≠•Ôºå‰πüÂá∫Áèæ‰∫ÜÈóúÊñºÊÇ£ËÄÖË≥áÊñôÈö±ÁßÅ„ÄÅÂÄ´ÁêÜËÄÉÈáèÂíåÊ≥ïË¶èÈÅµÂæ™ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü AI Â∞çÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈõôÈáçÂΩ±ÈüøÔºåÂº∑Ë™øÂÖ∂ËΩâÂûãÊΩõÂäõ‰ª•Âèä‰øùË≠∑ÊïèÊÑüÂÅ•Â∫∑Ë≥áË®äÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÅ•Â∫∑‰øùÈö™ÂèØÊîúÊÄßÂíåË≤¨‰ªªÊ≥ïÊ°à (HIPAA) ‰ΩúÁÇ∫Á¢∫‰øùË≥áÊñôÈö±ÁßÅÂíåÂÆâÂÖ®ÁöÑÊ≥ïË¶èÊû∂ÊßãÁöÑËßíËâ≤ÔºåÂº∑Ë™øÂú® AI È©ÖÂãïÁöÑÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂÅ•ÂÖ®‰øùÈöúÊé™ÊñΩÂíåÈÅìÂæ∑Ê®ôÊ∫ñÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÂåÖÊã¨ AI Âú®Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆä„ÄÅËÖ´Áò§Â≠∏‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÂúçÁπûË≥áÊñôÂÖ±‰∫´ÁöÑÁà≠Ë≠∞ÔºåÂº∑Ë™ø‰∫Ü AI ÂØ¶ÊñΩÁöÑÂÄ´ÁêÜÂíåÊ≥ïÂæãË§áÈõúÊÄß„ÄÇ‰∏ÄÁ®ÆÂπ≥Ë°°ÁöÑÊñπÊ≥ïÔºåÂú®‰øÉÈÄ≤ÂâµÊñ∞ÁöÑÂêåÊôÇÔºåÁ∂≠Ë≠∑ÊÇ£ËÄÖÁöÑ‰ø°‰ªªÂíåÈö±ÁßÅÔºåËá≥ÈóúÈáçË¶Å„ÄÇÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÊåÅÁ∫åÊïôËÇ≤„ÄÅÈÄèÊòéÂ∫¶ÂíåÈÅµÂÆàÊ≥ïË¶èÊ°ÜÊû∂ÁöÑÈáçË¶ÅÊÄßÔºå‰ª•Ë≤†Ë≤¨‰ªª‰∏îÂêà‰πéÈÅìÂæ∑ÁöÑÊñπÂºèÂà©Áî® AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÖ®ÈÉ®ÊΩõÂäõ„ÄÇ

##### **Merging Context Clustering with Visual State Space Models for Medical Image Segmentation**
2501.01618v1 by Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang

Medical image segmentation demands the aggregation of global and local
feature representations, posing a challenge for current methodologies in
handling both long-range and short-range feature interactions. Recently, vision
mamba (ViM) models have emerged as promising solutions for addressing model
complexities by excelling in long-range feature iterations with linear
complexity. However, existing ViM approaches overlook the importance of
preserving short-range local dependencies by directly flattening spatial tokens
and are constrained by fixed scanning patterns that limit the capture of
dynamic spatial context information. To address these challenges, we introduce
a simple yet effective method named context clustering ViM (CCViM), which
incorporates a context clustering module within the existing ViM models to
segment image tokens into distinct windows for adaptable local clustering. Our
method effectively combines long-range and short-range feature interactions,
thereby enhancing spatial contextual representations for medical image
segmentation tasks. Extensive experimental evaluations on diverse public
datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the
superior performance of our method compared to current state-of-the-art
methods. Our code can be found at https://github.com/zymissy/CCViM.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÂâ≤ÈúÄË¶ÅËÅöÂêàÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÁâπÂæµË°®Á§∫ÔºåÂ∞çÁï∂ÂâçÊñπÊ≥ïËôïÁêÜÈï∑Á®ãÂíåÁü≠Á®ãÁâπÂæµ‰∫§‰∫íÊßãÊàêÊåëÊà∞„ÄÇÊúÄËøëÔºåË¶ñË¶∫ÊõºÂ∑¥ (ViM) Ê®°ÂûãÂ∑≤ÊàêÁÇ∫Ëß£Ê±∫Ê®°ÂûãË§áÈõúÊÄßÁöÑÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂÆÉÂú®Á∑öÊÄßË§áÈõúÂ∫¶‰∏ãÊìÖÈï∑Èï∑Á®ãÁâπÂæµËø≠‰ª£„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ ViM ÊñπÊ≥ïÂøΩË¶ñ‰∫ÜÈÄèÈÅéÁõ¥Êé•Â£ìÂπ≥Á©∫ÈñìÊ®ôË®ò‰æÜ‰øùÁïôÁü≠Á®ãÂ±ÄÈÉ®‰æùË≥¥ÊÄßÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶‰∏îÂèóÂà∞ÈôêÂà∂ÁöÑÊéÉÊèèÊ®°ÂºèÁöÑÁ¥ÑÊùüÔºåÈÄôÊúÉÈôêÂà∂ÂãïÊÖãÁ©∫ÈñìËÉåÊôØË≥áË®äÁöÑÊì∑Âèñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ËÉåÊôØËÅöÈ°û ViM (CCViM) ÁöÑÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂÆÉÂú®ÁèæÊúâÁöÑ ViM Ê®°Âûã‰∏≠Âä†ÂÖ•‰∫Ü‰∏ÄÂÄãËÉåÊôØËÅöÈ°ûÊ®°ÁµÑÔºåÂ∞áÂΩ±ÂÉèÊ®ôË®òÂàÜÂâ≤Êàê‰∏çÂêåÁöÑË¶ñÁ™óÔºå‰ª•ÈÄ≤Ë°åÈÅ©ÊáâÊÄßÂ±ÄÈÉ®ËÅöÈ°û„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊúâÊïàÂú∞ÁµêÂêà‰∫ÜÈï∑Á®ãÂíåÁü≠Á®ãÁâπÂæµ‰∫§‰∫íÔºåÂæûËÄåÂ¢ûÂº∑‰∫ÜÁî®ÊñºÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂãôÁöÑÁ©∫ÈñìËÉåÊôØË°®Á§∫„ÄÇÂú®ÂêÑÁ®ÆÂÖ¨ÈñãË≥áÊñôÈõÜÔºàÂç≥ Kumar„ÄÅCPM17„ÄÅISIC17„ÄÅISIC18 Âíå SynapseÔºâ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïËàáÁï∂ÂâçÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÂÖ∑ÊúâÂçìË∂äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://github.com/zymissy/CCViM ÊâæÂà∞„ÄÇ

##### **PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents**
2501.01594v1 by Jingoo Lee, Kyungho Lim, Young-Chul Jung, Byung-Hoon Kim

Recent advances in large language models (LLMs) have accelerated the
development of conversational agents capable of generating human-like
responses. Since psychiatric assessments typically involve complex
conversational interactions between psychiatrists and patients, there is
growing interest in developing LLM-based psychiatric assessment conversational
agents (PACAs) that aim to simulate the role of psychiatrists in clinical
evaluations. However, standardized methods for benchmarking the clinical
appropriateness of PACAs' interaction with patients still remain underexplored.
Here, we propose PSYCHE, a novel framework designed to enable the 1) clinically
relevant, 2) ethically safe, 3) cost-efficient, and 4) quantitative evaluation
of PACAs. This is achieved by simulating psychiatric patients based on a
multi-faceted psychiatric construct that defines the simulated patients'
profiles, histories, and behaviors, which PACAs are expected to assess. We
validate the effectiveness of PSYCHE through a study with 10 board-certified
psychiatrists, supported by an in-depth analysis of the simulated patient
utterances.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂä†ÈÄü‰∫ÜÊúÉË©±‰ª£ÁêÜÁöÑÈñãÁôºÔºåÈÄô‰∫õ‰ª£ÁêÜËÉΩÂ§†Áî¢ÁîüÈ°û‰ºº‰∫∫È°ûÁöÑÂõûÊáâ„ÄÇÁî±ÊñºÁ≤æÁ•ûÁßëË©ï‰º∞ÈÄöÂ∏∏Ê∂âÂèäÁ≤æÁ•ûÁßëÈÜ´Â∏´ÂíåÊÇ£ËÄÖ‰πãÈñìË§áÈõúÁöÑÊúÉË©±‰∫íÂãïÔºåÂõ†Ê≠§Â∞çÊñºÈñãÁôºÂü∫Êñº LLM ÁöÑÁ≤æÁ•ûÁßëË©ï‰º∞ÊúÉË©±‰ª£ÁêÜ (PACA) ÁöÑËààË∂£ËàáÊó•‰ø±Â¢ûÔºåÈÄô‰∫õ‰ª£ÁêÜÊó®Âú®Ê®°Êì¨Á≤æÁ•ûÁßëÈÜ´Â∏´Âú®Ëá®Â∫äË©ï‰º∞‰∏≠ÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÁî®ÊñºË©ïÈáè PACA ËàáÊÇ£ËÄÖ‰∫íÂãïÁöÑËá®Â∫äÈÅ©Áï∂ÊÄßÁöÑÊ®ôÊ∫ñÂåñÊñπÊ≥ï‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ PSYCHEÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÂØ¶Áèæ 1) Ëá®Â∫äÁõ∏Èóú„ÄÅ2) ÈÅìÂæ∑ÂÆâÂÖ®„ÄÅ3) ÊàêÊú¨ÊïàÁõäÔºå‰ª•Âèä 4) PACA ÁöÑÂÆöÈáèË©ï‰º∞„ÄÇÈÄôÊòØÈÄèÈÅéÊ®°Êì¨Âü∫ÊñºÂ§öÈù¢ÂêëÁ≤æÁ•ûÁßëÂª∫ÊßãÁöÑÁ≤æÁ•ûÁßëÊÇ£ËÄÖ‰æÜÂØ¶ÁèæÁöÑÔºåË©≤Âª∫ÊßãÂÆöÁæ©‰∫ÜÊ®°Êì¨ÊÇ£ËÄÖÁöÑÂÄã‰∫∫Ë≥áÊñô„ÄÅÁóÖÂè≤ÂíåË°åÁÇ∫ÔºåËÄå PACA È†êË®àÊúÉË©ï‰º∞ÈÄô‰∫õÂÖßÂÆπ„ÄÇÊàëÂÄëÈÄèÈÅé‰∏ÄÈ†ÖÊúâ 10 ‰ΩçÁ∂ìË™çË≠âÁöÑÁ≤æÁ•ûÁßëÈÜ´Â∏´ÂèÉËàáÁöÑÁ†îÁ©∂È©óË≠â‰∫Ü PSYCHE ÁöÑÊúâÊïàÊÄßÔºå‰∏¶Ëºî‰ª•Â∞çÊ®°Êì¨ÊÇ£ËÄÖË©±Ë™ûÁöÑÊ∑±ÂÖ•ÂàÜÊûê„ÄÇ

##### **Model Checking in Medical Imaging for Tumor Detection and Segmentation**
2501.02024v2 by Elhoucine Elfatimi, Lahcen El fatimi

Recent advancements in model checking have demonstrated significant potential
across diverse applications, particularly in signal and image analysis. Medical
imaging stands out as a critical domain where model checking can be effectively
applied to design and evaluate robust frameworks. These frameworks facilitate
automatic and semi-automatic delineation of regions of interest within images,
aiding in accurate segmentation. This paper provides a comprehensive analysis
of recent works leveraging spatial logic to develop operators and tools for
identifying regions of interest, including tumorous and non-tumorous areas.
Additionally, we examine the challenges inherent to spatial model-checking
techniques, such as variability in ground truth data and the need for
streamlined procedures suitable for routine clinical practice.

ÊëòË¶ÅÔºöËøë‰æÜÊ®°ÂûãÊ™¢ÂÆöÁöÑÈÄ≤Â±ïÈ°ØÁ§∫Âá∫Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë®äËôüÂíåÂΩ±ÂÉèÂàÜÊûê‰∏≠„ÄÇÈÜ´ÁôÇÊàêÂÉè‰ΩúÁÇ∫‰∏ÄÂÄãÈóúÈçµÈ†òÂüüÔºåÊ®°ÂûãÊ™¢ÂÆöÂèØ‰ª•ÊúâÊïàÂú∞ÊáâÁî®ÊñºË®≠Ë®àÂíåË©ï‰º∞Á©©ÂÅ•ÁöÑÊû∂Êßã„ÄÇÈÄô‰∫õÊû∂ÊßãÊúâÂä©ÊñºËá™ÂãïÂíåÂçäËá™ÂãïÂú∞ÊèèÁπ™ÂΩ±ÂÉè‰∏≠ÁöÑÊÑüËààË∂£ÂçÄÂüüÔºåÊúâÂä©ÊñºÊ∫ñÁ¢∫ÁöÑÂàÜÂâ≤„ÄÇÊú¨ÊñáÂ∞çËøë‰æÜÂà©Áî®Á©∫ÈñìÈÇèËºØÈñãÁôºÈÅãÁÆóÂ≠êÂíåÂ∑•ÂÖ∑‰ª•Ë≠òÂà•ÊÑüËààË∂£ÂçÄÂüüÔºàÂåÖÊã¨ËÖ´Áò§ÂíåÈùûËÖ´Áò§ÂçÄÂüüÔºâÁöÑÁõ∏ÈóúÁ†îÁ©∂ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ©∫ÈñìÊ®°ÂûãÊ™¢ÂÆöÊäÄË°ìÂõ∫ÊúâÁöÑÊåëÊà∞Ôºå‰æãÂ¶ÇÂü∫Êú¨‰∫ãÂØ¶Ë≥áÊñôÁöÑÂèØËÆäÊÄß‰ª•ÂèäÂ∞çÈÅ©ÂêàÂ∏∏Ë¶èËá®Â∫äÂØ¶ÂãôÁöÑÁ∞°ÂåñÁ®ãÂ∫èÁöÑÈúÄÊ±Ç„ÄÇ

##### **Training Medical Large Vision-Language Models with Abnormal-Aware Feedback**
2501.01377v1 by Yucheng Zhou, Lingran Song, Jianbing Shen

Existing Medical Large Vision-Language Models (Med-LVLMs), which encapsulate
extensive medical knowledge, demonstrate excellent capabilities in
understanding medical images and responding to human queries based on these
images. However, there remain challenges in visual localization in medical
images, which is crucial for abnormality detection and interpretation. To
address these issues, we propose a novel UMed-LVLM designed with Unveiling
Medical abnormalities. Specifically, we collect a Medical Abnormalities
Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM
training. To collect MAU dataset, we propose a prompt method utilizing the
GPT-4V to generate diagnoses based on identified abnormal areas in medical
images. Moreover, the two-stage training method includes Abnormal-Aware
Instruction Tuning and Abnormal-Aware Rewarding, comprising Abnormal
Localization Rewarding and Vision Relevance Rewarding. Experimental results
demonstrate that our UMed-LVLM surpasses existing Med-LVLMs in identifying and
understanding medical abnormality. In addition, this work shows that enhancing
the abnormality detection capabilities of Med-LVLMs significantly improves
their understanding of medical images and generalization capability.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÈÜ´ÁôÇÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (Med-LVLMs) Â∞ÅË£ù‰∫ÜÂª£Ê≥õÁöÑÈÜ´ÁôÇÁü•Ë≠òÔºåÂú®ÁêÜËß£ÈÜ´ÁôÇÂΩ±ÂÉèÂíåÊ†πÊìöÈÄô‰∫õÂΩ±ÂÉèÂõûÊáâ‰∫∫È°ûÊü•Ë©¢ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÈÄ≤Ë°åË¶ñË¶∫ÂÆö‰Ωç‰ªçÂ≠òÂú®ÊåëÊà∞ÔºåÈÄôÂ∞çÊñºÁï∞Â∏∏ÂÅµÊ∏¨ÂíåËß£ËÆÄËá≥ÈóúÈáçË¶Å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ UMed-LVLMÔºåÂÖ∂Ë®≠Ë®àÁî®ÊñºÊè≠Á§∫ÈÜ´ÁôÇÁï∞Â∏∏„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü‰∏ÄÂÄãÈÜ´ÁôÇÁï∞Â∏∏Êè≠Á§∫ (MAU) Ë≥áÊñôÈõÜÔºå‰∏¶ÁÇ∫ UMed-LVLM Ë®ìÁ∑¥ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµË®ìÁ∑¥ÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊî∂ÈõÜ MAU Ë≥áÊñôÈõÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊèêÁ§∫ÊñπÊ≥ïÔºåÂà©Áî® GPT-4V Ê†πÊìöÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠Ë≠òÂà•Âá∫ÁöÑÁï∞Â∏∏ÂçÄÂüüÁîüÊàêË®∫Êñ∑„ÄÇÊ≠§Â§ñÔºåÂÖ©ÈöéÊÆµË®ìÁ∑¥ÊñπÊ≥ïÂåÖÊã¨Áï∞Â∏∏ÊÑüÁü•ÊåáÂ∞éË™øÊï¥ÂíåÁï∞Â∏∏ÊÑüÁü•ÁçéÂãµÔºåÂåÖÊã¨Áï∞Â∏∏ÂÆö‰ΩçÁçéÂãµÂíåË¶ñË¶∫Áõ∏ÈóúÊÄßÁçéÂãµ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑ UMed-LVLM Âú®Ë≠òÂà•ÂíåÁêÜËß£ÈÜ´ÁôÇÁï∞Â∏∏ÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÁöÑ Med-LVLMs„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÂ∑•‰ΩúË°®ÊòéÔºåÂ¢ûÂº∑ Med-LVLMs ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨ËÉΩÂäõÂèØ‰ª•È°ØËëóÊèêÂçáÂÆÉÂÄëÂ∞çÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÁêÜËß£ÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **ScarNet: A Novel Foundation Model for Automated Myocardial Scar Quantification from LGE in Cardiac MRI**
2501.01372v1 by Neda Tavakoli, Amir Ali Rahsepar, Brandon C. Benefield, Daming Shen, Santiago L√≥pez-Tapia, Florian Schiffers, Jeffrey J. Goldberger, Christine M. Albert, Edwin Wu, Aggelos K. Katsaggelos, Daniel C. Lee, Daniel Kim

Background: Late Gadolinium Enhancement (LGE) imaging is the gold standard
for assessing myocardial fibrosis and scarring, with left ventricular (LV) LGE
extent predicting major adverse cardiac events (MACE). Despite its importance,
routine LGE-based LV scar quantification is hindered by labor-intensive manual
segmentation and inter-observer variability. Methods: We propose ScarNet, a
hybrid model combining a transformer-based encoder from the Medical Segment
Anything Model (MedSAM) with a convolution-based U-Net decoder, enhanced by
tailored attention blocks. ScarNet was trained on 552 ischemic cardiomyopathy
patients with expert segmentations of myocardial and scar boundaries and tested
on 184 separate patients. Results: ScarNet achieved robust scar segmentation in
184 test patients, yielding a median Dice score of 0.912 (IQR: 0.863--0.944),
significantly outperforming MedSAM (median Dice = 0.046, IQR: 0.043--0.047) and
nnU-Net (median Dice = 0.638, IQR: 0.604--0.661). ScarNet demonstrated lower
bias (-0.63%) and coefficient of variation (4.3%) compared to MedSAM (bias:
-13.31%, CoV: 130.3%) and nnU-Net (bias: -2.46%, CoV: 20.3%). In Monte Carlo
simulations with noise perturbations, ScarNet achieved significantly higher
scar Dice (0.892 \pm 0.053, CoV = 5.9%) than MedSAM (0.048 \pm 0.112, CoV =
233.3%) and nnU-Net (0.615 \pm 0.537, CoV = 28.7%). Conclusion: ScarNet
outperformed MedSAM and nnU-Net in accurately segmenting myocardial and scar
boundaries in LGE images. The model exhibited robust performance across diverse
image qualities and scar patterns.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÂª∂ËøüÈíÜÂ¢ûÂº∫ÔºàLGEÔºâÊàêÂÉèÁî®‰∫éËØÑ‰º∞ÂøÉËÇåÁ∫§Áª¥ÂåñÂíåÁò¢ÁóïÁöÑÈªÑÈáëÊ†áÂáÜÔºåÂ∑¶ÂøÉÂÆ§ (LV) LGE ËåÉÂõ¥È¢ÑÊµãÈáçÂ§ßÁöÑÂøÉËÑè‰∏çËâØ‰∫ã‰ª∂ (MACE)„ÄÇÂ∞ΩÁÆ°ÂÖ∂ÈáçË¶ÅÊÄßÔºå‰ΩÜÂü∫‰∫é LGE ÁöÑÂ∏∏ËßÑ LV Áò¢ÁóïÈáèÂåñÂèóÂà∞Âä≥Âä®ÂØÜÈõÜÂûãÊâãÂä®ÂàÜÂâ≤ÂíåËßÇÂØüËÄÖÈó¥Â∑ÆÂºÇÁöÑÈòªÁ¢ç„ÄÇÊñπÊ≥ïÔºöÊàë‰ª¨ÊèêÂá∫ ScarNetÔºå‰∏ÄÁßçÊ∑∑ÂêàÊ®°ÂûãÔºåÂÆÉÂ∞ÜÊù•Ëá™ÂåªÂ≠¶ÂàÜÂâ≤‰ªª‰ΩïÊ®°Âûã (MedSAM) ÁöÑÂü∫‰∫é Transformer ÁöÑÁºñÁ†ÅÂô®‰∏éÂü∫‰∫éÂç∑ÁßØÁöÑ U-Net Ëß£Á†ÅÂô®Áõ∏ÁªìÂêàÔºåÂπ∂ÈÄöËøáÂÆöÂà∂ÁöÑÊ≥®ÊÑèÂäõÂùóËøõË°åÂ¢ûÂº∫„ÄÇScarNet Âú® 552 ‰æãÁº∫Ë°ÄÊÄßÂøÉËÇåÁóÖÊÇ£ËÄÖ‰∏äÊé•ÂèóËÆ≠ÁªÉÔºåËøô‰∫õÊÇ£ËÄÖÁöÑÂøÉËÇåÂíåÁò¢ÁóïËæπÁïåÁî±‰∏ìÂÆ∂ÂàÜÂâ≤ÔºåÂπ∂Âú® 184 ‰æãÂçïÁã¨ÊÇ£ËÄÖ‰∏äËøõË°åÊµãËØï„ÄÇÁªìÊûúÔºöScarNet Âú® 184 ‰æãÊµãËØïÊÇ£ËÄÖ‰∏≠ÂÆûÁé∞‰∫ÜÁ®≥ÂÅ•ÁöÑÁò¢ÁóïÂàÜÂâ≤Ôºå‰∫ßÁîü 0.912 ÁöÑ‰∏≠ÂÄº Dice ÂæóÂàÜÔºàIQRÔºö0.863--0.944ÔºâÔºåÊòéÊòæ‰ºò‰∫é MedSAMÔºà‰∏≠ÂÄº Dice = 0.046ÔºåIQRÔºö0.043--0.047ÔºâÂíå nnU-NetÔºà‰∏≠ÂÄº Dice = 0.638ÔºåIQRÔºö0.604--0.661Ôºâ„ÄÇ‰∏é MedSAMÔºàÂÅèÂ∑ÆÔºö-13.31%ÔºåCoVÔºö130.3%ÔºâÂíå nnU-NetÔºàÂÅèÂ∑ÆÔºö-2.46%ÔºåCoVÔºö20.3%ÔºâÁõ∏ÊØîÔºåScarNet Ë°®Áé∞Âá∫ËæÉ‰ΩéÁöÑÂÅèÂ∑ÆÔºà-0.63%ÔºâÂíåÂèòÂºÇÁ≥ªÊï∞Ôºà4.3%Ôºâ„ÄÇÂú®Â∏¶ÊúâÂô™Â£∞Êâ∞Âä®ÁöÑËíôÁâπÂç°ÁΩóÊ®°Êãü‰∏≠ÔºåScarNet ÂÆûÁé∞‰∫ÜÊòéÊòæÈ´ò‰∫é MedSAMÔºà0.048 ¬± 0.112ÔºåCoV = 233.3%ÔºâÂíå nnU-NetÔºà0.615 ¬± 0.537ÔºåCoV = 28.7%ÔºâÁöÑÁò¢Áóï DiceÔºà0.892 ¬± 0.053ÔºåCoV = 5.9%Ôºâ„ÄÇÁªìËÆ∫ÔºöScarNet Âú®ÂáÜÁ°ÆÂàÜÂâ≤ LGE ÂõæÂÉè‰∏≠ÁöÑÂøÉËÇåÂíåÁò¢ÁóïËæπÁïåÊñπÈù¢‰ºò‰∫é MedSAM Âíå nnU-Net„ÄÇËØ•Ê®°ÂûãÂú®‰∏çÂêåÁöÑÂõæÂÉèË¥®ÈáèÂíåÁò¢ÁóïÊ®°Âºè‰∏ãË°®Áé∞Âá∫Á®≥ÂÅ•ÁöÑÊÄßËÉΩ„ÄÇ</paragraph>

##### **Contrastive Learning from Exploratory Actions: Leveraging Natural Interactions for Preference Elicitation**
2501.01367v1 by Nathaniel Dennler, Stefanos Nikolaidis, Maja Matariƒá

People have a variety of preferences for how robots behave. To understand and
reason about these preferences, robots aim to learn a reward function that
describes how aligned robot behaviors are with a user's preferences. Good
representations of a robot's behavior can significantly reduce the time and
effort required for a user to teach the robot their preferences. Specifying
these representations -- what "features" of the robot's behavior matter to
users -- remains a difficult problem; Features learned from raw data lack
semantic meaning and features learned from user data require users to engage in
tedious labeling processes. Our key insight is that users tasked with
customizing a robot are intrinsically motivated to produce labels through
exploratory search; they explore behaviors that they find interesting and
ignore behaviors that are irrelevant. To harness this novel data source of
exploratory actions, we propose contrastive learning from exploratory actions
(CLEA) to learn trajectory features that are aligned with features that users
care about. We learned CLEA features from exploratory actions users performed
in an open-ended signal design activity (N=25) with a Kuri robot, and evaluated
CLEA features through a second user study with a different set of users (N=42).
CLEA features outperformed self-supervised features when eliciting user
preferences over four metrics: completeness, simplicity, minimality, and
explainability.

ÊëòË¶ÅÔºö‰∫∫ÂÄëÂ∞çÊñºÊ©üÂô®‰∫∫ÁöÑË°åÁÇ∫ÊñπÂºèÊúâÂêÑÁ®ÆÂÅèÂ•Ω„ÄÇÁÇ∫‰∫ÜÁêÜËß£ÂíåÊé®Ë´ñÈÄô‰∫õÂÅèÂ•ΩÔºåÊ©üÂô®‰∫∫Êó®Âú®Â≠∏Áøí‰∏ÄÂÄãÁçéÂãµÂáΩÊï∏ÔºåË™™ÊòéÊ©üÂô®‰∫∫ÁöÑË°åÁÇ∫Ëàá‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•ΩÊúâÂ§öÈ∫º‰∏ÄËá¥„ÄÇËâØÂ•ΩÁöÑÊ©üÂô®‰∫∫Ë°åÁÇ∫Ë°®Á§∫ÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ë‰ΩøÁî®ËÄÖÊïôÂ∞éÊ©üÂô®‰∫∫ÂÖ∂ÂÅèÂ•ΩÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõ„ÄÇË™™ÊòéÈÄô‰∫õË°®Á§∫‚Äî‚ÄîÊ©üÂô®‰∫∫Ë°åÁÇ∫ÁöÑÂì™‰∫õ„ÄåÁâπÂæµ„ÄçÂ∞ç‰ΩøÁî®ËÄÖ‰æÜË™™ÂæàÈáçË¶Å‚Äî‚Äî‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂõ∞Èõ£ÁöÑÂïèÈ°åÔºõÂæûÂéüÂßãË≥áÊñôÂ≠∏ÁøíÂà∞ÁöÑÁâπÂæµÁº∫‰πèË™ûÊÑèÊÑèÁæ©ÔºåËÄåÂæû‰ΩøÁî®ËÄÖË≥áÊñôÂ≠∏ÁøíÂà∞ÁöÑÁâπÂæµÈúÄË¶Å‰ΩøÁî®ËÄÖÂèÉËàáÁπÅÁë£ÁöÑÊ®ôÁ±§ËôïÁêÜÁ®ãÂ∫è„ÄÇÊàëÂÄëÁöÑÈóúÈçµË¶ãËß£ÊòØÔºåË≤†Ë≤¨Ëá™Ë®ÇÊ©üÂô®‰∫∫ÁöÑ‰ΩøÁî®ËÄÖÊú¨Ë≥™‰∏äÊúÉÈÄèÈÅéÊé¢Á¥¢ÊÄßÊêúÂ∞ãÁî¢ÁîüÊ®ôÁ±§Ôºõ‰ªñÂÄëÊúÉÊé¢Á¥¢‰ªñÂÄëË¶∫ÂæóÊúâË∂£ÁöÑË°åÁÇ∫Ôºå‰∏¶ÂøΩÁï•‰∏çÁõ∏ÈóúÁöÑË°åÁÇ∫„ÄÇÁÇ∫‰∫ÜÂà©Áî®ÈÄôÂÄãÊé¢Á¥¢ÊÄßÂãï‰ΩúÁöÑÊñ∞Á©éË≥áÊñô‰æÜÊ∫êÔºåÊàëÂÄëÊèêÂá∫ÂæûÊé¢Á¥¢ÊÄßÂãï‰Ωú‰∏≠ÈÄ≤Ë°åÂ∞çÊØîÂ≠∏Áøí (CLEA)Ôºå‰ª•Â≠∏ÁøíËàá‰ΩøÁî®ËÄÖÈóúÂøÉÁöÑÁâπÂæµ‰∏ÄËá¥ÁöÑËªåË∑°ÁâπÂæµ„ÄÇÊàëÂÄëÂæû‰ΩøÁî®ËÄÖÂú®Ëàá Kuri Ê©üÂô®‰∫∫ÁöÑÈñãÊîæÂºèË®äËôüË®≠Ë®àÊ¥ªÂãï (N=25) ‰∏≠Âü∑Ë°åÁöÑÊé¢Á¥¢ÊÄßÂãï‰Ωú‰∏≠Â≠∏Áøí‰∫Ü CLEA ÁâπÂæµÔºå‰∏¶ÈÄèÈÅéÁ¨¨‰∫åÂÄã‰ΩøÁî®ËÄÖÁ†îÁ©∂Â∞ç CLEA ÁâπÂæµÈÄ≤Ë°åË©ï‰º∞ÔºåË©≤Á†îÁ©∂‰ΩøÁî®‰∫Ü‰∏ÄÁµÑ‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖ (N=42)„ÄÇÂú®ÂºïÂá∫‰ΩøÁî®ËÄÖÂÅèÂ•ΩÊôÇÔºåCLEA ÁâπÂæµÂú®ÂõõÂÄãÊåáÊ®ô‰∏äÂÑ™ÊñºËá™Áõ£Áù£ÁâπÂæµÔºöÂÆåÊï¥ÊÄß„ÄÅÁ∞°ÊΩîÊÄß„ÄÅÊúÄÂ∞èÊÄß„ÄÅÂèØËß£ÈáãÊÄß„ÄÇ

##### **Multi-Head Explainer: A General Framework to Improve Explainability in CNNs and Transformers**
2501.01311v2 by Bohang Sun, Pietro Li√≤

In this study, we introduce the Multi-Head Explainer (MHEX), a versatile and
modular framework that enhances both the explainability and accuracy of
Convolutional Neural Networks (CNNs) and Transformer-based models. MHEX
consists of three core components: an Attention Gate that dynamically
highlights task-relevant features, Deep Supervision that guides early layers to
capture fine-grained details pertinent to the target class, and an Equivalent
Matrix that unifies refined local and global representations to generate
comprehensive saliency maps. Our approach demonstrates superior compatibility,
enabling effortless integration into existing residual networks like ResNet and
Transformer architectures such as BERT with minimal modifications. Extensive
experiments on benchmark datasets in medical imaging and text classification
show that MHEX not only improves classification accuracy but also produces
highly interpretable and detailed saliency scores.

ÊëòË¶ÅÔºöÂú®Êú¨Ê¨°Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂ§öÈ†≠Ëß£ÈáãÂô® (MHEX)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÂäüËÉΩ‰∏îÊ®°ÁµÑÂåñÁöÑÊû∂ÊßãÔºåÂèØÂ¢ûÂº∑Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âíå Transformer Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇMHEX ÂåÖÂê´‰∏âÂÄãÊ†∏ÂøÉÁµÑÊàêÈÉ®ÂàÜÔºöÂãïÊÖãÁ™ÅÈ°ØËàá‰ªªÂãôÁõ∏ÈóúÁâπÂæµÁöÑÊ≥®ÊÑèÂäõÈñòÈñÄ„ÄÅÂºïÂ∞éÊó©ÊúüÂ±§ÊçïÊçâËàáÁõÆÊ®ôÈ°ûÂà•Áõ∏ÈóúÁöÑÁ¥∞ÂæÆÁ¥∞ÁØÄÁöÑÊ∑±Â∫¶Áõ£Áù£Ôºå‰ª•ÂèäÁµ±‰∏ÄÁ≤æÁ∑ªÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄË°®Á§∫‰ª•Áî¢ÁîüÂÖ®Èù¢È°ØËëóÊÄßÂúñÁöÑÁ≠âÊïàÁü©Èô£„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÁõ∏ÂÆπÊÄßÔºåËÉΩËºïÈ¨ÜÊï¥ÂêàÂà∞ÁèæÊúâÁöÑÊÆòÂ∑ÆÁ∂≤Ë∑ØÔºàÂ¶Ç ResNetÔºâÂíå Transformer Êû∂ÊßãÔºàÂ¶Ç BERTÔºâÔºå‰∏îÂè™ÈúÄÈÄ≤Ë°åÊúÄÂ∞èÁöÑ‰øÆÊîπ„ÄÇÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊñáÂ≠óÂàÜÈ°ûÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåMHEX ‰∏çÂÉÖËÉΩÊèêÂçáÂàÜÈ°ûÊ∫ñÁ¢∫ÊÄßÔºåÈÇÑËÉΩÁî¢ÁîüÈ´òÂ∫¶ÂèØËß£Èáã‰∏îË©≥Á¥∞ÁöÑÈ°ØËëóÊÄßÂàÜÊï∏„ÄÇ

##### **Machine Learning-Based Differential Diagnosis of Parkinson's Disease Using Kinematic Feature Extraction and Selection**
2501.02014v1 by Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin

Parkinson's disease (PD), the second most common neurodegenerative disorder,
is characterized by dopaminergic neuron loss and the accumulation of abnormal
synuclein. PD presents both motor and non-motor symptoms that progressively
impair daily functioning. The severity of these symptoms is typically assessed
using the MDS-UPDRS rating scale, which is subjective and dependent on the
physician's experience. Additionally, PD shares symptoms with other
neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and
multiple system atrophy (MSA), complicating accurate diagnosis. To address
these diagnostic challenges, we propose a machine learning-based system for
differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system
utilizes a kinematic feature-based hierarchical feature extraction and
selection approach. Initially, 18 kinematic features are extracted, including
two newly proposed features: Thumb-to-index vector velocity and acceleration,
which provide insights into motor control patterns. In addition, 41 statistical
features were extracted here from each kinematic feature, including some new
approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency,
Standard Deviation of Frequency, and Slope. Feature selection is performed
using One-way ANOVA to rank features, followed by Sequential Forward Floating
Selection (SFFS) to identify the most relevant ones, aiming to reduce the
computational complexity. The final feature set is used for classification,
achieving a classification accuracy of 66.67% for each dataset and 88.89% for
each patient, with particularly high performance for the MSA and HC groups
using the SVM algorithm. This system shows potential as a rapid and accurate
diagnostic tool in clinical practice, though further data collection and
refinement are needed to enhance its reliability.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóáÔºàPDÔºâÊòØÁ¨¨‰∫åÂ∏∏ËßÅÁöÑËÑëÁ•ûÁªèÈÄÄÂåñÊÄßÁñæÁóÖÔºå
ÂÖ∂ÁâπÂæÅÊòØÂ§öÂ∑¥ËÉ∫ËÉΩÁ•ûÁªèÂÖÉ‰∏ßÂ§±ÂíåÂºÇÂ∏∏Œ±-Á™ÅËß¶Ê†∏ËõãÁôΩÁöÑÁßØÁ¥Ø„ÄÇPD ÂêåÊó∂Âá∫Áé∞ËøêÂä®ÂíåÈùûËøêÂä®ÁóáÁä∂ÔºåËøô‰∫õÁóáÁä∂‰ºöÈÄêÊ∏êÊçüÂÆ≥Êó•Â∏∏ÂäüËÉΩ„ÄÇËøô‰∫õÁóáÁä∂ÁöÑ‰∏•ÈáçÁ®ãÂ∫¶ÈÄöÂ∏∏‰ΩøÁî® MDS-UPDRS ËØÑÂÆöÈáèË°®ËøõË°åËØÑ‰º∞ÔºåËØ•ÈáèË°®ÊòØ‰∏ªËßÇÁöÑÔºåÂπ∂‰∏î‰æùËµñ‰∫éÂåªÁîüÁöÑÁªèÈ™å„ÄÇÊ≠§Â§ñÔºåPD ‰∏éÂÖ∂‰ªñÁ•ûÁªèÈÄÄÂåñÊÄßÁñæÁóÖÔºà‰æãÂ¶ÇËøõË°åÊÄßÊ†∏‰∏äÊÄßÈ∫ªÁóπ (PSP) ÂíåÂ§öÁ≥ªÁªüËêéÁº© (MSA)ÔºâÊúâÁõ∏ÂêåÁöÑÁóáÁä∂ÔºåËøô‰ΩøÂæóÂáÜÁ°ÆËØäÊñ≠ÂèòÂæóÂ§çÊùÇ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õËØäÊñ≠ÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÁöÑÁ≥ªÁªüÔºåÁî®‰∫é PD„ÄÅPSP„ÄÅMSA ÂíåÂÅ•Â∫∑ÂØπÁÖß (HC) ÁöÑÈâ¥Âà´ËØäÊñ≠„ÄÇËØ•Á≥ªÁªüÂà©Áî®Âü∫‰∫éËøêÂä®Â≠¶ÁâπÂæÅÁöÑÂàÜÂ±ÇÁâπÂæÅÊèêÂèñÂíåÈÄâÊã©ÊñπÊ≥ï„ÄÇÊúÄÂàùÔºåÊèêÂèñ‰∫Ü 18 ‰∏™ËøêÂä®Â≠¶ÁâπÂæÅÔºåÂåÖÊã¨‰∏§‰∏™Êñ∞ÊèêÂá∫ÁöÑÁâπÂæÅÔºöÊãáÊåáÂà∞È£üÊåáÁöÑÁü¢ÈáèÈÄüÂ∫¶ÂíåÂä†ÈÄüÂ∫¶ÔºåÂÆÉ‰ª¨Êèê‰æõ‰∫ÜÂØπËøêÂä®ÊéßÂà∂Ê®°ÂºèÁöÑËßÅËß£„ÄÇÊ≠§Â§ñÔºåÊ≠§Â§Ñ‰ªéÊØè‰∏™ËøêÂä®Â≠¶ÁâπÂæÅ‰∏≠ÊèêÂèñ‰∫Ü 41 ‰∏™ÁªüËÆ°ÁâπÂæÅÔºåÂåÖÊã¨‰∏Ä‰∫õÊñ∞ÊñπÊ≥ïÔºå‰æãÂ¶ÇÂπ≥ÂùáÁªùÂØπÂèòÂåñ„ÄÅËäÇÂ•è„ÄÅÊåØÂπÖ„ÄÅÈ¢ëÁéá„ÄÅÈ¢ëÁéáÊ†áÂáÜÂ∑ÆÂíåÊñúÁéá„ÄÇ‰ΩøÁî®ÂçïÂêëÊñπÂ∑ÆÂàÜÊûêÂØπÁâπÂæÅËøõË°åÊéíÂêçÔºåÁÑ∂Âêé‰ΩøÁî®È°∫Â∫èÂâçÂêëÊµÆÂä®ÈÄâÊã© (SFFS) ËØÜÂà´ÊúÄÁõ∏ÂÖ≥ÁöÑÁâπÂæÅÔºå‰ª•Èôç‰ΩéËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÊúÄÁªàÁâπÂæÅÈõÜÁî®‰∫éÂàÜÁ±ªÔºåÂØπ‰∫éÊØè‰∏™Êï∞ÊçÆÈõÜÔºåÂàÜÁ±ªÂáÜÁ°ÆÁéáËææÂà∞ 66.67%ÔºåÂØπ‰∫éÊØè‰∏™ÊÇ£ËÄÖÔºåÂáÜÁ°ÆÁéáËææÂà∞ 88.89%Ôºå‰ΩøÁî® SVM ÁÆóÊ≥ïÊó∂ÔºåMSA Âíå HC ÁªÑÁöÑÊÄßËÉΩÂ∞§ÂÖ∂È´ò„ÄÇËØ•Á≥ªÁªüÊòæÁ§∫Âá∫‰Ωú‰∏∫‰∏¥Â∫äÂÆûË∑µ‰∏≠Âø´ÈÄü‰∏îÂáÜÁ°ÆÁöÑËØäÊñ≠Â∑•ÂÖ∑ÁöÑÊΩúÂäõÔºåÂ∞ΩÁÆ°ÈúÄË¶ÅËøõ‰∏ÄÊ≠•Êî∂ÈõÜÊï∞ÊçÆÂíåÊîπËøõ‰ª•Â¢ûÂº∫ÂÖ∂ÂèØÈù†ÊÄß„ÄÇ

##### **Data Augmentation Techniques for Chinese Disease Name Normalization**
2501.01195v1 by Wenqian Cui, Xiangling Fu, Shaohui Liu, Mingjun Gu, Xien Liu, Ji Wu, Irwin King

Disease name normalization is an important task in the medical domain. It
classifies disease names written in various formats into standardized names,
serving as a fundamental component in smart healthcare systems for various
disease-related functions. Nevertheless, the most significant obstacle to
existing disease name normalization systems is the severe shortage of training
data. Consequently, we present a novel data augmentation approach that includes
a series of data augmentation techniques and some supporting modules to help
mitigate the problem. Through extensive experimentation, we illustrate that our
proposed approach exhibits significant performance improvements across various
baseline models and training objectives, particularly in scenarios with limited
training data

ÊëòË¶ÅÔºöÁñæÁóÖÂêçÁ®±Ê≠£Ë¶èÂåñÊòØÈÜ´Â≠∏È†òÂüü‰∏≠‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇÂÆÉÂ∞á‰ª•ÂêÑÁ®ÆÊ†ºÂºèÊõ∏ÂØ´ÁöÑÁñæÁóÖÂêçÁ®±ÂàÜÈ°ûÁÇ∫Ê®ôÊ∫ñÂåñÂêçÁ®±Ôºå‰ΩúÁÇ∫Êô∫ÊÖßÈÜ´ÁôÇÁ≥ªÁµ±‰∏≠ÂêÑÁ®ÆÁñæÁóÖÁõ∏ÈóúÂäüËÉΩÁöÑÂü∫Êú¨ÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁñæÁóÖÂêçÁ®±Ê≠£Ë¶èÂåñÁ≥ªÁµ±ÊúÄÈ°ØËëóÁöÑÈöúÁ§ôÊòØË®ìÁ∑¥Ë≥áÊñôÂö¥ÈáçÁü≠Áº∫„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰∏ÄÁ≥ªÂàóË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÂíå‰∏Ä‰∫õËºîÂä©Ê®°ÁµÑÔºå‰ª•Âπ´Âä©Ê∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË™™ÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂêÑÁ®ÆÂü∫Á∑öÊ®°ÂûãÂíåË®ìÁ∑¥ÁõÆÊ®ô‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåÁâπÂà•ÊòØÂú®Ë®ìÁ∑¥Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ã

##### **Reasoning based on symbolic and parametric knowledge bases: a survey**
2501.01030v1 by Mayi Xu, Yunfeng Ning, Yongqi Li, Jianhao Chen, Jintao Wen, Yao Xiao, Shen Zhou, Birong Pan, Zepeng Bao, Xin Miao, Hankun Kang, Ke Sun, Tieyun Qian

Reasoning is fundamental to human intelligence, and critical for
problem-solving, decision-making, and critical thinking. Reasoning refers to
drawing new conclusions based on existing knowledge, which can support various
applications like clinical diagnosis, basic education, and financial analysis.
Though a good number of surveys have been proposed for reviewing
reasoning-related methods, none of them has systematically investigated these
methods from the viewpoint of their dependent knowledge base. Both the
scenarios to which the knowledge bases are applied and their storage formats
are significantly different. Hence, investigating reasoning methods from the
knowledge base perspective helps us better understand the challenges and future
directions. To fill this gap, this paper first classifies the knowledge base
into symbolic and parametric ones. The former explicitly stores information in
human-readable symbols, and the latter implicitly encodes knowledge within
parameters. Then, we provide a comprehensive overview of reasoning methods
using symbolic knowledge bases, parametric knowledge bases, and both of them.
Finally, we identify the future direction toward enhancing reasoning
capabilities to bridge the gap between human and machine intelligence.

ÊëòË¶ÅÔºöÊé®ÁêÜÊòØ‰∫∫Á±ªÊô∫ËÉΩÁöÑÂü∫Á°ÄÔºåÂØπ‰∫éËß£ÂÜ≥ÈóÆÈ¢ò„ÄÅÂÜ≥Á≠ñÂíåÊâπÂà§ÊÄßÊÄùÁª¥Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÊé®ÁêÜÊòØÊåáÊ†πÊçÆÁé∞ÊúâÁü•ËØÜÂæóÂá∫Êñ∞ÁöÑÁªìËÆ∫ÔºåËøôÂèØ‰ª•ÊîØÊåÅÂêÑÁßçÂ∫îÁî®Á®ãÂ∫èÔºåÂ¶Ç‰∏¥Â∫äËØäÊñ≠„ÄÅÂü∫Á°ÄÊïôËÇ≤ÂíåË¥¢Âä°ÂàÜÊûê„ÄÇÂ∞ΩÁÆ°Â∑≤ÁªèÊèêÂá∫‰∫ÜÂ§ßÈáèË∞ÉÊü•Êù•ÂÆ°Êü•‰∏éÊé®ÁêÜÁõ∏ÂÖ≥ÁöÑÂêÑÁßçÊñπÊ≥ïÔºå‰ΩÜÊ≤°Êúâ‰∏ÄÁßçÊñπÊ≥ï‰ªéÂÖ∂‰æùËµñÁü•ËØÜÂ∫ìÁöÑËßíÂ∫¶Á≥ªÁªüÂú∞Á†îÁ©∂Ëøô‰∫õÊñπÊ≥ï„ÄÇÁü•ËØÜÂ∫ìË¢´Â∫îÁî®Âà∞ÁöÑÂú∫ÊôØÂèäÂÖ∂Â≠òÂÇ®Ê†ºÂºèÈÉΩÊúâÊòæÁùÄÂ∑ÆÂºÇ„ÄÇÂõ†Ê≠§Ôºå‰ªéÁü•ËØÜÂ∫ìÁöÑËßíÂ∫¶Á†îÁ©∂Êé®ÁêÜÊñπÊ≥ïÊúâÂä©‰∫éÊàë‰ª¨Êõ¥Â•ΩÂú∞ÁêÜËß£ÊåëÊàòÂíåÊú™Êù•ÁöÑÊñπÂêë„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºåÊú¨ÊñáÈ¶ñÂÖàÂ∞ÜÁü•ËØÜÂ∫ìÂàÜ‰∏∫Á¨¶Âè∑Áü•ËØÜÂ∫ìÂíåÂèÇÊï∞Áü•ËØÜÂ∫ì„ÄÇÂâçËÄÖ‰ª•‰∫∫Á±ªÂèØËØªÁöÑÁ¨¶Âè∑ÊòéÁ°ÆÂ≠òÂÇ®‰ø°ÊÅØÔºåËÄåÂêéËÄÖÂàôÂú®ÂèÇÊï∞‰∏≠ÈöêÂºèÁºñÁ†ÅÁü•ËØÜ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂØπ‰ΩøÁî®Á¨¶Âè∑Áü•ËØÜÂ∫ì„ÄÅÂèÇÊï∞Áü•ËØÜÂ∫ì‰ª•Âèä‰∏§ËÄÖÁªìÂêàÁöÑÊé®ÁêÜÊñπÊ≥ïËøõË°å‰∫ÜÂÖ®Èù¢Ê¶ÇËø∞„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Á°ÆÂÆö‰∫ÜÂ¢ûÂº∫Êé®ÁêÜËÉΩÂäõ‰ª•Áº©Â∞è‰∫∫ÂíåÊú∫Âô®Êô∫ËÉΩ‰πãÈó¥Â∑ÆË∑ùÁöÑÊú™Êù•ÊñπÂêë„ÄÇ

##### **Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice**
2501.00982v1 by Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

In psychological practice, standardized questionnaires serve as essential
tools for assessing mental constructs (e.g., attitudes, traits, and emotions)
through structured questions (aka items). With the increasing prevalence of
social media platforms where users share personal experiences and emotions,
researchers are exploring computational methods to leverage this data for rapid
mental health screening. In this study, we propose a novel adaptive
Retrieval-Augmented Generation (RAG) approach that completes psychological
questionnaires by analyzing social media posts. Our method retrieves the most
relevant user posts for each question in a psychological survey and uses Large
Language Models (LLMs) to predict questionnaire scores in a zero-shot setting.
Our findings are twofold. First we demonstrate that this approach can
effectively predict users' responses to psychological questionnaires, such as
the Beck Depression Inventory II (BDI-II), achieving performance comparable to
or surpassing state-of-the-art models on Reddit-based benchmark datasets
without relying on training data. Second, we show how this methodology can be
generalized as a scalable screening tool, as the final assessment is
systematically derived by completing standardized questionnaires and tracking
how individual item responses contribute to the diagnosis, aligning with
established psychometric practices.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂøÉÁêÜÂ≠∏ÂØ¶Âãô‰∏≠ÔºåÊ®ôÊ∫ñÂåñÂïèÂç∑‰ΩúÁÇ∫Ë©ïÈáèÂøÉÁêÜÂª∫ÊßãÔºà‰æãÂ¶ÇÊÖãÂ∫¶„ÄÅÁâπË≥™ÂíåÊÉÖÁ∑íÔºâÁöÑÂøÖË¶ÅÂ∑•ÂÖ∑ÔºåÈÄèÈÅéÁµêÊßãÂåñÂïèÈ°åÔºàÂèàÁ®±È†ÖÁõÆÔºâ‰æÜÈÄ≤Ë°åË©ïÈáè„ÄÇÈö®ËëóÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºå‰ΩøÁî®ËÄÖÊúÉÂú®‰∏äÈù¢ÂàÜ‰∫´ÂÄã‰∫∫Á∂ìÈ©óÂíåÊÉÖÁ∑íÔºåÁ†îÁ©∂‰∫∫Âì°Ê≠£Âú®Êé¢Ë®éÈÅãÁÆóÊñπÊ≥ïÔºå‰ª•Âà©Áî®ÈÄô‰∫õË≥áÊñôÈÄ≤Ë°åÂø´ÈÄüÁöÑÁöÑÂøÉÁêÜÂÅ•Â∫∑ÁØ©Ê™¢„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÈÅ©ÊáâÊÄßÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÔºåÈÄèÈÅéÂàÜÊûêÁ§æÁæ§Â™íÈ´îË≤ºÊñá‰æÜÂÆåÊàêÂøÉÁêÜÂïèÂç∑„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÈáùÂ∞çÂøÉÁêÜË™øÊü•‰∏≠ÁöÑÊØèÂÄãÂïèÈ°åÔºåÊì∑ÂèñËàá‰πãÊúÄÁõ∏ÈóúÁöÑ‰ΩøÁî®ËÄÖË≤ºÊñáÔºå‰∏¶‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Èõ∂Ê¨°Â≠∏ÁøíÁöÑË®≠ÂÆö‰∏ãÈ†êÊ∏¨ÂïèÂç∑ÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊúâÂÖ©ÊñπÈù¢„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÈ†êÊ∏¨‰ΩøÁî®ËÄÖÂ∞çÂøÉÁêÜÂïèÂç∑ÁöÑÂõûÁ≠îÔºå‰æãÂ¶ÇË≤ùÂÖãÊÜÇÈ¨±ÈáèË°®Á¨¨‰∫åÁâàÔºàBDI-IIÔºâÔºåÂú®Âü∫Êñº Reddit ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫ÜËàáÊúÄÂÖàÈÄ≤Ê®°ÂûãÁõ∏Áï∂ÊàñË∂ÖË∂äÁöÑË°®ÁèæÔºåËÄå‰∏î‰∏¶Êú™‰æùË≥¥Ë®ìÁ∑¥Ë≥áÊñô„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÂÄãÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩË¢´Ê¶ÇÊã¨ÁÇ∫‰∏ÄÁ®ÆÂèØÊì¥ÂÖÖÁöÑÁØ©Ê™¢Â∑•ÂÖ∑ÔºåÂõ†ÁÇ∫ÊúÄÁµÇË©ïÈáèÊòØÈÄèÈÅéÂÆåÊàêÊ®ôÊ∫ñÂåñÂïèÂç∑‰∏¶ËøΩËπ§ÂÄãÂà•È†ÖÁõÆÂõûÁ≠îÂ¶Ç‰Ωï‰øÉÊàêË®∫Êñ∑ËÄåÁ≥ªÁµ±ÊÄßÂú∞ÂæóÂá∫ÁöÑÔºåÈÄôËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊ∏¨ÈáèÂØ¶ÂãôÁõ∏Á¨¶„ÄÇ</paragraph>

##### **Enhancing Early Diabetic Retinopathy Detection through Synthetic DR1 Image Generation: A StyleGAN3 Approach**
2501.00954v1 by Sagarnil Das, Pradeep Walia

Diabetic Retinopathy (DR) is a leading cause of preventable blindness. Early
detection at the DR1 stage is critical but is hindered by a scarcity of
high-quality fundus images. This study uses StyleGAN3 to generate synthetic DR1
images characterized by microaneurysms with high fidelity and diversity. The
aim is to address data scarcity and enhance the performance of supervised
classifiers. A dataset of 2,602 DR1 images was used to train the model,
followed by a comprehensive evaluation using quantitative metrics, including
Frechet Inception Distance (FID), Kernel Inception Distance (KID), and
Equivariance with respect to translation (EQ-T) and rotation (EQ-R).
Qualitative assessments included Human Turing tests, where trained
ophthalmologists evaluated the realism of synthetic images. Spectral analysis
further validated image quality. The model achieved a final FID score of 17.29,
outperforming the mean FID of 21.18 (95 percent confidence interval - 20.83 to
21.56) derived from bootstrap resampling. Human Turing tests demonstrated the
model's ability to produce highly realistic images, though minor artifacts near
the borders were noted. These findings suggest that StyleGAN3-generated
synthetic DR1 images hold significant promise for augmenting training datasets,
enabling more accurate early detection of Diabetic Retinopathy. This
methodology highlights the potential of synthetic data in advancing medical
imaging and AI-driven diagnostics.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆä (DR) ÊòØÂèØÈ†êÈò≤Â§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†„ÄÇÂú® DR1 ÈöéÊÆµÊó©ÊúüÁôºÁèæËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÁº∫‰πèÈ´òÂìÅË≥™ÁúºÂ∫ïÂúñÂÉèËÄåÂèóÂà∞ÈòªÁ§ô„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî® StyleGAN3 ÁîüÊàêÂêàÊàê DR1 ÂúñÂÉèÔºåÂÖ∂ÁâπÂæµÊòØÂÖ∑ÊúâÈ´ò‰øùÁúüÂ∫¶ÂíåÂ§öÊ®£ÊÄßÁöÑÂæÆÂãïËÑàÁò§„ÄÇÁõÆÁöÑÊòØËß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°åÔºå‰∏¶ÊèêÂçáÁõ£Áù£ÂàÜÈ°ûÂô®ÁöÑÊïàËÉΩ„ÄÇ‰ΩøÁî® 2,602 Âºµ DR1 ÂúñÂÉèÁöÑË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥Ê®°ÂûãÔºåÁÑ∂Âæå‰ΩøÁî®ÈáèÂåñÊåáÊ®ôÈÄ≤Ë°åÂÖ®Èù¢Ë©ï‰º∞ÔºåÂåÖÊã¨ Fr√©chet Inception Distance (FID)„ÄÅKernel Inception Distance (KID) ‰ª•ÂèäÁõ∏Â∞çÊñºÂπ≥Áßª (EQ-T) ÂíåÊóãËΩâ (EQ-R) ÁöÑÁ≠âËÆäÁï∞ÊÄß„ÄÇÂÆöÊÄßË©ï‰º∞ÂåÖÊã¨‰∫∫È°ûÂúñÈùàÊ∏¨Ë©¶ÔºåÂÖ∂‰∏≠Ë®ìÁ∑¥ÊúâÁ¥†ÁöÑÁúºÁßëÈÜ´ÁîüË©ï‰º∞ÂêàÊàêÂúñÂÉèÁöÑÁúüÂØ¶ÊÄß„ÄÇÂÖâË≠úÂàÜÊûêÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÂΩ±ÂÉèÂìÅË≥™„ÄÇË©≤Ê®°ÂûãÈÅîÂà∞‰∫Ü 17.29 ÁöÑÊúÄÁµÇ FID ÂàÜÊï∏ÔºåÂÑ™ÊñºÂæû bootstrap ÈáçÊäΩÊ®£ÂæóÂá∫ÁöÑ 21.18 ÁöÑÂπ≥Âùá FIDÔºà95% ‰ø°Ë≥¥ÂçÄÈñì - 20.83 Âà∞ 21.56Ôºâ„ÄÇ‰∫∫È°ûÂúñÈùàÊ∏¨Ë©¶Ë≠âÊòé‰∫ÜË©≤Ê®°ÂûãÁî¢ÁîüÈ´òÂ∫¶ÈÄºÁúüÂúñÂÉèÁöÑËÉΩÂäõÔºåÂÑòÁÆ°Ê≥®ÊÑèÂà∞ÈÇäÁ∑£ÈôÑËøëÊúâËºïÂæÆÁöÑ‰∫∫Â∑•Ë£ΩÂìÅ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåStyleGAN3 ÁîüÊàêÁöÑÂêàÊàê DR1 ÂúñÂÉèÂ∞çÊñºÊì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñôÈõÜÂÖ∑ÊúâÈ°ØËëóÁöÑÂ∏åÊúõÔºåËÉΩÂ§†Êõ¥Ê∫ñÁ¢∫Âú∞Êó©ÊúüÁôºÁèæÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆä„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁ™ÅÈ°Ø‰∫ÜÂêàÊàêË≥áÊñôÂú®Êé®ÈÄ≤ÈÜ´Â≠∏ÂΩ±ÂÉèÂíå AI È©ÖÂãïË®∫Êñ∑ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Multi-Center Study on Deep Learning-Assisted Detection and Classification of Fetal Central Nervous System Anomalies Using Ultrasound Imaging**
2501.02000v1 by Yang Qi, Jiaxin Cai, Jing Lu, Runqing Xiong, Rongshang Chen, Liping Zheng, Duo Ma

Prenatal ultrasound evaluates fetal growth and detects congenital
abnormalities during pregnancy, but the examination of ultrasound images by
radiologists requires expertise and sophisticated equipment, which would
otherwise fail to improve the rate of identifying specific types of fetal
central nervous system (CNS) abnormalities and result in unnecessary patient
examinations. We construct a deep learning model to improve the overall
accuracy of the diagnosis of fetal cranial anomalies to aid prenatal diagnosis.
In our collected multi-center dataset of fetal craniocerebral anomalies
covering four typical anomalies of the fetal central nervous system (CNS):
anencephaly, encephalocele (including meningocele), holoprosencephaly, and
rachischisis, patient-level prediction accuracy reaches 94.5%, with an AUROC
value of 99.3%. In the subgroup analyzes, our model is applicable to the entire
gestational period, with good identification of fetal anomaly types for any
gestational period. Heatmaps superimposed on the ultrasound images not only
provide a visual interpretation for the algorithm but also provide an intuitive
visual aid to the physician by highlighting key areas that need to be reviewed,
helping the physician to quickly identify and validate key areas. Finally, the
retrospective reader study demonstrates that by combining the automatic
prediction of the DL system with the professional judgment of the radiologist,
the diagnostic accuracy and efficiency can be effectively improved and the
misdiagnosis rate can be reduced, which has an important clinical application
prospect.

ÊëòË¶ÅÔºöÁî¢ÂâçË∂ÖÈü≥Ê≥¢Ë©ï‰º∞ËÉéÂÖíÁîüÈï∑‰∏¶Âú®Êá∑Â≠ïÊúüÈñìÂÅµÊ∏¨ÂÖàÂ§©Áï∞Â∏∏Ôºå‰ΩÜË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑÊ™¢Êü•ÈúÄË¶ÅÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∞àÊ•≠Áü•Ë≠òÂíåÁ≤æÂØÜÂÑÄÂô®ÔºåÂê¶ÂâáÁÑ°Ê≥ïÊîπÂñÑÁâπÂÆöÈ°ûÂûãËÉéÂÖí‰∏≠Ê®ûÁ•ûÁ∂ìÁ≥ªÁµ± (CNS) Áï∞Â∏∏ÁöÑËæ®Ë≠òÁéáÔºå‰∏¶Â∞éËá¥‰∏çÂøÖË¶ÅÁöÑÁóÖ‰∫∫Ê™¢Êü•„ÄÇÊàëÂÄëÂª∫Êßã‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÊîπÂñÑËÉéÂÖíÈ°±È™®Áï∞Â∏∏Ë®∫Êñ∑ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶Ôºå‰ª•ÂçîÂä©Áî¢ÂâçË®∫Êñ∑„ÄÇÂú®ÊàëÂÄëÊî∂ÈõÜÁöÑÂ§ö‰∏≠ÂøÉËÉéÂÖíÈ°±ËÖ¶Áï∞Â∏∏Ë≥áÊñôÈõÜ‰∏≠ÔºåÊ∂µËìãËÉéÂÖí‰∏≠Ê®ûÁ•ûÁ∂ìÁ≥ªÁµ± (CNS) ÁöÑÂõõÁ®ÆÂÖ∏ÂûãÁï∞Â∏∏ÔºöÁÑ°ËÖ¶Áóá„ÄÅËÖ¶ËÜ®Âá∫ÔºàÂåÖÊã¨ËÖ¶ËÜúËÜ®Âá∫Ôºâ„ÄÅÂÖ®ÂâçËÖ¶ÁóáÂíåËÑäË£ÇÔºåÁóÖ‰∫∫Â±§Á¥öÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 94.5%ÔºåAUROC ÂÄºÁÇ∫ 99.3%„ÄÇÂú®Â≠êÁæ§ÂàÜÊûê‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅ©Áî®ÊñºÊï¥ÂÄãÂ¶äÂ®†ÊúüÔºå‰∏îËÉΩËâØÂ•ΩËæ®Ë≠ò‰ªª‰ΩïÂ¶äÂ®†ÊúüÁöÑËÉéÂÖíÁï∞Â∏∏È°ûÂûã„ÄÇÁñäÂä†Âú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰∏äÁöÑÁÜ±Âúñ‰∏çÂÉÖÊèê‰æõÊºîÁÆóÊ≥ïÁöÑË¶ñË¶∫Ë©ÆÈáãÔºå‰πüÈÄèÈÅéÁ™ÅÈ°ØÈúÄË¶ÅÊ™¢Ë¶ñÁöÑÈóúÈçµÂçÄÂüüÔºåÊèê‰æõÁõ¥Ë¶∫ÁöÑË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑Áµ¶ÈÜ´Â∏´ÔºåÂçîÂä©ÈÜ´Â∏´Âø´ÈÄüËæ®Ë≠òÂíåÈ©óË≠âÈóúÈçµÂçÄÂüü„ÄÇÊúÄÂæåÔºåÂõûÊ∫ØÊÄßÈñ±ËÆÄÁ†îÁ©∂È°ØÁ§∫ÔºåÁµêÂêà DL Á≥ªÁµ±ÁöÑËá™ÂãïÈ†êÊ∏¨ÂíåÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∞àÊ•≠Âà§Êñ∑ÔºåÂèØ‰ª•ÊúâÊïàÊîπÂñÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÂíåÊïàÁéáÔºå‰∏¶Èôç‰ΩéË™§Ë®∫ÁéáÔºåÈÄôÂÖ∑ÊúâÈáçË¶ÅÁöÑËá®Â∫äÊáâÁî®ÂâçÊôØ„ÄÇ

##### **Efficient Standardization of Clinical Notes using Large Language Models**
2501.00644v1 by Daniel B. Hier, Michael D. Carrithers, Thanh Son Do, Tayo Obafemi-Ajayi

Clinician notes are a rich source of patient information but often contain
inconsistencies due to varied writing styles, colloquialisms, abbreviations,
medical jargon, grammatical errors, and non-standard formatting. These
inconsistencies hinder the extraction of meaningful data from electronic health
records (EHRs), posing challenges for quality improvement, population health,
precision medicine, decision support, and research.
  We present a large language model approach to standardizing a corpus of 1,618
clinical notes. Standardization corrected an average of $4.9 +/- 1.8$
grammatical errors, $3.3 +/- 5.2$ spelling errors, converted $3.1 +/- 3.0$
non-standard terms to standard terminology, and expanded $15.8 +/- 9.1$
abbreviations and acronyms per note. Additionally, notes were re-organized into
canonical sections with standardized headings. This process prepared notes for
key concept extraction, mapping to medical ontologies, and conversion to
interoperable data formats such as FHIR.
  Expert review of randomly sampled notes found no significant data loss after
standardization. This proof-of-concept study demonstrates that standardization
of clinical notes can improve their readability, consistency, and usability,
while also facilitating their conversion into interoperable data formats.

ÊëòË¶ÅÔºöËá®Â∫äÈÜ´Â∏´ÁöÑÁ≠ÜË®òÊòØË±êÂØåÁöÑÁóÖ‰∫∫Ë≥áË®ä‰æÜÊ∫êÔºå‰ΩÜÂ∏∏Â∏∏Âõ†ÁÇ∫Êõ∏ÂØ´È¢®Ê†º‰∏çÂêå„ÄÅÊÖ£Áî®Ë™û„ÄÅÁ∏ÆÂØ´„ÄÅÈÜ´Â≠∏Ë°ìË™û„ÄÅÊñáÊ≥ïÈåØË™§ÂíåÈùûÊ®ôÊ∫ñÊ†ºÂºèËÄåÂåÖÂê´‰∏ç‰∏ÄËá¥ÁöÑÂú∞Êñπ„ÄÇÈÄô‰∫õ‰∏ç‰∏ÄËá¥ÊúÉÈòªÁ§ôÂæûÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠ËêÉÂèñÊúâÊÑèÁæ©ÁöÑË≥áÊñôÔºåÂ∞çÂìÅË≥™ÊîπÂñÑ„ÄÅ‰∫∫Âè£ÂÅ•Â∫∑„ÄÅÁ≤æÊ∫ñÈÜ´ÁôÇ„ÄÅÊ±∫Á≠ñÊîØÊè¥ÂíåÁ†îÁ©∂ÊßãÊàêÊåëÊà∞„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊñπÊ≥ï‰æÜÊ®ôÊ∫ñÂåñ 1,618 ‰ªΩËá®Â∫äÁ≠ÜË®òÁöÑË™ûÊñôÂ∫´„ÄÇÊ®ôÊ∫ñÂåñÂπ≥ÂùáÊõ¥Ê≠£‰∫Ü $4.9 +/- 1.8$ ÂÄãÊñáÊ≥ïÈåØË™§„ÄÅ$3.3 +/- 5.2$ ÂÄãÊãºÂ≠óÈåØË™§ÔºåÂ∞á $3.1 +/- 3.0$ ÂÄãÈùûÊ®ôÊ∫ñË°ìË™ûËΩâÊèõÁÇ∫Ê®ôÊ∫ñË°ìË™ûÔºå‰∏¶Êì¥ÂÖÖ‰∫ÜÊØè‰ªΩÁ≠ÜË®ò‰∏≠ $15.8 +/- 9.1$ ÂÄãÁ∏ÆÂØ´ÂíåÈ¶ñÂ≠óÊØçÁ∏ÆÁï•Â≠ó„ÄÇÊ≠§Â§ñÔºåÁ≠ÜË®òË¢´ÈáçÊñ∞ÁµÑÁπîÊàêÂÖ∑ÊúâÊ®ôÊ∫ñÊ®ôÈ°åÁöÑÊ≠£Ë¶èÁ´†ÁØÄ„ÄÇÈÄôÂÄãÈÅéÁ®ãÊ∫ñÂÇô‰∫ÜÁ≠ÜË®òÔºåÁî®ÊñºÈóúÈçµÊ¶ÇÂøµËêÉÂèñ„ÄÅÂ∞çÊáâÂà∞ÈÜ´Â≠∏Êú¨‰ΩìÔºå‰ª•ÂèäËΩâÊèõÁÇ∫ÂèØ‰∫íÊìç‰ΩúÁöÑË≥áÊñôÊ†ºÂºèÔºå‰æãÂ¶Ç FHIR„ÄÇ
Â∞çÈö®Ê©üÊäΩÊ®£ÁöÑÁ≠ÜË®òÈÄ≤Ë°åÂ∞àÂÆ∂ÂØ©Êü•ÂæåÁôºÁèæÔºåÂú®Ê®ôÊ∫ñÂåñÂæåÊ≤íÊúâÈ°ØËëóÁöÑË≥áÊñôÈÅ∫Â§±„ÄÇÈÄôÂÄãÊ¶ÇÂøµÈ©óË≠âÁ†îÁ©∂Ë≠âÊòé‰∫ÜËá®Â∫äÁ≠ÜË®òÁöÑÊ®ôÊ∫ñÂåñÂèØ‰ª•ÊîπÂñÑÂÖ∂ÂèØËÆÄÊÄß„ÄÅ‰∏ÄËá¥ÊÄßÂíåÂèØÁî®ÊÄßÔºåÂêåÊôÇ‰πü‰øÉÈÄ≤ÂÖ∂ËΩâÊèõÁÇ∫ÂèØ‰∫íÊìç‰ΩúÁöÑË≥áÊñôÊ†ºÂºè„ÄÇ

##### **LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models**
2501.05464v1 by Hang Yang, Hao Chen, Hui Guo, Yineng Chen, Ching-Sheng Lin, Shu Hu, Jinrong Hu, Xi Wu, Xin Wang

Accurate and efficient question-answering systems are essential for
delivering high-quality patient care in the medical field. While Large Language
Models (LLMs) have made remarkable strides across various domains, they
continue to face significant challenges in medical question answering,
particularly in understanding domain-specific terminologies and performing
complex reasoning. These limitations undermine their effectiveness in critical
medical applications. To address these issues, we propose a novel approach
incorporating similar case generation within a multi-agent medical
question-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B
model, a state-of-the-art LLM, in a multi-agent architecture to enhance
performance on the MedQA dataset using zero-shot learning. Our method
capitalizes on the model's inherent medical knowledge and reasoning
capabilities, eliminating the need for additional training data. Experimental
results show substantial performance gains over existing benchmark models, with
improvements of 7% in both accuracy and F1-score across various medical QA
tasks. Furthermore, we examine the model's interpretability and reliability in
addressing complex medical queries. This research not only offers a robust
solution for medical question answering but also establishes a foundation for
broader applications of LLMs in the medical domain.

ÊëòË¶ÅÔºöÁ≤æÊ∫ñÈ´òÊïàÁöÑÂïèÈ°åËß£Á≠îÁ≥ªÁµ±Â∞çÊñºÊèê‰æõÈÜ´ÁôÇÈ†òÂüüÁöÑÈ´òÂìÅË≥™ÁóÖ‰∫∫ÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÂÄãÈ†òÂüüÈÉΩÊúâÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÂÆÉÂÄëÂú®ÈÜ´ÁôÇÂïèÈ°åËß£Á≠î‰∏≠‰ªçÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÁêÜËß£ÁâπÂÆöÈ†òÂüüÁöÑË°ìË™ûÂíåÂü∑Ë°åË§áÈõúÊé®ÁêÜÊñπÈù¢„ÄÇÈÄô‰∫õÈôêÂà∂ÂΩ±Èüø‰∫ÜÂÆÉÂÄëÂú®ÈóúÈçµÈÜ´ÁôÇÊáâÁî®‰∏≠ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂ∞áÈ°û‰ººÊ°à‰æãÁîüÊàêÊï¥ÂêàÂà∞Â§ö‰∏ªÈ´îÈÜ´ÁôÇÂïèÈ°åËß£Á≠î (MedQA) Á≥ªÁµ±‰∏≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú®Â§ö‰∏ªÈ´îÊû∂Êßã‰∏≠Âà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑ LLM Llama3.1:70B Ê®°ÂûãÔºå‰ª•‰ΩøÁî®Èõ∂Ê¨°Â≠∏Áøí‰æÜÂ¢ûÂº∑ MedQA Ë≥áÊñôÈõÜÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜË©≤Ê®°ÂûãÂÖßÂª∫ÁöÑÈÜ´ÁôÇÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõÔºåÊ∂àÈô§‰∫ÜÂ∞çÈ°çÂ§ñË®ìÁ∑¥Ë≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÁèæÊúâÁöÑÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÊïàËÉΩÊúâÈ°ØËëóÊèêÂçáÔºåÂú®ÂêÑÁ®ÆÈÜ´ÁôÇÂïèÁ≠î‰ªªÂãô‰∏≠ÔºåÊ∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÈÉΩÊèêÂçá‰∫Ü 7%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË©≤Ê®°ÂûãÂú®ÂõûÁ≠îË§áÈõúÈÜ´ÁôÇÂïèÈ°åÊôÇÁöÑË©ÆÈáãÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰∏çÂÉÖÁÇ∫ÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÊèê‰æõ‰∫ÜÂº∑ÂÅ•ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰πüÁÇ∫ LLM Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÊõ¥Âª£Ê≥õÊáâÁî®Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **Pan-infection Foundation Framework Enables Multiple Pathogen Prediction**
2501.01462v1 by Lingrui Zhang, Haonan Wu, Nana Jin, Chenqing Zheng, Jize Xie, Qitai Cai, Jun Wang, Qin Cao, Xubin Zheng, Jiankun Wang, Lixin Cheng

Host-response-based diagnostics can improve the accuracy of diagnosing
bacterial and viral infections, thereby reducing inappropriate antibiotic
prescriptions. However, the existing cohorts with limited sample size and
coarse infections types are unable to support the exploration of an accurate
and generalizable diagnostic model. Here, we curate the largest infection
host-response transcriptome data, including 11,247 samples across 89 blood
transcriptome datasets from 13 countries and 21 platforms. We build a
diagnostic model for pathogen prediction starting from a pan-infection model as
foundation (AUC = 0.97) based on the pan-infection dataset. Then, we utilize
knowledge distillation to efficiently transfer the insights from this "teacher"
model to four lightweight pathogen "student" models, i.e., staphylococcal
infection (AUC = 0.99), streptococcal infection (AUC = 0.94), HIV infection
(AUC = 0.93), and RSV infection (AUC = 0.94), as well as a sepsis "student"
model (AUC = 0.99). The proposed knowledge distillation framework not only
facilitates the diagnosis of pathogens using pan-infection data, but also
enables an across-disease study from pan-infection to sepsis. Moreover, the
framework enables high-degree lightweight design of diagnostic models, which is
expected to be adaptively deployed in clinical settings.

ÊëòË¶ÅÔºöÂü∫ÊñºÂÆø‰∏ªÂèçÊáâÁöÑË®∫Êñ∑ÂèØ‰ª•ÊèêÈ´òÁ¥∞ËèåÂíåÁóÖÊØíÊÑüÊüìÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÔºåÂæûËÄåÊ∏õÂ∞ë‰∏çÈÅ©Áï∂ÁöÑÊäóÁîüÁ¥†ËôïÊñπ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊ®£Êú¨ÈáèÊúâÈôê„ÄÅÊÑüÊüìÈ°ûÂûãÁ≤óÁ≥ôÁöÑÁæ§ÁµÑÁÑ°Ê≥ïÊîØÊåÅÊ∫ñÁ¢∫‰∏îÂèØÊ¶ÇÂåñÁöÑË®∫Êñ∑Ê®°ÂûãÁöÑÊé¢Á¥¢„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊï¥ÁêÜ‰∫ÜÊúÄÂ§ßÁöÑÊÑüÊüìÂÆø‰∏ªÂèçÊáâËΩâÈåÑÁµÑÊï∏ÊìöÔºåÂåÖÊã¨‰æÜËá™ 13 ÂÄãÂúãÂÆ∂Âíå 21 ÂÄãÂπ≥Âè∞ÁöÑ 89 ÂÄãË°ÄÊ∂≤ËΩâÈåÑÁµÑÊï∏ÊìöÈõÜ‰∏≠ÁöÑ 11,247 ÂÄãÊ®£Êú¨„ÄÇÊàëÂÄëÂæûÊ≥õÊÑüÊüìÊ®°ÂûãÈñãÂßãÂª∫Á´ã‰∏ÄÂÄãÁî®ÊñºÁóÖÂéüÈ´îÈ†êÊ∏¨ÁöÑË®∫Êñ∑Ê®°ÂûãÔºå‰ΩúÁÇ∫Âü∫Á§é (AUC = 0.97)ÔºåË©≤Ê®°ÂûãÂü∫ÊñºÊ≥õÊÑüÊüìÊï∏ÊìöÈõÜ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂà©Áî®Áü•Ë≠òËí∏È§æÊúâÊïàÂú∞Â∞áÈÄôÂÄã„ÄåÊïôÂ∏´„ÄçÊ®°Âûã‰∏≠ÁöÑË¶ãËß£ËΩâÁßªÂà∞ÂõõÂÄãËºïÈáèÁ¥öÁóÖÂéüÈ´î„ÄåÂ≠∏Áîü„ÄçÊ®°ÂûãÔºåÂç≥Ëë°ËêÑÁêÉËèåÊÑüÊüì (AUC = 0.99)„ÄÅÈèàÁêÉËèåÊÑüÊüì (AUC = 0.94)„ÄÅHIV ÊÑüÊüì (AUC = 0.93) Âíå RSV ÊÑüÊüì (AUC = 0.94)Ôºå‰ª•Âèä‰∏ÄÂÄãÊïóË°ÄÁóá„ÄåÂ≠∏Áîü„ÄçÊ®°Âûã (AUC = 0.99)„ÄÇÊâÄÊèêÂá∫ÁöÑÁü•Ë≠òËí∏È§æÊ°ÜÊû∂‰∏çÂÉÖ‰øÉÈÄ≤‰∫Ü‰ΩøÁî®Ê≥õÊÑüÊüìÊï∏ÊìöË®∫Êñ∑ÁóÖÂéüÈ´îÔºåÈÇÑÂØ¶Áèæ‰∫ÜÂæûÊ≥õÊÑüÊüìÂà∞ÊïóË°ÄÁóáÁöÑË∑®ÁñæÁóÖÁ†îÁ©∂„ÄÇÊ≠§Â§ñÔºåË©≤Ê°ÜÊû∂‰ΩøË®∫Êñ∑Ê®°ÂûãËÉΩÂ§†ÈÄ≤Ë°åÈ´òÂ∫¶ËºïÈáèÁ¥öË®≠Ë®àÔºåÈ†êË®àÂ∞áÈÅ©ÊáâÊÄßÂú∞ÈÉ®ÁΩ≤Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠„ÄÇ

##### **A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation**
2501.01991v1 by Lahcen El Fatimi, Elhoucine Elfatimi, Hanifa Bouchaneb

Model checking, a formal verification technique, ensures systems meet
predefined requirements, playing a crucial role in minimizing errors and
enhancing quality during development. This paper introduces a novel hybrid
framework integrating model checking with deep learning for brain tumor
detection and validation in medical imaging. By combining model-checking
principles with CNN-based feature extraction and K-FCM clustering for
segmentation, the proposed approach enhances the reliability of tumor detection
and segmentation. Experimental results highlight the framework's effectiveness,
achieving 98\% accuracy, 96.15\% precision, and 100\% recall, demonstrating its
potential as a robust tool for advanced medical image analysis.

ÊëòË¶ÅÔºöÊ®°ÂûãÊ™¢Êü•ÊòØ‰∏ÄÁ®ÆÊ≠£ÂºèÈ©óË≠âÊäÄË°ìÔºåÁî®ÊñºÁ¢∫‰øùÁ≥ªÁµ±Á¨¶ÂêàÈ†êÂÖàÂÆöÁæ©ÁöÑË¶ÅÊ±ÇÔºåÂú®ÈñãÁôºÈÅéÁ®ã‰∏≠ÊâÆÊºîËëóÊ•µÂÖ∂ÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁî®ÊñºÊúÄÂ∞èÂåñÈåØË™§‰∏¶ÊèêÂçáÂìÅË≥™„ÄÇÈÄôÁØáË´ñÊñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊï¥ÂêàÊ®°ÂûãÊ™¢Êü•ËàáÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂâµÊñ∞Ê∑∑ÂêàÊ°ÜÊû∂ÔºåÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑËÖ¶Áò§ÂÅµÊ∏¨ËàáÈ©óË≠â„ÄÇÈÄèÈÅéÁµêÂêàÊ®°ÂûãÊ™¢Êü•ÂéüÂâáËàáÂü∫Êñº CNN ÁöÑÁâπÂæµËêÉÂèñ‰ª•ÂèäÁî®ÊñºÂàÜÂâ≤ÁöÑ K-FCM ËÅöÈ°ûÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèêÂçá‰∫ÜËÖ´Áò§ÂÅµÊ∏¨ËàáÂàÜÂâ≤ÁöÑÂèØÈù†Â∫¶„ÄÇÂØ¶È©óÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈÄôÂÄãÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄßÔºåÈÅîÂà∞‰∫Ü 98% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÅ96.15% ÁöÑÁ≤æÁ¢∫Â∫¶Ôºå‰ª•Âèä 100% ÁöÑÂè¨ÂõûÁéáÔºåÈ°ØÁ§∫Âá∫ÂÖ∂‰ΩúÁÇ∫ÈÄ≤ÈöéÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁöÑÂº∑ÂÅ•Â∑•ÂÖ∑ÁöÑÊΩõÂäõ„ÄÇ

##### **GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification**
2501.01458v1 by George Yuanji Wang, Srisharan Murugesan, Aditya Prince Rohatgi

Identifying druggable genes is essential for developing effective
pharmaceuticals. With the availability of extensive, high-quality data,
computational methods have become a significant asset. Protein Interaction
Network (PIN) is valuable but challenging to implement due to its high
dimensionality and sparsity. Previous methods relied on indirect integration,
leading to resolution loss. This study proposes GAN-TAT, a framework utilizing
an advanced graph embedding technology, ImGAGN, to directly integrate PIN for
druggable gene inference work. Tested on three Pharos datasets, GAN-TAT
achieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows
that GAN-TAT's predictions are supported by clinical evidence, highlighting its
potential practical applications in pharmacogenomics. This research represents
a methodological attempt with the direct utilization of PIN, expanding
potential new solutions for developing drug targets. The source code of GAN-TAT
is available at (https://github.com/george-yuanji-wang/GAN-TAT).

ÊëòË¶ÅÔºöË≠òÂà•ÂèØËó•Áâ©ÂåñÂü∫Âõ†Â∞çÊñºÈñãÁôºÊúâÊïàÁöÑËó•Áâ©Ëá≥ÈóúÈáçË¶Å„ÄÇÈö®ËëóÂ§ßÈáèÈ´òÂìÅË≥™Êï∏ÊìöÁöÑÂá∫ÁèæÔºåË®àÁÆóÊñπÊ≥ïÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑË≥áÁî¢„ÄÇËõãÁôΩË≥™‰∫§‰∫íÁ∂≤Áµ° (PIN) ÂæàÊúâÂÉπÂÄºÔºå‰ΩÜÁî±ÊñºÂÖ∂È´òÁ∂≠Â∫¶ÂíåÁ®ÄÁñèÊÄßÔºåÂØ¶‰ΩúËµ∑‰æÜÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÖàÂâçÁöÑËæ¶Ê≥ï‰æùË≥¥ÊñºÈñìÊé•Êï¥ÂêàÔºåÂ∞éËá¥Ëß£ÊûêÂ∫¶Èôç‰Ωé„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫ GAN-TATÔºå‰∏ÄÂÄãÂà©Áî®ÂÖàÈÄ≤ÂúñÂΩ¢ÂµåÂÖ•ÊäÄË°ì ImGAGN ÁöÑÊû∂ÊßãÔºåÁõ¥Êé•Êï¥Âêà PIN ‰ª•ÈÄ≤Ë°åÂèØËó•Áâ©ÂåñÂü∫Âõ†Êé®Ë´ñÂ∑•‰Ωú„ÄÇÂú®‰∏âÂÄã Pharos Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåGAN-TAT Âú® Tclin ‰∏äÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑ AUC-ROC ÂàÜÊï∏ 0.951„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåGAN-TAT ÁöÑÈ†êÊ∏¨Áç≤Âæó‰∫ÜËá®Â∫äË≠âÊìöÁöÑÊîØÊåÅÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Ëó•Áâ©Âü∫Âõ†ÁµÑÂ≠∏‰∏≠ÁöÑÊΩõÂú®ÂØ¶ÈöõÊáâÁî®„ÄÇÊú¨Á†îÁ©∂‰ª£Ë°®‰∫Ü‰∏ÄÁ®ÆÁõ¥Êé•Âà©Áî® PIN ÁöÑÊñπÊ≥ïË´ñÂòóË©¶ÔºåÊì¥Â±ï‰∫ÜÈñãÁôºËó•Áâ©Èù∂Ê®ôÁöÑÊΩõÂú®Êñ∞Ëß£Ê±∫ÊñπÊ°à„ÄÇGAN-TAT ÁöÑÂéüÂßãÁ¢ºÂèØÂú® (https://github.com/george-yuanji-wang/GAN-TAT) ÂèñÂæó„ÄÇ

##### **Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind**
2501.00320v2 by Haibo Tong, Enmeng Lu, Yinqian Sun, Zhengqiang Han, Chao Liu, Feifei Zhao, Yi Zeng

With the widespread application of Artificial Intelligence (AI) in human
society, enabling AI to autonomously align with human values has become a
pressing issue to ensure its sustainable development and benefit to humanity.
One of the most important aspects of aligning with human values is the
necessity for agents to autonomously make altruistic, safe, and ethical
decisions, considering and caring for human well-being. Current AI extremely
pursues absolute superiority in certain tasks, remaining indifferent to the
surrounding environment and other agents, which has led to numerous safety
risks. Altruistic behavior in human society originates from humans' capacity
for empathizing others, known as Theory of Mind (ToM), combined with predictive
imaginative interactions before taking action to produce thoughtful and
altruistic behaviors. Inspired by this, we are committed to endow agents with
considerate self-imagination and ToM capabilities, driving them through
implicit intrinsic motivations to autonomously align with human altruistic
values. By integrating ToM within the imaginative space, agents keep an eye on
the well-being of other agents in real time, proactively anticipate potential
risks to themselves and others, and make thoughtful altruistic decisions that
balance negative effects on the environment. The ancient Chinese story of Sima
Guang Smashes the Vat illustrates the moral behavior of the young Sima Guang
smashed a vat to save a child who had accidentally fallen into it, which is an
excellent reference scenario for this paper. We design an experimental scenario
similar to Sima Guang Smashes the Vat and its variants with different
complexities, which reflects the trade-offs and comprehensive considerations
between self-goals, altruistic rescue, and avoiding negative side effects.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®‰∫∫È°ûÁ§æÊúÉ‰∏≠ÁöÑÂª£Ê≥õÊáâÁî®ÔºåËÆì AI Ëá™‰∏ªËàá‰∫∫È°ûÂÉπÂÄºËßÄ‰∏ÄËá¥Â∑≤ÊàêÁÇ∫Á¢∫‰øùÂÖ∂Ê∞∏Á∫åÁôºÂ±ïÂíåÈÄ†Á¶è‰∫∫È°ûÁöÑÁï∂Âãô‰πãÊÄ•„ÄÇËàá‰∫∫È°ûÂÉπÂÄºËßÄ‰∏ÄËá¥ÊúÄÈáçË¶ÅÁöÑÈù¢Âêë‰πã‰∏ÄÔºåÂú®Êñº‰ª£ÁêÜ‰∫∫ÂøÖÈ†àËá™‰∏ªÂÅöÂá∫Âà©‰ªñ„ÄÅÂÆâÂÖ®„ÄÅ‰∏îÂêà‰πéÈÅìÂæ∑ÁöÑÊ±∫Á≠ñÔºåËÄÉÈáè‰∏¶ÈóúÊá∑‰∫∫È°ûÁ¶èÁ•â„ÄÇÁõÆÂâçÁöÑ AI Âú®ÁâπÂÆö‰ªªÂãô‰∏≠Ê•µÂäõËøΩÊ±ÇÁµïÂ∞çÂÑ™Ë∂äÊÄßÔºåÂ∞çÊñºÂë®ÈÅ≠Áí∞Â¢ÉÂíåÂÖ∂ÂÆÉ‰ª£ÁêÜ‰∫∫Êº†‰∏çÈóúÂøÉÔºåÈÄôÂ∑≤Â∞éËá¥Ë®±Â§öÂÆâÂÖ®È¢®Èö™„ÄÇ‰∫∫È°ûÁ§æÊúÉ‰∏≠ÁöÑÂà©‰ªñË°åÁÇ∫Ê∫êËá™Êñº‰∫∫È°ûÂêåÁêÜ‰ªñ‰∫∫ÁöÑËÉΩÂäõÔºåÁ®±ÁÇ∫ÂøÉÊô∫ÁêÜË´ñÔºàToMÔºâÔºåÁµêÂêàÂú®Êé°ÂèñË°åÂãïÂâçÈÄ≤Ë°åÈ†êÊ∏¨ÊÄßÁöÑÊÉ≥ÂÉè‰∫íÂãïÔºå‰ª•Áî¢ÁîüÂë®Âà∞‰∏îÂà©‰ªñÁöÑË°åÁÇ∫„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëËá¥ÂäõÊñºË≥¶‰∫à‰ª£ÁêÜ‰∫∫È´îË≤ºÁöÑËá™ÊàëÊÉ≥ÂÉèÂíå ToM ËÉΩÂäõÔºåÈÄèÈÅéÈö±Âê´ÁöÑÂÖßÂú®ÂãïÊ©üÈ©Ö‰Ωø‰ªñÂÄëËá™‰∏ªËàá‰∫∫È°ûÂà©‰ªñÂÉπÂÄºËßÄ‰∏ÄËá¥„ÄÇÈÄèÈÅéÂ∞á ToM Êï¥ÂêàÂú®ÊÉ≥ÂÉèÁ©∫Èñì‰∏≠Ôºå‰ª£ÁêÜ‰∫∫ËÉΩÂç≥ÊôÇÈóúÊ≥®ÂÖ∂‰ªñ‰ª£ÁêÜ‰∫∫ÁöÑÁ¶èÁ•âÔºå‰∏ªÂãïÈ†êÊ∏¨Â∞çËá™Ë∫´Âíå‰ªñ‰∫∫ÊΩõÂú®ÁöÑÈ¢®Èö™Ôºå‰∏¶ÂÅöÂá∫Âë®Âà∞‰∏îÂà©‰ªñÁöÑÊ±∫Á≠ñÔºåÂπ≥Ë°°Â∞çÁí∞Â¢ÉÁöÑË≤†Èù¢ÂΩ±Èüø„ÄÇ‰∏≠ÂúãÂè§‰ª£ÊïÖ‰∫ã„ÄåÂè∏È¶¨ÂÖâÁ†∏Áº∏„ÄçË™™Êòé‰∫ÜÂπ¥ÂπºÁöÑÂè∏È¶¨ÂÖâÁÇ∫‰∫ÜÊïë‰∏ÄÂÄã‰∏çÂ∞èÂøÉÊéâÈÄ≤Ê∞¥Áº∏‰∏≠ÁöÑÂ≠©Â≠êËÄåÁ†∏Á†¥Ê∞¥Áº∏ÁöÑÈÅìÂæ∑Ë°åÁÇ∫ÔºåÊòØÊú¨ÊñáÁöÑÁµï‰Ω≥ÂèÉËÄÉÊÉÖÂ¢É„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãËàá„ÄåÂè∏È¶¨ÂÖâÁ†∏Áº∏„ÄçÁõ∏‰ººÁöÑÂØ¶È©óÊÉÖÂ¢ÉÔºå‰ª•ÂèäÂÖ∑Êúâ‰∏çÂêåË§áÈõúÊÄßÁöÑËÆäÈ´îÔºåÂèçÊò†‰∫ÜËá™ÊàëÁõÆÊ®ô„ÄÅÂà©‰ªñÊïëÊè¥ÂíåÈÅøÂÖçË≤†Èù¢ÂâØ‰ΩúÁî®‰πãÈñìÁöÑÊ¨äË°°ÂíåÁ∂úÂêàËÄÉÈáè„ÄÇ

##### **A Systematic Review of Machine Learning Methods for Multimodal EEG Data in Clinical Application**
2501.08585v1 by Siqi Zhao, Wangyang Li, Xiru Wang, Stevie Foglia, Hongzhao Tan, Bohan Zhang, Ameer Hamoodi, Aimee Nelson, Zhen Gao

Machine learning (ML) and deep learning (DL) techniques have been widely
applied to analyze electroencephalography (EEG) signals for disease diagnosis
and brain-computer interfaces (BCI). The integration of multimodal data has
been shown to enhance the accuracy of ML and DL models. Combining EEG with
other modalities can improve clinical decision-making by addressing complex
tasks in clinical populations. This systematic literature review explores the
use of multimodal EEG data in ML and DL models for clinical applications. A
comprehensive search was conducted across PubMed, Web of Science, and Google
Scholar, yielding 16 relevant studies after three rounds of filtering. These
studies demonstrate the application of multimodal EEG data in addressing
clinical challenges, including neuropsychiatric disorders, neurological
conditions (e.g., seizure detection), neurodevelopmental disorders (e.g.,
autism spectrum disorder), and sleep stage classification. Data fusion occurred
at three levels: signal, feature, and decision levels. The most commonly used
ML models were support vector machines (SVM) and decision trees. Notably, 11
out of the 16 studies reported improvements in model accuracy with multimodal
EEG data. This review highlights the potential of multimodal EEG-based ML
models in enhancing clinical diagnostics and problem-solving.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÂíåÊ∑±Â∫¶Â≠∏Áøí (DL) ÊäÄË°ìÂ∑≤Âª£Ê≥õÊáâÁî®ÊñºÂàÜÊûêËÖ¶ÈõªÂúñ (EEG) Ë®äËôüÔºå‰ª•ÈÄ≤Ë°åÁñæÁóÖË®∫Êñ∑ÂíåËÖ¶Ê©ü‰ªãÈù¢ (BCI)„ÄÇÂ§öÊ®°ÊÖãË≥áÊñôÁöÑÊï¥ÂêàÂ∑≤Ë¢´Ë≠âÊòéÂèØ‰ª•ÊèêÂçá ML Âíå DL Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂ∞á EEG ËàáÂÖ∂‰ªñÊ®°ÊÖãÁµêÂêàÔºåÂèØ‰ª•ÈÄèÈÅéËôïÁêÜËá®Â∫äÊóèÁæ§‰∏≠ÁöÑË§áÈõú‰ªªÂãôÔºå‰æÜÊîπÂñÑËá®Â∫äÊ±∫Á≠ñ„ÄÇÈÄô‰ªΩÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊé¢Ë®é‰∫ÜÂú®Ëá®Â∫äÊáâÁî®‰∏≠ÔºåÂ∞áÂ§öÊ®°ÊÖã EEG Ë≥áÊñôÁî®Êñº ML Âíå DL Ê®°Âûã„ÄÇÂú® PubMed„ÄÅWeb of Science Âíå Google Scholar ‰∏≠ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÊêúÂ∞ãÔºåÂú®Á∂ìÈÅé‰∏âËº™ÁØ©ÈÅ∏ÂæåÔºåÂÖ±Áî¢Áîü‰∫Ü 16 È†ÖÁõ∏ÈóúÁ†îÁ©∂„ÄÇÈÄô‰∫õÁ†îÁ©∂Â±ïÁ§∫‰∫ÜÂ§öÊ®°ÊÖã EEG Ë≥áÊñôÂú®Ëß£Ê±∫Ëá®Â∫äÊåëÊà∞‰∏≠ÁöÑÊáâÁî®ÔºåÂåÖÊã¨Á•ûÁ∂ìÁ≤æÁ•ûÁñæÁóÖ„ÄÅÁ•ûÁ∂ìÁñæÁóÖÔºà‰æãÂ¶ÇÁô≤ÁôáÂÅµÊ∏¨Ôºâ„ÄÅÁ•ûÁ∂ìÁôºÂ±ïÈöúÁ§ôÔºà‰æãÂ¶ÇËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ôÔºâÂíåÁù°Áú†ÂàÜÊúüÂàÜÈ°û„ÄÇË≥áÊñôËûçÂêàÁôºÁîüÂú®‰∏âÂÄãÂ±§Èù¢ÔºöË®äËôü„ÄÅÁâπÂæµÂíåÊ±∫Á≠ñÂ±§Èù¢„ÄÇÊúÄÂ∏∏Áî®ÁöÑ ML Ê®°ÂûãÊòØÊîØÊè¥ÂêëÈáèÊ©ü (SVM) ÂíåÊ±∫Á≠ñÊ®π„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® 16 È†ÖÁ†îÁ©∂‰∏≠ÔºåÊúâ 11 È†ÖÂ†±Âëä‰∫Ü‰ΩøÁî®Â§öÊ®°ÊÖã EEG Ë≥áÊñôÂæåÔºåÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÊúâÊâÄÊèêÂçá„ÄÇÈÄôÁØáÂõûÈ°ßÂº∑Ë™ø‰∫ÜÂü∫ÊñºÂ§öÊ®°ÊÖã EEG ÁöÑ ML Ê®°ÂûãÂú®Â¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÂíåÂïèÈ°åËß£Ê±∫ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **A Fourfold Pathogen Reference Ontology Suite**
2501.01454v1 by Shane Babcock, Carter Benson, Giacomo De Colle, Sydney Cohen, Alexander D. Diehl, Ram A. N. R. Challa, Anthony Huffman, Yongqun He, John Beverley

Infectious diseases remain a critical global health challenge, and the
integration of standardized ontologies plays a vital role in managing related
data. The Infectious Disease Ontology (IDO) and its extensions, such as the
Coronavirus Infectious Disease Ontology (CIDO), are essential for organizing
and disseminating information related to infectious diseases. The COVID-19
pandemic highlighted the need for updating IDO and its virus-specific
extensions. There is an additional need to update IDO extensions specific to
bacteria, fungus, and parasite infectious diseases. We adopt the "hub and
spoke" methodology to generate pathogen-specific extensions of IDO: Virus
Infectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology
(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious
Disease Ontology (PIDO). The creation of pathogen-specific reference ontologies
advances modularization and reusability of infectious disease data within the
IDO ecosystem. Future work will focus on further refining these ontologies,
creating new extensions, and developing application ontologies based on them,
in line with ongoing efforts to standardize biological and biomedical
terminologies for improved data sharing and analysis.

ÊëòË¶ÅÔºöÂÇ≥ÊüìÁóÖ‰ªçÊòØ‰∏ÄÈ†ÖÂÖ®ÁêÉÊÄßÁöÑÂÅ•Â∫∑ÊåëÊà∞ÔºåËÄåÊ®ôÊ∫ñÂåñÊú¨È´îÁöÑÊï¥ÂêàÂú®ÁÆ°ÁêÜÁõ∏ÈóúÊï∏ÊìöÊñπÈù¢ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂÇ≥ÊüìÁóÖÊú¨È´î (IDO) ÂèäÂÖ∂Êì¥ÂÖÖÔºå‰æãÂ¶ÇÂÜ†ÁãÄÁóÖÊØíÂÇ≥ÊüìÁóÖÊú¨È´î (CIDO)ÔºåÂ∞çÊñºÁµÑÁπîÂíåÂÇ≥Êí≠ËàáÂÇ≥ÊüìÁóÖÁõ∏ÈóúÁöÑË≥áË®äËá≥ÈóúÈáçË¶Å„ÄÇCOVID-19 Â§ßÊµÅË°åÂá∏È°Ø‰∫ÜÊõ¥Êñ∞ IDO ÂèäÂÖ∂ÁâπÂÆöÊñºÁóÖÊØíÁöÑÊì¥ÂÖÖÁöÑÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåÈÇÑÊúâÊõ¥Êñ∞ÁâπÂÆöÊñºÁ¥∞Ëèå„ÄÅÁúüËèåÂíåÂØÑÁîüËü≤ÂÇ≥ÊüìÁóÖÁöÑ IDO Êì¥ÂÖÖÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÊé°Áî®„ÄåÊ®ûÁ¥êËºªÊ¢ù„ÄçÊñπÊ≥ï‰æÜÁî¢Áîü IDO ÁöÑÁâπÂÆöÊñºÁóÖÂéüÈ´îÁöÑÊì¥ÂÖÖÔºöÁóÖÊØíÂÇ≥ÊüìÁóÖÊú¨È´î (VIDO)„ÄÅÁ¥∞ËèåÂÇ≥ÊüìÁóÖÊú¨È´î (BIDO)„ÄÅÁúüËèåÁóÖÂÇ≥ÊüìÁóÖÊú¨È´î (MIDO) ÂíåÂØÑÁîüËü≤ÂÇ≥ÊüìÁóÖÊú¨È´î (PIDO)„ÄÇÁâπÂÆöÊñºÁóÖÂéüÈ´îÁöÑÂèÉËÄÉÊú¨È´îÁöÑÂª∫Á´ãÔºå‰øÉËøõ‰∫Ü IDO ÁîüÊÖãÁ≥ªÁµ±ÂÖßÂÇ≥ÊüìÁóÖÊï∏ÊìöÁöÑÊ®°ÁµÑÂåñÂíåÂèØÈáçË§á‰ΩøÁî®ÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∑•‰ΩúÂ∞áÈáçÈªûÊîæÂú®ÈÄ≤‰∏ÄÊ≠•ÂÆåÂñÑÈÄô‰∫õÊú¨È´î„ÄÅÂª∫Á´ãÊñ∞ÁöÑÊì¥ÂÖÖÔºå‰ª•ÂèäÊ†πÊìöÈÄô‰∫õÊú¨È´îÈñãÁôºÊáâÁî®Êú¨È´îÔºåÈÄôËàáÊ®ôÊ∫ñÂåñÁîüÁâ©ÂíåÁîüÁâ©ÈÜ´Â≠∏Ë°ìË™û‰ª•ÊîπÂñÑÊï∏ÊìöÂÖ±‰∫´ÂíåÂàÜÊûêÁöÑÊåÅÁ∫åÂä™ÂäõÁõ∏‰∏ÄËá¥„ÄÇ

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

ÊëòË¶ÅÔºöÂú®Ê≠§ÔºåÊàë‰ª¨ÊèèËø∞‰∫ÜÁ¨¨‰∏Ä‰∏™ Web Á∫ßÊ∑∑ÂêàÁü•ËØÜÂõæË∞± (KG) - Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)ÔºåÂÖ∂‰∏≠ÂÖÖÊñ•ÁùÄÊúâÂÖ≥ÁªìÁõ¥ËÇ†ÁôåÁöÑÊúÄÊñ∞ÂêåË°åËØÑÂÆ°ÂåªÂ≠¶Áü•ËØÜ„ÄÇÁõÆÂâçÊ≠£Âú®ËØÑ‰º∞ÂÆÉ‰ª•ÂçèÂä© Moffitt ÁôåÁóá‰∏≠ÂøÉËøõË°åÂåªÂ≠¶Á†îÁ©∂Âíå‰∏¥Â∫ä‰ø°ÊÅØÊ£ÄÁ¥¢‰ªªÂä°ÔºåËØ•‰∏≠ÂøÉÊòØÁæéÂõΩÂíå‰∏ñÁïåÈ°∂Á∫ßÁôåÁóá‰∏≠ÂøÉ‰πã‰∏Ä„ÄÇÊàë‰ª¨ÁöÑÊ∑∑Âêà‰ΩìÈùûÂ∏∏Âá∫Ëâ≤ÔºåÂõ†‰∏∫ÂÆÉÊØîÂ≠§Á´ãÁöÑ LLM„ÄÅKG ÊàñÊêúÁ¥¢ÂºïÊìéÊõ¥Â•ΩÂú∞Êª°Ë∂≥Áî®Êà∑ÈúÄÊ±Ç„ÄÇ‰ºóÊâÄÂë®Áü•ÔºåLLM ‰ºöÂá∫Áé∞ÂπªËßâÂíåÁÅæÈöæÊÄßÈÅóÂøòÔºåÂπ∂‰∏îÊòØÂú®ËøáÊó∂ÁöÑËØ≠ÊñôÂ∫ì‰∏äËøõË°åËÆ≠ÁªÉÁöÑ„ÄÇÊúÄÂÖàËøõÁöÑ KGÔºå‰æãÂ¶Ç PrimeKG„ÄÅcBioPortal„ÄÅChEMBL„ÄÅNCBI Á≠âÈúÄË¶Å‰∫∫Â∑•Êï¥ÁêÜÔºåÂõ†Ê≠§ÂæàÂø´Â∞±‰ºöËøáÊó∂„ÄÇCancerKG Êó†ÈúÄÁõëÁù£ÔºåËÉΩÂ§üËá™Âä®ÊëÑÂèñÂíåÁªÑÁªáÊúÄÊñ∞ÁöÑÂåªÂ≠¶ÂèëÁé∞„ÄÇ‰∏∫‰∫ÜÂáèËΩª LLM ÁöÑÁº∫ÁÇπÔºåÁªèËøáÈ™åËØÅÁöÑ KG ÂÖÖÂΩìÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) Êä§Ê†è„ÄÇCancerKG Â±ïÁ§∫‰∫Ü 5 Áßç‰∏çÂêåÁöÑÈ´òÁ∫ßÁî®Êà∑ÁïåÈù¢ÔºåÊØèÁßçÁïåÈù¢ÈÉΩÈíàÂØπÊúçÂä°‰∏çÂêåÁöÑÊï∞ÊçÆÊ®°ÂºèÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Â•Ω„ÄÅÊõ¥Êñπ‰æøÁöÑÊúçÂä°„ÄÇ

##### **An Empirical Evaluation of Large Language Models on Consumer Health Questions**
2501.00208v1 by Moaiz Abrar, Yusuf Sermet, Ibrahim Demir

This study evaluates the performance of several Large Language Models (LLMs)
on MedRedQA, a dataset of consumer-based medical questions and answers by
verified experts extracted from the AskDocs subreddit. While LLMs have shown
proficiency in clinical question answering (QA) benchmarks, their effectiveness
on real-world, consumer-based, medical questions remains less understood.
MedRedQA presents unique challenges, such as informal language and the need for
precise responses suited to non-specialist queries. To assess model
performance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1:
70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was
used, where each model evaluated its responses as well as those of others to
minimize bias. The results indicated that GPT-4o mini achieved the highest
alignment with expert responses according to four out of the five models'
judges, while Mistral-7B scored lowest according to three out of five models'
judges. This study highlights the potential and limitations of current LLMs for
consumer health medical question answering, indicating avenues for further
development.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú® MedRedQA ‰∏äÁöÑÊïàËÉΩÔºåMedRedQA ÊòØ‰∏ÄÁµÑÊ∂àË≤ªËÄÖÈÜ´ÁôÇÂïèÈ°åËàáÁ≠îÊ°àÁöÑË≥áÊñôÈõÜÔºåÁî± AskDocs Â≠êÁâàÂ°ä‰∏≠Á∂ìÈÅéÈ©óË≠âÁöÑÂ∞àÂÆ∂ÊâÄÊèêÂá∫„ÄÇÂÑòÁÆ° LLM Â∑≤Âú®Ëá®Â∫äÂïèÈ°åËß£Á≠î (QA) Âü∫Ê∫ñ‰∏≠Â±ïÁèæÂá∫Â∞àÊ•≠Áü•Ë≠òÔºå‰ΩÜÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïå„ÄÅÊ∂àË≤ªËÄÖÁÇ∫Âü∫Á§éÁöÑÈÜ´ÁôÇÂïèÈ°å‰∏äÁöÑÊúâÊïàÊÄß‰ªçËºÉ‰∏çÊòéÁ¢∫„ÄÇMedRedQA ÊèêÂá∫Áç®ÁâπÁöÑÊåëÊà∞Ôºå‰æãÂ¶ÇÈùûÊ≠£ÂºèË™ûË®ÄÂíåÂ∞çÈùûÂ∞àÂÆ∂Êü•Ë©¢Êèê‰æõÁ≤æÁ¢∫ÂõûÊáâÁöÑÈúÄÊ±Ç„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ê®°ÂûãÊïàËÉΩÔºå‰ΩøÁî®‰∫îÂÄã LLM ÁîüÊàê‰∫ÜÂõûÊáâÔºöGPT-4o mini„ÄÅLlama 3.1Ôºö70B„ÄÅMistral-123B„ÄÅMistral-7B Âíå Gemini-Flash„ÄÇ‰ΩøÁî®‰∫Ü‰∫§ÂèâË©ï‰º∞ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÊØèÂÄãÊ®°ÂûãË©ï‰º∞Ëá™Â∑±ÁöÑÂõûÊáâ‰ª•ÂèäÂÖ∂‰ªñÊ®°ÂûãÁöÑÂõûÊáâÔºå‰ª•ÊúÄÂ∞èÂåñÂÅèÂ∑Æ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊ†πÊìö‰∫îÂÄãÊ®°Âûã‰∏≠ÁöÑÂõõÂÄãÊ®°ÂûãË©ïÂØ©ÔºåGPT-4o mini ËàáÂ∞àÂÆ∂ÂõûÊáâÁöÑ‰∏ÄËá¥ÊÄßÊúÄÈ´òÔºåËÄåÊ†πÊìö‰∫îÂÄãÊ®°Âûã‰∏≠ÁöÑ‰∏âÂÄãÊ®°ÂûãË©ïÂØ©ÔºåMistral-7B ÁöÑÂàÜÊï∏ÊúÄ‰Ωé„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÁõÆÂâç LLM Âú®Ê∂àË≤ªËÄÖÂÅ•Â∫∑ÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÊñπÈù¢ÁöÑÊΩõÂäõÂíåÈôêÂà∂Ôºå‰∏¶ÊåáÂá∫ÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÁöÑÈÄîÂæë„ÄÇ

##### **GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study**
2501.00199v1 by Giuliano Lorenzoni, Pedro Elkind Velmovitsky, Paulo Alencar, Donald Cowan

Depression has impacted millions of people worldwide and has become one of
the most prevalent mental disorders. Early mental disorder detection can lead
to cost savings for public health agencies and avoid the onset of other major
comorbidities. Additionally, the shortage of specialized personnel is a
critical issue because clinical depression diagnosis is highly dependent on
expert professionals and is time consuming.
  In this study, we explore the use of GPT-4 for clinical depression assessment
based on transcript analysis. We examine the model's ability to classify
patient interviews into binary categories: depressed and not depressed. A
comparative analysis is conducted considering prompt complexity (e.g., using
both simple and complex prompts) as well as varied temperature settings to
assess the impact of prompt complexity and randomness on the model's
performance.
  Results indicate that GPT-4 exhibits considerable variability in accuracy and
F1-Score across configurations, with optimal performance observed at lower
temperature values (0.0-0.2) for complex prompts. However, beyond a certain
threshold (temperature >= 0.3), the relationship between randomness and
performance becomes unpredictable, diminishing the gains from prompt
complexity.
  These findings suggest that, while GPT-4 shows promise for clinical
assessment, the configuration of the prompts and model parameters requires
careful calibration to ensure consistent results. This preliminary study
contributes to understanding the dynamics between prompt engineering and large
language models, offering insights for future development of AI-powered tools
in clinical settings.

ÊëòË¶ÅÔºöÊÜÇÈ¨±ÁóáÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÔºåÂ∑≤ÊàêÁÇ∫ÊúÄÊôÆÈÅçÁöÑÁ≤æÁ•ûÁñæÁóÖ‰πã‰∏Ä„ÄÇÊèêÊó©ÂÅµÊ∏¨Á≤æÁ•ûÁñæÁóÖÔºåËÉΩÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÊ©üÊßãÁØÄÁúÅÊàêÊú¨Ôºå‰∏¶ÈÅøÂÖçÂÖ∂‰ªñ‰∏ªË¶ÅÂÖ±ÁóÖÁöÑÁôºÁîü„ÄÇÊ≠§Â§ñÔºåÂ∞àÊ•≠‰∫∫Âì°Áü≠Áº∫ÊòØ‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÔºåÂõ†ÁÇ∫Ëá®Â∫äÊÜÇÈ¨±ÁóáÁöÑË®∫Êñ∑È´òÂ∫¶‰æùË≥¥ÊñºÂ∞àÊ•≠‰∫∫Âì°Ôºå‰∏îËÄóÊôÇË≤ªÂäõ„ÄÇ
Âú®ÈÄôÂÄãÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰ΩøÁî® GPT-4 ÈÄ≤Ë°åËá®Â∫äÊÜÇÈ¨±ÁóáË©ï‰º∞ÔºåÂü∫Á§éÊòØË¨ÑÊú¨ÂàÜÊûê„ÄÇÊàëÂÄëÊ™¢Ë¶ñÊ®°ÂûãÂ∞áÁóÖ‰∫∫Ë®™Ë´áÂàÜÈ°ûÁÇ∫‰∫åÂÖÉÈ°ûÂà•ÔºàÊÜÇÈ¨±ÁóáÂíåÈùûÊÜÇÈ¨±ÁóáÔºâÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºåËÄÉÈáèÊèêÁ§∫Ë§áÈõúÂ∫¶Ôºà‰æãÂ¶ÇÔºåÂêåÊôÇ‰ΩøÁî®Á∞°ÂñÆÂíåË§áÈõúÁöÑÊèêÁ§∫ÔºâÔºå‰ª•ÂèäÂêÑÁ®ÆÊ∫´Â∫¶Ë®≠ÂÆöÔºå‰ª•Ë©ï‰º∞ÊèêÁ§∫Ë§áÈõúÂ∫¶ÂíåÈö®Ê©üÊÄßÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇ
ÁµêÊûúÈ°ØÁ§∫ÔºåGPT-4 Âú®ÂêÑÁµÑÊÖã‰∏≠ÁöÑÊ∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ËÆäÂåñÂæàÂ§ßÔºåÂú®Ë§áÈõúÊèêÁ§∫ÁöÑËºÉ‰ΩéÊ∫´Â∫¶ÂÄºÔºà0.0-0.2Ôºâ‰∏ãËßÄÂØüÂà∞ÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåË∂ÖÈÅéÊüêÂÄãÈñæÂÄºÔºàÊ∫´Â∫¶ >= 0.3ÔºâÂæåÔºåÈö®Ê©üÊÄßÂíåÊïàËÉΩ‰πãÈñìÁöÑÈóú‰øÇËÆäÂæóÈõ£‰ª•È†êÊ∏¨ÔºåÈôç‰Ωé‰∫ÜÊèêÁ§∫Ë§áÈõúÂ∫¶Â∏∂‰æÜÁöÑÊî∂Áõä„ÄÇ
ÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåÈõñÁÑ∂ GPT-4 Âú®Ëá®Â∫äË©ï‰º∞ÊñπÈù¢È°ØÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜÊèêÁ§∫ÂíåÊ®°ÂûãÂèÉÊï∏ÁöÑÁµÑÊÖãÈúÄË¶Å‰ªîÁ¥∞Ê†°Ê∫ñÔºå‰ª•Á¢∫‰øùÁµêÊûúÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂ÊúâÂä©Êñº‰∫ÜËß£ÊèêÁ§∫Â∑•Á®ãÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰πãÈñìÁöÑÂãïÊÖãÔºåÁÇ∫Êú™‰æÜÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÈñãÁôº AI È©ÖÂãïÂ∑•ÂÖ∑Êèê‰æõË¶ãËß£„ÄÇ

##### **SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction**
2501.00190v2 by Changchang Yin, Shihan Fu, Bingsheng Yao, Thai-Hoang Pham, Weidan Cao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is an organ dysfunction caused by a deregulated immune response to an
infection. Early sepsis prediction and identification allow for timely
intervention, leading to improved clinical outcomes. Clinical calculators
(e.g., the six-organ dysfunction assessment of SOFA) play a vital role in
sepsis identification within clinicians' workflow, providing evidence-based
risk assessments essential for sepsis diagnosis. However, artificial
intelligence (AI) sepsis prediction models typically generate a single sepsis
risk score without incorporating clinical calculators for assessing organ
dysfunctions, making the models less convincing and transparent to clinicians.
To bridge the gap, we propose to mimic clinicians' workflow with a novel
framework SepsisCalc to integrate clinical calculators into the predictive
model, yielding a clinically transparent and precise model for utilization in
clinical settings. Practically, clinical calculators usually combine
information from multiple component variables in Electronic Health Records
(EHR), and might not be applicable when the variables are (partially) missing.
We mitigate this issue by representing EHRs as temporal graphs and integrating
a learning module to dynamically add the accurately estimated calculator to the
graphs. Experimental results on real-world datasets show that the proposed
model outperforms state-of-the-art methods on sepsis prediction tasks.
Moreover, we developed a system to identify organ dysfunctions and potential
sepsis risks, providing a human-AI interaction tool for deployment, which can
help clinicians understand the prediction outputs and prepare timely
interventions for the corresponding dysfunctions, paving the way for actionable
clinical decision-making support for early intervention.

ÊëòË¶ÅÔºöÊïóË°ÄÁóáÊòØÁî±Â∞çÊÑüÊüìÁöÑÂ§±Ë™øÂÖçÁñ´ÂèçÊáâÊâÄÈÄ†ÊàêÁöÑÂô®ÂÆòÂäüËÉΩÈöúÁ§ô„ÄÇÊó©ÊúüÊïóË°ÄÁóáÈ†êÊ∏¨ÂíåË≠òÂà•ÊúâÂä©ÊñºÂèäÊôÇ‰ªãÂÖ•ÔºåÈÄ≤ËÄåÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇËá®Â∫äË®àÁÆóÂô®Ôºà‰æãÂ¶ÇÔºåSOFA ÁöÑÂÖ≠Âô®ÂÆòÂäüËÉΩÈöúÁ§ôË©ï‰º∞ÔºâÂú®Ëá®Â∫äÈÜ´Â∏´ÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏≠ÊâÆÊºîËëóÊïóË°ÄÁóáË≠òÂà•ÁöÑÈáçË¶ÅËßíËâ≤ÔºåÊèê‰æõÊïóË°ÄÁóáË®∫Êñ∑ÂøÖË¶ÅÁöÑË≠âÊìöÁÇ∫Âü∫Á§éÁöÑÈ¢®Èö™Ë©ï‰º∞„ÄÇÁÑ∂ËÄåÔºå‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÊïóË°ÄÁóáÈ†êÊ∏¨Ê®°ÂûãÈÄöÂ∏∏ÊúÉÁî¢ÁîüÂñÆ‰∏ÄÁöÑÊïóË°ÄÁóáÈ¢®Èö™Ë©ïÂàÜÔºåËÄåÊú™Á¥çÂÖ•Áî®ÊñºË©ï‰º∞Âô®ÂÆòÂäüËÉΩÈöúÁ§ôÁöÑËá®Â∫äË®àÁÆóÂô®Ôºå‰ΩøÂæóÊ®°ÂûãÂ∞çËá®Â∫äÈÜ´Â∏´‰æÜË™™È°ØÂæóËºÉ‰∏çÂÖ∑Ë™™ÊúçÂäõ‰∏îÈÄèÊòé„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫Ê®°Êì¨Ëá®Â∫äÈÜ´Â∏´ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºå‰ΩøÁî®ÂâµÊñ∞ÁöÑ SepsisCalc Êû∂ÊßãÂ∞áËá®Â∫äË®àÁÆóÂô®Êï¥ÂêàÂà∞È†êÊ∏¨Ê®°Âûã‰∏≠ÔºåÁî¢Áîü‰∏ÄÂÄãÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰ΩøÁî®ÊôÇÂÖ∑ÊúâËá®Â∫äÈÄèÊòéÂ∫¶‰∏îÁ≤æÁ¢∫ÁöÑÊ®°Âûã„ÄÇÂØ¶Èöõ‰∏äÔºåËá®Â∫äË®àÁÆóÂô®ÈÄöÂ∏∏ÊúÉÁµêÂêàÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºàEHRÔºâ‰∏≠Â§öÂÄãÁµÑÊàêËÆäÊï∏ÁöÑË≥áË®äÔºå‰∏îÁï∂ËÆäÊï∏ÔºàÈÉ®ÂàÜÔºâÈÅ∫Â§±ÊôÇÂèØËÉΩ‰∏çÈÅ©Áî®„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞á EHR Ë°®Á§∫ÁÇ∫ÊôÇÈñìÂúñÂΩ¢‰∏¶Êï¥Âêà‰∏ÄÂÄãÂ≠∏ÁøíÊ®°ÁµÑÔºåÂãïÊÖãÂ∞áÊ∫ñÁ¢∫‰º∞Ë®àÁöÑË®àÁÆóÂô®Êñ∞Â¢ûÂà∞ÂúñÂΩ¢‰∏≠Ôºå‰æÜÊ∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÊïóË°ÄÁóáÈ†êÊ∏¨‰ªªÂãô‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±‰æÜË≠òÂà•Âô®ÂÆòÂäüËÉΩÈöúÁ§ôÂíåÊΩõÂú®ÁöÑÊïóË°ÄÁóáÈ¢®Èö™ÔºåÊèê‰æõ‰∏ÄÂÄãÂèØÁî®ÊñºÈÉ®ÁΩ≤ÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰∫íÂãïÂ∑•ÂÖ∑ÔºåÈÄôÊúâÂä©ÊñºËá®Â∫äÈÜ´Â∏´‰∫ÜËß£È†êÊ∏¨Ëº∏Âá∫Ôºå‰∏¶ÈáùÂ∞çÁõ∏ÊáâÁöÑÂäüËÉΩÈöúÁ§ôÊ∫ñÂÇôÂèäÊôÇÁöÑ‰ªãÂÖ•Êé™ÊñΩÔºåÁÇ∫Êó©Êúü‰ªãÂÖ•ÁöÑË°åÂãïËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Èã™Ë∑Ø„ÄÇ


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajƒÖc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|

#### Abstracts
##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

ÊëòË¶ÅÔºöÈöèÁùÄÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÂú®ÂåªÂ≠¶Êï∞ÊçÆ‰∏≠Ëé∑ÂæóÂÖ≥Ê≥®ÔºåÁ°Æ‰øùÈÄèÊòé‰∏îÂÄºÂæó‰ø°ËµñÁöÑÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÁöÆËÇ§ÁôåËØäÊñ≠‰∏≠ÔºåËôΩÁÑ∂ÁóÖÁÅ∂Ê£ÄÊµãÂíåÂàÜÁ±ªÁöÑËøõÊ≠•ÊèêÈ´ò‰∫ÜÂáÜÁ°ÆÊÄßÔºå‰ΩÜËøô‰∫õÊñπÊ≥ïÁöÑÈªëÁõíÊÄßË¥®ÂØπÁêÜËß£ÂÖ∂ÂÜ≥Á≠ñËøáÁ®ãÊûÑÊàê‰∫ÜÊåëÊàòÔºåÂØºËá¥ÂåªÁîü‰πãÈó¥ÁöÑ‰ø°‰ªªÈóÆÈ¢ò„ÄÇÊú¨Á†îÁ©∂Âà©Áî®Âú®‰∏çÂêåÁöÆËÇ§ÁóÖÂèòÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑ CLIPÔºàÂØπÊØîËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉÔºâÊ®°ÂûãÔºå‰ª•ÊçïÊçâËßÜËßâÁâπÂæÅÂíåËØäÊñ≠Ê†áÂáÜÊúØËØ≠‰πãÈó¥ÁöÑÊúâÊÑè‰πâÂÖ≥Á≥ª„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•ÊèêÈ´òÈÄèÊòéÂ∫¶ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ MedGrad E-CLIP ÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈÄöËøáÁªìÂêà‰∏ì‰∏∫ÁöÆËÇ§ÁóÖÂèòÁ≠âÂ§çÊùÇÂåªÂ≠¶ÂΩ±ÂÉèËÆæËÆ°ÁöÑÂä†ÊùÉÁÜµÊú∫Âà∂ÔºåÂª∫Á´ãÂú®Âü∫‰∫éÊ¢ØÂ∫¶ÁöÑ E-CLIP ‰πã‰∏ä„ÄÇÊ≠§ÊñπÊ≥ïÁ™ÅÂá∫‰∫Ü‰∏éÁâπÂÆöËØäÊñ≠ÊèèËø∞Áõ∏ÂÖ≥ËÅîÁöÑÂÖ≥ÈîÆÂõæÂÉèÂå∫Âüü„ÄÇÂºÄÂèëÁöÑÈõÜÊàêÁÆ°ÈÅì‰∏ç‰ªÖÈÄöËøáÂåπÈÖçÁõ∏Â∫îÁöÑÊèèËø∞ÂØπÁöÆËÇ§ÁóÖÂèòËøõË°åÂàÜÁ±ªÔºåËøòÊ∑ªÂä†‰∫Ü‰∏ÄÂ±Ç‰∏ìÈó®‰∏∫ÂåªÂ≠¶Êï∞ÊçÆÂºÄÂèëÁöÑÂü∫Êú¨ÂèØËß£ÈáäÊÄß„ÄÇÈÄöËøáÁõ¥ËßÇÂú∞Ëß£ÈáäÂõæÂÉè‰∏≠‰∏çÂêåÁâπÂæÅ‰∏éËØäÊñ≠Ê†áÂáÜÁöÑÂÖ≥Á≥ªÔºåËøôÁßçÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÈ´òÁ∫ßËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê‰∏≠ÁöÑÊΩúÂäõÔºåÊúÄÁªàÊèêÈ´ò‰∫ÜÈÄèÊòéÂ∫¶„ÄÅÁ®≥ÂÅ•ÊÄßÂíåÂØπ‰∫∫Â∑•Êô∫ËÉΩÈ©±Âä®ÁöÑËØäÊñ≠Á≥ªÁªüÁöÑ‰ø°‰ªª„ÄÇ

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

ÊëòË¶ÅÔºöÂπΩÈªòÈ¢®Ê†ºÂ∞çÂπ∏Á¶èÊÑüÂèØËÉΩÁî¢ÁîüË≤†Èù¢ÊàñÊ≠£Èù¢ÁöÑÂΩ±Èüø„ÄÇ
ÈëëÊñºÈÄô‰∫õÈ¢®Ê†ºÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÁöÑÈáçË¶ÅÊÄßÔºåÂ∑≤Á∂ìÂ∞çÂÖ∂Ëá™ÂãïË≠òÂà•ÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁî®ÊñºÊ≠§ÁõÆÁöÑÁöÑËá™ÂãïÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÊòØÈªëÁõíÂ≠êÔºå‰ΩøÂæóÂÖ∂È†êÊ∏¨Ê±∫Á≠ñ‰∏çÈÄèÊòé„ÄÇÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶Âú®ÂøÉÁêÜÂÅ•Â∫∑È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑ AI (XAI) Ê°ÜÊû∂ÔºåÁî®ÊñºÁêÜËß£ÂπΩÈªòÈ¢®Ê†ºÂàÜÈ°ûÔºåÂª∫Á´ãÂú®Ë®àÁÆóÂπΩÈªòÂàÜÊûêÁöÑÂÖàÂâçÂ∑•‰Ωú‰πã‰∏ä„ÄÇ‰ΩøÁî®ÂÖàÂâçÁ†îÁ©∂‰∏≠Ë°®ÁèæÊúÄÂ•ΩÁöÑÂñÆ‰∏ÄÊ®°Âûã (ALI+XGBoost)ÔºåÊàëÂÄëÊáâÁî®ÂÖ®Èù¢ÁöÑ XAI ÊäÄË°ì‰æÜÂàÜÊûêË™ûË®Ä„ÄÅÊÉÖÁ∑íÂíåË™ûÁæ©ÁâπÂæµÂ¶Ç‰ΩïÂΩ±ÈüøÂπΩÈªòÈ¢®Ê†ºÂàÜÈ°ûÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫Ü‰∏çÂêåÂπΩÈªòÈ¢®Ê†ºÂ¶Ç‰ΩïË¢´Ë°®ÂæµÂíåÈåØË™§ÂàÜÈ°ûÁöÑ‰∏çÂêåÊ®°ÂºèÔºåÁâπÂà•Âº∑Ë™ø‰∫ÜÂçÄÂàÜËÅØÂ±¨ÂπΩÈªòËàáÂÖ∂‰ªñÈ¢®Ê†ºÁöÑÊåëÊà∞„ÄÇÈÄöÈÅé‰ªîÁ¥∞Ê™¢Êü•ÁâπÂæµÈáçË¶ÅÊÄß„ÄÅÈåØË™§Ê®°ÂºèÂíåÈåØË™§ÂàÜÈ°ûÊ°à‰æãÔºåÊàëÂÄëÁ¢∫ÂÆö‰∫ÜÂΩ±ÈüøÊ®°ÂûãÊ±∫Á≠ñÁöÑÈóúÈçµÂõ†Á¥†ÔºåÂåÖÊã¨ÊÉÖÁ∑íÊ®°Á≥ä„ÄÅÊÉÖÂ¢ÉË™§Ëß£ÂíåÁõÆÊ®ôË≠òÂà•„ÄÇË©≤Ê°ÜÊû∂Â±ïÁ§∫‰∫ÜÂú®ÁêÜËß£Ê®°ÂûãË°åÁÇ∫ÊñπÈù¢ÁöÑÈ°ØËëóÊïàÁî®ÔºåÂØ¶Áèæ‰∫ÜÂ∞çÂÆöÁæ©‰∏çÂêåÂπΩÈªòÈ¢®Ê†ºÁöÑÁâπÂæµ‰πãÈñìË§áÈõúÁõ∏‰∫í‰ΩúÁî®ÁöÑÂèØËß£ÈáãË¶ãËß£„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊúâÂä©ÊñºË®àÁÆóÂπΩÈªòÂàÜÊûêÁöÑÁêÜË´ñÁêÜËß£ÂíåÂøÉÁêÜÂÅ•Â∫∑„ÄÅÂÖßÂÆπÂØ©Ê†∏ÂíåÊï∏Â≠ó‰∫∫ÊñáÁ†îÁ©∂‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇ

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÈúÄÊ±ÇÁöÑÂ¢ûÂä†ÔºåÂá∏È°Ø‰∫ÜÂâµÊñ∞Ëß£Ê±∫ÊñπÊ°àÁöÑÈúÄÊ±ÇÔºåÁâπÂà•ÊòØÂú®ÂøÉÁêÜÂ∞çË©±Âºè‰∫∫Â∑•Êô∫ÊÖßÈ†òÂüüÔºåÈÇ£Ë£°Áº∫‰πèÊïèÊÑüË≥áÊñô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Á¥¢‰∫ÜÈñãÁôº‰∏ÄÂÄãÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅÁöÑÁ≥ªÁµ±ÔºåÊé°Áî®‰∏ÄÁ®ÆÂü∫ÊñºÂèØËß£ÈáãÁöÑÊÉÖÁ∑íÁâπÂæµÁöÑÊñ∞ÊñπÊ≥ïÈÄ≤Ë°åÂøÉÁêÜË©ï‰º∞ÔºåÁµêÂêàÂêåÁêÜÂøÉÂ∞çË©±Ê®°ÂºèÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÂ∑•ÂÖ∑ÔºåÁî®ÊñºÊì¥ÂÖÖÂÇ≥Áµ±ÁÖßË≠∑ÔºåÁâπÂà•ÊòØÂú®ÁÑ°Ê≥ïÁ´ãÂç≥Áç≤ÂæóÂ∞àÊ•≠Áü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÊàëÂÄëÁöÑÂ∑•‰ΩúÂèØ‰ª•ÂàÜÁÇ∫ÂÖ©ÂÄã‰∏ªË¶ÅÈÉ®ÂàÜÔºåÂΩºÊ≠§ÂÖßÂú®Áõ∏Èóú„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü RACLETTEÔºå‰∏ÄÂÄãÂ∞çË©±Á≥ªÁµ±ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåÂú®ÁêÜËß£‰ΩøÁî®ËÄÖÊÉÖÁ∑íÁãÄÊÖãÂíåÂú®Â∞çË©±‰∏≠Áî¢ÁîüÂêåÁêÜÂøÉÂõûÊáâÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Ë∂äÁöÑÊÉÖÁ∑íÊ∫ñÁ¢∫ÊÄßÔºåÂêåÊôÇÈÄèÈÅé‰ªñÂÄëÁöÑ‰∫íÂãïÈÄêÊº∏Âª∫Á´ã‰ΩøÁî®ËÄÖÁöÑÊÉÖÁ∑íÁâπÂæµ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ËÄÖÁöÑÊÉÖÁ∑íÁâπÂæµÂ¶Ç‰ΩïÂèØÁî®‰ΩúÂøÉÁêÜÂÅ•Â∫∑Ë©ï‰º∞ÁöÑÂèØËß£ÈáãÊ®ôË®ò„ÄÇÈÄô‰∫õÁâπÂæµÂèØ‰ª•ËàáËàá‰∏çÂêåÂøÉÁêÜÁñæÁóÖÁõ∏ÈóúÁöÑÂÖ∏ÂûãÊÉÖÁ∑íÊ®°ÂºèÈÄ≤Ë°åÊØîËºÉÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂàùÊ≠•ÁØ©ÈÅ∏ÂíåÊîØÊåÅÁöÑÊñ∞ÊñπÊ≥ï„ÄÇ

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∑≤ÊàêÁÇ∫Â¢ûÂº∑È´îÂ§ñÂèóÁ≤æÔºàIVFÔºâÊ±∫Á≠ñÂà∂ÂÆöÂíåÂÑ™ÂåñÊ≤ªÁôÇÊñπÊ°àÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÁâπÂà•ÊòØÔºåAI Âú®ÊîØÊåÅ IVF ÈÅéÁ®ã‰∏≠ÂçµÂ∑¢Âà∫ÊøÄÈöéÊÆµÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊñπÈù¢È°ØÁ§∫Âá∫È°ØËëóÁöÑÂâçÊôØ„ÄÇÊú¨Á∂úËø∞Ë©ï‰º∞‰∫ÜÂ∞àÊ≥®Êñº AI ÁµêÂêàÂçµÂ∑¢Âà∫ÊøÄ‰∏≠ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®„ÄÅÊ™¢È©óÊñπÊ≥ï„ÄÅÁµêÊûúÂíåÁï∂ÂâçÈôêÂà∂ÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÂ∞ç 13 È†ÖÈóúÊñºÊ≠§‰∏ªÈ°åÁöÑÁ†îÁ©∂ÂàÜÊûêÈ°ØÁ§∫ÔºåÈõñÁÑ∂ AI ÊºîÁÆóÊ≥ïÂú®È†êÊ∏¨ÊúÄ‰Ω≥Ëç∑ÁàæËíôÂäëÈáè„ÄÅËß∏ÁôºÊôÇÊ©üÂíåÂçµÂ≠êÂèñÂá∫ÁµêÊûúÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõÔºå‰ΩÜÊâÄÂà©Áî®ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÊï∏Êìö‰∏ªË¶Å‰æÜËá™Êñº‰∫åÊ¨°ÂÖÉÔºà2DÔºâË∂ÖÈü≥Ê≥¢ÔºåËÄå‰∫åÊ¨°ÂÖÉË∂ÖÈü≥Ê≥¢‰∏ªË¶ÅÊ∂âÂèäÂü∫Êú¨ÈáèÂåñÔºå‰æãÂ¶ÇÊøæÊ≥°Â§ßÂ∞èÂíåÊï∏ÈáèÔºå‰∏îÊúâÈôê‰ΩøÁî®Áõ¥Êé•ÁâπÂæµÊèêÂèñÊàñÈÄ≤ÈöéÂΩ±ÂÉèÂàÜÊûêÊäÄË°ì„ÄÇÈÄôÊåáÂêë‰∏ÄÂÄãÂ∞öÊú™Êé¢Á¥¢ÁöÑÊ©üÊúÉÔºå‰æãÂ¶ÇÊ∑±Â∫¶Â≠∏ÁøíÁ≠âÈÄ≤ÈöéÂΩ±ÂÉèÂàÜÊûêÊñπÊ≥ïÔºå‰ª•ÂèäÊõ¥Â§öÂÖÉÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºå‰æãÂ¶Ç‰∏âÁ∂≠Ôºà3DÔºâË∂ÖÈü≥Ê≥¢ÔºåÂèØ‰ª•Ëß£ÈéñÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Á†îÁ©∂Áº∫‰πèÂèØËß£Èáã AIÔºàXAIÔºâÔºåÈÄôÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞ç AI È©ÖÂãïÊ±∫Á≠ñÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËøΩÊ∫ØÊÄßÁöÑÊìîÊÜÇÔºåËÄåÈÄèÊòéÂ∫¶ÂíåÂèØËøΩÊ∫ØÊÄßÊòØËá®Â∫äÊé°Áî®Âíå‰ø°‰ªªÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊ≠§Â§ñÔºåË®±Â§öÁ†îÁ©∂‰æùË≥¥ÊñºÂñÆ‰∏≠ÂøÉË®≠Ë®àÂíåÂ∞èÂûãÊï∏ÊìöÈõÜÔºåÈÄôÈôêÂà∂‰∫ÜÂÖ∂ÁôºÁèæÁöÑÊôÆÈÅçÊÄß„ÄÇÊú¨Á∂úËø∞Âº∑Ë™ø‰∫ÜÂ∞áÈÄ≤ÈöéÂΩ±ÂÉèÂàÜÊûêÊäÄË°ìËàáÂèØËß£Èáã AI ÊñπÊ≥ïÊï¥ÂêàËµ∑‰æÜÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•ÂèäÂà©Áî®Â§ö‰∏≠ÂøÉÂêà‰ΩúÂíåÂ§ßÂûãÊï∏ÊìöÈõÜÁöÑÈáçË¶ÅÊÄß„ÄÇËß£Ê±∫ÈÄô‰∫õÂ∑ÆË∑ùÊúâÂèØËÉΩÂ¢ûÂº∑ÂçµÂ∑¢Âà∫ÊøÄÁÆ°ÁêÜÔºåÁÇ∫ÊúâÊïà„ÄÅÂÄã‰∫∫ÂåñÂíåÊï∏ÊìöÈ©ÖÂãïÁöÑÊ≤ªÁôÇÈÄîÂæëÈã™Âπ≥ÈÅìË∑ØÔºåÈÄ≤ËÄåÊîπÂñÑ IVF ÁµêÊûú„ÄÇ

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁôåÁóáË®∫Êñ∑ÂíåÈ†êÊ∏¨ÊñπÊ≥ïÔºå‰ΩøÁî®ÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖß (XAI) ÂíåÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ì„ÄÇÁî±ÊñºÁôåÁóáÂú® 2020 Âπ¥ÈÄ†ÊàêÂÖ®ÁêÉËøë 1,000 Ëê¨‰∫∫Ê≠ª‰∫°ÔºåÂõ†Ê≠§Êó©ÊúüÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏Èù¢Ëá®ÊàêÊú¨„ÄÅÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÊñπÈù¢ÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈñãÁôº‰∫Ü‰∏ÄÂÄã AI Ê®°ÂûãÔºåÂÆÉÊèê‰æõÁ≤æÁ¢∫ÁöÑÁµêÊûú‰∏¶Ê∏ÖÊ•öÂú∞‰∫ÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ãÔºåËß£Ê±∫‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑ„ÄåÈªëÁÆ±„ÄçÂïèÈ°å„ÄÇÈÄöÈÅéÊé°Áî® XAI ÊäÄË°ìÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶ÔºåÂú®ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÂíåÊÇ£ËÄÖ‰πãÈñìÂª∫Á´ã‰ø°‰ªª„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÊûêÂª£Ê≥õÁöÑÊï∏ÊìöÈõÜÔºåË≠òÂà•ÁôåÁóáÊ™¢Ê∏¨Ê®°Âºè„ÄÇÈÄôÂÄãÊ®°ÂûãÊúâÂèØËÉΩÈÄöÈÅéÊèêÈ´òÈÜ´ÁôÇÊ±∫Á≠ñÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÂèØÂèäÊÄßÂíåÊ∏ÖÊô∞Â∫¶‰æÜÈù©Êñ∞Ë®∫Êñ∑ÔºåÂèØËÉΩÂ∞éËá¥Êõ¥Êó©ÁöÑÊ™¢Ê∏¨ÂíåÊõ¥ÂÄãÊÄßÂåñÁöÑÊ≤ªÁôÇÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÂÆÉÂèØ‰ª•‰ΩøÊõ¥Â§ö‰∫∫Áç≤ÂæóÈ´òÂìÅË≥™ÁöÑË®∫Êñ∑ÔºåÁâπÂà•ÊòØÂú®Ë≥áÊ∫êÊúâÈôêÁöÑÁí∞Â¢É‰∏≠ÔºåÊúâÂä©ÊñºÂÖ®ÁêÉÂÅ•Â∫∑ÂÖ¨Âπ≥„ÄÇË©≤Ê®°ÂûãÁöÑÊáâÁî®ÁØÑÂúç‰∏çÂÉÖÈôêÊñºÁôåÁóáË®∫Êñ∑ÔºåÈÇÑÂèØËÉΩËΩâËÆäÈÜ´ÁôÇÊ±∫Á≠ñÁöÑÂêÑÂÄãÊñπÈù¢Ôºå‰∏¶ÊãØÊïëÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÂëΩ„ÄÇ

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÈÄ≤Ê≠•‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰ΩÜÂèØËß£ÈáãÊÄßÊåëÊà∞ÈòªÁ§ô‰∫ÜÂÖ∂Ëá®Â∫äÊé°Áî®„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅé‰ΩøÁî®Ê¶ÇÂøµÁì∂È†∏Ê®°Âûã (CBM) ÂíåÂ§öÈáç‰ª£ÁêÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÈÄ≤Ë°åÂ†±ÂëäÁîüÊàêÔºåÂ¢ûÂº∑‰∫ÜËÉ∏ÈÉ® X ÂÖâ (CXR) ÂàÜÈ°ûÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄèÈÅéÂ∞çË¶ñË¶∫ÁâπÂæµÂíåËá®Â∫äÊ¶ÇÂøµ‰πãÈñìÁöÑÈóú‰øÇÈÄ≤Ë°åÂª∫Ê®°ÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜÂèØËß£ÈáãÁöÑÊ¶ÇÂøµÂêëÈáèÔºåÁî®‰æÜÂºïÂ∞éÂ§öÈáç‰ª£ÁêÜ RAG Á≥ªÁµ±ÁîüÊàêÊîæÂ∞ÑÁßëÂ†±ÂëäÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÁõ∏ÈóúÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÊÄß„ÄÇ‰ΩøÁî® LLM ‰ΩúÁÇ∫Âà§Êñ∑ËÄÖÂ∞çÁîüÊàêÁöÑÂ†±ÂëäÈÄ≤Ë°åË©ï‰º∞ÔºåÁ¢∫Ë™ç‰∫ÜÊàëÂÄëÊ®°ÂûãËº∏Âá∫ÁöÑÂèØËß£ÈáãÊÄßÂíåËá®Â∫äÂØ¶Áî®ÊÄß„ÄÇÂú® COVID-QU Ë≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 81% ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂº∑ÂÅ•ÁöÑÂ†±ÂëäÁîüÊàêÊïàËÉΩÔºå‰∫îÈ†ÖÈóúÈçµÊåáÊ®ô‰ªãÊñº 84% Âà∞ 90% ‰πãÈñì„ÄÇÈÄôÂÄãÂèØËß£ÈáãÁöÑÂ§öÈáç‰ª£ÁêÜÊû∂ÊßãÂΩåÂêà‰∫ÜÈ´òÊÄßËÉΩ AI ËàáÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÂèØÈù† AI È©ÖÂãï CXR ÂàÜÊûêÊâÄÈúÄÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇ

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

ÊëòË¶ÅÔºöËÉåÊôØÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁõÆÂâçÂú®ÈÜ´ÁôÇÈ†òÂüüÁÑ°ÊâÄ‰∏çÂú®Ôºå‰ΩÜ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊé¢Ë®éÂÖ∂Êé®ÁêÜË°åÁÇ∫ÁöÑÁ†îÁ©∂ÂçªÁõ∏Áï∂Áº∫‰πè„ÄÇÊàëÂÄëÂº∑Ë™ø‰∫ÜËß£Êé®ÁêÜË°åÁÇ∫ËÄåÈùûÈ´òÂ±§Á¥öÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†ÁÇ∫Âú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÈÄôÁ≠âÂêåÊñºÂèØËß£Èáã AI (XAI)„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Ëá®Â∫äÈ†òÂüü‰∏≠‰ΩøÁî®ÁöÑÈÜ´ÁôÇ LLM ‰∏≠ÂØ¶Áèæ XAIÔºåÂ∞áÂ∞çÊï¥ÂÄãÈÜ´ÁôÇ‰øùÂÅ•Áî¢Ê•≠Áî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÁµêÊûúÔºöÂõ†Ê≠§ÔºåÊàëÂÄëÂú®ÈÜ´ÁôÇ LLM ÁöÑÁâπÂÆöËÉåÊôØ‰∏ãÂÆöÁæ©‰∫ÜÊé®ÁêÜË°åÁÇ∫ÁöÑÊ¶ÇÂøµ„ÄÇÊé•ËëóÊàëÂÄëÂàÜÈ°û‰∏¶Êé¢Ë®éÁï∂ÂâçË©ï‰º∞ÈÜ´ÁôÇ LLM ‰∏≠Êé®ÁêÜË°åÁÇ∫ÁöÑÊñπÊ≥ïÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫ÁêÜË´ñÊû∂ÊßãÔºåËÆìÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÊàñÊ©üÂô®Â≠∏ÁøíÂ∑•Á®ãÂ∏´Âæó‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÈÄô‰∫õÂÖàÂâçÊ®°Á≥äÊ®°ÂûãÁöÑ‰ΩéÂ±§Á¥öÊé®ÁêÜÈÅãÁÆó„ÄÇÁµêË´ñÔºöËá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÂ∞çÈÜ´ÁôÇÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÈÄèÊòéÂ∫¶Âíå‰ø°‰ªªÂ∫¶Èö®‰πãÊèêÂçáÔºåÂ∞áÂä†ÈÄüÈÜ´ÁôÇ AI Âú®Êï¥ÂÄãÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠ÁöÑÊï¥Âêà„ÄÅÊáâÁî®ÂíåÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ï„ÄÇ

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

ÊëòË¶ÅÔºöÂ£ìÂäõÊòØ‰∏ÄÂÄãÊôÆÈÅçÁöÑÂÖ®ÁêÉÊÄßÂÅ•Â∫∑ÂïèÈ°åÔºåÂèØËÉΩÊúÉÂ∞éËá¥Âö¥ÈáçÁöÑÁ≤æÁ•û
ÂÅ•Â∫∑ÂïèÈ°å„ÄÇÊó©ÊúüÁôºÁèæÊèê‰æõÂèäÊôÇÁöÑÂπ≤È†êÂíåÈ†êÈò≤
Â£ìÂäõÁõ∏ÈóúÁñæÁóÖ„ÄÇÁõÆÂâçÁöÑÊó©ÊúüÁôºÁèæÊ®°ÂûãÂü∑Ë°å„ÄåÈªë
ÁõíÂ≠ê„ÄçÊé®Ë´ñÔºåÂ≠òÂú®ÂèØËß£ÈáãÊÄßÂíå‰ø°‰ªªÂ∫¶ÊúâÈôêÁöÑÂïèÈ°åÔºåÈòªÁ§ô‰∫Ü
ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÊáâÁî®„ÄÇÂ§öËôß‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂºïÂÖ•ÁöÑÁîüÊàêÂ±¨ÊÄßÔºåÊ≠§È°û
Ê®°ÂûãÁöÑÊ±∫Á≠ñÂíåÈ†êÊ∏¨ÈÄöÈÅéÂ∞çÊáâÊèèËø∞ÂÖ∑ÊúâÂçäÂèØËß£ÈáãÊÄß„ÄÇÁÑ∂ËÄåÔºå
ÁèæÊúâÁöÑ LLM ‰∏ªË¶ÅÈáùÂ∞ç‰∏ÄËà¨Áî®ÈÄîÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊ≤íÊúâÂøÉÁêÜË™çÁü•ÁêÜË´ñÁöÑÊåáÂ∞é„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈ¶ñÂÖàÂº∑Ë™ø
ÂÖàÈ©óÁêÜË´ñÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ËßÄÂØüÂà∞ÈáùÂ∞çÂ£ìÂäõÊ™¢Ê∏¨ÈáèË∫´ÂÆöÂà∂ÁöÑÊÄùÊÉ≥ÈèàÊèêÂçá‰∫ÜÊÄßËÉΩ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁ®±ÁÇ∫Ë™çÁü•
ÈèàÈÄöÈÅéÂü∫ÊñºË™çÁü•Ë©ï‰º∞ÁêÜË´ñÁöÑÂæ™Â∫èÊº∏ÈÄ≤ÁöÑË™çÁü•Ë¶ñËßíÈó°Êòé‰∫ÜÂ£ìÂäõÁöÑÁî¢ÁîüÔºå‰∏¶ÂÖ∑ÊúâÈÄ≤Â∫¶ÁÆ°ÈÅìÔºö
Âà∫ÊøÄ $\rightarrow$ Ë©ï‰º∞ $\rightarrow$ ÂèçÊáâ $\rightarrow$ Â£ìÂäõ
ÁãÄÊÖãÔºåÊåáÂ∞é LLM Êèê‰æõÂÖ®Èù¢ÁöÑÊé®ÁêÜËß£Èáã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•
ÈÄöÈÅéÂ∞áÂÖ∂Áî®‰Ωú LLM Êåá‰ª§Ë™øÊï¥ÁöÑÂêàÊàêÊï∏ÊìöÈõÜÁîüÊàêÊ®°Êùø‰æÜÁ†îÁ©∂ÊâÄÊèêÂá∫ÁöÑË™çÁü•ÈèàÊ†ºÂºèÂ∏∂‰æÜÁöÑÂÑ™ÈªûÔºå‰∏¶‰ªãÁ¥π CogInstructÔºåÈÄôÊòØ‰∏ÄÂÄãÈáùÂ∞çÂ£ìÂäõÊ™¢Ê∏¨ÁöÑÊåá‰ª§Ë™øÊï¥Êï∏ÊìöÈõÜ„ÄÇÈÄôÂÄã
Êï∏ÊìöÈõÜÊòØ‰ΩøÁî®‰∏ÄÂÄã‰∏âÈöéÊÆµÁöÑËá™ÁúÅÊ®ôË®ªÁÆ°ÈÅìÈñãÁôºÁöÑÔºå‰Ωø LLM ËÉΩÂ§†Ëá™‰∏ªÁîüÊàêÂíåÂÑ™ÂåñÊåá‰ª§Êï∏Êìö„ÄÇÈÄöÈÅé
‰ΩøÁî® CogInstruct Â∞ç Llama3 ÈÄ≤Ë°åÊåá‰ª§Ë™øÊï¥ÔºåÊàëÂÄëÈñãÁôº‰∫Ü CogLLMÔºåÈÄôÊòØ‰∏ÄÂÄãÂèØËß£ÈáãÁöÑ
Â£ìÂäõÊ™¢Ê∏¨Ê®°Âûã„ÄÇË©ï‰º∞Ë°®ÊòéÔºåCogLLM Âú®ÊèêÈ´òÂèØËß£ÈáãÊÄßÁöÑÂêåÊôÇÂØ¶Áèæ‰∫ÜÂá∫Ëâ≤ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄöÈÅéÂ∞áË™çÁü•ÁêÜË´ñÊï¥ÂêàÂà∞ LLM Êé®ÁêÜÈÅéÁ®ã‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºå
ÁÇ∫Êú™‰æÜÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇ

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

ÊëòË¶ÅÔºö‰∫∫Ê©üÂçî‰ΩúÂú®ÈÜ´ÁôÇ AI ‰∏≠ÔºåÈúÄË¶ÅÊàëÂÄëÁêÜËß£ÂèóÈÅéË®ìÁ∑¥ÁöÑËá®Â∫äÈÜ´ÁîüÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÊáâÈáçË¶ñ AI È†êÊ∏¨„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂È°ØÁ§∫ AI ËºîÂä©Âú®ÊîπÂñÑËá®Â∫äÈ†êÊ∏¨ÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰ΩÜÁèæÊúâÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÔºåË¶Å‰∏çÂ∞±Ê≤íÊúâÊèê‰æõÈ†êÊ∏¨ÁöÑÂèØËß£ÈáãÊÄßÔºåË¶Å‰∏çÂ∞±ÊòØ‰ΩøÁî®ÂÉèÈ°ØËëóÊÄßÂíå Shapley ÂÄº‰πãÈ°ûÁöÑÊäÄË°ìÔºåÈÄô‰∫õÊäÄË°ì‰∏çÂÖÅË®±Âü∫ÊñºÈÜ´ÁîüÁöÑÈ©óË≠â„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊú¨Á†îÁ©∂Â∞áÂÖàÂâç‰ΩøÁî®ÁöÑÂèØËß£Èáã AI ÊäÄË°ìËàá‰∏ÄÁ®ÆÊñ∞ÊèêÂá∫ÁöÑÁ®±ÁÇ∫„Äå2 Âõ†Â≠êÊ™¢Á¥¢ (2FR)„ÄçÁöÑÊäÄË°ìÈÄ≤Ë°åÊØîËºÉÔºåÂæåËÄÖÊòØ‰∏ÄÁ®Æ‰ªãÈù¢Ë®≠Ë®àÂíåÊêúÂ∞ãÊ™¢Á¥¢ÁöÑÁµÑÂêàÔºåÂÆÉÊúÉÂÇ≥ÂõûÊ®ôÁ±§Áõ∏‰ººÁöÑË≥áÊñôÔºåËÄå‰∏çÊúÉËôïÁêÜÈÄô‰∫õË≥áÊñô„ÄÇÈÄôÊúÉÁî¢Áîü‰∏ÄÂÄã 2 Âõ†Â≠êÂÆâÂÖ®Ê©üÂà∂ÔºåÂÖ∂‰∏≠Ôºö(a) Ê≠£Á¢∫ÁöÑÂΩ±ÂÉèÈúÄË¶ÅÁî± AI Ê™¢Á¥¢Ôºõ(b) ‰∫∫È°ûÊáâÂ∞áÊ™¢Á¥¢ÁöÑÂΩ±ÂÉèËàáÊ≠£Âú®Ê∏¨Ë©¶‰∏≠ÁöÑÁóÖÁêÜËÅØÊÉ≥Ëµ∑‰æÜ„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂Âú®ËÉ∏ÈÉ® X ÂÖâË®∫Êñ∑‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÊôÇÔºå2FR ÊúÉÊèêÈ´òËá®Â∫äÈÜ´ÁîüÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÁâπÂà•ÊòØÂú®Ëá®Â∫äÈÜ´ÁîüÊòØÊîæÂ∞ÑÁßëÈÜ´Áîü‰∏îÂ∞çÂÖ∂Ê±∫Á≠ñ‰ø°ÂøÉ‰∏çË∂≥ÊôÇÔºåÊúÉÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫ÜÁêÜËß£‰∫∫Ê©üÊ±∫Á≠ñÁöÑ‰∏çÂêåÊ®°ÂºèÂ¶Ç‰ΩïÂΩ±ÈüøËá®Â∫äÈÜ´ÁîüÂú®Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±‰∏≠ÁöÑÊ∫ñÁ¢∫ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

ÊëòË¶ÅÔºö<paragraph>‰∫ÜËß£ÂÖ¨ÁúæÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑË™çÁü•‰ª•ÂèäÊΩõÂú®È¢®Èö™ËàáÂ•ΩËôï‰πãÈñìÁöÑÊ¨äË°°Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÈÄô‰∫õË™çÁü•ÂèØËÉΩÊúÉÂΩ±ÈüøÊîøÁ≠ñÊ±∫Á≠ñ„ÄÅÂΩ±ÈüøÊàêÂäüÂ∏ÇÂ†¥Á≠ñÁï•ÁöÑÂâµÊñ∞ËªåË∑°Ôºå‰∏¶Ê±∫ÂÆöÂÄã‰∫∫ÂíåÁ§æÊúÉÂ∞ç AI ÊäÄË°ìÁöÑÊé•ÂèóÂ∫¶„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®‰æÜËá™Âæ∑ÂúãÁöÑ 1100 ÂêçÂèÉËàáËÄÖÁöÑ‰ª£Ë°®ÊÄßÊ®£Êú¨ÔºåÊé¢Ë®é‰∫Ü AI ÁöÑÂøÉÊô∫Ê®°Âûã„ÄÇÂèÉËàáËÄÖÂ∞ç 71 È†ÖÈóúÊñº AI Êú™‰æÜËÉΩÂäõÁöÑÈô≥Ëø∞Ôºà‰æãÂ¶ÇÔºåËá™ÂãïÈßïÈßõ„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅËóùË°ì„ÄÅÊîøÊ≤ª„ÄÅÊà∞Áà≠ÂíåÁ§æÊúÉÂàÜÊ≠ßÔºâÈÄ≤Ë°å‰∫ÜÂÆöÈáèË©ï‰º∞ÔºåË©ï‰º∞È†êÊúüÁöÑÁôºÁîüÂèØËÉΩÊÄß„ÄÅÊÑüÁü•È¢®Èö™„ÄÅÂ•ΩËôïÂíåÊï¥È´îÂÉπÂÄº„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÈ†êÊ∏¨ÁöÑÊéíÂêçÔºå‰∏¶ÈôÑ‰∏äË¶ñË¶∫ÂåñÊò†Â∞ÑÔºåË™™Êòé‰∫ÜÂÖ¨ÁúæÁöÑÈ¢®Èö™Êî∂ÁõäÊ¨äË°°„ÄÇÂÑòÁÆ°Ë®±Â§öÂ†¥ÊôØË¢´Ë™çÁÇ∫ÊòØÂèØËÉΩÁöÑÔºå‰ΩÜÂèÉËàáËÄÖÈÄöÂ∏∏Â∞áÂÆÉÂÄëËàáÈ´òÈ¢®Èö™„ÄÅÊúâÈôêÁöÑÂ•ΩËôïÂíå‰ΩéÊï¥È´îÂÉπÂÄºËÅØÁπ´Ëµ∑‰æÜ„ÄÇÂú®ÊâÄÊúâÂ†¥ÊôØ‰∏≠Ôºå96.4% ($r^2=96.4\%$) ÁöÑÂÉπÂÄºË©ï‰º∞Â∑ÆÁï∞ÂèØ‰ª•Áî®ÊÑüÁü•È¢®Èö™ ($\beta=-.504$) ÂíåÊÑüÁü•Â•ΩËôï ($\beta=+.710$) ‰æÜËß£ÈáãÔºåËàáÈ†êÊúüÁöÑÂèØËÉΩÊÄßÊ≤íÊúâÈ°ØËëóÈóú‰øÇ„ÄÇ‰∫∫Âè£Áµ±Ë®àÂíå‰∫∫Ê†ºÁâπË≥™ÂΩ±Èüø‰∫ÜÂ∞çÈ¢®Èö™„ÄÅÂ•ΩËôïÂíåÊï¥È´îË©ï‰º∞ÁöÑÁúãÊ≥ïÔºåÈÄôÂá∏È°Ø‰∫ÜÊèêÈ´ò AI Á¥†È§äÂíåÊ†πÊìö‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±ÇË™øÊï¥ÂÖ¨ÂÖ±Ë≥áË®äÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÈÄöÈÅéÂº∑Ë™øÈóúÈçµÁöÑÂÖ¨ÂÖ±ÈóúÊ≥®ÂíåËàáÂÄã‰∫∫ÂÉπÂÄºËßÄ‰∏ÄËá¥ÁöÑ AI ÈñãÁôºÂøÖ‰∏çÂèØÂ∞ëÁöÑÂÄã‰∫∫Âõ†Á¥†ÔºåÁÇ∫Á†îÁ©∂‰∫∫Âì°„ÄÅÈñãÁôº‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÊèê‰æõ‰∫ÜÂèØË°åÁöÑË¶ãËß£„ÄÇ</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠Ê©üÂô®Â≠∏ÁøíÂíå AI ÁöÑ‰ΩøÁî®Â∞çÊñºËá®Â∫äË¶ãËß£ÂÖ∑ÊúâÁõ∏Áï∂Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË≥áÊñôÁï∞Ë≥™ÊÄß„ÄÅÁ®ÄÁñèÊÄß„ÄÅÊôÇÈñìÈåØ‰ΩçÂíåÊ®ôÁ±§ÁµêÊûúÊúâÈôêÔºåÊ≠§ÊñπÊ≥ïÈù¢Ëá®ÊåëÊà∞„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÂà©Áî®‰æÜËá™Ëã±ÂúãÂ∏ÉÈáåÊñØÊâò„ÄÅÂåóËñ©ÈªòÂ°ûÁâπÂíåÂçóÊ†ºÊ¥õÊñØÁâπÈÉ°Á¥Ñ‰∏ÄÁôæËê¨ÂêçÂéªË≠òÂà•ÂÄã‰∫∫ÈÄ£ÁµêÁöÑ EHR Ë≥áÊñôÈõÜÔºå‰æÜÊèèËø∞Â∞øË∑ØÊÑüÊüì (UTI)„ÄÇÊàëÂÄëÂØ¶ÊñΩ‰∫ÜÂ∞áÂéüÂßã EHR Ë≥áÊñôËΩâÊèõÁÇ∫ÁµêÊßãÂåñÊ†ºÂºèÁöÑË≥áÊñôÂâçËôïÁêÜÂíåÊï¥ÁêÜÁÆ°Á∑öÔºåÈÅ©ÂêàÈñãÁôºÂ∞àÊ≥®ÊñºË≥áÊñôÂÖ¨Âπ≥ÊÄß„ÄÅÂïèË≤¨Âà∂ÂíåÈÄèÊòéÂ∫¶ÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÈëëÊñº UTI ÁúüÂØ¶ÁµêÊûúÁöÑÂèØÁî®ÊÄßÊúâÈôêÂíåÂÅèÂ∑ÆÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁî±Ëá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÂëäÁü•ÁöÑ UTI È¢®Èö™Ë©ï‰º∞Êû∂ÊßãÔºå‰ª•‰º∞Ë®àÂÄãÂà•ÊÇ£ËÄÖÊôÇÈñìËª∏‰∏äÁöÑ UTI È¢®Èö™„ÄÇÊàêÂ∞çÁöÑ XGBoost Ê®°Âûã‰ΩøÁî®Ê≠§Êû∂ÊßãÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•ÂçÄÂàÜ UTI È¢®Èö™È°ûÂà•Ôºå‰∏¶ÊáâÁî®ÂèØËß£ÈáãÁöÑ AI ÊäÄË°ì‰æÜË≠òÂà•ÈóúÈçµÈ†êÊ∏¨Âõ†Â≠ê‰∏¶ÊîØÊåÅÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫Ü‰∏çÂêåÈ¢®Èö™Áæ§ÁµÑÂú®Ëá®Â∫äÂíå‰∫∫Âè£Áµ±Ë®àÈ†êÊ∏¨Âõ†Â≠ê‰∏äÁöÑÂ∑ÆÁï∞„ÄÇÈõñÁÑ∂ÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫Ü AI È©ÖÂãïË¶ãËß£Âú®ÊîØÊè¥ UTI Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰ΩÜ‰ªçÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Ë™øÊü•ÊÇ£ËÄÖÂ≠êÁæ§È´îÂíåÂª£Ê≥õÈ©óË≠âÔºå‰ª•Á¢∫‰øùÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÂíåÈÅ©Áî®ÊÄß„ÄÇ

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºå‰∏îË∂ä‰æÜË∂äÈõ£‰ª•Ë¢´‰∫∫ÁêÜËß£Ôºå‰∫ÜËß£Êï∏‰ΩçÁ≥ªÁµ±Â¶Ç‰ΩïÊîØÊè¥Ëá®Â∫äÊ±∫Á≠ñÁöÑÈúÄÊ±Ç‰πüÊó•ÁõäÂ¢ûÂä†„ÄÇÈÄôÁ®ÆË§áÈõúÊÄßÂºïÁôº‰∫ÜÂ∞çÂèØ‰ø°Â∫¶ÁöÑÁñëÊÖÆÔºåÂΩ±Èüø‰∫ÜÊ≠§È°ûÊäÄË°ìÁöÑÂÆâÂÖ®‰∏îÊúâÊïàÊé°Áî®„ÄÇÊîπÂñÑÂ∞çÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑÁêÜËß£Ôºå‰ª•ÂèäÂ∞çÊ±∫Á≠ñÊîØÊè¥Â∑•ÂÖ∑ÊâÄÊèê‰æõË™™ÊòéÁöÑË¶ÅÊ±ÇÔºåÊòØÊèê‰æõÊúâÊïàÂèØËß£ÈáãËß£Ê±∫ÊñπÊ°àÁöÑÈáçË¶ÅÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄôÂú®Ë≥áÊñôÂØÜÈõÜ„ÄÅÂø´ÁØÄÂ•èÁöÑÂä†Ë≠∑ÁóÖÊàø (ICU) Áí∞Â¢É‰∏≠ÁâπÂà•Áõ∏Èóú„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄô‰∫õÂïèÈ°åÔºåÂ∞ç‰∏É‰Ωç ICU Ëá®Â∫äÈÜ´Â∏´ÈÄ≤Ë°å‰∫ÜÂ∞èÁµÑË®™Ë´áÔºåÈÄô‰∫õÈÜ´Â∏´‰ª£Ë°®‰∫Ü‰∏çÂêåÁöÑËßíËâ≤ÂíåÁ∂ìÈ©óÂ±§Á¥ö„ÄÇ‰∏ªÈ°åÂàÜÊûêÊè≠Èú≤‰∫Ü‰∏âÂÄãÊ†∏ÂøÉ‰∏ªÈ°åÔºö(T1) ICU Ê±∫Á≠ñÂà∂ÂÆö‰æùË≥¥ÊñºÂª£Ê≥õÁöÑÂõ†Á¥†Ôºå(T2) ÁóÖÊÇ£ÁãÄÊÖãÁöÑË§áÈõúÊÄßÂ∞çÂÖ±ÂêåÊ±∫Á≠ñÂà∂ÂÆöÊßãÊàêÊåëÊà∞Ôºå‰ª•Âèä (T3) AI Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑË¶ÅÊ±ÇÂíåËÉΩÂäõ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜËá®Â∫äËº∏ÂÖ•ÁöÑË®≠Ë®àÂª∫Ë≠∞ÔºåÊèê‰æõË¶ãËß£‰ª•Êèê‰æõË≥áË®äÁµ¶Êú™‰æÜÁî®ÊñºÂä†Ë≠∑ÁöÑ AI Á≥ªÁµ±„ÄÇ

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

ÊëòË¶ÅÔºöÂ∞èÂÖíÂøÉËáüÁñæÁóÖÂëàÁèæÂÖàÂ§©ÊÄßËàáÂæåÂ§©ÊÄßÁñæÁóÖÁöÑÂª£Ê≥õÂÖâË≠ú„ÄÇËºÉË§áÈõúÁöÑÂÖàÂ§©ÊÄßÁï∏ÂΩ¢ÈúÄË¶Å‰∏ÄÂÄãÂ∑ÆÁï∞Âåñ‰∏îÂ§öÊ®°ÂºèÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÈÄöÂ∏∏ÂåÖÊã¨Ë∂ÖÈü≥Ê≥¢Ê™¢Êü•‰ΩúÁÇ∫‰∏ªË¶ÅÁöÑÂΩ±ÂÉèÊñπÊ≥ï„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÂ∏åÊúõÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•‰øÉÈÄ≤Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•Ë≥áÊñôÁöÑËá™ÂãïÂåñËß£ËÆÄ„ÄÇÁÑ∂ËÄåÔºåÂ∞á‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊáâÁî®ÊñºÂ∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•ÂàÜÊûêÊúâË®±Â§öÊåëÊà∞Ôºå‰æãÂ¶ÇÊúâÈôêÁöÑÂÖ¨ÈñãË≥áÊñôÂèØÁî®ÊÄß„ÄÅË≥áÊñôÈö±ÁßÅÂíå‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÈÄèÊòéÂ∫¶„ÄÇÊúÄËøëÔºåÁ†îÁ©∂‰∫∫Âì°Â∞àÊ≥®ÊñºÁ†¥Â£ûÊÄßÊäÄË°ìÔºå‰æãÂ¶ÇËÅØÂêàÂ≠∏Áøí (FL) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•ÊîπÂñÑËá™ÂãïË®∫Êñ∑ÂíåÊ±∫Á≠ñÊîØÊè¥Â∑•‰ΩúÊµÅÁ®ã„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÂú®Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•‰∏≠ÁöÑÈôêÂà∂ÂíåÊ©üÊúÉÁöÑÂÖ®Èù¢Ê¶ÇËø∞ÔºåÂº∑Ë™ø‰∫Ü XAI Âíå FL ÁöÑÂçîÂêåÂ∑•‰ΩúÊµÅÁ®ãÂíåËßíËâ≤ÔºåÊâæÂá∫Á†îÁ©∂Â∑ÆË∑ù‰∏¶Êé¢Ë®éÊΩõÂú®ÁöÑÊú™‰æÜÁôºÂ±ï„ÄÇÊ≠§Â§ñÔºå‰∏âÂÄãÁõ∏ÈóúÁöÑËá®Â∫ä‰ΩøÁî®Ê°à‰æãÂ±ïÁ§∫‰∫Ü XAI Âíå FL ÁöÑÂäüËÉΩÔºåÈáçÈªûÂú®Êñº (i) Ê™¢Ë¶ñËæ®Ë≠ò„ÄÅ(ii) ÁñæÁóÖÂàÜÈ°û„ÄÅ(iii) ÂøÉËáüÁµêÊßãÂàÜÂâ≤Âíå (iv) ÂøÉËáüÂäüËÉΩÁöÑÈáèÂåñË©ï‰º∞„ÄÇ

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

ÊëòË¶ÅÔºöÈ™®Ë≥™ÁñèÈ¨ÜÁóáÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÁñæÁóÖÔºåÊúÉÂ¢ûÂä†È™®ÊäòÁöÑÈ¢®Èö™ÔºåÁâπÂà•ÊòØËÄÅÂπ¥‰∫∫„ÄÇÊó©ÊúüË®∫Êñ∑Â∞çÊñºÈ†êÈò≤È™®Êäò„ÄÅÈôç‰ΩéÊ≤ªÁôÇÊàêÊú¨ÂíåÁ∂≠ÊåÅË°åÂãïËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÈù¢Ëá®ËëóÊ®ôË®òÊï∏ÊìöÊúâÈôêÂíåËôïÁêÜÈÜ´Â≠∏ÂΩ±ÂÉèÂõ∞Èõ£Á≠âÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÊ®°ÂºèÂ≠∏ÁøíÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Êï¥Âêà‰∫ÜËá®Â∫äÂíåÂΩ±ÂÉèÊï∏ÊìöÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇË©≤Ê®°ÂûãÂà©Áî®‰∏âÂÄãÈ†êË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºåVGG19„ÄÅInceptionV3 Âíå ResNet50ÔºåÂæû X Â∞ÑÁ∑öÂΩ±ÂÉè‰∏≠ÊèêÂèñÊ∑±Â∫¶ÁâπÂæµ„ÄÇÈÄô‰∫õÁâπÂæµ‰ΩøÁî® PCA ËΩâÊèõ‰ª•Èôç‰ΩéÁ∂≠Â∫¶‰∏¶Â∞àÊ≥®ÊñºÊúÄÁõ∏ÈóúÁöÑÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂü∫ÊñºËÅöÈ°ûÁöÑÈÅ∏ÊìáÈÅéÁ®ãË≠òÂà•Âá∫ÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÁÑ∂ÂæåÂ∞áÈÄô‰∫õÁµÑÊàêÈÉ®ÂàÜËàáÈ†êËôïÁêÜÁöÑËá®Â∫äÊï∏ÊìöÁµêÂêàÔºå‰∏¶ÈÄöÈÅéÂÖ®ÈÄ£Êé•Á∂≤Ë∑Ø (FCN) ÈÄ≤Ë°åÊúÄÁµÇÂàÜÈ°û„ÄÇÁâπÂæµÈáçË¶ÅÊÄßÂúñÁ™ÅÂá∫‰∫ÜÈóúÈçµËÆäÊï∏ÔºåË°®ÊòéÁóÖÂè≤„ÄÅBMI ÂíåË∫´È´òÊòØ‰∏ªË¶ÅË≤¢ÁçªÂõ†Á¥†ÔºåÂº∑Ë™ø‰∫ÜÊÇ£ËÄÖÁâπÂÆöÊï∏ÊìöÁöÑÈáçË¶ÅÊÄß„ÄÇÈõñÁÑ∂ÂΩ±ÂÉèÁâπÂæµÂæàÊúâÂÉπÂÄºÔºå‰ΩÜÂÆÉÂÄëÁöÑÈáçË¶ÅÊÄßËºÉ‰ΩéÔºåÈÄôË°®ÊòéËá®Â∫äÊï∏ÊìöÂ∞çÊñºÊ∫ñÁ¢∫È†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊ≠§Ê°ÜÊû∂‰øÉËøõ‰∫ÜÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨ÔºåÊèêÈ´ò‰∫ÜÈÄèÊòéÂ∫¶Ôºå‰∏¶Âª∫Á´ã‰∫ÜÂ∞ç AI È©ÖÂãïË®∫Êñ∑Âú®Ëá®Â∫äÊï¥Âêà‰∏≠ÁöÑ‰ø°‰ªª„ÄÇ

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

ÊëòË¶ÅÔºöÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂú®Èùû‰æµÂÖ•ÂºèË™çÁü•ÂäüËÉΩÈöúÁ§ôÊ™¢Ê∏¨‰∏äÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂêÑÁ®ÆÈùû‰æµÂÖ•ÂºèÁöÑË™çÁü•Ë°∞ÈÄÄÊåáÊ®ôÔºåÂåÖÊã¨Ë™ûË®ÄÂíåË™ûË®Ä„ÄÅÈù¢ÈÉ®ÂíåÈÅãÂãïÊ©üËÉΩ„ÄÇÊú¨ÊñáÊ¶ÇËø∞‰∫ÜËàáÊ≠§È†òÂüüÁõ∏ÈóúÁöÑË≥áÊñôÈõÜ„ÄÅÁâπÂæµÊèêÂèñÊäÄË°ìÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇÊàëÂÄëÂàÜÊûê‰∫Ü‰∏çÂêåÊñπÊ≥ïÂú®‰∏çÂêåÊñπÂºè‰∏äÁöÑË°®ÁèæÔºå‰∏¶ËßÄÂØüÂà∞Âü∫ÊñºË™ûË®ÄÂíåË™ûË®ÄÁöÑÊñπÊ≥ïÈÄöÂ∏∏ËÉΩÈÅîÂà∞ÊúÄÈ´òÁöÑÊ™¢Ê∏¨Ë°®Áèæ„ÄÇÁµêÂêàËÅ≤Â≠∏ÂíåË™ûË®ÄÁâπÂæµÁöÑÁ†îÁ©∂ÂæÄÂæÄÂÑ™Êñº‰ΩøÁî®ÂñÆ‰∏ÄÊñπÂºèÁöÑÁ†îÁ©∂„ÄÇÈù¢ÈÉ®ÂàÜÊûêÊñπÊ≥ïÈ°ØÁ§∫Âá∫Ë¶ñË¶∫ÊñπÂºèÁöÑÊΩõÂäõÔºå‰ΩÜÁ†îÁ©∂ËºÉÂ∞ë„ÄÇÂ§ßÂ§öÊï∏Ë´ñÊñáÂ∞àÊ≥®Êñº‰∫åÂÖÉÂàÜÈ°ûÔºàÂèóÊêçËàáÊú™ÂèóÊêçÔºâÔºåËºÉÂ∞ëÊé¢Ë®éÂ§öÈ°ûÊàñÂõûÊ≠∏‰ªªÂãô„ÄÇÈÅ∑ÁßªÂ≠∏ÁøíÂíåÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂ∑≤ÊàêÁÇ∫ÊµÅË°å‰∏îÊúâÊïàÁöÑÊäÄË°ìÔºåÁâπÂà•ÊòØÂ∞çÊñºË™ûË®ÄÂàÜÊûê„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏Ä‰∫õÊåëÊà∞ÔºåÂåÖÊã¨Ë≥áÊñôÊ®ôÊ∫ñÂåñÂíåÂèØÂèäÊÄß„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÅÁ∏±ÂêëÂàÜÊûêÈôêÂà∂ÂíåËá®Â∫äÈÅ©ÊáâÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰æãÂ¶ÇË™øÊü•ËàáË™ûË®ÄÁÑ°ÈóúÁöÑË™ûÈü≥ÂàÜÊûêÊñπÊ≥ï„ÄÅÈñãÁôºÂ§öÊ®°ÂºèË®∫Êñ∑Á≥ªÁµ±Ôºå‰ª•ÂèäËß£Ê±∫‰∫∫Â∑•Êô∫ÊÖßËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÈÄèÈÅéÁ∂úÂêàÁõÆÂâçÁöÑË∂®Âã¢ÂíåÊâæÂá∫ÈóúÈçµÈöúÁ§ôÔºåÊú¨ÁØáË©ïË´ñÊó®Âú®ÂºïÂ∞éÊ∑±Â∫¶Â≠∏ÁøíÁÇ∫Âü∫Á§éÁöÑË™çÁü•ÂäüËÉΩÈöúÁ§ôÊ™¢Ê∏¨Á≥ªÁµ±ÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÔºå‰ª•ÊîπÂñÑÊó©ÊúüË®∫Êñ∑Ôºå‰∏¶ÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇ

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∞àÊ≥®ÊñºÂçîÂä©‰∫∫È°û‰∫ÜËß£ AI Á≥ªÁµ±ÈÅã‰ΩúÊàñÂÖ∂Ê±∫Á≠ñÔºåÊï∏ÂçÅÂπ¥‰æÜ‰∏ÄÁõ¥ÊòØ AI ÁöÑÂü∫Áü≥„ÄÇÊúÄËøëÁöÑÂèØËß£ÈáãÊÄßÁ†îÁ©∂Â∞àÊ≥®ÊñºËß£Èáã AI Ê®°ÂûãÊàñÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÈÅã‰Ωú„ÄÇ‰πüÊúâÂπæ‰ªΩÁ´ãÂ†¥ËÅ≤ÊòéÂíåË©ïË´ñË´ñÊñáË©≥Á¥∞Ë™™Êòé‰∫ÜÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞ç‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÔºå‰ΩÜÂØ¶‰ΩúËºÉÂ∞ë„ÄÇÂõ†Ê≠§ÔºåÊú¨Ë´ñÊñáÊó®Âú®ÂΩåË£úÊ®°ÂûãÂíå‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑ‰∏Ä‰∫õÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂª∫Á´ã‰∏ÄÂÄãËß£ÈáãÊú¨È´îÔºàEOÔºâ‰ª•ÈÄèÈÅéÂÖ∂ÊîØÊè¥ÂÖÉ‰ª∂‰æÜË°®Á§∫ÂæûÊñáÁçª‰∏≠Ë°çÁîüÁöÑËß£ÈáãÈ°ûÂûã„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∏ÄÂÄãÁü•Ë≠òÂ¢ûÂº∑ÁöÑÂïèÁ≠îÔºàQAÔºâÁÆ°Á∑öÔºå‰ª•Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊîØÊè¥ÊÉÖÂ¢ÉËß£Èáã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ≠£Âú®ÂØ¶‰Ωú‰∏ÄÂÄãÁ≥ªÁµ±Ôºå‰ª•ÁµêÂêà‰æÜËá™‰∏çÂêå AI ÊñπÊ≥ïÂíåË≥áÊñôÊ®°ÂºèÁöÑËß£Èáã„ÄÇÂú® EO ‰∏≠ÔºåÊàëÂÄëÂèØ‰ª•Ë°®Á§∫ 15 Á®Æ‰∏çÂêåÁöÑËß£ÈáãÈ°ûÂûãÔºå‰∏¶‰∏îÊàëÂÄëÂ∑≤Âú®ÂÖ≠ÂÄãÁØÑ‰æã‰ΩøÁî®Ê°à‰æã‰∏≠Ê∏¨Ë©¶ÈÄô‰∫õË°®Á§∫„ÄÇÊàëÂÄëÁôºÁèæÔºåÁü•Ë≠òÂ¢ûÂº∑ÊîπÂñÑ‰∫ÜÂü∫Á§éÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÊÉÖÂ¢ÉÂåñ QA ‰∏≠ÁöÑÊïàËÉΩÔºå‰∏¶‰∏îÊïàËÉΩÂõ†ÁñæÁóÖÁæ§ÁµÑËÄåÁï∞„ÄÇÂú®Áõ∏ÂêåÁöÑÁí∞Â¢É‰∏≠ÔºåËá®Â∫äÈÜ´Áîü‰πüË°®Á§∫‰ªñÂÄëÂ∏åÊúõÂ∞áÂèØÊìç‰ΩúÊÄßË¶ñÁÇ∫Ëß£Èáã‰∏≠ÁöÑ‰∏ªË¶ÅÁÑ¶Èªû‰πã‰∏Ä„ÄÇÂú®ÊàëÂÄëÁöÑËß£ÈáãÁµÑÂêàÊñπÊ≥ï‰∏≠ÔºåÊàëÂÄëË®àÁï´‰ΩøÁî®Áõ∏‰ººÊÄßÊåáÊ®ô‰æÜÁ¢∫ÂÆöÊÖ¢ÊÄßÁóÖÂÅµÊ∏¨Áí∞Â¢É‰∏≠Ëß£ÈáãÁöÑÁõ∏‰ººÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÈÄèÈÅéÊú¨Ë´ñÊñáÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂèØ‰ª•Âú®‰∏çÂêå‰ΩøÁî®Ê°à‰æã‰∏≠ÊîØÊè¥Áü•Ë≠òÂïüÁî®Ëß£ÈáãÁöÑÊñπÊ≥ïÔºåËÄÉÈáèÂà∞Áï∂‰ªä AI ÊôÇ‰ª£‰∏≠ÂèØ‰ª•Áî¢ÁîüÈÄô‰∫õËß£ÈáãÁöÑÊîØÊè¥ÂÖÉ‰ª∂ÂíåÂèØ‰ª•Â¢ûÂº∑ÈÄô‰∫õËß£ÈáãÁöÑÈ†òÂüüÁü•Ë≠ò‰æÜÊ∫êÁöÑÊñπÊ≥ï„ÄÇ

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÁöÑÔºöË™øÊü•Ëá®Â∫äÈÜ´ÁîüÂ∞çÁõÆÂâçËá™ÂãïÂåñÂøÉÈõªÂúñËß£ËÆÄÂíåÊñ∞ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÁöÑÊÖãÂ∫¶Ôºå‰ª•Âèä‰ªñÂÄëÂ∞çÈõªËÖ¶ËºîÂä©Ëß£ËÆÄÁöÑÁúãÊ≥ï„ÄÇÊùêÊñôÂíåÊñπÊ≥ïÔºöÊàëÂÄëÂ∞çËã±ÂúãÁöÑËá®Â∫äÈÜ´ÁîüÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóË®™Ë´á„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ôºö(i) Êé¢Ë®é‰∫∫Â∑•Êô∫ÊÖßÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÊú™‰æÜÁöÑ„ÄåÈ°û‰∫∫È°û„ÄçÈÅãÁÆóÊñπÊ≥ïÔºå‰ª•‰øÉÈÄ≤ÂøÉÈõªÂúñËß£ËÆÄ‰∏¶ÊîØÊåÅËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÔºå‰ª•Âèä (ii) ÂæµÊ±Ç‰ªñÂÄëÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÊºîÁÆóÊ≥ïÁöÑÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÁúãÊ≥ï„ÄÇÁµêÊûúÔºöÊàëÂÄëÂ∞ç 23 ‰ΩçËá®Â∫äÈÜ´ÁîüÁöÑË®™Ë´áË®òÈåÑÈÄ≤Ë°å‰∫ÜÊ≠∏Á¥ç‰∏ªÈ°åÂàÜÊûêÔºå‰∏¶ÊâæÂá∫‰ª•‰∏ã‰∏ªÈ°åÔºö(i) Â∞çÁõÆÂâçÁ≥ªÁµ±Áº∫‰πè‰ø°‰ªªÔºå(ii) Â∞çÊú™‰æÜ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÂíåÂ∞çÈÄô‰∫õÊáâÁî®ÁöÑË¶ÅÊ±ÇÊåÅÊ≠£Èù¢ÊÖãÂ∫¶Ôºå(iii) ÊºîÁÆóÊ≥ïÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•Âèä (iv) Â∞çÊïôËÇ≤„ÄÅÂèØËÉΩÁöÑÊäÄËÉΩÈÄÄÂåñÔºå‰ª•Âèä‰∫∫Â∑•Êô∫ÊÖßÂ∞çËá®Â∫äËÉΩÂäõÁöÑÂΩ±ÈüøÁöÑÁúãÊ≥ï„ÄÇË®éË´ñÔºöËá®Â∫äÈÜ´Áîü‰∏ç‰ø°‰ªªÁõÆÂâçÁöÑÈõªËÖ¶ÂåñÊñπÊ≥ïÔºå‰ΩÜÊ≠°ËøéÊú™‰æÜÁöÑ„Äå‰∫∫Â∑•Êô∫ÊÖß„ÄçÊäÄË°ì„ÄÇÂú®Ëá®Â∫äÈÜ´ÁîüÁõ∏‰ø°Êú™‰æÜÁöÑ AI Ëß£ËÆÄÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ªñÂÄë‰∏çÂ§™ÊìîÂøÉÂÆÉÊòØÂê¶ÂèØËß£Èáã„ÄÇ‰ªñÂÄë‰πüÊØîËºÉÂñúÊ≠°ËÉΩ‰ª•Ë¶ñË¶∫ÊñπÂºèÂëàÁèæÊºîÁÆóÊ≥ïÁµêÊûúÁöÑÂøÉÈõªÂúñËß£ËÆÄ„ÄÇÈõñÁÑ∂Ëá®Â∫äÈÜ´Áîü‰∏çÂÆ≥ÊÄïÂ§±Ê•≠Ôºå‰ΩÜ‰ªñÂÄëÊìîÂøÉÊäÄËÉΩÈÄÄÂåñÔºå‰ª•ÂèäÈúÄË¶ÅÊïôËÇ≤Âì°Â∑•Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁµêË´ñÔºöËá®Â∫äÈÜ´ÁîüÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÂú®Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö‰∏≠ÁöÑÊú™‰æÜÊáâÁî®ÊåÅÊ≠£Èù¢ÊÖãÂ∫¶„ÄÇÊ∫ñÁ¢∫ÊÄßÊòØÊé°Áî®‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰∏ÄÂÄãÈóúÈçµÂõ†Á¥†ÔºåËÄåË¶ñË¶∫ÂåñÊØîÁõÆÂâçÁöÑÈõªËÖ¶ÂåñÊñπÊ≥ïÊõ¥ÂèóÈùíÁùû„ÄÇÈÄôË¢´Ë¶ñÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®ÁöÑÂüπË®ìÂíåÊèêÂçáÊäÄËÉΩÁöÑÊñπÊ≥ïÔºåËàáËá™ÂãïÂåñÂèØËÉΩÂ∏∂‰æÜÁöÑÊäÄËÉΩÈÄÄÂåñÂΩ¢ÊàêÂ∞çÊØî„ÄÇ</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenm√ºller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Comp√©rat, Andreas Gocht, Monika H√§mmerle, Niels J. Rupp, Jula Westhoff, Irene Kr√ºcken, Maximillian Seidl, Christian M. Sch√ºrch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian H√∂rner, Kirsten D. Mertz, Constanze D√∂ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

ÊëòË¶ÅÔºöÂâçÂàóËÖ∫ÁôåÊòØÂÖ®ÁêÉÁî∑ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÁôåÁóáÔºåÂÖ∂ÊÉ°ÊÄßÁ®ãÂ∫¶‰∏ªË¶ÅÊ†πÊìö Gleason Ë©ïÂàÜÁ≥ªÁµ±‰ΩøÁî®ÁµÑÁπîÁóÖÁêÜÂ≠∏Êï∏ÊìöÈÄ≤Ë°åË©ï‰º∞„ÄÇÈõñÁÑ∂‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Ê∫ñÁ¢∫È†êÊ∏¨ Gleason Ë©ïÂàÜÊñπÈù¢Â∑≤Â±ïÁèæÊΩõÂäõÔºå‰ΩÜÈÄô‰∫õÈ†êÊ∏¨ÈÄöÂ∏∏Áº∫‰πèÂÖßÂú®ÁöÑÂèØËß£ÈáãÊÄßÔºåÂèØËÉΩÊúÉÂ∞éËá¥Â∞ç‰∫∫Ê©ü‰∫íÂãïÁöÑ‰∏ç‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÁî± 54 ‰ΩçÁóÖÁêÜÂ≠∏ÂÆ∂ÁµÑÊàêÁöÑÂúãÈöõÂúòÈöäË®ªËß£ÁöÑ 1,015 ÂÄãÁµÑÁπîÂæÆÈô£ÂàóÊ†∏ÂøÉÂΩ±ÂÉèÁöÑÊñ∞Á©éË≥áÊñôÈõÜ„ÄÇÈÄô‰∫õË®ªËß£Êèê‰æõ‰∫ÜË©≥Á¥∞ÁöÑÂ±ÄÈÉ®Ê®°ÂºèÊèèËø∞ÔºåÁî®ÊñºÁ¨¶ÂêàÂúãÈöõÊ∫ñÂâáÁöÑ Gleason ÂàÜÁ¥ö„ÄÇÂà©Áî®ÈÄôÂÄãË≥áÊñôÈõÜÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫Êñº U-Net Êû∂ÊßãÁöÑÂÖßÂú®ÂèØËß£Èáã AI Á≥ªÁµ±ÔºåË©≤Á≥ªÁµ±Êèê‰æõ‰∫ÜÂà©Áî®ÁóÖÁêÜÂ≠∏ÂÆ∂Ë°ìË™ûÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÈÄôÁ®ÆÊñπÊ≥ïË¶èÈÅø‰∫Ü‰∫ãÂæåÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºåÂêåÊôÇÁ∂≠ÊåÅÊàñË∂ÖË∂ä‰∫ÜÁõ¥Êé•Ë®ìÁ∑¥Áî®Êñº Gleason Ê®°ÂºèÂàÜÂâ≤ÁöÑÊñπÊ≥ïÁöÑÊïàËÉΩÔºàDice ÂàÜÊï∏Ôºö0.713 ¬± 0.003ÔºåË®ìÁ∑¥ÊñºËß£ÈáãÔºåÁõ∏Â∞çÊñº 0.691 ¬± 0.010ÔºåË®ìÁ∑¥Êñº Gleason Ê®°ÂºèÔºâ„ÄÇÈÄèÈÅéÂú®Ë®ìÁ∑¥ÊúüÈñìÊé°Áî®ËªüÊ®ôÁ±§ÔºåÊàëÂÄëÊçïÊçâ‰∫ÜË≥áÊñô‰∏≠ÁöÑÂÖßÂú®‰∏çÁ¢∫ÂÆöÊÄßÔºåÂç≥‰ΩøÂú®ËßÄÂØüËÄÖÈñìËÆäÁï∞ÊÄßÈ´òÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πüËÉΩÂú® Gleason Ê®°ÂºèÂàÜÂâ≤‰∏≠Áî¢ÁîüÂº∑Â§ßÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÈáãÂá∫ÈÄôÂÄãË≥áÊñôÈõÜÔºåÊàëÂÄëÊó®Âú®ÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰∏ªËßÄÊÄßÈ´òÁöÑÈÜ´ÁôÇ‰ªªÂãô‰∏≠ÁöÑÂàÜÂâ≤Ôºå‰∏¶Â¢ûÈÄ≤Â∞çÁóÖÁêÜÂ≠∏ÂÆ∂Êé®ÁêÜÈÅéÁ®ãÁöÑÁêÜËß£„ÄÇ

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèÊäÄË°ìÁöÑÈÄ≤Ê≠•Â∞éËá¥ÂæûÂÇ≥Áµ±ÁöÑÂÅáË®≠È©ÖÂãïÊñπÊ≥ïËΩâËÆäÁÇ∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï„ÄÇÂ§öÁµÑÂ≠∏ÊòØÊåáÊï¥ÂêàÂàÜÊûê‰æÜËá™Â§öÂÄã„ÄåÁµÑÂ≠∏„ÄçÁöÑË≥áÊñôÔºå‰æãÂ¶ÇÂü∫Âõ†ÁµÑÂ≠∏„ÄÅËõãÁôΩË≥™ÁµÑÂ≠∏„ÄÅËΩâÈåÑÁµÑÂ≠∏„ÄÅ‰ª£Ë¨ùÁµÑÂ≠∏ÂíåÂæÆÁîüÁâ©ÁµÑÂ≠∏„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊì∑ÂèñÁîüÁâ©Ë≥áË®äÁöÑ‰∏çÂêåÂ±§Èù¢ÔºåËÉΩÂÖ®Èù¢‰∫ÜËß£ÁîüÁâ©Á≥ªÁµ±„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®ÊñºÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñôÔºåÊèê‰æõÂàÜÂ≠ê‰∫§‰∫í‰ΩúÁî®ÁöÑÊ¥ûÂØüÂäõÔºå‰∏¶Âä†Âº∑Â∞çË§áÈõúÁñæÁóÖÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÖ∑ÊúâË®±Â§öÁõ∏‰∫íÈÄ£Êé•ÁöÑÂ±§Á¥öÂíåÈùûÁ∑öÊÄßÈóú‰øÇÔºåÈÄöÂ∏∏ÊúÉÂÉèÈªëÁõíÂ≠ê‰∏ÄÊ®£ÈÅã‰ΩúÔºåÁº∫‰πèÊ±∫Á≠ñÈÅéÁ®ãÁöÑÈÄèÊòéÂ∫¶„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÊ≠§ÊåëÊà∞ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (xAI) ÊñπÊ≥ïÂ∞çÊñºÂª∫Á´ãÈÄèÊòéÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Ëß£ÈáãÂíåËôïÁêÜË§áÈõúË≥áÊñô„ÄÇÊ≠§Ë©ïË´ñÊé¢Ë®é xAI Â¶Ç‰ΩïËÉΩÊîπÂñÑÂ§öÁµÑÂ≠∏Á†îÁ©∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÂº∑Ë™øÂÖ∂Êèê‰æõËá®Â∫äÈÜ´ÁîüÊòéÁ¢∫Ë¶ãËß£ÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤Ê≠§È°ûÊ®°ÂûãÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊáâÁî®„ÄÇ

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Gei√üler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞çÊñºÂª∫ÊßãÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÈ©ÖÂãïÊáâÁî®Á®ãÂºèËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑ÊàñËá™ÂãïÈßïÈßõÁ≠âÈóúÈçµÈ†òÂüü„ÄÇÊ≥ïÂæã„ÄÅÂïÜÊ•≠ÂíåÂÄ´ÁêÜË¶ÅÊ±Ç‰øÉ‰Ωø‰ΩøÁî®ÊúâÊïàÁöÑ XAIÔºå‰ΩÜÊï∏ÈáèÊó•ÁõäÂ¢ûÂä†ÁöÑ‰∏çÂêåÊñπÊ≥ï‰ΩøÂæóÊåëÈÅ∏Ê≠£Á¢∫ÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºËß£ÈáãÈ´òÂ∫¶‰æùË≥¥ÊñºËÉåÊôØÔºåÂú®Ê≤íÊúâ‰ΩøÁî®ËÄÖÁöÑÊÉÖÊ≥Å‰∏ãË°°Èáè XAI ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂè™ËÉΩÊè≠Á§∫ÊúâÈôêÁöÑË≥áË®äÔºåÊéíÈô§‰∫∫È°ûÂõ†Á¥†Ôºå‰æãÂ¶ÇÁêÜËß£ÂÆÉÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅé‰ΩøÁî®ËÄÖÊàêÂäüÂü∑Ë°å‰ª£ÁêÜ‰ªªÂãôÁöÑËÉΩÂäõ‰æÜË©ï‰º∞ XAI ÊñπÊ≥ïÔºåË®≠Ë®à‰ΩøÂæóËâØÂ•ΩÁöÑÂü∑Ë°åË°®ÁèæÊòØËß£ÈáãÊèê‰æõÊúâÁî®Ë≥áË®äÁöÑÊåáÊ®ô„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÊé¢Ë®é XAI Â∞ç‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂπ´Âä©„ÄÇÊ≠§Â§ñÔºåÂ∞çÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®Áî¢Áîü‰ø°‰ªªÂíåÊá∑ÁñëÁöÑËÉΩÂäõ‰ª•ÂèäÊ≠£Á¢∫Âà§Êñ∑ AI Ê±∫Á≠ñÊòØÂê¶Ê≠£Á¢∫ÁöÑËÉΩÂäõÊñπÈù¢Â≠òÂú®Â∑ÆÁï∞„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÂº∑ÁÉàÂª∫Ë≠∞‰ΩøÁî®ÂíåÊì¥ÂÖÖÈÄôÁ®ÆÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÊõ¥Â§ö‰ª•ÁõÆÊ®ôÁÇ∫Âü∫Á§éÁöÑ‰∫∫ÁÇ∫‰∏≠ÂøÉ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•ÁµÇÁ´ØÂà∞ÁµÇÁ´ØÁöÑÊñπÂºèË°°Èáè XAI ÊïàËÉΩ„ÄÇ

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

ÊëòË¶ÅÔºöÁî¢Á®ã‰∏≠È¢®Èö™ÁöÑÊó©ÊúüÂÅµÊ∏¨ÊúâÂä©ÊñºÈÄ≤Ë°åÂπ≤È†êÊé™ÊñΩÔºå‰ª•È†êÈò≤ÊàñÊ∏õËºï‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºå‰æãÂ¶ÇËÖ¶ÊÄßÈ∫ªÁó∫„ÄÇÁõÆÂâçÔºåÊ≤íÊúâÊ∫ñÁ¢∫ÁöÑËá™ÂãïÂåñÁ≥ªÁµ±ÂèØ‰ª•È†êÊ∏¨Ê≠§È°û‰∫ã‰ª∂Ôºå‰ª•ÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫„ÄåÁî®ÊñºÂª∫Ê®°ÂíåËß£ÈáãÊñ∞ÁîüÂÖíÂÅ•Â∫∑ÁöÑ‰∫∫Â∑•Êô∫ÊÖß„Äç(AIMEN)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉ‰∏çÂÉÖÂèØ‰ª•Ê†πÊìöÂ≠ïÁî¢Â©¶„ÄÅËÉéÂÖí„ÄÅÁî¢ÁßëÂíåÁî¢Á®ãÈ¢®Èö™Âõ†Á¥†È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºåÈÇÑËÉΩÊèê‰æõÊ®°ÂûãÂÅöÂá∫È†êÊ∏¨ËÉåÂæåÁöÑÂéüÂõ†„ÄÇÂæåËÄÖÂèØ‰ª•Êèê‰æõË¶ãËß£ÔºåË™™ÊòéÊ®°ÂûãËº∏ÂÖ•ËÆäÊï∏‰∏≠ÁöÑÂì™‰∫õ‰øÆÊîπÂèØËÉΩÊúÉÊîπËÆäÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÈÅ©ÊáâÊÄßÂêàÊàêÊäΩÊ®£ (ADASYN) ÂíåÊ¢ù‰ª∂Ë°®Ê†ºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (CTGAN) ‰æÜÂêàÊàêÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Ëß£Ê±∫‰∏çÂπ≥Ë°°ÂíåÂ∞èÂûãË≥áÊñôÈõÜÁöÑÊåëÊà∞„ÄÇAIMEN ‰ΩøÁî®ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈõÜÂêà‰ΩúÁÇ∫ÂÖ∂ÂàÜÈ°ûÁöÑÈ™®ÂππÔºå‰∏¶ÈÄèÈÅé ADASYN Êàñ CTGAN ÊîØÊè¥Ë≥áÊñôÊì¥ÂÖÖ„ÄÇÁî± CTGAN ÊîØÊè¥ÁöÑ AIMEN Âú®ÂàÜÈ°ûÊñπÈù¢ÂÑ™ÊñºÁî± ADASYN ÊîØÊè¥ÁöÑ AIMEN„ÄÇAIMEN ÂèØ‰ª•È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÁöÑÈ´òÈ¢®Èö™ÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.784„ÄÇÂÆÉÈÇÑÊèê‰æõÂèç‰∫ãÂØ¶Ëß£ÈáãÔºåÂèØÈÄèÈÅéÂπ≥ÂùáËÆäÊõ¥ 2 Ëá≥ 3 ÂÄãÂ±¨ÊÄß‰æÜÈÅîÊàê„ÄÇÂèØÁî®Ë≥áÊ∫êÔºöhttps://github.com/ab9mamun/AIMEN„ÄÇ

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

ÊëòË¶ÅÔºöÈÅ∫ÂÇ≥ÊÄßË¶ñÁ∂≤ËÜúÁñæÁóÖ (IRD) ÊòØ‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÈÅ∫ÂÇ≥ÁñæÁóÖÔºå
ÊúÉÂ∞éËá¥Ë¶ñÂäõÈÄêÊº∏Âñ™Â§±ÔºåÊòØÂ∑•‰ΩúÂπ¥ÈΩ°Êàê‰∫∫Â§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†„ÄÇIRD ÁöÑË§áÈõúÊÄßÂíåÁï∞Ë≥™ÊÄßÂ∞çË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊúÄËøë‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÈÄ≤Ê≠•ÁÇ∫ÈÄô‰∫õÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ
ÁÑ∂ËÄåÔºåAI ÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÂèäÂÖ∂Â§öÁ®ÆÊáâÁî®Â∞éËá¥‰∫ÜË©≤È†òÂüüÁöÑÁü•Ë≠òÂàÜÊï£„ÄÇÊú¨Á∂úËø∞Êï¥Âêà‰∫ÜÁèæÊúâÁ†îÁ©∂ÔºåÊâæÂá∫Â∑ÆË∑ùÔºå‰∏¶Ê¶ÇËø∞‰∫Ü AI Âú®Ë®∫Êñ∑ÂíåÁÆ°ÁêÜ IRD ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÆÉÊó®Âú®ÈÄöÈÅéÊé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁ≠â AI ÊäÄË°ìÔºåÁâπÂà•ÊòØÂú®ÁñæÁóÖÊ™¢Ê∏¨„ÄÅÈÄ≤Á®ãÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÊ≤ªÁôÇË®àÂäÉ‰∏≠ÔºåÁÇ∫Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÊßãÂª∫ÈÄîÂæë„ÄÇÁâπÂà•ÈóúÊ≥®ÈÄô‰∫õÈ†òÂüü‰∏≠Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåË®éË´ñ‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÔºåÂº∑Ë™ø‰∫ÜÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÂ∞çÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇË©≤Á∂úËø∞Ëß£Ê±∫‰∫ÜÂΩåÂêà AI Âú® IRD ‰∏≠‰ΩúÁî®ÁöÑÈáçÈªûÁ†îÁ©∂‰∏≠ÁèæÊúâÂ∑ÆË∑ùÁöÑÂøÖË¶ÅÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÁï∂Ââç AI ÊäÄË°ìÁöÑÁµêÊßãÂåñÂàÜÊûêÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊúÄÂæåÊ¶ÇËø∞‰∫ÜÂú® IRD ‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÊåëÊà∞ÂíåÊ©üÈÅáÔºåÂº∑Ë™ø‰∫ÜË∑®Â≠∏ÁßëÂêà‰ΩúÂíåÊåÅÁ∫åÈñãÁôºÂº∑Â§ß„ÄÅÂèØËß£ÈáãÁöÑ AI Ê®°Âûã‰ª•Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

ÊëòË¶ÅÔºöËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ±∫Á≠ñÊòØÁèæÂú® AI ÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÊáâÁî®ÊñºÂÉèÈÜ´Â≠∏ÂíåÊ≥ïÂæãÁ≠âÊïèÊÑüÊÉÖÂ¢ÉÊôÇ„ÄÇÁÑ∂ËÄåÔºåËß£ÈáãÊ±∫Á≠ñËÉåÂæåÁêÜÁî±ÁöÑÈúÄÊ±Ç‰πüÊòØÂü∫Êñº‰∫∫È°ûÁöÑËÄÉÈáèÁöÑ‰∏ÄÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂõ†ÁÇ∫ÊúâÂøÖË¶ÅË≠âÊòéÁÇ∫‰ªÄÈ∫ºÂÅöÂá∫ÊüêÂÄãÊ±∫Á≠ñ„ÄÇ‰æãÂ¶ÇÔºå‰ΩèÈô¢ÈÜ´Â∏´‰∏çÂÉÖÈúÄË¶ÅÊèê‰æõÔºàÂèØËÉΩÊòØÊ≠£Á¢∫ÁöÑÔºâË®∫Êñ∑ÔºåÈÇÑÈúÄË¶ÅËß£Èáã‰ªñÂÄëÂ¶Ç‰ΩïÈÅîÊàêÊüêÂÄãÁµêË´ñ„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÊñ∞ÁöÑÂ∑•ÂÖ∑‰æÜÂπ´Âä©‰ΩèÈô¢ÈÜ´Â∏´Ë®ìÁ∑¥‰ªñÂÄëÁöÑËß£ÈáãÊäÄÂ∑ßÊòØÊïôËÇ≤‰∏≠ AI ÁöÑ‰∏ÄÈ†ÖÊ†∏ÂøÉÁõÆÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅµÂæ™ÈÄôÂÄãÊñπÂêëÔºå‰∏¶‰∏îÊ†πÊìöÊàëÂÄëÁöÑ‰∫ÜËß£ÔºåÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ§öË™ûË®ÄÈÜ´Â≠∏ÂïèÁ≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Ëá®Â∫äÁóÖ‰æãÁöÑÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÈÉΩÈôÑÊúâÁî±ÈÜ´ÁîüÊí∞ÂØ´ÁöÑËá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇÈÄô‰∫õËß£ÈáãÂ∑≤‰ΩøÁî®Ë´ñË≠âÁµÑÊàêÔºàÂç≥ÂâçÊèê„ÄÅ‰∏ªÂºµÔºâÂíåË´ñË≠âÈóú‰øÇÔºàÂç≥ÊîªÊìä„ÄÅÊîØÊåÅÔºâÈÄ≤Ë°åÊâãÂãïË®ªËß£ÔºåÁî¢ÁîüÂ§öË™ûË®Ä CasiMedicos-Arg Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 558 ÂÄãÂÖ∑ÊúâËß£ÈáãÁöÑÂõõÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÊ≥ïË™û„ÄÅÁæ©Â§ßÂà©Ë™ûÔºâÁöÑËá®Â∫äÁóÖ‰æãÔºåÊàëÂÄëË®ªËß£‰∫Ü 5021 ÂÄã‰∏ªÂºµ„ÄÅ2313 ÂÄãÂâçÊèê„ÄÅ2431 ÂÄãÊîØÊåÅÈóú‰øÇÂíå 1106 ÂÄãÊîªÊìäÈóú‰øÇ„ÄÇÊàëÂÄëÊúÄÂæåÂ±ïÁ§∫‰∫ÜÁ´∂Áà≠Âü∫Ê∫ñÂ¶Ç‰ΩïÈáùÂ∞çË´ñË≠âÊé¢Âãò‰ªªÂãôÂü∑Ë°åÊ≠§ÂÖ∑ÊåëÊà∞ÊÄßÁöÑË≥áÊñôÈõÜ„ÄÇ

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

ÊëòË¶ÅÔºöË®∫Êñ∑È†êÊ∏¨ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ªªÂãôÔºåÂèäÊôÇ‰∏îÊ∫ñÁ¢∫Âú∞Ë≠òÂà•ÈÜ´ÁôÇÁãÄÊ≥ÅÊúÉÈ°ØËëóÂΩ±ÈüøÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇÂÇ≥Áµ±ÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤Âú®ÈÄôÂÄãÈ†òÂüüÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊòØ‰∏ÄÈ†ÖÈóúÈçµË¶ÅÊ±Ç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN)Ôºå‰ª•ÈñãÁôºÁî®ÊñºË®∫Êñ∑È†êÊ∏¨ÁöÑÂèØËß£ÈáãÊ®°Âûã„ÄÇÂü∫Êú¨‰∏äÔºåÊàëÂÄëË®≠Ë®à‰∏¶ÂØ¶‰Ωú‰∫ÜÂü∫Êñº LNN ÁöÑÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÈÄèÈÅéÂÖ∑ÊúâÂèØÂ≠∏ÁøíÈñæÂÄºÁöÑÈÇèËºØË¶èÂâáÊï¥ÂêàÈ†òÂüüÁâπÂÆöÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØ $M_{\text{multi-pathway}}$ Âíå $M_{\text{comprehensive}}$ÔºåË°®ÁèæÂá∫ÂÑ™ÊñºÂÇ≥Áµ±Ê®°ÂûãÔºà‰æãÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅSVM ÂíåÈö®Ê©üÊ£ÆÊûóÔºâÁöÑÂÑ™Áï∞ÊïàËÉΩÔºåÂú®Á≥ñÂ∞øÁóÖÈ†êÊ∏¨ÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºàÈ´òÈÅî 80.52%ÔºâÂíå AUROC ÂàÜÊï∏ÔºàÈ´òÈÅî 0.8457Ôºâ„ÄÇLNN Ê®°Âûã‰∏≠Â≠∏ÁøíÂà∞ÁöÑÊ¨äÈáçÂíåÈñæÂÄºÊèê‰æõ‰∫ÜÂ∞çÁâπÂæµË≤¢ÁçªÁöÑÁõ¥Êé•Ë¶ãËß£ÔºåÂ¢ûÂº∑‰∫ÜÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇ‰∏çÂΩ±ÈüøÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÂΩåÂêàÈÜ´ÁôÇ‰øùÂÅ• AI ÊáâÁî®‰∏≠Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄßÂ∑ÆË∑ùÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊèê‰æõÈÄèÊòé‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑË®∫Êñ∑Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÊé®ÈÄ≤Á≤æÊ∫ñÈÜ´ÁôÇÔºå‰∏¶ÊîØÊè¥ÂÖ¨Âπ≥ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈñãÁôº„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÂ∞áÈÄô‰∫õÊñπÊ≥ïÊì¥Â±ïÂà∞Êõ¥Â§ß‰∏îÊõ¥Â§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÂÖ∂Âú®‰∏çÂêåÈÜ´ÁôÇÁãÄÊ≥ÅÂíå‰∫∫Áæ§‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂæπÂ∫ïÊîπËÆä‰∫ÜÊô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•ÔºåÊé®Âãï‰∫ÜÂèØÁ©øÊà¥ÊäÄË°ì„ÄÅÊåÅÁ∫åÁõ£ÊéßË£ùÁΩÆÂíåÊô∫ÊÖßË®∫Êñ∑Á≥ªÁµ±ÁöÑÂâµÊñ∞„ÄÇÁÑ∂ËÄåÔºåÂÆâÂÖ®ÊÄß„ÄÅÂèØËß£ÈáãÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàËÉΩÊúÄ‰Ω≥ÂåñÊåëÊà∞‰ªçÁÑ∂ÊòØËá®Â∫äÁí∞Â¢É‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÈóúÈçµÈöúÁ§ô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïÔºå‰ΩøÁî®Ëá™ÈÅ©ÊáâÁâπÂæµË©ï‰º∞Âô® (AFE) ÊºîÁÆóÊ≥ï‰æÜÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜ‰∏≠ÁöÑÁâπÂæµÈÅ∏Âèñ‰∏¶ÂÖãÊúçÂïèÈ°å„ÄÇAFE Êï¥Âêà‰∫ÜÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï (GA)„ÄÅÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÂíåÊéíÂàóÁµÑÂêàÊäÄË°ì (PCT)ÔºåË©≤ÊºîÁÆóÊ≥ïÊúÄ‰Ω≥Âåñ‰∫ÜËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS)ÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ΩøÁî®ÂÖ≠Á®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÈ©óË≠â‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜÔºåË≠âÊòé‰∫ÜÂÖ∂Á©©ÂÅ•ÊÄßÂíåÂÑ™ÊñºÂÇ≥Áµ±ÁâπÂæµÈÅ∏ÂèñÊäÄË°ì„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü AFE Âú®Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËΩâËÆäÊΩõÂäõÔºåÂØ¶Áèæ‰∫ÜÂÄã‰∫∫ÂåñÂíåÈÄèÊòéÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåAFE ÊºîÁÆóÊ≥ïËàáÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶È´òÈÅî 98.5%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÊîπÂñÑÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑËÉΩÂäõ„ÄÇ

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Á≥ªÁµ±Â∑≤Â§ßÂπÖÊîπÂñÑÁöÆËÜöÁßëÈÜ´Â∏´Â∞çÈªëËâ≤Á¥†Áò§ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÔºåËÄåÂèØËß£Èáã AI (XAI) Á≥ªÁµ±ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáËá®Â∫äÈÜ´Â∏´Â∞ç AI È©ÖÂãïÊ±∫Á≠ñÁöÑ‰ø°ÂøÉËàá‰ø°Ë≥¥„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÂ∞çÊñºÁöÆËÜöÁßëÈÜ´Â∏´Â¶Ç‰Ωï‰ΩøÁî® AI Âíå XAI Â∑•ÂÖ∑Ôºå‰ªçÊúâÂÆ¢ËßÄË©ï‰º∞ÁöÑËø´ÂàáÈúÄÊ±Ç„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠Ôºå76 ‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´ÂèÉËàá‰∫Ü‰∏ÄÈ†ÖËÆÄËÄÖÁ†îÁ©∂Ôºå‰ΩøÁî® XAI Á≥ªÁµ±Ë®∫Êñ∑ 16 ÂºµÈªëËâ≤Á¥†Áò§ÂíåÁó£ÁöÑÁöÆËÜöÈè°ÂΩ±ÂÉèÔºåË©≤Á≥ªÁµ±Êèê‰æõË©≥Á¥∞ÁöÑÈ†òÂüüÁâπÂÆöË™™Êòé„ÄÇÊé°Áî®ÁúºÁêÉËøΩËπ§ÊäÄË°ì‰æÜË©ï‰º∞‰ªñÂÄëÁöÑ‰∫íÂãï„ÄÇÂ∞áË®∫Êñ∑Ë°®ÁèæËàáÁº∫‰πèË™™ÊòéÂäüËÉΩÁöÑÊ®ôÊ∫ñ AI Á≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåXAI Á≥ªÁµ±Áõ∏ËºÉÊñºÊ®ôÊ∫ñ AIÔºåÂ∞áÂπ≥Ë°°Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 2.8 ÂÄãÁôæÂàÜÈªû„ÄÇÊ≠§Â§ñÔºåËàá AI/XAI Á≥ªÁµ±ÁöÑË®∫Êñ∑ÂàÜÊ≠ßÂíåË§áÈõúÁöÑÁóÖÁÅ∂ËàáË™çÁü•Ë≤†ÊìîÂçáÈ´òÊúâÈóúÔºåÈÄôÁî±Â¢ûÂä†ÁöÑÁúºÁùõÊ≥®Ë¶ñÊ¨°Êï∏ÊâÄË≠âÂØ¶„ÄÇÈÄô‰∫õË¶ãËß£Â∞çËá®Â∫äÂØ¶Âãô„ÄÅË¶ñË¶∫‰ªªÂãô AI Â∑•ÂÖ∑ÁöÑË®≠Ë®àÂíåÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ XAI ÁöÑÂª£Ê≥õÁôºÂ±ïÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇ

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

ÊëòË¶ÅÔºöËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÁöÑÊó©ÊúüË®∫Êñ∑Âíå‰ªãÂÖ•Â∑≤Ë¢´Ë≠âÂØ¶ËÉΩÈ°ØËëóÊîπÂñÑËá™ÈñâÁóáÊÇ£ËÄÖÁöÑÁîüÊ¥ªÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåASD ÁöÑË®∫Êñ∑ÊñπÊ≥ï‰æùË≥¥ÊñºÂü∫ÊñºËá®Â∫äË°®ÁèæÁöÑË©ï‰º∞ÔºåÂÆπÊòìÁî¢ÁîüÂÅèË¶ãÔºå‰∏îÂèØËÉΩÈõ£‰ª•ÂÅöÂá∫Êó©ÊúüË®∫Êñ∑„ÄÇÊúâÂøÖË¶ÅÊâæÂá∫ ASD ÁöÑÂÆ¢ËßÄÁîüÁâ©Ê®ôË®òÔºå‰ª•Âπ´Âä©ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®ÂæûÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôË®∫Êñ∑ÁñæÁóÖÂíåÁóÖÁóáÊñπÈù¢ÂèñÂæóÂÇëÂá∫ÁöÑË°®Áèæ„ÄÇÂ∑≤Á∂ìÈáùÂ∞çÂª∫Á´ã‰ΩøÁî®ÈùúÊÖãÂäüËÉΩÊÄßÁ£ÅÊåØÈÄ†ÂΩ± (fMRI) Ë≥áÊñôÂ∞ç ASD ÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ®°ÂûãÈÄ≤Ë°åÂª£Ê≥õÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéÂª∫Á´ã‰∏ÄÂÄã‰∏çÂÉÖËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºåÈÇÑËÉΩÊèê‰æõÂèØËß£ÈáãË¶ãËß£Ë™™ÊòéÂÖ∂ÈÅã‰ΩúÂéüÁêÜÁöÑ DL Ê®°ÂûãÔºå‰æÜÊîπÂñÑ ASD Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÊòØËá™ÈñâÁóáÂ§ßËÖ¶ÂΩ±ÂÉèË≥áÊñô‰∫§Êèõ (ABIDE) ÁöÑÈ†êËôïÁêÜÁâàÊú¨ÔºåÂåÖÂê´ 884 ÂÄãÊ®£Êú¨„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåË©≤Ê®°ÂûãËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºå‰∏¶Âº∑Ë™ø ASD ËàáÂÖ∏ÂûãÂ∞çÁÖßÁµÑ‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞ÁöÑÈóúÈçµËÖ¶ÂçÄÔºåÂ∞çÊñº ASD ÁöÑÊó©ÊúüË®∫Êñ∑ÂíåÁ•ûÁ∂ìÂü∫Á§éÁöÑÁêÜËß£ÂÖ∑ÊúâÊΩõÂú®ÁöÑÊÑèÁæ©„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁµêÊûúÂ∑≤Áî±‰ΩøÁî®‰∏çÂêåË≥áÊñôÈõÜÂíåÊñπÂºèÁöÑÊñáÁçªÁ†îÁ©∂È©óË≠âÔºåË≠âÂØ¶Ë©≤Ê®°ÂûãÂØ¶Èöõ‰∏äÂ≠∏Áøí‰∫Ü ASD ÁöÑÁâπÂæµÔºåËÄå‰∏çÂÉÖÂÉÖÊòØË≥áÊñôÈõÜ„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÂº∑ÂÅ•‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåÊé®Âãï‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÂèØËß£Èáã AI ÁöÑÈ†òÂüüÔºåÂæûËÄåÁÇ∫Êú™‰æÜÊèê‰æõÂÆ¢ËßÄ‰∏îÂèØÈù†ÁöÑ ASD Ë®∫Êñ∑ÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Cl√©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

ÊëòË¶ÅÔºöÂ∞øË∑ØÈè°Ê™¢Êü•‰∏≠ËÖéÁµêÁü≥È°ûÂûãÁöÑÈ´îÂÖßË≠òÂà•Â∞áÊòØÊ≥åÂ∞øÁßëÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÈÄ≤Â±ïÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•Ê∏õÂ∞ëÁπÅÁë£ÁöÑËÖéÁµêÁü≥ÂèñÂá∫ÈÅéÁ®ãÁöÑÊôÇÈñìÔºåÂêåÊôÇÈôç‰ΩéÊÑüÊüìÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåÈÄôÁ®ÆËá™ÂãïÂåñÁ®ãÂ∫èÂ∞á‰ΩøÁ´ãÂç≥ÈñãÁ´ãÊäóÂæ©ÁôºÊ≤ªÁôÇÊàêÁÇ∫ÂèØËÉΩ„ÄÇÂ¶Ç‰ªäÔºåÂè™ÊúâÂ∞ëÊï∏Á∂ìÈ©óË±êÂØåÁöÑÊ≥åÂ∞øÁßëÈÜ´ÁîüËÉΩÂ§†Âú®ÂÖßË¶ñÈè°Ê™¢Êü•ÊúüÈñìÂ±èÂπï‰∏äÈ°ØÁ§∫ÁöÑË¶ñÈ†ªÂúñÂÉè‰∏≠Ë≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÂõ†Ê≠§ÔºåÊúÄËøëÂ∑≤ÊèêÂá∫Â§öÁ®ÆÊ∑±Â∫¶Â≠∏Áøí (DL) Ê®°ÂûãÔºå‰ª•‰ΩøÁî®Ëº∏Â∞øÁÆ°Èè°ÂúñÂÉèËá™ÂãïË≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ DL Ê®°ÂûãÊú¨Ë≥™‰∏äÊòØÈªëÁõíÂ≠êÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ°à‰æãÊé®ÁêÜÁöÑ DL Ê®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÂéüÂûãÈÉ®ÂàÜ (PP) ‰∏¶ÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶„ÄÇPP ÁÇ∫ÊØèÁ®ÆÈ°ûÂûãÔºàÂç≥ËÖéÁµêÁü≥È°ûÂûãÔºâÁ∑®Á¢ºË¶ñË¶∫ÁâπÂæµ‰ø°ÊÅØÔºàËâ≤Ë™ø„ÄÅÈ£ΩÂíåÂ∫¶„ÄÅÂº∑Â∫¶ÂíåÁ¥ãÁêÜÔºâÔºåÈ°û‰ººÊñºÁîüÁâ©Â≠∏ÂÆ∂‰ΩøÁî®ÁöÑ‰ø°ÊÅØ„ÄÇÁî±ÊñºÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñì‰ΩøÁî®ÁöÑÊñ∞ÊêçÂ§±ÂáΩÊï∏ÔºåPP ÂæóÂà∞‰∫ÜÊúÄ‰Ω≥ÁîüÊàê„ÄÇÊ≠§Â§ñÔºåPP ÁöÑÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶ÂÖÅË®±‰ª•ÁîüÁâ©Â≠∏ÂÆ∂ÂíåÊ≥åÂ∞øÁßëÈÜ´ÁîüÂèØ‰ª•ÁêÜËß£ÁöÑÊñπÂºèËß£ÈáãÊ±∫Á≠ñÔºà‚Äú‰ªÄÈ∫º‚Äù‰ø°ÊÅØÔºå‚ÄúÂúñÂÉè‰∏≠ÁöÑ‰ªÄÈ∫º‰ΩçÁΩÆ‚ÄùÔºâ„ÄÇÊâÄÊèêÂá∫ÁöÑ DL Ê®°ÂûãÂ∑≤Âú®‰∏ÄÂÄãÂåÖÂê´ÂÖ≠Á®ÆÊúÄÂª£Ê≥õÁöÑËÖéÁµêÁü≥È°ûÂûãÂúñÂÉèÁöÑÊï∏ÊìöÂ∫´‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁ∏ΩÈ´îÂπ≥ÂùáÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÁÇ∫ 90.37„ÄÇÂ∞áÊ≠§ÁµêÊûúËàáËÖéÁµêÁü≥ÊúÄÂÖàÈÄ≤ÁöÑÂÖ´ÂÄãÂÖ∂‰ªñ DL Ê®°ÂûãÁöÑÁµêÊûúÈÄ≤Ë°åÊØîËºÉÊôÇÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÂèØËß£ÈáãÊÄßÁöÑÂØ∂Ë≤¥Â¢ûÁõä‰∏¶Êú™‰ª•Ê∫ñÁ¢∫ÊÄßÁÇ∫‰ª£ÂÉπÔºåÁîöËá≥Áï•ÊúâÂ¢ûÂä†ËàáÊñáÁçª‰∏≠ÊúÄÂ•ΩÁöÑÊñπÊ≥ï (88.2) Áõ∏ÊØî„ÄÇÈÄô‰∫õÊúâÂ∏åÊúõ‰∏îÂèØËß£ÈáãÁöÑÁµêÊûú‰πüÈºìÂãµÊ≥åÂ∞øÁßëÈÜ´ÁîüÁõ∏‰ø°Âü∫Êñº‰∫∫Â∑•Êô∫ËÉΩÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂà©Áî®Ë°åÊîøÁî≥Â†±Ë≥áÊñôÔºåÁµêÂêàÂÖàÈÄ≤Ê©üÂô®Â≠∏ÁøíËàáÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºåÈ†êÊ∏¨ÊÖ¢ÊÄßËÖéËáüÁóÖ (CKD) ÈÄ≤Â±ïËá≥Êú´ÊúüËÖéËáüÁñæÁóÖ (ESRD) ÁöÑÂèØËÉΩÊÄß„ÄÇÊàëÂÄëÂàÜÊûê‰∏ÄÂÆ∂Â§ßÂûãÂÅ•Â∫∑‰øùÈö™ÁµÑÁπîÊèê‰æõÁöÑ 10 Âπ¥Á∂úÂêàË≥áÊñôÈõÜÔºå‰ΩøÁî®ÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈö®Ê©üÊ£ÆÊûóÂíå XGBoostÔºâ‰ª•ÂèäÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈï∑ÊúüÁü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑ØÔºâÈñãÁôºÂ§öÂÄãËßÄÂØüË¶ñÁ™óÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLSTM Ê®°ÂûãÔºàÂ∞§ÂÖ∂ÊòØ 24 ÂÄãÊúàËßÄÂØüË¶ñÁ™óÔºâÂú®È†êÊ∏¨ ESRD ÈÄ≤Â±ïÊñπÈù¢Ë°®ÁèæÂÑ™Áï∞ÔºåÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÁèæÊúâÊ®°Âûã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊáâÁî® SHapley ÂèØÂä†ÊÄßËß£Èáã (SHAP) ÂàÜÊûê‰ª•Â¢ûÂº∑ÂèØËß£ÈáãÊÄßÔºåÊ∑±ÂÖ•‰∫ÜËß£ÂÄãÂà•ÁâπÂæµÂ∞çÂÄãÂà•ÊÇ£ËÄÖÂ±§Á¥öÈ†êÊ∏¨ÁöÑÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂà©Áî®Ë°åÊîøÁî≥Â†±Ë≥áÊñôÈÄ≤Ë°å CKD ÁÆ°ÁêÜÂíåÈ†êÊ∏¨ ESRD ÈÄ≤Â±ïÁöÑÂÉπÂÄº„ÄÇ

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

ÊëòË¶ÅÔºöÈö®ËëóË∂ä‰æÜË∂äË§áÈõú‰∏îÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖß (AI) Ëß£Ê±∫ÊñπÊ°àÁöÑÊèêÊ°àÂú®Ë®±Â§öÈ†òÂüü‰∏≠ËÆäÂæóÁÑ°Ëôï‰∏çÂú®„ÄÇÈö®ËëóÈÄô‰∫õÊ®°ÂûãË§áÈõúÊÄßÁöÑÂ¢ûÂä†ÔºåÈÄèÊòéÂ∫¶Âíå‰ΩøÁî®ËÄÖÁöÑÁêÜËß£ÂäõÂæÄÂæÄÊúÉÈôç‰Ωé„ÄÇÈÄôË°®Á§∫ÂÉÖÊúâÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨‰∏¶‰∏çË∂≥‰ª•ËÆì AI Ëß£Ê±∫ÊñπÊ°àÁúüÊ≠£ÊúâÁî®„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÈñãÁôº‰∏≠ÔºåÈÄôÂºïÂÖ•‰∫ÜËàáÂïèË≤¨Âà∂ÂíåÂÆâÂÖ®ÊÄßÁõ∏ÈóúÁöÑÊñ∞ÂïèÈ°å„ÄÇÁû≠Ëß£ AI Á≥ªÁµ±Â¶Ç‰Ωï‰ª•ÂèäÁÇ∫‰ΩïÊèêÂá∫Âª∫Ë≠∞ÂèØËÉΩÈúÄË¶ÅÂ∞çÂÖ∂ÂÖßÈÉ®ÈÅã‰ΩúÂíåÊé®ÁêÜÈÅéÁ®ãÈÄ≤Ë°åË§áÈõúÁöÑË™™Êòé„ÄÇÂÑòÁÆ°ËøëÂπ¥‰æÜÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Â∑≤Â§ßÂπÖÂ¢ûÂä†Ôºå‰∏îÈÜ´Â≠∏È†òÂüüÂ∞ç XAI ÊúâÂæàÈ´òÁöÑÈúÄÊ±ÇÔºå‰ΩÜÂÆöÁæ©‰ªÄÈ∫ºÊßãÊàê‰∏ÄÂÄãÂ•ΩÁöÑËß£Èáã‰ªçÊòØËá®ÊôÇÊÄßÁöÑÔºåËÄåÊèê‰æõÈÅ©Áï∂ÁöÑËß£Èáã‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÁôºÊèÆ AI ÁöÑÊΩõÂäõÔºåÂ∞çÊñºÂÆâÂÖ®ÈóúÈçµÂûã AI ÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ AIÔºâÁöÑËß£ÈáãÔºåÊé¢Ë®éÂÖ©ÂÄãÂü∫Êú¨ÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºö(1) ‰ªÄÈ∫ºÊòØÂÅ•Â∫∑ AI ‰∏≠ÁöÑËß£ÈáãÔºü‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩÁöÑËß£ÈáãÊúâÂì™‰∫õÂ±¨ÊÄßÔºüÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂ∑≤ÁôºË°®ÁöÑÊñáÁçªÔºå‰∏¶ÈÄèÈÅéÂÖ©Ëº™Âæ∑ÁàæËè≤Á†îÁ©∂Êî∂ÈõÜ‰∫ÜÂ∞àÂÆ∂ÊÑèË¶ã„ÄÇÁ†îÁ©∂ÊàêÊûúÂåÖÊã¨Ôºö(1) ÂÅ•Â∫∑ AI ‰∏≠‰ªÄÈ∫ºÊßãÊàêËß£ÈáãÁöÑÂÆöÁæ©Ôºå‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩËß£ÈáãÁöÑÂ±¨ÊÄßÊ∏ÖÂñÆ„ÄÇ

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂ∑≤Á∂ìÂºïÈÄ≤ÂêÑÁ®ÆÊñπÊ≥ï‰æÜËß£Èáã„ÄåÈªëÁÆ±„ÄçAI Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâç‰∏¶‰∏çÊ∏ÖÊ•ö‰ΩøÁî®ËÄÖÊòØÂê¶ÂØ¶ÈöõÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË©ï‰º∞ÁôåÁóáÈ¢®Èö™ÁöÑÂõûÊ≠∏Â∑•ÂÖ∑ÁöÑËß£ÈáãÔºå‰∏¶Êé¢Ë®éËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÂ∞ç‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁêÜËß£Âíå‰ø°‰ªªÊåáÊ®ôÁöÑÂΩ±Èüø„ÄÇÈóúÊñºÂÖßÂÆπÔºåÊàëÂÄëÂØ¶È©ó‰∫ÜÂÖ©Á®ÆËß£ÈáãÊñπÊ≥ïÔºöÊµÅË°åÁöÑ SHAPÔºåÂü∫ÊñºÂçöÂºàË´ñÊ¶ÇÂøµÔºåÂõ†Ê≠§Â∞çÊñºÊó•Â∏∏‰ΩøÁî®ËÄÖ‰æÜË™™ÂèØËÉΩÂæàË§áÈõúÔºå‰ª•ÂèäÂü∫ÊñºÁâπÂæµÈÅÆËîΩÁöÑ occlusion-1ÔºåÂèØËÉΩÊõ¥ÊòìÊñºÁêÜËß£„ÄÇÈóúÊñºÊ†ºÂºèÔºåÊàëÂÄëÂ∞á SHAP Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (SC)ÔºåÈÄôÊòØÊÖ£‰æãÔºåËÄåÂ∞á occlusion-1 Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (OC) ‰ª•ÂèäÊñáÂ≠ó (OT)ÔºåÂÖ∂ËºÉÁÇ∫Á∞°ÂñÆÁöÑÊÄßË≥™‰πüÈÅ©Áî®ÊñºÊ≠§„ÄÇÈÄô‰∫õÂØ¶È©óÁ≠âÂêåÊñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåË©¢ÂïèÂèÉËàáËÄÖÔºåÂÖ∑ÊúâÂÖ©Á®Æ‰∏çÂêåÁ®ãÂ∫¶ÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºà‰∏ÄËà¨Ê∞ëÁúæÂíåÂÖ∑ÂÇô‰∏Ä‰∫õÈÜ´Â≠∏Ë®ìÁ∑¥ÁöÑ‰∫∫ÔºâÔºå‰ªñÂÄëÂ∞çÂõûÊ≠∏Â∑•ÂÖ∑Ëº∏Âá∫Ëß£ÈáãÁöÑ‰∏ªËßÄÂíåÂÆ¢ËßÄÁêÜËß£Âíå‰ø°‰ªª„ÄÇÂú®ÂÖ©È†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæÔºåÂú®Âü∫ÊñºÂÖßÂÆπÈÄ≤Ë°åÊØîËºÉÊôÇÔºå‰∏ÄËà¨‰æÜË™™Ôºåocclusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÔºåÂú®‰∏ªËßÄÁêÜËß£Âíå‰ø°‰ªªÊñπÈù¢ÊúâÊòéÈ°ØÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÉÖÊéßÂà∂Ê†ºÂºèÁöÑÊÉÖÊ≥Å‰∏ãÁõ¥Êé•ÊØîËºÉËß£ÈáãÔºåÂú®Â§ßÂ§öÊï∏ÊÉÖÊ≥Å‰∏ãÂè™È°ØÁ§∫ OT ÂÑ™Êñº SC Ëß£ÈáãÁöÑË≠âÊìöÔºåÈÄôË°®Êòé occlusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÁöÑ‰∏ªÂ∞éÂú∞‰ΩçÂèØËÉΩÊòØÁî±ÂÅèÂ•ΩÊñáÂ≠óËÄåÈùûÂúñË°®‰ΩúÁÇ∫Ëß£ÈáãÊâÄÈ©ÖÂãïÁöÑ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæËß£ÈáãÈ°ûÂûãÂú®ÂÆ¢ËßÄÁêÜËß£ÊñπÈù¢ÁöÑÂ∑ÆÁï∞Ë≠âÊìö„ÄÇÂõ†Ê≠§ÔºåÁ∏ΩÈ´îËÄåË®ÄÔºåÂ∞çËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÁöÑÈÅ∏ÊìáÈúÄË¶Å‰ªîÁ¥∞Ê≥®ÊÑèÔºåÂõ†ÁÇ∫Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÊ†ºÂºèËÄåÈùûÂÖßÂÆπÔºåÂèØËÉΩÂú®ÊîπÂñÑ‰ΩøÁî®ËÄÖÈ´îÈ©óÊñπÈù¢ÁôºÊèÆÈóúÈçµ‰ΩúÁî®„ÄÇ</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Li√≤, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞Á™ÅÁ†¥Êèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÈóúÊñºÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑË™øÊü•ÈÄöÂ∏∏Â∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®ÊàñÊ®°ÂûãÊû∂ÊßãÔºåÁº∫‰πèÊï¥ÂêàÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÊúÄÊñ∞ÈÄ≤Â±ïÁöÑÂÖ®Èù¢ÂàÜÊûê„ÄÇÊú¨Á∂úËø∞Âü∫ÊñºÂ∞ç‰æÜËá™ PubMed„ÄÅWeb of Science Âíå arXiv Á≠âÊï∏ÊìöÂ∫´ÁöÑ 484 ÁØáÂá∫ÁâàÁâ©ÁöÑÂàÜÊûêÔºåÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑÁï∂ÂâçÁèæÊ≥Å„ÄÅÊáâÁî®„ÄÅÊåëÊà∞ÂíåÂâçÊôØÔºåÂÖ∂ÁâπÈªûÊòØÈóúÊ≥®ÈÄô‰∫õÊ®°ÂûãÂú®ÁèæÂØ¶‰∏ñÁïåÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü LLM Âú®Âª£Ê≥õÁöÑÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãô‰∏≠ÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÔºåÂåÖÊã¨Ë®∫Êñ∑ËºîÂä©„ÄÅËó•Áâ©ÁôºÁèæÂíåÂÄãÊÄßÂåñÈÜ´ÁôÇÁ≠âÔºå‰∏¶Âæû 137 È†ÖÈóúÈçµÁ†îÁ©∂‰∏≠Ê±≤ÂèñË¶ãËß£„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM ÁöÑÈÅ©ÊáâÁ≠ñÁï•ÔºåÂåÖÊã¨ÂñÆÊ®°ÊÖãÂíåÂ§öÊ®°ÊÖã LLM ÁöÑÂæÆË™øÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∑ÂÆÉÂÄëÂú®Èõ∂Ê¨°Â≠∏ÁøíÁÑ°Ê≥ïÂØ¶ÁèæÁöÑÂ∞àÊ•≠ÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÊÄßËÉΩÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÂíåÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªÁöÑÊúâÊïàËôïÁêÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÈù¢Ëá®ÁöÑÊåëÊà∞ÔºåÂåÖÊã¨Êï∏ÊìöÈö±ÁßÅÂïèÈ°å„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄßÊúâÈôê„ÄÅÊï∏ÊìöÈõÜË≥™ÈáèÂïèÈ°å‰ª•ÂèäÁî±ÊñºÁîüÁâ©ÈÜ´Â≠∏Êï∏ÊìöÁöÑÊïèÊÑüÊÄß„ÄÅÂ∞çÈ´òÂ∫¶ÂèØÈù†Ê®°ÂûãËº∏Âá∫ÁöÑÈúÄÊ±Ç‰ª•ÂèäÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÂÄ´ÁêÜÂΩ±ÈüøËÄåÁî¢ÁîüÁöÑÂÄ´ÁêÜÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈÇÑÁ¢∫ÂÆö‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂåÖÊã¨Áî®Êñº‰øùË≠∑Êï∏ÊìöÈö±ÁßÅÁöÑËÅØÂêàÂ≠∏ÁøíÊñπÊ≥ï‰ª•ÂèäÊï¥ÂêàÂèØËß£Èáã AI ÊñπÊ≥ï‰ª•Â¢ûÂº∑ LLM ÁöÑÈÄèÊòéÂ∫¶„ÄÇ

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÈÜ´ÁôÇÂíå‰øùÂÅ•ÊáâÁî®‰∏≠ÊäïÂÖ•‰∫ÜÂ§ßÈáèÁöÑÊäïË≥áÂíåÈñãÁôºÔºåÈÄ≤ËÄåÂ∞éËá¥ÈÜ´ÁôÇÊäÄË°ì‰∏≠ÁöÑÂÖàÈÄ≤ÊéßÂà∂Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÁöÑ‰∏çÈÄèÊòéÊÄßÂºïÁôº‰∫ÜÂ∞çÊ≠§È°ûÊïèÊÑüÊáâÁî®‰∏≠ÊâÄÈúÄÂü∫Êú¨ÁâπÊÄßÁöÑÊìîÊÜÇÔºå‰æãÂ¶ÇÈÄèÊòéÂ∫¶ÂíåÂèØ‰ø°Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéË™øÊü•‰∏ÄÂÄãÁ®ãÂ∫è‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÁî®ÊñºÈÅ∏ÊìáÊúÄÂÖÖÂàÜÁöÑÂèØËß£Èáã AIÔºàXAIÔºâÊñπÊ≥ïÔºå‰ª•Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶èÂú®ÈÜ´ÁôÇÂô®ÊùêÁöÑÊô∫ÊÖßÂûãÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑË™™ÊòéË¶ÅÊ±Ç„ÄÇÊé°Áî®ÁöÑÊñπÊ≥ïÂæûÈÄèÈÅéÂÖ∂ÊéßÂà∂Ê©üÂà∂ÔºàÈñãËø¥Ë∑Ø„ÄÅÈñâËø¥Ë∑ØÂíåÂçäÈñâËø¥Ë∑ØÁ≥ªÁµ±ÔºâÂ∞çÊô∫ÊÖßÂûãË£ùÁΩÆÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶Ê∑±ÂÖ•Êé¢Ë®éÂÖ∂ÊäÄË°ìÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂàÜÊûêÈÄô‰∫õÊ≥ïË¶è‰ª•ÂÆöÁæ©ÂÖ∂Â∞çÂêÑÁ®ÆË£ùÁΩÆÂíåÁõ∏ÈóúÁõÆÊ®ôÁöÑÂèØËß£ÈáãÊÄßË¶ÅÊ±Ç„ÄÇÂêåÊôÇÔºåÊàëÂÄëÈÄèÈÅéÂÖ∂Ë™™ÊòéÁõÆÊ®ôÂ∞ç XAI ÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÂÖÅË®±Â∞áÊ≥ïÂæãÂèØËß£ÈáãÊÄßË¶ÅÊ±ÇËàá XAI Ë™™ÊòéÁõÆÊ®ôÁõ∏ÂåπÈÖçÔºå‰∏¶Á¢∫ÂÆöÈÅ©Áï∂ÁöÑ XAI ÊºîÁÆóÊ≥ï‰æÜÈÅîÊàêÂÆÉÂÄë„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÂ∞çÂì™‰∫õ XAI ÊºîÁÆóÊ≥ïÊõ¥Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶è‰ª•ÈÅ©Áî®Êñº‰∏çÂêåÈ°ûÂûãÁöÑÈÜ´ÁôÇÂô®ÊùêÁöÑÁ¥∞Á∑ªÁêÜËß£„ÄÇÊàëÂÄëÈÄèÈÅé‰∏çÂêåÁ•ûÁ∂ìÊ§çÂÖ•Áâ©ÁöÑÂØ¶ÈöõÊ°à‰æãÁ†îÁ©∂‰æÜË≠âÊòéÈÄô‰∏ÄÈªûÔºåÂæûÊÖ¢ÊÄßÁñæÁóÖÁÆ°ÁêÜÂà∞ÂÖàÈÄ≤ÁöÑÁæ©ËÇ¢„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â°´Ë£ú‰∫ÜÂ∞áÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑ XAI ÊáâÁî®ËàáÊ≠êÁõüÊ≥ïË¶èÁöÑÂö¥Ê†ºË¶èÂÆöÁõ∏Á¨¶ÁöÑÈáçË¶ÅÁ©∫ÁôΩ„ÄÇÂÆÉÁÇ∫ÈñãÁôº‰∫∫Âì°ÂíåÁ†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®ÁöÑÊû∂ÊßãÔºåÁ¢∫‰øùÂÖ∂ AI ÂâµÊñ∞ËÉΩ‰øÉÈÄ≤ÈÜ´ÁôÇÊäÄË°ì‰∏¶ÈÅµÂÆàÊ≥ïÂæãÂíåÈÅìÂæ∑Ê®ôÊ∫ñ„ÄÇ

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Á¥¢Ê∑±Â∫¶ÁîüÊàêÊ®°ÂûãÔºåÂú®ÈÜ´ÁôÇËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆ‰∏≠ÁîüÊàêÂü∫ÊñºÊ°à‰æãÁöÑË™™Êòé„ÄÇÈÄèÈÅéÂü∫ÊñºÊ°à‰æãÁöÑÂèØËß£ÈáãÊÄß‰æÜËß£Èáã AI Ê®°ÂûãÊ±∫Á≠ñÔºåÂ∞çÊñºÂ¢ûÂä†‰ø°‰ªª‰∏¶ÂÖÅË®± AI Âú®Ëá®Â∫äÂØ¶Âãô‰∏≠Âª£Ê≥õÊé°Áî®Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ AI Ë®ìÁ∑¥ÁØÑ‰æãÊ≠£ËΩâÂêëËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆÔºå‰ª•Á¨¶ÂêàË≥áÊñô‰øùË≠∑Ê≥ïË¶è„ÄÇÂú®ËÅØÈÇ¶ÊÉÖÂ¢É‰∏≠ÔºåÈÅéÂéªÁöÑË≥áÊñôÂ∞çÁõÆÂâçÁöÑ‰ΩøÁî®ËÄÖËÄåË®ÄÊòØÁÑ°Ê≥ïÂèñÂæóÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®Ê∑±Â∫¶ÁîüÊàêÊ®°Âûã‰æÜÁî¢Áîü‰øùË≠∑Èö±ÁßÅÂíåËß£ÈáãÊ±∫Á≠ñÁöÑÂêàÊàêÁØÑ‰æã„ÄÇÊàëÂÄëÁöÑÊ¶ÇÂøµÈ©óË≠âËëóÈáçÊñºËÉ∏ËÖîÁ©çÊ∂≤Ë®∫Êñ∑Ôºå‰∏¶‰ΩøÁî®ÂÖ¨ÈñãÂèØÂèñÂæóÁöÑËÉ∏ÈÉ® X ÂÖâË≥áÊñô„ÄÇ

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gru√ºhagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

ÊëòË¶ÅÔºöËªüÁµÑÁπîÂíåÈ™®È™ºËÖ´Áò§ÔºàSTBTÔºâÊòØÁΩïË¶ã„ÄÅË®∫Êñ∑ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁóÖÁÅ∂ÔºåÂÖ∂Ëá®Â∫äË°åÁÇ∫ÂíåÊ≤ªÁôÇÊñπÊ≥ïÂêÑ‰∏çÁõ∏Âêå„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊèê‰æõ‰∫Ü‰ΩøÁî®ÊîæÂ∞ÑÂΩ±ÂÉèÈÄ≤Ë°åË®∫Êñ∑ÂíåÈ†êÂæåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁöÑÊ¶ÇËßÄÔºåÈáçÈªûË™™Êòé‰∫ÜËá®Â∫äËΩâË≠ØÁöÑÊåëÊà∞Ôºå‰∏¶Ë©ï‰º∞Á†îÁ©∂ËàáÈÜ´ÁôÇÂΩ±ÂÉè AI Ê†∏Êü•Ë°® (CLAIM) Âíå FUTURE-AI ÂèØ‰ø°Ë≥¥‰∏îÂèØÈÉ®ÁΩ≤ AI ÁöÑÂúãÈöõÂÖ±Ë≠òÊ∫ñÂâáÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ª•‰øÉÈÄ≤ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇÈÄôÁØáÂõûÈ°ßÊ∂µËìã‰∫ÜÂπæÂÄãÊõ∏ÁõÆË≥áÊñôÂ∫´‰∏≠ÁöÑÊñáÁçªÔºåÂåÖÊã¨Âú® 2024 Âπ¥ 7 Êúà 17 Êó•‰πãÂâçÁôºË°®ÁöÑË´ñÊñá„ÄÇÁ¥çÂÖ•‰∫Ü‰ª•ÊîæÂ∞ÑÁÇ∫Âü∫Á§éÁöÑ AI Ë®∫Êñ∑ÊàñÈ†êÂæåÂéüÁôºÊÄß STBT ÁöÑÂêåË°åË©ïÂØ©ÊúüÂàä‰∏≠ÁöÑÂéüÂßãÁ†îÁ©∂„ÄÇÊéíÈô§Ê®ôÊ∫ñÊòØÂãïÁâ©„ÄÅÂ±çÈ´îÊàñÂØ¶È©óÂÆ§Á†îÁ©∂Ôºå‰ª•ÂèäÈùûËã±ÊñáË´ñÊñá„ÄÇÊëòË¶ÅÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑÂÖ©‰ΩçÁØ©ÈÅ∏Ë≥áÊ†º„ÄÇÂêàÊ†ºÁöÑË´ñÊñáÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑ‰∏Ä‰ΩçÊ†πÊìöÊ∫ñÂâáÈÄ≤Ë°åË©ï‰º∞„ÄÇÊêúÁ¥¢Ë≠òÂà•Âá∫ 15,015 ÁØáÊëòË¶ÅÔºåÂÖ∂‰∏≠ 325 ÁØáÊñáÁ´†Ë¢´Á¥çÂÖ•Ë©ï‰º∞„ÄÇÂ§ßÂ§öÊï∏Á†îÁ©∂Âú® CLAIM ‰∏≠Ë°®Áèæ‰∏≠Á≠âÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 53 ÂàÜ‰∏≠ÁöÑ 28.9¬±7.5 ÂàÜÔºå‰ΩÜÂú® FUTURE-AI ‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 30 ÂàÜ‰∏≠ÁöÑ 5.1¬±2.1 ÂàÜ„ÄÇSTBT ÁöÑÂΩ±ÂÉè AI Â∑•ÂÖ∑‰ªçËôïÊñºÊ¶ÇÂøµÈ©óË≠âÈöéÊÆµÔºåË°®ÊòéÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇAI ÈñãÁôº‰∫∫Âì°Êú™‰æÜÁöÑÂä™ÂäõÊáâÈõÜ‰∏≠Âú®Ë®≠Ë®àÔºà‰æãÂ¶ÇÂÆöÁæ©Êú™ÊªøË∂≥ÁöÑËá®Â∫äÈúÄÊ±Ç„ÄÅÈ†êÊúüÁöÑËá®Â∫äÁí∞Â¢É‰ª•Âèä AI Â¶Ç‰ΩïÊï¥ÂêàÂà∞Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ôºâ„ÄÅÈñãÁôºÔºà‰æãÂ¶ÇÂª∫Á´ãÂú®ÂÖàÂâçÁöÑÂ∑•‰Ωú„ÄÅÂèØËß£ÈáãÊÄßÔºâ„ÄÅË©ï‰º∞Ôºà‰æãÂ¶ÇË©ï‰º∞ÂíåËß£Ê±∫ÂÅèÂ∑Æ„ÄÅË©ï‰º∞ AI ËàáÊúÄ‰Ω≥ÂØ¶ÂãôÔºâ„ÄÅ‰ª•ÂèäÊï∏ÊìöÂèØË§áË£ΩÊÄßÂíåÂèØÁî®ÊÄßÔºàÂÖ¨ÈñãÊèê‰æõÊñá‰ª∂ÂåñÁöÑ‰ª£Á¢ºÂíåÊï∏ÊìöÔºâ„ÄÇÈÅµÂæ™ÈÄô‰∫õÂª∫Ë≠∞ÂèØ‰ª•ÊîπÂñÑ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇ

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Str√ºmke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

ÊëòË¶ÅÔºöËÖ¶ÊÄßÈ∫ªÁó∫ (CP) ÁöÑÊó©ÊúüÂÅµÊ∏¨Â∞çÊñºÊúâÊïàÁöÑ‰ªãÂÖ•ÂíåÁõ£Ê∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊ∏¨Ë©¶‰∫ÜÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÁöÑÂèØÈù†ÊÄßÂíåÈÅ©Áî®ÊÄßÔºå‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÈÄèÈÅéÂàÜÊûêÂæûÂ¨∞ÂÖíÂãï‰ΩúÂΩ±ÁâáË®òÈåÑ‰∏≠ÊèêÂèñÁöÑÈ™®È™ºË≥áÊñô‰æÜÈ†êÊ∏¨ CP„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî® XAI Ë©ï‰º∞ÊåáÊ®ôÔºàÂç≥Âø†ÂØ¶Â∫¶ÂíåÁ©©ÂÆöÊÄßÔºâ‰æÜÈáèÂåñË©ï‰º∞È°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (CAM) ÂíåÊ¢ØÂ∫¶Âä†Ê¨äÈ°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (Grad-CAM) Âú®ÈÄôÂÄãÁâπÂÆöÈÜ´ÁôÇÊáâÁî®‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÂà©Áî®‰∏ÄÂÄãÁç®ÁâπÁöÑÂ¨∞ÂÖíÂãï‰ΩúË≥áÊñôÈõÜÔºå‰∏¶ÊáâÁî®È™®È™ºË≥áÊñôÊìæÂãïÔºåËÄå‰∏çÊúÉÊâ≠Êõ≤Â¨∞ÂÖíÂãï‰ΩúÁöÑÂéüÂßãÂãïÂäõ„ÄÇÊàëÂÄëÁöÑ CP È†êÊ∏¨Ê®°ÂûãÂà©Áî®Êï¥È´îÊñπÊ≥ïÔºåÂõ†Ê≠§ÊàëÂÄëË©ï‰º∞‰∫ÜÊï¥È´îÊï¥È´îÂíåÂÄãÂà•Ê®°ÂûãÁöÑ XAI ÊåáÊ®ôË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÖ©Á®Æ XAI ÊñπÊ≥ïÈÉΩËÉΩÊúâÊïàË≠òÂà•ÂΩ±Èüø CP È†êÊ∏¨ÁöÑÈóúÈçµË∫´È´îÈÉ®‰ΩçÔºå‰∏¶‰∏îÈÄô‰∫õËß£ÈáãÂ∞çÊñºÂæÆÂ∞èÁöÑË≥áÊñôÊìæÂãïÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇGrad-CAM Âú® RISv ÊåáÊ®ô‰∏≠È°ØËëóÂÑ™Êñº CAMÔºåË©≤ÊåáÊ®ôË°°ÈáèÈÄüÂ∫¶ÊñπÈù¢ÁöÑÁ©©ÂÆöÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåCAM Âú® RISb ÊåáÊ®ô‰∏≠Ë°®ÁèæÂæóÊõ¥Â•ΩÔºåË©≤ÊåáÊ®ôËàáÈ™®È™ºÁ©©ÂÆöÊÄßÊúâÈóúÔºåËÄå RRS ÊåáÊ®ôÂâáË©ï‰º∞ÂÖßÈÉ®Ë°®Á§∫ÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊï¥È´î‰∏≠ÁöÑÂÄãÂà•Ê®°ÂûãÈ°ØÁ§∫Âá∫‰∏çÂêåÁöÑÁµêÊûúÔºåCAM Âíå Grad-CAM ÈÉΩ‰∏ç‰∏ÄËá¥Âú∞ÂÑ™ÊñºÂè¶‰∏ÄÁ®ÆÔºåÊï¥È´îÊñπÊ≥ïÊèê‰æõ‰∫ÜÂÖ∂ÁµÑÊàêÊ®°ÂûãÁµêÊûúÁöÑË°®Á§∫„ÄÇ

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÂÖ®ÁêÉ‰º∞Ë®àË°®ÊòéÔºåÂ§öÈÅî 24.1 ÂÑÑ‰∫∫Êúâ
ÂÅ•Â∫∑ÁãÄÊ≥ÅÂèØÂæûÂæ©ÂÅ•ÊúçÂãô‰∏≠ÂèóÁõä„ÄÇÂ±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇ (PT) Âú®Êèê‰æõ‰∫íÂãïÂºè
ÂõûÈ•ãÂíåÊúâÊÑèÁæ©ÁöÑËßÄÂØüÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞Ôºå‰æõÊ≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖ‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô
ÂÄãÁº∫Âè£ÔºåÊàëÂÄëÊèêÂá∫ MicroXerciseÔºåÂÆÉÂ∞áÂæÆÂãï‰ΩúÂàÜÊûêËàá
ÂèØÁ©øÊà¥ÂºèÊÑüÊ∏¨Âô®Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÁÇ∫Ê≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ
ÂõûÈ•ã‰ªãÈù¢ÔºåÂåÖÊã¨ÂΩ±Áâá„ÄÅÊñáÂ≠óÂíåÂàÜÊï∏„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂÆÉÊé°Áî®
Â§öÁ∂≠ÂãïÊÖãÊôÇÈñìË¶èÊï¥ (DTW) ÂíåÂü∫ÊñºÊ≠∏Âõ†ÁöÑÂèØËß£Èáã
ÊñπÊ≥ï‰æÜÂàÜÊûêÁõ£ÊéßÈÅãÂãï‰∏≠ÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂ∞àÊ≥®ÊñºÈÅãÂãïÁöÑÈ´òÁ≤íÂ∫¶„ÄÇÈÄôÁ®ÆÂçîÂêå
ÊñπÊ≥ïËá≥ÈóúÈáçË¶ÅÔºåÊèê‰æõËàáËº∏ÂÖ•Â§ßÂ∞èÂåπÈÖçÁöÑËº∏Âá∫Ôºå‰ª•Á≤æÁ¢∫Âú∞
Á™ÅÂá∫ PT ‰∏≠ÈóúÈçµÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•ÂíåÂãï‰ΩúÔºåÂæûËÄåÂ∞áË§áÈõúÁöÑ AI
ÂàÜÊûêËΩâÊèõÁÇ∫Ê∏ÖÊô∞„ÄÅÂèØÊìç‰ΩúÁöÑÂõûÈ•ã„ÄÇÈÄèÈÅéÂú®‰∏çÂêåÊåáÊ®ô‰∏≠Á™ÅÈ°ØÈÄô‰∫õÂæÆÂãï‰ΩúÔºå‰æãÂ¶ÇÁ©©ÂÆöÊÄßÂíåÂãï‰ΩúÁØÑÂúçÔºåMicroXercise
È°ØËëóÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çÂõûÈ•ãÁöÑÁêÜËß£ÂíåÁõ∏ÈóúÊÄß„ÄÇÊØîËºÉÊïàËÉΩÊåáÊ®ôÂº∑Ë™øÂÖ∂ÂÑ™Êñº
ÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰æãÂ¶ÇÁâπÂæµ‰∫íÊÉ†Ë≥áË®ä (FMI) ÂíåÈÄ£Á∫åÊÄßÂàÜÂà•ÊèêÂçá‰∫Ü 39% Âíå 42%„ÄÇMicroXercise Âú®Â±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇÊñπÈù¢Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÊèê‰æõÊäÄË°ìÂÖàÈÄ≤‰∏îÁõ¥Ë¶∫ÊúâÁî®ÁöÑ
Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊèêÂçáÊÇ£ËÄÖÁÖßË≠∑ÂíåÁµêÊûú„ÄÇ

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

ÊëòË¶ÅÔºöÂú®Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåËß£Ê±∫Ê∫ñÁ¢∫ÁñæÁóÖÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÂª∫Ë≠∞ÁöÑË§áÈõúÊÄßÊó¢Ëá≥ÈóúÈáçË¶ÅÂèàÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü MLtoGAIÔºåÂÆÉÂ∞áË™ûÁæ©Á∂≤Ë∑ØÊäÄË°ìËàáÊ©üÂô®Â≠∏Áøí (ML) Áõ∏ÁµêÂêàÔºå‰ª•Â¢ûÂº∑ÁñæÁóÖÈ†êÊ∏¨‰∏¶ÈÄèÈÅé ChatGPT Êèê‰æõ‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑË™™Êòé„ÄÇË©≤Á≥ªÁµ±ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãÂèØÈáçË§á‰ΩøÁî®ÁöÑÁñæÁóÖÊú¨‰ΩìÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÂêÑÁ®ÆÁñæÁóÖÁöÑË©≥Á¥∞Áü•Ë≠òÔºõ‰∏ÄÂÄãË®∫Êñ∑ÂàÜÈ°ûÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÊÇ£ËÄÖÁóáÁãÄ‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÁâπÂÆöÁñæÁóÖÔºõ‰ª•ÂèäË™ûÁæ©Á∂≤Ë∑ØË¶èÂâáË™ûË®Ä (SWRL) ËàáÊú¨‰ΩìÂíå ChatGPT ÁöÑÊï¥ÂêàÔºå‰ª•Áî¢ÁîüÊ∏ÖÊô∞„ÄÅÂÄãÊÄßÂåñÁöÑÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÊòìÊñºÁêÜËß£ÁöÑÁµêÊûúÔºåËß£Ê±∫‰∫ÜÁñæÁóÖÂíå‰∏çÂêåÁóáÁãÄÁöÑË§áÈõúÊÄß„ÄÇMLtoGAI Á≥ªÁµ±Â±ïÁ§∫‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÊªøÊÑèÂ∫¶ÁöÑÂØ¶Ë≥™ÊÄßÈÄ≤Ê≠•ÔºåÊúâÂä©ÊñºÈñãÁôºÊõ¥Êô∫ÊÖß‰∏îÊõ¥ÊòìÊñºÂèñÂæóÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü ML ÊºîÁÆóÊ≥ïÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÈÄèÈÅé ChatGPT Êèê‰æõÈÄèÊòé‰∏î‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË™™ÊòéÁöÑËÉΩÂäõÔºåÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄèÈÅéÂà©Áî®Ë™ûÁæ©ÊäÄË°ìÂíåÂèØËß£ÈáãÁöÑ AIÔºåË©≤Á≥ªÁµ±ÊèêÈ´ò‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÂª∫Ë≠∞ËàáÂÄãÂà•ÊÇ£ËÄÖÁõ∏Èóú‰∏îÊòìÊñºÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂÖàÈÄ≤ÊäÄË°ì‰ª•ÂÖãÊúçÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÁèæÊúâÊåëÊà∞ÁöÑÊΩõÂäõÔºåÁÇ∫Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊú™‰æÜÁôºÂ±ïÈã™Ë∑Ø„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±‰ΩøÁî® 200 ÂÄãÂêàÊàêÊÇ£ËÄÖË≥áÊñôË®òÈåÑÈÄ≤Ë°åÈ©óË≠âÔºåÁ¢∫‰øù‰∫ÜÁ©©ÂÅ•ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÂ∞á‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ïÊï¥ÂêàÂà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑËæØË´ñÊ†∏ÂøÉ„ÄÇÈ´òÂü∑Ë°åÊïàËÉΩÁöÑ AI/ML Ê®°ÂûãÔºå‰æãÂ¶ÇÊï¥È´îÂ≠∏ÁøíÂô®ÂíåÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈòªÁ§ôËá®Â∫äÈÜ´ÁîüÂ∞çÂÖ∂È†êÊ∏¨ÁöÑ‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊ≠£Âú®ÈñãÁôº XAI ÊäÄË°ìÔºå‰ª•‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË°ìË™ûÊèèËø∞ AI/ML È†êÊ∏¨„ÄÇ‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÊòØÊé°Áî®ÊïèÊÑüÂ∫¶ÂàÜÊûê (SA) ÂíåÂÖ®ÁêÉÊïèÊÑüÂ∫¶ÂàÜÊûê (GSA)ÔºåÂÆÉÂÄëÊú¨Ë≥™‰∏äÊúÉ‰æùÊìöÊ®°ÂûãËº∏ÂÖ•Â∞çÈ†êÊ∏¨ÁöÑÂΩ±Èüø‰æÜÂ∞çÂÖ∂ÈÄ≤Ë°åÊéíÂêç„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞ÁöÑ delta-XAI ÊñπÊ≥ïÔºåÈÄèÈÅéÊì¥ÂÖÖ GSA ÊåáÊ®ô delta ÊåáÊï∏‰æÜÊèê‰æõ ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇdelta-XAI ÊåáÊï∏Ë©ï‰º∞ÊØèÂÄãÁâπÂæµÂÄºÂ∞çÂõûÊ≠∏ÂíåÂàÜÈ°ûÂïèÈ°å‰∏≠ÂÄãÂà•‰æãÈ†ÖÁöÑÈ†êÊ∏¨Ëº∏Âá∫‰πãÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞á delta-XAI ÊåáÊï∏ÂΩ¢ÂºèÂåñÔºå‰∏¶Êèê‰æõÂÖ∂ÂØ¶‰ΩúÁöÑÁ®ãÂºèÁ¢º„ÄÇ‰ΩøÁî®Á∑öÊÄßÂõûÊ≠∏Ê®°ÂûãÂ∞çÊ®°Êì¨ÊÉÖÂ¢ÉË©ï‰º∞ delta-XAI ÊñπÊ≥ïÔºå‰∏¶‰ª• Shapley ÂÄº‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÁµêÊûúÈ°ØÁ§∫ delta-XAI ÊåáÊï∏ÈÄöÂ∏∏Ëàá Shapley ÂÄº‰∏ÄËá¥Ôºå‰ΩÜÂú®ÂÖ∑ÊúâÈ´òÂ∫¶ÂΩ±ÈüøÂäõÊàñÊ•µÁ´ØÁâπÂæµÂÄºÁöÑÊ®°Âûã‰∏≠Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇdelta-XAI ÊåáÊï∏Âú®ÂÅµÊ∏¨‰∏ªË¶ÅÁâπÂæµÂíåËôïÁêÜÊ•µÁ´ØÁâπÂæµÂÄºÊñπÈù¢Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊïèÊÑüÂ∫¶„ÄÇÂÆöÊÄßÂú∞‰æÜË™™Ôºådelta-XAI ÈÄèÈÅéÂà©Áî®Ê©üÁéáÂØÜÂ∫¶ÂáΩÊï∏Êèê‰æõÁõ¥ËßÄÁöÑËß£ÈáãÔºå‰ΩøÁâπÂæµÊéíÂêçÊõ¥Ê∏ÖÊô∞‰∏îÂ∞çÂæûÊ•≠‰∫∫Âì°‰æÜË™™Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºådelta-XAI ÊñπÊ≥ïÂ∞çÊñºÁ©©ÂÅ•Âú∞ÂèñÂæó ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã‰ºº‰πéÂæàÊúâÂ∏åÊúõ„ÄÇÂ∞áÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•Ë™øÊü•Ôºå‰ª•Ë©ï‰º∞ÂÖ∂Â∞ç AI ËºîÂä©Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂΩ±Èüø„ÄÇ

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

ÊëòË¶ÅÔºöÂ§±Êô∫ÁóáÊòØ‰∏ÄÁ®ÆÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÁöÑË°∞Âº±ÊÄßÁ•ûÁ∂ìÁñæÁóÖÔºåÂú®Ë®∫Êñ∑‰∏äÂÖ∑ÊúâÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂ§±Êô∫ÂíåÈùûÂ§±Êô∫ËÄÅÂπ¥ÊÇ£ËÄÖÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ΩøÁî® 3D Â§ßËÖ¶Á£ÅÊåØÈÄ†ÂΩ± (MRI) ÊéÉÊèè„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÁç®ÁâπÊäÄË°ìÔºåÁî®ÊñºÈÅ∏ÊìáÊÄßËôïÁêÜ MRI ÂàáÁâáÔºåÈáçÈªûÈóúÊ≥®ÊúÄÁõ∏ÈóúÁöÑÂ§ßËÖ¶ÂçÄÂüüÔºå‰∏¶ÊéíÈô§‰ø°ÊÅØÈáèËºÉÂ∞ëÁöÑÈÉ®ÂàÜ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁî±‰∏ÄÂÄãÂü∫Êñº‰ø°ÂøÉÁöÑÂàÜÈ°ûÂßîÂì°ÊúÉË£úÂÖÖÔºåË©≤ÂßîÂì°ÊúÉÁî±‰∏âÂÄãËá™ÂÆöÁæ©Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁµÑÊàêÔºöDem3D ResNet„ÄÅDem3D CNN Âíå Dem3D EfficientNet„ÄÇÈÄô‰∫õÊ®°ÂûãÂçîÂêåÂ∑•‰Ωú‰ª•Â¢ûÂº∑Ê±∫Á≠ñÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÈõÜÈ´îÂÑ™Âã¢„ÄÇÂú®ÂΩ±ÂÉèÁ†îÁ©∂ÈñãÊîæÂ≠òÂèñÁ≥ªÂàó (OASIS) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 94.12% ÁöÑÈ©ö‰∫∫Ê∫ñÁ¢∫Â∫¶ÔºåË∂ÖÈÅé‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁ•ûÁ∂ìÂΩ±ÂÉèÂÄ°Ë≠∞ (ADNI) Ë≥áÊñôÈõÜ‰∏äÁöÑÈ©óË≠âË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂèØËß£Èáã AI (XAI) ÊäÄË°ìÂíåÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜÊàëÂÄëÊäÄË°ìÁöÑÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÂíåÊàëÂÄëÊñπÊ≥ïÈáçË¶ÅÊÄßÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§±Êô∫ÁóáË®∫Êñ∑Êèê‰æõ‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºåÁÇ∫Ëá®Â∫äÊáâÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈ´òÂ∫¶Ê∫ñÁ¢∫‰∏îÈ´òÊïàÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

ÊëòË¶ÅÔºöËóâÁî±Êô∫ÊÖßÁí∞Â¢É‰∏≠‰∏çÂºï‰∫∫Ê≥®ÁõÆÁöÑÊÑüÊ∏¨Âô®Ëæ®Ë≠òÊó•Â∏∏Ê¥ªÂãïÔºåËÉΩÂïüÁî®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÁõ£ÊéßÂèóË©¶ËÄÖÂú®ÂÆ∂‰∏≠Â¶Ç‰ΩïÂü∑Ë°åÊ¥ªÂãïÔºå‰ª•ÂèäÂÖ∂Èö®ËëóÊôÇÈñìÁöÑËÆäÂåñÔºåÂèØ‰ª•Êè≠Á§∫ÂÅ•Â∫∑ÂïèÈ°åÁöÑÊó©ÊúüÁóáÁãÄÔºå‰æãÂ¶ÇË™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇÊ≠§È†òÂüü‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Â∞áÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çÊáâËá≥Ê¥ªÂãïÁöÑÈªëÁõíÂ≠ê„ÄÇÁÑ∂ËÄåÔºåÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÔºà‰æãÂ¶ÇËá®Â∫äÈÜ´Â∏´ÔºâÈúÄË¶Å‰ø°‰ªª‰∏¶‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑËº∏Âá∫„ÄÇÂõ†Ê≠§Ôºå‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠òÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºå‰ª•Êèê‰æõ‰æÜËá™ÈÄô‰∫õÊ®°ÂûãÁöÑÁõ¥Ë¶∫Ëá™ÁÑ∂Ë™ûË®ÄË™™Êòé„ÄÇ‰∏çÂêåÁöÑ XAI ÊñπÊ≥ïÊúÉÁî¢Áîü‰∏çÂêåÁöÑË™™ÊòéÔºåËÄåÂÖ∂ÊúâÊïàÊÄßÈÄöÂ∏∏ÈÄèÈÅé‰ΩøÁî®ËÄÖË™øÊü•‰æÜË©ï‰º∞ÔºåÈÄôÂú®ÊàêÊú¨ÂíåÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Âú®ÂÄôÈÅ∏ËÄÖ‰∏≠ÊâæÂá∫ÊúÄÈÅ©ÂêàÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÁöÑ XAI ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË°®ÊòéÔºåLLM Ë©ï‰º∞Ëàá‰ΩøÁî®ËÄÖË™øÊü•‰∏ÄËá¥„ÄÇ

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

ÊëòË¶ÅÔºöÂ∑•Ê•≠ 5.0 ËëóÈáçÊñº‰∫∫È°ûËàá‰∫∫Â∑•Êô∫ÊÖß (AI) Âêà‰ΩúÂü∑Ë°åË£ΩÈÄ†‰∏≠ÁöÑ‰∏çÂêå‰ªªÂãôÔºåÊ∂âÂèäÊõ¥Â§öÊ©üÂô®‰∫∫„ÄÅÁâ©ËÅØÁ∂≤ (IoT) Ë£ùÁΩÆÂíå‰∫íÈÄ£„ÄÅÊì¥Â¢û/ËôõÊì¨ÂØ¶Â¢É (AR) ÂíåÂÖ∂‰ªñÊô∫ÊÖßË£ùÁΩÆ„ÄÇÈÄô‰∫õË£ùÁΩÆÂíå‰∫íÈÄ£Âú®Á∂ìÊøü„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÊïôËÇ≤ÂíåÂúãÈò≤Á≥ªÁµ±Á≠âÂêÑÁ®ÆÈóúÈçµÈ†òÂüüÁöÑÂª£Ê≥õÂèÉËàáÔºåÂºïÁôº‰∫ÜÂ§öÁ®ÆÈ°ûÂûãÁöÑÊΩõÂú®ÂÆâÂÖ®ÊºèÊ¥û„ÄÇAI Êú¨Ë∫´Â∑≤Ë¢´Ë≠âÊòéÊòØÁ∂≤Ë∑ØÂÆâÂÖ®‰∏çÂêåÈ†òÂüü‰∏≠ÈùûÂ∏∏ÊúâÊïà‰∏îÂº∑Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰æãÂ¶ÇÂÖ•‰æµÂÅµÊ∏¨„ÄÅÊÉ°ÊÑèËªüÈ´îÂÅµÊ∏¨ÂíåÁ∂≤Ë∑ØÈá£È≠öÂÅµÊ∏¨Á≠â„ÄÇÂ∞±ÂÉèÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏ÄÊ®£ÔºåÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÊ•≠‰∫∫Âì°‰∏çÈ°òÊÑèÊé•ÂèóÈªëÁõí ML Ëß£Ê±∫ÊñπÊ°à‰æÜÊáâÁî®ÊñºÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÇÈÄôÁ®Æ‰∏çÈ°òÊÑè‰øÉ‰ΩøÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂ∑•ÂÖ∑Ë¢´Êé°Áî®ÔºåÊúâÂä©ÊñºË™™ÊòéÂú®Âü∫Êñº ML ÁöÑÁ≥ªÁµ±‰∏≠Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÂ∞çÂ∑•Ê•≠ 5.0 ÁöÑ‰∏çÂêåÂü∫Êñº XAI ÁöÑÂÖ•‰æµÂÅµÊ∏¨Á≥ªÁµ±ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰∏¶‰∏îÊàëÂÄë‰πüÈÄèÈÅéÂ∞çÊäóÂºè XIDS (Adv-XIDS) ÊñπÊ≥ïÁöÑËßÄÈªû‰æÜÊé¢Ë®éÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÁ∂≤Ë∑ØÂÆâÂÖ®ÂØ¶ÂãôÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂ∑•Ê•≠ 5.0 ÁöÑ XAI Á∂≤Ë∑ØÂÆâÂÖ®Á≥ªÁµ±‰∏≠ÂèØËÉΩÂ≠òÂú®ÁöÑÊ©üÊúÉÂíåÊåëÊà∞ÔºåÂºïÁôº‰∫ÜÊú™‰æÜÈáùÂ∞ç XAI Âü∫Á§éËß£Ê±∫ÊñπÊ°àÁöÑÁ†îÁ©∂Ôºå‰ª•‰æõÈ´òÈ¢®Èö™ÁöÑÂ∑•Ê•≠ 5.0 ÊáâÁî®Êé°Áî®„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÈ†ÖÂö¥Ë¨πÁöÑÂàÜÊûêÂ∞áÁÇ∫ÊåáÂÆöÈ†òÂüüÂÖßÁöÑÂæåÁ∫åÁ†îÁ©∂Â∑•‰ΩúÂª∫Á´ãÂü∫Á§éÊû∂Êßã„ÄÇ

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÂ∞áËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÂØ¶‰ΩúÊñºÈÜ´ÁôÇ‰ø°ÂáΩÁ∑®Á¢ºËá™ÂãïÂåñÔºå‰∏¶ÂÖ∑ÂÇôË¶ñË¶∫ÂåñË™™ÊòéËÉΩÂäõÂíåËºïÈáèÂåñÁöÑÊú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö„ÄÇÁõÆÂâçÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÁ∑®Á¢ºÊòØ‰∏ÄÁ®ÆÊâãÂãïÊµÅÁ®ãÔºåÊ∂âÂèäÁÇ∫ÁóÖÊÇ£Êñá‰ª∂‰∏≠ÁöÑÊØèÈ†ÖÁóÖÁóá„ÄÅÁ®ãÂ∫èÂíåËó•Áâ©ÊåáÊ¥æ‰ª£Á¢º (‰æãÂ¶ÇÔºå‰ΩøÁî® SNOMED CT ‰ª£Á¢º 56265001 Ë°®Á§∫ÂøÉËáüÁóÖ)„ÄÇÊ≠§È†òÂüüÊúâ‰ΩøÁî®ÊúÄÊñ∞ ML Ê®°ÂûãÈÄ≤Ë°åËá™ÂãïÁ∑®Á¢ºÁöÑÂàùÊ≠•Á†îÁ©∂ÔºõÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂ§ßÂ∞èÔºå‰∏¶Êú™ÂØ¶ÁèæÂØ¶ÈöõÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•‰øÉÈÄ≤Ëá™ÂãïÁ∑®Á¢ºÂØ¶ÂãôÁöÑÂèØËÉΩÊÄßÔºåÊàëÂÄëÂú®Êú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö‰∏≠Êé¢Ë®é‰∫Ü‰∏Ä‰∫õËß£Ê±∫ÊñπÊ°àÔºõÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË™™ÊòéÂäüËÉΩÂú® AI Ê®°ÂûãÈÄèÊòéÂ∫¶‰∏≠ÁöÑÂäüËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ¨ÈñãÁöÑ MIMIC-III Ë≥áÊñôÂ∫´Âíå HAN/HLAN Á∂≤Ë∑ØÊ®°ÂûãÈÄ≤Ë°å ICD ‰ª£Á¢ºÈ†êÊ∏¨„ÄÇÊàëÂÄëÈÇÑË©¶È©ó‰∫Ü ICD Âíå SNOMED CT Áü•Ë≠òÂ∫´‰πãÈñìÁöÑÂ∞çÊáâ„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫Ü 97.98% ‰ª£Á¢ºÁöÑÊúâÁî®Ë≥áË®ä„ÄÇÈÄôÈ†ÖË™øÊü•ÁµêÊûúÂèØ‰ª•ÁÇ∫ÂØ¶Âãô‰∏≠ÁöÑËá™ÂãïËá®Â∫äÁ∑®Á¢ºÂØ¶‰ΩúÊèê‰æõ‰∏Ä‰∫õË¶ãËß£Ôºå‰æãÂ¶ÇÂú®ÈÜ´Èô¢Áí∞Â¢É‰∏≠ÔºåÁî±Ëá®Â∫äÈÜ´Áîü‰ΩøÁî®ÁöÑÊú¨Âú∞ÈõªËÖ¶ÔºåÂ∞àÊ°àÈ†ÅÈù¢ \url{https://github.com/Glenj01/Medical-Coding}„ÄÇ

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊîØÊåÅÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊòØÊú™‰æÜ 6G Á∂≤Ë∑Ø‰∏≠ÁöÑÈóúÈçµÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠Â∞áÂºïÂÖ•ÂéüÁîü AI ÁöÑÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåAI Âª£Ê≥õÁî®Êñº‰∏çÂêåÁöÑÈóúÈçµÊáâÁî®‰∏≠Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÂíåÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®ÈÄô‰∫õÊáâÁî®‰∏≠Ôºå‰ΩøÁî® AI ‰ΩúÁÇ∫ÈªëÁõíÊ®°ÂûãÊòØÊúâÈ¢®Èö™‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ„ÄÇÂõ†Ê≠§ÔºåÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÊòØÈñãÁôºÂèØËß£Èáã AI (XAI) Êû∂ÊßãÔºåÊó®Âú®Ëß£ÈáãÈªëÁõíÊ®°ÂûãË°åÁÇ∫ËÉåÂæåÁöÑÈÇèËºØÔºåÂæûËÄåÁ¢∫‰øùÂÖ∂ÊúâÊïà‰∏îÂÆâÂÖ®ÁöÑÈÉ®ÁΩ≤„ÄÇÊúÄËøëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊìæÂãïÁöÑ XAI-CHEST Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Èù¢ÂêëÁÑ°Á∑öÈÄö‰ø°‰∏≠ÁöÑ‰ø°ÈÅì‰º∞Ë®à„ÄÇXAI-CHEST Ê°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöÈÅéÂú®ÁÑ°ÈóúËº∏ÂÖ•‰∏äÂºïÂÖ•È´òÂô™ËÅ≤‰æÜË≠òÂà•Áõ∏ÈóúÊ®°ÂûãËº∏ÂÖ•„ÄÇÈÄô‰ªΩÊâãÁ®øÊèê‰æõ‰∫Ü XAI-CHEST Ê°ÜÊû∂ÁöÑË©≥Á¥∞ÁêÜË´ñÂü∫Á§é„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé®Â∞é‰∫Ü XAI-CHEST ÊêçÂ§±ÂáΩÊï∏ÂíåÂô™ËÅ≤ÈñæÂÄºÂæÆË™øÂÑ™ÂåñÂïèÈ°åÁöÑËß£ÊûêË°®ÈÅîÂºè„ÄÇÂõ†Ê≠§ÔºåË®≠Ë®àÁöÑ XAI-CHEST Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊô∫ËÉΩËº∏ÂÖ•ÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÂÑ™ÂåñÊâÄÁî®Ê®°ÂûãÁöÑÊû∂ÊßãÁöÑÂêåÊôÇÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊï¥È´îÊÄßËÉΩ„ÄÇÊ®°Êì¨ÁµêÊûúË°®ÊòéÔºåXAI-CHEST Ê°ÜÊû∂Êèê‰æõ‰∫ÜÊúâÊïàÁöÑËß£ÈáãÔºåÂú®Èôç‰ΩéÊâÄÈúÄÁöÑË®àÁÆóË§áÈõúÂ∫¶ÁöÑÂêåÊôÇÔºåÊèê‰æõ‰∫ÜÊîπÈÄ≤ÁöÑÊØîÁâπÈåØË™§ÁéáÊÄßËÉΩÔºåËÄåÈÄôËàáÂü∫ÊñºÂÇ≥Áµ± DL ÁöÑ‰ø°ÈÅì‰º∞Ë®àÁõ∏ÊØî„ÄÇ

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

ÊëòË¶ÅÔºöËøôÁØáËÆ∫ÊñáÊèêÂá∫‰∫ÜÁî®‰∫é‰ªéËßÜÁΩëËÜúÁúºÂ∫ïÂõæÂÉèËøõË°åÁñæÁóÖÂàÜÁ±ªÁöÑÊâ©Âº†ÊÆãÂ∑ÆÁΩëÁªú (ResNet) Ê®°Âûã„ÄÇÊâ©Âº†Âç∑ÁßØÊª§Ê≥¢Âô®Áî®‰∫éÊõøÊç¢ ResNet Ê®°ÂûãËæÉÈ´òÂ±Ç‰∏≠ÁöÑÊ≠£Â∏∏Âç∑ÁßØÊª§Ê≥¢Âô®ÔºàÊâ©Âº† ResNetÔºâÔºå‰ª•ÊîπÂñÑÊÑüÁü•Âú∫Ôºå‰ªéËÄåÈíàÂØπÁñæÁóÖÂàÜÁ±ªÂØπÊ≠£Â∏∏ ResNet Ê®°ÂûãËøõË°åÊîπËøõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÈááÁî®Ê∑±Â∫¶Â≠¶‰π†ÁöÑËÆ°ÁÆóÊú∫ËæÖÂä©ËØäÊñ≠Â∑•ÂÖ∑ÔºåÂπ∂ÈÄöËøáÂèØËß£ÈáäÁöÑ AI ÊäÄÊúØËøõË°å‰∫ÜÂ¢ûÂº∫„ÄÇËøô‰∫õÊäÄÊúØÊó®Âú®‰ΩøËØ•Â∑•ÂÖ∑ÁöÑÂÜ≥Á≠ñËøáÁ®ãÈÄèÊòéÂåñÔºå‰ªéËÄå‰ΩøÂåªÂ≠¶‰∏ì‰∏ö‰∫∫Â£´ËÉΩÂ§üÁêÜËß£Âíå‰ø°‰ªª AI ÁöÑËØäÊñ≠ÂÜ≥Á≠ñ„ÄÇÂÆÉ‰ª¨‰∏éÂΩì‰ªäÁöÑÂåªÁñó‰øùÂÅ•È¢ÜÂüüÂ∞§‰∏∫Áõ∏ÂÖ≥ÔºåÂú®ËØ•È¢ÜÂüüÔºåÂØπ AI Â∫îÁî®ÁöÑÈÄèÊòéÂ∫¶ÈúÄÊ±Ç‰∏çÊñ≠Â¢ûÈïøÔºå‰ª•Á°Æ‰øùÂÖ∂ÂèØÈù†ÊÄßÂíåÂêà‰πéÈÅìÂæ∑ÁöÑ‰ΩøÁî®„ÄÇÊâ©Âº† ResNet Áî®‰ΩúÊ≠£Â∏∏ ResNet ÁöÑÊõø‰ª£ÂìÅÔºå‰ª•ÊèêÈ´òËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÊâÄÈúÄÁöÑËÆ°ÁÆóÊó∂Èó¥„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜÊòØÁúºÁßëÁñæÁóÖÊô∫ËÉΩËØÜÂà´ (ODIR) Êï∞ÊçÆÈõÜÔºåËøôÊòØ‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÁúºÁßëÊï∞ÊçÆÂ∫ìÔºåÂåÖÂê´ÂÖ´Á±ªÊ∂µÁõñÂ§ßÂ§öÊï∞Â∏∏ËßÅËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖ„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨Á≤æÁ°ÆÂ∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÂáÜÁ°ÆÂ∫¶Âíå F1 ÂæóÂàÜ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÂØπ ResNet-18„ÄÅResNet-34„ÄÅResNet-50„ÄÅResNet-101 Âíå ResNet-152 ‰∫î‰∏™Âèò‰ΩìÁöÑÊ≠£Â∏∏ ResNet Ê®°ÂûãÂíåÊâ©Âº† ResNet Ê®°ÂûãËøõË°å‰∫ÜÊØîËæÉÁ†îÁ©∂„ÄÇ‰∏éÊ≠£Â∏∏ ResNet Áõ∏ÊØîÔºåÊâ©Âº† ResNet Ê®°ÂûãÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºåÂú® ODIR Â§öÁ±ªÁñæÁóÖÂàÜÁ±ª‰∏≠Ôºå‰∏äËø∞ÂêÑ‰∏™Âèò‰ΩìÁöÑÂπ≥Âùá F1 ÂæóÂàÜ‰∏∫ 0.71„ÄÅ0.70„ÄÅ0.69„ÄÅ0.67 Âíå 0.70„ÄÇ

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºå‰ª£Ë°®ËëóÂú®Âä†Âº∑Ë®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇÊñπÈù¢ÈÇÅÂá∫‰∏ÄÂ§ßÊ≠•„ÄÇÁÑ∂ËÄåÔºåÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂ∞çÂÖ∂ÂèØ‰ø°Â∫¶ÈÄ≤Ë°åÂö¥Ê†ºÁöÑÂØ©Êü•ÔºåÂåÖÊã¨Èö±ÁßÅ„ÄÅÁ©©ÂÅ•ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÁõÆÂâçÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Âü∫Á§éÊ®°ÂûãÁöÑË™øÊü•ÊñáÁçª‰∏≠È°ØÁ§∫Âá∫Áõ∏Áï∂Â§ßÁöÑÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂú®ÂèØ‰ø°Â∫¶ÊñπÈù¢„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÈóúÊñºÂü∫Á§éÊ®°ÂûãÂèØ‰ø°Â∫¶ÁöÑË™øÊü•‰∏¶Êú™ÂÖÖÂàÜËß£Ê±∫ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüü‰∏≠ÁöÑÁâπÂÆöËÆäÂåñÂíåÊáâÁî®„ÄÇÊú¨Ë™øÊü•Êó®Âú®ÈÄöÈÅéÊèêÂá∫ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠‰ΩøÁî®ÁöÑÂü∫Á§éÊ®°ÂûãÁöÑÊñ∞ÂàÜÈ°ûÊ≥ï‰∏¶ÂàÜÊûêÁ¢∫‰øùÂÖ∂ÂèØ‰ø°Â∫¶ÁöÑÈóúÈçµÂãïÊ©üÔºå‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÂü∫Á§éÊ®°ÂûãÂú®‰∏ªË¶ÅÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÁöÑÁï∂ÂâçÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®ÂàÜÂâ≤„ÄÅÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê„ÄÅÈÜ´ÁôÇÂïèÈ°åÂíåÂõûÁ≠î (Q&A) ‰ª•ÂèäÁñæÁóÖË®∫Êñ∑„ÄÇÈÄô‰∫õÈ†òÂüü‰πãÊâÄ‰ª•Ë¢´Âº∑Ë™øÔºåÊòØÂõ†ÁÇ∫ËàáÂÖ∂‰ªñÊáâÁî®Áõ∏ÊØîÔºåÂÆÉÂÄëÂ∑≤Á∂ìÁúãÂà∞Áõ∏Â∞çÊàêÁÜü‰∏îÂ§ßÈáèÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÊé¢Ë®éÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÊâãÁ®ø‰∏≠ÂèØ‰ø°Â∫¶ÁöÑÊñáÁçª„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÁÇ∫ÊØèÂÄãÊáâÁî®ÊßãÂª∫ÂèØ‰ø°Âü∫Á§éÊ®°ÂûãÁöÑË§áÈõúÊåëÊà∞ÔºåÁ∏ΩÁµê‰∫ÜÁï∂ÂâçÈóúÊ≥®ÈªûÂíåÂ¢ûÂº∑ÂèØ‰ø°Â∫¶ÁöÑÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Èù©Êñ∞ÊÇ£ËÄÖË≠∑ÁêÜÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÊúùËëóÂèØ‰ø°Ë≥¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÇÅÈÄ≤ÁöÑÂøÖË¶ÅÊÄßÔºå‰∏¶ÂÄ°Â∞é‰∏ÄÁ®ÆÂπ≥Ë°°ÁöÑÊñπÊ≥ïÔºåÊó¢ËÉΩ‰øÉÈÄ≤ÂâµÊñ∞ÔºåÂèàËÉΩÁ¢∫‰øùÈÅìÂæ∑ÂíåÂÖ¨Âπ≥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

ÊëòË¶ÅÔºöÂ∫äÈÇäË∂ÖÈü≥Ê≥¢ (POCUS) ÊòØËá®Â∫äÈÜ´Â∏´Âú®ÊÇ£ËÄÖÂ∫äÈÇäÈÄ≤Ë°åÂíåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÊéÉÊèèÁöÑÂØ¶Âãô„ÄÇÁÑ∂ËÄåÔºåËß£ËÆÄÈÄô‰∫õÂΩ±ÂÉèÊâÄÈúÄÁöÑÂ∞àÊ•≠Áü•Ë≠òÁõ∏Áï∂ÂèØËßÄÔºåËÄå‰∏îÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØËÉΩ‰∏¶ÈùûÈö®ÊôÇÂÖ∑ÂÇô„ÄÇÈÄôÁ®ÆÁèæÂØ¶ÊÉÖÊ≥Å‰ΩøÂæóÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Á≠âÊºîÁÆóÊ≥ïÂ∞çÊñºÂä†Âº∑‰∫∫È°ûÊ±∫Á≠ñËÆäÂæóÊ•µÁÇ∫ÊúâÂÉπÂÄº„ÄÇPOCUS Ë£ùÁΩÆÊ≠£‰ª•ÂêàÁêÜÊàêÊú¨Êé®Âá∫ÔºåÂ∞∫ÂØ∏ÁÇ∫ÊâãÊ©üÂ§ßÂ∞è„ÄÇÂ∞á POCUS Ë£ùÁΩÆËΩâËÆäÁÇ∫ÊïëÁîüÂ∑•ÂÖ∑ÁöÑÊåëÊà∞Âú®ÊñºÔºåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈúÄË¶ÅÂ∞àÈñÄË®ìÁ∑¥ÂíåÁ∂ìÈ©ó„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂèñÂæóÊ≠£ÂêëË®ìÁ∑¥ÂΩ±ÂÉèÁöÑÂõ∞Èõ£Â∫¶‰ª£Ë°®ËëóÂª∫ÁΩÆÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÂàÜÈ°ûÂô®ÁöÑ‰∏ÄÂ§ßÈöúÁ§ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂòóË©¶Êé¢Ë®éÁöÑÂïèÈ°åÊòØÂ¶Ç‰ΩïÊé¢Á¥¢Á≠ñÁï•Ôºå‰ª•ÊèêÈ´ò‰ΩøÁî®Á®ÄÁñèË≥áÊñôË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â∞ëÊï∏Ë≥áÊñôÂØ¶‰æãÈÄ≤Ë°åË®ìÁ∑¥ÂèØËÉΩ‰∏çË∂≥‰ª•ËÆìÂàÜÈ°ûÂô®Ê¶ÇÊã¨ÔºåÂ∞éËá¥ÂÆÉÂÄëÈÅéÂ∫¶Êì¨Âêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®ÂèØËß£Èáã AI Â¢ûÂº∑ÊñπÊ≥ïÔºå‰ª•ÂçîÂä©ÊºîÁÆóÊ≥ïÂæûËºÉÂ∞ëÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÊõ¥Â§öÔºå‰∏¶ÊΩõÂú®ÂçîÂä©ÂàÜÈ°ûÂô®Êõ¥Â•ΩÂú∞Ê¶ÇÊã¨„ÄÇ

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁæéÂúãË¶ãË≠â‰∫ÜÈõªÂ≠êÁÖôÊàñÈõªÂ≠êÈ¶ôËè∏‰ΩøÁî®ÁéáÂ§ßÂπÖÊøÄÂ¢ûÔºåÂ∞éËá¥ÈõªÂ≠êÁÖôÂíåÈõªÂ≠êÁÖô‰ΩøÁî®Áõ∏ÈóúËÇ∫ÊêçÂÇ∑ (EVALI) ÁóÖ‰æãÈ°ØËëóÂ¢ûÂä†ÔºåÂú® 2019 Âπ¥ EVALI ÁàÜÁôºÊúüÈñìÈÄ†Êàê‰ΩèÈô¢ÂíåÊ≠ª‰∫°ÔºåÂá∏È°Ø‰∫ÜÁêÜËß£ÈõªÂ≠êÁÖôË°åÁÇ∫ÂíåÂà∂ÂÆöÊúâÊïàÊàíËè∏Á≠ñÁï•ÁöÑËø´ÂàáÊÄß„ÄÇÁî±ÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºåÂÖ®ÁêÉË∂ÖÈÅé 47 ÂÑÑ‰ΩøÁî®ËÄÖ‰ΩøÁî®ÂÆÉÂÄëÈÄ≤Ë°åÈÄ£Áµê„ÄÅÊ∫ùÈÄö„ÄÅÊñ∞ËÅûÂíåÂ®õÊ®ÇÔºåÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜËàáÂÅ•Â∫∑Áõ∏ÈóúÔºåÂõ†Ê≠§Â∞áÁ§æÁæ§Â™íÈ´îË≥áÊñôÂª∫Á´ãÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÁ†îÁ©∂‰∏≠ÁÑ°ÂÉπÁöÑÊúâÊ©üË≥áÊñôË≥áÊ∫ê„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû Reddit ‰∏ä‰∏ÄÂÄãÈõªÂ≠êÁÖôÂ≠êÁ§æÁæ§‰∏≠ÊèêÂèñ‰∏ÄÂÄãÁØÑ‰æãË≥áÊñôÈõÜÔºå‰ª•ÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñ„ÄÇÂà©Áî® OpenAI ÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã GPT-4 ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñÂÅµÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÊ≠§Ê®°ÂûãÁöÑÁµêÊûúËàáÂ§ñË°å‰∫∫ÂíåËá®Â∫äÂ∞àÂÆ∂Ë®ªËß£„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏Áøí„ÄÅ‰∏ÄÊ¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÊÄùËÄÉÈèàÊèêÁ§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü 8 ÂÄãÊèêÁ§∫ÔºåË©≥Á¥∞Á®ãÂ∫¶‰∏çÂêåÔºåÂêë GPT-4 Ëß£Èáã‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞ÈÄô‰∫õÁ≠ñÁï•ÂΩºÊ≠§‰πãÈñìÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÂàùÊ≠•ÁôºÁèæÂº∑Ë™ø‰∫Ü GPT-4 Âú®Á§æÁæ§Â™íÈ´îË≥áÊñôÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë≠òÂà•‰∫∫È°ûÂÅµÊ∏¨ÂèØËÉΩÁÑ°Ê≥ïÂØüË¶∫ÁöÑ‰ΩøÁî®ËÄÖÂæÆÂ¶ôÊÑèÂúñÊñπÈù¢„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Â∑≤ÈÅîÂà∞Êï¥È´îÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÁÑ∂ËÄåÔºåÁâπÂÆöÊÇ£ËÄÖÁæ§È´îÁöÑÊïàËÉΩÂ∑ÆÁï∞Â∞çÂÖ∂Ëá®Â∫äÊïàÁî®„ÄÅÂÆâÂÖ®ÊÄßËàáÂÖ¨Âπ≥ÊÄßÊßãÊàêÊåëÊà∞„ÄÇÈÄôÂèØËÉΩÊúÉÂΩ±ÈüøÂ∑≤Áü•ÁöÑÊÇ£ËÄÖÁæ§È´îÔºà‰æãÂ¶ÇÂü∫ÊñºÊÄßÂà•„ÄÅÂπ¥ÈΩ°ÊàñÁñæÁóÖ‰∫ûÂûãÔºâ‰ª•ÂèäÂÖàÂâçÊú™Áü•‰∏îÊú™Ê®ôÁ±§ÁöÑÁæ§È´î„ÄÇÊ≠§Â§ñÔºåÊ≠§È°ûËßÄÂØüÂà∞ÁöÑÊïàËÉΩÂ∑ÆÁï∞ÁöÑÊ†πÊú¨ÂéüÂõ†ÈÄöÂ∏∏Èõ£‰ª•ÁôºÁèæÔºåÈòªÁ§ô‰∫ÜÁ∑©Ëß£Êé™ÊñΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂà©Áî®ÂàáÁâáÁôºÁèæÊñπÊ≥ï (SDM) ‰æÜË≠òÂà•ÂèØËß£ÈáãÁöÑË≥áÊñôÊïàËÉΩ‰∏ç‰Ω≥Â≠êÈõÜÔºå‰∏¶ÈáùÂ∞çËßÄÂØüÂà∞ÁöÑÊïàËÉΩÂ∑ÆÁï∞ÂéüÂõ†Âà∂ÂÆöÂÅáË®≠„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÁöÑ SDMÔºå‰∏¶Âú®ËÉ∏ÈÉ® X ÂÖâÁâá‰∏≠ËÇ∫ÁÇéÂíåËÇ∫‰∏çÂºµÂàÜÈ°ûÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÊáâÁî®ÂÆÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòé‰∫Ü SDM Âú®ÂÅáË®≠Âà∂ÂÆö‰∏≠ÁöÑÊúâÊïàÊÄßÔºå‰∏¶Â∞çÂª£Ê≥õ‰ΩøÁî®ÁöÑËÉ∏ÈÉ® X ÂÖâÁâáË≥áÊñôÈõÜÂíåÊ®°Âûã‰∏≠ÂÖàÂâçËßÄÂØüÂà∞‰ΩÜÁÑ°Ê≥ïËß£ÈáãÁöÑÁî∑ÊÄßÂíåÂ•≥ÊÄßÊÇ£ËÄÖ‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞Êèê‰æõ‰∫ÜËß£Èáã„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåÂú®ÂàÜÈ°û‰ªªÂãô‰∏≠ÔºåÈÄèÈÅéËÉ∏ËÖîÂºïÊµÅÁÆ°ÂíåÂøÉÈõªÂúñÂ∞éÁ∑öÁöÑÂ≠òÂú®ÔºåÂ≠òÂú®Êç∑ÂæëÂ≠∏Áøí„ÄÇÈÄô‰∫õÊç∑ÂæëÁâπÂæµÁöÑÁõõË°åÁéáÂ≠òÂú®Âü∫ÊñºÊÄßÂà•ÁöÑÂ∑ÆÁï∞Ôºå‰ºº‰πéÊúÉÂ∞éËá¥ËßÄÂØüÂà∞ÁöÑÂàÜÈ°ûÊïàËÉΩÂ∑ÆË∑ùÔºåÈÄô‰ª£Ë°®Êç∑ÂæëÂ≠∏ÁøíÂíåÊ®°ÂûãÂÖ¨Âπ≥ÊÄßÂàÜÊûê‰πãÈñìÂÖàÂâçÊú™ÂèóÂà∞ÈáçË¶ñÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇ

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôÁöÑÊ¶ÇÂøµÂú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂÇôÂèóÈóúÊ≥®ÔºåÂÖ∂ÈáçË¶ÅÊáâÁî®‰πã‰∏Ä‰æøÊòØÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÂÖÉÂÆáÂÆôÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÈÄèÈÅéÊîπËÆäÁóÖÊÇ£ÁÖßË≠∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤Ôºå‰ª•ÂèäÊïôÂ≠∏/Â≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÊñπÂºè‰æÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÁöÑÊòØÊèê‰æõÂÖÉÂÆáÂÆôÂü∫Êú¨Ê¶ÇÂøµÂíåÂü∫Á§éÊäÄË°ìÁöÑ‰ªãÁ¥π„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶ÂæûÊäÄË°ìÂíå AI ÁöÑËßíÂ∫¶ÂàÜÊûêÂÖ∂ÊΩõÂäõ„ÄÇÁâπÂà•ÊòØÔºåË®éË´ñ‰∫ÜÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑËßíËâ≤ÔºõÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂ∞áÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÂÖÉÂÆáÂÆôÁî¢ÁîüÁöÑË≥áÊñôÔºå‰ª•Áç≤ÂæóÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÊñπÈù¢ÁöÑÊõ¥‰Ω≥Ë¶ãËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊé¢Ë®éÂçÄÂ°äÈèàÁ≠âÊñ∞ËààÊäÄË°ìÔºå‰∏¶Ëß£Ê±∫Èö±ÁßÅÂïèÈ°åÔºå‰æÜÊé¢Ë®éÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑÊú™‰æÜÈ°òÊôØ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÂÖ∂Âú®ÈÜ´ÁôÇÊúçÂãôÊèê‰æõÊñπÈù¢ÁôºÊèÆÈù©ÂëΩÊÄßËÆäÈù©ÁöÑÊΩõÂäõ„ÄÇ

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫‰∏îÂèäÊôÇÂú∞ÂÅµÊ∏¨‰π≥ÁôåÂ∞çÊñºÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåËá≥ÈóúÈáçË¶Å„ÄÇË®∫Êñ∑ÊñπÊ≥ïÂÇ≥Áµ±‰∏ä‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºõÁÑ∂ËÄåÔºåÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÊ≠£Âú®Êï¥ÂêàË∂ÖË∂äÂÇ≥Áµ±ÂΩ±ÂÉèÁöÑÂêÑÁ®ÆË≥áÊñô‰æÜÊ∫ê„ÄÇ‰ΩøÁî®Êï¥ÂêàÂΩ±ÂÉèÂíåÈùûÂΩ±ÂÉèË≥áÊñôÁöÑÂ§öÊ®°ÂºèÊäÄË°ìÔºåÊ®ôË™åËëó‰π≥ÁôåË®∫Êñ∑ÁöÑËÆäÈù©ÊÄßÈÄ≤Â±ï„ÄÇÊú¨ÁØáÁ∂úËø∞ÁöÑÁõÆÁöÑÊòØÊé¢Ë®éÂ§öÊ®°ÂºèÊäÄË°ìÁöÑÊñ∞ËààÈ†òÂüüÔºåÁâπÂà•ÊòØÂ∞áÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèËàáÈùûÂΩ±ÂÉèË≥áÊñôËûçÂêà„ÄÇÊ≠§Â§ñÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞áÁî®ÊñºÈó°ÊòéË§áÈõúÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÂº∑Ë™øË®∫Êñ∑ÈÅéÁ®ã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á∂úËø∞Âà©Áî®Â§öÊ®°ÂºèË≥áÊñô‰∏¶Âº∑Ë™øÂèØËß£ÈáãÊÄßÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÅËá®Â∫äÈÜ´Â∏´ÁöÑ‰ø°ÂøÉÂíåÊÇ£ËÄÖÂèÉËàáÂ∫¶ÔºåÊúÄÁµÇ‰øÉÈÄ≤‰π≥ÁôåÊõ¥ÂÄã‰∫∫ÂåñÁöÑÊ≤ªÁôÇÁ≠ñÁï•ÔºåÂêåÊôÇ‰πüÊâæÂá∫Â§öÊ®°ÂºèÂíåÂèØËß£ÈáãÊÄßÁöÑÁ†îÁ©∂Â∑ÆË∑ùÔºåÂºïÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂Ôºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÁ≠ñÁï•ÊñπÂêëÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

ÊëòË¶ÅÔºöÊñ∞ÁîüÂÖíÊúüÊòØÂ§ßËÖ¶ÁôºËÇ≤ÊúÄËÑÜÂº±ÁöÑÊôÇÊúüÔºåÂÆπÊòìÂá∫ÁèæÁô≤ÁôáÁôº‰Ωú„ÄÇÂ§ßËÖ¶ÁôºËÇ≤‰∏çÊàêÁÜüÊôÇÂá∫ÁèæÁô≤ÁôáÁôº‰ΩúÊúÉÈÄ†Êàê‰∏çËâØÂæåÊûúÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊó©Ë®∫Êñ∑„ÄÇÁõÆÂâçÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÁöÑÈªÉÈáëÊ®ôÊ∫ñ‰æùË≥¥ÊñºÈÄ£Á∫åÁöÑË¶ñË®äËÖ¶ÈõªÂúñ (EEG) Áõ£Ê∏¨ÔºõÂÖ∂‰∏≠ÂåÖÊã¨Âú®Êñ∞ÁîüÂÖíÂä†Ë≠∑ÁóÖÊàø (NICU) ÂÖßÂêåÊôÇÈÄ≤Ë°åÂ§öÈ†ªÈÅìËÖ¶ÈõªÂúñ (EEG) Ë®òÈåÑÂíåÂç≥ÊôÇË¶ñË®äÁõ£Êéß„ÄÇÁÑ∂ËÄåÔºåË¶ñË®äËÖ¶ÈõªÂúñÁõ£ÊéßÊäÄË°ìÈúÄË¶ÅËá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÔºåËÄå‰∏îÈÄöÂ∏∏ÂÉÖÈôêÊñºÊäÄË°ìÂÖàÈÄ≤‰∏îË≥áÊ∫êË±êÂØåÁöÑÁí∞Â¢É„ÄÇÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñ∞ÊäÄË°ìÂèØ‰ª•Âπ´Âä©ÈÜ´ÁôÇÁïåÊ∫ñÁ¢∫Ë®∫Êñ∑‰∏¶Á´ãÂç≥ÊèêÂÄ°Ê≤ªÁôÇ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ëá™ÂãïÂåñÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÈÅéÁ®ãÔºå‰∏¶Êé°Áî®Ê∏õÂ∞ëÁöÑËÖ¶ÈõªÂúñË£ùÁΩÆÔºåÂÖ∂‰∏≠Êé°Áî®‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅÂúñÂΩ¢Ê≥®ÊÑèÂäõÂ±§ÂíåÂÖ®ÈÄ£Êé•Â±§„ÄÇÈô§‰∫ÜËÉΩÂ§†‰ΩøÁî®Ê∏õÂ∞ëÁöÑË£ùÁΩÆÂç≥ÊôÇÂÅµÊ∏¨Áô≤ÁôáÁôº‰ΩúÂ§ñÔºåÊ≠§Ê®°ÂûãÈÇÑÊèê‰æõ‰∫ÜÂç≥ÊôÇÂèØËß£ÈáãÊÄßÁöÑÁç®ÁâπÂÑ™Âã¢„ÄÇÈÄèÈÅéÂú® Zenodo Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® 10 ÂÄç‰∫§ÂèâÈ©óË≠âË©ï‰º∞ÊïàËÉΩÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Êõ≤Á∑ö‰∏ãÈù¢Á©ç (AUC) ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 8.31% Âíå 42.86% ÁöÑÁµïÂ∞çÊîπÂñÑ„ÄÇ

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüüÊ≠£Âø´ÈÄüÂΩ±ÈüøËëóÂÅ•Â∫∑ËàáÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩÜÂ∞çÊñºÈù¢Ëá®Âª£Ê≥õÁµêÊßãÊÄßÂ£ìËø´ÁöÑ‰∫∫Áæ§‰æÜË™™ÔºåÂÅèË¶ãÂíå‰∏çËâØË°®Áèæ‰æùÁÑ∂Â≠òÂú®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Ê∏ÖÊ•öË™™ÊòéÔºåÈúÄË¶ÅÊõ¥Âö¥Ê†ºÂú∞Ê≥®ÊÑèË≥áÊñô‰ª£Ë°®ÊÄßÂíåÊ®°ÂûãÊïàËÉΩÔºå‰ª•‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄß‰∏¶Ê∏õÂ∞ëÂÅèË¶ã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊúâÊ©üÊúÉÈÄèÈÅéÈÅãÁî®Á§æÊúÉÊµÅË°åÁóÖÂ≠∏ÂíåÂÅ•Â∫∑ÂÖ¨Âπ≥ÁöÑÊúÄ‰Ω≥ÂØ¶ÂãôÔºå‰æÜÊîπÂñÑ AI ÁöÑÂèØËß£ÈáãÊÄßÔºå‰ª•Âπ´Âä©ÊàëÂÄëÈáùÂ∞çÁôºÁèæÁöÑÈóúËÅØÊÄßÔºåÁôºÂ±ïÂÅáË®≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂèØËß£Èáã AI (XAI)Ôºå‰∏¶ÊèèËø∞‰∏ÄÂÄãË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂØ©Êü•Êû∂ÊßãÔºå‰ª•ÂæûÂ§öÈáçËßÄÈªûË®éË´ñÂíåÊâπÂà§ÊÄßË©ï‰º∞ AI Ê®°ÂûãÁöÑËß£ÈáãÔºå‰∏¶ÊâæÂá∫ÂÅèË¶ãÈ†òÂüüÂíåÊú™‰æÜÁ†îÁ©∂ÁöÑÊñπÂêë„ÄÇÊàëÂÄëÂº∑Ë™øË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂ∞çÊñºÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖ¨Âπ≥ÁöÑË©ÆÈáãËá≥ÈóúÈáçË¶ÅÔºåËÄåÈÄô‰∫õË©ÆÈáãÊòØÊ†πÊìöÊ≠∑Âè≤ÂíåËÑàÁµ°ËÄå‰æÜÁöÑ„ÄÇË∑®È†òÂüüÂ∞èÁµÑË®éË´ñÊúâÂä©ÊñºÊ∏õÂ∞ëÂÅèË¶ã„ÄÅÊâæÂá∫ÊΩõÂú®ÁöÑÊ∑∑Ê∑ÜÂõ†Á¥†Ôºå‰∏¶Âú®ÊñáÁçª‰∏≠ÊúâÁº∫Âè£ÊôÇÊâæÂá∫È°çÂ§ñÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇÂèçÈÅé‰æÜÔºåÈÄô‰∫õË¶ãËß£ÂèØ‰ª•Âª∫Ë≠∞ AI Ê®°ÂûãÊîπÈÄ≤ÁöÑÊ©üÊúÉ„ÄÇ

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajƒÖc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÂØ¶È©óÂÆ§ÂØ¶È©ó‰∏≠‰∏çÊñ∑Âú∞ËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂåπÊïµÊàñË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÁôºÁèæÊîæÂ∞ÑÁßë AI ÁÇ∫Âü∫Á§éÁ≥ªÁµ±ÁöÑÂØ¶ÈöõÂü∑Ë°åÂπæ‰πéÊ≤íÊúâÊèê‰æõËá®Â∫äÂÉπÂÄº„ÄÇÊú¨ÊñáÊé¢Ë®éÂ¶Ç‰ΩïÁÇ∫ AI Ë®≠Ë®àÂú®‰∏çÂêåÊÉÖÂ¢É‰∏≠Ëá®Â∫ä‰∏äÁöÑÊïàÁî®„ÄÇÊàëÂÄëÊ†πÊìöÂäüËÉΩÊÄß AI ÁÇ∫Âü∫Á§éÂéüÂûãÁöÑ‰∏âÊ¨°Ëø≠‰ª£ÔºåÂú®‰∏πÈ∫•ÂíåËÇØ‰∫ûÁöÑ 7 ÂÄãËá®Â∫äÂ†¥ÂüüËàá 13 ‰ΩçÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°å‰∫Ü 19 Ê¨°Ë®≠Ë®àÊúÉË≠∞ÂíåË®≠Ë®à‰ªãÂÖ•„ÄÇÂçÅÂÄãÁ§æÊúÉÊäÄË°ì‰æùË≥¥Èóú‰øÇË¢´Ë™çÁÇ∫Â∞çÊñºÊîæÂ∞ÑÁßë‰∏≠ AI ÁöÑË®≠Ë®àËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊ¶ÇÂøµÂåñ‰∫ÜÂõõÂÄãÊäÄË°ìÈù¢ÂêëÔºåÂøÖÈ†àÊ†πÊìöÈ†êÊúüÁöÑËá®Â∫ä‰ΩøÁî®ÊÉÖÂ¢ÉÈÄ≤Ë°åË®≠ÂÆöÔºöAI ÂäüËÉΩ„ÄÅAI ÈÜ´ÁôÇÈáçÈªû„ÄÅAI Ê±∫Á≠ñÈñÄÊ™ªÔºå‰ª•Âèä AI ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂõõÈ†ÖË®≠Ë®àÂª∫Ë≠∞ÔºåË™™ÊòéÂ¶Ç‰ΩïËôïÁêÜËàáÈÜ´ÁôÇÁü•Ë≠ò„ÄÅË®∫ÊâÄÈ°ûÂûã„ÄÅ‰ΩøÁî®ËÄÖÂ∞àÊ•≠Áü•Ë≠òÁ≠âÁ¥ö„ÄÅÊÇ£ËÄÖÊÉÖÂ¢ÉÔºå‰ª•ÂèäÂΩ±ÈüøÈÄô‰∫õÊäÄË°ìÈù¢ÂêëË®≠ÂÆöÁöÑ‰ΩøÁî®ËÄÖÊÉÖÂ¢ÉÁõ∏ÈóúÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

ÊëòË¶ÅÔºö<paragraph>ÂàùÁ¥ö‰øùÂÅ•Êèê‰æõËÄÖÂ∞çÊñºÊúÄÂàùÁöÑÂàÜÊµÅÂíåËΩâË®∫Âà∞Â∞àÁßëÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈùíÂÖâÁúºÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁÑ°ÁóáÁãÄ‰∏îÂø´ÈÄüÊÉ°ÂåñÂèØËÉΩÂ∞éËá¥Ë¶ñÂäõÂñ™Â§±ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊôÇËΩâË®∫Áµ¶Â∞àÂÆ∂„ÄÇÁÑ∂ËÄåÔºåÂàùÁ¥öÁúºÁßë‰øùÂÅ•Êèê‰æõËÄÖÂèØËÉΩÁÑ°Ê≥ïË≠òÂà•Á∑äÊÄ•ÊÉÖÊ≥ÅÔºåÂèØËÉΩÊúÉÂª∂Ë™§ÁÖßË≠∑„ÄÇÊèê‰æõËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂèØ‰ª•Âä†Âº∑‰ªñÂÄëÁöÑËΩâË®∫Ê±∫Á≠ñ„ÄÇÊàëÂÄëÁ†îÁ©∂ÂêÑÁ®Æ AI Ëß£ÈáãÂ¶Ç‰ΩïÂπ´Âä©Êèê‰æõËÄÖÂçÄÂàÜÈúÄË¶ÅÁ´ãÂç≥ÊàñÈùûÁ∑äÊÄ•Â∞àÁßëËΩâË®∫ÁöÑÊÇ£ËÄÖ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜËß£ÈáãÊÄß AI ÊºîÁÆóÊ≥ïÔºå‰ª•Âæû‰æãË°åÁúºÁßëË≠∑ÁêÜË≥áÊñôÈ†êÊ∏¨ÈùíÂÖâÁúºÊâãË°ìÈúÄÊ±ÇÔºå‰ΩúÁÇ∫Ë≠òÂà•È´òÈ¢®Èö™ÊÇ£ËÄÖÁöÑ‰ª£ÁêÜ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜÂÖßÂú®Âíå‰∫ãÂæåËß£ÈáãÊÄßÔºå‰∏¶ËàáÈ©óÂÖâÂ∏´ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∑ö‰∏äÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞‰∫∫Ê©üÂúòÈöäÁöÑË°®ÁèæÔºåË°°ÈáèËΩâË®∫Ê∫ñÁ¢∫Â∫¶‰∏¶ÂàÜÊûêËàá AI ÁöÑ‰∫íÂãïÔºåÂåÖÊã¨ÂêåÊÑèÁéá„ÄÅ‰ªªÂãôÊôÇÈñìÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÊÑüÁü•„ÄÇÂú® 87 ÂêçÂèÉËàáËÄÖ‰∏≠ÔºåAI ÊîØÊè¥ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºà‰ΩøÁî® AI/Êú™‰ΩøÁî®ÁöÑÊØî‰æãÁÇ∫ 59.9%/50.8%ÔºâÔºåÂÑòÁÆ°‰∫∫Ê©üÂúòÈöäÁöÑË°®Áèæ‰∏çÂ¶ÇÂñÆÁç®‰ΩøÁî® AI„ÄÇÂèÉËàáËÄÖË™çÁÇ∫‰ªñÂÄëÂú®‰ΩøÁî®ÂÖßÂú®Ê®°ÂûãÊôÇÊõ¥Â§öÂú∞Á¥çÂÖ•‰∫Ü AI Âª∫Ë≠∞Ôºå‰∏¶Ë™çÁÇ∫ÂÆÉÊõ¥ÊúâÁî®‰∏îÊõ¥ÊúâÂ∏åÊúõ„ÄÇÊ≤íÊúâËß£ÈáãÔºåAI Âª∫Ë≠∞ÁöÑÂÅèÂ∑ÆÊúÉÂ¢ûÂä†„ÄÇAI ÊîØÊè¥‰∏¶Êú™Â¢ûÂä†Â∑•‰ΩúÈáè„ÄÅ‰ø°ÂøÉÂíå‰ø°‰ªªÔºå‰ΩÜÊ∏õÂ∞ë‰∫ÜÊåëÊà∞„ÄÇÂú®‰∏ÄÂÄãÂñÆÁç®ÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÈªëÁõíÂ≠êÂíåÂÖßÂú®Ê®°ÂûãÂú®È†êÊ∏¨ÊâãË°ìÁµêÊûúÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 77% Âíå 71% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÊâæÂá∫Âú®ÂàùÁ¥öÁúºÁßë‰øùÂÅ•‰∏≠Ôºå‰∫∫Ê©üÂúòÈöäÂêà‰ΩúÁÆ°ÁêÜÈùíÂÖâÁúºÁöÑÊ©üÊúÉÔºå‰∏¶Ê≥®ÊÑèÂà∞ÈõñÁÑ∂ AI ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂç≥‰ΩøÊúâËß£ÈáãÔºåÂÆÉ‰πüÈ°ØÁ§∫Âá∫ËàáÂñÆÁç®‰ΩøÁî® AI Áõ∏ÊØîÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ‰∫∫È°ûÂèÉËàáÂú®ÈÜ´ÁôÇÊ±∫Á≠ñ‰∏≠‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶ÅÔºåÈÄôÂº∑Ë™ø‰∫ÜÊú™‰æÜÁ†îÁ©∂ÂÑ™ÂåñÂçî‰Ωú„ÄÅÁ¢∫‰øùÊ≠£Èù¢Á∂ìÈ©óÂíåÂÆâÂÖ®‰ΩøÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇ</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

ÊëòË¶ÅÔºöÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÁñæÁóÖÊ™¢Ê∏¨ÂíåÈ†êÂæå‰ªªÂãô‰∏≠ÔºåËæ®Âà• AI Ê®°ÂûãÈ†êÊ∏¨ËÉåÂæåÁöÑÂéüÁêÜÂ∞çÊñºË©ï‰º∞ÂÖ∂Ê±∫Á≠ñÁöÑÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑËß£ÈáãÊñπÊ≥ïÂú®Ë≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰∏≠ÂèØË≠òÂà•ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÂÖ∂‰∏≠ÂçÄÂà•ÊÄßÁâπÂæµÂæàÂæÆÂ¶ôÊàñ‰∏¶‰∏çÊòéÈ°Ø„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂÖ∑ÂÇôÊ±∫Á≠ñÊé®ÁêÜÂíåÁâπÂæµË≠òÂà•ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ™¢Ê∏¨ÊúâÂΩ±ÈüøÂäõÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºåÈÇÑÊè≠Á§∫‰∫ÜÊé®ÂãïÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµ„ÄÇÈÄöÈÅéÂØ¶ÊñΩÊàëÂÄëÁöÑÊ®°ÂûãÔºåÊàëÂÄëÂèØ‰ª•ÊúâÊïàË≠òÂà•ÂíåË¶ñË¶∫ÂåñÁî±Êï∏ÊìöÈ©ÖÂãïÊ®°ÂûãÂà©Áî®ÁöÑÈ°ûÁâπÂÆöÁâπÂæµÔºåÂæûËÄåÊ∑±ÂÖ•‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊ±∫Á≠ñÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®Ë¶ÅÊ±ÇÂö¥Ê†ºÁöÑÈÜ´Â≠∏È†êÂæå‰ªªÂãôÈ†òÂüüÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊèêÈ´ò AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØÈù†ÊÄßÂíåÁôºÁèæÈ†êÂæåÁêÜËß£ÂèóÈôêÁñæÁóÖÁöÑÊñ∞Áü•Ë≠òÊñπÈù¢ÁöÑÂäüÊïàÂíåÊΩõÂäõ„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥Êù•ÔºåÂü∫‰∫éÊú∫Âô®Â≠¶‰π†ÁöÑ‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü (CDSS) Âú®Â§öÁßçÁñæÁóÖÁöÑÂàÜÊûê‰∏≠ÊâÆÊºî‰∫ÜÂÖ≥ÈîÆËßíËâ≤„ÄÇÂ∞ΩÁÆ°ÂÆÉ‰ª¨ÂÖ∑ÊúâÂπøÈòîÁöÑÂâçÊôØÔºå‰ΩÜ AI Ê®°ÂûãÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÂ∞§ÂÖ∂Âú®ÂåªÁñóÈ¢ÜÂüüÔºåÂèØÈù†ÊÄßÊòØÂº∫Âà∂ÊÄßÊñπÈù¢ÔºåËøôÂ∏¶Êù•‰∫ÜÈáçÂ§ßÊåëÊàò„ÄÇÁÑ∂ËÄåÔºåËß£ÈáäÊÄß‰ºº‰πé‰∏éÂáÜÁ°ÆÊÄßÊàêÂèçÊØî„ÄÇÂõ†Ê≠§ÔºåÂú®‰∏çÂΩ±ÂìçÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÊåëÊàò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•ÈÄöËøáÊîæÂ∞ÑÁªÑÂ≠¶ÁöÑÂÜÖÂú®ÂèØËß£ÈáäÊÄßÊù•Â¢ûÂº∫ CNN Ë°çÁîüÁâπÂæÅÁöÑÈ¢ÑÊµãËÉΩÂäõ„ÄÇRad4XCNN ÈÄöËøáÊîæÂ∞ÑÁªÑÂ≠¶Â∞ÜÂèØÁêÜËß£ÁöÑÂê´‰πâ‰∏é CNN Ë°çÁîüÁâπÂæÅÂÖ≥ËÅîËµ∑Êù•Ôºå‰ªéËÄåÂÅèÁ¶ª‰∫ÜÂü∫‰∫éÊòæÁùÄÊÄßÂõæÁöÑ‰º†ÁªüÊñπÊ≥ïÔºå‰∏∫Ë∂ÖË∂äÂèØËßÜÂåñÂõæÁöÑËß£ÈáäÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÜËßí„ÄÇ‰ΩøÁî®‰π≥ËÖ∫ÁôåÂàÜÁ±ª‰ªªÂä°‰Ωú‰∏∫Ê°à‰æãÁ†îÁ©∂ÔºåÊàë‰ª¨Âú®Ë∂ÖÂ£∞ÊàêÂÉèÊï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞‰∫Ü Rad4XCNNÔºåÂåÖÊã¨‰∏Ä‰∏™Âú®Á∫øÊï∞ÊçÆÈõÜÂíå‰∏§‰∏™Áî®‰∫éÂÜÖÈÉ®ÂíåÂ§ñÈÉ®È™åËØÅÁöÑÂÜÖÈÉ®Êï∞ÊçÆÈõÜ„ÄÇ‰∏Ä‰∫õÂÖ≥ÈîÆÁªìÊûúÊòØÔºöi) ‰∏é ViT Ë°çÁîüÂíåÊîæÂ∞ÑÁªÑÂ≠¶ÁâπÂæÅÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæÅ‰øùËØÅ‰∫ÜÊõ¥Á®≥ÂÅ•ÁöÑÂáÜÁ°ÆÊÄßÔºõii) Áî®‰∫éËß£ÈáäÁöÑ‰º†ÁªüÂèØËßÜÂåñÂõæÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN ‰∏ç‰ºö‰∏∫‰∫ÜÂèØËß£ÈáäÊÄßËÄåÁâ∫Áâ≤Ê®°ÂûãÂáÜÁ°ÆÊÄßÔºõiv) Rad4XCNN Êèê‰æõÂÖ®Â±ÄËß£ÈáäÔºå‰ΩøÂåªÁîüËÉΩÂ§üÊèêÂèñÂÖ®Â±ÄËßÅËß£ÂíåÂèëÁé∞„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•ÂáèËΩª‰∏Ä‰∫õ‰∏éÂèØËß£ÈáäÊÄß-ÂáÜÁ°ÆÊÄßÊùÉË°°Áõ∏ÂÖ≥ÁöÑÊãÖÂøß„ÄÇÊú¨Á†îÁ©∂Âº∫Ë∞É‰∫ÜÊèêÂá∫Êñ∞ÊñπÊ≥ïÊù•Ëß£ÈáäÊ®°ÂûãËÄå‰∏çÂΩ±ÂìçÂÖ∂ÂáÜÁ°ÆÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠¶‰π†Ê≠£Â§ßÂπÖËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÁ∑öÂ≠∏È†òÂüüÔºåËÉΩËæ®Ë≠òÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Á¥¢Âº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÁöÑÂèç‰∫ãÂØ¶ÂÖßÊèíÊñπÊ≥ï (COIN)ÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÂ∞áÈ†êÊ∏¨ÁöÑÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÂâáÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÊèíÁï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæó„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖÈÅéÂ∑≤Âª∫Á´ãÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ËÆìÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÁéáÈÇÅÈÄ≤‰∏ÄÊ≠•ÔºåÂÖ∂‰∏≠Ë®ªËß£Ë≥áÊñôÂæàÁ®ÄÂ∞ë„ÄÇ

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊï∏‰Ωç‰∫∫ÊñáÂ≠∏Áßë (DH) ‰ΩúÁÇ∫‰∏ÄÈñÄÂ≠∏ÁßëËàáÊ∑∑ÂêàÊô∫ËÉΩ (HI) ‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂ÂÖ∏ÁØÑ‰πãÈñìÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂú® DH Á†îÁ©∂‰∏≠ÔºåÊï∏‰ΩçÊñπÊ≥ïÁöÑ‰ΩøÁî®ÔºåÁâπÂà•ÊòØ‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰ΩøÁî®ÔºåÂèóÂà∞‰∏ÄÁ≥ªÂàóË¶ÅÊ±ÇÂíåÈôêÂà∂„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õË¶ÅÊ±ÇÂíåÈôêÂà∂Áç≤Âæó HI ÁöÑËÉΩÂäõÂíåÁõÆÊ®ôÁöÑÂÖÖÂàÜÊîØÊåÅ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÊâæÂá∫‰∫îÂÄãÈÄôÊ®£ÁöÑ DH Ë¶ÅÊ±ÇÔºöÊàêÂäüÁöÑ AI Á≥ªÁµ±ÈúÄË¶ÅËÉΩÂ§† 1) ËàáÔºà‰∫∫È°ûÔºâÂ≠∏ËÄÖÂêà‰ΩúÔºõ2) ÊîØÊè¥Ë≥áÊñôÊâπË©ïÔºõ3) ÊîØÊè¥Â∑•ÂÖ∑ÊâπË©ïÔºõ4) ÂØüË¶∫‰∏¶ËøéÂêàÂêÑÁ®ÆËßÄÈªûÔºõ5) ÊîØÊè¥ÈÅ†Ë∑ùÂíåËøëË∑ùÈõ¢Èñ±ËÆÄ„ÄÇÊàëÂÄëÂ∞áÊ∑∑ÂêàÊô∫ËÉΩÁöÑ CARE ÂéüÂâáÔºàÂçî‰Ωú„ÄÅÈÅ©Êáâ„ÄÅË≤†Ë≤¨ÂíåÂèØËß£ÈáãÔºâ‰ΩúÁÇ∫ÁêÜË´ñÊû∂ÊßãÔºå‰∏¶Â∞áÈÄô‰∫õÂéüÂâáÂ∞çÊáâÂà∞ DH Ë¶ÅÊ±Ç„ÄÇÂú®Ê≠§Â∞çÊáâ‰∏≠ÔºåÊàëÂÄëÁ¥çÂÖ•ÁØÑ‰æãÁ†îÁ©∂Â∞àÊ°à„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞á DH ÁöÑË¶ãËß£ÊáâÁî®Êñº HIÔºå‰∏¶Ë®éË´ñÁµêÂêàÈÄôÂÖ©ÂÄãÂ≠∏ÁßëÁöÑÈñãÊîæÊåëÊà∞„ÄÇ

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÂÖ∑ÊúâÂæπÂ∫ïÊîπËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂª£Ê≥õÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÊú¨ÊñáÊó®Âú®Âº∑Ë™øËàá FM Áõ∏ÈóúÁöÑÂÄ´ÁêÜÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊ°ÜÊû∂‰æÜÊåáÂ∞éÂÆÉÂÄëÂú®ÈÜ´Â≠∏‰∏≠ÁöÑË≤†Ë≤¨‰ªªÈñãÁôºÂíåÂØ¶ÊñΩ„ÄÇÊàëÂÄë‰ªîÁ¥∞ÂØ©Êü•‰∫ÜÂÄ´ÁêÜÂïèÈ°åÔºå‰æãÂ¶ÇÊÇ£ËÄÖÊï∏ÊìöÈö±ÁßÅ„ÄÅÂÅèÂ∑ÆÁ∑©Ëß£„ÄÅÊºîÁÆóÊ≥ïÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÂïèË≤¨Âà∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êó®Âú®ÂÑ™ÂÖàËÄÉÊÖÆÊÇ£ËÄÖÁ¶èÂà©„ÄÅÊ∏õËºïÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂüπÈ§äÂ∞ç AI ËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰ø°‰ªª„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊï∏ÊìöËûçÂêàÊñπÊ≥ïÔºåÁî®ÊñºÁñºÁóõË°åÁÇ∫Ë≠òÂà•ÔºåÂ∞áÁµ±Ë®àÁõ∏ÈóúÂàÜÊûêËàá‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑË¶ãËß£Áõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂÖ©È†ÖÈóúÈçµÂâµÊñ∞Ôºö1) Â∞áÊï∏ÊìöÈ©ÖÂãïÁöÑÁµ±Ë®àÁõ∏ÈóúÊ¨äÈáçÊï¥ÂêàÂà∞ËûçÂêàÁ≠ñÁï•‰∏≠Ôºå‰ª•ÊúâÊïàÂà©Áî®‰æÜËá™Áï∞Ë≥™Ê®°ÊÖãÁöÑË£úÂÖÖ‰ø°ÊÅØÔºå‰ª•Âèä 2) Â∞á‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÈÅãÂãïÁâπÂæµÁ¥çÂÖ•Â§öÊ®°ÊÖãË°®Á§∫Â≠∏Áøí‰∏≠Ôºå‰ª•Ë©≥Á¥∞Âª∫Ê®°ÁñºÁóõË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã‰∏≠ÂæóÂà∞È©óË≠âÔºåÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËá™ÂÆöÁæ©ÁöÑÊ°ÜÊû∂ÔºåÊ†πÊìöÁµ±Ë®àÈ°ØËëóÊÄßÂ∞áÊØèÂÄãÊ®°ÊÖãËàáÂêàÈÅ©ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩäÔºåÊé®ÈÄ≤ÂÄãÊÄßÂåñÂíåÊúâÊïàÁöÑÂ§öÊ®°ÊÖãËûçÂêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõÂ∞çÂ§öÊ®°ÊÖãÊï∏ÊìöÁöÑÂèØËß£ÈáãÂàÜÊûêÔºåÊúâÂä©ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØËß£ÈáãÂíåÂèØËß£Èáã AI„ÄÇÈÄöÈÅéÂº∑Ë™øÊï∏ÊìöÂ§öÊ®£ÊÄßÂíåÊ®°ÊÖãÁâπÂÆöË°®Á§∫ÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÇ≥Áµ±ÁöÑËûçÂêàÊäÄË°ìÔºå‰∏¶ÁÇ∫Ë≠òÂà•Ë§áÈõúÁöÑÁñºÁóõË°åÁÇ∫Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞ç‰øÉÈÄ≤‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Âπ≤È†êÂíåÊîØÊåÅÂèØËß£ÈáãÁöÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂÖ∑ÊúâÈáçË¶ÅÊÑèÁæ©„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑Ôºå‰∫ÜËß£ÂÆÉÂÄëÂú®Ëß£Á¢ºÂíåËß£ÈáãË™ûË®ÄÊâÄËòäÂê´ÁöÑË§áÈõúÂõ†ÊûúÈóú‰øÇÁ∂≤Ë∑Ø‰∏≠ÁöÑËÉΩÂäõÂíåÈôêÂà∂ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÊäÄË°ì‰ΩøÁî®ÊòéÁ¢∫ÊàñÈö±Âê´ÁöÑÂõ†ÊûúÊé®ÁêÜÔºå‰ΩÜÂº∑ÁÉàÈúÄË¶Å‰∏ÄÁ®ÆÁµ±‰∏ÄÁöÑÊñπÊ≥ïÔºåÁµêÂêàÂÖ©ËÄÖ‰ª•Êõ¥ÊúâÊïàÂú∞ËôïÁêÜÂª£Ê≥õÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ÊÉÖÂ¢ÉÊÑüÁü•Êé®ÁêÜÂ¢ûÂº∑ËàáÂèç‰∫ãÂØ¶ÂàÜÊûê (CARE CA) Ê°ÜÊû∂ÁöÑÊñ∞Êû∂ÊßãÔºå‰ª•Â¢ûÂº∑Âõ†ÊûúÊé®ÁêÜÂíåÂèØËß£ÈáãÊÄß„ÄÇÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁµêÂêà‰∫Ü‰ΩøÁî® ConceptNet ÂíåÂèç‰∫ãÂØ¶Èô≥Ëø∞ÁöÑÊòéÁ¢∫Âõ†ÊûúÊ™¢Ê∏¨Ê®°ÁµÑÔºå‰ª•ÂèäÈÄèÈÅé LLM ÈÄ≤Ë°åÁöÑÈö±Âê´Âõ†ÊûúÊ™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÂä†ÂÖ•‰∏ÄÂ±§Âèç‰∫ãÂØ¶Ëß£ÈáãÔºå‰ª•Âº∑Ë™ø LLM Â∞çÂõ†ÊûúÈóú‰øÇÁöÑÁêÜËß£„ÄÇ‰æÜËá™ ConceptNet ÁöÑÁü•Ë≠òÂ¢ûÂº∑‰∫ÜÂ§öÈ†ÖÂõ†ÊûúÊé®ÁêÜ‰ªªÂãôÁöÑÂü∑Ë°åÔºå‰æãÂ¶ÇÂõ†ÊûúÁôºÁèæ„ÄÅÂõ†ÊûúË≠òÂà•ÂíåÂèç‰∫ãÂØ¶Êé®ÁêÜ„ÄÇÂèç‰∫ãÂØ¶Âè•Âä†ÂÖ•‰∫ÜÊú™Áî±ÊÉÖÂ¢ÉÈÄ†ÊàêÁöÑÊòéÁ¢∫Áü•Ë≠ò„ÄÇÈÄèÈÅéÁµêÂêàÈÄô‰∫õÂº∑Â§ßÁöÑÊ®°ÁµÑÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊó®Âú®Êèê‰æõÂ∞çÂõ†ÊûúÈóú‰øÇÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£ÔºåÂØ¶ÁèæÂ¢ûÂº∑ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑË©ï‰º∞È°ØÁ§∫Âú®ÊâÄÊúâÊåáÊ®ôÔºà‰æãÂ¶ÇÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºâ‰∏äÈÉΩÊúâÊâÄÊèêÂçá„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü CausalNetÔºå‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÈôÑ‰∏ä‰∫ÜÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºå‰ª•‰øÉÈÄ≤Âú®ÈÄôÂÄãÈ†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>ÊØèÂÄãÂ∞ç‰∫∫ÂÅöÂá∫Ê±∫ÂÆöÁöÑ AI Á≥ªÁµ±ÈÉΩÊúâ‰∏ÄÁæ§Âà©ÂÆ≥Èóú‰øÇ‰∫∫
ÂèóÂà∞ÈÄô‰∫õÊ±∫ÂÆöÁöÑË¶™Ë∫´ÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåAI
Á≥ªÁµ±ÁöÑËß£ÈáãÂæàÂ∞ëËÉΩÊªøË∂≥ÈÄôÁæ§Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑË≥áË®äÈúÄÊ±ÇÔºåËÄå‰ªñÂÄë
ÈÄöÂ∏∏ÈÉΩÊòØ AI Êñ∞Êâã„ÄÇÈÄôÈÄ†Êàê‰∫ÜÂÇ≥ÈÅîË≥áË®äËàá
ÂèóÂà∞Á≥ªÁµ±Ê±∫Á≠ñÂΩ±ÈüøÁöÑ‰∫∫Â£´Ôºà‰æãÂ¶ÇÈ†òÂüüÂ∞àÂÆ∂ÂíåÊ±∫Á≠ñ‰∏ªÈ´îÔºâÈáçË¶ñÁöÑË≥áË®ä‰πãÈñìÁöÑËêΩÂ∑Æ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü
„ÄåXAI Êñ∞ÊâãÂïèÈ°åÂ∫´„ÄçÔºåÂÆÉÊòØ XAI ÂïèÈ°åÂ∫´ÁöÑÂª∂‰º∏ÔºåÂåÖÂê´‰æÜËá™ AI Êñ∞ÊâãÂú®ÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æã‰∏≠ÁöÑË≥áË®äÈúÄÊ±ÇÁõÆÈåÑÔºöÂ∞±Ê•≠
È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Ê∏¨„ÄÇÁõÆÈåÑÊ∂µËìã‰∫ÜË≥áÊñô„ÄÅ
Á≥ªÁµ±ËÉåÊôØ„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÁ≠âÈ°ûÂà•„ÄÇÊàëÂÄëÈÄèÈÅé‰ªªÂãôÂûãË®™Ë´áÊî∂ÈõÜË≥áË®äÈúÄÊ±ÇÔºåÂèÉËàáËÄÖÂú®Ë®™Ë´á‰∏≠Ë©¢Âïè‰∫ÜÂÖ©ÂÄã AI Á≥ªÁµ±ÁöÑÂïèÈ°åÔºå‰ª•Ê±∫ÂÆöÊòØÂê¶Êé°Áî®ÂÆÉÂÄëÔºå‰∏¶Êî∂Âà∞Âè£È†≠
Ëß£Èáã‰ΩúÁÇ∫ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂèÉËàáËÄÖÂú®Êî∂Âà∞Ëß£ÈáãÂæå‰ø°ÂøÉÊúâÊâÄÊèêÂçáÔºå‰ΩÜ‰ªñÂÄëÁöÑÁêÜËß£ÂçªÈù¢Ëá®ÊåëÊà∞„ÄÇÈÄô‰∫õÊåëÊà∞ÂåÖÊã¨Èõ£‰ª•ÊâæÂà∞Ë≥áË®äÂíåË©ï‰º∞Ëá™Â∑±ÁöÑÁêÜËß£Ôºå‰ª•ÂèäË©¶ÂúñÂ§ñÂåÖ
ÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÂÖàÂâçÂõûÈ•ãÂΩ±Èüø‰∫Ü‰ªñÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇË™çÁÇ∫È¢®Èö™È´òÁöÑÂèÉËàáËÄÖÂ∞ãÊ±ÇËß£ÈáãÁ≥ªÁµ±ÈÉ®ÁΩ≤ËÉåÂæåÁöÑÊÑèÂúñÔºåËÄåË™çÁÇ∫È¢®Èö™‰ΩéÁöÑ‰∫∫ÂâáË©¢ÂïèÁ≥ªÁµ±ÁöÑ
Êìç‰Ωú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ÈÄèÈÅéÂº∑Ë™ø AI Êñ∞ÊâãÁöÑË≥áË®äÈúÄÊ±Ç„ÄÅÁõÆÊ®ôÂíå
ÊåëÊà∞Ôºå‰æÜÊîØÊåÅÂ∞á AI Êñ∞ÊâãÁ¥çÂÖ•ÂèØËß£ÈáãÊÄßÂ∑•‰Ωú‰∏≠„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∏ΩÁµêÁÇ∫‰∫îÂÄãÈóúÈçµÂïüÁ§∫ÔºåÈÄô‰∫õÂïüÁ§∫ÂèØ‰ª•ÁÇ∫Êú™‰æÜÈáùÂ∞çÈùûÂ∞àÊ•≠Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèóÁúæÁöÑËß£ÈáãË®≠Ë®àÊèê‰æõÂèÉËÄÉ„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|null|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|null|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v1](http://arxiv.org/abs/2501.08613v1)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-13**|**SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**|Fabien Bernier et.al.|[2501.07639v1](http://arxiv.org/abs/2501.07639v1)|null|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713v2](http://arxiv.org/abs/2501.06713v2)|[link](https://github.com/hkuds/minirag)|
|**2025-01-12**|**Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**|Aidan Hogan et.al.|[2501.06699v1](http://arxiv.org/abs/2501.06699v1)|null|
|**2025-01-11**|**Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**|Mohammed Maree et.al.|[2501.06628v1](http://arxiv.org/abs/2501.06628v1)|null|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v1](http://arxiv.org/abs/2501.06465v1)|null|
|**2025-01-10**|**Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**|Mumin Jia et.al.|[2501.06382v1](http://arxiv.org/abs/2501.06382v1)|null|
|**2025-01-10**|**Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**|Zuyuan Zhang et.al.|[2501.05673v1](http://arxiv.org/abs/2501.05673v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**|Ruijun Feng et.al.|[2501.04510v1](http://arxiv.org/abs/2501.04510v1)|null|
|**2025-01-08**|**S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**|Prashant Verma et.al.|[2501.05485v1](http://arxiv.org/abs/2501.05485v1)|null|
|**2025-01-08**|**Multimodal Graph Constrastive Learning and Prompt for ChartQA**|Yue Dai et.al.|[2501.04303v1](http://arxiv.org/abs/2501.04303v1)|null|
|**2025-01-07**|**Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**|Wen-Dong Jiang et.al.|[2501.06224v1](http://arxiv.org/abs/2501.06224v1)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**|Yubo Wang et.al.|[2501.02844v1](http://arxiv.org/abs/2501.02844v1)|null|
|**2025-01-06**|**KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**|Zaiyi Zheng et.al.|[2501.02711v1](http://arxiv.org/abs/2501.02711v1)|null|
|**2025-01-04**|**Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**|Markus J. Buehler et.al.|[2501.02393v2](http://arxiv.org/abs/2501.02393v2)|[link](https://github.com/lamm-mit/graph-aware-transformers)|
|**2025-01-04**|**What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**|Yutao Jiang et.al.|[2501.02268v1](http://arxiv.org/abs/2501.02268v1)|[link](https://github.com/jytmelon/g-prune)|
|**2025-01-04**|**Personalized Graph-Based Retrieval for Large Language Models**|Steven Au et.al.|[2501.02157v1](http://arxiv.org/abs/2501.02157v1)|[link](https://github.com/pgraphrag-benchmark/pgr-llm)|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v1](http://arxiv.org/abs/2501.01945v1)|[link](https://github.com/yuanchenbei/awesome-cold-start-recommendation)|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|[link](https://github.com/hysonlab/biomedkg)|
|**2025-01-02**|**Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**|Kedi Chen et.al.|[2501.02020v1](http://arxiv.org/abs/2501.02020v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|[link](https://github.com/Alibaba-NLP/CHRONOS)|
|**2025-01-01**|**Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**|Wei Zhang et.al.|[2501.03257v1](http://arxiv.org/abs/2501.03257v1)|null|
|**2025-01-01**|**SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**|Mao Xun Huang et.al.|[2501.01998v1](http://arxiv.org/abs/2501.01998v1)|null|
|**2024-12-31**|**Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**|Yipeng Kang et.al.|[2501.00581v1](http://arxiv.org/abs/2501.00581v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**The Potential of LLMs in Automating Software Testing: From Generation to Reporting**|Betim Sherifi et.al.|[2501.00217v1](http://arxiv.org/abs/2501.00217v1)|null|
|**2024-12-30**|**Detection-Fusion for Knowledge Graph Extraction from Videos**|Taniya Das et.al.|[2501.00136v1](http://arxiv.org/abs/2501.00136v1)|[link](https://github.com/Taniya-Das/video_annotation)|
|**2024-12-30**|**Machine Learning-Based Security Policy Analysis**|Krish Jain et.al.|[2501.00085v2](http://arxiv.org/abs/2501.00085v2)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-29**|**ICLR: In-Context Learning of Representations**|Core Francisco Park et.al.|[2501.00070v1](http://arxiv.org/abs/2501.00070v1)|null|
|**2024-12-28**|**Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**|Minhye Jeon et.al.|[2412.20163v2](http://arxiv.org/abs/2412.20163v2)|null|
|**2024-12-28**|**From Generalist to Specialist: A Survey of Large Language Models for Chemistry**|Yang Han et.al.|[2412.19994v1](http://arxiv.org/abs/2412.19994v1)|[link](https://github.com/opendfm/llm4chemistry)|
|**2024-12-27**|**Toward Adaptive Reasoning in Large Language Models with Thought Rollback**|Sijia Chen et.al.|[2412.19707v1](http://arxiv.org/abs/2412.19707v1)|[link](https://github.com/iQua/llmpebase)|
|**2024-12-26**|**Dynamic Skill Adaptation for Large Language Models**|Jiaao Chen et.al.|[2412.19361v1](http://arxiv.org/abs/2412.19361v1)|null|
|**2024-12-26**|**Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**|Tao Liu et.al.|[2412.19021v1](http://arxiv.org/abs/2412.19021v1)|null|
|**2024-12-25**|**PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**|ChenRui Duan et.al.|[2412.18827v1](http://arxiv.org/abs/2412.18827v1)|null|
|**2024-12-24**|**CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**|Yanlin Feng et.al.|[2412.18702v1](http://arxiv.org/abs/2412.18702v1)|[link](https://github.com/megagonlabs/cypherbench)|
|**2024-12-24**|**From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**|Ratnesh Kumar Joshi et.al.|[2412.18672v1](http://arxiv.org/abs/2412.18672v1)|null|
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu et.al.|[2412.18537v2](http://arxiv.org/abs/2412.18537v2)|[link](https://github.com/Applied-Machine-Learning-Lab/AMAR)|
|**2024-12-24**|**DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**|Karishma Thakrar et.al.|[2412.18644v1](http://arxiv.org/abs/2412.18644v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v2](http://arxiv.org/abs/2412.18260v2)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-23**|**CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**|Ruibo Tu et.al.|[2412.17970v1](http://arxiv.org/abs/2412.17970v1)|[link](https://github.com/turuibo/cautabbench)|
|**2024-12-23**|**Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**|Ge Zhang et.al.|[2412.17963v1](http://arxiv.org/abs/2412.17963v1)|null|
|**2024-12-23**|**ResearchTown: Simulator of Human Research Community**|Haofei Yu et.al.|[2412.17767v1](http://arxiv.org/abs/2412.17767v1)|[link](https://github.com/ulab-uiuc/research-town)|
|**2024-12-23**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690v3](http://arxiv.org/abs/2412.17690v3)|null|
|**2024-12-23**|**A Dual-Perspective Metaphor Detection Framework Using Large Language Models**|Yujie Lin et.al.|[2412.17332v2](http://arxiv.org/abs/2412.17332v2)|[link](https://github.com/deeplearnxmu/dmd)|
|**2024-12-22**|**GraphAgent: Agentic Graph Language Assistant**|Yuhao Yang et.al.|[2412.17029v1](http://arxiv.org/abs/2412.17029v1)|null|
|**2024-12-22**|**Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**|Bohan Jin et.al.|[2412.16922v1](http://arxiv.org/abs/2412.16922v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v2](http://arxiv.org/abs/2412.16833v2)|null|
|**2024-12-21**|**Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**|Christophe Debruyne et.al.|[2412.16766v1](http://arxiv.org/abs/2412.16766v1)|null|
|**2024-12-21**|**Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**|Chao-Chi Chen et.al.|[2412.16533v1](http://arxiv.org/abs/2412.16533v1)|null|
|**2024-12-21**|**Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**|Junyi Ye et.al.|[2412.16420v1](http://arxiv.org/abs/2412.16420v1)|[link](https://github.com/junyiye/textflow)|
|**2024-12-20**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311v1](http://arxiv.org/abs/2412.16311v1)|null|
|**2024-12-20**|**Logical Consistency of Large Language Models in Fact-checking**|Bishwamittra Ghosh et.al.|[2412.16100v1](http://arxiv.org/abs/2412.16100v1)|null|
|**2024-12-20**|**GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**|Heming Zhang et.al.|[2412.15790v1](http://arxiv.org/abs/2412.15790v1)|null|
|**2024-12-20**|**KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**|Xingyu Xiao et.al.|[2412.18627v1](http://arxiv.org/abs/2412.18627v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443v1](http://arxiv.org/abs/2412.15443v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|[link](https://github.com/ml-research/answersetnetworks)|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|[link](https://github.com/mminici/socgfm)|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|
|**2024-12-18**|**Knowledge Editing with Dynamic Knowledge Graphs for Multi-Hop Question Answering**|Yifan Lu et.al.|[2412.13782v2](http://arxiv.org/abs/2412.13782v2)|null|
|**2024-12-18**|**Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**|Zheng Hu et.al.|[2412.13544v1](http://arxiv.org/abs/2412.13544v1)|[link](https://github.com/laowangzi/cikgrec)|
|**2024-12-18**|**Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**|Yingjie Zhu et.al.|[2412.13540v1](http://arxiv.org/abs/2412.13540v1)|[link](https://github.com/aaandy-zhu/vgcure)|
|**2024-12-18**|**Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**|Imam Nur Bani Yusuf et.al.|[2412.13467v1](http://arxiv.org/abs/2412.13467v1)|[link](https://github.com/imamnurby/transducer-tuning)|
|**2024-12-17**|**Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**|Konstantin Zaitsev et.al.|[2412.13283v1](http://arxiv.org/abs/2412.13283v1)|null|
|**2024-12-17**|**SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**|Yuzheng Cai et.al.|[2412.15272v1](http://arxiv.org/abs/2412.15272v1)|[link](https://github.com/YZ-Cai/SimGRAG)|
|**2024-12-17**|**Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**|Ziqi Qiu et.al.|[2412.12808v2](http://arxiv.org/abs/2412.12808v2)|null|
|**2024-12-17**|**AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models**|Haoyi Zhang et.al.|[2412.19824v1](http://arxiv.org/abs/2412.19824v1)|null|
|**2024-12-17**|**LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**|Mufan Xu et.al.|[2412.12643v1](http://arxiv.org/abs/2412.12643v1)|null|
|**2024-12-17**|**SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**|Aman Tiwari et.al.|[2412.12612v1](http://arxiv.org/abs/2412.12612v1)|null|
|**2024-12-17**|**Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**|Yibo Zhao et.al.|[2412.15268v2](http://arxiv.org/abs/2412.15268v2)|null|
|**2024-12-17**|**Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**|Xunkai Li et.al.|[2412.12456v1](http://arxiv.org/abs/2412.12456v1)|null|
|**2024-12-16**|**Graph-Guided Textual Explanation Generation Framework**|Shuzhou Yuan et.al.|[2412.12318v1](http://arxiv.org/abs/2412.12318v1)|null|
|**2024-12-16**|**Cost-Effective Label-free Node Classification with LLMs**|Taiyan Zhang et.al.|[2412.11983v1](http://arxiv.org/abs/2412.11983v1)|null|
|**2024-12-16**|**SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**|Tao Meng et.al.|[2412.11652v1](http://arxiv.org/abs/2412.11652v1)|null|
|**2024-12-16**|**EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**|Nuowei Liu et.al.|[2412.11618v1](http://arxiv.org/abs/2412.11618v1)|null|
|**2024-12-16**|**Embodied CoT Distillation From LLM To Off-the-shelf Agents**|Wonje Choi et.al.|[2412.11499v1](http://arxiv.org/abs/2412.11499v1)|null|

#### Abstracts
##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

ÊëòË¶ÅÔºöËæ®Ë≠òÊùêÊñôÂåñÂ≠∏‰∏≠ÂèØÈù†ÁöÑÂêàÊàêË∑ØÂæëÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑ‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ËÅöÂêàÁâ©ÁßëÂ≠∏‰∏≠ÔºåÂõ†ÁÇ∫Â∑®ÂàÜÂ≠êÁöÑÂëΩÂêçÊ≥ïÈåØÁ∂úË§áÈõú‰∏îÁ∂ìÂ∏∏‰∏çÂîØ‰∏Ä„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁü•Ë≠òÂúñË≠ú (KG) ÁöÑ‰ª£ÁêÜÁ≥ªÁµ±„ÄÇÈÄèÈÅéÂà©Áî® LLM Âº∑Â§ßÁöÑÂåñÂ≠∏Áâ©Ë≥™ÂêçÁ®±ËêÉÂèñÂíåËæ®Ë≠òËÉΩÂäõÔºå‰∏¶Â∞áËêÉÂèñÁöÑË≥áÊñôÂÑ≤Â≠òÂú®ÁµêÊßãÂåñÁöÑÁü•Ë≠òÂúñË≠ú‰∏≠ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂèØÂÆåÂÖ®Ëá™ÂãïÂåñÁõ∏ÈóúÊñáÁçªÁöÑÊ™¢Á¥¢„ÄÅÂèçÊáâË≥áÊñôÁöÑËêÉÂèñ„ÄÅË≥áÊñôÂ∫´Êü•Ë©¢„ÄÅÈÄÜÂêàÊàêË∑ØÂæëÊ®πÁöÑÂª∫Êßã„ÄÅÈÄèÈÅéÊ™¢Á¥¢È°çÂ§ñÊñáÁçªÈÄ≤‰∏ÄÊ≠•Êì¥ÂÖÖÔºå‰ª•ÂèäÊúÄ‰Ω≥ÂèçÊáâË∑ØÂæëÁöÑÂª∫Ë≠∞„ÄÇ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÂàÜÊîØÂèçÊáâË∑ØÂæëÊêúÂ∞ã (MBRPS) ÊºîÁÆóÊ≥ïËÉΩÊé¢Á¥¢ÊâÄÊúâË∑ØÂæëÔºåÁâπÂà•Â∞àÊ≥®ÊñºÂ§öÂàÜÊîØË∑ØÂæëÔºåÂçîÂä© LLM ÂÖãÊúçÂ§öÂàÜÊîØË∑ØÂæë‰∏≠ÁöÑÂº±Êé®ÁêÜ„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ª£Ë°®È¶ñÊ¨°ÂòóË©¶ÈñãÁôº‰∏ÄÁ®ÆÂÆåÂÖ®Ëá™ÂãïÂåñÁöÑÈÄÜÂêàÊàêË¶èÂäÉ‰ª£ÁêÜÔºåÂ∞àÈñÄÈáùÂ∞çÁî± LLM È©ÖÂãïÁöÑÂ∑®ÂàÜÂ≠êÈáèË∫´ÊâìÈÄ†„ÄÇÊáâÁî®ÊñºËÅöÈÜØ‰∫ûËÉ∫ÂêàÊàêÔºåÊàëÂÄëÁöÑÊñ∞ÊñπÊ≥ïÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´Êï∏ÁôæÊ¢ùË∑ØÂæëÁöÑÈÄÜÂêàÊàêË∑ØÂæëÊ®πÔºå‰∏¶Âª∫Ë≠∞ÊúÄ‰Ω≥ÂåñË∑ØÂæëÔºåÂåÖÊã¨Â∑≤Áü•ÂíåÊñ∞Á©éÁöÑË∑ØÂæëÔºåË≠âÊòéÂÖ∂Âú®Êõ¥Âª£Ê≥õÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÂíåÊΩõÂäõ„ÄÇ

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, B√°lint Moln√°r

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Âü∫ÊñºÁõ∏‰ººÂ∫¶ÁöÑÊ®°ÂºèÊØîÂ∞çÊñπÊ≥ïÁÑ°Ê≥ïËß£Ê±∫ÁâπÂÆöÈ†òÂüüË§áÈõúÊØîÂ∞çÂ†¥ÊôØ‰∏≠ÁöÑË™ûÊÑèÊ®°Á≥äÊÄßÂíåË°ùÁ™ÅÔºåÈÄôÊòØÂõ†ÁÇ∫Áº∫‰πèÂ∏∏Ë≠òÂíåÁâπÂÆöÈ†òÂüüÁü•Ë≠ò„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫ÂïèÈ°å‰πü‰ΩøÂæóÂü∫Êñº LLM ÁöÑÊ®°ÂºèÊØîÂ∞çÈõ£‰ª•Ëß£Ê±∫‰∏äËø∞ÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠úÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊ®°ÂûãÔºåÁî®ÊñºÊ®°ÂºèÊØîÂ∞çÔºåÁ®±ÁÇ∫ KG-RAG4SM„ÄÇÂÖ∑È´îËÄåË®ÄÔºåKG-RAG4SM ÂºïÂÖ•‰∫ÜÂü∫ÊñºÂêëÈáèÁöÑ„ÄÅÂü∫ÊñºÂúñÂΩ¢ÈÅçÊ≠∑ÁöÑÂíåÂü∫ÊñºÊü•Ë©¢ÁöÑÂúñÂΩ¢Ê™¢Á¥¢Ôºå‰ª•Âèä‰∏ÄÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÂíåÊéíÂêçÊñπÊ°àÔºåÈÄô‰∫õÊñπÊ°àÂæûÂ§ñÈÉ®Â§ßÂûãÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠Ë≠òÂà•ÊúÄÁõ∏ÈóúÁöÑÂ≠êÂúñ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂü∫Êñº KG ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ LLM ËÉΩÂ§†Âú®‰∏çÈÄ≤Ë°å‰ªª‰ΩïÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÁÇ∫Ë§áÈõúÁöÑÊØîÂ∞çÊ°à‰æãÁîüÊàêÊõ¥Ê∫ñÁ¢∫ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú® MIMIC Ë≥áÊñôÈõÜ‰∏äÔºåKG-RAG4SM Âú®Ê∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÊñπÈù¢ÂàÜÂà•ÊØîÂü∫Êñº LLM ÁöÑÊúÄÊñ∞ (SOTA) ÊñπÊ≥ï (‰æãÂ¶Ç Jellyfish-8B) È´òÂá∫ 35.89% Âíå 30.50%ÔºõÂÖ∑Êúâ GPT-4o-mini ÁöÑ KG-RAG4SM Âú®Ê∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÊñπÈù¢ÂàÜÂà•ÊØîÂü∫ÊñºÈ†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑ SOTA ÊñπÊ≥ï (‰æãÂ¶Ç SMAT) È´òÂá∫ 69.20% Âíå 21.97% Âú® Synthea Ë≥áÊñôÈõÜ‰∏ä„ÄÇÁµêÊûúÈÇÑË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Á´ØÂà∞Á´ØÊ®°ÂºèÊØîÂ∞ç‰∏≠Êõ¥ÊúâÊïàÁéáÔºå‰∏¶‰∏îÂèØ‰ª•Êì¥Â±ïÂà∞ÂæûÂ§ßÂûã KG ‰∏≠Ê™¢Á¥¢„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ÁèæÂØ¶‰∏ñÁïåÊ®°ÂºèÊØîÂ∞çÂ†¥ÊôØÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÊ°à‰æãÁ†îÁ©∂Ë°®ÊòéÔºåÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÂæàÂ•ΩÂú∞Á∑©Ëß£‰∫Ü LLM Âú®Ê®°ÂºèÊØîÂ∞ç‰∏≠ÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇ

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v1 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

ÊëòË¶ÅÔºöÊúÄËøë‰ª•Â∑•ÂÖ∑Â¢ûÂº∫ÂûãÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Ëß£ÂÜ≥ÈÄªËæëÊé®ÁêÜÈóÆÈ¢òÁöÑÊñ∞ÂÖ¥ËåÉ‰æãÂà©Áî®‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÈôàËø∞Âà∞‰∏ÄÈò∂ÈÄªËæë (FOL) ÂíåÂ§ñÈÉ®ÂÆöÁêÜËØÅÊòéÂô®ÁöÑËΩ¨Âåñ„ÄÇÁÑ∂ËÄåÔºåFOL ÈôàËø∞ÁöÑÊ≠£Á°ÆÊÄßÔºàÂåÖÊã¨ÁÆóÂ≠êÂíåÊñáÊú¨Ë∞ìËØçÔºâÈÄöÂ∏∏Âõ†Áº∫‰πèÁî®‰∫éÊØîËæÉÁîüÊàêÁöÑ FOL ÂíåÁúüÂÆû FOL ÁöÑÂèØÈù†ËØÑ‰º∞ÊåáÊ†áËÄåÊó†Ê≥ïÂæóÂà∞È™åËØÅ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂØπÁé∞ÊúâÊåáÊ†áÁöÑÊïèÊÑüÊÄßÂèäÂÖ∂‰∏é‰∫∫Á±ªÂØπ FOL ËØÑ‰º∞Âà§Êñ≠ÁöÑ‰∏ÄËá¥ÊÄßËøõË°å‰∫ÜÂÖ®Èù¢Á†îÁ©∂„ÄÇ‰ΩøÁî®ÁúüÂÆû FOLÔºåÊàë‰ª¨Á≤æÂøÉËÆæËÆ°‰∫ÜÂØπÁúüÂÆû FOL ÁöÑÂêÑÁßçÊâ∞Âä®Êù•ËØÑ‰º∞ÊåáÊ†áÊïèÊÑüÊÄß„ÄÇÊàë‰ª¨ÂØπËá™ÁÑ∂ËØ≠Ë®ÄÈôàËø∞ÊäΩÊ†∑ FOL ÁøªËØëÂÄôÈÄâÔºåÂπ∂ÊµãÈáèËá™Âä®ÊåáÊ†áÂíå‰∫∫Á±ªÊ≥®ÈáäËÄÖ‰πãÈó¥ÁöÑÊéíÂêç‰∏ÄËá¥ÊÄß„ÄÇÊàë‰ª¨ÁöÑÁªèÈ™åÁªìÊûúÁ™ÅÂá∫‰∫Ü n-gram ÊåáÊ†á BLEU ÂØπÊñáÊú¨Êâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß„ÄÅËØ≠‰πâÂõæÊåáÊ†á Smatch++ ÂØπÁªìÊûÑÊâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß‰ª•Âèä FOL ÊåáÊ†áÂØπÁÆóÂ≠êÊâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß„ÄÇÊàë‰ª¨ËøòËßÇÂØüÂà∞ BertScore ‰∏é‰∫∫Á±ªÂà§Êñ≠‰πãÈó¥Êõ¥Á¥ßÂØÜÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ë°®ÊòéÔºå‰∏é‰ΩøÁî®Âçï‰∏™ÊåáÊ†áÁõ∏ÊØîÔºåÁªÑÂêàÊåáÊ†áÂèØ‰ª•ÊèêÈ´ò‰∏ÄËá¥ÊÄßÂíåÊïèÊÑüÊÄß„ÄÇ

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

ÊëòË¶ÅÔºöÈö®Ëëó REST API Âú®Áèæ‰ª£Á∂≤Ë∑ØÊúçÂãô‰∏≠Âª£Ê≥õ‰ΩøÁî®ÔºåÂ∞çÈÄô‰∫õ API ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÊ∏¨Ë©¶ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÁî±ÊñºÂª£Â§ßÁöÑÊêúÂ∞ãÁ©∫ÈñìÂåÖÂê´Êìç‰Ωú„ÄÅÂèÉÊï∏ÂíåÂèÉÊï∏ÂÄº‰ª•ÂèäÂÆÉÂÄëË§áÈõúÁöÑ‰æùË≥¥Èóú‰øÇÂíåÁ¥ÑÊùüÔºåÁõÆÂâçÁöÑÊ∏¨Ë©¶Â∑•ÂÖ∑Â≠òÂú®Á®ãÂºèÁ¢ºË¶ÜËìãÁéá‰ΩéÁöÑÂïèÈ°åÔºåÂ∞éËá¥ÊïÖÈöúÂÅµÊ∏¨‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Â∑•ÂÖ∑ AutoRestTestÔºåÂÆÉÊï¥Âêà‰∫ÜË™ûÁæ©Êìç‰Ωú‰æùË≥¥Âúñ (SODG) ËàáÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ REST API Ê∏¨Ë©¶„ÄÇAutoRestTest ‰ΩøÁî® SODG Á¢∫ÂÆö‰æùË≥¥ÊñºÊìç‰ΩúÁöÑÂèÉÊï∏Ôºå‰∏¶‰ΩøÁî®‰∫îÂÄãÂ∞àÈñÄÁöÑ‰ª£ÁêÜ (Êìç‰Ωú„ÄÅÂèÉÊï∏„ÄÅÂÄº„ÄÅ‰æùË≥¥Èóú‰øÇÂíåÊ®ôÈ†≠) ‰æÜË≠òÂà•Êìç‰ΩúÁöÑ‰æùË≥¥Èóú‰øÇ‰∏¶Áî¢ÁîüÊìç‰ΩúÂ∫èÂàó„ÄÅÂèÉÊï∏ÁµÑÂêàÂíåÂÄº„ÄÇAutoRestTest Êèê‰æõÂëΩ‰ª§Âàó‰ªãÈù¢ÂíåÊåÅÁ∫åÈÅôÊ∏¨ÔºåÂåÖÊã¨ÊàêÂäüÊìç‰ΩúÊ¨°Êï∏„ÄÅÂÅµÊ∏¨Âà∞ÁöÑÂîØ‰∏Ä‰º∫ÊúçÂô®ÈåØË™§ÂíåÁ∂ìÈÅéÊôÇÈñì„ÄÇÂÆåÊàêÂæåÔºåAutoRestTest ÊúÉÁî¢Áîü‰∏Ä‰ªΩË©≥Á¥∞Â†±ÂëäÔºåÈáçÈªûË™™ÊòéÂÅµÊ∏¨Âà∞ÁöÑÈåØË™§ÂíåÂü∑Ë°åÁöÑÊìç‰Ωú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÊàëÂÄëÁöÑÂ∑•ÂÖ∑‰∏¶ÊèêÂá∫ÂàùÊ≠•ÁµêÊûú„ÄÇ

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ‰ΩéÁß©ÈÅ©Êáâ (LoRA) ÊñπÊ≥ïÁî±ÊñºÁÑ°Ê≥ïÁ∂≠ÊåÅÁ®ÄÁñèÊÄßÔºåÂú®Á®ÄÁñèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏äÈù¢Ëá®ÊåëÊà∞„ÄÇÊúÄËøëÁöÑ‰ΩúÂìÅÂºïÂÖ•‰∫ÜÈÄèÈÅé‰ΩøÁî®È°çÂ§ñÁöÑÈÅÆÁΩ©Ê©üÂà∂‰æÜÊì¥ÂÖÖ LoRA ÊäÄË°ìÁöÑÊñπÊ≥ï‰æÜÁ∂≠ÊåÅÁ®ÄÁñèÊÄß„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÊàêÂäüÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÊúÉÂ¢ûÂä†Ë®òÊÜ∂È´îÂíåÈÅãÁÆóÁöÑÈñãÈä∑ÔºåÈÄôÊúÉÂΩ±Èüø LoRA ÊñπÊ≥ïÁöÑÊïàÁéá„ÄÇÁÇ∫‰∫ÜÂõûÊáâÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü LoRSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Âú®ÂæÆË™øÁ®ÄÁñè LLM ÊôÇÂêåÊôÇÂØ¶ÁèæË®òÊÜ∂È´îÂíåÈÅãÁÆóÊïàÁéá„ÄÇÁÇ∫‰∫ÜÊ∏õËºïËàáÁ∂≠ÊåÅÁ®ÄÁñèÊÄßÁõ∏ÈóúÁöÑÈæêÂ§ßË®òÊÜ∂È´îÂíåÈÅãÁÆóÈúÄÊ±ÇÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêà‰∫ÜÊ¨äÈáçÈáçÊñ∞Ë®àÁÆóÂíåË®àÁÆóÂúñÂΩ¢ÈáçÊñ∞ÊéíÂàóÁöÑÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÈÄèÈÅéÊõ¥Â•ΩÁöÑÈÅ©ÈÖçÂô®ÂàùÂßãÂåñ‰æÜÊèêÈ´ò LoRS ÁöÑÊúâÊïàÊÄß„ÄÇÈÄô‰∫õÂâµÊñ∞Âú®ÂæÆË™øÈöéÊÆµÈ°ØËëóÊ∏õÂ∞ë‰∫ÜË®òÊÜ∂È´îÂíåÈÅãÁÆóÊ∂àËÄóÔºåÂêåÊôÇÂØ¶Áèæ‰∫ÜÂÑ™ÊñºÁèæÊúâ LoRA ÊñπÊ≥ïÁöÑÊïàËÉΩÁ≠âÁ¥ö„ÄÇ

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

ÊëòË¶ÅÔºöÂú®Ê©üÂô®Â≠∏ÁøíÁöÑÁï∂‰ª£ÔºåTransformer Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆÈ†òÂüüÁöÑ‰∫ãÂØ¶Ê®ôÊ∫ñÊñπÊ≥ïÔºå‰æãÂ¶ÇÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂü∫Êñº Transformer ÁöÑËß£Ê±∫ÊñπÊ°àÊòØÁï∂ÂâçË™ûË®ÄÁîüÊàê„ÄÅÂΩ±ÂÉèÂíåÂΩ±ÁâáÂàÜÈ°û„ÄÅÂàÜÂâ≤„ÄÅÂãï‰ΩúÂíåÁâ©‰ª∂Ëæ®Ë≠òÁ≠âÊúÄÊñ∞ÊñπÊ≥ïÁöÑÈ™®Âππ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÈõñÁÑ∂ÈÄô‰∫õÊúÄÊñ∞ÊñπÊ≥ïÂú®ÂÖ∂ÂêÑËá™ÁöÑÈ†òÂüü‰∏≠Áî¢Áîü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁµêÊûúÔºå‰ΩÜÁêÜËß£Ë¶ñË¶∫ÂíåË™ûË®Ä‰πãÈñìÈóú‰øÇÁöÑÂïèÈ°å‰ªçÁÑ∂Ë∂ÖÂá∫‰∫ÜÊàëÂÄëÁöÑÁêÜËß£ÁØÑÂúç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ª•ÂèØËß£Èáã‰∏î‰ª•Á®ãÂºèÁÇ∫Âü∫Á§éÁöÑÊñπÂºèÔºåÂú®ÊôÇÁ©∫‰∏≠ÁöÑ‰∫ã‰ª∂‰πãÈñìÊèêÂá∫‰∫ÜË¶ñË¶∫ÂíåË™ûË®ÄÁöÑÂÖ±ÂêåÂü∫Á§éÔºå‰ª•ÈÄ£Êé•Âü∫ÊñºÂ≠∏ÁøíÁöÑË¶ñË¶∫ÂíåË™ûË®ÄÊúÄÊñ∞Ê®°ÂûãÔºå‰∏¶Êèê‰æõÊèèËø∞ÂΩ±ÁâáÁöÑËá™ÁÑ∂Ë™ûË®ÄÈï∑ÊúüÂïèÈ°åÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïËÉΩÂ§†Âú®ÂæûÂêÑÁ®ÆË≥áÊñôÈõÜÊî∂ÈõÜÁöÑÂΩ±Áâá‰∏≠Áî¢ÁîüÈÄ£Ë≤´„ÄÅË±êÂØå‰∏îÁõ∏ÈóúÁöÑÊñáÂ≠óÊèèËø∞ÔºåÂêåÊôÇ‰ΩøÁî®Ê®ôÊ∫ñÊåáÊ®ôÔºà‰æãÂ¶Ç Bleu„ÄÅROUGEÔºâÂíåÁèæ‰ª£ LLM ‰ΩúÁÇ∫Ë©ïÂØ©ÊñπÊ≥ï„ÄÇ

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

ÊëòË¶ÅÔºö<paragraph>ËøΩÊ±ÇËá™ÂãïÂåñÁßëÂ≠∏ÁôºÁèæÂ∑≤Á∂ìÊé®Âãï‰∫ÜÂæûÁ¨¶ËôüÈÇèËºØÂà∞Áèæ‰ª£ AI ÁöÑÈÄ≤Â±ïÔºåÂú®Êé®ÁêÜÂíåÊ®°ÂºèË≠òÂà•‰∏≠ÈñãÈó¢‰∫ÜÊñ∞ÁöÑÈ†òÂüü„ÄÇTransformer ‰ΩúÁÇ∫ÊΩõÂú®Á≥ªÁµ±ÈÅã‰ΩúÔºåÂÖ∂‰∏≠ÊØèÁ®ÆÂèØËÉΩÁöÑÈóú‰øÇÈÉΩ‰øùÊåÅÊΩõÂú®ÊΩõÂäõÔºåÁõ¥Âà∞‰ªªÂãôÊñΩÂä†Á¥ÑÊùüÔºåÈ°û‰ººÊñºÊ∏¨Èáè„ÄÇÁÑ∂ËÄåÔºåÂÑ™ÂåñÂÖ∂Êé°Ê®£ÈúÄË¶ÅÁöÑ‰∏çÂè™ÊòØÊ©üÁéáÈÅ∏ÊìáÔºöËß£Ê±∫ÊñπÊ°àÂøÖÈ†àÁ¨¶ÂêàÁâπÂÆöÁµêÊßãÊàñË¶èÂâáÔºå‰ª•Á¢∫‰øù‰∏ÄËá¥ÊÄß‰∏¶ÂëºÊáâ‰∏ÄËà¨ÂéüÂâá„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü Graph-PReFLexORÔºàÂü∫ÊñºÂúñÂΩ¢ÁöÑÂü∫ÊñºÂÅèÂ•ΩÁöÑÈÅûËø¥Ë™ûË®ÄÂª∫Ê®°ÔºåÁî®ÊñºÊé®ÁêÜÁöÑÊé¢Á¥¢ÊÄßÂÑ™ÂåñÔºâÔºå‰∏ÄÂÄãÂ∞áÂúñÂΩ¢Êé®ÁêÜËàáÁ¨¶ËôüÊäΩË±°Áõ∏ÁµêÂêà‰ª•ÂãïÊÖãÊì¥Â±ïÈ†òÂüüÁü•Ë≠òÁöÑÊ°ÜÊû∂„ÄÇÂèóÂº∑ÂåñÂ≠∏ÁøíÁöÑÂïüÁôºÔºåGraph-PReFLexOR Â∞áÊé®ÁêÜÂÆöÁæ©ÁÇ∫ÁµêÊßãÂåñÂ∞çÊáâÔºå‰ªªÂãôÁî¢ÁîüÁü•Ë≠òÂúñÂΩ¢„ÄÅÊäΩË±°Ê®°Âºè‰ª•ÂèäÊúÄÁµÇÁ≠îÊ°à„ÄÇÂèóÁØÑÁñáË´ñÁöÑÂïüÁôºÔºåÂÆÉÂ∞áÊ¶ÇÂøµÁ∑®Á¢ºÁÇ∫ÁØÄÈªûÔºåÂ∞áÂÆÉÂÄëÁöÑÈóú‰øÇÁ∑®Á¢ºÁÇ∫ÈÇäÁ∑£ÔºåÈÄöÈÅéÂêåÊßãË°®Á§∫ÊîØÊåÅÈöéÂ±§ÂºèÊé®Ë´ñÂíåËá™ÈÅ©ÊáâÂ≠∏Áøí„ÄÇÁ§∫ÁØÑÂåÖÊã¨ÂÅáË®≠ÁîüÊàê„ÄÅÊùêÊñôË®≠Ë®àÂíåÂâµÈÄ†ÊÄßÊé®ÁêÜÔºå‰æãÂ¶ÇÁôºÁèæÁ•ûË©±Ê¶ÇÂøµÔºàÂ¶Ç„ÄåËñÑÂº±Èªû„ÄçÔºâËàáÊùêÊñôÁßëÂ≠∏‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ„ÄåÁü•Ë≠òËä±ÂúíÊàêÈï∑„ÄçÁ≠ñÁï•ÔºåÂÆÉÊï¥Âêà‰∫ÜË∑®È†òÂüüÁöÑË¶ãËß£Ôºå‰øÉÈÄ≤‰∫ÜË∑®Â≠∏ÁßëÁöÑËÅØÁπ´„ÄÇ‰ΩøÁî® 30 ÂÑÑÂèÉÊï∏ Graph-PReFLexOR Ê®°ÂûãÁöÑÁµêÊûúÈ°ØÁ§∫Âá∫ÂÑ™Áï∞ÁöÑÊé®ÁêÜÊ∑±Â∫¶ÂíåÈÅ©ÊáâÊÄßÔºåÂº∑Ë™ø‰∫ÜÈÄèÊòé„ÄÅÂ§öÂ≠∏Áßë AI È©ÖÂãïÁôºÁèæÁöÑÊΩõÂäõ„ÄÇÂÆÉÁÇ∫ÈÄöÁî®ÁöÑËá™‰∏ªÊé®ÁêÜËß£Ê±∫ÊñπÊ°àÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ</paragraph>

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊàêÂäüÔºõÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Êé®ÁêÜ‰ªªÂãô‰∏≠‰ªçÊúÉÈÅáÂà∞ÊåëÊà∞ÔºåÈÄô‰∫õ‰ªªÂãôÈúÄË¶ÅÁêÜËß£ÂíåÊé®Ë´ñÊñáÂ≠óÂ∫èÂàó‰∏≠‰∏çÂêåË≥áË®äÁâáÊÆµ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÈÄôÂÄãÊåëÊà∞Âú®Ê∂âÂèäÂ§öÊ≠•È©üÁ®ãÂ∫èÁöÑ‰ªªÂãô‰∏≠ÁâπÂà•ÊòéÈ°ØÔºå‰æãÂ¶ÇÈÇèËºØÊé®ÁêÜÂíåÂ§öË∑≥ÂïèÈ°åËß£Á≠îÔºåÂÖ∂‰∏≠ÁêÜËß£ÂØ¶È´î‰πãÈñìÁöÑÈö±Âê´Èóú‰øÇ‰∏¶Âà©Áî®Áµ¶ÂÆöËÑàÁµ°‰∏≠ÁöÑÂ§öË∑≥ÈÄ£Êé•Ëá≥ÈóúÈáçË¶Å„ÄÇÂúñÂΩ¢‰ΩúÁÇ∫Âü∫Êú¨ÁöÑË≥áÊñôÁµêÊßãÔºåÊòéÁ¢∫Ë°®Á§∫ÂØ¶È´î‰πãÈñìÊàêÂ∞çÁöÑÈóú‰øÇÔºåÂæûËÄåÊèê‰æõÂ¢ûÂº∑ LLM Êé®ÁêÜËÉΩÂäõÁöÑÊΩõÂäõ„ÄÇÂ§ñÈÉ®ÂúñÂΩ¢Â∑≤Ë¢´Ë≠âÊòéÂèØ‰ª•ÊúâÊïàÊîØÊè¥ LLM Âü∑Ë°åÂ§öÈ†Ö‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÊé®ÁêÜ‰ªªÂãô‰∏≠Ôºå‰∏¶Ê≤íÊúâÊèê‰æõÈ†êÂÖàÂ≠òÂú®ÁöÑÂúñÂΩ¢ÁµêÊßã„ÄÇÊàëÂÄëËÉΩÂ∞áÂæûËÑàÁµ°‰∏≠Ë°çÁîüÁöÑÈö±Âê´Áü•Ë≠òÁµêÊßãÊàêÂúñÂΩ¢Ôºå‰ª•ÂçîÂä© LLM ÈÄ≤Ë°åÊé®ÁêÜÂóéÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰ΩøÁî®ÂúñÂΩ¢ÈÄ≤Ë°åÊé®ÁêÜ (RwG)ÔºåÊñπÊ≥ïÊòØÈ¶ñÂÖàÂæûËÑàÁµ°‰∏≠Âª∫ÊßãÊòéÁ¢∫ÁöÑÂúñÂΩ¢ÔºåÁÑ∂ÂæåÂà©Áî®ÈÄô‰∫õÂúñÂΩ¢‰æÜÂ¢ûÂº∑ LLM Âú®Êé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑÊé®ÁêÜÊïàËÉΩ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÊîπÈÄ≤ÈÇèËºØÊé®ÁêÜÂíåÂ§öË∑≥ÂïèÈ°åËß£Á≠î‰ªªÂãôÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÈ©ÖÂãïÁöÑÂ§ö‰ª£ÁêÜÊû∂ÊßãÂ∑≤Âú®Ëá™ÂãïÂåñË¶èÂäÉÂíå‰ªªÂãôÂü∑Ë°å‰∏≠Â±ïÁèæÂá∫Â∑®Â§ßÁöÑÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåÂú®Âü∑Ë°åÊúüÈñìÊúâÊïàË™øÊï¥‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ãÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂„ÄÇÊúâÊïàÁöÑÂ∑•‰ΩúÊµÅÁ®ãË™øÊï¥Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫Âú®Ë®±Â§öÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÔºåÂàùÂßãË®àÁï´ÂøÖÈ†àÂç≥ÊôÇË™øÊï¥‰ª•ÊáâÂ∞çÁÑ°Ê≥ïÈ†êË¶ãÁöÑÊåëÊà∞Âíå‰∏çÊñ∑ËÆäÂåñÁöÑÊ¢ù‰ª∂Ôºå‰ª•Á¢∫‰øùË§áÈõú‰ªªÂãôÁöÑÊúâÊïàÂü∑Ë°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÂ∑•‰ΩúÊµÅÁ®ãÂÆöÁæ©ÁÇ∫È†ÇÈªû‰∏äÁöÑÊ¥ªÂãïÔºàAOVÔºâÂúñÂΩ¢„ÄÇÊàëÂÄëÊ†πÊìöÊ≠∑Âè≤Á∏æÊïàÂíåÂÖàÂâçÁöÑ AOV Ëàá LLM ‰ª£ÁêÜÔºåÈÄèÈÅéÂãïÊÖãË™øÊï¥‰ªªÂãôÂàÜÈÖçÔºåÊåÅÁ∫åÂÑ™ÂåñÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÁ≥ªÁµ±ÊïàËÉΩÔºåÊàëÂÄëÂº∑Ë™øÂü∫ÊñºÊ∏¨Èáè‰∏¶Ë°åÊÄßÂíå‰æùË≥¥Ë§áÈõúÊÄßÁöÑÂ∑•‰ΩúÊµÅÁ®ãË®≠Ë®à‰∏≠ÁöÑÊ®°ÁµÑÂåñ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÂ§ö‰ª£ÁêÜÊû∂ÊßãÈÅîÂà∞‰∫ÜÊúâÊïàÂ≠ê‰ªªÂãô‰∏¶Ë°åÂü∑Ë°å„ÄÅÁõÆÊ®ôÈÅîÊàêÂíåÂÆπÈåØ„ÄÇË∑®‰∏çÂêåÂØ¶Èöõ‰ªªÂãôÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòéÔºåÈÄèÈÅéÂãïÊÖãÂ∑•‰ΩúÊµÅÁ®ãÊõ¥Êñ∞ÂíåÊ®°ÁµÑÂåñÔºåÂ§ö‰ª£ÁêÜÊû∂ÊßãÁöÑÊïàÁéáÊúâ‰∫ÜÈ°ØËëóÁöÑÊèêÂçá„ÄÇ

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂ÂÑ™Áï∞ÁöÑÊÄßËÉΩÔºåÂú®ÂêÑÂÄãÈ†òÂüü‰∏≠ÂºïËµ∑‰∫ÜË®±Â§öÈóúÊ≥®ÔºåÁõÆÊ®ôÊòØË®ìÁ∑¥Êï∏ÂÑÑÊàñÊõ¥Â§öÂèÉÊï∏Ôºå‰ª•ÁêÜËß£ÂíåÁî¢ÁîüÂ§ßÈáèÊñáÊú¨Ë≥áÊñô‰∏≠ÁöÑËá™ÁÑ∂Ë™ûË®Ä„ÄÇÈö®Ëëó LLM ÂÑ™Áï∞ÊÄßËÉΩÁöÑÈ°ØÁèæÔºåÂÆÉÂÄëÊ≠£Ë∂ä‰æÜË∂äÂª£Ê≥õÂú∞ÊáâÁî®ÊñºÁü•Ë≠òÂúñË≠úÂµåÂÖ• (KGE) Áõ∏Èóú‰ªªÂãôÔºå‰ª•ÊîπÂñÑËôïÁêÜÁµêÊûú„ÄÇ‰ΩúÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüü‰∏≠ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÂÆÉÂ≠∏ÁøíÂ§ßÈáèÁöÑÊñáÊú¨Ë≥áÊñôÔºå‰ª•È†êÊ∏¨‰∏ã‰∏ÄÂÄãÂñÆÂ≠óÊàñÁî¢ÁîüËàáÁµ¶ÂÆöÊñáÊú¨Áõ∏ÈóúÁöÑÂÖßÂÆπ„ÄÇÁÑ∂ËÄåÔºåÊ†πÊìö‰ªªÂãôÁâπÊÄßÔºåLLM ÊúÄËøëÂ∑≤Âú®‰∏çÂêåÈ°ûÂûãÁöÑ KGE Áõ∏ÈóúÂ†¥ÊôØÔºà‰æãÂ¶ÇÂ§öÊ®°ÊÖã KGE ÂíåÈñãÊîæÂºè KGEÔºâ‰∏≠‰ª•‰∏çÂêåÁ®ãÂ∫¶Ë¢´Êé°Áî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂú®‰∏çÂêåÈ°ûÂûãÁöÑ KGE Â†¥ÊôØ‰∏≠Âü∑Ë°åËàá LLM Áõ∏Èóú‰ªªÂãôÁöÑÂêÑÁ®ÆÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊõ¥Â•ΩÂú∞ÊØîËºÉÂêÑÁ®ÆÊñπÊ≥ïÔºåÊàëÂÄëÂú®ÂàÜÈ°û‰∏≠Á∏ΩÁµê‰∫ÜÊØèÂÄã KGE Â†¥ÊôØ„ÄÇÈô§‰∫ÜÂàÜÈ°ûÊñπÊ≥ï‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÊñπÊ≥ïÂèäÂÖ∂ÂéüÂßãÁ¢ºÈÄ£ÁµêÁöÑË°®Ê†ºÊ¶ÇËßÄÔºå‰ª•‰æøÈÄ≤Ë°åÊõ¥Áõ¥Êé•ÁöÑÊØîËºÉ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜÈÄô‰∫õÊñπÊ≥ï‰∏ªË¶ÅÁî®ÊñºÂì™‰∫õÊáâÁî®Ôºå‰∏¶Âª∫Ë≠∞‰∫ÜÂπæÂÄãÈÄôÂÄãÊñ∞Á†îÁ©∂È†òÂüüÁôºÂ±ïÁöÑÂâçÁûªÊÄßÊñπÂêë„ÄÇ

##### **SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**
2501.07639v1 by Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi

Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.

ÊëòË¶ÅÔºöÂú®ÈõªÂäõÁ≥ªÁµ±‰∏≠ÊúâÊïàËß£Ê±∫ÊúÄ‰Ω≥ÈõªÂäõÊµÅ (OPF) ÂïèÈ°åÂ∞çÊñºÈÅãÁáüË¶èÂäÉÂíåÈõªÁ∂≤ÁÆ°ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÂ∞çÊñºËÉΩÂ§†ËôïÁêÜÁèæ‰ª£ÈõªÂäõÁ∂≤Ë∑Ø‰∏≠Êó•ÁõäÂ¢ûÂä†ÁöÑÂèØËÆäÊÄß„ÄÅÁ¥ÑÊùüÂíå‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂèØÊì¥ÂÖÖÊºîÁÆóÊ≥ïÔºåÂêåÊôÇÊèê‰æõÊ∫ñÁ¢∫‰∏îÂø´ÈÄüÁöÑËß£Ê±∫ÊñπÊ°àÔºåÈúÄÊ±ÇËàáÊó•‰ø±Â¢û„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÁâπÂà•ÊòØÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤ÊàêÁÇ∫ÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÊú¨‰ø°‰ªãÁ¥π‰∫Ü SafePowerGraph-LLMÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊòéÁ¢∫Ë®≠Ë®àÁî®Êñº‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëß£Ê±∫ OPF ÂïèÈ°åÁöÑÊ°ÜÊû∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁµêÂêà‰∫ÜÈõªÂäõÁ∂≤Ë∑ØÁöÑÂúñÂΩ¢ÂíåË°®Ê†ºË°®Á§∫Ôºå‰ª•ÊúâÊïàÊü•Ë©¢ LLMÔºåÊçïÊçâÈõªÂäõÁ≥ªÁµ±‰∏≠ÁöÑË§áÈõúÈóú‰øÇÂíåÁ¥ÑÊùü„ÄÇÂºïÂÖ•‰∫ÜÈáùÂ∞ç LLM ÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíÂíåÂæÆË™øÂçîÂÆöÁöÑÊñ∞ÂØ¶‰ΩúÔºåÂ∞àÈñÄÈáùÂ∞ç OPF ÂïèÈ°åÈáèË∫´ÊâìÈÄ†„ÄÇSafePowerGraph-LLM ‰ΩøÁî®ÁèæÊàêÁöÑ LLM Â±ïÁ§∫‰∫ÜÂèØÈù†ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫Ü LLM Êû∂Êßã„ÄÅÂ§ßÂ∞èÂíåÂæÆË™øÁöÑÂΩ±ÈüøÔºå‰∏¶Â±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ°ÜÊû∂ËôïÁêÜÁèæÂØ¶ÈõªÁ∂≤ÁµÑÊàêÂíåÁ¥ÑÊùüÁöÑËÉΩÂäõ„ÄÇ

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

ÊëòË¶ÅÔºö<paragraph>Âú®Â§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÁï∂ÂâçÁôºÂ±ï‰∏≠ÔºåÁ¢∫‰øùÂü∫Á§éÊï∏Êìö‰æÜÊ∫êÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÈùûÂ∏∏ÈáçË¶Å„ÄÇLLM Â∞çÊñºÂêÑÁ®ÆÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºË®ìÁ∑¥Êï∏Êìö‰∏≠ÁöÑÁü•Ë≠òÂ∑ÆË∑ùÔºåÂÆÉÂÄëÁ∂ìÂ∏∏ÊúÉÂá∫ÁèæÂπªË¶∫Âíå‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÁü•Ë≠òÂúñË≠ú (KG) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÁµêÊßãÂåñÂ∑•ÂÖ∑ÔºåÂèØ‰ª•‰ΩúÁÇ∫‰∏ÄÂÄãÈáçË¶ÅÁöÑÂ§ñÈÉ®‰ø°ÊÅØ‰æÜÊ∫êÔºå‰ª•Ê∏õËºï‰∏äËø∞ÂïèÈ°å„ÄÇÈÄöÈÅéÊèê‰æõÂ∞çÁèæÂØ¶‰∏ñÁïåÊï∏ÊìöÁöÑÁµêÊßãÂåñÂíåÂÖ®Èù¢ÁêÜËß£ÔºåKG ÊèêÈ´ò‰∫Ü LLM ÁöÑÊÄßËÉΩÂíåÂèØÈù†ÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ÂæûÈùûÁµêÊßãÂåñÊï∏Êìö‰∏≠ÊèêÂèñ‰∏âÂÖÉÁµÑ‰ª•ÊßãÂª∫ KG ÊôÇÔºåKG ‰∏≠Â≠òÂú®ÈåØË™§ÊòØÂæàÂ∏∏Ë¶ãÁöÑ„ÄÇÈÄôÂèØËÉΩÊúÉÂ∞éËá¥‰∏ãÊ∏∏‰ªªÂãôÔºà‰æãÂ¶ÇÂïèÁ≠îÂíåÊé®Ëñ¶Á≥ªÁµ±ÔºâÁöÑÊÄßËÉΩ‰∏ãÈôç„ÄÇÂõ†Ê≠§ÔºåKG ‰∏≠ÁöÑÁï∞Â∏∏Ê™¢Ê∏¨Â∞çÊñºË≠òÂà•ÂíåÁ≥æÊ≠£ÈÄô‰∫õÈåØË™§Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÈõôÈÄöÈÅìÂ≠∏ÁøíÁöÑÁü•Ë≠òÂúñË≠úÁï∞Â∏∏Ê™¢Ê∏¨ÁÆóÊ≥ï (ADKGD)„ÄÇADKGD Âà©Áî®ÈõôÈÄöÈÅìÂ≠∏ÁøíÊñπÊ≥ïÂæûÂØ¶È´îË¶ñËßíÂíå‰∏âÂÖÉÁµÑË¶ñËßíÂ¢ûÂº∑Ë°®Á§∫Â≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂‰ΩøÁî®Ë∑®Â±§ÊñπÊ≥ïÊï¥Âêà‰∫ÜÂÖßÈÉ®‰ø°ÊÅØËÅöÂêàÂíå‰∏ä‰∏ãÊñá‰ø°ÊÅØËÅöÂêà„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü Kullback-Leibler (KL) ÊêçÂ§±ÁµÑ‰ª∂Ôºå‰ª•ÊèêÈ´òÈõôÈÄöÈÅì‰πãÈñìË©ïÂàÜÂáΩÊï∏ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ ADKGD ÁöÑÊÄßËÉΩÔºåÊàëÂÄëÂ∞ç‰∏âÂÄãÁúüÂØ¶‰∏ñÁïå KGÔºöWN18RR„ÄÅFB15K Âíå NELL-995 ÈÄ≤Ë°å‰∫ÜÂØ¶Ë≠âÁ†îÁ©∂„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåADKGD ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁï∞Â∏∏Ê™¢Ê∏¨ÁÆóÊ≥ï„ÄÇÊ∫ê‰ª£Á¢ºÂíåÊï∏ÊìöÈõÜÂèØÂú® https://github.com/csjywu1/ADKGD ÂÖ¨ÈñãÁç≤Âæó„ÄÇ</paragraph>

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ΩøÁî®Ëá™Ë®ÇË™ûË®ÄÊ®°ÂûãÂàÜÊûê‰∫Ü 1980 Âπ¥Ëá≥ 2023 Âπ¥Ë∂ÖÈÅé 44,000 ‰ªΩ NBER Âíå CEPR Â∑•‰ΩúË´ñÊñáÔºå‰ª•Âª∫ÊßãÁü•Ë≠òÂúñË≠úÔºåÂ∞çÁ∂ìÊøüÊ¶ÇÂøµÂèäÂÖ∂Èóú‰øÇÈÄ≤Ë°åÂ∞çÊáâ„ÄÇÊàëÂÄëÂçÄÂàÜ‰∏ÄËà¨ÊÄßË´ñËø∞ÂíåÈÄèÈÅéÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÔºà‰æãÂ¶Ç DiD„ÄÅIV„ÄÅRDD„ÄÅRCTÔºâË®òÈåÑÁöÑË´ñËø∞„ÄÇÊàëÂÄëË®òÈåÑÂà∞Âõ†ÊûúË´ñËø∞ÁöÑ‰ªΩÈ°çÂ§ßÂπÖ‰∏äÂçáÔºåÂæû 1990 Âπ¥ÁöÑÁ¥Ñ 4% ‰∏äÂçáÂà∞ 2020 Âπ¥ÁöÑËøë 28%ÔºåÂèçÊò†‰∫Ü„ÄåÂèØ‰ø°Â∫¶Èù©ÂëΩ„ÄçÁöÑÂΩ±ÈüøÂäõÊó•ÁõäÂ¢ûÂº∑„ÄÇÊàëÂÄëÁôºÁèæÂõ†ÊûúÊïòËø∞ÁöÑË§áÈõúÊÄßÔºà‰æãÂ¶ÇÂõ†ÊûúÈèàÁöÑÊ∑±Â∫¶ÔºâÂº∑ÁÉàÈ†êÊ∏¨‰∫ÜÂú®È†ÇÂ∞ñ 5 Â§ßÊúüÂàäÁöÑÁôºË°®ÂíåËºÉÈ´òÁöÑÂºïÁî®Ê¨°Êï∏ÔºåËÄåÈùûÂõ†ÊûúË§áÈõúÊÄßÂâáÂæÄÂæÄËàáÈÄô‰∫õÁµêÊûúÁÑ°ÈóúÊàñÂëàË≤†Áõ∏Èóú„ÄÇÊñ∞Á©éÊÄßÂ∞çÊñºÈ†ÇÂ∞ñ 5 Â§ßÊúüÂàäÁöÑÁôºË°®‰πüËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂâçÊèêÊòØÂª∫Á´ãÂú®ÂèØ‰ø°ÁöÑÂõ†ÊûúÊñπÊ≥ïÁöÑÂü∫Á§é‰∏äÔºöÂºïÂÖ•ÁúüÊ≠£Êñ∞ÁöÑÂõ†ÊûúÈÇäÁ∑£ÊàñË∑ØÂæëÈ°ØËëóÂ¢ûÂä†‰∫ÜÂú®È†ÇÂ∞ñÂ™íÈ´î‰∏äË¢´Êé•ÂèóÁöÑÂèØËÉΩÊÄßÂíåÈï∑ÊúüÂºïÁî®ÔºåËÄåÈùûÂõ†ÊûúÊñ∞Á©éÊÄßÂâáË°®ÁèæÂá∫ÂæÆÂº±ÁîöËá≥Ë≤†Èù¢ÁöÑÂΩ±Èüø„ÄÇÊé¢Ë®é‰∏≠ÂøÉ„ÄÅÂª£Ê≥õË™çÂèØÁöÑÊ¶ÇÂøµÁöÑË´ñÊñáÂæÄÂæÄÊúÉÂê∏ÂºïÊõ¥Â§öÂºïÁî®ÔºåÁ™ÅÈ°ØÂá∫Êé®ÂãïÁôºË°®ÊàêÂäüÂíåÈï∑ÊúüÂ≠∏Ë°ìÂΩ±ÈüøÁöÑÂõ†Á¥†‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÊúÄÂæåÔºåÂ°´Ë£úÊé¢Á¥¢‰∏çË∂≥ÁöÑÊ¶ÇÂøµÂ∞çÊôÇÔºå‰∏ªË¶ÅÊòØÂª∫Á´ãÂú®Âõ†ÊûúÊñπÊ≥ïÁöÑÂü∫Á§é‰∏äÔºå‰ΩÜÈÄôÁ®ÆÂ∑ÆË∑ùÂ°´Ë£ú‰∏¶Êú™Ë°®ÁèæÂá∫ËàáÊú™‰æÜÂºïÁî®ÁöÑ‰∏ÄËá¥ÈóúËÅØ„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊñπÊ≥ïË´ñÂö¥Ë¨πÊÄßÂíåÂõ†ÊûúÂâµÊñ∞ÊòØÂ≠∏Ë°ìË™çÂèØÁöÑ‰∏ªË¶ÅÈ©ÖÂãïÂäõÔºå‰ΩÜÊåÅÁ∫åÁöÑÂΩ±ÈüøÂèØËÉΩÈúÄË¶ÅÂπ≥Ë°°Êñ∞Á©éË≤¢ÁçªËàáËûçÂÖ•Êó¢ÂÆöÁöÑÁ∂ìÊøüË´ñËø∞‰∏≠ÁöÑÊ¶ÇÂøµÊï¥Âêà„ÄÇ</paragraph>

##### **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**
2501.06713v2 by Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang

The growing demand for efficient and lightweight Retrieval-Augmented
Generation (RAG) systems has highlighted significant challenges when deploying
Small Language Models (SLMs) in existing RAG frameworks. Current approaches
face severe performance degradation due to SLMs' limited semantic understanding
and text processing capabilities, creating barriers for widespread adoption in
resource-constrained scenarios. To address these fundamental limitations, we
present MiniRAG, a novel RAG system designed for extreme simplicity and
efficiency. MiniRAG introduces two key technical innovations: (1) a
semantic-aware heterogeneous graph indexing mechanism that combines text chunks
and named entities in a unified structure, reducing reliance on complex
semantic understanding, and (2) a lightweight topology-enhanced retrieval
approach that leverages graph structures for efficient knowledge discovery
without requiring advanced language capabilities. Our extensive experiments
demonstrate that MiniRAG achieves comparable performance to LLM-based methods
even when using SLMs while requiring only 25\% of the storage space.
Additionally, we contribute a comprehensive benchmark dataset for evaluating
lightweight RAG systems under realistic on-device scenarios with complex
queries. We fully open-source our implementation and datasets at:
https://github.com/HKUDS/MiniRAG.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÈ´òÊïà‰∏îËºïÈáèÂåñÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÈúÄÊ±ÇÁöÑÂ¢ûÈï∑ÔºåÂú®ÁèæÊúâ RAG Êû∂Êßã‰∏≠ÈÉ®ÁΩ≤Â∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) ÊôÇÁ™ÅÈ°Ø‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÁî±Êñº SLM ÁöÑË™ûÁæ©ÁêÜËß£ÂíåÊñáÂ≠óËôïÁêÜËÉΩÂäõÊúâÈôêÔºåÁõÆÂâçÁöÑÂÅöÊ≥ïÈù¢Ëá®Âö¥ÈáçÁöÑÊïàËÉΩ‰∏ãÈôçÔºåÁÇ∫Âú®Ë≥áÊ∫êÂèóÈôêÁöÑÊÉÖÊ≥Å‰∏ãÂª£Ê≥õÊé°Áî®Ë£ΩÈÄ†‰∫ÜÈöúÁ§ô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊ†πÊú¨ÊÄßÁöÑÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MiniRAGÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫Ê•µËá¥Á∞°ÊΩîÂíåÊïàÁéáËÄåË®≠Ë®àÁöÑÊñ∞Âûã RAG Á≥ªÁµ±„ÄÇMiniRAG Â∞éÂÖ•‰∫ÜÂÖ©È†ÖÈóúÈçµÊäÄË°ìÂâµÊñ∞Ôºö(1) ‰∏ÄÁ®ÆË™ûÁæ©ÊÑüÁü•Áï∞Ë≥™ÂúñÂΩ¢Á¥¢ÂºïÊ©üÂà∂ÔºåÂÆÉÂ∞áÊñáÂ≠óÂçÄÂ°äÂíåÂëΩÂêçÂØ¶È´îÁµêÂêàÂú®‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÁµêÊßã‰∏≠ÔºåÊ∏õÂ∞ë‰∫ÜÂ∞çË§áÈõúË™ûÁæ©ÁêÜËß£ÁöÑ‰æùË≥¥Ôºå‰ª•Âèä (2) ‰∏ÄÁ®ÆËºïÈáèÁ¥öÊãìÊí≤Â¢ûÂº∑Ê™¢Á¥¢ÊñπÊ≥ïÔºåÂÆÉÂà©Áî®ÂúñÂΩ¢ÁµêÊßãÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÁü•Ë≠òÁôºÁèæÔºåËÄå‰∏çÈúÄË¶ÅÈÄ≤ÈöéÁöÑË™ûË®ÄËÉΩÂäõ„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÂç≥‰ΩøÂú®‰ΩøÁî® SLM ÊôÇÔºåMiniRAG ‰πüËÉΩÈÅîÂà∞ËàáÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÂè™ÈúÄË¶Å 25% ÁöÑÂÑ≤Â≠òÁ©∫Èñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÔºåÁî®ÊñºÂú®ÂÖ∑ÊúâË§áÈõúÊü•Ë©¢ÁöÑÂØ¶ÈöõË£ùÁΩÆÊÉÖÊ≥Å‰∏ãË©ï‰º∞ËºïÈáèÁ¥ö RAG Á≥ªÁµ±„ÄÇÊàëÂÄëÂú® https://github.com/HKUDS/MiniRAG ‰∏äÂÆåÂÖ®ÈñãÊ∫êÊàëÂÄëÁöÑÂØ¶‰ΩúÂíåË≥áÊñôÈõÜ„ÄÇ

##### **Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**
2501.06699v1 by Aidan Hogan, Xin Luna Dong, Denny Vrandeƒçiƒá, Gerhard Weikum

Much has been discussed about how Large Language Models, Knowledge Graphs and
Search Engines can be combined in a synergistic manner. A dimension largely
absent from current academic discourse is the user perspective. In particular,
there remain many open questions regarding how best to address the diverse
information needs of users, incorporating varying facets and levels of
difficulty. This paper introduces a taxonomy of user information needs, which
guides us to study the pros, cons and possible synergies of Large Language
Models, Knowledge Graphs and Search Engines. From this study, we derive a
roadmap for future research.

ÊëòË¶ÅÔºöÂ∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÁü•Ë≠òÂúñË≠úÂíåÊêúÂ∞ãÂºïÊìéÂ¶Ç‰ΩïËÉΩ‰ª•ÂçîÂêåÁöÑÊñπÂºèÁµêÂêàÔºåÂ∑≤Á∂ìÊúâË®±Â§öË®éË´ñ„ÄÇÁõÆÂâçÂ≠∏Ë°ìË´ñËø∞‰∏≠ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂøΩÁï•‰∫Ü‰∏ÄÂÄãÈù¢ÂêëÔºåÈÇ£Â∞±ÊòØ‰ΩøÁî®ËÄÖÁöÑËßÄÈªû„ÄÇÁâπÂà•ÊòØÔºåÈóúÊñºÂ¶Ç‰ΩïÊúÄÂ•ΩÂú∞ÊªøË∂≥‰ΩøÁî®ËÄÖÂ§öÂÖÉÁöÑË≥áË®äÈúÄÊ±ÇÔºå‰∏¶Á¥çÂÖ•‰∏çÂêåÈù¢ÂêëÂíåÈõ£Â∫¶Â±§Á¥öÔºå‰ªçÊúâË®±Â§öÊú™Ëß£Ê±∫ÁöÑÂïèÈ°å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄã‰ΩøÁî®ËÄÖË≥áË®äÈúÄÊ±ÇÁöÑÂàÜÈ°ûÊ≥ïÔºåÂºïÂ∞éÊàëÂÄëÁ†îÁ©∂Â§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÁü•Ë≠òÂúñË≠úÂíåÊêúÂ∞ãÂºïÊìéÁöÑÂÑ™Áº∫ÈªûÂíåÂèØËÉΩÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂæûÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË°çÁîüÂá∫Êú™‰æÜÁ†îÁ©∂ÁöÑË∑ØÁ∑öÂúñ„ÄÇ

##### **Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**
2501.06628v1 by Mohammed Maree

This paper introduces a neuro-symbolic approach for relational exploration in
cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for
explanation generation and a novel mathematical framework to quantify the
interestingness of relationships. We demonstrate the importance of
interestingness measure using a quantitative analysis, by highlighting its
impact on the overall performance of our proposed system, particularly in terms
of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked
Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of
0.68, and an F1-score of 0.69, representing an improvement compared to
graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based
baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our
LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),
ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline
approaches. We show a strong correlation (0.65) between interestingness measure
and the quality of generated explanations, validating its effectiveness. The
findings highlight the importance of LLMs and a mathematical formalization for
interestingness in enhancing the effectiveness of relational exploration in
cultural heritage knowledge graphs, with results that are measurable and
testable. We further show that the system enables more effective exploration
compared to purely knowledge-based and graph-based methods.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÔºåÁî®ÊñºÊñáÂåñÈÅ∫Áî¢Áü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÈóú‰øÇÊé¢Á¥¢ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åËß£ÈáãÁîüÊàêÔºå‰∏¶Âà©Áî®‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊï∏Â≠∏Ê°ÜÊû∂‰æÜÈáèÂåñÈóú‰øÇÁöÑË∂£Âë≥ÊÄß„ÄÇÊàëÂÄëÈÄèÈÅéÂÆöÈáèÂàÜÊûêÂ±ïÁ§∫‰∫ÜË∂£Âë≥ÊÄßÊ∏¨ÈáèÁöÑÈáçË¶ÅÊÄßÔºåÂº∑Ë™øÂÆÉÂ∞çÊàëÂÄëÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Êï¥È´îÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂú®Á≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢„ÄÇ‰ΩøÁî® Wikidata ÊñáÂåñÈÅ∫Áî¢ÈÄ£ÁµêÈñãÊîæË≥áÊñô (WCH-LOD) Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢Áîü‰∫Ü 0.70 ÁöÑÁ≤æÁ¢∫Â∫¶„ÄÅ0.68 ÁöÑÂè¨ÂõûÁéáÂíå 0.69 ÁöÑ F1 ÂàÜÊï∏ÔºåËàáÂü∫ÊñºÂúñÂΩ¢ (Á≤æÁ¢∫Â∫¶Ôºö0.28„ÄÅÂè¨ÂõûÁéáÔºö0.25„ÄÅF1 ÂàÜÊï∏Ôºö0.26) ÂíåÂü∫ÊñºÁü•Ë≠òÁöÑÂü∫Á∑ö (Á≤æÁ¢∫Â∫¶Ôºö0.45„ÄÅÂè¨ÂõûÁéáÔºö0.42„ÄÅF1 ÂàÜÊï∏Ôºö0.43) Áõ∏ÊØîÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄ≤Ê≠•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁî± LLM ‰øÉÊàêÁöÑËß£ÈáãÂ±ïÁèæÂá∫Êõ¥Â•ΩÁöÑÂìÅË≥™ÔºåÂèçÊò†Âú® BLEU (0.52)„ÄÅROUGE-L (0.58) Âíå METEOR (0.63) ÂàÜÊï∏‰∏äÔºåÈÉΩÈ´òÊñºÂü∫Á∑öÊñπÊ≥ï„ÄÇÊàëÂÄëÈ°ØÁ§∫‰∫ÜË∂£Âë≥ÊÄßÊ∏¨ÈáèÂíåÁî¢ÁîüÁöÑËß£ÈáãÂìÅË≥™‰πãÈñìÂº∑ÁÉàÁöÑÁõ∏ÈóúÊÄß (0.65)ÔºåÈ©óË≠â‰∫ÜÂÆÉÁöÑÊúâÊïàÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫Ü LLM ÂíåË∂£Âë≥ÊÄßÁöÑÊï∏Â≠∏ÂΩ¢ÂºèÂåñÂú®Â¢ûÂº∑ÊñáÂåñÈÅ∫Áî¢Áü•Ë≠òÂúñË≠ú‰∏≠Èóú‰øÇÊé¢Á¥¢ÁöÑÊúâÊïàÊÄßÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÔºåÂÖ∂ÁµêÊûúÊòØÂèØ‰ª•Ë°°ÈáèÂíåÊ∏¨Ë©¶ÁöÑ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë°®ÊòéÔºåËàáÁ¥îÁ≤πÂü∫ÊñºÁü•Ë≠òÂíåÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåË©≤Á≥ªÁµ±ËÉΩÈÄ≤Ë°åÊõ¥ÊúâÊïàÁöÑÊé¢Á¥¢„ÄÇ

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v1 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁÇ∫‰∏≠ÊñáÈÜ´ÁôÇÁ§æÁæ§ÂºïÈÄ≤ÂÖ®ÁêÉÈ¶ñÂÄãËá®Â∫äË°ìË™ûÔºåÂç≥ MedCTÔºå‰∏¶ÈôÑÊúâËá®Â∫äÂü∫Á§éÊ®°Âûã MedBERT ÂíåÂØ¶È´îÈÄ£ÁµêÊ®°Âûã MedLink„ÄÇMedCT Á≥ªÁµ±ËÉΩÊ®ôÊ∫ñÂåñ‰∏¶‰ª•Á®ãÂºèÂåñÊñπÂºèÂëàÁèæ‰∏≠ÊñáËá®Â∫äË≥áÊñôÔºåÈÄ≤ËÄåÂà∫ÊøÄÊñ∞Ëó•Áâ©„ÄÅÊ≤ªÁôÇÈÄîÂæëÁöÑÈñãÁôºÔºå‰∏¶ÁÇ∫‰∫∫Âè£ÁúæÂ§öÁöÑËèØ‰∫∫Á§æÁæ§Â∏∂‰æÜÊõ¥Â•ΩÁöÑÈÜ´ÁôÇÁµêÊûú„ÄÇÊ≠§Â§ñÔºåMedCT Áü•Ë≠òÂúñË≠úÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂéüÂâáÊÄßÁöÑÊ©üÂà∂ÔºåÁî®‰ª•ÊúÄÂ∞èÂåñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫ÂïèÈ°åÔºåÂõ†Ê≠§Âú®Âü∫Êñº LLM ÁöÑËá®Â∫äÊáâÁî®‰∏≠ÂØ¶Áèæ‰∫ÜÈ°ØËëóÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÈÄèÈÅéÂà©Áî® LLM Âú®ÁîüÊàêÊÄßÂíåË°®ÈÅîÊÄßÊñπÈù¢ÁöÑÈ°ØËëóËÉΩÂäõÔºåÊàëÂÄëÂæó‰ª•Âø´ÈÄüÂª∫Êßã‰∏ÄÂÄãÁîüÁî¢ÂìÅË≥™ÁöÑË°ìË™ûÁ≥ªÁµ±Ôºå‰∏¶Âú®‰∏âÂÄãÊúàÂÖßÈÉ®ÁΩ≤Âà∞ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÈ†òÂüüÔºåËÄåÂÉè SNOMED CT Á≠âÂÇ≥Áµ±Ë°ìË™ûÂ∑≤Ê≠∑Á∂ì‰∫åÂçÅÂ§öÂπ¥ÁöÑÁôºÂ±ï„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåMedCT Á≥ªÁµ±Âú®Ë™ûÊÑèÈÖçÂ∞çÂíåÂØ¶È´îÈÄ£Áµê‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊïàËÉΩÔºå‰∏çÂÉÖÈÅ©Áî®Êñº‰∏≠ÊñáÔºå‰πüÈÅ©Áî®ÊñºËã±Êñá„ÄÇÊàëÂÄëÈÇÑÈÄèÈÅéÂú®ÂÖ∑‰ª£Ë°®ÊÄßÁöÑËá®Â∫ä‰ªªÂãôÁØÑÂúç‰∏≠ÊáâÁî® MedCT Âíå LLM ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∏±ÂêëÂØ¶Âú∞ÂØ¶È©óÔºåÂåÖÊã¨ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Ëá™ÂãïÁîüÊàêÂíåÁî®ÊñºË®∫Êñ∑Ê±∫Á≠ñÁöÑÈÜ´ÁôÇÊñá‰ª∂ÊêúÂ∞ã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ MedCT Â∞çËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÂíåÊÇ£ËÄÖÁµêÊûúÂÖ∑ÊúâÂ§öÈáçÂÉπÂÄºÔºåÁâπÂà•ÊòØÂú®Êñ∞È°ûÂûãÁöÑËá®Â∫ä LLM ÊáâÁî®‰∏≠„ÄÇÊàëÂÄë‰ª•ÂÖÖÂàÜÁöÑÂ∑•Á®ãÁ¥∞ÁØÄÂëàÁèæÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂõ†Ê≠§ÂØ¶‰ΩúÂÖ∂‰ªñÈùûËã±Ë™ûÁ§æÊúÉÁöÑËá®Â∫äË°ìË™ûÊáâÊòìÊñºË§áË£Ω„ÄÇÊàëÂÄëÈñãÊîæÁôºÂ∏ÉÊàëÂÄëÁöÑË°ìË™û„ÄÅÊ®°ÂûãÂíåÊºîÁÆóÊ≥ïÔºå‰ª•ÂèäÁî®ÊñºÈñãÁôºÁöÑÁèæÂØ¶‰∏ñÁïåËá®Â∫äË≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**
2501.06382v1 by Mumin Jia, Jairo Diaz-Rodriguez

Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change occurs only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling "spontaneous" conversations more
naturally. To our knowledge, this is the first work to address these questions
in such close relation to human conversation and thought.

ÊëòË¶ÅÔºö‰∫∫È°ûË™çÁü•ÂèØ‰ª•Ëá™ÁôºÂú∞ËΩâÊèõÂ∞çË©±‰∏ªÈ°åÔºåÈÄöÂ∏∏ÊòØÁî±ÊÉÖÁ∑íÊàñË™ûÂ¢É‰ø°ËôüËß∏Áôº„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂü∫ÊñºËá™ÊàëÊ≥®ÊÑèÂäõÁöÑË™ûË®ÄÊ®°Âûã‰æùË≥¥ÊñºËº∏ÂÖ•Á¨¶ËôüÁöÑÁµêÊßãÂåñÁµ±Ë®àÁ∑öÁ¥¢‰æÜÈ†êÊ∏¨‰∏ã‰∏ÄÂÄãÁ¨¶ËôüÔºåÁº∫‰πèÈÄôÁ®ÆËá™ÁôºÊÄß„ÄÇÂèóÈÄôÁ®ÆÂçÄÂà•ÁöÑÂïüÁôºÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂΩ±Èüø‰∏ã‰∏ÄÂÄãÁ¨¶ËôüÈ†êÊ∏¨‰ª•ÊîπËÆäËº∏ÂÖ•Â∫èÂàó‰∏ªÈ°åÁöÑÂõ†Á¥†„ÄÇÊàëÂÄëÊ†πÊìöÂ∞á‰∏ªÈ°åÂÆöÁæ©ÁÇ∫‰∏ÄÁµÑÁ¨¶ËôüÂÑ™ÂÖàÁ¥öÂúñÔºàTPGÔºâ‰æÜÂÆöÁæ©‰∏ªÈ°åÈÄ£Á∫åÊÄß„ÄÅÊ≠ßÁæ©Â∫èÂàóÂíå‰∏ªÈ°åËÆäÂåñÁöÑÊ¶ÇÂøµ„ÄÇ‰ΩøÁî®Á∞°ÂåñÁöÑÂñÆÂ±§Ëá™Ê≥®ÊÑèÂäõÊû∂ÊßãÔºåÊàëÂÄëÊé®Â∞éÂá∫‰∏ªÈ°åËÆäÂåñÁöÑÂàÜÊûêÁâπÂæµ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠âÊòéÔºà1ÔºâÊ®°ÂûãÁ∂≠Ë≠∑ËàáËº∏ÂÖ•‰∏ªÈ°åÁõ∏ÈóúÁöÑÁ¨¶ËôüÁöÑÂÑ™ÂÖàÈ†ÜÂ∫èÔºåÔºà2ÔºâÂè™ÊúâÁï∂ËºÉ‰ΩéÂÑ™ÂÖàÈ†ÜÂ∫èÁöÑÁ¨¶ËôüÂ§öÊñºËº∏ÂÖ•‰∏ªÈ°åÁöÑÊâÄÊúâËºÉÈ´òÂÑ™ÂÖàÈ†ÜÂ∫èÁöÑÁ¨¶ËôüÊôÇÔºåÊâçÊúÉÁôºÁîü‰∏ªÈ°åËÆäÂåñÔºå‰ª•ÂèäÔºà3ÔºâËàá‰∫∫È°ûË™çÁü•‰∏çÂêåÔºåËºÉÈï∑ÁöÑ‰∏ä‰∏ãÊñáÈï∑Â∫¶ÂíåÈáçÁñäÁöÑ‰∏ªÈ°åÊúÉÈôç‰ΩéËá™ÁôºÈáçÂÆöÂêëÁöÑÂèØËÉΩÊÄß„ÄÇÈÄô‰∫õË¶ãËß£Á™ÅÂá∫‰∫Ü‰∫∫È°ûË™çÁü•ÂíåÂü∫ÊñºËá™Ê≥®ÊÑèÂäõÁöÑÊ®°ÂûãÂú®ÊáâÂ∞ç‰∏ªÈ°åËÆäÂåñÊôÇÁöÑÂ∑ÆÁï∞Ôºå‰∏¶Âº∑Ë™ø‰∫ÜÂú®Ë®≠Ë®àËÉΩÂ§†Êõ¥Ëá™ÁÑ∂Âú∞ËôïÁêÜ„ÄåËá™Áôº„ÄçÂ∞çË©±ÁöÑÂ∞çË©±Âºè AI ÊôÇÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ¶ÇÊ≠§ÂØÜÂàáÂú∞Ëàá‰∫∫È°ûÂ∞çË©±ÂíåÊÄùÁ∂≠Áõ∏ÈóúÂú∞Êé¢Ë®éÈÄô‰∫õÂïèÈ°åÁöÑÁ†îÁ©∂„ÄÇ

##### **Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**
2501.05673v1 by Zuyuan Zhang, Vaneet Aggarwal, Tian Lan

Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÊúçÂãôË∂ä‰æÜË∂äÈÄèÈÅéËÄÉÊÖÆ‰∏≤ÈÄ£ÁöÑËôõÊì¨Á∂≤Ë∑ØÂäüËÉΩÂíåÁõ∏ÈóúÊµÅÈáèÈÄ≤Ë°åÁÆ°ÁêÜÔºåÁ®±ÁÇ∫ÊúçÂãôÂäüËÉΩÈèà (SFC)„ÄÇÁÇ∫‰∫Ü‰ª•Á∑ö‰∏äÊñπÂºèËôïÁêÜ SFC ÁöÑÈ†ÜÂ∫èÂà∞ÈÅîÔºåÊàëÂÄëÂøÖÈ†àËÄÉÊÖÆÂÖ©ÂÄãÁ∑äÂØÜÁµêÂêàÁöÑÂïèÈ°åÔºöÂ∞á SFC Â∞çÊáâÂà∞Á∂≤Ë∑Ø‰∏≠ÁöÑ‰º∫ÊúçÂô®/ÈÄ£ÁµêÁöÑ SFC ÈÖçÁΩÆÂïèÈ°åÔºå‰ª•ÂèäÊ±∫ÂÆöÊØèÂÄã SFC ‰ΩïÊôÇÂü∑Ë°åÁöÑ SFC ÊéíÁ®ãÂïèÈ°å„ÄÇÂêåÊôÇÈáùÂ∞çÈÄôÂÖ©ÂÄãÊúÄ‰Ω≥Âåñ‰æÜËß£Ê±∫Êï¥ÂÄã SFC ÂïèÈ°åÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ê¢ù‰ª∂ÁîüÊàêÊ®°ÂûãÁöÑÂâµÊñ∞Á∂≤Ë∑ØÊì¥Êï£Âô®ÔºåÁî®ÊñºÊ≠§ SFC ÈÖçÁΩÆÊéíÁ®ãÊúÄ‰Ω≥Âåñ„ÄÇÁîüÊàêÂºè AI ÂíåÊì¥Êï£Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøÂæóÂæûË™ûË®ÄÊèèËø∞‰∏≠Áî¢ÁîüÈ´òÂìÅË≥™ÁöÑÂΩ±ÂÉè/ÂΩ±ÁâáÂíåÊ±∫Á≠ñËªåË∑°ÊàêÁÇ∫ÂèØËÉΩ„ÄÇÊàëÂÄëÂ∞á SFC ÊúÄ‰Ω≥ÂåñÂà∂ÂÆöÁÇ∫Áî¢Áîü‰∏ÄÂÄãÁãÄÊÖãÂ∫èÂàóÁöÑÂïèÈ°åÔºåÁî®ÊñºË¶èÂäÉÔºå‰∏¶Â∞çÁãÄÊÖãËªåË∑°Âü∑Ë°åÂúñÂΩ¢Êì¥Êï£Ôºå‰ª•ÊèêÂèñ SFC Ê±∫Á≠ñÔºå‰∏¶‰ª• SFC ÊúÄ‰Ω≥ÂåñÁ¥ÑÊùüÂíåÁõÆÊ®ô‰ΩúÁÇ∫Ê¢ù‰ª∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Áî±Êñº NP Èõ£Â∫¶Âíå SFC ÊúÄ‰Ω≥ÂåñÁöÑÊåáÊï∏ÂïèÈ°åÁ©∫ÈñìËÄåÂ∞éËá¥ÁöÑÁ§∫ÁØÑË≥áÊñô‰∏çË∂≥ÔºåÊàëÂÄë‰πüÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞‰∏îÊúâÈªûÁâπÁ´ãÁç®Ë°åÁöÑÂÅöÊ≥ïÔºö‰∏çÊòØËß£Ê±∫ÈÄôÂÄãÂõ∞Èõ£ÊúÄ‰Ω≥ÂåñÁöÑÂØ¶‰æãÔºåËÄåÊòØÂæûÈö®Ê©üÁî¢ÁîüÁöÑËß£‰ΩúÁÇ∫Ëº∏ÂÖ•ÈñãÂßãÔºåÁÑ∂ÂæåÊ±∫ÂÆöÈÅ©Áï∂ÁöÑ SFC ÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºåËÆìÈÄô‰∫õËß£ÂèØË°å„ÄÇÈÄôÂÄãÈÄÜÂêëÁ§∫ÁØÑËÆìÊàëÂÄëËÉΩÂ§†ÈÄèÈÅéÈÄ≤‰∏ÄÊ≠•ÊúÄ‰Ω≥ÂåñÔºåÁç≤ÂæóË∂≥Â§†ÁöÑÂ∞àÂÆ∂Á§∫ÁØÑÔºå‰πüÂ∞±ÊòØÂïèÈ°åËß£Ê±∫ÈÖçÂ∞ç„ÄÇÂú®ÊàëÂÄëÁöÑÊï∏ÂÄºË©ï‰º∞‰∏≠ÔºåÊâÄÊèêÂá∫ÁöÑÁ∂≤Ë∑ØÊì¥Êï£Âô®ÂÑ™ÊñºÂ≠∏ÁøíÂíåÂïüÁôºÂºèÂü∫Ê∫ñÔºåSFC ÁçéÂãµÊèêÂçá‰∫ÜÁ¥Ñ 20%ÔºåSFC Á≠âÂæÖÊôÇÈñìÂíåÂ∞ÅÈéñÁéáÈôç‰Ωé‰∫ÜÁ¥Ñ 50%„ÄÇ

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

ÊëòË¶ÅÔºöÂÆ§ÂÖßË®≠Ë®àÊ∂âÂèä‰ªîÁ¥∞ÊåëÈÅ∏ÂíåÂÆâÊéíÁâ©‰ª∂Ôºå‰ª•ÂâµÈÄ†‰∏ÄÂÄãÁæéËßÄ„ÄÅÂØ¶Áî®‰∏îÂíåË´ßÁöÑÁ©∫ÈñìÔºåÁ¨¶ÂêàÂÆ¢Êà∂ÁöÑË®≠Ë®àÁ∞°Â†±„ÄÇÈÄôÈ†Ö‰ªªÂãôÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÊàêÂäüÁöÑË®≠Ë®à‰∏çÂÉÖÂøÖÈ†à‰ª•‰∏ÄËá¥ÁöÑÈ¢®Ê†ºÁ¥çÂÖ•ÊâÄÊúâÂøÖË¶ÅÁöÑÁâ©‰ª∂ÔºåÈÇÑÂøÖÈ†àÁ¢∫‰øùÂÆÉÂÄëÁöÑÊéíÂàóÊñπÂºèËÉΩÊúÄÂ§ßÂåñÂèØÂèäÊÄßÔºåÂêåÊôÇÁ¨¶ÂêàÂêÑÁ®ÆË≤†ÊìîËÉΩÂäõÂíå‰ΩøÁî®ËÄÉÈáè„ÄÇÂ∑≤Á∂ìÊèêÂá∫‰∫ÜË≥áÊñôÈ©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÈÄô‰∫õËß£Ê±∫ÊñπÊ°àÈÄöÂ∏∏ÊòØÁâπÂÆöÊñºÊàøÈñìÊàñÈ†òÂüüÔºåËÄå‰∏îÁº∫‰πèÂú®Áî¢ÁîüÊúÄÁµÇ‰ΩàÂ±ÄÊôÇÊâÄ‰ΩøÁî®ÁöÑË®≠Ë®àËÄÉÈáèÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂê¶ÂèØ‰ª•Áõ¥Êé•Áî®ÊñºÂÆ§ÂÖßË®≠Ë®à„ÄÇÈõñÁÑ∂ÊàëÂÄëÁôºÁèæ LLM Â∞öÊú™ËÉΩÂ§†Áî¢ÁîüÂÆåÊï¥ÁöÑ‰ΩàÂ±ÄÔºå‰ΩÜÂÆÉÂÄëÂèØ‰ª•ÊúâÊïàÂú∞‰ª•ÁµêÊßãÂåñÁöÑÊñπÂºèÂà©Áî®ÔºåÈùàÊÑü‰æÜËá™ÂÆ§ÂÖßË®≠Ë®àÂ∏´ÁöÑÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÈÄèÈÅéÁ≥ªÁµ±ÊÄßÂú∞Êé¢Êü• LLMÔºåÊàëÂÄëÂèØ‰ª•ÂèØÈù†Âú∞Áî¢Áîü‰∏ÄÂÄãÁâ©‰ª∂Ê∏ÖÂñÆÔºå‰ª•ÂèäÊåáÂ∞éÂÆÉÂÄëÊîæÁΩÆ‰ΩçÁΩÆÁöÑÁõ∏ÂÖ≥Á¥ÑÊùü„ÄÇÊàëÂÄëÂ∞áÈÄô‰∫õË≥áË®äËΩâÊèõÊàêË®≠Ë®à‰ΩàÂ±ÄÂúñÔºåÁÑ∂Âæå‰ΩøÁî®ÁèæÊàêÁöÑÁ¥ÑÊùüÂºèÊúÄ‰Ω≥ÂåñË®≠ÂÆö‰æÜËß£Ê±∫Ôºå‰ª•Áî¢ÁîüÊúÄÁµÇ‰ΩàÂ±Ä„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆË®≠Ë®àÈÖçÁΩÆ‰∏≠Â∞áÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïËàáÁèæÊúâÁöÑÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÂíå‰∫∫È°ûË®≠Ë®àÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰∏¶‰ΩøÁî®ÂêÑÁ®ÆÈáèÂåñÂíåË≥™ÂåñÊåáÊ®ô‰ª•Âèä‰ΩøÁî®ËÄÖÁ†îÁ©∂‰æÜË©ï‰º∞ÁµêÊûú„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëË≠âÊòé‰∫Ü LLM Âú®‰ª•ÁµêÊßãÂåñÁöÑÊñπÂºè‰ΩøÁî®ÊôÇÔºåÂèØ‰ª•ÊúâÊïàÂú∞Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑÈ´òÂìÅË≥™‰ΩàÂ±ÄÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂâµÈÄ†Â§ßÂûãËôõÊì¨Â†¥ÊôØÁöÑÂèØË°åËß£Ê±∫ÊñπÊ°à„ÄÇÂ∞àÊ°àÁ∂≤È†ÅÂú® https://flairgpt.github.io/

##### **CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**
2501.04510v1 by Ruijun Feng, Hammond Pearce, Pietro Liguori, Yulei Sui

Large language models (LLMs) have been proposed as powerful tools for
detecting software vulnerabilities, where task-specific fine-tuning is
typically employed to provide vulnerability-specific knowledge to the LLMs for
this purpose. However, traditional full-parameter fine-tuning is inefficient
for modern, complex LLMs, which contain billions of parameters.
  Soft prompt tuning has been suggested as a more efficient alternative for
fine-tuning LLMs in general cases. However, pure soft prompt tuning treats
source code as plain text, losing structural information inherent in source
code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to
address this issue, are unable to preserve the rich semantic information within
code graphs, as they are primarily designed for general graph-related tasks and
focus more on adjacency information. They also fail to ensure computational
efficiency while accounting for graph-text interactions.
  This paper, therefore, introduces a new code graph-enhanced, structure-aware
soft prompt tuning method for vulnerability detection, referred to as
CGP-Tuning. It employs innovative type-aware embeddings to capture the rich
semantic information within code graphs, along with a novel and efficient
cross-modal alignment module that achieves linear computational cost while
incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on
the latest DiverseVul dataset and the most recent open-source code LLMs,
CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning
outperforms the best state-of-the-art method by an average of 3.5 percentage
points in accuracy, without compromising its vulnerability detection
capabilities for long source code.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë¢´ÊèêÂá∫Áî®ÊñºÂÅµÊ∏¨ËªüÈ´îÊºèÊ¥ûÁöÑÂº∑Â§ßÂ∑•ÂÖ∑ÔºåÂÖ∂‰∏≠‰ªªÂãôÁâπÂÆöÂæÆË™øÈÄöÂ∏∏Áî®ÊñºÊèê‰æõÊºèÊ¥ûÁâπÂÆöÁü•Ë≠òÁµ¶ LLM ‰ª•ÈÅîÂà∞Ê≠§ÁõÆÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÂÆåÊï¥ÂèÉÊï∏ÂæÆË™øÂ∞çÊñºÂåÖÂê´Êï∏ÂçÅÂÑÑÂÄãÂèÉÊï∏ÁöÑÁèæ‰ª£Ë§áÈõú LLM ‰æÜË™™ÊïàÁéá‰Ωé‰∏ã„ÄÇ
ËªüÊèêÁ§∫ÂæÆË™øÂ∑≤Ë¢´Âª∫Ë≠∞‰ΩúÁÇ∫‰∏ÄËà¨ÊÉÖÊ≥Å‰∏ãÂæÆË™ø LLM ÁöÑÊõ¥ÊúâÊïàÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁ¥îËªüÊèêÁ§∫ÂæÆË™øÂ∞áÂéüÂßãÁ¢ºË¶ñÁÇ∫Á¥îÊñáÂ≠óÔºåÂ§±Âéª‰∫ÜÂéüÂßãÁ¢º‰∏≠Âõ∫ÊúâÁöÑÁµêÊßãË≥áË®ä„ÄÇÂêåÊôÇÔºåÊó®Âú®Ëß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÂúñÂΩ¢Â¢ûÂº∑ËªüÊèêÁ§∫ÂæÆË™øÊñπÊ≥ïÁÑ°Ê≥ï‰øùÁïôÁ®ãÂºèÁ¢ºÂúñÂΩ¢‰∏≠ÁöÑË±êÂØåË™ûÁæ©Ë≥áË®äÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏ªË¶ÅË®≠Ë®àÁî®Êñº‰∏ÄËà¨ÁöÑÂúñÂΩ¢Áõ∏Èóú‰ªªÂãôÔºå‰∏îÊõ¥Â∞àÊ≥®ÊñºÈÑ∞Êé•Ë≥áË®ä„ÄÇÂÆÉÂÄë‰πüÁÑ°Ê≥ïÂú®ËÄÉÈáèÂúñÂΩ¢ÊñáÂ≠ó‰∫íÂãïÁöÑÂêåÊôÇÁ¢∫‰øùÈÅãÁÆóÊïàÁéá„ÄÇ
Âõ†Ê≠§ÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁ®ãÂºèÁ¢ºÂúñÂΩ¢Â¢ûÂº∑„ÄÅÁµêÊßãÊÑüÁü•ËªüÊèêÁ§∫ÂæÆË™øÊñπÊ≥ï‰æÜÂÅµÊ∏¨ÊºèÊ¥ûÔºåÁ®±ÁÇ∫ CGP-Tuning„ÄÇÂÆÉÊé°Áî®ÂâµÊñ∞ÁöÑÈ°ûÂûãÊÑüÁü•ÂµåÂÖ•‰æÜÊì∑ÂèñÁ®ãÂºèÁ¢ºÂúñÂΩ¢‰∏≠ÁöÑË±êÂØåË™ûÁæ©Ë≥áË®äÔºå‰ª•Âèä‰∏ÄÂÄãÊñ∞Á©é‰∏îÊúâÊïàÁöÑË∑®Ê®°ÊÖãÂ∞çÈΩäÊ®°ÁµÑÔºåË©≤Ê®°ÁµÑÂú®Á¥çÂÖ•ÂúñÂΩ¢ÊñáÂ≠ó‰∫íÂãïÁöÑÂêåÊôÇÂØ¶ÁèæÁ∑öÊÄßÈÅãÁÆóÊàêÊú¨„ÄÇÊèêË≠∞ÁöÑ CGP-Tuning Âú®ÊúÄÊñ∞ÁöÑ DiverseVul Ë≥áÊñôÈõÜÂíåÊúÄÊñ∞ÁöÑÈñãÊ∫êÁ®ãÂºèÁ¢º LLMÔºàCodeLlama Âíå CodeGemmaÔºâ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåCGP-Tuning Âú®Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢Âπ≥ÂùáÊØîÊúÄ‰Ω≥ÁöÑÁèæÊúâÊäÄË°ìÈ´òÂá∫ 3.5 ÂÄãÁôæÂàÜÈªûÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥ÂÖ∂Â∞çÈï∑ÂéüÂßãÁ¢ºÁöÑÊºèÊ¥ûÂÅµÊ∏¨ËÉΩÂäõ„ÄÇ

##### **S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**
2501.05485v1 by Prashant Verma

Document chunking is a critical task in natural language processing (NLP)
that involves dividing a document into meaningful segments. Traditional methods
often rely solely on semantic analysis, ignoring the spatial layout of
elements, which is crucial for understanding relationships in complex
documents. This paper introduces a novel hybrid approach that combines layout
structure, semantic analysis, and spatial relationships to enhance the cohesion
and accuracy of document chunks. By leveraging bounding box information (bbox)
and text embeddings, our method constructs a weighted graph representation of
document elements, which is then clustered using spectral clustering.
Experimental results demonstrate that this approach outperforms traditional
methods, particularly in documents with diverse layouts such as reports,
articles, and multi-column designs. The proposed method also ensures that no
chunk exceeds a specified token length, making it suitable for use cases where
token limits are critical (e.g., language models with input size limitations)

ÊëòË¶ÅÔºöÊñá‰ª∂ÂàÜÂ°äÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãôÔºåÊ∂âÂèäÂ∞áÊñá‰ª∂ÂàÜÂâ≤ÊàêÊúâÊÑèÁæ©ÁöÑÂçÄÂ°ä„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖ‰æùË≥¥Ë™ûÁæ©ÂàÜÊûêÔºåÂøΩÁï•ÂÖÉÁ¥†ÁöÑÁ©∫Èñì‰ΩàÂ±ÄÔºåËÄåÈÄôÂ∞çÊñºÁêÜËß£Ë§áÈõúÊñá‰ª∂‰∏≠ÁöÑÈóú‰øÇËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑∑ÂêàÊñπÊ≥ïÔºåÁµêÂêà‰ΩàÂ±ÄÁµêÊßã„ÄÅË™ûÁæ©ÂàÜÊûêÂíåÁ©∫ÈñìÈóú‰øÇÔºå‰ª•Â¢ûÂº∑Êñá‰ª∂ÂçÄÂ°äÁöÑÂÖßËÅöÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÈÄèÈÅéÂà©Áî®ÈÇäÁïåÊ°ÜË≥áË®ä (bbox) ÂíåÊñáÂ≠óÂµåÂÖ•ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂª∫ÊßãÊñá‰ª∂ÂÖÉÁ¥†ÁöÑÂä†Ê¨äÂúñË°®Ë°®Á§∫ÔºåÁÑ∂Âæå‰ΩøÁî®Ë≠úËÅöÈ°ûÈÄ≤Ë°åËÅöÈ°û„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊ≠§ÊñπÊ≥ïÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®ÂÖ∑Êúâ‰∏çÂêå‰ΩàÂ±ÄÁöÑÊñá‰ª∂‰∏≠Ôºå‰æãÂ¶ÇÂ†±Âëä„ÄÅÊñáÁ´†ÂíåÂ§öÊ¨ÑË®≠Ë®à„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÈÇÑÁ¢∫‰øùÊ≤íÊúâ‰ªª‰ΩïÂçÄÂ°äË∂ÖÈÅéÊåáÂÆöÁöÑ‰ª§ÁâåÈï∑Â∫¶Ôºå‰ΩøÂÖ∂ÈÅ©Áî®Êñº‰ª§ÁâåÈôêÂà∂Ëá≥ÈóúÈáçË¶ÅÁöÑ‰ΩøÁî®Ê°à‰æãÔºà‰æãÂ¶ÇÔºåÂÖ∑ÊúâËº∏ÂÖ•Â§ßÂ∞èÈôêÂà∂ÁöÑË™ûË®ÄÊ®°ÂûãÔºâ

##### **Multimodal Graph Constrastive Learning and Prompt for ChartQA**
2501.04303v1 by Yue Dai, Soyeon Caren Han, Wei Liu

ChartQA presents significant challenges due to the complex distribution of
chart elements and the implicit patterns embedded within the underlying data.
In this chapter, we have developed a joint multimodal scene graph for charts,
explicitly representing the relationships between chart elements and their
associated patterns.
  Our proposed multimodal scene graph consists of two components: a visual
graph and a textual graph, each designed to capture the structural and semantic
information within the chart. To unify representations across these different
modalities, we introduce a multimodal graph contrastive learning approach that
learns unified representations by maximizing similarity between nodes
representing the same object across multimodal graphs. The learned graph
representations can be seamlessly incorporated into a transformer decoder as a
soft prompt.
  Additionally, given the growing need for Multimodal Large Language Models
(MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts
for MLLMs to reduce hallucinations. We tested both methods on public benchmarks
such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and
validating the effectiveness of our proposed methods.

ÊëòË¶ÅÔºöChartQA Âõ†ÂúñË°®ÂÖÉÁ¥†ÁöÑË§áÈõúÂàÜ‰ΩàÂíåÂü∫Á§éË≥áÊñô‰∏≠ÂÖßÂµåÁöÑÈö±Âê´Ê®°ÂºèËÄåÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞„ÄÇ
Âú®Êú¨Á´†‰∏≠ÔºåÊàëÂÄëÁÇ∫ÂúñË°®ÈñãÁôº‰∫Ü‰∏ÄÂÄãËÅØÂêàÂ§öÊ®°ÊÖãÂ†¥ÊôØÂúñÂΩ¢ÔºåÊòéÁ¢∫Ë°®Á§∫ÂúñË°®ÂÖÉÁ¥†‰πãÈñìÁöÑÈóú‰øÇÂèäÂÖ∂ÈóúËÅØÊ®°Âºè„ÄÇ
ÊàëÂÄëÊèêÂá∫ÁöÑÂ§öÊ®°ÊÖãÂ†¥ÊôØÂúñÂΩ¢ÂåÖÂê´ÂÖ©ÂÄãÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãË¶ñË¶∫ÂúñÂΩ¢Âíå‰∏ÄÂÄãÊñáÊú¨ÂúñÂΩ¢ÔºåÊØèÂÄãÁµÑÊàêÈÉ®ÂàÜÈÉΩÊó®Âú®Êì∑ÂèñÂúñË°®‰∏≠ÁöÑÁµêÊßãÂåñÂíåË™ûÁæ©Ë≥áË®ä„ÄÇ
ÁÇ∫‰∫ÜÁµ±‰∏ÄÈÄô‰∫õ‰∏çÂêåÊ®°ÊÖãÁöÑË°®Á§∫ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂúñÂΩ¢Â∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÔºåÈÄèÈÅéÊúÄÂ§ßÂåñË∑®Â§öÊ®°ÊÖãÂúñÂΩ¢Ë°®Á§∫Áõ∏ÂêåÁâ©‰ª∂ÁöÑÁØÄÈªû‰πãÈñìÁöÑÁõ∏‰ººÊÄß‰æÜÂ≠∏ÁøíÁµ±‰∏ÄÁöÑË°®Á§∫„ÄÇ
Â≠∏ÁøíÂà∞ÁöÑÂúñÂΩ¢Ë°®Á§∫ÂèØ‰ª•ÁÑ°Á∏´Âú∞Êï¥ÂêàÂà∞TransformerËß£Á¢ºÂô®‰∏≠Ôºå‰ΩúÁÇ∫‰∏ÄÂÄãËªüÊèêÁ§∫„ÄÇ
Ê≠§Â§ñÔºåÈëëÊñºÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Âú®Èõ∂Ê¨°Â≠∏ÁøíÂ†¥ÊôØ‰∏≠ÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÂä†ÔºåÊàëÂÄëÁÇ∫ MLLM Ë®≠Ë®à‰∫ÜÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫Ôºå‰ª•Ê∏õÂ∞ëÂπªË¶∫„ÄÇ
ÊàëÂÄëÂú®ÂÖ¨ÁúæÂü∫Ê∫ñ‰∏äÊ∏¨Ë©¶‰∫ÜÈÄôÂÖ©Á®ÆÊñπÊ≥ïÔºå‰æãÂ¶Ç ChartQA„ÄÅOpenCQA Âíå ChartXÔºåË≠âÊòé‰∫ÜÊïàËÉΩÁöÑÊèêÂçáÔºå‰∏¶È©óË≠â‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**
2501.06224v1 by Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy

Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºå‰ΩøÁî®Áµ±‰∏ÄÂ§öÊ®°ÊÖãÊ®°ÂûãÈñãÁôºÁöÑÊö¥ÂäõÂÅµÊ∏¨Á≥ªÁµ±ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰∏¶ÂºïËµ∑Âª£Ê≥õÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±Â§ßÂ§öÈù¢Ëá®ÂÖ©È†ÖÂö¥Â≥ªÊåëÊà∞ÔºöÁº∫‰πèÈªëÁÆ±Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰ª•ÂèäÂäüËÉΩÂèóÈôêÔºåÂÉÖÊèê‰æõÂàÜÈ°ûÊàñÊ™¢Á¥¢ËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊö¥ÂäõÂÅµÊ∏¨Á≥ªÁµ±ÔºåÁ®±ÁÇ∫‰∏âÂêà‰∏Ä (TIO) Á≥ªÁµ±„ÄÇTIO Á≥ªÁµ±Êï¥ÂêàÁü•Ë≠òÂúñË≠ú (KG) ÂíåÂúñÂΩ¢Ê≥®ÊÑèÂäõÁ∂≤Ë∑Ø (GAT)Ôºå‰ª•Êèê‰æõ‰∏âÈ†ÖÊ†∏ÂøÉÂäüËÉΩÔºöÂÅµÊ∏¨„ÄÅÊ™¢Á¥¢ÂíåËß£Èáã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåË©≤Á≥ªÁµ±ËôïÁêÜÊØèÂÄãÂΩ±ÁâáÂπÄÔºå‰ª•ÂèäÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫ÂåÖÂê´ÊΩõÂú®Êö¥ÂäõË°åÁÇ∫ÁöÑÂΩ±ÁâáÁî¢ÁîüÁöÑÊñáÂ≠óÊèèËø∞„ÄÇÂÆÉÊé°Áî® ImageBind Áî¢ÁîüÈ´òÁ∂≠ÂµåÂÖ•ÔºåÁî®ÊñºÂª∫ÊßãÁü•Ë≠òÂúñË≠úÔºå‰ΩøÁî® GAT ÈÄ≤Ë°åÊé®ÁêÜÔºå‰∏¶ÊáâÁî®ËºïÈáèÁ¥öÊôÇÈñìÂ∫èÂàóÊ®°ÁµÑ‰æÜÊèêÂèñÂΩ±ÁâáÂµåÂÖ•ÁâπÂæµ„ÄÇÊúÄÂæå‰∏ÄÊ≠•ÈÄ£Êé•ÂàÜÈ°ûÂô®ÂíåÊ™¢Á¥¢Âô®Ôºå‰ª•Áî¢ÁîüÂ§öÂäüËÉΩËº∏Âá∫„ÄÇKG ÁöÑÂèØËß£ÈáãÊÄßËÆìÁ≥ªÁµ±ËÉΩÂ§†È©óË≠âÊØèÂÄãËº∏Âá∫ËÉåÂæåÁöÑÊé®ÁêÜÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÊú¨Êñá‰ªãÁ¥π‰∫ÜÂπæÁ®ÆËºïÈáèÁ¥öÊñπÊ≥ïÔºå‰ª•Ê∏õÂ∞ë TIO Á≥ªÁµ±ÁöÑË≥áÊ∫êÊ∂àËÄóÔºå‰∏¶ÊèêÂçáÂÖ∂ÊïàÁéá„ÄÇÂú® XD-Violence Âíå UCF-Crime Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫Á≥ªÁµ±ÁöÑÊúâÊïàÊÄß„ÄÇÊ°à‰æãÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫Ü‰∏ÄÂÄãÊúâË∂£ÁöÑÁèæË±°ÔºöÈö®ËëóÊóÅËßÄËÄÖ‰∫∫Êï∏Â¢ûÂä†ÔºåÊö¥ÂäõË°åÁÇ∫ÁôºÁîüÁöÑÊ©üÁéáÊúÉ‰∏ãÈôç„ÄÇ</paragraph>

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®‰ºÅÊ•≠Âª∫Ê®°‰∏≠ÁöÑËßíËâ≤ÊúÄËøëÂ∑≤ÈñãÂßãÂæûÂ≠∏Ë°ìÁ†îÁ©∂ËΩâËÆäÁÇ∫Áî¢Ê•≠ÊáâÁî®„ÄÇÂõ†Ê≠§ÔºåLLM ‰ª£Ë°®‰∫ÜÊ©üÂô®ÊîØÊè¥ÁöÑ‰ºÅÊ•≠Ê®°ÂûãÁîüÊàêÁöÑÈÄ≤‰∏ÄÊ≠•Âª∫ÊßãÊ®°ÁµÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°Áî®Âü∫ÊñºÁü•Ë≠òÂúñË°®ÁöÑ‰ºÅÊ•≠Âª∫Ê®°ÊñπÊ≥ïÔºå‰∏¶Êé¢Ë®é LLM Âú®Ê≠§ËÑàÁµ°‰∏≠ÁöÑÊΩõÂú®ÊïàÁõä„ÄÇÊ≠§Â§ñÔºåÂ∞àÂÆ∂Ë™øÊü•ÂíåÂü∫Êñº ChatGPT-4o ÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑÊ®°ÂûãÁîüÊàêÂ±ïÁèæÊúÄÂ∞èÁöÑÂèØËÆäÊÄßÔºå‰ΩÜ‰ªç‰æ∑ÈôêÊñºÁâπÂÆö‰ªªÂãôÔºåËÄåÂèØÈù†ÊÄßÊúÉÈö®Ëëó‰ªªÂãôÁöÑË§áÈõúÊÄßËÄå‰∏ãÈôç„ÄÇË™øÊü•ÁµêÊûúÈÄ≤‰∏ÄÊ≠•Ë°®ÊòéÔºå‰∫∫È°ûÂª∫Ê®°Â∞àÂÆ∂ÁöÑÁõ£Áù£Âíå‰ªãÂÖ•Â∞çÊñºÁ¢∫‰øùÁîüÊàêÊ®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂÆåÊï¥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇ

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

ÊëòË¶ÅÔºöÂ§öË™ûË®ÄÁü•Ë≠òÂúñË≠ú (KG) ÁÇ∫ÂêÑÁ®Æ NLP ÊáâÁî®Á®ãÂºèÊèê‰æõÈ´òÂìÅË≥™ÁöÑÈóú‰øÇÂíåÊñáÂ≠óË≥áË®äÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÊòØ‰∏çÂÆåÊï¥ÁöÑÔºåÁâπÂà•ÊòØÈùûËã±Ë™ûË™ûË®Ä„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÁµêÂêà‰∏çÂêåË™ûË®Ä‰∏≠ KG ÁöÑË≥áË®äÊúâÂä©ÊñºÁü•Ë≠òÂúñË≠úÂÆåÊàêÂäüËÉΩ (KGC)ÔºåÂç≥È†êÊ∏¨ÂØ¶È´î‰πãÈñìÈÅ∫Â§±ÁöÑÈóú‰øÇÔºåÊàñÁü•Ë≠òÂúñË≠úÂ¢ûÂº∑ (KGE)ÔºåÂç≥È†êÊ∏¨ÂØ¶È´îÈÅ∫Â§±ÁöÑÊñáÂ≠óË≥áË®ä„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÂä™ÂäõÂ∞á KGC Âíå KGE Ë¶ñÁÇ∫Áç®Á´ãÁöÑ‰ªªÂãôÔºåÊàëÂÄëÂÅáË®≠ÂÆÉÂÄëÊòØÁõ∏‰∫í‰æùË≥¥‰∏î‰∫íÂà©ÁöÑ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü KG-TRICKÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ∫èÂàóÂà∞Â∫èÂàóÊû∂ÊßãÔºåÂÆÉÁµ±‰∏Ä‰∫ÜÂ§öË™ûË®Ä KG ÁöÑÊñáÂ≠óÂíåÈóú‰øÇË≥áË®äÂÆåÊàê‰ªªÂãô„ÄÇKG-TRICK Ë≠âÊòéÔºöi) ÂèØ‰ª•Â∞á KGC Âíå KGE ÁöÑ‰ªªÂãôÁµ±‰∏ÄÂà∞ÂñÆ‰∏ÄÊû∂Êßã‰∏≠Ôºå‰ª•Âèä ii) ÁµêÂêàÂ§öÁ®ÆË™ûË®ÄÁöÑÊñáÂ≠óË≥áË®äÊúâÂä©ÊñºÊèêÈ´ò KG ÁöÑÂÆåÊï¥ÊÄß„ÄÇ‰ΩúÁÇ∫ÊàëÂÄëË≤¢ÁçªÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü WikiKGE10++ÔºåÈÄôÊòØ KG ÊñáÂ≠óË≥áË®äÂÆåÊàêÊúÄÂ§ßÁöÑÊâãÂãïÊï¥ÁêÜÂü∫Ê∫ñÔºåÂÖ∂ÁâπÈªûÊòØË∂ÖÈÅé 10 Á®Æ‰∏çÂêåË™ûË®Ä‰∏≠ÁöÑ 25,000 ÂÄãÂØ¶È´î„ÄÇ

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®Æ NLP ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È©ö‰∫∫ÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ë™ûÊÑèÂàÜÊûêÔºåÂÆÉÂ∞áËá™ÁÑ∂Ë™ûË®ÄËΩâÊèõÁÇ∫Ê≠£ÂºèÁöÑÁ®ãÂºèÁ¢ºË°®Á§∫„ÄÇÁÑ∂ËÄåÔºåÂèçÂêëÈÅéÁ®ãÔºåÂ∞áÁ®ãÂºèÁ¢ºËΩâÊèõÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄÔºåÁ®±ÁÇ∫Ë™ûÊÑèÊ®ôÈ°åÔºåÂâáËºÉÂ∞ëÂèóÂà∞ÈóúÊ≥®„ÄÇÈö®Ëëó LLM Êï¥ÂêàÂà∞Á®ãÂºèÁ¢ºÁî¢Áîü„ÄÅÂÆâÂÖ®ÊÄßÂàÜÊûêÂíåÊïôËÇ≤ÁõÆÁöÑÁöÑÂπ≥Âè∞‰∏≠ÔºåÈÄôÈ†Ö‰ªªÂãôÊ≠£ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®Êñº SQL Êü•Ë©¢ÁöÑÊ®ôÈ°å (SQL2Text)Ôºå‰ª•ÊªøË∂≥Âú® LLM Áî¢ÁîüÁöÑÁ®ãÂºèÁ¢ºÊßãÊàêÊΩõÂú®ÂÆâÂÖ®È¢®Èö™ÁöÑÊôÇ‰ª£‰∏≠ÔºåÁêÜËß£ÂíåËß£Èáã SQL Êü•Ë©¢ÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî® GPT-4o Â∞éÂÖ•ÂèçË¶ÜÁöÑ ICL ÊèêÁ§∫‰æÜÁî¢ÁîüÂ§öÂÄãÈ°çÂ§ñÁöÑË™ûÂè•ÔºåÈáçÊñ∞Ë™øÊï¥ Text2SQL Ë≥áÊñôÈõÜ‰ª•Áî®Êñº SQL2TextÔºåÈÄôÂ¢ûÂº∑‰∫ÜË≥áÊñôÈõÜÂ∞çÂèçÂêë‰ªªÂãôÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄë‰ΩøÁî®Âü∫Êñº‰∏çÂêåÁØÑ‰æãÈÅ∏ÂèñÊñπÊ≥ïÁöÑÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÈÄ≤Ë°åÂØ¶È©óÔºåÂº∑Ë™øËºÉÂ∞è„ÄÅË®àÁÆóÊïàÁéáËºÉÈ´òÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòéÔºåÂà©Áî® SQL ÁöÑÂÖßÂú®ÂúñÂΩ¢Â±¨ÊÄßÈÄ≤Ë°å ICL ÁØÑ‰æãÈÅ∏ÂèñÔºåÂú® BLEU ÂàÜÊï∏‰∏äÈ°ØËëóÂÑ™ÊñºÈö®Ê©üÈÅ∏ÂèñÔºåÊúÄÂ§öÂèØÈÅî 39%Ôºå‰∏¶Êèê‰æõÊØîÂÖ∂‰ªñÊñπÊ≥ïÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇË≥áÊñôÈõÜÂíåÁ®ãÂºèÁ¢ºÂ∑≤ÁôºÂ∏ÉÔºö\url{https://github.com/aliwister/ast-icl}„ÄÇ

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

ÊëòË¶ÅÔºöÂÆ¢Ë£ΩÂåñÊôÇÂ∞öÊé®Ëñ¶ÊòØ‰∏ÄÈ†ÖÂõ∞Èõ£ÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ 1) Ê±∫Á≠ñËàá‰ΩøÁî®ËÄÖÁöÑÁæéÂ≠∏ÂñúÂ•ΩÈ´òÂ∫¶Áõ∏ÈóúÔºåËÄåÂÖàÂâçÁöÑÁ†îÁ©∂Á∂ìÂ∏∏ÂøΩÁï•ÈÄô‰∏ÄÈªûÔºå‰ª•Âèä 2) Ë®±Â§öÊñ∞ÂïÜÂìÅ‰∏çÊñ∑Êé®Âá∫ÔºåÈÄôÊúÉÂú®ÊµÅË°åÁöÑË∫´ÂàÜ (ID) ÁÇ∫Âü∫Á§éÁöÑÊé®Ëñ¶ÊñπÊ≥ï‰∏≠ÈÄ†ÊàêÂö¥ÈáçÁöÑÂÜ∑ÂïüÂãïÂïèÈ°å„ÄÇÈÄô‰∫õÊñ∞ÂïÜÂìÅÂ∞çÊñºÊé®Ëñ¶Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÂºïÈ†òÊ∂àË≤ªË∂®Âã¢„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Êèê‰æõÊõ¥Ê∫ñÁ¢∫ÁöÑÂÆ¢Ë£ΩÂåñÊôÇÂ∞öÊé®Ëñ¶Ôºå‰∏¶ÈÄèÈÅéÂ∞áÂèØÁî®Ë≥áË®äÔºàÂ∞§ÂÖ∂ÊòØÂúñÁâáÔºâËΩâÊèõÊàêÂÖ©ÂÄãÂ±¨ÊÄßÂúñË°®‰æÜËß£Ê±∫ÂÜ∑ÂïüÂãïÂïèÈ°åÔºåÈáçÈªûÂú®ÊñºÊúÄ‰Ω≥ÂåñÂúñÁâá‰ΩøÁî®ÂíåÈôç‰ΩéÈõúË®äÁöÑ‰ΩøÁî®ËÄÖÂª∫Ê®°„ÄÇËàáÂ∞áÂúñÁâáÂíåÊñáÂ≠óÂàÜÈñãÁÇ∫ÂÖ©ÂÄãÁµÑÊàêÁöÑÂÖàÂâçÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁµêÂêàÂúñÁâáÂíåÊñáÂ≠óË≥áË®äÔºå‰ª•Âª∫Á´ãÊõ¥Ë±êÂØåÁöÑÂ±¨ÊÄßÂúñË°®„ÄÇÂà©Áî®Â§ßÂûãË™ûË®ÄÂíåË¶ñË¶∫Ê®°ÂûãÁöÑÈÄ≤Ê≠•ÔºåÊàëÂÄëÂòóË©¶‰ΩøÁî®ÂÖ©Á®Æ‰∏çÂêåÁöÑÊèêÁ§∫ÊúâÊïàÁéá‰∏îÂ¶ÇÈ†êÊúüËà¨Âú∞ËêÉÂèñÁ¥∞Á∑ªÁöÑÂ±¨ÊÄß„ÄÇÂú® IQON3000 Ë≥áÊñôÈõÜ‰∏äÁöÑÂàùÊ≠•ÂØ¶È©óÈ°ØÁ§∫ÔºåËàáÂü∫Ê∫ñÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÈÅîÂà∞‰∫ÜÁ´∂Áà≠ÂäõÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**
2501.02844v1 by Yubo Wang, Haoyang Li, Fei Teng, Lei Chen

Text classification is a fundamental task in natural language processing,
pivotal to various applications such as query optimization, data integration,
and schema matching. While neural network-based models, such as CNN and BERT,
have demonstrated remarkable performance in text classification, their
effectiveness heavily relies on abundant labeled training data. This dependency
makes these models less effective in dynamic few-shot text classification,
where labeled data is scarce, and target labels frequently evolve based on
application needs. Recently, large language models (LLMs) have shown promise
due to their extensive pretraining and contextual understanding. Current
approaches provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to predict text labels. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. GORAG constructs and maintains an
adaptive information graph by extracting side information across all target
texts, rather than treating each input independently. It employs a weighted
edge mechanism to prioritize the importance and reliability of extracted
information and dynamically retrieves relevant context using a minimum-cost
spanning tree tailored for each text input. Empirical evaluations demonstrate
that GORAG outperforms existing approaches by providing more comprehensive and
accurate contextual information.

ÊëòË¶ÅÔºöÊñáÊú¨ÂàÜÈ°ûÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑÂü∫Êú¨‰ªªÂãôÔºå
Â∞çÊñºÂêÑÁ®ÆÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÊü•Ë©¢ÂÑ™Âåñ„ÄÅË≥áÊñôÊï¥ÂêàÔºå
ÂíåÊ®°ÂºèÂåπÈÖç„ÄÇÈõñÁÑ∂Âü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç CNN Âíå BERTÔºå
Âú®ÊñáÊú¨ÂàÜÈ°û‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÖ∂
ÊúâÊïàÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÂ§ßÈáèÁöÑÊ®ôÁ±§Ë®ìÁ∑¥Ë≥áÊñô„ÄÇÈÄôÂÄã‰æùË≥¥ÊÄß
‰ΩøÂæóÈÄô‰∫õÊ®°ÂûãÂú®ÂãïÊÖãÂ∞ëÊ®£Êú¨ÊñáÊú¨ÂàÜÈ°û‰∏≠ÊïàÊûúËºÉÂ∑ÆÔºå
ÂÖ∂‰∏≠Ê®ôÁ±§Ë≥áÊñôÁ®ÄÁº∫Ôºå‰∏¶‰∏îÁõÆÊ®ôÊ®ôÁ±§ÊúÉÊ†πÊìö
ÊáâÁî®ÈúÄÊ±ÇÈ†ªÁπÅÊºîËÆä„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂Âª£Ê≥õÁöÑÈ†êË®ìÁ∑¥Âíå‰∏ä‰∏ãÊñáÁêÜËß£ËÄåÈ°ØÁ§∫Âá∫ÂâçÊôØ„ÄÇÁõÆÂâç
ÊñπÊ≥ïÁÇ∫ LLM Êèê‰æõÊñáÊú¨Ëº∏ÂÖ•„ÄÅÂÄôÈÅ∏Ê®ôÁ±§ÂíåÈôÑÂä†ÂÅ¥ÈÇä
Ë≥áË®äÔºà‰æãÂ¶ÇÔºåÊèèËø∞Ôºâ‰ª•È†êÊ∏¨ÊñáÊú¨Ê®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÂÖ∂
ÊúâÊïàÊÄßÂèóÂà∞Ëº∏ÂÖ•Â§ßÂ∞èÂ¢ûÂä†ÂíåÂÅ¥ÈÇäË≥áË®äËôïÁêÜÂºïÂÖ•ÁöÑÈõúË®äÁöÑÈòªÁ§ô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã
Âü∫ÊñºÂúñË°®ÁöÑÁ∑ö‰∏äÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊû∂ÊßãÔºåÂç≥ GORAGÔºåÁî®Êñº
ÂãïÊÖãÂ∞ëÊ®£Êú¨ÊñáÊú¨ÂàÜÈ°û„ÄÇGORAG ÈÄöÈÅéÊèêÂèñÊâÄÊúâÁõÆÊ®ôÁöÑÂÅ¥ÈÇäË≥áË®ä‰æÜÂª∫Êßã‰∏¶Á∂≠Ë≠∑‰∏ÄÂÄã
Ëá™ÈÅ©ÊáâË≥áË®äÂúñË°®
ÊñáÊú¨ÔºåËÄå‰∏çÊòØÁç®Á´ãËôïÁêÜÊØèÂÄãËº∏ÂÖ•„ÄÇÂÆÉÊé°Áî®Âä†Ê¨ä
ÈÇäÁ∑£Ê©üÂà∂‰æÜÂÑ™ÂÖàËÄÉÊÖÆÊèêÂèñË≥áË®äÁöÑÈáçË¶ÅÊÄßÂèäÂèØÈù†ÊÄßÔºå‰∏¶‰ΩøÁî®ÈáùÂ∞çÊØèÂÄãÊñáÊú¨Ëº∏ÂÖ•ÈáèË∫´ÊâìÈÄ†ÁöÑÊúÄÂ∞èÊàêÊú¨
ÁîüÊàêÊ®πÂãïÊÖãÊ™¢Á¥¢Áõ∏ÈóúÁöÑ‰∏ä‰∏ãÊñá„ÄÇÂØ¶Ë≠âË©ï‰º∞Ë°®Êòé
GORAG ÈÄöÈÅéÊèê‰æõÊõ¥ÂÖ®Èù¢‰∏îÊ∫ñÁ¢∫ÁöÑ‰∏ä‰∏ãÊñáË≥áË®äÔºåÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**
2501.02711v1 by Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li

Large Language Models (LLMs) have shown impressive performance in various
tasks, including knowledge graph completion (KGC). However, current studies
mostly apply LLMs to classification tasks, like identifying missing triplets,
rather than ranking-based tasks, where the model ranks candidate entities based
on plausibility. This focus limits the practical use of LLMs in KGC, as
real-world applications prioritize highly plausible triplets. Additionally,
while graph paths can help infer the existence of missing triplets and improve
completion accuracy, they often contain redundant information. To address these
issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.
KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,
achieving superior results on real-world datasets. The code and datasets are
available at \url{https://anonymous.4open.science/r/KG-CF}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®ÁèæÔºåÂåÖÊã¨Áü•Ë≠òÂúñË≠úÂÆåÊàêÂäüËÉΩ (KGC)„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁ†îÁ©∂Â§ßÂ§öÂ∞á LLM ÊáâÁî®ÊñºÂàÜÈ°û‰ªªÂãôÔºå‰æãÂ¶ÇË≠òÂà•ÈÅ∫ÊºèÁöÑ‰∏âÂÖÉÁµÑÔºåËÄåÈùûÂü∫ÊñºÊéíÂêçÁöÑ‰ªªÂãôÔºåÂÖ∂‰∏≠Ê®°ÂûãÊ†πÊìöÂêàÁêÜÊÄßÂ∞çÂÄôÈÅ∏ÂØ¶È´îÈÄ≤Ë°åÊéíÂêç„ÄÇÈÄôÁ®ÆÈáçÈªûÈôêÂà∂‰∫Ü LLM Âú® KGC ‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®ÔºåÂõ†ÁÇ∫ÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®ÂÑ™ÂÖàËÄÉÊÖÆÈ´òÂ∫¶ÂêàÁêÜÁöÑÁöÑ‰∏âÂÖÉÁµÑ„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°ÂúñÂΩ¢Ë∑ØÂæëÊúâÂä©ÊñºÊé®Êñ∑ÈÅ∫ÊºèÁöÑ‰∏âÂÖÉÁµÑÁöÑÂ≠òÂú®‰∏¶ÊèêÈ´òÂÆåÊàêÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÂåÖÂê´ÂÜóÈ§òË≥áË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ KG-CFÔºå‰∏ÄÂÄãÂ∞àÈñÄÈáùÂ∞çÂü∫ÊñºÊéíÂêçÁöÑ KGC ‰ªªÂãôÁöÑÊ°ÜÊû∂„ÄÇKG-CF Âà©Áî® LLM ÁöÑÊé®ÁêÜËÉΩÂäõ‰æÜÈÅéÊøæ‰∏çÁõ∏ÈóúÁöÑ‰∏ä‰∏ãÊñáÔºåÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÂçìË∂äÁöÑÊàêÊûú„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØÂú® \url{https://anonymous.4open.science/r/KG-CF} ÂèñÂæó„ÄÇ

##### **Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**
2501.02393v2 by Markus J. Buehler

We present an approach to modifying Transformer architectures by integrating
graph-aware relational reasoning into the attention mechanism, merging concepts
from graph neural networks and language modeling. Building on the inherent
connection between attention and graph theory, we reformulate the Transformer's
attention mechanism as a graph operation and propose Graph-Aware Isomorphic
Attention. This method leverages advanced graph modeling strategies, including
Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),
to enrich the representation of relational structures. Our approach captures
complex dependencies and generalizes across tasks, as evidenced by a reduced
generalization gap and improved learning performance. Additionally, we expand
the concept of graph-aware attention to introduce Sparse GIN-Attention, a
fine-tuning approach that employs sparse GINs. By interpreting attention
matrices as sparse adjacency graphs, this technique enhances the adaptability
of pre-trained foundational models with minimal computational overhead,
endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning
achieves improved training dynamics and better generalization compared to
alternative methods like low-rank adaption (LoRA). We discuss latent graph-like
structures within traditional attention mechanisms, offering a new lens through
which Transformers can be understood. By evolving Transformers as hierarchical
GIN models for relational reasoning. This perspective suggests profound
implications for foundational model development, enabling the design of
architectures that dynamically adapt to both local and global dependencies.
Applications in bioinformatics, materials science, language modeling, and
beyond could benefit from this synthesis of relational and sequential data
modeling, setting the stage for interpretable and generalizable modeling
strategies.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰øÆÊîπ Transformer Êû∂ÊßãÁöÑÊñπÊ≥ïÔºåÊñπÊ≥ïÊòØÂ∞áÂúñÊÑüÁü•ÈóúËÅØÊé®ÁêÜÊï¥ÂêàÂà∞Ê≥®ÊÑèÂäõÊ©üÂà∂‰∏≠ÔºåÂêà‰ΩµÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåË™ûË®ÄÊ®°ÂûãÁöÑÊ¶ÇÂøµ„ÄÇÂü∫ÊñºÊ≥®ÊÑèÂäõÂíåÂúñË´ñ‰πãÈñìÁöÑÂÖßÂú®ËÅØÁπ´ÔºåÊàëÂÄëÂ∞á Transformer ÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂ÈáçÊñ∞Ë°®Ëø∞ÁÇ∫ÂúñÊìç‰ΩúÔºå‰∏¶ÊèêÂá∫ÂúñÊÑüÁü•ÂêåÊßãÊ≥®ÊÑèÂäõ„ÄÇÊ≠§ÊñπÊ≥ïÂà©Áî®ÂÖàÈÄ≤ÁöÑÂúñÊ®°ÂûãÁ≠ñÁï•ÔºåÂåÖÊã¨ÂúñÂêåÊßãÁ∂≤Ë∑Ø (GIN) Âíå‰∏ªÈÑ∞ÂüüËÅöÂêà (PNA)Ôºå‰ª•Ë±êÂØåÈóú‰øÇÁµêÊßãÁöÑË°®Á§∫„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊçïÊçâ‰∫ÜË§áÈõúÁöÑ‰æùË≥¥Èóú‰øÇÔºå‰∏¶Âú®ÂêÑÈ†Ö‰ªªÂãô‰∏≠ÈÄ≤Ë°åÊ¶ÇÊã¨ÔºåÈÄôÂæûÁ∏ÆÂ∞èÁöÑÊ¶ÇÊã¨Â∑ÆË∑ùÂíåÊîπÂñÑÁöÑÂ≠∏ÁøíË°®Áèæ‰∏≠ÂæóÂà∞Ë≠âÊòé„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊì¥Â±ï‰∫ÜÂúñÊÑüÁü•Ê≥®ÊÑèÂäõÁöÑÊ¶ÇÂøµÔºåÂºïÂÖ•‰∫ÜÁ®ÄÁñè GIN Ê≥®ÊÑèÂäõÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊé°Áî®Á®ÄÁñè GIN ÁöÑÂæÆË™øÊñπÊ≥ï„ÄÇÈÄöÈÅéÂ∞áÊ≥®ÊÑèÂäõÁü©Èô£Ëß£ÈáãÁÇ∫Á®ÄÁñèÈÑ∞Êé•ÂúñÔºåÊ≠§ÊäÄË°ì‰ª•ÊúÄÂ∞èÁöÑË®àÁÆóÈñãÈä∑Â¢ûÂº∑‰∫ÜÈ†êË®ìÁ∑¥Âü∫Á§éÊ®°ÂûãÁöÑÈÅ©ÊáâÊÄßÔºåË≥¶‰∫àÂÆÉÂÄëÂúñÊÑüÁü•ËÉΩÂäõ„ÄÇËàá‰ΩéÁß©ÈÅ©Êáâ (LoRA) Á≠âÊõø‰ª£ÊñπÊ≥ïÁõ∏ÊØîÔºåÁ®ÄÁñè GIN Ê≥®ÊÑèÂäõÂæÆË™øÂØ¶Áèæ‰∫ÜÊîπÈÄ≤ÁöÑË®ìÁ∑¥ÂãïÊÖãÂíåÊõ¥Â•ΩÁöÑÊ¶ÇÊã¨„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂÇ≥Áµ±Ê≥®ÊÑèÂäõÊ©üÂà∂‰∏≠ÁöÑÊΩõÂú®ÂúñÂΩ¢ÁµêÊßãÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË¶ñËßíÔºåÈÄöÈÅéÂÆÉÂèØ‰ª•ÁêÜËß£ Transformer„ÄÇÈÄöÈÅéÂ∞á Transformer ÊºîÂåñÁÇ∫Áî®ÊñºÈóú‰øÇÊé®ÁêÜÁöÑÂàÜÂ±§ GIN Ê®°Âûã„ÄÇÈÄôÁ®ÆËßÄÈªûÂ∞çÂü∫Á§éÊ®°ÂûãÁöÑÈñãÁôºÂÖ∑ÊúâÊ∑±ÈÅ†ÁöÑÂΩ±ÈüøÔºåÂèØ‰ª•Ë®≠Ë®àÂá∫ÂãïÊÖãÈÅ©ÊáâÂ±ÄÈÉ®ÂíåÂÖ®Â±Ä‰æùË≥¥Èóú‰øÇÁöÑÊû∂Êßã„ÄÇÁîüÁâ©Ë≥áË®äÂ≠∏„ÄÅÊùêÊñôÁßëÂ≠∏„ÄÅË™ûË®ÄÂª∫Ê®°Á≠âÈ†òÂüüÁöÑÊáâÁî®ÂèØ‰ª•ÂæûÈÄôÁ®ÆÈóú‰øÇÂíåÂ∫èÂàóË≥áÊñôÂª∫Ê®°ÁöÑÁ∂úÂêà‰∏≠ÂèóÁõäÔºåÁÇ∫ÂèØËß£ÈáãÂíåÂèØÊ¶ÇÊã¨ÁöÑÂª∫Ê®°Á≠ñÁï•Â•†ÂÆöÂü∫Á§é„ÄÇ</paragraph>

##### **What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**
2501.02268v1 by Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou

Recent Multimodal Large Language Models(MLLMs) often use a large number of
visual tokens to compensate their visual shortcoming, leading to excessive
computation and obvious visual redundancy. In this paper, we investigate what
kind of visual tokens are needed for MLLMs, and reveal that both foreground and
background tokens are critical for MLLMs given the varying difficulties of
examples. Based on this observation, we propose a graph-based method towards
training-free visual token pruning, termed G-Prune.In particular, G-Prune
regards visual tokens as nodes, and construct their connections based on their
semantic similarities. Afterwards, the information flow is propagated via
weighted links, and the most important tokens after iterations are kept for
MLLMs, which can be front or background.To validate G-Prune, we apply it to a
recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of
benchmarks.The experiment results show that G-Prune can greatly reduce
computation overhead while retaining high performance on both coarse- and
fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of
LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops,
respectively.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) ÁªèÂ∏∏‰ΩøÁî®Â§ßÈáèÁöÑËßÜËßâÊ†áËÆ∞Êù•Âº•Ë°•ÂÖ∂ËßÜËßâ‰∏äÁöÑÁº∫ÁÇπÔºåÂØºËá¥ËøáÂ∫¶ÁöÑËÆ°ÁÆóÂíåÊòéÊòæÁöÑËßÜËßâÂÜó‰Ωô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫Ü MLLM ÈúÄË¶ÅÂì™ÁßçËßÜËßâÊ†áËÆ∞ÔºåÂπ∂Êè≠Á§∫‰∫ÜÈâ¥‰∫éÁ§∫‰æãÁöÑÈöæÂ∫¶‰∏çÂêåÔºåÂâçÊôØÊ†áËÆ∞ÂíåËÉåÊôØÊ†áËÆ∞ÂØπ‰∫é MLLM ÈÉΩÊòØËá≥ÂÖ≥ÈáçË¶ÅÁöÑ„ÄÇÂü∫‰∫éÊ≠§ËßÇÂØüÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂõæÁöÑÊó†ËÆ≠ÁªÉËßÜËßâÊ†áËÆ∞Ââ™ÊûùÊñπÊ≥ïÔºåÁß∞‰∏∫ G-Prune„ÄÇÁâπÂà´ÊòØÔºåG-Prune Â∞ÜËßÜËßâÊ†áËÆ∞ËßÜ‰∏∫ËäÇÁÇπÔºåÂπ∂Ê†πÊçÆÂÖ∂ËØ≠‰πâÁõ∏‰ººÊÄßÊûÑÂª∫ÂÆÉ‰ª¨ÁöÑËøûÊé•„ÄÇ‰πãÂêéÔºå‰ø°ÊÅØÊµÅÈÄöËøáÂä†ÊùÉÈìæÊé•‰º†Êí≠ÔºåÂπ∂‰∏îÂú®Ëø≠‰ª£ÂêéÊúÄÈáçË¶ÅÁöÑÊ†áËÆ∞‰øùÁïôÁî®‰∫é MLLMÔºåÂÆÉÂèØ‰ª•ÊòØÂâçÊôØÊàñËÉåÊôØ„ÄÇ‰∏∫‰∫ÜÈ™åËØÅ G-PruneÔºåÊàë‰ª¨Â∞ÜÂÖ∂Â∫îÁî®‰∫éÁß∞‰∏∫ LLaVA-NeXT ÁöÑÊúÄÊñ∞ MLLMÔºåÂπ∂Âú®‰∏ÄÁªÑÂü∫ÂáÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™å„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåG-Prune ÂèØ‰ª•ÊûÅÂ§ßÂú∞ÂáèÂ∞ëËÆ°ÁÆóÂºÄÈîÄÔºåÂêåÊó∂Âú®Á≤óÁ≤íÂ∫¶ÂíåÁªÜÁ≤íÂ∫¶‰ªªÂä°‰∏ä‰øùÊåÅÈ´òÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåG-Prune ÂèØ‰ª•Â∞Ü LLaVA-NeXT Âú® VQA2.0 Âíå TextVQA ‰∏äÁöÑ FLOP ÂáèÂ∞ë 63.57%ÔºåËÄåÂáÜÁ°ÆÂ∫¶ÂàÜÂà´‰ªÖ‰∏ãÈôç 0.95% Âíå 2.34%„ÄÇ

##### **Personalized Graph-Based Retrieval for Large Language Models**
2501.02157v1 by Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

As large language models (LLMs) evolve, their ability to deliver personalized
and context-aware responses offers transformative potential for improving user
experiences. Existing personalization approaches, however, often rely solely on
user history to augment the prompt, limiting their effectiveness in generating
tailored outputs, especially in cold-start scenarios with sparse data. To
address these limitations, we propose Personalized Graph-based
Retrieval-Augmented Generation (PGraphRAG), a framework that leverages
user-centric knowledge graphs to enrich personalization. By directly
integrating structured user knowledge into the retrieval process and augmenting
prompts with user-relevant context, PGraphRAG enhances contextual understanding
and output quality. We also introduce the Personalized Graph-based Benchmark
for Text Generation, designed to evaluate personalized text generation tasks in
real-world settings where user history is sparse or unavailable. Experimental
results show that PGraphRAG significantly outperforms state-of-the-art
personalization methods across diverse tasks, demonstrating the unique
advantages of graph-based retrieval for personalization.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊºîÈÄ≤ÔºåÂÆÉÂÄëÊèê‰æõÂÄã‰∫∫ÂåñÂíåÊÉÖÂ¢ÉÊÑüÁü•ÂõûÊáâÁöÑËÉΩÂäõÔºåÁÇ∫ÊèêÂçá‰ΩøÁî®ËÄÖÈ´îÈ©óÊèê‰æõ‰∫ÜËÆäÈù©ÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂÄã‰∫∫ÂåñÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖ‰æùË≥¥‰ΩøÁî®ËÄÖË®òÈåÑ‰æÜÊì¥ÂÖÖÊèêÁ§∫ÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Áî¢ÁîüÂÆ¢Ë£ΩÂåñËº∏Âá∫ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ë≥áÊñôÁ®ÄÁñèÁöÑÂÜ∑ÂïüÂãïÊÉÖÂ¢É‰∏≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåÂÄã‰∫∫ÂåñÂúñÂΩ¢ÂåñÊ™¢Á¥¢Êì¥ÂÖÖÁî¢Áîü„Äç(PGraphRAG)Ôºå‰∏ÄÂÄãÂà©Áî®‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁü•Ë≠òÂúñÂΩ¢‰æÜË±êÂØåÂÄã‰∫∫ÂåñÁöÑÊû∂Êßã„ÄÇÈÄèÈÅéÂ∞áÁµêÊßãÂåñÁöÑ‰ΩøÁî®ËÄÖÁü•Ë≠òÁõ¥Êé•Êï¥ÂêàÂà∞Ê™¢Á¥¢Á®ãÂ∫è‰∏≠Ôºå‰∏¶‰ΩøÁî®Ëàá‰ΩøÁî®ËÄÖÁõ∏ÈóúÁöÑÂÖßÂÆπÊì¥ÂÖÖÊèêÁ§∫ÔºåPGraphRAG Â¢ûÂº∑‰∫ÜÊÉÖÂ¢ÉÁêÜËß£ÂíåËº∏Âá∫ÂìÅË≥™„ÄÇÊàëÂÄë‰πüÂºïÂÖ•‰∫Ü„ÄåÂÄã‰∫∫ÂåñÂúñÂΩ¢ÂåñÂü∫Ê∫ñÊñáÊú¨Áî¢Áîü„ÄçÔºåÊó®Âú®Ë©ï‰º∞Âú®‰ΩøÁî®ËÄÖË®òÈåÑÁ®ÄÁñèÊàñ‰∏çÂèØÁî®ÁöÑÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÁöÑÂÄã‰∫∫ÂåñÊñáÊú¨Áî¢Áîü‰ªªÂãô„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåPGraphRAG Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠È°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂÄã‰∫∫ÂåñÊñπÊ≥ïÔºåË≠âÊòé‰∫ÜÂúñÂΩ¢ÂåñÊ™¢Á¥¢Âú®ÂÄã‰∫∫ÂåñÊñπÈù¢ÁöÑÁç®ÁâπÂÑ™Âã¢„ÄÇ

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v1 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

ÊëòË¶ÅÔºöÂÜ∑ÂïüÂãïÂïèÈ°åÊòØÊé®Ëñ¶Á≥ªÁµ±‰∏≠Èï∑‰πÖ‰ª•‰æÜÁöÑÊåëÊà∞‰πã‰∏ÄÔºåÂ∞àÊ≥®ÊñºÊ∫ñÁ¢∫Âª∫Ê®°Êñ∞‰ΩøÁî®ËÄÖÊàñ‰∫íÂãïÊúâÈôêÁöÑ‰ΩøÁî®ËÄÖÊàñÈ†ÖÁõÆÔºå‰ª•Êèê‰æõÊõ¥Â•ΩÁöÑÊé®Ëñ¶„ÄÇÁî±ÊñºÁ∂≤Ë∑ØÂπ≥Âè∞ÁöÑÂ§öÊ®£Âåñ‰ª•Âèä‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÁöÑÊåáÊï∏Á¥öÂ¢ûÈï∑ÔºåÂÜ∑ÂïüÂãïÊé®Ëñ¶ (CSR) ÁöÑÈáçË¶ÅÊÄßËÆäÂæóË∂ä‰æÜË∂äÊòéÈ°Ø„ÄÇÂêåÊôÇÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÂèñÂæóÂ∑®Â§ßÁöÑÊàêÂäüÔºå‰∏¶ÂÖ∑ÂÇôÂª∫Ê®°‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆË≥áË®äÁöÑÂº∑Â§ßËÉΩÂäõÔºåÁÇ∫ÂÜ∑ÂïüÂãïÊé®Ëñ¶Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåCSR ÁöÑÁ†îÁ©∂Á§æÁæ§‰ªçÁÑ∂Áº∫‰πèÂ∞çÊ≠§È†òÂüüÁöÑÂÖ®Èù¢ÂõûÈ°ßÂíåÂèçÊÄù„ÄÇÂü∫ÊñºÊ≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ´ôÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊôÇ‰ª£ËÉåÊôØ‰∏ãÔºåÂ∞ç CSR ÁöÑË∑ØÁ∑öÂúñ„ÄÅÁõ∏ÈóúÊñáÁçªÂíåÊú™‰æÜÊñπÂêëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂõûÈ°ßÂíåË®éË´ñ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁèæÊúâ CSR Â¶Ç‰ΩïÂà©Áî®Ë≥áË®äÁöÑÁôºÂ±ïË∑ØÂæëÔºåÂæûÂÖßÂÆπÁâπÂæµ„ÄÅÂúñÂΩ¢Èóú‰øÇÂíåÈ†òÂüüË≥áË®äÔºåÂà∞Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊâÄÊìÅÊúâÁöÑ‰∏ñÁïåÁü•Ë≠òÔºåÊó®Âú®ÁÇ∫Á†îÁ©∂ÂíåÁî¢Ê•≠Á§æÁæ§Âú® CSR ‰∏äÊèê‰æõÊñ∞ÁöÑË¶ãËß£„ÄÇÂÜ∑ÂïüÂãïÊé®Ëñ¶ÁöÑÁõ∏ÈóúË≥áÊ∫êÂ∑≤Êî∂ÈõÜ‰∏¶ÊåÅÁ∫åÊõ¥Êñ∞Ôºå‰æõÁ§æÁæ§Âú® https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation ‰∏≠‰ΩøÁî®„ÄÇ

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

ÊëòË¶ÅÔºöÁîüÁâ©ÂåªÂ≠¶Áü•Ë≠òÂúñË≠ú (BKG) Êï¥ÂêàÂ§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰ª•Èó°ÊòéÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÂÖßÁöÑË§áÈõúÈóú‰øÇ„ÄÇÂú®ÈÄô‰∫õÂúñË≠ú‰∏äÈÄ≤Ë°åÊúâÊïàÁöÑÈÄ£ÁµêÈ†êÊ∏¨ÔºåÂèØ‰ª•ÁôºÁèæÊúâÂÉπÂÄºÁöÑÈÄ£ÁµêÔºå‰æãÂ¶ÇÊΩõÂú®ÁöÑÊñ∞Ëó•Áâ©-ÁñæÁóÖÈóú‰øÇ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÊñπÊ≥ïÔºåÂÆÉÂ∞á‰æÜËá™Â∞àÁî®Ë™ûË®ÄÊ®°Âûã (LM) ÁöÑÂµåÂÖ•ËàáÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí (GCL) Áµ±‰∏ÄËµ∑‰æÜÔºå‰ª•Â¢ûÂº∑ÂØ¶È´îÂÖßÈóú‰øÇÔºåÂêåÊôÇÊé°Áî®Áü•Ë≠òÂúñÂΩ¢ÂµåÂÖ• (KGE) Ê®°Âûã‰æÜÊçïÊçâÂØ¶È´îÈñìÈóú‰øÇÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑÈÄ£ÁµêÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÁèæÊúâ BKG ‰∏≠ÁöÑÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PrimeKG++ÔºåÈÄôÊòØ‰∏ÄÂÄãË±êÂØåÁöÑÁü•Ë≠òÂúñÂΩ¢ÔºåÂÆÉÁµêÂêà‰∫ÜÂ§öÊ®°ÊÖãÊï∏ÊìöÔºåÂåÖÊã¨ÊØèÁ®ÆÈ°ûÂûãÂØ¶È´îÁöÑÁîüÁâ©Â∫èÂàóÂíåÊñáÂ≠óÊèèËø∞„ÄÇÈÄöÈÅéÂú®Áµ±‰∏ÄË°®Á§∫‰∏≠ÁµêÂêàË™ûÁæ©ÂíåÈóú‰øÇË≥áË®äÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊ¶ÇÊã¨ÊÄßÔºåÂç≥‰ΩøÂ∞çÊñºÊú™Ë¶ãÁØÄÈªû‰πüËÉΩÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑÈÄ£ÁµêÈ†êÊ∏¨„ÄÇÂú® PrimeKG++ Âíå DrugBank Ëó•Áâ©-Ê®ôÈù∂‰∫§‰∫í‰ΩúÁî®Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ¢º„ÄÅÈ†êË®ìÁ∑¥Ê®°ÂûãÂíåË≥áÊñôÂèØÂú® https://github.com/HySonLab/BioMedKG ÂÖ¨ÈñãÂèñÂæó„ÄÇ

##### **Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**
2501.02020v1 by Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He

Large Language Models (LLMs) are prone to hallucination with non-factual or
unfaithful statements, which undermines the applications in real-world
scenarios. Recent researches focus on uncertainty-based hallucination
detection, which utilizes the output probability of LLMs for uncertainty
calculation and does not rely on external knowledge or frequent sampling from
LLMs. Whereas, most approaches merely consider the uncertainty of each
independent token, while the intricate semantic relations among tokens and
sentences are not well studied, which limits the detection of hallucination
that spans over multiple tokens and sentences in the passage. In this paper, we
propose a method to enhance uncertainty modeling with semantic graph for
hallucination detection. Specifically, we first construct a semantic graph that
well captures the relations among entity tokens and sentences. Then, we
incorporate the relations between two entities for uncertainty propagation to
enhance sentence-level hallucination detection. Given that hallucination occurs
due to the conflict between sentences, we further present a graph-based
uncertainty calibration method that integrates the contradiction probability of
the sentence with its neighbors in the semantic graph for uncertainty
calculation. Extensive experiments on two datasets show the great advantages of
our proposed approach. In particular, we obtain substantial improvements with
19.78% in passage-level hallucination detection.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÆπÊòìÂá∫ÁèæÈùû‰∫ãÂØ¶ÊÄßÊàñ‰∏çÂø†ÂØ¶ÁöÑÈô≥Ëø∞ÔºåÈÄôÊúÉÁ†¥Â£ûÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÊáâÁî®„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÈáçÈªûÈóúÊ≥®Âü∫Êñº‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂπªË¶∫Ê™¢Ê∏¨ÔºåÂÆÉÂà©Áî® LLM ÁöÑËº∏Âá∫Ê©üÁéáÈÄ≤Ë°å‰∏çÁ¢∫ÂÆöÊÄßË®àÁÆóÔºå‰∏¶‰∏î‰∏ç‰æùË≥¥ÊñºÂ§ñÈÉ®Áü•Ë≠òÊàñÂæû LLM ‰∏≠È†ªÁπÅÂèñÊ®£„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÊñπÊ≥ïÂÉÖËÄÉÊÖÆÊØèÂÄãÁç®Á´ãÁ¨¶ËôüÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåËÄåÁ¨¶ËôüÂíåÂè•Â≠ê‰πãÈñìÁöÑË§áÈõúË™ûÁæ©Èóú‰øÇÂ∞öÊú™ÂæóÂà∞ÂæàÂ•ΩÁöÑÁ†îÁ©∂ÔºåÈÄôÈôêÂà∂‰∫ÜÂ∞çË∑®Ë∂äÊÆµËêΩ‰∏≠Â§öÂÄãÁ¨¶ËôüÂíåÂè•Â≠êÁöÑÂπªË¶∫ÁöÑÊ™¢Ê∏¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Ë™ûÁæ©ÂúñÂ¢ûÂº∑‰∏çÁ¢∫ÂÆöÊÄßÂª∫Ê®°‰ª•ÈÄ≤Ë°åÂπªË¶∫Ê™¢Ê∏¨ÁöÑÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÊßãÂª∫‰∏ÄÂÄãË™ûÁæ©ÂúñÔºåÂÆÉÂæàÂ•ΩÂú∞ÊçïÊçâ‰∫ÜÂØ¶È´îÁ¨¶ËôüÂíåÂè•Â≠ê‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÂÖ©ÂÄãÂØ¶È´î‰πãÈñìÁöÑÈóú‰øÇÁ¥çÂÖ•‰∏çÁ¢∫ÂÆöÊÄßÂÇ≥Êí≠Ôºå‰ª•Â¢ûÂº∑Âè•Â≠êÁ¥öÂà•ÁöÑÂπªË¶∫Ê™¢Ê∏¨„ÄÇÁî±ÊñºÂπªË¶∫ÊòØÂõ†Âè•Â≠ê‰πãÈñìÁöÑË°ùÁ™ÅËÄåÁôºÁîüÁöÑÔºåÂõ†Ê≠§ÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂúñÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊ†°Ê∫ñÊñπÊ≥ïÔºåÂÆÉÂ∞áÂè•Â≠êÁöÑÁüõÁõæÊ©üÁéáËàáÂÖ∂Âú®Ë™ûÁæ©Âúñ‰∏≠ÁöÑÈÑ∞Â±ÖÁµêÂêàËµ∑‰æÜÈÄ≤Ë°å‰∏çÁ¢∫ÂÆöÊÄßË®àÁÆó„ÄÇÂú®ÂÖ©ÂÄãÊï∏ÊìöÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÂ∑®Â§ßÂÑ™Âã¢„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂú®ÊÆµËêΩÁ¥öÂà•ÁöÑÂπªË¶∫Ê™¢Ê∏¨‰∏≠Áç≤Âæó‰∫Ü 19.78% ÁöÑÈ°ØËëóÊîπÈÄ≤„ÄÇ

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

ÊëòË¶ÅÔºöÂú®Ë≥áË®äÂø´ÈÄüËÆäÈÅ∑ÁöÑÈ†òÂüü‰∏≠ÔºåÂæûÂ§ßÈáèÁöÑ‰∫ã‰ª∂Áõ∏ÈóúÂÖßÂÆπÂª∫ÊßãÈÄ£Ë≤´ÁöÑÊôÇÈñìËª∏ÁöÑËÉΩÂäõËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇË§áÈõúÊÄßÂú®ÊñºÂΩôÁ∏ΩÁõ∏ÈóúÊñá‰ª∂Ôºå‰ª•ÂúçÁπû‰∏≠ÂøÉ‰∏ªÈ°åÂª∫Á´ãÊúâÊÑèÁæ©ÁöÑ‰∫ã‰ª∂Âúñ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü CHRONOS - ÈñãÊîæÈ†òÂüüÊñ∞ËÅûÊôÇÈñìËª∏ÊëòË¶ÅÁöÑÂõ†ÊûúÊ®ôÈ°åÊ™¢Á¥¢ÔºåÈÄèÈÅéÂèçË¶ÜËá™ÊàëÊèêÂïèÔºåÊèê‰æõÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËôïÁêÜÊôÇÈñìËª∏ÊëòË¶Å (TLS) ‰ªªÂãôÁöÑÊñ∞ËßÄÈªû„ÄÇÈÄèÈÅéÂèçË¶ÜÊÄùËÄÉ‰∫ã‰ª∂Â¶Ç‰ΩïÈÄ£ÁµêÔºå‰∏¶Â∞çÁâπÂÆöÊñ∞ËÅû‰∏ªÈ°åÊèêÂá∫Êñ∞ÂïèÈ°åÔºå‰ª•ÂæûÁ∑ö‰∏äÊàñÈõ¢Á∑öÁü•Ë≠òÂ∫´Êî∂ÈõÜË≥áË®äÔºåLLM ÊúÉÊ†πÊìöÊØèËº™Ê™¢Á¥¢ÁöÑÊñá‰ª∂Áî¢Áîü‰∏¶Êõ¥Êñ∞ÊôÇÈñìÊëòË¶Å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü Open-TLSÔºå‰∏ÄÂÄãÁî±Â∞àÊ•≠Ë®òËÄÖÁ∑®ÂØ´ÁöÑËøëÊúüÊñ∞ËÅû‰∏ªÈ°åÊôÇÈñìËª∏ÁöÑÊñ∞Á©éË≥áÊñôÈõÜÔºå‰ª•Ë©ï‰º∞ÈñãÊîæÈ†òÂüüÁöÑ TLSÔºåÂÖ∂‰∏≠Ë≥áË®äÈÅéËºâ‰ΩøÂæóÁÑ°Ê≥ïÂæûÁ∂≤Ë∑Ø‰∏äÊâæÂà∞ÂÖ®Èù¢ÁöÑÁõ∏ÈóúÊñá‰ª∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåCHRONOS ‰∏çÂÉÖÊìÖÈï∑ÈñãÊîæÈ†òÂüüÁöÑÊôÇÈñìËª∏ÊëòË¶ÅÔºåËÄå‰∏îÈÇÑËàáÂ∞àÁÇ∫Â∞ÅÈñâÈ†òÂüüÊáâÁî®Ë®≠Ë®àÁöÑÁèæÊúâÊúÄÂÖàÈÄ≤Á≥ªÁµ±ÁöÑÊïàËÉΩÁõ∏Â™≤ÁæéÔºåÂÖ∂‰∏≠Êèê‰æõ‰∫ÜÁõ∏ÈóúÁöÑÊñ∞ËÅûË™ûÊñôÂ∫´Áî®ÊñºÊëòË¶Å„ÄÇ

##### **Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**
2501.03257v1 by Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin

Recently, end-to-end automatic speech recognition has become the mainstream
approach in both industry and academia. To optimize system performance in
specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively
used to integrate acoustic and language models, leveraging its capacity to
implicitly fuse language models within static graphs, thereby ensuring robust
recognition while also facilitating rapid error correction. However, WFST
necessitates a frame-by-frame search of CTC posterior probabilities through
autoregression, which significantly hampers inference speed. In this work, we
thoroughly investigate the spike property of CTC outputs and further propose
the conjecture that adjacent frames to non-blank spikes carry semantic
information beneficial to the model. Building on this, we propose the Spike
Window Decoding algorithm, which greatly improves the inference speed by making
the number of frames decoded in WFST linearly related to the number of spiking
frames in the CTC output, while guaranteeing the recognition performance. Our
method achieves SOTA recognition accuracy with significantly accelerates
decoding speed, proven across both AISHELL-1 and large-scale In-House datasets,
establishing a pioneering approach for integrating CTC output with WFST.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåÁ´ØÂà∞Á´ØÁöÑËá™Âä®ËØ≠Èü≥ËØÜÂà´Â∑≤Êàê‰∏∫Â∑•‰∏öÁïåÂíåÂ≠¶ÊúØÁïåÁöÑÊµÅË°åÊñπÊ≥ï„ÄÇ‰∏∫‰∫Ü‰ºòÂåñÁâπÂÆöÂú∫ÊôØ‰∏≠ÁöÑÁ≥ªÁªüÊÄßËÉΩÔºåÂä†ÊùÉÊúâÈôêÁä∂ÊÄÅËΩ¨Êç¢Âô® (WFST) Ë¢´ÂπøÊ≥õÁî®‰∫éÈõÜÊàêÂ£∞Â≠¶ÂíåËØ≠Ë®ÄÊ®°ÂûãÔºåÂà©Áî®ÂÖ∂Âú®ÈùôÊÄÅÂõæ‰∏≠ÈöêÂºèËûçÂêàËØ≠Ë®ÄÊ®°ÂûãÁöÑËÉΩÂäõÔºå‰ªéËÄåÁ°Æ‰øùÁ®≥ÂÅ•ÁöÑËØÜÂà´ÔºåÂêåÊó∂‰øÉËøõÂø´ÈÄüÁ∫†Èîô„ÄÇÁÑ∂ËÄåÔºåWFST ÈúÄË¶ÅÈÄöËøáËá™ÂõûÂΩíÈÄêÂ∏ßÊêúÁ¥¢ CTC ÂêéÈ™åÊ¶ÇÁéáÔºåËøôÊûÅÂ§ßÂú∞ÈòªÁ¢ç‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂΩªÂ∫ïÁ†îÁ©∂‰∫Ü CTC ËæìÂá∫ÁöÑÂ∞ñÂ≥∞ÁâπÊÄßÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÊèêÂá∫‰∏Ä‰∏™ÁåúÊÉ≥ÔºåÂç≥ÈùûÁ©∫ÁôΩÂ∞ñÂ≥∞ÁöÑÁõ∏ÈÇªÂ∏ßÊê∫Â∏¶ÂØπÊ®°ÂûãÊúâÁõäÁöÑËØ≠‰πâ‰ø°ÊÅØ„ÄÇÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Spike Window Ëß£Á†ÅÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÈÄöËøá‰Ωø WFST ‰∏≠Ëß£Á†ÅÁöÑÂ∏ßÊï∞‰∏é CTC ËæìÂá∫‰∏≠Â∞ñÂ≥∞Â∏ßÊï∞Á∫øÊÄßÁõ∏ÂÖ≥ÔºåÂêåÊó∂‰øùËØÅËØÜÂà´ÊÄßËÉΩÔºåÊûÅÂ§ßÂú∞ÊèêÈ´ò‰∫ÜÊé®ÁêÜÈÄüÂ∫¶„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® AISHELL-1 ÂíåÂ§ßËßÑÊ®°ÂÜÖÈÉ®Êï∞ÊçÆÈõÜ‰∏äÈÉΩÂÆûÁé∞‰∫Ü SOTA ËØÜÂà´ÂáÜÁ°ÆÂ∫¶ÔºåÂπ∂ÊòæËëóÂä†Âø´‰∫ÜËß£Á†ÅÈÄüÂ∫¶Ôºå‰∏∫Â∞Ü CTC ËæìÂá∫‰∏é WFST ÈõÜÊàêÂª∫Á´ã‰∫ÜÂÖàÈ©±ÊñπÊ≥ï„ÄÇ

##### **SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**
2501.01998v1 by Mao Xun Huang, Hen-Hsen Huang

Stable Diffusion models have made remarkable strides in generating
photorealistic images from text prompts but often falter when tasked with
accurately representing complex spatial arrangements, particularly involving
intricate 3D relationships. To address this limitation, we introduce
SmartSpatial, an innovative approach that enhances the spatial arrangement
capabilities of Stable Diffusion models through 3D-aware conditioning and
attention-guided mechanisms. SmartSpatial incorporates depth information and
employs cross-attention control to ensure precise object placement, delivering
notable improvements in spatial accuracy metrics. In conjunction with
SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework
designed to assess spatial relationships. This framework utilizes
vision-language models and graph-based dependency parsing for performance
analysis. Experimental results on the COCO and SpatialPrompts datasets show
that SmartSpatial significantly outperforms existing methods, setting new
benchmarks for spatial arrangement accuracy in image generation.

ÊëòË¶ÅÔºöStable Diffusion Ê®°ÂûãÂú®Ê†πÊìöÊñáÂ≠óÊèêÁ§∫ÁîüÊàêÈÄºÁúüÁöÑÂΩ±ÂÉèÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÂú®Ê∫ñÁ¢∫ÂëàÁèæË§áÈõúÁöÑÁ©∫ÈñìÈÖçÁΩÆÊôÇÔºåÁâπÂà•ÊòØÊ∂âÂèäË§áÈõúÁöÑ 3D Èóú‰øÇÊôÇÔºåÂ∏∏Â∏∏ÊúÉÂ§±Êïó„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü SmartSpatialÔºåÈÄôÊòØ‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅé 3D ÊÑüÁü•Ê¢ù‰ª∂ÂíåÊ≥®ÊÑèÂäõÂºïÂ∞éÊ©üÂà∂ÔºåÂ¢ûÂº∑ Stable Diffusion Ê®°ÂûãÁöÑÁ©∫ÈñìÈÖçÁΩÆËÉΩÂäõ„ÄÇSmartSpatial ÁµêÂêàÊ∑±Â∫¶Ë≥áË®ä‰∏¶Êé°Áî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊéßÂà∂Ôºå‰ª•Á¢∫‰øùÁ≤æÁ¢∫ÁöÑÁâ©‰ª∂ÊîæÁΩÆÔºåÂú®Á©∫ÈñìÊ∫ñÁ¢∫Â∫¶ÊåáÊ®ôÊñπÈù¢Â∏∂‰æÜÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÁµêÂêà SmartSpatialÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SmartSpatialEvalÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË©ï‰º∞Êû∂ÊßãÔºåÊó®Âú®Ë©ï‰º∞Á©∫ÈñìÈóú‰øÇ„ÄÇÈÄôÂÄãÊû∂ÊßãÂà©Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂíåÂü∫ÊñºÂúñÂΩ¢ÁöÑ‰æùÂ≠òÂàÜÊûêÈÄ≤Ë°åÊïàËÉΩÂàÜÊûê„ÄÇÂú® COCO Âíå SpatialPrompts Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåSmartSpatial ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÁÇ∫ÂΩ±ÂÉèÁîüÊàêÁöÑÁ©∫ÈñìÈÖçÁΩÆÊ∫ñÁ¢∫Â∫¶Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**
2501.00581v1 by Yipeng Kang, Junqi Wang, Yexin Li, Fangwei Zhong, Xue Feng, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Zilong Zheng

As large language models (LLMs) become increasingly integrated into critical
applications, aligning their behavior with human values presents significant
challenges. Current methods, such as Reinforcement Learning from Human Feedback
(RLHF), often focus on a limited set of values and can be resource-intensive.
Furthermore, the correlation between values has been largely overlooked and
remains underutilized. Our framework addresses this limitation by mining a
causal graph that elucidates the implicit relationships among various values
within the LLMs. Leveraging the causal graph, we implement two lightweight
mechanisms for value steering: prompt template steering and Sparse Autoencoder
feature steering, and analyze the effects of altering one value dimension on
others. Extensive experiments conducted on Gemma-2B-IT and Llama3-8B-IT
demonstrate the effectiveness and controllability of our steering methods.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êó•ÁõäÊï¥ÂêàÂà∞ÈóúÈçµÊáâÁî®Á®ãÂºè‰∏≠ÔºåËÆìÂÖ∂Ë°åÁÇ∫Ëàá‰∫∫È°ûÂÉπÂÄºËßÄ‰∏ÄËá¥ÊúÉÂ∏∂‰æÜÈáçÂ§ßÊåëÊà∞„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÔºå‰æãÂ¶Ç‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF)ÔºåÈÄöÂ∏∏Â∞àÊ≥®ÊñºÊúâÈôêÁöÑÂÉπÂÄºËßÄÔºå‰∏îÂèØËÉΩËÄóË≤ªÂ§ßÈáèË≥áÊ∫ê„ÄÇÊ≠§Â§ñÔºåÂÉπÂÄºËßÄ‰πãÈñìÁöÑÈóúËÅØÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äË¢´ÂøΩË¶ñÔºå‰∏îÊú™Ë¢´ÂÖÖÂàÜÂà©Áî®„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈÄèÈÅéÊé¢ÂãòÂõ†ÊûúÂúñË°®‰æÜËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåË©≤ÂúñË°®Èó°Êòé‰∫Ü LLM ‰∏≠ÂêÑÁ®ÆÂÉπÂÄºËßÄ‰πãÈñìÁöÑÈö±Âê´Èóú‰øÇ„ÄÇÂà©Áî®Âõ†ÊûúÂúñË°®ÔºåÊàëÂÄëÂØ¶‰Ωú‰∫ÜÂÖ©Á®ÆËºïÈáèÁ¥öÁöÑÂÉπÂÄºÂºïÂ∞éÊ©üÂà∂ÔºöÊèêÁ§∫ÁØÑÊú¨ÂºïÂ∞éÂíåÁ®ÄÁñèËá™Á∑®Á¢ºÂô®ÁâπÂæµÂºïÂ∞éÔºå‰∏¶ÂàÜÊûê‰∫ÜÊîπËÆä‰∏ÄÂÄãÂÉπÂÄºÁ∂≠Â∫¶Â∞çÂÖ∂‰ªñÁ∂≠Â∫¶ÁöÑÂΩ±Èüø„ÄÇÂú® Gemma-2B-IT Âíå Llama3-8B-IT ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂºïÂ∞éÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÂèØÊéßÊÄß„ÄÇ

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

ÊëòË¶ÅÔºöÂú®Ê≠§ÔºåÊàë‰ª¨ÊèèËø∞‰∫ÜÁ¨¨‰∏Ä‰∏™ Web Á∫ßÊ∑∑ÂêàÁü•ËØÜÂõæË∞± (KG) - Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)ÔºåÂÖ∂‰∏≠ÂÖÖÊñ•ÁùÄÊúâÂÖ≥ÁªìÁõ¥ËÇ†ÁôåÁöÑÊúÄÊñ∞ÂêåË°åËØÑÂÆ°ÂåªÂ≠¶Áü•ËØÜ„ÄÇÁõÆÂâçÊ≠£Âú®ËØÑ‰º∞ÂÆÉ‰ª•ÂçèÂä© Moffitt ÁôåÁóá‰∏≠ÂøÉËøõË°åÂåªÂ≠¶Á†îÁ©∂Âíå‰∏¥Â∫ä‰ø°ÊÅØÊ£ÄÁ¥¢‰ªªÂä°ÔºåËØ•‰∏≠ÂøÉÊòØÁæéÂõΩÂíå‰∏ñÁïåÈ°∂Á∫ßÁôåÁóá‰∏≠ÂøÉ‰πã‰∏Ä„ÄÇÊàë‰ª¨ÁöÑÊ∑∑Âêà‰ΩìÈùûÂ∏∏Âá∫Ëâ≤ÔºåÂõ†‰∏∫ÂÆÉÊØîÂ≠§Á´ãÁöÑ LLM„ÄÅKG ÊàñÊêúÁ¥¢ÂºïÊìéÊõ¥Â•ΩÂú∞Êª°Ë∂≥Áî®Êà∑ÈúÄÊ±Ç„ÄÇ‰ºóÊâÄÂë®Áü•ÔºåLLM ‰ºöÂá∫Áé∞ÂπªËßâÂíåÁÅæÈöæÊÄßÈÅóÂøòÔºåÂπ∂‰∏îÊòØÂú®ËøáÊó∂ÁöÑËØ≠ÊñôÂ∫ì‰∏äËøõË°åËÆ≠ÁªÉÁöÑ„ÄÇÊúÄÂÖàËøõÁöÑ KGÔºå‰æãÂ¶Ç PrimeKG„ÄÅcBioPortal„ÄÅChEMBL„ÄÅNCBI Á≠âÈúÄË¶Å‰∫∫Â∑•Êï¥ÁêÜÔºåÂõ†Ê≠§ÂæàÂø´Â∞±‰ºöËøáÊó∂„ÄÇCancerKG Êó†ÈúÄÁõëÁù£ÔºåËÉΩÂ§üËá™Âä®ÊëÑÂèñÂíåÁªÑÁªáÊúÄÊñ∞ÁöÑÂåªÂ≠¶ÂèëÁé∞„ÄÇ‰∏∫‰∫ÜÂáèËΩª LLM ÁöÑÁº∫ÁÇπÔºåÁªèËøáÈ™åËØÅÁöÑ KG ÂÖÖÂΩìÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) Êä§Ê†è„ÄÇCancerKG Â±ïÁ§∫‰∫Ü 5 Áßç‰∏çÂêåÁöÑÈ´òÁ∫ßÁî®Êà∑ÁïåÈù¢ÔºåÊØèÁßçÁïåÈù¢ÈÉΩÈíàÂØπÊúçÂä°‰∏çÂêåÁöÑÊï∞ÊçÆÊ®°ÂºèÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Â•Ω„ÄÅÊõ¥Êñπ‰æøÁöÑÊúçÂä°„ÄÇ

##### **The Potential of LLMs in Automating Software Testing: From Generation to Reporting**
2501.00217v1 by Betim Sherifi, Khaled Slhoub, Fitzroy Nembhard

Having a high quality software is essential in software engineering, which
requires robust validation and verification processes during testing
activities. Manual testing, while effective, can be time consuming and costly,
leading to an increased demand for automated methods. Recent advancements in
Large Language Models (LLMs) have significantly influenced software
engineering, particularly in areas like requirements analysis, test automation,
and debugging. This paper explores an agent-oriented approach to automated
software testing, using LLMs to reduce human intervention and enhance testing
efficiency. The proposed framework integrates LLMs to generate unit tests,
visualize call graphs, and automate test execution and reporting. Evaluations
across multiple applications in Python and Java demonstrate the system's high
test coverage and efficient operation. This research underscores the potential
of LLM-powered agents to streamline software testing workflows while addressing
challenges in scalability and accuracy.

ÊëòË¶ÅÔºöÂú®ËªüÈ´îÂ∑•Á®ã‰∏≠ÔºåÊìÅÊúâÈ´òÂìÅË≥™ÁöÑËªüÈ´îËá≥ÈóúÈáçË¶ÅÔºåÈÄôÈúÄË¶ÅÂú®Ê∏¨Ë©¶Ê¥ªÂãï‰∏≠ÈÄ≤Ë°åÂº∑ÂÅ•ÁöÑÈ©óË≠âÂíåÈ©óË≠âÁ®ãÂ∫è„ÄÇÊâãÂãïÊ∏¨Ë©¶ÈõñÁÑ∂ÊúâÊïàÔºå‰ΩÜÂèØËÉΩËÄóÊôÇ‰∏îÊàêÊú¨È´òÊòÇÔºåÂ∞éËá¥Â∞çËá™ÂãïÂåñÊñπÊ≥ïÁöÑÈúÄÊ±ÇÂ¢ûÂä†„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÂΩ±Èüø‰∫ÜËªüÈ´îÂ∑•Á®ãÔºåÁâπÂà•ÊòØÂú®ÈúÄÊ±ÇÂàÜÊûê„ÄÅÊ∏¨Ë©¶Ëá™ÂãïÂåñÂíåÈô§ÈåØÁ≠âÈ†òÂüü„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏ÄÁ®ÆÈù¢Âêë‰ª£ÁêÜÁöÑËá™ÂãïÂåñËªüÈ´îÊ∏¨Ë©¶ÊñπÊ≥ïÔºå‰ΩøÁî® LLM ‰æÜÊ∏õÂ∞ë‰∫∫Â∑•Âπ≤È†ê‰∏¶ÊèêÈ´òÊ∏¨Ë©¶ÊïàÁéá„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êï¥Âêà‰∫Ü LLM ‰æÜÁî¢ÁîüÂñÆÂÖÉÊ∏¨Ë©¶„ÄÅË¶ñË¶∫ÂåñÂëºÂè´ÂúñË°®‰ª•ÂèäËá™ÂãïÂåñÊ∏¨Ë©¶Âü∑Ë°åÂíåÂ†±Âëä„ÄÇÂú® Python Âíå Java ‰∏≠ÁöÑË∑®Â§öÂÄãÊáâÁî®Á®ãÂºèÁöÑË©ï‰º∞Ë≠âÊòé‰∫ÜÁ≥ªÁµ±ÁöÑÈ´òÊ∏¨Ë©¶Ë¶ÜËìãÁéáÂíåÈ´òÊïàÈÅã‰Ωú„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫Ü LLM È©ÖÂãïÁöÑ‰ª£ÁêÜÂú®Á∞°ÂåñËªüÈ´îÊ∏¨Ë©¶Â∑•‰ΩúÊµÅÁ®ãÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂêåÊôÇÊáâÂ∞çÂèØÊì¥ÂÖÖÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÊñπÈù¢ÁöÑÊåëÊà∞„ÄÇ

##### **Detection-Fusion for Knowledge Graph Extraction from Videos**
2501.00136v1 by Taniya Das, Louis Mahon, Thomas Lukasiewicz

One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.

ÊëòË¶ÅÔºöÂΩ±ÁâáÁêÜËß£È†òÂüü‰∏≠‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÊòØÂæûÂΩ±ÁâáËº∏ÂÖ•‰∏≠ËêÉÂèñË™ûÊÑèÂÖßÂÆπ„ÄÇÁèæÊúâÁöÑÂ§ßÈÉ®ÂàÜÁ≥ªÁµ±‰ΩøÁî®Ë™ûË®ÄÊ®°Âûã‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÂè•Â≠êÊèèËø∞ÂΩ±ÁâáÔºå‰ΩÜÈÄôÊúâÂπæÂÄã‰∏ªË¶ÅÁöÑÁº∫Èªû„ÄÇÊ≠§È°ûÁ≥ªÁµ±ÂèØËÉΩÈÅéÂ∫¶‰æùË≥¥Ë™ûË®ÄÊ®°ÂûãÁµÑ‰ª∂Ôºå‰∏¶Ê†πÊìöËá™ÁÑ∂Ë™ûË®ÄÊñáÂ≠ó‰∏≠ÁöÑÁµ±Ë®àË¶èÂæãÔºåËÄåÈùûÂΩ±ÁâáÁöÑË¶ñË¶∫ÂÖßÂÆπÔºå‰æÜÂª∫ÊßãÂÖ∂Ëº∏Âá∫„ÄÇÊ≠§Â§ñÔºåËá™ÁÑ∂Ë™ûË®ÄË®ªËß£ÁÑ°Ê≥ïËºïÊòìÂú∞Áî±ÈõªËÖ¶ËôïÁêÜÔºåÈõ£‰ª•‰ΩøÁî®ÊïàËÉΩÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞Ôºå‰∏îÁÑ°Ê≥ïËºïÊòìÁøªË≠ØÊàê‰∏çÂêåÁöÑËá™ÁÑ∂Ë™ûË®Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Áü•Ë≠òÂúñË°®ÁÇ∫ÂΩ±ÁâáÂä†‰∏äË®ªËß£ÁöÑÊñπÊ≥ïÔºå‰∏¶ËóâÊ≠§ÈÅøÂÖçÈÄô‰∫õÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°Âûã‰æÜÂü∑Ë°åÈÄôÈ†Ö‰ªªÂãôÔºåÂÆÉÊúÉÂÖàÈ†êÊ∏¨ÂÄãÈ´îÂ∞çÔºåÁÑ∂ÂæåÂÜçÈ†êÊ∏¨ÂÄãÈ´î‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ®°ÂûãÂª∂‰º∏Ôºå‰ª•Â∞áËÉåÊôØÁü•Ë≠òÁ¥çÂÖ•Áü•Ë≠òÂúñË°®ÁöÑÂª∫Êßã‰∏≠„ÄÇ

##### **Machine Learning-Based Security Policy Analysis**
2501.00085v2 by Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman

Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.

ÊëòË¶ÅÔºöSELinuxÔºàÂÆâÂÖ®Âº∑ÂåñÂûã LinuxÔºâÊòØ‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÂÆâÂÖ®Ê©üÂà∂ÔºåÂÆÉÂº∑Âà∂Âü∑Ë°åÂº∑Âà∂Ë®™ÂïèÊéßÂà∂ (MAC)Ôºå‰ΩÜÂÖ∂ÊîøÁ≠ñË™ûË®ÄÁöÑË§áÈõúÊÄßÂ∞çÊîøÁ≠ñÂàÜÊûêÂíåÁÆ°ÁêÜÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰ΩøÁî®Âü∫ÊñºÂúñÂΩ¢ÊäÄË°ìÁµêÂêàÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ï‰æÜËá™ÂãïÂåñ SELinux ÊîøÁ≠ñÂàÜÊûêÔºå‰ª•Ê™¢Ê∏¨ÊîøÁ≠ñÁï∞Â∏∏„ÄÇÊú¨Á†îÁ©∂Ëß£Ê±∫‰∫ÜÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÔºöÊòØÂê¶ËÉΩÈÄèÈÅéÂúñÂΩ¢ÂàÜÊûêËá™ÂãïÂåñ SELinux ÊîøÁ≠ñÂàÜÊûêÔºå‰ª•Âèä‰∏çÂêåÁöÑÁï∞Â∏∏Ê™¢Ê∏¨Ê®°ÂûãÂú®ÂàÜÊûê SELinux ÊîøÁ≠ñÊôÇÊúâ‰ΩïÊØîËºÉÔºüÊàëÂÄëÂ∞áÊØîËºÉ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåË©ï‰º∞ÂÆÉÂÄëÂú®Ê™¢Ê∏¨ÊîøÁ≠ñÈÅïË¶èÂíåÁï∞Â∏∏ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî® Neo4j ÈÄ≤Ë°åÊîøÁ≠ñÁöÑÂúñÂΩ¢Ë°®Á§∫ÔºåNode2vec Â∞áÈÄô‰∫õÂúñÂΩ¢ÁµêÊßãËΩâÊèõÊàêÊúâÊÑèÁæ©ÁöÑÂêëÈáèÂµåÂÖ•ÔºåÊàëÂÄëÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂèØ‰ª•ËôïÁêÜÈÄô‰∫õÂµåÂÖ•„ÄÇÂú®ÊàëÂÄëÁöÑÁµêÊûú‰∏≠ÔºåMLP Á•ûÁ∂ìÁ∂≤Ë∑ØÂú®‰∏çÂêåÁöÑË≥áÊñôÈõÜÂ§ßÂ∞è‰∏≠ÂßãÁµÇË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú®Âπ≥Ë°°ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊåáÊ®ô‰∏ãÈÅîÂà∞ 95% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåËÄåÈö®Ê©üÊ£ÆÊûóÂíå SVM Ê®°ÂûãÂú®Ê™¢Ê∏¨ÊîøÁ≠ñÈÅïË¶èÊñπÈù¢Ë°®ÁèæÂá∫Á´∂Áà≠ÂäõÔºå‰ΩÜÊïàËÉΩÁï•‰Ωé„ÄÇÈÄôÁ®ÆÂü∫ÊñºÂúñÂΩ¢Âª∫Ê®°ÂíåÊ©üÂô®Â≠∏ÁøíÁöÑÁµÑÂêàÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊõ¥Á≤æÁ∑ª‰∏îËá™ÂãïÂåñÁöÑÊñπÂºèÔºåËàáÂÇ≥Áµ±ÁöÑÊâãÂãïÂàÜÊûêÊñπÊ≥ïÁõ∏ÊØîÔºåÂèØ‰ª•ÁêÜËß£ÂíåÂàÜÊûêË§áÈõúÁöÑ SELinux ÊîøÁ≠ñ„ÄÇ

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÁöÑË°®ÁèæÔºå‰ΩÜÂÆÉÂÄëÁ∂ìÂ∏∏ÂèóÂà∞ÂπªË¶∫ÂíåÁü•Ë≠òÊôÇÊïàÊÄßÁöÑÂΩ±Èüø„ÄÇÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ‰ΩúÁÇ∫Â§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫êÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÂèØË°åÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÁèæÊúâÁöÑ LLM Âü∫ÊñºÁü•Ë≠òÂúñË≠úÂïèÁ≠î (KGQA) ÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÂèóÂà∞ KG ‰∏äÈÄêÊ≠•Ê±∫Á≠ñÁöÑÈôêÂà∂ÔºåÈôêÂà∂‰∫Ü LLM ÁöÑÂÖ®Â±ÄË¶èÂäÉÂíåÊé®ÁêÜËÉΩÂäõÔºåÊàñËÄÖÂÆÉÂÄëÈúÄË¶ÅÈáùÂ∞çÁâπÂÆö KG ÈÄ≤Ë°åÂæÆË™øÊàñÈ†êË®ìÁ∑¥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁü•Ë≠òÂúñË≠úËºîÂä©Êé®ÁêÜË∑ØÂæëËÅöÂêà (KARPA)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂà©Áî® LLM ÁöÑÂÖ®Â±ÄË¶èÂäÉËÉΩÂäõÈÄ≤Ë°åÈ´òÊïà‰∏îÊ∫ñÁ¢∫ÁöÑ KG Êé®ÁêÜ„ÄÇKARPA ÂàÜ‰∏âÊ≠•Êìç‰ΩúÔºö‰ΩøÁî® LLM ÁöÑÂÖ®Â±ÄË¶èÂäÉËÉΩÂäõÈ†êÂÖàË¶èÂäÉÈóú‰øÇË∑ØÂæë„ÄÅÈÄöÈÅéÂµåÂÖ•Ê®°ÂûãÂåπÈÖçË™ûÁæ©Áõ∏ÈóúË∑ØÂæëÔºå‰ª•ÂèäÊé®ÁêÜÈÄô‰∫õË∑ØÂæë‰ª•Áî¢ÁîüÁ≠îÊ°à„ÄÇËàáÁèæÊúâÁöÑ KGQA ÊñπÊ≥ï‰∏çÂêåÔºåKARPA ÈÅøÂÖçÈÄêÊ≠•ÈÅçÊ≠∑Ôºå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑË®ìÁ∑¥Ôºå‰∏¶‰∏îÂèØ‰ª•ÈÅ©ÊáâÂêÑÁ®Æ LLM Êû∂Êßã„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåKARPA Âú® KGQA ‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÊó¢Êèê‰æõ‰∫ÜÈ´òÊïàÁéáÂèàÊèê‰æõ‰∫ÜÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂú® Github ‰∏äÊèê‰æõ„ÄÇ

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ª•Êú¨‰ΩìÁÇ∫Âü∫Á§éÁöÑÊñπÊ≥ï‰æÜÂª∫ÊßãÁü•Ë≠òÂúñË≠úÔºàKGÔºâÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Áü•Ë≠òÂ∫´‰∏ä„ÄÇÊú¨‰ΩìÊòØÁî±Âú®Áü•Ë≠òÂ∫´‰∏äÁî¢ÁîüËÉΩÂäõÂïèÈ°åÔºàCQÔºâ‰æÜÁôºÁèæÁü•Ë≠òÁØÑÂúçÔºåÂæû CQ ‰∏≠ÊèêÂèñÈóú‰øÇÔºå‰∏¶ÂòóË©¶Áî® Wikidata ‰∏≠ÁöÑÂ∞çÊáâÈóú‰øÇÊõøÊèõÁ≠âÊïàÈóú‰øÇËÄåÁ∑®ÂØ´ÁöÑ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÁµêÊûú KG ÁöÑ‰∏ÄËá¥ÊÄßÂíåÂèØËß£ÈáãÊÄßÔºåÊàëÂÄëÊ†πÊìöÊèêÂèñÁöÑÈóú‰øÇÔºå‰ª•Á∑®ÂØ´ÁöÑÊú¨‰ΩìÁÇ∫Âü∫Á§é‰æÜÂª∫Á´ã KG ÁöÑÁî¢Áîü„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫Âú®Áü•Ë≠òÂúñË≠úÂª∫Êßã‰ªªÂãô‰∏≠ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÂèØ‰ª•ÈÄèÈÅéÊ•µÂ∞ëÁöÑ‰∫∫Â∑•‰ªãÂÖ•‰æÜÂª∫ÊßãÂèØÊì¥ÂÖÖÁöÑ KG ÁÆ°Á∑öÔºåÁî¢ÁîüÈ´òÂìÅË≥™‰∏î‰∫∫È°ûÂèØËß£ÈáãÁöÑ KGÔºåÈÄô‰∫õ KG Ëàá Wikidata Ë™ûÁæ©ÂèØ‰ª•‰∫íÈÄöÔºå‰ª•Êì¥ÂÖÖÊΩõÂú®ÁöÑÁü•Ë≠òÂ∫´„ÄÇ

##### **ICLR: In-Context Learning of Representations**
2501.00070v1 by Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
"graph tracing" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁî±È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÊåáÂÆöÁöÑËØ≠‰πâ‰ºöÂΩ±ÂìçÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠‰∏çÂêåÊ¶ÇÂøµÁöÑË°®ÂæÅÁªÑÁªáÊñπÂºè„ÄÇÁÑ∂ËÄåÔºåÈâ¥‰∫é LLM ÁöÑÂºÄÊîæÂºèÊú¨Ë¥®Ôºå‰æãÂ¶ÇÂÆÉ‰ª¨Âú®ËØ≠Â¢É‰∏≠Â≠¶‰π†ÁöÑËÉΩÂäõÔºåÊàë‰ª¨ÂèØ‰ª•ËØ¢ÈóÆÊ®°ÂûãÊòØÂê¶‰ºöÊîπÂèòËøô‰∫õÈ¢ÑËÆ≠ÁªÉËØ≠‰πâ‰ª•ÈááÁî®Êõø‰ª£ÁöÑ„ÄÅËØ≠Â¢ÉÊåáÂÆöÁöÑËØ≠‰πâ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂ¶ÇÊûúÊàë‰ª¨Âú®ËØ≠Â¢É‰∏≠Êèê‰æõÁ§∫‰æãÔºåÂÖ∂‰∏≠‰∏Ä‰∏™Ê¶ÇÂøµÊâÆÊºîÁöÑËßíËâ≤‰∏éÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÊâÄÊöóÁ§∫ÁöÑ‰∏çÂêåÔºåÊ®°ÂûãÊòØÂê¶‰ºöÊ†πÊçÆËøô‰∫õÊñ∞ËØ≠‰πâÈáçÊñ∞ÁªÑÁªáÂÆÉ‰ª¨ÁöÑË°®ÂæÅÔºü‰∏∫‰∫ÜÂõûÁ≠îËøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨‰ªéÊ¶ÇÂøµËßíËâ≤ËØ≠‰πâÁêÜËÆ∫‰∏≠Ê±≤ÂèñÁÅµÊÑüÔºåÂπ∂ÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Áé©ÂÖ∑‚ÄúÂõæÁ§∫ËøΩË∏™‚Äù‰ªªÂä°ÔºåÂÖ∂‰∏≠ÂõæÁöÑËäÇÁÇπÈÄöËøáËÆ≠ÁªÉÊúüÈó¥ÁúãÂà∞ÁöÑÊ¶ÇÂøµÔºà‰æãÂ¶ÇÔºåËãπÊûú„ÄÅÈ∏üÁ≠âÔºâËøõË°åÂºïÁî®ÔºåÂπ∂‰∏îÂõæÁöÑËøûÈÄöÊÄßÊòØÈÄöËøá‰∏Ä‰∫õÈ¢ÑÂÆö‰πâÁöÑÁªìÊûÑÔºà‰æãÂ¶ÇÔºåÊ≠£ÊñπÂΩ¢ÁΩëÊ†ºÔºâÂÆö‰πâÁöÑ„ÄÇÁªôÂÆöÊåáÁ§∫Âú®Âõæ‰∏äÈöèÊú∫Ê∏∏Ëµ∞ÁöÑËΩ®ËøπÁöÑÁ§∫‰æãÔºåÊàë‰ª¨ÂàÜÊûê‰∫ÜÊ®°ÂûãÁöÑ‰∏≠Èó¥Ë°®ÂæÅÔºåÂèëÁé∞ÈöèÁùÄËØ≠Â¢ÉÈáèÁöÑÂ¢ûÂä†Ôºå‰ªéÈ¢ÑËÆ≠ÁªÉËØ≠‰πâË°®ÂæÅÂà∞‰∏éÂõæÁªìÊûÑÂØπÈΩêÁöÑËØ≠Â¢ÉË°®ÂæÅÁ™ÅÁÑ∂ÂèëÁîü‰∫ÜÈáçÊñ∞ÁªÑÁªá„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂèëÁé∞ÂΩìÂèÇËÄÉÊ¶ÇÂøµÂú®ÂÖ∂ËØ≠‰πâ‰∏≠ÂÖ∑ÊúâÁõ∏ÂÖ≥ÊÄßÔºà‰æãÂ¶ÇÔºåÊòüÊúü‰∏Ä„ÄÅÊòüÊúü‰∫åÁ≠âÔºâÊó∂ÔºåËØ≠Â¢ÉÊåáÂÆöÁöÑÂõæÁªìÊûÑ‰ªçÁÑ∂Â≠òÂú®‰∫éË°®ÂæÅ‰∏≠Ôºå‰ΩÜÊó†Ê≥ïÊîØÈÖçÈ¢ÑËÆ≠ÁªÉÁªìÊûÑ„ÄÇ‰∏∫‰∫ÜËß£ÈáäËøô‰∫õÁªìÊûúÔºåÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑ‰ªªÂä°Á±ªÊØî‰∏∫È¢ÑÂÆö‰πâÂõæÊãìÊâëÁöÑËÉΩÈáèÊúÄÂ∞èÂåñÔºå‰∏∫Êé®Êñ≠ËØ≠Â¢ÉÊåáÂÆöËØ≠‰πâÁöÑÈöêÂºè‰ºòÂåñËøáÁ®ãÊèê‰æõ‰∫ÜËØÅÊçÆ„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÊâ©Â±ïËØ≠Â¢ÉÂ§ßÂ∞èÂèØ‰ª•ÁÅµÊ¥ªÂú∞ÈáçÊñ∞ÁªÑÁªáÊ®°ÂûãË°®ÂæÅÔºåÊúâÂèØËÉΩËß£ÈîÅÊñ∞ÁöÑÂäüËÉΩ„ÄÇ</paragraph>

##### **Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**
2412.20163v2 by Minhye Jeon, Seokho Ahn, Young-Duk Seo

The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂú®Êé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑ‰ΩøÁî®Â∑≤ÊàêÁÇ∫Ëß£Ê±∫Ë≥áÊñôÁ®ÄÁñèÊÄßÂíåÂÜ∑ÂïüÂãïÂïèÈ°åÁöÑÂ∏∏Ë¶ãÊñπÊ≥ï‰πã‰∏Ä„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫ËôïÁêÜÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÂÅ¥ÈÇäÂíåËÉåÊôØË≥áË®äÊèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈúÄË¶ÅÈ†òÂüüÂ∞àÂÆ∂ÁöÑ‰ªãÂÖ•‰ª•ÂèäÁ≥ªÁµ±ÁâπÊÄßÁöÑÂ∑ÆÁï∞ÔºåË∑®ÂêÑÁ®ÆÁ≥ªÁµ±ÁöÑ‰∏ÄËá¥Êï¥Âêà‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰∏ÄËá¥ÁöÑÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî® LLM ÂæûÂÅ¥ÈÇäÂíåËÉåÊôØË≥áË®ä‰∏≠ÊèêÂèñ‰∏ÄËà¨ÂíåÁâπÂÆö‰∏ªÈ°å„ÄÇÈ¶ñÂÖàÔºåÂæûÂÅ¥ÈÇäË≥áË®ä‰∏≠ÂèçË¶ÜÊèêÂèñÂíåÊõ¥Êñ∞‰∏ÄËà¨‰∏ªÈ°å„ÄÇÁÑ∂ÂæåÔºå‰ΩøÁî®ËÉåÊôØË≥áË®äÊèêÂèñÁâπÂÆö‰∏ªÈ°å„ÄÇÊúÄÂæåÔºåÁÇ∫‰∫ÜËôïÁêÜÂú®ÁâπÂÆö‰∏ªÈ°åÊèêÂèñÈÅéÁ®ã‰∏≠Áî¢ÁîüÁöÑÂêåÁæ©‰∏ªÈ°åÔºå‰∏ÄÁ®ÆÁ≤æÁÖâÊºîÁÆóÊ≥ïÊúâÊïàÂú∞ËôïÁêÜ‰∏¶Ëß£Ê±∫‰∫ÜÈÄô‰∫õÂïèÈ°å„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±‰∏ÄËà¨‰∏ªÈ°åÊì∑ÂèñÂêÑÁ®ÆÈ†ÖÁõÆÁâπÊÄßÁöÑÂª£Ê≥õÁü•Ë≠òÔºåËÄåÁâπÂÆö‰∏ªÈ°åÂâáÂº∑Ë™øË©≥Á¥∞Â±¨ÊÄßÔºåÂæûËÄåÊõ¥ÂÖ®Èù¢Âú∞‰∫ÜËß£È†ÖÁõÆÁöÑË™ûÁæ©ÁâπÂæµÂíå‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•Ω„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú®ÂêÑÁ®ÆÁü•Ë≠òÂúñË≠ú‰∏≠ÔºåÊé®Ëñ¶ÊïàËÉΩÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇ

##### **From Generalist to Specialist: A Survey of Large Language Models for Chemistry**
2412.19994v1 by Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen

Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤È°ØËëóÊîπËÆäÊàëÂÄëÁöÑÊó•Â∏∏ÁîüÊ¥ªÔºå‰∏¶Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇÁÑ∂ËÄåÔºåLLM Âú®Âª£Ê≥õÁöÑÂü∫ÊñºÁ∂≤Ë∑ØÁöÑÊñáÊú¨‰∏äÈÄ≤Ë°åÁöÑÁõõË°åÈ†êË®ìÁ∑¥Â∞çÊñºÂÖàÈÄ≤ÁöÑÁßëÂ≠∏ÁôºÁèæ‰ªçÁÑ∂‰∏çË∂≥ÔºåÁâπÂà•ÊòØÂú®ÂåñÂ≠∏È†òÂüü„ÄÇÂ∞àÊ•≠ÂåñÂ≠∏Êï∏ÊìöÁöÑÁ®ÄÁº∫ÔºåÂä†‰∏ä 2D ÂúñÂΩ¢„ÄÅ3D ÁµêÊßãÂíåÂÖâË≠úÁ≠âÂ§öÊ®°ÊÖãÊï∏ÊìöÁöÑË§áÈõúÊÄßÔºåÊèêÂá∫‰∫Ü‰∏çÂêåÁöÑÊåëÊà∞„ÄÇÂÑòÁÆ°‰∏Ä‰∫õÁ†îÁ©∂ÂõûÈ°ß‰∫ÜÂåñÂ≠∏‰∏≠ÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM)Ôºå‰ΩÜÈ°ØËëóÁº∫‰πèÂ∞àÊ≥®Êñº‰ª•ÂåñÂ≠∏ÁÇ∫Â∞éÂêëÁöÑ LLM ÁöÑÁ≥ªÁµ±ÊÄßË™øÊü•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂ∞áÁâπÂÆöÈ†òÂüüÁöÑÂåñÂ≠∏Áü•Ë≠òÂíåÂ§öÊ®°ÊÖãË≥áË®äÁ¥çÂÖ• LLM ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÈÇÑÂ∞áÂåñÂ≠∏ LLM Ê¶ÇÂøµÂåñÁÇ∫‰ΩøÁî®ÂåñÂ≠∏Â∑•ÂÖ∑ÁöÑ‰ª£ÁêÜÔºå‰∏¶Á†îÁ©∂ÂÆÉÂÄëÂä†ÈÄüÁßëÂ≠∏Á†îÁ©∂ÁöÑÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜÁèæÊúâÁöÑÂü∫Ê∫ñ‰æÜË©ï‰º∞ LLM ÁöÑÂåñÂ≠∏ËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊâπÂà§ÊÄßÂú∞ÂØ©Êü•‰∫ÜÁï∂ÂâçÁöÑÊåëÊà∞Ôºå‰∏¶Á¢∫ÂÆö‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇÈÄöÈÅéÈÄôÈ†ÖÂÖ®Èù¢ÁöÑË™øÊü•ÔºåÊàëÂÄëÊó®Âú®ÂçîÂä©Á†îÁ©∂‰∫∫Âì°ÊéåÊè°ÂåñÂ≠∏ LLM ÁôºÂ±ïÁöÑÊúÄÂâçÊ≤øÔºå‰∏¶ÊøÄÁôºË©≤È†òÂüüÁöÑÂâµÊñ∞ÊáâÁî®„ÄÇ

##### **Toward Adaptive Reasoning in Large Language Models with Thought Rollback**
2412.19707v1 by Sijia Chen, Baochun Li

Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂ∑≤Â∏∏Ë¶èÁî®ÊñºËß£Ê±∫ÂêÑÁ®Æ‰ªªÂãôÔºå‰ΩøÁî®ÈÄêÊ≠•Êé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºå‰∏≠ÈñìÊé®ÁêÜÊ≠•È©üÊàñÊÉ≥Ê≥ïÁöÑÁµêÊßãÊòØÂÉµÂåñ‰∏îÂñÆÂêëÁöÑÔºå‰æãÂ¶ÇÈèà„ÄÅÊ®πÊàñÁÑ°Áí∞ÊúâÂêëÂúñ„ÄÇÂõ†Ê≠§ÔºåÁî¢ÁîüÁöÑÂÉµÂåñ‰∏îÂÉÖÂêëÂâçÊé®ÁêÜÂèØËÉΩÁÑ°Ê≥ïËß£Ê±∫ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºå‰∏¶‰∏îÁï∂ LLM È†ªÁπÅÁµ¶Âá∫ÈåØË™§ÁöÑÂõûÊáâÔºàÂç≥„ÄåÂπªË¶∫„ÄçÔºâÊôÇÊúÉÂ§±Êïó„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊé®ÁêÜÊ°ÜÊû∂ÔºåÁ®±ÁÇ∫ Thought RollbackÔºàTRÔºâÔºåÂÖÅË®± LLM Âú®Ëß£Ê±∫„ÄåÂπªË¶∫„ÄçÂïèÈ°åÊôÇËá™ÈÅ©ÊáâÂú∞ÊßãÂª∫ÊÄùÊÉ≥ÁµêÊßãÔºåÂêåÊôÇ‰øùÊåÅÊúâÊïàÁöÑÊé®ÁêÜ„ÄÇTR ÁöÑÊ†∏ÂøÉÊ©üÂà∂ÊòØÂõûÊªæÊÄùÊÉ≥ÔºåÂÆÉÂÖÅË®± LLM Â∞çÊÄùÊÉ≥Âü∑Ë°åÈåØË™§ÂàÜÊûêÔºå‰∏¶Âõ†Ê≠§ÂõûÊªæÂà∞‰ªª‰ΩïÂÖàÂâçÈåØË™§ÁöÑÊÄùÊÉ≥ÈÄ≤Ë°å‰øÆÊîπ„ÄÇÈö®ÂæåÔºåÈÄöÈÅéÂú®ÊèêÁ§∫‰∏≠ÂåÖÂê´Ê≠§È°ûË©¶ÈåØ‰æÜÊåáÂ∞é LLMÔºåÊØèÊ¨°ÂõûÊªæÈÉΩÊúÉÂ∞éËá¥‰∏ÄÊ¢ùÊõ¥ÂèØÈù†ÁöÑÊé®ÁêÜË∑ØÂæë„ÄÇÂõ†Ê≠§ÔºåÂæû‰∏ÄÂÄãÊ≤íÊúâ‰∫∫Â∑•Ë®ªÈáãÁöÑÁ∞°ÂñÆÊèêÁ§∫ÈñãÂßãÔºåÂ∏∂Êúâ TR ÁöÑ LLM Ëá™ÈÅ©ÊáâÂú∞ÈÄêÊº∏Êé¢Á¥¢ÊÄùÊÉ≥‰ª•Áç≤ÂæóÊ≠£Á¢∫ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®Êï∏Â≠∏ÂïèÈ°åÂíåÂ§ö‰ªªÂãôÊé®ÁêÜ‰∏äÁöÑÁ∂úÂêàÂØ¶È©óË≠âÊòé‰∫Ü TR Âú®ÂïèÈ°åËß£Ê±∫ÁéáÂíå‰∫§‰∫íÊàêÊú¨ÊñπÈù¢ÁöÑÊúÄÂÖàÈÄ≤ÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂ∏∂Êúâ TR ÁöÑ GPT-4 ÁöÑÊ±ÇËß£ÁéáÂú® MATH Êï∏ÊìöÈõÜ‰∏äÊØîÁõÆÂâçÁöÑÊúÄ‰Ω≥ÊÄßËÉΩÈ´òÂá∫ 9%„ÄÇ

##### **Dynamic Skill Adaptation for Large Language Models**
2412.19361v1 by Jiaao Chen, Diyi Yang

We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ÂãïÊÖãÊäÄËÉΩÈÅ©Êáâ (DSA)Ôºå‰∏ÄÁ®ÆÈÅ©ÊáâÊÄßÂíåÂãïÊÖãÊ°ÜÊû∂ÔºåÁî®ÊñºÂ∞áÊñ∞Á©é‰∏îË§áÈõúÁöÑÊäÄËÉΩÈÅ©ÊáâÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇËàáÂÖàÂâçÂæû‰∫∫È°ûÁ≠ñÂäÉÂíåÈùúÊÖãË≥áÊñô‰∏≠‰ª•Èö®Ê©üÈ†ÜÂ∫èÂ≠∏ÁøíÁöÑÂ∑•‰ΩúÁõ∏ÊØîÔºåÊàëÂÄëÂª∫Ë≠∞È¶ñÂÖàÈÄèÈÅéÊ®°Êì¨‰∫∫È°ûÁöÑÂ≠∏ÁøíË∑ØÂæëËá™ÂãïÁî¢ÁîüÂíåÁµÑÁπîË®ìÁ∑¥Ë≥áÊñôÔºåÁÑ∂ÂæåÊ†πÊìöË®ìÁ∑¥ÂãïÊÖãÂãïÊÖãË™øÊï¥Ë®ìÁ∑¥Ë≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂèóÂà∞‰∫∫È°ûÊïôËÇ≤Á≥ªÁµ±‰∏≠ÁöÑÂ≠∏ÁøíÁµêÊßãÂíåÊïôÂ≠∏Á≠ñÁï•ÁöÑÂïüÁôºÔºåÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÂ∞áË§áÈõúÊäÄËÉΩÂàÜËß£ÊàêÂ≠êÊäÄËÉΩ‰∏¶Ê†πÊìöÂÆÉÂÄëÂú®‰∫∫È°ûÈü≥ÁØÄ‰∏≠ÁöÑ‰æùË≥¥ÊÄß‰æÜÊéíÂàóÂÆÉÂÄë‰æÜÊßãÂª∫ÊäÄËÉΩÂúñ„ÄÇÂ∞çÊñºÊØèÈ†ÖÊäÄËÉΩÔºåÊàëÂÄëÂà©Áî® LLM Áî¢ÁîüÈ°û‰ººÊïôÁßëÊõ∏ÁöÑË≥áÊñôÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊäÄËÉΩÁöÑË©≥Á¥∞ÊèèËø∞ÔºåÁî®ÊñºÈ†êË®ìÁ∑¥ÂíåÁ∑¥ÁøíÈ°ûÂûãÁöÑË≥áÊñôÔºåÂÖ∂ÁõÆÊ®ôÊòØÊòéÁ¢∫Âà©Áî®ÊäÄËÉΩËß£Ê±∫ÂïèÈ°åÔºå‰ª•ÈÄ≤Ë°åÊåá‰ª§Ë™øÊï¥„ÄÇÊ≠§Â§ñÔºåÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÔºåÊàëÂÄëÊúÉÂãïÊÖãÊõ¥Êñ∞Ë®ìÁ∑¥Ë≥áÊñôÔºåÂÖ∂‰∏≠ÊúÉÈôç‰ΩéÊòìÊñºÂ≠∏ÁøíÁØÑ‰æãÁöÑÊ¨äÈáç„ÄÅÁî¢ÁîüÊõ¥Ë§áÈõúÁöÑÁØÑ‰æãÔºå‰∏¶ÈÅéÊøæÊéâÊúâÈåØË™§ÁöÑË≥áÊñô„ÄÇÂú® LLAMA Âíå Mistral Á≠âÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÈÅ©ÊáâÊï∏Â≠∏Êé®ÁêÜÊäÄËÉΩÂíåÁ§æÊúÉÁ†îÁ©∂ÊäÄËÉΩÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation**
2412.19021v1 by Tao Liu, Rongjie Li, Chongyu Wang, Xuming He

Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of
the closed-set assumption by aligning visual relationship representations with
open-vocabulary textual representations. This enables the identification of
novel visual relationships, making it applicable to real-world scenarios with
diverse relationships. However, existing OV-SGG methods are constrained by
fixed text representations, limiting diversity and accuracy in image-text
alignment. To address these challenges, we propose the Relation-Aware
Hierarchical Prompting (RAHP) framework, which enhances text representation by
integrating subject-object and region-specific relation information. Our
approach utilizes entity clustering to address the complexity of relation
triplet categories, enabling the effective integration of subject-object
information. Additionally, we utilize a large language model (LLM) to generate
detailed region-aware prompts, capturing fine-grained visual interactions and
improving alignment between visual and textual modalities. RAHP also introduces
a dynamic selection mechanism within Vision-Language Models (VLMs), which
adaptively selects relevant text prompts based on the visual content, reducing
noise from irrelevant prompts. Extensive experiments on the Visual Genome and
Open Images v6 datasets demonstrate that our framework consistently achieves
state-of-the-art performance, demonstrating its effectiveness in addressing the
challenges of open-vocabulary scene graph generation.

ÊëòË¶ÅÔºöÈñãÊîæË©ûÂΩôÂ†¥ÊôØÂúñÁîüÊàê (OV-SGG) ÂÖãÊúç‰∫ÜÂ∞ÅÈñâÂºèÂÅáË®≠ÁöÑÈôêÂà∂ÔºåÈÄèÈÅéÂ∞áË¶ñË¶∫Èóú‰øÇË°®ÂæµËàáÈñãÊîæË©ûÂΩôÊñáÊú¨Ë°®ÂæµÂ∞çÈΩä„ÄÇÈÄô‰ΩøÂæóËÉΩÂ§†Ë≠òÂà•Êñ∞ÁöÑË¶ñË¶∫Èóú‰øÇÔºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÂÖ∑ÊúâÂ§öÊ®£ÂåñÈóú‰øÇÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ OV-SGG ÊñπÊ≥ïÂèóÂà∞Âõ∫ÂÆöÊñáÊú¨Ë°®ÂæµÁöÑÈôêÂà∂ÔºåÈôêÂà∂‰∫ÜÂúñÂÉèÊñáÊú¨Â∞çÈΩäÁöÑÂ§öÊ®£ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈóú‰øÇÊÑüÁü•ÈöéÂ±§ÂºèÊèêÁ§∫ (RAHP) Êû∂ÊßãÔºåÈÄèÈÅéÊï¥Âêà‰∏ªÈ´îÂÆ¢È´îÂíåÁâπÂÆöÂçÄÂüüÁöÑÈóú‰øÇË≥áË®ä‰æÜÂ¢ûÂº∑ÊñáÊú¨Ë°®Âæµ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®ÂØ¶È´îËÅöÈ°û‰æÜËß£Ê±∫Èóú‰øÇ‰∏âÂÖÉÁµÑÈ°ûÂà•ÁöÑË§áÈõúÊÄßÔºå‰Ωø‰∏ªÈ´îÂÆ¢È´îË≥áË®äËÉΩÂ§†ÊúâÊïàÊï¥Âêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁî¢ÁîüË©≥Á¥∞ÁöÑÂçÄÂüüÊÑüÁü•ÊèêÁ§∫ÔºåÊçïÊçâÁ¥∞ÂæÆÁöÑË¶ñË¶∫‰∫íÂãï‰∏¶ÊîπÂñÑË¶ñË¶∫ÂíåÊñáÊú¨Ê®°Âºè‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇRAHP ‰πüÂú®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ‰∏≠ÂºïÂÖ•‰∫ÜÂãïÊÖãÈÅ∏ÊìáÊ©üÂà∂ÔºåÊ†πÊìöË¶ñË¶∫ÂÖßÂÆπËá™ÈÅ©ÊáâÂú∞ÈÅ∏ÊìáÁõ∏ÈóúÊñáÊú¨ÊèêÁ§∫ÔºåÊ∏õÂ∞ë‰∏çÁõ∏ÈóúÊèêÁ§∫ÁöÑÈõúË®ä„ÄÇÂú® Visual Genome Âíå Open Images v6 Ë≥áÊñôÈõÜ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊû∂ÊßãÊåÅÁ∫åÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåË≠âÊòéÂÖ∂Âú®Ëß£Ê±∫ÈñãÊîæË©ûÂΩôÂ†¥ÊôØÂúñÁîüÊàêÁöÑÊåëÊà∞‰∏äÂÖ∑ÊúâÊïàËÉΩ„ÄÇ

##### **PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation**
2412.18827v1 by ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li

Phylogenetic trees elucidate evolutionary relationships among species, but
phylogenetic inference remains challenging due to the complexity of combining
continuous (branch lengths) and discrete parameters (tree topology).
Traditional Markov Chain Monte Carlo methods face slow convergence and
computational burdens. Existing Variational Inference methods, which require
pre-generated topologies and typically treat tree structures and branch lengths
independently, may overlook critical sequence features, limiting their accuracy
and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained
genomic language model to generate and optimize phylogenetic trees without
dependence on evolutionary models or aligned sequence constraints. PhyloGen
views phylogenetic inference as a conditionally constrained tree structure
generation problem, jointly optimizing tree topology and branch lengths through
three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and
(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function
to guide the model towards a more stable gradient descent. We demonstrate the
effectiveness and robustness of PhyloGen on eight real-world benchmark
datasets. Visualization results confirm PhyloGen provides deeper insights into
phylogenetic relationships.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÁôºÁîüÊ®πÈó°Êòé‰∫ÜÁâ©Á®Æ‰πãÈñìÁöÑÊºîÂåñÈóú‰øÇÔºå‰ΩÜÁî±ÊñºÈÄ£Á∫åÂèÉÊï∏ÔºàÂàÜÊîØÈï∑Â∫¶ÔºâÂíåÈõ¢Êï£ÂèÉÊï∏ÔºàÊ®πÂΩ¢ÁµêÊßãÔºâÁµêÂêàÁöÑË§áÈõúÊÄßÔºåÁ≥ªÁµ±ÁôºÁîüÊé®Ë´ñ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÇ≥Áµ±ÁöÑÈ¶¨ÂèØÂ§´ÈèàËíôÁâπÂç°ÁæÖÊñπÊ≥ïÈù¢Ëá®Êî∂ÊñÇÈÄüÂ∫¶ÊÖ¢ÂíåË®àÁÆóË≤†ÊìîÈáç„ÄÇÁèæÊúâÁöÑËÆäÂàÜÊé®Ë´ñÊñπÊ≥ïÈúÄË¶ÅÈ†êÂÖàÁî¢ÁîüÁöÑÊãìÊí≤ÁµêÊßãÔºå‰∏¶‰∏îÈÄöÂ∏∏Áç®Á´ãËôïÁêÜÊ®πÂΩ¢ÁµêÊßãÂíåÂàÜÊîØÈï∑Â∫¶ÔºåÂèØËÉΩÊúÉÂøΩÁï•ÈóúÈçµÁöÑÂ∫èÂàóÁâπÂæµÔºåÂæûËÄåÈôêÂà∂ÂÖ∂Ê∫ñÁ¢∫ÊÄßÂíåÈùàÊ¥ªÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü PhyloGenÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®È†êË®ìÁ∑¥ÁöÑÂü∫Âõ†ÁµÑË™ûË®ÄÊ®°Âûã‰æÜÁîüÊàêÂíåÂÑ™ÂåñÁ≥ªÁµ±ÁôºÁîüÊ®πÔºåËÄå‰∏çÈúÄË¶Å‰æùË≥¥ÊºîÂåñÊ®°ÂûãÊàñÊØîÂ∞çÂ∫èÂàóÁ¥ÑÊùü„ÄÇPhyloGen Â∞áÁ≥ªÁµ±ÁôºÁîüÊé®Ë´ñË¶ñÁÇ∫‰∏ÄÂÄãÊ¢ù‰ª∂Á¥ÑÊùüÁöÑÊ®πÂΩ¢ÁµêÊßãÁîüÊàêÂïèÈ°åÔºåÈÄöÈÅé‰∏âÂÄãÊ†∏ÂøÉÊ®°ÁµÑÂÖ±ÂêåÂÑ™ÂåñÊ®πÂΩ¢ÁµêÊßãÂíåÂàÜÊîØÈï∑Â∫¶Ôºö(i) ÁâπÂæµÊèêÂèñ„ÄÅ(ii) PhyloTree ÊßãÂª∫Ôºå‰ª•Âèä (iii) PhyloTree ÁµêÊßãÂª∫Ê®°„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË©ïÂàÜÂáΩÊï∏‰æÜÂºïÂ∞éÊ®°ÂûãÊúùËëóÊõ¥Á©©ÂÆöÁöÑÊ¢ØÂ∫¶‰∏ãÈôçÊñπÂêëÁôºÂ±ï„ÄÇÊàëÂÄëÂú®ÂÖ´ÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÂ±ïÁ§∫‰∫Ü PhyloGen ÁöÑÊúâÊïàÊÄßÂíåÈ≠ØÊ£íÊÄß„ÄÇÂèØË¶ñÂåñÁµêÊûúË≠âÂØ¶ÔºåPhyloGen ËÉΩÂ§†Êõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£Á≥ªÁµ±ÁôºÁîüÈóú‰øÇ„ÄÇ

##### **CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**
2412.18702v1 by Yanlin Feng, Simone Papicchio, Sajjadur Rahman

Retrieval from graph data is crucial for augmenting large language models
(LLM) with both open-domain knowledge and private enterprise data, and it is
also a key component in the recent GraphRAG system (edge et al., 2024). Despite
decades of research on knowledge graphs and knowledge base question answering,
leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal
support for retrieval from modern encyclopedic knowledge graphs like Wikidata.
In this paper, we analyze the root cause and suggest that modern RDF knowledge
graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly
large schemas that far exceed the typical LLM context window, use of resource
identifiers, overlapping relation types and lack of normalization. As a
solution, we propose property graph views on top of the underlying RDF graph
that can be efficiently queried by LLMs using Cypher. We instantiated this idea
on Wikidata and introduced CypherBench, the first benchmark with 11
large-scale, multi-domain property graphs with 7.8 million entities and over
10,000 questions. To achieve this, we tackled several key challenges, including
developing an RDF-to-property graph conversion engine, creating a systematic
pipeline for text-to-Cypher task generation, and designing new evaluation
metrics.

ÊëòË¶ÅÔºöÂæûÂúñÂΩ¢Ë≥áÊñô‰∏≠Êì∑ÂèñÂ∞çÊñºÊì¥Â¢ûÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈùûÂ∏∏ÈáçË¶ÅÔºåÂÆÉÁµêÂêà‰∫ÜÈñãÊîæÈ†òÂüüÁü•Ë≠òÂíåÁßÅ‰∫∫‰ºÅÊ•≠Ë≥áÊñôÔºåÂêåÊôÇ‰πüÊòØËøëÊúü GraphRAG Á≥ªÁµ± (edge et al., 2024) ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂÑòÁÆ°Á∂ìÈÅéÊï∏ÂçÅÂπ¥ÁöÑÁü•Ë≠òÂúñË≠úÂíåÁü•Ë≠òÂ∫´ÂïèÈ°åËß£Á≠îÁ†îÁ©∂Ôºå‰ΩÜÈ†òÂÖàÁöÑ LLM Ê°ÜÊû∂Ôºà‰æãÂ¶Ç Langchain Âíå LlamaIndexÔºâÂÉÖËÉΩÊúÄ‰ΩéÈôêÂ∫¶ÊîØÊè¥ÂæûÁèæ‰ª£ÁôæÁßëÁü•Ë≠òÂúñË≠úÔºà‰æãÂ¶Ç WikidataÔºâÊì∑Âèñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊ†πÊú¨ÂéüÂõ†Ôºå‰∏¶ÊèêÂá∫Áèæ‰ª£ RDF Áü•Ë≠òÂúñË≠úÔºà‰æãÂ¶Ç Wikidata„ÄÅFreebaseÔºâÂ∞çÊñº LLM ‰æÜË™™ÊïàÁéáËºÉ‰ΩéÔºåÈÄôÊòØÂõ†ÁÇ∫ÈÅéÊñºÈæêÂ§ßÁöÑÊû∂ÊßãÈÅ†ÈÅ†Ë∂ÖÈÅéÂÖ∏ÂûãÁöÑ LLM ËÉåÊôØË¶ñÁ™ó„ÄÅ‰ΩøÁî®Ë≥áÊ∫êË≠òÂà•Á¢º„ÄÅÈáçÁñäÁöÑÈóú‰øÇÈ°ûÂûãÂíåÁº∫‰πèÊ®ôÊ∫ñÂåñ„ÄÇ‰ΩúÁÇ∫Ëß£Ê±∫ÊñπÊ°àÔºåÊàëÂÄëÊèêÂá∫Âú®Â∫ïÂ±§ RDF ÂúñÂΩ¢‰∏äÂª∫Á´ãÂ±¨ÊÄßÂúñÂΩ¢Ê™¢Ë¶ñÔºåLLM ÂèØ‰ª•‰ΩøÁî® Cypher ÊúâÊïàÂú∞Êü•Ë©¢ÈÄô‰∫õÊ™¢Ë¶ñ„ÄÇÊàëÂÄëÂú® Wikidata ‰∏äÂØ¶‰æãÂåñ‰∫ÜÈÄôÂÄãÊÉ≥Ê≥ïÔºå‰∏¶ÂºïÂÖ•‰∫Ü CypherBenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂåÖÂê´ 11 ÂÄãÂ§ßÂûã„ÄÅÂ§öÈ†òÂüüÁöÑÂ±¨ÊÄßÂúñÂΩ¢ÔºåÊìÅÊúâ 780 Ëê¨ÂÄãÂØ¶È´îÂíåË∂ÖÈÅé 10,000 ÂÄãÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàëÂÄëÊáâÂ∞ç‰∫ÜÂπæÂÄãÈóúÈçµÊåëÊà∞ÔºåÂåÖÊã¨ÈñãÁôº RDF Âà∞Â±¨ÊÄßÂúñÂΩ¢ËΩâÊèõÂºïÊìé„ÄÅÂª∫Á´ãÊñáÂ≠óÂà∞ Cypher ‰ªªÂãôÁî¢ÁîüÁ≥ªÁµ±ÂåñÊµÅÁ®ãÔºå‰ª•ÂèäË®≠Ë®àÊñ∞ÁöÑË©ï‰º∞ÊåáÊ®ô„ÄÇ

##### **From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**
2412.18672v1 by Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal

Hallucination, a persistent challenge plaguing language models, undermines
their efficacy and trustworthiness in various natural language processing
endeavors by generating responses that deviate from factual accuracy or
coherence. This paper addresses language model hallucination by integrating
curated knowledge graph (KG) triples to anchor responses in empirical data. We
meticulously select and integrate relevant KG triples tailored to specific
contexts, enhancing factual grounding and alignment with input. Our
contribution involves constructing a comprehensive KG repository from Wikipedia
and refining data to spotlight essential information for model training. By
imbuing language models with access to this curated knowledge, we aim to
generate both linguistically fluent responses and deeply rooted in factual
accuracy and context relevance. This integration mitigates hallucinations by
providing a robust foundation of information, enabling models to draw upon a
rich reservoir of factual data during response generation. Experimental
evaluations demonstrate the effectiveness of multiple approaches in reducing
hallucinatory responses, underscoring the role of curated knowledge graphs in
improving the reliability and trustworthiness of language model outputs.

ÊëòË¶ÅÔºöÂπªË¶∫Ôºå‰∏ÄÁ®ÆÊåÅÁ∫åÂõ∞ÊìæË™ûË®ÄÊ®°ÂûãÁöÑÊåëÊà∞ÔºåÁ†¥Â£û‰∫ÜÂÆÉÂÄëÂú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∑•‰Ωú‰∏≠ÁöÑÊïàÁéáÂíåÂèØ‰ø°Â∫¶ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁî¢ÁîüÁöÑÂèçÊáâÂÅèÈõ¢‰∫Ü‰∫ãÂØ¶ÁöÑÊ∫ñÁ¢∫ÊÄßÊàñÈÄ£Ë≤´ÊÄß„ÄÇÊú¨ÊñáÈÄèÈÅéÊï¥ÂêàÁ∂ìÈÅéÊï¥ÁêÜÁöÑÁü•Ë≠òÂúñË≠ú (KG) ‰∏âÂÖÉÁµÑ‰æÜÈå®ÂÆöÁ∂ìÈ©óÊï∏Êìö‰∏≠ÁöÑÂõûÊáâÔºå‰æÜËß£Ê±∫Ë™ûË®ÄÊ®°ÂûãÁöÑÂπªË¶∫„ÄÇÊàëÂÄë‰ªîÁ¥∞Âú∞ÈÅ∏Êìá‰∏¶Êï¥ÂêàËàáÁâπÂÆöËÑàÁµ°Áõ∏Á¨¶ÁöÑÁõ∏Èóú KG ‰∏âÂÖÉÁµÑÔºåÂ¢ûÂº∑‰∫ãÂØ¶‰æùÊìö‰∏¶ËàáËº∏ÂÖ•‰øùÊåÅ‰∏ÄËá¥„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÂæûÁ∂≠Âü∫ÁôæÁßëÊßãÂª∫‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ KG ÂÑ≤Â≠òÂ∫´Ôºå‰∏¶Á≤æÁÖâÊï∏ÊìöÔºå‰ª•Á™ÅÈ°ØÊ®°ÂûãË®ìÁ∑¥ÁöÑÈáçË¶ÅË≥áË®ä„ÄÇÈÄèÈÅéËÆìË™ûË®ÄÊ®°ÂûãÂ≠òÂèñÈÄôÂÄãÁ∂ìÈÅéÊï¥ÁêÜÁöÑÁü•Ë≠òÔºåÊàëÂÄëÊó®Âú®Áî¢ÁîüÊó¢Ë™ûË®ÄÊµÅÊö¢ÔºåÂèàÊ∑±Ê§çÊñº‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÂíåËÑàÁµ°Áõ∏ÈóúÊÄßÁöÑÂõûÊáâ„ÄÇÈÄôÁ®ÆÊï¥ÂêàÈÄèÈÅéÊèê‰æõÁ©©ÂÅ•ÁöÑË≥áË®äÂü∫Á§é‰æÜÊ∏õËºïÂπªË¶∫ÔºåËÆìÊ®°ÂûãÂú®ÂõûÊáâÁî¢ÁîüÊúüÈñìËÉΩÂ§†Âà©Áî®Ë±êÂØåÁöÑ‰∫ãÂØ¶Êï∏ÊìöÂÑ≤ÂÇô„ÄÇÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫ÜÂ§öÁ®ÆÊñπÊ≥ïÂú®Ê∏õÂ∞ëÂπªË¶∫ÂèçÊáâÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂº∑Ë™ø‰∫ÜÁ∂ìÈÅéÊï¥ÁêÜÁöÑÁü•Ë≠òÂúñË≠úÂú®ÊîπÂñÑË™ûË®ÄÊ®°ÂûãËº∏Âá∫ÁöÑÂèØÈù†ÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢ÊâÄÊâÆÊºîÁöÑËßíËâ≤„ÄÇ

##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v2 by Derong Xu, Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁ§∫‰∫ÜÈùûÂá°ÁöÑËÉΩÂäõÔºå‰ΩÜÂú®Âü∑Ë°åË§áÈõúÁöÑÁü•Ë≠òÊé®ÁêÜÊôÇÔºåÂçªÊúÉÂá∫ÁèæÂπªË¶∫ÂíåÈÅéÊôÇÁöÑÁü•Ë≠òÔºåÂ∞éËá¥‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÁöÑËº∏Âá∫„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÂòóË©¶ÈÄèÈÅéÂæûÂ§ßË¶èÊ®°Áü•Ë≠òÂúñË≠ú (KG) ‰∏≠Êì∑Âèñ‰∫ãÂØ¶Áü•Ë≠ò‰æÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºå‰ª•ÂçîÂä© LLM ÈÄ≤Ë°åÈÇèËºØÊé®ÁêÜÂíåÁ≠îÊ°àÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂºïÂÖ•ÈõúË®äÂíå‰∏çÁõ∏ÈóúÁöÑË≥áÊñôÔºåÁâπÂà•ÊòØÂú®ÂÖ∑Êúâ‰æÜËá™Â§öÂÄãÁü•Ë≠òÈù¢ÂêëÁöÑÂª£Ê≥õËÑàÁµ°ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÈÄôÊ®£‰∏Ä‰æÜÔºåLLM ÁöÑÊ≥®ÊÑèÂäõÂèØËÉΩÊúÉË¢´ÂïèÈ°åÂíåÁõ∏ÈóúË≥áË®äË™§Â∞é„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÈÅ©ÊáâÊÄßÂ§öÈù¢ÂêëÊì∑ÂèñÂ¢ûÂº∑ÂûãÁü•Ë≠òÂúñË≠ú (Amar) Ê°ÜÊû∂„ÄÇÊ≠§ÊñπÊ≥ïÊì∑ÂèñÂåÖÊã¨ÂØ¶È´î„ÄÅÈóú‰øÇÂíåÂ≠êÂúñÁöÑÁü•Ë≠òÔºå‰∏¶Â∞áÊØèÂÄãÊì∑ÂèñÁöÑÊñáÂ≠óËΩâÊèõÁÇ∫ÊèêÁ§∫ÂµåÂÖ•„ÄÇAmar Ê°ÜÊû∂ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÂ≠êÂÖÉ‰ª∂Ôºö1) ‰∏ÄÂÄãËá™ÊàëÂ∞çÈΩäÊ®°ÁµÑÔºåÁî®ÊñºÂ∞çÈΩäÂØ¶È´î„ÄÅÈóú‰øÇÂíåÂ≠êÂúñ‰πãÈñìÁöÑÂÖ±ÊÄßÔºå‰ª•Â¢ûÂº∑Êì∑ÂèñÁöÑÊñáÂ≠óÔºåÂæûËÄåÊ∏õÂ∞ëÈõúË®äÂπ≤ÊìæÔºõ2) ‰∏ÄÂÄãÁõ∏ÈóúÊÄßÈñòÊéßÊ®°ÁµÑÔºåÊé°Áî®ËªüÈñòÊéß‰æÜÂ≠∏ÁøíÂïèÈ°åÂíåÂ§öÈù¢ÂêëÊì∑ÂèñË≥áÊñô‰πãÈñìÁöÑÁõ∏ÂÖ≥ÊÄßÂàÜÊï∏Ôºå‰ª•Á¢∫ÂÆöÂì™‰∫õË≥áË®äÊáâ‰ΩøÁî®‰æÜÂ¢ûÂº∑ LLM ÁöÑËº∏Âá∫ÔºåÁîöËá≥ÂÆåÂÖ®ÈÅéÊøæÊéâ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄãÂ∏∏Ë¶ãÁöÑË≥áÊñôÈõÜ WebQSP Âíå CWQ ‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåËàáÊúÄ‰Ω≥Á´∂Áà≠ËÄÖÁõ∏ÊØîÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 1.9%ÔºåËàáÁõ¥Êé•‰ΩøÁî®Êì∑ÂèñÊñáÂ≠ó‰ΩúÁÇ∫ËÑàÁµ°ÊèêÁ§∫ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÈÇèËºØÂΩ¢ÂºèÁîüÊàêÊèêÂçá‰∫Ü 6.6%„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫Ü Amar Âú®ÊîπÂñÑ LLM Êé®ÁêÜÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **DynaGRAG: Improving Language Understanding and Generation through Dynamic Subgraph Representation in Graph Retrieval-Augmented Generation**
2412.18644v1 by Karishma Thakrar

Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework is proposed to focus on enhancing subgraph representation
and diversity within the knowledge graph. By improving graph density, capturing
entity and relation information more effectively, and dynamically prioritizing
relevant and diverse subgraphs, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results on
multiple benchmark datasets demonstrate the effectiveness of the proposed GRAG
framework, showcasing the significance of enhanced subgraph representation and
diversity for improved language understanding and generation.

ÊëòË¶ÅÔºöÂúñË°®Êì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàGRAG Êàñ Graph RAGÔºâÊû∂ÊßãÊó®Âú®
ÈÄèÈÅéÈÅãÁî®Â§ñÈÉ®Áü•Ë≠ò‰æÜÂ¢ûÂº∑Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàê„ÄÇ
ÁÑ∂ËÄåÔºåÊúâÊïàÊì∑ÂèñÂíåÊï¥ÂêàÊñáÊú¨ÂíåÁµêÊßãÂåñË≥áÊñô‰∏≠Ë±êÂØåÁöÑË™ûÁæ©Ë≥áË®ä‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ GRAG Ê°ÜÊû∂ÔºåÂ∞àÊ≥®ÊñºÂ¢ûÂº∑Áü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÂ≠êÂúñË°®Á§∫ÂíåÂ§öÊ®£ÊÄß„ÄÇÈÄèÈÅéÊîπÂñÑÂúñÂΩ¢ÂØÜÂ∫¶„ÄÅÊõ¥ÊúâÊïàÂú∞Êì∑ÂèñÂØ¶È´îÂíåÈóú‰øÇË≥áË®äÔºå‰ª•ÂèäÂãïÊÖãÂÑ™ÂÖàËÄÉÊÖÆÁõ∏Èóú‰∏îÂ§öÊ®£ÂåñÁöÑÂ≠êÂúñÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËÉΩÊõ¥ÂÖ®Èù¢Âú∞ÁêÜËß£Â∫ïÂ±§Ë™ûÁæ©ÁµêÊßã„ÄÇÈÄôÊòØÈÄèÈÅéÁµêÂêàÈáçË§áË≥áÊñôÂà™Èô§Á®ãÂ∫è„ÄÅÂµåÂÖ•ÁöÑÂÖ©Ê≠•È©üÂπ≥ÂùáÊ±†Âåñ„ÄÅËÄÉÊÖÆÂîØ‰∏ÄÁØÄÈªûÁöÑÊü•Ë©¢ÊÑüÁü•Êì∑ÂèñÔºå‰ª•ÂèäÂãïÊÖãÁõ∏‰ººÂ∫¶ÊÑüÁü•Âª£Â∫¶ÂÑ™ÂÖàÊêúÂ∞ãÔºàDSA-BFSÔºâÊºîÁÆóÊ≥ï‰æÜÂØ¶ÁèæÁöÑ„ÄÇÈÄèÈÅéÁ°¨ÊèêÁ§∫Êï¥ÂêàÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑ØÔºàGCNÔºâÂíåÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Ë±êÂØåÁØÄÈªûÂíåÈÇäÁ∑£Ë°®Á§∫ÁöÑÂ≠∏ÁøíÔºåÂêåÊôÇ‰øùÁïôÈöéÂ±§ÂºèÂ≠êÂúñÁµêÊßã„ÄÇÂú®Â§öÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑ GRAG Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÂ¢ûÂº∑Â≠êÂúñË°®Á§∫ÂíåÂ§öÊ®£ÊÄßÂ∞çÊñºÊîπÂñÑË™ûË®ÄÁêÜËß£ÂíåÁîüÊàêÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂÆåÊàê (KGC) ‰ªªÂãôÁöÑÊ†∏ÂøÉÊòØÈ†êÊ∏¨ÂíåÂÆåÊàê KG ‰∏≠ÈÅ∫Â§±ÁöÑÈóú‰øÇÊàñÁØÄÈªû„ÄÇÂ∏∏Ë¶ãÁöÑ KGC ‰ªªÂãôÂ§ßÂ§öÊòØÈóúÊñºÊé®Ë´ñÊú™Áü•ÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÊàñÂÖ©ÂÄãÂÖÉÁ¥†Âú®‰∏âÂÖÉÁµÑ‰∏≠Â∑≤Áü•„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∏âÂÖÉÁµÑÈõÜÂêàÈ†êÊ∏¨ (TSP) ‰ªªÂãôÊòØ‰∏ÄÂÄãÊõ¥ÂØ¶ÈöõÁöÑÁü•Ë≠òÂúñË≠úÂÆåÊàê‰ªªÂãô„ÄÇÂÆÉÊó®Âú®Ê†πÊìöÂ∑≤Áü•‰∏âÂÖÉÁµÑ‰∏≠ÁöÑË≥áË®äÈ†êÊ∏¨Êú™Áü•‰∏âÂÖÉÁµÑÁöÑÊâÄÊúâÂÖÉÁ¥†„ÄÇËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë™ûË®ÄÁêÜËß£ÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÈ°ØÁ§∫Âá∫ KGC ‰ªªÂãôÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM Âú® TSP ‰ªªÂãô‰∏äÁöÑÊΩõÂäõÂ∞öÊú™ÂæóÂà∞Êé¢Ë®é„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊ°ÜÊû∂‰æÜÊé¢Á¥¢ LLM Âú® TSP ‰ªªÂãô‰∏≠ÁöÑÂÑ™Âã¢ÂíåÂ±ÄÈôêÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåË©≤Ê°ÜÊû∂ÂåÖÂê´Âü∫Êñº LLM ÁöÑË¶èÂâáÊåñÊéòÂíåÂü∫Êñº LLM ÁöÑ‰∏âÂÖÉÁµÑÈõÜÂêàÈ†êÊ∏¨„ÄÇÂµåÂÖ•Ë±êÂØåË™ûÁæ©Ë≥áË®äÁöÑ KG Èóú‰øÇÊ∏ÖÂñÆÈ¶ñÂÖàË¢´Âà©Áî®‰æÜÊèêÁ§∫ LLM ÁîüÊàêË¶èÂâá„ÄÇÈÄôÂÄãÈÅéÁ®ãÊó¢ÊúâÊïàÁéáÂèàÁç®Á´ãÊñºÁµ±Ë®àË≥áË®äÔºå‰ΩøÂæóÊåñÊéòÊúâÊïà‰∏îÂØ¶ÈöõÁöÑË¶èÂâáËÆäÂæóÊõ¥ÂÆπÊòì„ÄÇÂ∞çÊñºÊØèÂÄãÂ≠êÂúñÔºåÊåáÂÆöË¶èÂâáËàáË©≤Â≠êÂúñ‰∏≠Áõ∏ÈóúÁöÑ‰∏âÂÖÉÁµÑÁµêÂêà‰ΩøÁî®Ôºå‰ª•ÊåáÂ∞é LLM È†êÊ∏¨ÈÅ∫Â§±ÁöÑ‰∏âÂÖÉÁµÑ„ÄÇÈö®ÂæåÔºåÂêà‰ΩµÊâÄÊúâÂ≠êÂúñÁöÑÈ†êÊ∏¨Ôºå‰ª•Êé®Â∞é KG ‰∏äÈ†êÊ∏¨‰∏âÂÖÉÁµÑÁöÑÂÆåÊï¥ÈõÜÂêà„ÄÇÊúÄÂæåÔºåË©≤ÊñπÊ≥ïÂú®Áõ∏Â∞çÂÆåÊï¥ÁöÑ CFamily Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁï∂Ë¶ÅÊ±Ç LLM ÈÅµÂæ™Â§ßÈáè‰∫ãÂØ¶Áü•Ë≠ò‰æÜÈ†êÊ∏¨ÈÅ∫Â§±ÁöÑ‰∏âÂÖÉÁµÑÊôÇÔºåÊúÉÁôºÁîüÈ°ØËëóÁöÑÂπªË¶∫ÔºåÂ∞éËá¥ÊïàËÉΩÈ°ØËëó‰∏ãÈôç„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Êé¢Ë®éÈÄôÁ®ÆÁèæË±°ÁöÑÂéüÂõ†ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÁî±Ë©≥Á¥∞Ê°à‰æãÁ†îÁ©∂ÊîØÊè¥ÁöÑÂÖ®Èù¢ÂàÜÊûê„ÄÇ

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v2 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

ÊëòË¶ÅÔºöÁ®ãÂºèÁ¢ºÊºèÊ¥ûÂÅµÊ∏¨ (CVD) Â∞çËß£Ê±∫ÂíåÈ†êÈò≤Á≥ªÁµ±ÂÆâÂÖ®ÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºåÂú®Á¢∫‰øùËªüÈ´îÂÆâÂÖ®‰∏äÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇ
ÂÖàÂâçÁöÑÂü∫ÊñºÂ≠∏ÁøíÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÊñπÊ≥ï‰ª∞Ë≥¥ÂæÆË™ø‰∏≠ÂûãÂ∫èÂàóÊ®°ÂûãÊàñÂæûÈ†≠Ë®ìÁ∑¥ËºÉÂ∞èÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇ
Â§ßÂûãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂú®ÂêÑÁ®ÆÁ®ãÂºèÁ¢ºÊô∫ÊÖß‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõÔºåÂåÖÊã¨Á®ãÂºèÁ¢ºÁêÜËß£ÂíåÁî¢Áîü„ÄÇ
ÁÑ∂ËÄåÔºåLLM Âú®ÂÅµÊ∏¨Á®ãÂºèÁ¢ºÊºèÊ¥ûÁöÑÊïàËÉΩÂçªÈÆÆÂ∞ëË¢´Êé¢Ë®é„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéÂæÆË™ø LLM ‰æÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊ∂âÂèäÂõõÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÈñãÊ∫ê LLM„ÄÇ
ÊàëÂÄë‰πüÂØ¶‰Ωú‰∫ÜÂÖ∂‰ªñ‰∫îÂÄãÂÖàÂâçÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊàñ‰∏≠ÂûãÂ∫èÂàóÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇ
ÂØ¶È©óÂú®‰∫îÂÄãÂ∏∏Áî®ÁöÑ CVD Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÔºåÂåÖÂê´Áü≠ÁØÑ‰æãÂíåÈï∑ÁØÑ‰æãÁöÑÈÉ®ÂàÜ„ÄÇ
Ê≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÈáèÂåñÂØ¶È©ó‰æÜÊé¢Ë®éÈ°ûÂà•‰∏çÂπ≥Ë°°ÂïèÈ°åÂíåÊ®°ÂûãÂú®‰∏çÂêåÈï∑Â∫¶ÁØÑ‰æã‰∏äÁöÑË°®ÁèæÔºåÈÄô‰∫õÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠ÂæàÂ∞ëË¢´Êé¢Ë®é„ÄÇ
ÁÇ∫Êõ¥Â•ΩÂú∞‰øÉÈÄ≤Á§æÁæ§ÔºåÊàëÂÄëÂú® https://github.com/SakiRinn/LLM4CVD Âíå https://huggingface.co/datasets/xuefen/VulResource ÈñãÊ∫êÊú¨Á†îÁ©∂ÁöÑÊâÄÊúâÁ®ãÂºèÁ¢ºÂíåË≥áÊ∫ê„ÄÇ

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

ÊëòË¶ÅÔºöÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤ÊàêÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂèØÂæûÂúñÂΩ¢ÁµêÊßãÂåñË≥áÊñô‰∏≠Â≠∏ÁøíÊé®Ëñ¶„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫Êñº GNN ÁöÑÊé®Ëñ¶ÊñπÊ≥ïÂ§ßÂ§öÂÅ¥ÈáçÊñºÈ†êÂÆöÁæ©ÂúñÂΩ¢‰∏äÁöÑÊ®°ÂûãÁµêÊßãÂíåÂ≠∏ÁøíÁ≠ñÁï•ÁöÑÊúÄ‰Ω≥ÂåñÔºåÂøΩÁï•‰∫ÜÂúñÂΩ¢Âª∫ÊßãÈöéÊÆµÁöÑÈáçË¶ÅÊÄß„ÄÇÊó©ÊúüÂúñÂΩ¢Âª∫ÊßãÂ∑•‰ΩúÈÄöÂ∏∏‰æùË≥¥ÊñºÁâπÂÆöË¶èÂâáÊàñÁæ§ÁúæÂ§ñÂåÖÔºåÈÄô‰∫õÊñπÊ≥ïÈÅéÊñºÁ∞°ÂåñÊàñÈÅéÊñºÂãûÂãïÂØÜÈõÜ„ÄÇÊúÄËøëÁöÑÂ∑•‰ΩúÈñãÂßãÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËá™ÂãïÂåñÂúñÂΩ¢Âª∫ÊßãÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÖ∑ÊúâË±êÂØåÁöÑÈñãÊîæ‰∏ñÁïåÁü•Ë≠òÂíåÂçìË∂äÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÆÉÂÄëÈÄöÂ∏∏Â≠òÂú®ÂÖ©ÂÄãÈôêÂà∂Ôºö(1) ÂÖ®ÂüüÊ™¢Ë¶ñÁöÑ‰∏çÂèØË¶ãÊÄßÔºà‰æãÂ¶ÇÔºåÂøΩÁï•‰∏ä‰∏ãÊñáË≥áË®äÔºâÂíå (2) Âª∫ÊßãÊïàÁéá‰Ωé‰∏ã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü AutoGraphÔºå‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑËá™ÂãïÂúñÂΩ¢Âª∫ÊßãÊ°ÜÊû∂ÔºåÁî®ÊñºÊé®Ëñ¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® LLM Êé®Êñ∑‰ΩøÁî®ËÄÖÂÅèÂ•ΩÂíåÈ†ÖÁõÆÁü•Ë≠òÔºå‰∏¶Â∞áÂÖ∂Á∑®Á¢ºÁÇ∫Ë™ûÁæ©ÂêëÈáè„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊé°Áî®ÂêëÈáèÈáèÂåñÂæûË™ûÁæ©ÂêëÈáè‰∏≠ÊèêÂèñÊΩõÂú®Âõ†Â≠ê„ÄÇÁÑ∂ÂæåÂ∞áÊΩõÂú®Âõ†Â≠ê‰ΩúÁÇ∫È°çÂ§ñÁØÄÈªûÂä†ÂÖ•Ôºå‰ª•ÈÄ£Áµê‰ΩøÁî®ËÄÖ/È†ÖÁõÆÁØÄÈªûÔºåÂæûËÄåÂΩ¢Êàê‰∏ÄÂÄãÂÖ∑ÊúâÊ∑±ÂÖ•ÂÖ®ÂüüÊ™¢Ë¶ñË™ûÁæ©ÁöÑÂúñÂΩ¢„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∫ÜÂü∫ÊñºÂÖÉË∑ØÂæëÁöÑË®äÊÅØËÅöÂêàÔºå‰ª•ÊúâÊïàËÅöÂêàË™ûÁæ©ÂíåÂçî‰ΩúË≥áË®ä„ÄÇË©≤Ê°ÜÊû∂ËàáÊ®°ÂûãÁÑ°ÈóúÔºå‰∏¶Ëàá‰∏çÂêåÁöÑ‰∏ªÂππÊ®°ÂûãÁõ∏ÂÆπ„ÄÇÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü AutoGraph ËàáÁèæÊúâÂü∫Ê∫ñÊñπÊ≥ïÁõ∏ÊØîÁöÑÊïàËÉΩÂíåÊïàÁéá„ÄÇÊàëÂÄëÂ∑≤Âú®ËèØÁÇ∫Âª£ÂëäÂπ≥Âè∞‰∏äÈÉ®ÁΩ≤‰∫Ü AutoGraphÔºå‰∏¶Âú®Á∑ö‰∏ä A/B Ê∏¨Ë©¶‰∏≠Áç≤Âæó‰∫Ü RPM ÊèêÂçá 2.69% Âíå eCPM ÊèêÂçá 7.31%„ÄÇÁõÆÂâç AutoGraph Â∑≤Ë¢´Áî®‰Ωú‰∏ªË¶ÅÁöÑÊµÅÈáèÊ®°ÂûãÔºåÊúçÂãôÊñºÊï∏ÂÑÑ‰∫∫„ÄÇ

##### **CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**
2412.17970v1 by Ruibo Tu, Hedvig Kjellstr√∂m, Gustav Eje Henter, Cheng Zhang

Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.

ÊëòË¶ÅÔºöÂõ†ÊûúÊé®ÁêÜËÉΩÂäõÂØπ‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÈÄÇÁî®‰∫éÂπøÊ≥õÁöÑÂ∫îÁî®Ôºå‰æãÂ¶ÇÊïôËÇ≤ÂíåÂåªÁñó‰øùÂÅ•„ÄÇ‰ΩÜÂØπ‰∫éÊõ¥Â•ΩÂú∞ÁêÜËß£Ê≠§Á±ªËÉΩÂäõÔºå‰ªçÁÑ∂Áº∫‰πèÂü∫ÂáÜ„ÄÇÂΩìÂâçÁöÑ LLM Âü∫ÂáÜ‰∏ªË¶ÅÂü∫‰∫é‰ºöËØù‰ªªÂä°„ÄÅÂ≠¶ÊúØÊï∞Â≠¶ÊµãËØïÂíåÁºñÁ†ÅÊµãËØï„ÄÇÊ≠§Á±ªÂü∫ÂáÜÂú®ÁªèËøáËâØÂ•ΩËßÑËåÉÁöÑÁéØÂ¢É‰∏≠ËØÑ‰º∞ LLMÔºå‰ΩÜÂÆÉ‰ª¨Âú®ËØÑ‰º∞Ëß£ÂÜ≥ÂÆûÈôÖÈóÆÈ¢òÁöÑËÉΩÂäõÂíåÊäÄËÉΩÊñπÈù¢ÂèóÂà∞ÈôêÂà∂„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âü∫ÂáÜÔºåÂêç‰∏∫ CARL-GTÔºåÂÆÉ‰ΩøÁî®ÂõæÂíåË°®Ê†ºÊï∞ÊçÆÊù•ËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂõ†ÊûúÊé®ÁêÜËÉΩÂäõ„ÄÇËØ•Âü∫ÂáÜÂÖ∑ÊúâÂêÑÁßç‰ªªÂä°ÔºåÁî®‰∫é‰ªéÂõ†ÊûúÂõæÊé®ÁêÜ„ÄÅÁü•ËØÜÂèëÁé∞ÂíåÂÜ≥Á≠ñÊñπÈù¢ËØÑ‰º∞ LLM„ÄÇÊ≠§Â§ñÔºåÈíàÂØπËøô‰∫õ‰ªªÂä°ÂºÄÂèë‰∫ÜÊúâÊïàÁöÑÈõ∂Ê†∑Êú¨Â≠¶‰π†ÊèêÁ§∫„ÄÇÂú®Êàë‰ª¨ÁöÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨Âà©Áî®Âü∫ÂáÜÊù•ËØÑ‰º∞ÂºÄÊ∫ê LLMÔºåÂπ∂ÂØπ LLM ÁöÑÂõ†ÊûúÊé®ÁêÜËÉΩÂäõËøõË°å‰∫ÜËØ¶ÁªÜÊØîËæÉ„ÄÇÊàë‰ª¨ÂèëÁé∞ LLM Âú®Âõ†ÊûúÊé®ÁêÜÊñπÈù¢‰ªçÁÑ∂ÂæàÂº±ÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ΩøÁî®Ë°®Ê†ºÊï∞ÊçÆÂèëÁé∞Êñ∞ËßÅËß£Êó∂„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÈÄöËøáÂàÜÊûê LLM ÁöÑÊÄßËÉΩÊù•Ë∞ÉÊü•ÂíåËÆ®ËÆ∫‰∏çÂêåÂü∫ÂáÜ‰ªªÂä°‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåLLM Âú®‰∏çÂêå‰ªªÂä°‰∏äÂÖ∑Êúâ‰∏çÂêåÁöÑ‰ºòÂäøÔºåÂπ∂‰∏îÂÆÉ‰ª¨Âú®‰∏çÂêåÁ±ªÂà´‰∏≠ÁöÑ‰ªªÂä°‰∏äÁöÑË°®Áé∞ÔºåÂç≥Âõ†ÊûúÂõæÊé®ÁêÜ„ÄÅÁü•ËØÜÂèëÁé∞ÂíåÂÜ≥Á≠ñÔºåÊØîÂêå‰∏ÄÁ±ªÂà´‰∏≠ÁöÑ‰ªªÂä°Ë°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ

##### **Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**
2412.17963v1 by Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao

Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâÂª£Ê≥õÁöÑË™ûÁæ©Áü•Ë≠òÔºå‰ΩÜÂú®Ë§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãô‰∏≠Á∂ìÂ∏∏ÈÅáÂà∞Âõ∞Èõ£ÔºåÁâπÂà•ÊòØÂú®Èóú‰øÇÊé®ÁêÜÂïèÈ°å‰∏≠Ôºå‰æãÂ¶ÇË¶™Â±¨Èóú‰øÇÊàñÁ©∫ÈñìÊé®ÁêÜ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÊÄùËÄÉË∑ØÂæë (PoT)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄöÈÅéÂ∞á‰ªªÂãôÂàÜËß£ÁÇ∫‰∏âÂÄãÈóúÈçµÈöéÊÆµ‰æÜËß£Ê±∫Èóú‰øÇÊé®ÁêÜÔºöÂúñÂΩ¢ÊèêÂèñ„ÄÅË∑ØÂæëË≠òÂà•ÂíåÊé®ÁêÜ„ÄÇËàá‰πãÂâçÁöÑÂÅöÊ≥ï‰∏çÂêåÔºåPoT ÊúâÊïàÂú∞ÊèêÂèñ‰∫Ü‰∏ÄÂÄãËàá‰ªªÂãôÁÑ°ÈóúÁöÑÂúñÂΩ¢ÔºåË©≤ÂúñÂΩ¢Ë≠òÂà•‰∫ÜÂïèÈ°åËÉåÊôØ‰∏≠ÁöÑÈóúÈçµÂØ¶È´î„ÄÅÈóú‰øÇÂíåÂ±¨ÊÄß„ÄÇÈö®ÂæåÔºåPoT Âú®ËàáÊâÄÊèêÂá∫ÁöÑÂïèÈ°åÁõ∏ÊáâÁöÑÂúñÂΩ¢‰∏≠Ë≠òÂà•Âá∫Áõ∏ÈóúÁöÑÊé®ÁêÜÈèàÔºåÂæûËÄåÊé®Êñ∑Âá∫ÊΩõÂú®Á≠îÊ°à„ÄÇÂú®ÈúÄË¶ÅÈï∑Êé®ÁêÜÈèàÁöÑÂõõÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óË©ï‰º∞Ë°®ÊòéÔºåPoT ‰ª•È°ØËëóÁöÑÂÑ™Âã¢ÔºàÊúÄÂ§ß 21.3%ÔºâË∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÔºåËÄåÁÑ°ÈúÄÂæÆË™øÊàñÂª£Ê≥õÁöÑ LLM Ë™øÁî®„ÄÇÊ≠§Â§ñÔºåËàáÂÖàÂâçÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÁõ∏ÂèçÔºåPoT ÈÄöÈÅéÂà©Áî®ÂúñÂΩ¢ÁöÑÁµÑÂêàÁâπÊÄßË°®ÁèæÂá∫Â∞ç LLM ÈåØË™§ÁöÑÂ¢ûÂº∑ÁöÑÂΩàÊÄß„ÄÇ

##### **ResearchTown: Simulator of Human Research Community**
2412.17767v1 by Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You

Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁßëÂ≠∏È†òÂüüÂ±ïÁèæ‰∫ÜÈùûÂá°ÁöÑÊΩõÂäõÔºå‰ΩÜ‰ªçÊúâ‰∏ÄÂÄãÂü∫Êú¨ÂïèÈ°åÂ∞öÊú™Ëß£Á≠îÔºöÊàëÂÄëËÉΩÁî® LLM Ê®°Êì¨‰∫∫È°ûÁ†îÁ©∂Á§æÁæ§ÂóéÔºüÊé¢Ë®éÈÄôÂÄãÂïèÈ°åËÉΩÂä†Ê∑±ÊàëÂÄëÂ∞çËÖ¶ÂäõÊøÄÁõ™ËÉåÂæåÊµÅÁ®ãÁöÑÁêÜËß£Ôºå‰∏¶ÊøÄÁôºËá™ÂãïÁôºÁèæÊñ∞ÁßëÂ≠∏Ë¶ãËß£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ ResearchTownÔºå‰∏ÄÂÄãÁî®ÊñºÁ†îÁ©∂Á§æÁæ§Ê®°Êì¨ÁöÑÂ§ö‰ª£ÁêÜÊû∂Êßã„ÄÇÂú®ÈÄôÂÄãÊû∂Êßã‰∏≠Ôºå‰∫∫È°ûÁ†îÁ©∂Á§æÁæ§Ë¢´Á∞°Âåñ‰∏¶Âª∫Ê®°ÁÇ∫‰ª£ÁêÜË≥áÊñôÂúñÔºåÂÖ∂‰∏≠Á†îÁ©∂‰∫∫Âì°ÂíåË´ñÊñáÂàÜÂà•Ë°®Á§∫ÁÇ∫‰ª£ÁêÜÈ°ûÂûãÁØÄÈªûÂíåË≥áÊñôÈ°ûÂûãÁØÄÈªûÔºå‰∏¶Ê†πÊìö‰ªñÂÄëÁöÑÂêà‰ΩúÈóú‰øÇÈÄ≤Ë°åÈÄ£Êé•„ÄÇÊàëÂÄëÈÇÑ‰ªãÁ¥π‰∫Ü TextGNNÔºå‰∏ÄÂÄãÂü∫ÊñºÊñáÂ≠óÁöÑÊé®Ë´ñÊû∂ÊßãÔºåÂÆÉÂ∞áÂêÑÁ®ÆÁ†îÁ©∂Ê¥ªÂãïÔºà‰æãÂ¶ÇÔºåÈñ±ËÆÄË´ñÊñá„ÄÅÊí∞ÂØ´Ë´ñÊñáÂíåÊí∞ÂØ´Ë©ïË´ñÔºâÂª∫Ê®°ÁÇ∫‰ª£ÁêÜË≥áÊñôÂúñ‰∏äÁµ±‰∏ÄË®äÊÅØÂÇ≥ÈÅûÈÅéÁ®ãÁöÑÁâπÊÆäÂΩ¢Âºè„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Á†îÁ©∂Ê®°Êì¨ÁöÑÂìÅË≥™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü ResearchBenchÔºå‰∏ÄÂÄã‰ΩøÁî®ÁØÄÈªûÈÅÆÁΩ©È†êÊ∏¨‰ªªÂãôÈÄ≤Ë°åÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÂèØÊì¥ÂÖÖ‰∏îÂÆ¢ËßÄË©ï‰º∞ÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü‰∏âÂÄãÈóúÈçµÁôºÁèæÔºö(1) ResearchTown ÂèØ‰ª•Êèê‰æõÂçî‰ΩúÁ†îÁ©∂Ê¥ªÂãïÁöÑÈÄºÁúüÊ®°Êì¨ÔºåÂåÖÊã¨Êí∞ÂØ´Ë´ñÊñáÂíåÊí∞ÂØ´Ë©ïË´ñÔºõ(2) ResearchTown ÂèØ‰ª•Á∂≠ÊåÅÂ§ö‰ΩçÁ†îÁ©∂‰∫∫Âì°Âíå‰∏çÂêåË´ñÊñáÁöÑÁ©©ÂÅ•Ê®°Êì¨Ôºõ(3) ResearchTown ÂèØ‰ª•Áî¢ÁîüË∑®Â≠∏ÁßëÁ†îÁ©∂ÊßãÊÉ≥ÔºåÊΩõÂú®ÊøÄÁôºÊñ∞ÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇ

##### **RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**
2412.17690v3 by Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech

Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.

ÊëòË¶ÅÔºöÂ∞çË©±ÂºèÂïèÁ≠îÔºàConvQAÔºâÊòØ‰∏ÄÁ®ÆÊêúÂ∞ã RDF Áü•Ë≠òÂúñË≠úÔºàKGÔºâÁöÑ‰æøÂà©ÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰∏ÄÁ®ÆÊôÆÈÅçÁöÑÊñπÊ≥ïÊòØÂ∞áËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åËΩâÊèõÁÇ∫ SPARQL Êü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåSPARQL ÊúâÊüê‰∫õÁº∫ÈªûÔºö(i) Â∞çÊñºË§áÈõúÁöÑÊÑèÂúñÂíåÂ∞çË©±ÂºèÂïèÈ°åËÄåË®ÄÔºåÂÆÉÂæàËÑÜÂº±Ôºå(ii) ÂÆÉ‰∏çÈÅ©ÂêàÊõ¥ÊäΩË±°ÁöÑÈúÄÊ±Ç„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÈõôÁÆ°ÈΩä‰∏ãÁöÑÁ≥ªÁµ±ÔºåÂÖ∂‰∏≠ÊàëÂÄëËûçÂêàÔºö(i) ÂæûËá™ÂãïÂæû KG ‰∏≠Ê¥æÁîüÁöÑË≥áÊñôÂ∫´‰∏äÁöÑ SQL Êü•Ë©¢ÁµêÊûúÔºå‰ª•Âèä (ii) KG ‰∫ãÂØ¶ÁöÑË®ÄË™ûÂåñ‰∏äÁöÑÊñáÂ≠óÊêúÂ∞ãÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁÆ°Á∑öÊîØÊè¥ÂèçË¶ÜÊ™¢Á¥¢ÔºöÁï∂ÁôºÁèæ‰ªª‰ΩïÂàÜÊîØÁöÑÁµêÊûú‰∏ç‰ª§‰∫∫ÊªøÊÑèÊôÇÔºåÁ≥ªÁµ±ÂèØ‰ª•Ëá™ÂãïÈÅ∏ÊìáÈÄ≤‰∏ÄÊ≠•ÁöÑÂõûÂêà„ÄÇÊàëÂÄëÂ∞áÊâÄÊúâÂÖßÂÆπÊï¥ÂêàÂà∞Ê™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÔºàRAGÔºâË®≠ÂÆö‰∏≠ÔºåÂÖ∂‰∏≠ LLM ÂæûÁ¥ØÁ©çÁöÑÊêúÂ∞ãÁµêÊûú‰∏≠Áî¢ÁîüÈÄ£Ë≤´ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÂú® BMW Ê±ΩËªäÁöÑÁü•Ë≠òÂúñË≠ú‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÁ≥ªÁµ±ÂÑ™ÊñºÂπæÂÄãÂü∫Á∑öÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **A Dual-Perspective Metaphor Detection Framework Using Large Language Models**
2412.17332v2 by Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su

Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.

ÊëòË¶ÅÔºöÈö±ÂñªÂÅµÊ∏¨ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãôÔºåÊ∂âÂèäË≠òÂà•Âè•Â≠ê‰∏≠ÁâπÂÆöÂñÆÂ≠óÊòØÂê¶‰ª•Èö±ÂñªÊñπÂºè‰ΩøÁî®„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Áõ£Áù£ÂºèÂ≠∏ÁøíÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÊ†πÊìöÈö±ÂñªÁêÜË´ñÈö±Âê´Á∑®Á¢ºË™ûÁæ©Èóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏Âú®Ê±∫Á≠ñÈÅéÁ®ã‰∏≠Áº∫‰πèÈÄèÊòéÂ∫¶ÔºåÈÄôÊúÉÊêçÂÆ≥ÂÖ∂È†êÊ∏¨ÁöÑÂèØÈù†ÊÄß„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåLLMÔºàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºâÂú®Èö±ÂñªÂÅµÊ∏¨‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂÆÉÂÄëÁöÑÊé®ÁêÜËÉΩÂäõÂèóÂà∞È†êÂÆöÁæ©Áü•Ë≠òÂúñË°®ÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DMDÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈõôÈáçËßÄÈªûÊû∂ÊßãÔºåÂÆÉÂà©Áî®Èö±ÂñªÁêÜË´ñÁöÑÈö±Âê´ÂíåÊòéÁ¢∫ÊáâÁî®‰æÜÂºïÂ∞é LLM ÈÄ≤Ë°åÈö±ÂñªÂÅµÊ∏¨Ôºå‰∏¶Êé°Áî®Ëá™ÊàëÂà§Êñ∑Ê©üÂà∂‰æÜÈ©óË≠â‰∏äËø∞ÊåáÂ∞éÂΩ¢ÂºèÁöÑÂõûÊáâ„ÄÇËàáÂÖàÂâçÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊû∂ÊßãÊèê‰æõ‰∫ÜÊõ¥ÈÄèÊòéÁöÑÊé®ÁêÜÈÅéÁ®ãÔºå‰∏¶Êèê‰æõ‰∫ÜÊõ¥ÂèØÈù†ÁöÑÈ†êÊ∏¨„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü DMD ÁöÑÊúâÊïàÊÄßÔºåË≠âÊòé‰∫ÜÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜ‰∏≠ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇ

##### **GraphAgent: Agentic Graph Language Assistant**
2412.17029v1 by Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang

Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.

ÊëòË¶ÅÔºöÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñô‰ª•ÁµêÊßãÂåñÔºà‰æãÂ¶ÇÂúñÂΩ¢ÈÄ£Êé•ÔºâÂíåÈùûÁµêÊßãÂåñÔºà‰æãÂ¶ÇÊñáÂ≠ó„ÄÅË¶ñË¶∫Ë≥áË®äÔºâÊ†ºÂºèÂëàÁèæÔºåÂåÖÂê´Ë§áÈõúÁöÑÈóú‰øÇÔºåÂåÖÊã¨ÊòéÁ¢∫ÁöÑÈÄ£ÁµêÔºà‰æãÂ¶ÇÁ§æ‰∫§ÈÄ£ÁµêÂíå‰ΩøÁî®ËÄÖË°åÁÇ∫ÔºâÂíåË™ûÊÑèÂØ¶È´î‰πãÈñìÁöÑÈö±Âê´Áõ∏‰∫í‰æùË≥¥ÔºåÈÄöÂ∏∏ÈÄèÈÅéÁü•Ë≠òÂúñË°®‰æÜË™™Êòé„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ GraphAgentÔºå‰∏ÄÂÄãËá™ÂãïÂåñ‰ª£ÁêÜÁ®ãÂºèÁÆ°ÈÅìÔºåÂÆÉËôïÁêÜÊòéÁ¢∫ÁöÑÂúñÂΩ¢‰æùË≥¥Èóú‰øÇÂíåÈö±Âê´ÁöÑÂúñÂΩ¢Â¢ûÂº∑Ë™ûÊÑèÁõ∏‰∫í‰æùË≥¥Èóú‰øÇÔºåËàáÈ†êÊ∏¨‰ªªÂãôÔºà‰æãÂ¶ÇÁØÄÈªûÂàÜÈ°ûÔºâÂíåÁîüÊàê‰ªªÂãôÔºà‰æãÂ¶ÇÊñáÂ≠óÁîüÊàêÔºâÁöÑÂØ¶ÈöõË≥áÊñôÊÉÖÂ¢É‰øùÊåÅ‰∏ÄËá¥„ÄÇGraphAgent ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö(i) ‰∏ÄÂÄãÂúñÂΩ¢Áî¢ÁîüÂô®‰ª£ÁêÜÁ®ãÂºèÔºåÁî®‰æÜÂª∫ÊßãÁü•Ë≠òÂúñË°®‰ª•ÂèçÊò†Ë§áÈõúÁöÑË™ûÊÑè‰æùË≥¥Èóú‰øÇÔºõ(ii) ‰∏ÄÂÄã‰ªªÂãôË¶èÂäÉ‰ª£ÁêÜÁ®ãÂºèÔºåÁî®‰æÜË©ÆÈáã‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÊü•Ë©¢Ôºå‰∏¶ÈÄèÈÅé‰ª£ÁêÜËá™Ë¶èÂäÉÂà∂ÂÆöÁõ∏ÊáâÁöÑ‰ªªÂãôÔºõ‰ª•Âèä (iii) ‰∏ÄÂÄã‰ªªÂãôÂü∑Ë°å‰ª£ÁêÜÁ®ãÂºèÔºåÁî®‰æÜÂú®ÂõûÊáâ‰ΩøÁî®ËÄÖÊü•Ë©¢ÊôÇÔºåÊúâÊïàÁéáÂú∞Âü∑Ë°åÂ∑≤Ë¶èÂäÉÁöÑ‰ªªÂãôÔºåÂêåÊôÇËá™ÂãïÂåñÂ∑•ÂÖ∑ÈÖçÂ∞çÂíåÂëºÂè´„ÄÇÈÄô‰∫õ‰ª£ÁêÜÁ®ãÂºèÁÑ°Á∏´Âú∞Âçî‰ΩúÔºåÂ∞áË™ûË®ÄÊ®°ÂûãËàáÂúñÂΩ¢Ë™ûË®ÄÊ®°ÂûãÊï¥ÂêàÂú®‰∏ÄËµ∑Ôºå‰ª•Êè≠Èú≤Ë§áÈõúÁöÑÈóú‰øÇË≥áË®äÂíåË≥áÊñôË™ûÊÑè‰æùË≥¥Èóú‰øÇ„ÄÇÈÄèÈÅéÂú®‰∏çÂêåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂêÑÁ®ÆËàáÂúñÂΩ¢Áõ∏ÈóúÁöÑÈ†êÊ∏¨ÂíåÊñáÂ≠óÁîüÊàê‰ªªÂãôÁöÑÂª£Ê≥õÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫Ü GraphAgent Âú®ÂêÑÁ®ÆË®≠ÂÆö‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂ∑≤Â∞áÊàëÂÄëÊèêÂá∫ÁöÑ GraphAgent ÈñãÊ∫êÔºöhttps://github.com/HKUDS/GraphAgent„ÄÇ

##### **Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**
2412.16922v1 by Bohan Jin, Qianyou Sun, Lihua Chen

In the current global economy, supply chain transparency plays a pivotal role
in ensuring this security by enabling companies to monitor supplier performance
and fostering accountability and responsibility. Despite the advancements in
supply chain relationship datasets like Bloomberg and FactSet, supply chain
transparency remains a significant challenge in emerging economies due to
issues such as information asymmetry and institutional gaps in regulation. This
study proposes a novel approach to enhance supply chain transparency in
emerging economies by leveraging online content and large language models
(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates
advanced LLMs with web crawler technology to automatically collect and analyze
supply chain information. The system's effectiveness is validated through a
case study focusing on the semiconductor supply chain, a domain that has
recently gained significant attention due to supply chain risks. Our results
demonstrate that the proposed system provides greater applicability for
emerging economies, such as mainland China, complementing the data gaps in
existing datasets. However, challenges including the accurate estimation of
monetary and material flows, the handling of time series data, synonyms
disambiguation, and mitigating biases from online contents still remains.
Future research should focus on addressing these issues to further enhance the
system's capabilities and broaden its application to other emerging economies
and industries.

ÊëòË¶ÅÔºöÂú®Áï∂‰ªäÂÖ®ÁêÉÁ∂ìÊøü‰∏≠Ôºå‰æõÊáâÈèàÈÄèÊòéÂ∫¶Âú®Á¢∫‰øùÊ≠§ÂÆâÂÖ®ÊÄßÊñπÈù¢ÁôºÊèÆËëóÈóúÈçµ‰ΩúÁî®ÔºåËÆìÂÖ¨Âè∏ËÉΩÂ§†Áõ£Êéß‰æõÊáâÂïÜÁ∏æÊïà‰∏¶‰øÉÈÄ≤ÂïèË≤¨Âà∂ÂíåË≤¨‰ªªÊÑü„ÄÇÂÑòÁÆ°ÂΩ≠ÂçöÁ§æÂíå FactSet Á≠â‰æõÊáâÈèàÈóú‰øÇÊï∏ÊìöÈõÜÂèñÂæóÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºË≥áË®ä‰∏çÂ∞çÁ®±ÂíåÊ≥ïË¶èÂà∂Â∫¶Â∑ÆË∑ùÁ≠âÂïèÈ°åÔºå‰æõÊáâÈèàÈÄèÊòéÂ∫¶Âú®ÈñãÁôº‰∏≠ÂúãÂÆ∂‰ªçÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®Á∑ö‰∏äÂÖßÂÆπÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂä†Âº∑ÈñãÁôº‰∏≠ÂúãÂÆ∂ÁöÑ‰æõÊáâÈèàÈÄèÊòéÂ∫¶„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã‰æõÊáâÈèàÁü•Ë≠òÂúñË≠úÊåñÊéòÁ≥ªÁµ±ÔºåÂ∞áÂÖàÈÄ≤ÁöÑ LLM ËàáÁ∂≤Ë∑ØÁà¨Ëü≤ÊäÄË°ìÊï¥ÂêàÂú®‰∏ÄËµ∑Ôºå‰ª•Ëá™ÂãïÊî∂ÈõÜÂíåÂàÜÊûê‰æõÊáâÈèàË≥áË®ä„ÄÇË©≤Á≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂ∑≤ÈÄöÈÅéÈáùÂ∞çÂçäÂ∞éÈ´î‰æõÊáâÈèàÁöÑÊ°à‰æãÁ†îÁ©∂ÂæóÂà∞È©óË≠âÔºåÂçäÂ∞éÈ´î‰æõÊáâÈèàÊòØ‰∏ÄÂÄãÁî±Êñº‰æõÊáâÈèàÈ¢®Èö™ËÄåÊúÄËøëÂèóÂà∞Ê•µÂ§ßÈóúÊ≥®ÁöÑÈ†òÂüü„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁÇ∫ÈñãÁôº‰∏≠ÂúãÂÆ∂Ôºà‰æãÂ¶Ç‰∏≠ÂúãÂ§ßÈô∏ÔºâÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÈÅ©Áî®ÊÄßÔºåË£úÂÖÖ‰∫ÜÁèæÊúâÊï∏ÊìöÈõÜ‰∏≠ÁöÑÊï∏ÊìöÂ∑ÆË∑ù„ÄÇÁÑ∂ËÄåÔºåÂåÖÊã¨Ê∫ñÁ¢∫‰º∞Ë®àË≤®Âπ£ÂíåÁâ©ÊñôÊµÅ„ÄÅËôïÁêÜÊôÇÈñìÂ∫èÂàóÊï∏Êìö„ÄÅÊ∂àÈô§ÂêåÁæ©Ë©ûÊ≠ßÁæ©ÂíåÊ∏õËºïÁ∑ö‰∏äÂÖßÂÆπÂÅèË¶ãÂú®ÂÖßÁöÑÊåëÊà∞‰ªçÁÑ∂Â≠òÂú®„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÂ∞àÊ≥®ÊñºËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Á≥ªÁµ±ÁöÑËÉΩÂäõ‰∏¶Êì¥Â§ßÂÖ∂Âú®ÂÖ∂‰ªñÈñãÁôº‰∏≠ÂúãÂÆ∂ÂíåÁî¢Ê•≠ÁöÑÊáâÁî®„ÄÇ

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v2 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

ÊëòË¶ÅÔºöÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊñºÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÈúÄË¶ÅÁ≥ªÁµ±ÊÄßÊû∂ÊßãÔºåÊ≠§Êû∂ÊßãÂøÖÈ†àËÉΩËôïÁêÜË§áÈõúÁöÑÈÜ´ÁôÇÊÉÖÂ¢ÉÔºåÂêåÊôÇ‰øùÊúâÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÊàëÂÄëÊèêÂá∫ KG4DiagnosisÔºå‰∏ÄÂÄãÁµêÂêà LLM ËàáËá™ÂãïÂåñÁü•Ë≠òÂúñË°®Âª∫ÊßãÁöÑÊñ∞ÂûãÈöéÂ±§ÂºèÂ§öÈáç‰ª£ÁêÜÊû∂ÊßãÔºåÊ∂µËìã 362 Á®ÆÂ∏∏Ë¶ãÁñæÁóÖÔºåÊ©´Ë∑®ÂêÑÂÄãÈÜ´ÁôÇÂ∞àÁßë„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈÄèÈÅéÈõôÂ±§Êû∂ÊßãÂèçÊò†ÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇÁ≥ªÁµ±Ôºö‰∏Ä‰ΩçË≤†Ë≤¨ÂàùÊ≠•Ë©ï‰º∞ÂíåÂàÜÊµÅÁöÑÂÆ∂Â∫≠ÈÜ´Â∏´ (GP) ‰ª£ÁêÜÔºåÂçîË™øÂêÑÂÄãÂ∞àÁßë‰ª£ÁêÜÈÄ≤Ë°åÊ∑±ÂÖ•Ë®∫Êñ∑„ÄÇÊ†∏ÂøÉÂâµÊñ∞Âú®ÊñºÊàëÂÄëÁöÑÁ´ØÂ∞çÁ´ØÁü•Ë≠òÂúñË°®Áî¢ÁîüÊñπÊ≥ïÔºåÁµêÂêàÔºö(1) Ë™ûÊÑèÈ©ÖÂãïÁöÑÂØ¶È´îËàáÈóú‰øÇËêÉÂèñÔºåÈáùÂ∞çÈÜ´ÁôÇË°ìË™ûÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºõ(2) ÂæûÈùûÁµêÊßãÂåñÈÜ´ÁôÇÊñáÊú¨ÈáçÂª∫Â§öÁ∂≠Â∫¶Ê±∫Á≠ñÈóú‰øÇÔºõ‰ª•Âèä (3) ‰∫∫È°ûÂºïÂ∞éÁöÑÊé®ÁêÜÔºåÁî®ÊñºÁü•Ë≠òÊì¥ÂÖÖ„ÄÇKG4Diagnosis ÂèØ‰ΩúÁÇ∫Â∞àÈñÄÈÜ´ÁôÇË®∫Êñ∑Á≥ªÁµ±ÁöÑÂèØÂª∂‰º∏Âü∫Á§éÔºåÊúâËÉΩÂäõÊï¥ÂêàÊñ∞ÁöÑÁñæÁóÖÂíåÈÜ´ÁôÇÁü•Ë≠ò„ÄÇÊ≠§Êû∂ÊßãÁöÑÊ®°ÁµÑÂåñË®≠Ë®àËÉΩÁÑ°Á∏´Êï¥ÂêàÁâπÂÆöÈ†òÂüüÁöÑÂº∑ÂåñÂäüËÉΩÔºå‰ΩøÂÖ∂Â∞çÊñºÈñãÁôºÁõÆÊ®ôÂ∞éÂêëÁöÑÈÜ´ÁôÇË®∫Êñ∑Á≥ªÁµ±Ê•µÂÖ∑ÂÉπÂÄº„ÄÇÊàëÂÄëÊèê‰æõÊû∂ÊßãÊåáÂºïÂíåÂçîÂÆöÔºå‰ª•‰øÉÈÄ≤Âú®ÂêÑÁ®ÆÈÜ´ÁôÇÊÉÖÂ¢É‰∏≠ÁöÑÊé°Áî®„ÄÇ

##### **Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**
2412.16766v1 by Christophe Debruyne, Ademar Crotti Junior

Knowledge graph construction (KGC) from (semi-)structured data is
challenging, and facilitating user involvement is an issue frequently brought
up within this community. We cannot deny the progress we have made with respect
to (declarative) knowledge generation languages and tools to help build such
mappings. However, it is surprising that no two studies report on similar
protocols. This heterogeneity does not allow for a comparison of KGC languages,
techniques, and tools. This paper first analyses the various studies that
report on studies involving users to identify the points of comparison. These
gaps include a lack of systematic consistency in task design, participant
selection, and evaluation metrics. Moreover, there needs to be a systematic way
of analyzing the data and reporting the findings, which is also lacking. We
thus propose and introduce a user protocol for KGC designed to address this
challenge. Where possible, we draw and take elements from the literature we
deem fit for such a protocol. The protocol, as such, allows for the comparison
of languages and techniques for the RDF Mapping Languages core functionality,
which is covered by most of the other state-of-the-art techniques and tools. We
also propose how the protocol can be amended to compare extensions (of RML).
This protocol provides an important step towards a more comparable evaluation
of KGC user studies.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂª∫Êßã (KGC) Âæû (Âçä) ÁµêÊßãÂåñË≥áÊñô‰∏≠ÈÄ≤Ë°åÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåËÄå‰øÉÈÄ≤‰ΩøÁî®ËÄÖÂèÉËàáÊòØÈÄôÂÄãÁ§æÁæ§‰∏≠Á∂ìÂ∏∏ÊèêÂá∫ÁöÑË≠∞È°å„ÄÇÊàëÂÄëÁÑ°Ê≥ïÂê¶Ë™çÊàëÂÄëÂú®ÂçîÂä©Âª∫ÊßãÊ≠§È°ûÂ∞çÊáâÁöÑ (ÂÆ£ÂëäÂºè) Áü•Ë≠òÁî¢ÁîüË™ûË®ÄÂíåÂ∑•ÂÖ∑ÊñπÈù¢ÊâÄÂÅöÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºå‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊ≤íÊúâÂÖ©È†ÖÁ†îÁ©∂Â†±ÂëäÈ°û‰ººÁöÑÂçîÂÆö„ÄÇÈÄôÁ®ÆÁï∞Ë≥™ÊÄß‰∏çÂÖÅË®±ÊØîËºÉ KGC Ë™ûË®Ä„ÄÅÊäÄË°ìÂíåÂ∑•ÂÖ∑„ÄÇÊú¨ÊñáÈ¶ñÂÖàÂàÜÊûêÂêÑÁ®ÆÁ†îÁ©∂ÔºåÈÄô‰∫õÁ†îÁ©∂Â†±ÂëäÊ∂âÂèä‰ΩøÁî®ËÄÖÁöÑÁ†îÁ©∂Ôºå‰ª•ÊâæÂá∫ÊØîËºÉÈªû„ÄÇÈÄô‰∫õÂ∑ÆË∑ùÂåÖÊã¨‰ªªÂãôË®≠Ë®à„ÄÅÂèÉËàáËÄÖÈÅ∏ÊìáÂíåË©ïÈáèÊåáÊ®ôÁº∫‰πèÁ≥ªÁµ±ÊÄßÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÈúÄË¶ÅÊúâÁ≥ªÁµ±ÁöÑÊñπÊ≥ï‰æÜÂàÜÊûêË≥áÊñôÂíåÂ†±ÂëäÁµêÊûúÔºåÈÄô‰πüÊòØÊâÄÁº∫‰πèÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏¶‰ªãÁ¥π‰∏ÄÂÄã‰ΩøÁî®ËÄÖÂçîÂÆöÔºåÁî®Êñº KGCÔºåÊó®Âú®Ëß£Ê±∫ÈÄôÂÄãÊåëÊà∞„ÄÇÂú®ÂèØËÉΩÁöÑÁØÑÂúçÂÖßÔºåÊàëÂÄëÂæûÊàëÂÄëË™çÁÇ∫ÈÅ©ÂêàÊ≠§È°ûÂçîÂÆöÁöÑÊñáÁçª‰∏≠Ê±≤Âèñ‰∏¶Êé°Áî®ÂÖÉÁ¥†„ÄÇÂõ†Ê≠§ÔºåË©≤ÂçîÂÆöÂÖÅË®±ÊØîËºÉ RDF Â∞çÊáâË™ûË®ÄÊ†∏ÂøÉÂäüËÉΩÁöÑË™ûË®ÄÂíåÊäÄË°ìÔºåËÄåÂ§ßÂ§öÊï∏ÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊäÄË°ìÂíåÂ∑•ÂÖ∑ÈÉΩÊ∂µËìã‰∫ÜÈÄô‰∏ÄÈªû„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫Â¶Ç‰Ωï‰øÆÊîπÂçîÂÆö‰ª•ÊØîËºÉÂª∂‰º∏ (RML)„ÄÇÊ≠§ÂçîÂÆöÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈáçË¶ÅÁöÑÊ≠•È©üÔºåÊúùÂêëÊõ¥ÂÖ∑ÂèØÊØîËºÉÊÄßÁöÑ KGC ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ë©ïÈáèÈÇÅÈÄ≤„ÄÇ

##### **Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**
2412.16533v1 by Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen

We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫ÜÊÄùÊÉ≥Áü•Ë≠òÁ∂≤Ë∑Ø (kNoT)Ôºö‰∏ÄÁ®ÆÊèêÁ§∫Êû∂ÊßãÔºåÂÆÉÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõÊèêÂçáÂà∞‰∫ÜË∂ÖË∂äÁèæÊúâÁØÑ‰æãÁöÑÂ¢ÉÁïåÔºå‰æãÂ¶ÇÊÄùÊÉ≥Èèà (CoT)„ÄÅÊÄùÊÉ≥Ê®π (ToT) ÂíåÊÄùÊÉ≥Âúñ (GoT)„ÄÇkNoT ÁöÑÈóúÈçµÂâµÊñ∞ÊòØ LLM Â∑•‰ΩúÊµÅÁ®ãÁØÑÊú¨ (LWT)ÔºåÂÆÉÂÖÅË®± LLM ÁÇ∫ LLM ÊåáÂÆö‰∏ÄÂÄãÂèØÂü∑Ë°åÁöÑË®àÁï´„ÄÇLWT ÂÖÅË®±ÈÄô‰∫õË®àÁï´ÊàêÁÇ∫‰ªªÊÑèÁ∂≤Ë∑ØÔºåÂÖ∂‰∏≠ÂñÆÊ≠• LLM Êìç‰ΩúÁÇ∫ÁØÄÈªûÔºåËÄåÈÇäÁ∑£Â∞çÊáâÊñºÈÄô‰∫õÊ≠•È©ü‰πãÈñìÁöÑË®äÊÅØÂÇ≥ÈÅû„ÄÇÊ≠§Â§ñÔºåLWT ÊîØÊè¥ÈÄèÈÅéÁ¥¢ÂºïÈÅ∏ÂèñÂÄãÂà•ÂÖÉÁ¥†ÔºåÈÄ≤ËÄåËÆì kNoT ËÉΩÂ§†Âà∂ÂÆöË§áÈõúÁöÑË®àÁï´ÔºåÂÖ∂‰∏≠ÊØèÂÄã LLM Êìç‰ΩúÈÉΩÂèØ‰ª•ÈôêÂà∂ÁÇ∫Âü∫Êú¨Êìç‰ΩúÔºåÂ§ßÂπÖÊèêÂçáÂª∂‰º∏‰ªªÂãôÂ∫èÂàóÁöÑÂèØÈù†ÊÄß„ÄÇÊàëÂÄëË≠âÊòé kNoT Âú®ÂÖ≠ÂÄãÁî®‰æã‰∏äÈ°ØËëóÂÑ™ÊñºÁèæÊúâÊäÄË°ìÔºåÂêåÊôÇÊ∏õÂ∞ë‰∫ÜÂ∞çÂª£Ê≥õÊèêÁ§∫Â∑•Á®ãÁöÑÈúÄÊ±Ç„ÄÇ‰æãÂ¶ÇÔºåkNoT Âú®Â∞ç 32 ÂÄãÊï∏Â≠óÈÄ≤Ë°åÊéíÂ∫èÊôÇÁôºÁèæ 92% ÁöÑÊ∫ñÁ¢∫ÁéáÔºåËÄå ToT Âíå GoT ÁÇ∫ 12% Âíå 31%ÔºåÂêåÊôÇÂàÜÂà•Âà©Áî®‰∫ÜÂ∞ëÈÅî 84.4% Âíå 87.3% ÁöÑÁâπÂÆö‰ªªÂãôÊèêÁ§∫„ÄÇ

##### **Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**
2412.16420v1 by Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang

Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.

ÊëòË¶ÅÔºöÊµÅÁ®ãÂúñÈÄöÂ∏∏‰ª•ÂΩ±ÂÉèÂëàÁèæÔºåÊé®Âãï‰∫Ü‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÈÄ≤Ë°åÁ´ØÂ∞çÁ´ØÊµÅÁ®ãÂúñÁêÜËß£ÁöÑË∂®Âã¢„ÄÇÁÑ∂ËÄåÔºåÂá∫Áèæ‰∫ÜÂÖ©ÂÄãÈóúÈçµÊåëÊà∞Ôºö(i) ÂèØÊéßÊÄßÊúâÈôê‚Äî‚Äî‰ΩøÁî®ËÄÖÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÁöÑÂΩ±ÈüøÂæàÂ∞èÔºåÂõ†ÁÇ∫‰ªñÂÄëÂè™ËÉΩ‰øÆÊîπËº∏ÂÖ•ÂΩ±ÂÉèÔºåËÄåÂ§ßÂ§öÊï∏Á†îÁ©∂‰∫∫Âì°ÂæÄÂæÄÁÑ°Ê≥ïË®ìÁ∑¥ VLM„ÄÇ(ii) Áº∫‰πèÂèØËß£ÈáãÊÄß‚Äî‚ÄîÈõ£‰ª•ËøΩÊ∫Ø VLM ÈåØË™§Âà∞ÂÖ∑È´îÂéüÂõ†Ôºå‰æãÂ¶ÇË¶ñË¶∫Á∑®Á¢ºÊàñÊé®ÁêÜÂ§±Êïó„ÄÇÊàëÂÄëÊèêÂá∫ TextFlowÔºåÈÄèÈÅéÂÖ©ÂÄãÈöéÊÆµ‰æÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºö(i) Ë¶ñË¶∫ÊñáÂ≠óÂåñÂô®‚Äî‚ÄîÂæûÊµÅÁ®ãÂúñÂΩ±ÂÉèÁî¢ÁîüÊñáÂ≠óË°®Á§∫Ôºõ(ii) ÊñáÂ≠óÊé®ÁêÜÂô®‚Äî‚ÄîÊ†πÊìöÊñáÂ≠óË°®Á§∫Âü∑Ë°åÂïèÁ≠î„ÄÇTextFlow Êèê‰æõ‰∫Ü‰∏âÂÄã‰∏ªË¶ÅÂÑ™ÈªûÔºö(i) ‰ΩøÁî®ËÄÖÂèØ‰ª•ÈÅ∏ÊìáÊñáÂ≠óË°®Á§∫ÁöÑÈ°ûÂûãÔºà‰æãÂ¶Ç Graphviz„ÄÅMermaid„ÄÅPlantUMLÔºâÔºåÊàñÈÄ≤‰∏ÄÊ≠•Â∞áÂÆÉÂÄëËΩâÊèõÁÇ∫ÂèØÂü∑Ë°åÁöÑÂúñÂΩ¢Áâ©‰ª∂‰æÜÂëºÂè´Â∑•ÂÖ∑ÔºåÂ¢ûÂº∑ÊïàËÉΩÂíåÂèØÊéßÊÄßÔºõ(ii) ÂÆÉÈÄèÈÅéÂπ´Âä©Êõ¥Ê∏ÖÊ•öÂú∞Â∞áÈåØË™§Ê≠∏Âõ†ÊñºË¶ñË¶∫ÊàñÊñáÂ≠óËôïÁêÜÂÖÉ‰ª∂‰æÜÊîπÂñÑÂèØËß£ÈáãÊÄßÔºõ(iii) ÂÆÉ‰øÉÈÄ≤‰∫ÜËß£Ê±∫ÊñπÊ°àÁöÑÊ®°ÁµÑÂåñÔºå‰æãÂ¶ÇÂÖÅË®±Âú® VLM Âú®Á´ØÂ∞çÁ´ØÊ®°Âºè‰∏ãË°®Áèæ‰∏ç‰Ω≥ÊôÇÔºåÂú®Êé®ÁêÜÂô®ÈöéÊÆµ‰ΩøÁî®ÈÄ≤Èöé LLM„ÄÇÂú® FlowVQA Âíå FlowLearn Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫Ü TextFlow ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ‰ª•ÂèäÂÖ∂Á©©ÂÅ•ÊÄß„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢ºÈÉΩÂÖ¨ÈñãÂèØÁî®„ÄÇ

##### **HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**
2412.16311v1 by Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

Given a semi-structured knowledge base (SKB), where text documents are
interconnected by relations, how can we effectively retrieve relevant
information to answer user questions? Retrieval-Augmented Generation (RAG)
retrieves documents to assist large language models (LLMs) in question
answering; while Graph RAG (GRAG) uses structured knowledge bases as its
knowledge source. However, many questions require both textual and relational
information from SKB - referred to as "hybrid" questions - which complicates
the retrieval process and underscores the need for a hybrid retrieval method
that leverages both information. In this paper, through our empirical analysis,
we identify key insights that show why existing methods may struggle with
hybrid question answering (HQA) over SKB. Based on these insights, we propose
HybGRAG for HQA consisting of a retriever bank and a critic module, with the
following advantages: (1) Agentic, it automatically refines the output by
incorporating feedback from the critic module, (2) Adaptive, it solves hybrid
questions requiring both textual and relational information with the retriever
bank, (3) Interpretable, it justifies decision making with intuitive refinement
path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In
experiments on the STaRK benchmark, HybGRAG achieves significant performance
gains, with an average relative improvement in Hit@1 of 51%.

ÊëòË¶ÅÔºö<paragraph>Áµ¶ÂÆö‰∏ÄÂÄãÂçäÁµêÊßãÂåñÁü•Ë≠òÂ∫´ (SKB)ÔºåÂÖ∂‰∏≠ÊñáÊú¨Êñá‰ª∂Áî±Èóú‰øÇÁõ∏‰∫íÈÄ£Êé•ÔºåÊàëÂÄëÂ¶Ç‰ΩïÊúâÊïàÂú∞Êì∑ÂèñÁõ∏ÈóúË≥áË®ä‰æÜÂõûÁ≠î‰ΩøÁî®ËÄÖÁöÑÂïèÈ°åÔºüÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàê (RAG) Êì∑ÂèñÊñá‰ª∂‰ª•ÂçîÂä©Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂõûÁ≠îÂïèÈ°åÔºõËÄåÂúñÂΩ¢ RAG (GRAG) ‰ΩøÁî®ÁµêÊßãÂåñÁü•Ë≠òÂ∫´‰ΩúÁÇ∫ÂÖ∂Áü•Ë≠ò‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÂïèÈ°åÈúÄË¶Å‰æÜËá™ SKB ÁöÑÊñáÂ≠óÂíåÈóú‰øÇË≥áË®äÔºåÁ®±ÁÇ∫„ÄåÊ∑∑Âêà„ÄçÂïèÈ°åÔºåÈÄô‰ΩøÂæóÊì∑ÂèñÈÅéÁ®ãË§áÈõúÂåñÔºå‰∏¶Âº∑Ë™øÈúÄË¶Å‰∏ÄÁ®ÆÂà©Áî®ÈÄôÂÖ©Á®ÆË≥áË®äÁöÑÊ∑∑ÂêàÊì∑ÂèñÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÈÄèÈÅéÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÔºåÊàëÂÄëÊâæÂá∫È°ØÁ§∫ÁèæÊúâÊñπÊ≥ïÂèØËÉΩÈõ£‰ª•Âú® SKB ‰∏äÈÄ≤Ë°åÊ∑∑ÂêàÂïèÈ°åËß£Á≠î (HQA) ÁöÑÈóúÈçµË¶ãËß£„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫Áî±Êì∑ÂèñÂô®Â∫´ÂíåÊâπË©ïÊ®°ÁµÑÁµÑÊàê„ÄÅÂÖ∑Êúâ‰ª•‰∏ãÂÑ™ÈªûÁöÑ HQA HybGRAGÔºö(1) ‰ª£ÁêÜÔºåÂÆÉÈÄèÈÅéÁ¥çÂÖ•ÊâπË©ïÊ®°ÁµÑÁöÑÂõûÈ•ãËá™ÂãïÁ≤æÁÖâËº∏Âá∫Ôºå(2) ÈÅ©ÊáâÔºåÂÆÉ‰ΩøÁî®Êì∑ÂèñÂô®Â∫´Ëß£Ê±∫ÈúÄË¶ÅÊñáÂ≠óÂíåÈóú‰øÇË≥áË®äÁöÑÊ∑∑ÂêàÂïèÈ°åÔºå(3) ÂèØËß£ÈáãÔºåÂÆÉ‰ª•Áõ¥Ë¶∫ÁöÑÁ≤æÁÖâË∑ØÂæëË≠âÊòéÊ±∫Á≠ñÔºå‰ª•Âèä (4) ÊúâÊïàÔºåÂÆÉË∂ÖË∂ä‰∫Ü HQA Âü∫Ê∫ñÁöÑÊâÄÊúâÂü∫Ê∫ñ„ÄÇÂú® STaRK Âü∫Ê∫ñÁöÑÂØ¶È©ó‰∏≠ÔºåHybGRAG ÈÅîÂà∞‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåHit@1 ÁöÑÂπ≥ÂùáÁõ∏Â∞çÊîπÂñÑÁÇ∫ 51%„ÄÇ</paragraph>

##### **Logical Consistency of Large Language Models in Fact-checking**
2412.16100v1 by Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan

In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses -- a meaning-preserving change in the input query
results in an inconsistent response and attributes to vulnerabilities of LLMs
such as hallucination, jailbreaking, etc. Consequently, existing research
focuses on simple paraphrasing-based consistency assessment of LLMs, and
ignores complex queries that necessitates an even better understanding of
logical reasoning by an LLM. Our work therefore addresses the logical
inconsistency of LLMs under complex logical queries with primitive logical
operators, e.g., negation, conjunction, and disjunction. As a test bed, we
consider retrieval-augmented LLMs on a fact-checking task involving
propositional logic queries from real-world knowledge graphs (KGs). Our
contributions are three-fold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries as input and demonstrate that existing LLMs lack
logical consistency, specially on complex queries. Improvement: We employ
supervised fine-tuning to improve the logical consistency of LLMs on the
complex fact-checking task with KG contexts.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âü∑Ë°åÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãôÔºà‰æãÂ¶ÇË™ûË®ÄÁøªË≠Ø„ÄÅÂïèÁ≠î„ÄÅÊëòË¶Å„ÄÅ‰∫ãÂØ¶Êü•Ê†∏Á≠âÔºâÊñπÈù¢Â±ïÁèæÂá∫È°ØËëóÁöÑÊàêÂäü„ÄÇÂÑòÁÆ° LLM ËÉΩÁî¢ÁîüÈ°û‰ºº‰∫∫È°ûÁöÑÊñáÂ≠óÔºå‰ΩÜ LLM ‰ª•ÂÖ∂‰∏ç‰∏ÄËá¥ÁöÑÂõûÊáâËÄåËá≠ÂêçÊò≠Ëëó‚Äî‚ÄîËº∏ÂÖ•Êü•Ë©¢‰∏≠‰∏ÄÂÄã‰øùÊÑèÊîπËÆäÊúÉÂ∞éËá¥‰∏ç‰∏ÄËá¥ÁöÑÂõûÊáâÔºå‰∏¶Ê≠∏Âõ†Êñº LLM ÁöÑÊºèÊ¥ûÔºå‰æãÂ¶ÇÂπªË¶∫„ÄÅË∂äÁçÑÁ≠â„ÄÇÂõ†Ê≠§ÔºåÁèæÊúâÁöÑÁ†îÁ©∂Â∞àÊ≥®Êñº LLM ÁöÑÂü∫ÊñºÁ∞°ÂñÆÊîπÂØ´ÁöÑ‰∏ÄËá¥ÊÄßË©ï‰º∞ÔºåËÄåÂøΩÁï•‰∫ÜÈúÄË¶Å LLM Êõ¥Ê∑±ÂÖ•ÁêÜËß£ÈÇèËºØÊé®ÁêÜÁöÑË§áÈõúÊü•Ë©¢„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ëß£Ê±∫‰∫Ü LLM Âú®ÂÖ∑ÊúâÂü∫Êú¨ÈÇèËºØÈÅãÁÆóÂÖÉÔºà‰æãÂ¶ÇÂê¶ÂÆö„ÄÅÂêàÂèñÂíåÊûêÂèñÔºâÁöÑË§áÈõúÈÇèËºØÊü•Ë©¢‰∏ãÁöÑÈÇèËºØ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÊàëÂÄëËÄÉÊÖÆÂú®‰∏ÄÂÄãÊ∂âÂèä‰æÜËá™ÁúüÂØ¶‰∏ñÁïåÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÂëΩÈ°åÈÇèËºØÊü•Ë©¢ÁöÑ‰∫ãÂØ¶Êü•Ê†∏‰ªªÂãô‰∏≠ÔºåÊ™¢Á¥¢Â¢ûÂº∑ÁöÑ LLM„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊúâ‰∏âÊñπÈù¢„ÄÇÂü∫Ê∫ñÔºöÊàëÂÄëÂú® KG ‰∏äÂºïÂÖ•‰∫Ü‰∏âÂÄãÈÇèËºØ‰∫ãÂØ¶Êü•Ê†∏Êï∏ÊìöÈõÜÔºå‰ª•‰øÉÈÄ≤Á§æÂçÄÈñãÁôºÈÇèËºØ‰∏ÄËá¥ÁöÑ LLM„ÄÇË©ï‰º∞ÔºöÊàëÂÄëÊèêÂá∫‰∫Ü LLM Âú®ÂëΩÈ°åÈÇèËºØÊü•Ë©¢‰ΩúÁÇ∫Ëº∏ÂÖ•‰∏äÁöÑ‰∏ÄËá¥ÊÄßÊ∏¨ÈáèÔºå‰∏¶Ë≠âÊòéÁèæÊúâÁöÑ LLM Áº∫‰πèÈÇèËºØ‰∏ÄËá¥ÊÄßÔºåÁâπÂà•ÊòØÂú®Ë§áÈõúÊü•Ë©¢‰∏ä„ÄÇÊîπÈÄ≤ÔºöÊàëÂÄëÊé°Áî®Áõ£Áù£ÂæÆË™ø‰æÜÊèêÈ´ò LLM Âú®ÂÖ∑Êúâ KG ËÉåÊôØÁöÑË§áÈõú‰∫ãÂØ¶Êü•Ê†∏‰ªªÂãô‰∏äÁöÑÈÇèËºØ‰∏ÄËá¥ÊÄß„ÄÇ

##### **GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**
2412.15790v1 by Heming Zhang, Di Huang, Yixin Chen, Fuhai Li

The integration of multi-omic data is pivotal for understanding complex
diseases, but its high dimensionality and noise present significant challenges.
Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale
signaling pathways and protein-protein interaction networks, yet they face
limitations in expressivity when capturing intricate biological relationships.
To address this, we propose Graph Sequence Language Model (GraphSeqLM), a
framework that enhances GNNs with biological sequence embeddings generated by
Large Language Models (LLMs). These embeddings encode structural and biological
properties of DNA, RNA, and proteins, augmenting GNNs with enriched features
for analyzing sample-specific multi-omic data. By integrating topological,
sequence-derived, and biological information, GraphSeqLM demonstrates superior
predictive accuracy and outperforms existing methods, paving the way for more
effective multi-omic data integration in precision medicine.

ÊëòË¶ÅÔºöÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñôÂ∞çÊñºÁêÜËß£Ë§áÈõúÁñæÁóÖËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÖ∂È´òÁ∂≠Â∫¶ÂíåÈõúË®äÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑÊåëÊà∞„ÄÇÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•ÁöÑÊû∂ÊßãÔºåÁî®ÊñºÂàÜÊûêÂ§ßË¶èÊ®°‰ø°ËôüË∑ØÂæëÂíåËõãÁôΩË≥™-ËõãÁôΩË≥™‰∫§‰∫íÁ∂≤Ë∑ØÔºåÁÑ∂ËÄåÂÆÉÂÄëÂú®ÊçïÊçâË§áÈõúÁöÑÁîüÁâ©Èóú‰øÇÊôÇÔºåÂú®Ë°®ÁèæÂäõÊñπÈù¢Èù¢Ëá®ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂúñÂ∫èÂàóË™ûË®ÄÊ®°Âûã (GraphSeqLM)Ôºå‰∏ÄÂÄãÂ¢ûÂº∑ GNN ÁöÑÊû∂ÊßãÔºåÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁîüÊàêÁöÑÁîüÁâ©Â∫èÂàóÂµåÂÖ•„ÄÇÈÄô‰∫õÂµåÂÖ•Á∑®Á¢º‰∫Ü DNA„ÄÅRNA ÂíåËõãÁôΩË≥™ÁöÑÁµêÊßãÂíåÁîüÁâ©ÁâπÊÄßÔºåÈÄèÈÅéË±êÂØåÁöÑÁâπÊÄßÊì¥ÂÖÖ GNNÔºåÁî®ÊñºÂàÜÊûêÁâπÂÆöÊ®£Êú¨ÁöÑÂ§öÁµÑÂ≠∏Ë≥áÊñô„ÄÇÈÄèÈÅéÊï¥ÂêàÊãìÊí≤„ÄÅÂ∫èÂàóË°çÁîüÂíåÁîüÁâ©Ë≥áË®äÔºåGraphSeqLM Â±ïÁèæ‰∫ÜÂÑ™Ë∂äÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÁÇ∫Á≤æÊ∫ñÈÜ´ÁôÇ‰∏≠Êõ¥ÊúâÊïàÁöÑÂ§öÁµÑÂ≠∏Ë≥áÊñôÊï¥ÂêàÈã™Ë∑Ø„ÄÇ

##### **KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models**
2412.18627v1 by Xingyu Xiao, Peng Chen, Ben Qi, Hongru Zhao, Jingang Liang, Jiejuan Tong, Haitao Wang

Human reliability analysis (HRA) is crucial for evaluating and improving the
safety of complex systems. Recent efforts have focused on estimating human
error probability (HEP), but existing methods often rely heavily on expert
knowledge,which can be subjective and time-consuming. Inspired by the success
of large language models (LLMs) in natural language processing, this paper
introduces a novel two-stage framework for knowledge-driven reliability
analysis, integrating IDHEAS and LLMs (KRAIL). This innovative framework
enables the semi-automated computation of base HEP values. Additionally,
knowledge graphs are utilized as a form of retrieval-augmented generation (RAG)
for enhancing the framework' s capability to retrieve and process relevant data
efficiently. Experiments are systematically conducted and evaluated on
authoritative datasets of human reliability. The experimental results of the
proposed methodology demonstrate its superior performance on base HEP
estimation under partial information for reliability assessment.

ÊëòË¶ÅÔºö‰∫∫È°ûÂèØÈù†Â∫¶ÂàÜÊûê (HRA) Â∞çÊñºË©ï‰º∞ÂíåÊèêÂçáË§áÈõúÁ≥ªÁµ±ÁöÑÂÆâÂÖ®ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÁöÑÂä™ÂäõÂ∞àÊ≥®Êñº‰º∞Ë®à‰∫∫ÁÇ∫ÈåØË™§Ê©üÁéá (HEP)Ôºå‰ΩÜÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏È´òÂ∫¶‰æùË≥¥Â∞àÂÆ∂Áü•Ë≠òÔºåËÄåÈÄôÂèØËÉΩÊúÉÂ∏∂Êúâ‰∏ªËßÄÊÄß‰∏îËÄóÊôÇ„ÄÇÂèóÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÊàêÂäüÁöÑÂïüÁôºÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÖ©ÈöéÊÆµÊû∂ÊßãÔºåÁî®ÊñºÁü•Ë≠òÈ©ÖÂãïÁöÑÂèØÈù†Â∫¶ÂàÜÊûêÔºåÊï¥Âêà IDHEAS Âíå LLM (KRAIL)„ÄÇÈÄôÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãËÉΩÂçäËá™ÂãïÂåñË®àÁÆóÂü∫Êú¨ HEP ÂÄº„ÄÇÊ≠§Â§ñÔºåÁü•Ë≠òÂúñË≠úË¢´Áî®‰ΩúÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁöÑ‰∏ÄÁ®ÆÂΩ¢ÂºèÔºåÁî®ÊñºÂ¢ûÂº∑Êû∂ÊßãÊúâÊïàÁéáÂú∞Ê™¢Á¥¢ÂíåËôïÁêÜÁõ∏ÈóúË≥áÊñôÁöÑËÉΩÂäõ„ÄÇÁ≥ªÁµ±ÊÄßÂú∞ÈáùÂ∞ç‰∫∫È°ûÂèØÈù†Â∫¶ÁöÑÊ¨äÂ®ÅË≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶È©ó‰∏¶Ë©ï‰º∞„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÂÖ∂Âú®ÈÉ®ÂàÜË≥áË®ä‰∏ãÈÄ≤Ë°åÂèØÈù†Â∫¶Ë©ï‰º∞ÊôÇÔºåÂú®Âü∫Êú¨ HEP ‰º∞Ë®à‰∏äÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇ

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

ÊëòË¶ÅÔºöÈ£≤È£üÂú®‰∫∫È°ûÂÅ•Â∫∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁÑ∂ËÄåÊ†πÊìöÂÄã‰∫∫ÂÅ•Â∫∑ÁãÄÊ≥ÅË™øÊï¥È£≤È£üÊé®ÁêÜ‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁáüÈ§äÂïèÈ°åÂïèÁ≠î (QA) Â∑≤ÊàêÁÇ∫Ëß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊµÅË°åÊñπÊ≥ï„ÄÇ‰∏çÈÅéÔºåÁõÆÂâçÁöÑÁ†îÁ©∂Èù¢Ëá®ÂÖ©È†ÖÈáçÂ§ßÁöÑÈôêÂà∂„ÄÇ‰∏ÄÊñπÈù¢ÔºåÁº∫‰πèÂåÖÂê´‰ΩøÁî®ËÄÖÁâπÂÆöÈÜ´ÁôÇË≥áË®äÁöÑË≥áÊñôÈõÜÂö¥ÈáçÈôêÂà∂‰∫Ü„ÄåÂÄã‰∫∫Âåñ„Äç„ÄÇÈÄôÂÄãÊåëÊà∞ÈÄ≤‰∏ÄÊ≠•ÂèóÂà∞ÂÄã‰∫∫ÂÅ•Â∫∑ÈúÄÊ±ÇÂª£Ê≥õËÆäÁï∞ÁöÑÂΩ±Èüø„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÈõñÁÑ∂Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÊ≠§‰ªªÂãôÁöÑÁÜ±ÈñÄËß£Ê±∫ÊñπÊ°àÔºåÂ±ïÁ§∫Âá∫Âº∑Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄëÂú®ÂÄã‰∫∫ÂåñÂÅ•Â∫∑È£≤È£üÊé®ÁêÜÁöÑÁâπÂÆöÈ†òÂüüË§áÈõúÊÄß‰∏ä‰ªçÊúâÂõ∞Èõ£ÔºåËÄåÁèæÊúâÁöÑÂü∫Ê∫ñ‰πüÁÑ°Ê≥ïÊçïÊçâÈÄô‰∫õÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁáüÈ§äÂúñË°®ÂïèÁ≠î (NGQA) Âü∫Ê∫ñÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÁÇ∫ÂÄã‰∫∫ÂåñÁáüÈ§äÂÅ•Â∫∑Êé®ÁêÜË®≠Ë®àÁöÑÂúñË°®ÂïèÁ≠îË≥áÊñôÈõÜ„ÄÇNGQA Âà©Áî®ÂúãÂÆ∂ÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES) ÂíåÈ£≤È£üÁ†îÁ©∂È£üÁâ©ËàáÁáüÈ§äË≥áÊñôÂ∫´ (FNDDS) ÁöÑË≥áÊñôÔºåË©ï‰º∞È£üÁâ©ÊòØÂê¶Â∞çÁâπÂÆö‰ΩøÁî®ËÄÖÂÅ•Â∫∑Ôºå‰∏¶Ë™™Êòé‰∏ªË¶ÅË≤¢ÁçªÁáüÈ§äÁ¥†„ÄÇÊ≠§Âü∫Ê∫ñÁ¥çÂÖ•‰∫Ü‰∏âÂÄãÂïèÈ°åË§áÈõúÂ∫¶Ë®≠ÂÆöÔºå‰∏¶Ë©ï‰º∞‰∏âÂÄã‰∏ãÊ∏∏‰ªªÂãôÁöÑÊé®ÁêÜ„ÄÇ‰ΩøÁî® LLM ‰∏ªÂππÂíåÂü∫Á∑öÊ®°ÂûãÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåNGQA Âü∫Ê∫ñÊúâÊïàÊåëÊà∞‰∫ÜÁèæÊúâÊ®°Âûã„ÄÇÁ∏Ω‰πãÔºåNGQA Ëß£Ê±∫‰∫Ü‰∏ÄÂÄãÈáçÂ§ßÁöÑÁèæÂØ¶‰∏ñÁïåÂïèÈ°åÔºåÂêåÊôÇÈÄèÈÅéÊñ∞Á©éÁöÑÁâπÂÆöÈ†òÂüüÂü∫Ê∫ñÊé®Âãï‰∫Ü GraphQA Á†îÁ©∂„ÄÇ

##### **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**
2412.15443v1 by Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary

Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.

ÊëòË¶ÅÔºöÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±Â∑≤ÊàêÁÇ∫Âà©Áî®ÈæêÂ§ßË™ûÊñôÂ∫´‰æÜÁî¢ÁîüÊòéÊô∫‰∏îËàáÊÉÖÂ¢ÉÁõ∏ÈóúÂõûÊáâÁöÑÈóúÈçµÔºåÁâπÂà•ÊòØÊ∏õÂ∞ëÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÂπªË¶∫„ÄÇÂÑòÁÆ°ÊúâÈ°ØËëóÁöÑÈÄ≤Â±ïÔºå‰ΩÜÈÄô‰∫õÁ≥ªÁµ±Âú®ËôïÁêÜÂíåÊì∑Âèñ‰æÜËá™Â§ßÂûãË≥áÊñôÈõÜÁöÑË≥áË®äÊôÇ‰ªçÊúâÂõ∞Èõ£ÔºåÂêåÊôÇÈÇÑË¶ÅÁ∂≠ÊåÅÂ∞çÊÉÖÂ¢ÉÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÊú¨Êñá‰ªãÁ¥π SKETCHÔºå‰∏ÄÁ®ÆÈÄèÈÅéÂ∞áË™ûÊÑèÊñáÂ≠óÊì∑ÂèñËàáÁü•Ë≠òÂúñË°®Êï¥ÂêàÔºåËóâÊ≠§Âêà‰ΩµÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñË≥áÊñô‰ª•Áç≤ÂæóÊõ¥ÂÖ®Èù¢ÁöÑÁêÜËß£Ôºå‰æÜÂ¢ûÂº∑ RAG Êì∑ÂèñÁ®ãÂ∫èÁöÑÂâµÊñ∞ÊñπÊ≥ï„ÄÇSKETCH Âú®Êì∑ÂèñÊïàËÉΩÊñπÈù¢Â±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•Ôºå‰∏¶ËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÁ∂≠ÊåÅËºÉ‰Ω≥ÁöÑÊÉÖÂ¢ÉÂÆåÊï¥ÊÄß„ÄÇÂú®ÂõõÂÄã‰∏çÂêåÁöÑË≥áÊñôÈõÜÔºöQuALITY„ÄÅQASPER„ÄÅNarrativeQA Âíå Italian Cuisine ‰∏≠ÈÄ≤Ë°åË©ï‰º∞ÔºåSKETCH Âú®ÈóúÈçµÁöÑ RAGAS ÊåáÊ®ôÔºà‰æãÂ¶Ç answer_relevancy„ÄÅfaithfulness„ÄÅcontext_precision Âíå context_recallÔºâ‰∏äÂßãÁµÇÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® Italian Cuisine Ë≥áÊñôÈõÜ‰∏äÔºåSKETCH ÁöÑ answer relevancy ÈÅîÂà∞ 0.94Ôºåcontext precision ÈÅîÂà∞ 0.99Ôºå‰ª£Ë°®Âú®ÊâÄÊúâË©ï‰º∞ÊåáÊ®ô‰∏≠Ë°®ÁèæÊúÄ‰Ω≥„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü SKETCH Âú®Êèê‰æõÊõ¥Ê∫ñÁ¢∫‰∏îËàáÊÉÖÂ¢ÉÁõ∏ÈóúÂõûÊáâÁöÑËÉΩÂäõÔºåÁÇ∫Êú™‰æÜÁöÑÊì∑ÂèñÁ≥ªÁµ±Ê®πÁ´ã‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

ÊëòË¶ÅÔºöËøëÊúüÊ©üÂô®Â≠∏ÁøíÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰æãÂ¶Ç BERT Âíå GPTÔºåÊèê‰æõ‰∫ÜË±êÂØåÁöÑ‰∏ä‰∏ãÊñáÂµåÂÖ•ÔºåÊîπÈÄ≤‰∫ÜÊñáÊú¨Ë°®Âæµ„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑÊñá‰ª∂ÂàÜÁæ§ÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•ÂëΩÂêçÂØ¶È´î (NE) ‰πãÈñìÊõ¥Ê∑±Â±§ÁöÑÈóú‰øÇÂíå LLM ÂµåÂÖ•ÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂ∞áÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) Âíå LLM ÂµåÂÖ•Êï¥ÂêàÂà∞Âü∫ÊñºÂúñÂΩ¢ÁöÑÊû∂Êßã‰∏≠Ôºå‰ª•ÈÄ≤Ë°åÊñá‰ª∂ÂàÜÁæ§„ÄÇË©≤ÊñπÊ≥ïÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂúñÂΩ¢ÔºåÂÖ∂‰∏≠ÁØÄÈªû‰ª£Ë°®Êñá‰ª∂ÔºåÈÇäÁ∑£ÂâáÁî±ÂëΩÂêçÂØ¶È´îÁõ∏‰ººÊÄßÂä†Ê¨äÔºå‰∏¶‰ΩøÁî®ÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) ÈÄ≤Ë°åÊúÄ‰Ω≥Âåñ„ÄÇÈÄôÁ¢∫‰øù‰∫ÜË™ûÁæ©Áõ∏ÈóúÊñá‰ª∂Êõ¥ÊúâÊïàÁöÑÂàÜÁµÑ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÂÖ±ÁèæÊñπÊ≥ïÂú®ÂàÜÁæ§‰∏≠ÁöÑË°®ÁèæÔºåÁâπÂà•ÊòØÂ∞çÊñºÂØåÂê´ÂëΩÂêçÂØ¶È´îÁöÑÊñá‰ª∂„ÄÇ

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

ÊëòË¶ÅÔºöÂÑòÁÆ°Á≠îÊ°àÈõÜÁ®ãÂºèË®≠Ë®àÔºàASPÔºâÂÖÅË®±Á¥ÑÊùüÁ•ûÁ∂ìÁ¨¶ËôüÔºàNeSyÔºâÁ≥ªÁµ±Ôºå‰ΩÜÂÖ∂ÊáâÁî®ÂèóÂà∞Ë®àÁÆóÁ©©ÂÆöÊ®°ÂûãÁöÑÈÅéÈ´òÊàêÊú¨ÂíåÁèæÊúâÊ±ÇËß£Âô®Âèó CPU ÈôêÂà∂ÁöÑÊú¨Ë≥™ÊâÄÈòªÁ§ô„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Á≠îÊ°àÈõÜÁ∂≤Ë∑ØÔºàASNÔºâÔºå‰∏ÄÂÄã NeSy Ê±ÇËß£Âô®„ÄÇASN Âü∫ÊñºÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâÔºåÊòØ‰∏ÄÁ®ÆÂü∫Êñº ASP ÁöÑÊ∑±Â∫¶Ê©üÁéáÈÇèËºØÁ®ãÂºèË®≠Ë®àÔºàDPPLÔºâÁöÑÂèØÊì¥ÂÖÖÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ±ïÁ§∫Â¶Ç‰ΩïÂ∞á ASP ËΩâÊèõÁÇ∫ ASNÔºå‰∏¶Â±ïÁ§∫ ASN Â¶Ç‰ΩïÈÄèÈÅéÂà©Áî® GPU ÁöÑÊâπÊ¨°ËôïÁêÜÂíå‰∏¶Ë°åÂåñÂäüËÉΩÊúâÊïàÂú∞Ëß£Ê±∫Á∑®Á¢ºÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË©ï‰º∞Ë°®ÊòéÔºåASN Âú®Â§öÈ†Ö‰ªªÂãô‰∏äÂÑ™ÊñºÁèæÊúâÁöÑÂèó CPU ÈôêÂà∂ÁöÑ NeSy Á≥ªÁµ±„ÄÇÂêåÊôÇÔºåÊàëÂÄëÊ†πÊìö ASN ÁöÑÂÑ™Âã¢ÂÅöÂá∫‰∫Ü‰ª•‰∏ãÂÖ©È†ÖË≤¢Áçª„ÄÇ‰πüÂ∞±ÊòØË™™ÔºåÊàëÂÄëÈ¶ñÊ¨°Â±ïÁ§∫‰ΩøÁî® DPPL Â∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÈÄ≤Ë°åÂæÆË™øÔºå‰ΩøÁî® ASN ‰ª•ÈÇèËºØÂºïÂ∞éË®ìÁ∑¥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁÑ°‰∫∫Ê©üÁöÑ„ÄåÊÜ≤Ê≥ïÂ∞éËà™„ÄçÔºåÂç≥Âú® ASN ‰∏≠Á∑®Á¢ºÂÖ¨ÂÖ±Ëà™Á©∫Ê≥ïÔºå‰ª•‰æøÂú®‰∏çÁ¢∫ÂÆöÁöÑÁí∞Â¢É‰∏≠Â∞çÁÑ°‰∫∫Ê©üÈÄ≤Ë°åË∑ØÁî±„ÄÇ

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

ÊëòË¶ÅÔºöÁ§æ‰∫§Â™íÈ´îÂπ≥Âè∞Â∑≤ÊàêÁÇ∫ÂÖ¨ÂÖ±Ë´ñËø∞ÁöÑÈáçË¶ÅÁ©∫ÈñìÔºå‰ΩúÁÇ∫Áèæ‰ª£Âª£Â†¥ÔºåÂêÑÁ®ÆËÅ≤Èü≥ÂΩ±ÈüøËëóÁ§æÊúÉÊïò‰∫ã„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÈñãÊîæÊÄß‰πü‰ΩøÂæóÂÆÉÂÄëÂÆπÊòìÂèóÂà∞ÊÉ°ÊÑèË°åÁÇ∫ËÄÖÁöÑÂà©Áî®ÔºåÂåÖÊã¨ÂúãÂÆ∂Ë≥áÂä©ÁöÑÂØ¶È´îÔºå‰ªñÂÄëÂèØ‰ª•ÈÄ≤Ë°å‰ø°ÊÅØÊìç‰Ωú (IO) ‰ª•ÊìçÁ∏±ËºøË´ñ„ÄÇÈåØË™§‰ø°ÊÅØÁöÑÂÇ≥Êí≠„ÄÅËôõÂÅáÊñ∞ËÅûÂíåË™§Â∞éÊÄßË™™Ê≥ïÂ®ÅËÑÖËëóÊ∞ë‰∏ªÈÄ≤Á®ãÂíåÁ§æÊúÉÂáùËÅöÂäõÔºåÂõ†Ê≠§Âà∂ÂÆöÂèäÊôÇÊ™¢Ê∏¨ËôõÂÅáÊ¥ªÂãï‰ª•‰øùË≠∑Âú®Á∑öË´ñËø∞ÁöÑÂÆåÊï¥ÊÄßÁöÑÊñπÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÊó®Âú®Ë≠òÂà•Âú®ÂêÑÁ®ÆÂΩ±ÈüøÂäõÈÅãÂãï‰∏≠Á≠ñÂäÉ‰ø°ÊÅØË°åÂãïÁöÑÁî®Êà∂ÔºåÂç≥ÊâÄË¨ÇÁöÑ„ÄåIO È©ÖÂãïÁ®ãÂ∫è„Äç„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂêçÁÇ∫ \texttt{IOHunter}ÔºåÂÆÉÂà©Áî®Ë™ûË®ÄÊ®°ÂûãÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÁ∂úÂêàÂÑ™Âã¢‰æÜÊîπÂñÑ„ÄåÁõ£Áù£„Äç„ÄÅ„ÄåÁ®ÄÁñèÁõ£Áù£„ÄçÂíå„ÄåË∑® IO„ÄçÊÉÖÂ¢É‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®‰æÜËá™ÂÖ≠ÂÄãÂúãÂÆ∂ÁöÑÂ§öÁµÑ IO ‰∏≠ÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÈ°ØËëóË∂ÖË∂ä‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ê®ôË™åËëóÂ∞àÈñÄÈáùÂ∞çÁ§æ‰∫§Â™íÈ´îÂπ≥Âè∞‰∏äÁöÑ IO Ê™¢Ê∏¨‰ªªÂãôÈñãÁôºÂúñÂü∫Á§éÊ®°ÂûãÈÇÅÂá∫‰∫Ü‰∏ÄÊ≠•„ÄÇ

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

ÊëòË¶ÅÔºöÂú®ÂÖ∑Ë∫´ÂïèÁ≠î (EQA) ‰∏≠Ôºå‰ª£ÁêÜÂøÖÈ†àÊé¢Á¥¢‰∏¶ÁôºÂ±ïÂ∞çÊú™Ë¶ãÈÅéÁí∞Â¢ÉÁöÑË™ûÁæ©ÁêÜËß£ÔºåÊâçËÉΩÊúâ‰ø°ÂøÉÂú∞ÂõûÁ≠îÊÉÖÂ¢ÉÂïèÈ°å„ÄÇÁî±ÊñºÈõ£‰ª•ÂèñÂæóÊúâÁî®ÁöÑË™ûÁæ©Ë°®Á§∫„ÄÅÁ∑ö‰∏äÊõ¥Êñ∞ÈÄô‰∫õË°®Á§∫Ôºå‰ª•ÂèäÂà©Áî®ÂÖàÂâçÁöÑ‰∏ñÁïåÁü•Ë≠òÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÊé¢Á¥¢ÂíåË¶èÂäÉÔºåÈÄôÂú®Ê©üÂô®‰∫∫Â≠∏‰∏≠‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ GraphEQAÔºå‰∏ÄÁ®ÆÂà©Áî®Âç≥ÊôÇ 3D Â∫¶ÈáèË™ûÁæ©Â†¥ÊôØÂúñ (3DSG) ÂíåËàá‰ªªÂãôÁõ∏ÈóúÁöÑÂΩ±ÂÉè‰ΩúÁÇ∫Â§öÊ®°ÂºèË®òÊÜ∂È´îÁöÑÊñ∞Á©éÊñπÊ≥ïÔºå‰ª•Êé•Âú∞Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ‰æÜÂü∑Ë°åÊú™Ë¶ãÈÅéÁí∞Â¢É‰∏≠ÁöÑ EQA ‰ªªÂãô„ÄÇÊàëÂÄëÊé°Áî®ÂàÜÂ±§Ë¶èÂäÉÊñπÊ≥ïÔºåÂà©Áî® 3DSG ÁöÑÂàÜÂ±§ÊÄßË≥™ÈÄ≤Ë°åÁµêÊßãÂåñË¶èÂäÉÂíåË™ûÁæ©ÂºïÂ∞éÊé¢Á¥¢„ÄÇÈÄèÈÅéÂú® HM-EQA Ë≥áÊñôÈõÜ‰∏äÁöÑÊ®°Êì¨ÂØ¶È©óÔºå‰ª•ÂèäÂú®ÂÆ∂Â∫≠ÂíåËæ¶ÂÖ¨ÂÆ§Áí∞Â¢É‰∏≠ÁöÑÁúüÂØ¶‰∏ñÁïå‰∏≠ÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅé‰ª•ËºÉÈ´òÁöÑÊàêÂäüÁéáÂíåËºÉÂ∞ëÁöÑË¶èÂäÉÊ≠•È©üÂÆåÊàê EQA ‰ªªÂãôÔºåÂÑ™Êñº‰∏ªË¶ÅÁöÑÂü∫Á∑ö„ÄÇ

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

ÊëòË¶ÅÔºöÂõ†ÊûúÁôºÁèæÂ∞çÊñºÁêÜËß£Ë§áÈõúÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂº∑ËÄå‰∏çÂèØÊ∏¨Ë©¶ÁöÑÂÅáË®≠ÔºåÈÄô‰ΩøÂæóÈÄôÂÄãÈÅéÁ®ãÂÖÖÊªøÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂæûÂü∫ÊñºÊñáÊú¨ÁöÑÂÖÉÊï∏Êìö‰∏≠ÊèêÂèñÂõ†ÊûúË¶ãËß£ÁöÑÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºåÂÆÉÊï¥Âêà‰∫ÜÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁÑ∂ËÄåÔºåLLM ÂÆπÊòìÂá∫Áèæ‰∏çÂèØÈù†ÊÄßÂíåÂπªË¶∫ÔºåÈÄôÈúÄË¶ÅËÄÉÊÖÆÂÖ∂ÈôêÂà∂ÁöÑÁ≠ñÁï•„ÄÇ‰∏ÄÁ®ÆÈÄôÊ®£ÁöÑÁ≠ñÁï•Ê∂âÂèäÂà©Áî®‰∏ÄËá¥ÊÄßÂ∫¶Èáè‰æÜË©ï‰º∞ÂèØÈù†ÊÄß„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏ÊñáÊú¨ÂÖÉÊï∏Êìö‰∏¶Êú™Ê∏ÖÊ•öÂú∞ÂçÄÂàÜÁõ¥Êé•Âõ†ÊûúÈóú‰øÇÂíåÈñìÊé•Âõ†ÊûúÈóú‰øÇÔºåÈÄôÈÄ≤‰∏ÄÊ≠•Ë§áÈõúÂåñ‰∫ÜÂõ†ÊûúÂúñÁöÑÊé®Ë´ñ„ÄÇÂõ†Ê≠§ÔºåÂ∞àÊ≥®ÊñºÂõ†ÊûúÈ†ÜÂ∫èÔºåËÄå‰∏çÊòØÂõ†ÊûúÂúñÔºåÊàêÁÇ∫‰∏ÄÁ®ÆÊõ¥ÂØ¶Áî®„ÄÅÊõ¥Á©©ÂÅ•ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï‰æÜÊé®Â∞éÁÑ°Áí∞Èå¶Ê®ôË≥ΩÁöÑÂàÜÂ∏ÉÔºàË°®Á§∫ÂêàÁêÜÁöÑÂõ†ÊûúÈ†ÜÂ∫èÔºâÔºåÈÄôÊúÄÂ§ßÂåñ‰∫Ü‰∏ÄËá¥ÊÄßÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàË®àÁÆóËÆäÈáè‰πãÈñìÊàêÂ∞çÁöÑ‰∏ÄËá¥ÊÄßÂàÜÊï∏ÔºåÁî¢Áîü‰∏ÄÂÄãÂΩôÁ∏ΩÈÄô‰∫õÂàÜÊï∏ÁöÑÂæ™Áí∞Èå¶Ê®ôË≥Ω„ÄÇÂæûÈÄôÂÄãÁµêÊßã‰∏≠ÔºåÊàëÂÄëË≠òÂà•Âá∫ËàáÂéüÂßãÈå¶Ê®ôË≥ΩÁõ∏ÂÆπÁöÑÊúÄ‰Ω≥ÁÑ°Áí∞Èå¶Ê®ôË≥ΩÔºåÂÑ™ÂÖàËÄÉÊÖÆÈÇ£‰∫õÂú®ÊâÄÊúâÈÖçÁΩÆ‰∏≠ÊúÄÂ§ßÂåñ‰∏ÄËá¥ÊÄßÁöÑÈå¶Ê®ôË≥Ω„ÄÇÊàëÂÄëÂú®Á∂ìÂÖ∏‰∏îÂÆåÂñÑÁöÑÂü∫Ê∫ñ‰ª•Âèä‰æÜËá™ÊµÅË°åÁóÖÂ≠∏ÂíåÂÖ¨ÂÖ±Ë°õÁîüÁöÑÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜ‰∏äÊ∏¨Ë©¶‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®‰ª•ÊúÄÂ∞èË™§Â∑ÆÊÅ¢Âæ©Âõ†ÊûúÈ†ÜÂ∫èÂàÜÂ∏ÉÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, Mari√´lle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

ÊëòË¶ÅÔºöÂú®ËÄÉÈáèÈ´òÈ¢®Èö™‰∫ã‰ª∂ÊàñË°åÂãïÊôÇÔºåÊàëÂÄë‰∏çËÉΩ‰Ωé‰º∞ÊâÄÊ∂âÁâ©‰ª∂ÁöÑËßíËâ≤ÔºöÊâãÊ©ü‰∏≠ÁöÑÂÖÖÈõªÈõªÊ±†ÂèØÈÅøÂÖçÂú®ÁàÜËÉéÂæåÂèóÂõ∞Ê≤ôÊº†ÁöÑÈ¢®Èö™ÔºåËÄåÂäüËÉΩÊ≠£Â∏∏ÁöÑÈò≤ÁÅ´ÁâÜÂâáÂèØÈôç‰ΩéÈß≠ÂÆ¢ÂÖ•‰æµÁ∂≤Ë∑ØÁöÑÈ¢®Èö™„ÄÇÂÉπÂÄºËàáÈ¢®Èö™ÁöÑÂÖ±Áî®Êú¨‰ΩìË´ñ (COVER) Âº∑Ë™øÁâ©‰ª∂ÂèäÂÖ∂Èóú‰øÇÁöÑËßíËâ≤ÔºåÂ∞çÊñºÂü∑Ë°åÈÄèÊòé„ÄÅÂÆåÊï¥‰∏îË≤†Ë≤¨‰ªªÁöÑÈ¢®Èö™Ë©ï‰º∞‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á COVER ÊâÄÊèêÂá∫ÁöÑÈÉ®ÂàÜÊ¶ÇÂøµÔºà‰æãÂ¶ÇÁâ©‰ª∂‰πãÈñìÁöÑÁµÑÊàêÈÉ®ÂàÜÈóú‰øÇÔºå‰ª•ÂèäÁâ©‰ª∂ÂèÉËàá‰∫ã‰ª∂/Ë°åÂãïÔºâÂÖ∑È´îÂåñÔºåËóâÁî±ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÈ¢®Èö™Ë©ï‰º∞Êû∂ÊßãÔºöDODGE„ÄÇDODGE ÈÄèÈÅéÂ∞áÊú¨‰ΩìË´ñËàáÂΩ¢ÂºèÂåñÊñπÊ≥ïÊ©ãÊé•Ëá≥‰∏ÄÂÄãÊú¨‰ΩìË´ñÊÑüÁü•ÂΩ¢ÂºèÂåñÊû∂Êßã‰∏≠ÔºåË±êÂØå‰∫ÜÈ¢®Èö™È©óË≠âÂΩ¢ÂºèÂåñÊ®°ÂûãÔºà‰æãÂ¶ÇÊïÖÈöúÊ®πÂíåÊîªÊìäÊ®πÔºâÁöÑË°®ÈÅîÂäõÔºåË©≤Êû∂ÊßãÁî±Êõ¥ÂÖ∑Ë°®ÈÅîÂäõÁöÑÂª∫Ê®°ÂΩ¢Âºè‰∏ªÁæ©„ÄÅÁâ©‰ª∂Â∞éÂêë‰∏≠Êñ∑Âúñ (ODG)„ÄÅÈÇèËºØ (ODGLog) Âíå‰∏ÄÂÄã‰∏≠ÈñìÊü•Ë©¢Ë™ûË®Ä (ODGLang) ÁµÑÊàê„ÄÇÈÄèÈÅéÈÄô‰∫õÔºåDODGE ËÆìÈ¢®Èö™Ë©ï‰º∞ËÄÖËÉΩÂ§†ÊèêÂá∫ÊúâÈóú‰∏≠Êñ∑ÂÇ≥Êí≠„ÄÅ‰∏≠Êñ∑ÂèØËÉΩÊÄßÂíåÈ¢®Èö™Â±§Á¥öÁöÑÂïèÈ°åÔºåÂêåÊôÇÂßãÁµÇ‰øùÊåÅÂ∞çÈ¢®Èö™Áâ©‰ª∂ÁöÑÂü∫Êú¨ËßíËâ≤ÁöÑÈóúÊ≥®„ÄÇ

##### **Knowledge Editing with Dynamic Knowledge Graphs for Multi-Hop Question Answering**
2412.13782v2 by Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang

Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.

ÊëòË¶ÅÔºöÂ§öË∑≥ÂïèÁ≠î (MHQA) Áî±ÊñºÊ∂âÂèäÂª£Ê≥õÁöÑÁü•Ë≠òÈúÄÊ±ÇÔºåÂõ†Ê≠§Â∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁü•Ë≠òÁ∑®ËºØÊó®Âú®Á≤æÁ¢∫‰øÆÊîπ LLM ‰ª•Á¥çÂÖ•ÁâπÂÆöÁü•Ë≠òÔºåÂêåÊôÇ‰∏çÂ∞çÂÖ∂‰ªñÁÑ°ÈóúÁü•Ë≠òÁî¢ÁîüË≤†Èù¢ÂΩ±ÈüøÔºåÁÇ∫‰∫ÜËß£Ê±∫ LLM ‰∏≠ÁöÑ MHQA ÊåëÊà∞Êèê‰æõ‰∫ÜÊΩõÂú®Ëß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑËß£Ê±∫ÊñπÊ°àÈõ£‰ª•ÊúâÊïàËß£Ê±∫Áü•Ë≠òË°ùÁ™ÅÂïèÈ°å„ÄÇÂ§ßÂ§öÊï∏‰øùÁïôÂèÉÊï∏ÁöÑÁ∑®ËºØÊñπÊ≥ïÂèóÂà∞‰∏çÊ∫ñÁ¢∫Ê™¢Á¥¢ÁöÑÈòªÁ§ôÔºå‰∏¶‰∏îÂøΩË¶ñ‰∫ÜÊ¨°Ë¶ÅÁ∑®ËºØÂïèÈ°åÔºåÈÄôÂèØËÉΩÊúÉÂú® LLM ÁöÑÊé®ÁêÜÈÅéÁ®ã‰∏≠ÂºïÂÖ•ÈõúË®ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü KEDKGÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÔºåÂÆÉÂà©Áî®ÂãïÊÖãÁü•Ë≠òÂúñË≠úÈÄ≤Ë°å MHQAÔºåÊó®Âú®Á¢∫‰øùÁ≠îÊ°àÁöÑÂèØÈù†ÊÄß„ÄÇKEDKG Ê∂âÂèäÂÖ©ÂÄã‰∏ªË¶ÅÊ≠•È©üÔºöÂãïÊÖãÁü•Ë≠òÂúñË≠úÊßãÂª∫ÂíåÁü•Ë≠òÂúñË≠úÂ¢ûÂº∑ÁîüÊàê„ÄÇÊúÄÂàùÔºåKEDKG Ëá™‰∏ªÊßãÂª∫‰∏ÄÂÄãÂãïÊÖãÁü•Ë≠òÂúñË≠ú‰æÜÂÑ≤Â≠ò‰øÆÊîπÂæåÁöÑË≥áË®äÔºåÂêåÊôÇËß£Ê±∫ÊΩõÂú®ÁöÑÁü•Ë≠òË°ùÁ™Å„ÄÇÈö®ÂæåÔºåÂÆÉÊé°Áî®Á¥∞Á≤íÂ∫¶ÁöÑÊ™¢Á¥¢Á≠ñÁï•ÔºåÁµêÂêàÂØ¶È´îÂíåÈóú‰øÇÊ™¢Ê∏¨Âô®Ôºå‰ª•ÊèêÈ´ò LLM ÁîüÊàêÁöÑÂúñË≠úÊ™¢Á¥¢Ê∫ñÁ¢∫Â∫¶„ÄÇÂü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåKEDKG Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤Ê®°ÂûãÔºåÂú®ÂÖ∑ÊúâÂãïÊÖãË≥áË®äÁöÑÁí∞Â¢É‰∏≠Êèê‰æõ‰∫ÜÊõ¥Ê∫ñÁ¢∫ÂíåÂèØÈù†ÁöÑÁ≠îÊ°à„ÄÇ

##### **Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**
2412.13544v1 by Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren

In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with sparse interactions.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁü•Ë≠òÂúñË≠úÂ∑≤Êï¥ÂêàÂà∞Êé®Ëñ¶Á≥ªÁµ±‰∏≠Ôºå‰ΩúÁÇ∫È†ÖÁõÆÂÅ¥ËºîÂä©Ë≥áË®äÔºåÊèêÂçáÊé®Ëñ¶Ê∫ñÁ¢∫Â∫¶„ÄÇ
ÁÑ∂ËÄåÔºåÁî±Êñº‰ΩøÁî®ËÄÖÂÅ¥ÁâπÂæµÁöÑÁ≤íÂ∫¶‰∏çÁï∂ÂíåÂÖßÂú®Á®ÄÂ∞ëÊÄßÔºåÂª∫ÊßãÂíåÊï¥ÂêàÁµêÊßãÂåñ‰ΩøÁî®ËÄÖÂÅ¥Áü•Ë≠ò‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇ
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊèê‰æõ‰∫ÜÂΩåÂêàÊ≠§Â∑ÆË∑ùÁöÑÊΩõÂäõÔºåÊñπÊ≥ïÊòØÂà©Áî®ÂÆÉÂÄëÂ∞ç‰∫∫È°ûË°åÁÇ∫ÁöÑÁêÜËß£ÂíåÂª£Ê≥õÁöÑÁúüÂØ¶‰∏ñÁïåÁü•Ë≠ò„ÄÇ
ÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂ∞á LLM ÁîüÊàêÁöÑË≥áË®äÊï¥ÂêàÂà∞Êé®Ëñ¶Á≥ªÁµ±‰∏≠ÊúÉÂ∏∂‰æÜÊåëÊà∞ÔºåÂåÖÊã¨ÈõúË®äË≥áË®äÁöÑÈ¢®Èö™ÂíåÈúÄË¶ÅÈ°çÂ§ñÁöÑÁü•Ë≠òËΩâÁßª„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº LLM ÁöÑ‰ΩøÁî®ËÄÖÂÅ¥Áü•Ë≠òÊé®Ë´ñÊñπÊ≥ïÔºå‰ª•Âèä‰∏ÄÂÄãÁ≤æÂøÉË®≠Ë®àÁöÑÊé®Ëñ¶Êû∂ÊßãÔºå‰ª•ÊáâÂ∞çÈÄô‰∫õÊåëÊà∞„ÄÇ
ÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî® LLM ‰æÜÊé®Ë´ñÂü∫ÊñºÊ≠∑Âè≤Ë°åÁÇ∫ÁöÑ‰ΩøÁî®ËÄÖËààË∂£ÔºåÂ∞áÊ≠§‰ΩøÁî®ËÄÖÂÅ¥Ë≥áË®äËàáÈ†ÖÁõÆÂÅ¥ÂíåÂçî‰ΩúË≥áÊñôÊï¥ÂêàËµ∑‰æÜÔºå‰ª•Âª∫Êßã‰∏ÄÂÄãÊ∑∑ÂêàÁµêÊßãÔºöÂçî‰ΩúËààË∂£Áü•Ë≠òÂúñË≠ú (CIKG)„ÄÇ
Ê≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº CIKG ÁöÑÊé®Ëñ¶Êû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰ΩøÁî®ËÄÖËààË∂£ÈáçÂª∫Ê®°ÁµÑÂíåË∑®Á∂≤ÂüüÂ∞çÊØîÂ≠∏ÁøíÊ®°ÁµÑÔºå‰ª•Ê∏õËºïÊΩõÂú®ÈõúË®ä‰∏¶‰øÉÈÄ≤Áü•Ë≠òËΩâÁßª„ÄÇ
ÊàëÂÄëÂ∞ç‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•È©óË≠âÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ
ËàáÁ´∂Áà≠Âü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞çÊñº‰∫íÂãïÁ®ÄÁñèÁöÑ‰ΩøÁî®ËÄÖ„ÄÇ

##### **Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**
2412.13540v1 by Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Min Zhang

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across diverse tasks. Despite great success, recent studies show that LVLMs
encounter substantial limitations when engaging with visual graphs. To study
the reason behind these limitations, we propose VGCure, a comprehensive
benchmark covering 22 tasks for examining the fundamental graph understanding
and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs
reveal that LVLMs are weak in basic graph understanding and reasoning tasks,
particularly those concerning relational or structurally complex information.
Based on this observation, we propose a structure-aware fine-tuning framework
to enhance LVLMs with structure learning abilities through 3 self-supervised
learning tasks. Experiments validate the effectiveness of our method in
improving LVLMs' zero-shot performance on fundamental graph learning tasks, as
well as enhancing the robustness of LVLMs against complex visual graphs.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Â∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑË°®Áèæ„ÄÇÂÑòÁÆ°Áç≤ÂæóÂ∑®Â§ßÁöÑÊàêÂäüÔºåÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåLVLMs Âú®ËôïÁêÜË¶ñË¶∫ÂúñÂΩ¢ÊôÇÊúÉÈÅáÂà∞ÈáçÂ§ßÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÁ†îÁ©∂ÈÄô‰∫õÈôêÂà∂ËÉåÂæåÁöÑÂéüÂõ†ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü VGCureÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∂µËìã 22 È†Ö‰ªªÂãôÁöÑÁ∂úÂêàÂü∫Ê∫ñÔºåÁî®ÊñºÊ™¢Êü• LVLMs ÁöÑÂü∫Êú¨ÂúñÂΩ¢ÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂ∞ç 14 ÂÄã LVLMs ÈÄ≤Ë°åÁöÑÂª£Ê≥õË©ï‰º∞È°ØÁ§∫ÔºåLVLMs Âú®Âü∫Êú¨ÁöÑÂúñÂΩ¢ÁêÜËß£ÂíåÊé®ÁêÜ‰ªªÂãô‰∏≠ËºÉÂº±ÔºåÁâπÂà•ÊòØÈÇ£‰∫õÊ∂âÂèäÈóú‰øÇÊàñÁµêÊßãË§áÈõúË≥áË®äÁöÑ‰ªªÂãô„ÄÇÂü∫ÊñºÊ≠§ËßÄÂØüÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµêÊßãÊÑüÁü•ÂæÆË™øÊ°ÜÊû∂Ôºå‰ª•ÈÄèÈÅé 3 ÂÄãËá™ÊàëÁõ£Áù£Â≠∏Áøí‰ªªÂãô‰æÜÂ¢ûÂº∑ LVLMs ÁöÑÁµêÊßãÂ≠∏ÁøíËÉΩÂäõ„ÄÇÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊèêÂçá LVLMs Âú®Âü∫Êú¨ÂúñÂΩ¢Â≠∏Áøí‰ªªÂãô‰∏äÁöÑÈõ∂Ê¨°Â≠∏ÁøíË°®ÁèæÁöÑÊúâÊïàÊÄßÔºå‰ª•ÂèäÂ¢ûÂº∑ LVLMs Â∞çË§áÈõúË¶ñË¶∫ÂúñÂΩ¢ÁöÑÈ≠ØÊ£íÊÄß„ÄÇ

##### **Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**
2412.13467v1 by Imam Nur Bani Yusuf, Lingxiao Jiang

Large language models have demonstrated promising performance across various
software engineering tasks. While fine-tuning is a common practice to adapt
these models for downstream tasks, it becomes challenging in
resource-constrained environments due to increased memory requirements from
growing trainable parameters in increasingly large language models. We
introduce \approach, a technique to adapt large models for downstream code
tasks using Code Property Graphs (CPGs). Our approach introduces a modular
component called \transducer that enriches code embeddings with structural and
dependency information from CPGs. The Transducer comprises two key components:
Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE
extracts CPGs from input source code and transforms them into graph feature
vectors. ABFL then fuses those graphs feature vectors with initial code
embeddings from a large language model. By optimizing these transducers for
different downstream tasks, our approach enhances the models without the need
to fine-tune them for specific tasks. We have evaluated \approach on three
downstream tasks: code summarization, assert generation, and code translation.
Our results demonstrate competitive performance compared to full parameter
fine-tuning while reducing up to 99\% trainable parameters to save memory.
\approach also remains competitive against other fine-tuning approaches (e.g.,
LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their
trainable parameters. Our findings show that integrating structural and
dependency information through Transducer Tuning enables more efficient model
adaptation, making it easier for users to adapt large models in
resource-constrained settings.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∑≤Âú®ÂêÑÁ®ÆËªüÈ´îÂ∑•Á®ã‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩ„ÄÇÈõñÁÑ∂ÂæÆË™øÊòØË™øÊï¥ÈÄô‰∫õÊ®°Âûã‰ª•Âü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÔºå‰ΩÜÁî±ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÂèØË®ìÁ∑¥ÂèÉÊï∏‰∏çÊñ∑Â¢ûÂä†ÔºåÂ∞éËá¥Ë®òÊÜ∂È´îÈúÄÊ±ÇÂ¢ûÂä†ÔºåÂõ†Ê≠§Âú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠ËÆäÂæóÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü \approachÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰ΩøÁî®Á®ãÂºèÁ¢ºÂ±¨ÊÄßÂúñ (CPG) ‰æÜË™øÊï¥Â§ßÂûãÊ®°Âûã‰ª•Âü∑Ë°å‰∏ãÊ∏∏Á®ãÂºèÁ¢º‰ªªÂãôÁöÑÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÁ®±ÁÇ∫ \transducer ÁöÑÊ®°ÁµÑÂåñÂÖÉ‰ª∂ÔºåÂÆÉ‰ΩøÁî®‰æÜËá™ CPG ÁöÑÁµêÊßãÂíå‰æùË≥¥Èóú‰øÇË≥áË®ä‰æÜË±êÂØåÁ®ãÂºèÁ¢ºÂµåÂÖ•„ÄÇTransducer ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÂÖÉ‰ª∂ÔºöÂúñÂêëÈáèÂåñÂºïÊìé (GVE) ÂíåÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑËûçÂêàÂ±§ (ABFL)„ÄÇGVE ÂæûËº∏ÂÖ•ÂéüÂßãÁ¢º‰∏≠ËêÉÂèñ CPGÔºå‰∏¶Â∞áÂÆÉÂÄëËΩâÊèõÁÇ∫ÂúñÂΩ¢ÁâπÂæµÂêëÈáè„ÄÇABFL Êé•ËëóÂ∞áÈÄô‰∫õÂúñÂΩ¢ÁâπÂæµÂêëÈáèËàá‰æÜËá™Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂàùÂßãÁ®ãÂºèÁ¢ºÂµåÂÖ•ËûçÂêà„ÄÇÈÄèÈÅéÈáùÂ∞ç‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãôÊúÄ‰Ω≥ÂåñÈÄô‰∫õËΩâÊèõÂô®ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÔºåËÄåÁÑ°ÈúÄÈáùÂ∞çÁâπÂÆö‰ªªÂãôÈÄ≤Ë°åÂæÆË™ø„ÄÇÊàëÂÄëÂ∑≤Âú®‰∏âÂÄã‰∏ãÊ∏∏‰ªªÂãô‰∏≠Ë©ï‰º∞ \approachÔºöÁ®ãÂºèÁ¢ºÊëòË¶Å„ÄÅÊñ∑Ë®ÄÁî¢ÁîüÂíåÁ®ãÂºèÁ¢ºÁøªË≠Ø„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÆåÂÖ®ÂèÉÊï∏ÂæÆË™øÁõ∏ÊØîÔºåÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩÔºåÂêåÊôÇÊ∏õÂ∞ë‰∫ÜÂ§öÈÅî 99% ÁöÑÂèØË®ìÁ∑¥ÂèÉÊï∏‰ª•ÁØÄÁúÅË®òÊÜ∂È´î„ÄÇ\approach Âú®ÂÉÖ‰ΩøÁî® 1.5% - 80% ÂèØË®ìÁ∑¥ÂèÉÊï∏ÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ªçÁÑ∂Âú®ËàáÂÖ∂‰ªñÂæÆË™øÊñπÊ≥ïÔºà‰æãÂ¶Ç LoRA„ÄÅPrompt-Tuning„ÄÅPrefix-TuningÔºâÁöÑÁ´∂Áà≠‰∏≠‰øùÊåÅÁ´∂Áà≠Âäõ„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåÈÄèÈÅé Transducer Tuning Êï¥ÂêàÁµêÊßãÂíå‰æùË≥¥Èóú‰øÇË≥áË®äÂèØ‰ª•ÂØ¶ÁèæÊõ¥ÊúâÊïàÁéáÁöÑÊ®°ÂûãË™øÊï¥Ôºå‰ΩøÁî®Êà∂Êõ¥ÂÆπÊòìÂú®Ë≥áÊ∫êÂèóÈôêÁöÑË®≠ÂÆö‰∏≠Ë™øÊï¥Â§ßÂûãÊ®°Âûã„ÄÇ

##### **Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**
2412.13283v1 by Konstantin Zaitsev

In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âõ†ÂÖ∂Â¢ûÂº∑ËôõÊì¨Âä©ÁêÜÂíåËÅäÂ§©Ê©üÂô®‰∫∫‰∏≠ÂÄã‰∫∫ÂåñÈ´îÈ©óÁöÑÊΩõÂäõËÄåÂÇôÂèóÈóúÊ≥®„ÄÇ‰∏ÄÂÄãÈóúÈçµÁöÑËààË∂£È†òÂüüÊòØÂ∞áËßíËâ≤ËûçÂÖ• LLMÔºå‰ª•ÊîπÂñÑÂ∞çË©±ÁöÑËá™ÁÑ∂ÊÄßÂíå‰ΩøÁî®ËÄÖÂèÉËàáÂ∫¶„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éËßíËâ≤ÂàÜÈ°ûÁöÑÊåëÊà∞ÔºåÈÄôÊòØÂ∞çË©±ÁêÜËß£‰∏≠ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºåÊèêÂá∫‰∏ÄÂÄãÁµêÂêàÊñáÊú¨ÂµåÂÖ•ËàáÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÊû∂ÊßãÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑËßíËâ≤ÂàÜÈ°û„ÄÇÈëëÊñºÁº∫‰πèÂ∞àÁî®ÁöÑËßíËâ≤ÂàÜÈ°ûË≥áÊñôÈõÜÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊâãÂãïÊ®ôË®ªÁöÑË≥áÊñôÈõÜÔºå‰ª•Âà©ÊñºÊ®°ÂûãË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂåÖÊã¨‰ΩøÁî®ÊñáÊú¨ÂµåÂÖ•ÂæûËßíËâ≤Èô≥Ëø∞‰∏≠ÊèêÂèñË™ûÁæ©ÁâπÂæµÔºå‰∏¶Âª∫Êßã‰∏ÄÂÄãÂúñÔºåÂÖ∂‰∏≠ÁØÄÈªûË°®Á§∫ËßíËâ≤ÔºåËÄåÈÇäÁ∑£ÊçïÊçâÂÆÉÂÄëÁöÑÁõ∏‰ººÊÄß„ÄÇGNN ÁµÑ‰ª∂‰ΩøÁî®ÈÄôÂÄãÂúñÁµêÊßã‰æÜÂÇ≥Êí≠Áõ∏ÈóúË≥áË®äÔºåÂæûËÄåÊîπÂñÑÂàÜÈ°ûÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÁâπÂà•ÊòØ GNN ÁöÑÊï¥ÂêàÔºåÈ°ØËëóÊîπÂñÑ‰∫ÜÂàÜÈ°ûÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÈñãÁôºËßíËâ≤ÂàÜÈ°ûÊû∂ÊßãÂíåÂª∫Á´ãË≥áÊñôÈõÜ„ÄÇ

##### **SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**
2412.15272v1 by Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng

Recent advancements in large language models (LLMs) have shown impressive
versatility across various tasks. To eliminate its hallucinations,
retrieval-augmented generation (RAG) has emerged as a powerful approach,
leveraging external knowledge sources like knowledge graphs (KGs). In this
paper, we study the task of KG-driven RAG and propose a novel Similar Graph
Enhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively
addresses the challenge of aligning query texts and KG structures through a
two-stage process: (1) query-to-pattern, which uses an LLM to transform queries
into a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the
alignment between the pattern and candidate subgraphs using a graph semantic
distance (GSD) metric. We also develop an optimized retrieval algorithm that
efficiently identifies the top-$k$ subgraphs within 1-second latency on a
10-million-scale KG. Extensive experiments show that SimGRAG outperforms
state-of-the-art KG-driven RAG methods in both question answering and fact
verification, offering superior plug-and-play usability and scalability.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÊ∂àÈô§ÂÖ∂ÂπªË¶∫ÔºåÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂº∑Â§ßÁöÑÊñπÊ≥ïÔºåÂà©Áî®Â§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫êÔºå‰æãÂ¶ÇÁü•Ë≠òÂúñË≠úÔºàKGÔºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü KG È©ÖÂãï RAG ÁöÑ‰ªªÂãôÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈ°û‰ººÂúñÂΩ¢Â¢ûÂº∑Êì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàSimGRAGÔºâÊñπÊ≥ï„ÄÇÂÆÉÈÄöÈÅé‰∏ÄÂÄãÂÖ©ÈöéÊÆµÈÅéÁ®ãÊúâÊïàÂú∞ÊáâÂ∞ç‰∫ÜÂ∞çÈΩäÊü•Ë©¢ÊñáÊú¨Âíå KG ÁµêÊßãÁöÑÊåëÊà∞Ôºö(1) Êü•Ë©¢Âà∞Ê®°ÂºèÔºåÂÆÉ‰ΩøÁî® LLM Â∞áÊü•Ë©¢ËΩâÊèõÁÇ∫ÊâÄÈúÄÁöÑÂúñÂΩ¢Ê®°ÂºèÔºå‰ª•Âèä (2) Ê®°ÂºèÂà∞Â≠êÂúñÔºåÂÆÉ‰ΩøÁî®ÂúñÂΩ¢Ë™ûÁæ©Ë∑ùÈõ¢ (GSD) Â∫¶Èáè‰æÜÈáèÂåñÊ®°ÂºèÂíåÂÄôÈÅ∏Â≠êÂúñ‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊúÄ‰Ω≥ÂåñÁöÑÊì∑ÂèñÊºîÁÆóÊ≥ïÔºåÂèØ‰ª•Âú® 1000 Ëê¨Ë¶èÊ®°ÁöÑ KG ‰∏ä‰ª• 1 ÁßíÁöÑÂª∂ÈÅ≤ÊúâÊïàÂú∞Ë≠òÂà•Ââç $k$ ÂÄãÂ≠êÂúñ„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåSimGRAG Âú®ÂïèÁ≠îÂíå‰∫ãÂØ¶È©óË≠âÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ KG È©ÖÂãï RAG ÊñπÊ≥ïÔºåÊèê‰æõ‰∫ÜÂçìË∂äÁöÑÂç≥ÊèíÂç≥Áî®ÂèØÁî®ÊÄßÂíåÂèØÊì¥Â±ïÊÄß„ÄÇ

##### **Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**
2412.12808v2 by Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin

This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®ËÆΩÂà∫Ê£ÄÊµãÔºåÂÖ∂Êó®Âú®ËØÜÂà´ÁªôÂÆöÁöÑÈôàËø∞ÊòØÂê¶‰º†Ëææ‰∫Ü‰∏éÂ≠óÈù¢ÊÑèÊÄùÁõ∏ÂèçÁöÑÊâπËØÑ„ÄÅÂò≤ËÆΩÊàñÂÖ∂‰ªñÊ∂àÊûÅÊÉÖÁª™„ÄÇ‰∏∫‰∫ÜÊ£ÄÊµãËÆΩÂà∫Ôºå‰∫∫Á±ªÈÄöÂ∏∏ÈúÄË¶ÅÂÖ®Èù¢ÁêÜËß£ÈôàËø∞‰∏≠ÁöÑËØ≠‰πâÔºåÁîöËá≥ËØâËØ∏Â§ñÈÉ®Â∏∏ËØÜÊù•Êé®Êñ≠ÁªÜÁ≤íÂ∫¶ÁöÑÁüõÁõæ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Èù¢ÂØπÂ§çÊùÇÁöÑÁé∞ÂÆû‰∏ñÁïåÂú∫ÊôØÊó∂Áº∫‰πèÂ∏∏ËØÜÊé®ÁêÜËÉΩÂäõÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁî®‰∫éËÆΩÂà∫Ê£ÄÊµãÁöÑÊñ∞ÂûãÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Âü∫‰∫éÂ∏∏ËØÜÂ¢ûÂº∫ËøõË°å‰∏ç‰∏ÄËá¥Êé®ÁêÜÔºåÁß∞‰∏∫ EICR„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨È¶ñÂÖàÈááÁî®Ê£ÄÁ¥¢Â¢ûÂº∫ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊù•Ë°•ÂÖÖÁº∫Â§±‰ΩÜ‰∏çÂèØÊàñÁº∫ÁöÑÂ∏∏ËØÜËÉåÊôØÁü•ËØÜ„ÄÇ‰∏∫‰∫ÜÊçïÊçâÂ§çÊùÇÁöÑ‰∏ä‰∏ãÊñáÂÖ≥ËÅîÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™‰æùËµñÂõæÔºåÂπ∂ÈÄöËøáÂõæÁªÜÂåñËé∑Âæó‰∫Ü‰ºòÂåñÁöÑÊãìÊâë„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÊé®ÁêÜÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈõÜÊàê‰∫ÜÂÖàÈ™åËßÑÂàôÔºå‰ª•ÊòéÁ°ÆÊèêÂèñÊÉÖÁª™‰∏ç‰∏ÄËá¥ÁöÑÂ≠êÂõæ„ÄÇ‰∏∫‰∫ÜÊ∂àÈô§ÂçïËØçÂíåÊ†áÁ≠æ‰πãÈó¥ÂèØËÉΩÁöÑËôöÂÅáÂÖ≥Á≥ªÔºåÊàë‰ª¨ÈááÁî®ÂØπÊäóÂØπÊØîÂ≠¶‰π†Êù•Â¢ûÂº∫Ê£ÄÊµãÂô®ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇÂú®‰∫î‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂÆûÈ™åËØÅÊòé‰∫Ü EICR ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **AnalogXpert: Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models**
2412.19824v1 by Haoyi Zhang, Shizhao Sun, Yibo Lin, Runsheng Wang, Jiang Bian

Analog circuits are crucial in modern electronic systems, and automating
their design has attracted significant research interest. One of major
challenges is topology synthesis, which determines circuit components and their
connections. Recent studies explore large language models (LLM) for topology
synthesis. However, the scenarios addressed by these studies do not align well
with practical applications. Specifically, existing work uses vague design
requirements as input and outputs an ideal model, but detailed structural
requirements and device-level models are more practical. Moreover, current
approaches either formulate topology synthesis as graph generation or Python
code generation, whereas practical topology design is a complex process that
demands extensive design knowledge. In this work, we propose AnalogXpert, a
LLM-based agent aiming at solving practical topology synthesis problem by
incorporating circuit design expertise into LLMs. First, we represent analog
topology as SPICE code and introduce a subcircuit library to reduce the design
space, in the same manner as experienced designers. Second, we decompose the
problem into two sub-task (i.e., block selection and block connection) through
the use of CoT and incontext learning techniques, to mimic the practical design
process. Third, we introduce a proofreading strategy that allows LLMs to
incrementally correct the errors in the initial design, akin to human designers
who iteratively check and adjust the initial topology design to ensure
accuracy. Finally, we construct a high-quality benchmark containing both real
data (30) and synthetic data (2k). AnalogXpert achieves 40% and 23% success
rates on the synthetic dataset and real dataset respectively, which is markedly
better than those of GPT-4o (3% on both the synthetic dataset and the real
dataset).

ÊëòË¶ÅÔºöÈ°ûÊØîÈõªË∑ØÂú®Áèæ‰ª£ÈõªÂ≠êÁ≥ªÁµ±‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåËÄåËá™ÂãïÂåñÂÖ∂Ë®≠Ë®àÂ∑≤ÂºïËµ∑ÈáçÂ§ßÁ†îÁ©∂ËààË∂£„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄã‰∏ªË¶ÅÊåëÊà∞ÊòØÊãìÊí≤ÂêàÊàêÔºåÂÆÉÊ±∫ÂÆöÈõªË∑ØÂÖÉ‰ª∂ÂèäÂÖ∂ÈÄ£Êé•„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÁî®ÊñºÊãìÊí≤ÂêàÊàêÁöÑ LLMÔºàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºâ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ†îÁ©∂ÊâÄË®éË´ñÁöÑÂ†¥ÊôØËàáÂØ¶ÈöõÊáâÁî®‰∏¶‰∏çÂ§™‰∏ÄËá¥„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÁèæÊúâÂ∑•‰Ωú‰ΩøÁî®Ê®°Á≥äÁöÑË®≠Ë®àÈúÄÊ±Ç‰ΩúÁÇ∫Ëº∏ÂÖ•‰∏¶Ëº∏Âá∫‰∏ÄÂÄãÁêÜÊÉ≥Ê®°ÂûãÔºå‰ΩÜË©≥Á¥∞ÁöÑÁµêÊßãÈúÄÊ±ÇÂíåË®≠ÂÇôÁ¥öÂà•Ê®°ÂûãÊõ¥ÂØ¶Áî®„ÄÇÊ≠§Â§ñÔºåÁï∂ÂâçÁöÑÈÄîÂæëÂ∞áÊãìÊí≤ÂêàÊàêË°®Ëø∞ÁÇ∫ÂúñÂΩ¢ÁîüÊàêÊàñ Python Á®ãÂºèÁ¢ºÁîüÊàêÔºåËÄåÂØ¶Áî®ÁöÑÊãìÊí≤Ë®≠Ë®àÊòØ‰∏ÄÂÄãË§áÈõúÁöÑÈÅéÁ®ãÔºåÈúÄË¶ÅÂª£Ê≥õÁöÑË®≠Ë®àÁü•Ë≠ò„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü AnalogXpertÔºå‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÔºåÊó®Âú®ÈÄöÈÅéÂ∞áÈõªË∑ØË®≠Ë®àÂ∞àÊ•≠Áü•Ë≠òÊï¥ÂêàÂà∞ LLM ‰∏≠‰æÜËß£Ê±∫ÂØ¶ÈöõÁöÑÊãìÊí≤ÂêàÊàêÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ∞áÈ°ûÊØîÊãìÊí≤Ë°®Á§∫ÁÇ∫ SPICE Á®ãÂºèÁ¢ºÔºå‰∏¶ÂºïÂÖ•‰∏ÄÂÄãÂ≠êÈõªË∑ØÂ∫´‰ª•Ê∏õÂ∞ëË®≠Ë®àÁ©∫ÈñìÔºåÈÄôËàáÁ∂ìÈ©óË±êÂØåÁöÑË®≠Ë®àÂ∏´ÊâÄÂÅöÁöÑ‰∏ÄÊ®£„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈÄöÈÅé‰ΩøÁî® CoT ÂíåÊÉÖÂ¢ÉÂ≠∏ÁøíÊäÄË°ìÂ∞áÂïèÈ°åÂàÜËß£ÁÇ∫ÂÖ©ÂÄãÂ≠ê‰ªªÂãôÔºàÂç≥ÔºåÂçÄÂ°äÈÅ∏ÊìáÂíåÂçÄÂ°äÈÄ£Êé•ÔºâÔºå‰ª•Ê®°Êì¨ÂØ¶ÈöõÁöÑË®≠Ë®àÈÅéÁ®ã„ÄÇÁ¨¨‰∏âÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ†°Â∞çÁ≠ñÁï•ÔºåÂÖÅË®± LLM ÈÄêÊ≠•Êõ¥Ê≠£ÂàùÂßãË®≠Ë®à‰∏≠ÁöÑÈåØË™§ÔºåÈ°û‰ººÊñº‰∫∫È°ûË®≠Ë®àÂ∏´ÂèçË¶ÜÊ™¢Êü•ÂíåË™øÊï¥ÂàùÂßãÊãìÊí≤Ë®≠Ë®à‰ª•Á¢∫‰øùÊ∫ñÁ¢∫ÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁúüÂØ¶Êï∏ÊìöÔºà30ÔºâÂíåÂêàÊàêÊï∏ÊìöÔºà2kÔºâ„ÄÇÂú®ÂêàÊàêÊï∏ÊìöÈõÜÂíåÁúüÂØ¶Êï∏ÊìöÈõÜ‰∏äÔºåAnalogXpert ÂàÜÂà•ÈÅîÂà∞‰∫Ü 40% Âíå 23% ÁöÑÊàêÂäüÁéáÔºåÈÄôÊòéÈ°ØÂÑ™Êñº GPT-4oÔºàÂú®ÂêàÊàêÊï∏ÊìöÈõÜÂíåÁúüÂØ¶Êï∏ÊìöÈõÜ‰∏äÁöÑÊàêÂäüÁéáÂùáÁÇ∫ 3%Ôºâ„ÄÇ

##### **LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**
2412.12643v1 by Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang

Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂü∫ÊñºÁîüÊàêÂºèÈ†êË®ìÁ∑¥ TransformerÔºåÂú®Áü•Ë≠òÂúñË≠úÂïèÁ≠îÔºàKGQAÔºâ‰ªªÂãô‰∏äÂ∑≤ÂèñÂæóÈ°ØËëóÁöÑÊàêÊïà„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁîüÊàêÂºèÁØÑ‰æãÂ∏∂‰æÜÁöÑÂπªË¶∫Ë°åÁÇ∫ÔºåLLM Âú® KGQA ‰∏≠Á∂ìÂ∏∏Áî¢ÁîüÁÑ°Ê†πÊìöÁöÑÂ≠êÂúñË¶èÂäÉÊàñÊé®ÁêÜÁµêÊûúÔºåÈÄôÂèØËÉΩÊúÉÈòªÁ§ôÂü∫Êñº LLM ÁöÑ KGQA Ê®°ÂûãÁöÑÈÄ≤Â±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫Êñº LLM ÁöÑÂà§Âà•Êé®ÁêÜÔºàLDRÔºâÊñπÊ≥ïÔºå‰ª•ÊòéÁ¢∫Âª∫Ê®°Â≠êÂúñÊ™¢Á¥¢ÂíåÁ≠îÊ°àÊé®Ë´ñÈÅéÁ®ã„ÄÇÈÄöÈÅéÊé°Áî®Âà§Âà•Á≠ñÁï•ÔºåÊâÄÊèêÂá∫ÁöÑ LLM ÊñπÊ≥ï‰∏çÂÉÖÂ¢ûÂº∑‰∫Ü LLM Ê™¢Á¥¢ËàáÂïèÈ°åÁõ∏ÈóúÁöÑÂ≠êÂúñÁöÑËÉΩÂäõÔºåËÄå‰∏îÈÇÑÁ∑©Ëß£‰∫Ü LLM ÁöÑÁîüÊàêÂºèÁØÑ‰æãÂ∏∂‰æÜÁöÑÁÑ°Ê†πÊìöÊé®ÁêÜÂïèÈ°å„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÑ™ÊñºÂ§öÁ®ÆÂº∑Â§ßÁöÑÊØîËºÉÊñπÊ≥ïÔºåÂêåÊôÇÂú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑ WebQSP Âíå CWQ Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**
2412.12612v1 by Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan

Cypher, the query language for Neo4j graph databases, plays a critical role
in enabling graph-based analytics and data exploration. While substantial
research has been dedicated to natural language to SQL query generation
(Text2SQL), the analogous problem for graph databases referred to as
Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a
fully synthetic and automated data generation pipeline designed to address this
gap. SynthCypher employs a novel LLMSupervised Generation-Verification
framework, ensuring syntactically and semantically correct Cypher queries
across diverse domains and query complexities. Using this pipeline, we create
SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher
instances. Fine-tuning open-source large language models (LLMs), including
LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant
performance improvements of up to 40% on the Text2Cypher test set and 30% on
the SPIDER benchmark adapted for graph databases. This work demonstrates that
high-quality synthetic data can effectively advance the state-of-the-art in
Text2Cypher tasks.

ÊëòË¶ÅÔºöCypher ÊòØ Neo4j ÂúñÂΩ¢Ë≥áÊñôÂ∫´ÁöÑÊü•Ë©¢Ë™ûË®ÄÔºåÂú®ÂïüÁî®‰ª•ÂúñÂΩ¢ÁÇ∫Âü∫Á§éÁöÑÂàÜÊûêÂíåË≥áÊñôÊé¢Á¥¢ÊñπÈù¢ÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÊäïÂÖ•Â§ßÈáèÁ†îÁ©∂Â∞áËá™ÁÑ∂Ë™ûË®ÄËΩâÊèõÁÇ∫ SQL Êü•Ë©¢ÁîüÊàê (Text2SQL)Ôºå‰ΩÜÁ®±ÁÇ∫ Text2Cypher ÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´È°ûÊØîÂïèÈ°å‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü SynthCypherÔºåÈÄôÊòØ‰∏ÄÂÄãÂÆåÂÖ®ÂêàÊàê‰∏îËá™ÂãïÂåñÁöÑË≥áÊñôÁîüÊàêÁÆ°ÈÅìÔºåÊó®Âú®Ëß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ù„ÄÇSynthCypher Êé°Áî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ LLMSupervised ÁîüÊàêÈ©óË≠âÊ°ÜÊû∂ÔºåÁ¢∫‰øù‰∫ÜË∑®Ë∂ä‰∏çÂêåÈ†òÂüüÂíåÊü•Ë©¢Ë§áÈõúÊÄßÁöÑ Cypher Êü•Ë©¢Âú®Ë™ûÊ≥ïÂíåË™ûÁæ©‰∏äÊ≠£Á¢∫„ÄÇ‰ΩøÁî®ÈÄôÂÄãÁÆ°ÈÅìÔºåÊàëÂÄëÂâµÂª∫‰∫Ü SynthCypher Ë≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 29.8k Text2Cypher ÂØ¶‰æãÁöÑÂ§ßË¶èÊ®°Âü∫Ê∫ñ„ÄÇÂæÆË™øÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂåÖÊã¨ SynthCypher ‰∏äÁöÑ LLaMa-3.1- 8B„ÄÅMistral-7B Âíå QWEN-7BÔºåÂú® Text2Cypher Ê∏¨Ë©¶ÈõÜ‰∏≠Áî¢Áîü‰∫ÜÈ´òÈÅî 40% ÁöÑÈ°ØËëóÊÄßËÉΩÊèêÂçáÔºåÂú®ÈÅ©Áî®ÊñºÂúñÂΩ¢Ë≥áÊñôÂ∫´ÁöÑ SPIDER Âü∫Ê∫ñ‰∏äÊèêÂçá‰∫Ü 30%„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúË≠âÊòé‰∫ÜÈ´òÂìÅË≥™ÁöÑÂêàÊàêË≥áÊñôÂèØ‰ª•ÊúâÊïàÂú∞Êé®Âãï Text2Cypher ‰ªªÂãôÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇ

##### **Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**
2412.15268v2 by Yibo Zhao, Jiapeng Zhu, Can Xu, Xiang Li

The rapid growth of social media platforms has raised significant concerns
regarding online content toxicity. When Large Language Models (LLMs) are used
for toxicity detection, two key challenges emerge: 1) the absence of
domain-specific toxic knowledge leads to false negatives; 2) the excessive
sensitivity of LLMs to toxic speech results in false positives, limiting
freedom of speech. To address these issues, we propose a novel method called
MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance
hatred and toxicity detection. First, we construct a comprehensive meta-toxic
knowledge graph by utilizing LLMs to extract toxic information through a
three-step pipeline, with toxic benchmark datasets serving as corpora. Second,
we query the graph via retrieval and ranking processes to supplement accurate,
relevant toxic knowledge. Extensive experiments and in-depth case studies
across multiple datasets demonstrate that our MetaTox significantly decreases
the false positive rate while boosting overall toxicity detection performance.
Our code will be available soon.

ÊëòË¶ÅÔºöÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞Âø´ÈÄüÊàêÈï∑ÔºåÂ∞çÊñºÁ∑ö‰∏äÂÖßÂÆπÊØíÊÄßÂºïÁôºÈ´òÂ∫¶ÈóúÊ≥®„ÄÇÁï∂Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî®ÊñºÊØíÊÄßÂÅµÊ∏¨ÊôÇÔºåÊúÉÂá∫ÁèæÂÖ©ÂÄã‰∏ªË¶ÅÊåëÊà∞Ôºö1) Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑÊØíÊÄßÁü•Ë≠òÔºåÂ∞éËá¥ÂÅáÈô∞ÊÄßÔºõ2) LLM Â∞çÊØíÊÄßË®ÄË´ñÈÅéÂ∫¶ÊïèÊÑüÔºåÂ∞éËá¥ÂÅáÈôΩÊÄßÔºåÈôêÂà∂Ë®ÄË´ñËá™Áî±„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ MetaTox ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®ÂúñÂΩ¢ÊêúÂ∞ãÂú®ÂÖÉÊØíÊÄßÁü•Ë≠òÂúñË≠ú‰∏äÔºå‰ª•Â¢ûÂº∑‰ªáÊÅ®ÂíåÊØíÊÄßÂÅµÊ∏¨„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈÄèÈÅé LLM Âà©Áî®‰∏âÊ≠•È©üÁÆ°Á∑öËêÉÂèñÊØíÊÄßË≥áË®äÔºåÂª∫ÊßãÂÖ®Èù¢ÁöÑÂÖÉÊØíÊÄßÁü•Ë≠òÂúñË≠úÔºå‰∏¶‰ª•ÊØíÊÄßÂü∫Ê∫ñË≥áÊñôÈõÜ‰ΩúÁÇ∫Ë™ûÊñôÂ∫´„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈÄèÈÅéÊ™¢Á¥¢ÂíåÊéíÂêçÁ®ãÂ∫èÊü•Ë©¢ÂúñÂΩ¢Ôºå‰ª•Ë£úÂÖÖÊ∫ñÁ¢∫‰∏îÁõ∏ÈóúÁöÑÊØíÊÄßÁü•Ë≠ò„ÄÇË∑®Â§öÂÄãË≥áÊñôÈõÜÁöÑÂª£Ê≥õÂØ¶È©óÂíåÊ∑±ÂÖ•Ê°à‰æãÁ†îÁ©∂È°ØÁ§∫ÔºåÊàëÂÄëÁöÑ MetaTox Â§ßÂπÖÈôç‰ΩéÂÅáÈôΩÊÄßÁéáÔºåÂêåÊôÇÊèêÂçáÊï¥È´îÊØíÊÄßÂÅµÊ∏¨ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂæàÂø´Êèê‰æõ„ÄÇ

##### **Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**
2412.12456v1 by Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang

With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóË∑®È†òÂüüÊñáÊú¨Â±¨ÊÄßÂúñ (TAG) Ë≥áÊñôÔºà‰æãÂ¶ÇÂºïÊñáÁ∂≤Ë∑Ø„ÄÅÊé®Ëñ¶Á≥ªÁµ±„ÄÅÁ§æ‰∫§Á∂≤Ë∑ØÂíå ai4scienceÔºâÁöÑÊó•ÁõäÊôÆÂèäÔºåÂ∞áÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞Áµ±‰∏ÄÁöÑÊ®°ÂûãÊû∂ÊßãÔºà‰æãÂ¶ÇÔºåLLM ‰ΩúÁÇ∫Â¢ûÂº∑Âô®„ÄÅLLM ‰ΩúÁÇ∫Âçî‰ΩúËÄÖ„ÄÅLLM ‰ΩúÁÇ∫È†êÊ∏¨Âô®Ôºâ‰∏≠Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊäÄË°ìÂÖ∏ÁØÑ„ÄÇÈÄôÁ®ÆÊñ∞ÁöÑÂúñÂΩ¢Â≠∏ÁøíÂÖ∏ÁØÑÁöÑÊ†∏ÂøÉÂú®Êñº GNN ÊçïÊçâË§áÈõúÁµêÊßãÈóú‰øÇÁöÑËÉΩÂäõËàá LLM ÂæûÂúñÂΩ¢ÁöÑË±êÂØåÊñáÂ≠óÊèèËø∞‰∏≠ÁêÜËß£Ë≥áË®äË±êÂØåËÉåÊôØÁöÑÁÜüÁ∑¥Â∫¶ÁöÑÂçîÂêåÁµÑÂêà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂèØ‰ª•Âà©Áî®ÂÖ∑ÊúâË±êÂØåË™ûÁæ©ËÉåÊôØÁöÑÂúñÂΩ¢ÊèèËø∞ÊñáÂ≠óÔºåÂæûÊ†πÊú¨‰∏äÊèêÂçáË≥áÊñôÂìÅË≥™ÔºåÂæûËÄåÊîπÂñÑ‰ª•Ê®°ÂûãÁÇ∫‰∏≠ÂøÉÁöÑÈÄîÂæëÁöÑË°®Á§∫ËÉΩÂäõÔºå‰∏¶Á¨¶Âêà‰ª•Ë≥áÊñôÁÇ∫‰∏≠ÂøÉÁöÑÊ©üÂô®Â≠∏ÁøíÂéüÂâá„ÄÇÈÄèÈÅéÂà©Áî®ÈÄô‰∫õ‰∏çÂêåÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÁöÑÂÑ™ÈªûÔºåÈÄôÁ®ÆÊï¥ÂêàÊñπÊ≥ïËß£Ê±∫‰∫ÜÂª£Ê≥õÁöÑÂü∫Êñº TAG ÁöÑ‰ªªÂãôÔºà‰æãÂ¶ÇÔºåÂúñÂΩ¢Â≠∏Áøí„ÄÅÂúñÂΩ¢Êé®ÁêÜÂíåÂúñÂΩ¢ÂïèÁ≠îÔºâÔºåÁâπÂà•ÊòØÂú®Ë§áÈõúÁöÑÁî¢Ê•≠Â†¥ÊôØÔºà‰æãÂ¶ÇÔºåÁõ£Áù£Âºè„ÄÅÂ∞ëÊ®£Êú¨ÂíåÈõ∂Ê®£Êú¨Ë®≠ÂÆöÔºâ‰∏≠„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÂèØ‰ª•Â∞áÊñáÂ≠óË¶ñÁÇ∫‰∏ÄÁ®ÆÂ™í‰ªãÔºå‰ª•ÂØ¶ÁèæÂúñÂΩ¢Â≠∏ÁøíÊ®°ÂûãÁöÑË∑®È†òÂüüÊ≥õÂåñÔºåËÆìÂñÆ‰∏ÄÂúñÂΩ¢Ê®°ÂûãËÉΩÂ§†ÊúâÊïàÂú∞ËôïÁêÜ‰∏çÂêåË≥áÊñôÈ†òÂüü‰∏≠‰∏ãÊ∏∏Âü∫ÊñºÂúñÂΩ¢ÁöÑ‰ªªÂãôÁöÑÂ§öÊ®£ÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ΩúÁÇ∫Á†îÁ©∂‰∫∫Âì°ÂíåÂØ¶ÂãôÂ∑•‰ΩúËÄÖÁöÑÂü∫Á§éÂèÉËÄÉÔºå‰ªñÂÄëÂ∏åÊúõÂú® LLM Âø´ÈÄüÊºîËÆäÁöÑÁí∞Â¢É‰∏≠Êé®ÈÄ≤ÂúñÂΩ¢Â≠∏ÁøíÊñπÊ≥ï„ÄÇÊàëÂÄëÊåÅÁ∫åÂú® \url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers} Á∂≠Ë≠∑Áõ∏ÈóúÁöÑÈñãÊîæÂéüÂßãÁ¢ºË≥áÊñô„ÄÇ</paragraph>

##### **Graph-Guided Textual Explanation Generation Framework**
2412.12318v1 by Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael F√§rber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein

Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned the faithfulness of NLEs, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations -- input fragments identified as critical
for the model's predictions -- exhibit measurable faithfulness, which has been
incrementally improved through existing research. Building on this foundation,
we propose G-Tex, a Graph-Guided Textual Explanation Generation framework
designed to enhance the faithfulness of NLEs by leveraging highlight
explanations. Specifically, highlight explanations are extracted as highly
faithful cues representing the model's reasoning and are subsequently encoded
through a graph neural network layer, which explicitly guides the NLE
generation process. This alignment ensures that the generated explanations
closely reflect the model's underlying reasoning. Experiments on T5 and BART
using three reasoning datasets show that G-Tex improves NLE faithfulness by up
to 17.59% compared to baseline methods. Additionally, G-Tex generates NLEs with
greater semantic and lexical similarity to human-written ones. Human
evaluations show that G-Tex can decrease redundant content and enhance the
overall quality of NLEs. As our work introduces a novel method for explicitly
guiding NLE generation to improve faithfulness, we hope it will serve as a
stepping stone for addressing additional criteria for NLE and generated text
overall.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËß£Èáã (NLE) Â∏∏Áî®ÊñºÊèê‰æõÊ®°ÂûãÂ∞çÂÖ∂È†êÊ∏¨ÁöÑÂêàÁêÜËß£Èáã„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë≥™Áñë NLE ÁöÑÂø†ÂØ¶Â∫¶ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØËÉΩÁÑ°Ê≥ïÊ∫ñÁ¢∫ÂèçÊò†Ê®°ÂûãÂú®ÂÖ∂È†êÊ∏¨Á≠îÊ°à‰∏äÁöÑÂÖßÈÉ®Êé®ÁêÜÈÅéÁ®ã„ÄÇÁõ∏ÂèçÔºåÈáçÈªûËß£Èáã‚Äî‚ÄîË¢´Ë≠òÂà•ÁÇ∫Â∞çÊ®°ÂûãÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶ÅÁöÑËº∏ÂÖ•ÁâáÊÆµ‚Äî‚ÄîË°®ÁèæÂá∫ÂèØË°°ÈáèÁöÑÂø†ÂØ¶Â∫¶ÔºåÈÄôÂ∑≤ÈÄöÈÅéÁèæÊúâÁ†îÁ©∂ÈÄêÊ≠•ÂæóÂà∞ÊîπÈÄ≤„ÄÇÂú®Ê≠§Âü∫Á§é‰∏äÔºåÊàëÂÄëÊèêÂá∫‰∫Ü G-TexÔºå‰∏ÄÂÄãÂúñÂΩ¢ÂºïÂ∞éÊñáÊú¨Ëß£ÈáãÁîüÊàêÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄöÈÅéÂà©Áî®ÈáçÈªûËß£Èáã‰æÜÂ¢ûÂº∑ NLE ÁöÑÂø†ÂØ¶Â∫¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈáçÈªûËß£ÈáãË¢´ÊèêÂèñÁÇ∫‰ª£Ë°®Ê®°ÂûãÊé®ÁêÜÁöÑÈ´òÂ∫¶Âø†ÂØ¶Á∑öÁ¥¢ÔºåÁÑ∂ÂæåÈÄöÈÅéÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂ±§ÈÄ≤Ë°åÁ∑®Á¢ºÔºåÈÄôÊòéÁ¢∫ÊåáÂ∞é‰∫Ü NLE ÁîüÊàêÈÅéÁ®ã„ÄÇÈÄôÁ®ÆÂ∞çÈΩäÁ¢∫‰øùÁîüÊàêÁöÑËß£ÈáãÁ∑äÂØÜÂèçÊò†Ê®°ÂûãÁöÑÂ∫ïÂ±§Êé®ÁêÜ„ÄÇ‰ΩøÁî®‰∏âÂÄãÊé®ÁêÜÊï∏ÊìöÈõÜÂ∞ç T5 Âíå BART ÈÄ≤Ë°åÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåG-Tex Â∞á NLE ÁöÑÂø†ÂØ¶Â∫¶ÊèêÈ´ò‰∫Ü 17.59%„ÄÇÊ≠§Â§ñÔºåG-Tex ÁîüÊàêÁöÑ NLE Ëàá‰∫∫È°ûÁ∑®ÂØ´ÁöÑ NLE Âú®Ë™ûÁæ©ÂíåË©ûÂΩô‰∏äÂÖ∑ÊúâÊõ¥È´òÁöÑÁõ∏‰ººÊÄß„ÄÇ‰∫∫È°ûË©ï‰º∞Ë°®ÊòéÔºåG-Tex ÂèØ‰ª•Ê∏õÂ∞ëÂÜóÈ§òÂÖßÂÆπ‰∏¶ÊèêÈ´ò NLE ÁöÑÊï¥È´îÂìÅË≥™„ÄÇÁî±ÊñºÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊòéÁ¢∫ÊåáÂ∞é NLE ÁîüÊàêÁöÑÂâµÊñ∞ÊñπÊ≥ï‰æÜÊèêÈ´òÂø†ÂØ¶Â∫¶ÔºåÊàëÂÄëÂ∏åÊúõÂÆÉÂ∞á‰ΩúÁÇ∫Ëß£Ê±∫ NLE ÂíåÊï¥È´îÁîüÊàêÊñáÊú¨ÁöÑÈôÑÂä†Ê®ôÊ∫ñÁöÑÂ¢äËÖ≥Áü≥„ÄÇ

##### **Cost-Effective Label-free Node Classification with LLMs**
2412.11983v1 by Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai

Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of "critical" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the "critical" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤ÊàêÁÇ∫ÂúñÂΩ¢Ë≥áÊñô‰∏≠ÁØÄÈªûÂàÜÈ°ûÁöÑÁÜ±ÈñÄÊ®°ÂûãÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂú®ËûçÂêàÂúñÂΩ¢ÁµêÊßãÂíåÂ±¨ÊÄßÊñπÈù¢ÂÖ∑ÊúâÂº∑Â§ßÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÊ®°ÂûãÂú®Ë®ìÁ∑¥ÊôÇÈ´òÂ∫¶‰æùË≥¥Ë∂≥Â§†ÁöÑÈ´òÂìÅË≥™Ê®ôÁ±§Ë≥áÊñôÔºåËÄåÈÄô‰∫õË≥áÊñôÂú®ÂØ¶Âãô‰∏äÂèñÂæóÁöÑÊàêÊú¨ÂæàÈ´ò„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÔºå‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÊòØÂà©Áî®ÂÖ∂ÂçìË∂äÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÂíåÊµ∑ÈáèÁü•Ë≠òÈÄ≤Ë°åÁØÄÈªûÊ®ôÁ±§„ÄÇÂÑòÁÆ°Â†±Âëä‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºå‰ΩÜÊ≠§ÊñπÊ≥ï‰∏çÊòØÈúÄË¶ÅÂ§ßÈáèÊü•Ë©¢ LLMÔºåÂ∞±ÊòØÊúÉÂõ†ÁÇ∫ LLM Áî¢ÁîüÁöÑÊ®ôÁ±§ÊúâÈõúË®äËÄåÂ∞éËá¥ÊïàËÉΩÂèóÊêç„ÄÇ
ÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨Á†îÁ©∂ÊèêÂá∫ CellaÔºå‰∏ÄÂÄã‰∏ªÂãïËá™Ë®ìÁ∑¥Êû∂ÊßãÔºå‰ª•ÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑÊñπÂºèÂ∞á LLM Êï¥ÂêàÂà∞ GNN ‰∏≠„ÄÇCella ÁöÑË®≠Ë®àÁßòË®£ÊòØ‰ΩøÁî® GNN Ëø≠‰ª£Ë≠òÂà•Â∞èÁµÑ„ÄåÈóúÈçµ„ÄçÊ®£Êú¨Ôºå‰∏¶‰ΩøÁî® LLM Âíå GNN ‰ΩúÁÇ∫È°çÂ§ñÁöÑÁõ£Áù£Ë®äËôüÔºåÁÇ∫ÈÄô‰∫õÊ®£Êú¨ËêÉÂèñÊúâÊÑèÁæ©ÁöÑÂÅΩÊ®ôÁ±§Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãË®ìÁ∑¥„ÄÇÁâπÂà•ÊòØÔºåCella ÂåÖÂê´‰∏âÂÄã‰∏ªË¶ÅÁµÑÊàêÈÉ®ÂàÜÔºö(i) ‰∏ÄÂÄãÊúâÊïàÁöÑÁØÄÈªû‰∏ªÂãïÈÅ∏ÊìáÁ≠ñÁï•ÔºåÁî®ÊñºÂàùÂßãË®ªËß£Ôºõ(ii) ‰∏ÄÂÄãÊòéÊô∫ÁöÑÊ®£Êú¨ÈÅ∏ÊìáÊñπÊ°àÔºåÊ†πÊìöÊ®ôÁ±§‰∏çÂçîË™øÊÄßÂíåÁÜµÁØ©ÈÅ∏Âá∫„ÄåÈóúÈçµ„ÄçÁØÄÈªûÔºõ‰ª•Âèä (iii) ‰∏ÄÂÄãÁµêÂêà LLM Âíå GNN ‰ª•ÂèäÈáçÊñ∞ÈÄ£Á∑öÊãìÊí≤ÁöÑÊ®ôÁ±§Á≤æÁ∑ªÊ®°ÁµÑ„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÂü∫Ê∫ñÊñáÂ≠óÂ±¨ÊÄßÂúñÂΩ¢Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÂú®Áõ∏ÂêåÁöÑ LLM Êü•Ë©¢È†êÁÆó‰∏ãÔºåCella Âú®ÁÑ°Ê®ôÁ±§ÁØÄÈªûÂàÜÈ°ûÊñπÈù¢È°ØËëóÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇÁâπÂà•ÊòØÂú®ÂÖ∑Êúâ 14.3k ÂÄãÁØÄÈªûÁöÑ DBLP Ë≥áÊñôÈõÜ‰∏äÔºåCella ËÉΩÂ§†‰ª•‰ΩéÊñº‰∏ÄÁæéÂàÜÁöÑÊàêÊú¨ÔºåÂú®Ê∫ñÁ¢∫Â∫¶‰∏äÊØîÁèæÊúâÊäÄË°ìÈ°ØËëóÊèêÂçá 8.08%„ÄÇ

##### **SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**
2412.11652v1 by Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li

Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.

ÊëòË¶ÅÔºöÊñáÊú¨Ë°®ÂæµÂ≠∏Áøí‰ΩúÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÂü∫Áü≥ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÊÑèÁæ©„ÄÇËøëÂπ¥‰æÜÔºåÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí (GCL) Âõ†ÂÖ∂Âú®Ëá™ÊàëÁõ£Áù£Ë®≠ÂÆö‰∏≠Ë°®ÂæµÂíåÊì∑ÂèñË§áÈõúÊñáÊú¨Ë≥áË®äÁöÑËÉΩÂäõÔºåËÄåË¢´Âª£Ê≥õÁî®ÊñºÊñáÊú¨Ë°®ÂæµÂ≠∏Áøí„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑ‰∏ªÊµÅÂúñÂΩ¢Â∞çÊØîÂ≠∏ÁøíÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂä†ÂÖ•È†òÂüüÁü•Ë≠òÊàñÁπÅÁë£ÁöÑÈÅãÁÆó‰æÜÂºïÂ∞éË≥áÊñôÊì¥ÂÖÖÁ®ãÂ∫èÔºåÈÄôÈ°ØËëóÂú∞ÈôêÂà∂‰∫Ü GCL ÁöÑÊáâÁî®ÊïàÁéáÂíåÁØÑÂúç„ÄÇÊ≠§Â§ñÔºåË®±Â§öÊñπÊ≥ïÂÉÖÈÄèÈÅéÂª∫ÊßãÂ≠óË©ûÊñá‰ª∂Èóú‰øÇ‰æÜÂ≠∏ÁøíÊñáÊú¨Ë°®ÂæµÔºåÈÄôÂøΩÁï•‰∫ÜÊñáÊú¨‰∏≠Ë±êÂØåÁöÑËÑàÁµ°Ë™ûÁæ©Ë≥áË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å‰∏¶ÈÅãÁî®ÂÖ∑‰ª£Ë°®ÊÄßÁöÑÊñáÊú¨Ë™ûÁæ©ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº‰∫ã‰ª∂„ÄÅÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí (SE-GCL) ‰æÜÈÄ≤Ë°åÊñáÊú¨Ë°®Âæµ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂæûÊñáÊú¨‰∏≠ËêÉÂèñ‰∫ã‰ª∂ÂçÄÂ°ä‰∏¶Âª∫ÊßãÂÖßÈÉ®Èóú‰øÇÂúñÂΩ¢‰æÜË°®ÂæµË™ûÁæ©ÈñìÁöÑÁõ∏‰∫íÈÄ£ÁµêÔºåÈÄôËÉΩÁ¢∫‰øù‰øùÁïôÊúÄÈóúÈçµÁöÑË™ûÁæ©Ë≥áË®ä„ÄÇÊé•ËëóÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁ∞°ÂåñÁöÑÁÑ°Áõ£Áù£ÂúñÂΩ¢Â∞çÊØîÂ≠∏ÁøíÊû∂ÊßãÔºå‰ª•Âà©Áî®‰∫ã‰ª∂Ë™ûÁæ©ÂíåÁµêÊßãË≥áË®äÁöÑ‰∫íË£úÁâπÊÄß‰æÜÊì∑ÂèñË§áÈõúÁöÑÁâπÂæµË≥áÊñô„ÄÇÁâπÂà•Âú∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∫ã‰ª∂È™®Êû∂ÁöÑÊ¶ÇÂøµÔºåÁî®ÊñºÊ†∏ÂøÉË°®ÂæµË™ûÁæ©Ôºå‰∏¶Á∞°ÂåñÁèæÊúâÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí‰∏≠ÈÄöÂ∏∏Ë§áÈõúÁöÑË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•ÊèêÂçáÊºîÁÆóÊ≥ïÊïàÁéá„ÄÇÊàëÂÄëÊé°Áî®Â§öÈáçÊêçÂ§±ÂáΩÊï∏‰æÜ‰øÉ‰Ωø‰∏çÂêåÁöÑÂµåÂÖ•Âú®ÂêëÈáèÁ©∫Èñì‰∏≠ÂèóÈôêË∑ùÈõ¢ÂÖßÊî∂ÊñÇÊàñÁôºÊï£ÔºåÊúÄÁµÇÈÅîÊàêÂíåË´ßÁöÑÂπ≥Ë°°„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÊ®ôÊ∫ñË≥áÊñôÈõÜ (AG News„ÄÅ20NG„ÄÅSougouNews Âíå THUCNews) ‰∏äÂ∞çÊâÄÊèêÂá∫ÁöÑ SE-GCL ÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºå‰ª•È©óË≠âÂÖ∂Âú®ÊñáÊú¨Ë°®ÂæµÂ≠∏Áøí‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**
2412.11618v1 by Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan

Current Large Language Models (LLMs) for understanding proteins primarily
treats amino acid sequences as a text modality. Meanwhile, Protein Language
Models (PLMs), such as ESM-2, have learned massive sequential evolutionary
knowledge from the universe of natural protein sequences. Furthermore,
structure-based encoders like ProteinMPNN learn the structural information of
proteins through Graph Neural Networks. However, whether the incorporation of
protein encoders can enhance the protein understanding of LLMs has not been
explored. To bridge this gap, we propose EvoLlama, a multimodal framework that
connects a structure-based encoder, a sequence-based protein encoder and an LLM
for protein understanding. EvoLlama consists of a ProteinMPNN structure
encoder, an ESM-2 protein sequence encoder, a multimodal projector to align
protein and text representations and a Llama-3 text decoder. To train EvoLlama,
we fine-tune it on protein-oriented instructions and protein property
prediction datasets verbalized via natural language instruction templates. Our
experiments show that EvoLlama's protein understanding capabilities have been
significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in
zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art
baseline with supervised fine-tuning by an average of 6%. On protein property
prediction datasets, our approach achieves promising results that are
competitive with state-of-the-art task-specific baselines. We will release our
code in a future version.

ÊëòË¶ÅÔºöÁõÆÂâçÁî®ÊñºÁêÜËß£ËõãÁôΩË≥™ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏ªË¶ÅÂ∞áËÉ∫Âü∫ÈÖ∏Â∫èÂàóË¶ñÁÇ∫ÊñáÂ≠óÂΩ¢Âºè„ÄÇÂêåÊôÇÔºåËõãÁôΩË≥™Ë™ûË®ÄÊ®°Âûã (PLM)Ôºå‰æãÂ¶Ç ESM-2ÔºåÂ∑≤ÂæûËá™ÁÑ∂ËõãÁôΩË≥™Â∫èÂàóÁöÑÂÆáÂÆô‰∏≠Â≠∏ÁøíÂà∞Â§ßÈáèÁöÑÈ†ÜÂ∫èÈÄ≤ÂåñÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÂÉè ProteinMPNN Á≠âÂü∫ÊñºÁµêÊßãÁöÑÁ∑®Á¢ºÂô®ÈÄèÈÅéÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÂ≠∏ÁøíËõãÁôΩË≥™ÁöÑÁµêÊßãË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂ∞öÊú™Êé¢Ë®éÁµêÂêàËõãÁôΩË≥™Á∑®Á¢ºÂô®ÊòØÂê¶ËÉΩÂ¢ûÂº∑ LLM Â∞çËõãÁôΩË≥™ÁöÑÁêÜËß£„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫ EvoLlamaÔºå‰∏ÄÂÄãÂ§öÊ®°ÊÖãÊû∂ÊßãÔºåÂÆÉÁµêÂêà‰∏ÄÂÄãÂü∫ÊñºÁµêÊßãÁöÑÁ∑®Á¢ºÂô®„ÄÅ‰∏ÄÂÄãÂü∫ÊñºÂ∫èÂàóÁöÑËõãÁôΩË≥™Á∑®Á¢ºÂô®Âíå‰∏ÄÂÄãÁî®ÊñºÁêÜËß£ËõãÁôΩË≥™ÁöÑ LLM„ÄÇEvoLlama ÂåÖÂê´‰∏ÄÂÄã ProteinMPNN ÁµêÊßãÁ∑®Á¢ºÂô®„ÄÅ‰∏ÄÂÄã ESM-2 ËõãÁôΩË≥™Â∫èÂàóÁ∑®Á¢ºÂô®„ÄÅ‰∏ÄÂÄãÂ§öÊ®°ÊÖãÊäïÂΩ±Âô®ÔºåÁî®ÊñºÂ∞çÈΩäËõãÁôΩË≥™ÂíåÊñáÂ≠óË°®ÂæµÔºå‰ª•Âèä‰∏ÄÂÄã Llama-3 ÊñáÂ≠óËß£Á¢ºÂô®„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥ EvoLlamaÔºåÊàëÂÄëÈáùÂ∞çËõãÁôΩË≥™Â∞éÂêëÁöÑÊåá‰ª§ÂíåÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§ÁØÑÊú¨Ë°®ÈÅîÁöÑËõãÁôΩË≥™Â±¨ÊÄßÈ†êÊ∏¨Ë≥áÊñôÈõÜÂæÆË™øÂÆÉ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåEvoLlama ÁöÑËõãÁôΩË≥™ÁêÜËß£ËÉΩÂäõÂ∑≤Áç≤ÂæóÈ°ØËëóÊèêÂçáÔºåÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠ÔºåÂπ≥ÂùáÂÑ™ÊñºÂÖ∂‰ªñÂæÆË™øÁöÑËõãÁôΩË≥™Â∞éÂêë LLM 1%-8%Ôºå‰∏¶Âú®ÊúâÁõ£Áù£ÁöÑÂæÆË™ø‰∏≠Âπ≥ÂùáÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ 6%„ÄÇÂú®ËõãÁôΩË≥™Â±¨ÊÄßÈ†êÊ∏¨Ë≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÂà∞‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÁâπÂÆö‰ªªÂãôÂü∫Ê∫ñÁõ∏Áï∂„ÄÇÊàëÂÄëÂ∞áÂú®Êú™‰æÜÁâàÊú¨‰∏≠ÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Embodied CoT Distillation From LLM To Off-the-shelf Agents**
2412.11499v1 by Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo

We address the challenge of utilizing large language models (LLMs) for
complex embodied tasks, in the environment where decision-making systems
operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a
framework for decomposing and distilling the embodied reasoning capabilities
from LLMs to efficient, small language model (sLM)-based policies. In DeDer,
the decision-making process of LLM-based strategies is restructured into a
hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is
distilled from the data that is generated through the embodied in-context
learning and self-verification of an LLM, so it can produce effective
rationales. The planning-policy, guided by the rationales, can render optimized
plans efficiently. In turn, DeDer allows for adopting sLMs for both policies,
deployed on off-the-shelf devices. Furthermore, to enhance the quality of
intermediate rationales, specific to embodied tasks, we devise the embodied
knowledge graph, and to generate multiple rationales timely through a single
inference, we also use the contrastively prompted attention model. Our
experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading
language planning and distillation approaches, indicating the applicability and
efficiency of sLM-based embodied policies derived through DeDer.

ÊëòË¶ÅÔºöÊàëÂÄëËß£Ê±∫‰∫ÜÂú®Ê±∫Á≠ñÁ≥ªÁµ±ÊñºÂÆπÈáèÊúâÈôêÁöÑÁèæÊàêË®≠ÂÇô‰∏äÂç≥ÊôÇÈÅã‰ΩúÁöÑÁí∞Â¢É‰∏≠ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âü∑Ë°åË§áÈõúÂÖ∑Ë∫´‰ªªÂãôÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫ DeDerÔºå‰∏ÄÂÄãÁî®ÊñºÂ∞áÂÖ∑Ë∫´Êé®ÁêÜËÉΩÂäõÂæû LLM ÂàÜËß£‰∏¶ËêÉÂèñÂá∫È´òÊïàËÉΩ„ÄÅÂ∞èÂûãË™ûË®ÄÊ®°Âûã (sLM) ÁÇ∫Âü∫Á§éÁöÑÊîøÁ≠ñÁöÑÊ°ÜÊû∂„ÄÇÂú® DeDer ‰∏≠ÔºåÂü∫Êñº LLM ÁöÑÁ≠ñÁï•ÁöÑÊ±∫Á≠ñÊµÅÁ®ãË¢´ÈáçÊñ∞ÁµêÊßãÁÇ∫‰∏ÄÂÄãÂÖ∑ÊúâÊé®ÁêÜÊîøÁ≠ñÂíåË¶èÂäÉÊîøÁ≠ñÁöÑÈöéÂ±§„ÄÇÊé®ÁêÜÊîøÁ≠ñÂæûÈÄèÈÅé LLM ÁöÑÂÖ∑Ë∫´ÊÉÖÂ¢ÉÂ≠∏ÁøíÂíåËá™ÊàëÈ©óË≠âÊâÄÁî¢ÁîüÁöÑË≥áÊñô‰∏≠ËêÉÂèñÂá∫ÔºåÂõ†Ê≠§ÂÆÉÂèØ‰ª•Áî¢ÁîüÊúâÊïàÁöÑ‰æùÊìö„ÄÇË¶èÂäÉÊîøÁ≠ñÂú®‰æùÊìöÁöÑÂºïÂ∞é‰∏ãÔºåÂèØ‰ª•ÊúâÊïàÁéáÂú∞ÂëàÁèæÊúÄ‰Ω≥ÂåñÁöÑË®àÁï´„ÄÇÂèçÈÅé‰æÜÔºåDeDer ÂÖÅË®±Êé°Áî® sLM ‰æÜÂü∑Ë°åÈÄôÂÖ©ÂÄãÊîøÁ≠ñÔºå‰∏¶ÈÉ®ÁΩ≤Âú®ÁèæÊàêË®≠ÂÇô‰∏ä„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÊèêÂçá‰∏≠Èñì‰æùÊìöÁöÑÂìÅË≥™ÔºåÁâπÂà•ÊòØÈáùÂ∞çÂÖ∑Ë∫´‰ªªÂãôÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂÖ∑Ë∫´Áü•Ë≠òÂúñË≠úÔºå‰∏¶ÈÄèÈÅéÂñÆ‰∏ÄÊé®Ë´ñÂç≥ÊôÇÁî¢ÁîüÂ§öÂÄã‰æùÊìöÔºåÊàëÂÄë‰πü‰ΩøÁî®‰∫ÜÂ∞çÊØîÊèêÁ§∫Ê≥®ÊÑèÂäõÊ®°Âûã„ÄÇÊàëÂÄë‰ΩøÁî® ALFRED Âü∫Ê∫ñÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºåDeDer Ë∂ÖË∂ä‰∫ÜÈ†òÂÖàÁöÑË™ûË®ÄË¶èÂäÉÂíåËêÉÂèñÊñπÊ≥ïÔºåÈÄôË°®Á§∫ÈÄèÈÅé DeDer Ë°çÁîüÁöÑÂü∫Êñº sLM ÁöÑÂÖ∑Ë∫´ÊîøÁ≠ñÂÖ∑ÊúâÈÅ©Áî®ÊÄßÂíåÊïàÁéá„ÄÇ


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-15**|**How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**|Tosin Fadahunsi et.al.|[2501.09014v1](http://arxiv.org/abs/2501.09014v1)|[link](https://github.com/giordanodaloisio/sd-bias)|
|**2025-01-15**|**Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**|Ruixiang Jiang et.al.|[2501.09012v1](http://arxiv.org/abs/2501.09012v1)|[link](https://github.com/songrise/mllm4art)|
|**2025-01-15**|**Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**|Shaona Ghosh et.al.|[2501.09004v1](http://arxiv.org/abs/2501.09004v1)|null|
|**2025-01-15**|**Personality Modeling for Persuasion of Misinformation using AI Agent**|Qianmin Lou et.al.|[2501.08985v1](http://arxiv.org/abs/2501.08985v1)|null|
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v1](http://arxiv.org/abs/2501.08977v1)|null|
|**2025-01-15**|**Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models**|Karukriti Kaushik Ghosh et.al.|[2501.08974v1](http://arxiv.org/abs/2501.08974v1)|null|
|**2025-01-15**|**Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography**|Ilia Shumailov et.al.|[2501.08970v1](http://arxiv.org/abs/2501.08970v1)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Kolmogorov-Arnold Networks for Time Series Granger Causality Inference**|Meiliang Liu et.al.|[2501.08958v1](http://arxiv.org/abs/2501.08958v1)|null|
|**2025-01-15**|**Analyzing the Ethical Logic of Six Large Language Models**|W. Russell Neuman et.al.|[2501.08951v1](http://arxiv.org/abs/2501.08951v1)|null|
|**2025-01-15**|**Applying General Turn-taking Models to Conversational Human-Robot Interaction**|Gabriel Skantze et.al.|[2501.08946v1](http://arxiv.org/abs/2501.08946v1)|null|
|**2025-01-15**|**Visual WetlandBirds Dataset: Bird Species Identification and Behavior Recognition in Videos**|Javier Rodriguez-Juan et.al.|[2501.08931v1](http://arxiv.org/abs/2501.08931v1)|[link](https://github.com/3dperceptionlab/visual-wetlandbirds)|
|**2025-01-15**|**Disentangling Exploration of Large Language Models by Optimal Exploitation**|Tim Grams et.al.|[2501.08925v1](http://arxiv.org/abs/2501.08925v1)|null|
|**2025-01-15**|**Modeling Melt Pool Features and Spatter Using Symbolic Regression and Machine Learning**|Olabode T. Ajenifujah et.al.|[2501.08922v1](http://arxiv.org/abs/2501.08922v1)|null|
|**2025-01-15**|**GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text Detection Challenge**|Liam Dugan et.al.|[2501.08913v1](http://arxiv.org/abs/2501.08913v1)|null|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|null|
|**2025-01-15**|**Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model**|Runqing Wu et.al.|[2501.08878v1](http://arxiv.org/abs/2501.08878v1)|null|
|**2025-01-15**|**Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts**|Antonio Castellanos et.al.|[2501.08869v1](http://arxiv.org/abs/2501.08869v1)|null|
|**2025-01-15**|**ARMOR: Shielding Unlearnable Examples against Data Augmentation**|Xueluan Gong et.al.|[2501.08862v1](http://arxiv.org/abs/2501.08862v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-15**|**Graph Counterfactual Explainable AI via Latent Space Traversal**|Andreas Abildtrup Hansen et.al.|[2501.08850v1](http://arxiv.org/abs/2501.08850v1)|null|
|**2025-01-15**|**RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning**|Carlos G√ºemes-Palau et.al.|[2501.08848v1](http://arxiv.org/abs/2501.08848v1)|null|
|**2025-01-15**|**Exploring Task-Level Optimal Prompts for Visual In-Context Learning**|Yan Zhu et.al.|[2501.08841v1](http://arxiv.org/abs/2501.08841v1)|null|
|**2025-01-15**|**ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind**|Kazutoshi Shinoda et.al.|[2501.08838v1](http://arxiv.org/abs/2501.08838v1)|[link](https://github.com/nttmdlab-nlp/ToMATO)|
|**2025-01-15**|**IDEA: Image Description Enhanced CLIP-Adapter**|Zhipeng Ye et.al.|[2501.08816v1](http://arxiv.org/abs/2501.08816v1)|null|
|**2025-01-15**|**How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering**|Christoph Treude et.al.|[2501.08774v1](http://arxiv.org/abs/2501.08774v1)|null|
|**2025-01-15**|**Enhanced Large Language Models for Effective Screening of Depression and Anxiety**|June M. Liu et.al.|[2501.08769v1](http://arxiv.org/abs/2501.08769v1)|null|
|**2025-01-15**|**Leveraging LLM Agents for Translating Network Configurations**|Yunze Wei et.al.|[2501.08760v1](http://arxiv.org/abs/2501.08760v1)|null|
|**2025-01-15**|**Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese Sentiment Analysis Models**|Hong-Viet Tran et.al.|[2501.08758v1](http://arxiv.org/abs/2501.08758v1)|null|
|**2025-01-15**|**The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities**|Irina Bigoulaeva et.al.|[2501.08716v1](http://arxiv.org/abs/2501.08716v1)|[link](https://github.com/ukplab/arxiv2025-inherent-limits-plms)|
|**2025-01-15**|**Self-supervised Transformation Learning for Equivariant Representations**|Jaemyung Yu et.al.|[2501.08712v1](http://arxiv.org/abs/2501.08712v1)|[link](https://github.com/jaemyung-u/stl)|
|**2025-01-15**|**Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk Differentiation in Chinese Psychological Support Hotlines**|Han Wang et.al.|[2501.08696v1](http://arxiv.org/abs/2501.08696v1)|[link](https://github.com/sco-field/speechemotionrecognition)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|null|
|**2025-01-15**|**Application of Deep Reinforcement Learning to UAV Swarming for Ground Surveillance**|Ra√∫l Arranz et.al.|[2501.08655v1](http://arxiv.org/abs/2501.08655v1)|null|
|**2025-01-15**|**Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor Graph**|Wang-Tao Zhou et.al.|[2501.08653v1](http://arxiv.org/abs/2501.08653v1)|null|
|**2025-01-15**|**MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities**|Savya Khosla et.al.|[2501.08648v1](http://arxiv.org/abs/2501.08648v1)|null|
|**2025-01-15**|**Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations**|Kaiyuan Zheng et.al.|[2501.08641v1](http://arxiv.org/abs/2501.08641v1)|null|
|**2025-01-15**|**SWSC: Shared Weight for Similar Channel in LLM**|Binrui Zeng et.al.|[2501.08631v1](http://arxiv.org/abs/2501.08631v1)|null|
|**2025-01-15**|**ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair**|Hong-Viet Tran et.al.|[2501.08621v1](http://arxiv.org/abs/2501.08621v1)|null|
|**2025-01-15**|**Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models**|Aruna Sankaranarayanan et.al.|[2501.08618v1](http://arxiv.org/abs/2501.08618v1)|[link](https://github.com/arunasank/disjoint-processing-llms)|
|**2025-01-15**|**RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation**|Kaiqu Liang et.al.|[2501.08617v1](http://arxiv.org/abs/2501.08617v1)|null|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v1](http://arxiv.org/abs/2501.08613v1)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design**|Zhi Zheng et.al.|[2501.08603v1](http://arxiv.org/abs/2501.08603v1)|[link](https://github.com/zz1358m/mcts-ahd-master)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LlamaRestTest: Effective REST API Testing with Small Language Models**|Myeongsoo Kim et.al.|[2501.08598v1](http://arxiv.org/abs/2501.08598v1)|null|
|**2025-01-15**|**Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning**|Julian Perry et.al.|[2501.08597v1](http://arxiv.org/abs/2501.08597v1)|null|
|**2025-01-15**|**OpenMLDB: A Real-Time Relational Data Feature Computation System for Online ML**|Xuanhe Zhou et.al.|[2501.08591v1](http://arxiv.org/abs/2501.08591v1)|null|
|**2025-01-15**|**Sound Scene Synthesis at the DCASE 2024 Challenge**|Mathieu Lagrange et.al.|[2501.08587v1](http://arxiv.org/abs/2501.08587v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-15**|**What Limits LLM-based Human Simulation: LLMs or Our Design?**|Qian Wang et.al.|[2501.08579v1](http://arxiv.org/abs/2501.08579v1)|null|
|**2025-01-15**|**Information Entropy Invariance: Enhancing Length Extrapolation in Attention Mechanisms**|Kewei Li et.al.|[2501.08570v1](http://arxiv.org/abs/2501.08570v1)|null|
|**2025-01-15**|**Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement**|Qianniu Chen et.al.|[2501.08566v1](http://arxiv.org/abs/2501.08566v1)|null|
|**2025-01-15**|**ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins**|Safayat Bin Hakim et.al.|[2501.08561v1](http://arxiv.org/abs/2501.08561v1)|[link](https://github.com/sbhakim/ansr-dt)|
|**2025-01-15**|**LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation**|Yiran Tao et.al.|[2501.08558v1](http://arxiv.org/abs/2501.08558v1)|null|
|**2025-01-15**|**The Devil is in Temporal Token: High Quality Video Reasoning Segmentation**|Sitong Gong et.al.|[2501.08549v1](http://arxiv.org/abs/2501.08549v1)|null|
|**2025-01-15**|**Knowledge prompt chaining for semantic modeling**|Ning Pei Ding et.al.|[2501.08540v1](http://arxiv.org/abs/2501.08540v1)|[link](https://github.com/dingningpei/llm_semantics)|
|**2025-01-15**|**Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers**|Zhongwang Zhang et.al.|[2501.08537v1](http://arxiv.org/abs/2501.08537v1)|[link](https://github.com/sjtuzzw/complexity_control)|
|**2025-01-15**|**Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy**|Runsheng Lin et.al.|[2501.08528v1](http://arxiv.org/abs/2501.08528v1)|null|
|**2025-01-15**|**Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation**|Jiaxin Guo et.al.|[2501.08523v1](http://arxiv.org/abs/2501.08523v1)|null|
|**2025-01-15**|**Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes**|Huy Q. Le et.al.|[2501.08521v1](http://arxiv.org/abs/2501.08521v1)|null|
|**2025-01-15**|**Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training**|Kavita Selva et.al.|[2501.08506v1](http://arxiv.org/abs/2501.08506v1)|null|
|**2025-01-15**|**Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom**|Melissa Torgbi et.al.|[2501.08502v1](http://arxiv.org/abs/2501.08502v1)|null|
|**2025-01-14**|**Quantifying the Importance of Data Alignment in Downstream Model Performance**|Krrish Chawla et.al.|[2501.08496v1](http://arxiv.org/abs/2501.08496v1)|null|
|**2025-01-14**|**Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition**|Md Meem Hossain et.al.|[2501.08471v1](http://arxiv.org/abs/2501.08471v1)|null|
|**2025-01-14**|**Detecting Contextual Anomalies by Discovering Consistent Spatial Regions**|Zhengye Yang et.al.|[2501.08470v1](http://arxiv.org/abs/2501.08470v1)|null|
|**2025-01-14**|**Selective Attention Merging for low resource tasks: A case study of Child ASR**|Natarajan Balaji Shankar et.al.|[2501.08468v1](http://arxiv.org/abs/2501.08468v1)|[link](https://github.com/balaji1312/sa_merging)|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**Large Language Models For Text Classification: Case Study And Comprehensive Review**|Arina Kostina et.al.|[2501.08457v1](http://arxiv.org/abs/2501.08457v1)|null|
|**2025-01-14**|**Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack**|Sagiv Antebi et.al.|[2501.08454v1](http://arxiv.org/abs/2501.08454v1)|null|
|**2025-01-14**|**Active Sampling for Node Attribute Completion on Graphs**|Benyuan Liu et.al.|[2501.08450v1](http://arxiv.org/abs/2501.08450v1)|null|
|**2025-01-14**|**Jochre 3 and the Yiddish OCR corpus**|Assaf Urieli et.al.|[2501.08442v1](http://arxiv.org/abs/2501.08442v1)|null|
|**2025-01-14**|**Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies**|Ajwad Abrar et.al.|[2501.08441v1](http://arxiv.org/abs/2501.08441v1)|null|
|**2025-01-14**|**Modeling Discrimination with Causal Abstraction**|Milan Moss√© et.al.|[2501.08429v1](http://arxiv.org/abs/2501.08429v1)|null|
|**2025-01-14**|**Causal vs. Anticausal merging of predictors**|Sergio Hernan Garrido Mejia et.al.|[2501.08426v1](http://arxiv.org/abs/2501.08426v1)|null|
|**2025-01-14**|**SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models**|Anurag Kumar et.al.|[2501.08421v1](http://arxiv.org/abs/2501.08421v1)|null|
|**2025-01-14**|**CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks**|Zijiang Yan et.al.|[2501.08418v1](http://arxiv.org/abs/2501.08418v1)|null|
|**2025-01-14**|**Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics**|Georgii Gotin et.al.|[2501.08415v1](http://arxiv.org/abs/2501.08415v1)|null|
|**2025-01-14**|**Ensemble of Large Language Models for Curated Labeling and Rating of Free-text Data**|Jiaxing Qiu et.al.|[2501.08413v1](http://arxiv.org/abs/2501.08413v1)|null|
|**2025-01-14**|**OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**|Hao Chen et.al.|[2501.08406v1](http://arxiv.org/abs/2501.08406v1)|[link](https://github.com/li-group/optichat)|
|**2025-01-14**|**Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge**|Santiago del Rey et.al.|[2501.08402v1](http://arxiv.org/abs/2501.08402v1)|null|
|**2025-01-14**|**PokerBench: Training Large Language Models to become Professional Poker Players**|Richard Zhuang et.al.|[2501.08328v1](http://arxiv.org/abs/2501.08328v1)|[link](https://github.com/pokerllm/pokerbench)|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**|Amirhossein Aliakbarzadeh et.al.|[2501.08322v1](http://arxiv.org/abs/2501.08322v1)|[link](https://github.com/caisa-lab/llms-real-world-noise-robustness)|
|**2025-01-14**|**Enhancing Automated Interpretability with Output-Centric Feature Descriptions**|Yoav Gur-Arieh et.al.|[2501.08319v1](http://arxiv.org/abs/2501.08319v1)|[link](https://github.com/yoavgur/feature-descriptions)|
|**2025-01-14**|**Diffusion Adversarial Post-Training for One-Step Video Generation**|Shanchuan Lin et.al.|[2501.08316v1](http://arxiv.org/abs/2501.08316v1)|null|
|**2025-01-14**|**MiniMax-01: Scaling Foundation Models with Lightning Attention**|MiniMax et.al.|[2501.08313v1](http://arxiv.org/abs/2501.08313v1)|null|
|**2025-01-14**|**Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**|Al≈æbƒõta Kuƒçerov√° et.al.|[2501.08312v1](http://arxiv.org/abs/2501.08312v1)|[link](https://github.com/calc-project/object-naming-data)|
|**2025-01-14**|**Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**|Karine Chubarian et.al.|[2501.08297v1](http://arxiv.org/abs/2501.08297v1)|null|
|**2025-01-14**|**HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**|Abhilasha Ravichander et.al.|[2501.08292v1](http://arxiv.org/abs/2501.08292v1)|null|
|**2025-01-14**|**AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**|Shamsuddeen Hassan Muhammad et.al.|[2501.08284v2](http://arxiv.org/abs/2501.08284v2)|[link](https://github.com/afrihate/afrihate)|
|**2025-01-14**|**Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**|Pulkit Arora et.al.|[2501.08276v1](http://arxiv.org/abs/2501.08276v1)|null|
|**2025-01-14**|**Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**|Saad Mashkoor Siddiqui et.al.|[2501.08271v1](http://arxiv.org/abs/2501.08271v1)|null|
|**2025-01-14**|**AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**|Sanjida Afrin Mou et.al.|[2501.08266v1](http://arxiv.org/abs/2501.08266v1)|[link](https://github.com/SanjidaAfrin25/flood-detection-using-deepLab-unet-resnet)|
|**2025-01-14**|**Towards Best Practices for Open Datasets for LLM Training**|Stefan Baack et.al.|[2501.08365v1](http://arxiv.org/abs/2501.08365v1)|null|
|**2025-01-14**|**Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**|Yifu Qiu et.al.|[2501.08248v1](http://arxiv.org/abs/2501.08248v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**|Enrique Adrian Villarrubia-Martin et.al.|[2501.08234v1](http://arxiv.org/abs/2501.08234v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Modeling Feature Maps for Quantum Machine Learning**|Navneet Singh et.al.|[2501.08205v1](http://arxiv.org/abs/2501.08205v1)|null|
|**2025-01-14**|**ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**|Zain Ul Abedin et.al.|[2501.08203v1](http://arxiv.org/abs/2501.08203v1)|null|

#### Abstracts
##### **How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**
2501.09014v1 by Tosin Fadahunsi, Giordano d'Aloisio, Antinisca Di Marco, Federica Sarro

Generative models are nowadays widely used to generate graphical content used
for multiple purposes, e.g. web, art, advertisement. However, it has been shown
that the images generated by these models could reinforce societal biases
already existing in specific contexts. In this paper, we focus on understanding
if this is the case when one generates images related to various software
engineering tasks. In fact, the Software Engineering (SE) community is not
immune from gender and ethnicity disparities, which could be amplified by the
use of these models. Hence, if used without consciousness, artificially
generated images could reinforce these biases in the SE domain. Specifically,
we perform an extensive empirical evaluation of the gender and ethnicity bias
exposed by three versions of the Stable Diffusion (SD) model (a very popular
open-source text-to-image model) - SD 2, SD XL, and SD 3 - towards SE tasks. We
obtain 6,720 images by feeding each model with two sets of prompts describing
different software-related tasks: one set includes the Software Engineer
keyword, and one set does not include any specification of the person
performing the task. Next, we evaluate the gender and ethnicity disparities in
the generated images. Results show how all models are significantly biased
towards male figures when representing software engineers. On the contrary,
while SD 2 and SD XL are strongly biased towards White figures, SD 3 is
slightly more biased towards Asian figures. Nevertheless, all models
significantly under-represent Black and Arab figures, regardless of the prompt
style used. The results of our analysis highlight severe concerns about
adopting those models to generate content for SE tasks and open the field for
future research on bias mitigation in this context.

ÊëòË¶ÅÔºöÁîüÊàêÊ®°ÂûãÁèæ‰ªäÂª£Ê≥õÁî®ÊñºÁî¢ÁîüÂúñÂΩ¢ÂÖßÂÆπÔºåÁî®ÊñºÂ§öÁ®ÆÁõÆÁöÑÔºå‰æãÂ¶ÇÁ∂≤Ë∑Ø„ÄÅËóùË°ì„ÄÅÂª£Âëä„ÄÇÁÑ∂ËÄåÔºåÂ∑≤È°ØÁ§∫Áî±ÈÄô‰∫õÊ®°ÂûãÁî¢ÁîüÁöÑÂΩ±ÂÉèÂèØËÉΩÂº∑ÂåñÁâπÂÆöÊÉÖÂ¢É‰∏≠Â∑≤Â≠òÂú®ÁöÑÁ§æÊúÉÂÅèË¶ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®Êñº‰∫ÜËß£Âú®Áî¢ÁîüËàáÂêÑÁ®ÆËªüÈ´îÂ∑•Á®ã‰ªªÂãôÁõ∏ÈóúÁöÑÂΩ±ÂÉèÊôÇÊòØÂê¶Â¶ÇÊ≠§„ÄÇ‰∫ãÂØ¶‰∏äÔºåËªüÈ´îÂ∑•Á®ã (SE) Á§æÁæ§‰∏¶Èùû‰∏çÂèóÊÄßÂà•ÂíåÁ®ÆÊóèÂ∑ÆÁï∞ÂΩ±ÈüøÔºåËÄåÈÄô‰∫õÂ∑ÆÁï∞ÂèØËÉΩÊúÉÂõ†‰ΩøÁî®ÈÄô‰∫õÊ®°ÂûãËÄåÊì¥Â§ß„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúÂú®Ê≤íÊúâÊÑèË≠òÁöÑÊÉÖÊ≥Å‰∏ã‰ΩøÁî®Ôºå‰∫∫Â∑•Áî¢ÁîüÁöÑÂΩ±ÂÉèÂèØËÉΩÊúÉÂº∑Âåñ SE È†òÂüü‰∏≠ÁöÑÈÄô‰∫õÂÅèË¶ã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞ç Stable Diffusion (SD) Ê®°ÂûãÔºà‰∏ÄÂÄãÈùûÂ∏∏ÊµÅË°åÁöÑÈñãÊ∫êÊñáÂ≠óËΩâÂΩ±ÂÉèÊ®°ÂûãÔºâÁöÑ‰∏âÂÄãÁâàÊú¨ÔºàSD 2„ÄÅSD XL Âíå SD 3ÔºâÂ∞ç SE ‰ªªÂãôÊâÄÊè≠Èú≤ÁöÑÊÄßÂà•ÂíåÁ®ÆÊóèÂÅèË¶ãÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶Ë≠âË©ï‰º∞„ÄÇÊàëÂÄëÈÄèÈÅéÊèê‰æõÂÖ©ÁµÑÊèèËø∞‰∏çÂêåËªüÈ´îÁõ∏Èóú‰ªªÂãôÁöÑÊèêÁ§∫Áµ¶ÂêÑÂÄãÊ®°ÂûãÔºåÂèñÂæó 6,720 ÂºµÂΩ±ÂÉèÔºö‰∏ÄÁµÑÂåÖÂê´ËªüÈ´îÂ∑•Á®ãÂ∏´ÈóúÈçµÂ≠óÔºåÂè¶‰∏ÄÁµÑÂâá‰∏çÂåÖÂê´Âü∑Ë°å‰ªªÂãôÁöÑ‰∫∫Âì°ÁöÑ‰ªª‰ΩïË™™Êòé„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëË©ï‰º∞Áî¢ÁîüÂΩ±ÂÉè‰∏≠ÁöÑÊÄßÂà•ÂíåÁ®ÆÊóèÂ∑ÆÁï∞„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊâÄÊúâÊ®°ÂûãÂú®‰ª£Ë°®ËªüÈ´îÂ∑•Á®ãÂ∏´ÊôÇÈÉΩÈ°ØËëóÂÅèÂêëÁî∑ÊÄßËßíËâ≤„ÄÇÁõ∏ÂèçÂú∞ÔºåSD 2 Âíå SD XL ÈõñÁÑ∂Âº∑ÁÉàÂÅèÂêëÁôΩ‰∫∫ËßíËâ≤Ôºå‰ΩÜ SD 3 Á®çÂæÆÊõ¥ÂÅèÂêë‰∫ûÊ¥≤ËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÊâÄÊúâÊ®°ÂûãÈÉΩÈ°ØËëó‰Ωé‰º∞‰∫ÜÈªë‰∫∫ÂíåÈòøÊãâ‰ºØ‰∫∫ÁöÑËßíËâ≤ÔºåÁÑ°Ë´ñ‰ΩøÁî®Âì™Á®ÆÊèêÁ§∫Ê®£Âºè„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÊé°Áî®ÈÄô‰∫õÊ®°Âûã‰æÜÁî¢Áîü SE ‰ªªÂãôÂÖßÂÆπÁöÑÂö¥ÈáçÁñëÊÖÆÔºå‰∏¶ÁÇ∫Êú™‰æÜÂú®ÈÄôÂÄãÊÉÖÂ¢É‰∏≠Ê∏õËºïÂÅèË¶ãÁöÑÁ†îÁ©∂ÈñãÂïü‰∫ÜÈ†òÂüü„ÄÇ

##### **Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**
2501.09012v1 by Ruixiang Jiang, Changwen Chen

We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability
shall be elicited to evaluate the aesthetics of artworks. To facilitate this
investigation, we construct MM-StyleBench, a novel high-quality dataset for
benchmarking artistic stylization. We then develop a principled method for
human preference modeling and perform a systematic correlation analysis between
MLLMs' responses and human preference. Our experiments reveal an inherent
hallucination issue of MLLMs in art evaluation, associated with response
subjectivity. ArtCoT is proposed, demonstrating that art-specific task
decomposition and the use of concrete language boost MLLMs' reasoning ability
for aesthetics. Our findings offer valuable insights into MLLMs for art and can
benefit a wide range of downstream applications, such as style transfer and
artistic image generation. Code available at
https://github.com/songrise/MLLM4Art.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÈóúÊñºÂ¶Ç‰ΩïÂºïÁôºÂ§öÊ®°ÊÖã LLM (MLLM) Êé®ÁêÜËÉΩÂäõÁöÑÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ËóùË°ìÂìÅÁöÑÁæéÊÑü„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄôÈ†ÖË™øÊü•ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü MM-StyleBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÂü∫Ê∫ñÂåñËóùË°ìÈ¢®Ê†ºÂåñÁöÑÂÖ®Êñ∞È´òÂìÅË≥™Ë≥áÊñôÈõÜ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂéüÂâáÁöÑÊñπÊ≥ïÈÄ≤Ë°å‰∫∫È°ûÂÅèÂ•ΩÂª∫Ê®°Ôºå‰∏¶Âú® MLLM ÁöÑÂõûÊáâÂíå‰∫∫È°ûÂÅèÂ•Ω‰πãÈñìÂü∑Ë°åÁ≥ªÁµ±ÊÄßÁöÑÁõ∏ÈóúÊÄßÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü MLLM Âú®ËóùË°ìË©ï‰º∞‰∏≠Âõ∫ÊúâÁöÑÂπªË¶∫ÂïèÈ°åÔºåËàáÂõûÊáâÁöÑ‰∏ªËßÄÊÄßÊúâÈóú„ÄÇArtCoT Ë¢´ÊèêÂá∫ÔºåË≠âÊòéÁâπÂÆöÊñºËóùË°ìÁöÑ‰ªªÂãôÂàÜËß£ÂíåÂÖ∑È´îË™ûË®ÄÁöÑ‰ΩøÁî®ÊèêÂçá‰∫Ü MLLM Â∞çÁæéÂ≠∏ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁÇ∫ MLLM Âú®ËóùË°ìÈ†òÂüüÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£Ôºå‰∏¶ÂèØ‰ª•‰ΩøÂª£Ê≥õÁöÑ‰∏ãÊ∏∏ÊáâÁî®ÂèóÁõäÔºå‰æãÂ¶ÇÈ¢®Ê†ºËΩâÁßªÂíåËóùË°ìÂúñÂÉèÁîüÊàê„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/songrise/MLLM4Art ÂèñÂæó„ÄÇ

##### **Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**
2501.09004v1 by Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin Rajan Varghese, Christopher Parisien

As Large Language Models (LLMs) and generative AI become increasingly
widespread, concerns about content safety have grown in parallel. Currently,
there is a clear lack of high-quality, human-annotated datasets that address
the full spectrum of LLM-related safety risks and are usable for commercial
applications. To bridge this gap, we propose a comprehensive and adaptable
taxonomy for categorizing safety risks, structured into 12 top-level hazard
categories with an extension to 9 fine-grained subcategories. This taxonomy is
designed to meet the diverse requirements of downstream users, offering more
granular and flexible tools for managing various risk types. Using a hybrid
data generation pipeline that combines human annotations with a multi-LLM
"jury" system to assess the safety of responses, we obtain Aegis 2.0, a
carefully curated collection of 34,248 samples of human-LLM interactions,
annotated according to our proposed taxonomy. To validate its effectiveness, we
demonstrate that several lightweight models, trained using parameter-efficient
techniques on Aegis 2.0, achieve performance competitive with leading safety
models fully fine-tuned on much larger, non-commercial datasets. In addition,
we introduce a novel training blend that combines safety with topic following
data.This approach enhances the adaptability of guard models, enabling them to
generalize to new risk categories defined during inference. We plan to
open-source Aegis 2.0 data and models to the research community to aid in the
safety guardrailing of LLMs.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI Êó•ÁõäÊôÆÂèäÔºåÂÖßÂÆπÂÆâÂÖ®ÊñπÈù¢ÁöÑÊìîÊÜÇ‰πüÂêåÊ≠•Â¢ûÂä†„ÄÇÁõÆÂâçÔºåÈ°ØËëóÁº∫‰πèÈ´òÂìÅË≥™„ÄÅ‰∫∫Â∑•Ê®ôË®ªÁöÑË≥áÊñôÈõÜ‰æÜËß£Ê±∫Ëàá LLM Áõ∏ÈóúÁöÑÂÆâÂÖ®È¢®Èö™ÂÖ®Ë≤åÔºå‰∏îÂèØ‰æõÂïÜÊ•≠ÊáâÁî®‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑÂàÜÈ°ûÊ≥ïÔºåÁî®ÊñºÂàÜÈ°ûÂÆâÂÖ®È¢®Èö™ÔºåÊû∂ÊßãÊàê 12 ÂÄãÈ†ÇÂ±§Âç±ÂÆ≥È°ûÂà•Ôºå‰∏¶Âª∂‰º∏Âà∞ 9 ÂÄãÁ¥∞Á∑ªÁöÑÂ≠êÈ°ûÂà•„ÄÇÊ≠§ÂàÜÈ°ûÊ≥ïÊó®Âú®ÊªøË∂≥‰∏ãÊ∏∏‰ΩøÁî®ËÄÖÁöÑÂ§öÂÖÉÈúÄÊ±ÇÔºåÊèê‰æõÊõ¥Á¥∞Á∑ª‰∏îÂΩàÊÄßÁöÑÂ∑•ÂÖ∑‰æÜÁÆ°ÁêÜÂêÑÁ®ÆÈ¢®Èö™È°ûÂûã„ÄÇÊàëÂÄë‰ΩøÁî®ÁµêÂêà‰∫∫Â∑•Ê®ôË®ªÂíåÂ§ö LLM„ÄåË©ïÂØ©Âúò„ÄçÁ≥ªÁµ±ÁöÑÊ∑∑ÂêàË≥áÊñôÁî¢ÁîüÊµÅÁ®ã‰æÜË©ï‰º∞ÂõûÊáâÁöÑÂÆâÂÖ®ÊÄßÔºåÂèñÂæó Aegis 2.0Ôºå‰∏ÄÂÄãÁ∂ìÈÅé‰ªîÁ¥∞Êï¥ÁêÜ„ÄÅÂåÖÂê´ 34,248 ÂÄãÁØÑ‰æãÁöÑ‰∫∫È°û LLM ‰∫íÂãïÈõÜÂêàÔºå‰∏¶Ê†πÊìöÊàëÂÄëÊèêÂá∫ÁöÑÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÊ®ôË®ª„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊúâÊïàÊÄßÔºåÊàëÂÄëÁ§∫ÁØÑ‰∫ÜÊï∏ÂÄãËºïÈáèÁ¥öÊ®°ÂûãÔºå‰ΩøÁî®ÂèÉÊï∏ÊúâÊïàÊäÄË°ìÂú® Aegis 2.0 ‰∏äË®ìÁ∑¥ÔºåÂÖ∂ÊïàËÉΩËàáÂú®Êõ¥Â§ß„ÄÅÈùûÂïÜÊ•≠Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæÆË™øÁöÑÈ†òÂÖàÂÆâÂÖ®Ê®°Âûã‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®ìÁ∑¥Ê∑∑ÂêàÔºåÁµêÂêàÂÆâÂÖ®ÊÄßËàá‰∏ªÈ°åËøΩËπ§Ë≥áÊñô„ÄÇÊ≠§ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÈò≤Ë≠∑Ê®°ÂûãÁöÑÈÅ©ÊáâÊÄßÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Âú®Êé®Ë´ñÊúüÈñìÊ¶ÇÂåñÂà∞Êñ∞ÁöÑÈ¢®Èö™È°ûÂà•„ÄÇÊàëÂÄëË®àÁï´Â∞á Aegis 2.0 Ë≥áÊñôÂíåÊ®°ÂûãÈñãÊ∫êÁµ¶Á†îÁ©∂Á§æÁæ§Ôºå‰ª•ÂçîÂä© LLM ÁöÑÂÆâÂÖ®Èò≤Ë≠∑„ÄÇ

##### **Personality Modeling for Persuasion of Misinformation using AI Agent**
2501.08985v1 by Qianmin Lou, Wentao Xu

The proliferation of misinformation on social media platforms has highlighted
the need to understand how individual personality traits influence
susceptibility to and propagation of misinformation. This study employs an
innovative agent-based modeling approach to investigate the relationship
between personality traits and misinformation dynamics. Using six AI agents
embodying different dimensions of the Big Five personality traits
(Extraversion, Agreeableness, and Neuroticism), we simulated interactions
across six diverse misinformation topics. The experiment, implemented through
the AgentScope framework using the GLM-4-Flash model, generated 90 unique
interactions, revealing complex patterns in how personality combinations affect
persuasion and resistance to misinformation. Our findings demonstrate that
analytical and critical personality traits enhance effectiveness in
evidence-based discussions, while non-aggressive persuasion strategies show
unexpected success in misinformation correction. Notably, agents with critical
traits achieved a 59.4% success rate in HIV-related misinformation discussions,
while those employing non-aggressive approaches maintained consistent
persuasion rates above 40% across different personality combinations. The study
also revealed a non-transitive pattern in persuasion effectiveness, challenging
conventional assumptions about personality-based influence. These results
provide crucial insights for developing personality-aware interventions in
digital environments and suggest that effective misinformation countermeasures
should prioritize emotional connection and trust-building over confrontational
approaches. The findings contribute to both theoretical understanding of
personality-misinformation dynamics and practical strategies for combating
misinformation in social media contexts.

ÊëòË¶ÅÔºöÁ§æ‰∫§Â™íÈ´îÂπ≥Âè∞‰∏äÈåØË™§Ë®äÊÅØÁöÑÊøÄÂ¢ûÔºåÂá∏È°Ø‰∫Ü‰∫ÜËß£ÂÄã‰∫∫‰∫∫Ê†ºÁâπË≥™Â¶Ç‰ΩïÂΩ±ÈüøÂ∞çÈåØË™§Ë®äÊÅØÁöÑÊïèÊÑüÂ∫¶ÂíåÂÇ≥Êí≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨Á†îÁ©∂Êé°Áî®ÂâµÊñ∞ÁöÑÂü∫Êñº‰ª£ÁêÜÁöÑÂª∫Ê®°ÊñπÊ≥ï‰æÜÊé¢Ë®é‰∫∫Ê†ºÁâπË≥™ËàáÈåØË™§Ë®äÊÅØÂãïÊÖã‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ≠ÂÄãÈ´îÁèæÂ§ß‰∫î‰∫∫Ê†ºÁâπË≥™‰∏çÂêåÈù¢ÂêëÔºàÂ§ñÂêëÊÄß„ÄÅË¶™ÂíåÊÄßÂíåÁ•ûÁ∂ìË≥™ÔºâÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰ª£ÁêÜÔºåÊ®°Êì¨‰∫ÜÂÖ≠ÂÄã‰∏çÂêåÈåØË™§Ë®äÊÅØ‰∏ªÈ°å‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÈÄèÈÅé‰ΩøÁî® GLM-4-Flash Ê®°ÂûãÔºåÈÄèÈÅé AgentScope Ê°ÜÊû∂Âü∑Ë°åÁöÑÂØ¶È©óÁî¢Áîü‰∫Ü 90 ÂÄãÁç®Áâπ‰∫íÂãïÔºåÊè≠Á§∫‰∫Ü‰∫∫Ê†ºÁµÑÂêàÂ¶Ç‰ΩïÂΩ±ÈüøË™™ÊúçÂäõÂíåÂ∞çÈåØË™§Ë®äÊÅØÁöÑÊäµÊäóÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂàÜÊûêÂíåÊâπÂà§ÁöÑ‰∫∫Ê†ºÁâπË≥™ÂèØ‰ª•ÊèêÈ´òÂü∫ÊñºË≠âÊìöÁöÑË®éË´ñÁöÑÊúâÊïàÊÄßÔºåËÄåÈùû‰æµÁï•ÊÄßÁöÑË™™ÊúçÁ≠ñÁï•Âú®ÈåØË™§Ë®äÊÅØÊõ¥Ê≠£ÊñπÈù¢È°ØÁ§∫Âá∫ÊÑèÊÉ≥‰∏çÂà∞ÁöÑÊàêÂäü„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÖ∑ÊúâÊâπÂà§ÁâπË≥™ÁöÑ‰ª£ÁêÜ‰∫∫Âú®Ëàá HIV Áõ∏ÈóúÁöÑÈåØË™§Ë®äÊÅØË®éË´ñ‰∏≠ÂèñÂæó‰∫Ü 59.4% ÁöÑÊàêÂäüÁéáÔºåËÄåÊé°Áî®Èùû‰æµÁï•ÊÄßÊñπÊ≥ïÁöÑ‰ª£ÁêÜ‰∫∫Âú®‰∏çÂêå‰∫∫Ê†ºÁµÑÂêà‰∏≠Á∂≠ÊåÅ‰∫Ü‰∏ÄËá¥ÁöÑË™™ÊúçÁéáÔºåÈ´òÊñº 40%„ÄÇË©≤Á†îÁ©∂ÈÇÑÊè≠Á§∫‰∫ÜË™™ÊúçÊúâÊïàÊÄßÁöÑÈùûÈÅûÁßªÊ®°ÂºèÔºåÊåëÊà∞‰∫ÜÂü∫Êñº‰∫∫Ê†ºÁöÑÂΩ±ÈüøÁöÑÂÇ≥Áµ±ÂÅáË®≠„ÄÇÈÄô‰∫õÁµêÊûúÁÇ∫Âú®Êï∏‰ΩçÁí∞Â¢É‰∏≠ÈñãÁôºÂÖ∑ÊúâÂÄãÊÄßÂåñÁöÑÂπ≤È†êÊé™ÊñΩÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑË¶ãËß£Ôºå‰∏¶Ë°®ÊòéÊúâÊïàÁöÑÈåØË™§Ë®äÊÅØÂ∞çÁ≠ñÊáâÂÑ™ÂÖàËÄÉÊÖÆÊÉÖÊÑüËÅØÁπ´ÂíåÂª∫Á´ã‰ø°‰ªªÔºåËÄå‰∏çÊòØÂ∞çÊäóÊÄßÊñπÊ≥ï„ÄÇÈÄô‰∫õÁôºÁèæÊúâÂä©ÊñºÂ∞ç‰∫∫Ê†ºÈåØË™§Ë®äÊÅØÂãïÊÖãÁöÑÁêÜË´ñÁêÜËß£ÂíåÂú®Á§æ‰∫§Â™íÈ´îËÉåÊôØ‰∏ãÊâìÊìäÈåØË™§Ë®äÊÅØÁöÑÂØ¶Áî®Á≠ñÁï•„ÄÇ

##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v1 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high- versus low-quality summaries for discriminant validity. Seven
physician raters evaluated 779 summaries and answered 8,329 questions,
achieving over 80% power for inter-rater reliability. The PDSQI-9 demonstrated
strong internal consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and
high inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized (rho = -0.190, p = 0.037). Discriminant validity distinguished high-
from low-quality summaries (p < 0.001). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÔºåÈ©óË≠âÂ∑•ÂÖ∑Â∞çÊñºÂú®ÂØ¶ÊñΩÂâçË©ï‰º∞ÂÖ∂ÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÊèê‰æõËÄÖÊñá‰ª∂ÂìÅË≥™Â∑•ÂÖ∑ÈÄöÂ∏∏‰∏çÈÅ©Âêà LLM ÁîüÊàêÁöÑÊñáÂ≠óË§áÈõúÊÄßÔºå‰∏îÁº∫‰πèÂ∞çÁúüÂØ¶‰∏ñÁïåË≥áÊñôÁöÑÈ©óË≠â„ÄÇÊèê‰æõËÄÖÊñá‰ª∂ÊëòË¶ÅÂìÅË≥™Â∑•ÂÖ∑ (PDSQI-9) ÁöÑÈñãÁôºÁõÆÁöÑÊòØË©ï‰º∞ LLM ÁîüÊàêÁöÑËá®Â∫äÊëòË¶Å„ÄÇ‰ΩøÁî®Â§öÂÄã LLMÔºàGPT-4o„ÄÅMixtral 8x7b Âíå Llama 3-8bÔºâÂæûË∑®Â§öÂÄãÂ∞àÁßëÁöÑÁúüÂØ¶‰∏ñÁïå EHR Ë≥áÊñô‰∏≠Áî¢ÁîüÂ§öÊñá‰ª∂ÊëòË¶Å„ÄÇÈ©óË≠âÂåÖÊã¨ÂØ¶Ë≥™ÊïàÂ∫¶ÁöÑÁöÆÁàæÊ£ÆÁõ∏Èóú‰øÇÊï∏„ÄÅÁµêÊßãÊïàÂ∫¶ÁöÑÂõ†Â≠êÂàÜÊûêÂíåÂÖãÊúóÂ∑¥Ëµ´ Œ± ‰øÇÊï∏„ÄÅÊ¶ÇÊã¨ÊÄßÁöÑË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÔºàICC ÂíåÂÖãÈáåÂΩ≠Â§öÂ§´ Œ± ‰øÇÊï∏Ôºâ„ÄÅÂÖßÂÆπÊïàÂ∫¶ÁöÑÂçäÂæ∑ÁàæËè≤Á®ãÂ∫èÔºå‰ª•ÂèäÁî®ÊñºÂà§Âà•ÊïàÂ∫¶ÁöÑÂÑ™Ë≥™ËàáÂä£Ë≥™ÊëòË¶ÅÊØîËºÉ„ÄÇ‰∏É‰ΩçÈÜ´Â∏´Ë©ïÂàÜËÄÖË©ï‰º∞‰∫Ü 779 ‰ªΩÊëòË¶Å‰∏¶ÂõûÁ≠î‰∫Ü 8,329 ÂÄãÂïèÈ°åÔºåË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÈÅîÂà∞ 80% ‰ª•‰∏ä„ÄÇPDSQI-9 Ë°®ÁèæÂá∫Âº∑Â§ßÁöÑÂÖßÈÉ®‰∏ÄËá¥ÊÄßÔºàÂÖãÊúóÂ∑¥Ëµ´ Œ± ‰øÇÊï∏ = 0.879Ôºõ95% CIÔºö0.867-0.891ÔºâÂíåÈ´òË©ïÂàÜËÄÖÈñì‰ø°Â∫¶ÔºàICC = 0.867Ôºõ95% CIÔºö0.867-0.868ÔºâÔºåÊîØÊåÅÁµêÊßãÊïàÂ∫¶ÂíåÊ¶ÇÊã¨ÊÄß„ÄÇÂõ†Â≠êÂàÜÊûêËæ®Ë≠òÂá∫‰∏ÄÂÄã 4 Âõ†Â≠êÊ®°ÂûãÔºåËß£Èáã‰∫Ü 58% ÁöÑËÆäÁï∞Ôºå‰ª£Ë°®ÁµÑÁπî„ÄÅÊ∏ÖÊô∞Â∫¶„ÄÅÊ∫ñÁ¢∫ÊÄßÂíåÂØ¶Áî®ÊÄß„ÄÇÂØ¶Ë≥™ÊïàÂ∫¶ÂèóÂà∞ÊëòË¶ÅÈï∑Â∫¶ËàáÁ∞°ÊΩîÔºàrho = -0.200Ôºåp = 0.029ÔºâÂíåÁµÑÁπîÔºàrho = -0.190Ôºåp = 0.037ÔºâÂàÜÊï∏‰πãÈñìÁõ∏ÈóúÊÄßÁöÑÊîØÊåÅ„ÄÇÂà§Âà•ÊïàÂ∫¶ÂçÄÂàÜ‰∫ÜÂÑ™Ë≥™ÂíåÂä£Ë≥™ÊëòË¶ÅÔºàp < 0.001Ôºâ„ÄÇPDSQI-9 Ë°®ÁèæÂá∫Á©©ÂÅ•ÁöÑÂª∫ÊßãÊïàÂ∫¶ÔºåÊîØÊåÅÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠‰ΩøÁî®ÂÆÉ‰æÜË©ï‰º∞ LLM ÁîüÊàêÁöÑÊëòË¶ÅÔºå‰∏¶‰øÉÈÄ≤ LLM Êõ¥ÂÆâÂÖ®ÁöÑÊï¥ÂêàÂà∞ÈÜ´ÁôÇ‰øùÂÅ•Â∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇ

##### **Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models**
2501.08974v1 by Karukriti Kaushik Ghosh, Chiranjib Sur

Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment
analysis that aims to extract and classify sentiments based on specific aspects
or features of a product, service, or entity. Unlike traditional sentiment
analysis, which assigns a general sentiment score to entire reviews or texts,
ABSA focuses on breaking down the text into individual components or aspects
(e.g., quality, price, service) and evaluating the sentiment towards each. This
allows for a more granular level of understanding of customer opinions,
enabling businesses to pinpoint specific areas of strength and improvement. The
process involves several key steps, including aspect extraction, sentiment
classification, and aspect-level sentiment aggregation for a review paragraph
or any other form that the users have provided. ABSA has significant
applications in areas such as product reviews, social media monitoring,
customer feedback analysis, and market research. By leveraging techniques from
natural language processing (NLP) and machine learning, ABSA facilitates the
extraction of valuable insights, enabling companies to make data-driven
decisions that enhance customer satisfaction and optimize offerings. As ABSA
evolves, it holds the potential to greatly improve personalized customer
experiences by providing a deeper understanding of sentiment across various
product aspects. In this work, we have analyzed the strength of LLMs for a
complete cross-domain aspect-based sentiment analysis with the aim of defining
the framework for certain products and using it for other similar situations.
We argue that it is possible to that at an effectiveness of 92\% accuracy for
the Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12.

ÊëòË¶ÅÔºöÂü∫ÊñºÈù¢ÂêëÊñπÈù¢ÁöÑËßÄÈªûÂàÜÊûê (ASBA) ÊòØ‰∏ÄÁ®ÆÁ≤æÁ∑ªÁöÑÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÔºåÊó®Âú®Ê†πÊìöÁî¢ÂìÅ„ÄÅÊúçÂãôÊàñÂØ¶È´îÁöÑÁâπÂÆöÈù¢ÂêëÊàñÁâπÂæµ‰æÜÊèêÂèñÂíåÂàÜÈ°ûËßÄÈªû„ÄÇËàáÂ∞á‰∏ÄËà¨ËßÄÈªûË©ïÂàÜÂàÜÈÖçÁµ¶Êï¥ÂÄãË©ïË´ñÊàñÊñáÂ≠óÁöÑÂÇ≥Áµ±ËßÄÈªûÂàÜÊûê‰∏çÂêåÔºåABSA Â∞àÊ≥®ÊñºÂ∞áÊñáÂ≠óÂàÜËß£ÁÇ∫ÂÄãÂà•ÁµÑÊàêÈÉ®ÂàÜÊàñÈù¢ÂêëÔºà‰æãÂ¶ÇÔºåÂìÅË≥™„ÄÅÂÉπÊ†º„ÄÅÊúçÂãôÔºâÔºå‰∏¶Ë©ï‰º∞Â∞çÊØèÂÄãÈù¢ÂêëÁöÑËßÄÈªû„ÄÇÈÄôÂÖÅË®±Êõ¥Á¥∞Á∑ªÂú∞‰∫ÜËß£ÂÆ¢Êà∂ÊÑèË¶ãÔºå‰Ωø‰ºÅÊ•≠ËÉΩÂ§†Á≤æÁ¢∫ÊâæÂá∫ÂÑ™Âã¢ÂíåÊîπÈÄ≤È†òÂüü„ÄÇÈÄôÂÄãÈÅéÁ®ãÊ∂âÂèäÂπæÂÄãÈóúÈçµÊ≠•È©üÔºåÂåÖÊã¨Èù¢ÂêëÊèêÂèñ„ÄÅËßÄÈªûÂàÜÈ°ûÔºå‰ª•ÂèäË©ïË´ñÊÆµËêΩÊàñ‰ΩøÁî®ËÄÖÊèê‰æõÁöÑ‰ªª‰ΩïÂÖ∂‰ªñÂΩ¢ÂºèÁöÑËßÄÈªûÂ±§Á¥öËßÄÈªûÂΩôÁ∏Ω„ÄÇABSA Âú®Áî¢ÂìÅË©ïË´ñ„ÄÅÁ§æÁæ§Â™íÈ´îÁõ£Êéß„ÄÅÂÆ¢Êà∂ÂõûÈ•ãÂàÜÊûêÂíåÂ∏ÇÂ†¥Á†îÁ©∂Á≠âÈ†òÂüüÊúâÈáçË¶ÅÁöÑÊáâÁî®„ÄÇÈÄèÈÅéÂà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏ÁøíÁöÑÊäÄË°ìÔºåABSA ‰øÉÈÄ≤ÊúâÂÉπÂÄºË¶ãËß£ÁöÑÊèêÂèñÔºåËÆìÂÖ¨Âè∏ËÉΩÂ§†ÂÅöÂá∫‰ª•Êï∏ÊìöÁÇ∫Âü∫Á§éÁöÑÊ±∫Á≠ñÔºå‰ª•Â¢ûÂº∑ÂÆ¢Êà∂ÊªøÊÑèÂ∫¶‰∏¶ÊúÄ‰Ω≥ÂåñÁî¢ÂìÅ„ÄÇÈö®Ëëó ABSA ÁöÑÊºîÈÄ≤ÔºåÂÆÉÊúâÊΩõÂäõÈÄèÈÅéÊèê‰æõÂ∞çÂêÑÁ®ÆÁî¢ÂìÅÈù¢ÂêëËßÄÈªûÁöÑÊõ¥Ê∑±ÂÖ•‰∫ÜËß£Ôºå‰æÜÂ§ßÂπÖÊîπÂñÑÂÄã‰∫∫ÂåñÁöÑÂÆ¢Êà∂È´îÈ©ó„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫Ü LLM Âú®ÂÆåÊï¥ÁöÑË∑®È†òÂüüÂü∫ÊñºÈù¢ÂêëÁöÑËßÄÈªûÂàÜÊûê‰∏≠ÁöÑÂÑ™Âã¢ÔºåÁõÆÁöÑÊòØÂÆöÁæ©ÁâπÂÆöÁî¢ÂìÅÁöÑÊû∂ÊßãÔºå‰∏¶Â∞áÂÖ∂Áî®ÊñºÂÖ∂‰ªñÈ°û‰ººÊÉÖÊ≥Å„ÄÇÊàëÂÄëË´ñË≠âÔºåÂú® SemEval-2015 ‰ªªÂãô 12 ÁöÑÂü∫ÊñºÈù¢ÂêëÁöÑËßÄÈªûÂàÜÊûêË≥áÊñôÈõÜ‰∏äÈÅîÂà∞ 92% Á≤æÁ¢∫Â∫¶ÁöÑÊúâÊïàÊÄßÊòØÂèØËÉΩÁöÑ„ÄÇ

##### **Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography**
2501.08970v1 by Ilia Shumailov, Daniel Ramage, Sarah Meiklejohn, Peter Kairouz, Florian Hartmann, Borja Balle, Eugene Bagdasarian

We often interact with untrusted parties. Prioritization of privacy can limit
the effectiveness of these interactions, as achieving certain goals
necessitates sharing private data. Traditionally, addressing this challenge has
involved either seeking trusted intermediaries or constructing cryptographic
protocols that restrict how much data is revealed, such as multi-party
computations or zero-knowledge proofs. While significant advances have been
made in scaling cryptographic approaches, they remain limited in terms of the
size and complexity of applications they can be used for. In this paper, we
argue that capable machine learning models can fulfill the role of a trusted
third party, thus enabling secure computations for applications that were
previously infeasible. In particular, we describe Trusted Capable Model
Environments (TCMEs) as an alternative approach for scaling secure computation,
where capable machine learning model(s) interact under input/output
constraints, with explicit information flow control and explicit statelessness.
This approach aims to achieve a balance between privacy and computational
efficiency, enabling private inference where classical cryptographic solutions
are currently infeasible. We describe a number of use cases that are enabled by
TCME, and show that even some simple classic cryptographic problems can already
be solved with TCME. Finally, we outline current limitations and discuss the
path forward in implementing them.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁ∂ìÂ∏∏Ëàá‰∏çÂèØ‰ø°Ë≥¥ÁöÑÂ∞çË±°‰∫íÂãï„ÄÇÈö±ÁßÅÂÑ™ÂÖàËÄÉÈáèÂèØËÉΩÊúÉÈôêÂà∂ÈÄô‰∫õ‰∫íÂãïÁöÑÊàêÊïàÔºåÂõ†ÁÇ∫ÈÅîÊàêÁâπÂÆöÁõÆÊ®ôÈúÄË¶ÅÂàÜ‰∫´ÁßÅ‰∫∫Ë≥áÊñô„ÄÇÂÇ≥Áµ±‰∏äÔºåËß£Ê±∫Ê≠§ÊåëÊà∞ÁöÑÊñπÊ≥ïÊòØÂ∞ãÊ±ÇÂèó‰ø°‰ªªÁöÑ‰∏≠‰ªãËÄÖÊàñÂª∫ÊßãÂä†ÂØÜÂçîÂÆö‰æÜÈôêÂà∂Êè≠Èú≤ÁöÑË≥áÊñôÈáèÔºå‰æãÂ¶ÇÂ§öÊñπÈÅãÁÆóÊàñÈõ∂Áü•Ë≠òË≠âÊòé„ÄÇÈõñÁÑ∂Âä†ÂØÜÊñπÊ≥ïÁöÑË¶èÊ®°ÂåñÂ∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÂú®ÂèØ‰ΩøÁî®ÁöÑÊáâÁî®Á®ãÂºèÂ§ßÂ∞èÂíåË§áÈõúÂ∫¶ÊñπÈù¢‰ªçÁÑ∂ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰∏ªÂºµÊúâËÉΩÂäõÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂèØ‰ª•ÊâÆÊºîÂèó‰ø°‰ªªÁ¨¨‰∏âÊñπËßíËâ≤ÔºåÈÄ≤ËÄåÁÇ∫‰ª•Ââç‰∏çÂèØË°åÁöÑÊáâÁî®Á®ãÂºèÂïüÁî®ÂÆâÂÖ®ÈÅãÁÆó„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ∞áÂèó‰ø°‰ªªÊúâËÉΩÂäõÊ®°ÂûãÁí∞Â¢É (TCME) ÊèèËø∞ÁÇ∫ÂÆâÂÖ®ÈÅãÁÆóË¶èÊ®°ÂåñÁöÑÂè¶‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÊúâËÉΩÂäõÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®Ëº∏ÂÖ•/Ëº∏Âá∫ÈôêÂà∂‰∏ã‰∫íÂãïÔºå‰∏¶ÂÖ∑ÊúâÊòéÁ¢∫ÁöÑË≥áË®äÊµÅÊéßÂà∂ÂíåÊòéÁ¢∫ÁöÑÁÑ°ÁãÄÊÖãÊÄß„ÄÇÊ≠§ÊñπÊ≥ïÊó®Âú®ÈÅîÊàêÈö±ÁßÅÂíåÈÅãÁÆóÊïàÁéá‰πãÈñìÁöÑÂπ≥Ë°°ÔºåÂú®ÂÇ≥Áµ±Âä†ÂØÜËß£Ê±∫ÊñπÊ°àÁõÆÂâç‰∏çÂèØË°åÁöÑÊÉÖÊ≥Å‰∏ãÂïüÁî®ÁßÅ‰∫∫Êé®Ë´ñ„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü TCME ÂïüÁî®ÁöÑË®±Â§ö‰ΩøÁî®Ê°à‰æãÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂç≥‰ΩøÊòØ‰∏Ä‰∫õÁ∞°ÂñÆÁöÑÁ∂ìÂÖ∏Âä†ÂØÜÂïèÈ°å‰πüÂèØ‰ª•ËóâÁî± TCME Ëß£Ê±∫„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÁõÆÂâçÁöÑÈôêÂà∂Ôºå‰∏¶Ë®éË´ñ‰∫ÜÂØ¶‰ΩúÂÆÉÂÄëÁöÑÊú™‰æÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, Jos√© Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, √ârico Moutinho, J√©ssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

ÊëòË¶ÅÔºöAI ÊºîÁÆóÊ≥ïÂ∑≤ÊàêÁÇ∫ÂçîÂä©ÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÁöÑÂØ∂Ë≤¥Â∑•ÂÖ∑„ÄÇÈÄô‰∫õÊ®°ÂûãÁç≤ÂæóÁöÑ‰ø°ÂøÉÊó•ÁõäÊèêÂçáÔºåÊúâÂä©ÊñºÈóúÈçµÊ±∫Á≠ñÈúÄÊ±Ç„ÄÇÂú®Ëá®Â∫äÁöÆËÜöÁßëÔºåÂàÜÈ°ûÊ®°ÂûãÂÉÖ‰ΩøÁî® RGB ÂΩ±ÂÉè‰ΩúÁÇ∫Ëº∏ÂÖ•ÔºåÂç≥ÂèØÂÅµÊ∏¨ÊÇ£ËÄÖÁöÆËÜö‰∏äÁöÑÊÉ°ÊÄßÁóÖÁÅ∂„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Âü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÊé°Áî®ÂæûÁöÆËÜöÈè°Ë≥áÊñôÈõÜÂèñÂæóÁöÑË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÔºåÈÄô‰∫õË≥áÊñôÈõÜÈæêÂ§ß‰∏îÂ∑≤ÈÄöÈÅéÈáëÊ®ôÊ∫ñÈ©óË≠â„ÄÇËá®Â∫äÊ®°ÂûãÊó®Âú®ËôïÁêÜ‰ΩøÁî®ËÄÖÊô∫ÊÖßÂûãÊâãÊ©üÁõ∏Ê©ü‰∏äÁöÑÂàÜÈ°ûÔºåÈÄô‰∫õÁõ∏Ê©ü‰∏çÂåÖÂê´ÁöÆËÜöÈè°Êèê‰æõÁöÑÂ∞çÊáâËß£ÊûêÂ∫¶„ÄÇÊ≠§Â§ñÔºåËá®Â∫äÊáâÁî®Á®ãÂºèÂ∏∂‰æÜÊñ∞ÁöÑÊåëÊà∞„ÄÇÂÆÉÂèØËÉΩÂåÖÂê´‰æÜËá™‰∏çÂèóÊéßÁí∞Â¢ÉÁöÑÊì∑Âèñ„ÄÅËÜöËâ≤ËÆäÂåñ„ÄÅË¶ñÈªûËÆäÊõ¥„ÄÅË≥áÊñôÂíåÊ®ôÁ±§‰∏≠ÁöÑÈõúË®äÔºå‰ª•Âèä‰∏çÂπ≥Ë°°ÁöÑÈ°ûÂà•„ÄÇ‰∏ÄÁ®ÆÂèØËÉΩÁöÑÊõø‰ª£ÊñπÊ°àÊòØ‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏Áøí‰æÜËôïÁêÜËá®Â∫äÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊ®£Êú¨Êï∏ÈáèÂ∞ëÔºåÂèØËÉΩÊúÉÂ∞éËá¥Ê®°ÂûãÊïàËÉΩ‰∏ãÈôçÔºõË®ìÁ∑¥‰∏≠‰ΩøÁî®ÁöÑ‰æÜÊ∫êÂàÜ‰ΩàËàáÊ∏¨Ë©¶ÈõÜ‰∏çÂêå„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Ë©ï‰º∞ÁöÆËÜöÈè°ÂíåËá®Â∫äÊ®£Êú¨‰πãÈñìÁöÑÂ∑ÆË∑ùÔºå‰∏¶‰∫ÜËß£Ë≥áÊñôÈõÜËÆäÂåñÂ¶Ç‰ΩïÂΩ±ÈüøË®ìÁ∑¥„ÄÇÂÆÉË©ï‰º∞ÊúÉÂπ≤ÊìæÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰∏ªË¶ÅÂàÜ‰ΩàÂ∑ÆÁï∞„ÄÇÊúÄÂæåÔºåÂæû‰∏çÂêåÊû∂ÊßãÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëË´ñË≠âÂ¶Ç‰ΩïÁµêÂêà‰æÜËá™‰∏çÂêåÂàÜ‰ΩàÁöÑË≥áÊñôÔºåÈôç‰ΩéÂ∞çÊ®°ÂûãÊúÄÁµÇÊ∫ñÁ¢∫Â∫¶ÁöÑÂΩ±Èüø„ÄÇ

##### **Kolmogorov-Arnold Networks for Time Series Granger Causality Inference**
2501.08958v1 by Meiliang Liu, Yunfang Xu, Zijin Li, Zhengye Si, Xiaoxiao Yang, Xinyue Yang, Zhiwen Zhao

We introduce Granger Causality Kolmogorov-Arnold Networks (GCKAN), an
innovative architecture that extends the recently proposed Kolmogorov-Arnold
Networks (KAN) to the domain of causal inference. By extracting base weights
from KAN layers and incorporating the sparsity-inducing penalty along with
ridge regularization, GCKAN infers the Granger causality from time series while
enabling automatic time lag selection. Additionally, we propose an algorithm
leveraging time-reversed Granger causality to enhance inference accuracy. The
algorithm compares prediction and sparse-inducing losses derived from the
original and time-reversed series, automatically selecting the casual
relationship with the higher score or integrating the results to mitigate
spurious connectivities. Comprehensive experiments conducted on Lorenz-96, gene
regulatory networks, fMRI BOLD signals, and VAR datasets demonstrate that the
proposed model achieves competitive performance to state-of-the-art methods in
inferring Granger causality from nonlinear, high-dimensional, and
limited-sample time series.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π Granger Âõ†ÊûúÈóú‰øÇ Kolmogorov-Arnold Á∂≤Ë∑Ø (GCKAN)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂ∞áÊúÄËøëÊèêÂá∫ÁöÑ Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN) Âª∂‰º∏Âà∞Âõ†ÊûúÊé®Ë´ñÁöÑÈ†òÂüü„ÄÇÈÄèÈÅéÂæû KAN Â±§‰∏≠ÊèêÂèñÂü∫Á§éÊ¨äÈáç‰∏¶ÁµêÂêàÁ®ÄÁñèÊÄßË™òÂ∞éÊá≤ÁΩ∞‰ª•ÂèäÂ∂∫ÂõûÊ≠∏ÔºåGCKAN ÂæûÊôÇÈñìÂ∫èÂàó‰∏≠Êé®Êñ∑ Granger Âõ†ÊûúÈóú‰øÇÔºåÂêåÊôÇÂïüÁî®Ëá™ÂãïÊôÇÈñìÊªØÂæåÈÅ∏Êìá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊºîÁÆóÊ≥ïÔºåÂà©Áî®ÊôÇÈñìÂèçËΩâ Granger Âõ†ÊûúÈóú‰øÇ‰æÜÂ¢ûÂº∑Êé®Ë´ñÊ∫ñÁ¢∫ÊÄß„ÄÇË©≤ÊºîÁÆóÊ≥ïÊØîËºÉÂæûÂéüÂßãÊôÇÈñìÂ∫èÂàóÂíåÊôÇÈñìÂèçËΩâÊôÇÈñìÂ∫èÂàó‰∏≠Ë°çÁîüÁöÑÈ†êÊ∏¨ÂíåÁ®ÄÁñèÊÄßË™òÂ∞éÊêçÂ§±ÔºåËá™ÂãïÈÅ∏ÊìáÂÖ∑ÊúâËºÉÈ´òÂàÜÊï∏ÁöÑÂõ†ÊûúÈóú‰øÇÊàñÊï¥ÂêàÁµêÊûú‰ª•Ê∏õËºïËôõÂÅáÈÄ£ÈÄöÊÄß„ÄÇÂú® Lorenz-96„ÄÅÂü∫Âõ†Ë™øÊéßÁ∂≤Ë∑Ø„ÄÅfMRI BOLD Ë®äËôüÂíå VAR Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÂæûÈùûÁ∑öÊÄß„ÄÅÈ´òÁ∂≠ÂíåÊúâÈôêÊ®£Êú¨ÊôÇÈñìÂ∫èÂàó‰∏≠Êé®Êñ∑ Granger Âõ†ÊûúÈóú‰øÇÊñπÈù¢ÔºåÂèØÈÅîÂà∞ËàáÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏Â™≤ÁæéÁöÑÊïàËÉΩ„ÄÇ

##### **Analyzing the Ethical Logic of Six Large Language Models**
2501.08951v1 by W. Russell Neuman, Chad Coleman, Manan Shah

This study examines the ethical reasoning of six prominent generative large
language models: OpenAI GPT-4o, Meta LLaMA 3.1, Perplexity, Anthropic Claude
3.5 Sonnet, Google Gemini, and Mistral 7B. The research explores how these
models articulate and apply ethical logic, particularly in response to moral
dilemmas such as the Trolley Problem, and Heinz Dilemma. Departing from
traditional alignment studies, the study adopts an explainability-transparency
framework, prompting models to explain their ethical reasoning. This approach
is analyzed through three established ethical typologies: the
consequentialist-deontological analytic, Moral Foundations Theory, and the
Kohlberg Stages of Moral Development Model. Findings reveal that LLMs exhibit
largely convergent ethical logic, marked by a rationalist, consequentialist
emphasis, with decisions often prioritizing harm minimization and fairness.
Despite similarities in pre-training and model architecture, a mixture of
nuanced and significant differences in ethical reasoning emerge across models,
reflecting variations in fine-tuning and post-training processes. The models
consistently display erudition, caution, and self-awareness, presenting ethical
reasoning akin to a graduate-level discourse in moral philosophy. In striking
uniformity these systems all describe their ethical reasoning as more
sophisticated than what is characteristic of typical human moral logic.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂Êé¢Ë®é‰∫ÜÂÖ≠Á®ÆËëóÂêçÁöÑÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂÄ´ÁêÜÊé®ÁêÜÔºöOpenAI GPT-4o„ÄÅMeta LLaMA 3.1„ÄÅPerplexity„ÄÅAnthropic Claude 3.5 Sonnet„ÄÅGoogle Gemini Âíå Mistral 7B„ÄÇË©≤Á†îÁ©∂Êé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïÈó°Ëø∞ÂíåÊáâÁî®ÂÄ´ÁêÜÈÇèËºØÔºåÁâπÂà•ÊòØÂú®ÂõûÊáâÈÅìÂæ∑ÂÖ©Èõ£ÂïèÈ°åÔºå‰æãÂ¶ÇÈõªËªäÈõ£È°åÂíåÊµ∑Âõ†Ëå®ÂÖ©Èõ£ÂïèÈ°åÊôÇ„ÄÇË©≤Á†îÁ©∂Ë∑≥ËÑ´ÂÇ≥Áµ±ÁöÑÂ∞çÈΩäÁ†îÁ©∂ÔºåÊé°Áî®ÂèØËß£ÈáãÊÄßÈÄèÊòéÂ∫¶Êû∂ÊßãÔºå‰øÉ‰ΩøÊ®°ÂûãËß£ÈáãÂÖ∂ÂÄ´ÁêÜÊé®ÁêÜ„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅé‰∏âÁ®ÆÊó¢ÂÆöÁöÑÂÄ´ÁêÜÈ°ûÂûãÂ≠∏ÈÄ≤Ë°åÂàÜÊûêÔºöÂæåÊûúË´ñ - Áæ©ÂãôË´ñÂàÜÊûê„ÄÅÈÅìÂæ∑Âü∫Á§éÁêÜË´ñÂíåÁßëÁàæ‰ºØÊ†ºÈÅìÂæ∑ÁôºÂ±ïÈöéÊÆµÊ®°Âûã„ÄÇÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM Ë°®ÁèæÂá∫È´òÂ∫¶‰∏ÄËá¥ÁöÑÂÄ´ÁêÜÈÇèËºØÔºåÁâπÂæµÂú®ÊñºÁêÜÊÄß‰∏ªÁæ©„ÄÅÂæåÊûúË´ñÁöÑÂº∑Ë™øÔºåÊ±∫Á≠ñÈÄöÂ∏∏ÂÑ™ÂÖàËÄÉÊÖÆÊúÄÂ∞èÂåñÂÇ∑ÂÆ≥ÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÂÑòÁÆ°È†êË®ìÁ∑¥ÂíåÊ®°ÂûãÊû∂ÊßãÁõ∏‰ººÔºå‰ΩÜ‰∏çÂêåÊ®°Âûã‰πãÈñìÂá∫Áèæ‰∫ÜÁ¥∞ÂæÆ‰∏îÈ°ØËëóÁöÑÂÄ´ÁêÜÊé®ÁêÜÂ∑ÆÁï∞ÔºåÂèçÊò†‰∫ÜÂæÆË™øÂíåÂæåË®ìÁ∑¥ÈÅéÁ®ãÁöÑÂ∑ÆÁï∞„ÄÇÈÄô‰∫õÊ®°ÂûãÂßãÁµÇË°®ÁèæÂá∫ÂçöÂ≠∏„ÄÅË¨πÊÖéÂíåËá™ÊàëÊÑèË≠òÔºåÂëàÁèæÂá∫È°û‰ººÊñºÈÅìÂæ∑Âì≤Â≠∏Á†îÁ©∂ÁîüÂ±§Á¥öË´ñËø∞ÁöÑÂÄ´ÁêÜÊé®ÁêÜ„ÄÇÈÄô‰∫õÁ≥ªÁµ±È©ö‰∫∫Âú∞‰∏ÄËá¥Âú∞ÊèèËø∞ÂÆÉÂÄëÁöÑÂÄ´ÁêÜÊé®ÁêÜÊØîÂÖ∏Âûã‰∫∫È°ûÈÅìÂæ∑ÈÇèËºØÁöÑÁâπÊÄßÊõ¥ÁÇ∫Ë§áÈõú„ÄÇ

##### **Applying General Turn-taking Models to Conversational Human-Robot Interaction**
2501.08946v1 by Gabriel Skantze, Bahar Irfan

Turn-taking is a fundamental aspect of conversation, but current Human-Robot
Interaction (HRI) systems often rely on simplistic, silence-based models,
leading to unnatural pauses and interruptions. This paper investigates, for the
first time, the application of general turn-taking models, specifically TurnGPT
and Voice Activity Projection (VAP), to improve conversational dynamics in HRI.
These models are trained on human-human dialogue data using self-supervised
learning objectives, without requiring domain-specific fine-tuning. We propose
methods for using these models in tandem to predict when a robot should begin
preparing responses, take turns, and handle potential interruptions. We
evaluated the proposed system in a within-subject study against a traditional
baseline system, using the Furhat robot with 39 adults in a conversational
setting, in combination with a large language model for autonomous response
generation. The results show that participants significantly prefer the
proposed system, and it significantly reduces response delays and
interruptions.

ÊëòË¶ÅÔºöËº™ÊµÅÁôºË®ÄÊòØÂ∞çË©±ÁöÑÂü∫Êú¨Èù¢ÂêëÔºå‰ΩÜÁï∂ÂâçÁöÑÊ©üÂô®‰∫∫‰∫∫È°û‰∫íÂãï (HRI) Á≥ªÁµ±Á∂ìÂ∏∏‰æùË≥¥ÊñºÁ∞°ÂåñÁöÑ„ÄÅÂü∫ÊñºÊ≤âÈªòÁöÑÊ®°ÂûãÔºåÂ∞éËá¥‰∏çËá™ÁÑ∂ÁöÑÂÅúÈ†ìÂíå‰∏≠Êñ∑„ÄÇÊú¨ÊñáÈ¶ñÊ¨°Êé¢Ë®éÂ∞á‰∏ÄËà¨ÁöÑËº™ÊµÅÁôºË®ÄÊ®°ÂûãÔºåÁâπÂà•ÊòØ TurnGPT ÂíåË™ûÈü≥Ê¥ªÂãïÈ†êÊ∏¨ (VAP)ÔºåÊáâÁî®ÊñºÊîπÂñÑ HRI ‰∏≠ÁöÑÂ∞çË©±ÂãïÊÖã„ÄÇÈÄô‰∫õÊ®°Âûã‰ΩøÁî®Ëá™ÊàëÁõ£Áù£ÁöÑÂ≠∏ÁøíÁõÆÊ®ôÂú®‰∫∫Ëàá‰∫∫ÁöÑÂ∞çË©±Ë≥áÊñô‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄå‰∏çÈúÄË¶ÅÁâπÂÆöÊñºÈ†òÂüüÁöÑÂæÆË™ø„ÄÇÊàëÂÄëÊèêÂá∫‰ΩøÁî®ÈÄô‰∫õÊ®°Âûã‰∏≤ËÅØÁöÑÊñπÊ≥ïÔºå‰ª•È†êÊ∏¨Ê©üÂô®‰∫∫ÊáâË©≤‰ΩïÊôÇÈñãÂßãÊ∫ñÂÇôÂõûÊáâ„ÄÅËº™ÊµÅÁôºË®Ä‰ª•ÂèäËôïÁêÜÊΩõÂú®ÁöÑ‰∏≠Êñ∑„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄã‰∏ªÈ°åÂÖßÁ†îÁ©∂‰∏≠Ë©ï‰º∞‰∫ÜÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Ôºå‰∏¶ÈáùÂ∞çÂÇ≥Áµ±ÁöÑÂü∫Ê∫ñÁ≥ªÁµ±Ôºå‰ΩøÁî® Furhat Ê©üÂô®‰∫∫Âíå 39 ‰ΩçÊàê‰∫∫ÈÄ≤Ë°åÂ∞çË©±Ë®≠ÂÆöÔºå‰∏¶ÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åËá™‰∏ªÂõûÊáâÁî¢Áîü„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂèÉËàáËÄÖÈ°ØËëóÂÅèÂ•ΩÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±Ôºå‰∏¶‰∏îÂÆÉÈ°ØËëóÊ∏õÂ∞ë‰∫ÜÂõûÊáâÂª∂ÈÅ≤Âíå‰∏≠Êñ∑„ÄÇ

##### **Visual WetlandBirds Dataset: Bird Species Identification and Behavior Recognition in Videos**
2501.08931v1 by Javier Rodriguez-Juan, David Ortiz-Perez, Manuel Benavent-Lledo, David Mulero-P√©rez, Pablo Ruiz-Ponce, Adrian Orihuela-Torres, Jose Garcia-Rodriguez, Esther Sebasti√°n-Gonz√°lez

The current biodiversity loss crisis makes animal monitoring a relevant field
of study. In light of this, data collected through monitoring can provide
essential insights, and information for decision-making aimed at preserving
global biodiversity. Despite the importance of such data, there is a notable
scarcity of datasets featuring videos of birds, and none of the existing
datasets offer detailed annotations of bird behaviors in video format. In
response to this gap, our study introduces the first fine-grained video dataset
specifically designed for bird behavior detection and species classification.
This dataset addresses the need for comprehensive bird video datasets and
provides detailed data on bird actions, facilitating the development of deep
learning models to recognize these, similar to the advancements made in human
action recognition. The proposed dataset comprises 178 videos recorded in
Spanish wetlands, capturing 13 different bird species performing 7 distinct
behavior classes. In addition, we also present baseline results using state of
the art models on two tasks: bird behavior recognition and species
classification.

ÊëòË¶ÅÔºöÁï∂ÂâçÁîüÁâ©Â§öÊ®£ÊÄßÂñ™Â§±Âç±Ê©ü‰ΩøÂæóÂãïÁâ©Áõ£ÊéßÊàêÁÇ∫‰∏ÄÂÄãÁõ∏ÈóúÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÈÄèÈÅéÁõ£ÊéßÊî∂ÈõÜÁöÑË≥áÊñôÂèØ‰ª•Êèê‰æõÂøÖË¶ÅÁöÑË¶ãËß£Ôºå‰ª•ÂèäÁî®ÊñºÊ±∫Á≠ñÂà∂ÂÆö‰ª•‰øùË≠∑ÂÖ®ÁêÉÁîüÁâ©Â§öÊ®£ÊÄßÁöÑË≥áË®ä„ÄÇÂÑòÁÆ°Ê≠§È°ûË≥áÊñôÂæàÈáçË¶ÅÔºå‰ΩÜÂÖ∂‰∏≠Áº∫Â∞ëÈ≥•È°ûÂΩ±ÁâáÁöÑË≥áÊñôÈõÜÔºåËÄå‰∏îÁèæÊúâÁöÑË≥áÊñôÈõÜÈÉΩÊ≤íÊúâÊèê‰æõÂΩ±ÁâáÊ†ºÂºèÁöÑÈ≥•È°ûË°åÁÇ∫Ë©≥Á¥∞Ë®ªËß£„ÄÇÁÇ∫‰∫ÜÂõûÊáâÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÁ¨¨‰∏ÄÂÄãÁ¥∞Á∑ªÁöÑÂΩ±ÁâáË≥áÊñôÈõÜÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈ≥•È°ûË°åÁÇ∫ÂÅµÊ∏¨ÂíåÁâ©Á®ÆÂàÜÈ°û„ÄÇÊ≠§Ë≥áÊñôÈõÜËß£Ê±∫‰∫ÜÂ∞çÂÖ®Èù¢È≥•È°ûÂΩ±ÁâáË≥áÊñôÈõÜÁöÑÈúÄÊ±ÇÔºå‰∏¶Êèê‰æõÈóúÊñºÈ≥•È°ûÂãï‰ΩúÁöÑË©≥Á¥∞Ë≥áÊñôÔºå‰øÉÈÄ≤ÈñãÁôºÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜË≠òÂà•ÈÄô‰∫õÂãï‰ΩúÔºåÈ°û‰ººÊñº‰∫∫È°ûÂãï‰ΩúË≠òÂà•ÊñπÈù¢ÂèñÂæóÁöÑÈÄ≤Â±ï„ÄÇÂª∫Ë≠∞ÁöÑË≥áÊñôÈõÜÂåÖÂê´ 178 ÈÉ®Âú®Ë•øÁè≠ÁâôÊøïÂú∞ÈåÑË£ΩÁöÑÂΩ±ÁâáÔºåÊçïÊçâÂà∞ 13 Á®Æ‰∏çÂêåÁöÑÈ≥•È°ûÂü∑Ë°å 7 Á®Æ‰∏çÂêåÁöÑË°åÁÇ∫È°ûÂà•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑ‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏äÂëàÁèæÂü∫Ê∫ñÁµêÊûúÔºöÈ≥•È°ûË°åÁÇ∫Ë≠òÂà•ÂíåÁâ©Á®ÆÂàÜÈ°û„ÄÇ

##### **Disentangling Exploration of Large Language Models by Optimal Exploitation**
2501.08925v1 by Tim Grams, Patrick Betz, Christian Bartelt

Exploration is a crucial skill for self-improvement and open-ended
problem-solving. However, it remains uncertain whether large language models
can effectively explore the state-space. Existing evaluations predominantly
focus on the trade-off between exploration and exploitation, often assessed in
multi-armed bandit problems. In contrast, this work isolates exploration as the
sole objective, tasking the agent with delivering information that enhances
future returns. For the evaluation, we propose to decompose missing rewards
into exploration and exploitation components by measuring the optimal
achievable return for the states already explored. Our experiments with various
LLMs reveal that most models struggle to sufficiently explore the state-space
and that weak exploration is insufficient. We observe a positive correlation
between model size and exploration performance, with larger models
demonstrating superior capabilities. Furthermore, we show that our
decomposition provides insights into differences in behaviors driven by agent
instructions during prompt engineering, offering a valuable tool for refining
LLM performance in exploratory tasks.

ÊëòË¶ÅÔºöÊé¢Á¥¢ÊòØËá™ÊàëÊèêÂçáÂíåÈñãÊîæÂºèÂïèÈ°åËß£Ê±∫ÁöÑÈóúÈçµÊäÄËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊòØÂê¶ËÉΩÊúâÊïàÊé¢Á¥¢ÁãÄÊÖãÁ©∫Èñì‰ªç‰∏çÁ¢∫ÂÆö„ÄÇÁèæÊúâÁöÑË©ï‰º∞‰∏ªË¶ÅÈóúÊ≥®Êé¢Á¥¢ÂíåÂà©Áî®‰πãÈñìÁöÑÊ¨äË°°ÔºåÈÄöÂ∏∏Âú®Â§öËáÇË≥≠ÂæíÂïèÈ°å‰∏≠ÈÄ≤Ë°åË©ï‰º∞„ÄÇÁõ∏ÂèçÔºåÈÄôÈ†ÖÂ∑•‰ΩúÂ∞áÊé¢Á¥¢Â≠§Á´ãÁÇ∫ÂîØ‰∏ÄÁõÆÊ®ôÔºåË≥¶‰∫à‰ª£ÁêÜ‰∫∫Êèê‰æõÂ¢ûÂº∑Êú™‰æÜÂõûÂ†±ÁöÑË≥áË®äÁöÑ‰ªªÂãô„ÄÇÂ∞çÊñºË©ï‰º∞ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÈÅ∫Â§±ÁöÑÁçéÂãµÂàÜËß£ÁÇ∫Êé¢Á¥¢ÂíåÂà©Áî®ÁµÑÊàêÔºåÊñπÊ≥ïÊòØÊ∏¨ÈáèÂ∑≤Êé¢Á¥¢ÁãÄÊÖãÁöÑÂèØÂØ¶ÁèæÊúÄ‰Ω≥ÂõûÂ†±„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®Æ LLM ÁöÑÂØ¶È©óË°®ÊòéÔºåÂ§ßÂ§öÊï∏Ê®°ÂûãÈõ£‰ª•ÂÖÖÂàÜÊé¢Á¥¢ÁãÄÊÖãÁ©∫ÈñìÔºå‰∏¶‰∏îÊé¢Á¥¢‰∏çË∂≥„ÄÇÊàëÂÄëËßÄÂØüÂà∞Ê®°ÂûãÂ§ßÂ∞èÂíåÊé¢Á¥¢ÊÄßËÉΩ‰πãÈñìÂ≠òÂú®Ê≠£Áõ∏ÈóúÔºåËºÉÂ§ßÁöÑÊ®°ÂûãË°®ÁèæÂá∫Êõ¥Âº∑ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÂàÜËß£Êèê‰æõ‰∫ÜÂ∞çÊèêÁ§∫Â∑•Á®ãÈÅéÁ®ã‰∏≠‰ª£ÁêÜÊåá‰ª§È©ÖÂãïÁöÑË°åÁÇ∫Â∑ÆÁï∞ÁöÑË¶ãËß£ÔºåÁÇ∫ÊîπÈÄ≤Êé¢Á¥¢ÊÄß‰ªªÂãô‰∏≠ÁöÑ LLM ÊÄßËÉΩÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Modeling Melt Pool Features and Spatter Using Symbolic Regression and Machine Learning**
2501.08922v1 by Olabode T. Ajenifujah, Amir Barati Farimani

Additive manufacturing (AM) is a rapidly evolving technology that has
attracted applications across a wide range of fields due to its ability to
fabricate complex geometries. However, one of the key challenges in AM is
achieving consistent print quality. This inconsistency is often attributed to
uncontrolled melt pool dynamics, partly caused by spatter which can lead to
defects. Therefore, capturing and controlling the evolution of the melt pool is
crucial for enhancing process stability and part quality. In this study, we
developed a framework to support decision-making in AM operations, facilitating
quality control and minimizing defects via machine learning (ML) and polynomial
symbolic regression models. We implemented experimentally validated
computational tools as a cost-effective approach to collect large datasets from
laser powder bed fusion (LPBF) processes. For a dataset consisting of 281
process conditions, parameters such as melt pool dimensions (length, width,
depth), melt pool geometry (area, volume), and volume indicated as spatter were
extracted. Using machine learning (ML) and polynomial symbolic regression
models, a high R2 of over 95 % was achieved in predicting the melt pool
dimensions and geometry features for both the training and testing datasets,
with either process conditions (power and velocity) or melt pool dimensions as
the model inputs. In the case of volume indicated as spatter, R2 improved after
logarithmic transforming the model inputs, which was either the process
conditions or the melt pool dimensions. Among the investigated ML models, the
ExtraTree model achieved the highest R2 values of 96.7 % and 87.5 %.

ÊëòË¶ÅÔºöÂ¢ûÊùêË£ΩÈÄ† (AM) ÊòØ‰∏ÄÈ†ÖÂø´ÈÄüÁôºÂ±ïÁöÑÊäÄË°ìÔºåÁî±ÊñºÂÖ∂Ë£ΩÈÄ†Ë§áÈõúÂπæ‰ΩïÂΩ¢ÁãÄÁöÑËÉΩÂäõÔºåÂú®Âª£Ê≥õÁöÑÈ†òÂüü‰∏≠ÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåAM ÁöÑ‰∏ªË¶ÅÊåëÊà∞‰πã‰∏ÄÊòØÂØ¶Áèæ‰∏ÄËá¥ÁöÑÂàóÂç∞ÂìÅË≥™„ÄÇÈÄôÁ®Æ‰∏ç‰∏ÄËá¥ÊÄßÈÄöÂ∏∏Ê≠∏Âõ†ÊñºÁÜîÊ±†ÂãïÂäõÂ≠∏‰∏çÂèóÊéßÔºåÈÉ®ÂàÜÂéüÂõ†ÊòØÈ£õÊø∫ÂèØËÉΩÂ∞éËá¥Áº∫Èô∑„ÄÇÂõ†Ê≠§ÔºåÊçïÊçâÂíåÊéßÂà∂ÁÜîÊ±†ÁöÑÊºîËÆäÂ∞çÊñºÊèêÈ´òË£ΩÁ®ãÁ©©ÂÆöÊÄßÂíåÈõ∂‰ª∂ÂìÅË≥™Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊû∂Êßã‰æÜÊîØÊè¥ AM ‰ΩúÊ•≠‰∏≠ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÈÄèÈÅéÊ©üÂô®Â≠∏Áøí (ML) ÂíåÂ§öÈ†ÖÂºèÁ¨¶ËôüÂõûÊ≠∏Ê®°ÂûãÔºå‰øÉÈÄ≤ÂìÅË≥™ÊéßÁÆ°‰∏¶Â∞áÁº∫Èô∑ÈôçËá≥ÊúÄ‰Ωé„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÁ∂ìÈÅéÂØ¶È©óÈ©óË≠âÁöÑË®àÁÆóÂ∑•ÂÖ∑Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñπÊ≥ïÔºåÂæûÈõ∑Â∞ÑÁ≤âÊú´Â∫äÁÜîÂêà (LPBF) Ë£ΩÁ®ã‰∏≠Êî∂ÈõÜÂ§ßÂûãË≥áÊñôÈõÜ„ÄÇÂ∞çÊñºÁî± 281 ÂÄãË£ΩÁ®ãÊ¢ù‰ª∂ÁµÑÊàêÁöÑË≥áÊñôÈõÜÔºåËêÉÂèñ‰∫ÜÁÜîÊ±†Â∞∫ÂØ∏ÔºàÈï∑Â∫¶„ÄÅÂØ¨Â∫¶„ÄÅÊ∑±Â∫¶Ôºâ„ÄÅÁÜîÊ±†Âπæ‰ΩïÂΩ¢ÁãÄÔºàÈù¢Á©ç„ÄÅÈ´îÁ©çÔºâÂíåÊ®ôÁ§∫ÁÇ∫È£õÊø∫ÁöÑÈ´îÁ©çÁ≠âÂèÉÊï∏„ÄÇ‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂ§öÈ†ÖÂºèÁ¨¶ËôüÂõûÊ≠∏Ê®°ÂûãÔºåÂú®Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰∏≠È†êÊ∏¨ÁÜîÊ±†Â∞∫ÂØ∏ÂíåÂπæ‰ΩïÁâπÂæµÊôÇÔºåÈÅîÂà∞‰∫ÜË∂ÖÈÅé 95% ÁöÑÈ´ò R2ÔºåÊ®°ÂûãËº∏ÂÖ•ÁÇ∫Ë£ΩÁ®ãÊ¢ù‰ª∂ÔºàÂäüÁéáÂíåÈÄüÂ∫¶ÔºâÊàñÁÜîÊ±†Â∞∫ÂØ∏„ÄÇÂú®Ê®ôÁ§∫ÁÇ∫È£õÊø∫ÁöÑÈ´îÁ©çÊÉÖÊ≥Å‰∏ãÔºåÂú®Â∞çÊ®°ÂûãËº∏ÂÖ•ÔºàË£ΩÁ®ãÊ¢ù‰ª∂ÊàñÁÜîÊ±†Â∞∫ÂØ∏ÔºâÈÄ≤Ë°åÂ∞çÊï∏ËΩâÊèõÂæåÔºåR2 ÊúâÊâÄÊèêÂçá„ÄÇÂú®ÊâÄË™øÊü•ÁöÑ ML Ê®°Âûã‰∏≠ÔºåExtraTree Ê®°ÂûãÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑ R2 ÂÄºÔºåÂàÜÂà•ÁÇ∫ 96.7% Âíå 87.5%„ÄÇ

##### **GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text Detection Challenge**
2501.08913v1 by Liam Dugan, Andrew Zhu, Firoj Alam, Preslav Nakov, Marianna Apidianaki, Chris Callison-Burch

Recently there have been many shared tasks targeting the detection of
generated text from Large Language Models (LLMs). However, these shared tasks
tend to focus either on cases where text is limited to one particular domain or
cases where text can be from many domains, some of which may not be seen during
test time. In this shared task, using the newly released RAID benchmark, we aim
to answer whether or not models can detect generated text from a large, yet
fixed, number of domains and LLMs, all of which are seen during training. Over
the course of three months, our task was attempted by 9 teams with 23 detector
submissions. We find that multiple participants were able to obtain accuracies
of over 99% on machine-generated text from RAID while maintaining a 5% False
Positive Rate -- suggesting that detectors are able to robustly detect text
from many domains and models simultaneously. We discuss potential
interpretations of this result and provide directions for future research.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÊúâË®±Â§öÂÖ±Áî®‰ªªÂãôÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁîüÊàêÁöÑÊñáÂ≠óÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂÖ±Áî®‰ªªÂãôÂÇæÂêëÊñºÂ∞àÊ≥®ÊñºÊñáÂ≠óÂÉÖÈôêÊñºÁâπÂÆöÈ†òÂüüÁöÑÊ°à‰æãÔºåÊàñÊñáÂ≠óÂèØËÉΩ‰æÜËá™Ë®±Â§öÈ†òÂüüÁöÑÊ°à‰æãÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÈ†òÂüüÂú®Ê∏¨Ë©¶ÊúüÈñìÂèØËÉΩÁúã‰∏çÂà∞„ÄÇÂú®ÈÄôÂÄãÂÖ±Áî®‰ªªÂãô‰∏≠Ôºå‰ΩøÁî®Êñ∞ÁôºÂ∏ÉÁöÑ RAID Âü∫Ê∫ñÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÂõûÁ≠îÊ®°ÂûãÊòØÂê¶ÂèØ‰ª•ÂæûÂ§ßÈáè‰ΩÜÂõ∫ÂÆöÁöÑÈ†òÂüüÂíå LLM ‰∏≠ÂÅµÊ∏¨ÁîüÊàêÁöÑÊñáÂ≠óÔºåÊâÄÊúâÈÄô‰∫õÂú®Ë®ìÁ∑¥ÊúüÈñìÈÉΩÂèØ‰ª•ÁúãÂà∞„ÄÇÂú®‰∏âÂÄãÊúàÂÖßÔºåÊàëÂÄëÁöÑ‰ªªÂãôÁî± 9 ÂÄãÂúòÈöäÂòóË©¶ÔºåÊèê‰∫§‰∫Ü 23 ÂÄãÂÅµÊ∏¨Âô®„ÄÇÊàëÂÄëÁôºÁèæÔºåÂ§ö‰ΩçÂèÉËàáËÄÖËÉΩÂ§†Âú® RAID ÁöÑÊ©üÂô®ÁîüÊàêÁöÑÊñáÂ≠ó‰∏≠Áç≤ÂæóË∂ÖÈÅé 99% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂêåÊôÇ‰øùÊåÅ 5% ÁöÑË™§Â†±Áéá‚Äî‚ÄîÈÄôË°®ÊòéÂÅµÊ∏¨Âô®ËÉΩÂ§†Á©©ÂÅ•Âú∞ÂêåÊôÇÂÅµÊ∏¨‰æÜËá™Ë®±Â§öÈ†òÂüüÂíåÊ®°ÂûãÁöÑÊñáÂ≠ó„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÂÄãÁµêÊûúÁöÑÊΩõÂú®Ëß£ÈáãÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõÊñπÂêë„ÄÇ</paragraph>

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

ÊëòË¶ÅÔºöËæ®Ë≠òÊùêÊñôÂåñÂ≠∏‰∏≠ÂèØÈù†ÁöÑÂêàÊàêË∑ØÂæëÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑ‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ËÅöÂêàÁâ©ÁßëÂ≠∏‰∏≠ÔºåÂõ†ÁÇ∫Â∑®ÂàÜÂ≠êÁöÑÂëΩÂêçÊ≥ïÈåØÁ∂úË§áÈõú‰∏îÁ∂ìÂ∏∏‰∏çÂîØ‰∏Ä„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁü•Ë≠òÂúñË≠ú (KG) ÁöÑ‰ª£ÁêÜÁ≥ªÁµ±„ÄÇÈÄèÈÅéÂà©Áî® LLM Âº∑Â§ßÁöÑÂåñÂ≠∏Áâ©Ë≥™ÂêçÁ®±ËêÉÂèñÂíåËæ®Ë≠òËÉΩÂäõÔºå‰∏¶Â∞áËêÉÂèñÁöÑË≥áÊñôÂÑ≤Â≠òÂú®ÁµêÊßãÂåñÁöÑÁü•Ë≠òÂúñË≠ú‰∏≠ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂèØÂÆåÂÖ®Ëá™ÂãïÂåñÁõ∏ÈóúÊñáÁçªÁöÑÊ™¢Á¥¢„ÄÅÂèçÊáâË≥áÊñôÁöÑËêÉÂèñ„ÄÅË≥áÊñôÂ∫´Êü•Ë©¢„ÄÅÈÄÜÂêàÊàêË∑ØÂæëÊ®πÁöÑÂª∫Êßã„ÄÅÈÄèÈÅéÊ™¢Á¥¢È°çÂ§ñÊñáÁçªÈÄ≤‰∏ÄÊ≠•Êì¥ÂÖÖÔºå‰ª•ÂèäÊúÄ‰Ω≥ÂèçÊáâË∑ØÂæëÁöÑÂª∫Ë≠∞„ÄÇ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÂàÜÊîØÂèçÊáâË∑ØÂæëÊêúÂ∞ã (MBRPS) ÊºîÁÆóÊ≥ïËÉΩÊé¢Á¥¢ÊâÄÊúâË∑ØÂæëÔºåÁâπÂà•Â∞àÊ≥®ÊñºÂ§öÂàÜÊîØË∑ØÂæëÔºåÂçîÂä© LLM ÂÖãÊúçÂ§öÂàÜÊîØË∑ØÂæë‰∏≠ÁöÑÂº±Êé®ÁêÜ„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ª£Ë°®È¶ñÊ¨°ÂòóË©¶ÈñãÁôº‰∏ÄÁ®ÆÂÆåÂÖ®Ëá™ÂãïÂåñÁöÑÈÄÜÂêàÊàêË¶èÂäÉ‰ª£ÁêÜÔºåÂ∞àÈñÄÈáùÂ∞çÁî± LLM È©ÖÂãïÁöÑÂ∑®ÂàÜÂ≠êÈáèË∫´ÊâìÈÄ†„ÄÇÊáâÁî®ÊñºËÅöÈÜØ‰∫ûËÉ∫ÂêàÊàêÔºåÊàëÂÄëÁöÑÊñ∞ÊñπÊ≥ïÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´Êï∏ÁôæÊ¢ùË∑ØÂæëÁöÑÈÄÜÂêàÊàêË∑ØÂæëÊ®πÔºå‰∏¶Âª∫Ë≠∞ÊúÄ‰Ω≥ÂåñË∑ØÂæëÔºåÂåÖÊã¨Â∑≤Áü•ÂíåÊñ∞Á©éÁöÑË∑ØÂæëÔºåË≠âÊòéÂÖ∂Âú®Êõ¥Âª£Ê≥õÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÂíåÊΩõÂäõ„ÄÇ

##### **Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model**
2501.08878v1 by Runqing Wu, Fei Ye, Qihe Liu, Guoxi Huang, Jinyu Guo, Rongyao Hu

Continual Learning seeks to develop a model capable of incrementally
assimilating new information while retaining prior knowledge. However, current
research predominantly addresses a straightforward learning context, wherein
all data samples originate from a singular data domain. This paper shifts focus
to a more complex and realistic learning environment, characterized by data
samples sourced from multiple distinct domains. We tackle this intricate
learning challenge by introducing a novel methodology, termed the Multi-Source
Dynamic Expansion Model (MSDEM), which leverages various pre-trained models as
backbones and progressively establishes new experts based on them to adapt to
emerging tasks. Additionally, we propose an innovative dynamic expandable
attention mechanism designed to selectively harness knowledge from multiple
backbones, thereby accelerating the new task learning. Moreover, we introduce a
dynamic graph weight router that strategically reuses all previously acquired
parameters and representations for new task learning, maximizing the positive
knowledge transfer effect, which further improves generalization performance.
We conduct a comprehensive series of experiments, and the empirical findings
indicate that our proposed approach achieves state-of-the-art performance.

ÊëòË¶ÅÔºöÊåÅÁ∫åÂ≠∏ÁøíÊó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÊ®°ÂûãÔºåËÉΩÂ§†ÈÄêÊ≠•Âê∏Êî∂Êñ∞Ë≥áË®äÔºåÂêåÊôÇ‰øùÁïôÂÖàÂâçÁöÑÁü•Ë≠ò„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈáùÂ∞çÁõ¥Êé•ÁöÑÂ≠∏ÁøíÁí∞Â¢ÉÔºåÂÖ∂‰∏≠ÊâÄÊúâË≥áÊñôÁØÑ‰æãÈÉΩ‰æÜËá™ÂñÆ‰∏ÄË≥áÊñôÁ∂≤Âüü„ÄÇÊú¨ÊñáÂ∞áÈáçÈªûËΩâÁßªÂà∞Êõ¥Ë§áÈõú‰∏îÊõ¥ÁúüÂØ¶ÁöÑÂ≠∏ÁøíÁí∞Â¢ÉÔºåÂÖ∂ÁâπÈªûÊòØË≥áÊñôÁØÑ‰æã‰æÜËá™Â§öÂÄã‰∏çÂêåÁ∂≤Âüü„ÄÇÊàëÂÄëÈÄèÈÅéÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï‰æÜÊáâÂ∞çÈÄôÂÄãË§áÈõúÁöÑÂ≠∏ÁøíÊåëÊà∞ÔºåÁ®±ÁÇ∫Â§ö‰æÜÊ∫êÂãïÊÖãÊì¥ÂÖÖÊ®°Âûã (MSDEM)ÔºåÂÆÉÂà©Áî®ÂêÑÁ®ÆÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã‰ΩúÁÇ∫‰∏ªÂππÔºå‰∏¶Ê†πÊìöÈÄô‰∫õÊ®°ÂûãÈÄêÊ≠•Âª∫Á´ãÊñ∞ÁöÑÂ∞àÂÆ∂‰ª•ÈÅ©ÊáâÊñ∞Ëàà‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂãïÊÖãÂèØÊì¥ÂÖÖÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÊó®Âú®ÊúâÈÅ∏ÊìáÂú∞Âà©Áî®‰æÜËá™Â§öÂÄã‰∏ªÂππÁöÑÁü•Ë≠òÔºåÂæûËÄåÂä†ÈÄüÊñ∞‰ªªÂãôÁöÑÂ≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂãïÊÖãÂúñÂΩ¢Ê¨äÈáçË∑ØÁî±Âô®ÔºåÂèØÁ≠ñÁï•ÊÄßÂú∞ÈáçË§á‰ΩøÁî®ÊâÄÊúâÂÖàÂâçÁç≤ÂæóÁöÑÂèÉÊï∏ÂíåË°®Á§∫Ôºå‰ª•ÈÄ≤Ë°åÊñ∞ÁöÑ‰ªªÂãôÂ≠∏ÁøíÔºåÊúÄÂ§ßÂåñÊ≠£ÂêëÁü•Ë≠òÂÇ≥ÈÅûÊïàÊûúÔºåÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊ≥õÂåñÊïàËÉΩ„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåËÄåÁ∂ìÈ©óÁôºÁèæË°®ÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts**
2501.08869v1 by Antonio Castellanos, Galit B. Yom-Tov, Yair Goldberg, Jaeyoung Park

In the quest to improve services, companies offer customers the option to
interact with agents via texting. Such contact centers face unique challenges
compared to traditional call centers, as measuring customer experience proxies
like abandonment and patience involves uncertainty. A key source of this
uncertainty is silent abandonment, where customers leave without notifying the
system, wasting agent time and leaving their status unclear. Silent abandonment
also obscures whether a customer was served or left. Our goals are to measure
the magnitude of silent abandonment and mitigate its effects. Classification
models show that 3%-70% of customers across 17 companies abandon silently. In
one study, 71.3% of abandoning customers did so silently, reducing agent
efficiency by 3.2% and system capacity by 15.3%, incurring $5,457 in annual
costs per agent. We develop an expectation-maximization (EM) algorithm to
estimate customer patience under uncertainty and identify influencing
covariates. We find that companies should use classification models to estimate
abandonment scope and our EM algorithm to assess patience. We suggest
strategies to operationally mitigate the impact of silent abandonment by
predicting suspected silent-abandonment behavior or changing service design.
Specifically, we show that while allowing customers to write while waiting in
the queue creates a missing data challenge, it also significantly increases
patience and reduces service time, leading to reduced abandonment and lower
staffing requirements.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜÊîπÂñÑÊúçÂãôÔºåÂÖ¨Âè∏Êèê‰æõÂÆ¢Êà∂ÈÄèÈÅéÁ∞°Ë®äËàáÂÆ¢Êúç‰∫∫Âì°‰∫íÂãïÁöÑÈÅ∏È†Ö„ÄÇÊ≠§È°ûËÅØÁπ´‰∏≠ÂøÉÈù¢Ëá®ÁöÑÊåëÊà∞ËàáÂÇ≥Áµ±ÂëºÂè´‰∏≠ÂøÉ‰∏çÂêåÔºåÂõ†ÁÇ∫Ë°°ÈáèÂÆ¢Êà∂È´îÈ©ó‰ª£ÁêÜÔºå‰æãÂ¶ÇÊîæÊ£ÑÂíåËÄêÂøÉÔºåÊ∂âÂèä‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄ†ÊàêÈÄôÁ®Æ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÈóúÈçµ‰æÜÊ∫êÊòØÈùúÈªòÊîæÊ£ÑÔºåÂÆ¢Êà∂Âú®Êú™ÈÄöÁü•Á≥ªÁµ±ÁöÑÊÉÖÊ≥Å‰∏ãÈõ¢ÈñãÔºåÊµ™Ë≤ªÂÆ¢Êúç‰∫∫Âì°ÊôÇÈñì‰∏¶ËÆì‰ªñÂÄëÁöÑÁãÄÊÖã‰∏çÊòéÁ¢∫„ÄÇÈùúÈªòÊîæÊ£Ñ‰πüÊ®°Á≥ä‰∫ÜÂÆ¢Êà∂ÊòØÁç≤ÂæóÊúçÂãôÈÇÑÊòØÈõ¢Èñã„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØË°°ÈáèÈùúÈªòÊîæÊ£ÑÁöÑË¶èÊ®°‰∏¶Ê∏õËºïÂÖ∂ÂΩ±Èüø„ÄÇÂàÜÈ°ûÊ®°ÂûãÈ°ØÁ§∫Ôºå17 ÂÆ∂ÂÖ¨Âè∏ÁöÑ 3%-70% ÁöÑÂÆ¢Êà∂ÊúÉÈùúÈªòÊîæÊ£Ñ„ÄÇÂú®‰∏ÄÈ†ÖÁ†îÁ©∂‰∏≠Ôºå71.3% ÊîæÊ£ÑÁöÑÂÆ¢Êà∂ÊòØÈùúÈªòÊîæÊ£ÑÔºåÂ∞éËá¥ÂÆ¢Êúç‰∫∫Âì°ÊïàÁéáÈôç‰Ωé 3.2%ÔºåÁ≥ªÁµ±ÂÆπÈáèÈôç‰Ωé 15.3%ÔºåÊØèÂπ¥ÊØè‰ΩçÂÆ¢Êúç‰∫∫Âì°Áî¢Áîü 5,457 ÁæéÂÖÉÁöÑÊàêÊú¨„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊúüÊúõÊúÄÂ§ßÂåñ (EM) ÊºîÁÆóÊ≥ïÔºåÂú®‰∏çÁ¢∫ÂÆöÊÄß‰∏ã‰º∞Ë®àÂÆ¢Êà∂ËÄêÂøÉ‰∏¶ÊâæÂá∫ÂΩ±ÈüøÂçîËÆäÊï∏„ÄÇÊàëÂÄëÁôºÁèæÔºåÂÖ¨Âè∏Êáâ‰ΩøÁî®ÂàÜÈ°ûÊ®°Âûã‰º∞Ë®àÊîæÊ£ÑÁØÑÂúçÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÁöÑ EM ÊºîÁÆóÊ≥ïË©ï‰º∞ËÄêÂøÉ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅéÈ†êÊ∏¨Áñë‰ººÈùúÈªòÊîæÊ£ÑË°åÁÇ∫ÊàñËÆäÊõ¥ÊúçÂãôË®≠Ë®àÔºåÂú®ÁáüÈÅã‰∏äÊ∏õËºïÈùúÈªòÊîæÊ£ÑÁöÑÂΩ±Èüø„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË°®ÊòéÔºåÈõñÁÑ∂ÂÖÅË®±ÂÆ¢Êà∂Âú®ÊéíÈöäÊôÇÂØ´Ë®äÊÅØÊúÉÈÄ†ÊàêÈÅ∫Â§±Ë≥áÊñôÁöÑÊåëÊà∞Ôºå‰ΩÜÂÆÉ‰πüÊúÉÈ°ØËëóÊèêÈ´òËÄêÂøÉ‰∏¶Ê∏õÂ∞ëÊúçÂãôÊôÇÈñìÔºåÂæûËÄåÊ∏õÂ∞ëÊîæÊ£Ñ‰∏¶Èôç‰Ωé‰∫∫Âì°ÈúÄÊ±Ç„ÄÇ</paragraph>

##### **ARMOR: Shielding Unlearnable Examples against Data Augmentation**
2501.08862v1 by Xueluan Gong, Yuji Wang, Yanjiao Chen, Haocheng Dong, Yiming Li, Mengyuan Sun, Shuaike Li, Qian Wang, Chen Chen

Private data, when published online, may be collected by unauthorized parties
to train deep neural networks (DNNs). To protect privacy, defensive noises can
be added to original samples to degrade their learnability by DNNs. Recently,
unlearnable examples are proposed to minimize the training loss such that the
model learns almost nothing. However, raw data are often pre-processed before
being used for training, which may restore the private information of protected
data. In this paper, we reveal the data privacy violation induced by data
augmentation, a commonly used data pre-processing technique to improve model
generalization capability, which is the first of its kind as far as we are
concerned. We demonstrate that data augmentation can significantly raise the
accuracy of the model trained on unlearnable examples from 21.3% to 66.1%. To
address this issue, we propose a defense framework, dubbed ARMOR, to protect
data privacy from potential breaches of data augmentation. To overcome the
difficulty of having no access to the model training process, we design a
non-local module-assisted surrogate model that better captures the effect of
data augmentation. In addition, we design a surrogate augmentation selection
strategy that maximizes distribution alignment between augmented and
non-augmented samples, to choose the optimal augmentation strategy for each
class. We also use a dynamic step size adjustment algorithm to enhance the
defensive noise generation process. Extensive experiments are conducted on 4
datasets and 5 data augmentation methods to verify the performance of ARMOR.
Comparisons with 6 state-of-the-art defense methods have demonstrated that
ARMOR can preserve the unlearnability of protected private data under data
augmentation. ARMOR reduces the test accuracy of the model trained on augmented
protected samples by as much as 60% more than baselines.

ÊëòË¶ÅÔºö<paragraph>Áï∂ÁßÅ‰∫∫Ë≥áÊñôÂú®Á∂≤Ë∑Ø‰∏äÂÖ¨ÈñãÊôÇÔºåÂèØËÉΩÊúÉË¢´Êú™Á∂ìÊéàÊ¨äÁöÑÁ¨¨‰∏âÊñπÊî∂ÈõÜÔºåÁî®ÊñºË®ìÁ∑¥Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN)„ÄÇÁÇ∫‰∫Ü‰øùË≠∑Èö±ÁßÅÔºåÂèØ‰ª•Â∞áÈò≤Á¶¶ÊÄßÈõúË®äÂä†ÂÖ•ÂéüÂßãÊ®£Êú¨‰∏≠Ôºå‰ª•Èôç‰Ωé DNN ÁöÑÂèØÂ≠∏ÁøíÊÄß„ÄÇÊúÄËøëÔºå‰∏çÂèØÂ≠∏ÁøíÁöÑÁØÑ‰æãË¢´ÊèêÂá∫ÔºåÁî®ÊñºÊúÄÂ∞èÂåñË®ìÁ∑¥ÊêçÂ§±Ôºå‰ΩøÊ®°ÂûãÂπæ‰πéÂ≠∏‰∏çÂà∞‰ªª‰ΩïÊù±Ë•ø„ÄÇÁÑ∂ËÄåÔºåÂéüÂßãË≥áÊñôÂú®Áî®ÊñºË®ìÁ∑¥‰πãÂâçÈÄöÂ∏∏ÊúÉÁ∂ìÈÅéÈ†êËôïÁêÜÔºåÈÄôÂèØËÉΩÊúÉÈÇÑÂéüÂèó‰øùË≠∑Ë≥áÊñôÁöÑÁßÅ‰∫∫Ë≥áË®ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊè≠Èú≤‰∫ÜË≥áÊñôÊì¥ÂÖÖÊâÄÂºïÁôºÁöÑË≥áÊñôÈö±ÁßÅ‰æµÂÆ≥ÔºåË≥áÊñôÊì¥ÂÖÖÊòØ‰∏ÄÁ®ÆÂ∏∏Áî®ÁöÑË≥áÊñôÈ†êËôïÁêÜÊäÄË°ìÔºåÁî®ÊñºÊèêÂçáÊ®°ÂûãÊ¶ÇÂåñËÉΩÂäõÔºåÂ∞±ÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÂêåÈ°ûÊäÄË°ì‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄã„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜË≥áÊñôÊì¥ÂÖÖÂèØ‰ª•È°ØËëóÊèêÈ´òÂú®‰∏çÂèØÂ≠∏ÁøíÁöÑÁØÑ‰æã‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂæû 21.3% ÊèêÂçáÂà∞ 66.1%„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ ARMOR ÁöÑÈò≤Á¶¶Êû∂ÊßãÔºå‰ª•‰øùË≠∑Ë≥áÊñôÈö±ÁßÅÂÖçÊñºË≥áÊñôÊì¥ÂÖÖÁöÑÊΩõÂú®‰æµÂÆ≥„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÁÑ°Ê≥ïÂ≠òÂèñÊ®°ÂûãË®ìÁ∑¥ÈÅéÁ®ãÁöÑÂõ∞Èõ£ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈùûÂ±ÄÈÉ®Ê®°ÁµÑËºîÂä©‰ª£ÁêÜÊ®°ÂûãÔºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâË≥áÊñôÊì¥ÂÖÖÁöÑÊïàÊûú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄã‰ª£ÁêÜÊì¥ÂÖÖÈÅ∏ÊìáÁ≠ñÁï•Ôºå‰ª•ÊúÄÂ§ßÂåñÊì¥ÂÖÖÂíåÊú™Êì¥ÂÖÖÊ®£Êú¨‰πãÈñìÁöÑÂàÜÂ∏ÉÂ∞çÈΩäÔºåÁÇ∫ÊØèÂÄãÈ°ûÂà•ÈÅ∏ÊìáÊúÄ‰Ω≥ÁöÑÊì¥ÂÖÖÁ≠ñÁï•„ÄÇÊàëÂÄëÈÇÑ‰ΩøÁî®ÂãïÊÖãÊ≠•Èï∑Ë™øÊï¥ÊºîÁÆóÊ≥ï‰æÜÂ¢ûÂº∑Èò≤Á¶¶ÊÄßÈõúË®äÁîüÊàêÈÅéÁ®ã„ÄÇÂú® 4 ÂÄãË≥áÊñôÈõÜÂíå 5 ÂÄãË≥áÊñôÊì¥ÂÖÖÊñπÊ≥ï‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•È©óË≠â ARMOR ÁöÑÊïàËÉΩ„ÄÇËàá 6 Á®ÆÊúÄÂÖàÈÄ≤ÁöÑÈò≤Á¶¶ÊñπÊ≥ïÁöÑÊØîËºÉÁµêÊûúË°®ÊòéÔºåARMOR ÂèØ‰ª•‰øùÁïôÂèó‰øùË≠∑ÁßÅ‰∫∫Ë≥áÊñôÂú®Ë≥áÊñôÊì¥ÂÖÖ‰∏ãÁöÑ‰∏çÂèØÂ≠∏ÁøíÊÄß„ÄÇËàáÂü∫Á∑öÁõ∏ÊØîÔºåARMOR Â∞áÂú®Êì¥ÂÖÖÁöÑÂèó‰øùË≠∑Ê®£Êú¨‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶Èôç‰Ωé‰∫ÜÂ§öÈÅî 60%„ÄÇ</paragraph>

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÈùíÂ∞ëÂπ¥ÁâπÂà´ÂÆπÊòìÁΩπÊÇ£Á≤æÁ•ûÁñæÁóÖÔºå75% ‰ª•‰∏äÁöÑÁóÖ‰æãÂú® 25 Â≤Å‰πãÂâçÊòæÁé∞„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂè™Êúâ 18% Âà∞ 34% ÁªèÂéÜÈ´òÂ∫¶ÊäëÈÉÅÊàñÁÑ¶ËôëÁóáÁä∂ÁöÑÂπ¥ËΩª‰∫∫ÂØªÊ±ÇÊîØÊåÅ„ÄÇÂà©Áî®Êô∫ËÉΩÊâãÊú∫ÁöÑÊï∞‰ΩçÂ∑•ÂÖ∑Êèê‰æõÂèØÊâ©Â±ïÁöÑÊó©Êúü‰ªãÂÖ•Êú∫‰ºö„ÄÇÁõÆÊ†áÔºöÊú¨Á†îÁ©∂‰ΩøÁî®Êñ∞È¢ñÁöÑÊú∫Âô®Â≠¶‰π†Ê°ÜÊû∂ÔºåËØÑ‰º∞Â∞Ü‰∏ªÂä®ÂíåË¢´Âä®Êô∫ËÉΩÊâãÊú∫Êï∞ÊçÆÊï¥ÂêàÊù•È¢ÑÊµãÈùû‰∏¥Â∫äÈùíÂ∞ëÂπ¥Á≤æÁ•ûÁñæÁóÖÁöÑÂèØË°åÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫Ü Mindcraft Â∫îÁî®Á®ãÂ∫èÂú®È¢ÑÊµãÂÜÖÂåñÂíåÂ§ñÂåñÈöúÁ¢ç„ÄÅÈ•ÆÈ£üÂ§±Ë∞É„ÄÅÂ§±Áú†ÂíåËá™ÊùÄÊÑèÂøµÊñπÈù¢ÁöÑÊïàÁî®„ÄÇÊñπÊ≥ïÔºöÂèÇ‰∏éËÄÖÔºàN=103ÔºõÂπ≥ÂùáÂπ¥ÈæÑ 16.1 Â≤ÅÔºâÊù•Ëá™‰º¶Êï¶ÁöÑ‰∏âÊâÄÂ≠¶Ê†°„ÄÇÂèÇ‰∏éËÄÖÂÆåÊàê‰∫Ü‰ºòÂäøÂíåÂõ∞ÈöæÈóÆÂç∑„ÄÅËøõÈ£üÈöúÁ¢ç-15 ÈóÆÂç∑„ÄÅÁù°Áú†Áä∂ÂÜµÊåáÊ†áÈóÆÂç∑ÔºåÂπ∂ÊåáÂá∫‰∫ÜÊòØÂê¶Â≠òÂú®Ëá™ÊùÄÊÑèÂøµ„ÄÇ‰ªñ‰ª¨‰ΩøÁî® Mindcraft Â∫îÁî®Á®ãÂ∫è 14 Â§©ÔºåÈÄöËøáËá™ÊàëÊä•ÂëäÊèê‰æõ‰∏ªÂä®Êï∞ÊçÆÔºåÂπ∂‰ªéÊô∫ËÉΩÊâãÊú∫‰º†ÊÑüÂô®Êèê‰æõË¢´Âä®Êï∞ÊçÆ„ÄÇÂ∫îÁî®ÂØπÊØîÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊù•Â¢ûÂº∫ÁâπÂÆöÁî®Êà∑ÁöÑÁâπÂæÅÁ®≥ÂÆöÊÄßÔºåÁÑ∂ÂêéËøõË°åÁõëÁù£ÂæÆË∞É„ÄÇÊ®°ÂûãËØÑ‰º∞ÈááÁî®Áïô‰∏ÄÊ≥ï‰∫§ÂèâÈ™åËØÅÔºå‰ΩøÁî®Âπ≥Ë°°ÂáÜÁ°ÆÂ∫¶‰Ωú‰∏∫‰∏ªË¶ÅÊåáÊ†á„ÄÇÁªìÊûúÔºö‰∏é‰∏™Âà´Êï∞ÊçÆÊ∫êÁõ∏ÊØîÔºå‰∏ªÂä®ÂíåË¢´Âä®Êï∞ÊçÆÁöÑÊï¥ÂêàÂÆûÁé∞‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩÔºåSDQ È´òÈ£éÈô©ÁöÑÂπ≥ÂùáÂπ≥Ë°°ÂáÜÁ°ÆÂ∫¶‰∏∫ 0.71ÔºåÂ§±Áú†‰∏∫ 0.67ÔºåËá™ÊùÄÊÑèÂøµ‰∏∫ 0.77ÔºåÈ•ÆÈ£üÂ§±Ë∞É‰∏∫ 0.70„ÄÇÂØπÊØîÂ≠¶‰π†Ê°ÜÊû∂Á®≥ÂÆö‰∫ÜÊØèÊó•Ë°å‰∏∫Ë°®ÂæÅÔºåÂ¢ûÂº∫‰∫ÜÈ¢ÑÊµãÈ≤ÅÊ£íÊÄß„ÄÇÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫ÜÂ∞Ü‰∏ªÂä®ÂíåË¢´Âä®Êô∫ËÉΩÊâãÊú∫Êï∞ÊçÆ‰∏éÂÖàËøõÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÁõ∏ÁªìÂêà‰ª•È¢ÑÊµãÂøÉÁêÜÂÅ•Â∫∑È£éÈô©ÁöÑÊΩúÂäõ„ÄÇ</paragraph>

##### **Graph Counterfactual Explainable AI via Latent Space Traversal**
2501.08850v1 by Andreas Abildtrup Hansen, Paraskevas Pegios, Anna Calissano, Aasa Feragen

Explaining the predictions of a deep neural network is a nontrivial task, yet
high-quality explanations for predictions are often a prerequisite for
practitioners to trust these models. Counterfactual explanations aim to explain
predictions by finding the ''nearest'' in-distribution alternative input whose
prediction changes in a pre-specified way. However, it remains an open question
how to define this nearest alternative input, whose solution depends on both
the domain (e.g. images, graphs, tabular data, etc.) and the specific
application considered. For graphs, this problem is complicated i) by their
discrete nature, as opposed to the continuous nature of state-of-the-art graph
classifiers; and ii) by the node permutation group acting on the graphs. We
propose a method to generate counterfactual explanations for any differentiable
black-box graph classifier, utilizing a case-specific permutation equivariant
graph variational autoencoder. We generate counterfactual explanations in a
continuous fashion by traversing the latent space of the autoencoder across the
classification boundary of the classifier, allowing for seamless integration of
discrete graph structure and continuous graph attributes. We empirically
validate the approach on three graph datasets, showing that our model is
consistently high-performing and more robust than the baselines.

ÊëòË¶ÅÔºöËß£ÈáãÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈ†êÊ∏¨‰∏¶ÈùûÊòì‰∫ãÔºå‰ΩÜÈ´òÂìÅË≥™ÁöÑÈ†êÊ∏¨Ëß£ÈáãÈÄöÂ∏∏ÊòØÂØ¶Âãô‰∫∫Âì°‰ø°Ë≥¥ÈÄô‰∫õÊ®°ÂûãÁöÑÂÖàÊ±∫Ê¢ù‰ª∂„ÄÇÂèç‰∫ãÂØ¶Ëß£ÈáãÊó®Âú®ÈÄèÈÅéÂ∞ãÊâæÈ†êÊ∏¨‰ª•È†êÂÖàÊåáÂÆöÊñπÂºèÊîπËÆäÁöÑ„ÄåÊúÄËøë„ÄçÂêåÂàÜ‰ΩàÊõø‰ª£Ëº∏ÂÖ•Ôºå‰æÜËß£ÈáãÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÂ¶Ç‰ΩïÂÆöÁæ©ÈÄôÂÄãÊúÄËøëÁöÑÊõø‰ª£Ëº∏ÂÖ•‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÂïèÈ°åÔºåÂÖ∂Ëß£Ê±∫ÊñπÊ°àÂèñÊ±∫ÊñºÈ†òÂüüÔºà‰æãÂ¶ÇÂΩ±ÂÉè„ÄÅÂúñË°®„ÄÅË°®Ê†ºË≥áÊñôÁ≠âÔºâÂíåÊâÄËÄÉÊÖÆÁöÑÁâπÂÆöÊáâÁî®Á®ãÂºè„ÄÇÂ∞çÊñºÂúñË°®ËÄåË®ÄÔºåÈÄôÂÄãÂïèÈ°åÁöÑË§áÈõúÊÄßÂú®ÊñºÔºöiÔºâËàáÊúÄÂÖàÈÄ≤ÂúñË°®ÂàÜÈ°ûÂô®ÁöÑÈÄ£Á∫åÊÄßË≥™Áõ∏ÂèçÔºåÂúñË°®ÁöÑÈõ¢Êï£ÊÄßË≥™Ôºõ‰ª•Âèä iiÔºâ‰ΩúÁî®ÊñºÂúñË°®ÁöÑÁØÄÈªûÁΩÆÊèõÁæ§„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ïÔºåÂà©Áî®ÁâπÂÆöÊ°à‰æãÁΩÆÊèõÁ≠âËÆäÂúñË°®ËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®ÔºåÁÇ∫‰ªª‰ΩïÂèØÂæÆÂàÜÁöÑÈªëÁõíÂúñË°®ÂàÜÈ°ûÂô®Áî¢ÁîüÂèç‰∫ãÂØ¶Ëß£Èáã„ÄÇÊàëÂÄëÈÄèÈÅéÂú®ÂàÜÈ°ûÂô®ÂàÜÈ°ûÈÇäÁïå‰∏äÁ©øË∂äËá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÊΩõÂú®Á©∫ÈñìÔºå‰ª•ÈÄ£Á∫åÁöÑÊñπÂºèÁî¢ÁîüÂèç‰∫ãÂØ¶Ëß£ÈáãÔºåÂÖÅË®±Èõ¢Êï£ÂúñË°®ÁµêÊßãÂíåÈÄ£Á∫åÂúñË°®Â±¨ÊÄßÁöÑÁÑ°Á∏´Êï¥Âêà„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÂúñË°®Ë≥áÊñôÈõÜ‰∏äÂØ¶Ë≠âÈ©óË≠â‰∫ÜÊ≠§ÊñπÊ≥ïÔºåÈ°ØÁ§∫ÊàëÂÄëÁöÑÊ®°ÂûãÊïàËÉΩÂßãÁµÇÂæàÈ´òÔºå‰∏îÊØîÂü∫Á∑öÊõ¥Âº∑ÂÅ•„ÄÇ

##### **RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning**
2501.08848v1 by Carlos G√ºemes-Palau, Miquel Ferriol-Galm√©s, Jordi Paillisse-Vilanova, Albert L√≥pez-Bresc√≥, Pere Barlet-Ros, Albert Cabellos-Aparicio

Network simulation is pivotal in network modeling, assisting with tasks
ranging from capacity planning to performance estimation. Traditional
approaches such as Discrete Event Simulation (DES) face limitations in terms of
computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel
integration of a testbed network with a Machine Learning (ML) model to address
these challenges. By using the testbed as a hardware accelerator,
RouteNet-Gauss generates training datasets rapidly and simulates network
scenarios with high fidelity to real-world conditions. Experimental results
show that RouteNet-Gauss significantly reduces prediction errors by up to 95%
and achieves a 488x speedup in inference time compared to state-of-the-art
DES-based methods. RouteNet-Gauss's modular architecture is dynamically
constructed based on the specific characteristics of the network scenario, such
as topology and routing. This enables it to understand and generalize to
different network configurations beyond those seen during training, including
networks up to 10x larger. Additionally, it supports Temporal Aggregated
Performance Estimation (TAPE), providing configurable temporal granularity and
maintaining high accuracy in flow performance metrics. This approach shows
promise in improving both simulation efficiency and accuracy, offering a
valuable tool for network operators.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÊ®°Êì¨Âú®Á∂≤Ë∑ØÂª∫Ê®°‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂçîÂä©Âü∑Ë°åÂæûÂÆπÈáèË¶èÂäÉÂà∞ÊïàËÉΩ‰º∞Ë®àÁöÑ‰ªªÂãô„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶ÇÈõ¢Êï£‰∫ã‰ª∂Ê®°Êì¨ (DES)ÔºâÂú®ÈÅãÁÆóÊàêÊú¨ÂíåÊ∫ñÁ¢∫ÊÄßÊñπÈù¢Èù¢Ëá®ÈôêÂà∂„ÄÇÊú¨Êñá‰ªãÁ¥π RouteNet-GaussÔºå‰∏ÄÁ®ÆÊ∏¨Ë©¶Á∂≤Ë∑ØËàáÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÁöÑÂâµÊñ∞Êï¥ÂêàÔºå‰ª•Ëß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÈÄèÈÅé‰ΩøÁî®Ê∏¨Ë©¶Á∂≤Ë∑Ø‰ΩúÁÇ∫Á°¨È´îÂä†ÈÄüÂô®ÔºåRouteNet-Gauss ËÉΩÂø´ÈÄüÁî¢ÁîüË®ìÁ∑¥Ë≥áÊñôÈõÜÔºå‰∏¶Ê®°Êì¨ËàáÁúüÂØ¶‰∏ñÁïåÊ¢ù‰ª∂È´òÂ∫¶ÂêªÂêàÁöÑÁ∂≤Ë∑ØÂ†¥ÊôØ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåRouteNet-Gauss Â∞áÈ†êÊ∏¨Ë™§Â∑ÆÈ°ØËëóÈôç‰ΩéÈÅî 95%Ôºå‰∏¶‰∏îËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Êñº DES ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊé®ÁêÜÊôÇÈñìÂä†Âø´‰∫Ü 488 ÂÄç„ÄÇRouteNet-Gauss ÁöÑÊ®°ÁµÑÂåñÊû∂ÊßãÊòØÊ†πÊìöÁ∂≤Ë∑ØÂ†¥ÊôØÁöÑÁâπÂÆöÁâπÊÄßÂãïÊÖãÂª∫ÊßãÁöÑÔºå‰æãÂ¶ÇÊãìÊí≤ÂíåË∑ØÁî±„ÄÇÈÄô‰ΩøÂÖ∂ËÉΩÂ§†ÁêÜËß£‰∏¶Ê¶ÇÊã¨Âà∞Ë®ìÁ∑¥ÊúüÈñìÊú™Ë¶ãÁöÑ‰∏çÂêåÁ∂≤Ë∑ØÁµÑÊÖãÔºåÂåÖÊã¨Â§ßËá≥ 10 ÂÄçÁöÑÁ∂≤Ë∑Ø„ÄÇÊ≠§Â§ñÔºåÂÆÉÊîØÊè¥ÊôÇÈñìËÅöÂêàÊïàËÉΩ‰º∞Ë®à (TAPE)ÔºåÊèê‰æõÂèØË®≠ÂÆöÁöÑÊôÇÈñìÁ≤íÂ∫¶Ôºå‰∏¶Âú®ÊµÅÈáèÊïàËÉΩÊåáÊ®ô‰∏≠Á∂≠ÊåÅÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈ°ØÁ§∫Âá∫Âú®ÊîπÂñÑÊ®°Êì¨ÊïàÁéáÂíåÊ∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂæàÊúâÂâçÊôØÔºåÁÇ∫Á∂≤Ë∑ØÁáüÈÅãÂïÜÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Exploring Task-Level Optimal Prompts for Visual In-Context Learning**
2501.08841v1 by Yan Zhu, Huan Ma, Changqing Zhang

With the development of Vision Foundation Models (VFMs) in recent years,
Visual In-Context Learning (VICL) has become a better choice compared to
modifying models in most scenarios. Different from retraining or fine-tuning
model, VICL does not require modifications to the model's weights or
architecture, and only needs a prompt with demonstrations to teach VFM how to
solve tasks. Currently, significant computational cost for finding optimal
prompts for every test sample hinders the deployment of VICL, as determining
which demonstrations to use for constructing prompts is very costly. In this
paper, however, we find a counterintuitive phenomenon that most test samples
actually achieve optimal performance under the same prompts, and searching for
sample-level prompts only costs more time but results in completely identical
prompts. Therefore, we propose task-level prompting to reduce the cost of
searching for prompts during the inference stage and introduce two time-saving
yet effective task-level prompt search strategies. Extensive experimental
results show that our proposed method can identify near-optimal prompts and
reach the best VICL performance with a minimal cost that prior work has never
achieved.

ÊëòË¶ÅÔºöÈö®ËëóËøëÂπ¥‰æÜ Vision Foundation Models (VFMs) ÁöÑÁôºÂ±ïÔºåËàáÂÖ∂Âú®Â§öÊï∏ÊÉÖÊ≥Å‰∏ã‰øÆÊîπÊ®°ÂûãÔºåË¶ñË¶∫ÊÉÖÂ¢ÉÂ≠∏Áøí (VICL) Â∑≤ÊàêÁÇ∫Êõ¥Â•ΩÁöÑÈÅ∏Êìá„ÄÇVICL ËàáÈáçÊñ∞Ë®ìÁ∑¥ÊàñÂæÆË™øÊ®°Âûã‰∏çÂêåÔºåÂÆÉ‰∏çÈúÄË¶Å‰øÆÊîπÊ®°ÂûãÁöÑÊ¨äÈáçÊàñÊû∂ÊßãÔºåÂè™ÈúÄË¶Å‰∏ÄÂÄãÂ∏∂ÊúâÁ§∫ÁØÑÁöÑÊèêÁ§∫‰æÜÊïôÂ∞é VFM Â¶Ç‰ΩïËß£Ê±∫‰ªªÂãô„ÄÇÁõÆÂâçÔºåÁÇ∫ÊØèÂÄãÊ∏¨Ë©¶Ê®£Êú¨Â∞ãÊâæÊúÄ‰Ω≥ÊèêÁ§∫ÁöÑÈ°ØËëóÈÅãÁÆóÊàêÊú¨ÈòªÁ§ô‰∫Ü VICL ÁöÑÈÉ®ÁΩ≤ÔºåÂõ†ÁÇ∫Ê±∫ÂÆöÁî®ÊñºÂª∫ÊßãÊèêÁ§∫ÁöÑÁ§∫ÁØÑ‰ª£ÂÉπÂæàÈ´ò„ÄÇÁÑ∂ËÄåÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰∫Ü‰∏ÄÂÄãÂèçÁõ¥Ë¶∫ÁöÑÁèæË±°ÔºåÂç≥Â§ßÂ§öÊï∏Ê∏¨Ë©¶Ê®£Êú¨ÂØ¶Èöõ‰∏äÂú®Áõ∏ÂêåÁöÑÊèêÁ§∫‰∏ãÈÉΩËÉΩÈÅîÂà∞ÊúÄ‰Ω≥ÊïàËÉΩÔºåËÄå‰∏îÂè™ÊêúÂ∞ãÊ®£Êú¨Â±§Á¥öÁöÑÊèêÁ§∫Âè™ÊúÉËä±Ë≤ªÊõ¥Â§öÊôÇÈñìÔºå‰ΩÜÊúÉÁî¢ÁîüÂÆåÂÖ®Áõ∏ÂêåÁöÑÊèêÁ§∫„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰ªªÂãôÂ±§Á¥öÊèêÁ§∫Ôºå‰ª•Èôç‰ΩéÂú®Êé®Ë´ñÈöéÊÆµÊêúÂ∞ãÊèêÁ§∫ÁöÑÊàêÊú¨Ôºå‰∏¶ÂºïÂÖ•ÂÖ©Á®ÆÁúÅÊôÇ‰∏îÊúâÊïàÁöÑ‰ªªÂãôÂ±§Á¥öÊèêÁ§∫ÊêúÂ∞ãÁ≠ñÁï•„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•Ë≠òÂà•Êé•ËøëÊúÄ‰Ω≥ÁöÑÊèêÁ§∫Ôºå‰∏¶‰ª•ÂÖàÂâçÂ∑•‰ΩúÂæûÊú™ÈÅîÊàêÁöÑÊúÄÂ∞èÊàêÊú¨ÈÅîÂà∞ÊúÄ‰Ω≥ VICL ÊïàËÉΩ„ÄÇ

##### **ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind**
2501.08838v1 by Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Saki Mizuno, Keita Suzuki, Ryo Masumura, Hiroaki Sugiyama, Kuniko Saito

Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in
three aspects: 1) they assess a limited range of mental states such as beliefs,
2) false beliefs are not comprehensively explored, and 3) the diverse
personality traits of characters are overlooked. To address these challenges,
we introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over
conversations. ToMATO is generated via LLM-LLM conversations featuring
information asymmetry. By employing a prompting method that requires
role-playing LLMs to verbalize their thoughts before each utterance, we capture
both first- and second-order mental states across five categories: belief,
intention, desire, emotion, and knowledge. These verbalized thoughts serve as
answers to questions designed to assess the mental states of characters within
conversations. Furthermore, the information asymmetry introduced by hiding
thoughts from others induces the generation of false beliefs about various
mental states. Assigning distinct personality traits to LLMs further
diversifies both utterances and thoughts. ToMATO consists of 5.4k questions,
753 conversations, and 15 personality trait patterns. Our analysis shows that
this dataset construction approach frequently generates false beliefs due to
the information asymmetry between role-playing LLMs, and effectively reflects
diverse personalities. We evaluate nine LLMs on ToMATO and find that even
GPT-4o mini lags behind human performance, especially in understanding false
beliefs, and lacks robustness to various personality traits.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂøÉÊô∫ÁêÜË´ñ (ToM) Âü∫Ê∫ñÂú®‰∏âÂÄãÊñπÈù¢ËàáÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØÊúâÊâÄ‰∏çÂêåÔºö1) ÂÆÉÂÄëË©ï‰º∞ÁöÑÁØÑÂúçÂÉÖÈôêÊñº‰ø°ÂøµÁ≠âÂøÉÊô∫ÁãÄÊÖãÔºå2) Ê≤íÊúâÂÖ®Èù¢Êé¢Ë®éÈåØË™§‰ø°ÂøµÔºå‰ª•Âèä 3) ÂøΩÁï•‰∫ÜËßíËâ≤ÁöÑÂ§öÊ®£Âåñ‰∫∫Ê†ºÁâπË≥™„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ToMATOÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑ ToM Âü∫Ê∫ñÔºå‰ª•Â§öÈÅ∏È°åÂïèÁ≠îÁöÑÂΩ¢ÂºèÂà∂ÂÆöÔºåÂÖßÂÆπÊòØÂ∞çË©±„ÄÇToMATO ÊòØÈÄèÈÅéÂÖ∑ÊúâË≥áË®ä‰∏çÂ∞çÁ®±ÁöÑ LLM-LLM Â∞çË©±ÊâÄÁî¢Áîü„ÄÇÈÄèÈÅéÊé°Áî®‰∏ÄÁ®ÆÊèêÁ§∫ÊñπÊ≥ïÔºåË¶ÅÊ±ÇËßíËâ≤ÊâÆÊºî LLM Âú®ÊØèÊ¨°ÁôºË®ÄÂâçÂ∞áÂÖ∂ÊÉ≥Ê≥ïÂè£È†≠ÂåñÔºåÊàëÂÄëÊçïÊçâÂà∞‰∫Ü‰∫îÁ®ÆÈ°ûÂà•ÁöÑ‰∏ÄÈöéÂíå‰∫åÈöéÂøÉÊô∫ÁãÄÊÖãÔºö‰ø°Âøµ„ÄÅÊÑèÂúñ„ÄÅÊÖæÊúõ„ÄÅÊÉÖÁ∑íÂíåÁü•Ë≠ò„ÄÇÈÄô‰∫õÂè£È†≠ÂåñÁöÑÊÉ≥Ê≥ïÂèØÁî®ÊñºÂõûÁ≠îÂïèÈ°åÔºåÈÄô‰∫õÂïèÈ°åÊó®Âú®Ë©ï‰º∞Â∞çË©±‰∏≠ËßíËâ≤ÁöÑÂøÉÊô∫ÁãÄÊÖã„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÈö±Ëóè‰ªñ‰∫∫ÊÉ≥Ê≥ïÊâÄÁî¢ÁîüÁöÑË≥áË®ä‰∏çÂ∞çÁ®±ÔºåÊúÉÂ∞éËá¥Â∞çÂêÑÁ®ÆÂøÉÊô∫ÁãÄÊÖãÁî¢ÁîüÈåØË™§‰ø°Âøµ„ÄÇÁÇ∫ LLM ÂàÜÈÖç‰∏çÂêåÁöÑÂÄãÊÄßÁâπË≥™ÔºåÈÄ≤‰∏ÄÊ≠•‰ΩøÁôºË®ÄÂíåÊÉ≥Ê≥ïÂ§öÊ®£Âåñ„ÄÇToMATO Áî± 5.4k ÂÄãÂïèÈ°å„ÄÅ753 ÂÄãÂ∞çË©±Âíå 15 Á®ÆÂÄãÊÄßÁâπË≥™Ê®°ÂºèÁµÑÊàê„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÈÄôÁ®ÆË≥áÊñôÈõÜÂª∫ÊßãÊñπÊ≥ïÁî±ÊñºËßíËâ≤ÊâÆÊºî LLM ‰πãÈñìÁöÑË≥áË®ä‰∏çÂ∞çÁ®±ÔºåÁ∂ìÂ∏∏ÊúÉÁî¢ÁîüÈåØË™§‰ø°ÂøµÔºå‰∏¶ÊúâÊïàÂú∞ÂèçÊò†Âá∫‰∏çÂêåÁöÑÂÄãÊÄß„ÄÇÊàëÂÄëÂú® ToMATO ‰∏äË©ï‰º∞‰∫Ü‰πùÂÄã LLMÔºåÁôºÁèæÂç≥‰ΩøÊòØ GPT-4o mini ‰πüËêΩÂæåÊñº‰∫∫È°ûË°®ÁèæÔºåÁâπÂà•ÊòØÂú®ÁêÜËß£ÈåØË™§‰ø°ÂøµÊñπÈù¢Ôºå‰∏¶‰∏îÁº∫‰πèÂ∞çÂêÑÁ®ÆÂÄãÊÄßÁâπË≥™ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ

##### **IDEA: Image Description Enhanced CLIP-Adapter**
2501.08816v1 by Zhipeng Ye, Feng Jiang, Qiufeng Wang, Kaizhu Huang, Jiaqi Huang

CLIP (Contrastive Language-Image Pre-training) has attained great success in
pattern recognition and computer vision. Transferring CLIP to downstream tasks
(e.g. zero- or few-shot classification) is a hot topic in multimodal learning.
However, current studies primarily focus on either prompt learning for text or
adapter tuning for vision, without fully exploiting the complementary
information and correlations among image-text pairs. In this paper, we propose
an Image Description Enhanced CLIP-Adapter (IDEA) method to adapt CLIP to
few-shot image classification tasks. This method captures fine-grained features
by leveraging both visual features and textual descriptions of images. IDEA is
a training-free method for CLIP, and it can be comparable to or even exceeds
state-of-the-art models on multiple tasks. Furthermore, we introduce
Trainable-IDEA (T-IDEA), which extends IDEA by adding two lightweight learnable
components (i.e., a projector and a learnable latent space), further enhancing
the model's performance and achieving SOTA results on 11 datasets. As one
important contribution, we employ the Llama model and design a comprehensive
pipeline to generate textual descriptions for images of 11 datasets, resulting
in a total of 1,637,795 image-text pairs, named "IMD-11". Our code and data are
released at https://github.com/FourierAI/IDEA.

ÊëòË¶ÅÔºöCLIPÔºàÂØπÊØîËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉÔºâÂú®Ê®°ÂºèËØÜÂà´ÂíåËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠ÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂäü„ÄÇÂ∞Ü CLIP ËΩ¨ÁßªÂà∞‰∏ãÊ∏∏‰ªªÂä°Ôºà‰æãÂ¶ÇÈõ∂Ê†∑Êú¨ÊàñÂ∞ëÊ†∑Êú¨ÂàÜÁ±ªÔºâÊòØÂ§öÊ®°ÊÄÅÂ≠¶‰π†‰∏≠ÁöÑÁÉ≠Èó®ËØùÈ¢ò„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÊñáÊú¨ÁöÑÊèêÁ§∫Â≠¶‰π†ÊàñËßÜËßâÁöÑÈÄÇÈÖçÂô®Ë∞ÉÊï¥‰∏äÔºåÂπ∂Êú™ÂÖÖÂàÜÂà©Áî®ÂõæÂÉèÊñáÊú¨ÂØπ‰πãÈó¥ÁöÑ‰∫íË°•‰ø°ÊÅØÂíåÁõ∏ÂÖ≥ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂõæÂÉèÊèèËø∞Â¢ûÂº∫ CLIP ÈÄÇÈÖçÂô® (IDEA) ÊñπÊ≥ïÔºå‰ª•Â∞Ü CLIP ÈÄÇÂ∫î‰∫éÂ∞ëÊ†∑Êú¨ÂõæÂÉèÂàÜÁ±ª‰ªªÂä°„ÄÇÊ≠§ÊñπÊ≥ïÈÄöËøáÂà©Áî®ÂõæÂÉèÁöÑËßÜËßâÁâπÂæÅÂíåÊñáÊú¨ÊèèËø∞Êù•ÊçïÊçâÁªÜÁ≤íÂ∫¶ÁâπÂæÅ„ÄÇIDEA ÊòØ CLIP ÁöÑ‰∏ÄÁßçÊó†ËÆ≠ÁªÉÊñπÊ≥ïÔºåÂπ∂‰∏îÂú®Â§öÈ°π‰ªªÂä°‰∏äÂèØ‰ª•‰∏éÊúÄÂÖàËøõÁöÑÊ®°ÂûãÂ™≤ÁæéÁîöËá≥Ë∂ÖË∂äÂÆÉ‰ª¨„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂèØËÆ≠ÁªÉ IDEA (T-IDEA)ÔºåÂÆÉÈÄöËøáÊ∑ªÂä†‰∏§‰∏™ËΩªÈáèÁ∫ßÂèØÂ≠¶‰π†ÁªÑ‰ª∂ÔºàÂç≥ÊäïÂΩ±‰ª™ÂíåÂèØÂ≠¶‰π†ÊΩúÂú®Á©∫Èó¥ÔºâÊù•Êâ©Â±ï IDEAÔºåËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÂπ∂Âú® 11 ‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü SOTA ÁªìÊûú„ÄÇ‰Ωú‰∏∫‰∏ÄÈ°πÈáçË¶ÅË¥°ÁåÆÔºåÊàë‰ª¨ÈááÁî®‰∫Ü Llama Ê®°ÂûãÂπ∂ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÁªºÂêàÁÆ°ÈÅìÊù•‰∏∫ 11 ‰∏™Êï∞ÊçÆÈõÜÁöÑÂõæÂÉèÁîüÊàêÊñáÊú¨ÊèèËø∞ÔºåÂÖ±‰∫ßÁîü‰∫Ü 1,637,795 ÂØπÂõæÂÉèÊñáÊú¨ÔºåÂêç‰∏∫‚ÄúIMD-11‚Äù„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂíåÊï∞ÊçÆÂ∑≤Âú® https://github.com/FourierAI/IDEA ‰∏äÂèëÂ∏É„ÄÇ

##### **How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering**
2501.08774v1 by Christoph Treude, Marco A. Gerosa

Artificial intelligence (AI), including large language models and generative
AI, is emerging as a significant force in software development, offering
developers powerful tools that span the entire development lifecycle. Although
software engineering research has extensively studied AI tools in software
development, the specific types of interactions between developers and these
AI-powered tools have only recently begun to receive attention. Understanding
and improving these interactions has the potential to improve productivity,
trust, and efficiency in AI-driven workflows. In this paper, we propose a
taxonomy of interaction types between developers and AI tools, identifying
eleven distinct interaction types, such as auto-complete code suggestions,
command-driven actions, and conversational assistance. Building on this
taxonomy, we outline a research agenda focused on optimizing AI interactions,
improving developer control, and addressing trust and usability challenges in
AI-assisted development. By establishing a structured foundation for studying
developer-AI interactions, this paper aims to stimulate research on creating
more effective, adaptive AI tools for software development.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÔºåÂåÖÂê´Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂíåÁîüÊàêÂºè AIÔºåÊ≠£ÊàêÁÇ∫ËªüÈ´îÈñãÁôº‰∏≠‰∏ÄËÇ°ÈáçË¶ÅÁöÑÂäõÈáèÔºåÁÇ∫ÈñãÁôº‰∫∫Âì°Êèê‰æõÊ©´Ë∑®Êï¥ÂÄãÈñãÁôºÁîüÂëΩÈÄ±ÊúüÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÂÑòÁÆ°ËªüÈ´îÂ∑•Á®ãÁ†îÁ©∂Â∑≤Âª£Ê≥õÊé¢Ë®éËªüÈ´îÈñãÁôº‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂ∑•ÂÖ∑Ôºå‰ΩÜÈñãÁôº‰∫∫Âì°ËàáÈÄô‰∫õ AI È©ÖÂãïÂ∑•ÂÖ∑‰πãÈñìÁöÑÁâπÂÆö‰∫íÂãïÈ°ûÂûãÁõ¥Âà∞ÊúÄËøëÊâçÈñãÂßãÂèóÂà∞ÈóúÊ≥®„ÄÇ‰∫ÜËß£ÂíåÊîπÈÄ≤ÈÄô‰∫õ‰∫íÂãïÊúâÊΩõÂäõÊèêÈ´ò AI È©ÖÂãïÂ∑•‰ΩúÊµÅÁ®ãÁöÑÁîüÁî¢Âäõ„ÄÅ‰ø°‰ªªÂíåÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÈñãÁôº‰∫∫Âì°Ëàá AI Â∑•ÂÖ∑‰πãÈñì‰∫íÂãïÈ°ûÂûãÁöÑÂàÜÈ°ûÊ≥ïÔºåÊâæÂá∫ 11 Á®Æ‰∏çÂêåÁöÑ‰∫íÂãïÈ°ûÂûãÔºå‰æãÂ¶ÇËá™ÂãïÂÆåÊàêÁ®ãÂºèÁ¢ºÂª∫Ë≠∞„ÄÅÂëΩ‰ª§È©ÖÂãïÂãï‰ΩúÂíåÂ∞çË©±ÂçîÂä©„ÄÇÊ†πÊìöÊ≠§ÂàÜÈ°ûÊ≥ïÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂ∞àÊ≥®ÊñºÊúÄ‰Ω≥Âåñ AI ‰∫íÂãï„ÄÅÊîπÂñÑÈñãÁôº‰∫∫Âì°ÊéßÂà∂Ôºå‰ª•ÂèäËß£Ê±∫ AI ËºîÂä©ÈñãÁôº‰∏≠ÁöÑ‰ø°‰ªªÂíåÂèØÁî®ÊÄßÊåëÊà∞ÁöÑÁ†îÁ©∂Ë≠∞Á®ã„ÄÇÈÄèÈÅéÁÇ∫Á†îÁ©∂ÈñãÁôº‰∫∫Âì°Ëàá AI ÁöÑ‰∫íÂãïÂª∫Á´ã‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÂü∫Á§éÔºåÊú¨ÊñáÊó®Âú®ÊøÄÂãµÁ†îÁ©∂Ôºå‰ª•ÂâµÈÄ†Êõ¥ÊúâÊïà„ÄÅÊõ¥ÂÖ∑ÈÅ©ÊáâÊÄßÁöÑËªüÈ´îÈñãÁôº AI Â∑•ÂÖ∑„ÄÇ

##### **Enhanced Large Language Models for Effective Screening of Depression and Anxiety**
2501.08769v1 by June M. Liu, Mengxia Gao, Sahand Sabour, Zhuang Chen, Minlie Huang, Tatia M. C. Lee

Depressive and anxiety disorders are widespread, necessitating timely
identification and management. Recent advances in Large Language Models (LLMs)
offer potential solutions, yet high costs and ethical concerns about training
data remain challenges. This paper introduces a pipeline for synthesizing
clinical interviews, resulting in 1,157 interactive dialogues (PsyInterview),
and presents EmoScan, an LLM-based emotional disorder screening system. EmoScan
distinguishes between coarse (e.g., anxiety or depressive disorders) and fine
disorders (e.g., major depressive disorders) and conducts high-quality
interviews. Evaluations showed that EmoScan exceeded the performance of base
models and other LLMs like GPT-4 in screening emotional disorders
(F1-score=0.7467). It also delivers superior explanations (BERTScore=0.9408)
and demonstrates robust generalizability (F1-score of 0.67 on an external
dataset). Furthermore, EmoScan outperforms baselines in interviewing skills, as
validated by automated ratings and human evaluations. This work highlights the
importance of scalable data-generative pipelines for developing effective
mental health LLM tools.

ÊëòË¶ÅÔºöÊÜÇÈ¨±ÁóáÂíåÁÑ¶ÊÖÆÁóáÂçÅÂàÜÊôÆÈÅçÔºåÈúÄË¶ÅÂèäÊôÇË≠òÂà•ÂíåÁÆ°ÁêÜ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊèê‰æõ‰∫ÜÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜË®ìÁ∑¥Ë≥áÊñôÁöÑÈ´òÊàêÊú¨ÂíåÂÄ´ÁêÜÂïèÈ°å‰ªçÁÑ∂ÊòØÊåëÊà∞„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºÂêàÊàêËá®Â∫äË®™Ë´áÁöÑÁÆ°ÈÅìÔºåÁî¢Áîü‰∫Ü 1,157 ÂÄã‰∫íÂãïÂ∞çË©± (PsyInterview)Ôºå‰∏¶Â±ïÁ§∫‰∫Ü EmoScanÔºå‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑÊÉÖÁ∑íÈöúÁ§ôÁØ©Ê™¢Á≥ªÁµ±„ÄÇEmoScan ÂçÄÂàÜ‰∫ÜÁ≤óÁï•ÁöÑÔºà‰æãÂ¶ÇÔºåÁÑ¶ÊÖÆÁóáÊàñÊÜÇÈ¨±ÁóáÔºâÂíåÁ≤æÁ¥∞ÁöÑÈöúÁ§ôÔºà‰æãÂ¶ÇÔºåÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÔºâÔºå‰∏¶ÈÄ≤Ë°åÈ´òÂìÅË≥™ÁöÑË®™Ë´á„ÄÇË©ï‰º∞È°ØÁ§∫ÔºåEmoScan Âú®ÁØ©Ê™¢ÊÉÖÁ∑íÈöúÁ§ôÊñπÈù¢ÂÑ™ÊñºÂü∫Á§éÊ®°ÂûãÂíåÂÖ∂‰ªñ LLMÔºå‰æãÂ¶Ç GPT-4ÔºàF1 ÂàÜÊï∏ = 0.7467Ôºâ„ÄÇÂÆÉÈÇÑÊèê‰æõ‰∫ÜÂÑ™Áï∞ÁöÑËß£ÈáãÔºàBERTScore = 0.9408ÔºâÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂº∑ÂÅ•ÁöÑÊ¶ÇÊã¨ÊÄßÔºàÂú®Â§ñÈÉ®Ë≥áÊñôÈõÜ‰∏äÁöÑ F1 ÂàÜÊï∏ÁÇ∫ 0.67Ôºâ„ÄÇÊ≠§Â§ñÔºåEmoScan Âú®Ë®™Ë´áÊäÄÂ∑ßÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñÔºåÁ∂ìÁî±Ëá™ÂãïË©ïÂàÜÂíå‰∫∫È°ûË©ï‰º∞È©óË≠â„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁ™ÅÈ°Ø‰∫ÜÂèØÊì¥ÂÖÖË≥áÊñôÁîüÊàêÁÆ°ÈÅìÂ∞çÊñºÈñãÁôºÊúâÊïàÁöÑ LLM ÂøÉÁêÜÂÅ•Â∫∑Â∑•ÂÖ∑ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Leveraging LLM Agents for Translating Network Configurations**
2501.08760v1 by Yunze Wei, Xiaohui Xie, Yiwei Zuo, Tianshuo Hu, Xinyi Chen, Kaiwen Chi, Yong Cui

Configuration translation is a critical and frequent task in network
operations. When a network device is damaged or outdated, administrators need
to replace it to maintain service continuity. The replacement devices may
originate from different vendors, necessitating configuration translation to
ensure seamless network operation. However, translating configurations manually
is a labor-intensive and error-prone process. In this paper, we propose an
intent-based framework for translating network configuration with Large
Language Model (LLM) Agents. The core of our approach is an Intent-based
Retrieval Augmented Generation (IRAG) module that systematically splits a
configuration file into fragments, extracts intents, and generates accurate
translations. We also design a two-stage verification method to validate the
syntax and semantics correctness of the translated configurations. We implement
and evaluate the proposed method on real-world network configurations.
Experimental results show that our method achieves 97.74% syntax correctness,
outperforming state-of-the-art methods in translation accuracy.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÊìç‰Ωú‰∏≠ÔºåÁµÑÊÖãËΩâÊèõÊòØ‰∏ÄÈ†ÖÈáçË¶Å‰∏îÈ†ªÁπÅÁöÑ‰ªªÂãô„ÄÇÁï∂Á∂≤Ë∑ØË£ùÁΩÆÊêçÂ£ûÊàñÈÅéÊôÇÔºåÁÆ°ÁêÜÂì°ÈúÄË¶ÅÊõ¥ÊèõÂÆÉ‰ª•Á∂≠ÊåÅÊúçÂãôÁöÑÈÄ£Á∫åÊÄß„ÄÇÊõ¥ÊèõÁöÑË£ùÁΩÆÂèØËÉΩ‰æÜËá™‰∏çÂêåÁöÑ‰æõÊáâÂïÜÔºåÈúÄË¶ÅÈÄ≤Ë°åÁµÑÊÖãËΩâÊèõÔºå‰ª•Á¢∫‰øùÁ∂≤Ë∑ØÊìç‰ΩúÁöÑÈ†ÜÊö¢„ÄÇÁÑ∂ËÄåÔºåÊâãÂãïËΩâÊèõÁµÑÊÖãÊòØ‰∏ÄÂÄãÂãûÂäõÂØÜÈõÜ‰∏îÂÆπÊòìÂá∫ÈåØÁöÑÈÅéÁ®ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊÑèÂúñÁöÑÊû∂ÊßãÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª£ÁêÜ‰æÜËΩâÊèõÁ∂≤Ë∑ØÁµÑÊÖã„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊòØ‰∏ÄÂÄãÂü∫ÊñºÊÑèÂúñÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (IRAG) Ê®°ÁµÑÔºåÂÆÉÊúÉÁ≥ªÁµ±ÊÄßÂú∞Â∞áÁµÑÊÖãÊ™îÊ°àÊãÜÂàÜÁÇ∫ÁâáÊÆµ„ÄÅËêÉÂèñÊÑèÂúñÔºå‰∏¶Áî¢ÁîüÊ∫ñÁ¢∫ÁöÑËΩâÊèõ„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµÈ©óË≠âÊñπÊ≥ïÔºåÁî®ÊñºÈ©óË≠âÂ∑≤ËΩâÊèõÁµÑÊÖãÁöÑË™ûÊ≥ïÂíåË™ûÊÑèÊ≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑÁ∂≤Ë∑ØÁµÑÊÖã‰∏äÂØ¶‰Ωú‰∏¶Ë©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÈÅîÂà∞‰∫Ü 97.74% ÁöÑË™ûÊ≥ïÊ≠£Á¢∫ÊÄßÔºåÂú®ËΩâÊèõÊ∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese Sentiment Analysis Models**
2501.08758v1 by Hong-Viet Tran, Van-Tan Bui, Lam-Quan Tran

Sentiment analysis is one of the most crucial tasks in Natural Language
Processing (NLP), involving the training of machine learning models to classify
text based on the polarity of opinions. Pre-trained Language Models (PLMs) can
be applied to downstream tasks through fine-tuning, eliminating the need to
train the model from scratch. Specifically, PLMs have been employed for
Sentiment Analysis, a process that involves detecting, analyzing, and
extracting the polarity of text sentiments. Numerous models have been proposed
to address this task, with pre-trained PhoBERT-V2 models standing out as the
state-of-the-art language models for Vietnamese. The PhoBERT-V2 pre-training
approach is based on RoBERTa, optimizing the BERT pre-training method for more
robust performance. In this paper, we introduce a novel approach that combines
PhoBERT-V2 and SentiWordnet for Sentiment Analysis of Vietnamese reviews. Our
proposed model utilizes PhoBERT-V2 for Vietnamese, offering a robust
optimization for the prominent BERT model in the context of Vietnamese
language, and leverages SentiWordNet, a lexical resource explicitly designed to
support sentiment classification applications. Experimental results on the VLSP
2016 and AIVIVN 2019 datasets demonstrate that our sentiment analysis system
has achieved excellent performance in comparison to other models.

ÊëòË¶ÅÔºöÊÉÖÊÑüÂàÜÊûêÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÊúÄÈáçË¶ÅÁöÑ‰ªªÂãô‰πã‰∏ÄÔºåÊ∂âÂèäË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°Âûã‰ª•Ê†πÊìöÊÑèË¶ãÁöÑÊ•µÊÄßÂ∞çÊñáÊú¨ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÂèØÈÄèÈÅéÂæÆË™øÊáâÁî®Êñº‰∏ãÊ∏∏‰ªªÂãôÔºåÁÑ°ÈúÄÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥Ê®°Âûã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåPLM Â∑≤Ë¢´Áî®ÊñºÊÉÖÊÑüÂàÜÊûêÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∂âÂèäÊ™¢Ê∏¨„ÄÅÂàÜÊûêÂíåÊèêÂèñÊñáÊú¨ÊÉÖÊÑüÊ•µÊÄßÁöÑÈÅéÁ®ã„ÄÇÂ∑≤Á∂ìÊèêÂá∫‰∫ÜË®±Â§öÊ®°Âûã‰æÜËß£Ê±∫ÈÄôÂÄã‰ªªÂãôÔºåÂÖ∂‰∏≠È†êË®ìÁ∑¥ÁöÑ PhoBERT-V2 Ê®°Âûã‰ΩúÁÇ∫Ë∂äÂçóË™ûÁöÑÊúÄÊñ∞Ë™ûË®ÄÊ®°ÂûãËÄåËÑ´Á©éËÄåÂá∫„ÄÇPhoBERT-V2 È†êË®ìÁ∑¥ÊñπÊ≥ïÂü∫Êñº RoBERTaÔºåÈáùÂ∞çÊõ¥Âº∑Â§ßÁöÑÊïàËÉΩÊúÄ‰Ω≥Âåñ BERT È†êË®ìÁ∑¥ÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÁµêÂêà PhoBERT-V2 Âíå SentiWordnet ÁöÑÊñ∞ÊñπÊ≥ïÔºåÁî®ÊñºË∂äÂçóË©ïË´ñÁöÑÊÉÖÊÑüÂàÜÊûê„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂà©Áî® PhoBERT-V2 ËôïÁêÜË∂äÂçóË™ûÔºåÈáùÂ∞çË∂äÂçóË™ûÂ¢É‰∏≠ÁöÑÁü•Âêç BERT Ê®°ÂûãÊèê‰æõÂº∑Â§ßÁöÑÊúÄ‰Ω≥ÂåñÔºå‰∏¶Âà©Áî® SentiWordNetÔºåÈÄôÊòØ‰∏ÄÂÄãÊòéÁ¢∫Ë®≠Ë®àÁî®ÊñºÊîØÊè¥ÊÉÖÊÑüÂàÜÈ°ûÊáâÁî®Á®ãÂºèÁöÑË©ûÂΩôË≥áÊ∫ê„ÄÇÂú® VLSP 2016 Âíå AIVIVN 2019 Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂÖ∂‰ªñÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑË™ûÊÑèÂàÜÊûêÁ≥ªÁµ±Â∑≤Á∂ìÂèñÂæó‰∫ÜÊ•µ‰Ω≥ÁöÑÊïàËÉΩ„ÄÇ

##### **The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities**
2501.08716v1 by Irina Bigoulaeva, Harish Tayyar Madabushi, Iryna Gurevych

Large Language Models (LLMs), trained on extensive web-scale corpora, have
demonstrated remarkable abilities across diverse tasks, especially as they are
scaled up. Nevertheless, even state-of-the-art models struggle in certain
cases, sometimes failing at problems solvable by young children, indicating
that traditional notions of task complexity are insufficient for explaining LLM
capabilities. However, exploring LLM capabilities is complicated by the fact
that most widely-used models are also "instruction-tuned" to respond
appropriately to prompts. With the goal of disentangling the factors
influencing LLM performance, we investigate whether instruction-tuned models
possess fundamentally different capabilities from base models that are prompted
using in-context examples. Through extensive experiments across various model
families, scales and task types, which included instruction tuning 90 different
LLMs, we demonstrate that the performance of instruction-tuned models is
significantly correlated with the in-context performance of their base
counterparts. By clarifying what instruction-tuning contributes, we extend
prior research into in-context learning, which suggests that base models use
priors from pretraining data to solve tasks. Specifically, we extend this
understanding to instruction-tuned models, suggesting that their pretraining
data similarly sets a limiting boundary on the tasks they can solve, with the
added influence of the instruction-tuning dataset.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âª£Ê≥õÁöÑÁ∂≤Ë∑ØË¶èÊ®°Ë™ûÊñôÂ∫´‰∏äË®ìÁ∑¥ÔºåÂú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®ÂÆÉÂÄëÊì¥Â§ßË¶èÊ®°ÊôÇ„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ã‰πüÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÊúâÊôÇÁîöËá≥ÁÑ°Ê≥ïËß£Ê±∫ÂπºÂÖíÂèØ‰ª•Ëß£Ê±∫ÁöÑÂïèÈ°åÔºåÈÄôË°®Á§∫ÂÇ≥Áµ±‰ªªÂãôË§áÈõúÊÄßÁöÑÊ¶ÇÂøµ‰∏çË∂≥‰ª•Ëß£Èáã LLM ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊé¢Á¥¢ LLM ËÉΩÂäõÊúÉÂõ†ÁÇ∫‰∏ÄÂÄã‰∫ãÂØ¶ËÄåËÆäÂæóË§áÈõúÔºåÈÇ£Â∞±ÊòØÂ§ßÂ§öÊï∏Âª£Ê≥õ‰ΩøÁî®ÁöÑÊ®°Âûã‰πüÁ∂ìÈÅé„ÄåÊåá‰ª§Ë™øÊï¥„ÄçÔºå‰ª•ÈÅ©Áï∂Âú∞ÂõûÊáâÊèêÁ§∫„ÄÇÁÇ∫‰∫ÜËß£ÈñãÂΩ±Èüø LLM ÊïàËÉΩÁöÑÂõ†Á¥†ÔºåÊàëÂÄëË™øÊü•Á∂ìÈÅéÊåá‰ª§Ë™øÊï¥ÁöÑÊ®°ÂûãÊòØÂê¶ÂÖ∑ÂÇôËàá‰ΩøÁî®ÊÉÖÂ¢ÉÁØÑ‰æãÊèêÁ§∫ÁöÑÂü∫Êú¨Ê®°ÂûãÊà™ÁÑ∂‰∏çÂêåÁöÑËÉΩÂäõ„ÄÇÈÄèÈÅéÈáùÂ∞çÂêÑÁ®ÆÊ®°ÂûãÂÆ∂Êóè„ÄÅË¶èÊ®°Âíå‰ªªÂãôÈ°ûÂûãÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÊã¨Â∞ç 90 ÂÄã‰∏çÂêåÁöÑ LLM ÈÄ≤Ë°åÊåá‰ª§Ë™øÊï¥ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÁ∂ìÈÅéÊåá‰ª§Ë™øÊï¥ÁöÑÊ®°ÂûãÁöÑÊïàËÉΩËàáÂÖ∂Âü∫Êú¨Â∞çÊáâÊ®°ÂûãÁöÑÊÉÖÂ¢ÉÊïàËÉΩÈ°ØËëóÁõ∏Èóú„ÄÇÈÄèÈÅéÈáêÊ∏ÖÊåá‰ª§Ë™øÊï¥ÁöÑË≤¢ÁçªÔºåÊàëÂÄëÊì¥Â±ï‰∫ÜÂÖàÂâçÂ∞çÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÁ†îÁ©∂ÔºåÈÄôË°®ÊòéÂü∫Êú¨Ê®°Âûã‰ΩøÁî®È†êË®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑÂÖàÈ©óÁü•Ë≠ò‰æÜËß£Ê±∫‰ªªÂãô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÊ≠§ÁêÜËß£Êì¥Â±ïÂà∞Á∂ìÈÅéÊåá‰ª§Ë™øÊï¥ÁöÑÊ®°ÂûãÔºåÈÄôË°®Êòé‰ªñÂÄëÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñôÂêåÊ®£Ë®≠ÂÆö‰∫Ü‰∏ÄÂÄãÈôêÂà∂ÈÇäÁïåÔºåÈôêÂà∂‰∫Ü‰ªñÂÄëÂèØ‰ª•Ëß£Ê±∫ÁöÑ‰ªªÂãôÔºå‰∏¶Â¢ûÂä†‰∫ÜÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÈõÜÁöÑÂΩ±Èüø„ÄÇ

##### **Self-supervised Transformation Learning for Equivariant Representations**
2501.08712v1 by Jaemyung Yu, Jaehyun Choi, Dong-Jae Lee, HyeongGwon Hong, Junmo Kim

Unsupervised representation learning has significantly advanced various
machine learning tasks. In the computer vision domain, state-of-the-art
approaches utilize transformations like random crop and color jitter to achieve
invariant representations, embedding semantically the same inputs despite
transformations. However, this can degrade performance in tasks requiring
precise features, such as localization or flower classification. To address
this, recent research incorporates equivariant representation learning, which
captures transformation-sensitive information. However, current methods depend
on transformation labels and thus struggle with interdependency and complex
transformations. We propose Self-supervised Transformation Learning (STL),
replacing transformation labels with transformation representations derived
from image pairs. The proposed method ensures transformation representation is
image-invariant and learns corresponding equivariant transformations, enhancing
performance without increased batch complexity. We demonstrate the approach's
effectiveness across diverse classification and detection tasks, outperforming
existing methods in 7 out of 11 benchmarks and excelling in detection. By
integrating complex transformations like AugMix, unusable by prior equivariant
methods, this approach enhances performance across tasks, underscoring its
adaptability and resilience. Additionally, its compatibility with various base
models highlights its flexibility and broad applicability. The code is
available at https://github.com/jaemyung-u/stl.

ÊëòË¶ÅÔºöÁÑ°Áõ£Áù£Ë°®Á§∫Â≠∏ÁøíÂ∑≤Â§ßÂπÖÊèêÂçáÂêÑÁ®ÆÊ©üÂô®Â≠∏Áøí‰ªªÂãô„ÄÇÂú®ÈõªËÖ¶Ë¶ñË¶∫È†òÂüü‰∏≠ÔºåÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÂà©Áî®Èö®Ê©üË£ÅÂâ™ÂíåËâ≤ÂΩ©ÊäñÂãïÁ≠âËΩâÊèõÔºå‰ª•ÈÅîÊàê‰∏çËÆäË°®Á§∫ÔºåÂç≥‰ΩøÁ∂ìÈÅéËΩâÊèõÔºåË™ûÊÑè‰∏äÁõ∏ÂêåÁöÑËº∏ÂÖ•‰ªçÊúÉÂµåÂÖ•„ÄÇÁÑ∂ËÄåÔºåÈÄôÂèØËÉΩÊúÉÈôç‰ΩéÈúÄË¶ÅÁ≤æÁ¢∫ÁâπÂæµÁöÑ‰ªªÂãôÊïàËÉΩÔºå‰æãÂ¶ÇÂÆö‰ΩçÊàñËä±ÂçâÂàÜÈ°û„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊúÄËøëÁöÑÁ†îÁ©∂Á¥çÂÖ•‰∫ÜÁ≠âËÆäË°®Á§∫Â≠∏ÁøíÔºåÈÄôÊì∑Âèñ‰∫ÜÂ∞çËΩâÊèõÊïèÊÑüÁöÑË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºËΩâÊèõÊ®ôÁ±§ÔºåÂõ†Ê≠§Èõ£‰ª•ËôïÁêÜÁõ∏‰∫í‰æùË≥¥ÊÄßÂíåË§áÈõúÁöÑËΩâÊèõ„ÄÇÊàëÂÄëÊèêÂá∫Ëá™Áõ£Áù£ËΩâÊèõÂ≠∏Áøí (STL)Ôºå‰ª•ÂæûÂΩ±ÂÉèÂ∞ç‰∏≠Ë°çÁîüÁöÑËΩâÊèõË°®Á§∫Âèñ‰ª£ËΩâÊèõÊ®ôÁ±§„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁ¢∫‰øùËΩâÊèõË°®Á§∫ÊòØÂΩ±ÂÉè‰∏çËÆäÁöÑÔºå‰∏¶Â≠∏ÁøíÂ∞çÊáâÁöÑÁ≠âËÆäËΩâÊèõÔºåÂú®‰∏çÂ¢ûÂä†ÊâπÊ¨°Ë§áÈõúÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÊèêÂçáÊïàËÉΩ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ≠§ÊñπÊ≥ïÂú®ÂêÑÁ®ÆÂàÜÈ°ûÂíåÂÅµÊ∏¨‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂú® 11 ÂÄãÂü∫Ê∫ñ‰∏≠ÁöÑ 7 ÂÄãË°®ÁèæÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºå‰∏îÂú®ÂÅµÊ∏¨ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÈÄèÈÅéÊï¥ÂêàÂÖàÂâçÁöÑÁ≠âËÆäÊñπÊ≥ïÁÑ°Ê≥ï‰ΩøÁî®ÁöÑË§áÈõúËΩâÊèõÔºå‰æãÂ¶Ç AugMixÔºåÊ≠§ÊñπÊ≥ïÊèêÂçá‰∫ÜÂêÑÁ®Æ‰ªªÂãôÁöÑÊïàËÉΩÔºåÁ™ÅÈ°ØÂÖ∂ÈÅ©ÊáâÊÄßÂíåÈüåÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉËàáÂêÑÁ®ÆÂü∫Á§éÊ®°ÂûãÁöÑÁõ∏ÂÆπÊÄßÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÈùàÊ¥ªÊÄßËàáÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/jaemyung-u/stl ÂèñÂæó„ÄÇ

##### **Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk Differentiation in Chinese Psychological Support Hotlines**
2501.08696v1 by Han Wang, Jianqiang Li, Qing Zhao, Zhonglong Chen, Changwei Song, Jing Tang, Yuning Huang, Wei Zhai, Yongsheng Tong, Guanghui Fu

Mental health is a critical global public health issue, and psychological
support hotlines play a pivotal role in providing mental health assistance and
identifying suicide risks at an early stage. However, the emotional expressions
conveyed during these calls remain underexplored in current research. This
study introduces a method that combines pitch acoustic features with deep
learning-based features to analyze and understand emotions expressed during
hotline interactions. Using data from China's largest psychological support
hotline, our method achieved an F1-score of 79.13% for negative binary emotion
classification.Additionally, the proposed approach was validated on an open
dataset for multi-class emotion classification,where it demonstrated better
performance compared to the state-of-the-art methods. To explore its clinical
relevance, we applied the model to analysis the frequency of negative emotions
and the rate of emotional change in the conversation, comparing 46 subjects
with suicidal behavior to those without. While the suicidal group exhibited
more frequent emotional changes than the non-suicidal group, the difference was
not statistically significant.Importantly, our findings suggest that emotional
fluctuation intensity and frequency could serve as novel features for
psychological assessment scales and suicide risk prediction.The proposed method
provides valuable insights into emotional dynamics and has the potential to
advance early intervention and improve suicide prevention strategies through
integration with clinical tools and assessments The source code is publicly
available at https://github.com/Sco-field/Speechemotionrecognition/tree/main.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊòØÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÁöÑ‰∏ÄÈ†ÖÈáçË¶ÅË≠∞È°åÔºåËÄåÂøÉÁêÜË´ÆË©¢ÁÜ±Á∑öÂú®Êèê‰æõÂøÉÁêÜÂÅ•Â∫∑ÂçîÂä©ÂíåÊó©ÊúüËæ®Ë≠òËá™ÊÆ∫È¢®Èö™‰∏äÊâÆÊºîËëóÈóúÈçµÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÄô‰∫õÈÄöË©±‰∏≠ÊâÄÂÇ≥ÈÅîÁöÑÊÉÖÁ∑íË°®ÈÅîÂú®ÁõÆÂâçÁöÑÁ†îÁ©∂‰∏≠‰ªçÊú™ÂèóÂà∞ÂÖÖÂàÜÁöÑÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁµêÂêàÈü≥È´òËÅ≤Â≠∏ÁâπÂæµËàáÊ∑±Â∫¶Â≠∏ÁøíÁâπÂæµÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÊûêÂíåÁêÜËß£ÁÜ±Á∑ö‰∫íÂãï‰∏≠ÊâÄË°®ÈÅîÁöÑÊÉÖÁ∑í„ÄÇ‰ΩøÁî®‰æÜËá™‰∏≠ÂúãÊúÄÂ§ßÁöÑÂøÉÁêÜË´ÆË©¢ÁÜ±Á∑öÁöÑÊï∏ÊìöÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ë≤†Èù¢‰∫åÂÖÉÊÉÖÁ∑íÂàÜÈ°û‰∏≠ÈÅîÂà∞‰∫Ü 79.13% ÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®‰∏ÄÂÄãÈñãÊîæÁöÑÂ§öÈ°ûÊÉÖÁ∑íÂàÜÈ°ûÊï∏ÊìöÈõÜ‰∏äÂæóÂà∞‰∫ÜÈ©óË≠âÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂÆÉË°®ÁèæÂá∫Êõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÂÖ∂Ëá®Â∫äÁõ∏ÈóúÊÄßÔºåÊàëÂÄëÂ∞áÊ®°ÂûãÊáâÁî®ÊñºÂàÜÊûêË≤†Èù¢ÊÉÖÁ∑íÁöÑÈ†ªÁéáÂíåÂ∞çË©±‰∏≠ÁöÑÊÉÖÁ∑íËÆäÂåñÁéáÔºå‰∏¶Â∞á 46 ÂêçÊúâËá™ÊÆ∫Ë°åÁÇ∫ÁöÑÂèóË©¶ËÄÖËàáÊ≤íÊúâËá™ÊÆ∫Ë°åÁÇ∫ÁöÑÂèóË©¶ËÄÖÈÄ≤Ë°åÊØîËºÉ„ÄÇÈõñÁÑ∂ÊúâËá™ÊÆ∫Ë°åÁÇ∫ÁöÑÁµÑÂà•Ë°®ÁèæÂá∫ÊØîÊ≤íÊúâËá™ÊÆ∫Ë°åÁÇ∫ÁöÑÁµÑÂà•Êõ¥È†ªÁπÅÁöÑÊÉÖÁ∑íËÆäÂåñÔºå‰ΩÜÂ∑ÆÁï∞‰∏¶Êú™ÈÅîÂà∞Áµ±Ë®àÈ°ØËëóÊÄß„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊÉÖÁ∑íÊ≥¢ÂãïÁöÑÂº∑Â∫¶ÂíåÈ†ªÁéáÂèØÁî®‰ΩúÂøÉÁêÜË©ï‰º∞ÈáèË°®ÂíåËá™ÊÆ∫È¢®Èö™È†êÊ∏¨ÁöÑÊñ∞ÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ∞çÊÉÖÁ∑íÂãïÊÖãÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶ÊúâÊΩõÂäõÈÄèÈÅéËàáËá®Â∫äÂ∑•ÂÖ∑ÂíåË©ï‰º∞Êï¥ÂêàÔºåÊé®ÈÄ≤Êó©ÊúüÂπ≤È†ê‰∏¶ÊîπÂñÑËá™ÊÆ∫È†êÈò≤Á≠ñÁï•„ÄÇÂéüÂßãÁ¢ºÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÂú® https://github.com/Sco-field/Speechemotionrecognition/tree/main„ÄÇ

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, B√°lint Moln√°r

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Âü∫ÊñºÁõ∏‰ººÂ∫¶ÁöÑÊ®°ÂºèÊØîÂ∞çÊñπÊ≥ïÁÑ°Ê≥ïËß£Ê±∫ÁâπÂÆöÈ†òÂüüË§áÈõúÊØîÂ∞çÂ†¥ÊôØ‰∏≠ÁöÑË™ûÊÑèÊ®°Á≥äÊÄßÂíåË°ùÁ™ÅÔºåÈÄôÊòØÂõ†ÁÇ∫Áº∫‰πèÂ∏∏Ë≠òÂíåÁâπÂÆöÈ†òÂüüÁü•Ë≠ò„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫ÂïèÈ°å‰πü‰ΩøÂæóÂü∫Êñº LLM ÁöÑÊ®°ÂºèÊØîÂ∞çÈõ£‰ª•Ëß£Ê±∫‰∏äËø∞ÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠úÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊ®°ÂûãÔºåÁî®ÊñºÊ®°ÂºèÊØîÂ∞çÔºåÁ®±ÁÇ∫ KG-RAG4SM„ÄÇÂÖ∑È´îËÄåË®ÄÔºåKG-RAG4SM ÂºïÂÖ•‰∫ÜÂü∫ÊñºÂêëÈáèÁöÑ„ÄÅÂü∫ÊñºÂúñÂΩ¢ÈÅçÊ≠∑ÁöÑÂíåÂü∫ÊñºÊü•Ë©¢ÁöÑÂúñÂΩ¢Ê™¢Á¥¢Ôºå‰ª•Âèä‰∏ÄÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÂíåÊéíÂêçÊñπÊ°àÔºåÈÄô‰∫õÊñπÊ°àÂæûÂ§ñÈÉ®Â§ßÂûãÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠Ë≠òÂà•ÊúÄÁõ∏ÈóúÁöÑÂ≠êÂúñ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂü∫Êñº KG ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ LLM ËÉΩÂ§†Âú®‰∏çÈÄ≤Ë°å‰ªª‰ΩïÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÁÇ∫Ë§áÈõúÁöÑÊØîÂ∞çÊ°à‰æãÁîüÊàêÊõ¥Ê∫ñÁ¢∫ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú® MIMIC Ë≥áÊñôÈõÜ‰∏äÔºåKG-RAG4SM Âú®Ê∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÊñπÈù¢ÂàÜÂà•ÊØîÂü∫Êñº LLM ÁöÑÊúÄÊñ∞ (SOTA) ÊñπÊ≥ï (‰æãÂ¶Ç Jellyfish-8B) È´òÂá∫ 35.89% Âíå 30.50%ÔºõÂÖ∑Êúâ GPT-4o-mini ÁöÑ KG-RAG4SM Âú®Ê∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÊñπÈù¢ÂàÜÂà•ÊØîÂü∫ÊñºÈ†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑ SOTA ÊñπÊ≥ï (‰æãÂ¶Ç SMAT) È´òÂá∫ 69.20% Âíå 21.97% Âú® Synthea Ë≥áÊñôÈõÜ‰∏ä„ÄÇÁµêÊûúÈÇÑË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Á´ØÂà∞Á´ØÊ®°ÂºèÊØîÂ∞ç‰∏≠Êõ¥ÊúâÊïàÁéáÔºå‰∏¶‰∏îÂèØ‰ª•Êì¥Â±ïÂà∞ÂæûÂ§ßÂûã KG ‰∏≠Ê™¢Á¥¢„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ÁèæÂØ¶‰∏ñÁïåÊ®°ÂºèÊØîÂ∞çÂ†¥ÊôØÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÊ°à‰æãÁ†îÁ©∂Ë°®ÊòéÔºåÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÂæàÂ•ΩÂú∞Á∑©Ëß£‰∫Ü LLM Âú®Ê®°ÂºèÊØîÂ∞ç‰∏≠ÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇ

##### **Application of Deep Reinforcement Learning to UAV Swarming for Ground Surveillance**
2501.08655v1 by Ra√∫l Arranz, David Carrami√±ana, Gonzalo de Miguel, Juan A. Besada, Ana M. Bernardos

This paper summarizes in depth the state of the art of aerial swarms,
covering both classical and new reinforcement-learning-based approaches for
their management. Then, it proposes a hybrid AI system, integrating deep
reinforcement learning in a multi-agent centralized swarm architecture. The
proposed system is tailored to perform surveillance of a specific area,
searching and tracking ground targets, for security and law enforcement
applications. The swarm is governed by a central swarm controller responsible
for distributing different search and tracking tasks among the cooperating
UAVs. Each UAV agent is then controlled by a collection of cooperative
sub-agents, whose behaviors have been trained using different deep
reinforcement learning models, tailored for the different task types proposed
by the swarm controller. More specifically, proximal policy optimization (PPO)
algorithms were used to train the agents' behavior. In addition, several
metrics to assess the performance of the swarm in this application were
defined. The results obtained through simulation show that our system searches
the operation area effectively, acquires the targets in a reasonable time, and
is capable of tracking them continuously and consistently.

ÊëòË¶ÅÔºöÊú¨ÊñáÊ∑±ÂÖ•ÊÄªÁªì‰∫ÜÁ©∫‰∏≠ËúÇÁæ§ÁöÑÊúÄÊñ∞ÊäÄÊúØÔºåÊ∂µÁõñ‰∫ÜÁî®‰∫éÁÆ°ÁêÜÁ©∫‰∏≠ËúÇÁæ§ÁöÑÁªèÂÖ∏ÊñπÊ≥ïÂíåÊñ∞ÁöÑÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ÂêéÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊ∑∑Âêà‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªüÔºåÂ∞ÜÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Êï¥ÂêàÂà∞Â§öÊô∫ËÉΩ‰ΩìÈõÜ‰∏≠ËúÇÁæ§Êû∂ÊûÑ‰∏≠„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁªü‰∏ìÈó®Áî®‰∫éÊâßË°åÁâπÂÆöÂå∫ÂüüÁöÑÁõëËßÜ„ÄÅÊêúÁ¥¢ÂíåË∑üË∏™Âú∞Èù¢ÁõÆÊ†áÔºå‰ª•Áî®‰∫éÂÆâÂÖ®ÂíåÊâßÊ≥ïÂ∫îÁî®„ÄÇËúÇÁæ§Áî±‰∏Ä‰∏™‰∏≠Â§ÆËúÇÁæ§ÊéßÂà∂Âô®ÁÆ°ÁêÜÔºåË¥üË¥£Âú®Âêà‰ΩúÊó†‰∫∫Êú∫‰πãÈó¥ÂàÜÈÖç‰∏çÂêåÁöÑÊêúÁ¥¢ÂíåË∑üË∏™‰ªªÂä°„ÄÇÁÑ∂ÂêéÔºåÊØè‰∏™Êó†‰∫∫Êú∫‰ª£ÁêÜÁî±‰∏ÄÁªÑÂçè‰ΩúÂ≠ê‰ª£ÁêÜÊéßÂà∂ÔºåËøô‰∫õÂ≠ê‰ª£ÁêÜÁöÑË°å‰∏∫Â∑≤‰ΩøÁî®‰∏çÂêåÁöÑÊ∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ê®°ÂûãËøõË°åËÆ≠ÁªÉÔºåËøô‰∫õÊ®°ÂûãÈíàÂØπËúÇÁæ§ÊéßÂà∂Âô®ÊèêÂá∫ÁöÑ‰∏çÂêå‰ªªÂä°Á±ªÂûãÈáèË∫´ÂÆöÂà∂„ÄÇÊõ¥ÂÖ∑‰ΩìÂú∞ËØ¥ÔºåËøëÁ´ØÁ≠ñÁï•‰ºòÂåñ (PPO) ÁÆóÊ≥ïÁî®‰∫éËÆ≠ÁªÉ‰ª£ÁêÜË°å‰∏∫„ÄÇÊ≠§Â§ñÔºåËøòÂÆö‰πâ‰∫ÜÂá†‰∏™ÊåáÊ†áÊù•ËØÑ‰º∞ËúÇÁæ§Âú®Ê≠§Â∫îÁî®‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÈÄöËøá‰ªøÁúüËé∑ÂæóÁöÑÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÁ≥ªÁªüÊúâÊïàÂú∞ÊêúÁ¥¢‰∫ÜÊìç‰ΩúÂå∫ÂüüÔºåÂú®ÂêàÁêÜÁöÑÊó∂Èó¥ÂÜÖËé∑Âèñ‰∫ÜÁõÆÊ†áÔºåÂπ∂‰∏îËÉΩÂ§üÊåÅÁª≠‰∏çÊñ≠Âú∞Ë∑üË∏™ÁõÆÊ†á„ÄÇ

##### **Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor Graph**
2501.08653v1 by Wang-Tao Zhou, Zhao Kang, Sicong Liu, Lizong Zhang, Ling Tian

Event prediction tasks often handle spatio-temporal data distributed in a
large spatial area. Different regions in the area exhibit different
characteristics while having latent correlations. This spatial heterogeneity
and correlations greatly affect the spatio-temporal distributions of event
occurrences, which has not been addressed by state-of-the-art models. Learning
spatial dependencies of events in a continuous space is challenging due to its
fine granularity and a lack of prior knowledge. In this work, we propose a
novel Graph Spatio-Temporal Point Process (GSTPP) model for fine-grained event
prediction. It adopts an encoder-decoder architecture that jointly models the
state dynamics of spatially localized regions using neural Ordinary
Differential Equations (ODEs). The state evolution is built on the foundation
of a novel Self-Adaptive Anchor Graph (SAAG) that captures spatial
dependencies. By adaptively localizing the anchor nodes in the space and
jointly constructing the correlation edges between them, the SAAG enhances the
model's ability of learning complex spatial event patterns. The proposed GSTPP
model greatly improves the accuracy of fine-grained event prediction. Extensive
experimental results show that our method greatly improves the prediction
accuracy over existing spatio-temporal event prediction approaches.

ÊëòË¶ÅÔºö‰∫ã‰ª∂È¢ÑÊµã‰ªªÂãôÈÄöÂ∏∏ÊúÉËôïÁêÜÂàÜÂ∏ÉÂú®Âª£ÈóäÁ©∫ÈñìÂçÄÂüü‰∏≠ÁöÑÊôÇÁ©∫Ë≥áÊñô„ÄÇË©≤ÂçÄÂüü‰∏≠ÁöÑ‰∏çÂêåÂçÄÂüüË°®ÁèæÂá∫‰∏çÂêåÁöÑÁâπÂæµÔºåÂêåÊôÇÂÖ∑ÊúâÊΩõÂú®Áõ∏ÈóúÊÄß„ÄÇÈÄôÁ®ÆÁ©∫ÈñìÁï∞Ë≥™ÊÄßÂíåÁõ∏ÈóúÊÄßÊ•µÂ§ßÂú∞ÂΩ±Èüø‰∫Ü‰∫ã‰ª∂ÁôºÁîüÁöÑÊôÇÁ©∫ÂàÜ‰ΩàÔºåËÄåÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂ∞öÊú™Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÁî±Êñº‰∫ã‰ª∂Âú®ÈÄ£Á∫åÁ©∫Èñì‰∏≠ÁöÑÁ≤æÁ¥∞Á≤íÂ∫¶ÂíåÁº∫‰πèÂÖàÈ©óÁü•Ë≠òÔºåÂ≠∏Áøí‰∫ã‰ª∂ÁöÑÁ©∫Èñì‰æùË≥¥ÊÄßÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂúñÂΩ¢ÊôÇÁ©∫ÈªûÈÅéÁ®ã (GSTPP) Ê®°ÂûãÔºåÁî®ÊñºÁ≤æÁ¥∞ÁöÑ‰∫ã‰ª∂È†êÊ∏¨„ÄÇÂÆÉÊé°Áî®Á∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂ÊßãÔºå‰ΩøÁî®Á•ûÁ∂ìÂ∏∏ÂæÆÂàÜÊñπÁ®ã (ODE) ËÅØÂêàÂª∫Ê®°Á©∫ÈñìÂÆö‰ΩçÂçÄÂüüÁöÑÁãÄÊÖãÂãïÊÖã„ÄÇÁãÄÊÖãÊºîÂåñÂª∫Á´ãÂú®Êñ∞ÁöÑËá™ÈÅ©ÊáâÈå®ÂÆöÂúñ (SAAG) ÁöÑÂü∫Á§é‰∏äÔºåË©≤ÂúñÊçïÊçâ‰∫ÜÁ©∫Èñì‰æùË≥¥ÊÄß„ÄÇÈÄöÈÅéËá™ÈÅ©ÊáâÂú∞ÂÆö‰ΩçÁ©∫Èñì‰∏≠ÁöÑÈå®ÂÆöÁØÄÈªû‰∏¶ËÅØÂêàÊßãÈÄ†ÂÆÉÂÄë‰πãÈñìÁöÑÁõ∏ÈóúÈÇäÁ∑£ÔºåSAAG Â¢ûÂº∑‰∫ÜÊ®°ÂûãÂ≠∏ÁøíË§áÈõúÁ©∫Èñì‰∫ã‰ª∂Ê®°ÂºèÁöÑËÉΩÂäõ„ÄÇÊèêÂá∫ÁöÑ GSTPP Ê®°ÂûãÂ§ßÂ§ßÊèêÈ´ò‰∫ÜÁ≤æÁ¥∞‰∫ã‰ª∂È†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊØîÁèæÊúâÁöÑÊôÇÁ©∫‰∫ã‰ª∂È†êÊ∏¨ÊñπÊ≥ïÂ§ßÂ§ßÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄß„ÄÇ

##### **MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities**
2501.08648v1 by Savya Khosla, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi

While originally designed for unidirectional generative modeling,
decoder-only large language models (LLMs) are increasingly being adapted for
bidirectional modeling. However, unidirectional and bidirectional models are
typically trained separately with distinct objectives (generation and
representation learning, respectively). This separation overlooks the
opportunity for developing a more versatile language model and for these
objectives to complement each other. In this work, we introduce MAGNET, an
adaptation of decoder-only LLMs that enhances their ability to generate robust
representations and infill missing text spans, while preserving their knowledge
and text generation capabilities. MAGNET employs three self-supervised training
objectives and introduces an attention mechanism that combines bidirectional
and causal attention, enabling unified training across all objectives. Our
results demonstrate that LLMs adapted with MAGNET (1) surpass strong text
encoders on token-level and sentence-level representation learning tasks, (2)
generate contextually appropriate text infills by leveraging future context,
(3) retain the ability for open-ended text generation without exhibiting
repetition problem, and (4) preserve the knowledge gained by the LLM during
pretraining.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄÂàùÊòØÁÇ∫ÂñÆÂêëÁîüÊàêÂºèÂª∫Ê®°ËÄåË®≠Ë®àÔºå
ÂÉÖËß£Á¢ºÂô®ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÂçªÊó•ÁõäË¢´ÊîπÁ∑®ÁÇ∫
ÈõôÂêëÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÂñÆÂêëÂíåÈõôÂêëÊ®°Âûã
ÈÄöÂ∏∏ÊúÉ‰ª•‰∏çÂêåÁöÑÁõÆÊ®ôÔºàÂàÜÂà•ÁÇ∫Áî¢ÁîüÂíå
Ë°®Á§∫Â≠∏ÁøíÔºâÂàÜÈñãË®ìÁ∑¥„ÄÇÈÄôÁ®ÆÂàÜÈõ¢ÂøΩË¶ñ‰∫Ü
ÈñãÁôºÊõ¥ÈÄöÁî®Ë™ûË®ÄÊ®°ÂûãÁöÑÊ©üÊúÉÔºå‰ª•ÂèäÈÄô‰∫õ
ÁõÆÊ®ôÁõ∏‰∫íË£úÂÖÖÁöÑÊ©üÊúÉ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MAGNETÔºå‰∏ÄÁ®ÆÂÉÖËß£Á¢ºÂô® LLM ÁöÑÊîπÁ∑®ÔºåÂÆÉÂ¢ûÂº∑‰∫ÜÂÆÉÂÄëÁîüÊàêÁ©©ÂÅ•
Ë°®Á§∫ÂíåÂ°´Ë£úÁº∫Â§±ÊñáÂ≠óÂçÄÊÆµÁöÑËÉΩÂäõÔºåÂêåÊôÇ‰øùÁïôÂÆÉÂÄëÁöÑÁü•Ë≠ò
ÂíåÊñáÂ≠óÁîüÊàêËÉΩÂäõ„ÄÇMAGNET Êé°Áî®‰∏âÂÄãËá™ÊàëÁõ£Áù£Ë®ìÁ∑¥
ÁõÆÊ®ôÔºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÁµêÂêàÈõôÂêë
ÂíåÂõ†ÊûúÊ≥®ÊÑèÂäõÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåËÆìÊâÄÊúâÁõÆÊ®ôÈÉΩËÉΩÈÄ≤Ë°åÁµ±‰∏ÄË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑ
ÁµêÊûúË≠âÊòé‰ΩøÁî® MAGNET ÊîπÁ∑®ÁöÑ LLM (1) Âú®Ê®ôË®òÂ±§Á¥öÂíåÂè•Â≠êÂ±§Á¥öË°®Á§∫Â≠∏Áøí‰ªªÂãô‰∏≠Ë∂ÖË∂äÂº∑Â§ßÁöÑÊñáÂ≠ó
Á∑®Á¢ºÂô®Ôºå(2)
Âà©Áî®Êú™‰æÜÂÖßÂÆπÁî¢ÁîüÈÅ©Áï∂ÁöÑÊñáÂ≠óÂ°´Ë£úÔºå
(3) ‰øùÁïôÈÄ≤Ë°åÈñãÊîæÂºèÊñáÂ≠óÁîüÊàêÁöÑËÉΩÂäõÔºåËÄå‰∏çÊúÉÂá∫Áèæ
ÈáçË§áÁöÑÂïèÈ°åÔºå‰ª•Âèä (4) ‰øùÁïô LLM Âú®
È†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂæóÁöÑÁü•Ë≠ò„ÄÇ

##### **Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations**
2501.08641v1 by Kaiyuan Zheng, Qinghua Zhao, Lei Li

The relationship between language and thought remains an unresolved
philosophical issue. Existing viewpoints can be broadly categorized into two
schools: one asserting their independence, and another arguing that language
constrains thought. In the context of large language models, this debate raises
a crucial question: Does a language model's grasp of semantic meaning depend on
thought processes? To explore this issue, we investigate whether reasoning
techniques can facilitate semantic understanding. Specifically, we
conceptualize thought as reasoning, employ chain-of-thought prompting as a
reasoning technique, and examine its impact on sentiment analysis tasks. The
experiments show that chain-of-thought has a minimal impact on sentiment
analysis tasks. Both the standard and chain-of-thought prompts focus on aspect
terms rather than sentiment in the generated content. Furthermore,
counterfactual experiments reveal that the model's handling of sentiment tasks
primarily depends on information from demonstrations. The experimental results
support the first viewpoint.

ÊëòË¶ÅÔºöË™ûË®ÄËàáÊÄùËÄÉ‰πãÈñìÁöÑÈóú‰øÇ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊú™Ëß£Ê±∫ÁöÑÂì≤Â≠∏ÂïèÈ°å„ÄÇÁèæÊúâÁöÑËßÄÈªûÂ§ßËá¥ÂèØÂàÜÁÇ∫ÂÖ©Ê¥æÔºö‰∏ÄÊ¥æ‰∏ªÂºµÂÆÉÂÄëÁöÑÁç®Á´ãÊÄßÔºåÂè¶‰∏ÄÊ¥æÂâáË™çÁÇ∫Ë™ûË®ÄÁ¥ÑÊùü‰∫ÜÊÄùËÄÉ„ÄÇÂú®Â§ßË™ûË®ÄÊ®°ÂûãÁöÑËÉåÊôØ‰∏ãÔºåÈÄôÁ®ÆÁà≠Ë´ñÂºïÁôº‰∫Ü‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÔºöË™ûË®ÄÊ®°ÂûãÂ∞çË™ûÁæ©ÊÑèÁæ©ÁöÑÊéåÊè°ÊòØÂê¶‰æùË≥¥ÊñºÊÄùËÄÉÈÅéÁ®ãÔºüÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÊé®ÁêÜÊäÄË°ìÊòØÂê¶ÂèØ‰ª•‰øÉÈÄ≤Ë™ûÁæ©ÁêÜËß£„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÊÄùËÄÉÊ¶ÇÂøµÂåñÁÇ∫Êé®ÁêÜÔºåÊé°Áî®ÊÄùÊÉ≥ÈèàÊèêÁ§∫‰ΩúÁÇ∫Êé®ÁêÜÊäÄË°ìÔºå‰∏¶Ê™¢È©óÂÖ∂Â∞çÊÉÖÁ∑íÂàÜÊûê‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÂØ¶È©óË°®ÊòéÔºåÊÄùÊÉ≥ÈèàÂ∞çÊÉÖÁ∑íÂàÜÊûê‰ªªÂãôÁöÑÂΩ±ÈüøÂæàÂ∞è„ÄÇÊ®ôÊ∫ñÊèêÁ§∫ÂíåÊÄùÊÉ≥ÈèàÊèêÁ§∫ÈÉΩÂÅ¥ÈáçÊñºÁîüÊàêÁöÑÂÖßÂÆπ‰∏≠ÁöÑÊñπÈù¢Ë°ìË™ûÔºåËÄå‰∏çÊòØÊÉÖÁ∑í„ÄÇÊ≠§Â§ñÔºåÂèç‰∫ãÂØ¶ÂØ¶È©óË°®ÊòéÔºåÊ®°ÂûãÂ∞çÊÉÖÁ∑í‰ªªÂãôÁöÑËôïÁêÜ‰∏ªË¶Å‰æùË≥¥ÊñºÊºîÁ§∫‰∏≠ÁöÑ‰ø°ÊÅØ„ÄÇÂØ¶È©óÁµêÊûúÊîØÊåÅÁ¨¨‰∏ÄÂÄãËßÄÈªû„ÄÇ

##### **SWSC: Shared Weight for Similar Channel in LLM**
2501.08631v1 by Binrui Zeng, Yongtao Tang, Xiaodong Liu, Xiaopeng Li

Large language models (LLMs) have spurred development in multiple industries.
However, the growing number of their parameters brings substantial storage and
computing burdens, making it essential to explore model compression techniques
for parameter reduction and easier deployment. We propose SWSC, an LLM
compression method based on the concept of Shared Weight for Similar Channel.
It uses the K-Means clustering algorithm to cluster model weights
channel-by-channel, generating clusters with highly similar vectors within
each. A representative vector from each cluster is selected to approximately
replace all vectors in the cluster, significantly reducing the number of model
weight parameters. However, approximate restoration will inevitably cause
damage to the performance of the model. To tackle this issue, we perform
singular value decomposition on the weight error values before and after
compression and retain the larger singular values and their corresponding
singular vectors to compensate for the accuracy. The experimental results show
that our method can effectively ensure the performance of the compressed LLM
even under low-precision conditions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤‰øÉ‰ΩøÂ§öÂÄãÁî¢Ê•≠ÁôºÂ±ï„ÄÇ
ÁÑ∂ËÄåÔºåÂÖ∂ÂèÉÊï∏Êï∏Èáè‰∏çÊñ∑Â¢ûÂä†ÔºåÂ∏∂‰æÜÈæêÂ§ßÁöÑÂÑ≤Â≠òÂíåÈÅãÁÆóË≤†ÊìîÔºåÂõ†Ê≠§Êé¢Á¥¢Ê®°ÂûãÂ£ìÁ∏ÆÊäÄË°ì‰ª•Ê∏õÂ∞ëÂèÉÊï∏‰∏¶Á∞°ÂåñÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫ SWSCÔºå‰∏ÄÁ®ÆÂü∫ÊñºÁõ∏‰ººÈÄöÈÅìÂÖ±‰∫´Ê¨äÈáçÁöÑ LLM Â£ìÁ∏ÆÊñπÊ≥ï„ÄÇ
ÂÆÉ‰ΩøÁî® K-Means ËÅöÈ°ûÊºîÁÆóÊ≥ïÂ∞çÊ®°ÂûãÊ¨äÈáçÈÄêÈÄöÈÅìËÅöÈ°ûÔºåÂú®ÊØèÂÄãÈÄöÈÅìÂÖßÁî¢ÁîüÂÖ∑ÊúâÈ´òÂ∫¶Áõ∏‰ººÂêëÈáèÁöÑËÅöÈ°û„ÄÇÂæûÊØèÂÄãËÅöÈ°û‰∏≠ÈÅ∏Âèñ‰∏ÄÂÄã‰ª£Ë°®ÂêëÈáè‰æÜËøë‰ººÊõøÊèõËÅöÈ°û‰∏≠ÁöÑÊâÄÊúâÂêëÈáèÔºåÂ§ßÂπÖÊ∏õÂ∞ëÊ®°ÂûãÊ¨äÈáçÂèÉÊï∏ÁöÑÊï∏Èáè„ÄÇÁÑ∂ËÄåÔºåËøë‰ººÈÇÑÂéü‰∏çÂèØÈÅøÂÖçÂú∞ÊúÉÊêçÂÆ≥Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®Â£ìÁ∏ÆÂâçÂæåÂ∞çÊ¨äÈáçË™§Â∑ÆÂÄºÂü∑Ë°åÂ•áÁï∞ÂÄºÂàÜËß£Ôºå‰∏¶‰øùÁïôËºÉÂ§ßÁöÑÂ•áÁï∞ÂÄºÂèäÂÖ∂Â∞çÊáâÁöÑÂ•áÁï∞ÂêëÈáè‰ª•Ë£úÂÑüÊ∫ñÁ¢∫Â∫¶„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂç≥‰ΩøÂú®‰ΩéÁ≤æÂ∫¶Ê¢ù‰ª∂‰∏ãÔºåÊàëÂÄëÁöÑÊñπÊ≥ï‰πüËÉΩÊúâÊïàÁ¢∫‰øùÂ£ìÁ∏Æ LLM ÁöÑÊïàËÉΩ„ÄÇ

##### **ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair**
2501.08621v1 by Hong-Viet Tran, Minh-Quy Nguyen, Van-Vinh Nguyen

This paper presents an results of the VLSP 2022-2023 Machine Translation
Shared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine
translation. The tasks were organized as part of the 9th, 10th annual workshop
on Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The
objective of the shared task was to build machine translation systems,
specifically targeting Vietnamese-Chinese and Vietnamese-Lao translation
(corresponding to 4 translation directions). The submission were evaluated on
1,000 pairs for testing (news and general domains) using established metrics
like BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were
evaluated with human judgment provided by experts in Chinese and Lao languages.
These human assessments played a crucial role in ranking the performance of the
machine translation models, ensuring a more comprehensive evaluation.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü VLSP 2022-2023 Ê©üÂô®ÁøªË≠ØÂÖ±‰∫´‰ªªÂãôÁöÑÁµêÊûúÔºåÈáçÈªûÈóúÊ≥®Ë∂äÂçóË™û-‰∏≠ÊñáÂíåË∂äÂçóË™û-ÂØÆË™ûÊ©üÂô®ÁøªË≠Ø„ÄÇÈÄô‰∫õ‰ªªÂãôÊòØ‰ΩúÁÇ∫Á¨¨ 9 Â±Ü„ÄÅÁ¨¨ 10 Â±ÜË∂äÂçóË™ûË®ÄÂíåË™ûÈü≥ËôïÁêÜÂπ¥Â∫¶Á†îË®éÊúÉ (VLSP 2022„ÄÅVLSP 2023) ÁöÑ‰∏ÄÈÉ®ÂàÜ‰æÜÁµÑÁπîÁöÑ„ÄÇÂÖ±‰∫´‰ªªÂãôÁöÑÁõÆÊ®ôÊòØÂª∫ÊßãÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±ÔºåÁâπÂà•ÈáùÂ∞çË∂äÂçóË™û-‰∏≠ÊñáÂíåË∂äÂçóË™û-ÂØÆË™ûÁøªË≠ØÔºàÂ∞çÊáâ 4 ÂÄãÁøªË≠ØÊñπÂêëÔºâ„ÄÇÊèê‰∫§ÂÖßÂÆπ‰ΩøÁî®Êó¢ÂÆöÁöÑÊåáÊ®ôÔºà‰æãÂ¶Ç BLEU [11] Âíå SacreBLEU [12]ÔºâÈáùÂ∞ç 1,000 Â∞çÊ∏¨Ë©¶Â∞çÔºàÊñ∞ËÅûÂíå‰∏ÄËà¨È†òÂüüÔºâÈÄ≤Ë°åË©ï‰º∞„ÄÇÊ≠§Â§ñÔºåÁ≥ªÁµ±Ëº∏Âá∫‰πüÁî±‰∏≠ÊñáÂíåÂØÆË™ûÂ∞àÂÆ∂Êèê‰æõÁöÑ‰∫∫È°ûÂà§Êñ∑ÈÄ≤Ë°åË©ï‰º∞„ÄÇÈÄô‰∫õ‰∫∫È°ûË©ï‰º∞Âú®Â∞çÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÊïàËÉΩÈÄ≤Ë°åÊéíÂêçÊôÇÁôºÊèÆ‰∫ÜËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®ÔºåÁ¢∫‰øù‰∫ÜÊõ¥ÂÖ®Èù¢ÁöÑË©ï‰º∞„ÄÇ

##### **Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models**
2501.08618v1 by Aruna Sankaranarayanan, Dylan Hadfield-Menell, Aaron Mueller

All natural languages are structured hierarchically. In humans, this
structural restriction is neurologically coded: when two grammars are presented
with identical vocabularies, brain areas responsible for language processing
are only sensitive to hierarchical grammars. Using large language models
(LLMs), we investigate whether such functionally distinct hierarchical
processing regions can arise solely from exposure to large-scale language
distributions. We generate inputs using English, Italian, Japanese, or nonce
words, varying the underlying grammars to conform to either hierarchical or
linear/positional rules. Using these grammars, we first observe that language
models show distinct behaviors on hierarchical versus linearly structured
inputs. Then, we find that the components responsible for processing
hierarchical grammars are distinct from those that process linear grammars; we
causally verify this in ablation experiments. Finally, we observe that
hierarchy-selective components are also active on nonce grammars; this suggests
that hierarchy sensitivity is not tied to meaning, nor in-distribution inputs.

ÊëòË¶ÅÔºöÊâÄÊúâËá™ÁÑ∂Ë™ûË®ÄÈÉΩÊòØÂ±§Á¥öÁµêÊßãÁöÑ„ÄÇÂú®‰∫∫È°ûË∫´‰∏äÔºåÈÄôÁ®ÆÁµêÊßãÈôêÂà∂ÊòØÁî±Á•ûÁ∂ìÁ∑®Á¢ºÁöÑÔºöÁï∂ÂÖ©ÂÄãÊñáÊ≥ïË¢´Ë≥¶‰∫àÁõ∏ÂêåÁöÑË©ûÂΩôÊôÇÔºåË≤†Ë≤¨Ë™ûË®ÄËôïÁêÜÁöÑÂ§ßËÖ¶ÂçÄÂüüÂè™Â∞çÂ±§Á¥öÊñáÊ≥ïÊïèÊÑü„ÄÇ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊàëÂÄëÁ†îÁ©∂ÈÄôÁ®ÆÂäüËÉΩ‰∏ä‰∏çÂêåÁöÑÂ±§Á¥öËôïÁêÜÂçÄÂüüÊòØÂê¶ÂÉÖËÉΩÂæûÊé•Ëß∏Â§ßË¶èÊ®°Ë™ûË®ÄÂàÜ‰Ωà‰∏≠Áî¢Áîü„ÄÇÊàëÂÄë‰ΩøÁî®Ëã±Ë™û„ÄÅÁæ©Â§ßÂà©Ë™û„ÄÅÊó•Ë™ûÊàñËôõÊßãË©ûÂΩôÁî¢ÁîüËº∏ÂÖ•ÔºåÊîπËÆäÂü∫Á§éÊñáÊ≥ï‰ª•Á¨¶ÂêàÂ±§Á¥öÊàñÁ∑öÊÄß/‰ΩçÁΩÆË¶èÂâá„ÄÇ‰ΩøÁî®ÈÄô‰∫õÊñáÊ≥ïÔºåÊàëÂÄëÈ¶ñÂÖàËßÄÂØüÂà∞Ë™ûË®ÄÊ®°ÂûãÂú®Â±§Á¥öÁµêÊßãÁöÑËº∏ÂÖ•ËàáÁ∑öÊÄßÁµêÊßãÁöÑËº∏ÂÖ•‰∏äË°®ÁèæÂá∫‰∏çÂêåÁöÑË°åÁÇ∫„ÄÇÊé•ËëóÔºåÊàëÂÄëÁôºÁèæËôïÁêÜÂ±§Á¥öÊñáÊ≥ïÁöÑÁµÑÊàêÈÉ®ÂàÜËàáËôïÁêÜÁ∑öÊÄßÊñáÊ≥ïÁöÑÁµÑÊàêÈÉ®ÂàÜ‰∏çÂêåÔºõÊàëÂÄëÂú®Ê∂àËûçÂØ¶È©ó‰∏≠Âõ†ÊûúÈ©óË≠â‰∫ÜÈÄô‰∏ÄÈªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëËßÄÂØüÂà∞Â±§Á¥öÈÅ∏ÊìáÊÄßÁµÑÊàêÈÉ®ÂàÜÂú®ËôõÊßãÊñáÊ≥ï‰∏≠‰πüÊ¥ªË∫çÔºõÈÄôË°®Á§∫Â±§Á¥öÊïèÊÑüÊÄßËàáÊÑèÁæ©ÊàñÂàÜ‰Ωà‰∏≠ÁöÑËº∏ÂÖ•ÁÑ°Èóú„ÄÇ

##### **RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation**
2501.08617v1 by Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fern√°ndez Fisac

Generative AI systems like foundation models (FMs) must align well with human
values to ensure their behavior is helpful and trustworthy. While Reinforcement
Learning from Human Feedback (RLHF) has shown promise for optimizing model
performance using human judgments, existing RLHF pipelines predominantly rely
on immediate feedback, which can fail to accurately reflect the downstream
impact of an interaction on users' utility. We demonstrate that feedback based
on evaluators' foresight estimates of downstream consequences systematically
induces Goodhart's Law dynamics, incentivizing misaligned behaviors like
sycophancy and deception and ultimately degrading user outcomes. To alleviate
this, we propose decoupling evaluation from prediction by refocusing RLHF on
hindsight feedback. Our theoretical analysis reveals that conditioning
evaluator feedback on downstream observations mitigates misalignment and
improves expected human utility, even when these observations are simulated by
the AI system itself. To leverage this insight in a practical alignment
algorithm, we introduce Reinforcement Learning from Hindsight Simulation
(RLHS), which first simulates plausible consequences and then elicits feedback
to assess what behaviors were genuinely beneficial in hindsight. We apply RLHS
to two widely-employed online and offline preference optimization methods --
Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) --
and show empirically that misalignment is significantly reduced with both
methods. Through an online human user study, we show that RLHS consistently
outperforms RLHF in helping users achieve their goals and earns higher
satisfaction ratings, despite being trained solely with simulated hindsight
feedback. These results underscore the importance of focusing on long-term
consequences, even simulated ones, to mitigate misalignment in RLHF.

ÊëòË¶ÅÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÔºåÂ¶ÇÂü∫Á§éÊ®°Âûã (FM)ÔºåÂøÖÈ†àËàá‰∫∫È°ûÂÉπÂÄºËßÄ‰øùÊåÅ‰∏ÄËá¥Ôºå‰ª•Á¢∫‰øùÂÖ∂Ë°åÁÇ∫ÊòØÊúâÂπ´Âä©‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑ„ÄÇÈõñÁÑ∂ÈÄèÈÅé‰∫∫È°ûÂõûÈ•ãÈÄ≤Ë°åÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∑≤È°ØÁ§∫Âá∫Âà©Áî®‰∫∫È°ûÂà§Êñ∑‰æÜÊúÄ‰Ω≥ÂåñÊ®°ÂûãÊïàËÉΩÁöÑÂèØËÉΩÊÄßÔºå‰ΩÜÁèæÊúâÁöÑ RLHF ÁÆ°Á∑ö‰∏ªË¶Å‰æùË≥¥Âç≥ÊôÇÂõûÈ•ãÔºåÈÄôÂèØËÉΩÁÑ°Ê≥ïÊ∫ñÁ¢∫ÂèçÊò†‰∫íÂãïÂ∞ç‰ΩøÁî®ËÄÖÊïàÁî®ÁöÑ‰∏ãÊ∏∏ÂΩ±Èüø„ÄÇÊàëÂÄëË≠âÊòéÔºåÂü∫ÊñºË©ï‰º∞ËÄÖÂ∞ç‰∏ãÊ∏∏ÂæåÊûúÁöÑÂâçÁûªÊÄß‰º∞Ë®àÁöÑÂõûÈ•ãÁ≥ªÁµ±ÊÄßÂú∞Ë™òÁôºÂè§Âæ∑ÂìàÁâπÂÆöÂæãÂãïÊÖãÔºåÈºìÂãµÊãçÈ¶¨Â±ÅÂíåÊ¨∫È®ôÁ≠â‰∏ç‰∏ÄËá¥ÁöÑË°åÁÇ∫Ôºå‰∏¶ÊúÄÁµÇÈôç‰Ωé‰ΩøÁî®ËÄÖÊàêÊûú„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅéÈáçÊñ∞ÈóúÊ≥® RLHF Âú®‰∫ãÂæåÂõûÈ•ã‰∏ä‰æÜËß£Èô§Ë©ï‰º∞ËàáÈ†êÊ∏¨ÁöÑÈóúËÅØ„ÄÇÊàëÂÄëÁöÑÁêÜË´ñÂàÜÊûêË°®ÊòéÔºåÂú®Ë©ï‰º∞ËÄÖÂõûÈ•ã‰∏≠Âä†ÂÖ•‰∏ãÊ∏∏ËßÄÂØüÁµêÊûúÂèØ‰ª•Ê∏õËºï‰∏ç‰∏ÄËá¥ÊÄßÔºå‰∏¶ÊèêÈ´òÈ†êÊúüÁöÑ‰ΩøÁî®ËÄÖÊïàÁî®ÔºåÂç≥‰ΩøÈÄô‰∫õËßÄÂØüÁµêÊûúÊòØÁî± AI Á≥ªÁµ±Êú¨Ë∫´Ê®°Êì¨ÁöÑ„ÄÇÁÇ∫‰∫ÜÂú®ÂØ¶ÈöõÂ∞çÈΩäÊºîÁÆóÊ≥ï‰∏≠ÈÅãÁî®ÈÄôÂÄãË¶ãËß£ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∫ãÂæåÊ®°Êì¨Âº∑ÂåñÂ≠∏Áøí (RLHS)ÔºåÂÆÉÊúÉÂÖàÊ®°Êì¨ÂêàÁêÜÁöÑÂæåÊûúÔºåÁÑ∂ÂæåÂºïÁôºÂõûÈ•ãÔºå‰ª•Ë©ï‰º∞Âì™‰∫õË°åÁÇ∫Âú®‰∫ãÂæåÁúüÁöÑÊúâÁõä„ÄÇÊàëÂÄëÂ∞á RLHS ÊáâÁî®ÊñºÂÖ©Á®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑÁ∑ö‰∏äÂíåÈõ¢Á∑öÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ï‚Äî‚ÄîËøëÁ´ØÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (PPO) ÂíåÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)‚Äî‚Äî‰∏¶ÈÄèÈÅéÂØ¶Ë≠âÈ°ØÁ§∫ÔºåÈÄôÂÖ©Á®ÆÊñπÊ≥ïÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÈÉΩÈ°ØËëóÈôç‰Ωé„ÄÇÈÄèÈÅé‰∏ÄÈ†ÖÁ∑ö‰∏ä‰∫∫È°û‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÊàëÂÄëË≠âÊòé‰∫Ü RLHS Âú®Âπ´Âä©‰ΩøÁî®ËÄÖÈÅîÊàêÁõÆÊ®ôÊñπÈù¢ÂßãÁµÇÂÑ™Êñº RLHFÔºå‰∏¶Áç≤ÂæóÊõ¥È´òÁöÑÊªøÊÑèÂ∫¶Ë©ïÂàÜÔºåÂÑòÁÆ°ÂÉÖ‰ΩøÁî®Ê®°Êì¨‰∫ãÂæåÂõûÈ•ãÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÈóúÊ≥®Èï∑ÊúüÂæåÊûúÔºàÂç≥‰ΩøÊòØÊ®°Êì¨ÁöÑÂæåÊûúÔºâ‰ª•Ê∏õËºï RLHF ‰∏≠‰∏ç‰∏ÄËá¥ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v1 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

ÊëòË¶ÅÔºöÊúÄËøë‰ª•Â∑•ÂÖ∑Â¢ûÂº∫ÂûãÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Ëß£ÂÜ≥ÈÄªËæëÊé®ÁêÜÈóÆÈ¢òÁöÑÊñ∞ÂÖ¥ËåÉ‰æãÂà©Áî®‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÈôàËø∞Âà∞‰∏ÄÈò∂ÈÄªËæë (FOL) ÂíåÂ§ñÈÉ®ÂÆöÁêÜËØÅÊòéÂô®ÁöÑËΩ¨Âåñ„ÄÇÁÑ∂ËÄåÔºåFOL ÈôàËø∞ÁöÑÊ≠£Á°ÆÊÄßÔºàÂåÖÊã¨ÁÆóÂ≠êÂíåÊñáÊú¨Ë∞ìËØçÔºâÈÄöÂ∏∏Âõ†Áº∫‰πèÁî®‰∫éÊØîËæÉÁîüÊàêÁöÑ FOL ÂíåÁúüÂÆû FOL ÁöÑÂèØÈù†ËØÑ‰º∞ÊåáÊ†áËÄåÊó†Ê≥ïÂæóÂà∞È™åËØÅ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂØπÁé∞ÊúâÊåáÊ†áÁöÑÊïèÊÑüÊÄßÂèäÂÖ∂‰∏é‰∫∫Á±ªÂØπ FOL ËØÑ‰º∞Âà§Êñ≠ÁöÑ‰∏ÄËá¥ÊÄßËøõË°å‰∫ÜÂÖ®Èù¢Á†îÁ©∂„ÄÇ‰ΩøÁî®ÁúüÂÆû FOLÔºåÊàë‰ª¨Á≤æÂøÉËÆæËÆ°‰∫ÜÂØπÁúüÂÆû FOL ÁöÑÂêÑÁßçÊâ∞Âä®Êù•ËØÑ‰º∞ÊåáÊ†áÊïèÊÑüÊÄß„ÄÇÊàë‰ª¨ÂØπËá™ÁÑ∂ËØ≠Ë®ÄÈôàËø∞ÊäΩÊ†∑ FOL ÁøªËØëÂÄôÈÄâÔºåÂπ∂ÊµãÈáèËá™Âä®ÊåáÊ†áÂíå‰∫∫Á±ªÊ≥®ÈáäËÄÖ‰πãÈó¥ÁöÑÊéíÂêç‰∏ÄËá¥ÊÄß„ÄÇÊàë‰ª¨ÁöÑÁªèÈ™åÁªìÊûúÁ™ÅÂá∫‰∫Ü n-gram ÊåáÊ†á BLEU ÂØπÊñáÊú¨Êâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß„ÄÅËØ≠‰πâÂõæÊåáÊ†á Smatch++ ÂØπÁªìÊûÑÊâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß‰ª•Âèä FOL ÊåáÊ†áÂØπÁÆóÂ≠êÊâ∞Âä®ÁöÑËøáÂ∫¶ÊïèÊÑüÊÄß„ÄÇÊàë‰ª¨ËøòËßÇÂØüÂà∞ BertScore ‰∏é‰∫∫Á±ªÂà§Êñ≠‰πãÈó¥Êõ¥Á¥ßÂØÜÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ë°®ÊòéÔºå‰∏é‰ΩøÁî®Âçï‰∏™ÊåáÊ†áÁõ∏ÊØîÔºåÁªÑÂêàÊåáÊ†áÂèØ‰ª•ÊèêÈ´ò‰∏ÄËá¥ÊÄßÂíåÊïèÊÑüÊÄß„ÄÇ

##### **Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design**
2501.08603v1 by Zhi Zheng, Zhuoliang Xie, Zhenkun Wang, Bryan Hooi

Handcrafting heuristics for solving complex planning tasks (e.g., NP-hard
combinatorial optimization (CO) problems) is a common practice but requires
extensive domain knowledge. Recently, Large Language Model (LLM)-based
automatic heuristics design (AHD) methods have shown promise in generating
high-quality heuristics without manual intervention. Existing LLM-based AHD
methods employ a population to maintain a fixed number of top-performing
LLM-generated heuristics and introduce evolutionary computation (EC) to enhance
the population iteratively. However, the population-based procedure brings
greedy properties, often resulting in convergence to local optima. Instead, to
more comprehensively explore the space of heuristics, we propose using Monte
Carlo Tree Search (MCTS) for LLM-based heuristic evolution while preserving all
LLM-generated heuristics in a tree structure. With a novel thought-alignment
process and an exploration-decay technique, the proposed MCTS-AHD method
delivers significantly higher-quality heuristics on various complex tasks. Our
code is available at https://github.com/zz1358m/MCTS-AHD-master.

ÊëòË¶ÅÔºöÊâãÂ∑•Âà∂ÂÆöÂêØÂèëÂºèÊñπÊ≥ïÊù•Ëß£ÂÜ≥Â§çÊùÇÁöÑËßÑÂàí‰ªªÂä°Ôºà‰æãÂ¶ÇÔºåNP Âõ∞ÈöæÁöÑÁªÑÂêà‰ºòÂåñ (CO) ÈóÆÈ¢òÔºâÊòØ‰∏ÄÁßçÂ∏∏ËßÅÁöÑÂÅöÊ≥ïÔºå‰ΩÜÈúÄË¶ÅÂπøÊ≥õÁöÑÈ¢ÜÂüüÁü•ËØÜ„ÄÇÊúÄËøëÔºåÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑËá™Âä®ÂêØÂèëÂºèËÆæËÆ° (AHD) ÊñπÊ≥ïÂú®Êó†ÈúÄ‰∫∫Â∑•Âπ≤È¢ÑÁöÑÊÉÖÂÜµ‰∏ãÁîüÊàêÈ´òË¥®ÈáèÂêØÂèëÂºèÊñπÈù¢ÊòæÁ§∫Âá∫ÂâçÊôØ„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫é LLM ÁöÑ AHD ÊñπÊ≥ïÈááÁî®ÁßçÁæ§Êù•Áª¥ÊåÅ‰∏ÄÂÆöÊï∞ÈáèÁöÑÊÄßËÉΩÊúÄ‰Ω≥ÁöÑ LLM ÁîüÊàêÁöÑÂêØÂèëÂºèÊñπÊ≥ïÔºåÂπ∂ÂºïÂÖ•ËøõÂåñËÆ°ÁÆó (EC) Êù•Ëø≠‰ª£Â¢ûÂº∫ÁßçÁæ§„ÄÇÁÑ∂ËÄåÔºåÂü∫‰∫éÁßçÁæ§ÁöÑËøáÁ®ãÂ∏¶Êù•‰∫ÜË¥™Â©™Â±ûÊÄßÔºåÈÄöÂ∏∏‰ºöÂØºËá¥Êî∂ÊïõÂà∞Â±ÄÈÉ®ÊúÄ‰ºò„ÄÇÁõ∏ÂèçÔºå‰∏∫‰∫ÜÊõ¥ÂÖ®Èù¢Âú∞Êé¢Á¥¢ÂêØÂèëÂºèÁ©∫Èó¥ÔºåÊàë‰ª¨Âª∫ËÆÆÂú®Âü∫‰∫é LLM ÁöÑÂêØÂèëÂºèËøõÂåñ‰∏≠‰ΩøÁî®ËíôÁâπÂç°ÁΩóÊ†ëÊêúÁ¥¢ (MCTS)ÔºåÂêåÊó∂Â∞ÜÊâÄÊúâ LLM ÁîüÊàêÁöÑÂêØÂèëÂºè‰øùÂ≠òÂú®Ê†ëÁªìÊûÑ‰∏≠„ÄÇÈÄöËøáÊñ∞È¢ñÁöÑÊÄùÊÉ≥ÂØπÈΩêËøáÁ®ãÂíåÊé¢Á¥¢Ë°∞ÂáèÊäÄÊúØÔºåÊâÄÊèêÂá∫ÁöÑ MCTS-AHD ÊñπÊ≥ïÂú®ÂêÑÁßçÂ§çÊùÇ‰ªªÂä°‰∏äÊèê‰æõ‰∫ÜÊòéÊòæÊõ¥È´òË¥®ÈáèÁöÑÂêØÂèëÂºèÊñπÊ≥ï„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/zz1358m/MCTS-AHD-master Ëé∑Âæó„ÄÇ

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

ÊëòË¶ÅÔºöÈö®Ëëó REST API Âú®Áèæ‰ª£Á∂≤Ë∑ØÊúçÂãô‰∏≠Âª£Ê≥õ‰ΩøÁî®ÔºåÂ∞çÈÄô‰∫õ API ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÊ∏¨Ë©¶ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÁî±ÊñºÂª£Â§ßÁöÑÊêúÂ∞ãÁ©∫ÈñìÂåÖÂê´Êìç‰Ωú„ÄÅÂèÉÊï∏ÂíåÂèÉÊï∏ÂÄº‰ª•ÂèäÂÆÉÂÄëË§áÈõúÁöÑ‰æùË≥¥Èóú‰øÇÂíåÁ¥ÑÊùüÔºåÁõÆÂâçÁöÑÊ∏¨Ë©¶Â∑•ÂÖ∑Â≠òÂú®Á®ãÂºèÁ¢ºË¶ÜËìãÁéá‰ΩéÁöÑÂïèÈ°åÔºåÂ∞éËá¥ÊïÖÈöúÂÅµÊ∏¨‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Â∑•ÂÖ∑ AutoRestTestÔºåÂÆÉÊï¥Âêà‰∫ÜË™ûÁæ©Êìç‰Ωú‰æùË≥¥Âúñ (SODG) ËàáÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ REST API Ê∏¨Ë©¶„ÄÇAutoRestTest ‰ΩøÁî® SODG Á¢∫ÂÆö‰æùË≥¥ÊñºÊìç‰ΩúÁöÑÂèÉÊï∏Ôºå‰∏¶‰ΩøÁî®‰∫îÂÄãÂ∞àÈñÄÁöÑ‰ª£ÁêÜ (Êìç‰Ωú„ÄÅÂèÉÊï∏„ÄÅÂÄº„ÄÅ‰æùË≥¥Èóú‰øÇÂíåÊ®ôÈ†≠) ‰æÜË≠òÂà•Êìç‰ΩúÁöÑ‰æùË≥¥Èóú‰øÇ‰∏¶Áî¢ÁîüÊìç‰ΩúÂ∫èÂàó„ÄÅÂèÉÊï∏ÁµÑÂêàÂíåÂÄº„ÄÇAutoRestTest Êèê‰æõÂëΩ‰ª§Âàó‰ªãÈù¢ÂíåÊåÅÁ∫åÈÅôÊ∏¨ÔºåÂåÖÊã¨ÊàêÂäüÊìç‰ΩúÊ¨°Êï∏„ÄÅÂÅµÊ∏¨Âà∞ÁöÑÂîØ‰∏Ä‰º∫ÊúçÂô®ÈåØË™§ÂíåÁ∂ìÈÅéÊôÇÈñì„ÄÇÂÆåÊàêÂæåÔºåAutoRestTest ÊúÉÁî¢Áîü‰∏Ä‰ªΩË©≥Á¥∞Â†±ÂëäÔºåÈáçÈªûË™™ÊòéÂÅµÊ∏¨Âà∞ÁöÑÈåØË™§ÂíåÂü∑Ë°åÁöÑÊìç‰Ωú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÊàëÂÄëÁöÑÂ∑•ÂÖ∑‰∏¶ÊèêÂá∫ÂàùÊ≠•ÁµêÊûú„ÄÇ

##### **LlamaRestTest: Effective REST API Testing with Small Language Models**
2501.08598v1 by Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

Modern web services rely heavily on REST APIs, typically documented using the
OpenAPI specification. The widespread adoption of this standard has resulted in
the development of many black-box testing tools that generate tests based on
these specifications. Recent advancements in Natural Language Processing (NLP),
particularly with Large Language Models (LLMs), have enhanced REST API testing
by extracting actionable rules and generating input values from the
human-readable portions of the specification. However, these advancements
overlook the potential of continuously refining the identified rules and test
inputs based on server responses. To address this limitation, we present
LlamaRestTest, a novel approach that employs two custom LLMs to generate
realistic test inputs and uncover parameter dependencies during the testing
process by incorporating server responses. These LLMs are created by
fine-tuning the Llama3-8b model, using mined datasets of REST API example
values and inter-parameter dependencies. We evaluated LlamaRestTest on 12
real-world services (including popular services such as Spotify), comparing it
against RESTGPT, a GPT-powered specification-enhancement tool, as well as
several state-of-the-art REST API testing tools, including RESTler, MoRest,
EvoMaster, and ARAT-RL. Our results show that fine-tuning enables smaller LLMs
to outperform larger models in detecting actionable rules and generating inputs
for REST API testing. We evaluated configurations from the base Llama3-8B to
fine-tuned versions and explored 2-bit, 4-bit, and 8-bit quantization for
efficiency. LlamaRestTest surpasses state-of-the-art tools in code coverage and
error detection, even with RESTGPT-enhanced specifications, and an ablation
study highlights the impact of its novel components.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ª£Á∂≤Ë∑ØÊúçÂãôÈ´òÂ∫¶‰æùË≥¥ REST APIÔºåÈÄöÂ∏∏‰ΩøÁî® OpenAPI Ë¶èÁØÑÊñá‰ª∂„ÄÇÈÄôÂÄãÊ®ôÊ∫ñÁöÑÂª£Ê≥õÊé°Áî®ÔºåÂ∞éËá¥Ë®±Â§öÈªëÁõíÊ∏¨Ë©¶Â∑•ÂÖ∑ÁöÑÈñãÁôºÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÊúÉÊ†πÊìöÈÄô‰∫õË¶èÁØÑÊñá‰ª∂Áî¢ÁîüÊ∏¨Ë©¶„ÄÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂ§ßË™ûË®ÄÊ®°Âûã (LLM)ÔºåÈÄèÈÅéÂæûË¶èÁØÑÊñá‰ª∂ÁöÑ‰∫∫È°ûÂèØËÆÄÈÉ®ÂàÜ‰∏≠ËêÉÂèñÂèØË°åÁöÑË¶èÂâáÂíåÁî¢ÁîüËº∏ÂÖ•ÂÄºÔºåÂ¢ûÂº∑‰∫Ü REST API Ê∏¨Ë©¶„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈÄ≤Â±ïÂøΩÁï•‰∫ÜÊ†πÊìö‰º∫ÊúçÂô®ÂõûÊáâÊåÅÁ∫åÁ≤æÈÄ≤Â∑≤Ë≠òÂà•Ë¶èÂâáÂíåÊ∏¨Ë©¶Ëº∏ÂÖ•ÁöÑÊΩõÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ LlamaRestTestÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®ÂÖ©ÂÄãËá™Ë®ÇÁöÑ LLM Áî¢ÁîüÈÄºÁúüÁöÑÊ∏¨Ë©¶Ëº∏ÂÖ•Ôºå‰∏¶Âú®Ê∏¨Ë©¶ÈÅéÁ®ã‰∏≠ÈÄèÈÅéÁ¥çÂÖ•‰º∫ÊúçÂô®ÂõûÊáâ‰æÜÊè≠Èú≤ÂèÉÊï∏‰æùË≥¥ÊÄß„ÄÇÈÄô‰∫õ LLM ÊòØÈÄèÈÅéÂæÆË™ø Llama3-8b Ê®°ÂûãÔºå‰ΩøÁî® REST API ÁØÑ‰æãÂÄºÁöÑÊåñÊéòË≥áÊñôÈõÜÂíåÂèÉÊï∏ÈñìÁöÑ‰æùË≥¥ÊÄßÊâÄÂª∫Á´ãÁöÑ„ÄÇÊàëÂÄëÂú® 12 È†ÖÁúüÂØ¶‰∏ñÁïåÁöÑÊúçÂãôÔºàÂåÖÊã¨ Spotify Á≠âÁÜ±ÈñÄÊúçÂãôÔºâ‰∏äË©ï‰º∞ LlamaRestTestÔºå‰∏¶Â∞áÂÆÉËàá RESTGPTÔºà‰∏ÄÁ®ÆÁî± GPT È©ÖÂãïÁöÑË¶èÁØÑÊñá‰ª∂Â¢ûÂº∑Â∑•ÂÖ∑Ôºâ‰ª•ÂèäÂπæÂÄãÊúÄÂÖàÈÄ≤ÁöÑ REST API Ê∏¨Ë©¶Â∑•ÂÖ∑ÔºàÂåÖÊã¨ RESTler„ÄÅMoRest„ÄÅEvoMaster Âíå ARAT-RLÔºâÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂæÆË™øËÆìËºÉÂ∞èÁöÑ LLM ËÉΩÂú®ÂÅµÊ∏¨ÂèØË°åÁöÑË¶èÂâáÂíåÁî¢Áîü REST API Ê∏¨Ë©¶ÁöÑËº∏ÂÖ•ÊñπÈù¢ÔºåË°®ÁèæÂÑ™ÊñºËºÉÂ§ßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂæûÂü∫Á§é Llama3-8B Âà∞ÂæÆË™øÁâàÊú¨ÁöÑÁµÑÊÖãÔºå‰∏¶Êé¢Á¥¢‰∫Ü 2 ‰ΩçÂÖÉ„ÄÅ4 ‰ΩçÂÖÉÂíå 8 ‰ΩçÂÖÉÈáèÂåñ‰ª•ÊèêÂçáÊïàÁéá„ÄÇÂç≥‰ΩøÂú® RESTGPT Â¢ûÂº∑ÁöÑË¶èÁØÑÊñá‰ª∂‰∏≠ÔºåLlamaRestTest ‰πüÂú®Á®ãÂºèÁ¢ºÊ∂µËìãÁéáÂíåÈåØË™§ÂÅµÊ∏¨ÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂ∑•ÂÖ∑ÔºåËÄå‰∏îÊ∂àËûçÁ†îÁ©∂Á™ÅÈ°Ø‰∫ÜÂÖ∂Êñ∞Á©éÂÖÉ‰ª∂ÁöÑÂΩ±Èüø„ÄÇ</paragraph>

##### **Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning**
2501.08597v1 by Julian Perry, Surasakdi Siripong, Thanakorn Phonchai

Large Vision-Language Models (LVLMs) have demonstrated impressive
capabilities in multimodal tasks, but their performance is often constrained by
the lack of external knowledge integration, limiting their ability to handle
knowledge-intensive tasks such as visual question answering and reasoning. To
address this challenge, we propose a novel method, Adaptive Knowledge-Guided
Pretraining for Large Vision-Language Models (AKGP-LVLM), which dynamically
incorporates structured and unstructured knowledge into LVLMs during
pretraining and fine-tuning. Our approach employs a knowledge encoder to
represent external knowledge, a retrieval mechanism to select task-relevant
information, and a dynamic adaptor to align multimodal and knowledge
representations effectively. We evaluate our method on four benchmark datasets,
demonstrating significant performance improvements over state-of-the-art
models. Furthermore, human evaluations highlight the superior correctness and
relevance of our model's outputs. Extensive analyses confirm the robustness,
efficiency, and scalability of AKGP-LVLM, making it a compelling solution for
real-world knowledge-intensive tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Â∑≤Âú®Â§öÊ®°ÊÖã‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÂÖ∂ÊïàËÉΩÁ∂ìÂ∏∏ÂèóÂà∞Â§ñÈÉ®Áü•Ë≠òÊï¥Âêà‰∏çË∂≥ÁöÑÈôêÂà∂ÔºåÈÄôÊúÉÈôêÂà∂ÂÆÉÂÄëËôïÁêÜÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÔºà‰æãÂ¶ÇË¶ñË¶∫ÂïèÁ≠îÂíåÊé®ÁêÜÔºâÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂç≥Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑËá™ÈÅ©ÊáâÁü•Ë≠òÂºïÂ∞éÈ†êË®ìÁ∑¥ (AKGP-LVLM)ÔºåÂÆÉÊúÉÂú®È†êË®ìÁ∑¥ÂíåÂæÆË™øÊúüÈñìÂãïÊÖãÂú∞Â∞áÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñÁü•Ë≠òÁ¥çÂÖ• LVLMs„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®Áü•Ë≠òÁ∑®Á¢ºÂô®‰æÜË°®Á§∫Â§ñÈÉ®Áü•Ë≠òÔºåÊé°Áî®Ê™¢Á¥¢Ê©üÂà∂‰æÜÈÅ∏ÊìáËàá‰ªªÂãôÁõ∏ÈóúÁöÑË≥áË®äÔºå‰∏¶Êé°Áî®ÂãïÊÖãÈÅ©ÈÖçÂô®‰æÜÊúâÊïàÂú∞Â∞çÈΩäÂ§öÊ®°ÊÖãÂíåÁü•Ë≠òË°®Á§∫„ÄÇÊàëÂÄëÂú®ÂõõÂ§ßÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåË≠âÊòéÂÖ∂ÊïàËÉΩÈ°ØËëóÂÑ™ÊñºÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºå‰∫∫Â∑•Ë©ï‰º∞Á™ÅÈ°Ø‰∫ÜÊàëÂÄëÊ®°ÂûãËº∏Âá∫ÁöÑÊ≠£Á¢∫ÊÄßÂíåÁõ∏ÈóúÊÄßÁöÑÂÑ™Ë∂äÊÄß„ÄÇÂª£Ê≥õÁöÑÂàÜÊûêË≠âÂØ¶‰∫Ü AKGP-LVLM ÁöÑÁ©©ÂÅ•ÊÄß„ÄÅÊïàÁéáÂíåÂèØÊì¥ÂÖÖÊÄßÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÁèæÂØ¶‰∏ñÁïåÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÁöÑÂº∑Â§ßËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **OpenMLDB: A Real-Time Relational Data Feature Computation System for Online ML**
2501.08591v1 by Xuanhe Zhou, Wei Zhou, Liguo Qi, Hao Zhang, Dihao Chen, Bingsheng He, Mian Lu, Guoliang Li, Fan Wu, Yuqiang Chen

Efficient and consistent feature computation is crucial for a wide range of
online ML applications. Typically, feature computation is divided into two
distinct phases, i.e., offline stage for model training and online stage for
model serving. These phases often rely on execution engines with different
interface languages and function implementations, causing significant
inconsistencies. Moreover, many online ML features involve complex time-series
computations (e.g., functions over varied-length table windows) that differ
from standard streaming and analytical queries. Existing data processing
systems (e.g., Spark, Flink, DuckDB) often incur multi-second latencies for
these computations, making them unsuitable for real-time online ML applications
that demand timely feature updates.
  This paper presents OpenMLDB, a feature computation system deployed in
4Paradigm's SageOne platform and over 100 real scenarios. Technically, OpenMLDB
first employs a unified query plan generator for consistent computation results
across the offline and online stages, significantly reducing feature deployment
overhead. Second, OpenMLDB provides an online execution engine that resolves
performance bottlenecks caused by long window computations (via
pre-aggregation) and multi-table window unions (via data self-adjusting). It
also provides a high-performance offline execution engine with window parallel
optimization and time-aware data skew resolving. Third, OpenMLDB features a
compact data format and stream-focused indexing to maximize memory usage and
accelerate data access. Evaluations in testing and real workloads reveal
significant performance improvements and resource savings compared to the
baseline systems. The open community of OpenMLDB now has over 150 contributors
and gained 1.6k stars on GitHub.

ÊëòË¶ÅÔºö<paragraph>È´òÊïà‰∏î‰∏ÄËá¥ÁöÑÁâπÂæÅËÆ°ÁÆóÂØπ‰∫éÂπøÊ≥õÁöÑÂú®Á∫øÊú∫Âô®Â≠¶‰π†Â∫îÁî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇÈÄöÂ∏∏ÔºåÁâπÂæÅËÆ°ÁÆóÂàÜ‰∏∫‰∏§‰∏™‰∏çÂêåÁöÑÈò∂ÊÆµÔºåÂç≥Áî®‰∫éÊ®°ÂûãËÆ≠ÁªÉÁöÑÁ¶ªÁ∫øÈò∂ÊÆµÂíåÁî®‰∫éÊ®°ÂûãÊúçÂä°ÁöÑÂú®Á∫øÈò∂ÊÆµ„ÄÇËøô‰∫õÈò∂ÊÆµÈÄöÂ∏∏‰æùËµñ‰∫éÂÖ∑Êúâ‰∏çÂêåÁïåÈù¢ËØ≠Ë®ÄÂíåÂáΩÊï∞ÂÆûÁé∞ÁöÑÊâßË°åÂºïÊìéÔºå‰ªéËÄåÂØºËá¥ÈáçÂ§ß‰∏ç‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåËÆ∏Â§öÂú®Á∫øÊú∫Âô®Â≠¶‰π†ÁâπÂæÅÊ∂âÂèäÂ§çÊùÇÁöÑÊó∂Èó¥Â∫èÂàóËÆ°ÁÆóÔºà‰æãÂ¶ÇÔºåÂØπ‰∏çÂêåÈïøÂ∫¶Ë°®Á™óÂè£ÁöÑÂáΩÊï∞ÔºâÔºåËøô‰∏çÂêå‰∫éÊ†áÂáÜÊµÅÂíåÂàÜÊûêÊü•ËØ¢„ÄÇÁé∞ÊúâÁöÑÊï∞ÊçÆÂ§ÑÁêÜÁ≥ªÁªüÔºà‰æãÂ¶ÇÔºåSpark„ÄÅFlink„ÄÅDuckDBÔºâÈÄöÂ∏∏‰ºö‰∏∫Ëøô‰∫õËÆ°ÁÆóÈÄ†ÊàêÂ§öÁßíÁöÑÂª∂ËøüÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨‰∏çÈÄÇÁî®‰∫éÈúÄË¶ÅÂèäÊó∂ÁâπÂæÅÊõ¥Êñ∞ÁöÑÂÆûÊó∂Âú®Á∫øÊú∫Âô®Â≠¶‰π†Â∫îÁî®„ÄÇ
Êú¨Êñá‰ªãÁªç‰∫Ü OpenMLDBÔºåËøôÊòØ‰∏Ä‰∏™ÈÉ®ÁΩ≤Âú® 4Paradigm ÁöÑ SageOne Âπ≥Âè∞Âíå 100 Â§ö‰∏™ÁúüÂÆûÂú∫ÊôØ‰∏≠ÁöÑÁâπÂæÅËÆ°ÁÆóÁ≥ªÁªü„ÄÇ‰ªéÊäÄÊúØ‰∏äËÆ≤ÔºåOpenMLDB È¶ñÂÖàÈááÁî®Áªü‰∏ÄÁöÑÊü•ËØ¢ËÆ°ÂàíÁîüÊàêÂô®Ôºå‰ª•Âú®Á¶ªÁ∫øÂíåÂú®Á∫øÈò∂ÊÆµËé∑Âæó‰∏ÄËá¥ÁöÑËÆ°ÁÆóÁªìÊûúÔºå‰ªéËÄåÊòæËëóÂáèÂ∞ëÁâπÂæÅÈÉ®ÁΩ≤ÂºÄÈîÄ„ÄÇÂÖ∂Ê¨°ÔºåOpenMLDB Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âú®Á∫øÊâßË°åÂºïÊìéÔºåÈÄöËøáÈ¢ÑËÅöÂêàÔºàÈíàÂØπÈïøÁ™óÂè£ËÆ°ÁÆóÔºâÂíåÂ§öË°®Á™óÂè£ËÅîÂêàÔºàÈÄöËøáÊï∞ÊçÆËá™Ë∞ÉÊï¥ÔºâËß£ÂÜ≥‰∫ÜÊÄßËÉΩÁì∂È¢à„ÄÇÂÆÉËøòÊèê‰æõ‰∫Ü‰∏Ä‰∏™È´òÊÄßËÉΩÁöÑÁ¶ªÁ∫øÊâßË°åÂºïÊìéÔºåÂÖ∑ÊúâÁ™óÂè£Âπ∂Ë°å‰ºòÂåñÂíåÊó∂Èó¥ÊÑüÁü•Êï∞ÊçÆÂÄæÊñúËß£ÂÜ≥„ÄÇÁ¨¨‰∏âÔºåOpenMLDB ÈááÁî®Á¥ßÂáëÁöÑÊï∞ÊçÆÊ†ºÂºèÂíå‰ª•ÊµÅ‰∏∫‰∏≠ÂøÉÁöÑÁ¥¢ÂºïÔºå‰ª•ÊúÄÂ§ßÂåñÂÜÖÂ≠ò‰ΩøÁî®Âπ∂Âä†ÈÄüÊï∞ÊçÆËÆøÈóÆ„ÄÇÂú®ÊµãËØïÂíåÂÆûÈôÖÂ∑•‰ΩúË¥üËΩΩ‰∏≠ÁöÑËØÑ‰º∞ÊòæÁ§∫Ôºå‰∏éÂü∫Á∫øÁ≥ªÁªüÁõ∏ÊØîÔºåÊÄßËÉΩÊúâ‰∫ÜÊòæËëóÊèêÂçáÔºåËµÑÊ∫ê‰πüÂæóÂà∞‰∫ÜËäÇÁúÅ„ÄÇOpenMLDB ÁöÑÂºÄÊîæÁ§æÂå∫Áé∞Âú®Êã•Êúâ 150 Â§ö‰ΩçË¥°ÁåÆËÄÖÔºåÂπ∂Âú® GitHub ‰∏äËé∑Âæó‰∫Ü 1.6k È¢óÊòü„ÄÇ</paragraph>

##### **Sound Scene Synthesis at the DCASE 2024 Challenge**
2501.08587v1 by Mathieu Lagrange, Junwon Lee, Modan Tailleur, Laurie M. Heller, Keunwoo Choi, Brian McFee, Keisuke Imoto, Yuki Okamoto

This paper presents Task 7 at the DCASE 2024 Challenge: sound scene
synthesis. Recent advances in sound synthesis and generative models have
enabled the creation of realistic and diverse audio content. We introduce a
standardized evaluation framework for comparing different sound scene synthesis
systems, incorporating both objective and subjective metrics. The challenge
attracted four submissions, which are evaluated using the Fr\'echet Audio
Distance (FAD) and human perceptual ratings. Our analysis reveals significant
insights into the current capabilities and limitations of sound scene synthesis
systems, while also highlighting areas for future improvement in this rapidly
evolving field.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñá‰ªãÁ¥π‰∫Ü DCASE 2024 ÊåëÊà∞‰∏≠ÁöÑ‰ªªÂãô 7ÔºöËÅ≤Èü≥Â†¥ÊôØÂêàÊàê„ÄÇËÅ≤Èü≥ÂêàÊàêÂíåÁîüÊàêÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøÂæóËÉΩÂ§†ÂâµÈÄ†Âá∫ÈÄºÁúü‰∏îÂ§öÊ®£ÂåñÁöÑÈü≥Ë®äÂÖßÂÆπ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞Êû∂ÊßãÔºåÁî®ÊñºÊØîËºÉ‰∏çÂêåÁöÑËÅ≤Èü≥Â†¥ÊôØÂêàÊàêÁ≥ªÁµ±ÔºåÁµêÂêà‰∫ÜÂÆ¢ËßÄÂíå‰∏ªËßÄÁöÑÊåáÊ®ô„ÄÇÊ≠§ÊåëÊà∞Âê∏Âºï‰∫ÜÂõõ‰ªΩÊèê‰∫§ÔºåÈÄô‰∫õÊèê‰∫§‰ΩøÁî® Fr\'echet Èü≥Ë®äË∑ùÈõ¢ (FAD) Âíå‰∫∫È°ûÊÑüÁü•Ë©ïÂàÜÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫ÜÂ∞çËÅ≤Èü≥Â†¥ÊôØÂêàÊàêÁ≥ªÁµ±Áï∂ÂâçËÉΩÂäõÂíåÈôêÂà∂ÁöÑÈáçÂ§ßË¶ãËß£ÔºåÂêåÊôÇ‰πüÂº∑Ë™ø‰∫ÜÈÄôÂÄãÂø´ÈÄüÁôºÂ±ïÈ†òÂüü‰∏≠Êú™‰æÜÊîπÈÄ≤ÁöÑÈ†òÂüü„ÄÇ

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ‰ΩéÁß©ÈÅ©Êáâ (LoRA) ÊñπÊ≥ïÁî±ÊñºÁÑ°Ê≥ïÁ∂≠ÊåÅÁ®ÄÁñèÊÄßÔºåÂú®Á®ÄÁñèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏äÈù¢Ëá®ÊåëÊà∞„ÄÇÊúÄËøëÁöÑ‰ΩúÂìÅÂºïÂÖ•‰∫ÜÈÄèÈÅé‰ΩøÁî®È°çÂ§ñÁöÑÈÅÆÁΩ©Ê©üÂà∂‰æÜÊì¥ÂÖÖ LoRA ÊäÄË°ìÁöÑÊñπÊ≥ï‰æÜÁ∂≠ÊåÅÁ®ÄÁñèÊÄß„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÊàêÂäüÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÊúÉÂ¢ûÂä†Ë®òÊÜ∂È´îÂíåÈÅãÁÆóÁöÑÈñãÈä∑ÔºåÈÄôÊúÉÂΩ±Èüø LoRA ÊñπÊ≥ïÁöÑÊïàÁéá„ÄÇÁÇ∫‰∫ÜÂõûÊáâÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü LoRSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÊó®Âú®Âú®ÂæÆË™øÁ®ÄÁñè LLM ÊôÇÂêåÊôÇÂØ¶ÁèæË®òÊÜ∂È´îÂíåÈÅãÁÆóÊïàÁéá„ÄÇÁÇ∫‰∫ÜÊ∏õËºïËàáÁ∂≠ÊåÅÁ®ÄÁñèÊÄßÁõ∏ÈóúÁöÑÈæêÂ§ßË®òÊÜ∂È´îÂíåÈÅãÁÆóÈúÄÊ±ÇÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêà‰∫ÜÊ¨äÈáçÈáçÊñ∞Ë®àÁÆóÂíåË®àÁÆóÂúñÂΩ¢ÈáçÊñ∞ÊéíÂàóÁöÑÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÈÄèÈÅéÊõ¥Â•ΩÁöÑÈÅ©ÈÖçÂô®ÂàùÂßãÂåñ‰æÜÊèêÈ´ò LoRS ÁöÑÊúâÊïàÊÄß„ÄÇÈÄô‰∫õÂâµÊñ∞Âú®ÂæÆË™øÈöéÊÆµÈ°ØËëóÊ∏õÂ∞ë‰∫ÜË®òÊÜ∂È´îÂíåÈÅãÁÆóÊ∂àËÄóÔºåÂêåÊôÇÂØ¶Áèæ‰∫ÜÂÑ™ÊñºÁèæÊúâ LoRA ÊñπÊ≥ïÁöÑÊïàËÉΩÁ≠âÁ¥ö„ÄÇ

##### **What Limits LLM-based Human Simulation: LLMs or Our Design?**
2501.08579v1 by Qian Wang, Jiaying Wu, Zhenheng Tang, Bingqiao Luo, Nuo Chen, Wei Chen, Bingsheng He

We argue that advancing LLM-based human simulation requires addressing both
LLM's inherent limitations and simulation framework design challenges. Recent
studies have revealed significant gaps between LLM-based human simulations and
real-world observations, highlighting these dual challenges. To address these
gaps, we present a comprehensive analysis of LLM limitations and our design
issues, proposing targeted solutions for both aspects. Furthermore, we explore
future directions that address both challenges simultaneously, particularly in
data collection, LLM generation, and evaluation. To support further research in
this field, we provide a curated collection of LLM-based human simulation
resources.\footnote{https://github.com/Persdre/llm-human-simulation}

ÊëòË¶ÅÔºöÊàëÂÄëË™çÁÇ∫ÔºåË¶ÅÊé®ÈÄ≤Âü∫Êñº LLM ÁöÑ‰∫∫È°ûÊ®°Êì¨ÔºåÈúÄË¶ÅËß£Ê±∫ LLM Êú¨Ë∫´ÁöÑÈôêÂà∂ÂíåÊ®°Êì¨Ê°ÜÊû∂Ë®≠Ë®àÊåëÊà∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂü∫Êñº LLM ÁöÑ‰∫∫È°ûÊ®°Êì¨ËàáÁúüÂØ¶‰∏ñÁïåÁöÑËßÄÂØü‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÂá∏È°Ø‰∫ÜÈÄôÂÖ©ÂÄãÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÂ∑ÆË∑ùÔºåÊàëÂÄëÂ∞ç LLM ÁöÑÈôêÂà∂ÂíåÊàëÂÄëÁöÑË®≠Ë®àÂïèÈ°åÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûêÔºå‰∏¶ÈáùÂ∞çÈÄôÂÖ©ÂÄãÊñπÈù¢ÊèêÂá∫‰∫ÜÊúâÈáùÂ∞çÊÄßÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÊé¢Ë®é‰∫ÜÂêåÊôÇÊáâÂ∞çÈÄôÂÖ©ÂÄãÊåëÊà∞ÁöÑÊú™‰æÜÊñπÂêëÔºåÁâπÂà•ÊòØÂú®Êï∏ÊìöÊî∂ÈõÜ„ÄÅLLM ÁîüÊàêÂíåË©ï‰º∞ÊñπÈù¢„ÄÇÁÇ∫‰∫ÜÊîØÊåÅË©≤È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ≥ªÂàóÁ∂ìÈÅéÊï¥ÁêÜÁöÑÂü∫Êñº LLM ÁöÑ‰∫∫È°ûÊ®°Êì¨Ë≥áÊ∫ê„ÄÇ\footnote{https://github.com/Persdre/llm-human-simulation}

##### **Information Entropy Invariance: Enhancing Length Extrapolation in Attention Mechanisms**
2501.08570v1 by Kewei Li, Yanwen Kong, Yiping Xu, Lan Huang, Ruochi Zhang, Fengfeng Zhou

Improving the length extrapolation capabilities of Large Language Models
(LLMs) remains a critical challenge in natural language processing. Many recent
efforts have focused on modifying the scaled dot-product attention mechanism,
and often introduce scaled temperatures without rigorous theoretical
justification. To fill this gap, we introduce a novel approach based on
information entropy invariance. We propose two new scaled temperatures to
enhance length extrapolation. First, a training-free method InfoScale is
designed for dot-product attention, and preserves focus on original tokens
during length extrapolation by ensuring information entropy remains consistent.
Second, we theoretically analyze the impact of scaling (CosScale) on cosine
attention. Experimental data demonstrates that combining InfoScale and CosScale
achieves state-of-the-art performance on the GAU-{\alpha} model with a context
window extended to 64 times the training length, and outperforms seven existing
methods. Our analysis reveals that significantly increasing CosScale
approximates windowed attention, and highlights the significance of attention
score dilution as a key challenge in long-range context handling. The code and
data are available at https://github.com/HT-NEKO/InfoScale.

ÊëòË¶ÅÔºöÊîπÂñÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈï∑Â∫¶Â§ñÊé®ËÉΩÂäõ‰ªçÁÑ∂ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇË®±Â§öËøëÊúüÁöÑÂä™ÂäõÈÉΩÂ∞àÊ≥®Êñº‰øÆÊîπÁ∏ÆÊîæÈªûÁ©çÊ≥®ÊÑèÂäõÊ©üÂà∂Ôºå‰∏¶‰∏îÁ∂ìÂ∏∏Âú®Ê≤íÊúâÂö¥Ë¨πÁêÜË´ñ‰æùÊìöÁöÑÊÉÖÊ≥Å‰∏ãÂºïÂÖ•Á∏ÆÊîæÊ∫´Â∫¶„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºË≥áË®äÁÜµ‰∏çËÆäÊÄßÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©Á®ÆÊñ∞ÁöÑÁ∏ÆÊîæÊ∫´Â∫¶‰æÜÂ¢ûÂº∑Èï∑Â∫¶Â§ñÊé®„ÄÇÈ¶ñÂÖàÔºå‰∏ÄÁ®ÆÂÖçË®ìÁ∑¥ÁöÑÊñπÊ≥ï InfoScale ÊòØÁÇ∫ÈªûÁ©çÊ≥®ÊÑèÂäõË®≠Ë®àÁöÑÔºå‰∏¶‰∏îÂú®Èï∑Â∫¶Â§ñÊé®ÊúüÈñì‰øùÊåÅÂ∞çÂéüÂßãÊ®ôË®òÁöÑÈóúÊ≥®ÔºåÊñπÊ≥ïÊòØÁ¢∫‰øùË≥áË®äÁÜµ‰øùÊåÅ‰∏ÄËá¥„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂæûÁêÜË´ñ‰∏äÂàÜÊûê‰∫ÜÁ∏ÆÊîæ (CosScale) Â∞çÈ§òÂº¶Ê≥®ÊÑèÂäõÁöÑÂΩ±Èüø„ÄÇÂØ¶È©óÊï∏ÊìöË°®ÊòéÔºåÂ∞á InfoScale Âíå CosScale ÁµêÂêà‰ΩøÁî®ÔºåÂú® GAU-{\alpha} Ê®°Âûã‰∏äÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºå‰∏ä‰∏ãÊñáÁ™óÂè£Êì¥Â±ïÂà∞Ë®ìÁ∑¥Èï∑Â∫¶ÁöÑ 64 ÂÄçÔºå‰∏¶‰∏îÂÑ™Êñº‰∏ÉÁ®ÆÁèæÊúâÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåÈ°ØËëóÂ¢ûÂä† CosScale Ëøë‰ººÊñºË¶ñÁ™óÊ≥®ÊÑèÂäõÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊ≥®ÊÑèÂäõÂàÜÊï∏Á®ÄÈáã‰ΩúÁÇ∫Èï∑Á®ã‰∏ä‰∏ãÊñáËôïÁêÜ‰∏≠ÁöÑÈóúÈçµÊåëÊà∞„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/HT-NEKO/InfoScale ÂèñÂæó„ÄÇ

##### **Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement**
2501.08566v1 by Qianniu Chen, Xiaoyang Hao, Bowen Li, Yue Liu, Li Lu

Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized
voice customization through voice cloning. However, current methods for
achieving zero-shot TTS heavily rely on large model scales and extensive
training datasets to ensure satisfactory performance and generalizability
across various speakers. This raises concerns regarding both deployment costs
and data security. In this paper, we present a lightweight and stable zero-shot
TTS system. We introduce a novel TTS architecture designed to effectively model
linguistic content and various speaker attributes from source speech and prompt
speech, respectively. Furthermore, we present a two-stage self-distillation
framework that constructs parallel data pairs for effectively disentangling
linguistic content and speakers from the perspective of training data.
Extensive experiments show that our system exhibits excellent performance and
superior stability on the zero-shot TTS tasks. Moreover, it shows markedly
superior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and
GPU, respectively.

ÊëòË¶ÅÔºöÈõ∂Ê®£Êú¨ÊñáÂ≠óËΩâË™ûÈü≥ (TTS) ÂêàÊàêÂú®ÈÄèÈÅéË™ûÈü≥Ë§áË£ΩÊäÄË°ìÈÄ≤Ë°åÂÄãÊÄßÂåñË™ûÈü≥Ëá™Ë®ÇÊñπÈù¢Â±ïÁèæÂá∫Ê•µ‰Ω≥ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÈÅîÊàêÈõ∂Ê®£Êú¨ TTS ÁöÑÊñπÊ≥ïÊ•µÂ∫¶‰æùË≥¥Â§ßÂûãÊ®°ÂûãË¶èÊ®°ÂíåÂª£Ê≥õÁöÑË®ìÁ∑¥Ë≥áÊñôÈõÜÔºå‰ª•Á¢∫‰øùÂú®ÂêÑÁ®ÆË™™Ë©±ËÄÖ‰πãÈñìÊúâ‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩÂíåÊ¶ÇÊã¨ÊÄß„ÄÇÈÄôÂºïÁôº‰∫ÜÂ∞çÈÉ®ÁΩ≤ÊàêÊú¨ÂíåË≥áÊñôÂÆâÂÖ®ÁöÑÁñëÊÖÆ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËºïÈáè‰∏îÁ©©ÂÆöÁöÑÈõ∂Ê®£Êú¨ TTS Á≥ªÁµ±„ÄÇÊàëÂÄëÊé®Âá∫‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑ TTS Êû∂ÊßãÔºåÊó®Âú®ÊúâÊïàÂú∞Âª∫ÊßãË™ûË®ÄÂÖßÂÆπÂíåÂêÑÁ®ÆË™™Ë©±ËÄÖÂ±¨ÊÄßÔºåÂàÜÂà•‰æÜËá™ÂéüÂßãË™ûÈü≥ÂíåÊèêÁ§∫Ë™ûÈü≥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂÖ©ÈöéÊÆµÁöÑËá™Ëí∏È§æÊû∂ÊßãÔºåÁî®ÊñºÂª∫ÊßãÂπ≥Ë°åË≥áÊñôÂ∞çÔºå‰ª•ÊúâÊïàÂú∞ÂæûË®ìÁ∑¥Ë≥áÊñôÁöÑËßíÂ∫¶Ëß£ÈñãË™ûË®ÄÂÖßÂÆπÂíåË™™Ë©±ËÄÖ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±Âú®Èõ∂Ê®£Êú¨ TTS ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µ‰Ω≥ÁöÑÊïàËÉΩÂíåÂÑ™Áï∞ÁöÑÁ©©ÂÆöÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÂ±ïÁèæÂá∫È°ØËëóÂÑ™Áï∞ÁöÑÈÅãÁÆóÊïàÁéáÔºåÂú® CPU Âíå GPU ‰∏äÁöÑ RTF ÂàÜÂà•ÁÇ∫ 0.13 Âíå 0.012„ÄÇ

##### **ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins**
2501.08561v1 by Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Houbing Herbert Song

In this paper, we propose an Adaptive Neuro-Symbolic Learning Framework for
digital twin technology called ``ANSR-DT." Our approach combines pattern
recognition algorithms with reinforcement learning and symbolic reasoning to
enable real-time learning and adaptive intelligence. This integration enhances
the understanding of the environment and promotes continuous learning, leading
to better and more effective decision-making in real-time for applications that
require human-machine collaboration. We evaluated the \textit{ANSR-DT}
framework for its ability to learn and adapt to dynamic patterns, observing
significant improvements in decision accuracy, reliability, and
interpretability when compared to existing state-of-the-art methods. However,
challenges still exist in extracting and integrating symbolic rules in complex
environments, which limits the full potential of our framework in heterogeneous
settings. Moreover, our ongoing research aims to address this issue in the
future by ensuring seamless integration of neural models at large. In addition,
our open-source implementation promotes reproducibility and encourages future
research to build on our foundational work.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÁ•ûÁªèÁ¨¶Âè∑Â≠¶‰π†Ê°ÜÊû∂ÔºåÁî®‰∫éÁß∞‰∏∫ ``ANSR-DT'' ÁöÑÊï∞Â≠óÂ≠™ÁîüÊäÄÊúØ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∞ÜÊ®°ÂºèËØÜÂà´ÁÆóÊ≥ï‰∏éÂº∫ÂåñÂ≠¶‰π†ÂíåÁ¨¶Âè∑Êé®ÁêÜÁõ∏ÁªìÂêàÔºå‰ª•ÂÆûÁé∞ÂÆûÊó∂Â≠¶‰π†ÂíåËá™ÈÄÇÂ∫îÊô∫ËÉΩ„ÄÇËøôÁßçÈõÜÊàêÂ¢ûÂº∫‰∫ÜÂØπÁéØÂ¢ÉÁöÑÁêÜËß£Âπ∂‰øÉËøõ‰∫ÜÊåÅÁª≠Â≠¶‰π†Ôºå‰ªéËÄåÂú®ÈúÄË¶Å‰∫∫Êú∫Âçè‰ΩúÁöÑÂ∫îÁî®‰∏≠ÂÆûÊó∂ÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊúâÊïàÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫Ü \textit{ANSR-DT} Ê°ÜÊû∂Â≠¶‰π†ÂíåÈÄÇÂ∫îÂä®ÊÄÅÊ®°ÂºèÁöÑËÉΩÂäõÔºå‰∏éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÁõ∏ÊØîÔºåËßÇÂØüÂà∞ÂÜ≥Á≠ñÂáÜÁ°ÆÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÂèØËß£ÈáäÊÄßÁöÑÊòæÁùÄÊèêÈ´ò„ÄÇÁÑ∂ËÄåÔºåÂú®Â§çÊùÇÁéØÂ¢É‰∏≠ÊèêÂèñÂíåÈõÜÊàêÁ¨¶Âè∑ËßÑÂàô‰ªçÁÑ∂Â≠òÂú®ÊåëÊàòÔºåËøôÈôêÂà∂‰∫ÜÊàë‰ª¨Âú®ÂºÇÊûÑÁéØÂ¢É‰∏≠Ê°ÜÊû∂ÁöÑÂÖ®ÈÉ®ÊΩúÂäõ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ê≠£Âú®ËøõË°åÁöÑÁ†îÁ©∂Êó®Âú®ÈÄöËøáÁ°Æ‰øùÁ•ûÁªèÊ®°ÂûãÁöÑÂ§ßËßÑÊ®°Êó†ÁºùÈõÜÊàêÔºåÂú®Êú™Êù•Ëß£ÂÜ≥Ê≠§ÈóÆÈ¢ò„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÂºÄÊ∫êÂÆûÁé∞‰øÉËøõ‰∫ÜÂèØÈáçÂ§çÊÄßÔºåÂπ∂ÈºìÂä±Êú™Êù•ÁöÑÁ†îÁ©∂Âª∫Á´ãÂú®Êàë‰ª¨ÁöÑÂü∫Á°ÄÂ∑•‰Ωú‰πã‰∏ä„ÄÇ

##### **LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation**
2501.08558v1 by Yiran Tao, Jehan Yang, Dan Ding, Zackory Erickson

Teleoperating high degrees-of-freedom (DoF) robotic manipulators via low-DoF
controllers like joysticks often requires frequent switching between control
modes, where each mode maps controller movements to specific robot actions.
Manually performing this frequent switching can make teleoperation cumbersome
and inefficient. On the other hand, existing automatic mode-switching
solutions, such as heuristic-based or learning-based methods, are often
task-specific and lack generalizability. In this paper, we introduce LLM-Driven
Automatic Mode Switching (LAMS), a novel approach that leverages Large Language
Models (LLMs) to automatically switch control modes based on task context.
Unlike existing methods, LAMS requires no prior task demonstrations and
incrementally improves by integrating user-generated mode-switching examples.
We validate LAMS through an ablation study and a user study with 10
participants on complex, long-horizon tasks, demonstrating that LAMS
effectively reduces manual mode switches, is preferred over alternative
methods, and improves performance over time. The project website with
supplementary materials is at https://lams-assistance.github.io/.

ÊëòË¶ÅÔºöÈÄèÈÅé‰ΩéËá™Áî±Â∫¶ (DoF) ÊéßÂà∂Âô®ÔºàÂ¶ÇÊìçÁ∏±Ê°øÔºâÈÅ†Á´ØÊìç‰ΩúÈ´òËá™Áî±Â∫¶Ê©üÂô®‰∫∫Ê©üÊ¢∞ÊâãÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂú®ÊéßÂà∂Ê®°Âºè‰πãÈñìÈ†ªÁπÅÂàáÊèõÔºåÂÖ∂‰∏≠ÊØèÂÄãÊ®°ÂºèÂ∞áÊéßÂà∂Âô®ÁßªÂãïÂ∞çÊáâÂà∞ÁâπÂÆöÁöÑÊ©üÂô®‰∫∫Âãï‰Ωú„ÄÇÊâãÂãïÂü∑Ë°åÈÄôÁ®ÆÈ†ªÁπÅÂàáÊèõÊúÉ‰ΩøÈÅ†Á´ØÊìç‰ΩúËÆäÂæóÁπÅÁë£‰∏î‰ΩéÊïàÁéá„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÁèæÊúâÁöÑËá™ÂãïÊ®°ÂºèÂàáÊèõËß£Ê±∫ÊñπÊ°àÔºà‰æãÂ¶ÇÂü∫ÊñºÂïüÁôºÂºèÊàñÂü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÔºâÈÄöÂ∏∏ÊòØÁâπÂÆöÊñº‰ªªÂãôÁöÑÔºå‰∏¶‰∏îÁº∫‰πèÊôÆÈÅçÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü LLM È©ÖÂãïÁöÑËá™ÂãïÊ®°ÂºèÂàáÊèõ (LAMS)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê†πÊìö‰ªªÂãô‰∏ä‰∏ãÊñáËá™ÂãïÂàáÊèõÊéßÂà∂Ê®°Âºè„ÄÇËàáÁèæÊúâÊñπÊ≥ï‰∏çÂêåÔºåLAMS ‰∏çÈúÄË¶ÅÂÖàÂâçÁöÑ‰ªªÂãôÊºîÁ§∫Ôºå‰∏¶‰∏îÈÄöÈÅéÊï¥Âêà‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑÊ®°ÂºèÂàáÊèõÁØÑ‰æã‰æÜÈÄêÊ≠•ÊîπÈÄ≤„ÄÇÊàëÂÄëÈÄèÈÅéÊ∂àËûçÁ†îÁ©∂ÂíåËàá 10 ‰ΩçÂèÉËàáËÄÖÈÄ≤Ë°åÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂È©óË≠â‰∫Ü LAMS Âú®Ë§áÈõú„ÄÅÈï∑ÊôÇÁ®ã‰ªªÂãô‰∏äÁöÑË°®ÁèæÔºåË≠âÊòé LAMS ÊúâÊïàÊ∏õÂ∞ë‰∫ÜÊâãÂãïÊ®°ÂºèÂàáÊèõÔºåÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ïÔºå‰∏¶‰∏îÈö®ËëóÊôÇÈñìÊé®ÁßªËÄåÊèêÂçáÊïàËÉΩ„ÄÇÂåÖÂê´Ë£úÂÖÖË≥áÊñôÁöÑÂ∞àÊ°àÁ∂≤Á´ô‰ΩçÊñº https://lams-assistance.github.io/„ÄÇ

##### **The Devil is in Temporal Token: High Quality Video Reasoning Segmentation**
2501.08549v1 by Sitong Gong, Yunzhi Zhuge, Lu Zhang, Zongxin Yang, Pingping Zhang, Huchuan Lu

Existing methods for Video Reasoning Segmentation rely heavily on a single
special token to represent the object in the keyframe or the entire video,
inadequately capturing spatial complexity and inter-frame motion. To overcome
these challenges, we propose VRS-HQ, an end-to-end video reasoning segmentation
approach that leverages Multimodal Large Language Models (MLLMs) to inject rich
spatiotemporal features into hierarchical tokens.Our key innovations include a
Temporal Dynamic Aggregation (TDA) and a Token-driven Keyframe Selection (TKS).
Specifically, we design frame-level <SEG> and temporal-level <TAK> tokens that
utilize MLLM's autoregressive learning to effectively capture both local and
global information. Subsequently, we apply a similarity-based weighted fusion
and frame selection strategy, then utilize SAM2 to perform keyframe
segmentation and propagation. To enhance keyframe localization accuracy, the
TKS filters keyframes based on SAM2's occlusion scores during inference. VRS-HQ
achieves state-of-the-art performance on ReVOS, surpassing VISA by
5.9%/12.5%/9.1% in J&F scores across the three subsets. These results highlight
the strong temporal reasoning and segmentation capabilities of our method. Code
and model weights will be released at VRS-HQ.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂΩ±ÁâáÊé®ÁêÜÂàÜÂâ≤ÊñπÊ≥ïÈÅéÂ∫¶‰æùË≥¥ÂñÆ‰∏ÄÁâπÊÆäÁ¨¶Ëôü‰æÜË°®Á§∫ÈóúÈçµÂΩ±Ê†ºÊàñÊï¥ÂÄãÂΩ±Áâá‰∏≠ÁöÑÁâ©‰ª∂ÔºåÁÑ°Ê≥ïÂÖÖÂàÜÊçïÊçâÁ©∫ÈñìË§áÈõúÂ∫¶ÂíåÂΩ±Ê†ºÈñìÁöÑÂãï‰Ωú„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ VRS-HQÔºå‰∏ÄÁ®ÆÁ´ØÂ∞çÁ´ØÁöÑÂΩ±ÁâáÊé®ÁêÜÂàÜÂâ≤ÊñπÊ≥ïÔºåÂà©Áî®Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Â∞áË±êÂØåÁöÑÊôÇÁ©∫ÁâπÂæµÊ≥®ÂÖ•ÂàÜÂ±§Á¨¶Ëôü„ÄÇÊàëÂÄëÁöÑÈóúÈçµÂâµÊñ∞ÂåÖÊã¨ÊôÇÂ∫èÂãïÊÖãËÅöÂêà (TDA) ÂíåÁ¨¶ËôüÈ©ÖÂãïÈóúÈçµÂΩ±Ê†ºÈÅ∏Êìá (TKS)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂΩ±Ê†ºÂ±§Á¥öÁöÑ <SEG> ÂíåÊôÇÂ∫èÂ±§Á¥öÁöÑ <TAK> Á¨¶ËôüÔºåÂà©Áî® MLLM ÁöÑËá™Ëø¥Ê≠∏Â≠∏Áøí‰æÜÊúâÊïàÊçïÊçâÂ±ÄÈÉ®ÂíåÂÖ®ÂüüË≥áË®ä„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊáâÁî®Âü∫ÊñºÁõ∏‰ººÊÄßÁöÑÂä†Ê¨äËûçÂêàÂíåÂΩ±Ê†ºÈÅ∏ÊìáÁ≠ñÁï•ÔºåÁÑ∂ÂæåÂà©Áî® SAM2 ‰æÜÂü∑Ë°åÈóúÈçµÂΩ±Ê†ºÂàÜÂâ≤ÂíåÂÇ≥Êí≠„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ÈóúÈçµÂΩ±Ê†ºÂÆö‰ΩçÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåTKS Âú®Êé®Ë´ñÊúüÈñìÊ†πÊìö SAM2 ÁöÑÈÅÆÊìãÂàÜÊï∏ÈÅéÊøæÈóúÈçµÂΩ±Ê†º„ÄÇVRS-HQ Âú® ReVOS ‰∏äÂèñÂæóÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂú®‰∏âÂÄãÂ≠êÈõÜ‰∏≠‰ª• J&F ÂàÜÊï∏Ë∂ÖË∂ä VISA 5.9%/12.5%/9.1%„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÊñπÊ≥ïÂº∑Â§ßÁöÑÊôÇÂ∫èÊé®ÁêÜÂíåÂàÜÂâ≤ËÉΩÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÊ¨äÈáçÂ∞áÂú® VRS-HQ ÁôºÂ∏É„ÄÇ

##### **Knowledge prompt chaining for semantic modeling**
2501.08540v1 by Ning Pei Ding, Jingge Du, Zaiwen Feng

The task of building semantics for structured data such as CSV, JSON, and XML
files is highly relevant in the knowledge representation field. Even though we
have a vast of structured data on the internet, mapping them to domain
ontologies to build semantics for them is still very challenging as it requires
the construction model to understand and learn graph-structured knowledge.
Otherwise, the task will require human beings' effort and cost. In this paper,
we proposed a novel automatic semantic modeling framework: Knowledge Prompt
Chaining. It can serialize the graph-structured knowledge and inject it into
the LLMs properly in a Prompt Chaining architecture. Through this knowledge
injection and prompting chaining, the model in our framework can learn the
structure information and latent space of the graph and generate the semantic
labels and semantic graphs following the chains' insturction naturally. Based
on experimental results, our method achieves better performance than existing
leading techniques, despite using reduced structured input data.

ÊëòË¶ÅÔºöÂú®Áü•Ë≠òË°®Á§∫È†òÂüü‰∏≠ÔºåÁÇ∫ÁµêÊßãÂåñË≥áÊñôÔºà‰æãÂ¶Ç CSV„ÄÅJSON Âíå XML Ê™îÊ°àÔºâÂª∫Á´ãË™ûÊÑèÁöÑ‰ªªÂãôÈùûÂ∏∏ÈáçË¶Å„ÄÇÂÑòÁÆ°Á∂≤Ë∑Ø‰∏äÊúâÂ§ßÈáèÁöÑÁµêÊßãÂåñË≥áÊñôÔºå‰ΩÜÂ∞áÂÆÉÂÄëÂ∞çÊáâÂà∞È†òÂüüÊú¨‰Ωì‰ª•Âª∫Á´ãË™ûÊÑè‰ªçÁÑ∂ÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÈÄôÈúÄË¶ÅÂª∫ÊßãÊ®°Âûã‰æÜÁêÜËß£ÂíåÂ≠∏ÁøíÂúñÂΩ¢ÁµêÊßãÁöÑÁü•Ë≠ò„ÄÇÂê¶ÂâáÔºåÊ≠§‰ªªÂãôÂ∞áÈúÄË¶Å‰∫∫È°ûÁöÑÂä™ÂäõÂíåÊàêÊú¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËá™ÂãïË™ûÁæ©Âª∫Ê®°Ê°ÜÊû∂ÔºöÁü•Ë≠òÊèêÁ§∫ÈèàÊé•„ÄÇÂÆÉÂèØ‰ª•Â∫èÂàóÂåñÂúñÂΩ¢ÁµêÊßãÁöÑÁü•Ë≠òÔºå‰∏¶ÈÅ©Áï∂Âú∞Â∞áÂÖ∂Ê≥®ÂÖ•Âà∞ÊèêÁ§∫ÈèàÊé•Êû∂Êßã‰∏≠ÁöÑ LLM ‰∏≠„ÄÇÈÄèÈÅéÈÄôÁ®ÆÁü•Ë≠òÊ≥®ÂÖ•ÂíåÊèêÁ§∫ÈèàÊé•ÔºåÊàëÂÄëÊ°ÜÊû∂‰∏≠ÁöÑÊ®°ÂûãÂèØ‰ª•Â≠∏ÁøíÂúñÂΩ¢ÁöÑÁµêÊßãË≥áË®äÂíåÊΩõÂú®Á©∫ÈñìÔºå‰∏¶Ëá™ÁÑ∂Âú∞ÈÅµÂæ™ÈèàÊé•ÁöÑÊåáÁ§∫‰æÜÁî¢ÁîüË™ûÁæ©Ê®ôÁ±§ÂíåË™ûÁæ©Âúñ„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÂÑòÁÆ°‰ΩøÁî®Ê∏õÂ∞ëÁöÑÁµêÊßãÂåñËº∏ÂÖ•Ë≥áÊñôÔºå‰ΩÜÊàëÂÄëÁöÑÊñπÊ≥ï‰ªçÊØîÁèæÊúâÁöÑÈ†òÂÖàÊäÄË°ìÁç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ

##### **Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers**
2501.08537v1 by Zhongwang Zhang, Pengxiao Lin, Zhiwei Wang, Yaoyu Zhang, Zhi-Qin John Xu

Transformers have demonstrated impressive capabilities across various tasks,
yet their performance on compositional problems remains a subject of debate. In
this study, we investigate the internal mechanisms underlying Transformers'
behavior in compositional tasks. We find that complexity control strategies
significantly influence whether the model learns primitive-level rules that
generalize out-of-distribution (reasoning-based solutions) or relies solely on
memorized mappings (memory-based solutions). By applying masking strategies to
the model's information circuits and employing multiple complexity metrics, we
reveal distinct internal working mechanisms associated with different solution
types. Further analysis reveals that reasoning-based solutions exhibit a lower
complexity bias, which aligns with the well-studied neuron condensation
phenomenon. This lower complexity bias is hypothesized to be the key factor
enabling these solutions to learn reasoning rules. We validate these
conclusions across multiple real-world datasets, including image generation and
natural language processing tasks, confirming the broad applicability of our
findings.

ÊëòË¶ÅÔºöËÆäÂΩ¢ÈáëÂâõÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå
‰ΩÜÂÆÉÂÄëÂú®ÁµÑÂêàÂïèÈ°å‰∏äÁöÑË°®Áèæ‰ªçÊúâÁà≠Ë≠∞„ÄÇÂú®
Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜËÆäÂΩ¢ÈáëÂâõÂú®ÁµÑÂêà‰ªªÂãô‰∏≠ÁöÑË°åÁÇ∫ËÉåÂæåÁöÑÂü∫Êú¨Ê©üÂà∂„ÄÇÊàëÂÄëÁôºÁèæË§áÈõúÊÄßÊéßÂà∂Á≠ñÁï•
È°ØËëóÂΩ±ÈüøÊ®°ÂûãÊòØÂê¶Â≠∏ÁøíÂéüÂßãÁ¥öÂà•ÁöÑË¶èÂâáÔºåÈÄô‰∫õË¶èÂâáÊ¶ÇÊã¨‰∫ÜÂàÜÂ∏ÉÂ§ñÔºàÂü∫ÊñºÊé®ÁêÜÁöÑËß£Ê±∫ÊñπÊ°àÔºâÊàñÂÉÖ‰æùË≥¥
Ë®òÊÜ∂Êò†Â∞ÑÔºàÂü∫ÊñºË®òÊÜ∂ÁöÑËß£Ê±∫ÊñπÊ°àÔºâ„ÄÇÈÄöÈÅéÂ∞ç
Ê®°ÂûãÁöÑ‰ø°ÊÅØÈõªË∑ØÊáâÁî®Â±èËîΩÁ≠ñÁï•‰∏¶Êé°Áî®Â§öÂÄãË§áÈõúÊÄßÊåáÊ®ôÔºåÊàëÂÄë
Êè≠Á§∫‰∫ÜËàá‰∏çÂêåËß£Ê±∫ÊñπÊ°àÈ°ûÂûãÁõ∏ÈóúÁöÑ‰∏çÂêåÂÖßÈÉ®Â∑•‰ΩúÊ©üÂà∂„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË°®ÊòéÔºåÂü∫ÊñºÊé®ÁêÜÁöÑËß£Ê±∫ÊñπÊ°àË°®ÁèæÂá∫ËºÉ‰ΩéÁöÑ
Ë§áÈõúÊÄßÂÅèÂ∑ÆÔºåÈÄôËàáÁ†îÁ©∂ÂÖÖÂàÜÁöÑÁ•ûÁ∂ìÂÖÉÂáùËÅöÁèæË±°‰∏ÄËá¥„ÄÇÂÅáË®≠ÈÄôÁ®ÆËºÉ‰ΩéÁöÑË§áÈõúÊÄßÂÅèÂ∑ÆÊòØ
‰ΩøÈÄô‰∫õËß£Ê±∫ÊñπÊ°àËÉΩÂ§†Â≠∏ÁøíÊé®ÁêÜË¶èÂâáÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊàëÂÄëÈ©óË≠â‰∫ÜÈÄô‰∫õ
ÁµêË´ñË∑®Â§öÂÄãÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜÔºåÂåÖÊã¨ÂúñÂÉèÁîüÊàêÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºåÁ¢∫Ë™ç‰∫ÜÊàëÂÄë
ÁôºÁèæÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄß„ÄÇ

##### **Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy**
2501.08528v1 by Runsheng Lin, Zihan Xing, Mingze Ma, Raymond S. T. Lee

With the development of deep learning, Dynamic Portfolio Optimization (DPO)
problem has received a lot of attention in recent years, not only in the field
of finance but also in the field of deep learning. Some advanced research in
recent years has proposed the application of Deep Reinforcement Learning (DRL)
to the DPO problem, which demonstrated to be more advantageous than supervised
learning in solving the DPO problem. However, there are still certain unsolved
issues: 1) DRL algorithms usually have the problems of slow learning speed and
high sample complexity, which is especially problematic when dealing with
complex financial data. 2) researchers use DRL simply for the purpose of
obtaining high returns, but pay little attention to the problem of risk control
and trading strategy, which will affect the stability of model returns. In
order to address these issues, in this study we revamped the intrinsic
structure of the model based on the Deep Deterministic Policy Gradient (DDPG)
and proposed the Augmented DDPG model. Besides, we also proposed an innovative
risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum
Finance Theory (QFT). Our experimental results revealed that our model has
better profitability as well as risk control ability with less sample
complexity in the DPO problem compared to the baseline models.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÊ∑±Â∫¶Â≠∏ÁøíÁöÑÁôºÂ±ïÔºåÂãïÊÖãÊäïË≥áÁµÑÂêàÊúÄ‰Ω≥ÂåñÔºàDPOÔºâÂïèÈ°åËøëÂπ¥‰æÜÂèóÂà∞Âª£Ê≥õÈóúÊ≥®Ôºå‰∏çÂÉÖÂú®ÈáëËûçÈ†òÂüüÔºå‰πüÂú®Ê∑±Â∫¶Â≠∏ÁøíÈ†òÂüü„ÄÇËøëÂπ¥‰æÜ‰∏Ä‰∫õÈÄ≤ÈöéÁöÑÁ†îÁ©∂ÊèêÂá∫Â∞áÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÔºàDRLÔºâÊáâÁî®Êñº DPO ÂïèÈ°åÔºåË≠âÊòéÊØîÁõ£Áù£ÂºèÂ≠∏ÁøíÂú®Ëß£Ê±∫ DPO ÂïèÈ°å‰∏äÊõ¥ÊúâÂÑ™Âã¢„ÄÇÁÑ∂ËÄåÔºå‰ªçÂ≠òÂú®‰∏Ä‰∫õÊú™Ëß£Ê±∫ÁöÑÂïèÈ°åÔºö1ÔºâDRL ÊºîÁÆóÊ≥ïÈÄöÂ∏∏ÊúâÂ≠∏ÁøíÈÄüÂ∫¶ÊÖ¢„ÄÅÊ®£Êú¨Ë§áÈõúÂ∫¶È´òÁöÑÂïèÈ°åÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜË§áÈõúÁöÑÈáëËûçË≥áÊñôÊôÇÊúÉÂá∫ÁèæÂïèÈ°å„ÄÇ2ÔºâÁ†îÁ©∂‰∫∫Âì°‰ΩøÁî® DRL ÂÉÖÂÉÖÊòØÁÇ∫‰∫ÜÁç≤ÂæóÈ´òÂ†±ÈÖ¨Ôºå‰ΩÜËºÉÂ∞ëÈóúÊ≥®È¢®Èö™ÊéßÁÆ°Âíå‰∫§ÊòìÁ≠ñÁï•ÁöÑÂïèÈ°åÔºåÈÄôÂ∞áÂΩ±ÈüøÊ®°ÂûãÂ†±ÈÖ¨ÁöÑÁ©©ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊú¨Á†îÁ©∂‰ª•Ê∑±Â∫¶Á¢∫ÂÆöÊÄßÁ≠ñÁï•Ê¢ØÂ∫¶ÔºàDDPGÔºâÁÇ∫Âü∫Á§éÔºåÊîπÈÄ†‰∫ÜÊ®°ÂûãÁöÑÂÖßÂú®ÁµêÊßãÔºå‰∏¶ÊèêÂá∫‰∫ÜÊì¥Â¢û DDPG Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÈ¢®Èö™ÊéßÁÆ°Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Âü∫ÊñºÈáèÂ≠êÈáëËûçÁêÜË´ñÔºàQFTÔºâË°çÁîüÁöÑÈáèÂ≠êÂÉπÊ†ºÊ∞¥Ê∫ñÔºàQPLÔºâ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂü∫Á∑öÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® DPO ÂïèÈ°å‰∏äÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÁç≤Âà©ËÉΩÂäõÂíåÈ¢®Èö™ÊéßÁÆ°ËÉΩÂäõÔºå‰∏îÊ®£Êú¨Ë§áÈõúÂ∫¶ËºÉ‰Ωé„ÄÇ</paragraph>

##### **Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation**
2501.08523v1 by Jiaxin Guo, Yuanchang Luo, Daimeng Wei, Ling Zhang, Zongyao Li, Hengchao Shang, Zhiqiang Rao, Shaojun Li, Jinlong Yang, Zhanglin Wu, Hao Yang

The field of artificial intelligence has witnessed significant advancements
in natural language processing, largely attributed to the capabilities of Large
Language Models (LLMs). These models form the backbone of Agents designed to
address long-context dependencies, particularly in Document-level Machine
Translation (DocMT). DocMT presents unique challenges, with quality,
consistency, and fluency being the key metrics for evaluation. Existing
approaches, such as Doc2Doc and Doc2Sent, either omit sentences or compromise
fluency. This paper introduces Doc-Guided Sent2Sent++, an Agent that employs an
incremental sentence-level forced decoding strategy \textbf{to ensure every
sentence is translated while enhancing the fluency of adjacent sentences.} Our
Agent leverages a Doc-Guided Memory, focusing solely on the summary and its
translation, which we find to be an efficient approach to maintaining
consistency. Through extensive testing across multiple languages and domains,
we demonstrate that Sent2Sent++ outperforms other methods in terms of quality,
consistency, and fluency. The results indicate that, our approach has achieved
significant improvements in metrics such as s-COMET, d-COMET, LTCR-$1_f$, and
document-level perplexity (d-ppl). The contributions of this paper include a
detailed analysis of current DocMT research, the introduction of the
Sent2Sent++ decoding method, the Doc-Guided Memory mechanism, and validation of
its effectiveness across languages and domains.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÈ¢ÜÂüüËßÅËØÅ‰∫ÜËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁöÑÈáçÂ§ßËøõÂ±ïÔºåËøôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂΩíÂäü‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ„ÄÇËøô‰∫õÊ®°ÂûãÊûÑÊàê‰∫Ü‰ª£ÁêÜÁöÑÂü∫Á°ÄÔºåÊó®Âú®Ëß£ÂÜ≥Èïø‰∏ä‰∏ãÊñá‰æùËµñÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊñáÊ°£Á∫ßÊú∫Âô®ÁøªËØë (DocMT) ‰∏≠„ÄÇDocMT ÂëàÁé∞Âá∫Áã¨ÁâπÁöÑÊåëÊàòÔºåÂÖ∂‰∏≠Ë¥®Èáè„ÄÅ‰∏ÄËá¥ÊÄßÂíåÊµÅÁïÖÊÄßÊòØËØÑ‰º∞ÁöÑÂÖ≥ÈîÆÊåáÊ†á„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÔºå‰æãÂ¶Ç Doc2Doc Âíå Doc2SentÔºåË¶Å‰πàÁúÅÁï•Âè•Â≠êÔºåË¶Å‰πàÂΩ±ÂìçÊµÅÁïÖÊÄß„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü Doc-Guided Sent2Sent++ÔºåËøôÊòØ‰∏Ä‰∏™ÈááÁî®Â¢ûÈáèÂè•Â≠êÁ∫ßÂº∫Âà∂Ëß£Á†ÅÁ≠ñÁï•ÁöÑ‰ª£ÁêÜÔºå‰ª•Á°Æ‰øùÁøªËØëÊØè‰∏™Âè•Â≠êÔºåÂêåÊó∂Â¢ûÂº∫Áõ∏ÈÇªÂè•Â≠êÁöÑÊµÅÁïÖÊÄß„ÄÇÊàë‰ª¨ÁöÑ‰ª£ÁêÜÂà©Áî® Doc-Guided MemoryÔºå‰ªÖÂÖ≥Ê≥®ÊëòË¶ÅÂèäÂÖ∂ÁøªËØëÔºåÊàë‰ª¨ÂèëÁé∞ËøôÊòØ‰∏ÄÁßç‰øùÊåÅ‰∏ÄËá¥ÊÄßÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÈÄöËøáË∑®Â§ö‰∏™ËØ≠Ë®ÄÂíåÈ¢ÜÂüüÁöÑÂπøÊ≥õÊµãËØïÔºåÊàë‰ª¨ËØÅÊòé Sent2Sent++ Âú®Ë¥®Èáè„ÄÅ‰∏ÄËá¥ÊÄßÂíåÊµÅÁïÖÊÄßÊñπÈù¢‰ºò‰∫éÂÖ∂‰ªñÊñπÊ≥ï„ÄÇÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® s-COMET„ÄÅd-COMET„ÄÅLTCR-$1_f$ ÂíåÊñáÊ°£Á∫ßÂõ∞ÊÉëÂ∫¶ (d-ppl) Á≠âÊåáÊ†áÊñπÈù¢ÂèñÂæó‰∫ÜÊòæÁùÄÊîπËøõ„ÄÇÊú¨ÊñáÁöÑË¥°ÁåÆÂåÖÊã¨ÂØπÂΩìÂâç DocMT Á†îÁ©∂ÁöÑËØ¶ÁªÜÂàÜÊûê„ÄÅSent2Sent++ Ëß£Á†ÅÊñπÊ≥ïÁöÑ‰ªãÁªç„ÄÅDoc-Guided Memory Êú∫Âà∂Ôºå‰ª•ÂèäË∑®ËØ≠Ë®ÄÂíåÈ¢ÜÂüüÁöÑÊúâÊïàÊÄßÈ™åËØÅ„ÄÇ

##### **Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes**
2501.08521v1 by Huy Q. Le, Ye Lin Tun, Yu Qiao, Minh N. H. Nguyen, Keon Oh Kim, Choong Seon Hong

Federated Learning (FL) has emerged as a decentralized machine learning
technique, allowing clients to train a global model collaboratively without
sharing private data. However, most FL studies ignore the crucial challenge of
heterogeneous domains where each client has a distinct feature distribution,
which is common in real-world scenarios. Prototype learning, which leverages
the mean feature vectors within the same classes, has become a prominent
solution for federated learning under domain skew. However, existing federated
prototype learning methods only consider inter-domain prototypes on the server
and overlook intra-domain characteristics. In this work, we introduce a novel
federated prototype learning method, namely I$^2$PFL, which incorporates
$\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, to
mitigate domain shifts and learn a generalized global model across multiple
domains in federated learning. To construct intra-domain prototypes, we propose
feature alignment with MixUp-based augmented prototypes to capture the
diversity of local domains and enhance the generalization of local features.
Additionally, we introduce a reweighting mechanism for inter-domain prototypes
to generate generalized prototypes to provide inter-domain knowledge and reduce
domain skew across multiple clients. Extensive experiments on the Digits,
Office-10, and PACS datasets illustrate the superior performance of our method
compared to other baselines.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂàÜÊï£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂÖÅË®±ÂÆ¢Êà∂Âú®‰∏çÂÖ±Áî®ÁßÅ‰∫∫Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂçîÂêåË®ìÁ∑¥ÂÖ®ÁêÉÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ FL Á†îÁ©∂ÂøΩÁï•‰∫ÜÁï∞Ë≥™Á∂≤ÂüüÁöÑÈóúÈçµÊåëÊà∞ÔºåÂÖ∂‰∏≠ÊØèÂÄãÂÆ¢Êà∂Á´ØÈÉΩÊúâ‰∏çÂêåÁöÑÁâπÂæµÂàÜÂ∏ÉÔºåÈÄôÂú®ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÂæàÂ∏∏Ë¶ã„ÄÇÂéüÂûãÂ≠∏ÁøíÂà©Áî®Áõ∏ÂêåÈ°ûÂà•‰∏≠ÁöÑÂπ≥ÂùáÁâπÂæµÂêëÈáèÔºåÂ∑≤ÊàêÁÇ∫Âú®Á∂≤ÂüüÂÅèÂ∑Æ‰∏ãÈÄ≤Ë°åËÅØÈÇ¶Â≠∏ÁøíÁöÑÂÇëÂá∫Ëß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑËÅØÈÇ¶ÂéüÂûãÂ≠∏ÁøíÊñπÊ≥ïÂÉÖËÄÉÊÖÆ‰º∫ÊúçÂô®‰∏äÁöÑÁ∂≤ÂüüÈñìÂéüÂûãÔºåËÄåÂøΩÁï•‰∫ÜÁ∂≤ÂüüÂÖßÁâπÂæµ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑËÅØÈÇ¶ÂéüÂûãÂ≠∏ÁøíÊñπÊ≥ïÔºåÂç≥ I$^2$PFLÔºåÂÆÉÁµêÂêà‰∫ÜÁ∂≤ÂüüÂÖßÂíåÁ∂≤ÂüüÈñìÂéüÂûãÔºå‰ª•Ê∏õËºïÁ∂≤ÂüüËΩâÁßªÔºå‰∏¶Âú®ËÅØÈÇ¶Â≠∏Áøí‰∏≠Ë∑®Â§öÂÄãÁ∂≤ÂüüÂ≠∏ÁøíÂª£Áæ©ÁöÑÂÖ®ÁêÉÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÂª∫ÊßãÁ∂≤ÂüüÂÖßÂéüÂûãÔºåÊàëÂÄëÊèêÂá∫‰ΩøÁî®Âü∫Êñº MixUp ÁöÑÊì¥ÂÖÖÂéüÂûãÁöÑÁâπÂæµÊØîÂ∞çÔºå‰ª•Êì∑ÂèñÊú¨Âú∞Á∂≤ÂüüÁöÑÂ§öÊ®£ÊÄßÔºå‰∏¶Â¢ûÂº∑Êú¨Âú∞ÁâπÂæµÁöÑÊ¶ÇÊã¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫Á∂≤ÂüüÈñìÂéüÂûãÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈáçÊñ∞Âä†Ê¨äÊ©üÂà∂Ôºå‰ª•Áî¢ÁîüÂª£Áæ©ÂéüÂûãÔºå‰ª•Êèê‰æõÁ∂≤ÂüüÈñìÁü•Ë≠ò‰∏¶Ê∏õÂ∞ëÂ§öÂÄãÂÆ¢Êà∂Á´Ø‰πãÈñìÁöÑÁ∂≤ÂüüÂÅèÂ∑Æ„ÄÇÂú® Digits„ÄÅOffice-10 Âíå PACS Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË™™Êòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïËàáÂÖ∂‰ªñÂü∫Á∑öÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ

##### **Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training**
2501.08506v1 by Kavita Selva, Satita Vittayaareekul, Brando Miranda

Currently, data and model size dominate the narrative in the training of
super-large, powerful models. However, there has been a lack of exploration on
the effect of other attributes of the training dataset on model performance. We
hypothesize that dataset diversity can impact the performance of vision models.
Our study shows positive correlations between test set accuracy and data
diversity, providing an argument for furthering the research of dataset
attributes beyond size. We analyzed pre-training and model-agnostic
meta-learning methods on twelve popular visual datasets (e.g., Omniglot,
CIFAR-FS, Aircraft) and five model configurations, including MAML variants with
different numbers of inner gradient steps and supervised learning. We show
moderate to strong positive correlations (R-squared: 0.15-0.42) between
accuracy and data diversity and weaker but significant correlations (R-squared:
~0.2) between loss and diversity. These findings support our hypothesis and
demonstrate a promising way for a deeper exploration of how formal data
diversity influences model performance. This initial study highlights the
potential of (Task2Vec) data diversity as a valuable measure in the rapidly
evolving field of large-scale learning and emphasizes that understanding the
dataset is key to building more powerful and generalizable models.

ÊëòË¶ÅÔºöÁõÆÂâçÔºåË≥áÊñôÂíåÊ®°ÂûãÂ§ßÂ∞è‰∏ªÂ∞é‰∫ÜË∂ÖÁ¥öÂ§ßÂûã„ÄÅÂº∑Â§ßÊ®°ÂûãÁöÑË®ìÁ∑¥ÊïòËø∞„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÂÖ∂‰ªñÂ±¨ÊÄßÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±ÈüøÔºå‰∏ÄÁõ¥Áº∫‰πèÊé¢Ë®é„ÄÇÊàëÂÄëÂÅáË®≠Ë≥áÊñôÈõÜÁöÑÂ§öÊ®£ÊÄßÊúÉÂΩ±ÈüøË¶ñË¶∫Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫Ê∏¨Ë©¶ÈõÜÊ∫ñÁ¢∫Â∫¶ÂíåË≥áÊñôÂ§öÊ®£ÊÄß‰πãÈñìÂ≠òÂú®Ê≠£Áõ∏ÈóúÔºåÈÄôÁÇ∫ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Ë≥áÊñôÈõÜÂ±¨ÊÄßÔºà‰∏çÂè™Â§ßÂ∞èÔºâÊèê‰æõ‰∫ÜË´ñÊìö„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂçÅ‰∫åÂÄãÊµÅË°åÁöÑË¶ñË¶∫Ë≥áÊñôÈõÜÔºà‰æãÂ¶Ç Omniglot„ÄÅCIFAR-FS„ÄÅAircraftÔºâÂíå‰∫îÁ®ÆÊ®°ÂûãÁµÑÊÖãÔºàÂåÖÊã¨ÂÖ∑Êúâ‰∏çÂêåÂÖßÈÉ®Ê¢ØÂ∫¶Ê≠•È©üÊï∏ÁöÑ MAML ËÆäÈ´îÂíåÁõ£Áù£ÂºèÂ≠∏ÁøíÔºâ‰∏äÁöÑÈ†êË®ìÁ∑¥ÂíåËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÂÖÉÂ≠∏ÁøíÊñπÊ≥ï„ÄÇÊàëÂÄëÈ°ØÁ§∫Ê∫ñÁ¢∫Â∫¶ÂíåË≥áÊñôÂ§öÊ®£ÊÄß‰πãÈñìÂ≠òÂú®‰∏≠Á≠âËá≥Âº∑ÁÉàÁöÑÊ≠£Áõ∏ÈóúÔºàR Âπ≥ÊñπÔºö0.15-0.42ÔºâÔºåÊêçÂ§±ÂíåÂ§öÊ®£ÊÄß‰πãÈñìÂ≠òÂú®ËºÉÂº±‰ΩÜÈ°ØËëóÁöÑÁõ∏ÈóúÊÄßÔºàR Âπ≥ÊñπÔºö~0.2Ôºâ„ÄÇÈÄô‰∫õÁôºÁèæÊîØÊåÅÊàëÂÄëÁöÑÂÅáË®≠Ôºå‰∏¶Â±ïÁ§∫‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Êõ¥Ê∑±ÂÖ•Âú∞Êé¢Ë®éÊ≠£ÂºèË≥áÊñôÂ§öÊ®£ÊÄßÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩ„ÄÇÈÄôÈ†ÖÂàùÊ≠•Á†îÁ©∂Á™ÅÈ°Ø‰∫ÜÔºàTask2VecÔºâË≥áÊñôÂ§öÊ®£ÊÄß‰ΩúÁÇ∫Âø´ÈÄüÁôºÂ±ïÁöÑÂ§ßË¶èÊ®°Â≠∏ÁøíÈ†òÂüü‰∏≠‰∏ÄÈ†ÖÊúâÂÉπÂÄºÁöÑË°°ÈáèÊ®ôÊ∫ñÁöÑÊΩõÂäõÔºå‰∏¶Âº∑Ë™ø‰∫ÜËß£Ë≥áÊñôÈõÜÊòØÂª∫ÊßãÊõ¥Âº∑Â§ß‰∏îÊõ¥ÂÖ∑Ê≥õÂåñÊÄßÁöÑÊ®°ÂûãÁöÑÈóúÈçµ„ÄÇ

##### **Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom**
2501.08502v1 by Melissa Torgbi, Andrew Clayman, Jordan J. Speight, Harish Tayyar Madabushi

We collect novel data in the public service domain to evaluate the capability
of the state-of-the-art automatic speech recognition (ASR) models in capturing
regional differences in accents in the United Kingdom (UK), specifically
focusing on two accents from Scotland with distinct dialects. This study
addresses real-world problems where biased ASR models can lead to
miscommunication in public services, disadvantaging individuals with regional
accents particularly those in vulnerable populations. We first examine the
out-of-the-box performance of the Whisper large-v3 model on a baseline dataset
and our data. We then explore the impact of fine-tuning Whisper on the
performance in the two UK regions and investigate the effectiveness of existing
model evaluation techniques for our real-world application through manual
inspection of model errors. We observe that the Whisper model has a higher word
error rate (WER) on our test datasets compared to the baseline data and
fine-tuning on a given data improves performance on the test dataset with the
same domain and accent. The fine-tuned models also appear to show improved
performance when applied to the test data outside of the region it was trained
on suggesting that fine-tuned models may be transferable within parts of the
UK. Our manual analysis of model outputs reveals the benefits and drawbacks of
using WER as an evaluation metric and fine-tuning to adapt to regional
dialects.

ÊëòË¶ÅÔºöÊàëÂÄëÂú®ÂÖ¨ÂÖ±ÊúçÂãôÈ†òÂüüÊî∂ÈõÜÊñ∞Á©éÊï∏ÊìöÔºå‰ª•Ë©ï‰º∞ÊúÄÂÖàÈÄ≤ÁöÑËá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR) Ê®°ÂûãÂú®ÊçïÊçâËã±ÂúãÂçÄÂüüÂè£Èü≥Â∑ÆÁï∞ÁöÑËÉΩÂäõÔºåÁâπÂà•Â∞àÊ≥®ÊñºËòáÊ†ºËò≠ÂÖ©ÂÄãÂÖ∑Êúâ‰∏çÂêåÊñπË®ÄÁöÑÂè£Èü≥„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êé¢Ë®é‰∫ÜÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÂïèÈ°åÔºåÂÖ∂‰∏≠ÊúâÂÅèÂ∑ÆÁöÑ ASR Ê®°ÂûãÂèØËÉΩÂ∞éËá¥ÂÖ¨ÂÖ±ÊúçÂãô‰∏≠ÁöÑÊ∫ùÈÄö‰∏çËâØÔºåÁâπÂà•ÊòØÂ∞çÂº±Âã¢Áæ§È´î‰∏≠ÂÖ∑ÊúâÂçÄÂüüÂè£Èü≥ÁöÑÂÄã‰∫∫ÈÄ†Êàê‰∏çÂà©ÂΩ±Èüø„ÄÇÊàëÂÄëÈ¶ñÂÖàÊ™¢Êü• Whisper large-v3 Ê®°ÂûãÂú®Âü∫Á∑öÊï∏ÊìöÈõÜÂíåÊàëÂÄëÊï∏Êìö‰∏äÁöÑÈñãÁÆ±Âç≥Áî®ÊïàËÉΩ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé¢Ë®éÂæÆË™ø Whisper Â∞çËã±ÂúãÂÖ©ÂÄãÂú∞ÂçÄÊïàËÉΩÁöÑÂΩ±ÈüøÔºå‰∏¶ÈÄèÈÅéÊâãÂãïÊ™¢Êü•Ê®°ÂûãÈåØË™§‰æÜÊé¢Ë®éÁèæÊúâÊ®°ÂûãË©ï‰º∞ÊäÄË°ìÂ∞çÊàëÂÄëÁèæÂØ¶‰∏ñÁïåÊáâÁî®Á®ãÂºèÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåËàáÂü∫Á∑öÊï∏ÊìöÁõ∏ÊØîÔºåWhisper Ê®°ÂûãÂú®ÊàëÂÄëÁöÑÊ∏¨Ë©¶Êï∏ÊìöÈõÜ‰∏äÂÖ∑ÊúâËºÉÈ´òÁöÑÂ≠óÂÖÉÈåØË™§Áéá (WER)Ôºå‰∏¶‰∏îÂú®ÁâπÂÆöÊï∏Êìö‰∏äÈÄ≤Ë°åÂæÆË™øÊúÉÊîπÂñÑÂÖ∑ÊúâÁõ∏ÂêåÈ†òÂüüÂíåÂè£Èü≥ÁöÑÊ∏¨Ë©¶Êï∏ÊìöÈõÜ‰∏äÁöÑÊïàËÉΩ„ÄÇÂæÆË™øÂæåÁöÑÊ®°ÂûãÂú®ÊáâÁî®ÊñºË®ìÁ∑¥ÂçÄÂüü‰ª•Â§ñÁöÑÊ∏¨Ë©¶Êï∏ÊìöÊôÇÔºå‰ºº‰πé‰πüÈ°ØÁ§∫Âá∫ÊîπÂñÑÁöÑÊïàËÉΩÔºåÈÄôË°®ÊòéÂæÆË™øÂæåÁöÑÊ®°ÂûãÂèØËÉΩÂèØ‰ª•Âú®Ëã±ÂúãÈÉ®ÂàÜÂú∞ÂçÄËΩâÁßª„ÄÇÊàëÂÄëÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÊâãÂãïÂàÜÊûêÊè≠Á§∫‰∫Ü‰ΩøÁî® WER ‰ΩúÁÇ∫Ë©ï‰º∞ÊåáÊ®ôÂíåÂæÆË™ø‰ª•ÈÅ©ÊáâÂçÄÂüüÊñπË®ÄÁöÑÂÑ™Áº∫Èªû„ÄÇ

##### **Quantifying the Importance of Data Alignment in Downstream Model Performance**
2501.08496v1 by Krrish Chawla, Aryan Sahai, Mario DePavia, Sudharsan Sundar, Brando Miranda

Contrary to the conventional emphasis on dataset size, we explore the role of
data alignment -- an often overlooked aspect of data quality -- in training
capable Large Language Models (LLMs). To do so, we use the Task2Vec-based
alignment coefficient, a quantitative measure of the similarity between two
datasets, to quantify the impact of alignment between training data and
evaluation data on downstream performance. In particular, we conduct controlled
\textit{interventional} experiments for two settings: 1. the impact of
increased alignment coefficients between various pre-training (pt) against
evaluation datasets, and 2. the impact of increased alignment coefficients
between domain specific fine-tuning (ft) against domain specific evaluation.
The domain specific task we explore is Autoformalization -- the machine
translation task between natural language and code for formal verification. In
both settings, we find a strong, predictable negative correlation between the
alignment coefficient of a model's training and evaluation data and the model's
loss/perplexity on the respective downstream task. These findings suggest a
re-evaluation of LLM training approaches, demonstrating the relevance of data
alignment compared to data quantity, especially in specialized downstream tasks
such as Autoformalization.

ÊëòË¶ÅÔºöËàáÂÇ≥Áµ±Âº∑Ë™øË≥áÊñôÈõÜÂ§ßÂ∞èÁõ∏ÂèçÔºåÊàëÂÄëÊé¢Ë®éË≥áÊñôÂ∞çÈΩäÁöÑËßíËâ≤ - Ë≥áÊñôÂìÅË≥™‰∏≠Á∂ìÂ∏∏Ë¢´ÂøΩÁï•ÁöÑÂ±§Èù¢ - Âú®Ë®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®Âü∫Êñº Task2Vec ÁöÑÂ∞çÈΩä‰øÇÊï∏ÔºåÈÄôÊòØË°°ÈáèÂÖ©ÂÄãË≥áÊñôÈõÜÁõ∏‰ººÊÄßÁöÑÈáèÂåñÊåáÊ®ôÔºåÁî®ÊñºÈáèÂåñË®ìÁ∑¥Ë≥áÊñôÂíåË©ï‰º∞Ë≥áÊñô‰πãÈñìÁöÑÂ∞çÈΩäÂ∞ç‰∏ãÊ∏∏ÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÈáùÂ∞çÂÖ©Á®ÆË®≠ÂÆöÈÄ≤Ë°åÂèóÊéßÁöÑ„Äå‰ªãÂÖ•„ÄçÂØ¶È©óÔºö1. ÂêÑÁ®ÆÈ†êË®ìÁ∑¥ (pt) ËàáË©ï‰º∞Ë≥áÊñôÈõÜ‰πãÈñìÂ¢ûÂä†Â∞çÈΩä‰øÇÊï∏ÁöÑÂΩ±ÈüøÔºå‰ª•Âèä 2. È†òÂüüÁâπÂÆöÂæÆË™ø (ft) ËàáÈ†òÂüüÁâπÂÆöË©ï‰º∞‰πãÈñìÂ¢ûÂä†Â∞çÈΩä‰øÇÊï∏ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊé¢Ë®éÁöÑÈ†òÂüüÁâπÂÆö‰ªªÂãôÊòØËá™ÂãïÂΩ¢ÂºèÂåñ - Ëá™ÁÑ∂Ë™ûË®ÄËàáÁ®ãÂºèÁ¢º‰πãÈñìÁöÑÊ©üÂô®ÁøªË≠ØÔºåÁî®ÊñºÂΩ¢ÂºèÈ©óË≠â„ÄÇÂú®ÈÄôÂÖ©Á®ÆË®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÁôºÁèæÊ®°ÂûãË®ìÁ∑¥ÂíåË©ï‰º∞Ë≥áÊñôÁöÑÂ∞çÈΩä‰øÇÊï∏ËàáÊ®°ÂûãÂú®ÂêÑËá™‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑÊêçÂ§±/Âõ∞ÊÉëÂ∫¶‰πãÈñìÂ≠òÂú®Âº∑ÁÉàÁöÑ„ÄÅÂèØÈ†êÊ∏¨ÁöÑË≤†Áõ∏Èóú„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÈáçÊñ∞Ë©ï‰º∞ LLM Ë®ìÁ∑¥ÊñπÊ≥ïÔºåË≠âÊòéË≥áÊñôÂ∞çÈΩäËàáË≥áÊñôÈáèÁõ∏ÊØîÂÖ∑ÊúâÁõ∏ÈóúÊÄßÔºåÁâπÂà•ÊòØÂú®Ëá™ÂãïÂΩ¢ÂºèÂåñÁ≠âÂ∞àÊ•≠ÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠„ÄÇ

##### **Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition**
2501.08471v1 by Md Meem Hossain, The Anh Han, Safina Showkat Ara, Zia Ush Shamszaman

Human Activity Recognition (HAR) has gained significant importance with the
growing use of sensor-equipped devices and large datasets. This paper evaluates
the performance of three categories of models : classical machine learning,
deep learning architectures, and Restricted Boltzmann Machines (RBMs) using
five key benchmark datasets of HAR (UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and
Berkeley MHAD). We assess various models, including Decision Trees, Random
Forests, Convolutional Neural Networks (CNN), and Deep Belief Networks (DBNs),
using metrics such as accuracy, precision, recall, and F1-score for a
comprehensive comparison. The results show that CNN models offer superior
performance across all datasets, especially on the Berkeley MHAD. Classical
models like Random Forest do well on smaller datasets but face challenges with
larger, more complex data. RBM-based models also show notable potential,
particularly for feature learning. This paper offers a detailed comparison to
help researchers choose the most suitable model for HAR tasks.

ÊëòË¶ÅÔºö‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠ò (HAR) Èö®ËëóÈÖçÂÇôÊÑüÊ∏¨Âô®Ë£ùÁΩÆÂíåÂ§ßÂûãË≥áÊñôÈõÜÁöÑ‰ΩøÁî®Êó•ÁõäÊôÆÂèäÔºåËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÊú¨ÊñáË©ï‰º∞‰∫Ü‰∏âÁ®ÆÈ°ûÂà•Ê®°ÂûãÁöÑÊïàËÉΩÔºöÂÇ≥Áµ±Ê©üÂô®Â≠∏Áøí„ÄÅÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÂíåÂèóÈôêÁéªÁàæËå≤ÊõºÊ©ü (RBM)Ôºå‰ΩøÁî®‰∫îÂÄã HAR ‰∏ªË¶ÅÂü∫Ê∫ñË≥áÊñôÈõÜ (UCI-HAR„ÄÅOPPORTUNITY„ÄÅPAMAP2„ÄÅWISDM Âíå Berkeley MHAD)„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÊ∑±Â∫¶‰ø°ÂøµÁ∂≤Ë∑Ø (DBN)Ôºå‰ΩøÁî®Ê∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Á≠âÊåáÊ®ôÈÄ≤Ë°åÂÖ®Èù¢ÊØîËºÉ„ÄÇÁµêÊûúÈ°ØÁ§∫ CNN Ê®°ÂûãÂú®ÊâÄÊúâË≥áÊñôÈõÜ‰∏äÈÉΩÊèê‰æõÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú® Berkeley MHAD ‰∏ä„ÄÇÈö®Ê©üÊ£ÆÊûóÁ≠âÂÇ≥Áµ±Ê®°ÂûãÂú®ËºÉÂ∞èÁöÑË≥áÊñôÈõÜ‰∏äË°®ÁèæËâØÂ•ΩÔºå‰ΩÜÈù¢Â∞çËºÉÂ§ß„ÄÅËºÉË§áÈõúÁöÑË≥áÊñôÊôÇÊúÉÈù¢Ëá®ÊåëÊà∞„ÄÇÂü∫Êñº RBM ÁöÑÊ®°Âûã‰πüÂ±ïÁèæ‰∫ÜÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®ÁâπÂæµÂ≠∏ÁøíÊñπÈù¢„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜË©≥Á¥∞ÁöÑÊØîËºÉÔºå‰ª•ÂçîÂä©Á†îÁ©∂‰∫∫Âì°ÈÅ∏ÊìáÊúÄÈÅ©Âêà HAR ‰ªªÂãôÁöÑÊ®°Âûã„ÄÇ

##### **Detecting Contextual Anomalies by Discovering Consistent Spatial Regions**
2501.08470v1 by Zhengye Yang, Richard J. Radke

We describe a method for modeling spatial context to enable video anomaly
detection. The main idea is to discover regions that share similar object-level
activities by clustering joint object attributes using Gaussian mixture models.
We demonstrate that this straightforward approach, using orders of magnitude
fewer parameters than competing models, achieves state-of-the-art performance
in the challenging spatial-context-dependent Street Scene dataset. As a side
benefit, the high-resolution discovered regions learned by the model also
provide explainable normalcy maps for human operators without the need for any
pre-trained segmentation model.

ÊëòË¶ÅÔºöÊàëÂÄëÊèèËø∞‰∫Ü‰∏ÄÁ®ÆÂ∞çÁ©∫ÈñìËÉåÊôØÂª∫Ê®°ÁöÑÊñπÊ≥ïÔºå‰ª•ÂØ¶ÁèæÂΩ±ÁâáÁï∞Â∏∏ÂÅµÊ∏¨„ÄÇ‰∏ªË¶ÅÊ¶ÇÂøµÊòØÈÄèÈÅé‰ΩøÁî®È´òÊñØÊ∑∑ÂêàÊ®°ÂûãÂ∞çÈóúÁØÄÁâ©‰ª∂Â±¨ÊÄßÈÄ≤Ë°åÂàÜÁæ§ÔºåÊâæÂá∫ÂÖ±‰∫´È°û‰ººÁâ©‰ª∂Á¥öÂà•Ê¥ªÂãïÁöÑÂçÄÂüü„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÈÄôÁ®ÆÁõ¥Êé•ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÊØîÁ´∂Áà≠Ê®°ÂûãÂ∞ëÂπæÂÄãÊï∏ÈáèÁ¥öÁöÑÂèÉÊï∏ÔºåÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ©∫ÈñìËÉåÊôØ‰æùË≥¥ÊÄßË°óÊôØË≥áÊñôÈõÜ‰∏äÔºåÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ‰ΩúÁÇ∫È°çÂ§ñÁöÑÂÑ™ÈªûÔºåÊ®°ÂûãÊâÄÂ≠∏Âà∞ÁöÑÈ´òËß£ÊûêÂ∫¶ÁôºÁèæÂçÄÂüüÔºå‰πüÁÇ∫‰∫∫È°ûÊìç‰ΩúÂì°Êèê‰æõ‰∫ÜÂèØËß£ÈáãÁöÑÂ∏∏ÊÖãÂú∞ÂúñÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÈ†êÂÖàË®ìÁ∑¥ÁöÑÂàÜÊÆµÊ®°Âûã„ÄÇ

##### **Selective Attention Merging for low resource tasks: A case study of Child ASR**
2501.08468v1 by Natarajan Balaji Shankar, Zilai Wang, Eray Eren, Abeer Alwan

While Speech Foundation Models (SFMs) excel in various speech tasks, their
performance for low-resource tasks such as child Automatic Speech Recognition
(ASR) is hampered by limited pretraining data. To address this, we explore
different model merging techniques to leverage knowledge from models trained on
larger, more diverse speech corpora. This paper also introduces Selective
Attention (SA) Merge, a novel method that selectively merges task vectors from
attention matrices to enhance SFM performance on low-resource tasks.
Experiments on the MyST database show significant reductions in relative word
error rate of up to 14%, outperforming existing model merging and data
augmentation techniques. By combining data augmentation techniques with SA
Merge, we achieve a new state-of-the-art WER of 8.69 on the MyST database for
the Whisper-small model, highlighting the potential of SA Merge for improving
low-resource ASR.

ÊëòË¶ÅÔºöÈõñÁÑ∂Ë™ûÈü≥Âü∫Á§éÊ®°Âûã (SFM) Âú®ÂêÑÁ®ÆË™ûÈü≥‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÂú®‰ΩéË≥áÊ∫ê‰ªªÂãôÔºà‰æãÂ¶ÇÂÖíÁ´•Ëá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR)Ôºâ‰∏≠ÁöÑË°®ÁèæÂèóÂà∞È†êË®ìÁ∑¥Êï∏ÊìöÊúâÈôêÁöÑÈòªÁ§ô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Á¥¢‰∫Ü‰∏çÂêåÁöÑÊ®°ÂûãÂêà‰ΩµÊäÄË°ìÔºå‰ª•Âà©Áî®Âú®Êõ¥Â§ß„ÄÅÊõ¥Â§öÊ®£ÂåñÁöÑË™ûÈü≥Ë™ûÊñôÂ∫´‰∏äË®ìÁ∑¥Ê®°ÂûãÁöÑÁü•Ë≠ò„ÄÇÊú¨ÊñáÈÇÑ‰ªãÁ¥π‰∫ÜÈÅ∏ÊìáÊÄßÊ≥®ÊÑè (SA) Âêà‰ΩµÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÈÅ∏ÊìáÊÄßÂú∞Âêà‰Ωµ‰æÜËá™Ê≥®ÊÑèÁü©Èô£ÁöÑ‰ªªÂãôÂêëÈáèÔºå‰ª•Â¢ûÂº∑ SFM Âú®‰ΩéË≥áÊ∫ê‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇÂú® MyST Ë≥áÊñôÂ∫´‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÁõ∏Â∞çÂ≠óÈåØË™§ÁéáÈ°ØËëóÈôç‰ΩéÔºåÊúÄÈ´òÈÅî 14%ÔºåÂÑ™ÊñºÁèæÊúâÁöÑÊ®°ÂûãÂêà‰ΩµÂíåË≥áÊñôÊì¥ÂÖÖÊäÄË°ì„ÄÇÈÄèÈÅéÂ∞áË≥áÊñôÊì¥ÂÖÖÊäÄË°ìËàá SA Âêà‰ΩµÁµêÂêàÔºåÊàëÂÄëÂú® MyST Ë≥áÊñôÂ∫´‰∏äÁÇ∫ Whisper-small Ê®°ÂûãÈÅîÂà∞‰∫Ü 8.69 ÁöÑÊñ∞ÊúÄÂÖàÈÄ≤ WERÔºåÁ™ÅÈ°Ø‰∫Ü SA Âêà‰ΩµÂú®ÊîπÂñÑ‰ΩéË≥áÊ∫ê ASR ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

ÊëòË¶ÅÔºöÂú®Ê©üÂô®Â≠∏ÁøíÁöÑÁï∂‰ª£ÔºåTransformer Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆÈ†òÂüüÁöÑ‰∫ãÂØ¶Ê®ôÊ∫ñÊñπÊ≥ïÔºå‰æãÂ¶ÇÈõªËÖ¶Ë¶ñË¶∫ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂü∫Êñº Transformer ÁöÑËß£Ê±∫ÊñπÊ°àÊòØÁï∂ÂâçË™ûË®ÄÁîüÊàê„ÄÅÂΩ±ÂÉèÂíåÂΩ±ÁâáÂàÜÈ°û„ÄÅÂàÜÂâ≤„ÄÅÂãï‰ΩúÂíåÁâ©‰ª∂Ëæ®Ë≠òÁ≠âÊúÄÊñ∞ÊñπÊ≥ïÁöÑÈ™®Âππ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÈõñÁÑ∂ÈÄô‰∫õÊúÄÊñ∞ÊñπÊ≥ïÂú®ÂÖ∂ÂêÑËá™ÁöÑÈ†òÂüü‰∏≠Áî¢Áîü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁµêÊûúÔºå‰ΩÜÁêÜËß£Ë¶ñË¶∫ÂíåË™ûË®Ä‰πãÈñìÈóú‰øÇÁöÑÂïèÈ°å‰ªçÁÑ∂Ë∂ÖÂá∫‰∫ÜÊàëÂÄëÁöÑÁêÜËß£ÁØÑÂúç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ª•ÂèØËß£Èáã‰∏î‰ª•Á®ãÂºèÁÇ∫Âü∫Á§éÁöÑÊñπÂºèÔºåÂú®ÊôÇÁ©∫‰∏≠ÁöÑ‰∫ã‰ª∂‰πãÈñìÊèêÂá∫‰∫ÜË¶ñË¶∫ÂíåË™ûË®ÄÁöÑÂÖ±ÂêåÂü∫Á§éÔºå‰ª•ÈÄ£Êé•Âü∫ÊñºÂ≠∏ÁøíÁöÑË¶ñË¶∫ÂíåË™ûË®ÄÊúÄÊñ∞Ê®°ÂûãÔºå‰∏¶Êèê‰æõÊèèËø∞ÂΩ±ÁâáÁöÑËá™ÁÑ∂Ë™ûË®ÄÈï∑ÊúüÂïèÈ°åÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïËÉΩÂ§†Âú®ÂæûÂêÑÁ®ÆË≥áÊñôÈõÜÊî∂ÈõÜÁöÑÂΩ±Áâá‰∏≠Áî¢ÁîüÈÄ£Ë≤´„ÄÅË±êÂØå‰∏îÁõ∏ÈóúÁöÑÊñáÂ≠óÊèèËø∞ÔºåÂêåÊôÇ‰ΩøÁî®Ê®ôÊ∫ñÊåáÊ®ôÔºà‰æãÂ¶Ç Bleu„ÄÅROUGEÔºâÂíåÁèæ‰ª£ LLM ‰ΩúÁÇ∫Ë©ïÂØ©ÊñπÊ≥ï„ÄÇ

##### **Large Language Models For Text Classification: Case Study And Comprehensive Review**
2501.08457v1 by Arina Kostina, Marios D. Dikaiakos, Dimosthenis Stefanidis, George Pallis

Unlocking the potential of Large Language Models (LLMs) in data
classification represents a promising frontier in natural language processing.
In this work, we evaluate the performance of different LLMs in comparison with
state-of-the-art deep-learning and machine-learning models, in two different
classification scenarios: i) the classification of employees' working locations
based on job reviews posted online (multiclass classification), and 2) the
classification of news articles as fake or not (binary classification). Our
analysis encompasses a diverse range of language models differentiating in
size, quantization, and architecture. We explore the impact of alternative
prompting techniques and evaluate the models based on the weighted F1-score.
Also, we examine the trade-off between performance (F1-score) and time
(inference response time) for each language model to provide a more nuanced
understanding of each model's practical applicability. Our work reveals
significant variations in model responses based on the prompting strategies. We
find that LLMs, particularly Llama3 and GPT-4, can outperform traditional
methods in complex classification tasks, such as multiclass classification,
though at the cost of longer inference times. In contrast, simpler ML models
offer better performance-to-time trade-offs in simpler binary classification
tasks.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë≥áÊñôÂàÜÈ°û‰∏≠ÁöÑÊΩõÂäõÔºå‰ª£Ë°®‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñ∞È†òÂüü„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏çÂêå LLM ÁöÑÊïàËÉΩÔºå‰∏¶ËàáÊúÄÂÖàÈÄ≤ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂíåÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂú®ÂÖ©Á®Æ‰∏çÂêåÁöÑÂàÜÈ°ûÊÉÖÂ¢É‰∏≠Ôºö‰∏ÄÔºâÊ†πÊìöÂú®Á∂≤Ë∑Ø‰∏äÁôºÂ∏ÉÁöÑÂ∑•‰ΩúË©ïË´ñÔºåÂ∞çÂì°Â∑•ÁöÑÂ∑•‰ΩúÂú∞ÈªûÈÄ≤Ë°åÂàÜÈ°ûÔºàÂ§öÈ°ûÂàÜÈ°ûÔºâÔºå‰ª•Âèä‰∫åÔºâÂ∞áÊñ∞ËÅûÊñáÁ´†ÂàÜÈ°ûÁÇ∫ÁúüÊàñÂÅáÔºà‰∫åÂÖÉÂàÜÈ°ûÔºâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊ∂µËìã‰∫ÜÂêÑÁ®ÆË™ûË®ÄÊ®°ÂûãÔºåÂÆÉÂÄëÂú®Â§ßÂ∞è„ÄÅÈáèÂåñÂíåÊû∂Êßã‰∏äÊúâÊâÄ‰∏çÂêå„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÊõø‰ª£ÊèêÁ§∫ÊäÄË°ìÁöÑÂΩ±ÈüøÔºå‰∏¶Ê†πÊìöÂä†Ê¨ä F1 ÂàÜÊï∏Ë©ï‰º∞Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáùÂ∞çÊØèÂÄãË™ûË®ÄÊ®°ÂûãÊé¢Ë®éÊïàËÉΩÔºàF1 ÂàÜÊï∏ÔºâÂíåÊôÇÈñìÔºàÊé®Ë´ñÂõûÊáâÊôÇÈñìÔºâ‰πãÈñìÁöÑÊ¨äË°°Ôºå‰ª•Êèê‰æõÂ∞çÊØèÂÄãÊ®°ÂûãÂØ¶Áî®ÊÄßÁöÑÊõ¥Á¥∞Á∑ªÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫ÜÂü∫ÊñºÊèêÁ§∫Á≠ñÁï•ÁöÑÊ®°ÂûãÂõûÊáâÁöÑÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåLLMÔºåÁâπÂà•ÊòØ Llama3 Âíå GPT-4ÔºåÂèØ‰ª•Âú®Ë§áÈõúÁöÑÂàÜÈ°û‰ªªÂãô‰∏≠ÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºå‰æãÂ¶ÇÂ§öÈ°ûÂàÜÈ°ûÔºåÂÑòÁÆ°‰ª£ÂÉπÊòØÊé®Ë´ñÊôÇÈñìËºÉÈï∑„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåËºÉÁ∞°ÂñÆÁöÑ ML Ê®°ÂûãÂú®ËºÉÁ∞°ÂñÆÁöÑ‰∫åÂÖÉÂàÜÈ°û‰ªªÂãô‰∏≠Êèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÊïàËÉΩÊôÇÈñìÊ¨äË°°„ÄÇ

##### **Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack**
2501.08454v1 by Sagiv Antebi, Edan Habler, Asaf Shabtai, Yuval Elovici

Large language models (LLMs) have become essential digital task assistance
tools. Their training relies heavily on the collection of vast amounts of data,
which may include copyright-protected or sensitive information. Recent studies
on the detection of pretraining data in LLMs have primarily focused on
sentence-level or paragraph-level membership inference attacks (MIAs), usually
involving probability analysis of the target model prediction tokens. However,
the proposed methods often demonstrate poor performance, specifically in terms
of accuracy, failing to account for the semantic importance of textual content
and word significance. To address these shortcomings, we propose Tag&Tab, a
novel approach for detecting data that has been used as part of the LLM
pretraining. Our method leverages advanced natural language processing (NLP)
techniques to tag keywords in the input text - a process we term Tagging. Then,
the LLM is used to obtain the probabilities of these keywords and calculate
their average log-likelihood to determine input text membership, a process we
refer to as Tabbing. Our experiments on three benchmark datasets (BookMIA,
MIMIR, and the Pile) and several open-source LLMs of varying sizes demonstrate
an average increase in the AUC scores ranging from 4.1% to 12.1% over
state-of-the-art methods. Tag&Tab not only sets a new standard for data leakage
detection in LLMs, but its outstanding performance is a testament to the
importance of words in MIAs on LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫ÈáçË¶ÅÁöÑÊï∏‰ΩçÂ∑•‰ΩúËºîÂä©Â∑•ÂÖ∑„ÄÇÂÖ∂Ë®ìÁ∑¥‰ª∞Ë≥¥Â§ßÈáèË≥áÊñôÁöÑËíêÈõÜÔºåÂÖ∂‰∏≠ÂèØËÉΩÂåÖÂê´ÂèóËëó‰ΩúÊ¨ä‰øùË≠∑ÊàñÊïèÊÑüÁöÑË≥áË®ä„ÄÇËøëÊúüÈóúÊñº LLM ‰∏≠È†êË®ìÁ∑¥Ë≥áÊñôÂÅµÊ∏¨ÁöÑÁ†îÁ©∂Ôºå‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âè•Â≠êÂ±§Á¥öÊàñÊÆµËêΩÂ±§Á¥öÁöÑÊàêÂì°Ë∫´ÂàÜÊé®Ë´ñÊîªÊìä (MIA)ÔºåÈÄöÂ∏∏Ê∂âÂèäÁõÆÊ®ôÊ®°ÂûãÈ†êÊ∏¨Ê¨äÊùñÁöÑÊ©üÁéáÂàÜÊûê„ÄÇÁÑ∂ËÄåÔºåÊèêÂá∫ÁöÑÊñπÊ≥ïÁ∂ìÂ∏∏Â±ïÁèæ‰∏ç‰Ω≥ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÔºåÁÑ°Ê≥ïËÄÉÈáèÊñáÂ≠óÂÖßÂÆπÁöÑË™ûÊÑèÈáçË¶ÅÊÄßËàáÂ≠óË©ûÊÑèÁæ©„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÊàëÂÄëÊèêÂá∫ Tag&TabÔºå‰∏ÄÁ®ÆÁî®ÊñºÂÅµÊ∏¨Ë≥áÊñôÊòØÂê¶ÊõæÁî®Êñº LLM È†êË®ìÁ∑¥ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®ÈÄ≤ÈöéËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÔºåÊ®ôË®òËº∏ÂÖ•ÊñáÂ≠ó‰∏≠ÁöÑÈóúÈçµÂ≠óÔºåÈÄôÂÄãÁ®ãÂ∫èÁ®±‰πãÁÇ∫Ê®ôË®ò„ÄÇÊé•ËëóÔºå‰ΩøÁî® LLM ÂèñÂæóÈÄô‰∫õÈóúÈçµÂ≠óÁöÑÊ©üÁéáÔºå‰∏¶Ë®àÁÆóÂÖ∂Âπ≥ÂùáÂ∞çÊï∏‰ººÁÑ∂ÂÄºÔºå‰ª•Âà§ÂÆöËº∏ÂÖ•ÊñáÂ≠óÁöÑÊàêÂì°Ë∫´ÂàÜÔºåÈÄôÂÄãÁ®ãÂ∫èÊàëÂÄëÁ®±‰πãÁÇ∫Ê®ôÁ±§Âåñ„ÄÇÊàëÂÄëÈáùÂ∞ç‰∏âÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ (BookMIA„ÄÅMIMIR Âíå Pile) ÈÄ≤Ë°åÂØ¶È©óÔºå‰ª•ÂèäÊï∏ÂÄã‰∏çÂêåÂ§ßÂ∞èÁöÑÈñãÊ∫ê LLMÔºåÁµêÊûúÈ°ØÁ§∫ËàáÁèæÊúâÊäÄË°ìÁõ∏ÊØîÔºåAUC ÂàÜÊï∏Âπ≥ÂùáÊèêÂçá 4.1% Ëá≥ 12.1%„ÄÇTag&Tab ‰∏çÂÉÖÁÇ∫ LLM ‰∏≠ÁöÑË≥áÊñôÂ§ñÊ¥©ÂÅµÊ∏¨Ê®πÁ´ãÊñ∞Ê®ôÊ∫ñÔºåÂÖ∂ÂÇëÂá∫ÁöÑÊïàËÉΩ‰πüË≠âÊòé‰∫ÜÂ≠óË©ûÂú®ÈáùÂ∞ç LLM ÈÄ≤Ë°å MIA ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Active Sampling for Node Attribute Completion on Graphs**
2501.08450v1 by Benyuan Liu, Xu Chen, Yanfeng Wang, Ya Zhang, Zhi Cao, Ivor Tsang

Node attribute, a type of crucial information for graph analysis, may be
partially or completely missing for certain nodes in real world applications.
Restoring the missing attributes is expected to benefit downstream graph
learning. Few attempts have been made on node attribute completion, but a novel
framework called Structure-attribute Transformer (SAT) was recently proposed by
using a decoupled scheme to leverage structures and attributes. SAT ignores the
differences in contributing to the learning schedule and finding a practical
way to model the different importance of nodes with observed attributes is
challenging. This paper proposes a novel AcTive Sampling algorithm (ATS) to
restore missing node attributes. The representativeness and uncertainty of each
node's information are first measured based on graph structure, representation
similarity and learning bias. To select nodes as train samples in the next
optimization step, a weighting scheme controlled by Beta distribution is then
introduced to linearly combine the two properties. Extensive experiments on
four public benchmark datasets and two downstream tasks have shown the
superiority of ATS in node attribute completion.

ÊëòË¶ÅÔºöÁØÄÈªûÂ±¨ÊÄßÊòØÂúñÂΩ¢ÂàÜÊûê‰∏≠ÁöÑ‰∏ÄÁ®ÆÈóúÈçµË≥áË®äÈ°ûÂûãÔºåÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®‰∏≠ÔºåÊüê‰∫õÁØÄÈªûÁöÑÈÉ®ÂàÜÊàñÂÖ®ÈÉ®Â±¨ÊÄßÂèØËÉΩÈÅ∫Â§±„ÄÇ‰øÆÂæ©ÈÅ∫Â§±ÁöÑÂ±¨ÊÄßÈ†êÊúüÂ∞áÊúâÂà©Êñº‰∏ãÊ∏∏ÂúñÂΩ¢Â≠∏Áøí„ÄÇÂæàÂ∞ëÊúâ‰∫∫ÂòóË©¶ÂÆåÊàêÁØÄÈªûÂ±¨ÊÄßÔºå‰ΩÜÊúÄËøëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ÁµêÊßãÂ±¨ÊÄßËΩâÊèõÂô® (SAT) ÁöÑÊñ∞Á©éÊû∂ÊßãÔºåÂÆÉ‰ΩøÁî®Ëß£ËÄ¶ÊñπÊ°à‰æÜÂà©Áî®ÁµêÊßãÂíåÂ±¨ÊÄß„ÄÇSAT ÂøΩÁï•‰∫ÜÂ∞çÂ≠∏ÁøíÊôÇÈñìË°®ÁöÑË≤¢ÁçªÂ∑ÆÁï∞Ôºå‰∏¶‰∏îÂ∞ãÊâæ‰∏ÄÁ®ÆÂØ¶ÈöõÁöÑÊñπÊ≥ï‰æÜÂª∫Ê®°ÂÖ∑ÊúâËßÄÂØüÂ±¨ÊÄßÁöÑÁØÄÈªûÁöÑ‰∏çÂêåÈáçË¶ÅÊÄßÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁ©çÊ•µÂèñÊ®£ÊºîÁÆóÊ≥ï (ATS) ‰æÜ‰øÆÂæ©ÈÅ∫Â§±ÁöÑÁØÄÈªûÂ±¨ÊÄß„ÄÇÈ¶ñÂÖàÊ†πÊìöÂúñÂΩ¢ÁµêÊßã„ÄÅË°®Á§∫Áõ∏‰ººÊÄßÂíåÂ≠∏ÁøíÂÅèÂ∑Æ‰æÜË°°ÈáèÊØèÂÄãÁØÄÈªûË≥áË®äÁöÑ‰ª£Ë°®ÊÄßÂíå‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜÂú®‰∏ã‰∏ÄÂÑ™ÂåñÊ≠•È©ü‰∏≠ÈÅ∏ÊìáÁØÄÈªû‰ΩúÁÇ∫Ë®ìÁ∑¥Ê®£Êú¨ÔºåÁÑ∂ÂæåÂºïÂÖ•Áî± Beta ÂàÜÂ∏ÉÊéßÂà∂ÁöÑÂä†Ê¨äÊñπÊ°à‰æÜÁ∑öÊÄßÁµÑÂêàÈÄôÂÖ©ÂÄãÂ±¨ÊÄß„ÄÇÂú®ÂõõÂÄãÂÖ¨ÂÖ±Âü∫Ê∫ñË≥áÊñôÈõÜÂíåÂÖ©ÂÄã‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑÂ§ßÈáèÂØ¶È©óÈ°ØÁ§∫‰∫Ü ATS Âú®ÁØÄÈªûÂ±¨ÊÄßÂÆåÊàêÊñπÈù¢ÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **Jochre 3 and the Yiddish OCR corpus**
2501.08442v1 by Assaf Urieli, Amber Clooney, Michelle Sigiel, Grisha Leyfer

We describe the construction of a publicly available Yiddish OCR Corpus, and
describe and evaluate the open source OCR tool suite Jochre 3, including an
Alto editor for corpus annotation, OCR software for Alto OCR layer generation,
and a customizable OCR search engine. The current version of the Yiddish OCR
corpus contains 658 pages, 186K tokens and 840K glyphs. The Jochre 3 OCR tool
uses various fine-tuned YOLOv8 models for top-down page layout analysis, and a
custom CNN network for glyph recognition. It attains a CER of 1.5% on our test
corpus, far out-performing all other existing public models for Yiddish. We
analyzed the full 660M word Yiddish Book Center with Jochre 3 OCR, and the new
OCR is searchable through the Yiddish Book Center OCR search engine.

ÊëòË¶ÅÔºöÊàëÂÄëÊèèËø∞‰∫Ü‰∏ÄÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÊÑèÁ¨¨Á∑íË™û OCR Ë™ûÊñôÂ∫´ÁöÑÂª∫ÊßãÔºå‰∏¶ÊèèËø∞ÂíåË©ï‰º∞ÈñãÊ∫ê OCR Â∑•ÂÖ∑ÁµÑ Jochre 3ÔºåÂÖ∂‰∏≠ÂåÖÊã¨Áî®ÊñºË™ûÊñôÂ∫´Ë®ªËß£ÁöÑ Alto Á∑®ËºØÂô®„ÄÅÁî®Êñº Alto OCR Â±§ÁîüÊàêÁöÑÈ´òÈöé OCR ËªüÈ´îÔºå‰ª•Âèä‰∏ÄÂÄãÂèØËá™Ë®ÇÁöÑ OCR ÊêúÂ∞ãÂºïÊìé„ÄÇÊÑèÁ¨¨Á∑íË™û OCR Ë™ûÊñôÂ∫´ÁöÑÁèæË°åÁâàÊú¨ÂåÖÂê´ 658 È†Å„ÄÅ186K ÂÄãË©ûÂΩôÂíå 840K ÂÄãÂ≠óÂΩ¢„ÄÇJochre 3 OCR Â∑•ÂÖ∑‰ΩøÁî®ÂêÑÁ®ÆÂæÆË™øÁöÑ YOLOv8 Ê®°ÂûãÈÄ≤Ë°åÁî±‰∏äËÄå‰∏ãÁöÑÈ†ÅÈù¢ÁâàÈù¢ÂàÜÊûêÔºå‰ª•Âèä‰∏ÄÂÄãËá™Ë®ÇÁöÑ CNN Á∂≤Ë∑ØÈÄ≤Ë°åÂ≠óÂΩ¢Ëæ®Ë≠ò„ÄÇÂú®ÊàëÂÄëÁöÑÊ∏¨Ë©¶Ë™ûÊñôÂ∫´‰∏äÔºåÂÆÉÈÅîÂà∞‰∫Ü 1.5% ÁöÑÂ≠óÂÖÉÈåØË™§Áéá (CER)ÔºåÈÅ†ÈÅ†ÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñÁèæÊúâÁöÑÂÖ¨ÈñãÊÑèÁ¨¨Á∑íË™ûÊ®°Âûã„ÄÇÊàëÂÄë‰ΩøÁî® Jochre 3 OCR ÂàÜÊûê‰∫ÜÂÆåÊï¥ÁöÑ 6.6 ÂÑÑÂ≠óÊÑèÁ¨¨Á∑íË™ûÊõ∏Á±ç‰∏≠ÂøÉÔºåËÄåÊñ∞ÁöÑ OCR ÂèØÈÄèÈÅéÊÑèÁ¨¨Á∑íË™ûÊõ∏Á±ç‰∏≠ÂøÉ OCR ÊêúÂ∞ãÂºïÊìéÈÄ≤Ë°åÊêúÂ∞ã„ÄÇ

##### **Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies**
2501.08441v1 by Ajwad Abrar, Nafisa Tabassum Oeshy, Mohsinul Kabir, Sophia Ananiadou

Note: This paper includes examples of potentially offensive content related
to religious bias, presented solely for academic purposes. The widespread
adoption of language models highlights the need for critical examinations of
their inherent biases, particularly concerning religion. This study
systematically investigates religious bias in both language models and
text-to-image generation models, analyzing both open-source and closed-source
systems. We construct approximately 400 unique, naturally occurring prompts to
probe language models for religious bias across diverse tasks, including mask
filling, prompt completion, and image generation. Our experiments reveal
concerning instances of underlying stereotypes and biases associated
disproportionately with certain religions. Additionally, we explore
cross-domain biases, examining how religious bias intersects with demographic
factors such as gender, age, and nationality. This study further evaluates the
effectiveness of targeted debiasing techniques by employing corrective prompts
designed to mitigate the identified biases. Our findings demonstrate that
language models continue to exhibit significant biases in both text and image
generation tasks, emphasizing the urgent need to develop fairer language models
to achieve global acceptability.

ÊëòË¶ÅÔºöÊ≥®ÊÑèÔºöÊú¨ÊñáÂåÖÂê´ËàáÂÆóÊïôÂÅèË¶ãÁõ∏ÈóúÁöÑÊΩõÂú®ÂÜíÁäØÊÄßÂÖßÂÆπÁØÑ‰æãÔºåÂÉÖÂá∫ÊñºÂ≠∏Ë°ìÁõÆÁöÑËÄåÂëàÁèæ„ÄÇË™ûË®ÄÊ®°ÂûãÁöÑÂª£Ê≥õÊé°Áî®Âá∏È°Ø‰∫ÜÊâπÂà§ÊÄßÊ™¢Ë¶ñÂÖ∂ÂÖßÂú®ÂÅèË¶ãÁöÑÂøÖË¶ÅÊÄßÔºåÁâπÂà•ÊòØÈóúÊñºÂÆóÊïô„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë™øÊü•‰∫ÜË™ûË®ÄÊ®°ÂûãÂíåÊñáÂ≠óËΩâÂúñÂÉèÁîüÊàêÊ®°Âûã‰∏≠ÁöÑÂÆóÊïôÂÅèË¶ãÔºåÂàÜÊûê‰∫ÜÈñãÊ∫êÂíåÈñâÊ∫êÁ≥ªÁµ±„ÄÇÊàëÂÄëÊßãÂª∫‰∫ÜÂ§ßÁ¥Ñ 400 ÂÄãÁç®ÁâπÁöÑ„ÄÅËá™ÁÑ∂ÁôºÁîüÁöÑÊèêÁ§∫Ôºå‰ª•Êé¢Ë®éË™ûË®ÄÊ®°ÂûãÂú®‰∏çÂêå‰ªªÂãô‰∏≠ÁöÑÂÆóÊïôÂÅèË¶ãÔºåÂåÖÊã¨Â°´Á©∫„ÄÅÊèêÁ§∫ÂÆåÊàêÂíåÂúñÂÉèÁîüÊàê„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫ÜËàáÊüê‰∫õÂÆóÊïô‰∏çÊàêÊØî‰æãÂú∞Áõ∏ÈóúÁöÑÊΩõÂú®ÂàªÊùøÂç∞Ë±°ÂíåÂÅèË¶ã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË∑®È†òÂüüÂÅèË¶ãÔºåÊ™¢Ë¶ñÂÆóÊïôÂÅèË¶ãÂ¶Ç‰ΩïËàáÊÄßÂà•„ÄÅÂπ¥ÈΩ°ÂíåÂúãÁ±çÁ≠â‰∫∫Âè£Âõ†Á¥†Áõ∏‰∫§„ÄÇÊú¨Á†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë©ï‰º∞‰∫ÜÁõÆÊ®ôÂéªÂÅèÊäÄË°ìÁöÑÊúâÊïàÊÄßÔºåÊé°Áî®Êó®Âú®Ê∏õËºïÂ∑≤Ë≠òÂà•ÂÅèË¶ãÁöÑ‰øÆÊ≠£ÊèêÁ§∫„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåË™ûË®ÄÊ®°ÂûãÂú®ÊñáÂ≠óÂíåÂúñÂÉèÁîüÊàê‰ªªÂãô‰∏≠ÊåÅÁ∫åÂ±ïÁèæÈ°ØËëóÁöÑÂÅèË¶ãÔºåÂº∑Ë™ø‰∫ÜÈñãÁôºÊõ¥ÂÖ¨Âπ≥ÁöÑË™ûË®ÄÊ®°Âûã‰ª•ÂØ¶ÁèæÂÖ®ÁêÉÂèØÊé•ÂèóÊÄßÁöÑËø´ÂàáÈúÄË¶Å„ÄÇ

##### **Modeling Discrimination with Causal Abstraction**
2501.08429v1 by Milan Moss√©, Kara Schechtman, Frederick Eberhardt, Thomas Icard

A person is directly racially discriminated against only if her race caused
her worse treatment. This implies that race is an attribute sufficiently
separable from other attributes to isolate its causal role. But race is
embedded in a nexus of social factors that resist isolated treatment. If race
is socially constructed, in what sense can it cause worse treatment? Some
propose that the perception of race, rather than race itself, causes worse
treatment. Others suggest that since causal models require modularity, i.e. the
ability to isolate causal effects, attempts to causally model discrimination
are misguided.
  This paper addresses the problem differently. We introduce a framework for
reasoning about discrimination, in which race is a high-level abstraction of
lower-level features. In this framework, race can be modeled as itself causing
worse treatment. Modularity is ensured by allowing assumptions about social
construction to be precisely and explicitly stated, via an alignment between
race and its constituents. Such assumptions can then be subjected to normative
and empirical challenges, which lead to different views of when discrimination
occurs. By distinguishing constitutive and causal relations, the abstraction
framework pinpoints disagreements in the current literature on modeling
discrimination, while preserving a precise causal account of discrimination.

ÊëòË¶ÅÔºö‰∏ÄÂÄã‰∫∫Âè™ÊúâÂú®Â•πÁöÑÁ®ÆÊóèÂ∞éËá¥Â•πÂèóÂà∞Êõ¥Â∑ÆÁöÑÂæÖÈÅáÊôÇÔºåÊâçÊúÉÁõ¥Êé•ÂèóÂà∞Á®ÆÊóèÊ≠ßË¶ñ„ÄÇÈÄôÊÑèÂë≥ËëóÁ®ÆÊóèÊòØ‰∏ÄÂÄãËàáÂÖ∂‰ªñÂ±¨ÊÄßË∂≥Â§†ÂàÜÈõ¢ÁöÑÂ±¨ÊÄßÔºåÂèØ‰ª•Â≠§Á´ãÂÖ∂Âõ†ÊûúÈóú‰øÇ„ÄÇ‰ΩÜÁ®ÆÊóèÊ†πÊ§çÊñº‰∏ÄÂÄãÊäµÊäóÂ≠§Á´ãÂ∞çÂæÖÁöÑÁ§æÊúÉÂõ†Á¥†Á∂≤Áµ°‰∏≠„ÄÇÂ¶ÇÊûúÁ®ÆÊóèÊòØÁ§æÊúÉÂª∫ÊßãÁöÑÔºåÈÇ£È∫ºÂÆÉÂú®‰ªÄÈ∫ºÊÑèÁæ©‰∏äÊúÉÂ∞éËá¥Êõ¥Â∑ÆÁöÑÂæÖÈÅáÔºüÊúâ‰∫õ‰∫∫ÊèêÂá∫ÔºåÁ®ÆÊóèÊú¨Ë∫´ÔºåËÄå‰∏çÊòØÁ®ÆÊóèÁöÑË™çÁü•ÔºåÊúÉÂ∞éËá¥Êõ¥Â∑ÆÁöÑÂæÖÈÅá„ÄÇÂè¶‰∏Ä‰∫õ‰∫∫ÂâáË™çÁÇ∫ÔºåÁî±ÊñºÂõ†ÊûúÊ®°ÂûãÈúÄË¶ÅÊ®°ÁµÑÂåñÔºåÂç≥ÈöîÈõ¢Âõ†ÊûúÊïàÊáâÁöÑËÉΩÂäõÔºåÂõ†Ê≠§ÂòóË©¶Â∞çÊ≠ßË¶ñÈÄ≤Ë°åÂõ†ÊûúÂª∫Ê®°ÊòØÈåØË™§ÁöÑ„ÄÇ
Êú¨Êñá‰ª•‰∏çÂêåÁöÑÊñπÂºèËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊé®ÁêÜÊ≠ßË¶ñÁöÑÊ°ÜÊû∂ÔºåÂÖ∂‰∏≠Á®ÆÊóèÊòØ‰ΩéÂ±§Á¥öÁâπÂæµÁöÑÈ´òÂ±§Á¥öÊäΩË±°„ÄÇÂú®ÈÄôÂÄãÊ°ÜÊû∂‰∏≠ÔºåÁ®ÆÊóèÂèØ‰ª•Ë¢´Âª∫Ê®°ÁÇ∫Êú¨Ë∫´Â∞éËá¥Êõ¥Â∑ÆÁöÑÂæÖÈÅá„ÄÇÈÄöÈÅéÂÖÅË®±Â∞çÁ§æÊúÉÂª∫ÊßãÁöÑÂÅáË®≠ÈÄöÈÅéÁ®ÆÊóèÂèäÂÖ∂ÁµÑÊàêÈÉ®ÂàÜ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÈÄ≤Ë°åÁ≤æÁ¢∫ÂíåÊòéÁ¢∫ÁöÑÈô≥Ëø∞ÔºåÁ¢∫‰øù‰∫ÜÊ®°ÁµÑÂåñ„ÄÇÁÑ∂ÂæåÔºåÈÄô‰∫õÂÅáË®≠ÂèØ‰ª•ÂèóÂà∞Ë¶èÁØÑÊÄßÂíåÁ∂ìÈ©óÊÄßÊåëÊà∞ÔºåÈÄôÊúÉÂ∞éËá¥Â∞ç‰ΩïÊôÇÁôºÁîüÊ≠ßË¶ñÁöÑ‰∏çÂêåÁúãÊ≥ï„ÄÇÈÄöÈÅéÂçÄÂàÜÊßãÊàêÊÄßÂíåÂõ†ÊûúÈóú‰øÇÔºåÊäΩË±°Ê°ÜÊû∂ÊåáÂá∫‰∫ÜÁï∂ÂâçÊ≠ßË¶ñÂª∫Ê®°ÊñáÁçª‰∏≠ÁöÑÂàÜÊ≠ßÔºåÂêåÊôÇ‰øùÁïô‰∫ÜÂ∞çÊ≠ßË¶ñÁöÑÁ≤æÁ¢∫Âõ†ÊûúË™™Êòé„ÄÇ

##### **Causal vs. Anticausal merging of predictors**
2501.08426v1 by Sergio Hernan Garrido Mejia, Patrick Bl√∂baum, Bernhard Sch√∂lkopf, Dominik Janzing

We study the differences arising from merging predictors in the causal and
anticausal directions using the same data. In particular we study the
asymmetries that arise in a simple model where we merge the predictors using
one binary variable as target and two continuous variables as predictors. We
use Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors,
however, we expect similar differences to hold also when we use other merging
methods that take into account asymmetries between cause and effect. We show
that if we observe all bivariate distributions, the CMAXENT solution reduces to
a logistic regression in the causal direction and Linear Discriminant Analysis
(LDA) in the anticausal direction. Furthermore, we study how the decision
boundaries of these two solutions differ whenever we observe only some of the
bivariate distributions implications for Out-Of-Variable (OOV) generalisation.

ÊëòË¶ÅÔºöÊàëÂÄë‰ΩøÁî®Áõ∏ÂêåÁöÑË≥áÊñôÁ†îÁ©∂Âêà‰ΩµÈ†êÊ∏¨Âô®Âú®Âõ†ÊûúÂíåÂèçÂõ†ÊûúÊñπÂêë‰∏äÁî¢ÁîüÁöÑÂ∑ÆÁï∞„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁ†îÁ©∂Âú®‰∏ÄÂÄãÁ∞°ÂñÆÊ®°Âûã‰∏≠Áî¢ÁîüÁöÑ‰∏çÂ∞çÁ®±ÊÄßÔºåÂú®Ë©≤Ê®°Âûã‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄã‰∫åÂÖÉËÆäÊï∏‰ΩúÁÇ∫ÁõÆÊ®ôÂíåÂÖ©ÂÄãÈÄ£Á∫åËÆäÊï∏‰ΩúÁÇ∫È†êÊ∏¨Âô®‰æÜÂêà‰ΩµÈ†êÊ∏¨Âô®„ÄÇÊàëÂÄë‰ΩøÁî®Âõ†ÊûúÊúÄÂ§ßÁÜµ (CMAXENT) ‰ΩúÁÇ∫Ê≠∏Á¥çÂÅèË¶ã‰æÜÂêà‰ΩµÈ†êÊ∏¨Âô®ÔºåÁÑ∂ËÄåÔºåÊàëÂÄëÈ†êÊúüÂú®ÊàëÂÄë‰ΩøÁî®ÂÖ∂‰ªñËÄÉÊÖÆÂà∞Âõ†Êûú‰πãÈñì‰∏çÂ∞çÁ®±ÊÄßÁöÑÂêà‰ΩµÊñπÊ≥ïÊôÇÔºå‰πüÊúÉÁî¢ÁîüÈ°û‰ººÁöÑÂ∑ÆÁï∞„ÄÇÊàëÂÄëË°®ÊòéÔºåÂ¶ÇÊûúÊàëÂÄëËßÄÂØüÂà∞ÊâÄÊúâ‰∫åËÆäÊï∏ÂàÜ‰ΩàÔºåÂâá CMAXENT Ëß£Ê±∫ÊñπÊ°àÊúÉÁ∞°ÂåñÁÇ∫Âõ†ÊûúÊñπÂêë‰∏≠ÁöÑÈÇèËºØËø¥Ê≠∏ÂíåÂèçÂõ†ÊûúÊñπÂêë‰∏≠ÁöÑÁ∑öÊÄßÂà§Âà•ÂàÜÊûê (LDA)„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÁï∂ÊàëÂÄëÂÉÖËßÄÂØüÂà∞Êüê‰∫õ‰∫åËÆäÊï∏ÂàÜ‰ΩàÊôÇÔºåÈÄôÂÖ©ÂÄãËß£Ê±∫ÊñπÊ°àÁöÑÊ±∫Á≠ñÈÇäÁïåÊúâ‰Ωï‰∏çÂêåÔºåÈÄôÂ∞çËÆäÊï∏Â§ñ (OOV) Ê¶ÇÊã¨ÁöÑÂΩ±Èüø„ÄÇ

##### **SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models**
2501.08421v1 by Anurag Kumar, Rohit Paturi, Amber Afshan, Sundararajan Srinivasan

Speaker Diarization (SD) is a crucial component of modern end-to-end ASR
pipelines. Traditional SD systems, which are typically audio-based and operate
independently of ASR, often introduce speaker errors, particularly during
speaker transitions and overlapping speech. Recently, language models including
fine-tuned large language models (LLMs) have shown to be effective as a
second-pass speaker error corrector by leveraging lexical context in the
transcribed output. In this work, we introduce a novel acoustic conditioning
approach to provide more fine-grained information from the acoustic diarizer to
the LLM. We also show that a simpler constrained decoding strategy reduces LLM
hallucinations, while avoiding complicated post-processing. Our approach
significantly reduces the speaker error rates by 24-43% across Fisher,
Callhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.

ÊëòË¶ÅÔºöË™ûËÄÖÊó•Ë®òÂåñ (SD) ÊòØÁèæ‰ª£Á´ØÂ∞çÁ´Ø ASR ÁÆ°ÈÅìÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂÇ≥Áµ±ÁöÑ SD Á≥ªÁµ±ÈÄöÂ∏∏Âü∫ÊñºÈü≥Ë®äÔºå‰∏¶Áç®Á´ãÊñº ASR ÈÅã‰ΩúÔºåÂú®Ë™ûËÄÖËΩâÊèõÂíåË™ûÈü≥ÈáçÁñäÊúüÈñìÔºåÈÄöÂ∏∏ÊúÉÂºïÁôºË™ûËÄÖÈåØË™§„ÄÇÊúÄËøëÔºåÂåÖÊã¨ÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂÖßÁöÑË™ûË®ÄÊ®°ÂûãÂ∑≤Ë≠âÊòéÂèØÊúâÊïà‰ΩúÁÇ∫Á¨¨‰∫åËº™Ë™ûËÄÖÈåØË™§Ê†°Ê≠£Âô®ÔºåÊñπÊ≥ïÊòØÂà©Áî®ËΩâÈåÑËº∏Âá∫ÁöÑË©ûÂΩôËÉåÊôØ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈü≥ÈüøÊ¢ù‰ª∂ÂåñÊñπÊ≥ïÔºå‰ª•Âêë LLM Êèê‰æõ‰æÜËá™Èü≥ÈüøÊó•Ë®òÂô®ÁöÑÊõ¥Á¥∞Á∑ªË≥áË®ä„ÄÇÊàëÂÄë‰πüÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊõ¥Á∞°ÂñÆÁöÑÂèóÈôêËß£Á¢ºÁ≠ñÁï•ÂèØÊ∏õÂ∞ë LLM ÂπªË¶∫ÔºåÂêåÊôÇÈÅøÂÖçË§áÈõúÁöÑÂæåËôïÁêÜ„ÄÇËàáÁ¨¨‰∏ÄËº™Èü≥Èüø SD Áõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÈôç‰Ωé‰∫Ü Fisher„ÄÅCallhome Âíå RT03-CTS Ë≥áÊñôÈõÜ‰∏≠ÁöÑË™ûËÄÖÈåØË™§ÁéáÈÅî 24-43%„ÄÇ

##### **CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks**
2501.08418v1 by Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang

Efficient resource allocation is essential for optimizing various tasks in
wireless networks, which are usually formulated as generalized assignment
problems (GAP). GAP, as a generalized version of the linear sum assignment
problem, involves both equality and inequality constraints that add
computational challenges. In this work, we present a novel Conditional Value at
Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address
GAP in vehicular networks (VNets). Our approach leverages a hybrid
quantum-classical structure, integrating a tailored cost function that balances
both objective and constraint-specific penalties to improve solution quality
and stability. Using the CVaR-VQE model, we handle the GAP efficiently by
focusing optimization on the lower tail of the solution space, enhancing both
convergence and resilience on noisy intermediate-scale quantum (NISQ) devices.
We apply this framework to a user-association problem in VNets, where our
method achieves 23.5% improvement compared to the deep neural network (DNN)
approach.

ÊëòË¶ÅÔºöÊúâÊïàË≥áÊ∫êÈÖçÁΩÆÂ∞çÊñºÂÑ™ÂåñÁÑ°Á∑öÁ∂≤Ë∑Ø‰∏≠ÁöÑÂêÑÁ®Æ‰ªªÂãôËá≥ÈóúÈáçË¶ÅÔºåÈÄô‰∫õ‰ªªÂãôÈÄöÂ∏∏Ë¢´Âà∂ÂÆöÁÇ∫Âª£Áæ©ÂàÜÈÖçÂïèÈ°å (GAP)„ÄÇGAP ‰ΩúÁÇ∫Á∑öÊÄßÁ∏ΩÂíåÂàÜÈÖçÂïèÈ°åÁöÑÂª£Áæ©ÁâàÊú¨ÔºåÊ∂âÂèäÁ≠âÂºèÂíå‰∏çÁ≠âÂºèÁ¥ÑÊùüÔºåÂ¢ûÂä†‰∫ÜÈÅãÁÆóÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ¢ù‰ª∂ÂÉπÂÄºÈ¢®Èö™ (CVaR) ÁÇ∫Âü∫Á§éÁöÑËÆäÂàÜÈáèÂ≠êÊú¨ÂæµÊ±ÇËß£Âô® (VQE) Ê°ÜÊû∂Ôºå‰ª•Ëß£Ê±∫ËªäËºõÁ∂≤Ë∑Ø (VNet) ‰∏≠ÁöÑ GAP„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Ê∑∑ÂêàÈáèÂ≠êÁ∂ìÂÖ∏ÁµêÊßãÔºåÊï¥Âêà‰∏ÄÂÄãÈáèË∫´Ë®ÇÂÅöÁöÑÊàêÊú¨ÂáΩÊï∏ÔºåÂπ≥Ë°°ÁõÆÊ®ôÂíåÁ¥ÑÊùüÁâπÂÆöÊá≤ÁΩ∞Ôºå‰ª•ÊèêÈ´òËß£ÁöÑÂìÅË≥™ÂíåÁ©©ÂÆöÊÄß„ÄÇ‰ΩøÁî® CVaR-VQE Ê®°ÂûãÔºåÊàëÂÄëÈÄèÈÅéÂ∞áÊúÄ‰Ω≥ÂåñÈõÜ‰∏≠Âú®Ëß£Á©∫ÈñìÁöÑ‰∏ãÂ∞æÔºåÊúâÊïàÂú∞ËôïÁêÜ GAPÔºåÂ¢ûÂº∑Âú®ÊúâÈõúË®äÁöÑ‰∏≠ÈñìÈáèÁ¥öÈáèÂ≠ê (NISQ) Ë£ùÁΩÆ‰∏äÁöÑÊî∂ÊñÇÊÄßÂíåÂæ©ÂéüÂäõ„ÄÇÊàëÂÄëÂ∞áÊ≠§Ê°ÜÊû∂ÊáâÁî®Êñº VNet ‰∏≠ÁöÑ‰ΩøÁî®ËÄÖÈóúËÅØÂïèÈ°åÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïËàáÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÊñπÊ≥ïÁõ∏ÊØîÔºåÁç≤Âæó‰∫Ü 23.5% ÁöÑÊîπÈÄ≤„ÄÇ

##### **Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics**
2501.08415v1 by Georgii Gotin, Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin

Recent studies have revealed that modern image and video quality assessment
(IQA/VQA) metrics are vulnerable to adversarial attacks. An attacker can
manipulate a video through preprocessing to artificially increase its quality
score according to a certain metric, despite no actual improvement in visual
quality. Most of the attacks studied in the literature are white-box attacks,
while black-box attacks in the context of VQA have received less attention.
Moreover, some research indicates a lack of transferability of adversarial
examples generated for one model to another when applied to VQA. In this paper,
we propose a cross-modal attack method, IC2VQA, aimed at exploring the
vulnerabilities of modern VQA models. This approach is motivated by the
observation that the low-level feature spaces of images and videos are similar.
We investigate the transferability of adversarial perturbations across
different modalities; specifically, we analyze how adversarial perturbations
generated on a white-box IQA model with an additional CLIP module can
effectively target a VQA model. The addition of the CLIP module serves as a
valuable aid in increasing transferability, as the CLIP model is known for its
effective capture of low-level semantics. Extensive experiments demonstrate
that IC2VQA achieves a high success rate in attacking three black-box VQA
models. We compare our method with existing black-box attack strategies,
highlighting its superiority in terms of attack success within the same number
of iterations and levels of attack strength. We believe that the proposed
method will contribute to the deeper analysis of robust VQA metrics.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁèæ‰ª£ÂΩ±ÂÉèÂíåÂΩ±ÁâáÂìÅË≥™Ë©ï‰º∞ (IQA/VQA) ÊåáÊ®ôÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÁöÑÂΩ±Èüø„ÄÇÊîªÊìäËÄÖÂèØ‰ª•ÈÄèÈÅéÈ†êËôïÁêÜ‰æÜÊìçÁ∏±ÂΩ±ÁâáÔºå‰ª•‰∫∫ÁÇ∫ÊèêÈ´òÂÖ∂ÂìÅË≥™ÂàÜÊï∏ÔºåÁ¨¶ÂêàÁâπÂÆöÊåáÊ®ôÔºåÂÑòÁÆ°Ë¶ñË¶∫ÂìÅË≥™‰∏¶Ê≤íÊúâÂØ¶ÈöõÊîπÂñÑ„ÄÇÊñáÁçª‰∏≠Á†îÁ©∂ÁöÑÂ§ßÂ§öÊï∏ÊîªÊìäÈÉΩÊòØÁôΩÁõíÊîªÊìäÔºåËÄå VQA ‰∏≠ÁöÑÈªëÁõíÊîªÊìäÂâáËºÉÂ∞ëÂèóÂà∞ÈóúÊ≥®„ÄÇÊ≠§Â§ñÔºå‰∏Ä‰∫õÁ†îÁ©∂ÊåáÂá∫ÔºåÁï∂Â∞çÊäóÁØÑ‰æãÊáâÁî®Êñº VQA ÊôÇÔºåÈáùÂ∞ç‰∏ÄÂÄãÊ®°ÂûãÁî¢ÁîüÁöÑÂ∞çÊäóÁØÑ‰æãÁº∫‰πèÂèØËΩâÁßªÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË∑®Ê®°ÊÖãÊîªÊìäÊñπÊ≥ï IC2VQAÔºåÊó®Âú®Êé¢Á¥¢Áèæ‰ª£ VQA Ê®°ÂûãÁöÑÊºèÊ¥û„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂãïÊ©ü‰æÜËá™ÊñºËßÄÂØüÂà∞ÂΩ±ÂÉèÂíåÂΩ±ÁâáÁöÑ‰ΩéÈöéÁâπÂæµÁ©∫ÈñìÊòØÁõ∏‰ººÁöÑ„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫ÜÂ∞çÊäóÊìæÂãïÂú®‰∏çÂêåÊ®°ÊÖã‰πãÈñìÁöÑÂèØËΩâÁßªÊÄßÔºõÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂú®ÂÖ∑ÊúâÈ°çÂ§ñ CLIP Ê®°ÁµÑÁöÑÁôΩÁõí IQA Ê®°Âûã‰∏äÁî¢ÁîüÁöÑÂ∞çÊäóÊìæÂãïÂ¶Ç‰ΩïÊúâÊïàÂú∞ÈáùÂ∞ç VQA Ê®°Âûã„ÄÇCLIP Ê®°ÁµÑÁöÑÂä†ÂÖ•ÊúâÂä©ÊñºÊèêÈ´òÂèØËΩâÁßªÊÄßÔºåÂõ†ÁÇ∫ CLIP Ê®°Âûã‰ª•ÊúâÊïàÊì∑Âèñ‰ΩéÈöéË™ûÊÑèËÄåËÅûÂêç„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåIC2VQA Âú®ÊîªÊìä‰∏âÂÄãÈªëÁõí VQA Ê®°ÂûãÊôÇÂèñÂæó‰∫ÜÂæàÈ´òÁöÑÊàêÂäüÁéá„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãËàáÁèæÊúâÁöÑÈªëÁõíÊîªÊìäÁ≠ñÁï•ÈÄ≤Ë°åÊØîËºÉÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÂú®Áõ∏ÂêåËø≠‰ª£Ê¨°Êï∏ÂíåÊîªÊìäÂº∑Â∫¶Á¥öÂà•‰∏ãÁöÑÊîªÊìäÊàêÂäüÁéáÂÑ™Âã¢„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞áÊúâÂä©ÊñºÂ∞çÂº∑ÂÅ•ÁöÑ VQA ÊåáÊ®ôÈÄ≤Ë°åÊõ¥Ê∑±ÂÖ•ÁöÑÂàÜÊûê„ÄÇ</paragraph>

##### **Ensemble of Large Language Models for Curated Labeling and Rating of Free-text Data**
2501.08413v1 by Jiaxing Qiu, Dongliang Guo, Papini Natalie, Peace Noelle, Levinson Cheri, Teague R. Henry

Free-text responses are commonly collected in psychological studies,
providing rich qualitative insights that quantitative measures may not capture.
Labeling curated topics of research interest in free-text data by multiple
trained human coders is typically labor-intensive and time-consuming. Though
large language models (LLMs) excel in language processing, LLM-assisted
labeling techniques relying on closed-source LLMs cannot be directly applied to
free-text data, without explicit consent for external use.
  In this study, we propose a framework of assembling locally-deployable LLMs
to enhance the labeling of predetermined topics in free-text data under privacy
constraints. Analogous to annotation by multiple human raters, this framework
leverages the heterogeneity of diverse open-source LLMs. The ensemble approach
seeks a balance between the agreement and disagreement across LLMs, guided by a
relevancy scoring methodology that utilizes embedding distances between topic
descriptions and LLMs' reasoning. We evaluated the ensemble approach using both
publicly accessible Reddit data from eating disorder related forums, and
free-text responses from eating disorder patients, both complemented by human
annotations.
  We found that: (1) there is heterogeneity in the performance of labeling
among same-sized LLMs, with some showing low sensitivity but high precision,
while others exhibit high sensitivity but low precision. (2) Compared to
individual LLMs, the ensemble of LLMs achieved the highest accuracy and optimal
precision-sensitivity trade-off in predicting human annotations. (3) The
relevancy scores across LLMs showed greater agreement than dichotomous labels,
indicating that the relevancy scoring method effectively mitigates the
heterogeneity in LLMs' labeling.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂøÉÁêÜÁ†îÁ©∂‰∏≠ÔºåÈÄöÂ∏∏‰ºöÊî∂ÈõÜËá™Áî±ÊñáÊú¨ÂõûÂ§çÔºåÊèê‰æõÂÆöÈáèÊµãÈáèÂèØËÉΩÊó†Ê≥ïÊçïÊçâÂà∞ÁöÑ‰∏∞ÂØåÁöÑÂÆöÊÄßËßÅËß£„ÄÇÈÄöËøáÂ§ö‰ΩçËÆ≠ÁªÉÊúâÁ¥†ÁöÑ‰∫∫Á±ªÁºñÁ†ÅÂëòÂØπËá™Áî±ÊñáÊú¨Êï∞ÊçÆ‰∏≠ÊÑüÂÖ¥Ë∂£ÁöÑÁ†îÁ©∂‰∏ªÈ¢òËøõË°åÊ†áËÆ∞ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫ÂäõÂíåÊó∂Èó¥„ÄÇÂ∞ΩÁÆ°Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ËØ≠Ë®ÄÂ§ÑÁêÜÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜ‰æùËµñ‰∫éÈó≠Ê∫ê LLM ÁöÑ LLM ËæÖÂä©Ê†áËÆ∞ÊäÄÊúØ‰∏çËÉΩÁõ¥Êé•Â∫îÁî®‰∫éËá™Áî±ÊñáÊú¨Êï∞ÊçÆÔºåËÄåÊó†ÈúÄÊòéÁ°ÆÂêåÊÑèÂ§ñÈÉ®‰ΩøÁî®„ÄÇ
Âú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁªÑË£ÖÂèØÊú¨Âú∞ÈÉ®ÁΩ≤ÁöÑ LLM ÁöÑÊ°ÜÊû∂Ôºå‰ª•Â¢ûÂº∫Âú®ÈöêÁßÅÁ∫¶Êùü‰∏ãÂØπËá™Áî±ÊñáÊú¨Êï∞ÊçÆ‰∏≠È¢ÑÂÆö‰∏ªÈ¢òÁöÑÊ†áËÆ∞„ÄÇÁ±ª‰ºº‰∫éÂ§ö‰∏™‰∫∫Á±ªËØÑ‰º∞ÂëòÁöÑÊ≥®ÈáäÔºåËØ•Ê°ÜÊû∂Âà©Áî®‰∫ÜÂêÑÁßçÂºÄÊ∫ê LLM ÁöÑÂºÇË¥®ÊÄß„ÄÇÈõÜÊàêÊñπÊ≥ïÂØªÊ±ÇÂπ≥Ë°° LLM ‰πãÈó¥ÁöÑ‰∏ÄËá¥ÊÄßÂíåÂàÜÊ≠ßÔºåÁî±Áõ∏ÂÖ≥ÊÄßËØÑÂàÜÊñπÊ≥ïÊåáÂØºÔºåËØ•ÊñπÊ≥ïÂà©Áî®‰∏ªÈ¢òÊèèËø∞Âíå LLM Êé®ÁêÜ‰πãÈó¥ÁöÑÂµåÂÖ•Ë∑ùÁ¶ª„ÄÇÊàë‰ª¨‰ΩøÁî®Êù•Ëá™È•ÆÈ£üÂ§±Ë∞ÉÁõ∏ÂÖ≥ËÆ∫ÂùõÁöÑÂÖ¨ÂºÄ Reddit Êï∞ÊçÆÂíåÈ•ÆÈ£üÂ§±Ë∞ÉÊÇ£ËÄÖÁöÑËá™Áî±ÊñáÊú¨ÂõûÂ§çÂØπÈõÜÊàêÊñπÊ≥ïËøõË°å‰∫ÜËØÑ‰º∞ÔºåËøô‰∏§ËÄÖÈÉΩËæÖ‰ª•‰∫∫Á±ªÊ≥®Èáä„ÄÇ
Êàë‰ª¨ÂèëÁé∞Ôºö(1) ÂêåÁ≠âËßÑÊ®°ÁöÑ LLM Âú®Ê†áËÆ∞ÊÄßËÉΩÊñπÈù¢Â≠òÂú®ÂºÇË¥®ÊÄßÔºå‰∏Ä‰∫õ LLM ÊòæÁ§∫Âá∫‰ΩéÊïèÊÑüÊÄß‰ΩÜÈ´òÁ≤æÂ∫¶ÔºåËÄåÂè¶‰∏Ä‰∫õ LLM ÂàôÊòæÁ§∫Âá∫È´òÊïèÊÑüÊÄß‰ΩÜ‰ΩéÁ≤æÂ∫¶„ÄÇ(2) ‰∏éÂçï‰∏™ LLM Áõ∏ÊØîÔºåLLM ÁöÑÈõÜÊàêÂú®È¢ÑÊµã‰∫∫Á±ªÊ≥®ÈáäÊó∂ÂÆûÁé∞‰∫ÜÊúÄÈ´òÁöÑÂáÜÁ°ÆÊÄßÂíåÊúÄ‰Ω≥ÁöÑÁ≤æÂ∫¶ÁÅµÊïèÂ∫¶ÊùÉË°°„ÄÇ(3) LLM ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄßÂæóÂàÜÊòæÁ§∫Âá∫ÊØî‰∫åÂàÜÊ†áÁ≠æÊõ¥Â§ßÁöÑÂÖ±ËØÜÔºåË°®ÊòéÁõ∏ÂÖ≥ÊÄßËØÑÂàÜÊñπÊ≥ïÊúâÊïàÂú∞ÂáèËΩª‰∫Ü LLM Ê†áËÆ∞‰∏≠ÁöÑÂºÇË¥®ÊÄß„ÄÇ</paragraph>

##### **OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**
2501.08406v1 by Hao Chen, Gonzalo Esteban Constante-Flores, Krishna Sri Ipsit Mantri, Sai Madhukiran Kompalli, Akshdeep Singh Ahluwalia, Can Li

Optimization models have been applied to solve a wide variety of
decision-making problems. These models are usually developed by optimization
experts but are used by practitioners without optimization expertise in various
application domains. As a result, practitioners often struggle to interact with
and draw useful conclusions from optimization models independently. To fill
this gap, we introduce OptiChat, a natural language dialogue system designed to
help practitioners interpret model formulation, diagnose infeasibility, analyze
sensitivity, retrieve information, evaluate modifications, and provide
counterfactual explanations. By augmenting large language models (LLMs) with
functional calls and code generation tailored for optimization models, we
enable seamless interaction and minimize the risk of hallucinations in
OptiChat. We develop a new dataset to evaluate OptiChat's performance in
explaining optimization models. Experiments demonstrate that OptiChat
effectively bridges the gap between optimization models and practitioners,
delivering autonomous, accurate, and instant responses.

ÊëòË¶ÅÔºöÊúÄ‰Ω≥ÂåñÊ®°ÂûãÂ∑≤Ë¢´ÈÅãÁî®ÊñºËß£Ê±∫ÂêÑÂºèÂêÑÊ®£ÁöÑÊ±∫Á≠ñÂïèÈ°å„ÄÇÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÊòØÁî±ÊúÄ‰Ω≥ÂåñÂ∞àÂÆ∂ÈñãÁôºÔºå‰ΩÜÊúÉÁî±Ê≤íÊúâÊúÄ‰Ω≥ÂåñÂ∞àÊ•≠Áü•Ë≠òÁöÑÂæûÊ•≠ËÄÖÂú®ÂêÑÁ®ÆÊáâÁî®È†òÂüü‰∏≠‰ΩøÁî®„ÄÇÂõ†Ê≠§ÔºåÂæûÊ•≠ËÄÖÈÄöÂ∏∏Èõ£‰ª•ËàáÊúÄ‰Ω≥ÂåñÊ®°Âûã‰∫íÂãï‰∏¶Áç®Á´ãÂæóÂá∫ÊúâÁî®ÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü OptiChatÔºåÈÄôÊòØ‰∏ÄÂÄãËá™ÁÑ∂Ë™ûË®ÄÂ∞çË©±Á≥ªÁµ±ÔºåÊó®Âú®Âπ´Âä©ÂæûÊ•≠ËÄÖË©ÆÈáãÊ®°ÂûãÂÖ¨Âºè„ÄÅË®∫Êñ∑‰∏çÂèØË°åÊÄß„ÄÅÂàÜÊûêÊïèÊÑüÊÄß„ÄÅÊì∑ÂèñË≥áË®ä„ÄÅË©ï‰º∞‰øÆÊîπÔºå‰∏¶Êèê‰æõÂèç‰∫ãÂØ¶Ëß£Èáã„ÄÇËóâÁî±Êì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂäüËÉΩÂëºÂè´ÂíåÂ∞àÁÇ∫ÊúÄ‰Ω≥ÂåñÊ®°ÂûãÈáèË∫´ÊâìÈÄ†ÁöÑÁ®ãÂºèÁ¢ºÁî¢ÁîüÔºåÊàëÂÄëËÆì OptiChat ËÉΩÂ§†È†ÜÊö¢‰∫íÂãï‰∏¶Â∞áÁî¢ÁîüÂπªË¶∫ÁöÑÈ¢®Èö™ÈôçÂà∞ÊúÄ‰Ωé„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºå‰ª•Ë©ï‰º∞ OptiChat Âú®Ëß£ÈáãÊúÄ‰Ω≥ÂåñÊ®°ÂûãÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÂØ¶È©óË≠âÊòéÔºåOptiChat ÊúâÊïàÂú∞ÂΩåÂêà‰∫ÜÊúÄ‰Ω≥ÂåñÊ®°ÂûãÂíåÂæûÊ•≠ËÄÖ‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊèê‰æõ‰∫ÜËá™‰∏ª„ÄÅÊ∫ñÁ¢∫‰∏îÂç≥ÊôÇÁöÑÂõûÊáâ„ÄÇ

##### **Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge**
2501.08402v1 by Santiago del Rey, Adri√† Medina, Xavier Franch, Silverio Mart√≠nez-Fern√°ndez

Deep learning (DL) systems present unique challenges in software engineering,
especially concerning quality attributes like correctness and resource
efficiency. While DL models achieve exceptional performance in specific tasks,
engineering DL-based systems is still essential. The effort, cost, and
potential diminishing returns of continual improvements must be carefully
evaluated, as software engineers often face the critical decision of when to
stop refining a system relative to its quality attributes. This experience
paper explores the role of MLOps practices -- such as monitoring and experiment
tracking -- in creating transparent and reproducible experimentation
environments that enable teams to assess and justify the impact of design
decisions on quality attributes. Furthermore, we report on experiences
addressing the quality challenges by embedding domain knowledge into the design
of a DL model and its integration within a larger system. The findings offer
actionable insights into not only the benefits of domain knowledge and MLOps
but also the strategic consideration of when to limit further optimizations in
DL projects to maximize overall system quality and reliability.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Á≥ªÁµ±Âú®ËªüÈ´îÂ∑•Á®ã‰∏≠ÂëàÁèæÂá∫Áç®ÁâπÁöÑÊåëÊà∞Ôºå
ÁâπÂà•ÊòØÈóúÊñºÊ≠£Á¢∫ÊÄßÂíåË≥áÊ∫êÊïàÁéáÁ≠âÂìÅË≥™Â±¨ÊÄß„ÄÇÈõñÁÑ∂ DL Ê®°ÂûãÂú®ÁâπÂÆö‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫ÜÈùûÂá°ÁöÑÊïàËÉΩÔºå
‰ΩÜÂª∫ÊßãÂü∫Êñº DL ÁöÑÁ≥ªÁµ±‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶Å„ÄÇÂøÖÈ†à‰ªîÁ¥∞Ë©ï‰º∞ÊåÅÁ∫åÊîπÈÄ≤ÁöÑÂä™Âäõ„ÄÅÊàêÊú¨ÂíåÊΩõÂú®ÁöÑÈÅûÊ∏õÂ†±ÈÖ¨Ôºå
Âõ†ÁÇ∫ËªüÈ´îÂ∑•Á®ãÂ∏´Á∂ìÂ∏∏Èù¢Ëá®‰ΩïÊôÇÂÅúÊ≠¢Áõ∏Â∞çÊñºÂÖ∂ÂìÅË≥™Â±¨ÊÄß‰æÜÊîπÂñÑÁ≥ªÁµ±ÁöÑÈóúÈçµÊ±∫Á≠ñ„ÄÇÈÄô‰ªΩÁ∂ìÈ©óË´ñÊñáÊé¢Ë®é‰∫Ü MLOps ÂØ¶ÂãôÂú®Âª∫Á´ãÈÄèÊòé‰∏îÂèØÈáçÁèæÁöÑÂØ¶È©óÁí∞Â¢É‰∏≠ÁöÑËßíËâ≤Ôºå
ÈÄô‰∫õÁí∞Â¢É‰ΩøÂúòÈöäËÉΩÂ§†Ë©ï‰º∞ÂíåË≠âÊòéË®≠Ë®àÊ±∫Á≠ñÂ∞çÂìÅË≥™Â±¨ÊÄßÁöÑÂΩ±ÈüøÔºå‰æãÂ¶ÇÁõ£ÊéßÂíåÂØ¶È©óËøΩËπ§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ†±Âëä‰∫ÜÈÄèÈÅéÂ∞áÈ†òÂüüÁü•Ë≠òÂµåÂÖ• DL Ê®°ÂûãÁöÑË®≠Ë®àÂèäÂÖ∂Âú®ËºÉÂ§ßÂûãÁ≥ªÁµ±‰∏≠ÁöÑÊï¥Âêà‰æÜËß£Ê±∫ÂìÅË≥™ÊåëÊà∞ÁöÑÁ∂ìÈ©ó„ÄÇÈÄô‰∫õÁôºÁèæ‰∏çÂÉÖÊèê‰æõ‰∫ÜÈóúÊñºÈ†òÂüüÁü•Ë≠òÂíå MLOps Â•ΩËôïÁöÑÂèØË°åË¶ãËß£Ôºå
ÈÇÑÊèê‰æõ‰∫ÜÈóúÊñº‰ΩïÊôÇÈôêÂà∂ÈÄ≤‰∏ÄÊ≠•ÊúÄ‰Ω≥Âåñ‰ª•ÊúÄÂ§ßÂåñÊï¥È´îÁ≥ªÁµ±ÂìÅË≥™ÂíåÂèØÈù†ÊÄßÁöÑÁ≠ñÁï•ËÄÉÈáè„ÄÇ

##### **PokerBench: Training Large Language Models to become Professional Poker Players**
2501.08328v1 by Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli

We introduce PokerBench - a benchmark for evaluating the poker-playing
abilities of large language models (LLMs). As LLMs excel in traditional NLP
tasks, their application to complex, strategic games like poker poses a new
challenge. Poker, an incomplete information game, demands a multitude of skills
such as mathematics, reasoning, planning, strategy, and a deep understanding of
game theory and human psychology. This makes Poker the ideal next frontier for
large language models. PokerBench consists of a comprehensive compilation of
11,000 most important scenarios, split between pre-flop and post-flop play,
developed in collaboration with trained poker players. We evaluate prominent
models including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,
finding that all state-of-the-art LLMs underperform in playing optimal poker.
However, after fine-tuning, these models show marked improvements. We validate
PokerBench by having models with different scores compete with each other,
demonstrating that higher scores on PokerBench lead to higher win rates in
actual poker games. Through gameplay between our fine-tuned model and GPT-4, we
also identify limitations of simple supervised fine-tuning for learning optimal
playing strategy, suggesting the need for more advanced methodologies for
effectively training language models to excel in games. PokerBench thus
presents a unique benchmark for a quick and reliable evaluation of the
poker-playing ability of LLMs as well as a comprehensive benchmark to study the
progress of LLMs in complex game-playing scenarios. The dataset and code will
be made available at: \url{https://github.com/pokerllm/pokerbench}.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé®Âá∫ PokerBench - ‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊí≤ÂÖãÈÅäÊà≤ËÉΩÂäõÁöÑÂü∫Ê∫ñ„ÄÇÁî±Êñº LLM Âú®ÂÇ≥Áµ± NLP ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÔºåÂõ†Ê≠§Â∞áÂÖ∂ÊáâÁî®ÊñºÊí≤ÂÖãÁ≠âË§áÈõúÁöÑÁ≠ñÁï•ÈÅäÊà≤ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÊñ∞ÁöÑÊåëÊà∞„ÄÇÊí≤ÂÖãÊòØ‰∏ÄÁ®Æ‰∏çÂÆåÂÖ®Ë≥áË®äÈÅäÊà≤ÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑÊäÄËÉΩÔºå‰æãÂ¶ÇÊï∏Â≠∏„ÄÅÊé®ÁêÜ„ÄÅË¶èÂäÉ„ÄÅÁ≠ñÁï•Ôºå‰ª•ÂèäÂ∞çÂçöÂºàË´ñÂíå‰∫∫È°ûÂøÉÁêÜÂ≠∏ÁöÑÊ∑±ÂÖ•ÁêÜËß£„ÄÇÈÄô‰ΩøÂæóÊí≤ÂÖãÊàêÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÁêÜÊÉ≥‰∏ã‰∏ÄÂÄãÂâçÊ≤ø„ÄÇPokerBench ÂåÖÂê´ 11,000 ÂÄãÊúÄÈáçË¶ÅÁöÑÂ†¥ÊôØÁöÑÁ∂úÂêàÂΩôÁ∑®ÔºåÂàÜÁÇ∫ÁøªÁâåÂâçÂíåÁøªÁâåÂæåÈÅäÊà≤Ôºå‰∏¶ËàáË®ìÁ∑¥ÊúâÁ¥†ÁöÑÊí≤ÂÖãÁé©ÂÆ∂Âêà‰ΩúÈñãÁôº„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂåÖÊã¨ GPT-4„ÄÅChatGPT 3.5 ‰ª•ÂèäÂêÑÁ®Æ Llama Âíå Gemma Á≥ªÂàóÊ®°ÂûãÂú®ÂÖßÁöÑÁü•ÂêçÊ®°ÂûãÔºåÁôºÁèæÊâÄÊúâÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®Áé©ÊúÄ‰Ω≥Êí≤ÂÖãÊôÇË°®Áèæ‰∏ç‰Ω≥„ÄÇÁÑ∂ËÄåÔºåÂú®ÂæÆË™øÂæåÔºåÈÄô‰∫õÊ®°ÂûãÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄëÈÄöÈÅéËÆìÂÖ∑Êúâ‰∏çÂêåÂàÜÊï∏ÁöÑÊ®°ÂûãÁõ∏‰∫íÁ´∂Áà≠‰æÜÈ©óË≠â PokerBenchÔºåË≠âÊòé PokerBench ‰∏äËºÉÈ´òÁöÑÂàÜÊï∏ÊúÉÂ∞éËá¥ÂØ¶ÈöõÊí≤ÂÖãÈÅäÊà≤‰∏≠ËºÉÈ´òÁöÑÁç≤ÂãùÁéá„ÄÇÈÄöÈÅéÊàëÂÄëÂæÆË™øÁöÑÊ®°ÂûãÂíå GPT-4 ‰πãÈñìÁöÑÈÅäÊà≤ÔºåÊàëÂÄëÈÇÑÁôºÁèæ‰∫ÜÁ∞°ÂñÆÁöÑÁõ£Áù£ÂæÆË™øÂú®Â≠∏ÁøíÊúÄ‰Ω≥ÈÅäÊà≤Á≠ñÁï•ÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄßÔºåÈÄôË°®ÊòéÈúÄË¶ÅÊõ¥ÂÖàÈÄ≤ÁöÑÊñπÊ≥ï‰æÜÊúâÊïàÂú∞Ë®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂú®ÈÅäÊà≤‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÂõ†Ê≠§ÔºåPokerBench ÁÇ∫Âø´ÈÄüÂèØÈù†Âú∞Ë©ï‰º∞ LLM ÁöÑÊí≤ÂÖãÈÅäÊà≤ËÉΩÂäõÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁç®ÁâπÁöÑÂü∫Ê∫ñÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñ‰æÜÁ†îÁ©∂ LLM Âú®Ë§áÈõúÈÅäÊà≤Â†¥ÊôØ‰∏≠ÁöÑÈÄ≤Â±ï„ÄÇÊï∏ÊìöÈõÜÂíå‰ª£Á¢ºÂ∞áÂú®‰ª•‰∏ã‰ΩçÁΩÆÊèê‰æõÔºö\url{https://github.com/pokerllm/pokerbench}„ÄÇ</paragraph>

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóáÂàÜÊûêÊ®°ÂûãÁîüÊàê 1 (ADAM) ÊòØ‰∏ÄÂÄãÂ§ö‰ª£ÁêÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êû∂ÊßãÔºåÊó®Âú®Êï¥ÂêàÂíåÂàÜÊûêÂ§öÊ®°ÂºèÊï∏ÊìöÔºåÂåÖÊã¨ÂæÆÁîüÁâ©ÁµÑÁâπÂæµ„ÄÅËá®Â∫äÊï∏ÊìöÈõÜÂíåÂ§ñÈÉ®Áü•Ë≠òÂ∫´Ôºå‰ª•Â¢ûÈÄ≤Â∞çÈòøËå≤Êµ∑ÈªòÁóá (AD) ÁöÑÁêÜËß£ÂíåÂÅµÊ∏¨„ÄÇÈÄèÈÅéÂà©Áî®Êì∑ÂèñÂ¢ûÂº∑ÁîüÊàê (RAG) ÊäÄË°ì‰ª•ÂèäÂÖ∂Â§ö‰ª£ÁêÜÊû∂ÊßãÔºåADAM-1 Âæû‰∏çÂêåÁöÑÊï∏Êìö‰æÜÊ∫ê‰∏≠Á∂úÂêàË¶ãËß£Ôºå‰∏¶‰ΩøÁî®ÊñáÁçªÈ©ÖÂãïÁöÑË≠âÊìöÂ∞çÁôºÁèæÈÄ≤Ë°åÊÉÖÂ¢ÉÂåñ„ÄÇËàá XGBoost ÁöÑÊØîËºÉË©ï‰º∞È°ØÁ§∫È°û‰ººÁöÑÂπ≥Âùá F1 ÂàÜÊï∏Ôºå‰ΩÜ ADAM-1 ÁöÑËÆäÁï∞È°ØËëóÈôç‰ΩéÔºåÁ™ÅÈ°ØÂÖ∂Á©©ÂÅ•ÊÄßÂíå‰∏ÄËá¥ÊÄßÔºåÁâπÂà•ÊòØÂú®Â∞èÂûãÂØ¶È©óÂÆ§Êï∏ÊìöÈõÜ‰∏≠„ÄÇÈõñÁÑ∂ÁõÆÂâçÈáùÂ∞ç‰∫åÂÖÉÂàÜÈ°û‰ªªÂãôÈÄ≤Ë°åË™øÊï¥Ôºå‰ΩÜÊú™‰æÜÁöÑËø≠‰ª£Êó®Âú®Á¥çÂÖ•ÂÖ∂‰ªñÊï∏ÊìöÊ®°ÂºèÔºå‰æãÂ¶ÇÁ•ûÁ∂ìÂΩ±ÂÉèÂíåÁîüÁâ©Ê®ôË®òÔºå‰ª•Êì¥Â§ßÈòøËå≤Êµ∑ÈªòÁóáÁ†îÁ©∂ÂíåË®∫Êñ∑ÁöÑÂèØÊì¥ÂÖÖÊÄßÂíåÈÅ©Áî®ÊÄß„ÄÇ

##### **Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**
2501.08322v1 by Amirhossein Aliakbarzadeh, Lucie Flek, Akbar Karimi

Large Language Models (LLMs) are trained on Web data that might contain
spelling errors made by humans. But do they become robust to similar real-world
noise? In this paper, we investigate the effect of real-world spelling mistakes
on the performance of 9 language models, with parameters ranging from 0.2B to
13B, in 3 different NLP tasks, namely Natural Language Inference (NLI), Name
Entity Recognition (NER), and Intent Classification (IC). We perform our
experiments on 6 different languages and build a dictionary of real-world noise
for them using the Wikipedia edit history. We show that the performance gap of
the studied models on the clean and noisy test data averaged across all the
datasets and languages ranges from 2.3 to 4.3 absolute percentage points. In
addition, mT5 models, in general, show more robustness compared to BLOOM,
Falcon, and BERT-like models. In particular, mT5 (13B), was the most robust on
average overall, across the 3 tasks, and in 4 of the 6 languages.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÊ†πÊìöÁ∂≤Ë∑ØË≥áÊñôË®ìÁ∑¥ËÄåÊàêÁöÑÔºåÈÄô‰∫õË≥áÊñôÂèØËÉΩÂåÖÂê´‰∫∫È°ûÊãºÂØ´ÈåØË™§„ÄÇ‰ΩÜÂÆÉÂÄëÊòØÂê¶ËÉΩÂ∞çÈ°û‰ººÁöÑÁúüÂØ¶‰∏ñÁïåÈõúË®äÁî¢ÁîüÁ©©ÂÅ•ÊÄßÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÁúüÂØ¶‰∏ñÁïåÊãºÂØ´ÈåØË™§Â∞ç 9 ÂÄãË™ûË®ÄÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÈÄô‰∫õÊ®°ÂûãÁöÑÂèÉÊï∏ÁØÑÂúçÂæû 0.2B Âà∞ 13BÔºåÊ∂µËìã 3 ÂÄã‰∏çÂêåÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÔºåÂç≥Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI)„ÄÅÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÂíåÊÑèÂúñÂàÜÈ°û (IC)„ÄÇÊàëÂÄëÂú® 6 Á®Æ‰∏çÂêåÁöÑË™ûË®Ä‰∏äÂü∑Ë°åÂØ¶È©óÔºå‰∏¶‰ΩøÁî®Á∂≠Âü∫ÁôæÁßëÁ∑®ËºØË®òÈåÑÁÇ∫ÈÄô‰∫õË™ûË®ÄÂª∫Á´ãÁúüÂØ¶‰∏ñÁïåÈõúË®äÂ≠óÂÖ∏„ÄÇÊàëÂÄëÈ°ØÁ§∫Âá∫ÈÄô‰∫õÁ†îÁ©∂Ê®°ÂûãÂú®‰πæÊ∑®ÂíåÈõúË®äÊ∏¨Ë©¶Ë≥áÊñô‰∏äÁöÑÊïàËÉΩÂ∑ÆË∑ùÔºåÂπ≥ÂùáÂú®ÊâÄÊúâË≥áÊñôÈõÜÂíåË™ûË®ÄÁöÑÁØÑÂúçÂæû 2.3 Âà∞ 4.3 ÂÄãÁµïÂ∞çÁôæÂàÜÊØîÈªû„ÄÇÊ≠§Â§ñÔºåËàá BLOOM„ÄÅFalcon Âíå BERT È°û‰ººÊ®°ÂûãÁõ∏ÊØîÔºåmT5 Ê®°ÂûãÈÄöÂ∏∏Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁâπÂà•ÊòØÔºåmT5 (13B) Âú® 3 ÂÄã‰ªªÂãôÂíå 6 Á®ÆË™ûË®Ä‰∏≠ÁöÑ 4 Á®ÆË™ûË®Ä‰∏≠ÔºåÊï¥È´î‰∏äÊúÄÁ©©ÂÅ•„ÄÇ

##### **Enhancing Automated Interpretability with Output-Centric Feature Descriptions**
2501.08319v1 by Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva

Automated interpretability pipelines generate natural language descriptions
for the concepts represented by features in large language models (LLMs), such
as plants or the first word in a sentence. These descriptions are derived using
inputs that activate the feature, which may be a dimension or a direction in
the model's representation space. However, identifying activating inputs is
costly, and the mechanistic role of a feature in model behavior is determined
both by how inputs cause a feature to activate and by how feature activation
affects outputs. Using steering evaluations, we reveal that current pipelines
provide descriptions that fail to capture the causal effect of the feature on
outputs. To fix this, we propose efficient, output-centric methods for
automatically generating feature descriptions. These methods use the tokens
weighted higher after feature stimulation or the highest weight tokens after
applying the vocabulary "unembedding" head directly to the feature. Our
output-centric descriptions better capture the causal effect of a feature on
model outputs than input-centric descriptions, but combining the two leads to
the best performance on both input and output evaluations. Lastly, we show that
output-centric descriptions can be used to find inputs that activate features
previously thought to be "dead".

ÊëòË¶ÅÔºöËá™ÂãïÂèØËß£ÈáãÊÄßÁÆ°ÈÅìÊúÉÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁâπÂæµÊâÄ‰ª£Ë°®ÁöÑÊ¶ÇÂøµÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄË™™ÊòéÔºå‰æãÂ¶ÇÊ§çÁâ©ÊàñÂè•Â≠ê‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄãÂ≠ó„ÄÇÈÄô‰∫õË™™ÊòéÊòØ‰ΩøÁî®ÊúÉÂïüÂãïÁâπÂæµÁöÑËº∏ÂÖ•ÊâÄË°çÁîüÔºåËÄåÈÄô‰∫õËº∏ÂÖ•ÂèØËÉΩÊòØÊ®°ÂûãË°®Á§∫Á©∫Èñì‰∏≠ÁöÑÁ∂≠Â∫¶ÊàñÊñπÂêë„ÄÇÁÑ∂ËÄåÔºåÊâæÂá∫ÂïüÂãïËº∏ÂÖ•ÁöÑÊàêÊú¨ÂæàÈ´òÔºå‰∏îÁâπÂæµÂú®Ê®°ÂûãË°åÁÇ∫‰∏≠ÊâÄÊâÆÊºîÁöÑÊ©üÊ¢∞ËßíËâ≤ÊòØÁî±Ëº∏ÂÖ•Â¶Ç‰ΩïÂ∞éËá¥ÁâπÂæµÂïüÂãïÔºå‰ª•ÂèäÁâπÂæµÂïüÂãïÂ¶Ç‰ΩïÂΩ±ÈüøËº∏Âá∫ÊâÄÊ±∫ÂÆö„ÄÇ‰ΩøÁî®ÂºïÂ∞éË©ï‰º∞ÔºåÊàëÂÄëÊè≠Èú≤ÁõÆÂâçÁöÑÁÆ°ÈÅìÊâÄÊèê‰æõÁöÑË™™ÊòéÁÑ°Ê≥ïÊçïÊçâÁâπÂæµÂ∞çËº∏Âá∫ÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÁÇ∫‰∫Ü‰øÆÊ≠£ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Áî®ÊñºËá™ÂãïÁî¢ÁîüÁâπÂæµË™™ÊòéÁöÑÊúâÊïà‰∏î‰ª•Ëº∏Âá∫ÁÇ∫‰∏≠ÂøÉÁöÑÂêÑÁ®ÆÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊúÉ‰ΩøÁî®Âú®ÁâπÂæµÂà∫ÊøÄÂæåÊ¨äÈáçËºÉÈ´òÁöÑ‰ª£Á¢ºÔºåÊàñÂú®Â∞áË©ûÂΩô„ÄåËß£ÂµåÂÖ•„ÄçÊ®ôÈ†≠Áõ¥Êé•Â•óÁî®Ëá≥ÁâπÂæµÂæåÊ¨äÈáçÊúÄÈ´òÁöÑ‰ª£Á¢º„ÄÇÊàëÂÄë‰ª•Ëº∏Âá∫ÁÇ∫‰∏≠ÂøÉÁöÑË™™ÊòéÊØî‰ª•Ëº∏ÂÖ•ÁÇ∫‰∏≠ÂøÉÁöÑË™™ÊòéÊõ¥ËÉΩÊçïÊçâÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂõ†ÊûúÈóú‰øÇÔºå‰ΩÜÁµêÂêàÈÄôÂÖ©Á®ÆË™™ÊòéÂèØÂú®Ëº∏ÂÖ•ÂíåËº∏Âá∫Ë©ï‰º∞‰∏≠Áç≤ÂæóÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË≠âÊòé‰ª•Ëº∏Âá∫ÁÇ∫‰∏≠ÂøÉÁöÑË™™ÊòéÂèØÁî®ÊñºÊâæÂá∫ÊúÉÂïüÂãï‰ª•ÂâçË¢´Ë™çÁÇ∫ÊòØ„ÄåÁÑ°Êïà„ÄçÁöÑÁâπÂæµÁöÑËº∏ÂÖ•„ÄÇ

##### **Diffusion Adversarial Post-Training for One-Step Video Generation**
2501.08316v1 by Shanchuan Lin, Xin Xia, Yuxi Ren, Ceyuan Yang, Xuefeng Xiao, Lu Jiang

The diffusion models are widely used for image and video generation, but
their iterative generation process is slow and expansive. While existing
distillation approaches have demonstrated the potential for one-step generation
in the image domain, they still suffer from significant quality degradation. In
this work, we propose Adversarial Post-Training (APT) against real data
following diffusion pre-training for one-step video generation. To improve the
training stability and quality, we introduce several improvements to the model
architecture and training procedures, along with an approximated R1
regularization objective. Empirically, our experiments show that our
adversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,
24fps videos in real time using a single forward evaluation step. Additionally,
our model is capable of generating 1024px images in a single step, achieving
quality comparable to state-of-the-art methods.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂª£Ê≥õÁî®ÊñºÂΩ±ÂÉèÂíåÂΩ±ÁâáÁîüÊàêÔºå‰ΩÜÂÖ∂ÂèçË¶ÜÁîüÊàêÈÅéÁ®ãÁ∑©ÊÖ¢‰∏îËÄóË≤ªË≥áÊ∫ê„ÄÇÈõñÁÑ∂ÁèæÊúâÁöÑËí∏È§æÊñπÊ≥ïÂ∑≤Â±ïÁ§∫Âá∫Âú®ÂΩ±ÂÉèÈ†òÂüüÈÄ≤Ë°åÂñÆÊ≠•ÁîüÊàêÁöÑÂèØËÉΩÊÄßÔºå‰ΩÜÂÆÉÂÄë‰ªçÊúÉÈÄ†ÊàêÂìÅË≥™Â§ßÂπÖ‰∏ãÈôç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈáùÂ∞çÁúüÂØ¶Ë≥áÊñôÊèêÂá∫Â∞çÊäóÂºèÂæåË®ìÁ∑¥ (APT)Ôºå‰∏¶Âú®Êì¥Êï£È†êË®ìÁ∑¥ÂæåÈÄ≤Ë°åÂñÆÊ≠•ÂΩ±ÁâáÁîüÊàê„ÄÇÁÇ∫‰∫ÜÊîπÂñÑË®ìÁ∑¥Á©©ÂÆöÊÄßÂíåÂìÅË≥™ÔºåÊàëÂÄëÂ∞çÊ®°ÂûãÊû∂ÊßãÂíåË®ìÁ∑¥Á®ãÂ∫èÈÄ≤Ë°åÂ§öÈ†ÖÊîπËâØÔºå‰∏¶Êé°Áî®Ëøë‰ºº R1 Ê≠£ÂâáÂåñÁõÆÊ®ô„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂ∞çÊäóÂºèÂæåË®ìÁ∑¥Ê®°Âûã Seaweed-APT ËÉΩÂ§†‰ΩøÁî®ÂñÆ‰∏ÄÂâçÂêëË©ï‰º∞Ê≠•È©üÔºåÂç≥ÊôÇÁîüÊàê 2 Áßí„ÄÅ1280x720„ÄÅ24fps ÁöÑÂΩ±Áâá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÂ§†Âú®ÂñÆ‰∏ÄÊ≠•È©ü‰∏≠ÁîüÊàê 1024px ÁöÑÂΩ±ÂÉèÔºå‰∏¶ÈÅîÂà∞ËàáÁèæÊúâÊñπÊ≥ïÁõ∏Áï∂ÁöÑÂìÅË≥™„ÄÇ

##### **MiniMax-01: Scaling Foundation Models with Lightning Attention**
2501.08313v1 by MiniMax, Aonian Li, Bangwei Gong, Bo Yang, Boji Shan, Chang Liu, Cheng Zhu, Chunhao Zhang, Congchao Guo, Da Chen, Dong Li, Enwei Jiao, Gengxin Li, Guojun Zhang, Haohai Sun, Houze Dong, Jiadai Zhu, Jiaqi Zhuang, Jiayuan Song, Jin Zhu, Jingtao Han, Jingyang Li, Junbin Xie, Junhao Xu, Junjie Yan, Kaishun Zhang, Kecheng Xiao, Kexi Kang, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Zheng, Linbo Chai, Long Xing, Meizhi Ju, Mingyuan Chi, Mozhi Zhang, Peikai Huang, Pengcheng Niu, Pengfei Li, Pengyu Zhao, Qi Yang, Qidi Xu, Qiexiang Wang, Qin Wang, Qiuhui Li, Ruitao Leng, Shengmin Shi, Shuqi Yu, Sichen Li, Songquan Zhu, Tao Huang, Tianrun Liang, Weigao Sun, Weixuan Sun, Weiyu Cheng, Wenkai Li, Xiangjun Song, Xiao Su, Xiaodong Han, Xinjie Zhang, Xinzhu Hou, Xu Min, Xun Zou, Xuyang Shen, Yan Gong, Yingjie Zhu, Yipeng Zhou, Yiran Zhong, Yongyi Hu, Yuanxiang Fan, Yue Yu, Yufeng Yang, Yuhao Li, Yunan Huang, Yunji Li, Yunpeng Huang, Yunzhi Xu, Yuxin Mao, Zehan Li, Zekang Li, Zewei Tao, Zewen Ying, Zhaoyang Cong, Zhen Qin, Zhenhua Fan, Zhihang Yu, Zhuo Jiang, Zijia Wu

We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,
which are comparable to top-tier models while offering superior capabilities in
processing longer contexts. The core lies in lightning attention and its
efficient scaling. To maximize computational capacity, we integrate it with
Mixture of Experts (MoE), creating a model with 32 experts and 456 billion
total parameters, of which 45.9 billion are activated for each token. We
develop an optimized parallel strategy and highly efficient
computation-communication overlap techniques for MoE and lightning attention.
This approach enables us to conduct efficient training and inference on models
with hundreds of billions of parameters across contexts spanning millions of
tokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens
during training and extrapolate to 4 million tokens during inference at an
affordable cost. Our vision-language model, MiniMax-VL-01 is built through
continued training with 512 billion vision-language tokens. Experiments on both
standard and in-house benchmarks show that our models match the performance of
state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32
times longer context window. We publicly release MiniMax-01 at
https://github.com/MiniMax-AI.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé®Âá∫ MiniMax-01 Á≥ªÂàóÔºåÂåÖÊã¨ MiniMax-Text-01 Âíå MiniMax-VL-01Ôºå
ÂÆÉÂÄëËàáÈ†ÇÁ¥öÊ®°ÂûãÁõ∏Áï∂ÔºåÂêåÊôÇÂú®ËôïÁêÜËºÉÈï∑Ë™ûÂ¢ÉÊñπÈù¢Êèê‰æõÂçìË∂äÁöÑÂäüËÉΩ„ÄÇÊ†∏ÂøÉÂú®ÊñºÈñÉÈõªÊ≥®ÊÑèÂäõÂèäÂÖ∂È´òÊïàÁ∏ÆÊîæ„ÄÇÁÇ∫‰∫ÜÊúÄÂ§ßÂåñË®àÁÆóËÉΩÂäõÔºåÊàëÂÄëÂ∞áÂÖ∂ËàáÂ∞àÂÆ∂Ê∑∑Âêà (MoE) Êï¥ÂêàÔºåÂª∫Á´ã‰∏ÄÂÄãÊìÅÊúâ 32 ÂÄãÂ∞àÂÆ∂Âíå 4560 ÂÑÑÂÄãÁ∏ΩÂèÉÊï∏ÁöÑÊ®°ÂûãÔºåÂÖ∂‰∏≠ 459 ÂÑÑÂÄãÂèÉÊï∏Ë¢´ÂïüÁî®ÊñºÊØèÂÄã‰ª£Âπ£„ÄÇÊàëÂÄëÁÇ∫ MoE ÂíåÈñÉÈõªÊ≥®ÊÑèÂäõÈñãÁôº‰∫Ü‰∏ÄÂÄãÂÑ™ÂåñÁöÑ‰∏¶Ë°åÁ≠ñÁï•ÂíåÈ´òÊïàÁöÑË®àÁÆóÈÄöË®äÈáçÁñäÊäÄË°ì„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Â∞çÊìÅÊúâÊï∏ÁôæÂÑÑÂÄãÂèÉÊï∏ÁöÑÊ®°ÂûãÈÄ≤Ë°åÈ´òÊïàÁöÑË®ìÁ∑¥ÂíåÊé®ÁêÜÔºåËÄåÈÄô‰∫õÂèÉÊï∏Ë∑®Ë∂äÊï∏ÁôæËê¨ÂÄã‰ª£Âπ£ÁöÑË™ûÂ¢É„ÄÇMiniMax-Text-01 ÁöÑË™ûÂ¢ÉÁ™óÂè£Âú®Ë®ìÁ∑¥ÊúüÈñìÂèØ‰ª•ÈÅîÂà∞ 100 Ëê¨ÂÄã‰ª£Âπ£Ôºå‰∏¶Âú®Êé®ÁêÜÊúüÈñì‰ª•ÂêàÁêÜÊàêÊú¨Êé®Êñ∑Âà∞ 400 Ëê¨ÂÄã‰ª£Âπ£„ÄÇÊàëÂÄëÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã MiniMax-VL-01 ÊòØÈÄèÈÅéÊåÅÁ∫åË®ìÁ∑¥ 5120 ÂÑÑÂÄãË¶ñË¶∫Ë™ûË®Ä‰ª£Âπ£Âª∫Á´ãÁöÑ„ÄÇÂú®Ê®ôÊ∫ñÂü∫Ê∫ñÂíåÂÖßÈÉ®Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãËàá GPT-4o Âíå Claude-3.5-Sonnet Á≠âÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÊÄßËÉΩÁõ∏ÂåπÈÖçÔºåÂêåÊôÇÊèê‰æõ 20-32 ÂÄçÊõ¥Èï∑ÁöÑË™ûÂ¢ÉÁ™óÂè£„ÄÇÊàëÂÄëÂú® https://github.com/MiniMax-AI ‰∏äÂÖ¨ÈñãÁôºÂ∏É MiniMax-01„ÄÇ</paragraph>

##### **Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**
2501.08312v1 by Al≈æbƒõta Kuƒçerov√°, Johann-Mattis List

Object naming - the act of identifying an object with a word or a phrase - is
a fundamental skill in interpersonal communication, relevant to many
disciplines, such as psycholinguistics, cognitive linguistics, or language and
vision research. Object naming datasets, which consist of concept lists with
picture pairings, are used to gain insights into how humans access and select
names for objects in their surroundings and to study the cognitive processes
involved in converting visual stimuli into semantic concepts. Unfortunately,
object naming datasets often lack transparency and have a highly idiosyncratic
structure. Our study tries to make current object naming data transparent and
comparable by using a multilingual, computer-assisted approach that links
individual items of object naming lists to unified concepts. Our current sample
links 17 object naming datasets that cover 30 languages from 10 different
language families. We illustrate how the comparative dataset can be explored by
searching for concepts that recur across the majority of datasets and comparing
the conceptual spaces of covered object naming datasets with classical basic
vocabulary lists from historical linguistics and linguistic typology. Our
findings can serve as a basis for enhancing cross-linguistic object naming
research and as a guideline for future studies dealing with object naming
tasks.

ÊëòË¶ÅÔºö<paragraph>Â∞çË±°ÂëΩÂêç‚Äî‚ÄîÁî®‰∏ÄÂÄãË©ûÊàñ‰∏ÄÂÄãÁü≠Ë™ûË≠òÂà•‰∏ÄÂÄãÂ∞çË±°ÁöÑË°åÁÇ∫‚Äî‚ÄîÊòØ‰∏ÄÈ†Ö‰∫∫ÈöõÊ∫ùÈÄöÁöÑÂü∫Êú¨ÊäÄËÉΩÔºåËàáË®±Â§öÈ†òÂüüÁõ∏ÈóúÔºå‰æãÂ¶ÇÂøÉÁêÜË™ûË®ÄÂ≠∏„ÄÅË™çÁü•Ë™ûË®ÄÂ≠∏ÊàñË™ûË®ÄÂíåË¶ñË¶∫Á†îÁ©∂„ÄÇÂ∞çË±°ÂëΩÂêçÊï∏ÊìöÈõÜÂåÖÂê´Â∏∂ÊúâÂúñÁâáÈÖçÂ∞çÁöÑÊ¶ÇÂøµÊ∏ÖÂñÆÔºåÁî®ÊñºÊ∑±ÂÖ•‰∫ÜËß£‰∫∫È°ûÂ¶Ç‰ΩïË®™ÂïèÂíåÈÅ∏ÊìáÂë®ÂúçÂ∞çË±°ÁöÑÂêçÁ®±Ôºå‰ª•ÂèäÁ†îÁ©∂Â∞áË¶ñË¶∫Âà∫ÊøÄËΩâÊèõÁÇ∫Ë™ûÁæ©Ê¶ÇÂøµÊâÄÊ∂âÂèäÁöÑË™çÁü•ÈÅéÁ®ã„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂ∞çË±°ÂëΩÂêçÊï∏ÊìöÈõÜÈÄöÂ∏∏Áº∫‰πèÈÄèÊòéÂ∫¶Ôºå‰∏¶‰∏îÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÁç®ÁâπÊÄßÁµêÊßã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë©¶ÂúñÈÄöÈÅé‰ΩøÁî®Â§öË™ûË®Ä„ÄÅË®àÁÆóÊ©üËºîÂä©ÁöÑÊñπÊ≥ïÂ∞áÂ∞çË±°ÂëΩÂêçÊ∏ÖÂñÆÁöÑÂñÆÂÄãÈ†ÖÁõÆÈèàÊé•Âà∞Áµ±‰∏ÄÁöÑÊ¶ÇÂøµÔºåÂæûËÄå‰ΩøÁï∂ÂâçÂ∞çË±°ÂëΩÂêçÊï∏ÊìöÈÄèÊòé‰∏îÂÖ∑ÊúâÂèØÊØîÊÄß„ÄÇÊàëÂÄëÁõÆÂâçÁöÑÊ®£Êú¨ÈèàÊé•‰∫Ü 17 ÂÄãÂ∞çË±°ÂëΩÂêçÊï∏ÊìöÈõÜÔºåÈÄô‰∫õÊï∏ÊìöÈõÜÊ∂µËìã‰∫Ü‰æÜËá™ 10 ÂÄã‰∏çÂêåË™ûË®ÄÂÆ∂ÊóèÁöÑ 30 Á®ÆË™ûË®Ä„ÄÇÊàëÂÄëË™™ÊòéÁû≠Â¶Ç‰ΩïÈÄöÈÅéÊêúÁ¥¢Ë∑®Â§ßÂ§öÊï∏Êï∏ÊìöÈõÜÈáçË§áÂá∫ÁèæÁöÑÊ¶ÇÂøµ‰ª•ÂèäÂ∞áÊ∂µËìãÁöÑÂ∞çË±°ÂëΩÂêçÊï∏ÊìöÈõÜÁöÑÊ¶ÇÂøµÁ©∫ÈñìËàáÊ≠∑Âè≤Ë™ûË®ÄÂ≠∏ÂíåË™ûË®ÄÈ°ûÂûãÂ≠∏‰∏≠ÁöÑÁ∂ìÂÖ∏Âü∫Êú¨Ë©ûÂΩôË°®ÈÄ≤Ë°åÊØîËºÉ‰æÜÊé¢Á¥¢ÊØîËºÉÊï∏ÊìöÈõÜ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂèØ‰ª•‰ΩúÁÇ∫Â¢ûÂº∑Ë∑®Ë™ûË®ÄÂ∞çË±°ÂëΩÂêçÁ†îÁ©∂ÁöÑÂü∫Á§éÔºå‰∏¶‰ΩúÁÇ∫ËôïÁêÜÂ∞çË±°ÂëΩÂêç‰ªªÂãôÁöÑÊú™‰æÜÁ†îÁ©∂ÁöÑÊåáÂ∞éÊñπÈáù„ÄÇ</paragraph>

##### **Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**
2501.08297v1 by Karine Chubarian, Johnny Joyce, Gyorgy Turan

The tree-width of a multivariate polynomial is the tree-width of the
hypergraph with hyperedges corresponding to its terms. Multivariate polynomials
of bounded tree-width have been studied by Makowsky and Meer as a new sparsity
condition that allows for polynomial solvability of problems which are
intractable in general. We consider a variation on this theme for Boolean
variables. A representation of a Boolean function as the sign of a polynomial
is called a polynomial threshold representation. We discuss Boolean functions
representable as polynomial threshold functions of bounded tree-width and
present two applications to Bayesian network classifiers, a probabilistic
graphical model. Both applications are in Explainable Artificial Intelligence
(XAI), the research area dealing with the black-box nature of many recent
machine learning models. We also give a separation result between the
representational power of positive and general polynomial threshold functions.

ÊëòË¶ÅÔºöÂ§öËÆäÈáèÂ§öÈ†ÖÂºèÁöÑÊ®πÂØ¨Â∫¶ÊòØËàáÂÖ∂È†ÖÂ∞çÊáâÁöÑË∂ÖÂúñÁöÑÊ®πÂØ¨Â∫¶„ÄÇMakowsky Âíå Meer Á†îÁ©∂‰∫ÜÊúâÁïåÊ®πÂØ¨Â∫¶ÁöÑÂ§öËÆäÈáèÂ§öÈ†ÖÂºèÔºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÊñ∞ÁöÑÁ®ÄÁñèÊÄßÊ¢ù‰ª∂ÔºåÂÖÅË®±Â∞ç‰∏ÄËà¨Èõ£‰ª•Ëß£Ê±∫ÁöÑÂïèÈ°åÈÄ≤Ë°åÂ§öÈ†ÖÂºèÊ±ÇËß£„ÄÇÊàëÂÄëËÄÉÊÖÆ‰∫ÜÂ∏ÉÊûóËÆäÊï∏ÁöÑÈÄôÂÄã‰∏ªÈ°åËÆäÈ´î„ÄÇÂ∏ÉÊûóÂáΩÊï∏ÁöÑË°®Á§∫ÂΩ¢ÂºèÁÇ∫Â§öÈ†ÖÂºèÁöÑÁ¨¶ËôüÔºåÁ®±ÁÇ∫Â§öÈ†ÖÂºèÈñæÂÄºË°®Á§∫„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂèØË°®Á§∫ÁÇ∫ÊúâÁïåÊ®πÂØ¨Â∫¶ÁöÑÂ§öÈ†ÖÂºèÈñæÂÄºÂáΩÊï∏ÁöÑÂ∏ÉÊûóÂáΩÊï∏Ôºå‰∏¶‰ªãÁ¥π‰∫ÜË≤ùÊ∞èÁ∂≤Ë∑ØÂàÜÈ°ûÂô®Ôºà‰∏ÄÁ®ÆÊ©üÁéáÂúñÂΩ¢Ê®°ÂûãÔºâÁöÑÂÖ©ÂÄãÊáâÁî®„ÄÇÈÄôÂÖ©ÂÄãÊáâÁî®ÈÉΩÂú®ÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâ‰∏≠ÔºåÈÄôÊòØ‰∏ÄÂÄãÁ†îÁ©∂Ë®±Â§öËøëÊúüÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÈªëÁÆ±ÊÄßË≥™ÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÊàëÂÄëÈÇÑÁµ¶Âá∫‰∫ÜÊ≠£Â§öÈ†ÖÂºèÈñæÂÄºÂáΩÊï∏Âíå‰∏ÄËà¨Â§öÈ†ÖÂºèÈñæÂÄºÂáΩÊï∏ÁöÑË°®Á§∫ËÉΩÂäõ‰πãÈñìÁöÑÂàÜÈõ¢ÁµêÊûú„ÄÇ

##### **HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**
2501.08292v1 by Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi

Despite their impressive ability to generate high-quality and fluent text,
generative large language models (LLMs) also produce hallucinations: statements
that are misaligned with established world knowledge or provided input context.
However, measuring hallucination can be challenging, as having humans verify
model generations on-the-fly is both expensive and time-consuming. In this
work, we release HALoGEN, a comprehensive hallucination benchmark consisting
of: (1) 10,923 prompts for generative models spanning nine domains including
programming, scientific attribution, and summarization, and (2) automatic
high-precision verifiers for each use case that decompose LLM generations into
atomic units, and verify each unit against a high-quality knowledge source. We
use this framework to evaluate ~150,000 generations from 14 language models,
finding that even the best-performing models are riddled with hallucinations
(sometimes up to 86% of generated atomic facts depending on the domain). We
further define a novel error classification for LLM hallucinations based on
whether they likely stem from incorrect recollection of training data (Type A
errors), or incorrect knowledge in training data (Type B errors), or are
fabrication (Type C errors). We hope our framework provides a foundation to
enable the principled study of why generative models hallucinate, and advances
the development of trustworthy large language models.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâÁîüÊàêÈ´òÂìÅË≥™‰∏îÊµÅÂà©ÊñáÂ≠óÁöÑÈ©ö‰∫∫ËÉΩÂäõÔºå
‰ΩÜÂÆÉÂÄë‰πüÊúÉÁî¢ÁîüÂπªË¶∫ÔºöËàáÊó¢ÂÆöÁöÑ‰∏ñÁïåÁü•Ë≠òÊàñÊèê‰æõÁöÑËº∏ÂÖ•ËÉåÊôØ‰∏çÁ¨¶ÁöÑÈô≥Ëø∞„ÄÇ
ÁÑ∂ËÄåÔºåÊ∏¨ÈáèÂπªË¶∫ÂèØËÉΩÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ËÆì‰∫∫È°ûÂç≥ÊôÇÈ©óË≠âÊ®°ÂûãÁîüÊàêÊó¢ÊòÇË≤¥ÂèàËÄóÊôÇ„ÄÇÂú®
ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü HALoGENÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂπªË¶∫Âü∫Ê∫ñÔºåÂåÖÂê´Ôºö
(1) 10,923 ÂÄãÊèêÁ§∫Ôºå‰æõÁîüÊàêÊ®°ÂûãÊ∂µËìã‰πùÂÄãÈ†òÂüüÔºåÂåÖÊã¨
Á®ãÂºèË®≠Ë®à„ÄÅÁßëÂ≠∏Ê≠∏Âõ†ÂíåÊëòË¶ÅÔºå‰ª•Âèä (2) ÈáùÂ∞çÊØèÂÄã‰ΩøÁî®Ê°à‰æãÁöÑËá™Âãï
È´òÁ≤æÂ∫¶È©óË≠âÂô®ÔºåÂ∞á LLM ÁîüÊàêÂàÜËß£ÁÇ∫ÂéüÂ≠êÂñÆ‰ΩçÔºå‰∏¶Ê†πÊìöÈ´òÂìÅË≥™Áü•Ë≠ò‰æÜÊ∫êÈ©óË≠âÊØèÂÄãÂñÆ‰Ωç„ÄÇÊàëÂÄë
‰ΩøÁî®ÈÄôÂÄãÊ°ÜÊû∂Âæû 14 ÂÄãË™ûË®ÄÊ®°ÂûãË©ï‰º∞‰∫ÜÁ¥Ñ 150,000 ÂÄãÁîüÊàêÔºå
ÁôºÁèæÂç≥‰ΩøÊòØÊïàËÉΩÊúÄÂ•ΩÁöÑÊ®°Âûã‰πüÂÖÖÊñ•ËëóÂπªË¶∫
ÔºàÊúâÊôÇÈ´òÈÅî 86% ÁöÑÁîüÊàêÂéüÂ≠ê‰∫ãÂØ¶ÔºåË¶ñÈ†òÂüüËÄåÂÆöÔºâ„ÄÇÊàëÂÄë
ÈÄ≤‰∏ÄÊ≠•ÂÆöÁæ©‰∫Ü LLM ÂπªË¶∫ÁöÑÊñ∞ÈåØË™§ÂàÜÈ°ûÔºåÂü∫ÊñºÂÆÉÂÄëÂèØËÉΩÊ∫êËá™Ë®ìÁ∑¥Ë≥áÊñôÁöÑÈåØË™§ÂõûÊÜ∂ÔºàA Âûã
ÈåØË™§Ôºâ„ÄÅË®ìÁ∑¥Ë≥áÊñô‰∏≠ÁöÑÈåØË™§Áü•Ë≠òÔºàB ÂûãÈåØË™§ÔºâÔºåÊàñÊçèÈÄ†ÔºàC ÂûãÈåØË™§Ôºâ„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÊ°ÜÊû∂Êèê‰æõ‰∏ÄÂÄãÂü∫Á§éÔºå
‰ª•ËÆìÂéüÂâáÊÄßÁöÑÁ†îÁ©∂ËÉΩÂ§†‰∫ÜËß£ÁîüÊàêÊ®°ÂûãÁî¢ÁîüÂπªË¶∫ÁöÑÂéüÂõ†Ôºå‰∏¶‰øÉÈÄ≤ÂèØ‰ø°Ë≥¥Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈñãÁôº„ÄÇ

##### **AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**
2501.08284v2 by Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, David Ifeoluwa Adelani, Ibrahim Said Ahmad, Saminu Mohammad Aliyu, Nelson Odhiambo Onyango, Lilian D. A. Wanzare, Samuel Rutunda, Lukman Jibril Aliyu, Esubalew Alemneh, Oumaima Hourrane, Hagos Tesfahun Gebremichael, Elyas Abdi Ismail, Meriem Beloucif, Ebrahim Chekol Jibril, Andiswa Bukula, Rooweither Mabuya, Salomey Osei, Abigail Oppong, Tadesse Destaw Belay, Tadesse Kebede Guge, Tesfa Tegegne Asfaw, Chiamaka Ijeoma Chukwuneke, Paul R√∂ttger, Seid Muhie Yimam, Nedjma Ousidhoum

Hate speech and abusive language are global phenomena that need
socio-cultural background knowledge to be understood, identified, and
moderated. However, in many regions of the Global South, there have been
several documented occurrences of (1) absence of moderation and (2) censorship
due to the reliance on keyword spotting out of context. Further, high-profile
individuals have frequently been at the center of the moderation process, while
large and targeted hate speech campaigns against minorities have been
overlooked. These limitations are mainly due to the lack of high-quality data
in the local languages and the failure to include local communities in the
collection, annotation, and moderation processes. To address this issue, we
present AfriHate: a multilingual collection of hate speech and abusive language
datasets in 15 African languages. Each instance in AfriHate is annotated by
native speakers familiar with the local culture. We report the challenges
related to the construction of the datasets and present various classification
baseline results with and without using LLMs. The datasets, individual
annotations, and hate speech and offensive language lexicons are available on
https://github.com/AfriHate/AfriHate

ÊëòË¶ÅÔºö‰ªáÊÅ®Ë®ÄË´ñÂíåËæ±ÁΩµÊÄßË™ûË®ÄÊòØÂÖ®ÁêÉÁèæË±°ÔºåÈúÄË¶ÅÁ§æÊúÉÊñáÂåñËÉåÊôØÁü•Ë≠òÊâçËÉΩÁêÜËß£„ÄÅË≠òÂà•ÂíåÁÆ°ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÖ®ÁêÉÂçóÊñπÁöÑË®±Â§öÂú∞ÂçÄÔºåÂ∑≤Á∂ìÊúâÂπæËµ∑Ë®òÈåÑÂú®Ê°àÁöÑÔºà1ÔºâÁº∫‰πèÁÆ°ÁêÜÂíåÔºà2ÔºâÁî±Êñº‰æùË≥¥ÊñºË™ûÂ¢É‰πãÂ§ñÁöÑÈóúÈçµÂ≠óÊ®ôË®òËÄåÂ∞éËá¥ÁöÑÂØ©Êü•Âà∂Â∫¶„ÄÇÊ≠§Â§ñÔºåÂÇôÂèóÁüöÁõÆÁöÑÂÄã‰∫∫Á∂ìÂ∏∏ÊàêÁÇ∫ÁÆ°ÁêÜÁ®ãÂ∫èÁöÑ‰∏≠ÂøÉÔºåËÄåÈáùÂ∞çÂ∞ëÊï∏Áæ§È´îÁöÑÂ§ßË¶èÊ®°‰∏îÊúâÈáùÂ∞çÊÄßÁöÑ‰ªáÊÅ®Ë®ÄË´ñÊ¥ªÂãïÂçªË¢´ÂøΩË¶ñ‰∫Ü„ÄÇÈÄô‰∫õÈôêÂà∂‰∏ªË¶ÅÊòØÁî±ÊñºÁº∫‰πèÁï∂Âú∞Ë™ûË®ÄÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÔºå‰ª•ÂèäÊú™ËÉΩËÆìÁï∂Âú∞Á§æÁæ§ÂèÉËàáÊî∂ÈõÜ„ÄÅË®ªËß£ÂíåÁÆ°ÁêÜÁ®ãÂ∫è„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü AfriHateÔºö‰∏ÄÂÄãÂ§öË™ûË®ÄÁöÑ‰ªáÊÅ®Ë®ÄË´ñÂíåËæ±ÁΩµÊÄßË™ûË®ÄË≥áÊñôÈõÜÔºåÂåÖÂê´ 15 Á®ÆÈùûÊ¥≤Ë™ûË®Ä„ÄÇAfriHate ‰∏≠ÁöÑÊØèÂÄãÂØ¶‰æãÈÉΩÁî±ÁÜüÊÇâÁï∂Âú∞ÊñáÂåñÁöÑÊØçË™û‰∫∫Â£´Ë®ªËß£„ÄÇÊàëÂÄëÂ†±Âëä‰∫ÜËàáË≥áÊñôÈõÜÂª∫ÊßãÁõ∏ÈóúÁöÑÊåëÊà∞Ôºå‰∏¶Â±ïÁ§∫‰∫Ü‰ΩøÁî®Âíå‰∏ç‰ΩøÁî® LLM ÁöÑÂêÑÁ®ÆÂàÜÈ°ûÂü∫Ê∫ñÁµêÊûú„ÄÇË≥áÊñôÈõÜ„ÄÅÂÄãÂà•Ë®ªËß£‰ª•Âèä‰ªáÊÅ®Ë®ÄË´ñÂíåÊîªÊìäÊÄßË™ûË®ÄË©ûÂΩôË°®ÂèØÂú® https://github.com/AfriHate/AfriHate ‰∏äÂèñÂæó

##### **Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**
2501.08276v1 by Pulkit Arora, Akbar Karimi, Lucie Flek

Large Language Models (LLMs) have shown impressive performance in various NLP
tasks. However, there are concerns about their reliability in different domains
of linguistic variations. Many works have proposed robustness evaluation
measures for local adversarial attacks, but we need globally robust models
unbiased to different language styles. We take a broader approach to explore a
wider range of variations across sociodemographic dimensions to perform
structured reliability tests on the reasoning capacity of language models. We
extend the SocialIQA dataset to create diverse paraphrased sets conditioned on
sociodemographic styles. The assessment aims to provide a deeper understanding
of LLMs in (a) their capability of generating demographic paraphrases with
engineered prompts and (b) their reasoning capabilities in real-world, complex
language scenarios. We also explore measures such as perplexity,
explainability, and ATOMIC performance of paraphrases for fine-grained
reliability analysis of LLMs on these sets. We find that demographic-specific
paraphrasing significantly impacts the performance of language models,
indicating that the subtleties of language variations remain a significant
challenge. The code and dataset will be made available for reproducibility and
future research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂÆÉÂÄëÂú®‰∏çÂêåË™ûË®ÄËÆäÁï∞È†òÂüüÁöÑÂèØÈù†ÊÄß‰ªçÊúâÁñëÊÖÆ„ÄÇË®±Â§öÁ†îÁ©∂Â∑≤ÈáùÂ∞çÂ±ÄÈÉ®Â∞çÊäóÊîªÊìäÊèêÂá∫Á©©ÂÅ•ÊÄßË©ï‰º∞Êé™ÊñΩÔºå‰ΩÜÊàëÂÄëÈúÄË¶ÅÂ∞ç‰∏çÂêåË™ûË®ÄÈ¢®Ê†ºÊ≤íÊúâÂÅèË¶ãÁöÑÂÖ®ÁêÉÁ©©ÂÅ•Ê®°Âûã„ÄÇÊàëÂÄëÊé°ÂèñÊõ¥Âª£Ê≥õÁöÑÊñπÊ≥ïÔºåÊé¢Á¥¢Á§æÊúÉ‰∫∫Âè£ÁâπÂæµÁ∂≠Â∫¶‰∏≠Êõ¥Âª£Ê≥õÁöÑËÆäÁï∞ÔºåÂ∞çË™ûË®ÄÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÈÄ≤Ë°åÁµêÊßãÂåñÁöÑÂèØÈù†ÊÄßÊ∏¨Ë©¶„ÄÇÊàëÂÄëÊì¥ÂÖÖ SocialIQA Ë≥áÊñôÈõÜÔºå‰ª•Âª∫Á´ã‰ª•Á§æÊúÉ‰∫∫Âè£ÁâπÂæµÈ¢®Ê†ºÁÇ∫Ê¢ù‰ª∂ÁöÑ‰∏çÂêåÂêåÁæ©Ë©ûÁµÑ„ÄÇË©ï‰º∞Êó®Âú®Êèê‰æõÂ∞ç LLM ÁöÑÊõ¥Ê∑±ÂÖ•ÁêÜËß£ÔºåÂåÖÊã¨Ôºö(a) ÂÆÉÂÄë‰ΩøÁî®Ë®≠Ë®àÊèêÁ§∫Áî¢Áîü‰∫∫Âè£ÂêåÁæ©Ë©ûÁöÑËÉΩÂäõÔºå‰ª•Âèä (b) ÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠Ë§áÈõúË™ûË®ÄÊÉÖÂ¢É‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑÊé¢Á¥¢Âõ∞ÊÉëÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÂêåÁæ©Ë©ûÁöÑ ATOMIC ÊïàËÉΩÁ≠âÊåáÊ®ôÔºå‰ª•Â∞ç LLM Âú®ÈÄô‰∫õÈõÜÂêà‰∏äÁöÑÂèØÈù†ÊÄßÈÄ≤Ë°åÁ¥∞Á∑ªÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÁôºÁèæÔºåÁâπÂÆö‰∫∫Âè£ÁöÑÂêåÁæ©Ë©ûÊîπÂØ´ÊúÉÈ°ØËëóÂΩ±ÈüøË™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩÔºåÈÄôË°®Á§∫Ë™ûË®ÄËÆäÁï∞ÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∞áÊèê‰æõÂá∫‰æÜÔºå‰ª•Âà©ÊñºÂÜçÁèæÊÄßÂíåÂæåÁ∫åÁ†îÁ©∂„ÄÇ

##### **Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**
2501.08271v1 by Saad Mashkoor Siddiqui, Mohammad Ali Sheikh, Muhammad Aleem, Kajol R Singh

In this work, we investigate the efficacy of various adapter architectures on
supervised binary classification tasks from the SuperGLUE benchmark as well as
a supervised multi-class news category classification task from Kaggle.
Specifically, we compare classification performance and time complexity of
three transformer models, namely DistilBERT, ELECTRA, and BART, using
conventional fine-tuning as well as nine state-of-the-art (SoTA) adapter
architectures. Our analysis reveals performance differences across adapter
architectures, highlighting their ability to achieve comparable or better
performance relative to fine-tuning at a fraction of the training time. Similar
results are observed on the new classification task, further supporting our
findings and demonstrating adapters as efficient and flexible alternatives to
fine-tuning. This study provides valuable insights and guidelines for selecting
and implementing adapters in diverse natural language processing (NLP)
applications.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂêÑÁ®ÆÈÅ©ÈÖçÂô®Êû∂ÊßãÂú® SuperGLUE Âü∫Ê∫ñ‰∏≠ÁöÑÁõ£Áù£Âºè‰∫åÂÖÉÂàÜÈ°û‰ªªÂãô‰ª•Âèä‰æÜËá™ Kaggle ÁöÑÁõ£Áù£ÂºèÂ§öÈ°ûÊñ∞ËÅûÂàÜÈ°û‰ªªÂãô‰∏≠ÁöÑÂäüÊïà„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊØîËºÉ‰∫Ü DistilBERT„ÄÅELECTRA Âíå BART ÈÄô‰∏âÁ®ÆTransformerÊ®°ÂûãÁöÑÂàÜÈ°ûÊïàËÉΩÂíåÊôÇÈñìË§áÈõúÂ∫¶Ôºå‰ΩøÁî®ÂÇ≥Áµ±ÂæÆË™ø‰ª•Âèä‰πùÁ®ÆÊúÄÂÖàÈÄ≤ (SoTA) ÈÅ©ÈÖçÂô®Êû∂Êßã„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫‰∫ÜÈÅ©ÈÖçÂô®Êû∂Êßã‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞ÔºåÁ™ÅÂá∫‰∫ÜÂÆÉÂÄë‰ª•‰ΩéÊñºË®ìÁ∑¥ÊôÇÈñìÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÈÅîÂà∞ËàáÂæÆË™øÁõ∏Áï∂ÊàñÊõ¥Â•ΩÁöÑÊïàËÉΩÁöÑËÉΩÂäõ„ÄÇÂú®Êñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰∏≠ËßÄÂØüÂà∞‰∫ÜÈ°û‰ººÁöÑÁµêÊûúÔºåÈÄ≤‰∏ÄÊ≠•ÊîØÊåÅÊàëÂÄëÁöÑÁôºÁèæÔºå‰∏¶Â±ïÁ§∫ÈÅ©ÈÖçÂô®‰ΩúÁÇ∫ÂæÆË™øÁöÑÊúâÊïà‰∏îÈùàÊ¥ªÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊú¨Á†îÁ©∂ÁÇ∫Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊáâÁî®‰∏≠ÈÅ∏ÊìáÂíåÂØ¶‰ΩúÈÅ©ÈÖçÂô®Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÂíåÊåáÂçó„ÄÇ

##### **AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**
2501.08266v1 by Sanjida Afrin Mou, Tasfia Noor Chowdhury, Adib Ibn Mannan, Sadia Nourin Mim, Lubana Tarannum, Tasrin Noman, Jamal Uddin Ahamed

Flooding is a major natural hazard causing significant fatalities and
economic losses annually, with increasing frequency due to climate change.
Rapid and accurate flood detection and monitoring are crucial for mitigating
these impacts. This study compares the performance of three deep learning
models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in
flood detection, utilizing images from drones, in field observations, and
social media. This study involves creating a new dataset that augments
wellknown benchmark datasets with flood-specific images, enhancing the
robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are
tested to determine their effectiveness in various environmental conditions and
geographical locations, and the strengths and limitations of each model are
also discussed here, providing insights into their applicability in different
scenarios by predicting image segmentation masks. This fully automated approach
allows these models to isolate flooded areas in images, significantly reducing
processing time compared to traditional semi-automated methods. The outcome of
this study is to predict segmented masks for each image effected by a flood
disaster and the validation accuracy of these models. This methodology
facilitates timely and continuous flood monitoring, providing vital data for
emergency response teams to reduce loss of life and economic damages. It offers
a significant reduction in the time required to generate flood maps, cutting
down the manual processing time. Additionally, we present avenues for future
research, including the integration of multimodal data sources and the
development of robust deep learning architectures tailored specifically for
flood detection tasks. Overall, our work contributes to the advancement of
flood management strategies through innovative use of deep learning
technologies.

ÊëòË¶ÅÔºö<paragraph>Ê¥™Ê∞¥ÊòØ‰∏ÄÁ®ÆÈáçÂ§ßÁöÑËá™ÁÑ∂ÁÅΩÂÆ≥ÔºåÊØèÂπ¥ÈÄ†ÊàêÂ§ßÈáè‰∫∫Âì°ÂÇ∑‰∫°ÂíåÁ∂ìÊøüÊêçÂ§±ÔºåËÄå‰∏îÁî±ÊñºÊ∞£ÂÄôËÆäÈÅ∑ÔºåÊ¥™Ê∞¥ÁôºÁîüÁöÑÈ†ªÁéáË∂ä‰æÜË∂äÈ´ò„ÄÇÂø´ÈÄüËÄåÊ∫ñÁ¢∫ÁöÑÊ¥™Ê∞¥ÂÅµÊ∏¨ÂíåÁõ£ÊéßÂ∞çÊñºÊ∏õËºïÈÄô‰∫õÂΩ±ÈüøËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÊØîËºÉ‰∫Ü‰∏âÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã UNet„ÄÅResNet Âíå DeepLabv3 Âú®ÂÉèÁ¥†Á¥öÊ∞¥È´îÂàÜÂâ≤‰∏≠ÁöÑË°®ÁèæÔºå‰ª•ÂçîÂä©Ê¥™Ê∞¥ÂÅµÊ∏¨ÔºåÂà©Áî®ÁÑ°‰∫∫Ê©ü„ÄÅÁèæÂ†¥ËßÄÊ∏¨ÂíåÁ§æÁæ§Â™íÈ´î‰∏≠ÁöÑÂΩ±ÂÉè„ÄÇÊú¨Á†îÁ©∂Ê∂âÂèäÂª∫Á´ã‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºåÂ∞áÁúæÊâÄÂë®Áü•ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜËàáÁâπÂÆöÊ¥™Ê∞¥ÁöÑÂΩ±ÂÉèÊì¥ÂÖÖÔºå‰ª•Â¢ûÂº∑Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊ∏¨Ë©¶ UNet„ÄÅResNet Âíå DeepLab v3 Êû∂ÊßãÔºå‰ª•Á¢∫ÂÆöÂÆÉÂÄëÂú®ÂêÑÁ®ÆÁí∞Â¢ÉÊ¢ù‰ª∂ÂíåÂú∞ÁêÜ‰ΩçÁΩÆ‰∏≠ÁöÑÊúâÊïàÊÄßÔºå‰∏¶‰∏îÂú®Ê≠§Êé¢Ë®éÊØèÂÄãÊ®°ÂûãÁöÑÂÑ™ÈªûÂíåÈôêÂà∂ÔºåÊèê‰æõÂú®‰∏çÂêåÂ†¥ÊôØ‰∏≠È†êÊ∏¨ÂΩ±ÂÉèÂàÜÂâ≤ÈÅÆÁΩ©ÁöÑÊáâÁî®Ë¶ãËß£„ÄÇÈÄôÁ®ÆÂÖ®Ëá™ÂãïÂåñÊñπÊ≥ïËÆìÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†Âú®ÂΩ±ÂÉè‰∏≠ÈöîÈõ¢Ê∑πÊ∞¥ÂçÄÂüüÔºåËàáÂÇ≥Áµ±ÁöÑÂçäËá™ÂãïÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåÂ§ßÂπÖÊ∏õÂ∞ëËôïÁêÜÊôÇÈñì„ÄÇÊú¨Á†îÁ©∂ÁöÑÊàêÊûúÊòØÈ†êÊ∏¨ÂèóÊ¥™ÁÅΩÂΩ±ÈüøÁöÑÊØèÂºµÂΩ±ÂÉèÁöÑÂàÜÂâ≤ÈÅÆÁΩ©Ôºå‰ª•ÂèäÈÄô‰∫õÊ®°ÂûãÁöÑÈ©óË≠âÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰øÉÈÄ≤ÂèäÊôÇ‰∏îÊåÅÁ∫åÁöÑÊ¥™Ê∞¥Áõ£ÊéßÔºåÊèê‰æõÁ∑äÊÄ•ÊáâËÆäÂ∞èÁµÑÁöÑÈáçË¶ÅË≥áÊñôÔºå‰ª•Ê∏õÂ∞ë‰∫∫Âì°ÂÇ∑‰∫°ÂíåÁ∂ìÊøüÊêçÂ§±„ÄÇÂÆÉÂ§ßÂπÖÁ∏ÆÁü≠‰∫ÜÁîüÊàêÊ¥™Ê∞¥Âú∞ÂúñÊâÄÈúÄÁöÑÊôÇÈñìÔºåÊ∏õÂ∞ë‰∫ÜÊâãÂãïËôïÁêÜÊôÇÈñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑÈÄîÂæëÔºåÂåÖÊã¨Êï¥ÂêàÂ§öÊ®°ÂºèË≥áÊñô‰æÜÊ∫êÔºå‰ª•ÂèäÈñãÁôºÂ∞àÈñÄÈáùÂ∞çÊ¥™Ê∞¥ÂÅµÊ∏¨‰ªªÂãôÁöÑÁ©©ÂÅ•Ê∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÂâµÊñ∞‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºåÁÇ∫Ê¥™Ê∞¥ÁÆ°ÁêÜÁ≠ñÁï•ÁöÑÈÄ≤Ê≠•ÂÅöÂá∫Ë≤¢Áçª„ÄÇ</paragraph>

##### **Towards Best Practices for Open Datasets for LLM Training**
2501.08365v1 by Stefan Baack, Stella Biderman, Kasia Odrozek, Aviya Skowron, Ayah Bdeir, Jillian Bommarito, Jennifer Ding, Maximilian Gahntz, Paul Keller, Pierre-Carl Langlais, Greg Lindahl, Sebastian Majstorovic, Nik Marda, Guilherme Penedo, Maarten Van Segbroeck, Jennifer Wang, Leandro von Werra, Mitchell Baker, Julie Beli√£o, Kasia Chmielinski, Marzieh Fadaee, Lisa Gutermuth, Hynek Kydl√≠ƒçek, Greg Leppert, EM Lewis-Jong, Solana Larsen, Shayne Longpre, Angela Oduor Lungati, Cullen Miller, Victor Miller, Max Ryabinin, Kathleen Siminyu, Andrew Strait, Mark Surman, Anna Tumad√≥ttir, Maurice Weber, Rebecca Weiss, Lee White, Thomas Wolf

Many AI companies are training their large language models (LLMs) on data
without the permission of the copyright owners. The permissibility of doing so
varies by jurisdiction: in countries like the EU and Japan, this is allowed
under certain restrictions, while in the United States, the legal landscape is
more ambiguous. Regardless of the legal status, concerns from creative
producers have led to several high-profile copyright lawsuits, and the threat
of litigation is commonly cited as a reason for the recent trend towards
minimizing the information shared about training datasets by both corporate and
public interest actors. This trend in limiting data information causes harm by
hindering transparency, accountability, and innovation in the broader ecosystem
by denying researchers, auditors, and impacted individuals access to the
information needed to understand AI models.
  While this could be mitigated by training language models on open access and
public domain data, at the time of writing, there are no such models (trained
at a meaningful scale) due to the substantial technical and sociological
challenges in assembling the necessary corpus. These challenges include
incomplete and unreliable metadata, the cost and complexity of digitizing
physical records, and the diverse set of legal and technical skills required to
ensure relevance and responsibility in a quickly changing landscape. Building
towards a future where AI systems can be trained on openly licensed data that
is responsibly curated and governed requires collaboration across legal,
technical, and policy domains, along with investments in metadata standards,
digitization, and fostering a culture of openness.

ÊëòË¶ÅÔºöË®±Â§ö AI ÂÖ¨Âè∏Âú®Ê≤íÊúâÂèñÂæóËëó‰ΩúÊ¨äÊâÄÊúâËÄÖË®±ÂèØÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ΩøÁî®Ë≥áÊñô‰æÜË®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÂú®‰∏çÂêåÂè∏Ê≥ïÁÆ°ËΩÑÂçÄÔºåÈÄôÁ®ÆÂÅöÊ≥ïÁöÑÂêàÊ≥ïÊÄßÊúâÊâÄ‰∏çÂêåÔºöÂú®Ê≠êÁõüÂíåÊó•Êú¨Á≠âÂúãÂÆ∂ÔºåÂú®ÁâπÂÆöÈôêÂà∂‰∏ãÂÖÅË®±Ê≠§ÂÅöÊ≥ïÔºåËÄåÂú®ÁæéÂúãÔºåÊ≥ïÂæãÁí∞Â¢ÉÂâáËºÉÁÇ∫Ê®°Á≥ä„ÄÇÁÑ°Ë´ñÊ≥ïÂæãÂú∞‰ΩçÂ¶Ç‰ΩïÔºå‰æÜËá™ÂâµÊÑèË£Ω‰Ωú‰∫∫ÁöÑÁñëÊÖÆÂ∑≤Â∞éËá¥Â§öËµ∑Âºï‰∫∫Ê≥®ÁõÆÁöÑËëó‰ΩúÊ¨äË®¥Ë®üÔºåËÄåË®¥Ë®üÂ®ÅËÑÖÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫ËøëÊúü‰ºÅÊ•≠ÂíåÂÖ¨ÂÖ±Âà©ÁõäÂèÉËàáËÄÖË∂®ÂêëÊñºÁõ°ÈáèÊ∏õÂ∞ëÂàÜ‰∫´ÈóúÊñºË®ìÁ∑¥Ë≥áÊñôÈõÜË≥áË®äÁöÑÂéüÂõ†„ÄÇÈôêÂà∂Ë≥áÊñôË≥áË®äÁöÑË∂®Âã¢ÊúÉÈÄèÈÅéÊãíÁµïÁ†îÁ©∂‰∫∫Âì°„ÄÅÁ®ΩÊ†∏‰∫∫Âì°ÂíåÂèóÂΩ±ÈüøÁöÑÂÄã‰∫∫ÂèñÂæóÁêÜËß£ AI Ê®°ÂûãÊâÄÈúÄÁöÑË≥áË®äÔºåÈÄ≤ËÄåÈòªÁ§ôÊõ¥Âª£Ê≥õÁîüÊÖãÁ≥ªÁµ±‰∏≠ÁöÑÈÄèÊòéÂ∫¶„ÄÅÂïèË≤¨Âà∂ÂíåÂâµÊñ∞ÔºåÂæûËÄåÈÄ†ÊàêÂÇ∑ÂÆ≥„ÄÇÂÑòÁÆ°ÈÄèÈÅéÂú®ÈñãÊîæÂèñÁî®ÂíåÂÖ¨ÊúâÈ†òÂüüË≥áÊñô‰∏äË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂèØ‰ª•Ê∏õËºïÈÄôÂÄãÂïèÈ°åÔºå‰ΩÜÂú®Êí∞ÂØ´Êú¨ÊñáÊôÇÔºåÁî±ÊñºÂú®ÂΩôÁ∑®ÂøÖË¶ÅÁöÑË™ûÊñôÂ∫´ÊñπÈù¢Â≠òÂú®ÈáçÂ§ßÁöÑÊäÄË°ìÂíåÁ§æÊúÉÊåëÊà∞ÔºåÂõ†Ê≠§‰∏¶‰∏çÂ≠òÂú®Ê≠§È°ûÊ®°ÂûãÔºà‰ª•ÊúâÊÑèÁæ©ÁöÑË¶èÊ®°Ë®ìÁ∑¥Ôºâ„ÄÇÈÄô‰∫õÊåëÊà∞ÂåÖÊã¨‰∏çÂÆåÊï¥‰∏î‰∏çÂèØÈù†ÁöÑÂÖÉË≥áÊñô„ÄÅÊï∏‰ΩçÂåñÂØ¶È´îË®òÈåÑÁöÑÊàêÊú¨ÂíåË§áÈõúÊÄßÔºå‰ª•ÂèäÂú®Âø´ÈÄüËÆäÂåñÁöÑÁí∞Â¢É‰∏≠Á¢∫‰øùÁõ∏ÈóúÊÄßÂíåË≤¨‰ªªÊâÄÈúÄÁöÑÂ§öÊ®£ÂåñÊ≥ïÂæãÂíåÊäÄË°ìÊäÄËÉΩ„ÄÇÊúùËëó AI Á≥ªÁµ±ËÉΩÂ§†Âú®Ë≤†Ë≤¨‰ªªÂú∞Á≠ñÂ±ïÂíåÁÆ°ÁêÜÁöÑÈñãÊîæÊéàÊ¨äË≥áÊñô‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÁöÑÊú™‰æÜÈÇÅÈÄ≤ÔºåÈúÄË¶ÅË∑®Ê≥ïÂæã„ÄÅÊäÄË°ìÂíåÊîøÁ≠ñÈ†òÂüüÈÄ≤Ë°åÂêà‰ΩúÔºå‰∏¶ÊäïË≥áÊñºÂÖÉË≥áÊñôÊ®ôÊ∫ñ„ÄÅÊï∏‰ΩçÂåñÔºå‰ª•ÂèäÂüπÈ§äÈñãÊîæÊñáÂåñ„ÄÇ

##### **Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**
2501.08248v1 by Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han

Recent advancements in long-context language models (LCLMs) promise to
transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With
their expanded context windows, LCLMs can process entire knowledge bases and
perform retrieval and reasoning directly -- a capability we define as
In-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like
LOFT often overestimate LCLM performance by providing overly simplified
contexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs
in more realistic scenarios by including confounding passages retrieved with
strong retrievers. We then propose three methods to enhance LCLM performance:
(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which
uses attention heads to filter and de-noise long contexts during decoding, and
(3) joint retrieval head training alongside the generation head. Our evaluation
of five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with
our best approach applied to Mistral-7B: +17 and +15 points by Exact Match on
LOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised
fine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks
despite being a much smaller model.

ÊëòË¶ÅÔºöÈï∑ÊñáÊú¨Ë™ûË®ÄÊ®°Âûã (LCLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊúâÊúõÈÄèÈÅéÁ∞°ÂåñÁÆ°Á∑ö‰æÜËΩâÊèõÊ™¢Á¥¢Â¢ûÂº∑Áî¢Áîü (RAG)„ÄÇLCLM ÈÄèÈÅéÂÖ∂Êì¥ÂÖÖÁöÑÂÖßÂÆπË¶ñÁ™óÔºåÂèØ‰ª•ËôïÁêÜÊï¥ÂÄãÁü•Ë≠òÂ∫´Ôºå‰∏¶Áõ¥Êé•Âü∑Ë°åÊ™¢Á¥¢ÂíåÊé®ÁêÜÔºåÊàëÂÄëÂ∞áÊ≠§ÂäüËÉΩÂÆöÁæ©ÁÇ∫ÊÉÖÂ¢ÉÂÖßÊ™¢Á¥¢ÂíåÊé®ÁêÜ (ICR^2)„ÄÇ‰∏çÈÅéÔºåÁèæÊúâÁöÑÂü∫Ê∫ñÔºà‰æãÂ¶Ç LOFTÔºâÁ∂ìÂ∏∏ÈÄèÈÅéÊèê‰æõÈÅéÂ∫¶Á∞°ÂåñÁöÑÂÖßÂÆπ‰æÜÈ´ò‰º∞ LCLM ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé®Âá∫ ICR^2ÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄèÈÅéÁ¥çÂÖ•‰ΩøÁî®Âº∑Â§ßÊ™¢Á¥¢Âô®Ê™¢Á¥¢Âà∞ÁöÑÊ∑∑Ê∑ÜÊÆµËêΩÔºåÂú®Êõ¥ÂØ¶ÈöõÁöÑÂ†¥ÊôØ‰∏≠Ë©ï‰º∞ LCLM ÁöÑÂü∫Ê∫ñ„ÄÇÊé•ËëóÔºåÊàëÂÄëÊèêÂá∫‰∏âÁ®ÆÊñπÊ≥ï‰æÜÊèêÂçá LCLM ÁöÑÊïàËÉΩÔºö(1) ÂÖàÊ™¢Á¥¢ÂæåÁî¢ÁîüÁöÑÂæÆË™ø„ÄÅ(2) Ê™¢Á¥¢Ê≥®ÊÑèÂäõÊé¢Ê∏¨ÔºåÂÆÉ‰ΩøÁî®Ê≥®ÊÑèÂäõÊ®ôÈ†≠Âú®Ëß£Á¢ºÊúüÈñìÈÅéÊøæÂíåÂéªÈô§ÈõúË®äÔºå‰ª•Âèä (3) Âú®Áî¢ÁîüÊ®ôÈ†≠ÊóÅÈÄ≤Ë°åËÅØÂêàÊ™¢Á¥¢Ê®ôÈ†≠Ë®ìÁ∑¥„ÄÇÊàëÂÄëÂú® LOFT Âíå ICR^2 ‰∏äÂ∞ç‰∫îÂÄãÁü•ÂêçÁöÑ LCLM ÈÄ≤Ë°åË©ï‰º∞ÔºåË≠âÊòéÊàëÂÄëÁöÑÊúÄ‰Ω≥ÊñπÊ≥ïÊáâÁî®Êñº Mistral-7B ÊôÇÊúâÈ°ØËëóÈÄ≤Ê≠•ÔºöËàáÂéüÂßã RAG ÂíåÁõ£Áù£ÂæÆË™øÁõ∏ÊØîÔºåÂú® LOFT ‰∏äÁöÑÂÆåÂÖ®ÊØîÂ∞çÂ¢ûÂä†‰∫Ü 17 Âíå 15 ÈªûÔºåÂú® ICR^2 ‰∏äÂ¢ûÂä†‰∫Ü 13 Âíå 2 Èªû„ÄÇÂç≥‰ΩøÂÆÉÊòØ‰∏ÄÂÄãÂ∞èÂæóÂ§öÁöÑÊ®°ÂûãÔºå‰ΩÜÂú®Â§ßÂ§öÊï∏‰ªªÂãô‰∏ä‰ªçÂÑ™Êñº GPT-4-Turbo„ÄÇ

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

ÊëòË¶ÅÔºöÊñ∞ÂÜ†ËÇ∫ÁÇéÁñ´ÊÉÖÂ∑≤ÂØπÂÖ®ÁêÉÊï∞ÂçÅ‰∫ø‰∫∫‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇÁî±‰∫éÂÖ∂‰º†Êí≠ËøÖÈÄü‰∏îÂëºÂê∏ÈÅìÁóáÁä∂‰∏•ÈáçÔºåÂÆÉÂØπÂÖ¨ÂÖ±Âç´ÁîüÂíåÂåªÁñó‰øùÂÅ•Á≥ªÁªüÊûÑÊàêÊåëÊàò„ÄÇÂáèËΩªÊñ∞ÂÜ†ËÇ∫ÁÇéÁñ´ÊÉÖÁöÑÊúâÊïàÁ≠ñÁï•ÂåÖÊã¨Êï¥ÂêàÊ£ÄÊµã‰ª•ËØÜÂà´ÂèóÊÑüÊüìËÄÖ„ÄÇËôΩÁÑ∂ RT-PCR Ë¢´ËÆ§‰∏∫ÊòØËØäÊñ≠Êñ∞ÂÜ†ËÇ∫ÁÇéÁöÑÈªÑÈáëÊ†áÂáÜÔºå‰ΩÜÂÆÉ‰πüÊúâ‰∏Ä‰∫õÈôêÂà∂Ôºå‰æãÂ¶ÇÂÅáÈò¥ÊÄßÁöÑÈ£éÈô©„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊ∑±Â∫¶Â≠¶‰π†ËØäÊñ≠Á≥ªÁªüÔºåËØ•Á≥ªÁªüÂ∞ÜÈ¢ÑËÆ≠ÁªÉÁöÑÊ∑±Â∫¶Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (DCNN) ÈõÜÊàêÂà∞ÈõÜÊàêÂ≠¶‰π†Ê°ÜÊû∂‰∏≠Ôºå‰ª•‰ªéËÉ∏ÈÉ® X Â∞ÑÁ∫ø (CXR) ÂõæÂÉè‰∏≠Á≤æÁ°ÆËØÜÂà´Êñ∞ÂÜ†ËÇ∫ÁÇéÁóÖ‰æã„ÄÇÊàë‰ª¨‰ΩøÁî® Choquet ÁßØÂàÜÁªìÂêàÊù•Ëá™È¢ÑËÆ≠ÁªÉ DCNN ÁöÑÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÂ±ÇÁöÑÁâπÂæÅÂêëÈáèÔºå‰ª•ÊçïËé∑Á∫øÊÄßÊñπÊ≥ïÊó†Ê≥ïÂÆûÁé∞ÁöÑ‰∏çÂêå DCNN ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÊàë‰ª¨ÈááÁî® Sugeno-$\lambda$ ÊµãÂ∫¶ÁêÜËÆ∫Êù•ÂØºÂá∫ÁΩëÁªúÂ≠êÈõÜÁöÑÊ®°Á≥äÊµãÂ∫¶‰ª•ÂÆûÁé∞ËÅöÂêà„ÄÇÊàë‰ª¨Âà©Áî®Â∑ÆÂàÜËøõÂåñÊù•‰º∞ËÆ°Ê®°Á≥äÂØÜÂ∫¶„ÄÇÁî±‰∫éËÅöÂêàÁâπÂæÅÂêëÈáèÁöÑÂ§çÊùÇÊÄßÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™Âü∫‰∫é TensorFlow ÁöÑ Choquet Êìç‰ΩúÂ±Ç‰ª•‰øÉËøõÈ´òÊïàËÅöÂêà„ÄÇCOVIDx Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÈõÜÊàêÊ®°ÂûãÂú®‰∏âÁ±ªÂàÜÁ±ª‰∏≠ËææÂà∞ 98% ÁöÑÂáÜÁ°ÆÁéáÔºåÂú®‰∫åÂÖÉÂàÜÁ±ª‰∏≠ËææÂà∞ 99.50%Ôºå‰ºò‰∫éÂÖ∂ÁªÑ‰ª∂ DenseNet-201Ôºà‰∏âÁ±ª‰∏∫ 97%Ôºå‰∫åÂÖÉ‰∏∫ 98.75%Ôºâ„ÄÅInception-v3Ôºà‰∏âÁ±ª‰∏∫ 96.25%Ôºå‰∫åÂÖÉ‰∏∫ 98.50%ÔºâÂíå XceptionÔºà‰∏âÁ±ª‰∏∫ 94.50%Ôºå‰∫åÂÖÉ‰∏∫ 98%ÔºâÔºåÂπ∂Ë∂ÖË∂ä‰∫ÜËÆ∏Â§ö‰ª•ÂâçÁöÑÊñπÊ≥ï„ÄÇ

##### **Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**
2501.08234v1 by Enrique Adrian Villarrubia-Martin, Luis Rodriguez-Benitez, David Mu√±oz-Valero, Giovanni Montana, Luis Jimenez-Linares

This paper addresses a critical challenge in the high-speed passenger railway
industry: designing effective dynamic pricing strategies in the context of
competing and cooperating operators. To address this, a multi-agent
reinforcement learning (MARL) framework based on a non-zero-sum Markov game is
proposed, incorporating random utility models to capture passenger decision
making. Unlike prior studies in areas such as energy, airlines, and mobile
networks, dynamic pricing for railway systems using deep reinforcement learning
has received limited attention. A key contribution of this paper is a
parametrisable and versatile reinforcement learning simulator designed to model
a variety of railway network configurations and demand patterns while enabling
realistic, microscopic modelling of user behaviour, called RailPricing-RL. This
environment supports the proposed MARL framework, which models heterogeneous
agents competing to maximise individual profits while fostering cooperative
behaviour to synchronise connecting services. Experimental results validate the
framework, demonstrating how user preferences affect MARL performance and how
pricing policies influence passenger choices, utility, and overall system
dynamics. This study provides a foundation for advancing dynamic pricing
strategies in railway systems, aligning profitability with system-wide
efficiency, and supporting future research on optimising pricing policies.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÈ´òÈÄüÈêµË∑ØÁî¢Ê•≠‰∏≠ÁöÑÈóúÈçµÊåëÊà∞ÔºöÂú®Á´∂Áà≠ËàáÂêà‰ΩúÁöÑÁáüÈÅãÂïÜËÉåÊôØ‰∏ãÔºåË®≠Ë®àÊúâÊïàÁöÑÂãïÊÖãÂÆöÂÉπÁ≠ñÁï•„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈùûÈõ∂ÂíåÈ¶¨ÂèØÂ§´ÂçöÂºàÁöÑÂ§öÈáç‰ª£ÁêÜÂº∑ÂåñÂ≠∏Áøí (MARL) Êû∂ÊßãÔºå‰∏¶Á¥çÂÖ•Èö®Ê©üÊïàÁî®Ê®°Âûã‰æÜÊçïÊçâ‰πòÂÆ¢Ê±∫Á≠ñ„ÄÇËàáËÉΩÊ∫ê„ÄÅËà™Á©∫ÂÖ¨Âè∏ÂíåË°åÂãïÁ∂≤Ë∑ØÁ≠âÈ†òÂüüÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºå‰ΩøÁî®Ê∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÁöÑÈêµË∑ØÁ≥ªÁµ±ÂãïÊÖãÂÆöÂÉπÂèóÂà∞ÁöÑÈóúÊ≥®ÊúâÈôê„ÄÇÊú¨ÊñáÁöÑ‰∏ÄÈ†ÖÈáçË¶ÅË≤¢ÁçªÊòØÂèØÂèÉÊï∏Âåñ‰∏îÁî®ÈÄîÂª£Ê≥õÁöÑÂº∑ÂåñÂ≠∏ÁøíÊ®°Êì¨Âô®ÔºåÊó®Âú®Ê®°Êì¨ÂêÑÁ®ÆÈêµË∑ØÁ∂≤Ë∑ØÁµÑÊÖãÂíåÈúÄÊ±ÇÊ®°ÂºèÔºåÂêåÊôÇÊîØÊè¥‰ΩøÁî®ËÄÖË°åÁÇ∫ÁöÑÂØ¶ÈöõÂæÆËßÄÂª∫Ê®°ÔºåÁ®±ÁÇ∫ RailPricing-RL„ÄÇÊ≠§Áí∞Â¢ÉÊîØÊè¥ÊâÄÊèêÂá∫ÁöÑ MARL Êû∂ÊßãÔºåË©≤Êû∂ÊßãÊ®°Êì¨Áï∞Ë≥™‰ª£ÁêÜÁ´∂Áà≠‰ª•ÊúÄÂ§ßÂåñÂÄãÂà•Âà©ÊΩ§ÔºåÂêåÊôÇ‰øÉÈÄ≤Âêà‰ΩúË°åÁÇ∫‰ª•ÂêåÊ≠•ÈÄ£Êé•ÊúçÂãô„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊ≠§Êû∂ÊßãÔºåÂ±ïÁ§∫‰ΩøÁî®ËÄÖÂÅèÂ•ΩÂ¶Ç‰ΩïÂΩ±Èüø MARL ÊÄßËÉΩÔºå‰ª•ÂèäÂÆöÂÉπÊîøÁ≠ñÂ¶Ç‰ΩïÂΩ±Èüø‰πòÂÆ¢ÈÅ∏Êìá„ÄÅÊïàÁî®ÂíåÊï¥È´îÁ≥ªÁµ±ÂãïÊÖã„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÊé®ÈÄ≤ÈêµË∑ØÁ≥ªÁµ±ÂãïÊÖãÂÆöÂÉπÁ≠ñÁï•ÁöÑÂü∫Á§éÔºåÂ∞áÁç≤Âà©ËÉΩÂäõËàáÁ≥ªÁµ±ÁØÑÂúçÁöÑÊïàÁéáÁµêÂêàËµ∑‰æÜÔºå‰∏¶ÊîØÊè¥Êú™‰æÜÂÑ™ÂåñÂÆöÂÉπÊîøÁ≠ñÁöÑÁ†îÁ©∂„ÄÇ

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá®Â∫äÂïèÁ≠î (QA) ‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊΩõÂäõÔºåÂÖ∂‰∏≠Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊàêÁÇ∫Á¢∫‰øùÊ®°ÂûãÂõûÊáâ‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÁöÑÈ†òÂÖàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËá™ÂãïÂåñ RAG ÊåáÊ®ôÂú®Ëá®Â∫äÂíåÂ∞çË©±ÂºèÁî®‰æã‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇ‰ΩøÁî®Ëá®Â∫ä‰∫∫È°ûÂ∞çÂõûÊáâÁöÑË©ï‰º∞Êó¢ÊòÇË≤¥Âèà‰∏çÂÖ∑ÂèØÊì¥ÂÖÖÊÄßÔºå‰πü‰∏çÂà©Êñº RAG Á≥ªÁµ±ÁöÑÊåÅÁ∫åËø≠‰ª£ÈñãÁôº„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ASTRID - ‰∏ÄÁ®ÆÁî®ÊñºË©ï‰º∞Âà©Áî® RAG ÁöÑËá®Â∫ä QA Á≥ªÁµ±ÁöÑËá™ÂãïÂåñ‰∏îÂèØÊì¥ÂÖÖÁöÑ TRIaD - ÂåÖÂê´‰∏âÂÄãÊåáÊ®ôÔºöËÑàÁµ°Áõ∏ÈóúÊÄß (CR)„ÄÅÊãíÁµïÊ∫ñÁ¢∫ÊÄß (RA) ÂíåÂ∞çË©±Âø†ÂØ¶Â∫¶ (CF)„ÄÇÊàëÂÄëÊñ∞Á©éÁöÑË©ï‰º∞ÊåáÊ®ô CF Êó®Âú®Êõ¥Â•ΩÂú∞ÊçïÊçâÊ®°ÂûãÂ∞çÁü•Ë≠òÂ∫´ÁöÑÂõûÊáâÁöÑÂø†ÂØ¶Â∫¶ÔºåÂêåÊôÇ‰∏çÊá≤ÁΩ∞Â∞çË©±ÂÖÉÁ¥†„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÁöÑ‰∏âÂÖÉÁµÑÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÂÄãÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Âú®ÁôΩÂÖßÈöúÊâãË°ìË°ìÂæåÈö®Ë®™ÊúüÈñìÂêë LLM Âü∫Êñº QA ÁöÑ‰ª£ÁêÜÊèêÂá∫ÁöÑ 200 Â§öÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊÇ£ËÄÖÂïèÈ°å - ‰∏ñÁïå‰∏äÊâãË°ìÈáèÊúÄÂ§ßÁöÑÊâãË°ì - ‰∏¶Â¢ûÂä†‰∫ÜËá®Â∫äÈÜ´ÁîüÈÅ∏ÊìáÁöÑÂïèÈ°åÔºåÁî®ÊñºÁ∑äÊÄ•„ÄÅËá®Â∫äÂíåÈùûËá®Â∫äÈ†òÂüüÂ§ñÊÉÖÂ¢É„ÄÇÊàëÂÄëË≠âÊòéÔºåËàáÂ∞çË©±ÂºèÁî®‰æãÁèæÊúâÂÆöÁæ©Áõ∏ÊØîÔºåCF ÂèØ‰ª•Êõ¥Â•ΩÂú∞È†êÊ∏¨‰∫∫È°ûÂ∞çÂø†ÂØ¶Â∫¶ÁöÑË©ïÂàÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®Êòé‰ΩøÁî®Áî± CF„ÄÅRA Âíå CR ÁµÑÊàêÁöÑ‰∏âÂÖÉÁµÑÈÄ≤Ë°åË©ï‰º∞ËàáËá®Â∫äÈÜ´ÁîüÂ∞ç‰∏çÈÅ©Áï∂„ÄÅÊúâÂÆ≥ÊàñÁÑ°ÁõäÁöÑÂõûÊáâÁöÑË©ï‰º∞‰øùÊåÅ‰∏ÄËá¥„ÄÇÊúÄÂæåÔºå‰ΩøÁî®‰πùÁ®Æ‰∏çÂêåÁöÑ LLMÔºåÊàëÂÄëË≠âÊòéÈÄô‰∏âÂÄãÊåáÊ®ôÂèØ‰ª•Ëàá‰∫∫È°ûË©ï‰º∞Á∑äÂØÜ‰∏ÄËá¥ÔºåÁ™ÅÈ°Ø‰∫ÜÈÄô‰∫õÊåáÊ®ôÂú® LLM È©ÖÂãïÁöÑËá™ÂãïÂåñË©ï‰º∞ÁÆ°ÈÅì‰∏≠‰ΩøÁî®ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÈÇÑÂÖ¨‰Ωà‰∫ÜÈÄô‰∫õÂØ¶È©óÁöÑÊèêÁ§∫ÂíåÊï∏ÊìöÈõÜÔºåÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÂíåÈñãÁôºÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫ê„ÄÇ

##### **Modeling Feature Maps for Quantum Machine Learning**
2501.08205v1 by Navneet Singh, Shiva Raj Pokhrel

Quantum Machine Learning (QML) offers significant potential for complex tasks
like genome sequence classification, but quantum noise on Noisy
Intermediate-Scale Quantum (NISQ) devices poses practical challenges. This
study systematically evaluates how various quantum noise models including
dephasing, amplitude damping, depolarizing, thermal noise, bit-flip, and
phase-flip affect key QML algorithms (QSVC, Peg-QSVC, QNN, VQC) and feature
mapping techniques (ZFeatureMap, ZZFeatureMap, and PauliFeatureMap). Results
indicate that QSVC is notably robust under noise, whereas Peg-QSVC and QNN are
more sensitive, particularly to depolarizing and amplitude-damping noise. The
PauliFeatureMap is especially vulnerable, highlighting difficulties in
maintaining accurate classification under noisy conditions. These findings
underscore the critical importance of feature map selection and noise
mitigation strategies in optimizing QML for genomic classification, with
promising implications for personalized medicine.

ÊëòË¶ÅÔºöÈáèÂ≠êÊ©üÂô®Â≠∏Áøí (QML) ÁÇ∫Âü∫Âõ†ÁµÑÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãôÊèê‰æõ‰∫ÜÂ∑®Â§ßÁöÑÊΩõÂäõÔºå‰ΩÜÊúâÂô™ËÅ≤‰∏≠ÈöéÈáèÂ≠ê (NISQ) Ë£ùÁΩÆ‰∏äÁöÑÈáèÂ≠êÂô™ËÅ≤ÊúÉÂ∏∂‰æÜÂØ¶ÈöõÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜÂêÑÁ®ÆÈáèÂ≠êÂô™ËÅ≤Ê®°ÂûãÔºåÂåÖÊã¨ÂéªÁõ∏‰Ωç„ÄÅÊåØÂπÖÈòªÂ∞º„ÄÅÂéªÊ•µÂåñ„ÄÅÁÜ±Âô™ËÅ≤„ÄÅ‰ΩçÂÖÉÁøªËΩâÂíåÁõ∏‰ΩçÁøªËΩâÔºåÂ¶Ç‰ΩïÂΩ±Èüø‰∏ªË¶ÅÁöÑ QML ÊºîÁÆóÊ≥ï (QSVC„ÄÅPeg-QSVC„ÄÅQNN„ÄÅVQC) ÂíåÁâπÂæµÂ∞çÊáâÊäÄË°ì (ZFeatureMap„ÄÅZZFeatureMap Âíå PauliFeatureMap)„ÄÇÁµêÊûúË°®ÊòéÔºåQSVC Âú®Âô™ËÅ≤‰∏ãÈ°ØËëóÂº∑ÂÅ•ÔºåËÄå Peg-QSVC Âíå QNN ÂâáËºÉÊïèÊÑüÔºåÁâπÂà•ÊòØÂ∞çÊñºÂéªÊ•µÂåñÂíåÊåØÂπÖÈòªÂ∞ºÂô™ËÅ≤„ÄÇPauliFeatureMap ÁâπÂà•ÂÆπÊòìÂèóÂà∞ÂΩ±ÈüøÔºåÁ™ÅÈ°Ø‰∫ÜÂú®ÊúâÂô™ËÅ≤Ê¢ù‰ª∂‰∏ãÁ∂≠ÊåÅÊ∫ñÁ¢∫ÂàÜÈ°ûÁöÑÈõ£Â∫¶„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÁâπÂæµÂ∞çÊáâÈÅ∏ÊìáÂíåÂô™ËÅ≤Á∑©Ëß£Á≠ñÁï•Âú®ÊúÄ‰Ω≥Âåñ QML ‰ª•ÈÄ≤Ë°åÂü∫Âõ†ÁµÑÂàÜÈ°û‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÂ∞çÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊúâ‰ª§‰∫∫ÊåØÂ•ÆÁöÑÂΩ±Èüø„ÄÇ

##### **ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**
2501.08203v1 by Zain Ul Abedin, Shahzeb Qamar, Lucie Flek, Akbar Karimi

While Large Language Models (LLMs) have shown impressive capabilities in math
problem-solving tasks, their robustness to noisy inputs is not well-studied. In
this work, we propose ArithmAttack to examine how robust the LLMs are when they
encounter noisy prompts that contain extra noise in the form of punctuation
marks. While being easy to implement, ArithmAttack does not cause any
information loss since words are not added or deleted from the context. We
evaluate the robustness of seven LLMs, including LLama3, Mistral, and
Mathstral, on noisy GSM8K and MultiArith datasets. Our experiments suggest that
all the studied models show vulnerability to such noise, with more noise
leading to poorer performances.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êï∏Â≠∏ÂïèÈ°åËß£Ê±∫‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂÆÉÂÄëÂ∞çÊñºÊúâÈõúË®äËº∏ÂÖ•ÁöÑÂÅ•Â£ØÊÄßÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ ArithmAttack ‰æÜÊ™¢È©ó LLM Âú®ÈÅáÂà∞ÂåÖÂê´È°çÂ§ñÈõúË®äÔºà‰ª•Ê®ôÈªûÁ¨¶ËôüÂΩ¢ÂºèÔºâÁöÑÈõúË®äÊèêÁ§∫ÊôÇÂÖ∑ÊúâÂ§öÈ∫ºÂÅ•Â£Ø„ÄÇArithmAttack ÂÆπÊòìÂØ¶‰ΩúÔºåËÄå‰∏î‰∏çÊúÉÈÄ†Êàê‰ªª‰ΩïË≥áË®äÈÅ∫Â§±ÔºåÂõ†ÁÇ∫‰∏çÊúÉÂæûÂÖßÂÆπ‰∏≠Êñ∞Â¢ûÊàñÂà™Èô§Â≠óË©û„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÉÂÄã LLM ÁöÑÂÅ•Â£ØÊÄßÔºåÂåÖÊã¨ LLama3„ÄÅMistral Âíå MathstralÔºåÂú®ÊúâÈõúË®äÁöÑ GSM8K Âíå MultiArith Ë≥áÊñôÈõÜ‰∏ä„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊâÄÊúâÁ†îÁ©∂ÁöÑÊ®°ÂûãÈÉΩÈ°ØÁ§∫Âá∫Â∞çÈÄôÁ®ÆÈõúË®äÁöÑËÑÜÂº±ÊÄßÔºåÈõúË®äË∂äÂ§öÔºåÊïàËÉΩË∂äÂ∑Æ„ÄÇ

