# arxiv-daily
 Automated deployment @ 2024-12-17 09:11:31 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v1](http://arxiv.org/abs/2412.10337v1)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-12**|**Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**|Shengxuming Zhang et.al.|[2412.09521v1](http://arxiv.org/abs/2412.09521v1)|null|
|**2024-12-12**|**Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**|Xiaoshuang Huang et.al.|[2412.09278v1](http://arxiv.org/abs/2412.09278v1)|[link](https://github.com/shawnhuang497/medplib)|
|**2024-12-12**|**CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2412.09223v1](http://arxiv.org/abs/2412.09223v1)|null|
|**2024-12-12**|**Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**|Alfio Ventura et.al.|[2412.09086v1](http://arxiv.org/abs/2412.09086v1)|null|
|**2024-12-12**|**Radiology Report Generation via Multi-objective Preference Optimization**|Ting Xiao et.al.|[2412.08901v2](http://arxiv.org/abs/2412.08901v2)|null|
|**2024-12-12**|**AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**|Ting He et.al.|[2412.08900v1](http://arxiv.org/abs/2412.08900v1)|null|
|**2024-12-12**|**Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**|Hans Moen et.al.|[2412.08873v1](http://arxiv.org/abs/2412.08873v1)|null|
|**2024-12-11**|**Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**|Jiarui Zhang et.al.|[2412.08737v1](http://arxiv.org/abs/2412.08737v1)|null|
|**2024-12-11**|**Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**|Elena Cardillo et.al.|[2412.09651v1](http://arxiv.org/abs/2412.09651v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|Célia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|[link](https://github.com/celia-bl/hierarchical_classifying_corals_dataset)|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|[link](https://github.com/Princeton-RL/contrastive-successor-features)|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v2](http://arxiv.org/abs/2412.07951v2)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|[link](https://github.com/Healthy-AI/inpole)|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v2](http://arxiv.org/abs/2412.07880v2)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|[link](https://github.com/ai-law-society-lab/evaluating-durable-safeguards)|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**|Venkat Margapuri et.al.|[2412.07806v1](http://arxiv.org/abs/2412.07806v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|[link](https://github.com/precise-ai4oph/va_pred_pac)|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v2](http://arxiv.org/abs/2412.06600v2)|[link](https://github.com/everydaylucky/wu_xing_harmony_system)|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**|Xuefeng Ni et.al.|[2412.05876v1](http://arxiv.org/abs/2412.05876v1)|[link](https://github.com/xuefeng-ni/mg-3d)|
|**2024-12-08**|**Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**|Dinesh Parthasarathy et.al.|[2412.05852v1](http://arxiv.org/abs/2412.05852v1)|null|
|**2024-12-07**|**Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**|Abd Ur Rehman et.al.|[2412.05632v1](http://arxiv.org/abs/2412.05632v1)|null|
|**2024-12-07**|**UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**|Saba Hesaraki et.al.|[2412.05585v1](http://arxiv.org/abs/2412.05585v1)|null|
|**2024-12-07**|**Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**|Atit Pokharel et.al.|[2412.05583v2](http://arxiv.org/abs/2412.05583v2)|null|
|**2024-12-07**|**Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**|Cailian Ruan et.al.|[2412.05536v1](http://arxiv.org/abs/2412.05536v1)|null|
|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828v1](http://arxiv.org/abs/2412.06828v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v2](http://arxiv.org/abs/2412.05248v2)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v3](http://arxiv.org/abs/2412.02819v3)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Jingyuan Yi et.al.|[2412.02801v2](http://arxiv.org/abs/2412.02801v2)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v2](http://arxiv.org/abs/2412.02012v2)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v2](http://arxiv.org/abs/2412.01031v2)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|

#### Abstracts
##### **Generative AI in Medicine**
2412.10337v1 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

摘要：生成式 AI 的能力提升大幅擴展了其在醫學中的潛在應用案例。我們提供了一個全面的概觀，說明生成式 AI 在臨床醫生、患者、臨床試驗組織者、研究人員和受訓人員的應用案例。接著，我們討論了許多挑戰，包括維護隱私和安全性、提升透明度和可解釋性、維護公平性，以及嚴格評估模型，這些挑戰必須克服才能實現這種潛力，以及它們引發的開放研究方向。

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

摘要：由於世界衛生組織將猴痘病毒全球爆發定為國際關注的公共衛生緊急事件，因此猴痘病毒與其他皮膚病變疾病在視覺上的相似性，對診斷帶來重大挑戰。目前的臨床檢測技術在準確性和效率方面面臨限制，因此需要改進的自動化診斷解決方案。本研究引入了一個新穎的串聯空洞組注意力 (CAGA) 模組，專門設計用於增強多尺度特徵表示，同時最佳化運算效率。透過將 CAGA 與 EfficientViT-L1 整合作為主幹架構，我們的做法在 MCSI 資料集上以 0.98% 的分數達到了最先進的效能，同時與原始 EfficientViT-L1 相比，模型參數減少了 37.5%。這種運算複雜度的降低維持了診斷準確性，同時支援在資源受限的醫療保健環境中更廣泛地部署。在包括 MSID 和 MSLD 在內的另外兩個基準資料集上的廣泛驗證證明了模型的穩健性，始終優於現有方法。我們的研究結果表明，CAGA 的高效特徵提取機制可以調整為其他需要細緻視覺辨別的醫學影像任務。

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

摘要：加速式 MRI 重建技術旨在縮短檢查時間，同時維持高影像保真度，這在臨床環境中非常理想，可提升病患舒適度和醫院效率。現有的深度學習方法通常使用傳統重建方法從欠採樣數據重建影像，但仍難以提供高保真度結果。擴散模型在近年展現出提升生成影像保真度的絕佳潛力。然而，其從隨機高斯雜訊開始的推論過程會為結果帶來不穩定性，且通常需要數千個採樣步驟，導致次最佳重建品質和低效率。為了應對這些挑戰，我們提出循環一致橋接擴散模型 (CBDM)。CBDM 使用兩個橋接擴散模型，建構一個具有相容性損失的循環一致擴散過程，增強重建影像的精細細節並減少擴散步驟的數量。此外，CBDM 整合了一個輪廓分解嵌入模組 (CDEM)，透過頻域分解金字塔和方向濾波器組在影像中擷取多尺度結構紋理知識，以提升結構保真度。廣泛的實驗證明了我們模型的優異性，具有更高的重建品質和更少的訓練反覆運算，在 fastMRI 和 IXI 資料集的加速式 MRI 重建中達成新的技術水準。

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

摘要：本文探討大型語言模型 (LLM) 在護理和老年照護中的應用，重點在於 AI 驅動的病人監控和互動。我們引入了一個新穎的中文護理資料集，並實施增量預訓練 (IPT) 和監督微調 (SFT) 技術，以增強 LLM 在專業任務中的表現。使用 LangChain，我們開發了一個動態護理助理，能夠提供即時照護和個人化干預措施。實驗結果證明了顯著的改進，為 AI 驅動的解決方案鋪平了道路，以滿足老齡化人口對醫療保健日益增長的需求。

##### **Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**
2412.09521v1 by Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Mingli Song, Xiuming Zhang, Zunlei Feng

Pathological diagnosis is vital for determining disease characteristics,
guiding treatment, and assessing prognosis, relying heavily on detailed,
multi-scale analysis of high-resolution whole slide images (WSI). However,
traditional pure vision models face challenges of redundant feature extraction,
whereas existing large vision-language models (LVLMs) are limited by input
resolution constraints, hindering their efficiency and accuracy. To overcome
these issues, we propose two innovative strategies: the mixed task-guided
feature enhancement, which directs feature extraction toward lesion-related
details across scales, and the prompt-guided detail feature completion, which
integrates coarse- and fine-grained features from WSI based on specific prompts
without compromising inference speed. Leveraging a comprehensive dataset of
490,000 samples from diverse pathology tasks-including cancer detection,
grading, vascular and neural invasion identification, and so on-we trained the
pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that
this model significantly outperforms existing methods in diagnostic accuracy
and efficiency, offering an interactive, clinically aligned approach for
auxiliary diagnosis in a wide range of pathology applications.

摘要：病理诊断对于确定疾病特征、指导治疗和评估预后至关重要，它严重依赖于对高分辨率全玻片图像 (WSI) 的详细、多尺度分析。然而，传统的纯视觉模型面临冗余特征提取的挑战，而现有的大型视觉语言模型 (LVLMs) 受到输入分辨率约束的限制，阻碍了它们的效率和准确性。为了克服这些问题，我们提出了两种创新策略：混合任务引导的特征增强，它将特征提取引导到跨尺度的病变相关细节上；以及提示引导的细节特征完成，它基于特定提示将 WSI 中的粗粒度和细粒度特征集成在一起，而不会影响推理速度。利用来自不同病理任务的 490,000 个样本的综合数据集，包括癌症检测、分级、血管和神经侵袭识别等，我们训练了病理学专业 LVLM，即 OmniPath。大量的实验表明，该模型在诊断准确性和效率方面明显优于现有方法，为广泛的病理学应用中的辅助诊断提供了一种交互式、临床上一致的方法。

##### **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
2412.09278v1 by Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang

In recent years, Multimodal Large Language Models (MLLM) have achieved
notable advancements, demonstrating the feasibility of developing an
intelligent biomedical assistant. However, current biomedical MLLMs
predominantly focus on image-level understanding and restrict interactions to
textual commands, thus limiting their capability boundaries and the flexibility
of usage. In this paper, we introduce a novel end-to-end multimodal large
language model for the biomedical domain, named MedPLIB, which possesses
pixel-level understanding. Excitingly, it supports visual question answering
(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form
shapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)
multi-stage training strategy, which divides MoE into separate training phases
for a visual-language expert model and a pixel-grounding expert model, followed
by fine-tuning using MoE. This strategy effectively coordinates multitask
learning while maintaining the computational cost at inference equivalent to
that of a single expert model. To advance the research of biomedical MLLMs, we
introduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),
which comprises an array of 8 modalities for complex medical imaging question
answering and image region understanding. Experimental results indicate that
MedPLIB has achieved state-of-the-art outcomes across multiple medical visual
language tasks. More importantly, in zero-shot evaluations for the pixel
grounding task, MedPLIB leads the best small and large models by margins of
19.7 and 15.6 respectively on the mDice metric. The codes, data, and model
checkpoints will be made publicly available at
https://github.com/ShawnHuang497/MedPLIB.

摘要：<paragraph>近年来，多模态大型语言模型 (MLLM) 已取得显著进展，证明了开发智能生物医学助理的可行性。然而，当前的生物医学 MLLM 主要专注于图像级理解，并将交互限制在文本命令中，从而限制了它们的能力边界和使用灵活性。在本文中，我们介绍了一个用于生物医学领域的全新端到端多模态大型语言模型，名为 MedPLIB，它具有像素级理解能力。令人兴奋的是，它支持视觉问答 (VQA)、任意像素级提示（点、边界框和自由形式形状）以及像素级接地。我们提出了一种新颖的专家混合 (MoE) 多阶段训练策略，该策略将 MoE 分为视觉语言专家模型和像素接地专家模型的单独训练阶段，然后使用 MoE 进行微调。该策略有效地协调了多任务学习，同时将推理时的计算成本保持在与单个专家模型相当的水平。为了推进生物医学 MLLM 的研究，我们引入了医学复杂视觉问答数据集 (MeCoVQA)，它包含一系列 8 种用于复杂医学影像问答和图像区域理解的模态。实验结果表明，MedPLIB 在多个医学视觉语言任务中取得了最先进的成果。更重要的是，在像素接地任务的零样本评估中，MedPLIB 在 mDice 指标上分别以 19.7 和 15.6 的优势领先于最好的小型和大型模型。代码、数据和模型检查点将在 https://github.com/ShawnHuang497/MedPLIB 上公开。
</paragraph>

##### **CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**
2412.09223v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez

The rise of digital platforms has led to an increasing reliance on
technology-driven, home-based healthcare solutions, enabling individuals to
monitor their health and share information with healthcare professionals as
needed. However, creating an efficient care plan management system requires
more than just analyzing hospital summaries and Electronic Health Records
(EHRs). Factors such as individual user needs and social determinants of
health, including living conditions and the flow of healthcare information
between different settings, must also be considered. Challenges in this complex
healthcare network involve schema diversity (in EHRs, personal health records,
etc.) and terminology diversity (e.g., ICD, SNOMED-CT) across ancillary
healthcare operations. Establishing interoperability among various systems and
applications is crucial, with the European Interoperability Framework (EIF)
emphasizing the need for patient-centric access and control of healthcare data.
In this paper, we propose an integrated ontological model, the Common Semantic
Data Model for Social Determinants of Health (CSSDH), by combining ISO/DIS
13940:2024 ContSys with WHO Social Determinants of Health. CSSDH aims to
achieve interoperability within the Continuity of Care Network.

摘要：數位平台的興起導致愈來愈依賴科技驅動、居家醫療保健解決方案，讓個人得以監測自己的健康，並視需要與醫療保健專業人員分享資訊。然而，建立一個有效的照護計畫管理系統，需要的可不僅僅是分析醫院摘要和電子健康紀錄 (EHR) 而已。還必須考量個人使用者需求和健康的社會決定因素，包括生活條件和不同環境之間的醫療保健資訊流動。這個複雜的醫療保健網路中的挑戰，包括架構多樣性 (在 EHR、個人健康紀錄等) 和術語多樣性 (例如 ICD、SNOMED-CT) 等輔助醫療保健作業。在各種系統和應用程式之間建立互通性至關重要，歐洲互通性架構 (EIF) 強調需要以病人為中心存取和控制醫療保健資料。在本文中，我們提出一個整合的本體論模型，即結合 ISO/DIS 13940:2024 ContSys 與 WHO 健康社會決定因素的社會決定因素健康共同語義資料模型 (CSSDH)。CSSDH 旨在在照護連續性網路中達成互通性。

##### **Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**
2412.09086v1 by Alfio Ventura, Nils Köbis

This position paper discusses the benefits of longitudinal behavioural
research with customised AI tools for exploring the opportunities and risks of
synthetic relationships. Synthetic relationships are defined as "continuing
associations between humans and AI tools that interact with one another wherein
the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions."
(Starke et al., 2024). These relationships can potentially improve health,
education, and the workplace, but they also bring the risk of subtle
manipulation and privacy and autonomy concerns. To harness the opportunities of
synthetic relationships and mitigate their risks, we outline a methodological
approach that complements existing findings. We propose longitudinal research
designs with self-assembled AI agents that enable the integration of detailed
behavioural and self-reported data.

摘要：本立場文件探討縱向行為研究與客製化 AI 工具的優點，用於探討合成關係的機會與風險。合成關係定義為「人類與 AI 工具之間持續的關聯，彼此互動，其中 AI 工具會影響人類的想法、感受和/或行為。」（Starke 等人，2024 年）。這些關係有可能改善健康、教育和職場，但它們也帶來微妙的操縱以及隱私和自主權的隱憂。為了利用合成關係的機會並降低其風險，我們概述了一種方法論方法，補充現有的發現。我們提出使用自組裝 AI 代理的縱向研究設計，使我們能夠整合詳細的行為和自我報告資料。

##### **Radiology Report Generation via Multi-objective Preference Optimization**
2412.08901v2 by Ting Xiao, Lei Shi, Peng Liu, Zhe Wang, Chenjia Bai

Automatic Radiology Report Generation (RRG) is an important topic for
alleviating the substantial workload of radiologists. Existing RRG approaches
rely on supervised regression based on different architectures or additional
knowledge injection,while the generated report may not align optimally with
radiologists' preferences. Especially, since the preferences of radiologists
are inherently heterogeneous and multidimensional, e.g., some may prioritize
report fluency, while others emphasize clinical accuracy. To address this
problem,we propose a new RRG method via Multi-objective Preference Optimization
(MPO) to align the pre-trained RRG model with multiple human preferences, which
can be formulated by multi-dimensional reward functions and optimized by
multi-objective reinforcement learning (RL). Specifically, we use a preference
vector to represent the weight of preferences and use it as a condition for the
RRG model. Then, a linearly weighed reward is obtained via a dot product
between the preference vector and multi-dimensional reward. Next,the RRG model
is optimized to align with the preference vector by optimizing such a reward
via RL. In the training stage,we randomly sample diverse preference vectors
from the preference space and align the model by optimizing the weighted
multi-objective rewards, which leads to an optimal policy on the entire
preference space. When inference,our model can generate reports aligned with
specific preferences without further fine-tuning. Extensive experiments on two
public datasets show the proposed method can generate reports that cater to
different preferences in a single model and achieve state-of-the-art
performance.

摘要：自動放射報告生成 (RRG) 是減輕放射科醫師大量工作負擔的重要議題。現有的 RRG 方法仰賴基於不同架構或額外知識注入的監督式回歸，而產生的報告可能無法最佳地符合放射科醫師的偏好。特別是，由於放射科醫師的偏好本質上是異質且多面向的，例如，有些人可能優先考慮報告的流暢度，而另一些人則強調臨床準確性。為了解決這個問題，我們透過多目標偏好最佳化 (MPO) 提出一個新的 RRG 方法，以將預先訓練的 RRG 模型與多個人類偏好對齊，這可以用多維獎勵函數來制定，並透過多目標強化學習 (RL) 來最佳化。具體來說，我們使用偏好向量來表示偏好的權重，並將其用作 RRG 模型的條件。然後，透過偏好向量和多維獎勵之間的點積，獲得線性加權獎勵。接下來，透過 RL 最佳化此類獎勵，最佳化 RRG 模型以與偏好向量對齊。在訓練階段，我們從偏好空間中隨機取樣不同的偏好向量，並透過最佳化加權的多目標獎勵來對齊模型，這會產生整個偏好空間的最佳策略。在推論時，我們的模型可以生成與特定偏好對齊的報告，而無需進一步微調。在兩個公開資料集上的廣泛實驗顯示，所提出的方法可以在單一模型中生成迎合不同偏好的報告，並達到最先進的效能。

##### **AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**
2412.08900v1 by Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis

The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.

摘要：適當標靶療法在癌症病患的應用，需要在現有知識和生物醫學文獻中所描述的最新發現的脈絡下，完整分析腫瘤的分子特徵和病患的臨床特徵。我們評估了特定自然語言處理解決方案在支援從生物醫學文獻中發現知識的潛在貢獻。我們測試了來自 Transformer 雙向編碼器表示法 (BERT) 家族的兩個模型、兩個大型語言模型和 PubTator 3.0，以評估它們支援命名實體辨識 (NER) 和關係萃取 (RE) 任務的能力。PubTator 3.0 和 BioBERT 模型在 NER 任務中表現最佳（最佳 F1 分數分別為 0.93 和 0.89），而 BioBERT 在 RE 任務中優於所有其他解決方案（最佳 F1 分數為 0.79），並且在一個特定的應用案例中，它幾乎辨識出所有實體提及和大部分關係。

##### **Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**
2412.08873v1 by Hans Moen, Vishnu Raj, Andrius Vabalas, Markus Perola, Samuel Kaski, Andrea Ganna, Pekka Marttinen

Health registers contain rich information about individuals' health
histories. Here our interest lies in understanding how individuals' health
trajectories evolve in a nationwide longitudinal dataset with coded features,
such as clinical codes, procedures, and drug purchases. We introduce a
straightforward approach for training a Transformer-based deep learning model
in a way that lets us analyze how individuals' trajectories change over time.
This is achieved by modifying the training objective and by applying a causal
attention mask. We focus here on a general task of predicting the onset of a
range of common diseases in a given future forecast interval. However, instead
of providing a single prediction about diagnoses that could occur in this
forecast interval, our approach enable the model to provide continuous
predictions at every time point up until, and conditioned on, the time of the
forecast period. We find that this model performs comparably to other models,
including a bi-directional transformer model, in terms of basic prediction
performance while at the same time offering promising trajectory modeling
properties. We explore a couple of ways to use this model for analyzing health
trajectories and aiding in early detection of events that forecast possible
later disease onsets. We hypothesize that this method may be helpful in
continuous monitoring of peoples' health trajectories and enabling
interventions in ongoing health trajectories, as well as being useful in
retrospective analyses.

摘要：健康登記包含個人健康史的豐富資訊。我們在此有興趣了解個人健康軌跡如何隨著編碼功能（例如臨床代碼、程序和藥物購買）在全國縱向資料集中演變。我們引入一種直接的方法，用於訓練 Transformer 為基礎的深度學習模型，讓我們分析個人軌跡如何隨著時間推移而改變。這是透過修改訓練目標並應用因果注意力遮罩來實現的。我們在此專注於預測在給定未來預測區間內一系列常見疾病發病的一般任務。然而，我們的做法並非提供關於可能在此預測區間內發生的診斷的單一預測，而是讓模型能夠在每個時間點提供連續預測，直到預測期間的時間，並以其為條件。我們發現此模型的表現與其他模型（包括雙向 Transformer 模型）相當，在基本預測效能方面如此，同時提供有希望的軌跡建模屬性。我們探索了幾種使用此模型分析健康軌跡並協助早期偵測預測可能後續發病事件的方法。我們假設此方法可能有助於持續監測個人健康軌跡，並讓干預措施得以在持續的健康軌跡中進行，且在回顧性分析中也很有用。

##### **Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**
2412.08737v1 by Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger

Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.

摘要：近幾年，多模態大型語言模型 (MLLM) 迅速進展，但仍持續與低階視覺感知 (LLVP) 奮戰，尤其是準確描述影像幾何細節的能力。此功能對於機器人、醫學影像分析和製造等領域的應用至關重要。在本文中，我們首先介紹 Geoperception，一個基準，旨在評估 MLLM 從影像準確轉錄 2D 幾何資訊的能力。使用此基準，我們展示了領先 MLLM 的限制，然後進行全面的實證研究，探討改善其在幾何任務上表現的策略。我們的研究結果突出了特定模型架構、訓練技術和資料策略的優點，包括使用高保真合成資料和具有資料課程的多階段訓練。值得注意的是，我們發現資料課程能讓模型學習他們無法從頭開始學習的具有挑戰性的幾何理解任務。利用這些見解，我們開發了 Euclid，一個專門針對強低階幾何感知而最佳化的模型家族。儘管純粹在合成多模態資料上訓練，但 Euclid 對新幾何形狀展現出強大的泛化能力。例如，Euclid 在某些 Geoperception 基準任務上比最佳閉源模型 Gemini-1.5-Pro 高出 58.56%，在所有任務上的平均表現高出 10.65%。

##### **Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**
2412.09651v1 by Elena Cardillo, Lucilla Frattura

Coding morbidity data using international standard diagnostic classifications
is increasingly important and still challenging. Clinical coders and physicians
assign codes to patient episodes based on their interpretation of case notes or
electronic patient records. Therefore, accurate coding relies on the legibility
of case notes and the coders' understanding of medical terminology. During the
last ten years, many studies have shown poor reproducibility of clinical
coding, even recently, with the application of Artificial Intelligence-based
models. Given this context, the paper aims to present the SISCO.web approach
designed to support physicians in filling in Hospital Discharge Records with
proper diagnoses and procedures codes using the International Classification of
Diseases (9th and 10th), and, above all, in identifying the main pathological
condition. The web service leverages NLP algorithms, specific coding rules, as
well as ad hoc decision trees to identify the main condition, showing promising
results in providing accurate ICD coding suggestions.

摘要：使用國際標準診斷分類對病態資料進行編碼越來越重要，但仍具有挑戰性。臨床編碼員和醫師根據他們對病例記錄或電子病歷的解讀，為患者就診情況分配代碼。因此，準確編碼依賴於病例記錄的可讀性和編碼員對醫學術語的理解。在過去十年中，許多研究表明臨床編碼的可再現性很差，即使在最近，人工智能模型的應用也是如此。鑑於這種情況，本文旨在介紹 SISCO.web 方法，該方法旨在支援醫師使用國際疾病分類 (第 9 版和第 10 版) 填寫出院記錄，並正確診斷和編碼程序，最重要的是，找出主要的病理狀況。網路服務利用 NLP 演算法、特定的編碼規則以及特別決策樹來找出主要狀況，在提供準確的 ICD 編碼建議方面顯示出有希望的結果。

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

摘要：<paragraph>公共衛生從業人員通常有監控患者和最大化患者處於「有利」或健康狀態的時間的目標，同時受到有限資源的限制。不安分的多臂強盜 (RMAB) 是解決此問題的有效模型，因為它們有助於在資源限制下，在許多代理之間分配有限的資源，其中患者的行為取決於是否對其進行干預。然而，RMAB 假設已知回報函數。這在許多公共衛生環境中是不切實際的，因為患者面臨獨特的挑戰，而且對於如此大規模的干預，人類不可能知道誰最需要干預。為了解決這個缺點，本文首次提出使用逆向強化學習 (IRL) 來學習 RMAB 的期望回報，並且我們在母嬰健康遠距醫療計畫中展示了改善的結果。首先，我們允許公共衛生專家在總體或人口層級指定他們的目標，並提出一個演算法來根據這些目標大規模設計專家軌跡。其次，我們的演算法 WHIRL 使用梯度更新來最佳化目標，允許有效且準確地學習 RMAB 回報。第三，我們與現有的基準進行比較，並在執行時間和準確性方面優於這些基準。最後，我們評估並展示了 WHIRL 在印度實際母嬰健康環境中對數千名受益者的有用性。我們在此公開發布我們的程式碼：https://github.com/Gjain234/WHIRL。</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

摘要：我們提出 SmolTulu-1.7b-Instruct，本報告中稱為 SmolTulu-DPO-1130，這是一種指令調整語言模型，採用 AllenAI 的 Tulu 3 後訓練管道來增強 Huggingface 的 SmolLM2-1.7B 基礎模型。透過使用 135M 參數模型的全面經驗分析，我們證明學習率與批次大小之間的關係會以任務相關的方式顯著影響模型效能。我們的發現揭示了一個明確的分歧：像 ARC 和 GSM8K 等推理任務受益於較高的學習率對批次大小的比率，而像 HellaSwag 和 IFEval 等模式辨識任務則顯示出較低比率的最佳效能。這些見解為 SmolTulu 的開發提供了資訊，在小於 2B 參數模型中，在指令遵循方面取得了最先進的表現，在 IFEval 上得分 67.7%（Δ11%），在 GSM8K 上的數學推理得分為 51.6%（Δ3.4%），而另一個版本在 ARC 上得分 57.1%（Δ5.4%）。我們發布我們的模型、訓練範例和消融研究，以促進高效模型對齊的進一步研究，證明仔細調整最佳化動態可以幫助縮小小型和大型語言模型之間的能力差距。

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by Célia Blondin, Joris Guérin, Kelly Inagaki, Guilherme Longo, Laure Berti-Équille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

摘要：自動化底棲影像註解對於有效監測和保護珊瑚礁免受氣候變遷影響至關重要。目前的機器學習方法無法捕捉覆蓋礁石基質的底棲生物的階層性質，例如珊瑚分類等級和健康狀況。為了解決此限制，我們建議使用階層分類註解底棲影像。對來自巴西東北部珊瑚礁的自訂資料集進行的實驗顯示，我們的做法優於平面分類器，在不同數量的訓練資料中將 F1 和階層 F1 分數都提高了大約 2%。此外，這種階層式方法與生態目標更為一致。

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

摘要：醫學影像的自動化分割高度依賴於準確的手動影像標註。此類標註非常耗時且生成成本高昂，且通常需要專業知識，特別是對於每個患者包含許多切片的橫斷面影像。確保最佳利用標註資源至關重要。在本文中，我們系統性地回答了如何選擇橫斷面醫學影像切片以最大化深度學習分割模型效能的問題。我們針對 4 項醫學影像分割任務進行了實驗，這些任務具有不同的標註預算、標註案例數、每個體積的標註切片數、切片選擇技術和遮罩內插。我們發現：
1) 在給定標註預算的情況下，幾乎總是優先標註每個體積較少切片和更多體積。2) 透過非監督主動學習 (UAL) 選擇切片進行標註並不優於隨機或固定間隔選擇切片，前提是每個體積分配的標註切片數相同。3) 在標註切片之間內插遮罩很少能提升模型效能，但某些 3D 模型的特定組態除外。

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

摘要：自我監督學習有潛力解決當今強化學習中的幾個關鍵挑戰，例如探索、表徵學習和獎勵設計。最近的研究（METRA）有效地論證了遠離互信息並改為優化某個 Wasserstein 距離對於良好的性能很重要。在本文中，我們論證該論文中看到的優點可以在互信息技能學習（MISL）的現有框架內得到很大程度的解釋。我們的分析提出了一種新的 MISL 方法（對比後繼特徵），它保留了 METRA 的出色性能，同時減少了活動部件，並突出了技能學習、對比表徵學習和後繼特徵之間的聯繫。最後，通過仔細的消融研究，我們進一步深入了解了我們的方法和 METRA 的一些關鍵要素。

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v2 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

摘要：近期 AI 對話代理的普及提升，導致其在提升生產力和支持幸福感方面的應用日益增加。雖然先前的研究旨在了解與 AI 對話代理互動相關的風險，但這些研究往往無法捕捉到生活體驗。此外，在過去的分類工作中，心理風險通常被視為更廣泛的 AI 相關風險中的子類別，導致 AI 使用心理風險的影響被低估。為了應對這些挑戰，我們的研究提出了新穎的風險分類法，重點關注透過個人生活經驗收集的 AI 使用心理風險。我們採用混合方法，包括對 283 位具有生活心理健康經驗的個人進行全面調查，以及與生活經驗專家合作的研討會，以制定心理風險分類法。我們的分類法包含 19 種 AI 行為、21 種負面心理影響和 15 種與個人相關的背景。此外，我們提出了一個新穎的多路徑小插圖框架，用於了解 AI 行為、心理影響和個人使用者背景之間的複雜交互作用。最後，根據從研討會中獲得的回饋，我們提出了設計建議，以開發更安全、更強大的 AI 代理。我們的研究深入了解了與 AI 對話代理相關的心理風險，並為政策制定者、研究人員和開發人員提供了可行的建議。

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

摘要：基於觀察資料對序貫臨床決策制定建模政策，有助於描述治療實務、標準化治療中的常見模式，以及評估替代政策。對於每項任務，政策模型的可解釋性至關重要。學習精確的模型需要有效擷取患者的狀態，無論是透過序列表徵學習或精心製作的病史摘要。雖然近期研究偏好前者，但如何以最佳方式表徵病史以進行可解釋的政策建模，仍是一個問題。我們專注於模型擬合度，系統性地比較各種摘要患者病史的方法，以針對四項序貫決策制定任務進行可解釋的臨床政策建模。我們透過按患者子群、危急狀態和治療階段細分評估，來說明使用各種表徵所學習到的政策之間的差異，並強調特定於常見使用案例的挑戰。我們發現，使用學習表徵的可解釋序列模型在所有任務中表現與黑箱模型不相上下。使用手工製作表徵的可解釋模型在完全忽略病史時表現明顯較差，但透過僅納入少數患者病史的彙整和近期元素，便能使其具有競爭力。使用更豐富表徵的額外好處在子群和特定使用案例中顯著。這強調了在預期用途的脈絡中評估政策模型的重要性。

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v2 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

摘要：人工智慧對社會影響（AI4SI）提供了巨大的潛力，用於解決複雜的社會挑戰，例如公共衛生、農業、教育、保育和公共安全。然而，現有的 AI4SI 研究通常需要大量人力和資源，這限制了其可及性和可擴展性；標準方法是設計一個針對特定 AI4SI 問題量身打造的（基礎層級）系統。我們建議開發一個新穎的元層級多代理系統，旨在加速此類基礎層級系統的開發，從而降低運算成本和社會影響領域專家與 AI 研究人員的負擔。透過運用基礎模型和大型語言模型的進展，我們建議的方法專注於資源配置問題，提供從問題建構、解決方案設計到影響評估的完整 AI4SI 管線的協助。我們強調部署此類系統時固有的道德考量和挑戰，並強調人機協作方法的重要性，以確保負責任且有效地應用 AI 系統。

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

摘要：有害腦部活動的分類，例如癲癇發作和週期性放電，在神經重症照護中扮演著至關重要的角色，能及時診斷和介入。腦電圖 (EEG) 提供了一種非侵入式的方法來監測腦部活動，但 EEG 訊號的手動判讀耗時且高度依賴專家的判斷。本研究針對深度學習架構進行比較分析，包括卷積神經網路 (CNN)、視覺Transformer (ViT) 和 EEGNet，運用於有害腦部活動的分類，同時使用原始 EEG 資料和透過連續小波轉換 (CWT) 生成的時頻表示。我們評估這些模型使用多模式資料表示的效能，包括高解析度頻譜圖和波形資料，並引入多階段訓練策略來改善模型的穩健性。我們的結果顯示，訓練策略、資料前處理和擴充技術對於模型的成功與架構選擇一樣重要，其中多階段 TinyViT 和 EfficientNet 表現出優異的效能。這些發現強調了穩健訓練機制對於達成準確且有效率的 EEG 分類的重要性，為在臨床實務中部署 AI 模型提供了寶貴的見解。

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

摘要：人類健康越來越受到接觸有害物質的威脅，尤其是持久性和有毒的化學物質。科學研究已證明這些物質（通常存在於複雜的混合物中）與各種疾病之間的關聯。然而，這些資訊分散在多個來源中，人類和機器都很難取得。本文評估了當前發布/取得有關有害化學物質資訊的慣例，並提出一個新穎的平台，旨在促進在緊急情況下取得關鍵化學資料。此平台匯集來自多個來源的資訊，並將其組織成結構化的知識圖譜。使用者可以透過視覺化介面（例如 Neo4J Bloom 和儀表板）或使用聊天機器人的自然語言查詢來取得這些資訊。我們的研究結果表明，當資料集遵循 FAIR 原則時，取得重要化學資訊所需的時間和精力會大幅減少。此外，我們討論從此平台的開發和實作中學到的經驗教訓，並為資料擁有者和發布者提供建議，以增強資料再利用和互操作性。這項工作旨在改善醫療保健專業人員取得和使用化學資訊的方式，從而支持更好的健康結果，並在面對接觸化學中毒風險的患者時做出明智的決策。

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多 NLP 任務上表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，
利用檢索增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，
能穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：
非平穩環境的持續演變可能導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。
為了應對這些挑戰，我們引入了多目標多臂老虎機增強的 RAG 框架，
並在實務中採用具備多元能力的各種檢索方法，以應對豐富且不斷演變的檢索情境。
在此框架中，每個檢索方法都被視為一個不同的「手臂」。
該系統利用即時使用者回饋來適應動態環境，
根據輸入查詢和每個手臂的歷史多目標效能來選擇適當的檢索方法。
在兩個基準 KGQA 資料集上進行的廣泛實驗表明，
我們的模型在非平穩設定中顯著優於基線模型，同時在平穩環境中達到最先進的效能。
程式碼和資料可於 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

摘要：<paragraph>建模使用者偏好主要透過觀察使用者與系統中不同元素的互動記錄。
根據歷史資料調整個人偏好的內容是連續推薦的主要目標。
問題的本質，以及在各個領域觀察到的良好效能，激勵了Transformer架構的使用，在增加模型參數數量時，已證明能有效利用越來越多訓練資料。這種規模行為引起了極大的關注，因為它在設計和訓練更大模型時提供了有價值的指導。
從訓練大型語言模型中觀察到的規模法則中汲取靈感，我們探討了連續推薦的類似原則。
我們使用了完整的 Amazon 產品資料集，其他研究僅部分探討過，並揭示了與在語言模型中發現的類似的規模行為。計算最佳訓練是可能的，但需要仔細分析特定於應用程式的計算效能折衷。
我們還展示了效能規模轉化為下游任務，透過對較小的特定任務領域微調較大的預訓練模型。我們的做法和發現為模型訓練和在實際高維度偏好空間中部署提供了策略性路線圖，促進更好的訓練和推理效率。
我們希望這篇論文能彌合Transformer潛力與實際推薦系統中高維度連續推薦的內在複雜性之間的差距。
程式碼和模型可以在 https://github.com/mercadolibre/srt 找到</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

摘要：以語音對話為最佳化的人工智慧系統正快速出現。此類模型在醫療保健方面很有趣，因為這些聲控助理可以支援長者並能進行遠距健康監控。然而，效能的瓶頸在於這些裝置在實際運作上的表現如何，以及長者如何體驗它們，但這方面的研究卻很稀少。我們回顧了長者使用聲控人工智慧的狀況，並重點說明各種以使用者和技術為中心的議題，在能實現有效的聲控人工智慧以進行長者照護之前，這些議題都需要加以考量。

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

摘要：磁振造影 (MRI) 對於診斷和規劃各種醫療狀況的治療至關重要，因為它能夠產生揭示不同組織特徵的多系列影像。然而，整合這些不同的系列以形成連貫的分析會帶來重大的挑戰，例如不同的空間解析度和對比模式，同時需要大量的註解資料，但在臨床實務中卻很稀少。由於這些問題，我們引入了一種新穎的跨系列遮罩 (CSM) 策略，以便以自我監督的方式有效地學習 MRI 表徵。具體來說，CSM 從隨機抽樣區域和系列的子集開始，然後對其進行策略性遮罩。在訓練過程中，跨系列表徵是透過利用未遮罩的資料來重建遮罩部分而學習的。這個過程不僅整合了不同系列的資訊，還促進了對系列內和系列間關聯性和互補性的建模能力。透過學習到的表徵，下游任務（例如分割和分類）也會得到增強。以腦組織分割、乳房腫瘤良性/惡性分類和前列腺癌診斷為例，我們的模型在公開資料集和內部資料集上都達到了最先進的效能。

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

摘要：利害關係人（從模型開發人員到政策制定者）尋求將大型語言模型 (LLM) 的雙重使用風險降至最低。對此目標的公開挑戰在於，技術保障措施是否能阻止 LLM 的濫用，即使模型可通過微調進行自訂，或模型權重完全開放時亦然。為了解決此問題，最近有幾項研究提出方法，以產生適用於開放權重 LLM 的耐用 LLM 保障措施，這些保障措施能承受透過微調對模型權重進行的對抗性修改。這有望提高對手的成本，即使在對手可以直接微調模型權重的強威脅模型下亦然。然而，在本文中，我們敦促更仔細地描述這些方法的限制。透過多項案例研究，我們證明即使評估這些防禦措施也極其困難，並且很容易誤導受眾，讓他們認為保障措施比實際上更耐用。我們從我們辨識出的評估陷阱中汲取教訓，並建議未來的研究謹慎地將主張限制在更受限、定義明確且經過嚴格審查的威脅模型中，這可以為利害關係人提供更有用且坦率的評估。

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

摘要：我們提出了一種使用 AI 來建模和模擬生物學和生命的方法。
為什麼這很重要？因為在醫學、藥學、公共衛生、
長壽、農業和食品安全、環境保護和清潔
能源的核心，都是生物學在運作。物理世界中的生物學太過複雜，
難以操作，而且總是昂貴且有風險。從這個角度來看，
我們制定了一種可行的工程方法來解決這個挑戰，方法是
構建一個 AI 驅動的數位生物體 (AIDO)，一個整合的
多尺度基礎模型系統，以模組化、可連接和整體的方式
來反映生物尺度、連通性和複雜性。AIDO 開啟了一個安全、
負擔得起且高通量的替代平台，用於預測、
模擬和編程從分子到細胞到個體的所有層級的生物學。我們預計 AIDO 將引發一波
由更佳指導的濕式實驗和更完善的第一原理
推理的新浪潮，最終可以幫助我們更好地解碼和改善生命。

##### **Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**
2412.07806v1 by Venkat Margapuri

Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads
to ulcers along the large intestine and rectum. The increase in the prevalence
of UC coupled with gastrointestinal physician shortages stresses the healthcare
system and limits the care UC patients receive. A colonoscopy is performed to
diagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).
The MES ranges between zero and three, wherein zero indicates no inflammation
and three indicates that the inflammation is markedly high. Artificial
Intelligence (AI)-based neural network models, such as convolutional neural
networks (CNNs) are capable of analyzing colonoscopies to diagnose and
determine the severity of UC by modeling colonoscopy analysis as a multi-class
classification problem. Prior research for AI-based UC diagnosis relies on
supervised learning approaches that require large annotated datasets to train
the CNNs. However, creating such datasets necessitates that domain experts
invest a significant amount of time, rendering the process expensive and
challenging. To address the challenge, this research employs self-supervised
learning (SSL) frameworks that can efficiently train on unannotated datasets to
analyze colonoscopies and, aid in diagnosing UC and its severity. A comparative
analysis with supervised learning models shows that SSL frameworks, such as
SwAV and SparK outperform supervised learning models on the LIMUC dataset, the
largest publicly available annotated dataset of colonoscopy images for UC.

摘要：潰瘍性結腸炎 (UC) 是一種無法治癒的發炎性腸道疾病，會導致大腸和直腸潰瘍。UC 的患病率增加，加上腸胃科醫師短缺，對醫療保健系統造成壓力，並限制 UC 患者接受的照護。進行大腸鏡檢查以診斷 UC 並根據 Mayo 內視鏡評分 (MES) 評估其嚴重程度。MES 的範圍在 0 到 3 之間，其中 0 表示沒有發炎，而 3 表示發炎程度顯著。基於人工智慧 (AI) 的神經網路模型，例如卷積神經網路 (CNN)，能夠分析大腸鏡檢查以診斷和確定 UC 的嚴重程度，方法是將大腸鏡檢查分析建模為多類別分類問題。先前針對基於 AI 的 UC 診斷的研究依賴於監督式學習方法，需要大量標註的資料集來訓練 CNN。然而，建立此類資料集需要領域專家投入大量時間，使這個過程既昂貴又具有挑戰性。為了應對這個挑戰，本研究採用自我監督學習 (SSL) 框架，可以在未標註的資料集上進行有效率的訓練，以分析大腸鏡檢查並協助診斷 UC 及其嚴重程度。與監督式學習模型的比較分析顯示，SSL 框架（例如 SwAV 和 SparK）在 LIMUC 資料集（最大的公開 UC 大腸鏡檢查影像標註資料集）上優於監督式學習模型。

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

摘要：Bankart 病灶，或前下盂唇撕裂，由於其影像特徵微妙，在標準核磁共振成像中診斷具有挑戰性，通常需要侵入性核磁共振血管造影 (MRA)。本研究開發深度學習 (DL) 模型，用於在標準核磁共振成像和核磁共振血管造影中檢測 Bankart 病灶，旨在提高診斷準確性並減少對核磁共振血管造影的依賴。我們從 558 名接受關節鏡檢查的患者中策劃了一組 586 例肩部核磁共振成像 (335 例標準，251 例核磁共振血管造影) 的數據集。基本事實標籤來自術中發現，這是 Bankart 病灶診斷的黃金標準。使用 Swin Transformer 架構訓練了核磁共振血管造影和標準核磁共振成像的單獨深度學習模型，並在公開的膝部核磁共振成像數據集上進行預訓練。矢狀面、軸面和冠狀面的預測結果被組合起來以優化性能。這些模型在 20% 的保留測試集（117 例核磁共振成像：46 例核磁共振血管造影，71 例標準核磁共振成像）上進行了評估。在 31.9% 的核磁共振血管造影和 8.6% 的標準核磁共振成像中發現了 Bankart 病灶。這些模型在標準核磁共振成像和核磁共振血管造影中的 AUC 分別達到 0.87（86% 準確度，83% 靈敏度，86% 特異度）和 0.90（85% 準確度，82% 靈敏度，86% 特異度）。這些結果與放射科醫生對我們數據集的表現相匹配或超過，並超過了報告的文獻指標。值得注意的是，我們的模型在非侵入性標準核磁共振成像中的表現與放射科醫生對核磁共振血管造影的解釋相匹配或超過。本研究證明了使用深度學習來解決 Bankart 病灶等微妙病理診斷挑戰的可行性。我們的模型展示了提高診斷信心、減少對侵入性影像檢查的依賴以及增強獲得照護的機會的潛力。

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

摘要：深度學習在醫療保健領域擁有巨大的潛力，可用於發掘廣泛臨床資料集中的隱藏模式，協助診斷各種疾病。帕金森氏症 (PD) 是一種神經退化性疾病，其特徵是大腦功能惡化。在 PD 的初期階段，由於 PD 患者與健康者的行為相似，因此自動診斷具有挑戰性。我們的目標是提出一個有效的模型，可以幫助早期檢測帕金森氏症。我們採用了來自 Physionet 的 VGRF 步態信號資料集，用於區分健康個體和被診斷出患有帕金森氏症的個體。本文介紹了一種基於 LSTM 網路的深度學習新架構，用於自動檢測帕金森氏症患者的步態凍結發作。與傳統機器學習演算法相比，此方法消除了手動特徵工程，並熟練地捕捉步態模式中的長時間依賴性，從而改進了帕金森氏症的診斷。LSTM 網路通過使用記憶區塊代替自連接隱藏單元來解決梯度消失問題，從而實現最佳資訊同化。為了防止過度擬合，已採用中斷和 L2 正則化技術。此外，隨機梯度優化器 Adam 用於優化過程。結果表明，我們提出的方法在 FOG 發作檢測方面超越了當前最先進的模型，達到了 97.71% 的準確率、99% 的靈敏度、98% 的精確度和 96% 的特異性。這證明了其作為帕金森氏症檢測的優越分類方法的潛力。

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

摘要：及時地偵測和治療對於維持眼睛健康至關重要。
視力（VA），用於測量遠距離視覺的清晰度，是維持眼睛健康的關鍵指標。機器學習（ML）技術已被引入以協助 VA 測量，潛在地減輕臨床醫師的工作負擔。然而，ML 模型中固有的不確定性使得僅依賴它們進行 VA 預測並非理想。VA 預測任務涉及多種不確定性來源，需要更強大的方法。一種有前途的方法是建立預測集合或區間，而不是點估計，通過像共形預測和大概正確（PAC）預測集合這樣的技術提供覆蓋率保證。儘管有潛力，但迄今為止，這些方法尚未應用於 VA 預測任務。為了解決這個問題，我們提出了一種從眼底圖像估計視力的預測區間的方法，並提供 PAC 保證。我們的實驗結果表明，PAC 保證得到維持，其性能與不提供此類保證的兩項先前工作的性能相當或更好。

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

摘要：旅遊產業快速成長，提升了預訂系統中即時最佳化的需求，這個系統可以處理龐大的資料和交易量。本研究提出一個混合架構，它結合人工智慧和微服務方法來最佳化系統效能。人工智慧演算法預測需求模式，最佳化資源配置，並加強由微服務架構驅動的決策制定，因此分散系統元件以利於擴充性、容錯能力和減少停機時間。所提供的模型專注於與旅遊預訂系統相關的主要問題，例如系統延遲、負載平衡和資料一致性。它賦予系統預測模型，基於人工智慧提升預測使用者需求的能力。微服務也會在流量模式不均時處理不同的規模。因此，這兩個面向確保能更好地處理尖峰負載和流量激增，同時將延遲降到最低並確保高服務品質。比較傳統的預訂模型（單體式）和新的 AI-微服務模型。比較之下，分析結果指出處理時間有顯著改善，其中系統正常運行時間和資源使用率證明了人工智慧和微服務在預訂方面轉型旅遊產業的能力。這項研究工作專注於人工智慧和微服務，以實現即時最佳化，提供關鍵見解，說明如何透過實用建議，使用這項技術升級旅遊預訂系統。

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v2 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

摘要：在傳統醫學中，音樂療法已被證實能有效治療各種心理和生理疾病。特別是在東方傳統中，根植於中醫的五行音樂療法 (FEMT) 具有深遠的文化意義和獨特的治療理念。隨著資訊科技和人工智慧的快速發展，將這些現代技術應用於 FEMT 可以增強療法的個人化和文化相關性，並有可能改善治療效果。在本文中，我們首次通過將音樂療法中的五行理論應用於實踐，開發了一個音樂療法系統。這種創新方法將先進的資訊科技和人工智慧與五行音樂療法 (FEMT) 相結合，以增強個性化的音樂療法實務。由於傳統音樂療法主要遵循西方方法，因此應考慮東方實務的獨特方面，特別是中醫的五行理論。此系統旨在利用計算技術彌合這一差距，以提供更個人化、文化相關且治療效果更好的音樂療法體驗。

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

摘要：肝包蟲病（HE）在經濟落後的畜牧地區盛行，那裡通常缺乏足夠的醫療資源。現有方法通常忽略多尺度特徵融合，或僅關注相鄰層之間的特徵融合，這可能導致特徵融合不足。為了解決這些問題，我們提出了 HES-UNet，這是一種用於 HE 病灶分割的高效且準確的模型。此模型結合了卷積層和注意力模組，以擷取局部和全局特徵。在降採樣過程中，採用多向降採樣區塊 (MDB) 來整合高頻和低頻特徵，有效提取影像細節。多尺度聚合區塊 (MAB) 聚合多尺度特徵資訊。相反，多尺度上採樣區塊 (MUB) 會學習高度抽象的特徵，並將此資訊提供給跳躍連接模組，以融合多尺度特徵。由於 HE 的區域特徵不同，目前沒有公開可用的高品質資料集可供訓練我們的模型。我們從某家醫院收集了 268 位患者的 CT 切片資料，以訓練和評估模型。實驗結果表明，HES-UNet 在我們的資料集上達到了最先進的效能，整體 Dice 相似性係數 (DSC) 達到 89.21%，比 TransUNet 高 1.09%。專案頁面可於 https://chenjiayan-qhu.github.io/HES-UNet-page 取得。

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

摘要：現有的任務導向 AI 代理通常依賴明確的指示或外部獎勵，這限制了它們像人類一樣由內在動機驅動的能力。在本文中，我們提出了一個慾望驅動的自主框架，以指導基於大型語言模型 (LLM) 的代理模擬類人的日常活動。與之前的代理不同，我們的慾望驅動自主代理 (D2A) 遵循內在慾望的原則，允許它自主提出和選擇符合其動機框架的任務。受需求理論的啟發，動機框架包含對類人慾望的理解，例如社會互動、個人滿足和自我保健的需要。利用慾望驅動任務生成機制，代理評估其當前狀態並採取一系列與其內在動機一致的活動。通過模擬，我們證明了我們的慾望驅動自主代理 (D2A) 產生了連貫、與上下文相關的日常活動，同時表現出與人類行為相似的可變性和適應性。與其他基於 LLM 的框架進行比較分析表明，我們的做法顯著提高了模擬活動的合理性。

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

摘要：自 2019 年 COVID-19 大流行爆发以来，医学影像已成为诊断 COVID-19 肺炎的主要方式。在临床环境中，从计算机断层扫描图像中分割肺部感染，可以快速、准确地量化和诊断 COVID-19。分割肺部中的 COVID-19 感染是一个艰巨的挑战，这主要是由于毛玻璃样变现出的边界不清晰且对比度有限。此外，浸润、肺组织和肺壁之间的混淆相似性进一步复杂化了这项分割任务。为了应对这些挑战，本文介绍了一种新颖的深度网络架构，称为 CAD-Unet，用于分割 COVID-19 肺部感染。在此架构中，胶囊网络被纳入现有的 Unet 框架中。胶囊网络代表了一种新颖的网络架构，它不同于传统的卷积神经网络。它们利用向量在胶囊之间进行信息传输，促进了复杂病变空间信息的提取。此外，我们设计了一个胶囊编码器路径，并在 unet 编码器和胶囊编码器之间建立了一个耦合路径。这种设计最大限度地发挥了两种网络结构的互补优势，同时实现了高效的信息融合。\noindent
最后，在四个公开可用的数据集上进行了广泛的实验，包括二进制分割任务和多类分割任务。实验结果证明了所提出模型的卓越分割性能。该代码已发布在：
https://github.com/AmanoTooko-jie/CAD-Unet。

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

摘要：近年來，先進的 U 型網路在醫學影像分割任務中展現出卓越的表現。然而，它們的缺點包括過多的參數、高運算複雜度和緩慢的推論速度，對在運算資源有限的情況下實際執行構成挑戰。現有的輕量級 U 型網路已經減輕了這些問題，但它們通常有預先設計的結構，並包含不可分離的模組，限制了它們的應用場景。在本文中，我們透過採用神經記憶常微分方程式 (nmODE) 的不同離散化方法，提出了三個即插即用的解碼器。這些解碼器透過處理來自跳躍連接的資訊，並在向上路徑上執行數值運算，整合了不同抽象層級的特徵。透過在 PH2、ISIC2017 和 ISIC2018 資料集上的實驗，我們將這些解碼器嵌入到不同的 U 型網路中，證明它們在顯著減少參數和 FLOP 的同時，還能維持效能。總之，所提出的離散 nmODE 解碼器能夠將參數數量減少約 20% ~ 50%，FLOP 最多減少 74%，同時具備適應所有 U 型網路的潛力。我們的程式碼可以在 https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks 取得。

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

摘要：裂縫偵測在結構健康監測中是一項重要的任務，旨在評估橋樑、建築物和道路的結構完整性，以防止潛在的故障。基於視覺的裂縫偵測由於其易於實作和有效性，已成為主流方法。將紅外線 (IR) 通道與紅色、綠色和藍色 (RGB) 通道融合可以增強特徵表示，進而改善裂縫偵測。然而，IR 和 RGB 通道通常解析度不同。為了對齊它們，通常需要對較高解析度的 RGB 影像進行降採樣以匹配 IR 影像解析度，這會導致精細細節的遺失。此外，裂縫偵測效能受到傳統影像分割網路有限的感受野和高運算複雜度的限制。受近期提出的 Mamba 神經架構啟發，本研究引入了一個稱為 MSCrackMamba 的兩階段範例，它利用 Vision Mamba 和超解析度網路來應對這些挑戰。具體來說，為了對齊 IR 和 RGB 通道，我們首先對 IR 通道應用超解析度，以匹配 RGB 通道的解析度，以進行資料融合。然後採用 Vision Mamba 作為骨幹網路，同時採用 UperNet 作為裂縫偵測的解碼器。我們的做法已在大型裂縫偵測資料集 Crack900 中得到驗證，與效能最佳的基準方法相比，mIoU 提升了 3.55%。

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

摘要：點擊率 (CTR) 預測在線上廣告中至關重要，其中語意資訊在塑造使用者決策和提升 CTR 效益方面扮演著關鍵角色。擷取和建模深入的語意資訊（例如使用者偏好「H\"aagen-Dazs' HEAVEN 草莓輕盈冰淇淋」，因為它具有注重健康和高級的屬性）是一項挑戰。傳統的語意建模通常會忽略使用者和項目層級的這些複雜細節。為了彌補此差距，我們提出了一種創新的方法，該方法可以端對端地建模深入語意資訊，並利用大型語言模型 (LLM) 的全面世界知識能力。我們提出的 LLM 注入 CTR 預測架構（透過知識萃取的多層級深入語意資訊注入 CTR 模型，MSD）旨在透過利用 LLM 萃取和提煉關鍵資訊到一個更小、更有效率的模型中，來發掘深入的語意洞察，實現無縫端對端訓練和推論。重要的是，我們的架構經過仔細設計，以平衡效率和效能，確保模型不僅能達成高性能，還能以最佳資源利用率運作。在美團贊助搜尋系統上進行的線上 A/B 測試證明，我們的模型在每千次成本 (CPM) 和 CTR 方面顯著優於基線模型，驗證了其在實際應用中的有效性、可擴充性和平衡方法。

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

摘要：大型視覺語言模型 (LVLMs) 的進步推動了它們在醫療領域的應用。然而，醫學 LVLMs (Med-LVLMs) 由於模態錯位而遇到事實挑戰，其中模型優先考慮文字知識而非視覺輸入，導致幻覺與醫學影像中的資訊相矛盾。先前嘗試透過偏好最佳化來增強 Med-LVLMs 中的模態對齊，在偏好資料中不足以減輕臨床相關性，使得這些範例容易區分，並降低對齊效果。為了應對這項挑戰，我們提出 MMedPO，一種新的多模態醫學偏好最佳化方法，它考慮偏好範例的臨床相關性，以增強 Med-LVLM 對齊。MMedPO 透過引入兩種類型的反偏好來管理多模態偏好資料：(1) 合理的幻覺透過目標 Med-LVLMs 或 GPT-4o 注入，以產生醫學上不準確的回應，以及 (2) 透過局部病灶雜訊實現病灶區域忽略，破壞對關鍵區域的視覺理解。然後，我們根據來自多個 Med-LLMs 和視覺工具的分數計算每個範例的臨床相關性，並將這些分數作為權重整合到偏好最佳化過程中，以實現有效對齊。我們的實驗證明，MMedPO 明顯增強了 Med-LVLMs 中的事實準確性，在 Med-VQA 和報告生成任務中，平均分別比現有的偏好最佳化方法提高了 14.2% 和 51.7%。我們的程式碼可以在 https://github.com/aiming-lab/MMedPO 中取得。

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

摘要：縱向被動感測研究對於健康和行為結果常常有缺失和不完整的資料。有效處理缺失資料因此是資料處理和建模的重要步驟。我們與從事縱向健康和行為被動感測的研究人員進行的形成性訪談揭露了一個反覆出現的主題：大多數研究人員認為內插是其分析和推論流程中優先順序較低的一個步驟，選擇使用簡單且現成的內插策略，而沒有全面評估其對研究結果的影響。透過這篇論文，我們呼籲重視內插。使用公開的被動感測資料集進行憂鬱症研究，我們證明優先考慮內插會對研究結果產生重大影響——我們提出的內插策略使 AUROC 預測憂鬱症的能力比原始內插策略提高了 31%。最後，我們討論了在縱向感測研究中有效內插的挑戰和機會。

##### **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**
2412.05876v1 by Xuefeng Ni, Linshan Wu, Jiaxin Zhuang, Qiong Wang, Mingxiang Wu, Varut Vardhanabhuti, Lihai Zhang, Hanyu Gao, Hao Chen

3D medical image analysis is pivotal in numerous clinical applications.
However, the scarcity of labeled data and limited generalization capabilities
hinder the advancement of AI-empowered models. Radiology reports are easily
accessible and can serve as weakly-supervised signals. However, large-scale
vision-language pre-training (VLP) remains underexplored in 3D medical image
analysis. Specifically, the insufficient investigation into multi-grained
radiology semantics and their correlations across patients leads to
underutilization of large-scale volume-report data.
  Considering intra-patient cross-modal semantic consistency and inter-patient
semantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained
on large-scale data (47.1K), addressing the challenges by the following two
aspects: 1) Establishing the correspondence between volume semantics and
multi-grained medical knowledge of each patient with cross-modal global
alignment and complementary modality-guided local reconstruction, ensuring
intra-patient features of different modalities cohesively represent the same
semantic content; 2) Correlating inter-patient visual semantics based on
fine-grained report correlations across patients, and keeping sensitivity to
global individual differences via contrastive learning, enhancing the
discriminative feature representation. Furthermore, we delve into the scaling
law to explore potential performance improvements. Comprehensive evaluations
across nine uni- and cross-modal clinical tasks are carried out to assess model
efficacy. Extensive experiments on both internal and external datasets
demonstrate the superior transferability, scalability, and generalization of
MG-3D, showcasing its potential in advancing feature representation for 3D
medical image analysis. Code will be available:
https://github.com/Xuefeng-Ni/MG-3D.

摘要：<paragraph>3D 醫學影像分析在眾多臨床應用中至關重要。
然而，標記資料的稀缺和有限的概化能力
阻礙了 AI 賦能模型的進步。放射報告容易獲得，可以用作弱監督信號。然而，大規模
視覺語言預訓練 (VLP) 在 3D 醫學影像
分析中仍未得到充分探索。具體來說，對多粒度
放射語義及其在患者之間的相關性研究不足，導致大規模體積報告數據利用不足。
考慮到患者內部跨模態語義一致性和患者間
語義相關性，我們提出了一種多任務 VLP 方法 MG-3D，預訓練
在大型數據 (47.1K) 上，通過以下兩個方面解決挑戰：1) 建立體積語義和
每個患者的多粒度醫學知識之間的對應關係，通過跨模態全局
對齊和互補模態引導的局部重建，確保不同模態的患者內部特徵一致地表示相同的
語義內容；2) 基於患者之間的細粒度報告相關性對患者間的視覺語義進行關聯，並通過對比學習保持對
全局個體差異的敏感性，增強判別特徵表示。此外，我們深入研究了擴展
定律以探索潛在的性能改進。跨越九項單模態和跨模態臨床任務的綜合評估是進行的，以評估模型
效能。在內部和外部數據集上的廣泛實驗
證明了 MG-3D 的卓越可傳遞性、可擴展性和泛化性，展示了其在推進 3D
醫學影像分析特徵表示方面的潛力。代碼將提供：
https://github.com/Xuefeng-Ni/MG-3D。</paragraph>

##### **Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**
2412.05852v1 by Dinesh Parthasarathy, Wayne Bradford Mitchell, Harald Köstler

Multigrid methods despite being known to be asymptotically optimal
algorithms, depend on the careful selection of their individual components for
efficiency. Also, they are mostly restricted to standard cycle types like V-,
F-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,
wherein the smoothers and their relaxation weights are chosen independently at
each step within the cycle. We call this a flexible multigrid cycle. These
flexible cycles are used in Algebraic Multigrid (AMG) methods with the help of
grammar rules and optimized using genetic programming. The flexible AMG methods
are implemented in the software library of hypre, and the programs are
optimized separately for two cases: a standalone AMG solver for a 3D
anisotropic problem and an AMG preconditioner with conjugate gradient for a
multiphysics code. We observe that the optimized flexible cycles provide higher
efficiency and better performance than the standard cycle types.

摘要：多重網格法儘管已知為漸近最佳演算法，但其效率取決於其個別組成的仔細選擇。此外，它們大多侷限於標準循環類型，例如 V、F 和 W 循環。我們使用語法規則來產生任意形狀的循環，其中平滑器及其鬆弛權重在循環中的每個步驟中獨立選擇。我們稱之為彈性多重網格循環。這些彈性循環在代數多重網格 (AMG) 方法中使用，並在語法規則的幫助下使用遺傳程式設計進行最佳化。彈性 AMG 方法在 hypre 的軟體程式庫中實作，且程式針對兩種情況分別最佳化：3D 異向性問題的獨立 AMG 求解器，以及多物理場程式碼的共軛梯度 AMG 預處理器。我們觀察到最佳化的彈性循環提供比標準循環類型更高的效率和更好的效能。

##### **Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**
2412.05632v1 by Abd Ur Rehman, Azka Rehman, Muhammad Usman, Abdullah Shahid, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Brain aging involves structural and functional changes and therefore serves
as a key biomarker for brain health. Combining structural magnetic resonance
imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the
potential to improve brain age estimation by leveraging complementary data.
However, fMRI data, being noisier than sMRI, complicates multimodal fusion.
Traditional fusion methods often introduce more noise than useful information,
which can reduce accuracy compared to using sMRI alone. In this paper, we
propose a novel multimodal framework for biological brain age estimation,
utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our
framework integrates adversarial and variational learning to effectively
disentangle the latent features from both modalities. Specifically, we
decompose the latent space into modality-specific codes and shared codes to
represent complementary and common information across modalities, respectively.
To enhance the disentanglement, we introduce cross-reconstruction and
shared-distinct distance ratio loss as regularization terms. Importantly, we
incorporate sex information into the learned latent code, enabling the model to
capture sex-specific aging patterns for brain age estimation via an integrated
regressor module. We evaluate our model using the publicly available OpenBHB
dataset, a comprehensive multi-site dataset for brain age estimation. The
results from ablation studies and comparisons with state-of-the-art methods
demonstrate that our framework outperforms existing approaches and shows
significant robustness across various age groups, highlighting its potential
for real-time clinical applications in the early detection of neurodegenerative
diseases.

摘要：大腦老化涉及結構和功能的改變，因此可作為大腦健康的關鍵生物標記。結合結構性磁振造影 (sMRI) 和功能性磁振造影 (fMRI) 有可能透過利用互補數據來改善大腦年齡估計。然而，fMRI 資料比 sMRI 雜訊更多，這使得多模態融合變得複雜。傳統融合方法通常會引入比有用資訊更多雜訊，這可能會降低與單獨使用 sMRI 相比的準確性。在本文中，我們提出一個用於生物大腦年齡估計的新多模態框架，利用一個有性別意識的對抗變異自動編碼器 (SA-AVAE)。我們的框架整合了對抗和變異學習，以有效地解開來自兩種模態的潛在特徵。具體而言，我們將潛在空間分解為特定於模態的代碼和共享代碼，分別表示跨模態的互補和共同資訊。為了增強解開，我們引入了交叉重建和共享不同距離比率損失作為正則化項。重要的是，我們將性別資訊納入學習到的潛在代碼中，使模型能夠透過整合回歸模組，捕捉特定於性別的老化模式，以進行大腦年齡估計。我們使用公開可用的 OpenBHB 資料集評估我們的模型，這是一個用於大腦年齡估計的綜合多場域資料集。消融研究和與最先進方法的比較結果表明，我們的框架優於現有方法，並在各個年齡組中顯示出顯著的穩健性，突顯了其在神經退化性疾病早期檢測中的即時臨床應用潛力。

##### **UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**
2412.05585v1 by Saba Hesaraki, Morteza Akbari, Ramin Mousa

Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.

摘要：乳癌是全球女性死亡的主要原因，及早發現對於降低死亡率扮演關鍵角色。在 BUSI 資料集中使用超音波掃描進行乳癌相關的醫學影像，透過應用 UNet 和 UNet++ 網路已展現出令人滿意的分割結果。然而，這些模型一個顯著的缺點在於它們忽略了影像中包含的時間面向。本研究致力於透過整合 LSTM 層和自我注意機制來豐富 UNet++ 架構，以利用時間特徵進行分割。此外，整合多尺度特徵萃取模組旨在掌握 UNet++ 中各種尺度的特徵。透過將我們提出的方法與 BUSI with GT 資料集上的資料擴充結合，達到了 98.88% 的準確率、99.53% 的特異性、95.34% 的精確度、91.20% 的敏感度、93.74 的 F1 分數，以及 92.74% 的 Dice 係數。這些發現證明了與現有文獻中概述的尖端技術具有競爭力。

##### **Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**
2412.05583v2 by Atit Pokharel, Shashank Dahal, Pratik Sapkota, Bhupendra Bimal Chhetri

The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.

摘要：人工智慧的快速進展，特別是機器學習（ML）和深度學習（DL），為醫學科學開闢了新的前景，以改善嚴重健康狀況的診斷、預後和治療。本文重點在於開發具有高預測精度的 ML 模型，用於分類心律不整心電圖 (ECG) 信號。本研究中使用的 ECG 信號資料集來自 PhysioNet 和 MIT-BIH 資料庫。研究從二元分類開始，其中經過最佳化的雙向長短期記憶 (Bi-LSTM) 模型在區分正常和心房顫動信號方面產生了極佳的結果。本研究的一個關鍵方面是針對醫護專業人員進行的調查，這不僅驗證了基於 AI 的 ECG 分類器的實用性，還找出改進領域，包括準確性和納入更多心律不整類型。這些見解推動了先進卷積神經網路 (CNN) 系統的開發，該系統能夠以更高的準確度和精確度對五種類型的 ECG 信號進行分類。透過嚴格的分層 5 倍交叉驗證，確保了 CNN 模型的強健效能。還開發了一個網路入口網站來展示真實世界的效用，提供存取已訓練模型以進行即時分類。本研究強調了此類模型在遠距健康監測、預測性醫療保健、輔助診斷工具以及用於教育訓練和資料科學家與醫護人員之間跨領域合作的模擬環境中的潛在應用。

##### **Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**
2412.05536v1 by Cailian Ruan, Chengyue Huang, Yahe Yang

This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.

摘要：本研究引入了一個用於醫療影像診斷中多模態模型的評估框架。我們開發了一個結合了資料前處理、模型推論和基於偏好的評估的管道，透過受控擴充將最初的 500 個臨床案例擴充到 3,000 個。我們的做法結合了醫學影像和臨床觀察，以產生評估，使用 Claude 3.5 Sonnet 對抗醫師撰寫的診斷進行獨立評估。結果顯示不同模型的表現不同，其中 Llama 3.2-90B 在 85.27% 的案例中優於人類診斷。相比之下，專門的視覺模型，例如 BLIP2 和 Llava，分別在 41.36% 和 46.77% 的案例中顯示出偏好。此框架突顯了大型多模態模型在某些任務中優於人類診斷的潛力。

##### **Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**
2412.06828v1 by Fang Zeng, Zhiliang Lyu, Quanzheng Li, Xiang Li

This study introduces "RadCouncil," a multi-agent Large Language Model (LLM)
framework designed to enhance the generation of impressions in radiology
reports from the finding section. RadCouncil comprises three specialized
agents: 1) a "Retrieval" Agent that identifies and retrieves similar reports
from a vector database, 2) a "Radiologist" Agent that generates impressions
based on the finding section of the given report plus the exemplar reports
retrieved by the Retrieval Agent, and 3) a "Reviewer" Agent that evaluates the
generated impressions and provides feedback. The performance of RadCouncil was
evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and
qualitative criteria assessed by GPT-4, using chest X-ray as a case study.
Experiment results show improvements in RadCouncil over the single-agent
approach across multiple dimensions, including diagnostic accuracy, stylistic
concordance, and clarity. This study highlights the potential of utilizing
multiple interacting LLM agents, each with a dedicated task, to enhance
performance in specialized medical tasks and the development of more robust and
adaptable healthcare AI solutions.

摘要：本研究引入了「RadCouncil」，一個多重代理大型語言模型 (LLM)
框架，旨在增強放射科報告中印象的產生，特別是發現部分。RadCouncil 包含三個專門的代理：1) 一個「檢索」代理，用於識別並從向量資料庫中檢索類似的報告，2) 一個「放射科醫師」代理，用於根據給定報告的發現部分加上檢索代理檢索到的範例報告，產生印象，以及 3) 一個「審查者」代理，用於評估產生的印象並提供回饋。RadCouncil 的效能使用量化指標 (BLEU、ROUGE、BERTScore) 進行評估，並使用胸部 X 光作為案例研究，由 GPT-4 評估質化標準。實驗結果顯示，RadCouncil 在多個面向都有改進，包括診斷準確性、風格一致性，以及清晰度，優於單一代理方法。本研究強調了利用多個互動式 LLM 代理的潛力，每個代理都有專門的任務，以增強在專業醫療任務中的效能，並開發更強健且適應性更強的醫療保健 AI 解決方案。

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v2 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

摘要：本文提出了一個創新的方法，使用印度食品知識圖譜 (FKG.in) 和 LLM 來計算印度食譜的食品成分數據。主要重點是提供自動化食品成分分析工作流程的廣泛概述，並描述其核心功能：營養數據彙總、食品成分分析和 LLM 增強的信息解析。此工作流程旨在補充 FKG.in，並反覆補充來自驗證知識庫的食品成分數據。此外，本文重點介紹了表示印度食品和以數位方式存取食品成分數據的挑戰。它還回顧了食品成分數據的三個關鍵來源：印度食品成分表、印度營養資料庫和 Nutritionix API。此外，它簡要概述了使用者如何與工作流程互動以獲得基於飲食的健康建議和大量食譜的詳細食品成分資訊。然後，我們探討了分析印度食譜資訊在結構、多語言和不確定性等方面的複雜挑戰，並展示我們在基於 LLM 的解決方案上進行的持續工作，以解決這些問題。本文研討會論文中提出的 AI 驅動知識策展和資訊解析方法與應用程式無關，可概括且可複製到任何領域。

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, Fabrício Góes, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

摘要：這篇論文探討前沿大型語言模型 (LLM) 在科學中心問答互動中的適用性，目的是在維持事實準確性的同時提升訪客參與度。我們使用從英國萊斯特國家太空中心收集的提問資料集，評估了三個領先模型生成的回應：OpenAI 的 GPT-4、Claude 3.5 Sonnet 和 Google Gemini 1.5。每個模型都被提示針對 8 歲的受眾量身打造標準和有創意的回應，而這些回應則由太空科學專家根據準確性、參與度、清晰度、新穎性和與預期答案的偏差進行評估。結果顯示創造力與準確性之間存在權衡，Claude 在維持清晰度和吸引年輕受眾方面優於 GPT 和 Gemini，即使被要求產生更多有創意的回應。儘管如此，專家們觀察到，所有模型中較高的新穎性通常與較低的實際可靠性相關。這項研究強調了 LLM 在教育環境中的潛力，並強調需要仔細提示工程以平衡參與度和科學嚴謹性。

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

摘要：外科手術，特別是在神經外科，代表了複雜且高風險的場景，對外科團隊施加了巨大的認知負擔。儘管經過深思熟慮的教育和實踐可以增強認知能力，但由於患者安全問題，外科培訓機會仍然有限。為了應對外科培訓和手術中的這些認知挑戰，我們提出了 SurgBox，一個由代理驅動的沙盒框架，用於系統地增強外科醫生在沉浸式外科模擬中的認知能力。具體來說，我們的 SurgBox 利用大型語言模型 (LLM) 和量身定制的檢索增強生成 (RAG) 來真實地複製各種外科角色，為深思熟慮的實踐提供逼真的培訓環境。特別是，我們設計了手術副駕駛，一個由 AI 驅動的助手，用於主動協調外科信息流並支持臨床決策制定，從而減少外科團隊在手術期間的認知負擔。通過結合一種新穎的長短期記憶機制，我們的 Surgery Copilot 可以有效地平衡即時程序協助和全面的外科知識。使用真實的神經外科手術記錄進行的廣泛實驗驗證了我們的 SurgBox 框架，既能增強外科認知能力，又能支持臨床決策制定。通過提供一個綜合的培訓和運營支持解決方案來應對認知挑戰，我們的 SurgBox 框架推動了外科教育和實踐，有可能改變外科結果和醫療保健質量。代碼可在 https://github.com/franciszchen/SurgBox 獲得。

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

摘要：是否可能將類人社會機器人整合到工作流程或官方環境中的客戶服務中，例如市政辦公室？如果是這樣，這樣的應用場景可能會是什麼樣子，而機器人在與人類客戶互動時需要具備哪些技能？這種互動有哪些要求？我們為這種情況設計了一個應用場景，確定了機器人必要或理想的能力，開發了一個對應的機器人應用程式，並與基爾市議會共同在一個專案中進行了初步測試和評估。該專案獲得的最重要見解之一是，與平板電腦上用於市議會資訊系統的標準瀏覽器解決方案相比，具有人工語言處理能力（基於大型語言模型）以及類人的手勢和姿勢變化（動畫）的類人機器人被使用者更為青睞。此外，我們建議將 ACT-R 認知架構與機器人連接起來，其中 ACT-R 模型用於與機器人應用程式互動，以認知處理和增強人與機器人之間的對話。

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

摘要：對於後門攻擊已經有幾項努力，但這些主要集中在分類器的閉集效能（即分類）上。這使得在處理分類器開放集效能的威脅上出現了一個缺口，在文獻中稱為異常值偵測。可靠的異常值偵測對於在關鍵的真實世界應用中部署分類器至關重要，例如自動駕駛和醫學影像分析。首先，我們展示現有的後門攻擊在影響分類器的開放集效能方面不足，因為它們被特別設計用來混淆閉集內決策邊界。相比之下，有效的異常值偵測後門攻擊需要混淆閉集和開放集之間的決策邊界。有鑑於此，在本研究中，我們提出 BATOD，一種針對異常值偵測任務的新型後門攻擊。具體來說，我們設計了兩種類型的觸發器，將內點樣本轉移到異常值，反之亦然。我們使用各種真實世界資料集評估 BATOD，並展示了它在降低分類器的開放集效能方面的優異能力，與之前在應用防禦措施之前和之後的攻擊相比。

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah Pütz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

摘要：護理人員日益短缺，且護理之家發生跌倒的風險極高，對醫療保健系統構成重大挑戰。本研究提出將自動化跌倒偵測系統整合至護理床，旨在提升病患安全，同時透過穿戴式裝置或視訊監控來保護隱私。透過床架傳遞的機械振動會使用短時距傅立葉轉換進行處理，並能利用卷積神經網路對不同人類跌倒模式進行穩健分類。針對資料數量和多樣性的挑戰，提出產生額外資料的建議，特別著重於增加變化性。雖然此模型在使用實驗室資料區分跌倒事件和雜訊時顯示出有希望的結果，但建議在真實環境中進一步測試以進行驗證和改進。儘管可用資料有限，但所提出的系統顯示出對跌倒事件做出準確且快速的反應的潛力，減輕健康影響，並滿足老齡化人口的需求。此案例研究是作為 ZIM 專案的一部分進行的。ShapeFuture 專案將持續進行人工智慧增強感測器的進一步研究。

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

摘要：了解具有潛在社交網絡的人群中隔離政策的影響對於公共衛生至關重要，但由於假設個人獨立，大多數因果推論方法在此處失敗。我們引入了 DeepNetTMLE，這是一種深度學習增強的目標最大似然估計 (TMLE) 方法，旨在估計觀測數據中的時間敏感處理效果。DeepNetTMLE 透過整合時間模組和領域對抗訓練來建立介入不變表示，從而減輕一般干擾下時變混雜因素的偏差。此過程消除了當前處理與歷史變數之間的關聯，而目標設定步驟則維持偏差變異權衡，增強反事實預測的可靠性。使用具有不同隔離覆蓋率的「易感者-感染者-康復者」模型的模擬，我們表明 DeepNetTMLE 在反事實估計中實現了較低的偏差和更精確的信心區間，從而在預算限制內實現了最佳隔離建議，超越了最先進的方法。

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

摘要：<paragraph>心臟病是全球過早死亡的主因，特別是在中年和老年人中，男性發生率較高。根據世界衛生組織 (WHO) 的數據，包括心臟病在內的非傳染性疾病占全球死亡人數的 25%（1790 萬），孟加拉國每年有超過 43,204 人死於心臟病。然而，由於缺乏基準數據集和依賴手動或數據有限的方法，針對孟加拉國人口量身打造的心臟病檢測 (HDD) 系統的開發仍未得到充分探索。本研究通過引入新的、符合道德標準的 HDD 數據集、BIG 數據集和 CD 數據集來應對這些挑戰，其中包含有關症狀、檢查技術和風險因素的全面數據。使用先進的機器學習技術，包括邏輯迴歸和隨機森林，我們使用隨機森林實現了高達 96.6% 的顯著測試準確度。所提出的 AI 驅動系統整合了這些模型和數據集，以提供實時的準確診斷和個性化的醫療保健建議。通過利用結構化數據集和最先進的機器學習算法，本研究為可擴展且有效的心臟病檢測提供了一個創新的解決方案，具有降低死亡率和改善臨床結果的潛力。</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

摘要：反問題涉及從不完整或有雜訊的觀測中估計參數，出現在各種領域，例如醫學影像、地球物理和訊號處理。這些問題通常是不適定的，需要正則化技術來穩定解。在這項工作中，我們採用隨機插值 (SI)，一種生成式架構，整合確定性和隨機過程，將簡單的參考分佈（例如高斯分佈）對應到目標分佈。我們的 DAWS-SI 方法：資料感知和雜訊知情的隨機插值，結合資料和雜訊嵌入，讓模型能夠明確存取關於測量資料的表示，並考量觀測中的雜訊，使其在資料有雜訊或不完整的情況下特別穩健。透過學習與時間相關的速度場，SI 不僅提供精確的解，還能透過產生多個合理的結果來量化不確定性。與預先訓練的擴散模型不同，後者在高度不適定的設定中可能會遇到困難，我們的做法是針對每個反問題進行訓練，並適應不同的雜訊等級。我們透過廣泛的數值實驗驗證了我們方法的有效性和穩健性，這些任務包括影像去模糊和斷層掃描。

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

摘要：可靠的大規模森林狀態資料對於監測生態系統健康、碳儲量和氣候變遷的影響至關重要。目前對樹種分布的了解極度依賴於實地手動收集資料，這通常需要花費數年才能完成，導致只能涵蓋全球少數森林的有限資料集。最近的研究顯示，使用光探測和測距 (LiDAR) 影像的最新深度學習模型，可以在各種生態系統中對樹種進行準確且可擴充的分類。儘管 LiDAR 影像包含豐富的 3D 資訊，但大多數先前的研究會將 3D 影像壓縮成 2D 投影，以使用卷積神經網路 (CNN)。本文提供了三項重要的貢獻：(1) 我們將深度學習架構應用於熱帶稀樹草原的樹種分類；(2) 我們使用機載 LiDAR 影像，其解析度較低，但可擴充性比大多數先前研究中使用的地面 LiDAR 影像更高；(3) 我們引入了直接將 3D 點雲影像輸入到視覺Transformer模型 (PCTreeS) 的方法。我們的結果顯示，PCTreeS 方法在 AUC (0.81)、整體準確度 (0.72) 和訓練時間 (~45 分鐘) 方面優於當前使用 2D 投影的 CNN 基準。本文也激勵進一步收集和驗證 LiDAR 影像，以進行準確的大規模樹種自動分類。

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

摘要：放射科报告生成 (RRG) 已显示出极大的潜力，可通过自动执行报告编写的劳动密集型任务来协助放射科医生。虽然最近的进步提高了生成报告的质量和连贯性，但确保其事实正确性仍然是一项重大挑战。尽管已提出生成性医学视觉大语言模型 (VLLM) 来解决此问题，但这些模型容易出现幻觉并可能产生不准确的诊断信息。为了解决这些问题，我们引入了一个新颖的基于语义一致性的不确定性量化框架，该框架提供报告级和句子级的不确定性。与现有方法不同，我们的方法不需要修改底层模型或访问其内部状态（例如输出标记 logit），因此可用作即插即用模块，可以与最先进的模型无缝集成。广泛的实验表明了我们的方法在检测幻觉和提高自动生成的放射科报告的事实准确性方面的功效。通过避免高度不确定的报告，我们的方法将真实性得分提高了 10%，这是通过使用 MIMIC-CXR 数据集上的 Radialog 模型拒绝 20% 的报告实现的。此外，句子级不确定性标记了每份报告中精度最低的句子，成功率为 82.9%。

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

摘要：本文介紹 ClinicSum，這是一個新穎的架構，旨在自動從病患與醫師的對話中產生臨床摘要。它利用一個雙模組架構：一個基於檢索的過濾模組，從對話轉錄中萃取主觀、客觀、評估和計畫 (SOAP) 資訊，以及一個由微調過之預先訓練語言模型 (PLM) 提供動力的推論模組，它利用萃取的 SOAP 資料產生摘要的臨床摘要。為了微調 PLM，我們建立了一個訓練資料集，其中包含 1,473 組對話摘要，透過合併兩個公開可用的資料集 FigShare 和 MTS-Dialog，以及由主題專家 (SME) 驗證的真實摘要。ClinicSum 的效能透過自動評量指標 (例如 ROUGE、BERTScore) 和專家人類評估進行評量。結果顯示 ClinicSum 勝過現有最先進的 PLM，在自動評量中展現出優異的精確度、召回率和 F-1 分數，並在人類評估中獲得 SME 的高度偏好，使其成為自動臨床摘要的強健解決方案。

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

摘要：深度學習和自然語言生成技術的最新進展顯著改善了影像標題，能為視覺內容提供自動化的人類語言描述。在這項工作中，我們將這些標題技術應用於產生類似臨床醫師對心電圖資料的詮釋。這項研究利用既有的心電圖資料集，並附上由醫療保健專業人員 (HCP) 撰寫的自由文字報告作為訓練資料。這些報告雖然常常不一致，但為自動化學習提供了有價值的基礎。我們引入了一個編碼器-解碼器方法，使用這些報告來訓練模型，以產生心電圖事件的詳細描述。這代表心電圖分析自動化的重大進展，在零次學習分類和自動化臨床決策支援中具有潛在應用。此模型在各種資料集上進行測試，包括 1 導程和 12 導程心電圖。它明顯優於邱等人的現有最佳參考模型，與參考模型達成的 24.51% 相比，達到了 55.53% 的 METEOR 分數。此外，討論了幾個關鍵的設計選擇，提供了對這個領域中當前挑戰和創新的全面概述。此研究的原始程式碼在我們的 Git 儲存庫 https://git.zib.de/ableich/ecg-comment-generation-public 中公開。

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

摘要：個人化醫療旨在針對個別患者特徵調整醫療保健。然而，醫療系統中患者資料的異質性對達成準確且有效的個人化治療帶來重大挑戰。倫理問題進一步使來自不同機構的大量資料的彙總複雜化。聯邦學習 (FL) 提供了一種有前景的分散式解決方案，透過交換客戶模型而非原始資料來實現協作模型訓練，從而保護隱私。然而，現有的 FL 方法在伺服器彙總期間經常遭受退化，導致實際醫療 FL 設定中的模型效能下降。為了解決分散式醫療系統中的資料變異性，我們引入了個人化藥物聯邦元學習 (FedMetaMed)，它結合了聯邦學習和元學習來建立模型，以適應醫療系統中不同的患者資料。FedMetaMed 框架旨在透過解決這些限制，為個別客戶產生優越的個人化模型。具體來說，我們在伺服器端引入了累積傅立葉彙總 (CFA)，以改善全球知識彙總的穩定性和有效性。CFA 透過逐步整合從低頻率到高頻率的客戶模型來實現這一點。在客戶端層級，我們實施了一種協作傳輸最佳化 (CTO) 策略，採用三步驟流程 - 擷取、回饋和精煉 - 透過無縫的全球知識傳輸來增強個人化本地模型。在實際醫療影像資料集上的實驗表明，FedMetaMed 優於最先進的 FL 方法，即使在非分佈群組中也展現出優越的泛化性。

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

摘要：本文提出了一种新颖的多尺度、内在动机强化学习 (RL) 框架，名为“通过最大熵进行情景和终身探索”(ELEMENT)，该框架能够在不使用任何外在奖励的情况下探索环境，并有效地将所学技能转移到下游任务中。我们在三个方面提升了技术水平。首先，我们提出了多尺度熵优化，以解决以下事实：先前的最大状态熵在进行数百万次状态观察的终身探索时，会遭受奖励消失的影响，并且在每次迭代中都会变得非常昂贵。因此，我们在每个情景中添加了一个情景最大熵，以进一步加快搜索速度。其次，我们提出了一种新的内在奖励，用于情景熵最大化，名为“平均情景状态熵”，它为情景状态熵目标的理论上限提供了最优解。第三，为了加快终身熵最大化，我们提出了一个 $k$ 近邻 ($k$NN) 图，用于组织熵的估计和更新过程，从而大幅减少了计算。我们的 ELEMENT 在情景和终身设置中都明显优于最先进的内在奖励。此外，它还可以用于与任务无关的预训练、收集离线强化学习数据等。

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

摘要：隨著心理健康障礙的盛行率和複雜性日益增加，對於準確診斷和治療提出了嚴峻的挑戰，特別是在了解共存疾病之間的相互作用時。心理健康障礙，例如憂鬱症和焦慮症，經常共存，但目前從社群媒體貼文中衍生的資料集通常只關注單一障礙標籤，限制了它們在全面診斷分析中的效用。本文透過提出一個創新的方法來清理、抽樣、標籤和組合資料，以建立多功能的多標籤資料集，來解決這個關鍵的差距。我們的做法引進了一種合成標籤技術，將單標籤資料集轉換為多標籤註解，捕捉重疊心理健康狀況的複雜性。為了達成這個目標，首先將兩個單標籤資料集合併成一個基礎多標籤資料集，以進行共存診斷的實際分析。然後，我們設計並評估大型語言模型 (LLM) 的各種提示策略，從單標籤預測到能夠偵測任何現有障礙的無限制提示。在嚴格評估多個 LLM 和提示配置後，找出最佳組合並應用於標籤來自 RMHD 的六個其他單一障礙資料集。結果是 SPAADE-DR，一個包含各種心理健康狀況的強健多標籤資料集。這項研究展示了 LLM 驅動的合成標籤在推進從社群媒體資料進行心理健康診斷的轉型潛力，為更細緻、資料驅動的心理保健見解鋪路。

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

摘要：由於當前臨床評估的主觀性，因此出現了對構音障礙言語中自動嚴重程度評估的需求。DNN 模型優於 ML 模型，但缺乏使用者友善的可解釋性。ML 模型在特徵層級提供可解釋的結果，但其效能相對較低。當前的 ML 模型從原始波形中擷取各種特徵以預測嚴重程度。然而，現有方法並未涵蓋臨床評估中使用的所有構音障礙特徵。為了解決這個差距，我們提出了一種可將資訊損失降至最低的特徵擷取方法。我們引入了 ASR 轉錄作為一種新穎的特徵擷取來源。我們為構音障礙言語微調 ASR 模型，然後使用此模型轉錄構音障礙言語並擷取字元區段邊界資訊。它可以擷取更精細的發音和更廣泛的韻律特徵。這些特徵顯示出比現有特徵更好的嚴重程度預測效能：平衡準確度為 83.72%。

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

摘要：世界可能是一個複雜且難以應付的地方。高功能自閉症譜系障礙以及一般社交無能的人，經常會面對其他人口統計資料中的人根本不會遇到的應對挑戰。當他們處於青少年時期和成年初期（通常是大學生的年齡範圍）時，這種情況可能會變得更加明顯。當他們處於如此脆弱的年齡時，他們更容易受到社交互動感到自在和滿足的掙扎，以及擁有牢固關係（在他們的直系親屬之外）的影響。關於這一點，人工智慧聊天機器人的快速出現，導致許多人被用於造福不同年齡和人口統計資料的人，並具有易於存取性。有了這個，如果患有高功能自閉症和社交無能的人在自我提升的指導方面有任何想要的東西，那麼易於存取肯定會是一個。使用由 Mindstudio AI 提供技術支援的聊天機器人，為患有上述情況的青少年和年輕人提供心理健康支援，有哪些潛在的好處和限制？可以使用這樣的工具來幫助那些人應對不同社會環境中的道德困境，以減少現有的社會緊張局勢，可以做些什麼？本文探討這些問題，並提供見解，為未來關於此主題的討論提供資訊。

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

摘要：醫學影像分割最近已透過深度神經網路展現驚人的進展，但異質模態和標籤稀少限制了在未標註模態上開發分割模型。本文探討了一個新典範，以利用生成模型在醫學應用中：可控地合成未標註模態的資料，而無需註冊資料對。具體來說，我們在本文中做出以下貢獻：(i) 我們收集並策劃了一個大規模的放射影像文字資料集 MedGen-1M，包含模態標籤、屬性、區域和器官資訊，以及一部分器官標籤，以支援可控醫學影像生成的相關研究；(ii) 我們提出了一個基於擴散的資料引擎，稱為 MRGen，它能夠根據文字提示和標籤生成條件，合成缺乏標籤註解的不同模態的 MR 影像，以訓練未標註模態的分割模型；(iii) 我們在各種模態中進行了廣泛的實驗，說明我們的資料引擎可以有效地合成訓練樣本，並將 MRI 分割延伸至未標註的模態。

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

摘要：鉴于心血管疾病在全球的普遍性，迫切需要容易获取的早期筛查方法。通常，这需要医疗从业人员检查心脏听诊是否有不规则的声音，然后进行超声心动图和心电图检查。为了使早期诊断民主化，我们提出了一种用户友好的解决方案，用于检测异常心脏声音，利用移动电话和一个轻量级神经网络，该神经网络针对设备内推理进行了优化。与以前依赖于专用听诊器的做法不同，我们的方法直接分析音频记录，这得益于一种称为 IConNet 的新颖架构。IConNet 是一种可解释的卷积神经网络，利用音频信号处理的见解，提高效率，并提供从原始波形信号中提取神经模式的透明性。这是朝向医疗保健中可信赖的人工智能迈出的重要一步，有助于远程健康监测工作。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

摘要：本研究探討區塊鏈技術在醫療保健中的整合，專注於提升電子健康紀錄 (EHR) 管理的安全性與效率。我們提出一個創新的以太坊系統，賦予患者安全地控制其醫療數據的權力。我們的做法解決了醫療保健區塊鏈實作中的主要挑戰，包括可擴充性、隱私和法規遵循。該系統整合了數位簽章、基於角色的存取控制和多層架構，以確保安全且受控的存取。我們開發了一個具有使用者友善介面的去中心化應用程式 (dApp)，適用於患者、醫生和管理員，展示了我們解決方案的實際應用。在醫療保健專業人員和 IT 專家之間進行的一項調查顯示，他們對區塊鏈的採用有濃厚興趣，但也強調了對整合成本的擔憂。該研究探討了未來的強化，包括與 IoT 裝置整合和 AI 驅動的分析，有助於安全、高效且可互操作的醫療保健系統的演進，該系統利用尖端技術改善患者照護。

##### **CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**
2412.02819v3 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering 16k to 128k,
695 samples in total, the annotations are human-driven. We evaluate commercial
and open-source models on CNNSum and conduct a detailed analysis. Based on the
observations, we further conduct fine-tuning exploration with short-context
summary data. In our study: (1) GPT-4o underperformed, due to excessive
subjective commentary. (2) Currently, long-context summarization mainly relies
on memory ability, small LLMs with stable longer context lengths are the most
cost-effective. Using long data concatenated from short-context summaries makes
a significant improvement. (3) Prompt templates may cause a large performance
gap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or
Instruction versions may harm the Base model and further fine-tuning cannot
bridge performance gap. (5) while models with RoPE base scaling exhibit strong
extrapolation potential, their performance may vary significantly when combined
with other interpolation methods and need careful selection. (6) CNNSum
provides more reliable and insightful evaluation results than other benchmarks.
We release CNNSum to advance research in this field
(https://github.com/CxsGhost/CNNSum).

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得深入研究。然而，由於標註成本高，用於訓練或評估的高品質長語境摘要資料集稀少，限制了進一步的研究。在這項工作中，我們引入了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k 到 128k，總共 695 個範例，標註是由人工驅動的。我們評估了 CNNSum 上的商業和開源模型，並進行了詳細的分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，原因是過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串接而成的長資料顯著改善了表現。(3) 提示範本可能會造成很大的效能差距，但可以透過微調來減輕。(4) 微調過的聊天或指令版本可能會損害基礎模型，而進一步的微調無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但與其他內插方法結合時，其效能可能會顯著變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推進此領域的研究 (https://github.com/CxsGhost/CNNSum)。</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v2 by Jingyuan Yi, Peiyang Yu, Tianyi Huang, Zeqiu Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

摘要：<paragraph>針對最新的粒子群最佳化演算法，本文提出改良的 Transformer 模型，以提升心臟病預測的準確度，並提供新的演算法思維。我們首先使用三種主流機器學習分類演算法——決策樹、隨機森林與 XGBoost，並輸出這三種模型的混淆矩陣。結果顯示隨機森林模型在預測心臟病分類上表現最佳，準確度為 92.2%。接著，我們將基於粒子群最佳化 (PSO) 演算法的 Transformer 模型套用於相同資料集進行分類實驗。結果顯示該模型的分類準確度高達 96.5%，比隨機森林高出 4.3 個百分點，驗證了 PSO 在最佳化 Transformer 模型上的有效性。從上述研究中，我們可以看出粒子群最佳化顯著提升了 Transformer 在心臟病預測上的表現。提升預測心臟病的能力是一項全球性的優先要務，對全人類都有益。準確的預測可以增進公共衛生、優化醫療資源並降低醫療保健成本，進而促進全球人口的健康和社會生產力。這項進展為更有效率的健康管理鋪路，並支持建立一個更健康、更具韌性的全球社群。</paragraph>

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

摘要：深度學習的最新進展大幅革新了臨床診斷和治療領域，提供了改善各種臨床領域診斷精準度和治療效果的新方法，進而推動精準醫療的追求。多器官和多模態資料集的可用性日益增加，加速了大規模醫療多模態基礎模型 (MMFM) 的發展。這些模型以其強大的概化能力和豐富的表徵能力而聞名，正日益被改編以解決廣泛的臨床任務，從早期診斷到個人化治療策略。本篇評論提供了對 MMFM 近期發展的全面分析，重點關注三個關鍵面向：資料集、模型架構和臨床應用。我們也探討了最佳化多模態表徵的挑戰和機會，並討論這些進展如何透過改善患者預後和更有效率的臨床工作流程，形塑醫療保健的未來。

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

摘要：醫療影像在醫療保健中至關重要，可提供患者解剖結構和病理學的重要見解，有助於診斷和治療。X 光、磁振造影 (MRI)、電腦斷層掃描 (CT) 和超音波 (US) 等非侵入式技術，可捕捉器官、組織和異常的詳細影像。有效分析這些影像需要精確的分割，以描繪感興趣區域 (ROI)，例如器官或病灶。傳統的分割方法依賴於手動特徵萃取，既費時又因專家而異。人工智慧 (AI) 和深度學習 (DL) 的最新進展，特別是 U-Net 和其變體 (U-Net++ 和 U-Net 3+) 等卷積模型，已透過自動化流程和提高準確度，轉變了醫療影像分割 (MIS)。這些模型能跨越各種影像模式進行有效且精確的逐像素分類，克服了手動分割的限制。本篇評論探討了各種醫療影像技術，審查了 U-Net 架構及其改編，並討論了它們在不同模式中的應用。它也找出了 MIS 中常見的挑戰，並提出了潛在的解決方案。

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

摘要：<paragraph>從真實世界資料中還原物理驅動模型，即基礎動態系統的控制方程式組，一直是近期的研究重點。現有方法大多在具有非現實高取樣率的模擬資料上執行，或需要所有系統變數的明確測量值，這在真實世界的部署中並不可行。此外，這些方法假設對物理系統的外部擾動的時間戳是先驗已知的，且沒有不確定性，隱含地忽略了任何感測器時間同步或人為回報錯誤。在本文中，我們提出了一種基於新穎液態時間常數神經網路 (LTC-NN) 的架構，以從真實世界資料中還原物理動態的基礎模型。LTC-NN 節點的自動微分特性克服了與低取樣率相關的問題，LTC-NN 節點隱藏層的前向傳遞中輸入依賴的時間常數會產生一個巨大的隱式物理動態搜尋空間，基於物理模型求解器的資料重建損失引導了對正確隱式動態集的搜尋，並且在稠密層中使用中斷正則化確保了最稀疏模型的提取。此外，為了考慮擾動計時錯誤，我們利用稠密層節點來搜尋輸入位移，這將導致最低的重建損失。在四個基準動態系統（三個使用模擬資料，一個使用真實世界資料）上的實驗表明，LTC-NN 架構在恢復隱式物理模型係數方面比最先進的稀疏模型恢復方法更準確。我們還介紹了四個額外的案例研究（總共八個），這些研究涉及模擬中的真實醫療範例和真實世界的臨床資料，以展示我們的做法在實務中恢復基礎模型的有效性。</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

摘要：<paragraph>許多研究致力於發現特定遺傳性疾病，但其在廣泛的疾病類型和分類中的分類仍然難以捉摸。遺傳性疾病的早期診斷能及時介入並改善結果。本研究實作機器學習模型，使用出生或嬰兒時期可測量的基本臨床指標，以在生命的早期階段進行診斷。監督式學習演算法實作在一個包含 22083 個實例的資料集上，其中包含 42 個特徵，例如家族史、新生兒指標和基本實驗室檢驗。進行了廣泛的超參數調整、特徵工程和選擇。開發了兩個多類別分類器：一個用於預測疾病類型（粒線體、多因素和單基因），另一個用於預測亞型（9 種疾病）。使用準確度、精確度、召回率和 F1 分數評估效能。CatBoost 分類器在預測遺傳性疾病類型方面達到了 77% 的最高準確度。對於亞型，SVM 達到了 80% 的最高準確度。本研究證明了在機器學習模型中使用基本臨床資料進行早期分類和診斷各種遺傳性疾病的可行性。將機器學習應用於基本臨床指標，可以在較大的資料集上驗證後及時進行干預。有必要進行進一步的研究以改善此資料集上的模型效能。</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

摘要：隨著大規模視覺語言模型的出現，僅使用醫療影像作為輸入，並透過簡單提示引導，即可產生逼真的放射科報告。然而，由於其對發現的描述有事實上的錯誤，因此其實際效用受到限制。在本文中，我們提出了一個用於可解釋事實查核的新模型，該模型可識別報告中發現的錯誤及其位置。具體來說，我們分析了自動化報告方法所產生的錯誤類型，並從真實資料集中衍生出一個新的合成影像資料集，其中配對了發現及其位置的真實和虛假描述。然後在這個資料集上訓練一個新的多標籤跨模態對比回歸網路。我們評估了產生的事實查核模型及其在更正由多個 SOTA 自動化報告工具在各種基準資料集上產生的報告中的效用，結果表明透過這種錯誤偵測和更正，報告品質獲得了超過 40% 的提升。

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

摘要：自大型語言模型 (LLM) 出現以來，有效利用其在醫療保健中的潛力的挑戰已成為重中之重。使用 LLM 從非結構化臨床筆記中提取見解的一個關鍵障礙在於提示工程過程。儘管它在確定任務績效中扮演著舉足輕重的角色，但仍缺乏明確的提示最佳化框架。目前解決此差距的方法採用手動提示優化方法，其中領域專家與提示工程師合作建立最佳提示，這非常耗時且難以擴展，或透過採用自動提示最佳化方法，其中領域專家的輸入價值並未充分實現。為了解決這個問題，我們提出了 StructEase，這是一個新穎的框架，它彌合了自動化與提示工程中人類專業知識輸入之間的差距。該框架的核心創新是 SamplEase，這是一種迭代式抽樣演算法，它識別出專家回饋能顯著提升績效的高價值案例。這種方法將專家介入降到最低，以有效提升分類結果。這種有針對性的方法減少了標籤冗餘，減輕了人為錯誤，並提升了分類結果。我們使用來自美國國家電子傷害監測系統 (NEISS) 的去識別化臨床敘述資料集評估了 StructEase 的績效，與目前的方法相比，分類績效有了顯著的提升。我們的研究結果強調了專家整合在 LLM 工作流程中的價值，在維持最少專家工作量的同時，達到了 F1 分數的顯著提升。透過結合透明度、彈性和可擴展性，StructEase 為一個框架奠定了基礎，將專家輸入整合到醫療保健及其他領域的 LLM 工作流程中。

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

摘要：隨著全球高齡化加劇，老年人的健康管理已成為社會關注的焦點。本研究設計並實作一個智慧老人照護服務模型，以解決老人健康行為預測中的資料異質性、健康狀態複雜性、長期依賴性與資料流失、行為突變、資料隱私等問題。該模型透過多模態資料融合、資料流失處理、非線性預測、緊急事件偵測、隱私保護等模組，達到老人健康行為的精準預測與動態管理。在實驗設計上，基於多來源資料集與市場調查結果，該模型在健康行為預測、緊急事件偵測、個人化服務等方面均展現出優異的表現。實驗結果顯示，該模型能有效提升健康行為預測的準確性與魯棒性，並滿足智慧老人照護領域的實際應用需求。未來隨著更多資料的整合與技術的進一步優化，該模型將為智慧老人照護服務提供更強大的技術支撐。

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v2 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

摘要：由於體積龐大，體積掃描和全玻片病理圖像 (WSI) 通常透過從局部區域提取嵌入式處理，然後聚合器從此組中做出預測。然而，目前的方法需要事後可視化技術（例如 Grad-CAM），而且常常無法定位小型但臨床上至關重要的細節。為了解決這些限制，我們引入了 INSIGHT，這是一種新穎的弱監督聚合器，它將熱圖生成整合為歸納偏誤。從預先訓練好的特徵圖開始，INSIGHT 使用帶有小型卷積核的檢測模組來擷取精細的細節，以及帶有較廣泛感受野的上下文模組來抑制局部誤報。產生的內部熱圖突出了診斷相關區域。在 CT 和 WSI 基準上，INSIGHT 達到了最先進的分類結果和高弱標記語義分割效能。專案網站和程式碼可於下列網址取得：
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

摘要：癌症臨床試驗由於缺乏面向參與者的資訊和教育資源，常常在招募和參與方面面臨挑戰。本研究探討了大型語言模型 (LLM)，特別是 GPT4，從臨床試驗知情同意書中產生對患者友善的教育內容的潛力。我們使用來自 ClinicalTrials.gov 的資料，採用零次學習來建立試驗摘要，以及一次學習來開發多選題，並透過患者調查和群眾外包註解來評估其有效性。結果顯示，GPT4 生成的摘要具有可讀性和全面性，並且可能提高患者對臨床試驗的理解和興趣。多選題展示出很高的準確度，並且與群眾外包註解者達成共識。對於這兩種資源類型，我們發現了需要持續的人工監督的幻覺。這些發現展示了 LLM「開箱即用」的潛力，可以用最少的試驗特定工程來支援臨床試驗教育材料的產生，但仍需要採用有人在迴路中的實作來避免錯誤資訊的風險。

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

摘要：加護病房 (ICU) 提供重症照護和生命支持，給予醫院中病情最嚴重和受傷最嚴重的患者。由於對加護病房的需求快速且空前地增長，特別是在 COVID-19 期間，準確找出病情最危急的患者有助於醫院更有效地分配資源並挽救更多生命。預測加護病房轉診和其他無法預見事件 (PICTURE) 模型透過將面臨迫在眉睫的加護病房轉診、呼吸衰竭或死亡的高風險患者與風險較低的患者區分開來，預測患者惡化。本研究旨在實作深度學習模型，以基準化 XGBoost 模型的效能，後者是一種在預測方面具有競爭力的現有模型。

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

摘要：精準的睡眠分期分類對於了解睡眠障礙和改善整體健康至關重要。本研究提出一個新的三階段方法，使用 ECG 訊號進行睡眠分期分類，提供了一個更易於取得的替代方案，傳統方法通常依賴於 EEG 等複雜的模式。在第 1 和第 2 階段，我們初始化兩個網路的權重，然後在第 3 階段整合它們以進行全面的分類。在第一階段，我們使用特徵模仿網路 (FIN) 估計關鍵特徵，以實現更高的準確度和更快的收斂。第二階段專注於透過 ECG 訊號的時頻表示來識別 N1 睡眠階段。最後，第三階段整合前一階段的模型，並採用 Kolmogorov-Arnold 網路 (KAN) 來分類五個不同的睡眠階段。此外，資料擴充技術，特別是 SMOTE，用於增強對 N1 等代表性不足階段的分類能力。我們的結果證明了分類效能有顯著的改善，整體準確度為 80.79%，整體 kappa 為 0.73。該模型對清醒、N1、N2、N3 和 REM 的特定準確度分別為 86.70%、60.36%、83.89%、84.85% 和 87.16%。本研究強調了權重初始化和資料擴充在使用 ECG 訊號最佳化睡眠分期分類中的重要性。

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

摘要：稀疏視圖電腦斷層掃描 (CT) 是一種新興的協定，旨在減少醫療影像中的 X 射線劑量輻射。傳統的濾波反向投影演算法重建因稀疏資料而導致嚴重的偽影。相比之下，基於模型的迭代重建 (MBIR) 演算法，雖然透過正則化在減輕雜訊方面表現得更好，但對於臨床使用而言，其計算成本過高。本文介紹了一種創新的技術，稱為 Deep Guess 加速方案，它使用訓練過的類神經網路來加速正則化的 MBIR 並增強重建準確度。我們整合了最先進的深度學習工具，為求解非凸模型的近端演算法初始化一個聰明的起始猜測，從而僅在幾次迭代中計算出可解釋的解影像。在真實 CT 影像上的實驗結果證明了 Deep Guess 在（非常）稀疏斷層攝影協定中的有效性，在該協定中，它克服了其單純的變分對應物和許多最先進的資料驅動方法。我們還考慮了無真實依據的實作，並測試了所提出的架構對雜訊的穩健性。

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

摘要：社群媒體平台，特別是 Reddit 的 r/Epilepsy 社群，提供了癲癇患者 (PWE) 及其照顧者的經驗獨特觀點。這項研究分析了 57k 則貼文和 533k 則留言，探討不同人口統計資料（例如年齡、性別和關係）中的主要主題。我們的發現強調了關於癲癇相關挑戰的重要討論，包括憂鬱症（39.75% 的貼文表示有嚴重症狀）、駕駛限制、職場問題和癲癇女性的懷孕相關問題。我們引進了一項創新的參與度指標 F(P)，它結合了貼文長度、情緒分數和可讀性，以量化社群互動。這項分析強調了整合性照護的重要性，它能同時解決 PWE 面臨的神經和心理健康挑戰。這項研究的見解提供了針對性支持和意識介入策略。

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

摘要：臨床決策制定 (CDM) 是一個複雜、動態的過程，對於醫療保健的提供至關重要，然而對於人工智慧系統來說，它仍然是一項重大的挑戰。雖然大型語言模型 (LLM) 基礎代理已使用執照考試和知識問答任務對一般醫療知識進行了測試，但它們在實際場景中的 CDM 中的表現受到缺乏反映實際醫療實務的綜合測試資料集的限制。為了解決這個差距，我們提出了 MedChain，這是一個包含 12,163 個臨床案例的資料集，涵蓋了臨床工作流程的五個關鍵階段。MedChain 以現實世界臨床實務的三個關鍵特徵區別於現有的基準：個人化、互動性和順序性。此外，為了應對現實世界的 CDM 挑戰，我們還提出了 MedChain-Agent，這是一個整合了回饋機制和 MCase-RAG 模組的人工智慧系統，用於從先前的案例中學習並調整其回應。MedChain-Agent 在動態收集資訊和處理順序性臨床任務方面展現了顯著的適應性，顯著優於現有方法。相關的資料集和程式碼將在本文被接受後發布。

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

摘要：深度學習工具整合在胃腸道視覺中，在診斷、治療和整體病人照護方面具有顯著進展的潛力。然而，一個重大的挑戰是，這些工具傾向於做出過度自信的預測，即使在遇到未見或新出現的疾病模式時，也會破壞其可靠性。
我們將此可靠性的關鍵問題，架構為一個異常分佈 (OOD) 偵測問題，其中以前未見和新出現的疾病被視為 OOD 範例。然而，由於分佈內 (ID) 和 OOD 範例之間的重疊特徵表示，胃腸道影像構成了一項獨特的挑戰。現有的方法通常忽略此特性，因為它們主要是為自然影像資料集而開發，其中特徵區別較為明顯。儘管有重疊，我們假設分佈內範例的特徵會聚集在其真實類別的質心附近，導致到最近質心的距離較短。相反地，OOD 範例與所有類別質心的距離相等。基於此觀察，我們在特徵空間中提出了一個用於胃腸道 OOD 偵測的新穎最近質心距離差 (NCCD) 分數。
在多個深度學習架構和兩個公開基準 Kvasir2 和 Gastrovision 中的評估，證明了我們的方法與幾種最先進的方法相比的有效性。程式碼和實作細節公開於：
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

摘要：早期皮膚異常偵測在診斷和治療皮膚癌中扮演著至關重要的角色。使用 AI 驅動的裝置分割受影響的皮膚區域相對常見，並支援診斷流程。然而，由於需要高解析度影像和個別病灶通常不明確的邊界，要達成高性能仍是一項重大的挑戰。同時，醫療裝置要求分割模型具有小的記憶體佔用空間和低運算成本。基於這些需求，我們引進了一種名為 MambaU-Lite 的新型輕量級模型，它結合了 Mamba 和 CNN 架構的優點，特點是只有超過 400K 個參數和超過 1G flops 的運算成本。為了增強全局背景和局部特徵萃取，我們提出了 P-Mamba 塊，這是一個新的組成部分，它結合了 VSS 塊和多個池化層，使模型能夠有效地學習多尺度特徵並增強分割性能。我們在兩個皮膚資料集 ISIC2018 和 PH2 上評估了模型的性能，產生了有希望的結果。我們的原始程式碼將公開於：https://github.com/nqnguyen812/MambaU-Lite。

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

摘要：近來，愈來愈多人於各種社群媒體平台發布其心理狀態。利用此資料，可以開發出基於 AI 的系統，用於評估個人的心理健康，例如自殺風險。本文是一項針對自殺風險評估的研究，利用 Reddit 資料，並利用基礎語言模型來識別社群媒體貼文的模式。我們已經證明，使用較小的語言模型（即小於 5 億個參數）也可以有效，這與參數大於 5 億個的 LLM 相比。我們提出 Su-RoBERTa，一個針對自殺風險預測任務進行微調的 RoBERTa，它利用標記和未標記的 Reddit 資料，並透過使用 GPT-2 模型進行資料擴充來解決類別不平衡的問題。我們的 Su-RoBERTa 模型在最終評估期間獲得了 69.84% 的加權 F1 分數。本文證明了基礎語言模型在分析與心理健康相關的風險因子方面的有效性，並具備高效的運算管道

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

摘要：醫療病患資料總是多模態的。影像、文字、年齡、性別、組織病理學資料只是此脈絡下不同模態的幾個例子。處理和整合這些多模態資料，並使用深度學習方法，由於其在醫療程序（例如診斷和病患治療計畫）的龐大潛力，因此至關重要。在這項工作中，我們重新訓練一個多模態Transformer基礎模型，用於疾病分類。為此，我們使用來自 OpenI 的文字影像配對資料集，其中包含與臨床報告相關的 2D 胸部 X 光。我們的重點在於融合方法，用於合併從醫療資料集提取的文字和影像資訊。測試了具有 LLaMA II 主幹模型的不同架構結構。特定於模態特徵的早期融合會產生更好的結果，最佳模型達到 97.10% 的平均 AUC，高於從架構更深層次進行的後期融合（最佳模型：96.67% 的平均 AUC）。兩者都優於在相同多模態資料集上測試的前分類模型。新推出的多模態架構可以毫不費力地應用於其他多模態資料集，並且可以輕鬆改編以進行進一步的研究，特別是（但不限於）醫療 AI 領域。

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

摘要：放射學實務的核心挑戰，在於整合複雜的影像資料與臨床資訊，以產生可行的見解。語言的細緻運用是各種活動的關鍵，包括管理請求、描述和解讀影像結果的臨床資料，以及簡潔地記錄和傳達結果。大型語言模型 (LLM) 的出現，提供了一個機會來改善放射學中大量資料的管理和解讀。儘管主要是一般用途，這些先進的計算模型在專業的語言相關任務中展現出令人印象深刻的能力，即使沒有特定的訓練。要解鎖 LLM 在放射學中的潛力，需要基本了解其基礎，以及應對其獨特之處的策略性方法。這篇評論從實務放射學和機器學習專業知識以及近期文獻中汲取，為讀者提供 LLM 在放射學中的潛力的見解。它檢視了迄今為止在 LLM 快速演變的領域中經得起時間考驗的最佳實務。這包括針對放射學實務最佳化 LLM 特性的實務建議，以及限制、有效的提示和微調策略。

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

摘要：物件追蹤是現代創新中的一項基本工具，應用於國防系統、自動駕駛車輛和生物醫學研究中。它能精準地辨識、監控和時空分析連續畫面中的物件，提供動態行為的見解。在細胞生物學中，物件追蹤對於揭露細胞機制至關重要，例如遷移、交互作用和對藥物或病原體的反應。這些見解推動了對疾病進程和治療干預的理解的突破。
隨著時間的推移，物件追蹤方法已從傳統的基於特徵的方法演變為先進的機器學習和深度學習架構。雖然傳統方法在受控環境中是可靠的，但它們在有遮擋、光線變化和物件密度高的複雜環境中會遇到困難。深度學習模型通過提供更高的準確性、適應性和魯棒性來應對這些挑戰。
本綜述將物件追蹤技術分為傳統、統計、基於特徵和機器學習範例，重點關注生物醫學應用。這些方法對於追蹤細胞和亞細胞結構至關重要，促進了我們對健康和疾病的理解。討論了關鍵的效能指標，包括準確性、效率和適應性。本文探討了當前方法的局限性，並重點介紹了新興趨勢，以指導下一代生物醫學研究和更廣泛的科學領域追蹤系統的開發。

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v2 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

摘要：最近已开发出几种评估指标，仅基于使用词法、语义或临床命名实体识别方法的文本信息，自动评估胸部 X 光片的生成式 AI 报告的质量。在本文中，我们开发了一种新的报告质量评估方法，首先提取细粒度的发现模式，捕捉大量临床发现的位置、左右性和严重性。然后，我们执行短语接地以定位其在胸部 X 光片图像上的相关解剖区域。然后将文本和视觉测量相结合，对生成报告的质量进行评分。我们展示了将此评估指标与其他文本指标在源自 MIMIC 集合的金标准数据集上进行比较的结果，并展示了其对事实错误的鲁棒性和敏感性。

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

摘要：傳統語言模型已廣泛評估軟體工程領域，但 ChatGPT 和 Gemini 的潛力尚未被完全探索。為了填補這個差距，本文提出了全面的案例研究，以探討這兩種語言模型在開發各種需求工程應用程式方面的潛力。它深入探討了不同層級專家知識提示對這兩種語言模型預測精度的影響。在 4 個不同的需求工程任務公共基準資料集，它比較了這兩種語言模型與現有任務特定機器/深度學習預測器和傳統語言模型的效能。具體來說，本文利用 4 個基準資料集；Pure（7,445 個樣本，需求萃取）、PROMISE（622 個樣本，需求分類）、REQuestA（300 個問答 (QA) 對）和航太資料集（6347 個字，需求 NER 標記）。我們的實驗顯示，與 ChatGPT 相比，Gemini 需要更仔細的提示工程才能提供準確的預測。此外，在需求萃取基準資料集，最先進的 F1 分數為 0.86，而 ChatGPT 和 Gemini 分別達到 0.76 和 0.77。需求分類資料集的最先進 F1 分數為 0.96，而這兩種語言模型都為 0.78。在命名實體識別 (NER) 任務中，最先進的 F1 分數為 0.92，而 ChatGPT 產生 0.36，Gemini 產生 0.25。類似地，在問答資料集，最先進的 F1 分數為 0.90，而 ChatGPT 和 Gemini 分別產生 0.91 和 0.88。我們的實驗表明，Gemini 需要比 ChatGPT 更精確的提示工程。除了問答之外，這兩個模型在其他任務的表現都低於目前的最新預測器。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction**|Sicheng Zuo et.al.|[2412.10373v1](http://arxiv.org/abs/2412.10373v1)|[link](https://github.com/zuosc19/gaussianworld)|
|**2024-12-13**|**A Grounded Typology of Word Classes**|Coleman Haley et.al.|[2412.10369v1](http://arxiv.org/abs/2412.10369v1)|null|
|**2024-12-13**|**Apollo: An Exploration of Video Understanding in Large Multimodal Models**|Orr Zohar et.al.|[2412.10360v1](http://arxiv.org/abs/2412.10360v1)|null|
|**2024-12-13**|**A Library for Learning Neural Operators**|Jean Kossaifi et.al.|[2412.10354v1](http://arxiv.org/abs/2412.10354v1)|null|
|**2024-12-13**|**A dual contrastive framework**|Yuan Sun et.al.|[2412.10348v1](http://arxiv.org/abs/2412.10348v1)|null|
|**2024-12-13**|**COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation Tasks and Language Models**|Yuchen Ren et.al.|[2412.10347v1](http://arxiv.org/abs/2412.10347v1)|null|
|**2024-12-13**|**TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies**|Ruijie Zheng et.al.|[2412.10345v1](http://arxiv.org/abs/2412.10345v1)|null|
|**2024-12-13**|**Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining**|Zhiqi Ge et.al.|[2412.10342v1](http://arxiv.org/abs/2412.10342v1)|null|
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v1](http://arxiv.org/abs/2412.10337v1)|null|
|**2024-12-13**|**AdvPrefix: An Objective for Nuanced LLM Jailbreaks**|Sicheng Zhu et.al.|[2412.10321v1](http://arxiv.org/abs/2412.10321v1)|null|
|**2024-12-13**|**SCBench: A KV Cache-Centric Analysis of Long-Context Methods**|Yucheng Li et.al.|[2412.10319v1](http://arxiv.org/abs/2412.10319v1)|null|
|**2024-12-13**|**BrushEdit: All-In-One Image Inpainting and Editing**|Yaowei Li et.al.|[2412.10316v1](http://arxiv.org/abs/2412.10316v1)|null|
|**2024-12-13**|**Interlocking-free Selective Rationalization Through Genetic-based Learning**|Federico Ruggeri et.al.|[2412.10312v1](http://arxiv.org/abs/2412.10312v1)|null|
|**2024-12-13**|**DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding**|Zhiyu Wu et.al.|[2412.10302v1](http://arxiv.org/abs/2412.10302v1)|[link](https://github.com/deepseek-ai/deepseek-vl2)|
|**2024-12-13**|**Still "Talking About Large Language Models": Some Clarifications**|Murray Shanahan et.al.|[2412.10291v1](http://arxiv.org/abs/2412.10291v1)|null|
|**2024-12-13**|**One world, one opinion? The superstar effect in LLM responses**|Sofie Goethals et.al.|[2412.10281v1](http://arxiv.org/abs/2412.10281v1)|null|
|**2024-12-13**|**Envisioning National Resources for Artificial Intelligence Research: NSF Workshop Report**|Shantenu Jha et.al.|[2412.10278v1](http://arxiv.org/abs/2412.10278v1)|null|
|**2024-12-13**|**Benchmarking Linguistic Diversity of Large Language Models**|Yanzhu Guo et.al.|[2412.10271v1](http://arxiv.org/abs/2412.10271v1)|[link](https://github.com/yanzhuguo/llm-diversity)|
|**2024-12-13**|**Cultural Evolution of Cooperation among LLM Agents**|Aron Vallinder et.al.|[2412.10270v1](http://arxiv.org/abs/2412.10270v1)|null|
|**2024-12-13**|**Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT**|Danielle R. Thomas et.al.|[2412.10267v1](http://arxiv.org/abs/2412.10267v1)|[link](https://github.com/cmu-plus/lak2025-advocacy)|
|**2024-12-13**|**Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media**|Jiaqing Yuan et.al.|[2412.10266v1](http://arxiv.org/abs/2412.10266v1)|null|
|**2024-12-13**|**Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models**|Harry J. Davies et.al.|[2412.10257v1](http://arxiv.org/abs/2412.10257v1)|null|
|**2024-12-13**|**Exploring the Frontiers of Animation Video Generation in the Sora Era: Method, Dataset and Benchmark**|Yudong Jiang et.al.|[2412.10255v1](http://arxiv.org/abs/2412.10255v1)|null|
|**2024-12-13**|**Efficient Continual Pre-training of LLMs for Low-resource Languages**|Arijit Nag et.al.|[2412.10244v1](http://arxiv.org/abs/2412.10244v1)|null|
|**2024-12-13**|**Physics Instrument Design with Reinforcement Learning**|Shah Rukh Qasim et.al.|[2412.10237v1](http://arxiv.org/abs/2412.10237v1)|null|
|**2024-12-13**|**How good is my story? Towards quantitative metrics for evaluating LLM-generated XAI narratives**|Timour Ichmoukhamedov et.al.|[2412.10220v1](http://arxiv.org/abs/2412.10220v1)|null|
|**2024-12-13**|**GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion**|Jiapeng Tang et.al.|[2412.10209v1](http://arxiv.org/abs/2412.10209v1)|null|
|**2024-12-13**|**Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization**|Xiao Zhang et.al.|[2412.10207v1](http://arxiv.org/abs/2412.10207v1)|null|
|**2024-12-13**|**From Allies to Adversaries: Manipulating LLM Tool-Calling through Adversarial Injection**|Haowei Wang et.al.|[2412.10198v1](http://arxiv.org/abs/2412.10198v1)|null|
|**2024-12-13**|**Solving Robust Markov Decision Processes: Generic, Reliable, Efficient**|Tobias Meggendorfer et.al.|[2412.10185v1](http://arxiv.org/abs/2412.10185v1)|null|
|**2024-12-13**|**Multi-Head Encoding for Extreme Label Classification**|Daojun Liang et.al.|[2412.10182v1](http://arxiv.org/abs/2412.10182v1)|[link](https://github.com/anoise/mhe)|
|**2024-12-13**|**SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models**|Hung Nguyen et.al.|[2412.10178v1](http://arxiv.org/abs/2412.10178v1)|null|
|**2024-12-13**|**Scaling Combinatorial Optimization Neural Improvement Heuristics with Online Search and Adaptation**|Federico Julian Camerota Verdù et.al.|[2412.10163v1](http://arxiv.org/abs/2412.10163v1)|null|
|**2024-12-13**|**Direct Encoding of Declare Constraints in ASP**|Francesco Chiariello et.al.|[2412.10152v1](http://arxiv.org/abs/2412.10152v1)|[link](https://github.com/ainnoot/padl-2024)|
|**2024-12-13**|**VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval Augmented Generation**|Hyeonseok Lim et.al.|[2412.10151v1](http://arxiv.org/abs/2412.10151v1)|null|
|**2024-12-13**|**TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse Analysis with Prompt Engineering**|Bingru Li et.al.|[2412.10139v1](http://arxiv.org/abs/2412.10139v1)|null|
|**2024-12-13**|**ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL**|Yang Qin et.al.|[2412.10138v1](http://arxiv.org/abs/2412.10138v1)|[link](https://github.com/alibaba/route)|
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers**|Junyan Hu et.al.|[2412.10135v1](http://arxiv.org/abs/2412.10135v1)|null|
|**2024-12-13**|**You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects**|Islem Bouzenia et.al.|[2412.10133v1](http://arxiv.org/abs/2412.10133v1)|null|
|**2024-12-13**|**Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data**|Jonas Golde et.al.|[2412.10121v1](http://arxiv.org/abs/2412.10121v1)|null|
|**2024-12-13**|**CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models**|Zhihao Du et.al.|[2412.10117v1](http://arxiv.org/abs/2412.10117v1)|null|
|**2024-12-13**|**Label-template based Few-Shot Text Classification with Contrastive Learning**|Guanghua Hou et.al.|[2412.10110v1](http://arxiv.org/abs/2412.10110v1)|null|
|**2024-12-13**|**NetOrchLLM: Mastering Wireless Network Orchestration with Large Language Models**|Asmaa Abdallah et.al.|[2412.10107v1](http://arxiv.org/abs/2412.10107v1)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset**|Sagi Shaier et.al.|[2412.10105v1](http://arxiv.org/abs/2412.10105v1)|null|
|**2024-12-13**|**RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector**|Zhensheng Wang et.al.|[2412.10104v1](http://arxiv.org/abs/2412.10104v1)|[link](https://github.com/jensen-w/retqa)|
|**2024-12-13**|**AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation**|Xiyuan Gao et.al.|[2412.10103v1](http://arxiv.org/abs/2412.10103v1)|null|
|**2024-12-13**|**HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation**|Jaione Bengoetxea et.al.|[2412.10095v1](http://arxiv.org/abs/2412.10095v1)|null|
|**2024-12-13**|**AI in the Cosmos**|N. Sahakyan et.al.|[2412.10093v1](http://arxiv.org/abs/2412.10093v1)|null|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|[link](https://github.com/spongeorge/long-context-multihop)|
|**2024-12-13**|**Panacea: Novel DNN Accelerator using Accuracy-Preserving Asymmetric Quantization and Energy-Saving Bit-Slice Sparsity**|Dongyun Kam et.al.|[2412.10059v1](http://arxiv.org/abs/2412.10059v1)|null|
|**2024-12-13**|**GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?**|Zhikai Lei et.al.|[2412.10056v1](http://arxiv.org/abs/2412.10056v1)|null|
|**2024-12-13**|**Unsupervised Named Entity Disambiguation for Low Resource Domains**|Debarghya Datta et.al.|[2412.10054v1](http://arxiv.org/abs/2412.10054v1)|[link](https://github.com/deba-iitbh/gst-ned)|
|**2024-12-13**|**TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting from Sparse Views**|Liang Zhao et.al.|[2412.10051v1](http://arxiv.org/abs/2412.10051v1)|null|
|**2024-12-13**|**Large Action Models: From Inception to Implementation**|Lu Wang et.al.|[2412.10047v1](http://arxiv.org/abs/2412.10047v1)|[link](https://github.com/microsoft/UFO)|
|**2024-12-13**|**Enhanced Speech Emotion Recognition with Efficient Channel Attention Guided Deep CNN-BiLSTM Framework**|Niloy Kumar Kundu et.al.|[2412.10011v1](http://arxiv.org/abs/2412.10011v1)|null|
|**2024-12-13**|**Automated Collection of Evaluation Dataset for Semantic Search in Low-Resource Domain Language**|Anastasia Zhukova et.al.|[2412.10008v1](http://arxiv.org/abs/2412.10008v1)|null|
|**2024-12-13**|**The role of inhibitory control in garden-path sentence processing: A Chinese-English bilingual perspective**|Xiaohui Rao et.al.|[2412.10006v1](http://arxiv.org/abs/2412.10006v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**A Comparative Study of LLMs, NMT Models, and Their Combination in Persian-English Idiom Translation**|Sara Rezaeimanesh et.al.|[2412.09993v1](http://arxiv.org/abs/2412.09993v1)|null|
|**2024-12-13**|**Visual Object Tracking across Diverse Data Modalities: A Review**|Mengmeng Wang et.al.|[2412.09991v1](http://arxiv.org/abs/2412.09991v1)|null|
|**2024-12-13**|**Small Language Model as Data Prospector for Large Language Model**|Shiwen Ni et.al.|[2412.09990v1](http://arxiv.org/abs/2412.09990v1)|null|
|**2024-12-13**|**AI and the Future of Digital Public Squares**|Beth Goldberg et.al.|[2412.09988v1](http://arxiv.org/abs/2412.09988v1)|null|
|**2024-12-13**|**Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective**|Yuchen Fang et.al.|[2412.09972v1](http://arxiv.org/abs/2412.09972v1)|null|
|**2024-12-13**|**EP-CFG: Energy-Preserving Classifier-Free Guidance**|Kai Zhang et.al.|[2412.09966v1](http://arxiv.org/abs/2412.09966v1)|null|
|**2024-12-13**|**Romanized to Native Malayalam Script Transliteration Using an Encoder-Decoder Framework**|Bajiyo Baiju et.al.|[2412.09957v1](http://arxiv.org/abs/2412.09957v1)|[link](https://github.com/vrclc-duk/ml-en-transliteration)|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-13**|**B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens**|Zhuqiang Lu et.al.|[2412.09919v1](http://arxiv.org/abs/2412.09919v1)|null|
|**2024-12-13**|**Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning**|Jing Bi et.al.|[2412.09906v1](http://arxiv.org/abs/2412.09906v1)|[link](https://github.com/bijings/sgft)|
|**2024-12-13**|**Analyzing Fairness of Computer Vision and Natural Language Processing Models**|Ahmed Rashed et.al.|[2412.09900v1](http://arxiv.org/abs/2412.09900v1)|null|
|**2024-12-13**|**Analyzing Fairness of Classification Machine Learning Model with Structured Dataset**|Ahmed Rashed et.al.|[2412.09896v1](http://arxiv.org/abs/2412.09896v1)|null|
|**2024-12-13**|**Semi-Periodic Activation for Time Series Classification**|José Gilberto Barbosa de Medeiros Júnior et.al.|[2412.09889v1](http://arxiv.org/abs/2412.09889v1)|[link](https://github.com/jose-gilberto/leakysinelu)|
|**2024-12-13**|**CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls**|Li Chai et.al.|[2412.09887v1](http://arxiv.org/abs/2412.09887v1)|null|
|**2024-12-13**|**Benchmarking Table Comprehension In The Wild**|Yikang Pan et.al.|[2412.09884v1](http://arxiv.org/abs/2412.09884v1)|null|
|**2024-12-13**|**On the Limit of Language Models as Planning Formalizers**|Cassie Huang et.al.|[2412.09879v1](http://arxiv.org/abs/2412.09879v1)|[link](https://github.com/cassiehuang22/llm-as-pddl-formalizer)|
|**2024-12-13**|**Byte Latent Transformer: Patches Scale Better Than Tokens**|Artidoro Pagnoni et.al.|[2412.09871v1](http://arxiv.org/abs/2412.09871v1)|[link](https://github.com/facebookresearch/blt)|
|**2024-12-13**|**Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for Supervised Fine-tuning**|Abraham Atsiwo et.al.|[2412.09859v1](http://arxiv.org/abs/2412.09859v1)|[link](https://github.com/abraham-atsiwo/filbert-lc)|
|**2024-12-13**|**RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning**|Charles Xu et.al.|[2412.09858v1](http://arxiv.org/abs/2412.09858v1)|null|
|**2024-12-13**|**LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity**|Hongjie Wang et.al.|[2412.09856v1](http://arxiv.org/abs/2412.09856v1)|null|
|**2024-12-13**|**Learning Structural Causal Models from Ordering: Identifiable Flow Models**|Minh Khoa Le et.al.|[2412.09843v1](http://arxiv.org/abs/2412.09843v1)|null|
|**2024-12-13**|**Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models**|Changqun Li et.al.|[2412.09827v1](http://arxiv.org/abs/2412.09827v1)|null|
|**2024-12-13**|**Precise Antigen-Antibody Structure Predictions Enhance Antibody Development with HelixFold-Multimer**|Jie Gao et.al.|[2412.09826v1](http://arxiv.org/abs/2412.09826v1)|null|
|**2024-12-13**|**MERaLiON-AudioLLM: Technical Report**|Yingxu He et.al.|[2412.09818v1](http://arxiv.org/abs/2412.09818v1)|null|
|**2024-12-13**|**Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation**|Xiaofeng Zhang et.al.|[2412.09817v1](http://arxiv.org/abs/2412.09817v1)|[link](https://github.com/fanshuozeng/simignore)|
|**2024-12-13**|**Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated Learning**|Jianhong Chen et.al.|[2412.09814v1](http://arxiv.org/abs/2412.09814v1)|[link](https://github.com/pechen123/2dbn_learning)|
|**2024-12-13**|**ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic LayerReplace and Selective Rank Compression**|Kai Yao et.al.|[2412.09812v1](http://arxiv.org/abs/2412.09812v1)|null|
|**2024-12-13**|**LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering**|Patrick Sutanto et.al.|[2412.09807v1](http://arxiv.org/abs/2412.09807v1)|null|
|**2024-12-13**|**Universal Inceptive GNNs by Eliminating the Smoothness-generalization Dilemma**|Ming Gu et.al.|[2412.09805v1](http://arxiv.org/abs/2412.09805v1)|null|
|**2024-12-13**|**CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection**|Qibo Chen et.al.|[2412.09799v1](http://arxiv.org/abs/2412.09799v1)|null|
|**2024-12-13**|**AutoPatent: A Multi-Agent Framework for Automatic Patent Generation**|Qiyao Wang et.al.|[2412.09796v1](http://arxiv.org/abs/2412.09796v1)|[link](https://github.com/qiyao-wang/autopatent)|
|**2024-12-13**|**Learning Visually Grounded Domain Ontologies via Embodied Conversation and Explanation**|Jonghyuk Park et.al.|[2412.09770v1](http://arxiv.org/abs/2412.09770v1)|[link](https://github.com/jpstyle/ns-arch-unity)|
|**2024-12-12**|**Memory Layers at Scale**|Vincent-Pierre Berges et.al.|[2412.09764v1](http://arxiv.org/abs/2412.09764v1)|[link](https://github.com/facebookresearch/memory)|
|**2024-12-12**|**Congruence-based Learning of Probabilistic Deterministic Finite Automata**|Matías Carrasco et.al.|[2412.09760v1](http://arxiv.org/abs/2412.09760v1)|null|
|**2024-12-12**|**AI Red-Teaming is a Sociotechnical System. Now What?**|Tarleton Gillespie et.al.|[2412.09751v1](http://arxiv.org/abs/2412.09751v1)|null|
|**2024-12-12**|**Let Curves Speak: A Continuous Glucose Monitor based Large Sensor Foundation Model for Diabetes Management**|Junjie Luo et.al.|[2412.09727v1](http://arxiv.org/abs/2412.09727v1)|null|
|**2024-12-12**|**The Unreasonable Effectiveness of Gaussian Score Approximation for Diffusion Models and its Applications**|Binxu Wang et.al.|[2412.09726v1](http://arxiv.org/abs/2412.09726v1)|null|
|**2024-12-12**|**GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers**|Sarkar Snigdha Sarathi Das et.al.|[2412.09722v1](http://arxiv.org/abs/2412.09722v1)|null|
|**2024-12-12**|**Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection of Generated Images and the Impact of Prompts**|Philipp Moeßner et.al.|[2412.09715v1](http://arxiv.org/abs/2412.09715v1)|[link](https://github.com/heikeadel/cocoxgen)|

#### Abstracts
##### **GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction**
2412.10373v1 by Sicheng Zuo, Wenzhao Zheng, Yuanhui Huang, Jie Zhou, Jiwen Lu

3D occupancy prediction is important for autonomous driving due to its
comprehensive perception of the surroundings. To incorporate sequential inputs,
most existing methods fuse representations from previous frames to infer the
current 3D occupancy. However, they fail to consider the continuity of driving
scenarios and ignore the strong prior provided by the evolution of 3D scenes
(e.g., only dynamic objects move). In this paper, we propose a
world-model-based framework to exploit the scene evolution for perception. We
reformulate 3D occupancy prediction as a 4D occupancy forecasting problem
conditioned on the current sensor input. We decompose the scene evolution into
three factors: 1) ego motion alignment of static scenes; 2) local movements of
dynamic objects; and 3) completion of newly-observed scenes. We then employ a
Gaussian world model (GaussianWorld) to explicitly exploit these priors and
infer the scene evolution in the 3D Gaussian space considering the current RGB
observation. We evaluate the effectiveness of our framework on the widely used
nuScenes dataset. Our GaussianWorld improves the performance of the
single-frame counterpart by over 2% in mIoU without introducing additional
computations. Code: https://github.com/zuosc19/GaussianWorld.

摘要：3D 佔用預測對於自動駕駛很重要，因為它能全面感知周圍環境。為了納入序列輸入，大多數現有方法融合了前幾幀的表示，以推論當前的 3D 佔用。然而，它們未能考慮駕駛場景的連續性，並且忽略了 3D 場景演化所提供的強先驗（例如，只有動態物體會移動）。在本文中，我們提出了一個基於世界模型的框架，以利用場景演化進行感知。我們將 3D 佔用預測重新表述為 4D 佔用預測問題，條件取決於當前的感測器輸入。我們將場景演化分解為三個因素：1）靜態場景的自運動對齊；2）動態物體的局部運動；以及 3）新觀察場景的完成。然後，我們採用高斯世界模型 (GaussianWorld) 來明確利用這些先驗，並在考慮當前 RGB 觀測值的情況下，推論 3D 高斯空間中的場景演化。我們在廣泛使用的 nuScenes 資料集上評估了我們框架的有效性。我們的 GaussianWorld 在不引入額外計算的情況下，將單幀對應項的 mIoU 效能提升了 2% 以上。程式碼：https://github.com/zuosc19/GaussianWorld。

##### **A Grounded Typology of Word Classes**
2412.10369v1 by Coleman Haley, Sharon Goldwater, Edoardo Ponti

We propose a grounded approach to meaning in language typology. We treat data
from perceptual modalities, such as images, as a language-agnostic
representation of meaning. Hence, we can quantify the function--form
relationship between images and captions across languages. Inspired by
information theory, we define "groundedness", an empirical measure of
contextual semantic contentfulness (formulated as a difference in surprisal)
which can be computed with multilingual multimodal language models. As a proof
of concept, we apply this measure to the typology of word classes. Our measure
captures the contentfulness asymmetry between functional (grammatical) and
lexical (content) classes across languages, but contradicts the view that
functional classes do not convey content. Moreover, we find universal trends in
the hierarchy of groundedness (e.g., nouns > adjectives > verbs), and show that
our measure partly correlates with psycholinguistic concreteness norms in
English. We release a dataset of groundedness scores for 30 languages. Our
results suggest that the grounded typology approach can provide quantitative
evidence about semantic function in language.

摘要：我們提出了一個基於語言類型學意義的紮實方法。我們將來自感知方式的數據（例如圖像）視為一種與語言無關的意義表示。因此，我們可以量化跨語言的圖像和字幕之間的功能形式關係。受資訊理論的啟發，我們定義了「紮實性」，這是一個上下文語義內容豐富性的經驗測量（表述為驚奇的差異），可以用多語言多模態語言模型計算。作為概念驗證，我們將此測量應用於詞類的類型學。我們的測量捕捉了跨語言的功能（語法）和詞彙（內容）類別之間的內容豐富性不對稱，但與功能類別不傳達內容的觀點相矛盾。此外，我們發現了紮實性層級中的普遍趨勢（例如，名詞>形容詞>動詞），並表明我們的測量部分與英語的心理語言具體性規範相關。我們發布了一個包含 30 種語言的紮實性分數的數據集。我們的結果表明，紮實類型學方法可以提供關於語言中語義功能的量化證據。

##### **Apollo: An Exploration of Video Understanding in Large Multimodal Models**
2412.10360v1 by Orr Zohar, Xiaohan Wang, Yann Dubois, Nikhil Mehta, Tong Xiao, Philippe Hansen-Estruch, Licheng Yu, Xiaofang Wang, Felix Juefei-Xu, Ning Zhang, Serena Yeung-Levy, Xide Xia

Despite the rapid integration of video perception capabilities into Large
Multimodal Models (LMMs), the underlying mechanisms driving their video
understanding remain poorly understood. Consequently, many design decisions in
this domain are made without proper justification or analysis. The high
computational cost of training and evaluating such models, coupled with limited
open research, hinders the development of video-LMMs. To address this, we
present a comprehensive study that helps uncover what effectively drives video
understanding in LMMs.
  We begin by critically examining the primary contributors to the high
computational requirements associated with video-LMM research and discover
Scaling Consistency, wherein design and training decisions made on smaller
models and datasets (up to a critical size) effectively transfer to larger
models. Leveraging these insights, we explored many video-specific aspects of
video-LMMs, including video sampling, architectures, data composition, training
schedules, and more. For example, we demonstrated that fps sampling during
training is vastly preferable to uniform frame sampling and which vision
encoders are the best for video representation.
  Guided by these findings, we introduce Apollo, a state-of-the-art family of
LMMs that achieve superior performance across different model sizes. Our models
can perceive hour-long videos efficiently, with Apollo-3B outperforming most
existing $7$B models with an impressive 55.1 on LongVideoBench. Apollo-7B is
state-of-the-art compared to 7B LMMs with a 70.9 on MLVU, and 63.3 on
Video-MME.

摘要：儘管影片感知能力已快速整合至大型多模態模型 (LMM)，但驅動其影片理解的底層機制仍鮮為人知。因此，此領域中的許多設計決策都是在缺乏適當依據或分析的情況下做出的。訓練和評估此類模型的高運算成本，加上有限的公開研究，阻礙了影片 LMM 的發展。為了解決這個問題，我們提出了一項全面性研究，有助於揭示有效驅動 LMM 中影片理解的因素。
我們首先批判性地審視與影片 LMM 研究相關的高運算需求的主要因素，並發現規模一致性，其中在較小型號和資料集（達到臨界規模）上做出的設計和訓練決策，可有效轉移到較大型號。運用這些見解，我們探討了影片 LMM 的許多影片特定面向，包括影片取樣、架構、資料組成、訓練時程等。例如，我們證明了訓練期間的 fps 取樣遠比均勻的影格取樣來得理想，以及哪種視覺編碼器最適合影片表徵。
在這些發現的指導下，我們推出了 Apollo，一個最先進的 LMM 系列，可在不同模型規模中實現卓越的效能。我們的模型可以有效感知長達一小時的影片，其中 Apollo-3B 以令人印象深刻的 LongVideoBench 55.1 分數，超越了現有的 $7$B 模型。Apollo-7B 以 MLVU 70.9 分和 Video-MME 63.3 分，與 7B LMM 相比是目前最先進的。

##### **A Library for Learning Neural Operators**
2412.10354v1 by Jean Kossaifi, Nikola Kovachki, Zongyi Li, Davit Pitt, Miguel Liu-Schiaffini, Robert Joseph George, Boris Bonev, Kamyar Azizzadenesheli, Julius Berner, Anima Anandkumar

We present NeuralOperator, an open-source Python library for operator
learning. Neural operators generalize neural networks to maps between function
spaces instead of finite-dimensional Euclidean spaces. They can be trained and
inferenced on input and output functions given at various discretizations,
satisfying a discretization convergence properties. Built on top of PyTorch,
NeuralOperator provides all the tools for training and deploying neural
operator models, as well as developing new ones, in a high-quality, tested,
open-source package. It combines cutting-edge models and customizability with a
gentle learning curve and simple user interface for newcomers.

摘要：我們展示了 NeuralOperator，這是一個用於算子學習的開源 Python 函式庫。神經算子將神經網路概括為函數空間之間的映射，而不是有限維的歐幾里得空間。它們可以在各種離散化中給出的輸入和輸出函數上進行訓練和推論，滿足離散化收斂特性。NeuralOperator 建構在 PyTorch 之上，提供訓練和部署神經算子模型以及開發新模型的所有工具，並以高品質、經過測試的開源套件提供。它結合了尖端的模型和可自訂性，並為新手提供了平緩的學習曲線和簡單的使用者介面。

##### **A dual contrastive framework**
2412.10348v1 by Yuan Sun, Zhao Zhang, Jorge Ortiz

In current multimodal tasks, models typically freeze the encoder and decoder
while adapting intermediate layers to task-specific goals, such as region
captioning. Region-level visual understanding presents significant challenges
for large-scale vision-language models. While limited spatial awareness is a
known issue, coarse-grained pretraining, in particular, exacerbates the
difficulty of optimizing latent representations for effective encoder-decoder
alignment. We propose AlignCap, a framework designed to enhance region-level
understanding through fine-grained alignment of latent spaces. Our approach
introduces a novel latent feature refinement module that enhances conditioned
latent space representations to improve region-level captioning performance. We
also propose an innovative alignment strategy, the semantic space alignment
module, which boosts the quality of multimodal representations. Additionally,
we incorporate contrastive learning in a novel manner within both modules to
further enhance region-level captioning performance. To address spatial
limitations, we employ a General Object Detection (GOD) method as a data
preprocessing pipeline that enhances spatial reasoning at the regional level.
Extensive experiments demonstrate that our approach significantly improves
region-level captioning performance across various tasks

摘要：在當前的多模態任務中，模型通常會凍結編碼器和解碼器，同時調整中間層以適應特定任務的目標，例如區域標題。區域級別的視覺理解對大規模視覺語言模型提出了重大挑戰。儘管已知空間感知有限是一個問題，但粗粒度預訓練尤其會加劇優化潛在表示以實現有效編碼器-解碼器對齊的難度。我們提出了 AlignCap，一個旨在通過潛在空間的細粒度對齊來增強區域級別理解的框架。我們的做法引入了一個新穎的潛在特徵細化模組，它增強了條件潛在空間表示以改善區域級別標題的性能。我們還提出了一種創新的對齊策略，語義空間對齊模組，它提升了多模態表示的品質。此外，我們在兩個模組中以一種新穎的方式納入了對比學習，以進一步增強區域級別的標題性能。為了解決空間限制，我們採用通用物件偵測 (GOD) 方法作為資料預處理管道，它增強了區域級別的空間推理。廣泛的實驗表明，我們的做法顯著改善了各種任務中的區域級別標題性能

##### **COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation Tasks and Language Models**
2412.10347v1 by Yuchen Ren, Wenwei Han, Qianyuan Zhang, Yining Tang, Weiqiang Bai, Yuchen Cai, Lifeng Qiao, Hao Jiang, Dong Yuan, Tao Chen, Siqi Sun, Pan Tan, Wanli Ouyang, Nanqing Dong, Xinzhu Ma, Peng Ye

As key elements within the central dogma, DNA, RNA, and proteins play crucial
roles in maintaining life by guaranteeing accurate genetic expression and
implementation. Although research on these molecules has profoundly impacted
fields like medicine, agriculture, and industry, the diversity of machine
learning approaches-from traditional statistical methods to deep learning
models and large language models-poses challenges for researchers in choosing
the most suitable models for specific tasks, especially for cross-omics and
multi-omics tasks due to the lack of comprehensive benchmarks. To address this,
we introduce the first comprehensive multi-omics benchmark COMET (Benchmark for
Biological COmprehensive Multi-omics Evaluation Tasks and Language Models),
designed to evaluate models across single-omics, cross-omics, and multi-omics
tasks. First, we curate and develop a diverse collection of downstream tasks
and datasets covering key structural and functional aspects in DNA, RNA, and
proteins, including tasks that span multiple omics levels. Then, we evaluate
existing foundational language models for DNA, RNA, and proteins, as well as
the newly proposed multi-omics method, offering valuable insights into their
performance in integrating and analyzing data from different biological
modalities. This benchmark aims to define critical issues in multi-omics
research and guide future directions, ultimately promoting advancements in
understanding biological processes through integrated and different omics data
analysis.

摘要：作為中心法則中的關鍵元素，DNA、RNA 和蛋白質在維持生命方面發揮著至關重要的作用，它們保證了準確的基因表達和實施。儘管對這些分子的研究對醫學、農業和工業等領域產生了深遠的影響，但機器學習方法的多樣性（從傳統的統計方法到深度學習模型和大語言模型）對研究人員在為特定任務選擇最合適的模型提出了挑戰，特別是對於組學間和多組學任務，這是由於缺乏全面的基準。為了解決這個問題，我們引入了第一個全面的多組學基準 COMET（生物綜合多組學評估任務和語言模型基準），旨在評估模型在單組學、組學間和多組學任務中的表現。首先，我們策劃並開發了一系列多樣的下游任務和數據集，涵蓋了 DNA、RNA 和蛋白質中的關鍵結構和功能方面，包括跨越多個組學層級的任務。然後，我們評估了現有的 DNA、RNA 和蛋白質基礎語言模型，以及新提出的多組學方法，對它們整合和分析來自不同生物模式的數據的性能提供了寶貴的見解。這個基準旨在定義多組學研究中的關鍵問題並指導未來的方向，最終通過整合和不同的組學數據分析促進對生物過程的理解。

##### **TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies**
2412.10345v1 by Ruijie Zheng, Yongyuan Liang, Shuaiyi Huang, Jianfeng Gao, Hal Daumé III, Andrey Kolobov, Furong Huang, Jianwei Yang

Although large vision-language-action (VLA) models pretrained on extensive
robot datasets offer promising generalist policies for robotic learning, they
still struggle with spatial-temporal dynamics in interactive robotics, making
them less effective in handling complex tasks, such as manipulation. In this
work, we introduce visual trace prompting, a simple yet effective approach to
facilitate VLA models' spatial-temporal awareness for action prediction by
encoding state-action trajectories visually. We develop a new TraceVLA model by
finetuning OpenVLA on our own collected dataset of 150K robot manipulation
trajectories using visual trace prompting. Evaluations of TraceVLA across 137
configurations in SimplerEnv and 4 tasks on a physical WidowX robot demonstrate
state-of-the-art performance, outperforming OpenVLA by 10% on SimplerEnv and
3.5x on real-robot tasks and exhibiting robust generalization across diverse
embodiments and scenarios. To further validate the effectiveness and generality
of our method, we present a compact VLA model based on 4B Phi-3-Vision,
pretrained on the Open-X-Embodiment and finetuned on our dataset, rivals the 7B
OpenVLA baseline while significantly improving inference efficiency.

摘要：儘管在廣泛機器人資料集上預訓練的大型視覺語言動作 (VLA) 模型為機器人學習提供了有前途的通才策略，但它們在互動機器人中的時空動態上仍有困難，這使得它們在處理複雜任務（例如操作）時效率較低。在這項工作中，我們引入了視覺軌跡提示，這是一種簡單但有效的方法，通過視覺編碼狀態動作軌跡來促進 VLA 模型的時空感知，以進行動作預測。我們通過使用視覺軌跡提示，在我們自己收集的 150K 機器人操作軌跡數據集上對 OpenVLA 進行微調，開發了一個新的 TraceVLA 模型。TraceVLA 在 SimplerEnv 中的 137 種配置和物理 WidowX 機器人上的 4 項任務的評估證明了最先進的效能，在 SimplerEnv 上比 OpenVLA 高出 10%，在真實機器人任務上高出 3.5 倍，並在不同的具體化和場景中表現出強大的泛化能力。為了進一步驗證我們方法的有效性和普遍性，我們提出了一個基於 4B Phi-3-Vision 的緊湊 VLA 模型，在 Open-X-Embodiment 上預訓練並在我們的數據集上進行微調，與 7B OpenVLA 基線相媲美，同時顯著提高了推理效率。

##### **Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining**
2412.10342v1 by Zhiqi Ge, Juncheng Li, Xinglei Pang, Minghe Gao, Kaihang Pan, Wang Lin, Hao Fei, Wenqiao Zhang, Siliang Tang, Yueting Zhuang

Digital agents are increasingly employed to automate tasks in interactive
digital environments such as web pages, software applications, and operating
systems. While text-based agents built on Large Language Models (LLMs) often
require frequent updates due to platform-specific APIs, visual agents
leveraging Multimodal Large Language Models (MLLMs) offer enhanced adaptability
by interacting directly with Graphical User Interfaces (GUIs). However, these
agents face significant challenges in visual perception, particularly when
handling high-resolution, visually complex digital environments. This paper
introduces Iris, a foundational visual agent that addresses these challenges
through two key innovations: Information-Sensitive Cropping (ISC) and
Self-Refining Dual Learning (SRDL). ISC dynamically identifies and prioritizes
visually dense regions using a edge detection algorithm, enabling efficient
processing by allocating more computational resources to areas with higher
information density. SRDL enhances the agent's ability to handle complex tasks
by leveraging a dual-learning loop, where improvements in referring (describing
UI elements) reinforce grounding (locating elements) and vice versa, all
without requiring additional annotated data. Empirical evaluations demonstrate
that Iris achieves state-of-the-art performance across multiple benchmarks with
only 850K GUI annotations, outperforming methods using 10x more training data.
These improvements further translate to significant gains in both web and OS
agent downstream tasks.

摘要：數位代理人愈來愈常被用來自動化互動式數位環境中的任務，例如網頁、軟體應用程式和作業系統。雖然建立在大型語言模型 (LLM) 上的文字代理人通常需要頻繁更新，以符合特定平台的 API，但利用多模態大型語言模型 (MLLM) 的視覺代理人透過直接與圖形使用者介面 (GUI) 互動，提供增強的適應性。然而，這些代理人在視覺感知方面面臨重大挑戰，特別是在處理高解析度、視覺複雜的數位環境時。本文介紹 Iris，這是一個基礎視覺代理人，透過兩項主要創新來解決這些挑戰：資訊敏感裁切 (ISC) 和自我精進雙重學習 (SRDL)。ISC 使用邊緣偵測演算法動態識別和優先處理視覺密集區域，透過將更多運算資源配置到資訊密度較高的區域，實現有效率的處理。SRDL 透過利用雙重學習迴圈來增強代理人處理複雜任務的能力，其中參照（描述 UI 元素）的改進強化了基礎（定位元素），反之亦然，而且所有這些都不需要額外的註解資料。經驗評估顯示，Iris 僅使用 850K GUI 註解，就在多個基準測試中達到最先進的效能，表現優於使用多 10 倍訓練資料的方法。這些改進進一步轉化為網頁和作業系統代理人下游任務的顯著收益。

##### **Generative AI in Medicine**
2412.10337v1 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

摘要：生成式 AI 的能力提升大幅擴展了其在醫學中的潛在應用案例。我們提供了一個全面的概觀，說明生成式 AI 在臨床醫生、患者、臨床試驗組織者、研究人員和受訓人員的應用案例。接著，我們討論了許多挑戰，包括維護隱私和安全性、提升透明度和可解釋性、維護公平性，以及嚴格評估模型，這些挑戰必須克服才能實現這種潛力，以及它們引發的開放研究方向。

##### **AdvPrefix: An Objective for Nuanced LLM Jailbreaks**
2412.10321v1 by Sicheng Zhu, Brandon Amos, Yuandong Tian, Chuan Guo, Ivan Evtimov

Many jailbreak attacks on large language models (LLMs) rely on a common
objective: making the model respond with the prefix "Sure, here is (harmful
request)". While straightforward, this objective has two limitations: limited
control over model behaviors, often resulting in incomplete or unrealistic
responses, and a rigid format that hinders optimization. To address these
limitations, we introduce AdvPrefix, a new prefix-forcing objective that
enables more nuanced control over model behavior while being easy to optimize.
Our objective leverages model-dependent prefixes, automatically selected based
on two criteria: high prefilling attack success rates and low negative
log-likelihood. It can further simplify optimization by using multiple prefixes
for a single user request. AdvPrefix can integrate seamlessly into existing
jailbreak attacks to improve their performance for free. For example, simply
replacing GCG attack's target prefixes with ours on Llama-3 improves nuanced
attack success rates from 14% to 80%, suggesting that current alignment
struggles to generalize to unseen prefixes. Our work demonstrates the
importance of jailbreak objectives in achieving nuanced jailbreaks.

摘要：許多針對大型語言模型 (LLM) 的越獄攻擊都依賴於一個共同目標：讓模型以「好的，以下是 (有害請求)」的前綴回應。雖然直接了當，但此目標有兩個限制：對模型行為的控制有限，通常會導致不完整或不切實際的回應，以及阻礙最佳化的僵化格式。為了解決這些限制，我們引入了 AdvPrefix，這是一個新的前綴強制目標，可以在易於最佳化的同時，對模型行為進行更細緻的控制。我們的目標利用了依據兩個標準自動選取的模型依賴前綴：高預填充攻擊成功率和低負對數似然度。它可以透過對單一使用者請求使用多個前綴，進一步簡化最佳化。AdvPrefix 可以無縫整合到現有的越獄攻擊中，以免費提升其效能。例如，僅僅用我們 Llama-3 上的目標前綴取代 GCG 攻擊的目標前綴，就能將細緻的攻擊成功率從 14% 提升至 80%，這表示目前的比對難以概括到未見的前綴。我們的研究展示了越獄目標在達成細緻越獄中的重要性。

##### **SCBench: A KV Cache-Centric Analysis of Long-Context Methods**
2412.10319v1 by Yucheng Li, Huiqiang Jiang, Qianhui Wu, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu

Long-context LLMs have enabled numerous downstream applications but also
introduced significant challenges related to computational and memory
efficiency. To address these challenges, optimizations for long-context
inference have been developed, centered around the KV cache. However, existing
benchmarks often evaluate in single-request, neglecting the full lifecycle of
the KV cache in real-world use. This oversight is particularly critical, as KV
cache reuse has become widely adopted in LLMs inference frameworks, such as
vLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,
Google, and Anthropic. To address this gap, we introduce
SCBench(SharedContextBench), a comprehensive benchmark for evaluating
long-context methods from a KV cachecentric perspective: 1) KV cache
generation, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache
loading. Specifically, SCBench uses test examples with shared context, ranging
12 tasks with two shared context modes, covering four categories of
long-context capabilities: string retrieval, semantic retrieval, global
information, and multi-task. With it, we provide an extensive KV cache-centric
analysis of eight categories long-context solutions, including Gated Linear
RNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,
KV cache dropping, quantization, retrieval, loading, and prompt compression.
The evaluation is conducted on 8 long-context LLMs. Our findings show that
sub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding
with O(n) memory and sub-O(n^2) pre-filling computation perform robustly.
Dynamic sparsity yields more expressive KV caches than static patterns, and
layer-level sparsity in hybrid architectures reduces memory usage with strong
performance. Additionally, we identify attention distribution shift issues in
long-generation scenarios. https://aka.ms/SCBench.

摘要：長語境 LLM 已啟用許多下游應用程式，但也引入了與運算和記憶體效率相關的重大挑戰。為了應對這些挑戰，已針對長語境推論開發最佳化，集中在 KV 快取上。然而，現有的基準測試通常在單一要求中進行評估，忽略了 KV 快取在實際使用中的完整生命週期。這種疏忽特別關鍵，因為 KV 快取重複使用已在 LLM 推論架構中廣泛採用，例如 vLLM 和 SGLang，以及 LLM 供應商，包括 OpenAI、Microsoft、Google 和 Anthropic。為了解決這個差距，我們引入了 SCBench（SharedContextBench），這是一個全面的基準測試，用 KV 快取為中心的觀點評估長語境方法：1) KV 快取產生，2) KV 快取壓縮，3) KV 快取擷取，4) KV 快取載入。具體來說，SCBench 使用具有共用語境的測試範例，範圍涵蓋兩種共用語境模式的 12 個任務，涵蓋長語境功能的四種類別：字串擷取、語意擷取、全域資訊和多任務。透過它，我們提供了對八種類別長語境解決方案的廣泛 KV 快取為中心分析，包括閘控線性 RNN、Mamba-Attention 混合體，以及稀疏注意力、KV 快取捨棄、量化、擷取、載入和提示壓縮等有效方法。評估是在 8 個長語境 LLM 上進行的。我們的研究結果顯示，sub-O(n) 記憶體方法在多輪情況下會受到影響，而具有 O(n) 記憶體和 sub-O(n^2) 預先填入運算的稀疏編碼則表現得很好。動態稀疏性產生比靜態模式更具表現力的 KV 快取，而混合架構中的層級稀疏性則以強勁的效能降低記憶體使用量。此外，我們在長生成情況中發現了注意力分佈轉移問題。https://aka.ms/SCBench。

##### **BrushEdit: All-In-One Image Inpainting and Editing**
2412.10316v1 by Yaowei Li, Yuxuan Bian, Xuan Ju, Zhaoyang Zhang, Ying Shan, Qiang Xu

Image editing has advanced significantly with the development of diffusion
models using both inversion-based and instruction-based methods. However,
current inversion-based approaches struggle with big modifications (e.g.,
adding or removing objects) due to the structured nature of inversion noise,
which hinders substantial changes. Meanwhile, instruction-based methods often
constrain users to black-box operations, limiting direct interaction for
specifying editing regions and intensity. To address these limitations, we
propose BrushEdit, a novel inpainting-based instruction-guided image editing
paradigm, which leverages multimodal large language models (MLLMs) and image
inpainting models to enable autonomous, user-friendly, and interactive
free-form instruction editing. Specifically, we devise a system enabling
free-form instruction editing by integrating MLLMs and a dual-branch image
inpainting model in an agent-cooperative framework to perform editing category
classification, main object identification, mask acquisition, and editing area
inpainting. Extensive experiments show that our framework effectively combines
MLLMs and inpainting models, achieving superior performance across seven
metrics including mask region preservation and editing effect coherence.

摘要：影像編輯隨著使用基於反演和基於指令方法的擴散模型的發展而顯著進步。然而，當前的基於反演的方法由於反演雜訊的結構性質而難以進行大幅修改（例如，增加或移除物件），這阻礙了實質性的變更。同時，基於指令的方法通常限制使用者只能進行黑盒子操作，限制了直接互動以指定編輯區域和強度。為了解決這些限制，我們提出了 BrushEdit，一種新穎的基於內插的指令引導影像編輯範例，它利用多模態大型語言模型 (MLLM) 和影像內插模型來實現自主、使用者友善且互動的自由形式指令編輯。具體來說，我們設計了一個系統，透過整合 MLLM 和一個雙分支影像內插模型在一個代理合作架構中來執行編輯類別分類、主物件識別、遮罩擷取和編輯區域內插，從而實現自由形式指令編輯。廣泛的實驗表明，我們的架構有效地結合了 MLLM 和內插模型，在七項指標中實現了卓越的效能，包括遮罩區域保留和編輯效果一致性。

##### **Interlocking-free Selective Rationalization Through Genetic-based Learning**
2412.10312v1 by Federico Ruggeri, Gaetano Signorelli

A popular end-to-end architecture for selective rationalization is the
select-then-predict pipeline, comprising a generator to extract highlights fed
to a predictor. Such a cooperative system suffers from suboptimal equilibrium
minima due to the dominance of one of the two modules, a phenomenon known as
interlocking. While several contributions aimed at addressing interlocking,
they only mitigate its effect, often by introducing feature-based heuristics,
sampling, and ad-hoc regularizations. We present GenSPP, the first
interlocking-free architecture for selective rationalization that does not
require any learning overhead, as the above-mentioned. GenSPP avoids
interlocking by performing disjoint training of the generator and predictor via
genetic global search. Experiments on a synthetic and a real-world benchmark
show that our model outperforms several state-of-the-art competitors.

摘要：選擇式簡化的一種流行端對端架構是選擇再預測管線，包含一個產生器用於萃取亮點並提供給預測器。這種合作系統會因兩個模組之一的支配而導致次佳平衡極小值，這種現象稱為互鎖。雖然有許多貢獻旨在解決互鎖，但它們僅能減輕其影響，通常是透過引入基於特徵的啟發法、取樣和特定規範化。我們提出 GenSPP，這是第一個無互鎖架構，用於選擇式簡化，不需要任何學習開銷，如上述。GenSPP 透過遺傳全球搜尋執行產生器和預測器的分離訓練，來避免互鎖。在合成和真實世界基準上的實驗顯示，我們的模型優於多個最先進的競爭者。

##### **DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding**
2412.10302v1 by Zhiyu Wu, Xiaokang Chen, Zizheng Pan, Xingchao Liu, Wen Liu, Damai Dai, Huazuo Gao, Yiyang Ma, Chengyue Wu, Bingxuan Wang, Zhenda Xie, Yu Wu, Kai Hu, Jiawei Wang, Yaofeng Sun, Yukun Li, Yishi Piao, Kang Guan, Aixin Liu, Xin Xie, Yuxiang You, Kai Dong, Xingkai Yu, Haowei Zhang, Liang Zhao, Yisong Wang, Chong Ruan

We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)
Vision-Language Models that significantly improves upon its predecessor,
DeepSeek-VL, through two key major upgrades. For the vision component, we
incorporate a dynamic tiling vision encoding strategy designed for processing
high-resolution images with different aspect ratios. For the language
component, we leverage DeepSeekMoE models with the Multi-head Latent Attention
mechanism, which compresses Key-Value cache into latent vectors, to enable
efficient inference and high throughput. Trained on an improved vision-language
dataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,
including but not limited to visual question answering, optical character
recognition, document/table/chart understanding, and visual grounding. Our
model series is composed of three variants: DeepSeek-VL2-Tiny,
DeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated
parameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art
performance with similar or fewer activated parameters compared to existing
open-source dense and MoE-based models. Codes and pre-trained models are
publicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.

摘要：我們提出了 DeepSeek-VL2，這是一個先進的大型混合專家 (MoE) 系列視覺語言模型，透過兩項主要升級，大幅改進其前身 DeepSeek-VL。對於視覺元件，我們結合動態拼貼視覺編碼策略，旨在處理具有不同長寬比的高解析度影像。對於語言元件，我們利用具備多頭潛在注意力機制的 DeepSeekMoE 模型，將鍵值快取壓縮成潛在向量，以實現有效率的推論和高通量。在改良的視覺語言資料集上進行訓練，DeepSeek-VL2 在各種任務中展現出優異的能力，包括但不限於視覺問題解答、光學字元辨識、文件/表格/圖表理解和視覺基礎。我們的模型系列由三種變體組成：DeepSeek-VL2-Tiny、DeepSeek-VL2-Small 和 DeepSeek-VL2，分別具有 1.0B、2.8B 和 4.5B 個已啟用的參數。與現有的開源密集和基於 MoE 的模型相比，DeepSeek-VL2 以相同或更少的已啟用參數，取得具競爭力或最先進的效能。程式碼和預訓練模型可在 https://github.com/deepseek-ai/DeepSeek-VL2 公開取得。

##### **Still "Talking About Large Language Models": Some Clarifications**
2412.10291v1 by Murray Shanahan

My paper "Talking About Large Language Models" has more than once been
interpreted as advocating a reductionist stance towards large language models.
But the paper was not intended that way, and I do not endorse such positions.
This short note situates the paper in the context of a larger philosophical
project that is concerned with the (mis)use of words rather than metaphysics,
in the spirit of Wittgenstein's later writing.

摘要：我的論文「談大型語言模型」已不止一次被解讀為主張對大型語言模型採取還原論立場。但這篇論文並非如此用意，我也不認同這種立場。這篇簡短的註解將這篇論文定位在一個較大的哲學專案的背景下，這個專案關注的是（誤）用詞彙，而非形上學，並秉持維根斯坦後期著作的精神。

##### **One world, one opinion? The superstar effect in LLM responses**
2412.10281v1 by Sofie Goethals, Lauren Rhue

As large language models (LLMs) are shaping the way information is shared and
accessed online, their opinions have the potential to influence a wide
audience. This study examines who the LLMs view as the most prominent figures
across various fields, using prompts in ten different languages to explore the
influence of linguistic diversity. Our findings reveal low diversity in
responses, with a small number of figures dominating recognition across
languages (also known as the "superstar effect"). These results highlight the
risk of narrowing global knowledge representation when LLMs retrieve subjective
information.

摘要：隨著大型語言模型 (LLM) 形塑線上資訊分享與取得的方式，它們的觀點有潛力影響廣大受眾。本研究使用十種不同語言的提示來探討語言多樣性的影響，探討 LLM 視為各領域最傑出人物的人選。我們的研究結果顯示，回應的多樣性低，少數人物在各語言中都獲得極高的認可（也稱為「超級巨星效應」）。這些結果凸顯了當 LLM 擷取主觀資訊時，全球知識呈現可能會過於狹隘的風險。

##### **Envisioning National Resources for Artificial Intelligence Research: NSF Workshop Report**
2412.10278v1 by Shantenu Jha, Yolanda Gil

This is a report of an NSF workshop titled "Envisioning National Resources
for Artificial Intelligence Research" held in Alexandria, Virginia, in May
2024. The workshop aimed to identify initial challenges and opportunities for
national resources for AI research (e.g., compute, data, models, etc.) and to
facilitate planning for the envisioned National AI Research Resource.
Participants included AI and cyberinfrastructure (CI) experts. The report
outlines significant findings and identifies needs and recommendations from the
workshop.

摘要：這份報告是 NSF 工作坊的報告，標題為「構想人工智慧研究的國家資源」，於 2024 年 5 月在維吉尼亞州亞歷山卓市舉行。該工作坊旨在找出國家 AI 研究資源（例如運算、資料、模型等）的初步挑戰和機會，並促進規劃構想中的國家 AI 研究資源。參與者包括 AI 和網路基礎建設 (CI) 專家。這份報告概述了重要的發現，並找出工作坊的需求和建議。

##### **Benchmarking Linguistic Diversity of Large Language Models**
2412.10271v1 by Yanzhu Guo, Guokan Shang, Chloé Clavel

The development and evaluation of Large Language Models (LLMs) has primarily
focused on their task-solving capabilities, with recent models even surpassing
human performance in some areas. However, this focus often neglects whether
machine-generated language matches the human level of diversity, in terms of
vocabulary choice, syntactic construction, and expression of meaning, raising
questions about whether the fundamentals of language generation have been fully
addressed. This paper emphasizes the importance of examining the preservation
of human linguistic richness by language models, given the concerning surge in
online content produced or aided by LLMs. We propose a comprehensive framework
for evaluating LLMs from various linguistic diversity perspectives including
lexical, syntactic, and semantic dimensions. Using this framework, we benchmark
several state-of-the-art LLMs across all diversity dimensions, and conduct an
in-depth case study for syntactic diversity. Finally, we analyze how different
development and deployment choices impact the linguistic diversity of LLM
outputs.

摘要：大型語言模型 (LLM) 的開發和評估主要集中於其解決任務的能力，最近的模型甚至在某些領域超越了人類的表現。然而，這種關注往往忽略了機器產生的語言在詞彙選擇、句法結構和意義表達方面的多樣性是否達到人類的水平，這引發了關於語言生成的基本原理是否已得到充分解決的問題。本文強調了在 LLM 生產或輔助的線上內容激增的情況下，檢視語言模型對人類語言豐富性的保留的重要性。我們提出了一個全面的框架，從詞彙、句法和語義維度等各種語言多樣性角度評估 LLM。使用這個框架，我們對所有多樣性維度進行了數個最先進的 LLM 基準測試，並對句法多樣性進行了深入的案例研究。最後，我們分析了不同的開發和部署選擇如何影響 LLM 輸出的語言多樣性。

##### **Cultural Evolution of Cooperation among LLM Agents**
2412.10270v1 by Aron Vallinder, Edward Hughes

Large language models (LLMs) provide a compelling foundation for building
generally-capable AI agents. These agents may soon be deployed at scale in the
real world, representing the interests of individual humans (e.g., AI
assistants) or groups of humans (e.g., AI-accelerated corporations). At
present, relatively little is known about the dynamics of multiple LLM agents
interacting over many generations of iterative deployment. In this paper, we
examine whether a "society" of LLM agents can learn mutually beneficial social
norms in the face of incentives to defect, a distinctive feature of human
sociality that is arguably crucial to the success of civilization. In
particular, we study the evolution of indirect reciprocity across generations
of LLM agents playing a classic iterated Donor Game in which agents can observe
the recent behavior of their peers. We find that the evolution of cooperation
differs markedly across base models, with societies of Claude 3.5 Sonnet agents
achieving significantly higher average scores than Gemini 1.5 Flash, which, in
turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an
additional mechanism for costly punishment to achieve yet higher scores, while
Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also
observe variation in emergent behavior across random seeds, suggesting an
understudied sensitive dependence on initial conditions. We suggest that our
evaluation regime could inspire an inexpensive and informative new class of LLM
benchmarks, focussed on the implications of LLM agent deployment for the
cooperative infrastructure of society.

摘要：大型語言模型 (LLM) 為建構具備一般能力的 AI 代理提供了令人信服的基礎。這些代理人可能很快就會在現實世界中大規模部署，代表個人人類（例如，AI 助理）或人類群體（例如，AI 加速公司）的利益。目前，對於多個 LLM 代理在多代疊代部署中互動的動態知之甚少。在本文中，我們探討了一個 LLM 代理「社會」是否能夠在背叛誘因面前學習到對彼此有益的社會規範，這是人類社會性的一個顯著特徵，可以說是文明成功的重要關鍵。特別是，我們研究了 LLM 代理在經典的重複捐贈者遊戲中跨世代的間接互惠演變，在該遊戲中，代理人可以觀察到同儕最近的行為。我們發現合作的演變在基礎模型之間有顯著差異，Claude 3.5 Sonnet 代理的社會比 Gemini 1.5 Flash 獲得顯著更高的平均分數，而後者又優於 GPT-4o。此外，Claude 3.5 Sonnet 可以利用額外的代價懲罰機制來獲得更高的分數，而 Gemini 1.5 Flash 和 GPT-4o 則無法做到這一點。對於每個模型類別，我們還觀察到隨機種子中出現行為的變化，這表明對初始條件的敏感依賴性尚未得到充分研究。我們建議我們的評估制度可以激勵一種廉價且有益的新型 LLM 基準，專注於 LLM 代理部署對社會合作基礎設施的影響。

##### **Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT**
2412.10267v1 by Danielle R. Thomas, Conrad Borchers, Sanjit Kakarla, Jionghao Lin, Shambhavi Bhushan, Boyuan Guo, Erin Gatz, Kenneth R. Koedinger

The role of multiple-choice questions (MCQs) as effective learning tools has
been debated in past research. While MCQs are widely used due to their ease in
grading, open response questions are increasingly used for instruction, given
advances in large language models (LLMs) for automated grading. This study
evaluates MCQs effectiveness relative to open-response questions, both
individually and in combination, on learning. These activities are embedded
within six tutor lessons on advocacy. Using a posttest-only randomized control
design, we compare the performance of 234 tutors (790 lesson completions)
across three conditions: MCQ only, open response only, and a combination of
both. We find no significant learning differences across conditions at
posttest, but tutors in the MCQ condition took significantly less time to
complete instruction. These findings suggest that MCQs are as effective, and
more efficient, than open response tasks for learning when practice time is
limited. To further enhance efficiency, we autograded open responses using
GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of
low-stakes assessment, though further research is needed for broader use. This
study contributes a dataset of lesson log data, human annotation rubrics, and
LLM prompts to promote transparency and reproducibility.

摘要：多選題 (MCQ) 作為有效的學習工具的角色在過去的研究中一直備受爭議。雖然 MCQ 因其易於評分而被廣泛使用，但隨著大型語言模型 (LLM) 在自動評分方面的進步，開放式問題正越來越被用於教學。本研究評估了 MCQ 相對於開放式問題的有效性，無論是單獨還是組合，對學習的影響。這些活動嵌入在六個關於倡導的輔導課程中。使用僅限後測的隨機對照設計，我們比較了 234 位輔導員 (790 個課程完成) 在三種條件下的表現：僅 MCQ、僅開放式回應以及兩者的組合。我們發現後測時各條件之間沒有顯著的學習差異，但在 MCQ 條件下的輔導員完成教學所需的時間顯著減少。這些發現表明，當練習時間有限時，MCQ 與開放式任務一樣有效，而且效率更高。為了進一步提高效率，我們使用 GPT-4o 和 GPT-4-turbo 自動評分開放式回應。GPT 模型展示了低風險評估目的的熟練度，儘管需要進一步的研究以更廣泛地使用。本研究提供了一組課程日誌數據、人工註釋準則和 LLM 提示，以促進透明度和可複製性。

##### **Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media**
2412.10266v1 by Jiaqing Yuan, Ruijie Xi, Munindar P. Singh

Stance detection is crucial for fostering a human-centric Web by analyzing
user-generated content to identify biases and harmful narratives that undermine
trust. With the development of Large Language Models (LLMs), existing
approaches treat stance detection as a classification problem, providing robust
methodologies for modeling complex group interactions and advancing
capabilities in natural language tasks. However, these methods often lack
interpretability, limiting their ability to offer transparent and
understandable justifications for predictions. This study adopts a generative
approach, where stance predictions include explicit, interpretable rationales,
and integrates them into smaller language models through single-task and
multitask learning. We find that incorporating reasoning into stance detection
enables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot
performance, achieving an improvement of up to 9.57%. Moreover, our results
show that reasoning capabilities enhance multitask learning performance but may
reduce effectiveness in single-task settings. Crucially, we demonstrate that
faithful rationales improve rationale distillation into SLMs, advancing efforts
to build interpretable, trustworthy systems for addressing discrimination,
fostering trust, and promoting equitable engagement on social media.

摘要：立場偵測對於促進以人為本的網路至關重要，透過分析使用者產生的內容來辨識破壞信任的偏見和有害敘述。隨著大型語言模型 (LLM) 的發展，現有的方法將立場偵測視為分類問題，提供強健的方法來建模複雜的群體互動，並提升自然語言任務的能力。然而，這些方法通常缺乏可解釋性，限制了它們提供透明且可理解的預測依據的能力。本研究採用生成式方法，其中立場預測包括明確、可解釋的依據，並透過單一任務和多任務學習將它們整合到較小的語言模型中。我們發現將推理納入立場偵測能讓較小的模型 (FlanT5) 優於 GPT-3.5 的零次學習效能，提升幅度最高達 9.57%。此外，我們的結果顯示推理能力提升了多任務學習效能，但可能降低單一任務設定中的效能。至關重要的是，我們證明忠實的依據能改善將依據萃取到 SLM 中，促進建構可解釋、值得信賴的系統，以解決歧視、建立信任，並在社群媒體上推廣公平的參與。

##### **Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models**
2412.10257v1 by Harry J. Davies, Giorgos Iacovides, Danilo P. Mandic

The sheer scale of data required to train modern large language models (LLMs)
poses significant risks, as models are likely to gain knowledge of sensitive
topics such as bio-security, as well the ability to replicate copyrighted
works. Methods designed to remove such knowledge must do so from all prompt
directions, in a multi-lingual capacity and without degrading general model
performance. To this end, we introduce the targeted angular reversal (TARS)
method of knowledge removal from LLMs. The TARS method firstly leverages the
LLM in combination with a detailed prompt to aggregate information about a
selected concept in the internal representation space of the LLM. It then
refines this approximate concept vector to trigger the concept token with high
probability, by perturbing the approximate concept vector with noise and
transforming it into token scores with the language model head. The feedforward
weight vectors in the LLM which operate directly on the internal representation
space, and have the highest cosine similarity with this targeting vector, are
then replaced by a reversed targeting vector, thus limiting the ability of the
concept to propagate through the model. The modularity of the TARS method
allows for a sequential removal of concepts from Llama 3.1 8B, such as the
famous literary detective Sherlock Holmes, and the planet Saturn. It is
demonstrated that the probability of triggering target concepts can be reduced
to 0.00 with as few as 1 TARS edit, whilst simultaneously removing the
knowledge bi-directionally. Moreover, knowledge is shown to be removed across
all languages despite only being targeted in English. Importantly, TARS has
minimal impact on the general model capabilities, as after removing 5 diverse
concepts in a modular fashion, there is minimal KL divergence in the next token
probabilities of the LLM on large corpora of Wikipedia text (median of 0.002).

摘要：<paragraph>訓練現代大型語言模型 (LLM) 所需的龐大數據規模帶來重大風險，因為模型很可能會獲取敏感主題的知識，例如生物安全，以及複製受版權保護作品的能力。旨在移除此類知識的方法必須從所有提示方向以多語言方式執行此操作，且不會降低一般模型效能。為此，我們引入了從 LLM 中移除知識的目標角反轉 (TARS) 方法。TARS 方法首先利用 LLM 結合詳細提示，在 LLM 的內部表示空間中彙整有關所選概念的資訊。然後，它會微調此近似概念向量，藉由使用雜訊擾動近似概念向量，並使用語言模型頭將其轉換為代幣分數，以高機率觸發概念代幣。在 LLM 中直接作用於內部表示空間，且與此目標向量具有最高餘弦相似度的前饋權重向量，隨後會被反向目標向量取代，因此限制了概念在模型中傳播的能力。TARS 方法的模組化允許從 Llama 3.1 8B 中循序移除概念，例如著名的文學偵探夏洛克福爾摩斯和土星。結果表明，觸發目標概念的機率可以透過少至 1 次 TARS 編輯降低至 0.00，同時雙向移除知識。此外，儘管僅以英文為目標，但已顯示知識已跨所有語言移除。重要的是，TARS 對一般模型功能的影響很小，因為在以模組化方式移除 5 個不同的概念後，LLM 在大量維基百科文字中的下一個代幣機率的 KL 分歧很小（中位數為 0.002）。</paragraph>

##### **Exploring the Frontiers of Animation Video Generation in the Sora Era: Method, Dataset and Benchmark**
2412.10255v1 by Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun

Animation has gained significant interest in the recent film and TV industry.
Despite the success of advanced video generation models like Sora, Kling, and
CogVideoX in generating natural videos, they lack the same effectiveness in
handling animation videos. Evaluating animation video generation is also a
great challenge due to its unique artist styles, violating the laws of physics
and exaggerated motions. In this paper, we present a comprehensive system,
AniSora, designed for animation video generation, which includes a data
processing pipeline, a controllable generation model, and an evaluation
dataset. Supported by the data processing pipeline with over 10M high-quality
data, the generation model incorporates a spatiotemporal mask module to
facilitate key animation production functions such as image-to-video
generation, frame interpolation, and localized image-guided animation. We also
collect an evaluation benchmark of 948 various animation videos, the evaluation
on VBench and human double-blind test demonstrates consistency in character and
motion, achieving state-of-the-art results in animation video generation. %We
also collect an evaluation benchmark of 948 various animation videos, with
specifically developed metrics for animation video generation. Our model access
API and evaluation benchmark will be publicly available.

摘要：動畫在最近的電影和電視產業中獲得了顯著的關注。
儘管像 Sora、Kling 和 CogVideoX 這樣的先進影片生成模型在生成自然影片方面取得了成功，但在處理動畫影片方面卻缺乏相同的效能。由於其獨特的藝術風格、違反物理定律和誇張的動作，評估動畫影片生成也是一個巨大的挑戰。在本文中，我們提出了一個全面的系統 AniSora，專門用於動畫影片生成，其中包括一個資料處理管線、一個可控的生成模型和一個評估資料集。在擁有超過 10M 高品質資料的資料處理管線的支援下，生成模型結合了時空遮罩模組，以促進關鍵動畫製作功能，例如影像轉影片生成、幀插補和局部影像導向動畫。我們還收集了一個由 948 個各種動畫影片組成的評估基準，在 VBench 和人類雙盲測試上的評估證明了角色和動作的一致性，在動畫影片生成中取得了最先進的成果。% 我們還收集了一個由 948 個各種動畫影片組成的評估基準，並為動畫影片生成特別開發了指標。我們的模型存取 API 和評估基準將公開提供。

##### **Efficient Continual Pre-training of LLMs for Low-resource Languages**
2412.10244v1 by Arijit Nag, Soumen Chakrabarti, Animesh Mukherjee, Niloy Ganguly

Open-source Large Language models (OsLLMs) propel the democratization of
natural language research by giving the flexibility to augment or update model
parameters for performance improvement. Nevertheless, like proprietary LLMs,
Os-LLMs offer poorer performance on low-resource languages (LRLs) than
high-resource languages (HRLs), owing to smaller amounts of training data and
underrepresented vocabulary. On the other hand, continual pre-training (CPT)
with large amounts of language-specific data is a costly proposition in terms
of data acquisition and computational resources. Our goal is to drastically
reduce CPT cost. To that end, we first develop a new algorithm to select a
subset of texts from a larger corpus. We show the effectiveness of our
technique using very little CPT data. In search of further improvement, we
design a new algorithm to select tokens to include in the LLM vocabulary. We
experiment with the recent Llama-3 model and nine Indian languages with diverse
scripts and extent of resource availability. For evaluation, we use
IndicGenBench, a generation task benchmark dataset for Indic languages. We
experiment with various CPT corpora and augmented vocabulary size and offer
insights across language families.

摘要：開放原始碼大型語言模型 (OsLLM) 推動自然語言研究的民主化，讓模型參數可以靈活地擴充或更新以提升效能。儘管如此，與專有 LLM 類似，由於訓練資料量較少且詞彙量不足，Os-LLM 在低資源語言 (LRL) 上的表現比高資源語言 (HRL) 差。另一方面，針對特定語言資料進行持續預訓練 (CPT) 在資料取得和運算資源方面是一項昂貴的提議。我們的目標是大幅降低 CPT 成本。為此，我們首先開發一種新演算法，從較大的語料庫中選取一個子集的文字。我們使用極少的 CPT 資料來展示我們技術的有效性。為了進一步改進，我們設計一種新演算法來選取要包含在 LLM 詞彙中的詞彙。我們使用最新的 Llama-3 模型和九種印度語言進行實驗，這些語言具有不同的文字系統和資源可用性程度。在評估方面，我們使用 IndicGenBench，這是一個針對印度語言的產生任務基準資料集。我們使用各種 CPT 語料庫和擴充的詞彙量進行實驗，並提供跨語言系列的見解。

##### **Physics Instrument Design with Reinforcement Learning**
2412.10237v1 by Shah Rukh Qasim, Patrick Owen, Nicola Serra

We present a case for the use of Reinforcement Learning (RL) for the design
of physics instrument as an alternative to gradient-based
instrument-optimization methods. It's applicability is demonstrated using two
empirical studies. One is longitudinal segmentation of calorimeters and the
second is both transverse segmentation as well longitudinal placement of
trackers in a spectrometer. Based on these experiments, we propose an
alternative approach that offers unique advantages over differentiable
programming and surrogate-based differentiable design optimization methods.
First, Reinforcement Learning (RL) algorithms possess inherent exploratory
capabilities, which help mitigate the risk of convergence to local optima.
Second, this approach eliminates the necessity of constraining the design to a
predefined detector model with fixed parameters. Instead, it allows for the
flexible placement of a variable number of detector components and facilitates
discrete decision-making. We then discuss the road map of how this idea can be
extended into designing very complex instruments. The presented study sets the
stage for a novel framework in physics instrument design, offering a scalable
and efficient framework that can be pivotal for future projects such as the
Future Circular Collider (FCC), where most optimized detectors are essential
for exploring physics at unprecedented energy scales.

摘要：我們提出一個案例，說明使用強化學習 (RL) 來設計物理儀器，作為基於梯度的儀器最佳化方法的替代方案。它的適用性已通過兩項實證研究得到證實。一個是量熱器的縱向分割，另一個是橫向分割和光譜儀中追蹤器的縱向放置。基於這些實驗，我們提出了一種替代方法，它比可微分程式設計和基於代理的可微分設計最佳化方法具有獨特優勢。首先，強化學習 (RL) 演算法具有內在的探索能力，有助於降低收斂到局部最優的風險。其次，這種方法消除了將設計限制在具有固定參數的預定義偵測器模型的必要性。相反，它允許靈活放置可變數量的偵測器組件，並促進離散決策制定。然後，我們討論了如何將這個想法擴展到設計非常複雜的儀器的路線圖。提出的研究為物理儀器設計中的新框架奠定了基礎，提供了一個可擴充且高效的框架，對於未來的專案（例如未來環形對撞機 (FCC)）至關重要，在這些專案中，最最佳化的偵測器對於探索前所未有的能量尺度的物理現象至關重要。

##### **How good is my story? Towards quantitative metrics for evaluating LLM-generated XAI narratives**
2412.10220v1 by Timour Ichmoukhamedov, James Hinns, David Martens

A rapidly developing application of LLMs in XAI is to convert quantitative
explanations such as SHAP into user-friendly narratives to explain the
decisions made by smaller prediction models. Evaluating the narratives without
relying on human preference studies or surveys is becoming increasingly
important in this field. In this work we propose a framework and explore
several automated metrics to evaluate LLM-generated narratives for explanations
of tabular classification tasks. We apply our approach to compare several
state-of-the-art LLMs across different datasets and prompt types. As a
demonstration of their utility, these metrics allow us to identify new
challenges related to LLM hallucinations for XAI narratives.

摘要：LLM 在 XAI 中快速發展的應用是將定量解釋（例如 SHAP）轉換為使用者友善的敘述，以解釋較小的預測模型所做的決策。在這個領域中，在不依賴人類偏好研究或調查的情況下評估敘述變得越來越重要。在這項工作中，我們提出一個架構並探討多種自動化指標，以評估 LLM 生成的敘述，用於解釋表格分類任務。我們應用我們的做法來比較不同資料集和提示類型中的幾個最先進的 LLM。作為其效用的示範，這些指標讓我們能夠找出與 XAI 敘述的 LLM 幻覺相關的新挑戰。

##### **GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion**
2412.10209v1 by Jiapeng Tang, Davide Davoli, Tobias Kirschstein, Liam Schoneveld, Matthias Niessner

We propose a novel approach for reconstructing animatable 3D Gaussian avatars
from monocular videos captured by commodity devices like smartphones.
Photorealistic 3D head avatar reconstruction from such recordings is
challenging due to limited observations, which leaves unobserved regions
under-constrained and can lead to artifacts in novel views. To address this
problem, we introduce a multi-view head diffusion model, leveraging its priors
to fill in missing regions and ensure view consistency in Gaussian splatting
renderings. To enable precise viewpoint control, we use normal maps rendered
from FLAME-based head reconstruction, which provides pixel-aligned inductive
biases. We also condition the diffusion model on VAE features extracted from
the input image to preserve details of facial identity and appearance. For
Gaussian avatar reconstruction, we distill multi-view diffusion priors by using
iteratively denoised images as pseudo-ground truths, effectively mitigating
over-saturation issues. To further improve photorealism, we apply latent
upsampling to refine the denoised latent before decoding it into an image. We
evaluate our method on the NeRSemble dataset, showing that GAF outperforms the
previous state-of-the-art methods in novel view synthesis by a 5.34\% higher
SSIM score. Furthermore, we demonstrate higher-fidelity avatar reconstructions
from monocular videos captured on commodity devices.

摘要：我們提出了一種創新的方法，用智慧型手機等商品設備所拍攝的單眼影片，重建出可動畫的 3D 高斯頭像。
從這類錄製影片中重建出逼真的 3D 頭像頭像具有挑戰性，因為觀察有限，這使得未觀察到的區域受到約束不足，並可能導致新視圖中出現人工製品。
為了解決這個問題，我們引入了多視圖頭部擴散模型，利用其先驗來填補缺失區域並確保高斯潑灑渲染中的視圖一致性。
為了實現精確的視點控制，我們使用了從基於 FLAME 的頭部重建所渲染的法線貼圖，它提供了像素對齊的歸納偏差。
我們還根據從輸入影像中提取的 VAE 特徵對擴散模型進行條件化，以保留面部特徵和外觀的細節。
對於高斯頭像重建，我們使用反覆降噪影像作為偽地面實況，來提取多視圖擴散先驗，有效地減輕過飽和問題。
為了進一步提高逼真度，我們應用潛在向上取樣來改善降噪潛在值，然後將其解碼成影像。
我們在 NeRSemble 資料集上評估了我們的方法，顯示 GAF 在新視圖合成中優於先前的最新方法，SSIM 分數高出 5.34%。
此外，我們展示了從商品設備上拍攝的單眼影片中重建出更高保真度的頭像。

##### **Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization**
2412.10207v1 by Xiao Zhang, Qianru Meng, Johan Bos

Open-domain semantic parsing remains a challenging task, as models often rely
on heuristics and struggle to handle unseen concepts. In this paper, we
investigate the potential of large language models (LLMs) for this task and
introduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective
approach that integrates external lexical knowledge into the parsing process.
Our experiments not only show that LLMs outperform previous encoder-decoder
baselines for semantic parsing, but that RASP further enhances their ability to
predict unseen concepts, nearly doubling the performance of previous models on
out-of-distribution concepts. These findings highlight the promise of
leveraging large language models and retrieval mechanisms for robust and
open-domain semantic parsing.

摘要：開放領域語義解析仍然是一項具有挑戰性的任務，因為模型通常依賴啟發法，並且難以處理未見過的概念。在本文中，我們探討大型語言模型 (LLM) 在這項任務中的潛力，並提出檢索增強語義解析 (RASP)，這是一種簡單但有效的方法，可以將外部詞彙知識整合到解析過程中。我們的實驗不僅表明 LLM 優於語義解析的先前編碼器 - 解碼器基線，而且 RASP 進一步增強了它們預測未見過概念的能力，幾乎將先前模型在分布外概念上的效能提高了一倍。這些發現突顯了利用大型語言模型和檢索機制進行強健且開放領域語義解析的潛力。

##### **From Allies to Adversaries: Manipulating LLM Tool-Calling through Adversarial Injection**
2412.10198v1 by Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang

Tool-calling has changed Large Language Model (LLM) applications by
integrating external tools, significantly enhancing their functionality across
diverse tasks. However, this integration also introduces new security
vulnerabilities, particularly in the tool scheduling mechanisms of LLM, which
have not been extensively studied. To fill this gap, we present ToolCommander,
a novel framework designed to exploit vulnerabilities in LLM tool-calling
systems through adversarial tool injection. Our framework employs a
well-designed two-stage attack strategy. Firstly, it injects malicious tools to
collect user queries, then dynamically updates the injected tools based on the
stolen information to enhance subsequent attacks. These stages enable
ToolCommander to execute privacy theft, launch denial-of-service attacks, and
even manipulate business competition by triggering unscheduled tool-calling.
Notably, the ASR reaches 91.67% for privacy theft and hits 100% for
denial-of-service and unscheduled tool calling in certain cases. Our work
demonstrates that these vulnerabilities can lead to severe consequences beyond
simple misuse of tool-calling systems, underscoring the urgent need for robust
defensive strategies to secure LLM Tool-calling systems.

摘要：工具呼叫已透過整合外部工具來改變大型語言模型 (LLM) 應用程式，大幅提升其在各種任務中的功能。不過，這種整合也引入了新的安全性漏洞，特別是在 LLM 的工具排程機制中，而這尚未獲得廣泛的研究。為了填補這個空白，我們提出 ToolCommander，這是一個新穎的架構，旨在透過對抗性的工具注入來利用 LLM 工具呼叫系統中的漏洞。我們的架構採用精心設計的兩階段攻擊策略。首先，它會注入惡意工具來收集使用者查詢，然後根據竊取的資訊動態更新注入的工具，以加強後續攻擊。這些階段讓 ToolCommander 能夠執行隱私竊取、發動阻斷服務攻擊，甚至透過觸發非預定的工具呼叫來操縱商業競爭。值得注意的是，在某些情況下，ASR 達到 91.67% 的隱私竊取，並達到 100% 的阻斷服務和非預定工具呼叫。我們的研究表明，這些漏洞可能會導致嚴重的後果，而這不只是工具呼叫系統的濫用，這強調了確保 LLM 工具呼叫系統安全的穩健防禦策略的迫切需求。

##### **Solving Robust Markov Decision Processes: Generic, Reliable, Efficient**
2412.10185v1 by Tobias Meggendorfer, Maximilian Weininger, Patrick Wienhöft

Markov decision processes (MDP) are a well-established model for sequential
decision-making in the presence of probabilities. In robust MDP (RMDP), every
action is associated with an uncertainty set of probability distributions,
modelling that transition probabilities are not known precisely. Based on the
known theoretical connection to stochastic games, we provide a framework for
solving RMDPs that is generic, reliable, and efficient. It is *generic* both
with respect to the model, allowing for a wide range of uncertainty sets,
including but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;
and with respect to the objective, including long-run average reward,
undiscounted total reward, and stochastic shortest path. It is *reliable*, as
our approach not only converges in the limit, but provides precision guarantees
at any time during the computation. It is *efficient* because -- in contrast to
state-of-the-art approaches -- it avoids explicitly constructing the underlying
stochastic game. Consequently, our prototype implementation outperforms
existing tools by several orders of magnitude and can solve RMDPs with a
million states in under a minute.

摘要：馬可夫決策過程 (MDP) 是一種在機率存在的情況下進行順序決策的既定模型。在強健 MDP (RMDP) 中，每個動作都與機率分佈的不確定性集合相關，建模為轉移機率並非精確已知。根據已知的與隨機博弈的理論連結，我們提供了一個解決 RMDP 的架構，它具有通用性、可靠性與效率。它在模型方面是「通用的」，允許使用廣泛的不確定性集合，包括但不限於區間、$L^1$ 或 $L^2$ 球體和多面體；在目標方面也是通用的，包括長期平均獎勵、未貼現總獎勵和隨機最短路徑。它很「可靠」，因為我們的做法不僅會在極限中收斂，還會在運算過程中隨時提供精確度保證。它很「有效」，因為與最先進的做法相反，它避免明確建構基礎隨機博弈。因此，我們的原型實作在幾個數量級上都優於現有工具，而且可以在不到一分鐘的時間內解決擁有數百萬個狀態的 RMDP。

##### **Multi-Head Encoding for Extreme Label Classification**
2412.10182v1 by Daojun Liang, Haixia Zhang, Dongfeng Yuan, Minggao Zhang

The number of categories of instances in the real world is normally huge, and
each instance may contain multiple labels. To distinguish these massive labels
utilizing machine learning, eXtreme Label Classification (XLC) has been
established. However, as the number of categories increases, the number of
parameters and nonlinear operations in the classifier also rises. This results
in a Classifier Computational Overload Problem (CCOP). To address this, we
propose a Multi-Head Encoding (MHE) mechanism, which replaces the vanilla
classifier with a multi-head classifier. During the training process, MHE
decomposes extreme labels into the product of multiple short local labels, with
each head trained on these local labels. During testing, the predicted labels
can be directly calculated from the local predictions of each head. This
reduces the computational load geometrically. Then, according to the
characteristics of different XLC tasks, e.g., single-label, multi-label, and
model pretraining tasks, three MHE-based implementations, i.e., Multi-Head
Product, Multi-Head Cascade, and Multi-Head Sampling, are proposed to more
effectively cope with CCOP. Moreover, we theoretically demonstrate that MHE can
achieve performance approximately equivalent to that of the vanilla classifier
by generalizing the low-rank approximation problem from Frobenius-norm to
Cross-Entropy. Experimental results show that the proposed methods achieve
state-of-the-art performance while significantly streamlining the training and
inference processes of XLC tasks. The source code has been made public at
https://github.com/Anoise/MHE.

摘要：<paragraph>現實世界中實例類別的數量通常龐大，且每個實例可能包含多個標籤。為了利用機器學習來區分這些大量的標籤，已建立極端標籤分類 (XLC)。然而，隨著類別數量的增加，分類器中的參數和非線性運算數量也會增加。這導致分類器計算過載問題 (CCOP)。為了解決這個問題，我們提出了一個多頭編碼 (MHE) 機制，它以一個多頭分類器取代了香草分類器。在訓練過程中，MHE 將極端標籤分解為多個較短的局部標籤的乘積，每個頭部都在這些局部標籤上進行訓練。在測試期間，可以根據每個頭部的局部預測直接計算預測標籤。這在幾何上減少了計算負載。然後，根據不同的 XLC 任務的特徵，例如單標籤、多標籤和模型預訓練任務，提出了三種基於 MHE 的實現，即多頭乘積、多頭串聯和多頭抽樣，以更有效地應對 CCOP。此外，我們從理論上證明了 MHE 可以通過將低秩逼近問題從 Frobenius 範數推廣到交叉熵來實現與香草分類器近似的性能。實驗結果表明，所提出的方法在顯著簡化 XLC 任務的訓練和推理過程的同時，實現了最先進的性能。源代碼已公開在 https://github.com/Anoise/MHE。</paragraph>

##### **SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models**
2412.10178v1 by Hung Nguyen, Quang Qui-Vinh Nguyen, Khoi Nguyen, Rang Nguyen

Given an input video of a person and a new garment, the objective of this
paper is to synthesize a new video where the person is wearing the specified
garment while maintaining spatiotemporal consistency. While significant
advances have been made in image-based virtual try-ons, extending these
successes to video often results in frame-to-frame inconsistencies. Some
approaches have attempted to address this by increasing the overlap of frames
across multiple video chunks, but this comes at a steep computational cost due
to the repeated processing of the same frames, especially for long video
sequence. To address these challenges, we reconceptualize video virtual try-on
as a conditional video inpainting task, with garments serving as input
conditions. Specifically, our approach enhances image diffusion models by
incorporating temporal attention layers to improve temporal coherence. To
reduce computational overhead, we introduce ShiftCaching, a novel technique
that maintains temporal consistency while minimizing redundant computations.
Furthermore, we introduce the \dataname~dataset, a new video try-on dataset
featuring more complex backgrounds, challenging movements, and higher
resolution compared to existing public datasets. Extensive experiments show
that our approach outperforms current baselines, particularly in terms of video
consistency and inference speed. Data and code are available at
https://github.com/VinAIResearch/swift-try

摘要：給定一個人的輸入影片和一件新衣服，本文的目標是合成一個新影片，影片中的人穿著指定的衣服，同時保持時空一致性。雖然在基於影像的虛擬試穿方面已有顯著進展，但將這些成功推廣到影片中，通常會導致逐幀不一致。一些方法已嘗試透過增加多個影片區塊中幀的重疊來解決此問題，但由於重複處理相同的幀，特別是對於長的影片序列，這會帶來高昂的運算成本。為了應對這些挑戰，我們將影片虛擬試穿重新概念化為條件影片修復任務，並將服裝作為輸入條件。具體來說，我們的做法是透過加入時間注意力層來增強影像擴散模型，以改善時間相干性。為了減少運算負擔，我們引入了 ShiftCaching，這是一種新技術，可在最大程度減少重複運算的同時，維持時間一致性。此外，我們引入了 \dataname~資料集，這是一個新的影片試穿資料集，與現有的公開資料集相比，具有更複雜的背景、具挑戰性的動作和更高的解析度。廣泛的實驗表明，我們的做法優於目前的基準，特別是在影片一致性和推論速度方面。資料和程式碼可在 https://github.com/VinAIResearch/swift-try 取得

##### **Scaling Combinatorial Optimization Neural Improvement Heuristics with Online Search and Adaptation**
2412.10163v1 by Federico Julian Camerota Verdù, Lorenzo Castelli, Luca Bortolussi

We introduce Limited Rollout Beam Search (LRBS), a beam search strategy for
deep reinforcement learning (DRL) based combinatorial optimization improvement
heuristics. Utilizing pre-trained models on the Euclidean Traveling Salesperson
Problem, LRBS significantly enhances both in-distribution performance and
generalization to larger problem instances, achieving optimality gaps that
outperform existing improvement heuristics and narrowing the gap with
state-of-the-art constructive methods. We also extend our analysis to two
pickup and delivery TSP variants to validate our results. Finally, we employ
our search strategy for offline and online adaptation of the pre-trained
improvement policy, leading to improved search performance and surpassing
recent adaptive methods for constructive heuristics.

摘要：我們引入了有限展開波束搜尋 (LRBS)，一種基於深度強化學習 (DRL) 的組合優化改善啟發式演算法的波束搜尋策略。利用在歐幾里得旅行商問題上預先訓練的模型，LRBS 大幅提升了分佈內效能和對較大型問題實例的泛化，達到了優於現有改善啟發式演算法的最佳化差距，並縮小了與最先進建構方法的差距。我們也將分析延伸到兩個取貨和遞送 TSP 變體，以驗證我們的結果。最後，我們採用我們的搜尋策略進行預先訓練的改善策略的離線和線上適應，提升了搜尋效能，並超越了建構啟發式演算法的近期適應方法。

##### **Direct Encoding of Declare Constraints in ASP**
2412.10152v1 by Francesco Chiariello, Valeria Fionda, Antonio Ielo, Francesco Ricca

Answer Set Programming (ASP), a well-known declarative logic programming
paradigm, has recently found practical application in Process Mining. In
particular, ASP has been used to model tasks involving declarative
specifications of business processes. In this area, Declare stands out as the
most widely adopted declarative process modeling language, offering a means to
model processes through sets of constraints valid traces must satisfy, that can
be expressed in Linear Temporal Logic over Finite Traces (LTLf). Existing
ASP-based solutions encode Declare constraints by modeling the corresponding
LTLf formula or its equivalent automaton which can be obtained using
established techniques. In this paper, we introduce a novel encoding for
Declare constraints that directly models their semantics as ASP rules,
eliminating the need for intermediate representations. We assess the
effectiveness of this novel approach on two Process Mining tasks by comparing
it with alternative ASP encodings and a Python library for Declare. Under
consideration in Theory and Practice of Logic Programming (TPLP).

摘要：<paragraph>Answer Set Programming (ASP)，一種著名的宣告式邏輯程式設計範例，最近在流程探勘中找到實用應用。特別是，ASP 已用於建模涉及業務流程宣告式規範的任務。在這個領域，Declare 作為最廣泛採用的宣告式流程建模語言而脫穎而出，提供一種方法，透過必須滿足的約束集來建模流程，這些約束集可以用有限軌跡上的線性時序邏輯 (LTLf) 來表示。現有的基於 ASP 的解決方案透過建模對應的 LTLf 公式或可以使用已建立技術取得的等效自動機來編碼 Declare 約束。在本文中，我們引入一種新的 Declare 約束編碼，直接將其語意建模為 ASP 規則，消除了對中間表示的需求。我們透過與備用的 ASP 編碼和 Declare 的 Python 函式庫進行比較，評估這種新方法在兩個流程探勘任務上的有效性。在邏輯程式設計理論與實務 (TPLP) 中考量中。</paragraph>

##### **VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval Augmented Generation**
2412.10151v1 by Hyeonseok Lim, Dongjae Shin, Seohyun Song, Inho Won, Minjun Kim, Junghun Yuk, Haneol Jang, KyungTae Lim

We propose the VLR-Bench, a visual question answering (VQA) benchmark for
evaluating vision language models (VLMs) based on retrieval augmented
generation (RAG). Unlike existing evaluation datasets for external
knowledge-based VQA, the proposed VLR-Bench includes five input passages. This
allows testing of the ability to determine which passage is useful for
answering a given query, a capability lacking in previous research. In this
context, we constructed a dataset of 32,000 automatically generated
instruction-following examples, which we denote as VLR-IF. This dataset is
specifically designed to enhance the RAG capabilities of VLMs by enabling them
to learn how to generate appropriate answers based on input passages. We
evaluated the validity of the proposed benchmark and training data and verified
its performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3
model. The proposed VLR-Bench and VLR-IF datasets are publicly available
online.

摘要：我們提出 VLR-Bench，一種視覺問答 (VQA) 基準，用於根據檢索增強生成 (RAG) 評估視覺語言模型 (VLM)。與現有外部知識庫 VQA 評估資料集不同，所提出的 VLR-Bench 包含五個輸入段落。這允許測試確定哪個段落有助於回答特定查詢的能力，這項功能在先前的研究中有所欠缺。在此背景下，我們建構了一個資料集，包含 32,000 個自動產生的遵循指令範例，我們將其表示為 VLR-IF。此資料集特別設計用於增強 VLM 的 RAG 功能，讓它們能夠學習如何根據輸入段落產生適當的答案。我們評估了所提出的基準和訓練資料的有效性，並使用最先進的基於 Llama3 的 VLM，即 Llava-Llama-3 模型，驗證其效能。所提出的 VLR-Bench 和 VLR-IF 資料集已公開在線上。

##### **TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse Analysis with Prompt Engineering**
2412.10139v1 by Bingru Li, Han Wang

The capacity of LLMs to carry out automated qualitative analysis has been
questioned by corpus linguists, and it has been argued that corpus-based
discourse analysis incorporating LLMs is hindered by issues of unsatisfying
performance, hallucination, and irreproducibility. Our proposed method,
TACOMORE, aims to address these concerns by serving as an effective prompting
framework in this domain. The framework consists of four principles, i.e.,
Task, Context, Model and Reproducibility, and specifies five fundamental
elements of a good prompt, i.e., Role Description, Task Definition, Task
Procedures, Contextual Information and Output Format. We conduct experiments on
three LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that
TACOMORE helps improve LLM performance in three representative discourse
analysis tasks, i.e., the analysis of keywords, collocates and concordances,
based on an open corpus of COVID-19 research articles. Our findings show the
efficacy of the proposed prompting framework TACOMORE in corpus-based discourse
analysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and
provide novel insights into the application and evaluation of LLMs in automated
qualitative studies.

摘要：大型語言模型執行自動化定性分析的能力已受到語料庫語言學家的質疑，有人認為，結合大型語言模型的語料庫為基礎的語篇分析受到不令人滿意的表現、幻覺和不可複製性等問題的阻礙。我們提出的方法 TACOMORE 旨在透過作為此領域中有效的提示架構來解決這些問題。此架構包含四項原則，即任務、脈絡、模型和可複製性，並指定良好提示的五個基本元素，即角色描述、任務定義、任務程序、脈絡資訊和輸出格式。我們對三個大型語言模型執行實驗，即 GPT-4o、Gemini-1.5-Pro 和 Gemini-1.5.Flash，發現 TACOMORE 有助於提升大型語言模型在三項代表性語篇分析任務中的表現，即關鍵字、搭配詞和共現分析，這些任務基於 COVID-19 研究文章的開放語料庫。我們的研究結果顯示，提出的提示架構 TACOMORE 在語料庫為基礎的語篇分析中，在準確性、倫理性、推理和可複製性方面具有效能，並提供大型語言模型在自動化定性研究中應用和評估的新見解。

##### **ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL**
2412.10138v1 by Yang Qin, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng, Peng Hu, Jieping Ye

Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by
large language models (LLMs), the latest state-of-the-art techniques are still
trapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which
limits their applicability in open scenarios. To address this challenge, we
propose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to
improve the comprehensive capabilities of open-source LLMs for Text2SQL,
thereby providing a more practical solution. Our approach begins with
multi-task supervised fine-tuning (SFT) using various synthetic training data
related to SQL generation. Unlike existing SFT-based Text2SQL methods, we
introduced several additional SFT tasks, including schema linking, noise
correction, and continuation writing. Engaging in a variety of SQL generation
tasks enhances the model's understanding of SQL syntax and improves its ability
to generate high-quality SQL queries. Additionally, inspired by the
collaborative modes of LLM agents, we introduce a Multitask Collaboration
Prompting (MCP) strategy. This strategy leverages collaboration across several
SQL-related tasks to reduce hallucinations during SQL generation, thereby
maximizing the potential of enhancing Text2SQL performance through explicit
multitask capabilities. Extensive experiments and in-depth analyses have been
performed on eight open-source LLMs and five widely-used benchmarks. The
results demonstrate that our proposal outperforms the latest Text2SQL methods
and yields leading performance.

摘要：儘管大型語言模型 (LLM) 促進了文字轉 SQL (Text2SQL) 的重大進展，但最新的最先進技術仍受限於封閉原始碼 LLM (例如 GPT-4) 的情境學習中，這限制了它們在開放場景中的適用性。為了應對這一挑戰，我們提出了一種新穎的強健多任務調整和協作方法 (ROUTE)，以提高開放原始碼 LLM 對 Text2SQL 的綜合能力，從而提供更實用的解決方案。我們的做法從使用與 SQL 生成相關的各種合成訓練資料的多任務監督微調 (SFT) 開始。與現有的基於 SFT 的 Text2SQL 方法不同，我們引入了幾個額外的 SFT 任務，包括模式連結、雜訊校正和延續寫作。參與各種 SQL 生成任務增強了模型對 SQL 語法的理解，並提高了它生成高品質 SQL 查詢的能力。此外，在 LLM 代理的協作模式的啟發下，我們引入了多任務協作提示 (MCP) 策略。此策略利用跨多個與 SQL 相關任務的協作來減少 SQL 生成過程中的幻覺，從而通過明確的多任務能力最大限度地發揮增強 Text2SQL 效能的潛力。已經對八個開放原始碼 LLM 和五個廣泛使用的基準進行了廣泛的實驗和深入的分析。結果表明，我們的提案優於最新的 Text2SQL 方法，並產生了領先的效能。

##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

摘要：圖形是普遍存在於許多真實世界應用中的資料結構，例如藥物發現、推薦系統和社交網路分析。圖形神經網路 (GNN) 已成為一種流行的工具，可透過在這些結構上傳遞訊息來學習節點嵌入。然而，當將 GNN 應用於具有不同特徵空間的多個圖形時，會出現一個重大的挑戰，因為現有的 GNN 架構並非設計用於跨圖形特徵對齊。為了解決這個問題，最近的方法引入了文字屬性圖形，其中每個節點都與文字描述相關聯，從而可以使用共用文字編碼器將來自不同圖形的節點投影到統一的特徵空間中。儘管有希望，但此方法在很大程度上依賴於文字屬性資料的可用性，這在實務上可能難以取得。為了彌補這個差距，我們提出了一種名為拓撲感知節點描述合成 (TANS) 的新方法，該方法利用大型語言模型 (LLM) 將現有圖形自動轉換為文字屬性圖形。其關鍵思想是將拓撲資訊與每個節點的屬性整合在一起，增強 LLM 解釋圖形拓撲如何影響節點語義的能力。我們在文字豐富、文字受限和無文字圖形上評估我們的 TANS，證明它能讓單一 GNN 在不同的圖形中運作。值得注意的是，在無文字圖形上，我們的模型顯著優於手動設計節點特徵的現有方法，展示了 LLM 在預處理圖形結構資料方面的潛力，即使在沒有文字資訊的情況下也是如此。程式碼和資料可在 https://github.com/Zehong-Wang/TANS 取得。

##### **ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers**
2412.10135v1 by Junyan Hu, Xue Xiao, Mengqi Zhang, Xiao Chen, Zhaochun Ren, Zhumin Chen, Pengjie Ren

As large language models (LLMs) grow in size, traditional full fine-tuning
becomes increasingly impractical due to its high computational and storage
costs. Although popular parameter-efficient fine-tuning methods, such as LoRA,
have significantly reduced the number of tunable parameters, there is still
room for further optimization. In this work, we propose ASLoRA, a cross-layer
parameter-sharing strategy combining global sharing with partial adaptive
sharing. Specifically, we share the low-rank matrix A across all layers and
adaptively merge matrix B during training. This sharing mechanism not only
mitigates overfitting effectively but also captures inter-layer dependencies,
significantly enhancing the model's representational capability. We conduct
extensive experiments on various NLP tasks, showing that ASLoRA outperforms
LoRA while using less than 25% of the parameters, highlighting its flexibility
and superior parameter efficiency. Furthermore, in-depth analyses of the
adaptive sharing strategy confirm its significant advantages in enhancing both
model flexibility and task adaptability.

摘要：隨著大型語言模型 (LLM) 規模的擴大，由於其高運算和儲存成本，傳統的全微調變得越來越不切實際。儘管流行的參數有效微調方法，例如 LoRA，已顯著減少可調參數的數量，但仍有進一步最佳化的空間。在這項工作中，我們提出 ASLoRA，一種跨層參數共享策略，結合了全局共享和部分自適應共享。具體來說，我們在所有層中共享低秩矩陣 A，並在訓練期間自適應地合併矩陣 B。這種共享機制不僅有效地減輕了過度擬合，而且還捕獲了層間依賴性，顯著增強了模型的表示能力。我們對各種 NLP 任務進行了廣泛的實驗，表明 ASLoRA 在使用不到 25% 的參數時優於 LoRA，突出了其靈活性與卓越的參數效率。此外，對自適應共享策略的深入分析證實了其在增強模型靈活性與任務適應性方面的顯著優勢。

##### **You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects**
2412.10133v1 by Islem Bouzenia, Michael Pradel

The ability to execute the test suite of a project is essential in many
scenarios, e.g., to assess code quality and code coverage, to validate code
changes made by developers or automated tools, and to ensure compatibility with
dependencies. Despite its importance, executing the test suite of a project can
be challenging in practice because different projects use different programming
languages, software ecosystems, build systems, testing frameworks, and other
tools. These challenges make it difficult to create a reliable, universal test
execution method that works across different projects. This paper presents
ExecutionAgent, an automated technique that installs arbitrary projects,
configures them to run test cases, and produces project-specific scripts to
reproduce the setup. Inspired by the way a human developer would address this
task, our approach is a large language model-based agent that autonomously
executes commands and interacts with the host system. The agent uses
meta-prompting to gather guidelines on the latest technologies related to the
given project, and it iteratively refines its process based on feedback from
the previous steps. Our evaluation applies ExecutionAgent to 50 open-source
projects that use 14 different programming languages and many different build
and testing tools. The approach successfully executes the test suites of 33/55
projects, while matching the test results of ground truth test suite executions
with a deviation of only 7.5\%. These results improve over the best previously
available technique by 6.6x. The costs imposed by the approach are reasonable,
with an execution time of 74 minutes and LLM costs of 0.16 dollars, on average
per project. We envision ExecutionAgent to serve as a valuable tool for
developers, automated programming tools, and researchers that need to execute
tests across a wide variety of projects.

摘要：在許多場景中，執行專案的測試套件的能力至關重要，例如評估程式碼品質和程式碼涵蓋率、驗證開發人員或自動化工具所做的程式碼變更，以及確保與依賴項相容。儘管其重要性，在實務上執行專案的測試套件可能具有挑戰性，因為不同的專案使用不同的程式語言、軟體生態系統、建置系統、測試架構和其他工具。這些挑戰使得難以建立一個可靠的通用測試執行方法，可以在不同的專案中運作。本文提出 ExecutionAgent，一種自動化技術，它會安裝任意專案、將其組態為執行測試案例，並產生專案特定的腳本以重現設定。我們的做法受到人類開發人員處理此任務的方式啟發，是一種大型語言模型基礎的代理，它會自動執行指令並與主機系統互動。代理使用元提示來收集有關給定專案的最新技術的指南，並且根據前一階段的回饋，反覆改善其流程。我們的評估將 ExecutionAgent 套用到 50 個使用 14 種不同程式語言和許多不同建置和測試工具的開源專案。此做法成功執行 33/55 個專案的測試套件，同時僅有 7.5% 的偏差，與基本實況測試套件執行結果相符。這些結果比先前可用的最佳技術進步了 6.6 倍。此做法產生的成本合理，平均每個專案的執行時間為 74 分鐘，LLM 成本為 0.16 美元。我們預想 ExecutionAgent 可作為開發人員、自動化程式設計工具和需要執行各種專案測試的研究人員的寶貴工具。

##### **Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data**
2412.10121v1 by Jonas Golde, Patrick Haller, Max Ploner, Fabio Barth, Nicolaas Jedema, Alan Akbik

Zero-shot named entity recognition (NER) is the task of detecting named
entities of specific types (such as 'Person' or 'Medicine') without any
training examples. Current research increasingly relies on large synthetic
datasets, automatically generated to cover tens of thousands of distinct entity
types, to train zero-shot NER models. However, in this paper, we find that
these synthetic datasets often contain entity types that are semantically
highly similar to (or even the same as) those in standard evaluation
benchmarks. Because of this overlap, we argue that reported F1 scores for
zero-shot NER overestimate the true capabilities of these approaches. Further,
we argue that current evaluation setups provide an incomplete picture of
zero-shot abilities since they do not quantify the label shift (i.e., the
similarity of labels) between training and evaluation datasets. To address
these issues, we propose Familiarity, a novel metric that captures both the
semantic similarity between entity types in training and evaluation, as well as
their frequency in the training data, to provide an estimate of label shift. It
allows researchers to contextualize reported zero-shot NER scores when using
custom synthetic training datasets. Further, it enables researchers to generate
evaluation setups of various transfer difficulties for fine-grained analysis of
zero-shot NER.

摘要：零次學習命名實體辨識 (NER) 是一項任務，在沒有任何訓練範例的情況下，偵測特定類型的命名實體（例如「人物」或「藥物」）。目前的研究所越來越依賴大型合成資料集，自動產生涵蓋數萬個不同實體類型的資料，來訓練零次學習 NER 模型。然而，在本文中，我們發現這些合成資料集通常包含語義上與標準評量基準中的實體類型高度相似（甚至相同）的實體類型。由於這種重疊，我們認為零次學習 NER 所報告的 F1 分數高估了這些方法的真實能力。此外，我們認為目前的評量設定提供了不完整的零次學習能力，因為它們沒有量化訓練和評量資料集之間的標籤轉移（即標籤的相似性）。為了解決這些問題，我們提出了熟悉度，這是一種新的指標，它同時擷取了訓練和評量中實體類型之間的語義相似性，以及它們在訓練資料中的頻率，以提供標籤轉移的估計值。它允許研究人員在使用自訂合成訓練資料集時，將所報告的零次學習 NER 分數脈絡化。此外，它使研究人員能夠產生各種轉移難度的評量設定，以進行零次學習 NER 的細粒度分析。

##### **CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models**
2412.10117v1 by Zhihao Du, Yuxuan Wang, Qian Chen, Xian Shi, Xiang Lv, Tianyu Zhao, Zhifu Gao, Yexin Yang, Changfeng Gao, Hui Wang, Fan Yu, Huadai Liu, Zhengyan Sheng, Yue Gu, Chong Deng, Wen Wang, Shiliang Zhang, Zhijie Yan, Jingren Zhou

In our previous work, we introduced CosyVoice, a multilingual speech
synthesis model based on supervised discrete speech tokens. By employing
progressive semantic decoding with two popular generative models, language
models (LMs) and Flow Matching, CosyVoice demonstrated high prosody
naturalness, content consistency, and speaker similarity in speech in-context
learning. Recently, significant progress has been made in multi-modal large
language models (LLMs), where the response latency and real-time factor of
speech synthesis play a crucial role in the interactive experience. Therefore,
in this report, we present an improved streaming speech synthesis model,
CosyVoice 2, which incorporates comprehensive and systematic optimizations.
Specifically, we introduce finite-scalar quantization to improve the codebook
utilization of speech tokens. For the text-speech LM, we streamline the model
architecture to allow direct use of a pre-trained LLM as the backbone. In
addition, we develop a chunk-aware causal flow matching model to support
various synthesis scenarios, enabling both streaming and non-streaming
synthesis within a single model. By training on a large-scale multilingual
dataset, CosyVoice 2 achieves human-parity naturalness, minimal response
latency, and virtually lossless synthesis quality in the streaming mode. We
invite readers to listen to the demos at
https://funaudiollm.github.io/cosyvoice2.

摘要：在我們之前的工作中，我們介紹了 CosyVoice，這是一個基於監督離散語音符號的多語言語音合成模型。通過使用兩個流行的生成模型（語言模型 (LM) 和流匹配）來採用漸進語義解碼，CosyVoice 展示了語境學習中語調的自然性、內容的一致性和說話者的相似性。最近，多模態大型語言模型 (LLM) 取得了重大進展，其中語音合成的響應延遲和實時因素在互動體驗中發揮著至關重要的作用。因此，在本文中，我們提出了一個改進的串流語音合成模型 CosyVoice 2，它包含了全面和系統性的最佳化。具體來說，我們引入了有限標量量化來改善語音符號的碼本利用率。對於文字語音 LM，我們簡化了模型架構，允許直接使用預訓練的 LLM 作為主幹。此外，我們開發了一個分塊感知因果流匹配模型來支援各種合成場景，在單一模型中實現串流和非串流合成。通過在一個大規模多語言資料集上訓練，CosyVoice 2 在串流模式下實現了人類同等的自然性、最小的響應延遲和幾乎無損的合成品質。我們邀請讀者在 https://funaudiollm.github.io/cosyvoice2 上收聽示範。

##### **Label-template based Few-Shot Text Classification with Contrastive Learning**
2412.10110v1 by Guanghua Hou, Shuhui Cao, Deqiang Ouyang, Ning Wang

As an algorithmic framework for learning to learn, meta-learning provides a
promising solution for few-shot text classification. However, most existing
research fail to give enough attention to class labels. Traditional basic
framework building meta-learner based on prototype networks heavily relies on
inter-class variance, and it is easily influenced by noise. To address these
limitations, we proposes a simple and effective few-shot text classification
framework. In particular, the corresponding label templates are embed into
input sentences to fully utilize the potential value of class labels, guiding
the pre-trained model to generate more discriminative text representations
through the semantic information conveyed by labels. With the continuous
influence of label semantics, supervised contrastive learning is utilized to
model the interaction information between support samples and query samples.
Furthermore, the averaging mechanism is replaced with an attention mechanism to
highlight vital semantic information. To verify the proposed scheme, four
typical datasets are employed to assess the performance of different methods.
Experimental results demonstrate that our method achieves substantial
performance enhancements and outperforms existing state-of-the-art models on
few-shot text classification tasks.

摘要：作為一種用於學習學習的演算法架構，元學習為少發文字分類提供了一個有前途的解決方案。然而，現有的大多數研究未能給予類別標籤足夠的關注。傳統的基本架構建立基於原型網路的元學習者，嚴重依賴於類間差異，並且容易受到雜訊的影響。為了解決這些限制，我們提出了一個簡單而有效的少發文字分類架構。具體來說，將對應的標籤範本嵌入輸入句子中，以充分利用類別標籤的潛在價值，指導預訓練模型通過標籤傳達的語義資訊生成更具區別性的文字表示。在標籤語義的持續影響下，利用監督對比學習對支援樣本和查詢樣本之間的互動資訊進行建模。此外，將平均機制替換為注意力機制，以突出重要的語義資訊。為了驗證所提出的方案，採用了四個典型的資料集來評估不同方法的效能。實驗結果表明，我們的模型在少發文字分類任務中實現了顯著的效能提升，並且優於現有的最先進模型。

##### **NetOrchLLM: Mastering Wireless Network Orchestration with Large Language Models**
2412.10107v1 by Asmaa Abdallah, Abdullatif Albaseer, Abdulkadir Celik, Mohamed Abdallah, Ahmed M. Eltawil

The transition to 6G networks promises unprecedented advancements in wireless
communication, with increased data rates, ultra-low latency, and enhanced
capacity. However, the complexity of managing and optimizing these
next-generation networks presents significant challenges. The advent of large
language models (LLMs) has revolutionized various domains by leveraging their
sophisticated natural language understanding capabilities. However, the
practical application of LLMs in wireless network orchestration and management
remains largely unexplored. Existing literature predominantly offers visionary
perspectives without concrete implementations, leaving a significant gap in the
field. To address this gap, this paper presents NETORCHLLM, a wireless NETwork
ORCHestrator LLM framework that uses LLMs to seamlessly orchestrate diverse
wireless-specific models from wireless communication communities using their
language understanding and generation capabilities. A comprehensive framework
is introduced, demonstrating the practical viability of our approach and
showcasing how LLMs can be effectively harnessed to optimize dense network
operations, manage dynamic environments, and improve overall network
performance. NETORCHLLM bridges the theoretical aspirations of prior research
with practical, actionable solutions, paving the way for future advancements in
integrating generative AI technologies within the wireless communications
sector.

摘要：6G 網路轉型承諾無線通訊前所未有的進展，包括更高的資料速率、極低的延遲和增強的容量。然而，管理和最佳化這些次世代網路的複雜性，帶來了重大的挑戰。大型語言模型 (LLM) 的出現，透過運用其精密自然語言理解能力，徹底改變了各種領域。然而，LLM 在無線網路協調和管理中的實際應用，仍然很大程度上未經探索。現有的文獻主要提供有遠見的觀點，而沒有具體的實作，在該領域留下了重大的鴻溝。為了解決這個鴻溝，本文提出 NETORCHLLM，一個無線網路協調器 LLM 架構，它使用 LLM 從無線通訊社群中無縫地協調各種特定於無線的模型，使用它們的語言理解和生成能力。引進了一個全面的架構，展示我們方法的實際可行性，並展示如何有效地利用 LLM 來最佳化密集網路操作、管理動態環境，以及改善整體網路效能。NETORCHLLM 將先前研究的理論願景與實用且可行的解決方案連結起來，為未來在無線通訊領域整合生成式 AI 技術的進展鋪路。

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

摘要：由於世界衛生組織將猴痘病毒全球爆發定為國際關注的公共衛生緊急事件，因此猴痘病毒與其他皮膚病變疾病在視覺上的相似性，對診斷帶來重大挑戰。目前的臨床檢測技術在準確性和效率方面面臨限制，因此需要改進的自動化診斷解決方案。本研究引入了一個新穎的串聯空洞組注意力 (CAGA) 模組，專門設計用於增強多尺度特徵表示，同時最佳化運算效率。透過將 CAGA 與 EfficientViT-L1 整合作為主幹架構，我們的做法在 MCSI 資料集上以 0.98% 的分數達到了最先進的效能，同時與原始 EfficientViT-L1 相比，模型參數減少了 37.5%。這種運算複雜度的降低維持了診斷準確性，同時支援在資源受限的醫療保健環境中更廣泛地部署。在包括 MSID 和 MSLD 在內的另外兩個基準資料集上的廣泛驗證證明了模型的穩健性，始終優於現有方法。我們的研究結果表明，CAGA 的高效特徵提取機制可以調整為其他需要細緻視覺辨別的醫學影像任務。

##### **MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset**
2412.10105v1 by Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence E Hunter, Katharina von der Wense

Language models (LMs) have excelled in various broad domains. However, to
ensure their safe and effective integration into real-world educational
settings, they must demonstrate proficiency in specific, granular areas of
knowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'
knowledge, have three major limitations. They: 1) do not cover the educational
domain; 2) typically focus on low-complexity, generic knowledge or broad
domains, which do not adequately assess the models' knowledge in specific
subjects; and 3) often rely on templates that can bias model predictions. Here,
we introduce MALAMUTE, a multilingual, template-free, and highly granular
probing dataset comprising expert-written, peer-reviewed probes from 71
university-level textbooks across three languages (English, Spanish, and
Polish). MALAMUTE is the first education-based cloze-style dataset. It covers
eight domains, each with up to 14 subdomains, further broken down into concepts
and concept-based prompts, totaling 33,361 university curriculum concepts and
116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion
of both sentence-level and paragraph-level prompts make it an ideal tool for
evaluating LMs' course-related knowledge. Our evaluation of masked and causal
LMs on MALAMUTE shows that despite overall proficiency, they have significant
gaps in knowledge when examined closely on specific subjects, hindering their
safe use in classrooms and underscoring the need for further development.

摘要：語言模型 (LM) 在各種廣泛的領域中表現出色。然而，為了確保它們安全有效地整合到現實世界的教育環境中，它們必須在特定、細緻的知識領域中展現出熟練度。現有的完形填空基準，通常用於評估 LM 的知識，有三個主要的限制。它們：1) 沒有涵蓋教育領域；2) 通常專注於低複雜性、通用知識或廣泛領域，無法充分評估模型在特定主題中的知識；3) 經常依賴可能偏向模型預測的範本。在此，我們介紹 MALAMUTE，一個多語言、無範本且高度細緻的探測資料集，包含來自 71 本大學教科書的專家撰寫、同行評審的探測，涵蓋三種語言（英語、西班牙語和波蘭語）。MALAMUTE 是第一個基於教育的完形填空資料集。它涵蓋八個領域，每個領域最多有 14 個子領域，進一步細分為概念和基於概念的提示，總計 33,361 個大學課程概念和 116,887 個提示。MALAMUTE 的細緻粒度、教育焦點以及包含句子層級和段落層級提示，使其成為評估 LM 與課程相關知識的理想工具。我們對 MALAMUTE 上的遮蔽和因果 LM 的評估表明，儘管整體熟練，但仔細檢視特定主題時，它們在知識上存在顯著差距，阻礙了它們在課堂上的安全使用，並強調進一步開發的必要性。

##### **RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector**
2412.10104v1 by Zhensheng Wang, Wenmian Yang, Kun Zhou, Yiquan Zhang, Weijia Jia

The real estate market relies heavily on structured data, such as property
details, market trends, and price fluctuations. However, the lack of
specialized Tabular Question Answering datasets in this domain limits the
development of automated question-answering systems. To fill this gap, we
introduce RETQA, the first large-scale open-domain Chinese Tabular Question
Answering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762
question-answer pairs across 16 sub-fields within three major domains: property
information, real estate company finance information and land auction
information. Compared with existing tabular question answering datasets, RETQA
poses greater challenges due to three key factors: long-table structures,
open-domain retrieval, and multi-domain queries. To tackle these challenges, we
propose the SLUTQA framework, which integrates large language models with
spoken language understanding tasks to enhance retrieval and answering
accuracy. Extensive experiments demonstrate that SLUTQA significantly improves
the performance of large language models on RETQA by in-context learning. RETQA
and SLUTQA provide essential resources for advancing tabular question answering
research in the real estate domain, addressing critical challenges in
open-domain and long-table question-answering. The dataset and code are
publicly available at \url{https://github.com/jensen-w/RETQA}.

摘要：房地產市場極度依賴結構化資料，例如地產明細、市場趨勢和價格波動。然而，此領域缺乏專業的表格問答資料集，限制了自動化問答系統的發展。為了填補此缺口，我們引進 RETQA，這是第一個針對房地產的大規模開放領域中文表格問答資料集。RETQA 包含 4,932 個表格和 20,762 個問答組，涵蓋三個主要領域內的 16 個子領域：地產資訊、房地產公司財務資訊和土地拍賣資訊。與現有的表格問答資料集相比，RETQA 由於三個關鍵因素而帶來更大的挑戰：長表格結構、開放領域擷取和多領域查詢。為了應對這些挑戰，我們提出了 SLUTQA 框架，它將大型語言模型與口語理解任務整合在一起，以增強擷取和回答的準確性。廣泛的實驗證明，SLUTQA 透過情境學習，大幅提升大型語言模型在 RETQA 上的效能。RETQA 和 SLUTQA 提供了必要的資源，用於推進房地產領域的表格問答研究，解決開放領域和長表格問答中的關鍵挑戰。資料集和程式碼已公開於 \url{https://github.com/jensen-w/RETQA}。

##### **AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation**
2412.10103v1 by Xiyuan Gao, Shubhi Bansal, Kushaan Gowda, Zhu Li, Shekhar Nayak, Nagendra Kumar, Matt Coler

Detecting sarcasm effectively requires a nuanced understanding of context,
including vocal tones and facial expressions. The progression towards
multimodal computational methods in sarcasm detection, however, faces
challenges due to the scarcity of data. To address this, we present AMuSeD
(Attentive deep neural network for MUltimodal Sarcasm dEtection incorporating
bi-modal Data augmentation). This approach utilizes the Multimodal Sarcasm
Detection Dataset (MUStARD) and introduces a two-phase bimodal data
augmentation strategy. The first phase involves generating varied text samples
through Back Translation from several secondary languages. The second phase
involves the refinement of a FastSpeech 2-based speech synthesis system,
tailored specifically for sarcasm to retain sarcastic intonations. Alongside a
cloud-based Text-to-Speech (TTS) service, this Fine-tuned FastSpeech 2 system
produces corresponding audio for the text augmentations. We also investigate
various attention mechanisms for effectively merging text and audio data,
finding self-attention to be the most efficient for bimodal integration. Our
experiments reveal that this combined augmentation and attention approach
achieves a significant F1-score of 81.0% in text-audio modalities, surpassing
even models that use three modalities from the MUStARD dataset.

摘要：偵測諷刺需要對脈絡有細緻的理解，包括語調和表情。然而，朝向多模態計算方法的進展在諷刺偵測上會面臨挑戰，因為資料稀少。為了解決這個問題，我們提出了 AMuSeD (用於多模態諷刺偵測的注意力深度神經網路，結合雙模態資料擴充)。此方法利用多模態諷刺偵測資料集 (MUStARD)，並引入一個兩階段的雙模態資料擴充策略。第一階段包含透過從多種次要語言進行反向翻譯來產生不同的文字範例。第二階段包含改進 FastSpeech 2 為基礎的語音合成系統，特別針對諷刺進行調整，以保留諷刺性的語調。這個微調過的 FastSpeech 2 系統與雲端文字轉語音 (TTS) 服務一起，為文字擴充產生對應的音訊。我們也研究了各種注意力機制，以有效地合併文字和音訊資料，發現自我注意力對於雙模態整合最有效率。我們的實驗顯示，這種結合擴充和注意力的方法在文字音訊模態中達到顯著的 F1 分數 81.0%，甚至超越使用 MUStARD 資料集三個模態的模型。

##### **HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation**
2412.10095v1 by Jaione Bengoetxea, Mikel Zubillaga, Ekhi Azurmendi, Maite Heredia, Julen Etxaniz, Markel Ferro, Jeremy Barnes

In this paper we present our submission for the NorSID Shared Task as part of
the 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:
Intent Detection, Slot Filling and Dialect Identification, evaluated using data
in different dialects of the Norwegian language. For Intent Detection and Slot
Filling, we have fine-tuned a multitask model in a cross-lingual setting, to
leverage the xSID dataset available in 17 languages. In the case of Dialect
Identification, our final submission consists of a model fine-tuned on the
provided development set, which has obtained the highest scores within our
experiments. Our final results on the test set show that our models do not drop
in performance compared to the development set, likely due to the
domain-specificity of the dataset and the similar distribution of both subsets.
Finally, we also report an in-depth analysis of the provided datasets and their
artifacts, as well as other sets of experiments that have been carried out but
did not yield the best results. Additionally, we present an analysis on the
reasons why some methods have been more successful than others; mainly the
impact of the combination of languages and domain-specificity of the training
data on the results.

摘要：<paragraph>在本文中，我們提交了我們對 NorSID 共享任務的提交，作為 2025 VarDial 研討會（Scherrer 等人，2025 年）的一部分，包括三個任務：意圖偵測、槽位填補和方言辨識，使用挪威語不同方言的資料進行評估。對於意圖偵測和槽位填補，我們在跨語言設定中微調了一個多任務模型，以利用 17 種語言中可用的 xSID 資料集。在方言辨識的情況下，我們的最終提交包含一個在提供的開發設定上微調的模型，該模型在我們的實驗中獲得了最高分。我們在測試設定上的最終結果顯示，與開發設定相比，我們的模型的效能沒有下降，這可能是由於資料集的特定領域和兩個子集的相似分佈。最後，我們還報告了對提供的資料集及其人工製品的深入分析，以及已執行但未產生最佳結果的其他實驗組。此外，我們分析了某些方法比其他方法更成功的原因；主要是語言組合和訓練資料的特定領域對結果的影響。</paragraph>

##### **AI in the Cosmos**
2412.10093v1 by N. Sahakyan

Artificial intelligence (AI) is revolutionizing research by enabling the
efficient analysis of large datasets and the discovery of hidden patterns. In
astrophysics, AI has become essential, transforming the classification of
celestial sources, data modeling, and the interpretation of observations. In
this review, I highlight examples of AI applications in astrophysics, including
source classification, spectral energy distribution modeling, and discuss the
advancements achievable through generative AI. However, the use of AI
introduces challenges, including biases, errors, and the "black box" nature of
AI models, which must be resolved before their application. These issues can be
addressed through the concept of Human-Guided AI (HG-AI), which integrates
human expertise and domain-specific knowledge into AI applications. This
approach aims to ensure that AI is applied in a robust, interpretable, and
ethical manner, leading to deeper insights and fostering scientific excellence.

摘要：人工智慧 (AI) 透過協助有效分析大型資料集和發現隱藏模式，進而革新研究。在天文物理學中，AI 已成為不可或缺的工具，轉變了天體來源的分類、資料建模和觀測結果的詮釋。在這篇評論中，我重點介紹了 AI 在天文物理學中的應用範例，包括來源分類、光譜能量分布建模，並探討透過生成式 AI 所能達到的進展。然而，AI 的使用也帶來了挑戰，包括偏差、錯誤和 AI 模型的「黑箱」性質，在應用之前必須解決這些問題。這些問題可透過人類引導 AI (HG-AI) 的概念來解決，這將人類的專業知識和特定領域的知識整合到 AI 應用中。這種方法旨在確保 AI 以強健、可詮釋和合乎道德的方式應用，進而獲得更深入的見解並促進科學卓越。

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

摘要：先前的研究發現，最近的長語境語言模型無法平均利用其輸入中段的資訊，偏好位於尾端的資訊片段，這會造成不當的偏差，在我們希望模型能平均使用輸入不同部分的情況下。到目前為止，這個問題主要只在具有單一關鍵資訊片段的設定中被考慮，導致我們質疑當多個必要的資訊片段散佈在輸入中時會發生什麼情況。在此，我們示範了「遺失在中間」問題在多跳問答設定中的影響，其中需要跨越未連接文件的多次推理「跳躍」，並顯示效能不僅會隨著資訊與語境邊緣的距離而下降，也會隨著資訊片段之間的距離而下降。此外，我們實驗了透過知識圖譜三元組萃取和摘要來減少多餘文件內容，並提示模型使用思考鏈提示來更徹底地推理，以減輕問題的方法。

##### **Panacea: Novel DNN Accelerator using Accuracy-Preserving Asymmetric Quantization and Energy-Saving Bit-Slice Sparsity**
2412.10059v1 by Dongyun Kam, Myeongji Yun, Sunwoo Yoo, Seungwoo Hong, Zhengya Zhang, Youngjoo Lee

Low bit-precisions and their bit-slice sparsity have recently been studied to
accelerate general matrix-multiplications (GEMM) during large-scale deep neural
network (DNN) inferences. While the conventional symmetric quantization
facilitates low-resolution processing with bit-slice sparsity for both weight
and activation, its accuracy loss caused by the activation's asymmetric
distributions cannot be acceptable, especially for large-scale DNNs. In efforts
to mitigate this accuracy loss, recent studies have actively utilized
asymmetric quantization for activations without requiring additional
operations. However, the cutting-edge asymmetric quantization produces numerous
nonzero slices that cannot be compressed and skipped by recent bit-slice GEMM
accelerators, naturally consuming more processing energy to handle the
quantized DNN models.
  To simultaneously achieve high accuracy and hardware efficiency for
large-scale DNN inferences, this paper proposes an Asymmetrically-Quantized
bit-Slice GEMM (AQS-GEMM) for the first time. In contrast to the previous
bit-slice computing, which only skips operations of zero slices, the AQS-GEMM
compresses frequent nonzero slices, generated by asymmetric quantization, and
skips their operations. To increase the slice-level sparsity of activations, we
also introduce two algorithm-hardware co-optimization methods: a zero-point
manipulation and a distribution-based bit-slicing. To support the proposed
AQS-GEMM and optimizations at the hardware-level, we newly introduce a DNN
accelerator, Panacea, which efficiently handles sparse/dense workloads of the
tiled AQS-GEMM to increase data reuse and utilization. Panacea supports a
specialized dataflow and run-length encoding to maximize data reuse and
minimize external memory accesses, significantly improving its hardware
efficiency. Our benchmark evaluations show Panacea outperforms existing DNN
accelerators.

摘要：<paragraph>低位元精度及其位元切片稀疏性最近已被研究用于在大型深度神经网络 (DNN) 推论期间加速通用矩阵乘法 (GEMM)。虽然传统的对称量化促进了位元切片稀疏性的低分辨率处理，同时适用于权重和激活，但由于激活的不对称分布而造成的准确性损失是不可接受的，特别是对于大型 DNN。为了减轻这种准确性损失，最近的研究积极利用了不对称量化来激活，而不需要额外的操作。然而，最先进的不对称量化产生了大量非零切片，这些切片无法被最近的位元切片 GEMM 加速器压缩和跳过，自然会消耗更多处理能量来处理量化的 DNN 模型。
为了同时实现大型 DNN 推论的高精度和硬件效率，本文首次提出了不对称量化的位元切片 GEMM (AQS-GEMM)。与以前仅跳过零切片操作的位元切片计算不同，AQS-GEMM 压缩了由不对称量化生成的高频非零切片，并跳过它们的运算。为了增加激活的切片级稀疏性，我们还引入了两种算法-硬件协同优化方法：零点操作和基于分布的位元切片。为了在硬件级别支持所提出的 AQS-GEMM 和优化，我们新推出了一种 DNN 加速器 Panacea，它可以有效地处理平铺 AQS-GEMM 的稀疏/密集工作负载，以增加数据重用和利用率。Panacea 支持专门的数据流和游程编码，以最大化数据重用并最小化外部内存访问，从而显著提高其硬件效率。我们的基准评估表明，Panacea 优于现有的 DNN 加速器。</paragraph>

##### **GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?**
2412.10056v1 by Zhikai Lei, Tianyi Liang, Hanglei Hu, Jin Zhang, Yunhua Zhou, Yunfan Shao, Linyang Li, Chenchui Li, Changbo Wang, Hang Yan, Qipeng Guo

Large Language Models (LLMs) are commonly evaluated using human-crafted
benchmarks, under the premise that higher scores implicitly reflect stronger
human-like performance. However, there is growing concern that LLMs may ``game"
these benchmarks due to data leakage, achieving high scores while struggling
with tasks simple for humans. To substantively address the problem, we create
GAOKAO-Eval, a comprehensive benchmark based on China's National College
Entrance Examination (Gaokao), and conduct ``closed-book" evaluations for
representative models released prior to Gaokao. Contrary to prevailing
consensus, even after addressing data leakage and comprehensiveness,
GAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned
capabilities. To better understand this mismatch, We introduce the Rasch model
from cognitive psychology to analyze LLM scoring patterns and identify two key
discrepancies: 1) anomalous consistent performance across various question
difficulties, and 2) high variance in performance on questions of similar
difficulty. In addition, We identified inconsistent grading of LLM-generated
answers among teachers and recurring mistake patterns. we find that the
phenomenons are well-grounded in the motivations behind OpenAI o1, and o1's
reasoning-as-difficulties can mitigate the mismatch. These results show that
GAOKAO-Eval can reveal limitations in LLM capabilities not captured by current
benchmarks and highlight the need for more LLM-aligned difficulty analysis.

摘要：大型語言模型（LLM）通常使用人工評分基準進行評估，前提是較高的分數隱含著更強的人類表現。然而，越來越令人擔憂的是，LLM 可能會由於資料外洩而「玩弄」這些評分基準，在人類執行簡單任務時苦苦掙扎，卻能獲得高分。為了實質解決這個問題，我們根據中國國家大學入學考試（高考）建立了一個全面的評分基準 GAOKAO-Eval，並對在高考之前發布的代表性模型進行「閉卷」評估。與普遍共識相反，即使在解決資料外洩和全面性問題後，GAOKAO-Eval 揭示高分仍然無法真正反映與人類一致的能力。為了更好地理解這種不匹配，我們引入了認知心理學中的 Rasch 模型來分析 LLM 評分模式並找出兩個關鍵差異：1）在各種問題難度中異常一致的表現，以及 2）在難度相似的問題上表現出高變異性。此外，我們發現教師對 LLM 生成的答案評分不一致，並且存在重複的錯誤模式。我們發現這些現象深深植根於 OpenAI o1 背後的動機，o1 的推理即困難，可以減輕這種不匹配。這些結果表明，GAOKAO-Eval 可以揭示 LLM 能力中的限制，而目前的評分基準無法捕捉到這些限制，並強調需要進行更多與 LLM 一致的難度分析。

##### **Unsupervised Named Entity Disambiguation for Low Resource Domains**
2412.10054v1 by Debarghya Datta, Soumajit Pramanik

In the ever-evolving landscape of natural language processing and information
retrieval, the need for robust and domain-specific entity linking algorithms
has become increasingly apparent. It is crucial in a considerable number of
fields such as humanities, technical writing and biomedical sciences to enrich
texts with semantics and discover more knowledge. The use of Named Entity
Disambiguation (NED) in such domains requires handling noisy texts, low
resource settings and domain-specific KBs. Existing approaches are mostly
inappropriate for such scenarios, as they either depend on training data or are
not flexible enough to work with domain-specific KBs. Thus in this work, we
present an unsupervised approach leveraging the concept of Group Steiner Trees
(GST), which can identify the most relevant candidates for entity
disambiguation using the contextual similarities across candidate entities for
all the mentions present in a document. We outperform the state-of-the-art
unsupervised methods by more than 40\% (in avg.) in terms of Precision@1 across
various domain-specific datasets.

摘要：在不断演進的自然語言處理和資訊檢索領域中，對強健且特定於領域的實體連結演算法的需求已變得越來越明顯。在大量領域中，例如人文學科、技術寫作和生物醫學科學，豐富語意和發現更多知識至關重要。在這些領域中使用命名實體消歧 (NED) 需要處理雜訊文字、低資源設定和特定於領域的知識庫。現有的方法大多不適合此類場景，因為它們依賴於訓練資料或不夠靈活，無法與特定於領域的知識庫搭配使用。因此，在這項工作中，我們提出了一個無監督的方法，利用群組史坦納樹 (GST) 的概念，它可以使用文件中所有提及的候選實體之間的上下文相似性來識別實體消歧最相關的候選項。在各種特定於領域的資料集上，我們在 Precision@1 方面優於最先進的無監督方法超過 40%（平均值）。

##### **TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting from Sparse Views**
2412.10051v1 by Liang Zhao, Zehan Bao, Yi Xie, Hong Chen, Yaohui Chen, Weifu Li

Recent advances in Gaussian Splatting have significantly advanced the field,
achieving both panoptic and interactive segmentation of 3D scenes. However,
existing methodologies often overlook the critical need for reconstructing
specified targets with complex structures from sparse views. To address this
issue, we introduce TSGaussian, a novel framework that combines semantic
constraints with depth priors to avoid geometry degradation in challenging
novel view synthesis tasks. Our approach prioritizes computational resources on
designated targets while minimizing background allocation. Bounding boxes from
YOLOv9 serve as prompts for Segment Anything Model to generate 2D mask
predictions, ensuring semantic accuracy and cost efficiency. TSGaussian
effectively clusters 3D gaussians by introducing a compact identity encoding
for each Gaussian ellipsoid and incorporating 3D spatial consistency
regularization. Leveraging these modules, we propose a pruning strategy to
effectively reduce redundancy in 3D gaussians. Extensive experiments
demonstrate that TSGaussian outperforms state-of-the-art methods on three
standard datasets and a new challenging dataset we collected, achieving
superior results in novel view synthesis of specific objects. Code is available
at: https://github.com/leon2000-ai/TSGaussian.

摘要：高斯散射的最新进展显著推动了该领域的发展，实现了 3D 场景的全景和交互式分割。然而，现有的方法通常忽视了从稀疏视图重建具有复杂结构的特定目标的关键需求。为了解决这个问题，我们引入了 TSGaussian，这是一个新颖的框架，它将语义约束与深度先验相结合，以避免在具有挑战性的新视图合成任务中几何退化。我们的方法将计算资源优先分配给指定目标，同时最小化背景分配。来自 YOLOv9 的边界框用作提示，以使 Segment Anything Model 生成 2D 掩码预测，确保语义准确性和成本效益。TSGaussian 通过为每个高斯椭球体引入紧凑的身份编码并结合 3D 空间一致性正则化，有效地对 3D 高斯进行聚类。利用这些模块，我们提出了一种修剪策略，以有效减少 3D 高斯中的冗余。大量的实验表明，TSGaussian 在三个标准数据集和我们收集的一个具有挑战性的新数据集上优于最先进的方法，在特定对象的 novel view synthesis 中取得了优异的成果。代码可从以下网址获得：https://github.com/leon2000-ai/TSGaussian。

##### **Large Action Models: From Inception to Implementation**
2412.10047v1 by Lu Wang, Fangkai Yang, Chaoyun Zhang, Junting Lu, Jiaxu Qian, Shilin He, Pu Zhao, Bo Qiao, Ray Huang, Si Qin, Qisheng Su, Jiayi Ye, Yudi Zhang, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

As AI continues to advance, there is a growing demand for systems that go
beyond language-based assistance and move toward intelligent agents capable of
performing real-world actions. This evolution requires the transition from
traditional Large Language Models (LLMs), which excel at generating textual
responses, to Large Action Models (LAMs), designed for action generation and
execution within dynamic environments. Enabled by agent systems, LAMs hold the
potential to transform AI from passive language understanding to active task
completion, marking a significant milestone in the progression toward
artificial general intelligence.
  In this paper, we present a comprehensive framework for developing LAMs,
offering a systematic approach to their creation, from inception to deployment.
We begin with an overview of LAMs, highlighting their unique characteristics
and delineating their differences from LLMs. Using a Windows OS-based agent as
a case study, we provide a detailed, step-by-step guide on the key stages of
LAM development, including data collection, model training, environment
integration, grounding, and evaluation. This generalizable workflow can serve
as a blueprint for creating functional LAMs in various application domains. We
conclude by identifying the current limitations of LAMs and discussing
directions for future research and industrial deployment, emphasizing the
challenges and opportunities that lie ahead in realizing the full potential of
LAMs in real-world applications.
  The code for the data collection process utilized in this paper is publicly
available at: https://github.com/microsoft/UFO/tree/main/dataflow, and
comprehensive documentation can be found at
https://microsoft.github.io/UFO/dataflow/overview/.

摘要：隨著人工智慧持續進步，對於超越基於語言的協助，並朝向能夠執行實際行動的智慧代理人的系統需求日益增長。此演進需要從擅長產生文字回應的傳統大型語言模型 (LLM) 轉變為大型動作模型 (LAM)，而後者則專為在動態環境中產生動作和執行動作而設計。透過代理系統的協助，LAM 擁有將人工智慧從被動語言理解轉變為主動任務完成的潛力，並在朝向人工通用智慧邁進的過程中樹立重要的里程碑。
  在本文中，我們提出了一個用於開發 LAM 的全面架構，並提供從構思到部署的系統方法來建立 LAM。我們首先概述 LAM，重點說明其獨特特性，並說明其與 LLM 的不同之處。我們使用基於 Windows 作業系統的代理作為案例研究，並提供有關 LAM 開發關鍵階段的詳細逐步指南，包括資料收集、模型訓練、環境整合、基礎和評估。這個可概括的工作流程可作為在各種應用領域建立功能性 LAM 的藍圖。我們最後找出 LAM 目前的限制，並討論未來研究和產業部署的方向，強調在實際應用中實現 LAM 全部潛力的挑戰和機會。
  本文中使用的資料收集程序程式碼已公開於：https://github.com/microsoft/UFO/tree/main/dataflow，而全面的文件可於 https://microsoft.github.io/UFO/dataflow/overview/ 找到。

##### **Enhanced Speech Emotion Recognition with Efficient Channel Attention Guided Deep CNN-BiLSTM Framework**
2412.10011v1 by Niloy Kumar Kundu, Sarah Kobir, Md. Rayhan Ahmed, Tahmina Aktar, Niloya Roy

Speech emotion recognition (SER) is crucial for enhancing affective computing
and enriching the domain of human-computer interaction. However, the main
challenge in SER lies in selecting relevant feature representations from speech
signals with lower computational costs. In this paper, we propose a lightweight
SER architecture that integrates attention-based local feature blocks (ALFBs)
to capture high-level relevant feature vectors from speech signals. We also
incorporate a global feature block (GFB) technique to capture sequential,
global information and long-term dependencies in speech signals. By aggregating
attention-based local and global contextual feature vectors, our model
effectively captures the internal correlation between salient features that
reflect complex human emotional cues. To evaluate our approach, we extracted
four types of spectral features from speech audio samples: mel-frequency
cepstral coefficients, mel-spectrogram, root mean square value, and
zero-crossing rate. Through a 5-fold cross-validation strategy, we tested the
proposed method on five multi-lingual standard benchmark datasets: TESS,
RAVDESS, BanglaSER, SUBESCO, and Emo-DB, and obtained a mean accuracy of
99.65%, 94.88%, 98.12%, 97.94%, and 97.19% respectively. The results indicate
that our model achieves state-of-the-art (SOTA) performance compared to most
existing methods.

摘要：語音情緒辨識 (SER) 對於加強情感運算和豐富人機互動領域至關重要。然而，SER 的主要挑戰在於以較低的運算成本從語音訊號中選擇相關特徵表徵。在本文中，我們提出了一種輕量級 SER 架構，它整合了基於注意力的局部特徵區塊 (ALFB) 以從語音訊號中擷取高層級相關特徵向量。我們還結合了全局特徵區塊 (GFB) 技術，以擷取語音訊號中的順序、全局資訊和長期依賴性。透過彙總基於注意力的局部和全局脈絡特徵向量，我們的模型有效地擷取了反映複雜人類情緒線索的顯著特徵之間的內部關聯性。為了評估我們的作法，我們從語音音訊範例中萃取了四種類型的頻譜特徵：梅爾頻率倒頻率譜係數、梅爾頻譜圖、均方根值和零交越率。透過 5 倍交叉驗證策略，我們在五個多語言標準基準資料集：TESS、RAVDESS、BanglaSER、SUBESCO 和 Emo-DB 上測試了所提出的方法，並分別獲得了 99.65%、94.88%、98.12%、97.94% 和 97.19% 的平均準確度。結果表明，與大多數現有方法相比，我們的模型達到了最先進 (SOTA) 的效能。

##### **Automated Collection of Evaluation Dataset for Semantic Search in Low-Resource Domain Language**
2412.10008v1 by Anastasia Zhukova, Christian E. Matt, Bela Gipp

Domain-specific languages that use a lot of specific terminology often fall
into the category of low-resource languages. Collecting test datasets in a
narrow domain is time-consuming and requires skilled human resources with
domain knowledge and training for the annotation task. This study addresses the
challenge of automated collecting test datasets to evaluate semantic search in
low-resource domain-specific German language of the process industry. Our
approach proposes an end-to-end annotation pipeline for automated query
generation to the score reassessment of query-document pairs. To overcome the
lack of text encoders trained in the German chemistry domain, we explore a
principle of an ensemble of "weak" text encoders trained on common knowledge
datasets. We combine individual relevance scores from diverse models to
retrieve document candidates and relevance scores generated by an LLM, aiming
to achieve consensus on query-document alignment. Evaluation results
demonstrate that the ensemble method significantly improves alignment with
human-assigned relevance scores, outperforming individual models in both
inter-coder agreement and accuracy metrics. These findings suggest that
ensemble learning can effectively adapt semantic search systems for
specialized, low-resource languages, offering a practical solution to resource
limitations in domain-specific contexts.

摘要：<paragraph>使用大量特定術語的特定領域語言通常屬於低資源語言類別。在狹窄的領域中收集測試數據集非常耗時，並且需要具備領域知識和標註任務訓練的熟練人力資源。本研究解決了自動收集測試數據集的挑戰，以評估流程產業中低資源特定領域德語的語義搜索。我們的做法提出了一個端到端的標註管道，用於自動查詢生成，以重新評分查詢文件對。為了克服在德語化學領域中訓練的文本編碼器的不足，我們探討了一個由在常識數據集上訓練的「弱」文本編碼器組成的集合原理。我們結合了來自不同模型的個別相關性分數，以擷取文件候選項和 LLM 生成的相關性分數，旨在達成查詢文件比對的共識。評估結果表明，集合方法顯著改善了與人工指定的相關性分數的比對，在編碼器間的一致性和準確性指標方面都優於個別模型。這些發現表明，集合學習可以有效地調整語義搜索系統以適應專業的低資源語言，為特定領域背景中的資源限制提供實用的解決方案。</paragraph>

##### **The role of inhibitory control in garden-path sentence processing: A Chinese-English bilingual perspective**
2412.10006v1 by Xiaohui Rao, Haoze Li, Xiaofang Lin, Lijuan Liang

In reading garden-path sentences, people must resolve competing
interpretations, though initial misinterpretations can linger despite
reanalysis. This study examines the role of inhibitory control (IC) in managing
these misinterpretations among Chinese-English bilinguals. Using self-paced
reading tasks, we investigated how IC influences recovery from garden-path
sentences in Chinese (L1) and its interaction with language proficiency during
English (L2) processing. Results indicate that IC does not affect garden-path
recovery in Chinese, suggesting reliance on semantic context may reduce the
need for IC. In contrast, findings for English L2 learners reveal a complex
relationship between language proficiency and IC: Participants with low L2
proficiency but high IC showed lingering misinterpretations, while those with
high proficiency exhibited none. These results support and extend the Model of
Cognitive Control (Ness et al., 2023). Moreover, our comparison of three Stroop
task versions identifies L1 colour-word Stroop task as the preferred measure of
IC in bilingual research.

摘要：在閱讀花園小徑句時，人們必須解決相互競爭的解釋，儘管重新分析，最初的誤解可能會持續存在。本研究探討了抑制性控制 (IC) 在管理中國英語雙語者之間這些誤解中的作用。使用自定進度閱讀任務，我們調查了 IC 如何影響從中文 (L1) 的花園小徑句中恢復，以及它在英語 (L2) 處理過程中與語言能力的互動。結果表明，IC 沒有影響中文中的花園小徑恢復，這表明依賴語義上下文可以減少對 IC 的需求。相比之下，英語 L2 學習者的研究結果揭示了語言能力和 IC 之間的複雜關係：L2 水平低但 IC 高的參與者表現出持續的誤解，而那些水平高的參與者則沒有。這些結果支持並擴展了認知控制模型 (Ness 等人，2023)。此外，我們對三個 Stroop 任務版本的比較將 L1 顏色詞 Stroop 任務確定為雙語研究中 IC 的首選測量方法。

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

摘要：加速式 MRI 重建技術旨在縮短檢查時間，同時維持高影像保真度，這在臨床環境中非常理想，可提升病患舒適度和醫院效率。現有的深度學習方法通常使用傳統重建方法從欠採樣數據重建影像，但仍難以提供高保真度結果。擴散模型在近年展現出提升生成影像保真度的絕佳潛力。然而，其從隨機高斯雜訊開始的推論過程會為結果帶來不穩定性，且通常需要數千個採樣步驟，導致次最佳重建品質和低效率。為了應對這些挑戰，我們提出循環一致橋接擴散模型 (CBDM)。CBDM 使用兩個橋接擴散模型，建構一個具有相容性損失的循環一致擴散過程，增強重建影像的精細細節並減少擴散步驟的數量。此外，CBDM 整合了一個輪廓分解嵌入模組 (CDEM)，透過頻域分解金字塔和方向濾波器組在影像中擷取多尺度結構紋理知識，以提升結構保真度。廣泛的實驗證明了我們模型的優異性，具有更高的重建品質和更少的訓練反覆運算，在 fastMRI 和 IXI 資料集的加速式 MRI 重建中達成新的技術水準。

##### **A Comparative Study of LLMs, NMT Models, and Their Combination in Persian-English Idiom Translation**
2412.09993v1 by Sara Rezaeimanesh, Faezeh Hosseini, Yadollah Yaghoobzadeh

Large language models (LLMs) have shown superior capabilities in translating
figurative language compared to neural machine translation (NMT) systems.
However, the impact of different prompting methods and LLM-NMT combinations on
idiom translation has yet to be thoroughly investigated. This paper introduces
two parallel datasets of sentences containing idiomatic expressions for
Persian$\rightarrow$English and English$\rightarrow$Persian translations, with
Persian idioms sampled from our PersianIdioms resource, a collection of 2,200
idioms and their meanings. Using these datasets, we evaluate various open- and
closed-source LLMs, NMT models, and their combinations. Translation quality is
assessed through idiom translation accuracy and fluency. We also find that
automatic evaluation methods like LLM-as-a-judge, BLEU and BERTScore are
effective for comparing different aspects of model performance. Our experiments
reveal that Claude-3.5-Sonnet delivers outstanding results in both translation
directions. For English$\rightarrow$Persian, combining weaker LLMs with Google
Translate improves results, while Persian$\rightarrow$English translations
benefit from single prompts for simpler models and complex prompts for advanced
ones.

摘要：大型語言模型 (LLM) 在翻譯比喻語言方面展現出比神經機器翻譯 (NMT) 系統更優越的能力。
然而，不同的提示方法和 LLM-NMT 組合對慣用語翻譯的影響尚未得到徹底研究。本文介紹了兩個包含慣用語句子的平行數據集，用於波斯語$\rightarrow$英語和英語$\rightarrow$波斯語翻譯，其中波斯語慣用語取樣自我們的 PersianIdioms 資源，該資源收集了 2,200 個慣用語及其含義。使用這些數據集，我們評估了各種開源和閉源 LLM、NMT 模型及其組合。翻譯品質通過慣用語翻譯準確度和流暢度進行評估。我們還發現，像 LLM-as-a-judge、BLEU 和 BERTScore 等自動評估方法對於比較模型效能的不同方面是有效的。我們的實驗表明，Claude-3.5-Sonnet 在兩個翻譯方向上都提供了傑出的結果。對於英語$\rightarrow$波斯語，將較弱的 LLM 與 Google Translate 結合起來可以改善結果，而波斯語$\rightarrow$英語翻譯則受益於較簡單模型的單一提示和較高級模型的複雜提示。

##### **Visual Object Tracking across Diverse Data Modalities: A Review**
2412.09991v1 by Mengmeng Wang, Teli Ma, Shuo Xin, Xiaojun Hou, Jiazheng Xing, Guang Dai, Jingdong Wang, Yong Liu

Visual Object Tracking (VOT) is an attractive and significant research area
in computer vision, which aims to recognize and track specific targets in video
sequences where the target objects are arbitrary and class-agnostic. The VOT
technology could be applied in various scenarios, processing data of diverse
modalities such as RGB, thermal infrared and point cloud. Besides, since no one
sensor could handle all the dynamic and varying environments, multi-modal VOT
is also investigated. This paper presents a comprehensive survey of the recent
progress of both single-modal and multi-modal VOT, especially the deep learning
methods. Specifically, we first review three types of mainstream single-modal
VOT, including RGB, thermal infrared and point cloud tracking. In particular,
we conclude four widely-used single-modal frameworks, abstracting their schemas
and categorizing the existing inheritors. Then we summarize four kinds of
multi-modal VOT, including RGB-Depth, RGB-Thermal, RGB-LiDAR and RGB-Language.
Moreover, the comparison results in plenty of VOT benchmarks of the discussed
modalities are presented. Finally, we provide recommendations and insightful
observations, inspiring the future development of this fast-growing literature.

摘要：視覺物件追蹤 (VOT) 是電腦視覺中一個有吸引力且重要的研究領域，其目標是識別並追蹤影片序列中特定的目標，其中目標物件是任意的且與類別無關。VOT 技術可應用於各種場景，處理各種模式的資料，例如 RGB、熱紅外線和點雲。此外，由於沒有任何一種感測器可以處理所有動態且多變的環境，因此多模式 VOT 也在研究中。本文提供了單模式和多模式 VOT 最近進展的全面調查，特別是深度學習方法。具體來說，我們首先回顧了三種類型的主流單模式 VOT，包括 RGB、熱紅外線和點雲追蹤。特別是，我們總結了四個廣泛使用的單模式架構，抽象其架構並分類現有的繼承者。然後，我們總結了四種類型的多模式 VOT，包括 RGB-深度、RGB-熱、RGB-LiDAR 和 RGB-語言。此外，還提供了在大量 VOT 基準中討論模式的比較結果。最後，我們提供了建議和有見地的觀察，激勵了這個快速成長的領域的未來發展。

##### **Small Language Model as Data Prospector for Large Language Model**
2412.09990v1 by Shiwen Ni, Haihong Wu, Di Yang, Qiang Qu, Hamid Alinejad-Rokny, Min Yang

The quality of instruction data directly affects the performance of
fine-tuned Large Language Models (LLMs). Previously, \cite{li2023one} proposed
\texttt{NUGGETS}, which identifies and selects high-quality quality data from a
large dataset by identifying those individual instruction examples that can
significantly improve the performance of different tasks after being learnt as
one-shot instances. In this work, we propose \texttt{SuperNUGGETS}, an improved
variant of \texttt{NUGGETS} optimised for efficiency and performance. Our
\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large
language model (LLM) to filter the data for outstanding one-shot instances and
refines the predefined set of tests. The experimental results show that the
performance of \texttt{SuperNUGGETS} only decreases by 1-2% compared to
\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.
Compared to the original \texttt{NUGGETS}, our \texttt{SuperNUGGETS} has a
higher utility value due to the significantly lower resource consumption.

摘要：教學資料的品質直接影響微調後的巨量語言模型 (LLM) 的效能。先前，\cite{li2023one} 提出 \texttt{NUGGETS}，它會從大型資料集中識別並選取高品質資料，方法是找出那些個別教學範例，在學習為一次性實例後，能大幅提升不同任務的效能。在這項工作中，我們提出 \texttt{SuperNUGGETS}，這是 \texttt{NUGGETS} 的改良版本，針對效率和效能進行了最佳化。我們的 \texttt{SuperNUGGETS} 使用小型語言模型 (SLM)，而非大型語言模型 (LLM)，來過濾資料以找出傑出的單次實例，並改善預先定義的測試集。實驗結果顯示，與 \texttt{NUGGETS} 相比，\texttt{SuperNUGGETS} 的效能僅下降 1-2%，但效率卻能提升 58 倍。與原始 \texttt{NUGGETS} 相比，我們的 \texttt{SuperNUGGETS} 具有更高的實用價值，因為資源消耗顯著降低。

##### **AI and the Future of Digital Public Squares**
2412.09988v1 by Beth Goldberg, Diana Acosta-Navas, Michiel Bakker, Ian Beacock, Matt Botvinick, Prateek Buch, Renée DiResta, Nandika Donthi, Nathanael Fast, Ravi Iyer, Zaria Jalan, Andrew Konya, Grace Kwak Danciu, Hélène Landemore, Alice Marwick, Carl Miller, Aviv Ovadya, Emily Saltz, Lisa Schirch, Dalit Shalom, Divya Siddarth, Felix Sieker, Christopher Small, Jonathan Stray, Audrey Tang, Michael Henry Tessler, Amy Zhang

Two substantial technological advances have reshaped the public square in
recent decades: first with the advent of the internet and second with the
recent introduction of large language models (LLMs). LLMs offer opportunities
for a paradigm shift towards more decentralized, participatory online spaces
that can be used to facilitate deliberative dialogues at scale, but also create
risks of exacerbating societal schisms. Here, we explore four applications of
LLMs to improve digital public squares: collective dialogue systems, bridging
systems, community moderation, and proof-of-humanity systems. Building on the
input from over 70 civil society experts and technologists, we argue that LLMs
both afford promising opportunities to shift the paradigm for conversations at
scale and pose distinct risks for digital public squares. We lay out an agenda
for future research and investments in AI that will strengthen digital public
squares and safeguard against potential misuses of AI.

摘要：近十年來，兩項重大的技術進步重塑了公共領域：首先是網際網路的出現，其次是最近引入的大型語言模型 (LLM)。LLM 為轉向更分散、更具參與性的線上空間提供了機會，可被用於促進大規模的審議對話，但也產生了加劇社會分裂的風險。在此，我們探討了 LLM 在改善數位公共領域的四種應用：集體對話系統、橋接系統、社群審核和人類證明系統。根據 70 多位公民社會專家和技術人員的意見，我們認為 LLM 既提供了轉變大規模對話典範的有希望機會，也對數位公共領域構成明確的風險。我們制定了一項未來研究和 AI 投資議程，將強化數位公共領域並防止 AI 遭到潛在的誤用。

##### **Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective**
2412.09972v1 by Yuchen Fang, Yuxuan Liang, Bo Hui, Zezhi Shao, Liwei Deng, Xu Liu, Xinke Jiang, Kai Zheng

Road traffic forecasting is crucial in real-world intelligent transportation
scenarios like traffic dispatching and path planning in city management and
personal traveling. Spatio-temporal graph neural networks (STGNNs) stand out as
the mainstream solution in this task. Nevertheless, the quadratic complexity of
remarkable dynamic spatial modeling-based STGNNs has become the bottleneck over
large-scale traffic data. From the spatial data management perspective, we
present a novel Transformer framework called PatchSTG to efficiently and
dynamically model spatial dependencies for large-scale traffic forecasting with
interpretability and fidelity. Specifically, we design a novel irregular
spatial patching to reduce the number of points involved in the dynamic
calculation of Transformer. The irregular spatial patching first utilizes the
leaf K-dimensional tree (KDTree) to recursively partition irregularly
distributed traffic points into leaf nodes with a small capacity, and then
merges leaf nodes belonging to the same subtree into occupancy-equaled and
non-overlapped patches through padding and backtracking. Based on the patched
data, depth and breadth attention are used interchangeably in the encoder to
dynamically learn local and global spatial knowledge from points in a patch and
points with the same index of patches. Experimental results on four real world
large-scale traffic datasets show that our PatchSTG achieves train speed and
memory utilization improvements up to $10\times$ and $4\times$ with the
state-of-the-art performance.

摘要：道路交通預測在實際的智慧運輸場景中至關重要，例如城市管理和個人旅行中的交通調度和路徑規劃。時空圖神經網路 (STGNN) 成為這項任務的主流解決方案。然而，基於顯著動態空間建模的 STGNN 的二次複雜度已成為大規模交通數據的瓶頸。從空間數據管理的角度來看，我們提出一個名為 PatchSTG 的新型 Transformer 框架，以便有效且動態地對大規模交通預測建模空間依賴性，同時具備可解釋性和保真度。具體來說，我們設計了一個新穎的不規則空間修補，以減少 Transformer 動態計算中涉及的點數。不規則空間修補首先利用葉 K 維樹 (KDTree) 將不規則分佈的交通點遞迴分割成容量小的葉節點，然後透過填充和回溯將屬於相同子樹的葉節點合併成佔用相等且不重疊的修補程式。基於修補的數據，深度和廣度注意力在編碼器中互換使用，以動態地從修補程式中的點和具有相同修補程式索引的點中學習局部和全局空間知識。在四個真實世界的大規模交通數據集上的實驗結果表明，我們的 PatchSTG 在訓練速度和記憶體利用率方面分別提升了最先進的效能達 $10\times$ 和 $4\times$。

##### **EP-CFG: Energy-Preserving Classifier-Free Guidance**
2412.09966v1 by Kai Zhang, Fujun Luan, Sai Bi, Jianming Zhang

Classifier-free guidance (CFG) is widely used in diffusion models but often
introduces over-contrast and over-saturation artifacts at higher guidance
strengths. We present EP-CFG (Energy-Preserving Classifier-Free Guidance),
which addresses these issues by preserving the energy distribution of the
conditional prediction during the guidance process. Our method simply rescales
the energy of the guided output to match that of the conditional prediction at
each denoising step, with an optional robust variant for improved artifact
suppression. Through experiments, we show that EP-CFG maintains natural image
quality and preserves details across guidance strengths while retaining CFG's
semantic alignment benefits, all with minimal computational overhead.

摘要：無分類器引導 (CFG) 廣泛用於擴散模型，但通常會在較高的引導強度下引入過度對比和過度飽和的偽像。我們提出 EP-CFG（能量保留無分類器引導），它透過在引導過程中保留條件預測的能量分佈來解決這些問題。我們的模型僅僅在每個去噪步驟中重新調整引導輸出的能量，以匹配條件預測的能量，並提供一個可選的穩健變體以改善偽像抑制。透過實驗，我們證明 EP-CFG 能夠在保持 CFG 的語義對齊優勢的同時，在所有引導強度下維持自然影像品質和保留細節，且計算量開銷極小。

##### **Romanized to Native Malayalam Script Transliteration Using an Encoder-Decoder Framework**
2412.09957v1 by Bajiyo Baiju, Kavya Manohar, Leena G Pillai, Elizabeth Sherly

In this work, we present the development of a reverse transliteration model
to convert romanized Malayalam to native script using an encoder-decoder
framework built with attention-based bidirectional Long Short Term Memory
(Bi-LSTM) architecture. To train the model, we have used curated and combined
collection of 4.3 million transliteration pairs derived from publicly available
Indic language translitertion datasets, Dakshina and Aksharantar. We evaluated
the model on two different test dataset provided by IndoNLP-2025-Shared-Task
that contain, (1) General typing patterns and (2) Adhoc typing patterns,
respectively. On the Test Set-1, we obtained a character error rate (CER) of
7.4%. However upon Test Set-2, with adhoc typing patterns, where most vowel
indicators are missing, our model gave a CER of 22.7%.

摘要：在這項工作中，我們展示了一個反轉音譯模型的開發，使用一個建構於基於注意力的雙向長短期記憶 (Bi-LSTM) 架構的編碼器-解碼器框架，將羅馬化的馬拉雅拉姆語轉換成原生文字。為了訓練模型，我們使用了一個由公開的印度語言轉寫資料集 Dakshina 和 Aksharantar 中衍生的 430 萬個轉寫對的精選和組合集合。我們在 IndoNLP-2025-Shared-Task 提供的兩個不同的測試資料集上評估了模型，分別包含 (1) 一般輸入模式和 (2) 特殊輸入模式。在測試集 1 上，我們獲得了 7.4% 的字元錯誤率 (CER)。然而在測試集 2 上，在特殊輸入模式中，大多數的元音指示符號都遺失，我們的模型給出了 22.7% 的 CER。

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

摘要：本文探討大型語言模型 (LLM) 在護理和老年照護中的應用，重點在於 AI 驅動的病人監控和互動。我們引入了一個新穎的中文護理資料集，並實施增量預訓練 (IPT) 和監督微調 (SFT) 技術，以增強 LLM 在專業任務中的表現。使用 LangChain，我們開發了一個動態護理助理，能夠提供即時照護和個人化干預措施。實驗結果證明了顯著的改進，為 AI 驅動的解決方案鋪平了道路，以滿足老齡化人口對醫療保健日益增長的需求。

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

摘要：近年来，基于神经网络和预训练模型的文本分类方法越来越受到关注，并表现出优异的性能。然而，这些方法在实际应用中仍然存在一些局限性：(1) 它们通常只关注句子之间的匹配相似性。然而，同类句子内部和不同类句子之间都存在隐含的高价值信息，这对分类任务至关重要。(2) 预训练语言模型和基于图的方法等现有方法通常需要大量的内存用于训练和文本图构建。(3) 虽然一些低资源方法可以达到良好的性能，但它们通常处理时间过长。为了应对这些挑战，我们提出了一种低资源且快速的文本分类模型，称为 LFTC。我们的方法首先为每个类别构建一个压缩器列表，以充分挖掘类内数据中的规律性信息。然后，我们删除与目标分类无关的冗余信息，以减少处理时间。最后，我们计算文本对之间的相似性距离进行分类。我们在 9 个公开的基准数据集上评估了 LFTC，结果表明在有限的计算和数据资源下，其性能和处理时间都有显著提升，突出了其优越的优势。

##### **B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens**
2412.09919v1 by Zhuqiang Lu, Zhenfei Yin, Mengwei He, Zhihui Wang, Zicheng Liu, Zhiyong Wang, Kun Hu

Recently, Vision Large Language Models (VLLMs) integrated with vision
encoders have shown promising performance in vision understanding. The key of
VLLMs is to encode visual content into sequences of visual tokens, enabling
VLLMs to simultaneously process both visual and textual content. However,
understanding videos, especially long videos, remain a challenge to VLLMs as
the number of visual tokens grows rapidly when encoding videos, resulting in
the risk of exceeding the context window of VLLMs and introducing heavy
computation burden. To restrict the number of visual tokens, existing VLLMs
either: (1) uniformly downsample videos into a fixed number of frames or (2)
reducing the number of visual tokens encoded from each frame. We argue the
former solution neglects the rich temporal cue in videos and the later
overlooks the spatial details in each frame. In this work, we present
Balanced-VLLM (B-VLLM): a novel VLLM framework that aims to effectively
leverage task relevant spatio-temporal cues while restricting the number of
visual tokens under the VLLM context window length. At the core of our method,
we devise a text-conditioned adaptive frame selection module to identify frames
relevant to the visual understanding task. The selected frames are then
de-duplicated using a temporal frame token merging technique. The visual tokens
of the selected frames are processed through a spatial token sampling module
and an optional spatial token merging strategy to achieve precise control over
the token count. Experimental results show that B-VLLM is effective in
balancing the number of frames and visual tokens in video understanding,
yielding superior performance on various video understanding benchmarks. Our
code is available at https://github.com/zhuqiangLu/B-VLLM.

摘要：<paragraph>最近，结合视觉编码器的视觉大型语言模型 (VLLM) 在视觉理解中展现了令人满意的性能。VLLM 的关键在于将视觉内容编码成视觉标记序列，让 VLLM 能够同时处理视觉和文本内容。然而，理解视频，尤其是长视频，对于 VLLM 来说仍然是一个挑战，因为在对视频进行编码时，视觉标记的数量会迅速增长，从而导致超出 VLLM 的上下文窗口并带来沉重的计算负担的风险。为了限制视觉标记的数量，现有的 VLLM 要么：(1) 将视频均匀降采样成固定数量的帧，要么：(2) 减少从每帧编码的视觉标记数量。我们认为前一种解决方案忽略了视频中丰富的时序线索，而后一种解决方案忽略了每帧中的空间细节。在这项工作中，我们提出了平衡 VLLM (B-VLLM)：一种新颖的 VLLM 框架，旨在有效利用与任务相关的时空线索，同时限制 VLLM 上下文窗口长度下的视觉标记数量。在我们的方法的核心，我们设计了一个文本条件自适应帧选择模块来识别与视觉理解任务相关的帧。然后使用时序帧标记合并技术对选定的帧进行去重处理。选定帧的视觉标记通过空间标记采样模块和可选的空间标记合并策略进行处理，以实现对标记计数的精确控制。实验结果表明，B-VLLM 在平衡视频理解中的帧数和视觉标记数量方面是有效的，在各种视频理解基准上产生了更优异的性能。我们的代码可在 https://github.com/zhuqiangLu/B-VLLM 获得。</paragraph>

##### **Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning**
2412.09906v1 by Jing Bi, Yuting Wu, Weiwei Xing, Zhenjie Wei

Large language models (LLMs) have demonstrated remarkable performance across
a wide range of tasks. Advances in prompt engineering and fine-tuning
techniques have further enhanced their ability to address complex reasoning
challenges. However, these advanced capabilities are often exclusive to models
exceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning
methods have been explored for smaller models (under 10 billion parameters),
they typically depend on extensive CoT training data, which can introduce
inconsistencies and limit effectiveness in low-data settings. To overcome these
limitations, this paper introduce a new reasoning strategy Solution Guidance
(SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT)
for enhancing the reasoning capabilities of small language models. SG focuses
on problem understanding and decomposition at the semantic and logical levels,
rather than specific computations, which can effectively improve the SLMs'
generalization and reasoning abilities. With only a small amount of SG training
data, SGFT can fine-tune a SLM to produce accurate problem-solving guidances,
which can then be flexibly fed to any SLM as prompts, enabling it to generate
correct answers directly. Experimental results demonstrate that our method
significantly improves the performance of SLMs on various reasoning tasks,
enhancing both their practicality and efficiency within resource-constrained
environments.

摘要：大型語言模型 (LLM) 已在廣泛的任務中展現出卓越的效能。提示工程和微調技術的進展進一步提升了它們處理複雜推理挑戰的能力。然而，這些進階功能通常專屬於超過 1000 億個參數的模型。儘管已針對較小模型（小於 100 億個參數）探索思維鏈 (CoT) 微調方法，但它們通常依賴於大量的 CoT 訓練資料，這可能會在資料量少的情況下造成不一致性並限制效能。為了克服這些限制，本文介紹了一種新的推理策略「解決方案指導」(SG) 和一種即插即用訓練範例「解決方案指導微調」(SGFT)，用於增強小型語言模型的推理能力。SG 專注於語意和邏輯層面的問題理解和分解，而非特定運算，這可以有效提升 SLM 的概化和推理能力。SGFT 僅需少量的 SG 訓練資料，就能微調 SLM 以產生準確的解決問題指導，然後可以靈活地將其提供給任何 SLM 作為提示，使其能夠直接產生正確的答案。實驗結果表明，我們的模型顯著提升了 SLM 在各種推理任務中的效能，在資源受限的環境中提升了其實用性和效率。

##### **Analyzing Fairness of Computer Vision and Natural Language Processing Models**
2412.09900v1 by Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb

Machine learning (ML) algorithms play a crucial role in decision making
across diverse fields such as healthcare, finance, education, and law
enforcement. Despite their widespread adoption, these systems raise ethical and
social concerns due to potential biases and fairness issues. This study focuses
on evaluating and improving the fairness of Computer Vision and Natural
Language Processing (NLP) models applied to unstructured datasets, emphasizing
how biased predictions can reinforce existing systemic inequalities. A publicly
available dataset from Kaggle was utilized to simulate a practical scenario for
examining fairness in ML workflows. To address and mitigate biases, the study
employed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by
IBM. These tools offer comprehensive frameworks for fairness analysis,
including metrics evaluation, result visualization, and bias mitigation
techniques. The research aims to measure bias levels in ML models, compare the
effectiveness of these fairness libraries, and provide actionable
recommendations for practitioners. The results demonstrate that each library
possesses distinct strengths and limitations in evaluating and mitigating
fairness. By systematically analyzing these tools, the study contributes
valuable insights to the growing field of ML fairness, offering practical
guidance for integrating fairness solutions into real world applications. This
research underscores the importance of building more equitable and responsible
machine learning systems.

摘要：機器學習 (ML) 演算法在醫療保健、金融、教育和執法等不同領域的決策制定中扮演著至關重要的角色。儘管這些系統被廣泛採用，但由於潛在的偏見和公平性問題，這些系統引發了倫理和社會問題。本研究重點在於評估和改善應用於非結構化資料集的電腦視覺和自然語言處理 (NLP) 模型的公平性，強調有偏見的預測如何加劇現有的系統性不平等。利用 Kaggle 上公開提供的資料集來模擬實際場景，以檢視 ML 工作流程中的公平性。為了解決和減輕偏見，本研究採用了兩個領先的公平性函式庫：Microsoft 的 Fairlearn 和 IBM 的 AIF360。這些工具提供了全面的公平性分析架構，包括指標評估、結果視覺化和偏見緩解技術。本研究旨在衡量 ML 模型中的偏見程度，比較這些公平性函式庫的有效性，並為從業人員提供可行的建議。結果表明，每個函式庫在評估和減輕公平性方面都具有不同的優勢和限制。透過系統性地分析這些工具，本研究為 ML 公平性這個不斷發展的領域做出了寶貴的見解，為將公平性解決方案整合到實際應用中提供了實用的指導。本研究強調了建構更公平、更負責任的機器學習系統的重要性。

##### **Analyzing Fairness of Classification Machine Learning Model with Structured Dataset**
2412.09896v1 by Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb

Machine learning (ML) algorithms have become integral to decision making in
various domains, including healthcare, finance, education, and law enforcement.
However, concerns about fairness and bias in these systems pose significant
ethical and social challenges. This study investigates the fairness of ML
models applied to structured datasets in classification tasks, highlighting the
potential for biased predictions to perpetuate systemic inequalities. A
publicly available dataset from Kaggle was selected for analysis, offering a
realistic scenario for evaluating fairness in machine learning workflows.
  To assess and mitigate biases, three prominent fairness libraries; Fairlearn
by Microsoft, AIF360 by IBM, and the What If Tool by Google were employed.
These libraries provide robust frameworks for analyzing fairness, offering
tools to evaluate metrics, visualize results, and implement bias mitigation
strategies. The research aims to assess the extent of bias in the ML models,
compare the effectiveness of these libraries, and derive actionable insights
for practitioners.
  The findings reveal that each library has unique strengths and limitations in
fairness evaluation and mitigation. By systematically comparing their
capabilities, this study contributes to the growing field of ML fairness by
providing practical guidance for integrating fairness tools into real world
applications. These insights are intended to support the development of more
equitable machine learning systems.

摘要：機器學習 (ML) 演算法已成為各個領域（包括醫療保健、金融、教育和執法）決策中不可或缺的一部分。
然而，對於這些系統中公平性和偏差的疑慮，帶來了重大的倫理和社會挑戰。本研究探討了 ML 模型在分類任務中應用於結構化資料集的公平性，強調了有偏差的預測可能使系統性不平等永續化的潛力。我們選擇了 Kaggle 上一個公開可用的資料集進行分析，提供了評估機器學習工作流程中公平性的實際情境。
為了評估和減輕偏差，我們使用了三個著名的公平性函式庫：Microsoft 的 Fairlearn、IBM 的 AIF360 和 Google 的 What If Tool。這些函式庫提供了強大的框架來分析公平性，提供了用於評估指標、視覺化結果和實作偏差減緩策略的工具。這項研究旨在評估 ML 模型中偏差的程度，比較這些函式庫的有效性，並為從業人員得出可行的見解。
研究結果顯示，每個函式庫在公平性評估和減緩方面都有其獨特的優點和缺點。透過系統性地比較它們的能力，本研究透過提供將公平性工具整合到實際應用中的實務指南，為 ML 公平性這個不斷成長的領域做出貢獻。這些見解旨在支援開發更公平的機器學習系統。

##### **Semi-Periodic Activation for Time Series Classification**
2412.09889v1 by José Gilberto Barbosa de Medeiros Júnior, Andre Guarnier de Mitri, Diego Furtado Silva

This paper investigates the lack of research on activation functions for
neural network models in time series tasks. It highlights the need to identify
essential properties of these activations to improve their effectiveness in
specific domains. To this end, the study comprehensively analyzes properties,
such as bounded, monotonic, nonlinearity, and periodicity, for activation in
time series neural networks. We propose a new activation that maximizes the
coverage of these properties, called LeakySineLU. We empirically evaluate the
LeakySineLU against commonly used activations in the literature using 112
benchmark datasets for time series classification, obtaining the best average
ranking in all comparative scenarios.

摘要：這篇論文探討時間序列任務中神經網路模型的激活函數研究不足的問題。它強調了識別這些激活函數基本特性的必要性，以提高它們在特定領域的有效性。為此，本研究全面分析了時間序列神經網路中激活函數的性質，例如有界、單調、非線性和週期性。我們提出了一個新的激活函數 LeakySineLU，它最大化了這些性質的覆蓋範圍。我們使用 112 個時間序列分類基準資料集，根據文獻中常用的激活函數對 LeakySineLU 進行實證評估，在所有比較情境中獲得最佳平均排名。

##### **CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls**
2412.09887v1 by Li Chai, Donglin Wang

Lyric-to-melody generation is a highly challenging task in the field of AI
music generation. Due to the difficulty of learning strict yet weak
correlations between lyrics and melodies, previous methods have suffered from
weak controllability, low-quality and poorly structured generation. To address
these challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody
generation method based on an in-attention Transformer decoder with
fine-grained lyric and musical controls, which is able to generate full-song
melodies matched with the given lyrics and user-specified musical attributes.
Specifically, we first introduce REMI-Aligned, a novel music representation
that incorporates strict syllable- and sentence-level alignments between lyrics
and melodies, facilitating precise alignment modeling. Subsequently,
sentence-level semantic lyric embeddings independently extracted from a
sentence-wise Transformer encoder are combined with word-level part-of-speech
embeddings and syllable-level tone embeddings as fine-grained controls to
enhance the controllability of lyrics over melody generation. Then we introduce
human-labeled musical tags, sentence-level statistical musical attributes, and
learned musical features extracted from a pre-trained VQ-VAE as coarse-grained,
fine-grained and high-fidelity controls, respectively, to the generation
process, thereby enabling user control over melody generation. Finally, an
in-attention Transformer decoder technique is leveraged to exert fine-grained
control over the full-song melody generation with the aforementioned lyric and
musical conditions. Experimental results demonstrate that our proposed CSL-L2M
outperforms the state-of-the-art models, generating melodies with higher
quality, better controllability and enhanced structure. Demos and source code
are available at https://lichaiustc.github.io/CSL-L2M/.

摘要：歌詞轉旋律生成是 AI 音樂生成領域中極具挑戰性的任務。由於難以學習歌詞和旋律之間嚴格但薄弱的相關性，以前的生成方法一直飽受可控性差、品質低落且結構不良的困擾。為了應對這些挑戰，我們提出了 CSL-L2M，這是一種可控的歌曲級歌詞轉旋律生成方法，它基於帶有細粒度歌詞和音樂控制的非注意力 Transformer 解碼器，能夠生成與給定歌詞和使用者指定的音樂屬性相匹配的全曲旋律。具體來說，我們首先介紹 REMI-Aligned，這是一種新穎的音樂表示，它結合了歌詞和旋律之間嚴格的音節和句子級別對齊，促進了精確對齊建模。隨後，從句子級 Transformer 編碼器中獨立提取的句子級語義歌詞嵌入與詞級詞性嵌入和音節級音調嵌入相結合，作為細粒度控制，以增強歌詞對旋律生成的控制力。然後，我們在生成過程中分別將人工標記的音樂標籤、句子級統計音樂屬性以及從預訓練的 VQ-VAE 中提取的學習音樂特徵引入為粗粒度、細粒度和高保真控制，從而使用戶能夠控制旋律生成。最後，利用非注意力 Transformer 解碼器技術，對全曲旋律生成施加細粒度控制，並具備上述歌詞和音樂條件。實驗結果表明，我們提出的 CSL-L2M 優於最先進的模型，生成的旋律具有更高的品質、更好的可控性以及增強的結構。展示和源代碼可在 https://lichaiustc.github.io/CSL-L2M/ 獲得。

##### **Benchmarking Table Comprehension In The Wild**
2412.09884v1 by Yikang Pan, Yi Zhu, Rand Xie, Yizhi Liu

Large Language Models (LLMs), while being increasingly dominant on a myriad
of knowledge-intensive activities, have only had limited success understanding
lengthy table-text mixtures, such as academic papers and financial reports.
Recent advances of long-context LLMs have opened up new possibilities for this
field. Nonetheless, we identify two roadblocks: (1) Prior benchmarks of table
question answering (TableQA) have focused on isolated tables without context,
making it hard to evaluate models in real-world scenarios. (2) Prior benchmarks
have focused on some narrow skill sets of table comprehension such as table
recognition, data manipulation/calculation, table summarization etc., while a
skilled human employs those skills collectively. In this work, we introduce
TableQuest, a new benchmark designed to evaluate the holistic table
comprehension capabilities of LLMs in the natural table-rich context of
financial reports. We employ a rigorous data processing and filtering procedure
to ensure that the question-answer pairs are logical, reasonable, and diverse.
We experiment with 7 state-of-the-art models, and find that despite reasonable
accuracy in locating facts, they often falter when required to execute more
sophisticated reasoning or multi-step calculations. We conclude with a
qualitative study of the failure modes and discuss the challenges of
constructing a challenging benchmark. We make the evaluation data, judging
procedure and results of this study publicly available to facilitate research
in this field.

摘要：大型語言模型 (LLM) 儘管在各種知識密集活動中越來越佔主導地位，但在理解冗長的表格文字混合物（例如學術論文和財務報告）方面卻僅獲得有限的成功。長語境 LLM 的最新進展為這個領域開啟了新的可能性。儘管如此，我們發現了兩個障礙：(1) 先前的表格問題回答 (TableQA) 基準側重於沒有語境的孤立表格，這使得在真實世界場景中評估模型變得困難。(2) 先前的基準側重於表格理解的一些狹窄技能，例如表格識別、數據處理/計算、表格摘要等，而熟練的人員會綜合運用這些技能。在這項工作中，我們介紹了 TableQuest，這是一個新的基準，旨在評估 LLM 在財務報告的自然表格豐富語境中的整體表格理解能力。我們採用嚴格的數據處理和過濾程序，以確保問題答案對具有邏輯性、合理性和多樣性。我們使用 7 個最先進的模型進行實驗，發現儘管在定位事實方面具有合理的準確性，但它們在需要執行更複雜的推理或多步驟計算時常常會失敗。我們以失敗模式的定性研究作為結論，並討論了構建具有挑戰性的基準的挑戰。我們公開評估數據、評審程序和本研究的結果，以促進該領域的研究。

##### **On the Limit of Language Models as Planning Formalizers**
2412.09879v1 by Cassie Huang, Li Zhang

Large Language Models have been shown to fail to create executable and
verifiable plans in grounded environments. An emerging line of work shows
success in using LLM as a formalizer to generate a formal representation (e.g.,
PDDL) of the planning domain, which can be deterministically solved to find a
plan. We systematically evaluate this methodology while bridging some major
gaps. While previous work only generates a partial PDDL representation given
templated and thus unrealistic environment descriptions, we generate the
complete representation given descriptions of various naturalness levels. Among
an array of observations critical to improve LLMs' formal planning ability, we
note that large enough models can effectively formalize descriptions as PDDL,
outperforming those directly generating plans, while being robust to lexical
perturbation. As the descriptions become more natural-sounding, we observe a
decrease in performance and provide detailed error analysis.

摘要：大型語言模型已被證明無法在接地的環境中建立可執行和可驗證的計畫。新興的工作路線顯示，使用 LLM 作為形式化器來產生規劃領域的形式化表示（例如，PDDL）是成功的，該表示可以確定性地求解以找到一個計畫。我們系統性地評估此方法，同時彌合一些主要差距。雖然先前的工作只產生部分 PDDL 表示，給定模板化且不切實際的環境描述，但我們產生了給定各種自然程度描述的完整表示。在改進 LLM 形式化規劃能力的眾多觀察中，我們注意到足夠大的模型可以有效地將描述形式化為 PDDL，優於直接產生計畫的模型，同時對詞彙擾動具有魯棒性。隨著描述變得更自然，我們觀察到性能下降並提供詳細的錯誤分析。

##### **Byte Latent Transformer: Patches Scale Better Than Tokens**
2412.09871v1 by Artidoro Pagnoni, Ram Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu, Jason Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srinivasan Iyer

We introduce the Byte Latent Transformer (BLT), a new byte-level LLM
architecture that, for the first time, matches tokenization-based LLM
performance at scale with significant improvements in inference efficiency and
robustness. BLT encodes bytes into dynamically sized patches, which serve as
the primary units of computation. Patches are segmented based on the entropy of
the next byte, allocating more compute and model capacity where increased data
complexity demands it. We present the first FLOP controlled scaling study of
byte-level models up to 8B parameters and 4T training bytes. Our results
demonstrate the feasibility of scaling models trained on raw bytes without a
fixed vocabulary. Both training and inference efficiency improve due to
dynamically selecting long patches when data is predictable, along with
qualitative improvements on reasoning and long tail generalization. Overall,
for fixed inference costs, BLT shows significantly better scaling than
tokenization-based models, by simultaneously growing both patch and model size.

摘要：我們介紹 Byte Latent Transformer (BLT)，這是一種新的位元組級別 LLM 架構，它首次以顯著提升的推論效率和穩健性，匹配了基於標記化的 LLM 的規模化效能。BLT 將位元組編碼成動態大小的區塊，作為運算的主要單位。區塊根據下一個位元組的熵進行分割，在增加的資料複雜度需要時，分配更多運算和模型容量。我們提供了第一個 FLOP 控制的位元組級別模型擴充研究，參數高達 8B，訓練位元組高達 4T。我們的結果證明了在沒有固定詞彙表的情況下，擴充在原始位元組上訓練的模型的可行性。由於在資料可預測時動態選擇長區塊，以及在推理和長尾概括上的質化改進，訓練和推論效率都有所提升。總體而言，對於固定的推論成本，BLT 透過同時增加區塊和模型大小，展現出比基於標記化的模型顯著更好的擴充。

##### **Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for Supervised Fine-tuning**
2412.09859v1 by Abraham Atsiwo

The Efficient Market Hypothesis (EMH) highlights the essence of financial
news in stock price movement. Financial news comes in the form of corporate
announcements, news titles, and other forms of digital text. The generation of
insights from financial news can be done with sentiment analysis.
General-purpose language models are too general for sentiment analysis in
finance. Curated labeled data for fine-tuning general-purpose language models
are scare, and existing fine-tuned models for sentiment analysis in finance do
not capture the maximum context width. We hypothesize that using actual and
synthetic data can improve performance. We introduce BertNSP-finance to
concatenate shorter financial sentences into longer financial sentences, and
finbert-lc to determine sentiment from digital text. The results show improved
performance on the accuracy and the f1 score for the financial phrasebank data
with $50\%$ and $100\%$ agreement levels.

摘要：有效市場假設 (EMH) 強調了財經新聞在股價變動中的精髓。財經新聞以公司公告、新聞標題和其他形式的數位文字呈現。從財經新聞中產生見解可以使用情緒分析來完成。
通用語言模型對於財務中的情緒分析來說過於通用。用於微調通用語言模型的精選標籤數據很稀少，而現有的用於財務情緒分析的微調模型無法捕捉最大的上下文寬度。我們假設使用實際和合成數據可以提高性能。我們引入 BertNSP-finance 將較短的財務句子串聯成較長的財務句子，以及 finbert-lc 從數位文字中確定情緒。結果顯示在準確性和 f1 分數上改進了財務詞彙庫數據的表現，同意程度為 50% 和 100%。

##### **RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning**
2412.09858v1 by Charles Xu, Qiyang Li, Jianlan Luo, Sergey Levine

Recent advances in robotic foundation models have enabled the development of
generalist policies that can adapt to diverse tasks. While these models show
impressive flexibility, their performance heavily depends on the quality of
their training data. In this work, we propose Reinforcement Learning Distilled
Generalists (RLDG), a method that leverages reinforcement learning to generate
high-quality training data for finetuning generalist policies. Through
extensive real-world experiments on precise manipulation tasks like connector
insertion and assembly, we demonstrate that generalist policies trained with
RL-generated data consistently outperform those trained with human
demonstrations, achieving up to 40% higher success rates while generalizing
better to new tasks. We also provide a detailed analysis that reveals this
performance gain stems from both optimized action distributions and improved
state coverage. Our results suggest that combining task-specific RL with
generalist policy distillation offers a promising approach for developing more
capable and efficient robotic manipulation systems that maintain the
flexibility of foundation models while achieving the performance of specialized
controllers. Videos and code can be found on our project website
https://generalist-distillation.github.io

摘要：機器人基礎模型的最新進展已能開發出適應各種任務的通才策略。儘管這些模型展現出令人印象深刻的靈活性，但其效能卻高度依賴於訓練資料的品質。在這項工作中，我們提出強化學習蒸餾通才 (RLDG)，這是一種運用強化學習來產生高品質訓練資料以微調通才策略的方法。透過針對精準操作任務（如連接器插入和組裝）進行廣泛的實際實驗，我們證明使用 RL 生成的資料訓練出的通才策略，其效能始終優於使用人類示範訓練出的策略，在推廣到新任務時可將成功率提高多達 40%。我們也提供詳細分析，揭示這種效能提升來自於最佳化的動作分配和改善的狀態覆蓋率。我們的結果表明，將特定任務的 RL 與通才策略蒸餾結合，為開發更強大、更有效率的機器人操作系統提供了一種有前途的方法，這種系統在維持基礎模型的靈活性的同時，也能達到專用控制器的效能。可以在我們的專案網站 https://generalist-distillation.github.io 找到影片和程式碼

##### **LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity**
2412.09856v1 by Hongjie Wang, Chih-Yao Ma, Yen-Cheng Liu, Ji Hou, Tao Xu, Jialiang Wang, Felix Juefei-Xu, Yaqiao Luo, Peizhao Zhang, Tingbo Hou, Peter Vajda, Niraj K. Jha, Xiaoliang Dai

Text-to-video generation enhances content creation but is highly
computationally intensive: The computational cost of Diffusion Transformers
(DiTs) scales quadratically in the number of pixels. This makes minute-length
video generation extremely expensive, limiting most existing models to
generating videos of only 10-20 seconds length. We propose a Linear-complexity
text-to-video Generation (LinGen) framework whose cost scales linearly in the
number of pixels. For the first time, LinGen enables high-resolution
minute-length video generation on a single GPU without compromising quality. It
replaces the computationally-dominant and quadratic-complexity block,
self-attention, with a linear-complexity block called MATE, which consists of
an MA-branch and a TE-branch. The MA-branch targets short-to-long-range
correlations, combining a bidirectional Mamba2 block with our token
rearrangement method, Rotary Major Scan, and our review tokens developed for
long video generation. The TE-branch is a novel TEmporal Swin Attention block
that focuses on temporal correlations between adjacent tokens and medium-range
tokens. The MATE block addresses the adjacency preservation issue of Mamba and
improves the consistency of generated videos significantly. Experimental
results show that LinGen outperforms DiT (with a 75.6% win rate) in video
quality with up to 15$\times$ (11.5$\times$) FLOPs (latency) reduction.
Furthermore, both automatic metrics and human evaluation demonstrate our
LinGen-4B yields comparable video quality to state-of-the-art models (with a
50.5%, 52.1%, 49.1% win rate with respect to Gen-3, LumaLabs, and Kling,
respectively). This paves the way to hour-length movie generation and real-time
interactive video generation. We provide 68s video generation results and more
examples in our project website: https://lineargen.github.io/.

摘要：文本到影片生成會增強內容創作，但計算成本極高：擴散式Transformer (DiT) 的計算成本會隨著像素數平方增加。這使得影片生成極為昂貴，限制大多數現有模型只能產生長度僅 10-20 秒的影片。我們提出一個線性複雜度文本到影片生成 (LinGen) 架構，其成本會隨著像素數線性增加。LinGen 首次在單一 GPU 上實現高解析度分鐘長度影片生成，且不損害品質。它使用線性複雜度區塊 MATE 取代計算量龐大且複雜度為平方的自注意力區塊，MATE 包含 MA 分支和 TE 分支。MA 分支鎖定短距離到長距離關聯，結合雙向 Mamba2 區塊與我們的代幣重新排列方法、旋轉主掃描，以及我們針對長影片生成所開發的審查代幣。TE 分支是一種新穎的時序 Swin 注意力區塊，專注於相鄰代幣和中距離代幣之間的時序關聯。MATE 區塊解決了 Mamba 的鄰接保留問題，並大幅改善生成影片的一致性。實驗結果顯示，LinGen 在影片品質上優於 DiT（勝率 75.6%），且 FLOP（延遲）減少多達 15 倍（11.5 倍）。此外，自動指標和人為評估都證明我們的 LinGen-4B 產生與最先進模型相當的影片品質（與 Gen-3、LumaLabs 和 Kling 相比，勝率分別為 50.5%、52.1%、49.1%）。這為小時長度電影生成和即時互動影片生成鋪路。我們在專案網站中提供 68 秒影片生成結果和更多範例：https://lineargen.github.io/。

##### **Learning Structural Causal Models from Ordering: Identifiable Flow Models**
2412.09843v1 by Minh Khoa Le, Kien Do, Truyen Tran

In this study, we address causal inference when only observational data and a
valid causal ordering from the causal graph are available. We introduce a set
of flow models that can recover component-wise, invertible transformation of
exogenous variables. Our flow-based methods offer flexible model design while
maintaining causal consistency regardless of the number of discretization
steps. We propose design improvements that enable simultaneous learning of all
causal mechanisms and reduce abduction and prediction complexity to linear O(n)
relative to the number of layers, independent of the number of causal
variables. Empirically, we demonstrate that our method outperforms previous
state-of-the-art approaches and delivers consistent performance across a wide
range of structural causal models in answering observational, interventional,
and counterfactual questions. Additionally, our method achieves a significant
reduction in computational time compared to existing diffusion-based
techniques, making it practical for large structural causal models.

摘要：在這個研究中，我們在只有觀察資料和因果圖中有效的因果順序時，探討因果推論。我們介紹了一組流動模型，可以恢復外生變數的組成部分、可逆轉換。我們的基於流動的方法提供了靈活的模型設計，同時無論離散化步驟的數量如何，都能維持因果一致性。我們提出了設計改進，能夠同時學習所有因果機制，並將外推和預測複雜度降低為線性 O(n)，相對於層數，與因果變數的數量無關。根據經驗，我們證明了我們的方法優於先前的最先進方法，並且在回答觀察、介入和反事實問題時，在各種結構因果模型中提供了穩定的效能。此外，與現有的基於擴散的技術相比，我們的方法在計算時間上實現了顯著的減少，這使得它適用於大型結構因果模型。

##### **Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models**
2412.09827v1 by Changqun Li, Chaofan Ding, Kexin Luan, Xinhan Di

Fine-tuning pre-trained large language models in a parameter-efficient manner
is widely studied for its effectiveness and efficiency. LoRA is one of the most
widely used methods, which assumes that the optimization process is essentially
low dimensional. Although LoRA has demonstrated commendable performance, there
remains a significant performance gap between LoRA and full fine-tuning when
learning new tasks. In this work, we propose Low-Rank Adaptation with
Task-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features
from the perspective of editing neural network representations. To prioritize
task-relevant features, a task-aware filter that selectively extracts valuable
knowledge from hidden representations for the target or current task is
designed. As the experiments on a vareity of datasets including NLU,
commonsense reasoning and mathematical reasoning tasks demonstrates, our method
reduces 33.71% parameters and achieves better performance on a variety of
datasets in comparison with SOTA low-rank methods.

摘要：以參數有效率的方式微調預先訓練的大語言模型因其有效性和效率而廣受研究。LoRA 是其中一種最廣泛使用的方法，它假設最佳化過程本質上是低維度的。儘管 LoRA 已展現出令人稱道的效能，但在學習新任務時，LoRA 和完全微調之間仍存在顯著的效能差距。在這項工作中，我們提出具有任務相關特徵增強的低秩適應 (LoRATRF)，以編輯神經網路表示的方式增強與任務相關的特徵。為了優先考慮與任務相關的特徵，我們設計了一個任務感知篩選器，用於有選擇地從隱藏表示中提取有價值的知識，以供目標或當前任務使用。正如在包含 NLU、常識推理和數學推理任務在內的各種資料集上的實驗所示，與 SOTA 低秩方法相比，我們的模型減少了 33.71% 的參數，並在各種資料集上實現了更好的效能。

##### **Precise Antigen-Antibody Structure Predictions Enhance Antibody Development with HelixFold-Multimer**
2412.09826v1 by Jie Gao, Jing Hu, Lihang Liu, Yang Xue, Kunrui Zhu, Xiaonan Zhang, Xiaomin Fang

The accurate prediction of antigen-antibody structures is essential for
advancing immunology and therapeutic development, as it helps elucidate
molecular interactions that underlie immune responses. Despite recent progress
with deep learning models like AlphaFold and RoseTTAFold, accurately modeling
antigen-antibody complexes remains a challenge due to their unique evolutionary
characteristics. HelixFold-Multimer, a specialized model developed for this
purpose, builds on the framework of AlphaFold-Multimer and demonstrates
improved precision for antigen-antibody structures. HelixFold-Multimer not only
surpasses other models in accuracy but also provides essential insights into
antibody development, enabling more precise identification of binding sites,
improved interaction prediction, and enhanced design of therapeutic antibodies.
These advances underscore HelixFold-Multimer's potential in supporting antibody
research and therapeutic innovation.

摘要：準確預測抗原抗體結構對於免疫學和治療開發至關重要，因為它有助於闡明免疫反應的基礎分子交互作用。儘管像 AlphaFold 和 RoseTTAFold 等深度學習模型取得了進展，但由於抗原抗體複合物的獨特演化特性，準確建模仍然是一個挑戰。HelixFold-Multimer 是為此目的開發的專用模型，它建立在 AlphaFold-Multimer 的框架之上，並展示了抗原抗體結構的改進精度。HelixFold-Multimer 不僅在準確性上超越其他模型，還提供了對抗體開發的必要見解，從而能夠更精確地識別結合位點、改進交互作用預測以及增強治療性抗體的設計。這些進展強調了 HelixFold-Multimer 在支持抗體研究和治療創新方面的潛力。

##### **MERaLiON-AudioLLM: Technical Report**
2412.09818v1 by Yingxu He, Zhuohan Liu, Shuo Sun, Bin Wang, Wenyu Zhang, Xunlong Zou, Nancy F. Chen, Ai Ti Aw

We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning
in One Network), the first speech-text model tailored for Singapore's
multilingual and multicultural landscape. Developed under the National Large
Language Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates
advanced speech and text processing to address the diverse linguistic nuances
of local accents and dialects, enhancing accessibility and usability in
complex, multilingual environments. Our results demonstrate improvements in
both speech recognition and task-specific understanding, positioning
MERaLiON-AudioLLM as a pioneering solution for region specific AI applications.
We envision this release to set a precedent for future models designed to
address localised linguistic and cultural contexts in a global framework.

摘要：我們推出 MERaLiON-AudioLLM（多模態同理推理和學習於一體網路），這是第一個專為新加坡的多語言和多元文化環境量身打造的語音文本模型。在新加坡國家大型語言模型資助計畫下開發的 MERaLiON-AudioLLM 整合了進階的語音和文字處理，以應對當地口音和方言的多樣化語言差異，提升在複雜的多語言環境中的可及性和可用性。我們的結果證明了語音辨識和特定任務理解都有所進步，讓 MERaLiON-AudioLLM 成為區域特定 AI 應用的一項先驅解決方案。我們預見此版本將為未來模型樹立先例，這些模型旨在在全球架構中應對在地化的語言和文化背景。

##### **Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation**
2412.09817v1 by Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao

Multimodal large language models have experienced rapid growth, and numerous
different models have emerged. The interpretability of LVLMs remains an
under-explored area. Especially when faced with more complex tasks such as
chain-of-thought reasoning, its internal mechanisms still resemble a black box
that is difficult to decipher. By studying the interaction and information flow
between images and text, we noticed that in models such as LLaVA1.5, image
tokens that are semantically related to text are more likely to have
information flow convergence in the LLM decoding layer, and these image tokens
receive higher attention scores. However, those image tokens that are less
relevant to the text do not have information flow convergence, and they only
get very small attention scores. To efficiently utilize the image information,
we propose a new image token reduction method, Simignore, which aims to improve
the complex reasoning ability of LVLMs by computing the similarity between
image and text embeddings and ignoring image tokens that are irrelevant and
unimportant to the text. Through extensive experiments, we demonstrate the
effectiveness of our method for complex reasoning tasks. The paper's source
code can be accessed from \url{https://github.com/FanshuoZeng/Simignore}.

摘要：多模态大型语言模型经历了快速发展，并且出现了许多不同的模型。LLVM 的可解释性仍然是一个尚未充分探索的领域。特别是当面临链式思维推理等更复杂的任务时，其内部机制仍然类似于一个难以破译的黑匣子。通过研究图像和文本之间的交互和信息流，我们注意到在 LLaVA1.5 等模型中，与文本语义相关的图像标记更有可能在 LLM 解码层中具有信息流收敛，并且这些图像标记接收更高的注意力分数。然而，那些与文本相关性较低的图像标记没有信息流收敛，而且它们只获得非常小的注意力分数。为了有效利用图像信息，我们提出了一种新的图像标记简化方法 Simignore，其旨在通过计算图像和文本嵌入之间的相似性并忽略与文本无关且不重要的图像标记来提高 LLVMs 的复杂推理能力。通过广泛的实验，我们证明了我们的方法对复杂推理任务的有效性。本文的源代码可以从 \url{https://github.com/FanshuoZeng/Simignore} 访问。

##### **Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated Learning**
2412.09814v1 by Jianhong Chen, Ying Ma, Xubo Yue

Traditionally, learning the structure of a Dynamic Bayesian Network has been
centralized, with all data pooled in one location. However, in real-world
scenarios, data are often dispersed among multiple parties (e.g., companies,
devices) that aim to collaboratively learn a Dynamic Bayesian Network while
preserving their data privacy and security. In this study, we introduce a
federated learning approach for estimating the structure of a Dynamic Bayesian
Network from data distributed horizontally across different parties. We propose
a distributed structure learning method that leverages continuous optimization
so that only model parameters are exchanged during optimization. Experimental
results on synthetic and real datasets reveal that our method outperforms other
state-of-the-art techniques, particularly when there are many clients with
limited individual sample sizes.

摘要：傳統上，學習動態貝氏網路的結構是集中式的，所有資料都集中在一個位置。然而，在真實世界的場景中，資料通常分散在多個參與者（例如公司、裝置）中，他們希望在保留資料隱私和安全性的同時，協作學習動態貝氏網路。在這項研究中，我們引入了一種聯邦學習方法，用於估計橫跨不同參與者的資料中動態貝氏網路的結構。我們提出了一種分佈式結構學習方法，利用連續最佳化，這樣在最佳化過程中只會交換模型參數。在合成和真實資料集上的實驗結果顯示，我們的模型優於其他最先進的技術，特別是在有許多客戶且個別樣本大小有限的情況下。

##### **ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic LayerReplace and Selective Rank Compression**
2412.09812v1 by Kai Yao, Zhaorui Tan, Tiandi Ye, Lichun Li, Yuan Zhao, Wenyan Liu, Wei Wang, Jianke Zhu

Offsite-tuning is a privacy-preserving method for tuning large language
models (LLMs) by sharing a lossy compressed emulator from the LLM owners with
data owners for downstream task tuning. This approach protects the privacy of
both the model and data owners. However, current offsite tuning methods often
suffer from adaptation degradation, high computational costs, and limited
protection strength due to uniformly dropping LLM layers or relying on
expensive knowledge distillation. To address these issues, we propose ScaleOT,
a novel privacy-utility-scalable offsite-tuning framework that effectively
balances privacy and utility. ScaleOT introduces a novel layerwise lossy
compression algorithm that uses reinforcement learning to obtain the importance
of each layer. It employs lightweight networks, termed harmonizers, to replace
the raw LLM layers. By combining important original LLM layers and harmonizers
in different ratios, ScaleOT generates emulators tailored for optimal
performance with various model scales for enhanced privacy protection.
Additionally, we present a rank reduction method to further compress the
original LLM layers, significantly enhancing privacy with negligible impact on
utility. Comprehensive experiments show that ScaleOT can achieve nearly
lossless offsite tuning performance compared with full fine-tuning while
obtaining better model privacy.

摘要：場外微調是一種隱私保護方法，用於透過 LLM 所有者與資料所有者分享有損失壓縮的 LLM 模擬器，以進行下游任務微調，進而微調大型語言模型 (LLM)。此方法保護模型和資料所有者的隱私。然而，目前的場外微調方法通常會因為適應性降低、高運算成本和有限的保護強度而受苦，這是因為均勻地捨棄 LLM 層或依賴昂貴的知識萃取。為了解決這些問題，我們提出 ScaleOT，這是一個新穎的隱私公用事業可擴充場外微調架構，能有效平衡隱私和公用事業。ScaleOT 介紹了一種新穎的逐層有損失壓縮演算法，該演算法使用強化學習來取得每一層的重要性。它採用稱為調和器的輕量級網路，以取代原始的 LLM 層。透過以不同的比例結合重要的原始 LLM 層和調和器，ScaleOT 能產生針對最佳效能量身打造的模擬器，並具備各種模型規模以增強隱私保護。此外，我們提出一個秩次簡約法，以進一步壓縮原始的 LLM 層，大幅提升隱私，且對公用事業的影響可以忽略不計。全面的實驗顯示，與完全微調相比，ScaleOT 能夠達成近乎無損失的場外微調效能，同時還能取得更好的模型隱私。

##### **LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering**
2412.09807v1 by Patrick Sutanto, Joan Santoso

Multiple Choice Question Answering (MCQA) is an important problem with
numerous real-world applications, such as medicine, law, and education. The
high cost of building MCQA datasets makes few-shot learning pivotal in this
domain. While Large Language Models (LLMs) can enable few-shot learning, their
direct application in real-world scenarios is often hindered by their high
computational cost. To address this challenge, we propose a simple yet
effective approach that uses LLMs for data generation and scoring. Our approach
utilizes LLMs to create MCQA data which contains questions and choices, and to
assign probability scores to the generated choices. We then use the generated
data and LLM-assigned scores to finetune a smaller and more efficient
encoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive
experiments on the Massive Multitask Language Understanding (MMLU) benchmark
demonstrate that our method improves accuracy from 28.9% to 39.3%, representing
a gain of over 10% compared to a baseline finetuned directly on 5-shot
examples. This shows the effectiveness of LLM-driven data generation and
knowledge distillation for few-shot MCQA.

摘要：多選題問答 (MCQA) 是一個重要的問題，在現實世界中有許多應用，例如醫學、法律和教育。建立 MCQA 資料集的成本很高，這使得小樣本學習在這個領域至關重要。儘管大型語言模型 (LLM) 可以支援小樣本學習，但它們在實際場景中的直接應用常常受到其高昂的運算成本所阻礙。為了應對這個挑戰，我們提出了一種簡單但有效的方法，該方法使用 LLM 來進行資料產生和評分。我們的做法利用 LLM 來建立包含問題和選項的 MCQA 資料，並為產生的選項分配機率分數。然後，我們使用產生的資料和 LLM 分配的分數，藉由利用蒸餾損失來微調一個更小且更有效率的編碼器專用模型 DeBERTa-v3-base。在 Massive Multitask Language Understanding (MMLU) 基準上進行的廣泛實驗證明，我們的方法將準確率從 28.9% 提升至 39.3%，與直接微調在 5 次嘗試的範例上相比，增加了超過 10%。這顯示了 LLM 驅動的資料產生和知識蒸餾在小樣本 MCQA 中的有效性。

##### **Universal Inceptive GNNs by Eliminating the Smoothness-generalization Dilemma**
2412.09805v1 by Ming Gu, Zhuonan Zheng, Sheng Zhou, Meihan Liu, Jiawei Chen, Tanyu Qiao, Liangcheng Li, Jiajun Bu

Graph Neural Networks (GNNs) have demonstrated remarkable success in various
domains, such as transaction and social net-works. However, their application
is often hindered by the varyinghomophily levels across different orders of
neighboring nodes, ne-cessitating separate model designs for homophilic and
heterophilicgraphs. In this paper, we aim to develop a unified framework
ca-pable of handling neighborhoods of various orders and homophilylevels.
Through theoretical exploration, we identify a previouslyoverlooked
architectural aspect in multi-hop learning: the cascadedependency, which leads
to asmoothness-generalization dilemma.This dilemma significantly affects the
learning process, especiallyin the context of high-order neighborhoods and
heterophilic graphs.To resolve this issue, we propose an Inceptive Graph Neural
Net-work (IGNN), a universal message-passing framework that replacesthe cascade
dependency with an inceptive architecture. IGNN pro-vides independent
representations for each hop, allowing personal-ized generalization
capabilities, and captures neighborhood-wiserelationships to select appropriate
receptive fields. Extensive ex-periments show that our IGNN outperforms 23
baseline methods,demonstrating superior performance on both homophilic and
het-erophilic graphs, while also scaling efficiently to large graphs.

摘要：圖神經網路 (GNN) 已在各種領域中展現出顯著的成功，例如交易和社交網路。然而，其應用通常會受到不同順序鄰接節點之間不同同質性層級的阻礙，因此需要針對同質性與異質性圖形設計不同的模型。在本文中，我們旨在開發一個統一的架構，能夠處理不同順序和同質性層級的鄰域。透過理論探討，我們識別出多跳學習中先前被忽略的架構層面：串聯依賴性，這會導致平滑性泛化兩難。此兩難顯著影響學習過程，特別是在高階鄰域和異質性圖形中。為了解決此問題，我們提出一個深度圖神經網路 (IGNN)，一個通用的訊息傳遞架構，以深度架構取代串聯依賴性。IGNN 為每個跳躍提供獨立的表示，允許個人化的泛化能力，並擷取鄰域更明智的關係以選擇適當的感受野。廣泛的實驗顯示，我們的 IGNN 優於 23 種基準方法，證明了在同質性和異質性圖形上都具有優異的效能，同時也能有效擴充到大型圖形。

##### **CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection**
2412.09799v1 by Qibo Chen, Weizhong Jin, Jianyue Ge, Mengdi Liu, Yuchao Yan, Jian Jiang, Li Yu, Xuanjiang Guo, Shuchang Li, Jianzhong Chen

Recent research on universal object detection aims to introduce language in a
SoTA closed-set detector and then generalize the open-set concepts by
constructing large-scale (text-region) datasets for training. However, these
methods face two main challenges: (i) how to efficiently use the prior
information in the prompts to genericise objects and (ii) how to reduce
alignment bias in the downstream tasks, both leading to sub-optimal performance
in some scenarios beyond pre-training. To address these challenges, we propose
a strong universal detection foundation model called CP-DETR, which is
competitive in almost all scenarios, with only one pre-training weight.
Specifically, we design an efficient prompt visual hybrid encoder that enhances
the information interaction between prompt and visual through scale-by-scale
and multi-scale fusion modules. Then, the hybrid encoder is facilitated to
fully utilize the prompted information by prompt multi-label loss and auxiliary
detection head. In addition to text prompts, we have designed two practical
concept prompt generation methods, visual prompt and optimized prompt, to
extract abstract concepts through concrete visual examples and stably reduce
alignment bias in downstream tasks. With these effective designs, CP-DETR
demonstrates superior universal detection performance in a broad spectrum of
scenarios. For example, our Swin-T backbone model achieves 47.6 zero-shot AP on
LVIS, and the Swin-L backbone model achieves 32.2 zero-shot AP on ODinW35.
Furthermore, our visual prompt generation method achieves 68.4 AP on COCO val
by interactive detection, and the optimized prompt achieves 73.1 fully-shot AP
on ODinW13.

摘要：<paragraph>最近的通用物体检测研究旨在在 SoTA 闭集检测器中引入语言，然后通过构建用于训练的大规模（文本区域）数据集来概括开放集概念。然而，这些方法面临两个主要挑战：（i）如何有效地使用提示中的先验信息来泛化对象，以及（ii）如何减少下游任务中的对齐偏差，这两者都会导致在某些超出预训练的场景中出现次优性能。为了应对这些挑战，我们提出了一个名为 CP-DETR 的强大的通用检测基础模型，该模型在几乎所有场景中都具有竞争力，并且只有一个预训练权重。具体来说，我们设计了一个高效的提示视觉混合编码器，它通过按比例融合模块和多尺度融合模块增强了提示和视觉之间的信息交互。然后，通过提示多标签损失和辅助检测头，促进混合编码器充分利用提示信息。除了文本提示之外，我们还设计了两种实用的概念提示生成方法，即视觉提示和优化提示，以通过具体的视觉示例提取抽象概念并稳定地减少下游任务中的对齐偏差。通过这些有效的设计，CP-DETR 在广泛的场景中展示了卓越的通用检测性能。例如，我们的 Swin-T 主干模型在 LVIS 上实现了 47.6 的零次 AP，而 Swin-L 主干模型在 ODinW35 上实现了 32.2 的零次 AP。此外，我们的视觉提示生成方法通过交互式检测在 COCO val 上实现了 68.4 AP，而优化提示在 ODinW13 上实现了 73.1 的全次 AP。</paragraph>

##### **AutoPatent: A Multi-Agent Framework for Automatic Patent Generation**
2412.09796v1 by Qiyao Wang, Shiwen Ni, Huaren Liu, Shule Lu, Guhong Chen, Xi Feng, Chi Wei, Qiang Qu, Hamid Alinejad-Rokny, Yuan Lin, Min Yang

As the capabilities of Large Language Models (LLMs) continue to advance, the
field of patent processing has garnered increased attention within the natural
language processing community. However, the majority of research has been
concentrated on classification tasks, such as patent categorization and
examination, or on short text generation tasks like patent summarization and
patent quizzes. In this paper, we introduce a novel and practical task known as
Draft2Patent, along with its corresponding D2P benchmark, which challenges LLMs
to generate full-length patents averaging 17K tokens based on initial drafts.
Patents present a significant challenge to LLMs due to their specialized
nature, standardized terminology, and extensive length. We propose a
multi-agent framework called AutoPatent which leverages the LLM-based planner
agent, writer agents, and examiner agent with PGTree and RRAG to generate
lengthy, intricate, and high-quality complete patent documents. The
experimental results demonstrate that our AutoPatent framework significantly
enhances the ability to generate comprehensive patents across various LLMs.
Furthermore, we have discovered that patents generated solely with the
AutoPatent framework based on the Qwen2.5-7B model outperform those produced by
larger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,
in both objective metrics and human evaluations. We will make the data and code
available upon acceptance at \url{https://github.com/QiYao-Wang/AutoPatent}.

摘要：隨著大型語言模型 (LLM) 的能力不斷進步，專利處理領域在自然語言處理社群中備受關注。然而，大部分研究都集中在分類任務上，例如專利分類和審查，或簡短文字生成任務，例如專利摘要和專利測驗。在本文中，我們介紹了一項新穎且實用的任務，稱為 Draft2Patent，以及其對應的 D2P 基準，它挑戰 LLM 根據初始草稿生成平均 17K 個代碼的全文專利。專利由於其專業性質、標準化術語和篇幅冗長，對 LLM 構成重大挑戰。我們提出了一個名為 AutoPatent 的多代理架構，它利用基於 LLM 的規劃器代理、寫作者代理和審查員代理與 PGTree 和 RRAG 來生成冗長、複雜且高品質的完整專利文件。實驗結果表明，我們的 AutoPatent 架構顯著增強了跨各種 LLM 生成綜合專利的能力。此外，我們發現僅使用基於 Qwen2.5-7B 模型的 AutoPatent 架構生成的專利在客觀指標和人類評估中都優於由更大、更強大的 LLM（例如 GPT-4o、Qwen2.5-72B 和 LLAMA3.1-70B）產生的專利。我們將在 \url{https://github.com/QiYao-Wang/AutoPatent} 上接受後提供數據和代碼。

##### **Learning Visually Grounded Domain Ontologies via Embodied Conversation and Explanation**
2412.09770v1 by Jonghyuk Park, Alex Lascarides, Subramanian Ramamoorthy

In this paper, we offer a learning framework in which the agent's knowledge
gaps are overcome through corrective feedback from a teacher whenever the agent
explains its (incorrect) predictions. We test it in a low-resource visual
processing scenario, in which the agent must learn to recognize distinct types
of toy truck. The agent starts the learning process with no ontology about what
types of trucks exist nor which parts they have, and a deficient model for
recognizing those parts from visual input. The teacher's feedback to the
agent's explanations addresses its lack of relevant knowledge in the ontology
via a generic rule (e.g., "dump trucks have dumpers"), whereas an inaccurate
part recognition is corrected by a deictic statement (e.g., "this is not a
dumper"). The learner utilizes this feedback not only to improve its estimate
of the hypothesis space of possible domain ontologies and probability
distributions over them, but also to use those estimates to update its visual
interpretation of the scene. Our experiments demonstrate that teacher-learner
pairs utilizing explanations and corrections are more data-efficient than those
without such a faculty.

摘要：在本文中，我們提供了一個學習架構，其中代理的知識差距會透過教師在代理解釋其（錯誤的）預測時提供的糾正回饋來克服。我們在低資源視覺處理場景中測試了它，其中代理必須學會辨識不同類型的玩具卡車。代理從學習過程中開始，沒有關於卡車類型或其零件的本體論，以及一個從視覺輸入中辨識這些零件的缺陷模型。教師對代理解釋的回饋透過一個通用規則（例如，「自卸卡車有自卸車斗」）來解決其在本體論中缺乏相關知識，而一個不準確的零件辨識則會透過一個指示性陳述（例如，「這不是自卸車斗」）來修正。學習者利用此回饋不僅可以改善其對可能的領域本體論的假設空間和其上機率分布的估計，還可以利用這些估計來更新其對場景的視覺詮釋。我們的實驗證明，利用解釋和修正的老師與學習者配對比沒有這種能力的配對更具資料效率。

##### **Memory Layers at Scale**
2412.09764v1 by Vincent-Pierre Berges, Barlas Oğuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Gosh

Memory layers use a trainable key-value lookup mechanism to add extra
parameters to a model without increasing FLOPs. Conceptually, sparsely
activated memory layers complement compute-heavy dense feed-forward layers,
providing dedicated capacity to store and retrieve information cheaply. This
work takes memory layers beyond proof-of-concept, proving their utility at
contemporary scale. On downstream tasks, language models augmented with our
improved memory layer outperform dense models with more than twice the
computation budget, as well as mixture-of-expert models when matched for both
compute and parameters. We find gains are especially pronounced for factual
tasks. We provide a fully parallelizable memory layer implementation,
demonstrating scaling laws with up to 128B memory parameters, pretrained to 1
trillion tokens, comparing to base models with up to 8B parameters.

摘要：記憶層使用可訓練的鍵值查詢機制，在不增加 FLOP 的情況下為模型新增額外參數。從概念上來說，稀疏激活記憶層補充了計算密集的稠密前饋層，提供了專門的容量來廉價儲存和擷取資訊。這項工作將記憶層帶離了概念驗證，證明了它們在當代規模上的效用。在下游任務中，使用我們改良的記憶層增強的語言模型，其效能優於計算預算增加兩倍以上的稠密模型，以及在計算和參數方面都匹配的專家混合模型。我們發現收益在事實任務中特別明顯。我們提供了一個完全可並行的記憶層實作，展示了高達 128B 記憶體參數的縮放定律，預訓練到 1 兆個 token，與高達 8B 參數的基本模型進行比較。

##### **Congruence-based Learning of Probabilistic Deterministic Finite Automata**
2412.09760v1 by Matías Carrasco, Franz Mayr, Sergio Yovine

This work studies the question of learning probabilistic deterministic
automata from language models. For this purpose, it focuses on analyzing the
relations defined on algebraic structures over strings by equivalences and
similarities on probability distributions. We introduce a congruence that
extends the classical Myhill-Nerode congruence for formal languages. This new
congruence is the basis for defining regularity over language models. We
present an active learning algorithm that computes the quotient with respect to
this congruence whenever the language model is regular. The paper also defines
the notion of recognizability for language models and shows that it coincides
with regularity for congruences. For relations which are not congruences, it
shows that this is not the case. Finally, it discusses the impact of this
result on learning in the context of language models.

摘要：本研究探討從語言模型學習機率性確定自動機的問題。為此，它專注於分析由機率分佈上的等價性和相似性在字串上的代數結構所定義的關係。我們引入了一個同餘，它擴充了形式語言的經典 Myhill-Nerode 同餘。這個新的同餘是定義語言模型上正則性的基礎。我們提出了一個主動學習演算法，只要語言模型是正則的，它就會計算相對於這個同餘的商。本文還定義了語言模型的可辨識概念，並表明它與同餘的正則性一致。對於不是同餘的關係，它表明情況並非如此。最後，它討論了這個結果對語言模型中學習的影響。

##### **AI Red-Teaming is a Sociotechnical System. Now What?**
2412.09751v1 by Tarleton Gillespie, Ryland Shaw, Mary L. Gray, Jina Suh

As generative AI technologies find more and more real-world applications, the
importance of testing their performance and safety seems paramount.
``Red-teaming'' has quickly become the primary approach to test AI
models--prioritized by AI companies, and enshrined in AI policy and regulation.
Members of red teams act as adversaries, probing AI systems to test their
safety mechanisms and uncover vulnerabilities. Yet we know too little about
this work and its implications. This essay calls for collaboration between
computer scientists and social scientists to study the sociotechnical systems
surrounding AI technologies, including the work of red-teaming, to avoid
repeating the mistakes of the recent past. We highlight the importance of
understanding the values and assumptions behind red-teaming, the labor
involved, and the psychological impacts on red-teamers.

摘要：隨著生成式 AI 技術在現實世界中找到越來越多的應用，測試其效能和安全性顯得至關重要。
「紅隊」已迅速成為測試 AI 模型的主要方法，由 AI 公司優先考慮，並載入 AI 政策和法規中。
紅隊成員扮演對手，探測 AI 系統以測試其安全機制並找出漏洞。然而，我們對這項工作及其影響所知甚少。本文呼籲電腦科學家和社會科學家合作研究圍繞 AI 技術的社會技術系統，包括紅隊工作，以避免重蹈近期錯誤。我們強調了解紅隊背後的價值觀和假設、所涉及的勞動力以及對紅隊成員的心理影響的重要性。

##### **Let Curves Speak: A Continuous Glucose Monitor based Large Sensor Foundation Model for Diabetes Management**
2412.09727v1 by Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao

While previous studies of AI in diabetes management focus on long-term risk,
research on near-future glucose prediction remains limited but important as it
enables timely diabetes self-management. Integrating AI with continuous glucose
monitoring (CGM) holds promise for near-future glucose prediction. However,
existing models have limitations in capturing patterns of blood glucose
fluctuations and demonstrate poor generalizability. A robust approach is needed
to leverage massive CGM data for near-future glucose prediction. We propose
large sensor models (LSMs) to capture knowledge in CGM data by modeling
patients as sequences of glucose. CGM-LSM is pretrained on 15.96 million
glucose records from 592 diabetes patients for near-future glucose prediction.
We evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM
dataset across various metrics, prediction horizons, and unseen patients.
Additionally, we assessed its generalizability across factors like diabetes
type, age, gender, and hour of day. CGM-LSM achieved exceptional performance,
with an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for
type 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM
dataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous
best of 31.97 mg/dL. Robustness analyses revealed consistent performance not
only for unseen patients and future periods, but also across diabetes type,
age, and gender. The model demonstrated adaptability to different hours of day,
maintaining accuracy across periods of various activity intensity levels.
CGM-LSM represents a transformative step in diabetes management by leveraging
pretraining to uncover latent glucose generation patterns in sensor data. Our
findings also underscore the broader potential of LSMs to drive innovation
across domains involving complex sensor data.

摘要：儘管先前的糖尿病管理人工智慧研究著重於長期風險，
但對於近期血糖預測的研究仍然有限，但由於它能及時進行糖尿病自我管理，因此非常重要。將人工智慧與連續血糖監測 (CGM) 結合，有望進行近期血糖預測。然而，
現有模型在捕捉血糖波動模式方面有其限制，且顯示出不佳的概括性。需要一種穩健的方法來利用大量的 CGM 資料進行近期血糖預測。我們提出大型感測器模型 (LSM) 來捕捉 CGM 資料中的知識，方法是將患者建模為葡萄糖序列。CGM-LSM 在 592 位糖尿病患者的 1596 萬筆葡萄糖記錄上進行預訓練，以進行近期血糖預測。
我們使用 OhioT1DM 資料集根據各種指標、預測範圍和未見患者，針對最先進的方法評估 CGM-LSM。
此外，我們評估了它在糖尿病類型、年齡、性別和一天中的小時等因素中的概括性。CGM-LSM 達到了非凡的效能，在兩小時預測範圍內，1 型糖尿病患者的 rMSE 為 29.81 mg/dL，2 型糖尿病患者的 rMSE 為 23.49 mg/dL。對於 OhioT1DM 資料集，CGM-LSM 達到一小時 rMSE 為 15.64 mg/dL，將先前的最佳值 31.97 mg/dL 減半。穩健性分析顯示，效能不僅對於未見患者和未來期間一致，而且在糖尿病類型、年齡和性別方面也一致。該模型證明了對一天中不同小時的適應性，在各種活動強度時期保持準確性。
CGM-LSM 透過利用預訓練來揭示感測器資料中的潛在葡萄糖生成模式，代表了糖尿病管理的轉型步驟。我們的研究結果也強調了 LSM 在推動涉及複雜感測器資料的領域創新的更廣泛潛力。

##### **The Unreasonable Effectiveness of Gaussian Score Approximation for Diffusion Models and its Applications**
2412.09726v1 by Binxu Wang, John J. Vastola

By learning the gradient of smoothed data distributions, diffusion models can
iteratively generate samples from complex distributions. The learned score
function enables their generalization capabilities, but how the learned score
relates to the score of the underlying data manifold remains largely unclear.
Here, we aim to elucidate this relationship by comparing learned neural scores
to the scores of two kinds of analytically tractable distributions: Gaussians
and Gaussian mixtures. The simplicity of the Gaussian model makes it
theoretically attractive, and we show that it admits a closed-form solution and
predicts many qualitative aspects of sample generation dynamics. We claim that
the learned neural score is dominated by its linear (Gaussian) approximation
for moderate to high noise scales, and supply both theoretical and empirical
arguments to support this claim. Moreover, the Gaussian approximation
empirically works for a larger range of noise scales than naive theory suggests
it should, and is preferentially learned early in training. At smaller noise
scales, we observe that learned scores are better described by a coarse-grained
(Gaussian mixture) approximation of training data than by the score of the
training distribution, a finding consistent with generalization. Our findings
enable us to precisely predict the initial phase of trained models' sampling
trajectories through their Gaussian approximations. We show that this allows
the skipping of the first 15-30% of sampling steps while maintaining high
sample quality (with a near state-of-the-art FID score of 1.93 on CIFAR-10
unconditional generation). This forms the foundation of a novel hybrid sampling
method, termed analytical teleportation, which can seamlessly integrate with
and accelerate existing samplers, including DPM-Solver-v3 and UniPC. Our
findings suggest ways to improve the design and training of diffusion models.

摘要：透過學習平滑資料分佈的梯度，擴散模型可以反覆生成複雜分佈的樣本。學習到的分數函數能讓它們具備概化能力，但學習到的分數如何與底層資料流形的分數相關，在很大程度上仍不清楚。在此，我們旨在透過將學習到的神經分數與兩種解析可處理分佈（高斯分佈和高斯混合分佈）的分數進行比較，來闡明這種關係。高斯模型的簡潔性使其在理論上具有吸引力，我們表明它承認閉合形式的解，並預測了樣本生成動態的許多定性方面。我們聲稱，對於中等至高噪聲尺度，學習到的神經分數由其線性（高斯）近似主導，並提供理論和經驗論證來支持此說法。此外，高斯近似在比樸素理論所建議的更廣泛的噪聲尺度範圍內經驗上有效，並且在訓練早期優先學習。在較小的噪聲尺度下，我們觀察到學習到的分數由訓練資料的粗粒度（高斯混合）近似，而不是訓練分佈的分數來更好地描述，這一發現與概化相一致。我們的發現使我們能夠通過高斯近似準確預測訓練模型採樣軌跡的初始階段。我們表明，這允許跳過前 15-30% 的採樣步驟，同時保持高樣本品質（在 CIFAR-10 無條件生成上獲得接近最先進的 1.93 FID 分數）。這構成了創新混合採樣方法的基礎，稱為分析傳送，它可以無縫整合並加速現有採樣器，包括 DPM-Solver-v3 和 UniPC。我們的發現提出了改進擴散模型設計和訓練的方法。

##### **GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers**
2412.09722v1 by Sarkar Snigdha Sarathi Das, Ryo Kamoi, Bo Pang, Yusen Zhang, Caiming Xiong, Rui Zhang

The effectiveness of large language models (LLMs) is closely tied to the
design of prompts, making prompt optimization essential for enhancing their
performance across a wide range of tasks. Many existing approaches to
automating prompt engineering rely exclusively on textual feedback, refining
prompts based solely on inference errors identified by large, computationally
expensive LLMs. Unfortunately, smaller models struggle to generate high-quality
feedback, resulting in complete dependence on large LLM judgment. Moreover,
these methods fail to leverage more direct and finer-grained information, such
as gradients, due to operating purely in text space. To this end, we introduce
GReaTer, a novel prompt optimization technique that directly incorporates
gradient information over task-specific reasoning. By utilizing task loss
gradients, GReaTer enables self-optimization of prompts for open-source,
lightweight language models without the need for costly closed-source LLMs.
This allows high-performance prompt optimization without dependence on massive
LLMs, closing the gap between smaller models and the sophisticated reasoning
often needed for prompt refinement. Extensive evaluations across diverse
reasoning tasks including BBH, GSM8k, and FOLIO demonstrate that GReaTer
consistently outperforms previous state-of-the-art prompt optimization methods,
even those reliant on powerful LLMs. Additionally, GReaTer-optimized prompts
frequently exhibit better transferability and, in some cases, boost task
performance to levels comparable to or surpassing those achieved by larger
language models, highlighting the effectiveness of prompt optimization guided
by gradients over reasoning. Code of GReaTer is available at
https://github.com/psunlpgroup/GreaTer.

摘要：大型語言模型 (LLM) 的效能與提示設計息息相關，因此提示最佳化對於提升 LLM 在各種任務中的表現至關重要。許多現有的自動化提示工程方法僅依賴文字回饋，根據大型、運算成本高昂的 LLM 識別出的推論錯誤來改進提示。不幸的是，較小的模型難以產生高品質的回饋，導致完全依賴大型 LLM 的判斷。此外，這些方法由於純粹在文字空間中運作，無法利用更直接、更細緻的資訊，例如梯度。為此，我們引入了 GReaTer，這是一種新穎的提示最佳化技術，可直接將梯度資訊納入特定任務的推理中。透過利用任務損失梯度，GReaTer 可以為開放原始碼、輕量級語言模型進行提示自最佳化，無需依賴昂貴的閉源 LLM。這允許執行高性能提示最佳化，而無需依賴大型 LLM，縮小了較小模型與提示改進通常需要的複雜推理之間的差距。在包括 BBH、GSM8k 和 FOLIO 在內的各種推理任務中進行的廣泛評估表明，GReaTer 一致優於先前的提示最佳化方法，即使是依賴強大 LLM 的方法也是如此。此外，GReaTer 最佳化的提示通常表現出更好的可移植性，在某些情況下，任務效能提升至與較大型語言模型相當或超越其效能的程度，突顯了透過推理梯度引導的提示最佳化的效能。GReaTer 的程式碼可在 https://github.com/psunlpgroup/GreaTer 取得。

##### **Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection of Generated Images and the Impact of Prompts**
2412.09715v1 by Philipp Moeßner, Heike Adel

With the advent of publicly available AI-based text-to-image systems, the
process of creating photorealistic but fully synthetic images has been largely
democratized. This can pose a threat to the public through a simplified spread
of disinformation. Machine detectors and human media expertise can help to
differentiate between AI-generated (fake) and real images and counteract this
danger. Although AI generation models are highly prompt-dependent, the impact
of the prompt on the fake detection performance has rarely been investigated
yet. This work therefore examines the influence of the prompt's level of detail
on the detectability of fake images, both with an AI detector and in a user
study. For this purpose, we create a novel dataset, COCOXGEN, which consists of
real photos from the COCO dataset as well as images generated with SDXL and
Fooocus using prompts of two standardized lengths. Our user study with 200
participants shows that images generated with longer, more detailed prompts are
detected significantly more easily than those generated with short prompts.
Similarly, an AI-based detection model achieves better performance on images
generated with longer prompts. However, humans and AI models seem to pay
attention to different details, as we show in a heat map analysis.

摘要：隨著公開的人工智慧基於文字轉換圖像系統的出現，創造寫實但完全合成的圖像的過程在很大程度上已經民主化。這可能會透過簡化錯誤訊息的散布對公眾構成威脅。機器偵測器和人類媒體專業知識有助於區分人工智慧產生的（假的）和真實的圖像，並對抗這種危險。儘管人工智慧生成模型高度依賴提示，但提示對假偵測效能的影響卻很少受到調查。因此，這項工作探討了提示的詳細程度對假圖像的可偵測性的影響，同時使用人工智慧偵測器和使用者研究。為此，我們創建了一個新的資料集 COCOXGEN，其中包含來自 COCO 資料集的真實照片，以及使用兩種標準化長度的提示產生的 SDXL 和 Fooocus 影像。我們對 200 名參與者進行的使用者研究顯示，使用較長、更詳細的提示產生的圖像比使用簡短提示產生的圖像更容易被偵測到。同樣地，基於人工智慧的偵測模型在使用較長提示產生的圖像上獲得了更好的效能。然而，正如我們在熱點圖分析中所示，人類和人工智慧模型似乎關注不同的細節。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|

#### Abstracts
##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

摘要：機器學習和人工智慧在電子健康紀錄 (EHR) 上的應用具有
臨床見解的巨大潛力。然而，這種方法由於資料異質性、稀疏性、時間錯位和標記結果有限，因此面臨重大挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特郡和南格洛斯特郡的大約一百萬名去識別化個人的連結式 EHR 資料集，以描述泌尿道感染 (UTI) 並開發專注於資料品質、公平性和透明度的預測模型。全面的資料前處理和整理管道將原始 EHR 資料轉換為適合 AI 建模的結構化格式。鑑於實際 UTI 結果的可用性有限和偏見，我們引入了一個由臨床專業知識提供資訊的 UTI 風險評估架構，以估計個人患者時間線上的 UTI 風險。使用此架構，我們建立了成對的 XGBoost 模型，以區分 UTI 風險類別，並使用可解釋的 AI 技術來識別關鍵預測因子，同時確保可解釋性。我們的研究結果揭示了不同風險群組的臨床和人口統計因素的差異，提供了對 UTI 風險分層和進展的見解。本研究展示了 AI 驅動的見解在 UTI 臨床決策中的附加價值，同時優先考慮可解釋性、透明度和公平性，強調了健全資料實務在促進健康結果中的重要性。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

摘要：<paragraph>重要性估計器是一種可解釋性方法，用於量化深度神經網路 (DNN) 的特徵重要性。在視覺Transformer (ViT) 中，自我注意機制自然會導致注意力圖，有時會將其解釋為重要性分數，表示 ViT 模型關注哪些輸入特徵。然而，注意力圖並未考慮來自下游任務的信號。為了產生對下游任務敏感的解釋，我們開發了類別區分注意力圖 (CDAM)，這是一種基於梯度的擴充，用於估計相對於已知類別或潛在概念的特徵重要性。CDAM 根據對應的符號與分類器頭的預測相關程度，調整注意力分數。除了針對監督分類器外，CDAM 還可以通過測量 ViT 的潛在空間中的相似性來解釋選定樣本共有的任意概念。此外，我們引入了平滑 CDAM 和積分 CDAM，它們對一系列具有略微改變的符號的 CDAM 進行平均。我們的量化基準包括正確性、緊湊性和類別敏感性，與其他 7 個重要性估計器相比。香草、平滑和積分 CDAM 在所有三個基準中表現出色。特別是，我們的結果表明現有的重要性估計器可能無法提供足夠的類別敏感性。我們通過基於肺部電腦斷層掃描 (CT) 掃描訓練和解釋惡性腫瘤和生物標記預測模型，證明了 CDAM 在醫學影像中的效用。總的來說，CDAM 被證明具有高度類別區分性和語義相關性，同時提供簡潔的解釋。</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|[link](https://github.com/spongeorge/long-context-multihop)|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-12**|**Uncommon Belief in Rationality**|Qi Shi et.al.|[2412.09407v1](http://arxiv.org/abs/2412.09407v1)|null|
|**2024-12-12**|**Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**|Sai Bhargav Rongali et.al.|[2412.09230v1](http://arxiv.org/abs/2412.09230v1)|null|
|**2024-12-12**|**Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**|Ben Liu et.al.|[2412.09094v1](http://arxiv.org/abs/2412.09094v1)|[link](https://github.com/lb0828/ftg)|
|**2024-12-12**|**Neural Interactive Proofs**|Lewis Hammond et.al.|[2412.08897v1](http://arxiv.org/abs/2412.08897v1)|null|
|**2024-12-12**|**A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**|Jiankang Wang et.al.|[2412.08864v1](http://arxiv.org/abs/2412.08864v1)|null|
|**2024-12-11**|**In-Context Learning with Topological Information for Knowledge Graph Completion**|Udari Madhushani Sehwag et.al.|[2412.08742v1](http://arxiv.org/abs/2412.08742v1)|null|
|**2024-12-11**|**VEL: A Formally Verified Reasoner for OWL2 EL Profile**|Atalay Mert Ileri et.al.|[2412.08739v1](http://arxiv.org/abs/2412.08739v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v1](http://arxiv.org/abs/2412.08174v1)|null|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|[link](https://github.com/Xin-Cheng-Wen/RepoSPD)|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v2](http://arxiv.org/abs/2412.08038v2)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420v1](http://arxiv.org/abs/2412.07420v1)|null|
|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412v1](http://arxiv.org/abs/2412.07412v1)|null|
|**2024-12-10**|**My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**|Jian Liao et.al.|[2412.07367v1](http://arxiv.org/abs/2412.07367v1)|null|
|**2024-12-09**|**ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**|Jieyu Zhang et.al.|[2412.07012v2](http://arxiv.org/abs/2412.07012v2)|[link](https://github.com/jieyuz2/provision)|
|**2024-12-09**|**A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**|Zhepeng Wang et.al.|[2412.06212v1](http://arxiv.org/abs/2412.06212v1)|null|
|**2024-12-08**|**Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**|Vijayalaxmi Sahadevan et.al.|[2412.05868v1](http://arxiv.org/abs/2412.05868v1)|null|
|**2024-12-08**|**A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**|Aniruddha Salve et.al.|[2412.05838v1](http://arxiv.org/abs/2412.05838v1)|null|
|**2024-12-08**|**Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**|Faqian Guan et.al.|[2412.05830v1](http://arxiv.org/abs/2412.05830v1)|null|
|**2024-12-08**|**GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**|Haotong Yang et.al.|[2412.06849v1](http://arxiv.org/abs/2412.06849v1)|null|
|**2024-12-08**|**M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**|Siyuan Guo et.al.|[2412.06847v1](http://arxiv.org/abs/2412.06847v1)|[link](https://github.com/bz99bz/m-3)|
|**2024-12-07**|**HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**|Zihao Zhu et.al.|[2412.05685v1](http://arxiv.org/abs/2412.05685v1)|null|
|**2024-12-07**|**KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**|Weijie Chen et.al.|[2412.05547v1](http://arxiv.org/abs/2412.05547v1)|null|
|**2024-12-06**|**Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**|Krishnasai Addala et.al.|[2412.05453v1](http://arxiv.org/abs/2412.05453v1)|null|
|**2024-12-06**|**A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**|Savini Kashmira et.al.|[2412.05447v1](http://arxiv.org/abs/2412.05447v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342v1](http://arxiv.org/abs/2412.04342v1)|[link](https://github.com/krystalan/RAGtrans)|
|**2024-12-05**|**GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**|Cristian-George Crăciun et.al.|[2412.04119v1](http://arxiv.org/abs/2412.04119v1)|null|
|**2024-12-05**|**MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**|Yunhe Pang et.al.|[2412.03930v1](http://arxiv.org/abs/2412.03930v1)|[link](https://github.com/thudm/whoiswho)|
|**2024-12-05**|**How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**|Patrick Ocheja et.al.|[2412.03856v1](http://arxiv.org/abs/2412.03856v1)|null|
|**2024-12-05**|**Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**|Samuel Abedu et.al.|[2412.03815v1](http://arxiv.org/abs/2412.03815v1)|null|
|**2024-12-05**|**Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**|Jialin Wang et.al.|[2412.03801v1](http://arxiv.org/abs/2412.03801v1)|null|
|**2024-12-04**|**Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**|Ximing Wen et.al.|[2412.03761v1](http://arxiv.org/abs/2412.03761v1)|null|
|**2024-12-04**|**How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**|Wenyi Wang et.al.|[2412.03624v1](http://arxiv.org/abs/2412.03624v1)|[link](https://github.com/hishamalyahya/semantic_backprop)|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**|Ammar Shaikh et.al.|[2412.03605v1](http://arxiv.org/abs/2412.03605v1)|null|
|**2024-12-03**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788v2](http://arxiv.org/abs/2412.02788v2)|[link](https://github.com/semantic-systems/hybrid-squad)|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-02**|**A Neurosymbolic Fast and Slow Architecture for Graph Coloring**|Vedant Khandelwal et.al.|[2412.01752v1](http://arxiv.org/abs/2412.01752v1)|null|
|**2024-12-02**|**Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**|Jialin Wang et.al.|[2412.01490v4](http://arxiv.org/abs/2412.01490v4)|null|
|**2024-12-01**|**SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**|Aihua Pei et.al.|[2412.00765v1](http://arxiv.org/abs/2412.00765v1)|null|
|**2024-11-30**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608v3](http://arxiv.org/abs/2412.00608v3)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|Théo Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**|Xinyu Lin et.al.|[2412.00478v1](http://arxiv.org/abs/2412.00478v1)|[link](https://github.com/xinyulin-fz/lenie)|
|**2024-11-29**|**An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**|Saurabh Mishra et.al.|[2412.00224v1](http://arxiv.org/abs/2412.00224v1)|null|
|**2024-11-29**|**PerLA: Perceptive 3D Language Assistant**|Guofeng Mei et.al.|[2411.19774v1](http://arxiv.org/abs/2411.19774v1)|null|
|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539v1](http://arxiv.org/abs/2411.19539v1)|null|
|**2024-11-28**|**Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**|Yutong Zhang et.al.|[2411.19064v1](http://arxiv.org/abs/2411.19064v1)|null|
|**2024-11-28**|**EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**|Meher Bhardwaj et.al.|[2411.18923v1](http://arxiv.org/abs/2411.18923v1)|null|
|**2024-11-27**|**MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**|Angus Fung et.al.|[2412.00103v1](http://arxiv.org/abs/2412.00103v1)|null|
|**2024-11-27**|**Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**|Valentina Anita Carriero et.al.|[2412.03589v1](http://arxiv.org/abs/2412.03589v1)|null|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v2](http://arxiv.org/abs/2411.16495v2)|[link](https://github.com/THU-KEG/AtomR)|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|
|**2024-11-22**|**One to rule them all: natural language to bind communication, perception and action**|Simone Colombani et.al.|[2411.15033v1](http://arxiv.org/abs/2411.15033v1)|null|
|**2024-11-22**|**Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**|Simone Colombani et.al.|[2411.15027v1](http://arxiv.org/abs/2411.15027v1)|null|
|**2024-11-22**|**GOT4Rec: Graph of Thoughts for Sequential Recommendation**|Zewen Long et.al.|[2411.14922v1](http://arxiv.org/abs/2411.14922v1)|null|
|**2024-11-22**|**VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**|Camilo Chacón Sartori et.al.|[2411.14832v1](http://arxiv.org/abs/2411.14832v1)|null|
|**2024-11-22**|**MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**|Jiatong Li et.al.|[2411.14721v1](http://arxiv.org/abs/2411.14721v1)|null|
|**2024-11-21**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592v2](http://arxiv.org/abs/2411.14592v2)|[link](https://github.com/RadeenXALNW/G-RAG_1.0)|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v2](http://arxiv.org/abs/2411.12950v2)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**|Hubert Plisiecki et.al.|[2411.12493v2](http://arxiv.org/abs/2411.12493v2)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**|Yuze Liu et.al.|[2411.14479v1](http://arxiv.org/abs/2411.14479v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**LLaSA: Large Language and Structured Data Assistant**|Yao Xu et.al.|[2411.14460v1](http://arxiv.org/abs/2411.14460v1)|null|
|**2024-11-16**|**Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**|Zhangchi Qiu et.al.|[2411.14459v1](http://arxiv.org/abs/2411.14459v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Qing Cheng et.al.|[2411.10371v2](http://arxiv.org/abs/2411.10371v2)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|

#### Abstracts
##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

摘要：圖形是普遍存在於許多真實世界應用中的資料結構，例如藥物發現、推薦系統和社交網路分析。圖形神經網路 (GNN) 已成為一種流行的工具，可透過在這些結構上傳遞訊息來學習節點嵌入。然而，當將 GNN 應用於具有不同特徵空間的多個圖形時，會出現一個重大的挑戰，因為現有的 GNN 架構並非設計用於跨圖形特徵對齊。為了解決這個問題，最近的方法引入了文字屬性圖形，其中每個節點都與文字描述相關聯，從而可以使用共用文字編碼器將來自不同圖形的節點投影到統一的特徵空間中。儘管有希望，但此方法在很大程度上依賴於文字屬性資料的可用性，這在實務上可能難以取得。為了彌補這個差距，我們提出了一種名為拓撲感知節點描述合成 (TANS) 的新方法，該方法利用大型語言模型 (LLM) 將現有圖形自動轉換為文字屬性圖形。其關鍵思想是將拓撲資訊與每個節點的屬性整合在一起，增強 LLM 解釋圖形拓撲如何影響節點語義的能力。我們在文字豐富、文字受限和無文字圖形上評估我們的 TANS，證明它能讓單一 GNN 在不同的圖形中運作。值得注意的是，在無文字圖形上，我們的模型顯著優於手動設計節點特徵的現有方法，展示了 LLM 在預處理圖形結構資料方面的潛力，即使在沒有文字資訊的情況下也是如此。程式碼和資料可在 https://github.com/Zehong-Wang/TANS 取得。

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

摘要：先前的研究發現，最近的長語境語言模型無法平均利用其輸入中段的資訊，偏好位於尾端的資訊片段，這會造成不當的偏差，在我們希望模型能平均使用輸入不同部分的情況下。到目前為止，這個問題主要只在具有單一關鍵資訊片段的設定中被考慮，導致我們質疑當多個必要的資訊片段散佈在輸入中時會發生什麼情況。在此，我們示範了「遺失在中間」問題在多跳問答設定中的影響，其中需要跨越未連接文件的多次推理「跳躍」，並顯示效能不僅會隨著資訊與語境邊緣的距離而下降，也會隨著資訊片段之間的距離而下降。此外，我們實驗了透過知識圖譜三元組萃取和摘要來減少多餘文件內容，並提示模型使用思考鏈提示來更徹底地推理，以減輕問題的方法。

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

摘要：近年来，基于神经网络和预训练模型的文本分类方法越来越受到关注，并表现出优异的性能。然而，这些方法在实际应用中仍然存在一些局限性：(1) 它们通常只关注句子之间的匹配相似性。然而，同类句子内部和不同类句子之间都存在隐含的高价值信息，这对分类任务至关重要。(2) 预训练语言模型和基于图的方法等现有方法通常需要大量的内存用于训练和文本图构建。(3) 虽然一些低资源方法可以达到良好的性能，但它们通常处理时间过长。为了应对这些挑战，我们提出了一种低资源且快速的文本分类模型，称为 LFTC。我们的方法首先为每个类别构建一个压缩器列表，以充分挖掘类内数据中的规律性信息。然后，我们删除与目标分类无关的冗余信息，以减少处理时间。最后，我们计算文本对之间的相似性距离进行分类。我们在 9 个公开的基准数据集上评估了 LFTC，结果表明在有限的计算和数据资源下，其性能和处理时间都有显著提升，突出了其优越的优势。

##### **Uncommon Belief in Rationality**
2412.09407v1 by Qi Shi, Pavel Naumov

Common knowledge/belief in rationality is the traditional standard assumption
in analysing interaction among agents. This paper proposes a graph-based
language for capturing significantly more complicated structures of
higher-order beliefs that agents might have about the rationality of the other
agents. The two main contributions are a solution concept that captures the
reasoning process based on a given belief structure and an efficient algorithm
for compressing any belief structure into a unique minimal form.

摘要：在分析代理之間的互動時，理性中的常識/信念是傳統的標準假設。本文提出了一種基於圖形的語言，用於捕捉代理人可能對其他代理人的理性具有顯著更複雜的高階信念結構。兩項主要貢獻是捕捉基於給定信念結構的推理過程的解決方案概念，以及將任何信念結構壓縮成唯一最小形式的有效演算法。

##### **Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**
2412.09230v1 by Sai Bhargav Rongali, Mohamad Hassan N C, Ankit Jha, Neha Bhargava, Saurabh Prasad, Biplab Banerjee

This paper tackles the intricate challenge of video question-answering
(VideoQA). Despite notable progress, current methods fall short of effectively
integrating questions with video frames and semantic object-level abstractions
to create question-aware video representations. We introduce Local-Global
Question Aware Video Embedding (LGQAVE), which incorporates three major
innovations to integrate multi-modal knowledge better and emphasize semantic
visual concepts relevant to specific questions. LGQAVE moves beyond traditional
ad-hoc frame sampling by utilizing a cross-attention mechanism that precisely
identifies the most relevant frames concerning the questions. It captures the
dynamics of objects within these frames using distinct graphs, grounding them
in question semantics with the miniGPT model. These graphs are processed by a
question-aware dynamic graph transformer (Q-DGT), which refines the outputs to
develop nuanced global and local video representations. An additional
cross-attention module integrates these local and global embeddings to generate
the final video embeddings, which a language model uses to generate answers.
Extensive evaluations across multiple benchmarks demonstrate that LGQAVE
significantly outperforms existing models in delivering accurate multi-choice
and open-ended answers.

摘要：本文探討了影片問答 (VideoQA) 的複雜挑戰。儘管取得顯著進展，但目前的技術仍無法有效結合問題、影片畫面和語義物件層級抽象，以建立問題感知的影片表徵。我們引進了局部-全域問題感知影片嵌入 (LGQAVE)，它包含三項重大創新，以更好地整合多模式知識，並強調與特定問題相關的語義視覺概念。LGQAVE 超越了傳統的臨時畫面取樣，利用跨注意力機制精確找出與問題最相關的畫面。它使用不同的圖形捕捉這些畫面中物件的動態，並透過 miniGPT 模型將它們奠基於問題語義中。這些圖形由問題感知動態圖形轉換器 (Q-DGT) 處理，它會改善輸出，以開發細緻的全局和局部影片表徵。額外的跨注意力模組整合這些局部和全局嵌入，以產生最終的影片嵌入，語言模型使用這些嵌入來產生答案。跨多個基準的廣泛評估證明，LGQAVE 在提供準確的多選和開放式答案方面，明顯優於現有模型。

##### **Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**
2412.09094v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng

Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a \textit{filter-then-generate} paradigm and formulate the KGC task
into a multiple-choice question format. In this way, we can harness the
capability of LLMs while mitigating the issue casused by hallucinations.
Moreover, we devise a flexible ego-graph serialization prompt and employ a
structure-text adapter to couple structure and text information in a
contextualized manner. Experimental results demonstrate that FtG achieves
substantial performance gain compared to existing state-of-the-art methods. The
instruction dataset and code are available at
\url{https://github.com/LB0828/FtG}.

摘要：大型語言模型 (LLM) 具有龐大的內部知識和卓越的語義理解能力，這徹底改變了自然語言處理中的各種任務。儘管它們成功，但在使 LLM 能執行知識圖譜完成 (KGC) 方面仍存在一個關鍵差距。經驗證據表明，即使透過精密的提示設計或量身打造的指令調整，LLM 的表現也始終不如傳統的 KGC 方法。從根本上來說，在 KGC 上應用 LLM 會帶來幾個關鍵挑戰，包括大量的實體候選、LLM 的幻覺問題以及圖形結構的利用不足。為了應對這些挑戰，我們提出了一種新的基於指令調整的方法，即 FtG。具體來說，我們提出了「先過濾再生成」的範例，並將 KGC 任務制定為多選題格式。這樣，我們就能利用 LLM 的能力，同時減輕幻覺所造成的問題。此外，我們設計了一個靈活的自圖序列化提示，並採用結構文本適配器，以情境化的方式結合結構和文本資訊。實驗結果表明，與現有的最先進方法相比，FtG 獲得了顯著的效能提升。指令資料集和程式碼可在
\url{https://github.com/LB0828/FtG} 取得。

##### **Neural Interactive Proofs**
2412.08897v1 by Lewis Hammond, Sam Adam-Day

We consider the problem of how a trusted, but computationally bounded agent
(a 'verifier') can learn to interact with one or more powerful but untrusted
agents ('provers') in order to solve a given task. More specifically, we study
the case in which agents are represented using neural networks and refer to
solutions of this problem as neural interactive proofs. First we introduce a
unifying framework based on prover-verifier games, which generalises previously
proposed interaction protocols. We then describe several new protocols for
generating neural interactive proofs, and provide a theoretical comparison of
both new and existing approaches. Finally, we support this theory with
experiments in two domains: a toy graph isomorphism problem that illustrates
the key ideas, and a code validation task using large language models. In so
doing, we aim to create a foundation for future work on neural interactive
proofs and their application in building safer AI systems.

摘要：<paragraph>我們考慮一個問題，說明一個受信任但計算受限的代理（「驗證者」）如何學會與一個或多個強大但不可信的代理（「證明者」）互動，以解決給定的任務。更具體地說，我們研究代理使用神經網路表示的情況，並將此問題的解決方案稱為神經互動證明。首先，我們引入一個基於證明者驗證者遊戲的統一框架，它概括了先前提出的互動協議。然後，我們描述了幾個生成神經互動證明的新協議，並對新舊方法進行了理論比較。最後，我們在兩個領域中用實驗支持了這個理論：一個玩具圖同構問題，說明了關鍵思想，以及使用大型語言模型的代碼驗證任務。這樣做，我們旨在為神經互動證明及其在構建更安全的 AI 系統中的應用奠定基礎。</paragraph>

##### **A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**
2412.08864v1 by Jiankang Wang, Jianjun Xu, Xiaorui Wang, Yuxin Wang, Mengting Xing, Shancheng Fang, Zhineng Chen, Hongtao Xie, Yongdong Zhang

Synthesizing high-quality reasoning data for continual training has been
proven to be effective in enhancing the performance of Large Language Models
(LLMs). However, previous synthetic approaches struggle to easily scale up data
and incur high costs in the pursuit of high quality. In this paper, we propose
the Graph-based Synthetic Data Pipeline (GSDP), an economical and scalable
framework for high-quality reasoning data synthesis. Inspired by knowledge
graphs, we extracted knowledge points from seed data and constructed a
knowledge point relationships graph to explore their interconnections. By
exploring the implicit relationships among knowledge, our method achieves
$\times$255 data expansion. Furthermore, GSDP led by open-source models,
achieves synthesis quality comparable to GPT-4-0613 while maintaining
$\times$100 lower costs. To tackle the most challenging mathematical reasoning
task, we present the GSDP-MATH dataset comprising over 1.91 million pairs of
math problems and answers. After fine-tuning on GSDP-MATH, GSDP-7B based on
Mistral-7B achieves 37.7% accuracy on MATH and 78.4% on GSM8K, demonstrating
the effectiveness of our method. The dataset and models trained in this paper
will be available.

摘要：<paragraph>合成高品質推理資料以進行持續訓練已被證實能有效提升大型語言模型 (LLM) 的效能。然而，先前的合成方法難以輕易擴充資料，且在追求高品質的過程中會產生高成本。在本文中，我們提出基於圖表的合成資料管線 (GSDP)，一個經濟且可擴充的高品質推理資料合成架構。受知識圖表啟發，我們從種子資料中萃取知識點，並建構一個知識點關係圖表以探索它們的相互關聯性。透過探索知識中的隱含關係，我們的做法達到了 $\times$255 資料擴充。此外，由開源模型領導的 GSDP，達到了與 GPT-4-0613 相當的合成品質，同時將成本降低了 $\times$100。為了應對最具挑戰性的數學推理任務，我們提出了 GSDP-MATH 資料集，其中包含超過 191 萬對數學問題和答案。在 GSDP-MATH 上進行微調後，基於 Mistral-7B 的 GSDP-7B 在 MATH 上達到了 37.7% 的準確度，在 GSM8K 上達到了 78.4%，證明了我們方法的有效性。本文中訓練的資料集和模型將會公開。</paragraph>

##### **In-Context Learning with Topological Information for Knowledge Graph Completion**
2412.08742v1 by Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, Sumitra Ganesh

Knowledge graphs (KGs) are crucial for representing and reasoning over
structured information, supporting a wide range of applications such as
information retrieval, question answering, and decision-making. However, their
effectiveness is often hindered by incompleteness, limiting their potential for
real-world impact. While knowledge graph completion (KGC) has been extensively
studied in the literature, recent advances in generative AI models,
particularly large language models (LLMs), have introduced new opportunities
for innovation. In-context learning has recently emerged as a promising
approach for leveraging pretrained knowledge of LLMs across a range of natural
language processing tasks and has been widely adopted in both academia and
industry. However, how to utilize in-context learning for effective KGC remains
relatively underexplored. We develop a novel method that incorporates
topological information through in-context learning to enhance KGC performance.
By integrating ontological knowledge and graph structure into the context of
LLMs, our approach achieves strong performance in the transductive setting
i.e., nodes in the test graph dataset are present in the training graph
dataset. Furthermore, we apply our approach to KGC in the more challenging
inductive setting, i.e., nodes in the training graph dataset and test graph
dataset are disjoint, leveraging the ontology to infer useful information about
missing nodes which serve as contextual cues for the LLM during inference. Our
method demonstrates superior performance compared to baselines on the
ILPC-small and ILPC-large datasets.

摘要：知識圖譜 (KG) 對於表示和推理結構化資訊至關重要，支援廣泛的應用程式，例如資訊檢索、問題解答和決策制定。然而，它們的效能經常受到不完整性的阻礙，限制了它們對現實世界影響的潛力。雖然知識圖譜完成 (KGC) 已在文獻中廣泛研究，但生成式 AI 模型的最新進展，特別是大型語言模型 (LLM)，為創新帶來了新的機會。情境學習最近已成為一種有前途的方法，用於跨越一系列自然語言處理任務利用 LLM 的預訓練知識，並已廣泛應用於學術界和產業。然而，如何利用情境學習進行有效的 KGC 仍然相對未被探討。我們開發了一種新方法，透過情境學習納入拓撲資訊來增強 KGC 效能。透過將本體知識和圖形結構整合到 LLM 的情境中，我們的做法在轉導式設定中取得強勁的效能，即測試圖形資料集中的節點存在於訓練圖形資料集中。此外，我們將我們的做法應用於更具挑戰性的歸納式設定中的 KGC，即訓練圖形資料集和測試圖形資料集中的節點是不相交的，利用本體來推斷有關遺失節點的有用資訊，這些節點在推理過程中作為 LLM 的情境提示。與 ILPC-small 和 ILPC-large 資料集上的基準相比，我們的做法展現出優異的效能。

##### **VEL: A Formally Verified Reasoner for OWL2 EL Profile**
2412.08739v1 by Atalay Mert Ileri, Nalen Rangarajan, Jack Cannell, Hande McGinty

Over the past two decades, the Web Ontology Language (OWL) has been
instrumental in advancing the development of ontologies and knowledge graphs,
providing a structured framework that enhances the semantic integration of
data. However, the reliability of deductive reasoning within these systems
remains challenging, as evidenced by inconsistencies among popular reasoners in
recent competitions. This evidence underscores the limitations of current
testing-based methodologies, particularly in high-stakes domains such as
healthcare. To mitigate these issues, in this paper, we have developed VEL, a
formally verified EL++ reasoner equipped with machine-checkable correctness
proofs that ensure the validity of outputs across all possible inputs. This
formalization, based on the algorithm of Baader et al., has been transformed
into executable OCaml code using the Coq proof assistant's extraction
capabilities. Our formalization revealed several errors in the original
completeness proofs, which led to changes to the algorithm to ensure its
completeness. Our work demonstrates the necessity of mechanization of reasoning
algorithms to ensure their correctness at theoretical and implementation
levels.

摘要：在過去二十年，Web Ontology Language (OWL) 已在推動本体和知識圖譜的發展中發揮關鍵作用，提供一個增強資料語意整合的結構化架構。然而，這些系統中演繹推理的可靠性仍然具有挑戰性，正如最近比賽中流行的推理機之間的不一致性所證明的那樣。這個證據突顯了當前基於測試的方法的局限性，特別是在醫療保健等高風險領域。為了減輕這些問題，我們在本文中開發了 VEL，一個正式驗證的 EL++ 推理機，配備了機器可檢查的正確性證明，以確保在所有可能的輸入中輸出的有效性。這個形式化，基於 Baader 等人的演算法，已使用 Coq 證明助手的提取功能轉換為可執行的 OCaml 程式碼。我們的形式化揭示了原始完整性證明中的幾個錯誤，這導致了演算法的改變以確保其完整性。我們的作品證明了推理演算法機械化的必要性，以確保它們在理論和實作層面的正確性。

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas Dugué, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

摘要：<paragraph>透過模擬人類社交互動或語言中詞彙共現等複雜系統中的資訊，有助於了解這些系統的組織和運作方式。這些系統可以用網路來建模，而網路理論提供了有用的方法集來分析它們。在這些方法中，圖形嵌入是一種強大的工具，可用於在向量化特徵空間中總結網路的交互和拓撲。當用於機器學習演算法的輸入時，嵌入向量有助於常見的圖形問題，例如連結預測、圖形配對等。詞嵌入的目標是表示詞彙的意義，從大型文字語料庫中萃取它。儘管嵌入演算法輸入資訊的結構不同，但許多圖形嵌入方法都是根據自然語言處理中的方法改編和啟發的。在兩個領域中都觀察到這些方法的限制。大多數這些方法需要漫長且耗費資源的訓練。大多數方法的另一個缺點是它們是黑盒子，從中理解資訊如何被結構化相當複雜。模型的可解釋性允許在不需要外部資訊的情況下了解向量空間是如何被結構化的，因此可以更容易地進行稽核。牢記這兩個限制，我們提出了一個新穎的框架，以有效的方式將網路頂點嵌入可解釋的向量空間中。我們的低維二部圖框架 (LDBGF) 利用網路的二部圖投影使用派系來降低維度。除了 LDBGF 之外，我們還介紹了兩個依賴社群而非派系的此框架實作：SINr-NR 和 SINr-MF。我們展示了 SINr-MF 在經典圖形上可以執行良好，而 SINr-NR 可以產生高品質的圖形和詞嵌入，這些嵌入在各次執行中都是可解釋且穩定的。</paragraph>

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v1 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

摘要：<paragraph>儘管利用網際網路規模的圖像文字配對，在建立具有對比語言影像預訓練 (CLIP) 的視覺模型方面已取得巨大的成功，但由於三個基本問題，使用 CLIP 管線建立可轉移的圖神經網路 (GNN) 具有挑戰性：標記資料和文字監督的稀缺性、不同層級的下游任務，以及領域之間的概念差距。為了解決這些問題，我們在這個工作中利用多模式提示學習，在僅給予少數語義標記範例（每個範例都具有極弱的文字監督）的情況下，有效地調整預訓練的 GNN 以適應下游任務和資料。我們的範例透過同時學習圖提示和文字提示，將圖形直接嵌入與大型語言模型 (LLM) 相同的空間中。為了達成這個目標，我們改進了最先進的圖提示方法，然後提出第一個圖語言多模式提示學習方法，以利用預訓練模型中的知識。值得注意的是，由於微調的監督不足，在我們的範例中，預訓練的 GNN 和 LLM 保持凍結，因此可學習的參數遠少於微調任何預訓練模型。透過在真實世界資料集上進行廣泛的實驗，我們展示了我們的範例在少量、多任務層級和跨領域設定中的優異效能。此外，我們建立了第一個 CLIP 風格的零次分類原型，它可以將 GNN 推廣到具有極弱文字監督的未見類別。</paragraph>

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

摘要：<paragraph>軟體供應商通常會在沒有提供足夠的諮詢（例如常見漏洞和曝險）或延遲透過資源（例如國家漏洞資料庫）更新的情況下，無聲地發布安全性修補程式。因此，偵測這些安全性修補程式以確保軟體維護安全至關重要。然而，現有方法面臨以下挑戰：(1) 它們主要關注修補程式本身的資訊，忽略了儲存庫中複雜的相依性。(2) 安全性修補程式通常涉及多個函式和檔案，增加了良好學習表示形式的難度。為了緩解上述挑戰，本文提出了一個名為 RepoSPD 的儲存庫層級安全性修補程式偵測架構，它包含三個關鍵元件：1) 儲存庫層級圖形建構，RepoCPG，它透過合併儲存庫層級的前修補程式和後修補程式原始碼來表示軟體修補程式；2) 結構感知修補程式表示形式，它融合了圖形和序列分支，旨在理解多個程式碼變更之間的關係；3) 漸進式學習，它有助於模型平衡語意和結構資訊。為了評估 RepoSPD，我們在安全性修補程式偵測中採用了兩個廣泛使用的資料集：SPI-DB 和 PatchDB。我們進一步將這些資料集擴充套件到儲存庫層級，分別納入了 C/C++ 程式語言中總計 20,238 和 28,781 個版本的儲存庫，表示為 SPI-DB* 和 PatchDB*。我們將 RepoSPD 與六種現有的安全性修補程式偵測方法和五種靜態工具進行比較。我們的實驗結果表明，RepoSPD 優於最先進的基準，在兩個資料集上的準確性分別提高了 11.90% 和 3.10%。</paragraph>

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v2 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

摘要：圖表表徵學習方法在處理複雜非歐幾里得資料時非常有效，它能捕捉圖表結構中的複雜關係和特徵。然而，傳統方法在處理異質圖表時會面臨挑戰，因為異質圖表包含各種節點和邊緣類型，這是由於資料來源多樣且性質複雜。現有的異質圖神經網路 (HGNN) 已展現出有前景的成果，但需要事先知道節點和邊緣類型，以及統一的節點特徵格式，這限制了它們的適用性。最近在使用大型語言模型 (LLM) 進行圖表表徵學習方面取得的進展提供了新的解決方案，方法是整合 LLM 的資料處理功能，讓各種圖表表徵得以對齊。儘管如此，這些方法經常忽略異質圖表資料，而且需要廣泛的預處理。為了解決這些限制，我們提出了一種新方法，它同時利用了 LLM 和 GNN 的優點，允許處理任何格式和類型節點和邊緣的圖表資料，而不需要類型資訊或特殊預處理。我們的這個方法採用 LLM 自動摘要和分類不同的資料格式和類型，對齊節點特徵，並使用專門的 GNN 進行目標學習，從而為下游任務取得有效的圖表表徵。理論分析和實驗驗證已證明我們這個方法的有效性。

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

摘要：人類健康越來越受到接觸有害物質的威脅，尤其是持久性和有毒的化學物質。科學研究已證明這些物質（通常存在於複雜的混合物中）與各種疾病之間的關聯。然而，這些資訊分散在多個來源中，人類和機器都很難取得。本文評估了當前發布/取得有關有害化學物質資訊的慣例，並提出一個新穎的平台，旨在促進在緊急情況下取得關鍵化學資料。此平台匯集來自多個來源的資訊，並將其組織成結構化的知識圖譜。使用者可以透過視覺化介面（例如 Neo4J Bloom 和儀表板）或使用聊天機器人的自然語言查詢來取得這些資訊。我們的研究結果表明，當資料集遵循 FAIR 原則時，取得重要化學資訊所需的時間和精力會大幅減少。此外，我們討論從此平台的開發和實作中學到的經驗教訓，並為資料擁有者和發布者提供建議，以增強資料再利用和互操作性。這項工作旨在改善醫療保健專業人員取得和使用化學資訊的方式，從而支持更好的健康結果，並在面對接觸化學中毒風險的患者時做出明智的決策。

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多 NLP 任務上表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，
利用檢索增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，
能穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：
非平穩環境的持續演變可能導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。
為了應對這些挑戰，我們引入了多目標多臂老虎機增強的 RAG 框架，
並在實務中採用具備多元能力的各種檢索方法，以應對豐富且不斷演變的檢索情境。
在此框架中，每個檢索方法都被視為一個不同的「手臂」。
該系統利用即時使用者回饋來適應動態環境，
根據輸入查詢和每個手臂的歷史多目標效能來選擇適當的檢索方法。
在兩個基準 KGQA 資料集上進行的廣泛實驗表明，
我們的模型在非平穩設定中顯著優於基線模型，同時在平穩環境中達到最先進的效能。
程式碼和資料可於 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **RAG-based Question Answering over Heterogeneous Data and Text**
2412.07420v1 by Philipp Christmann, Gerhard Weikum

This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.

摘要：本文介紹 QUASAR 系統，用於回答非結構化文字、結構化表格和知識圖表中的問題，並統一處理所有來源。該系統採用基於 RAG 的架構，管道包括證據檢索後接答案生成，後者由中等規模的語言模型提供支援。此外，QUASAR 獨特地包含問題理解元件，以衍生更清晰的輸入進行證據檢索，以及在將最有資訊的片段輸入答案生成之前重新排序和過濾檢索到的證據。使用三個不同的基準進行的實驗證明了我們方法的高回答品質，與大型 GPT 模型相當或更好，同時將運算成本和能源消耗降低了幾個數量級。

##### **Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**
2412.07412v1 by Ahan Bhatt, Nandan Vaghela, Kush Dudhia

Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.

摘要：知識圖譜 (KG) 對於 GraphRAG 的功能至關重要，GraphRAG 是一種檢索增強式生成系統 (RAG)，在需要結構化推理和語義理解的任務中表現出色。然而，由於傳統方法的準確性和可擴充性限制，為 GraphRAG 建立 KG 仍然是一項重大挑戰。本文介紹了一種創新方法，利用大型語言模型 (LLM)，例如 GPT-4、LLaMA 2 (13B) 和 BERT，直接從非結構化數據生成 KG，繞過傳統管道。我們使用準確度、召回率、F1 分數、圖形編輯距離和語義相似性等指標，評估模型生成高品質 KG 的能力。結果表明，GPT-4 達到了卓越的語義保真度和結構準確性，LLaMA 2 在輕量級、特定領域的圖形中表現出色，而 BERT 則提供了對實體關係建模挑戰的見解。這項研究強調了 LLM 簡化 KG 建立和增強 GraphRAG 在現實世界應用中可及性的潛力，同時為未來的進展奠定了基礎。

##### **My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**
2412.07367v1 by Jian Liao, Yu Feng, Xiaoyu Wang, Suge Wang, Jianxing Zheng, Deyu Li

In implicit emotion analysis (IEA), the subtlety of emotional expressions
makes it particularly sensitive to user-specific characteristics. Existing
studies often inject personalization into the analysis by focusing on the
authorial dimension of the emotional text. However, these methods overlook the
potential influence of the intended reader on the reaction of implicit
emotions. In this paper, we refine the IEA task to Personalized Implicit
Emotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework
designed to address the issue of missing user information within this task. In
particular, 1) we create reader agents based on the Large Language Model to
simulate reader reactions, to address challenges of the spiral of silence and
data incompleteness encountered when acquiring reader feedback information. 2)
We establish a reader propagation role system and develop a role-aware emotion
propagation multi-view graph learning model, which effectively deals with the
sparsity of reader information by utilizing the distribution of propagation
roles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,
thereby addressing the limitation of prior datasets that primarily focus on
textual content annotation. Extensive experiments on these datasets indicate
that the RAPPIE model outperforms current state-of-the-art baselines,
highlighting the significance and efficacy of incorporating reader feedback
into the PIEA process.

摘要：在隐式情感分析 (IEA) 中，情感表达的微妙性使其对特定于用户的特征特别敏感。现有的研究通常通过关注情感文本的作者维度来将个性化注入到分析中。然而，这些方法忽略了预期读者对隐式情感反应的潜在影响。在本文中，我们将 IEA 任务细化为个性化隐式情感分析 (PIEA)，并引入 RAPPIE 模型，这是一个新颖的框架，旨在解决此任务中缺少用户信息的问题。特别是，1) 我们基于大型语言模型创建读者代理来模拟读者反应，以解决在获取读者反馈信息时遇到的沉默螺旋和数据不完整性的挑战。2) 我们建立了一个读者传播角色系统，并开发了一个角色感知情绪传播多视图图学习模型，该模型通过利用传播角色的分布有效地处理读者信息的稀疏性。3) 我们使用详细的用户元数据注释了两个中文 PIEA 数据集，从而解决了先前主要专注于文本内容注释的数据集的局限性。在这些数据集上进行的广泛实验表明，RAPPIE 模型优于当前最先进的基线，突出了将读者反馈纳入 PIEA 过程的重要性及有效性。

##### **ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**
2412.07012v2 by Jieyu Zhang, Le Xue, Linxin Song, Jun Wang, Weikai Huang, Manli Shu, An Yan, Zixian Ma, Juan Carlos Niebles, silvio savarese, Caiming Xiong, Zeyuan Chen, Ranjay Krishna, Ran Xu

With the rise of multimodal applications, instruction data has become
critical for training multimodal language models capable of understanding
complex image-based queries. Existing practices rely on powerful but costly
large language models (LLMs) or multimodal language models (MLMs) to produce
instruction data. These are often prone to hallucinations, licensing issues and
the generation process is often hard to scale and interpret. In this work, we
present a programmatic approach that employs scene graphs as symbolic
representations of images and human-written programs to systematically
synthesize vision-centric instruction data. Our approach ensures the
interpretability and controllability of the data generation process and scales
efficiently while maintaining factual accuracy. By implementing a suite of 24
single-image, 14 multi-image instruction generators, and a scene graph
generation pipeline, we build a scalable, cost-effective system: ProVision
which produces diverse question-answer pairs concerning objects, attributes,
relations, depth, etc., for any given image. Applied to Visual Genome and
DataComp datasets, we generate over 10 million instruction data points,
ProVision-10M, and leverage them in both pretraining and instruction tuning
stages of MLMs. When adopted in the instruction tuning stage, our single-image
instruction data yields up to a 7% improvement on the 2D split and 8% on the 3D
split of CVBench, along with a 3% increase in performance on QBench2,
RealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%
improvement on Mantis-Eval. Incorporation of our data in both pre-training and
fine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%
across 11 benchmarks.

摘要：<paragraph>隨著多模態應用程式興起，指令資料已成為訓練多模態語言模型的關鍵，該模型能夠理解基於複雜影像的查詢。現有做法依賴於強大但昂貴的大型語言模型 (LLM) 或多模態語言模型 (MLM) 來產生指令資料。這些方法經常容易出現幻覺、授權問題，且生成過程通常難以擴充和詮釋。在這項工作中，我們提出了一種程式化方法，使用場景圖形作為影像的符號表示，並使用人撰寫的程式系統性地合成以視覺為中心的指令資料。我們的做法確保了資料生成過程的可詮釋性和可控性，並在維持事實準確性的同時有效地擴充。透過實作一組 24 個單一影像、14 個多重影像指令產生器，以及一個場景圖形產生管線，我們建立了一個可擴充、具有成本效益的系統：ProVision，它針對任何給定的影像產生關於物件、屬性、關係、深度等的各種問答配對。應用於 Visual Genome 和 DataComp 資料集，我們產生了超過 1000 萬個指令資料點，ProVision-10M，並在 MLM 的預訓練和指令微調階段中加以利用。當在指令微調階段採用時，我們的單一影像指令資料在 CVBench 的 2D 分割中提升了 7%，在 3D 分割中提升了 8%，在 QBench2、RealWorldQA 和 MMMU 上的效能也提升了 3%。我們的多重影像指令資料在 Mantis-Eval 上提升了 8%。在 xGen-MM-4B 的預訓練和微調階段中納入我們的資料，在 11 個基準測試中平均提升了 1.6%。</paragraph>

##### **A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**
2412.06212v1 by Zhepeng Wang, Runxue Bao, Yawen Wu, Guodong Liu, Lei Yang, Liang Zhan, Feng Zheng, Weiwen Jiang, Yanfu Zhang

Graph neural networks (GNNs) are powerful machine learning models designed to
handle irregularly structured data. However, their generic design often proves
inadequate for analyzing brain connectomes in Alzheimer's Disease (AD),
highlighting the need to incorporate domain knowledge for optimal performance.
Infusing AD-related knowledge into GNNs is a complicated task. Existing methods
typically rely on collaboration between computer scientists and domain experts,
which can be both time-intensive and resource-demanding. To address these
limitations, this paper presents a novel self-guided, knowledge-infused
multimodal GNN that autonomously incorporates domain knowledge into the model
development process. Our approach conceptualizes domain knowledge as natural
language and introduces a specialized multimodal GNN capable of leveraging this
uncurated knowledge to guide the learning process of the GNN, such that it can
improve the model performance and strengthen the interpretability of the
predictions. To evaluate our framework, we curated a comprehensive dataset of
recent peer-reviewed papers on AD and integrated it with multiple real-world AD
datasets. Experimental results demonstrate the ability of our method to extract
relevant domain knowledge, provide graph-based explanations for AD diagnosis,
and improve the overall performance of the GNN. This approach provides a more
scalable and efficient alternative to inject domain knowledge for AD compared
with the manual design from the domain expert, advancing both prediction
accuracy and interpretability in AD diagnosis.

摘要：圖形神經網路 (GNN) 是一款強大的機器學習模型，專門用於處理結構不規則的資料。然而，它們的通用設計通常無法充分分析阿茲海默症 (AD) 中的腦連接體，突顯了加入領域知識以優化效能的需求。將 AD 相關知識融入 GNN 是一項複雜的任務。現有方法通常仰賴電腦科學家和領域專家之間的合作，這可能會耗費大量時間和資源。為了解決這些限制，本文提出了一種新穎的自導式、知識注入多模式 GNN，它能自主地將領域知識納入模型開發過程中。我們的做法將領域知識概念化為自然語言，並引入一個專門的多模式 GNN，它能利用這種未經整理的知識來指導 GNN 的學習過程，以便它能改善模型效能並加強預測的可解釋性。為了評估我們的架構，我們整理了一份關於 AD 的近期同行評審論文的全面資料集，並將其與多個真實世界的 AD 資料集整合。實驗結果證明了我們的方法能夠萃取相關的領域知識、提供 AD 診斷的圖形化說明，並改善 GNN 的整體效能。與領域專家的手動設計相比，這種方法提供了一個更具可擴充性和效率性的替代方案，用於注入 AD 的領域知識，進而提升 AD 診斷中的預測準確性和可解釋性。

##### **Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**
2412.05868v1 by Vijayalaxmi Sahadevan, Sushil Mario, Yash Jaiswal, Divyanshu Bajpai, Vishal Singh, Hiralal Aggarwal, Suhas Suresh, Manjunath Maigur

Ontology-based knowledge graphs (KG) are desirable for effective knowledge
management and reuse in various decision making scenarios, including design.
Creating and populating extensive KG based on specific ontological models can
be highly labour and time-intensive unless automated processes are developed
for knowledge extraction and graph creation. Most research and development on
automated extraction and creation of KG is based on extensive unstructured data
sets that provide contextual information. However, some of the most useful
information about the products and services of a company has traditionally been
recorded as structured data. Such structured data sets rarely follow a standard
ontology, do not capture explicit mapping of relationships between the
entities, and provide no contextual information. Therefore, this research
reports a method and digital workflow developed to address this gap. The
developed method and workflow employ rule-based techniques to extract and
create a Function Behaviour-Structure (FBS) ontology-based KG from legacy
structured data, especially specification sheets and product catalogues. The
solution approach consists of two main components: a process for deriving
context and context-based classification rules for FBS ontology concepts and a
workflow for populating and retrieving the FBS ontology-based KG. KG and
Natural Language Processing (NLP) are used to automate knowledge extraction,
representation, and retrieval. The workflow's effectiveness is demonstrated via
pilot implementation in an industrial context. Insights gained from the pilot
study are reported regarding the challenges and opportunities, including
discussing the FBS ontology and concepts.

摘要：<paragraph>基於本体論的知識圖譜 (KG) 對於在各種決策制定情境（包括設計）中有效管理和重用知識是理想的。建立並填入基於特定本體模型的廣泛 KG 可能非常耗費人力和時間，除非開發出用於知識萃取和圖譜建立的自動化流程。大多數關於 KG 自動化萃取和建立的研究和開發都基於提供脈絡資訊的廣泛非結構化資料集。然而，關於公司產品和服務的一些最有用的資訊傳統上都是以結構化資料記錄的。此類結構化資料集很少遵循標準本體論，不會擷取實體之間關係的明確對應，也不會提供脈絡資訊。因此，本研究報告了一種方法和數位工作流程，用於解決此差距。開發的方法和工作流程採用基於規則的技術，從傳統結構化資料（特別是規格表和產品目錄）中萃取並建立功能行為結構 (FBS) 本體論基礎的 KG。解決方案方法包含兩個主要組成部分：一個用於推導 FBS 本體論概念的脈絡和基於脈絡的分類規則的流程，以及一個用於填入和檢索 FBS 本體論基礎的 KG 的工作流程。KG 和自然語言處理 (NLP) 用於自動化知識萃取、表示和檢索。工作流程的有效性透過在工業脈絡中的試點實作得到證明。報告了從試點研究中獲得的見解，包括討論 FBS 本體論和概念在內的挑戰和機會。</paragraph>

##### **A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**
2412.05838v1 by Aniruddha Salve, Saba Attar, Mahesh Deshmukh, Sayali Shivpuje, Arnab Mitra Utsab

Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
incorporating external, domain-specific data into the generative process. While
LLMs are highly capable, they often rely on static, pre-trained datasets,
limiting their ability to integrate dynamic or private data. Traditional RAG
systems typically use a single-agent architecture to handle query generation,
data retrieval, and response synthesis. However, this approach becomes
inefficient when dealing with diverse data sources, such as relational
databases, document stores, and graph databases, often leading to performance
bottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system
to address these limitations. Specialized agents, each optimized for a specific
data source, handle query generation for relational, NoSQL, and document-based
systems. These agents collaborate within a modular framework, with query
execution delegated to an environment designed for compatibility across various
database types. This distributed approach enhances query efficiency, reduces
token overhead, and improves response accuracy by ensuring that each agent
focuses on its specialized task. The proposed system is scalable and adaptable,
making it ideal for generative AI workflows that require integration with
diverse, dynamic, or private data sources. By leveraging specialized agents and
a modular execution environment, the system provides an efficient and robust
solution for handling complex, heterogeneous data environments in generative AI
applications.

摘要：檢索增強生成 (RAG) 透過將外部領域特定資料納入生成流程，增強大型語言模型 (LLM)。雖然 LLM 具有高度能力，但它們通常依賴於靜態的預訓練資料集，限制了它們整合動態或私人資料的能力。傳統的 RAG 系統通常使用單一代理架構來處理查詢生成、資料檢索和回應合成。然而，當處理多樣化的資料來源時，這種方法會變得沒有效率，例如關係資料庫、文件儲存和圖形資料庫，通常會導致效能瓶頸和降低準確性。本文提出一個多代理 RAG 系統來解決這些限制。針對特定資料來源最佳化的專門代理，負責關係、NoSQL 和基於文件系統的查詢生成。這些代理在一個模組化架構內協作，查詢執行委派給一個環境，該環境設計為與各種資料庫類型相容。這種分散式方法增強了查詢效率，減少了標記開銷，並透過確保每個代理專注於其專門任務，來改善回應準確性。所提出的系統具有可擴充性和適應性，使其成為需要與多樣化、動態或私人資料來源整合的生成式 AI 工作流程的理想選擇。透過利用專門代理和模組化執行環境，該系統為處理生成式 AI 應用程式中複雜、異質的資料環境，提供了一個有效且穩健的解決方案。

##### **Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**
2412.05830v1 by Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, Wanlei Zhou

Graph Neural Networks (GNNs), specifically designed to process the graph
data, have achieved remarkable success in various applications. Link stealing
attacks on graph data pose a significant privacy threat, as attackers aim to
extract sensitive relationships between nodes (entities), potentially leading
to academic misconduct, fraudulent transactions, or other malicious activities.
Previous studies have primarily focused on single datasets and did not explore
cross-dataset attacks, let alone attacks that leverage the combined knowledge
of multiple attackers. However, we find that an attacker can combine the data
knowledge of multiple attackers to create a more effective attack model, which
can be referred to cross-dataset attacks. Moreover, if knowledge can be
extracted with the help of Large Language Models (LLMs), the attack capability
will be more significant. In this paper, we propose a novel link stealing
attack method that takes advantage of cross-dataset and Large Language Models
(LLMs). The LLM is applied to process datasets with different data structures
in cross-dataset attacks. Each attacker fine-tunes the LLM on their specific
dataset to generate a tailored attack model. We then introduce a novel model
merging method to integrate the parameters of these attacker-specific models
effectively. The result is a merged attack model with superior generalization
capabilities, enabling effective attacks not only on the attackers' datasets
but also on previously unseen (out-of-domain) datasets. We conducted extensive
experiments in four datasets to demonstrate the effectiveness of our method.
Additional experiments with three different GNN and LLM architectures further
illustrate the generality of our approach.

摘要：圖神經網路 (GNN) 專門用於處理圖形資料，在各種應用中都取得了顯著的成功。連結竊取攻擊對圖形資料構成重大的隱私威脅，因為攻擊者旨在提取節點（實體）之間的敏感關係，可能導致學術不當行為、欺詐交易或其他惡意活動。先前的研究主要集中於單一資料集，並且沒有探討跨資料集攻擊，更不用說利用多個攻擊者的綜合知識的攻擊。然而，我們發現攻擊者可以結合多個攻擊者的資料知識來建立更有效的攻擊模型，這可以稱為跨資料集攻擊。此外，如果可以在大型語言模型 (LLM) 的幫助下提取知識，則攻擊能力將會更顯著。在本文中，我們提出了一種新穎的連結竊取攻擊方法，該方法利用跨資料集和大型語言模型 (LLM)。LLM 用於在跨資料集攻擊中處理具有不同資料結構的資料集。每個攻擊者針對其特定資料集微調 LLM 以產生量身打造的攻擊模型。然後，我們引入一種新穎的模型合併方法，以有效整合這些特定於攻擊者的模型的參數。結果是一個合併的攻擊模型，具有優異的泛化能力，不僅可以在攻擊者的資料集上進行有效攻擊，還可以在以前未見的（域外）資料集上進行有效攻擊。我們在四個資料集中進行了廣泛的實驗，以證明我們方法的有效性。使用三種不同的 GNN 和 LLM 架構進行的額外實驗進一步說明了我們方法的普遍性。

##### **GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**
2412.06849v1 by Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang

Recent research on integrating Large Language Models (LLMs) with Graph Neural
Networks (GNNs) typically follows two approaches: LLM-centered models, which
convert graph data into tokens for LLM processing, and GNN-centered models,
which use LLMs to encode text features into node and edge representations for
GNN input. LLM-centered models often struggle to capture graph structures
effectively, while GNN-centered models compress variable-length textual data
into fixed-size vectors, limiting their ability to understand complex
semantics. Additionally, GNN-centered approaches require converting tasks into
a uniform, manually-designed format, restricting them to classification tasks
and preventing language output. To address these limitations, we introduce a
new architecture that deeply integrates GNN with LLM, featuring three key
innovations: (1) Structure-Aware Transformers, which incorporate GNN's
message-passing capabilities directly into LLM's transformer layers, allowing
simultaneous processing of textual and structural information and generating
outputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes
full, uncompressed text from graph nodes and edges, ensuring complete semantic
integration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible
autoregressive generation alongside GNN's scalable one-pass prediction.
GL-Fusion achieves outstand performance on various tasks. Notably, it achieves
state-of-the-art performance on OGBN-Arxiv and OGBG-Code2.

摘要：<paragraph>將大型語言模型 (LLM) 與圖神經網路 (GNN) 整合的最新研究通常遵循兩種方法：以 LLM 為中心的模型，將圖形資料轉換為 LLM 處理的符號，以及以 GNN 為中心的模型，使用 LLM 將文字特徵編碼成節點和邊緣表示，作為 GNN 輸入。以 LLM 為中心的模型通常難以有效擷取圖形結構，而以 GNN 為中心的模型會將變長文字資料壓縮成固定大小的向量，限制它們理解複雜語意的能力。此外，以 GNN 為中心的模型需要將任務轉換成統一的手動設計格式，限制它們只能進行分類任務，且無法產生語言輸出。為了解決這些限制，我們引入一種新的架構，將 GNN 與 LLM 深度整合，具備三大關鍵創新：(1) 結構感知Transformer，將 GNN 的訊息傳遞功能直接整合到 LLM 的Transformer層中，允許同時處理文字和結構資訊，並從 GNN 和 LLM 產生輸出；(2) 圖形文字交叉注意力，處理來自圖形節點和邊緣的完整未壓縮文字，確保完整的語義整合；(3) GNN-LLM 雙重預測器，啟用 LLM 的彈性自迴歸產生，以及 GNN 的可擴充單次預測。GL-Fusion 在各種任務中達成傑出的效能。值得注意的是，它在 OGBN-Arxiv 和 OGBG-Code2 上達到了最先進的效能。</paragraph>

##### **M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**
2412.06847v1 by Siyuan Guo, Lexuan Wang, Chang Jin, Jinxian Wang, Han Peng, Huayang Shi, Wengen Li, Jihong Guan, Shuigeng Zhou

This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecular
dataset that contains over 20 million molecules. Designed to support AI-driven
drug design and discovery, M$^{3}$-20M is 71 times more in the number of
molecules than the largest existing dataset, providing an unprecedented scale
that can highly benefit training or fine-tuning large (language) models with
superior performance for drug design and discovery. This dataset integrates
one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional
molecular structures, physicochemical properties, and textual descriptions
collected through web crawling and generated by using GPT-3.5, offering a
comprehensive view of each molecule. To demonstrate the power of M$^{3}$-20M in
drug design and discovery, we conduct extensive experiments on two key tasks:
molecule generation and molecular property prediction, using large language
models including GLM4, GPT-3.5, and GPT-4. Our experimental results show that
M$^{3}$-20M can significantly boost model performance in both tasks.
Specifically, it enables the models to generate more diverse and valid
molecular structures and achieve higher property prediction accuracy than the
existing single-modal datasets, which validates the value and potential of
M$^{3}$-20M in supporting AI-driven drug design and discovery. The dataset is
available at \url{https://github.com/bz99bz/M-3}.

摘要：這篇論文介紹了 M$^{3}$-20M，一個包含超過 2000 萬個分子的大型多模態分子資料集。M$^{3}$-20M 旨在支援 AI 驅動的藥物設計和發現，其分子數量是現有最大資料集的 71 倍，提供了前所未有的規模，可以極大地受益於訓練或微調大型（語言）模型，以在藥物設計和發現方面獲得卓越的效能。此資料集整合了透過網路爬取收集和使用 GPT-3.5 生成的單維 SMILES、二維分子圖、三維分子結構、物理化學性質和文字描述，提供了每個分子的全面檢視。為了展示 M$^{3}$-20M 在藥物設計和發現中的強大功能，我們對兩個關鍵任務進行了廣泛的實驗：分子生成和分子性質預測，使用包括 GLM4、GPT-3.5 和 GPT-4 在內的大型語言模型。我們的實驗結果表明，M$^{3}$-20M 可以顯著提升模型在兩個任務中的效能。具體來說，它使模型能夠產生更多樣化和有效的分子結構，並比現有的單模態資料集獲得更高的性質預測準確度，這驗證了 M$^{3}$-20M 在支援 AI 驅動的藥物設計和發現中的價值和潛力。資料集可在 \url{https://github.com/bz99bz/M-3} 取得。

##### **HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**
2412.05685v1 by Zihao Zhu, Hongbao Zhang, Guanzong Wu, Siwei Lyu, Baoyuan Wu

Visual-textual inconsistency (VTI) evaluation plays a crucial role in
cleansing vision-language data. Its main challenges stem from the high variety
of image captioning datasets, where differences in content can create a range
of inconsistencies (\eg, inconsistencies in scene, entities, entity attributes,
entity numbers, entity interactions). Moreover, variations in caption length
can introduce inconsistencies at different levels of granularity as well. To
tackle these challenges, we design an adaptive evaluation framework, called
Hierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can
provide multi-grained evaluations covering both accuracy and completeness for
various image-caption pairs. Specifically, the HMGIE framework is implemented
by three consecutive modules. Firstly, the semantic graph generation module
converts the image caption to a semantic graph for building a structural
representation of all involved semantic items. Then, the hierarchical
inconsistency evaluation module provides a progressive evaluation procedure
with a dynamic question-answer generation and evaluation strategy guided by the
semantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).
Finally, the quantitative evaluation module calculates the accuracy and
completeness scores based on the HIEG, followed by a natural language
explanation about the detection results. Moreover, to verify the efficacy and
flexibility of the proposed framework on handling different image captioning
datasets, we construct MVTID, an image-caption dataset with diverse types and
granularities of inconsistencies. Extensive experiments on MVTID and other
benchmark datasets demonstrate the superior performance of the proposed HMGIE
to current state-of-the-art methods.

摘要：視覺文本不一致性 (VTI) 評估在清理視覺語言資料中扮演著至關重要的角色。其主要挑戰源自於圖像標題資料集的種類繁多，其中內容的差異可能會造成各種不一致性（例如場景、實體、實體屬性、實體數量、實體互動的不一致性）。此外，標題長度的變化也會在不同粒度層級引發不一致性。為了應對這些挑戰，我們設計了一個自適應評估架構，稱為階層式多粒度不一致性評估 (HMGIE)，它可以提供多粒度評估，涵蓋各種圖像標題對的準確性和完整性。具體來說，HMGIE 架構是由三個連續模組實作的。首先，語意圖形產生模組將圖像標題轉換為語意圖形，以建立所有相關語意項目的結構化表示。然後，階層式不一致性評估模組提供漸進式評估程序，並採用由語意圖形引導的動態問題解答產生和評估策略，產生階層式不一致性評估圖形 (HIEG)。最後，量化評估模組根據 HIEG 計算準確性和完整性分數，接著對偵測結果進行自然語言說明。此外，為了驗證所提出的架構在處理不同圖像標題資料集上的效能和靈活性，我們建構了 MVTID，一個具有不同類型和不一致性粒度的圖像標題資料集。在 MVTID 和其他基準資料集上的大量實驗證明了所提出的 HMGIE 優於當前最先進的方法。

##### **KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**
2412.05547v1 by Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

Large language models with retrieval-augmented generation encounter a pivotal
challenge in intricate retrieval tasks, e.g., multi-hop question answering,
which requires the model to navigate across multiple documents and generate
comprehensive responses based on fragmented information. To tackle this
challenge, we introduce a novel Knowledge Graph-based RAG framework with a
hierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing
in KG-Retriever is constructed on a hierarchical index graph that consists of a
knowledge graph layer and a collaborative document layer. The associative
nature of graph structures is fully utilized to strengthen intra-document and
inter-document connectivity, thereby fundamentally alleviating the information
fragmentation problem and meanwhile improving the retrieval efficiency in
cross-document retrieval of LLMs. With the coarse-grained collaborative
information from neighboring documents and concise information from the
knowledge graph, KG-Retriever achieves marked improvements on five public QA
datasets, showing the effectiveness and efficiency of our proposed RAG
framework.

摘要：大型语言模型使用检索增强生成在复杂的检索任务中会遇到关键挑战，例如多跳问题解答，这要求模型跨多个文档导航并根据片段信息生成综合响应。为了应对这一挑战，我们引入了一个基于知识图谱的新型 RAG 框架，该框架具有分层知识检索器，称为 KG-Retriever。KG-Retriever 中的检索索引构建在分层索引图上，该图由知识图谱层和协作文档层组成。图结构的关联性质被充分利用以加强文档内和文档间连接性，从而从根本上缓解信息碎片化问题，同时提高 LLM 跨文档检索中的检索效率。通过来自相邻文档的粗粒度协作信息和来自知识图谱的简洁信息，KG-Retriever 在五个公共问答数据集上取得了显着改进，显示了我们提出的 RAG 框架的有效性和效率。

##### **Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**
2412.05453v1 by Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

This study explores the effectiveness of using knowledge graphs generated by
large language models to decompose high school-level physics questions into
sub-questions. We introduce a pipeline aimed at enhancing model response
quality for Question Answering tasks. By employing LLMs to construct knowledge
graphs that capture the internal logic of the questions, these graphs then
guide the generation of subquestions. We hypothesize that this method yields
sub-questions that are more logically consistent with the original questions
compared to traditional decomposition techniques. Our results show that
sub-questions derived from knowledge graphs exhibit significantly improved
fidelity to the original question's logic. This approach not only enhances the
learning experience by providing clearer and more contextually appropriate
sub-questions but also highlights the potential of LLMs to transform
educational methodologies. The findings indicate a promising direction for
applying AI to improve the quality and effectiveness of educational content.

摘要：本研究探討使用大型語言模型產生的知識圖譜將高中物理題目分解成子問題的有效性。我們引進一個旨在增強模型回應品質的管道，用於問答任務。透過使用大型語言模型建立知識圖譜以捕捉問題的內部邏輯，這些圖譜接著引導子問題的產生。我們假設與傳統分解技術相比，此方法產生的子問題與原始問題在邏輯上更一致。我們的結果顯示，從知識圖譜衍生的子問題展現出顯著改善的保真度，符合原始問題的邏輯。此方法不僅透過提供更清晰且更符合脈絡的子問題來增強學習體驗，也突顯大型語言模型轉化教育方法的潛力。這些發現指出了一個有前途的方向，可將人工智慧應用於提升教育內容的品質與有效性。

##### **A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**
2412.05447v1 by Savini Kashmira, Jayanaka L. Dantanarayana, Joshua Brodsky, Ashish Mahendra, Yiping Kang, Krisztian Flautner, Lingjia Tang, Jason Mars

TOBU is a novel mobile application that captures and retrieves `personal
memories' (pictures/videos together with stories and context around those
moments) in a user-engaging AI-guided conversational approach. Our initial
prototype showed that existing retrieval techniques such as retrieval-augmented
generation (RAG) systems fall short due to their limitations in understanding
memory relationships, causing low recall, hallucination, and unsatisfactory
user experience. We design TOBUGraph, a novel graph-based retrieval approach.
During capturing, TOBUGraph leverages large language models (LLMs) to
automatically create a dynamic knowledge graph of memories, establishing
context and relationships of those memories. During retrieval, TOBUGraph
combines LLMs with the memory graph to achieve comprehensive recall through
graph traversal. Our evaluation using real user data demonstrates that
TOBUGraph outperforms multiple RAG implementations in both precision and
recall, significantly improving user experience through improved retrieval
accuracy and reduced hallucination.

摘要：TOBU 是一款新颖的移动应用程序，它以用户参与式 AI 引导对话方式捕捉和检索“个人记忆”（图片/视频以及这些时刻周围的故事和背景）。我们的初始原型表明，现有的检索技术（例如检索增强生成 (RAG) 系统）由于它们在理解记忆关系方面的局限性而表现不佳，从而导致召回率低、出现幻觉和用户体验不佳。我们设计了 TOBUGraph，一种新颖的基于图的检索方法。在捕获期间，TOBUGraph 利用大型语言模型 (LLM) 自动创建动态知识图谱，建立这些记忆的背景和关系。在检索期间，TOBUGraph 将 LLM 与记忆图谱结合起来，通过图遍历实现全面召回。我们使用真实用户数据进行的评估表明，TOBUGraph 在精确度和召回率方面都优于多个 RAG 实现，通过提高检索准确度和减少幻觉，显著改善了用户体验。

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

摘要：<paragraph>自動回歸大型語言模型 (LLM) 經由下一個符號預測預先訓練，本質上擅長生成式任務。然而，它們在知識驅動任務（例如事實知識查詢）上的表現仍不盡人意。知識圖譜 (KG) 作為高品質的結構化知識庫，可以為 LLM 提供可靠的知識，潛在地彌補其知識不足。將 LLM 與來自 KG 的明確結構化知識對齊一直是一項挑戰；先前的嘗試要么無法有效對齊知識表示，要么損害 LLM 的生成能力，導致結果不盡理想。本文提出了一個**KaLM**，一種**知識對齊語言建模**方法，它微調自動回歸 LLM 以透過明確知識對齊和隱式知識對齊的聯合目標與 KG 知識對齊。明確知識對齊目標旨在透過雙視圖知識圖譜對比學習直接最佳化 LLM 的知識表示。隱式知識對齊目標專注於透過三元組完成語言建模將知識的文字模式納入 LLM。值得注意的是，我們的模型在知識驅動任務的評估中獲得顯著的效能提升，特別是基於嵌入的知識圖譜完成和基於生成的知識圖譜問題解答。</paragraph>

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

摘要：本文提出 HyperGraphOS，這是一個創新的作業系統，專為科學和工程領域設計。它結合了基於模型的工程、圖形建模、資料容器和計算工具，為使用者提供一個動態工作空間，用於建立和管理表示為可自訂圖形的複雜模型。HyperGraphOS 使用基於 Web 的架構，只需要一個現代瀏覽器即可將知識、文件和內容組織成互連模型。特定領域語言驅動工作空間導覽、程式碼產生、AI 整合和流程組織。平台模型同時作為視覺繪圖和資料結構，支援動態修改和檢查，無論是互動式還是以程式方式進行。HyperGraphOS 已在各種領域中進行評估，包括虛擬化身、使用大型語言模型的機器人任務規劃，以及用於基於特徵的程式碼開發的元建模。結果顯示出靈活性、資料管理、運算和文件處理方面的顯著改進。

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

摘要：搜尋是許多重要任務中的一項基礎能力，最近的研究表明，大型語言模型 (LLM) 難以穩健地執行搜尋。目前尚不清楚這種無能是源於資料不足、模型參數不足，還是 Transformer 架構的基本限制。在這項工作中，我們使用基礎圖形連通性問題作為測試平台，生成有效無限的高覆蓋率資料，以訓練小型 Transformer 並測試它們是否能學會執行搜尋。我們發現，當給予正確的訓練分佈時，Transformer 能夠學會搜尋。
我們透過一種新穎的機制可解釋性技術分析 Transformer 學到的演算法，這讓我們能夠從訓練好的模型中提取運算圖形。我們發現，對於輸入圖形中的每個頂點，Transformer 會計算從該頂點可到達的頂點集合。然後，每一層都會逐步擴充這些集合，讓模型能夠在與層數呈指數關係的頂點數目上進行搜尋。
然而，我們發現，隨著輸入圖形大小的增加，Transformer 在學習任務時會遇到更大的困難。即使增加參數數量，這種困難也不會得到解決，這表明增加模型規模不會帶來穩健的搜尋能力。我們還發現，在上下文中執行搜尋（即思考鏈）無法解決這種無法學習在較大圖形上搜尋的問題。

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

摘要：實體對齊 (EA) 旨在識別和匹配不同知識圖譜 (KG) 中對應的實體，在知識融合和整合中扮演著至關重要的角色。基於嵌入的實體對齊 (EA) 近來備受關注，進而催生出許多創新的方法。最初，這些方法專注於根據知識圖譜 (KG) 的結構特徵來學習實體嵌入，這些特徵由關係三元組定義。後續方法將實體名稱和屬性整合為補充資訊，以改善用於 EA 的嵌入。然而，現有方法缺乏對實體屬性和關係的深入語義理解。在本文中，我們提出了一種基於大型語言模型 (LLM) 的實體對齊方法 LLM-Align，該方法探索了大型語言模型的遵循指令和零次學習能力，以推論實體對齊。LLM-Align 使用啟發式方法來選擇實體的重要屬性和關係，然後將實體的選定三元組饋入 LLM 以推論對齊結果。為了保證對齊結果的品質，我們設計了一個多輪投票機制，以減輕 LLM 中出現的幻覺和位置偏差問題。在三個 EA 資料集上的實驗表明，與現有的 EA 方法相比，我們的做法達到了最先進的效能。

##### **Retrieval-Augmented Machine Translation with Unstructured Knowledge**
2412.04342v1 by Jiaan Wang, Fandong Meng, Yingxue Zhang, Jie Zhou

Retrieval-augmented generation (RAG) introduces additional information to
enhance large language models (LLMs). In machine translation (MT), previous
work typically retrieves in-context examples from paired MT corpora, or
domain-specific knowledge from knowledge graphs, to enhance models' MT ability.
However, a large amount of world knowledge is organized in unstructured
documents, and might not be fully paired across different languages. In this
paper, we study retrieval-augmented MT using unstructured documents.
Specifically, we build RAGtrans, the first benchmark to train and evaluate
LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples
collected via GPT-4o and human translators. Besides, documents from different
languages are also provided to supply the knowledge to these samples. Based on
RAGtrans, we further propose a multi-task training method to teach LLMs how to
use information from multilingual documents during their translation. The
method uses existing multilingual corpora to create auxiliary training
objectives without additional labeling requirements. Extensive experiments show
that the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.

摘要：檢索增強產生 (RAG) 會引入額外資訊，以增強大型語言模型 (LLM)。在機器翻譯 (MT) 中，先前的作業通常會從配對的 MT 語料庫中檢索情境範例，或從知識圖表中檢索特定領域的知識，以增強模型的 MT 能力。然而，大量的世界知識都是以非結構化文件組織，而且可能無法完全配對到不同的語言中。在本文中，我們研究使用非結構化文件進行檢索增強 MT。具體來說，我們建立了 RAGtrans，這是第一個用於訓練和評估 LLM 的檢索增強 MT 能力的基準。RAGtrans 包含透過 GPT-4o 和人工翻譯人員收集的 79K 個 MT 範例。此外，也提供了不同語言的文件，以提供這些範例的知識。根據 RAGtrans，我們進一步提出了一個多任務訓練方法，以教導 LLM 如何在翻譯過程中使用多語言文件的資訊。該方法使用現有的多語言語料庫建立輔助訓練目標，而無需額外的標記需求。廣泛的實驗顯示，該方法將 LLM 的 BLEU 分數提高了 1.58-3.09，COMET 分數提高了 1.00-2.03。

##### **GRAF: Graph Retrieval Augmented by Facts for Legal Question Answering**
2412.04119v1 by Cristian-George Crăciun, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

Pre-trained Language Models (PLMs) have shown remarkable performances in
recent years, setting a new paradigm for NLP research and industry. The legal
domain has received some attention from the NLP community partly due to its
textual nature. Some tasks from this domain are represented by
question-answering (QA) tasks. This work explores the legal domain
Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this
work is multi-fold. We first introduce JuRO, the first openly available
Romanian legal MCQA dataset, comprising three different examinations and a
number of 10,836 total questions. Along with this dataset, we introduce CROL,
an organized corpus of laws that has a total of 93 distinct documents with
their modifications from 763 time spans, that we leveraged in this work for
Information Retrieval (IR) techniques. Moreover, we are the first to propose
Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is
derived from the aforementioned corpus. Lastly, we propose a novel approach for
MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive
results with generally accepted SOTA methods and even exceeds them in most
settings.

摘要：<paragraph>預訓練語言模型 (PLM) 在近年來展現出卓越的效能，為自然語言處理的研究和產業樹立了新的典範。法律領域因為其文本性質而受到自然語言處理社群的部分關注。此領域中的一些任務由問答 (QA) 任務表示。這項工作探索了低資源語言的法律領域多重選擇問答 (MCQA)。這項工作的貢獻是多方面的。我們首先介紹 JuRO，這是第一個公開的羅馬尼亞法律 MCQA 資料集，包含三次不同的考試和總共 10,836 個問題。除了這個資料集之外，我們還介紹了 CROL，這是一個有組織的法律語料庫，總共有 93 個不同的文件，包含了來自 763 個時間區間的修改，我們在這個工作中利用它來進行資訊檢索 (IR) 技術。此外，我們是第一個提出 Law-RoG 的人，這是一個羅馬尼亞語的知識圖譜 (KG)，而這個 KG 是從上述語料庫衍生的。最後，我們提出了一個新的多重選擇問答方法，由事實增強的圖形檢索 (GRAF)，它在一般公認的 SOTA 方法中獲得了有競爭力的結果，甚至在大多數設定中都超越了它們。</paragraph>

##### **MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**
2412.03930v1 by Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Jie Tang

The rapid growth of academic publications has exacerbated the issue of author
name ambiguity in online digital libraries. Despite advances in name
disambiguation algorithms, cumulative errors continue to undermine the
reliability of academic systems. It is estimated that over 10% paper-author
assignments are rectified when constructing the million-scale WhoIsWho
benchmark. Existing endeavors to detect incorrect assignments are either
semantic-based or graph-based approaches, which fall short of making full use
of the rich text attributes of papers and implicit structural features defined
via the co-occurrence of paper attributes. To this end, this paper introduces a
structure-enhanced language model that combines key structural features from
graph-based methods with fine-grained semantic features from rich paper
attributes to detect incorrect assignments. The proposed model is trained with
a highly effective multi-modal multi-turn instruction tuning framework, which
incorporates task-guided instruction tuning, text-attribute modality, and
structural modality. Experimental results demonstrate that our model
outperforms previous approaches, achieving top performance on the leaderboard
of KDD Cup 2024. Our code has been publicly available.

摘要：學術出版品的快速成長，加劇了線上數位圖書館中作者姓名歧義的問題。儘管姓名消歧演算法有進展，累積的錯誤仍持續破壞學術系統的可靠性。據估計，在建構百萬規模的 WhoIsWho 基準時，超過 10% 的論文作者指派被修正。現有的偵測不正確指派的努力，不是基於語意的，就是基於圖的，無法充分利用論文豐富的文字屬性和透過論文屬性共現定義的隱含結構特徵。為此，本文介紹了一個結構增強語言模型，將基於圖的方法中的關鍵結構特徵與豐富論文屬性中的細粒度語義特徵相結合，以偵測不正確的指派。所提出的模型使用一個高效的多模態多輪指令微調架構進行訓練，其中包含任務導向的指令微調、文字屬性模態和結構模態。實驗結果證明，我們的模型優於先前的模型，在 KDD Cup 2024 的排行榜上取得最佳效能。我們的程式碼已公開。

##### **How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**
2412.03856v1 by Patrick Ocheja, Brendan Flanagan, Yiling Dai, Hiroaki Ogata

E-learning environments are increasingly harnessing large language models
(LLMs) like GPT-3.5 and GPT-4 for tailored educational support. This study
introduces an approach that integrates dynamic knowledge graphs with LLMs to
offer nuanced student assistance. By evaluating past and ongoing student
interactions, the system identifies and appends the most salient learning
context to prompts directed at the LLM. Central to this method is the knowledge
graph's role in assessing a student's comprehension of topic prerequisites.
Depending on the categorized understanding (good, average, or poor), the LLM
adjusts its guidance, offering advanced assistance, foundational reviews, or
in-depth prerequisite explanations, respectively. Preliminary findings suggest
students could benefit from this tiered support, achieving enhanced
comprehension and improved task outcomes. However, several issues related to
potential errors arising from LLMs were identified, which can potentially
mislead students. This highlights the need for human intervention to mitigate
these risks. This research aims to advance AI-driven personalized learning
while acknowledging the limitations and potential pitfalls, thus guiding future
research in technology and data-driven education.

摘要：電子學習環境正日益利用大型語言模型 (LLM)，例如 GPT-3.5 和 GPT-4，提供量身打造的教育支援。本研究提出了一種方法，將動態知識圖與 LLM 整合，提供細緻入微的學生協助。系統會評估過去和正在進行的學生互動，找出並附加最顯著的學習脈絡，以提示 LLM。此方法的核心在於知識圖在評估學生對主題先備知識的理解程度方面所扮演的角色。LLM 會根據分類後的理解程度（良好、普通或差）調整其指導，分別提供進階協助、基礎回顧或深入的先備知識說明。初步發現表明，學生可以受益於這種分層支援，達到增強的理解力和改善的任務成果。然而，已找出與 LLM 產生的潛在錯誤相關的幾個問題，這些錯誤可能會誤導學生。這突顯了人類介入以降低這些風險的必要性。本研究旨在推進 AI 驅動的個人化學習，同時承認限制和潛在的陷阱，從而指導未來在技術和資料驅動教育方面的研究。

##### **Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**
2412.03815v1 by Samuel Abedu, SayedHassan Khatoonabadi, Emad Shihab

Software repositories contain valuable information for gaining insights into
their development process. However, extracting insights from these repository
data is time-consuming and requires technical expertise. While software
engineering chatbots have been developed to facilitate natural language
interactions with repositories, they struggle with understanding natural
language and accurately retrieving relevant data. This study aims to improve
the accuracy of LLM-based chatbots in answering repository-related questions by
augmenting them with knowledge graphs. We achieve this in a two-step approach;
(1) constructing a knowledge graph from the repository data and (2) synergizing
the knowledge graph with LLM to allow for the natural language questions and
answers. We curated a set of 20 questions with different complexities and
evaluated our approach on five popular open-source projects. Our approach
achieved an accuracy of 65%. We further investigated the limitations and
identified six key issues, with the majority relating to the reasoning
capability of the LLM. We experimented with a few-shot chain-of-thought
prompting to determine if it could enhance our approach. This technique
improved the overall accuracy to 84%. Our findings demonstrate the synergy
between LLMs and knowledge graphs as a viable solution for making repository
data accessible to both technical and non-technical stakeholders.

摘要：軟體儲存庫包含有價值的資訊，可深入了解其開發流程。然而，從這些儲存庫資料中擷取見解既耗時又需要技術專業知識。儘管已開發出軟體工程聊天機器人來促進與儲存庫的自然語言互動，但它們在理解自然語言和準確擷取相關資料方面仍有困難。本研究旨在透過知識圖譜擴充 LLM 基礎聊天機器人，以提高其回答儲存庫相關問題的準確性。我們採用兩步驟方法來達成此目標：(1) 從儲存庫資料建構知識圖譜，以及 (2) 將知識圖譜與 LLM 結合，以允許自然語言問題和答案。我們策劃了一組 20 個具有不同複雜度的問題，並針對五個熱門的開源專案評估我們的做法。我們的做法達到了 65% 的準確度。我們進一步探討了限制，並找出六個關鍵問題，其中大部分與 LLM 的推理能力有關。我們實驗了少次數的思考鏈提示，以確定它是否可以增強我們的做法。此技術將整體準確度提高到 84%。我們的研究結果證明了 LLM 和知識圖譜之間的協同效應，作為讓技術和非技術利害關係人能夠存取儲存庫資料的可行解決方案。

##### **Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**
2412.03801v1 by Jialin Wang, Zhihua Duan

This paper explores the transformative role of Agent AI and LangGraph in
advancing the automation and effectiveness of machine translation (MT). Agents
are modular components designed to perform specific tasks, such as translating
between particular languages, with specializations like TranslateEnAgent,
TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese
translations, respectively. These agents leverage the powerful semantic
capabilities of large language models (LLMs), such as GPT-4o, to ensure
accurate, contextually relevant translations while maintaining modularity,
scalability, and context retention.
  LangGraph, a graph-based framework built on LangChain, simplifies the
creation and management of these agents and their workflows. It supports
dynamic state management, enabling agents to maintain dialogue context and
automates complex workflows by linking agents and facilitating their
collaboration. With flexibility, open-source community support, and seamless
integration with LLMs, LangGraph empowers agents to deliver high-quality
translations.
  Together, Agent AI and LangGraph create a cohesive system where LangGraph
orchestrates agent interactions, ensuring that user inputs are analyzed,
routed, and processed efficiently. Experimental results demonstrate the
potential of this system to enhance multilingual translation accuracy and
scalability. By highlighting modular design and automated workflows, this paper
sets the stage for further innovations in intelligent machine translation
services.

摘要：本文探討了 Agent AI 和 LangGraph 在推動機器翻譯 (MT) 的自動化和效率方面的變革性作用。Agent 是模組化元件，旨在執行特定任務，例如在特定語言之間翻譯，並具有專門領域，例如 TranslateEnAgent、TranslateFrenchAgent 和 TranslateJpAgent 分別用於英文、法文和日文的翻譯。這些 Agent 運用大型語言模型 (LLM) 的強大語義功能，例如 GPT-4o，以確保準確、與上下文相關的翻譯，同時保持模組化、可擴充性和上下文保留。
LangGraph 是建構於 LangChain 上的圖形化框架，簡化了這些 Agent 及其工作流程的建立和管理。它支援動態狀態管理，讓 Agent 能夠維護對話內容，並透過連結 Agent 和促進其協作，自動化複雜的工作流程。LangGraph 具有靈活性、開放原始碼社群支援和與 LLM 無縫整合等優點，讓 Agent 能夠提供高品質的翻譯。
Agent AI 和 LangGraph 共同建立了一個緊密的系統，其中 LangGraph 編排 Agent 互動，確保使用者輸入被有效地分析、路由和處理。實驗結果證明了這個系統在提升多語言翻譯準確性和可擴充性方面的潛力。透過強調模組化設計和自動化工作流程，本文為智慧型機器翻譯服務的進一步創新奠定了基礎。

##### **Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**
2412.03761v1 by Ximing Wen

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on NLP tasks, but their black-box
nature, which leads to a lack of interpretability, has been a major concern. My
dissertation focuses on developing intrinsically interpretable models when
using LMs as encoders while maintaining their superior performance via
prototypical networks. I initiated my research by investigating enhancements in
performance for interpretable models of sarcasm detection. My proposed approach
focuses on capturing sentiment incongruity to enhance accuracy while offering
instance-based explanations for the classification decisions. Later, I
developed a novel white-box multi-head graph attention-based prototype network
designed to explain the decisions of text classification models without
sacrificing the accuracy of the original black-box LMs. In addition, I am
working on extending the attention-based prototype network with contrastive
learning to redesign an interpretable graph neural network, aiming to enhance
both the interpretability and performance of the model in document
classification.

摘要：預先訓練好的基於 Transformer 的語言模型 (LM) 以其在 NLP 任務中取得顯著進步的能力而聞名，但它們的黑盒性質導致缺乏可解釋性，一直是一個主要問題。我的論文重點在於在使用 LM 作為編碼器時開發內在可解釋的模型，同時通過原型網路維持其優異的效能。我透過研究諷刺偵測的可解釋模型的效能提升來啟動我的研究。我提出的方法專注於捕捉情緒不一致性，以提高準確度，同時為分類決策提供基於實例的解釋。後來，我開發了一個新穎的白盒多頭圖形注意力原型網路，旨在解釋文字分類模型的決策，而不會犧牲原始黑盒 LM 的準確度。此外，我正在努力將基於注意力的原型網路與對比學習擴展，以重新設計一個可解釋的圖形神經網路，旨在增強模型在文件分類中的可解釋性和效能。

##### **How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**
2412.03624v1 by Wenyi Wang, Hisham A. Alyahya, Dylan R. Ashley, Oleg Serikov, Dmitrii Khizbullin, Francesco Faccio, Jürgen Schmidhuber

Language-based agentic systems have shown great promise in recent years,
transitioning from solving small-scale research problems to being deployed in
challenging real-world tasks. However, optimizing these systems often requires
substantial manual labor. Recent studies have demonstrated that these systems
can be represented as computational graphs, enabling automatic optimization.
Despite these advancements, most current efforts in Graph-based Agentic System
Optimization (GASO) fail to properly assign feedback to the system's components
given feedback on the system's output. To address this challenge, we formalize
the concept of semantic backpropagation with semantic gradients -- a
generalization that aligns several key optimization techniques, including
reverse-mode automatic differentiation and the more recent TextGrad by
exploiting the relationship among nodes with a common successor. This serves as
a method for computing directional information about how changes to each
component of an agentic system might improve the system's output. To use these
gradients, we propose a method called semantic gradient descent which enables
us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show
that our approach outperforms existing state-of-the-art methods for solving
GASO problems. A detailed ablation study on the LIAR dataset demonstrates the
parsimonious nature of our method. A full copy of our implementation is
publicly available at https://github.com/HishamAlyahya/semantic_backprop

摘要：<paragraph>近年來，基於語言的代理系統展現了極大的前景，
從解決小規模的研究問題，轉變為部署在
具有挑戰性的真實世界任務中。然而，最佳化這些系統通常需要
大量的人工勞力。最近的研究表明，這些系統
可以表示為計算圖，實現自動最佳化。
儘管有這些進展，但目前大多數基於圖形的代理系統
最佳化 (GASO) 的努力，都無法適當地將回饋分配給系統的組成部分
給予系統輸出的回饋。為了應對這一挑戰，我們正式化了
語義反向傳播的概念，並帶有語義梯度——一種
概括，它結合了幾種關鍵的最佳化技術，包括
反向模式自動微分和最近的 TextGrad，利用具有共同後繼者的節點之間的關係。這可以用作
一種計算方向資訊的方法，說明如何改變代理系統的每個
組成部分可能會改善系統的輸出。為了使用這些
梯度，我們提出了一種稱為語義梯度下降的方法，使我們能夠
有效地解決 GASO。我們在 BIG-Bench Hard 和 GSM8K 上的結果表明
我們的做法優於解決
GASO 問題的現有最先進方法。在 LIAR 資料集上進行的詳細消融研究證明了
我們方法的簡約性。我們的實作的完整副本公開於 https://github.com/HishamAlyahya/semantic_backprop</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

摘要：供應鏈風險管理中的一個關鍵障礙在於企業和政策制定者缺乏對相互依存供應網路關係的能見度。關係預測，也稱為連結預測，是供應鏈監控研究中一個新興領域，旨在使用資料驅動技術提高供應鏈的能見度。現有方法已成功預測關係，但難以提取這些關係所嵌入的背景，例如所供應的產品或供應地點。缺乏背景會妨礙從業者區分交易關係和既定的供應鏈關係，進而阻礙風險的準確評估。在這項工作中，我們開發了一個新的生成式人工智慧 (Gen AI) 增強機器學習架構，它利用預先訓練的語言模型作為嵌入模型，並結合機器學習模型來預測知識圖譜中的供應鏈關係。透過整合生成式 AI 技術，我們的做法捕捉到實體之間細微的語義關係，從而提高供應鏈能見度並促進更精確的風險管理。使用來自真實案例研究的資料，我們證明 GenAI 增強連結預測優於所有基準，並展示如何探索和有效地在供應鏈風險管理中使用 GenAI 模型。

##### **CBEval: A framework for evaluating and interpreting cognitive biases in LLMs**
2412.03605v1 by Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar

Rapid advancements in Large Language models (LLMs) has significantly enhanced
their reasoning capabilities. Despite improved performance on benchmarks, LLMs
exhibit notable gaps in their cognitive processes. Additionally, as reflections
of human-generated data, these models have the potential to inherit cognitive
biases, raising concerns about their reasoning and decision making
capabilities. In this paper we present a framework to interpret, understand and
provide insights into a host of cognitive biases in LLMs. Conducting our
research on frontier language models we're able to elucidate reasoning
limitations and biases, and provide reasoning behind these biases by
constructing influence graphs that identify phrases and words most responsible
for biases manifested in LLMs. We further investigate biases such as round
number bias and cognitive bias barrier revealed when noting framing effect in
language models.

摘要：大型語言模型 (LLM) 的快速進步顯著增強了它們的推理能力。儘管在基準測試中的表現有所提升，但 LLM 在其認知過程中仍存在顯著的差距。此外，作為人類生成數據的反映，這些模型有可能繼承認知偏差，引發人們對其推理和決策能力的擔憂。在本文中，我們提出了一個框架來解釋、理解和洞察 LLM 中的一系列認知偏差。通過對前沿語言模型進行研究，我們能夠闡明推理限制和偏差，並通過構建影響圖來提供這些偏差背後的推理，這些影響圖識別出對 LLM 中表現出的偏差負有最大責任的短語和詞彙。我們進一步研究了在語言模型中註明框架效應時揭示的偏差，例如四捨五入偏差和認知偏差障礙。

##### **Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**
2412.02788v2 by Tilahun Abedissa Taffa, Debayan Banerjee, Yaregal Assabie, Ricardo Usbeck

Existing Scholarly Question Answering (QA) methods typically target
homogeneous data sources, relying solely on either text or Knowledge Graphs
(KGs). However, scholarly information often spans heterogeneous sources,
necessitating the development of QA systems that integrate information from
multiple heterogeneous data sources. To address this challenge, we introduce
Hybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale
QA dataset designed to facilitate answering questions incorporating both text
and KG facts. The dataset consists of 10.5K question-answer pairs generated by
a large language model, leveraging the KGs DBLP and SemOpenAlex alongside
corresponding text from Wikipedia. In addition, we propose a RAG-based baseline
hybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD
test set.

摘要：現有的學術問題解答 (QA) 方法通常針對同質資料來源，僅依賴文本或知識圖譜 (KG)。然而，學術資訊通常橫跨異質來源，因此有必要開發整合來自多個異質資料來源資訊的 QA 系統。為了應對此挑戰，我們引入了 Hybrid-SQuAD（混合學術問題解答資料集），這是一個新穎的大規模 QA 資料集，旨在促進回答包含文本和 KG 事實的問題。該資料集包含 10.5K 個問題答案對，由大型語言模型生成，利用 KGs DBLP 和 SemOpenAlex 以及來自維基百科的對應文本。此外，我們提出了基於 RAG 的基線混合 QA 模型，在 Hybrid-SQuAD 測試集中實現了 69.65 的完全匹配分數。

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

摘要：降臨節密碼（以下簡稱 AoC）是一項流行的編碼挑戰，需要解決各種技能組和等級的程式設計謎題。AoC 遵循降臨曆，因此是一項為期 25 天的年度挑戰。AoC 參與者通常在社群網路上發布他們的解決方案，並在網路上討論它們。這些挑戰很有趣，因為它們可以突顯新工具的採用、開發人員社群的演進，或知名公司的技術需求。基於這些原因，我們首先建立一個包含在 subreddit {\tt /r/adventofcode} 上進行討論串的 2019-2021 年 AoC 版本資料集。然後，我們提出一個基於串流圖的模型來最佳研究此背景，其中我們隨著時間呈現其最重要的參與者：參與者、留言和程式語言。透過我們的模型，我們調查使用者參與度、在挑戰期間和兩者之間採用新程式語言的情況，以及根據 Stack Overflow 調查對程式語言的復原力。我們發現三年來最常用的程式語言幾乎相同，指出了它們的重要性。此外，參與者傾向於在整個挑戰中使用相同的程式語言，而參加兩個 AoC 的參與者通常會在下一場比賽中更換程式語言。最後，我們觀察到關於根據 Stack Overflow 調查被歸類為「熱門」或「喜愛」的程式語言的一些有趣結果。首先，這些程式語言是 AoC 版本中採用最久的程式語言，因此使用者有很高的機會完成挑戰。其次，當參與者決定在同一個挑戰中更改程式語言時，它們是最常被選用的程式語言。

##### **A Neurosymbolic Fast and Slow Architecture for Graph Coloring**
2412.01752v1 by Vedant Khandelwal, Vishal Pallagani, Biplav Srivastava, Francesca Rossi

Constraint Satisfaction Problems (CSPs) present significant challenges to
artificial intelligence due to their intricate constraints and the necessity
for precise solutions. Existing symbolic solvers are often slow, and prior
research has shown that Large Language Models (LLMs) alone struggle with CSPs
because of their complexity. To bridge this gap, we build upon the existing
SOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,
Fast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,
integrates refined metacognitive governance mechanisms to improve adaptability
across complex domains, specifically tailored for solving CSPs like graph
coloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a
deliberative System 2 (S2) governed by a metacognition module. S1's initial
solutions, often limited by non-adherence to constraints, are enhanced through
metacognitive governance, which provides targeted feedback and examples to
adapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition
strategically invokes S2, ensuring accurate and reliable solutions. With
empirical results, we show that SOFAI-v2 for graph coloring problems achieves a
16.98% increased success rate and is 32.42% faster than symbolic solvers.

摘要：約束滿足問題 (CSP) 因為其複雜的約束和對精確解的必要性，對人工智慧提出了重大的挑戰。現有的符號求解器通常很慢，而先前的研究表明，大型語言模型 (LLM) 因為其複雜性而無法單獨處理 CSP。為了彌補這個差距，我們建立在現有的 SOFAI 架構（或 SOFAI-v1）之上，它將 Daniel Kahneman 的「快思慢想」認知模型調整為 AI。我們增強的架構 SOFAI-v2 整合了精緻的元認知治理機制，以提高跨複雜領域的適應性，特別是針對解決圖形著色等 CSP 而量身打造。SOFAI-v2 結合了基於 LLM 的快速系統 1 (S1) 和由元認知模組管控的審慎系統 2 (S2)。S1 的初始解法通常受到不遵守約束的限制，透過元認知治理得以增強，提供有針對性的回饋和範例，以適應 S1 的 CSP 需求。如果 S1 無法解決問題，元認知會策略性地呼叫 S2，確保準確且可靠的解法。透過經驗結果，我們展示了用於圖形著色問題的 SOFAI-v2 達到了成功率提高 16.98%，並且比符號求解器快 32.42%。

##### **Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows**
2412.01490v4 by Jialin Wang, Zhihua Duan

This paper presents a Spark-based modular LangGraph framework, designed to
enhance machine learning workflows through scalability, visualization, and
intelligent process optimization. At its core, the framework introduces Agent
AI, a pivotal innovation that leverages Spark's distributed computing
capabilities and integrates with LangGraph for workflow orchestration.
  Agent AI facilitates the automation of data preprocessing, feature
engineering, and model evaluation while dynamically interacting with data
through Spark SQL and DataFrame agents. Through LangGraph's graph-structured
workflows, the agents execute complex tasks, adapt to new inputs, and provide
real-time feedback, ensuring seamless decision-making and execution in
distributed environments. This system simplifies machine learning processes by
allowing users to visually design workflows, which are then converted into
Spark-compatible code for high-performance execution.
  The framework also incorporates large language models through the LangChain
ecosystem, enhancing interaction with unstructured data and enabling advanced
data analysis. Experimental evaluations demonstrate significant improvements in
process efficiency and scalability, as well as accurate data-driven
decision-making in diverse application scenarios.
  This paper emphasizes the integration of Spark with intelligent agents and
graph-based workflows to redefine the development and execution of machine
learning tasks in big data environments, paving the way for scalable and
user-friendly AI solutions.

摘要：<paragraph>本文提出了一個基於 Spark 的模組化 LangGraph 框架，旨在透過可擴充性、可視化和智慧流程最佳化來提升機器學習工作流程。在核心部分，此框架引入了 Agent AI，這項關鍵創新利用了 Spark 的分散式運算能力，並與 LangGraph 整合以進行工作流程編排。
  Agent AI 促進了資料前處理、特徵工程和模型評估的自動化，同時透過 Spark SQL 和 DataFrame 代理與資料動態互動。透過 LangGraph 的圖形結構工作流程，這些代理執行複雜的任務、適應新的輸入，並提供即時回饋，確保在分散式環境中進行無縫決策制定和執行。此系統透過允許使用者視覺化設計工作流程（其後轉換為相容於 Spark 的程式碼以進行高性能執行）來簡化機器學習流程。
  此框架也透過 LangChain 生態系整合了大型語言模型，增強了與非結構化資料的互動，並啟用了進階資料分析。實驗評估顯示，流程效率和可擴充性有顯著改善，而且在不同的應用情境中進行了精確的資料驅動決策制定。
  本文強調了 Spark 與智慧代理和基於圖形的工作流程的整合，以重新定義大資料環境中機器學習任務的開發和執行，為可擴充且使用者友善的 AI 解决方案鋪路。</paragraph>

##### **SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**
2412.00765v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia

Traditional methods for evaluating the robustness of large language models
(LLMs) often rely on standardized benchmarks, which can escalate costs and
limit evaluations across varied domains. This paper introduces a novel
framework designed to autonomously evaluate the robustness of LLMs by
incorporating refined adversarial prompts and domain-constrained knowledge
guidelines in the form of knowledge graphs. Our method systematically generates
descriptive sentences from domain-constrained knowledge graph triplets to
formulate adversarial prompts, enhancing the relevance and challenge of the
evaluation. These prompts, generated by the LLM itself and tailored to evaluate
its own robustness, undergo a rigorous filtering and refinement process,
ensuring that only those with high textual fluency and semantic fidelity are
used. This self-evaluation mechanism allows the LLM to evaluate its robustness
without the need for external benchmarks. We assess the effectiveness of our
framework through extensive testing on both proprietary models like ChatGPT and
open-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that
our approach not only reduces dependency on conventional data but also provides
a targeted and efficient means of evaluating LLM robustness in constrained
domains.

摘要：傳統用於評估大型語言模型 (LLM) 穩健性的方法通常依賴標準化基準，這可能會增加成本並限制跨不同領域的評估。本文介紹了一個新穎的框架，旨在透過在知識圖譜的形式中納入精緻的對抗提示和領域約束知識準則，來自主評估 LLM 的穩健性。我們的做法是系統性地從領域約束知識圖譜三元組中產生描述性句子，以制定對抗提示，增強評估的相關性和挑戰性。這些提示是由 LLM 本身產生，並針對評估其自身的穩健性而量身打造，它們會經歷嚴格的過濾和精煉過程，確保只有那些具有高度文本流暢性和語義保真性的提示才會被使用。這種自我評估機制允許 LLM 在不需要外部基準的情況下評估其穩健性。我們透過對專有模型（例如 ChatGPT）和開源模型（例如 Llama-3.1、Phi-3 和 Mistral）進行廣泛測試，評估我們框架的有效性。結果證實，我們的做法不僅減少了對傳統資料的依賴性，還提供了一種有針對性和有效的方法，可以在受限領域中評估 LLM 的穩健性。

##### **Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**
2412.00608v3 by Mohammad Sadeq Abolhasani, Rong Pan

Extracting relevant and structured knowledge from large, complex technical
documents within the Reliability and Maintainability (RAM) domain is
labor-intensive and prone to errors. Our work addresses this challenge by
presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge
Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through
an interactive user interface guided by our adaptive iterative Chain of Thought
(CoT) algorithm to ensure that the ontology extraction process and, thus, KG
generation align with user-specific requirements. Although KG generation
follows a clear, structured path based on the confirmed ontology, there is no
universally correct ontology as it is inherently based on the user's
preferences. OntoKGen recommends an ontology grounded in best practices,
minimizing user effort and providing valuable insights that may have been
overlooked, all while giving the user complete control over the final ontology.
Having generated the KG based on the confirmed ontology, OntoKGen enables
seamless integration into schemeless, non-relational databases like Neo4j. This
integration allows for flexible storage and retrieval of knowledge from
diverse, unstructured sources, facilitating advanced querying, analysis, and
decision-making. Moreover, the generated KG serves as a robust foundation for
future integration into Retrieval Augmented Generation (RAG) systems, offering
enhanced capabilities for developing domain-specific intelligent applications.

摘要：從可靠性和可維護性 (RAM) 領域中龐大且複雜的技術文件中萃取相關且結構化的知識，是一項勞力密集且容易出錯的工作。我們的研究透過提出 OntoKGen 來解決這個挑戰，這是一個真正的本体萃取和知識圖譜 (KG) 產生的管道。OntoKGen 透過大型語言模型 (LLM) 以及由我們自適應的迭代思考鏈 (CoT) 演算法引導的互動式使用者介面，來確保本体萃取的流程以及知識圖譜的產生符合使用者特定的需求。雖然知識圖譜的產生會遵循一個明確且結構化的路徑，根據已確認的本体，但並沒有一個普遍正確的本体，因為它本質上是基於使用者的偏好。OntoKGen 會推薦一個基於最佳實務的本体，將使用者的工作量降到最低，並提供可能被忽略的寶貴見解，同時讓使用者完全控制最終的本体。在根據已確認的本体產生知識圖譜後，OntoKGen 能夠無縫整合到像 Neo4j 這樣的無模式、非關係式資料庫中。這種整合允許從多樣且非結構化的來源中靈活地儲存和擷取知識，促進進階的查詢、分析和決策制定。此外，產生的知識圖譜可作為未來整合到檢索擴增生成 (RAG) 系統中的穩固基礎，提供開發特定領域智慧型應用程式的進階功能。

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by Théo Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

摘要：這篇論文介紹了 Opus，一個用於產生和最佳化工作流程的新穎架構，專為複雜的業務流程外包 (BPO) 使用案例量身打造，重點在於降低成本和提升品質，同時遵守既定的產業流程和營運限制。我們的做法根據意圖產生可執行的工作流程，意圖定義為客戶輸入、客戶輸出和流程背景的對齊。這些工作流程表示為有向無環圖 (DAG)，節點為包含可執行指令序列的任務，包括工具和人類專家的審查。我們採用兩階段方法：工作流程產生和工作流程最佳化。在產生階段，工作流程使用大型工作模型 (LWM) 產生，該模型由編碼特定領域程序和運作知識的工作知識圖 (WKG) 提供資訊。在最佳化階段，工作流程轉換為工作流程圖 (WFG)，其中通過路徑最佳化來確定最佳工作流程。我們的實驗表明，最先進的大型語言模型 (LLM) 在可靠地擷取詳細的流程資料以及產生符合產業規範的工作流程方面面臨挑戰。這篇論文的主要貢獻包括將工作知識圖 (WKG) 整合到大型工作模型 (LWM) 中，以產生具備情境感知、語義對齊、結構化和可稽核的工作流程。它進一步介紹了一種兩階段方法，將基於意圖的工作流程產生與基於圖形的工作流程最佳化相結合。最後，我們展示了 Opus Alpha 1 Large 和 Opus Alpha 1 Small，它們在醫療編碼使用案例中分別比最先進的 LLM 在工作流程產生方面高出 38% 和 29%。

##### **Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**
2412.00478v1 by Xinyu Lin, Tianyu Zhang, Chengbin Hou, Jinbao Wang, Jianye Xue, Hairong Lv

Node Importance Estimation (NIE) is a task that quantifies the importance of
node in a graph. Recent research has investigated to exploit various
information from Knowledge Graphs (KGs) to estimate node importance scores.
However, the semantic information in KGs could be insufficient, missing, and
inaccurate, which would limit the performance of existing NIE models. To
address these issues, we leverage Large Language Models (LLMs) for semantic
augmentation thanks to the LLMs' extra knowledge and ability of integrating
knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered
Node Importance Estimation (LENIE) method to enhance the semantic information
in KGs for better supporting NIE tasks. To our best knowledge, this is the
first work incorporating LLMs into NIE. Specifically, LENIE employs a novel
clustering-based triplet sampling strategy to extract diverse knowledge of a
node sampled from the given KG. After that, LENIE adopts the node-specific
adaptive prompts to integrate the sampled triplets and the original node
descriptions, which are then fed into LLMs for generating richer and more
precise augmented node descriptions. These augmented descriptions finally
initialize node embeddings for boosting the downstream NIE model performance.
Extensive experiments demonstrate LENIE's effectiveness in addressing semantic
deficiencies in KGs, enabling more informative semantic augmentation and
enhancing existing NIE models to achieve the state-of-the-art performance. The
source code of LENIE is freely available at
\url{https://github.com/XinyuLin-FZ/LENIE}.

摘要：節點重要性估計 (NIE) 是一項量化圖中節點重要性的任務。最近的研究已調查利用知識圖譜 (KG) 中的各種資訊來估計節點重要性分數。然而，KG 中的語義資訊可能不足、遺失且不準確，這將限制現有 NIE 模型的效能。為了解決這些問題，我們利用大型語言模型 (LLM) 進行語義增強，這要歸功於 LLM 的額外知識和整合 LLM 和 KG 中知識的能力。為此，我們提出 LLM 強化節點重要性估計 (LENIE) 方法，以增強 KG 中的語義資訊，以便更好地支援 NIE 任務。據我們所知，這是將 LLM 納入 NIE 的第一項工作。具體來說，LENIE 採用新穎的基於群集的三元組取樣策略，以萃取從給定 KG 取樣的節點的多元知識。在那之後，LENIE 採用特定於節點的自適應提示，以整合取樣的三元組和原始節點描述，然後將它們輸入 LLM 以產生更豐富且更精確的增強節點描述。這些增強的描述最終初始化節點嵌入，以提升下游 NIE 模型效能。廣泛的實驗證明了 LENIE 在解決 KG 中的語義缺陷方面的有效性，實現更多資訊性的語義增強，並增強現有的 NIE 模型以達成最先進的效能。LENIE 的原始程式碼可於\url{https://github.com/XinyuLin-FZ/LENIE} 免費取得。

##### **An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**
2412.00224v1 by Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao

Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.

摘要：基礎建設建設，常被稱為「產業中的產業」，與政府支出和公共採購息息相關，透過提升透明度和資訊取得，能大幅提升效率和生產力。透過善用這些機會，我們能在生產力、成本節省和更廣泛的經濟效益上獲得顯著的收益。我們的做法引進一個整合式軟體生態系，利用資料網格和服務網格架構。這個系統包含基礎建設和採購最大的訓練資料集，涵蓋超過 1000 億個符號、科學出版品、活動和風險資料，所有資料都以系統化的 AI 架構進行結構化。我們的平台由連結到特定領域的多重代理人任務和問答功能的知識圖譜提供支援，標準化並匯入不同的資料來源，將其轉換為結構化的知識。我們的系統利用大語言模型 (LLM) 和自動化，徹底改革資料結構化和知識建立，協助在早期階段的專案規劃、詳細研究、市場趨勢分析和定性評估中進行決策制定。其可擴充至網路規模的架構提供領域策展的資訊，讓 AI 代理人能夠促進推理和管理不確定性，同時準備好以專門代理人因應特定挑戰，進行未來的擴充。這種將 AI 與領域專業知識整合的方式，不僅提升建設和基礎建設的效率和決策制定，也建立了一個架構，以提升政府效率並加速傳統產業轉型至數位工作流程。這項工作準備對這個部門的 AI 驅動計畫產生重大影響，並引導 AI 作業的最佳實務。

##### **PerLA: Perceptive 3D Language Assistant**
2411.19774v1 by Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang

Enabling Large Language Models (LLMs) to understand the 3D physical world is
an emerging yet challenging research direction. Current strategies for
processing point clouds typically downsample the scene or divide it into
smaller parts for separate analysis. However, both approaches risk losing key
local details or global contextual information. In this paper, we introduce
PerLA, a 3D language assistant designed to be more perceptive to both details
and context, making visual representations more informative for the LLM. PerLA
captures high-resolution (local) details in parallel from different point cloud
areas and integrates them with (global) context obtained from a
lower-resolution whole point cloud. We present a novel algorithm that preserves
point cloud locality through the Hilbert curve and effectively aggregates
local-to-global information via cross-attention and a graph neural network.
Lastly, we introduce a novel loss for local representation consensus to promote
training stability. PerLA outperforms state-of-the-art 3D language assistants,
with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on
ScanRefer and +3.88 on Nr3D for dense
captioning.\url{https://gfmei.github.io/PerLA/}

摘要：讓大型語言模型 (LLM) 理解 3D 物理世界是一個新興但具有挑戰性的研究方向。當前處理點雲的策略通常會對場景進行降採樣或將其分為更小的部分以進行單獨分析。然而，這兩種方法都有可能遺失關鍵的局部細節或全局背景資訊。在本文中，我們介紹了 PerLA，這是一個 3D 語言助理，旨在更敏銳地感知細節和背景，讓視覺表現對 LLM 更有資訊性。PerLA 從不同的點雲區域並行擷取高解析度（局部）細節，並將其與從低解析度全點雲中獲得的（全局）背景整合在一起。我們提出了一種新演算法，透過希爾伯特曲線保留點雲局部性，並透過交叉注意力和圖形神經網路有效地匯總局部到全局資訊。最後，我們引入了一個新的損失函數，用於局部表示共識，以促進訓練穩定性。PerLA 優於最先進的 3D 語言助理，在 ScanQA 上問答獲得高達 +1.34 CiDEr 的增益，在 ScanRefer 上獲得 +4.22，在 Nr3D 上獲得 +3.88 的密集標題。\url{https://gfmei.github.io/PerLA/}

##### **Knowledge Management for Automobile Failure Analysis Using Graph RAG**
2411.19539v1 by Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, Hiroaki Sakata, Kazuya Seki, Yuu Teshigawara, Masami Yamashita, Kazuhiro Aoyama

This paper presents a knowledge management system for automobile failure
analysis using retrieval-augmented generation (RAG) with large language models
(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a
growing demand for knowledge transfer of failure analysis from experienced
engineers to young engineers. However, failure events are phenomena that occur
in a chain reaction, making them difficult for beginners to analyze them. While
knowledge graphs, which can describe semantic relationships and structure
information is effective in representing failure events, due to their
capability of representing the relationships between components, there is much
information in KGs, so it is challenging for young engineers to extract and
understand sub-graphs from the KG. On the other hand, there is increasing
interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for
knowledge management. However, when using the current Graph RAG framework with
an existing knowledge graph for automobile failures, several issues arise
because it is difficult to generate executable queries for a knowledge graph
database which is not constructed by LLMs. To address this, we focused on
optimizing the Graph RAG pipeline for existing knowledge graphs. Using an
original Q&A dataset, the ROUGE F1 score of the sentences generated by the
proposed method showed an average improvement of 157.6% compared to the current
method. This highlights the effectiveness of the proposed method for automobile
failure analysis.

摘要：本文提出了一個使用檢索增強生成（RAG）和大型語言模型（LLM）和知識圖譜（KG）的汽車故障分析知識管理系統。在汽車產業中，有越來越多的需求，將故障分析知識從經驗豐富的工程師傳授給年輕的工程師。然而，故障事件是一種連鎖反應中發生的現象，這使得初學者難以分析它們。儘管知識圖譜可以描述語義關係和結構化資訊，並有效地表示故障事件，由於它們有表示元件之間關係的能力，KG 中有許多資訊，因此年輕的工程師很難從 KG 中提取和理解子圖。另一方面，人們越來越有興趣使用 Graph RAG，這是一種結合 LLM 和 KG 進行知識管理的 RAG。然而，當將目前的 Graph RAG 框架與現有的汽車故障知識圖譜一起使用時，會出現幾個問題，因為難以生成針對非 LLM 構建的知識圖譜資料庫的可執行查詢。為了解決這個問題，我們專注於針對現有知識圖譜最佳化 Graph RAG 管道。使用原始問答資料集，所提出方法生成的句子的 ROUGE F1 分數與目前方法相比，平均提升了 157.6%。這突顯了所提出方法對於汽車故障分析的有效性。

##### **Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**
2411.19064v1 by Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai

Large language models (LLMs) have demonstrated exceptional performance across
a wide variety of domains. Nonetheless, generalist LLMs continue to fall short
in reasoning tasks necessitating specialized knowledge. Prior investigations
into specialized LLMs focused on domain-specific training, which entails
substantial efforts in domain data acquisition and model parameter fine-tuning.
To address these challenges, this paper proposes the Way-to-Specialist (WTS)
framework, which synergizes retrieval-augmented generation with knowledge
graphs (KGs) to enhance the specialized capability of LLMs in the absence of
specialized training. In distinction to existing paradigms that merely utilize
external knowledge from general KGs or static domain KGs to prompt LLM for
enhanced domain-specific reasoning, WTS proposes an innovative
"LLM$\circlearrowright$KG" paradigm, which achieves bidirectional enhancement
between specialized LLM and domain knowledge graph (DKG). The proposed paradigm
encompasses two closely coupled components: the DKG-Augmented LLM and the
LLM-Assisted DKG Evolution. The former retrieves question-relevant domain
knowledge from DKG and uses it to prompt LLM to enhance the reasoning
capability for domain-specific tasks; the latter leverages LLM to generate new
domain knowledge from processed tasks and use it to evolve DKG. WTS closes the
loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling
continuous improvement in the domain specialization as it progressively answers
and learns from domain-specific questions. We validate the performance of WTS
on 6 datasets spanning 5 domains. The experimental results show that WTS
surpasses the previous SOTA in 4 specialized domains and achieves a maximum
performance improvement of 11.3%.

摘要：大型語言模型 (LLM) 已在各個領域展現出優異的表現。然而，通才 LLM 在需要專業知識的推理任務中仍表現不佳。先前對專業 LLM 的研究集中在特定領域訓練，這需要大量領域資料取得和模型參數微調。為了應對這些挑戰，本文提出 Way-to-Specialist (WTS) 架構，它將檢索增強生成與知識圖譜 (KG) 結合起來，以提升 LLM 在沒有專業訓練情況下的專業能力。與僅利用來自一般 KG 或靜態領域 KG 的外部知識提示 LLM 以增強特定領域推理的既有範例不同，WTS 提出一個創新的「LLM$\circlearrowright$KG」範例，它在專業 LLM 和領域知識圖譜 (DKG) 之間實現雙向增強。所提出的範例包含兩個緊密結合的組成部分：DKG 增強 LLM 和 LLM 輔助 DKG 演化。前者從 DKG 中檢索與問題相關的領域知識，並使用它提示 LLM 以增強特定領域任務的推理能力；後者利用 LLM 從處理過的任務中產生新的領域知識，並使用它來演化 DKG。WTS 閉合了 DKG 增強 LLM 和 LLM 輔助 DKG 演化之間的迴路，隨著它逐漸回答和學習特定領域問題，能夠持續改善領域專業化。我們在橫跨 5 個領域的 6 個資料集上驗證 WTS 的效能。實驗結果顯示，WTS 在 4 個專業領域中超越先前的 SOTA，並達到 11.3% 的最大效能提升。

##### **EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**
2411.18923v1 by Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem

The SQL-to-text generation task traditionally uses template base, Seq2Seq,
tree-to-sequence, and graph-to-sequence models. Recent models take advantage of
pre-trained generative language models for this task in the Seq2Seq framework.
However, treating SQL as a sequence of inputs to the pre-trained models is not
optimal. In this work, we put forward a new SQL intermediate representation
called EzSQL to align SQL with the natural language text sequence. EzSQL
simplifies the SQL queries and brings them closer to natural language text by
modifying operators and keywords, which can usually be described in natural
language. EzSQL also removes the need for set operators. Our proposed
SQL-to-text generation model uses EzSQL as the input to a pre-trained
generative language model for generating the text descriptions. We demonstrate
that our model is an effective state-of-the-art method to generate text
narrations from SQL queries on the WikiSQL and Spider datasets. We also show
that by generating pretraining data using our SQL-to-text generation model, we
can enhance the performance of Text-to-SQL parsers.

摘要：SQL 轉文字生成任務傳統上使用範本基礎、Seq2Seq、樹到序列和圖到序列模型。最近的模型利用預訓練生成式語言模型來執行 Seq2Seq 架構中的此項任務。然而，將 SQL 視為預訓練模型輸入序列並非最佳解。在此項工作中，我們提出一個名為 EzSQL 的新式 SQL 中間表示，以將 SQL 與自然語言文字序列對齊。EzSQL 簡化 SQL 查詢，並透過修改運算子與關鍵字（通常可以用自然語言描述），讓它們更接近自然語言文字。EzSQL 也消除了對集合運算子的需求。我們提出的 SQL 轉文字生成模型使用 EzSQL 作為輸入，輸入預訓練生成式語言模型以產生文字描述。我們示範我們的模型是一種有效的最新方法，可以用於從 WikiSQL 與 Spider 資料集中的 SQL 查詢產生文字敘述。我們也展示透過使用我們的 SQL 轉文字生成模型產生預訓練資料，我們可以提升文字轉 SQL 解析器的效能。

##### **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**
2412.00103v1 by Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat

Robotic search of people in human-centered environments, including healthcare
settings, is challenging as autonomous robots need to locate people without
complete or any prior knowledge of their schedules, plans or locations.
Furthermore, robots need to be able to adapt to real-time events that can
influence a person's plan in an environment. In this paper, we present
MLLM-Search, a novel zero-shot person search architecture that leverages
multimodal large language models (MLLM) to address the mobile robot problem of
searching for a person under event-driven scenarios with varying user
schedules. Our approach introduces a novel visual prompting method to provide
robots with spatial understanding of the environment by generating a spatially
grounded waypoint map, representing navigable waypoints by a topological graph
and regions by semantic labels. This is incorporated into a MLLM with a region
planner that selects the next search region based on the semantic relevance to
the search scenario, and a waypoint planner which generates a search path by
considering the semantically relevant objects and the local spatial context
through our unique spatial chain-of-thought prompting approach. Extensive 3D
photorealistic experiments were conducted to validate the performance of
MLLM-Search in searching for a person with a changing schedule in different
environments. An ablation study was also conducted to validate the main design
choices of MLLM-Search. Furthermore, a comparison study with state-of-the art
search methods demonstrated that MLLM-Search outperforms existing methods with
respect to search efficiency. Real-world experiments with a mobile robot in a
multi-room floor of a building showed that MLLM-Search was able to generalize
to finding a person in a new unseen environment.

摘要：機器人在以人為中心的環境中搜尋人，包括醫療保健環境，這是一個挑戰，因為自主機器人需要在完全或沒有事先知道他們的時間表、計畫或位置的情況下找到人。此外，機器人需要能夠適應可能影響環境中某人計畫的即時事件。在本文中，我們提出 MLLM-Search，一種新穎的零次人搜尋架構，它利用多模態大型語言模型 (MLLM) 來解決在事件驅動場景中搜尋具有不同使用者時間表的某人的行動機器人問題。我們的做法引入了一種新穎的視覺提示方法，通過生成一個空間接地的航點圖，以拓撲圖表示可導航航點，並通過語義標籤表示區域，為機器人提供環境的空間理解。這被整合到一個具有區域規劃器的 MLLM 中，該區域規劃器根據與搜尋場景的語義相關性選擇下一個搜尋區域，以及一個航點規劃器，該規劃器通過考慮語義相關物件和局部空間背景通過我們獨特的空間思維提示方法生成搜尋路徑。進行了廣泛的 3D 真實感實驗，以驗證 MLLM-Search 在不同環境中搜尋具有變更時間表的人的效能。還進行了一項消融研究，以驗證 MLLM-Search 的主要設計選擇。此外，與最先進的搜尋方法的比較研究表明，MLLM-Search 在搜尋效率方面優於現有方法。在建築物多房間樓層中使用行動機器人進行的真實世界實驗表明，MLLM-Search 能夠概括到在一個新的未見環境中找到某人。

##### **Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models**
2412.03589v1 by Valentina Anita Carriero, Antonia Azzini, Ilaria Baroni, Mario Scrocca, Irene Celino

Procedural Knowledge is the know-how expressed in the form of sequences of
steps needed to perform some tasks. Procedures are usually described by means
of natural language texts, such as recipes or maintenance manuals, possibly
spread across different documents and systems, and their interpretation and
subsequent execution is often left to the reader. Representing such procedures
in a Knowledge Graph (KG) can be the basis to build digital tools to support
those users who need to apply or execute them. In this paper, we leverage Large
Language Model (LLM) capabilities and propose a prompt engineering approach to
extract steps, actions, objects, equipment and temporal information from a
textual procedure, in order to populate a Procedural KG according to a
pre-defined ontology. We evaluate the KG extraction results by means of a user
study, in order to qualitatively and quantitatively assess the perceived
quality and usefulness of the LLM-extracted procedural knowledge. We show that
LLMs can produce outputs of acceptable quality and we assess the subjective
perception of AI by human evaluators.

摘要：程序性知識是以執行某些任務所需的步驟序列形式表達的技術知識。程序通常由自然語言文本描述，例如食譜或維護手冊，可能分散在不同的文件和系統中，其解釋和後續執行通常留給讀者。在知識圖譜 (KG) 中表示此類程序可以成為構建數位工具的基礎，以支援需要應用或執行這些程序的使用者。在本文中，我們利用大型語言模型 (LLM) 功能並提出提示工程方法，從文字程序中提取步驟、動作、物件、設備和時間資訊，以便根據預定義的本体填充程序 KG。我們透過使用者研究評估 KG 提取結果，以定性和定量評估 LLM 提取的程序知識的感知品質和實用性。我們表明 LLM 可以產生可接受品質的輸出，並且我們評估了人類評估者對 AI 的主觀感知。

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

摘要：隨著理解現代系統和演算法中變數之間的因果關係的重要性日益增加，從觀測資料中學習因果關係已成為一種比進行隨機對照試驗更受青睞且更有效率的方法。然而，純粹的觀測資料可能不足以重建真正的因果圖。因此，許多研究人員嘗試利用某種形式的先驗知識來改善因果發現過程。在此背景下，大型語言模型 (LLM) 的強大功能已成為昂貴的先驗專家知識獲取的替代方案。在這項工作中，我們進一步探討了使用 LLM 來增強因果發現方法的可能性，特別關注基於評分的模型，並且我們提出了一個通用框架，不僅可以利用一個 LLM，還可以利用多個 LLM 來擴充發現過程。

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

摘要：<paragraph>建構圖形使用者介面 (GUI) 助理極有望提升人類工作流程的生產力。雖然大多數代理都是基於語言，仰賴具有豐富文字元資訊封閉原始碼 API（例如 HTML 或無障礙樹），但它們在感知使用者介面視覺效果方面顯示出限制，這凸顯了對 GUI 視覺代理的需求。在這項工作中，我們在數位世界中開發了一個視覺語言動作模型，即 ShowUI，其具有以下創新功能：(i) UI 引導視覺代幣選擇，透過將螢幕截圖表述為 UI 連接圖，自適應地識別其冗餘關係，並作為自注意力區塊中代幣選擇的準則，以降低運算成本；(ii) 交錯視覺語言動作串流，靈活地統一 GUI 任務中的各種需求，在導覽中有效管理視覺動作歷程，或配對每個螢幕截圖的多輪查詢動作序列，以提升訓練效率；(iii) 小規模高品質 GUI 指令遵循資料集，透過仔細的資料整理和採用再抽樣策略，來解決顯著的資料類型不平衡。ShowUI 是一個使用 256K 資料的輕量級 2B 模型，具備上述組成部分，在零次方螢幕截圖接地中達到強勁的 75.1% 精確度。其 UI 引導代幣選擇進一步減少了訓練期間 33% 的冗餘視覺代幣，並將效能提升了 1.4 倍。跨網路 Mind2Web、行動 AITW 和線上 MiniWob 環境的導覽實驗進一步強調了我們的模型在推進 GUI 視覺代理方面的有效性和潛力。這些模型可在 https://github.com/showlab/ShowUI 取得。</paragraph>

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

摘要：<paragraph>在現實世界的場景中，從資訊檢索 (IR) 系統取得的大部分資料都是非結構化的。將自然語言句子轉換為結構化的知識圖譜 (KG) 仍然是一項重大的挑戰。已建構的 KG 品質也可能影響某些依賴 KG 的領域，例如 GraphRAG 系統和推薦系統的效能。最近，大型語言模型 (LLM) 已展現出令人印象深刻的能力，能處理廣泛的自然語言處理任務。然而，當利用 LLM 來處理產生結構化 KG 的任務時，仍然存在挑戰。我們已針對現有的 KG 建構方法找出三個限制。(1) 在現實世界的文件中有大量的資訊和過多的雜訊，這可能會導致萃取雜亂的資訊。(2) 原生 LLM 難以從某些特定領域的文件中有效萃取精確的知識。(3) 在將 LLM 直接用作建構 KG 的非監督式方法時，無法忽略幻覺現象。在本文中，我們提出 GraphJudger，這是一個知識圖譜建構架構，用於解決上述挑戰。我們在方法中引入了三個創新的模組，分別是實體為中心的反覆文字去雜訊、知識感知指令微調和圖形判斷。我們尋求利用 LLM 的能力，使其發揮圖形判斷者的功能，這項能力優於其僅作為 KG 建構問題預測者的角色。在兩個一般文字圖形配對資料集和一個特定領域文字圖形配對資料集上進行的實驗顯示，與基線方法相比，其效能優異。我們提出的方法的程式碼可於 https://github.com/hhy-huang/GraphJudger 取得。</paragraph>

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

摘要：許多真實世界的使用者查詢（例如「如何製作蛋炒飯？」）可以受益於能夠產生包含文字步驟和附帶圖片的回應的系統，類似於食譜。專門用於產生交錯文本和圖片的模型面臨確保這些方式內部和之間的一致性的挑戰。為了應對這些挑戰，我們提出了 ISG，一個用於交錯文本和圖片產生的綜合評估架構。ISG 利用場景圖結構來捕捉文本和圖片區塊之間的關係，在四個層級的粒度上評估回應：整體、結構、區塊層級和圖片特定。這種多層評估允許對一致性、連貫性和準確性進行細緻的評估，並提供可解釋的問題解答回饋。結合 ISG，我們引入了基準 ISG-Bench，涵蓋 8 個類別和 21 個子類別中的 1,150 個範例。這個基準資料集包含複雜的語言視覺依賴關係和黃金答案，以有效評估模型在以視覺為中心的任務（例如風格轉移）上的表現，這是當前模型面臨的挑戰領域。使用 ISG-Bench，我們證明了最近的統一視覺語言模型在產生交錯內容上的表現不佳。雖然結合單獨語言和圖片模型的組合方法在整體層級上比統一模型提升了 111%，但它們在區塊和圖片層級上的表現仍然不佳。為了促進後續工作，我們開發了 ISG-Agent，一個採用「計畫執行修正」管線的基準代理，用於呼叫工具，實現了 122% 的效能提升。

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v2 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

摘要：大型語言模型 (LLM) 的最新進展已大幅提升各種自然語言處理任務的表現，但 LLM 仍難以執行知識密集型複雜問題解答，原因在於 LLM 在推理規劃和幻覺問題方面效率不彰。典型的解決方案是採用檢索增強生成 (RAG) 搭配思維鏈 (CoT) 推理，將複雜問題分解成鏈狀子問題，並在每個子問題套用反覆 RAG。然而，先前的研究展現出次佳推理規劃，並忽略從異質來源進行動態知識檢索。在本文中，我們提出 AtomR，一個新穎的異質知識推理架構，在原子層級進行多來源推理。AtomR 從知識的圖形建模中汲取靈感，利用大型語言模型 (LLM) 將複雜問題分解成三種原子知識運算子的組合，大幅提升規劃和執行階段的推理程序。我們也引進 BlendQA，一個新穎的評量基準，專門用於評估複雜異質知識推理。實驗顯示，AtomR 在三個單一來源和兩個多來源推理基準中，表現顯著優於現有技術基線，在 2WikiMultihop 上獲得 9.4% 的顯著效能提升，在 BlendQA 上獲得 9.5% 的提升。

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

摘要：大型語言模型 (LLM) 已知在複雜推理任務（例如數學文字題 (MWP)）中會遇到困難。在本文中，我們展示了來自結構相似的問題的類比如何能改善 LLM 對 MWP 的問題解決能力。具體來說，我們依賴於擷取與給定問題具有類似運算圖形的問題，作為提示中的範例，為生成模型提供正確的推理路徑以供參考。六個數學文字題數據集的實證結果證明了我們提出的方法的有效性，與基線方法相比，平均絕對值提高了 6.7 個百分點。這些結果突出了我們的方法在解決當前 LLM 中的推理挑戰方面的潛力。

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

摘要：知識增強語言模型（KELM）已成為彌合大規模語言模型與特定領域知識差距的有前途的工具。KELM 可以透過利用知識圖譜（KG）來提高事實準確性並減少幻覺。它們經常與適配器模組結合使用，以降低運算負載和災難性遺忘的風險。在本文中，我們對基於適配器的 KELM 方法進行系統性的文獻回顧（SLR）。我們透過定量和定性分析提供該領域既有方法論的結構化概觀，並探討個別方法的優點和潛在缺點。我們表明，一般知識和特定領域的方法已與各種適配器架構和下游任務一起被頻繁探索。我們特別關注熱門的生物醫學領域，在該領域中，我們提供了現有 KELM 的有見地效能比較。我們概述了主要趨勢，並提出了有前途的未來方向。

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

摘要：工業園區對於都市經濟成長至關重要。然而，其發展經常會遇到工業需求與都市服務之間不平衡所產生的挑戰，這凸顯了策略性規劃與營運的需求。本文介紹了 IndustryScopeKG，一個先驅性的、大規模、多模式、多層級的工業園區知識圖譜，它整合了包含街景、公司、社會經濟和地理空間資訊在內的各種都市資料，捕捉工業園區內複雜的關係和語意。除此之外，我們提出了 IndustryScopeGPT 架構，它利用大型語言模型 (LLM) 與蒙地卡羅樹狀搜尋，以增強工具輔助推理和在工業園區規劃和營運 (IPPO) 中的決策制定。我們的研究大幅改善了場地推薦和功能規劃，展示了結合 LLM 和結構化資料集以推進工業園區管理的潛力。這個方法為智慧 IPPO 研究設定了新的基準，並為推進都市產業發展奠定了穩固的基礎。資料集和相關程式碼可在 https://github.com/Tongji-KGLLM/IndustryScope 取得。

##### **One to rule them all: natural language to bind communication, perception and action**
2411.15033v1 by Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone

In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.

摘要：近年来，人机交互领域的研究重点
在于开发能够理解复杂人类指令并在动态和多样化环境中执行任务的机器人。这些系统具有广泛的应用，从个人助理到工业机器人，强调了机器人与人类灵活、自然和安全交互的重要性。本文提出了一种先进的机器人动作规划架构，该架构集成了通信、感知和规划与大型语言模型 (LLM)。我们的系统旨在将以自然语言表达的命令翻译成可执行的机器人动作，并结合环境信息并根据实时反馈动态更新计划。规划器模块是系统的核心，其中嵌入在修改后的 ReAct 框架中的 LLM 用于解释和执行用户命令。通过利用其广泛的预训练知识，LLM 可以有效处理用户请求，而无需引入有关不断变化的环境的新知识。修改后的 ReAct 框架通过提供实时环境感知和物理动作的结果进一步增强了执行空间。通过将鲁棒且动态语义地图表示与控制组件和故障解释相结合，该架构增强了机器人的适应性、任务执行以及与人类用户在共享和动态环境中的无缝协作。通过将连续反馈回路与环境相结合，系统可以动态调整计划以适应意外变化，从而优化机器人执行任务的能力。利用先前的经验数据集，可以提供有关故障的详细反馈。使用有关如何克服问题的建议更新下一个迭代的 LLM 上下文。

##### **Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**
2411.15027v1 by Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone

Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.

摘要：<paragraph>機器人正越來越廣泛地應用於工作場所、醫院和家庭等動態環境中。因此，與機器人的互動必須簡單直觀，機器人的感知能力必須有效適應人類引發的變化。本文提出了一種機器人控制架構，用於解決人機互動中的關鍵挑戰，特別關注機器人狀態表示的動態建立和持續更新。該架構使用大型語言模型整合多種資訊來源，包括自然語言命令、機器人技能表示、感知場景的即時動態語義對應。這使得機器人在複雜的動態環境中能夠靈活適應。傳統的機器人系統通常依賴於靜態的、預先編程的指令和設定，這限制了它們對動態環境和即時協作的適應能力。相比之下，此架構使用 LLM 來詮釋複雜的高層級指令，並制定可行的計畫，以增強人機協作。在系統的核心，感知模組使用 RGB-D 感測器資料產生並持續更新語義場景圖，提供環境的詳細且結構化的表示。採用粒子濾波器以確保在動態的真實世界設定中準確定位物件。規劃模組利用這個最新的語義地圖，將高層級任務分解為子任務，並將它們連結到機器人技能，例如導航、物件操作（例如，取放）和移動（例如，前往）。透過結合即時感知、狀態追蹤和 LLM 驅動的溝通和任務規劃，此架構增強了動態環境中的適應能力、任務效率和人機協作。</paragraph>

##### **GOT4Rec: Graph of Thoughts for Sequential Recommendation**
2411.14922v1 by Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang

With the advancement of large language models (LLMs), researchers have
explored various methods to optimally leverage their comprehension and
generation capabilities in sequential recommendation scenarios. However,
several challenges persist in this endeavor. Firstly, most existing approaches
rely on the input-output prompting paradigm, which can result in irrelevant or
inaccurate responses. Secondly, while there have been attempts to enhance LLMs
using prompting strategies such as chain-of-thought (CoT), these efforts have
not fully harnessed the reasoning abilities of LLMs or effectively captured the
multifaceted information contained within user sequences. To address these
limitations, we propose GOT4Rec, a sequential recommendation method that
utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we
identify and utilize three key types of information within user history
sequences: short-term interests, long-term interests and collaborative
information from other users. Our approach enables LLMs to independently reason
and generate recommendations based on these distinct types of information,
subsequently aggregating the results within the GoT framework to derive the
final recommended items. This method allows LLMs, with enhanced reasoning
capabilities, to more effectively consider the diverse information within user
sequences, resulting in more accurate recommendations and more comprehensive
explanations. Extensive experiments on real-world datasets demonstrate the
effectiveness of GOT4Rec, indicating that it outperforms existing
state-of-the-art baselines. Our code is available at
https://anonymous.4open.science/r/GOT4Rec-ED99.

摘要：隨著大型語言模型 (LLM) 的進步，研究人員已探索各種方法，以最佳方式利用其理解和生成能力在順序推薦場景中。然而，在這個努力中仍存在一些挑戰。首先，大多數現有方法依賴於輸入輸出提示範例，這可能會導致不相關或不準確的回應。其次，雖然有人嘗試使用提示策略（例如思想鏈 (CoT)）來增強 LLM，但這些努力並未充分利用 LLM 的推理能力或有效擷取使用者序列中包含的多方面資訊。為了解決這些限制，我們提出 GOT4Rec，這是一種順序推薦方法，利用了思想圖 (GoT) 提示策略。具體來說，我們在使用者歷史序列中識別並利用三種類型的關鍵資訊：短期興趣、長期興趣和來自其他使用者的協作資訊。我們的方法使 LLM 能夠根據這些不同類型的資訊獨立推理並產生建議，然後在 GoT 框架內匯總結果以推導出最終推薦的項目。這種方法允許 LLM 在增強推理能力的同時，更有效地考慮使用者序列中的不同資訊，從而產生更準確的建議和更全面的說明。在真實世界資料集上的大量實驗證明了 GOT4Rec 的有效性，表明它優於現有的最先進基準。我們的程式碼可在 https://anonymous.4open.science/r/GOT4Rec-ED99 取得。

##### **VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**
2411.14832v1 by Camilo Chacón Sartori, Christian Blum, Filippo Bistaffa

The fast advancement of Large Vision-Language Models (LVLMs) has shown
immense potential. These models are increasingly capable of tackling abstract
visual tasks. Geometric structures, particularly graphs with their inherent
flexibility and complexity, serve as an excellent benchmark for evaluating
these models' predictive capabilities. While human observers can readily
identify subtle visual details and perform accurate analyses, our investigation
reveals that state-of-the-art LVLMs exhibit consistent limitations in specific
visual graph scenarios, especially when confronted with stylistic variations.
In response to these challenges, we introduce VisGraphVar (Visual Graph
Variability), a customizable benchmark generator able to produce graph images
for seven distinct task categories (detection, classification, segmentation,
pattern recognition, link prediction, reasoning, matching), designed to
systematically evaluate the strengths and limitations of individual LVLMs. We
use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing
two distinct prompting strategies, namely zero-shot and chain-of-thought. The
findings demonstrate that variations in visual attributes of images (e.g., node
labeling and layout) and the deliberate inclusion of visual imperfections, such
as overlapping nodes, significantly affect model performance. This research
emphasizes the importance of a comprehensive evaluation across graph-related
tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights
to guide the development of more reliable and robust systems capable of
performing advanced visual graph analysis.

摘要：大型視覺語言模型 (LVLMs) 的快速進步已展現出巨大的潛力。這些模型越來越有能力處理抽象的視覺任務。幾何結構，特別是具有內在靈活性與複雜性的圖形，可用作評估這些模型預測能力的絕佳基準。人類觀察者可以輕易辨識微妙的視覺細節並執行準確的分析，但我們的調查顯示，最先進的 LVLMs 在特定的視覺圖形場景中表現出持續的限制，特別是在面對風格變化時。為了應對這些挑戰，我們引入了 VisGraphVar（視覺圖形變異），這是一個可自訂的基準產生器，能夠產生七個不同任務類別的圖形影像（偵測、分類、分割、模式辨識、連結預測、推理、配對），旨在系統性地評估個別 LVLMs 的優點和限制。我們使用 VisGraphVar 產生 990 個圖形影像並評估六個 LVLMs，採用兩種不同的提示策略，即零次學習和思維鏈。研究結果表明，影像視覺屬性的變化（例如節點標籤和版面）以及視覺瑕疵的故意加入（例如重疊節點）會顯著影響模型效能。這項研究強調了跨圖形相關任務進行全面評估的重要性，而不僅限於推理。VisGraphVar 提供了寶貴的見解，以指導更可靠且強大的系統的開發，這些系統能夠執行進階的視覺圖形分析。

##### **MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**
2411.14721v1 by Jiatong Li, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, Qing Li

Molecule discovery is a pivotal research field, impacting everything from the
medicines we take to the materials we use. Recently, Large Language Models
(LLMs) have been widely adopted in molecule understanding and generation, yet
the alignments between molecules and their corresponding captions remain a
significant challenge. Previous endeavours often treat the molecule as a
general SMILES string or molecular graph, neglecting the fine-grained
alignments between the molecular sub-structures and the descriptive textual
phrases, which are crucial for accurate and explainable predictions. In this
case, we introduce MolReFlect, a novel teacher-student framework designed to
contextually perform the molecule-caption alignments in a fine-grained way. Our
approach initially leverages a larger teacher LLM to label the detailed
alignments by directly extracting critical phrases from molecule captions or
SMILES strings and implying them to corresponding sub-structures or
characteristics. To refine these alignments, we propose In-Context Selective
Reflection, which retrieves previous extraction results as context examples for
teacher LLM to reflect and lets a smaller student LLM select from in-context
reflection and previous extraction results. Finally, we enhance the learning
process of the student LLM through Chain-of-Thought In-Context Molecule Tuning,
integrating the fine-grained alignments and the reasoning processes within the
Chain-of-Thought format. Our experimental results demonstrate that MolReFlect
enables LLMs like Mistral-7B to significantly outperform the previous
baselines, achieving SOTA performance on the ChEBI-20 dataset. This advancement
not only enhances the generative capabilities of LLMs in the molecule-caption
translation task, but also contributes to a more explainable framework.

摘要：分子發現是一個關鍵的研究領域，從我們服用的藥物到我們使用的材料，影響著一切。最近，大型語言模型 (LLM) 已廣泛應用於分子理解和生成中，但分子及其對應標題之間的對齊仍然是一項重大挑戰。先前的努力通常將分子視為一般的 SMILES 字符串或分子圖，忽略了分子子結構和描述性文本短語之間的細粒度對齊，這對於準確且可解釋的預測至關重要。在這種情況下，我們引入了 MolReFlect，這是一個新穎的師生框架，旨在以細粒度的方式對分子標題對齊進行上下文執行。我們的做法最初利用一個更大的教師 LLM 來標記詳細對齊，方法是直接從分子標題或 SMILES 字符串中提取關鍵短語，並將它們暗示為對應的子結構或特徵。為了優化這些對齊，我們提出了上下文選擇性反射，它將以前的提取結果作為上下文範例，供教師 LLM 進行反射，並讓一個較小的學生 LLM 從上下文反射和以前的提取結果中進行選擇。最後，我們通過思想鏈上下文分子調整增強了學生 LLM 的學習過程，將細粒度對齊和推理過程整合到思想鏈格式中。我們的實驗結果表明，MolReFlect 使像 Mistral-7B 這樣的 LLM 能夠顯著優於先前的基準，在 ChEBI-20 數據集上實現了 SOTA 性能。這一進步不僅增強了 LLM 在分子標題翻譯任務中的生成能力，而且還有助於建立一個更具可解釋性的框架。

##### **G-RAG: Knowledge Expansion in Material Science**
2411.14592v2 by Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan

In the field of Material Science, effective information retrieval systems are
essential for facilitating research. Traditional Retrieval-Augmented Generation
(RAG) approaches in Large Language Models (LLMs) often encounter challenges
such as outdated information, hallucinations, limited interpretability due to
context constraints, and inaccurate retrieval. To address these issues, Graph
RAG integrates graph databases to enhance the retrieval process. Our proposed
method processes Material Science documents by extracting key entities
(referred to as MatIDs) from sentences, which are then utilized to query
external Wikipedia knowledge bases (KBs) for additional relevant information.
We implement an agent-based parsing technique to achieve a more detailed
representation of the documents. Our improved version of Graph RAG called G-RAG
further leverages a graph database to capture relationships between these
entities, improving both retrieval accuracy and contextual understanding. This
enhanced approach demonstrates significant improvements in performance for
domains that require precise information retrieval, such as Material Science.

摘要：在材料科學領域，有效的資訊檢索系統對於促進研究至關重要。大型語言模型 (LLM) 中的傳統檢索增強生成 (RAG) 方法通常會遇到挑戰，例如過時的資訊、幻覺、由於上下文限制而導致的可解釋性有限，以及檢索不準確。為了解決這些問題，Graph RAG 整合了圖形資料庫以增強檢索過程。我們提出的方法透過從句子中萃取關鍵實體 (稱為 MatID) 來處理材料科學文件，然後利用這些實體查詢外部的維基百科知識庫 (KB) 以取得其他相關資訊。我們實作了一種基於代理的解析技術，以達成更詳細的文件表示。我們改良版本的 Graph RAG，稱為 G-RAG，進一步利用圖形資料庫來擷取這些實體之間的關係，進而改善檢索準確度和脈絡理解。這種增強的方法在需要精確資訊檢索的領域（例如材料科學）中，展現了顯著的效能提升。

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

摘要：大型語言模型（LLM）徹底改變了基於自然語言處理（NLP）的應用，包括自動文字生成、問題解答、聊天機器人等。然而，它們面臨著一個重大的挑戰：幻覺，模型產生聽起來合理但事實上不正確的回應。這會破壞信任，並限制 LLM 在不同領域的適用性。另一方面，知識圖譜（KG）提供了以實體（節點）及其關係（邊緣）表示的相互連接事實的結構化集合。在最近的研究中，KG 已被用於提供上下文，可以填補 LLM 對某些主題理解的空白，提供了一種有希望的方法來減輕 LLM 中的幻覺，提高它們的可靠性和準確性，同時受益於它們的廣泛適用性。儘管如此，這仍然是一個非常活躍的研究領域，有各種未解決的開放問題。在本文中，我們討論了這些開放挑戰，涵蓋了最先進的數據集和基準，以及知識整合和評估幻覺的方法。在我們的討論中，我們考慮了 LLM 系統中 KG 的當前使用，並確定了這些挑戰中的每一個未來的方向。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖（SKG）在可擴充性、靈活性、情境理解以及處理非結構化或含糊資訊方面面臨挑戰。然而，它們提供正式且結構化的知識，能透過推理和查詢提供高度可解釋且可靠的結果。大型語言模型（LLM）克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想了邏輯增強生成（LAG），它結合了兩個世界的優點。LAG 使用 LLM 作為反應式連續知識圖，它可以按需產生潛在的無限關係和默會知識。SKG 是注入離散啟發式維度（具有明確邏輯和事實邊界）的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。理解 LAG 的特性和限制（目前仍然大多數未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

摘要：有效率地處理和解讀網路資料對於日益複雜的網路操作至關重要。大型語言模型 (LLM) 和檢索增強產生 (RAG) 技術的最新進展已經改善了網路管理中的資料處理。然而，現有的 RAG 方法（例如 VectorRAG 和 GraphRAG）難以應付半結構化技術資料的複雜性和隱含性質，導致時間、成本和檢索效率不彰。本文介紹 FastRAG，一種專為半結構化資料設計的新穎 RAG 方法。FastRAG 使用架構學習和腳本學習來萃取和建構資料，而無需將整個資料來源提交給 LLM。它將文字搜尋與知識圖譜 (KG) 查詢整合，以提高檢索內容豐富資訊的準確性。評估結果證明，FastRAG 提供了準確的問答，同時與 GraphRAG 相比，時間改善了 90%，成本改善了 85%。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v2 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

摘要：數值推理在各種人工智慧應用中至關重要，例如自然語言處理和推薦系統，其中涉及使用實體、關係和屬性值（例如，重量、長度）來推論新的事實關係（例如，尼羅河比亞馬遜河長）。然而，現有方法在建模中遇到兩個關鍵挑戰：（1）語義相關性 - 無法充分捕捉實體、關係和數值屬性之間必要的上下文交互的挑戰，通常導致次優推理；以及（2）語義歧義 - 在數值推理期間準確區分序數關係的難度，這會損害高品質樣本的產生並限制對比學習的有效性。為了應對這些挑戰，我們提出了用於數值推理的知識圖譜嵌入的新型知識感知屬性嵌入模型 (KAAE)。具體來說，為了克服語義相關性的挑戰，我們引入了一個混合專家知識感知 (MoEKA) 編碼器，旨在將實體、關係和數值屬性的語義整合到一個聯合語義空間中。為了應對語義歧義，我們實施了一種新的序數知識對比學習 (OKCL) 策略，該策略利用序數關係從原始數據中生成高品質序數樣本，捕捉對準確數值推理至關重要的細緻語義差異。在三個公開基準數據集上的實驗證明了 KAAE 在各種屬性值分佈中的優異性能。

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

摘要：人工智能系統的發展能夠理解並推理複雜的真實世界場景是一個重大的挑戰。在這項工作中，我們提出了一種新穎的方法來增強和利用 LLM 反應能力，以解決複雜的問題並解釋深層的語境真實世界意義。我們介紹了一種方法和工具，用於建立多模態、知識增強的意義形式化表示，結合了大型語言模型與結構化語義表示的優點。我們的模型從影像輸入開始，利用最先進的大型語言模型來產生自然語言描述。然後將此描述轉換為抽象意義表示 (AMR) 圖形，並使用邏輯設計模式進行形式化和豐富，以及從語言和事實知識庫中衍生的分層語義。然後將結果圖形回饋到 LLM，以擴充 LLM 中由複雜的啟發式學習所啟用的內隱知識，包括語義蘊涵、道德價值、具身認知和隱喻表示。我們的模型透過彌合非結構化語言模型與形式語義結構之間的差距，為解決自然語言理解和推理中的複雜問題開闢了新的途徑。

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

摘要：繼大型Transformer在情境學習中表現出令人印象深刻的能力後，情境模仿學習 (ICIL) 成為了機器人領域中一個有前途的機會。我們引入了即時策略，它僅從一或兩次示範中立即學習新任務（無需進一步訓練），並通過兩個關鍵組成部分實現 ICIL。首先，我們通過圖形表示和模型 ICIL 引入歸納偏差，並將其作為具有學習擴散過程的圖形生成問題，從而能夠對示範、觀察和動作進行結構化推理。其次，我們展示了這種模型可以使用偽示範進行訓練，而偽示範是模擬中產生的任意軌跡，可用作幾乎無限的訓練數據池。模擬和真實實驗表明，即時策略能夠快速學習各種日常機器人任務。我們還展示了它如何作為跨具身和零次傳輸到語言定義任務的基礎。代碼和影片可在 https://www.robot-learning.uk/instant-policy 取得。

##### **Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**
2411.12493v2 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

摘要：本文介紹了語義傳播圖神經網路 (SProp GNN)，這是一種機器學習情緒分析 (SA) 架構，專門依賴句法結構和詞彙層級的情緒線索來預測文字中的情緒。透過在語義上讓模型對特定字詞的資訊視而不見，它能有效消除政治或性別偏見等偏誤，這些偏誤一直困擾著先前的機器學習式 SA 系統。SProp GNN 在兩項不同的預測任務和兩種語言上的表現都優於基於詞彙庫的替代方案，例如 VADER 和 EmoAtlas。此外，它在大幅減少情緒預測任務中的偏誤同時，也接近了基於轉換器的模型的準確度。透過提供更好的可解釋性並減少偏誤，SProp GNN 搭起了可詮釋詞彙方法與強大但經常不透明的深度學習模型之間的方法論鴻溝，提供了一個強健的工具，可以透過文字理解人類行為，進行公平且有效的分析。

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

摘要：捕捉近乎實時的最新資訊，並利用它來擴充現有的大型語言模型 (LLM)，對於產生即時、有根據且可靠的輸出至關重要。當 LLM 被用於快速演化的領域中的訊息任務時，這個問題會變得特別具有挑戰性，例如與涉及實體的近期或正在發生的事件相關的網路搜尋，在這種情況下，產生時間相關的回應需要取得最新的新聞來源。然而，LLM 的參數記憶體建模的資訊經常過時，而原型檢索系統的網路結果可能無法捕捉最新的相關資訊，並且難以處理演化中的新聞中的相互矛盾的報導。為了應對這個挑戰，我們提出了 NEON 框架，旨在萃取新興實體互動（例如事件或活動），如新聞文章中所描述的。NEON 建構了一個以實體為中心的帶時間戳記的知識圖譜，用來捕捉此類互動，從而促進與新聞事件相關的增強式問答能力。我們的框架透過將開放資訊萃取 (openIE) 風格元組整合到 LLM 中，以啟用情境內檢索增強式產生，進而創新。當處理時間、以實體為中心的搜尋查詢時，這種整合顯示出問答效能的顯著提升。透過 NEON，LLM 可以提供更準確、可靠且最新的回應。

##### **GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**
2411.14479v1 by Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu

Large language models (LLMs) have demonstrated impressive success in a wide
range of natural language processing (NLP) tasks due to their extensive general
knowledge of the world. Recent works discovered that the performance of LLMs is
heavily dependent on the input prompt. However, prompt engineering is usually
done manually in a trial-and-error fashion, which can be labor-intensive and
challenging in order to find the optimal prompts. To address these problems and
unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic
framework for prompt optimization, namely GRL-Prompt, which aims to
automatically construct optimal prompts via reinforcement learning (RL) in an
end-to-end manner. To provide structured action/state representation for
optimizing prompts, we construct a knowledge graph (KG) that better encodes the
correlation between the user query and candidate in-context examples.
Furthermore, a policy network is formulated to generate the optimal action by
selecting a set of in-context examples in a rewardable order to construct the
prompt. Additionally, the embedding-based reward shaping is utilized to
stabilize the RL training process. The experimental results show that
GRL-Prompt outperforms recent state-of-the-art methods, achieving an average
increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in
BLEU.

摘要：大型語言模型 (LLM) 在廣泛的自然語言處理 (NLP) 任務中展現出令人印象深刻的成功，這歸功於它們對世界的廣泛一般知識。最近的研究發現，LLM 的效能高度依賴於輸入提示。然而，提示工程通常以試錯的方式手動完成，這在尋找最佳提示時可能會耗費大量人力且具有挑戰性。為了解決這些問題並發揮 LLM 的最大潛力，我們提出了一個新的 LLM 不可知框架，用於提示最佳化，即 GRL-Prompt，其旨在透過強化學習 (RL) 以端到端的方式自動建構最佳提示。為了提供結構化的動作/狀態表示以最佳化提示，我們建構了一個知識圖譜 (KG)，它能更好地編碼使用者查詢與候選情境範例之間的關聯性。此外，我們制定了一個策略網路，透過以可獎勵的順序選擇一組情境範例來建構提示，以產生最佳動作。此外，我們利用基於嵌入的獎勵塑造來穩定 RL 訓練過程。實驗結果顯示，GRL-Prompt 優於最近的最新方法，在 ROUGE-1 中平均增加 0.10，在 ROUGE-2 中增加 0.07，在 ROUGE-L 中增加 0.07，在 BLEU 中增加 0.05。

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

摘要：網路多模態環境中的毒性辨識，由於模態間（例如文字和視覺）的脈絡關聯複雜，因此仍是一項具有挑戰性的任務。在本文中，我們提出一個新穎的架構，整合來自大型視覺語言模型 (LVLMs) 的知識蒸餾 (KD) 和知識注入，以增強仇恨迷因中毒性偵測的效能。我們的做法從 ConceptNet（一個大型常識知識圖譜 (KG)）中萃取子知識圖，並注入到一個緊湊的 VLM 架構中。標題和迷因中具有毒性的詞彙之間的關係脈絡，以及迷因中的視覺概念，增強了模型的推理能力。我們在兩個仇恨言論基準資料集上進行的研究的實驗結果，證明了在 AU-ROC、F1 和召回率方面，我們的做法優於最先進的基準，分別提升了 1.1%、7% 和 35%。鑑於毒性偵測任務的脈絡複雜性，我們的做法展示了從明確（例如 KG）和隱含（例如 LVLMs）脈絡線索中學習，並透過混合神經符號方法整合起來的重要性。這對於真實世界的應用至關重要，在這些應用中，準確且可擴充的毒性內容辨識對於創造更安全的網路環境至關重要。

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

摘要：強化學習 (RL) 是一種有希望的方法，可以學習未知動態系統的最佳控制策略。特別是，基於高階規範（例如用線性時序邏輯 (LTL) 等時序語言表達的規範）為安全關鍵系統合成控制器，這在控制系統研究中是一個重大挑戰。目前的基於 RL 的 LTL 任務方法通常僅提供漸近保證，這在學習階段沒有提供暫態效能的見解。在執行 RL 演算法時，如果我們停止學習，評估我們距離達成最佳行為有多近至關重要。在本文中，我們提出了第一個無遺憾線上演算法，用於學習一個控制器，該控制器解決了馬可夫決策過程 (MDP) 上的一般類別 LTL 規範，其中包含有限的狀態和動作集合。我們首先提出一個無遺憾學習演算法來解決無限時域到達避免問題。對於一般 LTL 規範，我們表明當圖形結構已知時，合成問題可以簡化為到達避免問題。此外，我們提供了一個演算法來學習圖形結構，假設知道最小轉移機率，它獨立於主要的無遺憾演算法運作。

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

摘要：<paragraph>在开放世界环境中部署机器人涉及复杂的任务，其特点是序列长、交互丰富，需要在不同且复杂的场景中高效地转移机器人技能。为了应对这一挑战，我们提出一个基于知识图谱的技能库框架，它赋予机器人高级技能意识和空间语义理解。该框架通过构建“任务图”和“场景图”来分层组织操作知识，分别表示任务和场景语义信息。我们引入一个“状态图”来促进高级任务规划和低级场景信息之间的交互。此外，我们提出了一个操作技能的分层转移框架。在任务层面，该框架在一个四阶段提示范式中集成了上下文学习和思想链提示，利用大语言模型 (LLM) 的推理和泛化能力来实现任务级子任务序列转移。在运动层面，使用 A* 算法和技能库开发了一种自适应轨迹转移方法，实现运动级自适应轨迹转移。在物理层面，我们引入了一种基于触觉感知的自适应轮廓提取和姿态感知方法。该方法从视觉触觉纹理数据中动态获取高精度的轮廓和姿态信息，并调整转移的技能，例如接触位置和姿态，以确保在新的环境中有效。实验结果验证了所提出方法的有效性。项目网站：https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

摘要：<paragraph>在本文中，我們提出了一種方法，透過將知識圖譜 (KG) 作為附加方式納入大型語言模型 (LLM)，以減少幻覺。我們的做法包括將輸入文字轉換成一組 KG 嵌入，並使用適配器將這些嵌入整合到語言模型空間，而無需依賴外部檢索程序。
為了促進這一點，我們建立了 WikiEntities，這是一個包含超過 300 萬個維基百科文字的資料集，其中附有來自 Wikidata 的實體註解，以及它們來自 PyTorch-BigGraph 的對應嵌入。此資料集作為訓練實體連結模型和使用專門適配器將所述方法調整到各種 LLM 的寶貴資源。
我們的做法不需要微調語言模型本身；相反，我們只訓練適配器。這確保了模型在其他任務上的效能不受影響。我們使用此資料集訓練了 Mistral 7B、LLaMA 2-7B (聊天) 和 LLaMA 3-8B (指令) 模型的適配器，並證明了我們的做法改善了 HaluEval、真假基準和 FEVER 資料集的效能。結果表明，將 KG 作為一種新方式納入可以有效減少幻覺，並提高語言模型的事實準確性，而無需外部檢索。</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

摘要：本文建立在我们先前关于协调多项式网络 (RPN) 的工作之上。最初的 RPN 模型是在输入数据独立性的假设下设计的，假定数据批次中各个实例之间的独立性以及每个数据实例中的属性之间的独立性。然而，对于涉及复杂相互依赖数据（例如语言、图像、时间序列和图形）的功能学习任务，这种假设通常被证明是无效的。忽略此类数据相互依赖性不可避免地会导致性能显着下降。
为了克服这些限制，我们在本文中引入了新的协调多项式网络（版本 2），即 RPN 2。通过结合数据和结构相互依赖函数，RPN 2 通过其架构中的新组件函数明确地对数据相互依赖性进行建模。
这种增强不仅显着提高了 RPN 2 的学习性能，而且还大幅扩展了其统一潜力，使其能够在其规范表示中包含更广泛的当代主干模型。这些主干包括但不限于卷积神经网络 (CNN)、循环神经网络 (RNN)、图神经网络 (GNN) 和 Transformer。我们的分析表明，这些主干模型之间的根本区别主要源于它们定义相互依赖函数的不同方法。此外，这种统一表示为设计创新架构开辟了新的机会，这些架构有可能超越这些主干的性能。

##### **LLaSA: Large Language and Structured Data Assistant**
2411.14460v1 by Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu

Structured data, such as tables, graphs, and databases, play a critical role
in plentiful NLP tasks such as question answering and dialogue system.
Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)
have been introduced as an additional modality into the input of Large Language
Models (LLMs) to improve their performance on Structured Knowledge Grounding
(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:
(1) They employ diverse GNNs to model varying types of structured data,
rendering them unable to uniformly process various forms of structured data.
(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs
from fully aligning with the textual space and limits their adaptability to
other LLMs. To address these issues, we propose \textbf{L}arge
\textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a
general framework for enhancing LLMs' ability to handle structured data.
Specifically, we represent various types of structured data in a unified
hypergraph format, and use self-supervised learning to pretrain a hypergraph
encoder, and a G-Former compressing encoded hypergraph representations with
cross-attention. The compressed hypergraph representations are appended to the
serialized inputs during training and inference stages of LLMs. Experimental
results on multiple SKG tasks show that our pretrained hypergraph encoder can
adapt to various LLMs and enhance their ability to process different types of
structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous
SOTA method using full parameters tuning.

摘要：<paragraph>結構化資料，例如表格、圖表和資料庫，在豐富的 NLP 任務中扮演著至關重要的角色，例如問答和對話系統。
最近，受到視覺語言模型的啟發，圖形中立網路 (GNN) 已被引入大型語言模型 (LLM) 的輸入中作為一種額外的模式，以提升其在結構化知識基礎 (SKG) 任務上的表現。然而，這些 GNN 增強的 LLM 具有以下限制：
(1) 它們使用不同的 GNN 來建模各種結構化資料類型，導致它們無法統一處理各種形式的結構化資料。
(2) GNN 的預訓練與特定的 LLM 結合在一起，這會阻止 GNN 與文本空間完全對齊，並限制其適應其他 LLM。為了解決這些問題，我們提出了**L**arge **L**anguage and **S**tructured Data **A**ssistant (LLaSA)，一個用於增強 LLM 處理結構化資料能力的通用框架。
具體來說，我們以統一的超圖格式表示各種結構化資料類型，並使用自我監督學習來預訓練超圖編碼器，以及使用跨注意力壓縮編碼超圖表示的 G-Former。壓縮的超圖表示會附加到 LLM 的訓練和推論階段的序列化輸入中。多個 SKG 任務的實驗結果表明，我們預訓練的超圖編碼器可以適應各種 LLM，並增強其處理不同類型結構化資料的能力。此外，LLaSA 使用 LoRA 微調，優於使用全參數微調的先前 SOTA 方法。</paragraph>

##### **Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**
2411.14459v1 by Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew

Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations through dynamically capturing user preferences in interactive
conversations. Conventional CRSs often extract user preferences as hidden
representations, which are criticized for their lack of interpretability. This
diminishes the transparency and trustworthiness of the recommendation process.
Recent works have explored combining the impressive capabilities of Large
Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs
(KGs) to generate human-understandable recommendation explanations. Despite
these efforts, the integration of LLMs and KGs for CRSs remains challenging due
to the modality gap between unstructured dialogues and structured KGs.
Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for
analyzing user preferences, which require domain-specific knowledge. In this
paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and
KGs to unveil user preferences, enhancing the performance and explainability of
existing CRSs. To address integration challenges, COMPASS employs a two-stage
training approach: first, it bridges the gap between the structured KG and
natural language through an innovative graph entity captioning pre-training
mechanism. This enables the LLM to transform KG entities into concise natural
language descriptions, allowing them to comprehend domain-specific knowledge.
Following, COMPASS optimizes user preference modeling via knowledge-aware
instruction fine-tuning, where the LLM learns to reason and summarize user
preferences from both dialogue histories and KG-augmented context. This enables
COMPASS to perform knowledge-aware reasoning and generate comprehensive and
interpretable user preferences that can seamlessly integrate with existing CRS
models for improving recommendation performance and explainability.

摘要：對話式推薦系統 (CRS) 旨在透過動態捕捉互動對話中的使用者偏好，提供個人化推薦。傳統的 CRS 通常會將使用者偏好擷取為隱藏式表徵，而其缺點在於缺乏可解釋性，這降低了推薦程式的透明度和可信度。最近的研究探討將大型語言模型 (LLM) 的強大功能與知識圖譜 (KG) 的特定領域知識結合，以產生人類可以理解的推薦說明。儘管有這些努力，由於非結構化對話和結構化 KG 之間的模式差異，LLM 和 KG 在 CRS 中的整合仍然具有挑戰性。此外，針對大型語料庫預先訓練的 LLM 可能不適合分析使用者偏好，因為這需要特定領域的知識。在本文中，我們提出 COMPASS，這是一個即插即用的架構，它協同運用 LLM 和 KG 來揭示使用者偏好，增強現有 CRS 的效能和可解釋性。為了應對整合挑戰，COMPASS 採用了兩階段的訓練方法：首先，它透過創新的圖形實體標題預訓練機制，彌合結構化 KG 和自然語言之間的差距。這讓 LLM 能夠將 KG 實體轉換為簡潔的自然語言描述，讓它們能夠理解特定領域的知識。接下來，COMPASS 透過知識感知指令微調來最佳化使用者偏好建模，其中 LLM 學習從對話記錄和 KG 擴充的內容中推論和總結使用者偏好。這讓 COMPASS 能夠執行知識感知推理，並產生全面且可解釋的使用者偏好，這些偏好可以無縫整合到現有的 CRS 模型中，以改善推薦效能和可解釋性。

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

摘要：隨著大型語言模型 (LLM) 在因果發現中作為人類領域專家的替代品使用日益增加，這凸顯了最佳模型選擇的需求。本文提出了第一份流行 LLM 的幻覺調查以進行因果發現。我們表明在因果發現中使用 LLM 時存在幻覺，因此 LLM 的選擇很重要。我們建議使用檢索強化生成 (RAG) 來減少在有品質資料時產生的幻覺。此外，我們引入了一種新的方法，在辯論中使用多個 LLM 和仲裁者來審核因果圖中的邊緣，與 RAG 相比，幻覺減少了許多。

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

摘要：視覺語言模型 (VLM) 的最新進展為機器人任務規劃提供了潛力，但由於 VLM 傾向於生成不正確的動作序列，因此仍存在挑戰。為了解決這些限制，我們提出了 VeriGraph，這是一個新穎的架構，它整合了 VLM 以進行機器人規劃，同時驗證動作的可行性。VeriGraph 使用場景圖作為中間表示，擷取關鍵物件和空間關係以改善計畫驗證和精煉。系統從輸入影像中生成場景圖，並使用它來反覆檢查和修正由基於 LLM 的任務規劃器產生的動作序列，確保遵守約束且動作可執行。我們的做法大幅提高了在各種操作場景中的任務完成率，在基於語言的任務中優於基線方法 58%，在基於影像的任務中優於 30%。

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v2 by Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

摘要：事件因果關係識別 (ECI) 已成為自然語言處理 (NLP) 中一項至關重要的任務，旨在從文本資料中自動萃取因果關係。在此調查中，我們系統性地探討 ECI 的基礎原理、技術架構和挑戰，提供一個全面的分類法來分類和釐清當前的研究方法，以及對現有模型的量化評估。我們首先為 ECI 建立一個概念框架，概述關鍵定義、問題表述和評估標準。我們的分類法根據句子層級 (SECI) 和文件層級 (DECI) 事件因果關係識別這兩個主要任務，對 ECI 方法進行分類。對於 SECI，我們檢視基於特徵模式的比對、深度語意編碼、因果知識預訓練和基於提示的微調，以及外部知識增強方法。對於 DECI，我們強調以事件圖推論和基於提示的技術為重點的方法，以解決跨句子因果推論的複雜性。此外，我們分析每種方法的優點、限制和開放性挑戰。我們進一步對各種 ECI 方法在兩個基準資料集上進行廣泛的量化評估。最後，我們探討未來的研究方向，強調有希望克服當前限制和擴展 ECI 應用程式的途徑。

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

摘要：<paragraph>產生準確的程式碼審查評論仍然是一個重大挑戰，因為任務輸出的本質上是多樣且非獨特的。在程式設計和自然語言資料上進行預訓練的大型語言模型往往在以程式碼為導向的任務中表現良好。然而，由於其對環境的影響和專案特定的一般化問題，大規模預訓練並非總是可行的。在這項工作中，我們首先在參數有效、量化的低秩 (QLoRA) 方式中微調開源大型語言模型 (LLM)，在消費級硬體上改善審查評論的產生。最近的研究證明了在提示中增加語義元資料資訊以提升其他與程式碼相關任務中效能的功效。為了在程式碼審查活動中探索這一點，我們也提示專有的、閉源 LLM，使用函數呼叫圖和程式碼摘要來增加輸入程式碼修補程式。我們的兩種策略都改善了審查評論產生的效能，在 GPT-3.5 模型上使用函數呼叫圖增加的少量提示，在 CodeReviewer 資料集上超越了預訓練基準，BLEU-4 分數提高了約 90%。此外，少量提示的 Gemini-1.0 Pro、QLoRA 微調的 Code Llama 和 Llama 3.1 模型在此任務上達到了有競爭力的結果（效能提升範圍為 25% 至 83%）。額外的使用者評估研究進一步驗證了我們的實驗結果，反映了實際開發人員對 LLM 產生的程式碼審查評論的看法，這些看法基於相關的定性指標。</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

摘要：本文提出 HistoLens，一個基於大型語言模型 (LLM) 的多層分析架構，用於歷史文本。使用重要的西漢王朝文本「鹽鐵論」作為個案研究，我們展示了該架構在歷史研究和教育中的潛在應用。HistoLens 整合了 NLP 技術（尤其是 LLM），包括命名實體識別、知識圖譜建構和地理資訊視覺化。本文展示了 HistoLens 如何透過多維度、視覺化和量化方法探索「鹽鐵論」中的西漢文化，特別關注儒家和法家思想對政治、經濟、軍事和種族的影響。我們還展示了 HistoLens 如何建構一個使用 LLM 的機器教學場景，以進行可解釋分析，這是基於 LLM 協助提取的儒家和法家思想資料集。這種方法為研究「鹽鐵論」等歷史文本提供了新穎且多樣化的觀點，並為歷史教育提供了新的輔助工具。該架構旨在為歷史學家和學習者提供 LLM 協助的工具，以利於深入、多層次地分析歷史文本，並促進歷史教育的創新。

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

摘要：大型語言模型承諾大幅加速關鍵知識圖譜和本体工程任務，包括本体建模、擴充、修改、填充、比對以及實體消歧。我們將 LLM 為基礎的知識圖譜和本体工程規劃為一個新興的研究領域，並主張模組化本体方法將至關重要。

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, András Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

摘要：制定一個參數化問題類別的有效約束模型對於隨後求解該類別的實例的效率至關重要。事先很難知道一組候選模型中哪一個在實務上表現最佳。本文提出一個系統，採用圖形重寫來自動重新制定輸入模型以改善效能。透過將我們的工作置於 Essence 抽象約束規範語言中，我們可以使用其高層級變數類型中的結構來直接觸發重寫。我們透過以 Graph Programs 2 語言表示的重寫規則來實作我們的系統，應用於輸入規範的抽象語法樹。我們展示如何自動將重新制定問題的解法轉換為原始問題的解法，以進行驗證和呈現。我們透過詳細的個案研究來展示我們系統的效能。

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

摘要：大型語言模型 (LLM) 正在革新生成式人工智慧 (GenAI) 的領域，創新的 LLM 支持解決方案迅速湧現。然而，當應用於資料庫技術，特別是圖形資料庫和知識圖譜 (KG) 的查詢產生時，LLM 仍然面臨重大挑戰。雖然存在針對結構化查詢語言 (SQL) 的 LLM 驅動查詢產生的研究，但圖形資料庫的類似系統仍未充分發展。本文提出了一項比較研究，以解決使用開放式 LLM 產生 Cypher 查詢的挑戰，Cypher 查詢是一種用於與圖形資料庫互動的強大語言。我們使用設計的少量學習提示和由思想鏈 (CoT) 推理支持的檢索擴充生成 (RAG) 嚴格評估了多個 LLM 代理（OpenAI ChatGPT 4o、Claude Sonnet 3.5、Google Gemini Pro 1.5 和本地部署的 Llama 3.1 8B）。我們對查詢產生準確性的實證分析表明，Claude Sonnet 3.5 在這個特定領域優於其同類產品。此外，我們重點介紹了有希望的未來研究方向，以解決已識別的限制並推進 LLM 驅動的圖形資料庫查詢產生。

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

摘要：大型語言模型 (LLM) 近來在廣泛的應用中備受關注。在透過大量資料集進行預訓練期間，此類模型會隱含地將訓練資料集的事實知識記憶在其隱藏參數中。然而，隱含在參數中的知識通常會因為缺乏常識推理而導致下游應用無法有效使用。在本文中，我們介紹了一個通用架構，允許在 LLM 的協助下建立知識庫，專門用於處理網路新聞。此架構將基於規則的新聞資訊萃取器 (NewsIE) 套用到新聞項目，以萃取其關係元組（稱為知識庫），然後將其與 LLM 取得的新聞項目的隱含知識事實進行圖形卷積，以進行分類。它包含兩個輕量級元件：1) NewsIE：用於萃取每個新聞項目的結構化資訊，以關係元組的形式呈現；2) BERTGraph：用於將 NewsIE 萃取的關係元組與隱含知識事實進行圖形卷積。我們已在不同的與新聞相關的資料集下評估我們的架構，用於新聞類別分類，並獲得有希望的實驗結果。

