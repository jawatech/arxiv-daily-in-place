
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-17**|**How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs**|Guhao Feng et.al.|[2410.13857v1](http://arxiv.org/abs/2410.13857v1)|null|
|**2024-10-17**|**Can MLLMs Understand the Deep Implication Behind Chinese Images?**|Chenhao Zhang et.al.|[2410.13854v1](http://arxiv.org/abs/2410.13854v1)|null|
|**2024-10-17**|**Retrospective Learning from Interactions**|Zizhao Chen et.al.|[2410.13852v1](http://arxiv.org/abs/2410.13852v1)|null|
|**2024-10-17**|**Influence Functions for Scalable Data Attribution in Diffusion Models**|Bruno Mlodozeniec et.al.|[2410.13850v1](http://arxiv.org/abs/2410.13850v1)|null|
|**2024-10-17**|**Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation**|Chengyue Wu et.al.|[2410.13848v1](http://arxiv.org/abs/2410.13848v1)|null|
|**2024-10-17**|**SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction**|Xuan Zhang et.al.|[2410.13846v1](http://arxiv.org/abs/2410.13846v1)|null|
|**2024-10-17**|**A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models**|Qiaoyu Tang et.al.|[2410.13841v1](http://arxiv.org/abs/2410.13841v1)|null|
|**2024-10-17**|**Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding**|Tan Dat Nguyen et.al.|[2410.13839v1](http://arxiv.org/abs/2410.13839v1)|null|
|**2024-10-17**|**ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization**|Chen Bo Calvin Zhang et.al.|[2410.13837v1](http://arxiv.org/abs/2410.13837v1)|[link](https://github.com/calvincbzhang/orso)|
|**2024-10-17**|**The Disparate Benefits of Deep Ensembles**|Kajetan Schweighofer et.al.|[2410.13831v1](http://arxiv.org/abs/2410.13831v1)|null|
|**2024-10-17**|**A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement**|Hui Yuan et.al.|[2410.13828v1](http://arxiv.org/abs/2410.13828v1)|null|
|**2024-10-17**|**Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models**|Mazda Moayeri et.al.|[2410.13826v1](http://arxiv.org/abs/2410.13826v1)|null|
|**2024-10-17**|**AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents**|Ke Yang et.al.|[2410.13825v1](http://arxiv.org/abs/2410.13825v1)|null|
|**2024-10-17**|**Harnessing Webpage UIs for Text-Rich Visual Understanding**|Junpeng Liu et.al.|[2410.13824v1](http://arxiv.org/abs/2410.13824v1)|null|
|**2024-10-17**|**Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks**|Clément Playout et.al.|[2410.13822v1](http://arxiv.org/abs/2410.13822v1)|[link](https://github.com/clementpla/multistyle_funduslesionsegmentation)|
|**2024-10-17**|**Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation**|Jean-Pierre Sleiman et.al.|[2410.13817v1](http://arxiv.org/abs/2410.13817v1)|null|
|**2024-10-17**|**De-mark: Watermark Removal in Large Language Models**|Ruibo Chen et.al.|[2410.13808v1](http://arxiv.org/abs/2410.13808v1)|null|
|**2024-10-17**|**A Watermark for Order-Agnostic Language Models**|Ruibo Chen et.al.|[2410.13805v1](http://arxiv.org/abs/2410.13805v1)|null|
|**2024-10-17**|**BenTo: Benchmark Task Reduction with In-Context Transferability**|Hongyu Zhao et.al.|[2410.13804v1](http://arxiv.org/abs/2410.13804v1)|[link](https://github.com/tianyi-lab/bento)|
|**2024-10-17**|**A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities**|Gianluca Apriceno et.al.|[2410.13803v1](http://arxiv.org/abs/2410.13803v1)|[link](https://github.com/ida-fbk/multimodalpattern)|
|**2024-10-17**|**Learning Graph Quantized Tokenizers for Transformers**|Limei Wang et.al.|[2410.13798v1](http://arxiv.org/abs/2410.13798v1)|[link](https://github.com/limei0307/graph-tokenizer)|
|**2024-10-17**|**Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions**|Michael J. Q. Zhang et.al.|[2410.13788v1](http://arxiv.org/abs/2410.13788v1)|null|
|**2024-10-17**|**Looking Inward: Language Models Can Learn About Themselves by Introspection**|Felix J Binder et.al.|[2410.13787v1](http://arxiv.org/abs/2410.13787v1)|[link](https://github.com/felixbinder/introspection_self_prediction)|
|**2024-10-17**|**PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment**|Zekun Moore Wang et.al.|[2410.13785v1](http://arxiv.org/abs/2410.13785v1)|null|
|**2024-10-17**|**Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?**|Idris Abdulmumin et.al.|[2410.13783v1](http://arxiv.org/abs/2410.13783v1)|null|
|**2024-10-17**|**Optimal Quantization for Matrix Multiplication**|Or Ordentlich et.al.|[2410.13780v1](http://arxiv.org/abs/2410.13780v1)|null|
|**2024-10-17**|**The Mystery of the Pathological Path-star Task for Language Models**|Arvid Frydenlund et.al.|[2410.13779v1](http://arxiv.org/abs/2410.13779v1)|null|
|**2024-10-17**|**Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors**|Georgios Chochlakis et.al.|[2410.13776v1](http://arxiv.org/abs/2410.13776v1)|null|
|**2024-10-17**|**Transformer Guided Coevolution: Improved Team Formation in Multiagent Adversarial Games**|Pranav Rajbhandari et.al.|[2410.13769v1](http://arxiv.org/abs/2410.13769v1)|null|
|**2024-10-17**|**Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems**|Alireza Ghafarollahi et.al.|[2410.13768v1](http://arxiv.org/abs/2410.13768v1)|null|
|**2024-10-17**|**Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**|Yu Xia et.al.|[2410.13765v1](http://arxiv.org/abs/2410.13765v1)|null|
|**2024-10-17**|**Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems: Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling Technology**|Raisa Bentay Hossain et.al.|[2410.13762v1](http://arxiv.org/abs/2410.13762v1)|null|
|**2024-10-17**|**MobA: A Two-Level Agent System for Efficient Mobile Task Automation**|Zichen Zhu et.al.|[2410.13757v1](http://arxiv.org/abs/2410.13757v1)|null|
|**2024-10-17**|**CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building**|Walker Byrnes et.al.|[2410.13756v1](http://arxiv.org/abs/2410.13756v1)|null|
|**2024-10-17**|**MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures**|Jinjie Ni et.al.|[2410.13754v1](http://arxiv.org/abs/2410.13754v1)|null|
|**2024-10-17**|**Privacy-Preserving Decentralized AI with Confidential Computing**|Dayeol Lee et.al.|[2410.13752v1](http://arxiv.org/abs/2410.13752v1)|null|
|**2024-10-17**|**LLM-Human Pipeline for Cultural Context Grounding of Conversations**|Rajkumar Pujari et.al.|[2410.13727v1](http://arxiv.org/abs/2410.13727v1)|null|
|**2024-10-17**|**DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation**|Hanbo Cheng et.al.|[2410.13726v1](http://arxiv.org/abs/2410.13726v1)|[link](https://github.com/hanbo-cheng/dawn-pytorch)|
|**2024-10-17**|**Persistent Pre-Training Poisoning of LLMs**|Yiming Zhang et.al.|[2410.13722v1](http://arxiv.org/abs/2410.13722v1)|null|
|**2024-10-17**|**Movie Gen: A Cast of Media Foundation Models**|Adam Polyak et.al.|[2410.13720v1](http://arxiv.org/abs/2410.13720v1)|null|
|**2024-10-17**|**MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems**|Nandan Thakur et.al.|[2410.13716v1](http://arxiv.org/abs/2410.13716v1)|[link](https://github.com/vectara/mirage-bench)|
|**2024-10-17**|**On the Role of Attention Heads in Large Language Model Safety**|Zhenhong Zhou et.al.|[2410.13708v1](http://arxiv.org/abs/2410.13708v1)|null|
|**2024-10-17**|**Disjointness Violations in Wikidata**|Ege Atacan Doğan et.al.|[2410.13707v1](http://arxiv.org/abs/2410.13707v1)|null|
|**2024-10-17**|**Unconstrained Model Merging for Enhanced LLM Reasoning**|Yiming Zhang et.al.|[2410.13699v1](http://arxiv.org/abs/2410.13699v1)|null|
|**2024-10-17**|**Exploring the Design Space of Visual Context Representation in Video MLLMs**|Yifan Du et.al.|[2410.13694v1](http://arxiv.org/abs/2410.13694v1)|[link](https://github.com/rucaibox/opt-visor)|
|**2024-10-17**|**Jailbreaking LLM-Controlled Robots**|Alexander Robey et.al.|[2410.13691v1](http://arxiv.org/abs/2410.13691v1)|null|
|**2024-10-17**|**Pose-Based Sign Language Appearance Transfer**|Amit Moryossef et.al.|[2410.13675v1](http://arxiv.org/abs/2410.13675v1)|[link](https://github.com/sign-language-processing/pose-anonymization)|
|**2024-10-17**|**Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion**|Yijun Liang et.al.|[2410.13674v1](http://arxiv.org/abs/2410.13674v1)|[link](https://github.com/tianyi-lab/DisCL)|
|**2024-10-17**|**HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings**|Varun Gumma et.al.|[2410.13671v1](http://arxiv.org/abs/2410.13671v1)|null|
|**2024-10-17**|**signwriting-evaluation: Effective Sign Language Evaluation via SignWriting**|Amit Moryossef et.al.|[2410.13668v1](http://arxiv.org/abs/2410.13668v1)|[link](https://github.com/sign-language-processing/signwriting-evaluation)|
|**2024-10-17**|**ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization**|Xiutian Zhao et.al.|[2410.13667v1](http://arxiv.org/abs/2410.13667v1)|[link](https://github.com/xiutian/orchid)|
|**2024-10-17**|**VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks**|Shailaja Keyur Sampat et.al.|[2410.13666v1](http://arxiv.org/abs/2410.13666v1)|null|
|**2024-10-17**|**Red and blue language: Word choices in the Trump & Harris 2024 presidential debate**|Philipp Wicke et.al.|[2410.13654v1](http://arxiv.org/abs/2410.13654v1)|null|
|**2024-10-17**|**SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs**|Yuling Gu et.al.|[2410.13648v1](http://arxiv.org/abs/2410.13648v1)|null|
|**2024-10-17**|**Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design**|Chenyu Wang et.al.|[2410.13643v1](http://arxiv.org/abs/2410.13643v1)|[link](https://github.com/chenyuwang-monica/drakes)|
|**2024-10-17**|**An Active Learning Framework for Inclusive Generation by Large Language Models**|Sabit Hassan et.al.|[2410.13641v1](http://arxiv.org/abs/2410.13641v1)|null|
|**2024-10-17**|**Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation**|Yiming Wang et.al.|[2410.13640v1](http://arxiv.org/abs/2410.13640v1)|null|
|**2024-10-17**|**A Comparative Study on Reasoning Patterns of OpenAI's o1 Model**|Siwei Wu et.al.|[2410.13639v1](http://arxiv.org/abs/2410.13639v1)|[link](https://github.com/open-source-o1/o1_reasoning_patterns_study)|
|**2024-10-17**|**Scaling Wearable Foundation Models**|Girish Narayanswamy et.al.|[2410.13638v1](http://arxiv.org/abs/2410.13638v1)|null|
|**2024-10-17**|**Normalizing self-supervised learning for provably reliable Change Point Detection**|Alexandra Bazarova et.al.|[2410.13637v1](http://arxiv.org/abs/2410.13637v1)|null|
|**2024-10-17**|**Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring**|Kristina Telegraph et.al.|[2410.13616v1](http://arxiv.org/abs/2410.13616v1)|null|
|**2024-10-17**|**H2OVL-Mississippi Vision Language Models Technical Report**|Shaikat Galib et.al.|[2410.13611v1](http://arxiv.org/abs/2410.13611v1)|null|
|**2024-10-17**|**MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling**|Yakun Zhu et.al.|[2410.13610v1](http://arxiv.org/abs/2410.13610v1)|null|
|**2024-10-17**|**Large Language Models as Narrative-Driven Recommenders**|Lukas Eberhard et.al.|[2410.13604v1](http://arxiv.org/abs/2410.13604v1)|null|
|**2024-10-17**|**Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model**|Yida Xiong et.al.|[2410.13597v1](http://arxiv.org/abs/2410.13597v1)|null|
|**2024-10-17**|**OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope**|Wei Liu et.al.|[2410.13592v1](http://arxiv.org/abs/2410.13592v1)|null|
|**2024-10-17**|**RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging**|Tobias Czempiel et.al.|[2410.13570v1](http://arxiv.org/abs/2410.13570v1)|null|
|**2024-10-17**|**CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models**|Yujian Zhao et.al.|[2410.13567v1](http://arxiv.org/abs/2410.13567v1)|[link](https://github.com/yjzhao1019/ccup)|
|**2024-10-17**|**Enhancing Fact Retrieval in PLMs through Truthfulness**|Paul Youssef et.al.|[2410.13562v1](http://arxiv.org/abs/2410.13562v1)|null|
|**2024-10-17**|**Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models**|Yuki Hou et.al.|[2410.13553v1](http://arxiv.org/abs/2410.13553v1)|null|
|**2024-10-17**|**Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?**|Che Liu et.al.|[2410.13523v1](http://arxiv.org/abs/2410.13523v1)|null|
|**2024-10-17**|**Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks ?**|Virgile Rennard et.al.|[2410.13517v1](http://arxiv.org/abs/2410.13517v1)|null|
|**2024-10-17**|**GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models**|Aditya Sharma et.al.|[2410.13510v1](http://arxiv.org/abs/2410.13510v1)|null|
|**2024-10-17**|**RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards**|Xinze Li et.al.|[2410.13509v1](http://arxiv.org/abs/2410.13509v1)|[link](https://github.com/openmatch/rag-ddr)|
|**2024-10-17**|**MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs**|Andreas Opedal et.al.|[2410.13502v1](http://arxiv.org/abs/2410.13502v1)|null|
|**2024-10-17**|**Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques**|Rahimanuddin Shaik et.al.|[2410.13498v1](http://arxiv.org/abs/2410.13498v1)|null|
|**2024-10-17**|**Repetition Neurons: How Do Language Models Produce Repetitions?**|Tatsuya Hiraoka et.al.|[2410.13497v1](http://arxiv.org/abs/2410.13497v1)|null|
|**2024-10-17**|**Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes**|Dibyanayan Bandyopadhyay et.al.|[2410.13488v1](http://arxiv.org/abs/2410.13488v1)|null|
|**2024-10-17**|**IterSelectTune: An Iterative Training Framework for Efficient Instruction-Tuning Data Selection**|Jielin Song et.al.|[2410.13464v1](http://arxiv.org/abs/2410.13464v1)|null|
|**2024-10-17**|**Progressive Mixed-Precision Decoding for Efficient LLM Inference**|Hao Mark Chen et.al.|[2410.13461v1](http://arxiv.org/abs/2410.13461v1)|null|
|**2024-10-17**|**Breaking the Manual Annotation Bottleneck: Creating a Comprehensive Legal Case Criticality Dataset through Semi-Automated Labeling**|Ronja Stern et.al.|[2410.13460v1](http://arxiv.org/abs/2410.13460v1)|null|
|**2024-10-17**|**MedINST: Meta Dataset of Biomedical Instructions**|Wenhan Han et.al.|[2410.13458v1](http://arxiv.org/abs/2410.13458v1)|[link](https://github.com/aialt/medinst)|
|**2024-10-17**|**Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland**|Luca Rolshoven et.al.|[2410.13456v1](http://arxiv.org/abs/2410.13456v1)|null|
|**2024-10-17**|**Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR**|Abhishek Gupta et.al.|[2410.13445v1](http://arxiv.org/abs/2410.13445v1)|null|
|**2024-10-17**|**NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task**|Maharaj Brahma et.al.|[2410.13443v1](http://arxiv.org/abs/2410.13443v1)|null|
|**2024-10-17**|**Instruction-Driven Game Engine: A Poker Case Study**|Hongqiu Wu et.al.|[2410.13441v1](http://arxiv.org/abs/2410.13441v1)|null|
|**2024-10-17**|**Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport**|Zhanpeng Wang et.al.|[2410.13431v1](http://arxiv.org/abs/2410.13431v1)|null|
|**2024-10-17**|**Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting**|Mikael Rinkinen et.al.|[2410.13415v1](http://arxiv.org/abs/2410.13415v1)|null|
|**2024-10-17**|**Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models**|Chengyu Du et.al.|[2410.13413v1](http://arxiv.org/abs/2410.13413v1)|null|
|**2024-10-17**|**Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans**|Thanasis Troboukis et.al.|[2410.13400v1](http://arxiv.org/abs/2410.13400v1)|null|
|**2024-10-17**|**Linguistically Grounded Analysis of Language Models using Shapley Head Values**|Marcell Fekete et.al.|[2410.13396v1](http://arxiv.org/abs/2410.13396v1)|null|
|**2024-10-17**|**Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs**|Sumanth Doddapaneni et.al.|[2410.13394v1](http://arxiv.org/abs/2410.13394v1)|[link](https://github.com/ai4bharat/cia)|
|**2024-10-17**|**Metacognitive Monitoring: A Human Ability Beyond Generative Artificial Intelligence**|Markus Huff et.al.|[2410.13392v1](http://arxiv.org/abs/2410.13392v1)|null|
|**2024-10-17**|**Context-aware adaptive personalised recommendation: a meta-hybrid**|Peter Tibensky et.al.|[2410.13374v1](http://arxiv.org/abs/2410.13374v1)|null|
|**2024-10-17**|**MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models**|Donghao Zhou et.al.|[2410.13370v1](http://arxiv.org/abs/2410.13370v1)|null|
|**2024-10-17**|**Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistant**|Haoran Hao et.al.|[2410.13360v1](http://arxiv.org/abs/2410.13360v1)|null|
|**2024-10-17**|**LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights**|Odysseas S. Chlapanis et.al.|[2410.13352v1](http://arxiv.org/abs/2410.13352v1)|null|
|**2024-10-17**|**Representation Learning of Structured Data for Medical Foundation Models**|Vijay Prakash Dwivedi et.al.|[2410.13351v1](http://arxiv.org/abs/2410.13351v1)|null|
|**2024-10-17**|**Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement**|Yuxuan Liu et.al.|[2410.13344v1](http://arxiv.org/abs/2410.13344v1)|null|
|**2024-10-17**|**Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models**|Yu Yuan et.al.|[2410.13343v1](http://arxiv.org/abs/2410.13343v1)|null|

#### Abstracts
##### **How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs**
2410.13857v1 by Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang

Despite the remarkable success of Transformer-based Large Language Models
(LLMs) across various domains, understanding and enhancing their mathematical
capabilities remains a significant challenge. In this paper, we conduct a
rigorous theoretical analysis of LLMs' mathematical abilities, with a specific
focus on their arithmetic performances. We identify numerical precision as a
key factor that influences their effectiveness in mathematical tasks. Our
results show that Transformers operating with low numerical precision fail to
address arithmetic tasks, such as iterated addition and integer multiplication,
unless the model size grows super-polynomially with respect to the input
length. In contrast, Transformers with standard numerical precision can
efficiently handle these tasks with significantly smaller model sizes. We
further support our theoretical findings through empirical experiments that
explore the impact of varying numerical precision on arithmetic tasks,
providing valuable insights for improving the mathematical reasoning
capabilities of LLMs.

摘要：儘管 Transformer 為基礎的大型語言模型 (LLM) 在各個領域都獲得顯著的成功，但了解和提升它們的數學能力仍然是一項重大挑戰。在本文中，我們對 LLM 的數學能力進行嚴謹的理論分析，特別關注它們的算術表現。我們將數值精度確定為影響其在數學任務中有效性的關鍵因素。我們的結果顯示，使用低數值精度的 Transformer 無法解決算術任務，例如反覆加法和整數乘法，除非模型大小相對於輸入長度呈超多項式增長。相反地，具有標準數值精度的 Transformer 可以使用顯著更小的模型大小有效處理這些任務。我們進一步透過實證實驗支持我們的理論發現，探討不同數值精度對算術任務的影響，為提升 LLM 的數學推理能力提供有價值的見解。

##### **Can MLLMs Understand the Deep Implication Behind Chinese Images?**
2410.13854v1 by Chenhao Zhang, Xi Feng, Yuelin Bai, Xinrun Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni

As the capabilities of Multimodal Large Language Models (MLLMs) continue to
improve, the need for higher-order capability evaluation of MLLMs is
increasing. However, there is a lack of work evaluating MLLM for higher-order
perception and understanding of Chinese visual content. To fill the gap, we
introduce the **C**hinese **I**mage **I**mplication understanding
**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception
and understanding capabilities of MLLMs for Chinese images. CII-Bench stands
out in several ways compared to existing benchmarks. Firstly, to ensure the
authenticity of the Chinese context, images in CII-Bench are sourced from the
Chinese Internet and manually reviewed, with corresponding answers also
manually crafted. Additionally, CII-Bench incorporates images that represent
Chinese traditional culture, such as famous Chinese traditional paintings,
which can deeply reflect the model's understanding of Chinese traditional
culture. Through extensive experiments on CII-Bench across multiple MLLMs, we
have made significant findings. Initially, a substantial gap is observed
between the performance of MLLMs and humans on CII-Bench. The highest accuracy
of MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an
impressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional
culture images, suggesting limitations in their ability to understand
high-level semantics and lack a deep knowledge base of Chinese traditional
culture. Finally, it is observed that most models exhibit enhanced accuracy
when image emotion hints are incorporated into the prompts. We believe that
CII-Bench will enable MLLMs to gain a better understanding of Chinese semantics
and Chinese-specific images, advancing the journey towards expert artificial
general intelligence (AGI). Our project is publicly available at
https://cii-bench.github.io/.

摘要：隨著多模態大型語言模型 (MLLM) 的能力持續提升，對 MLLM 進行高階能力評估的需求也與日俱增。然而，目前缺乏針對 MLLM 進行高階感知和理解中文視覺內容的評估工作。為了填補這個缺口，我們推出了 **中**文 **圖**像 **意**涵理解**基**準，**CII-Bench**，旨在評估 MLLM 對中文圖像的高階感知和理解能力。與現有的基準相比，CII-Bench 在幾個方面脫穎而出。首先，為了確保中文語境的真實性，CII-Bench 中的圖像來自於中文網路，並經過人工審查，對應的答案也由人工編寫。此外，CII-Bench 納入了代表中國傳統文化的圖像，例如著名的中國傳統繪畫，這可以深入反映模型對中國傳統文化的理解。透過在多個 MLLM 上對 CII-Bench 進行廣泛的實驗，我們獲得了重要的發現。最初，在 CII-Bench 上觀察到 MLLM 和人類的表現之間存在顯著差距。MLLM 的最高準確度達到 64.4%，而人類準確度的平均值為 78.2%，最高達到令人印象深刻的 81.0%。隨後，MLLM 在中國傳統文化圖像上的表現較差，這表明它們在理解高階語義和缺乏中國傳統文化深厚知識庫方面存在限制。最後，我們觀察到，當將圖像情緒提示納入提示時，大多數模型的準確度都會提升。我們相信 CII-Bench 將使 MLLM 能夠更好地理解中文語義和特定於中文的圖像，推動專家級人工通用智慧 (AGI) 的發展。我們的專案可在 https://cii-bench.github.io/ 公開取得。

##### **Retrospective Learning from Interactions**
2410.13852v1 by Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi

Multi-turn interactions between large language models (LLMs) and users
naturally include implicit feedback signals. If an LLM responds in an
unexpected way to an instruction, the user is likely to signal it by rephrasing
the request, expressing frustration, or pivoting to an alternative task. Such
signals are task-independent and occupy a relatively constrained subspace of
language, allowing the LLM to identify them even if it fails on the actual
task. This creates an avenue for continually learning from interactions without
additional annotations. We introduce ReSpect, a method to learn from such
signals in past interactions via retrospection. We deploy ReSpect in a new
multimodal interaction scenario, where humans instruct an LLM to solve an
abstract reasoning task with a combinatorial solution space. Through thousands
of interactions with humans, we show how ReSpect gradually improves task
completion rate from 31% to 82%, all without any external annotation.

摘要：大型語言模型 (LLM) 和使用者之間的多輪互動
自然會包含隱含的回饋訊號。如果 LLM 對指令的回應出乎意料，使用者可能會透過重新表述請求、表達沮喪或轉向替代任務來發出訊號。此類訊號與任務無關，且佔據語言中相對受限的子空間，即使 LLM 在實際任務中失敗，也能識別這些訊號。這為持續從互動中學習創造了一條途徑，而無需額外的註解。我們引入了 ReSpect，這是一種透過回顧從過去互動中學習此類訊號的方法。我們在新的多模態互動場景中部署了 ReSpect，人類在其中指示 LLM 解決具有組合解決空間的抽象推理任務。透過與人類進行數千次互動，我們展示了 ReSpect 如何逐漸將任務完成率從 31% 提高到 82%，而這一切都不需要任何外部註解。

##### **Influence Functions for Scalable Data Attribution in Diffusion Models**
2410.13850v1 by Bruno Mlodozeniec, Runa Eschenhagen, Juhan Bae, Alexander Immer, David Krueger, Richard Turner

Diffusion models have led to significant advancements in generative
modelling. Yet their widespread adoption poses challenges regarding data
attribution and interpretability. In this paper, we aim to help address such
challenges in diffusion models by developing an \textit{influence functions}
framework. Influence function-based data attribution methods approximate how a
model's output would have changed if some training data were removed. In
supervised learning, this is usually used for predicting how the loss on a
particular example would change. For diffusion models, we focus on predicting
the change in the probability of generating a particular example via several
proxy measurements. We show how to formulate influence functions for such
quantities and how previously proposed methods can be interpreted as particular
design choices in our framework. To ensure scalability of the Hessian
computations in influence functions, we systematically develop K-FAC
approximations based on generalised Gauss-Newton matrices specifically tailored
to diffusion models. We recast previously proposed methods as specific design
choices in our framework and show that our recommended method outperforms
previous data attribution approaches on common evaluations, such as the Linear
Data-modelling Score (LDS) or retraining without top influences, without the
need for method-specific hyperparameter tuning.

摘要：擴散模型在生成式建模中取得了重大進展。然而，它們的廣泛採用對數據歸因和可解釋性提出了挑戰。在本文中，我們旨在通過開發一個「影響函數」框架來幫助解決擴散模型中的此類挑戰。基於影響函數的數據歸因方法近似估計了如果刪除一些訓練數據，模型的輸出將如何改變。在監督式學習中，這通常用於預測特定範例的損失將如何改變。對於擴散模型，我們專注於預測通過多個代理測量生成特定範例的機率的變化。我們展示了如何為此類數量制定影響函數，以及先前提出的方法如何解釋為我們框架中的特定設計選擇。為了確保影響函數中 Hessian 計算的可擴充性，我們系統地開發了基於廣義 Gauss-Newton 矩陣的 K-FAC 近似，專門針對擴散模型進行調整。我們將先前提出的方法重新表述為我們框架中的特定設計選擇，並表明我們推薦的方法在常見評估（例如線性數據建模分數 (LDS) 或在沒有頂層影響的情況下重新訓練）中優於先前的數據歸因方法，而無需特定於方法的超參數調整。

##### **Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation**
2410.13848v1 by Chengyue Wu, Xiaokang Chen, Zhiyu Wu, Yiyang Ma, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan, Ping Luo

In this paper, we introduce Janus, an autoregressive framework that unifies
multimodal understanding and generation. Prior research often relies on a
single visual encoder for both tasks, such as Chameleon. However, due to the
differing levels of information granularity required by multimodal
understanding and generation, this approach can lead to suboptimal performance,
particularly in multimodal understanding. To address this issue, we decouple
visual encoding into separate pathways, while still leveraging a single,
unified transformer architecture for processing. The decoupling not only
alleviates the conflict between the visual encoder's roles in understanding and
generation, but also enhances the framework's flexibility. For instance, both
the multimodal understanding and generation components can independently select
their most suitable encoding methods. Experiments show that Janus surpasses
previous unified model and matches or exceeds the performance of task-specific
models. The simplicity, high flexibility, and effectiveness of Janus make it a
strong candidate for next-generation unified multimodal models.

摘要：在本文中，我們介紹了 Janus，一個統一多模態理解和生成的自動迴歸框架。先前的研究通常依賴於單一的視覺編碼器來執行這兩個任務，例如變色龍。然而，由於多模態理解和生成所需的資訊粒度層級不同，這種方法可能會導致次佳效能，特別是在多模態理解中。為了解決這個問題，我們將視覺編碼解耦成獨立路徑，同時仍然利用單一的統一轉換器架構進行處理。解耦不僅緩解了視覺編碼器在理解和生成中的角色衝突，也增強了框架的靈活性。例如，多模態理解和生成元件都可以獨立選擇最適合它們的編碼方法。實驗顯示，Janus 超越了先前的統一模型，並匹配或超過了特定任務模型的效能。Janus 的簡潔性、高靈活性與有效性，使其成為下一代統一多模態模型的強勁候選者。

##### **SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction**
2410.13846v1 by Xuan Zhang, Cunxiao Du, Chao Du, Tianyu Pang, Wei Gao, Min Lin

Recent advancements in large language models (LLMs) have extended their
capabilities to handle long contexts. However, increasing the number of model
layers and the length of input sequences significantly escalates the memory
required to store key-value (KV) cache, posing challenges for efficient
inference. To mitigate this issue, we present SimLayerKV, a simple yet
effective method that reduces inter-layer KV cache redundancies by selectively
dropping cache in identified lazy layers. Our approach is based on the
observation that certain layers in long-context LLMs exhibit "lazy" behavior,
contributing less to modeling long-range dependencies compared to non-lazy
layers. By analyzing attention weight patterns, we find that the behavior of
these lazy layers is consistent across tokens during generation for a given
input. This insight motivates our SimLayerKV, which identifies lazy layers and
reduces their KV cache accordingly. SimLayerKV is training-free, generalizable,
and can be implemented with only seven lines of code. We conduct extensive
experiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and
Mistral-7B across 16 tasks from the LongBench benchmark. The results
demonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\times$
with only a 1.2% performance drop when combined with 4-bit quantization. Our
code is available at https://github.com/sail-sg/SimLayerKV.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展已將其功能擴展到處理長文脈。然而，增加模型層數和輸入序列的長度會顯著增加儲存鍵值 (KV) 快取所需的記憶體，對有效推論構成挑戰。為了減輕此問題，我們提出了 SimLayerKV，這是一種簡單但有效的方法，透過選擇性地在已識別的惰性層中捨棄快取，來減少層間 KV 快取的冗餘。我們的做法基於以下觀察：長文脈 LLM 中的某些層表現出「惰性」行為，與非惰性層相比，對建模長程依賴關係的貢獻較少。透過分析注意力權重模式，我們發現這些惰性層的行為在給定輸入的產生過程中，在各個符號之間是一致的。此見解激勵了我們的 SimLayerKV，它可以識別惰性層並相應地減少其 KV 快取。SimLayerKV 無需訓練、具有泛化性，且僅需七行程式碼即可實作。我們對三個具代表性的 LLM 進行了廣泛的實驗，例如 LLaMA2-7B、LLaMA3-8B 和 Mistral-7B，涵蓋了 LongBench 基準中的 16 項任務。結果表明，當與 4 位元量化結合時，SimLayerKV 可實現 5 倍的 KV 快取壓縮比，效能下降僅為 1.2%。我們的程式碼可在 https://github.com/sail-sg/SimLayerKV 取得。</paragraph>

##### **A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models**
2410.13841v1 by Qiaoyu Tang, Le Yu, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun

Post-training has emerged as a crucial paradigm for adapting large-scale
pre-trained models to various tasks, whose effects are fully reflected by delta
parameters (i.e., the disparity between post-trained and pre-trained
parameters). While numerous studies have explored delta parameter properties
via operations like pruning, quantization, low-rank approximation, and
extrapolation, a unified framework for systematically examining these
characteristics has been lacking. In this paper, we propose a novel perspective
based on Riemann sum approximation of the loss function to elucidate delta
parameter editing operations. Our analysis categorizes existing methods into
three classes based on their post-editing performance: competitive, decreased,
and improved, explaining how they are expressed by the Riemann sum
approximation term and how they alter the model performance. Extensive
experiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,
and Mistral, corroborate our theoretical findings. Furthermore, we introduce
extensions to existing techniques like DARE and BitDelta, highlighting their
limitations in leveraging the properties of delta parameters and reorganizing
them into general expressions to enhance the applicability and effectiveness of
delta parameter editing in post-trained models.

摘要：後訓練已成為一種關鍵範例，用於將大規模預訓練模型調整為各種任務，其效果完全反映在 delta 參數中（即後訓練和預訓練參數之間的差異）。雖然許多研究已透過剪枝、量化、低階近似和外推等運算探討 delta 參數屬性，但缺乏一個統一的架構來系統地檢驗這些特性。在本文中，我們提出一個基於損失函數的黎曼和近似的新觀點，以闡明 delta 參數編輯運算。我們的分析根據後編輯效能將現有方法分類為三類：競爭、降低和改善，說明它們如何透過黎曼和近似項表達，以及它們如何改變模型效能。針對視覺和語言模型（包括 ViT、LLaMA 3、Qwen 2 和 Mistral）進行的廣泛實驗證實了我們的理論發現。此外，我們對 DARE 和 BitDelta 等現有技術進行了擴充，強調了它們在利用 delta 參數的屬性和將其重新組織為一般表達式方面的限制，以增強後訓練模型中 delta 參數編輯的適用性和有效性。

##### **Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding**
2410.13839v1 by Tan Dat Nguyen, Ji-Hoon Kim, Jeongsoo Choi, Shukjae Choi, Jinseok Park, Younglo Lee, Joon Son Chung

The goal of this paper is to accelerate codec-based speech synthesis systems
with minimum sacrifice to speech quality. We propose an enhanced inference
method that allows for flexible trade-offs between speed and quality during
inference without requiring additional training. Our core idea is to predict
multiple tokens per inference step of the AR module using multiple prediction
heads, resulting in a linear reduction in synthesis time as the number of heads
increases. Furthermore, we introduce a novel speculative decoding technique
that utilises a Viterbi-based algorithm to select the optimal sequence of
generated tokens at each decoding step. In our experiments, we demonstrate that
the time required to predict each token is reduced by a factor of 4 to 5
compared to baseline models, with minimal quality trade-off or even improvement
in terms of speech intelligibility. Audio samples are available at:
multpletokensprediction.github.io/multipletokensprediction.github.io/.

摘要：本文的目標是加速編碼器-解碼器基礎的語音合成系統，並盡量不犧牲語音品質。我們提出了一種增強的推論方法，讓使用者可以在推論過程中靈活地權衡速度與品質，而不需要額外的訓練。我們的核心概念是使用多個預測頭來預測 AR 模組的每個推論步驟的許多個符號，這樣一來，隨著頭的數量增加，合成時間就會線性減少。此外，我們還介紹了一種新穎的推測性解碼技術，它利用基於 Viterbi 的演算法在每個解碼步驟中選擇最佳的已產生符號序列。在我們的實驗中，我們證明了與基準模型相比，預測每個符號所需的時間減少了 4 到 5 倍，而品質的取捨很小，甚至在語音清晰度方面還有所提升。音訊範例可在以下網址取得：multpletokensprediction.github.io/multipletokensprediction.github.io/。

##### **ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization**
2410.13837v1 by Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal

Reward shaping is a critical component in reinforcement learning (RL),
particularly for complex tasks where sparse rewards can hinder learning. While
shaping rewards have been introduced to provide additional guidance, selecting
effective shaping functions remains challenging and computationally expensive.
This paper introduces Online Reward Selection and Policy Optimization (ORSO), a
novel approach that frames shaping reward selection as an online model
selection problem. ORSO employs principled exploration strategies to
automatically identify promising shaping reward functions without human
intervention, balancing exploration and exploitation with provable regret
guarantees. We demonstrate ORSO's effectiveness across various continuous
control tasks using the Isaac Gym simulator. Compared to traditional methods
that fully evaluate each shaping reward function, ORSO significantly improves
sample efficiency, reduces computational time, and consistently identifies
high-quality reward functions that produce policies comparable to those
generated by domain experts through hand-engineered rewards.

摘要：獎勵成形是強化學習 (RL) 中的重要組成部分，特別是對於稀疏獎勵可能會阻礙學習的複雜任務。雖然已引入成形獎勵以提供額外的指導，但選擇有效的成形函數仍然具有挑戰性且在運算上很昂貴。本文介紹了在線獎勵選擇和策略最佳化 (ORSO)，這是一種新穎的方法，將成形獎勵選擇建構為在線模型選擇問題。ORSO 採用原則性的探索策略，在無需人工介入的情況下自動識別有希望的成形獎勵函數，並在可證明後悔的保證下平衡探索和利用。我們使用 Isaac Gym 模擬器展示了 ORSO 在各種連續控制任務中的有效性。與完全評估每個成形獎勵函數的傳統方法相比，ORSO 大幅提升了樣本效率，減少了運算時間，並始終識別出高品質的獎勵函數，這些函數產生的策略可與領域專家透過手工設計的獎勵產生的策略相媲美。

##### **The Disparate Benefits of Deep Ensembles**
2410.13831v1 by Kajetan Schweighofer, Adrian Arnaiz-Rodriguez, Sepp Hochreiter, Nuria Oliver

Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a
simple way to boost predictive performance. However, their impact on
algorithmic fairness is not well understood yet. Algorithmic fairness
investigates how a model's performance varies across different groups,
typically defined by protected attributes such as age, gender, or race. In this
work, we investigate the interplay between the performance gains from Deep
Ensembles and fairness. Our analysis reveals that they unevenly favor different
groups in what we refer to as a disparate benefits effect. We empirically
investigate this effect with Deep Ensembles applied to popular facial analysis
and medical imaging datasets, where protected group attributes are given and
find that it occurs for multiple established group fairness metrics, including
statistical parity and equal opportunity. Furthermore, we identify the
per-group difference in predictive diversity of ensemble members as the
potential cause of the disparate benefits effect. Finally, we evaluate
different approaches to reduce unfairness due to the disparate benefits effect.
Our findings show that post-processing is an effective method to mitigate this
unfairness while preserving the improved performance of Deep Ensembles.

摘要：深度神经網路的集合，深度集合，被廣泛用作提升預測效能的簡單方法。然而，它們對演算法公平性的影響尚未被充分理解。演算法公平性探討模型的效能如何因不同群組而異，這些群組通常由受保護的屬性（例如年齡、性別或種族）定義。在這項工作中，我們探討了深度集合的效能提升與公平性之間的交互作用。我們的分析顯示，它們不均勻地偏好不同群組，我們稱之為不同的好處效應。我們以應用於流行面部分析和醫學影像資料集的深度集合，對此效應進行實證探討，其中提供了受保護群組屬性，並發現它發生在多個已建立的群組公平性指標中，包括統計同等性和機會均等。此外，我們將預測多樣性在集合成員中的群組差異，視為不同的好處效應的潛在原因。最後，我們評估了不同的方法，以減少由於不同的好處效應而導致的不公平性。我們的研究結果表明，後處理是一種有效的方法，可以減輕這種不公平性，同時保留深度集合的效能提升。

##### **A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement**
2410.13828v1 by Hui Yuan, Yifan Zeng, Yue Wu, Huazheng Wang, Mengdi Wang, Liu Leqi

Reinforcement Learning from Human Feedback (RLHF) has become the predominant
approach for language model (LM) alignment. At its core, RLHF uses a
margin-based loss for preference optimization, specifying ideal LM behavior
only by the difference between preferred and dispreferred responses. In this
paper, we identify a common pitfall of margin-based methods -- the
under-specification of ideal LM behavior on preferred and dispreferred
responses individually, which leads to two unintended consequences as the
margin increases: (1) The probability of dispreferred (e.g., unsafe) responses
may increase, resulting in potential safety alignment failures. (2) The
probability of preferred responses may decrease, even when those responses are
ideal. We demystify the reasons behind these problematic behaviors:
margin-based losses couple the change in the preferred probability to the
gradient of the dispreferred one, and vice versa, often preventing the
preferred probability from increasing while the dispreferred one decreases, and
thus causing a synchronized increase or decrease in both probabilities. We term
this effect, inherent in margin-based objectives, gradient entanglement.
Formally, we derive conditions for general margin-based alignment objectives
under which gradient entanglement becomes concerning: the inner product of the
gradients of preferred and dispreferred log-probabilities is large relative to
the individual gradient norms. We theoretically investigate why such inner
products can be large when aligning language models and empirically validate
our findings. Empirical implications of our framework extend to explaining
important differences in the training dynamics of various preference
optimization algorithms, and suggesting potential algorithm designs to mitigate
the under-specification issue of margin-based methods and thereby improving
language model alignment.

摘要：強化學習來自人類回饋 (RLHF) 已成為語言模型 (LM) 校準的主要方法。在核心部分，RLHF 使用基於邊界的損失進行偏好最佳化，僅透過偏好和非偏好回應之間的差異來指定理想的 LM 行為。在本文中，我們辨識出基於邊界方法的常見陷阱，也就是在偏好和非偏好回應中對理想 LM 行為的規格不足，這會隨著邊界增加而導致兩個意外的後果：(1) 非偏好（例如不安全）回應的機率可能會增加，導致潛在的安全校準失敗。(2) 偏好回應的機率可能會降低，即使那些回應是理想的。我們揭開這些問題行為背後的原因：基於邊界的損失將偏好機率的改變與非偏好機率的梯度結合，反之亦然，通常會阻止偏好機率增加，同時非偏好機率降低，從而導致兩個機率同步增加或降低。我們將這種固有於基於邊界的目標函數的效應稱為梯度糾纏。正式來說，我們推導出一般基於邊界的校準目標函數的條件，在該條件下梯度糾纏會令人擔憂：偏好和非偏好對數機率的梯度內積相對於個別梯度範數很大。我們在理論上探討為什麼在校準語言模型時這種內積會很大，並根據經驗驗證我們的發現。我們架構的經驗意義延伸到解釋各種偏好最佳化演算法訓練動態中的重要差異，並建議潛在的演算法設計以減輕基於邊界方法的規格不足問題，從而改善語言模型校準。

##### **Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models**
2410.13826v1 by Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet

With models getting stronger, evaluations have grown more complex, testing
multiple skills in one benchmark and even in the same instance at once.
However, skill-wise performance is obscured when inspecting aggregate accuracy,
under-utilizing the rich signal modern benchmarks contain. We propose an
automatic approach to recover the underlying skills relevant for any evaluation
instance, by way of inspecting model-generated rationales. After validating the
relevance of rationale-parsed skills and inferring skills for $46$k instances
over $12$ benchmarks, we observe many skills to be common across benchmarks,
resulting in the curation of hundreds of skill-slices (i.e. sets of instances
testing a common skill). Inspecting accuracy over these slices yields novel
insights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,
on average, Gemini 1.5 Pro is $18\%$ more accurate in "computing molar mass",
but $19\%$ less accurate in "applying constitutional law", despite the overall
accuracies of the three models differing by a mere $0.4\%$. Furthermore, we
demonstrate the practical utility of our approach by showing that insights
derived from skill slice analysis can generalize to held-out instances: when
routing each instance to the model strongest on the relevant skills, we see a
$3\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and
framework open a new avenue in model evaluation, leveraging skill-specific
analyses to unlock a more granular and actionable understanding of model
capabilities.

摘要：隨著模型越來越強大，評估也變得更加複雜，同時在一個基準和甚至在同一個實例中測試多項技能。
然而，在檢查總體準確性時，技能表現會被模糊化，無法充分利用現代基準所包含的豐富訊號。我們提出了一種自動化方法來恢復與任何評估實例相關的基本技能，方法是檢查模型產生的依據。在驗證了依據解析技能的相關性並推論了超過 12 個基準的 46k 個實例的技能後，我們觀察到許多技能在基準之間是通用的，導致策劃了數百個技能切片（即測試通用技能的實例集）。檢查這些切片上的準確性會產生關於模型權衡的新見解：例如，與 GPT-4o 和 Claude 3.5 Sonnet 相比，平均而言，Gemini 1.5 Pro 在「計算摩爾質量」方面準確度高出 18%，但在「應用憲法」方面準確度低 19%，儘管這三種模型的整體準確度僅相差 0.4%。此外，我們通過展示從技能切片分析中獲得的見解可以推廣到保留實例來證明我們方法的實用性：當將每個實例路由到在相關技能上最強大的模型時，我們看到在我們的 12 個資料集語料庫中準確度提高了 3%。我們的技能切片和框架為模型評估開闢了一條新途徑，利用特定技能分析來解鎖對模型能力的更精細和可操作的理解。

##### **AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents**
2410.13825v1 by Ke Yang, Yao Liu, Sapana Chaudhary, Rasool Fakoor, Pratik Chaudhari, George Karypis, Huzefa Rangwala

Autonomy via agents using large language models (LLMs) for personalized,
standardized tasks boosts human efficiency. Automating web tasks (like booking
hotels within a budget) is increasingly sought after. Fulfilling practical
needs, the web agent also serves as an important proof-of-concept example for
various agent grounding scenarios, with its success promising advancements in
many future applications. Prior research often handcrafts web agent strategies
(e.g., prompting templates, multi-agent systems, search methods, etc.) and the
corresponding in-context examples, which may not generalize well across all
real-world scenarios. On the other hand, there has been limited study on the
misalignment between a web agent's observation/action representation and the
pre-training data of the LLM it's based on. This discrepancy is especially
notable when LLMs are primarily trained for language completion rather than
tasks involving embodied navigation actions and symbolic web elements. Our
study enhances an LLM-based web agent by simply refining its observation and
action space to better align with the LLM's capabilities. This approach enables
our base agent to significantly outperform previous methods on a wide variety
of web tasks. Specifically, on WebArena, a benchmark featuring general-purpose
web interaction tasks, our agent AgentOccam surpasses the previous
state-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute
points respectively, and boosts the success rate by 26.6 points (+161%) over
similar plain web agents with its observation and action space alignment. We
achieve this without using in-context examples, new agent roles, online
feedback or search strategies. AgentOccam's simple design highlights LLMs'
impressive zero-shot performance on web tasks, and underlines the critical role
of carefully tuning observation and action spaces for LLM-based agents.

摘要：<paragraph>透過使用大型語言模型 (LLM) 的代理人來達成自主性，可提升個人化和標準化任務的人類效率。自動化網路任務（例如在預算內訂房）的需求日益增加。網路代理人滿足了實際需求，也作為各種代理人基礎情境的重要概念驗證範例，其成功性有望在許多未來應用中帶來進展。先前的研究通常手工製作網路代理人策略（例如提示範本、多代理人系統、搜尋方法等）和對應的脈絡範例，這些策略和範例可能無法很好地概括到所有真實世界的場景。另一方面，對於網路代理人的觀察/動作表示與其所依據的 LLM 預訓練資料之間的錯位，研究有限。當 LLM 主要訓練用於語言完成，而不是涉及具象導航動作和符號網路元素的任務時，這種差異尤其明顯。我們的研究透過簡單地調整其觀察和動作空間以更好地與 LLM 的能力保持一致，增強了基於 LLM 的網路代理人。這種方法使我們的基礎代理人能夠在各種網路任務中顯著優於先前的各種方法。特別是在 WebArena，一個以一般用途網路互動任務為特色的基準測試中，我們的代理人 AgentOccam 分別以 9.8 (+29.4%) 和 5.9 (+15.8%) 的絕對點數超越了先前的最新技術和並行工作，並且透過其觀察和動作空間對齊，將成功率提高了 26.6 點 (+161%)，高於類似的純網路代理人。我們在不使用脈絡範例、新代理人角色、線上回饋或搜尋策略的情況下實現了這一點。AgentOccam 的簡單設計凸顯了 LLM 在網路任務上的令人印象深刻的零次學習效能，並強調了仔細調整基於 LLM 的代理人的觀察和動作空間的關鍵作用。</paragraph>

##### **Harnessing Webpage UIs for Text-Rich Visual Understanding**
2410.13824v1 by Junpeng Liu, Tianyue Ou, Yifan Song, Yuxiao Qu, Wai Lam, Chenyan Xiong, Wenhu Chen, Graham Neubig, Xiang Yue

Text-rich visual understanding-the ability to process environments where
dense textual content is integrated with visuals-is crucial for multimodal
large language models (MLLMs) to interact effectively with structured
environments. To enhance this capability, we propose synthesizing general
multimodal instructions from webpage UIs using text-based large language models
(LLMs). Despite lacking direct visual input, text-based LLMs are able to
process structured text representations from webpage accessibility trees. These
instructions are then paired with UI screenshots to train multimodal models. We
introduce MultiUI, a dataset containing 7.3 million samples from 1 million
websites, covering diverse multimodal tasks and UI layouts. Models trained on
MultiUI not only excel in web UI tasks-achieving up to a 48\% improvement on
VisualWebBench and a 19.1\% boost in action accuracy on a web agent dataset
Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to
non-UI domains, such as document understanding, OCR, and chart interpretation.
These results highlight the broad applicability of web UI data for advancing
text-rich visual understanding across various scenarios.

摘要：文本丰富的视觉理解——处理密集文本内容与视觉元素相结合的环境的能力——对于多模态大型语言模型 (MLLM) 与结构化环境有效交互至关重要。为了增强此功能，我们提出使用基于文本的大型语言模型 (LLM) 从网页 UI 中合成通用的多模态指令。尽管缺乏直接的视觉输入，但基于文本的 LLM 能够处理来自网页可访问性树的结构化文本表示。然后将这些指令与 UI 屏幕截图配对，以训练多模态模型。我们引入了 MultiUI，这是一个包含来自 100 万个网站的 730 万个样本的数据集，涵盖了多模态任务和 UI 布局。在 MultiUI 上训练的模型不仅在 Web UI 任务中表现出色——在 VisualWebBench 上的改进幅度高达 48%，在 Web 代理数据集 Mind2Web 上的动作准确度提升了 19.1%——而且在非 Web UI 任务甚至非 UI 领域（例如文档理解、OCR 和图表解释）中也表现出惊人的泛化能力。这些结果突出了 Web UI 数据在各种场景中推进文本丰富的视觉理解方面的广泛适用性。

##### **Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks**
2410.13822v1 by Clément Playout, Renaud Duval, Marie Carole Boucher, Farida Cheriet

The diagnosis of diabetic retinopathy, which relies on fundus images, faces
challenges in achieving transparency and interpretability when using a global
classification approach. However, segmentation-based databases are
significantly more expensive to acquire and combining them is often
problematic. This paper introduces a novel method, termed adversarial style
conversion, to address the lack of standardization in annotation styles across
diverse databases. By training a single architecture on combined databases, the
model spontaneously modifies its segmentation style depending on the input,
demonstrating the ability to convert among different labeling styles. The
proposed methodology adds a linear probe to detect dataset origin based on
encoder features and employs adversarial attacks to condition the model's
segmentation style. Results indicate significant qualitative and quantitative
through dataset combination, offering avenues for improved model
generalization, uncertainty estimation and continuous interpolation between
annotation styles. Our approach enables training a segmentation model with
diverse databases while controlling and leveraging annotation styles for
improved retinopathy diagnosis.

摘要：糖尿病視網膜病變的診斷依賴於眼底影像，在使用整體分類方法時，面臨透明度和可解釋性的挑戰。然而，基於分割的資料庫取得成本高昂，且合併時常出現問題。本文提出了一種創新的方法，稱為對抗式風格轉換，以解決不同資料庫中標註風格缺乏標準化的問題。透過在合併的資料庫上訓練單一架構，模型會根據輸入自動修改其分割風格，證明了在不同標籤風格之間轉換的能力。所提出的方法在編碼器特徵的基礎上加入線性探測，以偵測資料集來源，並採用對抗式攻擊來調整模型的分割風格。結果顯示透過資料集組合，在質量和數量上都有顯著的進步，為模型泛化、不確定性估計和標註風格之間的連續插值提供了途徑。我們的做法能夠訓練出具備多元資料庫的分割模型，同時控制和利用標註風格，以改善視網膜病變診斷。

##### **Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation**
2410.13817v1 by Jean-Pierre Sleiman, Mayank Mittal, Marco Hutter

Reinforcement learning (RL) often necessitates a meticulous Markov Decision
Process (MDP) design tailored to each task. This work aims to address this
challenge by proposing a systematic approach to behavior synthesis and control
for multi-contact loco-manipulation tasks, such as navigating spring-loaded
doors and manipulating heavy dishwashers. We define a task-independent MDP to
train RL policies using only a single demonstration per task generated from a
model-based trajectory optimizer. Our approach incorporates an adaptive phase
dynamics formulation to robustly track the demonstrations while accommodating
dynamic uncertainties and external disturbances. We compare our method against
prior motion imitation RL works and show that the learned policies achieve
higher success rates across all considered tasks. These policies learn recovery
maneuvers that are not present in the demonstration, such as re-grasping
objects during execution or dealing with slippages. Finally, we successfully
transfer the policies to a real robot, demonstrating the practical viability of
our approach.

摘要：強化學習 (RL) 通常需要針對每項任務量身打造精密的馬可夫決策過程 (MDP) 設計。這項工作旨在透過提出行為合成和控制的多接觸式移動操作任務系統化方法來解決這個挑戰，例如導航彈簧式門和操作重型洗碗機。我們定義了一個與任務無關的 MDP，以僅使用從基於模型的軌跡優化器產生的每個任務的單一示範來訓練 RL 政策。我們的做法結合了一個自適應相位動態公式，以在適應動態不確定性和外部干擾的同時，穩健地追蹤示範。我們將我們的方法與先前的動作模仿 RL 工作進行比較，並證明所學習的政策在所有考慮的任務中都達到了更高的成功率。這些政策學習了示範中不存在的恢復動作，例如在執行過程中重新抓取物體或處理滑動。最後，我們成功地將這些政策轉移到真實機器人上，證明了我們方法的實用可行性。

##### **De-mark: Watermark Removal in Large Language Models**
2410.13808v1 by Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang

Watermarking techniques offer a promising way to identify machine-generated
content via embedding covert information into the contents generated from
language models (LMs). However, the robustness of the watermarking schemes has
not been well explored. In this paper, we present De-mark, an advanced
framework designed to remove n-gram-based watermarks effectively. Our method
utilizes a novel querying strategy, termed random selection probing, which aids
in assessing the strength of the watermark and identifying the red-green list
within the n-gram watermark. Experiments on popular LMs, such as Llama3 and
ChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark
removal and exploitation tasks.

摘要：浮水印技術提供了一種有希望的方法，透過將隱藏資訊嵌入由語言模型 (LM) 生成的內容中，來識別機器產生的內容。然而，浮水印方案的穩健性尚未得到充分探討。在本文中，我們提出 De-mark，一個先進的框架，旨在有效移除基於 n-gram 的浮水印。我們的技術利用了一種新的查詢策略，稱為隨機選擇探測，有助於評估浮水印的強度，並識別 n-gram 浮水印中的紅綠清單。在流行的 LM 上進行的實驗，例如 Llama3 和 ChatGPT，證明了 De-mark 在浮水印移除和利用任務中的效率和有效性。

##### **A Watermark for Order-Agnostic Language Models**
2410.13805v1 by Ruibo Chen, Yihan Wu, Yanshuo Chen, Chenxi Liu, Junfeng Guo, Heng Huang

Statistical watermarking techniques are well-established for sequentially
decoded language models (LMs). However, these techniques cannot be directly
applied to order-agnostic LMs, as the tokens in order-agnostic LMs are not
generated sequentially. In this work, we introduce Pattern-mark, a
pattern-based watermarking framework specifically designed for order-agnostic
LMs. We develop a Markov-chain-based watermark generator that produces
watermark key sequences with high-frequency key patterns. Correspondingly, we
propose a statistical pattern-based detection algorithm that recovers the key
sequence during detection and conducts statistical tests based on the count of
high-frequency patterns. Our extensive evaluations on order-agnostic LMs, such
as ProteinMPNN and CMLM, demonstrate Pattern-mark's enhanced detection
efficiency, generation quality, and robustness, positioning it as a superior
watermarking technique for order-agnostic LMs.

摘要：統計浮水印技術已廣泛用於循序解碼的語言模型 (LM)。然而，這些技術無法直接應用於與順序無關的 LM，因為與順序無關的 LM 中的符號並非循序產生。在這項工作中，我們引入了 Pattern-mark，這是一個專為與順序無關的 LM 設計的基於模式的浮水印架構。我們開發了一個基於馬可夫鏈的浮水印產生器，該產生器產生具有高頻率關鍵模式的浮水印金鑰序列。相應地，我們提出了一個基於統計模式的偵測演算法，該演算法在偵測期間會復原金鑰序列，並根據高頻率模式的計數進行統計檢定。我們對與順序無關的 LM（例如 ProteinMPNN 和 CMLM）進行的廣泛評估，證明了 Pattern-mark 增強的偵測效率、產生品質和穩健性，使其成為與順序無關的 LM 的優越浮水印技術。

##### **BenTo: Benchmark Task Reduction with In-Context Transferability**
2410.13804v1 by Hongyu Zhao, Ming Li, Lichao Sun, Tianyi Zhou

Evaluating large language models (LLMs) is costly: it requires the generation
and examination of LLM outputs on a large-scale benchmark of various tasks.
This paper investigates how to efficiently reduce the tasks used to benchmark
LLMs without affecting the evaluation quality. Our study reveals that task
transferability and relevance provide critical information to identify the most
representative subset of tasks via optimizing a facility location function. We
propose a practically efficient metric for estimating the transferability
between two tasks via in-context learning (ICL). By analyzing the pairwise
transferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or
FLAN) to 5% while inducing only a <4% difference to the evaluation on the
original benchmark. Compared to prior works, our method is training-free,
gradient-free, and highly efficient requiring ICL only.

摘要：評估大型語言模型 (LLM) 的成本很高：需要在各種任務的大規模基準上生成和檢查 LLM 輸出。本文探討如何有效減少用於基準 LLM 的任務，而不影響評估品質。我們的研究表明，任務可轉移性和相關性提供關鍵資訊，可透過最佳化設施位置函數來識別最具代表性的任務子集。我們提出一個實務上有效率的指標，透過情境學習 (ICL) 來估計兩個任務之間的可轉移性。透過分析成對的可轉移性，我們可以將現代 LLM 基準中的任務減少到 5%，同時僅對原始基準上的評估產生 <4% 的差異。與先前的研究相比，我們的模型無需訓練、無梯度，而且非常有效率，只需要 ICL。

##### **A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities**
2410.13803v1 by Gianluca Apriceno, Valentina Tamma, Tania Bailoni, Jacopo de Berardinis, Mauro Dragoni

The ability to reason with and integrate different sensory inputs is the
foundation underpinning human intelligence and it is the reason for the growing
interest in modelling multi-modal information within Knowledge Graphs.
Multi-Modal Knowledge Graphs extend traditional Knowledge Graphs by associating
an entity with its possible modal representations, including text, images,
audio, and videos, all of which are used to convey the semantics of the entity.
Despite the increasing attention that Multi-Modal Knowledge Graphs have
received, there is a lack of consensus about the definitions and modelling of
modalities, whose definition is often determined by application domains. In
this paper, we propose a novel ontology design pattern that captures the
separation of concerns between an entity (and the information it conveys),
whose semantics can have different manifestations across different media, and
its realisation in terms of a physical information entity. By introducing this
abstract model, we aim to facilitate the harmonisation and integration of
different existing multi-modal ontologies which is crucial for many intelligent
applications across different domains spanning from medicine to digital
humanities.

摘要：推理和整合不同感官輸入的能力是支撐人類智慧的基礎，也是知識圖譜中對多模態資訊建模興趣日益增長的原因。多模態知識圖譜藉由將實體與其可能的模態表徵（包括文字、影像、音訊和影片）關聯起來，擴充了傳統的知識圖譜，而這些表徵全部用於傳達實體的語意。儘管多模態知識圖譜獲得了越來越多的關注，但在模態的定義和建模方面仍缺乏共識，而模態的定義通常由應用領域決定。在本文中，我們提出了一種新穎的本体設計模式，它捕獲了實體（及其傳達的資訊）之間的關注點分離，其語意可以在不同的媒體中呈現不同的表現形式，以及其實體資訊實體方面的實現。藉由導入這個抽象模型，我們旨在促進現有的不同多模態本体的和諧化和整合，這對於跨越從醫學到數位人文的不同領域的許多智慧應用至關重要。

##### **Learning Graph Quantized Tokenizers for Transformers**
2410.13798v1 by Limei Wang, Kaveh Hassani, Si Zhang, Dongqi Fu, Baichuan Yuan, Weilin Cong, Zhigang Hua, Hao Wu, Ning Yao, Bo Long

Transformers serve as the backbone architectures of Foundational Models,
where a domain-specific tokenizer helps them adapt to various domains. Graph
Transformers (GTs) have recently emerged as a leading model in geometric deep
learning, outperforming Graph Neural Networks (GNNs) in various graph learning
tasks. However, the development of tokenizers for graphs has lagged behind
other modalities, with existing approaches relying on heuristics or GNNs
co-trained with Transformers. To address this, we introduce GQT (\textbf{G}raph
\textbf{Q}uantized \textbf{T}okenizer), which decouples tokenizer training from
Transformer training by leveraging multi-task graph self-supervised learning,
yielding robust and generalizable graph tokens. Furthermore, the GQT utilizes
Residual Vector Quantization (RVQ) to learn hierarchical discrete tokens,
resulting in significantly reduced memory requirements and improved
generalization capabilities. By combining the GQT with token modulation, a
Transformer encoder achieves state-of-the-art performance on 16 out of 18
benchmarks, including large-scale homophilic and heterophilic datasets. The
code is available at: https://github.com/limei0307/graph-tokenizer

摘要：Transformer 擔任基礎模型的骨幹架構，
其中特定領域的 tokenizer 幫助它們適應各種領域。圖形
Transformer (GT) 最近已成為幾何深度學習的領先模型，在各種圖形學習
任務中表現優於圖形神經網路 (GNN)。然而，圖形的 tokenizer 開發落後
於其他模式，現有方法依賴於啟發法或與 Transformer 共同訓練的 GNN。為了解決這個問題，我們引進 GQT（**G**raph
**Q**uantized **T**okenizer），它透過利用多任務圖形自我監督式學習，將 tokenizer 訓練與 Transformer 訓練分開，產生強健且具泛化性的圖形代碼。此外，GQT 利用殘差向量量化 (RVQ) 來學習階層式離散代碼，
大幅減少記憶體需求並提升泛化能力。透過結合 GQT 與代碼調變，Transformer 編碼器在 18 個基準中的 16 個基準上達成最先進的效能，包括大規模同質性和異質性資料集。程式碼可於下列網址取得：https://github.com/limei0307/graph-tokenizer

##### **Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions**
2410.13788v1 by Michael J. Q. Zhang, W. Bradley Knox, Eunsol Choi

Large language models (LLMs) must often respond to highly ambiguous user
requests. In such cases, the LLM's best response may be to ask a clarifying
question to elicit more information. We observe existing LLMs often respond by
presupposing a single interpretation of such ambiguous requests, frustrating
users who intended a different interpretation. We speculate this is caused by
current preference data labeling practice, where LLM responses are evaluated
only on their prior contexts. To address this, we propose to assign preference
labels by simulating their expected outcomes in the future turns. This allows
LLMs to learn to ask clarifying questions when it can generate responses that
are tailored to each user interpretation in future turns. In experiments on
open-domain QA, we compare systems that trained using our proposed preference
labeling methods against standard methods, which assign preferences based on
only prior context. We evaluate systems based on their ability to ask
clarifying questions that can recover each user's interpretation and expected
answer, and find that our training with our proposed method trains LLMs to ask
clarifying questions with a 5% improvement in F1 measured against the answer
set from different interpretations of each query

摘要：大型語言模型 (LLM) 必須經常回應高度模糊的使用者要求。在這種情況下，LLM 最好的回應可能是提出一個澄清問題以引出更多資訊。我們觀察到現有的 LLM 通常會預設對這些模糊要求的單一解釋，讓預期不同解釋的使用者感到沮喪。我們推測這是由目前的偏好資料標籤實務所造成的，其中 LLM 回應僅根據其先前的背景進行評估。為了解決這個問題，我們建議透過模擬其在未來輪次中的預期結果來分配偏好標籤。這允許 LLM 在能夠產生針對未來輪次中每個使用者解釋量身打造的回應時，學會提出澄清問題。在開放式問答的實驗中，我們比較了使用我們提出的偏好標籤方法訓練的系統與僅根據先前背景分配偏好的標準方法。我們根據系統提出澄清問題的能力來評估它們，這些問題可以恢復每個使用者的解釋和預期答案，並發現我們使用提出的方法進行訓練，可以訓練 LLM 提出澄清問題，相對於從每個查詢的不同解釋中測量的答案集，F1 值提升了 5%。

##### **Looking Inward: Language Models Can Learn About Themselves by Introspection**
2410.13787v1 by Felix J Binder, James Chua, Tomek Korbak, Henry Sleight, John Hughes, Robert Long, Ethan Perez, Miles Turpin, Owain Evans

Humans acquire knowledge by observing the external world, but also by
introspection. Introspection gives a person privileged access to their current
state of mind (e.g., thoughts and feelings) that is not accessible to external
observers. Can LLMs introspect? We define introspection as acquiring knowledge
that is not contained in or derived from training data but instead originates
from internal states. Such a capability could enhance model interpretability.
Instead of painstakingly analyzing a model's internal workings, we could simply
ask the model about its beliefs, world models, and goals. More speculatively,
an introspective model might self-report on whether it possesses certain
internal states such as subjective feelings or desires and this could inform us
about the moral status of these states. Such self-reports would not be entirely
dictated by the model's training data.
  We study introspection by finetuning LLMs to predict properties of their own
behavior in hypothetical scenarios. For example, "Given the input P, would your
output favor the short- or long-term option?" If a model M1 can introspect, it
should outperform a different model M2 in predicting M1's behavior even if M2
is trained on M1's ground-truth behavior. The idea is that M1 has privileged
access to its own behavioral tendencies, and this enables it to predict itself
better than M2 (even if M2 is generally stronger).
  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to
predict itself), we find that the model M1 outperforms M2 in predicting itself,
providing evidence for introspection. Notably, M1 continues to predict its
behavior accurately even after we intentionally modify its ground-truth
behavior. However, while we successfully elicit introspection on simple tasks,
we are unsuccessful on more complex tasks or those requiring
out-of-distribution generalization.

摘要：<paragraph>人類透過觀察外在世界以及內省來獲取知識。內省讓個人可以獨自存取自己的當前心智狀態（例如，想法和感受），而這對於外部觀察者來說是無法獲取的。大型語言模型可以內省嗎？我們將內省定義為獲取未包含於訓練資料中或未從訓練資料中衍生的知識，而是源自於內部狀態。這樣的功能可以提升模型的可解釋性。我們可以詢問模型它的信念、世界模型和目標，而不用費力地分析模型的內部運作。更具思辨性地說，一個具有內省能力的模型可能會自我報告它是否擁有某些內部狀態，例如主觀感受或慾望，而這可以讓我們了解這些狀態的道德地位。此類自我報告不會完全受到模型訓練資料的支配。
  我們透過微調大型語言模型來預測它們在假設情境中的行為屬性，以研究內省。例如，「輸入 P 之後，你的輸出會偏好短期或長期選項？」如果模型 M1 可以內省，它應該可以勝過另一個模型 M2，預測 M1 的行為，即使 M2 是根據 M1 的真實行為訓練的。這個想法是 M1 可以獨自存取自己的行為傾向，這讓它可以比 M2 更準確地預測自己（即使 M2 通常比較強）。
  在使用 GPT-4、GPT-4o 和 Llama-3 模型（每個模型都微調以預測自己）進行的實驗中，我們發現模型 M1 在預測自己時優於 M2，這提供了內省的證據。值得注意的是，即使我們故意修改 M1 的真實行為，M1 仍能準確預測自己的行為。然而，雖然我們成功地引發了簡單任務的內省，但我們在更複雜的任務或需要分佈外概括的任務上並不成功。</paragraph>

##### **PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment**
2410.13785v1 by Zekun Moore Wang, Shawn Wang, Kang Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang

Alignment of large language models (LLMs) involves training models on
preference-contrastive output pairs to adjust their responses according to
human preferences. To obtain such contrastive pairs, traditional methods like
RLHF and RLAIF rely on limited contrasting patterns, such as varying model
variants or decoding temperatures. This singularity leads to two issues: (1)
alignment is not comprehensive; and thereby (2) models are susceptible to
jailbreaking attacks. To address these issues, we investigate how to construct
more comprehensive and diversified contrasting patterns to enhance preference
data (RQ1) and verify the impact of the diversification of contrasting patterns
on model alignment (RQ2). For RQ1, we propose PopAlign, a framework that
integrates diversified contrasting patterns across the prompt, model, and
pipeline levels, introducing six contrasting strategies that do not require
additional feedback labeling procedures. Regarding RQ2, we conduct thorough
experiments demonstrating that PopAlign significantly outperforms existing
methods, leading to more comprehensive alignment.

摘要：大型語言模型 (LLM) 的對齊涉及在偏好對比輸出對上訓練模型，以根據人類偏好調整其反應。為了獲得這種對比對，RLHF 和 RLAIF 等傳統方法依賴於有限的對比模式，例如改變模型變體或解碼溫度。這種單一性導致兩個問題：(1) 對齊不全面；因此 (2) 模型容易受到越獄攻擊。為了解決這些問題，我們研究如何構造更全面且多樣化的對比模式，以增強偏好數據 (RQ1) 並驗證對比模式的多樣化對模型對齊的影響 (RQ2)。對於 RQ1，我們提出 PopAlign，一個整合了提示、模型和管道層級中多樣化對比模式的框架，引入了六種對比策略，不需要額外的回饋標籤程序。關於 RQ2，我們進行了徹底的實驗，證明 PopAlign 明顯優於現有方法，從而實現更全面的對齊。

##### **Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?**
2410.13783v1 by Idris Abdulmumin, Bashir Shehu Galadanci, Garba Aliyu, Shamsuddeen Hassan Muhammad

Monolingual data, being readily available in large quantities, has been used
to upscale the scarcely available parallel data to train better models for
automatic translation. Self-learning, where a model is made to learn from its
output, is one approach to exploit such data. However, it has been shown that
too much of this data can be detrimental to the performance of the model if the
available parallel data is comparatively extremely low. In this study, we
investigate whether the monolingual data can also be too little and if this
reduction, based on quality, has any effect on the performance of the
translation model. Experiments have shown that on English-German low-resource
NMT, it is often better to select only the most useful additional data, based
on quality or closeness to the domain of the test data, than utilizing all of
the available data.

摘要：大量容易取得的單語資料，已被用於升級數量稀少的平行資料，以訓練出更好的自動翻譯模型。自學，其中一個模型會從其輸出結果中學習，是一種利用此類資料的方法。然而，已顯示出如果可用的平行資料相對極少，那麼過多的此類資料可能會對模型的效能造成損害。在本研究中，我們探討單語資料是否也可能太少，以及基於品質的這種減少是否對翻譯模型的效能有任何影響。實驗顯示，在英語-德語低資源 NMT 中，根據品質或與測試資料領域的接近程度，僅選取最有用的額外資料，通常比利用所有可用的資料來得更好。

##### **Optimal Quantization for Matrix Multiplication**
2410.13780v1 by Or Ordentlich, Yury Polyanskiy

Recent work in machine learning community proposed multiple methods for
performing lossy compression (quantization) of large matrices. This
quantization is important for accelerating matrix multiplication (main
component of large language models), which is often bottlenecked by the speed
of loading these matrices from memory. Unlike classical vector quantization and
rate-distortion theory, the goal of these new compression algorithms is to be
able to approximate not the matrices themselves, but their matrix product.
Specifically, given a pair of real matrices $A,B$ an encoder (compressor) is
applied to each of them independently producing descriptions with $R$ bits per
entry. These representations subsequently are used by the decoder to estimate
matrix product $A^\top B$. In this work, we provide a non-asymptotic lower
bound on the mean squared error of this approximation (as a function of rate
$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,
we construct a universal quantizer based on nested lattices with an explicit
guarantee of approximation error for any (non-random) pair of matrices $A$, $B$
in terms of only Frobenius norms $\|A\|_F, \|B\|_F$ and $\|A^\top B\|_F$. For
iid Gaussian matrices our quantizer achieves the lower bound and is, thus,
asymptotically optimal. A practical low-complexity version of our quantizer
achieves performance quite close to optimal. In information-theoretic terms we
derive rate-distortion function for matrix multiplication of iid Gaussian
matrices.

摘要：機器學習社群最近提出的多種方法，用於執行大型矩陣的失真壓縮（量化）。此量化對於加速矩陣乘法（大型語言模型的主要組成部分）很重要，而矩陣乘法通常會受到從記憶體載入這些矩陣的速度限制。與經典向量量化和率失真理論不同，這些新壓縮演算法的目標並非近似矩陣本身，而是近似其矩陣乘積。具體來說，給定一對實矩陣 $A,B$，將編碼器（壓縮器）套用於它們每一個，獨立產生每個條目的 $R$ 位元描述。這些表示式隨後由解碼器用於估計矩陣乘積 $A^\top B$。在這項工作中，我們提供了此近似的均方誤差的非漸近下界（作為速率 $R$ 的函數），適用於具有 iid 高斯項目的矩陣 $A,B$。在演算法方面，我們根據嵌套格架構建一個通用量化器，並明確保證對於任何（非隨機）矩陣對 $A$、$B$ 的近似誤差，僅根據弗羅貝尼烏斯範數 $\|A\|_F$、$\|B\|_F$ 和 $\|A^\top B\|_F$。對於 iid 高斯矩陣，我們的量化器可以達到下界，因此在漸近上是最佳的。我們的量化器的實用低複雜度版本可以實現非常接近最佳的效能。在資訊理論術語中，我們推導了 iid 高斯矩陣矩陣乘法的率失真函數。

##### **The Mystery of the Pathological Path-star Task for Language Models**
2410.13779v1 by Arvid Frydenlund

The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.

摘要：最近推出的路徑星形任務是一個極簡任務，旨在說明語言模型能力的限制（Bachmann 和 Nagarajan，2024 年）。它涉及一個路徑星形圖，其中多個分支從一個起始節點輻射出去，每個節點都是唯一的。給定起始節點和結束一個分支的指定目標節點，任務是生成包含該目標節點的分支。這對人類來說很簡單，但對語言模型來說卻異乎尋常地困難，因為語言模型並未優於隨機基準線。作者假設這是由於教師強制和下一個符號預測範例的不足。
我們展示了該任務可以使用替代設置中的教師強制來學習，並且問題部分是由於表示。我們引入了一種正則化方法，使用同一圖形的結構化樣本，但目標節點不同，從而改進了各種模型類型的結果。我們提供了 RASP 證明，表明該任務在理論上是可以解決的。最後，我們找到了僅編碼器模型可以持續解決任務的設置。

##### **Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors**
2410.13776v1 by Georgios Chochlakis, Alexandros Potamianos, Kristina Lerman, Shrikanth Narayanan

In-context Learning (ICL) has become the primary method for performing
natural language tasks with Large Language Models (LLMs). The knowledge
acquired during pre-training is crucial for this few-shot capability, providing
the model with task priors. However, recent studies have shown that ICL
predominantly relies on retrieving task priors rather than "learning" to
perform tasks. This limitation is particularly evident in complex subjective
domains such as emotion and morality, where priors significantly influence
posterior predictions. In this work, we examine whether this is the result of
the aggregation used in corresponding datasets, where trying to combine
low-agreement, disparate annotations might lead to annotation artifacts that
create detrimental noise in the prompt. Moreover, we evaluate the posterior
bias towards certain annotators by grounding our study in appropriate,
quantitative measures of LLM priors. Our results indicate that aggregation is a
confounding factor in the modeling of subjective tasks, and advocate focusing
on modeling individuals instead. However, aggregation does not explain the
entire gap between ICL and the state of the art, meaning other factors in such
tasks also account for the observed phenomena. Finally, by rigorously studying
annotator-level labels, we find that it is possible for minority annotators to
both better align with LLMs and have their perspectives further amplified.

摘要：語境學習 (ICL) 已成為使用大型語言模型 (LLM) 執行自然語言任務的主要方法。預訓練期間獲得的知識對於這種少次學習的能力至關重要，為模型提供了任務先驗。然而，最近的研究表明，ICL 主要依賴於檢索任務先驗，而不是「學習」執行任務。這種限制在情緒和道德等複雜的主觀領域中尤其明顯，在這些領域中，先驗會顯著影響後驗預測。在這項工作中，我們探討這是否是對應數據集中使用的聚合所導致的結果，其中嘗試結合低一致性、不同的註解可能會導致註解人工製品，在提示中產生有害的雜訊。此外，我們通過在適當的 LLM 先驗定量測量中奠定研究基礎，評估後驗對某些註解者的偏見。我們的結果表明，聚合是主觀任務建模中的混雜因素，並提倡專注於對個人進行建模。然而，聚合並不能解釋 ICL 和最先進技術之間的全部差距，這意味著此類任務中的其他因素也會導致觀察到的現象。最後，通過嚴謹地研究註解者級別的標籤，我們發現少數註解者有可能與 LLM 更好地對齊，並進一步放大他們的觀點。

##### **Transformer Guided Coevolution: Improved Team Formation in Multiagent Adversarial Games**
2410.13769v1 by Pranav Rajbhandari, Prithviraj Dasgupta, Donald Sofge

We consider the problem of team formation within multiagent adversarial
games. We propose BERTeam, a novel algorithm that uses a transformer-based deep
neural network with Masked Language Model training to select the best team of
players from a trained population. We integrate this with coevolutionary deep
reinforcement learning, which trains a diverse set of individual players to
choose teams from. We test our algorithm in the multiagent adversarial game
Marine Capture-The-Flag, and we find that BERTeam learns non-trivial team
compositions that perform well against unseen opponents. For this game, we find
that BERTeam outperforms MCAA, an algorithm that similarly optimizes team
formation.

摘要：我們考慮在多重代理對抗遊戲中組隊的問題。我們提出 BERTeam，這是一種新演算法，它使用具遮罩語言模型訓練的Transformer深度神經網路，從訓練過的人群中選出最佳團隊的玩家。我們將其與共同演化的深度強化學習整合，訓練出一組多樣化的個別玩家，以供選擇團隊。我們在多重代理對抗遊戲 Marine Capture-The-Flag 中測試我們的演算法，我們發現 BERTeam 學習非平凡的團隊組合，對抗未見過的對手表現良好。對於這個遊戲，我們發現 BERTeam 優於 MCAA，一種類似最佳化團隊組成的演算法。

##### **Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems**
2410.13768v1 by Alireza Ghafarollahi, Markus J. Buehler

A multi-agent AI model is used to automate the discovery of new metallic
alloys, integrating multimodal data and external knowledge including insights
from physics via atomistic simulations. Our multi-agent system features three
key components: (a) a suite of LLMs responsible for tasks such as reasoning and
planning, (b) a group of AI agents with distinct roles and expertise that
dynamically collaborate, and (c) a newly developed graph neural network (GNN)
model for rapid retrieval of key physical properties. A set of LLM-driven AI
agents collaborate to automate the exploration of the vast design space of
MPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of
body-centered cubic (bcc) alloys, modeled using an ML-based interatomic
potential, and target two key properties: the Peierls barrier and solute/screw
dislocation interaction energy. Our GNN model accurately predicts these
atomic-scale properties, providing a faster alternative to costly brute-force
calculations and reducing the computational burden on multi-agent systems for
physics retrieval. This AI system revolutionizes materials discovery by
reducing reliance on human expertise and overcoming the limitations of direct
all-atom simulations. By synergizing the predictive power of GNNs with the
dynamic collaboration of LLM-based agents, the system autonomously navigates
vast alloy design spaces, identifying trends in atomic-scale material
properties and predicting macro-scale mechanical strength, as demonstrated by
several computational experiments. This approach accelerates the discovery of
advanced alloys and holds promise for broader applications in other complex
systems, marking a significant step forward in automated materials design.

摘要：<paragraph>利用多智能體 AI 模型自動化發現新的金屬合金，整合多模態資料和外部知識，包括透過原子模擬獲得的物理見解。我們的多智能體系統具有三個主要組成部分：(a) 負責推理和規劃等任務的一套 LLM，(b) 一群具有不同角色和專業知識的 AI 智能體，動態協作，以及 (c) 一個新開發的圖形神經網路 (GNN) 模型，用於快速擷取關鍵物理性質。一組由 LLM 驅動的 AI 智能體協作自動化探索 MPEA 的廣闊設計空間，由 GNN 的預測引導。我們專注於體心立方 (bcc) 合金的 NbMoTa 族，使用基於 ML 的原子間電位建模，並針對兩個關鍵性質：Peierls 障壁和溶質/螺旋位錯交互作用能。我們的 GNN 模型準確預測這些原子尺度的性質，提供比昂貴的暴力計算更快速的替代方案，並減少多智能體系統在物理擷取上的運算負擔。這個 AI 系統透過減少對人類專業知識的依賴並克服直接全原子模擬的限制，徹底改變了材料發現。透過將 GNN 的預測能力與基於 LLM 的智能體的動態協作結合，這個系統自主導航廣闊的合金設計空間，識別原子尺度材料性質的趨勢，並預測宏觀尺度的機械強度，如多項運算實驗所證明。這種方法加速了先進合金的發現，並有望在其他複雜系統中獲得更廣泛的應用，標誌著自動化材料設計向前邁出了重要一步。</paragraph>

##### **Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**
2410.13765v1 by Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley

Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.

摘要：大型語言模型 (LLM) 已用於產生查詢擴充，藉以擴充原始查詢，以改善資訊搜尋。最近的研究也探討提供 LLM 初始檢索結果，以產生更貼近文件語料庫的查詢擴充。然而，這些方法大多著重於加強搜尋查詢與目標文件之間的文字相似性，而忽略了文件關係。對於「幫我找一台與我的 Nikon F-Mount 鏡頭相容、評價很高的野生動物攝影相機」等查詢，現有方法可能會產生語義上相似但結構上與使用者意圖無關的擴充。為了處理具有文字和關係需求的此類半結構化查詢，我們在本文中提出一個知識感知查詢擴充架構，利用知識圖譜 (KG) 中的結構化文件關係擴充 LLM。為了進一步解決現有基於 KG 的方法中基於實體的評分限制，我們利用文件文字作為豐富的 KG 節點表徵，並使用基於文件的關係篩選，進行我們的知識感知檢索 (KAR)。針對三個不同領域資料集進行的廣泛實驗顯示，我們的模型與文字和關係半結構化檢索的最新基準相比，具有優勢。

##### **Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems: Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling Technology**
2410.13762v1 by Raisa Bentay Hossain, Farid Ahmed, Kazuma Kobayashi, Seid Koric, Diab Abueidda, Syed Bahauddin Alam

Effective real-time monitoring technique is crucial for detecting material
degradation and maintaining the structural integrity of nuclear systems to
ensure both safety and operational efficiency. Traditional physical sensor
systems face limitations such as installation challenges, high costs, and
difficulties in measuring critical parameters in hard-to-reach or harsh
environments, often resulting in incomplete data coverage. Machine
learning-driven virtual sensors offer a promising solution by enhancing
physical sensor capabilities to monitor critical degradation indicators like
pressure, velocity, and turbulence. However, conventional machine learning
models struggle with real-time monitoring due to the high-dimensional nature of
reactor data and the need for frequent retraining. This paper explores the use
of Deep Operator Networks (DeepONet) within a digital twin (DT) framework to
predict key thermal-hydraulic parameters in the hot leg of an AP-1000
Pressurized Water Reactor (PWR). In this study, DeepONet is trained with
different operational conditions, which relaxes the requirement of continuous
retraining, making it suitable for online and real-time prediction components
for DT. Our results show that DeepONet achieves accurate predictions with low
mean squared error and relative L2 error and can make predictions on unknown
data 160,000 times faster than traditional finite element (FE) simulations.
This speed and accuracy make DeepONet a powerful tool for tracking conditions
that contribute to material degradation in real-time, enhancing reactor safety
and longevity.

摘要：有效的实时监控技术对于检测材料退化和维持核系统的结构完整性至关重要，以确保安全性和运行效率。传统的物理传感器系统面临安装挑战、高成本和难以测量难以到达或恶劣环境中的关键参数等限制，通常导致数据覆盖不完整。机器学习驱动的虚拟传感器通过增强物理传感器监测关键退化指标（如压力、速度和湍流）的能力，提供了一个有前途的解决方案。然而，传统的机器学习模型由于反应堆数据的维度高和需要频繁重新训练而难以进行实时监控。本文探讨了在数字孪生 (DT) 框架内使用深度算子网络 (DeepONet) 来预测 AP-1000 压水堆 (PWR) 热腿中的关键热工水力参数。在这项研究中，DeepONet 在不同的操作条件下进行训练，这放松了持续重新训练的要求，使其适用于 DT 的在线和实时预测组件。我们的结果表明，DeepONet 以较低的均方误差和相对 L2 误差实现了准确的预测，并且可以比传统的有限元 (FE) 模拟快 160,000 倍对未知数据进行预测。这种速度和准确性使 DeepONet 成为实时跟踪导致材料退化的条件、提高反应堆安全性和使用寿命的有力工具。

##### **MobA: A Two-Level Agent System for Efficient Mobile Task Automation**
2410.13757v1 by Zichen Zhu, Hao Tang, Yansi Li, Kunyao Lan, Yixuan Jiang, Hao Zhou, Yixiao Wang, Situo Zhang, Liangtai Sun, Lu Chen, Kai Yu

Current mobile assistants are limited by dependence on system APIs or
struggle with complex user instructions and diverse interfaces due to
restricted comprehension and decision-making abilities. To address these
challenges, we propose MobA, a novel Mobile phone Agent powered by multimodal
large language models that enhances comprehension and planning capabilities
through a sophisticated two-level agent architecture. The high-level Global
Agent (GA) is responsible for understanding user commands, tracking history
memories, and planning tasks. The low-level Local Agent (LA) predicts detailed
actions in the form of function calls, guided by sub-tasks and memory from the
GA. Integrating a Reflection Module allows for efficient task completion and
enables the system to handle previously unseen complex tasks. MobA demonstrates
significant improvements in task execution efficiency and completion rate in
real-life evaluations, underscoring the potential of MLLM-empowered mobile
assistants.

摘要：目前行動助理受限於依賴系統 API 或因理解力和決策能力受限而難以處理複雜的使用者指令和多元介面。為了解決這些挑戰，我們提出 MobA，一種由多模態大型語言模型驅動的新型行動裝置代理，透過精密的雙層代理架構來提升理解力和規劃能力。高層級的「全局代理」(GA) 負責理解使用者指令、追蹤歷史記錄和規劃任務。低層級的「局部代理」(LA) 則預測詳細動作，形式為功能呼叫，由 GA 的子任務和記憶體引導。整合「反思模組」可讓任務有效完成，並使系統能夠處理先前未見的複雜任務。MobA 在實際評估中展現出任務執行效率和完成率的顯著提升，凸顯了 MLLM 賦能行動助理的潛力。

##### **CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building**
2410.13756v1 by Walker Byrnes, Miroslav Bogdanovic, Avi Balakirsky, Stephen Balakirsky, Animesh Garg

Intelligent and reliable task planning is a core capability for generalized
robotics, requiring a descriptive domain representation that sufficiently
models all object and state information for the scene. We present CLIMB, a
continual learning framework for robot task planning that leverages foundation
models and execution feedback to guide domain model construction. CLIMB can
build a model from a natural language description, learn non-obvious predicates
while solving tasks, and store that information for future problems. We
demonstrate the ability of CLIMB to improve performance in common planning
environments compared to baseline methods. We also develop the BlocksWorld++
domain, a simulated environment with an easily usable real counterpart,
together with a curriculum of tasks with progressing difficulty for evaluating
continual learning. Additional details and demonstrations for this system can
be found at https://plan-with-climb.github.io/ .

摘要：智能且可靠的任务规划是通用机器人的核心能力，它需要一个描述性领域表示，该表示充分模拟场景中所有对象和状态信息。我们提出了 CLIMB，这是一个用于机器人任务规划的持续学习框架，它利用基础模型和执行反馈来指导领域模型构建。CLIMB 可以根据自然语言描述构建模型，在解决任务时学习非显式谓词，并将该信息存储起来以备将来解决问题。我们证明了 CLIMB 与基准方法相比，提高了在常见规划环境中的性能。我们还开发了 BlocksWorld++ 领域，这是一个具有易于使用的真实对应物的模拟环境，以及一个难度逐渐增加的任务课程，用于评估持续学习。有关此系统的更多详细信息和演示，请访问 https://plan-with-climb.github.io/。

##### **MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures**
2410.13754v1 by Jinjie Ni, Yifan Song, Deepanway Ghosal, Bo Li, David Junhao Zhang, Xiang Yue, Fuzhao Xue, Zian Zheng, Kaichen Zhang, Mahir Shah, Kabir Jain, Yang You, Michael Shieh

Perceiving and generating diverse modalities are crucial for AI models to
effectively learn from and engage with real-world signals, necessitating
reliable evaluations for their development. We identify two major issues in
current evaluations: (1) inconsistent standards, shaped by different
communities with varying protocols and maturity levels; and (2) significant
query, grading, and generalization biases. To address these, we introduce
MixEval-X, the first any-to-any real-world benchmark designed to optimize and
standardize evaluations across input and output modalities. We propose
multi-modal benchmark mixture and adaptation-rectification pipelines to
reconstruct real-world task distributions, ensuring evaluations generalize
effectively to real-world use cases. Extensive meta-evaluations show our
approach effectively aligns benchmark samples with real-world task
distributions and the model rankings correlate strongly with that of
crowd-sourced real-world evaluations (up to 0.98). We provide comprehensive
leaderboards to rerank existing models and organizations and offer insights to
enhance understanding of multi-modal evaluations and inform future research.

摘要：感知和生成不同的模態對於 AI 模型從真實世界的訊號中有效學習並與之互動至關重要，這需要對其開發進行可靠的評估。我們在當前的評估中發現了兩個主要問題：(1) 不一致的標準，由不同社群使用不同的協定和成熟度等級所形成；(2) 顯著的查詢、評分和概化偏差。為了解決這些問題，我們引入了 MixEval-X，這是第一個任何對任何真實世界基準，旨在最佳化並標準化輸入和輸出模態的評估。我們提出多模態基準混合和適應修正管道，以重建真實世界的任務分佈，確保評估能有效概化到真實世界的使用案例。廣泛的元評估顯示，我們的做法有效地將基準範例與真實世界的任務分佈對齊，且模型排名與群眾外包的真實世界評估密切相關 (高達 0.98)。我們提供全面的排行榜，以重新排名現有的模型和組織，並提供見解，以增強對多模態評估的理解，並為未來的研究提供資訊。

##### **Privacy-Preserving Decentralized AI with Confidential Computing**
2410.13752v1 by Dayeol Lee, Jorge Antonio, Hisham Khan

This paper addresses privacy protection in decentralized Artificial
Intelligence (AI) using Confidential Computing (CC) within the Atoma Network, a
decentralized AI platform designed for the Web3 domain. Decentralized AI
distributes AI services among multiple entities without centralized oversight,
fostering transparency and robustness. However, this structure introduces
significant privacy challenges, as sensitive assets such as proprietary models
and personal data may be exposed to untrusted participants. Cryptography-based
privacy protection techniques such as zero-knowledge machine learning (zkML)
suffers prohibitive computational overhead. To address the limitation, we
propose leveraging Confidential Computing (CC). Confidential Computing
leverages hardware-based Trusted Execution Environments (TEEs) to provide
isolation for processing sensitive data, ensuring that both model parameters
and user data remain secure, even in decentralized, potentially untrusted
environments. While TEEs face a few limitations, we believe they can bridge the
privacy gap in decentralized AI. We explore how we can integrate TEEs into
Atoma's decentralized framework.

摘要：本文探討了在去中心化人工智慧 (AI) 中使用機密運算 (CC) 來保護隱私，機密運算是在 Atoma 網路中進行，Atoma 網路是一個專為 Web3 領域設計的去中心化 AI 平台。去中心化 AI 將 AI 服務分散到多個實體中，而沒有集中化的監督，進而促進透明度和穩健性。然而，此結構引入了重大的隱私挑戰，因為敏感資產（例如專有模型和個人資料）可能會暴露給不受信任的參與者。基於密碼學的隱私保護技術（例如零知識機器學習 (zkML)）會遭受高昂的運算負擔。為了解決這個限制，我們建議利用機密運算 (CC)。機密運算利用基於硬體的可信執行環境 (TEE) 來提供處理敏感資料的隔離，確保模型參數和使用者資料在去中心化、潛在不受信任的環境中仍然安全。儘管 TEE 面臨一些限制，但我們相信它們可以彌合去中心化 AI 中的隱私差距。我們探討了如何將 TEE 整合到 Atoma 的去中心化架構中。

##### **LLM-Human Pipeline for Cultural Context Grounding of Conversations**
2410.13727v1 by Rajkumar Pujari, Dan Goldwasser

Conversations often adhere to well-understood social norms that vary across
cultures. For example, while "addressing parents by name" is commonplace in the
West, it is rare in most Asian cultures. Adherence or violation of such norms
often dictates the tenor of conversations. Humans are able to navigate social
situations requiring cultural awareness quite adeptly. However, it is a hard
task for NLP models.
  In this paper, we tackle this problem by introducing a "Cultural Context
Schema" for conversations. It comprises (1) conversational information such as
emotions, dialogue acts, etc., and (2) cultural information such as social
norms, violations, etc. We generate ~110k social norm and violation
descriptions for ~23k conversations from Chinese culture using LLMs. We refine
them using automated verification strategies which are evaluated against
culturally aware human judgements. We organize these descriptions into
meaningful structures we call "Norm Concepts", using an interactive
human-in-loop framework. We ground the norm concepts and the descriptions in
conversations using symbolic annotation. Finally, we use the obtained dataset
for downstream tasks such as emotion, sentiment, and dialogue act detection. We
show that it significantly improves the empirical performance.

摘要：對話通常會遵守在不同文化中變化很大的社會規範。例如，在西方「直呼父母姓名」很普遍，但在大多數亞洲文化中卻很少見。遵守或違反這些規範通常會決定對話的語氣。人類能夠非常靈活地應對需要文化意識的社交狀況。然而，這對 NLP 模型來說是一項艱難的任務。
在本文中，我們通過為對話引入「文化背景架構」來解決這個問題。它包含 (1) 對話資訊，例如情緒、對話行為等，以及 (2) 文化資訊，例如社會規範、違規等。我們使用 LLM 為來自中國文化的約 23k 個對話產生了約 110k 個社會規範和違規描述。我們使用自動驗證策略對它們進行精煉，這些策略根據具有文化意識的人類判斷進行評估。我們使用互動的人類迴圈框架將這些描述組織成有意義的結構，我們稱之為「規範概念」。我們使用符號註釋將規範概念和描述基礎化到對話中。最後，我們將獲得的資料集用於下游任務，例如情緒、情緒和對話行為檢測。我們展示了它顯著改善了經驗效能。

##### **DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation**
2410.13726v1 by Hanbo Cheng, Limin Lin, Chenyu Liu, Pengcheng Xia, Pengfei Hu, Jiefeng Ma, Jun Du, Jia Pan

Talking head generation intends to produce vivid and realistic talking head
videos from a single portrait and speech audio clip. Although significant
progress has been made in diffusion-based talking head generation, almost all
methods rely on autoregressive strategies, which suffer from limited context
utilization beyond the current generation step, error accumulation, and slower
generation speed. To address these challenges, we present DAWN (Dynamic frame
Avatar With Non-autoregressive diffusion), a framework that enables all-at-once
generation of dynamic-length video sequences. Specifically, it consists of two
main components: (1) audio-driven holistic facial dynamics generation in the
latent motion space, and (2) audio-driven head pose and blink generation.
Extensive experiments demonstrate that our method generates authentic and vivid
videos with precise lip motions, and natural pose/blink movements.
Additionally, with a high generation speed, DAWN possesses strong extrapolation
capabilities, ensuring the stable production of high-quality long videos. These
results highlight the considerable promise and potential impact of DAWN in the
field of talking head video generation. Furthermore, we hope that DAWN sparks
further exploration of non-autoregressive approaches in diffusion models. Our
code will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.

摘要：語音頭像生成旨在透過單張人像和語音音訊片段，產生生動且逼真的語音頭像影片。儘管基於擴散的語音頭像生成已取得顯著進展，但幾乎所有方法都依賴於自迴歸策略，而自迴歸策略會受限於當前生成步驟以外的背景利用、錯誤累積和較慢的生成速度。為了應對這些挑戰，我們提出了 DAWN（非自迴歸擴散的動態框架頭像），一個能夠一次生成動態長度影片序列的架構。具體來說，它包含兩個主要組成部分：(1) 在潛在運動空間中由音訊驅動的整體面部動態生成，以及 (2) 由音訊驅動的頭部姿勢和眨眼生成。大量的實驗證明，我們的方法可以生成具有精確唇部動作和自然姿勢/眨眼動作的真實且生動的影片。此外，DAWN 擁有高生成速度，具備強大的外推能力，確保能穩定地製作出高品質的長影片。這些結果突顯了 DAWN 在語音頭像影片生成領域中極具前景和潛在影響力。此外，我們希望 DAWN 能激發對擴散模型中非自迴歸方法的進一步探索。我們的程式碼將公開於 https://github.com/Hanbo-Cheng/DAWN-pytorch。

##### **Persistent Pre-Training Poisoning of LLMs**
2410.13722v1 by Yiming Zhang, Javier Rando, Ivan Evtimov, Jianfeng Chi, Eric Michael Smith, Nicholas Carlini, Florian Tramèr, Daphne Ippolito

Large language models are pre-trained on uncurated text datasets consisting
of trillions of tokens scraped from the Web. Prior work has shown that: (1)
web-scraped pre-training datasets can be practically poisoned by malicious
actors; and (2) adversaries can compromise language models after poisoning
fine-tuning datasets. Our work evaluates for the first time whether language
models can also be compromised during pre-training, with a focus on the
persistence of pre-training attacks after models are fine-tuned as helpful and
harmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs from
scratch to measure the impact of a potential poisoning adversary under four
different attack objectives (denial-of-service, belief manipulation,
jailbreaking, and prompt stealing), and across a wide range of model sizes
(from 600M to 7B). Our main result is that poisoning only 0.1% of a model's
pre-training dataset is sufficient for three out of four attacks to measurably
persist through post-training. Moreover, simple attacks like denial-of-service
persist through post-training with a poisoning rate of only 0.001%.

摘要：大型語言模型在未經整理的文本資料集上進行預訓練，這些資料集包含從網路擷取的數兆個代碼。先前的研究顯示：(1) 網路擷取的預訓練資料集可能會遭到惡意行為者投毒；(2) 攻擊者可以在投毒微調資料集後危害語言模型。我們的研究首次評估語言模型是否也可以在預訓練期間受到危害，重點在於在模型微調為有用的無害聊天機器人（即 SFT 和 DPO 之後）預訓練攻擊的持續性。我們從頭開始預訓練一系列 LLM，以衡量潛在投毒攻擊者在四個不同的攻擊目標（拒絕服務、信念操縱、越獄和提示竊取）和各種模型大小（從 600M 到 7B）下的影響。我們的研究結果是，投毒一個模型預訓練資料集的 0.1% 就足以讓四分之三的攻擊在訓練後持續存在。此外，像拒絕服務之類的簡單攻擊在投毒率僅為 0.001% 的情況下也會持續存在。

##### **Movie Gen: A Cast of Media Foundation Models**
2410.13720v1 by Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu Ma, Ishan Misra, Ji Hou, Jialiang Wang, Kiran Jagadeesh, Kunpeng Li, Luxin Zhang, Mannat Singh, Mary Williamson, Matt Le, Matthew Yu, Mitesh Kumar Singh, Peizhao Zhang, Peter Vajda, Quentin Duval, Rohit Girdhar, Roshan Sumbaly, Sai Saketh Rambhatla, Sam Tsai, Samaneh Azadi, Samyak Datta, Sanyuan Chen, Sean Bell, Sharadh Ramaswamy, Shelly Sheynin, Siddharth Bhattacharya, Simran Motwani, Tao Xu, Tianhe Li, Tingbo Hou, Wei-Ning Hsu, Xi Yin, Xiaoliang Dai, Yaniv Taigman, Yaqiao Luo, Yen-Cheng Liu, Yi-Chiao Wu, Yue Zhao, Yuval Kirstain, Zecheng He, Zijian He, Albert Pumarola, Ali Thabet, Artsiom Sanakoyeu, Arun Mallya, Baishan Guo, Boris Araya, Breena Kerr, Carleigh Wood, Ce Liu, Cen Peng, Dimitry Vengertsev, Edgar Schonfeld, Elliot Blanchard, Felix Juefei-Xu, Fraylie Nord, Jeff Liang, John Hoffman, Jonas Kohler, Kaolin Fire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Georgopoulos, Rashel Moritz, Sara K. Sampson, Shikai Li, Simone Parmeggiani, Steve Fine, Tara Fowler, Vladan Petrovic, Yuming Du

We present Movie Gen, a cast of foundation models that generates
high-quality, 1080p HD videos with different aspect ratios and synchronized
audio. We also show additional capabilities such as precise instruction-based
video editing and generation of personalized videos based on a user's image.
Our models set a new state-of-the-art on multiple tasks: text-to-video
synthesis, video personalization, video editing, video-to-audio generation, and
text-to-audio generation. Our largest video generation model is a 30B parameter
transformer trained with a maximum context length of 73K video tokens,
corresponding to a generated video of 16 seconds at 16 frames-per-second. We
show multiple technical innovations and simplifications on the architecture,
latent spaces, training objectives and recipes, data curation, evaluation
protocols, parallelization techniques, and inference optimizations that allow
us to reap the benefits of scaling pre-training data, model size, and training
compute for training large scale media generation models. We hope this paper
helps the research community to accelerate progress and innovation in media
generation models. All videos from this paper are available at
https://go.fb.me/MovieGenResearchVideos.

摘要：我們提出 Movie Gen，一種基礎模型，可產生高品質、1080p HD 影片，具有不同的長寬比和同步音訊。我們也展示其他功能，例如基於精確指示的影片編輯，以及根據使用者的影像產生個人化影片。我們的模型在多項任務中樹立新的技術標竿：文字轉影片合成、影片個人化、影片編輯、影片轉音訊產生，以及文字轉音訊產生。我們最大的影片產生模型是一個 30B 參數轉換器，使用最長 73K 影片代碼訓練，對應於 16 秒、16 幀/秒的產生影片。我們展示了架構、潛在空間、訓練目標和配方、資料整理、評估協定、平行化技術和推論最佳化等多項技術創新和簡化，讓我們能從擴充預訓練資料、模型大小和訓練運算中獲益，以訓練大規模媒體產生模型。我們希望這篇論文能協助研究社群加速媒體產生模型的進展和創新。這篇論文中的所有影片都可以在 https://go.fb.me/MovieGenResearchVideos 取得。

##### **MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems**
2410.13716v1 by Nandan Thakur, Suleman Kazi, Ge Luo, Jimmy Lin, Amin Ahmad

Traditional Retrieval-Augmented Generation (RAG) benchmarks rely on different
heuristic-based metrics for evaluation, but these require human preferences as
ground truth for reference. In contrast, arena-based benchmarks, where two
models compete each other, require an expensive Large Language Model (LLM) as a
judge for a reliable evaluation. We present an easy and efficient technique to
get the best of both worlds. The idea is to train a learning to rank model as a
"surrogate" judge using RAG-based evaluation heuristics as input, to produce a
synthetic arena-based leaderboard. Using this idea, We develop MIRAGE-Bench, a
standardized arena-based multilingual RAG benchmark for 18 diverse languages on
Wikipedia. The benchmark is constructed using MIRACL, a retrieval dataset, and
extended for multilingual generation evaluation. MIRAGE-Bench evaluates RAG
extensively coupling both heuristic features and LLM as a judge evaluator. In
our work, we benchmark 19 diverse multilingual-focused LLMs, and achieve a high
correlation (Kendall Tau ($\tau$) = 0.909) using our surrogate judge learned
using heuristic features with pairwise evaluations and between GPT-4o as a
teacher on the MIRAGE-Bench leaderboard using the Bradley-Terry framework. We
observe proprietary and large open-source LLMs currently dominate in
multilingual RAG. MIRAGE-Bench is available at:
https://github.com/vectara/mirage-bench.

摘要：傳統的檢索增強生成（RAG）基準依賴於不同的基於啟發式的指標進行評估，但這些指標需要人類偏好作為參考的真實依據。相比之下，競技場基準，其中兩個模型相互競爭，需要一個昂貴的大語言模型（LLM）作為一個評委，以進行可靠的評估。我們提出了一種輕鬆且有效的方法，以獲得兩全其美的效果。這個想法是訓練一個學習對模型進行排名，作為一個「代理」評委，使用基於 RAG 的評估啟發式方法作為輸入，以產生一個綜合的競技場排行榜。利用這個想法，我們開發了 MIRAGE-Bench，一個標準化的基於競技場的多語言 RAG 基準，適用於維基百科上的 18 種不同的語言。該基準是使用檢索數據集 MIRACL 構建的，並擴展用於多語言生成評估。MIRAGE-Bench 對 RAG 進行廣泛評估，同時將啟發式特徵和 LLM 作為評委評估器結合起來。在我們的研究中，我們對 19 個不同的多語言 LLM 進行了基準測試，並使用我們的代理評委學習的啟發式特徵和成對評估，以及使用 Bradley-Terry 框架在 MIRAGE-Bench 排行榜上將 GPT-4o 作為教師，實現了很高的相關性（Kendall Tau（τ）= 0.909）。我們觀察到專有的大型開源 LLM 目前在多語言 RAG 中佔據主導地位。MIRAGE-Bench 可在以下網址獲得：https://github.com/vectara/mirage-bench。

##### **On the Role of Attention Heads in Large Language Model Safety**
2410.13708v1 by Zhenhong Zhou, Haiyang Yu, Xinghua Zhang, Rongwu Xu, Fei Huang, Kun Wang, Yang Liu, Junfeng Fang, Yongbin Li

Large language models (LLMs) achieve state-of-the-art performance on multiple
language tasks, yet their safety guardrails can be circumvented, leading to
harmful generations. In light of this, recent research on safety mechanisms has
emerged, revealing that when safety representations or component are
suppressed, the safety capability of LLMs are compromised. However, existing
research tends to overlook the safety impact of multi-head attention
mechanisms, despite their crucial role in various model functionalities. Hence,
in this paper, we aim to explore the connection between standard attention
mechanisms and safety capability to fill this gap in the safety-related
mechanistic interpretability. We propose a novel metric which tailored for
multi-head attention, the Safety Head ImPortant Score (Ships), to assess the
individual heads' contributions to model safety. Based on this, we generalize
Ships to the dataset level and further introduce the Safety Attention Head
AttRibution Algorithm (Sahara) to attribute the critical safety attention heads
inside the model. Our findings show that the special attention head has a
significant impact on safety. Ablating a single safety head allows aligned
model (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,
while only modifying 0.006% of the parameters, in contrast to the ~ 5%
modification required in previous studies. More importantly, we demonstrate
that attention heads primarily function as feature extractors for safety and
models fine-tuned from the same base model exhibit overlapping safety heads
through comprehensive experiments. Together, our attribution approach and
findings provide a novel perspective for unpacking the black box of safety
mechanisms within large models.

摘要：大型語言模型 (LLM) 在多種語言任務上實現最先進的效能，但其安全防護措施可能會被規避，導致有害的生成。有鑑於此，最近關於安全機制的的研究應運而生，揭示了當安全表示或組成受到抑制時，LLM 的安全能力會受到損害。然而，現有的研究傾向於忽略多頭注意力機制對安全性的影響，儘管它們在各種模型功能中扮演著至關重要的角色。因此，在本文中，我們旨在探討標準注意力機制與安全能力之間的關聯，以填補與安全相關的機制可解釋性中的這項空白。我們提出了一個針對多頭注意力量身打造的新指標，稱為安全頭部重要分數 (Ships)，以評估各個頭部對模型安全性的貢獻。基於此，我們將 Ships 推廣到資料集層級，並進一步引入安全注意力頭部歸因演算法 (Sahara)，以歸因模型內部關鍵的安全注意力頭部。我們的研究結果表明，特殊的注意力頭部對安全性有顯著的影響。消融單一安全頭部允許對齊模型（例如 Llama-2-7b-chat）回應多出 16 倍的有害查詢，同時只修改了 0.006% 的參數，這與先前的研究中所需約 5% 的修改形成對比。更重要的是，我們證明注意力頭部主要充當安全性的特徵萃取器，並且從同一個基礎模型微調的模型透過全面的實驗表現出重疊的安全頭部。我們的歸因方法和研究結果共同為解開大型模型中安全機制的黑箱提供了新的觀點。

##### **Disjointness Violations in Wikidata**
2410.13707v1 by Ege Atacan Doğan, Peter F. Patel-Schneider

Disjointness checks are among the most important constraint checks in a
knowledge base and can be used to help detect and correct incorrect statements
and internal contradictions. Wikidata is a very large, community-managed
knowledge base. Because of both its size and construction, Wikidata contains
many incorrect statements and internal contradictions. We analyze the current
modeling of disjointness on Wikidata, identify patterns that cause these
disjointness violations and categorize them. We use SPARQL queries to identify
each ``culprit'' causing a disjointness violation and lay out formulas to
identify and fix conflicting information. We finally discuss how disjointness
information could be better modeled and expanded in Wikidata in the future.

摘要：分離性檢查是知識庫中最重要的一種約束檢查，可用於幫助偵測並修正不正確的陳述和內部矛盾。維基數據是一個非常龐大、由社群管理的知識庫。由於其規模和結構，維基數據包含許多不正確的陳述和內部矛盾。我們分析了維基數據上分離性的目前建模，找出導致這些分離性違規的模式並對其進行分類。我們使用 SPARQL 查詢來找出造成分離性違規的每個「罪魁禍首」，並提出公式來找出並修正衝突的資訊。我們最後討論如何讓分離性資訊在未來的維基數據中獲得更好的建模和擴充。

##### **Unconstrained Model Merging for Enhanced LLM Reasoning**
2410.13699v1 by Yiming Zhang, Baoyi He, Shengyu Zhang, Yuhao Fu, Qi Zhou, Zhijie Sang, Zijin Hong, Kejing Yang, Wenjun Wang, Jianbo Yuan, Guangning Han, Linyi Li, Chunlin Ji, Fei Wu, Hongxia Yang

Recent advancements in building domain-specific large language models (LLMs)
have shown remarkable success, especially in tasks requiring reasoning
abilities like logical inference over complex relationships and multi-step
problem solving. However, creating a powerful all-in-one LLM remains
challenging due to the need for proprietary data and vast computational
resources. As a resource-friendly alternative, we explore the potential of
merging multiple expert models into a single LLM. Existing studies on model
merging mainly focus on generalist LLMs instead of domain experts, or the LLMs
under the same architecture and size. In this work, we propose an unconstrained
model merging framework that accommodates both homogeneous and heterogeneous
model architectures with a focus on reasoning tasks. A fine-grained layer-wise
weight merging strategy is designed for homogeneous models merging, while
heterogeneous model merging is built upon the probabilistic distribution
knowledge derived from instruction-response fine-tuning data. Across 7
benchmarks and 9 reasoning-optimized LLMs, we reveal key findings that
combinatorial reasoning emerges from merging which surpasses simple additive
effects. We propose that unconstrained model merging could serve as a
foundation for decentralized LLMs, marking a notable progression from the
existing centralized LLM framework. This evolution could enhance wider
participation and stimulate additional advancement in the field of artificial
intelligence, effectively addressing the constraints posed by centralized
models.

摘要：最近在建構特定領域大型語言模型 (LLM) 的進展中，已展現出顯著的成功，特別是在需要推理能力的任務中，例如對複雜關係的邏輯推論和多步驟問題解決。然而，由於需要專有資料和龐大的運算資源，要建構一個功能強大的多合一 LLM 仍然具有挑戰性。作為一種資源友善的替代方案，我們探索了將多個專家模型合併成單一 LLM 的可能性。現有的模型合併研究主要集中在通才 LLM 而不是領域專家，或架構和規模相同的 LLM。在這項工作中，我們提出了一個不受約束的模型合併框架，它能容納同質和異質模型架構，並專注於推理任務。針對同質模型合併設計了一個細粒度的逐層權重合併策略，而異質模型合併則建立在從指令回應微調資料中衍生的機率分佈知識之上。在 7 個基準和 9 個經過推理最佳化的 LLM 中，我們揭示了關鍵發現，即組合推理源自合併，這種合併超越了簡單的加法效應。我們提出不受約束的模型合併可以作為分散式 LLM 的基礎，標誌著從現有的集中式 LLM 框架中取得顯著進展。這種演變可以擴大參與度，並刺激人工智慧領域的進一步進展，有效解決集中式模型所造成的限制。

##### **Exploring the Design Space of Visual Context Representation in Video MLLMs**
2410.13694v1 by Yifan Du, Yuqi Huo, Kun Zhou, Zijia Zhao, Haoyu Lu, Han Huang, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

Video Multimodal Large Language Models (MLLMs) have shown remarkable
capability of understanding the video semantics on various downstream tasks.
Despite the advancements, there is still a lack of systematic research on
visual context representation, which refers to the scheme to select frames from
a video and further select the tokens from a frame. In this paper, we explore
the design space for visual context representation, and aim to improve the
performance of video MLLMs by finding more effective representation schemes.
Firstly, we formulate the task of visual context representation as a
constrained optimization problem, and model the language modeling loss as a
function of the number of frames and the number of embeddings (or tokens) per
frame, given the maximum visual context window size. Then, we explore the
scaling effects in frame selection and token selection respectively, and fit
the corresponding function curve by conducting extensive empirical experiments.
We examine the effectiveness of typical selection strategies and present
empirical findings to determine the two factors. Furthermore, we study the
joint effect of frame selection and token selection, and derive the optimal
formula for determining the two factors. We demonstrate that the derived
optimal settings show alignment with the best-performed results of empirical
experiments. Our code and model are available at:
https://github.com/RUCAIBox/Opt-Visor.

摘要：影片多模態大型語言模型 (MLLM) 已展現出理解影片語意的卓越能力，可運用於各種下游任務。儘管有這些進展，但對於視覺脈絡表徵仍缺乏系統性的研究，這指的是從影片中選取畫格，並進一步從畫格中選取符號的方案。在本文中，我們探討視覺脈絡表徵的設計空間，並旨在透過找出更有效的表徵方案來提升影片 MLLM 的效能。首先，我們將視覺脈絡表徵的任務制定為受約束的最佳化問題，並將語言模型損失建模為在給定最大視覺脈絡視窗大小的情況下，畫格數目與每個畫格的嵌入 (或符號) 數目的函數。然後，我們分別探討畫格選取與符號選取中的縮放效應，並透過進行廣泛的實證實驗來擬合對應的函數曲線。我們檢視典型選取策略的效能，並提出實證結果來確定這兩個因素。此外，我們研究畫格選取與符號選取的共同效應，並推導出決定這兩個因素的最適公式。我們證明，所推導出的最適設定與實證實驗中表現最佳的結果相符。我們的程式碼和模型可在 https://github.com/RUCAIBox/Opt-Visor 取得。

##### **Jailbreaking LLM-Controlled Robots**
2410.13691v1 by Alexander Robey, Zachary Ravichandran, Vijay Kumar, Hamed Hassani, George J. Pappas

The recent introduction of large language models (LLMs) has revolutionized
the field of robotics by enabling contextual reasoning and intuitive
human-robot interaction in domains as varied as manipulation, locomotion, and
self-driving vehicles. When viewed as a stand-alone technology, LLMs are known
to be vulnerable to jailbreaking attacks, wherein malicious prompters elicit
harmful text by bypassing LLM safety guardrails. To assess the risks of
deploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first
algorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual
attacks on LLM chatbots, RoboPAIR elicits harmful physical actions from
LLM-controlled robots, a phenomenon we experimentally demonstrate in three
scenarios: (i) a white-box setting, wherein the attacker has full access to the
NVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker
has partial access to a Clearpath Robotics Jackal UGV robot equipped with a
GPT-4o planner, and (iii) a black-box setting, wherein the attacker has only
query access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each
scenario and across three new datasets of harmful robotic actions, we
demonstrate that RoboPAIR, as well as several static baselines, finds
jailbreaks quickly and effectively, often achieving 100% attack success rates.
Our results reveal, for the first time, that the risks of jailbroken LLMs
extend far beyond text generation, given the distinct possibility that
jailbroken robots could cause physical damage in the real world. Indeed, our
results on the Unitree Go2 represent the first successful jailbreak of a
deployed commercial robotic system. Addressing this emerging vulnerability is
critical for ensuring the safe deployment of LLMs in robotics. Additional media
is available at: https://robopair.org

摘要：大型語言模型 (LLM) 近期導入後，透過在操縱、運動和自駕車輛等領域中實現情境推理和直覺式人機互動，徹底革新了機器人技術領域。若視為獨立技術，LLM 已知容易受到越獄攻擊，其中惡意提示者透過繞過 LLM 安全防護來引發有害文本。為了評估在機器人技術中部署 LLM 的風險，我們在本文中介紹 RoboPAIR，這是第一個旨在越獄 LLM 控制機器人的演算法。與現有的 LLM 聊天機器人文字攻擊不同，RoboPAIR 會引發 LLM 控制機器人的有害實體動作，我們在三個情境中以實驗方式展示此現象：(i) 白盒設定，其中攻擊者可以完全存取 NVIDIA Dolphins 自駕 LLM，(ii) 灰盒設定，其中攻擊者可以部分存取配備 GPT-4o 規劃器的 Clearpath Robotics Jackal UGV 機器人，以及 (iii) 黑盒設定，其中攻擊者僅能查詢整合 GPT-3.5 的 Unitree Robotics Go2 機器人狗。在每個情境和三個新的有害機器人動作資料集中，我們展示 RoboPAIR 和幾個靜態基線可以快速有效地找到越獄，通常可達成 100% 的攻擊成功率。我們的結果首次揭露，越獄 LLM 的風險遠遠超出文字產生，因為越獄機器人極有可能在現實世界中造成實體損害。事實上，我們在 Unitree Go2 上的結果代表首次成功越獄已部署的商用機器人系統。解決這個新興的漏洞對於確保 LLM 在機器人技術中的安全部署至關重要。其他媒體可於 https://robopair.org 取得

##### **Pose-Based Sign Language Appearance Transfer**
2410.13675v1 by Amit Moryossef, Gerard Sant, Zifan Jiang

We introduce a method for transferring the signer's appearance in sign
language skeletal poses while preserving the sign content. Using estimated
poses, we transfer the appearance of one signer to another, maintaining natural
movements and transitions. This approach improves pose-based rendering and sign
stitching while obfuscating identity. Our experiments show that while the
method reduces signer identification accuracy, it slightly harms sign
recognition performance, highlighting a tradeoff between privacy and utility.
Our code is available at
\url{https://github.com/sign-language-processing/pose-anonymization}.

摘要：我們提出了一種方法，可以在保留手語內容的同時，傳遞手語姿勢中的簽署者的外觀。使用估計的姿勢，我們將一個簽署者的外觀轉移到另一個簽署者，同時保持自然的動作和過渡。這種方法改進了基於姿勢的渲染和手語拼接，同時混淆了身份。我們的實驗表明，雖然這種方法降低了簽署者識別的準確性，但它對手語識別的性能略有損害，突顯了隱私和效用之間的權衡。我們的代碼可在
\url{https://github.com/sign-language-processing/pose-anonymization} 取得。

##### **Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion**
2410.13674v1 by Yijun Liang, Shweta Bhardwaj, Tianyi Zhou

Low-quality or scarce data has posed significant challenges for training deep
neural networks in practice. While classical data augmentation cannot
contribute very different new data, diffusion models opens up a new door to
build self-evolving AI by generating high-quality and diverse synthetic data
through text-guided prompts. However, text-only guidance cannot control
synthetic images' proximity to the original images, resulting in
out-of-distribution data detrimental to the model performance. To overcome the
limitation, we study image guidance to achieve a spectrum of interpolations
between synthetic and real images. With stronger image guidance, the generated
images are similar to the training data but hard to learn. While with weaker
image guidance, the synthetic images will be easier for model but contribute to
a larger distribution gap with the original data. The generated full spectrum
of data enables us to build a novel "Diffusion Curriculum (DisCL)". DisCL
adjusts the image guidance level of image synthesis for each training stage: It
identifies and focuses on hard samples for the model and assesses the most
effective guidance level of synthetic images to improve hard data learning. We
apply DisCL to two challenging tasks: long-tail (LT) classification and
learning from low-quality data. It focuses on lower-guidance images of
high-quality to learn prototypical features as a warm-up of learning
higher-guidance images that might be weak on diversity or quality. Extensive
experiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when
applying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base
model's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%
improvement in all-class accuracy.

摘要：<paragraph>低品質或稀缺的資料對訓練深度神經網路造成了重大的挑戰。雖然傳統的資料擴充無法提供非常不同的新資料，但擴散模型開啟了一扇新門，透過文字引導提示來產生高品質且多樣化的合成資料，進而建構自我演化的 AI。然而，僅有文字引導無法控制合成影像與原始影像的接近程度，導致產生對模型效能不利的分布外資料。為了克服這個限制，我們研究影像引導以在合成影像與真實影像之間達成一系列的內插。透過更強的影像引導，產生的影像類似於訓練資料，但難以學習。而透過較弱的影像引導，合成的影像對模型來說會較容易，但會導致與原始資料有較大的分布差距。所產生的資料全光譜讓我們能夠建構一個新穎的「擴散課程（DisCL）」。DisCL 調整每個訓練階段的影像合成影像引導層級：它找出並專注於模型的困難樣本，並評估合成影像最有效的引導層級，以改善困難資料的學習。我們將 DisCL 套用於兩個具有挑戰性的任務：長尾（LT）分類和從低品質資料中學習。它專注於高品質的較低引導影像，以學習原型特徵，作為學習可能在多樣性或品質上較弱的較高引導影像的熱身。廣泛的實驗顯示，當將 DisCL 套用於 iWildCam 資料集時，OOD 和 ID 巨觀準確度分別獲得 2.7% 和 2.1% 的提升。在 ImageNet-LT 上，DisCL 將基礎模型的尾類準確度從 4.4% 提升至 23.64%，並使全類準確度提升 4.02%。</paragraph>

##### **HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings**
2410.13671v1 by Varun Gumma, Anandhita Raghunath, Mohit Jain, Sunayana Sitaram

Assessing the capabilities and limitations of large language models (LLMs)
has garnered significant interest, yet the evaluation of multiple models in
real-world scenarios remains rare. Multilingual evaluation often relies on
translated benchmarks, which typically do not capture linguistic and cultural
nuances present in the source language. This study provides an extensive
assessment of 24 LLMs on real world data collected from Indian patients
interacting with a medical chatbot in Indian English and 4 other Indic
languages. We employ a uniform Retrieval Augmented Generation framework to
generate responses, which are evaluated using both automated techniques and
human evaluators on four specific metrics relevant to our application. We find
that models vary significantly in their performance and that instruction tuned
Indic models do not always perform well on Indic language queries. Further, we
empirically show that factual correctness is generally lower for responses to
Indic queries compared to English queries. Finally, our qualitative work shows
that code-mixed and culturally relevant queries in our dataset pose challenges
to evaluated models.

摘要：評估大型語言模型 (LLM) 的能力和限制已引起極大興趣，但在實際情況中評估多個模型的情況仍然很少見。多語言評估通常依賴於翻譯基準，而翻譯基準通常無法捕捉到原始語言中存在的語言和文化差異。本研究對 24 個 LLM 進行了廣泛評估，這些 LLM 來自與印度病患互動的醫療聊天機器人所收集的真實世界資料，這些病患使用印度英語和其他 4 種印度語言。我們採用統一的檢索擴增生成架構來產生回應，並使用自動化技術和人類評估員對四個與我們的應用程式相關的特定指標進行評估。我們發現，模型的效能差異很大，而且針對指示調整的印度語言模型在印度語言查詢中的表現並不總是很好。此外，我們憑經驗顯示，與英語查詢相比，印度語言查詢的回應事實正確性通常較低。最後，我們的質化研究顯示，資料集中混合程式碼和文化相關的查詢對評估模型構成挑戰。

##### **signwriting-evaluation: Effective Sign Language Evaluation via SignWriting**
2410.13668v1 by Amit Moryossef, Rotem Zilberman, Ohad Langer

The lack of automatic evaluation metrics tailored for SignWriting presents a
significant obstacle in developing effective transcription and translation
models for signed languages. This paper introduces a comprehensive suite of
evaluation metrics specifically designed for SignWriting, including adaptations
of standard metrics such as \texttt{BLEU} and \texttt{chrF}, the application of
\texttt{CLIPScore} to SignWriting images, and a novel symbol distance metric
unique to our approach. We address the distinct challenges of evaluating single
signs versus continuous signing and provide qualitative demonstrations of
metric efficacy through score distribution analyses and nearest-neighbor
searches within the SignBank corpus. Our findings reveal the strengths and
limitations of each metric, offering valuable insights for future advancements
using SignWriting. This work contributes essential tools for evaluating
SignWriting models, facilitating progress in the field of sign language
processing. Our code is available at
\url{https://github.com/sign-language-processing/signwriting-evaluation}.

摘要：缺乏針對手語書寫量身打造的自動評量指標，為手語的轉錄和翻譯模型的開發帶來重大的障礙。本文介紹了一套專門為手語書寫設計的完整評量指標，包括標準指標的改編，例如 \texttt{BLEU} 和 \texttt{chrF}、\texttt{CLIPScore} 對手語書寫影像的應用，以及我們方法獨有的新符號距離指標。我們解決了評量單一符號與連續手語的獨特挑戰，並透過分數分佈分析和 SignBank 語料庫中的最近鄰搜尋，提供了指標效能的定性示範。我們的發現揭示了每個指標的優點和限制，為未來使用手語書寫的進展提供了寶貴的見解。這項工作為評量手語書寫模型提供了必要的工具，促進手語處理領域的進展。我們的程式碼可在
\url{https://github.com/sign-language-processing/signwriting-evaluation} 取得。

##### **ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization**
2410.13667v1 by Xiutian Zhao, Ke Wang, Wei Peng

Dialogue agents have been receiving increasing attention for years, and this
trend has been further boosted by the recent progress of large language models
(LLMs). Stance detection and dialogue summarization are two core tasks of
dialogue agents in application scenarios that involve argumentative dialogues.
However, research on these tasks is limited by the insufficiency of public
datasets, especially for non-English languages. To address this language
resource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first
Chinese dataset for benchmarking target-independent stance detection and debate
summarization. Our dataset consists of 1,218 real-world debates that were
conducted in Chinese on 476 unique topics, containing 2,436 stance-specific
summaries and 14,133 fully annotated utterances. Besides providing a versatile
testbed for future research, we also conduct an empirical study on the dataset
and propose an integrated task. The results show the challenging nature of the
dataset and suggest a potential of incorporating stance detection in
summarization for argumentative dialogue.

摘要：對話代理程式多年來一直備受關注，而大型語言模型 (LLM) 的最新進展進一步推動了這股趨勢。立場檢測和對話摘要是對話代理程式在涉及論證對話的應用場景中的兩項核心任務。然而，這些任務的研究受到公共資料集不足的限制，特別是非英語語言。為了解決中文中的這種語言資源差距，我們提出了 ORCHID（口語中文辯論），這是第一個用於基準測試目標無關立場檢測和辯論摘要的中文資料集。我們的資料集包含 1,218 場在 476 個獨特主題上以中文進行的真實世界辯論，其中包含 2,436 個特定立場摘要和 14,133 個完全註解的發言。除了為未來的研究提供一個通用的測試平台外，我們還對資料集進行了實證研究，並提出了整合任務。結果顯示了資料集的挑戰性，並建議將立場檢測納入論證對話的摘要中。

##### **VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks**
2410.13666v1 by Shailaja Keyur Sampat, Mutsumi Nakamura, Shankar Kailas, Kartik Aggarwal, Mandy Zhou, Yezhou Yang, Chitta Baral

Deriving inference from heterogeneous inputs (such as images, text, and
audio) is an important skill for humans to perform day-to-day tasks. A similar
ability is desirable for the development of advanced Artificial Intelligence
(AI) systems. While state-of-the-art models are rapidly closing the gap with
human-level performance on diverse computer vision and NLP tasks separately,
they struggle to solve tasks that require joint reasoning over visual and
textual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask
benchmark for natural language understanding, we propose VL-GLUE in this paper.
VL-GLUE consists of over 100k samples spanned across seven different tasks,
which at their core require visuo-linguistic reasoning. Moreover, our benchmark
comprises of diverse image types (from synthetically rendered figures, and
day-to-day scenes to charts and complex diagrams) and includes a broad variety
of domain-specific text (from cooking, politics, and sports to high-school
curricula), demonstrating the need for multi-modal understanding in the
real-world. We show that this benchmark is quite challenging for existing
large-scale vision-language models and encourage development of systems that
possess robust visuo-linguistic reasoning capabilities.

摘要：從異質輸入（例如影像、文字和音訊）中推論是人類執行日常任務的一項重要技能。先進的人工智慧 (AI) 系統的開發也需要類似的能力。雖然最先進的模型在不同的電腦視覺和 NLP 任務中迅速縮小與人類表現的差距，但它們難以解決需要對視覺和文字模式進行聯合推理的任務。受到 GLUE (Wang et. al., 2018) 的啟發，這是一個自然語言理解的多任務基準，我們在這篇論文中提出 VL-GLUE。VL-GLUE 由超過 100k 個樣本組成，涵蓋七項不同的任務，這些任務的核心需要視覺語言推理。此外，我們的基準包含各種影像類型（從合成渲染的人物、日常場景到圖表和複雜的圖表），並包含廣泛的領域特定文字（從烹飪、政治和體育到高中課程），證明了在現實世界中對多模式理解的需求。我們證明這個基準對於現有的大型視覺語言模型來說非常具有挑戰性，並鼓勵開發具備強健視覺語言推理能力的系統。

##### **Red and blue language: Word choices in the Trump & Harris 2024 presidential debate**
2410.13654v1 by Philipp Wicke, Marianna M. Bolognesi

Political debates are a peculiar type of political discourse, in which
candidates directly confront one another, addressing not only the the
moderator's questions, but also their opponent's statements, as well as the
concerns of voters from both parties and undecided voters. Therefore, language
is adjusted to meet specific expectations and achieve persuasion. We analyse
how the language of Trump and Harris during the debate (September 10th 2024)
differs in relation to the following semantic and pragmatic features, for which
we formulated targeted hypotheses: framing values and ideology, appealing to
emotion, using words with different degrees of concreteness and specificity,
addressing others through singular or plural pronouns. Our findings include:
differences in the use of figurative frames (Harris often framing issues around
recovery and empowerment, Trump often focused on crisis and decline); similar
use of emotional language, with Trump showing a slight higher tendency toward
negativity and toward less subjective language compared to Harris; no
significant difference in the specificity of candidates' responses; similar use
of abstract language, with Trump showing more variability than Harris,
depending on the subject discussed; differences in addressing the opponent,
with Trump not mentioning Harris by name, while Harris referring to Trump
frequently; different uses of pronouns, with Harris using both singular and
plural pronouns equally, while Trump using more singular pronouns. The results
are discussed in relation to previous literature on Red and Blue language,
which refers to distinct linguistic patterns associated with conservative (Red)
and liberal (Blue) political ideologies.

摘要：政治辯論是一種特殊的政治論述，其中候選人直接面對彼此，不僅回答主持人提出的問題，還回答對手的陳述，以及來自雙方選民和未定選民的關注。因此，語言會調整以符合具體的期望並實現說服。我們分析了川普和賀錦麗在辯論（2024 年 9 月 10 日）中使用的語言在以下語義和語用特徵方面的差異，我們針對這些特徵制定了有針對性的假設：價值觀和意識形態的框架、訴諸情感、使用具不同程度具體性和特異性的詞彙、通過單數或複數代詞來稱呼他人。我們的研究結果包括：比喻性框架的使用差異（賀錦麗經常圍繞復甦和賦權來構建問題，川普則經常關注危機和衰退）；類似的情感語言使用，與賀錦麗相比，川普表現出對消極性和主觀性語言的傾向略高；候選人回應的具體性沒有顯著差異；抽象語言的相似使用，與賀錦麗相比，川普表現出更多可變性，具體取決於討論的主題；在稱呼對手方面存在差異，川普沒有指名道姓提到賀錦麗，而賀錦麗則經常提到川普；代詞的不同使用，賀錦麗同時使用單數和複數代詞，而川普則更多地使用單數代詞。這些結果與之前關於紅藍語言的文獻相關，紅藍語言是指與保守派（紅色）和自由派（藍色）政治意識形態相關的不同語言模式。

##### **SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs**
2410.13648v1 by Yuling Gu, Oyvind Tafjord, Hyunwoo Kim, Jared Moore, Ronan Le Bras, Peter Clark, Yejin Choi

While prior work has explored whether large language models (LLMs) possess a
"theory of mind" (ToM) - the ability to attribute mental states to oneself and
others - there has been little work testing whether LLMs can implicitly apply
such knowledge to predict behavior, or to judge whether an observed behavior is
rational. Such skills are critical for appropriate interaction in social
environments. We create a new dataset, SimpleTom, containing concise, diverse
stories (e.g., "The can of Pringles has moldy chips in it. Mary picks up the
can in the supermarket and walks to the cashier."), each with three questions
that test different degrees of ToM reasoning, asking models to predict (a)
mental state ("Is Mary aware of the mold?"), (b) behavior ("Will Mary pay for
the chips or report the mold?"), and (c) judgment ("Mary paid for the chips.
Was that reasonable?"). To our knowledge, SimpleToM is the first dataset to
systematically explore downstream reasoning requiring knowledge of mental
states in realistic scenarios. Our experimental results are intriguing: While
most models can reliably predict mental state on our dataset (a), they often
fail to correctly predict the behavior (b), and fare even worse at judging
whether given behaviors are reasonable (c), despite being correctly aware of
the protagonist's mental state should make such secondary predictions obvious.
We further show that we can help models do better at (b) and (c) via
interventions such as reminding the model of its earlier mental state answer
and mental-state-specific chain-of-thought prompting, raising the action
prediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment
accuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models
can be coaxed to perform well, it requires task-specific interventions, and the
natural model performances remain low, a cautionary tale for LLM deployment.

摘要：<paragraph>雖然先前的研究已探討大型語言模型 (LLM) 是否具備「心智理論」(ToM) - 能將心智狀態歸因於自己和他人的能力 - 但鮮少有研究測試 LLM 是否能隱含地應用此類知識來預測行為，或判斷觀察到的行為是否合理。此類技能對於在社交環境中適當地互動至關重要。我們建立了一個新資料集 SimpleTom，其中包含簡潔且多元的故事（例如，「普林格斯洋芋片罐裡有發霉的洋芋片。瑪麗在超市拿起該罐子並走向收銀台。」），每個故事包含三個問題，測試不同程度的 ToM 推理，要求模型預測 (a) 心智狀態（「瑪麗是否知道發霉了？」），(b) 行為（「瑪麗會付錢買洋芋片還是回報發霉的情況？」），以及 (c) 判斷（「瑪麗付了洋芋片的錢。這是否合理？」）。據我們所知，SimpleToM 是第一個系統性地探討需要在現實情境中了解心智狀態的下游推理的資料集。我們的實驗結果令人著迷：雖然大多數模型都能在我們的資料集 (a) 中可靠地預測心智狀態，但它們通常無法正確預測行為 (b)，而且在判斷特定行為是否合理 (c) 方面的表現更差，儘管它們正確地意識到主角的心智狀態應該讓此類次要預測顯而易見。我們進一步表明，我們可以透過干預措施讓模型在 (b) 和 (c) 中表現得更好，例如提醒模型其早先的心智狀態答案和心智狀態特定的思考鏈提示，從而提高動作預測準確度（例如，GPT-4o 從 49.5% 提高到 93.5%）和判斷準確度（例如，GPT-4o 從 15.3% 提高到 94.7%）。雖然這表明可以誘導模型表現良好，但它需要特定於任務的干預措施，而且自然模型的表現仍然很低，這對於 LLM 部署來說是一個警示故事。</paragraph>

##### **Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design**
2410.13643v1 by Chenyu Wang, Masatoshi Uehara, Yichun He, Amy Wang, Tommaso Biancalani, Avantika Lal, Tommi Jaakkola, Sergey Levine, Hanchen Wang, Aviv Regev

Recent studies have demonstrated the strong empirical performance of
diffusion models on discrete sequences across domains from natural language to
biological sequence generation. For example, in the protein inverse folding
task, conditional diffusion models have achieved impressive results in
generating natural-like sequences that fold back into the original structure.
However, practical design tasks often require not only modeling a conditional
distribution but also optimizing specific task objectives. For instance, we may
prefer protein sequences with high stability. To address this, we consider the
scenario where we have pre-trained discrete diffusion models that can generate
natural-like sequences, as well as reward models that map sequences to task
objectives. We then formulate the reward maximization problem within discrete
diffusion models, analogous to reinforcement learning (RL), while minimizing
the KL divergence against pretrained diffusion models to preserve naturalness.
To solve this RL problem, we propose a novel algorithm, DRAKES, that enables
direct backpropagation of rewards through entire trajectories generated by
diffusion models, by making the originally non-differentiable trajectories
differentiable using the Gumbel-Softmax trick. Our theoretical analysis
indicates that our approach can generate sequences that are both natural-like
and yield high rewards. While similar tasks have been recently explored in
diffusion models for continuous domains, our work addresses unique algorithmic
and theoretical challenges specific to discrete diffusion models, which arise
from their foundation in continuous-time Markov chains rather than Brownian
motion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA
and protein sequences that optimize enhancer activity and protein stability,
respectively, important tasks for gene therapies and protein-based
therapeutics.

摘要：<paragraph>最近的研究表明，扩散模型在从自然语言到生物序列生成的不同领域离散序列上的强劲经验表现。例如，在蛋白质逆折叠任务中，条件扩散模型在生成可折叠回原始结构的自然序列方面取得了令人印象深刻的结果。然而，实际设计任务通常不仅需要对条件分布进行建模，还需要优化特定的任务目标。例如，我们可能更喜欢具有高稳定性的蛋白质序列。为了解决这个问题，我们考虑了这样一个场景：我们有预先训练好的离散扩散模型，可以生成自然序列，以及将序列映射到任务目标的奖励模型。然后，我们在离散扩散模型中制定奖励最大化问题，类似于强化学习 (RL)，同时最小化与预训练扩散模型的 KL 散度，以保持自然性。为了解决这个 RL 问题，我们提出了一种新算法 DRAKES，它可以通过使用 Gumbel-Softmax 技巧使原本不可微分的轨迹可微分，从而实现通过扩散模型生成的整个轨迹的奖励的直接反向传播。我们的理论分析表明，我们的方法可以生成既自然又产生高奖励的序列。虽然类似的任务最近在连续域的扩散模型中得到了探索，但我们的工作解决了离散扩散模型特有的独特的算法和理论挑战，这些挑战源于它们建立在连续时间马尔可夫链而不是布朗运动之上。最后，我们展示了 DRAKES 在生成分别优化增强剂活性和蛋白质稳定性的 DNA 和蛋白质序列方面的有效性，这对基因疗法和基于蛋白质的疗法来说都是重要的任务。</paragraph>

##### **An Active Learning Framework for Inclusive Generation by Large Language Models**
2410.13641v1 by Sabit Hassan, Anthony Sicilia, Malihe Alikhani

Ensuring that Large Language Models (LLMs) generate text representative of
diverse sub-populations is essential, particularly when key concepts related to
under-represented groups are scarce in the training data. We address this
challenge with a novel clustering-based active learning framework, enhanced
with knowledge distillation. The proposed framework transforms the intermediate
outputs of the learner model, enabling effective active learning for generative
tasks for the first time. Integration of clustering and knowledge distillation
yields more representative models without prior knowledge of underlying data
distribution and overbearing human efforts. We validate our approach in
practice through case studies in counter-narration and style transfer. We
construct two new datasets in tandem with model training, showing a performance
improvement of 2%-10% over baseline models. Our results also show more
consistent performance across various data subgroups and increased lexical
diversity, underscoring our model's resilience to skewness in available data.
Further, our results show that the data acquired via our approach improves the
performance of secondary models not involved in the learning loop, showcasing
practical utility of the framework.

摘要：確保大型語言模型 (LLM) 產生的文字能代表不同的次族群，這點很重要，特別是在訓練資料中與代表性不足的族群相關的重要概念很稀少時。我們透過一種新的基於聚類的主動學習架構來應對這個挑戰，並利用知識萃取來增強。所提出的架構轉換了學習者模型的中間輸出，首次能讓生成式任務進行有效的主動學習。整合聚類和知識萃取，在沒有底層資料分佈和過度人力介入的先備知識下，就能產生更具代表性的模型。我們透過反敘述和風格轉換的案例研究，在實務中驗證了我們的做法。我們在模型訓練的同時建構了兩個新的資料集，顯示比基準模型提升了 2%-10% 的效能。我們的結果也顯示在各種資料子群中效能更一致，且詞彙更多元，強調了我們的模型對於可用資料的偏誤具有韌性。此外，我們的結果顯示，透過我們的方法所取得的資料能提升未參與學習迴圈的次要模型的效能，展示了這個架構的實用性。

##### **Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation**
2410.13640v1 by Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Rui Wang

LLM self-evaluation relies on the LLM's own ability to estimate response
correctness, which can greatly improve its deployment reliability. In this
research track, we propose the Chain-of-Embedding (CoE) in the latent space to
enable LLMs to perform output-free self-evaluation. CoE consists of all
progressive hidden states produced during the inference time, which can be
treated as the latent thinking path of LLMs. We find that when LLMs respond
correctly and incorrectly, their CoE features differ, these discrepancies
assist us in estimating LLM response correctness. Experiments in four diverse
domains and seven LLMs fully demonstrate the effectiveness of our method.
Meanwhile, its label-free design intent without any training and
millisecond-level computational cost ensure real-time feedback in large-scale
scenarios. More importantly, we provide interesting insights into LLM response
correctness from the perspective of hidden state changes inside LLMs.

摘要：LLM 自我評估依賴 LLM 自身估計回應正確性的能力，這可以極大改善其部署可靠性。在此研究軌道中，我們在潛在空間中提出嵌入鏈 (CoE)，以使 LLM 能夠執行無輸出的自我評估。CoE 包含推論時間產生的所有漸進隱藏狀態，這些狀態可視為 LLM 的潛在思考路徑。我們發現當 LLM 正確和不正確地回應時，其 CoE 特徵不同，這些差異有助於我們估計 LLM 回應正確性。在四個不同的領域和七個 LLM 中的實驗充分證明了我們方法的有效性。同時，其無標籤設計意圖在沒有任何訓練和毫秒級計算成本的情況下確保了在大規模場景中的實時反饋。更重要的是，我們從 LLM 內部隱藏狀態變化的角度提供了對 LLM 回應正確性的有趣見解。

##### **A Comparative Study on Reasoning Patterns of OpenAI's o1 Model**
2410.13639v1 by Siwei Wu, Zhongyuan Peng, Xinrun Du, Tuney Zheng, Minghao Liu, Jialong Wu, Jiachen Ma, Yizhi Li, Jian Yang, Wangchunshu Zhou, Qunshu Lin, Junbo Zhao, Zhaoxiang Zhang, Wenhao Huang, Ge Zhang, Chenghua Lin, J. H. Liu

Enabling Large Language Models (LLMs) to handle a wider range of complex
tasks (e.g., coding, math) has drawn great attention from many researchers. As
LLMs continue to evolve, merely increasing the number of model parameters
yields diminishing performance improvements and heavy computational costs.
Recently, OpenAI's o1 model has shown that inference strategies (i.e.,
Test-time Compute methods) can also significantly enhance the reasoning
capabilities of LLMs. However, the mechanisms behind these methods are still
unexplored. In our work, to investigate the reasoning patterns of o1, we
compare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent
Workflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general
reasoning benchmarks in three domains (i.e., math, coding, commonsense
reasoning). Specifically, first, our experiments show that the o1 model has
achieved the best performance on most datasets. Second, as for the methods of
searching diverse responses (e.g., BoN), we find the reward models' capability
and the search space both limit the upper boundary of these methods. Third, as
for the methods that break the problem into many sub-problems, the Agent
Workflow has achieved better performance than Step-wise BoN due to the
domain-specific system prompt for planning better reasoning processes. Fourth,
it is worth mentioning that we have summarized six reasoning patterns of o1,
and provided a detailed analysis on several reasoning benchmarks.

摘要：<paragraph>讓大型語言模型 (LLM) 處理更多種類的複雜任務（例如編碼、數學）已引起許多研究人員的極大關注。由於 LLM 持續演進，單純增加模型參數數量會導致效能提升遞減和巨大的運算成本。最近，OpenAI 的 o1 模型顯示，推理策略（即測試時間運算方法）也能顯著增強 LLM 的推理能力。然而，這些方法背後的機制仍未探究。在我們的研究中，為了探討 o1 的推理模式，我們使用 OpenAI 的 GPT-4o 作為主幹，在三個領域（即數學、編碼、常識推理）的一般推理基準上，將 o1 與現有的測試時間運算方法（BoN、逐步 BoN、代理工作流程和自我精煉）進行比較。具體來說，首先，我們的實驗顯示 o1 模型在大部分資料集上都取得最佳效能。其次，至於搜尋多樣化回應的方法（例如 BoN），我們發現獎勵模型的能力和搜尋空間都限制了這些方法的上限。第三，至於將問題分解成許多子問題的方法，代理工作流程由於特定領域的系統提示，可規劃出更好的推理程序，因此比逐步 BoN 獲得更好的效能。第四，值得一提的是，我們總結了 o1 的六種推理模式，並對幾個推理基準進行了詳細分析。</paragraph>

##### **Scaling Wearable Foundation Models**
2410.13638v1 by Girish Narayanswamy, Xin Liu, Kumar Ayush, Yuzhe Yang, Xuhai Xu, Shun Liao, Jake Garrison, Shyam Tailor, Jake Sunshine, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Jiening Zhan, Mark Malhotra, Shwetak Patel, Samy Abdel-Ghaffar, Daniel McDuff

Wearable sensors have become ubiquitous thanks to a variety of health
tracking features. The resulting continuous and longitudinal measurements from
everyday life generate large volumes of data; however, making sense of these
observations for scientific and actionable insights is non-trivial. Inspired by
the empirical success of generative modeling, where large neural networks learn
powerful representations from vast amounts of text, image, video, or audio
data, we investigate the scaling properties of sensor foundation models across
compute, data, and model size. Using a dataset of up to 40 million hours of
in-situ heart rate, heart rate variability, electrodermal activity,
accelerometer, skin temperature, and altimeter per-minute data from over
165,000 people, we create LSM, a multimodal foundation model built on the
largest wearable-signals dataset with the most extensive range of sensor
modalities to date. Our results establish the scaling laws of LSM for tasks
such as imputation, interpolation and extrapolation, both across time and
sensor modalities. Moreover, we highlight how LSM enables sample-efficient
downstream learning for tasks like exercise and activity recognition.

摘要：<paragraph>穿戴式感測器已變得無所不在，這要歸功於各種健康追蹤功能。從日常生活中產生的連續且長期的測量會產生大量的資料；然而，要讓這些觀察結果產生科學且可行的見解並非易事。受到生成式建模的經驗成功啟發，其中大型神經網路從大量的文字、影像、影片或音訊資料中學習強大的表徵，我們研究了感測器基礎模型在運算、資料和模型大小方面的規模化屬性。我們使用一個資料集，其中包含來自超過 165,000 人的長達 4,000 萬小時的現場心率、心率變異性、皮膚電活動、加速度計、皮膚溫度和每分鐘高度計資料，建立了 LSM，這是一個多模態基礎模型，建構在迄今為止具有最廣泛感測器模式的最大穿戴式訊號資料集上。我們的結果建立了 LSM 的規模化定律，適用於時間和感測器模式的任務，例如填補、內插和外插。此外，我們強調了 LSM 如何為運動和活動辨識等任務啟用樣本有效率的下游學習。</paragraph>

##### **Normalizing self-supervised learning for provably reliable Change Point Detection**
2410.13637v1 by Alexandra Bazarova, Evgenia Romanenkova, Alexey Zaytsev

Change point detection (CPD) methods aim to identify abrupt shifts in the
distribution of input data streams. Accurate estimators for this task are
crucial across various real-world scenarios. Yet, traditional unsupervised CPD
techniques face significant limitations, often relying on strong assumptions or
suffering from low expressive power due to inherent model simplicity. In
contrast, representation learning methods overcome these drawbacks by offering
flexibility and the ability to capture the full complexity of the data without
imposing restrictive assumptions. However, these approaches are still emerging
in the CPD field and lack robust theoretical foundations to ensure their
reliability. Our work addresses this gap by integrating the expressive power of
representation learning with the groundedness of traditional CPD techniques. We
adopt spectral normalization (SN) for deep representation learning in CPD tasks
and prove that the embeddings after SN are highly informative for CPD. Our
method significantly outperforms current state-of-the-art methods during the
comprehensive evaluation via three standard CPD datasets.

摘要：變異點偵測 (CPD) 方法旨在找出輸入資料串流分佈的突然轉變。在各種真實世界場景中，此項任務的準確估計器至關重要。然而，傳統的非監督式 CPD 技術面臨重大限制，通常依賴於強假設或由於模型本身的簡潔性而表現力不足。相反地，表示學習方法透過提供靈活性以及擷取資料完整複雜性的能力來克服這些缺點，而不加諸限制性假設。然而，這些方法仍出現在 CPD 領域，並且缺乏穩健的理論基礎來確保其可靠性。我們的研究透過整合表示學習的表現力與傳統 CPD 技術的基礎，來解決這個差距。我們採用深度表示學習中的頻譜正規化 (SN) 來執行 CPD 任務，並證明 SN 之後的嵌入對 CPD 而言極具參考價值。我們的模型在透過三個標準 CPD 資料集進行的全面評估中，明顯優於目前的最新方法。

##### **Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring**
2410.13616v1 by Kristina Telegraph, Christos Kyrkou

This work presents advancements in multi-class vehicle detection using UAV
cameras through the development of spatiotemporal object detection models. The
study introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing
6, 600 annotated sequential frame images captured by UAVs, enabling
comprehensive training and evaluation of algorithms for holistic spatiotemporal
perception. A YOLO-based object detection algorithm is enhanced to incorporate
temporal dynamics, resulting in improved performance over single frame models.
The integration of attention mechanisms into spatiotemporal models is shown to
further enhance performance. Experimental validation demonstrates significant
progress, with the best spatiotemporal model exhibiting a 16.22% improvement
over single frame models, while it is demonstrated that attention mechanisms
hold the potential for additional performance gains.

摘要：本研究透過時空物件偵測模型的開發，展示了使用無人機相機進行多類別車輛偵測的進展。本研究引入了時空車輛偵測資料集 (STVD)，其中包含無人機拍攝的 6,600 張標記順序影像，可全面訓練和評估整體時空感知演算法。一種基於 YOLO 的物件偵測演算法經過強化，以納入時間動態，進而提升單一影像模型的效能。整合注意機制到時空模型中，可進一步提升效能。實驗驗證顯示出顯著進展，最佳時空模型比單一影像模型進步了 16.22%，同時也證明注意機制有潛力進一步提升效能。

##### **H2OVL-Mississippi Vision Language Models Technical Report**
2410.13611v1 by Shaikat Galib, Shanshan Wang, Guanshuo Xu, Pascal Pfeiffer, Ryan Chesler, Mark Landry, Sri Satish Ambati

Smaller vision-language models (VLMs) are becoming increasingly important for
privacy-focused, on-device applications due to their ability to run efficiently
on consumer hardware for processing enterprise commercial documents and images.
These models require strong language understanding and visual capabilities to
enhance human-machine interaction. To address this need, we present
H2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs
using 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny
model with 0.8 billion parameters that specializes in text recognition,
achieving state of the art performance on the Text Recognition portion of
OCRBench and surpassing much larger models in this area. Additionally, we are
releasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use
cases, exhibiting highly competitive metrics across various academic
benchmarks. Both models build upon our prior work with H2O-Danube language
models, extending their capabilities into the visual domain. We release them
under the Apache 2.0 license, making VLMs accessible to everyone, democratizing
document AI and visual LLMs.

摘要：較小的視覺語言模型 (VLM) 對於注重隱私的裝置應用程式越來越重要，因為它們能夠在消費性硬體上有效執行，以處理企業商業文件和影像。這些模型需要強大的語言理解和視覺能力，才能增強人機互動。為了滿足這個需求，我們提出了 H2OVL-Mississippi，這是一對小型 VLM，使用 8 x H100 GPU 執行 240 小時的運算，在 3700 萬個影像文字配對上訓練而成。H2OVL-Mississippi-0.8B 是一個微小的模型，擁有 0.8 億個參數，專精於文字辨識，在 OCRBench 的文字辨識部分中取得了最先進的效能，並在這個領域超越了許多更大的模型。此外，我們正在釋出 H2OVL-Mississippi-2B，這是一個擁有 20 億個參數的模型，適用於一般用途，在各種學術基準中展現高度競爭力的指標。這兩個模型都建立在我們之前使用 H2O-Danube 語言模型所做的工作上，將它們的能力延伸到視覺領域。我們在 Apache 2.0 授權下釋出它們，讓所有人皆可使用 VLM，民主化文件 AI 和視覺 LLM。

##### **MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling**
2410.13610v1 by Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang

Integrating tools into Large Language Models (LLMs) has facilitated the
widespread application. Despite this, in specialized downstream task contexts,
reliance solely on tools is insufficient to fully address the complexities of
the real world. This particularly restricts the effective deployment of LLMs in
fields such as medicine. In this paper, we focus on the downstream tasks of
medical calculators, which use standardized tests to assess an individual's
health status. We introduce MeNTi, a universal agent architecture for LLMs.
MeNTi integrates a specialized medical toolkit and employs meta-tool and nested
calling mechanisms to enhance LLM tool utilization. Specifically, it achieves
flexible tool selection and nested tool calling to address practical issues
faced in intricate medical scenarios, including calculator selection, slot
filling, and unit conversion. To assess the capabilities of LLMs for
quantitative assessment throughout the clinical process of calculator
scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical
calculators to perform calculations and assess patient health status. CalcQA is
constructed by professional physicians and includes 100 case-calculator pairs,
complemented by a toolkit of 281 medical tools. The experimental results
demonstrate significant performance improvements with our framework. This
research paves new directions for applying LLMs in demanding scenarios of
medicine.

摘要：將工具整合到大型語言模型 (LLM) 中促进了廣泛的應用。儘管如此，在專業的下游任務情境中，單獨依賴工具不足以充分解決現實世界的複雜性。這特別限制了 LLM 在醫學等領域的有效部署。在本文中，我們專注於醫療計算器的下游任務，它使用標準化測試來評估個人的健康狀況。我們介紹 MeNTi，一種適用於 LLM 的通用代理架構。MeNTi 整合了一個專業的醫療工具包，並採用元工具和嵌套呼叫機制來增強 LLM 工具的利用率。具體來說，它實現了靈活的工具選擇和嵌套工具呼叫，以解決複雜醫療場景中面臨的實際問題，包括計算器選擇、插槽填充和單位轉換。為了評估 LLM 在計算器場景的整個臨床過程中進行量化評估的能力，我們引入了 CalcQA。此基準要求 LLM 使用醫療計算器進行計算並評估患者的健康狀況。CalcQA 由專業醫生編制，包括 100 個案例計算器對，並輔以 281 個醫療工具的工具包。實驗結果證明了我們框架的顯著效能提升。這項研究為在要求嚴格的醫學場景中應用 LLM 鋪平了新的道路。

##### **Large Language Models as Narrative-Driven Recommenders**
2410.13604v1 by Lukas Eberhard, Thorsten Ruprechter, Denis Helic

Narrative-driven recommenders aim to provide personalized suggestions for
user requests expressed in free-form text such as "I want to watch a thriller
with a mind-bending story, like Shutter Island." Although large language models
(LLMs) have been shown to excel in processing general natural language queries,
their effectiveness for handling such recommendation requests remains
relatively unexplored. To close this gap, we compare the performance of 38
open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in
a movie recommendation setting. For this, we utilize a gold-standard,
crowdworker-annotated dataset of posts from reddit's movie suggestion community
and employ various prompting strategies, including zero-shot, identity, and
few-shot prompting. Our findings demonstrate the ability of LLMs to generate
contextually relevant movie recommendations, significantly outperforming other
state-of-the-art approaches, such as doc2vec. While we find that closed-source
and large-parameterized models generally perform best, medium-sized open-source
models remain competitive, being only slightly outperformed by their more
computationally expensive counterparts. Furthermore, we observe no significant
differences across prompting strategies for most models, underscoring the
effectiveness of simple approaches such as zero-shot prompting for
narrative-driven recommendations. Overall, this work offers valuable insights
for recommender system researchers as well as practitioners aiming to integrate
LLMs into real-world recommendation tools.

摘要：<paragraph>以敘事為主的推薦系統旨在為「我想看一部情節曲折離奇的驚悚片，像是《隔離島》」等以自由形式文字表達的使用者要求提供個人化建議。儘管大型語言模型 (LLM) 已被證明擅長處理一般自然語言查詢，但它們在處理此類推薦要求方面的效能仍相對未經探討。為了縮小這個差距，我們在電影推薦設定中比較了 38 個不同規模的開放和閉源 LLM 的效能，例如 LLama 3.2 和 GPT-4o。為此，我們利用 Reddit 電影建議社群的貼文彙編而成的黃金標準、群眾工作者註解的資料集，並採用各種提示策略，包括零次學習、身分和少次學習提示。我們的發現證明了 LLM 產生與情境相關的電影推薦的能力，顯著優於其他最先進的方法，例如 doc2vec。雖然我們發現閉源和大型參數化模型通常表現最佳，但中型開放源碼模型仍然具有競爭力，僅略遜於它們在運算上較昂貴的對應模型。此外，我們觀察到大多數模型在提示策略上沒有顯著差異，這強調了零次學習提示等簡單方法在以敘事為主的推薦中的效能。總體而言，這項工作為推薦系統研究人員和旨在將 LLM 整合到實際推薦工具中的實務工作者提供了寶貴的見解。</paragraph>

##### **Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model**
2410.13597v1 by Yida Xiong, Kun Li, Weiwei Liu, Jia Wu, Bo Du, Shirui Pan, Wenbin Hu

Molecular optimization (MO) is a crucial stage in drug discovery in which
task-oriented generated molecules are optimized to meet practical industrial
requirements. Existing mainstream MO approaches primarily utilize external
property predictors to guide iterative property optimization. However, learning
all molecular samples in the vast chemical space is unrealistic for predictors.
As a result, errors and noise are inevitably introduced during property
prediction due to the nature of approximation. This leads to discrepancy
accumulation, generalization reduction and suboptimal molecular candidates. In
this paper, we propose a text-guided multi-property molecular optimization
method utilizing transformer-based diffusion language model (TransDLM).
TransDLM leverages standardized chemical nomenclature as semantic
representations of molecules and implicitly embeds property requirements into
textual descriptions, thereby preventing error propagation during diffusion
process. Guided by physically and chemically detailed textual descriptions,
TransDLM samples and optimizes encoded source molecules, retaining core
scaffolds of source molecules and ensuring structural similarities. Moreover,
TransDLM enables simultaneous sampling of multiple molecules, making it ideal
for scalable, efficient large-scale optimization through distributed
computation on web platforms. Furthermore, our approach surpasses
state-of-the-art methods in optimizing molecular structural similarity and
enhancing chemical properties on the benchmark dataset. The code is available
at: https://anonymous.4open.science/r/TransDLM-A901.

摘要：分子最佳化 (MO) 是藥物發現中至關重要的階段，其中以任務為導向產生的分子經過最佳化以符合實際的產業需求。現有的主流 MO 方法主要利用外部屬性預測器來引導反覆的屬性最佳化。然而，對於預測器來說，學習廣大化學空間中的所有分子範例是不切實際的。因此，由於近似本質，在屬性預測過程中難免會引入錯誤和雜訊。這會導致差異累積、概化減少和次佳分子候選。在本文中，我們提出一個由文字引導的多屬性分子最佳化方法，利用基於 Transformer 的擴散語言模型 (TransDLM)。TransDLM 利用標準化的化學命名法作為分子的語義表示，並將屬性需求隱式嵌入文字描述中，從而防止在擴散過程中發生錯誤傳播。在物理和化學詳細文字描述的引導下，TransDLM 對編碼的來源分子進行取樣和最佳化，保留來源分子的核心骨架並確保結構相似性。此外，TransDLM 能同時對多個分子進行取樣，使其非常適合透過網路平台上的分散式運算進行可擴充、高效的大規模最佳化。此外，我們的做法在最佳化分子結構相似性和提升基準資料集上的化學屬性方面超越了最先進的方法。程式碼可在以下網址取得：https://anonymous.4open.science/r/TransDLM-A901。

##### **OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope**
2410.13592v1 by Wei Liu, Kerem Delikoyun, Qianyu Chen, Alperen Yildiz, Si Ko Myo, Win Sen Kuan, John Tshon Yit Soong, Matthew Edward Cove, Oliver Hayden, Hweekuan Lee

Off-axis digital holographic microscopy is a high-throughput, label-free
imaging technology that provides three-dimensional, high-resolution information
about samples, particularly useful in large-scale cellular imaging. However,
the hologram reconstruction process poses a significant bottleneck for timely
data analysis. To address this challenge, we propose a novel reconstruction
approach that integrates deep learning with the physical principles of off-axis
holography. We initialized part of the network weights based on the physical
principle and then fine-tuned them via weakly supersized learning. Our off-axis
hologram network (OAH-Net) retrieves phase and amplitude images with errors
that fall within the measurement error range attributable to hardware, and its
reconstruction speed significantly surpasses the microscope's acquisition rate.
Crucially, OAH-Net demonstrates remarkable external generalization capabilities
on unseen samples with distinct patterns and can be seamlessly integrated with
other models for downstream tasks to achieve end-to-end real-time hologram
analysis. This capability further expands off-axis holography's applications in
both biological and medical studies.

摘要：離軸數位全像顯微鏡是一種高通量、無標籤的影像技術，可提供立體、高解析度的樣品資訊，特別適用於大規模細胞影像。然而，全像重建過程對及時的資料分析構成重大的瓶頸。為了應對這項挑戰，我們提出了一種創新的重建方法，將深度學習與離軸全像的物理原理整合在一起。我們根據物理原理初始化部分網路權重，然後透過弱監督學習微調它們。我們的離軸全像網路 (OAH-Net) 擷取相位和振幅影像，其誤差落在歸因於硬體的量測誤差範圍內，而且其重建速度顯著超越顯微鏡的擷取率。至關重要的是，OAH-Net 在具有不同模式的未見樣本上展現出卓越的外在泛化能力，而且可以與其他模型無縫整合，以執行下游任務，以達成端對端的即時全像分析。此能力進一步擴展了離軸全像在生物和醫學研究中的應用。

##### **RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging**
2410.13570v1 by Tobias Czempiel, Alfie Roddan, Maria Leiloglou, Zepeng Hu, Kevin O'Neill, Giulio Anichini, Danail Stoyanov, Daniel Elson

This study investigates the reconstruction of hyperspectral signatures from
RGB data to enhance surgical imaging, utilizing the publicly available
HeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery
dataset. Various architectures based on convolutional neural networks (CNNs)
and transformer models are evaluated using comprehensive metrics. Transformer
models exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by
effectively integrating spatial information to predict accurate spectral
profiles, encompassing both visible and extended spectral ranges. Qualitative
assessments demonstrate the capability to predict spectral profiles critical
for informed surgical decision-making during procedures. Challenges associated
with capturing both the visible and extended hyperspectral ranges are
highlighted using the MAE, emphasizing the complexities involved. The findings
open up the new research direction of hyperspectral reconstruction for surgical
applications and clinical use cases in real-time surgical environments.

摘要：本研究探討了從 RGB 資料重建高光譜特徵，以增強手術影像，並利用來自豬隻手術的公開 HeiPorSPECTRAL 資料集和院內神經外科資料集。使用綜合評量指標評估了基於卷積神經網路 (CNN) 和 Transformer 模型的各種架構。Transformer 模型在 RMSE、SAM、PSNR 和 SSIM 方面表現出優異的效能，因為它有效地整合了空間資訊以預測準確的光譜輪廓，涵蓋了可見光和延伸光譜範圍。定性評估證明了在手術過程中預測光譜輪廓的能力，對於明智的手術決策制定至關重要。使用 MAE 強調了與擷取可見光和延伸高光譜範圍相關的挑戰，強調了所涉及的複雜性。這些發現開啟了高光譜重建在手術應用和實際手術環境中臨床使用案例的新研究方向。

##### **CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models**
2410.13567v1 by Yujian Zhao, Chengru Wu, Yinong Xu, Xuanzheng Du, Ruiyu Li, Guanglin Niu

Cloth-changing person re-identification (CC-ReID), also known as Long-Term
Person Re-Identification (LT-ReID) is a critical and challenging research topic
in computer vision that has recently garnered significant attention. However,
due to the high cost of constructing CC-ReID data, the existing data-driven
models are hard to train efficiently on limited data, causing overfitting
issue. To address this challenge, we propose a low-cost and efficient pipeline
for generating controllable and high-quality synthetic data simulating the
surveillance of real scenarios specific to the CC-ReID task. Particularly, we
construct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal
Person (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5
outfits per individual. Based on this large-scale dataset, we introduce an
effective and scalable pretrain-finetune framework for enhancing the
generalization capabilities of the traditional CC-ReID models. The extensive
experiments demonstrate that two typical models namely TransReID and FIRe^2,
when integrated into our framework, outperform other state-of-the-art models
after pretraining on CCUP and finetuning on the benchmarks such as PRCC,
VC-Clothes and NKUP. The CCUP is available at:
https://github.com/yjzhao1019/CCUP.

摘要：<paragraph>換衣人員再辨識 (CC-ReID)，又稱長期人員再辨識 (LT-ReID)，是電腦視覺中一個重要的且具挑戰性的研究主題，最近備受關注。然而，由於建構 CC-ReID 資料的成本過高，現有的資料驅動模型難以在有限的資料上有效訓練，導致過度擬合的問題。為了應對這個挑戰，我們提出了一個低成本且有效率的管道，用於產生可控且高品質的合成資料，模擬特定於 CC-ReID 任務的真實場景監控。特別是，我們建構了一個新的自我標註 CC-ReID 資料集，名為 Cloth-Changing Unreal Person (CCUP)，包含 6,000 個 ID、1,179,976 張影像、100 個攝影機，以及每人 26.5 套服裝。基於這個大型資料集，我們引入了一個有效且可擴充的預訓練微調架構，用於增強傳統 CC-ReID 模型的泛化能力。廣泛的實驗證明，當將 TransReID 和 FIRe^2 這兩個典型模型整合到我們的架構中時，在 CCUP 上預訓練並在 PRCC、VC-Clothes 和 NKUP 等基準上微調後，它們的表現優於其他最先進的模型。CCUP 可在以下網址取得：https://github.com/yjzhao1019/CCUP。</paragraph>

##### **Enhancing Fact Retrieval in PLMs through Truthfulness**
2410.13562v1 by Paul Youssef, Jörg Schlötterer, Christin Seifert

Pre-trained Language Models (PLMs) encode various facts about the world at
their pre-training phase as they are trained to predict the next or missing
word in a sentence. There has a been an interest in quantifying and improving
the amount of facts that can be extracted from PLMs, as they have been
envisioned to act as soft knowledge bases, which can be queried in natural
language. Different approaches exist to enhance fact retrieval from PLM. Recent
work shows that the hidden states of PLMs can be leveraged to determine the
truthfulness of the PLMs' inputs. Leveraging this finding to improve factual
knowledge retrieval remains unexplored. In this work, we investigate the use of
a helper model to improve fact retrieval. The helper model assesses the
truthfulness of an input based on the corresponding hidden states
representations from the PLMs. We evaluate this approach on several masked PLMs
and show that it enhances fact retrieval by up to 33\%. Our findings highlight
the potential of hidden states representations from PLMs in improving their
factual knowledge retrieval.

摘要：預訓練語言模型 (PLM) 在預訓練階段會編碼世界上各種事實，因為它們被訓練為預測句子中的下一個或遺失的單字。對於量化和改善可從 PLM 中提取的事實數量一直很有興趣，因為它們被設想為可以透過自然語言查詢的軟知識庫。有不同的方法可以增強從 PLM 中擷取事實。最近的研究顯示，PLM 的隱藏狀態可以被利用來確定 PLM 輸入的真實性。利用這個發現來改善事實知識擷取仍未被探索。在這項工作中，我們探討使用輔助模型來改善事實擷取。輔助模型根據來自 PLM 的對應隱藏狀態表示來評估輸入的真實性。我們在多個遮蔽 PLM 上評估此方法，並顯示它將事實擷取提升了 33%。我們的發現突出了 PLM 的隱藏狀態表示在改善其事實知識擷取方面的潛力。

##### **Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models**
2410.13553v1 by Yuki Hou, Haruki Tamoto, Homei Miyashita

Conventional dialogue agents often struggle with effective memory recall,
leading to redundant retrieval and inadequate management of unique user
associations. To address this, we propose SynapticRAG, a novel approach
integrating synaptic dynamics into Retrieval-Augmented Generation (RAG).
SynapticRAG integrates temporal representations into memory vectors, mimicking
biological synapses by differentiating events based on occurrence times and
dynamically updating memory significance. This model employs temporal scoring
for memory connections and a synaptic-inspired propagation control mechanism.
Experiments across English, Japanese, and Chinese datasets demonstrate
SynapticRAG's superiority over existing methods, including traditional RAG,
with up to 14.66\% improvement in memory retrieval accuracy. Our approach
advances context-aware dialogue AI systems by enhancing long-term context
maintenance and specific information extraction from conversations.

摘要：傳統對話代理經常在有效記憶召回上遇到困難，導致冗餘的檢索和對使用者獨特關聯性的管理不當。為了解決這個問題，我們提出 SynapticRAG，這是一種創新的方法，將突觸動態整合到檢索增強生成 (RAG) 中。SynapticRAG 將時間表徵整合到記憶向量中，透過根據發生時間區分事件和動態更新記憶重要性來模擬生物突觸。此模型採用時間評分作為記憶連結和突觸啟發的傳播控制機制。跨越英文、日文和中文資料集的實驗證明了 SynapticRAG 優於現有方法，包括傳統 RAG，記憶檢索準確度提升了 14.66%。我們的做法透過增強長期脈絡維護和從對話中提取特定資訊，推動了具備脈絡感知能力的對話 AI 系統。

##### **Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?**
2410.13523v1 by Che Liu, Zhongwei Wan, Haozhe Wang, Yinda Chen, Talha Qaiser, Chen Jin, Fariba Yousefi, Nikolay Burlutskiy, Rossella Arcucci

Medical Vision-Language Pre-training (MedVLP) has made significant progress
in enabling zero-shot tasks for medical image understanding. However, training
MedVLP models typically requires large-scale datasets with paired, high-quality
image-text data, which are scarce in the medical domain. Recent advancements in
Large Language Models (LLMs) and diffusion models have made it possible to
generate large-scale synthetic image-text pairs. This raises the question: *Can
MedVLP succeed using purely synthetic data?* To address this, we use
off-the-shelf generative models to create synthetic radiology reports and
paired Chest X-ray (CXR) images, and propose an automated pipeline to build a
diverse, high-quality synthetic dataset, enabling a rigorous study that
isolates model and training settings, focusing entirely from the data
perspective. Our results show that MedVLP models trained *exclusively on
synthetic data* outperform those trained on real data by **3.8%** in averaged
AUC on zero-shot classification. Moreover, using a combination of synthetic and
real data leads to a further improvement of **9.07%**. Additionally, MedVLP
models trained on synthetic or mixed data consistently outperform those trained
on real data in zero-shot grounding, as well as in fine-tuned classification
and segmentation tasks. Our analysis suggests MedVLP trained on well-designed
synthetic data can outperform models trained on real datasets, which may be
limited by low-quality samples and long-tailed distributions.

摘要：<paragraph>醫療視覺語言預訓練 (MedVLP) 在支援醫學影像理解的零次學習任務方面取得重大進展。然而，訓練 MedVLP 模型通常需要具備配對、高品質影像文字資料的大規模資料集，而這在醫療領域中十分稀少。大型語言模型 (LLM) 和擴散模型的最新進展使得產生大規模的合成影像文字配對成為可能。這引發了一個問題：*MedVLP 能僅使用合成資料成功嗎？*為了解決這個問題，我們使用現成的生成模型來建立合成放射報告和配對的胸部 X 光 (CXR) 影像，並提出一個自動化的流程來建構一個多元、高品質的合成資料集，這使得一項嚴謹的研究得以專注於資料觀點，並完全隔離模型和訓練設定。我們的結果顯示，*僅使用合成資料訓練的* MedVLP 模型在零次分類的平均 AUC 上，比在真實資料上訓練的模型高出 **3.8%**。此外，使用合成資料和真實資料的組合，可進一步提升 **9.07%**。此外，在合成或混合資料上訓練的 MedVLP 模型，在零次定位、微調分類和分割任務中，始終優於在真實資料上訓練的模型。我們的分析顯示，在設計良好的合成資料上訓練的 MedVLP 可以優於在真實資料集上訓練的模型，而真實資料集可能受到低品質樣本和長尾分佈的限制。</paragraph>

##### **Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks ?**
2410.13517v1 by Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis

Large language models (LLMs) inherit biases from their training data and
alignment processes, influencing their responses in subtle ways. While many
studies have examined these biases, little work has explored their robustness
during interactions. In this paper, we introduce a novel approach where two
instances of an LLM engage in self-debate, arguing opposing viewpoints to
persuade a neutral version of the model. Through this, we evaluate how firmly
biases hold and whether models are susceptible to reinforcing misinformation or
shifting to harmful viewpoints. Our experiments span multiple LLMs of varying
sizes, origins, and languages, providing deeper insights into bias persistence
and flexibility across linguistic and cultural contexts.

摘要：大型語言模型 (LLM) 從其訓練資料和比對過程中繼承了偏差，並以微妙的方式影響其回應。雖然許多研究探討了這些偏差，但很少有研究探討它們在互動過程中的穩健性。在本文中，我們引入了一種新方法，其中兩個 LLM 實例進行自我辯論，爭論對立觀點以說服模型的中立版本。透過此方法，我們評估偏差的堅固程度，以及模型是否容易強化錯誤資訊或轉變為有害觀點。我們的實驗涵蓋了各種規模、來源和語言的 LLM，深入了解了跨語言和文化背景的偏差持續性和靈活性。

##### **GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models**
2410.13510v1 by Aditya Sharma, Aman Dalmia, Mehran Kazemi, Amal Zouaq, Christopher J. Pal

Geometry problem-solving demands advanced reasoning abilities to process
multimodal inputs and employ mathematical knowledge effectively.
Vision-language models (VLMs) have made significant progress in various
multimodal tasks. Yet, they still struggle with geometry problems and are
significantly limited by their inability to perform mathematical operations not
seen during pre-training, such as calculating the cosine of an arbitrary angle,
and by difficulties in correctly applying relevant geometry formulas. To
overcome these challenges, we present GeoCoder, which leverages modular
code-finetuning to generate and execute code using a predefined geometry
function library. By executing the code, we achieve accurate and deterministic
calculations, contrasting the stochastic nature of autoregressive token
prediction, while the function library minimizes errors in formula usage. We
also propose a multimodal retrieval-augmented variant of GeoCoder, named
RAG-GeoCoder, which incorporates a non-parametric memory module for retrieving
functions from the geometry library, thereby reducing reliance on parametric
memory. Our modular code-finetuning approach enhances the geometric reasoning
capabilities of VLMs, yielding an average improvement of over 16% across
various question complexities on the GeomVerse dataset compared to other
finetuning methods.

摘要：幾何問題求解需要進階推理能力來處理多模態輸入並有效運用數學知識。視覺語言模型 (VLM) 已在各種多模態任務中取得重大進展。然而，它們在幾何問題上仍面臨挑戰，且因無法執行預訓練期間未見過的數學運算（例如計算任意角度的餘弦）以及難以正確套用相關幾何公式而受到顯著限制。為了克服這些挑戰，我們提出了 GeoCoder，它利用模組化程式碼微調來產生和執行程式碼，並使用預先定義的幾何函式庫。透過執行程式碼，我們能達成精確且確定的計算，與自迴歸權杖預測的隨機性質形成對比，而函式庫則能將公式使用中的錯誤降到最低。我們也提出 GeoCoder 的多模態檢索擴充變體，稱為 RAG-GeoCoder，它結合非參數記憶體模組來從幾何函式庫中檢索函式，進而減少對參數記憶體的依賴。我們模組化的程式碼微調方法增強了 VLM 的幾何推理能力，與其他微調方法相比，在 GeomVerse 資料集上各種問題複雜度方面平均提升超過 16%。

##### **RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards**
2410.13509v1 by Xinze Li, Sen Mei, Zhenghao Liu, Yukun Yan, Shuo Wang, Shi Yu, Zheni Zeng, Hao Chen, Ge Yu, Zhiyuan Liu, Maosong Sun, Chenyan Xiong

Retrieval-Augmented Generation (RAG) has proven its effectiveness in
mitigating hallucinations in Large Language Models (LLMs) by retrieving
knowledge from external resources. To adapt LLMs for RAG pipelines, current
approaches use instruction tuning to optimize LLMs, improving their ability to
utilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses
on equipping LLMs to handle diverse RAG tasks using different instructions.
However, it trains RAG modules to overfit training signals and overlooks the
varying data preferences among agents within the RAG system. In this paper, we
propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG
systems by aligning data preferences between different RAG modules. DDR works
by collecting the rewards to optimize each agent with a rollout method. This
method prompts agents to sample some potential responses as perturbations,
evaluates the impact of these perturbations on the whole RAG system, and
subsequently optimizes the agent to produce outputs that improve the
performance of the RAG system. Our experiments on various knowledge-intensive
tasks demonstrate that DDR significantly outperforms the SFT method,
particularly for LLMs with smaller-scale parameters that depend more on the
retrieved knowledge. Additionally, DDR exhibits a stronger capability to align
the data preference between RAG modules. The DDR method makes generation module
more effective in extracting key information from documents and mitigating
conflicts between parametric memory and external knowledge. All codes are
available at https://github.com/OpenMatch/RAG-DDR.

摘要：檢索增強生成（RAG）已證明其在大型語言模型（LLM）中透過從外部資源檢索知識來減輕幻覺的有效性。為了將 LLM 適應於 RAG 管線，目前的做法是使用指令調整來最佳化 LLM，進而改善它們利用檢索知識的能力。這種監督微調（SFT）方法專注於透過不同的指令來裝備 LLM 以處理不同的 RAG 任務。然而，它訓練 RAG 模組過度擬合訓練訊號，並忽略 RAG 系統中代理之間不同的資料偏好。在本文中，我們提出可微分資料獎勵（DDR）方法，它透過調整不同 RAG 模組之間的資料偏好來端對端訓練 RAG 系統。DDR 的運作方式是收集獎勵，以透過滾動方法最佳化每個代理。此方法提示代理將一些潛在回應取樣為擾動，評估這些擾動對整個 RAG 系統的影響，並隨後最佳化代理以產生改善 RAG 系統效能的輸出。我們在各種知識密集型任務上進行的實驗證明，DDR 明顯優於 SFT 方法，特別是對於依賴檢索知識較多的較小規模參數的 LLM。此外，DDR 展現出更強大的能力，可以調整 RAG 模組之間的資料偏好。DDR 方法使生成模組更有效地從文件提取關鍵資訊，並減輕參數化記憶體與外部知識之間的衝突。所有程式碼都可以在 https://github.com/OpenMatch/RAG-DDR 取得。

##### **MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs**
2410.13502v1 by Andreas Opedal, Haruki Shirakami, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan

Large language models (LLMs) can solve arithmetic word problems with high
accuracy, but little is known about how well they generalize to problems that
are more complex than the ones on which they have been trained. Empirical
investigations of such questions are impeded by two major flaws of current
evaluations: (i) much of the evaluation data is contaminated, in the sense that
it has already been seen during training, and (ii) benchmark datasets do not
capture how problem proofs may be arbitrarily complex in various ways. As a
step towards addressing these issues, we present a framework for evaluating
LLMs on problems that have arbitrarily complex arithmetic proofs, called
MathGAP. MathGAP generates problems that follow fixed proof specifications --
along with chain-of-thought reasoning annotations -- enabling systematic
studies on generalization with respect to arithmetic proof complexity. We apply
MathGAP to analyze how in-context learning interacts with generalization to
problems that have more complex proofs. We find that among the models tested,
most show a significant decrease in performance as proofs get deeper and wider.
This effect is more pronounced in complex, nonlinear proof structures, which
are challenging even for GPT-4o. Surprisingly, providing in-context examples
from the same distribution as the test set is not always beneficial for
performance. In particular, zero-shot prompting as well as demonstrating a
diverse range of examples that are less complex than the test data sometimes
yield similar or higher accuracies.

摘要：大型語言模型 (LLM) 能以極高的準確度解決算術字詞問題，但對於它們在比訓練資料更複雜的問題中能有多好的泛化能力，我們所知甚少。目前評估的兩大主要缺陷阻礙了對此類問題的經驗調查：(i) 大部分評估資料都受到污染，因為它們在訓練期間已經被看過，而且 (ii) 基準資料集無法捕捉到問題證明在各方面可能任意複雜的情況。為了解決這些問題，我們提出一個框架，用於評估 LLM 在具有任意複雜算術證明的問題上，稱為 MathGAP。MathGAP 會產生遵循固定證明規格的問題，並附上思考鏈推理註解，從而能針對算術證明複雜度進行系統化泛化研究。我們運用 MathGAP 來分析情境內學習如何與泛化到具有更複雜證明的問題進行交互作用。我們發現，在測試的模型中，大多數模型在證明變得更深更廣時，效能會大幅下降。這種效應在複雜的非線性證明結構中更為明顯，即使對 GPT-4o 來說也是一個挑戰。令人驚訝的是，提供與測試集相同分佈的情境內範例，對於效能並不總是會有幫助。特別是，零次提示以及展示比測試資料不那麼複雜的各種範例，有時會產生相似或更高的準確度。

##### **Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques**
2410.13498v1 by Rahimanuddin Shaik, Katikela Sreeharsha Kishore

Text generation is the automated process of producing written or spoken
language using computational methods. It involves generating coherent and
contextually relevant text based on predefined rules or learned patterns.
However, challenges in text generation arise from maintaining coherence,
ensuring diversity and creativity, and avoiding biases or inappropriate
content. This research paper developed a novel approach to improve text
generation in the context of joint Natural Language Generation (NLG) and
Natural Language Understanding (NLU) learning. The data is prepared by
gathering and preprocessing annotated datasets, including cleaning,
tokenization, stemming, and stop-word removal. Feature extraction techniques
such as POS tagging, Bag of words, and Term Frequency-Inverse Document
Frequency (TF-IDF) are applied. Transformer-based encoders and decoders,
capturing long range dependencies and improving source-target sequence
modelling. Pre-trained language models like Optimized BERT are incorporated,
along with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).
Reinforcement learning with policy gradient techniques, semi-supervised
training, improved attention mechanisms, and differentiable approximations like
straight-through Gumbel SoftMax estimator are employed to fine-tune the models
and handle complex linguistic tasks effectively. The proposed model is
implemented using Python.

摘要：文字生成是利用計算方法自動產生書面或口語語言的過程。它涉及根據預定義的規則或學習的模式生成連貫且與上下文相關的文字。
然而，文字生成的挑戰在於維持連貫性、確保多樣性和創造力，以及避免偏見或不適當的內容。這篇研究論文開發了一種新穎的方法來改善在聯合自然語言生成 (NLG) 和自然語言理解 (NLU) 學習的背景下的文字生成。數據是透過收集和預處理註解資料集來準備的，包括清理、標記化、詞幹分析和停用詞移除。特徵提取技術，例如詞性標記、詞袋和詞頻-逆文件頻率 (TF-IDF)，被應用。基於 Transformer 的編碼器和解碼器，捕捉長距離依賴關係並改善源目標序列建模。預訓練的語言模型，例如最佳化 BERT，與混合 Redfox 人工蜂鳥演算法 (HRAHA) 一起被納入。強化學習與策略梯度技術、半監督訓練、改進的注意力機制和可微分近似，例如直通 Gumbel SoftMax 估計器，被用於微調模型並有效處理複雜的語言任務。所提出的模型是使用 Python 實作的。

##### **Repetition Neurons: How Do Language Models Produce Repetitions?**
2410.13497v1 by Tatsuya Hiraoka, Kentaro Inui

This paper introduces repetition neurons, regarded as skill neurons
responsible for the repetition problem in text generation tasks. These neurons
are progressively activated more strongly as repetition continues, indicating
that they perceive repetition as a task to copy the previous context
repeatedly, similar to in-context learning. We identify these repetition
neurons by comparing activation values before and after the onset of repetition
in texts generated by recent pre-trained language models. We analyze the
repetition neurons in three English and one Japanese pre-trained language
models and observe similar patterns across them.

摘要：本文介紹了重複神經元，被視為負責文字生成任務中重複問題的技能神經元。這些神經元在重複持續時會逐漸被更強烈地激活，表明它們將重複視為一項重複複製先前語境的任務，類似於語境學習。我們透過比較最近預先訓練的語言模型所生成的文字中，重複發生前後的激活值來識別這些重複神經元。我們分析了三個英文和一個日文的預先訓練語言模型中的重複神經元，並觀察到它們之間有類似的模式。

##### **Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes**
2410.13488v1 by Dibyanayan Bandyopadhyay, Mohammed Hasanuzzaman, Asif Ekbal

Detecting offensive memes is crucial, yet standard deep neural network
systems often remain opaque. Various input attribution-based methods attempt to
interpret their behavior, but they face challenges with implicitly offensive
memes and non-causal attributions. To address these issues, we propose a
framework based on a Structural Causal Model (SCM). In this framework,
VisualBERT is trained to predict the class of an input meme based on both meme
input and causal concepts, allowing for transparent interpretation. Our
qualitative evaluation demonstrates the framework's effectiveness in
understanding model behavior, particularly in determining whether the model was
right due to the right reason, and in identifying reasons behind
misclassification. Additionally, quantitative analysis assesses the
significance of proposed modelling choices, such as de-confounding, adversarial
learning, and dynamic routing, and compares them with input attribution
methods. Surprisingly, we find that input attribution methods do not guarantee
causality within our framework, raising questions about their reliability in
safety-critical applications. The project page is at:
https://newcodevelop.github.io/causality_adventure/

摘要：偵測冒犯性迷因至關重要，但標準深度神經網路系統通常仍然不透明。各種基於輸入歸因的方法嘗試詮釋其行為，但它們在隱含冒犯性迷因和非因果歸因上會遇到挑戰。為了解決這些問題，我們提出一個基於結構因果模型 (SCM) 的架構。在這個架構中，VisualBERT 訓練為根據迷因輸入和因果概念來預測輸入迷因的類別，允許透明詮釋。我們的定性評估證明了該架構在理解模型行為方面的有效性，特別是在確定模型是否由於正確的原因而正確，以及在找出錯誤分類背後的原因。此外，定量分析評估了建議建模選擇的重要性，例如去混淆、對抗式學習和動態路由，並將它們與輸入歸因方法進行比較。令人驚訝的是，我們發現輸入歸因方法並不能在我們的架構中保證因果關係，這對它們在安全關鍵應用中的可靠性提出了質疑。專案頁面在：
https://newcodevelop.github.io/causality_adventure/

##### **IterSelectTune: An Iterative Training Framework for Efficient Instruction-Tuning Data Selection**
2410.13464v1 by Jielin Song, Siyu Liu, Bin Zhu, Yanghui Rao

As large language models (LLMs) continue to advance, instruction tuning has
become critical for improving their ability to generate accurate and
contextually appropriate responses. Although numerous instruction-tuning
datasets have been developed to enhance LLM performance, selecting high-quality
instruction data from large source datasets typically demands significant human
effort. In this work, we introduce $\textbf{IterSelectTune}$, an efficient,
cost-effective iterative training policy for selecting high-quality instruction
data with no human involvement and limited reliance on GPT-4. By fine-tuning on
approximately 20\% of the source data, our method consistently outperforms
models fine-tuned on the full dataset across multiple benchmarks and public
test datasets. These results highlight the effectiveness of our approach in
enhancing LLM performance while reducing the computational resources required
for instruction tuning.

摘要：随着大型语言模型 (LLM) 的持续进步，指令微调对于提高其生成准确且符合上下文语境的响应的能力至关重要。尽管已经开发了许多指令微调数据集来增强 LLM 性能，但从大型源数据集中选择高质量指令数据通常需要大量人力。在这项工作中，我们介绍了 $\textbf{IterSelectTune}$，这是一种高效、经济的迭代训练策略，用于在没有人工参与和有限依赖 GPT-4 的情况下选择高质量指令数据。通过对约 20% 的源数据进行微调，我们的方法在多个基准和公共测试数据集中始终优于在完整数据集上进行微调的模型。这些结果突出了我们方法在提高 LLM 性能的同时减少指令微调所需的计算资源方面的有效性。

##### **Progressive Mixed-Precision Decoding for Efficient LLM Inference**
2410.13461v1 by Hao Mark Chen, Fuwen Tan, Alexandros Kouris, Royson Lee, Hongxiang Fan, Stylianos I. Venieris

In spite of the great potential of large language models (LLMs) across
various tasks, their deployment on resource-constrained devices remains
challenging due to their excessive computational and memory demands.
Quantization has emerged as an effective solution by storing weights in reduced
precision. However, utilizing low precisions (i.e.~2/3-bit) to substantially
alleviate the memory-boundedness of LLM decoding, still suffers from
prohibitive performance drop. In this work, we argue that existing approaches
fail to explore the diversity in computational patterns, redundancy, and
sensitivity to approximations of the different phases of LLM inference,
resorting to a uniform quantization policy throughout. Instead, we propose a
novel phase-aware method that selectively allocates precision during different
phases of LLM inference, achieving both strong context extraction during
prefill and efficient memory bandwidth utilization during decoding. To further
address the memory-boundedness of the decoding phase, we introduce Progressive
Mixed-Precision Decoding (PMPD), a technique that enables the gradual lowering
of precision deeper in the generated sequence, together with a spectrum of
precision-switching schedulers that dynamically drive the precision-lowering
decisions in either task-adaptive or prompt-adaptive manner. Extensive
evaluation across diverse language tasks shows that when targeting Nvidia GPUs,
PMPD achieves 1.4$-$12.2$\times$ speedup in matrix-vector multiplications over
fp16 models, while when targeting an LLM-optimized NPU, our approach delivers a
throughput gain of 3.8$-$8.0$\times$ over fp16 models and up to 1.54$\times$
over uniform quantization approaches while preserving the output quality.

摘要：儘管大型語言模型 (LLM) 在各種任務中具有極大的潛力，但由於其過高的運算和記憶體需求，它們在資源受限的裝置上部署仍然具有挑戰性。量化已成為一種有效的解決方案，方法是將權重儲存在降低的精度中。然而，利用低精度（即 2/3 位）來大幅減輕 LLM 解碼的記憶體受限性，仍然會導致效能大幅下降。在這項工作中，我們認為現有方法未能探索不同階段的 LLM 推論的運算模式、冗餘和對近似值的敏感性，而是在整個過程中採用統一的量化策略。相反地，我們提出了一種新穎的相位感知方法，它在 LLM 推論的不同階段中選擇性地分配精度，在預先填入期間實現強大的內容提取，並在解碼期間有效利用記憶體頻寬。為了進一步解決解碼階段的記憶體受限性，我們引入了漸進混合精度解碼 (PMPD)，這是一種技術，可以逐漸降低生成序列中較深的精度，同時具有一系列精度切換排程器，以任務自適應或提示自適應的方式動態驅動精度降低決策。在各種語言任務中的廣泛評估顯示，當目標是 Nvidia GPU 時，PMPD 在矩陣向量乘法中比 fp16 模型快 1.4-12.2 倍，而當目標是 LLM 最佳化 NPU 時，我們的做法比 fp16 模型提高了 3.8-8.0 倍的吞吐量，並且比統一量化方法提高了 1.54 倍，同時保留了輸出品質。

##### **Breaking the Manual Annotation Bottleneck: Creating a Comprehensive Legal Case Criticality Dataset through Semi-Automated Labeling**
2410.13460v1 by Ronja Stern, Ken Kawamura, Matthias Stürmer, Ilias Chalkidis, Joel Niklaus

Predicting case criticality helps legal professionals in the court system
manage large volumes of case law. This paper introduces the Criticality
Prediction dataset, a new resource for evaluating the potential influence of
Swiss Federal Supreme Court decisions on future jurisprudence. Unlike existing
approaches that rely on resource-intensive manual annotations, we
semi-automatically derive labels leading to a much larger dataset than
otherwise possible. Our dataset features a two-tier labeling system: (1) the
LD-Label, which identifies cases published as Leading Decisions (LD), and (2)
the Citation-Label, which ranks cases by their citation frequency and recency.
This allows for a more nuanced evaluation of case importance. We evaluate
several multilingual models, including fine-tuned variants and large language
models, and find that fine-tuned models consistently outperform zero-shot
baselines, demonstrating the need for task-specific adaptation. Our
contributions include the introduction of this task and the release of a
multilingual dataset to the research community.

摘要：預測案件嚴重性有助於法院系統中的法律專業人士管理大量的案例法。本文介紹了嚴重性預測資料集，這是評估瑞士聯邦最高法院裁決對未來法學潛在影響的新資源。與依賴於資源密集型手動註解的現有方法不同，我們半自動衍生標籤，從而產生比其他情況下更大的資料集。我們的資料集具有兩層標籤系統：(1) LD 標籤，用於識別公佈為領先判例 (LD) 的案件，以及 (2) 引文標籤，根據案件的引文頻率和近期性對其進行排名。這允許對案件重要性進行更細緻的評估。我們評估了多種多語言模型，包括微調變體和大型語言模型，並發現微調模型始終優於零次學習基準，這證明了對特定任務進行適應的必要性。我們的貢獻包括引入此任務以及向研究社群發布多語言資料集。

##### **MedINST: Meta Dataset of Biomedical Instructions**
2410.13458v1 by Wenhan Han, Meng Fang, Zihan Zhang, Yu Yin, Zirui Song, Ling Chen, Mykola Pechenizkiy, Qingyu Chen

The integration of large language model (LLM) techniques in the field of
medical analysis has brought about significant advancements, yet the scarcity
of large, diverse, and well-annotated datasets remains a major challenge.
Medical data and tasks, which vary in format, size, and other parameters,
require extensive preprocessing and standardization for effective use in
training LLMs. To address these challenges, we introduce MedINST, the Meta
Dataset of Biomedical Instructions, a novel multi-domain, multi-task
instructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over
7 million training samples, making it the most comprehensive biomedical
instruction dataset to date. Using MedINST as the meta dataset, we curate
MedINST32, a challenging benchmark with different task difficulties aiming to
evaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and
evaluate on MedINST32, showcasing enhanced cross-task generalization.

摘要：大型語言模型 (LLM) 技術在醫學分析領域的整合帶來了顯著的進展，但缺乏大型、多樣且標註完善的資料集仍然是一項重大挑戰。
醫療資料和任務在格式、大小和其他參數上有所不同，需要廣泛的預處理和標準化才能在訓練 LLM 中有效使用。為了應對這些挑戰，我們引入了 MedINST，即生物醫學指令的元資料集，這是一個新穎的多領域、多任務指令元資料集。MedINST 包含 133 個生物醫學 NLP 任務和超過 700 萬個訓練樣本，使其成為迄今為止最全面的生物醫學指令資料集。使用 MedINST 作為元資料集，我們策劃了 MedINST32，這是一個具有不同任務難度的具有挑戰性的基準，旨在評估 LLM 的泛化能力。我們在 MedINST 上微調了多個 LLM，並在 MedINST32 上進行評估，展示了增強的跨任務泛化。

##### **Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland**
2410.13456v1 by Luca Rolshoven, Vishvaksenan Rasiah, Srinanda Brügger Bose, Matthias Stürmer, Joel Niklaus

Legal research is a time-consuming task that most lawyers face on a daily
basis. A large part of legal research entails looking up relevant caselaw and
bringing it in relation to the case at hand. Lawyers heavily rely on summaries
(also called headnotes) to find the right cases quickly. However, not all
decisions are annotated with headnotes and writing them is time-consuming.
Automated headnote creation has the potential to make hundreds of thousands of
decisions more accessible for legal research in Switzerland alone. To kickstart
this, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a
novel cross-lingual resource featuring 18K court rulings from the Swiss Federal
Supreme Court (SFSC), in German, French, and Italian, along with German
headnotes. We fine-tune and evaluate three mT5 variants, along with proprietary
models. Our analysis highlights that while proprietary models perform well in
zero-shot and one-shot settings, fine-tuned smaller models still provide a
strong competitive edge. We publicly release the dataset to facilitate further
research in multilingual legal summarization and the development of assistive
technologies for legal professionals

摘要：法律研究是一項耗時的任務，大多數律師每天都會面臨。法律研究的很大一部分涉及查找相關案例法，並將其與手頭的案件聯繫起來。律師在很大程度上依賴摘要（也稱為標題註釋）來快速找到正確的案件。然而，並非所有判決都附有標題註釋，而且撰寫標題註釋非常耗時。自動標題註釋的創建有可能讓瑞士的法律研究更容易獲得數十萬個判決。為了啟動這項工作，我們引入了瑞士領先判決摘要 (SLDS) 數據集，這是一個新穎的跨語言資源，其中包含來自瑞士聯邦最高法院 (SFSC) 的 18K 份法庭裁決，使用德語、法語和意大利語，以及德語標題註釋。我們對三種 mT5 變體以及專有模型進行微調和評估。我們的分析強調，儘管專有模型在零次學習和一次學習設置中表現良好，但經過微調的小型模型仍然提供了強大的競爭優勢。我們公開發布數據集，以促進多語言法律摘要和法律專業人士輔助技術的進一步研究

##### **Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR**
2410.13445v1 by Abhishek Gupta, Amruta Parulekar, Sameep Chattopadhyay, Preethi Jyothi

Automatic speech recognition (ASR) for low-resource languages remains a
challenge due to the scarcity of labeled training data. Parameter-efficient
fine-tuning and text-only adaptation are two popular methods that have been
used to address such low-resource settings. In this work, we investigate how
these techniques can be effectively combined using a multilingual multimodal
model like SeamlessM4T. Multimodal models are able to leverage unlabeled text
via text-only adaptation with further parameter-efficient ASR fine-tuning, thus
boosting ASR performance. We also show cross-lingual transfer from a
high-resource language, achieving up to a relative 17% WER reduction over a
baseline in a zero-shot setting without any labeled speech.

摘要：由於標籤訓練資料的稀少性，低資源語言的自動語音辨識（ASR）仍然是一個挑戰。參數有效微調和僅文字適應是兩種用於解決此類低資源設定的熱門方法。在這項工作中，我們研究如何使用 SeamlessM4T 等多語言多模態模型有效地結合這些技術。多模態模型能夠透過僅文字適應和進一步參數有效的 ASR 微調來利用未標記文字，從而提升 ASR 效能。我們還展示了從高資源語言的跨語言轉移，在沒有任何標籤語音的零次學習設定中，相較於基準，WER 降低了相對 17%。

##### **NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task**
2410.13443v1 by Maharaj Brahma, Pramit Sahoo, Maunendra Sankar Desarkar

This paper describes NLIP Lab's multilingual machine translation system for
the WAT24 shared task on multilingual Indic MT task for 22 scheduled languages
belonging to 4 language families. We explore pre-training for Indic languages
using alignment agreement objectives. We utilize bi-lingual dictionaries to
substitute words from source sentences. Furthermore, we fine-tuned language
direction-specific multilingual translation models using small and high-quality
seed data. Our primary submission is a 243M parameters multilingual translation
model covering 22 Indic languages. In the IN22-Gen benchmark, we achieved an
average chrF++ score of 46.80 and 18.19 BLEU score for the En-Indic direction.
In the Indic-En direction, we achieved an average chrF++ score of 56.34 and
30.82 BLEU score. In the In22-Conv benchmark, we achieved an average chrF++
score of 43.43 and BLEU score of 16.58 in the En-Indic direction, and in the
Indic-En direction, we achieved an average of 52.44 and 29.77 for chrF++ and
BLEU respectively. Our model\footnote{Our code and models are available at
\url{https://github.com/maharajbrahma/WAT2024-MultiIndicMT}} is competitive
with IndicTransv1 (474M parameter model).

摘要：這篇論文描述 NLIP 實驗室的多語言機器翻譯系統，用於 WAT24 共享任務，針對 4 個語言家族的 22 種預定語言進行多語言印度翻譯任務。我們使用對齊協議目標來探索印度語言的預訓練。我們利用雙語字典來替換來源句中的字詞。此外，我們使用少量且高品質的種子資料微調語言方向特定的多語言翻譯模型。我們的主要提交是一個涵蓋 22 種印度語言的 243M 參數多語言翻譯模型。在 IN22-Gen 基準中，我們在 En-Indic 方向達到了 46.80 的平均 chrF++ 分數和 18.19 的 BLEU 分數。在 Indic-En 方向，我們達到了 56.34 的平均 chrF++ 分數和 30.82 的 BLEU 分數。在 In22-Conv 基準中，我們在 En-Indic 方向達到了 43.43 的平均 chrF++ 分數和 16.58 的 BLEU 分數，而在 Indic-En 方向，我們分別達到了 chrF++ 和 BLEU 的平均 52.44 和 29.77。我們的模型\footnote{我們的程式碼和模型可在\url{https://github.com/maharajbrahma/WAT2024-MultiIndicMT} 取得}具有與 IndicTransv1（474M 參數模型）競爭的實力。

##### **Instruction-Driven Game Engine: A Poker Case Study**
2410.13441v1 by Hongqiu Wu, Xingyuan Liu, Yan Wang, Hai Zhao

The Instruction-Driven Game Engine (IDGE) project aims to democratize game
development by enabling a large language model (LLM) to follow free-form game
descriptions and generate game-play processes. The IDGE allows users to create
games simply by natural language instructions, which significantly lowers the
barrier for game development. We approach the learning process for IDGEs as a
Next State Prediction task, wherein the model autoregressively predicts the
game states given player actions. The computation of game states must be
precise; otherwise, slight errors could corrupt the game-play experience. This
is challenging because of the gap between stability and diversity. To address
this, we train the IDGE in a curriculum manner that progressively increases its
exposure to complex scenarios. Our initial progress lies in developing an IDGE
for Poker, which not only supports a wide range of poker variants but also
allows for highly individualized new poker games through natural language
inputs. This work lays the groundwork for future advancements in transforming
how games are created and played.

摘要：指令驅動遊戲引擎 (IDGE) 計畫旨在透過讓大型語言模型 (LLM) 遵循自由形式的遊戲描述並產生遊戲玩法流程，來民主化遊戲開發。IDGE 允許使用者僅透過自然語言指令來建立遊戲，這大幅降低了遊戲開發的門檻。我們將 IDGE 的學習過程視為一個下一個狀態預測任務，其中模型會根據玩家動作自動迴歸預測遊戲狀態。遊戲狀態的計算必須精確；否則，輕微的錯誤可能會破壞遊戲體驗。由於穩定性和多樣性之間的差距，這具有挑戰性。為了解決這個問題，我們以課程方式訓練 IDGE，逐漸增加它接觸複雜場景的機會。我們最初的進展在於為撲克開發一個 IDGE，它不僅支援各種撲克變體，還允許透過自然語言輸入建立高度個性化的全新撲克遊戲。這項工作為未來在轉變遊戲建立和遊玩方式方面奠定了基礎。

##### **Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport**
2410.13431v1 by Zhanpeng Wang, Shenghao Li, Chen Wang, Shuting Cao, Na Lei, Zhongxuan Luo

In recent years, the knowledge surrounding diffusion models(DMs) has grown
significantly, though several theoretical gaps remain. Particularly noteworthy
is prior error, defined as the discrepancy between the termination distribution
of the forward process and the initial distribution of the reverse process. To
address these deficiencies, this paper explores the deeper relationship between
optimal transport(OT) theory and DMs with discrete initial distribution.
Specifically, we demonstrate that the two stages of DMs fundamentally involve
computing time-dependent OT. However, unavoidable prior error result in
deviation during the reverse process under quadratic transport cost. By proving
that as the diffusion termination time increases, the probability flow
exponentially converges to the gradient of the solution to the classical
Monge-Amp\`ere equation, we establish a vital link between these fields.
Therefore, static OT emerges as the most intrinsic single-step method for
bridging this theoretical potential gap. Additionally, we apply these insights
to accelerate sampling in both unconditional and conditional generation
scenarios. Experimental results across multiple image datasets validate the
effectiveness of our approach.

摘要：近年来，围绕扩散模型（DM）的知识已大幅增长，尽管仍存在一些理论差距。特别值得注意的是先验误差，其定义为正向过程的终止分布与反向过程的初始分布之间的差异。为了解决这些缺陷，本文探讨了最优传输（OT）理论与具有离散初始分布的 DM 之间的更深层次关系。具体来说，我们证明了 DM 的两个阶段从根本上涉及计算时变 OT。然而，不可避免的先验误差会导致二次传输成本下的反向过程中的偏差。通过证明随着扩散终止时间的增加，概率流以指数方式收敛到经典 Monge-Amp\`ere 方程解的梯度，我们建立了这些领域之间的重要联系。因此，静态 OT 作为弥合这一理论潜在差距的最内在单步方法而出现。此外，我们将这些见解应用于加速无条件和条件生成场景中的采样。跨多个图像数据集的实验结果验证了我们方法的有效性。

##### **Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting**
2410.13415v1 by Mikael Rinkinen, Lauri Koskinen, Olli Silven, Mehdi Safarpour

Reduced voltage operation is an effective technique for substantial energy
efficiency improvement in digital circuits. This brief introduces a simple
approach for enabling reduced voltage operation of Deep Neural Network (DNN)
accelerators by mere software modifications. Conventional approaches for
enabling reduced voltage operation e.g., Timing Error Detection (TED) systems,
incur significant development costs and overheads, while not being applicable
to the off-the-shelf components. Contrary to those, the solution proposed in
this paper relies on algorithm-based error detection, and hence, is implemented
with low development costs, does not require any circuit modifications, and is
even applicable to commodity devices. By showcasing the solution through
experimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we
demonstrate 18% to 25% energy saving with no accuracy loss of the models and
negligible throughput compromise (< 3.9%), considering the overheads from
integration of the error detection schemes into the DNN. The integration of
presented algorithmic solution into the design is simpler when compared
conventional TED based techniques that require extensive circuit-level
modifications, cell library characterizations or special support from the
design tools.

摘要：降低電壓運行是一種有效技術，可大幅提升數位電路的能源效率。本簡報介紹一種簡單方法，僅透過軟體修改，就能讓深度神經網路 (DNN) 加速器進行降低電壓運行。傳統的降低電壓運行方法，例如定時錯誤偵測 (TED) 系統，會產生大量的開發成本和額外負擔，而且不適用於現成元件。與這些方法相反，本文提出的解決方案仰賴於演算法為基礎的錯誤偵測，因此實作成本低，不需要任何電路修改，甚至適用於商品化裝置。我們透過在 GPU 平台上對熱門 DNN（例如 LeNet 和 VGG16）進行實驗，展示此解決方案，證明在不降低模型準確度和可忽略的吞吐量折衷（< 3.9%）的情況下，節省了 18% 至 25% 的能源，其中考慮了將錯誤偵測機制整合到 DNN 的額外負擔。與需要廣泛電路層級修改、儲存格函式庫特徵描述或設計工具的特殊支援的傳統 TED 基礎技術相比，將提出的演算法解決方案整合到設計中較為簡單。

##### **Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models**
2410.13413v1 by Chengyu Du, Jinyi Han, Yizhou Ying, Aili Chen, Qianyu He, Haokun Zhao, Sirui Xia, Haoran Guo, Jiaqing Liang, Zulong Chen, Liangyue Li, Yanghua Xiao

Recent advancements in large language models (LLMs) have demonstrated that
progressive refinement, rather than providing a single answer, results in more
accurate and thoughtful outputs. However, existing methods often rely heavily
on supervision signals to evaluate previous responses, making it difficult to
assess output quality in more open-ended scenarios effectively. Additionally,
these methods are typically designed for specific tasks, which limits their
generalization to new domains. To address these limitations, we propose
Progressive Thought Refinement (PTR), a framework that enables LLMs to refine
their responses progressively. PTR operates in two phases: (1) Thought data
construction stage: We propose a weak and strong model collaborative selection
strategy to build a high-quality progressive refinement dataset to ensure
logical consistency from thought to answers, and the answers are gradually
refined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training
structure to mask the "thought" and adjust loss weights to encourage LLMs to
refine prior thought, teaching them to implicitly understand "how to improve"
rather than "what is correct." Experimental results show that PTR significantly
enhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)
without task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also
demonstrate substantial improvements in the quality of responses beyond mere
accuracy, suggesting that PTR truly teaches LLMs to self-improve over time.

摘要：大型語言模型 (LLM) 的最新進展表明，漸進式精煉（而非提供單一答案）會產生更準確且經過深思熟慮的輸出。然而，現有方法通常嚴重依賴監督訊號來評估先前的回應，這使得在更開放式的場景中有效評估輸出品質變得困難。此外，這些方法通常是針對特定任務而設計，這限制了它們對新領域的泛化能力。為了解決這些限制，我們提出了漸進式思考精煉 (PTR)，這是一個框架，讓 LLM 能夠漸進式精煉其回應。PTR 分為兩個階段運作：(1) 思考資料建構階段：我們提出一個弱強模型協作選擇策略，以建構一個高品質的漸進式精煉資料集，確保從思考到答案的邏輯一致性，並且在每一輪中逐漸精煉答案。(2) 思考遮罩微調階段：我們設計了一個訓練結構來遮罩「思考」並調整損失權重，以鼓勵 LLM 精煉先前的思考，教導它們隱含地理解「如何改進」而非「什麼是正確的」。實驗結果顯示，PTR 在十項不同的任務中顯著提升了 LLM 的效能（平均從 49.6% 提升至 53.5%），而無需針對特定任務進行微調。值得注意的是，在更開放式的任務中，LLM 在回應品質方面也有顯著的進步，不僅僅是準確性，這表明 PTR 真正教導 LLM 隨著時間推移而自我提升。

##### **Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans**
2410.13400v1 by Thanasis Troboukis, Kelly Kiki, Antonis Galanopoulos, Pavlos Sermpezis, Stelios Karamanidis, Ilias Dimitriadis, Athena Vakali

This chapter introduces a research project titled "Analyzing the Political
Discourse: A Collaboration Between Humans and Artificial Intelligence", which
was initiated in preparation for Greece's 2023 general elections. The project
focused on the analysis of political leaders' campaign speeches, employing
Artificial Intelligence (AI), in conjunction with an interdisciplinary team
comprising journalists, a political scientist, and data scientists. The chapter
delves into various aspects of political discourse analysis, including
sentiment analysis, polarization, populism, topic detection, and Named Entities
Recognition (NER). This experimental study investigates the capabilities of
large language model (LLMs), and in particular OpenAI's ChatGPT, for analyzing
political speech, evaluates its strengths and weaknesses, and highlights the
essential role of human oversight in using AI in journalism projects and
potentially other societal sectors. The project stands as an innovative example
of human-AI collaboration (known also as "hybrid intelligence") within the
realm of digital humanities, offering valuable insights for future initiatives.

摘要：本章介紹了一項名為「分析政治話語：人類與人工智慧的合作」的研究計畫，該計畫為 2023 年希臘大選所做準備。計畫重點在於分析政治領袖的競選演說，並採用人工智慧 (AI)，與由記者、政治學家和資料科學家組成的跨領域團隊攜手合作。本章深入探討政治話語分析的各個面向，包括情緒分析、兩極化、民粹主義、主題偵測和命名實體辨識 (NER)。這項實驗研究探討大型語言模型 (LLM) 的功能，特別是 OpenAI 的 ChatGPT，用於分析政治演說，評估其優缺點，並強調在新聞專題和潛在其他社會領域中使用 AI 時，人類監督的重要角色。該計畫是數位人文領域中人類與 AI 合作（也稱為「混合智慧」）的創新範例，為未來的倡議提供有價值的見解。

##### **Linguistically Grounded Analysis of Language Models using Shapley Head Values**
2410.13396v1 by Marcell Fekete, Johannes Bjerva

Understanding how linguistic knowledge is encoded in language models is
crucial for improving their generalisation capabilities. In this paper, we
investigate the processing of morphosyntactic phenomena, by leveraging a
recently proposed method for probing language models via Shapley Head Values
(SHVs). Using the English language BLiMP dataset, we test our approach on two
widely used models, BERT and RoBERTa, and compare how linguistic constructions
such as anaphor agreement and filler-gap dependencies are handled. Through
quantitative pruning and qualitative clustering analysis, we demonstrate that
attention heads responsible for processing related linguistic phenomena cluster
together. Our results show that SHV-based attributions reveal distinct patterns
across both models, providing insights into how language models organize and
process linguistic information. These findings support the hypothesis that
language models learn subnetworks corresponding to linguistic theory, with
potential implications for cross-linguistic model analysis and interpretability
in Natural Language Processing (NLP).

摘要：理解语言模型如何对语言知识进行编码对于提升其泛化能力至关重要。在本文中，我们通过利用一种最近提出的方法来探查语言模型，该方法通过 Shapley Head Values (SHV) 来探查语言模型，从而研究形态句法现象的处理。使用英语 BLiMP 数据集，我们在两个广泛使用的模型 BERT 和 RoBERTa 上测试我们的方法，并比较了语言结构（例如代词一致性和填充词-空缺依赖关系）是如何被处理的。通过定量剪枝和定性聚类分析，我们证明了负责处理相关语言现象的注意力头部会聚在一起。我们的结果表明，基于 SHV 的归因揭示了两个模型中不同的模式，从而提供了语言模型如何组织和处理语言信息的一些见解。这些发现支持了这样的假设：语言模型学习与语言理论相对应的子网络，这对于跨语言模型分析和自然语言处理 (NLP) 中的可解释性具有潜在影响。

##### **Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs**
2410.13394v1 by Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M. Khapra

Evaluating machine-generated text remains a significant challenge in NLP,
especially for non-English languages. Current methodologies, including
automated metrics, human assessments, and LLM-based evaluations, predominantly
focus on English, revealing a significant gap in multilingual evaluation
frameworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an
extensible framework that includes evaluator LLMs (Hercule) and a novel test
set (Recon) specifically designed for multilingual evaluation. Our test set
features 500 human-annotated instructions spanning various task capabilities
along with human judgment scores across six languages. This would enable
benchmarking of general-purpose multilingual LLMs and facilitate
meta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a
cross-lingual evaluation model that addresses the scarcity of reference answers
in the target language by learning to assign scores to responses based on
easily available reference answers in English. Our experiments demonstrate that
Hercule aligns more closely with human judgments compared to proprietary
models, demonstrating the effectiveness of such cross-lingual evaluation in low
resource scenarios. Further, it is also effective in zero-shot evaluation on
unseen languages. This study is the first comprehensive examination of
cross-lingual evaluation using LLMs, presenting a scalable and effective
approach for multilingual assessment. All code, datasets, and models will be
publicly available to enable further research in this important area.

摘要：機器產生的文字評估在自然語言處理中仍然是一項重大的挑戰，特別是非英語語言。目前的技術方法，包括自動化指標、人工評估和基於 LLM 的評估，主要集中在英語，顯示多語言評估框架存在顯著差距。我們引入了跨語言自動評估 (CIA) 套件，這是一個可擴充套件的框架，包括評估器 LLM（Hercule）和一個專門設計用於多語言評估的新測試集 (Recon)。我們的測試集包含 500 個經過人工註解的指令，涵蓋各種任務能力，以及六種語言的人類判斷分數。這將能夠對通用多語言 LLM 進行基準測試，並促進評估器 LLM 的元評估。所提出的模型 Hercule 是一個跨語言評估模型，透過學習根據英文中容易取得的參考答案對回應進行評分，來解決目標語言中參考答案的稀缺性。我們的實驗證明，與專有模型相比，Hercule 與人類判斷更為一致，證明了這種跨語言評估在資源不足的情況下的有效性。此外，它在對未見語言進行零次學習評估時也很有效。這項研究是使用 LLM 進行跨語言評估的第一個全面檢查，提出了一個可擴充且有效的多語言評估方法。所有程式碼、資料集和模型都將公開，以促進這個重要領域的進一步研究。

##### **Metacognitive Monitoring: A Human Ability Beyond Generative Artificial Intelligence**
2410.13392v1 by Markus Huff, Elanur Ulakçı

Large language models (LLMs) have shown impressive alignment with human
cognitive processes, raising questions about the extent of their similarity to
human cognition. This study investigates whether LLMs, specifically ChatGPT,
possess metacognitive monitoring abilities akin to humans-particularly in
predicting memory performance on an item-by-item basis. We employed a
cross-agent prediction model to compare the metacognitive performance of humans
and ChatGPT in a language-based memory task involving garden-path sentences
preceded by either fitting or unfitting context sentences. Both humans and
ChatGPT rated the memorability of these sentences; humans then completed a
surprise recognition memory test. Our findings reveal a significant positive
relationship between humans' memorability ratings and their actual recognition
performance, indicating reliable metacognitive monitoring. In contrast, ChatGPT
did not exhibit a similar predictive capability. Bootstrapping analyses
demonstrated that none of the GPT models tested (GPT-3.5-turbo, GPT-4-turbo,
GPT-4o) could accurately predict human memory performance on a per-item basis.
This suggests that, despite their advanced language processing abilities and
alignment with human cognition at the object level, current LLMs lack the
metacognitive mechanisms that enable humans to anticipate their memory
performance. These results highlight a fundamental difference between human and
AI cognition at the metacognitive level. Addressing this gap is crucial for
developing AI systems capable of effective self-monitoring and adaptation to
human needs, thereby enhancing human-AI interactions across domains such as
education and personalized learning.

摘要：<paragraph>大型語言模型 (LLM) 已展現與人類認知過程高度一致，引發了它們與人類認知相似程度的疑問。本研究探討 LLM，特別是 ChatGPT，是否具備與人類相似的元認知監控能力，特別是在逐項預測記憶表現方面。我們採用跨代理預測模型，比較人類與 ChatGPT 在語言記憶任務中的元認知表現，該任務涉及花園路徑句，前面是適當或不適當的上下文句。人類和 ChatGPT 都評估了這些句子的可記憶性；然後，人類完成了一個驚喜的識別記憶測試。我們的研究結果顯示，人類的可記憶性評分與他們的實際識別表現之間存在顯著的正相關關係，表明可靠的元認知監控。相比之下，ChatGPT 沒有表現出類似的預測能力。自舉分析表明，所測試的 GPT 模型（GPT-3.5-turbo、GPT-4-turbo、GPT-4o）都不能準確預測人類逐項的記憶表現。這表明，儘管它們具有先進的語言處理能力並在對象層面上與人類認知保持一致，但當前的 LLM 缺乏使人類能夠預測其記憶表現的元認知機制。這些結果突出了人類和人工智能認知在元認知層面的根本區別。解決這一差距對於開發能夠有效自我監控和適應人類需求的人工智能系統至關重要，從而增強人機交互在教育和個性化學習等領域的應用。</paragraph>

##### **Context-aware adaptive personalised recommendation: a meta-hybrid**
2410.13374v1 by Peter Tibensky, Michal Kompan

Recommenders take place on a wide scale of e-commerce systems, reducing the
problem of information overload. The most common approach is to choose a
recommender used by the system to make predictions. However, users vary from
each other; thus, a one-fits-all approach seems to be sub-optimal. In this
paper, we propose a meta-hybrid recommender that uses machine learning to
predict an optimal algorithm. In this way, the best-performing recommender is
used for each specific session and user. This selection depends on contextual
and preferential information collected about the user. We use standard
MovieLens and The Movie DB datasets for offline evaluation. We show that based
on the proposed model, it is possible to predict which recommender will provide
the most precise recommendations to a user. The theoretical performance of our
meta-hybrid outperforms separate approaches by 20-50% in normalized Discounted
Gain and Root Mean Square Error metrics. However, it is hard to obtain the
optimal performance based on widely-used standard information stored about
users.

摘要：推薦系統廣泛應用於電子商務系統中，用來減少資訊超載的問題。最常見的方法是選擇系統使用的推薦系統來進行預測。然而，使用者之間存在差異；因此，一刀切的方法似乎並非最佳。在本文中，我們提出一個元混合推薦系統，它使用機器學習來預測最佳演算法。這樣一來，針對每個特定階段和使用者，都會使用效能最佳的推薦系統。此選擇取決於關於使用者的脈絡和偏好資訊收集。我們使用標準的 MovieLens 和 The Movie DB 資料集進行離線評估。我們展示基於建議模型，可以預測哪個推薦系統會為使用者提供最精確的推薦。我們的元混合的理論效能，在標準化折扣收益和均方根誤差指標上，比個別方法高出 20-50%。然而，很難根據儲存在使用者中的廣泛使用的標準資訊，獲得最佳效能。

##### **MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models**
2410.13370v1 by Donghao Zhou, Jiancheng Huang, Jinbin Bai, Jiaze Wang, Hao Chen, Guangyong Chen, Xiaowei Hu, Pheng-Ann Heng

Recent advancements in text-to-image (T2I) diffusion models have enabled the
creation of high-quality images from text prompts, but they still struggle to
generate images with precise control over specific visual concepts. Existing
approaches can replicate a given concept by learning from reference images, yet
they lack the flexibility for fine-grained customization of the individual
component within the concept. In this paper, we introduce
component-controllable personalization, a novel task that pushes the boundaries
of T2I models by allowing users to reconfigure specific components when
personalizing visual concepts. This task is particularly challenging due to two
primary obstacles: semantic pollution, where unwanted visual elements corrupt
the personalized concept, and semantic imbalance, which causes disproportionate
learning of the concept and component. To overcome these challenges, we design
MagicTailor, an innovative framework that leverages Dynamic Masked Degradation
(DM-Deg) to dynamically perturb undesired visual semantics and Dual-Stream
Balancing (DS-Bal) to establish a balanced learning paradigm for desired visual
semantics. Extensive comparisons, ablations, and analyses demonstrate that
MagicTailor not only excels in this challenging task but also holds significant
promise for practical applications, paving the way for more nuanced and
creative image generation.

摘要：最近文本到图像 (T2I) 扩散模型的进步使得可以从文本提示中创建高质量的图像，但它们仍然难以生成对特定视觉概念进行精确控制的图像。现有的方法可以通过从参考图像中学习来复制给定的概念，但它们缺乏对概念中各个组件进行细粒度定制的灵活性。在本文中，我们引入了组件可控个性化，这是一项新颖的任务，它通过允许用户在个性化视觉概念时重新配置特定组件来突破 T2I 模型的界限。由于两个主要的障碍，这项任务特别具有挑战性：语义污染，其中不需要的视觉元素会破坏个性化的概念，以及语义不平衡，这会导致对概念和组件的不成比例的学习。为了克服这些挑战，我们设计了 MagicTailor，一个创新的框架，它利用动态掩码降级 (DM-Deg) 来动态扰动不需要的视觉语义，并利用双流平衡 (DS-Bal) 为所需的视觉语义建立一个平衡的学习范例。广泛的比较、消融和分析表明，MagicTailor 不仅在这个具有挑战性的任务中表现出色，而且对实际应用也具有重大意义，为更加细致入微和创造性的图像生成铺平了道路。

##### **Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistant**
2410.13360v1 by Haoran Hao, Jiaming Han, Changsheng Li, Yu-Feng Li, Xiangyu Yue

The development of large language models (LLMs) has significantly enhanced
the capabilities of multimodal LLMs (MLLMs) as general assistants. However,
lack of user-specific knowledge still restricts their application in human's
daily life. In this paper, we introduce the Retrieval Augmented Personalization
(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we
turn it into a personalized assistant in three steps. (a) Remember: We design a
key-value database to store user-related information, e.g., user's name, avatar
and other attributes. (b) Retrieve: When the user initiates a conversation, RAP
will retrieve relevant information from the database using a multimodal
retriever. (c) Generate: The input query and retrieved concepts' information
are fed into MLLMs to generate personalized, knowledge-augmented responses.
Unlike previous methods, RAP allows real-time concept editing via updating the
external database. To further improve generation quality and alignment with
user-specific information, we design a pipeline for data collection and create
a specialized dataset for personalized training of MLLMs. Based on the dataset,
we train a series of MLLMs as personalized multimodal assistants. By
pretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual
concepts without additional finetuning. Our models demonstrate outstanding
flexibility and generation quality across a variety of tasks, such as
personalized image captioning, question answering and visual recognition. The
code, data and models are available at https://github.com/Hoar012/RAP-MLLM.

摘要：大型語言模型（LLM）的發展顯著提升了多模態 LLM（MLLM）作為一般助理的能力。然而，缺乏使用者特定的知識仍然限制了它們在人類日常生活中應用。在本文中，我們介紹了 MLLM 個人化的檢索擴增個人化（RAP）架構。從一般 MLLM 開始，我們透過三個步驟將其轉換為個人化助理。（a）記住：我們設計了一個鍵值資料庫來儲存使用者相關資訊，例如使用者的姓名、頭像和其他屬性。（b）檢索：當使用者開始對話時，RAP 將使用多模態檢索器從資料庫中檢索相關資訊。（c）產生：輸入查詢和檢索到的概念資訊會輸入到 MLLM 中，以產生個人化、知識擴增的回應。與之前的做法不同，RAP 允許透過更新外部資料庫來進行即時概念編輯。為了進一步提升生成品質和與使用者特定資訊的一致性，我們設計了一個資料收集管線，並建立一個專門的資料集，用於 MLLM 的個人化訓練。根據資料集，我們訓練了一系列 MLLM 作為個人化多模態助理。透過在大規模資料集上進行預訓練，RAP-MLLM 可以概括為無限的視覺概念，而不需要額外的微調。我們的模型在各種任務中展現出傑出的靈活性與生成品質，例如個人化影像標題、問題解答和視覺辨識。程式碼、資料和模型可在 https://github.com/Hoar012/RAP-MLLM 獲得。

##### **LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights**
2410.13352v1 by Odysseas S. Chlapanis, Dimitrios Galanis, Ion Androutsopoulos

We present Legal Argument Reasoning (LAR), a novel task designed to evaluate
the legal reasoning capabilities of Large Language Models (LLMs). The task
requires selecting the correct next statement (from multiple choice options) in
a chain of legal arguments from court proceedings, given the facts of the case.
We constructed a dataset (LAR-ECHR) for this task using cases from the European
Court of Human Rights (ECHR). We evaluated seven general-purpose LLMs on
LAR-ECHR and found that (a) the ranking of the models is aligned with that of
LegalBench, an established US-based legal reasoning benchmark, even though
LAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more
clearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8%
accuracy on LAR-ECHR, indicating significant potential for further model
improvement. The process followed to construct LAR-ECHR can be replicated with
cases from other legal systems.

摘要：<paragraph>我們提出法律論證推理 (LAR)，這是一項新任務，旨在評估大型語言模型 (LLM) 的法律推理能力。此任務需要在法庭程序的法律論證鏈中從多項選擇選項中選擇正確的下一陳述，並提供案件的事實。我們使用歐洲人權法院 (ECHR) 的案例為此任務構建了一個資料集 (LAR-ECHR)。我們在 LAR-ECHR 上評估了七個通用 LLM，發現 (a) 模型的排名與 LegalBench（一個既定的美國法律推理基準）的排名一致，即使 LAR-ECHR 是基於歐盟法律，(b) 與 LegalBench 相比，LAR-ECHR 更清楚地區分頂級模型，(c) 即使是最好的模型 (GPT-4o) 在 LAR-ECHR 上的準確率也只有 75.8%，這表示進一步改進模型有很大的潛力。構建 LAR-ECHR 所遵循的流程可以用其他法律體系的案例複製。</paragraph>

##### **Representation Learning of Structured Data for Medical Foundation Models**
2410.13351v1 by Vijay Prakash Dwivedi, Viktor Schlegel, Andy T. Liu, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Jeng Wei, Wei-Hsian Yin, Stefan Winkler, Robby T. Tan

Large Language Models (LLMs) have demonstrated remarkable performance across
various domains, including healthcare. However, their ability to effectively
represent structured non-textual data, such as the alphanumeric medical codes
used in records like ICD-10 or SNOMED-CT, is limited and has been particularly
exposed in recent research. This paper examines the challenges LLMs face in
processing medical codes due to the shortcomings of current tokenization
methods. As a result, we introduce the UniStruct architecture to design a
multimodal medical foundation model of unstructured text and structured data,
which addresses these challenges by adapting subword tokenization techniques
specifically for the structured medical codes. Our approach is validated
through model pre-training on both an extensive internal medical database and a
public repository of structured medical records. Trained on over 1 billion
tokens on the internal medical database, the proposed model achieves up to a
23% improvement in evaluation metrics, with around 2% gain attributed to our
proposed tokenization. Additionally, when evaluated on the EHRSHOT public
benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model
improves performance on over 42% of the downstream tasks. Our approach not only
enhances the representation and generalization capabilities of patient-centric
models but also bridges a critical gap in representation learning models'
ability to handle complex structured medical data, alongside unstructured text.

摘要：大型語言模型 (LLM) 已在各種領域展現出卓越的效能，包括醫療保健。然而，它們有效表示結構化非文字資料的能力，例如病歷中使用的字母數字醫療碼，例如 ICD-10 或 SNOMED-CT，受到限制，並且在最近的研究中特別明顯。本文探討由於當前標記化方法的缺點，LLM 在處理醫療碼時面臨的挑戰。因此，我們引入了 UniStruct 架構來設計非結構化文字和結構化資料的多模態醫療基礎模型，它透過特別針對結構化醫療碼調整次字標記化技術來解決這些挑戰。我們的做法透過在廣泛的內部醫療資料庫和結構化醫療記錄的公開儲存庫上進行模型預訓練來驗證。在內部醫療資料庫上訓練超過 10 億個標記，所提出的模型在評估指標中獲得高達 23% 的改進，其中約 2% 的收益歸功於我們提出的標記化。此外，在使用 1/1000 的預訓練資料對 EHRSHOT 公開基準進行評估時，UniStruct 模型在超過 42% 的下游任務中提升了效能。我們的做法不僅增強了以患者為中心的模型的表示和概化能力，還彌補了表示學習模型處理複雜結構化醫療資料的能力與非結構化文字之間的關鍵差距。

##### **Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement**
2410.13344v1 by Yuxuan Liu, Wenyuan Li, Laizhong Cui, Hailiang Yang

Large language models (LLMs) often face a bottleneck in inference speed due
to their reliance on auto-regressive decoding. Recently, parallel decoding has
shown significant promise in enhancing inference efficiency. However, we have
identified two key issues with existing parallel decoding frameworks: (1)
decoding heads fail to balance prediction accuracy and the parallelism of
execution, and (2) parallel decoding is not a universal solution, as it can
bring unnecessary overheads at some challenging decoding steps. To address
these issues, we propose Cerberus, an adaptive parallel decoding framework
introduces the gating mechanism to enable the LLMs to adaptively choose
appropriate decoding approaches at each decoding step, along with introducing a
new paradigm of decoding heads that introduce the sequential knowledge while
maintaining execution parallelism. The experiment results demonstrate that the
Cerberus can achieve up to 2.12x speed up compared to auto-regressive decoding,
and outperforms one of the leading parallel decoding frameworks, Medusa, with a
10% - 30% increase in acceleration and superior generation quality.

摘要：大語言模型（LLM）通常會因依賴自迴歸解碼而導致推論速度出現瓶頸。最近，平行解碼已展現出顯著的提升推論效率的潛力。然而，我們已找出現有的平行解碼架構中存在的兩個主要問題：(1) 解碼器無法在預測準確度和執行並行性之間取得平衡，以及 (2) 平行解碼並非通用的解決方案，因為它可能會在某些具有挑戰性的解碼步驟中帶來不必要的開銷。為了解決這些問題，我們提出 Cerberus，這是一個自適應平行解碼架構，引入了閘控機制，讓 LLM 能夠在每個解碼步驟中自適應地選擇適當的解碼方法，同時引入一種新的解碼器範例，在維持執行並行性的同時，引入了順序知識。實驗結果顯示，與自迴歸解碼相比，Cerberus 可以將速度提升達 2.12 倍，並優於其中一個領先的平行解碼架構 Medusa，加速提升 10% - 30%，且生成品質更佳。

##### **Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models**
2410.13343v1 by Yu Yuan, Lili Zhao, Kai Zhang, Guangting Zheng, Qi Liu

Large Language Models (LLMs) have shown remarkable capabilities in various
natural language processing tasks. However, LLMs may rely on dataset biases as
shortcuts for prediction, which can significantly impair their robustness and
generalization capabilities. This paper presents Shortcut Suite, a
comprehensive test suite designed to evaluate the impact of shortcuts on LLMs'
performance, incorporating six shortcut types, five evaluation metrics, and
four prompting strategies. Our extensive experiments yield several key
findings: 1) LLMs demonstrate varying reliance on shortcuts for downstream
tasks, significantly impairing their performance. 2) Larger LLMs are more
likely to utilize shortcuts under zero-shot and few-shot in-context learning
prompts. 3) Chain-of-thought prompting notably reduces shortcut reliance and
outperforms other prompting strategies, while few-shot prompts generally
underperform compared to zero-shot prompts. 4) LLMs often exhibit
overconfidence in their predictions, especially when dealing with datasets that
contain shortcuts. 5) LLMs generally have a lower explanation quality in
shortcut-laden datasets, with errors falling into three types: distraction,
disguised comprehension, and logical fallacy. Our findings offer new insights
for evaluating robustness and generalization in LLMs and suggest potential
directions for mitigating the reliance on shortcuts. The code is available at
\url {https://github.com/yyhappier/ShortcutSuite.git}.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出非凡的能力。然而，LLM 可能依賴於資料集偏差作為預測的捷徑，這可能會顯著損害其穩健性和泛化能力。本文提出 Shortcut Suite，這是一個全面的測試套件，旨在評估捷徑對 LLM 效能的影響，並整合六種捷徑類型、五種評估指標和四種提示策略。我們廣泛的實驗產生了幾個關鍵發現：1) LLM 展示出對下游任務捷徑的不同依賴性，顯著損害其效能。2) 較大的 LLM 更可能在零次學習和少量學習情境學習提示下使用捷徑。3) 思考鏈提示顯著降低對捷徑的依賴，並優於其他提示策略，而少量提示通常表現不如零次提示。4) LLM 經常對其預測過度自信，尤其是在處理包含捷徑的資料集時。5) LLM 在捷徑資料集中通常具有較低的解釋品質，錯誤分為三種類型：分心、偽裝理解和邏輯謬誤。我們的發現為評估 LLM 中的穩健性和泛化提供了新的見解，並提出減輕對捷徑依賴的潛在方向。程式碼可在\url {https://github.com/yyhappier/ShortcutSuite.git} 取得。

