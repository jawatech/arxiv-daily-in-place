{"2412.19433": {"publish_time": "2024-12-27", "title": "Residual Feature-Reutilization Inception Network for Image Classification", "paper_summary": "Capturing feature information effectively is of great importance in the field\nof computer vision. With the development of convolutional neural networks\n(CNNs), concepts like residual connection and multiple scales promote continual\nperformance gains in diverse deep learning vision tasks. In this paper, we\npropose a novel CNN architecture that it consists of residual\nfeature-reutilization inceptions (ResFRI) or split-residual\nfeature-reutilization inceptions (Split-ResFRI). And it is composed of four\nconvolutional combinations of different structures connected by specially\ndesigned information interaction passages, which are utilized to extract\nmulti-scale feature information and effectively increase the receptive field of\nthe model. Moreover, according to the network structure designed above,\nSplit-ResFRI can adjust the segmentation ratio of the input information,\nthereby reducing the number of parameters and guaranteeing the model\nperformance. Specifically, in experiments based on popular vision datasets,\nsuch as CIFAR10 ($97.94$\\%), CIFAR100 ($85.91$\\%) and Tiny Imagenet\n($70.54$\\%), we obtain state-of-the-art results compared with other modern\nmodels under the premise that the model size is approximate and no additional\ndata is used.", "paper_summary_zh": "\u5728\u96fb\u8166\u8996\u89ba\u9818\u57df\u4e2d\uff0c\u6709\u6548\u64f7\u53d6\u7279\u5fb5\u8cc7\u8a0a\u975e\u5e38\u91cd\u8981\u3002\u96a8\u8457\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u7684\u767c\u5c55\uff0c\u6b98\u5dee\u9023\u63a5\u548c\u591a\u91cd\u5c3a\u5ea6\u7b49\u6982\u5ff5\u6301\u7e8c\u63d0\u5347\u5404\u7a2e\u6df1\u5ea6\u5b78\u7fd2\u8996\u89ba\u4efb\u52d9\u7684\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684 CNN \u67b6\u69cb\uff0c\u5b83\u5305\u542b\u6b98\u5dee\u7279\u5fb5\u518d\u5229\u7528 inception (ResFRI) \u6216\u5206\u5272\u6b98\u5dee\u7279\u5fb5\u518d\u5229\u7528 inception (Split-ResFRI)\u3002\u5b83\u7531\u56db\u500b\u5377\u7a4d\u7d44\u5408\u7d44\u6210\uff0c\u9019\u4e9b\u7d44\u5408\u7531\u7279\u5225\u8a2d\u8a08\u7684\u8cc7\u8a0a\u4ea4\u4e92\u901a\u9053\u9023\u63a5\uff0c\u7528\u65bc\u8403\u53d6\u591a\u5c3a\u5ea6\u7279\u5fb5\u8cc7\u8a0a\uff0c\u4e26\u6709\u6548\u589e\u52a0\u6a21\u578b\u7684\u611f\u53d7\u91ce\u3002\u6b64\u5916\uff0c\u6839\u64da\u4e0a\u8ff0\u8a2d\u8a08\u7684\u7db2\u8def\u7d50\u69cb\uff0cSplit-ResFRI \u53ef\u4ee5\u8abf\u6574\u8f38\u5165\u8cc7\u8a0a\u7684\u5206\u5272\u6bd4\u7387\uff0c\u5f9e\u800c\u6e1b\u5c11\u53c3\u6578\u6578\u91cf\u4e26\u4fdd\u8b49\u6a21\u578b\u6548\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u57fa\u65bc\u6d41\u884c\u8996\u89ba\u8cc7\u6599\u96c6\u7684\u5be6\u9a57\u4e2d\uff0c\u4f8b\u5982 CIFAR10 (97.94%)\u3001CIFAR100 (85.91%) \u548c Tiny Imagenet (70.54%)\uff0c\u6211\u5011\u5728\u6a21\u578b\u5927\u5c0f\u8fd1\u4f3c\u4e14\u672a\u4f7f\u7528\u984d\u5916\u8cc7\u6599\u7684\u524d\u63d0\u4e0b\uff0c\u7372\u5f97\u4e86\u8207\u5176\u4ed6\u73fe\u4ee3\u6a21\u578b\u76f8\u6bd4\u6700\u5148\u9032\u7684\u7d50\u679c\u3002", "author": "Yuanpeng He et.al.", "authors": "Yuanpeng He, Wenjie Song, Lijian Li, Tianxiang Zhan, Wenpin Jiao", "id": "2412.19433v1", "paper_url": "http://arxiv.org/abs/2412.19433v1", "repo": "null"}}