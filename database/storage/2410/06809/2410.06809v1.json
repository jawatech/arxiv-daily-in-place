{"2410.06809": {"publish_time": "2024-10-09", "title": "Root Defence Strategies: Ensuring Safety of LLM at the Decoding Level", "paper_summary": "Large language models (LLMs) have demonstrated immense utility across various\nindustries. However, as LLMs advance, the risk of harmful outputs increases due\nto incorrect or malicious instruction prompts. While current methods\neffectively address jailbreak risks, they share common limitations: 1) Judging\nharmful responses from the prefill-level lacks utilization of the model's\ndecoding outputs, leading to relatively lower effectiveness and robustness. 2)\nRejecting potentially harmful responses based on a single evaluation can\nsignificantly impair the model's helpfulness.This paper examines the LLMs'\ncapability to recognize harmful outputs, revealing and quantifying their\nproficiency in assessing the danger of previous tokens. Motivated by pilot\nexperiment results, we design a robust defense mechanism at the decoding level.\nOur novel decoder-oriented, step-by-step defense architecture corrects harmful\nqueries directly rather than rejecting them outright. We introduce speculative\ndecoding to enhance usability and facilitate deployment to boost secure\ndecoding speed. Extensive experiments demonstrate that our approach improves\nmodel security without compromising reasoning speed. Notably, our method\nleverages the model's ability to discern hazardous information, maintaining its\nhelpfulness compared to existing methods.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7522\u696d\u5c55\u793a\u51fa\u6975\u5927\u7684\u6548\u7528\u3002\u7136\u800c\uff0c\u96a8\u8457 LLM \u7684\u9032\u6b65\uff0c\u7531\u65bc\u932f\u8aa4\u6216\u60e1\u610f\u7684\u6307\u4ee4\u63d0\u793a\uff0c\u6709\u5bb3\u8f38\u51fa\u7684\u98a8\u96aa\u4e5f\u96a8\u4e4b\u589e\u52a0\u3002\u96d6\u7136\u76ee\u524d\u7684\u6280\u8853\u80fd\u6709\u6548\u89e3\u6c7a\u8d8a\u7344\u98a8\u96aa\uff0c\u4f46\u5b83\u5011\u6709\u5171\u540c\u7684\u9650\u5236\uff1a1) \u5f9e\u9810\u586b\u5c64\u7d1a\u5224\u65b7\u6709\u5bb3\u56de\u61c9\u7f3a\u4e4f\u5229\u7528\u6a21\u578b\u7684\u89e3\u78bc\u8f38\u51fa\uff0c\u5c0e\u81f4\u76f8\u5c0d\u8f03\u4f4e\u7684\u6709\u6548\u6027\u548c\u7a69\u5065\u6027\u30022) \u6839\u64da\u55ae\u4e00\u8a55\u4f30\u62d2\u7d55\u6f5b\u5728\u6709\u5bb3\u7684\u56de\u61c9\u6703\u986f\u8457\u640d\u5bb3\u6a21\u578b\u7684\u5e6b\u52a9\u6027\u3002\u672c\u6587\u63a2\u8a0e\u4e86 LLM \u8b58\u5225\u6709\u5bb3\u8f38\u51fa\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e26\u91cf\u5316\u4e86\u5b83\u5011\u8a55\u4f30\u5148\u524d\u6a19\u8a18\u5371\u96aa\u7684\u80fd\u529b\u3002\u53d7\u8a66\u9a57\u7d50\u679c\u555f\u767c\uff0c\u6211\u5011\u5728\u89e3\u78bc\u5c64\u7d1a\u8a2d\u8a08\u4e86\u4e00\u500b\u5f37\u5065\u7684\u9632\u79a6\u6a5f\u5236\u3002\u6211\u5011\u65b0\u7a4e\u7684\u9762\u5411\u89e3\u78bc\u5668\u3001\u9010\u6b65\u9032\u884c\u7684\u9632\u79a6\u67b6\u69cb\u6703\u76f4\u63a5\u4fee\u6b63\u6709\u5bb3\u67e5\u8a62\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u62d2\u7d55\u5b83\u5011\u3002\u6211\u5011\u5f15\u5165\u4e86\u63a8\u6e2c\u6027\u89e3\u78bc\u4f86\u589e\u5f37\u53ef\u7528\u6027\uff0c\u4e26\u4fc3\u9032\u90e8\u7f72\u4ee5\u63d0\u5347\u5b89\u5168\u7684\u89e3\u78bc\u901f\u5ea6\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u5be6\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u6539\u5584\u4e86\u6a21\u578b\u5b89\u5168\u6027\uff0c\u540c\u6642\u4e0d\u5f71\u97ff\u63a8\u7406\u901f\u5ea6\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8207\u73fe\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u5229\u7528\u4e86\u6a21\u578b\u8fa8\u5225\u6709\u5bb3\u8cc7\u8a0a\u7684\u80fd\u529b\uff0c\u7dad\u6301\u4e86\u5176\u5e6b\u52a9\u6027\u3002", "author": "Xinyi Zeng et.al.", "authors": "Xinyi Zeng, Yuying Shang, Yutao Zhu, Jiawei Chen, Yu Tian", "id": "2410.06809v1", "paper_url": "http://arxiv.org/abs/2410.06809v1", "repo": "null"}}