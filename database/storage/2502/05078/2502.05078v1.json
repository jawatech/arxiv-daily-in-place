{"2502.05078": {"publish_time": "2025-02-07", "title": "Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures", "paper_summary": "Large Language Models (LLMs) have demonstrated impressive reasoning\ncapabilities, yet their performance is highly dependent on the prompting\nstrategy and model scale. While reinforcement learning and fine-tuning have\nbeen deployed to boost reasoning, these approaches incur substantial\ncomputational and data overhead. In this work, we introduce Adaptive Graph of\nThoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM\nreasoning solely at test time. Rather than relying on fixed-step methods like\nChain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes\ncomplex queries into structured subproblems, forming an dynamic directed\nacyclic graph (DAG) of interdependent reasoning steps. By selectively expanding\nonly those subproblems that require further analysis, AGoT unifies the\nstrengths of chain, tree, and graph paradigms into a cohesive framework that\nallocates computation where it is most needed. We validate our approach on\ndiverse benchmarks spanning multi-hop retrieval, scientific reasoning, and\nmathematical problem-solving, achieving up to 46.2% improvement on scientific\nreasoning tasks (GPQA) - comparable to gains achieved through computationally\nintensive reinforcement learning approaches and outperforming state-of-the-art\niterative approaches. These results suggest that dynamic decomposition and\nstructured recursion offer a scalable, cost-effective alternative to\npost-training modifications, paving the way for more robust, general-purpose\nreasoning in LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u6548\u80fd\u9ad8\u5ea6\u4f9d\u8cf4\u65bc\u63d0\u793a\u7b56\u7565\u548c\u6a21\u578b\u898f\u6a21\u3002\u96d6\u7136\u5f37\u5316\u5b78\u7fd2\u548c\u5fae\u8abf\u5df2\u88ab\u7528\u65bc\u63d0\u5347\u63a8\u7406\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u6703\u9020\u6210\u5927\u91cf\u7684\u904b\u7b97\u548c\u8cc7\u6599\u958b\u92b7\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u300c\u9069\u61c9\u6027\u601d\u8003\u5716\u300d(AGoT)\uff0c\u4e00\u500b\u52d5\u614b\u7684\u3001\u57fa\u65bc\u5716\u5f62\u7684\u63a8\u8ad6\u67b6\u69cb\uff0c\u5b83\u50c5\u5728\u6e2c\u8a66\u6642\u5c31\u80fd\u589e\u5f37 LLM \u63a8\u7406\u3002AGoT \u4e26\u975e\u4f9d\u8cf4\u65bc\u93c8\u5f0f\u601d\u8003 (CoT) \u6216\u6a39\u72c0\u601d\u8003 (ToT) \u7b49\u56fa\u5b9a\u6b65\u9a5f\u65b9\u6cd5\uff0c\u800c\u662f\u905e\u8ff4\u5730\u5c07\u8907\u96dc\u7684\u67e5\u8a62\u5206\u89e3\u6210\u7d50\u69cb\u5316\u7684\u5b50\u554f\u984c\uff0c\u5f62\u6210\u4e00\u500b\u7531\u76f8\u4e92\u4f9d\u8cf4\u7684\u63a8\u7406\u6b65\u9a5f\u6240\u7d44\u6210\u7684\u52d5\u614b\u6709\u5411\u7121\u74b0\u5716 (DAG)\u3002\u900f\u904e\u9078\u64c7\u6027\u5730\u50c5\u64f4\u5145\u90a3\u4e9b\u9700\u8981\u9032\u4e00\u6b65\u5206\u6790\u7684\u5b50\u554f\u984c\uff0cAGoT \u5c07\u93c8\u5f0f\u3001\u6a39\u72c0\u548c\u5716\u5f62\u7bc4\u4f8b\u7684\u512a\u52e2\u7d71\u4e00\u5230\u4e00\u500b\u7dca\u5bc6\u7684\u67b6\u69cb\u4e2d\uff0c\u5c07\u904b\u7b97\u5206\u914d\u5230\u6700\u9700\u8981\u7684\u5730\u65b9\u3002\u6211\u5011\u5728\u8de8\u8d8a\u591a\u91cd\u8df3\u8e8d\u6aa2\u7d22\u3001\u79d1\u5b78\u63a8\u7406\u548c\u6578\u5b78\u554f\u984c\u89e3\u6c7a\u7b49\u591a\u6a23\u57fa\u6e96\u4e0a\u9a57\u8b49\u4e86\u6211\u5011\u7684\u505a\u6cd5\uff0c\u5728\u79d1\u5b78\u63a8\u7406\u4efb\u52d9 (GPQA) \u4e0a\u9054\u5230\u4e86\u9ad8\u9054 46.2% \u7684\u6539\u9032\uff0c\u9019\u8207\u900f\u904e\u904b\u7b97\u5bc6\u96c6\u7684\u5f37\u5316\u5b78\u7fd2\u65b9\u6cd5\u6240\u7372\u5f97\u7684\u589e\u76ca\u76f8\u7576\uff0c\u4e26\u4e14\u512a\u65bc\u6700\u5148\u9032\u7684\u8fed\u4ee3\u65b9\u6cd5\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0c\u52d5\u614b\u5206\u89e3\u548c\u7d50\u69cb\u5316\u905e\u8ff4\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u64f4\u5145\u3001\u5177\u6210\u672c\u6548\u76ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7528\u65bc\u8a13\u7df4\u5f8c\u4fee\u6539\uff0c\u70ba LLM \u4e2d\u66f4\u5f37\u5065\u3001\u66f4\u901a\u7528\u7684\u63a8\u7406\u92ea\u5e73\u4e86\u9053\u8def\u3002", "author": "Tushar Pandey et.al.", "authors": "Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha", "id": "2502.05078v1", "paper_url": "http://arxiv.org/abs/2502.05078v1", "repo": "null"}}