{"2405.04170": {"publish_time": "2024-05-07", "title": "D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models", "paper_summary": "Large language models (LLMs) have garnered significant attention and\nwidespread usage due to their impressive performance in various tasks. However,\nthey are not without their own set of challenges, including issues such as\nhallucinations, factual inconsistencies, and limitations in\nnumerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning\ntasks remains an active area of research. Prior to the breakthrough of LLMs,\nTransformers had already proven successful in the medical domain, effectively\nemployed for various natural language understanding (NLU) tasks. Following this\ntrend, LLMs have also been trained and utilized in the medical domain, raising\nconcerns regarding factual accuracy, adherence to safety protocols, and\ninherent limitations. In this paper, we focus on evaluating the natural\nlanguage inference capabilities of popular open-source and closed-source LLMs\nusing clinical trial reports as the dataset. We present the performance results\nof each LLM and further analyze their performance on a development set,\nparticularly focusing on challenging instances that involve medical\nabbreviations and require numerical-quantitative reasoning. Gemini, our leading\nLLM, achieved a test set F1-score of 0.748, securing the ninth position on the\ntask scoreboard. Our work is the first of its kind, offering a thorough\nexamination of the inference capabilities of LLMs within the medical domain.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u56e0\u5176\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7684\u51fa\u8272\u8868\u73fe\u800c\u5099\u53d7\u95dc\u6ce8\u548c\u5ee3\u6cdb\u4f7f\u7528\u3002\u7136\u800c\uff0c\u5b83\u5011\u4e26\u975e\u6c92\u6709\u81ea\u5df1\u7684\u6311\u6230\uff0c\u5305\u62ec\u5e7b\u89ba\u3001\u4e8b\u5be6\u4e0d\u4e00\u81f4\u4ee5\u53ca\u6578\u5b57\u5b9a\u91cf\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\u7b49\u554f\u984c\u3002\u5728\u5404\u7a2e\u63a8\u7406\u4efb\u52d9\u4e2d\u8a55\u4f30 LLM \u4ecd\u7136\u662f\u4e00\u500b\u6d3b\u8e8d\u7684\u7814\u7a76\u9818\u57df\u3002\u5728 LLM \u53d6\u5f97\u7a81\u7834\u4e4b\u524d\uff0cTransformers \u5df2\u5728\u91ab\u7642\u9818\u57df\u8b49\u660e\u4e86\u5176\u6210\u529f\uff0c\u6709\u6548\u5730\u7528\u65bc\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u7406\u89e3 (NLU) \u4efb\u52d9\u3002\u9075\u5faa\u9019\u4e00\u8da8\u52e2\uff0cLLM \u4e5f\u5df2\u5728\u91ab\u7642\u9818\u57df\u63a5\u53d7\u8a13\u7df4\u548c\u4f7f\u7528\uff0c\u5f15\u767c\u4e86\u5c0d\u4e8b\u5be6\u6e96\u78ba\u6027\u3001\u9075\u5b88\u5b89\u5168\u5354\u8b70\u548c\u56fa\u6709\u5c40\u9650\u6027\u7684\u64d4\u6182\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u4f7f\u7528\u81e8\u5e8a\u8a66\u9a57\u5831\u544a\u4f5c\u70ba\u6578\u64da\u96c6\u4f86\u8a55\u4f30\u6d41\u884c\u7684\u958b\u6e90\u548c\u9589\u6e90 LLM \u7684\u81ea\u7136\u8a9e\u8a00\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u5c55\u793a\u4e86\u6bcf\u500b LLM \u7684\u6027\u80fd\u7d50\u679c\uff0c\u4e26\u9032\u4e00\u6b65\u5206\u6790\u4e86\u5b83\u5011\u5728\u958b\u767c\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u7279\u5225\u95dc\u6ce8\u6d89\u53ca\u91ab\u7642\u7e2e\u5beb\u548c\u9700\u8981\u6578\u5b57\u5b9a\u91cf\u63a8\u7406\u7684\u5177\u6709\u6311\u6230\u6027\u7684\u5be6\u4f8b\u3002\u6211\u5011\u7684\u9818\u5148 LLM\u2014\u2014Gemini \u5728\u6e2c\u8a66\u96c6\u4e0a\u5be6\u73fe\u4e86 0.748 \u7684 F1 \u5206\u6578\uff0c\u5728\u4efb\u52d9\u6392\u884c\u699c\u4e0a\u7372\u5f97\u4e86\u7b2c\u4e5d\u540d\u3002\u6211\u5011\u7684\u9019\u9805\u5de5\u4f5c\u662f\u540c\u985e\u5de5\u4f5c\u4e2d\u7684\u7b2c\u4e00\u500b\uff0c\u63d0\u4f9b\u4e86\u5c0d LLM \u5728\u91ab\u7642\u9818\u57df\u5167\u63a8\u7406\u80fd\u529b\u7684\u5168\u9762\u6aa2\u9a57\u3002", "author": "Duygu Altinok et.al.", "authors": "Duygu Altinok", "id": "2405.04170v1", "paper_url": "http://arxiv.org/abs/2405.04170v1", "repo": "null"}}