{"2502.04040": {"publish_time": "2025-02-06", "title": "Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment", "paper_summary": "Training safe LLMs is one of the most critical research challenge. However,\nthe commonly used method, Refusal Training (RT), struggles to generalize\nagainst various OOD jailbreaking attacks. Many safety training methods have\nbeen proposed to address this issue. While they offer valuable insights, we aim\nto complement this line of research by investigating whether OOD attacks truly\nexceed the capability of RT model. Conducting evaluation with BoN, we observe\nsignificant improvements on generalization as N increases. This underscores\nthat the model possesses sufficient safety-related latent knowledge, but RT\nfails to consistently elicit this knowledge when addressing OOD attacks.\nFurther analysis based on domain adaptation reveals that training with direct\nrefusal causes model to rely on superficial shortcuts, resulting in learning of\nnon-robust representation mappings. Based on our findings, we propose training\nmodel to perform safety reasoning for each query. Reasoning supervision\nencourages model to perform more computations, explicitly eliciting and using\nlatent knowledge through reasoning. To achieve this, we synthesize reasoning\nsupervision based on pre-guidelines, training the model to reason in alignment\nwith them, thereby effectively eliciting and utilizing latent knowledge from\ndiverse perspectives. Extensive experiments show that our method significantly\nimproves generalization performance against OOD attacks.", "paper_summary_zh": "\u8a13\u7df4\u5b89\u5168\u7684 LLM \u662f\u6700\u91cd\u8981\u7684\u7814\u7a76\u6311\u6230\u4e4b\u4e00\u3002\u7136\u800c\uff0c\n\u5e38\u7528\u7684\u65b9\u6cd5\uff0c\u62d2\u7d55\u8a13\u7df4 (RT)\uff0c\u96e3\u4ee5\u6982\u62ec\n\u5404\u7a2e OOD \u8d8a\u7344\u653b\u64ca\u3002\u8a31\u591a\u5b89\u5168\u8a13\u7df4\u65b9\u6cd5\u5df2\n\u88ab\u63d0\u8b70\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u96d6\u7136\u5b83\u5011\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u6211\u5011\u65e8\u5728\n\u901a\u904e\u8abf\u67e5 OOD \u653b\u64ca\u662f\u5426\u771f\u6b63\u8d85\u904e RT \u6a21\u578b\u7684\u80fd\u529b\u4f86\u88dc\u5145\u9019\u689d\u7814\u7a76\u7dda\u3002\u4f7f\u7528 BoN \u9032\u884c\u8a55\u4f30\uff0c\u6211\u5011\u89c0\u5bdf\n\u96a8\u8457 N \u7684\u589e\u52a0\uff0c\u6cdb\u5316\u80fd\u529b\u986f\u8457\u63d0\u9ad8\u3002\u9019\u5f37\u8abf\n\u8a72\u6a21\u578b\u5177\u5099\u8db3\u5920\u7684\u5b89\u5168\u76f8\u95dc\u6f5b\u5728\u77e5\u8b58\uff0c\u4f46 RT\n\u5728\u8655\u7406 OOD \u653b\u64ca\u6642\u7121\u6cd5\u59cb\u7d42\u5982\u4e00\u5730\u5f15\u51fa\u9019\u7a2e\u77e5\u8b58\u3002\n\u57fa\u65bc\u57df\u9069\u61c9\u7684\u9032\u4e00\u6b65\u5206\u6790\u8868\u660e\uff0c\u76f4\u63a5\u8a13\u7df4\n\u62d2\u7d55\u5c0e\u81f4\u6a21\u578b\u4f9d\u8cf4\u65bc\u819a\u6dfa\u7684\u6377\u5f91\uff0c\u5c0e\u81f4\u5b78\u7fd2\n\u975e\u7a69\u5065\u8868\u793a\u6620\u5c04\u3002\u6839\u64da\u6211\u5011\u7684\u767c\u73fe\uff0c\u6211\u5011\u5efa\u8b70\u8a13\u7df4\n\u6a21\u578b\u70ba\u6bcf\u500b\u67e5\u8a62\u57f7\u884c\u5b89\u5168\u63a8\u7406\u3002\u63a8\u7406\u76e3\u7763\n\u9f13\u52f5\u6a21\u578b\u57f7\u884c\u66f4\u591a\u8a08\u7b97\uff0c\u901a\u904e\u63a8\u7406\u660e\u78ba\u5f15\u51fa\u4e26\u4f7f\u7528\n\u6f5b\u5728\u77e5\u8b58\u3002\u70ba\u6b64\uff0c\u6211\u5011\u6839\u64da\u9810\u6307\u5357\u5408\u6210\u63a8\u7406\n\u76e3\u7763\uff0c\u8a13\u7df4\u6a21\u578b\u8207\u5b83\u5011\u4fdd\u6301\u4e00\u81f4\uff0c\u5f9e\u800c\u6709\u6548\u5730\u5f15\u51fa\u548c\u5229\u7528\n\u4f86\u81ea\u4e0d\u540c\u89c0\u9ede\u7684\u6f5b\u5728\u77e5\u8b58\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\n\u65b9\u6cd5\u986f\u8457\u63d0\u9ad8\u4e86\u5c0d OOD \u653b\u64ca\u7684\u6cdb\u5316\u6027\u80fd\u3002", "author": "Haoyu Wang et.al.", "authors": "Haoyu Wang, Zeyu Qin, Li Shen, Xueqian Wang, Minhao Cheng, Dacheng Tao", "id": "2502.04040v1", "paper_url": "http://arxiv.org/abs/2502.04040v1", "repo": "null"}}