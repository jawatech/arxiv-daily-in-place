{"2409.17045": {"publish_time": "2024-09-25", "title": "GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design", "paper_summary": "We provide a dataset for enabling Deep Generative Models (DGMs) in\nengineering design and propose methods to automate data labeling by utilizing\nlarge-scale foundation models. GeoBiked is curated to contain 4 355 bicycle\nimages, annotated with structural and technical features and is used to\ninvestigate two automated labeling techniques: The utilization of consolidated\nlatent features (Hyperfeatures) from image-generation models to detect\ngeometric correspondences (e.g. the position of the wheel center) in structural\nimages and the generation of diverse text descriptions for structural images.\nGPT-4o, a vision-language-model (VLM), is instructed to analyze images and\nproduce diverse descriptions aligned with the system-prompt. By representing\ntechnical images as Diffusion-Hyperfeatures, drawing geometric correspondences\nbetween them is possible. The detection accuracy of geometric points in unseen\nsamples is improved by presenting multiple annotated source images. GPT-4o has\nsufficient capabilities to generate accurate descriptions of technical images.\nGrounding the generation only on images leads to diverse descriptions but\ncauses hallucinations, while grounding it on categorical labels restricts the\ndiversity. Using both as input balances creativity and accuracy. Successfully\nusing Hyperfeatures for geometric correspondence suggests that this approach\ncan be used for general point-detection and annotation tasks in technical\nimages. Labeling such images with text descriptions using VLMs is possible, but\ndependent on the models detection capabilities, careful prompt-engineering and\nthe selection of input information. Applying foundation models in engineering\ndesign is largely unexplored. We aim to bridge this gap with a dataset to\nexplore training, finetuning and conditioning DGMs in this field and suggesting\napproaches to bootstrap foundation models to process technical images.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u500b\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u5728\u5de5\u7a0b\u8a2d\u8a08\u4e2d\u555f\u7528\u6df1\u5ea6\u751f\u6210\u6a21\u578b (DGM)\uff0c\u4e26\u63d0\u51fa\u900f\u904e\u5229\u7528\u5927\u898f\u6a21\u57fa\u790e\u6a21\u578b\u81ea\u52d5\u5316\u8cc7\u6599\u6a19\u7c64\u7684\u65b9\u6cd5\u3002GeoBiked \u7d93\u904e\u7b56\u5c55\uff0c\u5305\u542b 4,355 \u5f35\u81ea\u884c\u8eca\u5f71\u50cf\uff0c\u4e26\u9644\u6709\u7d50\u69cb\u548c\u6280\u8853\u7279\u5fb5\u8a3b\u89e3\uff0c\u4e14\u7528\u65bc\u8abf\u67e5\u5169\u7a2e\u81ea\u52d5\u5316\u6a19\u7c64\u6280\u8853\uff1a\u5229\u7528\u5f71\u50cf\u751f\u6210\u6a21\u578b\u7684\u6574\u5408\u6f5b\u5728\u7279\u5fb5\uff08\u8d85\u7279\u5fb5\uff09\u4f86\u5075\u6e2c\u7d50\u69cb\u5f71\u50cf\u4e2d\u7684\u5e7e\u4f55\u5c0d\u61c9\uff08\u4f8b\u5982\u8eca\u8f2a\u4e2d\u5fc3\u7684\u4f4d\u5b50\uff09\uff0c\u4ee5\u53ca\u70ba\u7d50\u69cb\u5f71\u50cf\u7522\u751f\u591a\u6a23\u5316\u7684\u6587\u5b57\u63cf\u8ff0\u3002GPT-4o \u662f\u4e00\u500b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u6307\u793a\u8981\u5206\u6790\u5f71\u50cf\u4e26\u7522\u751f\u8207\u7cfb\u7d71\u63d0\u793a\u4e00\u81f4\u7684\u591a\u6a23\u5316\u63cf\u8ff0\u3002\u900f\u904e\u5c07\u6280\u8853\u5f71\u50cf\u8868\u793a\u70ba\u64f4\u6563\u8d85\u7279\u5fb5\uff0c\u5c31\u53ef\u4ee5\u7e6a\u88fd\u5b83\u5011\u4e4b\u9593\u7684\u5e7e\u4f55\u5c0d\u61c9\u3002\u900f\u904e\u5448\u73fe\u591a\u500b\u5e36\u8a3b\u89e3\u7684\u4f86\u6e90\u5f71\u50cf\uff0c\u53ef\u4ee5\u6539\u5584\u5728\u672a\u898b\u6a23\u672c\u4e2d\u5e7e\u4f55\u9ede\u7684\u5075\u6e2c\u6e96\u78ba\u5ea6\u3002GPT-4o \u5177\u6709\u8db3\u5920\u7684\u80fd\u529b\u4f86\u7522\u751f\u6280\u8853\u5f71\u50cf\u7684\u6e96\u78ba\u63cf\u8ff0\u3002\u50c5\u6839\u64da\u5f71\u50cf\u9032\u884c\u57fa\u790e\u6703\u7522\u751f\u591a\u6a23\u5316\u7684\u63cf\u8ff0\uff0c\u4f46\u6703\u7522\u751f\u5e7b\u89ba\uff0c\u800c\u6839\u64da\u5206\u985e\u6a19\u7c64\u9032\u884c\u57fa\u790e\u5247\u6703\u9650\u5236\u591a\u6a23\u6027\u3002\u5c07\u5169\u8005\u90fd\u7528\u4f5c\u8f38\u5165\uff0c\u53ef\u4ee5\u5e73\u8861\u5275\u9020\u529b\u548c\u6e96\u78ba\u6027\u3002\u6210\u529f\u5730\u5c07\u8d85\u7279\u5fb5\u7528\u65bc\u5e7e\u4f55\u5c0d\u61c9\uff0c\u8868\u793a\u9019\u7a2e\u65b9\u6cd5\u53ef\u7528\u65bc\u6280\u8853\u5f71\u50cf\u4e2d\u7684\u4e00\u822c\u9ede\u5075\u6e2c\u548c\u8a3b\u89e3\u4efb\u52d9\u3002\u4f7f\u7528 VLM \u6a19\u7c64\u6b64\u985e\u5f71\u50cf\u7684\u6587\u5b57\u63cf\u8ff0\u662f\u53ef\u884c\u7684\uff0c\u4f46\u53d6\u6c7a\u65bc\u6a21\u578b\u7684\u5075\u6e2c\u80fd\u529b\u3001\u4ed4\u7d30\u7684\u63d0\u793a\u5de5\u7a0b\u548c\u8f38\u5165\u8cc7\u8a0a\u7684\u9078\u64c7\u3002\u5728\u5de5\u7a0b\u8a2d\u8a08\u4e2d\u61c9\u7528\u57fa\u790e\u6a21\u578b\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5c1a\u672a\u63a2\u7d22\u3002\u6211\u5011\u65e8\u5728\u900f\u904e\u4e00\u500b\u8cc7\u6599\u96c6\u4f86\u586b\u88dc\u9019\u500b\u7a7a\u767d\uff0c\u4ee5\u63a2\u7d22\u5728\u9019\u500b\u9818\u57df\u8a13\u7df4\u3001\u5fae\u8abf\u548c\u8abf\u6574 DGM\uff0c\u4e26\u5efa\u8b70\u5f15\u5c0e\u57fa\u790e\u6a21\u578b\u8655\u7406\u6280\u8853\u5f71\u50cf\u7684\u65b9\u6cd5\u3002</paragraph>", "author": "Phillip Mueller et.al.", "authors": "Phillip Mueller, Sebastian Mueller, Lars Mikelsons", "id": "2409.17045v1", "paper_url": "http://arxiv.org/abs/2409.17045v1", "repo": "null"}}