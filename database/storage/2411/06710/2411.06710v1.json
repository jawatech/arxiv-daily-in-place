{"2411.06710": {"publish_time": "2024-11-11", "title": "Model Fusion through Bayesian Optimization in Language Model Fine-Tuning", "paper_summary": "Fine-tuning pre-trained models for downstream tasks is a widely adopted\ntechnique known for its adaptability and reliability across various domains.\nDespite its conceptual simplicity, fine-tuning entails several troublesome\nengineering choices, such as selecting hyperparameters and determining\ncheckpoints from an optimization trajectory. To tackle the difficulty of\nchoosing the best model, one effective solution is model fusion, which combines\nmultiple models in a parameter space. However, we observe a large discrepancy\nbetween loss and metric landscapes during the fine-tuning of pre-trained\nlanguage models. Building on this observation, we introduce a novel model\nfusion technique that optimizes both the desired metric and loss through\nmulti-objective Bayesian optimization. In addition, to effectively select\nhyperparameters, we establish a two-stage procedure by integrating Bayesian\noptimization processes into our framework. Experiments across various\ndownstream tasks show considerable performance improvements using our Bayesian\noptimization-guided method.", "paper_summary_zh": "\u5fae\u8abf\u9810\u8a13\u7df4\u6a21\u578b\u4ee5\u9032\u884c\u4e0b\u6e38\u4efb\u52d9\u662f\u4e00\u7a2e\u5ee3\u6cdb\u63a1\u7528\u7684\u6280\u8853\uff0c\u4ee5\u5176\u5728\u5404\u7a2e\u9818\u57df\u7684\u9069\u61c9\u6027\u548c\u53ef\u9760\u6027\u800c\u805e\u540d\u3002\u5118\u7ba1\u5176\u6982\u5ff5\u7c21\u55ae\uff0c\u4f46\u5fae\u8abf\u9700\u8981\u9032\u884c\u591a\u9805\u7e41\u7463\u7684\u5de5\u7a0b\u9078\u64c7\uff0c\u4f8b\u5982\u9078\u64c7\u8d85\u53c3\u6578\u548c\u78ba\u5b9a\u512a\u5316\u8ecc\u8de1\u4e2d\u7684\u6aa2\u67e5\u9ede\u3002\u70ba\u4e86\u89e3\u6c7a\u9078\u64c7\u6700\u4f73\u6a21\u578b\u7684\u96e3\u984c\uff0c\u4e00\u7a2e\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\u662f\u6a21\u578b\u878d\u5408\uff0c\u5b83\u5728\u53c3\u6578\u7a7a\u9593\u4e2d\u7d50\u5408\u4e86\u591a\u500b\u6a21\u578b\u3002\u7136\u800c\uff0c\u6211\u5011\u5728\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u7684\u5fae\u8abf\u904e\u7a0b\u4e2d\u89c0\u5bdf\u5230\u640d\u5931\u548c\u6307\u6a19\u666f\u89c0\u4e4b\u9593\u5b58\u5728\u5f88\u5927\u5dee\u7570\u3002\u57fa\u65bc\u9019\u4e00\u89c0\u5bdf\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u6a21\u578b\u878d\u5408\u6280\u8853\uff0c\u901a\u904e\u591a\u76ee\u6a19\u8c9d\u8449\u65af\u512a\u5316\u4f86\u512a\u5316\u6240\u9700\u7684\u6307\u6a19\u548c\u640d\u5931\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u6709\u6548\u5730\u9078\u64c7\u8d85\u53c3\u6578\uff0c\u6211\u5011\u901a\u904e\u5c07\u8c9d\u8449\u65af\u512a\u5316\u6d41\u7a0b\u6574\u5408\u5230\u6211\u5011\u7684\u6846\u67b6\u4e2d\u4f86\u5efa\u7acb\u4e00\u500b\u5169\u968e\u6bb5\u7a0b\u5e8f\u3002\u5728\u5404\u7a2e\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u5be6\u9a57\u8868\u660e\uff0c\u4f7f\u7528\u6211\u5011\u7684\u8c9d\u8449\u65af\u512a\u5316\u6307\u5c0e\u65b9\u6cd5\u986f\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "author": "Chaeyun Jang et.al.", "authors": "Chaeyun Jang, Hyungi Lee, Jungtaek Kim, Juho Lee", "id": "2411.06710v1", "paper_url": "http://arxiv.org/abs/2411.06710v1", "repo": "https://github.com/chaeyoon-jang/bomf"}}