{"2412.18185": {"publish_time": "2024-12-24", "title": "TextMatch: Enhancing Image-Text Consistency Through Multimodal Optimization", "paper_summary": "Text-to-image generative models excel in creating images from text but\nstruggle with ensuring alignment and consistency between outputs and prompts.\nThis paper introduces TextMatch, a novel framework that leverages multimodal\noptimization to address image-text discrepancies in text-to-image (T2I)\ngeneration and editing. TextMatch employs a scoring strategy powered by large\nlanguage models (LLMs) and visual question-answering (VQA) models to evaluate\nsemantic consistency between prompts and generated images. By integrating\nmultimodal in-context learning and chain of thought reasoning, our method\ndynamically refines prompts through iterative optimization. This process\nensures that the generated images better capture user intent of, resulting in\nhigher fidelity and relevance. Extensive experiments demonstrate that TextMatch\nsignificantly improves text-image consistency across multiple benchmarks,\nestablishing a reliable framework for advancing the capabilities of\ntext-to-image generative models. Our code is available at\nhttps://anonymous.4open.science/r/TextMatch-F55C/.", "paper_summary_zh": "\u6587\u5b57\u5230\u5f71\u50cf\u751f\u6210\u6a21\u578b\u5728\u6839\u64da\u6587\u5b57\u5efa\u7acb\u5f71\u50cf\u65b9\u9762\u8868\u73fe\u512a\u7570\uff0c\u4f46\u96e3\u4ee5\u78ba\u4fdd\u8f38\u51fa\u8207\u63d0\u793a\u4e4b\u9593\u7684\u4e00\u81f4\u6027\u548c\u5c0d\u9f4a\u3002\u672c\u6587\u4ecb\u7d39 TextMatch\uff0c\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u5229\u7528\u591a\u6a21\u614b\u6700\u4f73\u5316\u4f86\u89e3\u6c7a\u6587\u5b57\u5230\u5f71\u50cf (T2I) \u751f\u6210\u548c\u7de8\u8f2f\u4e2d\u7684\u5f71\u50cf\u6587\u5b57\u5dee\u7570\u3002TextMatch \u63a1\u7528\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u8996\u89ba\u554f\u7b54 (VQA) \u6a21\u578b\u63d0\u4f9b\u652f\u63f4\u7684\u8a55\u5206\u7b56\u7565\uff0c\u4ee5\u8a55\u4f30\u63d0\u793a\u548c\u751f\u6210\u5f71\u50cf\u4e4b\u9593\u7684\u8a9e\u7fa9\u4e00\u81f4\u6027\u3002\u900f\u904e\u6574\u5408\u591a\u6a21\u614b\u60c5\u5883\u5b78\u7fd2\u548c\u601d\u7dad\u93c8\u63a8\u7406\uff0c\u6211\u5011\u7684\u6a21\u578b\u900f\u904e\u53cd\u8986\u6700\u4f73\u5316\u52d5\u614b\u5730\u6539\u5584\u63d0\u793a\u3002\u9019\u500b\u7a0b\u5e8f\u53ef\u78ba\u4fdd\u751f\u6210\u7684\u5f71\u50cf\u66f4\u80fd\u6355\u6349\u4f7f\u7528\u8005\u7684\u610f\u5716\uff0c\u5e36\u4f86\u66f4\u9ad8\u7684\u4fdd\u771f\u5ea6\u548c\u76f8\u95dc\u6027\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e TextMatch \u5927\u5e45\u6539\u5584\u4e86\u591a\u500b\u57fa\u6e96\u4e2d\u7684\u6587\u5b57\u5f71\u50cf\u4e00\u81f4\u6027\uff0c\u70ba\u63d0\u5347\u6587\u5b57\u5230\u5f71\u50cf\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\u5efa\u7acb\u4e86\u4e00\u500b\u53ef\u9760\u7684\u67b6\u69cb\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://anonymous.4open.science/r/TextMatch-F55C/ \u53d6\u5f97\u3002", "author": "Yucong Luo et.al.", "authors": "Yucong Luo, Mingyue Cheng, Jie Ouyang, Xiaoyu Tao, Qi Liu", "id": "2412.18185v1", "paper_url": "http://arxiv.org/abs/2412.18185v1", "repo": "null"}}