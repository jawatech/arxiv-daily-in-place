{"2406.11547": {"publish_time": "2024-06-17", "title": "GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations", "paper_summary": "Large pre-trained language models have become popular for many applications\nand form an important backbone of many downstream tasks in natural language\nprocessing (NLP). Applying 'explainable artificial intelligence' (XAI)\ntechniques to enrich such models' outputs is considered crucial for assuring\ntheir quality and shedding light on their inner workings. However, large\nlanguage models are trained on a plethora of data containing a variety of\nbiases, such as gender biases, affecting model weights and, potentially,\nbehavior. Currently, it is unclear to what extent such biases also impact model\nexplanations in possibly unfavorable ways. We create a gender-controlled text\ndataset, GECO, in which otherwise identical sentences appear in male and female\nforms. This gives rise to ground-truth 'world explanations' for gender\nclassification tasks, enabling the objective evaluation of the correctness of\nXAI methods. We also provide GECOBench, a rigorous quantitative evaluation\nframework benchmarking popular XAI methods, applying them to pre-trained\nlanguage models fine-tuned to different degrees. This allows us to investigate\nhow pre-training induces undesirable bias in model explanations and to what\nextent fine-tuning can mitigate such explanation bias. We show a clear\ndependency between explanation performance and the number of fine-tuned layers,\nwhere XAI methods are observed to particularly benefit from fine-tuning or\ncomplete retraining of embedding layers. Remarkably, this relationship holds\nfor models achieving similar classification performance on the same task. With\nthat, we highlight the utility of the proposed gender-controlled dataset and\nnovel benchmarking approach for research and development of novel XAI methods.\nAll code including dataset generation, model training, evaluation and\nvisualization is available at: https://github.com/braindatalab/gecobench", "paper_summary_zh": "<paragraph>\u5927\u578b\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u5df2\u5ee3\u6cdb\u61c9\u7528\u65bc\u8a31\u591a\u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0c\u4e26\u69cb\u6210\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u8a31\u591a\u4e0b\u6e38\u4efb\u52d9\u7684\u91cd\u8981\u9aa8\u5e79\u3002\u5c07\u300c\u53ef\u89e3\u91cb\u4eba\u5de5\u667a\u6167\u300d(XAI) \u6280\u8853\u61c9\u7528\u65bc\u8c50\u5bcc\u6b64\u985e\u6a21\u578b\u7684\u8f38\u51fa\uff0c\u88ab\u8a8d\u70ba\u5c0d\u65bc\u78ba\u4fdd\u5176\u54c1\u8cea\u4e26\u95e1\u660e\u5176\u5167\u90e8\u904b\u4f5c\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u662f\u5728\u5305\u542b\u5404\u7a2e\u504f\u5dee\u7684\u9f90\u5927\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\uff0c\u4f8b\u5982\u6027\u5225\u504f\u5dee\uff0c\u6703\u5f71\u97ff\u6a21\u578b\u6b0a\u91cd\u548c\u6f5b\u5728\u884c\u70ba\u3002\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u6b64\u985e\u504f\u5dee\u5728\u4f55\u7a2e\u7a0b\u5ea6\u4e0a\u4e5f\u6703\u4ee5\u53ef\u80fd\u4e0d\u5229\u7684\u5f71\u97ff\u6a21\u578b\u89e3\u91cb\u3002\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u6027\u5225\u63a7\u5236\u6587\u5b57\u8cc7\u6599\u96c6 GECO\uff0c\u5176\u4e2d\u539f\u672c\u76f8\u540c\u7684\u53e5\u5b50\u4ee5\u7537\u6027\u548c\u5973\u6027\u5f62\u5f0f\u51fa\u73fe\u3002\u9019\u7522\u751f\u4e86\u6027\u5225\u5206\u985e\u4efb\u52d9\u7684\u771f\u5be6\u300c\u4e16\u754c\u89e3\u91cb\u300d\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u5ba2\u89c0\u8a55\u4f30 XAI \u65b9\u6cd5\u7684\u6b63\u78ba\u6027\u3002\u6211\u5011\u9084\u63d0\u4f9b\u4e86 GECOBench\uff0c\u9019\u662f\u4e00\u500b\u56b4\u8b39\u7684\u91cf\u5316\u8a55\u4f30\u67b6\u69cb\uff0c\u7528\u65bc\u5c0d\u6d41\u884c\u7684 XAI \u65b9\u6cd5\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\uff0c\u5c07\u5b83\u5011\u61c9\u7528\u65bc\u7d93\u904e\u4e0d\u540c\u7a0b\u5ea6\u5fae\u8abf\u7684\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u3002\u9019\u4f7f\u6211\u5011\u80fd\u5920\u7814\u7a76\u9810\u8a13\u7df4\u5982\u4f55\u5c0e\u81f4\u6a21\u578b\u89e3\u91cb\u4e2d\u51fa\u73fe\u4e0d\u826f\u504f\u5dee\uff0c\u4ee5\u53ca\u5fae\u8abf\u53ef\u4ee5\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u6e1b\u8f15\u9019\u7a2e\u89e3\u91cb\u504f\u5dee\u3002\u6211\u5011\u5c55\u793a\u4e86\u89e3\u91cb\u6548\u80fd\u8207\u5fae\u8abf\u5c64\u6578\u4e4b\u9593\u7684\u660e\u986f\u4f9d\u8cf4\u95dc\u4fc2\uff0c\u5176\u4e2d\u89c0\u5bdf\u5230 XAI \u65b9\u6cd5\u7279\u5225\u53d7\u76ca\u65bc\u5fae\u8abf\u6216\u5d4c\u5165\u5c64\u7684\u5b8c\u6574\u91cd\u65b0\u8a13\u7df4\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u9019\u7a2e\u95dc\u4fc2\u9069\u7528\u65bc\u5728\u540c\u4e00\u4efb\u52d9\u4e0a\u5be6\u73fe\u985e\u4f3c\u5206\u985e\u6548\u80fd\u7684\u6a21\u578b\u3002\u6709\u4e86\u9019\u4e9b\uff0c\u6211\u5011\u5f37\u8abf\u4e86\u6240\u63d0\u51fa\u7684\u6027\u5225\u63a7\u5236\u8cc7\u6599\u96c6\u548c\u65b0\u57fa\u6e96\u6e2c\u8a66\u65b9\u6cd5\u5c0d\u65b0 XAI \u65b9\u6cd5\u7684\u7814\u7a76\u548c\u958b\u767c\u7684\u6548\u7528\u3002\u6240\u6709\u7a0b\u5f0f\u78bc\uff0c\u5305\u62ec\u8cc7\u6599\u96c6\u751f\u6210\u3001\u6a21\u578b\u8a13\u7df4\u3001\u8a55\u4f30\u548c\u8996\u89ba\u5316\uff0c\u90fd\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u53d6\u5f97\uff1ahttps://github.com/braindatalab/gecobench</paragraph>", "author": "Rick Wilming et.al.", "authors": "Rick Wilming, Artur Dox, Hjalmar Schulz, Marta Oliveira, Benedict Clark, Stefan Haufe", "id": "2406.11547v1", "paper_url": "http://arxiv.org/abs/2406.11547v1", "repo": "https://github.com/braindatalab/gecobench"}}