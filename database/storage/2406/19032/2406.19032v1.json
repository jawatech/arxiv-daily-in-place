{"2406.19032": {"publish_time": "2024-06-27", "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment", "paper_summary": "Large language models (LLMs) are now rapidly advancing and surpassing human\nabilities on many natural language tasks. However, aligning these super-human\nLLMs with human knowledge remains challenging because the supervision signals\nfrom human annotators may be wrong. This issue, known as the \"super-alignment\"\nproblem, requires enhancing weak-to-strong generalization, where a strong LLM\nmust generalize from imperfect supervision provided by a weaker source. To\naddress this issue, we propose an approach to improve weak-to-strong\ngeneralization by involving the reliability of weak supervision signals in the\nalignment process. In our method, we query the weak supervisor for multiple\nanswers, estimate the answer reliability, and enhance the alignment process by\nfiltering out uncertain data or re-weighting reliable data. Experiments on four\ndatasets demonstrate that our methods effectively identify the quality of weak\nlabels and significantly enhance weak-to-strong generalization. Our work\npresents effective techniques for error-robust model alignment, reducing error\npropagation from noisy supervision and enhancing the accuracy and reliability\nof LLMs. Codes are publicly available at\nhttp://github.com/Irenehere/ReliableAlignment.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u73fe\u5728\u6b63\u5feb\u901f\u9032\u6b65\uff0c\u5728\u8a31\u591a\u81ea\u7136\u8a9e\u8a00\u4efb\u52d9\u4e0a\u8d85\u8d8a\u4eba\u985e\u80fd\u529b\u3002\u7136\u800c\uff0c\u8b93\u9019\u4e9b\u8d85\u4eba\u985e LLM \u8207\u4eba\u985e\u77e5\u8b58\u4fdd\u6301\u4e00\u81f4\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u4f86\u81ea\u4eba\u985e\u8a3b\u91cb\u8005\u7684\u76e3\u7763\u4fe1\u865f\u53ef\u80fd\u932f\u8aa4\u3002\u9019\u500b\u554f\u984c\u7a31\u70ba\u300c\u8d85\u7d1a\u5c0d\u9f4a\u300d\u554f\u984c\uff0c\u9700\u8981\u589e\u5f37\u5f9e\u5f31\u5230\u5f37\u7684\u6982\u62ec\u80fd\u529b\uff0c\u5176\u4e2d\u5f37\u5927\u7684 LLM \u5fc5\u9808\u5f9e\u8f03\u5f31\u4f86\u6e90\u63d0\u4f9b\u7684\u4e26\u4e0d\u5b8c\u7f8e\u7684\u76e3\u7763\u4e2d\u9032\u884c\u6982\u62ec\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b9\u6cd5\uff0c\u900f\u904e\u5728\u5c0d\u9f4a\u904e\u7a0b\u4e2d\u7d0d\u5165\u5f31\u76e3\u7763\u4fe1\u865f\u7684\u53ef\u9760\u6027\u4f86\u6539\u5584\u5f9e\u5f31\u5230\u5f37\u7684\u6982\u62ec\u80fd\u529b\u3002\u5728\u6211\u5011\u7684\u65b9\u6cd5\u4e2d\uff0c\u6211\u5011\u67e5\u8a62\u5f31\u76e3\u7763\u8005\u4ee5\u53d6\u5f97\u591a\u500b\u7b54\u6848\uff0c\u4f30\u8a08\u7b54\u6848\u7684\u53ef\u9760\u6027\uff0c\u4e26\u900f\u904e\u7be9\u9078\u4e0d\u78ba\u5b9a\u7684\u8cc7\u6599\u6216\u91cd\u65b0\u52a0\u6b0a\u53ef\u9760\u7684\u8cc7\u6599\u4f86\u589e\u5f37\u5c0d\u9f4a\u904e\u7a0b\u3002\u5728\u56db\u500b\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u6709\u6548\u5730\u8b58\u5225\u5f31\u6a19\u7c64\u7684\u54c1\u8cea\uff0c\u4e26\u986f\u8457\u589e\u5f37\u5f9e\u5f31\u5230\u5f37\u7684\u6982\u62ec\u80fd\u529b\u3002\u6211\u5011\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u91dd\u5c0d\u932f\u8aa4\u7a69\u5065\u6a21\u578b\u5c0d\u9f4a\u7684\u6709\u6548\u6280\u8853\uff0c\u6e1b\u5c11\u4f86\u81ea\u6709\u96dc\u8a0a\u76e3\u7763\u7684\u932f\u8aa4\u50b3\u64ad\uff0c\u4e26\u589e\u5f37 LLM \u7684\u6e96\u78ba\u6027\u548c\u53ef\u9760\u6027\u3002\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc http://github.com/Irenehere/ReliableAlignment\u3002", "author": "Yue Guo et.al.", "authors": "Yue Guo, Yi Yang", "id": "2406.19032v1", "paper_url": "http://arxiv.org/abs/2406.19032v1", "repo": "https://github.com/irenehere/reliablealignment"}}