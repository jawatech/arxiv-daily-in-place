{"2412.15156": {"publish_time": "2024-12-19", "title": "Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM", "paper_summary": "Text-to-video models have made remarkable advancements through optimization\non high-quality text-video pairs, where the textual prompts play a pivotal role\nin determining quality of output videos. However, achieving the desired output\noften entails multiple revisions and iterative inference to refine\nuser-provided prompts. Current automatic methods for refining prompts encounter\nchallenges such as Modality-Inconsistency, Cost-Discrepancy, and Model-Unaware\nwhen applied to text-to-video diffusion models. To address these problem, we\nintroduce an LLM-based prompt adaptation framework, termed as Prompt-A-Video,\nwhich excels in crafting Video-Centric, Labor-Free and Preference-Aligned\nprompts tailored to specific video diffusion model. Our approach involves a\nmeticulously crafted two-stage optimization and alignment system. Initially, we\nconduct a reward-guided prompt evolution pipeline to automatically create\noptimal prompts pool and leverage them for supervised fine-tuning (SFT) of the\nLLM. Then multi-dimensional rewards are employed to generate pairwise data for\nthe SFT model, followed by the direct preference optimization (DPO) algorithm\nto further facilitate preference alignment. Through extensive experimentation\nand comparative analyses, we validate the effectiveness of Prompt-A-Video\nacross diverse generation models, highlighting its potential to push the\nboundaries of video generation.", "paper_summary_zh": "\u6587\u672c\u5230\u5f71\u7247\u6a21\u578b\u900f\u904e\u6700\u4f73\u5316\u9ad8\u54c1\u8cea\u6587\u672c\u5f71\u7247\u914d\u5c0d\uff0c\u53d6\u5f97\u4e86\u986f\u8457\u7684\u9032\u6b65\uff0c\u5176\u4e2d\u6587\u5b57\u63d0\u793a\u5728\u6c7a\u5b9a\u5f71\u7247\u8f38\u51fa\u54c1\u8cea\u65b9\u9762\u626e\u6f14\u4e86\u95dc\u9375\u89d2\u8272\u3002\u7136\u800c\uff0c\u8981\u9054\u5230\u7406\u60f3\u7684\u8f38\u51fa\uff0c\u901a\u5e38\u9700\u8981\u591a\u6b21\u4fee\u6539\u548c\u53cd\u8986\u63a8\u8ad6\u4f86\u6539\u5584\u4f7f\u7528\u8005\u63d0\u4f9b\u7684\u63d0\u793a\u3002\u76ee\u524d\u7528\u65bc\u6539\u5584\u63d0\u793a\u7684\u81ea\u52d5\u5316\u65b9\u6cd5\uff0c\u5728\u61c9\u7528\u65bc\u6587\u672c\u5230\u5f71\u7247\u64f4\u6563\u6a21\u578b\u6642\uff0c\u6703\u9047\u5230\u6a21\u614b\u4e0d\u4e00\u81f4\u3001\u6210\u672c\u5dee\u7570\u548c\u6a21\u578b\u4e0d\u77e5\u60c5\u7b49\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u57fa\u65bc LLM \u7684\u63d0\u793a\u9069\u61c9\u67b6\u69cb\uff0c\u7a31\u70ba Prompt-A-Video\uff0c\u5b83\u64c5\u9577\u88fd\u4f5c\u91dd\u5c0d\u7279\u5b9a\u5f71\u7247\u64f4\u6563\u6a21\u578b\u91cf\u8eab\u6253\u9020\u7684\u4ee5\u5f71\u7247\u70ba\u4e2d\u5fc3\u3001\u514d\u4eba\u5de5\u548c\u504f\u597d\u5c0d\u9f4a\u7684\u63d0\u793a\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u542b\u7cbe\u5fc3\u8a2d\u8a08\u7684\u5169\u968e\u6bb5\u6700\u4f73\u5316\u548c\u5c0d\u9f4a\u7cfb\u7d71\u3002\u6700\u521d\uff0c\u6211\u5011\u57f7\u884c\u4e00\u500b\u734e\u52f5\u5f15\u5c0e\u63d0\u793a\u6f14\u5316\u7ba1\u9053\uff0c\u4ee5\u81ea\u52d5\u5efa\u7acb\u6700\u4f73\u63d0\u793a\u6c60\uff0c\u4e26\u5229\u7528\u5b83\u5011\u5c0d LLM \u9032\u884c\u76e3\u7763\u5fae\u8abf (SFT)\u3002\u7136\u5f8c\u63a1\u7528\u591a\u7dad\u5ea6\u734e\u52f5\u70ba SFT \u6a21\u578b\u7522\u751f\u6210\u5c0d\u8cc7\u6599\uff0c\u63a5\u8457\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u6f14\u7b97\u6cd5\u9032\u4e00\u6b65\u4fc3\u9032\u504f\u597d\u5c0d\u9f4a\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\u548c\u6bd4\u8f03\u5206\u6790\uff0c\u6211\u5011\u9a57\u8b49\u4e86 Prompt-A-Video \u5728\u5404\u7a2e\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7a81\u986f\u4e86\u5b83\u5728\u63a8\u52d5\u5f71\u7247\u751f\u6210\u908a\u754c\u7684\u6f5b\u529b\u3002", "author": "Yatai Ji et.al.", "authors": "Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang, Shoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen, Wenqi Shao, Xuefeng Xiao, Weilin Huang, Ping Luo", "id": "2412.15156v1", "paper_url": "http://arxiv.org/abs/2412.15156v1", "repo": "https://github.com/jiyt17/prompt-a-video"}}