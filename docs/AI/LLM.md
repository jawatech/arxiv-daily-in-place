
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-11**|**Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?**|Xingyu Fu et.al.|[2406.07546v1](http://arxiv.org/abs/2406.07546v1)|null|
|**2024-06-11**|**Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena**|Aidar Myrzakhan et.al.|[2406.07545v1](http://arxiv.org/abs/2406.07545v1)|[link](https://github.com/vila-lab/open-llm-leaderboard)|
|**2024-06-11**|**Situational Awareness Matters in 3D Vision Language Reasoning**|Yunze Man et.al.|[2406.07544v1](http://arxiv.org/abs/2406.07544v1)|null|
|**2024-06-11**|**Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**|David Ortiz-Perez et.al.|[2406.07542v1](http://arxiv.org/abs/2406.07542v1)|[link](https://github.com/davidorp/taukadial)|
|**2024-06-11**|**Simple and Effective Masked Diffusion Language Models**|Subham Sekhar Sahoo et.al.|[2406.07524v1](http://arxiv.org/abs/2406.07524v1)|[link](https://github.com/kuleshov-group/mdlm)|
|**2024-06-11**|**Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling**|Liliang Ren et.al.|[2406.07522v1](http://arxiv.org/abs/2406.07522v1)|null|
|**2024-06-11**|**Neural Gaffer: Relighting Any Object via Diffusion**|Haian Jin et.al.|[2406.07520v1](http://arxiv.org/abs/2406.07520v1)|null|
|**2024-06-11**|**Beyond Model Collapse: Scaling Up with Synthesized Data Requires Reinforcement**|Yunzhen Feng et.al.|[2406.07515v1](http://arxiv.org/abs/2406.07515v1)|null|
|**2024-06-11**|**Understanding Visual Concepts Across Models**|Brandon Trabucco et.al.|[2406.07506v1](http://arxiv.org/abs/2406.07506v1)|[link](https://github.com/visual-words/visual-words)|
|**2024-06-11**|**THaLLE: Text Hyperlocally Augmented Large Language Extension -- Technical Report**|KBTG Labs et.al.|[2406.07505v1](http://arxiv.org/abs/2406.07505v1)|null|
|**2024-06-11**|**Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling Queer Voices**|Atli Sigurgeirsson et.al.|[2406.07504v1](http://arxiv.org/abs/2406.07504v1)|null|
|**2024-06-11**|**Image Textualization: An Automatic Framework for Creating Accurate and Detailed Image Descriptions**|Renjie Pi et.al.|[2406.07502v1](http://arxiv.org/abs/2406.07502v1)|[link](https://github.com/sterzhang/image-textualization)|
|**2024-06-11**|**TextGrad: Automatic "Differentiation" via Text**|Mert Yuksekgonul et.al.|[2406.07496v1](http://arxiv.org/abs/2406.07496v1)|[link](https://github.com/zou-group/textgrad)|
|**2024-06-11**|**CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**|Frederic Kirstein et.al.|[2406.07494v1](http://arxiv.org/abs/2406.07494v1)|null|
|**2024-06-11**|**Paraphrasing in Affirmative Terms Improves Negation Understanding**|MohammadHossein Rezaei et.al.|[2406.07492v1](http://arxiv.org/abs/2406.07492v1)|null|
|**2024-06-11**|**Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing**|Mao Li et.al.|[2406.07483v1](http://arxiv.org/abs/2406.07483v1)|null|
|**2024-06-11**|**VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs**|Zesen Cheng et.al.|[2406.07476v1](http://arxiv.org/abs/2406.07476v1)|[link](https://github.com/damo-nlp-sg/videollama2)|
|**2024-06-11**|**On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations**|Shiao Meng et.al.|[2406.07444v1](http://arxiv.org/abs/2406.07444v1)|null|
|**2024-06-11**|**Textual Similarity as a Key Metric in Machine Translation Quality Estimation**|Kun Sun et.al.|[2406.07440v1](http://arxiv.org/abs/2406.07440v1)|null|
|**2024-06-11**|**Learning Domain-Invariant Features for Out-of-Context News Detection**|Yimeng Gu et.al.|[2406.07430v1](http://arxiv.org/abs/2406.07430v1)|null|
|**2024-06-11**|**MINERS: Multilingual Language Models as Semantic Retrievers**|Genta Indra Winata et.al.|[2406.07424v1](http://arxiv.org/abs/2406.07424v1)|null|
|**2024-06-11**|**Enhanced Gene Selection in Single-Cell Genomics: Pre-Filtering Synergy and Reinforced Optimization**|Weiliang Zhang et.al.|[2406.07418v1](http://arxiv.org/abs/2406.07418v1)|null|
|**2024-06-11**|**VersiCode: Towards Version-controllable Code Generation**|Tongtong Wu et.al.|[2406.07411v1](http://arxiv.org/abs/2406.07411v1)|null|
|**2024-06-11**|**Visual Representation Learning with Stochastic Frame Prediction**|Huiwon Jang et.al.|[2406.07398v1](http://arxiv.org/abs/2406.07398v1)|null|
|**2024-06-11**|**Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B**|Di Zhang et.al.|[2406.07394v1](http://arxiv.org/abs/2406.07394v1)|null|
|**2024-06-11**|**Limited Out-of-Context Knowledge Reasoning in Large Language Models**|Peng Hu et.al.|[2406.07393v1](http://arxiv.org/abs/2406.07393v1)|null|
|**2024-06-11**|**World Models with Hints of Large Language Models for Goal Achieving**|Zeyuan Liu et.al.|[2406.07381v1](http://arxiv.org/abs/2406.07381v1)|null|
|**2024-06-11**|**Large Language Models for Constrained-Based Causal Discovery**|Kai-Hendrik Cohrs et.al.|[2406.07378v1](http://arxiv.org/abs/2406.07378v1)|null|
|**2024-06-11**|**When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models**|Haoran You et.al.|[2406.07368v1](http://arxiv.org/abs/2406.07368v1)|[link](https://github.com/gatech-eic/linearized-llm)|
|**2024-06-11**|**BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction**|Yinhao Bai et.al.|[2406.07365v1](http://arxiv.org/abs/2406.07365v1)|[link](https://github.com/byinhao/bvsp)|
|**2024-06-11**|**AI Sandbagging: Language Models can Strategically Underperform on Evaluations**|Teun van der Weij et.al.|[2406.07358v1](http://arxiv.org/abs/2406.07358v1)|[link](https://github.com/teunvdweij/sandbagging)|
|**2024-06-11**|**Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities**|Delfina Sol Martinez Pandiani et.al.|[2406.07353v1](http://arxiv.org/abs/2406.07353v1)|null|
|**2024-06-11**|**DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering**|Zijian Hei et.al.|[2406.07348v1](http://arxiv.org/abs/2406.07348v1)|null|
|**2024-06-11**|**CTC-based Non-autoregressive Textless Speech-to-Speech Translation**|Qingkai Fang et.al.|[2406.07330v1](http://arxiv.org/abs/2406.07330v1)|[link](https://github.com/ictnlp/ctc-s2ut)|
|**2024-06-11**|**3D-Properties: Identifying Challenges in DPO and Charting a Path Forward**|Yuzi Yan et.al.|[2406.07327v1](http://arxiv.org/abs/2406.07327v1)|null|
|**2024-06-11**|**Should XAI Nudge Human Decisions with Explanation Biasing?**|Yosuke Fukuchi et.al.|[2406.07323v1](http://arxiv.org/abs/2406.07323v1)|null|
|**2024-06-11**|**MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting**|Zhiqi Ai et.al.|[2406.07310v1](http://arxiv.org/abs/2406.07310v1)|null|
|**2024-06-11**|**BertaQA: How Much Do Language Models Know About Local Culture?**|Julen Etxaniz et.al.|[2406.07302v1](http://arxiv.org/abs/2406.07302v1)|[link](https://github.com/juletx/bertaqa)|
|**2024-06-11**|**Instruct Large Language Models to Drive like Humans**|Ruijun Zhang et.al.|[2406.07296v1](http://arxiv.org/abs/2406.07296v1)|[link](https://github.com/bonbon-rj/instructdriver)|
|**2024-06-11**|**Joint Learning of Context and Feedback Embeddings in Spoken Dialogue**|Livia Qian et.al.|[2406.07291v1](http://arxiv.org/abs/2406.07291v1)|null|
|**2024-06-11**|**Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?**|Qingkai Fang et.al.|[2406.07289v1](http://arxiv.org/abs/2406.07289v1)|null|
|**2024-06-11**|**Fine-tuning with HED-IT: The impact of human post-editing for dialogical language models**|Daniela Occhipinti et.al.|[2406.07288v1](http://arxiv.org/abs/2406.07288v1)|null|
|**2024-06-11**|**Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5 Few-Shot Learning**|AmirMohammad Azadi et.al.|[2406.07287v1](http://arxiv.org/abs/2406.07287v1)|null|
|**2024-06-11**|**Speaking Your Language: Spatial Relationships in Interpretable Emergent Communication**|Olaf Lipinski et.al.|[2406.07277v1](http://arxiv.org/abs/2406.07277v1)|null|
|**2024-06-11**|**DCA-Bench: A Benchmark for Dataset Curation Agents**|Benhao Huang et.al.|[2406.07275v1](http://arxiv.org/abs/2406.07275v1)|null|
|**2024-06-11**|**Advancing Grounded Multimodal Named Entity Recognition via LLM-Based Reformulation and Box-Based Segmentation**|Jinyuan Li et.al.|[2406.07268v1](http://arxiv.org/abs/2406.07268v1)|null|
|**2024-06-11**|**Efficient 3D Molecular Generation with Flow Matching and Scale Optimal Transport**|Ross Irwin et.al.|[2406.07266v1](http://arxiv.org/abs/2406.07266v1)|null|
|**2024-06-11**|**Scientific Computing with Large Language Models**|Christopher Culver et.al.|[2406.07259v1](http://arxiv.org/abs/2406.07259v1)|null|
|**2024-06-11**|**Scholarly Question Answering using Large Language Models in the NFDI4DataScience Gateway**|Hamed Babaei Giglou et.al.|[2406.07257v1](http://arxiv.org/abs/2406.07257v1)|null|
|**2024-06-11**|**AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection**|Rong Gong et.al.|[2406.07256v1](http://arxiv.org/abs/2406.07256v1)|null|
|**2024-06-11**|**Is One GPU Enough? Pushing Image Generation at Higher-Resolutions with Foundation Models**|Athanasios Tragakis et.al.|[2406.07251v1](http://arxiv.org/abs/2406.07251v1)|null|
|**2024-06-11**|**Are Protein Language Models Compute Optimal?**|Yaiza Serrano et.al.|[2406.07249v1](http://arxiv.org/abs/2406.07249v1)|null|
|**2024-06-11**|**MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs**|Vera Neplenbroek et.al.|[2406.07243v1](http://arxiv.org/abs/2406.07243v1)|null|
|**2024-06-11**|**DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms**|Andong Chen et.al.|[2406.07232v1](http://arxiv.org/abs/2406.07232v1)|[link](https://github.com/loulianzhang/dual-reflect)|
|**2024-06-11**|**Decipherment-Aware Multilingual Learning in Jointly Trained Language Models**|Grandee Lee et.al.|[2406.07231v1](http://arxiv.org/abs/2406.07231v1)|null|
|**2024-06-11**|**Improving Commonsense Bias Classification by Mitigating the Influence of Demographic Terms**|JinKyu Lee et.al.|[2406.07229v1](http://arxiv.org/abs/2406.07229v1)|null|
|**2024-06-11**|**Needle In A Multimodal Haystack**|Weiyun Wang et.al.|[2406.07230v1](http://arxiv.org/abs/2406.07230v1)|null|
|**2024-06-11**|**Haptic Repurposing with GenAI**|Haoyu Wang et.al.|[2406.07228v1](http://arxiv.org/abs/2406.07228v1)|null|
|**2024-06-11**|**Improving Autoformalization using Type Checking**|Auguste Poiroux et.al.|[2406.07222v1](http://arxiv.org/abs/2406.07222v1)|null|
|**2024-06-11**|**A Synthetic Dataset for Personal Attribute Inference**|Hanna Yukhymenko et.al.|[2406.07217v1](http://arxiv.org/abs/2406.07217v1)|null|
|**2024-06-11**|**Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models**|Joshua Strong et.al.|[2406.07212v1](http://arxiv.org/abs/2406.07212v1)|null|
|**2024-06-11**|**Merging Improves Self-Critique Against Jailbreak Attacks**|Victor Gallego et.al.|[2406.07188v1](http://arxiv.org/abs/2406.07188v1)|[link](https://github.com/vicgalle/merging-self-critique-jailbreaks)|
|**2024-06-11**|**Teaching Language Models to Self-Improve by Learning from Language Feedback**|Chi Hu et.al.|[2406.07168v1](http://arxiv.org/abs/2406.07168v1)|null|
|**2024-06-11**|**EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark**|Ziyang Ma et.al.|[2406.07162v1](http://arxiv.org/abs/2406.07162v1)|[link](https://github.com/emo-box/emobox)|
|**2024-06-11**|**Scaling Large-Language-Model-based Multi-Agent Collaboration**|Chen Qian et.al.|[2406.07155v1](http://arxiv.org/abs/2406.07155v1)|[link](https://github.com/openbmb/chatdev)|
|**2024-06-11**|**EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels**|Shuqi Zhu et.al.|[2406.07151v1](http://arxiv.org/abs/2406.07151v1)|[link](https://github.com/promise-z5q2sq/eeg-imagenet-dataset)|
|**2024-06-11**|**Wearable Device-Based Physiological Signal Monitoring: An Assessment Study of Cognitive Load Across Tasks**|Ling He et.al.|[2406.07147v1](http://arxiv.org/abs/2406.07147v1)|null|
|**2024-06-11**|**Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**|Che Liu et.al.|[2406.07146v1](http://arxiv.org/abs/2406.07146v1)|null|
|**2024-06-11**|**Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models with Consistent "Middle" Enhancement**|Tong Wu et.al.|[2406.07138v1](http://arxiv.org/abs/2406.07138v1)|null|
|**2024-06-11**|**Translating speech with just images**|Dan Oneata et.al.|[2406.07133v1](http://arxiv.org/abs/2406.07133v1)|null|
|**2024-06-11**|**Mining Frequent Structures in Conceptual Models**|Mattia Fumagalli et.al.|[2406.07129v1](http://arxiv.org/abs/2406.07129v1)|[link](https://github.com/unibz-core/cm-mining_experimentdata)|
|**2024-06-11**|**Logical Distillation of Graph Neural Networks**|Alexander Pluska et.al.|[2406.07126v1](http://arxiv.org/abs/2406.07126v1)|[link](https://github.com/lexpk/logicaldistillationofgnns)|
|**2024-06-11**|**CARACAS: vehiCular ArchitectuRe for detAiled Can Attacks Simulation**|Sadek Misto Kirdi et.al.|[2406.07125v1](http://arxiv.org/abs/2406.07125v1)|null|
|**2024-06-11**|**CHARME: A chain-based reinforcement learning approach for the minor embedding problem**|Hoang M. Ngo et.al.|[2406.07124v1](http://arxiv.org/abs/2406.07124v1)|null|
|**2024-06-11**|**T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text**|Aoxiong Yin et.al.|[2406.07119v1](http://arxiv.org/abs/2406.07119v1)|null|
|**2024-06-11**|**Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees**|Sijia Chen et.al.|[2406.07115v1](http://arxiv.org/abs/2406.07115v1)|null|
|**2024-06-11**|**Beyond Bare Queries: Open-Vocabulary Object Retrieval with 3D Scene Graph**|Sergey Linok et.al.|[2406.07113v1](http://arxiv.org/abs/2406.07113v1)|null|
|**2024-06-11**|**Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter**|Andrei Andrusenko et.al.|[2406.07096v1](http://arxiv.org/abs/2406.07096v1)|null|
|**2024-06-11**|**Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning**|Menglong Cui et.al.|[2406.07081v1](http://arxiv.org/abs/2406.07081v1)|null|
|**2024-06-11**|**DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs**|Haishuo Fang et.al.|[2406.07080v1](http://arxiv.org/abs/2406.07080v1)|null|
|**2024-06-11**|**Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology**|Huahui Yi et.al.|[2406.07078v1](http://arxiv.org/abs/2406.07078v1)|[link](https://github.com/huahuiyi/mmdp)|
|**2024-06-11**|**HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation**|Wen Luo et.al.|[2406.07070v1](http://arxiv.org/abs/2406.07070v1)|null|
|**2024-06-11**|**TIM: Temporal Interaction Model in Notification System**|Huxiao Ji et.al.|[2406.07067v1](http://arxiv.org/abs/2406.07067v1)|null|
|**2024-06-11**|**Reconstructing the Tropical Pacific Upper Ocean using Online Data Assimilation with a Deep Learning model**|Zilu Meng et.al.|[2406.07063v1](http://arxiv.org/abs/2406.07063v1)|[link](https://github.com/zilum/dataassimlationwithdl)|
|**2024-06-11**|**Reading Miscue Detection in Primary School through Automatic Speech Recognition**|Lingyun Gao et.al.|[2406.07060v1](http://arxiv.org/abs/2406.07060v1)|null|
|**2024-06-11**|**Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study**|Yichi Zhang et.al.|[2406.07057v1](http://arxiv.org/abs/2406.07057v1)|null|
|**2024-06-11**|**Effectively Compress KV Heads for LLM**|Hao Yu et.al.|[2406.07056v1](http://arxiv.org/abs/2406.07056v1)|null|
|**2024-06-11**|**CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation**|Renhao Li et.al.|[2406.07054v1](http://arxiv.org/abs/2406.07054v1)|[link](https://github.com/lirenhao1997/coevol)|
|**2024-06-11**|**Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model**|Hongbin Zhang et.al.|[2406.07036v1](http://arxiv.org/abs/2406.07036v1)|[link](https://github.com/AzureStarz/paying_attention_to_the_source)|
|**2024-06-11**|**Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning**|Jeonghoon Kim et.al.|[2406.07034v1](http://arxiv.org/abs/2406.07034v1)|[link](https://github.com/kjh9503/caqr)|
|**2024-06-11**|**Entropy-Reinforced Planning with Large Language Models for Drug Discovery**|Xuefeng Liu et.al.|[2406.07025v1](http://arxiv.org/abs/2406.07025v1)|null|
|**2024-06-11**|**MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations**|Zixiao Wang et.al.|[2406.07017v1](http://arxiv.org/abs/2406.07017v1)|[link](https://github.com/shiningsord/moreaupruner)|
|**2024-06-11**|**Delving into ChatGPT usage in academic writing through excess vocabulary**|Dmitry Kobak et.al.|[2406.07016v1](http://arxiv.org/abs/2406.07016v1)|null|
|**2024-06-11**|**Bridging Language Gaps in Audio-Text Retrieval**|Zhiyong Yan et.al.|[2406.07012v1](http://arxiv.org/abs/2406.07012v1)|null|
|**2024-06-11**|**Eye-for-an-eye: Appearance Transfer with Semantic Correspondence in Diffusion Models**|Sooyeon Go et.al.|[2406.07008v1](http://arxiv.org/abs/2406.07008v1)|null|
|**2024-06-11**|**Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference**|Jihwan Bang et.al.|[2406.07007v1](http://arxiv.org/abs/2406.07007v1)|null|
|**2024-06-11**|**Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models**|Zhenyi Lu et.al.|[2406.07001v1](http://arxiv.org/abs/2406.07001v1)|[link](https://github.com/chuge0335/pc-cot)|
|**2024-06-11**|**Discrete Dictionary-based Decomposition Layer for Structured Representation Learning**|Taewon Park et.al.|[2406.06976v1](http://arxiv.org/abs/2406.06976v1)|null|
|**2024-06-11**|**Beyond the Norms: Detecting Prediction Errors in Regression Models**|Andres Altieri et.al.|[2406.06968v1](http://arxiv.org/abs/2406.06968v1)|null|
|**2024-06-11**|**Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples**|Kailas Dayanandan et.al.|[2406.06967v1](http://arxiv.org/abs/2406.06967v1)|[link](https://github.com/kailasdayanandan/dual_thinking)|

#### Abstracts
##### **Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?**
2406.07546v1 by Xingyu Fu, Muyu He, Yujie Lu, William Yang Wang, Dan Roth

We present a novel task and benchmark for evaluating the ability of
text-to-image(T2I) generation models to produce images that fit commonsense in
real life, which we call Commonsense-T2I. Given two adversarial text prompts
containing an identical set of action words with minor differences, such as "a
lightbulb without electricity" v.s. "a lightbulb with electricity", we evaluate
whether T2I models can conduct visual-commonsense reasoning, e.g. produce
images that fit "the lightbulb is unlit" vs. "the lightbulb is lit"
correspondingly. Commonsense-T2I presents an adversarial challenge, providing
pairwise text prompts along with expected outputs. The dataset is carefully
hand-curated by experts and annotated with fine-grained labels, such as
commonsense type and likelihood of the expected outputs, to assist analyzing
model behavior. We benchmark a variety of state-of-the-art (sota) T2I models
and surprisingly find that, there is still a large gap between image synthesis
and real life photos--even the DALL-E 3 model could only achieve 48.92% on
Commonsense-T2I, and the stable diffusion XL model only achieves 24.92%
accuracy. Our experiments show that GPT-enriched prompts cannot solve this
challenge, and we include a detailed analysis about possible reasons for such
deficiency. We aim for Commonsense-T2I to serve as a high-quality evaluation
benchmark for T2I commonsense checking, fostering advancements in real life
image generation.

摘要：<paragraph>我們提出了一項新任務和基準，用於評估文字轉圖像 (T2I) 生成模型產生符合現實生活常識圖像的能力，我們稱之為常識 T2I。給定兩個對抗性的文字提示，其中包含一組相同的動作詞，但有細微的差異，例如「沒有電的燈泡」與「有電的燈泡」，我們評估 T2I 模型是否能進行視覺常識推理，例如產生符合「燈泡未點亮」與「燈泡已點亮」的圖像。常識 T2I 呈現了一個對抗性的挑戰，提供了成對的文字提示以及預期的輸出。該數據集由專家仔細手工策劃，並註解了細粒度的標籤，例如常識類型和預期輸出的可能性，以協助分析模型行為。我們對各種最先進 (sota) T2I 模型進行基準測試，令人驚訝地發現，圖像合成和現實生活照片之間仍然存在很大差距——即使是 DALL-E 3 模型在常識 T2I 上也僅能達到 48.92%，而穩定擴散 XL 模型僅達到 24.92% 的準確率。我們的實驗表明，GPT 豐富的提示無法解決這個挑戰，我們對這種缺陷的可能原因進行了詳細分析。我們的目標是讓常識 T2I 成為 T2I 常識檢查的高品質評估基準，促進現實生活圖像生成的進步。</paragraph>

##### **Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena**
2406.07545v1 by Aidar Myrzakhan, Sondos Mahmoud Bsharat, Zhiqiang Shen

Multiple-choice questions (MCQ) are frequently used to assess large language
models (LLMs). Typically, an LLM is given a question and selects the answer
deemed most probable after adjustments for factors like length. Unfortunately,
LLMs may inherently favor certain answer choice IDs, such as A/B/C/D, due to
inherent biases of priori unbalanced probabilities, influencing the prediction
of answers based on these IDs. Previous research has introduced methods to
reduce this ''selection bias'' by simply permutating options on a few test
samples and applying to new ones. Another problem of MCQ is the lottery ticket
choice by ''random guessing''. The LLM does not learn particular knowledge, but
the option is guessed correctly. This situation is especially serious for those
small-scale LLMs. To address them, a more thorough approach involves shifting
from MCQ to open-style questions, which can fundamentally eliminate selection
bias and random guessing issues. However, transitioning causes its own set of
challenges in (1) identifying suitable open-style questions and (2) validating
the correctness of LLM open-style responses against human-annotated
ground-truths. This work aims to tackle these significant difficulties, and
establish a new LLM evaluation benchmark through entirely open-style questions.
Consequently, we introduce the Open-LLM-Leaderboard to track various LLMs'
performance and reflect true capability of them, such as GPT-4o/4/3.5, Claude
3, Gemini, etc. Our code and dataset are available at
https://github.com/VILA-Lab/Open-LLM-Leaderboard.

摘要：多選題 (MCQ) 常用於評量大型語言模型 (LLM)。通常，LLM 會收到一個問題，並在針對長度等因素進行調整後，選擇最有可能的答案。不幸的是，由於先驗不平衡機率的內在偏誤，LLM 可能天生偏好某些答案選項 ID，例如 A/B/C/D，這會影響根據這些 ID 預測答案。先前的研究已引入方法，透過僅在幾個測試樣本上排列選項並套用到新的樣本，來減少這種「選擇偏誤」。MCQ 的另一個問題是「隨機猜測」的樂透選項。LLM 沒有學習特定知識，但選項猜對了。對於那些小規模的 LLM 來說，這種情況尤其嚴重。為了解決這些問題，更徹底的方法涉及從 MCQ 轉換為開放式問題，這可以從根本上消除選擇偏誤和隨機猜測的問題。然而，轉換會在 (1) 找出合適的開放式問題和 (2) 驗證 LLM 開放式回應的正確性是否符合人工標記的真實情況方面，造成其自身的挑戰。這項工作旨在解決這些重大的困難，並透過完全開放式問題建立新的 LLM 評量基準。因此，我們引入了 Open-LLM-Leaderboard 來追蹤各種 LLM 的效能，並反映它們的真實能力，例如 GPT-4o/4/3.5、Claude 3、Gemini 等。我們的程式碼和資料集可在 https://github.com/VILA-Lab/Open-LLM-Leaderboard 取得。

##### **Situational Awareness Matters in 3D Vision Language Reasoning**
2406.07544v1 by Yunze Man, Liang-Yan Gui, Yu-Xiong Wang

Being able to carry out complicated vision language reasoning tasks in 3D
space represents a significant milestone in developing household robots and
human-centered embodied AI. In this work, we demonstrate that a critical and
distinct challenge in 3D vision language reasoning is situational awareness,
which incorporates two key components: (1) The autonomous agent grounds its
self-location based on a language prompt. (2) The agent answers open-ended
questions from the perspective of its calculated position. To address this
challenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D
vision language reasoning. We tokenize the 3D scene into sparse voxel
representation and propose a language-grounded situation estimator, followed by
a situated question answering module. Experiments on the SQA3D and ScanQA
datasets show that SIG3D outperforms state-of-the-art models in situation
estimation and question answering by a large margin (e.g., an enhancement of
over 30% on situation estimation accuracy). Subsequent analysis corroborates
our architectural design choices, explores the distinct functions of visual and
textual tokens, and highlights the importance of situational awareness in the
domain of 3D question answering.

摘要：能夠在 3D 空間中執行複雜的視覺語言推理任務，代表了家用機器人和以人為中心的具體 AI 發展中的重要里程碑。在這項工作中，我們證明了 3D 視覺語言推理中一項關鍵且獨特的挑戰在於情境感知，它包含兩個關鍵組成部分：(1) 自主代理根據語言提示確定其自我位置。(2) 代理從其計算出的位置的角度回答開放式問題。為了應對這一挑戰，我們引入了 SIG3D，這是一個端到端的 3D 視覺語言推理情境基礎模型。我們將 3D 場景標記化為稀疏體素表示，並提出一個語言基礎的情境估計器，隨後是一個情境問題回答模組。對 SQA3D 和 ScanQA 資料集的實驗表明，SIG3D 在情境估計和問題回答方面大幅優於最先進的模型（例如，情境估計準確度提高了 30% 以上）。後續分析證實了我們的架構設計選擇，探討了視覺和文字標記的不同功能，並強調了情境感知在 3D 問題回答領域中的重要性。

##### **Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**
2406.07542v1 by David Ortiz-Perez, Jose Garcia-Rodriguez, David Tomás

Cognitive decline is a natural process that occurs as individuals age. Early
diagnosis of anomalous decline is crucial for initiating professional treatment
that can enhance the quality of life of those affected. To address this issue,
we propose a multimodal model capable of predicting Mild Cognitive Impairment
and cognitive scores. The TAUKADIAL dataset is used to conduct the evaluation,
which comprises audio recordings of clinical interviews. The proposed model
demonstrates the ability to transcribe and differentiate between languages used
in the interviews. Subsequently, the model extracts audio and text features,
combining them into a multimodal architecture to achieve robust and generalized
results. Our approach involves in-depth research to implement various features
obtained from the proposed modalities.

摘要：認知能力下降是個人隨著年齡增長而發生的自然過程。及早診斷異常下降對於啟動專業治療至關重要，可提升受影響者的生活品質。為了解決此問題，我們提出一個多模態模型，能夠預測輕度認知障礙和認知評分。TAUKADIAL 資料集用於進行評估，其中包含臨床訪談的音訊錄製。所提出的模型展示了轉錄和區分訪談中所用語言的能力。隨後，模型會擷取音訊和文字特徵，將它們組合成多模態架構，以達成穩健且廣泛的結果。我們的做法涉及深入研究，以實作從所提出的模態中取得的各種特徵。

##### **Simple and Effective Masked Diffusion Language Models**
2406.07524v1 by Subham Sekhar Sahoo, Marianne Arriola, Yair Schiff, Aaron Gokaslan, Edgar Marroquin, Justin T Chiu, Alexander Rush, Volodymyr Kuleshov

While diffusion models excel at generating high-quality images, prior work
reports a significant performance gap between diffusion and autoregressive (AR)
methods in language modeling. In this work, we show that simple masked discrete
diffusion is more performant than previously thought. We apply an effective
training recipe that improves the performance of masked diffusion models and
derive a simplified, Rao-Blackwellized objective that results in additional
improvements. Our objective has a simple form -- it is a mixture of classical
masked language modeling losses -- and can be used to train encoder-only
language models that admit efficient samplers, including ones that can generate
arbitrary lengths of text semi-autoregressively like a traditional language
model. On language modeling benchmarks, a range of masked diffusion models
trained with modern engineering practices achieves a new state-of-the-art among
diffusion models, and approaches AR perplexity. We release our code at:
https://github.com/kuleshov-group/mdlm

摘要：儘管擴散模型在生成高品質影像方面表現出色，先前研究指出擴散與自迴歸 (AR) 方法在語言建模方面有顯著的效能差距。在這項研究中，我們證明簡單的遮罩離散擴散比先前所想的更有效能。我們應用有效的訓練配方，改善遮罩擴散模型的效能，並推導出簡化的 Rao-Blackwellized 目標，進一步提升效能。我們的目標形式簡單，是經典遮罩語言建模損失的混合，可用於訓練僅編碼器語言模型，並允許使用有效率的採樣器，包括可以像傳統語言模型一樣半自迴歸生成任意長度的文字。在語言建模基準測試中，使用現代工程實務訓練的各種遮罩擴散模型在擴散模型中達到新的最先進水準，並接近 AR 的困惑度。我們在以下位置釋出我們的程式碼：
https://github.com/kuleshov-group/mdlm

##### **Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling**
2406.07522v1 by Liliang Ren, Yang Liu, Yadong Lu, Yelong Shen, Chen Liang, Weizhu Chen

Efficiently modeling sequences with infinite context length has been a
long-standing problem. Past works suffer from either the quadratic computation
complexity or the limited extrapolation ability on length generalization. In
this work, we present Samba, a simple hybrid architecture that layer-wise
combines Mamba, a selective State Space Model (SSM), with Sliding Window
Attention (SWA). Samba selectively compresses a given sequence into recurrent
hidden states while still maintaining the ability to precisely recall memories
with the attention mechanism. We scale Samba up to 3.8B parameters with 3.2T
training tokens and show that Samba substantially outperforms the
state-of-the-art models based on pure attention or SSMs on a wide range of
benchmarks. When trained on 4K length sequences, Samba can be efficiently
extrapolated to 256K context length with perfect memory recall and show
improved token predictions up to 1M context length. As a linear-time sequence
model, Samba enjoys a 3.73x higher throughput compared to Transformers with
grouped-query attention when processing user prompts of 128K length, and 3.64x
speedup when generating 64K tokens with unlimited streaming. A sample
implementation of Samba is publicly available in
https://github.com/microsoft/Samba.

摘要：有效地對具有無限上下文長度的序列進行建模一直是一個長期的問題。過去的工作要么計算複雜度為二次方，要么在長度泛化上外推能力有限。在這項工作中，我們提出了 Samba，這是一種簡單的混合架構，它逐層結合了選擇性狀態空間模型 (SSM) Mamba 與滑動窗口注意力 (SWA)。Samba 將給定的序列選擇性地壓縮到遞迴隱藏狀態中，同時仍保持使用注意力機制準確召回記憶的能力。我們將 Samba 擴展到 3.8B 參數，並使用 3.2T 訓練令牌，並表明 Samba 在基於純注意力或 SSM 的各種基準上都明顯優於最先進的模型。在 4K 長度序列上進行訓練時，Samba 可以有效地外推到 256K 上下文長度，並完美地召回記憶，並顯示出在長達 1M 上下文長度範圍內改進的令牌預測。作為一個線性時間序列模型，與具有分組查詢注意力的 Transformer 相比，Samba 在處理 128K 長度的用戶提示時享有高 3.73 倍的吞吐量，並且在使用無限串流生成 64K 令牌時，加速了 3.64 倍。Samba 的示例實作已公開發布在 https://github.com/microsoft/Samba。

##### **Neural Gaffer: Relighting Any Object via Diffusion**
2406.07520v1 by Haian Jin, Yuan Li, Fujun Luan, Yuanbo Xiangli, Sai Bi, Kai Zhang, Zexiang Xu, Jin Sun, Noah Snavely

Single-image relighting is a challenging task that involves reasoning about
the complex interplay between geometry, materials, and lighting. Many prior
methods either support only specific categories of images, such as portraits,
or require special capture conditions, like using a flashlight. Alternatively,
some methods explicitly decompose a scene into intrinsic components, such as
normals and BRDFs, which can be inaccurate or under-expressive. In this work,
we propose a novel end-to-end 2D relighting diffusion model, called Neural
Gaffer, that takes a single image of any object and can synthesize an accurate,
high-quality relit image under any novel environmental lighting condition,
simply by conditioning an image generator on a target environment map, without
an explicit scene decomposition. Our method builds on a pre-trained diffusion
model, and fine-tunes it on a synthetic relighting dataset, revealing and
harnessing the inherent understanding of lighting present in the diffusion
model. We evaluate our model on both synthetic and in-the-wild Internet imagery
and demonstrate its advantages in terms of generalization and accuracy.
Moreover, by combining with other generative methods, our model enables many
downstream 2D tasks, such as text-based relighting and object insertion. Our
model can also operate as a strong relighting prior for 3D tasks, such as
relighting a radiance field.

摘要：單張影像重新打光是一項艱難的任務，涉及推理幾何、材料和光線之間的複雜交互作用。許多先前的技術僅支援特定類別的影像，例如人像，或需要特殊拍攝條件，例如使用手電筒。或者，某些技術會明確將場景分解為內在組成部分，例如法線和 BRDF，這可能會不準確或表達不足。在這項工作中，我們提出了一種新穎的端到端 2D 重新打光擴散模型，稱為 Neural Gaffer，它會擷取任何物體的單張影像，並可以在任何新穎的環境光照條件下合成準確、高品質的重新打光影像，只需在影像產生器上加上目標環境貼圖，而無需明確的場景分解。我們的技術建立在預先訓練好的擴散模型上，並在合成重新打光資料集上微調，揭示並利用擴散模型中存在的內在光照理解。我們在合成和野生網路影像上評估我們的模型，並展示其在泛化和準確性方面的優點。此外，透過與其他生成式技術結合，我們的模型支援許多下游 2D 任務，例如基於文字的重新打光和物件插入。我們的模型還可以作為 3D 任務的強大重新打光先驗，例如重新打光輻照場。

##### **Beyond Model Collapse: Scaling Up with Synthesized Data Requires Reinforcement**
2406.07515v1 by Yunzhen Feng, Elvis Dohmatob, Pu Yang, Francois Charton, Julia Kempe

Synthesized data from generative models is increasingly considered as an
alternative to human-annotated data for fine-tuning Large Language Models. This
raises concerns about model collapse: a drop in performance of models
fine-tuned on generated data. Considering that it is easier for both humans and
machines to tell between good and bad examples than to generate high-quality
samples, we investigate the use of feedback on synthesized data to prevent
model collapse. We derive theoretical conditions under which a Gaussian mixture
classification model can achieve asymptotically optimal performance when
trained on feedback-augmented synthesized data, and provide supporting
simulations for finite regimes. We illustrate our theoretical predictions on
two practical problems: computing matrix eigenvalues with transformers and news
summarization with large language models, which both undergo model collapse
when trained on model-generated data. We show that training from
feedback-augmented synthesized data, either by pruning incorrect predictions or
by selecting the best of several guesses, can prevent model collapse,
validating popular approaches like RLHF.

摘要：合成資料來自生成模型，越來越被視為用於微調大型語言模型的真人標註資料的替代方案。這引起了模型崩潰的擔憂：在生成資料上微調模型的效能下降。考慮到人類和機器比生成高品質範例更容易分辨好壞範例，我們研究在合成資料上使用回饋以防止模型崩潰。我們推導出高斯混合分類模型在訓練於回饋增強合成資料時，可以在漸近最佳效能下達成的理論條件，並提供有限狀態的支援模擬。我們在兩個實際問題上說明我們的理論預測：使用轉換器計算矩陣特徵值和使用大型語言模型進行新聞摘要，這兩個問題在訓練於模型生成的資料時都會發生模型崩潰。我們表明，透過修剪不正確的預測或選擇多個猜測中的最佳猜測，從回饋增強合成資料進行訓練可以防止模型崩潰，驗證了 RLHF 等熱門方法。

##### **Understanding Visual Concepts Across Models**
2406.07506v1 by Brandon Trabucco, Max Gurinas, Kyle Doherty, Ruslan Salakhutdinov

Large multimodal models such as Stable Diffusion can generate, detect, and
classify new visual concepts after fine-tuning just a single word embedding. Do
models learn similar words for the same concepts (i.e. <orange-cat> = orange +
cat)? We conduct a large-scale analysis on three state-of-the-art models in
text-to-image generation, open-set object detection, and zero-shot
classification, and find that new word embeddings are model-specific and
non-transferable. Across 4,800 new embeddings trained for 40 diverse visual
concepts on four standard datasets, we find perturbations within an
$\epsilon$-ball to any prior embedding that generate, detect, and classify an
arbitrary concept. When these new embeddings are spliced into new models,
fine-tuning that targets the original model is lost. We show popular soft
prompt-tuning approaches find these perturbative solutions when applied to
visual concept learning tasks, and embeddings for visual concepts are not
transferable. Code for reproducing our work is available at:
https://visual-words.github.io.

摘要：大型多模態模型，例如 Stable Diffusion，在僅微調單一單詞嵌入後，就能產生、偵測和分類新的視覺概念。模型是否會為相同的概念學習類似的單詞（例如 <orange-cat> = orange + cat）？我們對文本到影像產生、開放式物件偵測和零次分類這三種最先進的模型進行大規模分析，發現新的單詞嵌入是特定於模型且不可轉移的。針對四個標準資料集中的 40 個不同的視覺概念訓練的 4,800 個新嵌入，我們發現 $\epsilon$-ball 內的擾動會產生、偵測和分類任意概念，而這些擾動會產生、偵測和分類任意概念。當這些新嵌入被拼接成新模型時，針對原始模型的微調就會消失。我們展示了流行的軟提示微調方法在應用於視覺概念學習任務時會找到這些擾動解，並且視覺概念的嵌入不可轉移。重現我們工作的程式碼可在以下網址取得：https://visual-words.github.io。

##### **THaLLE: Text Hyperlocally Augmented Large Language Extension -- Technical Report**
2406.07505v1 by KBTG Labs, Danupat Khamnuansin, Atthakorn Petchsod, Anuruth Lertpiya, Pornchanan Balee, Thanawat Lodkaew, Tawunrat Chalothorn, Thadpong Pongthawornkamol, Monchai Lertsutthiwong

Recent advancements in Large Language Models (LLMs) have revealed new
capabilities and opportunities across the technological landscape. However, the
practicality of very large LLMs is challenged by their high compute cost, which
does not justify the benefits given their limited capability compared to
humans. While smaller, more practical LLMs have shown potential in financial
analysis, though they are not yet fully proficient, as evidenced by their
near-passing performance on the Chartered Financial Analyst (CFA) exam. In this
work, we present Financial Analyst Extension to our Text Hyperlocally Augmented
Large Language Extension (THaLLE), a series of 8B LLMs consistently achieving
highest performance on mock CFA exams against models of comparable size. We
thoroughly document the fine-tuning techniques used to facilitate future
research. Additionally, we introduce the use of Flare CFA, a publicly available
dataset for evaluating LLMs as a financial advisor.

摘要：大型語言模型 (LLM) 的最新進展揭示了技術領域的新功能和機會。然而，超大型 LLM 的實用性受到其高運算成本的挑戰，這無法證明其好處，因為與人類相比，它們的能力有限。雖然較小、更實用的 LLM 已在財務分析中展現潛力，但它們尚未完全熟練，這從它們在特許金融分析師 (CFA) 考試中接近及格的表現中可以看出。在這項工作中，我們為我們的文本超本地增強大型語言擴展 (THaLLE) 提出財務分析師擴展，一系列 8B LLM 在模擬 CFA 考試中持續取得最高表現，優於同等規模的模型。我們徹底記錄了用於促進未來研究的微調技術。此外，我們介紹了使用 Flare CFA，這是一個公開可用的數據集，用於評估 LLM 作為財務顧問。

##### **Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling Queer Voices**
2406.07504v1 by Atli Sigurgeirsson, Eddie L. Ungless

Modern voice cloning models claim to be able to capture a diverse range of
voices. We test the ability of a typical pipeline to capture the style known
colloquially as "gay voice" and notice a homogenisation effect: synthesised
speech is rated as sounding significantly "less gay" (by LGBTQ+ participants)
than its corresponding ground-truth for speakers with "gay voice", but ratings
actually increase for control speakers. Loss of "gay voice" has implications
for accessibility. We also find that for speakers with "gay voice", loss of
"gay voice" corresponds to lower similarity ratings.
  However, we caution that improving the ability of such models to synthesise
``gay voice'' comes with a great number of risks. We use this pipeline as a
starting point for a discussion on the ethics of modelling queer voices more
broadly. Collecting "clean" queer data has safety and fairness ramifications,
and the resulting technology may cause harms from mockery to death.

摘要：現代的聲音複製模型聲稱能夠捕捉各種不同的聲音。我們測試了一個典型管道捕捉口語中稱為「同志腔」的風格的能力，並注意到同質化的效果：合成語音被評為聽起來明顯「不那麼同志」（由 LGBTQ+ 參與者評分）比其對應的「同志腔」說話者的基本事實，但對照組說話者的評分實際上有所增加。失去「同志腔」對無障礙性有影響。我們還發現，對於「同志腔」說話者來說，失去「同志腔」對應著較低的相似度評分。
然而，我們警告，提高此類模型合成「同志腔」的能力會帶來許多風險。我們使用這個管道作為討論模擬酷兒聲音更廣泛的倫理的起點。收集「乾淨」的酷兒數據具有安全和公平性的影響，而由此產生的技術可能會造成從嘲笑到死亡的傷害。

##### **Image Textualization: An Automatic Framework for Creating Accurate and Detailed Image Descriptions**
2406.07502v1 by Renjie Pi, Jianshu Zhang, Jipeng Zhang, Rui Pan, Zhekai Chen, Tong Zhang

Image description datasets play a crucial role in the advancement of various
applications such as image understanding, text-to-image generation, and
text-image retrieval. Currently, image description datasets primarily originate
from two sources. One source is the scraping of image-text pairs from the web.
Despite their abundance, these descriptions are often of low quality and noisy.
Another is through human labeling. Datasets such as COCO are generally very
short and lack details. Although detailed image descriptions can be annotated
by humans, the high annotation cost limits the feasibility. These limitations
underscore the need for more efficient and scalable methods to generate
accurate and detailed image descriptions. In this paper, we propose an
innovative framework termed Image Textualization (IT), which automatically
produces high-quality image descriptions by leveraging existing multi-modal
large language models (MLLMs) and multiple vision expert models in a
collaborative manner, which maximally convert the visual information into text.
To address the current lack of benchmarks for detailed descriptions, we propose
several benchmarks for comprehensive evaluation, which verifies the quality of
image descriptions created by our framework. Furthermore, we show that
LLaVA-7B, benefiting from training on IT-curated descriptions, acquire improved
capability to generate richer image descriptions, substantially increasing the
length and detail of their output with less hallucination.

摘要：图像描述数据集在各种应用程序的发展中扮演着至关重要的角色，例如图像理解、文本到图像生成以及文本图像检索。目前，图像描述数据集主要来自两个来源。一个来源是从网络上抓取图像文本对。尽管这些描述很丰富，但它们通常质量低且嘈杂。另一个是通过人工标注。诸如 COCO 之类的数据集通常非常短且缺乏细节。尽管可以由人类对详细的图像描述进行标注，但高昂的标注成本限制了可行性。这些限制强调了需要更有效且可扩展的方法来生成准确且详细的图像描述。在本文中，我们提出了一种创新的框架，称为图像文本化 (IT)，它通过以协作方式利用现有的多模态大语言模型 (MLLM) 和多个视觉专家模型，自动生成高质量的图像描述，从而最大程度地将视觉信息转换为文本。为了解决当前详细描述缺乏基准的问题，我们提出了几个基准用于综合评估，从而验证了我们框架创建的图像描述的质量。此外，我们展示了 LLaVA-7B，受益于对 IT 策划的描述的训练，获得了生成更丰富的图像描述的改进能力，显著增加了其输出的长度和细节，并且减少了幻觉。

##### **TextGrad: Automatic "Differentiation" via Text**
2406.07496v1 by Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, James Zou

AI is undergoing a paradigm shift, with breakthroughs achieved by systems
orchestrating multiple large language models (LLMs) and other complex
components. As a result, developing principled and automated optimization
methods for compound AI systems is one of the most important new challenges.
Neural networks faced a similar challenge in its early days until
backpropagation and automatic differentiation transformed the field by making
optimization turn-key. Inspired by this, we introduce TextGrad, a powerful
framework performing automatic ``differentiation'' via text. TextGrad
backpropagates textual feedback provided by LLMs to improve individual
components of a compound AI system. In our framework, LLMs provide rich,
general, natural language suggestions to optimize variables in computation
graphs, ranging from code snippets to molecular structures. TextGrad follows
PyTorch's syntax and abstraction and is flexible and easy-to-use. It works
out-of-the-box for a variety of tasks, where the users only provide the
objective function without tuning components or prompts of the framework. We
showcase TextGrad's effectiveness and generality across a diverse range of
applications, from question answering and molecule optimization to radiotherapy
treatment planning. Without modifying the framework, TextGrad improves the
zero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\%$ to
$55\%$, yields $20\%$ relative performance gain in optimizing LeetCode-Hard
coding problem solutions, improves prompts for reasoning, designs new druglike
small molecules with desirable in silico binding, and designs radiation
oncology treatment plans with high specificity. TextGrad lays a foundation to
accelerate the development of the next-generation of AI systems.

摘要：<paragraph>AI 正經歷一場典範轉移，突破來自於系統編排多個大型語言模型 (LLM) 和其他複雜組成部分。因此，為複合式 AI 系統開發原則化且自動化的最佳化方法，是其中一項最重要的新挑戰。神經網路在早期面臨類似的挑戰，直到反向傳播和自動微分透過讓最佳化變得容易，進而轉變了這個領域。受到此啟發，我們引入了 TextGrad，一個強大的框架，透過文字執行自動「微分」。TextGrad 反向傳播 LLM 提供的文字回饋，以改善複合式 AI 系統的個別組成部分。在我們的框架中，LLM 提供豐富、通用、自然的語言建議，來最佳化運算圖中的變數，範圍從程式碼片段到分子結構。TextGrad 遵循 PyTorch 的語法和抽象，且靈活且易於使用。它適用於各種任務，使用者只需提供目標函數，而無需調整框架的組成部分或提示。我們展示了 TextGrad 在各種應用中的有效性和普遍性，從問答和分子最佳化到放射治療計畫。在不修改框架的情況下，TextGrad 將 Google-Proof 問答中 GPT-4o 的零次學習準確度從 51% 提升至 55%，在最佳化 LeetCode-Hard 編碼問題解答中產生 20% 的相對效能提升，改善推理提示，設計具有理想的矽基結合的新藥物小分子，並設計出具有高特異性的放射腫瘤治療計畫。TextGrad 為加速開發下一代 AI 系統奠定了基礎。</paragraph>

##### **CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**
2406.07494v1 by Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas

Abstractive dialogue summarization is the task of distilling conversations
into informative and concise summaries. Although reviews have been conducted on
this topic, there is a lack of comprehensive work detailing the challenges of
dialogue summarization, unifying the differing understanding of the task, and
aligning proposed techniques, datasets, and evaluation metrics with the
challenges. This article summarizes the research on Transformer-based
abstractive summarization for English dialogues by systematically reviewing
1262 unique research papers published between 2019 and 2024, relying on the
Semantic Scholar and DBLP databases. We cover the main challenges present in
dialog summarization (i.e., language, structure, comprehension, speaker,
salience, and factuality) and link them to corresponding techniques such as
graph-based approaches, additional training tasks, and planning strategies,
which typically overly rely on BART-based encoder-decoder models. We find that
while some challenges, like language, have seen considerable progress, mainly
due to training methods, others, such as comprehension, factuality, and
salience, remain difficult and hold significant research opportunities. We
investigate how these approaches are typically assessed, covering the datasets
for the subdomains of dialogue (e.g., meeting, medical), the established
automatic metrics and human evaluation approaches for assessing scores and
annotator agreement. We observe that only a few datasets span across all
subdomains. The ROUGE metric is the most used, while human evaluation is
frequently reported without sufficient detail on inner-annotator agreement and
annotation guidelines. Additionally, we discuss the possible implications of
the recently explored large language models and conclude that despite a
potential shift in relevance and difficulty, our described challenge taxonomy
remains relevant.

摘要：摘要式对话摘要的任务是将对话提炼成内容丰富且简洁的摘要。尽管已经对该主题进行了综述，但仍然缺乏详细说明对话摘要挑战的全面工作，统一对任务的不同理解，并将提议的技术、数据集和评估指标与挑战相一致。本文通过系统地审查 2019 年至 2024 年间发表的 1262 篇独特的论文，总结了基于 Transformer 的英语对话抽象摘要的研究，这些论文依赖于语义学者和 DBLP 数据库。我们涵盖了对话摘要中存在的主要挑战（即语言、结构、理解、说话者、显着性和事实性），并将它们与相应的技术联系起来，例如基于图的方法、额外的训练任务和规划策略，这些策略通常过度依赖基于 BART 的编码器-解码器模型。我们发现，虽然语言等一些挑战已经取得了相当大的进展，这主要是由于训练方法，但其他挑战，如理解、事实性和显着性，仍然困难且具有重要的研究机会。我们调查了通常如何评估这些方法，涵盖对话子域（例如会议、医疗）的数据集、用于评估分数和注释者一致性的已建立的自动指标和人工评估方法。我们观察到，只有少数数据集跨越所有子域。ROUGE 指标的使用最广泛，而人工评估经常在没有关于内部注释者一致性和注释指南的足够详细信息的情况下进行报告。此外，我们讨论了最近探索的大语言模型的可能影响，并得出结论，尽管相关性和难度可能会发生变化，但我们描述的挑战分类仍然相关。

##### **Paraphrasing in Affirmative Terms Improves Negation Understanding**
2406.07492v1 by MohammadHossein Rezaei, Eduardo Blanco

Negation is a common linguistic phenomenon. Yet language models face
challenges with negation in many natural language understanding tasks such as
question answering and natural language inference. In this paper, we experiment
with seamless strategies that incorporate affirmative interpretations (i.e.,
paraphrases without negation) to make models more robust against negation.
Crucially, our affirmative interpretations are obtained automatically. We show
improvements with CondaQA, a large corpus requiring reasoning with negation,
and five natural language understanding tasks.

摘要：否定是一種常見的語言現象。然而，語言模型在許多自然語言理解任務中面臨否定方面的挑戰，例如問答和自然語言推論。在本文中，我們嘗試了無縫策略，將肯定解釋（即沒有否定的同義詞）納入其中，以使模型對否定更強大。至關重要的是，我們的肯定解釋是自動獲得的。我們展示了使用 CondaQA（一個需要使用否定進行推理的大型語料庫）和五項自然語言理解任務的改進。

##### **Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing**
2406.07483v1 by Mao Li, Frederick Conrad

In the rapidly evolving landscape of Natural Language Processing (NLP), the
use of Large Language Models (LLMs) for automated text annotation in social
media posts has garnered significant interest. Despite the impressive
innovations in developing LLMs like ChatGPT, their efficacy, and accuracy as
annotation tools are not well understood. In this paper, we analyze the
performance of eight open-source and proprietary LLMs for annotating the stance
expressed in social media posts, benchmarking their performance against human
annotators' (i.e., crowd-sourced) judgments. Additionally, we investigate the
conditions under which LLMs are likely to disagree with human judgment. A
significant finding of our study is that the explicitness of text expressing a
stance plays a critical role in how faithfully LLMs' stance judgments match
humans'. We argue that LLMs perform well when human annotators do, and when
LLMs fail, it often corresponds to situations in which human annotators
struggle to reach an agreement. We conclude with recommendations for a
comprehensive approach that combines the precision of human expertise with the
scalability of LLM predictions. This study highlights the importance of
improving the accuracy and comprehensiveness of automated stance detection,
aiming to advance these technologies for more efficient and unbiased analysis
of social media.

摘要：在自然語言處理 (NLP) 快速演變的領域中，使用大型語言模型 (LLM) 對社交媒體貼文進行自動化文字註解引起了極大的興趣。儘管在開發 ChatGPT 等 LLM 方面有令人印象深刻的創新，但它們作為註解工具的效能和準確性尚未被充分理解。在本文中，我們分析了八種開源和專有 LLM 對社交媒體貼文中表達的立場進行註解的效能，並將其效能與人類註解者（即群眾外包）的判斷進行基準測試。此外，我們還探討了 LLM 可能與人類判斷意見相左的條件。我們研究的一個重要發現是，表達立場的文字的明確性在 LLM 的立場判斷與人類的匹配程度中扮演著至關重要的角色。我們認為，當人類註解者表現良好時，LLM 的表現也很好；而當 LLM 失敗時，通常對應於人類註解者難以達成共識的情況。我們最後提出建議，採用一種綜合方法，結合人類專業知識的準確性和 LLM 預測的可擴充性。本研究強調了提高自動化立場檢測的準確性和全面性的重要性，旨在推進這些技術，以便更有效率且無偏見地分析社交媒體。

##### **VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs**
2406.07476v1 by Zesen Cheng, Sicong Leng, Hang Zhang, Yifei Xin, Xin Li, Guanzheng Chen, Yongxin Zhu, Wenqi Zhang, Ziyang Luo, Deli Zhao, Lidong Bing

In this paper, we present the VideoLLaMA 2, a set of Video Large Language
Models (Video-LLMs) designed to enhance spatial-temporal modeling and audio
understanding in video and audio-oriented tasks. Building upon its predecessor,
VideoLLaMA 2 incorporates a tailor-made Spatial-Temporal Convolution (STC)
connector, which effectively captures the intricate spatial and temporal
dynamics of video data. Additionally, we integrate an Audio Branch into the
model through joint training, thereby enriching the multimodal understanding
capabilities of the model by seamlessly incorporating audio cues. Comprehensive
evaluations on multiple-choice video question answering (MC-VQA), open-ended
video question answering (OE-VQA), and video captioning (VC) tasks demonstrate
that VideoLLaMA 2 consistently achieves competitive results among open-source
models and even gets close to some proprietary models on several benchmarks.
Furthermore, VideoLLaMA 2 exhibits reasonable improvements in audio-only and
audio-video question-answering (AQA & OE-AVQA) benchmarks over existing models.
These advancements underline VideoLLaMA 2's superior performance in multimodal
comprehension, setting a new standard for intelligent video analysis systems.
All models are public to facilitate further research.

摘要：在本文中，我們展示了 VideoLLaMA 2，一組視訊大型語言模型 (Video-LLM)，旨在增強視訊和音訊導向任務中的時空建模和音訊理解。VideoLLaMA 2 建立在其前代的基礎上，結合了量身打造的時空卷積 (STC) 連接器，有效捕捉視訊資料的複雜時空動態。此外，我們透過聯合訓練將音訊分支整合到模型中，從而透過無縫整合音訊線索來豐富模型的多模態理解能力。在多選視訊問答 (MC-VQA)、開放式視訊問答 (OE-VQA) 和視訊字幕 (VC) 任務上的全面評估表明，VideoLLaMA 2 在開源模型中持續取得競爭力的結果，甚至在多個基準測試中接近一些專有模型。此外，VideoLLaMA 2 在僅音訊和音訊視訊問答 (AQA 和 OE-AVQA) 基準測試中，展現出優於現有模型的合理改進。這些進步突顯了 VideoLLaMA 2 在多模態理解方面的優異表現，為智慧型視訊分析系統樹立了新標準。所有模型都是公開的，以利進一步的研究。

##### **On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations**
2406.07444v1 by Shiao Meng, Xuming Hu, Aiwei Liu, Fukun Ma, Yawen Yang, Shuang Li, Lijie Wen

Driven by the demand for cross-sentence and large-scale relation extraction,
document-level relation extraction (DocRE) has attracted increasing research
interest. Despite the continuous improvement in performance, we find that
existing DocRE models which initially perform well may make more mistakes when
merely changing the entity names in the document, hindering the generalization
to novel entity names. To this end, we systematically investigate the
robustness of DocRE models to entity name variations in this work. We first
propose a principled pipeline to generate entity-renamed documents by replacing
the original entity names with names from Wikidata. By applying the pipeline to
DocRED and Re-DocRED datasets, we construct two novel benchmarks named
Env-DocRED and Env-Re-DocRED for robustness evaluation. Experimental results
show that both three representative DocRE models and two in-context learned
large language models consistently lack sufficient robustness to entity name
variations, particularly on cross-sentence relation instances and documents
with more entities. Finally, we propose an entity variation robust training
method which not only improves the robustness of DocRE models but also enhances
their understanding and reasoning capabilities. We further verify that the
basic idea of this method can be effectively transferred to in-context learning
for DocRE as well.

摘要：<paragraph>在跨句子和大规模关系抽取的需求推动下，文档级关系抽取 (DocRE) 吸引了越来越多的研究兴趣。尽管性能不断提升，我们发现，最初表现良好的现有 DocRE 模型在仅仅更改文档中的实体名称时可能会出错更多，从而阻碍了对新实体名称的泛化。为此，我们在这项工作中系统地研究了 DocRE 模型对实体名称变化的鲁棒性。我们首先提出一个有原则的管道，通过用来自 Wikidata 的名称替换原始实体名称来生成实体重命名文档。通过将该管道应用于 DocRED 和 Re-DocRED 数据集，我们构建了两个名为 Env-DocRED 和 Env-Re-DocRED 的新基准，用于鲁棒性评估。实验结果表明，三个有代表性的 DocRE 模型和两个上下文中学习的大语言模型始终缺乏对实体名称变化的充分鲁棒性，特别是在跨句子关系实例和具有更多实体的文档上。最后，我们提出了一种实体变化鲁棒训练方法，该方法不仅提高了 DocRE 模型的鲁棒性，还增强了它们的理解和推理能力。我们进一步验证了该方法的基本思想可以有效地转移到 DocRE 的上下文中学习中。</paragraph>

##### **Textual Similarity as a Key Metric in Machine Translation Quality Estimation**
2406.07440v1 by Kun Sun, Rong Wang

Machine Translation (MT) Quality Estimation (QE) assesses translation
reliability without reference texts. This study introduces "textual similarity"
as a new metric for QE, using sentence transformers and cosine similarity to
measure semantic closeness. Analyzing data from the MLQE-PE dataset, we found
that textual similarity exhibits stronger correlations with human scores than
traditional metrics (hter, model evaluation etc.). Employing GAMMs as a
statistical tool, we demonstrated that textual similarity consistently
outperforms other metrics across multiple language pairs in predicting human
scores. We also found that "hter" actually failed to predict human scores in
QE. Our findings highlight the effectiveness of textual similarity as a robust
QE metric, recommending its integration with other metrics into QE frameworks
and MT system training for improved accuracy and usability.

摘要：機器翻譯 (MT) 品質評估 (QE) 在沒有參考文本的情況下評估翻譯可靠性。本研究引入「文字相似度」作為 QE 的新指標，使用句子轉換器和餘弦相似度來測量語義接近度。分析來自 MLQE-PE 資料集的資料，我們發現文字相似度與人類評分之間的相關性比傳統指標（hter、模型評估等）更強。使用 GAMM 作為統計工具，我們證明文字相似度在預測人類評分方面始終優於多種語言對中的其他指標。我們還發現「hter」實際上無法在 QE 中預測人類評分。我們的研究結果突顯了文字相似度作為一種強大的 QE 指標的有效性，建議將其與其他指標整合到 QE 框架和 MT 系統訓練中，以提高準確性和可用性。

##### **Learning Domain-Invariant Features for Out-of-Context News Detection**
2406.07430v1 by Yimeng Gu, Mengqi Zhang, Ignacio Castro, Shu Wu, Gareth Tyson

Multimodal out-of-context news is a common type of misinformation on online
media platforms. This involves posting a caption, alongside an invalid
out-of-context news image. Reflecting its importance, researchers have
developed models to detect such misinformation. However, a common limitation of
these models is that they only consider the scenario where pre-labeled data is
available for each domain, failing to address the out-of-context news detection
on unlabeled domains (e.g., unverified news on new topics or agencies). In this
work, we therefore focus on domain adaptive out-of-context news detection. In
order to effectively adapt the detection model to unlabeled news topics or
agencies, we propose ConDA-TTA (Contrastive Domain Adaptation with Test-Time
Adaptation) which applies contrastive learning and maximum mean discrepancy
(MMD) to learn the domain-invariant feature. In addition, it leverages target
domain statistics during test-time to further assist domain adaptation.
Experimental results show that our approach outperforms baselines in 5 out of 7
domain adaptation settings on two public datasets, by as much as 2.93% in F1
and 2.08% in accuracy.

摘要：多模態非情境新聞是一種常見於線上媒體平台的錯誤資訊類型。這涉及張貼標題，並附上無效的非情境新聞圖片。研究人員已開發出模型來偵測此類錯誤資訊，以反映其重要性。然而，這些模型的常見限制是，它們只考慮每個網域都有預先標記資料的場景，無法解決未標記網域（例如新主題或機構的未驗證新聞）上的非情境新聞偵測。因此，我們在這項工作中專注於網域適應非情境新聞偵測。為了有效地將偵測模型適應到未標記的新聞主題或機構，我們提出 ConDA-TTA（對比網域適應與測試時間適應），它應用對比學習和最大平均差異（MMD）來學習網域不變特徵。此外，它在測試時間利用目標網域統計資料，以進一步協助網域適應。實驗結果顯示，我們的做法在兩個公開資料集上的 7 個網域適應設定中有 5 個優於基準，F1 值最多高出 2.93%，準確度高出 2.08%。

##### **MINERS: Multilingual Language Models as Semantic Retrievers**
2406.07424v1 by Genta Indra Winata, Ruochen Zhang, David Ifeoluwa Adelani

Words have been represented in a high-dimensional vector space that encodes
their semantic similarities, enabling downstream applications such as
retrieving synonyms, antonyms, and relevant contexts. However, despite recent
advances in multilingual language models (LMs), the effectiveness of these
models' representations in semantic retrieval contexts has not been
comprehensively explored. To fill this gap, this paper introduces the MINERS, a
benchmark designed to evaluate the ability of multilingual LMs in semantic
retrieval tasks, including bitext mining and classification via
retrieval-augmented contexts. We create a comprehensive framework to assess the
robustness of LMs in retrieving samples across over 200 diverse languages,
including extremely low-resource languages in challenging cross-lingual and
code-switching settings. Our results demonstrate that by solely retrieving
semantically similar embeddings yields performance competitive with
state-of-the-art approaches, without requiring any fine-tuning.

摘要：文字已在高維度向量空間中被表示，該空間編碼了它們的語義相似性，從而啟用了下游應用，例如檢索同義詞、反義詞和相關語境。然而，儘管多語言語言模型 (LM) 最近取得了進展，但這些模型的表徵在語義檢索語境中的有效性尚未得到全面探討。為了填補這一空白，本文介紹了 MINERS，這是一個基準，旨在評估多語言 LM 在語義檢索任務中的能力，包括通過檢索增強的語境進行雙語文本挖掘和分類。我們創建了一個綜合框架，用於評估 LM 在 200 多種不同語言中檢索樣本的穩健性，包括在具有挑戰性的跨語言和代碼轉換設置中的極低資源語言。我們的結果表明，僅通過檢索語義相似的嵌入，就可以產生與最先進的方法相媲美的性能，而無需進行任何微調。

##### **Enhanced Gene Selection in Single-Cell Genomics: Pre-Filtering Synergy and Reinforced Optimization**
2406.07418v1 by Weiliang Zhang, Zhen Meng, Dongjie Wang, Min Wu, Kunpeng Liu, Yuanchun Zhou, Meng Xiao

Recent advancements in single-cell genomics necessitate precision in gene
panel selection to interpret complex biological data effectively. Those methods
aim to streamline the analysis of scRNA-seq data by focusing on the most
informative genes that contribute significantly to the specific analysis task.
Traditional selection methods, which often rely on expert domain knowledge,
embedded machine learning models, or heuristic-based iterative optimization,
are prone to biases and inefficiencies that may obscure critical genomic
signals. Recognizing the limitations of traditional methods, we aim to
transcend these constraints with a refined strategy. In this study, we
introduce an iterative gene panel selection strategy that is applicable to
clustering tasks in single-cell genomics. Our method uniquely integrates
results from other gene selection algorithms, providing valuable preliminary
boundaries or prior knowledge as initial guides in the search space to enhance
the efficiency of our framework. Furthermore, we incorporate the stochastic
nature of the exploration process in reinforcement learning (RL) and its
capability for continuous optimization through reward-based feedback. This
combination mitigates the biases inherent in the initial boundaries and
harnesses RL's adaptability to refine and target gene panel selection
dynamically. To illustrate the effectiveness of our method, we conducted
detailed comparative experiments, case studies, and visualization analysis.

摘要：單細胞基因體學的最新進展需要基因組精準選擇，才能有效地詮釋複雜的生物資料。這些方法旨在簡化 scRNA-seq 資料的分析，專注於對特定分析任務有顯著貢獻的最具資訊性的基因。傳統的選擇方法，通常依賴於專家領域知識、內嵌機器學習模型或基於啟發式的反覆最佳化，容易產生偏差和低效率，可能會模糊關鍵的基因體訊號。認識到傳統方法的限制，我們旨在超越這些限制，採用精進的策略。在本研究中，我們介紹了一種反覆的基因組選擇策略，適用於單細胞基因體學中的分群任務。我們的獨特方法整合了其他基因選擇演算法的結果，提供了有價值的初步界線或先驗知識，作為搜尋空間中的初始指引，以提升我們架構的效率。此外，我們將探索過程的隨機性質納入強化學習 (RL) 中，並透過基於獎勵的回饋，發揮其持續最佳化的能力。這種組合減輕了初始界線中固有的偏差，並利用 RL 的適應性來動態地精進和鎖定基因組選擇。為了說明我們方法的有效性，我們進行了詳細的比較實驗、案例研究和視覺化分析。

##### **VersiCode: Towards Version-controllable Code Generation**
2406.07411v1 by Tongtong Wu, Weigang Wu, Xingyu Wang, Kang Xu, Suyu Ma, Bo Jiang, Ping Yang, Zhenchang Xing, Yuan-Fang Li, Gholamreza Haffari

Significant research has focused on improving the performance of large
language model on code-related tasks due to their practical importance.
Although performance is typically evaluated using public benchmark datasets,
the existing datasets do not account for the concept of \emph{version}, which
is crucial in professional software development. In this paper, we introduce
VersiCode, the first comprehensive dataset designed to assess the ability of
large language models to generate verifiable code for specific library
versions. VersiCode encompasses 300 libraries across more than 2,000 versions
spanning 9 years. We design two dedicated evaluation tasks: version-specific
code completion (VSCC) and version-aware code editing (VACE). Comprehensive
experiments are conducted to benchmark the performance of LLMs, revealing the
challenging nature of these tasks and VersiCode, that even state-of-the-art
LLMs struggle to generate version-correct code. This dataset, together with the
proposed tasks, sheds light on LLMs' capabilities and limitations in handling
version-specific code generation, and opens up an important new area of
research for further investigation. The resources can be found at
https://github.com/wutong8023/VersiCode.

摘要：由於大型語言模型在與程式碼相關任務上的實用重要性，許多重要的研究專注於提升其效能。雖然效能通常使用公開基準資料集進行評估，但現有的資料集並未考量到「版本」的概念，而這在專業軟體開發中至關重要。在本論文中，我們引入了 VersiCode，這是第一個全面的資料集，旨在評估大型語言模型為特定程式庫版本產生可驗證程式碼的能力。VersiCode 涵蓋了 9 年內超過 2,000 個版本的 300 個程式庫。我們設計了兩個專用的評估任務：特定版本程式碼完成 (VSCC) 和版本感知程式碼編輯 (VACE)。我們進行了全面的實驗來評量大型語言模型的效能，揭示了這些任務的挑戰性本質和 VersiCode，即使是現今最先進的大型語言模型也很難產生版本正確的程式碼。此資料集連同所提出的任務，闡明了大型語言模型在處理特定版本程式碼產生方面的能力和限制，並為進一步研究開闢了一個重要的領域。資源可以在 https://github.com/wutong8023/VersiCode 找到。

##### **Visual Representation Learning with Stochastic Frame Prediction**
2406.07398v1 by Huiwon Jang, Dongyoung Kim, Junsu Kim, Jinwoo Shin, Pieter Abbeel, Younggyo Seo

Self-supervised learning of image representations by predicting future frames
is a promising direction but still remains a challenge. This is because of the
under-determined nature of frame prediction; multiple potential futures can
arise from a single current frame. To tackle this challenge, in this paper, we
revisit the idea of stochastic video generation that learns to capture
uncertainty in frame prediction and explore its effectiveness for
representation learning. Specifically, we design a framework that trains a
stochastic frame prediction model to learn temporal information between frames.
Moreover, to learn dense information within each frame, we introduce an
auxiliary masked image modeling objective along with a shared decoder
architecture. We find this architecture allows for combining both objectives in
a synergistic and compute-efficient manner. We demonstrate the effectiveness of
our framework on a variety of tasks from video label propagation and
vision-based robot learning domains, such as video segmentation, pose tracking,
vision-based robotic locomotion, and manipulation tasks. Code is available on
the project webpage: https://sites.google.com/view/2024rsp.

摘要：利用未來影像預測來進行影像表徵的自監督學習，是一個很有前景的方向，但仍是一個挑戰。這是因為影像預測本質上未確定；單一目前的影像可能產生多種潛在未來。為了應對這個挑戰，我們在這篇論文中，重新檢視隨機影片生成的構想，學習捕捉影像預測中的不確定性，並探討其在表徵學習中的效用。具體來說，我們設計了一個架構，訓練一個隨機影像預測模型，以學習影像之間的時間資訊。此外，為了學習每個影像中的密集資訊，我們引進一個輔助的遮罩影像建模目標，以及一個共享的解碼器架構。我們發現這個架構可以以協同且計算有效率的方式，結合這兩個目標。我們在各種任務上展示了我們架構的效用，這些任務來自影片標籤傳播和基於視覺的機器人學習領域，例如影片分割、姿勢追蹤、基於視覺的機器人運動和操作任務。程式碼可以在專案網頁上取得：https://sites.google.com/view/2024rsp。

##### **Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B**
2406.07394v1 by Di Zhang, Jiatong Li, Xiaoshui Huang, Dongzhan Zhou, Yuqiang Li, Wanli Ouyang

This paper introduces the MCT Self-Refine (MCTSr) algorithm, an innovative
integration of Large Language Models (LLMs) with Monte Carlo Tree Search
(MCTS), designed to enhance performance in complex mathematical reasoning
tasks. Addressing the challenges of accuracy and reliability in LLMs,
particularly in strategic and mathematical reasoning, MCTSr leverages
systematic exploration and heuristic self-refine mechanisms to improve
decision-making frameworks within LLMs. The algorithm constructs a Monte Carlo
search tree through iterative processes of Selection, self-refine,
self-evaluation, and Backpropagation, utilizing an improved Upper Confidence
Bound (UCB) formula to optimize the exploration-exploitation balance. Extensive
experiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical
problems, significantly improving success rates across multiple datasets,
including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math
Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in
complex reasoning tasks and sets a foundation for future AI integration,
enhancing decision-making accuracy and reliability in LLM-driven applications.

摘要：這篇論文介紹了 MCT 自我精進 (MCTSr) 演算法，這是一個創新的演算法，結合了大型語言模型 (LLM) 與蒙地卡羅樹狀搜尋 (MCTS)，旨在提升複雜數學推理任務的效能。針對 LLM 在準確度和可靠度方面的挑戰，特別是在策略性和數學推理方面，MCTSr 採用系統性的探索和啟發式自我精進機制來改善 LLM 內的決策架構。該演算法透過選擇、自我精進、自我評估和反向傳播的迭代流程建構蒙地卡羅搜尋樹，並利用改良的上置信界 (UCB) 公式來最佳化探索與利用的平衡。大量的實驗證明了 MCTSr 在解奧林匹克等級數學問題上的效力，大幅提升了多個資料集的成功率，包括 GSM8K、GSM Hard、MATH，以及奧林匹克等級的基準，包括 Math Odyssey、AIME 和 OlympiadBench。這項研究推動了 LLM 在複雜推理任務中的應用，並為未來的 AI 整合奠定了基礎，提升了 LLM 驅動應用程式中決策的準確度和可靠度。

##### **Limited Out-of-Context Knowledge Reasoning in Large Language Models**
2406.07393v1 by Peng Hu, Changjiang Gao, Ruiqi Gao, Jiajun Chen, Shujian Huang

Large Language Models (LLMs) have demonstrated strong capabilities as
knowledge bases and significant in-context reasoning capabilities. However,
previous work challenges their out-of-context reasoning ability, i.e., the
ability to infer information from their training data, instead of from the
context or prompt. This paper focuses on a significant facet of out-of-context
reasoning: Out-of-Context Knowledge Reasoning (OCKR), which is to combine
multiple knowledge to infer new knowledge. We designed a synthetic dataset with
seven representative OCKR tasks to systematically assess the OCKR capabilities
of LLMs. Using this dataset, we evaluated the LLaMA2-13B-chat model and
discovered that its proficiency in this aspect is limited, regardless of
whether the knowledge is trained in a separate or adjacent training settings.
Moreover, training the model to reason with complete reasoning data did not
result in significant improvement. Training the model to perform explicit
knowledge retrieval helps in only one of the tasks, indicating that the model's
limited OCKR capabilities are due to difficulties in retrieving relevant
knowledge. Furthermore, we treat cross-lingual knowledge transfer as a distinct
form of OCKR, and evaluate this ability. Our results show that the evaluated
model also exhibits limited ability in transferring knowledge across languages.
The dataset used in this study is available at
https://github.com/NJUNLP/ID-OCKR.

摘要：大型語言模型 (LLM) 已展現出作為知識庫的強大功能，以及重要的語境推理能力。然而，先前的研究挑戰了它們的語境外推理能力，也就是從訓練資料中推論資訊的能力，而不是從語境或提示中推論。本文著重於語境外推理的重要面向：語境外知識推理 (OCKR)，也就是結合多種知識推論新知識。我們設計了一個包含七項具代表性的 OCKR 任務的合成資料集，以系統性評估 LLM 的 OCKR 能力。我們使用這個資料集評估了 LLaMA2-13B-chat 模型，發現它在這方面的能力有限，無論知識是在分開或相鄰的訓練設定中訓練。此外，訓練模型使用完整的推理資料進行推理並未帶來顯著的進步。訓練模型執行明確的知識擷取只對其中一項任務有幫助，這表示模型有限的 OCKR 能力是源於擷取相關知識的困難。此外，我們將跨語言知識轉移視為 OCKR 的一種不同形式，並評估這種能力。我們的結果顯示，所評估的模型在跨語言轉移知識方面的能力也受到限制。本研究中使用的資料集可在 https://github.com/NJUNLP/ID-OCKR 取得。

##### **World Models with Hints of Large Language Models for Goal Achieving**
2406.07381v1 by Zeyuan Liu, Ziyu Huan, Xiyao Wang, Jiafei Lyu, Jian Tao, Xiu Li, Furong Huang, Huazhe Xu

Reinforcement learning struggles in the face of long-horizon tasks and sparse
goals due to the difficulty in manual reward specification. While existing
methods address this by adding intrinsic rewards, they may fail to provide
meaningful guidance in long-horizon decision-making tasks with large state and
action spaces, lacking purposeful exploration. Inspired by human cognition, we
propose a new multi-modal model-based RL approach named Dreaming with Large
Language Models (DLLM). DLLM integrates the proposed hinting subgoals from the
LLMs into the model rollouts to encourage goal discovery and reaching in
challenging tasks. By assigning higher intrinsic rewards to samples that align
with the hints outlined by the language model during model rollouts, DLLM
guides the agent toward meaningful and efficient exploration. Extensive
experiments demonstrate that the DLLM outperforms recent methods in various
challenging, sparse-reward environments such as HomeGrid, Crafter, and
Minecraft by 27.7\%, 21.1\%, and 9.9\%, respectively.

摘要：由於手動獎勵規範的難度，強化學習在面對長時程任務和稀疏目標時會遇到困難。雖然現有方法透過增加內在獎勵來解決此問題，但它們可能無法在具有大量狀態和動作空間的長時程決策任務中提供有意義的指導，缺乏有目的的探索。受到人類認知的啟發，我們提出了一種新的多模式基於模型的 RL 方法，稱為使用大型語言模型的夢想 (DLLM)。DLLM 將 LLM 中提出的提示子目標整合到模型的滾動中，以鼓勵目標的發現和在具有挑戰性的任務中達成目標。透過將較高的內在獎勵分配給與語言模型在模型滾動期間概述的提示一致的樣本，DLLM 引導代理朝向有意義且有效的探索。大量的實驗證明，DLLM 在各種具有挑戰性的稀疏獎勵環境中優於最近的方法，例如 HomeGrid、Crafter 和 Minecraft，分別提高了 27.7%、21.1% 和 9.9%。

##### **Large Language Models for Constrained-Based Causal Discovery**
2406.07378v1 by Kai-Hendrik Cohrs, Gherardo Varando, Emiliano Diaz, Vasileios Sitokonstantinou, Gustau Camps-Valls

Causality is essential for understanding complex systems, such as the
economy, the brain, and the climate. Constructing causal graphs often relies on
either data-driven or expert-driven approaches, both fraught with challenges.
The former methods, like the celebrated PC algorithm, face issues with data
requirements and assumptions of causal sufficiency, while the latter demand
substantial time and domain knowledge. This work explores the capabilities of
Large Language Models (LLMs) as an alternative to domain experts for causal
graph generation. We frame conditional independence queries as prompts to LLMs
and employ the PC algorithm with the answers. The performance of the LLM-based
conditional independence oracle on systems with known causal graphs shows a
high degree of variability. We improve the performance through a proposed
statistical-inspired voting schema that allows some control over false-positive
and false-negative rates. Inspecting the chain-of-thought argumentation, we
find causal reasoning to justify its answer to a probabilistic query. We show
evidence that knowledge-based CIT could eventually become a complementary tool
for data-driven causal discovery.

摘要：因果關係對於理解複雜的系統至關重要，例如經濟、大腦和氣候。建構因果圖表通常依賴於資料驅動或專家驅動的方法，這兩種方法都充滿了挑戰。前者方法，例如著名的 PC 演算法，面臨資料需求和因果充足性的假設問題，而後者則需要大量的時間和領域知識。這項工作探討了大型語言模型 (LLM) 作為因果圖生成領域專家的替代方案的能力。我們將條件獨立查詢設定為 LLM 的提示，並使用 PC 演算法搭配答案。基於 LLM 的條件獨立神諭在具有已知因果圖表的系統上的效能顯示出高度的變異性。我們透過提議的統計啟發式投票架構來改善效能，該架構允許對假陽性和假陰性率進行一些控制。檢查思考鏈論證，我們發現因果推理可以證明其對機率查詢的回答。我們顯示基於知識的 CIT 最終可能成為資料驅動因果發現的補充工具的證據。

##### **When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models**
2406.07368v1 by Haoran You, Yichao Fu, Zheng Wang, Amir Yazdanbakhsh, Yingyan, Lin

Autoregressive Large Language Models (LLMs) have achieved impressive
performance in language tasks but face two significant bottlenecks: (1)
quadratic complexity in the attention module as the number of tokens increases,
and (2) limited efficiency due to the sequential processing nature of
autoregressive LLMs during generation. While linear attention and speculative
decoding offer potential solutions, their applicability and synergistic
potential for enhancing autoregressive LLMs remain uncertain. We conduct the
first comprehensive study on the efficacy of existing linear attention methods
for autoregressive LLMs, integrating them with speculative decoding. We
introduce an augmentation technique for linear attention that ensures
compatibility with speculative decoding, enabling more efficient training and
serving of LLMs. Extensive experiments and ablation studies involving seven
existing linear attention models and five encoder/decoder-based LLMs
consistently validate the effectiveness of our augmented linearized LLMs.
Notably, our approach achieves up to a 6.67 reduction in perplexity on the
LLaMA model and up to a 2$\times$ speedup during generation compared to prior
linear attention methods. Codes and models are available at
https://github.com/GATECH-EIC/Linearized-LLM.

摘要：自迴歸大型語言模型 (LLM) 在語言任務中取得令人印象深刻的表現，但面臨兩個重大的瓶頸：(1) 隨著符號數量增加，注意力模組中的二次複雜度，以及 (2) 由於自迴歸 LLM 在生成期間的順序處理特性所導致的效率受限。雖然線性注意力和推測性解碼提供了潛在的解決方案，但它們在自迴歸 LLM 中的適用性和協同潛力仍不確定。我們對現有線性注意力方法在自迴歸 LLM 中的效能進行了第一個全面的研究，將它們與推測性解碼整合在一起。我們引入了一種線性注意力的擴充技術，確保與推測性解碼相容，從而實現 LLM 的更有效率訓練和服務。涉及七個現有線性注意力模型和五個編碼器/解碼器基礎 LLM 的廣泛實驗和消融研究，一致驗證了我們擴充的線性化 LLM 的有效性。值得注意的是，與先前的線性注意力方法相比，我們的方法在 LLaMA 模型上實現了困惑度降低多達 6.67 倍，並且在生成期間加速多達 2 倍。程式碼和模型可以在 https://github.com/GATECH-EIC/Linearized-LLM 取得。

##### **BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction**
2406.07365v1 by Yinhao Bai, Yalan Xie, Xiaoyi Liu, Yuhua Zhao, Zhixin Han, Mengting Hu, Hang Gao, Renhong Cheng

Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based
elements, including aspect term, opinion term, aspect category, and sentiment
polarity. In practice, unseen aspects, due to distinct data distribution,
impose many challenges for a trained neural model. Motivated by this, this work
formulates ASQP into the few-shot scenario, which aims for fast adaptation in
real applications. Therefore, we first construct a few-shot ASQP dataset (FSQP)
that contains richer categories and is more balanced for the few-shot study.
Moreover, recent methods extract quads through a generation paradigm, which
involves converting the input sentence into a templated target sequence.
However, they primarily focus on the utilization of a single template or the
consideration of different template orders, thereby overlooking the
correlations among various templates. To tackle this issue, we further propose
a Broadview Soft Prompting (BvSP) method that aggregates multiple templates
with a broader view by taking into account the correlation between the
different templates. Specifically, BvSP uses the pre-trained language model to
select the most relevant k templates with Jensen-Shannon divergence. BvSP
further introduces soft prompts to guide the pre-trained language model using
the selected templates. Then, we aggregate the results of multi-templates by
voting mechanism. Empirical results demonstrate that BvSP significantly
outperforms the stateof-the-art methods under four few-shot settings and other
public datasets. Our code and dataset are available at
https://github.com/byinhao/BvSP.

摘要：面向方面的觀點四元組預測 (ASQP) 旨在預測四個基於方面的元素，包括方面詞、觀點詞、方面類別和觀點極性。在實務上，未見的方面由於資料分佈不同，對訓練好的神經模型造成許多挑戰。有鑑於此，本研究將 ASQP 制定成小樣本場景，旨在快速適應實際應用。因此，我們首先建構一個小樣本 ASQP 資料集 (FSQP)，其中包含更豐富的類別，並且對於小樣本研究更為平衡。此外，近期方法透過生成範例來萃取四元組，其中包括將輸入句子轉換成範本目標序列。然而，它們主要著重於使用單一範本或考慮不同範本順序，因而忽略了各種範本之間的關聯性。為了解決這個問題，我們進一步提出廣闊視角軟提示 (BvSP) 方法，透過考量不同範本之間的關聯性，以更廣闊的視野彙整多個範本。具體來說，BvSP 使用預先訓練好的語言模型，以 Jensen-Shannon divergence 選擇最相關的 k 個範本。BvSP 進一步導入軟提示，以使用選定的範本引導預先訓練好的語言模型。然後，我們透過投票機制彙整多範本的結果。實證結果顯示，在四種小樣本設定和其他公開資料集下，BvSP 的表現顯著優於現有技術。我們的程式碼和資料集可在 https://github.com/byinhao/BvSP 取得。

##### **AI Sandbagging: Language Models can Strategically Underperform on Evaluations**
2406.07358v1 by Teun van der Weij, Felix Hofstätter, Ollie Jaffe, Samuel F. Brown, Francis Rhys Ward

Trustworthy capability evaluations are crucial for ensuring the safety of AI
systems, and are becoming a key component of AI regulation. However, the
developers of an AI system, or the AI system itself, may have incentives for
evaluations to understate the AI's actual capability. These conflicting
interests lead to the problem of sandbagging $\unicode{x2013}$ which we define
as "strategic underperformance on an evaluation". In this paper we assess
sandbagging capabilities in contemporary language models (LMs). We prompt
frontier LMs, like GPT-4 and Claude 3 Opus, to selectively underperform on
dangerous capability evaluations, while maintaining performance on general
(harmless) capability evaluations. Moreover, we find that models can be
fine-tuned, on a synthetic dataset, to hide specific capabilities unless given
a password. This behaviour generalizes to high-quality, held-out benchmarks
such as WMDP. In addition, we show that both frontier and smaller models can be
prompted, or password-locked, to target specific scores on a capability
evaluation. Even more, we found that a capable password-locked model (Llama 3
70b) is reasonably able to emulate a less capable model (Llama 2 7b). Overall,
our results suggest that capability evaluations are vulnerable to sandbagging.
This vulnerability decreases the trustworthiness of evaluations, and thereby
undermines important safety decisions regarding the development and deployment
of advanced AI systems.

摘要：可信賴的能力評估對於確保 AI 系統的安全性至關重要，並正成為 AI 法規的一個關鍵組成部分。然而，AI 系統的開發人員或 AI 系統本身可能會有誘因讓評估低估 AI 的實際能力。這些利益衝突導致了「灌水」的問題，我們將其定義為「在評估中策略性地表現不佳」。在本文中，我們評估了當代語言模型 (LM) 中的灌水能力。我們提示前沿語言模型，例如 GPT-4 和 Claude 3 Opus，在危險的能力評估中選擇性地表現不佳，同時在一般（無害）能力評估中保持表現。此外，我們發現模型可以在合成資料集上進行微調，以隱藏特定能力，除非給出密碼。這種行為推廣到高品質、保留的基準，例如 WMDP。此外，我們表明，前沿和較小的模型都可以被提示或密碼鎖定，以在能力評估中瞄準特定分數。更重要的是，我們發現一個有能力的密碼鎖定模型（Llama 3 70b）有能力模擬一個能力較弱的模型（Llama 2 7b）。總的來說，我們的結果表明能力評估容易受到灌水攻擊。這種漏洞降低了評估的可信度，從而破壞了有關先進 AI 系統開發和部署的重要安全決策。

##### **Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities**
2406.07353v1 by Delfina Sol Martinez Pandiani, Erik Tjong Kim Sang, Davide Ceolin

Internet memes, channels for humor, social commentary, and cultural
expression, are increasingly used to spread toxic messages. Studies on the
computational analyses of toxic memes have significantly grown over the past
five years, and the only three surveys on computational toxic meme analysis
cover only work published until 2022, leading to inconsistent terminology and
unexplored trends. Our work fills this gap by surveying content-based
computational perspectives on toxic memes, and reviewing key developments until
early 2024. Employing the PRISMA methodology, we systematically extend the
previously considered papers, achieving a threefold result. First, we survey
119 new papers, analyzing 158 computational works focused on content-based
toxic meme analysis. We identify over 30 datasets used in toxic meme analysis
and examine their labeling systems. Second, after observing the existence of
unclear definitions of meme toxicity in computational works, we introduce a new
taxonomy for categorizing meme toxicity types. We also note an expansion in
computational tasks beyond the simple binary classification of memes as toxic
or non-toxic, indicating a shift towards achieving a nuanced comprehension of
toxicity. Third, we identify three content-based dimensions of meme toxicity
under automatic study: target, intent, and conveyance tactics. We develop a
framework illustrating the relationships between these dimensions and meme
toxicities. The survey analyzes key challenges and recent trends, such as
enhanced cross-modal reasoning, integrating expert and cultural knowledge, the
demand for automatic toxicity explanations, and handling meme toxicity in
low-resource languages. Also, it notes the rising use of Large Language Models
(LLMs) and generative AI for detecting and generating toxic memes. Finally, it
proposes pathways for advancing toxic meme detection and interpretation.

摘要：網路迷因，一種幽默、社會評論和文化表達的管道，正越來越常被用來散播有毒訊息。過去五年來，針對有毒迷因的運算分析研究大幅成長，而僅有的三份關於運算有毒迷因分析的調查僅涵蓋 2022 年之前發表的著作，導致術語不一致且趨勢未被探討。我們的研究透過調查基於內容的運算觀點來填補這個空白，並回顧截至 2024 年初的關鍵發展。採用 PRISMA 方法，我們系統性地擴充先前考慮的論文，取得三方面成果。首先，我們調查了 119 篇新論文，分析了 158 項專注於基於內容的有毒迷因分析的運算作品。我們找出有毒迷因分析中使用的超過 30 個資料集，並檢視其標記系統。其次，在觀察到運算作品中對迷因毒性缺乏明確定義後，我們引進一個新的分類法來分類迷因毒性類型。我們也注意到運算任務已擴展到超越將迷因簡單二元分類為有毒或無毒的範疇，顯示出朝向對毒性有細微差別的理解邁進。第三，我們找出有毒迷因在自動研究中基於內容的三個面向：目標、意圖和傳達策略。我們發展了一個架構來說明這些面向與迷因毒性之間的關係。這份調查分析了關鍵挑戰和近期趨勢，例如增強跨模態推理、整合專家和文化知識、對自動毒性解釋的需求，以及處理低資源語言中的迷因毒性。此外，它也指出大型語言模型 (LLM) 和生成式 AI 在偵測和產生有毒迷因中的使用率正逐漸上升。最後，它提出促進有毒迷因偵測和詮釋的途徑。

##### **DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering**
2406.07348v1 by Zijian Hei, Weiling Wei, Wenjie Ou, Juyi Qiao, Junming Jiao, Zhiqing Zhu, Guowen Song

Retrieval-Augmented Generation (RAG) has significantly demonstrated the
performance of Large Language Models (LLMs) in the knowledge-intensive tasks,
such as Question-Answering (QA). RAG expands the query context by incorporating
external knowledge bases to enhance the response accuracy. However, it would be
inefficient to access LLMs multiple times for each query and unreliable to
retrieve all the relevant documents by a single query. We find that even though
there is low relevance between some critical documents and query, it is
possible to retrieve the remaining documents by combining parts of the
documents with the query. To mine the relevance, a two-stage retrieval
framework called Dynamic-Relevant Retrieval-Augmented Generation (DR-RAG) is
proposed to improve document retrieval recall and the accuracy of answers while
maintaining efficiency. Also, a small classifier is applied to two different
selection strategies to determine the contribution of the retrieved documents
to answering the query and retrieve the relatively relevant documents.
Meanwhile, DR-RAG call the LLMs only once, which significantly improves the
efficiency of the experiment. The experimental results on multi-hop QA datasets
show that DR-RAG can significantly improve the accuracy of the answers and
achieve new progress in QA systems.

摘要：檢索增強生成 (RAG) 已顯著證明大型語言模型 (LLM) 在知識密集型任務中的效能，例如問答 (QA)。RAG 透過納入外部知識庫來擴展查詢內容，以增強回應準確性。然而，對於每個查詢多次存取 LLM 會很低效，且透過單一查詢檢索所有相關文件並不可靠。我們發現，即使某些關鍵文件與查詢之間關聯性低，也可以透過將文件的部分與查詢結合來檢索剩餘文件。為了挖掘相關性，提出了一個名為動態相關檢索增強生成 (DR-RAG) 的兩階段檢索架構，以改善文件檢索召回率和答案準確性，同時維持效率。此外，將一個小型分類器應用於兩種不同的選擇策略，以確定檢索到的文件對回答查詢的貢獻，並檢索相對相關的文件。同時，DR-RAG 只呼叫 LLM 一次，這顯著地改善了實驗效率。多跳 QA 資料集的實驗結果顯示，DR-RAG 可以顯著提高答案準確性，並在 QA 系統中取得新進展。

##### **CTC-based Non-autoregressive Textless Speech-to-Speech Translation**
2406.07330v1 by Qingkai Fang, Zhengrui Ma, Yan Zhou, Min Zhang, Yang Feng

Direct speech-to-speech translation (S2ST) has achieved impressive
translation quality, but it often faces the challenge of slow decoding due to
the considerable length of speech sequences. Recently, some research has turned
to non-autoregressive (NAR) models to expedite decoding, yet the translation
quality typically lags behind autoregressive (AR) models significantly. In this
paper, we investigate the performance of CTC-based NAR models in S2ST, as these
models have shown impressive results in machine translation. Experimental
results demonstrate that by combining pretraining, knowledge distillation, and
advanced NAR training techniques such as glancing training and non-monotonic
latent alignments, CTC-based NAR models achieve translation quality comparable
to the AR model, while preserving up to 26.81$\times$ decoding speedup.

摘要：直接語音轉語音翻譯 (S2ST) 已達到令人印象深刻的翻譯品質，但它經常面臨由於語音序列相當長而導致的編碼速度緩慢的挑戰。最近，一些研究已轉向非自迴歸 (NAR) 模型來加快編碼速度，但翻譯品質通常顯著落後於自迴歸 (AR) 模型。在本文中，我們探討了基於 CTC 的 NAR 模型在 S2ST 中的效能，因為這些模型在機器翻譯中已展現出令人印象深刻的結果。實驗結果證明，透過結合預訓練、知識萃取以及先進的 NAR 訓練技術（例如瀏覽訓練和非單調潛在對齊），基於 CTC 的 NAR 模型可達到與 AR 模型相當的翻譯品質，同時保留高達 26.81 倍的編碼速度。

##### **3D-Properties: Identifying Challenges in DPO and Charting a Path Forward**
2406.07327v1 by Yuzi Yan, Yibo Miao, Jialian Li, Yipin Zhang, Jian Xie, Zhijie Deng, Dong Yan

Aligning large language models (LLMs) with human preference has recently
gained tremendous attention, with the canonical yet costly RLHF-PPO and the
simple and straightforward Direct Preference Optimization (DPO) as two
examples. Despite the efficiency, DPO has rarely be used in the
state-of-the-art production-level LLMs, implying its potential pathologies. In
this work, we revisit DPO with a comprehensive examination of its empirical
efficacy and a systematic comparison with RLHF-PPO. We identify the
\textbf{3D}-properties of DPO's learning outcomes: the \textbf{D}rastic drop in
the likelihood of rejected responses, the \textbf{D}egradation into LLM
unlearning, and the \textbf{D}ispersion effect on unseen responses through
experiments with both a carefully designed toy model and practical LLMs on
tasks including mathematical problem-solving and instruction following. These
findings inherently connect to some observations made by related works and we
additionally contribute a plausible theoretical explanation for them.
Accordingly, we propose easy regularization methods to mitigate the issues
caused by \textbf{3D}-properties, improving the training stability and final
performance of DPO. Our contributions also include an investigation into how
the distribution of the paired preference data impacts the effectiveness of
DPO. We hope this work could offer research directions to narrow the gap
between reward-free preference learning methods and reward-based ones.

摘要：<paragraph>將大型語言模型 (LLM) 與人類偏好一致化最近受到極大的關注，其中典型的但代價高昂的 RLHF-PPO 和簡單直接的直接偏好最佳化 (DPO) 就是兩個範例。儘管效率高，但 DPO 在最先進的生產級 LLM 中很少使用，這意味著其潛在的病理。在這項工作中，我們以全面檢視其經驗效能和與 RLHF-PPO 的系統比較，重新探討 DPO。我們找出 DPO 學習成果的「3D」特性：被拒絕回應的機率大幅下降 (Drastic drop)、惡化成 LLM 失學 (Degradation) 以及透過仔細設計的玩具模型和實際 LLM 進行的實驗，對未見過回應產生分散效應 (Dispersion effect)，這些任務包括數學問題求解和遵循指令。這些發現與相關工作所做的某些觀察本質上相關聯，而且我們進一步為它們提供合理的理論解釋。因此，我們提出簡單的正則化方法來減輕由「3D」特性所造成的議題，改善 DPO 的訓練穩定性和最終效能。我們的貢獻還包括調查配對偏好資料的分配如何影響 DPO 的效能。我們希望這項工作可以提供研究方向，以縮小無獎勵偏好學習方法和基於獎勵的偏好學習方法之間的差距。</paragraph>

##### **Should XAI Nudge Human Decisions with Explanation Biasing?**
2406.07323v1 by Yosuke Fukuchi, Seiji Yamada

This paper reviews our previous trials of Nudge-XAI, an approach that
introduces automatic biases into explanations from explainable AIs (XAIs) with
the aim of leading users to better decisions, and it discusses the benefits and
challenges. Nudge-XAI uses a user model that predicts the influence of
providing an explanation or emphasizing it and attempts to guide users toward
AI-suggested decisions without coercion. The nudge design is expected to
enhance the autonomy of users, reduce the risk associated with an AI making
decisions without users' full agreement, and enable users to avoid AI failures.
To discuss the potential of Nudge-XAI, this paper reports a post-hoc
investigation of previous experimental results using cluster analysis. The
results demonstrate the diversity of user behavior in response to Nudge-XAI,
which supports our aim of enhancing user autonomy. However, it also highlights
the challenge of users who distrust AI and falsely make decisions contrary to
AI suggestions, suggesting the need for personalized adjustment of the strength
of nudges to make this approach work more generally.

摘要：本文檢視我們先前對 Nudge-XAI 的試驗，這是一種方法，可將自動偏差引入可解釋 AI (XAI) 的解釋中，目的是引導使用者做出更好的決策，並討論其優點和挑戰。Nudge-XAI 使用使用者模型來預測提供解釋或強調解釋的影響，並嘗試在沒有強制的情況下引導使用者朝向 AI 建議的決策。預期推動設計將增強使用者的自主性，降低 AI 在未經使用者充分同意下做出決策相關的風險，並讓使用者避免 AI 失敗。為了討論 Nudge-XAI 的潛力，本文回報了使用群集分析對先前實驗結果的事後調查。結果證明使用者行為對 Nudge-XAI 的反應具有多樣性，這支持了我們增強使用者自主性的目標。然而，它也突顯了不信任 AI 並錯誤地做出與 AI 建議相反決策的使用者所帶來的挑戰，這表示需要針對推動強度進行個人化調整，才能讓此方法更普遍地發揮作用。

##### **MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting**
2406.07310v1 by Zhiqi Ai, Zhiyong Chen, Shugong Xu

In this paper, we propose MM-KWS, a novel approach to user-defined keyword
spotting leveraging multi-modal enrollments of text and speech templates.
Unlike previous methods that focus solely on either text or speech features,
MM-KWS extracts phoneme, text, and speech embeddings from both modalities.
These embeddings are then compared with the query speech embedding to detect
the target keywords. To ensure the applicability of MM-KWS across diverse
languages, we utilize a feature extractor incorporating several multilingual
pre-trained models. Subsequently, we validate its effectiveness on Mandarin and
English tasks. In addition, we have integrated advanced data augmentation tools
for hard case mining to enhance MM-KWS in distinguishing confusable words.
Experimental results on the LibriPhrase and WenetPhrase datasets demonstrate
that MM-KWS outperforms prior methods significantly.

摘要：在本文中，我們提出了 MM-KWS，一種利用文字和語音範本的多模態註冊來進行使用者定義關鍵字偵測的新穎方法。與以往僅專注於文字或語音特徵的方法不同，MM-KWS 從兩種模式中提取音素、文字和語音嵌入。然後將這些嵌入與查詢語音嵌入進行比較，以偵測目標關鍵字。為了確保 MM-KWS 適用於各種語言，我們利用了一個結合多個多語言預訓練模型的特徵萃取器。隨後，我們驗證了它在普通話和英語任務上的有效性。此外，我們整合了先進的資料擴充工具，用於困難案例挖掘，以增強 MM-KWS 在區分混淆字詞上的能力。在 LibriPhrase 和 WenetPhrase 資料集上的實驗結果表明，MM-KWS 明顯優於先前的各種方法。

##### **BertaQA: How Much Do Language Models Know About Local Culture?**
2406.07302v1 by Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe

Large Language Models (LLMs) exhibit extensive knowledge about the world, but
most evaluations have been limited to global or anglocentric subjects. This
raises the question of how well these models perform on topics relevant to
other cultures, whose presence on the web is not that prominent. To address
this gap, we introduce BertaQA, a multiple-choice trivia dataset that is
parallel in English and Basque. The dataset consists of a local subset with
questions pertinent to the Basque culture, and a global subset with questions
of broader interest. We find that state-of-the-art LLMs struggle with local
cultural knowledge, even as they excel on global topics. However, we show that
continued pre-training in Basque significantly improves the models' performance
on Basque culture, even when queried in English. To our knowledge, this is the
first solid evidence of knowledge transfer from a low-resource to a
high-resource language. Our analysis sheds light on the complex interplay
between language and knowledge, and reveals that some prior findings do not
fully hold when reassessed on local topics. Our dataset and evaluation code are
available under open licenses at https://github.com/juletx/BertaQA.

摘要：大型語言模型 (LLM) 展示了對世界的廣泛知識，但
大多數評估僅限於全球或以盎格魯為中心的科目。這
引發了一個問題，即這些模型對與
其他文化相關的主題的表現如何，而這些文化在網路上的存在並不那麼突出。為了解決
這個差距，我們引入了 BertaQA，這是一個多選題瑣事資料集，
它在英語和巴斯克語中是平行的。該資料集包含一個本地子集，其中包含
與巴斯克文化相關的問題，以及一個全球子集，其中包含更廣泛的問題
興趣。我們發現，即使在全球主題上表現出色，最先進的 LLM 也難以應對當地
文化知識。然而，我們表明，在巴斯克語中持續預訓練顯著提高了模型的表現
巴斯克文化，即使用英語查詢。據我們所知，這是知識轉移的第一次確鑿證據
從低資源語言到高資源語言。我們的分析揭示了語言和知識之間的複雜相互作用，
並揭示了一些先前的發現並未
在重新評估當地主題時完全成立。我們的資料集和評估程式碼可在
https://github.com/juletx/BertaQA 下的開放許可下獲得。

##### **Instruct Large Language Models to Drive like Humans**
2406.07296v1 by Ruijun Zhang, Xianda Guo, Wenzhao Zheng, Chenming Zhang, Kurt Keutzer, Long Chen

Motion planning in complex scenarios is the core challenge in autonomous
driving. Conventional methods apply predefined rules or learn from driving data
to plan the future trajectory. Recent methods seek the knowledge preserved in
large language models (LLMs) and apply them in the driving scenarios. Despite
the promising results, it is still unclear whether the LLM learns the
underlying human logic to drive. In this paper, we propose an InstructDriver
method to transform LLM into a motion planner with explicit instruction tuning
to align its behavior with humans. We derive driving instruction data based on
human logic (e.g., do not cause collisions) and traffic rules (e.g., proceed
only when green lights). We then employ an interpretable InstructChain module
to further reason the final planning reflecting the instructions. Our
InstructDriver allows the injection of human rules and learning from driving
data, enabling both interpretability and data scalability. Different from
existing methods that experimented on closed-loop or simulated settings, we
adopt the real-world closed-loop motion planning nuPlan benchmark for better
evaluation. InstructDriver demonstrates the effectiveness of the LLM planner in
a real-world closed-loop setting. Our code is publicly available at
https://github.com/bonbon-rj/InstructDriver.

摘要：複雜情境下的運動規劃是自動駕駛的核心挑戰。傳統方法應用預先定義的規則或從駕駛數據中學習來規劃未來軌跡。最近的方法尋求保留在大語言模型 (LLM) 中的知識並將其應用於駕駛情境。儘管有令人滿意的結果，但 LLM 是否學習了人類的基本駕駛邏輯仍不清楚。在本文中，我們提出了一個 InstructDriver 方法，將 LLM 轉換為運動規劃器，並進行明確的指令調整，使其行為與人類保持一致。我們根據人類邏輯（例如，不要造成碰撞）和交通規則（例如，只有在綠燈時才進行）推導駕駛指令數據。然後，我們採用一個可解釋的 InstructChain 模組，進一步推論反映指令的最終規劃。我們的 InstructDriver 允許注入人類規則和從駕駛數據中學習，從而實現可解釋性和數據可擴充性。不同於在閉環或模擬設置中進行實驗的現有方法，我們採用了真實世界的閉環運動規劃 nuPlan 基準以進行更好的評估。InstructDriver 在真實世界的閉環設置中展示了 LLM 規劃器的有效性。我們的程式碼可在 https://github.com/bonbon-rj/InstructDriver 公開取得。

##### **Joint Learning of Context and Feedback Embeddings in Spoken Dialogue**
2406.07291v1 by Livia Qian, Gabriel Skantze

Short feedback responses, such as backchannels, play an important role in
spoken dialogue. So far, most of the modeling of feedback responses has focused
on their timing, often neglecting how their lexical and prosodic form influence
their contextual appropriateness and conversational function. In this paper, we
investigate the possibility of embedding short dialogue contexts and feedback
responses in the same representation space using a contrastive learning
objective. In our evaluation, we primarily focus on how such embeddings can be
used as a context-feedback appropriateness metric and thus for feedback
response ranking in U.S. English dialogues. Our results show that the model
outperforms humans given the same ranking task and that the learned embeddings
carry information about the conversational function of feedback responses.

摘要：簡短的回饋回應，例如反向頻道，在口語對話中扮演著重要的角色。到目前為止，大多數對回饋回應的建模都專注於時機，常常忽略其字彙和韻律形式如何影響其脈絡適當性和對話功能。在本文中，我們探討將簡短的對話脈絡和回饋回應嵌入同一個表示空間的可能性，並使用對比學習目標。在我們的評估中，我們主要專注於如何將此類嵌入用作脈絡回饋適當性指標，並進而用於美國英語對話中的回饋回應排名。我們的結果顯示，在相同的排名任務中，模型表現優於人類，且學習到的嵌入包含有關回饋回應對話功能的資訊。

##### **Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?**
2406.07289v1 by Qingkai Fang, Shaolei Zhang, Zhengrui Ma, Min Zhang, Yang Feng

Recently proposed two-pass direct speech-to-speech translation (S2ST) models
decompose the task into speech-to-text translation (S2TT) and text-to-speech
(TTS) within an end-to-end model, yielding promising results. However, the
training of these models still relies on parallel speech data, which is
extremely challenging to collect. In contrast, S2TT and TTS have accumulated a
large amount of data and pretrained models, which have not been fully utilized
in the development of S2ST models. Inspired by this, in this paper, we first
introduce a composite S2ST model named ComSpeech, which can seamlessly
integrate any pretrained S2TT and TTS models into a direct S2ST model.
Furthermore, to eliminate the reliance on parallel speech data, we propose a
novel training method ComSpeech-ZS that solely utilizes S2TT and TTS data. It
aligns representations in the latent space through contrastive learning,
enabling the speech synthesis capability learned from the TTS data to
generalize to S2ST in a zero-shot manner. Experimental results on the CVSS
dataset show that when the parallel speech data is available, ComSpeech
surpasses previous two-pass models like UnitY and Translatotron 2 in both
translation quality and decoding speed. When there is no parallel speech data,
ComSpeech-ZS lags behind \name by only 0.7 ASR-BLEU and outperforms the
cascaded models.

摘要：<paragraph>最近提出的兩階段直接語音轉語音翻譯 (S2ST) 模型
將任務分解為語音轉文字翻譯 (S2TT) 和文字轉語音
(TTS)，在端到端模型中產生令人滿意的結果。然而，這些模型的
訓練依舊仰賴平行語音資料，而這類資料極難收集。相較之下，S2TT 和 TTS 已累積了
大量的資料和預訓練模型，而這些資料和模型在 S2ST 模型的開發中尚未得到充分利用
受到這點啟發，我們在本文中首先介紹一個名為 ComSpeech 的複合式 S2ST 模型，它可以將任何預訓練的 S2TT 和 TTS 模型無縫整合到直接的 S2ST 模型中。
此外，為了不再依賴平行語音資料，我們提出了一種新穎的訓練方法 ComSpeech-ZS，它僅利用 S2TT 和 TTS 資料。它透過對比學習在潛在空間中比對表徵，
讓從 TTS 資料中學習到的語音合成能力能夠以零次學習的方式推廣到 S2ST。在 CVSS
資料集上的實驗結果顯示，當平行語音資料可用時，ComSpeech
在翻譯品質和解碼速度上都超越了先前的兩階段模型，例如 UnitY 和 Translatotron 2。當沒有平行語音資料時，
ComSpeech-ZS 僅落後 \name 0.7 ASR-BLEU，且表現優於串接模型。</paragraph>

##### **Fine-tuning with HED-IT: The impact of human post-editing for dialogical language models**
2406.07288v1 by Daniela Occhipinti, Michele Marchi, Irene Mondella, Huiyuan Lai, Felice Dell'Orletta, Malvina Nissim, Marco Guerini

Automatic methods for generating and gathering linguistic data have proven
effective for fine-tuning Language Models (LMs) in languages less resourced
than English. Still, while there has been emphasis on data quantity, less
attention has been given to its quality. In this work, we investigate the
impact of human intervention on machine-generated data when fine-tuning
dialogical models. In particular, we study (1) whether post-edited dialogues
exhibit higher perceived quality compared to the originals that were
automatically generated; (2) whether fine-tuning with post-edited dialogues
results in noticeable differences in the generated outputs; and (3) whether
post-edited dialogues influence the outcomes when considering the parameter
size of the LMs. To this end we created HED-IT, a large-scale dataset where
machine-generated dialogues are paired with the version post-edited by humans.
Using both the edited and unedited portions of HED-IT, we fine-tuned three
different sizes of an LM. Results from both human and automatic evaluation show
that the different quality of training data is clearly perceived and it has an
impact also on the models trained on such data. Additionally, our findings
indicate that larger models are less sensitive to data quality, whereas this
has a crucial impact on smaller models. These results enhance our comprehension
of the impact of human intervention on training data in the development of
high-quality LMs.

摘要：自動化方法用於產生和收集語言資料，已被證明有效適用於調整資源少於英語的語言模型 (LM)。儘管如此，雖然強調資料數量，但對其品質的關注卻較少。在這項工作中，我們探討了在調整對話模型時，人類介入對機器產生資料的影響。具體而言，我們研究 (1) 後編輯對話是否展現出比自動產生的原始對話更高的感知品質；(2) 使用後編輯對話進行調整是否會導致產出產生明顯差異；以及 (3) 後編輯對話是否會在考量 LM 參數大小時影響結果。為此，我們建立了 HED-IT，一個大型資料集，其中機器產生的對話與人類後編輯的版本配對。使用 HED-IT 的已編輯和未編輯部分，我們微調了 LM 的三種不同大小。來自人類和自動評估的結果顯示，訓練資料的不同品質明顯被感知，並且也會影響在這些資料上訓練的模型。此外，我們的研究結果表明，較大的模型對資料品質的敏感度較低，而這對較小的模型有至關重要的影響。這些結果增強了我們對在開發高品質 LM 時，人類介入對訓練資料影響的理解。

##### **Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5 Few-Shot Learning**
2406.07287v1 by AmirMohammad Azadi, Baktash Ansari, Sina Zamani

Sexism in online content is a pervasive issue that necessitates effective
classification techniques to mitigate its harmful impact. Online platforms
often have sexist comments and posts that create a hostile environment,
especially for women and minority groups. This content not only spreads harmful
stereotypes but also causes emotional harm. Reliable methods are essential to
find and remove sexist content, making online spaces safer and more welcoming.
Therefore, the sEXism Identification in Social neTworks (EXIST) challenge
addresses this issue at CLEF 2024. This study aims to improve sexism
identification in bilingual contexts (English and Spanish) by leveraging
natural language processing models. The tasks are to determine whether a text
is sexist and what the source intention behind it is. We fine-tuned the
XLM-RoBERTa model and separately used GPT-3.5 with few-shot learning prompts to
classify sexist content. The XLM-RoBERTa model exhibited robust performance in
handling complex linguistic structures, while GPT-3.5's few-shot learning
capability allowed for rapid adaptation to new data with minimal labeled
examples. Our approach using XLM-RoBERTa achieved 4th place in the soft-soft
evaluation of Task 1 (sexism identification). For Task 2 (source intention), we
achieved 2nd place in the soft-soft evaluation.

摘要：網路內容中的性別歧視是一個普遍存在的問題，需要有效的分類技術來減輕其有害影響。網路平台經常出現性別歧視的評論和文章，創造出不友善的環境，特別是對女性和少數族群。此類內容不僅散布有害的刻板印象，也會造成情緒傷害。可靠的方法對於尋找和移除性別歧視內容至關重要，讓網路空間更安全、更友善。因此，社群網路中的性別歧視辨識（EXIST）挑戰在 CLEF 2024 中探討這個問題。本研究旨在透過自然語言處理模型來改善雙語情境（英語和西班牙語）中的性別歧視辨識。任務是判斷一段文字是否具有性別歧視，以及背後的來源意圖為何。我們微調了 XLM-RoBERTa 模型，並分別使用 GPT-3.5 和少量學習提示來分類性別歧視內容。XLM-RoBERTa 模型在處理複雜的語言結構方面表現出色，而 GPT-3.5 的少量學習能力則允許使用最少的標記範例快速適應新資料。我們使用 XLM-RoBERTa 的方法在任務 1（性別歧視辨識）的軟性評估中獲得第 4 名。對於任務 2（來源意圖），我們在軟性評估中獲得第 2 名。

##### **Speaking Your Language: Spatial Relationships in Interpretable Emergent Communication**
2406.07277v1 by Olaf Lipinski, Adam J. Sobey, Federico Cerutti, Timothy J. Norman

Effective communication requires the ability to refer to specific parts of an
observation in relation to others. While emergent communication literature
shows success in developing various language properties, no research has shown
the emergence of such positional references. This paper demonstrates how agents
can communicate about spatial relationships within their observations. The
results indicate that agents can develop a language capable of expressing the
relationships between parts of their observation, achieving over 90% accuracy
when trained in a referential game which requires such communication. Using a
collocation measure, we demonstrate how the agents create such references. This
analysis suggests that agents use a mixture of non-compositional and
compositional messages to convey spatial relationships. We also show that the
emergent language is interpretable by humans. The translation accuracy is
tested by communicating with the receiver agent, where the receiver achieves
over 78% accuracy using parts of this lexicon, confirming that the
interpretation of the emergent language was successful.

摘要：有效的溝通需要具備根據其他部分指涉觀察特定部分的能力。儘管新興的溝通文獻顯示在發展各種語言屬性方面取得成功，但沒有研究顯示此類位置參考的出現。本文說明代理如何就其觀察中的空間關係進行溝通。結果表明，代理可以發展出能夠表達其觀察部分之間關係的語言，在需要此類溝通的參考遊戲中訓練後，準確率超過 90%。我們使用搭配測量法，說明代理如何建立此類參考。此分析表明，代理使用非組合和組合訊息的混合來傳達空間關係。我們也顯示，人類可以詮釋新興語言。翻譯準確度透過與接收者代理溝通進行測試，接收者使用此詞彙的一部分達到超過 78% 的準確度，確認新興語言的詮釋是成功的。

##### **DCA-Bench: A Benchmark for Dataset Curation Agents**
2406.07275v1 by Benhao Huang, Yingzhuo Yu, Jin Huang, Xingjian Zhang, Jiaqi Ma

The quality of datasets plays an increasingly crucial role in the research
and development of modern artificial intelligence (AI). Despite the
proliferation of open dataset platforms nowadays, data quality issues, such as
insufficient documentation, inaccurate annotations, and ethical concerns,
remain common in datasets widely used in AI. Furthermore, these issues are
often subtle and difficult to be detected by rule-based scripts, requiring
expensive manual identification and verification by dataset users or
maintainers. With the increasing capability of large language models (LLMs), it
is promising to streamline the curation of datasets with LLM agents. In this
work, as the initial step towards this goal, we propose a dataset curation
agent benchmark, DCA-Bench, to measure LLM agents' capability of detecting
hidden dataset quality issues. Specifically, we collect diverse real-world
dataset quality issues from eight open dataset platforms as a testbed.
Additionally, to establish an automatic pipeline for evaluating the success of
LLM agents, which requires a nuanced understanding of the agent outputs, we
implement a dedicated Evaluator using another LLM agent. We demonstrate that
the LLM-based Evaluator empirically aligns well with human evaluation, allowing
reliable automatic evaluation on the proposed benchmark. We further conduct
experiments on several baseline LLM agents on the proposed benchmark and
demonstrate the complexity of the task, indicating that applying LLMs to
real-world dataset curation still requires further in-depth exploration and
innovation. Finally, the proposed benchmark can also serve as a testbed for
measuring the capability of LLMs in problem discovery rather than just
problem-solving. The benchmark suite is available at
\url{https://github.com/TRAIS-Lab/dca-bench}.

摘要：<paragraph>資料集的品質在現代人工智慧 (AI) 的研究與開發中扮演著越來越關鍵的角色。儘管現今開放式資料集平台激增，資料品質問題，例如文件不足、註解不準確和道德疑慮，在廣泛使用於 AI 的資料集中仍然很常見。此外，這些問題通常很微妙，且難以透過基於規則的指令碼偵測，需要資料集使用者或維護人員進行昂貴的手動識別和驗證。隨著大型語言模型 (LLM) 能力的提升，使用 LLM 代理簡化資料集策展工作令人期待。在這項工作中，作為朝向此目標邁出的第一步，我們提出一個資料集策展代理基準測試，DCA-Bench，用於衡量 LLM 代理偵測隱藏資料集品質問題的能力。具體來說，我們從八個開放式資料集平台收集了各種真實世界的資料集品質問題作為測試平台。此外，為了建立一個用於評估 LLM 代理成功的自動化流程，這需要對代理輸出有細緻的了解，我們使用另一個 LLM 代理實作了一個專用的評估器。我們證明，基於 LLM 的評估器在經驗上與人工評估非常吻合，允許在所提出的基準測試上進行可靠的自動評估。我們進一步在所提出的基準測試上對幾個基線 LLM 代理進行實驗，並證明了這項任務的複雜性，表明將 LLM 應用於真實世界的資料集策展仍需要進一步的深入探索和創新。最後，所提出的基準測試也可以作為衡量 LLM 在問題發現而非僅僅問題解決方面的能力的測試平台。基準測試套件可在 \url{https://github.com/TRAIS-Lab/dca-bench} 取得。</paragraph>

##### **Advancing Grounded Multimodal Named Entity Recognition via LLM-Based Reformulation and Box-Based Segmentation**
2406.07268v1 by Jinyuan Li, Ziyan Li, Han Li, Jianfei Yu, Rui Xia, Di Sun, Gang Pan

Grounded Multimodal Named Entity Recognition (GMNER) task aims to identify
named entities, entity types and their corresponding visual regions. GMNER task
exhibits two challenging attributes: 1) The tenuous correlation between images
and text on social media contributes to a notable proportion of named entities
being ungroundable. 2) There exists a distinction between coarse-grained noun
phrases used in similar tasks (e.g., phrase localization) and fine-grained
named entities. In this paper, we propose RiVEG, a unified framework that
reformulates GMNER into a joint MNER-VE-VG task by leveraging large language
models (LLMs) as connecting bridges. This reformulation brings two benefits: 1)
It enables us to optimize the MNER module for optimal MNER performance and
eliminates the need to pre-extract region features using object detection
methods, thus naturally addressing the two major limitations of existing GMNER
methods. 2) The introduction of Entity Expansion Expression module and Visual
Entailment (VE) module unifies Visual Grounding (VG) and Entity Grounding (EG).
This endows the proposed framework with unlimited data and model scalability.
Furthermore, to address the potential ambiguity stemming from the
coarse-grained bounding box output in GMNER, we further construct the new
Segmented Multimodal Named Entity Recognition (SMNER) task and corresponding
Twitter-SMNER dataset aimed at generating fine-grained segmentation masks, and
experimentally demonstrate the feasibility and effectiveness of using box
prompt-based Segment Anything Model (SAM) to empower any GMNER model with the
ability to accomplish the SMNER task. Extensive experiments demonstrate that
RiVEG significantly outperforms SoTA methods on four datasets across the MNER,
GMNER, and SMNER tasks.

摘要：<paragraph>接地多模态命名实体识别 (GMNER) 任务旨在识别命名实体、实体类型及其对应的视觉区域。GMNER 任务展现出两个具有挑战性的属性：1) 图像和社交媒体文本之间的微弱关联导致相当一部分命名实体无法接地。2) 在类似任务（例如，短语定位）中使用的粗粒度名词短语与细粒度命名实体之间存在区别。在本文中，我们提出了 RiVEG，这是一个统一的框架，通过利用大型语言模型 (LLM) 作为连接桥梁，将 GMNER 重新表述为联合 MNER-VE-VG 任务。这种重新表述带来了两个好处：1) 它使我们能够针对最佳 MNER 性能优化 MNER 模块，并消除了使用对象检测方法预先提取区域特征的需要，从而自然地解决了现有 GMNER 方法的两个主要限制。2) 实体扩展表达式模块和视觉蕴涵 (VE) 模块的引入统一了视觉接地 (VG) 和实体接地 (EG)。这赋予了所提出的框架无限的数据和模型可扩展性。此外，为了解决源自 GMNER 中粗粒度边界框输出的潜在歧义，我们进一步构建了新的分段多模态命名实体识别 (SMNER) 任务和相应的 Twitter-SMNER 数据集，旨在生成细粒度分割掩码，并通过实验展示了使用基于框提示的 Segment Anything Model (SAM) 增强任何 GMNER 模型以完成 SMNER 任务的可行性和有效性。大量实验表明，RiVEG 在四个数据集上的 MNER、GMNER 和 SMNER 任务中明显优于 SoTA 方法。</paragraph>

##### **Efficient 3D Molecular Generation with Flow Matching and Scale Optimal Transport**
2406.07266v1 by Ross Irwin, Alessandro Tibo, Jon-Paul Janet, Simon Olsson

Generative models for 3D drug design have gained prominence recently for
their potential to design ligands directly within protein pockets. Current
approaches, however, often suffer from very slow sampling times or generate
molecules with poor chemical validity. Addressing these limitations, we propose
Semla, a scalable E(3)-equivariant message passing architecture. We further
introduce a molecular generation model, MolFlow, which is trained using flow
matching along with scale optimal transport, a novel extension of equivariant
optimal transport. Our model produces state-of-the-art results on benchmark
datasets with just 100 sampling steps. Crucially, MolFlow samples high quality
molecules with as few as 20 steps, corresponding to a two order-of-magnitude
speed-up compared to state-of-the-art, without sacrificing performance.
Furthermore, we highlight limitations of current evaluation methods for 3D
generation and propose new benchmark metrics for unconditional molecular
generators. Finally, using these new metrics, we compare our model's ability to
generate high quality samples against current approaches and further
demonstrate MolFlow's strong performance.

摘要：3D 藥物設計的生成模型最近因其直接在蛋白質口袋中設計配體的潛力而受到關注。然而，目前的方法通常會導致非常緩慢的取樣時間，或產生化學效度不佳的分子。為了解決這些限制，我們提出了 Semla，一種可擴充的 E(3) 等變訊息傳遞架構。我們進一步引入了分子生成模型 MolFlow，它是使用流匹配以及規模最佳傳輸（等變最佳傳輸的一種新延伸）進行訓練的。我們的模型在基準資料集上僅使用 100 個取樣步驟就產生了最先進的結果。至關重要的是，MolFlow 以低至 20 個步驟取樣高品質分子，相當於與最先進技術相比快了兩個數量級，同時不犧牲效能。此外，我們強調了目前 3D 生成的評估方法的限制，並提出了無條件分子生成器的新的基準指標。最後，使用這些新的指標，我們比較了我們的模型產生高品質樣本的能力與目前的方法，並進一步證明了 MolFlow 的強大效能。

##### **Scientific Computing with Large Language Models**
2406.07259v1 by Christopher Culver, Peter Hicks, Mihailo Milenkovic, Sanjif Shanmugavelu, Tobias Becker

We provide an overview of the emergence of large language models for
scientific computing applications. We highlight use cases that involve natural
language processing of scientific documents and specialized languages designed
to describe physical systems. For the former, chatbot style applications appear
in medicine, mathematics and physics and can be used iteratively with domain
experts for problem solving. We also review specialized languages within
molecular biology, the languages of molecules, proteins, and DNA where language
models are being used to predict properties and even create novel physical
systems at much faster rates than traditional computing methods.

摘要：我們概述了大型語言模型在科學計算應用中的出現。我們重點介紹了涉及科學文件自然語言處理和專門語言的用例，這些語言用於描述物理系統。對於前者，聊天機器人風格的應用出現在醫學、數學和物理學中，並且可以與領域專家反覆使用以解決問題。我們還回顧了分子生物學中的專業語言，即分子、蛋白質和 DNA 的語言，其中語言模型被用於預測屬性，甚至以比傳統計算方法快得多的速度創建新穎的物理系統。

##### **Scholarly Question Answering using Large Language Models in the NFDI4DataScience Gateway**
2406.07257v1 by Hamed Babaei Giglou, Tilahun Abedissa Taffa, Rana Abdullah, Aida Usmanova, Ricardo Usbeck, Jennifer D'Souza, Sören Auer

This paper introduces a scholarly Question Answering (QA) system on top of
the NFDI4DataScience Gateway, employing a Retrieval Augmented Generation-based
(RAG) approach. The NFDI4DS Gateway, as a foundational framework, offers a
unified and intuitive interface for querying various scientific databases using
federated search. The RAG-based scholarly QA, powered by a Large Language Model
(LLM), facilitates dynamic interaction with search results, enhancing filtering
capabilities and fostering a conversational engagement with the Gateway search.
The effectiveness of both the Gateway and the scholarly QA system is
demonstrated through experimental analysis.

摘要：本論文在 NFDI4DataScience Gateway 之上介紹了一個學術問答 (QA) 系統，採用檢索增強生成 (RAG) 方法。NFDI4DS Gateway 作為一個基礎架構，提供了一個統一且直觀的介面，可使用聯合搜尋查詢各種科學資料庫。由大型語言模型 (LLM) 支援的基於 RAG 的學術 QA，促進與搜尋結果的動態互動，增強過濾能力並促進與 Gateway 搜尋的對話式互動。Gateway 和學術 QA 系統的有效性都透過實驗分析得到證明。

##### **AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection**
2406.07256v1 by Rong Gong, Hongfei Xue, Lezhi Wang, Xin Xu, Qisheng Li, Lei Xie, Hui Bu, Shaomei Wu, Jiaming Zhou, Yong Qin, Binbin Zhang, Jun Du, Jia Bin, Ming Li

The rapid advancements in speech technologies over the past two decades have
led to human-level performance in tasks like automatic speech recognition (ASR)
for fluent speech. However, the efficacy of these models diminishes when
applied to atypical speech, such as stuttering. This paper introduces AS-70,
the first publicly available Mandarin stuttered speech dataset, which stands
out as the largest dataset in its category. Encompassing conversational and
voice command reading speech, AS-70 includes verbatim manual transcription,
rendering it suitable for various speech-related tasks. Furthermore, baseline
systems are established, and experimental results are presented for ASR and
stuttering event detection (SED) tasks. By incorporating this dataset into the
model fine-tuning, significant improvements in the state-of-the-art ASR models,
e.g., Whisper and Hubert, are observed, enhancing their inclusivity in
addressing stuttered speech.

摘要：在過去二十年中，語音技術的快速進展
已導致自動語音辨識 (ASR) 等任務中達到人類等級的表現
用於流暢的語音。然而，當應用於非典型語音（例如口吃）時，這些模型的效力會降低。本文介紹了 AS-70，
第一個公開可用的國語口吃語音資料集，在同類別中脫穎而出，成為最大的資料集。涵蓋對話和
語音命令朗讀語音，AS-70 包含逐字手動轉錄，使其適用於各種與語音相關的任務。此外，建立了基準
系統，並針對 ASR 和口吃事件偵測 (SED) 任務提供了實驗結果。透過將此資料集納入模型微調中，觀察到最先進的 ASR 模型（例如 Whisper 和 Hubert）有顯著的改進，增強了它們在處理口吃語音時的包容性。

##### **Is One GPU Enough? Pushing Image Generation at Higher-Resolutions with Foundation Models**
2406.07251v1 by Athanasios Tragakis, Marco Aversa, Chaitanya Kaul, Roderick Murray-Smith, Daniele Faccio

In this work, we introduce Pixelsmith, a zero-shot text-to-image generative
framework to sample images at higher resolutions with a single GPU. We are the
first to show that it is possible to scale the output of a pre-trained
diffusion model by a factor of 1000, opening the road for gigapixel image
generation at no additional cost. Our cascading method uses the image generated
at the lowest resolution as a baseline to sample at higher resolutions. For the
guidance, we introduce the Slider, a tunable mechanism that fuses the overall
structure contained in the first-generated image with enhanced fine details. At
each inference step, we denoise patches rather than the entire latent space,
minimizing memory demands such that a single GPU can handle the process,
regardless of the image's resolution. Our experimental results show that
Pixelsmith not only achieves higher quality and diversity compared to existing
techniques, but also reduces sampling time and artifacts. The code for our work
is available at https://github.com/Thanos-DB/Pixelsmith.

摘要：在這項工作中，我們介紹了 Pixelsmith，一個零次學習的文字轉圖片生成框架，可以在單一 GPU 上以更高的解析度取樣圖片。我們是第一個展示可以將預先訓練的擴散模型的輸出放大 1000 倍，為無額外成本的十億像素圖片生成開啟道路。我們的串聯方法使用在最低解析度生成的圖片作為基準，以更高的解析度取樣。對於引導，我們引入了 Slider，一種可調整的機制，它融合了第一個生成的圖片中包含的整體結構和增強的精細細節。在每個推論步驟中，我們會對區塊進行降噪，而不是對整個潛在空間進行降噪，這將記憶體需求降到最低，讓單一 GPU 可以處理這個過程，無論圖片的解析度為何。我們的實驗結果顯示，與現有技術相比，Pixelsmith 不僅達到了更高的品質和多樣性，還減少了取樣時間和人工製品。我們工作的程式碼可以在 https://github.com/Thanos-DB/Pixelsmith 取得。

##### **Are Protein Language Models Compute Optimal?**
2406.07249v1 by Yaiza Serrano, Álvaro Ciudad, Alexis Molina

While protein language models (pLMs) have transformed biological research,
the scaling laws governing their improvement remain underexplored. By adapting
methodologies from NLP scaling laws, we investigated the optimal ratio between
model parameters and training tokens within a fixed compute budget. Our study
reveals that pLM sizes scale sublinearly with compute budget, showing
diminishing returns in performance as model size increases, and we identify a
performance plateau in training loss comparable to the one found in relevant
works in the field. Our findings suggest that widely-used pLMs might not be
compute-optimal, indicating that larger models could achieve convergence more
efficiently. Training a 35M model on a reduced token set, we attained
perplexity results comparable to larger models like ESM-2 (15B) and xTrimoPGLM
(100B) with a single dataset pass. This work paves the way towards more
compute-efficient pLMs, democratizing their training and practical application
in computational biology.

摘要：儘管蛋白質語言模型 (pLM) 已轉變生物研究，
但支配其改進的規模法則仍未被充分探討。透過調整
自然語言處理規模法則的方法，我們探討了在固定運算預算內
模型參數與訓練代幣之間的最佳比例。我們的研究
顯示 pLM 規模與運算預算呈次線性擴展，顯示
模型規模增加時效能報酬遞減，且我們發現訓練損失中的
效能停滯期與該領域相關著作中發現的停滯期相當。我們的研究結果顯示，廣泛使用的 pLM 可能並非運算最佳化，表示較大型模型能更有效率地達成收斂。在縮減的代幣組上訓練 35M 模型，我們達到了與較大型模型（例如 ESM-2 (15B) 和 xTrimoPGLM (100B)）相當的困惑度結果，且僅需單一資料集傳遞。這項研究為更具運算效率的 pLM 鋪路，讓其訓練與在計算生物學中的實際應用更為普及。

##### **MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs**
2406.07243v1 by Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

Generative large language models (LLMs) have been shown to exhibit harmful
biases and stereotypes. While safety fine-tuning typically takes place in
English, if at all, these models are being used by speakers of many different
languages. There is existing evidence that the performance of these models is
inconsistent across languages and that they discriminate based on demographic
factors of the user. Motivated by this, we investigate whether the social
stereotypes exhibited by LLMs differ as a function of the language used to
prompt them, while controlling for cultural differences and task accuracy. To
this end, we present MBBQ (Multilingual Bias Benchmark for Question-answering),
a carefully curated version of the English BBQ dataset extended to Dutch,
Spanish, and Turkish, which measures stereotypes commonly held across these
languages. We further complement MBBQ with a parallel control dataset to
measure task performance on the question-answering task independently of bias.
Our results based on several open-source and proprietary LLMs confirm that some
non-English languages suffer from bias more than English, even when controlling
for cultural shifts. Moreover, we observe significant cross-lingual differences
in bias behaviour for all except the most accurate models. With the release of
MBBQ, we hope to encourage further research on bias in multilingual settings.
The dataset and code are available at https://github.com/Veranep/MBBQ.

摘要：生成式大型語言模型 (LLM) 已被證明會表現出有害的偏見和刻板印象。雖然安全性微調通常會在英語中進行（如果有的話），但這些模型正被許多不同語言的使用者使用。現有證據表明，這些模型的效能因語言而異，而且它們會根據使用者的個人資料因素進行區分。受此啟發，我們調查了 LLM 所表現出的社會刻板印象是否會因用於提示它們的語言而異，同時控制文化差異和任務準確性。為此，我們提出了 MBBQ（問題解答的多語言偏見基準），這是經過仔細策展的英文 BBQ 資料集，已延伸至荷蘭語、西班牙語和土耳其語，用於衡量這些語言中普遍存在的刻板印象。我們進一步補充了 MBBQ，並使用一個平行的控制資料集來衡量問題解答任務的任務效能，而不受偏見影響。我們根據幾個開源和專有 LLM 所得出的結果證實，即使控制了文化差異，某些非英語語言所遭受的偏見也比英語更嚴重。此外，我們觀察到，除了最準確的模型之外，所有模型在偏見行為方面都存在顯著的跨語言差異。隨著 MBQQ 的發布，我們希望鼓勵對多語言環境中的偏見進行進一步的研究。資料集和程式碼可在 https://github.com/Veranep/MBBQ 取得。

##### **DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms**
2406.07232v1 by Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang

Recently, large language models (LLMs) enhanced by self-reflection have
achieved promising performance on machine translation. The key idea is guiding
LLMs to generate translation with human-like feedback. However, existing
self-reflection methods lack effective feedback information, limiting the
translation performance. To address this, we introduce a DUAL-REFLECT
framework, leveraging the dual learning of translation tasks to provide
effective feedback, thereby enhancing the models' self-reflective abilities and
improving translation performance. The application of this method across
various translation tasks has proven its effectiveness in improving translation
accuracy and eliminating ambiguities, especially in translation tasks with
low-resource language pairs.

摘要：近期，由自我反省功能强化的巨量语言模型（LLM）已在机器翻译方面取得了可喜的成果。关键思想在于引导 LLM 根据类人反馈生成翻译。然而，现有的自我反省方法缺乏有效的反馈信息，限制了翻译性能。为了解决此问题，我们引入了 DUAL-REFLECT 框架，利用翻译任务的双重学习来提供有效的反馈，从而增强模型的自我反省能力并提高翻译性能。该方法在各种翻译任务中的应用已证明其在提高翻译准确性和消除歧义方面是有效的，尤其是在资源较少的语言对的翻译任务中。

##### **Decipherment-Aware Multilingual Learning in Jointly Trained Language Models**
2406.07231v1 by Grandee Lee

The principle that governs unsupervised multilingual learning (UCL) in
jointly trained language models (mBERT as a popular example) is still being
debated. Many find it surprising that one can achieve UCL with multiple
monolingual corpora. In this work, we anchor UCL in the context of language
decipherment and show that the joint training methodology is a decipherment
process pivotal for UCL. In a controlled setting, we investigate the effect of
different decipherment settings on the multilingual learning performance and
consolidate the existing opinions on the contributing factors to
multilinguality. From an information-theoretic perspective we draw a limit to
the UCL performance and demonstrate the importance of token alignment in
challenging decipherment settings caused by differences in the data domain,
language order and tokenization granularity. Lastly, we apply lexical alignment
to mBERT and investigate the contribution of aligning different lexicon groups
to downstream performance.

摘要：在聯合訓練的語言模型（例如 mBERT）中管理無監督多語言學習 (UCL) 的原則仍在爭論中。許多人驚訝地發現，人們可以用多個單語語料庫實現 UCL。在這項工作中，我們將 UCL 固定在語言破譯的背景中，並表明聯合訓練方法是 UCL 的關鍵破譯過程。在受控環境中，我們探討了不同的破譯設定對多語言學習效能的影響，並整合了現有意見，以了解多語言的促成因素。從資訊理論的角度來看，我們限制了 UCL 效能，並展示了在資料領域、語言順序和標記化粒度差異造成的具挑戰性破譯設定中，標記比對的重要性。最後，我們將詞彙比對應用於 mBERT，並探討了比對不同詞彙組對下游效能的貢獻。

##### **Improving Commonsense Bias Classification by Mitigating the Influence of Demographic Terms**
2406.07229v1 by JinKyu Lee, Jihie Kim

Understanding commonsense knowledge is crucial in the field of Natural
Language Processing (NLP). However, the presence of demographic terms in
commonsense knowledge poses a potential risk of compromising the performance of
NLP models. This study aims to investigate and propose methods for enhancing
the performance and effectiveness of a commonsense polarization classifier by
mitigating the influence of demographic terms. Three methods are introduced in
this paper: (1) hierarchical generalization of demographic terms (2)
threshold-based augmentation and (3) integration of hierarchical generalization
and threshold-based augmentation methods (IHTA). The first method involves
replacing demographic terms with more general ones based on a term hierarchy
ontology, aiming to mitigate the influence of specific terms. To address the
limited bias-related information, the second method measures the polarization
of demographic terms by comparing the changes in the model's predictions when
these terms are masked versus unmasked. This method augments commonsense
sentences containing terms with high polarization values by replacing their
predicates with synonyms generated by ChatGPT. The third method combines the
two approaches, starting with threshold-based augmentation followed by
hierarchical generalization. The experiments show that the first method
increases the accuracy over the baseline by 2.33%, and the second one by 0.96%
over standard augmentation methods. The IHTA techniques yielded an 8.82% and
9.96% higher accuracy than threshold-based and standard augmentation methods,
respectively.

摘要：<paragraph>在自然語言處理 (NLP) 領域中，理解常識知識至關重要。然而，常識知識中人口統計術語的存在可能會對 NLP 模型的效能造成損害。本研究旨在探討並提出方法，以透過減輕人口統計術語的影響來增強常識極化分類器的效能和有效性。本文介紹了三種方法：(1) 人口統計術語的階層概括 (2) 基於閾值的擴充，以及 (3) 階層概括與基於閾值的擴充方法 (IHTA) 的整合。第一種方法涉及根據術語階層本體，以更通用的術語取代人口統計術語，旨在減輕特定術語的影響。為了解決有限的偏見相關資訊，第二種方法透過比較在這些術語被遮蔽與未遮蔽時模型預測的變化，來衡量人口統計術語的極化。此方法透過將其謂詞替換為由 ChatGPT 生成的同義詞，來擴充包含極化值高的術語的常識句子。第三種方法結合了兩種方法，從基於閾值的擴充開始，接著進行階層概括。實驗顯示，第一種方法將準確度提升了 2.33%，而第二種方法則比標準擴充方法提升了 0.96%。IHTA 技術的準確度分別比基於閾值的擴充方法和標準擴充方法高出 8.82% 和 9.96%。</paragraph>

##### **Needle In A Multimodal Haystack**
2406.07230v1 by Weiyun Wang, Shuibo Zhang, Yiming Ren, Yuchen Duan, Tiantong Li, Shuo Liu, Mengkang Hu, Zhe Chen, Kaipeng Zhang, Lewei Lu, Xizhou Zhu, Ping Luo, Yu Qiao, Jifeng Dai, Wenqi Shao, Wenhai Wang

With the rapid advancement of multimodal large language models (MLLMs), their
evaluation has become increasingly comprehensive. However, understanding long
multimodal content, as a foundational ability for real-world applications,
remains underexplored. In this work, we present Needle In A Multimodal Haystack
(MM-NIAH), the first benchmark specifically designed to systematically evaluate
the capability of existing MLLMs to comprehend long multimodal documents. Our
benchmark includes three types of evaluation tasks: multimodal retrieval,
counting, and reasoning. In each task, the model is required to answer the
questions according to different key information scattered throughout the given
multimodal document. Evaluating the leading MLLMs on MM-NIAH, we observe that
existing models still have significant room for improvement on these tasks,
especially on vision-centric evaluation. We hope this work can provide a
platform for further research on long multimodal document comprehension and
contribute to the advancement of MLLMs. Code and benchmark are released at
https://github.com/OpenGVLab/MM-NIAH.

摘要：隨著多模態大型語言模型 (MLLM) 的快速進展，它們的評估變得越來越全面。然而，理解長多模態內容作為現實世界應用的一項基本能力，仍然未被充分探索。在這項工作中，我們提出了多模態乾草堆中的針頭 (MM-NIAH)，這是第一個專門設計用於系統評估現有 MLLM 理解長多模態文件的能力的基準。我們的基準包括三種類型的評估任務：多模態檢索、計數和推理。在每個任務中，模型都需要根據給定多模態文件中散布的不同關鍵信息來回答問題。在 MM-NIAH 上評估領先的 MLLM，我們觀察到現有模型在這些任務上仍有顯著的改進空間，特別是在以視覺為中心的評估上。我們希望這項工作可以為長多模態文件理解提供進一步研究的平台，並有助於 MLLM 的進步。代碼和基準發布於 https://github.com/OpenGVLab/MM-NIAH。

##### **Haptic Repurposing with GenAI**
2406.07228v1 by Haoyu Wang

Mixed Reality aims to merge the digital and physical worlds to create
immersive human-computer interactions. Despite notable advancements, the
absence of realistic haptic feedback often breaks the immersive experience by
creating a disconnect between visual and tactile perceptions. This paper
introduces Haptic Repurposing with GenAI, an innovative approach to enhance MR
interactions by transforming any physical objects into adaptive haptic
interfaces for AI-generated virtual assets. Utilizing state-of-the-art
generative AI models, this system captures both 2D and 3D features of physical
objects and, through user-directed prompts, generates corresponding virtual
objects that maintain the physical form of the original objects. Through
model-based object tracking, the system dynamically anchors virtual assets to
physical props in real time, allowing objects to visually morph into any
user-specified virtual object. This paper details the system's development,
presents findings from usability studies that validate its effectiveness, and
explores its potential to significantly enhance interactive MR environments.
The hope is this work can lay a foundation for further research into AI-driven
spatial transformation in immersive and haptic technologies.

摘要：混合現實旨在合併數位和實體世界，以創造身歷其境的使用者電腦互動。儘管有顯著的進展，但缺乏逼真的觸覺回饋往往會破壞身歷其境體驗，造成視覺和觸覺感知之間的脫節。本文介紹了具備 GenAI 的觸覺再利用，這是一種創新的方法，可透過將任何實體物件轉換成適應性觸覺介面，以增強 MR 互動，適用於 AI 生成的虛擬資產。利用最先進的生成式 AI 模型，此系統擷取實體物件的 2D 和 3D 特色，並透過使用者導向提示，產生對應的虛擬物件，以維持原始物件的實體形式。透過基於模型的物件追蹤，系統會動態地將虛擬資產錨定到實體道具中，讓物件能視覺化地轉變為任何使用者指定的虛擬物件。本文詳述了系統的開發，展示了可用性研究的結果，驗證了其有效性，並探討了其大幅增強互動式 MR 環境的潛力。希望這項工作能為進一步研究身歷其境和觸覺技術中的人工智慧驅動空間轉換奠定基礎。

##### **Improving Autoformalization using Type Checking**
2406.07222v1 by Auguste Poiroux, Gail Weiss, Viktor Kunčak, Antoine Bosselut

Large language models show promise for autoformalization, the task of
automatically translating natural language into formal languages. However,
current autoformalization methods remain limited. The last reported
state-of-the-art performance on the ProofNet formalization benchmark for the
Lean proof assistant, achieved using Codex for Lean 3, only showed successful
formalization of 16.1% of informal statements. Similarly, our evaluation of
GPT-4o for Lean 4 only produces successful translations 34.9% of the time. Our
analysis shows that the performance of these models is largely limited by their
inability to generate formal statements that successfully type-check (i.e., are
syntactically correct and consistent with types) - with a whopping 86.6% of
GPT-4o errors starting from a type-check failure. In this work, we propose a
method to fix this issue through decoding with type-check filtering, where we
initially sample a diverse set of candidate formalizations for an informal
statement, then use the Lean proof assistant to filter out candidates that do
not type-check. Using GPT-4o as a base model, and combining our method with
self-consistency, we obtain a +18.3% absolute increase in formalization
accuracy, and achieve a new state-of-the-art of 53.2% on ProofNet with Lean 4.

摘要：大型语言模型显示了自动形式化的前景，即自动将自然语言翻译成形式语言的任务。然而，当前的自动形式化方法仍然有限。在使用 Codex for Lean 3 针对 Lean 证明助手实现的 ProofNet 形式化基准上报告的最新性能，仅显示成功形式化了 16.1% 的非正式陈述。类似地，我们对 Lean 4 的 GPT-4o 的评估仅在 34.9% 的时间内产生了成功的翻译。我们的分析表明，这些模型的性能在很大程度上受到它们生成成功类型检查（即语法正确且与类型一致）的正式陈述的能力的限制——86.6% 的 GPT-4o 错误从类型检查失败开始。在这项工作中，我们提出了一种通过使用类型检查过滤进行解码来解决此问题的方法，其中我们最初为非正式陈述抽取一组不同的候选形式化，然后使用 Lean 证明助手来过滤掉未通过类型检查的候选项。使用 GPT-4o 作为基础模型，并将我们的方法与自洽性相结合，我们在形式化准确性上获得了 +18.3% 的绝对提升，并在 Lean 4 上的 ProofNet 上实现了 53.2% 的新技术水平。

##### **A Synthetic Dataset for Personal Attribute Inference**
2406.07217v1 by Hanna Yukhymenko, Robin Staab, Mark Vero, Martin Vechev

Recently, powerful Large Language Models (LLMs) have become easily accessible
to hundreds of millions of users worldwide. However, their strong capabilities
and vast world knowledge do not come without associated privacy risks. In this
work, we focus on the emerging privacy threat LLMs pose - the ability to
accurately infer personal information from online texts. Despite the growing
importance of LLM-based author profiling, research in this area has been
hampered by a lack of suitable public datasets, largely due to ethical and
privacy concerns associated with real personal data. In this work, we take two
steps to address this problem: (i) we construct a simulation framework for the
popular social media platform Reddit using LLM agents seeded with synthetic
personal profiles; (ii) using this framework, we generate SynthPAI, a diverse
synthetic dataset of over 7800 comments manually labeled for personal
attributes. We validate our dataset with a human study showing that humans
barely outperform random guessing on the task of distinguishing our synthetic
comments from real ones. Further, we verify that our dataset enables meaningful
personal attribute inference research by showing across 18 state-of-the-art
LLMs that our synthetic comments allow us to draw the same conclusions as
real-world data. Together, this indicates that our dataset and pipeline provide
a strong and privacy-preserving basis for future research toward understanding
and mitigating the inference-based privacy threats LLMs pose.

摘要：<paragraph>最近，功能强大的大型语言模型（LLM）已变得容易被全球数亿用户所使用。然而，它们强大的功能和广泛的世界知识并非没有相关的隐私风险。在这项工作中，我们关注 LLM 构成的日益严重的隐私威胁——从在线文本中准确推断个人信息的能力。尽管基于 LLM 的作者画像日益重要，但由于与真实个人数据相关的道德和隐私问题，该领域的研究一直受到缺乏合适的公共数据集的阻碍。在这项工作中，我们采取两步来解决这个问题：(i) 我们使用植入了合成个人资料的 LLM 代理构建了一个流行的社交媒体平台 Reddit 的模拟框架；(ii) 使用这个框架，我们生成了 SynthPAI，这是一个多样化的合成数据集，其中超过 7800 条评论被手动标记为个人属性。我们通过一项人类研究验证了我们的数据集，该研究表明，人类在区分我们的合成评论和真实评论的任务上几乎无法胜过随机猜测。此外，我们验证了我们的数据集能够进行有意义的个人属性推断研究，方法是在 18 个最先进的 LLM 中展示我们的合成评论使我们能够得出与现实世界数据相同的结论。总之，这表明我们的数据集和管道为未来的研究提供了强大且保护隐私的基础，以了解和减轻基于推理的 LLM 隐私威胁。</paragraph>

##### **Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models**
2406.07212v1 by Joshua Strong, Qianhui Men, Alison Noble

Large language models (LLMs) present a valuable technology for various
applications in healthcare, but their tendency to hallucinate introduces
unacceptable uncertainty in critical decision-making situations. Human-AI
collaboration (HAIC) can mitigate this uncertainty by combining human and AI
strengths for better outcomes. This paper presents a novel guided deferral
system that provides intelligent guidance when AI defers cases to human
decision-makers. We leverage LLMs' verbalisation capabilities and internal
states to create this system, demonstrating that fine-tuning smaller LLMs with
data from larger models enhances performance while maintaining computational
efficiency. A pilot study showcases the effectiveness of our deferral system.

摘要：大型語言模型（LLM）為醫療保健中的各種應用提供了有價值的技術，但它們出現幻覺的傾向在關鍵決策情況下帶來了不可接受的不確定性。人機協作（HAIC）可以通過結合人類和 AI 的優勢來減輕這種不確定性，從而獲得更好的結果。本文提出了一個新穎的指導性延遲系統，當 AI 將案例推遲給人類決策者時，它會提供智能指導。我們利用 LLM 的語言化能力和內部狀態來創建這個系統，證明使用來自更大模型的數據對較小的 LLM 進行微調可以提高性能，同時保持計算效率。一項試點研究展示了我們的延遲系統的有效性。

##### **Merging Improves Self-Critique Against Jailbreak Attacks**
2406.07188v1 by Victor Gallego

The robustness of large language models (LLMs) against adversarial
manipulations, such as jailbreak attacks, remains a significant challenge. In
this work, we propose an approach that enhances the self-critique capability of
the LLM and further fine-tunes it over sanitized synthetic data. This is done
with the addition of an external critic model that can be merged with the
original, thus bolstering self-critique capabilities and improving the
robustness of the LLMs response to adversarial prompts. Our results demonstrate
that the combination of merging and self-critique can reduce the attack success
rate of adversaries significantly, thus offering a promising defense mechanism
against jailbreak attacks. Code, data and models released at
https://github.com/vicgalle/merging-self-critique-jailbreaks .

摘要：大型語言模型 (LLM) 對抗敵對操縱（例如越獄攻擊）的穩健性仍然是一項重大挑戰。在這項工作中，我們提出了一種方法，它增強了 LLM 的自我批評能力，並進一步對其進行微調，以過濾合成的數據。這是通過添加一個外部批評模型來完成的，該模型可以與原始模型合併，從而增強自我批評能力並提高 LLM 對抗敵對提示的響應的穩健性。我們的結果表明，合併和自我批評的結合可以顯著降低對手的攻擊成功率，從而提供了一種有希望的防禦機制來對抗越獄攻擊。代碼、數據和模型已發布在 https://github.com/vicgalle/merging-self-critique-jailbreaks。

##### **Teaching Language Models to Self-Improve by Learning from Language Feedback**
2406.07168v1 by Chi Hu, Yimin Hu, Hang Cao, Tong Xiao, Jingbo Zhu

Aligning Large Language Models (LLMs) with human intentions and values is
crucial yet challenging. Current methods primarily rely on human preferences,
which are costly and insufficient in capturing nuanced feedback expressed in
natural language. In this paper, we present Self-Refinement Tuning (SRT), a
method that leverages model feedback for alignment, thereby reducing reliance
on human annotations. SRT uses a base language model (e.g., Tulu2) to generate
initial responses, which are critiqued and refined by a more advanced model
(e.g., GPT-4-Turbo). This process enables the base model to self-evaluate and
improve its outputs, facilitating continuous learning. SRT further optimizes
the model by learning from its self-generated feedback and refinements,
creating a feedback loop that promotes model improvement. Our empirical
evaluations demonstrate that SRT significantly outperforms strong baselines
across diverse tasks and model sizes. When applied to a 70B parameter model,
SRT increases the win rate from 9.6\% to 25.8\% on the AlpacaEval 2.0
benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2,
and Gemini. Our analysis highlights the crucial role of language feedback in
the success of SRT, suggesting potential for further exploration in this
direction.

摘要：調整大型語言模型 (LLM) 以符合人類意圖和價值觀至關重要且具有挑戰性。目前的技術主要依賴於人類偏好，而這在捕捉自然語言中表達的細微反饋方面既昂貴又不足夠。在本文中，我們提出了自我精進調整 (SRT)，這是一種利用模型反饋進行調整的方法，從而減少對人工註解的依賴。SRT 使用基礎語言模型（例如 Tulu2）生成初始回應，這些回應會受到更先進的模型（例如 GPT-4-Turbo）的批評和改進。此過程使基礎模型能夠自我評估和改進其輸出，促進持續學習。SRT 進一步通過從其自我生成的回饋和改進中學習來優化模型，從而建立一個促進模型改進的反饋迴路。我們的經驗評估表明，SRT 在不同的任務和模型規模上都明顯優於強大的基準。當應用於 70B 參數模型時，SRT 將 AlpacaEval 2.0 基準上的獲勝率從 9.6% 提高到 25.8%，超越了 GPT-4-0314、Claude 2 和 Gemini 等完善的系統。我們的分析強調了語言反饋在 SRT 成功中的關鍵作用，表明了進一步探索此方向的潛力。

##### **EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark**
2406.07162v1 by Ziyang Ma, Mingjie Chen, Hezhao Zhang, Zhisheng Zheng, Wenxi Chen, Xiquan Li, Jiaxin Ye, Xie Chen, Thomas Hain

Speech emotion recognition (SER) is an important part of human-computer
interaction, receiving extensive attention from both industry and academia.
However, the current research field of SER has long suffered from the following
problems: 1) There are few reasonable and universal splits of the datasets,
making comparing different models and methods difficult. 2) No commonly used
benchmark covers numerous corpus and languages for researchers to refer to,
making reproduction a burden. In this paper, we propose EmoBox, an
out-of-the-box multilingual multi-corpus speech emotion recognition toolkit,
along with a benchmark for both intra-corpus and cross-corpus settings. For
intra-corpus settings, we carefully designed the data partitioning for
different datasets. For cross-corpus settings, we employ a foundation SER
model, emotion2vec, to mitigate annotation errors and obtain a test set that is
fully balanced in speakers and emotions distributions. Based on EmoBox, we
present the intra-corpus SER results of 10 pre-trained speech models on 32
emotion datasets with 14 languages, and the cross-corpus SER results on 4
datasets with the fully balanced test sets. To the best of our knowledge, this
is the largest SER benchmark, across language scopes and quantity scales. We
hope that our toolkit and benchmark can facilitate the research of SER in the
community.

摘要：語音情緒辨識（SER）是人機互動中重要的一環，受到產業界與學術界的廣泛關注。然而，SER 的現有研究領域長期以來一直飽受以下問題所苦：1）資料集的合理且通用的切分很少，導致難以比較不同的模型與方法。2）沒有廣泛使用的基準涵蓋多種語料庫和語言供研究人員參考，使得重現成為一種負擔。在本文中，我們提出 EmoBox，這是一個開箱即用的多語言多語料庫語音情緒辨識工具組，並提供一個適用於語料庫內和語料庫間設定的基準。對於語料庫內設定，我們仔細設計了不同資料集的資料分割。對於語料庫間設定，我們採用基礎 SER 模型 emotion2vec 來減輕註解錯誤，並取得在說話者和情緒分佈上完全平衡的測試集。基於 EmoBox，我們呈現 10 個預訓練語音模型在 32 個情緒資料集（涵蓋 14 種語言）上的語料庫內 SER 結果，以及在 4 個具有完全平衡測試集的資料集上的語料庫間 SER 結果。據我們所知，這是最大的 SER 基準，涵蓋語言範圍和數量規模。我們希望我們的工具組和基準能促進社群中 SER 的研究。

##### **Scaling Large-Language-Model-based Multi-Agent Collaboration**
2406.07155v1 by Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun

Pioneering advancements in large language model-powered agents have
underscored the design pattern of multi-agent collaboration, demonstrating that
collective intelligence can surpass the capabilities of each individual.
Inspired by the neural scaling law, which posits that increasing neurons leads
to emergent abilities, this study investigates whether a similar principle
applies to increasing agents in multi-agent collaboration. Technically, we
propose multi-agent collaboration networks (MacNet), which utilize directed
acyclic graphs to organize agents and streamline their interactive reasoning
via topological ordering, with solutions derived from their dialogues.
Extensive experiments show that MacNet consistently outperforms baseline
models, enabling effective agent collaboration across various network
topologies and supporting cooperation among more than a thousand agents.
Notably, we observed a small-world collaboration phenomenon, where topologies
resembling small-world properties achieved superior performance. Additionally,
we identified a collaborative scaling law, indicating that normalized solution
quality follows a logistic growth pattern as scaling agents, with collaborative
emergence occurring much earlier than previously observed instances of neural
emergence. The code and data will be available at
https://github.com/OpenBMB/ChatDev.

摘要：<paragraph>大型语言模型驱动的代理的开创性进步强调了多代理协作的设计模式，证明了集体智能可以超越每个个体的能力。受神经网络扩展定律的启发，该定律认为增加神经元会导致能力的涌现，本研究调查了类似的原理是否适用于增加多代理协作中的代理。在技术上，我们提出了多代理协作网络（MacNet），它利用有向无环图来组织代理并通过拓扑排序简化它们的交互推理，解决方案来自它们的对话。广泛的实验表明，MacNet 始终优于基线模型，能够在各种网络拓扑中实现有效的代理协作，并支持一千多个代理之间的合作。值得注意的是，我们观察到了一种小世界协作现象，其中类似于小世界属性的拓扑结构取得了卓越的性能。此外，我们确定了一个协作扩展定律，表明归一化解决方案质量遵循逻辑增长模式作为扩展代理，协作涌现比先前观察到的神经涌现实例发生得更早。代码和数据将可在 https://github.com/OpenBMB/ChatDev 获得。</paragraph>

##### **EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels**
2406.07151v1 by Shuqi Zhu, Ziyi Ye, Qingyao Ai, Yiqun Liu

Identifying and reconstructing what we see from brain activity gives us a
special insight into investigating how the biological visual system represents
the world. While recent efforts have achieved high-performance image
classification and high-quality image reconstruction from brain signals
collected by Functional Magnetic Resonance Imaging (fMRI) or
magnetoencephalogram (MEG), the expensiveness and bulkiness of these devices
make relevant applications difficult to generalize to practical applications.
On the other hand, Electroencephalography (EEG), despite its advantages of ease
of use, cost-efficiency, high temporal resolution, and non-invasive nature, has
not been fully explored in relevant studies due to the lack of comprehensive
datasets. To address this gap, we introduce EEG-ImageNet, a novel EEG dataset
comprising recordings from 16 subjects exposed to 4000 images selected from the
ImageNet dataset. EEG-ImageNet consists of 5 times EEG-image pairs larger than
existing similar EEG benchmarks. EEG-ImageNet is collected with image stimuli
of multi-granularity labels, i.e., 40 images with coarse-grained labels and 40
with fine-grained labels. Based on it, we establish benchmarks for object
classification and image reconstruction. Experiments with several commonly used
models show that the best models can achieve object classification with
accuracy around 60% and image reconstruction with two-way identification around
64%. These results demonstrate the dataset's potential to advance EEG-based
visual brain-computer interfaces, understand the visual perception of
biological systems, and provide potential applications in improving machine
visual models.

摘要：<paragraph>透過辨識和重建我們從腦部活動所看到的，讓我們得以特別深入探究生物視覺系統如何呈現世界。雖然近期努力已從功能性磁振造影 (fMRI) 或腦磁圖 (MEG) 收集的腦部訊號中，達成高性能影像分類和高品質影像重建，但這些裝置的昂貴和笨重，使得相關應用難以推廣到實際應用。另一方面，腦波圖 (EEG) 雖然具有使用容易、成本效益高、時間解析度高和非侵入性等優點，但由於缺乏全面的資料集，尚未在相關研究中得到充分探討。為了解決這個差距，我們引入了 EEG-ImageNet，這是一個新穎的 EEG 資料集，包含來自 16 位受試者觀看從 ImageNet 資料集中挑選的 4000 張影像的記錄。EEG-ImageNet 包含比現有類似 EEG 基準大 5 倍的 EEG 影像對。EEG-ImageNet 是使用具有多粒度標籤的影像刺激收集的，即 40 張具有粗粒度標籤的影像和 40 張具有細粒度標籤的影像。基於此，我們建立了物件分類和影像重建的基準。使用幾個常用模型的實驗顯示，最佳模型可以在物件分類中達到約 60% 的準確度，在雙向辨識中達到約 64% 的影像重建。這些結果證明了該資料集在推動基於 EEG 的視覺腦電腦介面、了解生物系統的視覺感知，以及提供改善機器視覺模型的潛在應用方面的潛力。</paragraph>

##### **Wearable Device-Based Physiological Signal Monitoring: An Assessment Study of Cognitive Load Across Tasks**
2406.07147v1 by Ling He, Yanxin Chen, Wenqi Wang, Shuting He, Xiaoqiang Hu

This study employs cutting-edge wearable monitoring technology to conduct
high-precision, high-temporal-resolution cognitive load assessment on EEG data
from the FP1 channel and heart rate variability (HRV) data of secondary
vocational students(SVS). By jointly analyzing these two critical physiological
indicators, the research delves into their application value in assessing
cognitive load among SVS students and their utility across various tasks. The
study designed two experiments to validate the efficacy of the proposed
approach: Initially, a random forest classification model, developed using the
N-BACK task, enabled the precise decoding of physiological signal
characteristics in SVS students under different levels of cognitive load,
achieving a classification accuracy of 97%. Subsequently, this classification
model was applied in a cross-task experiment involving the National Computer
Rank Examination, demonstrating the method's significant applicability and
cross-task transferability in diverse learning contexts. Conducted with high
portability, this research holds substantial theoretical and practical
significance for optimizing teaching resource allocation in secondary
vocational education, as well as for cognitive load assessment methods and
monitoring. Currently, the research findings are undergoing trial
implementation in the school.

摘要：本研究採用前沿可穿戴式監測技術，對職業高中學生（SVS）的 EEG 資料中的 FP1 通道和心率變異性（HRV）資料進行高精度、高時間解析度的認知負荷評估。通過聯合分析這兩個關鍵生理指標，研究探討了它們在評估 SVS 學生認知負荷中的應用價值和它們在各種任務中的效用。本研究設計了兩個實驗來驗證所提出方法的有效性：最初，使用 N-BACK 任務開發的隨機森林分類模型，能夠精確解碼不同認知負荷水平下 SVS 學生生理信號的特徵，分類準確率達到 97%。隨後，將此分類模型應用於涉及全國電腦能力分級考試的跨任務實驗中，證明了該方法在不同學習情境中的顯著適用性和跨任務可轉移性。本研究具有很高的可移植性，對優化職業高中教育中的教學資源配置以及認知負荷評估方法和監控具有重要的理論和實踐意義。目前，研究成果正在學校中進行試驗實施。

##### **Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**
2406.07146v1 by Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

Automatic radiology report generation can significantly benefit the
labor-intensive process of report writing by radiologists, especially for 3D
radiographs like CT scans, which are crucial for broad clinical diagnostics yet
underexplored compared to 2D radiographs. Existing methods often handle 3D
volumes either slice-wise or with aggressive downsampling due to current GPU
memory limitations, which results in a loss of the inherent 3D nature and
critical details. To overcome these issues, we introduce a novel framework that
efficiently and effectively generates radiology reports for high-resolution
(HR) 3D volumes, based on large language models (LLMs). Specifically, our
framework utilizes low-resolution (LR) visual tokens as queries to mine
information from HR tokens, preserving detailed HR information while reducing
computational costs by only processing HR informed LR visual queries. Further
benefiting the field, we curate and release BIMCV-RG, a new dataset with 5,328
HR 3D volumes and paired reports, establishing the first benchmarks for report
generation from 3D HR medical images. Our method consistently surpasses
existing methods on this benchmark across three different settings:
normal-resolution, high-resolution inputs, and zero-shot domain transfer, all
at an acceptable computational cost, trainable on a single A100-80G.

摘要：自動放射線報告生成可以大幅提升放射科醫師撰寫報告的勞力密集流程，特別是 3D 射線照片（例如電腦斷層掃描），這對於廣泛的臨床診斷至關重要，但與 2D 射線照片相比，卻鮮少被探討。現有的方法通常以切片方式處理 3D 影像，或因為當前 GPU 記憶體限制而進行大幅降採樣，這會導致固有的 3D 特性與重要細節遺失。為了克服這些問題，我們引入了一個創新的架構，它能有效率且有效地為高解析度 (HR) 3D 影像產生放射線報告，其基礎是大語言模型 (LLM)。具體來說，我們的架構利用低解析度 (LR) 視覺符號作為查詢，從 HR 符號中挖掘資訊，同時保留詳細的 HR 資訊，並透過僅處理 HR 告知的 LR 視覺查詢來降低運算成本。為了進一步造福這個領域，我們策劃並發布了 BIMCV-RG，這個新資料集包含 5,328 個 HR 3D 影像和配對報告，建立了從 3D HR 醫學影像產生報告的第一個基準。我們的模型在三個不同的設定中，始終優於現有的模型：正常解析度、高解析度輸入和零次學習領域轉移，所有設定的運算成本都在可接受的範圍內，且可以在單個 A100-80G 上訓練。

##### **Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models with Consistent "Middle" Enhancement**
2406.07138v1 by Tong Wu, Yanpeng Zhao, Zilong Zheng

Recently, many methods have been developed to extend the context length of
pre-trained large language models (LLMs), but they often require fine-tuning at
the target length ($\gg4K$) and struggle to effectively utilize information
from the middle part of the context. To address these issues, we propose
$\textbf{C}$ontinuity-$\textbf{R}$elativity ind$\textbf{E}$xing with
g$\textbf{A}$ussian $\textbf{M}$iddle (CREAM), which interpolates positional
encodings by manipulating position indices. Apart from being simple, CREAM is
training-efficient: it only requires fine-tuning at the pre-trained context
window (eg, Llama 2-4K) and can extend LLMs to a much longer target context
length (eg, 256K). To ensure that the model focuses more on the information in
the middle, we introduce a truncated Gaussian to encourage sampling from the
middle part of the context during fine-tuning, thus alleviating the
``Lost-in-the-Middle'' problem faced by long-context LLMs. Experimental results
show that CREAM successfully extends LLMs to the target length for both Base
and Chat versions of $\texttt{Llama2-7B}$ with ``Never Miss A Beat''. Our code
will be publicly available soon.

摘要：最近，已經開發出許多方法來延伸預先訓練大型語言模型 (LLM) 的前後文長度，但它們通常需要在目標長度（$\gg4K$）進行微調，並且難以有效利用前後文中間部分的資訊。為了解決這些問題，我們提出了 $\textbf{C}$ontinuous-$\textbf{R}$elativity ind$\textbf{E}$xing with g$\textbf{A}$ussian $\textbf{M}$iddle (CREAM)，它透過調整位置索引來內插位置編碼。除了簡單之外，CREAM 的訓練效率也很高：它只需要在預先訓練的上下文視窗（例如，Llama 2-4K）進行微調，就能將 LLM 延伸到更長的目標上下文長度（例如，256K）。為了確保模型更專注於中間的資訊，我們引入了截斷的高斯函數，以鼓勵在微調期間從前後文的中間部分進行抽樣，從而減輕長上下文 LLM 面臨的「遺失在中間」問題。實驗結果表明，CREAM 成功地將 LLM 延伸到目標長度，適用於 $\texttt{Llama2-7B}$ 的基本版和聊天版，並具備「絕不遺漏節奏」的功能。我們的程式碼將很快公開。

##### **Translating speech with just images**
2406.07133v1 by Dan Oneata, Herman Kamper

Visually grounded speech models link speech to images. We extend this
connection by linking images to text via an existing image captioning system,
and as a result gain the ability to map speech audio directly to text. This
approach can be used for speech translation with just images by having the
audio in a different language from the generated captions. We investigate such
a system on a real low-resource language, Yor\`ub\'a, and propose a
Yor\`ub\'a-to-English speech translation model that leverages pretrained
components in order to be able to learn in the low-resource regime. To limit
overfitting, we find that it is essential to use a decoding scheme that
produces diverse image captions for training. Results show that the predicted
translations capture the main semantics of the spoken audio, albeit in a
simpler and shorter form.

摘要：視覺化基礎語音模型將語音連結到圖像。我們透過現有的圖像標題系統將圖像連結到文字，進而擴展這個連結，結果獲得將語音音訊直接對應到文字的能力。這個方法可以只用圖像進行語音翻譯，讓音訊與產生的標題使用不同的語言。我們在一個真正的低資源語言，Yor\`ub\'a，調查這種系統，並提出一個 Yor\`ub\'a-to-English 語音翻譯模型，它利用預先訓練的元件，以便能夠在低資源模式中學習。為了限制過度擬合，我們發現使用產生多樣化圖像標題用於訓練的解碼方案至關重要。結果顯示，預測的翻譯掌握了所說音訊的主要語意，儘管形式更簡單且更簡短。

##### **Mining Frequent Structures in Conceptual Models**
2406.07129v1 by Mattia Fumagalli, Tiago Prince Sales, Pedro Paulo F. Barcelos, Giovanni Micale, Vadim Zaytsev, Diego Calvanese, Giancarlo Guizzardi

The problem of using structured methods to represent knowledge is well-known
in conceptual modeling and has been studied for many years. It has been proven
that adopting modeling patterns represents an effective structural method.
Patterns are, indeed, generalizable recurrent structures that can be exploited
as solutions to design problems. They aid in understanding and improving the
process of creating models. The undeniable value of using patterns in
conceptual modeling was demonstrated in several experimental studies. However,
discovering patterns in conceptual models is widely recognized as a highly
complex task and a systematic solution to pattern identification is currently
lacking. In this paper, we propose a general approach to the problem of
discovering frequent structures, as they occur in conceptual modeling
languages. As proof of concept for our scientific contribution, we provide an
implementation of the approach, by focusing on UML class diagrams, in
particular OntoUML models. This implementation comprises an exploratory tool,
which, through the combination of a frequent subgraph mining algorithm and
graph manipulation techniques, can process multiple conceptual models and
discover recurrent structures according to multiple criteria. The primary
objective is to offer a support facility for language engineers. This can be
employed to leverage both good and bad modeling practices, to evolve and
maintain the conceptual modeling language, and to promote the reuse of encoded
experience in designing better models with the given language.

摘要：結構化方法用於表示知識的問題在概念建模中是眾所周知的，並且已經研究多年。已經證明採用建模模式代表一種有效的結構化方法。模式確實是可概括的遞迴結構，可以作為設計問題的解決方案加以利用。它們有助於理解和改進建立模型的過程。在多項實驗研究中證明了在概念建模中使用模式的不可否認價值。然而，發現概念模型中的模式被廣泛認為是一項高度複雜的任務，而且目前缺乏模式識別的系統性解決方案。在本文中，我們提出了一種發現頻繁結構問題的一般方法，因為它們出現在概念建模語言中。作為我們科學貢獻的概念驗證，我們提供了一種方法的實現，重點關注 UML 類別圖，特別是 OntoUML 模型。此實現包含一個探索工具，該工具通過結合頻繁子圖挖掘演算法和圖形處理技術，可以處理多個概念模型，並根據多個標準發現遞迴結構。主要目標是為語言工程師提供支援工具。這可以用來利用好的和壞的建模實務，來演進和維護概念建模語言，並促進在設計更好的模型時對編碼經驗的再利用。

##### **Logical Distillation of Graph Neural Networks**
2406.07126v1 by Alexander Pluska, Pascal Welke, Thomas Gärtner, Sagar Malhotra

We present a logic based interpretable model for learning on graphs and an
algorithm to distill this model from a Graph Neural Network (GNN). Recent
results have shown connections between the expressivity of GNNs and the
two-variable fragment of first-order logic with counting quantifiers (C2). We
introduce a decision-tree based model which leverages an extension of C2 to
distill interpretable logical classifiers from GNNs. We test our approach on
multiple GNN architectures. The distilled models are interpretable, succinct,
and attain similar accuracy to the underlying GNN. Furthermore, when the ground
truth is expressible in C2, our approach outperforms the GNN.

摘要：我們提出了基於邏輯的可解讀模型，用於圖形學習，以及從圖形神經網路 (GNN) 中提取此模型的演算法。最近的結果顯示，GNN 的表達力與帶有計數量詞 (C2) 的一階邏輯的二變數片段之間存在關聯。我們引入了一個基於決策樹的模型，利用 C2 的擴充從 GNN 中提取可解讀的邏輯分類器。我們在多個 GNN 架構上測試了我們的做法。提取的模型可解讀、簡潔，且可獲得與底層 GNN 相似的準確度。此外，當 ground truth 可用 C2 表達時，我們的做法優於 GNN。

##### **CARACAS: vehiCular ArchitectuRe for detAiled Can Attacks Simulation**
2406.07125v1 by Sadek Misto Kirdi, Nicola Scarano, Franco Oberti, Luca Mannella, Stefano Di Carlo, Alessandro Savino

Modern vehicles are increasingly vulnerable to attacks that exploit network
infrastructures, particularly the Controller Area Network (CAN) networks. To
effectively counter such threats using contemporary tools like Intrusion
Detection Systems (IDSs) based on data analysis and classification, large
datasets of CAN messages become imperative. This paper delves into the
feasibility of generating synthetic datasets by harnessing the modeling
capabilities of simulation frameworks such as Simulink coupled with a robust
representation of attack models to present CARACAS, a vehicular model,
including component control via CAN messages and attack injection capabilities.
CARACAS showcases the efficacy of this methodology, including a Battery
Electric Vehicle (BEV) model, and focuses on attacks targeting torque control
in two distinct scenarios.

摘要：現代車輛越來越容易受到攻擊，這些攻擊會利用網路基礎設施，特別是控制器區域網路 (CAN) 網路。為了有效地使用當代工具，例如基於資料分析和分類的入侵偵測系統 (IDS) 來對抗此類威脅，大量的 CAN 訊息資料集變得勢在必行。本文探討了利用 Simulink 等模擬架構的建模能力，結合攻擊模型的強大表示，來產生合成資料集的可行性，以展示 CARACAS，一種車輛模型，包括透過 CAN 訊息進行元件控制和攻擊注入能力。CARACAS 展示了此方法的效能，包括電池電動車 (BEV) 模型，並專注於在兩種不同情況下針對扭力控制的攻擊。

##### **CHARME: A chain-based reinforcement learning approach for the minor embedding problem**
2406.07124v1 by Hoang M. Ngo, Nguyen H K. Do, Minh N. Vu, Tamer Kahveci, My T. Thai

Quantum Annealing (QA) holds great potential for solving combinatorial
optimization problems efficiently. However, the effectiveness of QA algorithms
heavily relies on the embedding of problem instances, represented as logical
graphs, into the quantum unit processing (QPU) whose topology is in form of a
limited connectivity graph, known as the minor embedding Problem. Existing
methods for the minor embedding problem suffer from scalability issues when
confronted with larger problem sizes. In this paper, we propose a novel
approach utilizing Reinforcement Learning (RL) techniques to address the minor
embedding problem, named CHARME. CHARME includes three key components: a Graph
Neural Network (GNN) architecture for policy modeling, a state transition
algorithm ensuring solution validity, and an order exploration strategy for
effective training. Through comprehensive experiments on synthetic and
real-world instances, we demonstrate that the efficiency of our proposed order
exploration strategy as well as our proposed RL framework, CHARME. In details,
CHARME yields superior solutions compared to fast embedding methods such as
Minorminer and ATOM. Moreover, our method surpasses the OCT-based approach,
known for its slower runtime but high-quality solutions, in several cases. In
addition, our proposed exploration enhances the efficiency of the training of
the CHARME framework by providing better solutions compared to the greedy
strategy.

摘要：量子退火 (QA) 在有效解决组合优化问题方面具有巨大潜力。然而，QA 算法的有效性在很大程度上依赖于问题实例的嵌入，表示为逻辑图，到量子单元处理 (QPU) 中，其拓扑结构以有限连通图的形式存在，称为次要嵌入问题。现有的次要嵌入问题方法在面对较大问题规模时会遇到可扩展性问题。在本文中，我们提出了一种利用强化学习 (RL) 技术来解决次要嵌入问题的新方法，名为 CHARME。CHARME 包括三个关键组件：用于策略建模的图神经网络 (GNN) 架构、确保解决方案有效性的状态转换算法以及用于有效训练的顺序探索策略。通过对合成和真实世界实例的综合实验，我们证明了我们提出的顺序探索策略以及我们提出的 RL 框架 CHARME 的效率。详细来说，与 Minorminer 和 ATOM 等快速嵌入方法相比，CHARME 得出了更好的解决方案。此外，在某些情况下，我们的方法超越了基于 OCT 的方法，后者以运行时间慢但解决方案质量高而闻名。此外，我们提出的探索通过提供比贪婪策略更好的解决方案来提高 CHARME 框架训练的效率。

##### **T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text**
2406.07119v1 by Aoxiong Yin, Haoyuan Li, Kai Shen, Siliang Tang, Yueting Zhuang

In this work, we propose a two-stage sign language production (SLP) paradigm
that first encodes sign language sequences into discrete codes and then
autoregressively generates sign language from text based on the learned
codebook. However, existing vector quantization (VQ) methods are fixed-length
encodings, overlooking the uneven information density in sign language, which
leads to under-encoding of important regions and over-encoding of unimportant
regions. To address this issue, we propose a novel dynamic vector quantization
(DVA-VAE) model that can dynamically adjust the encoding length based on the
information density in sign language to achieve accurate and compact encoding.
Then, a GPT-like model learns to generate code sequences and their
corresponding durations from spoken language text. Extensive experiments
conducted on the PHOENIX14T dataset demonstrate the effectiveness of our
proposed method. To promote sign language research, we propose a new large
German sign language dataset, PHOENIX-News, which contains 486 hours of sign
language videos, audio, and transcription texts.Experimental analysis on
PHOENIX-News shows that the performance of our model can be further improved by
increasing the size of the training data. Our project homepage is
https://t2sgpt-demo.yinaoxiong.cn.

摘要：<paragraph>在這項工作中，我們提出一個兩階段手語產生 (SLP) 典範，首先將手語序列編碼成離散代碼，然後根據學習到的代碼簿自動回歸地從文字產生手語。但是，現有的向量量化 (VQ) 方法是定長編碼，忽略了手語中不均勻的資訊密度，導致重要區域編碼不足，而對不重要區域編碼過多。為了解決這個問題，我們提出一個新穎的動態向量量化 (DVA-VAE) 模型，它可以根據手語中的資訊密度動態調整編碼長度，以實現準確且緊湊的編碼。然後，一個類似 GPT 的模型學習從口語文本產生代碼序列及其對應的持續時間。在 PHOENIX14T 資料集上進行的廣泛實驗證明了我們提出的方法的有效性。為了促進手語研究，我們提出了一個新的大型德語手語資料集 PHOENIX-News，其中包含 486 小時的手語影片、音訊和轉錄文字。在 PHOENIX-News 上的實驗分析表明，透過增加訓練資料的大小，我們模型的效能可以進一步提升。我們的專案首頁是 https://t2sgpt-demo.yinaoxiong.cn。</paragraph>

##### **Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees**
2406.07115v1 by Sijia Chen, Yibo Wang, Yi-Feng Wu, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Lijun Zhang

Tool-augmented large language models (LLMs) leverage tools, often in the form
of APIs, to enhance their reasoning capabilities on complex tasks, thus taking
on the role of intelligent agents interacting with the real world. The recently
introduced ToolLLaMA model by Qin et al. [2024] utilizes the depth-first
search-based decision tree (DFSDT) method for reasoning with $16000+$
real-world APIs, which effectively improves the planning and inferencing
performance of tool-augmented LLMs compared to traditional chain reasoning
approaches. However, their approach only employs successful paths from decision
trees (also called inference trees) for supervised fine-tuning (SFT) during
training, which does not fully exploit the advantages of the tree of thought.
In this study, we propose an inference trajectory optimization framework based
on the preference data extracted from decision trees to address this
limitation. We first introduce a novel method for constructing preference data
from the tree of thought, capitalizing on the failed explorations previously
overlooked in the trees. Specifically, we generate an effective step-wise
preference dataset, named ToolPreference, for tool use based on the ToolBench
dataset. In the subsequent training phase, we first fine-tune the LLM with
tool-usage expert trajectories and then use these step-wise preference pairs
for direct preference optimization (DPO) to update the policy of the LLM,
resulting in our ToolPrefer-LLaMA (TP-LLaMA) model. Our experiments demonstrate
that by obtaining insights from errors in inference trees, TP-LLaMA
significantly outperforms the baselines across almost all test scenarios by a
large margin and exhibits better generalization capabilities with unseen APIs.
At the same time, TP-LLaMA has also demonstrated superior reasoning efficiency
compared to the baselines, making it more suitable for complex tool-usage
reasoning tasks.

摘要：<paragraph>具工具增強的大型語言模型 (LLM) 透過工具（通常以 API 形式呈現）來提升其在複雜任務上的推理能力，進而扮演與真實世界互動的智慧型代理的角色。Qin 等人 [2024] 最近提出的 ToolLLaMA 模型利用深度優先搜尋為基礎的決策樹 (DFSDT) 方法，以超過 16000 個真實世界 API 進行推理，與傳統的鏈式推理方法相比，有效提升具工具增強的 LLM 在規劃和推論上的表現。然而，他們的做法僅採用決策樹（也稱為推論樹）中的成功路徑，在訓練期間進行監督微調 (SFT)，並未完全發揮思想樹的優勢。在本研究中，我們提出一個基於從決策樹中萃取的偏好資料的推論軌跡最佳化架構，以解決此限制。我們首先提出一個從思想樹建構偏好資料的新方法，利用先前在樹中被忽略的失敗探索。具體來說，我們根據 ToolBench 資料集產生一個有效的逐步偏好資料集，稱為 ToolPreference，以供工具使用。在後續的訓練階段，我們首先使用工具使用專家軌跡微調 LLM，然後使用這些逐步偏好對進行直接偏好最佳化 (DPO) 來更新 LLM 的政策，產生我們的 ToolPrefer-LLaMA (TP-LLaMA) 模型。我們的實驗證明，藉由從推論樹中的錯誤中獲得見解，TP-LLaMA 在幾乎所有測試情境中都大幅超越基準，並展現出對未見 API 更佳的泛化能力。同時，與基準相比，TP-LLaMA 也展現出優異的推理效率，使其更適合於複雜的工具使用推理任務。</paragraph>

##### **Beyond Bare Queries: Open-Vocabulary Object Retrieval with 3D Scene Graph**
2406.07113v1 by Sergey Linok, Tatiana Zemskova, Svetlana Ladanova, Roman Titkov, Dmitry Yudin

Locating objects referred to in natural language poses a significant
challenge for autonomous agents. Existing CLIP-based open-vocabulary methods
successfully perform 3D object retrieval with simple (bare) queries but cannot
cope with ambiguous descriptions that demand an understanding of object
relations. To tackle this problem, we propose a modular approach called BBQ
(Beyond Bare Queries), which constructs 3D scene spatial graph representation
with metric edges and utilizes a large language model as a human-to-agent
interface through our deductive scene reasoning algorithm. BBQ employs robust
DINO-powered associations to form 3D objects, an advanced raycasting algorithm
to project them to 2D, and a vision-language model to describe them as graph
nodes. On Replica and ScanNet datasets, we show that the designed method
accurately constructs 3D object-centric maps. We have demonstrated that their
quality takes a leading place for open-vocabulary 3D semantic segmentation
against other zero-shot methods. Also, we show that leveraging spatial
relations is especially effective for scenes containing multiple entities of
the same semantic class. On Sr3D and Nr3D benchmarks, our deductive approach
demonstrates a significant improvement, enabling retrieving objects by complex
queries compared to other state-of-the-art methods. Considering our design
solutions, we achieved a processing speed approximately x3 times faster than
the closest analog. This promising performance enables our approach for usage
in applied intelligent robotics projects. We make the code publicly available
at linukc.github.io/bbq/.

摘要：<paragraph>在自然語言中，定位被引用的物件對自主代理人來說是一項重大的挑戰。現有的基於 CLIP 的開放式詞彙方法可以成功執行 3D 物件擷取，使用簡潔（單純）的查詢，但無法應對需要理解物件關係的含糊描述。為了解決這個問題，我們提出了一種名為 BBQ（超越單純查詢）的模組化方法，它使用度量邊緣構建 3D 場景空間圖形表示，並透過我們的演繹場景推理演算法，將大型語言模型用作人與代理人之間的介面。BBQ 使用強大的 DINO 驅動關聯來形成 3D 物件，一種先進的光線投射演算法將它們投射到 2D，以及一個視覺語言模型將它們描述為圖形節點。在 Replica 和 ScanNet 資料集上，我們展示了設計的方法可以準確地建構 3D 物件為中心的對應。我們已經證明，它們的品質在針對其他零次學習方法的開放式詞彙 3D 語意分割中處於領先地位。此外，我們展示了利用空間關係對於包含多個相同語意類別實體的場景特別有效。在 Sr3D 和 Nr3D 基準測試中，我們的演繹方法展示了顯著的進步，與其他最先進的方法相比，能夠透過複雜的查詢來擷取物件。考慮到我們的設計解決方案，我們實現的處理速度比最接近的類比快了約 3 倍。這種有前途的效能使我們的做法能夠用於應用智慧機器人專案。我們在 linukc.github.io/bbq/ 上公開程式碼。</paragraph>

##### **Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter**
2406.07096v1 by Andrei Andrusenko, Aleksandr Laptev, Vladimir Bataev, Vitaly Lavrukhin, Boris Ginsburg

Accurate recognition of rare and new words remains a pressing problem for
contextualized Automatic Speech Recognition (ASR) systems. Most context-biasing
methods involve modification of the ASR model or the beam-search decoding
algorithm, complicating model reuse and slowing down inference. This work
presents a new approach to fast context-biasing with CTC-based Word Spotter
(CTC-WS) for CTC and Transducer (RNN-T) ASR models. The proposed method matches
CTC log-probabilities against a compact context graph to detect potential
context-biasing candidates. The valid candidates then replace their greedy
recognition counterparts in corresponding frame intervals. A Hybrid
Transducer-CTC model enables the CTC-WS application for the Transducer model.
The results demonstrate a significant acceleration of the context-biasing
recognition with a simultaneous improvement in F-score and WER compared to
baseline methods. The proposed method is publicly available in the NVIDIA NeMo
toolkit.

摘要：針對情境化自動語音辨識 (ASR) 系統而言，準確辨識罕見且新穎的詞彙仍是一項迫切的問題。大多數情境偏差方法都涉及修改 ASR 模型或波束搜尋解碼演算法，這讓模型重複使用變得複雜，並降低推論速度。本研究提出了一種新的方法，以 CTC 為基礎的詞彙辨識器 (CTC-WS) 進行快速情境偏差，適用於 CTC 和 Transducer (RNN-T) ASR 模型。所提出的方法會將 CTC 對數機率與一個緊湊的情境圖表進行比對，以偵測潛在的情境偏差候選字。然後，有效的候選字會取代對應時間區間中貪婪辨識的對應字。混合 Transducer-CTC 模型讓 CTC-WS 可以應用於 Transducer 模型。結果顯示，與基準方法相比，情境偏差辨識的速度顯著提升，同時 F 值和 WER 也獲得改善。所提出的方法已公開發表於 NVIDIA NeMo 工具組中。

##### **Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning**
2406.07081v1 by Menglong Cui, Jiangcun Du, Shaolin Zhu, Deyi Xiong

Large language models (LLMs) exhibit outstanding performance in machine
translation via in-context learning. In contrast to sentence-level translation,
document-level translation (DOCMT) by LLMs based on in-context learning faces
two major challenges: firstly, document translations generated by LLMs are
often incoherent; secondly, the length of demonstration for in-context learning
is usually limited. To address these issues, we propose a Context-Aware
Prompting method (CAP), which enables LLMs to generate more accurate, cohesive,
and coherent translations via in-context learning. CAP takes into account
multi-level attention, selects the most relevant sentences to the current one
as context, and then generates a summary from these collected sentences.
Subsequently, sentences most similar to the summary are retrieved from the
datastore as demonstrations, which effectively guide LLMs in generating
cohesive and coherent translations. We conduct extensive experiments across
various DOCMT tasks, and the results demonstrate the effectiveness of our
approach, particularly in zero pronoun translation (ZPT) and literary
translation tasks.

摘要：大型語言模型 (LLM) 在機器翻譯中透過情境學習展現出傑出的表現。與句子層級翻譯相比，LLM 基於情境學習的文件層級翻譯 (DOCMT) 面臨兩項主要挑戰：首先，LLM 生成的文件翻譯常常不連貫；其次，情境學習的示範長度通常有限。為了解決這些問題，我們提出一個情境感知提示方法 (CAP)，它能讓 LLM 透過情境學習產生更準確、有凝聚力且連貫的翻譯。CAP 考量了多層級注意力，選擇與當前句子最相關的句子作為情境，然後從這些收集的句子產生摘要。隨後，從資料庫中擷取與摘要最相似的句子作為示範，有效引導 LLM 產生有凝聚力且連貫的翻譯。我們在各種 DOCMT 任務中進行廣泛的實驗，結果證明了我們方法的有效性，特別是在零代名詞翻譯 (ZPT) 和文學翻譯任務中。

##### **DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs**
2406.07080v1 by Haishuo Fang, Xiaodan Zhu, Iryna Gurevych

Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning
autonomous language agents in various real-life applications. To improve the
neural-symbolic reasoning capabilities of language agents powered by Large
Language Models (LLMs) in KGQA, we propose the DecompositionAlignment-Reasoning
Agent (DARA) framework. DARA effectively parses questions into formal queries
through a dual mechanism: high-level iterative task decomposition and low-level
task grounding. Importantly, DARA can be efficiently trained with a small
number of high-quality reasoning trajectories. Our experimental results
demonstrate that DARA fine-tuned on LLMs (e.g. Llama-2-7B, Mistral) outperforms
both in-context learning-based agents with GPT-4 and alternative fine-tuned
agents, across different benchmarks in zero-shot evaluation, making such models
more accessible for real-life applications. We also show that DARA attains
performance comparable to state-of-the-art enumerating-and-ranking-based
methods for KGQA.

摘要：回答知識圖表（KGQA）上的問題是各種現實生活應用中運作良好的自主語言代理的關鍵。為了改善大型語言模型（LLM）在 KGQA 中驅動的語言代理的神經符號推理能力，我們提出了分解對齊推理代理（DARA）框架。DARA 通過雙重機制有效地將問題解析為正式查詢：高級別迭代任務分解和低級別任務基礎。重要的是，DARA 可以使用少量的高品質推理軌跡進行有效訓練。我們的實驗結果表明，在 LLM（例如 Llama-2-7B、Mistral）上微調的 DARA 在零次評估的不同基準上優於基於上下文中學習的代理（使用 GPT-4）和替代微調代理，這使得此類模型更易於應用於現實生活中。我們還表明，DARA 獲得了與 KGQA 的最先進列舉和排名方法相當的性能。

##### **Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology**
2406.07078v1 by Huahui Yi, Xiaofei Wang, Kang Li, Chao Li

Multimodal learning, integrating histology images and genomics, promises to
enhance precision oncology with comprehensive views at microscopic and
molecular levels. However, existing methods may not sufficiently model the
shared or complementary information for more effective integration. In this
study, we introduce a Unified Modeling Enhanced Multimodal Learning (UMEML)
framework that employs a hierarchical attention structure to effectively
leverage shared and complementary features of both modalities of histology and
genomics. Specifically, to mitigate unimodal bias from modality imbalance, we
utilize a query-based cross-attention mechanism for prototype clustering in the
pathology encoder. Our prototype assignment and modularity strategy are
designed to align shared features and minimizes modality gaps. An additional
registration mechanism with learnable tokens is introduced to enhance
cross-modal feature integration and robustness in multimodal unified modeling.
Our experiments demonstrate that our method surpasses previous state-of-the-art
approaches in glioma diagnosis and prognosis tasks, underscoring its
superiority in precision neuro-Oncology.

摘要：多模态学习整合组织学图像和基因组学，有望通过在微观和分子层面的全面视图提升精密肿瘤学。然而，现有方法可能无法充分建模共享或互补信息以实现更有效的整合。在本研究中，我们引入了一个统一建模增强多模态学习 (UMEML) 框架，该框架采用层次化注意力结构来有效利用组织学和基因组学这两种方式的共享和互补特征。具体来说，为了减轻模态不平衡带来的单模态偏差，我们在病理学编码器中利用基于查询的交叉注意力机制进行原型聚类。我们的原型分配和模块化策略旨在对齐共享特征并最大程度地减少模态差距。引入了具有可学习标记的附加配准机制，以增强多模态统一建模中的跨模态特征集成和鲁棒性。我们的实验表明，我们的方法在神经胶质瘤诊断和预后任务中超越了以往的最新方法，突显了其在精密神经肿瘤学中的优越性。

##### **HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation**
2406.07070v1 by Wen Luo, Tianshu Shen, Wei Li, Guangyue Peng, Richeng Xuan, Houfeng Wang, Xi Yang

Large Language Models (LLMs) have significantly advanced the field of Natural
Language Processing (NLP), achieving remarkable performance across diverse
tasks and enabling widespread real-world applications. However, LLMs are prone
to hallucination, generating content that either conflicts with established
knowledge or is unfaithful to the original sources. Existing hallucination
benchmarks primarily focus on sentence- or passage-level hallucination
detection, neglecting dialogue-level evaluation, hallucination localization,
and rationale provision. They also predominantly target factuality
hallucinations while underestimating faithfulness hallucinations, often relying
on labor-intensive or non-specialized evaluators. To address these limitations,
we propose HalluDial, the first comprehensive large-scale benchmark for
automatic dialogue-level hallucination evaluation. HalluDial encompasses both
spontaneous and induced hallucination scenarios, covering factuality and
faithfulness hallucinations. The benchmark includes 4,094 dialogues with a
total of 146,856 samples. Leveraging HalluDial, we conduct a comprehensive
meta-evaluation of LLMs' hallucination evaluation capabilities in
information-seeking dialogues and introduce a specialized judge language model,
HalluJudge. The high data quality of HalluDial enables HalluJudge to achieve
superior or competitive performance in hallucination evaluation, facilitating
the automatic assessment of dialogue-level hallucinations in LLMs and providing
valuable insights into this phenomenon. The dataset and the code are available
at https://github.com/FlagOpen/HalluDial.

摘要：大型語言模型 (LLM) 已大幅提升自然語言處理 (NLP) 領域，在各種任務中達成非凡表現，並促成廣泛的實際應用。然而，LLM 容易出現幻覺，產生與既定知識相衝突或對原始來源不忠實的內容。現有的幻覺基準主要專注於句子或段落層級的幻覺偵測，忽略了對話層級的評估、幻覺定位和依據提供。它們也主要針對事實幻覺，而低估了忠實度幻覺，通常依賴於勞力密集或非專業的評估者。為了解決這些限制，我們提出了 HalluDial，這是第一個全面的大規模基準，用於自動對話層級幻覺評估。HalluDial 涵蓋自發性和誘發性幻覺場景，涵蓋事實和忠實度幻覺。此基準包含 4,094 個對話，總計 146,856 個樣本。利用 HalluDial，我們對 LLM 在資訊尋求對話中的幻覺評估能力進行全面的元評估，並引入了專業的評審語言模型 HalluJudge。HalluDial 的高資料品質使 HalluJudge 能在幻覺評估中達成優異或有競爭力的表現，有助於自動評估 LLM 中的對話層級幻覺，並提供對此現象的寶貴見解。資料集和程式碼可在 https://github.com/FlagOpen/HalluDial 取得。

##### **TIM: Temporal Interaction Model in Notification System**
2406.07067v1 by Huxiao Ji, Haitao Yang, Linchuan Li, Shunyu Zhang, Cunyi Zhang, Xuanping Li, Wenwu Ou

Modern mobile applications heavily rely on the notification system to acquire
daily active users and enhance user engagement. Being able to proactively reach
users, the system has to decide when to send notifications to users. Although
many researchers have studied optimizing the timing of sending notifications,
they only utilized users' contextual features, without modeling users' behavior
patterns. Additionally, these efforts only focus on individual notifications,
and there is a lack of studies on optimizing the holistic timing of multiple
notifications within a period. To bridge these gaps, we propose the Temporal
Interaction Model (TIM), which models users' behavior patterns by estimating
CTR in every time slot over a day in our short video application Kuaishou. TIM
leverages long-term user historical interaction sequence features such as
notification receipts, clicks, watch time and effective views, and employs a
temporal attention unit (TAU) to extract user behavior patterns. Moreover, we
provide an elegant strategy of holistic notifications send time control to
improve user engagement while minimizing disruption. We evaluate the
effectiveness of TIM through offline experiments and online A/B tests. The
results indicate that TIM is a reliable tool for forecasting user behavior,
leading to a remarkable enhancement in user engagement without causing undue
disturbance.

摘要：現代行動應用程式極度依賴通知系統來取得每日活躍用戶並加強使用者參與度。由於能夠主動接觸使用者，此系統必須決定何時向使用者傳送通知。儘管許多研究人員已研究最佳傳送通知時機，但他們僅利用使用者的脈絡功能，而未建模使用者的行為模式。此外，這些努力僅專注於個別通知，且缺乏針對一段時間內多個通知的整體時機進行最佳化的研究。為了彌補這些差距，我們提出時間互動模型 (TIM)，此模型透過在我們短影音應用程式快手中估計一天中每個時段的 CTR 來建模使用者的行為模式。TIM 利用長期使用者歷史互動序列功能，例如通知收據、點擊、觀看時間和有效觀看次數，並採用時間注意單元 (TAU) 來擷取使用者行為模式。此外，我們提供整體通知發送時間控制的優雅策略，以改善使用者參與度，同時將中斷降至最低。我們透過離線實驗和線上 A/B 測試評估 TIM 的有效性。結果顯示 TIM 是用於預測使用者行為的可靠工具，可顯著提升使用者參與度，且不會造成不必要的干擾。

##### **Reconstructing the Tropical Pacific Upper Ocean using Online Data Assimilation with a Deep Learning model**
2406.07063v1 by Zilu Meng, Gregory J. Hakim

A deep learning (DL) model, based on a transformer architecture, is trained
on a climate-model dataset and compared with a standard linear inverse model
(LIM) in the tropical Pacific. We show that the DL model produces more accurate
forecasts compared to the LIM when tested on a reanalysis dataset. We then
assess the ability of an ensemble Kalman filter to reconstruct the
monthly-averaged upper ocean from a noisy set of 24 sea-surface temperature
observations designed to mimic existing coral proxy measurements, and compare
results for the DL model and LIM. Due to signal damping in the DL model, we
implement a novel inflation technique by adding noise from hindcast
experiments. Results show that assimilating observations with the DL model
yields better reconstructions than the LIM for observation averaging times
ranging from one month to one year. The improved reconstruction is due to the
enhanced predictive capabilities of the DL model, which map the memory of past
observations to future assimilation times.

摘要：一個基於Transformer架構的深度學習 (DL) 模型，訓練於一個氣候模型資料集，並與一個標準線性反算模型 (LIM) 在熱帶太平洋中進行比較。我們顯示，當在一個再分析資料集上進行測試時，DL 模型產生比 LIM 更準確的預測。然後我們評估一個集合卡爾曼濾波器從一組 24 個海面溫度觀測值（設計用於模擬現有的珊瑚代理測量值）中重建每月平均的上層海洋的能力，並比較 DL 模型和 LIM 的結果。由於 DL 模型中的信號衰減，我們通過添加來自後測實驗的噪音來實施一種新的膨脹技術。結果顯示，使用 DL 模型同化觀測值會產生比 LIM 更好的重建，觀測平均時間範圍從一個月到一年。改進的重建歸因於 DL 模型增強的預測能力，它將過去觀測的記憶映射到未來的同化時間。

##### **Reading Miscue Detection in Primary School through Automatic Speech Recognition**
2406.07060v1 by Lingyun Gao, Cristian Tejedor-Garcia, Helmer Strik, Catia Cucchiarini

Automatic reading diagnosis systems can benefit both teachers for more
efficient scoring of reading exercises and students for accessing reading
exercises with feedback more easily. However, there are limited studies on
Automatic Speech Recognition (ASR) for child speech in languages other than
English, and limited research on ASR-based reading diagnosis systems. This
study investigates how efficiently state-of-the-art (SOTA) pretrained ASR
models recognize Dutch native children speech and manage to detect reading
miscues. We found that Hubert Large finetuned on Dutch speech achieves SOTA
phoneme-level child speech recognition (PER at 23.1\%), while Whisper (Faster
Whisper Large-v2) achieves SOTA word-level performance (WER at 9.8\%). Our
findings suggest that Wav2Vec2 Large and Whisper are the two best ASR models
for reading miscue detection. Specifically, Wav2Vec2 Large shows the highest
recall at 0.83, whereas Whisper exhibits the highest precision at 0.52 and an
F1 score of 0.52.

摘要：自動閱讀診斷系統可讓教師更有效率地評分閱讀練習，並讓學生更容易取得有回饋的閱讀練習。然而，針對英語以外語言的兒童語音進行自動語音辨識 (ASR) 的研究有限，而基於 ASR 的閱讀診斷系統的研究也相當有限。本研究探討最先進 (SOTA) 的預訓練 ASR 模型能多有效地辨識荷蘭母語兒童的語音，並設法偵測閱讀錯誤。我們發現針對荷蘭語音微調的 Hubert Large 可達成最先進的音素層級兒童語音辨識 (PER 為 23.1%)，而 Whisper (Faster Whisper Large-v2) 則可達成最先進的詞彙層級表現 (WER 為 9.8%)。我們的研究結果顯示，Wav2Vec2 Large 和 Whisper 是用於偵測閱讀錯誤的兩大最佳 ASR 模型。具體來說，Wav2Vec2 Large 展現最高的召回率 0.83，而 Whisper 則展現最高的精確率 0.52 和 F1 分數 0.52。

##### **Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study**
2406.07057v1 by Yichi Zhang, Yao Huang, Yitong Sun, Chang Liu, Zhe Zhao, Zhengwei Fang, Yifan Wang, Huanran Chen, Xiao Yang, Xingxing Wei, Hang Su, Yinpeng Dong, Jun Zhu

Despite the superior capabilities of Multimodal Large Language Models (MLLMs)
across diverse tasks, they still face significant trustworthiness challenges.
Yet, current literature on the assessment of trustworthy MLLMs remains limited,
lacking a holistic evaluation to offer thorough insights into future
improvements. In this work, we establish MultiTrust, the first comprehensive
and unified benchmark on the trustworthiness of MLLMs across five primary
aspects: truthfulness, safety, robustness, fairness, and privacy. Our benchmark
employs a rigorous evaluation strategy that addresses both multimodal risks and
cross-modal impacts, encompassing 32 diverse tasks with self-curated datasets.
Extensive experiments with 21 modern MLLMs reveal some previously unexplored
trustworthiness issues and risks, highlighting the complexities introduced by
the multimodality and underscoring the necessity for advanced methodologies to
enhance their reliability. For instance, typical proprietary models still
struggle with the perception of visually confusing images and are vulnerable to
multimodal jailbreaking and adversarial attacks; MLLMs are more inclined to
disclose privacy in text and reveal ideological and cultural biases even when
paired with irrelevant images in inference, indicating that the multimodality
amplifies the internal risks from base LLMs. Additionally, we release a
scalable toolbox for standardized trustworthiness research, aiming to
facilitate future advancements in this important field. Code and resources are
publicly available at: https://multi-trust.github.io/.

摘要：儘管多模態大型語言模型 (MMLM) 在各種任務中具備優異的能力，但它們仍面臨重大的可信度挑戰。然而，目前關於可信 MMLM 評估的文獻仍然有限，缺乏全面的評估來提供對未來改進的深入見解。在這項工作中，我們建立了 MultiTrust，這是第一個針對 MMLM 可信度的全面且統一的基準，涵蓋五個主要方面：真實性、安全性、健壯性、公平性和隱私。我們的基準採用嚴格的評估策略，解決了多模態風險和跨模態影響，包含 32 項使用自訂資料集的多元任務。使用 21 個現代 MLLM 進行的廣泛實驗揭示了一些先前未探索的可信度問題和風險，突顯了多模態性帶來的複雜性，並強調了採用先進方法以增強其可靠性的必要性。例如，典型的專有模型仍然難以辨識視覺上令人困惑的影像，並且容易受到多模態越獄和對抗性攻擊；MMLM 更傾向於在文字中揭露隱私，並在推論中與無關的影像配對時揭露意識形態和文化偏見，這表示多模態性放大了基礎 LLM 的內部風險。此外，我們發布了一個可擴充的工具箱，用於標準化的可信度研究，旨在促進這個重要領域的未來進展。程式碼和資源公開於：https://multi-trust.github.io/。

##### **Effectively Compress KV Heads for LLM**
2406.07056v1 by Hao Yu, Zelan Yang, Shen Li, Yong Li, Jianxin Wu

The advent of pre-trained large language models (LLMs) has revolutionized
various natural language processing tasks. These models predominantly employ an
auto-regressive decoding mechanism that utilizes Key-Value (KV) caches to
eliminate redundant calculations for previous tokens. Nevertheless, as context
lengths and batch sizes increase, the linear expansion in memory footprint of
KV caches becomes a key bottleneck of LLM deployment, which decreases
generation speeds significantly. To mitigate this issue, previous techniques
like multi-query attention (MQA) and grouped-query attention (GQA) have been
developed, in order to reduce KV heads to accelerate inference with comparable
accuracy to multi-head attention (MHA). Despite their effectiveness, existing
strategies for compressing MHA often overlook the intrinsic properties of the
KV caches. In this work, we explore the low-rank characteristics of the KV
caches and propose a novel approach for compressing KV heads. In particular, we
carefully optimize the MHA-to-GQA transformation to minimize compression error,
and to remain compatible with rotary position embeddings (RoPE), we also
introduce specialized strategies for key caches with RoPE. We demonstrate that
our method can compress half or even three-quarters of KV heads while
maintaining performance comparable to the original LLMs, which presents a
promising direction for more efficient LLM deployment in resource-constrained
environments.

摘要：預訓練大型語言模型 (LLM) 的出現，徹底改變了各種自然語言處理任務。這些模型主要採用自迴歸解碼機制，利用鍵值 (KV) 快取來消除先前符號的重複計算。然而，隨著內容長度和批次大小的增加，KV 快取的記憶體使用量線性擴充，成為 LLM 部署的主要瓶頸，大幅降低產生速度。為了減輕這個問題，已開發出多重查詢注意力 (MQA) 和群組查詢注意力 (GQA) 等先前的技術，以減少 KV 頭部，藉此加速推論，同時維持與多頭注意力 (MHA) 相當的準確度。儘管這些策略有效，現有的 MHA 壓縮策略往往忽略 KV 快取的內在特性。在這項工作中，我們探討 KV 快取的低秩特性，並提出一種壓縮 KV 頭部的創新方法。特別是，我們仔細最佳化 MHA 到 GQA 的轉換，以最小化壓縮誤差，並維持與旋轉位置嵌入 (RoPE) 的相容性，我們也針對使用 RoPE 的金鑰快取，引進專門的策略。我們證明了我們的方法可以在維持與原始 LLM 相當的效能下，壓縮一半甚至四分之三的 KV 頭部，這為在資源受限的環境中更有效率地部署 LLM，提供了有希望的方向。

##### **CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation**
2406.07054v1 by Renhao Li, Minghuan Tan, Derek F. Wong, Min Yang

In recent years, instruction fine-tuning (IFT) on large language models
(LLMs) has garnered considerable attention to enhance model performance on
unseen tasks. Attempts have been made on automatic construction and effective
selection for IFT data. However, we posit that previous methods have not fully
harnessed the potential of LLMs for enhancing data quality. The responses
within IFT data could be further enhanced by leveraging the capabilities of
LLMs themselves. In this paper, we propose CoEvol, an LLM-based multi-agent
cooperation framework for the improvement of responses to instructions. To
effectively refine the responses, we develop an iterative framework following a
debate-advise-edit-judge paradigm. A two-stage multi-agent debate strategy is
further devised to ensure the diversity and reliability of editing suggestions
within the framework. Empirically, models equipped with CoEvol outperform
competitive baselines evaluated by MT-Bench and AlpacaEval, demonstrating its
effectiveness in enhancing instruction-following capabilities for LLMs.

摘要：近年來，大型語言模型 (LLM) 上的指令微調 (IFT) 已引起相當大的關注，以增強模型在 unseen 任務上的效能。已嘗試自動建構和有效選擇 IFT 資料。然而，我們認為先前的技術並未充分利用 LLM 來增強資料品質。IFT 資料中的回應可以透過利用 LLM 本身的效能進一步增強。在本文中，我們提出 CoEvol，一個基於 LLM 的多主體合作架構，用於改善對指令的回應。為了有效改善回應，我們開發了一個遵循辯論-建議-編輯-判斷範式的反覆運算架構。進一步設計了一個兩階段多主體辯論策略，以確保架構中編輯建議的多樣性和可靠性。根據經驗，配備 CoEvol 的模型優於由 MT-Bench 和 AlpacaEval 評估的競爭基線，證明其在增強 LLM 的指令遵循能力方面的有效性。

##### **Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model**
2406.07036v1 by Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang

Large language models (LLMs) have showcased impressive multilingual machine
translation ability. However, unlike encoder-decoder style models, decoder-only
LLMs lack an explicit alignment between source and target contexts. Analyzing
contribution scores during generation processes revealed that LLMs can be
biased towards previously generated tokens over corresponding source tokens,
leading to unfaithful translations. To address this issue, we propose to
encourage LLMs to pay more attention to the source context from both source and
target perspectives in zeroshot prompting: 1) adjust source context attention
weights; 2) suppress irrelevant target prefix influence; Additionally, we
propose 3) avoiding over-reliance on the target prefix in instruction tuning.
Experimental results from both human-collected unfaithfulness test sets
focusing on LLM-generated unfaithful translations and general test sets, verify
our methods' effectiveness across multiple language pairs. Further human
evaluation shows our method's efficacy in reducing hallucinatory translations
and facilitating faithful translation generation.

摘要：大型語言模型 (LLM) 已展示出令人印象深刻的多語言機器翻譯能力。然而，與編碼器-解碼器風格模型不同，僅解碼器的 LLM 缺乏來源和目標語境之間的明確對齊。分析生成過程中的貢獻評分顯示，LLM 可能偏向於先前生成的標記，而不是對應的來源標記，從而導致不忠實的翻譯。為了解決此問題，我們建議鼓勵 LLM 從來源和目標角度在零次提示中更多地關注來源語境：1) 調整來源語境關注權重；2) 抑制無關的目標前綴影響；此外，我們建議 3) 避免過度依賴說明調整中的目標前綴。從專注於 LLM 生成的非忠實翻譯和一般測試集的人類收集的非忠實測試集中獲得的實驗結果驗證了我們的方法在多種語言對中的有效性。進一步的人類評估顯示了我們的方法在減少幻覺翻譯和促進忠實翻譯生成方面的效力。

##### **Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning**
2406.07034v1 by Jeonghoon Kim, Heesoo Jung, Hyeju Jang, Hogun Park

Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural
language processing, with numerous approaches aiming to answer First-Order
Logic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g.,
beta distribution)-based methodologies have effectively addressed complex FOL
queries. However, a common challenge across these methods lies in determining
accurate geometric bounds or probability parameters for these queries. The
challenge arises because existing methods rely on linear sequential operations
within their computation graphs, overlooking the logical structure of the query
and the relation-induced information that can be gleaned from the relations of
the query, which we call the context of the query. To address the problem, we
propose a model-agnostic methodology that enhances the effectiveness of
existing multi-hop logical reasoning approaches by fully integrating the
context of the FOL query graph. Our approach distinctively discerns (1) the
structural context inherent to the query structure and (2) the relation-induced
context unique to each node in the query graph as delineated in the
corresponding knowledge graph. This dual-context paradigm helps nodes within a
query graph attain refined internal representations throughout the multi-hop
reasoning steps. Through experiments on two datasets, our method consistently
enhances the three multi-hop reasoning foundation models, achieving performance
improvements of up to 19.5%. Our code is available at
https://github.com/kjh9503/caqr.

摘要：多跳邏輯推理是自然語言處理中的關鍵任務，許多方法旨在回答一階邏輯 (FOL) 查詢。最近的幾何形狀（例如，盒子、圓錐）和機率（例如，貝塔分佈）方法有效地解決了複雜的 FOL 查詢。然而，這些方法的共同挑戰在於，為這些查詢確定準確的幾何界限或機率參數。挑戰出現的原因在於，現有方法依賴於其運算圖形中的線性順序運算，忽略了查詢的邏輯結構以及可以從查詢關係中收集到的關係誘導資訊，我們稱之為查詢的背景。為了解決這個問題，我們提出了一種與模型無關的方法，透過完全整合 FOL 查詢圖形的背景，來提升現有多跳邏輯推理方法的效能。我們的做法獨特地辨別了 (1) 查詢結構固有的結構背景，以及 (2) 查詢圖形中每個節點獨有的關係誘導背景，如對應的知識圖形中所描繪的。這種雙重背景範例有助於查詢圖形中的節點在多跳推理步驟中獲得精緻的內部表示。透過在兩個資料集上進行實驗，我們的模型持續增強三種多跳推理基礎模型，效能提升最高達 19.5%。我們的程式碼可在 https://github.com/kjh9503/caqr 取得。

##### **Entropy-Reinforced Planning with Large Language Models for Drug Discovery**
2406.07025v1 by Xuefeng Liu, Chih-chan Tien, Peng Ding, Songhao Jiang, Rick L. Stevens

The objective of drug discovery is to identify chemical compounds that
possess specific pharmaceutical properties toward a binding target. Existing
large language models (LLMS) can achieve high token matching scores in terms of
likelihood for molecule generation. However, relying solely on LLM decoding
often results in the generation of molecules that are either invalid due to a
single misused token, or suboptimal due to unbalanced exploration and
exploitation as a consequence of the LLMs prior experience. Here we propose
ERP, Entropy-Reinforced Planning for Transformer Decoding, which employs an
entropy-reinforced planning algorithm to enhance the Transformer decoding
process and strike a balance between exploitation and exploration. ERP aims to
achieve improvements in multiple properties compared to direct sampling from
the Transformer. We evaluated ERP on the SARS-CoV-2 virus (3CLPro) and human
cancer cell target protein (RTCB) benchmarks and demonstrated that, in both
benchmarks, ERP consistently outperforms the current state-of-the-art algorithm
by 1-5 percent, and baselines by 5-10 percent, respectively. Moreover, such
improvement is robust across Transformer models trained with different
objectives. Finally, to further illustrate the capabilities of ERP, we tested
our algorithm on three code generation benchmarks and outperformed the current
state-of-the-art approach as well. Our code is publicly available at:
https://github.com/xuefeng-cs/ERP.

摘要：藥物發現的目標是找出對結合標靶具有特定藥理特性的化學化合物。現有的大型語言模型 (LLM) 能在分子產生的可能性方面達到很高的符號匹配分數。然而，僅依賴 LLM 解碼常常會產生無效的分子，原因是單一符號誤用，或因為 LLM 先前的經驗導致探索和利用不平衡而導致次佳結果。在此，我們提出 ERP，也就是Transformer解碼的熵增強規劃，它採用熵增強規劃演算法來增強Transformer解碼程序，並在利用和探索之間取得平衡。與直接從Transformer取樣相比，ERP 旨在改善多重特性。我們在 SARS-CoV-2 病毒 (3CLPro) 和人類癌細胞目標蛋白質 (RTCB) 基準上評估 ERP，並證明在兩個基準中，ERP 都比現有的最新演算法高出 1-5%，比基準高出 5-10%。此外，這種改進在使用不同目標訓練的Transformer模型中都很穩固。最後，為了進一步說明 ERP 的能力，我們在三個程式碼產生基準上測試我們的演算法，並也優於現有的最新方法。我們的程式碼已公開於：https://github.com/xuefeng-cs/ERP。

##### **MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations**
2406.07017v1 by Zixiao Wang, Jingwei Zhang, Wenqian Zhao, Farzan Farnia, Bei Yu

Few-shot gradient methods have been extensively utilized in existing model
pruning methods, where the model weights are regarded as static values and the
effects of potential weight perturbations are not considered. However, the
widely used large language models (LLMs) have several billion model parameters,
which could increase the fragility of few-shot gradient pruning. In this work,
we experimentally show that one-shot gradient pruning algorithms could lead to
unstable results under perturbations to model weights. And the minor error of
switching between data formats bfloat16 and float16 could result in drastically
different outcomes. To address such instabilities, we leverage optimization
analysis and propose an LLM structural pruning method, called MoreauPruner,
with provable robustness against weight perturbations. In MoreauPruner, the
model weight importance is estimated based on the neural network's Moreau
envelope, which can be flexibly combined with $\ell_1$-norm regularization
techniques to induce the sparsity required in the pruning task. We extensively
evaluate the MoreauPruner algorithm on several well-known LLMs, including
LLaMA-7B, LLaMA-13B, LLaMA3-8B, and Vicuna-7B. Our numerical results suggest
the robustness of MoreauPruner against weight perturbations, and indicate the
MoreauPruner's successful accuracy-based scores in comparison to several
existing pruning methods. We have released the code in
\url{https://github.com/ShiningSord/MoreauPruner}.

摘要：<paragraph>現有的模型剪枝方法中廣泛採用了少次梯度法，其中模型權重被視為靜態值，而潛在權重擾動的影響則未被考慮。然而，廣泛使用的大語言模型 (LLM) 具有數十億個模型參數，這可能會增加少次梯度剪枝的脆弱性。在這項工作中，我們透過實驗表明，一次梯度剪枝演算法可能會導致模型權重擾動下的不穩定結果。而資料格式 bfloat16 和 float16 之間的微小錯誤可能會導致截然不同的結果。為了解決這種不穩定性，我們利用最佳化分析並提出了一種 LLM 結構剪枝方法，稱為 MoreauPruner，它具有可證明對抗權重擾動的穩健性。在 MoreauPruner 中，模型權重重要性是根據神經網路的 Moreau 函數估計的，它可以靈活地與 $\ell_1$-norm 正則化技術相結合，以誘導剪枝任務中所需的稀疏性。我們在幾個著名的 LLM 上廣泛評估了 MoreauPruner 演算法，包括 LLaMA-7B、LLaMA-13B、LLaMA3-8B 和 Vicuna-7B。我們的數值結果表明 MoreauPruner 對抗權重擾動的穩健性，並表明 MoreauPruner 在與現有幾種剪枝方法的比較中獲得了成功的基於準確性的評分。我們已在\url{https://github.com/ShiningSord/MoreauPruner}釋出程式碼。</paragraph>

##### **Delving into ChatGPT usage in academic writing through excess vocabulary**
2406.07016v1 by Dmitry Kobak, Rita González Márquez, Emőke-Ágnes Horvát, Jan Lause

Recent large language models (LLMs) can generate and revise text with
human-level performance, and have been widely commercialized in systems like
ChatGPT. These models come with clear limitations: they can produce inaccurate
information, reinforce existing biases, and be easily misused. Yet, many
scientists have been using them to assist their scholarly writing. How
wide-spread is LLM usage in the academic literature currently? To answer this
question, we use an unbiased, large-scale approach, free from any assumptions
on academic LLM usage. We study vocabulary changes in 14 million PubMed
abstracts from 2010-2024, and show how the appearance of LLMs led to an abrupt
increase in the frequency of certain style words. Our analysis based on excess
words usage suggests that at least 10% of 2024 abstracts were processed with
LLMs. This lower bound differed across disciplines, countries, and journals,
and was as high as 30% for some PubMed sub-corpora. We show that the appearance
of LLM-based writing assistants has had an unprecedented impact in the
scientific literature, surpassing the effect of major world events such as the
Covid pandemic.

摘要：最近的大型语言模型 (LLM) 能够以人类级别的表现生成和修改文本，并且已在 ChatGPT 等系统中得到广泛的商业化应用。这些模型带有明显的限制：它们可能会产生不准确的信息、强化现有偏见，并且很容易被滥用。然而，许多科学家一直在使用它们来辅助他们的学术写作。目前 LLM 在学术文献中的使用有多广泛？为了回答这个问题，我们使用了一种公正、大规模的方法，不受任何关于学术 LLM 使用的假设的影响。我们研究了 2010-2024 年间 1400 万篇 PubMed 摘要中的词汇变化，并展示了 LLM 的出现如何导致某些风格词的频率急剧增加。我们基于超额词语使用的分析表明，至少 10% 的 2024 年摘要是用 LLM 处理过的。这个下限因学科、国家和期刊而异，对于一些 PubMed 子语料库而言，这个下限高达 30%。我们表明，基于 LLM 的写作助手的出现对科学文献产生了前所未有的影响，超过了 Covid 大流行等重大世界事件的影响。

##### **Bridging Language Gaps in Audio-Text Retrieval**
2406.07012v1 by Zhiyong Yan, Heinrich Dinkel, Yongqing Wang, Jizhong Liu, Junbo Zhang, Yujun Wang, Bin Wang

Audio-text retrieval is a challenging task, requiring the search for an audio
clip or a text caption within a database. The predominant focus of existing
research on English descriptions poses a limitation on the applicability of
such models, given the abundance of non-English content in real-world data. To
address these linguistic disparities, we propose a language enhancement (LE),
using a multilingual text encoder (SONAR) to encode the text data with
language-specific information. Additionally, we optimize the audio encoder
through the application of consistent ensemble distillation (CED), enhancing
support for variable-length audio-text retrieval. Our methodology excels in
English audio-text retrieval, demonstrating state-of-the-art (SOTA) performance
on commonly used datasets such as AudioCaps and Clotho. Simultaneously, the
approach exhibits proficiency in retrieving content in seven other languages
with only 10% of additional language-enhanced training data, yielding promising
results. The source code is publicly available
https://github.com/zyyan4/ml-clap.

摘要：音訊文字檢索是一項具有挑戰性的任務，需要在資料庫中搜尋音訊片段或文字標題。現有英文說明的研究重點，限制了此類模型的適用性，因為現實世界資料中存在大量非英文內容。為了解決這些語言差異，我們提出語言增強 (LE)，使用多語言文字編碼器 (SONAR) 編碼具有語言特定資訊的文字資料。此外，我們透過應用一致的整體蒸餾 (CED) 來最佳化音訊編碼器，加強對可變長度音訊文字檢索的支援。我們的技術在英文音訊文字檢索中表現優異，在 AudioCaps 和 Clotho 等常用資料集上展現最先進 (SOTA) 的效能。同時，此方法僅使用 10% 的額外語言增強訓練資料，就能熟練地檢索七種其他語言的內容，產生有希望的結果。原始程式碼公開於 https://github.com/zyyan4/ml-clap。

##### **Eye-for-an-eye: Appearance Transfer with Semantic Correspondence in Diffusion Models**
2406.07008v1 by Sooyeon Go, Kyungmook Choi, Minjung Shin, Youngjung Uh

As pretrained text-to-image diffusion models have become a useful tool for
image synthesis, people want to specify the results in various ways. In this
paper, we introduce a method to produce results with the same structure of a
target image but painted with colors from a reference image, i.e., appearance
transfer, especially following the semantic correspondence between the result
and the reference. E.g., the result wing takes color from the reference wing,
not the reference head. Existing methods rely on the query-key similarity
within self-attention layer, usually producing defective results. To this end,
we propose to find semantic correspondences and explicitly rearrange the
features according to the semantic correspondences. Extensive experiments show
the superiority of our method in various aspects: preserving the structure of
the target and reflecting the color from the reference according to the
semantic correspondences, even when the two images are not aligned.

摘要：隨著預訓練文字到影像擴散模型已成為影像合成有用的工具，人們希望以各種方式指定結果。在本文中，我們介紹一種方法，以產生具有目標影像相同結構，但以參考影像的顏色繪製的結果，即外觀轉移，特別是遵循結果與參考之間的語義對應。例如，結果的翅膀取自參考翅膀的顏色，而不是參考頭部。現有方法依賴於自注意力層內的查詢鍵相似性，通常會產生有缺陷的結果。為此，我們建議找出語義對應並根據語義對應明確重新排列特徵。廣泛的實驗表明，我們的模型在各方面都具有優越性：保留目標的結構，並根據語義對應反映參考的顏色，即使兩幅影像沒有對齊。

##### **Crayon: Customized On-Device LLM via Instant Adapter Blending and Edge-Server Hybrid Inference**
2406.07007v1 by Jihwan Bang, Juntae Lee, Kyuhong Shim, Seunghan Yang, Simyung Chang

The customization of large language models (LLMs) for user-specified tasks
gets important. However, maintaining all the customized LLMs on cloud servers
incurs substantial memory and computational overheads, and uploading user data
can also lead to privacy concerns. On-device LLMs can offer a promising
solution by mitigating these issues. Yet, the performance of on-device LLMs is
inherently constrained by the limitations of small-scaled models. To overcome
these restrictions, we first propose Crayon, a novel approach for on-device LLM
customization. Crayon begins by constructing a pool of diverse base adapters,
and then we instantly blend them into a customized adapter without extra
training. In addition, we develop a device-server hybrid inference strategy,
which deftly allocates more demanding queries or non-customized tasks to a
larger, more capable LLM on a server. This ensures optimal performance without
sacrificing the benefits of on-device customization. We carefully craft a novel
benchmark from multiple question-answer datasets, and show the efficacy of our
method in the LLM customization.

摘要：對於用戶指定任務的大語言模型 (LLM) 的自訂變得重要。然而，在雲端伺服器上維護所有自訂 LLM 會產生大量的記憶體和運算負擔，上傳使用者資料也可能導致隱私問題。裝置內 LLM 可透過減輕這些問題提供一個有前景的解決方案。然而，裝置內 LLM 的效能本質上受到小規模模型限制的約束。為了克服這些限制，我們首先提出 Crayon，一種用於裝置內 LLM 自訂的新方法。Crayon 的第一步是建構一個多樣化的基礎適配器池，然後我們立即將它們混合成自訂適配器，而無需額外訓練。此外，我們開發了一種裝置伺服器混合式推論策略，它靈巧地將更嚴苛的查詢或非自訂任務分配給伺服器上更大、功能更強大的 LLM。這可確保最佳效能，同時不犧牲裝置內自訂的好處。我們從多個問答資料集仔細製作一個新基準，並在 LLM 自訂中展示我們方法的功效。

##### **Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models**
2406.07001v1 by Zhenyi Lu, Jie Tian, Wei Wei, Xiaoye Qu, Yu Cheng, Wenfeng xie, Dangyang Chen

Text classification is a crucial task encountered frequently in practical
scenarios, yet it is still under-explored in the era of large language models
(LLMs). This study shows that LLMs are vulnerable to changes in the number and
arrangement of options in text classification. Our extensive empirical analyses
reveal that the key bottleneck arises from ambiguous decision boundaries and
inherent biases towards specific tokens and positions. To mitigate these
issues, we make the first attempt and propose a novel two-stage classification
framework for LLMs. Our approach is grounded in the empirical observation that
pairwise comparisons can effectively alleviate boundary ambiguity and inherent
bias. Specifically, we begin with a self-reduction technique to efficiently
narrow down numerous options, which contributes to reduced decision space and a
faster comparison process. Subsequently, pairwise contrastive comparisons are
employed in a chain-of-thought manner to draw out nuances and distinguish
confusable options, thus refining the ambiguous decision boundary. Extensive
experiments on four datasets (Banking77, HWU64, LIU54, and Clinic150) verify
the effectiveness of our framework. Furthermore, benefitting from our
framework, various LLMs can achieve consistent improvements. Our code and data
are available in \url{https://github.com/Chuge0335/PC-CoT}.

摘要：文本分類是實際場景中經常遇到的關鍵任務，但在大型語言模型 (LLM) 的時代仍未得到充分探索。本研究表明，LLM 容易受到文本分類中選項數量和排列方式的變化影響。我們廣泛的實證分析表明，關鍵瓶頸源於模稜兩可的決策界線和對特定標記和位置的固有偏差。為了減輕這些問題，我們首次嘗試並為 LLM 提出了一個新穎的兩階段分類框架。我們的做法基於經驗觀察，即成對比較可以有效緩解邊界模糊和固有偏差。具體來說，我們從一種自簡化技術開始，以有效縮小大量選項，這有助於減少決策空間和更快的比較過程。隨後，以思想鏈的方式採用成對對比比較，以找出細微差別並區分容易混淆的選項，從而優化模糊的決策界線。在四個資料集（Banking77、HWU64、LIU54 和 Clinic150）上的廣泛實驗驗證了我們框架的有效性。此外，受益於我們的框架，各種 LLM 可以實現持續改進。我們的程式碼和資料可在 \url{https://github.com/Chuge0335/PC-CoT} 中取得。

##### **Discrete Dictionary-based Decomposition Layer for Structured Representation Learning**
2406.06976v1 by Taewon Park, Hyun-Chul Kim, Minho Lee

Neuro-symbolic neural networks have been extensively studied to integrate
symbolic operations with neural networks, thereby improving systematic
generalization. Specifically, Tensor Product Representation (TPR) framework
enables neural networks to perform differentiable symbolic operations by
encoding the symbolic structure of data within vector spaces. However,
TPR-based neural networks often struggle to decompose unseen data into
structured TPR representations, undermining their symbolic operations. To
address this decomposition problem, we propose a Discrete Dictionary-based
Decomposition (D3) layer designed to enhance the decomposition capabilities of
TPR-based models. D3 employs discrete, learnable key-value dictionaries trained
to capture symbolic features essential for decomposition operations. It
leverages the prior knowledge acquired during training to generate structured
TPR representations by mapping input data to pre-learned symbolic features
within these dictionaries. D3 is a straightforward drop-in layer that can be
seamlessly integrated into any TPR-based model without modifications. Our
experimental results demonstrate that D3 significantly improves the systematic
generalization of various TPR-based models while requiring fewer additional
parameters. Notably, D3 outperforms baseline models on the synthetic task that
demands the systematic decomposition of unseen combinatorial data.

摘要：神經符號神經網路已被廣泛研究，用於整合符號運算和神經網路，從而改善系統性泛化。具體來說，張量積表示 (TPR) 框架使神經網路能夠通過在向量空間內編碼資料的符號結構來執行可微分的符號運算。然而，基於 TPR 的神經網路通常難以將未見資料分解成結構化的 TPR 表示，從而損害其符號運算。為了解決這個分解問題，我們提出了一個基於離散字典的分解 (D3) 層，旨在增強基於 TPR 的模型的分解能力。D3 使用離散的可學習鍵值字典，經過訓練以擷取分解運算中必要的符號特徵。它利用訓練期間獲得的先驗知識，通過將輸入資料對應到這些字典中的預先學習的符號特徵，來產生結構化的 TPR 表示。D3 是一個直接的插入層，可以無縫整合到任何基於 TPR 的模型中，而無需修改。我們的實驗結果表明，D3 大幅改善了各種基於 TPR 的模型的系統性泛化，同時需要較少的額外參數。值得注意的是，D3 在需要系統性分解未見組合資料的合成任務上優於基線模型。

##### **Beyond the Norms: Detecting Prediction Errors in Regression Models**
2406.06968v1 by Andres Altieri, Marco Romanelli, Georg Pichler, Florence Alberge, Pablo Piantanida

This paper tackles the challenge of detecting unreliable behavior in
regression algorithms, which may arise from intrinsic variability (e.g.,
aleatoric uncertainty) or modeling errors (e.g., model uncertainty). First, we
formally introduce the notion of unreliability in regression, i.e., when the
output of the regressor exceeds a specified discrepancy (or error). Then, using
powerful tools for probabilistic modeling, we estimate the discrepancy density,
and we measure its statistical diversity using our proposed metric for
statistical dissimilarity. In turn, this allows us to derive a data-driven
score that expresses the uncertainty of the regression outcome. We show
empirical improvements in error detection for multiple regression tasks,
consistently outperforming popular baseline approaches, and contributing to the
broader field of uncertainty quantification and safe machine learning systems.
Our code is available at https://zenodo.org/records/11281964.

摘要：本文探討了偵測回歸演算法中不可靠行為的挑戰，這些行為可能源自內在變異性（例如，隨機不確定性）或模型誤差（例如，模型不確定性）。首先，我們正式介紹回歸中不可靠性的概念，即當回歸器的輸出超過特定差異（或誤差）時。然後，使用機率模型的強大工具，我們估計差異密度，並使用我們提出的統計差異度量來衡量其統計多樣性。反過來，這使我們能夠推導出資料驅動的分數，表示回歸結果的不確定性。我們展示了多重回歸任務的錯誤偵測的經驗改進，始終優於流行的基準方法，並為不確定性量化和安全機器學習系統的更廣泛領域做出貢獻。我們的程式碼可在 https://zenodo.org/records/11281964 取得。

##### **Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples**
2406.06967v1 by Kailas Dayanandan, Anand Sinha, Brejesh Lall

The dual thinking framework considers fast, intuitive processing and slower,
logical processing. The perception of dual thinking in vision requires images
where inferences from intuitive and logical processing differ. We introduce an
adversarial dataset to provide evidence for the dual thinking framework in
human vision, which also aids in studying the qualitative behavior of deep
learning models. Our study also addresses a major criticism of using
classification models as computational models of human vision by using instance
segmentation models that localize objects. The evidence underscores the
importance of shape in identifying instances in human vision and shows that
deep learning models lack an understanding of sub-structures, as indicated by
errors related to the position and number of sub-components. Additionally, the
similarity in errors made by models and intuitive human processing indicates
that models only address intuitive thinking in human vision.

摘要：雙重思考架構考量快速、直覺的處理，以及較慢、邏輯的處理。在視覺中對雙重思考的感知需要影像，其中直覺和邏輯處理的推論不同。我們引入對抗性資料集，以提供人類視覺中雙重思考架構的證據，這也有助於研究深度學習模型的品質行為。我們的研究也處理使用分類模型作為人類視覺的計算模型的主要批評，方法是使用局部化物件的實例分割模型。證據強調形狀在人類視覺中識別實例的重要性，並顯示深度學習模型缺乏對子結構的理解，如與子組件的位置和數量相關的錯誤所顯示的。此外，模型和直覺人類處理所犯錯誤的相似性表明，模型僅處理人類視覺中的直覺思考。

