{"2412.02595": {"publish_time": "2024-12-03", "title": "Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset", "paper_summary": "Recent English Common Crawl datasets like FineWeb-Edu and DCLM achieved\nsignificant benchmark gains via aggressive model-based filtering, but at the\ncost of removing 90% of data. This limits their suitability for long token\nhorizon training, such as 15T tokens for Llama 3.1. In this paper, we show how\nto achieve better trade-offs between accuracy and data quantity by a\ncombination of classifier ensembling, synthetic data rephrasing, and reduced\nreliance on heuristic filters. When training 8B parameter models for 1T tokens,\nusing a high-quality subset of our data improves MMLU by 5.6 over DCLM,\ndemonstrating the efficacy of our methods for boosting accuracies over a\nrelatively short token horizon. Furthermore, our full 6.3T token dataset\nmatches DCLM on MMLU, but contains four times more unique real tokens than\nDCLM. This unlocks state-of-the-art training over a long token horizon: an 8B\nparameter model trained for 15T tokens, of which 7.2T came from our dataset, is\nbetter than the Llama 3.1 8B model: +5 on MMLU, +3.1 on ARC-Challenge, and +0.5\non average across ten diverse tasks. The dataset is available at\nhttps://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html", "paper_summary_zh": "\u6700\u8fd1\u7684 English Common Crawl \u8cc7\u6599\u96c6\uff0c\u4f8b\u5982 FineWeb-Edu \u548c DCLM\uff0c\u900f\u904e\u7a4d\u6975\u7684\u57fa\u65bc\u6a21\u578b\u7684\u7be9\u9078\uff0c\u7372\u5f97\u4e86\u986f\u8457\u7684\u57fa\u6e96\u6536\u76ca\uff0c\u4f46\u4ee3\u50f9\u662f\u79fb\u9664 90% \u7684\u8cc7\u6599\u3002\u9019\u9650\u5236\u4e86\u5b83\u5011\u9069\u7528\u65bc\u9577\u671f\u4ee3\u78bc\u8a13\u7df4\uff0c\u4f8b\u5982 Llama 3.1 \u7684 15T \u4ee3\u78bc\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u5982\u4f55\u900f\u904e\u5206\u985e\u5668\u96c6\u6210\u3001\u5408\u6210\u8cc7\u6599\u6539\u5beb\u548c\u6e1b\u5c11\u4f9d\u8cf4\u555f\u767c\u5f0f\u904e\u6ffe\u5668\uff0c\u5728\u6e96\u78ba\u5ea6\u548c\u8cc7\u6599\u6578\u91cf\u4e4b\u9593\u53d6\u5f97\u66f4\u597d\u7684\u6298\u8877\u3002\u5728\u91dd\u5c0d 1T \u4ee3\u78bc\u8a13\u7df4 8B \u53c3\u6578\u6a21\u578b\u6642\uff0c\u4f7f\u7528\u6211\u5011\u8cc7\u6599\u4e2d\u7684\u9ad8\u54c1\u8cea\u5b50\u96c6\uff0c\u5c07 MMLU \u63d0\u5347 5.6\uff0c\u9ad8\u65bc DCLM\uff0c\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u63d0\u5347\u6e96\u78ba\u5ea6\u65b9\u9762\u7684\u6548\u529b\uff0c\u4ee3\u78bc\u7bc4\u570d\u76f8\u5c0d\u8f03\u77ed\u3002\u6b64\u5916\uff0c\u6211\u5011\u5b8c\u6574\u7684 6.3T \u4ee3\u78bc\u8cc7\u6599\u96c6\u5728 MMLU \u4e0a\u8207 DCLM \u76f8\u7b26\uff0c\u4f46\u5305\u542b\u6bd4 DCLM \u591a\u56db\u500d\u7684\u7368\u7279\u771f\u5be6\u4ee3\u78bc\u3002\u9019\u89e3\u9396\u4e86\u5728\u9577\u671f\u4ee3\u78bc\u7bc4\u570d\u5167\u9032\u884c\u6700\u5148\u9032\u7684\u8a13\u7df4\uff1a\u91dd\u5c0d 15T \u4ee3\u78bc\u8a13\u7df4\u7684 8B \u53c3\u6578\u6a21\u578b\uff0c\u5176\u4e2d 7.2T \u4f86\u81ea\u6211\u5011\u7684\u8cc7\u6599\u96c6\uff0c\u512a\u65bc Llama 3.1 8B \u6a21\u578b\uff1aMMLU +5\uff0cARC-Challenge +3.1\uff0c\u4ee5\u53ca\u5728\u5341\u9805\u4e0d\u540c\u7684\u4efb\u52d9\u4e2d\u5e73\u5747 +0.5\u3002\u8cc7\u6599\u96c6\u53ef\u5728 https://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html \u53d6\u5f97", "author": "Dan Su et.al.", "authors": "Dan Su, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro", "id": "2412.02595v1", "paper_url": "http://arxiv.org/abs/2412.02595v1", "repo": "null"}}