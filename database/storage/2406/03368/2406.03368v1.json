{"2406.03368": {"publish_time": "2024-06-05", "title": "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models", "paper_summary": "Despite the widespread adoption of Large language models (LLMs), their\nremarkable capabilities remain limited to a few high-resource languages.\nAdditionally, many low-resource languages (e.g. African languages) are often\nevaluated only on basic text classification tasks due to the lack of\nappropriate or comprehensive benchmarks outside of high-resource languages. In\nthis paper, we introduce IrokoBench -- a human-translated benchmark dataset for\n16 typologically-diverse low-resource African languages covering three tasks:\nnatural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), and\nmulti-choice knowledge-based QA~(AfriMMLU). We use IrokoBench to evaluate\nzero-shot, few-shot, and translate-test settings~(where test sets are\ntranslated into English) across 10 open and four proprietary LLMs. Our\nevaluation reveals a significant performance gap between high-resource\nlanguages~(such as English and French) and low-resource African languages. We\nobserve a significant performance gap between open and proprietary models, with\nthe highest performing open model, Aya-101 only at 58\\% of the best-performing\nproprietary model GPT-4o performance. Machine translating the test set to\nEnglish before evaluation helped to close the gap for larger models that are\nEnglish-centric, like LLaMa 3 70B. These findings suggest that more efforts are\nneeded to develop and adapt LLMs for African languages.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u88ab\u5ee3\u6cdb\u63a1\u7528\uff0c\u5b83\u5011\u5353\u8d8a\u7684\u80fd\u529b\u4ecd\u50c5\u9650\u65bc\u5c11\u6578\u8cc7\u6e90\u8c50\u5bcc\u7684\u8a9e\u8a00\u3002\u6b64\u5916\uff0c\u8a31\u591a\u8cc7\u6e90\u8ca7\u4e4f\u7684\u8a9e\u8a00\uff08\u4f8b\u5982\u975e\u6d32\u8a9e\u8a00\uff09\u901a\u5e38\u50c5\u91dd\u5c0d\u57fa\u672c\u7684\u6587\u5b57\u5206\u985e\u4efb\u52d9\u9032\u884c\u8a55\u4f30\uff0c\u9019\u662f\u56e0\u70ba\u5728\u8cc7\u6e90\u8c50\u5bcc\u7684\u8a9e\u8a00\u4e4b\u5916\u7f3a\u4e4f\u9069\u7576\u6216\u5168\u9762\u7684\u57fa\u6e96\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 IrokoBench\uff0c\u9019\u662f\u4e00\u500b\u91dd\u5c0d 16 \u7a2e\u985e\u578b\u591a\u6a23\u7684\u8cc7\u6e90\u8ca7\u4e4f\u7684\u975e\u6d32\u8a9e\u8a00\u9032\u884c\u4eba\u5de5\u7ffb\u8b6f\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u6db5\u84cb\u4e09\u9805\u4efb\u52d9\uff1a\u81ea\u7136\u8a9e\u8a00\u63a8\u8ad6 (AfriXNLI)\u3001\u6578\u5b78\u63a8\u7406 (AfriMGSM) \u548c\u591a\u9078\u984c\u77e5\u8b58\u578b\u554f\u7b54 (AfriMMLU)\u3002\u6211\u5011\u4f7f\u7528 IrokoBench \u4f86\u8a55\u4f30\u96f6\u6b21\u5b78\u7fd2\u3001\u5c11\u6b21\u5b78\u7fd2\u548c\u7ffb\u8b6f\u6e2c\u8a66\u8a2d\u5b9a\uff08\u5176\u4e2d\u6e2c\u8a66\u96c6\u88ab\u7ffb\u8b6f\u6210\u82f1\u6587\uff09\u5728 10 \u500b\u958b\u653e\u539f\u59cb\u78bc\u548c\u56db\u500b\u5c08\u6709 LLM \u4e2d\u7684\u8868\u73fe\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u8cc7\u6e90\u8c50\u5bcc\u7684\u8a9e\u8a00\uff08\u4f8b\u5982\u82f1\u8a9e\u548c\u6cd5\u8a9e\uff09\u548c\u8cc7\u6e90\u8ca7\u4e4f\u7684\u975e\u6d32\u8a9e\u8a00\u4e4b\u9593\u5b58\u5728\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\u3002\u6211\u5011\u89c0\u5bdf\u5230\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u548c\u5c08\u6709\u6a21\u578b\u4e4b\u9593\u5b58\u5728\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\uff0c\u6548\u80fd\u6700\u9ad8\u7684\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b Aya-101 \u50c5\u9054\u5230\u6548\u80fd\u6700\u4f73\u7684\u5c08\u6709\u6a21\u578b GPT-4o \u6548\u80fd\u7684 58%\u3002\u5728\u8a55\u4f30\u4e4b\u524d\u5c07\u6e2c\u8a66\u96c6\u6a5f\u5668\u7ffb\u8b6f\u6210\u82f1\u6587\u6709\u52a9\u65bc\u7e2e\u5c0f\u4ee5\u82f1\u8a9e\u70ba\u4e2d\u5fc3\u7684\u8f03\u5927\u578b\u6a21\u578b\uff08\u4f8b\u5982 LLaMa 3 70B\uff09\u7684\u5dee\u8ddd\u3002\u9019\u4e9b\u767c\u73fe\u8868\u660e\uff0c\u9700\u8981\u4ed8\u51fa\u66f4\u591a\u52aa\u529b\u4f86\u958b\u767c\u548c\u8abf\u6574\u9069\u7528\u65bc\u975e\u6d32\u8a9e\u8a00\u7684 LLM\u3002", "author": "David Ifeoluwa Adelani et.al.", "authors": "David Ifeoluwa Adelani, Jessica Ojo, Israel Abebe Azime, Jian Yun Zhuang, Jesujoba O. Alabi, Xuanli He, Millicent Ochieng, Sara Hooker, Andiswa Bukula, En-Shiun Annie Lee, Chiamaka Chukwuneke, Happy Buzaaba, Blessing Sibanda, Godson Kalipe, Jonathan Mukiibi, Salomon Kabongo, Foutse Yuehgoh, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Tadesse Kebede Guge, Pontus Stenetorp", "id": "2406.03368v1", "paper_url": "http://arxiv.org/abs/2406.03368v1", "repo": "null"}}