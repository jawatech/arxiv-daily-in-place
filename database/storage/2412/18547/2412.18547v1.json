{"2412.18547": {"publish_time": "2024-12-24", "title": "Token-Budget-Aware LLM Reasoning", "paper_summary": "Reasoning is critical for large language models (LLMs) to excel in a wide\nrange of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM\nperformance by decomposing problems into intermediate steps, they also incur\nsignificant overhead in token usage, leading to increased costs. We find that\nthe reasoning process of current LLMs is unnecessarily lengthy and it can be\ncompressed by including a reasonable token budget in the prompt, but the choice\nof token budget plays a crucial role in the actual compression effectiveness.\nWe then propose a token-budget-aware LLM reasoning framework, which dynamically\nestimates token budgets for different problems based on reasoning complexity\nand uses the estimated token budgets to guide the reasoning process.\nExperiments show that our method effectively reduces token costs in CoT\nreasoning with only a slight performance reduction, offering a practical\nsolution to balance efficiency and accuracy in LLM reasoning. Code:\nhttps://github.com/GeniusHTX/TALE.", "paper_summary_zh": "\u63a8\u7406\u5c0d\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5ee3\u6cdb\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u50cf\u601d\u60f3\u93c8 (CoT) \u63a8\u7406\u7b49\u65b9\u6cd5\u900f\u904e\u5c07\u554f\u984c\u5206\u89e3\u6210\u4e2d\u9593\u6b65\u9a5f\u4f86\u589e\u5f37 LLM \u6548\u80fd\uff0c\u4f46\u5b83\u5011\u4e5f\u6703\u9020\u6210\u4ee3\u5e63\u4f7f\u7528\u4e0a\u7684\u986f\u8457\u8ca0\u64d4\uff0c\u5c0e\u81f4\u6210\u672c\u589e\u52a0\u3002\u6211\u5011\u767c\u73fe\uff0c\u76ee\u524d LLM \u7684\u63a8\u7406\u904e\u7a0b\u904e\u65bc\u5197\u9577\uff0c\u800c\u4e14\u53ef\u4ee5\u900f\u904e\u5728\u63d0\u793a\u4e2d\u5305\u542b\u5408\u7406\u7684\u4ee3\u5e63\u9810\u7b97\u4f86\u58d3\u7e2e\uff0c\u4f46\u4ee3\u5e63\u9810\u7b97\u7684\u9078\u64c7\u5728\u5be6\u969b\u58d3\u7e2e\u6548\u679c\u4e2d\u626e\u6f14\u95dc\u9375\u89d2\u8272\u3002\u6211\u5011\u63a5\u8457\u63d0\u51fa\u4e00\u500b\u5177\u5099\u4ee3\u5e63\u9810\u7b97\u611f\u77e5\u529f\u80fd\u7684 LLM \u63a8\u7406\u67b6\u69cb\uff0c\u5b83\u6703\u6839\u64da\u63a8\u7406\u8907\u96dc\u5ea6\u52d5\u614b\u4f30\u8a08\u4e0d\u540c\u554f\u984c\u7684\u4ee3\u5e63\u9810\u7b97\uff0c\u4e26\u4f7f\u7528\u4f30\u8a08\u7684\u4ee3\u5e63\u9810\u7b97\u4f86\u5f15\u5c0e\u63a8\u7406\u904e\u7a0b\u3002\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u4e86 CoT \u63a8\u7406\u4e2d\u7684\u4ee3\u5e63\u6210\u672c\uff0c\u6548\u80fd\u50c5\u7565\u5fae\u4e0b\u964d\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u5728 LLM \u63a8\u7406\u4e2d\u5e73\u8861\u6548\u7387\u8207\u7cbe\u78ba\u5ea6\u7684\u5be6\u7528\u89e3\u6c7a\u65b9\u6848\u3002\u7a0b\u5f0f\u78bc\uff1ahttps://github.com/GeniusHTX/TALE\u3002", "author": "Tingxu Han et.al.", "authors": "Tingxu Han, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen, Zhenting Wang", "id": "2412.18547v1", "paper_url": "http://arxiv.org/abs/2412.18547v1", "repo": "https://github.com/geniushtx/tale"}}