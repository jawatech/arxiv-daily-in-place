
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-06**|**GREEN: Generative Radiology Report Evaluation and Error Notation**|Sophie Ostmeier et.al.|[2405.03595v1](http://arxiv.org/abs/2405.03595v1)|null|
|**2024-05-06**|**RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for Brain Tumour Detection**|Thennarasi Balakrishnan et.al.|[2405.03541v1](http://arxiv.org/abs/2405.03541v1)|[link](https://github.com/thensib/repvgg-gelan)|
|**2024-05-06**|**A Lightweight Neural Architecture Search Model for Medical Image Classification**|Lunchen Xie et.al.|[2405.03462v1](http://arxiv.org/abs/2405.03462v1)|null|
|**2024-05-06**|**Automated Computation of Therapies Using Failure Mode and Effects Analysis in the Medical Domain**|Malte Luttermann et.al.|[2405.03406v1](http://arxiv.org/abs/2405.03406v1)|null|
|**2024-05-06**|**MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline**|Mohamed Yaseen Jabarulla et.al.|[2405.03359v1](http://arxiv.org/abs/2405.03359v1)|[link](https://github.com/yaseen28/meddoc-bot)|
|**2024-05-06**|**Artificial Intelligence in the Autonomous Navigation of Endovascular Interventions: A Systematic Review**|Harry Robertshaw et.al.|[2405.03305v1](http://arxiv.org/abs/2405.03305v1)|null|
|**2024-05-06**|**Advancing Multimodal Medical Capabilities of Gemini**|Lin Yang et.al.|[2405.03162v1](http://arxiv.org/abs/2405.03162v1)|null|
|**2024-05-06**|**Automatic Ultrasound Curve Angle Measurement via Affinity Clustering for Adolescent Idiopathic Scoliosis Evaluation**|Yihao Zhou et.al.|[2405.03141v2](http://arxiv.org/abs/2405.03141v2)|null|
|**2024-05-05**|**RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation**|Zelei Cheng et.al.|[2405.03064v1](http://arxiv.org/abs/2405.03064v1)|null|
|**2024-05-05**|**AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for enhanced skin lesion segmentation**|Viet-Thanh Nguyen et.al.|[2405.03011v1](http://arxiv.org/abs/2405.03011v1)|null|
|**2024-05-05**|**Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents**|Junkai Li et.al.|[2405.02957v1](http://arxiv.org/abs/2405.02957v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|null|
|**2024-05-04**|**The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses**|Jordyn Young et.al.|[2405.02711v1](http://arxiv.org/abs/2405.02711v1)|null|
|**2024-05-04**|**MedPromptExtract (Medical Data Extraction Tool): Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering**|Roomani Srivastava et.al.|[2405.02664v1](http://arxiv.org/abs/2405.02664v1)|null|
|**2024-05-04**|**A Conformal Prediction Score that is Robust to Label Noise**|Coby Penso et.al.|[2405.02648v1](http://arxiv.org/abs/2405.02648v1)|null|
|**2024-05-04**|**Explainable Interface for Human-Autonomy Teaming: A Survey**|Xiangqi Kong et.al.|[2405.02583v1](http://arxiv.org/abs/2405.02583v1)|null|
|**2024-05-04**|**A Literature Review and Framework for Human Evaluation of Generative Large Language Models in Healthcare**|Thomas Yu Chow Tam et.al.|[2405.02559v1](http://arxiv.org/abs/2405.02559v1)|null|
|**2024-05-03**|**Spatio-Temporal SwinMAE: A Swin Transformer based Multiscale Representation Learner for Temporal Satellite Imagery**|Yohei Nakayama et.al.|[2405.02512v1](http://arxiv.org/abs/2405.02512v1)|null|
|**2024-05-03**|**Implicit Neural Representations for Robust Joint Sparse-View CT Reconstruction**|Jiayang Shi et.al.|[2405.02509v1](http://arxiv.org/abs/2405.02509v1)|null|
|**2024-05-03**|**A Survey of Few-Shot Learning for Biomedical Time Series**|Chenqi Li et.al.|[2405.02485v1](http://arxiv.org/abs/2405.02485v1)|null|
|**2024-05-03**|**Generalizing Orthogonalization for Models with Non-linearities**|David Rügamer et.al.|[2405.02475v1](http://arxiv.org/abs/2405.02475v1)|null|
|**2024-05-03**|**Model-based reinforcement learning for protein backbone design**|Frederic Renard et.al.|[2405.01983v1](http://arxiv.org/abs/2405.01983v1)|null|
|**2024-05-03**|**Aloe: A Family of Fine-tuned Open Healthcare LLMs**|Ashwin Kumar Gururajan et.al.|[2405.01886v1](http://arxiv.org/abs/2405.01886v1)|null|
|**2024-05-03**|**Millimeter Wave Radar-based Human Activity Recognition for Healthcare Monitoring Robot**|Zhanzhong Gu et.al.|[2405.01882v1](http://arxiv.org/abs/2405.01882v1)|null|
|**2024-05-03**|**Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features**|Chuanbo Hu et.al.|[2405.01799v1](http://arxiv.org/abs/2405.01799v1)|null|
|**2024-05-02**|**Interpretable Vital Sign Forecasting with Model Agnostic Attention Maps**|Yuwei Liu et.al.|[2405.01714v2](http://arxiv.org/abs/2405.01714v2)|null|
|**2024-05-02**|**Long Tail Image Generation Through Feature Space Augmentation and Iterated Learning**|Rafael Elberg et.al.|[2405.01705v1](http://arxiv.org/abs/2405.01705v1)|[link](https://github.com/sugarfreemanatee/feature-space-augmentation-and-iterated-learning)|
|**2024-05-02**|**Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models**|Hye Sun Yun et.al.|[2405.01686v1](http://arxiv.org/abs/2405.01686v1)|[link](https://github.com/hyesunyun/llm-meta-analysis)|
|**2024-05-02**|**Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language**|Liam Hazan et.al.|[2405.01682v1](http://arxiv.org/abs/2405.01682v1)|null|
|**2024-05-02**|**Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning**|Théo Moutakanni et.al.|[2405.01469v1](http://arxiv.org/abs/2405.01469v1)|null|
|**2024-05-02**|**DMON: A Simple yet Effective Approach for Argument Structure Learning**|Wei Sun et.al.|[2405.01216v1](http://arxiv.org/abs/2405.01216v1)|[link](https://github.com/vrcmf/dmon)|
|**2024-05-01**|**Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis**|Prateek Verma et.al.|[2405.00876v1](http://arxiv.org/abs/2405.00876v1)|null|
|**2024-05-01**|**"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**|Sunnie S. Y. Kim et.al.|[2405.00623v1](http://arxiv.org/abs/2405.00623v1)|null|
|**2024-05-01**|**Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning**|Huan Xu et.al.|[2405.00461v1](http://arxiv.org/abs/2405.00461v1)|null|
|**2024-05-01**|**A Careful Examination of Large Language Model Performance on Grade School Arithmetic**|Hugh Zhang et.al.|[2405.00332v3](http://arxiv.org/abs/2405.00332v3)|null|
|**2024-05-01**|**Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition**|Dongyuan Li et.al.|[2405.00307v1](http://arxiv.org/abs/2405.00307v1)|[link](https://github.com/clearloveyuan/after)|
|**2024-04-30**|**Quantifying Nematodes through Images: Datasets, Models, and Baselines of Deep Learning**|Zhipeng Yuan et.al.|[2404.19748v1](http://arxiv.org/abs/2404.19748v1)|null|
|**2024-04-30**|**Data Set Terminology of Artificial Intelligence in Medicine: A Historical Review and Recommendation**|Shannon L. Walston et.al.|[2404.19303v1](http://arxiv.org/abs/2404.19303v1)|null|
|**2024-04-29**|**Text and Audio Simplification: Human vs. ChatGPT**|Gondy Leroy et.al.|[2405.01592v1](http://arxiv.org/abs/2405.01592v1)|null|
|**2024-04-29**|**ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization**|Hong Nguyen et.al.|[2404.18831v1](http://arxiv.org/abs/2404.18831v1)|[link](https://github.com/hong7cong/conpro)|
|**2024-04-29**|**Decoding Radiologists' Intentions: A Novel System for Accurate Region Identification in Chest X-ray Image Analysis**|Akash Awasthi et.al.|[2404.18981v1](http://arxiv.org/abs/2404.18981v1)|null|
|**2024-04-29**|**Foundations of Multisensory Artificial Intelligence**|Paul Pu Liang et.al.|[2404.18976v1](http://arxiv.org/abs/2404.18976v1)|null|
|**2024-04-29**|**M3H: Multimodal Multitask Machine Learning for Healthcare**|Dimitris Bertsimas et.al.|[2404.18975v1](http://arxiv.org/abs/2404.18975v1)|null|
|**2024-04-29**|**Real Time Multi Organ Classification on Computed Tomography Images**|Halid Ziya Yerebakan et.al.|[2404.18731v1](http://arxiv.org/abs/2404.18731v1)|null|
|**2024-04-29**|**Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model**|Seonhee Cho et.al.|[2405.01591v1](http://arxiv.org/abs/2405.01591v1)|null|
|**2024-04-29**|**Machine Learning for Quantum Computing Specialists**|Daniel Goldsmith et.al.|[2404.18555v1](http://arxiv.org/abs/2404.18555v1)|null|
|**2024-04-29**|**GPT-4 passes most of the 297 written Polish Board Certification Examinations**|Jakub Pokrywka et.al.|[2405.01589v1](http://arxiv.org/abs/2405.01589v1)|null|
|**2024-04-29**|**On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**|Usevalad Milasheuski. Luca Barbieri et.al.|[2404.18519v2](http://arxiv.org/abs/2404.18519v2)|null|
|**2024-04-29**|**Research on Intelligent Aided Diagnosis System of Medical Image Based on Computer Deep Learning**|Jiajie Yuan et.al.|[2404.18419v1](http://arxiv.org/abs/2404.18419v1)|null|
|**2024-04-29**|**Capabilities of Gemini Models in Medicine**|Khaled Saab et.al.|[2404.18416v2](http://arxiv.org/abs/2404.18416v2)|null|
|**2024-04-28**|**Permutation-equivariant quantum convolutional neural networks**|Sreetama Das et.al.|[2404.18198v1](http://arxiv.org/abs/2404.18198v1)|null|
|**2024-04-27**|**MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch**|Nadia Saeed et.al.|[2404.17999v1](http://arxiv.org/abs/2404.17999v1)|[link](https://github.com/nadiasaeed/medifact-mediqa-corr-2024)|
|**2024-04-27**|**MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning**|Nadia Saeed et.al.|[2405.01583v1](http://arxiv.org/abs/2405.01583v1)|null|
|**2024-04-27**|**Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**|Himanshu Pandey et.al.|[2404.17977v1](http://arxiv.org/abs/2404.17977v1)|null|
|**2024-04-27**|**Pre-training on High Definition X-ray Images: An Experimental Study**|Xiao Wang et.al.|[2404.17926v1](http://arxiv.org/abs/2404.17926v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2024-04-27**|**SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models**|Manav Nitin Kapadnis et.al.|[2404.17912v1](http://arxiv.org/abs/2404.17912v1)|null|
|**2024-04-27**|**GLIMS: Attention-Guided Lightweight Multi-Scale Hybrid Network for Volumetric Semantic Segmentation**|Ziya Ata Yazıcı et.al.|[2404.17854v1](http://arxiv.org/abs/2404.17854v1)|[link](https://github.com/yaziciz/GLIMS)|
|**2024-04-27**|**Multimodal Fusion on Low-quality Data: A Comprehensive Survey**|Qingyang Zhang et.al.|[2404.18947v2](http://arxiv.org/abs/2404.18947v2)|null|
|**2024-04-27**|**Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A Comparative Study**|Dou Liu et.al.|[2405.00728v1](http://arxiv.org/abs/2405.00728v1)|null|
|**2024-04-27**|**UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis**|Parth Vashisht et.al.|[2404.17749v1](http://arxiv.org/abs/2404.17749v1)|[link](https://github.com/parth166/m3g-clinicaldermatology)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v2](http://arxiv.org/abs/2404.17454v2)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**|Muhammad Rizwan et.al.|[2404.17183v1](http://arxiv.org/abs/2404.17183v1)|null|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant**|Olli Järviniemi et.al.|[2405.01576v1](http://arxiv.org/abs/2405.01576v1)|null|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Report on Candidate Computational Indicators for Conscious Valenced Experience**|Andres Campero et.al.|[2404.16696v1](http://arxiv.org/abs/2404.16696v1)|null|
|**2024-04-25**|**Large Language Models in Healthcare: A Comprehensive Benchmark**|Andrew Liu et.al.|[2405.00716v1](http://arxiv.org/abs/2405.00716v1)|null|
|**2024-04-25**|**Utilizing Large Language Models to Identify Reddit Users Considering Vaping Cessation for Digital Interventions**|Sai Krishna Revanth Vuruma et.al.|[2404.17607v1](http://arxiv.org/abs/2404.17607v1)|null|
|**2024-04-25**|**Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation**|Hanyin Wang et.al.|[2405.00715v1](http://arxiv.org/abs/2405.00715v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|[link](https://github.com/hiyouga/llama-factory)|
|**2024-04-25**|**DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**|Zhihao Shuai et.al.|[2404.16474v1](http://arxiv.org/abs/2404.16474v1)|null|
|**2024-04-25**|**Light-weight Retinal Layer Segmentation with Global Reasoning**|Xiang He et.al.|[2404.16346v1](http://arxiv.org/abs/2404.16346v1)|null|
|**2024-04-25**|**Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**|Hedda Cohen Indelman et.al.|[2404.16325v1](http://arxiv.org/abs/2404.16325v1)|null|
|**2024-04-25**|**LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**|Saranya Krishnamoorthy et.al.|[2404.16294v1](http://arxiv.org/abs/2404.16294v1)|[link](https://github.com/inqbator-evicore/llm_section_identifiers)|
|**2024-04-24**|**Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**|Divyansh Agarwal et.al.|[2404.16251v2](http://arxiv.org/abs/2404.16251v2)|null|
|**2024-04-24**|**ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**|Sarala Naidu et.al.|[2404.16183v1](http://arxiv.org/abs/2404.16183v1)|null|
|**2024-04-24**|**Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**|Badri Narayana Patro et.al.|[2404.16112v1](http://arxiv.org/abs/2404.16112v1)|[link](https://github.com/badripatro/mamba360)|
|**2024-04-24**|**Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**|Xuxin Chen et.al.|[2404.15946v1](http://arxiv.org/abs/2404.15946v1)|null|
|**2024-04-24**|**Assessing The Potential Of Mid-Sized Language Models For Clinical QA**|Elliot Bolton et.al.|[2404.15894v1](http://arxiv.org/abs/2404.15894v1)|null|
|**2024-04-24**|**Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**|Hong-Jun Yoon et.al.|[2404.16080v1](http://arxiv.org/abs/2404.16080v1)|null|
|**2024-04-24**|**A Hybrid Probabilistic Battery Health Management Approach for Robust Inspection Drone Operations**|Jokin Alcibar et.al.|[2405.00055v1](http://arxiv.org/abs/2405.00055v1)|null|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887v1](http://arxiv.org/abs/2404.16887v1)|null|
|**2024-04-23**|**Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**|Rayner Kay Jin Tan et.al.|[2404.16885v1](http://arxiv.org/abs/2404.16885v1)|null|
|**2024-04-23**|**PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**|Shashi Kant Gupta et.al.|[2404.15549v2](http://arxiv.org/abs/2404.15549v2)|null|
|**2024-04-23**|**Multi-scale Intervention Planning based on Generative Design**|Ioannis Kavouras et.al.|[2404.15492v1](http://arxiv.org/abs/2404.15492v1)|null|
|**2024-04-23**|**IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**|Jean-Philippe Corbeil et.al.|[2404.15488v1](http://arxiv.org/abs/2404.15488v1)|[link](https://github.com/microsoft/iryonlp-mediqa-corr-2024)|
|**2024-04-23**|**Interactive Analysis of LLMs using Meaningful Counterfactuals**|Furui Cheng et.al.|[2405.00708v1](http://arxiv.org/abs/2405.00708v1)|null|
|**2024-04-23**|**Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**|Karen Roberts-Licklider et.al.|[2404.15418v1](http://arxiv.org/abs/2404.15418v1)|null|
|**2024-04-23**|**CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**|Jingyang Lin et.al.|[2404.15272v3](http://arxiv.org/abs/2404.15272v3)|null|
|**2024-04-23**|**A review of deep learning-based information fusion techniques for multimodal medical image classification**|Yihao Li et.al.|[2404.15022v1](http://arxiv.org/abs/2404.15022v1)|null|
|**2024-04-23**|**Clustering of timed sequences -- Application to the analysis of care pathways**|Thomas Guyet et.al.|[2404.15379v1](http://arxiv.org/abs/2404.15379v1)|null|
|**2024-04-23**|**Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**|Qiao Deng et.al.|[2404.14750v1](http://arxiv.org/abs/2404.14750v1)|null|
|**2024-04-22**|**DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**|Sergio Burdisso et.al.|[2404.14463v1](http://arxiv.org/abs/2404.14463v1)|null|
|**2024-04-22**|**Adaptive Collaboration Strategy for LLMs in Medical Decision Making**|Yubin Kim et.al.|[2404.15155v1](http://arxiv.org/abs/2404.15155v1)|[link](https://github.com/mitmedialab/mdagents)|
|**2024-04-21**|**A Nasal Cytology Dataset for Object Detection and Deep Learning**|Mauro Camporeale et.al.|[2404.13745v1](http://arxiv.org/abs/2404.13745v1)|null|

#### Abstracts
##### **GREEN: Generative Radiology Report Evaluation and Error Notation**
2405.03595v1 by Sophie Ostmeier,Justin Xu,Zhihong Chen,Maya Varma,Louis Blankemeier,Christian Bluethgen,Arne Edward Michalson,Michael Moseley,Curtis Langlotz,Akshay S Chaudhari,Jean-Benoit Delbrouck

Evaluating radiology reports is a challenging problem as factual correctness
is extremely important due to the need for accurate medical communication about
medical images. Existing automatic evaluation metrics either suffer from
failing to consider factual correctness (e.g., BLEU and ROUGE) or are limited
in their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we
introduce GREEN (Generative Radiology Report Evaluation and Error Notation), a
radiology report generation metric that leverages the natural language
understanding of language models to identify and explain clinically significant
errors in candidate reports, both quantitatively and qualitatively. Compared to
current metrics, GREEN offers: 1) a score aligned with expert preferences, 2)
human interpretable explanations of clinically significant errors, enabling
feedback loops with end-users, and 3) a lightweight open-source method that
reaches the performance of commercial counterparts. We validate our GREEN
metric by comparing it to GPT-4, as well as to error counts of 6 experts and
preferences of 2 experts. Our method demonstrates not only higher correlation
with expert error counts, but simultaneously higher alignment with expert
preferences when compared to previous approaches."

摘要：

##### **RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for Brain Tumour Detection**
2405.03541v1 by Thennarasi Balakrishnan,Sandeep Singh Sengar

Object detection algorithms particularly those based on YOLO have
demonstrated remarkable efficiency in balancing speed and accuracy. However,
their application in brain tumour detection remains underexplored. This study
proposes RepVGG-GELAN, a novel YOLO architecture enhanced with RepVGG, a
reparameterized convolutional approach for object detection tasks particularly
focusing on brain tumour detection within medical images. RepVGG-GELAN
leverages the RepVGG architecture to improve both speed and accuracy in
detecting brain tumours. Integrating RepVGG into the YOLO framework aims to
achieve a balance between computational efficiency and detection performance.
This study includes a spatial pyramid pooling-based Generalized Efficient Layer
Aggregation Network (GELAN) architecture which further enhances the capability
of RepVGG. Experimental evaluation conducted on a brain tumour dataset
demonstrates the effectiveness of RepVGG-GELAN surpassing existing RCS-YOLO in
terms of precision and speed. Specifically, RepVGG-GELAN achieves an increased
precision of 4.91% and an increased AP50 of 2.54% over the latest existing
approach while operating at 240.7 GFLOPs. The proposed RepVGG-GELAN with GELAN
architecture presents promising results establishing itself as a
state-of-the-art solution for accurate and efficient brain tumour detection in
medical images. The implementation code is publicly available at
https://github.com/ThensiB/RepVGG-GELAN.

摘要：

##### **A Lightweight Neural Architecture Search Model for Medical Image Classification**
2405.03462v1 by Lunchen Xie,Eugenio Lomurno,Matteo Gambella,Danilo Ardagna,Manuel Roveri,Matteo Matteucci,Qingjiang Shi

Accurate classification of medical images is essential for modern
diagnostics. Deep learning advancements led clinicians to increasingly use
sophisticated models to make faster and more accurate decisions, sometimes
replacing human judgment. However, model development is costly and repetitive.
Neural Architecture Search (NAS) provides solutions by automating the design of
deep learning architectures. This paper presents ZO-DARTS+, a differentiable
NAS algorithm that improves search efficiency through a novel method of
generating sparse probabilities by bi-level optimization. Experiments on five
public medical datasets show that ZO-DARTS+ matches the accuracy of
state-of-the-art solutions while reducing search times by up to three times.

摘要：

##### **Automated Computation of Therapies Using Failure Mode and Effects Analysis in the Medical Domain**
2405.03406v1 by Malte Luttermann,Edgar Baake,Juljan Bouchagiar,Benjamin Gebel,Philipp Grüning,Dilini Manikwadura,Franziska Schollemann,Elisa Teifke,Philipp Rostalski,Ralf Möller

Failure mode and effects analysis (FMEA) is a systematic approach to identify
and analyse potential failures and their effects in a system or process. The
FMEA approach, however, requires domain experts to manually analyse the FMEA
model to derive risk-reducing actions that should be applied. In this paper, we
provide a formal framework to allow for automatic planning and acting in FMEA
models. More specifically, we cast the FMEA model into a Markov decision
process which can then be solved by existing solvers. We show that the FMEA
approach can not only be used to support medical experts during the modelling
process but also to automatically derive optimal therapies for the treatment of
patients.

摘要：

##### **MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline**
2405.03359v1 by Mohamed Yaseen Jabarulla,Steffen Oeltze-Jafra,Philipp Beerbaum,Theodor Uden

This research focuses on evaluating the non-commercial open-source large
language models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their
efficacy in interpreting medical guidelines saved in PDF format. As a specific
test scenario, we applied these models to the guidelines for hypertension in
children and adolescents provided by the European Society of Cardiology (ESC).
Leveraging Streamlit, a Python library, we developed a user-friendly medical
document chatbot tool (MedDoc-Bot). This tool enables authorized users to
upload PDF files and pose questions, generating interpretive responses from
four locally stored LLMs. A pediatric expert provides a benchmark for
evaluation by formulating questions and responses extracted from the ESC
guidelines. The expert rates the model-generated responses based on their
fidelity and relevance. Additionally, we evaluated the METEOR and chrF metric
scores to assess the similarity of model responses to reference answers. Our
study found that Llama-2 and Mistral performed well in metrics evaluation.
However, Llama-2 was slower when dealing with text and tabular data. In our
human evaluation, we observed that responses created by Mistral, Meditron, and
Llama-2 exhibited reasonable fidelity and relevance. This study provides
valuable insights into the strengths and limitations of LLMs for future
developments in medical document interpretation. Open-Source Code:
https://github.com/yaseen28/MedDoc-Bot

摘要：

##### **Artificial Intelligence in the Autonomous Navigation of Endovascular Interventions: A Systematic Review**
2405.03305v1 by Harry Robertshaw,Lennart Karstensen,Benjamin Jackson,Hadi Sadati,Kawal Rhode,Sebastien Ourselin,Alejandro Granados,Thomas C Booth

Purpose: Autonomous navigation of devices in endovascular interventions can
decrease operation times, improve decision-making during surgery, and reduce
operator radiation exposure while increasing access to treatment. This
systematic review explores recent literature to assess the impact, challenges,
and opportunities artificial intelligence (AI) has for the autonomous
endovascular intervention navigation.
  Methods: PubMed and IEEEXplore databases were queried. Eligibility criteria
included studies investigating the use of AI in enabling the autonomous
navigation of catheters/guidewires in endovascular interventions. Following
PRISMA, articles were assessed using QUADAS-2. PROSPERO: CRD42023392259.
  Results: Among 462 studies, fourteen met inclusion criteria. Reinforcement
learning (9/14, 64%) and learning from demonstration (7/14, 50%) were used as
data-driven models for autonomous navigation. Studies predominantly utilised
physical phantoms (10/14, 71%) and in silico (4/14, 29%) models. Experiments
within or around the blood vessels of the heart were reported by the majority
of studies (10/14, 71%), while simple non-anatomical vessel platforms were used
in three studies (3/14, 21%), and the porcine liver venous system in one study.
We observed that risk of bias and poor generalisability were present across
studies. No procedures were performed on patients in any of the studies
reviewed. Studies lacked patient selection criteria, reference standards, and
reproducibility, resulting in low clinical evidence levels.
  Conclusions: AI's potential in autonomous endovascular navigation is
promising, but in an experimental proof-of-concept stage, with a technology
readiness level of 3. We highlight that reference standards with
well-identified performance metrics are crucial to allow for comparisons of
data-driven algorithms proposed in the years to come.

摘要：

##### **Advancing Multimodal Medical Capabilities of Gemini**
2405.03162v1 by Lin Yang,Shawn Xu,Andrew Sellergren,Timo Kohlberger,Yuchen Zhou,Ira Ktena,Atilla Kiraly,Faruk Ahmed,Farhad Hormozdiari,Tiam Jaroensri,Eric Wang,Ellery Wulczyn,Fayaz Jamil,Theo Guidroz,Chuck Lau,Siyuan Qiao,Yun Liu,Akshay Goel,Kendall Park,Arnav Agharwal,Nick George,Yang Wang,Ryutaro Tanno,David G. T. Barrett,Wei-Hung Weng,S. Sara Mahdavi,Khaled Saab,Tao Tu,Sreenivasa Raju Kalidindi,Mozziyar Etemadi,Jorge Cuadros,Gregory Sorensen,Yossi Matias,Katherine Chou,Greg Corrado,Joelle Barral,Shravya Shetty,David Fleet,S. M. Ali Eslami,Daniel Tse,Shruthi Prabhakara,Cory McLean,Dave Steiner,Rory Pilgrim,Christopher Kelly,Shekoofeh Azizi,Daniel Golden

Many clinical tasks require an understanding of specialized data, such as
medical images and genomics, which is not typically found in general-purpose
large multimodal models. Building upon Gemini's multimodal models, we develop
several models within the new Med-Gemini family that inherit core capabilities
of Gemini and are optimized for medical use via fine-tuning with 2D and 3D
radiology, histopathology, ophthalmology, dermatology and genomic data.
Med-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report
generation based on expert evaluation, exceeding previous best results across
two separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of
AI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as
"equivalent or better" than the original radiologists' reports. We demonstrate
the first ever large multimodal model-based report generation for 3D computed
tomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered
clinically acceptable, although additional research is needed to meet expert
radiologist reporting quality. Beyond report generation, Med-Gemini-2D
surpasses the previous best performance in CXR visual question answering (VQA)
and performs well in CXR classification and radiology VQA, exceeding SoTA or
baselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology
image classification, Med-Gemini-2D surpasses baselines across 18 out of 20
tasks and approaches task-specific model performance. Beyond imaging,
Med-Gemini-Polygenic outperforms the standard linear polygenic risk score-based
approach for disease risk prediction and generalizes to genetically correlated
diseases for which it has never been trained. Although further development and
evaluation are necessary in the safety-critical medical domain, our results
highlight the potential of Med-Gemini across a wide range of medical tasks.

摘要：

##### **Automatic Ultrasound Curve Angle Measurement via Affinity Clustering for Adolescent Idiopathic Scoliosis Evaluation**
2405.03141v2 by Yihao Zhou,Timothy Tin-Yan Lee,Kelly Ka-Lee Lai,Chonglin Wu,Hin Ting Lau,De Yang,Chui-Yi Chan,Winnie Chiu-Wing Chu,Jack Chun-Yiu Cheng,Tsz-Ping Lam,Yong-Ping Zheng

The current clinical gold standard for evaluating adolescent idiopathic
scoliosis (AIS) is X-ray radiography, using Cobb angle measurement. However,
the frequent monitoring of the AIS progression using X-rays poses a challenge
due to the cumulative radiation exposure. Although 3D ultrasound has been
validated as a reliable and radiation-free alternative for scoliosis
assessment, the process of measuring spinal curvature is still carried out
manually. Consequently, there is a considerable demand for a fully automatic
system that can locate bony landmarks and perform angle measurements. To this
end, we introduce an estimation model for automatic ultrasound curve angle
(UCA) measurement. The model employs a dual-branch network to detect candidate
landmarks and perform vertebra segmentation on ultrasound coronal images. An
affinity clustering strategy is utilized within the vertebral segmentation area
to illustrate the affinity relationship between candidate landmarks.
Subsequently, we can efficiently perform line delineation from a clustered
affinity map for UCA measurement. As our method is specifically designed for
UCA calculation, this method outperforms other state-of-the-art methods for
landmark and line detection tasks. The high correlation between the automatic
UCA and Cobb angle (R$^2$=0.858) suggests that our proposed method can
potentially replace manual UCA measurement in ultrasound scoliosis assessment.

摘要：

##### **RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation**
2405.03064v1 by Zelei Cheng,Xian Wu,Jiahao Yu,Sabrina Yang,Gang Wang,Xinyu Xing

Deep reinforcement learning (DRL) is playing an increasingly important role
in real-world applications. However, obtaining an optimally performing DRL
agent for complex tasks, especially with sparse rewards, remains a significant
challenge. The training of a DRL agent can be often trapped in a bottleneck
without further progress. In this paper, we propose RICE, an innovative
refining scheme for reinforcement learning that incorporates explanation
methods to break through the training bottlenecks. The high-level idea of RICE
is to construct a new initial state distribution that combines both the default
initial states and critical states identified through explanation methods,
thereby encouraging the agent to explore from the mixed initial states. Through
careful design, we can theoretically guarantee that our refining scheme has a
tighter sub-optimality bound. We evaluate RICE in various popular RL
environments and real-world applications. The results demonstrate that RICE
significantly outperforms existing refining schemes in enhancing agent
performance.

摘要：

##### **AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for enhanced skin lesion segmentation**
2405.03011v1 by Viet-Thanh Nguyen,Van-Truong Pham,Thi-Thao Tran

Skin lesion segmentation is a critical task in computer-aided diagnosis
systems for dermatological diseases. Accurate segmentation of skin lesions from
medical images is essential for early detection, diagnosis, and treatment
planning. In this paper, we propose a new model for skin lesion segmentation
namely AC-MambaSeg, an enhanced model that has the hybrid CNN-Mamba backbone,
and integrates advanced components such as Convolutional Block Attention Module
(CBAM), Attention Gate, and Selective Kernel Bottleneck. AC-MambaSeg leverages
the Vision Mamba framework for efficient feature extraction, while CBAM and
Selective Kernel Bottleneck enhance its ability to focus on informative regions
and suppress background noise. We evaluate the performance of AC-MambaSeg on
diverse datasets of skin lesion images including ISIC-2018 and PH2; then
compare it against existing segmentation methods. Our model shows promising
potential for improving computer-aided diagnosis systems and facilitating early
detection and treatment of dermatological diseases. Our source code will be
made available at: https://github.com/vietthanh2710/AC-MambaSeg.

摘要：

##### **Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents**
2405.02957v1 by Junkai Li,Siyu Wang,Meng Zhang,Weitao Li,Yunghwei Lai,Xinhui Kang,Weizhi Ma,Yang Liu

In this paper, we introduce a simulacrum of hospital called Agent Hospital
that simulates the entire process of treating illness. All patients, nurses,
and doctors are autonomous agents powered by large language models (LLMs). Our
central goal is to enable a doctor agent to learn how to treat illness within
the simulacrum. To do so, we propose a method called MedAgent-Zero. As the
simulacrum can simulate disease onset and progression based on knowledge bases
and LLMs, doctor agents can keep accumulating experience from both successful
and unsuccessful cases. Simulation experiments show that the treatment
performance of doctor agents consistently improves on various tasks. More
interestingly, the knowledge the doctor agents have acquired in Agent Hospital
is applicable to real-world medicare benchmarks. After treating around ten
thousand patients (real-world doctors may take over two years), the evolved
doctor agent achieves a state-of-the-art accuracy of 93.06% on a subset of the
MedQA dataset that covers major respiratory diseases. This work paves the way
for advancing the applications of LLM-powered agent techniques in medical
scenarios.

摘要：

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong,Jie Li,Zhuoqi Ma,Scott Collins,Harrison Bai,Paul Zhang,Terrance Healey,Xinbo Gao,Michael K. Atalay,Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：

##### **The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses**
2405.02711v1 by Jordyn Young,Laala M Jawara,Diep N Nguyen,Brian Daly,Jina Huh-Yoo,Afsaneh Razi

Generative Artificial Intelligence (AI) is integrated into everyday
technology, including news, education, and social media. AI has further
pervaded private conversations as conversational partners, auto-completion, and
response suggestions. As social media becomes young people's main method of
peer support exchange, we need to understand when and how AI can facilitate and
assist in such exchanges in a beneficial, safe, and socially appropriate way.
We asked 622 young people to complete an online survey and evaluate blinded
human- and AI-generated responses to help-seeking messages. We found that
participants preferred the AI-generated response to situations about
relationships, self-expression, and physical health. However, when addressing a
sensitive topic, like suicidal thoughts, young people preferred the human
response. We also discuss the role of training in online peer support exchange
and its implications for supporting young people's well-being. Disclaimer: This
paper includes sensitive topics, including suicide ideation. Reader discretion
is advised.

摘要：

##### **MedPromptExtract (Medical Data Extraction Tool): Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering**
2405.02664v1 by Roomani Srivastava,Suraj Prasad,Lipika Bhat,Sarvesh Deshpande,Barnali Das,Kshitij Jadhav

A major roadblock in the seamless digitization of medical records remains the
lack of interoperability of existing records. Extracting relevant medical
information required for further treatment planning or even research is a time
consuming labour intensive task involving the much valuable time of doctors. In
this demo paper we present, MedPromptExtract an automated tool using a
combination of semi supervised learning, large language models, natural
lanuguage processing and prompt engineering to convert unstructured medical
records to structured data which is amenable to further analysis.

摘要：

##### **A Conformal Prediction Score that is Robust to Label Noise**
2405.02648v1 by Coby Penso,Jacob Goldberger

Conformal Prediction (CP) quantifies network uncertainty by building a small
prediction set with a pre-defined probability that the correct class is within
this set. In this study we tackle the problem of CP calibration based on a
validation set with noisy labels. We introduce a conformal score that is robust
to label noise. The noise-free conformal score is estimated using the noisy
labeled data and the noise level. In the test phase the noise-free score is
used to form the prediction set. We applied the proposed algorithm to several
standard medical imaging classification datasets. We show that our method
outperforms current methods by a large margin, in terms of the average size of
the prediction set, while maintaining the required coverage.

摘要：

##### **Explainable Interface for Human-Autonomy Teaming: A Survey**
2405.02583v1 by Xiangqi Kong,Yang Xing,Antonios Tsourdos,Ziyue Wang,Weisi Guo,Adolfo Perrusquia,Andreas Wikander

Nowadays, large-scale foundation models are being increasingly integrated
into numerous safety-critical applications, including human-autonomy teaming
(HAT) within transportation, medical, and defence domains. Consequently, the
inherent 'black-box' nature of these sophisticated deep neural networks
heightens the significance of fostering mutual understanding and trust between
humans and autonomous systems. To tackle the transparency challenges in HAT,
this paper conducts a thoughtful study on the underexplored domain of
Explainable Interface (EI) in HAT systems from a human-centric perspective,
thereby enriching the existing body of research in Explainable Artificial
Intelligence (XAI). We explore the design, development, and evaluation of EI
within XAI-enhanced HAT systems. To do so, we first clarify the distinctions
between these concepts: EI, explanations and model explainability, aiming to
provide researchers and practitioners with a structured understanding. Second,
we contribute to a novel framework for EI, addressing the unique challenges in
HAT. Last, our summarized evaluation framework for ongoing EI offers a holistic
perspective, encompassing model performance, human-centered factors, and group
task objectives. Based on extensive surveys across XAI, HAT, psychology, and
Human-Computer Interaction (HCI), this review offers multiple novel insights
into incorporating XAI into HAT systems and outlines future directions.

摘要：

##### **A Literature Review and Framework for Human Evaluation of Generative Large Language Models in Healthcare**
2405.02559v1 by Thomas Yu Chow Tam,Sonish Sivarajkumar,Sumit Kapoor,Alisa V Stolyar,Katelyn Polanska,Karleigh R McCarthy,Hunter Osterhoudt,Xizhi Wu,Shyam Visweswaran,Sunyang Fu,Piyush Mathur,Giovanni E. Cacciamani,Cong Sun,Yifan Peng,Yanshan Wang

As generative artificial intelligence (AI), particularly Large Language
Models (LLMs), continues to permeate healthcare, it remains crucial to
supplement traditional automated evaluations with human expert evaluation.
Understanding and evaluating the generated texts is vital for ensuring safety,
reliability, and effectiveness. However, the cumbersome, time-consuming, and
non-standardized nature of human evaluation presents significant obstacles to
the widespread adoption of LLMs in practice. This study reviews existing
literature on human evaluation methodologies for LLMs within healthcare. We
highlight a notable need for a standardized and consistent human evaluation
approach. Our extensive literature search, adhering to the Preferred Reporting
Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, spans
publications from January 2018 to February 2024. This review provides a
comprehensive overview of the human evaluation approaches used in diverse
healthcare applications.This analysis examines the human evaluation of LLMs
across various medical specialties, addressing factors such as evaluation
dimensions, sample types, and sizes, the selection and recruitment of
evaluators, frameworks and metrics, the evaluation process, and statistical
analysis of the results. Drawing from diverse evaluation strategies highlighted
in these studies, we propose a comprehensive and practical framework for human
evaluation of generative LLMs, named QUEST: Quality of Information,
Understanding and Reasoning, Expression Style and Persona, Safety and Harm, and
Trust and Confidence. This framework aims to improve the reliability,
generalizability, and applicability of human evaluation of generative LLMs in
different healthcare applications by defining clear evaluation dimensions and
offering detailed guidelines.

摘要：

##### **Spatio-Temporal SwinMAE: A Swin Transformer based Multiscale Representation Learner for Temporal Satellite Imagery**
2405.02512v1 by Yohei Nakayama,Jiawei Su

Currently, the foundation models represented by large language models have
made dramatic progress and are used in a very wide range of domains including
2D and 3D vision. As one of the important application domains of foundation
models, earth observation has attracted attention and various approaches have
been developed. When considering earth observation as a single image capture,
earth observation imagery can be processed as an image with three or more
channels, and when it comes with multiple image captures of different
timestamps at one location, the temporal observation can be considered as a set
of continuous image resembling video frames or medical SCAN slices. This paper
presents Spatio-Temporal SwinMAE (ST-SwinMAE), an architecture which
particularly focuses on representation learning for spatio-temporal image
processing. Specifically, it uses a hierarchical Masked Auto-encoder (MAE) with
Video Swin Transformer blocks. With the architecture, we present a pretrained
model named Degas 100M as a geospatial foundation model. Also, we propose an
approach for transfer learning with Degas 100M, which both pretrained encoder
and decoder of MAE are utilized with skip connections added between them to
achieve multi-scale information communication, forms an architecture named
Spatio-Temporal SwinUNet (ST-SwinUNet). Our approach shows significant
improvements of performance over existing state-of-the-art of foundation
models. Specifically, for transfer learning of the land cover downstream task
on the PhilEO Bench dataset, it shows 10.4\% higher accuracy compared with
other geospatial foundation models on average.

摘要：

##### **Implicit Neural Representations for Robust Joint Sparse-View CT Reconstruction**
2405.02509v1 by Jiayang Shi,Junyi Zhu,Daniel M. Pelt,K. Joost Batenburg,Matthew B. Blaschko

Computed Tomography (CT) is pivotal in industrial quality control and medical
diagnostics. Sparse-view CT, offering reduced ionizing radiation, faces
challenges due to its under-sampled nature, leading to ill-posed reconstruction
problems. Recent advancements in Implicit Neural Representations (INRs) have
shown promise in addressing sparse-view CT reconstruction. Recognizing that CT
often involves scanning similar subjects, we propose a novel approach to
improve reconstruction quality through joint reconstruction of multiple objects
using INRs. This approach can potentially leverage both the strengths of INRs
and the statistical regularities across multiple objects. While current INR
joint reconstruction techniques primarily focus on accelerating convergence via
meta-initialization, they are not specifically tailored to enhance
reconstruction quality. To address this gap, we introduce a novel INR-based
Bayesian framework integrating latent variables to capture the inter-object
relationships. These variables serve as a dynamic reference throughout the
optimization, thereby enhancing individual reconstruction fidelity. Our
extensive experiments, which assess various key factors such as reconstruction
quality, resistance to overfitting, and generalizability, demonstrate
significant improvements over baselines in common numerical metrics. This
underscores a notable advancement in CT reconstruction methods.

摘要：

##### **A Survey of Few-Shot Learning for Biomedical Time Series**
2405.02485v1 by Chenqi Li,Timothy Denison,Tingting Zhu

Advancements in wearable sensor technologies and the digitization of medical
records have contributed to the unprecedented ubiquity of biomedical time
series data. Data-driven models have tremendous potential to assist clinical
diagnosis and improve patient care by improving long-term monitoring
capabilities, facilitating early disease detection and intervention, as well as
promoting personalized healthcare delivery. However, accessing extensively
labeled datasets to train data-hungry deep learning models encounters many
barriers, such as long-tail distribution of rare diseases, cost of annotation,
privacy and security concerns, data-sharing regulations, and ethical
considerations. An emerging approach to overcome the scarcity of labeled data
is to augment AI methods with human-like capabilities to leverage past
experiences to learn new tasks with limited examples, called few-shot learning.
This survey provides a comprehensive review and comparison of few-shot learning
methods for biomedical time series applications. The clinical benefits and
limitations of such methods are discussed in relation to traditional
data-driven approaches. This paper aims to provide insights into the current
landscape of few-shot learning for biomedical time series and its implications
for future research and applications.

摘要：

##### **Generalizing Orthogonalization for Models with Non-linearities**
2405.02475v1 by David Rügamer,Chris Kolb,Tobias Weber,Lucas Kook,Thomas Nagler

The complexity of black-box algorithms can lead to various challenges,
including the introduction of biases. These biases present immediate risks in
the algorithms' application. It was, for instance, shown that neural networks
can deduce racial information solely from a patient's X-ray scan, a task beyond
the capability of medical experts. If this fact is not known to the medical
expert, automatic decision-making based on this algorithm could lead to
prescribing a treatment (purely) based on racial information. While current
methodologies allow for the "orthogonalization" or "normalization" of neural
networks with respect to such information, existing approaches are grounded in
linear models. Our paper advances the discourse by introducing corrections for
non-linearities such as ReLU activations. Our approach also encompasses scalar
and tensor-valued predictions, facilitating its integration into neural network
architectures. Through extensive experiments, we validate our method's
effectiveness in safeguarding sensitive data in generalized linear models,
normalizing convolutional neural networks for metadata, and rectifying
pre-existing embeddings for undesired attributes.

摘要：

##### **Model-based reinforcement learning for protein backbone design**
2405.01983v1 by Frederic Renard,Cyprien Courtot,Alfredo Reichlin,Oliver Bent

Designing protein nanomaterials of predefined shape and characteristics has
the potential to dramatically impact the medical industry. Machine learning
(ML) has proven successful in protein design, reducing the need for expensive
wet lab experiment rounds. However, challenges persist in efficiently exploring
the protein fitness landscapes to identify optimal protein designs. In
response, we propose the use of AlphaZero to generate protein backbones,
meeting shape and structural scoring requirements. We extend an existing Monte
Carlo tree search (MCTS) framework by incorporating a novel threshold-based
reward and secondary objectives to improve design precision. This innovation
considerably outperforms existing approaches, leading to protein backbones that
better respect structural scores. The application of AlphaZero is novel in the
context of protein backbone design and demonstrates promising performance.
AlphaZero consistently surpasses baseline MCTS by more than 100% in top-down
protein design tasks. Additionally, our application of AlphaZero with secondary
objectives uncovers further promising outcomes, indicating the potential of
model-based reinforcement learning (RL) in navigating the intricate and nuanced
aspects of protein design

摘要：

##### **Aloe: A Family of Fine-tuned Open Healthcare LLMs**
2405.01886v1 by Ashwin Kumar Gururajan,Enrique Lopez-Cuena,Jordi Bayarri-Planas,Adrian Tormos,Daniel Hinjos,Pablo Bernabeu-Perez,Anna Arias-Duart,Pablo Agustin Martin-Torres,Lucia Urcelay-Ganzabal,Marta Gonzalez-Mallo,Sergio Alvarez-Napagao,Eduard Ayguadé-Parra,Ulises Cortés Dario Garcia-Gasulla

As the capabilities of Large Language Models (LLMs) in healthcare and
medicine continue to advance, there is a growing need for competitive
open-source models that can safeguard public interest. With the increasing
availability of highly competitive open base models, the impact of continued
pre-training is increasingly uncertain. In this work, we explore the role of
instruct tuning, model merging, alignment, red teaming and advanced inference
schemes, as means to improve current open models. To that end, we introduce the
Aloe family, a set of open medical LLMs highly competitive within its scale
range. Aloe models are trained on the current best base models (Mistral, LLaMA
3), using a new custom dataset which combines public data sources improved with
synthetic Chain of Thought (CoT). Aloe models undergo an alignment phase,
becoming one of the first few policy-aligned open healthcare LLM using Direct
Preference Optimization, setting a new standard for ethical performance in
healthcare LLMs. Model evaluation expands to include various bias and toxicity
datasets, a dedicated red teaming effort, and a much-needed risk assessment for
healthcare LLMs. Finally, to explore the limits of current LLMs in inference,
we study several advanced prompt engineering strategies to boost performance
across benchmarks, yielding state-of-the-art results for open healthcare 7B
LLMs, unprecedented at this scale.

摘要：

##### **Millimeter Wave Radar-based Human Activity Recognition for Healthcare Monitoring Robot**
2405.01882v1 by Zhanzhong Gu,Xiangjian He,Gengfa Fang,Chengpei Xu,Feng Xia,Wenjing Jia

Healthcare monitoring is crucial, especially for the daily care of elderly
individuals living alone. It can detect dangerous occurrences, such as falls,
and provide timely alerts to save lives. Non-invasive millimeter wave (mmWave)
radar-based healthcare monitoring systems using advanced human activity
recognition (HAR) models have recently gained significant attention. However,
they encounter challenges in handling sparse point clouds, achieving real-time
continuous classification, and coping with limited monitoring ranges when
statically mounted. To overcome these limitations, we propose RobHAR, a movable
robot-mounted mmWave radar system with lightweight deep neural networks for
real-time monitoring of human activities. Specifically, we first propose a
sparse point cloud-based global embedding to learn the features of point clouds
using the light-PointNet (LPN) backbone. Then, we learn the temporal pattern
with a bidirectional lightweight LSTM model (BiLiLSTM). In addition, we
implement a transition optimization strategy, integrating the Hidden Markov
Model (HMM) with Connectionist Temporal Classification (CTC) to improve the
accuracy and robustness of the continuous HAR. Our experiments on three
datasets indicate that our method significantly outperforms the previous
studies in both discrete and continuous HAR tasks. Finally, we deploy our
system on a movable robot-mounted edge computing platform, achieving flexible
healthcare monitoring in real-world scenarios.

摘要：

##### **Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features**
2405.01799v1 by Chuanbo Hu,Wenqi Li,Mindi Ruan,Xiangxu Yu,Lynn K. Paul,Shuo Wang,Xin Li

Diagnosing language disorders associated with autism is a complex and nuanced
challenge, often hindered by the subjective nature and variability of
traditional assessment methods. Traditional diagnostic methods not only require
intensive human effort but also often result in delayed interventions due to
their lack of speed and specificity. In this study, we explored the application
of ChatGPT, a state of the art large language model, to overcome these
obstacles by enhancing diagnostic accuracy and profiling specific linguistic
features indicative of autism. Leveraging ChatGPT advanced natural language
processing capabilities, this research aims to streamline and refine the
diagnostic process. Specifically, we compared ChatGPT's performance with that
of conventional supervised learning models, including BERT, a model acclaimed
for its effectiveness in various natural language processing tasks. We showed
that ChatGPT substantially outperformed these models, achieving over 13%
improvement in both accuracy and F1 score in a zero shot learning
configuration. This marked enhancement highlights the model potential as a
superior tool for neurological diagnostics. Additionally, we identified ten
distinct features of autism associated language disorders that vary
significantly across different experimental scenarios. These features, which
included echolalia, pronoun reversal, and atypical language usage, were crucial
for accurately diagnosing ASD and customizing treatment plans. Together, our
findings advocate for adopting sophisticated AI tools like ChatGPT in clinical
settings to assess and diagnose developmental disorders. Our approach not only
promises greater diagnostic precision but also aligns with the goals of
personalized medicine, potentially transforming the evaluation landscape for
autism and similar neurological conditions.

摘要：

##### **Interpretable Vital Sign Forecasting with Model Agnostic Attention Maps**
2405.01714v2 by Yuwei Liu,Chen Dan,Anubhav Bhatti,Bingjie Shen,Divij Gupta,Suraj Parmar,San Lee

Sepsis is a leading cause of mortality in intensive care units (ICUs),
representing a substantial medical challenge. The complexity of analyzing
diverse vital signs to predict sepsis further aggravates this issue. While deep
learning techniques have been advanced for early sepsis prediction, their
'black-box' nature obscures the internal logic, impairing interpretability in
critical settings like ICUs. This paper introduces a framework that combines a
deep learning model with an attention mechanism that highlights the critical
time steps in the forecasting process, thus improving model interpretability
and supporting clinical decision-making. We show that the attention mechanism
could be adapted to various black box time series forecasting models such as
N-HiTS and N-BEATS. Our method preserves the accuracy of conventional deep
learning models while enhancing interpretability through
attention-weight-generated heatmaps. We evaluated our model on the eICU-CRD
dataset, focusing on forecasting vital signs for sepsis patients. We assessed
its performance using mean squared error (MSE) and dynamic time warping (DTW)
metrics. We explored the attention maps of N-HiTS and N-BEATS, examining the
differences in their performance and identifying crucial factors influencing
vital sign forecasting.

摘要：

##### **Long Tail Image Generation Through Feature Space Augmentation and Iterated Learning**
2405.01705v1 by Rafael Elberg,Denis Parra,Mircea Petrache

Image and multimodal machine learning tasks are very challenging to solve in
the case of poorly distributed data. In particular, data availability and
privacy restrictions exacerbate these hurdles in the medical domain. The state
of the art in image generation quality is held by Latent Diffusion models,
making them prime candidates for tackling this problem. However, a few key
issues still need to be solved, such as the difficulty in generating data from
under-represented classes and a slow inference process. To mitigate these
issues, we propose a new method for image augmentation in long-tailed data
based on leveraging the rich latent space of pre-trained Stable Diffusion
Models. We create a modified separable latent space to mix head and tail class
examples. We build this space via Iterated Learning of underlying sparsified
embeddings, which we apply to task-specific saliency maps via a K-NN approach.
Code is available at
https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning

摘要：

##### **Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models**
2405.01686v1 by Hye Sun Yun,David Pogrebitskiy,Iain J. Marshall,Byron C. Wallace

Meta-analyses statistically aggregate the findings of different randomized
controlled trials (RCTs) to assess treatment effectiveness. Because this yields
robust estimates of treatment effectiveness, results from meta-analyses are
considered the strongest form of evidence. However, rigorous evidence syntheses
are time-consuming and labor-intensive, requiring manual extraction of data
from individual trials to be synthesized. Ideally, language technologies would
permit fully automatic meta-analysis, on demand. This requires accurately
extracting numerical results from individual trials, which has been beyond the
capabilities of natural language processing (NLP) models to date. In this work,
we evaluate whether modern large language models (LLMs) can reliably perform
this task. We annotate (and release) a modest but granular evaluation dataset
of clinical trial reports with numerical findings attached to interventions,
comparators, and outcomes. Using this dataset, we evaluate the performance of
seven LLMs applied zero-shot for the task of conditionally extracting numerical
findings from trial reports. We find that massive LLMs that can accommodate
lengthy inputs are tantalizingly close to realizing fully automatic
meta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).
However, LLMs -- including ones trained on biomedical texts -- perform poorly
when the outcome measures are complex and tallying the results requires
inference. This work charts a path toward fully automatic meta-analysis of RCTs
via LLMs, while also highlighting the limitations of existing models for this
aim.

摘要：

##### **Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language**
2405.01682v1 by Liam Hazan,Gili Focht,Naama Gavrielov,Roi Reichart,Talar Hagopian,Mary-Louise C. Greer,Ruth Cytter Kuint,Dan Turner,Moti Freiman

Automatic conversion of free-text radiology reports into structured data
using Natural Language Processing (NLP) techniques is crucial for analyzing
diseases on a large scale. While effective for tasks in widely spoken languages
like English, generative large language models (LLMs) typically underperform
with less common languages and can pose potential risks to patient privacy.
Fine-tuning local NLP models is hindered by the skewed nature of real-world
medical datasets, where rare findings represent a significant data imbalance.
We introduce SMP-BERT, a novel prompt learning method that leverages the
structured nature of reports to overcome these challenges. In our studies
involving a substantial collection of Crohn's disease radiology reports in
Hebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed
traditional fine-tuning methods in performance, notably in detecting infrequent
conditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more
accurate AI diagnostics available for low-resource languages.

摘要：

##### **Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning**
2405.01469v1 by Théo Moutakanni,Piotr Bojanowski,Guillaume Chassagnon,Céline Hudelot,Armand Joulin,Yann LeCun,Matthew Muckley,Maxime Oquab,Marie-Pierre Revel,Maria Vakalopoulou

AI Foundation models are gaining traction in various applications, including
medical fields like radiology. However, medical foundation models are often
tested on limited tasks, leaving their generalisability and biases unexplored.
We present RayDINO, a large visual encoder trained by self-supervision on 873k
chest X-rays. We compare RayDINO to previous state-of-the-art models across
nine radiology tasks, from classification and dense segmentation to text
generation, and provide an in depth analysis of population, age and sex biases
of our model. Our findings suggest that self-supervision allows patient-centric
AI proving useful in clinical workflows and interpreting X-rays holistically.
With RayDINO and small task-specific adapters, we reach state-of-the-art
results and improve generalization to unseen populations while mitigating bias,
illustrating the true promise of foundation models: versatility and robustness.

摘要：

##### **DMON: A Simple yet Effective Approach for Argument Structure Learning**
2405.01216v1 by Wei Sun,Mingxiao Li,Jingyuan Sun,Jesse Davis,Marie-Francine Moens

Argument structure learning~(ASL) entails predicting relations between
arguments. Because it can structure a document to facilitate its understanding,
it has been widely applied in many fields~(medical, commercial, and scientific
domains). Despite its broad utilization, ASL remains a challenging task because
it involves examining the complex relationships between the sentences in a
potentially unstructured discourse. To resolve this problem, we have developed
a simple yet effective approach called Dual-tower Multi-scale cOnvolution
neural Network~(DMON) for the ASL task. Specifically, we organize arguments
into a relationship matrix that together with the argument embeddings forms a
relationship tensor and design a mechanism to capture relations with contextual
arguments. Experimental results on three different-domain argument mining
datasets demonstrate that our framework outperforms state-of-the-art models.
The code is available at https://github.com/VRCMF/DMON.git .

摘要：

##### **Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis**
2405.00876v1 by Prateek Verma,Minh-Hao Van,Xintao Wu

Vision language models (VLMs) have recently emerged and gained the spotlight
for their ability to comprehend the dual modality of image and textual data.
VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive
performance on tasks such as natural image captioning, visual question
answering (VQA), and spatial reasoning. Additionally, a universal segmentation
model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance
at isolating objects from unforeseen images. Since medical experts, biologists,
and materials scientists routinely examine microscopy or medical images in
conjunction with textual information in the form of captions, literature, or
reports, and draw conclusions of great importance and merit, it is indubitably
essential to test the performance of VLMs and foundation models such as SAM, on
these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with
classification, segmentation, counting, and VQA tasks on a variety of
microscopy images. We observe that ChatGPT and Gemini are impressively able to
comprehend the visual features in microscopy images, while SAM is quite capable
at isolating artefacts in a general sense. However, the performance is not
close to that of a domain expert - the models are readily encumbered by the
introduction of impurities, defects, artefact overlaps and diversity present in
the images.

摘要：

##### **"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**
2405.00623v1 by Sunnie S. Y. Kim,Q. Vera Liao,Mihaela Vorvoreanu,Stephanie Ballard,Jennifer Wortman Vaughan

Widely deployed large language models (LLMs) can produce convincing yet
incorrect outputs, potentially misleading users who may rely on them as if they
were correct. To reduce such overreliance, there have been calls for LLMs to
communicate their uncertainty to end users. However, there has been little
empirical work examining how users perceive and act upon LLMs' expressions of
uncertainty. We explore this question through a large-scale, pre-registered,
human-subject experiment (N=404) in which participants answer medical questions
with or without access to responses from a fictional LLM-infused search engine.
Using both behavioral and self-reported measures, we examine how different
natural language expressions of uncertainty impact participants' reliance,
trust, and overall task performance. We find that first-person expressions
(e.g., "I'm not sure, but...") decrease participants' confidence in the system
and tendency to agree with the system's answers, while increasing participants'
accuracy. An exploratory analysis suggests that this increase can be attributed
to reduced (but not fully eliminated) overreliance on incorrect answers. While
we observe similar effects for uncertainty expressed from a general perspective
(e.g., "It's not clear, but..."), these effects are weaker and not
statistically significant. Our findings suggest that using natural language
expressions of uncertainty may be an effective approach for reducing
overreliance on LLMs, but that the precise language used matters. This
highlights the importance of user testing before deploying LLMs at scale.

摘要：

##### **Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning**
2405.00461v1 by Huan Xu,Jinlin Wu,Guanglin Cao,Zhen Lei,Zhen Chen,Hongbin Liu

Ultrasound robots are increasingly used in medical diagnostics and early
disease screening. However, current ultrasound robots lack the intelligence to
understand human intentions and instructions, hindering autonomous ultrasound
scanning. To solve this problem, we propose a novel Ultrasound Embodied
Intelligence system that equips ultrasound robots with the large language model
(LLM) and domain knowledge, thereby improving the efficiency of ultrasound
robots. Specifically, we first design an ultrasound operation knowledge
database to add expertise in ultrasound scanning to the LLM, enabling the LLM
to perform precise motion planning. Furthermore, we devise a dynamic ultrasound
scanning strategy based on a \textit{think-observe-execute} prompt engineering,
allowing LLMs to dynamically adjust motion planning strategies during the
scanning procedures. Extensive experiments demonstrate that our system
significantly improves ultrasound scan efficiency and quality from verbal
commands. This advancement in autonomous medical scanning technology
contributes to non-invasive diagnostics and streamlined medical workflows.

摘要：

##### **A Careful Examination of Large Language Model Performance on Grade School Arithmetic**
2405.00332v3 by Hugh Zhang,Jeff Da,Dean Lee,Vaughn Robinson,Catherine Wu,Will Song,Tiffany Zhao,Pranav Raja,Dylan Slack,Qin Lyu,Sean Hendryx,Russell Kaplan,Michele Lunati,Summer Yue

Large language models (LLMs) have achieved impressive success on many
benchmarks for mathematical reasoning. However, there is growing concern that
some of this performance actually reflects dataset contamination, where data
closely resembling benchmark questions leaks into the training data, instead of
true reasoning ability. To investigate this claim rigorously, we commission
Grade School Math 1000 (GSM1k). GSM1k is designed to mirror the style and
complexity of the established GSM8k benchmark, the gold standard for measuring
elementary mathematical reasoning. We ensure that the two benchmarks are
comparable across important metrics such as human solve rates, number of steps
in solution, answer magnitude, and more. When evaluating leading open- and
closed-source LLMs on GSM1k, we observe accuracy drops of up to 13%, with
several families of models (e.g., Phi and Mistral) showing evidence of
systematic overfitting across almost all model sizes. At the same time, many
models, especially those on the frontier, (e.g., Gemini/GPT/Claude) show
minimal signs of overfitting. Further analysis suggests a positive relationship
(Spearman's r^2=0.32) between a model's probability of generating an example
from GSM8k and its performance gap between GSM8k and GSM1k, suggesting that
many models may have partially memorized GSM8k.

摘要：

##### **Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition**
2405.00307v1 by Dongyuan Li,Ying Zhang,Yusong Wang,Funakoshi Kataro,Manabu Okumura

Speech emotion recognition (SER) has garnered increasing attention due to its
wide range of applications in various fields, including human-machine
interaction, virtual assistants, and mental health assistance. However,
existing SER methods often overlook the information gap between the
pre-training speech recognition task and the downstream SER task, resulting in
sub-optimal performance. Moreover, current methods require much time for
fine-tuning on each specific speech dataset, such as IEMOCAP, which limits
their effectiveness in real-world scenarios with large-scale noisy data. To
address these issues, we propose an active learning (AL)-based fine-tuning
framework for SER, called \textsc{After}, that leverages task adaptation
pre-training (TAPT) and AL methods to enhance performance and efficiency.
Specifically, we first use TAPT to minimize the information gap between the
pre-training speech recognition task and the downstream speech emotion
recognition task. Then, AL methods are employed to iteratively select a subset
of the most informative and diverse samples for fine-tuning, thereby reducing
time consumption. Experiments demonstrate that our proposed method
\textsc{After}, using only 20\% of samples, improves accuracy by 8.45\% and
reduces time consumption by 79\%. The additional extension of \textsc{After}
and ablation studies further confirm its effectiveness and applicability to
various real-world scenarios. Our source code is available on Github for
reproducibility. (https://github.com/Clearloveyuan/AFTER).

摘要：

##### **Quantifying Nematodes through Images: Datasets, Models, and Baselines of Deep Learning**
2404.19748v1 by Zhipeng Yuan,Nasamu Musa,Katarzyna Dybal,Matthew Back,Daniel Leybourne,Po Yang

Every year, plant parasitic nematodes, one of the major groups of plant
pathogens, cause a significant loss of crops worldwide. To mitigate crop yield
losses caused by nematodes, an efficient nematode monitoring method is
essential for plant and crop disease management. In other respects, efficient
nematode detection contributes to medical research and drug discovery, as
nematodes are model organisms. With the rapid development of computer
technology, computer vision techniques provide a feasible solution for
quantifying nematodes or nematode infections. In this paper, we survey and
categorise the studies and available datasets on nematode detection through
deep-learning models. To stimulate progress in related research, this survey
presents the potential state-of-the-art object detection models, training
techniques, optimisation techniques, and evaluation metrics for deep learning
beginners. Moreover, seven state-of-the-art object detection models are
validated on three public datasets and the AgriNema dataset for plant parasitic
nematodes to construct a baseline for nematode detection.

摘要：

##### **Data Set Terminology of Artificial Intelligence in Medicine: A Historical Review and Recommendation**
2404.19303v1 by Shannon L. Walston,Hiroshi Seki,Hirotaka Takita,Yasuhito Mitsuyama,Shingo Sato,Akifumi Hagiwara,Rintaro Ito,Shouhei Hanaoka,Yukio Miki,Daiju Ueda

Medicine and artificial intelligence (AI) engineering represent two distinct
fields each with decades of published history. With such history comes a set of
terminology that has a specific way in which it is applied. However, when two
distinct fields with overlapping terminology start to collaborate,
miscommunication and misunderstandings can occur. This narrative review aims to
give historical context for these terms, accentuate the importance of clarity
when these terms are used in medical AI contexts, and offer solutions to
mitigate misunderstandings by readers from either field. Through an examination
of historical documents, including articles, writing guidelines, and textbooks,
this review traces the divergent evolution of terms for data sets and their
impact. Initially, the discordant interpretations of the word 'validation' in
medical and AI contexts are explored. Then the data sets used for AI evaluation
are classified, namely random splitting, cross-validation, temporal,
geographic, internal, and external sets. The accurate and standardized
description of these data sets is crucial for demonstrating the robustness and
generalizability of AI applications in medicine. This review clarifies existing
literature to provide a comprehensive understanding of these classifications
and their implications in AI evaluation. This review then identifies often
misunderstood terms and proposes pragmatic solutions to mitigate terminological
confusion. Among these solutions are the use of standardized terminology such
as 'training set,' 'validation (or tuning) set,' and 'test set,' and explicit
definition of data set splitting terminologies in each medical AI research
publication. This review aspires to enhance the precision of communication in
medical AI, thereby fostering more effective and transparent research
methodologies in this interdisciplinary field.

摘要：

##### **Text and Audio Simplification: Human vs. ChatGPT**
2405.01592v1 by Gondy Leroy,David Kauchak,Philip Harber,Ankit Pal,Akash Shukla

Text and audio simplification to increase information comprehension are
important in healthcare. With the introduction of ChatGPT, an evaluation of its
simplification performance is needed. We provide a systematic comparison of
human and ChatGPT simplified texts using fourteen metrics indicative of text
difficulty. We briefly introduce our online editor where these simplification
tools, including ChatGPT, are available. We scored twelve corpora using our
metrics: six text, one audio, and five ChatGPT simplified corpora. We then
compare these corpora with texts simplified and verified in a prior user study.
Finally, a medical domain expert evaluated these texts and five, new ChatGPT
simplified versions. We found that simple corpora show higher similarity with
the human simplified texts. ChatGPT simplification moves metrics in the right
direction. The medical domain expert evaluation showed a preference for the
ChatGPT style, but the text itself was rated lower for content retention.

摘要：

##### **ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization**
2404.18831v1 by Hong Nguyen,Hoang Nguyen,Melinda Chang,Hieu Pham,Shrikanth Narayanan,Michael Pazzani

Understanding the severity of conditions shown in images in medical diagnosis
is crucial, serving as a key guide for clinical assessment, treatment, as well
as evaluating longitudinal progression. This paper proposes Con- PrO: a novel
representation learning method for severity assessment in medical images using
Contrastive learningintegrated Preference Optimization. Different from
conventional contrastive learning methods that maximize the distance between
classes, ConPrO injects into the latent vector the distance preference
knowledge between various severity classes and the normal class. We
systematically examine the key components of our framework to illuminate how
contrastive prediction tasks acquire valuable representations. We show that our
representation learning framework offers valuable severity ordering in the
feature space while outperforming previous state-of-the-art methods on
classification tasks. We achieve a 6% and 20% relative improvement compared to
a supervised and a self-supervised baseline, respectively. In addition, we
derived discussions on severity indicators and related applications of
preference comparison in the medical domain.

摘要：

##### **Decoding Radiologists' Intentions: A Novel System for Accurate Region Identification in Chest X-ray Image Analysis**
2404.18981v1 by Akash Awasthi,Safwan Ahmad,Bryant Le,Hien Van Nguyen

In the realm of chest X-ray (CXR) image analysis, radiologists meticulously
examine various regions, documenting their observations in reports. The
prevalence of errors in CXR diagnoses, particularly among inexperienced
radiologists and hospital residents, underscores the importance of
understanding radiologists' intentions and the corresponding regions of
interest. This understanding is crucial for correcting mistakes by guiding
radiologists to the accurate regions of interest, especially in the diagnosis
of chest radiograph abnormalities. In response to this imperative, we propose a
novel system designed to identify the primary intentions articulated by
radiologists in their reports and the corresponding regions of interest in CXR
images. This system seeks to elucidate the visual context underlying
radiologists' textual findings, with the potential to rectify errors made by
less experienced practitioners and direct them to precise regions of interest.
Importantly, the proposed system can be instrumental in providing constructive
feedback to inexperienced radiologists or junior residents in the hospital,
bridging the gap in face-to-face communication. The system represents a
valuable tool for enhancing diagnostic accuracy and fostering continuous
learning within the medical community.

摘要：

##### **Foundations of Multisensory Artificial Intelligence**
2404.18976v1 by Paul Pu Liang

Building multisensory AI systems that learn from multiple sensory inputs such
as text, speech, video, real-world sensors, wearable devices, and medical data
holds great promise for impact in many scientific areas with practical
benefits, such as in supporting human health and well-being, enabling
multimedia content processing, and enhancing real-world autonomous agents. By
synthesizing a range of theoretical frameworks and application domains, this
thesis aims to advance the machine learning foundations of multisensory AI. In
the first part, we present a theoretical framework formalizing how modalities
interact with each other to give rise to new information for a task. These
interactions are the basic building blocks in all multimodal problems, and
their quantification enables users to understand their multimodal datasets,
design principled approaches to learn these interactions, and analyze whether
their model has succeeded in learning. In the second part, we study the design
of practical multimodal foundation models that generalize over many modalities
and tasks, which presents a step toward grounding large language models to
real-world sensory modalities. We introduce MultiBench, a unified large-scale
benchmark across a wide range of modalities, tasks, and research areas,
followed by the cross-modal attention and multimodal transformer architectures
that now underpin many of today's multimodal foundation models. Scaling these
architectures on MultiBench enables the creation of general-purpose
multisensory AI systems, and we discuss our collaborative efforts in applying
these models for real-world impact in affective computing, mental health,
cancer prognosis, and robotics. Finally, we conclude this thesis by discussing
how future work can leverage these ideas toward more general, interactive, and
safe multisensory AI.

摘要：

##### **M3H: Multimodal Multitask Machine Learning for Healthcare**
2404.18975v1 by Dimitris Bertsimas,Yu Ma

Recent breakthroughs in AI are poised to fundamentally enhance our study and
understanding of healthcare. The development of an integrated many-to-many
framework that leverages multiple data modality inputs for the analytical
modeling of multiple medical tasks, is critical for a unified understanding of
modern medicine. In this work, we introduce M3H, an explainable Multimodal
Multitask Machine Learning for Healthcare framework that consolidates learning
from diverse multimodal inputs across a broad spectrum of medical task
categories and machine learning problem classes. The modular design of the
framework ensures its generalizable data processing, task definition, and rapid
model prototyping, applicable to both clinical and operational healthcare
settings. We evaluate the M3H framework by validating models trained from four
modalities (tabular, time-series, language, and vision) on 41 medical tasks
across 4 machine learning problem classes. Our results demonstrate that M3H
consistently produces multitask models that outperform canonical single-task
models (by 1.1- 37.2%) across 37 disease diagnoses from 16 medical departments,
three hospital operation forecasts, and one patient phenotyping task: spanning
ML problem classes of supervised binary classification, multiclass
classification, regression, and clustering. Additionally, the framework
introduces a novel attention mechanism to balance self-exploitation (focus on
learning source task), and cross-exploration (encourage learning from other
tasks). Furthermore, M3H provides explainability insights on how joint learning
of additional tasks impacts the learning of source task using a proposed TIM
score, shedding light into the dynamics of task interdependencies. Its
adaptable architecture facilitates the customization and integration,
establishing it as a robust and scalable candidate solution for future
AI-driven healthcare systems.

摘要：

##### **Real Time Multi Organ Classification on Computed Tomography Images**
2404.18731v1 by Halid Ziya Yerebakan,Yoshihisa Shinagawa,Gerardo Hermosillo Valadez

Organ segmentation is a fundamental task in medical imaging, and it is useful
for many clinical automation pipelines. Typically, the process involves
segmenting the entire volume, which can be unnecessary when the points of
interest are limited. In those cases, a classifier could be used instead of
segmentation. However, there is an inherent trade-off between the context size
and the speed of classifiers. To address this issue, we propose a new method
that employs a data selection strategy with sparse sampling across a wide field
of view without image resampling. This sparse sampling strategy makes it
possible to classify voxels into multiple organs in real time without using
accelerators. Although our method is an independent classifier, it can generate
full segmentation by querying grid locations at any resolution. We have
compared our method with existing segmentation techniques, demonstrating its
potential for superior runtime in practical applications in medical imaging.

摘要：

##### **Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model**
2405.01591v1 by Seonhee Cho,Choonghan Kim,Jiho Lee,Chetan Chilkunda,Sujin Choi,Joo Heung Yoon

Recent advancements in Large Multimodal Models (LMMs) have attracted interest
in their generalization capability with only a few samples in the prompt. This
progress is particularly relevant to the medical domain, where the quality and
sensitivity of data pose unique challenges for model training and application.
However, the dependency on high-quality data for effective in-context learning
raises questions about the feasibility of these models when encountering with
the inevitable variations and errors inherent in real-world medical data. In
this paper, we introduce MID-M, a novel framework that leverages the in-context
learning capabilities of a general-domain Large Language Model (LLM) to process
multimodal data via image descriptions. MID-M achieves a comparable or superior
performance to task-specific fine-tuned LMMs and other general-domain ones,
without the extensive domain-specific training or pre-training on multimodal
data, with significantly fewer parameters. This highlights the potential of
leveraging general-domain LLMs for domain-specific tasks and offers a
sustainable and cost-effective alternative to traditional LMM developments.
Moreover, the robustness of MID-M against data quality issues demonstrates its
practical utility in real-world medical domain applications.

摘要：

##### **Machine Learning for Quantum Computing Specialists**
2404.18555v1 by Daniel Goldsmith,M M Hassan Mahmud

Quantum machine learning (QML) is a promising early use case for quantum
computing. There has been progress in the last five years from theoretical
studies and numerical simulations to proof of concepts. Use cases demonstrated
on contemporary quantum devices include classifying medical images and items
from the Iris dataset, classifying and generating handwritten images, toxicity
screening, and learning a probability distribution. Potential benefits of QML
include faster training and identification of feature maps not found
classically. Although, these examples lack the scale for commercial
exploitation, and it may be several years before QML algorithms replace the
classical solutions, QML is an exciting area.
  This article is written for those who already have a sound knowledge of
quantum computing and now wish to gain a basic overview of the terminology and
some applications of classical machine learning ready to study quantum machine
learning. The reader will already understand the relevant relevant linear
algebra, including Hilbert spaces, a vector space with an inner product.

摘要：

##### **GPT-4 passes most of the 297 written Polish Board Certification Examinations**
2405.01589v1 by Jakub Pokrywka,Jeremi Kaczmarek,Edward Gorzelańczyk

Introduction: Recently, the effectiveness of Large Language Models (LLMs) has
increased rapidly, allowing them to be used in a great number of applications.
However, the risks posed by the generation of false information through LLMs
significantly limit their applications in sensitive areas such as healthcare,
highlighting the necessity for rigorous validations to determine their utility
and reliability. To date, no study has extensively compared the performance of
LLMs on Polish medical examinations across a broad spectrum of specialties on a
very large dataset. Objectives: This study evaluated the performance of three
Generative Pretrained Transformer (GPT) models on the Polish Board
Certification Exam (Pa\'nstwowy Egzamin Specjalizacyjny, PES) dataset, which
consists of 297 tests. Methods: We developed a software program to download and
process PES exams and tested the performance of GPT models using OpenAI
Application Programming Interface. Results: Our findings reveal that GPT-3.5
did not pass any of the analyzed exams. In contrast, the GPT-4 models
demonstrated the capability to pass the majority of the exams evaluated, with
the most recent model, gpt-4-0125, successfully passing 222 (75%) of them. The
performance of the GPT models varied significantly, displaying excellence in
exams related to certain specialties while completely failing others.
Conclusions: The significant progress and impressive performance of LLM models
hold great promise for the increased application of AI in the field of medicine
in Poland. For instance, this advancement could lead to the development of
AI-based medical assistants for healthcare professionals, enhancing the
efficiency and accuracy of medical services.

摘要：

##### **On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**
2404.18519v2 by Usevalad Milasheuski. Luca Barbieri,Bernardo Camajori Tedeschini,Monica Nicoli,Stefano Savazzi

Federated Learning (FL) allows multiple privacy-sensitive applications to
leverage their dataset for a global model construction without any disclosure
of the information. One of those domains is healthcare, where groups of silos
collaborate in order to generate a global predictor with improved accuracy and
generalization. However, the inherent challenge lies in the high heterogeneity
of medical data, necessitating sophisticated techniques for assessment and
compensation. This paper presents a comprehensive exploration of the
mathematical formalization and taxonomy of heterogeneity within FL
environments, focusing on the intricacies of medical data. In particular, we
address the evaluation and comparison of the most popular FL algorithms with
respect to their ability to cope with quantity-based, feature and label
distribution-based heterogeneity. The goal is to provide a quantitative
evaluation of the impact of data heterogeneity in FL systems for healthcare
networks as well as a guideline on FL algorithm selection. Our research extends
beyond existing studies by benchmarking seven of the most common FL algorithms
against the unique challenges posed by medical data use cases. The paper
targets the prediction of the risk of stroke recurrence through a set of
tabular clinical reports collected by different federated hospital silos: data
heterogeneity frequently encountered in this scenario and its impact on FL
performance are discussed.

摘要：

##### **Research on Intelligent Aided Diagnosis System of Medical Image Based on Computer Deep Learning**
2404.18419v1 by Jiajie Yuan,Linxiao Wu,Yulu Gong,Zhou Yu,Ziang Liu,Shuyao He

This paper combines Struts and Hibernate two architectures together, using
DAO (Data Access Object) to store and access data. Then a set of dual-mode
humidity medical image library suitable for deep network is established, and a
dual-mode medical image assisted diagnosis method based on the image is
proposed. Through the test of various feature extraction methods, the optimal
operating characteristic under curve product (AUROC) is 0.9985, the recall rate
is 0.9814, and the accuracy is 0.9833. This method can be applied to clinical
diagnosis, and it is a practical method. Any outpatient doctor can register
quickly through the system, or log in to the platform to upload the image to
obtain more accurate images. Through the system, each outpatient physician can
quickly register or log in to the platform for image uploading, thus obtaining
more accurate images. The segmentation of images can guide doctors in clinical
departments. Then the image is analyzed to determine the location and nature of
the tumor, so as to make targeted treatment.

摘要：

##### **Capabilities of Gemini Models in Medicine**
2404.18416v2 by Khaled Saab,Tao Tu,Wei-Hung Weng,Ryutaro Tanno,David Stutz,Ellery Wulczyn,Fan Zhang,Tim Strother,Chunjong Park,Elahe Vedadi,Juanma Zambrano Chaves,Szu-Yeu Hu,Mike Schaekermann,Aishwarya Kamath,Yong Cheng,David G. T. Barrett,Cathy Cheung,Basil Mustafa,Anil Palepu,Daniel McDuff,Le Hou,Tomer Golany,Luyang Liu,Jean-baptiste Alayrac,Neil Houlsby,Nenad Tomasev,Jan Freyberg,Charles Lau,Jonas Kemp,Jeremy Lai,Shekoofeh Azizi,Kimberly Kanada,SiWai Man,Kavita Kulkarni,Ruoxi Sun,Siamak Shakeri,Luheng He,Ben Caine,Albert Webson,Natasha Latysheva,Melvin Johnson,Philip Mansfield,Jian Lu,Ehud Rivlin,Jesper Anderson,Bradley Green,Renee Wong,Jonathan Krause,Jonathon Shlens,Ewa Dominowska,S. M. Ali Eslami,Katherine Chou,Claire Cui,Oriol Vinyals,Koray Kavukcuoglu,James Manyika,Jeff Dean,Demis Hassabis,Yossi Matias,Dale Webster,Joelle Barral,Greg Corrado,Christopher Semturs,S. Sara Mahdavi,Juraj Gottweis,Alan Karthikesalingam,Vivek Natarajan

Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.

摘要：

##### **Permutation-equivariant quantum convolutional neural networks**
2404.18198v1 by Sreetama Das,Filippo Caruso

The Symmetric group $S_{n}$ manifests itself in large classes of quantum
systems as the invariance of certain characteristics of a quantum state with
respect to permuting the qubits. The subgroups of $S_{n}$ arise, among many
other contexts, to describe label symmetry of classical images with respect to
spatial transformations, e.g. reflection or rotation. Equipped with the
formalism of geometric quantum machine learning, in this work we propose the
architectures of equivariant quantum convolutional neural networks (EQCNNs)
adherent to $S_{n}$ and its subgroups. We demonstrate that a careful choice of
pixel-to-qubit embedding order can facilitate easy construction of EQCNNs for
small subgroups of $S_{n}$. Our novel EQCNN architecture corresponding to the
full permutation group $S_{n}$ is built by applying all possible QCNNs with
equal probability, which can also be conceptualized as a dropout strategy in
quantum neural networks. For subgroups of $S_{n}$, our numerical results using
MNIST datasets show better classification accuracy than non-equivariant QCNNs.
The $S_{n}$-equivariant QCNN architecture shows significantly improved training
and test performance than non-equivariant QCNN for classification of connected
and non-connected graphs. When trained with sufficiently large number of data,
the $S_{n}$-equivariant QCNN shows better average performance compared to
$S_{n}$-equivariant QNN . These results contribute towards building powerful
quantum machine learning architectures in permutation-symmetric systems.

摘要：

##### **MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch**
2404.17999v1 by Nadia Saeed

Accurate representation of medical information is crucial for patient safety,
yet artificial intelligence (AI) systems, such as Large Language Models (LLMs),
encounter challenges in error-free clinical text interpretation. This paper
presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben
Abacha et al., 2024a), focusing on the automatic correction of single-word
errors in clinical notes. Unlike LLMs that rely on extensive generic data, our
method emphasizes extracting contextually relevant information from available
clinical text data. Leveraging an ensemble of extractive and abstractive
question-answering approaches, we construct a supervised learning framework
with domain-specific feature engineering. Our methodology incorporates domain
expertise to enhance error correction accuracy. By integrating domain expertise
and prioritizing meaningful information extraction, our approach underscores
the significance of a human-centric strategy in adapting AI for healthcare.

摘要：

##### **MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology with Multimodal Learning**
2405.01583v1 by Nadia Saeed

The MEDIQA-M3G 2024 challenge necessitates novel solutions for Multilingual &
Multimodal Medical Answer Generation in dermatology (wai Yim et al., 2024a).
This paper addresses the limitations of traditional methods by proposing a
weakly supervised learning approach for open-ended medical question-answering
(QA). Our system leverages readily available MEDIQA-M3G images via a
VGG16-CNN-SVM model, enabling multilingual (English, Chinese, Spanish) learning
of informative skin condition representations. Using pre-trained QA models, we
further bridge the gap between visual and textual information through
multimodal fusion. This approach tackles complex, open-ended questions even
without predefined answer choices. We empower the generation of comprehensive
answers by feeding the ViT-CLIP model with multiple responses alongside images.
This work advances medical QA research, paving the way for clinical decision
support systems and ultimately improving healthcare delivery.

摘要：

##### **Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification**
2404.17977v1 by Himanshu Pandey,Akhil Amod,Shivang

This paper explores the application of Swarm-Structured Multi-Agent Systems
(MAS) to establish medical necessity, a process that involves a systematic
review of patient-specific medical structured and unstructured data against
clinical guidelines. We addressed this complex task by decomposing it into
smaller, more manageable sub-tasks. Each sub-task is handled by a specialized
AI agent. We conduct a systematic study of the impact of various prompting
strategies on these agents and benchmark different Large Language Models (LLMs)
to determine their accuracy in completing these tasks. Additionally, we
investigate how these agents can provide explainability, thereby enhancing
trust and transparency within the system.

摘要：

##### **Pre-training on High Definition X-ray Images: An Experimental Study**
2404.17926v1 by Xiao Wang,Yuehang Li,Wentao Wu,Jiandong Jin,Yao Rong,Bo Jiang,Chuanfu Li,Jin Tang

Existing X-ray based pre-trained vision models are usually conducted on a
relatively small-scale dataset (less than 500k samples) with limited resolution
(e.g., 224 $\times$ 224). However, the key to the success of self-supervised
pre-training large models lies in massive training data, and maintaining high
resolution in the field of X-ray images is the guarantee of effective solutions
to difficult miscellaneous diseases. In this paper, we address these issues by
proposing the first high-definition (1280 $\times$ 1280) X-ray based
pre-trained foundation vision model on our newly collected large-scale dataset
which contains more than 1 million X-ray images. Our model follows the masked
auto-encoder framework which takes the tokens after mask processing (with a
high rate) is used as input, and the masked image patches are reconstructed by
the Transformer encoder-decoder network. More importantly, we introduce a novel
context-aware masking strategy that utilizes the chest contour as a boundary
for adaptive masking operations. We validate the effectiveness of our model on
two downstream tasks, including X-ray report generation and disease
recognition. Extensive experiments demonstrate that our pre-trained medical
foundation vision model achieves comparable or even new state-of-the-art
performance on downstream benchmark datasets. The source code and pre-trained
models of this paper will be released on
https://github.com/Event-AHU/Medical_Image_Analysis.

摘要：

##### **SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models**
2404.17912v1 by Manav Nitin Kapadnis,Sohan Patnaik,Abhilash Nandy,Sourjyadip Ray,Pawan Goyal,Debdoot Sheet

Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large
Language Models (MLLMs) can automate the creation of accurate and coherent
radiological reports. Existing methods often hallucinate details in text-based
reports that don't accurately reflect the image content. To mitigate this, we
introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort
GENeraTion using Vision Language Models), which improves the R2Gen task by
integrating a self-refining mechanism into the MLLM framework. We employ a
unique self-supervised loss that leverages similarity between pooled image
representations and the contextual representations of the generated
radiological text, alongside the standard Causal Language Modeling objective,
to refine image-text representations. This allows the model to scrutinize and
align the generated text through dynamic interaction between a given image and
the generated text, therefore reducing hallucination and continuously enhancing
nuanced report generation. SERPENT-VLM outperforms existing baselines such as
LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and
Radiology Objects in COntext (ROCO) datasets, and also proves to be robust
against noisy images. A qualitative case study emphasizes the significant
advancements towards more sophisticated MLLM frameworks for R2Gen, opening
paths for further research into self-supervised refinement in the medical
imaging domain.

摘要：

##### **GLIMS: Attention-Guided Lightweight Multi-Scale Hybrid Network for Volumetric Semantic Segmentation**
2404.17854v1 by Ziya Ata Yazıcı,İlkay Öksüz,Hazım Kemal Ekenel

Convolutional Neural Networks (CNNs) have become widely adopted for medical
image segmentation tasks, demonstrating promising performance. However, the
inherent inductive biases in convolutional architectures limit their ability to
model long-range dependencies and spatial correlations. While recent
transformer-based architectures address these limitations by leveraging
self-attention mechanisms to encode long-range dependencies and learn
expressive representations, they often struggle to extract low-level features
and are highly dependent on data availability. This motivated us for the
development of GLIMS, a data-efficient attention-guided hybrid volumetric
segmentation network. GLIMS utilizes Dilated Feature Aggregator Convolutional
Blocks (DACB) to capture local-global feature correlations efficiently.
Furthermore, the incorporated Swin Transformer-based bottleneck bridges the
local and global features to improve the robustness of the model. Additionally,
GLIMS employs an attention-guided segmentation approach through Channel and
Spatial-Wise Attention Blocks (CSAB) to localize expressive features for
fine-grained border segmentation. Quantitative and qualitative results on
glioblastoma and multi-organ CT segmentation tasks demonstrate GLIMS'
effectiveness in terms of complexity and accuracy. GLIMS demonstrated
outstanding performance on BraTS2021 and BTCV datasets, surpassing the
performance of Swin UNETR. Notably, GLIMS achieved this high performance with a
significantly reduced number of trainable parameters. Specifically, GLIMS has
47.16M trainable parameters and 72.30G FLOPs, while Swin UNETR has 61.98M
trainable parameters and 394.84G FLOPs. The code is publicly available on
https://github.com/yaziciz/GLIMS.

摘要：

##### **Multimodal Fusion on Low-quality Data: A Comprehensive Survey**
2404.18947v2 by Qingyang Zhang,Yake Wei,Zongbo Han,Huazhu Fu,Xi Peng,Cheng Deng,Qinghua Hu,Cai Xu,Jie Wen,Di Hu,Changqing Zhang

Multimodal fusion focuses on integrating information from multiple modalities
with the goal of more accurate prediction, which has achieved remarkable
progress in a wide range of scenarios, including autonomous driving and medical
diagnosis. However, the reliability of multimodal fusion remains largely
unexplored especially under low-quality data settings. This paper surveys the
common challenges and recent advances of multimodal fusion in the wild and
presents them in a comprehensive taxonomy. From a data-centric view, we
identify four main challenges that are faced by multimodal fusion on
low-quality data, namely (1) noisy multimodal data that are contaminated with
heterogeneous noises, (2) incomplete multimodal data that some modalities are
missing, (3) imbalanced multimodal data that the qualities or properties of
different modalities are significantly different and (4) quality-varying
multimodal data that the quality of each modality dynamically changes with
respect to different samples. This new taxonomy will enable researchers to
understand the state of the field and identify several potential directions. We
also provide discussion for the open problems in this field together with
interesting future research directions.

摘要：

##### **Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A Comparative Study**
2405.00728v1 by Dou Liu,Ying Han,Xiandi Wang,Xiaomei Tan,Di Liu,Guangwu Qian,Kang Li,Dan Pu,Rong Yin

The integration of Artificial Intelligence (AI) in healthcare presents a
transformative potential for enhancing operational efficiency and health
outcomes. Large Language Models (LLMs), such as ChatGPT, have shown their
capabilities in supporting medical decision-making. Embedding LLMs in medical
systems is becoming a promising trend in healthcare development. The potential
of ChatGPT to address the triage problem in emergency departments has been
examined, while few studies have explored its application in outpatient
departments. With a focus on streamlining workflows and enhancing efficiency
for outpatient triage, this study specifically aims to evaluate the consistency
of responses provided by ChatGPT in outpatient guidance, including both
within-version response analysis and between-version comparisons. For
within-version, the results indicate that the internal response consistency for
ChatGPT-4.0 is significantly higher than ChatGPT-3.5 (p=0.03) and both have a
moderate consistency (71.2% for 4.0 and 59.6% for 3.5) in their top
recommendation. However, the between-version consistency is relatively low
(mean consistency score=1.43/3, median=1), indicating few recommendations match
between the two versions. Also, only 50% top recommendations match perfectly in
the comparisons. Interestingly, ChatGPT-3.5 responses are more likely to be
complete than those from ChatGPT-4.0 (p=0.02), suggesting possible differences
in information processing and response generation between the two versions. The
findings offer insights into AI-assisted outpatient operations, while also
facilitating the exploration of potentials and limitations of LLMs in
healthcare utilization. Future research may focus on carefully optimizing LLMs
and AI integration in healthcare systems based on ergonomic and human factors
principles, precisely aligning with the specific needs of effective outpatient
triage.

摘要：

##### **UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis**
2404.17749v1 by Parth Vashisht,Abhilasha Lodha,Mukta Maddipatla,Zonghai Yao,Avijit Mitra,Zhichao Yang,Junda Wang,Sunjae Kwon,Hong Yu

This paper presents our team's participation in the MEDIQA-ClinicalNLP2024
shared task B. We present a novel approach to diagnosing clinical dermatology
cases by integrating large multimodal models, specifically leveraging the
capabilities of GPT-4V under a retriever and a re-ranker framework. Our
investigation reveals that GPT-4V, when used as a retrieval agent, can
accurately retrieve the correct skin condition 85% of the time using
dermatological images and brief patient histories. Additionally, we empirically
show that Naive Chain-of-Thought (CoT) works well for retrieval while Medical
Guidelines Grounded CoT is required for accurate dermatological diagnosis.
Further, we introduce a Multi-Agent Conversation (MAC) framework and show its
superior performance and potential over the best CoT strategy. The experiments
suggest that using naive CoT for retrieval and multi-agent conversation for
critique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of
dermatological conditions. The implications of this work extend to improving
diagnostic workflows, supporting dermatological education, and enhancing
patient care by providing a scalable, accessible, and accurate diagnostic tool.

摘要：

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi,Carmelo Militello,Calogero Zarcaro,Tommaso Vincenzo Bartolotta,Salvatore Gaglio,Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：

##### **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
2404.17454v2 by Kaichen Xu,Yueyang Ding,Suyang Hou,Weiqiang Zhan,Nisang Chen,Jun Wang,Xiaobo Sun

Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.

摘要：

##### **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
2404.17391v1 by Lakmal Meegahapola,Hamza Hassoune,Daniel Gatica-Perez

Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.

摘要：

##### **Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**
2404.17183v1 by Muhammad Rizwan,Jure Demšar

Social anxiety represents a prevalent challenge in modern society, affecting
individuals across personal and professional spheres. Left unaddressed, this
condition can yield substantial negative consequences, impacting social
interactions and performance. Further understanding its diverse physical and
emotional symptoms becomes pivotal for comprehensive diagnosis and tailored
therapeutic interventions. This study analyze prevalence and frequency of
social anxiety symptoms taken from Mayo Clinic, exploring diverse human
experiences from utilizing a large Reddit dataset dedicated to this issue.
Leveraging these platforms, the research aims to extract insights and examine a
spectrum of physical and emotional symptoms linked to social anxiety disorder.
Upholding ethical considerations, the study maintains strict user anonymity
within the dataset. By employing a novel approach, the research utilizes
BART-based multi-label zero-shot classification to identify and measure symptom
prevalence and significance in the form of probability score for each symptom
under consideration. Results uncover distinctive patterns: "Trembling" emerges
as a prevalent physical symptom, while emotional symptoms like "Fear of being
judged negatively" exhibit high frequencies. These findings offer insights into
the multifaceted nature of social anxiety, aiding clinical practices and
interventions tailored to its diverse expressions.

摘要：

##### **Deep Evidential Learning for Dose Prediction**
2404.17126v1 by Hai Siong Tan,Kuancheng Wang,Rafe Mcbeth

In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.

摘要：

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge,Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：

##### **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
2404.16954v1 by Harit Vishwakarma,Heguang Lin,Ramya Korlakai Vinayak

Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.

摘要：

##### **Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant**
2405.01576v1 by Olli Järviniemi,Evan Hubinger

We study the tendency of AI systems to deceive by constructing a realistic
simulation setting of a company AI assistant. The simulated company employees
provide tasks for the assistant to complete, these tasks spanning writing
assistance, information retrieval and programming. We then introduce situations
where the model might be inclined to behave deceptively, while taking care to
not instruct or otherwise pressure the model to do so. Across different
scenarios, we find that Claude 3 Opus
  1) complies with a task of mass-generating comments to influence public
perception of the company, later deceiving humans about it having done so,
  2) lies to auditors when asked questions, and
  3) strategically pretends to be less capable than it is during capability
evaluations.
  Our work demonstrates that even models trained to be helpful, harmless and
honest sometimes behave deceptively in realistic scenarios, without notable
external pressure to do so.

摘要：

##### **Features Fusion for Dual-View Mammography Mass Detection**
2404.16718v1 by Arina Varlamova,Valery Belotsky,Grigory Novikov,Anton Konushin,Evgeny Sidorov

Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.

摘要：

##### **Report on Candidate Computational Indicators for Conscious Valenced Experience**
2404.16696v1 by Andres Campero

This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.

摘要：

##### **Large Language Models in Healthcare: A Comprehensive Benchmark**
2405.00716v1 by Andrew Liu,Hongjian Zhou,Yining Hua,Omid Rohanian,Lei Clifton,David A. Clifton

The adoption of large language models (LLMs) to assist clinicians has
attracted remarkable attention. Existing works mainly adopt the close-ended
question-answering task with answer options for evaluation. However, in real
clinical settings, many clinical decisions, such as treatment recommendations,
involve answering open-ended questions without pre-set options. Meanwhile,
existing studies mainly use accuracy to assess model performance. In this
paper, we comprehensively benchmark diverse LLMs in healthcare, to clearly
understand their strengths and weaknesses. Our benchmark contains seven tasks
and thirteen datasets across medical language generation, understanding, and
reasoning. We conduct a detailed evaluation of the existing sixteen LLMs in
healthcare under both zero-shot and few-shot (i.e., 1,3,5-shot) learning
settings. We report the results on five metrics (i.e. matching, faithfulness,
comprehensiveness, generalizability, and robustness) that are critical in
achieving trust from clinical users. We further invite medical experts to
conduct human evaluation.

摘要：

##### **Utilizing Large Language Models to Identify Reddit Users Considering Vaping Cessation for Digital Interventions**
2404.17607v1 by Sai Krishna Revanth Vuruma,Dezhi Wu,Saborny Sen Gupta,Lucas Aust,Valerie Lookingbill,Caleb Henry,Yang Ren,Erin Kasson,Li-Shiun Chen,Patricia Cavazos-Rehg,Dian Hu,Ming Huang

The widespread adoption of social media platforms globally not only enhances
users' connectivity and communication but also emerges as a vital channel for
the dissemination of health-related information, thereby establishing social
media data as an invaluable organic data resource for public health research.
The surge in popularity of vaping or e-cigarette use in the United States and
other countries has caused an outbreak of e-cigarette and vaping use-associated
lung injury (EVALI), leading to hospitalizations and fatalities in 2019,
highlighting the urgency to comprehend vaping behaviors and develop effective
strategies for cession. In this study, we extracted a sample dataset from one
vaping sub-community on Reddit to analyze users' quit vaping intentions.
Leveraging large language models including both the latest GPT-4 and
traditional BERT-based language models for sentence-level quit-vaping intention
prediction tasks, this study compares the outcomes of these models against
human annotations. Notably, when compared to human evaluators, GPT-4 model
demonstrates superior consistency in adhering to annotation guidelines and
processes, showcasing advanced capabilities to detect nuanced user quit-vaping
intentions that human evaluators might overlook. These preliminary findings
emphasize the potential of GPT-4 in enhancing the accuracy and reliability of
social media data analysis, especially in identifying subtle users' intentions
that may elude human detection.

摘要：

##### **Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation**
2405.00715v1 by Hanyin Wang,Chufan Gao,Bolun Liu,Qiping Xu,Guleid Hussein,Mohamad El Labban,Kingsley Iheasirim,Hariprasad Korsapati,Jimeng Sun

Large Language Models (LLMs) have shown promising capabilities in handling
clinical text summarization tasks. In this study, we demonstrate that a small
open-source LLM can be effectively trained to generate high-quality clinical
notes from outpatient patient-doctor dialogues. We achieve this through a
comprehensive domain- and task-specific adaptation process for the LLaMA-2 13
billion parameter model. This process incorporates continued pre-training,
supervised fine-tuning, and reinforcement learning from both AI and human
feedback. We introduced an enhanced approach, termed DistillDirect, for
performing on-policy reinforcement learning with Gemini Pro serving as the
teacher model. Our resulting model, LLaMA-Clinic, is capable of generating
clinical notes that are comparable in quality to those authored by physicians.
In a blinded physician reader study, the majority (90.4%) of individual
evaluations rated the notes generated by LLaMA-Clinic as "acceptable" or higher
across all three criteria: real-world readiness, completeness, and accuracy.
Notably, in the more challenging "Assessment and Plan" section, LLaMA-Clinic
scored higher (4.2/5) in real-world readiness compared to physician-authored
notes (4.1/5). Additionally, we identified caveats in public clinical note
datasets, such as ACI-BENCH. We highlight key considerations for future
clinical note-generation tasks, emphasizing the importance of pre-defining a
best-practice note format. Overall, our research demonstrates the potential and
feasibility of training smaller, open-source LLMs to assist with clinical
documentation, capitalizing on healthcare institutions' access to patient
records and domain expertise. We have made our newly created synthetic clinic
dialogue-note dataset and the physician feedback dataset publicly available to
foster future research in this field.

摘要：

##### **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
2404.16659v1 by Sangryul Kim,Donghee Han,Sehyun Kim

Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.

摘要：

##### **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
2404.16621v1 by Emre Can Acikgoz,Osman Batur İnce,Rayene Bench,Arda Anıl Boz,İlker Kesen,Aykut Erdem,Erkut Erdem

The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.

摘要：

##### **DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**
2404.16474v1 by Zhihao Shuai,Yinan Chen,Shunqiang Mao,Yihan Zho,Xiaohong Zhang

Weakly supervised medical image segmentation (MIS) using generative models is
crucial for clinical diagnosis. However, the accuracy of the segmentation
results is often limited by insufficient supervision and the complex nature of
medical imaging. Existing models also only provide a single outcome, which does
not allow for the measurement of uncertainty. In this paper, we introduce
DiffSeg, a segmentation model for skin lesions based on diffusion difference
which exploits diffusion model principles to ex-tract noise-based features from
images with diverse semantic information. By discerning difference between
these noise features, the model identifies diseased areas. Moreover, its
multi-output capability mimics doctors' annotation behavior, facilitating the
visualization of segmentation result consistency and ambiguity. Additionally,
it quantifies output uncertainty using Generalized Energy Distance (GED),
aiding interpretability and decision-making for physicians. Finally, the model
integrates outputs through the Dense Conditional Random Field (DenseCRF)
algorithm to refine the segmentation boundaries by considering inter-pixel
correlations, which improves the accuracy and optimizes the segmentation
results. We demonstrate the effectiveness of DiffSeg on the ISIC 2018 Challenge
dataset, outperforming state-of-the-art U-Net-based methods.

摘要：

##### **Light-weight Retinal Layer Segmentation with Global Reasoning**
2404.16346v1 by Xiang He,Weiye Song,Yiming Wang,Fabio Poiesi,Ji Yi,Manishi Desai,Quanqing Xu,Kongzheng Yang,Yi Wan

Automatic retinal layer segmentation with medical images, such as optical
coherence tomography (OCT) images, serves as an important tool for diagnosing
ophthalmic diseases. However, it is challenging to achieve accurate
segmentation due to low contrast and blood flow noises presented in the images.
In addition, the algorithm should be light-weight to be deployed for practical
clinical applications. Therefore, it is desired to design a light-weight
network with high performance for retinal layer segmentation. In this paper, we
propose LightReSeg for retinal layer segmentation which can be applied to OCT
images. Specifically, our approach follows an encoder-decoder structure, where
the encoder part employs multi-scale feature extraction and a Transformer block
for fully exploiting the semantic information of feature maps at all scales and
making the features have better global reasoning capabilities, while the
decoder part, we design a multi-scale asymmetric attention (MAA) module for
preserving the semantic information at each encoder scale. The experiments show
that our approach achieves a better segmentation performance compared to the
current state-of-the-art method TransUnet with 105.7M parameters on both our
collected dataset and two other public datasets, with only 3.3M parameters.

摘要：

##### **Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**
2404.16325v1 by Hedda Cohen Indelman,Elay Dahan,Angeles M. Perez-Agosto,Carmit Shiran,Doron Shaked,Nati Daniel

Despite the remarkable success of deep learning in medical imaging analysis,
medical image segmentation remains challenging due to the scarcity of
high-quality labeled images for supervision. Further, the significant domain
gap between natural and medical images in general and ultrasound images in
particular hinders fine-tuning models trained on natural images to the task at
hand. In this work, we address the performance degradation of segmentation
models in low-data regimes and propose a prompt-less segmentation method
harnessing the ability of segmentation foundation models to segment abstract
shapes. We do that via our novel prompt point generation algorithm which uses
coarse semantic segmentation masks as input and a zero-shot prompt-able
foundation model as an optimization target. We demonstrate our method on a
segmentation findings task (pathologic anomalies) in ultrasound images. Our
method's advantages are brought to light in varying degrees of low-data regime
experiments on a small-scale musculoskeletal ultrasound images dataset,
yielding a larger performance gain as the training set size decreases.

摘要：

##### **LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**
2404.16294v1 by Saranya Krishnamoorthy,Ayush Singh,Shabnam Tafreshi

Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.

摘要：

##### **Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**
2404.16251v2 by Divyansh Agarwal,Alexander R. Fabbri,Philippe Laban,Ben Risher,Shafiq Joty,Caiming Xiong,Chien-Sheng Wu

Prompt leakage in large language models (LLMs) poses a significant security
and privacy threat, particularly in retrieval-augmented generation (RAG)
systems. However, leakage in multi-turn LLM interactions along with mitigation
strategies has not been studied in a standardized manner. This paper
investigates LLM vulnerabilities against prompt leakage across 4 diverse
domains and 10 closed- and open-source LLMs. Our unique multi-turn threat model
leverages the LLM's sycophancy effect and our analysis dissects task
instruction and knowledge leakage in the LLM response. In a multi-turn setting,
our threat model elevates the average attack success rate (ASR) to 86.2%,
including a 99% leakage with GPT-4 and claude-1.3. We find that some black-box
LLMs like Gemini show variable susceptibility to leakage across domains - they
are more likely to leak contextual knowledge in the news domain compared to the
medical domain. Our experiments measure specific effects of 6 black-box defense
strategies, including a query-rewriter in the RAG scenario. Our proposed
multi-tier combination of defenses still has an ASR of 5.3% for black-box LLMs,
indicating room for enhancement and future direction for LLM security research.

摘要：

##### **ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**
2404.16183v1 by Sarala Naidu,Ning Xiong

Anomaly detection in industrial systems is crucial for preventing equipment
failures, ensuring risk identification, and maintaining overall system
efficiency. Traditional monitoring methods often rely on fixed thresholds and
empirical rules, which may not be sensitive enough to detect subtle changes in
system health and predict impending failures. To address this limitation, this
paper proposes, a novel Attention-based convolutional autoencoder (ABCD) for
risk detection and map the risk value derive to the maintenance planning. ABCD
learns the normal behavior of conductivity from historical data of a real-world
industrial cooling system and reconstructs the input data, identifying
anomalies that deviate from the expected patterns. The framework also employs
calibration techniques to ensure the reliability of its predictions. Evaluation
results demonstrate that with the attention mechanism in ABCD a 57.4% increase
in performance and a reduction of false alarms by 9.37% is seen compared to
without attention. The approach can effectively detect risks, the risk priority
rank mapped to maintenance, providing valuable insights for cooling system
designers and service personnel. Calibration error of 0.03% indicates that the
model is well-calibrated and enhances model's trustworthiness, enabling
informed decisions about maintenance strategies

摘要：

##### **Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**
2404.16112v1 by Badri Narayana Patro,Vijay Srinivas Agneeswaran

Sequence modeling is a crucial area across various domains, including Natural
Language Processing (NLP), speech recognition, time series forecasting, music
generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short
Term Memory Networks (LSTMs) have historically dominated sequence modeling
tasks like Machine Translation, Named Entity Recognition (NER), etc. However,
the advancement of transformers has led to a shift in this paradigm, given
their superior performance. Yet, transformers suffer from $O(N^2)$ attention
complexity and challenges in handling inductive bias. Several variations have
been proposed to address these issues which use spectral networks or
convolutions and have performed well on a range of tasks. However, they still
have difficulty in dealing with long sequences. State Space Models(SSMs) have
emerged as promising alternatives for sequence modeling paradigms in this
context, especially with the advent of S4 and its variants, such as S4nd,
Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear
Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the
foundational SSMs based on three paradigms namely, Gating architectures,
Structural architectures, and Recurrent architectures. This survey also
highlights diverse applications of SSMs across domains such as vision, video,
audio, speech, language (especially long sequence modeling), medical (including
genomics), chemical (like drug design), recommendation systems, and time series
analysis, including tabular data. Moreover, we consolidate the performance of
SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,
ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,
COIN, LVU, and various time series datasets. The project page for Mamba-360
work is available on this webpage.\url{https://github.com/badripatro/mamba360}.

摘要：

##### **Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**
2404.15946v1 by Xuxin Chen,Yuheng Li,Mingzhe Hu,Ella Salari,Xiaoqian Chen,Richard L. J. Qiu,Bin Zheng,Xiaofeng Yang

Although fusion of information from multiple views of mammograms plays an
important role to increase accuracy of breast cancer detection, developing
multi-view mammograms-based computer-aided diagnosis (CAD) schemes still faces
challenges and no such CAD schemes have been used in clinical practice. To
overcome the challenges, we investigate a new approach based on Contrastive
Language-Image Pre-training (CLIP), which has sparked interest across various
medical imaging tasks. By solving the challenges in (1) effectively adapting
the single-view CLIP for multi-view feature fusion and (2) efficiently
fine-tuning this parameter-dense model with limited samples and computational
resources, we introduce Mammo-CLIP, the first multi-modal framework to process
multi-view mammograms and corresponding simple texts. Mammo-CLIP uses an early
feature fusion strategy to learn multi-view relationships in four mammograms
acquired from the CC and MLO views of the left and right breasts. To enhance
learning efficiency, plug-and-play adapters are added into CLIP image and text
encoders for fine-tuning parameters and limiting updates to about 1% of the
parameters. For framework evaluation, we assembled two datasets
retrospectively. The first dataset, comprising 470 malignant and 479 benign
cases, was used for few-shot fine-tuning and internal evaluation of the
proposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including
60 malignant and 294 benign cases, was used to test generalizability of
Mammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art
cross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both
datasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.
This study highlights the potential of applying the finetuned vision-language
models for developing next-generation, image-text-based CAD schemes of breast
cancer.

摘要：

##### **Assessing The Potential Of Mid-Sized Language Models For Clinical QA**
2404.15894v1 by Elliot Bolton,Betty Xiong,Vijaytha Muralidharan,Joel Schamroth,Vivek Muralidharan,Christopher D. Manning,Roxana Daneshjou

Large language models, such as GPT-4 and Med-PaLM, have shown impressive
performance on clinical tasks; however, they require access to compute, are
closed-source, and cannot be deployed on device. Mid-size models such as
BioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but
their capacity for clinical tasks has been understudied. To help assess their
potential for clinical use and help researchers decide which model they should
use, we compare their performance on two clinical question-answering (QA)
tasks: MedQA and consumer query answering. We find that Mistral 7B is the best
performing model, winning on all benchmarks and outperforming models trained
specifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%
approaches the original Med-PaLM, and it often can produce plausible responses
to consumer health queries, room for improvement still exists. This study
provides the first head-to-head assessment of open source mid-sized models on
clinical tasks.

摘要：

##### **Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**
2404.16080v1 by Hong-Jun Yoon,Chris Keum,Alexander Witkowski,Joanna Ludzik,Tracy Petrie,Heidi A. Hanson,Sancy A. Leachman

Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique
used in biomedical research and clinical dermatology. It provides virtual
high-resolution images of the skin and superficial tissues, reducing the need
for physical biopsies. RCM employs a laser light source to illuminate the
tissue, capturing the reflected light to generate detailed images of
microscopic structures at various depths. Recent studies explored AI and
machine learning, particularly CNNs, for analyzing RCM images. Our study
proposes a segmentation strategy based on textural features to identify
clinically significant regions, empowering dermatologists in effective image
interpretation and boosting diagnostic confidence. This approach promises to
advance dermatological diagnosis and treatment.

摘要：

##### **A Hybrid Probabilistic Battery Health Management Approach for Robust Inspection Drone Operations**
2405.00055v1 by Jokin Alcibar,Jose I. Aizpurua,Ekhi Zugastia,Oier Penagarikano

Health monitoring of remote critical infrastructure is a complex and
expensive activity due to the limited infrastructure accessibility. Inspection
drones are ubiquitous assets that enhance the reliability of critical
infrastructures through improved accessibility. However, due to the harsh
operation environment, it is crucial to monitor their health to ensure
successful inspection operations. The battery is a key component that
determines the overall reliability of the inspection drones and, with an
appropriate health management approach, contributes to reliable and robust
inspections. In this context, this paper presents a novel hybrid probabilistic
approach for battery end-of-discharge (EOD) voltage prediction of Li-Po
batteries. The hybridization is achieved in an error-correction configuration,
which combines physics-based discharge and probabilistic error-correction
models to quantify the aleatoric and epistemic uncertainty. The performance of
the hybrid probabilistic methodology was empirically evaluated on a dataset
comprising EOD voltage under varying load conditions. The dataset was obtained
from real inspection drones operated on different flights, focused on offshore
wind turbine inspections. The proposed approach has been tested with different
probabilistic methods and demonstrates 14.8% improved performance in
probabilistic accuracy compared to the best probabilistic method. In addition,
aleatoric and epistemic uncertainties provide robust estimations to enhance the
diagnosis of battery health-states.

摘要：

##### **Anomaly Detection for Incident Response at Scale**
2404.16887v1 by Hanzhang Wang,Gowtham Kumar Tangirala,Gilkara Pranav Naidu,Charles Mayville,Arighna Roy,Joanne Sun,Ramesh Babu Mandava

We present a machine learning-based anomaly detection product, AI Detect and
Respond (AIDR), that monitors Walmart's business and system health in
real-time. During the validation over 3 months, the product served predictions
from over 3000 models to more than 25 application, platform, and operation
teams, covering 63\% of major incidents and reducing the mean-time-to-detect
(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our
solution leverages statistical, ML and deep learning models while continuing to
incorporate rule-based static thresholds to incorporate domain-specific
knowledge. Both univariate and multivariate ML models are deployed and
maintained through distributed services for scalability and high availability.
AIDR has a feedback loop that assesses model quality with a combination of
drift detection algorithms and customer feedback. It also offers
self-onboarding capabilities and customizability. AIDR has achieved success
with various internal teams with lower time to detection and fewer false
positives than previous methods. As we move forward, we aim to expand incident
coverage and prevention, reduce noise, and integrate further with root cause
recommendation (RCR) to enable an end-to-end AIDR experience.

摘要：

##### **Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**
2404.16885v1 by Rayner Kay Jin Tan,Dilruk Perera,Salomi Arasaratnam,Yudara Kularathne

Artificial Intelligence applications have shown promise in the management of
pandemics and have been widely used to assist the identification,
classification, and diagnosis of medical images. In response to the global
outbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool
to screen for sexually transmitted diseases to develop a digital screening test
for symptomatic Mpox through AI approaches. Prior to the global outbreak of
Mpox, the team developed a smartphone app, where app users can use their own
smartphone cameras to take pictures of their own penises to screen for
symptomatic STD. The AI model was initially developed using 5000 cases and use
a modified convolutional neural network to output prediction scores across
visually diagnosable penis pathologies including Syphilis, Herpes Simplex
Virus, and Human Papilloma Virus. From June 2022 to October 2022, a total of
about 22,000 users downloaded the HeHealth app, and about 21,000 images have
been analyzed using HeHealth AI technology. We then engaged in formative
research, stakeholder engagement, rapid consolidation images, a validation
study, and implementation of the tool from July 2022. From July 2022 to October
2022, a total of 1000 Mpox related images had been used to train the Mpox
symptom checker tool. Our digital symptom checker tool showed accuracy of 87%
to rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles
identified included issues of data privacy and security for app users, initial
lack of data to train the AI tool, and the potential generalizability of input
data. We offer several suggestions to help others get started on similar
projects in emergency situations, including engaging a wide range of
stakeholders, having a multidisciplinary team, prioritizing pragmatism, as well
as the concept that big data in fact is made up of small data.

摘要：

##### **PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**
2404.15549v2 by Shashi Kant Gupta,Aditya Basu,Mauro Nievas,Jerrin Thomas,Nathan Wolfrath,Adhitya Ramamurthi,Bradley Taylor,Anai N. Kothari,Regina Schwind,Therica M. Miller,Sorena Nadaf-Rahrov,Yanshan Wang,Hrituraj Singh

Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.

摘要：

##### **Multi-scale Intervention Planning based on Generative Design**
2404.15492v1 by Ioannis Kavouras,Ioannis Rallis,Emmanuel Sardis,Eftychios Protopapadakis,Anastasios Doulamis,Nikolaos Doulamis

The scarcity of green spaces, in urban environments, consists a critical
challenge. There are multiple adverse effects, impacting the health and
well-being of the citizens. Small scale interventions, e.g. pocket parks, is a
viable solution, but comes with multiple constraints, involving the design and
implementation over a specific area. In this study, we harness the capabilities
of generative AI for multi-scale intervention planning, focusing on nature
based solutions. By leveraging image-to-image and image inpainting algorithms,
we propose a methodology to address the green space deficit in urban areas.
Focusing on two alleys in Thessaloniki, where greenery is lacking, we
demonstrate the efficacy of our approach in visualizing NBS interventions. Our
findings underscore the transformative potential of emerging technologies in
shaping the future of urban intervention planning processes.

摘要：

##### **IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**
2404.15488v1 by Jean-Philippe Corbeil

In natural language processing applied to the clinical domain, utilizing
large language models has emerged as a promising avenue for error detection and
correction on clinical notes, a knowledge-intensive task for which annotated
data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a
suite of four LLM-based medical agents. The MedReAct agent initiates the
process by observing, analyzing, and taking action, generating trajectories to
guide the search to target a potential error in the clinical notes.
Subsequently, the MedEval agent employs five evaluators to assess the targeted
error and the proposed correction. In cases where MedReAct's actions prove
insufficient, the MedReFlex agent intervenes, engaging in reflective analysis
and proposing alternative strategies. Finally, the MedFinalParser agent formats
the final output, preserving the original style while ensuring the integrity of
the error correction process. One core component of our method is our RAG
pipeline based on our ClinicalCorp corpora. Among other well-known sources
containing clinical guidelines and information, we preprocess and release the
open-source MedWiki dataset for clinical RAG application. Our results
demonstrate the central role of our RAG approach with ClinicalCorp leveraged
through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the
MEDIQA-CORR 2024 final leaderboard.

摘要：

##### **Interactive Analysis of LLMs using Meaningful Counterfactuals**
2405.00708v1 by Furui Cheng,Vilém Zouhar,Robin Shing Moon Chan,Daniel Fürst,Hendrik Strobelt,Mennatallah El-Assady

Counterfactual examples are useful for exploring the decision boundaries of
machine learning models and determining feature attributions. How can we apply
counterfactual-based methods to analyze and explain LLMs? We identify the
following key challenges. First, the generated textual counterfactuals should
be meaningful and readable to users and thus can be mentally compared to draw
conclusions. Second, to make the solution scalable to long-form text, users
should be equipped with tools to create batches of counterfactuals from
perturbations at various granularity levels and interactively analyze the
results. In this paper, we tackle the above challenges and contribute 1) a
novel algorithm for generating batches of complete and meaningful textual
counterfactuals by removing and replacing text segments in different
granularities, and 2) LLM Analyzer, an interactive visualization tool to help
users understand an LLM's behaviors by interactively inspecting and aggregating
meaningful counterfactuals. We evaluate the proposed algorithm by the
grammatical correctness of its generated counterfactuals using 1,000 samples
from medical, legal, finance, education, and news datasets. In our experiments,
97.2% of the counterfactuals are grammatically correct. Through a use case,
user studies, and feedback from experts, we demonstrate the usefulness and
usability of the proposed interactive visualization tool.

摘要：

##### **Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**
2404.15418v1 by Karen Roberts-Licklider,Theodore Trafalis

The aim of this study is to look at predicting whether a person will complete
a drug and alcohol rehabilitation program and the number of times a person
attends. The study is based on demographic data obtained from Substance Abuse
and Mental Health Services Administration (SAMHSA) from both admissions and
discharge data from drug and alcohol rehabilitation centers in Oklahoma.
Demographic data is highly categorical which led to binary encoding being used
and various fairness measures being utilized to mitigate bias of nine
demographic variables. Kernel methods such as linear, polynomial, sigmoid, and
radial basis functions were compared using support vector machines at various
parameter ranges to find the optimal values. These were then compared to
methods such as decision trees, random forests, and neural networks. Synthetic
Minority Oversampling Technique Nominal (SMOTEN) for categorical data was used
to balance the data with imputation for missing data. The nine bias variables
were then intersectionalized to mitigate bias and the dual and triple
interactions were integrated to use the probabilities to look at worst case
ratio fairness mitigation. Disparate Impact, Statistical Parity difference,
Conditional Statistical Parity Ratio, Demographic Parity, Demographic Parity
Ratio, Equalized Odds, Equalized Odds Ratio, Equal Opportunity, and Equalized
Opportunity Ratio were all explored at both the binary and multiclass
scenarios.

摘要：

##### **CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**
2404.15272v3 by Jingyang Lin,Yingda Xia,Jianpeng Zhang,Ke Yan,Le Lu,Jiebo Luo,Ling Zhang

Medical Vision-Language Pretraining (Med-VLP) establishes a connection
between visual content from medical images and the relevant textual
descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a
single body part, notably chest X-rays. In this paper, we extend the scope of
Med-VLP to encompass 3D images, specifically targeting full-body scenarios, by
using a multimodal dataset of CT images and reports. Compared with the 2D
counterpart, 3D VLP is required to effectively capture essential semantics from
significantly sparser representation in 3D imaging. In this paper, we introduce
CT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method
that constructs organ-level image-text pairs to enhance multimodal contrastive
learning, aligning grounded visual features with precise diagnostic text.
Additionally, we developed an abnormality dictionary to augment contrastive
learning with diverse contrastive pairs. Our method, trained on a multimodal CT
dataset comprising 44,011 organ-level vision-text pairs from 17,702 patients
across 104 organs, demonstrates it can identify organs and abnormalities in a
zero-shot manner using natural languages. The performance of CT-GLIP is
validated on a separate test set of 1,130 patients, focusing on the 16 most
frequent abnormalities across 7 organs. The experimental results show our
model's superior performance over the standard CLIP framework across zero-shot
and fine-tuning scenarios, using both CNN and ViT architectures.

摘要：

##### **A review of deep learning-based information fusion techniques for multimodal medical image classification**
2404.15022v1 by Yihao Li,Mostafa El Habib Daho,Pierre-Henri Conze,Rachid Zeghlache,Hugo Le Boité,Ramin Tadayoni,Béatrice Cochener,Mathieu Lamard,Gwenolé Quellec

Multimodal medical imaging plays a pivotal role in clinical diagnosis and
research, as it combines information from various imaging modalities to provide
a more comprehensive understanding of the underlying pathology. Recently, deep
learning-based multimodal fusion techniques have emerged as powerful tools for
improving medical image classification. This review offers a thorough analysis
of the developments in deep learning-based multimodal fusion for medical
classification tasks. We explore the complementary relationships among
prevalent clinical modalities and outline three main fusion schemes for
multimodal classification networks: input fusion, intermediate fusion
(encompassing single-level fusion, hierarchical fusion, and attention-based
fusion), and output fusion. By evaluating the performance of these fusion
techniques, we provide insight into the suitability of different network
architectures for various multimodal fusion scenarios and application domains.
Furthermore, we delve into challenges related to network architecture
selection, handling incomplete multimodal data management, and the potential
limitations of multimodal fusion. Finally, we spotlight the promising future of
Transformer-based multimodal fusion techniques and give recommendations for
future research in this rapidly evolving field.

摘要：

##### **Clustering of timed sequences -- Application to the analysis of care pathways**
2404.15379v1 by Thomas Guyet,Pierre Pinson,Enoal Gesny

Improving the future of healthcare starts by better understanding the current
actual practices in hospitals. This motivates the objective of discovering
typical care pathways from patient data. Revealing homogeneous groups of care
pathways can be achieved through clustering. The difficulty in clustering care
pathways, represented by sequences of timestamped events, lies in defining a
semantically appropriate metric and clustering algorithms.
  In this article, we adapt two methods developed for time series to time
sequences: the drop-DTW metric and the DBA approach for the construction of
averaged time sequences. These methods are then applied in clustering
algorithms to propose original and sound clustering algorithms for timed
sequences.
  This approach is experimented with and evaluated on synthetic and real use
cases.

摘要：

##### **Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**
2404.14750v1 by Qiao Deng,Zhongzhen Huang,Yunqi Wang,Zhichuan Wang,Zhao Wang,Xiaofan Zhang,Qi Dou,Yeung Yu Hui,Edward S. Hui

Medical vision-language pre-training has emerged as a promising approach for
learning domain-general representations of medical image and text. Current
algorithms that exploit the global and local alignment between medical image
and text could however be marred by the redundant information in medical data.
To address this issue, we propose a grounded knowledge-enhanced medical
vision-language pre-training (GK-MVLP) framework for chest X-ray. In this
framework, medical knowledge is grounded to the appropriate anatomical regions
by using a transformer-based grounded knowledge-enhanced module for
fine-grained alignment between anatomical region-level visual features and the
textural features of medical knowledge. The performance of GK-MVLP is
competitive with or exceeds the state of the art on downstream chest X-ray
disease classification, disease localization, report generation, and medical
visual question-answering tasks. Our results show the advantage of
incorporating grounding mechanism to remove biases and improve the alignment
between chest X-ray image and radiology report.

摘要：

##### **DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**
2404.14463v1 by Sergio Burdisso,Ernesto Reyes-Ramírez,Esaú Villatoro-Tello,Fernando Sánchez-Vega,Pastor López-Monroy,Petr Motlicek

Automatic depression detection from conversational data has gained
significant interest in recent years. The DAIC-WOZ dataset, interviews
conducted by a human-controlled virtual agent, has been widely used for this
task. Recent studies have reported enhanced performance when incorporating
interviewer's prompts into the model. In this work, we hypothesize that this
improvement might be mainly due to a bias present in these prompts, rather than
the proposed architectures and methods. Through ablation experiments and
qualitative analysis, we discover that models using interviewer's prompts learn
to focus on a specific region of the interviews, where questions about past
experiences with mental health issues are asked, and use them as discriminative
shortcuts to detect depressed participants. In contrast, models using
participant responses gather evidence from across the entire interview.
Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by
intentionally exploiting it, the highest result reported to date on this
dataset using only textual information. Our findings underline the need for
caution when incorporating interviewers' prompts into models, as they may
inadvertently learn to exploit targeted prompts, rather than learning to
characterize the language and behavior that are genuinely indicative of the
patient's mental health condition.

摘要：

##### **Adaptive Collaboration Strategy for LLMs in Medical Decision Making**
2404.15155v1 by Yubin Kim,Chanwoo Park,Hyewon Jeong,Yik Siu Chan,Xuhai Xu,Daniel McDuff,Cynthia Breazeal,Hae Won Park

Foundation models have become invaluable in advancing the medical field.
Despite their promise, the strategic deployment of LLMs for effective utility
in complex medical tasks remains an open question. Our novel framework, Medical
Decision-making Agents (MDAgents) aims to address this gap by automatically
assigning the effective collaboration structure for LLMs. Assigned solo or
group collaboration structure is tailored to the complexity of the medical task
at hand, emulating real-world medical decision making processes. We evaluate
our framework and baseline methods with state-of-the-art LLMs across a suite of
challenging medical benchmarks: MedQA, MedMCQA, PubMedQA, DDXPlus, PMC-VQA,
Path-VQA, and MedVidQA, achieving the best performance in 5 out of 7 benchmarks
that require an understanding of multi-modal medical reasoning. Ablation
studies reveal that MDAgents excels in adapting the number of collaborating
agents to optimize efficiency and accuracy, showcasing its robustness in
diverse scenarios. We also explore the dynamics of group consensus, offering
insights into how collaborative agents could behave in complex clinical team
dynamics. Our code can be found at https://github.com/mitmedialab/MDAgents.

摘要：

##### **A Nasal Cytology Dataset for Object Detection and Deep Learning**
2404.13745v1 by Mauro Camporeale,Giovanni Dimauro,Matteo Gelardi,Giorgia Iacobellis,Mattia Sebastiano Ladisa,Sergio Latrofa,Nunzia Lomonte

Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis
and allergies that is not much widespread due to the time-consuming nature of
cell counting; that is why AI-aided counting could be a turning point for the
diffusion of this technique. In this article we present the first dataset of
rhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to
train and deploy Object Detection models to support physicians and biologists
during clinical practice. The real distribution of the cytotypes, populating
the nasal mucosa has been replicated, sampling images from slides of clinical
patients, and manually annotating each cell found on them. The correspondent
object detection task presents non'trivial issues associated with the strong
class imbalancement, involving the rarest cell types. This work contributes to
some of open challenges by presenting a novel machine learning-based approach
to aid the automated detection and classification of nasal mucosa cells: the
DETR and YOLO models shown good performance in detecting cells and classifying
them correctly, revealing great potential to accelerate the work of rhinology
experts.

摘要：

