{"2408.15545": {"publish_time": "2024-08-28", "title": "SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding", "paper_summary": "Scientific literature understanding is crucial for extracting targeted\ninformation and garnering insights, thereby significantly advancing scientific\ndiscovery. Despite the remarkable success of Large Language Models (LLMs), they\nface challenges in scientific literature understanding, primarily due to (1) a\nlack of scientific knowledge and (2) unfamiliarity with specialized scientific\ntasks.\n  To develop an LLM specialized in scientific literature understanding, we\npropose a hybrid strategy that integrates continual pre-training (CPT) and\nsupervised fine-tuning (SFT), to simultaneously infuse scientific domain\nknowledge and enhance instruction-following capabilities for domain-specific\ntasks.cIn this process, we identify two key challenges: (1) constructing\nhigh-quality CPT corpora, and (2) generating diverse SFT instructions. We\naddress these challenges through a meticulous pipeline, including PDF text\nextraction, parsing content error correction, quality filtering, and synthetic\ninstruction creation. Applying this strategy, we present a suite of LLMs:\nSciLitLLM, specialized in scientific literature understanding. These models\ndemonstrate promising performance on scientific literature understanding\nbenchmarks.\n  Our contributions are threefold: (1) We present an effective framework that\nintegrates CPT and SFT to adapt LLMs to scientific literature understanding,\nwhich can also be easily adapted to other domains. (2) We propose an LLM-based\nsynthesis method to generate diverse and high-quality scientific instructions,\nresulting in a new instruction set -- SciLitIns -- for supervised fine-tuning\nin less-represented scientific domains. (3) SciLitLLM achieves promising\nperformance improvements on scientific literature understanding benchmarks.", "paper_summary_zh": "<paragraph>\u79d1\u5b78\u6587\u737b\u7406\u89e3\u5c0d\u65bc\u8403\u53d6\u76ee\u6a19\u8cc7\u8a0a\u548c\u6536\u96c6\u898b\u89e3\u81f3\u95dc\u91cd\u8981\uff0c\u9032\u800c\u986f\u8457\u63a8\u9032\u79d1\u5b78\u767c\u73fe\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7372\u5f97\u975e\u51e1\u7684\u6210\u529f\uff0c\u4f46\u5b83\u5011\u5728\u79d1\u5b78\u6587\u737b\u7406\u89e3\u65b9\u9762\u4ecd\u9762\u81e8\u6311\u6230\uff0c\u5176\u4e3b\u8981\u539f\u56e0\u6709\uff1a(1) \u7f3a\u4e4f\u79d1\u5b78\u77e5\u8b58\uff0c\u4ee5\u53ca (2) \u4e0d\u719f\u6089\u5c08\u696d\u79d1\u5b78\u4efb\u52d9\u3002\n\u70ba\u4e86\u958b\u767c\u5c08\u7cbe\u65bc\u79d1\u5b78\u6587\u737b\u7406\u89e3\u7684 LLM\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6574\u5408\u6301\u7e8c\u9810\u8a13\u7df4 (CPT) \u548c\u76e3\u7763\u5fae\u8abf (SFT) \u7684\u6df7\u5408\u7b56\u7565\uff0c\u4ee5\u540c\u6642\u704c\u8f38\u79d1\u5b78\u9818\u57df\u77e5\u8b58\u4e26\u589e\u5f37\u7279\u5b9a\u9818\u57df\u4efb\u52d9\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002\u5728\u6b64\u904e\u7a0b\u4e2d\uff0c\u6211\u5011\u627e\u51fa\u5169\u500b\u95dc\u9375\u6311\u6230\uff1a(1) \u5efa\u69cb\u9ad8\u54c1\u8cea\u7684 CPT \u8a9e\u6599\u5eab\uff0c\u4ee5\u53ca (2) \u7522\u751f\u591a\u6a23\u7684 SFT \u6307\u4ee4\u3002\u6211\u5011\u900f\u904e\u4e00\u500b\u7d30\u7dfb\u7684\u6d41\u7a0b\u4f86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\uff0c\u5305\u62ec PDF \u6587\u5b57\u8403\u53d6\u3001\u89e3\u6790\u5167\u5bb9\u932f\u8aa4\u4fee\u6b63\u3001\u54c1\u8cea\u904e\u6ffe\u548c\u5408\u6210\u6307\u4ee4\u5efa\u7acb\u3002\u900f\u904e\u61c9\u7528\u6b64\u7b56\u7565\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7d44 LLM\uff1aSciLitLLM\uff0c\u5c08\u7cbe\u65bc\u79d1\u5b78\u6587\u737b\u7406\u89e3\u3002\u9019\u4e9b\u6a21\u578b\u5728\u79d1\u5b78\u6587\u737b\u7406\u89e3\u57fa\u6e96\u4e0a\u5c55\u73fe\u51fa\u4ee4\u4eba\u6eff\u610f\u7684\u6548\u80fd\u3002\n\u6211\u5011\u7684\u8ca2\u737b\u6709\u4e09\u65b9\u9762\uff1a(1) \u6211\u5011\u63d0\u51fa\u4e00\u500b\u6709\u6548\u7684\u67b6\u69cb\uff0c\u6574\u5408 CPT \u548c SFT \u4ee5\u9069\u61c9 LLM \u65bc\u79d1\u5b78\u6587\u737b\u7406\u89e3\uff0c\u9019\u4e5f\u53ef\u4ee5\u8f15\u6613\u5730\u9069\u61c9\u5230\u5176\u4ed6\u9818\u57df\u3002(2) \u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc LLM \u7684\u5408\u6210\u65b9\u6cd5\uff0c\u7528\u65bc\u7522\u751f\u591a\u6a23\u4e14\u9ad8\u54c1\u8cea\u7684\u79d1\u5b78\u6307\u4ee4\uff0c\u9032\u800c\u7522\u751f\u4e00\u500b\u65b0\u7684\u6307\u4ee4\u96c6 -- SciLitIns -- \u7528\u65bc\u5728\u4ee3\u8868\u6027\u8f03\u4f4e\u7684\u79d1\u5b78\u9818\u57df\u4e2d\u9032\u884c\u76e3\u7763\u5fae\u8abf\u3002(3) SciLitLLM \u5728\u79d1\u5b78\u6587\u737b\u7406\u89e3\u57fa\u6e96\u4e0a\u53d6\u5f97\u4ee4\u4eba\u6eff\u610f\u7684\u6548\u80fd\u63d0\u5347\u3002</paragraph>", "author": "Sihang Li et.al.", "authors": "Sihang Li, Jian Huang, Jiaxi Zhuang, Yaorui Shi, Xiaochen Cai, Mingjun Xu, Xiang Wang, Linfeng Zhang, Guolin Ke, Hengxing Cai", "id": "2408.15545v1", "paper_url": "http://arxiv.org/abs/2408.15545v1", "repo": "null"}}