
### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-14**|**Do Large Language Models Reason Causally Like Us? Even Better?**|Hanna M. Dettki et.al.|[2502.10215v1](http://arxiv.org/abs/2502.10215v1)|null|
|**2025-02-14**|**Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**|Daniil Gurgurov et.al.|[2502.10140v1](http://arxiv.org/abs/2502.10140v1)|null|
|**2025-02-14**|**Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**|Chenrui Tie et.al.|[2502.10090v1](http://arxiv.org/abs/2502.10090v1)|null|
|**2025-02-14**|**Decision Information Meets Large Language Models: The Future of Explainable Operations Research**|Yansen Zhang et.al.|[2502.09994v1](http://arxiv.org/abs/2502.09994v1)|null|
|**2025-02-14**|**KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**|Belinda Mo et.al.|[2502.09956v1](http://arxiv.org/abs/2502.09956v1)|null|
|**2025-02-14**|**ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**|Shu Wang et.al.|[2502.09891v1](http://arxiv.org/abs/2502.09891v1)|null|
|**2025-02-13**|**Visual Graph Question Answering with ASP and LLMs for Language Parsing**|Jakob Johannes Bauer et.al.|[2502.09211v1](http://arxiv.org/abs/2502.09211v1)|null|
|**2025-02-12**|**Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**|Doudou Zhou et.al.|[2502.08547v1](http://arxiv.org/abs/2502.08547v1)|null|
|**2025-02-12**|**Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy**|Ruizhan Xue et.al.|[2502.08353v1](http://arxiv.org/abs/2502.08353v1)|null|
|**2025-02-12**|**Graph Foundation Models for Recommendation: A Comprehensive Survey**|Bin Wu et.al.|[2502.08346v2](http://arxiv.org/abs/2502.08346v2)|null|
|**2025-02-12**|**Self-Evaluation for Job-Shop Scheduling**|Imanol Echeverria et.al.|[2502.08684v1](http://arxiv.org/abs/2502.08684v1)|null|
|**2025-02-12**|**Improving Existing Optimization Algorithms with LLMs**|Camilo Chacón Sartori et.al.|[2502.08298v1](http://arxiv.org/abs/2502.08298v1)|null|
|**2025-02-12**|**ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning**|Vy Vo et.al.|[2502.08148v1](http://arxiv.org/abs/2502.08148v1)|null|
|**2025-02-12**|**Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality**|Xin Kang et.al.|[2502.09658v1](http://arxiv.org/abs/2502.09658v1)|null|
|**2025-02-12**|**GCoT: Chain-of-Thought Prompt Learning for Graphs**|Xingtong Yu et.al.|[2502.08092v1](http://arxiv.org/abs/2502.08092v1)|null|
|**2025-02-11**|**Deep Semantic Graph Learning via LLM based Node Enhancement**|Chuanqi Shi et.al.|[2502.07982v1](http://arxiv.org/abs/2502.07982v1)|null|
|**2025-02-10**|**Cardiverse: Harnessing LLMs for Novel Card Game Prototyping**|Danrui Li et.al.|[2502.07128v1](http://arxiv.org/abs/2502.07128v1)|null|
|**2025-02-10**|**GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units**|Arghadip Das et.al.|[2502.06921v2](http://arxiv.org/abs/2502.06921v2)|[link](https://github.com/arghadippurdue/GraNNite)|
|**2025-02-10**|**Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language**|Zhiqiang Zhong et.al.|[2502.06634v1](http://arxiv.org/abs/2502.06634v1)|null|
|**2025-02-10**|**KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment**|Yuxing Lu et.al.|[2502.06472v1](http://arxiv.org/abs/2502.06472v1)|[link](https://github.com/YuxingLu613/KARMA)|
|**2025-02-10**|**RoToR: Towards More Reliable Responses for Order-Invariant Inputs**|Soyoung Yoon et.al.|[2502.08662v1](http://arxiv.org/abs/2502.08662v1)|null|
|**2025-02-10**|**K-ON: Stacking Knowledge On the Head Layer of Large Language Model**|Lingbing Guo et.al.|[2502.06257v1](http://arxiv.org/abs/2502.06257v1)|null|
|**2025-02-10**|**LegalViz: Legal Text Visualization by Text To Diagram Generation**|Eri Onami et.al.|[2502.06147v2](http://arxiv.org/abs/2502.06147v2)|null|
|**2025-02-09**|**Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs**|Han Meng et.al.|[2502.06075v1](http://arxiv.org/abs/2502.06075v1)|null|
|**2025-02-09**|**LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification**|Shubham Kumar Nigam et.al.|[2502.05836v1](http://arxiv.org/abs/2502.05836v1)|null|
|**2025-02-08**|**LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning**|Hanqing Yang et.al.|[2502.05453v1](http://arxiv.org/abs/2502.05453v1)|null|
|**2025-02-08**|**SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation**|Xingtong Yu et.al.|[2502.05424v1](http://arxiv.org/abs/2502.05424v1)|null|
|**2025-02-08**|**Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints**|Ali Al-Lawati et.al.|[2502.05414v1](http://arxiv.org/abs/2502.05414v1)|null|
|**2025-02-08**|**Knowledge Graph-Guided Retrieval Augmented Generation**|Xiangrong Zhu et.al.|[2502.06864v1](http://arxiv.org/abs/2502.06864v1)|[link](https://github.com/nju-websoft/KG2RAG)|
|**2025-02-07**|**Can Large Language Models Understand Intermediate Representations?**|Hailong Jiang et.al.|[2502.06854v1](http://arxiv.org/abs/2502.06854v1)|null|
|**2025-02-07**|**GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?**|Yang Zhou et.al.|[2502.05252v1](http://arxiv.org/abs/2502.05252v1)|null|
|**2025-02-07**|**Causality can systematically address the monsters under the bench(marks)**|Felix Leeb et.al.|[2502.05085v1](http://arxiv.org/abs/2502.05085v1)|null|
|**2025-02-07**|**Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**|Tushar Pandey et.al.|[2502.05078v1](http://arxiv.org/abs/2502.05078v1)|[link](https://github.com/AgnostiqHQ/multi-agent-llm)|
|**2025-02-07**|**Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics**|Hussam Ghanem et.al.|[2502.05239v1](http://arxiv.org/abs/2502.05239v1)|null|
|**2025-02-07**|**Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**|Junde Wu et.al.|[2502.04644v1](http://arxiv.org/abs/2502.04644v1)|[link](https://github.com/theworldofagents/agentic-reasoning)|
|**2025-02-07**|**Position-aware Automatic Circuit Discovery**|Tal Haklay et.al.|[2502.04577v1](http://arxiv.org/abs/2502.04577v1)|[link](https://github.com/technion-cs-nlp/peap)|
|**2025-02-06**|**Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**|Shangbin Feng et.al.|[2502.04510v1](http://arxiv.org/abs/2502.04510v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|[link](https://github.com/snowteam2023/medrag)|
|**2025-02-06**|**Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**|Longquan Jiang et.al.|[2502.03992v1](http://arxiv.org/abs/2502.03992v1)|[link](https://github.com/longquanjiang/ontoscprompt)|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v2](http://arxiv.org/abs/2502.04397v2)|null|
|**2025-02-06**|**Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**|Chenyang Shao et.al.|[2502.04392v1](http://arxiv.org/abs/2502.04392v1)|null|
|**2025-02-06**|**Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**|Rui Cai et.al.|[2502.03715v1](http://arxiv.org/abs/2502.03715v1)|null|
|**2025-02-05**|**A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**|Yiye Chen et.al.|[2502.03450v1](http://arxiv.org/abs/2502.03450v1)|null|
|**2025-02-05**|**SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**|Ben Liu et.al.|[2502.03283v1](http://arxiv.org/abs/2502.03283v1)|null|
|**2025-02-05**|**Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**|Daniil Laptev et.al.|[2502.03032v2](http://arxiv.org/abs/2502.03032v2)|null|
|**2025-02-05**|**A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**|Bradley P. Allen et.al.|[2502.02896v1](http://arxiv.org/abs/2502.02896v1)|null|
|**2025-02-05**|**Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**|Chanhui Lee et.al.|[2502.02810v1](http://arxiv.org/abs/2502.02810v1)|null|
|**2025-02-05**|**Leveraging the true depth of LLMs**|Ramón Calvo González et.al.|[2502.02790v1](http://arxiv.org/abs/2502.02790v1)|null|
|**2025-02-04**|**Modular Training of Neural Networks aids Interpretability**|Satvik Golechha et.al.|[2502.02470v2](http://arxiv.org/abs/2502.02470v2)|null|
|**2025-02-04**|**Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**|Sagnik Mukherjee et.al.|[2502.02362v3](http://arxiv.org/abs/2502.02362v3)|null|
|**2025-02-04**|**AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**|Shivam Singh et.al.|[2502.02067v1](http://arxiv.org/abs/2502.02067v1)|[link](https://github.com/sssshivvvv/adaptbot)|
|**2025-02-03**|**On Bob Dylan: A Computational Perspective**|Prashant Garg et.al.|[2502.01772v1](http://arxiv.org/abs/2502.01772v1)|null|
|**2025-02-03**|**VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**|Xubin Ren et.al.|[2502.01549v1](http://arxiv.org/abs/2502.01549v1)|null|
|**2025-02-03**|**Transformers trained on proteins can learn to attend to Euclidean distance**|Isaac Ellmen et.al.|[2502.01533v1](http://arxiv.org/abs/2502.01533v1)|[link](https://github.com/Ellmen/attending-to-distance)|
|**2025-02-03**|**Common Foundations for SHACL, ShEx, and PG-Schema**|S. Ahmetaj et.al.|[2502.01295v1](http://arxiv.org/abs/2502.01295v1)|null|
|**2025-02-03**|**GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**|Linhao Luo et.al.|[2502.01113v1](http://arxiv.org/abs/2502.01113v1)|[link](https://github.com/RManLuo/gfm-rag)|
|**2025-02-03**|**Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**|Seungri Yoon et.al.|[2502.01059v1](http://arxiv.org/abs/2502.01059v1)|null|
|**2025-02-03**|**Encrypted Large Model Inference: The Equivariant Encryption Paradigm**|James Buban et.al.|[2502.01013v1](http://arxiv.org/abs/2502.01013v1)|null|
|**2025-02-02**|**Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**|Juno Kim et.al.|[2502.01694v1](http://arxiv.org/abs/2502.01694v1)|null|
|**2025-02-02**|**PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**|Qixuan Li et.al.|[2502.00708v1](http://arxiv.org/abs/2502.00708v1)|null|
|**2025-02-02**|**A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**|Qika Lin et.al.|[2502.00681v1](http://arxiv.org/abs/2502.00681v1)|null|
|**2025-02-01**|**Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**|Jingyuan Yi et.al.|[2502.00339v1](http://arxiv.org/abs/2502.00339v1)|null|
|**2025-02-01**|**DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**|Jiaxin Guo et.al.|[2502.00305v1](http://arxiv.org/abs/2502.00305v1)|null|
|**2025-01-31**|**Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**|Nathaniel Tomczak et.al.|[2502.01659v2](http://arxiv.org/abs/2502.01659v2)|[link](https://github.com/KLab-AI3/Graph-Processing-Attention-IPDPS-2025)|
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-30**|**Semantic Web and Creative AI -- A Technical Report from ISWS 2023**|Raia Abu Ahmad et.al.|[2501.18542v1](http://arxiv.org/abs/2501.18542v1)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320v1](http://arxiv.org/abs/2501.18320v1)|null|
|**2025-01-30**|**Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**|Wanlong Liu et.al.|[2501.18154v1](http://arxiv.org/abs/2501.18154v1)|null|
|**2025-01-30**|**Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**|Qika Lin et.al.|[2501.18119v1](http://arxiv.org/abs/2501.18119v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|
|**2025-01-28**|**FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**|Deren Lei et.al.|[2501.17144v1](http://arxiv.org/abs/2501.17144v1)|[link](https://github.com/derenlei/factcg)|
|**2025-01-28**|**LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**|Li Yin et.al.|[2501.16673v2](http://arxiv.org/abs/2501.16673v2)|[link](https://github.com/sylphai-inc/adalflow)|
|**2025-01-27**|**360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**|Hamed Firooz et.al.|[2501.16450v3](http://arxiv.org/abs/2501.16450v3)|null|
|**2025-01-27**|**Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**|Antony Bartlett et.al.|[2501.16191v1](http://arxiv.org/abs/2501.16191v1)|null|
|**2025-01-27**|**Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**|Yu Li et.al.|[2501.15791v1](http://arxiv.org/abs/2501.15791v1)|[link](https://github.com/kse-eleven/makged)|
|**2025-01-27**|**Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**|Momoka Furuhashi et.al.|[2501.15777v1](http://arxiv.org/abs/2501.15777v1)|null|
|**2025-01-26**|**Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**|Haodi Ma et.al.|[2501.15688v1](http://arxiv.org/abs/2501.15688v1)|null|
|**2025-01-26**|**How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**|Manzong Huang et.al.|[2501.15378v1](http://arxiv.org/abs/2501.15378v1)|null|
|**2025-01-24**|**Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**|Cencheng Shen et.al.|[2501.14932v1](http://arxiv.org/abs/2501.14932v1)|null|
|**2025-01-24**|**Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**|Hang Luo et.al.|[2501.14892v1](http://arxiv.org/abs/2501.14892v1)|null|
|**2025-01-24**|**GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**|Ziwen Li et.al.|[2501.16382v1](http://arxiv.org/abs/2501.16382v1)|[link](https://github.com/aaronli43/grappi)|
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v2](http://arxiv.org/abs/2501.14497v2)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**|Yuhui Yun et.al.|[2501.13746v1](http://arxiv.org/abs/2501.13746v1)|null|
|**2025-01-23**|**Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**|Chang Gong et.al.|[2501.13731v1](http://arxiv.org/abs/2501.13731v1)|null|
|**2025-01-23**|**CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**|Hamza Landolsi et.al.|[2501.13993v1](http://arxiv.org/abs/2501.13993v1)|null|
|**2025-01-23**|**Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**|Hy Nguyen et.al.|[2501.13992v1](http://arxiv.org/abs/2501.13992v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|[link](https://github.com/reecall/graphtod)|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**|Qinggang Zhang et.al.|[2501.13958v1](http://arxiv.org/abs/2501.13958v1)|[link](https://github.com/deep-polyu/awesome-graphrag)|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v2](http://arxiv.org/abs/2501.11849v2)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|

#### Abstracts
##### **Do Large Language Models Reason Causally Like Us? Even Better?**
2502.10215v1 by Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder

Causal reasoning is a core component of intelligence. Large language models
(LLMs) have shown impressive capabilities in generating human-like text,
raising questions about whether their responses reflect true understanding or
statistical patterns. We compared causal reasoning in humans and four LLMs
using tasks based on collider graphs, rating the likelihood of a query variable
occurring given evidence from other variables. We find that LLMs reason
causally along a spectrum from human-like to normative inference, with
alignment shifting based on model, context, and task. Overall, GPT-4o and
Claude showed the most normative behavior, including "explaining away", whereas
Gemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected
independence of causes - Claude the least - they exhibited strong associative
reasoning and predictive inference when assessing the likelihood of the effect
given its causes. These findings underscore the need to assess AI biases as
they increasingly assist human decision-making.

摘要：因果推理是智能的核心組成部分。大型語言模型 (LLM) 在生成類人文本方面展現了令人印象深刻的能力，引發了關於它們的回應是否反映真實理解或統計模式的疑問。我們使用基於碰撞圖的任務比較了人類和四個 LLM 中的因果推理，根據其他變數的證據評估查詢變數發生的可能性。我們發現 LLM 沿著從類人到規範推論的光譜進行因果推理，對齊會根據模型、上下文和任務而改變。總體而言，GPT-4o 和 Claude 表現出最規範的行為，包括「解釋」，而 Gemini-Pro 和 GPT-3.5 則沒有。儘管所有代理都偏離了預期的原因獨立性 - Claude 最不偏離 - 但它們在評估給定原因的效果可能性時表現出強烈的關聯推理和預測推論。這些發現強調了評估 AI 偏差的必要性，因為它們越來越協助人類決策。

##### **Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**
2502.10140v1 by Daniil Gurgurov, Ivan Vykopal, Josef van Genabith, Simon Ostermann

Low-resource languages (LRLs) face significant challenges in natural language
processing (NLP) due to limited data. While current state-of-the-art large
language models (LLMs) still struggle with LRLs, smaller multilingual models
(mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of
their capacity to low training data sizes. This study systematically
investigates parameter-efficient adapter-based methods for adapting mLMs to
LRLs, evaluating three architectures: Sequential Bottleneck, Invertible
Bottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and
structured knowledge from ConceptNet, we show that small adaptation datasets
(e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains
in intrinsic (masked language modeling) and extrinsic tasks (topic
classification, sentiment analysis, and named entity recognition). We find that
Sequential Bottleneck adapters excel in language modeling, while Invertible
Bottleneck adapters slightly outperform other methods on downstream tasks due
to better embedding alignment and larger parameter counts. Adapter-based
methods match or outperform full fine-tuning while using far fewer parameters,
and smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3,
GPT-4, and DeepSeek-R1-based distilled models. While adaptation improves
performance, pre-training data size remains the dominant factor, especially for
languages with extensive pre-training coverage.

摘要：低資源語言 (LRL) 由於資料有限，在自然語言處理 (NLP) 中面臨重大挑戰。雖然當前最先進的大型語言模型 (LLM) 仍難以處理 LRL，但較小的多語言模型 (mLMS)，例如 mBERT 和 XLM-R，由於其容量更適合低訓練資料大小，因此提供了更大的希望。本研究系統性地探討了基於參數效率適配器的適配方法，以將 mLMS 適配到 LRL，評估了三種架構：順序瓶頸、可逆瓶頸和低秩適配。使用來自 GlotCC 的非結構化文本和來自 ConceptNet 的結構化知識，我們表明小型適配資料集（例如，高達 1 GB 的自由文本或幾 MB 的知識圖譜資料）在內在（遮蔽語言模型）和外在任務（主題分類、情緒分析和命名實體識別）中產生增益。我們發現順序瓶頸適配器在語言模型中表現出色，而可逆瓶頸適配器由於更好的嵌入對齊和更大的參數數量，在下游任務上略勝於其他方法。基於適配器的方法在使用更少參數的同時，可以匹配或優於完全微調，而較小的 mLM 被證明比 LLaMA-3、GPT-4 和基於 DeepSeek-R1 的蒸餾模型等大型 LLM 更適合 LRL。雖然適配可以提高效能，但預訓練資料大小仍然是主要因素，特別是對於預訓練覆蓋範圍廣泛的語言。

##### **Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**
2502.10090v1 by Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao

Humans possess an extraordinary ability to understand and execute complex
manipulation tasks by interpreting abstract instruction manuals. For robots,
however, this capability remains a substantial challenge, as they cannot
interpret abstract instructions and translate them into executable actions. In
this paper, we present Manual2Skill, a novel framework that enables robots to
perform complex assembly tasks guided by high-level manual instructions. Our
approach leverages a Vision-Language Model (VLM) to extract structured
information from instructional images and then uses this information to
construct hierarchical assembly graphs. These graphs represent parts,
subassemblies, and the relationships between them. To facilitate task
execution, a pose estimation model predicts the relative 6D poses of components
at each assembly step. At the same time, a motion planning module generates
actionable sequences for real-world robotic implementation. We demonstrate the
effectiveness of Manual2Skill by successfully assembling several real-world
IKEA furniture items. This application highlights its ability to manage
long-horizon manipulation tasks with both efficiency and precision,
significantly enhancing the practicality of robot learning from instruction
manuals. This work marks a step forward in advancing robotic systems capable of
understanding and executing complex manipulation tasks in a manner akin to
human capabilities.

摘要：人類擁有理解並執行複雜操作任務的非凡能力，方法是詮釋抽象的說明手冊。然而，對機器人來說，這項能力仍然是一項重大的挑戰，因為它們無法詮釋抽象的指令並將其轉換為可執行的動作。在本文中，我們提出了 Manual2Skill，這是一個新穎的框架，使機器人能夠在高階手冊說明的指導下執行複雜的組裝任務。我們的做法利用視覺語言模型 (VLM) 從教學圖片中提取結構化資訊，然後使用此資訊來建構階層式組裝圖。這些圖表示零件、子組件以及它們之間的關係。為了促進任務執行，姿勢估計模型會預測每個組裝步驟中組件的相對 6D 姿勢。同時，動作規劃模組會產生適用於實際機器人實作的可操作順序。我們透過成功組裝幾個真實世界的 IKEA 家具來展示 Manual2Skill 的有效性。此應用程式突顯了它以高效率和高精準度管理長時程操作任務的能力，大幅提升機器人從說明手冊中學習的實用性。這項工作標誌著機器人系統在理解和執行複雜操作任務方面向前邁進了一步，其方式類似於人類的能力。

##### **Decision Information Meets Large Language Models: The Future of Explainable Operations Research**
2502.09994v1 by Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, Chen Ma

Operations Research (OR) is vital for decision-making in many industries.
While recent OR methods have seen significant improvements in automation and
efficiency through integrating Large Language Models (LLMs), they still
struggle to produce meaningful explanations. This lack of clarity raises
concerns about transparency and trustworthiness in OR applications. To address
these challenges, we propose a comprehensive framework, Explainable Operations
Research (EOR), emphasizing actionable and understandable explanations
accompanying optimization. The core of EOR is the concept of Decision
Information, which emerges from what-if analysis and focuses on evaluating the
impact of complex constraints (or parameters) changes on decision-making.
Specifically, we utilize bipartite graphs to quantify the changes in the OR
model and adopt LLMs to improve the explanation capabilities. Additionally, we
introduce the first industrial benchmark to rigorously evaluate the
effectiveness of explanations and analyses in OR, establishing a new standard
for transparency and clarity in the field.

摘要：作業研究 (OR) 對許多產業的決策制定至關重要。雖然近期的 OR 方法已透過整合大型語言模型 (LLM) 在自動化和效率方面取得顯著的進步，但它們在產生有意義的解釋方面仍面臨挑戰。這種缺乏明確性的情況會對 OR 應用中的透明度和可信度造成疑慮。為了應對這些挑戰，我們提出一個全面的架構，即可解釋作業研究 (EOR)，強調在最佳化過程中提供可操作且易於理解的解釋。EOR 的核心是決策資訊的概念，它源自假設分析，並專注於評估複雜約束條件 (或參數) 變更對決策制定的影響。具體來說，我們利用二部圖量化 OR 模型的變化，並採用 LLM 來改善解釋能力。此外，我們引入了第一個產業基準，以嚴格評估 OR 中解釋和分析的有效性，為該領域的透明度和清晰度建立新的標準。

##### **KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**
2502.09956v1 by Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, Sanmi Koyejo

Recent interest in building foundation models for KGs has highlighted a
fundamental challenge: knowledge-graph data is relatively scarce. The
best-known KGs are primarily human-labeled, created by pattern-matching, or
extracted using early NLP techniques. While human-generated KGs are in short
supply, automatically extracted KGs are of questionable quality. We present a
solution to this data scarcity problem in the form of a text-to-KG generator
(KGGen), a package that uses language models to create high-quality graphs from
plaintext. Unlike other KG extractors, KGGen clusters related entities to
reduce sparsity in extracted KGs. KGGen is available as a Python library
(\texttt{pip install kg-gen}), making it accessible to everyone. Along with
KGGen, we release the first benchmark, Measure of of Information in Nodes and
Edges (MINE), that tests an extractor's ability to produce a useful KG from
plain text. We benchmark our new tool against existing extractors and
demonstrate far superior performance.

摘要：最近对于构建知识图谱基础模型的兴趣凸显了一个基本挑战：知识图谱数据相对稀缺。最知名的知识图谱主要为人标注，由模式匹配创建，或使用早期自然语言处理技术提取。虽然人生成的知识图谱供不应求，但自动提取的知识图谱质量堪忧。我们以文本到知识图谱生成器 (KGGen) 的形式为这一数据稀缺问题提供了一个解决方案，这是一个使用语言模型从纯文本创建高质量图表的包。与其他知识图谱提取器不同，KGGen 对相关实体进行聚类以减少提取的知识图谱中的稀疏性。KGGen 可用作 Python 库（\texttt{pip install kg-gen}），使其所有人都能访问。除了 KGGen，我们还发布了第一个基准测试，即节点和边信息度量 (MINE)，它测试了提取器从纯文本生成有用知识图谱的能力。我们针对现有提取器对我们的新工具进行基准测试，并展示了远超其性能。

##### **ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**
2502.09891v1 by Shu Wang, Yixiang Fang, Yingli Zhou, Xilin Liu, Yuchi Ma

Retrieval-Augmented Generation (RAG) has proven effective in integrating
external knowledge into large language models (LLMs) for question-answer (QA)
tasks. The state-of-the-art RAG approaches often use the graph data as the
external data since they capture the rich semantic information and link
relationships between entities. However, existing graph-based RAG approaches
cannot accurately identify the relevant information from the graph and also
consume large numbers of tokens in the online retrieval process. To address
these issues, we introduce a novel graph-based RAG approach, called Attributed
Community-based Hierarchical RAG (ArchRAG), by augmenting the question using
attributed communities, and also introducing a novel LLM-based hierarchical
clustering method. To retrieve the most relevant information from the graph for
the question, we build a novel hierarchical index structure for the attributed
communities and develop an effective online retrieval method. Experimental
results demonstrate that ArchRAG outperforms existing methods in terms of both
accuracy and token cost.

摘要：檢索增強生成 (RAG) 已證明可將外部知識整合到大型語言模型 (LLM)，用於問答 (QA) 任務。最先進的 RAG 方法通常使用圖形資料作為外部資料，因為它們擷取了豐富的語意資訊和實體之間的連結關係。然而，現有的基於圖形的 RAG 方法無法準確識別圖形中的相關資訊，而且在線上檢索過程中也會消耗大量的符號。為了解決這些問題，我們提出了一種新穎的基於圖形的 RAG 方法，稱為基於屬性社群的分層 RAG (ArchRAG)，透過使用屬性社群來擴充問題，並引入一種新穎的基於 LLM 的分層聚類方法。為了從圖形中檢索與問題最相關的資訊，我們為屬性社群建立了一個新穎的分層索引結構，並開發了一種有效的線上檢索方法。實驗結果證明，ArchRAG 在準確性和符號成本方面都優於現有方法。

##### **Visual Graph Question Answering with ASP and LLMs for Language Parsing**
2502.09211v1 by Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch

Visual Question Answering (VQA) is a challenging problem that requires to
process multimodal input. Answer-Set Programming (ASP) has shown great
potential in this regard to add interpretability and explainability to modular
VQA architectures. In this work, we address the problem of how to integrate ASP
with modules for vision and natural language processing to solve a new and
demanding VQA variant that is concerned with images of graphs (not graphs in
symbolic form). Images containing graph-based structures are an ubiquitous and
popular form of visualisation. Here, we deal with the particular problem of
graphs inspired by transit networks, and we introduce a novel dataset that
amends an existing one by adding images of graphs that resemble metro lines.
Our modular neuro-symbolic approach combines optical graph recognition for
graph parsing, a pretrained optical character recognition neural network for
parsing labels, Large Language Models (LLMs) for language processing, and ASP
for reasoning. This method serves as a first baseline and achieves an overall
average accuracy of 73% on the dataset. Our evaluation provides further
evidence of the potential of modular neuro-symbolic systems, in particular with
pretrained models that do not involve any further training and logic
programming for reasoning, to solve complex VQA tasks.

摘要：視覺問答（VQA）是一項具有挑戰性的問題，需要處理多模態輸入。答案集程式設計（ASP）在這方面顯示出巨大的潛力，可以為模組化 VQA 架構增加可解釋性和說明性。在這項工作中，我們探討如何將 ASP 與視覺和自然語言處理模組整合，以解決一個新的且要求嚴格的 VQA 變體，該變體與圖形影像（而非符號形式的圖形）有關。包含圖形結構的影像是一種普遍且流行的可視化形式。在這裡，我們處理受交通網路啟發的圖形特定問題，並引入一個新的資料集，透過新增類似地鐵路線的圖形影像來修正現有資料集。我們的模組化神經符號方法結合光學圖形辨識進行圖形解析、預先訓練的光學字元辨識神經網路進行標籤解析、大型語言模型（LLM）進行語言處理，以及 ASP 進行推理。此方法作為第一個基準，在資料集上達到 73% 的整體平均準確度。我們的評估進一步證明了模組化神經符號系統的潛力，特別是預先訓練的模型，這些模型不涉及任何進一步的訓練和邏輯程式設計進行推理，以解決複雜的 VQA 任務。

##### **Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**
2502.08547v1 by Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai

The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.

摘要：電子健康紀錄的採用擴大了在臨床照護和研究中利用資料驅動演算法的機會。在有效進行多機構電子健康紀錄研究時，一個主要的瓶頸是系統間資料異質性，其中有許多代碼在機構間不存在或表示不同的臨床概念。資料隱私的需求進一步限制了納入多機構患者層級資料的可行性，而這些資料對於研究患者亞群之間的相似性和差異性是必要的。為了應對這些挑戰，我們開發了 GAME 演算法。GAME 已在 7 個機構和 2 種語言中進行測試和驗證，它整合了多個層級的資料：(1) 在機構層級，使用知識圖表來建立代碼和現有知識來源之間的關係，為標準代碼及其彼此之間的關係提供醫療背景；(2) 在機構之間，利用語言模型來確定機構特定代碼與已建立的標準代碼之間的關係；(3) 使用圖形注意網路量化代碼之間關係的強度。使用遷移和聯合學習建立聯合訓練的嵌入，以保護資料隱私。在本研究中，我們展示了 GAME 在選擇相關特徵作為 AI 驅動演算法輸入時的適用性，適用於各種情況，例如心臟衰竭、類風濕性關節炎。然後，我們重點介紹了 GAME 和諧化多機構電子健康紀錄資料在阿茲海默症疾病結果和精神疾病患者自殺風險研究中的應用，而無需在個別機構之外共享患者層級資料。

##### **Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy**
2502.08353v1 by Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang

With the extensive application of Graph Neural Networks (GNNs) across various
domains, their trustworthiness has emerged as a focal point of research. Some
existing studies have shown that the integration of large language models
(LLMs) can improve the semantic understanding and generation capabilities of
GNNs, which in turn improves the trustworthiness of GNNs from various aspects.
Our review introduces a taxonomy that offers researchers a clear framework for
comprehending the principles and applications of different methods and helps
clarify the connections and differences among various approaches. Then we
systematically survey representative approaches along the four categories of
our taxonomy. Through our taxonomy, researchers can understand the applicable
scenarios, potential advantages, and limitations of each approach for the the
trusted integration of GNNs with LLMs. Finally, we present some promising
directions of work and future trends for the integration of LLMs and GNNs to
improve model trustworthiness.

摘要：隨著圖神經網路 (GNN) 在各種領域的廣泛應用，其可信度已成為研究的焦點。一些現有研究表明，整合大型語言模型 (LLM) 可以提升 GNN 的語意理解和生成能力，進而從各方面提升 GNN 的可信度。我們的評論介紹了一種分類法，為研究人員提供了一個清晰的架構，用於理解不同方法的原理和應用，並有助於釐清各種方法之間的關聯和差異。然後，我們系統性地針對分類法的四個類別進行代表性方法的調查。研究人員透過我們的分類法，可以了解每種方法在 GNN 與 LLM 的可信整合中適用的場景、潛在優點和限制。最後，我們提出 LLM 與 GNN 整合的一些有前景的工作方向和未來趨勢，以提升模型的可信度。

##### **Graph Foundation Models for Recommendation: A Comprehensive Survey**
2502.08346v2 by Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi

Recommender systems (RS) serve as a fundamental tool for navigating the vast
expanse of online information, with deep learning advancements playing an
increasingly important role in improving ranking accuracy. Among these, graph
neural networks (GNNs) excel at extracting higher-order structural information,
while large language models (LLMs) are designed to process and comprehend
natural language, making both approaches highly effective and widely adopted.
Recent research has focused on graph foundation models (GFMs), which integrate
the strengths of GNNs and LLMs to model complex RS problems more efficiently by
leveraging the graph-based structure of user-item relationships alongside
textual understanding. In this survey, we provide a comprehensive overview of
GFM-based RS technologies by introducing a clear taxonomy of current
approaches, diving into methodological details, and highlighting key challenges
and future directions. By synthesizing recent advancements, we aim to offer
valuable insights into the evolving landscape of GFM-based recommender systems.

摘要：推薦系統 (RS) 扮演著在廣大的線上資訊中引領方向的基本工具，而深度學習的進步在提升排名精準度上扮演著越來越重要的角色。其中，圖形神經網路 (GNN) 在萃取高階結構資訊上表現優異，而大型語言模型 (LLM) 則被設計用來處理和理解自然語言，這讓兩種方法都極具效益且被廣泛採用。最近的研究聚焦於圖形基礎模型 (GFM)，它整合了 GNN 和 LLM 的優點，藉由利用使用者與項目關係的圖形化結構以及文字理解來更有效率地建模複雜的 RS 問題。在這個調查中，我們提供了一個關於基於 GFM 的 RS 技術的全面概述，方法是介紹目前方法的明確分類法，深入探討方法論的細節，並強調關鍵挑戰和未來方向。藉由綜合最近的進展，我們旨在提供對於基於 GFM 的推薦系統不斷演變的樣貌的寶貴見解。

##### **Self-Evaluation for Job-Shop Scheduling**
2502.08684v1 by Imanol Echeverria, Maialen Murua, Roberto Santana

Combinatorial optimization problems, such as scheduling and route planning,
are crucial in various industries but are computationally intractable due to
their NP-hard nature. Neural Combinatorial Optimization methods leverage
machine learning to address these challenges but often depend on sequential
decision-making, which is prone to error accumulation as small mistakes
propagate throughout the process. Inspired by self-evaluation techniques in
Large Language Models, we propose a novel framework that generates and
evaluates subsets of assignments, moving beyond traditional stepwise
approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a
heterogeneous graph neural network with a Transformer to build a policy model
and a self-evaluation function. Experimental validation on challenging,
well-known benchmarks demonstrates the effectiveness of our approach,
surpassing state-of-the-art methods.

摘要：組合優化問題，例如排程和路線規劃，在各行各業中至關重要，但由於它們的 NP 難度，在計算上難以處理。神經組合優化方法利用機器學習來解決這些挑戰，但通常依賴於序貫決策制定，而序貫決策制定容易發生錯誤累積，因為小錯誤會在整個過程中傳播。受大型語言模型中的自我評估技術啟發，我們提出了一個新的框架，可生成和評估作業子集，超越傳統的分步方法。應用於工作車間排程問題，我們的方法將異質圖神經網路與 Transformer 整合在一起，以建立策略模型和自我評估函數。在具有挑戰性的著名基準上的實驗驗證證明了我們方法的有效性，超越了最先進的方法。

##### **Improving Existing Optimization Algorithms with LLMs**
2502.08298v1 by Camilo Chacón Sartori, Christian Blum

The integration of Large Language Models (LLMs) into optimization has created
a powerful synergy, opening exciting research opportunities. This paper
investigates how LLMs can enhance existing optimization algorithms. Using their
pre-trained knowledge, we demonstrate their ability to propose innovative
heuristic variations and implementation strategies. To evaluate this, we
applied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt
(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that
incorporates a heuristic in the solution construction phase. Our results show
that an alternative heuristic proposed by GPT-4o outperforms the
expert-designed heuristic of CMSA, with the performance gap widening on larger
and denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/

摘要：大型语言模型 (LLM) 与优化相结合，创造了一种强大的协同作用，开启了令人兴奋的研究机会。本文探讨了 LLM 如何增强现有的优化算法。利用其预先训练的知识，我们展示了它们提出创新启发式变体和实施策略的能力。为了评估这一点，我们应用了一种非平凡的优化算法，构建、合并、求解和适应 (CMSA)——一种用于组合优化问题的混合元启发式算法，它在求解构建阶段纳入了启发式算法。我们的结果表明，GPT-4o 提出的替代启发式算法优于 CMSA 的专家设计的启发式算法，并且随着图形变得更大、更密集，性能差距也在扩大。项目网址：https://imp-opt-algo-llms.surge.sh/

##### **ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning**
2502.08148v1 by Vy Vo, Lizhen Qu, Tao Feng, Yuncheng Hua, Xiaoxi Kang, Songhai Fan, Tim Dwyer, Lay-Ki Soon, Gholamreza Haffari

Identifying cause-and-effect relationships is critical to understanding
real-world dynamics and ultimately causal reasoning. Existing methods for
identifying event causality in NLP, including those based on Large Language
Models (LLMs), exhibit difficulties in out-of-distribution settings due to the
limited scale and heavy reliance on lexical cues within available benchmarks.
Modern benchmarks, inspired by probabilistic causal inference, have attempted
to construct causal graphs of events as a robust representation of causal
knowledge, where \texttt{CRAB} \citep{romanou2023crab} is one such recent
benchmark along this line. In this paper, we introduce \texttt{ACCESS}, a
benchmark designed for discovery and reasoning over abstract causal events.
Unlike existing resources, \texttt{ACCESS} focuses on causality of everyday
life events on the abstraction level. We propose a pipeline for identifying
abstractions for event generalizations from \texttt{GLUCOSE}
\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit
commonsense causal knowledge, from which we subsequently extract $1,4$K causal
pairs. Our experiments highlight the ongoing challenges of using statistical
methods and/or LLMs for automatic abstraction identification and causal
discovery in NLP. Nonetheless, we demonstrate that the abstract causal
knowledge provided in \texttt{ACCESS} can be leveraged for enhancing QA
reasoning performance in LLMs.

摘要：<paragraph>找出因果關係對於理解現實世界的動態和最終的因果推理至關重要。現有的 NLP 事件因果關係識別方法，包括基於大型語言模型 (LLM) 的方法，由於規模有限且過度依賴於可用基準中的詞彙線索，在分佈外環境中表現出困難。受機率因果推論啟發的現代基準已嘗試建構事件的因果圖，作為因果知識的強健表示，其中 \texttt{CRAB} \citep{romanou2023crab} 是這條路徑上最近的一個基準。在本文中，我們介紹 \texttt{ACCESS}，一個專門設計來探索和推理抽象因果事件的基準。與現有資源不同，\texttt{ACCESS} 專注於抽象層面上日常生活事件的因果關係。我們提出一個管道，用於從 \texttt{GLUCOSE} \citep{mostafazadeh-etal-2020-glucose} 找出事件概括的抽象，\texttt{GLUCOSE} 是隱含常識因果知識的大規模資料集，我們隨後從中萃取出 1,4K 因果對。我們的實驗突顯出使用統計方法和/或 LLM 進行 NLP 中的自動抽象識別和因果發現的持續挑戰。儘管如此，我們證明了 \texttt{ACCESS} 中提供的抽象因果知識可用於增強 LLM 中的問答推理效能。</paragraph>

##### **Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality**
2502.09658v1 by Xin Kang, Veronika Shteingardt, Yuhan Wang, Dov Dori

Knowledge representation and reasoning are critical challenges in Artificial
Intelligence (AI), particularly in integrating neural and symbolic approaches
to achieve explainable and transparent AI systems. Traditional knowledge
representation methods often fall short of capturing complex processes and
state changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a
specialization of the neuro-symbolic AI approach that integrates conceptual
modeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep
learning to enhance question-answering (QA) quality. By converting natural
language text into OPM models using in-context learning, NCAI leverages the
expressive power of OPM to represent complex OPM elements-processes, objects,
and states-beyond what traditional triplet-based knowledge graphs can easily
capture. This rich structured knowledge representation improves reasoning
transparency and answer accuracy in an OPM-QA system. We further propose
transparency evaluation metrics to quantitatively measure how faithfully the
predicted reasoning aligns with OPM-based conceptual logic. Our experiments
demonstrate that NCAI outperforms traditional methods, highlighting its
potential for advancing neuro-symbolic AI by providing rich knowledge
representations, measurable transparency, and improved reasoning.

摘要：知識表徵與推理是人工智慧 (AI) 中的重大挑戰，特別是在整合神經與符號方法以實現可解釋且透明的人工智慧系統時。傳統的知識表徵方法通常無法捕捉複雜的流程和狀態變化。我們引入了神經概念人工智慧 (NCAI)，一種神經符號 AI 方法的專門化，它將使用物件流程方法 (OPM) ISO 19450:2024 的概念建模與深度學習整合在一起，以提升問答 (QA) 的品質。透過使用情境學習將自然語言文字轉換為 OPM 模型，NCAI 充分利用 OPM 的表達能力來表徵複雜的 OPM 元素（流程、物件和狀態），超越傳統的三元組知識圖表容易捕捉的範圍。這種豐富的結構化知識表徵改善了 OPM-QA 系統中的推理透明度和答案準確度。我們進一步提出了透明度評估指標，以量化測量預測推理與基於 OPM 的概念邏輯的吻合程度。我們的實驗證明，NCAI 優於傳統方法，突顯了它在透過提供豐富的知識表徵、可測量的透明度和改善的推理來推進神經符號 AI 的潛力。

##### **GCoT: Chain-of-Thought Prompt Learning for Graphs**
2502.08092v1 by Xingtong Yu, Chang Zhou, Zhongwei Kuai, Xinming Zhang, Yuan Fang

Chain-of-thought (CoT) prompting has achieved remarkable success in natural
language processing (NLP). However, its vast potential remains largely
unexplored for graphs. This raises an interesting question: How can we design
CoT prompting for graphs to guide graph models to learn step by step? On one
hand, unlike natural languages, graphs are non-linear and characterized by
complex topological structures. On the other hand, many graphs lack textual
data, making it difficult to formulate language-based CoT prompting. In this
work, we propose the first CoT prompt learning framework for text-free graphs,
GCoT. Specifically, we decompose the adaptation process for each downstream
task into a series of inference steps, with each step consisting of
prompt-based inference, ``thought'' generation, and thought-conditioned prompt
learning. While the steps mimic CoT prompting in NLP, the exact mechanism
differs significantly. Specifically, at each step, an input graph, along with a
prompt, is first fed into a pre-trained graph encoder for prompt-based
inference. We then aggregate the hidden layers of the encoder to construct a
``thought'', which captures the working state of each node in the current step.
Conditioned on this thought, we learn a prompt specific to each node based on
the current state. These prompts are fed into the next inference step,
repeating the cycle. To evaluate and analyze the effectiveness of GCoT, we
conduct comprehensive experiments on eight public datasets, which demonstrate
the advantage of our approach.

摘要：<paragraph>鏈式思考 (CoT) 提示在自然語言處理 (NLP) 中取得了顯著的成功。然而，其龐大的潛力在圖形方面仍未得到充分探索。這提出了一個有趣的問題：我們如何設計圖形的 CoT 提示來指導圖形模型逐步學習？一方面，與自然語言不同，圖形是非線性的，並且具有複雜的拓撲結構。另一方面，許多圖形缺乏文本數據，這使得難以制定基於語言的 CoT 提示。在這項工作中，我們提出了第一個適用於無文本圖形的 CoT 提示學習框架 GCoT。具體來說，我們將每個下游任務的適應過程分解為一系列推理步驟，每個步驟都包含基於提示的推理、「思想」生成以及基於思想的提示學習。雖然這些步驟模擬了 NLP 中的 CoT 提示，但具體機制卻有很大不同。具體來說，在每一步中，一個輸入圖形連同一個提示首先被輸入到一個預訓練的圖形編碼器中進行基於提示的推理。然後，我們聚合編碼器的隱藏層以構建一個「思想」，它捕獲了當前步驟中每個節點的工作狀態。基於這個思想，我們根據當前狀態學習一個特定於每個節點的提示。這些提示被輸入到下一個推理步驟中，重複這個循環。為了評估和分析 GCoT 的有效性，我們對八個公共數據集進行了全面的實驗，這證明了我們方法的優勢。</paragraph>

##### **Deep Semantic Graph Learning via LLM based Node Enhancement**
2502.07982v1 by Chuanqi Shi, Yiyi Tao, Hang Zhang, Lun Wang, Shaoshuai Du, Yixian Shen, Yanxin Shen

Graph learning has attracted significant attention due to its widespread
real-world applications. Current mainstream approaches rely on text node
features and obtain initial node embeddings through shallow embedding learning
using GNNs, which shows limitations in capturing deep textual semantics. Recent
advances in Large Language Models (LLMs) have demonstrated superior
capabilities in understanding text semantics, transforming traditional text
feature processing. This paper proposes a novel framework that combines Graph
Transformer architecture with LLM-enhanced node features. Specifically, we
leverage LLMs to generate rich semantic representations of text nodes, which
are then processed by a multi-head self-attention mechanism in the Graph
Transformer to capture both local and global graph structural information. Our
model utilizes the Transformer's attention mechanism to dynamically aggregate
neighborhood information while preserving the semantic richness provided by LLM
embeddings. Experimental results demonstrate that the LLM-enhanced node
features significantly improve the performance of graph learning models on node
classification tasks. This approach shows promising results across multiple
graph learning tasks, offering a practical direction for combining graph
networks with language models.

摘要：圖形學習因其廣泛的現實世界應用而備受關注。目前的熱門方法依賴於文本節點特徵，並通過使用 GNN 的淺層嵌入學習來獲取初始節點嵌入，這在捕捉深度文本語義方面表現出局限性。大語言模型 (LLM) 的最新進展已證明在理解文本語義方面具有優越的能力，轉換了傳統的文本特徵處理。本文提出了一種新的框架，將圖形轉換器架構與 LLM 增強的節點特徵相結合。具體來說，我們利用 LLM 來生成文本節點的豐富語義表示，然後在圖形轉換器中由多頭自我注意機制處理，以捕捉局部和全局圖形結構信息。我們的模型利用 Transformer 的注意機制來動態聚合鄰域信息，同時保留 LLM 嵌入提供的語義豐富性。實驗結果表明，LLM 增強的節點特徵顯著提高了圖形學習模型在節點分類任務上的性能。這種方法在多個圖形學習任務中顯示出有希望的結果，為將圖形網絡與語言模型相結合提供了實用的方向。

##### **Cardiverse: Harnessing LLMs for Novel Card Game Prototyping**
2502.07128v1 by Danrui Li, Sen Zhang, Sam S. Sohn, Kaidong Hu, Muhammad Usman, Mubbasir Kapadia

The prototyping of computer games, particularly card games, requires
extensive human effort in creative ideation and gameplay evaluation. Recent
advances in Large Language Models (LLMs) offer opportunities to automate and
streamline these processes. However, it remains challenging for LLMs to design
novel game mechanics beyond existing databases, generate consistent gameplay
environments, and develop scalable gameplay AI for large-scale evaluations.
This paper addresses these challenges by introducing a comprehensive automated
card game prototyping framework. The approach highlights a graph-based indexing
method for generating novel game designs, an LLM-driven system for consistent
game code generation validated by gameplay records, and a gameplay AI
constructing method that uses an ensemble of LLM-generated action-value
functions optimized through self-play. These contributions aim to accelerate
card game prototyping, reduce human labor, and lower barriers to entry for game
developers.

摘要：電腦遊戲，尤其是卡牌遊戲的原型製作，需要大量的人力在創意構思和遊戲玩法評估上。大型語言模型 (LLM) 的最新進展提供了自動化和簡化這些流程的機會。然而，LLM 在設計超越現有資料庫的新穎遊戲機制、生成一致的遊戲環境，以及開發用於大規模評估的可擴充遊戲 AI 方面仍然面臨挑戰。本文通過引入一個全面的自動化卡牌遊戲原型製作框架來應對這些挑戰。該方法強調了一種基於圖表的索引方法，用於生成新穎的遊戲設計，一個由 LLM 驅動的系統，用於一致的遊戲程式碼生成，並由遊戲記錄驗證，以及一個遊戲 AI 構建方法，該方法使用由 LLM 生成的動作值函數的集合，通過自我對弈進行最佳化。這些貢獻旨在加速卡牌遊戲原型製作，減少人力，並降低遊戲開發人員的進入門檻。

##### **GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units**
2502.06921v2 by Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan

Graph Neural Networks (GNNs) are vital for learning from graph-structured
data, enabling applications in network analysis, recommendation systems, and
speech analytics. Deploying them on edge devices like client PCs and laptops
enhances real-time processing, privacy, and cloud independence. GNNs aid
Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and
enable event-based vision tasks. However, irregular memory access, sparsity,
and dynamic structures cause high latency and energy overhead on
resource-constrained devices. While modern edge processors integrate CPUs,
GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregular
GNN computations. We introduce GraNNite, the first hardware-aware framework
optimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNN
accelerators via a structured three-step methodology: (1) enabling NPU
execution, (2) optimizing performance, and (3) trading accuracy for efficiency
gains. Step 1 employs GraphSplit for workload distribution and StaGr for static
aggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boosts
performance using EffOp for control-heavy tasks and GraSp for sparsity
exploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduce
redundancy and memory transfers. Step 3 balances quality versus efficiency,
where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerate
attention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,
GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to
8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higher
performance than CPUs and GPUs, respectively, across GNN models.

摘要：圖形神經網路 (GNN) 對於從圖形結構資料中學習至關重要，能應用於網路分析、推薦系統和語音分析。將其部署在邊緣裝置（例如用戶端電腦和筆電）上可增強即時處理、隱私和雲端獨立性。GNN 協助大型語言模型 (LLM) 的檢索增強生成 (RAG)，並支援基於事件的視覺任務。然而，不規則的記憶體存取、稀疏性和動態結構會導致資源受限裝置上的高延遲和能源負擔。儘管現代邊緣處理器整合了 CPU、GPU 和 NPU，但針對資料平行任務所設計的 NPU 難以處理不規則的 GNN 計算。我們引入了 GraNNite，這是第一個硬體感知框架，透過結構化的三步驟方法最佳化商用現成 (COTS) SOTA DNN 加速器上的 GNN 執行：(1) 啟用 NPU 執行，(2) 最佳化效能，以及 (3) 以準確度換取效率提升。步驟 1 使用 GraphSplit 進行工作負載分配，並使用 StaGr 進行靜態聚合，而 GrAd 和 NodePad 則處理動態圖形。步驟 2 使用 EffOp 提升控制密集型任務的效能，並使用 GraSp 進行稀疏性利用。圖形卷積最佳化 PreG、SymG 和 CacheG 減少了冗餘和記憶體傳輸。步驟 3 平衡品質與效率，其中 QuantGr 適用 INT8 量化，而 GrAx1、GrAx2 和 GrAx3 則加速注意力、廣播加法和 SAGE-max 聚合。在 Intel Core Ultra AI PC 上，GraNNite 在預設 NPU 映射上實現了 2.6X 到 7.6X 的加速，在 CPU 和 GPU 上實現了高達 8.6X 的能源增益，在 GNN 模型中分別提供了比 CPU 和 GPU 高出 10.8X 和 6.7X 的效能。

##### **Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language**
2502.06634v1 by Zhiqiang Zhong, Simon Sataa-Yu Larsen, Haoyu Guo, Tao Tang, Kuangyu Zhou, Davide Mottin

Recent advancements in AI for biological research focus on integrating
molecular data with natural language to accelerate drug discovery. However, the
scarcity of high-quality annotations limits progress in this area. This paper
introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework
that leverages large language models to augment existing datasets, thereby
improving AI training. We demonstrate the effectiveness of LA$^3$ by creating
an enhanced dataset, LaChEBI-20, where we systematically rewrite the
annotations of molecules from an established dataset. These rewritten
annotations preserve essential molecular information while providing more
varied sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5
based on a benchmark architecture to learn the mapping between molecular
representations and augmented annotations.
  Experimental results on text-based *de novo* molecule generation and molecule
captioning demonstrate that LaMolT5 outperforms state-of-the-art models.
Notably, incorporating LA$^3$ leads to improvements of up to 301% over the
benchmark architecture. Furthermore, we validate the effectiveness of LA$^3$
notable applications in *image*, *text* and *graph* tasks, affirming its
versatility and utility.

摘要：<paragraph>人工智慧在生物研究上的最新進展，專注於將分子資料與自然語言整合，以加速藥物發現。然而，高品質註解的稀少限制了此領域的進展。這篇論文介紹了 LA$^3$，一個基於語言的自動註解擴充框架，它利用大型語言模型來擴充現有的資料集，進而改善人工智慧訓練。我們透過建立一個增強的資料集 LaChEBI-20 來展示 LA$^3$ 的有效性，我們系統性地改寫了一個既定資料集中分子的註解。這些改寫的註解保留了重要的分子資訊，同時提供了更多樣化的句子結構和詞彙。使用 LaChEBI-20，我們在基於基準架構上訓練 LaMolT5，以學習分子表示和擴充註解之間的對應。
在基於文字的 *從頭開始* 分子生成和分子標題上的實驗結果表明，LaMolT5 優於最先進的模型。值得注意的是，納入 LA$^3$ 可讓基準架構的改進幅度高達 301%。此外，我們驗證了 LA$^3$ 在 *影像*、*文字* 和 *圖形* 任務中的有效性，肯定了它的多功能性和實用性。</paragraph>

##### **KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment**
2502.06472v1 by Yuxing Lu, Jinzhuo Wang

Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical
for modern AI systems, but manual curation struggles to scale with the rapid
growth of scientific literature. This paper presents KARMA, a novel framework
employing multi-agent large language models (LLMs) to automate KG enrichment
through structured analysis of unstructured text. Our approach employs nine
collaborative agents, spanning entity discovery, relation extraction, schema
alignment, and conflict resolution that iteratively parse documents, verify
extracted knowledge, and integrate it into existing graph structures while
adhering to domain-specific schema. Experiments on 1,200 PubMed articles from
three different domains demonstrate the effectiveness of KARMA in knowledge
graph enrichment, with the identification of up to 38,230 new entities while
achieving 83.1\% LLM-verified correctness and reducing conflict edges by 18.6\%
through multi-layer assessments.

摘要：維護全面且最新的知識圖譜 (KG) 對現代 AI 系統至關重要，但手動策劃難以隨著科學文獻的快速增長而擴展。本文提出了 KARMA，一個採用多代理大型語言模型 (LLM) 的新框架，透過對非結構化文本的結構化分析來自動化 KG 豐富化。我們的做法採用九個協作代理，涵蓋實體發現、關係提取、架構比對和衝突解決，這些代理會反覆分析文件、驗證提取的知識，並將其整合到現有的圖結構中，同時遵守特定領域的架構。針對來自三個不同領域的 1,200 篇 PubMed 文章進行的實驗證明了 KARMA 在知識圖譜豐富化方面的有效性，識別出多達 38,230 個新實體，同時達到 83.1% 的 LLM 驗證正確性，並透過多層評估將衝突邊緣降低了 18.6%。

##### **RoToR: Towards More Reliable Responses for Order-Invariant Inputs**
2502.08662v1 by Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, Seung-won Hwang

Mitigating positional bias of language models (LMs) for listwise inputs is a
well-known and important problem (e.g., lost-in-the-middle). While zero-shot
order-invariant LMs have been proposed to solve this issue, their success on
practical listwise problems has been limited. In this work, as a first
contribution, we identify and overcome two limitations to make zero-shot
invariant LMs more practical: (1) training and inference distribution mismatch
arising from modifying positional ID assignments to enforce invariance, and (2)
failure to adapt to a mixture of order-invariant and sensitive inputs in
practical listwise problems. To overcome, we propose (1) RoToR, a zero-shot
invariant LM for genuinely order-invariant inputs with minimal modifications of
positional IDs, and (2) Selective Routing, an adaptive framework that handles
both order-invariant and order-sensitive inputs in listwise tasks. On the Lost
in the middle (LitM), Knowledge Graph Question Answering (KGQA), and MMLU
benchmarks, we show that RoToR with Selective Routing can effectively handle
practical listwise input tasks in a zero-shot manner.

摘要：語言模型 (LM) 的位置偏差緩解對於列表輸入來說是一個廣為人知且重要的問題（例如，迷失在中間）。雖然已經提出零次學習順序不變的 LM 來解決這個問題，但它們在實際列表問題上的成功卻很有限。在這項工作中，作為第一個貢獻，我們找出並克服了兩個限制，讓零次學習不變的 LM 更有實用性：(1) 訓練和推論分布不匹配，這是由於修改位置 ID 分配以強制不變性所造成的，以及 (2) 無法適應實際列表問題中不變和敏感輸入的組合。為了克服這些問題，我們提出 (1) RoToR，一個零次學習不變的 LM，用於真正不變的輸入，並對位置 ID 進行最小的修改，以及 (2) 選擇性路由，一個自適應框架，用於處理列表任務中不變和敏感的輸入。在迷失在中間 (LitM)、知識圖譜問答 (KGQA) 和 MMLU 基準測試中，我們展示了 RoToR 與選擇性路由可以有效地以零次學習的方式處理實際的列表輸入任務。

##### **K-ON: Stacking Knowledge On the Head Layer of Large Language Model**
2502.06257v1 by Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen

Recent advancements in large language models (LLMs) have significantly
improved various natural language processing (NLP) tasks. Typically, LLMs are
trained to predict the next token, aligning well with many NLP tasks. However,
in knowledge graph (KG) scenarios, entities are the fundamental units and
identifying an entity requires at least several tokens. This leads to a
granularity mismatch between KGs and natural languages. To address this issue,
we propose K-ON, which integrates KG knowledge into the LLM by employing
multiple head layers for next k-step prediction. K-ON can not only generate
entity-level results in one step, but also enables contrastive loss against
entities, which is the most powerful tool in KG representation learning.
Experimental results show that K-ON outperforms state-of-the-art methods that
incorporate text and even the other modalities.

摘要：大型語言模型 (LLM) 的最新進展顯著提升了各種自然語言處理 (NLP) 任務。通常，LLM 會接受訓練以預測下一個符號，這與許多 NLP 任務非常吻合。然而，在知識圖譜 (KG) 場景中，實體是基本單位，而識別實體至少需要幾個符號。這導致 KG 和自然語言之間的粒度不匹配。為了解決這個問題，我們提出了 K-ON，它透過採用多個頭部層進行下一個 k 步預測，將 KG 知識整合到 LLM 中。K-ON 不僅可以在一個步驟中產生實體層級的結果，還能針對實體啟用對比損失，這是 KG 表示學習中最有力的工具。實驗結果顯示，K-ON 優於將文字甚至其他方式納入考量的最新方法。

##### **LegalViz: Legal Text Visualization by Text To Diagram Generation**
2502.06147v2 by Eri Onami, Taiki Miyanishi, Koki Maeda, Shuhei Kurita

Legal documents including judgments and court orders require highly
sophisticated legal knowledge for understanding. To disclose expert knowledge
for non-experts, we explore the problem of visualizing legal texts with
easy-to-understand diagrams and propose a novel dataset of LegalViz with 23
languages and 7,010 cases of legal document and visualization pairs, using the
DOT graph description language of Graphviz. LegalViz provides a simple diagram
from a complicated legal corpus identifying legal entities, transactions, legal
sources, and statements at a glance, that are essential in each judgment. In
addition, we provide new evaluation metrics for the legal diagram visualization
by considering graph structures, textual similarities, and legal contents. We
conducted empirical studies on few-shot and finetuning large language models
for generating legal diagrams and evaluated them with these metrics, including
legal content-based evaluation within 23 languages. Models trained with
LegalViz outperform existing models including GPTs, confirming the
effectiveness of our dataset.

摘要：法律文件，包括判決和法院命令，需要高度專業的法律知識才能理解。為了向非專家揭露專家知識，我們探討了使用易於理解的圖表將法律文本視覺化的問題，並提出了一個新的 LegalViz 數據集，其中包含 23 種語言和 7,010 個法律文件和視覺化配對，使用 Graphviz 的 DOT 圖形描述語言。LegalViz 從複雜的法律語料庫中提供了一個簡單的圖表，可以一目了然地識別法律實體、交易、法律來源和陳述，這些在每項判決中都是必不可少的。此外，我們通過考慮圖形結構、文本相似性和法律內容，為法律圖表視覺化提供了新的評估指標。我們對少次學習和微調大型語言模型進行了實證研究，以生成法律圖表，並使用這些指標對它們進行了評估，包括在 23 種語言中基於法律內容的評估。使用 LegalViz 訓練的模型優於現有的模型，包括 GPT，證實了我們數據集的有效性。

##### **Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs**
2502.06075v1 by Han Meng, Renwen Zhang, Ganyi Wang, Yitian Yang, Peinuan Qin, Jungup Lee, Yi-Chieh Lee

Mental-illness stigma is a persistent social problem, hampering both
treatment-seeking and recovery. Accordingly, there is a pressing need to
understand it more clearly, but analyzing the relevant data is highly
labor-intensive. Therefore, we designed a chatbot to engage participants in
conversations; coded those conversations qualitatively with AI assistance; and,
based on those coding results, built causal knowledge graphs to decode stigma.
The results we obtained from 1,002 participants demonstrate that conversation
with our chatbot can elicit rich information about people's attitudes toward
depression, while our AI-assisted coding was strongly consistent with
human-expert coding. Our novel approach combining large language models (LLMs)
and causal knowledge graphs uncovered patterns in individual responses and
illustrated the interrelationships of psychological constructs in the dataset
as a whole. The paper also discusses these findings' implications for HCI
researchers in developing digital interventions, decomposing human
psychological constructs, and fostering inclusive attitudes.

摘要：精神疾病的污名化是一個持續存在的社會問題，阻礙了尋求治療和康復。因此，迫切需要更清楚地了解它，但分析相關數據非常費力。因此，我們設計了一個聊天機器人，讓參與者參與對話；使用 AI 協助對這些對話進行定性編碼；並根據這些編碼結果，構建因果知識圖譜來破譯污名化。我們從 1,002 名參與者那裡獲得的結果表明，與我們的聊天機器人的對話可以引出人們對憂鬱症的豐富資訊，而我們 AI 輔助的編碼與人類專家編碼非常一致。我們將大型語言模型 (LLM) 和因果知識圖譜相結合的新方法揭示了個別反應中的模式，並說明了資料集中心理建構之間的相互關係。本文還討論了這些發現對 HCI 研究人員在開發數位介入措施、分解人類心理建構和培養包容態度方面的影響。

##### **LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification**
2502.05836v1 by Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

In this paper, we address the task of semantic segmentation of legal
documents through rhetorical role classification, with a focus on Indian legal
judgments. We introduce LegalSeg, the largest annotated dataset for this task,
comprising over 7,000 documents and 1.4 million sentences, labeled with 7
rhetorical roles. To benchmark performance, we evaluate multiple
state-of-the-art models, including Hierarchical BiLSTM-CRF,
TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and
Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an
instruction-tuned large language model. Our results demonstrate that models
incorporating broader context, structural relationships, and sequential
sentence information outperform those relying solely on sentence-level
features. Additionally, we conducted experiments using surrounding context and
predicted or actual labels of neighboring sentences to assess their impact on
classification accuracy. Despite these advancements, challenges persist in
distinguishing between closely related roles and addressing class imbalance.
Our work underscores the potential of advanced techniques for improving legal
document understanding and sets a strong foundation for future research in
legal NLP.

摘要：<paragraph>在本文中，我們通過修辭角色分類來探討法律文件的語義分段任務，重點關注印度法律判決。我們引入了 LegalSeg，這是此任務中最大的註釋資料集，包含超過 7,000 份文件和 140 萬個句子，並標記了 7 個修辭角色。為了評量效能，我們評估了多個最先進的模型，包括分層 BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)、圖神經網路 (GNN) 和角色感知Transformer，以及探索性的 RhetoricLLaMA，一種經過指令調整的大型語言模型。我們的結果表明，結合廣泛背景、結構關係和順序句子資訊的模型，表現優於僅依賴句子層級特徵的模型。此外，我們使用周圍的背景和鄰近句子的預測或實際標籤進行實驗，以評估它們對分類精度的影響。儘管有這些進展，但在區分密切相關的角色和解決類別不平衡方面仍存在挑戰。我們的研究強調了先進技術在改善法律文件理解方面的潛力，並為法律自然語言處理的未來研究奠定了堅實的基礎。</paragraph>

##### **LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning**
2502.05453v1 by Hanqing Yang, Jingdi Chen, Marie Siew, Tania Lorido-Botran, Carlee Joe-Wong

Developing intelligent agents for long-term cooperation in dynamic open-world
scenarios is a major challenge in multi-agent systems. Traditional Multi-agent
Reinforcement Learning (MARL) frameworks like centralized training
decentralized execution (CTDE) struggle with scalability and flexibility. They
require centralized long-term planning, which is difficult without custom
reward functions, and face challenges in processing multi-modal data. CTDE
approaches also assume fixed cooperation strategies, making them impractical in
dynamic environments where agents need to adapt and plan independently. To
address decentralized multi-agent cooperation, we propose Decentralized
Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in
a novel Multi-agent Crafter environment. Our generative agents, powered by
Large Language Models (LLMs), are more scalable than traditional MARL agents by
leveraging external knowledge and language for long-term planning and
reasoning. Instead of fully sharing information from all past experiences,
DAMCS introduces a multi-modal memory system organized as a hierarchical
knowledge graph and a structured communication protocol to optimize agent
cooperation. This allows agents to reason from past interactions and share
relevant information efficiently. Experiments on novel multi-agent open-world
tasks show that DAMCS outperforms both MARL and LLM baselines in task
efficiency and collaboration. Compared to single-agent scenarios, the two-agent
scenario achieves the same goal with 63% fewer steps, and the six-agent
scenario with 74% fewer steps, highlighting the importance of adaptive memory
and structured communication in achieving long-term goals. We publicly release
our project at: https://happyeureka.github.io/damcs.

摘要：<paragraph>在動態開放世界情境中開發用於長期合作的智慧代理是多重代理系統中的一項重大挑戰。傳統的多重代理強化學習 (MARL) 框架，例如集中式訓練去中心化執行 (CTDE)，在可擴充性和靈活性方面面臨困難。它們需要集中式長期規劃，這在沒有自訂獎勵函數的情況下很難執行，並且在處理多模式數據時會面臨挑戰。CTDE 方法還假設固定的合作策略，這使得它們在代理需要獨立適應和規劃的動態環境中不切實際。為了解決分散式多重代理合作問題，我們在一個新穎的多重代理工匠環境中提出了分散式自適應知識圖譜記憶體和結構化通訊系統 (DAMCS)。我們的生成代理由大型語言模型 (LLM) 提供支援，透過利用外部知識和語言進行長期規劃和推理，比傳統的 MARL 代理更具可擴充性。DAMCS 沒有完全分享來自所有過去經驗的資訊，而是引入了多模式記憶體系統，該系統組織成階層式知識圖譜和結構化通訊協定，以最佳化代理合作。這允許代理根據過去的互動進行推理並有效地分享相關資訊。在新的多重代理開放世界任務上的實驗表明，DAMCS 在任務效率和協作方面優於 MARL 和 LLM 基準。與單一代理情境相比，雙重代理情境以少 63% 的步驟達成相同的目標，而六重代理情境則以少 74% 的步驟達成目標，突顯了自適應記憶體和結構化通訊在達成長期目標中的重要性。我們公開發布我們的專案於：https://happyeureka.github.io/damcs。</paragraph>

##### **SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation**
2502.05424v1 by Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang

Graphs are able to model interconnected entities in many online services,
supporting a wide range of applications on the Web. This raises an important
question: How can we train a graph foundational model on multiple source
domains and adapt to an unseen target domain? A major obstacle is that graphs
from different domains often exhibit divergent characteristics. Some studies
leverage large language models to align multiple domains based on textual
descriptions associated with the graphs, limiting their applicability to
text-attributed graphs. For text-free graphs, a few recent works attempt to
align different feature distributions across domains, while generally
neglecting structural differences. In this work, we propose a novel Structure
Alignment framework for text-free Multi-domain Graph Pre-Training and
cross-domain adaptation (SAMGPT). It is designed to learn multi-domain
knowledge from graphs originating in multiple source domains, which can then be
adapted to address applications in an unseen target domain. Specifically, we
introduce a set of structure tokens to harmonize structure-based aggregation
across source domains during the pre-training phase. Next, for cross-domain
adaptation, we design dual prompts, namely, holistic prompts and specific
prompts, which adapt unified multi-domain structural knowledge and
fine-grained, domain-specific information, respectively, to a target domain.
Finally, we conduct comprehensive experiments on seven public datasets to
evaluate and analyze the effectiveness of SAMGPT.

摘要：圖表能夠在許多線上服務中對相互關聯的實體進行建模，
支援網路上廣泛的應用程式。這提出了重要的問題：我們如何針對多個來源網域訓練圖表基礎模型，並適應未見過的目標網域？一個主要的障礙是，來自不同網域的圖表通常表現出不同的特性。一些研究利用大型語言模型，根據與圖表相關的文字描述，對齊多個網域，限制其適用性於有文字屬性的圖表。對於沒有文字的圖表，最近的一些作品嘗試對齊跨網域的不同特徵分佈，同時通常忽略結構上的差異。在這項工作中，我們提出了一個新的結構對齊框架，用於無文字多網域圖表預訓練和跨網域適應 (SAMGPT)。它被設計為從起源於多個來源網域的圖表中學習多網域知識，然後可以適應於未見過的目標網域中的應用程式。具體來說，我們引入了一組結構化代碼，以在預訓練階段，調和跨來源網域的基於結構的聚合。接下來，對於跨網域適應，我們設計了雙重提示，即整體提示和具體提示，分別將統一的多網域結構知識和細緻的、特定於網域的資訊適應到目標網域。最後，我們在七個公共資料集上進行了全面的實驗，以評估和分析 SAMGPT 的有效性。

##### **Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints**
2502.05414v1 by Ali Al-Lawati, Jason Lucas, Zhiwei Zhang, Prasenjit Mitra, Suhang Wang

In-context learning (ICL) effectively conditions large language models (LLMs)
for molecular tasks, such as property prediction and molecule captioning, by
embedding carefully selected demonstration examples into the input prompt. This
approach avoids the computational overhead of extensive pertaining and
fine-tuning. However, current prompt retrieval methods for molecular tasks have
relied on molecule feature similarity, such as Morgan fingerprints, which do
not adequately capture the global molecular and atom-binding relationships. As
a result, these methods fail to represent the full complexity of molecular
structures during inference. Moreover, small-to-medium-sized LLMs, which offer
simpler deployment requirements in specialized systems, have remained largely
unexplored in the molecular ICL literature. To address these gaps, we propose a
self-supervised learning technique, GAMIC (Graph-Aligned Molecular In-Context
learning, which aligns global molecular structures, represented by graph neural
networks (GNNs), with textual captions (descriptions) while leveraging local
feature similarity through Morgan fingerprints. In addition, we introduce a
Maximum Marginal Relevance (MMR) based diversity heuristic during retrieval to
optimize input prompt demonstration samples. Our experimental findings using
diverse benchmark datasets show GAMIC outperforms simple Morgan-based ICL
retrieval methods across all tasks by up to 45%.

摘要：<paragraph>情境學習 (ICL) 有效地調整大型語言模型 (LLM)，以執行分子任務，例如屬性預測和分子標題，方法是將仔細挑選的示範範例嵌入輸入提示中。這種方法避免了廣泛相關和微調的計算開銷。然而，目前針對分子任務的提示檢索方法依賴於分子特徵相似性，例如 Morgan 指紋，而無法充分捕捉全局分子和原子鍵結關係。因此，這些方法無法在推理過程中表示分子結構的完整複雜性。此外，在專業系統中提供更簡單部署需求的小到中型的 LLM，在分子 ICL 文獻中仍未得到充分探索。為了解決這些差距，我們提出了一種自我監督學習技術，GAMIC（圖形對齊分子情境學習），它將由圖形神經網路 (GNN) 表示的全局分子結構與文字標題（描述）對齊，同時透過 Morgan 指紋利用局部特徵相似性。此外，我們在檢索過程中引入了一個基於最大邊際相關性 (MMR) 的多樣性啟發法，以最佳化輸入提示示範樣本。我們使用不同的基準資料集進行的實驗結果顯示，GAMIC 在所有任務中都優於基於 Morgan 的簡單 ICL 檢索方法，最多可達 45%。</paragraph>

##### **Knowledge Graph-Guided Retrieval Augmented Generation**
2502.06864v1 by Xiangrong Zhu, Yuexiang Xie, Yi Liu, Yaliang Li, Wei Hu

Retrieval-augmented generation (RAG) has emerged as a promising technology
for addressing hallucination issues in the responses generated by large
language models (LLMs). Existing studies on RAG primarily focus on applying
semantic-based approaches to retrieve isolated relevant chunks, which ignore
their intrinsic relationships. In this paper, we propose a novel Knowledge
Graph-Guided Retrieval Augmented Generation (KG$^2$RAG) framework that utilizes
knowledge graphs (KGs) to provide fact-level relationships between chunks,
improving the diversity and coherence of the retrieved results. Specifically,
after performing a semantic-based retrieval to provide seed chunks, KG$^2$RAG
employs a KG-guided chunk expansion process and a KG-based chunk organization
process to deliver relevant and important knowledge in well-organized
paragraphs. Extensive experiments conducted on the HotpotQA dataset and its
variants demonstrate the advantages of KG$^2$RAG compared to existing RAG-based
approaches, in terms of both response quality and retrieval quality.

摘要：檢索增強生成 (RAG) 已成為一項有前途的技術，用於解決大型語言模型 (LLM) 所產生回應中的幻覺問題。現有關於 RAG 的研究主要專注於應用基於語義的方法來檢索孤立相關的區塊，而忽略它們的內在關係。在本文中，我們提出了一個新穎的知識圖表引導檢索增強生成 (KG$^2$RAG) 框架，它利用知識圖表 (KG) 來提供區塊之間的事實層級關係，從而提高檢索結果的多樣性和一致性。具體來說，在執行基於語義的檢索以提供種子區塊後，KG$^2$RAG 採用 KG 引導的區塊擴充程序和基於 KG 的區塊組織程序，以在組織良好的段落中傳達相關且重要的知識。在 HotpotQA 資料集及其變體上進行的大量實驗證明了 KG$^2$RAG 在回應品質和檢索品質方面優於現有的基於 RAG 的方法。

##### **Can Large Language Models Understand Intermediate Representations?**
2502.06854v1 by Hailong Jiang, Jianfeng Zhu, Yao Wan, Bo Fang, Hongyu Zhang, Ruoming Jin, Qiang Guan

Intermediate Representations (IRs) are essential in compiler design and
program analysis, yet their comprehension by Large Language Models (LLMs)
remains underexplored. This paper presents a pioneering empirical study to
investigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA
3.1, and Code Llama, in understanding IRs. We analyze their performance across
four tasks: Control Flow Graph (CFG) reconstruction, decompilation, code
summarization, and execution reasoning. Our results indicate that while LLMs
demonstrate competence in parsing IR syntax and recognizing high-level
structures, they struggle with control flow reasoning, execution semantics, and
loop handling. Specifically, they often misinterpret branching instructions,
omit critical IR operations, and rely on heuristic-based reasoning, leading to
errors in CFG reconstruction, IR decompilation, and execution reasoning. The
study underscores the necessity for IR-specific enhancements in LLMs,
recommending fine-tuning on structured IR datasets and integration of explicit
control flow models to augment their comprehension and handling of IR-related
tasks.

摘要：中間表徵 (IR) 在編譯器設計和程式分析中至關重要，但大型語言模型 (LLM) 對其理解仍未得到充分探討。本文提出了一項開創性的實證研究，以探討 LLM（包括 GPT-4、GPT-3、Gemma 2、LLaMA 3.1 和 Code Llama）理解 IR 的能力。我們分析了它們在四項任務中的表現：控制流程圖 (CFG) 重建、反編譯、程式碼摘要和執行推理。我們的結果表明，儘管 LLM 在解析 IR 語法和識別高階結構方面表現出能力，但它們在控制流程推理、執行語義和迴圈處理方面存在困難。具體而言，它們經常誤解分支指令、省略關鍵 IR 操作，並依賴於基於啟發式的推理，導致 CFG 重建、IR 反編譯和執行推理出現錯誤。這項研究強調了 LLM 中對 IR 特定的增強的必要性，建議對結構化的 IR 資料集進行微調，並整合明確的控制流程模型，以增強其對 IR 相關任務的理解和處理。

##### **GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?**
2502.05252v1 by Yang Zhou, Hongyi Liu, Zhuoming Chen, Yuandong Tian, Beidi Chen

Long-context large language models (LLMs) have recently shown strong
performance in information retrieval and long-document QA. However, to tackle
the most challenging intellectual problems, LLMs must reason effectively in
long and complex contexts (e.g., frontier mathematical research). Studying how
LLMs handle increasing reasoning complexity and context length is essential,
yet existing benchmarks lack a solid basis for quantitative evaluation.
Inspired by the abstraction of GSM-8K problems as computational graphs, and the
ability to introduce noise by adding unnecessary nodes and edges, we develop a
grade school math problem generator capable of producing arithmetic problems
with infinite difficulty and context length under fine-grained control. Using
our newly synthesized GSM-Infinite benchmark, we comprehensively evaluate
existing LLMs. We find a consistent sigmoid decline in reasoning performance as
complexity increases, along with a systematic inference scaling trend:
exponentially increasing inference computation yields only linear performance
gains. These findings underscore the fundamental limitations of current
long-context LLMs and the key challenges in scaling reasoning capabilities. Our
GSM-Infinite benchmark provides a scalable and controllable testbed for
systematically studying and advancing LLM reasoning in long and complex
contexts.

摘要：長文本大型語言模型 (LLM) 最近在資訊檢索和長文件問答中展示了強大的效能。然而，若要解決最具挑戰性的智力問題，LLM 必須在長且複雜的脈絡中有效推理（例如，前沿數學研究）。研究 LLM 如何處理增加的推理複雜性和脈絡長度至關重要，但現有的基準缺乏定量評估的穩固基礎。受到 GSM-8K 問題抽象化為計算圖形的啟發，以及透過加入不必要的節點和邊緣來引入雜訊的能力，我們開發了一個小學數學問題產生器，能夠在細緻的控制下產生具有無限難度和脈絡長度的算術問題。使用我們新合成的 GSM-Infinite 基準，我們全面評估現有的 LLM。我們發現推理效能會隨著複雜性的增加而持續呈 S 形下降，並伴隨著系統性的推論縮放趨勢：指數增加的推論計算僅產生線性的效能增益。這些發現強調了當前長脈絡 LLM 的基本限制，以及擴展推理能力的主要挑戰。我們的 GSM-Infinite 基準提供了一個可擴充且可控的測試平台，用於系統性地研究和提升 LLM 在長且複雜脈絡中的推理能力。

##### **Causality can systematically address the monsters under the bench(marks)**
2502.05085v1 by Felix Leeb, Zhijing Jin, Bernhard Schölkopf

Effective and reliable evaluation is essential for advancing empirical
machine learning. However, the increasing accessibility of generalist models
and the progress towards ever more complex, high-level tasks make systematic
evaluation more challenging. Benchmarks are plagued by various biases,
artifacts, or leakage, while models may behave unreliably due to poorly
explored failure modes. Haphazard treatments and inconsistent formulations of
such "monsters" can contribute to a duplication of efforts, a lack of trust in
results, and unsupported inferences. In this position paper, we argue causality
offers an ideal framework to systematically address these challenges. By making
causal assumptions in an approach explicit, we can faithfully model phenomena,
formulate testable hypotheses with explanatory power, and leverage principled
tools for analysis. To make causal model design more accessible, we identify
several useful Common Abstract Topologies (CATs) in causal graphs which help
gain insight into the reasoning abilities in large language models. Through a
series of case studies, we demonstrate how the precise yet pragmatic language
of causality clarifies the strengths and limitations of a method and inspires
new approaches for systematic progress.

摘要：有效的、可靠的評估對於推進經驗機器學習至關重要。然而，一般化模型的可及性日益提高，以及朝著更複雜、更高級別任務的進展，使得系統評估更具挑戰性。基準測試受到各種偏差、人工製品或洩漏的困擾，而模型由於探索不充分的故障模式而可能表現得不可靠。隨意處理和不一致的表述等「怪物」可能會導致重複工作、對結果缺乏信任以及不支援的推論。在本文中，我們論證因果關係提供了一個系統性解決這些挑戰的理想框架。通過在方法中明確因果假設，我們可以忠實地模擬現象，制定具有解釋力的可測試假設，並利用原則性的分析工具。為了使因果模型設計更易於使用，我們在因果圖中識別出幾個有用的通用抽象拓撲 (CAT)，有助於深入了解大型語言模型中的推理能力。通過一系列案例研究，我們展示了因果關係的精確但務實的語言如何釐清方法的優缺點，並激發系統進展的新方法。

##### **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**
2502.05078v1 by Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha

Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their performance is highly dependent on the prompting
strategy and model scale. While reinforcement learning and fine-tuning have
been deployed to boost reasoning, these approaches incur substantial
computational and data overhead. In this work, we introduce Adaptive Graph of
Thoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM
reasoning solely at test time. Rather than relying on fixed-step methods like
Chain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes
complex queries into structured subproblems, forming an dynamic directed
acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding
only those subproblems that require further analysis, AGoT unifies the
strengths of chain, tree, and graph paradigms into a cohesive framework that
allocates computation where it is most needed. We validate our approach on
diverse benchmarks spanning multi-hop retrieval, scientific reasoning, and
mathematical problem-solving, achieving up to 46.2% improvement on scientific
reasoning tasks (GPQA) - comparable to gains achieved through computationally
intensive reinforcement learning approaches and outperforming state-of-the-art
iterative approaches. These results suggest that dynamic decomposition and
structured recursion offer a scalable, cost-effective alternative to
post-training modifications, paving the way for more robust, general-purpose
reasoning in LLMs.

摘要：大型語言模型 (LLM) 已展現令人印象深刻的推理能力，但其效能高度依賴於提示策略和模型規模。雖然強化學習和微調已被用於提升推理，但這些方法會造成大量的運算和資料開銷。在這項工作中，我們引入了「適應性思考圖」(AGoT)，一個動態的、基於圖形的推論架構，它僅在測試時就能增強 LLM 推理。AGoT 並非依賴於鏈式思考 (CoT) 或樹狀思考 (ToT) 等固定步驟方法，而是遞迴地將複雜的查詢分解成結構化的子問題，形成一個由相互依賴的推理步驟所組成的動態有向無環圖 (DAG)。透過選擇性地僅擴充那些需要進一步分析的子問題，AGoT 將鏈式、樹狀和圖形範例的優勢統一到一個緊密的架構中，將運算分配到最需要的地方。我們在跨越多重跳躍檢索、科學推理和數學問題解決等多樣基準上驗證了我們的做法，在科學推理任務 (GPQA) 上達到了高達 46.2% 的改進，這與透過運算密集的強化學習方法所獲得的增益相當，並且優於最先進的迭代方法。這些結果表明，動態分解和結構化遞迴提供了一個可擴充、具成本效益的替代方案，用於訓練後修改，為 LLM 中更強健、更通用的推理鋪平了道路。

##### **Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics**
2502.05239v1 by Hussam Ghanem, Christophe Cruz

Recent advancements in large language models have demonstrated significant
potential in the automated construction of knowledge graphs from unstructured
text. This paper builds upon our previous work [16], which evaluated various
models using metrics like precision, recall, F1 score, triple matching, and
graph matching, and introduces a refined approach to address the critical
issues of hallucination and omission. We propose an enhanced evaluation
framework incorporating BERTScore for graph similarity, setting a practical
threshold of 95% for graph matching. Our experiments focus on the Mistral
model, comparing its original and fine-tuned versions in zero-shot and few-shot
settings. We further extend our experiments using examples from the KELM-sub
training dataset, illustrating that the fine-tuned model significantly improves
knowledge graph construction accuracy while reducing the exact hallucination
and omission. However, our findings also reveal that the fine-tuned models
perform worse in generalization tasks on the KELM-sub dataset. This study
underscores the importance of comprehensive evaluation metrics in advancing the
state-of-the-art in knowledge graph construction from textual data.

摘要：大型語言模型的最新進展已證明在從非結構化文字自動建構知識圖譜方面具有顯著的潛力。本文建立在我們先前的研究 [16] 之上，該研究使用準確度、召回率、F1 分數、三元組匹配和圖形匹配等指標評估各種模型，並引入了一種改進的方法來解決幻覺和遺漏的關鍵問題。我們提出一個增強的評估框架，結合 BERTScore 來進行圖形相似性，並將圖形匹配的實際閾值設定為 95%。我們的實驗重點在 Mistral 模型上，比較其原始版本和微調版本在零次學習和少量學習的設定中。我們進一步使用 KELM-sub 訓練資料集中的範例來擴展我們的實驗，說明微調後的模型顯著提高了知識圖譜建構的準確度，同時減少了精確的幻覺和遺漏。然而，我們的研究結果也顯示，微調後的模型在 KELM-sub 資料集上的泛化任務表現較差。這項研究強調了全面評估指標在推進從文字資料建構知識圖譜的最新技術方面的重要性。

##### **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**
2502.04644v1 by Junde Wu, Jiayuan Zhu, Yuyuan Liu

We introduce Agentic Reasoning, a framework that enhances large language
model (LLM) reasoning by integrating external tool-using agents. Unlike
conventional LLM-based reasoning approaches, which rely solely on internal
inference, Agentic Reasoning dynamically engages web search, code execution,
and structured reasoning-context memory to solve complex problems requiring
deep research and multi-step logical deduction. Our framework introduces the
Mind Map agent, which constructs a structured knowledge graph to track logical
relationships, improving deductive reasoning. Additionally, the integration of
web-search and coding agents enables real-time retrieval and computational
analysis, enhancing reasoning accuracy and decision-making. Evaluations on
PhD-level scientific reasoning (GPQA) and domain-specific deep research tasks
demonstrate that our approach significantly outperforms existing models,
including leading retrieval-augmented generation (RAG) systems and
closed-source LLMs. Moreover, our results indicate that agentic reasoning
improves expert-level knowledge synthesis, test-time scalability, and
structured problem-solving. The code is at:
https://github.com/theworldofagents/Agentic-Reasoning.

摘要：我們引入了代理推理，一個透過整合外部工具使用代理來增強大型語言模型 (LLM) 推理的框架。與僅依賴於內部推論的傳統基於 LLM 的推理方法不同，代理推理動態地運用網路搜尋、程式碼執行和結構化推理情境記憶來解決需要深入研究和多步驟邏輯推論的複雜問題。我們的框架引入了心智圖代理，它建立一個結構化的知識圖譜來追蹤邏輯關係，改善演繹推理。此外，整合網路搜尋和編碼代理能進行即時擷取和運算分析，增強推理準確度和決策制定。在博士等級科學推理 (GPQA) 和特定領域的深入研究任務上的評估顯示，我們的做法明顯優於現有模型，包括領先的檢索增強生成 (RAG) 系統和封閉原始碼 LLM。此外，我們的結果顯示，代理推理改進了專家級知識綜合、測試時間可擴充性和結構化問題解決。程式碼在：https://github.com/theworldofagents/Agentic-Reasoning。

##### **Position-aware Automatic Circuit Discovery**
2502.04577v1 by Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

A widely used strategy to discover and understand language model mechanisms
is circuit analysis. A circuit is a minimal subgraph of a model's computation
graph that executes a specific task. We identify a gap in existing circuit
discovery methods: they assume circuits are position-invariant, treating model
components as equally relevant across input positions. This limits their
ability to capture cross-positional interactions or mechanisms that vary across
positions. To address this gap, we propose two improvements to incorporate
positionality into circuits, even on tasks containing variable-length examples.
First, we extend edge attribution patching, a gradient-based method for circuit
discovery, to differentiate between token positions. Second, we introduce the
concept of a dataset schema, which defines token spans with similar semantics
across examples, enabling position-aware circuit discovery in datasets with
variable length examples. We additionally develop an automated pipeline for
schema generation and application using large language models. Our approach
enables fully automated discovery of position-sensitive circuits, yielding
better trade-offs between circuit size and faithfulness compared to prior work.

摘要：廣泛用於發現和了解語言模型機制的策略是電路分析。電路是模型計算圖的最小子圖，可執行特定任務。我們找出電路發現方法中的一個缺口：它們假設電路與位置無關，將模型組件視為在輸入位置中同樣相關。這限制了它們捕捉跨位置互動或在不同位置中變化的機制的能力。為了解決這個缺口，我們提出兩項改進，將位置性納入電路中，即使在包含變長範例的任務中也是如此。首先，我們擴充邊緣屬性修補，一種基於梯度的電路發現方法，以區分符號位置。其次，我們引入了資料集架構的概念，它定義了在範例中具有類似語義的符號跨距，使我們可以在具有變長範例的資料集中進行與位置相關的電路發現。此外，我們開發了一個自動化管線，用於使用大型語言模型進行架構生成和應用。我們的做法能讓位置敏感電路的發現完全自動化，與先前的研究相比，在電路大小和忠實度之間產生了更好的權衡。

##### **Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**
2502.04510v1 by Shangbin Feng, Zifeng Wang, Palash Goyal, Yike Wang, Weijia Shi, Huang Xia, Hamid Palangi, Luke Zettlemoyer, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister

We propose Heterogeneous Swarms, an algorithm to design multi-LLM systems by
jointly optimizing model roles and weights. We represent multi-LLM systems as
directed acyclic graphs (DAGs) of LLMs with topological message passing for
collaborative generation. Given a pool of LLM experts and a utility function,
Heterogeneous Swarms employs two iterative steps: role-step and weight-step.
For role-step, we interpret model roles as learning a DAG that specifies the
flow of inputs and outputs between LLMs. Starting from a swarm of random
continuous adjacency matrices, we decode them into discrete DAGs, call the LLMs
in topological order, evaluate on the utility function (e.g. accuracy on a
task), and optimize the adjacency matrices with particle swarm optimization
based on the utility score. For weight-step, we assess the contribution of
individual LLMs in the multi-LLM systems and optimize model weights with swarm
intelligence. We propose JFK-score to quantify the individual contribution of
each LLM in the best-found DAG of the role-step, then optimize model weights
with particle swarm optimization based on the JFK-score. Experiments
demonstrate that Heterogeneous Swarms outperforms 15 role- and/or weight-based
baselines by 18.5% on average across 12 tasks. Further analysis reveals that
Heterogeneous Swarms discovers multi-LLM systems with heterogeneous model roles
and substantial collaborative gains, and benefits from the diversity of
language models.

摘要：<paragraph>我們提出異質群體，一種演算法，透過共同最佳化模型角色和權重來設計多 LLM 系統。我們將多 LLM 系統表示為 LLM 的有向非循環圖 (DAG)，並透過拓撲訊息傳遞進行協作產生。給定一組 LLM 專家和一個效用函數，異質群體使用兩個反覆步驟：角色步驟和權重步驟。對於角色步驟，我們將模型角色解釋為學習一個 DAG，它指定 LLM 之間輸入和輸出的流動。從一組隨機連續鄰接矩陣開始，我們將它們解碼為離散 DAG，以拓撲順序呼叫 LLM，根據效用函數（例如任務的準確度）進行評估，並根據效用分數使用粒子群最佳化最佳化鄰接矩陣。對於權重步驟，我們評估個別 LLM 在多 LLM 系統中的貢獻，並使用群體智慧最佳化模型權重。我們提出 JFK 分數來量化每個 LLM 在角色步驟中找到的最佳 DAG 中的個別貢獻，然後根據 JFK 分數使用粒子群最佳化最佳化模型權重。實驗表明，異質群體在 12 項任務中平均比 15 個基於角色和/或權重的基線高出 18.5%。進一步的分析表明，異質群體發現具有異質模型角色和大量協作收益的多 LLM 系統，並受益於語言模型的多樣性。</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

摘要：檢索增強生成 (RAG) 是一種適用於檢索隱私敏感的電子健康記錄 (EHR) 的技術。它可以作為醫療保健副駕駛的一個關鍵模組，協助減少醫療保健從業人員和患者的誤診。然而，在醫療領域中使用的現有基於啟發法的 RAG 模型的診斷準確性和特異性不足，特別是對於具有類似表現的疾病。本文提出 MedRAG，一種由知識圖譜 (KG) 引發的推理增強的 RAG 模型，用於醫療領域，它根據表現檢索診斷和治療建議。MedRAG 系統性地構建了一個全面的四層階層式診斷 KG，涵蓋各種疾病的關鍵診斷差異。這些差異與從 EHR 資料庫中檢索到的類似 EHR 動態整合，並在大型語言模型中進行推理。這個過程可以實現更準確和具體的決策支援，同時主動提供後續問題，以增強個人化醫療決策制定。MedRAG 在公共資料集 DDXPlus 和從陳篤生醫院收集的私人慢性疼痛診斷資料集 (CPDD) 上進行評估，並將其效能與各種現有 RAG 方法進行比較。實驗結果顯示，利用 KG 的資訊整合和關係能力，我們的 MedRAG 提供了更具體的診斷見解，並在降低誤診率方面優於最先進的模型。我們的程式碼將在 https://github.com/SNOWTEAM2023/MedRAG 提供

##### **Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**
2502.03992v1 by Longquan Jiang, Junbo Huang, Cedric Möller, Ricardo Usbeck

Most existing Knowledge Graph Question Answering (KGQA) approaches are
designed for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the
heterogeneity of the underlying graph schema, topology and assertions, most
KGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without
resource-intensive training data. We present OntoSCPrompt, a novel Large
Language Model (LLM)-based KGQA approach with a two-stage architecture that
separates semantic parsing from KG-dependent interactions. OntoSCPrompt first
generates a SPARQL query structure (including SPARQL keywords such as SELECT,
ASK, WHERE and placeholders for missing tokens) and then fills them with
KG-specific information. To enhance the understanding of the underlying KG, we
present an ontology-guided, hybrid prompt learning strategy that integrates KG
ontology into the learning process of hybrid prompts (e.g., discrete and
continuous vectors). We also present several task-specific decoding strategies
to ensure the correctness and executability of generated SPARQL queries in both
stages. Experimental results demonstrate that OntoSCPrompt performs as well as
SOTA approaches without retraining on a number of KGQA datasets such as CWQ,
WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well
to unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

摘要：現有的知識圖譜問答（KGQA）方法大多是為特定 KG 而設計的，例如 Wikidata、DBpedia 或 Freebase。由於底層圖形模式、拓撲和斷言的異質性，大多數 KGQA 系統無法在沒有資源密集型訓練資料的情況下轉移到未見過的知識圖譜（KG）。我們提出 OntoSCPrompt，這是一種基於大型語言模型（LLM）的新型 KGQA 方法，採用兩階段架構，將語義解析與依賴 KG 的互動分開。OntoSCPrompt 首先生成 SPARQL 查詢結構（包括 SPARQL 關鍵字，例如 SELECT、ASK、WHERE 和缺失令牌的佔位符），然後用 KG 特定的資訊填寫它們。為了增強對底層 KG 的理解，我們提出了一種由本体指導的混合提示學習策略，將 KG 本体整合到混合提示（例如，離散和連續向量）的學習過程中。我們還提出了多種特定任務的解碼策略，以確保在兩個階段中生成的 SPARQL 查詢的正確性和可執行性。實驗結果表明，OntoSCPrompt 在 CWQ、WebQSP 和 LC-QuAD 1.0 等多個 KGQA 資料集上執行時，效能與 SOTA 方法一樣好，且資源使用效率高，並且可以很好地概括到未見過的特定領域 KG，例如 DBLP-QuAD 和 CoyPu KG Code：
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

##### **Multimodal Medical Code Tokenizer**
2502.04397v2 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

摘要：<paragraph>在患者电子健康记录 (EHR) 上训练的基础模型需要将医学数据标记为离散词汇项序列。现有的标记器将 EHR 中的医学代码视为孤立的文本标记。然而，每个医学代码都由其文本描述、在本体层次结构中的位置以及与其他代码的关系（例如疾病共现和药物治疗关联）来定义。医学词汇表包含超过 600,000 个代码，这些代码包含临床推理的关键信息。我们引入了 MedTok，这是一种多模态医学代码标记器，它使用文本描述和代码的关系上下文。MedTok 使用语言模型编码器处理文本，并使用图编码器对关系结构进行编码。然后，它将这两种模态量化为一个统一的标记空间，保留特定于模态和跨模态的信息。我们将 MedTok 集成到五个 EHR 模型中，并在住院和门诊数据集（包括结果预测、诊断分类、药物推荐和风险分层）上对其实施操作和临床任务进行评估。用 MedTok 替换标准 EHR 标记器可提高所有 EHR 模型的 AUPRC，在 MIMIC-III 上提高 4.10%，在 MIMIC-IV 上提高 4.78%，在 EHRShot 上提高 11.30%，其中药物推荐的增益最大。除了 EHR 建模之外，我们还演示了将 MedTok 标记器与医学问答系统结合使用。我们的结果证明了 MedTok 作为医学代码的统一标记器的潜力，改进了医学基础模型的标记化。</paragraph>

##### **Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**
2502.04392v1 by Chenyang Shao, Xinyuan Hu, Yutang Lin, Fengli Xu

The rapid expansion of web content has made on-device AI assistants
indispensable for helping users manage the increasing complexity of online
tasks. The emergent reasoning ability in large language models offer a
promising path for next-generation on-device AI agents. However, deploying
full-scale Large Language Models (LLMs) on resource-limited local devices is
challenging. In this paper, we propose Division-of-Thoughts (DoT), a
collaborative reasoning framework leveraging the synergy between locally
deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT
leverages a Task Decomposer to elicit the inherent planning abilities in
language models to decompose user queries into smaller sub-tasks, which allows
hybrid language models to fully exploit their respective strengths. Besides,
DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks
and create a dependency graph, facilitating parallel reasoning of sub-tasks and
the identification of key steps. To allocate the appropriate model based on the
difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an
additional task head attached to the SLM that does not alter the SLM's
parameters. To boost adapter's task allocation capability, we propose a
self-reinforced training method that relies solely on task execution feedback.
Extensive experiments on various benchmarks demonstrate that our DoT
significantly reduces LLM costs while maintaining competitive reasoning
accuracy. Specifically, DoT reduces the average reasoning time and API costs by
66.12% and 83.57%, while achieving comparable reasoning accuracy with the best
baseline methods.

摘要：<paragraph>網頁內容快速擴充，使得行動裝置上的 AI 助理在協助使用者管理日益複雜的線上工作上變得不可或缺。大型語言模型中浮現的推理能力為新一代行動裝置上的 AI 代理提供了一條有希望的途徑。然而，在資源有限的本機裝置上部署全規模的大型語言模型 (LLM) 是一項挑戰。在本文中，我們提出了思想分工 (DoT)，一個協作推理框架，利用了本地部署的小型語言模型 (SLM) 與雲端 LLM 之間的協同效應。DoT 利用任務分解器引出語言模型中固有的規劃能力，將使用者查詢分解成較小的子任務，這允許混合語言模型充分發揮其各自的優勢。此外，DoT 雇用了一個任務排程器來分析子任務的成對依賴性並建立一個依賴性圖，促進子任務的並行推理和關鍵步驟的識別。為了根據子任務的難度分配適當的模型，DoT 利用了即插即用適配器，這是一個附加在 SLM 上的任務頭，不會改變 SLM 的參數。為了提升適配器的任務分配能力，我們提出了一種自我強化訓練方法，它僅依賴於任務執行回饋。在各種基準上的廣泛實驗表明，我們的 DoT 大幅降低了 LLM 成本，同時維持了有競爭力的推理準確度。具體來說，DoT 將平均推理時間和 API 成本分別降低了 66.12% 和 83.57%，同時達到了與最佳基準方法相當的推理準確度。</paragraph>

##### **Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**
2502.03715v1 by Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong

Knowledge Graph-based recommendations have gained significant attention due
to their ability to leverage rich semantic relationships. However, constructing
and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy
of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent
advancements in Large Language Models (LLMs) offer a promising way to improve
the quality and relevance of KGs for recommendation tasks. Despite this,
integrating LLMs into KG-based systems presents challenges, such as efficiently
augmenting KGs, addressing hallucinations, and developing effective joint
learning methods. In this paper, we propose the Confidence-aware KG-based
Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework
that combines KGs and LLMs for recommendation task. The framework includes: (1)
an LLM-based subgraph augmenter for enriching KGs with high-quality
information, (2) a confidence-aware message propagation mechanism to filter
noisy triplets, and (3) a dual-view contrastive learning method to integrate
user-item interactions and KG data. Additionally, we employ a confidence-aware
explanation generation process to guide LLMs in producing realistic
explanations for recommendations. Finally, extensive experiments demonstrate
the effectiveness of CKG-LLMA across multiple public datasets.

摘要：基於知識圖譜的推薦因其利用豐富語義關係的能力而備受關注。然而，構建和維護知識圖譜 (KG) 是一項資源密集型任務，而 KG 的準確性可能會受到雜訊、過時或無關的三元組的影響。大型語言模型 (LLM) 的最新進展為提高 KG 在推薦任務中的品質和相關性提供了一種有前途的方法。儘管如此，將 LLM 整合到基於 KG 的系統中會帶來挑戰，例如有效擴充 KG、處理幻覺，以及開發有效的聯合學習方法。在本文中，我們提出具有 LLM 擴充的信心感知型基於 KG 的推薦框架 (CKG-LLMA)，這是一個結合 KG 和 LLM 進行推薦任務的新穎框架。該框架包括：(1) 一個基於 LLM 的子圖擴充器，用於使用高品質資訊豐富 KG，(2) 一個信心感知型訊息傳播機制，用於過濾雜訊三元組，以及 (3) 一個雙視圖對比學習方法，用於整合使用者-項目互動和 KG 資料。此外，我們採用一個信心感知型解釋產生程序，以引導 LLM 為推薦產生逼真的解釋。最後，大量的實驗證明了 CKG-LLMA 在多個公開資料集中的有效性。

##### **A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**
2502.03450v1 by Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell

Scene graphs have emerged as a structured and serializable environment
representation for grounded spatial reasoning with Large Language Models
(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason
framework for reasoning and planning with scene graphs. Our approach employs
two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and
information queries generation, and a (2) Retriever for extracting
corresponding graph information following the queries. Two agents collaborate
iteratively, enabling sequential reasoning and adaptive attention to graph
information. Unlike prior works, both agents are prompted only with the scene
graph schema rather than the full graph data, which reduces the hallucination
by limiting input tokens, and drives the Reasoner to generate reasoning trace
abstractly.Following the trace, the Retriever programmatically query the scene
graph data based on the schema understanding, allowing dynamic and global
attention on the graph that enhances alignment between reasoning and retrieval.
Through experiments in multiple simulation environments, we show that our
framework surpasses existing LLM-based approaches in numerical Q\&A and
planning tasks, and can benefit from task-level few-shot examples, even in the
absence of agent-level demonstrations. Project code will be released.

摘要：場景圖表已成為大型語言模型 (LLM) 以基礎空間推理為基礎的結構化且可序列化的環境表徵。在這項工作中，我們提出 SG-RwR，一個以綱要為導向的檢索與推理框架，用於場景圖表的推理和規劃。我們的做法採用了兩個協作的、編寫程式碼的 LLM 代理：一個 (1) 推論器，用於任務規劃和資訊查詢產生，以及一個 (2) 檢索器，用於根據查詢提取對應的圖形資訊。兩個代理反覆合作，實現對圖形資訊的順序推理和適應性關注。與先前的作品不同，兩個代理僅提示場景圖表綱要，而不是完整的圖形資料，這透過限制輸入代碼減少了幻覺，並驅使推論器抽象地產生推理軌跡。根據軌跡，檢索器根據綱要理解以程式化方式查詢場景圖形資料，允許對圖形進行動態和整體關注，增強推理和檢索之間的一致性。透過在多個模擬環境中的實驗，我們表明我們的框架在數值問答和規劃任務中超越了現有的基於 LLM 的方法，並且可以受益於任務級別的少次範例，即使在沒有代理級別示範的情況下也是如此。專案程式碼將會釋出。

##### **SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**
2502.03283v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng, Wotao Yin

Recent advancements have highlighted that Large Language Models (LLMs) are
prone to hallucinations when solving complex reasoning problems, leading to
erroneous results. To tackle this issue, researchers incorporate Knowledge
Graphs (KGs) to improve the reasoning ability of LLMs. However, existing
methods face two limitations: 1) they typically assume that all answers to the
questions are contained in KGs, neglecting the incompleteness issue of KGs, and
2) they treat the KG as a static repository and overlook the implicit logical
reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an
innovative neural-symbolic agent framework that achieves collaborative
augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments
and transform complex reasoning tasks into a multi-step interactive process,
enabling KGs to participate deeply in the reasoning process. SymAgent consists
of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages
LLM's inductive reasoning capability to extract symbolic rules from KGs,
guiding efficient question decomposition. The Agent-Executor autonomously
invokes predefined action tools to integrate information from KGs and external
documents, addressing the issues of KG incompleteness. Furthermore, we design a
self-learning framework comprising online exploration and offline iterative
policy updating phases, enabling the agent to automatically synthesize
reasoning trajectories and improve performance. Experimental results
demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields
better or comparable performance compared to various strong baselines. Further
analysis reveals that our agent can identify missing triples, facilitating
automatic KG updates.

摘要：<paragraph>最近的研究表明，大型语言模型 (LLM) 在解决复杂的推理问题时容易出现幻觉，从而导致错误的结果。为了解决这个问题，研究人员结合了知识图谱 (KG) 来提高 LLM 的推理能力。然而，现有方法面临两个局限性：1) 它们通常假设问题的答案都包含在 KG 中，忽略了 KG 不完整的问题，2) 它们将 KG 视为一个静态存储库，而忽略了 KG 中固有的隐式逻辑推理结构。在本文中，我们介绍了 SymAgent，这是一个创新的神经符号代理框架，可以在 KG 和 LLM 之间实现协作增强。我们将 KG 概念化为动态环境，并将复杂的推理任务转化为一个多步骤的交互过程，使 KG 能够深入参与推理过程。SymAgent 由两个模块组成：Agent-Planner 和 Agent-Executor。Agent-Planner 利用 LLM 的归纳推理能力从 KG 中提取符号规则，指导高效的问题分解。Agent-Executor 自主调用预定义的动作工具来整合来自 KG 和外部文档的信息，解决 KG 不完整的问题。此外，我们设计了一个自学习框架，包括在线探索和离线迭代策略更新阶段，使代理能够自动合成推理轨迹并提高性能。实验结果表明，具有弱 LLM 主干的 SymAgent（即 7B 系列）与各种强大的基线相比，产生了更好或相当的性能。进一步的分析表明，我们的代理可以识别缺失的三元组，促进自动 KG 更新。</paragraph>

##### **Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**
2502.03032v2 by Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov

We introduce a new approach to systematically map features discovered by
sparse autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.

摘要：我們提出了一種新方法，用於系統性地繪製大型語言模型連續層中稀疏自動編碼器發現的功能，擴展了先前研究層間特徵連結的工作。透過使用無資料餘弦相似性技術，我們追蹤特定特徵在每個階段如何持續、轉換或首次出現。此方法產生了特徵演化的細粒度流程圖，實現了細粒度的可解釋性和對模型運算的機制見解。至關重要的是，我們展示了這些跨層特徵圖如何透過放大或抑制所選特徵來促進模型行為的直接引導，在文字生成中實現目標主題控制。我們的研究結果共同突出了因果、跨層可解釋性框架的效用，不僅闡明了特徵如何透過前向傳遞發展，還提供了新的方法來透明地操作大型語言模型。

##### **A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**
2502.02896v1 by Bradley P. Allen, Paul T. Groth

Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

摘要：評估大型語言模型 (LLM) 執行知識圖譜建構支援事實萃取等任務時，通常會使用基於知識圖譜 (KG) 的基準事實計算準確度指標。這些評估假設錯誤代表事實上的分歧。然而，人類話語經常出現元語言分歧，其中代理人之間的差異不在於事實，而在於用於表達事實的語言的含義。鑑於使用 LLM 處理和產生自然語言的複雜性，我們提出疑問：LLM 和 KG 之間是否會發生元語言分歧？根據使用 T-REx 知識比對資料集進行的調查，我們假設元語言分歧確實會發生在 LLM 和 KG 之間，並可能與知識圖譜工程實務有關。我們提出一個基準，用於評估 LLM 和 KG 之間的事實和元語言分歧的偵測。此基準的初步概念驗證可在 Github 上取得。

##### **Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**
2502.02810v1 by Chanhui Lee, Yuheon Song, YongJun Jeong, Hanbum Ko, Rodrigo Hormazabal, Sehui Han, Kyunghoon Bae, Sungbin Lim, Sungwoong Kim

Recent advances in Large Language Models (LLMs) have motivated the
development of general LLMs for molecular tasks. While several studies have
demonstrated that fine-tuned LLMs can achieve impressive benchmark
performances, they are far from genuine generalist molecular LLMs due to a lack
of fundamental understanding of molecular structure. Specifically, when given
molecular task instructions, LLMs trained with naive next-token prediction
training assign similar likelihood scores to both original and negatively
corrupted molecules, revealing their lack of molecular structure understanding
that is crucial for reliable and general molecular LLMs. To overcome this
limitation and obtain a true generalist molecular LLM, we introduce a novel
multi-modal training method based on a thorough multi-modal instruction tuning
as well as a molecular structure preference optimization between chosen and
rejected graphs. On various molecular benchmarks, the proposed generalist
molecular LLM, called Mol-LLM, achieves state-of-the-art performances among
generalist LLMs on most tasks, at the same time, surpassing or comparable to
state-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior
generalization performances in reaction prediction tasks, demonstrating the
effect of the molecular structure understanding for generalization perspective.

摘要：大型語言模型 (LLM) 的近期進展激勵了針對分子任務開發通用 LLM。雖然多項研究已證明微調 LLM 可實現令人印象深刻的基準效能，但由於缺乏對分子結構的基本理解，它們遠非真正的通才分子 LLM。具體來說，當給予分子任務說明時，使用天真的下一個符號預測訓練訓練的 LLM 會將類似的可能性評分分配給原始分子和負面損壞分子，這顯示出它們缺乏對分子結構的理解，而這對於可靠且通用的分子 LLM 至關重要。為了克服這個限制並獲得真正的通才分子 LLM，我們引入了一種新穎的多模態訓練方法，該方法基於徹底的多模態說明調整以及在所選和拒絕圖形之間的分子結構偏好最佳化。在各種分子基準測試中，所提出的通才分子 LLM（稱為 Mol-LLM）在多數任務中實現了通才 LLM 中的最新效能，同時超越或與最新的專家 LLM 相當。此外，Mol-LLM 在反應預測任務中也展現出優異的泛化效能，證明了分子結構理解對泛化觀點的影響。

##### **Leveraging the true depth of LLMs**
2502.02790v1 by Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

Large Language Models demonstrate remarkable capabilities at the cost of high
compute requirements. While recent research has shown that intermediate layers
can be removed or have their order shuffled without impacting performance
significantly, these findings have not been employed to reduce the
computational cost of inference. We investigate several potential ways to
reduce the depth of pre-trained LLMs without significantly affecting
performance. Leveraging our insights, we present a novel approach that exploits
this decoupling between layers by grouping some of them into pairs that can be
evaluated in parallel.
  This modification of the computational graph -- through better parallelism --
results in an average improvement of around 1.20x on the number of tokens
generated per second, without re-training nor fine-tuning, while retaining
95%-99% of the original accuracy. Empirical evaluation demonstrates that this
approach significantly improves serving efficiency while maintaining model
performance, offering a practical improvement for large-scale LLM deployment.

摘要：大型语言模型展示了其强大的功能，但代价是较高的计算需求。虽然最近的研究表明，中间层可以被移除或重新排列其顺序，而不会显著影响性能，但这些发现尚未被用来降低推理的计算成本。我们研究了几种潜在的方法来减少预训练 LLM 的深度，而不会显著影响性能。利用我们的见解，我们提出了一种新颖的方法，该方法通过将其中一些分组为可以并行评估的成对来利用层之间的这种解耦。
通过更好的并行性对计算图进行修改，平均而言，每秒生成的令牌数量提高了约 1.20 倍，而无需重新训练或微调，同时保留了 95%-99% 的原始准确性。经验评估表明，这种方法显著提高了服务效率，同时保持了模型性能，为大规模 LLM 部署提供了实际改进。

##### **Modular Training of Neural Networks aids Interpretability**
2502.02470v2 by Satvik Golechha, Maheep Chaudhary, Joan Velja, Alessandro Abate, Nandi Schoots

An approach to improve neural network interpretability is via clusterability,
i.e., splitting a model into disjoint clusters that can be studied
independently. We define a measure for clusterability and show that pre-trained
models form highly enmeshed clusters via spectral graph clustering. We thus
train models to be more modular using a "clusterability loss" function that
encourages the formation of non-interacting clusters. Using automated
interpretability techniques, we show that our method can help train models that
are more modular and learn different, disjoint, and smaller circuits. We
investigate CNNs trained on MNIST and CIFAR, small transformers trained on
modular addition, and language models. Our approach provides a promising
direction for training neural networks that learn simpler functions and are
easier to interpret.

摘要：一種改善神經網路可解釋性的方法是透過群集性，
也就是將模型分割成可獨立研究的不相交群集。我們定義一個群集性的度量，並顯示預訓練的
模型透過光譜圖形群集形成高度糾纏的群集。因此，我們使用「群集性損失」函數訓練模型，使其更具模組化，
這鼓勵形成非交互群集。使用自動化可解釋性技術，我們顯示我們的模型可以幫助訓練更具模組化的模型，並學習不同、不相交且較小的電路。我們
研究了在 MNIST 和 CIFAR 上訓練的 CNN，在模組化加法上訓練的小型Transformer，以及語言模型。我們的做法為訓練學習更簡單函數且更容易解釋的神經網路提供了有希望的方向。

##### **Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**
2502.02362v3 by Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-Tür

Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large
language models (LLMs) by enabling detailed step-by-step solutions. However,
due to the verbosity of LLMs, the resulting reasoning chains can be long,
making it harder to verify the reasoning steps and trace issues resulting from
dependencies between the steps that may be farther away in the sequence of
steps. Importantly, mathematical reasoning allows each step to be derived from
a small set of premises, which are a subset of the preceding steps in the
reasoning chain. In this paper, we present a framework that identifies the
premises for each step, to improve the evaluation of reasoning. We restructure
conventional linear reasoning chains into Premise Augmented Reasoning Chains
(PARC) by introducing premise links, resulting in a directed acyclic graph
where the nodes are the steps and the edges are the premise links. Through
experiments with a PARC-based dataset that we built, namely PERL (Premises and
ERrors identification in LLMs), we demonstrate that LLMs can reliably identify
premises within complex reasoning chains. In particular, even open-source LLMs
achieve 90% recall in premise identification. We also show that PARC helps to
identify errors in reasoning chains more reliably. The accuracy of error
identification improves by 6% to 16% absolute when step-by-step verification is
carried out in PARC under the premises. Our findings highlight the utility of
premise-centric representations in addressing complex problem-solving tasks and
open new avenues for improving the reliability of LLM-based reasoning
evaluations.

摘要：<paragraph>思考鏈（CoT）提示透過提供詳細的逐步解法，增強大型語言模型（LLM）的數學推理能力。然而，由於 LLM 的冗長，產生的推理鏈可能很長，這使得驗證推理步驟和追蹤由步驟之間相依關係所產生的問題變得更加困難，而這些步驟可能在步驟順序中相距較遠。重要的是，數學推理允許每個步驟從一組小的前提中推導出來，這些前提是推理鏈中前一個步驟的子集。在本文中，我們提出了一個框架，用於識別每個步驟的前提，以改進推理評估。我們透過引入前提連結，將傳統的線性推理鏈重組為前提擴充推理鏈（PARC），產生一個有向無環圖，其中節點是步驟，而邊緣是前提連結。透過我們建立的基於 PARC 的資料集（即 PERL（LLM 中的前提和錯誤識別））進行的實驗，我們證明 LLM 能夠在複雜的推理鏈中可靠地識別前提。特別是，即使是開源 LLM 在前提識別中也能達到 90% 的召回率。我們還表明，PARC 有助於更可靠地識別推理鏈中的錯誤。在前提下於 PARC 中執行逐步驗證時，錯誤識別的準確度提高了 6% 到 16%。我們的研究結果突顯了以前提為中心的表示在解決複雜問題解決任務中的效用，並為改進基於 LLM 的推理評估的可靠性開闢了新途徑。</paragraph>

##### **AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**
2502.02067v1 by Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna

Embodied agents assisting humans are often asked to complete a new task in a
new scenario. An agent preparing a particular dish in the kitchen based on a
known recipe may be asked to prepare a new dish or to perform cleaning tasks in
the storeroom. There may not be sufficient resources, e.g., time or labeled
examples, to train the agent for these new situations. Large Language Models
(LLMs) trained on considerable knowledge across many domains are able to
predict a sequence of abstract actions for such new tasks and scenarios,
although it may not be possible for the agent to execute this action sequence
due to task-, agent-, or domain-specific constraints. Our framework addresses
these challenges by leveraging the generic predictions provided by LLM and the
prior domain-specific knowledge encoded in a Knowledge Graph (KG), enabling an
agent to quickly adapt to new tasks and scenarios. The robot also solicits and
uses human input as needed to refine its existing knowledge. Based on
experimental evaluation over cooking and cleaning tasks in simulation domains,
we demonstrate that the interplay between LLM, KG, and human input leads to
substantial performance gains compared with just using the LLM output.

摘要：具身代理协助人类时，通常需要在新的情境中完成新的任务。基于已知食谱在厨房准备特定菜肴的代理可能会被要求准备新菜肴或在储藏室执行清洁任务。可能没有足够资源（例如时间或标记的示例）来训练代理以应对这些新情况。在许多领域接受大量知识训练的大型语言模型 (LLM) 能够预测此类新任务和情境的抽象动作序列，尽管代理可能无法执行此动作序列，因为任务、代理或特定于域的约束。我们的框架通过利用 LLM 提供的通用预测和知识图 (KG) 中编码的先前特定于域的知识来应对这些挑战，使代理能够快速适应新任务和情境。该机器人还会根据需要征求并使用人类输入来完善其现有知识。基于在模拟域中对烹饪和清洁任务的实验评估，我们证明了 LLM、KG 和人类输入之间的相互作用与仅使用 LLM 输出相比带来了巨大的性能提升。

##### **On Bob Dylan: A Computational Perspective**
2502.01772v1 by Prashant Garg

Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style
-- a constant refusal to conform to expectation and a penchant for reinventing
his musical and lyrical identity. In this paper, I extend Sunstein's
observations through a large-scale computational analysis of Dylan's lyrics
from 1962 to 2012. Using o3-mini-high (a large language model), I extract
concept-to-concept relationships from the lyrics and construct directed
knowledge graphs that capture Dylan's thematic structure. I then quantify
shifts in sentiment, metaphorical expression, thematic diversity, and network
complexity over time. The results indicate that Dylan's lyrics increasingly
rely on metaphor, display an evolving sentiment profile, and exhibit heightened
dishabituation -- measured here as a growing variance in the network centrality
of key concepts. I also find that references to movement, protest, and mythic
imagery fluctuate in ways that align with well-known phases of Dylan's career,
reflecting the dynamic and unpredictable quality of his art. These findings not
only deepen our empirical understanding of Sunstein's thesis but also introduce
a novel computational method for analyzing an artist's evolution-offering
broader applicability to the study of cultural and creative change.

摘要：卡斯·桑斯坦的論文「論鮑伯·迪倫」描述了迪倫「去習慣化」的風格
-- 這種風格不斷拒絕符合預期，並熱衷於重新塑造他的音樂和歌詞認同。在本文中，我透過對迪倫 1962 年至 2012 年歌詞進行大規模的運算分析，來延伸桑斯坦的觀察。使用 o3-mini-high（一個大型語言模型），我從歌詞中提取概念對概念的關係，並建構有向知識圖，以捕捉迪倫的主題結構。然後，我量化情緒、隱喻表達、主題多樣性和網路複雜性隨時間的變化。結果顯示，迪倫的歌詞越來越依賴隱喻，展現出不斷演化的情緒輪廓，並表現出高度的去習慣化 -- 在這裡測量為關鍵概念的網路中心性的變異增加。我也發現，對運動、抗議和神話意象的引用，會以與迪倫職業生涯中眾所周知階段一致的方式波動，反映了他藝術的動態和不可預測的品質。這些發現不僅加深了我們對桑斯坦論文的經驗理解，也引入了分析藝術家演變的新穎運算方法，為文化和創造性變化的研究提供了更廣泛的適用性。

##### **VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**
2502.01549v1 by Xubin Ren, Lingrui Xu, Long Xia, Shuaiqiang Wang, Dawei Yin, Chao Huang

Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in
enhancing Large Language Models (LLMs) through external knowledge integration,
yet its application has primarily focused on textual content, leaving the rich
domain of multi-modal video knowledge predominantly unexplored. This paper
introduces VideoRAG, the first retrieval-augmented generation framework
specifically designed for processing and understanding extremely long-context
videos. Our core innovation lies in its dual-channel architecture that
seamlessly integrates (i) graph-based textual knowledge grounding for capturing
cross-video semantic relationships, and (ii) multi-modal context encoding for
efficiently preserving visual features. This novel design empowers VideoRAG to
process unlimited-length videos by constructing precise knowledge graphs that
span multiple videos while maintaining semantic dependencies through
specialized multi-modal retrieval paradigms. Through comprehensive empirical
evaluation on our proposed LongerVideos benchmark-comprising over 160 videos
totaling 134+ hours across lecture, documentary, and entertainment
categories-VideoRAG demonstrates substantial performance compared to existing
RAG alternatives and long video understanding methods. The source code of
VideoRAG implementation and the benchmark dataset are openly available at:
https://github.com/HKUDS/VideoRAG.

摘要：檢索增強生成 (RAG) 已證明在透過外部知識整合增強大型語言模型 (LLM) 方面取得顯著成功，但其應用主要集中在文字內容上，而豐富的多模態影片知識領域則鮮少被探索。本文介紹 VideoRAG，這是第一個檢索增強生成架構，專門設計用於處理和理解極長語境的影片。我們的核心創新在於其雙通道架構，它無縫整合 (i) 基於圖形文字知識基礎，用於擷取跨影片語義關係，以及 (ii) 多模態語境編碼，用於有效保留視覺特徵。這個新穎的設計讓 VideoRAG 能夠透過建構跨越多個影片的精確知識圖譜來處理長度不限的影片，同時透過專門的多模態檢索範例來維持語義依賴性。透過我們提出的 LongerVideos 基準的全面經驗評估，該基準包含超過 160 部影片，總時數超過 134 小時，涵蓋演講、紀錄片和娛樂類別，VideoRAG 與現有的 RAG 替代方案和長影片理解方法相比，展現出顯著的效能。VideoRAG 實作的原始碼和基準資料集已公開於：https://github.com/HKUDS/VideoRAG。

##### **Transformers trained on proteins can learn to attend to Euclidean distance**
2502.01533v1 by Isaac Ellmen, Constantin Schneider, Matthew I. J. Raybould, Charlotte M. Deane

While conventional Transformers generally operate on sequence data, they can
be used in conjunction with structure models, typically SE(3)-invariant or
equivariant graph neural networks (GNNs), for 3D applications such as protein
structure modelling. These hybrids typically involve either (1)
preprocessing/tokenizing structural features as input for Transformers or (2)
taking Transformer embeddings and processing them within a structural
representation. However, there is evidence that Transformers can learn to
process structural information on their own, such as the AlphaFold3 structural
diffusion model. In this work we show that Transformers can function
independently as structure models when passed linear embeddings of coordinates.
We first provide a theoretical explanation for how Transformers can learn to
filter attention as a 3D Gaussian with learned variance. We then validate this
theory using both simulated 3D points and in the context of masked token
prediction for proteins. Finally, we show that pre-training protein Transformer
encoders with structure improves performance on a downstream task, yielding
better performance than custom structural models. Together, this work provides
a basis for using standard Transformers as hybrid structure-language models.

摘要：雖然傳統的 Transformer 通常處理序列資料，但它們可用於結構模型，通常是 SE(3) 不變式或等變式圖神經網路 (GNN)，用於蛋白質結構建模等 3D 應用。這些混合模型通常包含 (1) 將結構特徵預處理/標記化為 Transformer 的輸入或 (2) 取用 Transformer 嵌入並在結構表示中處理它們。然而，有證據表明 Transformer 可以自行學習處理結構資訊，例如 AlphaFold3 結構擴散模型。在這項工作中，我們展示了 Transformer 在傳遞座標的線性嵌入時，可以獨立作為結構模型運作。我們首先提供了 Transformer 如何學習將注意力濾波為具有學習變異的 3D 高斯的理論解釋。然後我們使用模擬 3D 點和在蛋白質遮罩標記預測的背景下驗證此理論。最後，我們展示了使用結構預訓練蛋白質 Transformer 編碼器會改善下游任務的效能，產生比自訂結構模型更好的效能。綜合來說，這項工作提供了使用標準 Transformer 作為混合結構語言模型的基礎。

##### **Common Foundations for SHACL, ShEx, and PG-Schema**
2502.01295v1 by S. Ahmetaj, I. Boneva, J. Hidders, K. Hose, M. Jakubowski, J. E. Labra-Gayo, W. Martens, F. Mogavero, F. Murlak, C. Okulmus, A. Polleres, O. Savkovic, M. Simkus, D. Tomaszuk

Graphs have emerged as an important foundation for a variety of applications,
including capturing and reasoning over factual knowledge, semantic data
integration, social networks, and providing factual knowledge for machine
learning algorithms. To formalise certain properties of the data and to ensure
data quality, there is a need to describe the schema of such graphs. Because of
the breadth of applications and availability of different data models, such as
RDF and property graphs, both the Semantic Web and the database community have
independently developed graph schema languages: SHACL, ShEx, and PG-Schema.
Each language has its unique approach to defining constraints and validating
graph data, leaving potential users in the dark about their commonalities and
differences. In this paper, we provide formal, concise definitions of the core
components of each of these schema languages. We employ a uniform framework to
facilitate a comprehensive comparison between the languages and identify a
common set of functionalities, shedding light on both overlapping and
distinctive features of the three languages.

摘要：圖表已成為各種應用的重要基礎，包括擷取和推理事實知識、語義資料整合、社群網路，以及為機器學習演算法提供事實知識。為了形式化資料的特定屬性並確保資料品質，有必要描述此類圖表的架構。由於應用範圍廣泛且有不同的資料模型可用，例如 RDF 和屬性圖表，因此語義網路和資料庫社群已獨立開發圖表架構語言：SHACL、ShEx 和 PG-Schema。每種語言都有其定義約束和驗證圖表資料的獨特方法，讓潛在使用者不清楚它們的共性和差異。在本文中，我們提供這些架構語言中每個核心元件的正式簡潔定義。我們採用統一的框架來促進語言之間的全面比較，並找出功能的共同集合，說明這三種語言的重疊和獨特功能。

##### **GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**
2502.01113v1 by Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, Shirui Pan

Retrieval-augmented generation (RAG) has proven effective in integrating
knowledge into large language models (LLMs). However, conventional RAGs
struggle to capture complex relationships between pieces of knowledge, limiting
their performance in intricate reasoning that requires integrating knowledge
from multiple sources. Recently, graph-enhanced retrieval augmented generation
(GraphRAG) builds graph structure to explicitly model these relationships,
enabling more effective and efficient retrievers. Nevertheless, its performance
is still hindered by the noise and incompleteness within the graph structure.
To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for
retrieval augmented generation. GFM-RAG is powered by an innovative graph
neural network that reasons over graph structure to capture complex
query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage
training process on large-scale datasets, comprising 60 knowledge graphs with
over 14M triples and 700k documents. This results in impressive performance and
generalizability for GFM-RAG, making it the first graph foundation model
applicable to unseen datasets for retrieval without any fine-tuning required.
Extensive experiments on three multi-hop QA datasets and seven domain-specific
RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance
while maintaining efficiency and alignment with neural scaling laws,
highlighting its potential for further improvement.

摘要：檢索增強生成 (RAG) 已證明在整合知識到大語言模型 (LLM) 中有效。然而，傳統的 RAG 難以捕捉知識片段之間的複雜關係，限制了它們在需要整合來自多個來源的知識的複雜推理中的表現。最近，圖表增強檢索增強生成 (GraphRAG) 建立圖表結構來明確建模這些關係，從而實現更有效率的檢索器。儘管如此，其效能仍受到圖表結構中雜訊和不完整性的阻礙。為了解決這個問題，我們引入了 GFM-RAG，一種用於檢索增強生成的全新圖表基礎模型 (GFM)。GFM-RAG 由一個創新的圖神經網路驅動，該網路在圖表結構上進行推理以捕捉複雜的查詢知識關係。具有 8M 參數的 GFM 在大型資料集上進行兩階段訓練流程，包括 60 個包含超過 14M 個三元組和 700k 個文件的文件。這為 GFM-RAG 帶來了令人印象深刻的效能和通用性，使其成為第一個適用於未見過資料集的圖表基礎模型，而無需任何微調。在三個多跳問答資料集和七個特定領域 RAG 資料集上的廣泛實驗表明，GFM-RAG 達到了最先進的效能，同時保持了效率並與神經擴充定律保持一致，突顯了其進一步改進的潛力。

##### **Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**
2502.01059v1 by Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, Tae In Ahn

The development of biological data analysis tools and large language models
(LLMs) has opened up new possibilities for utilizing AI in plant science
research, with the potential to contribute significantly to knowledge
integration and research gap identification. Nonetheless, current LLMs struggle
to handle complex biological data and theoretical models in photosynthesis
research and often fail to provide accurate scientific contexts. Therefore,
this study proposed a photosynthesis research assistant (PRAG) based on
OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt
optimization. Vector databases and an automated feedback loop were used in the
prompt optimization process to enhance the accuracy and relevance of the
responses to photosynthesis-related queries. PRAG showed an average improvement
of 8.7% across five metrics related to scientific writing, with a 25.4%
increase in source transparency. Additionally, its scientific depth and domain
coverage were comparable to those of photosynthesis research papers. A
knowledge graph was used to structure PRAG's responses with papers within and
outside the database, which allowed PRAG to match key entities with 63% and
39.5% of the database and test papers, respectively. PRAG can be applied for
photosynthesis research and broader plant science domains, paving the way for
more in-depth data analysis and predictive capabilities.

摘要：生物資料分析工具和大型語言模型 (LLM) 的發展，為利用人工智慧於植物科學研究開啟了新的可能性，並有潛力對知識整合和研究差距的識別做出重大貢獻。儘管如此，目前的 LLM 在處理光合作用研究中的複雜生物資料和理論模型時仍有困難，而且常常無法提供準確的科學背景。因此，本研究提出了一個基於 OpenAI 的 GPT-4o、具備檢索增強生成 (RAG) 技術和提示最佳化的光合作用研究助理 (PRAG)。在提示最佳化過程中，使用了向量資料庫和自動回饋迴路，以增強對與光合作用相關查詢的回應的準確性和相關性。PRAG 在與科學寫作相關的五項指標中顯示出平均改善了 8.7%，來源透明度增加了 25.4%。此外，其科學深度和領域涵蓋範圍與光合作用研究論文相當。知識圖譜用於建構 PRAG 的回應，其中包含資料庫內外論文，這使得 PRAG 能夠分別與資料庫和測試論文中的 63% 和 39.5% 的關鍵實體相匹配。PRAG 可應用於光合作用研究和更廣泛的植物科學領域，為更深入的資料分析和預測能力鋪路。

##### **Encrypted Large Model Inference: The Equivariant Encryption Paradigm**
2502.01013v1 by James Buban, Hongyang Zhang, Claudio Angione, Harry Yang, Ahmad Farhan, Seyfal Sultanov, Michael Du, Xuran Ma, Zihao Wang, Yue Zhao, Arria Owlia, Fielding Johnston, Patrick Colangelo

Large scale deep learning model, such as modern language models and diffusion
architectures, have revolutionized applications ranging from natural language
processing to computer vision. However, their deployment in distributed or
decentralized environments raises significant privacy concerns, as sensitive
data may be exposed during inference. Traditional techniques like secure
multi-party computation, homomorphic encryption, and differential privacy offer
partial remedies but often incur substantial computational overhead, latency
penalties, or limited compatibility with non-linear network operations. In this
work, we introduce Equivariant Encryption (EE), a novel paradigm designed to
enable secure, "blind" inference on encrypted data with near zero performance
overhead. Unlike fully homomorphic approaches that encrypt the entire
computational graph, EE selectively obfuscates critical internal
representations within neural network layers while preserving the exact
functionality of both linear and a prescribed set of non-linear operations.
This targeted encryption ensures that raw inputs, intermediate activations, and
outputs remain confidential, even when processed on untrusted infrastructure.
We detail the theoretical foundations of EE, compare its performance and
integration complexity against conventional privacy preserving techniques, and
demonstrate its applicability across a range of architectures, from
convolutional networks to large language models. Furthermore, our work provides
a comprehensive threat analysis, outlining potential attack vectors and
baseline strategies, and benchmarks EE against standard inference pipelines in
decentralized settings. The results confirm that EE maintains high fidelity and
throughput, effectively bridging the gap between robust data confidentiality
and the stringent efficiency requirements of modern, large scale model
inference.

摘要：大型深度學習模型，例如現代語言模型和擴散架構，徹底改變了從自然語言處理到電腦視覺等各種應用。然而，它們在分散式或分散式環境中的部署引發了重大的隱私問題，因為敏感數據可能會在推理過程中遭到揭露。安全多方計算、同態加密和差分隱私等傳統技術提供了部分補救措施，但通常會產生大量的計算開銷、延遲處罰，或與非線性網路操作相容性有限。在這項工作中，我們引入了等變加密 (EE)，這是一種新穎的範例，旨在以接近零效能開銷對加密數據進行安全、「盲目」推理。與加密整個計算圖形的完全同態方法不同，EE 有選擇性地混淆神經網路層內的關鍵內部表示，同時保留線性和規定的一組非線性操作的精確功能。這種有針對性的加密確保了原始輸入、中間激活和輸出保持機密，即使在不受信任的基礎設施上處理也是如此。我們詳細說明了 EE 的理論基礎，比較了其效能和整合複雜度與傳統的隱私保護技術，並展示了其在從卷積網路到大語言模型等各種架構中的適用性。此外，我們的研究提供了全面的威脅分析，概述了潛在的攻擊媒介和基準策略，並在分散式設定中將 EE 與標準推理管道進行比較。結果證實，EE 保持了高保真度和高傳輸量，有效地彌合了強大的數據機密性與現代化、大規模模型推理的嚴格效率要求之間的差距。

##### **Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**
2502.01694v1 by Juno Kim, Denny Wu, Jason Lee, Taiji Suzuki

A key paradigm to improve the reasoning capabilities of large language models
(LLMs) is to allocate more inference-time compute to search against a verifier
or reward model. This process can then be utilized to refine the pretrained
model or distill its reasoning patterns into more efficient models. In this
paper, we study inference-time compute by viewing chain-of-thought (CoT)
generation as a metastable Markov process: easy reasoning steps (e.g.,
algebraic manipulations) form densely connected clusters, while hard reasoning
steps (e.g., applying a relevant theorem) create sparse, low-probability edges
between clusters, leading to phase transitions at longer timescales. Under this
framework, we prove that implementing a search protocol that rewards sparse
edges improves CoT by decreasing the expected number of steps to reach
different clusters. In contrast, we establish a limit on reasoning capability
when the model is restricted to local information of the pretrained graph. We
also show that the information gained by search can be utilized to obtain a
better reasoning model: (1) the pretrained model can be directly finetuned to
favor sparse edges via policy gradient methods, and moreover (2) a compressed
metastable representation of the reasoning dynamics can be distilled into a
smaller, more efficient model.

摘要：<paragraph>提升大型語言模型 (LLM) 推理能力的一個關鍵範例，是分配更多推論時間運算來搜尋驗證器或獎勵模型。此程序接著可用於改善預訓練模型或將其推理模式提煉到更有效率的模型中。在這篇論文中，我們透過將思維鏈 (CoT) 生成視為亞穩態馬可夫過程來研究推論時間運算：簡單的推理步驟（例如代數運算）形成密集連接的叢集，而困難的推理步驟（例如應用相關定理）則在叢集之間建立稀疏、低機率的邊緣，導致在較長時間尺度上產生相變。在此架構下，我們證明實作一種獎勵稀疏邊緣的搜尋協定，會透過減少到達不同叢集所需的預期步驟數來改善 CoT。相反地，當模型受限於預訓練圖形的局部資訊時，我們建立了推理能力的限制。我們也顯示搜尋所獲得的資訊可用於取得更好的推理模型：(1) 預訓練模型可以直接微調以透過策略梯度方法偏好稀疏邊緣，而且 (2) 推理動態的壓縮亞穩態表徵可以提煉到更小、更有效率的模型中。</paragraph>

##### **PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**
2502.00708v1 by Qixuan Li, Chao Wang, Zongjin He, Yan Peng

Text-to-3D asset generation has achieved significant optimization under the
supervision of 2D diffusion priors. However, when dealing with compositional
scenes, existing methods encounter several challenges: 1). failure to ensure
that composite scene layouts comply with physical laws; 2). difficulty in
accurately capturing the assets and relationships described in complex scene
descriptions; 3). limited autonomous asset generation capabilities among layout
approaches leveraging large language models (LLMs). To avoid these compromises,
we propose a novel framework for compositional scene generation, PhiP-G, which
seamlessly integrates generation techniques with layout guidance based on a
world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene
description to generate a scene graph, and integrating a multimodal 2D
generation agent and a 3D Gaussian generation method for targeted assets
creation. For the stage of layout, PhiP-G employs a physical pool with adhesion
capabilities and a visual supervision agent, forming a world model for layout
prediction and planning. Extensive experiments demonstrate that PhiP-G
significantly enhances the generation quality and physical rationality of the
compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)
performance in CLIP scores, achieves parity with the leading methods in
generation quality as measured by the T$^3$Bench, and improves efficiency by
24x.

摘要：<paragraph>在 2D 擴散先驗的監督下，文字轉 3D 資產生成已取得顯著的最佳化。然而，在處理合成場景時，現有方法會遇到幾個挑戰：1) 無法確保複合場景佈局符合物理定律；2) 難以準確捕捉複雜場景描述中所描述的資產和關係；3) 在利用大型語言模型 (LLM) 的佈局方法中，自主資產生成能力有限。為了避免這些折衷，我們提出了一個合成場景生成的新框架 PhiP-G，它將生成技術與基於世界模型的佈局指導無縫整合。利用基於 LLM 的代理，PhiP-G 分析複雜的場景描述以生成場景圖，並整合多模態 2D 生成代理和 3D 高斯生成方法以進行目標資產創建。對於佈局階段，PhiP-G 採用具有附著能力的物理池和視覺監督代理，形成用於佈局預測和規劃的世界模型。大量的實驗證明，PhiP-G 大幅提升了合成場景的生成品質和物理合理性。值得注意的是，PhiP-G 在 CLIP 分數中獲得了最先進 (SOTA) 的效能，在 T$^3$Bench 測量的生成品質中與領先的方法達到同等水準，並將效率提升了 24 倍。</paragraph>

##### **A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**
2502.00681v1 by Qika Lin, Zhen Peng, Kaize Shi, Kai He, Yiming Xu, Erik Cambria, Mengling Feng

Recent years have witnessed rapid advances in graph representation learning,
with the continuous embedding approach emerging as the dominant paradigm.
However, such methods encounter issues regarding parameter efficiency,
interpretability, and robustness. Thus, Quantized Graph Representation (QGR)
learning has recently gained increasing interest, which represents the graph
structure with discrete codes instead of conventional continuous embeddings.
Given its analogous representation form to natural language, QGR also possesses
the capability to seamlessly integrate graph structures with large language
models (LLMs). As this emerging paradigm is still in its infancy yet holds
significant promise, we undertake this thorough survey to promote its rapid
future prosperity. We first present the background of the general quantization
methods and their merits. Moreover, we provide an in-depth demonstration of
current QGR studies from the perspectives of quantized strategies, training
objectives, distinctive designs, knowledge graph quantization, and
applications. We further explore the strategies for code dependence learning
and integration with LLMs. At last, we give discussions and conclude future
directions, aiming to provide a comprehensive picture of QGR and inspire future
research.

摘要：近年来，图表示学习取得了快速进展，其中连续嵌入方法作为主导范式出现。然而，此类方法遇到了参数效率、可解释性和鲁棒性方面的问题。因此，量化图表示 (QGR) 学习最近引起了越来越多的兴趣，它使用离散代码而不是传统的连续嵌入来表示图结构。鉴于其与自然语言类似的表示形式，QGR 也具备将图结构与大型语言模型 (LLM) 无缝集成的能力。由于这种新兴范式仍处于起步阶段，但前景广阔，我们进行了这项全面调查以促进其快速未来的繁荣。我们首先介绍了通用量化方法的背景及其优点。此外，我们从量化策略、训练目标、独特设计、知识图谱量化和应用的角度对当前的 QGR 研究进行了深入的论证。我们进一步探索了代码依赖性学习和与 LLM 集成的策略。最后，我们给出了讨论并总结了未来的方向，旨在提供 QGR 的全面图景并激发未来的研究。

##### **Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**
2502.00339v1 by Jingyuan Yi, Zeqiu Xu, Tianyi Huang, Peiyang Yu

The pervasiveness of the dissemination of fake news through social media
platforms poses critical risks to the trust of the general public, societal
stability, and democratic institutions. This challenge calls for novel
methodologies in detection, which can keep pace with the dynamic and
multi-modal nature of misinformation. Recent works include powering the
detection using large language model advances in multimodal frameworks,
methodologies using graphs, and adversarial training in the literature of fake
news. Based on the different approaches which can bring success, some key
highlights will be underlined: enhanced LLM-improves accuracy through more
advanced semantics and cross-modality fusion for robust detections. The review
further identifies critical gaps in adaptability to dynamic social media
trends, real-time, and cross-platform detection capabilities, as well as the
ethical challenges thrown up by the misuse of LLMs. Future directions underline
the development of style-agnostic models, cross-lingual detection frameworks,
and robust policies with a view to mitigating LLM-driven misinformation. This
synthesis thus lays a concrete foundation for those researchers and
practitioners committed to reinforcing fake news detection systems with
complications that keep on growing in the digital landscape.

摘要：社群媒體平台上假新聞散播的普遍性對一般大眾的信任、社會穩定性與民主制度構成重大風險。這項挑戰需要在偵測方面採用創新的方法論，才能跟上錯誤資訊的動態和多模態特性。最近的研究包括使用多模態架構中大型語言模型的進展、使用圖形的方法論，以及在假新聞文獻中進行對抗訓練來強化偵測。根據可以帶來成功的不同方法，將重點說明一些重點：增強的 LLM 可透過更進階的語意和跨模態融合來提升準確度，以進行穩健的偵測。這篇評論進一步找出在適應動態社群媒體趨勢、即時和跨平台偵測能力方面的重大差距，以及 LLM 遭濫用的道德挑戰。未來的方向強調開發與風格無關的模型、跨語言偵測架構和穩健的政策，以減輕 LLM 驅動的錯誤資訊。因此，這種綜合分析為那些致力於強化假新聞偵測系統的研究人員和從業人員奠定了具體的基礎，而這些複雜性在數位環境中持續增長。

##### **DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**
2502.00305v1 by Jiaxin Guo, C. L. Philip Chen, Shuzhen Li, Tong Zhang

Cold-start active learning (CSAL) selects valuable instances from an
unlabeled dataset for manual annotation. It provides high-quality data at a low
annotation cost for label-scarce text classification. However, existing CSAL
methods overlook weak classes and hard representative examples, resulting in
biased learning. To address these issues, this paper proposes a novel
dual-diversity enhancing and uncertainty-aware (DEUCE) framework for CSAL.
Specifically, DEUCE leverages a pretrained language model (PLM) to efficiently
extract textual representations, class predictions, and predictive uncertainty.
Then, it constructs a Dual-Neighbor Graph (DNG) to combine information on both
textual diversity and class diversity, ensuring a balanced data distribution.
It further propagates uncertainty information via density-based clustering to
select hard representative instances. DEUCE performs well in selecting
class-balanced and hard representative data by dual-diversity and
informativeness. Experiments on six NLP datasets demonstrate the superiority
and efficiency of DEUCE.

摘要：冷啟動主動學習 (CSAL) 從未標記的資料集中選取有價值的實例進行手動標記。它以低標記成本提供高品質的資料，用於標籤稀少的文字分類。然而，現有的 CSAL 方法忽略了弱類別和難以代表的範例，導致有偏差的學習。為了解決這些問題，本文提出了一個新的雙重多樣性增強和不確定性感知 (DEUCE) 架構，用於 CSAL。具體來說，DEUCE 利用預訓練的語言模型 (PLM) 來有效地提取文字表徵、類別預測和預測不確定性。然後，它構建一個雙鄰居圖 (DNG) 來結合文字多樣性和類別多樣性的資訊，確保平衡的資料分佈。它進一步通過基於密度的聚類來傳播不確定性資訊，以選擇難以代表的實例。DEUCE 在通過雙重多樣性和資訊性選擇類別平衡和難以代表的資料方面表現良好。在六個 NLP 資料集上的實驗證明了 DEUCE 的優越性和效率。

##### **Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**
2502.01659v2 by Nathaniel Tomczak, Sanmukh Kuppannagari

Transformers have demonstrated great success in numerous domains including
natural language processing and bioinformatics. This success stems from the use
of the attention mechanism by these models in order to represent and propagate
pairwise interactions between individual tokens of sequential data. However,
the primary limitation of this operation is its quadratic memory and time
complexity in relation to the input's context length - the length of a sequence
over which the interactions need to be captured. This significantly limits the
length of sequences that can be inferred upon by these models. Extensive
research has been conducted to reduce the number of pairwise interactions to
sub-quadratic in relation to the context length by introducing sparsity into
the attention mechanism through the development of sparse attention masks.
However, efficient implementations that achieve "true sparsity" are lacking.
  In this work, we address this issue by proposing a graph computing view of
attention where tokens are perceived as nodes of the graph and the attention
mask determines the edges of the graph. Using this view, we develop graph
processing algorithms to implement the attention mechanism. Both theoretically
and empirically, we demonstrate that our algorithms only perform the needed
computations, i.e., they are work optimal. We also perform extensive
experimentation using popular attention masks to explore the impact of sparsity
on execution time and achievable context length. Our experiments demonstrate
significant speedups in execution times compared to state-of-the-art attention
implementations such as FlashAttention for large sequence lengths. We also
demonstrate that our algorithms are able to achieve extremely long sequence
lengths of as high as 160 million on a single NVIDIA A100 GPU (SXM4 80GB).

摘要：變形金剛已在許多領域展現出巨大的成功，包括自然語言處理和生物資訊學。這種成功源自於這些模型使用注意機制來表示和傳播序列資料中各個標記之間成對的互動。然而，這種運算的主要限制在於其二次記憶體和時間複雜度與輸入的內容長度有關，也就是需要擷取互動的序列長度。這會顯著限制這些模型可以推論的序列長度。已經進行了大量的研究來減少成對互動的數量，使其與內容長度成次二次關係，方法是透過開發稀疏注意遮罩來將稀疏性引入注意機制。然而，缺乏能達成「真實稀疏性」的高效實作。在這項工作中，我們透過提出注意力的圖形運算檢視來解決這個問題，其中標記被視為圖形的節點，而注意力遮罩則決定圖形中的邊緣。使用這種檢視，我們開發了圖形處理演算法來實作注意力機制。我們在理論上和經驗上都證明了我們的演算法只執行必要的運算，也就是說，它們是工作最優的。我們也使用流行的注意力遮罩進行廣泛的實驗，以探討稀疏性對執行時間和可達成的內容長度的影響。我們的實驗證明，與最先進的注意力實作（例如 FlashAttention）相比，對於大型序列長度，我們的演算法在執行時間方面有顯著的加速。我們也證明了我們的演算法能夠在單一的 NVIDIA A100 GPU (SXM4 80GB) 上達成極長的序列長度，最高可達 1.6 億。

##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

摘要：<paragraph>為了彌合視覺和語言 (VL) 之間的語意差距，必須制定良好的對齊策略，其中包括處理語意多樣性、視覺資訊的抽象表示以及模型的泛化能力。最近的研究使用基於偵測器的邊界框或具有規則分割的區塊來表示視覺語意。雖然目前的範例已取得進展，但對於完全捕捉各種物件之間的細微脈絡關係仍不足夠。本文提出了一個全面的視覺語意表示模組，需要利用全景分割來產生連貫的細粒度語意特徵。此外，我們提出了一個新穎的圖形脈衝混合網路 (GSHN)，它整合了脈衝神經網路 (SNN) 和圖形注意力網路 (GAT) 的互補優勢來編碼視覺語意資訊。有趣的是，該模型不僅編碼實例的離散和連續潛在變數，還能巧妙地捕捉局部和全域脈絡特徵，從而顯著增強語意表示的豐富性和多樣性。利用 SNN 中固有的時空特性，我們採用對比學習 (CL) 來增強嵌入的基於相似性的表示。此策略減輕了模型的計算負擔，並透過建構正負樣本對來豐富有意義的視覺表示。我們設計了一個創新的預訓練方法，脈衝文本學習 (STL)，它使用文本特徵來提高離散語意的編碼能力。實驗表明，所提出的 GSHN 在多個 VL 下游任務上展現出有希望的結果。</paragraph>

##### **Semantic Web and Creative AI -- A Technical Report from ISWS 2023**
2501.18542v1 by Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin Böckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, Manoé Kieffer, Antonis Klironomos, Inês Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin Neubert, Emetis Niazmand, Ebrahim Norouzi, Beatriz Olarte Martinez, Anouk Michelle Oudshoorn, Andrea Poltronieri, Valentina Presutti, Disha Purohit, Ensiyeh Raoufi, Celian Ringwald, Johanna Rockstroh, Sebastian Rudolph, Harald Sack, Zafar Saeed, Mohammad Javad Saeedizade, Aya Sahbi, Cristian Santini, Aleksandra Simic, Dennis Sommer, Rita Sousa, Mary Ann Tan, Vidyashree Tarikere, Tabea Tietz, Liam Tirpitz, Arnaldo Tomasino, Frank van Harmelen, Joao Vissoci, Caitlin Woods, Bohui Zhang, Xinyue Zhang, Heng Zheng

The International Semantic Web Research School (ISWS) is a week-long
intensive program designed to immerse participants in the field. This document
reports a collaborative effort performed by ten teams of students, each guided
by a senior researcher as their mentor, attending ISWS 2023. Each team provided
a different perspective to the topic of creative AI, substantiated by a set of
research questions as the main subject of their investigation. The 2023 edition
of ISWS focuses on the intersection of Semantic Web technologies and Creative
AI. ISWS 2023 explored various intersections between Semantic Web technologies
and creative AI. A key area of focus was the potential of LLMs as support tools
for knowledge engineering. Participants also delved into the multifaceted
applications of LLMs, including legal aspects of creative content production,
humans in the loop, decentralised approaches to multimodal generative AI
models, nanopublications and AI for personal scientific knowledge graphs,
commonsense knowledge in automatic story and narrative completion, generative
AI for art critique, prompt engineering, automatic music composition,
commonsense prototyping and conceptual blending, and elicitation of tacit
knowledge. As Large Language Models and semantic technologies continue to
evolve, new exciting prospects are emerging: a future where the boundaries
between creative expression and factual knowledge become increasingly permeable
and porous, leading to a world of knowledge that is both informative and
inspiring.

摘要：國際語意網路研究學校 (ISWS) 是一個為期一週的密集課程，旨在讓參與者沉浸在該領域中。本文件報告了由十個學生團隊進行的合作成果，每個團隊都由一位資深研究員作為導師，參加了 2023 年 ISWS。每個團隊都從不同的角度探討了創意 AI 主題，並以一系列研究問題作為調查的主要主題。2023 年版的 ISWS 關注於語意網路技術和創意 AI 的交集。ISWS 2023 探索了語意網路技術和創意 AI 之間的各種交集。一個重點關注領域是 LLM 作為知識工程的支援工具的潛力。參與者還深入探討了 LLM 的多方面應用，包括創意內容製作的法律方面、循環中的人類、多模態生成式 AI 模型的分散式方法、納米出版物和用於個人科學知識圖譜的 AI、自動故事和敘述完成中的常識知識、生成式 AI 用於藝術評論、提示工程、自動音樂創作、常識原型和概念混合，以及對默會知識的引導。隨著大型語言模型和語意技術的持續發展，新的令人興奮的前景正在出現：一個創意表達和事實知識之間的界限變得越來越可滲透和多孔的未來，從而導致一個既有資訊性又有啟發性的知識世界。

##### **Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**
2501.18320v1 by Tianpeng Pan, Wenqiang Pu, Licheng Zhao, Rui Zhou

Automated optimization modeling (AOM) has evoked considerable interest with
the rapid evolution of large language models (LLMs). Existing approaches
predominantly rely on prompt engineering, utilizing meticulously designed
expert response chains or structured guidance. However, prompt-based techniques
have failed to perform well in the sensor array signal processing (SASP) area
due the lack of specific domain knowledge. To address this issue, we propose an
automated modeling approach based on retrieval-augmented generation (RAG)
technique, which consists of two principal components: a multi-agent (MA)
structure and a graph-based RAG (Graph-RAG) process. The MA structure is
tailored for the architectural AOM process, with each agent being designed
based on principles of human modeling procedure. The Graph-RAG process serves
to match user query with specific SASP modeling knowledge, thereby enhancing
the modeling result. Results on ten classical signal processing problems
demonstrate that the proposed approach (termed as MAG-RAG) outperforms several
AOM benchmarks.

摘要：自動化最佳化建模 (AOM) 隨著大型語言模型 (LLM) 的快速演進而引起相當大的興趣。現有方法主要依賴提示工程，利用精心設計的專家回應鏈或結構化指導。然而，基於提示的技術由於缺乏特定領域知識，無法在感測器陣列訊號處理 (SASP) 領域中表現良好。為了解決這個問題，我們提出一個基於檢索增強生成 (RAG) 技術的自動化建模方法，它包含兩個主要組成部分：多代理 (MA) 結構和基於圖形的 RAG (Graph-RAG) 程序。MA 結構是針對架構 AOM 程序量身打造，每個代理都是根據人類建模程序的原理設計的。Graph-RAG 程序用於將使用者查詢與特定的 SASP 建模知識相匹配，從而增強建模結果。在十個經典訊號處理問題上的結果表明，所提出的方法（稱為 MAG-RAG）優於多個 AOM 基準。

##### **Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**
2501.18154v1 by Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the quantized and
original weights. To enhance the quantization performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign quantization bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of quantization strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
quantization performance under low-bit conditions.

摘要：訓練後量化 (PTQ) 對於在資源受限的設定中部署大型語言模型 (LLM) 至關重要，因為它能顯著降低資源需求。然而，現有的 PTQ 策略在低位元層級 < 3 位元時表現不佳，因為量化後的權重與原始權重之間有顯著的差異。為了提升低位元寬度的量化效能，我們提出混合精度圖神經網路 PTQ (MG-PTQ) 方法，採用圖神經網路 (GNN) 模組來擷取權重之間的依存關係，並動態分配量化位元寬度。透過 GNN 模組的資訊傳播，我們的方法能更有效地擷取目標權重之間的依存關係，進而更準確地評估權重重要性，並最佳化量化策略的配置。在 WikiText2 和 C4 資料集上的廣泛實驗證明，我們的 MG-PTQ 方法優於先前的最先進 PTQ 方法 GPTQ，在低位元條件下設定了量化效能的新基準。

##### **Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**
2501.18119v1 by Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply quantized codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
quantized methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.

摘要：由於知識圖譜 (KG) 結構與自然語言之間存在自然差距，將 KG 的整體結構資訊與大型語言模型 (LLM) 有效整合已成為一個重要的問題。為此，我們提出了一個兩階段架構來學習和應用每個實體的量化碼，旨在將 KG 與 LLM 無縫整合。首先，提出了一個自監督量化表示 (SSQR) 方法，將 KG 結構和語義知識壓縮成離散碼（即，符號），以對齊語言句子的格式。我們進一步設計 KG 指令遵循資料，將這些學習到的碼視為直接輸入 LLM 的特徵，從而實現無縫整合。實驗結果表明，SSQR 優於現有的無監督量化方法，產生更具區別性的碼。此外，微調後的 LLaMA2 和 LLaMA3.1 在 KG 連結預測和三元分類任務上也具有優異的性能，每個實體僅使用 16 個符號，而不是傳統提示方法中的數千個。

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

摘要：回答需要對結構化（表格）和非結構化（原始文字）資料來源進行推理和彙總的問題會帶來重大挑戰。目前的辦法仰賴微調和高品質、人工整理的資料，而這很難取得。大型語言模型（LLM）的最新進展已針對零次學習設定的單一來源文字資料多跳問題回答（QA）展現出有希望的結果，但對多來源表格文字 QA 的探討仍然有限。在本文中，我們提出了一種新穎的基於混合圖表的表格文字 QA 方法，它利用 LLM 而無需微調。我們的辦法從文字和表格資料建構一個統一的混合圖表，根據輸入問題修剪資訊，以簡潔地為 LLM 提供相關脈絡。我們使用最先進的 LLM，包括 GPT-3.5、GPT-4 和 LLaMA-3，針對具有挑戰性的 Hybrid-QA 和 OTT-QA 資料集評估我們的辦法。我們的辦法在兩個資料集上都達到了最佳的零次學習效能，在 Hybrid-QA 上將完全比對分數提高了 10%，在 OTT-QA 上將完全比對分數提高了 5.4%。此外，與原始脈絡相比，我們的辦法將符號使用量減少了 53%。

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

摘要：圖形結構資料在許多領域中扮演著至關重要的角色，例如社交網路、引用網路、常識推理圖形和知識圖形。雖然圖形神經網路已用於圖形處理，但最近的進展已探討整合大型語言模型以進行基於圖形的任務。在本文中，我們提出了一種名為可學習圖形池化令牌 (LGPT) 的新方法，它解決了節點層級投影中的可擴充性問題和圖形層級投影中的資訊遺失限制。LGPT 透過引入可學習的參數（在大型語言模型中作為令牌運作）來啟用彈性和高效的圖形表示，平衡細粒度和整體圖形資訊。此外，我們研究了一種早期查詢融合技術，它在建構圖形表示之前融合查詢內容，進而產生更有效的圖形嵌入。我們的方法在 GraphQA 基準上達到了 4.13% 的效能提升，而無需訓練大型語言模型，證明了在處理複雜的文字屬性圖形資料方面有顯著的進展。

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

摘要：視覺語言導航 (VLN) 任務主要根據代理程式在多個環境中執行個別指令的一次性執行來評估代理程式，旨在開發能夠在任何環境中以零次學習的方式運作的代理程式。然而，真實世界的導航機器人通常在持續性的環境中運作，而這些環境具有相對一致的物理配置、視覺觀察和指令的語言風格。任務設定中的這種差距提供了一個機會，可以透過將連續適應特定環境納入其中來改善 VLN 代理程式。為了更好地反映這些真實世界的條件，我們推出了 GSA-VLN，這是一個新任務，要求代理程式在特定場景中執行導航指令，並同時適應該場景，以隨著時間推移而提高效能。為了評估所提出的任務，必須解決現有 VLN 資料集中的兩個挑戰：缺乏 OOD 資料，以及每個場景的指令數量和風格多樣性有限。因此，我們提出了一個新的資料集 GSA-R2R，它顯著擴展了 R2R 資料集的環境和指令的多樣性和數量，以評估代理程式在 ID 和 OOD 背景下的適應能力。此外，我們設計了一個三階段指令編排管道，該管道利用大型語言模型 (LLM) 來精煉由說話者產生的指令，並應用角色扮演技巧將指令改寫成不同的說話風格。這項技術的靈感來自於觀察到每個個別使用者通常在其指令中具有相符的簽名或偏好。我們針對 GSA-R2R 進行了大量的實驗，以徹底評估我們的資料集和基準各種方法。根據我們的研究結果，我們提出了一種新的方法 GR-DUET，它將基於記憶的導航圖表與特定於環境的訓練策略結合在一起，在所有 GSA-R2R 分割中取得了最先進的結果。

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

摘要：知識圖譜問答系統 (KGQA) 根據知識圖譜中的資料回答事實問題。KGQA 系統很複雜，因為系統必須理解知識尋求自然語言查詢中的關係和實體，並將它們對映到針對知識圖譜的結構化查詢，才能回答這些查詢。在本文中，我們介紹了 Chronos，這是一個用於產業規模 KGQA 的全面評估框架。它旨在全面評估這種多組件系統，重點關注：(1) 端對端和組件層級指標，(2) 可擴充至各種資料集，以及 (3) 可擴充的方法，用於在釋出前衡量系統的效能。在本文中，我們討論了與產業規模 KGQA 系統評估相關的獨特挑戰，檢視 Chronos 的設計，以及它如何應對這些挑戰。我們將展示它如何提供資料驅動決策的基礎，並討論使用它來衡量和改善真實世界 KGQA 系統的挑戰。

##### **FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**
2501.17144v1 by Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng

Prior research on training grounded factuality classification models to
detect hallucinations in large language models (LLMs) has relied on public
natural language inference (NLI) data and synthetic data. However, conventional
NLI datasets are not well-suited for document-level reasoning, which is
critical for detecting LLM hallucinations. Recent approaches to document-level
synthetic data generation involve iteratively removing sentences from documents
and annotating factuality using LLM-based prompts. While effective, this method
is computationally expensive for long documents and limited by the LLM's
capabilities. In this work, we analyze the differences between existing
synthetic training data used in state-of-the-art models and real LLM output
claims. Based on our findings, we propose a novel approach for synthetic data
generation, CG2C, that leverages multi-hop reasoning on context graphs
extracted from documents. Our fact checker model, FactCG, demonstrates improved
performance with more connected reasoning, using the same backbone models.
Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark
with much smaller model size.

摘要：先前的研究訓練了基於事實的分類模型，以偵測大型語言模型 (LLM) 中的幻覺，依賴於公開的自然語言推論 (NLI) 資料和合成資料。然而，傳統的 NLI 資料集並不適合文件層級的推理，這對於偵測 LLM 的幻覺至關重要。最近的文件層級合成資料生成方法涉及從文件中反覆移除句子，並使用基於 LLM 的提示註解事實。雖然有效，但此方法對於長文件來說在運算上很昂貴，且受限於 LLM 的能力。在這項工作中，我們分析了現有合成訓練資料與最先進模型中使用的真實 LLM 輸出宣告之間的差異。根據我們的研究結果，我們提出了一個用於合成資料生成的創新方法 CG2C，它利用從文件中提取的內容圖表進行多跳推理。我們的查核模型 FactCG 使用相同的骨幹模型，展示了在更多連結的推理下改進的效能。實驗表明，它甚至在 LLM-Aggrefact 基準上優於 GPT-4-o，且模型大小小得多。

##### **LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**
2501.16673v2 by Li Yin, Zhangyang Wang

Large Language Models (LLMs) have reshaped natural language processing,
powering applications from multi-hop retrieval and question answering to
autonomous agent workflows. Yet, prompt engineering -- the task of crafting
textual inputs to effectively direct LLMs -- remains difficult and
labor-intensive, particularly for complex pipelines that combine multiple LLM
calls with functional operations like retrieval and data formatting. We
introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering
(APE) that extends textual gradient-based methods (such as Text-Grad) to
multi-component, potentially cyclic LLM architectures. Implemented within the
AdalFlow library, LLM-AutoDiff treats each textual input as a trainable
parameter and uses a frozen backward engine LLM to generate feedback-akin to
textual gradients -- that guide iterative prompt updates. Unlike prior
single-node approaches, LLM-AutoDiff inherently accommodates functional nodes,
preserves time-sequential behavior in repeated calls (e.g., multi-hop loops),
and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts
(instructions, formats, or few-shot examples). It further boosts training
efficiency by focusing on error-prone samples through selective gradient
computation. Across diverse tasks, including single-step classification,
multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff
consistently outperforms existing textual gradient baselines in both accuracy
and training cost. By unifying prompt optimization through a graph-centric
lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating
LLM workflows - mirroring the transformative role that automatic
differentiation libraries have long played in neural network research.

摘要：大型語言模型 (LLM) 已重塑自然語言處理，
為從多跳檢索和問答到
自主代理工作流程的應用提供動力。然而，提示工程 -- 編寫
文本輸入以有效指導 LLM 的任務 -- 仍然困難且
勞動密集，特別是對於將多個 LLM
呼叫與檢索和數據格式化等功能操作相結合的複雜管道。我們
介紹 LLM-AutoDiff：一個用於自動提示工程 (APE) 的新框架，它將基於文本梯度的
方法（例如 Text-Grad）擴展到多組件、潛在循環 LLM 架構中。在
AdalFlow 庫中實施，LLM-AutoDiff 將每個文本輸入視為一個可訓練
參數，並使用凍結的後向引擎 LLM 生成反饋——類似於
文本梯度——指導迭代提示更新。與先前的
單節點方法不同，LLM-AutoDiff 本質上適應功能節點，
在重複呼叫（例如，多跳循環）中保留時間順序行為，
並通過隔離不同的子提示（說明、格式或少數鏡頭示例）來解決“迷失在中間”問題。它進一步提高訓練
效率，通過選擇性梯度
計算專注於容易出錯的樣本。在包括單步分類、
多跳基於檢索的問答和代理驅動管道在內的各種任務中，LLM-AutoDiff
在準確性和訓練成本方面始終優於現有的文本梯度基準。通過圖形中心化
視角統一提示優化，LLM-AutoDiff 為擴展和自動化
LLM 工作流程提供了一個強大的新範例——反映了自動
微分庫在神經網絡研究中長期扮演的變革性角色。

##### **360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**
2501.16450v3 by Hamed Firooz, Maziar Sanjabi, Adrian Englhardt, Aman Gupta, Ben Levine, Dre Olgiati, Gungor Polatkan, Iuliia Melnychuk, Karthik Ramgopal, Kirill Talanine, Kutta Srinivasan, Luke Simon, Natesh Sivasubramoniapillai, Necip Fazil Ayan, Qingquan Song, Samira Sriram, Souvik Ghosh, Tao Song, Tejas Dharamsi, Vignesh Kothapalli, Xiaoling Zhai, Ya Xu, Yu Wang, Yun Dai

Ranking and recommendation systems are the foundation for numerous online
experiences, ranging from search results to personalized content delivery.
These systems have evolved into complex, multilayered architectures that
leverage vast datasets and often incorporate thousands of predictive models.
The maintenance and enhancement of these models is a labor intensive process
that requires extensive feature engineering. This approach not only exacerbates
technical debt but also hampers innovation in extending these systems to
emerging problem domains. In this report, we present our research to address
these challenges by utilizing a large foundation model with a textual interface
for ranking and recommendation tasks. We illustrate several key advantages of
our approach: (1) a single model can manage multiple predictive tasks involved
in ranking and recommendation, (2) decoder models with textual interface due to
their comprehension of reasoning capabilities, can generalize to new
recommendation surfaces and out-of-domain problems, and (3) by employing
natural language interfaces for task definitions and verbalizing member
behaviors and their social connections, we eliminate the need for feature
engineering and the maintenance of complex directed acyclic graphs of model
dependencies. We introduce our research pre-production model, 360Brew V1.0, a
150B parameter, decoder-only model that has been trained and fine-tuned on
LinkedIn's data and tasks. This model is capable of solving over 30 predictive
tasks across various segments of the LinkedIn platform, achieving performance
levels comparable to or exceeding those of current production systems based on
offline metrics, without task-specific fine-tuning. Notably, each of these
tasks is conventionally addressed by dedicated models that have been developed
and maintained over multiple years by teams of a similar or larger size than
our own.

摘要：排名和推薦系統是許多線上體驗的基礎，從搜尋結果到個人化內容傳遞。
這些系統已演變成複雜的多層架構，利用龐大的資料集，並經常納入數千個預測模型。
這些模型的維護和增強是一個勞力密集的過程，需要廣泛的特徵工程。
這種方法不僅加劇了技術債務，也阻礙了將這些系統擴展到新興問題領域的創新。
在此報告中，我們提出了我們的研究，以利用具有文字介面的大型基礎模型來解決這些挑戰，以進行排名和推薦任務。
我們說明了我們方法的幾個主要優點：(1) 單一模型可以管理排名和推薦中涉及的多個預測任務，(2) 由於解碼器模型具有文字介面，因此它們對推理能力的理解，可以推廣到新的推薦表面和領域外問題，以及 (3) 通過採用自然語言介面進行任務定義和表達成員行為及其社交連接，我們消除了對特徵工程和維護複雜的模型相依性有向無環圖的需求。
我們介紹了我們的研究前製作業模型 360Brew V1.0，這是一個 150B 參數，僅解碼器模型，已在 LinkedIn 的資料和任務上進行訓練和微調。
此模型能夠解決 LinkedIn 平臺各個區塊中超過 30 個預測任務，在不針對任務進行微調的情況下，達到與基於離線指標的現行製作系統相當或超越的效能水準。
值得注意的是，這些任務中的每個任務通常由專用模型處理，這些模型是由與我們規模相當或更大的團隊在多年間開發和維護的。

##### **Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**
2501.16191v1 by Antony Bartlett, Cynthia Liem, Annibale Panichella

Fixing Python dependency issues is a tedious and error-prone task for
developers, who must manually identify and resolve environment dependencies and
version constraints of third-party modules and Python interpreters. Researchers
have attempted to automate this process by relying on large knowledge graphs
and database lookup tables. However, these traditional approaches face
limitations due to the variety of dependency error types, large sets of
possible module versions, and conflicts among transitive dependencies. This
study explores the potential of using large language models (LLMs) to
automatically fix dependency issues in Python programs. We introduce PLLM
(pronounced "plum"), a novel technique that employs retrieval-augmented
generation (RAG) to help an LLM infer Python versions and required modules for
a given Python file. PLLM builds a testing environment that iteratively (1)
prompts the LLM for module combinations, (2) tests the suggested changes, and
(3) provides feedback (error messages) to the LLM to refine the fix. This
feedback cycle leverages natural language processing (NLP) to intelligently
parse and interpret build error messages. We benchmark PLLM on the Gistable
HG2.9K dataset, a collection of challenging single-file Python gists. We
compare PLLM against two state-of-the-art automatic dependency inference
approaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency
issues. Our results indicate that PLLM can fix more dependency issues than the
two baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)
over PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial
for projects with many dependencies and for specific third-party numerical and
machine-learning modules. Our findings demonstrate the potential of LLM-based
approaches to iteratively resolve Python dependency issues.

摘要：<paragraph>修復 Python 依賴項問題對開發人員來說是一項繁瑣且容易出錯的任務，他們必須手動識別和解決第三方模組和 Python 解譯器的環境依賴項和版本限制。研究人員已嘗試透過依賴大型知識圖譜和資料庫查詢表來自動化此程序。然而，這些傳統方法由於依賴項錯誤類型多樣、可能的模組版本數量龐大，以及傳遞依賴項之間的衝突，而面臨限制。本研究探討使用大型語言模型 (LLM) 自動修復 Python 程式中的依賴項問題的可能性。我們介紹 PLLM（發音為「plum」），這是一種新穎的技術，採用檢索增強生成 (RAG) 來協助 LLM 推論 Python 版本和給定 Python 檔案所需的模組。PLLM 建立一個測試環境，反覆 (1) 提示 LLM 模組組合，(2) 測試建議的變更，以及 (3) 提供回饋（錯誤訊息）給 LLM 以改善修正。此回饋循環利用自然語言處理 (NLP) 來智慧解析和詮釋建置錯誤訊息。我們在 Gistable HG2.9K 資料集上對 PLLM 進行基準測試，該資料集是一個具有挑戰性的單一檔案 Python gist 集合。我們將 PLLM 與兩種最先進的自動依賴項推論方法進行比較，即 PyEGo 和 ReadPyE，以比較解決依賴項問題的能力。我們的結果顯示，PLLM 可以修復比這兩個基準更多的依賴項問題，比 ReadPyE 多修復了 +218 (+15.97%) 個，比 PyEGo 多修復了 +281 (+21.58%) 個。我們更深入的分析表明，PLLM 對具有許多依賴項的專案以及特定第三方數值和機器學習模組特別有益。我們的研究結果證明了基於 LLM 的方法反覆解決 Python 依賴項問題的可能性。</paragraph>

##### **Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**
2501.15791v1 by Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu

Knowledge graphs are widely used in industrial applications, making error
detection crucial for ensuring the reliability of downstream applications.
Existing error detection methods often fail to effectively leverage
fine-grained subgraph information and rely solely on fixed graph structures,
while also lacking transparency in their decision-making processes, which
results in suboptimal detection performance. In this paper, we propose a novel
Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that
utilizes multiple large language models (LLMs) in a collaborative setting. By
concatenating fine-grained, bidirectional subgraph embeddings with LLM-based
query embeddings during training, our framework integrates these
representations to produce four specialized agents. These agents utilize
subgraph information from different dimensions to engage in multi-round
discussions, thereby improving error detection accuracy and ensuring a
transparent decision-making process. Extensive experiments on FB15K and WN18RR
demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the
accuracy and robustness of KG evaluation. For specific industrial scenarios,
our framework can facilitate the training of specialized agents using
domain-specific knowledge graphs for error detection, which highlights the
potential industrial application value of our framework. Our code and datasets
are available at https://github.com/kse-ElEvEn/MAKGED.

摘要：知識圖譜廣泛應用於工業應用中，使得錯誤偵測對於確保下游應用的可靠性至關重要。現有的錯誤偵測方法通常無法有效利用細粒度的子圖資訊，並且僅依賴於固定的圖形結構，同時在它們的決策過程中也缺乏透明度，這導致次佳的偵測效能。在本文中，我們提出了一個用於知識圖譜錯誤偵測 (MAKGED) 的新多代理架構，它在協作設定中利用了多個大型語言模型 (LLM)。透過在訓練期間將細粒度、雙向子圖嵌入與基於 LLM 的查詢嵌入串接，我們的架構整合了這些表示以產生四個專門代理。這些代理利用不同維度的子圖資訊參與多輪討論，從而提高錯誤偵測準確度並確保透明的決策過程。在 FB15K 和 WN18RR 上的廣泛實驗表明，MAKGED 優於最先進的方法，增強了 KG 評估的準確性和穩健性。對於特定產業情境，我們的架構可以利用特定領域的知識圖譜來促進專門代理的訓練以進行錯誤偵測，這突顯了我們架構的潛在產業應用價值。我們的程式碼和資料集可在 https://github.com/kse-ElEvEn/MAKGED 取得。

##### **Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**
2501.15777v1 by Momoka Furuhashi, Hiroaki Funayama, Yuya Iwase, Yuichiroh Matsubayashi, Yoriko Isobe, Toru Nagahama, Saku Sugawara, Kentaro Inui

Short-reading comprehension questions help students understand text structure
but lack effective feedback. Students struggle to identify and correct errors,
while manual feedback creation is labor-intensive. This highlights the need for
automated feedback linking responses to a scoring rubric for deeper
comprehension.
  Despite advances in Natural Language Processing (NLP), research has focused
on automatic grading, with limited work on feedback generation. To address
this, we propose a system that generates feedback for student responses.
  Our contributions are twofold. First, we introduce the first system for
feedback on short-answer reading comprehension. These answers are derived from
the text, requiring structural understanding. We propose an "answer diagnosis
graph," integrating the text's logical structure with feedback templates. Using
this graph and NLP techniques, we estimate students' comprehension and generate
targeted feedback.
  Second, we evaluate our feedback through an experiment with Japanese high
school students (n=39). They answered two 70-80 word questions and were divided
into two groups with minimal academic differences. One received a model answer,
the other system-generated feedback. Both re-answered the questions, and we
compared score changes. A questionnaire assessed perceptions and motivation.
  Results showed no significant score improvement between groups, but
system-generated feedback helped students identify errors and key points in the
text. It also significantly increased motivation. However, further refinement
is needed to enhance text structure understanding.

摘要：短篇閱讀理解題目有助學生理解文章結構，但缺乏有效的回饋。學生難以找出並更正錯誤，而手動建立回饋又很費力。這突顯了自動化回饋的必要性，將回應連結到評分標準，以獲得更深入的理解。

儘管自然語言處理 (NLP) 有所進展，但研究一直集中在自動評分上，而回饋生成的工作有限。為了解決這個問題，我們提出了一個系統，用於為學生的回答產生回饋。

我們的貢獻有兩個方面。首先，我們引入了第一個針對簡答閱讀理解提供回饋的系統。這些答案來自於文本，需要結構化的理解。我們提出了一個「答案診斷圖」，將文本的邏輯結構與回饋範本整合在一起。使用這個圖表和 NLP 技術，我們估計學生的理解力並產生有針對性的回饋。

其次，我們透過一項針對日本高中生的實驗（n=39）來評估我們的回饋。他們回答了兩個 70-80 字的問題，並被分成兩組，學術差異最小。一組收到範本答案，另一組收到系統產生的回饋。兩組都重新回答了問題，我們比較了分數的變化。一份問卷評估了認知和動機。

結果顯示兩組之間沒有顯著的分數進步，但系統產生的回饋有助於學生找出文本中的錯誤和重點。它也顯著地提高了動機。然而，需要進一步的改進來增強對文本結構的理解。

##### **Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**
2501.15688v1 by Haodi Ma, Dzmitry Kasinets, Daisy Zhe Wang

Multimodal knowledge graph completion (MMKGC) aims to predict missing links
in multimodal knowledge graphs (MMKGs) by leveraging information from various
modalities alongside structural data. Existing MMKGC approaches primarily
extend traditional knowledge graph embedding (KGE) models, which often require
creating an embedding for every entity. This results in large model sizes and
inefficiencies in integrating multimodal information, particularly for
real-world graphs. Meanwhile, Transformer-based models have demonstrated
competitive performance in knowledge graph completion (KGC). However, their
focus on single-modal knowledge limits their capacity to utilize cross-modal
information. Recently, Large vision-language models (VLMs) have shown potential
in cross-modal tasks but are constrained by the high cost of training. In this
work, we propose a novel approach that integrates Transformer-based KGE models
with cross-modal context generated by pre-trained VLMs, thereby extending their
applicability to MMKGC. Specifically, we employ a pre-trained VLM to transform
relevant visual information from entities and their neighbors into textual
sequences. We then frame KGC as a sequence-to-sequence task, fine-tuning the
model with the generated cross-modal context. This simple yet effective method
significantly reduces model size compared to traditional KGE approaches while
achieving competitive performance across multiple large-scale datasets with
minimal hyperparameter tuning.

摘要：多模態知識圖譜補全 (MMKGC) 旨在透過利用來自各種模態與結構化資料的資訊，來預測多模態知識圖譜 (MMKG) 中的缺失連結。現有的 MMKGC 方法主要擴充傳統的知識圖譜嵌入 (KGE) 模型，這些模型通常需要為每個實體建立一個嵌入。這會導致模型尺寸過大，且在整合多模態資訊時效率低下，特別是對於真實世界的圖譜。與此同時，基於 Transformer 的模型已在知識圖譜補全 (KGC) 中展現出競爭力。然而，它們著重於單模態知識，限制了它們利用跨模態資訊的能力。最近，大型視覺語言模型 (VLM) 已在跨模態任務中展現潛力，但受限於訓練成本過高。在這項工作中，我們提出了一種創新的方法，它將基於 Transformer 的 KGE 模型與預先訓練的 VLM 所產生的跨模態內容整合在一起，從而擴展它們在 MMKGC 中的適用性。具體來說，我們採用預先訓練的 VLM，將實體及其鄰居相關的視覺資訊轉換成文字序列。然後，我們將 KGC 架構成一個序列到序列的任務，並使用產生的跨模態內容微調模型。這種簡單但有效的方法，與傳統的 KGE 方法相比，大幅減少了模型尺寸，同時在多個大型資料集上達到了競爭力的效能，且只需最少的超參數調整。

##### **How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**
2501.15378v1 by Manzong Huang, Chenyang Bu, Yi He, Xindong Wu

Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently
propelled significant advances in complex reasoning tasks, thanks to their
broad domain knowledge and contextual awareness. Unfortunately, current methods
often assume KGs to be complete, which is impractical given the inherent
limitations of KG construction and the potential loss of contextual cues when
converting unstructured text into entity-relation triples. In response, this
paper proposes the Triple Context Restoration and Query-driven Feedback
(TCR-QF) framework, which reconstructs the textual context underlying each
triple to mitigate information loss, while dynamically refining the KG
structure by iteratively incorporating query-relevant missing knowledge.
Experiments on five benchmark question-answering datasets substantiate the
effectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1%
improvement in Exact Match and a 15.5% improvement in F1 over its
state-of-the-art GraphRAG competitors.

摘要：知識圖譜 (KG) 增強大型語言模型 (LLM) 最近推動複雜推理任務的重大進展，這要歸功於它們廣泛的領域知識和語境感知。不幸的是，目前的模型通常假設 KG 是完整的，這在考慮到 KG 建構的固有限制和在將非結構化文字轉換為實體關係三元組時潛在的語境線索損失時是不切實際的。為了解決這個問題，本文提出了三元組語境還原和查詢驅動回饋 (TCR-QF) 架構，它重建每個三元組底層的文字語境以減輕資訊損失，同時透過反覆納入與查詢相關的遺失知識來動態優化 KG 結構。在五個基準問題回答資料集上的實驗證實了 TCR-QF 在 KG 和 LLM 整合方面的有效性，它在 Exact Match 中獲得 29.1% 的改進，在 F1 中獲得 15.5% 的改進，優於最先進的 GraphRAG 競爭對手。

##### **Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**
2501.14932v1 by Cencheng Shen, Darren Edge, Jonathan Larson, Carey E. Priebe

Modern datasets often consist of numerous samples with abundant features and
associated timestamps. Analyzing such datasets to uncover underlying events
typically requires complex statistical methods and substantial domain
expertise. A notable example, and the primary data focus of this paper, is the
global synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)
-- a global hub of human trafficking data containing over 200,000 anonymized
records spanning from 2002 to 2022, with numerous categorical features for each
record. In this paper, we propose a fast and scalable method for analyzing and
extracting significant categorical feature interactions, and querying large
language models (LLMs) to generate data-driven insights that explain these
interactions. Our approach begins with a binarization step for categorical
features using one-hot encoding, followed by the computation of graph
covariance at each time. This graph covariance quantifies temporal changes in
dependence structures within categorical data and is established as a
consistent dependence measure under the Bernoulli distribution. We use this
measure to identify significant feature pairs, such as those with the most
frequent trends over time or those exhibiting sudden spikes in dependence at
specific moments. These extracted feature pairs, along with their timestamps,
are subsequently passed to an LLM tasked with generating potential explanations
of the underlying events driving these dependence changes. The effectiveness of
our method is demonstrated through extensive simulations, and its application
to the CTDC dataset reveals meaningful feature pairs and potential data stories
underlying the observed feature interactions.

摘要：現代資料集通常包含許多具有豐富特徵和關聯時間戳的樣本。分析此類資料集以揭示底層事件通常需要複雜的統計方法和大量的領域專業知識。一個值得注意的範例，也是本文的主要資料重點，是來自反人口販運資料合作組織 (CTDC) 的全球合成資料集，這是全球人口販運資料的樞紐，包含超過 200,000 筆從 2002 年到 2022 年的匿名記錄，每個記錄都有許多分類特徵。在本文中，我們提出了一種快速且可擴充的方法，用於分析和提取重要的分類特徵交互作用，並查詢大型語言模型 (LLM)，以產生資料驅動的見解來解釋這些交互作用。我們的做法從使用獨熱編碼對分類特徵進行二元化步驟開始，然後在每個時間點計算圖形共變異數。此圖形共變異數量化了分類資料中依賴結構的時間變化，並在伯努利分佈下建立為一致的依賴度量。我們使用此度量來識別重要的特徵對，例如隨時間推移趨勢最頻繁的特徵對，或在特定時刻表現出依賴性突然激增的特徵對。這些提取的特徵對及其時間戳隨後傳遞給 LLM，後者負責產生對驅動這些依賴性變化的底層事件的潛在解釋。我們的方法的有效性已通過廣泛的模擬得到證明，其在 CTDC 資料集中的應用揭示了有意義的特徵對和潛在的資料故事，這些故事是觀察到的特徵交互作用的基礎。

##### **Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**
2501.14892v1 by Hang Luo, Jian Zhang, Chujun Li

In knowledge-intensive tasks, especially in high-stakes domains like medicine
and law, it is critical not only to retrieve relevant information but also to
provide causal reasoning and explainability. Large language models (LLMs) have
achieved remarkable performance in natural language understanding and
generation tasks. However, they often suffer from limitations such as
difficulty in incorporating new knowledge, generating hallucinations, and
explaining their reasoning process. To address these challenges, integrating
knowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has
emerged as an effective solution. Traditional Graph RAG methods often rely on
simple graph traversal or semantic similarity, which do not capture causal
relationships or align well with the model's internal reasoning steps. This
paper proposes a novel pipeline that filters large knowledge graphs to
emphasize cause-effect edges, aligns the retrieval process with the model's
chain-of-thought (CoT), and enhances reasoning through multi-stage path
improvements. Experiments on medical question-answering tasks show consistent
gains, with up to a 10\% absolute improvement across multiple large language
models (LLMs). This approach demonstrates the value of combining causal
reasoning with stepwise retrieval, leading to more interpretable and logically
grounded solutions for complex queries.

摘要：在知識密集型任務中，特別是在醫學和法律等高風險領域，不僅檢索相關資訊至關重要，還必須提供因果推理和可解釋性。大型語言模型 (LLM) 在自然語言理解和生成任務中取得了顯著的表現。然而，它們通常會遇到一些限制，例如難以納入新知識、產生幻覺，以及解釋其推理過程。為了應對這些挑戰，將知識圖與圖形檢索增強生成 (Graph RAG) 整合在一起已成為一種有效的解決方案。傳統的 Graph RAG 方法通常依賴於簡單的圖形遍歷或語義相似性，這無法捕捉因果關係或與模型的內部推理步驟很好地對齊。本文提出了一個新穎的管道，該管道過濾大型知識圖以強調因果邊緣，將檢索過程與模型的思想鏈 (CoT) 對齊，並通過多階段路徑改進來增強推理。在醫療問題解答任務上的實驗顯示出一致的收益，在多個大型語言模型 (LLM) 中絕對改進幅度高達 10%。這種方法展示了將因果推理與逐步檢索相結合的價值，從而為複雜查詢提供更具可解釋性和邏輯依據的解決方案。

##### **GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**
2501.16382v1 by Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon

Drug discovery (DD) has tremendously contributed to maintaining and improving
public health. Hypothesizing that inhibiting protein misfolding can slow
disease progression, researchers focus on target identification (Target ID) to
find protein structures for drug binding. While Large Language Models (LLMs)
and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug
discovery, integrating models into cohesive workflows remains challenging. We
conducted a user study with drug discovery researchers to identify the
applicability of LLMs and RAGs in Target ID. We identified two main findings:
1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on
an initial protein and protein candidates that have a therapeutic impact; 2)
the model must provide the PPI and relevant explanations for better
understanding. Based on these observations, we identified three limitations in
previous approaches for Target ID: 1) semantic ambiguity, 2) lack of
explainability, and 3) short retrieval units. To address these issues, we
propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve
agent pipeline RAG framework to support large-scale PPI signaling pathway
exploration in understanding therapeutic impacts by decomposing the analysis of
entire PPI pathways into sub-tasks focused on the analysis of PPI edges.

摘要：药物发现 (DD) 极大地促进了公共卫生的维护和改善。研究人员假设抑制蛋白质错误折叠可以减缓疾病进展，因此专注于靶点识别 (Target ID) 以找到用于药物结合的蛋白质结构。虽然大型语言模型 (LLM) 和检索增强生成 (RAG) 框架加速了药物发现，但将模型整合到内聚工作流中仍然具有挑战性。我们与药物发现研究人员进行了一项用户研究，以确定 LLM 和 RAG 在 Target ID 中的适用性。我们确定了两个主要发现：1) LLM 应该基于初始蛋白质和具有治疗作用的蛋白质候选物提供多个蛋白质-蛋白质相互作用 (PPI)；2) 该模型必须提供 PPI 和相关解释以更好地理解。基于这些观察，我们发现了先前 Target ID 方法中的三个局限性：1) 语义歧义，2) 缺乏可解释性，3) 检索单元短。为了解决这些问题，我们提出了 GraPPI，这是一种基于大规模知识图 (KG) 的检索-分解-求解代理管道 RAG 框架，以支持大规模 PPI 信号通路探索，通过将整个 PPI 通路的分析分解为专注于 PPI 边缘分析的子任务来理解治疗影响。

##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v2 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez-Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

摘要：大型語言模型 (LLM) 已在各種任務中展現出巨大的潛力。然而，探索和改進 LLM 在解釋圖形結構方面的能力的研究仍然有限。為了解決這個差距，我們對提示當前開源 LLM 進行圖形轉文字生成任務的全面評估。儘管我們探索了最佳提示策略，並提出了一種新穎且有效的基於多樣性難度的少量樣本選擇方法，但我們發現無調校方法的改進是漸進的，因為 LLM 難以規劃複雜的圖形，特別是那些具有較多三元組的圖形。為了進一步改進 LLM 在圖形序列規劃和真實依據方面的能力，我們引入了一個新的圖形轉文字資料集 PlanGTG，並註解了兩個子任務：重新排序和歸因。透過廣泛的自動和人工評估，我們證明了使用 PlanGTG 資料集從少量學習和微調的角度顯著改進了生成文字的品質。我們的研究為圖形轉文字生成中的新研究方向鋪平了道路。PlanGTG 資料集可以在 https://github.com/probe2/kg_text 中找到。

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

摘要：圖表檢索增強生成 (GRAG) 是一種新穎的範例，它透過將圖表資訊（例如知識圖表 (KG)) 整合到大型語言模型 (LLM) 中，進一步提升了樸素的 RAG 系統以減輕幻覺。然而，現有的 GRAG 仍會遇到限制：1) 簡單的範例通常會因從 KG 中擷取的關聯性狹隘且淺薄而無法解決複雜的問題 2) 如果圖表很密集，與 KG 強耦合的方法往往會導致高運算成本和耗時。在本文中，我們提出了 Fast Think-on-Graph (FastToG)，這是一種創新的範例，可讓 LLM 在 KG 中「逐個社群」進行思考。為此，FastToG 使用社群偵測來擷取更深入的關聯性，並使用兩個階段的社群修剪（粗略修剪和精細修剪）來加快檢索速度。此外，我們還開發了兩種社群到文字的方法，將社群的圖表結構轉換為文字形式，以便 LLM 更容易理解。實驗結果證明了 FastToG 的有效性，與先前的研究相比，展示出更高的準確性、更快的推理速度和更好的可解釋性。

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

摘要：圖形資料庫（GDB），例如 Neo4j 和 TigerGraph，擅長處理相互連接的資料，但缺乏進階的推論能力。神經圖形資料庫（NGDB）透過整合圖形神經網路（GNN）來解決這個問題，以進行預測分析和對不完整或有雜訊的資料進行推理。然而，NGDB 依賴於預先定義的查詢，並且缺乏自主性和適應性。本文介紹了代理神經圖形資料庫（Agentic NGDB），它以三項核心功能擴充了 NGDB：自動查詢建構、神經查詢執行和持續學習。我們找出實現 Agentic NGDB 的十大關鍵挑戰：語義單元表示、演繹推理、可擴充查詢執行，以及與基礎模型（例如大型語言模型 (LLM)）整合。透過解決這些挑戰，Agentic NGDB 可以為現代資料驅動應用打造智慧且自我改善的系統，為適應性和自主資料管理解決方案鋪路。

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

摘要：GraphRAG 透過將外部知識結構化為多尺度知識圖譜，推動了檢索增強生成 (RAG)，使語言模型能夠在其推理中整合廣泛的背景和細微的細節。儘管 GraphRAG 在各個領域都已展現出成功，但其安全性影響在很大程度上仍未被探索。為了彌補這一差距，本研究探討了 GraphRAG 對投毒攻擊的脆弱性，揭示了一個有趣的安全悖論：與傳統的 RAG 相比，GraphRAG 基於圖表的索引和檢索增強了對簡單投毒攻擊的韌性；同時，相同的特徵也創造了新的攻擊面。我們提出了 GRAGPoison，這是一種新穎的攻擊，它利用知識圖譜中的共享關係來製作中毒文本，能夠同時危害多個查詢。GRAGPoison 採用了三項關鍵策略：i) 關係注入以引入錯誤的知識，ii) 關係增強以擴大投毒影響，以及 iii) 敘事生成以將惡意內容嵌入連貫的文本中。在各種數據集和模型上的經驗評估表明，GRAGPoison 在有效性（成功率高達 98%）和可擴展性（使用不到 68% 的投毒文本）方面都明顯優於現有的攻擊。我們還探討了潛在的防禦措施及其局限性，確定了未來研究的有希望的方向。

##### **EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**
2501.13746v1 by Yuhui Yun, Huilong Ye, Xinru Li, Ruojia Li, Jingfeng Deng, Li Li, Haoyi Xiong

The paper introduces EICopilot, an novel agent-based solution enhancing
search and exploration of enterprise registration data within extensive online
knowledge graphs like those detailing legal entities, registered capital, and
major shareholders. Traditional methods necessitate text-based queries and
manual subgraph explorations, often resulting in time-consuming processes.
EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this
landscape by utilizing Large Language Models (LLMs) to interpret natural
language queries. This solution automatically generates and executes Gremlin
scripts, providing efficient summaries of complex enterprise relationships.
Distinct feature a data pre-processing pipeline that compiles and annotates
representative queries into a vector database of examples for In-context
learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought
with ICL to enhance Gremlin script generation for knowledge graph search and
exploration, and a novel query masking strategy that improves intent
recognition for heightened script accuracy. Empirical evaluations demonstrate
the superior performance of EICopilot, including speed and accuracy, over
baseline methods, with the \emph{Full Mask} variant achieving a syntax error
rate reduction to as low as 10.00% and an execution correctness of up to
82.14%. These components collectively contribute to superior querying
capabilities and summarization of intricate datasets, positioning EICopilot as
a groundbreaking tool in the exploration and exploitation of large-scale
knowledge graphs for enterprise information search.

摘要：本文介紹了 EICopilot，這是一種基於代理的新型解決方案，可增強在廣泛的線上知識圖譜中搜尋和探索企業註冊資料，例如詳細說明法律實體、註冊資本和主要股東的資料。傳統方法需要基於文字的查詢和手動子圖探索，通常會導致耗時的流程。EICopilot 部署為百度企業搜尋的聊天機器人，透過利用大型語言模型 (LLM) 來詮釋自然語言查詢，進而改善這項技術。此解決方案會自動產生並執行 Gremlin 腳本，提供複雜企業關係的有效摘要。其獨特功能為資料前處理管線，可將具代表性的查詢編譯並註解到範例的向量資料庫中，以進行脈絡中學習 (ICL)，這是一個結合了思考鏈與 ICL 的綜合推理管線，用於增強 Gremlin 腳本產生，以進行知識圖譜搜尋和探索，以及一種新穎的查詢遮罩策略，可改善意圖辨識，進而提高腳本準確度。實證評估顯示，EICopilot 的效能優於基線方法，包括速度和準確度，其中「完整遮罩」變體將語法錯誤率降低至低於 10.00%，執行正確率高達 82.14%。這些元件共同促成了優異的查詢功能和複雜資料集的摘要，將 EICopilot 定位為探索和利用大規模知識圖譜進行企業資訊搜尋的創新工具。

##### **Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**
2501.13731v1 by Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng

Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.

摘要：圖表計算任務本質上具有挑戰性，而且通常需要開發先進的演算法才能有效解決。隨著大型語言模型 (LLM) 的出現，研究人員已開始探討其解決這些任務的可能性。然而，現有方法受到 LLM 理解複雜圖形結構的能力有限以及其高推理成本的限制，這使得它們不切實際地處理大規模圖形。受到人類解決圖形問題的方法啟發，我們引入了 PIE（偽代碼注入增強 LLM 圖形計算任務推理）這個新框架，它包含三個關鍵步驟：問題理解、提示設計和代碼生成。在此框架中，LLM 的任務是理解問題並擷取相關資訊以產生正確的代碼。分析圖形結構和執行代碼的責任委派給解釋器。我們將與任務相關的偽代碼注入提示中，以進一步協助 LLM 產生有效的代碼。我們還採用具有成本效益的試錯技術，以確保 LLM 生成的代碼正確執行。與需要為每個個別測試案例呼叫 LLM 的其他方法不同，PIE 僅在代碼產生階段呼叫 LLM，允許重複使用產生的代碼並大幅降低推理成本。大量的實驗證明，PIE 在準確性和計算效率方面都優於現有的基準。

##### **CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**
2501.13993v1 by Hamza Landolsi, Kais Letaief, Nizar Taghouti, Ines Abdeljaoued-Tej

The introduction of new features and services in the banking sector often
overwhelms customers, creating an opportunity for banks to enhance user
experience through financial chatbots powered by large language models (LLMs).
We initiated an AI agent designed to provide customers with relevant
information about banking services and insights from annual reports. We
proposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation
(CAPRAG) that effectively addresses both relationship-based and contextual
queries, thereby improving customer engagement in the digital banking
landscape. To implement this, we developed a processing pipeline to refine text
data, which we utilized in two main frameworks: Vector RAG and Graph RAG. This
dual approach enables us to populate both vector and graph databases with
processed data for efficient retrieval. The Cypher query component is employed
to effectively query the graph database. When a user submits a query, it is
first expanded by a query expansion module before being routed to construct a
final query from the hybrid Knowledge Base (KB). This final query is then sent
to an open-source LLM for response generation. Overall, our innovative,
designed to international banks, serves bank's customers in an increasingly
complex digital environment, enhancing clarity and accessibility of
information.

摘要：銀行業中新功能和服務的推出經常讓客戶感到不知所措，這為銀行透過大型語言模型 (LLM) 驅動的金融聊天機器人來提升使用者體驗創造了機會。我們啟動了一個人工智慧代理，旨在為客戶提供有關銀行服務和年度報告見解的相關資訊。我們提出了一個混合式客戶分析管道檢索擴充生成 (CAPRAG)，它有效地處理基於關係和情境式的查詢，從而提升數位銀行環境中的客戶參與度。為了實作這一點，我們開發了一個處理管道來精煉文字資料，我們在兩個主要架構中使用它：Vector RAG 和 Graph RAG。這種雙管齊下的方法讓我們能夠使用處理過的資料來填補向量和圖形資料庫，以利於有效檢索。Cypher 查詢元件用於有效查詢圖形資料庫。當使用者提交查詢時，它會先由查詢擴充模組擴充，然後再路由到混合式知識庫 (KB) 中建構最終查詢。然後這個最終查詢會傳送給開源 LLM 以產生回應。整體而言，我們創新的設計服務於國際銀行，在日益複雜的數位環境中服務銀行客戶，提升資訊的清晰度和可及性。

##### **Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**
2501.13992v1 by Hy Nguyen, Nguyen Hung Nguyen, Nguyen Linh Bao Nguyen, Srikanth Thudumu, Hung Du, Rajesh Vasa, Kon Mouzakis

The Hierarchical Navigable Small World (HNSW) algorithm is widely used for
approximate nearest neighbor (ANN) search, leveraging the principles of
navigable small-world graphs. However, it faces some limitations. The first is
the local optima problem, which arises from the algorithm's greedy search
strategy, selecting neighbors based solely on proximity at each step. This
often leads to cluster disconnections. The second limitation is that HNSW
frequently fails to achieve logarithmic complexity, particularly in
high-dimensional datasets, due to the exhaustive traversal through each layer.
To address these limitations, we propose a novel algorithm that mitigates local
optima and cluster disconnections while enhancing the construction speed,
maintaining inference speed. The first component is a dual-branch HNSW
structure with LID-based insertion mechanisms, enabling traversal from multiple
directions. This improves outlier node capture, enhances cluster connectivity,
accelerates construction speed and reduces the risk of local minima. The second
component incorporates a bridge-building technique that bypasses redundant
intermediate layers, maintaining inference and making up the additional
computational overhead introduced by the dual-branch structure. Experiments on
various benchmarks and datasets showed that our algorithm outperforms the
original HNSW in both accuracy and speed. We evaluated six datasets across
Computer Vision (CV), and Natural Language Processing (NLP), showing recall
improvements of 18\% in NLP, and up to 30\% in CV tasks while reducing the
construction time by up to 20\% and maintaining the inference speed. We did not
observe any trade-offs in our algorithm. Ablation studies revealed that
LID-based insertion had the greatest impact on performance, followed by the
dual-branch structure and bridge-building components.

摘要：分層可導航小世界 (HNSW) 演算法廣泛用於近似最近鄰居 (ANN) 搜尋，並利用可導航小世界圖形的原理。然而，它面臨一些限制。第一個是局部最佳化問題，這源自於演算法的貪婪搜尋策略，在每個步驟中僅根據鄰近度來選擇鄰居。這通常會導致群集斷線。第二個限制是，由於透過每一層的窮舉式遍歷，HNSW 常常無法在高維度資料集中達成對數複雜度。為了解決這些限制，我們提出了一種新的演算法，它可以減輕局部最佳化和群集斷線，同時提高建構速度，並維持推論速度。第一個組成部分是一個具有基於 LID 的插入機制的雙分支 HNSW 結構，它能從多個方向進行遍歷。這改善了異常值節點的擷取，增強了群集連通性，加速了建構速度，並降低了局部最小值的風險。第二個組成部分包含一種橋樑建構技術，它繞過了多餘的中間層，維持推論並彌補了雙分支結構所帶來的額外運算負擔。在各種基準和資料集上的實驗顯示，我們的演算法在準確度和速度上都優於原始的 HNSW。我們評估了電腦視覺 (CV) 和自然語言處理 (NLP) 中的六個資料集，顯示 NLP 中的召回率提高了 18%，CV 任務中提高了 30%，同時將建構時間縮短了 20%，並維持了推論速度。我們沒有在我們的演算法中觀察到任何取捨。消融研究顯示，基於 LID 的插入對效能的影響最大，其次是雙分支結構和橋樑建構組成部分。

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

摘要：已更新的醫療狀況診斷程序和治療途徑建議，以臨床實務指南 (CPG) 中的圖形流程記錄。為了有效使用 CPG 協助醫療專業人員進行治療決策，必須完整擷取指南知識，特別是圖表中的脈絡及其關係。雖然現有許多研究已利用這些指南為臨床決策支援系統建立規則基礎，但直接擷取 CPG 中包含的完整醫療知識的工作卻有限。這項研究提出了一種方法，以自動化擷取和節點與關係分類的方式，建立脈絡豐富、忠實的國家綜合癌症網路 (NCCN) 癌症 CPG 圖形數位表示。我們也透過使用大型語言模型 (LLM) 進行節點分類，實作模型的語意豐富化，分別在零次學習和少次學習中達到 80.86% 和 88.47% 的準確度。此外，我們引進了一種方法，透過運用 LLM 從指南知識庫中擷取相關子圖，來回答具有指南文字限制的自然語言問題。透過根據子圖路徑和語意資訊產生自然語言答案，我們降低了與 LLM 相關的錯誤答案和幻覺風險，確保了醫療領域問題解答中的事實準確性。

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

摘要：<paragraph>在學習個人化提供學習者巨大潛力的同時，高等教育中的現代實務需要更深入地考慮領域模型和學習情境，以開發有效的個人化演算法。本文介紹了一種創新的高等教育課程建模方法，該方法利用大型語言模型 (LLM) 來完成知識圖譜 (KG)，目的是建立個人化的學習路徑建議。我們的研究重點在於建模大學科目，並將它們的主題連結到對應的領域模型，從而能夠將來自不同院系和機構的學習模組整合到學生的學習路徑中。我們的做法核心是一個協作流程，其中 LLM 協助人類專家從講義材料中萃取高品質、細緻的主題。我們為大學模組和利害關係人開發了領域、課程和使用者模型。我們實作這個模型，從兩個研究模組建立 KG：嵌入式系統和使用 FPGA 的嵌入式系統開發。產生的 KG 建構了課程並將其連結到領域模型。我們透過定性專家回饋和定量圖形品質指標來評估我們的做法。領域專家驗證了模型的相關性和準確性，而圖形品質指標則測量了我們 KG 的結構特性。我們的結果顯示，LLM 輔助的圖形完成方法增強了跨學科連結相關課程的能力，以個人化學習體驗。專家回饋也顯示高度接受所提出的協作方法，用於概念萃取和分類。</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

摘要：儘管目前的大型語言模型 (LLM) 展現出令人印象深刻的能力，但執行複雜的真實世界任務仍需要工具學習。主流方法（例如 CoT/ReAct）依賴逐步工具呼叫與外部環境互動，但它們的感知範圍有限，且缺乏足夠的任務規劃能力。為了解決這些限制，其他研究引入了第一個基於搜尋的決策樹 (DFSDT)，但仍有很高的運算成本。在本文中，我們介紹了一種新穎的平行工具呼叫範例，DTA-Llama（分而合之 Llama）。首先，我們將傳統的基於樹的工具搜尋路徑轉換為有向無環圖 (DAG) 結構，產生高品質的平行工具呼叫資料集。然後在資料集上訓練 DTA-Llama，學習反覆將當前任務分成幾個平行工具呼叫子任務，並彙總呼叫結果以決定後續動作。此外，我們在將 DTA-Llama 應用於實際任務時，引入了一個受 Process/Threads 機制啟發的高效推論框架。實驗結果表明，我們的做法大幅提升了任務效能，同時減少了符號消耗和推論時間。使用我們方法的 Llama2-7B，可與 GPT-3.5 的官方平行函式呼叫方法相媲美。相關程式碼、資料集和模型權重可在 https://corn0205.github.io/ 取得

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

摘要：生成模型能力的提升有助于构建利用语言之外的多模态虚拟助手。通过观察人类执行多步骤任务，可以构建对正在执行的动作和任务有情境感知的助手，使他们能够根据这种理解提供帮助。在本文中，我们开发了一个具有多模态大语言模型的上下文感知指令任务助手 (InsTALL)，该助手利用在线视觉流（例如用户的屏幕共享或视频录制），并实时响应与手头任务相关的用户查询。为了提供有用的帮助，InsTALL 1) 在任务视频和配对文本数据上训练多模态模型，以及 2) 从视频数据中自动提取任务图，并在训练和推理时间利用它。我们展示了 InsTALL 在考虑用于多模态活动理解的提议子任务中实现了最先进的性能——任务识别 (TR)、动作识别 (AR)、下一个动作预测 (AP) 和计划预测 (PP)——并且在与自动错误识别相关的两个新子任务上优于现有的基准。

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, Raphaël Szymocha, Frédéric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

摘要：訓練任務導向對話系統既昂貴又耗時，
因為需要包含各種意圖的高品質資料集。
傳統方法依賴於廣泛的人工標註，而最近
的進展利用大型語言模型 (LLM) 來產生合成資料。
然而，這些方法通常需要自訂提示或程式碼，限制
非技術使用者的可及性。我們介紹 GraphTOD，一個端對端的
架構，簡化了任務導向對話的產生。使用者可以
透過指定 JSON 格式的轉換圖表來建立對話。我們的評估
證明 GraphTOD 在各種領域產生高品質對話，顯著降低資料集建立的成本和複雜性。

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

摘要：圖形結構的組合挑戰本質上很困難，因為它們的非線性和複雜性，通常會使傳統的計算方法無效或昂貴。然而，人類可以透過利用我們天生的空間推理能力的視覺表徵，更自然地應對這些挑戰。在本研究中，我們建議將圖形轉換為影像，以準確保留它們的高階結構特徵，從而革新用於解決圖形結構組合任務的表徵。這種方法允許機器在解決複雜的組合挑戰時模擬類人的處理。透過結合由多模態大型語言模型 (MLLM) 提供動力的創新範例與簡單的搜尋技術，我們旨在為解決此類問題開發一個新穎且有效的架構。我們對 MLLM 的研究涵蓋了各種基於圖形的任務，從組合問題（如影響力最大化）到網路拆除中的順序決策制定，以及解決六個基本的圖形相關問題。我們的研究結果表明，MLLM 表現出非凡的空間智能和處理這些問題的獨特能力，顯著提升了機器以類似人類認知的深度和直覺來理解和分析圖形結構資料的潛力。這些結果還暗示，將 MLLM 與簡單的最佳化策略整合在一起，可以形成一種新穎且有效的方法，用於在沒有複雜推導、計算需求量大的訓練和微調的情況下應對圖形結構的組合挑戰。

##### **A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**
2501.13958v1 by Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou, Zijin Hong, Junnan Dong, Hao Chen, Yi Chang, Xiao Huang

Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat text retrieval, face three critical
challenges: (i) complex query understanding in professional contexts, (ii)
difficulties in knowledge integration across distributed sources, and (iii)
system efficiency bottlenecks at scale. This survey presents a systematic
analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new
paradigm that revolutionizes domain-specific LLM applications. GraphRAG
addresses traditional RAG limitations through three key innovations: (i)
graph-structured knowledge representation that explicitly captures entity
relationships and domain hierarchies, (ii) efficient graph-based retrieval
techniques that enable context-preserving knowledge retrieval with multihop
reasoning ability, and (iii) structure-aware knowledge integration algorithms
that leverage retrieved knowledge for accurate and logical coherent generation
of LLMs. In this survey, we systematically analyze the technical foundations of
GraphRAG and examine current implementations across various professional
domains, identifying key technical challenges and promising research
directions. All the related resources of GraphRAG, including research papers,
open-source data, and projects, are collected for the community in
\textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的能力，但由於需要深入的專業知識，因此將其應用於專業領域仍具有挑戰性。檢索增強生成 (RAG) 已成為一種有前途的解決方案，可通過無縫整合外部知識庫來客製化 LLM 以適用於專業領域，從而在推理過程中即時存取特定領域的專業知識。儘管有其潛力，但基於平面文字檢索的傳統 RAG 系統面臨三項關鍵挑戰：(i) 在專業情境中進行複雜的查詢理解，(ii) 難以整合分散來源的知識，以及 (iii) 系統效率瓶頸會隨著規模擴大而產生。本調查系統性地分析了圖形化檢索增強生成 (GraphRAG) 的技術基礎，GraphRAG 是一個新的典範，它徹底改變了特定領域的 LLM 應用。GraphRAG 透過三項關鍵創新來解決傳統 RAG 的限制：(i) 圖形結構化的知識表述，明確擷取實體關係和領域階層，(ii) 有效的圖形化檢索技術，可進行保留脈絡的知識檢索，並具備多跳推理能力，以及 (iii) 結構感知知識整合演算法，可利用檢索到的知識來進行 LLM 的準確且邏輯一致的生成。在本調查中，我們系統性地分析了 GraphRAG 的技術基礎，並檢視了在各種專業領域中的現有實作，找出關鍵技術挑戰和有前景的研究方向。所有 GraphRAG 的相關資源，包括研究論文、開放原始碼資料和專案，都已在 \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} 中為社群收集。

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v2 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

摘要：<paragraph>在社交媒體上對抗錯誤資訊，偵測有組織的政治宣傳活動至關重要。現有的此類有組織行動識別方法，大多採用網路科學、圖形機器學習和自然語言處理的技術。它們的最終目標是分析使用者之間的關係和互動（例如轉發），以及他們貼文的文字相似性。儘管這些方法在辨識草根運動宣傳活動方面很有效，但它們面臨嚴峻的挑戰，特別是可用訓練資料集中的類別不平衡。為了減輕這個問題，最近的方法通常訴諸於資料擴充或增加正向樣本數量，但在現實世界中可能並非總是可行或足夠。本文採取不同的途徑，我們提出了一個基於大型語言模型 (LLM) 的辨識草根運動宣傳活動的新架構，並引入了平衡檢索擴充產生 (Balanced RAG) 組件。我們的做法首先將有關貼文（在我們的案例中是推文）的文字資訊和社交網路的使用者互動作為輸入，輸入到語言模型中。然後，透過提示工程和提出的平衡檢索擴充產生方法，它有效地偵測 X（Twitter）上協調的不實資訊宣傳活動。提出的架構不需要任何語言模型的訓練或微調。相反地，透過策略性地利用提示工程和平衡檢索擴充產生方法的優勢，它使大型語言模型能夠克服類別不平衡的影響，並有效地識別協調的政治宣傳活動。實驗結果證明，透過整合提出的提示工程和平衡檢索擴充產生方法，我們的架構優於傳統的基於圖形的基準，在精確度、召回率和 F1 分數方面獲得 2x-3x 的改進。</paragraph>

