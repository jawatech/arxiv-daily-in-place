{"2502.15631": {"publish_time": "2025-02-21", "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer", "paper_summary": "Large language models have demonstrated remarkable progress in mathematical\nreasoning, leveraging chain-of-thought and test-time compute scaling. However,\nmany open questions remain regarding the interplay between reasoning token\nusage and accuracy gains. In particular, when comparing models across\ngenerations, it is unclear whether improved performance results from longer\nreasoning chains or more efficient reasoning. We systematically analyze\nchain-of-thought length across o1-mini and o3-mini variants on the Omni-MATH\nbenchmark, finding that o3-mini (m) achieves superior accuracy without\nrequiring longer reasoning chains than o1-mini. Moreover, we show that accuracy\ngenerally declines as reasoning chains grow across all models and compute\nsettings, even when controlling for difficulty of the questions. This accuracy\ndrop is significantly smaller in more proficient models, suggesting that new\ngenerations of reasoning models use test-time compute more effectively.\nFinally, we highlight that while o3-mini (h) achieves a marginal accuracy gain\nover o3-mini (m), it does so by allocating substantially more reasoning tokens\nacross all problems, even the ones that o3-mini (m) can already solve. These\nfindings provide new insights into the relationship between model capability\nand reasoning length, with implications for efficiency, scaling, and evaluation\nmethodologies.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u6578\u5b78\u63a8\u7406\u65b9\u9762\u5c55\u793a\u4e86\u975e\u51e1\u7684\u9032\u5c55\uff0c\u5229\u7528\u601d\u7dad\u93c8\u548c\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u7e2e\u653e\u3002\u7136\u800c\uff0c\u95dc\u65bc\u63a8\u7406\u7b26\u865f\u4f7f\u7528\u548c\u6e96\u78ba\u6027\u63d0\u5347\u4e4b\u9593\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ecd\u7136\u5b58\u5728\u8a31\u591a\u672a\u89e3\u6c7a\u7684\u554f\u984c\u3002\u7279\u5225\u662f\uff0c\u5728\u6bd4\u8f03\u4e0d\u540c\u4e16\u4ee3\u7684\u6a21\u578b\u6642\uff0c\u5c1a\u4e0d\u6e05\u695a\u6539\u5584\u7684\u6548\u80fd\u662f\u6e90\u81ea\u66f4\u9577\u7684\u63a8\u7406\u93c8\u9084\u662f\u66f4\u6709\u6548\u7684\u63a8\u7406\u3002\u6211\u5011\u7cfb\u7d71\u6027\u5730\u5206\u6790\u4e86 Omni-MATH \u57fa\u6e96\u4e0a o1-mini \u548c o3-mini \u8b8a\u9ad4\u7684\u601d\u7dad\u93c8\u9577\u5ea6\uff0c\u767c\u73fe o3-mini (m) \u5728\u4e0d\u9700\u8981\u6bd4 o1-mini \u66f4\u9577\u7684\u63a8\u7406\u93c8\u7684\u60c5\u6cc1\u4e0b\u9054\u5230\u4e86\u66f4\u9ad8\u7684\u6e96\u78ba\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\uff0c\u5373\u4f7f\u5728\u63a7\u5236\u554f\u984c\u96e3\u5ea6\u7684\u60c5\u6cc1\u4e0b\uff0c\u6e96\u78ba\u6027\u901a\u5e38\u6703\u96a8\u8457\u6240\u6709\u6a21\u578b\u548c\u904b\u7b97\u8a2d\u5b9a\u7684\u63a8\u7406\u93c8\u589e\u9577\u800c\u4e0b\u964d\u3002\u5728\u66f4\u719f\u7df4\u7684\u6a21\u578b\u4e2d\uff0c\u9019\u7a2e\u6e96\u78ba\u6027\u4e0b\u964d\u5e45\u5ea6\u986f\u8457\u8f03\u5c0f\uff0c\u9019\u8868\u660e\u65b0\u4e00\u4ee3\u63a8\u7406\u6a21\u578b\u66f4\u6709\u6548\u5730\u4f7f\u7528\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5f37\u8abf\uff0c\u5118\u7ba1 o3-mini (h) \u6bd4 o3-mini (m) \u7372\u5f97\u4e86\u908a\u969b\u6e96\u78ba\u6027\u63d0\u5347\uff0c\u4f46\u5b83\u662f\u5728\u6240\u6709\u554f\u984c\u4e0a\u5206\u914d\u4e86\u66f4\u591a\u63a8\u7406\u7b26\u865f\uff0c\u751a\u81f3\u5305\u62ec o3-mini (m) \u5df2\u7d93\u53ef\u4ee5\u89e3\u6c7a\u7684\u554f\u984c\u3002\u9019\u4e9b\u767c\u73fe\u63d0\u4f9b\u4e86\u5c0d\u6a21\u578b\u80fd\u529b\u548c\u63a8\u7406\u9577\u5ea6\u4e4b\u9593\u95dc\u4fc2\u7684\u65b0\u898b\u89e3\uff0c\u5c0d\u6548\u7387\u3001\u7e2e\u653e\u548c\u8a55\u4f30\u65b9\u6cd5\u6709\u5f71\u97ff\u3002", "author": "Marthe Ballon et.al.", "authors": "Marthe Ballon, Andres Algaba, Vincent Ginis", "id": "2502.15631v1", "paper_url": "http://arxiv.org/abs/2502.15631v1", "repo": "null"}}