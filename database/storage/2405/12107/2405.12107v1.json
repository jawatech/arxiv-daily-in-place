{"2405.12107": {"publish_time": "2024-05-20", "title": "Imp: Highly Capable Large Multimodal Models for Mobile Devices", "paper_summary": "By harnessing the capabilities of large language models (LLMs), recent large\nmultimodal models (LMMs) have shown remarkable versatility in open-world\nmultimodal understanding. Nevertheless, they are usually parameter-heavy and\ncomputation-intensive, thus hindering their applicability in\nresource-constrained scenarios. To this end, several lightweight LMMs have been\nproposed successively to maximize the capabilities under constrained scale\n(e.g., 3B). Despite the encouraging results achieved by these methods, most of\nthem only focus on one or two aspects of the design space, and the key design\nchoices that influence model capability have not yet been thoroughly\ninvestigated. In this paper, we conduct a systematic study for lightweight LMMs\nfrom the aspects of model architecture, training strategy, and training data.\nBased on our findings, we obtain Imp -- a family of highly capable LMMs at the\n2B-4B scales. Notably, our Imp-3B model steadily outperforms all the existing\nlightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs\nat the 13B scale. With low-bit quantization and resolution reduction\ntechniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile\nchip with a high inference speed of about 13 tokens/s.", "paper_summary_zh": "<paragraph>\u900f\u904e\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u80fd\u529b\uff0c\u6700\u8fd1\u7684\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u5728\u958b\u653e\u4e16\u754c\u591a\u6a21\u614b\u7406\u89e3\u4e2d\u5c55\u73fe\u4e86\u9a5a\u4eba\u7684\u591a\u529f\u80fd\u6027\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u5b83\u5011\u901a\u5e38\u53c3\u6578\u7e41\u591a\u4e14\u8a08\u7b97\u5bc6\u96c6\uff0c\u56e0\u6b64\u963b\u7919\u4e86\u5b83\u5011\u5728\u8cc7\u6e90\u53d7\u9650\u5834\u666f\u4e2d\u7684\u61c9\u7528\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u5df2\u7d93\u9678\u7e8c\u63d0\u51fa\u4e86\u5e7e\u7a2e\u8f15\u91cf\u7d1a LMM\uff0c\u4ee5\u6700\u5927\u5316\u53d7\u9650\u898f\u6a21\uff08\u4f8b\u5982 3B\uff09\u4e0b\u7684\u80fd\u529b\u3002\u5118\u7ba1\u9019\u4e9b\u65b9\u6cd5\u53d6\u5f97\u4e86\u4ee4\u4eba\u9f13\u821e\u7684\u6210\u679c\uff0c\u4f46\u5b83\u5011\u5927\u591a\u53ea\u95dc\u6ce8\u8a2d\u8a08\u7a7a\u9593\u7684\u4e00\u500b\u6216\u5169\u500b\u65b9\u9762\uff0c\u800c\u5f71\u97ff\u6a21\u578b\u80fd\u529b\u7684\u95dc\u9375\u8a2d\u8a08\u9078\u64c7\u5c1a\u672a\u5f97\u5230\u5fb9\u5e95\u7814\u7a76\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f9e\u6a21\u578b\u67b6\u69cb\u3001\u8a13\u7df4\u7b56\u7565\u548c\u8a13\u7df4\u6578\u64da\u7b49\u65b9\u9762\u5c0d\u8f15\u91cf\u7d1a LMM \u9032\u884c\u4e86\u7cfb\u7d71\u6027\u7814\u7a76\u3002\u6839\u64da\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\uff0c\u6211\u5011\u7372\u5f97\u4e86 Imp\u2014\u2014\u4e00\u7cfb\u5217\u5728 2B-4B \u898f\u6a21\u4e0a\u5177\u6709\u9ad8\u5ea6\u80fd\u529b\u7684 LMM\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684 Imp-3B \u6a21\u578b\u7a69\u5b9a\u5730\u512a\u65bc\u6240\u6709\u73fe\u6709\u985e\u4f3c\u898f\u6a21\u7684\u8f15\u91cf\u7d1a LMM\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86 13B \u898f\u6a21\u7684\u6700\u65b0 LMM\u3002\u900f\u904e\u4f4e\u4f4d\u5143\u91cf\u5316\u548c\u89e3\u6790\u5ea6\u964d\u4f4e\u6280\u8853\uff0c\u6211\u5011\u7684 Imp \u6a21\u578b\u53ef\u4ee5\u90e8\u7f72\u5728 Qualcomm Snapdragon 8Gen3 \u884c\u52d5\u6676\u7247\u4e0a\uff0c\u5177\u6709\u7d04 13 \u500b\u7b26\u865f/\u79d2\u7684\u9ad8\u63a8\u8ad6\u901f\u5ea6\u3002</paragraph>", "author": "Zhenwei Shao et.al.", "authors": "Zhenwei Shao, Zhou Yu, Jun Yu, Xuecheng Ouyang, Lihao Zheng, Zhenbiao Gai, Mingyang Wang, Jiajun Ding", "id": "2405.12107v1", "paper_url": "http://arxiv.org/abs/2405.12107v1", "repo": "null"}}