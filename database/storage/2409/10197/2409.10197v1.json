{"2409.10197": {"publish_time": "2024-09-16", "title": "Fit and Prune: Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models", "paper_summary": "Recent progress in Multimodal Large Language Models(MLLMs) often use large\nimage tokens to compensate the visual shortcoming of MLLMs, which not only\nexhibits obvious redundancy but also greatly exacerbates the already high\ncomputation. Token pruning is an effective solution for speeding up MLLMs, but\nwhen and how to drop tokens still remains a challenge. In this paper, we\npropose a novel and training-free approach for the effective visual token\npruning of MLLMs, termed FitPrune, which can quickly produce a complete pruning\nrecipe for MLLMs according to a pre-defined budget. Specifically, FitPrune\nconsiders token pruning as a statistical problem of MLLM and its objective is\nto find out an optimal pruning scheme that can minimize the divergence of the\nattention distributions before and after pruning. In practice, FitPrune can be\nquickly accomplished based on the attention statistics from a small batch of\ninference data, avoiding the expensive trials of MLLMs. According to the\npruning recipe, an MLLM can directly remove the redundant visual tokens of\ndifferent examples during inference. To validate FitPrune, we apply it to a set\nof recent MLLMs, including LLaVA-1.5, LLaVA-HR and LLaVA-NEXT, and conduct\nextensive experiments on a set of benchmarks. The experimental results show\nthat our FitPrune can not only reduce the computational complexity to a large\nextent, while retaining high performance, e.g., -54.9% FLOPs for LLaVA-NEXT\nwith only 0.5% accuracy drop. Notably, the pruning recipe can be obtained in\nabout 5 minutes. Our code is available at https://github.com/ywh187/FitPrune.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b (MLLM) \u7684\u6700\u65b0\u8fdb\u5c55\u7ecf\u5e38\u4f7f\u7528\u5927\u578b\u56fe\u50cf\u6807\u8bb0\u6765\u5f25\u8865 MLLM \u7684\u89c6\u89c9\u7f3a\u9677\uff0c\u8fd9\u4e0d\u4ec5\u8868\u73b0\u51fa\u660e\u663e\u7684\u5197\u4f59\uff0c\u800c\u4e14\u8fd8\u6781\u5927\u5730\u52a0\u5267\u4e86\u672c\u5df2\u5f88\u9ad8\u7684\u8ba1\u7b97\u91cf\u3002\u6807\u8bb0\u526a\u679d\u662f\u52a0\u901f MLLM \u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u4e22\u5f03\u6807\u8bb0\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6709\u6548\u5730\u5bf9 MLLM \u7684\u89c6\u89c9\u6807\u8bb0\u8fdb\u884c\u526a\u679d\uff0c\u79f0\u4e3a FitPrune\uff0c\u5b83\u53ef\u4ee5\u6839\u636e\u9884\u5b9a\u4e49\u7684\u9884\u7b97\u5feb\u901f\u751f\u6210 MLLM \u7684\u5b8c\u6574\u526a\u679d\u65b9\u6848\u3002\u5177\u4f53\u6765\u8bf4\uff0cFitPrune \u5c06\u6807\u8bb0\u526a\u679d\u89c6\u4e3a MLLM \u7684\u7edf\u8ba1\u95ee\u9898\uff0c\u5176\u76ee\u6807\u662f\u627e\u51fa\u4e00\u79cd\u6700\u4f18\u526a\u679d\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u53ef\u4ee5\u6700\u5c0f\u5316\u526a\u679d\u524d\u540e\u6ce8\u610f\u529b\u5206\u5e03\u7684\u5dee\u5f02\u3002\u5728\u5b9e\u8df5\u4e2d\uff0cFitPrune \u53ef\u4ee5\u6839\u636e\u4e00\u5c0f\u6279\u63a8\u7406\u6570\u636e\u7684\u6ce8\u610f\u529b\u7edf\u8ba1\u6570\u636e\u5feb\u901f\u5b8c\u6210\uff0c\u907f\u514d\u4e86\u5bf9 MLLM \u8fdb\u884c\u6602\u8d35\u7684\u8bd5\u9a8c\u3002\u6839\u636e\u526a\u679d\u65b9\u6848\uff0cMLLM \u53ef\u4ee5\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u79fb\u9664\u4e0d\u540c\u793a\u4f8b\u7684\u5197\u4f59\u89c6\u89c9\u6807\u8bb0\u3002\u4e3a\u4e86\u9a8c\u8bc1 FitPrune\uff0c\u6211\u4eec\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u7ec4\u6700\u65b0\u7684 MLLM\uff0c\u5305\u62ec LLaVA-1.5\u3001LLaVA-HR \u548c LLaVA-NEXT\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684 FitPrune \u4e0d\u4ec5\u53ef\u4ee5\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u5f88\u5927\u7a0b\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u4f8b\u5982\uff0cLLaVA-NEXT \u7684 FLOP \u51cf\u5c11\u4e86 -54.9%\uff0c\u800c\u51c6\u786e\u5ea6\u4ec5\u4e0b\u964d\u4e86 0.5%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u526a\u679d\u65b9\u6848\u53ef\u4ee5\u5728\u5927\u7ea6 5 \u5206\u949f\u5185\u83b7\u5f97\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 https://github.com/ywh187/FitPrune \u83b7\u5f97\u3002", "author": "Weihao Ye et.al.", "authors": "Weihao Ye, Qiong Wu, Wenhao Lin, Yiyi Zhou", "id": "2409.10197v1", "paper_url": "http://arxiv.org/abs/2409.10197v1", "repo": "null"}}