{"2501.18532": {"publish_time": "2025-01-30", "title": "Differentially Private Steering for Large Language Model Alignment", "paper_summary": "Aligning Large Language Models (LLMs) with human values and away from\nundesirable behaviors (such as hallucination) has become increasingly\nimportant. Recently, steering LLMs towards a desired behavior via activation\nediting has emerged as an effective method to mitigate harmful generations at\ninference-time. Activation editing modifies LLM representations by preserving\ninformation from positive demonstrations (e.g., truthful) and minimising\ninformation from negative demonstrations (e.g., hallucinations). When these\ndemonstrations come from a private dataset, the aligned LLM may leak private\ninformation contained in those private samples. In this work, we present the\nfirst study of aligning LLM behavior with private datasets. Our work proposes\nthe \\textit{\\underline{P}rivate \\underline{S}teering for LLM\n\\underline{A}lignment (PSA)} algorithm to edit LLM activations with\ndifferential privacy (DP) guarantees. We conduct extensive experiments on seven\ndifferent benchmarks with open-source LLMs of different sizes (0.5B to 7B) and\nmodel families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSA\nachieves DP guarantees for LLM alignment with minimal loss in performance,\nincluding alignment metrics, open-ended text generation quality, and\ngeneral-purpose reasoning. We also develop the first Membership Inference\nAttack (MIA) for evaluating and auditing the empirical privacy for the problem\nof LLM steering via activation editing. Our attack is tailored for activation\nediting and relies solely on the generated texts without their associated\nprobabilities. Our experiments support the theoretical guarantees by showing\nimproved guarantees for our \\textit{PSA} algorithm compared to several existing\nnon-private techniques.", "paper_summary_zh": "<paragraph>\u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u50f9\u503c\u89c0\u4fdd\u6301\u4e00\u81f4\uff0c\u4e26\u9060\u96e2\u4e0d\u826f\u884c\u70ba\uff08\u4f8b\u5982\u5e7b\u89ba\uff09\u5df2\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u6700\u8fd1\uff0c\u901a\u904e\u6fc0\u6d3b\u7de8\u8f2f\u5c07 LLM \u5f15\u5c0e\u81f3\u6240\u9700\u884c\u70ba\u5df2\u6210\u70ba\u5728\u63a8\u7406\u6642\u6e1b\u8f15\u6709\u5bb3\u751f\u6210\u7684\u6709\u6548\u65b9\u6cd5\u3002\u6fc0\u6d3b\u7de8\u8f2f\u901a\u904e\u4fdd\u7559\u4f86\u81ea\u6b63\u9762\u6f14\u793a\uff08\u4f8b\u5982\u771f\u5be6\uff09\u7684\u4fe1\u606f\u4e26\u6700\u5927\u7a0b\u5ea6\u5730\u6e1b\u5c11\u4f86\u81ea\u8ca0\u9762\u6f14\u793a\uff08\u4f8b\u5982\u5e7b\u89ba\uff09\u7684\u4fe1\u606f\u4f86\u4fee\u6539 LLM \u8868\u793a\u3002\u7576\u9019\u4e9b\u6f14\u793a\u4f86\u81ea\u79c1\u6709\u6578\u64da\u96c6\u6642\uff0c\u5c0d\u9f4a\u7684 LLM \u53ef\u80fd\u6703\u6d29\u9732\u9019\u4e9b\u79c1\u6709\u6a23\u672c\u4e2d\u5305\u542b\u7684\u79c1\u6709\u4fe1\u606f\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5c07 LLM \u884c\u70ba\u8207\u79c1\u6709\u6578\u64da\u96c6\u5c0d\u9f4a\u7684\u7b2c\u4e00\u9805\u7814\u7a76\u3002\u6211\u5011\u7684\u7814\u7a76\u63d0\u51fa\u4e86\\textit{\\underline{P}rivate \\underline{S}teering for LLM \\underline{A}lignment (PSA)} \u6f14\u7b97\u6cd5\uff0c\u4ee5\u7de8\u8f2f\u5177\u6709\u5dee\u5206\u96b1\u79c1 (DP) \u4fdd\u8b49\u7684 LLM \u6fc0\u6d3b\u3002\u6211\u5011\u5c0d\u4e03\u500b\u4e0d\u540c\u7684\u57fa\u6e96\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u5176\u4e2d\u5305\u542b\u4e0d\u540c\u5927\u5c0f\uff080.5B \u5230 7B\uff09\u548c\u6a21\u578b\u7cfb\u5217\uff08LlaMa\u3001Qwen\u3001Mistral \u548c Gemma\uff09\u7684\u958b\u6e90 LLM\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cPSA \u5728 LLM \u5c0d\u9f4a\u65b9\u9762\u5be6\u73fe\u4e86 DP \u4fdd\u8b49\uff0c\u540c\u6642\u5728\u6027\u80fd\u65b9\u9762\u640d\u5931\u6700\u5c0f\uff0c\u5305\u62ec\u5c0d\u9f4a\u6307\u6a19\u3001\u958b\u653e\u5f0f\u6587\u672c\u751f\u6210\u8cea\u91cf\u548c\u901a\u7528\u63a8\u7406\u3002\u6211\u5011\u9084\u958b\u767c\u4e86\u7b2c\u4e00\u500b\u6210\u54e1\u63a8\u8ad6\u653b\u64ca (MIA)\uff0c\u7528\u65bc\u8a55\u4f30\u548c\u5be9\u8a08\u901a\u904e\u6fc0\u6d3b\u7de8\u8f2f\u9032\u884c LLM \u5f15\u5c0e\u7684\u7d93\u9a57\u96b1\u79c1\u3002\u6211\u5011\u7684\u653b\u64ca\u5c08\u9580\u91dd\u5c0d\u6fc0\u6d3b\u7de8\u8f2f\uff0c\u4e26\u4e14\u50c5\u4f9d\u8cf4\u65bc\u751f\u6210\u7684\u6587\u672c\uff0c\u800c\u4e0d\u9700\u8981\u5b83\u5011\u95dc\u806f\u7684\u6a5f\u7387\u3002\u6211\u5011\u7684\u5be6\u9a57\u901a\u904e\u5c55\u793a\u8207\u591a\u7a2e\u73fe\u6709\u7684\u975e\u79c1\u6709\u6280\u8853\u76f8\u6bd4\uff0c\u6211\u5011\u7684\\textit{PSA} \u6f14\u7b97\u6cd5\u5177\u6709\u66f4\u597d\u7684\u4fdd\u8b49\uff0c\u4f86\u652f\u6301\u7406\u8ad6\u4fdd\u8b49\u3002</paragraph>", "author": "Anmol Goel et.al.", "authors": "Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal", "id": "2501.18532v1", "paper_url": "http://arxiv.org/abs/2501.18532v1", "repo": "https://github.com/ukplab/iclr2025-psa"}}