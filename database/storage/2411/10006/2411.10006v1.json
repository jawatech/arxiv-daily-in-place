{"2411.10006": {"publish_time": "2024-11-15", "title": "Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits", "paper_summary": "Large language models has catalyzed the development of personalized dialogue\nsystems, numerous role-playing conversational agents have emerged. While\nprevious research predominantly focused on enhancing the model's capability to\nfollow instructions by designing character profiles, neglecting the\npsychological factors that drive human conversations. In this paper, we propose\nOrca, a framework for data processing and training LLMs of custom characters by\nintegrating personality traits. Orca comprises four stages: (1) Personality\ntraits inferring, leverage LLMs to infer user's BigFive personality trait\nreports and scores. (2) Data Augment, simulate user's profile, background\nstory, and psychological activities. (3) Dataset construction,\npersonality-conditioned instruction prompting (PCIP) to stimulate LLMs. (4)\nModeling and Training, personality-conditioned instruction tuning (PTIT and\nPSIT), using the generated data to enhance existing open-source LLMs. We\nintroduce OrcaBench, the first benchmark for evaluating the quality of content\ngenerated by LLMs on social platforms across multiple scales. Our experiments\ndemonstrate that our proposed model achieves superior performance on this\nbenchmark, demonstrating its excellence and effectiveness in perceiving\npersonality traits that significantly improve role-playing abilities. Our Code\nis available at https://github.com/Aipura/Orca.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u50ac\u5316\u4e86\u4e2a\u4eba\u5316\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5f00\u53d1\uff0c\u6d8c\u73b0\u51fa\u4f17\u591a\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u4ee3\u7406\u3002\u867d\u7136\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u901a\u8fc7\u8bbe\u8ba1\u89d2\u8272\u6863\u6848\u6765\u589e\u5f3a\u6a21\u578b\u9075\u5faa\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u4f46\u5ffd\u7565\u4e86\u63a8\u52a8\u4eba\u7c7b\u5bf9\u8bdd\u7684\u5fc3\u7406\u56e0\u7d20\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Orca\uff0c\u4e00\u4e2a\u901a\u8fc7\u6574\u5408\u4eba\u683c\u7279\u8d28\u6765\u8fdb\u884c\u6570\u636e\u5904\u7406\u548c\u8bad\u7ec3\u81ea\u5b9a\u4e49\u89d2\u8272\u7684 LLM \u6846\u67b6\u3002Orca \u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a(1) \u4eba\u683c\u7279\u8d28\u63a8\u65ad\uff0c\u5229\u7528 LLM \u63a8\u65ad\u7528\u6237\u7684\u4e94\u5927\u4eba\u683c\u7279\u8d28\u62a5\u544a\u548c\u5206\u6570\u3002(2) \u6570\u636e\u589e\u5f3a\uff0c\u6a21\u62df\u7528\u6237\u7684\u4e2a\u4eba\u8d44\u6599\u3001\u80cc\u666f\u6545\u4e8b\u548c\u5fc3\u7406\u6d3b\u52a8\u3002(3) \u6570\u636e\u96c6\u6784\u5efa\uff0c\u4eba\u683c\u6761\u4ef6\u6307\u4ee4\u63d0\u793a (PCIP) \u6765\u523a\u6fc0 LLM\u3002(4) \u5efa\u6a21\u548c\u8bad\u7ec3\uff0c\u4eba\u683c\u6761\u4ef6\u6307\u4ee4\u8c03\u6574 (PTIT \u548c PSIT)\uff0c\u4f7f\u7528\u751f\u6210\u7684\u6570\u636e\u6765\u589e\u5f3a\u73b0\u6709\u7684\u5f00\u6e90 LLM\u3002\u6211\u4eec\u5f15\u5165\u4e86 OrcaBench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30 LLM \u5728\u793e\u4ea4\u5e73\u53f0\u4e0a\u8de8\u591a\u4e2a\u5c3a\u5ea6\u751f\u6210\u7684\u5185\u5bb9\u8d28\u91cf\u7684\u57fa\u51c6\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u6a21\u578b\u5728\u8fd9\u4e2a\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5b83\u5728\u611f\u77e5\u4eba\u683c\u7279\u8d28\u65b9\u9762\u7684\u5353\u8d8a\u6027\u548c\u6709\u6548\u6027\uff0c\u663e\u7740\u63d0\u9ad8\u4e86\u89d2\u8272\u626e\u6f14\u80fd\u529b\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 https://github.com/Aipura/Orca \u83b7\u5f97\u3002", "author": "Yuxuan Huang et.al.", "authors": "Yuxuan Huang", "id": "2411.10006v1", "paper_url": "http://arxiv.org/abs/2411.10006v1", "repo": "null"}}