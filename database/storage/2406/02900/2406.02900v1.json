{"2406.02900": {"publish_time": "2024-06-05", "title": "Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms", "paper_summary": "Reinforcement Learning from Human Feedback (RLHF) has been crucial to the\nrecent success of Large Language Models (LLMs), however, it is often a complex\nand brittle process. In the classical RLHF framework, a reward model is first\ntrained to represent human preferences, which is in turn used by an online\nreinforcement learning (RL) algorithm to optimize the LLM. A prominent issue\nwith such methods is \\emph{reward over-optimization} or \\emph{reward hacking},\nwhere performance as measured by the learned proxy reward model increases, but\ntrue quality plateaus or even deteriorates. Direct Alignment Algorithms (DDAs)\nlike Direct Preference Optimization have emerged as alternatives to the\nclassical RLHF pipeline by circumventing the reward modeling phase. However,\nalthough DAAs do not use a separate proxy reward model, they still commonly\ndeteriorate from over-optimization. While the so-called reward hacking\nphenomenon is not well-defined for DAAs, we still uncover similar trends: at\nhigher KL budgets, DAA algorithms exhibit similar degradation patterns to their\nclassic RLHF counterparts. In particular, we find that DAA methods deteriorate\nnot only across a wide range of KL budgets but also often before even a single\nepoch of the dataset is completed. Through extensive empirical experimentation,\nthis work formulates and formalizes the reward over-optimization or hacking\nproblem for DAAs and explores its consequences across objectives, training\nregimes, and model scales.", "paper_summary_zh": "\u5f37\u5316\u5b78\u7fd2\u5f9e\u4eba\u985e\u56de\u994b\uff08RLHF\uff09\u5df2\u7d93\u6210\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLMs\uff09\u6700\u8fd1\u6210\u529f\u7684\u95dc\u9375\uff0c\u7136\u800c\uff0c\u9019\u901a\u5e38\u662f\u4e00\u500b\u8907\u96dc\u4e14\u8106\u5f31\u7684\u904e\u7a0b\u3002\u5728\u7d93\u5178\u7684 RLHF \u6846\u67b6\u4e2d\uff0c\u9996\u5148\u8a13\u7df4\u4e00\u500b\u734e\u52f5\u6a21\u578b\u4f86\u8868\u793a\u4eba\u985e\u504f\u597d\uff0c\u7136\u5f8c\u7531\u5728\u7dda\u5f37\u5316\u5b78\u7fd2\uff08RL\uff09\u6f14\u7b97\u6cd5\u7528\u65bc\u6700\u4f73\u5316 LLM\u3002\u6b64\u985e\u65b9\u6cd5\u7684\u4e00\u500b\u986f\u8457\u554f\u984c\u662f\\emph{\u734e\u52f5\u904e\u5ea6\u6700\u4f73\u5316}\u6216\\emph{\u734e\u52f5\u7834\u89e3}\uff0c\u5176\u4e2d\u6839\u64da\u5df2\u5b78\u7fd2\u7684\u4ee3\u7406\u734e\u52f5\u6a21\u578b\u6e2c\u91cf\u7684\u6548\u80fd\u6703\u589e\u52a0\uff0c\u4f46\u771f\u6b63\u7684\u54c1\u8cea\u6703\u505c\u6eef\u751a\u81f3\u60e1\u5316\u3002\u76f4\u63a5\u5c0d\u9f4a\u6f14\u7b97\u6cd5\uff08DDA\uff09\uff0c\u4f8b\u5982\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\uff0c\u5df2\u4f5c\u70ba\u8ff4\u907f\u734e\u52f5\u5efa\u6a21\u968e\u6bb5\u7684\u7d93\u5178 RLHF \u7ba1\u7dda\u7684\u66ff\u4ee3\u65b9\u6848\u51fa\u73fe\u3002\u7136\u800c\uff0c\u5118\u7ba1 DDA \u4e0d\u4f7f\u7528\u55ae\u7368\u7684\u4ee3\u7406\u734e\u52f5\u6a21\u578b\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u666e\u904d\u56e0\u904e\u5ea6\u6700\u4f73\u5316\u800c\u60e1\u5316\u3002\u96d6\u7136\u6240\u8b02\u7684\u734e\u52f5\u7834\u89e3\u73fe\u8c61\u5c0d\u65bc DDA \u4f86\u8aaa\u4e26\u672a\u5b9a\u7fa9\u660e\u78ba\uff0c\u4f46\u6211\u5011\u4ecd\u7136\u767c\u73fe\u985e\u4f3c\u7684\u8da8\u52e2\uff1a\u5728\u8f03\u9ad8\u7684 KL \u9810\u7b97\u4e0b\uff0cDAA \u6f14\u7b97\u6cd5\u6703\u8868\u73fe\u51fa\u8207\u5176\u7d93\u5178 RLHF \u5c0d\u61c9\u9805\u985e\u4f3c\u7684\u8870\u9000\u6a21\u5f0f\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u767c\u73fe DAA \u65b9\u6cd5\u4e0d\u50c5\u5728\u5ee3\u6cdb\u7684 KL \u9810\u7b97\u4e2d\u60e1\u5316\uff0c\u800c\u4e14\u901a\u5e38\u751a\u81f3\u5728\u8cc7\u6599\u96c6\u7684\u55ae\u500b\u4e16\u4ee3\u5b8c\u6210\u4e4b\u524d\u5c31\u6703\u60e1\u5316\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u8b49\u5be6\u9a57\uff0c\u9019\u9805\u5de5\u4f5c\u5236\u5b9a\u4e26\u5f62\u5f0f\u5316\u4e86 DDA \u7684\u734e\u52f5\u904e\u5ea6\u6700\u4f73\u5316\u6216\u7834\u89e3\u554f\u984c\uff0c\u4e26\u63a2\u8a0e\u5176\u5c0d\u76ee\u6a19\u3001\u8a13\u7df4\u6a5f\u5236\u548c\u6a21\u578b\u898f\u6a21\u7684\u5f71\u97ff\u3002", "author": "Rafael Rafailov et.al.", "authors": "Rafael Rafailov, Yaswanth Chittepu, Ryan Park, Harshit Sikchi, Joey Hejna, Bradley Knox, Chelsea Finn, Scott Niekum", "id": "2406.02900v1", "paper_url": "http://arxiv.org/abs/2406.02900v1", "repo": "null"}}