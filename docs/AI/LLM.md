
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-24**|**I Could've Asked That: Reformulating Unanswerable Questions**|Wenting Zhao et.al.|[2407.17469v1](http://arxiv.org/abs/2407.17469v1)|[link](https://github.com/wenting-zhao/couldask)|
|**2024-07-24**|**WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**|Wenting Zhao et.al.|[2407.17468v1](http://arxiv.org/abs/2407.17468v1)|null|
|**2024-07-24**|**CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**|Jiawei Gu et.al.|[2407.17467v1](http://arxiv.org/abs/2407.17467v1)|null|
|**2024-07-24**|**Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**|Massimo Passamonti et.al.|[2407.16890v1](http://arxiv.org/abs/2407.16890v1)|null|
|**2024-07-24**|**Fluent Student-Teacher Redteaming**|T. Ben Thompson et.al.|[2407.17447v1](http://arxiv.org/abs/2407.17447v1)|[link](https://github.com/Confirm-Solutions/flrt)|
|**2024-07-24**|**HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**|Zhenzhi Wang et.al.|[2407.17438v1](http://arxiv.org/abs/2407.17438v1)|[link](https://github.com/zhenzhiwang/humanvid)|
|**2024-07-24**|**(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**|Tianjin Huang et.al.|[2407.17412v1](http://arxiv.org/abs/2407.17412v1)|null|
|**2024-07-24**|**Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**|Yida Zhao et.al.|[2407.17406v1](http://arxiv.org/abs/2407.17406v1)|[link](https://github.com/zhaoyd1/dep_transformer_grammars)|
|**2024-07-24**|**Grammar-based Game Description Generation using Large Language Models**|Tsunehiko Tanaka et.al.|[2407.17404v1](http://arxiv.org/abs/2407.17404v1)|null|
|**2024-07-24**|**Systematic Reasoning About Relational Domains With Graph Neural Networks**|Irtaza Khalid et.al.|[2407.17396v1](http://arxiv.org/abs/2407.17396v1)|[link](https://github.com/erg0dic/gnn-sg)|
|**2024-07-24**|**CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**|Itamar Trainin et.al.|[2407.17390v1](http://arxiv.org/abs/2407.17390v1)|null|
|**2024-07-24**|**PERSONA: A Reproducible Testbed for Pluralistic Alignment**|Louis Castricato et.al.|[2407.17387v1](http://arxiv.org/abs/2407.17387v1)|null|
|**2024-07-24**|**A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**|Amirreza Naziri et.al.|[2407.17383v1](http://arxiv.org/abs/2407.17383v1)|null|
|**2024-07-24**|**MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**|Siwei Wu et.al.|[2407.17379v1](http://arxiv.org/abs/2407.17379v1)|null|
|**2024-07-24**|**Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**|Yuyang Ding et.al.|[2407.17349v1](http://arxiv.org/abs/2407.17349v1)|null|
|**2024-07-24**|**Label Alignment and Reassignment with Generalist Large Language Model for Enhanced Cross-Domain Named Entity Recognition**|Ke Bao et.al.|[2407.17344v1](http://arxiv.org/abs/2407.17344v1)|null|
|**2024-07-24**|**Preliminary study on artificial intelligence methods for cybersecurity threat detection in computer networks based on raw data packets**|Aleksander Ogonowski et.al.|[2407.17339v1](http://arxiv.org/abs/2407.17339v1)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?**|Leo Yu-Ho Lo et.al.|[2407.17291v1](http://arxiv.org/abs/2407.17291v1)|null|
|**2024-07-24**|**Improving ICD coding using Chapter based Named Entities and Attentional Models**|Abhijith R. Beeravolu et.al.|[2407.17230v1](http://arxiv.org/abs/2407.17230v1)|null|
|**2024-07-24**|**LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN prover**|Zijian Wu et.al.|[2407.17227v1](http://arxiv.org/abs/2407.17227v1)|null|
|**2024-07-24**|**Sublinear Regret for An Actor-Critic Algorithm in Continuous-Time Linear-Quadratic Reinforcement Learning**|Yilie Huang et.al.|[2407.17226v1](http://arxiv.org/abs/2407.17226v1)|null|
|**2024-07-24**|**Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles**|Zuoyin Tang et.al.|[2407.17211v1](http://arxiv.org/abs/2407.17211v1)|null|
|**2024-07-24**|**Nonverbal Immediacy Analysis in Education: A Multimodal Computational Model**|Uroš Petković et.al.|[2407.17209v1](http://arxiv.org/abs/2407.17209v1)|null|
|**2024-07-24**|**ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using 2D Labels Only**|Saad Lahlali et.al.|[2407.17197v1](http://arxiv.org/abs/2407.17197v1)|null|
|**2024-07-24**|**NarrationDep: Narratives on Social Media For Automatic Depression Detection**|Hamad Zogan et.al.|[2407.17174v1](http://arxiv.org/abs/2407.17174v1)|null|
|**2024-07-24**|**Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech SpeechT5 Model**|Jan Lehečka et.al.|[2407.17167v1](http://arxiv.org/abs/2407.17167v1)|null|
|**2024-07-24**|**Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**|Xiaoyu Tan et.al.|[2407.17164v1](http://arxiv.org/abs/2407.17164v1)|null|
|**2024-07-24**|**A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives**|Jan Lehečka et.al.|[2407.17160v1](http://arxiv.org/abs/2407.17160v1)|null|
|**2024-07-24**|**XMeCap: Meme Caption Generation with Sub-Image Adaptability**|Yuyan Chen et.al.|[2407.17152v1](http://arxiv.org/abs/2407.17152v1)|null|
|**2024-07-24**|**SimCT: A Simple Consistency Test Protocol in LLMs Development Lifecycle**|Fufangchen Zhao et.al.|[2407.17150v1](http://arxiv.org/abs/2407.17150v1)|null|
|**2024-07-24**|**SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**|Bernardo Consoli et.al.|[2407.17126v1](http://arxiv.org/abs/2407.17126v1)|null|
|**2024-07-24**|**Behavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?**|Anastasiia Sedova et.al.|[2407.17125v2](http://arxiv.org/abs/2407.17125v2)|null|
|**2024-07-24**|**Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective**|Jingren Liu et.al.|[2407.17120v1](http://arxiv.org/abs/2407.17120v1)|null|
|**2024-07-24**|**EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments**|Edward et.al.|[2407.17117v1](http://arxiv.org/abs/2407.17117v1)|null|
|**2024-07-24**|**Neural Dueling Bandits**|Arun Verma et.al.|[2407.17112v1](http://arxiv.org/abs/2407.17112v1)|null|
|**2024-07-24**|**PiPa++: Towards Unification of Domain Adaptive Semantic Segmentation via Self-supervised Learning**|Mu Chen et.al.|[2407.17101v1](http://arxiv.org/abs/2407.17101v1)|null|
|**2024-07-24**|**Towards Robust Knowledge Tracing Models via k-Sparse Attention**|Shuyan Huang et.al.|[2407.17097v1](http://arxiv.org/abs/2407.17097v1)|[link](https://github.com/pykt-team/pykt-toolkit)|
|**2024-07-24**|**OVR: A Dataset for Open Vocabulary Temporal Repetition Counting in Videos**|Debidatta Dwibedi et.al.|[2407.17085v1](http://arxiv.org/abs/2407.17085v1)|null|
|**2024-07-24**|**When Text and Images Don't Mix: Bias-Correcting Language-Image Similarity Scores for Anomaly Detection**|Adam Goodge et.al.|[2407.17083v1](http://arxiv.org/abs/2407.17083v1)|null|
|**2024-07-24**|**SAFETY-J: Evaluating Safety with Critique**|Yixiu Liu et.al.|[2407.17075v2](http://arxiv.org/abs/2407.17075v2)|null|
|**2024-07-24**|**Curriculum Negative Mining For Temporal Networks**|Ziyue Chen et.al.|[2407.17070v1](http://arxiv.org/abs/2407.17070v1)|[link](https://github.com/zziyue83/curnm)|
|**2024-07-24**|**High Efficiency Image Compression for Large Visual-Language Models**|Binzhe Li et.al.|[2407.17060v1](http://arxiv.org/abs/2407.17060v1)|null|
|**2024-07-24**|**Time Series Missing Imputation with Multivariate Radial Basis Function Neural Network**|Chanyoung Jung et.al.|[2407.17040v1](http://arxiv.org/abs/2407.17040v1)|null|
|**2024-07-24**|**Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference**|Jian Xu et.al.|[2407.17033v1](http://arxiv.org/abs/2407.17033v1)|null|
|**2024-07-24**|**From Internal Conflict to Contextual Adaptation of Language Models**|Sara Vera Marjanović et.al.|[2407.17023v1](http://arxiv.org/abs/2407.17023v1)|null|
|**2024-07-24**|**Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education**|Seungyoon Kim et.al.|[2407.17022v1](http://arxiv.org/abs/2407.17022v1)|[link](https://github.com/seungyoon1/llm-as-a-judge-human-eval)|
|**2024-07-24**|**Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism**|Anhao Zhao et.al.|[2407.17011v1](http://arxiv.org/abs/2407.17011v1)|null|
|**2024-07-24**|**SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**|Changchang Yin et.al.|[2407.16999v1](http://arxiv.org/abs/2407.16999v1)|[link](https://github.com/yinchangchang/sepsislab)|
|**2024-07-24**|**Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective**|Yujian Liu et.al.|[2407.16997v1](http://arxiv.org/abs/2407.16997v1)|[link](https://github.com/ucsb-nlp-chang/causal_unlearn)|
|**2024-07-24**|**A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs**|Jake R. Watts et.al.|[2407.16994v1](http://arxiv.org/abs/2407.16994v1)|null|
|**2024-07-24**|**Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model**|Lirui Zhao et.al.|[2407.16982v1](http://arxiv.org/abs/2407.16982v1)|null|
|**2024-07-24**|**Case-Enhanced Vision Transformer: Improving Explanations of Image Similarity with a ViT-based Similarity Metric**|Ziwei Zhao et.al.|[2407.16981v1](http://arxiv.org/abs/2407.16981v1)|null|
|**2024-07-24**|**Towards Aligning Language Models with Textual Feedback**|Saüc Abadal Lloret et.al.|[2407.16970v1](http://arxiv.org/abs/2407.16970v1)|[link](https://github.com/sauc-abadal/alt)|
|**2024-07-24**|**Stochastic Variance-Reduced Iterative Hard Thresholding in Graph Sparsity Optimization**|Derek Fox et.al.|[2407.16968v1](http://arxiv.org/abs/2407.16968v1)|[link](https://github.com/derek-fox/graph-scsg-iht)|
|**2024-07-24**|**Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**|Nur Ahmad Khatim et.al.|[2407.16962v1](http://arxiv.org/abs/2407.16962v1)|[link](https://github.com/inteligensi/dsapomdps.jl)|
|**2024-07-24**|**Cheems: Wonderful Matrices More Efficient and More Effective Architecture**|Jingze Shi et.al.|[2407.16958v2](http://arxiv.org/abs/2407.16958v2)|null|
|**2024-07-24**|**Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation**|Huimin Lu et.al.|[2407.16951v1](http://arxiv.org/abs/2407.16951v1)|null|
|**2024-07-24**|**Early screening of potential breakthrough technologies with enhanced interpretability: A patent-specific hierarchical attention network model**|Jaewoong Choi et.al.|[2407.16939v1](http://arxiv.org/abs/2407.16939v1)|null|
|**2024-07-24**|**Synthetic Trajectory Generation Through Convolutional Neural Networks**|Jesse Merhi et.al.|[2407.16938v1](http://arxiv.org/abs/2407.16938v1)|[link](https://github.com/jesse-merhi/CNN-TRAJGAN)|
|**2024-07-24**|**ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering**|Xiuying Chen et.al.|[2407.16931v1](http://arxiv.org/abs/2407.16931v1)|null|
|**2024-07-24**|**Train-Attention: Meta-Learning Where to Focus in Continual Knowledge Learning**|Yeongbin Seo et.al.|[2407.16920v1](http://arxiv.org/abs/2407.16920v1)|[link](https://github.com/ybseo-academy/TAALM)|
|**2024-07-23**|**Generation Constraint Scaling Can Mitigate Hallucination**|Georgios Kollias et.al.|[2407.16908v1](http://arxiv.org/abs/2407.16908v1)|null|
|**2024-07-23**|**$\textit{BenchIE}^{FL}$ : A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark**|Fabrice Lamarche et.al.|[2407.16860v1](http://arxiv.org/abs/2407.16860v1)|null|
|**2024-07-23**|**Synth4Kws: Synthesized Speech for User Defined Keyword Spotting in Low Resource Environments**|Pai Zhu et.al.|[2407.16840v1](http://arxiv.org/abs/2407.16840v1)|null|
|**2024-07-23**|**CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs**|Jihyung Kil et.al.|[2407.16837v1](http://arxiv.org/abs/2407.16837v1)|[link](https://github.com/raptormai/compbench)|
|**2024-07-23**|**A Multi-Level Hierarchical Framework for the Classification of Weather Conditions and Hazard Prediction**|Harish Neelam et.al.|[2407.16834v1](http://arxiv.org/abs/2407.16834v1)|null|
|**2024-07-23**|**Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach**|Zhuowan Li et.al.|[2407.16833v1](http://arxiv.org/abs/2407.16833v1)|null|
|**2024-07-23**|**Networks of Networks: Complexity Class Principles Applied to Compound AI Systems Design**|Jared Quincy Davis et.al.|[2407.16831v1](http://arxiv.org/abs/2407.16831v1)|null|
|**2024-07-23**|**Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems**|Timo Wilm et.al.|[2407.16828v1](http://arxiv.org/abs/2407.16828v1)|[link](https://github.com/otto-de/multitron)|
|**2024-07-23**|**AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**|Yuheng Wang et.al.|[2407.16822v1](http://arxiv.org/abs/2407.16822v1)|[link](https://github.com/ryan315/7pgd)|
|**2024-07-23**|**In Search for Architectures and Loss Functions in Multi-Objective Reinforcement Learning**|Mikhail Terekhov et.al.|[2407.16807v1](http://arxiv.org/abs/2407.16807v1)|null|
|**2024-07-23**|**Fusion and Cross-Modal Transfer for Zero-Shot Human Action Recognition**|Abhi Kamboj et.al.|[2407.16803v1](http://arxiv.org/abs/2407.16803v1)|null|
|**2024-07-23**|**Distribution-Aware Robust Learning from Long-Tailed Data with Noisy Labels**|Jae Soon Baik et.al.|[2407.16802v1](http://arxiv.org/abs/2407.16802v1)|[link](https://github.com/jaesoonbaik1213/dasc)|
|**2024-07-23**|**What Matters in Range View 3D Object Detection**|Benjamin Wilson et.al.|[2407.16789v1](http://arxiv.org/abs/2407.16789v1)|[link](https://github.com/benjaminrwilson/range-view-3d-detection)|
|**2024-07-23**|**VisMin: Visual Minimal-Change Understanding**|Rabiul Awal et.al.|[2407.16772v1](http://arxiv.org/abs/2407.16772v1)|null|
|**2024-07-23**|**Infinite Ends from Finite Samples: Open-Ended Goal Inference as Top-Down Bayesian Filtering of Bottom-Up Proposals**|Tan Zhi-Xuan et.al.|[2407.16770v1](http://arxiv.org/abs/2407.16770v1)|null|
|**2024-07-23**|**Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack**|Xiaoyue Xu et.al.|[2407.16695v1](http://arxiv.org/abs/2407.16695v1)|[link](https://github.com/ink-usc/lifelong-icl)|
|**2024-07-23**|**Explanation Regularisation through the Lens of Attributions**|Pedro Ferreira et.al.|[2407.16693v1](http://arxiv.org/abs/2407.16693v1)|null|
|**2024-07-23**|**Can Large Language Models Automatically Jailbreak GPT-4V?**|Yuanwei Wu et.al.|[2407.16686v1](http://arxiv.org/abs/2407.16686v1)|null|
|**2024-07-23**|**OpenDevin: An Open Platform for AI Software Developers as Generalist Agents**|Xingyao Wang et.al.|[2407.16741v1](http://arxiv.org/abs/2407.16741v1)|[link](https://github.com/opendevin/opendevin)|
|**2024-07-23**|**KAN or MLP: A Fairer Comparison**|Runpeng Yu et.al.|[2407.16674v1](http://arxiv.org/abs/2407.16674v1)|[link](https://github.com/yu-rp/kanbefair)|
|**2024-07-23**|**PLM-Net: Perception Latency Mitigation Network for Vision-Based Lateral Control of Autonomous Vehicles**|Aws Khalil et.al.|[2407.16740v1](http://arxiv.org/abs/2407.16740v1)|[link](https://github.com/awskhalil/oscar)|
|**2024-07-23**|**RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent**|Huiyu Xu et.al.|[2407.16667v1](http://arxiv.org/abs/2407.16667v1)|null|
|**2024-07-23**|**Towards scalable efficient on-device ASR with transfer learning**|Laxmi Pandey et.al.|[2407.16664v1](http://arxiv.org/abs/2407.16664v1)|null|
|**2024-07-23**|**A Survey of Text Style Transfer: Applications and Ethical Implications**|Sourabrata Mukherjee et.al.|[2407.16737v1](http://arxiv.org/abs/2407.16737v1)|null|
|**2024-07-23**|**Course-Correction: Safety Alignment Using Synthetic Preferences**|Rongwu Xu et.al.|[2407.16637v1](http://arxiv.org/abs/2407.16637v1)|null|
|**2024-07-23**|**Knowledge-driven AI-generated data for accurate and interpretable breast ultrasound diagnoses**|Haojun Yu et.al.|[2407.16634v1](http://arxiv.org/abs/2407.16634v1)|null|
|**2024-07-23**|**Semantic Change Characterization with LLMs using Rhetorics**|Jader Martins Camboim de Sá et.al.|[2407.16624v1](http://arxiv.org/abs/2407.16624v1)|null|
|**2024-07-23**|**Theoretical Analysis of Privacy Leakage in Trustworthy Federated Learning: A Perspective from Linear Algebra and Optimization Theory**|Xiaojin Zhang et.al.|[2407.16735v1](http://arxiv.org/abs/2407.16735v1)|null|
|**2024-07-23**|**Lawma: The Power of Specialization for Legal Tasks**|Ricardo Dominguez-Olmedo et.al.|[2407.16615v1](http://arxiv.org/abs/2407.16615v1)|null|
|**2024-07-23**|**No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots**|Alican Mertan et.al.|[2407.16613v1](http://arxiv.org/abs/2407.16613v1)|[link](https://github.com/mertan-a/no-brainer)|
|**2024-07-23**|**Local vs Global continual learning**|Giulia Lanzillotta et.al.|[2407.16611v1](http://arxiv.org/abs/2407.16611v1)|null|
|**2024-07-23**|**Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**|Daniela L. Ramos et.al.|[2407.16608v1](http://arxiv.org/abs/2407.16608v1)|null|
|**2024-07-23**|**Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?**|Jonathan Hayase et.al.|[2407.16607v2](http://arxiv.org/abs/2407.16607v2)|null|
|**2024-07-23**|**Shared Imagination: LLMs Hallucinate Alike**|Yilun Zhou et.al.|[2407.16604v1](http://arxiv.org/abs/2407.16604v1)|null|
|**2024-07-23**|**GenRec: A Flexible Data Generator for Recommendations**|Erica Coppolillo et.al.|[2407.16594v1](http://arxiv.org/abs/2407.16594v1)|null|
|**2024-07-23**|**A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**|Giorgos Lysandrou et.al.|[2407.16593v1](http://arxiv.org/abs/2407.16593v1)|null|
|**2024-07-23**|**TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback**|Eunseop Yoon et.al.|[2407.16574v1](http://arxiv.org/abs/2407.16574v1)|null|
|**2024-07-23**|**PyBench: Evaluating LLM Agent on various real-world coding tasks**|Yaolun Zhang et.al.|[2407.16732v1](http://arxiv.org/abs/2407.16732v1)|[link](https://github.com/mercury7353/pybench)|

#### Abstracts
##### **I Could've Asked That: Reformulating Unanswerable Questions**
2407.17469v1 by Wenting Zhao, Ge Gao, Claire Cardie, Alexander M. Rush

When seeking information from unfamiliar documents, users frequently pose
questions that cannot be answered by the documents. While existing large
language models (LLMs) identify these unanswerable questions, they do not
assist users in reformulating their questions, thereby reducing their overall
utility. We curate CouldAsk, an evaluation benchmark composed of existing and
new datasets for document-grounded question answering, specifically designed to
study reformulating unanswerable questions. We evaluate state-of-the-art
open-source and proprietary LLMs on CouldAsk. The results demonstrate the
limited capabilities of these models in reformulating questions. Specifically,
GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the
time, respectively. Error analysis shows that 62% of the unsuccessful
reformulations stem from the models merely rephrasing the questions or even
generating identical questions. We publicly release the benchmark and the code
to reproduce the experiments.

摘要：在從不熟悉的文檔中尋求資訊時，使用者經常會提出文檔無法回答的問題。雖然現有的大型語言模型 (LLM) 可以識別這些無法回答的問題，但它們並未協助使用者重新表述問題，因此降低了它們的整體效用。我們整理了 CouldAsk，這是一個評估基準，由現有和新的資料集組成，用於基於文檔的問答，特別設計用於研究重新表述無法回答的問題。我們在 CouldAsk 上評估了最先進的開源和專有 LLM。結果證明了這些模型在重新表述問題方面的能力有限。具體來說，GPT-4 和 Llama2-7B 分別僅在 26% 和 12% 的時間內成功重新表述問題。錯誤分析顯示，62% 的不成功重新表述源於模型僅僅重新表述問題，甚至產生相同的問題。我們公開發布基準和代碼以重現實驗。

##### **WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**
2407.17468v1 by Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, Abhilasha Ravichander, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi

While hallucinations of large language models (LLMs) prevail as a major
challenge, existing evaluation benchmarks on factuality do not cover the
diverse domains of knowledge that the real-world users of LLMs seek information
about. To bridge this gap, we introduce WildHallucinations, a benchmark that
evaluates factuality. It does so by prompting LLMs to generate information
about entities mined from user-chatbot conversations in the wild. These
generations are then automatically fact-checked against a systematically
curated knowledge source collected from web search. Notably, half of these
real-world entities do not have associated Wikipedia pages. We evaluate 118,785
generations from 15 LLMs on 7,919 entities. We find that LLMs consistently
hallucinate more on entities without Wikipedia pages and exhibit varying
hallucination rates across different domains. Finally, given the same base
models, adding a retrieval component only slightly reduces hallucinations but
does not eliminate hallucinations.

摘要：儘管大型語言模型 (LLM) 的幻覺盛行，成為一項重大挑戰，但現有的關於事實性的評估基準並未涵蓋 LLM 的真實使用者尋求資訊的各種知識領域。為了彌補這個差距，我們引入了 WildHallucinations，這是一個評估事實性的基準。它透過提示 LLM 產生從野外使用者聊天機器人對話中提取的實體資訊來做到這一點。然後根據從網路搜尋收集的系統化策展知識來源，自動對這些生成進行事實查核。值得注意的是，這些真實世界實體中有一半沒有關聯的維基百科頁面。我們評估了 15 個 LLM 在 7,919 個實體上產生的 118,785 個生成。我們發現 LLM 持續對沒有維基百科頁面的實體產生更多幻覺，並在不同領域表現出不同的幻覺率。最後，在給定相同的基礎模型的情況下，加入檢索元件僅能稍微減少幻覺，但無法消除幻覺。

##### **CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**
2407.17467v1 by Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan

Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Therefore, if we value the balance between efficiency and
effectiveness, CMR can be consider as the optimal mixture ratio.Through
extensive experiments, we ascertain the predictability of CMR, and propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.

摘要：大型語言模型 (LLM) 在各種任務中表現出色，但由於特定領域或專有語料庫有限，它們在專業領域的表現往往不佳。
持續預訓練 (CPT) 可透過導入新的特定領域或專有知識，同時重播一般語料庫來防止災難性遺忘，進而增強 LLM 的功能。然而，一般語料庫和特定領域語料庫的資料混合比例是根據經驗法則選擇的，導致實際訓練效率不佳。在此背景下，我們嘗試重新探討 LLM 在 CPT 引擎蓋下的擴充行為，並發現損失、混合比例和訓練代幣規模之間存在冪律關係。我們將一般功能和特定領域功能之間的權衡形式化，進而定義出一般資料和領域資料的明確臨界混合比例 (CMR)。CMR 在取得平衡後，可維持模型的一般能力並達成所需的領域轉移，確保對可用資源的最高利用率。因此，如果我們重視效率和效能之間的平衡，CMR 可以視為最佳混合比例。透過廣泛的實驗，我們確認了 CMR 的可預測性，並提出 CMR 擴充定律，並已證實其概括性。這些發現提供了實用的準則，用於最佳化特定領域的 LLM 訓練，同時確保一般和特定領域的效能，並有效管理訓練資源。

##### **Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**
2407.16890v1 by Massimo Passamonti

In this essay, I argue that explicit ethical machines, whose moral principles
are inferred through a bottom-up approach, are unable to replicate human-like
moral reasoning and cannot be considered moral agents. By utilizing Alan
Turing's theory of computation, I demonstrate that moral reasoning is
computationally intractable by these machines due to the halting problem. I
address the frontiers of machine ethics by formalizing moral problems into
'algorithmic moral questions' and by exploring moral psychology's dual-process
model. While the nature of Turing Machines theoretically allows artificial
agents to engage in recursive moral reasoning, critical limitations are
introduced by the halting problem, which states that it is impossible to
predict with certainty whether a computational process will halt. A thought
experiment involving a military drone illustrates this issue, showing that an
artificial agent might fail to decide between actions due to the halting
problem, which limits the agent's ability to make decisions in all instances,
undermining its moral agency.

摘要：在本文中，我主張通過自下而上方法推論出道德原則的明確道德機器，無法複製類人的道德推理，也不能被視為道德代理人。通過利用艾倫·圖靈的計算理論，我證明了由於停機問題，這些機器在計算上無法進行道德推理。我通過將道德問題形式化為「演算法道德問題」以及探索道德心理學的雙重過程模型，來探討機器倫理的邊界。雖然圖靈機的本質在理論上允許人工代理參與遞迴道德推理，但停機問題引入了關鍵限制，該問題指出不可能確定預測計算過程是否會停止。一個涉及軍事無人機的思想實驗說明了這個問題，表明人工代理可能會因為停機問題而無法在行動之間做出決定，這限制了代理人在所有情況下做出決定的能力，從而破壞了其道德代理。

##### **Fluent Student-Teacher Redteaming**
2407.17447v1 by T. Ben Thompson, Michael Sklar

Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. Users or security analysts
attempt to jailbreak or redteam these models with adversarial prompts which
cause compliance with requests. One attack method is to apply discrete
optimization techniques to the prompt. However, the resulting attack strings
are often gibberish text, easily filtered by defenders due to high measured
perplexity, and may fail for unseen tasks and/or well-tuned models. In this
work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.

摘要：許多公開可用的語言模型都經過安全性調整，以降低產生有毒或引發責任的文字的可能性。使用者或安全分析師嘗試使用對抗性提示來破解或對這些模型進行紅隊測試，這會導致符合請求。一種攻擊方法是對提示套用離散最佳化技術。然而，產生的攻擊字串通常是無意義的文字，由於測量到的困惑度高，很容易被防禦者過濾掉，並且可能無法執行未見過的工作和/或調整良好的模型。在這項工作中，我們改進了現有演算法（主要是 GCG 和 BEAST），以對 Llama-2 和 Phi-3 等安全性調整模型發動強大且流暢的攻擊。我們的技術圍繞一種新的基於蒸餾的方法，它鼓勵受害者模型模擬中毒的微調，無論是在輸出機率或內部激活方面。為了鼓勵人類流暢的攻擊，我們在目標中加入多模型困惑度懲罰和重複懲罰。我們還透過允許插入代碼、交換代碼和刪除代碼，以及使用較長的攻擊序列來增強最佳化器的強度。由此產生的程序能夠可靠地破解最困難的目標模型，其提示看起來類似於人類編寫的提示。在 Advbench 上，我們對 Llama-2-7B、Llama-3-8B 和 Vicuna-7B 達到了 $>93$% 的攻擊成功率，同時維持模型測量的困惑度 $<33$；我們對 Phi-3 達到了 $95$% 的攻擊成功率，儘管困惑度較高。我們還找到了經過通用最佳化的單一流暢提示，它可以在 Llama-2-7B、Phi-3-mini 和 Vicuna-7B 中以前所未見的工作上引發 $>88$% 的合規性，並傳輸到其他黑盒模型。

##### **HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**
2407.17438v1 by Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Youqing Fang, Yuwei Guo, Wenran Liu, Jing Tan, Kai Chen, Tianfan Xue, Bo Dai, Dahua Lin

Human image animation involves generating videos from a character photo,
allowing user control and unlocking potential for video and movie production.
While recent approaches yield impressive results using high-quality training
data, the inaccessibility of these datasets hampers fair and transparent
benchmarking. Moreover, these approaches prioritize 2D human motion and
overlook the significance of camera motions in videos, leading to limited
control and unstable video generation.To demystify the training data, we
present HumanVid, the first large-scale high-quality dataset tailored for human
image animation, which combines crafted real-world and synthetic data. For the
real-world data, we compile a vast collection of copyright-free real-world
videos from the internet. Through a carefully designed rule-based filtering
strategy, we ensure the inclusion of high-quality videos, resulting in a
collection of 20K human-centric videos in 1080P resolution. Human and camera
motion annotation is accomplished using a 2D pose estimator and a SLAM-based
method. For the synthetic data, we gather 2,300 copyright-free 3D avatar assets
to augment existing available 3D assets. Notably, we introduce a rule-based
camera trajectory generation method, enabling the synthetic pipeline to
incorporate diverse and precise camera motion annotation, which can rarely be
found in real-world data. To verify the effectiveness of HumanVid, we establish
a baseline model named CamAnimate, short for Camera-controllable Human
Animation, that considers both human and camera motions as conditions. Through
extensive experimentation, we demonstrate that such simple baseline training on
our HumanVid achieves state-of-the-art performance in controlling both human
pose and camera motions, setting a new benchmark. Code and data will be
publicly available at \url{https://github.com/zhenzhiwang/HumanVid/}.

摘要：人類影像動畫涉及從角色照片產生影片，
讓使用者可以控制並解鎖影片和電影製作的潛力。
雖然最近的方法使用高品質訓練資料產生令人印象深刻的結果，
但這些資料集難以取得，阻礙了公平和透明的基準測試。
此外，這些方法優先考慮 2D 人類動作，
而忽略了影片中相機動作的重要性，導致控制受限且影片產生不穩定。
為了釐清訓練資料，我們提出 HumanVid，這是第一個針對人類影像動畫量身打造的大規模高品質資料集，
結合了精心製作的真實世界和合成資料。
對於真實世界資料，我們從網路上編制了大量免版權的真實世界影片。
透過精心設計的基於規則的過濾策略，我們確保納入高品質影片，
產生了 1080P 解析度的 20K 以人類為中心的影片集。
人類和相機動作註解是使用 2D 姿勢估計器和基於 SLAM 的方法完成的。
對於合成資料，我們收集了 2,300 個免版權的 3D 頭像資產來擴充現有的 3D 資產。
值得注意的是，我們引入了基於規則的相機軌跡產生方法，
使合成管線能夠納入多樣且精確的相機動作註解，這在真實世界資料中很少見。
為了驗證 HumanVid 的有效性，我們建立了一個名為 CamAnimate 的基準模型，簡稱 Camera-controllable Human Animation，
將人類和相機動作都視為條件。
透過廣泛的實驗，我們證明了在我們的 HumanVid 上進行這種簡單的基準訓練，
在控制人類姿勢和相機動作方面達到了最先進的效能，樹立了新的基準。
程式碼和資料將在 \url{https://github.com/zhenzhiwang/HumanVid/} 公開。

##### **(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**
2407.17412v1 by Tianjin Huang, Fang Meng, Li Shen, Fan Liu, Yulong Pei, Mykola Pechenizkiy, Shiwei Liu, Tianlong Chen

Large-scale neural networks have demonstrated remarkable performance in
different domains like vision and language processing, although at the cost of
massive computation resources. As illustrated by compression literature,
structural model pruning is a prominent algorithm to encourage model
efficiency, thanks to its acceleration-friendly sparsity patterns. One of the
key questions of structural pruning is how to estimate the channel
significance. In parallel, work on data-centric AI has shown that
prompting-based techniques enable impressive generalization of large language
models across diverse downstream tasks. In this paper, we investigate a
charming possibility - \textit{leveraging visual prompts to capture the channel
importance and derive high-quality structural sparsity}. To this end, we
propose a novel algorithmic framework, namely \texttt{PASS}. It is a tailored
hyper-network to take both visual prompts and network weight statistics as
input, and output layer-wise channel sparsity in a recurrent manner. Such
designs consider the intrinsic channel dependency between layers. Comprehensive
experiments across multiple network architectures and six datasets demonstrate
the superiority of \texttt{PASS} in locating good structural sparsity. For
example, at the same FLOPs level, \texttt{PASS} subnetworks achieve $1\%\sim
3\%$ better accuracy on Food101 dataset; or with a similar performance of
$80\%$ accuracy, \texttt{PASS} subnetworks obtain $0.35\times$ more speedup
than the baselines.

摘要：大型神经網路在不同的領域，例如視覺和語言處理中，展現了非凡的效能，儘管是以大量的運算資源為代價。正如壓縮文獻所說明的，結構模型剪枝是一種突出的演算法，用於提升模型效率，這要歸功於其有利於加速的稀疏模式。結構剪枝的關鍵問題之一是如何估計通道重要性。與此同時，資料中心 AI 的研究表明，基於提示的技術能夠讓大型語言模型在各種下游任務中進行令人印象深刻的泛化。在本文中，我們探討了一個迷人的可能性——利用視覺提示來擷取通道重要性，並推導出高品質的結構稀疏性。為此，我們提出了一個新穎的演算法架構，即 \texttt{PASS}。它是一個量身打造的超網路，用於將視覺提示和網路權重統計資料作為輸入，並以遞迴方式輸出逐層通道稀疏性。此類設計考慮了層之間的內在通道依賴性。跨多個網路架構和六個資料集的綜合實驗證明了 \texttt{PASS} 在定位良好結構稀疏性方面的優越性。例如，在相同的 FLOP 層級，\texttt{PASS} 子網路在 Food101 資料集上達到了 $1\%\sim 3\%$ 的更佳準確度；或者在具有相似的 $80\%$ 準確度效能下，\texttt{PASS} 子網路比基準快了 $0.35\times$ 倍。

##### **Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**
2407.17406v1 by Yida Zhao, Chao Lou, Kewei Tu

Syntactic Transformer language models aim to achieve better generalization
through simultaneously modeling syntax trees and sentences. While prior work
has been focusing on adding constituency-based structures to Transformers, we
introduce Dependency Transformer Grammars (DTGs), a new class of Transformer
language model with explicit dependency-based inductive bias. DTGs simulate
dependency transition systems with constrained attention patterns by modifying
attention masks, incorporate the stack information through relative positional
encoding, and augment dependency arc representation with a combination of token
embeddings and operation embeddings. When trained on a dataset of sentences
annotated with dependency trees, DTGs achieve better generalization while
maintaining comparable perplexity with Transformer language model baselines.
DTGs also outperform recent constituency-based models, showing that dependency
can better guide Transformer language models. Our code is released at
https://github.com/zhaoyd1/Dep_Transformer_Grammars.

摘要：句法轉換語言模型旨在透過同時對句法樹和句子進行建模來達成更好的概括。雖然先前的研究一直專注於在 Transformers 中加入基於成分的結構，但我們引入了依賴轉換語法 (DTG)，這是一種新的轉換語言模型類別，具有明確的基於依賴的歸納偏誤。DTG 模擬具有約束注意力模式的依賴轉換系統，透過修改注意力遮罩、透過相對位置編碼納入堆疊資訊，並結合標記嵌入和運算嵌入來擴充依賴弧表示。當在標記有依賴樹的句子資料集上進行訓練時，DTG 可在維持與轉換語言模型基準相當的困惑度的同時，達成更好的概括。DTG 也優於最近基於成分的模型，顯示依賴可以更好地引導轉換語言模型。我們的程式碼已在 https://github.com/zhaoyd1/Dep_Transformer_Grammars 發布。

##### **Grammar-based Game Description Generation using Large Language Models**
2407.17404v1 by Tsunehiko Tanaka, Edgar Simo-Serra

To lower the barriers to game design development, automated game design,
which generates game designs through computational processes, has been
explored. In automated game design, machine learning-based techniques such as
evolutionary algorithms have achieved success. Benefiting from the remarkable
advancements in deep learning, applications in computer vision and natural
language processing have progressed in level generation. However, due to the
limited amount of data in game design, the application of deep learning has
been insufficient for tasks such as game description generation. To pioneer a
new approach for handling limited data in automated game design, we focus on
the in-context learning of large language models (LLMs). LLMs can capture the
features of a task from a few demonstration examples and apply the capabilities
acquired during pre-training. We introduce the grammar of game descriptions,
which effectively structures the game design space, into the LLMs' reasoning
process. Grammar helps LLMs capture the characteristics of the complex task of
game description generation. Furthermore, we propose a decoding method that
iteratively improves the generated output by leveraging the grammar. Our
experiments demonstrate that this approach performs well in generating game
descriptions.

摘要：為了降低遊戲設計開發的門檻，自動化遊戲設計（透過運算程序產生遊戲設計）已經被廣泛探討。在自動化遊戲設計中，基於機器學習的技術（例如演化演算法）已取得成功。受益於深度學習的顯著進步，電腦視覺和自然語言處理的應用已在關卡生成方面取得進展。然而，由於遊戲設計中的數據量有限，深度學習的應用對於遊戲描述生成等任務來說還不足夠。為了在自動化遊戲設計中處理有限數據開創一種新方法，我們專注於大型語言模型 (LLM) 的語境學習。LLM 可以從少數示範範例中擷取任務的特徵，並應用預訓練期間習得的能力。我們將遊戲描述的語法（有效地建構遊戲設計空間）引入 LLM 的推理過程中。語法有助於 LLM 擷取遊戲描述生成這項複雜任務的特徵。此外，我們提出了一種解碼方法，透過利用語法反覆改善產生的輸出。我們的實驗證明，這種方法在產生遊戲描述方面表現良好。

##### **Systematic Reasoning About Relational Domains With Graph Neural Networks**
2407.17396v1 by Irtaza Khalid, Steven Schockaert

Developing models that can learn to reason is a notoriously challenging
problem. We focus on reasoning in relational domains, where the use of Graph
Neural Networks (GNNs) seems like a natural choice. However, previous work on
reasoning with GNNs has shown that such models tend to fail when presented with
test examples that require longer inference chains than those seen during
training. This suggests that GNNs lack the ability to generalize from training
examples in a systematic way, which would fundamentally limit their reasoning
abilities. A common solution is to instead rely on neuro-symbolic methods,
which are capable of reasoning in a systematic way by design. Unfortunately,
the scalability of such methods is often limited and they tend to rely on
overly strong assumptions, e.g.\ that queries can be answered by inspecting a
single relational path. In this paper, we revisit the idea of reasoning with
GNNs, showing that systematic generalization is possible as long as the right
inductive bias is provided. In particular, we argue that node embeddings should
be treated as epistemic states and that GNN should be parameterised
accordingly. We propose a simple GNN architecture which is based on this view
and show that it is capable of achieving state-of-the-art results. We
furthermore introduce a benchmark which requires models to aggregate evidence
from multiple relational paths. We show that existing neuro-symbolic approaches
fail on this benchmark, whereas our considered GNN model learns to reason
accurately.

摘要：<paragraph>開發能學習推理的模型是出了名的困難問題。我們專注於關係領域中的推理，其中圖形神經網路 (GNN) 的使用似乎是一個自然選擇。然而，先前關於使用 GNN 推理的研究顯示，當提供比訓練期間所見更長推論鏈的測試範例時，此類模型往往會失敗。這表明 GNN 缺乏以系統方式從訓練範例中概化的能力，這從根本上限制了它們的推理能力。一個常見的解決方案是改而依賴神經符號方法，它在設計上能夠以系統方式進行推理。不幸的是，此類方法的可擴充性通常受到限制，而且它們往往依賴於過於強烈的假設，例如，查詢可以透過檢查單一關係路徑來回答。在本文中，我們重新探討使用 GNN 推理的想法，證明只要提供了正確的歸納偏誤，系統概化是可能的。特別是，我們主張節點嵌入應視為認識狀態，並且 GNN 應相應地參數化。我們提出了一個基於此觀點的簡單 GNN 架構，並表明它能夠實現最先進的結果。此外，我們還引入了需要模型從多個關係路徑匯總證據的基準。我們表明現有的神經符號方法在此基準上失敗，而我們考慮的 GNN 模型則學會準確推理。</paragraph>

##### **CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**
2407.17390v1 by Itamar Trainin, Omri Abend

This paper introduces CovScore, an automatic reference-less methodology for
evaluating thematic title sets, extracted from a corpus of documents. While
such extraction methods are widely used, evaluating their effectiveness remains
an open question. Moreover, some existing practices heavily rely on slow and
laborious human annotation procedures. Inspired by recently introduced
LLM-based judge methods, we propose a novel methodology that decomposes quality
into five main metrics along different aspects of evaluation. This framing
simplifies and expedites the manual evaluation process and enables automatic
and independent LLM-based evaluation. As a test case, we apply our approach to
a corpus of Holocaust survivor testimonies, motivated both by its relevance to
title set extraction and by the moral significance of this pursuit. We validate
the methodology by experimenting with naturalistic and synthetic title set
generation systems and compare their performance with the methodology.

摘要：本文介紹 CovScore，這是一種自動無參考方法，用於評估從文件語料庫中提取的主題標題集。雖然此類提取方法被廣泛使用，但評估其有效性仍然是一個懸而未決的問題。此外，一些現有做法嚴重依賴於緩慢且費力的真人標註程序。受最近推出的基於 LLM 的評審方法的啟發，我們提出了一種新方法，將質量分解為五個主要指標，涵蓋評估的不同方面。此框架簡化並加快了手動評估過程，並實現了基於 LLM 的自動且獨立評估。作為一個測試案例，我們將我們的做法應用於大屠殺倖存者證詞語料庫，這既是因為它與標題集提取相關，也是因為這項追求的道德意義。我們通過對自然主義和合成標題集生成系統進行實驗來驗證該方法，並將其性能與該方法進行比較。

##### **PERSONA: A Reproducible Testbed for Pluralistic Alignment**
2407.17387v1 by Louis Castricato, Nathan Lile, Rafael Rafailov, Jan-Philipp Fränken, Chelsea Finn

The rapid advancement of language models (LMs) necessitates robust alignment
with diverse user values. However, current preference optimization approaches
often fail to capture the plurality of user opinions, instead reinforcing
majority viewpoints and marginalizing minority perspectives. We introduce
PERSONA, a reproducible test bed designed to evaluate and improve pluralistic
alignment of LMs. We procedurally generate diverse user profiles from US census
data, resulting in 1,586 synthetic personas with varied demographic and
idiosyncratic attributes. We then generate a large-scale evaluation dataset
containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic
personas. Leveraging this dataset, we systematically evaluate LM capabilities
in role-playing diverse users, verified through human judges, and the
establishment of both a benchmark, PERSONA Bench, for pluralistic alignment
approaches as well as an extensive dataset to create new and future benchmarks.
The full dataset and benchmarks are available here:
https://www.synthlabs.ai/research/persona.

摘要：語言模型 (LM) 的快速進步需要與多元的使用者價值觀進行穩健的對齊。然而，目前的偏好最佳化方法通常無法捕捉到使用者的意見多元性，反而強化了多數觀點，並將少數觀點邊緣化。我們引入了 PERSONA，一個可重製的測試平台，旨在評估和改善 LM 的多元對齊。我們根據美國人口普查資料程序化地產生了多樣化的使用者輪廓，產生了 1,586 個具有不同人口統計和特殊屬性的合成角色。然後，我們生成了包含 3,868 個提示和 317,200 個回饋配對的大規模評估資料集，這些配對來自我們的合成角色。利用此資料集，我們系統性地評估了 LM 在扮演不同使用者時的能力，並透過人工評審員驗證，以及建立了一個基準，PERSONA Bench，用於多元對齊方法，以及一個廣泛的資料集來建立新的和未來的基準。完整的資料集和基準可在此處取得：
https://www.synthlabs.ai/research/persona。

##### **A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**
2407.17383v1 by Amirreza Naziri, Hossein Zeinali

Writing, as an omnipresent form of human communication, permeates nearly
every aspect of contemporary life. Consequently, inaccuracies or errors in
written communication can lead to profound consequences, ranging from financial
losses to potentially life-threatening situations. Spelling mistakes, among the
most prevalent writing errors, are frequently encountered due to various
factors. This research aims to identify and rectify diverse spelling errors in
text using neural networks, specifically leveraging the Bidirectional Encoder
Representations from Transformers (BERT) masked language model. To achieve this
goal, we compiled a comprehensive dataset encompassing both non-real-word and
real-word errors after categorizing different types of spelling mistakes.
Subsequently, multiple pre-trained BERT models were employed. To ensure optimal
performance in correcting misspelling errors, we propose a combined approach
utilizing the BERT masked language model and Levenshtein distance. The results
from our evaluation data demonstrate that the system presented herein exhibits
remarkable capabilities in identifying and rectifying spelling mistakes, often
surpassing existing systems tailored for the Persian language.

摘要：身為人類溝通中無所不在的一種形式，寫作滲透於當代生活的幾乎每個面向。因此，書面溝通中的不準確或錯誤可能導致深遠的後果，從財務損失到潛在危及生命的狀況。拼寫錯誤是最常見的寫作錯誤之一，由於各種因素而經常發生。本研究旨在使用神經網路識別和糾正文字中的各種拼寫錯誤，特別是利用來自 Transformer（BERT）的雙向編碼器表示法遮罩語言模型。為了實現這個目標，我們編制了一個全面的資料集，在對不同類型的拼寫錯誤進行分類後，包含非真實字詞和真實字詞的錯誤。隨後，採用了多個預訓練的 BERT 模型。為了確保在糾正拼寫錯誤方面獲得最佳效能，我們提出了一種結合 BERT 遮罩語言模型和 Levenshtein 距離的綜合方法。我們評估資料的結果表明，本文提出的系統在識別和糾正拼寫錯誤方面表現出顯著的能力，通常優於針對波斯語量身打造的現有系統。

##### **MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**
2407.17379v1 by Siwei Wu, Kang Zhu, Yu Bai, Yiming Liang, Yizhi Li, Haoning Wu, Jiaheng Liu, Ruibo Liu, Xingwei Qu, Xuxin Cheng, Ge Zhang, Wenhao Huang, Chenghua Lin

Given the remarkable success that large visual language models (LVLMs) have
achieved in image perception tasks, the endeavor to make LVMLs perceive the
world like humans is drawing increasing attention. Current multi-modal
benchmarks mainly focus on the objective fact or certain topic related
potential knowledge within a image, but overlook the associative relations
between multiple images. Therefore, we define a multi-image relation
association task, and meticulously curate \textbf{MMRA} benchmark, a
\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational
\textbf{A}ssociation benchmark, consisted of \textbf{1026} samples. In order to
systematically and comprehensively evaluate mainstream LVLMs, we establish an
associational relation system among images that contain \textbf{11 subtasks}
(e.g, UsageSimilarity, SubEvent, etc.) at two granularity levels (i.e.,
"\textbf{image}" and "\textbf{entity}") according to the relations in
ConceptNet. Our experiments demonstrate that, on our MMRA benchmark, current
mainstream LVLMs all have their own advantages and disadvantages across
different subtasks. It is worth noting that, at the entity level, the
performance of all models is worse than that of them at the image level,
indicating that the fine-grained multi-image perception task is still
challenging for LVLMs. The tasks related to spatial perception are relatively
difficult for LVLMs to handle. Furthermore, we find that LVMLs exhibit a good
ability to perceive image details, and the key to enhancing their multi-image
association capability is to strengthen the reasoning ability of their language
model component. All our codes and data are released at
htt\url{https://github.com/Wusiwei0410/MMRA}.

摘要：<paragraph>鉴于大型视觉语言模型 (LVLMs) 在图像感知任务中取得的显著成功，让 LVML 像人类一样感知世界的努力正引起越来越多的关注。当前的多模态基准主要关注图像中的客观事实或与特定主题相关的潜在知识，但忽略了多幅图像之间的关联关系。因此，我们定义了一个多图像关系关联任务，并精心策划了\textbf{MMRA}基准，这是一个\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational \textbf{A}ssociation基准，由\textbf{1026}个样本组成。为了系统全面地评估主流 LVLMs，我们根据 ConceptNet 中的关系，在包含\textbf{11 个子任务}(例如 UsageSimilarity、SubEvent 等)的图像中建立了一个关联关系系统，该系统具有两个粒度级别(即“\textbf{图像}”和“\textbf{实体}”)。我们的实验表明，在我们的 MMRA 基准上，当前的主流 LVLMs 在不同的子任务中都有各自的优势和劣势。值得注意的是，在实体层面上，所有模型的性能都比它们在图像层面的性能差，这表明细粒度多图像感知任务对于 LVLMs 仍然具有挑战性。与空间感知相关的任务对于 LVLMs 来说相对难以处理。此外，我们发现 LVMLs 表现出良好的感知图像细节的能力，增强其多图像关联能力的关键在于加强其语言模型组件的推理能力。我们所有的代码和数据都可以在htt\url{https://github.com/Wusiwei0410/MMRA}发布。</paragraph>

##### **Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**
2407.17349v1 by Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He

With the introduction of large language models (LLMs), automatic math
reasoning has seen tremendous success. However, current methods primarily focus
on providing solutions or using techniques like Chain-of-Thought to enhance
problem-solving accuracy. In this paper, we focus on improving the capability
of mathematics teaching via a Socratic teaching-based LLM
(\texttt{SocraticLLM}), which guides learners toward profound thinking with
clarity and self-discovery via conversation. We collect and release a
high-quality mathematical teaching dataset, named \texttt{SocraticMATH}, which
provides Socratic-style conversations of problems with extra knowledge. Also,
we propose a knowledge-enhanced LLM as a strong baseline to generate reliable
responses with review, guidance/heuristic, rectification, and summarization.
Experimental results show the great advantages of \texttt{SocraticLLM} by
comparing it with several strong generative models. The codes and datasets are
available on \url{https://github.com/ECNU-ICALK/SocraticMath}.

摘要：隨著大型語言模型 (LLM) 的導入，自動數學
推理取得了巨大的成功。然而，目前的方法主要專注於提供解決方案或使用思想鏈等技術來提高
問題解決的準確性。在本文中，我們專注於透過蘇格拉底教學為基礎的 LLM (\texttt{SocraticLLM}) 來提升數學教學能力，它透過對話引導學習者進行深入思考，並透過自我發現獲得清晰度。我們收集並發布一個高品質的數學教學資料集，名為 \texttt{SocraticMATH}，它提供了問題的蘇格拉底式對話以及額外的知識。此外，我們提出一個知識增強的 LLM 作為一個強大的基準，以產生可靠的回應，並提供回顧、指導/啟發式、修正和總結。實驗結果顯示了 \texttt{SocraticLLM} 的巨大優勢，並將其與幾個強大的生成模型進行比較。程式碼和資料集可在 \url{https://github.com/ECNU-ICALK/SocraticMath} 上取得。

##### **Label Alignment and Reassignment with Generalist Large Language Model for Enhanced Cross-Domain Named Entity Recognition**
2407.17344v1 by Ke Bao, Chonghuan Yang

Named entity recognition on the in-domain supervised and few-shot settings
have been extensively discussed in the NLP community and made significant
progress. However, cross-domain NER, a more common task in practical scenarios,
still poses a challenge for most NER methods. Previous research efforts in that
area primarily focus on knowledge transfer such as correlate label information
from source to target domains but few works pay attention to the problem of
label conflict. In this study, we introduce a label alignment and reassignment
approach, namely LAR, to address this issue for enhanced cross-domain named
entity recognition, which includes two core procedures: label alignment between
source and target domains and label reassignment for type inference. The
process of label reassignment can significantly be enhanced by integrating with
an advanced large-scale language model such as ChatGPT. We conduct an extensive
range of experiments on NER datasets involving both supervised and zero-shot
scenarios. Empirical experimental results demonstrate the validation of our
method with remarkable performance under the supervised and zero-shot
out-of-domain settings compared to SOTA methods.

摘要：命名實體辨識在領域內監督和少見設定中已被廣泛討論於 NLP 社群中，並取得顯著進展。然而，跨領域 NER 是實務場景中更常見的任務，對於大多數 NER 方法仍構成挑戰。該領域先前的研究工作主要專注於知識轉移，例如將標籤資訊從來源網域關聯到目標網域，但很少有工作關注標籤衝突的問題。在本研究中，我們引進標籤對齊和重新指派方法，即 LAR，來解決此問題，以增強跨領域命名實體辨識，其中包括兩個核心程序：來源網域和目標網域之間的標籤對齊，以及類型推論的標籤重新指派。標籤重新指派的程序可以透過與進階大型語言模型（例如 ChatGPT）整合來顯著增強。我們在涉及監督和零次學習場景的 NER 資料集上進行廣泛的實驗。經驗實驗結果證明了我們的方法驗證，與 SOTA 方法相比，在監督和零次學習的領域外設定下具有顯著效能。

##### **Preliminary study on artificial intelligence methods for cybersecurity threat detection in computer networks based on raw data packets**
2407.17339v1 by Aleksander Ogonowski, Michał Żebrowski, Arkadiusz Ćwiek, Tobiasz Jarosiewicz, Konrad Klimaszewski, Adam Padee, Piotr Wasiuk, Michał Wójcik

Most of the intrusion detection methods in computer networks are based on
traffic flow characteristics. However, this approach may not fully exploit the
potential of deep learning algorithms to directly extract features and patterns
from raw packets. Moreover, it impedes real-time monitoring due to the
necessity of waiting for the processing pipeline to complete and introduces
dependencies on additional software components.
  In this paper, we investigate deep learning methodologies capable of
detecting attacks in real-time directly from raw packet data within network
traffic. We propose a novel approach where packets are stacked into windows and
separately recognised, with a 2D image representation suitable for processing
with computer vision models. Our investigation utilizes the CIC IDS-2017
dataset, which includes both benign traffic and prevalent real-world attacks,
providing a comprehensive foundation for our research.

摘要：大多數電腦網路中的入侵偵測方法都基於流量特徵。然而，此方法可能無法充分利用深度學習演算法直接從原始封包中擷取特徵和模式的潛力。此外，由於必須等到處理管線完成，並引入對額外軟體元件的依賴性，因此會妨礙即時監控。
在本文中，我們探討了能夠直接從網路流量中的原始封包資料即時偵測攻擊的深度學習方法。我們提出了一種新穎的方法，其中封包堆疊到視窗中並分別識別，並使用適合電腦視覺模型處理的 2D 影像表示。我們的研究利用 CIC IDS-2017 資料集，其中包含良性流量和普遍的真實世界攻擊，為我們的研究提供了全面的基礎。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?**
2407.17291v1 by Leo Yu-Ho Lo, Huamin Qu

In this study, we address the growing issue of misleading charts, a prevalent
problem that undermines the integrity of information dissemination. Misleading
charts can distort the viewer's perception of data, leading to
misinterpretations and decisions based on false information. The development of
effective automatic detection methods for misleading charts is an urgent field
of research. The recent advancement of multimodal Large Language Models (LLMs)
has introduced a promising direction for addressing this challenge. We explored
the capabilities of these models in analyzing complex charts and assessing the
impact of different prompting strategies on the models' analyses. We utilized a
dataset of misleading charts collected from the internet by prior research and
crafted nine distinct prompts, ranging from simple to complex, to test the
ability of four different multimodal LLMs in detecting over 21 different chart
issues. Through three experiments--from initial exploration to detailed
analysis--we progressively gained insights into how to effectively prompt LLMs
to identify misleading charts and developed strategies to address the
scalability challenges encountered as we expanded our detection range from the
initial five issues to 21 issues in the final experiment. Our findings reveal
that multimodal LLMs possess a strong capability for chart comprehension and
critical thinking in data interpretation. There is significant potential in
employing multimodal LLMs to counter misleading information by supporting
critical thinking and enhancing visualization literacy. This study demonstrates
the applicability of LLMs in addressing the pressing concern of misleading
charts.

摘要：在這項研究中，我們探討了誤導性圖表日益嚴重的問題，這是一個普遍存在的問題，它破壞了資訊傳播的完整性。誤導性圖表可能會扭曲觀看者對資料的認知，導致誤解和基於錯誤資訊的決策。開發用於誤導性圖表的有效自動偵測方法是一個迫切的研究領域。多模態大型語言模型 (LLM) 的最新進展為解決這個挑戰帶來了有希望的方向。我們探索了這些模型在分析複雜圖表和評估不同提示策略對模型分析的影響方面的能力。我們利用了先前研究從網路上收集的誤導性圖表資料集，並設計了九個不同的提示，從簡單到複雜，以測試四種不同的多模態 LLM 在偵測超過 21 個不同圖表問題的能力。透過三個實驗，從初步探索到詳細分析，我們逐漸深入了解如何有效提示 LLM 識別誤導性圖表，並制定策略來解決我們在將偵測範圍從最初的五個問題擴展到最後實驗中的 21 個問題時遇到的可擴充性挑戰。我們的研究結果揭示了多模態 LLM 具備強大的圖表理解能力和資料詮釋方面的批判性思維能力。利用多模態 LLM 來對抗誤導性資訊，透過支援批判性思維和加強視覺化素養，具有顯著的潛力。這項研究證明了 LLM 在解決誤導性圖表這個迫切問題上的適用性。

##### **Improving ICD coding using Chapter based Named Entities and Attentional Models**
2407.17230v1 by Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer

Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding.

摘要：自然語言處理 (NLP) 的最新進展已導致各種領域的自動化。然而，臨床 NLP 通常依賴於基準資料集，這些資料集可能無法準確反映真實世界的場景。自動 ICD 編碼是一項重要的 NLP 任務，通常使用過時且不平衡的資料集，例如 MIMIC-III，由於許多假陽性，現有方法產生的微平均 F1 分數介於 0.4 和 0.7 之間。我們的研究引入了一種增強的 ICD 編碼方法，通過使用基於章節的命名實體和注意力模型來提高 F1 分數。此方法將出院摘要分類為 ICD-9 章節，並使用章節特定資料開發注意力模型，消除了考慮外部資料以進行代碼識別的需要。對於分類，我們使用 Chapter-IV 來消除偏差並影響關鍵實體和權重，而無需神經網路，從而建立準確的閾值並提供人類驗證的可解釋性。在驗證之後，我們使用帶有注意力和多頭注意架構的雙向門控遞迴單元 (GRU) 和 Transformer，為 Chapter-IV 中的三個頻繁和三個非頻繁代碼開發注意力模型。這些模型的平均微 F1 分數為 0.79 和 0.81，表明 ICD 編碼的效能有了顯著的提升。

##### **LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN prover**
2407.17227v1 by Zijian Wu, Jiayu Wang, Dahua Lin, Kai Chen

Recently, large language models have presented promising results in aiding
formal mathematical reasoning. However, their performance is restricted due to
the scarcity of formal theorem-proving data, which requires additional effort
to be extracted from raw formal language corpora. Meanwhile, a significant
amount of human-written formal language corpora remains underutilized. To
address this issue, we propose LEAN-GitHub, a dataset consisting of large-scale
formal data extracted from almost all Lean 4 repositories on GitHub. After
fine-tuning InternLM-math-plus on this dataset, our model achieved accuracies
of 48.8% with a single pass and 54.5% with 64 passes on the Lean 4 miniF2F
test, surpassing state-of-the-art method at 52%. And it also achieves
state-of-the-art on two other Lean 4 benchmarks (ProofNet and Putnam) targeting
different fields/levels of math. These results demonstrate that our proposed
dataset is beneficial for formal reasoning on a wide range of math topics. We
open-source our model at https://GitHub. com/InternLM/InternLM-Math and our
data at https://huggingface.co/ datasets/InternLM/Lean-GitHub

摘要：<paragraph>最近，大型语言模型在辅助形式数学推理方面展现出令人振奋的结果。然而，由于形式定理证明数据的稀缺，它们的性能受到限制，这需要从原始形式语言语料库中提取额外的工作。同时，大量的人工编写的形式语言语料库仍然未得到充分利用。为了解决这个问题，我们提出了 LEAN-GitHub，这是一个数据集，包含从 GitHub 上几乎所有 Lean 4 存储库中提取的大规模形式数据。在此数据集上对 InternLM-math-plus 进行微调后，我们的模型在 Lean 4 miniF2F 测试中单次通过的准确率达到 48.8%，64 次通过的准确率达到 54.5%，超过了 52% 的最新方法。它还在针对不同数学领域/级别的另外两个 Lean 4 基准（ProofNet 和 Putnam）上取得了最新成果。这些结果表明，我们提出的数据集对于广泛的数学主题的正式推理是有益的。我们在 https://GitHub. com/InternLM/InternLM-Math 上开源了我们的模型，并在 https://huggingface.co/ datasets/InternLM/Lean-GitHub 上开源了我们的数据</paragraph>

##### **Sublinear Regret for An Actor-Critic Algorithm in Continuous-Time Linear-Quadratic Reinforcement Learning**
2407.17226v1 by Yilie Huang, Yanwei Jia, Xun Yu Zhou

We study reinforcement learning (RL) for a class of continuous-time
linear-quadratic (LQ) control problems for diffusions where volatility of the
state processes depends on both state and control variables. We apply a
model-free approach that relies neither on knowledge of model parameters nor on
their estimations, and devise an actor-critic algorithm to learn the optimal
policy parameter directly. Our main contributions include the introduction of a
novel exploration schedule and a regret analysis of the proposed algorithm. We
provide the convergence rate of the policy parameter to the optimal one, and
prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to
a logarithmic factor. We conduct a simulation study to validate the theoretical
results and demonstrate the effectiveness and reliability of the proposed
algorithm. We also perform numerical comparisons between our method and those
of the recent model-based stochastic LQ RL studies adapted to the state- and
control-dependent volatility setting, demonstrating a better performance of the
former in terms of regret bounds.

摘要：我們研究一個連續時間線性二次 (LQ) 控制問題的強化學習 (RL)，其擴散狀態過程的波動性取決於狀態和控制變數。我們採用一種無模型方法，這種方法既不依賴模型參數的知識，也不依賴於對模型參數的估計，並設計了一個動作-評論演算法來直接學習最佳策略參數。我們的貢獻包括引入一個新的探索時間表和對所提出演算法的遺憾分析。我們提供了策略參數收斂到最佳策略參數的速率，並證明該演算法達到了 $O(N^{\frac{3}{4}})$ 的遺憾界限，誤差小於對數因子。我們進行了一項模擬研究，以驗證理論結果，並證明所提出演算法的有效性和可靠性。我們還對我們的方法與最近基於模型的隨機 LQ RL 研究（已適應狀態和控制依賴波動性設定）進行了數值比較，證明了前者在遺憾界限方面的效能較佳。

##### **Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles**
2407.17211v1 by Zuoyin Tang, Jianhua He, Dashuai Pei, Kezhong Liu, Tao Gao

Handling long tail corner cases is a major challenge faced by autonomous
vehicles (AVs). While large language models (LLMs) hold great potentials to
handle the corner cases with excellent generalization and explanation
capabilities and received increasing research interest on application to
autonomous driving, there are still technical barriers to be tackled, such as
strict model performance and huge computing resource requirements of LLMs. In
this paper, we investigate a new approach of applying remote or edge LLMs to
support autonomous driving. A key issue for such LLM assisted driving system is
the assessment of LLMs on their understanding of driving theory and skills,
ensuring they are qualified to undertake safety critical driving assistance
tasks for CAVs. We design and run driving theory tests for several proprietary
LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM
models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500
multiple-choices theory test questions. Model accuracy, cost and processing
latency are measured from the experiments. Experiment results show that while
model GPT-4 passes the test with improved domain knowledge and Ernie has an
accuracy of 85% (just below the 86% passing threshold), other LLM models
including GPT-3.5 fail the test. For the test questions with images, the
multimodal model GPT4-o has an excellent accuracy result of 96%, and the
MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger
potential for CAV driving assistance applications, the cost of using model GPT4
is much higher, almost 50 times of that of using GPT3.5. The results can help
make decision on the use of the existing LLMs for CAV applications and
balancing on the model performance and cost.

摘要：<paragraph>處理長尾角落案例是自動駕駛車輛 (AV) 面臨的一項重大挑戰。雖然大型語言模型 (LLM) 具有極佳的概括和說明能力，足以處理角落案例，並在應用於自動駕駛方面受到越來越多的研究興趣，但仍有技術障礙需要克服，例如 LLM 的嚴格模型效能和龐大運算資源需求。在本文中，我們探討了一種將遠端或邊緣 LLM 應用於支援自動駕駛的新方法。此類 LLM 協助駕駛系統的一個關鍵問題是評估 LLM 對駕駛理論和技能的理解，確保它們有資格承擔 CAV 的安全關鍵駕駛輔助任務。我們針對多個專有 LLM 模型（OpenAI GPT 模型、百度 Ernie 和阿里 QWen）和開源 LLM 模型（清華大學 MiniCPM-2B 和 MiniCPM-Llama3-V2.5）設計並執行駕駛理論測試，測試題目超過 500 題多選題理論考題。從實驗中測量模型準確度、成本和處理延遲。實驗結果顯示，儘管模型 GPT-4 通過測試，且領域知識有所提升，而 Ernie 的準確度為 85%（略低於 86% 的及格門檻），但包括 GPT-3.5 在內的其他 LLM 模型未通過測試。對於帶有圖片的測試題目，多模態模型 GPT4-o 的準確度結果極佳，達到 96%，而 MiniCPM-Llama3-V2.5 的準確度達到 76%。儘管 GPT-4 對於 CAV 駕駛輔助應用程式具有更強大的潛力，但使用模型 GPT4 的成本卻高得多，幾乎是使用 GPT3.5 的 50 倍。這些結果有助於針對 CAV 應用程式使用現有 LLM 做出決策，並在模型效能和成本之間取得平衡。</paragraph>

##### **Nonverbal Immediacy Analysis in Education: A Multimodal Computational Model**
2407.17209v1 by Uroš Petković, Jonas Frenkel, Olaf Hellwich, Rebecca Lazarides

This paper introduces a novel computational approach for analyzing nonverbal
social behavior in educational settings. Integrating multimodal behavioral
cues, including facial expressions, gesture intensity, and spatial dynamics,
the model assesses the nonverbal immediacy (NVI) of teachers from RGB classroom
videos. A dataset of 400 30-second video segments from German classrooms was
constructed for model training and validation. The gesture intensity regressor
achieved a correlation of 0.84, the perceived distance regressor 0.55, and the
NVI model 0.44 with median human ratings. The model demonstrates the potential
to provide a valuable support in nonverbal behavior assessment, approximating
the accuracy of individual human raters. Validated against both questionnaire
data and trained observer ratings, our models show moderate to strong
correlations with relevant educational outcomes, indicating their efficacy in
reflecting effective teaching behaviors. This research advances the objective
assessment of nonverbal communication behaviors, opening new pathways for
educational research.

摘要：本文介紹一種創新的運算方法，用於分析教育環境中的非語言社交行為。透過整合多模態行為線索，包括面部表情、手勢強度和空間動態，此模型評估了 RGB 教室影片中教師的非語言即時性 (NVI)。從德國教室中收集 400 個 30 秒影片片段的資料集，用於模型訓練和驗證。手勢強度回歸器達到 0.84 的相關性，感知距離回歸器為 0.55，NVI 模型為 0.44，與人類評分的中位數。此模型證明了在非語言行為評估中提供有價值的支援的潛力，近似於個別人類評分者的準確性。根據問卷資料和訓練觀察者評分進行驗證，我們的模型顯示出與相關教育成果的中度至強相關性，表明它們在反映有效教學行為方面具有成效。這項研究推動了非語言溝通行為的客觀評估，為教育研究開闢了新途徑。

##### **ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using 2D Labels Only**
2407.17197v1 by Saad Lahlali, Nicolas Granger, Hervé Le Borgne, Quoc-Cuong Pham

3D object detection plays a crucial role in various applications such as
autonomous vehicles, robotics and augmented reality. However, training 3D
detectors requires a costly precise annotation, which is a hindrance to scaling
annotation to large datasets. To address this challenge, we propose a weakly
supervised 3D annotator that relies solely on 2D bounding box annotations from
images, along with size priors. One major problem is that supervising a 3D
detection model using only 2D boxes is not reliable due to ambiguities between
different 3D poses and their identical 2D projection. We introduce a simple yet
effective and generic solution: we build 3D proxy objects with annotations by
construction and add them to the training dataset. Our method requires only
size priors to adapt to new classes. To better align 2D supervision with 3D
detection, our method ensures depth invariance with a novel expression of the
2D losses. Finally, to detect more challenging instances, our annotator follows
an offline pseudo-labelling scheme which gradually improves its 3D
pseudo-labels. Extensive experiments on the KITTI dataset demonstrate that our
method not only performs on-par or above previous works on the Car category,
but also achieves performance close to fully supervised methods on more
challenging classes. We further demonstrate the effectiveness and robustness of
our method by being the first to experiment on the more challenging nuScenes
dataset. We additionally propose a setting where weak labels are obtained from
a 2D detector pre-trained on MS-COCO instead of human annotations.

摘要：<paragraph>3D 物件偵測在各種應用中扮演著至關重要的角色，例如自動駕駛車、機器人和擴增實境。然而，訓練 3D 偵測器需要昂貴的精確標註，這會阻礙標註擴展到大型資料集。為了應對這個挑戰，我們提出一個弱監督的 3D 標註器，它僅依賴於來自影像的 2D 框標註，以及尺寸先驗。一個主要問題是，僅使用 2D 框來監督 3D 偵測模型並不可靠，因為不同 3D 姿勢及其相同的 2D 投影之間存在歧義。我們引入了一個簡單但有效且通用的解決方案：我們通過構造建立帶有標註的 3D 代理物件，並將它們新增到訓練資料集中。我們的模型只需要尺寸先驗就能適應新的類別。為了更好地將 2D 監督與 3D 偵測對齊，我們的模型使用 2D 損失的新表達方式確保深度不變性。最後，為了偵測更具挑戰性的實例，我們的標註器遵循離線偽標籤方案，逐漸改善其 3D 偽標籤。在 KITTI 資料集上的廣泛實驗表明，我們的模型不僅在汽車類別中表現出與先前的研究相同或更好的表現，而且還在更具挑戰性的類別中實現了接近完全監督模型的表現。我們進一步證明了我們模型的有效性和穩健性，成為第一個在更具挑戰性的 nuScenes 資料集上進行實驗的模型。此外，我們提出了一個設定，其中弱標籤是從在 MS-COCO 上預先訓練的 2D 偵測器獲得的，而不是來自人工標註。</paragraph>

##### **NarrationDep: Narratives on Social Media For Automatic Depression Detection**
2407.17174v1 by Hamad Zogan, Imran Razzak, Shoaib Jameel, Guandong Xu

Social media posts provide valuable insight into the narrative of users and
their intentions, including providing an opportunity to automatically model
whether a social media user is depressed or not. The challenge lies in
faithfully modelling user narratives from their online social media posts,
which could potentially be useful in several different applications. We have
developed a novel and effective model called \texttt{NarrationDep}, which
focuses on detecting narratives associated with depression. By analyzing a
user's tweets, \texttt{NarrationDep} accurately identifies crucial narratives.
\texttt{NarrationDep} is a deep learning framework that jointly models
individual user tweet representations and clusters of users' tweets. As a
result, \texttt{NarrationDep} is characterized by a novel two-layer deep
learning model: the first layer models using social media text posts, and the
second layer learns semantic representations of tweets associated with a
cluster. To faithfully model these cluster representations, the second layer
incorporates a novel component that hierarchically learns from users' posts.
The results demonstrate that our framework outperforms other comparative models
including recently developed models on a variety of datasets.

摘要：社群媒體貼文提供使用者敘述和意圖的寶貴見解，包括提供自動建模社群媒體使用者是否憂鬱的機會。挑戰在於忠實地根據使用者線上社群媒體貼文建模使用者敘述，這可能在幾個不同的應用程式中很有用。我們開發了一個稱為 \texttt{NarrationDep} 的新穎且有效的模型，專注於偵測與憂鬱症相關的敘述。藉由分析使用者的推文，\texttt{NarrationDep} 可以準確地找出關鍵敘述。\texttt{NarrationDep} 是深度學習架構，可以同時建模個別使用者的推文表徵和使用者的推文叢集。因此，\texttt{NarrationDep} 的特點是新穎的兩層深度學習模型：第一層使用社群媒體文字貼文建模，第二層學習與叢集相關的推文的語意表徵。為了忠實地建模這些叢集表徵，第二層結合一個新穎的元件，可以從使用者的貼文中分層學習。結果顯示我們的架構優於其他比較模型，包括最近開發的各種資料集模型。

##### **Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech SpeechT5 Model**
2407.17167v1 by Jan Lehečka, Zdeněk Hanzlíček, Jindřich Matoušek, Daniel Tihelka

In this paper, we experimented with the SpeechT5 model pre-trained on
large-scale datasets. We pre-trained the foundation model from scratch and
fine-tuned it on a large-scale robust multi-speaker text-to-speech (TTS) task.
We tested the model capabilities in a zero- and few-shot scenario. Based on two
listening tests, we evaluated the synthetic audio quality and the similarity of
how synthetic voices resemble real voices. Our results showed that the SpeechT5
model can generate a synthetic voice for any speaker using only one minute of
the target speaker's data. We successfully demonstrated the high quality and
similarity of our synthetic voices on publicly known Czech politicians and
celebrities.

摘要：在本文中，我们对在大型数据集上预先训练的 SpeechT5 模型进行了实验。我们从头开始预先训练基础模型，并在大型、稳健的多说话者文本转语音 (TTS) 任务上对它进行了微调。我们在零样本和少量样本场景中测试了模型的能力。基于两次聆听测试，我们评估了合成音频质量以及合成声音与真实声音的相似性。我们的结果表明，SpeechT5 模型仅使用目标说话者一分钟的数据就能为任何说话者生成合成声音。我们成功地展示了我们在捷克知名政治家和名人身上合成声音的高质量和相似性。

##### **Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**
2407.17164v1 by Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu

Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.

摘要：將深度神經網路與霍克斯過程整合，大幅提升了金融、健康資訊學和資訊科技的預測能力。然而，這些模型在現實世界中經常面臨挑戰，特別是因為標籤雜訊過大。這個問題在醫療領域特別令人擔憂，因為標籤雜訊可能來自電子病歷的更新延誤或誤診，導致預測風險增加。我們的研究表明，深度霍克斯過程模型在處理標籤雜訊時表現出較低的穩健性，特別是在標籤雜訊同時影響事件類型和時間點時。為了應對這些挑戰，我們首先研究標籤雜訊對近似強度函數的影響，並提出了一個新的框架，即穩健深度霍克斯過程 (RDHP)，以克服標籤雜訊對霍克斯模型強度函數的影響，同時考慮事件及其發生。我們使用多個具有合成雜訊的開源基準測試 RDHP，並對現實世界中具有內在標籤雜訊的阻塞性睡眠呼吸中止低通氣綜合症 (OSAHS) 進行案例研究。結果表明，即使在存在與事件及其時間點相關的雜訊的情況下，RDHP 仍能有效執行分類和回歸任務。據我們所知，這是第一個成功解決深度霍克斯過程模型中事件和時間標籤雜訊的研究，為醫療應用（特別是診斷 OSAHS）提供了一個有前景的解決方案。

##### **A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives**
2407.17160v1 by Jan Lehečka, Josef V. Psutka, Luboš Šmídl, Pavel Ircing, Josef Psutka

In this paper, we are comparing monolingual Wav2Vec 2.0 models with various
multilingual models to see whether we could improve speech recognition
performance on a unique oral history archive containing a lot of mixed-language
sentences. Our main goal is to push forward research on this unique dataset,
which is an extremely valuable part of our cultural heritage. Our results
suggest that monolingual speech recognition models are, in most cases, superior
to multilingual models, even when processing the oral history archive full of
mixed-language sentences from non-native speakers. We also performed the same
experiments on the public CommonVoice dataset to verify our results. We are
contributing to the research community by releasing our pre-trained models to
the public.

摘要：在本文中，我們將單語音 Wav2Vec 2.0 模型與各種多語言模型進行比較，以了解我們是否可以改善對包含大量混合語言句子的獨特口述歷史檔案的語音識別效能。我們的目標是推動對這個獨特資料集的研究，它是我們文化遺產中極有價值的一部分。我們的結果表明，單語音語音識別模型在多數情況下優於多語言模型，即使在處理來自非母語人士的混合語言句子的口述歷史檔案時也是如此。我們還在公共 CommonVoice 資料集上執行了相同的實驗來驗證我們的結果。我們透過向公眾發布我們的預訓練模型來為研究社群做出貢獻。

##### **XMeCap: Meme Caption Generation with Sub-Image Adaptability**
2407.17152v1 by Yuyan Chen, Songzhou Yan, Zhihong Zhu, Zhixu Li, Yanghua Xiao

Humor, deeply rooted in societal meanings and cultural details, poses a
unique challenge for machines. While advances have been made in natural
language processing, real-world humor often thrives in a multi-modal context,
encapsulated distinctively by memes. This paper poses a particular emphasis on
the impact of multi-images on meme captioning. After that, we introduce the
\textsc{XMeCap} framework, a novel approach that adopts supervised fine-tuning
and reinforcement learning based on an innovative reward model, which factors
in both global and local similarities between visuals and text. Our results,
benchmarked against contemporary models, manifest a marked improvement in
caption generation for both single-image and multi-image memes, as well as
different meme categories. \textsc{XMeCap} achieves an average evaluation score
of 75.85 for single-image memes and 66.32 for multi-image memes, outperforming
the best baseline by 3.71\% and 4.82\%, respectively. This research not only
establishes a new frontier in meme-related studies but also underscores the
potential of machines in understanding and generating humor in a multi-modal
setting.

摘要：幽默深深植根於社會意義和文化細節中，對機器來說是一個獨特的挑戰。儘管自然語言處理方面取得了進展，但現實世界的幽默通常在多模態語境中蓬勃發展，並由模因獨特地概括。本文特別強調多圖像對模因標題的影響。在那之後，我們介紹了\textsc{XMeCap}框架，這是一種新穎的方法，採用基於創新獎勵模型的監督微調和強化學習，該模型考慮了視覺和文本之間的全局和局部相似性。我們的結果與當代模型進行了基準測試，表明單圖像和多圖像模因以及不同模因類別的標題生成都有顯著改進。\textsc{XMeCap}對單圖像模因的平均評分為75.85，對多圖像模因的平均評分為66.32，分別優於最佳基線3.71%和4.82%。這項研究不僅在模因相關研究中開闢了一個新領域，而且強調了機器在多模態環境中理解和產生幽默的潛力。

##### **SimCT: A Simple Consistency Test Protocol in LLMs Development Lifecycle**
2407.17150v1 by Fufangchen Zhao, Guoqiang Jin, Rui Zhao, Jiangheng Huang, Fei Tan

In this work, we report our efforts to advance the standard operation
procedure of developing Large Language Models (LLMs) or LLMs-based systems or
services in industry. We introduce the concept of Large Language Model
Development Lifecycle (LDLC) and then highlight the importance of consistency
test in ensuring the delivery quality. The principled solution of consistency
test, however, is usually overlooked by industrial practitioners and not urgent
in academia, and current practical solutions are insufficiently rigours and
labor-intensive. We thus propose a simple yet effective consistency test
protocol, named SimCT. SimCT is mainly to proactively check the consistency
across different development stages of "bare metal" LLMs or associated services
without accessing the model artifacts, in an attempt to expedite the delivery
by reducing the back-and-forth alignment communications among multiple teams
involved in different development stages.
  Specifically, SimCT encompasses response-wise and model-wise tests. We
implement the protocol with LightGBM and Student's t-test for two components
respectively, and perform extensive experiments to substantiate the
effectiveness of SimCT and the involved components.

摘要：在這項工作中，我們報告了我們在推動大型語言模型 (LLM) 或基於 LLM 的系統或服務在產業中開發的標準作業程序方面的努力。我們引入了大型語言模型開發生命週期 (LDLC) 的概念，然後強調了一致性測試在確保交付品質方面的重要性。然而，一致性測試的原則性解決方案通常被產業從業者所忽略，而且在學術界並非迫切需要，而目前的實際解決方案不夠嚴謹且耗費人力。因此，我們提出了一個簡單但有效的一致性測試協定，稱為 SimCT。SimCT 主要用於在不存取模型工件的情況下，主動檢查「裸機」LLM 或相關服務不同開發階段的一致性，試圖透過減少參與不同開發階段的多個團隊之間的反覆對齊溝通，來加速交付。具體來說，SimCT 包含了回應明智和模型明智的測試。我們分別使用 LightGBM 和學生 t 檢定來實作兩個組件的協定，並執行廣泛的實驗來證實 SimCT 和所涉及組件的有效性。

##### **SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**
2407.17126v1 by Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding

Extracting social determinants of health (SDoH) from unstructured medical
notes depends heavily on labor-intensive annotations, which are typically
task-specific, hampering reusability and limiting sharing. In this study we
introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)
method leveraging contrastive examples and concise instructions to extract SDoH
without relying on extensive medical annotations or costly human intervention.
It achieved tenfold and twentyfold reductions in time and cost respectively,
and superior consistency with human annotators measured by Cohen's kappa of up
to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the
strengths of both, ensuring high accuracy and computational efficiency while
consistently maintaining 0.90+ AUROC scores. Testing across three distinct
datasets has confirmed its robustness and accuracy. This study highlights the
potential of leveraging LLMs to revolutionize medical note classification,
demonstrating their capability to achieve highly accurate classifications with
significantly reduced time and cost.

摘要：從非結構化的醫療筆記中萃取健康的社會決定因素 (SDoH) 仰賴大量的人工標註，而這些標註通常是針對特定任務，這會阻礙可重複使用性並限制分享。在這項研究中，我們引入了 SDoH-GPT，一種簡單且有效的方法，它利用對比範例和簡潔的指示來萃取 SDoH，而不需要仰賴大量的醫療標註或昂貴的人工介入。它分別在時間和成本上達到了十倍和二十倍的降低，並且與人類標註者的優異一致性，由 Cohen's kappa 測量高達 0.92。SDoH-GPT 和 XGBoost 的創新結合利用了兩者的優點，確保了高準確度和運算效率，同時始終維持 0.90+ 的 AUROC 分數。在三個不同的資料集上進行測試已經確認了它的穩健性和準確性。這項研究突顯了利用 LLM 來革新醫療筆記分類的潛力，展示了它們在顯著減少時間和成本的情況下實現高度準確分類的能力。

##### **Behavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?**
2407.17125v2 by Anastasiia Sedova, Robert Litschko, Diego Frassinelli, Benjamin Roth, Barbara Plank

One of the major aspects contributing to the striking performance of large
language models (LLMs) is the vast amount of factual knowledge accumulated
during pre-training. Yet, many LLMs suffer from self-inconsistency, which
raises doubts about their trustworthiness and reliability. In this paper, we
focus on entity type ambiguity and analyze current state-of-the-art LLMs for
their proficiency and consistency in applying their factual knowledge when
prompted for entities under ambiguity. To do so, we propose an evaluation
protocol that disentangles knowing from applying knowledge, and test
state-of-the-art LLMs on 49 entities. Our experiments reveal that LLMs perform
poorly with ambiguous prompts, achieving only 80% accuracy. Our results further
demonstrate systematic discrepancies in LLM behavior and their failure to
consistently apply information, indicating that the models can exhibit
knowledge without being able to utilize it, significant biases for preferred
readings, as well as self inconsistencies. Our study highlights the importance
of handling entity ambiguity in future for more trustworthy LLMs

摘要：大型語言模型 (LLM) 表現傑出的主要原因之一，是預訓練期間累積了大量的知識。然而，許多 LLM 都有自我矛盾的問題，這讓人質疑其可信度和可靠性。在本文中，我們專注於實體類型歧義，並分析目前最先進的 LLM，了解其在歧義實體提示下應用知識的熟練度和一致性。為此，我們提出一個評估協定，將知識與應用知識區分開來，並在 49 個實體上測試最先進的 LLM。我們的實驗顯示，LLM 在含糊的提示下表現不佳，僅達到 80% 的準確度。我們的結果進一步證明了 LLM 行為中的系統性差異，以及它們無法一致應用資訊，這表明模型可以表現出知識，但無法利用它，對首選讀數有顯著的偏見，以及自我矛盾。我們的研究強調了在未來處理實體歧義對於更值得信賴的 LLM 的重要性

##### **Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective**
2407.17120v1 by Jingren Liu, Zhong Ji, YunLong Yu, Jiale Cao, Yanwei Pang, Jungong Han, Xuelong Li

Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown
promise in adapting pre-trained models to sequential tasks while mitigating
catastrophic forgetting problem. However, understanding the mechanisms that
dictate continual performance in this paradigm remains elusive. To tackle this
complexity, we undertake a rigorous analysis of PEFT-CL dynamics to derive
relevant metrics for continual scenarios using Neural Tangent Kernel (NTK)
theory. With the aid of NTK as a mathematical analysis tool, we recast the
challenge of test-time forgetting into the quantifiable generalization gaps
during training, identifying three key factors that influence these gaps and
the performance of PEFT-CL: training sample size, task-level feature
orthogonality, and regularization. To address these challenges, we introduce
NTK-CL, a novel framework that eliminates task-specific parameter storage while
adaptively generating task-relevant features. Aligning with theoretical
guidance, NTK-CL triples the feature representation of each sample,
theoretically and empirically reducing the magnitude of both task-interplay and
task-specific generalization gaps. Grounded in NTK analysis, our approach
imposes an adaptive exponential moving average mechanism and constraints on
task-level feature orthogonality, maintaining intra-task NTK forms while
attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable
parameters with appropriate regularization, NTK-CL achieves state-of-the-art
performance on established PEFT-CL benchmarks. This work provides a theoretical
foundation for understanding and improving PEFT-CL models, offering insights
into the interplay between feature representation, task orthogonality, and
generalization, contributing to the development of more efficient continual
learning systems.

摘要：<paragraph>持續學習的參數有效微調 (PEFT-CL) 已顯示出在適應預訓練模型至順序任務的同時，減輕災難性遺忘問題的潛力。然而，了解在這個範例中支配持續效能的機制仍然難以捉摸。為了應對這個複雜性，我們對 PEFT-CL 動態進行嚴格分析，以使用神經切線核 (NTK) 理論推導出持續情境的相關指標。在 NTK 作為數學分析工具的幫助下，我們將測試時間遺忘的挑戰重新定義為訓練期間可量化的概化差距，找出影響這些差距和 PEFT-CL 效能的三個關鍵因素：訓練樣本大小、任務層級特徵正交性，以及規範化。為了應對這些挑戰，我們引入了 NTK-CL，一個創新的架構，它消除了任務特定參數儲存，同時自適應地產生與任務相關的特徵。與理論指導一致，NTK-CL 將每個樣本的特徵表示增加三倍，在理論上和經驗上減少了任務交互和任務特定概化差距的幅度。基於 NTK 分析，我們的做法強制執行自適應指數移動平均機制和任務層級特徵正交性的約束，在減弱任務間 NTK 形式的同時，維護任務內 NTK 形式。最後，透過微調具有適當規範化的可最佳化參數，NTK-CL 在已建立的 PEFT-CL 基準上達到了最先進的效能。這項工作為理解和改善 PEFT-CL 模型提供了理論基礎，提供了對特徵表示、任務正交性，以及概化之間相互作用的見解，有助於開發更有效率的持續學習系統。</paragraph>

##### **EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments**
2407.17117v1 by Edward, Mohamed Ragab, Yuecong Xu, Min Wu, Yuecong Xu, Zhenghua Chen, Abdulla Alseiari, Xiaoli Li

Unsupervised Domain Adaptation (UDA) has emerged as a key solution in
data-driven fault diagnosis, addressing domain shift where models underperform
in changing environments. However, under the realm of continually changing
environments, UDA tends to underperform on previously seen domains when
adapting to new ones - a problem known as catastrophic forgetting. To address
this limitation, we introduce the EverAdapt framework, specifically designed
for continuous model adaptation in dynamic environments. Central to EverAdapt
is a novel Continual Batch Normalization (CBN), which leverages source domain
statistics as a reference point to standardize feature representations across
domains. EverAdapt not only retains statistical information from previous
domains but also adapts effectively to new scenarios. Complementing CBN, we
design a class-conditional domain alignment module for effective integration of
target domains, and a Sample-efficient Replay strategy to reinforce memory
retention. Experiments on real-world datasets demonstrate EverAdapt superiority
in maintaining robust fault diagnosis in dynamic environments. Our code is
available: https://github.com/mohamedr002/EverAdapt

摘要：無監督域適應 (UDA) 已成為資料驅動故障診斷的一項關鍵解決方案，用於解決模型在變動環境中表現不佳的域轉移。然而，在持續變動的環境領域中，UDA 傾向於在適應新域時對先前看過的域表現不佳，此問題稱為災難性遺忘。為了解決此限制，我們引入了 EverAdapt 框架，專門設計用於動態環境中的持續模型適應。EverAdapt 的核心是一個新穎的持續批次正規化 (CBN)，它利用來源域統計資料作為參考點，以標準化跨域特徵表示。EverAdapt 不僅保留先前域的統計資訊，還能有效適應新的場景。為了補充 CBN，我們設計了一個類條件域比對模組，用於有效整合目標域，以及一個樣本有效重播策略，以加強記憶保留。在真實世界資料集上的實驗證明了 EverAdapt 在動態環境中維持穩健故障診斷的優越性。我們的程式碼已公開：https://github.com/mohamedr002/EverAdapt

##### **Neural Dueling Bandits**
2407.17112v1 by Arun Verma, Zhongxiang Dai, Xiaoqiang Lin, Patrick Jaillet, Bryan Kian Hsiang Low

Contextual dueling bandit is used to model the bandit problems, where a
learner's goal is to find the best arm for a given context using observed noisy
preference feedback over the selected arms for the past contexts. However,
existing algorithms assume the reward function is linear, which can be complex
and non-linear in many real-life applications like online recommendations or
ranking web search results. To overcome this challenge, we use a neural network
to estimate the reward function using preference feedback for the previously
selected arms. We propose upper confidence bound- and Thompson sampling-based
algorithms with sub-linear regret guarantees that efficiently select arms in
each round. We then extend our theoretical results to contextual bandit
problems with binary feedback, which is in itself a non-trivial contribution.
Experimental results on the problem instances derived from synthetic datasets
corroborate our theoretical results.

摘要：情境對決多臂機用於對多臂機問題進行建模，在該問題中，學習者的目標是使用在過去情境中對所選臂進行觀察到的帶噪聲的偏好回饋，找到給定情境下的最佳臂。然而，現有演算法假設獎勵函數是線性的，而這在許多現實生活應用中可能是複雜且非線性的，例如線上推薦或對網路搜尋結果進行排名。為了克服這個挑戰，我們使用神經網路來估計獎勵函數，並使用先前選擇的臂的偏好回饋。我們提出具有次線性後悔保證的上置信界和湯普森抽樣演算法，這些演算法可以在每一輪有效地選擇臂。然後，我們將理論結果擴展到具有二元回饋的情境多臂機問題，這本身就是一個不平凡的貢獻。從合成資料集衍生的問題實例的實驗結果證實了我們的理論結果。

##### **PiPa++: Towards Unification of Domain Adaptive Semantic Segmentation via Self-supervised Learning**
2407.17101v1 by Mu Chen, Zhedong Zheng, Yi Yang

Unsupervised domain adaptive segmentation aims to improve the segmentation
accuracy of models on target domains without relying on labeled data from those
domains. This approach is crucial when labeled target domain data is scarce or
unavailable. It seeks to align the feature representations of the source domain
(where labeled data is available) and the target domain (where only unlabeled
data is present), thus enabling the model to generalize well to the target
domain. Current image- and video-level domain adaptation have been addressed
using different and specialized frameworks, training strategies and
optimizations despite their underlying connections. In this paper, we propose a
unified framework PiPa++, which leverages the core idea of ``comparing'' to (1)
explicitly encourage learning of discriminative pixel-wise features with
intraclass compactness and inter-class separability, (2) promote the robust
feature learning of the identical patch against different contexts or
fluctuations, and (3) enable the learning of temporal continuity under dynamic
environments. With the designed task-smart contrastive sampling strategy,
PiPa++ enables the mining of more informative training samples according to the
task demand. Extensive experiments demonstrate the effectiveness of our method
on both image-level and video-level domain adaption benchmarks. Moreover, the
proposed method is compatible with other UDA approaches to further improve the
performance without introducing extra parameters.

摘要：無監督域適應分割旨在提升模型在目標域上的分割準確度，而無需依賴這些域中標籤化的資料。當標籤化的目標域資料稀少或不可用時，此方法至關重要。它旨在比對來源域（其中有標籤化的資料）和目標域（其中只有未標籤化的資料）的特徵表示，從而使模型能夠很好地推廣到目標域。儘管當前影像和影片層級的域適應已使用不同的專門架構、訓練策略和最佳化來處理，但它們的底層連接仍然存在。在本文中，我們提出一個統一的架構 PiPa++，它利用「比較」的核心概念來 (1) 明確鼓勵學習具有類內緊湊性和類間可分離性的判別像素級特徵，(2) 促進相同貼片的穩健特徵學習，以應對不同的背景或波動，以及 (3) 在動態環境下啟用時間連續性的學習。透過設計任務智慧型對比採樣策略，PiPa++ 能夠根據任務需求挖掘更多有資訊性的訓練樣本。廣泛的實驗證明了我們的方法在影像層級和影片層級域適應基準上的有效性。此外，所提出的方法與其他 UDA 方法相容，可以在不引入額外參數的情況下進一步提升效能。

##### **Towards Robust Knowledge Tracing Models via k-Sparse Attention**
2407.17097v1 by Shuyan Huang, Zitao Liu, Xiangyu Zhao, Weiqi Luo, Jian Weng

Knowledge tracing (KT) is the problem of predicting students' future
performance based on their historical interaction sequences. With the advanced
capability of capturing contextual long-term dependency, attention mechanism
becomes one of the essential components in many deep learning based KT (DLKT)
models. In spite of the impressive performance achieved by these attentional
DLKT models, many of them are often vulnerable to run the risk of overfitting,
especially on small-scale educational datasets. Therefore, in this paper, we
propose \textsc{sparseKT}, a simple yet effective framework to improve the
robustness and generalization of the attention based DLKT approaches.
Specifically, we incorporate a k-selection module to only pick items with the
highest attention scores. We propose two sparsification heuristics : (1)
soft-thresholding sparse attention and (2) top-$K$ sparse attention. We show
that our \textsc{sparseKT} is able to help attentional KT models get rid of
irrelevant student interactions and have comparable predictive performance when
compared to 11 state-of-the-art KT models on three publicly available
real-world educational datasets. To encourage reproducible research, we make
our data and code publicly available at
\url{https://github.com/pykt-team/pykt-toolkit}\footnote{We merged our model to
the \textsc{pyKT} benchmark at \url{https://pykt.org/}.}.

摘要：<paragraph>知識追蹤 (KT) 的問題在於預測學生的未來表現，依據他們過往的互動序列。在捕捉脈絡長期依賴性的進階能力下，注意力機制成為許多基於深度學習的知識追蹤 (DLKT) 模型中不可或缺的組成部分。儘管這些注意力 DLKT 模型獲得令人印象深刻的表現，但許多模型經常面臨過度擬合的風險，特別是在小規模的教育資料集上。因此，在本文中，我們提出 \textsc{sparseKT}，一個簡單但有效的架構，以改善基於注意力的 DLKT 方法的穩健性和泛化性。具體來說，我們結合了一個 k 選擇模組，僅挑選具有最高注意力分數的項目。我們提出兩種稀疏化啟發法：(1) 軟閾值稀疏注意力和 (2) 前 $K$ 個稀疏注意力。我們展示了我們的 \textsc{sparseKT} 能夠幫助注意力 KT 模型擺脫無關的學生互動，並且在與三個公開可用的真實世界教育資料集上的 11 個最先進的 KT 模型相比時，具有相當的預測效能。為了鼓勵可重複的研究，我們公開我們的資料和程式碼於 \url{https://github.com/pykt-team/pykt-toolkit}\footnote{我們將我們的模型合併到 \textsc{pyKT} 基準中，網址為 \url{https://pykt.org/}.}。</paragraph>

##### **OVR: A Dataset for Open Vocabulary Temporal Repetition Counting in Videos**
2407.17085v1 by Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Andrew Zisserman

We introduce a dataset of annotations of temporal repetitions in videos. The
dataset, OVR (pronounced as over), contains annotations for over 72K videos,
with each annotation specifying the number of repetitions, the start and end
time of the repetitions, and also a free-form description of what is repeating.
The annotations are provided for videos sourced from Kinetics and Ego4D, and
consequently cover both Exo and Ego viewing conditions, with a huge variety of
actions and activities. Moreover, OVR is almost an order of magnitude larger
than previous datasets for video repetition. We also propose a baseline
transformer-based counting model, OVRCounter, that can localise and count
repetitions in videos that are up to 320 frames long. The model is trained and
evaluated on the OVR dataset, and its performance assessed with and without
using text to specify the target class to count. The performance is also
compared to a prior repetition counting model. The dataset is available for
download at: https://sites.google.com/view/openvocabreps/

摘要：我們引入了一個影片中時間重複註解的資料集。
資料集 OVR（發音為 over）包含超過 72K 影片的註解，
每個註解都指定重複次數、重複的開始和結束時間，以及重複內容的自由格式描述。
註解是針對來自 Kinetics 和 Ego4D 的影片提供的，
因此涵蓋了 Exo 和 Ego 觀看條件，以及各種動作和活動。
此外，OVR 幾乎比以前用於影片重複的資料集大一個數量級。
我們還提出了一個基準Transformer計數模型 OVRCounter，它可以定位和計算長達 320 幀的影片中的重複。
該模型在 OVR 資料集上進行訓練和評估，並在使用和不使用文字指定要計數的目標類別的情況下評估其效能。
效能也與先前的重複計數模型進行比較。
資料集可於以下網址下載：https://sites.google.com/view/openvocabreps/

##### **When Text and Images Don't Mix: Bias-Correcting Language-Image Similarity Scores for Anomaly Detection**
2407.17083v1 by Adam Goodge, Bryan Hooi, Wee Siong Ng

Contrastive Language-Image Pre-training (CLIP) achieves remarkable
performance in various downstream tasks through the alignment of image and text
input embeddings and holds great promise for anomaly detection. However, our
empirical experiments show that the embeddings of text inputs unexpectedly
tightly cluster together, far away from image embeddings, contrary to the
model's contrastive training objective to align image-text input pairs. We show
that this phenomenon induces a `similarity bias' - in which false negative and
false positive errors occur due to bias in the similarities between images and
the normal label text embeddings. To address this bias, we propose a novel
methodology called BLISS which directly accounts for this similarity bias
through the use of an auxiliary, external set of text inputs. BLISS is simple,
it does not require strong inductive biases about anomalous behaviour nor an
expensive training process, and it significantly outperforms baseline methods
on benchmark image datasets, even when access to normal data is extremely
limited.

摘要：對比語言影像預訓練 (CLIP) 透過影像與文字輸入嵌入的對齊，在各種下游任務中取得顯著的效能，並對異常偵測極具前景。然而，我們的實證實驗顯示，文字輸入的嵌入意外地緊密地聚集在一起，遠離影像嵌入，這與模型的對比訓練目標（對齊影像文字輸入對）相違背。我們顯示這個現象會引發「相似性偏差」，其中假負面和假正面錯誤會發生，原因是影像與正常標籤文字嵌入之間的相似性偏差。為了解決這個偏差，我們提出一個新方法，稱為 BLISS，透過使用輔助的外部文字輸入集，直接說明這個相似性偏差。BLISS 很簡單，不需要關於異常行為的強歸納偏差，也不需要昂貴的訓練過程，而且在基準影像資料集上明顯優於基線方法，即使在正常資料的存取極為有限的情況下也是如此。

##### **SAFETY-J: Evaluating Safety with Critique**
2407.17075v2 by Yixiu Liu, Yuxiang Zheng, Shijie Xia, Yuan Guo, Jiajun Li, Yi Tu, Chaoling Song, Pengfei Liu

The deployment of Large Language Models (LLMs) in content generation raises
significant safety concerns, particularly regarding the transparency and
interpretability of content evaluations. Current methods, primarily focused on
binary safety classifications, lack mechanisms for detailed critique, limiting
their utility for model improvement and user trust. To address these
limitations, we introduce SAFETY-J, a bilingual generative safety evaluator for
English and Chinese with critique-based judgment. SAFETY-J utilizes a robust
training dataset that includes diverse dialogues and augmented query-response
pairs to assess safety across various scenarios comprehensively. We establish
an automated meta-evaluation benchmark that objectively assesses the quality of
critiques with minimal human intervention, facilitating scalable and continuous
improvement. Additionally, SAFETY-J employs an iterative preference learning
technique to dynamically refine safety assessments based on meta-evaluations
and critiques. Our evaluations demonstrate that SAFETY-J provides more nuanced
and accurate safety evaluations, thereby enhancing both critique quality and
predictive reliability in complex content scenarios. To facilitate further
research and application, we open-source SAFETY-J's training protocols,
datasets, and code at \url{https://github.com/GAIR-NLP/Safety-J}.

摘要：大型語言模型 (LLM) 在內容生成中的部署引發了重大的安全問題，特別是關於內容評估的透明度和可解釋性。目前的方法主要集中在二元安全分類上，缺乏詳細的批評機制，限制了它們在模型改進和使用者信任方面的效用。為了解決這些限制，我們引入了 SAFETY-J，這是一個基於批評判斷的英語和中文雙語生成安全評估器。SAFETY-J 使用了一個強大的訓練資料集，其中包括多樣化的對話和增強的查詢回應對，以全面評估各種場景中的安全性。我們建立了一個自動化的元評估基準，可以客觀地評估批評的品質，並將人為干預降至最低，促進可擴展和持續的改進。此外，SAFETY-J 採用了一種迭代偏好學習技術，根據元評估和批評動態優化安全評估。我們的評估表明，SAFETY-J 提供了更細緻且準確的安全評估，從而提高了複雜內容場景中的批評品質和預測可靠性。為了促進進一步的研究和應用，我們開放了 SAFETY-J 的訓練協議、資料集和程式碼，網址為 \url{https://github.com/GAIR-NLP/Safety-J}。

##### **Curriculum Negative Mining For Temporal Networks**
2407.17070v1 by Ziyue Chen, Tongya Zheng, Mingli Song

Temporal networks are effective in capturing the evolving interactions of
networks over time, such as social networks and e-commerce networks. In recent
years, researchers have primarily concentrated on developing specific model
architectures for Temporal Graph Neural Networks (TGNNs) in order to improve
the representation quality of temporal nodes and edges. However, limited
attention has been given to the quality of negative samples during the training
of TGNNs. When compared with static networks, temporal networks present two
specific challenges for negative sampling: positive sparsity and positive
shift. Positive sparsity refers to the presence of a single positive sample
amidst numerous negative samples at each timestamp, while positive shift
relates to the variations in positive samples across different timestamps. To
robustly address these challenges in training TGNNs, we introduce Curriculum
Negative Mining (CurNM), a model-aware curriculum learning framework that
adaptively adjusts the difficulty of negative samples. Within this framework,
we first establish a dynamically updated negative pool that balances random,
historical, and hard negatives to address the challenges posed by positive
sparsity. Secondly, we implement a temporal-aware negative selection module
that focuses on learning from the disentangled factors of recently active
edges, thus accurately capturing shifting preferences. Extensive experiments on
12 datasets and 3 TGNNs demonstrate that our method outperforms baseline
methods by a significant margin. Additionally, thorough ablation studies and
parameter sensitivity experiments verify the usefulness and robustness of our
approach. Our code is available at https://github.com/zziyue83/CurNM.

摘要：時序網路有效捕捉網路隨著時間演化的互動，例如社群網路和電子商務網路。近年來，研究人員主要專注於開發時序圖形神經網路 (TGNN) 的特定模型架構，以提升時序節點和邊緣的表示品質。然而，在 TGNN 訓練期間，負樣本的品質卻鮮少受到重視。與靜態網路相比，時序網路在負樣本抽樣時會面臨兩個特定挑戰：正樣本稀疏和正樣本轉移。正樣本稀疏是指在每個時間戳記中，只會在眾多負樣本中出現單一正樣本，而正樣本轉移則與不同時間戳記中正樣本的變化有關。為了在訓練 TGNN 時穩健地應對這些挑戰，我們引入了課程負樣本挖掘 (CurNM)，一種模型感知課程學習架構，可適應調整負樣本的難度。在此架構中，我們首先建立一個動態更新的負樣本池，平衡隨機、歷史和困難負樣本，以應對正樣本稀疏所帶來的挑戰。其次，我們實作了一個時序感知負樣本選擇模組，專注於從最近活躍邊緣的解糾結因子中學習，從而準確捕捉轉移偏好。在 12 個資料集和 3 個 TGNN 上進行的廣泛實驗證明，我們的方法以顯著的幅度優於基準方法。此外，徹底的消融研究和參數敏感性實驗驗證了我們方法的實用性和穩健性。我們的程式碼可在 https://github.com/zziyue83/CurNM 取得。

##### **High Efficiency Image Compression for Large Visual-Language Models**
2407.17060v1 by Binzhe Li, Shurun Wang, Shiqi Wang, Yan Ye

In recent years, large visual language models (LVLMs) have shown impressive
performance and promising generalization capability in multi-modal tasks, thus
replacing humans as receivers of visual information in various application
scenarios. In this paper, we pioneer to propose a variable bitrate image
compression framework consisting of a pre-editing module and an end-to-end
codec to achieve promising rate-accuracy performance for different LVLMs. In
particular, instead of optimizing an adaptive pre-editing network towards a
particular task or several representative tasks, we propose a new optimization
strategy tailored for LVLMs, which is designed based on the representation and
discrimination capability with token-level distortion and rank. The pre-editing
module and the variable bitrate end-to-end image codec are jointly trained by
the losses based on semantic tokens of the large model, which introduce
enhanced generalization capability for various data and tasks. {Experimental
results demonstrate that the proposed framework could efficiently achieve much
better rate-accuracy performance compared to the state-of-the-art coding
standard, Versatile Video Coding.} Meanwhile, experiments with multi-modal
tasks have revealed the robustness and generalization capability of the
proposed framework.

摘要：近年來，大型視覺語言模型 (LVLMs) 在多模態任務中展現出令人印象深刻的效能和有前景的泛化能力，因此在各種應用場景中取代人類成為視覺資訊的接收者。在本文中，我們率先提出一個可變位元率影像壓縮架構，由一個預編輯模組和一個端對端編解碼器組成，以達成不同 LVLMs 的有前景速率準確度效能。特別是，我們沒有針對特定任務或幾個代表性任務來最佳化自適應預編輯網路，而是提出一個專為 LVLMs 量身打造的新最佳化策略，其設計基於具有代幣層級失真和等級的表示和辨別能力。預編輯模組和可變位元率端對端影像編解碼器由大型模型的語意代幣所根據的損失聯合訓練，這為各種資料和任務引入了增強的泛化能力。{實驗結果證明，與最先進的編碼標準多功能視訊編碼相比，所提出的架構可以有效地達成更好的速率準確度效能。}同時，多模態任務的實驗揭示了所提出的架構的穩健性和泛化能力。

##### **Time Series Missing Imputation with Multivariate Radial Basis Function Neural Network**
2407.17040v1 by Chanyoung Jung, Yun Jang

Researchers have been persistently working to address the issue of missing
values in time series data. Numerous models have been proposed, striving to
estimate the distribution of the data. The Radial Basis Functions Neural
Network (RBFNN) has recently exhibited exceptional performance in estimating
data distribution. In this paper, we propose a time series imputation model
based on RBFNN. Our imputation model learns local information from timestamps
to create a continuous function. Additionally, we incorporate time gaps to
facilitate learning information considering the missing terms of missing
values. We name this model the Missing Imputation Multivariate RBFNN
(MIM-RBFNN). However, MIM-RBFNN relies on a local information-based learning
approach, which presents difficulties in utilizing temporal information.
Therefore, we propose an extension called the Missing Value Imputation
Recurrent Neural Network with Continuous Function (MIRNN-CF) using the
continuous function generated by MIM-RBFNN. We evaluate the performance using
two real-world datasets with non-random missing and random missing patterns,
and conduct an ablation study comparing MIM-RBFNN and MIRNN-CF.

摘要：研究人員持續致力於解決時序資料中遺失值的問題。已經提出了許多模型，努力估計資料的分布。徑向基函數神經網路 (RBFNN) 最近在估計資料分布方面表現出色。在本文中，我們提出一個基於 RBFNN 的時序插補模型。我們的插補模型從時間戳記中學習局部資訊，以建立一個連續函數。此外，我們納入時間間隔，以利於學習考慮遺失值遺失項的資訊。我們將這個模型命名為遺失插補多變量 RBFNN (MIM-RBFNN)。然而，MIM-RBFNN 依賴於基於局部資訊的學習方法，這在利用時間資訊方面存在困難。因此，我們提出了一個名為遺失值插補遞迴神經網路與連續函數 (MIRNN-CF) 的延伸，使用 MIM-RBFNN 生成的連續函數。我們使用兩個具有非隨機遺失和隨機遺失模式的真實世界資料集評估效能，並進行消融研究，比較 MIM-RBFNN 和 MIRNN-CF。

##### **Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference**
2407.17033v1 by Jian Xu, Delu Zeng, John Paisley

Deep Gaussian processes (DGPs) provide a robust paradigm for Bayesian deep
learning. In DGPs, a set of sparse integration locations called inducing points
are selected to approximate the posterior distribution of the model. This is
done to reduce computational complexity and improve model efficiency. However,
inferring the posterior distribution of inducing points is not straightforward.
Traditional variational inference approaches to posterior approximation often
lead to significant bias. To address this issue, we propose an alternative
method called Denoising Diffusion Variational Inference (DDVI) that uses a
denoising diffusion stochastic differential equation (SDE) to generate
posterior samples of inducing variables. We rely on score matching methods for
denoising diffusion model to approximate score functions with a neural network.
Furthermore, by combining classical mathematical theory of SDEs with the
minimization of KL divergence between the approximate and true processes, we
propose a novel explicit variational lower bound for the marginal likelihood
function of DGP. Through experiments on various datasets and comparisons with
baseline methods, we empirically demonstrate the effectiveness of DDVI for
posterior inference of inducing points for DGP models.

摘要：深度高斯過程 (DGP) 為貝氏深度學習提供一個穩健的範例。在 DGP 中，會選取一組稱為誘導點的稀疏積分位置，以逼近模型的後驗分佈。這樣做是為了降低運算複雜度並提升模型效率。然而，推論誘導點的後驗分佈並不容易。傳統的變異推論後驗逼近方法通常會導致顯著的偏差。為了解決這個問題，我們提出了一種稱為去噪擴散變異推論 (DDVI) 的替代方法，它使用去噪擴散隨機微分方程式 (SDE) 來產生誘導變數的後驗樣本。我們依賴去噪擴散模型的評分配對方法，以神經網路逼近評分函數。此外，透過結合 SDE 的經典數學理論與近似和真實過程之間的 KL 距離最小化，我們提出了 DGP 邊際似然函數的一個新穎的明確變異下界。透過在各種資料集上進行實驗並與基線方法進行比較，我們實證展示了 DDVI 在 DGP 模型的誘導點後驗推論中的有效性。

##### **From Internal Conflict to Contextual Adaptation of Language Models**
2407.17023v1 by Sara Vera Marjanović, Haeun Yu, Pepa Atanasova, Maria Maistro, Christina Lioma, Isabelle Augenstein

Knowledge-intensive language understanding tasks require Language Models
(LMs) to integrate relevant context, mitigating their inherent weaknesses, such
as incomplete or outdated knowledge. Nevertheless, studies indicate that LMs
often ignore the provided context as it can conflict with the pre-existing LM's
memory learned during pre-training. Moreover, conflicting knowledge can already
be present in the LM's parameters, termed intra-memory conflict. Existing works
have studied the two types of knowledge conflicts only in isolation. We
conjecture that the (degree of) intra-memory conflicts can in turn affect LM's
handling of context-memory conflicts. To study this, we introduce the DYNAMICQA
dataset, which includes facts with a temporal dynamic nature where a fact can
change with a varying time frequency and disputable dynamic facts, which can
change depending on the viewpoint. DYNAMICQA is the first to include real-world
knowledge conflicts and provide context to study the link between the different
types of knowledge conflicts. With the proposed dataset, we assess the use of
uncertainty for measuring the intra-memory conflict and introduce a novel
Coherent Persuasion (CP) score to evaluate the context's ability to sway LM's
semantic output. Our extensive experiments reveal that static facts, which are
unlikely to change, are more easily updated with additional context, relative
to temporal and disputable facts.

摘要：知識密集型語言理解任務需要語言模型 (LM) 整合相關背景，以減輕其固有的弱點，例如不完整或過時的知識。儘管如此，研究表明，LM 經常會忽略所提供的背景，因為它可能會與 LM 在預訓練期間學習的既有記憶產生衝突。此外，衝突的知識可能已經存在於 LM 的參數中，稱為記憶內衝突。現有的作品僅孤立地研究了這兩種類型的知識衝突。我們推測，記憶內衝突的（程度）反過來會影響 LM 處理上下文記憶衝突的方式。為了研究這一點，我們引入了 DYNAMICQA 資料集，其中包括具有時間動態特性的事實，其中事實可以隨著不同的時間頻率而改變，以及可爭議的動態事實，它可以根據觀點而改變。DYNAMICQA 是第一個包含真實世界知識衝突並提供背景以研究不同類型知識衝突之間聯繫的資料集。使用建議的資料集，我們評估了使用不確定性來衡量記憶內衝突，並引入了新的相干說服 (CP) 分數來評估背景影響 LM 語義輸出的能力。我們廣泛的實驗表明，不太可能改變的靜態事實相對於時間和可爭議的事實，更容易用額外的背景來更新。

##### **Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education**
2407.17022v1 by Seungyoon Kim, Seungone Kim

Large language model (LLM)-based evaluation pipelines have demonstrated their
capability to robustly evaluate machine-generated text. Extending this
methodology to assess human-written text could significantly benefit
educational settings by providing direct feedback to enhance writing skills,
although this application is not straightforward. In this paper, we investigate
whether LLMs can effectively assess human-written text for educational
purposes. We collected 100 texts from 32 Korean students across 15 types of
writing and employed GPT-4-Turbo to evaluate them using grammaticality,
fluency, coherence, consistency, and relevance as criteria. Our analyses
indicate that LLM evaluators can reliably assess grammaticality and fluency, as
well as more objective types of writing, though they struggle with other
criteria and types of writing. We publicly release our dataset and feedback.

摘要：基於大型語言模型 (LLM) 的評估管道已展現其穩健評估機器產生的文字的能力。將此方法擴展到評量人類撰寫的文字，能透過提供直接回饋來增強寫作技巧，對教育環境大有助益，儘管此應用並不簡單。在本文中，我們探討 LLM 是否能有效評估人類撰寫的文字，以供教育用途。我們從 32 位韓國學生收集了 100 篇文字，涵蓋 15 種類型的寫作，並使用 GPT-4-Turbo 來評估它們，以文法、流暢度、連貫性、一致性和相關性為準則。我們的分析表明，LLM 評估器可以可靠地評估文法和流暢度，以及較客觀的寫作類型，儘管它們在其他準則和寫作類型上仍有困難。我們公開發布我們的資料集和回饋。

##### **Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism**
2407.17011v1 by Anhao Zhao, Fanghua Ye, Jinlan Fu, Xiaoyu Shen

Large language models (LLMs) exhibit remarkable in-context learning (ICL)
capabilities. However, the underlying working mechanism of ICL remains poorly
understood. Recent research presents two conflicting views on ICL: One
attributes it to LLMs' inherent ability of task recognition, deeming label
correctness and shot numbers of demonstrations as not crucial; the other
emphasizes the impact of similar examples in the demonstrations, stressing the
need for label correctness and more shots. In this work, we provide a
Two-Dimensional Coordinate System that unifies both views into a systematic
framework. The framework explains the behavior of ICL through two orthogonal
variables: whether LLMs can recognize the task and whether similar examples are
presented in the demonstrations. We propose the peak inverse rank metric to
detect the task recognition ability of LLMs and study LLMs' reactions to
different definitions of similarity. Based on these, we conduct extensive
experiments to elucidate how ICL functions across each quadrant on multiple
representative classification tasks. Finally, we extend our analyses to
generation tasks, showing that our coordinate system can also be used to
interpret ICL for generation tasks effectively.

摘要：大型语言模型 (LLM) 展现出非凡的语境学习 (ICL) 能力。然而，ICL 的底层工作机制仍然知之甚少。最近的研究对 ICL 提出了两种相互矛盾的观点：一种将其归因于 LLM 任务识别的固有能力，认为标签正确性和演示的镜头数不重要；另一种强调演示中相似示例的影响，强调标签正确性和更多镜头的重要性。在这项工作中，我们提供了一个二维坐标系，将这两种观点统一到一个系统框架中。该框架通过两个正交变量解释了 ICL 的行为：LLM 是否可以识别任务以及演示中是否呈现了相似示例。我们提出了峰值逆秩度量来检测 LLM 的任务识别能力，并研究 LLM 对相似性不同定义的反应。基于这些，我们进行了广泛的实验来阐明 ICL 如何在多个代表性分类任务的每个象限中发挥作用。最后，我们将我们的分析扩展到生成任务，表明我们的坐标系也可以有效地用于解释生成任务的 ICL。

##### **SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**
2407.16999v1 by Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis
onset prediction and diagnosis could significantly improve the survival of
sepsis patients. Existing predictive models are usually trained on high-quality
data with few missing information, while missing values widely exist in
real-world clinical scenarios (especially in the first hours of admissions to
the hospital), which causes a significant decrease in accuracy and an increase
in uncertainty for the predictive models. The common method to handle missing
values is imputation, which replaces the unavailable variables with estimates
from the observed data. The uncertainty of imputation results can be propagated
to the sepsis prediction outputs, which have not been studied in existing works
on either sepsis prediction or uncertainty quantification. In this study, we
first define such propagated uncertainty as the variance of prediction output
and then introduce uncertainty propagation methods to quantify the propagated
uncertainty. Moreover, for the potential high-risk patients with low confidence
due to limited observations, we propose a robust active sensing algorithm to
increase confidence by actively recommending clinicians to observe the most
informative variables. We validate the proposed models in both publicly
available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The
Ohio State University Wexner Medical Center (OSUWMC). The experimental results
show that the propagated uncertainty is dominant at the beginning of admissions
to hospitals and the proposed algorithm outperforms state-of-the-art active
sensing methods. Finally, we implement a SepsisLab system for early sepsis
prediction and active sensing based on our pre-trained models. Clinicians and
potential sepsis patients can benefit from the system in early prediction and
diagnosis of sepsis.

摘要：敗血症是美國醫院中死亡的主要原因。敗血症的早期發作預測和診斷可以顯著提高敗血症患者的存活率。現有的預測模型通常在資料品質高且遺失資訊較少的情況下進行訓練，而遺失值在實際臨床情境中普遍存在（尤其是在入院的前幾個小時），這會導致預測模型的準確度顯著下降，並增加不確定性。處理遺失值的常見方法是內插，它使用從觀測資料中估計的數值取代不可用的變數。內插結果的不確定性可能會傳播到敗血症預測輸出，這在現有的敗血症預測或不確定性量化研究中尚未被探討。在這項研究中，我們首先將這種傳播的不確定性定義為預測輸出的變異，然後引入不確定性傳播方法來量化傳播的不確定性。此外，對於由於觀察有限而導致信心較低的潛在高風險患者，我們提出了一種強大的主動感測演算法，透過主動建議臨床醫生觀察最有資訊性的變數來增加信心。我們在公開資料（例如 MIMIC-III 和 AmsterdamUMCdb）和俄亥俄州立大學韋克斯納醫學中心 (OSUWMC) 的專有資料中驗證了所提出的模型。實驗結果表明，傳播的不確定性在入院初期佔主導地位，而所提出的演算法優於最先進的主動感測方法。最後，我們根據預先訓練的模型實作了一個敗血症實驗室系統，用於早期敗血症預測和主動感測。臨床醫生和潛在的敗血症患者可以在敗血症的早期預測和診斷中受益於該系統。

##### **Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective**
2407.16997v1 by Yujian Liu, Yang Zhang, Tommi Jaakkola, Shiyu Chang

This paper investigates Who's Harry Potter (WHP), a pioneering yet
insufficiently understood method for LLM unlearning. We explore it in two
steps. First, we introduce a new task of LLM targeted unlearning, where given
an unlearning target (e.g., a person) and some unlearning documents, we aim to
unlearn only the information about the target, rather than everything in the
unlearning documents. We further argue that a successful unlearning should
satisfy criteria such as not outputting gibberish, not fabricating facts about
the unlearning target, and not releasing factual information under jailbreak
attacks. Second, we construct a causal intervention framework for targeted
unlearning, where the knowledge of the unlearning target is modeled as a
confounder between LLM input and output, and the unlearning process as a
deconfounding process. This framework justifies and extends WHP, deriving a
simple unlearning algorithm that includes WHP as a special case. Experiments on
existing and new datasets show that our approach, without explicitly optimizing
for the aforementioned criteria, achieves competitive performance in all of
them. Our code is available at
https://github.com/UCSB-NLP-Chang/causal_unlearn.git.

摘要：這篇論文探討了「哈利波特是誰」(WHP)，一種開創性但理解不足的 LLM 遺忘方法。我們分兩步探討它。首先，我們介紹 LLM 目標遺忘的新任務，其中給定一個遺忘目標（例如，一個人）和一些遺忘文件，我們的目標是只遺忘有關目標的資訊，而不是遺忘文件中的一切。我們進一步論證，成功的遺忘應該滿足某些標準，例如不輸出無意義的文字、不捏造有關遺忘目標的事實，以及在越獄攻擊下不釋出事實資訊。其次，我們構建了一個針對性遺忘的因果介入架構，其中遺忘目標的知識被建模為 LLM 輸入和輸出之間的混淆因子，而遺忘過程則作為一個去混淆過程。這個架構證明並延伸了 WHP，推導出一個簡單的遺忘演算法，其中 WHP 是特殊情況。在現有和新的資料集上的實驗表明，我們的做法在不針對上述標準進行明確最佳化的情況下，在所有標準中都取得了有競爭力的表現。我們的程式碼可在 https://github.com/UCSB-NLP-Chang/causal_unlearn.git 取得。

##### **A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs**
2407.16994v1 by Jake R. Watts, Joel Sokol

This paper proposes a new method for preventing unsafe or otherwise low
quality large language model (LLM) outputs, by leveraging the stochasticity of
LLMs. We propose a system whereby LLM checkers vote on the acceptability of a
generated output, regenerating it if a threshold of disapproval is reached,
until sufficient checkers approve. We further propose estimators for cost and
failure rate, and based on those estimators and experimental data tailored to
the application, we propose an algorithm that achieves a desired failure rate
at the least possible cost. We demonstrate that, under these models, failure
rate decreases exponentially as a function of cost when voter count and
threshold are chosen according to the algorithm, and that the models reasonably
estimate the actual performance of such a system in action, even with limited
data.

摘要：本文提出了一種防止不安全或品質低劣的大型語言模型 (LLM) 輸出的新方法，方法是利用 LLM 的隨機性。我們提出一個系統，讓 LLM 檢查員對產生的輸出是否可接受進行投票，如果達到不通過的門檻值，則重新產生輸出，直到有足夠的檢查員通過。我們進一步提出成本和失敗率的估計器，並根據這些估計器和針對應用程式量身打造的實驗資料，我們提出一個演算法，以最低成本達成所需的失敗率。我們證明，在這些模型下，當投票者數量和門檻值根據演算法選擇時，失敗率會隨著成本呈指數下降，而且即使資料有限，這些模型也能合理地估計此類系統在實際運作中的效能。

##### **Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model**
2407.16982v1 by Lirui Zhao, Tianshuo Yang, Wenqi Shao, Yuxin Zhang, Yu Qiao, Ping Luo, Kaipeng Zhang, Rongrong Ji

This paper addresses an important problem of object addition for images with
only text guidance. It is challenging because the new object must be integrated
seamlessly into the image with consistent visual context, such as lighting,
texture, and spatial location. While existing text-guided image inpainting
methods can add objects, they either fail to preserve the background
consistency or involve cumbersome human intervention in specifying bounding
boxes or user-scribbled masks. To tackle this challenge, we introduce Diffree,
a Text-to-Image (T2I) model that facilitates text-guided object addition with
only text control. To this end, we curate OABench, an exquisite synthetic
dataset by removing objects with advanced image inpainting techniques. OABench
comprises 74K real-world tuples of an original image, an inpainted image with
the object removed, an object mask, and object descriptions. Trained on OABench
using the Stable Diffusion model with an additional mask prediction module,
Diffree uniquely predicts the position of the new object and achieves object
addition with guidance from only text. Extensive experiments demonstrate that
Diffree excels in adding new objects with a high success rate while maintaining
background consistency, spatial appropriateness, and object relevance and
quality.

摘要：这篇论文针对仅有文字指导的图像对象添加问题提出了一个重要的解决方法。它具有挑战性，因为新对象必须无缝地融入图像，并具有与光线、纹理和空间位置等一致的视觉环境。虽然现有的文本引导图像修复方法可以添加对象，但它们要么无法保持背景一致性，要么涉及到在指定边界框或用户涂鸦蒙版时繁琐的人工干预。为了应对这一挑战，我们引入了 Diffree，一个文本到图像 (T2I) 模型，它仅通过文本控制即可促进文本引导的对象添加。为此，我们策划了 OABench，这是一个精美的合成数据集，通过使用高级图像修复技术移除了对象。OABench 包含 74K 个真实世界的元组，包括原始图像、移除了对象的修复图像、对象蒙版和对象描述。在使用具有附加蒙版预测模块的 Stable Diffusion 模型对 OABench 进行训练后，Diffree 独特地预测了新对象的位置，并仅通过文本指导实现了对象添加。大量的实验表明，Diffree 在添加新对象时成功率很高，同时保持了背景一致性、空间适当性以及对象的关联性和质量。

##### **Case-Enhanced Vision Transformer: Improving Explanations of Image Similarity with a ViT-based Similarity Metric**
2407.16981v1 by Ziwei Zhao, David Leake, Xiaomeng Ye, David Crandall

This short paper presents preliminary research on the Case-Enhanced Vision
Transformer (CEViT), a similarity measurement method aimed at improving the
explainability of similarity assessments for image data. Initial experimental
results suggest that integrating CEViT into k-Nearest Neighbor (k-NN)
classification yields classification accuracy comparable to state-of-the-art
computer vision models, while adding capabilities for illustrating differences
between classes. CEViT explanations can be influenced by prior cases, to
illustrate aspects of similarity relevant to those cases.

摘要：本篇簡短論文提出關於 Case-Enhanced Vision Transformer (CEViT) 的初步研究，這是一種相似度測量方法，旨在提升影像資料相似度評估的可解釋性。初步實驗結果顯示，將 CEViT 整合到 k-最近鄰 (k-NN) 分類中，可產生與現有最先進電腦視覺模型相當的分類準確度，同時增加說明類別差異的功能。CEViT 解釋會受到先前案例影響，說明與這些案例相關的相似性面向。

##### **Towards Aligning Language Models with Textual Feedback**
2407.16970v1 by Saüc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan

We present ALT (ALignment with Textual feedback), an approach that aligns
language models with user preferences expressed in text. We argue that text
offers greater expressiveness, enabling users to provide richer feedback than
simple comparative preferences and this richer feedback can lead to more
efficient and effective alignment. ALT aligns the model by conditioning its
generation on the textual feedback. Our method relies solely on language
modeling techniques and requires minimal hyper-parameter tuning, though it
still presents the main benefits of RL-based alignment algorithms and can
effectively learn from textual feedback. We explore the efficacy and efficiency
of textual feedback across different tasks such as toxicity reduction,
summarization, and dialog response generation. We find that ALT outperforms PPO
for the task of toxicity reduction while being able to match its performance on
summarization with only 20% of the samples. We also explore how ALT can be used
with feedback provided by an existing LLM where we explore an LLM providing
constrained and unconstrained textual feedback. We also outline future
directions to align models with natural language feedback.

摘要：我們提出 ALT（與文字回饋對齊），這是一種將語言模型與使用者在文字中表達的偏好對齊的方法。我們認為文字提供更大的表達力，讓使用者能夠提供比單純的比較偏好更豐富的回饋，而這種更豐富的回饋可以帶來更有效率且更有效的對齊。ALT 透過將模型的生成條件化在文字回饋上來對齊模型。我們的技術僅依賴語言建模技術，且需要最少的超參數調整，儘管它仍提供 RL 基於對齊演算法的主要好處，且可以有效地從文字回饋中學習。我們探討文字回饋在不同任務中的效能和效率，例如降低毒性、摘要和對話回應生成。我們發現 ALT 在降低毒性的任務上優於 PPO，同時僅使用 20% 的樣本就能匹配其在摘要上的效能。我們也探討 ALT 如何與現有 LLM 提供的回饋一起使用，其中我們探討 LLM 提供受限和不受限的文字回饋。我們也概述了將模型與自然語言回饋對齊的未來方向。

##### **Stochastic Variance-Reduced Iterative Hard Thresholding in Graph Sparsity Optimization**
2407.16968v1 by Derek Fox, Samuel Hernandez, Qianqian Tong

Stochastic optimization algorithms are widely used for large-scale data
analysis due to their low per-iteration costs, but they often suffer from slow
asymptotic convergence caused by inherent variance. Variance-reduced techniques
have been therefore used to address this issue in structured sparse models
utilizing sparsity-inducing norms or $\ell_0$-norms. However, these techniques
are not directly applicable to complex (non-convex) graph sparsity models,
which are essential in applications like disease outbreak monitoring and social
network analysis. In this paper, we introduce two stochastic variance-reduced
gradient-based methods to solve graph sparsity optimization: GraphSVRG-IHT and
GraphSCSG-IHT. We provide a general framework for theoretical analysis,
demonstrating that our methods enjoy a linear convergence speed. Extensive
experiments validate

摘要：隨機優化演算法由於其每次迭代成本低，而廣泛用於大規模資料分析，但它們通常會因內在變異而導致漸近收斂速度慢。因此，已經使用降低變異的技術來解決結構化稀疏模型中此問題，利用誘導稀疏性的範數或 $\ell_0$-範數。然而，這些技術並不直接適用於複雜（非凸）圖形稀疏性模型，這在疾病爆發監測和社交網路分析等應用中至關重要。在本文中，我們介紹了兩種隨機變異減少的基於梯度的演算法來解決圖形稀疏性最佳化：GraphSVRG-IHT 和 GraphSCSG-IHT。我們提供了一個理論分析的通用框架，證明了我們的演算法具有線性收斂速度。大量的實驗驗證

##### **Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**
2407.16962v1 by Nur Ahmad Khatim, Ahmad Azmul Asmar Irfan, Amaliya Mata'ul Hayah, Mansur M. Arief

This study addresses the challenge of stroke diagnosis and treatment under
uncertainty, a critical issue given the rapid progression and severe
consequences of stroke conditions such as aneurysms, arteriovenous
malformations (AVM), and occlusions. Current diagnostic methods, including
Digital Subtraction Angiography (DSA), face limitations due to high costs and
its invasive nature. To overcome these challenges, we propose a novel approach
using a Partially Observable Markov Decision Process (POMDP) framework. Our
model integrates advanced diagnostic tools and treatment approaches with a
decision-making algorithm that accounts for the inherent uncertainties in
stroke diagnosis. Our approach combines noisy observations from CT scans,
Siriraj scores, and DSA reports to inform the subsequent treatment options. We
utilize the online solver DESPOT, which employs tree-search methods and
particle filters, to simulate potential future scenarios and guide our
strategies. The results indicate that our POMDP framework balances diagnostic
and treatment objectives, striking a tradeoff between the need for precise
stroke identification via invasive procedures like DSA and the constraints of
limited healthcare resources that necessitate more cost-effective strategies,
such as in-hospital or at-home observation, by relying only relying on
simulation rollouts and not imposing any prior knowledge. Our study offers a
significant contribution by presenting a systematic framework that optimally
integrates diagnostic and treatment processes for stroke and accounting for
various uncertainties, thereby improving care and outcomes in stroke
management.

摘要：本研究探討在不確定性下中風的診斷和治療的挑戰，這是考量到中風狀況（例如動脈瘤、動靜脈畸形 (AVM) 和阻塞）的快速進展和嚴重後果而出現的關鍵問題。目前的診斷方法（包括數位減影血管攝影 (DSA)）由於成本高昂和侵入性而面臨限制。為了克服這些挑戰，我們提出了一種使用部分可觀察馬可夫決策過程 (POMDP) 架構的新穎方法。我們的模型整合了先進的診斷工具和治療方法，以及一個決策演算法，該演算法考量了中風診斷中固有的不確定性。我們的做法結合了來自電腦斷層掃描、Siriraj 評分和 DSA 報告的雜訊觀測值，以告知後續的治療選項。我們利用線上求解器 DESPOT，它採用樹狀搜尋方法和粒子濾波器，模擬潛在的未來情境並指導我們的策略。結果表明，我們的 POMDP 架構平衡了診斷和治療目標，在透過 DSA 等侵入性程序精確識別中風的需求與需要更具成本效益的策略（例如住院或居家觀察）的醫療資源限制之間取得平衡，僅依賴模擬推出且不施加任何先驗知識。我們的研究透過提出一個系統性架構，最佳化整合中風的診斷和治療過程並考量各種不確定性，從而改善中風管理的照護和結果，做出了重大貢獻。

##### **Cheems: Wonderful Matrices More Efficient and More Effective Architecture**
2407.16958v2 by Jingze Shi, Lu He, Yuhan Wang, Tianyu He, Bingheng Wu, Mingkun Hou

Recent studies have shown that, relative position encoding performs well in
selective state space model scanning algorithms, and the architecture that
balances SSM and Attention enhances the efficiency and effectiveness of the
algorithm, while the sparse activation of the mixture of experts reduces the
training cost. I studied the effectiveness of using different position
encodings in structured state space dual algorithms, and the more effective
SSD-Attn internal and external function mixing method, and designed a more
efficient cross domain mixture of experts. I found that the same matrix is very
wonderful in different algorithms, which allows us to establish a new hybrid
sparse architecture: Cheems. Compared with other hybrid architectures, it is
more efficient and more effective in language modeling tasks.

摘要：最近的研究表明，相对位置编码在选择性状态空间模型扫描算法中表现良好，而平衡 SSM 和注意力的架构提高了算法的效率和有效性，而专家混合的稀疏激活降低了训练成本。我研究了在结构化状态空间对偶算法中使用不同位置编码的有效性，以及更有效的 SSD-Attn 内部和外部功能混合方法，并设计了一种更有效的跨域专家混合。我发现同一个矩阵在不同的算法中非常精彩，这使我们能够建立一个新的混合稀疏架构：Cheems。与其他混合架构相比，它在语言建模任务中更有效率、更有效。

##### **Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation**
2407.16951v1 by Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

Large language models (LLMs) often inherit biases from vast amounts of
training corpora. Traditional debiasing methods, while effective to some
extent, do not completely eliminate memorized biases and toxicity in LLMs. In
this paper, we study an unlearning-based approach to debiasing in LLMs by
performing gradient ascent on hate speech against minority groups, i.e.,
minimizing the likelihood of biased or toxic content. Specifically, we propose
a mask language modeling unlearning technique, which unlearns the harmful part
of the text. This method enables LLMs to selectively forget and disassociate
from biased and harmful content. Experimental results demonstrate the
effectiveness of our approach in diminishing bias while maintaining the
language modeling abilities. Surprisingly, the results also unveil an
unexpected potential for cross-domain transfer unlearning: debiasing in one
bias form (e.g. gender) may contribute to mitigating others (e.g. race and
religion).

摘要：大型語言模型 (LLM) 通常會從大量訓練資料集中繼承偏見。傳統的去偏見方法雖然在某種程度上有效，但並不能完全消除 LLM 中記憶的偏見和毒性。在本文中，我們研究了一種基於遺忘的 LLM 去偏見方法，方法是對針對少數群體的仇恨言論執行梯度上升，即最小化有偏見或有毒內容的可能性。具體來說，我們提出了一種遮罩語言建模遺忘技術，該技術遺忘了文本中有害的部分。此方法使 LLM 能夠選擇性地遺忘並擺脫有偏見和有害的內容。實驗結果證明了我們的方法在減少偏見的同時保持語言建模能力的有效性。令人驚訝的是，結果還揭示了跨域轉移遺忘的意外潛力：一種偏見形式（例如性別）的去偏見可能有助於減輕其他偏見（例如種族和宗教）。

##### **Early screening of potential breakthrough technologies with enhanced interpretability: A patent-specific hierarchical attention network model**
2407.16939v1 by Jaewoong Choi, Janghyeok Yoon, Changyong Lee

Despite the usefulness of machine learning approaches for the early screening
of potential breakthrough technologies, their practicality is often hindered by
opaque models. To address this, we propose an interpretable machine learning
approach to predicting future citation counts from patent texts using a
patent-specific hierarchical attention network (PatentHAN) model. Central to
this approach are (1) a patent-specific pre-trained language model, capturing
the meanings of technical words in patent claims, (2) a hierarchical network
structure, enabling detailed analysis at the claim level, and (3) a claim-wise
self-attention mechanism, revealing pivotal claims during the screening
process. A case study of 35,376 pharmaceutical patents demonstrates the
effectiveness of our approach in early screening of potential breakthrough
technologies while ensuring interpretability. Furthermore, we conduct
additional analyses using different language models and claim types to examine
the robustness of the approach. It is expected that the proposed approach will
enhance expert-machine collaboration in identifying breakthrough technologies,
providing new insight derived from text mining into technological value.

摘要：儘管機器學習方法對於潛在突破性技術的早期篩選很有用，但它們的實用性常常受到不透明模型的阻礙。為了解決這個問題，我們提出了一個可解釋的機器學習方法，使用專利特定分層注意力網路 (PatentHAN) 模型，根據專利文字預測未來的引文次數。這種方法的核心是 (1) 一個專利特定的預訓練語言模型，捕捉專利權利要求中技術詞彙的含義，(2) 一個分層網路結構，可以在權利要求層級進行詳細分析，以及 (3) 一個基於權利要求的自注意力機制，在篩選過程中揭示關鍵的權利要求。對 35,376 項製藥專利的案例研究證明了我們的方法在潛在突破性技術的早期篩選中的有效性，同時確保了可解釋性。此外，我們使用不同的語言模型和權利要求類型進行了額外的分析，以檢查該方法的穩健性。預計所提出的方法將增強專家機器在識別突破性技術方面的合作，從文字探勘中提供對技術價值的新見解。

##### **Synthetic Trajectory Generation Through Convolutional Neural Networks**
2407.16938v1 by Jesse Merhi, Erik Buchholz, Salil S. Kanhere

Location trajectories provide valuable insights for applications from urban
planning to pandemic control. However, mobility data can also reveal sensitive
information about individuals, such as political opinions, religious beliefs,
or sexual orientations. Existing privacy-preserving approaches for publishing
this data face a significant utility-privacy trade-off. Releasing synthetic
trajectory data generated through deep learning offers a promising solution.
Due to the trajectories' sequential nature, most existing models are based on
recurrent neural networks (RNNs). However, research in generative adversarial
networks (GANs) largely employs convolutional neural networks (CNNs) for image
generation. This discrepancy raises the question of whether advances in
computer vision can be applied to trajectory generation. In this work, we
introduce a Reversible Trajectory-to-CNN Transformation (RTCT) that adapts
trajectories into a format suitable for CNN-based models. We integrated this
transformation with the well-known DCGAN in a proof-of-concept (PoC) and
evaluated its performance against an RNN-based trajectory GAN using four
metrics across two datasets. The PoC was superior in capturing spatial
distributions compared to the RNN model but had difficulty replicating
sequential and temporal properties. Although the PoC's utility is not
sufficient for practical applications, the results demonstrate the
transformation's potential to facilitate the use of CNNs for trajectory
generation, opening up avenues for future research. To support continued
research, all source code has been made available under an open-source license.

摘要：位置軌跡為從都市規劃到疫情控制等應用程式提供了有價值的見解。然而，流動性資料也可能揭露個人敏感資訊，例如政治觀點、宗教信仰或性取向。現有的隱私保護方法在發布此資料時面臨重大的效用隱私權取捨。釋出透過深度學習產生的合成軌跡資料提供了有前途的解決方案。由於軌跡的順序性質，大多數現有模型都基於遞迴神經網路 (RNN)。然而，生成對抗網路 (GAN) 的研究在很大程度上採用了卷積神經網路 (CNN) 來產生影像。這種差異引發了一個問題，即電腦視覺的進步是否可以應用於軌跡生成。在這項工作中，我們引入了可逆軌跡到 CNN 轉換 (RTCT)，它將軌跡轉換成適合基於 CNN 的模型的格式。我們在概念驗證 (PoC) 中將此轉換與著名的 DCGAN 整合，並使用四個指標在兩個資料集上評估其效能與基於 RNN 的軌跡 GAN 相比。與 RNN 模型相比，PoC 在捕捉空間分佈方面表現優異，但難以複製順序和時間屬性。儘管 PoC 的效用不足以應用於實際應用，但結果證明了轉換在促進使用 CNN 進行軌跡生成的潛力，為未來的研究打開了道路。為了支持持續的研究，所有原始程式碼已在開源授權下提供。

##### **ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering**
2407.16931v1 by Xiuying Chen, Tairan Wang, Taicheng Guo, Kehan Guo, Juexiao Zhou, Haoyang Li, Mingchen Zhuge, Jürgen Schmidhuber, Xin Gao, Xiangliang Zhang

Question Answering (QA) effectively evaluates language models' reasoning and
knowledge depth. While QA datasets are plentiful in areas like general domain
and biomedicine, academic chemistry is less explored. Chemical QA plays a
crucial role in both education and research by effectively translating complex
chemical information into readily understandable format. Addressing this gap,
we introduce ScholarChemQA, a large-scale QA dataset constructed from chemical
papers. This dataset reflects typical real-world challenges, including an
imbalanced data distribution and a substantial amount of unlabeled data that
can be potentially useful. Correspondingly, we introduce a QAMatch model,
specifically designed to effectively answer chemical questions by fully
leveraging our collected data. We first address the issue of imbalanced label
distribution by re-weighting the instance-wise loss based on the inverse
frequency of each class, ensuring minority classes are not dominated by
majority ones during optimization. Next, we utilize the unlabeled data to
enrich the learning process, generating a variety of augmentations based on a
SoftMix operation and ensuring their predictions align with the same target,
i.e., pseudo-labels. To ensure the quality of the pseudo-labels, we propose a
calibration procedure aimed at closely aligning the pseudo-label estimates of
individual samples with a desired ground truth distribution. Experiments show
that our QAMatch significantly outperforms the recent similar-scale baselines
and Large Language Models (LLMs) not only on our ScholarChemQA dataset but also
on four benchmark datasets. We hope our benchmark and model can facilitate and
promote more research on chemical QA.

摘要：問答 (QA) 有效地評估語言模型的推理和知識深度。雖然在一般領域和生物醫學等領域中 QA 資料集很豐富，但學術化學卻較少被探討。化學 QA 在教育和研究中都扮演著關鍵角色，它能有效地將複雜的化學資訊轉換成易於理解的格式。為了解決這個差距，我們引入了 ScholarChemQA，一個由化學論文建構而成的、大規模的 QA 資料集。這個資料集反映了典型的現實世界挑戰，包括不平衡的資料分佈和大量的未標註資料，而這些資料可能具有潛在用途。相應地，我們引入了 QAMatch 模型，它專門設計用來有效地回答化學問題，並充分利用我們收集到的資料。我們首先透過根據每個類別的逆頻率重新調整每個例子的損失，來解決不平衡標籤分佈的問題，確保少數類別在最佳化過程中不會被多數類別所主導。接下來，我們利用未標註的資料來豐富學習過程，根據 SoftMix 運算產生各種增強，並確保它們的預測與同一個目標（即偽標籤）保持一致。為了確保偽標籤的品質，我們提出了一個校準程序，旨在讓個別樣本的偽標籤估計值與預期的基本事實分佈緊密一致。實驗顯示，我們的 QAMatch 不僅在我們的 ScholarChemQA 資料集上，也在四個基準資料集上，都明顯優於最近的類似規模基準和大型語言模型 (LLM)。我們希望我們的基準和模型能促進和推動更多關於化學 QA 的研究。

##### **Train-Attention: Meta-Learning Where to Focus in Continual Knowledge Learning**
2407.16920v1 by Yeongbin Seo, Dongha Lee, Jinyoung Yeo

Previous studies on continual knowledge learning (CKL) in large language
models (LLMs) have predominantly focused on approaches such as regularization,
architectural modifications, and rehearsal techniques to mitigate catastrophic
forgetting. However, these methods naively inherit the inefficiencies of
standard training procedures, indiscriminately applying uniform weight across
all tokens, which can lead to unnecessary parameter updates and increased
forgetting. To address these shortcomings, we propose a novel CKL approach
termed Train-Attention-Augmented Language Model (TAALM), which enhances
learning efficiency by dynamically predicting and applying weights to tokens
based on their usefulness. This method employs a meta-learning framework that
optimizes token importance predictions, facilitating targeted knowledge updates
and minimizing forgetting. Also, we observe that existing benchmarks do not
clearly exhibit the trade-off between learning and retaining, therefore we
propose a new benchmark, \textsc{LAMA-ckl}, to address this issue. Through
experiments conducted on both newly introduced and established CKL benchmarks,
TAALM proves the state-of-the-art performance upon the baselines, and also
shows synergistic compatibility when integrated with previous CKL approaches.

摘要：先前的持續知識學習 (CKL) 研究在大型語言模型 (LLM) 中主要集中於正規化、架構修改和排練技術等方法，以減輕災難性遺忘。然而，這些方法天真地繼承了標準訓練程序的低效率，不加區別地對所有符號應用統一權重，這可能導致不必要的參數更新和增加遺忘。為了解決這些缺點，我們提出了一種新的 CKL 方法，稱為訓練注意力增強語言模型 (TAALM)，它通過根據符號的有用性動態預測和應用權重來提高學習效率。此方法採用元學習框架，該框架優化符號重要性預測，促進有針對性的知識更新並最大程度地減少遺忘。此外，我們觀察到現有的基準並未明確展示學習和保留之間的權衡，因此我們提出了一個新的基準 \textsc{LAMA-ckl} 來解決此問題。通過在新引入和既定的 CKL 基準上進行的實驗，TAALM 證明了在基準線上的最新技術，並且在與先前的 CKL 方法集成時也顯示出協同兼容性。

##### **Generation Constraint Scaling Can Mitigate Hallucination**
2407.16908v1 by Georgios Kollias, Payel Das, Subhajit Chaudhury

Addressing the issue of hallucinations in large language models (LLMs) is a
critical challenge. As the cognitive mechanisms of hallucination have been
related to memory, here we explore hallucination for LLM that is enabled with
explicit memory mechanisms. We empirically demonstrate that by simply scaling
the readout vector that constrains generation in a memory-augmented LLM
decoder, hallucination mitigation can be achieved in a training-free manner.
Our method is geometry-inspired and outperforms a state-of-the-art LLM editing
method on the task of generation of Wikipedia-like biography entries both in
terms of generation quality and runtime complexity.

摘要：針對大型語言模型 (LLM) 中的幻覺問題進行探討是一項重大挑戰。由於幻覺的認知機制與記憶有關，因此我們在此探討具備明確記憶機制的 LLM 幻覺。我們透過實證證明，只要縮放約束記憶增強 LLM 解碼器中生成的讀出向量，即可在無訓練的情況下減輕幻覺。我們的做法受幾何啟發，且在生成類似維基百科傳記條目的任務中，在生成品質和執行時間複雜度方面都優於最先進的 LLM 編輯方法。

##### **$\textit{BenchIE}^{FL}$ : A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark**
2407.16860v1 by Fabrice Lamarche, Philippe Langlais

Open Information Extraction (OIE) is a field of natural language processing
that aims to present textual information in a format that allows it to be
organized, analyzed and reflected upon. Numerous OIE systems are developed,
claiming ever-increasing performance, marking the need for objective
benchmarks. BenchIE is the latest reference we know of. Despite being very well
thought out, we noticed a number of issues we believe are limiting. Therefore,
we propose $\textit{BenchIE}^{FL}$, a new OIE benchmark which fully enforces
the principles of BenchIE while containing fewer errors, omissions and
shortcomings when candidate facts are matched towards reference ones.
$\textit{BenchIE}^{FL}$ allows insightful conclusions to be drawn on the actual
performance of OIE extractors.

摘要：開放式資訊萃取 (OIE) 是自然語言處理的一個領域，旨在將文字資訊呈現為可組織、分析和反思的格式。已開發出許多 OIE 系統，聲稱效能不斷提升，標誌著對客觀基準的需求。BenchIE 是我們所知最新的參考。儘管構想非常完善，我們注意到一些我們認為有待改進的問題。因此，我們提出 $\textit{BenchIE}^{FL}$，一個新的 OIE 基準，它完全遵循 BenchIE 的原則，同時在將候選事實與參考事實匹配時包含更少的錯誤、遺漏和缺點。$\textit{BenchIE}^{FL}$ 允許對 OIE 萃取器的實際效能得出有見地的結論。

##### **Synth4Kws: Synthesized Speech for User Defined Keyword Spotting in Low Resource Environments**
2407.16840v1 by Pai Zhu, Dhruuv Agarwal, Jacob W. Bartel, Kurt Partridge, Hyun Jin Park, Quan Wang

One of the challenges in developing a high quality custom keyword spotting
(KWS) model is the lengthy and expensive process of collecting training data
covering a wide range of languages, phrases and speaking styles. We introduce
Synth4Kws - a framework to leverage Text to Speech (TTS) synthesized data for
custom KWS in different resource settings. With no real data, we found
increasing TTS phrase diversity and utterance sampling monotonically improves
model performance, as evaluated by EER and AUC metrics over 11k utterances of
the speech command dataset. In low resource settings, with 50k real utterances
as a baseline, we found using optimal amounts of TTS data can improve EER by
30.1% and AUC by 46.7%. Furthermore, we mix TTS data with varying amounts of
real data and interpolate the real data needed to achieve various quality
targets. Our experiments are based on English and single word utterances but
the findings generalize to i18n languages and other keyword types.

摘要：開發高品質自訂關鍵字辨識 (KWS) 模型時，其中一項挑戰在於收集訓練資料的過程漫長且昂貴，而這些資料必須涵蓋廣泛的語言、詞組和說話風格。我們推出 Synth4Kws，這是一個架構，可利用文字轉語音 (TTS) 合成的資料，在不同的資源設定中進行自訂 KWS。在沒有真實資料的情況下，我們發現增加 TTS 詞組多樣性和語句取樣，會單調地提升模型效能，這點從語音指令資料集 11k 個語句的 EER 和 AUC 指標評估中可見。在低資源設定中，以 50k 個真實語句作為基準，我們發現使用最佳數量的 TTS 資料，可以將 EER 提升 30.1%，AUC 提升 46.7%。此外，我們將 TTS 資料與不同數量的真實資料混合，並插入達到各種品質目標所需的真實資料。我們的實驗基於英文和單字語句，但這些發現可以推廣到 i18n 語言和其他關鍵字類型。

##### **CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs**
2407.16837v1 by Jihyung Kil, Zheda Mai, Justin Lee, Zihe Wang, Kerrie Cheng, Lemeng Wang, Ye Liu, Arpita Chowdhury, Wei-Lun Chao

The ability to compare objects, scenes, or situations is crucial for
effective decision-making and problem-solving in everyday life. For instance,
comparing the freshness of apples enables better choices during grocery
shopping, while comparing sofa designs helps optimize the aesthetics of our
living space. Despite its significance, the comparative capability is largely
unexplored in artificial general intelligence (AGI). In this paper, we
introduce CompBench, a benchmark designed to evaluate the comparative reasoning
capability of multimodal large language models (MLLMs). CompBench mines and
pairs images through visually oriented questions covering eight dimensions of
relative comparison: visual attribute, existence, state, emotion, temporality,
spatiality, quantity, and quality. We curate a collection of around 40K image
pairs using metadata from diverse vision datasets and CLIP similarity scores.
These image pairs span a broad array of visual domains, including animals,
fashion, sports, and both outdoor and indoor scenes. The questions are
carefully crafted to discern relative characteristics between two images and
are labeled by human annotators for accuracy and relevance. We use CompBench to
evaluate recent MLLMs, including GPT-4V(ision), Gemini-Pro, and LLaVA-1.6. Our
results reveal notable shortcomings in their comparative abilities. We believe
CompBench not only sheds light on these limitations but also establishes a
solid foundation for future enhancements in the comparative capability of
MLLMs.

摘要：比較物件、場景或情境的能力對於日常生活中的有效決策制定和問題解決至關重要。例如，比較蘋果的新鮮度可以在購買雜貨時做出更好的選擇，而比較沙發設計有助於優化我們生活空間的美學。儘管其重要性，但比較能力在人工通用智慧 (AGI) 中仍未得到充分探索。在本文中，我們介紹了 CompBench，這是一個基於評估多模態大型語言模型 (MLLM) 的比較推理能力而設計的基準測試。CompBench 通過視覺導向問題挖掘和配對圖像，涵蓋相對比較的八個維度：視覺屬性、存在、狀態、情緒、時間性、空間性、數量和質量。我們使用來自不同視覺數據集的元數據和 CLIP 相似度分數策劃了大約 40K 圖像對的集合。這些圖像對跨越廣泛的視覺領域，包括動物、時尚、運動以及戶外和室內場景。這些問題經過精心設計，旨在辨別兩幅圖像之間的相對特徵，並由人類註釋者標記其準確性和相關性。我們使用 CompBench 來評估最近的 MLLM，包括 GPT-4V(ision)、Gemini-Pro 和 LLaVA-1.6。我們的結果揭示了它們在比較能力方面的顯著缺陷。我們相信 CompBench 不僅可以闡明這些限制，而且還為 MLLM 的比較能力的未來改進奠定了堅實的基礎。

##### **A Multi-Level Hierarchical Framework for the Classification of Weather Conditions and Hazard Prediction**
2407.16834v1 by Harish Neelam

This paper presents a multilevel hierarchical framework for the
classification of weather conditions and hazard prediction. In recent years,
the importance of data has grown significantly, with various types like text,
numbers, images, audio, and videos playing a key role. Among these, images make
up a large portion of the data available. This application shows promise for
various purposes, especially when combined with decision support systems for
traffic management, afforestation, and weather forecasting. It's particularly
useful in situations where traditional weather predictions are not very
accurate, such as ensuring the safe operation of self driving cars in dangerous
weather. While previous studies have looked at this topic with fewer
categories, this paper focuses on eleven specific types of weather images. The
goal is to create a model that can accurately predict weather conditions after
being trained on a large dataset of images. Accuracy is crucial in real-life
situations to prevent accidents, making it the top priority for this paper.
This work lays the groundwork for future applications in weather prediction,
especially in situations where human expertise is not available or may be
biased. The framework, capable of classifying images into eleven weather
categories: dew, frost, glaze, rime, snow, hail, rain, lightning, rainbow, and
sandstorm, provides real-time weather information with an accuracy of 0.9329.
The proposed framework addresses the growing need for accurate weather
classification and hazard prediction, offering a robust solution for various
applications in the field.

摘要：本文提出了一個多層級階層架構，用於天氣狀況分類和災害預測。近年來，資料的重要性大幅提升，各種類型的資料，例如文字、數字、影像、音訊和影片，都扮演著關鍵角色。其中，影像佔了可用資料的很大一部分。此應用程式在各種用途上都展現了前景，特別是與交通管理、造林和天氣預報的決策支援系統結合使用時。在傳統天氣預測不太準確的情況下，它特別有用，例如確保自駕車在惡劣天氣中安全運行。雖然先前的研究已使用較少的類別探討這個主題，但本文著重於 11 種特定類型的氣象影像。目標是建立一個模型，可以在經過大量影像資料集訓練後準確預測天氣狀況。準確性在現實生活中至關重要，可以預防事故，因此是本文的首要任務。這項工作為天氣預測的未來應用奠定了基礎，特別是在無法獲得人類專業知識或可能存在偏見的情況下。這個架構能夠將影像分類為 11 種天氣類別：露水、霜、凍雨、霧淞、雪、冰雹、雨、閃電、彩虹和沙塵暴，並提供準確度為 0.9329 的即時天氣資訊。所提出的架構解決了對準確天氣分類和災害預測日益增長的需求，為該領域的各種應用提供了強大的解決方案。

##### **Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach**
2407.16833v1 by Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky

Retrieval Augmented Generation (RAG) has been a powerful tool for Large
Language Models (LLMs) to efficiently process overly lengthy contexts. However,
recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to
understand long contexts directly. We conduct a comprehensive comparison
between RAG and long-context (LC) LLMs, aiming to leverage the strengths of
both. We benchmark RAG and LC across various public datasets using three latest
LLMs. Results reveal that when resourced sufficiently, LC consistently
outperforms RAG in terms of average performance. However, RAG's significantly
lower cost remains a distinct advantage. Based on this observation, we propose
Self-Route, a simple yet effective method that routes queries to RAG or LC
based on model self-reflection. Self-Route significantly reduces the
computation cost while maintaining a comparable performance to LC. Our findings
provide a guideline for long-context applications of LLMs using RAG and LC.

摘要：檢索增強生成（RAG）一直是大型語言模型（LLM）有效處理過於冗長的內容的強大工具。然而，最近的 LLM，例如 Gemini-1.5 和 GPT-4，表現出直接理解長內容的非凡能力。我們對 RAG 和長內容（LC）LLM 進行了全面的比較，旨在利用兩者的優勢。我們使用三個最新的 LLM 對各種公共數據集對 RAG 和 LC 進行了基準測試。結果表明，當資源充足時，LC 在平均性能方面始終優於 RAG。然而，RAG 明顯較低的成本仍然是一個顯著的優勢。基於這一觀察，我們提出了 Self-Route，這是一種簡單但有效的方法，它根據模型自我反射將查詢路由到 RAG 或 LC。Self-Route 大幅降低了運算成本，同時保持與 LC 相當的性能。我們的研究結果為使用 RAG 和 LC 的 LLM 的長內容應用提供了指導方針。

##### **Networks of Networks: Complexity Class Principles Applied to Compound AI Systems Design**
2407.16831v1 by Jared Quincy Davis, Boris Hanin, Lingjiao Chen, Peter Bailis, Ion Stoica, Matei Zaharia

As practitioners seek to surpass the current reliability and quality frontier
of monolithic models, Compound AI Systems consisting of many language model
inference calls are increasingly employed. In this work, we construct systems,
which we call Networks of Networks (NoNs) organized around the distinction
between generating a proposed answer and verifying its correctness, a
fundamental concept in complexity theory that we show empirically extends to
Language Models (LMs). We introduce a verifier-based judge NoN with K
generators, an instantiation of "best-of-K" or "judge-based" compound AI
systems. Through experiments on synthetic tasks such as prime factorization,
and core benchmarks such as the MMLU, we demonstrate notable performance gains.
For instance, in factoring products of two 3-digit primes, a simple NoN
improves accuracy from 3.7\% to 36.6\%. On MMLU, a verifier-based judge
construction with only 3 generators boosts accuracy over individual GPT-4-Turbo
calls by 2.8\%. Our analysis reveals that these gains are most pronounced in
domains where verification is notably easier than generation--a
characterization which we believe subsumes many reasoning and procedural
knowledge tasks, but doesn't often hold for factual and declarative
knowledge-based settings. For mathematical and formal logic reasoning-based
subjects of MMLU, we observe a 5-8\% or higher gain, whilst no gain on others
such as geography and religion. We provide key takeaways for ML practitioners,
including the importance of considering verification complexity, the impact of
witness format on verifiability, and a simple test to determine the potential
benefit of this NoN approach for a given problem distribution. This work aims
to inform future research and practice in the design of compound AI systems.

摘要：<paragraph>隨著從業人員尋求超越當前單一模型的可靠性和品質前沿，由許多語言模型推理呼叫組成的複合式 AI 系統正日益被採用。在這項工作中，我們建構了系統，我們稱之為網路之網（NoN），其組織方式圍繞著提出建議答案和驗證其正確性之間的區別，這是一個複雜性理論中的基本概念，我們以實證方式展示其延伸至語言模型（LM）。我們引入了具有 K 個產生器的驗證者為基礎的評審 NoN，這是「K 中最佳」或「基於評審」複合式 AI 系統的實例化。透過對合成任務（例如質因數分解）和核心基準（例如 MMLU）的實驗，我們展示了顯著的效能提升。例如，在分解兩個 3 位數質數的乘積時，一個簡單的 NoN 將準確度從 3.7% 提升至 36.6%。在 MMLU 上，一個僅有 3 個產生器的基於驗證者的評審建構，將準確度提升了 2.8%，超越了個別的 GPT-4-Turbo 呼叫。我們的分析顯示，這些提升在驗證顯著比產生容易的領域中最为明顯——我們相信此特性涵蓋了許多推理和程序知識任務，但對於基於事實和宣告式知識的設定並不常見。對於 MMLU 中基於數學和形式邏輯推理的主題，我們觀察到 5-8% 或更高的提升，而其他主題（例如地理和宗教）則沒有提升。我們為 ML 從業人員提供了關鍵的重點，包括考量驗證複雜性的重要性、見證格式對可驗證性的影響，以及一個簡單的測試，用於確定此 NoN 方法對給定問題分布的潛在效益。這項工作旨在為複合式 AI 系統設計中的未來研究和實務提供資訊。</paragraph>

##### **Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems**
2407.16828v1 by Timo Wilm, Philipp Normann, Felix Stepprath

This work introduces MultiTRON, an approach that adapts Pareto front
approximation techniques to multi-objective session-based recommender systems
using a transformer neural network. Our approach optimizes trade-offs between
key metrics such as click-through and conversion rates by training on sampled
preference vectors. A significant advantage is that after training, a single
model can access the entire Pareto front, allowing it to be tailored to meet
the specific requirements of different stakeholders by adjusting an additional
input vector that weights the objectives. We validate the model's performance
through extensive offline and online evaluation. For broader application and
research, the source code is made available at
https://github.com/otto-de/MultiTRON . The results confirm the model's ability
to manage multiple recommendation objectives effectively, offering a flexible
tool for diverse business needs.

摘要：此項工作引入了 MultiTRON，這是一種使用Transformer神經網路將 Pareto 前緣近似技術調整到多目標基於會話的推薦系統的方法。我們的做法透過訓練採樣偏好向量，來最佳化點擊率和轉換率等關鍵指標之間的權衡。一個顯著的優點是，在訓練後，單一模型可以存取整個 Pareto 前緣，允許透過調整加權目標的附加輸入向量，來量身打造以滿足不同利害關係人的特定需求。我們透過廣泛的離線和線上評估驗證模型的效能。為了更廣泛的應用和研究，已在 https://github.com/otto-de/MultiTRON 提供原始程式碼。結果證實了模型有效管理多個推薦目標的能力，為不同的業務需求提供了靈活的工具。

##### **AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**
2407.16822v1 by Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee

The 7-point checklist (7PCL) is widely used in dermoscopy to identify
malignant melanoma lesions needing urgent medical attention. It assigns point
values to seven attributes: major attributes are worth two points each, and
minor ones are worth one point each. A total score of three or higher prompts
further evaluation, often including a biopsy. However, a significant limitation
of current methods is the uniform weighting of attributes, which leads to
imprecision and neglects their interconnections. Previous deep learning studies
have treated the prediction of each attribute with the same importance as
predicting melanoma, which fails to recognize the clinical significance of the
attributes for melanoma. To address these limitations, we introduce a novel
diagnostic method that integrates two innovative elements: a Clinical
Knowledge-Based Topological Graph (CKTG) and a Gradient Diagnostic Strategy
with Data-Driven Weighting Standards (GD-DDW). The CKTG integrates 7PCL
attributes with diagnostic information, revealing both internal and external
associations. By employing adaptive receptive domains and weighted edges, we
establish connections among melanoma's relevant features. Concurrently, GD-DDW
emulates dermatologists' diagnostic processes, who first observe the visual
characteristics associated with melanoma and then make predictions. Our model
uses two imaging modalities for the same lesion, ensuring comprehensive feature
acquisition. Our method shows outstanding performance in predicting malignant
melanoma and its features, achieving an average AUC value of 85%. This was
validated on the EDRA dataset, the largest publicly available dataset for the
7-point checklist algorithm. Specifically, the integrated weighting system can
provide clinicians with valuable data-driven benchmarks for their evaluations.

摘要：7 點檢查表 (7PCL) 廣泛用於皮膚鏡檢查，以識別需要緊急醫療照護的惡性黑色素瘤病灶。它為七個屬性分配分數：主要屬性各值兩分，次要屬性各值一分。總分為三或以上表示需要進一步評估，通常包括活檢。然而，目前方法的一個重大限制是屬性的統一加權，導致不精確且忽略它們之間的相互關聯。先前的深度學習研究將每個屬性的預測視為與預測黑色素瘤同等重要，這未能認識到屬性對黑色素瘤的臨床意義。為了解決這些限制，我們引入一種新的診斷方法，結合了兩個創新元素：基於臨床知識的拓撲圖 (CKTG) 和具有數據驅動加權標準的梯度診斷策略 (GD-DDW)。CKTG 將 7PCL 屬性與診斷信息整合在一起，揭示了內部和外部關聯。通過採用自適應感受域和加權邊緣，我們建立了黑色素瘤相關特徵之間的聯繫。同時，GD-DDW 模仿皮膚科醫生的診斷過程，他們首先觀察與黑色素瘤相關的視覺特徵，然後做出預測。我們的模型對同一個病灶使用兩種成像方式，確保全面獲取特徵。我們的這種方法在預測惡性黑色素瘤及其特徵方面表現出色，平均 AUC 值達到 85%。這已在 EDRA 數據集上得到驗證，該數據集是 7 點檢查表算法最大的公開可用數據集。具體來說，集成的加權系統可以為臨床醫生提供有價值的數據驅動基準，供他們評估。

##### **In Search for Architectures and Loss Functions in Multi-Objective Reinforcement Learning**
2407.16807v1 by Mikhail Terekhov, Caglar Gulcehre

Multi-objective reinforcement learning (MORL) is essential for addressing the
intricacies of real-world RL problems, which often require trade-offs between
multiple utility functions. However, MORL is challenging due to unstable
learning dynamics with deep learning-based function approximators. The research
path most taken has been to explore different value-based loss functions for
MORL to overcome this issue. Our work empirically explores model-free policy
learning loss functions and the impact of different architectural choices. We
introduce two different approaches: Multi-objective Proximal Policy
Optimization (MOPPO), which extends PPO to MORL, and Multi-objective Advantage
Actor Critic (MOA2C), which acts as a simple baseline in our ablations. Our
proposed approach is straightforward to implement, requiring only small
modifications at the level of function approximator. We conduct comprehensive
evaluations on the MORL Deep Sea Treasure, Minecart, and Reacher environments
and show that MOPPO effectively captures the Pareto front. Our extensive
ablation studies and empirical analyses reveal the impact of different
architectural choices, underscoring the robustness and versatility of MOPPO
compared to popular MORL approaches like Pareto Conditioned Networks (PCN) and
Envelope Q-learning in terms of MORL metrics, including hypervolume and
expected utility.

摘要：多目標強化學習 (MORL) 對於解決真實世界 RL 問題的複雜性至關重要，而這些問題通常需要在多個效用函數之間進行權衡。然而，由於基於深度學習的函數逼近器的不穩定學習動態，MORL 具有挑戰性。研究最常採取的路徑是探索不同的基於價值的損失函數，以克服 MORL 的這個問題。我們的研究經驗性地探討了無模型策略學習損失函數和不同架構選擇的影響。我們引入了兩種不同的方法：多目標近端策略優化 (MOPPO)，它將 PPO 擴展到 MORL，以及多目標優勢 Actor Critic (MOA2C)，它在我們的消融中作為一個簡單的基準。我們提出的方法易於實作，只需要在函數逼近器的層級進行微小的修改。我們對 MORL 深海寶藏、礦車和 Reacher 環境進行了全面的評估，並表明 MOPPO 有效地捕捉了 Pareto 前緣。我們廣泛的消融研究和經驗分析揭示了不同架構選擇的影響，強調了 MOPPO 與流行的 MORL 方法（如 Pareto 條件網路 (PCN) 和信封 Q 學習）相比在 MORL 指標（包括超體積和預期效用）方面的穩健性和多功能性。

##### **Fusion and Cross-Modal Transfer for Zero-Shot Human Action Recognition**
2407.16803v1 by Abhi Kamboj, Anh Duy Nguyen, Minh Do

Despite living in a multi-sensory world, most AI models are limited to
textual and visual interpretations of human motion and behavior. Inertial
measurement units (IMUs) provide a salient signal to understand human motion;
however, they are challenging to use due to their uninterpretability and
scarcity of their data. We investigate a method to transfer knowledge between
visual and inertial modalities using the structure of an informative joint
representation space designed for human action recognition (HAR). We apply the
resulting Fusion and Cross-modal Transfer (FACT) method to a novel setup, where
the model does not have access to labeled IMU data during training and is able
to perform HAR with only IMU data during testing. Extensive experiments on a
wide range of RGB-IMU datasets demonstrate that FACT significantly outperforms
existing methods in zero-shot cross-modal transfer.

摘要：儘管生活在多感官的世界中，大多數 AI 模型僅限於人類動作與行為的文字和視覺詮釋。慣性測量單元 (IMU) 提供一個顯著的訊號來了解人類動作；然而，由於其難以詮釋和資料稀少，因此它們的使用具有挑戰性。我們探討一種在視覺和慣性模式之間傳遞知識的方法，使用為人類動作辨識 (HAR) 設計的資訊性聯合表示空間的結構。我們將產生的融合與跨模式傳輸 (FACT) 方法應用於一個新的設定，其中模型在訓練期間無法存取標記的 IMU 資料，並且能夠在測試期間僅使用 IMU 資料執行 HAR。在廣泛的 RGB-IMU 資料集上進行的廣泛實驗表明，FACT 在零次學習跨模式傳輸中顯著優於現有方法。

##### **Distribution-Aware Robust Learning from Long-Tailed Data with Noisy Labels**
2407.16802v1 by Jae Soon Baik, In Young Yoon, Kun Hoon Kim, Jun Won Choi

Deep neural networks have demonstrated remarkable advancements in various
fields using large, well-annotated datasets. However, real-world data often
exhibit long-tailed distributions and label noise, significantly degrading
generalization performance. Recent studies addressing these issues have focused
on noisy sample selection methods that estimate the centroid of each class
based on high-confidence samples within each target class. The performance of
these methods is limited because they use only the training samples within each
class for class centroid estimation, making the quality of centroids
susceptible to long-tailed distributions and noisy labels. In this study, we
present a robust training framework called Distribution-aware Sample Selection
and Contrastive Learning (DaSC). Specifically, DaSC introduces a
Distribution-aware Class Centroid Estimation (DaCC) to generate enhanced class
centroids. DaCC performs weighted averaging of the features from all samples,
with weights determined based on model predictions. Additionally, we propose a
confidence-aware contrastive learning strategy to obtain balanced and robust
representations. The training samples are categorized into high-confidence and
low-confidence samples. Our method then applies Semi-supervised Balanced
Contrastive Loss (SBCL) using high-confidence samples, leveraging reliable
label information to mitigate class bias. For the low-confidence samples, our
method computes Mixup-enhanced Instance Discrimination Loss (MIDL) to improve
their representations in a self-supervised manner. Our experimental results on
CIFAR and real-world noisy-label datasets demonstrate the superior performance
of the proposed DaSC compared to previous approaches.

摘要：深度神经网络已使用大型、標註良好的資料集，在各種領域展示出顯著的進展。然而，真實世界資料通常表現出長尾分佈和標籤雜訊，顯著降低泛化效能。解決這些問題的近期研究專注於雜訊樣本選擇方法，該方法根據每個目標類別中高可信度樣本估計每個類別的質心。這些方法的效能受到限制，因為它們僅使用每個類別內的訓練樣本來估計類別質心，使得質心的品質容易受到長尾分佈和雜訊標籤的影響。在本研究中，我們提出一個名為分佈感知樣本選擇和對比學習 (DaSC) 的穩健訓練架構。具體來說，DaSC 導入一個分佈感知類別質心估計 (DaCC) 來產生增強的類別質心。DaCC 執行所有樣本特徵的加權平均，權重根據模型預測確定。此外，我們提出一個對比度感知策略來獲得平衡且穩健的表示。訓練樣本被分類為高可信度和低可信度樣本。然後，我們的模型使用高可信度樣本應用半監督平衡對比損失 (SBCL)，利用可靠的標籤資訊來減輕類別偏差。對於低可信度樣本，我們的模型計算混合增強實例辨別損失 (MIDL) 以自監督的方式改善它們的表示。我們在 CIFAR 和真實世界雜訊標籤資料集上的實驗結果證明了所提出的 DaSC 與先前方法相比具有優異的效能。

##### **What Matters in Range View 3D Object Detection**
2407.16789v1 by Benjamin Wilson, Nicholas Autio Mitchell, Jhony Kaesemodel Pontes, James Hays

Lidar-based perception pipelines rely on 3D object detection models to
interpret complex scenes. While multiple representations for lidar exist, the
range-view is enticing since it losslessly encodes the entire lidar sensor
output. In this work, we achieve state-of-the-art amongst range-view 3D object
detection models without using multiple techniques proposed in past range-view
literature. We explore range-view 3D object detection across two modern
datasets with substantially different properties: Argoverse 2 and Waymo Open.
Our investigation reveals key insights: (1) input feature dimensionality
significantly influences the overall performance, (2) surprisingly, employing a
classification loss grounded in 3D spatial proximity works as well or better
compared to more elaborate IoU-based losses, and (3) addressing non-uniform
lidar density via a straightforward range subsampling technique outperforms
existing multi-resolution, range-conditioned networks. Our experiments reveal
that techniques proposed in recent range-view literature are not needed to
achieve state-of-the-art performance. Combining the above findings, we
establish a new state-of-the-art model for range-view 3D object detection --
improving AP by 2.2% on the Waymo Open dataset while maintaining a runtime of
10 Hz. We establish the first range-view model on the Argoverse 2 dataset and
outperform strong voxel-based baselines. All models are multi-class and
open-source. Code is available at
https://github.com/benjaminrwilson/range-view-3d-detection.

摘要：<paragraph>基於雷射雷達的感知管道依賴 3D 物件偵測模型來詮釋複雜場景。雖然雷射雷達有多種表示法，但距離視圖很誘人，因為它無損地編碼了整個雷射雷達感測器輸出。在這項工作中，我們在距離視圖 3D 物件偵測模型中達到了最先進的技術，而沒有使用過去距離視圖文獻中提出的多種技術。我們探索了兩個性質截然不同的現代數據集中的距離視圖 3D 物件偵測：Argoverse 2 和 Waymo Open。我們的調查揭示了關鍵見解：(1) 輸入特徵維度顯著影響整體效能，(2) 令人驚訝的是，採用基於 3D 空間鄰近性的分類損失與更精細的基於 IoU 的損失相比效果一樣好，甚至更好，以及 (3) 透過直接的範圍子抽樣技術解決非均勻雷射雷達密度，其效能優於現有的多解析度、範圍條件化網路。我們的實驗揭示，最近距離視圖文獻中提出的技術並不需要達到最先進的效能。結合上述發現，我們為距離視圖 3D 物件偵測建立了一個新的最先進模型，同時在 Waymo Open 數據集上將 AP 提升了 2.2%，同時維持 10 Hz 的執行時間。我們在 Argoverse 2 數據集上建立了第一個距離視圖模型，並且優於強大的基於體素的基準。所有模型都是多類別的，且為開源。程式碼可在 https://github.com/benjaminrwilson/range-view-3d-detection 取得。</paragraph>

##### **VisMin: Visual Minimal-Change Understanding**
2407.16772v1 by Rabiul Awal, Saba Ahmadi, Le Zhang, Aishwarya Agrawal

Fine-grained understanding of objects, attributes, and relationships between
objects is crucial for visual-language models (VLMs). Existing benchmarks
primarily focus on evaluating VLMs' capability to distinguish between two very
similar \textit{captions} given an image. In this paper, we introduce a new,
challenging benchmark termed \textbf{Vis}ual \textbf{Min}imal-Change
Understanding (VisMin), which requires models to predict the correct
image-caption match given two images and two captions. The image pair and
caption pair contain minimal changes, i.e., only one aspect changes at a time
from among the following: \textit{object}, \textit{attribute}, \textit{count},
and \textit{spatial relation}. These changes test the models' understanding of
objects, attributes (such as color, material, shape), counts, and spatial
relationships between objects. We built an automatic framework using large
language models and diffusion models, followed by a rigorous 4-step
verification process by human annotators. Empirical experiments reveal that
current VLMs exhibit notable deficiencies in understanding spatial
relationships and counting abilities. We also generate a large-scale training
dataset to finetune CLIP and Idefics2, showing significant improvements in
fine-grained understanding across benchmarks and in CLIP's general image-text
alignment. We release all resources, including the benchmark, training data,
and finetuned model checkpoints, at \url{https://vismin.net/}.

摘要：對於視覺語言模型 (VLM) 來說，精細地理解物件、屬性以及物件之間的關係至關重要。現有的基準測試主要著重於評估 VLM 在給定影像的情況下區分兩個非常相似的「標題」的能力。在本文中，我們引入了一個新的、具有挑戰性的基準測試，稱為**視**覺**最**小變動理解 (VisMin)，它要求模型在給定兩張影像和兩個標題的情況下預測正確的影像標題配對。影像對和標題對包含最小的變動，亦即一次只變動下列其中一個面向：**物件**、**屬性**、**數量**和**空間關係**。這些變動測試模型對物件、屬性（例如顏色、材質、形狀）、數量以及物件之間空間關係的理解。我們使用大型語言模型和擴散模型建構了一個自動化架構，接著由人類註解者進行嚴謹的 4 步驟驗證程序。實證實驗顯示，目前的 VLM 在理解空間關係和計算能力方面表現出顯著的不足。我們也產生一個大型訓練資料集來微調 CLIP 和 Idefics2，顯示在基準測試和 CLIP 的一般影像文字對齊方面，精細理解有顯著的進步。我們在 \url{https://vismin.net/} 釋出所有資源，包括基準測試、訓練資料和微調後的模型檢查點。

##### **Infinite Ends from Finite Samples: Open-Ended Goal Inference as Top-Down Bayesian Filtering of Bottom-Up Proposals**
2407.16770v1 by Tan Zhi-Xuan, Gloria Kang, Vikash Mansinghka, Joshua B. Tenenbaum

The space of human goals is tremendously vast; and yet, from just a few
moments of watching a scene or reading a story, we seem to spontaneously infer
a range of plausible motivations for the people and characters involved. What
explains this remarkable capacity for intuiting other agents' goals, despite
the infinitude of ends they might pursue? And how does this cohere with our
understanding of other people as approximately rational agents? In this paper,
we introduce a sequential Monte Carlo model of open-ended goal inference, which
combines top-down Bayesian inverse planning with bottom-up sampling based on
the statistics of co-occurring subgoals. By proposing goal hypotheses related
to the subgoals achieved by an agent, our model rapidly generates plausible
goals without exhaustive search, then filters out goals that would be
irrational given the actions taken so far. We validate this model in a goal
inference task called Block Words, where participants try to guess the word
that someone is stacking out of lettered blocks. In comparison to both
heuristic bottom-up guessing and exact Bayesian inference over hundreds of
goals, our model better predicts the mean, variance, efficiency, and resource
rationality of human goal inferences, achieving similar accuracy to the exact
model at a fraction of the cognitive cost, while also explaining garden-path
effects that arise from misleading bottom-up cues. Our experiments thus
highlight the importance of uniting top-down and bottom-up models for
explaining the speed, accuracy, and generality of human theory-of-mind.

摘要：人類目標的空間極為廣闊；然而，僅僅從觀看場景或閱讀故事的幾分鐘中，我們似乎就能自發地推斷出所涉及人物和角色的一系列合理動機。儘管他們可能追求的目標無窮無盡，但什麼解釋了這種直覺理解其他代理人目標的非凡能力？這如何與我們將他人理解為近似理性的代理人的理解相一致？在本文中，我們引入了一個開放式目標推論的序貫蒙地卡羅模型，它結合了自上而下的貝葉斯逆向規劃和基於共現子目標的統計數據的自下而上的採樣。通過提出與代理人實現的子目標相關的目標假設，我們的模型在不進行窮舉搜索的情況下快速生成合理的目標，然後過濾掉根據迄今採取的行動會不合理的目標。我們在一個稱為 Block Words 的目標推論任務中驗證了這個模型，在這個任務中，參與者試圖猜測某人用帶字母的積木堆疊出來的單詞。與自下而上的啟發式猜測和對數百個目標的精確貝葉斯推論相比，我們的模型更好地預測了人類目標推論的平均值、方差、效率和資源合理性，以認知成本的一小部分實現了與精確模型相似的準確度，同時還解釋了由誤導性的自下而上線索產生的花園路徑效應。因此，我們的實驗強調了將自上而下和自下而上的模型結合起來對於解釋人類心智理論的速度、準確性和普遍性的重要性。

##### **Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack**
2407.16695v1 by Xiaoyue Xu, Qinyuan Ye, Xiang Ren

We introduce Lifelong ICL, a problem setting that challenges long-context
language models (LMs) to learn from a sequence of language tasks through
in-context learning (ICL). We further introduce Task Haystack, an evaluation
suite dedicated to assessing and diagnosing how long-context LMs utilizes
contexts in Lifelong ICL. When given a task instruction and test inputs,
long-context LMs are expected to leverage the relevant demonstrations in the
Lifelong ICL prompt, avoid distraction and interference from other tasks, and
achieve test accuracies that are not significantly worse than the Single-task
ICL baseline.
  Task Haystack draws inspiration from the widely-adopted
"needle-in-a-haystack" (NIAH) evaluation, but presents new and unique
challenges. It demands that models (1) utilize the contexts with deeper
understanding, rather than resorting to simple copying and pasting; (2)
navigate through long streams of evolving topics and tasks, which closely
approximates the complexities of real-world usage of long-context LMs.
Additionally, Task Haystack inherits the controllability aspect of NIAH,
providing model developers with tools and visualizations to identify model
vulnerabilities effectively.
  We benchmark 12 long-context LMs using Task Haystack. We find that
state-of-the-art closed models such as GPT-4o still struggle in this setting,
failing 15% of the cases on average, while all open-weight models we evaluate
further lack behind by a large margin, failing up to 61% of the cases. In our
controlled analysis, we identify factors such as distraction and recency bias
as contributors to these failure cases. Further, we observe declines in
performance when task instructions are paraphrased at test time or when ICL
demonstrations are repeated excessively, raising concerns about the robustness,
instruction understanding, and true context utilization of current long-context
LMs.

摘要：<paragraph>我們引入了終身 ICL，這是一個挑戰問題設置，讓長期語境語言模型 (LM) 能夠透過語境學習 (ICL) 從一系列語言任務中學習。我們進一步引入了任務乾草堆，這是一個評估套件，專門用於評估和診斷長期語境 LM 如何在終身 ICL 中使用語境。當給定任務說明和測試輸入時，預期長期語境 LM 將利用終身 ICL 提示中的相關示範，避免其他任務的干擾和干擾，並達到與單任務 ICL 基準線相差不大的測試準確度。
任務乾草堆從廣泛採用的「大海撈針」(NIAH) 評估中汲取靈感，但提出了新的獨特挑戰。它要求模型 (1) 以更深入的理解利用語境，而不是訴諸於簡單的複製和貼上；(2) 瀏覽不斷變化的主題和任務的長串流，這與長期語境 LM 在現實世界中的使用複雜性非常接近。此外，任務乾草堆繼承了 NIAH 的可控性方面，為模型開發人員提供了工具和可視化效果，以有效識別模型漏洞。
我們使用任務乾草堆對 12 個長期語境 LM 進行基準測試。我們發現，GPT-4o 等最先進的封閉模型在此設置中仍然舉步維艱，平均有 15% 的案例失敗，而我們評估的所有開放權重模型進一步落後一大截，有高達 61% 的案例失敗。在我們的受控分析中，我們將分心和近期偏誤等因素確定為這些失敗案例的成因。此外，我們觀察到，當任務說明在測試時被改寫，或當 ICL 示範被過度重複時，性能會下降，這引起了人們對當前長期語境 LM 的健壯性、指令理解和真實語境利用的擔憂。</paragraph>

##### **Explanation Regularisation through the Lens of Attributions**
2407.16693v1 by Pedro Ferreira, Wilker Aziz, Ivan Titov

Explanation regularisation (ER) has been introduced as a way to guide models
to make their predictions in a manner more akin to humans, i.e., making their
attributions "plausible". This is achieved by introducing an auxiliary
explanation loss, that measures how well the output of an input attribution
technique for the model agrees with relevant human-annotated rationales. One
positive outcome of using ER appears to be improved performance in
out-of-domain (OOD) settings, presumably due to an increased reliance on
"plausible" tokens. However, previous work has under-explored the impact of the
ER objective on model attributions, in particular when obtained with techniques
other than the one used to train ER. In this work, we contribute a study of
ER's effectiveness at informing classification decisions on plausible tokens,
and the relationship between increased plausibility and robustness to OOD
conditions. Through a series of analyses, we find that the connection between
ER and the ability of a classifier to rely on plausible features has been
overstated and that a stronger reliance on plausible tokens does not seem to be
the cause for any perceived OOD improvements.

摘要：說明規範化（ER）被引入作為引導模型以更類似人類的方式做出預測的方法，即讓模型的歸因「合理」。這透過引入輔助說明損失來達成，該損失衡量模型的輸入歸因技術的輸出與相關的人工標記依據吻合程度。使用 ER 的一個正面結果似乎是在領域外（OOD）設定中改善效能，這可能是由於更依賴於「合理」的標記。然而，先前的工作並未充分探討 ER 目標對模型歸因的影響，特別是在使用與訓練 ER 不同的技術取得歸因時。在這項工作中，我們貢獻了一項研究，探討 ER 在根據合理標記做出分類決策方面的有效性，以及增加合理性與對 OOD 條件的穩健性之間的關係。透過一系列的分析，我們發現 ER 與分類器依賴合理特徵的能力之間的關聯被誇大了，而且更依賴合理的標記似乎並非任何感知到的 OOD 改進的原因。

##### **Can Large Language Models Automatically Jailbreak GPT-4V?**
2407.16686v1 by Yuanwei Wu, Yue Huang, Yixin Liu, Xiang Li, Pan Zhou, Lichao Sun

GPT-4V has attracted considerable attention due to its extraordinary capacity
for integrating and processing multimodal information. At the same time, its
ability of face recognition raises new safety concerns of privacy leakage.
Despite researchers' efforts in safety alignment through RLHF or preprocessing
filters, vulnerabilities might still be exploited. In our study, we introduce
AutoJailbreak, an innovative automatic jailbreak technique inspired by prompt
optimization. We leverage Large Language Models (LLMs) for red-teaming to
refine the jailbreak prompt and employ weak-to-strong in-context learning
prompts to boost efficiency. Furthermore, we present an effective search method
that incorporates early stopping to minimize optimization time and token
expenditure. Our experiments demonstrate that AutoJailbreak significantly
surpasses conventional methods, achieving an Attack Success Rate (ASR)
exceeding 95.3\%. This research sheds light on strengthening GPT-4V security,
underscoring the potential for LLMs to be exploited in compromising GPT-4V
integrity.

摘要：GPT-4V 因其整合和處理多模態資訊的非凡能力而備受關注。同時，其人臉識別能力也引發了新的隱私洩露安全問題。儘管研究人員透過 RLHF 或預處理過濾器在安全調整方面做出了努力，但漏洞仍可能被利用。在我們的研究中，我們引入了 AutoJailbreak，這是一種創新的自動越獄技術，靈感來自提示最佳化。我們利用大型語言模型 (LLM) 進行紅隊演練，以優化越獄提示，並使用弱到強的上下文學習提示來提高效率。此外，我們提出了一種有效的方法，結合了早期停止以最小化最佳化時間和符號支出。我們的實驗表明，AutoJailbreak 明顯優於傳統方法，攻擊成功率 (ASR) 超過 95.3%。這項研究有助於加強 GPT-4V 安全性，強調了 LLM 在破壞 GPT-4V 完整性方面被利用的潛力。

##### **OpenDevin: An Open Platform for AI Software Developers as Generalist Agents**
2407.16741v1 by Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, Graham Neubig

Software is one of the most powerful tools that we humans have at our
disposal; it allows a skilled programmer to interact with the world in complex
and profound ways. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. In this
paper, we introduce OpenDevin, a platform for the development of powerful and
flexible AI agents that interact with the world in similar ways to those of a
human developer: by writing code, interacting with a command line, and browsing
the web. We describe how the platform allows for the implementation of new
agents, safe interaction with sandboxed environments for code execution,
coordination between multiple agents, and incorporation of evaluation
benchmarks. Based on our currently incorporated benchmarks, we perform an
evaluation of agents over 15 challenging tasks, including software engineering
(e.g., SWE-Bench) and web browsing (e.g., WebArena), among others. Released
under the permissive MIT license, OpenDevin is a community project spanning
academia and industry with more than 1.3K contributions from over 160
contributors and will improve going forward.

摘要：軟體是我們人類最具威力的工具之一；它允許熟練的程式設計師以複雜且深遠的方式與世界互動。同時，由於大型語言模型 (LLM) 的改進，也出現了與周圍環境互動並影響其變化的 AI 代理的快速發展。在本文中，我們介紹了 OpenDevin，一個用於開發強大且靈活的 AI 代理的平台，這些代理與世界互動的方式類似於人類開發人員：透過撰寫程式碼、與命令列互動以及瀏覽網路。我們描述了該平台如何允許實作新的代理、與沙盒環境安全互動以執行程式碼、協調多個代理，以及納入評估基準。根據我們目前納入的基準，我們對 15 項具有挑戰性的任務進行了代理評估，包括軟體工程（例如，SWE-Bench）和網路瀏覽（例如，WebArena）等。OpenDevin 在寬容的 MIT 授權下發布，是一個橫跨學術界和產業的社群專案，擁有來自 160 多位貢獻者的 1.3K 多筆貢獻，未來將持續改進。

##### **KAN or MLP: A Fairer Comparison**
2407.16674v1 by Runpeng Yu, Weihao Yu, Xinchao Wang

This paper does not introduce a novel method. Instead, it offers a fairer and
more comprehensive comparison of KAN and MLP models across various tasks,
including machine learning, computer vision, audio processing, natural language
processing, and symbolic formula representation. Specifically, we control the
number of parameters and FLOPs to compare the performance of KAN and MLP. Our
main observation is that, except for symbolic formula representation tasks, MLP
generally outperforms KAN. We also conduct ablation studies on KAN and find
that its advantage in symbolic formula representation mainly stems from its
B-spline activation function. When B-spline is applied to MLP, performance in
symbolic formula representation significantly improves, surpassing or matching
that of KAN. However, in other tasks where MLP already excels over KAN,
B-spline does not substantially enhance MLP's performance. Furthermore, we find
that KAN's forgetting issue is more severe than that of MLP in a standard
class-incremental continual learning setting, which differs from the findings
reported in the KAN paper. We hope these results provide insights for future
research on KAN and other MLP alternatives. Project link:
https://github.com/yu-rp/KANbeFair

摘要：本文并未引入新方法。相反，它对 KAN 和 MLP 模型在各个任务中的表现进行了更公平、更全面的比较，包括机器学习、计算机视觉、音频处理、自然语言处理和符号公式表示。具体来说，我们控制参数和 FLOP 的数量来比较 KAN 和 MLP 的性能。我们的主要观察结果是，除了符号公式表示任务之外，MLP 通常优于 KAN。我们还对 KAN 进行了消融研究，发现其在符号公式表示中的优势主要源于其 B 样条激活函数。当 B 样条应用于 MLP 时，符号公式表示的性能显着提高，超过或匹配 KAN。然而，在 MLP 已经优于 KAN 的其他任务中，B 样条并没有实质性地提高 MLP 的性能。此外，我们发现 KAN 的遗忘问题比 MLP 在标准类增量持续学习设置中更严重，这与 KAN 论文中报告的发现不同。我们希望这些结果为未来对 KAN 和其他 MLP 替代方案的研究提供见解。项目链接：https://github.com/yu-rp/KANbeFair

##### **PLM-Net: Perception Latency Mitigation Network for Vision-Based Lateral Control of Autonomous Vehicles**
2407.16740v1 by Aws Khalil, Jaerock Kwon

This study introduces the Perception Latency Mitigation Network (PLM-Net), a
novel deep learning approach for addressing perception latency in vision-based
Autonomous Vehicle (AV) lateral control systems. Perception latency is the
delay between capturing the environment through vision sensors (e.g., cameras)
and applying an action (e.g., steering). This issue is understudied in both
classical and neural-network-based control methods. Reducing this latency with
powerful GPUs and FPGAs is possible but impractical for automotive platforms.
PLM-Net comprises the Base Model (BM) and the Timed Action Prediction Model
(TAPM). BM represents the original Lane Keeping Assist (LKA) system, while TAPM
predicts future actions for different latency values. By integrating these
models, PLM-Net mitigates perception latency. The final output is determined
through linear interpolation of BM and TAPM outputs based on real-time latency.
This design addresses both constant and varying latency, improving driving
trajectories and steering control. Experimental results validate the efficacy
of PLM-Net across various latency conditions. Source code:
https://github.com/AwsKhalil/oscar/tree/devel-plm-net.

摘要：本研究提出感知延迟缓解网络 (PLM-Net)，这是一种用于解决基于视觉的自动驾驶 (AV) 横向控制系统中的感知延迟的新型深度学习方法。感知延迟是指通过视觉传感器（例如摄像头）捕捉环境和执行动作（例如转向）之间的延迟。这个问题在经典控制方法和基于神经网络的控制方法中都未得到充分研究。使用强大的 GPU 和 FPGA 来减少这种延迟是可行的，但对于汽车平台来说不切实际。PLM-Net 包含基础模型 (BM) 和定时动作预测模型 (TAPM)。BM 代表原始车道保持辅助 (LKA) 系统，而 TAPM 预测不同延迟值下的未来动作。通过整合这些模型，PLM-Net 减轻了感知延迟。最终输出是根据实时延迟对 BM 和 TAPM 输出进行线性插值确定的。这种设计解决了恒定和可变延迟的问题，改善了驾驶轨迹和转向控制。实验结果验证了 PLM-Net 在各种延迟条件下的有效性。源代码：https://github.com/AwsKhalil/oscar/tree/devel-plm-net。

##### **RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent**
2407.16667v1 by Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren

Recently, advanced Large Language Models (LLMs) such as GPT-4 have been
integrated into many real-world applications like Code Copilot. These
applications have significantly expanded the attack surface of LLMs, exposing
them to a variety of threats. Among them, jailbreak attacks that induce toxic
responses through jailbreak prompts have raised critical safety concerns. To
identify these threats, a growing number of red teaming approaches simulate
potential adversarial scenarios by crafting jailbreak prompts to test the
target LLM. However, existing red teaming methods do not consider the unique
vulnerabilities of LLM in different scenarios, making it difficult to adjust
the jailbreak prompts to find context-specific vulnerabilities. Meanwhile,
these methods are limited to refining jailbreak templates using a few mutation
operations, lacking the automation and scalability to adapt to different
scenarios. To enable context-aware and efficient red teaming, we abstract and
model existing attacks into a coherent concept called "jailbreak strategy" and
propose a multi-agent LLM system named RedAgent that leverages these strategies
to generate context-aware jailbreak prompts. By self-reflecting on contextual
feedback in an additional memory buffer, RedAgent continuously learns how to
leverage these strategies to achieve effective jailbreaks in specific contexts.
Extensive experiments demonstrate that our system can jailbreak most black-box
LLMs in just five queries, improving the efficiency of existing red teaming
methods by two times. Additionally, RedAgent can jailbreak customized LLM
applications more efficiently. By generating context-aware jailbreak prompts
towards applications on GPTs, we discover 60 severe vulnerabilities of these
real-world applications with only two queries per vulnerability. We have
reported all found issues and communicated with OpenAI and Meta for bug fixes.

摘要：<paragraph>最近，先进的大语言模型（LLM），例如 GPT-4，已整合到许多实际应用中，例如 Code Copilot。这些应用显著扩大了 LLM 的攻击面，使它们面临各种威胁。其中，通过越狱提示诱发有害反应的越狱攻击引发了关键的安全问题。为了识别这些威胁，越来越多的红队方法通过精心制作越狱提示来模拟潜在的对抗场景，以测试目标 LLM。然而，现有的红队方法并未考虑 LLM 在不同场景中的独特漏洞，这使得难以调整越狱提示来查找特定于上下文的漏洞。同时，这些方法仅限于使用少数变异操作来优化越狱模板，缺乏适应不同场景的自动化和可扩展性。为了实现上下文感知和高效的红队，我们将现有的攻击抽象并建模为一个连贯的概念，称为“越狱策略”，并提出一个名为 RedAgent 的多代理 LLM 系统，该系统利用这些策略来生成上下文感知的越狱提示。通过在附加的内存缓冲区中自省上下文反馈，RedAgent 持续学习如何利用这些策略在特定上下文中实现有效的越狱。广泛的实验表明，我们的系统仅在五次查询中就能越狱大多数黑盒 LLM，从而将现有红队方法的效率提高了两倍。此外，RedAgent 可以更有效地越狱定制的 LLM 应用程序。通过针对 GPT 上的应用程序生成上下文感知的越狱提示，我们仅通过每个漏洞两次查询就发现了这些实际应用程序的 60 个严重漏洞。我们已报告所有发现的问题，并与 OpenAI 和 Meta 沟通以修复错误。</paragraph>

##### **Towards scalable efficient on-device ASR with transfer learning**
2407.16664v1 by Laxmi Pandey, Ke Li, Jinxi Guo, Debjyoti Paul, Arthur Guo, Jay Mahadeokar, Xuedong Zhang

Multilingual pretraining for transfer learning significantly boosts the
robustness of low-resource monolingual ASR models. This study systematically
investigates three main aspects: (a) the impact of transfer learning on model
performance during initial training or fine-tuning, (b) the influence of
transfer learning across dataset domains and languages, and (c) the effect on
rare-word recognition compared to non-rare words. Our finding suggests that
RNNT-loss pretraining, followed by monolingual fine-tuning with Minimum Word
Error Rate (MinWER) loss, consistently reduces Word Error Rates (WER) across
languages like Italian and French. WER Reductions (WERR) reach 36.2% and 42.8%
compared to monolingual baselines for MLS and in-house datasets. Out-of-domain
pretraining leads to 28% higher WERR than in-domain pretraining. Both rare and
non-rare words benefit, with rare words showing greater improvements with
out-of-domain pretraining, and non-rare words with in-domain pretraining.

摘要：多語言預訓練用於遷移學習，可顯著提升低資源單語 ASR 模型的穩健性。本研究系統性地探討了三個主要面向：(a) 遷移學習對模型效能的影響，無論是在初始訓練或微調期間，(b) 遷移學習對資料集網域和語言的影響，以及 (c) 對罕見字辨識與非罕見字辨識的影響。我們的發現顯示，RNNT 損失預訓練，接著進行使用最小字元錯誤率 (MinWER) 損失的單語微調，會持續降低義大利語和法語等語言的字元錯誤率 (WER)。與 MLS 和內部資料集的單語基線相比，WER 降低幅度 (WERR) 達到 36.2% 和 42.8%。領域外預訓練導致 WERR 比領域內預訓練高出 28%。罕見字和非罕見字均受惠，罕見字在領域外預訓練中表現出較大的進步，而非罕見字則在領域內預訓練中表現出較大的進步。

##### **A Survey of Text Style Transfer: Applications and Ethical Implications**
2407.16737v1 by Sourabrata Mukherjee, Mateusz Lango, Zdenek Kasner, Ondrej Dušek

Text style transfer (TST) is an important task in controllable text
generation, which aims to control selected attributes of language use, such as
politeness, formality, or sentiment, without altering the style-independent
content of the text. The field has received considerable research attention in
recent years and has already been covered in several reviews, but the focus has
mostly been on the development of new algorithms and learning from different
types of data (supervised, unsupervised, out-of-domain, etc.) and not so much
on the application side. However, TST-related technologies are gradually
reaching a production- and deployment-ready level, and therefore, the inclusion
of the application perspective in TST research becomes crucial. Similarly, the
often overlooked ethical considerations of TST technology have become a
pressing issue. This paper presents a comprehensive review of TST applications
that have been researched over the years, using both traditional linguistic
approaches and more recent deep learning methods. We discuss current
challenges, future research directions, and ethical implications of TST
applications in text generation. By providing a holistic overview of the
landscape of TST applications, we hope to stimulate further research and
contribute to a better understanding of the potential as well as ethical
considerations associated with TST.

摘要：文字樣式轉移 (TST) 是可控文本生成中的一項重要任務，旨在控制語言使用的選定屬性，例如禮貌、正式或情緒，而不會改變文本的與樣式無關的內容。該領域近年來受到相當多的研究關注，並且已經在多篇評論中有所探討，但重點主要放在開發新演算法和從不同類型的資料 (監督式、非監督式、領域外等) 中學習，而較少放在應用方面。然而，TST 相關技術正逐漸達到可生產和部署的層級，因此，在 TST 研究中納入應用觀點至關重要。類似地，經常被忽略的 TST 技術倫理考量已成為一個迫切的問題。本文對多年來研究過的 TST 應用程式進行全面回顧，同時使用傳統語言學方法和較新的深度學習方法。我們討論了 TST 應用程式在文本生成中的當前挑戰、未來的研究方向和倫理影響。透過提供 TST 應用程式概況的整體觀點，我們希望激勵進一步的研究，並有助於更深入了解與 TST 相關的潛力和倫理考量。

##### **Course-Correction: Safety Alignment Using Synthetic Preferences**
2407.16637v1 by Rongwu Xu, Yishuo Cai, Zhenhong Zhou, Renjie Gu, Haiqin Weng, Yan Liu, Tianwei Zhang, Wei Xu, Han Qiu

The risk of harmful content generated by large language models (LLMs) becomes
a critical concern. This paper presents a systematic study on assessing and
improving LLMs' capability to perform the task of \textbf{course-correction},
\ie, the model can steer away from generating harmful content autonomously. To
start with, we introduce the \textsc{C$^2$-Eval} benchmark for quantitative
assessment and analyze 10 popular LLMs, revealing varying proficiency of
current safety-tuned LLMs in course-correction. To improve, we propose
fine-tuning LLMs with preference learning, emphasizing the preference for
timely course-correction. Using an automated pipeline, we create
\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to
teach models the concept of timely course-correction through data-driven
preference learning. Experiments on 2 LLMs, \textsc{Llama2-Chat 7B} and
\textsc{Qwen2 7B}, show that our method effectively enhances course-correction
skills without affecting general performance. Additionally, it effectively
improves LLMs' safety, particularly in resisting jailbreak attacks.

摘要：大型语言模型 (LLM) 产生的有害内容风险已成为一个关键问题。本文对评估和改进 LLM 执行“路径校正”任务的能力进行了系统性研究，即模型可以自主地避免生成有害内容。首先，我们引入了用于定量评估的 \textsc{C$^2$-Eval} 基准，并分析了 10 个流行的 LLM，揭示了当前安全调整的 LLM 在路径校正方面的熟练程度各不相同。为了改进，我们建议使用偏好学习对 LLM 进行微调，强调及时路径校正的偏好。我们使用自动化管道创建了 \textsc{C$^2$-Syn}，这是一个包含 750K 对偏好的合成数据集，以通过数据驱动的偏好学习向模型传授及时路径校正的概念。对 2 个 LLM（\textsc{Llama2-Chat 7B} 和 \textsc{Qwen2 7B}）的实验表明，我们的方法有效地增强了路径校正技能，而不会影响一般性能。此外，它有效地提高了 LLM 的安全性，尤其是在抵御越狱攻击方面。

##### **Knowledge-driven AI-generated data for accurate and interpretable breast ultrasound diagnoses**
2407.16634v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, Qingli Zhu, Yong Wang, Liwei Wang

Data-driven deep learning models have shown great capabilities to assist
radiologists in breast ultrasound (US) diagnoses. However, their effectiveness
is limited by the long-tail distribution of training data, which leads to
inaccuracies in rare cases. In this study, we address a long-standing challenge
of improving the diagnostic model performance on rare cases using long-tailed
data. Specifically, we introduce a pipeline, TAILOR, that builds a
knowledge-driven generative model to produce tailored synthetic data. The
generative model, using 3,749 lesions as source data, can generate millions of
breast-US images, especially for error-prone rare cases. The generated data can
be further used to build a diagnostic model for accurate and interpretable
diagnoses. In the prospective external evaluation, our diagnostic model
outperforms the average performance of nine radiologists by 33.5% in
specificity with the same sensitivity, improving their performance by providing
predictions with an interpretable decision-making process. Moreover, on ductal
carcinoma in situ (DCIS), our diagnostic model outperforms all radiologists by
a large margin, with only 34 DCIS lesions in the source data. We believe that
TAILOR can potentially be extended to various diseases and imaging modalities.

摘要：資料驅動的深度學習模型已展現出極佳的能力，協助放射科醫師進行乳房超音波 (US) 診斷。然而，其有效性受到訓練資料長尾分佈的限制，導致在罕見案例中出現不準確的情況。在本研究中，我們解決了使用長尾資料改善罕見案例診斷模型效能的長期挑戰。具體來說，我們引入了一條名為 TAILOR 的管線，它建立了一個知識驅動的生成模型來產生客製化的合成資料。生成模型使用 3,749 個病灶作為原始資料，可以產生數百萬個乳房超音波影像，特別是針對容易出錯的罕見案例。產生的資料可進一步用於建立診斷模型，以進行準確且可解釋的診斷。在預測外部評估中，我們的診斷模型在特異性方面以相同的敏感性優於九位放射科醫師的平均表現 33.5%，透過提供具有可解釋決策過程的預測來提升他們的表現。此外，在原位導管癌 (DCIS) 中，我們的診斷模型以極大的幅度優於所有放射科醫師，而原始資料中只有 34 個 DCIS 病灶。我們相信 TAILOR 潛在可擴充至各種疾病和影像模式。

##### **Semantic Change Characterization with LLMs using Rhetorics**
2407.16624v1 by Jader Martins Camboim de Sá, Marcos Da Silveira, Cédric Pruski

Languages continually evolve in response to societal events, resulting in new
terms and shifts in meanings. These changes have significant implications for
computer applications, including automatic translation and chatbots, making it
essential to characterize them accurately. The recent development of LLMs has
notably advanced natural language understanding, particularly in sense
inference and reasoning. In this paper, we investigate the potential of LLMs in
characterizing three types of semantic change: dimension, relation, and
orientation. We achieve this by combining LLMs' Chain-of-Thought with
rhetorical devices and conducting an experimental assessment of our approach
using newly created datasets. Our results highlight the effectiveness of LLMs
in capturing and analyzing semantic changes, providing valuable insights to
improve computational linguistic applications.

摘要：語言會持續隨著社會事件而演變，產生新詞彙和意義轉換。這些變化對電腦應用程式有重大的影響，包括自動翻譯和聊天機器人，因此精確地描述它們至關重要。大型語言模型 (LLM) 的最新發展顯著提升了自然語言理解，特別是在意義推論和推理方面。在本文中，我們探討了 LLM 在描述三種類型的語義變化（維度、關係和方向）方面的潛力。我們透過結合 LLM 的思考鏈、修辭裝置，並使用新建立的資料集對我們的做法進行實驗評估來達成這項任務。我們的結果突顯了 LLM 在捕捉和分析語義變化方面的效能，為改進計算語言應用程式提供了寶貴的見解。

##### **Theoretical Analysis of Privacy Leakage in Trustworthy Federated Learning: A Perspective from Linear Algebra and Optimization Theory**
2407.16735v1 by Xiaojin Zhang, Wei Chen

Federated learning has emerged as a promising paradigm for collaborative
model training while preserving data privacy. However, recent studies have
shown that it is vulnerable to various privacy attacks, such as data
reconstruction attacks. In this paper, we provide a theoretical analysis of
privacy leakage in federated learning from two perspectives: linear algebra and
optimization theory. From the linear algebra perspective, we prove that when
the Jacobian matrix of the batch data is not full rank, there exist different
batches of data that produce the same model update, thereby ensuring a level of
privacy. We derive a sufficient condition on the batch size to prevent data
reconstruction attacks. From the optimization theory perspective, we establish
an upper bound on the privacy leakage in terms of the batch size, the
distortion extent, and several other factors. Our analysis provides insights
into the relationship between privacy leakage and various aspects of federated
learning, offering a theoretical foundation for designing privacy-preserving
federated learning algorithms.

摘要：聯邦學習已成為一種有前途的協作模型訓練範例，同時還能保護資料隱私。不過，最近的研究顯示，它容易受到各種隱私攻擊，例如資料重建攻擊。在本文中，我們從線性代數和最佳化理論兩個角度，對聯邦學習中的隱私外洩進行理論分析。從線性代數的角度來看，我們證明當批次資料的雅可比矩陣不是滿秩時，存在不同批次的資料會產生相同的模型更新，從而確保一定的隱私。我們推導出批次大小的充分條件，以防止資料重建攻擊。從最佳化理論的角度來看，我們在批次大小、失真程度和幾個其他因素方面，建立了隱私外洩的上限。我們的分析深入探討了隱私外洩與聯邦學習各個面向之間的關係，為設計保護隱私的聯邦學習演算法提供了理論基礎。

##### **Lawma: The Power of Specialization for Legal Tasks**
2407.16615v1 by Ricardo Dominguez-Olmedo, Vedant Nanda, Rediet Abebe, Stefan Bechtold, Christoph Engel, Jens Frankenreiter, Krishna Gummadi, Moritz Hardt, Michael Livermore

Annotation and classification of legal text are central components of
empirical legal research. Traditionally, these tasks are often delegated to
trained research assistants. Motivated by the advances in language modeling,
empirical legal scholars are increasingly turning to prompting commercial
models, hoping that it will alleviate the significant cost of human annotation.
Despite growing use, our understanding of how to best utilize large language
models for legal tasks remains limited. We conduct a comprehensive study of 260
legal text classification tasks, nearly all new to the machine learning
community. Starting from GPT-4 as a baseline, we show that it has non-trivial
but highly varied zero-shot accuracy, often exhibiting performance that may be
insufficient for legal work. We then demonstrate that a lightly fine-tuned
Llama 3 model vastly outperforms GPT-4 on almost all tasks, typically by
double-digit percentage points. We find that larger models respond better to
fine-tuning than smaller models. A few tens to hundreds of examples suffice to
achieve high classification accuracy. Notably, we can fine-tune a single model
on all 260 tasks simultaneously at a small loss in accuracy relative to having
a separate model for each task. Our work points to a viable alternative to the
predominant practice of prompting commercial models. For concrete legal tasks
with some available labeled data, researchers are better off using a fine-tuned
open-source model.

摘要：法律文本的註解和分類是實證法律研究的核心組成部分。傳統上，這些任務通常委派給受過訓練的研究助理。在語言模型進步的推動下，實證法律學者正日益求助於提示商業模型，希望這將減輕人工註解的顯著成本。儘管使用日益廣泛，我們對如何最佳利用大型語言模型來執行法律任務的理解仍然有限。我們對 260 項法律文本分類任務進行了一項全面研究，其中幾乎所有任務對機器學習社群來說都是新的。從 GPT-4 作為基準開始，我們表明它具有非平凡但變化極大的零次學習準確度，通常表現出的效能可能不足以應付法律工作。然後我們展示了一個經過微調的 Llama 3 模型在幾乎所有任務上都大大優於 GPT-4，通常高出兩位數個百分點。我們發現，與較小的模型相比，較大的模型對微調的反應更好。幾十到幾百個範例就足以達到很高的分類準確度。值得注意的是，我們可以同時對所有 260 項任務微調單一模型，而準確度損失很小，相較於為每個任務使用單獨的模型。我們的研究指出了一個可行的替代方案，以取代提示商業模型的普遍做法。對於具有一些可用標記資料的具體法律任務，研究人員最好使用經過微調的開源模型。

##### **No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots**
2407.16613v1 by Alican Mertan, Nick Cheney

It is prevalent in contemporary AI and robotics to separately postulate a
brain modeled by neural networks and employ it to learn intelligent and
adaptive behavior. While this method has worked very well for many types of
tasks, it isn't the only type of intelligence that exists in nature. In this
work, we study the ways in which intelligent behavior can be created without a
separate and explicit brain for robot control, but rather solely as a result of
the computation occurring within the physical body of a robot. Specifically, we
show that adaptive and complex behavior can be created in voxel-based virtual
soft robots by using simple reactive materials that actively change the shape
of the robot, and thus its behavior, under different environmental cues. We
demonstrate a proof of concept for the idea of closed-loop morphological
computation, and show that in our implementation, it enables behavior mimicking
logic gates, enabling us to demonstrate how such behaviors may be combined to
build up more complex collective behaviors.

摘要：在當代的人工智慧與機器人領域中，普遍的做法是分別假設一個由神經網路建模的大腦，並使用它來學習智慧且適應性的行為。雖然這種方法在許多類型的任務中運作良好，但它並非自然界中存在的唯一智慧類型。在本研究中，我們探討了在沒有機器人控制的獨立且明確大腦的情況下，智慧行為可以如何被創造出來，而僅僅是機器人實體內部運算的結果。具體來說，我們展示了適應性和複雜的行為可以在基於體素的虛擬軟機器人中被創造出來，方法是使用簡單的反應材料，這些材料會積極改變機器人的形狀，並因此在不同的環境提示下改變其行為。我們展示了一個封閉迴路形態運算概念的驗證，並展示在我們的實作中，它能讓行為模擬邏輯閘，使我們能夠展示如何將這些行為組合起來，以建立更複雜的集體行為。

##### **Local vs Global continual learning**
2407.16611v1 by Giulia Lanzillotta, Sidak Pal Singh, Benjamin F. Grewe, Thomas Hofmann

Continual learning is the problem of integrating new information in a model
while retaining the knowledge acquired in the past. Despite the tangible
improvements achieved in recent years, the problem of continual learning is
still an open one. A better understanding of the mechanisms behind the
successes and failures of existing continual learning algorithms can unlock the
development of new successful strategies. In this work, we view continual
learning from the perspective of the multi-task loss approximation, and we
compare two alternative strategies, namely local and global approximations. We
classify existing continual learning algorithms based on the approximation
used, and we assess the practical effects of this distinction in common
continual learning settings.Additionally, we study optimal continual learning
objectives in the case of local polynomial approximations and we provide
examples of existing algorithms implementing the optimal objectives

摘要：持續學習是整合模型中新資訊的問題，同時保留過去獲得的知識。儘管近年來取得了顯著的進展，但持續學習的問題仍然是一個開放的問題。對現有持續學習演算法成功與失敗背後機制的更深入了解，可以開啟新的成功策略的發展。在這項工作中，我們從多任務損失近似的角度來看持續學習，並比較了兩種替代策略，即局部和全局近似。我們根據所使用的近似對現有的持續學習演算法進行分類，並評估了這種區別在常見持續學習設定中的實際效果。此外，我們研究了局部多項式近似情況下的最佳持續學習目標，並提供了實作最佳目標的現有演算法範例

##### **Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**
2407.16608v1 by Daniela L. Ramos, Hector J. Hortua

Colorectal polyps are generally benign alterations that, if not identified
promptly and managed successfully, can progress to cancer and cause
affectations on the colon mucosa, known as adenocarcinoma. Today advances in
Deep Learning have demonstrated the ability to achieve significant performance
in image classification and detection in medical diagnosis applications.
Nevertheless, these models are prone to overfitting, and making decisions based
only on point estimations may provide incorrect predictions. Thus, to obtain a
more informed decision, we must consider point estimations along with their
reliable uncertainty quantification. In this paper, we built different Bayesian
neural network approaches based on the flexibility of posterior distribution to
develop semantic segmentation of colorectal polyp images. We found that these
models not only provide state-of-the-art performance on the segmentation of
this medical dataset but also, yield accurate uncertainty estimates. We applied
multiplicative normalized flows(MNF) and reparameterization trick on the UNET,
FPN, and LINKNET architectures tested with multiple backbones in deterministic
and Bayesian versions. We report that the FPN + EfficientnetB7 architecture
with MNF is the most promising option given its IOU of 0.94 and Expected
Calibration Error (ECE) of 0.004, combined with its superiority in identifying
difficult-to-detect colorectal polyps, which is effective in clinical areas
where early detection prevents the development of colon cancer.

摘要：大腸息肉通常是良性病變，如果不及時發現並成功處理，可能會演變成癌症並導致大腸粘膜受累，即腺癌。如今，深度學習的進展已證明有能力在醫療診斷應用中實現圖像分類和檢測的顯著性能。儘管如此，這些模型容易過度擬合，並且僅基於點估計做出決策可能會提供不正確的預測。因此，為了獲得更明智的決策，我們必須考慮點估計及其可靠的不確定性量化。在本文中，我們基於後驗分佈的靈活性構建了不同的貝葉斯神經網絡方法，以開發大腸息肉圖像的語義分割。我們發現這些模型不僅在這個醫療數據集的分割上提供了最先進的性能，而且還產生了準確的不確定性估計。我們在確定性和貝葉斯版本中使用多個主幹測試的 UNET、FPN 和 LINKNET 架構上應用乘法歸一化流 (MNF) 和重新參數化技巧。我們報告說，具有 MNF 的 FPN + EfficientnetB7 架構是最有希望的選擇，因為它的 IOU 為 0.94，預期的校準誤差 (ECE) 為 0.004，並且在識別難以檢測的大腸息肉方面具有優越性，這在早期檢測可以防止結腸癌發展的臨床領域是有效的。

##### **Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?**
2407.16607v2 by Jonathan Hayase, Alisa Liu, Yejin Choi, Sewoong Oh, Noah A. Smith

The pretraining data of today's strongest language models is opaque; in
particular, little is known about the proportions of various domains or
languages represented. In this work, we tackle a task which we call data
mixture inference, which aims to uncover the distributional make-up of training
data. We introduce a novel attack based on a previously overlooked source of
information -- byte-pair encoding (BPE) tokenizers, used by the vast majority
of modern language models. Our key insight is that the ordered list of merge
rules learned by a BPE tokenizer naturally reveals information about the token
frequencies in its training data: the first merge is the most common byte pair,
the second is the most common pair after merging the first token, and so on.
Given a tokenizer's merge list along with data samples for each category of
interest, we formulate a linear program that solves for the proportion of each
category in the tokenizer's training set. Importantly, to the extent to which
tokenizer training data is representative of the pretraining data, we
indirectly learn about pretraining data. In controlled experiments, we show
that our attack recovers mixture ratios with high precision for tokenizers
trained on known mixtures of natural languages, programming languages, and data
sources. We then apply our approach to off-the-shelf tokenizers released with
recent LMs. We confirm much publicly disclosed information about these models,
and also make several new inferences: GPT-4o's tokenizer is much more
multilingual than its predecessors, training on 39% non-English data; Llama3
extends GPT-3.5's tokenizer primarily for multilingual (48%) use; GPT-3.5's and
Claude's tokenizers are trained on predominantly code (~60%). We hope our work
sheds light on current design practices for pretraining data, and inspires
continued research into data mixture inference for LMs.

摘要：當今最強大的語言模型的預訓練資料是不透明的；特別是，對於各種領域或語言的比例知之甚少。在這項工作中，我們處理一項我們稱之為資料混合推論的任務，其目的是揭示訓練資料的分布式組成。我們引入了一種基於先前被忽視的資訊來源的新攻擊——位元組對編碼 (BPE) 代幣器，它被絕大多數現代語言模型所使用。我們的關鍵見解是，BPE 代幣器所學習的合併規則的有序清單自然地揭示了其訓練資料中代幣頻率的資訊：第一次合併是最常見的位元組對，第二次合併是最常見的對，依此類推。給定一個代幣器的合併清單以及每個感興趣類別的資料範例，我們制定了一個線性程式，用於解決代幣器訓練集中每個類別的比例。重要的是，在代幣器訓練資料代表預訓練資料的程度下，我們間接了解了預訓練資料。在受控實驗中，我們展示了我們的攻擊以高精度恢復了在已知自然語言、程式語言和資料來源混合物上訓練的代幣器的混合比率。然後，我們將我們的做法應用於與近期 LM 一起發布的現成代幣器。我們確認了關於這些模型的大量公開資訊，並做出了幾個新的推論：GPT-4o 的代幣器比其前身更具多語言性，在 39% 的非英語資料上進行訓練；Llama3 主要為多語言 (48%) 使用而擴充了 GPT-3.5 的代幣器；GPT-3.5 和 Claude 的代幣器主要在程式碼 (~60%) 上進行訓練。我們希望我們的努力能為預訓練資料的當前設計實務提供啟發，並激勵持續研究 LM 的資料混合推論。

##### **Shared Imagination: LLMs Hallucinate Alike**
2407.16604v1 by Yilun Zhou, Caiming Xiong, Silvio Savarese, Chien-Sheng Wu

Despite the recent proliferation of large language models (LLMs), their
training recipes -- model architecture, pre-training data and optimization
algorithm -- are often very similar. This naturally raises the question of the
similarity among the resulting models. In this paper, we propose a novel
setting, imaginary question answering (IQA), to better understand model
similarity. In IQA, we ask one model to generate purely imaginary questions
(e.g., on completely made-up concepts in physics) and prompt another model to
answer. Surprisingly, despite the total fictionality of these questions, all
models can answer each other's questions with remarkable success, suggesting a
"shared imagination space" in which these models operate during such
hallucinations. We conduct a series of investigations into this phenomenon and
discuss implications on model homogeneity, hallucination, and computational
creativity.

摘要：儘管大型語言模型 (LLM) 近期大量湧現，但其訓練配方（模型架構、預訓練資料和最佳化演算法）通常非常相似。這自然會引發對所產生模型間相似性的疑問。在本文中，我們提出了一種新穎的設定，即虛擬問答 (IQA)，以更好地了解模型相似性。在 IQA 中，我們要求一個模型產生純粹虛擬的問題（例如，關於物理學中完全虛構的概念），並提示另一個模型回答。令人驚訝的是，儘管這些問題完全是虛構的，但所有模型都能以顯著的成功率回答彼此的問題，這表明這些模型在產生這些幻覺時運作於一個「共享想像空間」中。我們對此現象進行了一系列調查，並討論了對模型同質性、幻覺和計算創造力的影響。

##### **GenRec: A Flexible Data Generator for Recommendations**
2407.16594v1 by Erica Coppolillo, Simone Mungari, Ettore Ritacco, Giuseppe Manco

The scarcity of realistic datasets poses a significant challenge in
benchmarking recommender systems and social network analysis methods and
techniques. A common and effective solution is to generate synthetic data that
simulates realistic interactions. However, although various methods have been
proposed, the existing literature still lacks generators that are fully
adaptable and allow easy manipulation of the underlying data distributions and
structural properties. To address this issue, the present work introduces
GenRec, a novel framework for generating synthetic user-item interactions that
exhibit realistic and well-known properties observed in recommendation
scenarios. The framework is based on a stochastic generative process based on
latent factor modeling. Here, the latent factors can be exploited to yield
long-tailed preference distributions, and at the same time they characterize
subpopulations of users and topic-based item clusters. Notably, the proposed
framework is highly flexible and offers a wide range of hyper-parameters for
customizing the generation of user-item interactions. The code used to perform
the experiments is publicly available at
https://anonymous.4open.science/r/GenRec-DED3.

摘要：現實資料集的稀缺性在推薦系統和社交網路分析方法和技術的基準測試中構成重大挑戰。一個常見且有效的解決方案是生成模擬現實互動的合成資料。然而，儘管已經提出各種方法，現有文獻仍缺乏完全適應且允許輕鬆操作基礎資料分佈和結構屬性的產生器。為了解決這個問題，本研究引入了 GenRec，這是一個用於生成合成使用者一項目互動的新框架，該互動展現了在推薦情境中觀察到的現實且眾所周知的屬性。該框架基於一個基於潛在因子建模的隨機生成過程。在此，潛在因子可被利用以產生長尾偏好分佈，同時它們也表徵使用者次族群和基於主題的項目叢集。值得注意的是，所提出的框架非常靈活，並提供廣泛的超參數以自訂使用者一項目互動的生成。用於執行實驗的程式碼在 https://anonymous.4open.science/r/GenRec-DED3 公開提供。

##### **A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**
2407.16593v1 by Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley

There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.

摘要：醫療保健專業人員對於患者臨床經驗的認知與實際情況之間存在著一道無形的障礙。此障礙可能是由環境所造成，阻礙患者與醫療保健專業人員公開分享他們的經驗。由於觀察到患者在社群媒體上更坦率地討論和交換知識，因此可以從這些平台獲得有價值的見解。然而，社群媒體上充斥著非患者貼文，因此有必要過濾掉這些不相關的內容，以區分患者的真實聲音，我們將此任務稱為患者聲音分類。在本研究中，我們分析了語言特徵在準確分類患者聲音中的重要性。我們的研究結果強調了語言和統計文字相似性分析在識別患者群組之間共同模式中的重要角色。這些結果暗示了患者在疾病層級和各種治療領域中表達自己的方式存在著更明顯的差異。此外，我們根據具有類似語言模式的合併資料集微調了預先訓練好的語言模型，進而產生高度準確的自動患者聲音分類。作為這項主題的開創性研究，我們專注於從社群媒體中提取真實的患者經驗，這是邁向提升醫療保健標準和培養以患者為中心的途徑的關鍵一步。

##### **TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback**
2407.16574v1 by Eunseop Yoon, Hee Suk Yoon, SooHwan Eom, Gunsoo Han, Daniel Wontae Nam, Daejin Jo, Kyoung-Woon On, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo

Reinforcement Learning from Human Feedback (RLHF) leverages human preference
data to train language models to align more closely with human essence. These
human preference data, however, are labeled at the sequence level, creating a
mismatch between sequence-level preference labels and tokens, which are
autoregressively generated from the language model. Although several recent
approaches have tried to provide token-level (i.e., dense) rewards for each
individual token, these typically rely on predefined discrete reward values
(e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying
degrees of preference inherent to each token. To address this limitation, we
introduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a
discriminator trained to distinguish positive and negative tokens, and the
confidence of the discriminator is used to assign continuous rewards to each
token considering the context. Extensive experiments show that our proposed
TLCR leads to consistent performance improvements over previous sequence-level
or token-level discrete rewards on open-ended generation benchmarks.

摘要：強化學習來自人類回饋 (RLHF) 利用人類偏好資料訓練語言模型，以更貼近人類本質。然而，這些人類偏好資料是在序列層級標記，造成序列層級偏好標籤與由語言模型自迴歸產生的符號之間的不匹配。雖然最近有幾種方法嘗試為每個個別符號提供符號層級（即密集）獎勵，但這些方法通常依賴於預定義的離散獎勵值（例如，正面：+1，負面：-1，中立：0），未能考量每個符號固有的不同偏好程度。為了解決這個限制，我們針對 RLHF 引入了 TLCR（符號層級連續獎勵），它結合了一個訓練用於區分正面和負面符號的判別器，並且判別器的信心用於根據上下文為每個符號分配連續獎勵。廣泛的實驗顯示，我們提出的 TLCR 在開放式生成基準上，相較於先前的序列層級或符號層級離散獎勵，帶來了一致的效能提升。

##### **PyBench: Evaluating LLM Agent on various real-world coding tasks**
2407.16732v1 by Yaolun Zhang, Yinxu Pan, Yudong Wang, Jie Cai, Zhi Zheng, Guoyang Zeng, Zhiyuan Liu

The LLM Agent, equipped with a code interpreter, is capable of automatically
solving real-world coding tasks, such as data analysis and image editing.
  However, existing benchmarks primarily focus on either simplistic tasks, such
as completing a few lines of code, or on extremely complex and specific tasks
at the repository level, neither of which are representative of various daily
coding tasks.
  To address this gap, we introduce \textbf{PyBench}, a benchmark encompassing
five main categories of real-world tasks, covering more than 10 types of files.
Given a high-level user query and related files, the LLM Agent needs to reason
and execute Python code via a code interpreter for a few turns before making a
formal response to fulfill the user's requirements. Successfully addressing
tasks in PyBench demands a robust understanding of various Python packages,
superior reasoning capabilities, and the ability to incorporate feedback from
executed code. Our evaluations indicate that current open-source LLMs are
struggling with these tasks. Hence, we conduct analysis and experiments on four
kinds of datasets proving that comprehensive abilities are needed for PyBench.
Our fine-tuned 8B size model: \textbf{PyLlama3} achieves an exciting
performance on PyBench which surpasses many 33B and 70B size models. Our
Benchmark, Training Dataset, and Model are available at:
\href{https://github.com/Mercury7353/PyBench}{https://github.com/Mercury7353/PyBench}

摘要：配備程式碼解釋器的 LLM Agent，能夠自動解決現實世界的程式碼任務，例如資料分析和影像編輯。
然而，現有的基準測試主要專注於簡化的任務，例如完成幾行程式碼，或在儲存庫層級上極為複雜且特定的任務，這兩種都不是各種日常程式碼任務的代表。
為了解決這個差距，我們引入了\textbf{PyBench}，一個包含五種類別現實世界任務的基準測試，涵蓋超過 10 種檔案類型。
給定一個高階使用者查詢和相關檔案，LLM Agent 需要透過程式碼解釋器進行推理並執行 Python 程式碼幾次，才能正式回應以滿足使用者的需求。成功解決 PyBench 中的任務需要對各種 Python 套件有深入的了解、卓越的推理能力，以及整合執行程式碼回饋的能力。我們的評估表明，目前的開源 LLM 在這些任務上遇到了困難。因此，我們對四種類型的資料集進行分析和實驗，證明 PyBench 需要全面的能力。我們微調的 8B 大小模型：\textbf{PyLlama3} 在 PyBench 上達到了令人興奮的效能，超越了許多 33B 和 70B 大小的模型。我們的基準測試、訓練資料集和模型可在以下位置取得：
\href{https://github.com/Mercury7353/PyBench}{https://github.com/Mercury7353/PyBench}

