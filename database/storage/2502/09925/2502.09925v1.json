{"2502.09925": {"publish_time": "2025-02-14", "title": "TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types", "paper_summary": "Multimodal visual language models are gaining prominence in open-world\napplications, driven by advancements in model architectures, training\ntechniques, and high-quality data. However, their performance is often limited\nby insufficient task-specific data, leading to poor generalization and biased\noutputs. Existing efforts to increase task diversity in fine-tuning datasets\nare hindered by the labor-intensive process of manual task labeling, which\ntypically produces only a few hundred task types. To address this, we propose\nTaskGalaxy, a large-scale multimodal instruction fine-tuning dataset comprising\n19,227 hierarchical task types and 413,648 samples. TaskGalaxy utilizes GPT-4o\nto enrich task diversity by expanding from a small set of manually defined\ntasks, with CLIP and GPT-4o filtering those that best match open-source images,\nand generating relevant question-answer pairs. Multiple models are employed to\nensure sample quality. This automated process enhances both task diversity and\ndata quality, reducing manual intervention. Incorporating TaskGalaxy into\nLLaVA-v1.5 and InternVL-Chat-v1.0 models shows substantial performance\nimprovements across 16 benchmarks, demonstrating the critical importance of\ntask diversity. TaskGalaxy is publicly released at\nhttps://github.com/Kwai-YuanQi/TaskGalaxy.", "paper_summary_zh": "\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u5e94\u7528\u4e2d\u6b63\u53d8\u5f97\u8d8a\u6765\u8d8a\u7a81\u51fa\uff0c\u8fd9\u5f97\u76ca\u4e8e\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u6280\u672f\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u8fdb\u6b65\u3002\u7136\u800c\uff0c\u5b83\u4eec\u7684\u6027\u80fd\u5e38\u5e38\u53d7\u5230\u7279\u5b9a\u4efb\u52a1\u6570\u636e\u4e0d\u8db3\u7684\u9650\u5236\uff0c\u4ece\u800c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u8f93\u51fa\u6709\u504f\u5dee\u3002\u73b0\u6709\u7684\u52aa\u529b\u662f\u901a\u8fc7\u5fae\u8c03\u6570\u636e\u96c6\u6765\u589e\u52a0\u4efb\u52a1\u591a\u6837\u6027\uff0c\u4f46\u53d7\u5230\u4eba\u5de5\u4efb\u52a1\u6807\u8bb0\u52b3\u52a8\u5bc6\u96c6\u578b\u8fc7\u7a0b\u7684\u963b\u788d\uff0c\u901a\u5e38\u53ea\u80fd\u4ea7\u751f\u51e0\u767e\u79cd\u4efb\u52a1\u7c7b\u578b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 TaskGalaxy\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b 19,227 \u4e2a\u5206\u5c42\u4efb\u52a1\u7c7b\u578b\u548c 413,648 \u4e2a\u6837\u672c\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u3002TaskGalaxy \u5229\u7528 GPT-4o \u901a\u8fc7\u4ece\u4e00\u5c0f\u90e8\u5206\u624b\u52a8\u5b9a\u4e49\u7684\u4efb\u52a1\u6269\u5c55\u6765\u4e30\u5bcc\u4efb\u52a1\u591a\u6837\u6027\uff0c\u5e76\u4f7f\u7528 CLIP \u548c GPT-4o \u7b5b\u9009\u51fa\u4e0e\u5f00\u6e90\u56fe\u50cf\u6700\u5339\u914d\u7684\u4efb\u52a1\uff0c\u5e76\u751f\u6210\u76f8\u5173\u7684\u95ee\u7b54\u5bf9\u3002\u91c7\u7528\u591a\u4e2a\u6a21\u578b\u6765\u786e\u4fdd\u6837\u672c\u8d28\u91cf\u3002\u8fd9\u4e2a\u81ea\u52a8\u5316\u8fc7\u7a0b\u65e2\u63d0\u9ad8\u4e86\u4efb\u52a1\u591a\u6837\u6027\uff0c\u53c8\u63d0\u9ad8\u4e86\u6570\u636e\u8d28\u91cf\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5e72\u9884\u3002\u5c06 TaskGalaxy \u7eb3\u5165 LLaVA-v1.5 \u548c InternVL-Chat-v1.0 \u6a21\u578b\u663e\u793a\u51fa\u8de8\u8d8a 16 \u4e2a\u57fa\u51c6\u7684\u5b9e\u8d28\u6027\u6027\u80fd\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u4efb\u52a1\u591a\u6837\u6027\u7684\u5173\u952e\u91cd\u8981\u6027\u3002TaskGalaxy \u5df2\u5728 https://github.com/Kwai-YuanQi/TaskGalaxy \u516c\u5f00\u53d1\u5e03\u3002", "author": "Jiankang Chen et.al.", "authors": "Jiankang Chen, Tianke Zhang, Changyi Liu, Haojie Ding, Yaya Shi, Feng Cheng, Huihui Xiao, Bin Wen, Fan Yang, Tingting Gao, Di Zhang", "id": "2502.09925v1", "paper_url": "http://arxiv.org/abs/2502.09925v1", "repo": "null"}}