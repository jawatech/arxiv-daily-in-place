{"2408.03164": {"publish_time": "2024-08-06", "title": "Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study", "paper_summary": "Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced\nconvolution method that allows enlarging the receptive fields (RF) without\nincreasing the number of parameters, like the dilated convolution, yet without\nimposing a regular grid. DCLS has been shown to outperform the standard and\ndilated convolutions on several computer vision benchmarks. Here, we show that,\nin addition, DCLS increases the models' interpretability, defined as the\nalignment with human visual strategies. To quantify it, we use the Spearman\ncorrelation between the models' GradCAM heatmaps and the ClickMe dataset\nheatmaps, which reflect human visual attention. We took eight reference models\n- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and\n36) - and drop-in replaced the standard convolution layers with DCLS ones. This\nimproved the interpretability score in seven of them. Moreover, we observed\nthat Grad-CAM generated random heatmaps for two models in our study: CAFormer\nand ConvFormer models, leading to low interpretability scores. We addressed\nthis issue by introducing Threshold-Grad-CAM, a modification built on top of\nGrad-CAM that enhanced interpretability across nearly all models. The code and\ncheckpoints to reproduce this study are available at:\nhttps://github.com/rabihchamas/DCLS-GradCAM-Eval.", "paper_summary_zh": "\u53ef\u5b78\u7fd2\u9593\u8ddd\u64f4\u5c55\u5377\u7a4d (DCLS) \u662f\u4e00\u7a2e\u8fd1\u671f\u9032\u968e\u7684\u5377\u7a4d\u65b9\u6cd5\uff0c\u5141\u8a31\u64f4\u5c55\u611f\u53d7\u91ce (RF)\uff0c\u800c\u7121\u9808\u589e\u52a0\u53c3\u6578\u6578\u91cf\uff0c\u5c31\u50cf\u64f4\u5c55\u5377\u7a4d\u4e00\u6a23\uff0c\u4f46\u7121\u9808\u5f37\u5236\u4f7f\u7528\u898f\u5247\u7db2\u683c\u3002\u5df2\u8b49\u5be6 DCLS \u5728\u591a\u500b\u96fb\u8166\u8996\u89ba\u57fa\u6e96\u4e0a\u512a\u65bc\u6a19\u6e96\u5377\u7a4d\u548c\u64f4\u5c55\u5377\u7a4d\u3002\u5728\u6b64\uff0c\u6211\u5011\u5c55\u793a DCLS \u9664\u4e86\u80fd\u63d0\u5347\u6a21\u578b\u7684\u53ef\u8a6e\u91cb\u6027\uff0c\u5b9a\u7fa9\u70ba\u8207\u4eba\u985e\u8996\u89ba\u7b56\u7565\u7684\u4e00\u81f4\u6027\u3002\u70ba\u91cf\u5316\u5b83\uff0c\u6211\u5011\u4f7f\u7528\u6a21\u578b\u7684 GradCAM \u71b1\u5716\u8207 ClickMe \u8cc7\u6599\u96c6\u71b1\u5716\u4e4b\u9593\u7684 Spearman \u76f8\u95dc\u6027\uff0c\u5b83\u53cd\u6620\u4e86\u4eba\u985e\u7684\u8996\u89ba\u6ce8\u610f\u529b\u3002\u6211\u5011\u63a1\u7528\u4e86\u516b\u500b\u53c3\u8003\u6a21\u578b - ResNet50\u3001ConvNeXt (T\u3001S \u548c B)\u3001CAFormer\u3001ConvFormer \u548c FastViT (sa 24 \u548c 36) - \u4e26\u4ee5 DCLS \u53d6\u4ee3\u6a19\u6e96\u5377\u7a4d\u5c64\u3002\u9019\u63d0\u5347\u4e86\u5176\u4e2d\u4e03\u500b\u6a21\u578b\u7684\u53ef\u8a6e\u91cb\u6027\u5206\u6578\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230 Grad-CAM \u70ba\u6211\u5011\u7814\u7a76\u4e2d\u7684\u5169\u500b\u6a21\u578b\u7522\u751f\u4e86\u96a8\u6a5f\u71b1\u5716\uff1aCAFormer \u548c ConvFormer \u6a21\u578b\uff0c\u5c0e\u81f4\u53ef\u8a6e\u91cb\u6027\u5206\u6578\u4f4e\u3002\u6211\u5011\u900f\u904e\u5f15\u5165 Threshold-Grad-CAM \u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u9019\u662f\u4e00\u7a2e\u5efa\u7acb\u5728 Grad-CAM \u4e4b\u4e0a\u7684\u4fee\u6539\uff0c\u53ef\u589e\u5f37\u5e7e\u4e4e\u6240\u6709\u6a21\u578b\u7684\u53ef\u8a6e\u91cb\u6027\u3002\u53ef\u65bc\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\u91cd\u73fe\u6b64\u7814\u7a76\u7684\u7a0b\u5f0f\u78bc\u548c\u6aa2\u67e5\u9ede\uff1ahttps://github.com/rabihchamas/DCLS-GradCAM-Eval\u3002", "author": "Rabih Chamas et.al.", "authors": "Rabih Chamas, Ismail Khalfaoui-Hassani, Timothee Masquelier", "id": "2408.03164v1", "paper_url": "http://arxiv.org/abs/2408.03164v1", "repo": "null"}}