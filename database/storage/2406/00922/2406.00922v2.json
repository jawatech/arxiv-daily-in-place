{"2406.00922": {"publish_time": "2024-06-03", "title": "MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning", "paper_summary": "In high-stakes domains like clinical reasoning, AI assistants powered by\nlarge language models (LLMs) are yet to be reliable and safe. We identify a key\nobstacle towards reliability: existing LLMs are trained to answer any question,\neven with incomplete context in the prompt or insufficient parametric\nknowledge. We propose to change this paradigm to develop more careful LLMs that\nask follow-up questions to gather necessary and sufficient information and\nrespond reliably. We introduce MEDIQ, a framework to simulate realistic\nclinical interactions, which incorporates a Patient System and an adaptive\nExpert System. The Patient may provide incomplete information in the beginning;\nthe Expert refrains from making diagnostic decisions when unconfident, and\ninstead elicits missing details from the Patient via follow-up questions. To\nevaluate MEDIQ, we convert MEDQA and CRAFT-MD -- medical benchmarks for\ndiagnostic question answering -- into an interactive setup. We develop a\nreliable Patient system and prototype several Expert systems, first showing\nthat directly prompting state-of-the-art LLMs to ask questions degrades the\nquality of clinical reasoning, indicating that adapting LLMs to interactive\ninformation-seeking settings is nontrivial. We then augment the Expert with a\nnovel abstention module to better estimate model confidence and decide whether\nto ask more questions, thereby improving diagnostic accuracy by 20.3%; however,\nperformance still lags compared to an (unrealistic in practice) upper bound\nwhen full information is given upfront. Further analyses reveal that\ninteractive performance can be improved by filtering irrelevant contexts and\nreformatting conversations. Overall, our paper introduces a novel problem\ntowards LLM reliability, a novel MEDIQ framework, and highlights important\nfuture directions to extend the information-seeking abilities of LLM assistants\nin critical domains.", "paper_summary_zh": "<paragraph>\u5728\u81e8\u5e8a\u63a8\u7406\u7b49\u9ad8\u98a8\u96aa\u9818\u57df\uff0c\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63d0\u4f9b\u652f\u63f4\u7684 AI \u52a9\u7406\u4ecd\u672a\u9054\u5230\u53ef\u9760\u548c\u5b89\u5168\u7684\u7a0b\u5ea6\u3002\u6211\u5011\u627e\u51fa\u53ef\u9760\u6027\u7684\u4e00\u500b\u4e3b\u8981\u969c\u7919\uff1a\u73fe\u6709\u7684 LLM \u7d93\u904e\u8a13\u7df4\u53ef\u4ee5\u56de\u7b54\u4efb\u4f55\u554f\u984c\uff0c\u5373\u4f7f\u63d0\u793a\u4e2d\u7684\u5167\u5bb9\u4e0d\u5b8c\u6574\u6216\u53c3\u6578\u77e5\u8b58\u4e0d\u8db3\u3002\u6211\u5011\u5efa\u8b70\u6539\u8b8a\u9019\u7a2e\u6a21\u5f0f\uff0c\u958b\u767c\u51fa\u66f4\u8b39\u614e\u7684 LLM\uff0c\u5b83\u5011\u6703\u63d0\u51fa\u5f8c\u7e8c\u554f\u984c\u4f86\u6536\u96c6\u5fc5\u8981\u4e14\u5145\u5206\u7684\u8cc7\u8a0a\uff0c\u4e26\u505a\u51fa\u53ef\u9760\u7684\u56de\u61c9\u3002\u6211\u5011\u63a8\u51fa MEDIQ\uff0c\u4e00\u500b\u6a21\u64ec\u73fe\u5be6\u81e8\u5e8a\u4e92\u52d5\u7684\u67b6\u69cb\uff0c\u5b83\u5305\u542b\u4e00\u500b\u75c5\u4eba\u7cfb\u7d71\u548c\u4e00\u500b\u9069\u61c9\u6027\u5c08\u5bb6\u7cfb\u7d71\u3002\u75c5\u4eba\u4e00\u958b\u59cb\u53ef\u80fd\u6703\u63d0\u4f9b\u4e0d\u5b8c\u6574\u7684\u8cc7\u8a0a\uff1b\u5c08\u5bb6\u5728\u4e0d\u78ba\u5b9a\u7684\u6642\u5019\u6703\u907f\u514d\u505a\u51fa\u8a3a\u65b7\u6c7a\u7b56\uff0c\u800c\u662f\u900f\u904e\u5f8c\u7e8c\u554f\u984c\u5f9e\u75c5\u4eba\u90a3\u88e1\u5f15\u51fa\u907a\u6f0f\u7684\u7d30\u7bc0\u3002\u70ba\u4e86\u8a55\u4f30 MEDIQ\uff0c\u6211\u5011\u5c07 MEDQA \u548c CRAFT-MD\uff08\u7528\u65bc\u8a3a\u65b7\u6027\u554f\u7b54\u7684\u91ab\u7642\u57fa\u6e96\uff09\u8f49\u63db\u70ba\u4e92\u52d5\u5f0f\u8a2d\u5b9a\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u53ef\u9760\u7684\u75c5\u4eba\u7cfb\u7d71\u548c\u5e7e\u500b\u5c08\u5bb6\u7cfb\u7d71\u539f\u578b\uff0c\u9996\u5148\u8868\u660e\u76f4\u63a5\u63d0\u793a\u6700\u5148\u9032\u7684 LLM \u63d0\u51fa\u554f\u984c\u6703\u964d\u4f4e\u81e8\u5e8a\u63a8\u7406\u7684\u54c1\u8cea\uff0c\u9019\u8868\u793a\u5c07 LLM \u9069\u61c9\u5230\u4e92\u52d5\u5f0f\u8cc7\u8a0a\u5c0b\u6c42\u8a2d\u5b9a\u4e26\u975e\u6613\u4e8b\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u4e00\u500b\u65b0\u7a4e\u7684\u68c4\u6b0a\u6a21\u7d44\u64f4\u5145\u5c08\u5bb6\uff0c\u4ee5\u66f4\u597d\u5730\u4f30\u8a08\u6a21\u578b\u7684\u4fe1\u5fc3\u4e26\u6c7a\u5b9a\u662f\u5426\u8981\u63d0\u51fa\u66f4\u591a\u554f\u984c\uff0c\u5f9e\u800c\u5c07\u8a3a\u65b7\u6e96\u78ba\u7387\u63d0\u9ad8 20.3%\uff1b\u7136\u800c\uff0c\u8207\u5728\u6700\u958b\u59cb\u5c31\u7d66\u4e88\u5b8c\u6574\u8cc7\u8a0a\u7684\uff08\u5728\u5be6\u52d9\u4e0a\u4e0d\u5207\u5be6\u969b\u7684\uff09\u4e0a\u9650\u76f8\u6bd4\uff0c\u6548\u80fd\u4ecd\u7136\u843d\u5f8c\u3002\u9032\u4e00\u6b65\u7684\u5206\u6790\u986f\u793a\uff0c\u4e92\u52d5\u6548\u80fd\u53ef\u4ee5\u900f\u904e\u904e\u6ffe\u4e0d\u76f8\u95dc\u7684\u5167\u5bb9\u548c\u91cd\u65b0\u683c\u5f0f\u5316\u5c0d\u8a71\u4f86\u6539\u5584\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u7684\u8ad6\u6587\u91dd\u5c0d LLM \u53ef\u9760\u6027\u63d0\u51fa\u4e00\u500b\u65b0\u554f\u984c\u3001\u4e00\u500b\u65b0\u7a4e\u7684 MEDIQ \u67b6\u69cb\uff0c\u4e26\u5f37\u8abf\u5728\u95dc\u9375\u9818\u57df\u64f4\u5c55 LLM \u52a9\u7406\u8cc7\u8a0a\u5c0b\u6c42\u80fd\u529b\u7684\u91cd\u8981\u672a\u4f86\u65b9\u5411\u3002</paragraph>", "author": "Shuyue Stella Li et.al.", "authors": "Shuyue Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei Koh, Yulia Tsvetkov", "id": "2406.00922v2", "paper_url": "http://arxiv.org/abs/2406.00922v2", "repo": "https://github.com/stellali7/mediq"}}