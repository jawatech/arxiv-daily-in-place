{"2410.18607": {"publish_time": "2024-10-24", "title": "STTATTS: Unified Speech-To-Text And Text-To-Speech Model", "paper_summary": "Speech recognition and speech synthesis models are typically trained\nseparately, each with its own set of learning objectives, training data, and\nmodel parameters, resulting in two distinct large networks. We propose a\nparameter-efficient approach to learning ASR and TTS jointly via a multi-task\nlearning objective and shared parameters. Our evaluation demonstrates that the\nperformance of our multi-task model is comparable to that of individually\ntrained models while significantly saving computational and memory costs\n($\\sim$50\\% reduction in the total number of parameters required for the two\ntasks combined). We experiment with English as a resource-rich language, and\nArabic as a relatively low-resource language due to shortage of TTS data. Our\nmodels are trained with publicly available data, and both the training code and\nmodel checkpoints are openly available for further research.", "paper_summary_zh": "\u8a9e\u97f3\u8fa8\u8b58\u548c\u8a9e\u97f3\u5408\u6210\u6a21\u578b\u901a\u5e38\u662f\u5206\u958b\u8a13\u7df4\u7684\uff0c\u6bcf\u500b\u6a21\u578b\u90fd\u6709\u81ea\u5df1\u7684\u4e00\u7d44\u5b78\u7fd2\u76ee\u6a19\u3001\u8a13\u7df4\u8cc7\u6599\u548c\u6a21\u578b\u53c3\u6578\uff0c\u5c0e\u81f4\u5169\u500b\u4e0d\u540c\u7684\u5927\u578b\u7db2\u8def\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u53c3\u6578\u6709\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u900f\u904e\u591a\u4efb\u52d9\u5b78\u7fd2\u76ee\u6a19\u548c\u5171\u4eab\u53c3\u6578\u4f86\u5171\u540c\u5b78\u7fd2 ASR \u548c TTS\u3002\u6211\u5011\u7684\u8a55\u4f30\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u591a\u4efb\u52d9\u6a21\u578b\u7684\u6548\u80fd\u8207\u500b\u5225\u8a13\u7df4\u7684\u6a21\u578b\u76f8\u7576\uff0c\u540c\u6642\u5927\u5e45\u7bc0\u7701\u4e86\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u6210\u672c\uff08\u5169\u500b\u4efb\u52d9\u7e3d\u5171\u9700\u8981\u7684\u53c3\u6578\u6578\u91cf\u6e1b\u5c11\u4e86 $\\sim$50%\uff09\u3002\u6211\u5011\u4ee5\u82f1\u8a9e\u4f5c\u70ba\u4e00\u7a2e\u8cc7\u6e90\u8c50\u5bcc\u7684\u8a9e\u8a00\u9032\u884c\u5be6\u9a57\uff0c\u4e26\u4ee5\u963f\u62c9\u4f2f\u8a9e\u4f5c\u70ba\u4e00\u7a2e\u76f8\u5c0d\u8cc7\u6e90\u8f03\u5c11\u7684\u8a9e\u8a00\uff0c\u56e0\u70ba\u7f3a\u4e4f TTS \u8cc7\u6599\u3002\u6211\u5011\u7684\u6a21\u578b\u4f7f\u7528\u516c\u958b\u7684\u8cc7\u6599\u9032\u884c\u8a13\u7df4\uff0c\u8a13\u7df4\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u6aa2\u67e5\u9ede\u90fd\u516c\u958b\u63d0\u4f9b\uff0c\u4f9b\u9032\u4e00\u6b65\u7814\u7a76\u4f7f\u7528\u3002", "author": "Hawau Olamide Toyin et.al.", "authors": "Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki", "id": "2410.18607v1", "paper_url": "http://arxiv.org/abs/2410.18607v1", "repo": "null"}}