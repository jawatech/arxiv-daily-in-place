{"2405.07840": {"publish_time": "2024-05-13", "title": "Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM", "paper_summary": "Decoding language information from brain signals represents a vital research\narea within brain-computer interfaces, particularly in the context of\ndeciphering the semantic information from the fMRI signal. However, many\nexisting efforts concentrate on decoding small vocabulary sets, leaving space\nfor the exploration of open vocabulary continuous text decoding. In this paper,\nwe introduce a novel method, the \\textbf{Brain Prompt GPT (BP-GPT)}. By using\nthe brain representation that is extracted from the fMRI as a prompt, our\nmethod can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we\nintroduce a text-to-text baseline and align the fMRI prompt to the text prompt.\nBy introducing the text-to-text baseline, our BP-GPT can extract a more robust\nbrain prompt and promote the decoding of pre-trained LLM. We evaluate our\nBP-GPT on the open-source auditory semantic decoding dataset and achieve a\nsignificant improvement up to $4.61\\%$ on METEOR and $2.43\\%$ on BERTScore\nacross all the subjects compared to the state-of-the-art method. The\nexperimental results demonstrate that using brain representation as a prompt to\nfurther drive LLM for auditory neural decoding is feasible and effective.", "paper_summary_zh": "\u5f9e\u8166\u90e8\u8a0a\u865f\u89e3\u78bc\u8a9e\u8a00\u8cc7\u8a0a\uff0c\u5728\u8166\u96fb\u8166\u4ecb\u9762\u4e2d\u662f\u4e00\u500b\u91cd\u8981\u7684\u7814\u7a76\u9818\u57df\uff0c\u7279\u5225\u662f\u5728\u5f9e fMRI \u8a0a\u865f\u4e2d\u89e3\u78bc\u8a9e\u610f\u8cc7\u8a0a\u7684\u8108\u7d61\u4e2d\u3002\u7136\u800c\uff0c\u8a31\u591a\u73fe\u6709\u7684\u52aa\u529b\u90fd\u96c6\u4e2d\u5728\u89e3\u78bc\u5c0f\u578b\u8a5e\u5f59\u96c6\u4e0a\uff0c\u9019\u70ba\u63a2\u7d22\u958b\u653e\u5f0f\u8a5e\u5f59\u9023\u7e8c\u6587\u5b57\u89e3\u78bc\u7559\u4e0b\u4e86\u7a7a\u9593\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5373 \\textbf{\u8166\u63d0\u793a GPT (BP-GPT)}\u3002\u900f\u904e\u4f7f\u7528\u5f9e fMRI \u4e2d\u63d0\u53d6\u7684\u8166\u90e8\u8868\u5fb5\u4f5c\u70ba\u63d0\u793a\uff0c\u6211\u5011\u7684\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528 GPT-2 \u5c07 fMRI \u8a0a\u865f\u89e3\u78bc\u6210\u523a\u6fc0\u6587\u5b57\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u6587\u5b57\u5c0d\u6587\u5b57\u7684\u57fa\u6e96\uff0c\u4e26\u5c07 fMRI \u63d0\u793a\u8207\u6587\u5b57\u63d0\u793a\u5c0d\u9f4a\u3002\u900f\u904e\u5f15\u5165\u6587\u5b57\u5c0d\u6587\u5b57\u7684\u57fa\u6e96\uff0c\u6211\u5011\u7684 BP-GPT \u53ef\u4ee5\u63d0\u53d6\u66f4\u7a69\u5065\u7684\u8166\u90e8\u63d0\u793a\uff0c\u4e26\u4fc3\u9032\u9810\u5148\u8a13\u7df4\u597d\u7684 LLM \u7684\u89e3\u78bc\u3002\u6211\u5011\u5728\u958b\u653e\u539f\u59cb\u78bc\u807d\u89ba\u8a9e\u610f\u89e3\u78bc\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u6211\u5011\u7684 BP-GPT\uff0c\u4e26\u5728 METEOR \u4e0a\u7372\u5f97\u9ad8\u9054 4.61%\uff0c\u5728 BERTScore \u4e0a\u7372\u5f97 2.43% \u7684\u986f\u8457\u6539\u9032\uff0c\u8207\u6700\u5148\u9032\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u6709\u53d7\u8a66\u8005\u90fd\u7372\u5f97\u4e86\u6539\u9032\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u4f7f\u7528\u8166\u90e8\u8868\u5fb5\u4f5c\u70ba\u63d0\u793a\uff0c\u9032\u4e00\u6b65\u9a45\u52d5 LLM \u9032\u884c\u807d\u89ba\u795e\u7d93\u89e3\u78bc\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002", "author": "Xiaoyu Chen et.al.", "authors": "Xiaoyu Chen, Changde Du, Che Liu, Yizhe Wang, Huiguang He", "id": "2405.07840v1", "paper_url": "http://arxiv.org/abs/2405.07840v1", "repo": "null"}}