{"2409.11212": {"publish_time": "2024-09-17", "title": "Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization", "paper_summary": "Iterative preference optimization has recently become one of the de-facto\ntraining paradigms for large language models (LLMs), but the performance is\nstill underwhelming due to too much noisy preference data yielded in the loop.\nTo combat this issue, we present an \\textbf{U}ncertainty-enhanced\n\\textbf{P}reference \\textbf{O}ptimization (UPO) framework to make the LLM\nself-evolve with reliable feedback. The key idea is mitigating the noisy\npreference data derived from the current policy and reward models by performing\npair-wise uncertainty estimation and judiciously reliable feedback sampling. To\nreach this goal, we thus introduce an estimator model, which incorporates Monte\nCarlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty\nestimation for the preference data derived from the LLM policy. Compared to the\nexisting methods that directly filter generated responses based on the reward\nscore, the estimator focuses on the model uncertainty in a pair-wise manner and\neffectively bypasses the confirmation bias problem of the reward model.\nAdditionally, we also propose an uncertainty-enhanced self-evolution algorithm\nto improve the robustness of preference optimization and encourage the LLM to\ngenerate responses with both high reward and certainty. Extensive experiments\nover multiple benchmarks demonstrate that our framework substantially\nalleviates the noisy problem and improves the performance of iterative\npreference optimization.", "paper_summary_zh": "\u8fed\u4ee3\u504f\u597d\u4f18\u5316\u6700\u8fd1\u5df2\u6210\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b9e\u9645\u8bad\u7ec3\u8303\u4f8b\u4e4b\u4e00\uff0c\u4f46\u7531\u4e8e\u5faa\u73af\u4e2d\u4ea7\u751f\u7684\u592a\u591a\u566a\u58f0\u504f\u597d\u6570\u636e\uff0c\u6027\u80fd\u4ecd\u7136\u4ee4\u4eba\u5931\u671b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u589e\u5f3a\u7684\u504f\u597d\u4f18\u5316\uff08UPO\uff09\u6846\u67b6\uff0c\u4f7f LLM \u80fd\u591f\u901a\u8fc7\u53ef\u9760\u7684\u53cd\u9988\u8fdb\u884c\u81ea\u6211\u6f14\u5316\u3002\u5173\u952e\u601d\u60f3\u662f\u901a\u8fc7\u6267\u884c\u6210\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u660e\u667a\u53ef\u9760\u7684\u53cd\u9988\u91c7\u6837\u6765\u51cf\u8f7b\u4ece\u5f53\u524d\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\u4e2d\u5f97\u51fa\u7684\u5608\u6742\u504f\u597d\u6570\u636e\u3002\u4e3a\u4e86\u8fbe\u5230\u8fd9\u4e2a\u76ee\u6807\uff0c\u6211\u4eec\u56e0\u6b64\u5f15\u5165\u4e86\u4e00\u4e2a\u4f30\u8ba1\u5668\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u8499\u7279\u5361\u7f57 (MC) dropout \u7eb3\u5165\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc (BNN) \u4e2d\uff0c\u4ee5\u5bf9\u4ece LLM \u7b56\u7565\u4e2d\u5f97\u51fa\u7684\u504f\u597d\u6570\u636e\u6267\u884c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u4e0e\u76f4\u63a5\u6839\u636e\u5956\u52b1\u5206\u6570\u8fc7\u6ee4\u751f\u6210\u54cd\u5e94\u7684\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4f30\u8ba1\u5668\u4ee5\u6210\u5bf9\u65b9\u5f0f\u5173\u6ce8\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u6709\u6548\u7ed5\u8fc7\u4e86\u5956\u52b1\u6a21\u578b\u7684\u786e\u8ba4\u504f\u5dee\u95ee\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u589e\u5f3a\u7684\u81ea\u8fdb\u5316\u7b97\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u504f\u597d\u4f18\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u9f13\u52b1 LLM \u751f\u6210\u5177\u6709\u9ad8\u5956\u52b1\u548c\u786e\u5b9a\u6027\u7684\u54cd\u5e94\u3002\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5927\u5927\u7f13\u89e3\u4e86\u566a\u58f0\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e86\u8fed\u4ee3\u504f\u597d\u4f18\u5316\u7684\u6027\u80fd\u3002", "author": "Jianing Wang et.al.", "authors": "Jianing Wang, Yang Zhou, Xiaocheng Zhang, Mengjiao Bao, Peng Yan", "id": "2409.11212v1", "paper_url": "http://arxiv.org/abs/2409.11212v1", "repo": "null"}}