{"2410.15939": {"publish_time": "2024-10-21", "title": "CausalGraph2LLM: Evaluating LLMs for Causal Queries", "paper_summary": "Causality is essential in scientific research, enabling researchers to\ninterpret true relationships between variables. These causal relationships are\noften represented by causal graphs, which are directed acyclic graphs. With the\nrecent advancements in Large Language Models (LLMs), there is an increasing\ninterest in exploring their capabilities in causal reasoning and their\npotential use to hypothesize causal graphs. These tasks necessitate the LLMs to\nencode the causal graph effectively for subsequent downstream tasks. In this\npaper, we propose a comprehensive benchmark, \\emph{CausalGraph2LLM},\nencompassing a variety of causal graph settings to assess the causal graph\nunderstanding capability of LLMs. We categorize the causal queries into two\ntypes: graph-level and node-level queries. We benchmark both open-sourced and\nclosed models for our study. Our findings reveal that while LLMs show promise\nin this domain, they are highly sensitive to the encoding used. Even capable\nmodels like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with\ndeviations of about $60\\%$. We further demonstrate this sensitivity for\ndownstream causal intervention tasks. Moreover, we observe that LLMs can often\ndisplay biases when presented with contextual information about a causal graph,\npotentially stemming from their parametric memory.", "paper_summary_zh": "\u56e0\u679c\u5173\u7cfb\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5b83\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u89e3\u91ca\u53d8\u91cf\u4e4b\u95f4\u7684\u771f\u5b9e\u5173\u7cfb\u3002\u8fd9\u4e9b\u56e0\u679c\u5173\u7cfb\u901a\u5e38\u7528\u56e0\u679c\u56fe\u8868\u793a\uff0c\u56e0\u679c\u56fe\u662f\u6709\u5411\u65e0\u73af\u56fe\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u4eba\u4eec\u8d8a\u6765\u8d8a\u6709\u5174\u8da3\u63a2\u7d22\u5b83\u4eec\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u4ee5\u53ca\u5b83\u4eec\u5728\u5047\u8bbe\u56e0\u679c\u56fe\u4e2d\u7684\u6f5c\u5728\u7528\u9014\u3002\u8fd9\u4e9b\u4efb\u52a1\u9700\u8981 LLM \u6709\u6548\u5730\u5bf9\u56e0\u679c\u56fe\u8fdb\u884c\u7f16\u7801\uff0c\u4ee5\u4fbf\u540e\u7eed\u7684\u4e0b\u6e38\u4efb\u52a1\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\uff0c\\emph{CausalGraph2LLM}\uff0c\u5b83\u5305\u542b\u4e86\u5404\u79cd\u56e0\u679c\u56fe\u8bbe\u7f6e\uff0c\u4ee5\u8bc4\u4f30 LLM \u7684\u56e0\u679c\u56fe\u7406\u89e3\u80fd\u529b\u3002\u6211\u4eec\u5c06\u56e0\u679c\u67e5\u8be2\u5206\u4e3a\u4e24\u7c7b\uff1a\u56fe\u7ea7\u67e5\u8be2\u548c\u8282\u70b9\u7ea7\u67e5\u8be2\u3002\u6211\u4eec\u5bf9\u5f00\u6e90\u6a21\u578b\u548c\u5c01\u95ed\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136 LLM \u5728\u8be5\u9886\u57df\u663e\u793a\u51fa\u524d\u666f\uff0c\u4f46\u5b83\u4eec\u5bf9\u6240\u4f7f\u7528\u7684\u7f16\u7801\u975e\u5e38\u654f\u611f\u3002\u5373\u4f7f\u50cf GPT-4 \u548c Gemini-1.5 \u8fd9\u6837\u7684\u5f3a\u5927\u6a21\u578b\u4e5f\u5bf9\u7f16\u7801\u8868\u73b0\u51fa\u654f\u611f\u6027\uff0c\u504f\u5dee\u7ea6\u4e3a 60%\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u8fd9\u79cd\u5bf9\u4e0b\u6e38\u56e0\u679c\u5e72\u9884\u4efb\u52a1\u7684\u654f\u611f\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5f53 LLM \u83b7\u5f97\u6709\u5173\u56e0\u679c\u56fe\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u65f6\uff0c\u5b83\u4eec\u901a\u5e38\u4f1a\u8868\u73b0\u51fa\u504f\u89c1\uff0c\u8fd9\u53ef\u80fd\u6e90\u4e8e\u5b83\u4eec\u7684\u53c2\u6570\u8bb0\u5fc6\u3002", "author": "Ivaxi Sheth et.al.", "authors": "Ivaxi Sheth, Bahare Fatemi, Mario Fritz", "id": "2410.15939v1", "paper_url": "http://arxiv.org/abs/2410.15939v1", "repo": "https://github.com/ivaxi0s/causalgraph2llm"}}