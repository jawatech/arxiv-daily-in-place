{"2501.14204": {"publish_time": "2025-01-24", "title": "Dynamic Token Reduction during Generation for Vision Language Models", "paper_summary": "Vision-Language Models (VLMs) have achieved notable success in multimodal\ntasks but face practical limitations due to the quadratic complexity of decoder\nattention mechanisms and autoregressive generation. Existing methods like FASTV\nand VTW have achieved notable results in reducing redundant visual tokens, but\nthese approaches focus on pruning tokens in a single forward pass without\nsystematically analyzing the redundancy of visual tokens throughout the entire\ngeneration process. In this paper, we introduce a dynamic pruning strategy\ntailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the\ncompression rate during generation. Our analysis of the distribution of\nattention reveals that the importance of visual tokens decreases throughout the\ngeneration process, inspiring us to adopt a more aggressive compression rate.\nBy integrating a lightweight predictor based on attention distribution, our\napproach enables flexible adjustment of pruning rates based on the attention\ndistribution. Our experimental results demonstrate that our method not only\nreduces computational demands but also maintains the quality of responses.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5df2\u5728\u591a\u6a21\u614b\u4efb\u52d9\u4e2d\u53d6\u5f97\u986f\u8457\u6210\u529f\uff0c\u4f46\u7531\u65bc\u89e3\u78bc\u5668\u6ce8\u610f\u529b\u6a5f\u5236\u548c\u81ea\u8ff4\u6b78\u751f\u6210\u7684\u4e8c\u6b21\u8907\u96dc\u6027\u800c\u9762\u81e8\u5be6\u969b\u9650\u5236\u3002FASTV \u548c VTW \u7b49\u73fe\u6709\u65b9\u6cd5\u5df2\u5728\u6e1b\u5c11\u591a\u9918\u8996\u89ba\u7b26\u865f\u65b9\u9762\u53d6\u5f97\u986f\u8457\u6210\u679c\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u5c08\u6ce8\u65bc\u5728\u55ae\u6b21\u524d\u5411\u50b3\u905e\u4e2d\u4fee\u526a\u7b26\u865f\uff0c\u800c\u6c92\u6709\u7cfb\u7d71\u5730\u5206\u6790\u6574\u500b\u751f\u6210\u904e\u7a0b\u4e2d\u8996\u89ba\u7b26\u865f\u7684\u5197\u9918\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u5c08\u70ba VLM \u8a2d\u8a08\u7684\u52d5\u614b\u4fee\u526a\u7b56\u7565\uff0c\u7a31\u70ba\u52d5\u614b\u901f\u7387 (DyRate)\uff0c\u5b83\u6703\u5728\u751f\u6210\u904e\u7a0b\u4e2d\u9010\u6b65\u8abf\u6574\u58d3\u7e2e\u7387\u3002\u6211\u5011\u5c0d\u6ce8\u610f\u529b\u5206\u4f48\u7684\u5206\u6790\u8868\u660e\uff0c\u8996\u89ba\u7b26\u865f\u7684\u91cd\u8981\u6027\u6703\u5728\u6574\u500b\u751f\u6210\u904e\u7a0b\u4e2d\u964d\u4f4e\uff0c\u9019\u555f\u767c\u6211\u5011\u63a1\u7528\u66f4\u6fc0\u9032\u7684\u58d3\u7e2e\u7387\u3002\u901a\u904e\u6574\u5408\u57fa\u65bc\u6ce8\u610f\u529b\u5206\u4f48\u7684\u8f15\u91cf\u7d1a\u9810\u6e2c\u5668\uff0c\u6211\u5011\u7684\u6280\u8853\u53ef\u4ee5\u6839\u64da\u6ce8\u610f\u529b\u5206\u4f48\u9748\u6d3b\u8abf\u6574\u4fee\u526a\u7387\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6280\u8853\u4e0d\u50c5\u6e1b\u5c11\u4e86\u904b\u7b97\u9700\u6c42\uff0c\u800c\u4e14\u9084\u7dad\u6301\u4e86\u56de\u61c9\u7684\u54c1\u8cea\u3002", "author": "Xiaoyu Liang et.al.", "authors": "Xiaoyu Liang, Chaofeng Guan, Jiaying Lu, Huiyao Chen, Huan Wang, Haoji Hu", "id": "2501.14204v1", "paper_url": "http://arxiv.org/abs/2501.14204v1", "repo": "null"}}