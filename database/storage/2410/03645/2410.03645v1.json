{"2410.03645": {"publish_time": "2024-10-04", "title": "GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs", "paper_summary": "Robotic simulation today remains challenging to scale up due to the human\nefforts required to create diverse simulation tasks and scenes.\nSimulation-trained policies also face scalability issues as many sim-to-real\nmethods focus on a single task. To address these challenges, this work proposes\nGenSim2, a scalable framework that leverages coding LLMs with multi-modal and\nreasoning capabilities for complex and realistic simulation task creation,\nincluding long-horizon tasks with articulated objects. To automatically\ngenerate demonstration data for these tasks at scale, we propose planning and\nRL solvers that generalize within object categories. The pipeline can generate\ndata for up to 100 articulated tasks with 200 objects and reduce the required\nhuman efforts. To utilize such data, we propose an effective multi-task\nlanguage-conditioned policy architecture, dubbed proprioceptive point-cloud\ntransformer (PPT), that learns from the generated demonstrations and exhibits\nstrong sim-to-real zero-shot transfer. Combining the proposed pipeline and the\npolicy architecture, we show a promising usage of GenSim2 that the generated\ndata can be used for zero-shot transfer or co-train with real-world collected\ndata, which enhances the policy performance by 20% compared with training\nexclusively on limited real data.", "paper_summary_zh": "\u6a5f\u5668\u4eba\u6a21\u64ec\u81f3\u4eca\u4ecd\u96e3\u4ee5\u64f4\u5c55\uff0c\u539f\u56e0\u5728\u65bc\u5275\u9020\u591a\u6a23\u5316\u7684\u6a21\u64ec\u4efb\u52d9\u548c\u5834\u666f\u9700\u8981\u5927\u91cf\u4eba\u529b\u3002\n\u7d93\u904e\u6a21\u64ec\u8a13\u7df4\u7684\u7b56\u7565\u4e5f\u9762\u81e8\u53ef\u64f4\u5c55\u6027\u554f\u984c\uff0c\u56e0\u70ba\u8a31\u591a\u6a21\u64ec\u5230\u771f\u5be6\u7684\u65b9\u6cd5\u90fd\u5c08\u6ce8\u65bc\u55ae\u4e00\u4efb\u52d9\u3002\n\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u672c\u7814\u7a76\u63d0\u51fa GenSim2\uff0c\u4e00\u500b\u53ef\u64f4\u5c55\u7684\u6846\u67b6\uff0c\u8a72\u6846\u67b6\u5229\u7528\u5177\u5099\u591a\u6a21\u614b\u548c\u63a8\u7406\u80fd\u529b\u7684\u7de8\u78bc LLM \u4f86\u9032\u884c\u8907\u96dc\u4e14\u903c\u771f\u7684\u6a21\u64ec\u4efb\u52d9\u5efa\u7acb\uff0c\u5305\u62ec\u5177\u6709\u95dc\u7bc0\u7269\u9ad4\u7684\u9577\u6642\u7a0b\u4efb\u52d9\u3002\n\u70ba\u4e86\u81ea\u52d5\u751f\u6210\u9019\u4e9b\u4efb\u52d9\u7684\u5927\u898f\u6a21\u793a\u7bc4\u8cc7\u6599\uff0c\u6211\u5011\u63d0\u51fa\u5728\u7269\u4ef6\u985e\u5225\u4e2d\u9032\u884c\u6982\u62ec\u7684\u898f\u5283\u548c RL \u6c42\u89e3\u5668\u3002\n\u8a72\u7ba1\u9053\u53ef\u4ee5\u751f\u6210\u591a\u9054 100 \u500b\u5177\u6709 200 \u500b\u7269\u4ef6\u7684\u95dc\u7bc0\u4efb\u52d9\u7684\u8cc7\u6599\uff0c\u4e26\u6e1b\u5c11\u6240\u9700\u7684\u4eba\u529b\u3002\n\u70ba\u4e86\u5229\u7528\u6b64\u985e\u8cc7\u6599\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6709\u6548\u7684\u591a\u4efb\u52d9\u8a9e\u8a00\u689d\u4ef6\u7b56\u7565\u67b6\u69cb\uff0c\u7a31\u70ba proprioceptive point-cloud transformer (PPT)\uff0c\u8a72\u67b6\u69cb\u5f9e\u751f\u6210\u7684\u793a\u7bc4\u4e2d\u5b78\u7fd2\uff0c\u4e26\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u6a21\u64ec\u5230\u771f\u5be6\u96f6\u6b21\u5b78\u7fd2\u8f49\u79fb\u3002\n\u7d50\u5408\u6240\u63d0\u51fa\u7684\u7ba1\u9053\u548c\u7b56\u7565\u67b6\u69cb\uff0c\u6211\u5011\u5c55\u793a\u4e86 GenSim2 \u7684\u4e00\u500b\u6709\u524d\u9014\u7684\u7528\u9014\uff0c\u5373\u751f\u6210\u7684\u8cc7\u6599\u53ef\u7528\u65bc\u96f6\u6b21\u5b78\u7fd2\u8f49\u79fb\u6216\u8207\u73fe\u5be6\u4e16\u754c\u6536\u96c6\u7684\u8cc7\u6599\u5171\u540c\u8a13\u7df4\uff0c\u8207\u50c5\u5728\u6709\u9650\u7684\u771f\u5be6\u8cc7\u6599\u4e0a\u9032\u884c\u8a13\u7df4\u76f8\u6bd4\uff0c\u9019\u5c07\u7b56\u7565\u6548\u80fd\u63d0\u5347\u4e86 20%\u3002", "author": "Pu Hua et.al.", "authors": "Pu Hua, Minghuan Liu, Annabella Macaluso, Yunfeng Lin, Weinan Zhang, Huazhe Xu, Lirui Wang", "id": "2410.03645v1", "paper_url": "http://arxiv.org/abs/2410.03645v1", "repo": "null"}}