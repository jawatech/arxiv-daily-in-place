{"2410.18720": {"publish_time": "2024-10-24", "title": "GeoLoRA: Geometric integration for parameter efficient fine-tuning", "paper_summary": "Low-Rank Adaptation (LoRA) has become a widely used method for\nparameter-efficient fine-tuning of large-scale, pre-trained neural networks.\nHowever, LoRA and its extensions face several challenges, including the need\nfor rank adaptivity, robustness, and computational efficiency during the\nfine-tuning process. We introduce GeoLoRA, a novel approach that addresses\nthese limitations by leveraging dynamical low-rank approximation theory.\nGeoLoRA requires only a single backpropagation pass over the small-rank\nadapters, significantly reducing computational cost as compared to similar\ndynamical low-rank training methods and making it faster than popular baselines\nsuch as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated\nparameter budget across the model, achieving smaller low-rank adapters compared\nto heuristic methods like AdaLoRA and LoRA, while maintaining critical\nconvergence, descent, and error-bound theoretical guarantees. The resulting\nmethod is not only more efficient but also more robust to varying\nhyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several\nstate-of-the-art benchmarks, showing that it outperforms existing methods in\nboth accuracy and computational efficiency.", "paper_summary_zh": "\u4f4e\u79e9\u9069\u61c9 (LoRA) \u5df2\u6210\u70ba\u7528\u65bc\u5927\u898f\u6a21\u9810\u5148\u8a13\u7df4\u795e\u7d93\u7db2\u8def\u53c3\u6578\u6709\u6548\u5fae\u8abf\u7684\u5ee3\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0cLoRA \u53ca\u5176\u64f4\u5145\u9762\u81e8\u6578\u9805\u6311\u6230\uff0c\u5305\u62ec\u5728\u5fae\u8abf\u904e\u7a0b\u4e2d\u9700\u8981\u79e9\u9069\u61c9\u6027\u3001\u7a69\u5065\u6027\u548c\u904b\u7b97\u6548\u7387\u3002\u6211\u5011\u5f15\u5165 GeoLoRA\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u900f\u904e\u5229\u7528\u52d5\u614b\u4f4e\u79e9\u8fd1\u4f3c\u7406\u8ad6\u4f86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\u3002\u8207\u985e\u4f3c\u7684\u52d5\u614b\u4f4e\u79e9\u8a13\u7df4\u65b9\u6cd5\u76f8\u6bd4\uff0cGeoLoRA \u53ea\u9700\u8981\u4e00\u6b21\u53cd\u5411\u50b3\u64ad\u901a\u904e\u5c0f\u79e9\u9069\u914d\u5668\uff0c\u5927\u5e45\u964d\u4f4e\u904b\u7b97\u6210\u672c\uff0c\u4e26\u4f7f\u5176\u6bd4 AdaLoRA \u7b49\u71b1\u9580\u57fa\u6e96\u66f4\u5feb\u3002\u9019\u8b93 GeoLoRA \u80fd\u6709\u6548\u8abf\u6574\u6a21\u578b\u4e2d\u5206\u914d\u7684\u53c3\u6578\u9810\u7b97\uff0c\u8207 AdaLoRA \u548c LoRA \u7b49\u555f\u767c\u5f0f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u9054\u6210\u66f4\u5c0f\u7684\u4f4e\u79e9\u9069\u914d\u5668\uff0c\u540c\u6642\u7dad\u6301\u81e8\u754c\u7684\u6536\u6582\u3001\u4e0b\u964d\u548c\u8aa4\u5dee\u7d04\u675f\u7406\u8ad6\u4fdd\u8b49\u3002\u7522\u751f\u7684\u65b9\u6cd5\u4e0d\u50c5\u66f4\u6709\u6548\u7387\uff0c\u4e5f\u66f4\u80fd\u627f\u53d7\u4e0d\u540c\u7684\u8d85\u53c3\u6578\u8a2d\u5b9a\u3002\u6211\u5011\u5728\u6578\u500b\u6700\u5148\u9032\u7684\u57fa\u6e96\u4e0a\u5c55\u793a GeoLoRA \u7684\u6548\u80fd\uff0c\u986f\u793a\u51fa\u5b83\u5728\u6e96\u78ba\u6027\u548c\u904b\u7b97\u6548\u7387\u65b9\u9762\u90fd\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002", "author": "Steffen Schotth\u00f6fer et.al.", "authors": "Steffen Schotth\u00f6fer, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco, Jonas Kusch", "id": "2410.18720v1", "paper_url": "http://arxiv.org/abs/2410.18720v1", "repo": "null"}}