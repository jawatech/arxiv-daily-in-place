{"2501.05336": {"publish_time": "2025-01-09", "title": "Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction", "paper_summary": "The rapid advancement of large language models (LLMs) has led to significant\nimprovements in their capabilities, but also to increased concerns about their\nalignment with human values and intentions. Current alignment strategies,\nincluding adaptive training and inference-time methods, have demonstrated\npotential in this area. However, these approaches still struggle to balance\ndeployment complexity and capability across various tasks and difficulties. In\nthis work, we introduce the Streaming Distribution Induce Aligner (Stream\nAligner), a novel alignment paradigm that combines efficiency with enhanced\nperformance in various tasks throughout the generation process. Stream Aligner\nachieves dynamic sentence-level correction by using a small model to learn the\npreferences of the suffix sentence, iteratively correcting the suffix sentence\noutput by the upstream model, and then using the corrected sentence to replace\nthe suffix sentence in subsequent generations. Compared to Aligner, our\nexperiments demonstrate that Stream Aligner reduces reliance on the\ncapabilities of additional models, enhances the reasoning abilities of LLMs,\nand decreases latency during user interaction. Specifically, Stream Aligner-2B\nmodel has achieved an improvement of 76.1% in helpfulness, 36.0% in\nharmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has\nachieved an improvement of 3.5% on the math ability of the tested\nLlama3-70B-Instruct model.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u5c55\u5df2\u986f\u8457\u63d0\u5347\u5176\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u767c\u66f4\u591a\u95dc\u65bc\u5176\u8207\u4eba\u985e\u50f9\u503c\u89c0\u548c\u610f\u5716\u4e00\u81f4\u6027\u7684\u7591\u616e\u3002\u76ee\u524d\u7684\u5c0d\u9f4a\u7b56\u7565\uff0c\u5305\u62ec\u9069\u61c9\u6027\u8a13\u7df4\u548c\u63a8\u8ad6\u6642\u9593\u65b9\u6cd5\uff0c\u5df2\u5728\u6b64\u9818\u57df\u5c55\u73fe\u6f5b\u529b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u4ecd\u96e3\u4ee5\u5728\u5404\u7a2e\u4efb\u52d9\u548c\u96e3\u5ea6\u4e2d\u53d6\u5f97\u90e8\u7f72\u8907\u96dc\u5ea6\u548c\u80fd\u529b\u7684\u5e73\u8861\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e32\u6d41\u5206\u4f48\u8a98\u5c0e\u5c0d\u9f4a\u5668 (Stream Aligner)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u5c0d\u9f4a\u7bc4\u4f8b\uff0c\u7d50\u5408\u4e86\u6548\u7387\u8207\u5728\u6574\u500b\u751f\u6210\u904e\u7a0b\u4e2d\u5404\u7a2e\u4efb\u52d9\u4e2d\u589e\u5f37\u7684\u6548\u80fd\u3002Stream Aligner \u900f\u904e\u4f7f\u7528\u5c0f\u578b\u6a21\u578b\u4f86\u5b78\u7fd2\u5f8c\u7db4\u53e5\u5b50\u7684\u504f\u597d\uff0c\u53cd\u8986\u4fee\u6b63\u4e0a\u6e38\u6a21\u578b\u8f38\u51fa\u7684\u5f8c\u7db4\u53e5\u5b50\uff0c\u7136\u5f8c\u4f7f\u7528\u4fee\u6b63\u904e\u7684\u53e5\u5b50\u53d6\u4ee3\u5f8c\u7e8c\u751f\u6210\u4e2d\u7684\u5f8c\u7db4\u53e5\u5b50\uff0c\u9032\u800c\u9054\u6210\u52d5\u614b\u7684\u53e5\u5b50\u5c64\u7d1a\u4fee\u6b63\u3002\u8207 Aligner \u76f8\u6bd4\uff0c\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e Stream Aligner \u6e1b\u5c11\u4e86\u5c0d\u5176\u4ed6\u6a21\u578b\u80fd\u529b\u7684\u4f9d\u8cf4\uff0c\u589e\u5f37\u4e86 LLM \u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e26\u964d\u4f4e\u4e86\u4f7f\u7528\u8005\u4e92\u52d5\u671f\u9593\u7684\u5ef6\u9072\u3002\u5177\u9ad4\u800c\u8a00\uff0cStream Aligner-2B \u6a21\u578b\u5728\u6709\u76ca\u6027\u65b9\u9762\u63d0\u5347\u4e86 76.1%\uff0c\u5728\u7121\u5bb3\u6027\u65b9\u9762\u63d0\u5347\u4e86 36.0%\uff0c\u5728\u6e2c\u8a66\u7684 Llama2-70B-chat \u6a21\u578b\u4e0a\uff0c\u800c Stream Aligner-8B \u5247\u5728\u6e2c\u8a66\u7684 Llama3-70B-Instruct \u6a21\u578b\u7684\u6578\u5b78\u80fd\u529b\u65b9\u9762\u63d0\u5347\u4e86 3.5%\u3002", "author": "Hantao Lou et.al.", "authors": "Hantao Lou, Jiaming Ji, Kaile Wang, Yaodong Yang", "id": "2501.05336v1", "paper_url": "http://arxiv.org/abs/2501.05336v1", "repo": "null"}}