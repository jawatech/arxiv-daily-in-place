{"2407.14482": {"publish_time": "2024-07-19", "title": "ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities", "paper_summary": "In this work, we introduce ChatQA 2, a Llama3-based model designed to bridge\nthe gap between open-access LLMs and leading proprietary models (e.g.,\nGPT-4-Turbo) in long-context understanding and retrieval-augmented generation\n(RAG) capabilities. These two capabilities are essential for LLMs to process\nlarge volumes of information that cannot fit into a single prompt and are\ncomplementary to each other, depending on the downstream tasks and\ncomputational budgets. We present a detailed continued training recipe to\nextend the context window of Llama3-70B-base from 8K to 128K tokens, along with\na three-stage instruction tuning process to enhance the model's\ninstruction-following, RAG performance, and long-context understanding\ncapabilities. Our results demonstrate that the Llama3-ChatQA-2-70B model\nachieves accuracy comparable to GPT-4-Turbo-2024-0409 on many long-context\nunderstanding tasks and surpasses it on the RAG benchmark. Interestingly, we\nfind that the state-of-the-art long-context retriever can alleviate the top-k\ncontext fragmentation issue in RAG, further improving RAG-based results for\nlong-context understanding tasks. We also provide extensive comparisons between\nRAG and long-context solutions using state-of-the-art long-context LLMs.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 ChatQA 2\uff0c\u4e00\u7a2e\u57fa\u65bc Llama3 \u7684\u6a21\u578b\uff0c\u65e8\u5728\u5f4c\u5408\u958b\u653e\u5f0f LLM \u548c\u9818\u5148\u7684\u5c08\u6709\u6a21\u578b\uff08\u4f8b\u5982 GPT-4-Turbo\uff09\u5728\u9577\u671f\u8a9e\u5883\u7406\u89e3\u548c\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u80fd\u529b\u65b9\u9762\u7684\u5dee\u8ddd\u3002\u9019\u5169\u7a2e\u80fd\u529b\u5c0d\u65bc LLM \u8655\u7406\u5927\u91cf\u7121\u6cd5\u653e\u5165\u55ae\u4e00\u63d0\u793a\u4e2d\u7684\u8cc7\u8a0a\u81f3\u95dc\u91cd\u8981\uff0c\u4e26\u4e14\u6839\u64da\u4e0b\u6e38\u4efb\u52d9\u548c\u8a08\u7b97\u9810\u7b97\uff0c\u5b83\u5011\u662f\u4e92\u88dc\u7684\u3002\u6211\u5011\u63d0\u51fa\u4e86\u8a73\u7d30\u7684\u6301\u7e8c\u8a13\u7df4\u914d\u65b9\uff0c\u5c07 Llama3-70B-base \u7684\u8a9e\u5883\u8996\u7a97\u5f9e 8K \u64f4\u5c55\u5230 128K \u500b token\uff0c\u4e26\u63a1\u7528\u4e09\u968e\u6bb5\u6307\u4ee4\u8abf\u6574\u6d41\u7a0b\u4f86\u589e\u5f37\u6a21\u578b\u7684\u6307\u4ee4\u9075\u5faa\u3001RAG \u6548\u80fd\u548c\u9577\u671f\u8a9e\u5883\u7406\u89e3\u80fd\u529b\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cLlama3-ChatQA-2-70B \u6a21\u578b\u5728\u8a31\u591a\u9577\u671f\u8a9e\u5883\u7406\u89e3\u4efb\u52d9\u4e0a\u9054\u5230\u4e86\u8207 GPT-4-Turbo-2024-0409 \u76f8\u7576\u7684\u6e96\u78ba\u5ea6\uff0c\u4e26\u4e14\u5728 RAG \u57fa\u6e96\u4e0a\u8d85\u8d8a\u4e86\u5b83\u3002\u6709\u8da3\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u6700\u5148\u9032\u7684\u9577\u671f\u8a9e\u5883\u6aa2\u7d22\u5668\u53ef\u4ee5\u7de9\u89e3 RAG \u4e2d\u7684 top-k \u8a9e\u5883\u788e\u7247\u5316\u554f\u984c\uff0c\u9032\u4e00\u6b65\u6539\u5584\u4e86\u57fa\u65bc RAG \u7684\u9577\u671f\u8a9e\u5883\u7406\u89e3\u4efb\u52d9\u7684\u7d50\u679c\u3002\u6211\u5011\u9084\u63d0\u4f9b\u4e86\u4f7f\u7528\u6700\u5148\u9032\u7684\u9577\u671f\u8a9e\u5883 LLM\uff0c\u5728 RAG \u548c\u9577\u671f\u8a9e\u5883\u89e3\u6c7a\u65b9\u6848\u4e4b\u9593\u9032\u884c\u5ee3\u6cdb\u7684\u6bd4\u8f03\u3002", "author": "Peng Xu et.al.", "authors": "Peng Xu, Wei Ping, Xianchao Wu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro", "id": "2407.14482v1", "paper_url": "http://arxiv.org/abs/2407.14482v1", "repo": "null"}}