{"2501.11597": {"publish_time": "2025-01-20", "title": "Fairness Testing through Extreme Value Theory", "paper_summary": "Data-driven software is increasingly being used as a critical component of\nautomated decision-support systems. Since this class of software learns its\nlogic from historical data, it can encode or amplify discriminatory practices.\nPrevious research on algorithmic fairness has focused on improving average-case\nfairness. On the other hand, fairness at the extreme ends of the spectrum,\nwhich often signifies lasting and impactful shifts in societal attitudes, has\nreceived significantly less emphasis.\n  Leveraging the statistics of extreme value theory (EVT), we propose a novel\nfairness criterion called extreme counterfactual discrimination (ECD). This\ncriterion estimates the worst-case amounts of disadvantage in outcomes for\nindividuals solely based on their memberships in a protected group. Utilizing\ntools from search-based software engineering and generative AI, we present a\nrandomized algorithm that samples a statistically significant set of points\nfrom the tail of ML outcome distributions even if the input dataset lacks a\nsufficient number of relevant samples.\n  We conducted several experiments on four ML models (deep neural networks,\nlogistic regression, and random forests) over 10 socially relevant tasks from\nthe literature on algorithmic fairness. First, we evaluate the generative AI\nmethods and find that they generate sufficient samples to infer valid EVT\ndistribution in 95% of cases. Remarkably, we found that the prevalent bias\nmitigators reduce the average-case discrimination but increase the worst-case\ndiscrimination significantly in 5% of cases. We also observed that even the\ntail-aware mitigation algorithm -- MiniMax-Fairness -- increased the worst-case\ndiscrimination in 30% of cases. We propose a novel ECD-based mitigator that\nimproves fairness in the tail in 90% of cases with no degradation of the\naverage-case discrimination.", "paper_summary_zh": "<paragraph>\u8cc7\u6599\u9a45\u52d5\u8edf\u9ad4\u6b63\u65e5\u76ca\u88ab\u7528\u4f5c\u81ea\u52d5\u5316\u6c7a\u7b56\u652f\u63f4\u7cfb\u7d71\u7684\u91cd\u8981\u7d44\u6210\u90e8\u5206\u3002\u7531\u65bc\u6b64\u985e\u8edf\u9ad4\u5f9e\u6b77\u53f2\u8cc7\u6599\u4e2d\u5b78\u7fd2\u5176\u908f\u8f2f\uff0c\u56e0\u6b64\u5b83\u53ef\u4ee5\u7de8\u78bc\u6216\u64f4\u5927\u6b67\u8996\u6027\u505a\u6cd5\u3002\u5148\u524d\u91dd\u5c0d\u6f14\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u7814\u7a76\u8457\u91cd\u65bc\u6539\u5584\u5e73\u5747\u72c0\u6cc1\u516c\u5e73\u6027\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5149\u8b5c\u5169\u6975\u7684\u516c\u5e73\u6027\uff0c\u901a\u5e38\u8868\u793a\u793e\u6703\u614b\u5ea6\u6301\u4e45\u4e14\u6709\u5f71\u97ff\u529b\u7684\u8f49\u8b8a\uff0c\u53d7\u5230\u7684\u91cd\u8996\u537b\u660e\u986f\u8f03\u5c11\u3002\n  \u5229\u7528\u6975\u503c\u7406\u8ad6 (EVT) \u7684\u7d71\u8a08\u8cc7\u6599\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u9805\u540d\u70ba\u6975\u7aef\u53cd\u4e8b\u5be6\u6b67\u8996 (ECD) \u7684\u65b0\u516c\u5e73\u6027\u6e96\u5247\u3002\u6b64\u6e96\u5247\u4f30\u8a08\u500b\u4eba\u50c5\u57fa\u65bc\u5176\u53d7\u4fdd\u8b77\u7fa4\u7d44\u7684\u6210\u54e1\u8eab\u4efd\u800c\u7522\u751f\u7684\u6700\u5dee\u60c5\u6cc1\u7d50\u679c\u52a3\u52e2\u91cf\u3002\u5229\u7528\u4f86\u81ea\u57fa\u65bc\u641c\u5c0b\u7684\u8edf\u9ad4\u5de5\u7a0b\u548c\u751f\u6210\u5f0f AI \u7684\u5de5\u5177\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u96a8\u6a5f\u6f14\u7b97\u6cd5\uff0c\u5373\u4f7f\u8f38\u5165\u8cc7\u6599\u96c6\u7f3a\u4e4f\u8db3\u5920\u6578\u91cf\u7684\u76f8\u95dc\u6a23\u672c\uff0c\u4e5f\u80fd\u5f9e ML \u7d50\u679c\u5206\u4f48\u7684\u5c3e\u7aef\u62bd\u53d6\u4e00\u7d44\u5177\u6709\u7d71\u8a08\u986f\u8457\u6027\u7684\u9ede\u3002\n  \u6211\u5011\u91dd\u5c0d\u4f86\u81ea\u6f14\u7b97\u6cd5\u516c\u5e73\u6027\u6587\u737b\u4e2d\u7684 10 \u9805\u793e\u6703\u76f8\u95dc\u4efb\u52d9\uff0c\u5c0d\u56db\u500b ML \u6a21\u578b\uff08\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u3001\u908f\u8f2f\u8ff4\u6b78\u548c\u96a8\u6a5f\u68ee\u6797\uff09\u9032\u884c\u4e86\u591a\u9805\u5be6\u9a57\u3002\u9996\u5148\uff0c\u6211\u5011\u8a55\u4f30\u751f\u6210\u5f0f AI \u65b9\u6cd5\uff0c\u4e26\u767c\u73fe\u5b83\u5011\u7522\u751f\u4e86\u8db3\u5920\u7684\u6a23\u672c\uff0c\u53ef\u4ee5\u5728 95% \u7684\u6848\u4f8b\u4e2d\u63a8\u65b7\u51fa\u6709\u6548\u7684 EVT \u5206\u4f48\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u666e\u904d\u7684\u504f\u898b\u7de9\u89e3\u5668\u6703\u964d\u4f4e\u5e73\u5747\u72c0\u6cc1\u6b67\u8996\uff0c\u4f46\u5728 5% \u7684\u6848\u4f8b\u4e2d\u986f\u8457\u589e\u52a0\u4e86\u6700\u5dee\u60c5\u6cc1\u6b67\u8996\u3002\u6211\u5011\u9084\u89c0\u5bdf\u5230\uff0c\u5373\u4f7f\u662f\u5c3e\u7aef\u611f\u77e5\u7de9\u89e3\u6f14\u7b97\u6cd5\u2014\u2014MiniMax-Fairness\u2014\u2014\u5728 30% \u7684\u6848\u4f8b\u4e2d\u4e5f\u589e\u52a0\u4e86\u6700\u5dee\u60c5\u6cc1\u6b67\u8996\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u57fa\u65bc ECD \u7684\u7de9\u89e3\u5668\uff0c\u5b83\u5728 90% \u7684\u6848\u4f8b\u4e2d\u6539\u5584\u4e86\u5c3e\u7aef\u7684\u516c\u5e73\u6027\uff0c\u800c\u4e0d\u6703\u964d\u4f4e\u5e73\u5747\u72c0\u6cc1\u6b67\u8996\u3002</paragraph>", "author": "Verya Monjezi et.al.", "authors": "Verya Monjezi, Ashutosh Trivedi, Vladik Kreinovich, Saeid Tizpaz-Niari", "id": "2501.11597v1", "paper_url": "http://arxiv.org/abs/2501.11597v1", "repo": "null"}}