{"2502.10118": {"publish_time": "2025-02-14", "title": "Image Embedding Sampling Method for Diverse Captioning", "paper_summary": "Image Captioning for state-of-the-art VLMs has significantly improved over\ntime; however, this comes at the cost of increased computational complexity,\nmaking them less accessible for resource-constrained applications such as\nmobile devices and assistive technologies. Alternatively, smaller VLMs\nprioritize high-level scene descriptions, overlooking finer details that\ncontribute to a richer understanding of an image. In this paper, we introduce a\ntraining-free framework that enhances caption diversity and informativeness by\nexplicitly attending to distinct image regions using a comparably small VLM,\nBLIP, as the backbone. Our approach leverages structured segmentation to\nproduce hierarchical representations that capture both global and localized\nsemantics. Without requiring additional model training, we demonstrate that our\nmethod allows smaller VLMs to achieve performance comparable to larger models\nin terms of image-caption alignment, semantic integrity, and diversity. We\nevaluate our framework on MSCOCO, Flickr30k, and Nocaps test datasets,\nachieving a Div-2 score of 0.735, 0.750, and 0.748 for each dataset\nrespectively, while maintaining strong image-caption relevancy and semantic\nintegrity with the human-annotated captions.", "paper_summary_zh": "<paragraph>\u6700\u5148\u9032\u7684 VLM \u7684\u5f71\u50cf\u6a19\u984c\u5728\u4e00\u6bb5\u6642\u9593\u4ee5\u4f86\u5df2\u5927\u5e45\u6539\u5584\uff1b\u7136\u800c\uff0c\u9019\u662f\u4ee5\u589e\u52a0\u904b\u7b97\u8907\u96dc\u5ea6\u70ba\u4ee3\u50f9\uff0c\u9019\u4f7f\u5f97\u5b83\u5011\u5c0d\u65bc\u8cc7\u6e90\u53d7\u9650\u7684\u61c9\u7528\u7a0b\u5f0f\uff08\u4f8b\u5982\u884c\u52d5\u88dd\u7f6e\u548c\u8f14\u52a9\u6280\u8853\uff09\u8f03\u96e3\u4f7f\u7528\u3002\u6216\u8005\uff0c\u8f03\u5c0f\u7684 VLM \u512a\u5148\u8003\u91cf\u9ad8\u968e\u5834\u666f\u63cf\u8ff0\uff0c\u5ffd\u7565\u6709\u52a9\u65bc\u66f4\u8c50\u5bcc\u5730\u4e86\u89e3\u5f71\u50cf\u7684\u8f03\u7cbe\u7d30\u7d30\u7bc0\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e00\u500b\u7121\u9700\u8a13\u7df4\u7684\u67b6\u69cb\uff0c\u900f\u904e\u660e\u78ba\u95dc\u6ce8\u4e0d\u540c\u7684\u5f71\u50cf\u5340\u57df\uff0c\u4f7f\u7528\u8f03\u5c0f\u7684 VLM\uff0cBLIP\uff0c\u4f5c\u70ba\u4e3b\u5e79\uff0c\u4f86\u63d0\u5347\u6a19\u984c\u7684\u591a\u6a23\u6027\u548c\u8cc7\u8a0a\u6027\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u7d50\u69cb\u5316\u5206\u5272\u7522\u751f\u968e\u5c64\u5f0f\u8868\u793a\uff0c\u6355\u6349\u5168\u5c40\u548c\u5c40\u90e8\u8a9e\u610f\u3002\u5728\u4e0d\u9700\u8981\u984d\u5916\u6a21\u578b\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\uff0c\u6211\u5011\u8b49\u660e\u6211\u5011\u7684\u505a\u6cd5\u8b93\u8f03\u5c0f\u7684 VLM \u80fd\u5920\u5728\u5f71\u50cf\u6a19\u984c\u5c0d\u9f4a\u3001\u8a9e\u610f\u5b8c\u6574\u6027\u548c\u591a\u6a23\u6027\u65b9\u9762\uff0c\u9054\u5230\u8207\u8f03\u5927\u6a21\u578b\u76f8\u7576\u7684\u6548\u80fd\u3002\u6211\u5011\u5728 MSCOCO\u3001Flickr30k \u548c Nocaps \u6e2c\u8a66\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u6211\u5011\u7684\u67b6\u69cb\uff0c\u5206\u5225\u70ba\u6bcf\u500b\u8cc7\u6599\u96c6\u9054\u5230 0.735\u30010.750 \u548c 0.748 \u7684 Div-2 \u5206\u6578\uff0c\u540c\u6642\u7dad\u6301\u8207\u4eba\u5de5\u6a19\u8a3b\u7684\u6a19\u984c\u4e4b\u9593\u5f37\u5927\u7684\u5f71\u50cf\u6a19\u984c\u76f8\u95dc\u6027\u548c\u8a9e\u610f\u5b8c\u6574\u6027\u3002</paragraph>", "author": "Sania Waheed et.al.", "authors": "Sania Waheed, Na Min An", "id": "2502.10118v1", "paper_url": "http://arxiv.org/abs/2502.10118v1", "repo": "null"}}