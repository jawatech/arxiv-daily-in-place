{"2410.04884": {"publish_time": "2024-10-07", "title": "Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models", "paper_summary": "Visual language pre-training (VLP) models have demonstrated significant\nsuccess across various domains, yet they remain vulnerable to adversarial\nattacks. Addressing these adversarial vulnerabilities is crucial for enhancing\nsecurity in multimodal learning. Traditionally, adversarial methods targeting\nVLP models involve simultaneously perturbing images and text. However, this\napproach faces notable challenges: first, adversarial perturbations often fail\nto translate effectively into real-world scenarios; second, direct\nmodifications to the text are conspicuously visible. To overcome these\nlimitations, we propose a novel strategy that exclusively employs image patches\nfor attacks, thus preserving the integrity of the original text. Our method\nleverages prior knowledge from diffusion models to enhance the authenticity and\nnaturalness of the perturbations. Moreover, to optimize patch placement and\nimprove the efficacy of our attacks, we utilize the cross-attention mechanism,\nwhich encapsulates intermodal interactions by generating attention maps to\nguide strategic patch placements. Comprehensive experiments conducted in a\nwhite-box setting for image-to-text scenarios reveal that our proposed method\nsignificantly outperforms existing techniques, achieving a 100% attack success\nrate. Additionally, it demonstrates commendable performance in transfer tasks\ninvolving text-to-image configurations.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u9810\u8a13\u7df4 (VLP) \u6a21\u578b\u5728\u5404\u7a2e\u9818\u57df\u4e2d\u5c55\u73fe\u986f\u8457\u7684\u6210\u529f\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\u3002\u8655\u7406\u9019\u4e9b\u5c0d\u6297\u6027\u6f0f\u6d1e\u5c0d\u65bc\u589e\u5f37\u591a\u6a21\u614b\u5b78\u7fd2\u4e2d\u7684\u5b89\u5168\u6027\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u4e0a\uff0c\u91dd\u5c0d VLP \u6a21\u578b\u7684\u5c0d\u6297\u6027\u65b9\u6cd5\u5305\u62ec\u540c\u6642\u64fe\u52d5\u5f71\u50cf\u548c\u6587\u5b57\u3002\u7136\u800c\uff0c\u9019\u7a2e\u65b9\u6cd5\u9762\u81e8\u986f\u8457\u7684\u6311\u6230\uff1a\u9996\u5148\uff0c\u5c0d\u6297\u6027\u64fe\u52d5\u901a\u5e38\u7121\u6cd5\u6709\u6548\u8f49\u63db\u6210\u771f\u5be6\u4e16\u754c\u7684\u5834\u666f\uff1b\u5176\u6b21\uff0c\u5c0d\u6587\u5b57\u7684\u76f4\u63a5\u4fee\u6539\u986f\u800c\u6613\u898b\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u5c08\u9580\u4f7f\u7528\u5f71\u50cf\u8cbc\u7247\u9032\u884c\u653b\u64ca\uff0c\u5f9e\u800c\u4fdd\u7559\u539f\u59cb\u6587\u5b57\u7684\u5b8c\u6574\u6027\u3002\u6211\u5011\u7684\u6a21\u578b\u5229\u7528\u64f4\u6563\u6a21\u578b\u4e2d\u7684\u5148\u9a57\u77e5\u8b58\u4f86\u589e\u5f37\u64fe\u52d5\u7684\u771f\u5be6\u6027\u548c\u81ea\u7136\u6027\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u512a\u5316\u8cbc\u7247\u653e\u7f6e\u4e26\u63d0\u9ad8\u653b\u64ca\u7684\u6548\u80fd\uff0c\u6211\u5011\u5229\u7528\u8de8\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u900f\u904e\u7522\u751f\u6ce8\u610f\u529b\u5716\u4f86\u5f15\u5c0e\u7b56\u7565\u6027\u8cbc\u7247\u653e\u7f6e\uff0c\u5f9e\u800c\u5c01\u88dd\u8de8\u6a21\u614b\u4e92\u52d5\u3002\u5728\u5f71\u50cf\u5230\u6587\u5b57\u5834\u666f\u7684\u767d\u76d2\u8a2d\u5b9a\u4e2d\u9032\u884c\u7684\u5168\u9762\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u660e\u986f\u512a\u65bc\u73fe\u6709\u6280\u8853\uff0c\u9054\u5230 100% \u7684\u653b\u64ca\u6210\u529f\u7387\u3002\u6b64\u5916\uff0c\u5b83\u5728\u6d89\u53ca\u6587\u5b57\u5230\u5f71\u50cf\u914d\u7f6e\u7684\u8f49\u79fb\u4efb\u52d9\u4e2d\u5c55\u793a\u4e86\u503c\u5f97\u7a31\u9053\u7684\u6548\u80fd\u3002", "author": "Dehong Kong et.al.", "authors": "Dehong Kong, Siyuan Liang, Xiaopeng Zhu, Yuansheng Zhong, Wenqi Ren", "id": "2410.04884v1", "paper_url": "http://arxiv.org/abs/2410.04884v1", "repo": "null"}}