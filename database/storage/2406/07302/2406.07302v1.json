{"2406.07302": {"publish_time": "2024-06-11", "title": "BertaQA: How Much Do Language Models Know About Local Culture?", "paper_summary": "Large Language Models (LLMs) exhibit extensive knowledge about the world, but\nmost evaluations have been limited to global or anglocentric subjects. This\nraises the question of how well these models perform on topics relevant to\nother cultures, whose presence on the web is not that prominent. To address\nthis gap, we introduce BertaQA, a multiple-choice trivia dataset that is\nparallel in English and Basque. The dataset consists of a local subset with\nquestions pertinent to the Basque culture, and a global subset with questions\nof broader interest. We find that state-of-the-art LLMs struggle with local\ncultural knowledge, even as they excel on global topics. However, we show that\ncontinued pre-training in Basque significantly improves the models' performance\non Basque culture, even when queried in English. To our knowledge, this is the\nfirst solid evidence of knowledge transfer from a low-resource to a\nhigh-resource language. Our analysis sheds light on the complex interplay\nbetween language and knowledge, and reveals that some prior findings do not\nfully hold when reassessed on local topics. Our dataset and evaluation code are\navailable under open licenses at https://github.com/juletx/BertaQA.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u793a\u4e86\u5c0d\u4e16\u754c\u7684\u5ee3\u6cdb\u77e5\u8b58\uff0c\u4f46\n\u5927\u591a\u6578\u8a55\u4f30\u50c5\u9650\u65bc\u5168\u7403\u6216\u4ee5\u76ce\u683c\u9b6f\u70ba\u4e2d\u5fc3\u7684\u79d1\u76ee\u3002\u9019\n\u5f15\u767c\u4e86\u4e00\u500b\u554f\u984c\uff0c\u5373\u9019\u4e9b\u6a21\u578b\u5c0d\u8207\n\u5176\u4ed6\u6587\u5316\u76f8\u95dc\u7684\u4e3b\u984c\u7684\u8868\u73fe\u5982\u4f55\uff0c\u800c\u9019\u4e9b\u6587\u5316\u5728\u7db2\u8def\u4e0a\u7684\u5b58\u5728\u4e26\u4e0d\u90a3\u9ebc\u7a81\u51fa\u3002\u70ba\u4e86\u89e3\u6c7a\n\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 BertaQA\uff0c\u9019\u662f\u4e00\u500b\u591a\u9078\u984c\u7463\u4e8b\u8cc7\u6599\u96c6\uff0c\n\u5b83\u5728\u82f1\u8a9e\u548c\u5df4\u65af\u514b\u8a9e\u4e2d\u662f\u5e73\u884c\u7684\u3002\u8a72\u8cc7\u6599\u96c6\u5305\u542b\u4e00\u500b\u672c\u5730\u5b50\u96c6\uff0c\u5176\u4e2d\u5305\u542b\n\u8207\u5df4\u65af\u514b\u6587\u5316\u76f8\u95dc\u7684\u554f\u984c\uff0c\u4ee5\u53ca\u4e00\u500b\u5168\u7403\u5b50\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u66f4\u5ee3\u6cdb\u7684\u554f\u984c\n\u8208\u8da3\u3002\u6211\u5011\u767c\u73fe\uff0c\u5373\u4f7f\u5728\u5168\u7403\u4e3b\u984c\u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u6700\u5148\u9032\u7684 LLM \u4e5f\u96e3\u4ee5\u61c9\u5c0d\u7576\u5730\n\u6587\u5316\u77e5\u8b58\u3002\u7136\u800c\uff0c\u6211\u5011\u8868\u660e\uff0c\u5728\u5df4\u65af\u514b\u8a9e\u4e2d\u6301\u7e8c\u9810\u8a13\u7df4\u986f\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8868\u73fe\n\u5df4\u65af\u514b\u6587\u5316\uff0c\u5373\u4f7f\u7528\u82f1\u8a9e\u67e5\u8a62\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u77e5\u8b58\u8f49\u79fb\u7684\u7b2c\u4e00\u6b21\u78ba\u947f\u8b49\u64da\n\u5f9e\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u5230\u9ad8\u8cc7\u6e90\u8a9e\u8a00\u3002\u6211\u5011\u7684\u5206\u6790\u63ed\u793a\u4e86\u8a9e\u8a00\u548c\u77e5\u8b58\u4e4b\u9593\u7684\u8907\u96dc\u76f8\u4e92\u4f5c\u7528\uff0c\n\u4e26\u63ed\u793a\u4e86\u4e00\u4e9b\u5148\u524d\u7684\u767c\u73fe\u4e26\u672a\n\u5728\u91cd\u65b0\u8a55\u4f30\u7576\u5730\u4e3b\u984c\u6642\u5b8c\u5168\u6210\u7acb\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u8a55\u4f30\u7a0b\u5f0f\u78bc\u53ef\u5728\nhttps://github.com/juletx/BertaQA \u4e0b\u7684\u958b\u653e\u8a31\u53ef\u4e0b\u7372\u5f97\u3002", "author": "Julen Etxaniz et.al.", "authors": "Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe", "id": "2406.07302v1", "paper_url": "http://arxiv.org/abs/2406.07302v1", "repo": "https://github.com/juletx/bertaqa"}}