{"2407.08937": {"publish_time": "2024-07-12", "title": "Self-Evolving GPT: A Lifelong Autonomous Experiential Learner", "paper_summary": "To improve the performance of large language models (LLMs), researchers have\nexplored providing LLMs with textual task-solving experience via prompts.\nHowever, they rely on manual efforts to acquire and apply such experience for\neach task, which is not feasible for the growing demand for LLMs and the\nvariety of user questions. To address this issue, we design a lifelong\nautonomous experiential learning framework based on LLMs to explore whether\nLLMs can imitate human ability for learning and utilizing experience. It\nautonomously learns and accumulates experience through experience transfer and\ninduction, categorizing the types of input questions to select which\naccumulated experience to employ for them. Experimental results on six widely\nused NLP datasets show that our framework performs reliably in each\nintermediate step and effectively improves the performance of GPT-3.5 and\nGPT-4. This validates the feasibility of using LLMs to mimic human experiential\nlearning and application capabilities. Additionally, we provide a detailed\nanalysis of the behavior of our framework at each step.", "paper_summary_zh": "\u70ba\u4e86\u63d0\u5347\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6548\u80fd\uff0c\u7814\u7a76\u4eba\u54e1\u5df2\u63a2\u8a0e\u900f\u904e\u63d0\u793a\u63d0\u4f9b LLM \u6587\u5b57\u4efb\u52d9\u89e3\u6c7a\u7d93\u9a57\u3002\n\u7136\u800c\uff0c\u4ed6\u5011\u4ef0\u8cf4\u624b\u52d5\u65b9\u5f0f\u70ba\u6bcf\u500b\u4efb\u52d9\u53d6\u5f97\u4e26\u61c9\u7528\u6b64\u985e\u7d93\u9a57\uff0c\u9019\u5c0d\u65bc LLM \u4e0d\u65b7\u589e\u9577\u7684\u9f90\u5927\u9700\u6c42\u548c\u4f7f\u7528\u8005\u554f\u984c\u7684\u591a\u6a23\u6027\u800c\u8a00\u4e26\u4e0d\u53ef\u884c\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u57fa\u65bc LLM \u7684\u7d42\u8eab\u81ea\u4e3b\u9ad4\u9a57\u5f0f\u5b78\u7fd2\u67b6\u69cb\uff0c\u4ee5\u63a2\u8a0e LLM \u662f\u5426\u80fd\u6a21\u4eff\u4eba\u985e\u5b78\u7fd2\u548c\u5229\u7528\u7d93\u9a57\u7684\u80fd\u529b\u3002\u5b83\u900f\u904e\u7d93\u9a57\u50b3\u905e\u548c\u6b78\u7d0d\u81ea\u4e3b\u5b78\u7fd2\u4e26\u7d2f\u7a4d\u7d93\u9a57\uff0c\u5c0d\u8f38\u5165\u554f\u984c\u7684\u985e\u578b\u9032\u884c\u5206\u985e\uff0c\u4ee5\u9078\u64c7\u8981\u70ba\u5176\u63a1\u7528\u54ea\u7a2e\u7d2f\u7a4d\u7d93\u9a57\u3002\u5728\u516d\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684 NLP \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u67b6\u69cb\u5728\u6bcf\u500b\u4e2d\u9593\u6b65\u9a5f\u4e2d\u90fd\u80fd\u53ef\u9760\u57f7\u884c\uff0c\u4e26\u6709\u6548\u63d0\u5347 GPT-3.5 \u548c GPT-4 \u7684\u6548\u80fd\u3002\u9019\u9a57\u8b49\u4e86\u4f7f\u7528 LLM \u6a21\u4eff\u4eba\u985e\u9ad4\u9a57\u5f0f\u5b78\u7fd2\u548c\u61c9\u7528\u80fd\u529b\u7684\u53ef\u884c\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u67b6\u69cb\u5728\u6bcf\u500b\u6b65\u9a5f\u4e2d\u884c\u70ba\u7684\u8a73\u7d30\u5206\u6790\u3002", "author": "Jinglong Gao et.al.", "authors": "Jinglong Gao, Xiao Ding, Yiming Cui, Jianbai Zhao, Hepeng Wang, Ting Liu, Bing Qin", "id": "2407.08937v1", "paper_url": "http://arxiv.org/abs/2407.08937v1", "repo": "null"}}