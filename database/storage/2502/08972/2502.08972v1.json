{"2502.08972": {"publish_time": "2025-02-13", "title": "Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning", "paper_summary": "Language models are aligned to the collective voice of many, resulting in\ngeneric outputs that do not align with specific users' styles. In this work, we\npresent Trial-Error-Explain In-Context Learning (TICL), a tuning-free method\nthat personalizes language models for text generation tasks with fewer than 10\nexamples per user. TICL iteratively expands an in-context learning prompt via a\ntrial-error-explain process, adding model-generated negative samples and\nexplanations that provide fine-grained guidance towards a specific user's\nstyle. TICL achieves favorable win rates on pairwise comparisons with\nLLM-as-a-judge up to 91.5% against the previous state-of-the-art and\noutperforms competitive tuning-free baselines for personalized alignment tasks\nof writing emails, essays and news articles. Both lexical and qualitative\nanalyses show that the negative samples and explanations enable language models\nto learn stylistic context more effectively and overcome the bias towards\nstructural and formal phrases observed in their zero-shot outputs. By\nfront-loading inference compute to create a user-specific in-context learning\nprompt that does not require extra generation steps at test time, TICL presents\na novel yet simple approach for personalized alignment.", "paper_summary_zh": "\u8a9e\u8a00\u6a21\u578b\u8207\u773e\u4eba\u7684\u96c6\u9ad4\u8072\u97f3\u4fdd\u6301\u4e00\u81f4\uff0c\u5c0e\u81f4\u7522\u51fa\u5167\u5bb9\u6d41\u65bc\u4e00\u822c\uff0c\u7121\u6cd5\u8207\u7279\u5b9a\u4f7f\u7528\u8005\u7684\u98a8\u683c\u76f8\u7b26\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u8a66\u9a57\u932f\u8aa4\u89e3\u91cb\u60c5\u5883\u5167\u5b78\u7fd2 (TICL)\uff0c\u4e00\u7a2e\u514d\u8abf\u6821\u65b9\u6cd5\uff0c\u80fd\u70ba\u6587\u5b57\u751f\u6210\u4efb\u52d9\u500b\u4eba\u5316\u8a9e\u8a00\u6a21\u578b\uff0c\u6bcf\u500b\u4f7f\u7528\u8005\u5c11\u65bc 10 \u500b\u7bc4\u4f8b\u3002TICL \u900f\u904e\u8a66\u9a57\u932f\u8aa4\u89e3\u91cb\u7a0b\u5e8f\u53cd\u8986\u64f4\u5145\u60c5\u5883\u5167\u5b78\u7fd2\u63d0\u793a\uff0c\u52a0\u5165\u6a21\u578b\u7522\u751f\u7684\u8ca0\u9762\u7bc4\u4f8b\u548c\u8aaa\u660e\uff0c\u63d0\u4f9b\u7d30\u7dfb\u7684\u6307\u5c0e\uff0c\u5f15\u5c0e\u81f3\u7279\u5b9a\u4f7f\u7528\u8005\u7684\u98a8\u683c\u3002TICL \u5728\u8207 LLM \u4f5c\u70ba\u8a55\u5be9\u7684\u6210\u5c0d\u6bd4\u8f03\u4e2d\u7372\u5f97\u4e86\u9ad8\u52dd\u7387\uff0c\u9ad8\u9054 91.5%\uff0c\u512a\u65bc\u5148\u524d\u7684\u6280\u8853\u6c34\u6e96\uff0c\u4e26\u5728\u500b\u4eba\u5316\u5c0d\u9f4a\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4e86\u7af6\u722d\u6027\u7684\u514d\u8abf\u6821\u57fa\u6e96\uff0c\u5305\u62ec\u64b0\u5beb\u96fb\u5b50\u90f5\u4ef6\u3001\u8ad6\u6587\u548c\u65b0\u805e\u6587\u7ae0\u3002\u8a5e\u5f59\u548c\u8cea\u6027\u5206\u6790\u7686\u986f\u793a\uff0c\u8ca0\u9762\u7bc4\u4f8b\u548c\u8aaa\u660e\u8b93\u8a9e\u8a00\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u5b78\u7fd2\u98a8\u683c\u8108\u7d61\uff0c\u4e26\u514b\u670d\u96f6\u6b21\u5b78\u7fd2\u7522\u51fa\u4e2d\u89c0\u5bdf\u5230\u7684\u7d50\u69cb\u6027\u548c\u6b63\u5f0f\u8a5e\u7d44\u504f\u8aa4\u3002\u900f\u904e\u9810\u5148\u52a0\u8f09\u63a8\u8ad6\u904b\u7b97\uff0c\u5efa\u7acb\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u60c5\u5883\u5167\u5b78\u7fd2\u63d0\u793a\uff0c\u7121\u9700\u5728\u6e2c\u8a66\u6642\u984d\u5916\u7522\u751f\u6b65\u9a5f\uff0cTICL \u5448\u73fe\u4e00\u7a2e\u65b0\u7a4e\u537b\u7c21\u6f54\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u500b\u4eba\u5316\u5c0d\u9f4a\u3002", "author": "Hyundong Cho et.al.", "authors": "Hyundong Cho, Karishma Sharma, Nicolaas Jedema, Leonardo F. R. Ribeiro, Alessandro Moschitti, Ravi Krishnan, Jonathan May", "id": "2502.08972v1", "paper_url": "http://arxiv.org/abs/2502.08972v1", "repo": "null"}}