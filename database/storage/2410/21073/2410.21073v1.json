{"2410.21073": {"publish_time": "2024-10-28", "title": "Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices", "paper_summary": "This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep\nneural networks to address the gap between pre-trained and deployed models. In\nour approach, trainable LoRA (low-rank adaptation) adapters are inserted\nbetween the last layer and every other layer to enhance the network expressive\npower while keeping the backward computation cost low. This architecture is\nwell-suited to cache intermediate computation results of the forward pass and\nthen can skip the forward computation of seen samples as training epochs\nprogress. We implemented the combination of the proposed architecture and\ncache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our\nresults show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average\ncompared to the counterpart that has the same number of trainable parameters\nwhile preserving the accuracy, while taking only a few seconds on the\nmicrocontroller board.", "paper_summary_zh": "\u672c\u8ad6\u6587\u63d0\u51fa Skip2-LoRA \u4f5c\u70ba\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u7684\u8f15\u91cf\u7d1a\u5fae\u8abf\u65b9\u6cd5\uff0c\u4ee5\u89e3\u6c7a\u9810\u8a13\u7df4\u6a21\u578b\u548c\u5df2\u90e8\u7f72\u6a21\u578b\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u5728\u6211\u5011\u7684\u505a\u6cd5\u4e2d\uff0c\u53ef\u8a13\u7df4\u7684 LoRA\uff08\u4f4e\u79e9\u9069\u61c9\uff09\u9069\u914d\u5668\u6703\u63d2\u5165\u6700\u5f8c\u4e00\u5c64\u548c\u6bcf\u4e00\u5c64\u4e4b\u9593\uff0c\u4ee5\u589e\u5f37\u7db2\u8def\u8868\u9054\u80fd\u529b\uff0c\u540c\u6642\u4fdd\u6301\u53cd\u5411\u904b\u7b97\u6210\u672c\u4f4e\u3002\u6b64\u67b6\u69cb\u975e\u5e38\u9069\u5408\u5feb\u53d6\u524d\u5411\u50b3\u905e\u7684\u4e2d\u9593\u904b\u7b97\u7d50\u679c\uff0c\u7136\u5f8c\u96a8\u8457\u8a13\u7df4\u6642\u671f\u7684\u9032\u5c55\uff0c\u53ef\u4ee5\u8df3\u904e\u5df2\u898b\u6a23\u672c\u7684\u524d\u5411\u904b\u7b97\u3002\u6211\u5011\u5be6\u4f5c\u4e86\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u548c\u5feb\u53d6\u7684\u7d44\u5408\uff0c\u7a31\u70ba Skip2-LoRA\uff0c\u4e26\u5728 15 \u7f8e\u5143\u7684\u55ae\u677f\u96fb\u8166\u4e0a\u9032\u884c\u6e2c\u8a66\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u8207\u5177\u6709\u76f8\u540c\u6578\u91cf\u53ef\u8a13\u7df4\u53c3\u6578\u7684\u5c0d\u61c9\u9805\u76f8\u6bd4\uff0cSkip2-LoRA \u5e73\u5747\u6e1b\u5c11 90.0% \u7684\u5fae\u8abf\u6642\u9593\uff0c\u540c\u6642\u4fdd\u6301\u6e96\u78ba\u6027\uff0c\u800c\u50c5\u5728\u5fae\u63a7\u5236\u5668\u677f\u4e0a\u82b1\u8cbb\u5e7e\u79d2\u9418\u3002", "author": "Hiroki Matsutani et.al.", "authors": "Hiroki Matsutani, Masaaki Kondo, Kazuki Sunaga, Radu Marculescu", "id": "2410.21073v1", "paper_url": "http://arxiv.org/abs/2410.21073v1", "repo": "null"}}