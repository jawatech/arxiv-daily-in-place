{"2411.10020": {"publish_time": "2024-11-15", "title": "Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?", "paper_summary": "Backgrounds: Information extraction (IE) is critical in clinical natural\nlanguage processing (NLP). While large language models (LLMs) excel on\ngenerative tasks, their performance on extractive tasks remains debated.\nMethods: We investigated Named Entity Recognition (NER) and Relation Extraction\n(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,\nMIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinical\nentities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3\nagainst BiomedBERT in terms of performance, generalizability, computational\nresources, and throughput to BiomedBERT. Results: LLaMA models outperformed\nBiomedBERT across datasets. With sufficient training data, LLaMA showed modest\nimprovements (1% on NER, 1.5-3.7% on RE); improvements were larger with limited\ntraining data. On unseen i2b2 data, LLaMA-3-70B outperformed BiomedBERT by 7%\n(F1) on NER and 4% on RE. However, LLaMA models required more computing\nresources and ran up to 28 times slower. We implemented \"Kiwi,\" a clinical IE\npackage featuring both models, available at https://kiwi.clinicalnlp.org/.\nConclusion: This study is among the first to develop and evaluate a\ncomprehensive clinical IE system using open-source LLMs. Results indicate that\nLLaMA models outperform BiomedBERT for clinical NER and RE but with higher\ncomputational costs and lower throughputs. These findings highlight that\nchoosing between LLMs and traditional deep learning methods for clinical IE\napplications should remain task-specific, taking into account both performance\nmetrics and practical considerations such as available computing resources and\nthe intended use case scenarios.", "paper_summary_zh": "\u80cc\u666f\uff1a\u8cc7\u8a0a\u8403\u53d6 (IE) \u5728\u81e8\u5e8a\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u751f\u6210\u5f0f\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5b83\u5011\u5728\u8403\u53d6\u5f0f\u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u4ecd\u6709\u722d\u8b70\u3002\u65b9\u6cd5\uff1a\u6211\u5011\u4f7f\u7528\u4f86\u81ea\u56db\u500b\u4f86\u6e90\uff08UT Physicians\u3001MTSamples\u3001MIMIC-III \u548c i2b2\uff09\u7684 1,588 \u500b\u81e8\u5e8a\u7b46\u8a18\uff0c\u7814\u7a76\u4e86\u547d\u540d\u5be6\u9ad4\u8fa8\u8b58 (NER) \u548c\u95dc\u4fc2\u8403\u53d6 (RE)\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u8a3b\u89e3\u8a9e\u6599\u5eab\uff0c\u6db5\u84cb 4 \u500b\u81e8\u5e8a\u5be6\u9ad4\u548c 16 \u500b\u4fee\u98fe\u8a5e\uff0c\u4e26\u5728\u6548\u80fd\u3001\u6cdb\u5316\u6027\u3001\u904b\u7b97\u8cc7\u6e90\u548c\u8655\u7406\u91cf\u65b9\u9762\uff0c\u5c07\u7d93\u904e\u6307\u4ee4\u5fae\u8abf\u7684 LLaMA-2 \u548c LLaMA-3 \u8207 BiomedBERT \u9032\u884c\u6bd4\u8f03\u3002\u7d50\u679c\uff1aLLaMA \u6a21\u578b\u5728\u6240\u6709\u8cc7\u6599\u96c6\u7684\u8868\u73fe\u90fd\u512a\u65bc BiomedBERT\u3002\u5728\u6709\u8db3\u5920\u7684\u8a13\u7df4\u8cc7\u6599\u4e0b\uff0cLLaMA \u8868\u73fe\u51fa\u9069\u5ea6\u7684\u9032\u6b65\uff08NER \u63d0\u5347 1%\uff0cRE \u63d0\u5347 1.5-3.7%\uff09\uff1b\u5728\u8a13\u7df4\u8cc7\u6599\u6709\u9650\u7684\u60c5\u6cc1\u4e0b\uff0c\u9032\u6b65\u5e45\u5ea6\u66f4\u5927\u3002\u5728\u672a\u898b\u904e\u7684 i2b2 \u8cc7\u6599\u4e0a\uff0cLLaMA-3-70B \u5728 NER \u4e0a\u7684\u8868\u73fe\u512a\u65bc BiomedBERT 7%\uff08F1\uff09\uff0c\u5728 RE \u4e0a\u512a\u65bc 4%\u3002\u7136\u800c\uff0cLLaMA \u6a21\u578b\u9700\u8981\u66f4\u591a\u7684\u904b\u7b97\u8cc7\u6e90\uff0c\u57f7\u884c\u901f\u5ea6\u6162\u4e86 28 \u500d\u3002\u6211\u5011\u5be6\u4f5c\u4e86\u300cKiwi\u300d\uff0c\u4e00\u500b\u540c\u6642\u5177\u5099\u9019\u5169\u500b\u6a21\u578b\u7684\u81e8\u5e8a IE \u5957\u4ef6\uff0c\u53ef\u5728 https://kiwi.clinicalnlp.org/ \u53d6\u5f97\u3002\u7d50\u8ad6\uff1a\u672c\u7814\u7a76\u662f\u7b2c\u4e00\u500b\u4f7f\u7528\u958b\u6e90 LLM \u958b\u767c\u548c\u8a55\u4f30\u5168\u9762\u81e8\u5e8a IE \u7cfb\u7d71\u7684\u7814\u7a76\u3002\u7d50\u679c\u986f\u793a\uff0cLLaMA \u6a21\u578b\u5728\u81e8\u5e8a NER \u548c RE \u65b9\u9762\u512a\u65bc BiomedBERT\uff0c\u4f46\u904b\u7b97\u6210\u672c\u8f03\u9ad8\uff0c\u8655\u7406\u91cf\u8f03\u4f4e\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\uff0c\u5728\u81e8\u5e8a IE \u61c9\u7528\u4e2d\uff0c\u9078\u64c7 LLM \u548c\u50b3\u7d71\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u61c9\u53d6\u6c7a\u65bc\u7279\u5b9a\u4efb\u52d9\uff0c\u540c\u6642\u8003\u91cf\u6548\u80fd\u6307\u6a19\u548c\u5be6\u969b\u8003\u91cf\u56e0\u7d20\uff0c\u4f8b\u5982\u53ef\u7528\u7684\u904b\u7b97\u8cc7\u6e90\u548c\u9810\u671f\u7684\u4f7f\u7528\u6848\u4f8b\u60c5\u5883\u3002", "author": "Yan Hu et.al.", "authors": "Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu", "id": "2411.10020v1", "paper_url": "http://arxiv.org/abs/2411.10020v1", "repo": "null"}}