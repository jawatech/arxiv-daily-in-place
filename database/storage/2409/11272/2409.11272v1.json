{"2409.11272": {"publish_time": "2024-09-17", "title": "LOLA -- An Open-Source Massively Multilingual Large Language Model", "paper_summary": "This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39 LOLA\uff0c\u9019\u662f\u4e00\u500b\u7d93\u904e 160 \u591a\u7a2e\u8a9e\u8a00\u8a13\u7df4\u7684\u5927\u578b\u591a\u8a9e\u8a00\u8a9e\u8a00\u6a21\u578b\uff0c\u63a1\u7528\u7a00\u758f\u6df7\u5408\u5c08\u5bb6 Transformer \u67b6\u69cb\u3002\u6211\u5011\u7684\u67b6\u69cb\u548c\u5be6\u4f5c\u9078\u64c7\u61c9\u5c0d\u4e86\u5728\u7dad\u6301\u6548\u7387\u4e14\u907f\u514d\u591a\u8a9e\u8a00\u7684\u5e38\u898b\u9677\u9631\u7684\u540c\u6642\uff0c\u5229\u7528\u8a9e\u8a00\u591a\u6a23\u6027\u7684\u6311\u6230\u3002\u6211\u5011\u5c0d\u8a55\u4f30\u7d50\u679c\u7684\u5206\u6790\u986f\u793a\uff0c\u5728\u81ea\u7136\u8a9e\u8a00\u751f\u6210\u548c\u7406\u89e3\u4efb\u52d9\u4e2d\u5177\u6709\u7af6\u722d\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5b78\u7fd2\u5230\u7684\u5c08\u5bb6\u8def\u7531\u6a5f\u5236\u5982\u4f55\u5229\u7528\u96b1\u542b\u7684\u7cfb\u7d71\u767c\u751f\u8a9e\u8a00\u6a21\u5f0f\u4f86\u6f5b\u5728\u6e1b\u8f15\u591a\u8a9e\u8a00\u7684\u8a5b\u5492\u3002\u6211\u5011\u6df1\u5165\u63a2\u8a0e\u8a13\u7df4\u904e\u7a0b\u3001\u5206\u6790\u8cc7\u6599\u96c6\uff0c\u4e26\u5e73\u8861\u63a2\u8a0e\u6a21\u578b\u7684\u512a\u7f3a\u9ede\u3002\u4f5c\u70ba\u4e00\u500b\u958b\u6e90\u6a21\u578b\uff0cLOLA \u4fc3\u9032\u4e86\u53ef\u8907\u88fd\u6027\uff0c\u4e26\u4f5c\u70ba\u672a\u4f86\u7814\u7a76\u7684\u5f37\u5927\u57fa\u790e\u3002\u6211\u5011\u7684\u767c\u73fe\u4f7f\u958b\u767c\u51fa\u8de8\u8a9e\u8a00\u5177\u6709\u5f37\u5927\u3001\u53ef\u64f4\u5145\u6548\u80fd\u7684\u904b\u7b97\u6548\u7387\u591a\u8a9e\u8a00\u6a21\u578b\u6210\u70ba\u53ef\u80fd\u3002", "author": "Nikit Srivastava et.al.", "authors": "Nikit Srivastava, Denis Kuchelev, Tatiana Moteu, Kshitij Shetty, Michael Roeder, Diego Moussallem, Hamada Zahera, Axel-Cyrille Ngonga Ngomo", "id": "2409.11272v1", "paper_url": "http://arxiv.org/abs/2409.11272v1", "repo": "null"}}