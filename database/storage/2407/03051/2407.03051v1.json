{"2407.03051": {"publish_time": "2024-07-03", "title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment", "paper_summary": "The rapid advancement of large language models (LLMs) has facilitated their\ntransformation into conversational chatbots that can grasp contextual nuances\nand generate pertinent sentences, closely mirroring human values through\nadvanced techniques such as instruction tuning and reinforcement learning from\nhuman feedback (RLHF). However, the computational efficiency required for LLMs,\nachieved through techniques like post-training quantization (PTQ), presents\nchallenges such as token-flipping that can impair chatbot performance. In\nresponse, we propose a novel preference alignment approach, quantization-aware\ndirect preference optimization (QDPO), that aligns quantized LLMs with their\nfull-precision counterparts, improving conversational abilities. Evaluated on\ntwo instruction-tuned LLMs in various languages, QDPO demonstrated superior\nperformance in improving conversational abilities compared to established PTQ\nand knowledge-distillation fine-tuning techniques, marking a significant step\nforward in the development of efficient and effective conversational LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u6b65\u4fc3\u9032\u4e86\u5b83\u5011\u8f49\u8b8a\u70ba\u5c0d\u8a71\u5f0f\u804a\u5929\u6a5f\u5668\u4eba\uff0c\u53ef\u4ee5\u638c\u63e1\u8a9e\u5883\u7d30\u5fae\u5dee\u5225\u4e26\u751f\u6210\u76f8\u95dc\u53e5\u5b50\uff0c\u901a\u904e\u9ad8\u7d1a\u6280\u8853\uff08\u4f8b\u5982\u6307\u4ee4\u8abf\u6574\u548c\u4eba\u985e\u53cd\u994b\u7684\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff09\u7dca\u5bc6\u53cd\u6620\u4eba\u985e\u50f9\u503c\u89c0\u3002\u7136\u800c\uff0cLLM \u6240\u9700\u7684\u904b\u7b97\u6548\u7387\u662f\u901a\u904e\u5f8c\u8a13\u7df4\u91cf\u5316 (PTQ) \u7b49\u6280\u8853\u5be6\u73fe\u7684\uff0c\u9019\u5e36\u4f86\u4e86\u53ef\u80fd\u6703\u640d\u5bb3\u804a\u5929\u6a5f\u5668\u4eba\u6548\u80fd\u7684\u4ee3\u5e63\u7ffb\u8f49\u7b49\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u504f\u597d\u5c0d\u9f4a\u65b9\u6cd5\uff0c\u91cf\u5316\u611f\u77e5\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (QDPO)\uff0c\u5c07\u91cf\u5316\u7684 LLM \u8207\u5b83\u5011\u7684\u5b8c\u6574\u7cbe\u5ea6\u5c0d\u61c9\u9805\u5c0d\u9f4a\uff0c\u5f9e\u800c\u63d0\u9ad8\u5c0d\u8a71\u80fd\u529b\u3002\u5728\u5404\u7a2e\u8a9e\u8a00\u4e2d\u5c0d\u5169\u500b\u6307\u4ee4\u8abf\u6574\u7684 LLM \u9032\u884c\u8a55\u4f30\uff0cQDPO \u5728\u63d0\u9ad8\u5c0d\u8a71\u80fd\u529b\u65b9\u9762\u8868\u73fe\u51fa\u512a\u65bc\u5df2\u5efa\u7acb\u7684 PTQ \u548c\u77e5\u8b58\u63d0\u7149\u5fae\u8abf\u6280\u8853\u7684\u5353\u8d8a\u6548\u80fd\uff0c\u9019\u6a19\u8a8c\u8457\u9ad8\u6548\u4e14\u6709\u6548\u7684\u5c0d\u8a71\u5f0f LLM \u767c\u5c55\u5411\u524d\u9081\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002", "author": "Janghwan Lee et.al.", "authors": "Janghwan Lee, Seongmin Park, Sukjin Hong, Minsoo Kim, Du-Seong Chang, Jungwook Choi", "id": "2407.03051v1", "paper_url": "http://arxiv.org/abs/2407.03051v1", "repo": "null"}}