{"2409.03206": {"publish_time": "2024-09-05", "title": "TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations", "paper_summary": "Multimodal Large Language Models (MLLMs) have significantly improved\nperformance across various image-language applications. Recently, there has\nbeen a growing interest in adapting image pre-trained MLLMs for video-related\ntasks. However, most efforts concentrate on enhancing the vision encoder and\nprojector components, while the core part, Large Language Models (LLMs),\nremains comparatively under-explored. In this paper, we propose two strategies\nto enhance the model's capability in video understanding tasks by improving\ninter-layer attention computation in LLMs. Specifically, the first approach\nfocuses on the enhancement of Rotary Position Embedding (RoPE) with\nTemporal-Aware Dual RoPE, which introduces temporal position information to\nstrengthen the MLLM's temporal modeling capabilities while preserving the\nrelative position relationships of both visual and text tokens. The second\napproach involves enhancing the Attention Mask with the Frame-wise Block Causal\nAttention Mask, a simple yet effective method that broadens visual token\ninteractions within and across video frames while maintaining the causal\ninference mechanism. Based on these proposed methods, we adapt LLaVA for video\nunderstanding tasks, naming it Temporal-Considered LLaVA (TC-LLaVA). Our\nTC-LLaVA achieves new state-of-the-art performance across various video\nunderstanding benchmarks with only supervised fine-tuning (SFT) on\nvideo-related datasets.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b (MLLM) \u5df2\u663e\u8457\u63d0\u5347\u5404\u79cd\u56fe\u50cf\u8bed\u8a00\u5e94\u7528\u7a0b\u5e8f\u7684\u6027\u80fd\u3002\u6700\u8fd1\uff0c\u4eba\u4eec\u5bf9\u5c06\u56fe\u50cf\u9884\u8bad\u7ec3 MLLM \u8c03\u6574\u7528\u4e8e\u4e0e\u89c6\u9891\u76f8\u5173\u7684\u4efb\u52a1\u8d8a\u6765\u8d8a\u611f\u5174\u8da3\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u589e\u5f3a\u89c6\u89c9\u7f16\u7801\u5668\u548c\u6295\u5f71\u673a\u7ec4\u4ef6\u4e0a\uff0c\u800c\u6838\u5fc3\u90e8\u5206\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u4ecd\u76f8\u5bf9\u7f3a\u4e4f\u63a2\u7d22\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e24\u79cd\u7b56\u7565\u6765\u589e\u5f3a\u6a21\u578b\u5728\u89c6\u9891\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u65b9\u6cd5\u662f\u6539\u8fdb LLM \u4e2d\u7684\u5c42\u95f4\u6ce8\u610f\u529b\u8ba1\u7b97\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7b2c\u4e00\u79cd\u65b9\u6cd5\u4e13\u6ce8\u4e8e\u4f7f\u7528\u65f6\u95f4\u611f\u77e5\u53cc RoPE \u589e\u5f3a\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165 (RoPE)\uff0c\u5b83\u5f15\u5165\u4e86\u65f6\u95f4\u4f4d\u7f6e\u4fe1\u606f\u6765\u589e\u5f3a MLLM \u7684\u65f6\u95f4\u5efa\u6a21\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u89c6\u89c9\u6807\u8bb0\u548c\u6587\u672c\u6807\u8bb0\u7684\u76f8\u5bf9\u4f4d\u7f6e\u5173\u7cfb\u3002\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u6d89\u53ca\u4f7f\u7528\u5e27\u7ea7\u5757\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\u589e\u5f3a\u6ce8\u610f\u529b\u63a9\u7801\uff0c\u8fd9\u662f\u4e00\u79cd\u7b80\u5355\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5b83\u62d3\u5bbd\u4e86\u89c6\u9891\u5e27\u5185\u548c\u5e27\u95f4\u89c6\u89c9\u6807\u8bb0\u7684\u4ea4\u4e92\uff0c\u540c\u65f6\u4fdd\u6301\u56e0\u679c\u63a8\u7406\u673a\u5236\u3002\u57fa\u4e8e\u8fd9\u4e9b\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u8c03\u6574 LLaVA \u7528\u4e8e\u89c6\u9891\u7406\u89e3\u4efb\u52a1\uff0c\u5e76\u5c06\u5176\u547d\u540d\u4e3a\u65f6\u95f4\u8003\u8651 LLaVA (TC-LLaVA)\u3002\u6211\u4eec\u7684 TC-LLaVA \u5728\u5404\u79cd\u89c6\u9891\u7406\u89e3\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4ec5\u5728\u4e0e\u89c6\u9891\u76f8\u5173\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03 (SFT)\u3002", "author": "Mingze Gao et.al.", "authors": "Mingze Gao, Jingyu Liu, Mingda Li, Jiangtao Xie, Qingbin Liu, Bo Zhao, Xi Chen, Hui Xiong", "id": "2409.03206v1", "paper_url": "http://arxiv.org/abs/2409.03206v1", "repo": "null"}}