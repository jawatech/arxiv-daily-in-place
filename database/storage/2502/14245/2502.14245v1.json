{"2502.14245": {"publish_time": "2025-02-20", "title": "Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering", "paper_summary": "In this paper, we identify a critical problem, \"lost-in-retrieval\", in\nretrieval-augmented multi-hop question answering (QA): the key entities are\nmissed in LLMs' sub-question decomposition. \"Lost-in-retrieval\" significantly\ndegrades the retrieval performance, which disrupts the reasoning chain and\nleads to the incorrect answers. To resolve this problem, we propose a\nprogressive retrieval and rewriting method, namely ChainRAG, which sequentially\nhandles each sub-question by completing missing key entities and retrieving\nrelevant sentences from a sentence graph for answer generation. Each step in\nour retrieval and rewriting process builds upon the previous one, creating a\nseamless chain that leads to accurate retrieval and answers. Finally, all\nretrieved sentences and sub-question answers are integrated to generate a\ncomprehensive answer to the original question. We evaluate ChainRAG on three\nmulti-hop QA datasets$\\unicode{x2013}$MuSiQue, 2Wiki, and\nHotpotQA$\\unicode{x2013}$using three large language models: GPT4o-mini,\nQwen2.5-72B, and GLM-4-Plus. Empirical results demonstrate that ChainRAG\nconsistently outperforms baselines in both effectiveness and efficiency.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5728\u6aa2\u7d22\u589e\u5f37\u7684\u591a\u8df3\u554f\u7b54 (QA) \u4e2d\u767c\u73fe\u4e86\u4e00\u500b\u95dc\u9375\u554f\u984c\u300c\u6aa2\u7d22\u4e2d\u907a\u5931\u300d\uff0c\u95dc\u9375\u5be6\u9ad4\u907a\u5931\u5728 LLM \u7684\u5b50\u554f\u984c\u5206\u89e3\u4e2d\u3002\u300c\u6aa2\u7d22\u4e2d\u907a\u5931\u300d\u986f\u8457\u964d\u4f4e\u6aa2\u7d22\u6548\u80fd\uff0c\u9019\u6703\u4e2d\u65b7\u63a8\u7406\u93c8\u4e26\u5c0e\u81f4\u932f\u8aa4\u7684\u7b54\u6848\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u6f38\u9032\u5f0f\u6aa2\u7d22\u548c\u91cd\u5beb\u65b9\u6cd5\uff0c\u5373 ChainRAG\uff0c\u5b83\u901a\u904e\u5b8c\u6210\u907a\u5931\u7684\u95dc\u9375\u5be6\u9ad4\u4e26\u5f9e\u53e5\u5b50\u5716\u4e2d\u6aa2\u7d22\u76f8\u95dc\u53e5\u5b50\u4f86\u9806\u5e8f\u8655\u7406\u6bcf\u500b\u5b50\u554f\u984c\u4ee5\u7522\u751f\u7b54\u6848\u3002\u6211\u5011\u6aa2\u7d22\u548c\u91cd\u5beb\u904e\u7a0b\u4e2d\u6bcf\u4e00\u6b65\u90fd\u5efa\u7acb\u5728\u524d\u4e00\u6b65\u4e4b\u4e0a\uff0c\u5275\u9020\u4e86\u4e00\u500b\u7121\u7e2b\u7684\u93c8\uff0c\u5c0e\u81f4\u6e96\u78ba\u7684\u6aa2\u7d22\u548c\u7b54\u6848\u3002\u6700\u5f8c\uff0c\u6240\u6709\u6aa2\u7d22\u5230\u7684\u53e5\u5b50\u548c\u5b50\u554f\u984c\u7b54\u6848\u90fd\u6574\u5408\u8d77\u4f86\uff0c\u4ee5\u7522\u751f\u5c0d\u539f\u59cb\u554f\u984c\u7684\u5168\u9762\u7b54\u6848\u3002\u6211\u5011\u5728\u4e09\u500b\u591a\u8df3\u554f\u7b54\u8cc7\u6599\u96c6$\\unicode{x2013}$MuSiQue\u30012Wiki \u548c HotpotQA$\\unicode{x2013}$\u4e0a\u8a55\u4f30 ChainRAG\uff0c\u4f7f\u7528\u4e09\u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff1aGPT4o-mini\u3001Qwen2.5-72B \u548c GLM-4-Plus\u3002\u5be6\u8b49\u7d50\u679c\u8868\u660e\uff0cChainRAG \u5728\u6709\u6548\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u6301\u7e8c\u512a\u65bc\u57fa\u6e96\u3002</paragraph>", "author": "Rongzhi Zhu et.al.", "authors": "Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu", "id": "2502.14245v1", "paper_url": "http://arxiv.org/abs/2502.14245v1", "repo": "null"}}