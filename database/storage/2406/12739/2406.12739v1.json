{"2406.12739": {"publish_time": "2024-06-18", "title": "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages", "paper_summary": "LLMs have become a go-to solution not just for text generation, but also for\nnatural language understanding (NLU) tasks. Acquiring extensive knowledge\nthrough language modeling on web-scale corpora, they excel on English NLU, yet\nstruggle to extend their NLU capabilities to underrepresented languages. In\ncontrast, machine translation models (MT) produce excellent multilingual\nrepresentations, resulting in strong translation performance even for\nlow-resource languages. MT encoders, however, lack the knowledge necessary for\ncomprehensive NLU that LLMs obtain through language modeling training on\nimmense corpora. In this work, we get the best both worlds by integrating MT\nencoders directly into LLM backbones via sample-efficient self-distillation.\nThe resulting MT-LLMs preserve the inherent multilingual representational\nalignment from the MT encoder, allowing lower-resource languages to tap into\nthe rich knowledge embedded in English-centric LLMs. Merging the MT encoder and\nLLM in a single model, we mitigate the propagation of translation errors and\ninference overhead of MT decoding inherent to discrete translation-based\ncross-lingual transfer (e.g., translate-test). Evaluation spanning three\nprominent NLU tasks and 127 predominantly low-resource languages renders\nMT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially and\nconsistently outperform translate-test based on the same MT model, showing that\nwe truly unlock multilingual language understanding for LLMs.", "paper_summary_zh": "LLM \u4e0d\u50c5\u6210\u70ba\u6587\u672c\u751f\u6210\u7684\u9996\u9078\u89e3\u6c7a\u65b9\u6848\uff0c\u4e5f\u6210\u70ba\u81ea\u7136\u8a9e\u8a00\u7406\u89e3 (NLU) \u4efb\u52d9\u7684\u9996\u9078\u89e3\u6c7a\u65b9\u6848\u3002\u900f\u904e\u5728\u7db2\u8def\u898f\u6a21\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u8a9e\u8a00\u6a21\u578b\u5316\u4f86\u7372\u53d6\u5ee3\u6cdb\u77e5\u8b58\uff0c\u5b83\u5011\u5728\u82f1\u6587 NLU \u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u537b\u96e3\u4ee5\u5c07\u5176 NLU \u80fd\u529b\u64f4\u5c55\u5230\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8a9e\u8a00\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6a5f\u5668\u7ffb\u8b6f\u6a21\u578b (MT) \u53ef\u7522\u751f\u512a\u7570\u7684\u591a\u8a9e\u8a00\u8868\u5fb5\uff0c\u5373\u4f7f\u5c0d\u65bc\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u4e5f\u80fd\u7522\u751f\u5f37\u5927\u7684\u7ffb\u8b6f\u6548\u80fd\u3002\u7136\u800c\uff0cMT \u7de8\u78bc\u5668\u7f3a\u5c11\u900f\u904e\u8a9e\u8a00\u6a21\u578b\u5728\u9f90\u5927\u8a9e\u6599\u5eab\u4e0a\u8a13\u7df4\u800c\u7372\u5f97\u7684\uff0c\u5c0d\u65bc\u5168\u9762\u6027 NLU \u6240\u9700\u7684\u77e5\u8b58\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u900f\u904e\u6a23\u672c\u6709\u6548\u7387\u7684\u81ea\u6211\u84b8\u993e\uff0c\u5c07 MT \u7de8\u78bc\u5668\u76f4\u63a5\u6574\u5408\u5230 LLM \u4e3b\u5e79\u4e2d\uff0c\u53d6\u5f97\u5169\u5168\u5176\u7f8e\u3002\u7522\u751f\u7684 MT-LLM \u4fdd\u7559\u4e86 MT \u7de8\u78bc\u5668\u4e2d\u56fa\u6709\u7684\u591a\u8a9e\u8a00\u8868\u5fb5\u5c0d\u9f4a\uff0c\u8b93\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u80fd\u5920\u5229\u7528\u4ee5\u82f1\u6587\u70ba\u4e2d\u5fc3\u7684 LLM \u4e2d\u860a\u542b\u7684\u8c50\u5bcc\u77e5\u8b58\u3002\u5728\u55ae\u4e00\u6a21\u578b\u4e2d\u5408\u4f75 MT \u7de8\u78bc\u5668\u548c LLM\uff0c\u6211\u5011\u6e1b\u8f15\u4e86\u57fa\u65bc\u96e2\u6563\u7ffb\u8b6f\u7684\u8de8\u8a9e\u8a00\u8f49\u79fb (\u4f8b\u5982\u7ffb\u8b6f\u6e2c\u8a66) \u4e2d\u56fa\u6709\u7684\u7ffb\u8b6f\u932f\u8aa4\u50b3\u64ad\u548c MT \u89e3\u78bc\u63a8\u8ad6\u8ca0\u64d4\u3002\u8a55\u4f30\u6db5\u84cb\u4e09\u500b\u91cd\u8981\u7684 NLU \u4efb\u52d9\u548c 127 \u7a2e\u4ee5\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u70ba\u4e3b\u7684\u8a9e\u8a00\uff0c\u986f\u793a MT-LLM \u5728\u8de8\u8a9e\u8a00\u8f49\u79fb\u4e2d\u975e\u5e38\u6709\u6548\u3002MT-LLM \u5927\u5e45\u4e14\u6301\u7e8c\u512a\u65bc\u57fa\u65bc\u76f8\u540c MT \u6a21\u578b\u7684\u7ffb\u8b6f\u6e2c\u8a66\uff0c\u986f\u793a\u6211\u5011\u78ba\u5be6\u70ba LLM \u89e3\u9396\u4e86\u591a\u8a9e\u8a00\u8a9e\u8a00\u7406\u89e3\u3002", "author": "Fabian David Schmidt et.al.", "authors": "Fabian David Schmidt, Philipp Borchert, Ivan Vuli\u0107, Goran Glava\u0161", "id": "2406.12739v1", "paper_url": "http://arxiv.org/abs/2406.12739v1", "repo": "null"}}