{"2411.17374": {"publish_time": "2024-11-26", "title": "Fairness And Performance In Harmony: Data Debiasing Is All You Need", "paper_summary": "Fairness in both machine learning (ML) predictions and human decisions is\ncritical, with ML models prone to algorithmic and data bias, and human\ndecisions affected by subjectivity and cognitive bias. This study investigates\nfairness using a real-world university admission dataset with 870 profiles,\nleveraging three ML models, namely XGB, Bi-LSTM, and KNN. Textual features are\nencoded with BERT embeddings. For individual fairness, we assess decision\nconsistency among experts with varied backgrounds and ML models, using a\nconsistency score. Results show ML models outperform humans in fairness by\n14.08% to 18.79%. For group fairness, we propose a gender-debiasing pipeline\nand demonstrate its efficacy in removing gender-specific language without\ncompromising prediction performance. Post-debiasing, all models maintain or\nimprove their classification accuracy, validating the hypothesis that fairness\nand performance can coexist. Our findings highlight ML's potential to enhance\nfairness in admissions while maintaining high accuracy, advocating a hybrid\napproach combining human judgement and ML models.", "paper_summary_zh": "\u5728\u6a5f\u5668\u5b78\u7fd2 (ML) \u9810\u6e2c\u548c\u4eba\u985e\u6c7a\u7b56\u4e2d\uff0c\u516c\u5e73\u6027\u81f3\u95dc\u91cd\u8981\uff0cML \u6a21\u578b\u5bb9\u6613\u51fa\u73fe\u6f14\u7b97\u6cd5\u548c\u8cc7\u6599\u504f\u5dee\uff0c\u800c\u4eba\u985e\u6c7a\u7b56\u5247\u6703\u53d7\u5230\u4e3b\u89c0\u6027\u548c\u8a8d\u77e5\u504f\u5dee\u7684\u5f71\u97ff\u3002\u672c\u7814\u7a76\u4f7f\u7528\u5305\u542b 870 \u500b\u500b\u4eba\u8cc7\u6599\u7684\u771f\u5be6\u5927\u5b78\u5165\u5b78\u8cc7\u6599\u96c6\u4f86\u8abf\u67e5\u516c\u5e73\u6027\uff0c\u4e26\u5229\u7528 XGB\u3001Bi-LSTM \u548c KNN \u4e09\u7a2e ML \u6a21\u578b\u3002\u6587\u5b57\u7279\u5fb5\u4f7f\u7528 BERT \u5d4c\u5165\u9032\u884c\u7de8\u78bc\u3002\u5c0d\u65bc\u500b\u4eba\u516c\u5e73\u6027\uff0c\u6211\u5011\u4f7f\u7528\u4e00\u81f4\u6027\u8a55\u5206\u4f86\u8a55\u4f30\u4e0d\u540c\u80cc\u666f\u7684\u5c08\u5bb6\u548c ML \u6a21\u578b\u4e4b\u9593\u7684\u6c7a\u7b56\u4e00\u81f4\u6027\u3002\u7d50\u679c\u986f\u793a\uff0cML \u6a21\u578b\u5728\u516c\u5e73\u6027\u65b9\u9762\u512a\u65bc\u4eba\u985e\uff0c\u9054\u5230 14.08% \u81f3 18.79%\u3002\u5c0d\u65bc\u7fa4\u9ad4\u516c\u5e73\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6027\u5225\u53bb\u504f\u7ba1\u9053\uff0c\u4e26\u8b49\u660e\u4e86\u5176\u5728\u6d88\u9664\u7279\u5b9a\u6027\u5225\u8a9e\u8a00\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u540c\u6642\u4e0d\u5f71\u97ff\u9810\u6e2c\u6548\u80fd\u3002\u5728\u53bb\u504f\u8655\u7406\u5f8c\uff0c\u6240\u6709\u6a21\u578b\u90fd\u7dad\u6301\u6216\u63d0\u9ad8\u4e86\u5176\u5206\u985e\u6e96\u78ba\u5ea6\uff0c\u9a57\u8b49\u4e86\u516c\u5e73\u6027\u548c\u6548\u80fd\u53ef\u4ee5\u5171\u5b58\u7684\u5047\u8a2d\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u7a81\u986f\u4e86 ML \u5728\u63d0\u9ad8\u5165\u5b78\u516c\u5e73\u6027\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u540c\u6642\u7dad\u6301\u9ad8\u6e96\u78ba\u5ea6\uff0c\u5021\u5c0e\u4e00\u7a2e\u7d50\u5408\u4eba\u985e\u5224\u65b7\u548c ML \u6a21\u578b\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "author": "Junhua Liu et.al.", "authors": "Junhua Liu, Wendy Wan Yee Hui, Roy Ka-Wei Lee, Kwan Hui Lim", "id": "2411.17374v1", "paper_url": "http://arxiv.org/abs/2411.17374v1", "repo": "null"}}