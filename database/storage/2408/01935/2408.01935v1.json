{"2408.01935": {"publish_time": "2024-08-04", "title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference", "paper_summary": "Despite their impressive performance, large language models (LLMs) such as\nChatGPT are known to pose important risks. One such set of risks arises from\nmisplaced confidence, whether over-confidence or under-confidence, that the\nmodels have in their inference. While the former is well studied, the latter is\nnot, leading to an asymmetry in understanding the comprehensive risk of the\nmodel based on misplaced confidence. In this paper, we address this asymmetry\nby defining two types of risk (decision and composite risk), and proposing an\nexperimental framework consisting of a two-level inference architecture and\nappropriate metrics for measuring such risks in both discriminative and\ngenerative LLMs. The first level relies on a decision rule that determines\nwhether the underlying language model should abstain from inference. The second\nlevel (which applies if the model does not abstain) is the model's inference.\nDetailed experiments on four natural language commonsense reasoning datasets\nusing both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate\nthe practical utility of the evaluation framework. For example, our results\nshow that our framework can get an LLM to confidently respond to an extra 20.1%\nof low-risk inference tasks that other methods might misclassify as high-risk,\nand skip 19.8% of high-risk tasks, which would have been answered incorrectly.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f8b\u5982 ChatGPT \u64c1\u6709\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8868\u73fe\uff0c\u4f46\u5df2\u77e5\u6703\u9020\u6210\u91cd\u8981\u7684\u98a8\u96aa\u3002\u5176\u4e2d\u4e00\u7d44\u98a8\u96aa\u6e90\u81ea\u65bc\u6a21\u578b\u5728\u63a8\u8ad6\u4e2d\u51fa\u73fe\u7684\u932f\u8aa4\u4fe1\u5fc3\uff0c\u7121\u8ad6\u662f\u904e\u5ea6\u81ea\u4fe1\u6216\u904e\u5ea6\u4e0d\u81ea\u4fe1\u3002\u524d\u8005\u5df2\u88ab\u5ee3\u6cdb\u7814\u7a76\uff0c\u5f8c\u8005\u5247\u5426\uff0c\u5c0e\u81f4\u5728\u4e86\u89e3\u6a21\u578b\u57fa\u65bc\u932f\u8aa4\u4fe1\u5fc3\u7684\u5168\u9762\u98a8\u96aa\u6642\u51fa\u73fe\u4e0d\u5c0d\u7a31\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5b9a\u7fa9\u5169\u7a2e\u98a8\u96aa\uff08\u6c7a\u7b56\u98a8\u96aa\u548c\u8907\u5408\u98a8\u96aa\uff09\u4f86\u89e3\u6c7a\u9019\u500b\u4e0d\u5c0d\u7a31\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u5be6\u9a57\u67b6\u69cb\uff0c\u5305\u62ec\u4e00\u500b\u4e8c\u5c64\u63a8\u8ad6\u67b6\u69cb\u548c\u9069\u7576\u7684\u6307\u6a19\uff0c\u7528\u65bc\u8861\u91cf\u5224\u5225\u5f0f\u548c\u751f\u6210\u5f0f LLM \u4e2d\u7684\u9019\u5169\u7a2e\u98a8\u96aa\u3002\u7b2c\u4e00\u5c64\u4f9d\u8cf4\u65bc\u4e00\u500b\u6c7a\u7b56\u898f\u5247\uff0c\u7528\u65bc\u6c7a\u5b9a\u5e95\u5c64\u8a9e\u8a00\u6a21\u578b\u662f\u5426\u61c9\u68c4\u6b0a\u63a8\u8ad6\u3002\u7b2c\u4e8c\u5c64\uff08\u5982\u679c\u6a21\u578b\u4e0d\u68c4\u6b0a\u5247\u9069\u7528\uff09\u662f\u6a21\u578b\u7684\u63a8\u8ad6\u3002\u4f7f\u7528\u958b\u6e90\u7684\u57fa\u65bc\u96c6\u5408\u7684 RoBERTa \u6a21\u578b\u548c ChatGPT\uff0c\u5728\u56db\u500b\u81ea\u7136\u8a9e\u8a00\u5e38\u8b58\u63a8\u7406\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u8a73\u7d30\u5be6\u9a57\uff0c\u8b49\u660e\u4e86\u8a55\u4f30\u67b6\u69cb\u7684\u5be6\u7528\u6027\u3002\u4f8b\u5982\uff0c\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u67b6\u69cb\u53ef\u4ee5\u8b93 LLM \u81ea\u4fe1\u5730\u56de\u61c9\u984d\u5916\u7684 20.1% \u7684\u4f4e\u98a8\u96aa\u63a8\u8ad6\u4efb\u52d9\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u53ef\u80fd\u6703\u5c07\u5176\u932f\u8aa4\u5206\u985e\u70ba\u9ad8\u98a8\u96aa\uff0c\u4e26\u7565\u904e 19.8% \u7684\u9ad8\u98a8\u96aa\u4efb\u52d9\uff0c\u800c\u9019\u4e9b\u4efb\u52d9\u53ef\u80fd\u6703\u88ab\u56de\u7b54\u932f\u8aa4\u3002", "author": "Ke Shen et.al.", "authors": "Ke Shen, Mayank Kejriwal", "id": "2408.01935v1", "paper_url": "http://arxiv.org/abs/2408.01935v1", "repo": "null"}}