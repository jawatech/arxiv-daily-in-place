{"2412.11741": {"publish_time": "2024-12-16", "title": "CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation", "paper_summary": "The emergence of long-context text applications utilizing large language\nmodels (LLMs) has presented significant scalability challenges, particularly in\nmemory footprint. The linear growth of the Key-Value (KV) cache responsible for\nstoring attention keys and values to minimize redundant computations can lead\nto substantial increases in memory consumption, potentially causing models to\nfail to serve with limited memory resources. To address this issue, we propose\na novel approach called Cache Sparse Representation (CSR), which converts the\nKV cache by transforming the dense Key-Value cache tensor into sparse indexes\nand weights, offering a more memory-efficient representation during LLM\ninference. Furthermore, we introduce NeuralDict, a novel neural network-based\nmethod for automatically generating the dictionary used in our sparse\nrepresentation. Our extensive experiments demonstrate that CSR achieves\nperformance comparable to state-of-the-art KV cache quantization algorithms\nwhile maintaining robust functionality in memory-constrained environments.", "paper_summary_zh": "\u96a8\u8457\u63a1\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9577\u5167\u5bb9\u6587\u5b57\u61c9\u7528\u7a0b\u5f0f\u51fa\u73fe\uff0c\u7522\u751f\u4e86\u91cd\u5927\u7684\u53ef\u64f4\u5145\u6027\u6311\u6230\uff0c\u5c24\u5176\u662f\u5728\u8a18\u61b6\u9ad4\u4f54\u7528\u7a7a\u9593\u65b9\u9762\u3002\u8ca0\u8cac\u5132\u5b58\u6ce8\u610f\u529b\u9375\u548c\u503c\u7684\u5feb\u53d6\u8a18\u61b6\u9ad4 (KV) \u7684\u7dda\u6027\u6210\u9577\uff0c\u4ee5\u6700\u5c0f\u5316\u91cd\u8907\u904b\u7b97\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u8a18\u61b6\u9ad4\u6d88\u8017\u5927\u5e45\u589e\u52a0\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u6a21\u578b\u7121\u6cd5\u5728\u6709\u9650\u7684\u8a18\u61b6\u9ad4\u8cc7\u6e90\u4e0b\u63d0\u4f9b\u670d\u52d9\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba\u5feb\u53d6\u7a00\u758f\u8868\u793a (CSR) \u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u900f\u904e\u5c07\u5bc6\u96c6\u7684\u5feb\u53d6\u8a18\u61b6\u9ad4\u5f35\u91cf\u8f49\u63db\u6210\u7a00\u758f\u7d22\u5f15\u548c\u6b0a\u91cd\uff0c\u5c07 KV \u5feb\u53d6\u8a18\u61b6\u9ad4\u8f49\u63db\uff0c\u5728 LLM \u63a8\u8ad6\u671f\u9593\u63d0\u4f9b\u66f4\u5177\u8a18\u61b6\u9ad4\u6548\u7387\u7684\u8868\u793a\u65b9\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86 NeuralDict\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u795e\u7d93\u7db2\u8def\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u65bc\u81ea\u52d5\u7522\u751f\u6211\u5011\u5728\u7a00\u758f\u8868\u793a\u4e2d\u4f7f\u7528\u7684\u5b57\u5178\u3002\u6211\u5011\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cCSR \u9054\u5230\u4e86\u8207\u6700\u5148\u9032\u7684 KV \u5feb\u53d6\u91cf\u5316\u6f14\u7b97\u6cd5\u76f8\u7576\u7684\u6548\u80fd\uff0c\u540c\u6642\u5728\u8a18\u61b6\u9ad4\u53d7\u9650\u7684\u74b0\u5883\u4e2d\u7dad\u6301\u7a69\u5065\u7684\u529f\u80fd\u3002", "author": "Hongxuan Zhang et.al.", "authors": "Hongxuan Zhang, Yao Zhao, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen", "id": "2412.11741v1", "paper_url": "http://arxiv.org/abs/2412.11741v1", "repo": "null"}}