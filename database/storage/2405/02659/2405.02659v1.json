{"2405.02659": {"publish_time": "2024-05-04", "title": "R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models", "paper_summary": "Retrieval-augmented large language models (LLMs) leverage relevant content\nretrieved by information retrieval systems to generate correct responses,\naiming to alleviate the hallucination problem. However, existing\nretriever-responder methods typically append relevant documents to the prompt\nof LLMs to perform text generation tasks without considering the interaction of\nfine-grained structural semantics between the retrieved documents and the LLMs.\nThis issue is particularly important for accurate response generation as LLMs\ntend to ``lose in the middle'' when dealing with input prompts augmented with\nlengthy documents. In this work, we propose a new pipeline named ``Reinforced\nRetriever-Reorder-Responder'' (R$^4$) to learn document orderings for\nretrieval-augmented LLMs, thereby further enhancing their generation abilities\nwhile the large numbers of parameters of LLMs remain frozen. The reordering\nlearning process is divided into two steps according to the quality of the\ngenerated responses: document order adjustment and document representation\nenhancement. Specifically, document order adjustment aims to organize retrieved\ndocument orderings into beginning, middle, and end positions based on graph\nattention learning, which maximizes the reinforced reward of response quality.\nDocument representation enhancement further refines the representations of\nretrieved documents for responses of poor quality via document-level gradient\nadversarial learning. Extensive experiments demonstrate that our proposed\npipeline achieves better factual question-answering performance on\nknowledge-intensive tasks compared to strong baselines across various public\ndatasets. The source codes and trained models will be released upon paper\nacceptance.", "paper_summary_zh": "<paragraph>\u6aa2\u7d22\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5229\u7528\u8cc7\u8a0a\u6aa2\u7d22\u7cfb\u7d71\u6aa2\u7d22\u5230\u7684\u76f8\u95dc\u5167\u5bb9\u4f86\u7522\u751f\u6b63\u78ba\u7684\u56de\u61c9\uff0c\u65e8\u5728\u6e1b\u8f15\u5e7b\u89ba\u554f\u984c\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u6aa2\u7d22\u56de\u61c9\u65b9\u6cd5\u901a\u5e38\u5c07\u76f8\u95dc\u6587\u4ef6\u9644\u52a0\u5230 LLM \u7684\u63d0\u793a\u4e2d\uff0c\u4ee5\u57f7\u884c\u6587\u5b57\u751f\u6210\u4efb\u52d9\uff0c\u800c\u6c92\u6709\u8003\u616e\u6aa2\u7d22\u5230\u7684\u6587\u4ef6\u548c LLM \u4e4b\u9593\u7d30\u7c92\u5ea6\u7d50\u69cb\u8a9e\u7fa9\u7684\u4e92\u52d5\u3002\u9019\u500b\u554f\u984c\u5c0d\u65bc\u6e96\u78ba\u7684\u56de\u61c9\u751f\u6210\u7279\u5225\u91cd\u8981\uff0c\u56e0\u70ba LLM \u5728\u8655\u7406\u4ee5\u5197\u9577\u6587\u4ef6\u589e\u5f37\u7684\u8f38\u5165\u63d0\u793a\u6642\u5f80\u5f80\u6703\u300c\u8ff7\u5931\u5728\u4e2d\u9593\u300d\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba\u300c\u5f37\u5316\u6aa2\u7d22\u91cd\u6392\u5e8f\u56de\u61c9\u5668\u300d(R$^4$) \u7684\u65b0\u7ba1\u9053\uff0c\u7528\u65bc\u5b78\u7fd2\u6aa2\u7d22\u589e\u5f37 LLM \u7684\u6587\u4ef6\u6392\u5e8f\uff0c\u5f9e\u800c\u9032\u4e00\u6b65\u589e\u5f37\u5b83\u5011\u7684\u751f\u6210\u80fd\u529b\uff0c\u540c\u6642 LLM \u7684\u5927\u91cf\u53c3\u6578\u4fdd\u6301\u51cd\u7d50\u3002\u6839\u64da\u751f\u6210\u56de\u61c9\u7684\u54c1\u8cea\uff0c\u91cd\u6392\u5e8f\u5b78\u7fd2\u904e\u7a0b\u5206\u70ba\u5169\u500b\u6b65\u9a5f\uff1a\u6587\u4ef6\u9806\u5e8f\u8abf\u6574\u548c\u6587\u4ef6\u8868\u793a\u589e\u5f37\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6587\u4ef6\u9806\u5e8f\u8abf\u6574\u65e8\u5728\u6839\u64da\u5716\u6ce8\u610f\u529b\u5b78\u7fd2\u5c07\u6aa2\u7d22\u5230\u7684\u6587\u4ef6\u6392\u5e8f\u7d44\u7e54\u6210\u958b\u59cb\u3001\u4e2d\u9593\u548c\u7d50\u675f\u4f4d\u7f6e\uff0c\u9019\u6700\u5927\u5316\u4e86\u56de\u61c9\u54c1\u8cea\u7684\u5f37\u5316\u734e\u52f5\u3002\u6587\u4ef6\u8868\u793a\u589e\u5f37\u9032\u4e00\u6b65\u901a\u904e\u6587\u4ef6\u7d1a\u5225\u68af\u5ea6\u5c0d\u6297\u5b78\u7fd2\uff0c\u6539\u5584\u4e86\u54c1\u8cea\u4e0d\u4f73\u7684\u56de\u61c9\u7684\u6aa2\u7d22\u6587\u4ef6\u8868\u793a\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u5404\u7a2e\u516c\u5171\u6578\u64da\u96c6\u4e0a\u7684\u5f37\u5927\u57fa\u7dda\u76f8\u6bd4\uff0c\u6211\u5011\u63d0\u51fa\u7684\u7ba1\u9053\u5728\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u4e0a\u5be6\u73fe\u4e86\u66f4\u597d\u7684\u4e8b\u5be6\u554f\u7b54\u6027\u80fd\u3002\u539f\u59cb\u78bc\u548c\u8a13\u7df4\u597d\u7684\u6a21\u578b\u5c07\u5728\u8ad6\u6587\u88ab\u63a5\u53d7\u5f8c\u767c\u5e03\u3002</paragraph>", "author": "Taolin Zhang et.al.", "authors": "Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Longtao Huang, Hui Xue, Xiaofeng He, Jun Huang", "id": "2405.02659v1", "paper_url": "http://arxiv.org/abs/2405.02659v1", "repo": "null"}}