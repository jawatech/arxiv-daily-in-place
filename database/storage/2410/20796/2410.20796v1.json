{"2410.20796": {"publish_time": "2024-10-28", "title": "Rephrasing natural text data with different languages and quality levels for Large Language Model pre-training", "paper_summary": "Recently published work on rephrasing natural text data for pre-training LLMs\nhas shown promising results when combining the original dataset with the\nsynthetically rephrased data. We build upon previous work by replicating\nexisting results on C4 and extending them with our optimized rephrasing\npipeline to the English, German, Italian, and Spanish Oscar subsets of\nCulturaX. Our pipeline leads to increased performance on standard evaluation\nbenchmarks in both the mono- and multilingual setup. In addition, we provide a\ndetailed study of our pipeline, investigating the choice of the base dataset\nand LLM for the rephrasing, as well as the relationship between the model size\nand the performance after pre-training. By exploring data with different\nperceived quality levels, we show that gains decrease with higher quality.\nFurthermore, we find the difference in performance between model families to be\nbigger than between different model sizes. This highlights the necessity for\ndetailed tests before choosing an LLM to rephrase large amounts of data.\nMoreover, we investigate the effect of pre-training with synthetic data on\nsupervised fine-tuning. Here, we find increasing but inconclusive results that\nhighly depend on the used benchmark. These results (again) highlight the need\nfor better benchmarking setups. In summary, we show that rephrasing\nmultilingual and low-quality data is a very promising direction to extend LLM\npre-training data.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u53d1\u8868\u7684\u5173\u4e8e\u4e3a LLM \u9884\u8bad\u7ec3\u91cd\u65b0\u8868\u8ff0\u81ea\u7136\u6587\u672c\u6570\u636e\u7684\u8457\u4f5c\u5728\u5c06\u539f\u59cb\u6570\u636e\u96c6\u4e0e\u5408\u6210\u91cd\u65b0\u8868\u8ff0\u7684\u6570\u636e\u76f8\u7ed3\u5408\u65f6\u663e\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002\u6211\u4eec\u901a\u8fc7\u590d\u5236 C4 \u4e0a\u7684\u73b0\u6709\u7ed3\u679c\u5e76\u5c06\u5176\u6269\u5c55\u5230 CulturaX \u7684\u82f1\u8bed\u3001\u5fb7\u8bed\u3001\u610f\u5927\u5229\u8bed\u548c\u897f\u73ed\u7259\u8bed Oscar \u5b50\u96c6\uff0c\u4ee5\u4f18\u5316\u6211\u4eec\u7684\u91cd\u65b0\u8868\u8ff0\u7ba1\u9053\uff0c\u4ece\u800c\u5efa\u7acb\u5728\u4ee5\u524d\u7684\u5de5\u4f5c\u4e4b\u4e0a\u3002\u6211\u4eec\u7684\u7ba1\u9053\u63d0\u9ad8\u4e86\u5355\u8bed\u548c\u591a\u8bed\u8bbe\u7f6e\u4e2d\u6807\u51c6\u8bc4\u4f30\u57fa\u51c6\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u7ba1\u9053\u8be6\u7ec6\u7814\u7a76\uff0c\u8c03\u67e5\u4e86\u91cd\u65b0\u8868\u8ff0\u7684\u57fa\u7840\u6570\u636e\u96c6\u548c LLM \u7684\u9009\u62e9\uff0c\u4ee5\u53ca\u6a21\u578b\u5927\u5c0f\u4e0e\u9884\u8bad\u7ec3\u540e\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u63a2\u7d22\u5177\u6709\u4e0d\u540c\u611f\u77e5\u8d28\u91cf\u6c34\u5e73\u7684\u6570\u636e\uff0c\u6211\u4eec\u53d1\u73b0\u589e\u76ca\u4f1a\u968f\u7740\u8d28\u91cf\u7684\u63d0\u9ad8\u800c\u964d\u4f4e\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\u6a21\u578b\u7cfb\u5217\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u5927\u4e8e\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u8fd9\u7a81\u51fa\u4e86\u5728\u9009\u62e9 LLM \u91cd\u65b0\u8868\u8ff0\u5927\u91cf\u6570\u636e\u4e4b\u524d\u8fdb\u884c\u8be6\u7ec6\u6d4b\u8bd5\u7684\u5fc5\u8981\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8c03\u67e5\u4e86\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\u5bf9\u76d1\u7763\u5fae\u8c03\u7684\u5f71\u54cd\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u53d1\u73b0\u589e\u52a0\u4f46\u5c1a\u65e0\u5b9a\u8bba\u7684\u7ed3\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6240\u4f7f\u7528\u7684\u57fa\u51c6\u3002\u8fd9\u4e9b\u7ed3\u679c\uff08\u518d\u6b21\uff09\u5f3a\u8c03\u4e86\u5bf9\u66f4\u597d\u7684\u57fa\u51c6\u8bbe\u7f6e\u7684\u9700\u6c42\u3002\u603b\u4e4b\uff0c\u6211\u4eec\u8868\u660e\uff0c\u91cd\u65b0\u8868\u8ff0\u591a\u8bed\u8a00\u548c\u4f4e\u8d28\u91cf\u6570\u636e\u662f\u6269\u5c55 LLM \u9884\u8bad\u7ec3\u6570\u636e\u7684\u975e\u5e38\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002</paragraph>", "author": "Michael Pieler et.al.", "authors": "Michael Pieler, Marco Bellagente, Hannah Teufel, Duy Phung, Nathan Cooper, Jonathan Tow, Paulo Rocha, Reshinth Adithyan, Zaid Alyafeai, Nikhil Pinnaparaju, Maksym Zhuravinskyi, Carlos Riquelme", "id": "2410.20796v1", "paper_url": "http://arxiv.org/abs/2410.20796v1", "repo": "null"}}