{"2406.02021": {"publish_time": "2024-06-04", "title": "MetaMixer Is All You Need", "paper_summary": "Transformer, composed of self-attention and Feed-Forward Network, has\nrevolutionized the landscape of network design across various vision tasks. FFN\nis a versatile operator seamlessly integrated into nearly all AI models to\neffectively harness rich representations. Recent works also show that FFN\nfunctions like key-value memories. Thus, akin to the query-key-value mechanism\nwithin self-attention, FFN can be viewed as a memory network, where the input\nserves as query and the two projection weights operate as keys and values,\nrespectively. We hypothesize that the importance lies in query-key-value\nframework itself rather than in self-attention. To verify this, we propose\nconverting self-attention into a more FFN-like efficient token mixer with only\nconvolutions while retaining query-key-value framework, namely FFNification.\nSpecifically, FFNification replaces query-key and attention coefficient-value\ninteractions with large kernel convolutions and adopts GELU activation function\ninstead of softmax. The derived token mixer, FFNified attention, serves as\nkey-value memories for detecting locally distributed spatial patterns, and\noperates in the opposite dimension to the ConvNeXt block within each\ncorresponding sub-operation of the query-key-value framework. Building upon the\nabove two modules, we present a family of Fast-Forward Networks. Our FFNet\nachieves remarkable performance improvements over previous state-of-the-art\nmethods across a wide range of tasks. The strong and general performance of our\nproposed method validates our hypothesis and leads us to introduce MetaMixer, a\ngeneral mixer architecture that does not specify sub-operations within the\nquery-key-value framework. We show that using only simple operations like\nconvolution and GELU in the MetaMixer can achieve superior performance.", "paper_summary_zh": "<paragraph>Transformer \u7531\u81ea\u6ce8\u610f\u529b\u548c\u524d\u9988\u7f51\u7edc\u7ec4\u6210\uff0c\u5f7b\u5e95\u6539\u53d8\u4e86\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u7684\u7f51\u7edc\u8bbe\u8ba1\u683c\u5c40\u3002FFN \u662f\u4e00\u79cd\u591a\u529f\u80fd\u8fd0\u7b97\u5b50\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u51e0\u4e4e\u6240\u6709 AI \u6a21\u578b\u4e2d\uff0c\u4ee5\u6709\u6548\u5229\u7528\u4e30\u5bcc\u7684\u8868\u793a\u3002\u6700\u8fd1\u7684\u7814\u7a76\u8fd8\u8868\u660e\uff0cFFN \u7684\u529f\u80fd\u7c7b\u4f3c\u4e8e\u952e\u503c\u5b58\u50a8\u5668\u3002\u56e0\u6b64\uff0c\u7c7b\u4f3c\u4e8e\u81ea\u6ce8\u610f\u529b\u4e2d\u7684\u67e5\u8be2\u952e\u503c\u673a\u5236\uff0cFFN \u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u8bb0\u5fc6\u7f51\u7edc\uff0c\u5176\u4e2d\u8f93\u5165\u5145\u5f53\u67e5\u8be2\uff0c\u4e24\u4e2a\u6295\u5f71\u6743\u91cd\u5206\u522b\u5145\u5f53\u952e\u548c\u503c\u3002\u6211\u4eec\u5047\u8bbe\u91cd\u8981\u6027\u5728\u4e8e\u67e5\u8be2\u952e\u503c\u6846\u67b6\u672c\u8eab\uff0c\u800c\u4e0d\u662f\u81ea\u6ce8\u610f\u529b\u3002\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u5efa\u8bae\u5c06\u81ea\u6ce8\u610f\u529b\u8f6c\u6362\u4e3a\u4ec5\u4f7f\u7528\u5377\u79ef\u7684\u66f4\u50cf FFN \u7684\u9ad8\u6548\u4ee4\u724c\u6df7\u5408\u5668\uff0c\u540c\u65f6\u4fdd\u7559\u67e5\u8be2\u952e\u503c\u6846\u67b6\uff0c\u5373 FFN \u5316\u3002\u5177\u4f53\u6765\u8bf4\uff0cFFN \u5316\u7528\u5927\u6838\u5377\u79ef\u66ff\u6362\u67e5\u8be2\u952e\u548c\u6ce8\u610f\u529b\u7cfb\u6570\u503c\u4ea4\u4e92\uff0c\u5e76\u91c7\u7528 GELU \u6fc0\u6d3b\u51fd\u6570\u800c\u4e0d\u662f softmax\u3002\u6d3e\u751f\u7684\u4ee4\u724c\u6df7\u5408\u5668\uff0cFFN \u5316\u6ce8\u610f\u529b\uff0c\u7528\u4f5c\u68c0\u6d4b\u5c40\u90e8\u5206\u5e03\u7684\u7a7a\u95f4\u6a21\u5f0f\u7684\u952e\u503c\u5b58\u50a8\u5668\uff0c\u5e76\u5728\u67e5\u8be2\u952e\u503c\u6846\u67b6\u7684\u6bcf\u4e2a\u76f8\u5e94\u5b50\u64cd\u4f5c\u4e2d\u4e0e ConvNeXt \u5757\u5728\u76f8\u53cd\u7684\u7ef4\u5ea6\u4e0a\u64cd\u4f5c\u3002\u57fa\u4e8e\u4e0a\u8ff0\u4e24\u4e2a\u6a21\u5757\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5feb\u901f\u524d\u9988\u7f51\u7edc\u7cfb\u5217\u3002\u6211\u4eec\u7684 FFNet \u5728\u5e7f\u6cdb\u7684\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5bf9\u4ee5\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u663e\u7740\u6027\u80fd\u6539\u8fdb\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u5f3a\u5927\u800c\u901a\u7528\u7684\u6027\u80fd\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u5047\u8bbe\uff0c\u5e76\u5f15\u5bfc\u6211\u4eec\u5f15\u5165\u4e86 MetaMixer\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u7528\u6df7\u5408\u5668\u67b6\u6784\uff0c\u4e0d\u6307\u5b9a\u67e5\u8be2\u952e\u503c\u6846\u67b6\u5185\u7684\u5b50\u64cd\u4f5c\u3002\u6211\u4eec\u8868\u660e\uff0c\u5728 MetaMixer \u4e2d\u4ec5\u4f7f\u7528\u5377\u79ef\u548c GELU \u7b49\u7b80\u5355\u64cd\u4f5c\u5c31\u53ef\u4ee5\u5b9e\u73b0\u5353\u8d8a\u7684\u6027\u80fd\u3002</paragraph>", "author": "Seokju Yun et.al.", "authors": "Seokju Yun, Dongheon Lee, Youngmin Ro", "id": "2406.02021v1", "paper_url": "http://arxiv.org/abs/2406.02021v1", "repo": "https://github.com/ysj9909/ffnet"}}