{"2408.01420": {"publish_time": "2024-08-02", "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs", "paper_summary": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5927\u91cf\u7684\u6587\u672c\u8cc7\u6599\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u54c1\u8cea\u63a7\u7ba1\u6709\u9650\u3002\u56e0\u6b64\uff0cLLM \u53ef\u80fd\u6703\u8868\u73fe\u51fa\u610f\u5916\u751a\u81f3\u6709\u5bb3\u7684\u884c\u70ba\uff0c\u4f8b\u5982\u6d29\u9732\u8cc7\u8a0a\u3001\u5047\u65b0\u805e\u6216\u4ec7\u6068\u8a00\u8ad6\u3002\u5c0d\u7b56\u901a\u5e38\u7a31\u70ba\u504f\u597d\u5c0d\u9f4a\uff0c\u5305\u62ec\u4f7f\u7528\u7cbe\u5fc3\u88fd\u4f5c\u7684\u6240\u9700\u884c\u70ba\u7bc4\u4f8b\u5fae\u8abf\u9810\u8a13\u7df4\u7684 LLM\u3002\u5373\u4f7f\u5982\u6b64\uff0c\u5be6\u8b49\u8b49\u64da\u986f\u793a\uff0c\u504f\u597d\u5c0d\u9f4a\u7684 LLM \u4ecd\u53ef\u80fd\u53d7\u5230\u5f15\u8a98\u800c\u7522\u751f\u6709\u5bb3\u884c\u70ba\u3002\u9019\u7a2e\u6240\u8b02\u7684 LLM \u8d8a\u7344\u901a\u5e38\u662f\u900f\u904e\u5c0d LLM \u7684\u8f38\u5165\u63d0\u793a\u9032\u884c\u5c0d\u6297\u6027\u4fee\u6539\u4f86\u5be6\u73fe\u3002\u6211\u5011\u7684\u8ad6\u6587\u5f9e\u7d71\u8a08\u89d2\u5ea6\u63d0\u4f9b\u4e86\u5c0d\u504f\u597d\u5c0d\u9f4a\u548c\u8d8a\u7344\u73fe\u8c61\u7684\u7406\u8ad6\u898b\u89e3\u3002\u5728\u6211\u5011\u7684\u67b6\u69cb\u4e0b\uff0c\u6211\u5011\u9996\u5148\u5c55\u793a\u4e86\u5982\u679c\u8a13\u7df4\u8a9e\u6599\u5eab\u4e2d\u5b58\u5728\u6709\u5bb3\u884c\u70ba\uff0c\u9810\u8a13\u7df4\u7684 LLM \u5c07\u6703\u6a21\u4eff\u9019\u7a2e\u884c\u70ba\u3002\u5728\u540c\u4e00\u500b\u67b6\u69cb\u4e0b\uff0c\u6211\u5011\u63a5\u8457\u5f15\u5165\u4e86\u4e00\u500b\u5c0d\u9f4a\u7684\u7d71\u8a08\u6982\u5ff5\uff0c\u4e26\u5c0d\u8d8a\u7344\u6a5f\u7387\u9032\u884c\u4e0b\u9650\u7d04\u675f\uff0c\u986f\u793a\u5728\u5408\u7406\u7684\u5047\u8a2d\u4e0b\uff0c\u8d8a\u7344\u662f\u7121\u6cd5\u9810\u9632\u7684\u3002\u6839\u64da\u6211\u5011\u7684\u898b\u89e3\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5c0d\u76ee\u524d\u666e\u904d\u63a1\u7528\u7684\u5c0d\u9f4a\u7b56\u7565 RLHF \u7684\u4fee\u6539\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c0d RLHF \u76ee\u6a19\u9032\u884c\u4e86\u4e00\u500b\u7c21\u55ae\u7684\u4fee\u6539\uff0c\u6211\u5011\u7a31\u4e4b\u70ba E-RLHF\uff0c\u5176\u76ee\u7684\u662f\u63d0\u9ad8\u5b89\u5168\u56de\u61c9\u7684\u53ef\u80fd\u6027\u3002E-RLHF \u6c92\u6709\u5e36\u4f86\u984d\u5916\u7684\u8a13\u7df4\u6210\u672c\uff0c\u4e26\u4e14\u8207\u5176\u4ed6\u65b9\u6cd5\u76f8\u5bb9\u3002\u6839\u64da\u7d93\u9a57\uff0c\u6211\u5011\u8b49\u660e E-RLHF \u5728 AdvBench \u548c HarmBench \u5c08\u6848\u63d0\u51fa\u7684\u6240\u6709\u5c0d\u9f4a\u554f\u984c\u4e0a\u90fd\u512a\u65bc RLHF\uff0c\u540c\u6642\u4e0d\u6703\u72a7\u7272\u7531 MT-Bench \u5c08\u6848\u6e2c\u91cf\u7684\u6a21\u578b\u6548\u80fd\u3002", "author": "Jingtong Su et.al.", "authors": "Jingtong Su, Julia Kempe, Karen Ullrich", "id": "2408.01420v1", "paper_url": "http://arxiv.org/abs/2408.01420v1", "repo": "null"}}