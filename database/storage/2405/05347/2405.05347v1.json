{"2405.05347": {"publish_time": "2024-05-08", "title": "Benchmarking Educational Program Repair", "paper_summary": "The emergence of large language models (LLMs) has sparked enormous interest\ndue to their potential application across a range of educational tasks. For\nexample, recent work in programming education has used LLMs to generate\nlearning resources, improve error messages, and provide feedback on code.\nHowever, one factor that limits progress within the field is that much of the\nresearch uses bespoke datasets and different evaluation metrics, making direct\ncomparisons between results unreliable. Thus, there is a pressing need for\nstandardization and benchmarks that facilitate the equitable comparison of\ncompeting approaches. One task where LLMs show great promise is program repair,\nwhich can be used to provide debugging support and next-step hints to students.\nIn this article, we propose a novel educational program repair benchmark. We\ncurate two high-quality publicly available programming datasets, present a\nunified evaluation procedure introducing a novel evaluation metric rouge@k for\napproximating the quality of repairs, and evaluate a set of five recent models\nto establish baseline performance.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\u5f15\u8d77\u4e86\u6975\u5927\u7684\u8208\u8da3\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u5404\u7a2e\u6559\u80b2\u4efb\u52d9\u4e2d\u5177\u6709\u6f5b\u5728\u7684\u61c9\u7528\u3002\u4f8b\u5982\uff0c\u6700\u8fd1\u5728\u7a0b\u5f0f\u8a2d\u8a08\u6559\u80b2\u4e2d\u7684\u5de5\u4f5c\u5df2\u4f7f\u7528 LLM \u4f86\u7522\u751f\u5b78\u7fd2\u8cc7\u6e90\u3001\u6539\u5584\u932f\u8aa4\u8a0a\u606f\uff0c\u4e26\u63d0\u4f9b\u7a0b\u5f0f\u78bc\u56de\u994b\u3002\u7136\u800c\uff0c\u9650\u5236\u8a72\u9818\u57df\u9032\u5c55\u7684\u4e00\u500b\u56e0\u7d20\u662f\uff0c\u8a31\u591a\u7814\u7a76\u4f7f\u7528\u5ba2\u88fd\u5316\u8cc7\u6599\u96c6\u548c\u4e0d\u540c\u7684\u8a55\u4f30\u6307\u6a19\uff0c\u9019\u4f7f\u5f97\u7d50\u679c\u4e4b\u9593\u7684\u76f4\u63a5\u6bd4\u8f03\u4e0d\u53ef\u9760\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u6a19\u6e96\u5316\u548c\u57fa\u6e96\uff0c\u4ee5\u4fc3\u9032\u7af6\u722d\u65b9\u6cd5\u7684\u516c\u5e73\u6bd4\u8f03\u3002LLM \u986f\u73fe\u51fa\u5de8\u5927\u6f5b\u529b\u7684\u5176\u4e2d\u4e00\u9805\u4efb\u52d9\u662f\u7a0b\u5f0f\u4fee\u5fa9\uff0c\u53ef\u7528\u65bc\u63d0\u4f9b\u9664\u932f\u652f\u63f4\u548c\u4e0b\u4e00\u6b65\u63d0\u793a\u7d66\u5b78\u751f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u6559\u80b2\u7a0b\u5f0f\u4fee\u5fa9\u57fa\u6e96\u3002\u6211\u5011\u7b56\u5283\u4e86\u5169\u500b\u9ad8\u54c1\u8cea\u7684\u516c\u958b\u7a0b\u5f0f\u8a2d\u8a08\u8cc7\u6599\u96c6\uff0c\u63d0\u51fa\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u8a55\u4f30\u7a0b\u5e8f\uff0c\u4e26\u5f15\u5165\u4e86\u65b0\u7684\u8a55\u4f30\u6307\u6a19 Rouge@k \u4f86\u8fd1\u4f3c\u4fee\u5fa9\u54c1\u8cea\uff0c\u4e26\u8a55\u4f30\u4e86\u4e00\u7d44\u4e94\u500b\u6700\u8fd1\u7684\u6a21\u578b\u4ee5\u5efa\u7acb\u57fa\u6e96\u6548\u80fd\u3002", "author": "Charles Koutcheme et.al.", "authors": "Charles Koutcheme, Nicola Dainese, Sami Sarsa, Juho Leinonen, Arto Hellas, Paul Denny", "id": "2405.05347v1", "paper_url": "http://arxiv.org/abs/2405.05347v1", "repo": "https://github.com/koutchemecharles/gaied_nips23"}}