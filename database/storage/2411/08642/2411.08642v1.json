{"2411.08642": {"publish_time": "2024-11-13", "title": "Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models", "paper_summary": "The remarkable progress in neural-network-driven visual data generation,\nespecially with neural rendering techniques like Neural Radiance Fields and 3D\nGaussian splatting, offers a powerful alternative to GANs and diffusion models.\nThese methods can produce high-fidelity images and lifelike avatars,\nhighlighting the need for robust detection methods. In response, an\nunsupervised training technique is proposed that enables the model to extract\ncomprehensive features from the Fourier spectrum magnitude, thereby overcoming\nthe challenges of reconstructing the spectrum due to its centrosymmetric\nproperties. By leveraging the spectral domain and dynamically combining it with\nspatial domain information, we create a robust multimodal detector that\ndemonstrates superior generalization capabilities in identifying challenging\nsynthetic images generated by the latest image synthesis techniques. To address\nthe absence of a 3D neural rendering-based fake image database, we develop a\ncomprehensive database that includes images generated by diverse neural\nrendering techniques, providing a robust foundation for evaluating and\nadvancing detection methods.", "paper_summary_zh": "\u795e\u7d93\u7db2\u8def\u9a45\u52d5\u7684\u8996\u89ba\u8cc7\u6599\u751f\u6210\u6280\u8853\u9032\u5c55\u986f\u8457\uff0c\n\u7279\u5225\u662f\u50cf\u795e\u7d93\u8f3b\u7167\u5834\u548c 3D \u9ad8\u65af\u5674\u5c04\u7b49\u795e\u7d93\u6e32\u67d3\u6280\u8853\uff0c\u70ba GAN \u548c\u64f4\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u5f37\u800c\u6709\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\n\u9019\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u7522\u751f\u9ad8\u4fdd\u771f\u5f71\u50cf\u548c\u903c\u771f\u7684\u982d\u50cf\uff0c\n\u7a81\u986f\u4e86\u5c0d\u7a69\u5065\u6aa2\u6e2c\u65b9\u6cd5\u7684\u9700\u6c42\u3002\u70ba\u6b64\uff0c\n\u63d0\u51fa\u4e86\u4e00\u7a2e\u7121\u76e3\u7763\u8a13\u7df4\u6280\u8853\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u5f9e\u5085\u7acb\u8449\u983b\u8b5c\u5e45\u5ea6\u4e2d\u63d0\u53d6\u5168\u9762\u7684\u7279\u5fb5\uff0c\u5f9e\u800c\u514b\u670d\u4e86\u7531\u65bc\u5176\u4e2d\u5fc3\u5c0d\u7a31\u6027\u8cea\u800c\u91cd\u5efa\u983b\u8b5c\u7684\u6311\u6230\u3002\u901a\u904e\u5229\u7528\u983b\u8b5c\u57df\u4e26\u52d5\u614b\u5730\u5c07\u5176\u8207\u7a7a\u9593\u57df\u8cc7\u8a0a\u76f8\u7d50\u5408\uff0c\u6211\u5011\u5275\u9020\u4e86\u4e00\u500b\u7a69\u5065\u7684\u591a\u6a21\u614b\u6aa2\u6e2c\u5668\uff0c\u5728\u8b58\u5225\u6700\u65b0\u5f71\u50cf\u5408\u6210\u6280\u8853\u751f\u6210\u7684\u5177\u6709\u6311\u6230\u6027\u7684\u5408\u6210\u5f71\u50cf\u65b9\u9762\u8868\u73fe\u51fa\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u57fa\u65bc 3D \u795e\u7d93\u6e32\u67d3\u7684\u5047\u5f71\u50cf\u8cc7\u6599\u5eab\u7684\u7f3a\u5931\u554f\u984c\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u5168\u9762\u7684\u8cc7\u6599\u5eab\uff0c\u5176\u4e2d\u5305\u62ec\u7531\u5404\u7a2e\u795e\u7d93\u6e32\u67d3\u6280\u8853\u751f\u6210\u7684\u5f71\u50cf\uff0c\u70ba\u8a55\u4f30\u548c\u63a8\u9032\u6aa2\u6e2c\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7a69\u5065\u7684\u57fa\u790e\u3002", "author": "Chengdong Dong et.al.", "authors": "Chengdong Dong, Vijayakumar Bhagavatula, Zhenyu Zhou, Ajay Kumar", "id": "2411.08642v1", "paper_url": "http://arxiv.org/abs/2411.08642v1", "repo": "null"}}