
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-30**|**DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights**|Liana Mikaelyan et.al.|[2501.18596v1](http://arxiv.org/abs/2501.18596v1)|null|
|**2025-01-30**|**Diffusion Autoencoders are Scalable Image Tokenizers**|Yinbo Chen et.al.|[2501.18593v1](http://arxiv.org/abs/2501.18593v1)|null|
|**2025-01-30**|**Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models**|Hao Dong et.al.|[2501.18592v1](http://arxiv.org/abs/2501.18592v1)|[link](https://github.com/donghao51/awesome-multimodal-adaptation)|
|**2025-01-30**|**Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching**|David Chuan-En Lin et.al.|[2501.18588v1](http://arxiv.org/abs/2501.18588v1)|null|
|**2025-01-30**|**Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs**|Yue Wang et.al.|[2501.18585v1](http://arxiv.org/abs/2501.18585v1)|null|
|**2025-01-30**|**R.I.P.: Better Models by Survival of the Fittest Prompts**|Ping Yu et.al.|[2501.18578v1](http://arxiv.org/abs/2501.18578v1)|null|
|**2025-01-30**|**Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling**|Dan M. Kluger et.al.|[2501.18577v1](http://arxiv.org/abs/2501.18577v1)|null|
|**2025-01-30**|**BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended Videos**|Lehao Lin et.al.|[2501.18565v1](http://arxiv.org/abs/2501.18565v1)|null|
|**2025-01-30**|**Semantic Web and Creative AI -- A Technical Report from ISWS 2023**|Raia Abu Ahmad et.al.|[2501.18542v1](http://arxiv.org/abs/2501.18542v1)|null|
|**2025-01-30**|**Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method**|Peter Baile Chen et.al.|[2501.18539v1](http://arxiv.org/abs/2501.18539v1)|null|
|**2025-01-30**|**A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre**|Tasfia Noor Chowdhury et.al.|[2501.18535v1](http://arxiv.org/abs/2501.18535v1)|null|
|**2025-01-30**|**Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models**|Yi Ding et.al.|[2501.18533v1](http://arxiv.org/abs/2501.18533v1)|null|
|**2025-01-30**|**Differentially Private Steering for Large Language Model Alignment**|Anmol Goel et.al.|[2501.18532v1](http://arxiv.org/abs/2501.18532v1)|[link](https://github.com/ukplab/iclr2025-psa)|
|**2025-01-30**|**Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch**|Arthur Douillard et.al.|[2501.18512v1](http://arxiv.org/abs/2501.18512v1)|null|
|**2025-01-30**|**WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training**|Benjamin Feuer et.al.|[2501.18511v1](http://arxiv.org/abs/2501.18511v1)|[link](https://github.com/penfever/wildchat-50m)|
|**2025-01-30**|**CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction**|Peter J. Bentley et.al.|[2501.18504v1](http://arxiv.org/abs/2501.18504v1)|null|
|**2025-01-30**|**GuardReasoner: Towards Reasoning-based LLM Safeguards**|Yue Liu et.al.|[2501.18492v1](http://arxiv.org/abs/2501.18492v1)|null|
|**2025-01-30**|**CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization**|Yanxia Deng et.al.|[2501.18475v1](http://arxiv.org/abs/2501.18475v1)|[link](https://github.com/AozhongZhang/CLoQ)|
|**2025-01-30**|**Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking**|Eduardo Davalos et.al.|[2501.18468v1](http://arxiv.org/abs/2501.18468v1)|null|
|**2025-01-30**|**CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language Model Question Answering**|Yumeng Wang et.al.|[2501.18457v1](http://arxiv.org/abs/2501.18457v1)|[link](https://github.com/Alexwwwwww/CALM)|
|**2025-01-30**|**Conversation Games and a Strategic View of the Turing Test**|Kaveh Aryan et.al.|[2501.18455v1](http://arxiv.org/abs/2501.18455v1)|null|
|**2025-01-30**|**Clustering Properties of Self-Supervised Learning**|Xi Weng et.al.|[2501.18452v1](http://arxiv.org/abs/2501.18452v1)|null|
|**2025-01-30**|**o3-mini vs DeepSeek-R1: Which One is Safer?**|Aitor Arrieta et.al.|[2501.18438v1](http://arxiv.org/abs/2501.18438v1)|null|
|**2025-01-30**|**GENIE: Generative Note Information Extraction model for structuring EHR data**|Huaiyuan Ying et.al.|[2501.18435v1](http://arxiv.org/abs/2501.18435v1)|null|
|**2025-01-30**|**Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms**|Eneko Osaba et.al.|[2501.18432v1](http://arxiv.org/abs/2501.18432v1)|null|
|**2025-01-30**|**Guaranteed confidence-band enclosures for PDE surrogates**|Ander Gray et.al.|[2501.18426v1](http://arxiv.org/abs/2501.18426v1)|null|
|**2025-01-30**|**GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing**|Shuyin Xia et.al.|[2501.18413v1](http://arxiv.org/abs/2501.18413v1)|[link](https://github.com/lianxiaoyu724/GBFRS)|
|**2025-01-30**|**Efficient Transformer for High Resolution Image Motion Deblurring**|Amanturdieva Akmaral et.al.|[2501.18403v1](http://arxiv.org/abs/2501.18403v1)|[link](https://github.com/hamzafer/image-deblurring)|
|**2025-01-30**|**A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**|Yifan Wang et.al.|[2501.18367v1](http://arxiv.org/abs/2501.18367v1)|null|
|**2025-01-30**|**RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects**|Yiteng Tu et.al.|[2501.18365v1](http://arxiv.org/abs/2501.18365v1)|[link](https://github.com/StibiumT16/Robust-Fine-tuning)|
|**2025-01-30**|**MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**|Yuxin Zuo et.al.|[2501.18362v1](http://arxiv.org/abs/2501.18362v1)|null|
|**2025-01-30**|**State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence**|Thea Aviss et.al.|[2501.18356v1](http://arxiv.org/abs/2501.18356v1)|null|
|**2025-01-30**|**Transfer Learning of Surrogate Models: Integrating Domain Warping and Affine Transformations**|Shuaiqun Pan et.al.|[2501.18344v1](http://arxiv.org/abs/2501.18344v1)|null|
|**2025-01-30**|**CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**|Yicheng Wu et.al.|[2501.18328v1](http://arxiv.org/abs/2501.18328v1)|null|
|**2025-01-30**|**A Video-grounded Dialogue Dataset and Metric for Event-driven Activities**|Wiradee Imrattanatrai et.al.|[2501.18324v1](http://arxiv.org/abs/2501.18324v1)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320v1](http://arxiv.org/abs/2501.18320v1)|[link](https://github.com/advantages/MAG-RAG-for-SASP)|
|**2025-01-30**|**Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis**|Haoxiong Liu et.al.|[2501.18310v1](http://arxiv.org/abs/2501.18310v1)|[link](https://github.com/haoxiongliu/proofaug)|
|**2025-01-30**|**Model-Free RL Agents Demonstrate System 1-Like Intentionality**|Hal Ashton et.al.|[2501.18299v1](http://arxiv.org/abs/2501.18299v1)|null|
|**2025-01-30**|**A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**|Shayli Farshchiha et.al.|[2501.18294v1](http://arxiv.org/abs/2501.18294v1)|null|
|**2025-01-30**|**Citation Recommendation based on Argumentative Zoning of User Queries**|Shutian Ma et.al.|[2501.18292v1](http://arxiv.org/abs/2501.18292v1)|null|
|**2025-01-30**|**CueTip: An Interactive and Explainable Physics-aware Pool Assistant**|Sean Memery et.al.|[2501.18291v1](http://arxiv.org/abs/2501.18291v1)|null|
|**2025-01-30**|**Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: A Large-Scale Exploratory Study with Large Language Models**|Jennifer D'Souza et.al.|[2501.18287v1](http://arxiv.org/abs/2501.18287v1)|null|
|**2025-01-30**|**Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models**|Haoyu Liang et.al.|[2501.18280v1](http://arxiv.org/abs/2501.18280v1)|null|
|**2025-01-30**|**Pre-Trained Vision-Language Model Selection and Reuse for Downstream Tasks**|Hao-Zhe Tan et.al.|[2501.18271v1](http://arxiv.org/abs/2501.18271v1)|null|
|**2025-01-30**|**MAMS: Model-Agnostic Module Selection Framework for Video Captioning**|Sangho Lee et.al.|[2501.18269v1](http://arxiv.org/abs/2501.18269v1)|null|
|**2025-01-30**|**Collecting Cost-Effective, High-Quality Truthfulness Assessments with LLM Summarized Evidence**|Kevin Roitero et.al.|[2501.18265v1](http://arxiv.org/abs/2501.18265v1)|null|
|**2025-01-30**|**How to Select Datapoints for Efficient Human Evaluation of NLG Models?**|Vilém Zouhar et.al.|[2501.18251v1](http://arxiv.org/abs/2501.18251v1)|[link](https://github.com/zouharvi/subset2evaluate)|
|**2025-01-30**|**Statistical multi-metric evaluation and visualization of LLM system predictive performance**|Samuel Ackerman et.al.|[2501.18243v1](http://arxiv.org/abs/2501.18243v1)|null|
|**2025-01-30**|**Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**|Malte Tölle et.al.|[2501.18237v1](http://arxiv.org/abs/2501.18237v1)|null|
|**2025-01-30**|**Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark**|Manuel F. Mollon et.al.|[2501.18223v1](http://arxiv.org/abs/2501.18223v1)|null|
|**2025-01-30**|**Contextually Structured Token Dependency Encoding for Large Language Models**|James Blades et.al.|[2501.18205v1](http://arxiv.org/abs/2501.18205v1)|null|
|**2025-01-30**|**On Scaling Neurosymbolic Programming through Guided Logical Inference**|Thomas Jean-Michel Valentin et.al.|[2501.18202v1](http://arxiv.org/abs/2501.18202v1)|null|
|**2025-01-30**|**HKAN: Hierarchical Kolmogorov-Arnold Network without Backpropagation**|Grzegorz Dudek et.al.|[2501.18199v1](http://arxiv.org/abs/2501.18199v1)|null|
|**2025-01-30**|**Economic Rationality under Specialization: Evidence of Decision Bias in AI Agents**|ShuiDe Wen et.al.|[2501.18190v1](http://arxiv.org/abs/2501.18190v1)|null|
|**2025-01-30**|**In-Context Learning of Polynomial Kernel Regression in Transformers with GLU Layers**|Haoyuan Sun et.al.|[2501.18187v1](http://arxiv.org/abs/2501.18187v1)|null|
|**2025-01-30**|**Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**|Wanlong Liu et.al.|[2501.18154v1](http://arxiv.org/abs/2501.18154v1)|null|
|**2025-01-30**|**Tensor Completion for Surrogate Modeling of Material Property Prediction**|Shaan Pakala et.al.|[2501.18137v1](http://arxiv.org/abs/2501.18137v1)|null|
|**2025-01-30**|**Entropy-Synchronized Neural Hashing for Unsupervised Ransomware Detection**|Peter Idliman et.al.|[2501.18131v1](http://arxiv.org/abs/2501.18131v1)|null|
|**2025-01-30**|**Unraveling the Capabilities of Language Models in News Summarization**|Abdurrahman Odabaşı et.al.|[2501.18128v1](http://arxiv.org/abs/2501.18128v1)|null|
|**2025-01-30**|**VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical Constraints**|Xinyu Wang et.al.|[2501.18122v1](http://arxiv.org/abs/2501.18122v1)|[link](https://github.com/1457756434/VQLTI)|
|**2025-01-30**|**Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**|Qika Lin et.al.|[2501.18119v1](http://arxiv.org/abs/2501.18119v1)|null|
|**2025-01-30**|**Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**|Min Hun Lee et.al.|[2501.18108v1](http://arxiv.org/abs/2501.18108v1)|null|
|**2025-01-30**|**Scaling Inference-Efficient Language Models**|Song Bian et.al.|[2501.18107v1](http://arxiv.org/abs/2501.18107v1)|null|
|**2025-01-30**|**Diverse Preference Optimization**|Jack Lanchantin et.al.|[2501.18101v1](http://arxiv.org/abs/2501.18101v1)|null|
|**2025-01-30**|**Panacea: Mitigating Harmful Fine-tuning for Large Language Models via Post-fine-tuning Perturbation**|Yibo Wang et.al.|[2501.18100v1](http://arxiv.org/abs/2501.18100v1)|[link](https://github.com/w-yibo/panacea)|
|**2025-01-30**|**Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge**|Swarnadeep Saha et.al.|[2501.18099v1](http://arxiv.org/abs/2501.18099v1)|null|
|**2025-01-30**|**LLMs can see and hear without any training**|Kumar Ashutosh et.al.|[2501.18096v1](http://arxiv.org/abs/2501.18096v1)|[link](https://github.com/facebookresearch/mils)|
|**2025-01-30**|**Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**|Pratik S. Sachdeva et.al.|[2501.18081v1](http://arxiv.org/abs/2501.18081v1)|null|
|**2025-01-30**|**Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**|Pir Bakhsh Khokhar et.al.|[2501.18071v1](http://arxiv.org/abs/2501.18071v1)|null|
|**2025-01-30**|**Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features**|Mathieu Calvat et.al.|[2501.18064v1](http://arxiv.org/abs/2501.18064v1)|null|
|**2025-01-30**|**FinanceQA: A Benchmark for Evaluating Financial Analysis Capabilities of Large Language Models**|Spencer Mateega et.al.|[2501.18062v1](http://arxiv.org/abs/2501.18062v1)|null|
|**2025-01-29**|**Current Pathology Foundation Models are unrobust to Medical Center Differences**|Edwin D. de Jong et.al.|[2501.18055v1](http://arxiv.org/abs/2501.18055v1)|null|
|**2025-01-29**|**SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders**|Bartosz Cywiński et.al.|[2501.18052v1](http://arxiv.org/abs/2501.18052v1)|null|
|**2025-01-29**|**From tools to thieves: Measuring and understanding public perceptions of AI through crowdsourced metaphors**|Myra Cheng et.al.|[2501.18045v1](http://arxiv.org/abs/2501.18045v1)|null|
|**2025-01-29**|**Digital Twin-Enabled Real-Time Control in Robotic Additive Manufacturing via Soft Actor-Critic Reinforcement Learning**|Matsive Ali et.al.|[2501.18016v1](http://arxiv.org/abs/2501.18016v1)|null|
|**2025-01-29**|**Anatomy Might Be All You Need: Forecasting What to Do During Surgery**|Gary Sarwin et.al.|[2501.18011v1](http://arxiv.org/abs/2501.18011v1)|null|
|**2025-01-29**|**Large Language Models Think Too Fast To Explore Effectively**|Lan Pan et.al.|[2501.18009v1](http://arxiv.org/abs/2501.18009v1)|null|
|**2025-01-29**|**Topological Signatures of Adversaries in Multimodal Alignments**|Minh Vu et.al.|[2501.18006v1](http://arxiv.org/abs/2501.18006v1)|null|
|**2025-01-29**|**InnerThoughts: Disentangling Representations and Predictions in Large Language Models**|Didier Chételat et.al.|[2501.17994v1](http://arxiv.org/abs/2501.17994v1)|null|
|**2025-01-29**|**Investigating the Monte-Carlo Tree Search Approach for the Job Shop Scheduling Problem**|Laurie Boveroux et.al.|[2501.17991v1](http://arxiv.org/abs/2501.17991v1)|null|
|**2025-01-29**|**Limits to AI Growth: The Ecological and Social Consequences of Scaling**|Eshta Bhardwaj et.al.|[2501.17980v1](http://arxiv.org/abs/2501.17980v1)|null|
|**2025-01-29**|**Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization**|Zishun Yu et.al.|[2501.17974v1](http://arxiv.org/abs/2501.17974v1)|null|
|**2025-01-29**|**Deep Ensembles Secretly Perform Empirical Bayes**|Gabriel Loaiza-Ganem et.al.|[2501.17917v1](http://arxiv.org/abs/2501.17917v1)|null|
|**2025-01-29**|**Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**|Zijie Liu et.al.|[2501.17860v1](http://arxiv.org/abs/2501.17860v1)|null|
|**2025-01-29**|**Improving Your Model Ranking on Chatbot Arena by Vote Rigging**|Rui Min et.al.|[2501.17858v1](http://arxiv.org/abs/2501.17858v1)|[link](https://github.com/sail-sg/rigging-chatbotarena)|
|**2025-01-29**|**GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**|Ziang Liu et.al.|[2501.17855v1](http://arxiv.org/abs/2501.17855v1)|null|
|**2025-01-29**|**From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**|Junseok Park et.al.|[2501.17842v1](http://arxiv.org/abs/2501.17842v1)|null|
|**2025-01-29**|**Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**|Pouya Pezeshkpour et.al.|[2501.17840v1](http://arxiv.org/abs/2501.17840v1)|[link](https://github.com/megagonlabs/insight_miner)|
|**2025-01-29**|**A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**|Mousumi Akter et.al.|[2501.17830v1](http://arxiv.org/abs/2501.17830v1)|null|
|**2025-01-29**|**U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**|Md Kaykobad Reza et.al.|[2501.17823v1](http://arxiv.org/abs/2501.17823v1)|null|
|**2025-01-29**|**Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**|Sobhan Hemati et.al.|[2501.17822v1](http://arxiv.org/abs/2501.17822v1)|null|
|**2025-01-29**|**P-TAME: Explain Any Image Classifier with Trained Perturbations**|Mariano V. Ntrougkas et.al.|[2501.17813v1](http://arxiv.org/abs/2501.17813v1)|null|
|**2025-01-29**|**Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**|Xiaokang Chen et.al.|[2501.17811v1](http://arxiv.org/abs/2501.17811v1)|[link](https://github.com/deepseek-ai/janus)|
|**2025-01-29**|**BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**|Chan-Jan Hsu et.al.|[2501.17790v1](http://arxiv.org/abs/2501.17790v1)|null|
|**2025-01-29**|**Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**|Yu-Fei Shih et.al.|[2501.17785v1](http://arxiv.org/abs/2501.17785v1)|null|
|**2025-01-29**|**2SSP: A Two-Stage Framework for Structured Pruning of LLMs**|Fabrizio Sandri et.al.|[2501.17771v1](http://arxiv.org/abs/2501.17771v1)|[link](https://github.com/fabriziosandri/2ssp)|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**|Keshav Bhandari et.al.|[2501.17759v1](http://arxiv.org/abs/2501.17759v1)|[link](https://github.com/keshavbhandari/yinyang)|
|**2025-01-29**|**Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**|Aitor Arrieta et.al.|[2501.17749v1](http://arxiv.org/abs/2501.17749v1)|null|
|**2025-01-29**|**Exact characterization of ε-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**|Alberto Carlevaro et.al.|[2501.17731v1](http://arxiv.org/abs/2501.17731v1)|null|

#### Abstracts
##### **DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights**
2501.18596v1 by Liana Mikaelyan, Ayyoob Imani, Mathew Salvaris, Parth Pathak, Mohsen Fayyaz

We introduce DeltaLLM, a new post-training compression technique to reduce
the memory footprint of LLMs. We propose an alternative way of structuring LLMs
with weight sharing between layers in subsequent Transformer blocks, along with
additional low-rank difference matrices between them. For training, we adopt
the progressing module replacement method and show that the lightweight
training of the low-rank modules with approximately 30M-40M tokens is
sufficient to achieve performance on par with LLMs of comparable sizes trained
from scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a
12% parameter reduction, retaining 90% of the performance of the base Llama and
Phi models on common knowledge and reasoning benchmarks. Our method also
outperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT with
the same number of parameters removed. For example, DeltaPhi 2.9B with a 24%
reduction achieves similar average zero-shot accuracies as recovery fine-tuned
SlicedPhi 3.3B with a 12% reduction, despite being approximately 400M
parameters smaller with no fine-tuning applied. This work provides new insights
into LLM architecture design and compression methods when storage space is
critical.

摘要：我們引入了 DeltaLLM，這是一種新的訓練後壓縮技術，用於減少 LLM 的記憶體佔用空間。我們提出了一種結構化 LLM 的替代方法，在後續 Transformer 區塊中的層之間共享權重，並在它們之間添加低秩差分矩陣。在訓練方面，我們採用了逐漸替換模組的方法，並表明低秩模組的輕量化訓練，大約有 30M-40M 個符號，足以達到與從頭訓練的同等大小的 LLM 相當的效能。我們發布了結果模型 DeltaLLAMA 和 DeltaPHI，它們的參數減少了 12%，在常見知識和推理基準上保留了 Llama 和 Phi 基礎模型 90% 的效能。我們的技術也優於壓縮技術 JointDrop、LaCo、ShortGPT 和 SliceGPT，而移除的參數數量相同。例如，DeltaPhi 2.9B 減小了 24%，達到了與使用 12% 減小的 SlicedPhi 3.3B 進行恢復微調後類似的平均零次學習準確率，儘管它大約小了 400M 參數且未套用微調。當儲存空間至關重要時，這項工作為 LLM 架構設計和壓縮方法提供了新的見解。

##### **Diffusion Autoencoders are Scalable Image Tokenizers**
2501.18593v1 by Yinbo Chen, Rohit Girdhar, Xiaolong Wang, Sai Saketh Rambhatla, Ishan Misra

Tokenizing images into compact visual representations is a key step in
learning efficient and high-quality image generative models. We present a
simple diffusion tokenizer (DiTo) that learns compact visual representations
for image generation models. Our key insight is that a single learning
objective, diffusion L2 loss, can be used for training scalable image
tokenizers. Since diffusion is already widely used for image generation, our
insight greatly simplifies training such tokenizers. In contrast, current
state-of-the-art tokenizers rely on an empirically found combination of
heuristics and losses, thus requiring a complex training recipe that relies on
non-trivially balancing different losses and pretrained supervised models. We
show design decisions, along with theoretical grounding, that enable us to
scale DiTo for learning competitive image representations. Our results show
that DiTo is a simpler, scalable, and self-supervised alternative to the
current state-of-the-art image tokenizer which is supervised. DiTo achieves
competitive or better quality than state-of-the-art in image reconstruction and
downstream image generation tasks.

摘要：將影像標記化為精簡的視覺表徵是學習有效率且高品質影像生成模型的關鍵步驟。我們提出一個簡單的擴散標記化器 (DiTo)，可學習影像生成模型的精簡視覺表徵。我們的關鍵見解是，單一的學習目標，擴散 L2 損失，可用於訓練可擴充的影像標記化器。由於擴散已廣泛用於影像生成，我們的見解大幅簡化了此類標記化器的訓練。相比之下，目前的先進標記化器依賴於經驗法則和損失的經驗組合，因此需要複雜的訓練配方，依賴於非平凡地平衡不同的損失和預先訓練的監督模型。我們說明設計決策，以及理論依據，使我們能夠擴充 DiTo 以學習有競爭力的影像表徵。我們的結果顯示，DiTo 是比目前先進的影像標記化器更簡單、可擴充且自我監督的替代方案，而後者是監督的。DiTo 在影像重建和下游影像生成任務中，達到有競爭力或優於先進技術的品質。

##### **Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models**
2501.18592v1 by Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink

In real-world scenarios, achieving domain adaptation and generalization poses
significant challenges, as models must adapt to or generalize across unknown
target distributions. Extending these capabilities to unseen multimodal
distributions, i.e., multimodal domain adaptation and generalization, is even
more challenging due to the distinct characteristics of different modalities.
Significant progress has been made over the years, with applications ranging
from action recognition to semantic segmentation. Besides, the recent advent of
large-scale pre-trained multimodal foundation models, such as CLIP, has
inspired works leveraging these models to enhance adaptation and generalization
performances or adapting them to downstream tasks. This survey provides the
first comprehensive review of recent advances from traditional approaches to
foundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal
test-time adaptation; (3) Multimodal domain generalization; (4) Domain
adaptation and generalization with the help of multimodal foundation models;
and (5) Adaptation of multimodal foundation models. For each topic, we formally
define the problem and thoroughly review existing methods. Additionally, we
analyze relevant datasets and applications, highlighting open challenges and
potential future research directions. We maintain an active repository that
contains up-to-date literature at
https://github.com/donghao51/Awesome-Multimodal-Adaptation.

摘要：在實際場景中，實現領域適應和泛化會造成
顯著的挑戰，因為模型必須適應或泛化到未知
目標分佈。將這些能力擴展到未見的多模式
分佈，即多模式領域適應和泛化，由於不同模式的
不同特徵，因此更具挑戰性。多年來已取得顯著進展，
應用範圍從動作辨識到語義分割。此外，最近出現
了 CLIP 等大型預訓練多模式基礎模型，啟發了利用
這些模型來增強適應和泛化效能或將它們適應到下游
任務。這項調查提供了對從傳統方法到
基礎模型的最新進展的首次全面回顧，涵蓋：(1) 多模式
領域適應；(2) 多模式測試時間適應；(3) 多模式領域泛化；
(4) 在多模式基礎模型的幫助下進行領域適應和泛化；
以及 (5) 多模式基礎模型的適應。對於每個主題，我們正式
定義問題並徹底檢視現有方法。此外，我們
分析相關的資料集和應用，強調開放的挑戰和
潛在的未來研究方向。我們維護一個活躍的存放庫，其中
包含 https://github.com/donghao51/Awesome-Multimodal-Adaptation
的最新文獻。

##### **Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching**
2501.18588v1 by David Chuan-En Lin, Hyeonsu B. Kang, Nikolas Martelaro, Aniket Kittur, Yan-Ying Chen, Matthew K. Hong

With recent advancements in the capabilities of Text-to-Image (T2I) AI
models, product designers have begun experimenting with them in their work.
However, T2I models struggle to interpret abstract language and the current
user experience of T2I tools can induce design fixation rather than a more
iterative, exploratory process. To address these challenges, we developed
Inkspire, a sketch-driven tool that supports designers in prototyping product
design concepts with analogical inspirations and a complete
sketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we
conducted an exchange session with designers and distilled design goals for
improving T2I interactions. In a within-subjects study comparing Inkspire to
ControlNet, we found that Inkspire supported designers with more inspiration
and exploration of design ideas, and improved aspects of the co-creative
process by allowing designers to effectively grasp the current state of the AI
to guide it towards novel design intentions.

摘要：隨著文字轉圖像 (T2I) AI 模型的能力不斷進步，產品設計師已開始在工作中實驗使用它們。然而，T2I 模型難以詮釋抽象語言，而 T2I 工具目前的使用者體驗可能會導致設計固定，而不是更具迭代性的探索過程。為了應對這些挑戰，我們開發了 Inkspire，一種以草圖為基礎的工具，支援設計師使用類比靈感和完整的草圖到設計再到草圖的回饋迴路來製作產品設計概念的原型。為了讓 Inkspire 的設計更完善，我們與設計師進行了一場交流會，並提煉出改善 T2I 互動的設計目標。在將 Inkspire 與 ControlNet 進行比較的主體內研究中，我們發現 Inkspire 為設計師提供了更多靈感和設計概念的探索，並透過讓設計師有效掌握 AI 的當前狀態來引導它邁向新穎的設計意圖，進而改善共同創作過程的各個方面。

##### **Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs**
2501.18585v1 by Yue Wang, Qiuzhi Liu, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Linfeng Song, Dian Yu, Juntao Li, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu

Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkable
abilities in complex reasoning tasks by scaling test-time compute and
exhibiting human-like deep thinking. However, we identify a phenomenon we term
underthinking, where o1-like LLMs frequently switch between different reasoning
thoughts without sufficiently exploring promising paths to reach a correct
solution. This behavior leads to inadequate depth of reasoning and decreased
performance, particularly on challenging mathematical problems. To
systematically analyze this issue, we conduct experiments on three challenging
test sets and two representative open-source o1-like models, revealing that
frequent thought switching correlates with incorrect responses. We introduce a
novel metric to quantify underthinking by measuring token efficiency in
incorrect answers. To address underthinking, we propose a decoding strategy
with thought switching penalty TIP that discourages premature transitions
between thoughts, encouraging deeper exploration of each reasoning path.
Experimental results demonstrate that our approach improves accuracy across
challenging datasets without requiring model fine-tuning. Our findings
contribute to understanding reasoning inefficiencies in o1-like LLMs and offer
a practical solution to enhance their problem-solving capabilities.

摘要：大型語言模型（LLM），例如 OpenAI 的 o1，已在複雜的推理任務中展現出非凡的能力，方法是擴充測試時間運算並展現類似人類的深度思考。然而，我們發現一種我們稱之為「思考不足」的現象，其中類似 o1 的 LLM 經常在不同的推理思考之間切換，而沒有充分探索有希望達成正確解方的途徑。這種行為導致推理深度不足，且效能下降，特別是在具有挑戰性的數學問題上。為了系統性地分析這個問題，我們對三個具有挑戰性的測試集和兩個具有代表性的開源類似 o1 的模型進行實驗，結果顯示頻繁的思考切換與不正確的回應有關。我們引入了一個新指標，透過衡量不正確答案中的代碼效率來量化思考不足。為了解決思考不足的問題，我們提出了一種具有思考切換懲罰 TIP 的解碼策略，以阻止過早的思考轉換，鼓勵對每個推理路徑進行更深入的探索。實驗結果表明，我們的做法提高了具有挑戰性資料集的準確性，而不需要模型微調。我們的發現有助於理解類似 o1 的 LLM 中的推理效率低下，並提供了一個實用的解決方案來增強它們的解決問題能力。

##### **R.I.P.: Better Models by Survival of the Fittest Prompts**
2501.18578v1 by Ping Yu, Weizhe Yuan, Olga Golovneva, Tianhao Wu, Sainbayar Sukhbaatar, Jason Weston, Jing Xu

Training data quality is one of the most important drivers of final model
quality. In this work, we introduce a method for evaluating data integrity
based on the assumption that low-quality input prompts result in high variance
and low quality responses. This is achieved by measuring the rejected response
quality and the reward gap between the chosen and rejected preference pair. Our
method, Rejecting Instruction Preferences (RIP) can be used to filter prompts
from existing training sets, or to make high quality synthetic datasets,
yielding large performance gains across various benchmarks compared to
unfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win
Rate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama
3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18th
place to 6th overall in the leaderboard.

摘要：訓練資料品質是最終模型品質最重要的驅動力之一。在這項工作中，我們引入一種評估資料完整性的方法，基於低品質輸入提示會導致高變異和低品質回應的假設。這是透過測量被拒絕的回應品質，以及選擇和被拒絕的偏好配對之間的獎勵差距來實現的。我們的 Rejecting Instruction Preferences (RIP) 方法可用於從現有的訓練集中過濾提示，或建立高品質的合成資料集，與未過濾資料相比，在各種基準上產生巨大的效能提升。使用 Llama 3.1-8B-Instruct，RIP 將 AlpacaEval2 LC 勝率提升了 9.4%，Arena-Hard 提升了 8.7%，WildBench 提升了 9.9%。使用 Llama 3.3-70B-Instruct，RIP 將 Arena-Hard 從 67.5 提升到 82.9，在排行榜上從第 18 名躍升到第 6 名。

##### **Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling**
2501.18577v1 by Dan M. Kluger, Kerri Lu, Tijana Zrnic, Sherrie Wang, Stephen Bates

Machine learning models are increasingly used to produce predictions that
serve as input data in subsequent statistical analyses. For example, computer
vision predictions of economic and environmental indicators based on satellite
imagery are used in downstream regressions; similarly, language models are
widely used to approximate human ratings and opinions in social science
research. However, failure to properly account for errors in the machine
learning predictions renders standard statistical procedures invalid. Prior
work uses what we call the Predict-Then-Debias estimator to give valid
confidence intervals when machine learning algorithms impute missing variables,
assuming a small complete sample from the population of interest. We expand the
scope by introducing bootstrap confidence intervals that apply when the
complete data is a nonuniform (i.e., weighted, stratified, or clustered) sample
and to settings where an arbitrary subset of features is imputed. Importantly,
the method can be applied to many settings without requiring additional
calculations. We prove that these confidence intervals are valid under no
assumptions on the quality of the machine learning model and are no wider than
the intervals obtained by methods that do not use machine learning predictions.

摘要：機器學習模型越來越常被用於產生預測，這些預測會作為後續統計分析的輸入資料。例如，基於衛星影像的經濟和環境指標的電腦視覺預測會用於下游迴歸；類似地，語言模型廣泛用於近似社會科學研究中的人類評分和意見。然而，未能適當地考量機器學習預測中的錯誤，會使標準統計程序失效。先前的工作使用我們所謂的預測後去偏估計器，在機器學習演算法填補遺失變數時提供有效的信心區間，假設從目標母體中取得一個小的完整樣本。我們透過引入自舉法信心區間來擴大範圍，此區間適用於完整資料為非均勻（即加權、分層或分群）樣本，以及填補任意特徵子集的設定。重要的是，此方法可以應用於許多設定，而不需要額外的計算。我們證明這些信心區間在不對機器學習模型品質做任何假設的情況下是有效的，而且不會比不使用機器學習預測的方法所取得的區間更寬。

##### **BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended Videos**
2501.18565v1 by Lehao Lin, Ke Wang, Maha Abdallah, Wei Cai

In recent years, the rapid development of artificial intelligence (AI)
especially multi-modal Large Language Models (MLLMs), has enabled it to
understand text, images, videos, and other multimedia data, allowing AI systems
to execute various tasks based on human-provided prompts. However, AI-powered
bots have increasingly been able to bypass most existing CAPTCHA systems,
posing significant security threats to web applications. This makes the design
of new CAPTCHA mechanisms an urgent priority. We observe that humans are highly
sensitive to shifts and abrupt changes in videos, while current AI systems
still struggle to comprehend and respond to such situations effectively. Based
on this observation, we design and implement BounTCHA, a CAPTCHA mechanism that
leverages human perception of boundaries in video transitions and disruptions.
By utilizing AI's capability to expand original videos with prompts, we
introduce unexpected twists and changes to create a pipeline for generating
short videos for CAPTCHA purposes. We develop a prototype and conduct
experiments to collect data on humans' time biases in boundary identification.
This data serves as a basis for distinguishing between human users and bots.
Additionally, we perform a detailed security analysis of BounTCHA,
demonstrating its resilience against various types of attacks. We hope that
BounTCHA will act as a robust defense, safeguarding millions of web
applications in the AI-driven era.

摘要：近年來，人工智慧（AI）的快速發展，特別是多模態大型語言模型（MLLM），已能理解文字、圖像、影片和其他多媒體資料，讓 AI 系統能根據人類提供的提示執行各種任務。然而，由 AI 驅動的機器人越來越能繞過現有的 CAPTCHA 系統，對網路應用程式造成重大的安全威脅。這使得設計新的 CAPTCHA 機制成為當務之急。我們觀察到人類對影片中的變化和突然的改變非常敏感，而目前的 AI 系統仍然難以理解並有效應對這種情況。基於此觀察，我們設計並實作了 BounTCHA，這是一種 CAPTCHA 機制，它利用人類對影片轉場和中斷中邊界的感知。透過利用 AI 將原始影片擴充到提示的能力，我們引入了意想不到的曲折和變化，以建立一個產生短影片的管道，用於 CAPTCHA 目的。我們開發了一個原型並進行實驗，以收集人類在邊界辨識中時間偏誤的資料。這些資料作為區分人類使用者和機器人的基礎。此外，我們對 BounTCHA 進行了詳細的安全分析，證明了它對各種攻擊類型的韌性。我們希望 BounTCHA 能作為一個強大的防禦措施，在 AI 驅動的時代保護數百萬個網路應用程式。

##### **Semantic Web and Creative AI -- A Technical Report from ISWS 2023**
2501.18542v1 by Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin Böckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, Manoé Kieffer, Antonis Klironomos, Inês Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin Neubert, Emetis Niazmand, Ebrahim Norouzi, Beatriz Olarte Martinez, Anouk Michelle Oudshoorn, Andrea Poltronieri, Valentina Presutti, Disha Purohit, Ensiyeh Raoufi, Celian Ringwald, Johanna Rockstroh, Sebastian Rudolph, Harald Sack, Zafar Saeed, Mohammad Javad Saeedizade, Aya Sahbi, Cristian Santini, Aleksandra Simic, Dennis Sommer, Rita Sousa, Mary Ann Tan, Vidyashree Tarikere, Tabea Tietz, Liam Tirpitz, Arnaldo Tomasino, Frank van Harmelen, Joao Vissoci, Caitlin Woods, Bohui Zhang, Xinyue Zhang, Heng Zheng

The International Semantic Web Research School (ISWS) is a week-long
intensive program designed to immerse participants in the field. This document
reports a collaborative effort performed by ten teams of students, each guided
by a senior researcher as their mentor, attending ISWS 2023. Each team provided
a different perspective to the topic of creative AI, substantiated by a set of
research questions as the main subject of their investigation. The 2023 edition
of ISWS focuses on the intersection of Semantic Web technologies and Creative
AI. ISWS 2023 explored various intersections between Semantic Web technologies
and creative AI. A key area of focus was the potential of LLMs as support tools
for knowledge engineering. Participants also delved into the multifaceted
applications of LLMs, including legal aspects of creative content production,
humans in the loop, decentralised approaches to multimodal generative AI
models, nanopublications and AI for personal scientific knowledge graphs,
commonsense knowledge in automatic story and narrative completion, generative
AI for art critique, prompt engineering, automatic music composition,
commonsense prototyping and conceptual blending, and elicitation of tacit
knowledge. As Large Language Models and semantic technologies continue to
evolve, new exciting prospects are emerging: a future where the boundaries
between creative expression and factual knowledge become increasingly permeable
and porous, leading to a world of knowledge that is both informative and
inspiring.

摘要：國際語意網路研究學校 (ISWS) 是一個為期一週的密集課程，旨在讓參與者沉浸在該領域中。本文件報告了由十個學生團隊進行的合作成果，每個團隊都由一位資深研究員作為導師，參加了 2023 年 ISWS。每個團隊都從不同的角度探討了創意 AI 主題，並以一系列研究問題作為調查的主要主題。2023 年版的 ISWS 關注於語意網路技術和創意 AI 的交集。ISWS 2023 探索了語意網路技術和創意 AI 之間的各種交集。一個重點關注領域是 LLM 作為知識工程的支援工具的潛力。參與者還深入探討了 LLM 的多方面應用，包括創意內容製作的法律方面、循環中的人類、多模態生成式 AI 模型的分散式方法、納米出版物和用於個人科學知識圖譜的 AI、自動故事和敘述完成中的常識知識、生成式 AI 用於藝術評論、提示工程、自動音樂創作、常識原型和概念混合，以及對默會知識的引導。隨著大型語言模型和語意技術的持續發展，新的令人興奮的前景正在出現：一個創意表達和事實知識之間的界限變得越來越可滲透和多孔的未來，從而導致一個既有資訊性又有啟發性的知識世界。

##### **Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method**
2501.18539v1 by Peter Baile Chen, Yi Zhang, Michael Cafarella, Dan Roth

Real-world open-domain questions can be complicated, particularly when
answering them involves information from multiple information sources. LLMs
have demonstrated impressive performance in decomposing complex tasks into
simpler steps, and previous work has used it for better retrieval in support of
complex questions. However, LLM's decomposition of questions is unaware of what
data is available and how data is organized, often leading to a sub-optimal
retrieval performance. Recent effort in agentic RAG proposes to perform
retrieval in an iterative fashion, where a followup query is derived as an
action based on previous rounds of retrieval. While this provides one way of
interacting with the data collection, agentic RAG's exploration of data is
inefficient because successive queries depend on previous results rather than
being guided by the organization of available data in the collection. To
address this problem, we propose an LLM-based retrieval method -- ARM, that
aims to better align the question with the organization of the data collection
by exploring relationships among data objects beyond matching the utterance of
the query, thus leading to a retrieve-all-at-once solution for complex queries.
We evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms
standard RAG with query decomposition by up to 5.2 pt in execution accuracy and
agentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and
19.3 pt higher F1 match scores compared to these approaches.

摘要：真實世界的開放領域問題可能很複雜，特別是在回答這些問題需要來自多個資訊來源的資訊時。LLM 已展現出令人印象深刻的效能，可將複雜任務分解成更簡單的步驟，而先前的研究已將其用於更好的檢索以支援複雜問題。然而，LLM 對問題的分解並不知道有哪些資料可用以及資料如何組織，這常常會導致次佳的檢索效能。Agentic RAG 中最近的努力提議以反覆的方式執行檢索，其中後續查詢會根據前幾輪的檢索作為動作而衍生。雖然這提供了與資料收集互動的一種方式，但 agentic RAG 對資料的探索並非有效率，因為後續查詢仰賴先前的結果，而非由收集中可用資料的組織所引導。為了解決這個問題，我們提出一個基於 LLM 的檢索方法 ARM，其目標是透過探索資料物件之間的關係（不只是比對查詢的語句）讓問題與資料收集的組織更對齊，進而為複雜查詢找出一次檢索所有結果的解決方案。我們在兩個資料集 Bird 和 OTT-QA 上評估 ARM。在 Bird 上，在執行準確度上，它比標準 RAG 的查詢分解高出 5.2 個百分點，比 agentic RAG (ReAct) 高出 15.9 個百分點。在 OTT-QA 上，與這些方法相比，它在 F1 比對分數上分別高出 5.5 個百分點和 19.3 個百分點。

##### **A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre**
2501.18535v1 by Tasfia Noor Chowdhury, Sanjida Afrin Mou, Kazi Naimur Rahman

Patient length of stay (LoS) is a critical metric for evaluating the efficacy
of hospital management. The primary objectives encompass to improve efficiency
and reduce costs while enhancing patient outcomes and hospital capacity within
the patient journey. By seamlessly merging data-driven techniques with
simulation methodologies, the study proposes an all-encompassing framework for
the optimization of patient flow. Using a comprehensive dataset of 2.3 million
de-identified patient records, we analyzed demographics, diagnoses, treatments,
services, costs, and charges with machine learning models (Decision Tree,
Logistic Regression, Random Forest, Adaboost, LightGBM) and Python tools
(Spark, AWS clusters, dimensionality reduction). Our model predicts patient
length of stay (LoS) upon admission using supervised learning algorithms. This
hybrid approach enables the identification of key factors influencing LoS,
offering a robust framework for hospitals to streamline patient flow and
resource utilization. The research focuses on patient flow, corroborating the
efficacy of the approach, illustrating decreased patient length of stay within
a real healthcare environment. The findings underscore the potential of hybrid
data-driven models in transforming hospital management practices. This
innovative methodology provides generally flexible decision-making, training,
and patient flow enhancement; such a system could have huge implications for
healthcare administration and overall satisfaction with healthcare.

摘要：住院時間 (LoS) 是評估醫院管理效能的重要指標。主要目標包括在病患歷程中提升效率、降低成本，同時改善病患預後和醫院容量。透過無縫整合資料驅動技術與模擬方法，本研究提出一個全面性的架構，用於優化病患流程。我們使用一個包含 230 萬筆去識別化病患紀錄的綜合資料集，並使用機器學習模型（決策樹、邏輯迴歸、隨機森林、Adaboost、LightGBM）和 Python 工具（Spark、AWS 集群、降維）分析人口統計、診斷、治療、服務、成本和費用。我們的模型使用監督式學習演算法預測病患在入院時的住院時間 (LoS)。此混合方法能找出影響 LoS 的關鍵因素，提供一個強健的架構，讓醫院能簡化病患流程和資源利用。本研究專注於病患流程，佐證此方法的效能，說明在真實的醫療保健環境中減少了病患住院時間。研究結果強調混合資料驅動模型在轉型醫院管理實務中的潛力。此創新方法提供靈活的決策制定、訓練和病患流程改善；這樣的系統可能對醫療保健管理和整體醫療保健滿意度產生重大影響。

##### **Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models**
2501.18533v1 by Yi Ding, Lijun Li, Bing Cao, Jing Shao

Large Vision-Language Models (VLMs) have achieved remarkable performance
across a wide range of tasks. However, their deployment in safety-critical
domains poses significant challenges. Existing safety fine-tuning methods,
which focus on textual or multimodal content, fall short in addressing
challenging cases or disrupt the balance between helpfulness and harmlessness.
Our evaluation highlights a safety reasoning gap: these methods lack safety
visual reasoning ability, leading to such bottlenecks. To address this
limitation and enhance both visual perception and reasoning in safety-critical
contexts, we propose a novel dataset that integrates multi-image inputs with
safety Chain-of-Thought (CoT) labels as fine-grained reasoning logic to improve
model performance. Specifically, we introduce the Multi-Image Safety (MIS)
dataset, an instruction-following dataset tailored for multi-image safety
scenarios, consisting of training and test splits. Our experiments demonstrate
that fine-tuning InternVL2.5-8B with MIS significantly outperforms both
powerful open-source models and API-based models in challenging multi-image
tasks requiring safety-related visual reasoning. This approach not only
delivers exceptional safety performance but also preserves general capabilities
without any trade-offs. Specifically, fine-tuning with MIS increases average
accuracy by 0.83% across five general benchmarks and reduces the Attack Success
Rate (ASR) on multiple safety benchmarks by a large margin. Data and Models are
released under:
\href{https://dripnowhy.github.io/MIS/}{\texttt{https://dripnowhy.github.io/MIS/}}

摘要：大型視覺語言模型 (VLM) 已在各種任務中取得顯著成效。然而，它們在安全關鍵領域的部署卻帶來重大挑戰。現有的安全微調方法著重於文字或多模態內容，在處理具挑戰性的案例或破壞有益性和無害性之間的平衡方面做得不夠。我們的評估強調了安全推理差距：這些方法缺乏安全視覺推理能力，導致產生此類瓶頸。為了解決此限制並增強安全關鍵情境中的視覺感知和推理，我們提出了一個新穎的資料集，將多圖像輸入與安全思考鏈 (CoT) 標籤整合為細粒度的推理邏輯，以改善模型效能。具體來說，我們引入了多圖像安全 (MIS) 資料集，這是一個專為多圖像安全情境量身打造的指令遵循資料集，包含訓練和測試分割。我們的實驗證明，使用 MIS 微調 InternVL2.5-8B 在需要安全相關視覺推理的具挑戰性多圖像任務中，明顯優於功能強大的開源模型和基於 API 的模型。這種方法不僅提供了出色的安全效能，而且還保留了一般能力，沒有任何權衡取捨。具體來說，使用 MIS 進行微調可將五個一般基準的平均準確度提高 0.83%，並將多個安全基準的攻擊成功率 (ASR) 大幅降低。資料和模型在以下位置發布：
\href{https://dripnowhy.github.io/MIS/}{\texttt{https://dripnowhy.github.io/MIS/}}

##### **Differentially Private Steering for Large Language Model Alignment**
2501.18532v1 by Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal

Aligning Large Language Models (LLMs) with human values and away from
undesirable behaviors (such as hallucination) has become increasingly
important. Recently, steering LLMs towards a desired behavior via activation
editing has emerged as an effective method to mitigate harmful generations at
inference-time. Activation editing modifies LLM representations by preserving
information from positive demonstrations (e.g., truthful) and minimising
information from negative demonstrations (e.g., hallucinations). When these
demonstrations come from a private dataset, the aligned LLM may leak private
information contained in those private samples. In this work, we present the
first study of aligning LLM behavior with private datasets. Our work proposes
the \textit{\underline{P}rivate \underline{S}teering for LLM
\underline{A}lignment (PSA)} algorithm to edit LLM activations with
differential privacy (DP) guarantees. We conduct extensive experiments on seven
different benchmarks with open-source LLMs of different sizes (0.5B to 7B) and
model families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSA
achieves DP guarantees for LLM alignment with minimal loss in performance,
including alignment metrics, open-ended text generation quality, and
general-purpose reasoning. We also develop the first Membership Inference
Attack (MIA) for evaluating and auditing the empirical privacy for the problem
of LLM steering via activation editing. Our attack is tailored for activation
editing and relies solely on the generated texts without their associated
probabilities. Our experiments support the theoretical guarantees by showing
improved guarantees for our \textit{PSA} algorithm compared to several existing
non-private techniques.

摘要：<paragraph>讓大型語言模型 (LLM) 與人類價值觀保持一致，並遠離不良行為（例如幻覺）已變得越來越重要。最近，通過激活編輯將 LLM 引導至所需行為已成為在推理時減輕有害生成的有效方法。激活編輯通過保留來自正面演示（例如真實）的信息並最大程度地減少來自負面演示（例如幻覺）的信息來修改 LLM 表示。當這些演示來自私有數據集時，對齊的 LLM 可能會洩露這些私有樣本中包含的私有信息。在這項工作中，我們展示了將 LLM 行為與私有數據集對齊的第一項研究。我們的研究提出了\textit{\underline{P}rivate \underline{S}teering for LLM \underline{A}lignment (PSA)} 演算法，以編輯具有差分隱私 (DP) 保證的 LLM 激活。我們對七個不同的基準進行了廣泛的實驗，其中包含不同大小（0.5B 到 7B）和模型系列（LlaMa、Qwen、Mistral 和 Gemma）的開源 LLM。我們的結果表明，PSA 在 LLM 對齊方面實現了 DP 保證，同時在性能方面損失最小，包括對齊指標、開放式文本生成質量和通用推理。我們還開發了第一個成員推論攻擊 (MIA)，用於評估和審計通過激活編輯進行 LLM 引導的經驗隱私。我們的攻擊專門針對激活編輯，並且僅依賴於生成的文本，而不需要它們關聯的機率。我們的實驗通過展示與多種現有的非私有技術相比，我們的\textit{PSA} 演算法具有更好的保證，來支持理論保證。</paragraph>

##### **Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch**
2501.18512v1 by Arthur Douillard, Yanislav Donchev, Keith Rush, Satyen Kale, Zachary Charles, Zachary Garrett, Gabriel Teston, Dave Lacey, Ross McIlroy, Jiajun Shen, Alexandre Ramé, Arthur Szlam, Marc'Aurelio Ranzato, Paul Barham

Training of large language models (LLMs) is typically distributed across a
large number of accelerators to reduce training time. Since internal states and
parameter gradients need to be exchanged at each and every single gradient
step, all devices need to be co-located using low-latency high-bandwidth
communication links to support the required high volume of exchanged bits.
Recently, distributed algorithms like DiLoCo have relaxed such co-location
constraint: accelerators can be grouped into ``workers'', where
synchronizations between workers only occur infrequently. This in turn means
that workers can afford being connected by lower bandwidth communication links
without affecting learning quality. However, in these methods, communication
across workers still requires the same peak bandwidth as before, as the
synchronizations require all parameters to be exchanged across all workers. In
this paper, we improve DiLoCo in three ways. First, we synchronize only subsets
of parameters in sequence, rather than all at once, which greatly reduces peak
bandwidth. Second, we allow workers to continue training while synchronizing,
which decreases wall clock time. Third, we quantize the data exchanged by
workers, which further reduces bandwidth across workers. By properly combining
these modifications, we show experimentally that we can distribute training of
billion-scale parameters and reach similar quality as before, but reducing
required bandwidth by two orders of magnitude.

摘要：大型語言模型 (LLM) 的訓練通常會分散在大量的加速器上，以縮短訓練時間。由於內部狀態和參數梯度需要在每個單一梯度步驟中交換，因此所有裝置都需要使用低延遲高頻寬通訊連結並置，以支援大量交換位元的要求。最近，DiLoCo 等分散式演算法放寬了此並置限制：加速器可以分組成「工作者」，其中工作者之間的同步僅會不頻繁地發生。這反過來表示工作者可以負擔透過較低頻寬通訊連結連線，而不會影響學習品質。然而，在這些方法中，工作者之間的通訊仍然需要與以往相同的峰值頻寬，因為同步需要在所有工作者之間交換所有參數。在本文中，我們以三種方式改進 DiLoCo。首先，我們僅依序同步參數的子集，而不是一次同步所有參數，這大幅減少了峰值頻寬。其次，我們允許工作者在同步時繼續訓練，這減少了實際時鐘時間。第三，我們量化工作者交換的資料，這進一步減少了工作者之間的頻寬。透過適當地結合這些修改，我們透過實驗證明，我們可以分散訓練十億規模的參數，並達到與以往相似的品質，但將所需的頻寬減少了兩個數量級。

##### **WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training**
2501.18511v1 by Benjamin Feuer, Chinmay Hegde

Language model (LLM) post-training, from DPO to distillation, can refine
behaviors and unlock new skills, but the open science supporting these
post-training techniques is still in its infancy. One limiting factor has been
the difficulty of conducting large-scale comparative analyses of synthetic data
generating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,
the largest public chat dataset to date. We extend the existing WildChat
dataset to include responses not only from GPT, but from over 50 different
open-weight models, ranging in size from 0.5B to 104B parameters. We conduct an
extensive comparative analysis and demonstrate the potential of this dataset by
creating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3
SFT mixture from Allen AI with only 40% as many samples. Our dataset, samples
and code are available at https://github.com/penfever/wildchat-50m.

摘要：語言模型 (LLM) 後訓練，從 DPO 到蒸餾，可以改善行為並解鎖新技能，但支援這些後訓練技術的開放科學仍處於起步階段。一個限制因素是難以對合成資料產生模型和 LLM 評審進行大規模比較分析。為了縮小這個差距，我們引入了 WILDCHAT-50M，這是迄今為止最大的公開聊天資料集。我們擴充現有的 WildChat 資料集，不僅包含來自 GPT 的回應，還包含來自 50 多種不同的開放權重模型的回應，規模從 0.5B 到 104B 參數不等。我們進行了廣泛的比較分析，並透過建立我們自己的公開 SFT 混合 RE-WILD 來展示此資料集的潛力，它以僅 40% 的樣本數量就優於 Allen AI 最近的 Tulu-3 SFT 混合。我們的資料集、範例和程式碼可在 https://github.com/penfever/wildchat-50m 取得。

##### **CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction**
2501.18504v1 by Peter J. Bentley, Soo Ling Lim, Fuyuki Ishikawa

Large Language Model (LLM) image recognition is a powerful tool for
extracting data from images, but accuracy depends on providing sufficient cues
in the prompt - requiring a domain expert for specialized tasks. We introduce
Cue Learning using Evolution for Accurate Recognition (CLEAR), which uses a
combination of LLMs and evolutionary computation to generate and optimize cues
such that recognition of specialized features in images is improved. It
achieves this by auto-generating a novel domain-specific representation and
then using it to optimize suitable textual cues with a genetic algorithm. We
apply CLEAR to the real-world task of identifying sustainability data from
interior and exterior images of buildings. We investigate the effects of using
a variable-length representation compared to fixed-length and show how LLM
consistency can be improved by refactoring from categorical to real-valued
estimates. We show that CLEAR enables higher accuracy compared to expert human
recognition and human-authored prompts in every task with error rates improved
by up to two orders of magnitude and an ablation study evincing solution
concision.

摘要：大型語言模型 (LLM) 影像辨識是一種強大的工具，可從影像中萃取資料，但準確度取決於提示中提供足夠的提示，需要領域專家執行專業任務。我們導入使用演化進行精準辨識的提示學習 (CLEAR)，它結合 LLM 和演化運算來產生和最佳化提示，以改善影像中特定特徵的辨識。它透過自動產生新的特定領域表示，然後使用遺傳演算法最佳化合適的文字提示來達成此目的。我們將 CLEAR 應用於從建築物內部和外部影像識別永續性資料的實際任務。我們調查使用可變長度表示與固定長度表示的效果，並展示如何透過從分類估計值重構為實值估計值來改善 LLM 一致性。我們展示 CLEAR 與專家人類辨識和人類撰寫的提示相比，在每個任務中都能實現更高的準確度，錯誤率最高改善了兩個數量級，並且消融研究證明了解決方案的簡潔性。

##### **GuardReasoner: Towards Reasoning-based LLM Safeguards**
2501.18492v1 by Yue Liu, Hongcheng Gao, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, Bryan Hooi

As LLMs increasingly impact safety-critical applications, ensuring their
safety using guardrails remains a key challenge. This paper proposes
GuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to
reason. Concretely, we first create the GuardReasonerTrain dataset, which
consists of 127K samples with 460K detailed reasoning steps. Then, we introduce
reasoning SFT to unlock the reasoning capability of guard models. In addition,
we present hard sample DPO to further strengthen their reasoning ability. In
this manner, GuardReasoner achieves better performance, explainability, and
generalizability. Extensive experiments and analyses on 13 benchmarks of 3
guardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B
surpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on
average. We release the training data, code, and models with different scales
(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.

摘要：隨著 LLM 對安全關鍵應用程式的影響日益增加，確保其安全性的防護措施仍然是一項關鍵挑戰。本文提出 GuardReasoner，一種新的 LLM 保障措施，透過引導防護模型學習推理。具體而言，我們首先建立 GuardReasonerTrain 資料集，其中包含 127K 個樣本，並有 460K 個詳細的推理步驟。接下來，我們引入推理 SFT 以解鎖防護模型的推理能力。此外，我們提出困難樣本 DPO 以進一步增強其推理能力。透過這種方式，GuardReasoner 達到更好的效能、可解釋性和概括性。在 3 個防護任務的 13 個基準上進行的廣泛實驗和分析證明了它的優越性。值得注意的是，GuardReasoner 8B 在平均 F1 分數上分別比 GPT-4o+CoT 高出 5.74%，比 LLaMA Guard 3 8B 高出 20.84%。我們發布了不同規模（1B、3B、8B）的 GuardReasoner 訓練資料、程式碼和模型：https://github.com/yueliu1999/GuardReasoner/。

##### **CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization**
2501.18475v1 by Yanxia Deng, Aozhong Zhang, Naigang Wang, Selcuk Gurses, Zi Yang, Penghang Yin

Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has
become a highly efficient approach for downstream tasks, particularly in
scenarios with limited computational resources. However, applying LoRA
techniques to quantized LLMs poses unique challenges due to the reduced
representational precision of quantized weights. In this paper, we introduce
CLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic
initialization strategy designed to overcome these challenges. Our approach
focuses on minimizing the layer-wise discrepancy between the original LLM and
its quantized counterpart with LoRA components during initialization. By
leveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and
determines the optimal LoRA components for each layer, ensuring a strong
foundation for subsequent fine-tuning. A key contribution of this work is a
novel theoretical result that enables the accurate and closed-form construction
of these optimal LoRA components. We validate the efficacy of CLoQ across
multiple tasks such as language generation, arithmetic reasoning, and
commonsense reasoning, demonstrating that it consistently outperforms existing
LoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit
widths.

摘要：使用低秩適應 (LoRA) 微調大型語言模型 (LLM) 已成為下游任務的高度有效方法，特別是在計算資源有限的情況下。然而，由於量化權重的表示精度降低，將 LoRA 技術應用於量化 LLM 會帶來獨特的挑戰。在本文中，我們介紹了 CLoQ（量化 LLM 的校準 LoRA 初始化），這是一種旨在克服這些挑戰的簡化初始化策略。我們的做法著重於在初始化期間最小化原始 LLM 和其量化對應項與 LoRA 組件之間的逐層差異。通過利用一個小型校準數據集，CLoQ 量化預訓練的 LLM 並確定每層的最佳 LoRA 組件，從而確保後續微調的堅實基礎。這項工作的關鍵貢獻是創新的理論結果，它能準確且封閉地構造這些最佳 LoRA 組件。我們驗證了 CLoQ 在語言生成、算術推理和常識推理等多項任務中的功效，證明它始終優於現有的量化 LLM 的 LoRA 微調方法，特別是在極低位寬度下。

##### **Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking**
2501.18468v1 by Eduardo Davalos, Jorge Alberto Salas, Yike Zhang, Namrata Srivastava, Yashvitha Thatigotla, Abbey Gonzales, Sara McFadden, Sun-Joo Cho, Gautam Biswas, Amanda Goodwin

Understanding reader behaviors such as skimming, deep reading, and scanning
is essential for improving educational instruction. While prior eye-tracking
studies have trained models to recognize reading behaviors, they often rely on
instructed reading tasks, which can alter natural behaviors and limit the
applicability of these findings to in-the-wild settings. Additionally, there is
a lack of clear definitions for reading behavior archetypes in the literature.
We conducted a classroom study to address these issues by collecting instructed
and in-the-wild reading data. We developed a mixed-method framework, including
a human-driven theoretical model, statistical analyses, and an AI classifier,
to differentiate reading behaviors based on their velocity, density, and
sequentiality. Our lightweight 2D CNN achieved an F1 score of 0.8 for behavior
recognition, providing a robust approach for understanding in-the-wild reading.
This work advances our ability to provide detailed behavioral insights to
educators, supporting more targeted and effective assessment and instruction.

摘要：了解讀者行為，例如瀏覽、深層閱讀和掃描，對於改善教育教學至關重要。雖然先前的眼球追蹤研究已訓練模型來識別閱讀行為，但它們通常依賴於指示性閱讀任務，這可能會改變自然行為並限制這些發現對野外環境的適用性。此外，文獻中缺乏對閱讀行為原型明確的定義。我們進行了一項課堂研究，透過收集指示性和野外閱讀資料來解決這些問題。我們開發了一個混合方法框架，包括人為驅動的理論模型、統計分析和 AI 分類器，根據速度、密度和順序性來區分閱讀行為。我們的輕量級 2D CNN 在行為識別方面達到了 0.8 的 F1 分數，為理解野外閱讀提供了一種強大的方法。這項工作提升了我們向教育工作者提供詳細行為見解的能力，支援更有針對性和更有效的評估和教學。

##### **CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language Model Question Answering**
2501.18457v1 by Yumeng Wang, Zhiyuan Fan, Qingyun Wang, May Fung, Heng Ji

Large Language Models (LLMs) are pretrained on extensive multilingual corpora
to acquire both language-specific cultural knowledge and general knowledge.
Ideally, while LLMs should provide consistent responses to culture-independent
questions across languages, we observe significant performance disparities. To
address this, we explore the Cross-Lingual Self-Aligning ability of Language
Models (CALM) to align knowledge across languages. Specifically, for a given
question, we sample multiple responses across different languages, and select
the most self-consistent response as the target, leaving the remaining
responses as negative examples. We then employ direct preference optimization
(DPO) to align the model's knowledge across different languages. Evaluations on
the MEDQA and X-CSQA datasets demonstrate CALM's effectiveness in enhancing
cross-lingual knowledge question answering, both in zero-shot and retrieval
augmented settings. We also found that increasing the number of languages
involved in CALM training leads to even higher accuracy and consistency. We
offer a qualitative analysis of how cross-lingual consistency can enhance
knowledge alignment and explore the method's generalizability. The source code
and data of this paper are available on GitHub.

摘要：大型語言模型 (LLM) 在廣泛的多語言語料庫上進行預訓練，以獲取特定語言的文化知識和一般知識。理想情況下，雖然 LLM 應對各語言的文化無關問題提供一致的回應，但我們觀察到顯著的效能差異。為了解決這個問題，我們探討語言模型的跨語言自我對齊能力 (CALM)，以對齊各語言的知識。具體來說，對於一個給定的問題，我們在不同語言中採樣多個回應，並選擇最自洽的回應作為目標，將其餘的回應作為負面範例。然後，我們採用直接偏好最佳化 (DPO) 來對齊模型在不同語言中的知識。在 MEDQA 和 X-CSQA 資料集上的評估證明了 CALM 在增強跨語言知識問答方面的有效性，無論是在零次學習還是檢索增強設定中。我們還發現，增加 CALM 訓練中涉及的語言數量會導致更高的準確性和一致性。我們提供了一個定性分析，說明跨語言一致性如何增強知識對齊並探討該方法的可概化性。本文的原始碼和資料可在 GitHub 上取得。

##### **Conversation Games and a Strategic View of the Turing Test**
2501.18455v1 by Kaveh Aryan

Although many game-theoretic models replicate real interactions that often
rely on natural language, explicit study of games where language is central to
strategic interaction remains limited. This paper introduces the
\emph{conversation game}, a multi-stage, extensive-form game based on
linguistic strategic interaction. We focus on a subset of the games, called
verdict games. In a verdict game, two players alternate to contribute to a
conversation, which is evaluated at each stage by a non-strategic judge who may
render a conclusive binary verdict, or a decision to continue the dialogue. The
game ends once a limit is reached or a verdict is given. We show many familiar
processes, such as interrogation or a court process fall under this category.
We also, show that the Turing test is an instance of verdict game, and discuss
the significance of a strategic view of the Turing test in the age of advanced
AI deception. We show the practical relevance of the proposed concepts by
simulation experiments, and show that a strategic agent outperforms a naive
agent by a high margin.

摘要：儘管許多博弈論模型複製了真實的互動，而這些互動通常依賴於自然語言，但對於語言在策略互動中居於核心的遊戲之明確研究仍然有限。本文介紹了「對話遊戲」，這是一款基於語言策略互動的多階段廣義型遊戲。我們專注於遊戲的一個子集，稱為判決遊戲。在判決遊戲中，兩名玩家輪流參與對話，對話在每個階段由一名非策略性法官評估，該法官可能會做出明確的二元判決，或決定繼續對話。遊戲在達到限制或做出判決後結束。我們展示了許多常見的程序，例如審問或法庭程序屬於此類別。我們還展示了圖靈測試是判決遊戲的一個實例，並討論了在先進 AI 欺騙時代，從策略角度看待圖靈測試的重要性。我們透過模擬實驗展示了所提出概念的實際相關性，並展示了一個策略性代理遠遠優於一個天真代理。

##### **Clustering Properties of Self-Supervised Learning**
2501.18452v1 by Xi Weng, Jianing An, Xudong Ma, Binhang Qi, Jie Luo, Xi Yang, Jin Song Dong, Lei Huang

Self-supervised learning (SSL) methods via joint embedding architectures have
proven remarkably effective at capturing semantically rich representations with
strong clustering properties, magically in the absence of label supervision.
Despite this, few of them have explored leveraging these untapped properties to
improve themselves. In this paper, we provide an evidence through various
metrics that the encoder's output $encoding$ exhibits superior and more stable
clustering properties compared to other components. Building on this insight,
we propose a novel positive-feedback SSL method, termed Representation Soft
Assignment (ReSA), which leverages the model's clustering properties to promote
learning in a self-guided manner. Extensive experiments on standard SSL
benchmarks reveal that models pretrained with ReSA outperform other
state-of-the-art SSL methods by a significant margin. Finally, we analyze how
ReSA facilitates better clustering properties, demonstrating that it
effectively enhances clustering performance at both fine-grained and
coarse-grained levels, shaping representations that are inherently more
structured and semantically meaningful.

摘要：透過聯合嵌入架構的自監督學習 (SSL) 方法已證明在捕捉具有強大群集特性的語義豐富表徵方面非常有效，神奇的是在沒有標籤監督的情況下。儘管如此，很少有人探索利用這些未開發的特性來改善自身。在本文中，我們透過各種指標提供證據，證明編碼器的輸出 $encoding$ 與其他組件相比，表現出優異且更穩定的群集特性。根據此見解，我們提出了一種新穎的正回饋 SSL 方法，稱為表徵軟指派 (ReSA)，它利用模型的群集特性以自導引的方式促進學習。在標準 SSL 基準上的廣泛實驗表明，使用 ReSA 預訓練的模型在顯著幅度上優於其他最先進的 SSL 方法。最後，我們分析了 ReSA 如何促進更好的群集特性，證明它有效地增強了精細和粗略層級的群集效能，塑造出本質上更結構化且語義上有意義的表徵。

##### **o3-mini vs DeepSeek-R1: Which One is Safer?**
2501.18438v1 by Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura

The irruption of DeepSeek-R1 constitutes a turning point for the AI industry
in general and the LLMs in particular. Its capabilities have demonstrated
outstanding performance in several tasks, including creative thinking, code
generation, maths and automated program repair, at apparently lower execution
cost. However, LLMs must adhere to an important qualitative property, i.e.,
their alignment with safety and human values. A clear competitor of DeepSeek-R1
is its American counterpart, OpenAI's o3-mini model, which is expected to set
high standards in terms of performance, safety and cost. In this paper we
conduct a systematic assessment of the safety level of both, DeepSeek-R1 (70b
version) and OpenAI's o3-mini (beta version). To this end, we make use of our
recently released automated safety testing tool, named ASTRAL. By leveraging
this tool, we automatically and systematically generate and execute a total of
1260 unsafe test inputs on both models. After conducting a semi-automated
assessment of the outcomes provided by both LLMs, the results indicate that
DeepSeek-R1 is highly unsafe as compared to OpenAI's o3-mini. Based on our
evaluation, DeepSeek-R1 answered unsafely to 11.98% of the executed prompts
whereas o3-mini only to 1.19%.

摘要：DeepSeek-R1 的出現對於 AI 產業而言是一個轉捩點，特別是對於 LLM 而言。它的能力在多項任務中展現出傑出的表現，包括創意思考、程式碼生成、數學和自動化程式修復，而且執行成本明顯較低。然而，LLM 必須遵守一個重要的品質特性，也就是與安全性和人類價值觀保持一致。DeepSeek-R1 的一個明確競爭對手是其美國對手 OpenAI 的 o3-mini 模型，預計在效能、安全性與成本方面將樹立高標準。在本文中，我們對 DeepSeek-R1（70b 版本）和 OpenAI 的 o3-mini（beta 版本）的安全等級進行系統性評估。為此，我們利用我們最近發布的自動化安全測試工具 ASTRAL。透過使用這個工具，我們自動且系統性地生成並執行總共 1260 個不安全的測試輸入在兩個模型上。在對兩個 LLM 提供的結果進行半自動化評估後，結果顯示 DeepSeek-R1 與 OpenAI 的 o3-mini 相比，安全性非常低。根據我們的評估，DeepSeek-R1 對 11.98% 的執行提示做出了不安全的回答，而 o3-mini 只有 1.19%。

##### **GENIE: Generative Note Information Extraction model for structuring EHR data**
2501.18435v1 by Huaiyuan Ying, Hongyi Yuan, Jinsen Lu, Zitian Qu, Yang Zhao, Zhengyun Zhao, Isaac Kohane, Tianxi Cai, Sheng Yu

Electronic Health Records (EHRs) hold immense potential for advancing
healthcare, offering rich, longitudinal data that combines structured
information with valuable insights from unstructured clinical notes. However,
the unstructured nature of clinical text poses significant challenges for
secondary applications. Traditional methods for structuring EHR free-text data,
such as rule-based systems and multi-stage pipelines, are often limited by
their time-consuming configurations and inability to adapt across clinical
notes from diverse healthcare settings. Few systems provide a comprehensive
attribute extraction for terminologies. While giant large language models
(LLMs) like GPT-4 and LLaMA 405B excel at structuring tasks, they are slow,
costly, and impractical for large-scale use. To overcome these limitations, we
introduce GENIE, a Generative Note Information Extraction system that leverages
LLMs to streamline the structuring of unstructured clinical text into usable
data with standardized format. GENIE processes entire paragraphs in a single
pass, extracting entities, assertion statuses, locations, modifiers, values,
and purposes with high accuracy. Its unified, end-to-end approach simplifies
workflows, reduces errors, and eliminates the need for extensive manual
intervention. Using a robust data preparation pipeline and fine-tuned small
scale LLMs, GENIE achieves competitive performance across multiple information
extraction tasks, outperforming traditional tools like cTAKES and MetaMap and
can handle extra attributes to be extracted. GENIE strongly enhances real-world
applicability and scalability in healthcare systems. By open-sourcing the model
and test data, we aim to encourage collaboration and drive further advancements
in EHR structurization.

摘要：電子健康記錄 (EHR) 蘊藏著促進醫療保健的巨大潛力，提供豐富的縱向數據，結合了結構化資訊與非結構化臨床筆記中的寶貴見解。然而，臨床文本的非結構化性質對次要應用程式構成了重大挑戰。結構化 EHR 自由文字資料的傳統方法，例如基於規則的系統和多階段管道，通常受到其耗時的組態和無法適應來自不同醫療保健環境的臨床筆記的限制。少數系統為術語提供全面的屬性萃取。雖然像 GPT-4 和 LLaMA 405B 這樣的巨型大型語言模型 (LLM) 在結構化任務方面表現出色，但它們速度慢、成本高，且不切實際用於大規模使用。為了克服這些限制，我們引入了 GENIE，一個生成式筆記資訊萃取系統，它利用 LLM 將非結構化臨床文本簡化為具有標準化格式的可用資料。GENIE 在單次傳遞中處理整個段落，以高準確度萃取實體、斷言狀態、位置、修飾詞、值和目的。其統一的端對端方法簡化了工作流程、減少了錯誤，並消除了廣泛手動介入的需要。GENIE 使用強大的資料準備管道和微調的小型 LLM，在多個資訊萃取任務中實現了競爭力的效能，優於 cTAKES 和 MetaMap 等傳統工具，並且可以處理要萃取的額外屬性。GENIE 大幅增強了醫療保健系統中的真實世界適用性和可擴充性。透過開放原始碼模型和測試資料，我們旨在鼓勵協作並推動 EHR 結構化的進一步發展。

##### **Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms**
2501.18432v1 by Eneko Osaba, Pablo Miranda-Rodriguez, Andreas Oikonomakis, Matic Petrič, Sebastian Bock, Michail-Alexandros Kourtis

This paper presents a novel hybrid approach to solving real-world drone
routing problems by leveraging the capabilities of quantum computing. The
proposed method, coined Quantum for Drone Routing (Q4DR), integrates the two
most prominent paradigms in the field: quantum gate-based computing, through
the Eclipse Qrisp programming language; and quantum annealers, by means of
D-Wave System's devices. The algorithm is divided into two different phases: an
initial clustering phase executed using a Quantum Approximate Optimization
Algorithm (QAOA), and a routing phase employing quantum annealers. The efficacy
of Q4DR is demonstrated through three use cases of increasing complexity, each
incorporating real-world constraints such as asymmetric costs, forbidden paths,
and itinerant charging points. This research contributes to the growing body of
work in quantum optimization, showcasing the practical applications of quantum
computing in logistics and route planning.

摘要：這篇論文提出了一種創新的混合方法，利用量子運算的能力來解決現實世界的無人機路徑問題。
所提出的方法，稱為無人機路徑量子演算法 (Q4DR)，整合了該領域中兩個最突出的範例：透過 Eclipse Qrisp 程式語言進行的量子閘控計算；以及透過 D-Wave System 的裝置進行的量子退火。此演算法分為兩個不同的階段：使用量子近似最佳化演算法 (QAOA) 執行的初始群集階段，以及使用量子退火執行的路徑階段。Q4DR 的效能透過三個使用案例進行驗證，每個案例的複雜度都遞增，且都納入了現實世界的限制條件，例如不對稱成本、禁止路徑，以及巡迴充電點。這項研究有助於量子最佳化領域的發展，展示了量子運算在物流和路徑規劃中的實際應用。

##### **Guaranteed confidence-band enclosures for PDE surrogates**
2501.18426v1 by Ander Gray, Vignesh Gopakumar, Sylvain Rousseau, Sébastien Destercke

We propose a method for obtaining statistically guaranteed confidence bands
for functional machine learning techniques: surrogate models which map between
function spaces, motivated by the need build reliable PDE emulators. The method
constructs nested confidence sets on a low-dimensional representation (an SVD)
of the surrogate model's prediction error, and then maps these sets to the
prediction space using set-propagation techniques. The result are
conformal-like coverage guaranteed prediction sets for functional surrogate
models. We use zonotopes as basis of the set construction, due to their well
studied set-propagation and verification properties. The method is model
agnostic and can thus be applied to complex Sci-ML models, including Neural
Operators, but also in simpler settings. We also elicit a technique to capture
the truncation error of the SVD, ensuring the guarantees of the method.

摘要：我們提出一個方法來取得統計上保證的信賴帶
用於函數式機器學習技術：代理模型在函數空間之間建立映射，動機是需要建立可靠的偏微分方程式模擬器。這個方法
在代理模型預測誤差的低維表徵（奇異值分解）上建立巢狀信賴集，然後使用集合傳播技術將這些集合映射到預測空間。結果是
類共形覆蓋保證預測集，適用於函數代理模型。我們使用區間多面體作為集合構造的基礎，因為它們的集合傳播和驗證性質研究得很好。這個方法
與模型無關，因此可以應用於複雜的 Sci-ML 模型，包括神經算子，但也可以應用於更簡單的設定。我們也引出一個技術來捕捉奇異值分解的截斷誤差，確保這個方法的保證。

##### **GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing**
2501.18413v1 by Shuyin Xia, Xiaoyu Lian, Binbin Sang, Guoyin Wang, Xinbo Gao

Fuzzy rough set theory is effective for processing datasets with complex
attributes, supported by a solid mathematical foundation and closely linked to
kernel methods in machine learning. Attribute reduction algorithms and
classifiers based on fuzzy rough set theory exhibit promising performance in
the analysis of high-dimensional multivariate complex data. However, most
existing models operate at the finest granularity, rendering them inefficient
and sensitive to noise, especially for high-dimensional big data. Thus,
enhancing the robustness of fuzzy rough set models is crucial for effective
feature selection. Muiti-garanularty granular-ball computing, a recent
development, uses granular-balls of different sizes to adaptively represent and
cover the sample space, performing learning based on these granular-balls. This
paper proposes integrating multi-granularity granular-ball computing into fuzzy
rough set theory, using granular-balls to replace sample points. The
coarse-grained characteristics of granular-balls make the model more robust.
Additionally, we propose a new method for generating granular-balls, scalable
to the entire supervised method based on granular-ball computing. A forward
search algorithm is used to select feature sequences by defining the
correlation between features and categories through dependence functions.
Experiments demonstrate the proposed model's effectiveness and superiority over
baseline methods.

摘要：模糊粗糙集理論對於處理具有複雜屬性的資料集是有效的，它有堅實的數學基礎，並且與機器學習中的核方法密切相關。基於模糊粗糙集理論的屬性簡約演算法和分類器在高維多變量複雜資料的分析中表現出良好的效能。然而，現有的模型大多以最精細的粒度運作，這使得它們在高維大資料中效率低落且容易受到雜訊的影響。因此，增強模糊粗糙集模型的穩健性對於有效的特徵選擇至關重要。多粒度粒球運算是一種最近的發展，它使用不同大小的粒球來適應性地表示和覆蓋樣本空間，並根據這些粒球執行學習。本文提出將多粒度粒球運算整合到模糊粗糙集理論中，使用粒球來取代樣本點。粒球的粗粒度特性使得模型更加穩健。此外，我們提出了一種新的生成粒球的方法，它可以擴展到基於粒球運算的整個監督式方法。正向搜尋演算法用於透過依賴函數定義特徵和類別之間的相關性來選擇特徵序列。實驗證明了所提出的模型的有效性和優於基線方法。

##### **Efficient Transformer for High Resolution Image Motion Deblurring**
2501.18403v1 by Amanturdieva Akmaral, Muhammad Hamza Zafar

This paper presents a comprehensive study and improvement of the Restormer
architecture for high-resolution image motion deblurring. We introduce
architectural modifications that reduce model complexity by 18.4% while
maintaining or improving performance through optimized attention mechanisms.
Our enhanced training pipeline incorporates additional transformations
including color jitter, Gaussian blur, and perspective transforms to improve
model robustness as well as a new frequency loss term. Extensive experiments on
the RealBlur-R, RealBlur-J, and Ultra-High-Definition Motion blurred (UHDM)
datasets demonstrate the effectiveness of our approach. The improved
architecture shows better convergence behavior and reduced training time while
maintaining competitive performance across challenging scenarios. We also
provide detailed ablation studies analyzing the impact of our modifications on
model behavior and performance. Our results suggest that thoughtful
architectural simplification combined with enhanced training strategies can
yield more efficient yet equally capable models for motion deblurring tasks.
Code and Data Available at: https://github.com/hamzafer/image-deblurring

摘要：本文提出了一項關於 Restormer 架構的全面研究和改進，用於高解析度影像動態去模糊。我們引入了架構修改，可將模型複雜度降低 18.4%，同時透過最佳化的注意力機制來維持或改善效能。我們的增強訓練管道納入了額外的轉換，包括色彩抖動、高斯模糊和透視轉換，以改善模型穩健性以及新的頻率損失項。在 RealBlur-R、RealBlur-J 和超高解析度動態模糊 (UHDM) 資料集上的廣泛實驗證明了我們方法的有效性。改良後的架構展現出更好的收斂行為和縮短的訓練時間，同時在具挑戰性的場景中維持具競爭力的效能。我們也提供了詳細的消融研究，分析了修改對模型行為和效能的影響。我們的結果表明，深思熟慮的架構簡化結合增強的訓練策略，可以產生更有效率但功能同樣強大的動態去模糊任務模型。程式碼和資料可於此取得：https://github.com/hamzafer/image-deblurring

##### **A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**
2501.18367v1 by Yifan Wang, Hongfeng Ai, Ruiqi Li, Maowei Jiang, Cheng Jiang, Chenzhong Li

In medical time series disease diagnosis, two key challenges are
identified.First, the high annotation cost of medical data leads to overfitting
in models trained on label-limited, single-center datasets. To address this, we
propose incorporating external data from related tasks and leveraging AE-GAN to
extract prior knowledge,providing valuable references for downstream tasks.
Second, many existing studies employ contrastive learning to derive more
generalized medical sequence representations for diagnostic tasks, usually
relying on manually designed diverse positive and negative sample
pairs.However, these approaches are complex, lack generalizability, and fail to
adaptively capture disease-specific features across different conditions.To
overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),
a framework that integrates a multi-head attention mechanism and adaptively
learns representations from different views through inter-view and intra-view
contrastive learning strategies.Additionally, the pre-trained AE-GAN is used to
reconstruct discrepancies in the target data as disease probabilities, which
are then integrated into the contrastive learning process.Experiments on three
target datasets demonstrate that our method consistently outperforms seven
other baselines, highlighting its significant impact on healthcare applications
such as the diagnosis of myocardial infarction, Alzheimer's disease, and
Parkinson's disease.

摘要：在医疗时间序列疾病诊断中，确定了两个关键挑战。首先，医疗数据的标注成本高，导致在标签受限的单中心数据集上训练的模型出现过拟合。为了解决这个问题，我们建议合并来自相关任务的外部数据，并利用 AE-GAN 提取先验知识，为下游任务提供有价值的参考。其次，许多现有的研究采用对比学习来推导出更通用的医疗序列表示，用于诊断任务，通常依赖于手动设计的各种正负样本对。然而，这些方法复杂，缺乏通用性，并且无法自适应地捕获不同条件下的特定疾病特征。为了克服这个问题，我们引入了 LMCF（可学习的多视图对比框架），这是一个集成了多头注意机制的框架，并通过视图间和视图内对比学习策略自适应地学习来自不同视图的表示。此外，预训练的 AE-GAN 用于重建目标数据中的差异作为疾病概率，然后将其集成到对比学习过程中。在三个目标数据集上的实验表明，我们的方法始终优于其他七个基线，突出了其对医疗保健应用（如心肌梗塞、阿尔茨海默病和帕金森病的诊断）的重大影响。

##### **RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects**
2501.18365v1 by Yiteng Tu, Weihang Su, Yujia Zhou, Yiqun Liu, Qingyao Ai

Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge retrieved from a knowledge base. However, its
effectiveness is fundamentally constrained by the reliability of both the
retriever and the knowledge base. In real-world scenarios, imperfections in
these components often lead to the retrieval of noisy, irrelevant, or
misleading counterfactual information, ultimately undermining the
trustworthiness of RAG systems. To address this challenge, we propose Robust
Fine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against
retrieval defects through two targeted fine-tuning tasks. Experimental results
demonstrate that RbFT significantly improves the robustness of RAG systems
across diverse retrieval conditions, surpassing existing methods while
maintaining high inference efficiency and compatibility with other robustness
techniques.

摘要：檢索增強生成 (RAG) 整合從知識庫中檢索到的外部知識，增強大型語言模型 (LLM)。然而，其有效性基本上受到檢索器和知識庫可靠性的限制。在實際情況中，這些組件的不完善經常導致檢索到有雜訊、不相關或誤導性的反事實資訊，最終損害 RAG 系統的可信度。為了應對此挑戰，我們提出穩健微調 (RbFT)，這是一種方法，旨在透過兩個目標微調任務來增強 LLM 抵抗檢索缺陷的韌性。實驗結果證明，RbFT 大幅提升 RAG 系統在各種檢索條件下的穩健性，超越現有方法，同時維持高推論效率，且與其他穩健性技術相容。

##### **MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**
2501.18362v1 by Yuxin Zuo, Shang Qu, Yifei Li, Zhangren Chen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding, Bowen Zhou

We introduce MedXpertQA, a highly challenging and comprehensive benchmark to
evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA
includes 4,460 questions spanning 17 specialties and 11 body systems. It
includes two subsets, Text for text evaluation and MM for multimodal
evaluation. Notably, MM introduces expert-level exam questions with diverse
images and rich clinical information, including patient records and examination
results, setting it apart from traditional medical multimodal benchmarks with
simple QA pairs generated from image captions. MedXpertQA applies rigorous
filtering and augmentation to address the insufficient difficulty of existing
benchmarks like MedQA, and incorporates specialty board questions to improve
clinical relevance and comprehensiveness. We perform data synthesis to mitigate
data leakage risk and conduct multiple rounds of expert reviews to ensure
accuracy and reliability. We evaluate 16 leading models on MedXpertQA.
Moreover, medicine is deeply connected to real-world decision-making, providing
a rich and representative setting for assessing reasoning abilities beyond
mathematics and code. To this end, we develop a reasoning-oriented subset to
facilitate the assessment of o1-like models.

摘要：我們推出了 MedXpertQA，這是一個極具挑戰性且全面的基準，用於評估專家級的醫學知識和先進的推理能力。MedXpertQA 包含 4,460 個問題，涵蓋 17 個專科和 11 個身體系統。它包含兩個子集，文本用於文本評估，MM 用於多模式評估。值得注意的是，MM 引入了專家級考試題目，其中包含多樣化的影像和豐富的臨床資訊，包括患者記錄和檢查結果，這讓它有別於傳統的醫學多模式基準，後者是從影像標題中產生的簡單問答對。MedXpertQA 採用嚴格的過濾和擴充，以解決 MedQA 等現有基準的難度不足問題，並納入專科委員會問題以提高臨床相關性和全面性。我們執行資料合成以降低資料外洩風險，並進行多輪專家審查以確保準確性和可靠性。我們在 MedXpertQA 上評估了 16 個領先的模型。此外，醫學與現實世界的決策制定有密切的聯繫，提供了豐富且具代表性的環境，用於評估超越數學和程式碼的推理能力。為此，我們開發了一個以推理為導向的子集，以利於評估類 o1 的模型。

##### **State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence**
2501.18356v1 by Thea Aviss

We introduce the State Stream Transformer (SST), a novel LLM architecture
that reveals emergent reasoning behaviours and capabilities latent in
pretrained weights through addressing a fundamental limitation in traditional
transformer models: the lack of latent computational continuity across
autoregressive generations in the state space. SST introduces a sliding window
latent state (FFN) cache with weighted decay that maintains and evolves
persistent latent processes throughout autoregressive generations. Through
controlled experiments comparing base and SST architectures using the same
frozen weights, we demonstrate that this architectural modification alone
enables enhanced reasoning capabilities which appear best explained by some
form of potential higher-order processing, as evidenced by emergent
metacognitive behaviours. These behaviours persist under controlled conditions
designed to eliminate confounding factors such as stochastic variation or
learned response patterns. Analysis of latent state distributions and
processing dynamics provides evidence that it is solely the 'state stream' that
is responsible for these phenomena. In quantitative evaluations, the SST
achieves substantial performance improvements over the base model on two
reasoning benchmarks, reaching 89.01\% accuracy on GSM-8K (0-shot) and 91.04\%
on ARC Challenge (0-shot CoT). These findings indicate that persistent
computation in the latent state space enables fundamentally different
information processing and internal reasoning strategies, with implications for
our understanding of artificial intelligence systems.

摘要：我們引入了狀態串流轉換器 (SST)，一種新穎的 LLM 架構，它透過解決傳統轉換器模型中的根本限制，揭示了預訓練權重中潛在的推理行為和能力：狀態空間中自迴歸生成缺乏潛在的計算連續性。SST 引入了具有加權衰減的滑動視窗潛在狀態 (FFN) 快取，可在整個自迴歸生成中維護和演化持久的潛在過程。透過使用相同凍結權重的受控實驗比較基礎和 SST 架構，我們證明了僅此架構修改就能增強推理能力，而這種能力最能透過某種形式的潛在高階處理來解釋，正如新興的元認知行為所證明的那樣。這些行為在受控條件下持續存在，這些條件旨在消除混雜因素，例如隨機變異或學習的反應模式。對潛在狀態分佈和處理動態的分析提供了證據，證明僅「狀態串流」對這些現象負責。在量化評估中，SST 在兩個推理基準上實現了比基礎模型大幅提升的效能，在 GSM-8K（0 次學習）上達到 89.01% 的準確度，在 ARC 挑戰（0 次學習 CoT）上達到 91.04%。這些發現表明，潛在狀態空間中的持續計算能實現根本不同的資訊處理和內部推理策略，對我們理解人工智慧系統具有影響。

##### **Transfer Learning of Surrogate Models: Integrating Domain Warping and Affine Transformations**
2501.18344v1 by Shuaiqun Pan, Diederick Vermetten, Manuel López-Ibáñez, Thomas Bäck, Hao Wang

Surrogate models provide efficient alternatives to computationally demanding
real-world processes but often require large datasets for effective training. A
promising solution to this limitation is the transfer of pre-trained surrogate
models to new tasks. Previous studies have investigated the transfer of
differentiable and non-differentiable surrogate models, typically assuming an
affine transformation between the source and target functions. This paper
extends previous research by addressing a broader range of transformations,
including linear and nonlinear variations. Specifically, we consider the
combination of an unknown input warping, such as one modelled by the beta
cumulative distribution function, with an unspecified affine transformation.
Our approach achieves transfer learning by employing a limited number of data
points from the target task to optimize these transformations, minimizing
empirical loss on the transfer dataset. We validate the proposed method on the
widely used Black-Box Optimization Benchmark (BBOB) testbed and a real-world
transfer learning task from the automobile industry. The results underscore the
significant advantages of the approach, revealing that the transferred
surrogate significantly outperforms both the original surrogate and the one
built from scratch using the transfer dataset, particularly in data-scarce
scenarios.

摘要：代理模型提供了一种高效的替代方案，可以替代计算要求很高的现实世界过程，但通常需要大型数据集来进行有效训练。解决此限制的一个有前途的解决方案是将预训练的代理模型转移到新任务。先前的研究调查了可微和不可微代理模型的转移，通常假设源函数和目标函数之间存在仿射变换。本文通过解决更广泛的变换（包括线性和非线性变异）扩展了先前的研究。具体来说，我们考虑将未知输入翘曲（例如由 beta 累积分布函数建模的输入翘曲）与未指定的仿射变换相结合。我们的方法通过利用目标任务中有限数量的数据点来优化这些变换，从而实现迁移学习，最大程度地减少迁移数据集上的经验损失。我们在广泛使用的黑盒优化基准 (BBOB) 测试平台和汽车行业的真实迁移学习任务上验证了所提出的方法。结果强调了该方法的显着优势，表明转移代理明显优于原始代理和使用转移数据集从头开始构建的代理，尤其是在数据稀缺的情况下。

##### **CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**
2501.18328v1 by Yicheng Wu, Tao Song, Zhonghua Wu, Zongyuan Ge, Zhaolin Chen, Jianfei Cai

MRI imputation aims to synthesize the missing modality from one or more
available ones, which is highly desirable since it reduces scanning costs and
delivers comprehensive MRI information to enhance clinical diagnosis. In this
paper, we propose a unified model, CodeBrain, designed to adapt to various
brain MRI imputation scenarios. The core design lies in casting various
inter-modality transformations as a full-modality code prediction task. To this
end, CodeBrain is trained in two stages: Reconstruction and Code Prediction.
First, in the Reconstruction stage, we reconstruct each MRI modality, which is
mapped into a shared latent space followed by a scalar quantization. Since such
quantization is lossy and the code is low dimensional, another MRI modality
belonging to the same subject is randomly selected to generate common features
to supplement the code and boost the target reconstruction. In the second
stage, we train another encoder by a customized grading loss to predict the
full-modality codes from randomly masked MRI samples, supervised by the
corresponding quantized codes generated from the first stage. In this way, the
inter-modality transformation is achieved by mapping the instance-specific
codes in a finite scalar space. We evaluated the proposed CodeBrain model on
two public brain MRI datasets (i.e., IXI and BraTS 2023). Extensive experiments
demonstrate that our CodeBrain model achieves superior imputation performance
compared to four existing methods, establishing a new state of the art for
unified brain MRI imputation. Codes will be released.

摘要：MRI 補完旨在從一個或多個可用方式中合成遺失的模態，這是非常理想的，因為它降低了掃描成本，並提供了全面的 MRI 資訊以增強臨床診斷。在本文中，我們提出了一個統一模型 CodeBrain，旨在適應各種腦部 MRI 補完場景。核心設計在於將各種模態間轉換轉換為全模態碼預測任務。為此，CodeBrain 分兩個階段進行訓練：重建和碼預測。首先，在重建階段，我們重建每個 MRI 模態，它被映射到一個共享潛在空間，然後進行標量量化。由於這種量化是有損的，並且碼的維度很低，因此隨機選擇屬於同一個受試者的另一個 MRI 模態來產生共同特徵以補充碼並提升目標重建。在第二階段，我們通過自訂分級損失訓練另一個編碼器，從隨機遮罩的 MRI 樣本預測全模態碼，並由第一階段產生的對應量化碼進行監督。這樣，模態間轉換是通過將特定於例項的碼映射到一個有限的標量空間來實現的。我們在兩個公開的腦部 MRI 資料集（即 IXI 和 BraTS 2023）上評估了所提出的 CodeBrain 模型。大量的實驗證明，與四種現有方法相比，我們的 CodeBrain 模型實現了優異的補完效能，為統一的腦部 MRI 補完建立了新的技術水準。碼將會釋出。

##### **A Video-grounded Dialogue Dataset and Metric for Event-driven Activities**
2501.18324v1 by Wiradee Imrattanatrai, Masaki Asada, Kimihiro Hasegawa, Zhi-Qi Cheng, Ken Fukuda, Teruko Mitamura

This paper presents VDAct, a dataset for a Video-grounded Dialogue on
Event-driven Activities, alongside VDEval, a session-based context evaluation
metric specially designed for the task. Unlike existing datasets, VDAct
includes longer and more complex video sequences that depict a variety of
event-driven activities that require advanced contextual understanding for
accurate response generation. The dataset comprises 3,000 dialogues with over
30,000 question-and-answer pairs, derived from 1,000 videos with diverse
activity scenarios. VDAct displays a notably challenging characteristic due to
its broad spectrum of activity scenarios and wide range of question types.
Empirical studies on state-of-the-art vision foundation models highlight their
limitations in addressing certain question types on our dataset. Furthermore,
VDEval, which integrates dialogue session history and video content summaries
extracted from our supplementary Knowledge Graphs to evaluate individual
responses, demonstrates a significantly higher correlation with human
assessments on the VDAct dataset than existing evaluation metrics that rely
solely on the context of single dialogue turns.

摘要：本文提出了 VDAct，一个用于事件驱动活动中的视频基础对话的数据集，以及 VDEval，一种专门为该任务设计的基于会话的上下文评估指标。与现有数据集不同，VDAct 包含更长且更复杂的视频序列，这些序列描述了各种事件驱动的活动，这些活动需要高级上下文理解才能生成准确的响应。该数据集包含 3,000 个对话，其中包含超过 30,000 个问答对，这些对话来自 1,000 个具有不同活动场景的视频。由于其广泛的活动场景和广泛的问题类型，VDAct 表现出显着的挑战性特征。对最先进的视觉基础模型的实证研究突出了它们在解决我们数据集中的某些问题类型方面的局限性。此外，VDEval 集成了对话会话历史记录和从我们的补充知识图谱中提取的视频内容摘要，以评估各个响应，与仅依赖于单个对话轮次上下文的现有评估指标相比，它与 VDAct 数据集上的人类评估具有显着更高的相关性。

##### **Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**
2501.18320v1 by Tianpeng Pan, Wenqiang Pu, Licheng Zhao, Rui Zhou

Automated optimization modeling (AOM) has evoked considerable interest with
the rapid evolution of large language models (LLMs). Existing approaches
predominantly rely on prompt engineering, utilizing meticulously designed
expert response chains or structured guidance. However, prompt-based techniques
have failed to perform well in the sensor array signal processing (SASP) area
due the lack of specific domain knowledge. To address this issue, we propose an
automated modeling approach based on retrieval-augmented generation (RAG)
technique, which consists of two principal components: a multi-agent (MA)
structure and a graph-based RAG (Graph-RAG) process. The MA structure is
tailored for the architectural AOM process, with each agent being designed
based on principles of human modeling procedure. The Graph-RAG process serves
to match user query with specific SASP modeling knowledge, thereby enhancing
the modeling result. Results on ten classical signal processing problems
demonstrate that the proposed approach (termed as MAG-RAG) outperforms several
AOM benchmarks.

摘要：自動化最佳化建模 (AOM) 隨著大型語言模型 (LLM) 的快速演進而引起相當大的興趣。現有方法主要依賴提示工程，利用精心設計的專家回應鏈或結構化指導。然而，基於提示的技術由於缺乏特定領域知識，無法在感測器陣列訊號處理 (SASP) 領域中表現良好。為了解決這個問題，我們提出一個基於檢索增強生成 (RAG) 技術的自動化建模方法，它包含兩個主要組成部分：多代理 (MA) 結構和基於圖形的 RAG (Graph-RAG) 程序。MA 結構是針對架構 AOM 程序量身打造，每個代理都是根據人類建模程序的原理設計的。Graph-RAG 程序用於將使用者查詢與特定的 SASP 建模知識相匹配，從而增強建模結果。在十個經典訊號處理問題上的結果表明，所提出的方法（稱為 MAG-RAG）優於多個 AOM 基準。

##### **Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis**
2501.18310v1 by Haoxiong Liu, Jiacheng Sun, Zhenguo Li, Andrew C Yao

The synergy between deep learning models and traditional automation tools
plays a pivotal role in developing robust neural theorem provers (NTPs).
However, for proof synthesis with LLMs, previous work applies automation tools
either only when the model explicitly calls the method, or only at a single
granularity level, failing to fully exploit the power of built-in tactics and
off-the-shelf automated theorem provers. In this work, we propose ProofAug, a
novel theorem proving method that enjoys superior sample efficiency through
equipping proof-generation LLMs with automation methods in different
granularities via fine-grained structure analysis of model-generated proof
proposals. Furthermore, ProofAug serves as a versatile plug-and-play module
that seamlessly integrates with any tree-search algorithm, enabling our
construction of an efficient recursive proving (ERP) module to further enhance
performance. The superiority of our method is validated on the miniF2F-test
benchmark using the open-source deepseek-math-7b-base model and the Isabelle
proof assistant. Notably, by additionally employing a mixed prompting strategy,
we achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9%
for the original version), setting a new SOTA across all proof languages with a
total sample budget of only 2100. Our code is available at
https://github.com/haoxiongliu/ProofAug.

摘要：深度學習模型與傳統自動化工具之間的綜效，在開發強大的神經定理證明器 (NTP) 中扮演著關鍵角色。然而，對於使用 LLM 的證明合成，先前的研究只在模型明確呼叫方法時應用自動化工具，或只在單一粒度層級應用，無法充分利用內建策略和現成的自動化定理證明器的能力。在這項研究中，我們提出 ProofAug，一種創新的定理證明方法，透過對模型產生的證明提案進行細粒度結構分析，以不同粒度為生成證明的 LLM 配備自動化方法，享受優異的樣本效率。此外，ProofAug 可作為一個多功能的即插即用模組，無縫整合到任何樹狀搜尋演算法中，讓我們能夠建構一個高效的遞迴證明 (ERP) 模組，進一步提升效能。我們的方法的優越性已在使用開放原始碼 deepseek-math-7b-base 模型和 Isabelle 證明輔助工具的 miniF2F 測試基準上獲得驗證。特別是，透過額外採用混合提示策略，我們在整理資料集後達成了 66.0% 的累積通過率（原始版本為 61.9%），在所有證明語言中設定了一個新的 SOTA，總樣本預算僅為 2100。我們的程式碼可在 https://github.com/haoxiongliu/ProofAug 取得。

##### **Model-Free RL Agents Demonstrate System 1-Like Intentionality**
2501.18299v1 by Hal Ashton, Matija Franklin

This paper argues that model-free reinforcement learning (RL) agents, while
lacking explicit planning mechanisms, exhibit behaviours that can be analogised
to System 1 ("thinking fast") processes in human cognition. Unlike model-based
RL agents, which operate akin to System 2 ("thinking slow") reasoning by
leveraging internal representations for planning, model-free agents react to
environmental stimuli without anticipatory modelling. We propose a novel
framework linking the dichotomy of System 1 and System 2 to the distinction
between model-free and model-based RL. This framing challenges the prevailing
assumption that intentionality and purposeful behaviour require planning,
suggesting instead that intentionality can manifest in the structured, reactive
behaviours of model-free agents. By drawing on interdisciplinary insights from
cognitive psychology, legal theory, and experimental jurisprudence, we explore
the implications of this perspective for attributing responsibility and
ensuring AI safety. These insights advocate for a broader, contextually
informed interpretation of intentionality in RL systems, with implications for
their ethical deployment and regulation.

摘要：本文主張無模型強化學習 (RL) 代理雖然缺乏明確的規劃機制，但表現出的行為可以類比為人類認知中的系統 1（「快速思考」）過程。與基於模型的 RL 代理不同，後者類似於系統 2（「慢速思考」）推理，利用內部表徵進行規劃，無模型代理對環境刺激做出反應，而無需預測建模。我們提出了一個新的框架，將系統 1 和系統 2 的二分法與無模型和基於模型的 RL 之間的區別聯繫起來。這種框架挑戰了普遍存在的假設，即意向性和有目的的行為需要規劃，而是表明意向性可以在無模型代理的結構化反應行為中體現。通過借鑒認知心理學、法律理論和實驗法學的跨學科見解，我們探討了這種觀點對歸責和確保 AI 安全的影響。這些見解主張對 RL 系統中的意向性進行更廣泛、基於背景的解釋，對其道德部署和監管產生影響。

##### **A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**
2501.18294v1 by Shayli Farshchiha, Salman Asoudeh, Maryam Shavali Kuhshuri, Mehrshad Eisaeid, Mohamadreza Azadie, Saba Hesaraki

Lung cancer is a major issue in worldwide public health, requiring early
diagnosis using stable techniques. This work begins a thorough investigation of
the use of machine learning (ML) methods for precise classification of lung
cancer stages. A cautious analysis is performed to overcome overfitting issues
in model performance, taking into account minimum child weight and learning
rate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,
Adaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),
CatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.
Furthermore, the correlation between features and targets is examined using the
deep neural network (DNN) model and thus their capability in detecting complex
patternsis established. It is argued that several ML models can be capable of
classifying lung cancer stages with great accuracy. In spite of the complexity
of DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic
Regression excel with superior performance. The models perform better than the
others in lung cancer prediction on the complete set of comparative metrics
like accuracy, precision, recall, and F-1 score

摘要：肺癌是全球公共衛生的一大問題，需要使用穩定的技術進行早期診斷。這項工作開始徹底調查使用機器學習 (ML) 方法精確分類肺癌分期的使用情況。執行謹慎的分析以克服模型效能中的過度擬合問題，並考慮最小子權重和學習率。一組機器學習 (ML) 模型，包括 XGBoost (XGB)、LGBM、Adaboost、邏輯迴歸 (LR)、決策樹 (DT)、隨機森林 (RF)、CatBoost 和 k 最近鄰 (k-NN)，以有條理的方式執行並進行對比。此外，使用深度神經網路 (DNN) 模型檢查特徵和目標之間的關聯性，從而建立它們在檢測複雜模式中的能力。有人認為，多個 ML 模型能夠以很高的準確度對肺癌分期進行分類。儘管 DNN 架構很複雜，但傳統 ML 模型（如 XGBoost、LGBM 和邏輯迴歸）表現出色，效能優異。這些模型在肺癌預測中表現優於其他模型，在準確度、精確度、召回率和 F-1 分數等完整的比較指標中表現出色。

##### **Citation Recommendation based on Argumentative Zoning of User Queries**
2501.18292v1 by Shutian Ma, Chengzhi Zhang, Heng Zhang, Zheng Gao

Citation recommendation aims to locate the important papers for scholars to
cite. When writing the citing sentences, the authors usually hold different
citing intents, which are referred to citation function in citation analysis.
Since argumentative zoning is to identify the argumentative and rhetorical
structure in scientific literature, we want to use this information to improve
the citation recommendation task. In this paper, a multi-task learning model is
built for citation recommendation and argumentative zoning classification. We
also generated an annotated corpus of the data from PubMed Central based on a
new argumentative zoning schema. The experimental results show that, by
considering the argumentative information in the citing sentence, citation
recommendation model will get better performance.

摘要：引文推薦旨在為學者找到重要的論文以供引用。在撰寫引用句子時，作者通常抱持不同的引用意圖，這在引文分析中稱為引文功能。由於論證區塊化是識別科學文獻中的論證和修辭結構，我們希望使用這些資訊來改善引文推薦任務。在本文中，建立了一個多任務學習模型，用於引文推薦和論證區塊化分類。我們還根據新的論證區塊化架構，從 PubMed Central 生成了資料的註解語料庫。實驗結果表明，透過考慮引文句子中的論證資訊，引文推薦模型將獲得更好的效能。

##### **CueTip: An Interactive and Explainable Physics-aware Pool Assistant**
2501.18291v1 by Sean Memery, Kevin Denamganai, Jiaxin Zhang, Zehai Tu, Yiwen Guo, Kartic Subr

We present an interactive and explainable automated coaching assistant called
CueTip for a variant of pool/billiards. CueTip's novelty lies in its
combination of three features: a natural-language interface, an ability to
perform contextual, physics-aware reasoning, and that its explanations are
rooted in a set of predetermined guidelines developed by domain experts. We
instrument a physics simulator so that it generates event traces in natural
language alongside traditional state traces. Event traces lend themselves to
interpretation by language models, which serve as the interface to our
assistant. We design and train a neural adaptor that decouples tactical choices
made by CueTip from its interactivity and explainability allowing it to be
reconfigured to mimic any pool playing agent. Our experiments show that CueTip
enables contextual query-based assistance and explanations while maintaining
the strength of the agent in terms of win rate (improving it in some
situations). The explanations generated by CueTip are physically-aware and
grounded in the expert rules and are therefore more reliable.

摘要：我們提出了一種互動且可解釋的自動化教練助理，稱為
CueTip，適用於撞球/台球的變體。CueTip 的新穎之處在於它
結合了三個特點：自然語言介面、執行情境感知、物理感知推理的能力，以及它的解釋根植於由領域專家開發的一組預先確定的指導方針。我們
使用物理模擬器，讓它產生自然語言事件追蹤，以及傳統狀態追蹤。事件追蹤有助於語言模型進行詮釋，這些模型作為我們
助理的介面。我們設計並訓練一個神經適配器，將 CueTip 做出的戰術選擇與其互動性和可解釋性分開，使其能夠重新配置以模仿任何撞球遊戲代理。我們的實驗表明，CueTip
能提供情境查詢協助和解釋，同時在獲勝率方面保持代理的實力（在某些情況下有所提升）。CueTip 生成的解釋具有物理感知，並基於專家規則，因此更可靠。

##### **Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: A Large-Scale Exploratory Study with Large Language Models**
2501.18287v1 by Jennifer D'Souza, Zachary Laubach, Tarek Al Mustafa, Sina Zarrieß, Robert Frühstückl, Phyllis Illari

This paper presents an exploratory study that harnesses the capabilities of
large language models (LLMs) to mine key ecological entities from invasion
biology literature. Specifically, we focus on extracting species names, their
locations, associated habitats, and ecosystems, information that is critical
for understanding species spread, predicting future invasions, and informing
conservation efforts. Traditional text mining approaches often struggle with
the complexity of ecological terminology and the subtle linguistic patterns
found in these texts. By applying general-purpose LLMs without domain-specific
fine-tuning, we uncover both the promise and limitations of using these models
for ecological entity extraction. In doing so, this study lays the groundwork
for more advanced, automated knowledge extraction tools that can aid
researchers and practitioners in understanding and managing biological
invasions.

摘要：這篇論文提出了一項探索性研究，利用大型語言模型 (LLM) 的功能，從入侵生物學文獻中挖掘關鍵的生態實體。具體來說，我們專注於萃取物種名稱、其位置、相關棲地和生態系統，這些資訊對於了解物種擴散、預測未來入侵和提供保育工作資訊至關重要。傳統的文字探勘方法通常難以應付生態術語的複雜性和這些文字中發現的細微語言模式。透過應用無特定領域微調的通用 LLM，我們發現使用這些模型進行生態實體萃取的優點和限制。在這樣做的過程中，這項研究為更進階、自動化的知識萃取工具奠定了基礎，這些工具可以協助研究人員和從業者了解和管理生物入侵。

##### **Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models**
2501.18280v1 by Haoyu Liang, Youran Sun, Yunfeng Cai, Jun Zhu, Bo Zhang

The security issue of large language models (LLMs) has gained significant
attention recently, with various defense mechanisms developed to prevent
harmful outputs, among which safeguards based on text embedding models serve as
a fundamental defense. Through testing, we discover that the distribution of
text embedding model outputs is significantly biased with a large mean.
Inspired by this observation, we propose novel efficient methods to search for
universal magic words that can attack text embedding models. The universal
magic words as suffixes can move the embedding of any text towards the bias
direction, therefore manipulate the similarity of any text pair and mislead
safeguards. By appending magic words to user prompts and requiring LLMs to end
answers with magic words, attackers can jailbreak the safeguard. To eradicate
this security risk, we also propose defense mechanisms against such attacks,
which can correct the biased distribution of text embeddings in a train-free
manner.

摘要：大型語言模型 (LLM) 的安全性問題最近受到廣泛關注，並開發了各種防禦機制來防止有害輸出，其中基於文字內嵌模型的防護措施作為基本防禦。透過測試，我們發現文字內嵌模型輸出的分佈顯著偏向於大平均值。受此觀察啟發，我們提出創新的有效方法來搜尋可攻擊文字內嵌模型的通用魔術字詞。通用魔術字詞作為後綴，可以將任何文字的內嵌移向偏向方向，因此可以操縱任何文字對的相似度並誤導防護措施。攻擊者可以將魔術字詞附加到使用者提示，並要求 LLM 以魔術字詞結束答案，即可破解防護措施。為了消除此安全性風險，我們也提出針對此類攻擊的防禦機制，它可以在不需訓練的情況下修正文字內嵌的偏向分佈。

##### **Pre-Trained Vision-Language Model Selection and Reuse for Downstream Tasks**
2501.18271v1 by Hao-Zhe Tan, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li

Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular
across various visual tasks, and several open-sourced VLM variants have been
released. However, selecting the best-performing pre-trained VLM for a specific
downstream task is challenging since no single VLM can achieve promising
performance on all downstream tasks, and evaluating all available VLMs is
impossible due to time and data limitations. To address this problem, this
paper proposes a novel paradigm to select and reuse VLM for downstream tasks,
called Model Label Learning (MLL). The proposal contains three key modules:
\emph{model labeling}, which assigns labels to each VLM to describe their
specialty and utility; \emph{model selection}, which matches the requirements
of the target task with model labels; and \emph{model reuse}, which applies
selected VLMs to the target task in an ensemble manner. The proposal is highly
computationally efficient and growable since the model labeling process is
completed target task independent and the ability could grow with the number of
candidate VLMs. We also introduce a new benchmark for evaluating VLM selection
methods, including 49 VLMs and 17 target task datasets. Experimental results
clearly demonstrate the effectiveness of the proposed method for selecting and
reusing VLMs.

摘要：<paragraph>預先訓練好的視覺語言模型 (VLM) 在各種視覺任務中越來越受歡迎，並且已經發布了數個開源的 VLM 變體。然而，為特定下游任務選擇效能最佳的預先訓練好的 VLM 具有挑戰性，因為沒有單一的 VLM 能夠在所有下游任務上達到有希望的效能，而且由於時間和資料的限制，無法評估所有可用的 VLM。為了解決這個問題，本文提出了一個新的範例來為下游任務選擇和重新使用 VLM，稱為模型標籤學習 (MLL)。該提案包含三個關鍵模組：\emph{模型標籤}，它為每個 VLM 指定標籤以描述其專長和效用；\emph{模型選擇}，它將目標任務的要求與模型標籤相匹配；以及\emph{模型重複使用}，它以整體方式將選定的 VLM 應用於目標任務。該提案具有高度的運算效率且可擴充，因為模型標籤處理是獨立於目標任務而完成，而且其能力會隨著候選 VLM 的數量而增加。我們還引入了新的基準來評估 VLM 選擇方法，包括 49 個 VLM 和 17 個目標任務資料集。實驗結果清楚地證明了所提出的方法在選擇和重新使用 VLM 方面的有效性。</paragraph>

##### **MAMS: Model-Agnostic Module Selection Framework for Video Captioning**
2501.18269v1 by Sangho Lee, Il Yong Chun, Hogun Park

Multi-modal transformers are rapidly gaining attention in video captioning
tasks. Existing multi-modal video captioning methods typically extract a fixed
number of frames, which raises critical challenges. When a limited number of
frames are extracted, important frames with essential information for caption
generation may be missed. Conversely, extracting an excessive number of frames
includes consecutive frames, potentially causing redundancy in visual tokens
extracted from consecutive video frames. To extract an appropriate number of
frames for each video, this paper proposes the first model-agnostic module
selection framework in video captioning that has two main functions: (1)
selecting a caption generation module with an appropriate size based on visual
tokens extracted from video frames, and (2) constructing subsets of visual
tokens for the selected caption generation module. Furthermore, we propose a
new adaptive attention masking scheme that enhances attention on important
visual tokens. Our experiments on three different benchmark datasets
demonstrate that the proposed framework significantly improves the performance
of three recent video captioning models.

摘要：多模态 Transformer 在影片字幕任务中迅速获得关注。现有的多模态影片字幕方法通常会萃取固定数量的帧，这带来了关键的挑战。当萃取有限数量的帧时，可能会漏掉包含字幕生成必要资讯的重要帧。相反地，萃取过多的帧会包含连续的帧，这可能会导致从连续影片帧萃取的视觉标记出现冗余。为了萃取适当数量的帧给每部影片，这篇论文提出了影片字幕中的第一个与模型无关的模块选择架构，该架构有两个主要功能：(1) 根据从影片帧萃取的视觉标记，选择具有适当大小的字幕生成模块，以及 (2) 为选定的字幕生成模块建构视觉标记子集。此外，我们提出了一种新的自适应注意力遮罩方案，该方案增强了对重要视觉标记的注意力。我们在三个不同的基准数据集上的实验表明，所提出的架构显著地改善了三个近期影片字幕模型的效能。

##### **Collecting Cost-Effective, High-Quality Truthfulness Assessments with LLM Summarized Evidence**
2501.18265v1 by Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro

With the degradation of guardrails against mis- and disinformation online, it
is more critical than ever to be able to effectively combat it. In this paper,
we explore the efficiency and effectiveness of using crowd-sourced truthfulness
assessments based on condensed, large language model (LLM) generated summaries
of online sources. We compare the use of generated summaries to the use of
original web pages in an A/B testing setting, where we employ a large and
diverse pool of crowd-workers to perform the truthfulness assessment. We
evaluate the quality of assessments, the efficiency with which assessments are
performed, and the behavior and engagement of participants. Our results
demonstrate that the Summary modality, which relies on summarized evidence,
offers no significant change in assessment accuracy over the Standard modality,
while significantly increasing the speed with which assessments are performed.
Workers using summarized evidence produce a significantly higher number of
assessments in the same time frame, reducing the cost needed to acquire
truthfulness assessments. Additionally, the Summary modality maximizes both the
inter-annotator agreements as well as the reliance on and perceived usefulness
of evidence, demonstrating the utility of summarized evidence without
sacrificing the quality of assessments.

摘要：<paragraph>隨著網路防範錯誤和錯誤資訊的護欄逐漸失效，有效打擊錯誤和錯誤資訊比以往任何時候都更加重要。在本文中，我們探討了使用基於大型語言模型 (LLM) 生成的線上來源摘要的群眾外包真實性評估的效率和效能。我們在 A/B 測試設定中比較了使用生成摘要與使用原始網頁，我們採用大量且多元的群眾工作者來執行真實性評估。我們評估評估的品質、執行評估的效率，以及參與者的行為和參與度。我們的結果證明了依賴摘要證據的摘要模式，在評估準確度上與標準模式相比沒有顯著變化，同時顯著提高了執行評估的速度。使用摘要證據的工作者在相同時間內產生的評估數量顯著較高，降低了取得真實性評估所需的成本。此外，摘要模式最大化了標記人員間的一致性，以及對證據的依賴性和感知有用性，證明了摘要證據的效用，同時不犧牲評估品質。</paragraph>

##### **How to Select Datapoints for Efficient Human Evaluation of NLG Models?**
2501.18251v1 by Vilém Zouhar, Peng Cui, Mrinmaya Sachan

Human evaluation is the gold-standard for evaluating text generation models.
It is also expensive, and to fit budgetary constraints, a random subset of the
test data is often chosen in practice. The randomly selected data may not
accurately represent test performance, making this approach economically
inefficient for model comparison. Thus, in this work, we develop a suite of
selectors to get the most informative datapoints for human evaluation while
taking the evaluation costs into account. We show that selectors based on
variance in automated metric scores, diversity in model outputs, or Item
Response Theory outperform random selection. We further develop an approach to
distill these selectors to the scenario where the model outputs are not yet
available. In particular, we introduce source-based estimators, which predict
item usefulness for human evaluation just based on the source texts. We
demonstrate the efficacy of our selectors in two common NLG tasks, machine
translation and summarization, and show that up to only ~50% of the test data
is needed to produce the same evaluation result as the entire data. Our
implementations are published in the subset2evaluate package.

摘要：人類評估是評估文字生成模型的金標準。
它也很昂貴，為了符合預算限制，在實務上通常會選擇測試資料的隨機子集。隨機選取的資料可能無法準確地代表測試效能，這使得這種方法在模型比較上經濟效益不佳。因此，在這項工作中，我們開發了一套選擇器，以取得人類評估最有意義的資料點，同時考量評估成本。我們證明了基於自動化指標分數的變異、模型輸出的多樣性或項目反應理論的選擇器優於隨機選擇。我們進一步開發了一種方法，將這些選擇器提煉到模型輸出尚未可用的情況。特別是，我們引入了基於來源的估計器，它僅根據原始文字預測項目對人類評估的有用性。我們在兩個常見的 NLG 任務（機器翻譯和摘要）中展示了我們選擇器的效能，並證明僅需要約 50% 的測試資料即可產生與完整資料相同的評估結果。我們的實作已發布在 subset2evaluate 套件中。

##### **Statistical multi-metric evaluation and visualization of LLM system predictive performance**
2501.18243v1 by Samuel Ackerman, Eitan Farchi, Orna Raz, Assaf Toledo

The evaluation of generative or discriminative large language model
(LLM)-based systems is often a complex multi-dimensional problem. Typically, a
set of system configuration alternatives are evaluated on one or more benchmark
datasets, each with one or more evaluation metrics, which may differ between
datasets. We often want to evaluate -- with a statistical measure of
significance -- whether systems perform differently either on a given dataset
according to a single metric, on aggregate across metrics on a dataset, or
across datasets. Such evaluations can be done to support decision-making, such
as deciding whether a particular system component change (e.g., choice of LLM
or hyperparameter values) significantly improves performance over the current
system configuration, or, more generally, whether a fixed set of system
configurations (e.g., a leaderboard list) have significantly different
performances according to metrics of interest. We present a framework
implementation that automatically performs the correct statistical tests,
properly aggregates the statistical results across metrics and datasets (a
nontrivial task), and can visualize the results. The framework is demonstrated
on the multi-lingual code generation benchmark CrossCodeEval, for several
state-of-the-art LLMs.

摘要：生成或判別式大型語言模型 (LLM) 為基礎的系統評估通常是一個複雜的多維度問題。一般來說，會針對一個或多個基準資料集評估一組系統組態替代方案，每個資料集會有一個或多個評估指標，而不同資料集的指標可能不同。我們通常希望評估系統在給定資料集上根據單一指標、在資料集上根據指標總和、或在不同資料集上執行是否有所不同，並附上統計顯著性衡量。此類評估可用於支援決策制定，例如決定特定系統元件變更（例如，LLM 或超參數值選擇）是否顯著提升效能，或更廣泛來說，是否有一組固定的系統組態（例如，排行榜清單）根據感興趣的指標具有顯著不同的效能。我們提出一個框架實作，可自動執行正確的統計檢定、適當地彙總不同指標和資料集的統計結果（一項非平凡的任務），並可視覺化結果。此框架在多語言程式碼生成基準 CrossCodeEval 上以多個最先進的 LLM 示範。

##### **Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**
2501.18237v1 by Malte Tölle, Mohamad Scharaf, Samantha Fischer, Christoph Reich, Silav Zeid, Christoph Dieterich, Benjamin Meder, Norbert Frey, Philipp Wild, Sandy Engelhardt

A patient undergoes multiple examinations in each hospital stay, where each
provides different facets of the health status. These assessments include
temporal data with varying sampling rates, discrete single-point measurements,
therapeutic interventions such as medication administration, and images. While
physicians are able to process and integrate diverse modalities intuitively,
neural networks need specific modeling for each modality complicating the
training procedure. We demonstrate that this complexity can be significantly
reduced by visualizing all information as images along with unstructured text
and subsequently training a conventional vision-text transformer. Our approach,
Vision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not
only simplifies data preprocessing and modeling but also outperforms current
state-of-the-art methods in predicting in-hospital mortality and phenotyping,
as evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities
include patient's clinical measurements, medications, X-ray images, and
electrocardiography scans. We hope our work inspires advancements in
multi-modal medical AI by reducing the training complexity to (visual) prompt
engineering, thus lowering entry barriers and enabling no-code solutions for
training. The source code will be made publicly available.

摘要：在每次住院期間，患者會接受多項檢查，每一項檢查都能提供健康狀態的不同面向。這些評估包括具有不同取樣率的時間資料、離散單點測量值、治療介入（如藥物管理）和影像。雖然醫生能夠直觀地處理和整合不同的模式，但神經網路需要針對每種模式進行特定的建模，這使得訓練程序變得複雜。我們證明，通過將所有資訊視覺化為影像，並結合非結構化文字，隨後訓練一個傳統的視覺文字轉換器，可以大幅降低這種複雜性。我們的做法，即用於不規則採樣多模式測量的視覺轉換器 (ViTiMM)，不僅簡化了資料預處理和建模，而且在預測院內死亡率和表型方面也優於目前的最新方法，這是根據 MIMIC-IV 資料集中的 6,175 名患者評估的。這些模式包括患者的臨床測量值、藥物、X 光影像和心電圖掃描。我們希望我們的工作能透過降低訓練複雜度到（視覺）提示工程，從而降低進入門檻，並為訓練啟用無程式碼解決方案，進而激勵多模式醫療 AI 的進步。原始程式碼將公開提供。

##### **Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark**
2501.18223v1 by Manuel F. Mollon, Joaquin Gonzalez-Rodriguez, Alicia Lozano-Diez, Daniel Ramos, Doroteo T. Toledano

In this study, we expand upon the FLIP benchmark-designed for evaluating
protein fitness prediction models in small, specialized prediction tasks-by
assessing the performance of state-of-the-art large protein language models,
including ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse
benchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP
focuses on constrained settings where data availability is limited. This makes
it an ideal framework to evaluate model performance in scenarios with scarce
task-specific data. We investigate whether recent advances in protein language
models lead to significant improvements in such settings. Our findings provide
valuable insights into the performance of large-scale models in specialized
protein prediction tasks.

摘要：在這項研究中，我們擴展了 FLIP 基準，該基準旨在評估蛋白質適應度預測模型在小型的、專門的預測任務中的表現，方法是評估在 FLIP 資料集上最先進的大蛋白質語言模型（包括 ESM-2 和 SaProt）的效能。與涵蓋廣泛任務的較大型、更多樣化的基準（例如 ProteinGym）不同，FLIP 專注於受限的設定，其中資料可用性受到限制。這使其成為在任務特定資料稀少的場景中評估模型效能的理想架構。我們調查了蛋白質語言模型的最新進展是否在這種設定中帶來顯著的改進。我們的研究結果提供了有價值的見解，了解大型模型在專門的蛋白質預測任務中的效能。

##### **Contextually Structured Token Dependency Encoding for Large Language Models**
2501.18205v1 by James Blades, Frederick Somerfield, William Langley, Susan Everingham, Maurice Witherington

Token representation strategies within large-scale neural architectures often
rely on contextually refined embeddings, yet conventional approaches seldom
encode structured relationships explicitly within token interactions.
Self-attention mechanisms effectively capture dynamic contextual dependencies,
but their reliance on learned weight distributions limits the preservation of
long-range hierarchical structures in generated sequences. Dependency-aware
token encoding introduces a structured approach to embedding initialization,
ensuring that relational constraints are embedded within token representations
rather than inferred solely through attention dynamics. The proposed encoding
mechanism refines token interactions through dependency-weighted attention
computations, ensuring that syntactic and semantic dependencies are retained
across multiple processing layers. Empirical evaluations indicate reductions in
perplexity across diverse linguistic benchmarks, suggesting improvements in
contextual coherence and predictive consistency in autoregressive text
generation. Computational efficiency assessments reveal a moderate increase in
memory consumption and training time, attributed to additional matrix
computations within the encoding module, yet scalability remains feasible
within conventional transformer architectures. Structured encoding enhances
lexical variation and dependency retention, reinforcing linguistic coherence
without requiring external syntactic annotations or auxiliary training
objectives. Statistical comparisons highlight improvements in dependency
alignment, particularly in longer sequences where conventional self-attention
models exhibit degradation in hierarchical consistency. Sentence length
distributions indicate a reduction in abrupt phrase transitions, further
supporting the hypothesis that explicit dependency encoding facilitates more
structured phrase generation.

摘要：<paragraph>大型神经网络架构中的标记表征策略通常依赖于上下文精炼嵌入，但传统方法很少在标记交互中明确编码结构化关系。自注意力机制有效地捕捉动态上下文相关性，但它们对学习权重分布的依赖限制了生成序列中长程分层结构的保留。依赖感知标记编码引入了一种结构化嵌入初始化方法，确保关系约束嵌入在标记表征中，而不是仅通过注意力动态推断。所提出的编码机制通过依赖加权注意力计算来优化标记交互，确保句法和语义依赖关系在多个处理层中得以保留。实证评估表明，在各种语言基准测试中困惑度降低，表明自回归文本生成中的上下文连贯性和预测一致性得到改善。计算效率评估显示内存消耗和训练时间适度增加，这归因于编码模块中额外的矩阵计算，但可扩展性在传统转换器架构中仍然可行。结构化编码增强了词汇变化和依赖性保留，加强了语言连贯性，而不需要外部句法注释或辅助训练目标。统计比较突出了依赖关系对齐的改进，特别是在传统自注意力模型在分层一致性方面表现出下降的较长序列中。句子长度分布表明突然的短语转换减少，进一步支持了显式依赖编码促进更结构化的短语生成的假设。</paragraph>

##### **On Scaling Neurosymbolic Programming through Guided Logical Inference**
2501.18202v1 by Thomas Jean-Michel Valentin, Luisa Sophie Werner, Pierre Genevès, Nabil Layaïda

Probabilistic neurosymbolic learning seeks to integrate neural networks with
symbolic programming. Many state-of-the-art systems rely on a reduction to the
Probabilistic Weighted Model Counting Problem (PWMC), which requires computing
a Boolean formula called the logical provenance.However, PWMC is \\#P-hard, and
the number of clauses in the logical provenance formula can grow exponentially,
creating a major bottleneck that significantly limits the applicability of PNL
solutions in practice.We propose a new approach centered around an exact
algorithm DPNL, that enables bypassing the computation of the logical
provenance.The DPNL approach relies on the principles of an oracle and a
recursive DPLL-like decomposition in order to guide and speed up logical
inference.Furthermore, we show that this approach can be adapted for
approximate reasoning with $\epsilon$ or $(\epsilon, \delta)$ guarantees,
called ApproxDPNL.Experiments show significant performance gains.DPNL enables
scaling exact inference further, resulting in more accurate models.Further,
ApproxDPNL shows potential for advancing the scalability of neurosymbolic
programming by incorporating approximations even further, while simultaneously
ensuring guarantees for the reasoning process.

摘要：機率神經符號學習旨在將神經網路與符號程式設計整合。許多最先進的系統仰賴機率加權模型計數問題 (PWMC) 的簡化，而這需要計算稱為邏輯來源的布林公式。然而，PWMC 是 \\#P-hard，且邏輯來源公式中的子句數量可能會呈指數成長，造成重大的瓶頸，大幅限制 PNL 解決方案在實務中的適用性。我們提出一個新的方法，其核心是一個精確演算法 DPNL，它能繞過邏輯來源的計算。DPNL 方法仰賴預言機的原理，以及遞迴 DPLL 類似分解，以便引導並加速邏輯推論。此外，我們顯示此方法可以改編為近似推理，並提供 $\epsilon$ 或 $(\epsilon, \delta)$ 保證，稱為 ApproxDPNL。實驗顯示出顯著的效能提升。DPNL 能進一步擴充精確推論，產生更精確的模型。此外，ApproxDPNL 顯示出透過進一步納入近似值，同時確保推理程序的保證，來提升神經符號程式的可擴充性的潛力。

##### **HKAN: Hierarchical Kolmogorov-Arnold Network without Backpropagation**
2501.18199v1 by Grzegorz Dudek, Tomasz Rodak

This paper introduces the Hierarchical Kolmogorov-Arnold Network (HKAN), a
novel network architecture that offers a competitive alternative to the
recently proposed Kolmogorov-Arnold Network (KAN). Unlike KAN, which relies on
backpropagation, HKAN adopts a randomized learning approach, where the
parameters of its basis functions are fixed, and linear aggregations are
optimized using least-squares regression. HKAN utilizes a hierarchical
multi-stacking framework, with each layer refining the predictions from the
previous one by solving a series of linear regression problems. This
non-iterative training method simplifies computation and eliminates sensitivity
to local minima in the loss function. Empirical results show that HKAN delivers
comparable, if not superior, accuracy and stability relative to KAN across
various regression tasks, while also providing insights into variable
importance. The proposed approach seamlessly integrates theoretical insights
with practical applications, presenting a robust and efficient alternative for
neural network modeling.

摘要：本文介紹了分層 Kolmogorov-Arnold 網路 (HKAN)，這是一種新穎的網路架構，可提供與最近提出的 Kolmogorov-Arnold 網路 (KAN) 相抗衡的選擇。與依賴反向傳播的 KAN 不同，HKAN 採用隨機學習方法，其中其基底函數的參數是固定的，而線性聚合則是使用最小二乘回歸進行最佳化。HKAN 利用分層多堆疊架構，其中每一層透過解決一系列線性回歸問題來改善前一層的預測。這種非反覆訓練方法簡化了運算，並消除了損失函數中對局部最小值的敏感性。經驗結果顯示，HKAN 在各種回歸任務中提供了與 KAN 相當甚至更好的準確性和穩定性，同時也提供了變數重要性的見解。所提出的方法將理論見解與實際應用無縫整合，為神經網路建模提供了一個強健且有效率的替代方案。

##### **Economic Rationality under Specialization: Evidence of Decision Bias in AI Agents**
2501.18190v1 by ShuiDe Wen, Juan Feng

In the study by Chen et al. (2023) [01], the large language model GPT
demonstrated economic rationality comparable to or exceeding the average human
level in tasks such as budget allocation and risk preference. Building on this
finding, this paper further incorporates specialized agents, such as
biotechnology experts and economists, for a horizontal comparison to explore
whether specialization can enhance or maintain economic rationality equivalent
to that of GPT in similar decision-making scenarios. The results indicate that
when agents invest more effort in specialized fields, their decision-making
behavior is more prone to 'rationality shift,' specifically manifested as
increased violations of GARP (Generalized Axiom of Revealed Preference),
decreased CCEI (Critical Cost Efficiency Index), and more significant decision
deviations under high-risk conditions. In contrast, GPT and more generalized
basic agents maintain a more stable and consistent level of rationality across
multiple tasks. This study reveals the inherent conflict between specialization
and economic rationality, providing new insights for constructing AI
decision-making systems that balance specialization and generalization across
various scenarios.

摘要：在 Chen et al. (2023) [01] 的研究中，大型語言模型 GPT 在預算分配和風險偏好等任務中展現出與人類平均水準相當甚至更高的經濟理性。本篇論文以此發現為基礎，進一步納入生物技術專家和經濟學家等專業代理，進行橫向比較，探討專業化是否能提升或維持與 GPT 在類似決策情境中相當的經濟理性。結果顯示，當代理在專業領域投入更多心力時，其決策行為較容易出現「理性偏移」，具體表現為違反 GARP（揭示性偏好廣義公理）的次數增加、CCEI（臨界成本效率指數）降低，以及在高風險條件下決策偏差更大。相較之下，GPT 和較為通才的基本代理在多項任務中維持較穩定且一致的理性水準。本研究揭示了專業化與經濟理性之間的內在衝突，為建構在各種情境中平衡專業化和通才化的 AI 決策系統提供了新見解。

##### **In-Context Learning of Polynomial Kernel Regression in Transformers with GLU Layers**
2501.18187v1 by Haoyuan Sun, Ali Jadbabaie, Navid Azizan

Transformer-based models have demonstrated remarkable ability in in-context
learning (ICL), where they can adapt to unseen tasks from a prompt with a few
examples, without requiring parameter updates. Recent research has provided
insight into how linear Transformers can perform ICL by implementing gradient
descent estimators. In particular, it has been shown that the optimal linear
self-attention (LSA) mechanism can implement one step of gradient descent with
respect to a linear least-squares objective when trained on random linear
regression tasks.
  However, the theoretical understanding of ICL for nonlinear function classes
remains limited. In this work, we address this gap by first showing that LSA is
inherently restricted to solving linear least-squares objectives and thus, the
solutions in prior works cannot readily extend to nonlinear ICL tasks. To
overcome this limitation, drawing inspiration from modern architectures, we
study a mechanism that combines LSA with GLU-like feed-forward layers and show
that this allows the model to perform one step of gradient descent on a
polynomial kernel regression. Further, we characterize the scaling behavior of
the resulting Transformer model, highlighting the necessary model size to
effectively handle quadratic ICL tasks. Our findings highlight the distinct
roles of attention and feed-forward layers in nonlinear ICL and identify key
challenges when extending ICL to nonlinear function classes.

摘要：基於 Transformer 的模型已在情境中學習 (ICL) 中展現出非凡的能力，它們可以在提示中根據幾個範例適應未見過的工作，而無需參數更新。最近的研究提供了線性 Transformer 如何透過實作梯度下降估計器來執行 ICL 的見解。特別是，已顯示最佳線性自注意力 (LSA) 機制可以在隨機線性回歸工作上訓練時，針對線性最小平方目標實作一步梯度下降。
然而，對於非線性函數類別的 ICL 的理論理解仍然有限。在這項工作中，我們首先透過顯示 LSA 本質上僅限於求解線性最小平方目標，因此先前的著作中的解決方案無法輕易延伸到非線性 ICL 工作，來解決這個差距。為了克服這個限制，我們從現代架構中汲取靈感，研究一種將 LSA 與 GLU 類似的前饋層結合的機制，並顯示這允許模型在多項式核回歸上執行一步梯度下降。此外，我們描述了結果 Transformer 模型的縮放行為，強調有效處理二次 ICL 工作所需的模型大小。我們的發現突出了注意力和前饋層在非線性 ICL 中的不同角色，並在將 ICL 延伸到非線性函數類別時，識別出關鍵挑戰。

##### **Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**
2501.18154v1 by Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the quantized and
original weights. To enhance the quantization performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign quantization bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of quantization strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
quantization performance under low-bit conditions.

摘要：訓練後量化 (PTQ) 對於在資源受限的設定中部署大型語言模型 (LLM) 至關重要，因為它能顯著降低資源需求。然而，現有的 PTQ 策略在低位元層級 < 3 位元時表現不佳，因為量化後的權重與原始權重之間有顯著的差異。為了提升低位元寬度的量化效能，我們提出混合精度圖神經網路 PTQ (MG-PTQ) 方法，採用圖神經網路 (GNN) 模組來擷取權重之間的依存關係，並動態分配量化位元寬度。透過 GNN 模組的資訊傳播，我們的方法能更有效地擷取目標權重之間的依存關係，進而更準確地評估權重重要性，並最佳化量化策略的配置。在 WikiText2 和 C4 資料集上的廣泛實驗證明，我們的 MG-PTQ 方法優於先前的最先進 PTQ 方法 GPTQ，在低位元條件下設定了量化效能的新基準。

##### **Tensor Completion for Surrogate Modeling of Material Property Prediction**
2501.18137v1 by Shaan Pakala, Dawon Ahn, Evangelos Papalexakis

When designing materials to optimize certain properties, there are often many
possible configurations of designs that need to be explored. For example, the
materials' composition of elements will affect properties such as strength or
conductivity, which are necessary to know when developing new materials.
Exploring all combinations of elements to find optimal materials becomes very
time consuming, especially when there are more design variables. For this
reason, there is growing interest in using machine learning (ML) to predict a
material's properties. In this work, we model the optimization of certain
material properties as a tensor completion problem, to leverage the structure
of our datasets and navigate the vast number of combinations of material
configurations. Across a variety of material property prediction tasks, our
experiments show tensor completion methods achieving 10-20% decreased error
compared with baseline ML models such as GradientBoosting and Multilayer
Perceptron (MLP), while maintaining similar training speed.

摘要：在設計材料以最佳化特定屬性時，常有許多可能的設計配置需要探討。例如，材料的元素組成會影響強度或導電性等屬性，而這些屬性在開發新材料時是必須知道的。探索所有元素組合以找出最佳材料會非常耗時，尤其是在有更多設計變數時。因此，使用機器學習 (ML) 來預測材料屬性正受到越來越多的關注。在這項工作中，我們將特定材料屬性的最佳化建模為張量完成問題，以利用我們資料集的結構，並在大量的材料配置組合中導航。在各種材料屬性預測任務中，我們的實驗顯示，與 GradientBoosting 和多層感知器 (MLP) 等基準 ML 模型相比，張量完成方法可將誤差降低 10-20%，同時維持類似的訓練速度。

##### **Entropy-Synchronized Neural Hashing for Unsupervised Ransomware Detection**
2501.18131v1 by Peter Idliman, Wilfred Balfour, Benedict Featheringham, Hugo Chesterfield

Entropy-based detection methodologies have gained significant attention due
to their ability to analyze structural irregularities within executable files,
particularly in the identification of malicious software employing advanced
obfuscation techniques. The Entropy-Synchronized Neural Hashing (ESNH)
framework introduces a novel approach that leverages entropy-driven hash
representations to classify software binaries based on their underlying entropy
characteristics. Through the synchronization of entropy profiles with neural
network architectures, the model generates robust and unique hash values that
maintain stability even when faced with polymorphic and metamorphic
transformations. Comparative analysis against traditional detection approaches
revealed superior performance in identifying novel threats, reducing
false-positive rates, and achieving consistent classification across diverse
ransomware families. The incorporation of a self-regulating hash convergence
mechanism further ensured that entropy-synchronized hashes remained invariant
across executions, minimizing classification inconsistencies that often arise
due to dynamic modifications in ransomware payloads. Experimental results
demonstrated high detection rates across contemporary ransomware strains, with
the model exhibiting resilience against encryption-based evasion mechanisms,
code injection strategies, and reflective loading techniques. Unlike
conventional detection mechanisms that rely on static signatures and heuristic
analysis, the proposed entropy-aware classification framework adapts to
emerging threats through an inherent ability to capture entropy anomalies
within executable structures. The findings reinforce the potential of
entropy-based detection in addressing the limitations of traditional
methodologies while enhancing detection robustness against obfuscation and
adversarial evasion techniques.

摘要：基於熵的偵測方法論因其分析可執行檔案中結構不規則性的能力而備受關注，特別是在識別採用進階混淆技術的惡意軟體方面。熵同步神經雜湊 (ESNH) 架構引入一種新穎的方法，它利用熵驅動雜湊表示，根據其底層熵特徵對軟體二進位檔進行分類。透過將熵特徵檔與神經網路架構同步，此模型會產生強健且獨特的雜湊值，即使面對多型和變形轉換，也能維持穩定性。與傳統偵測方法的比較分析顯示，在識別新威脅、降低誤報率和對各種勒索軟體系列進行一致性分類方面，此方法具有優異的效能。整合自我調節雜湊收斂機制進一步確保熵同步雜湊在執行過程中保持不變，將因勒索軟體酬載中的動態修改而經常產生的分類不一致性降至最低。實驗結果顯示，在當代勒索軟體變種中，偵測率很高，此模型對基於加密的迴避機制、程式碼注入策略和反射載入技術具有韌性。與依賴靜態特徵碼和啟發式分析的傳統偵測機制不同，所提出的熵感知分類架構透過固有能力擷取可執行結構中的熵異常，適應新興威脅。這些發現強化了基於熵的偵測在解決傳統方法論限制方面的潛力，同時增強了對混淆和對抗性迴避技術的偵測強健性。

##### **Unraveling the Capabilities of Language Models in News Summarization**
2501.18128v1 by Abdurrahman Odabaşı, Göksel Biricik

Given the recent introduction of multiple language models and the ongoing
demand for improved Natural Language Processing tasks, particularly
summarization, this work provides a comprehensive benchmarking of 20 recent
language models, focusing on smaller ones for the news summarization task. In
this work, we systematically test the capabilities and effectiveness of these
models in summarizing news article texts which are written in different styles
and presented in three distinct datasets. Specifically, we focus in this study
on zero-shot and few-shot learning settings and we apply a robust evaluation
methodology that combines different evaluation concepts including automatic
metrics, human evaluation, and LLM-as-a-judge. Interestingly, including
demonstration examples in the few-shot learning setting did not enhance models'
performance and, in some cases, even led to worse quality of the generated
summaries. This issue arises mainly due to the poor quality of the gold
summaries that have been used as reference summaries, which negatively impacts
the models' performance. Furthermore, our study's results highlight the
exceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate
due to their advanced capabilities. However, among the public models evaluated,
certain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B
and Zephyr-7B-Beta demonstrated promising results. These models showed
significant potential, positioning them as competitive alternatives to large
models for the task of news summarization.

摘要：鉴于最近推出了多语言模型，并且对改进自然语言处理任务（尤其是摘要）的需求不断增长，这项工作对 20 个最近的语言模型进行了全面的基准测试，重点关注针对新闻摘要任务的较小模型。在这项工作中，我们系统地测试了这些模型在总结以不同风格撰写并呈现在三个不同数据集中的新闻文章文本方面的能力和有效性。具体来说，我们在这项研究中专注于零样本和少样本学习设置，并且我们应用了一种稳健的评估方法，该方法结合了不同的评估概念，包括自动指标、人工评估和 LLM 作为评委。有趣的是，在少样本学习设置中包含演示示例并没有提高模型的性能，在某些情况下甚至导致生成摘要的质量下降。这个问题主要是因为用作参考摘要的黄金摘要质量较差，这会对模型的性能产生负面影响。此外，我们研究的结果突出了 GPT-3.5-Turbo 和 GPT-4 的卓越性能，它们通常由于其高级功能而占据主导地位。然而，在评估的公共模型中，某些模型（例如 Qwen1.5-7B、SOLAR-10.7B-Instruct-v1.0、Meta-Llama-3-8B 和 Zephyr-7B-Beta）展示了有希望的结果。这些模型显示出巨大的潜力，将它们定位为新闻摘要任务中大型模型的有竞争力的替代品。

##### **VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical Constraints**
2501.18122v1 by Xinyu Wang, Lei Liu, Kang Chen, Tao Han, Bin Li, Lei Bai

Tropical cyclone (TC) intensity forecasting is crucial for early disaster
warning and emergency decision-making. Numerous researchers have explored
deep-learning methods to address computational and post-processing issues in
operational forecasting. Regrettably, they exhibit subpar long-term forecasting
capabilities. We use two strategies to enhance long-term forecasting. (1) By
enhancing the matching between TC intensity and spatial information, we can
improve long-term forecasting performance. (2) Incorporating physical knowledge
and physical constraints can help mitigate the accumulation of forecasting
errors. To achieve the above strategies, we propose the VQLTI framework. VQLTI
transfers the TC intensity information to a discrete latent space while
retaining the spatial information differences, using large-scale spatial
meteorological data as conditions. Furthermore, we leverage the forecast from
the weather prediction model FengWu to provide additional physical knowledge
for VQLTI. Additionally, we calculate the potential intensity (PI) to impose
physical constraints on the latent variables. In the global long-term TC
intensity forecasting, VQLTI achieves state-of-the-art results for the 24h to
120h, with the MSW (Maximum Sustained Wind) forecast error reduced by
35.65%-42.51% compared to ECMWF-IFS.

摘要：熱帶氣旋 (TC) 強度預測對於早期災害警報和緊急決策制定至關重要。許多研究人員已經探討了深度學習方法，以解決運算和後處理問題，用於作業預測。遺憾的是，它們表現出低於標準的長期預測能力。我們使用兩種策略來增強長期預測。(1) 透過增強 TC 強度和空間資訊之間的匹配，我們可以改善長期預測效能。(2) 結合物理知識和物理約束有助於減輕預測誤差的累積。為了達成上述策略，我們提出了 VQLTI 架構。VQLTI 將 TC 強度資訊傳輸到離散潛在空間，同時保留空間資訊差異，使用大規模空間氣象資料作為條件。此外，我們利用天氣預測模型 FengWu 的預測，為 VQLTI 提供額外的物理知識。此外，我們計算潛在強度 (PI)，對潛在變數施加物理約束。在全球長期 TC 強度預測中，VQLTI 達到了 24 小時至 120 小時的最新結果，與 ECMWF-IFS 相比，最大持續風速 (MSW) 預測誤差降低了 35.65%-42.51%。

##### **Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**
2501.18119v1 by Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply quantized codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
quantized methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.

摘要：由於知識圖譜 (KG) 結構與自然語言之間存在自然差距，將 KG 的整體結構資訊與大型語言模型 (LLM) 有效整合已成為一個重要的問題。為此，我們提出了一個兩階段架構來學習和應用每個實體的量化碼，旨在將 KG 與 LLM 無縫整合。首先，提出了一個自監督量化表示 (SSQR) 方法，將 KG 結構和語義知識壓縮成離散碼（即，符號），以對齊語言句子的格式。我們進一步設計 KG 指令遵循資料，將這些學習到的碼視為直接輸入 LLM 的特徵，從而實現無縫整合。實驗結果表明，SSQR 優於現有的無監督量化方法，產生更具區別性的碼。此外，微調後的 LLaMA2 和 LLaMA3.1 在 KG 連結預測和三元分類任務上也具有優異的性能，每個實體僅使用 16 個符號，而不是傳統提示方法中的數千個。

##### **Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**
2501.18108v1 by Min Hun Lee, Daniel P. Siewiorek, Alexandre Bernardino

Despite the growing potential of older adult care technologies, the adoption
of these technologies remains challenging. In this work, we conducted a
focus-group session with family caregivers to scope designs of the older adult
care technology. We then developed a high-fidelity prototype and conducted its
qualitative study with professional caregivers and older adults to understand
their perspectives on the system functionalities. This system monitors abnormal
activity patterns of older adults using wireless motion sensors and machine
learning models and supports interactive dialogue responses to explain abnormal
activity patterns of older adults to caregivers and allow older adults
proactively sharing their status with caregivers for an adequate intervention.
Both older adults and professional caregivers appreciated that our system can
provide a faster, personalized service while proactively controlling what
information is to be shared through interactive dialogue responses. We further
discuss other considerations to realize older adult technology in practice.

摘要：儘管老年人照護技術的潛力日益增長，但採用這些技術仍具有挑戰性。在這項研究中，我們與家庭照護者進行焦點小組會議，以界定老年人照護技術的設計範圍。接著，我們開發了一個高保真原型，並與專業照護者和老年人進行質性研究，以了解他們對系統功能的觀點。此系統使用無線動作感測器和機器學習模型監控老年人的異常活動模式，並支援互動式對話回應，向照護者解釋老年人的異常活動模式，並讓老年人主動與照護者分享他們的狀態，以進行適當的介入。老年人和專業照護者都讚賞我們的系統能提供更快速、個人化的服務，同時透過互動式對話回應主動控制要分享哪些資訊。我們進一步討論其他考量因素，以在實務中實現老年人技術。

##### **Scaling Inference-Efficient Language Models**
2501.18107v1 by Song Bian, Minghao Yan, Shivaram Venkataraman

Scaling laws are powerful tools to predict the performance of large language
models. However, current scaling laws fall short of accounting for inference
costs. In this work, we first show that model architecture affects inference
latency, where models of the same size can have up to 3.5x difference in
latency. To tackle this challenge, we modify the Chinchilla scaling laws to
co-optimize the model parameter count, the number of training tokens, and the
model architecture. Due to the reason that models of similar training loss
exhibit gaps in downstream evaluation, we also propose a novel method to train
inference-efficient models based on the revised scaling laws. We perform
extensive empirical studies to fit and evaluate our inference-aware scaling
laws. We vary model parameters from 80M to 1B, training tokens from 1.6B to
30B, and model shapes, training a total of 63 models. Guided by our
inference-efficient scaling law and model selection method, we release the
Morph-1B model, which improves inference latency by 1.8x while maintaining
accuracy on downstream tasks compared to open-source models, pushing the Pareto
frontier of accuracy-latency tradeoff.

摘要：規模化法則是用來預測大型語言模型效能的強大工具。然而，當前的規模化法則並未考慮推論成本。在這項研究中，我們首先展示模型架構會影響推論延遲，其中相同大小的模型在延遲上可能會有高達 3.5 倍的差異。為了應對這個挑戰，我們修改了 Chinchilla 規模化法則，以共同最佳化模型參數計數、訓練令牌數和模型架構。由於訓練損失類似的模型在下游評估中表現出差距，我們還提出了一種基於修改後的規模化法則訓練推論效率模型的新方法。我們進行廣泛的實證研究，以擬合和評估我們推論感知的規模化法則。我們將模型參數從 80M 變更到 1B，訓練令牌從 1.6B 變更到 30B，以及模型形狀，總共訓練了 63 個模型。在我們的推論效率規模化法則和模型選擇方法的指導下，我們發布了 Morph-1B 模型，與開放原始碼模型相比，它將推論延遲降低了 1.8 倍，同時維持了下游任務的準確性，推動了準確度-延遲權衡的帕累托前緣。

##### **Diverse Preference Optimization**
2501.18101v1 by Jack Lanchantin, Angelica Chen, Shehzaad Dhuliawala, Ping Yu, Jason Weston, Sainbayar Sukhbaatar, Ilia Kulikov

Post-training of language models, either through reinforcement learning,
preference optimization or supervised finetuning, tends to sharpen the output
probability distribution and reduce the diversity of generated responses. This
is particularly a problem for creative generative tasks where varied responses
are desired. %This impacts the ability to generate high quality synthetic data
which is becoming a vital component of model training. In this work we
introduce Diverse Preference Optimization (DivPO), an online optimization
method which learns to generate much more diverse responses than standard
pipelines, while maintaining the quality of the generations. In DivPO,
preference pairs are selected by first considering a pool of responses, and a
measure of diversity among them, and selecting chosen examples as being more
rare but high quality, while rejected examples are more common, but low
quality. DivPO results in generating 45.6% more diverse persona attributes, and
an 74.6% increase in story diversity, while maintaining similar win rates as
standard baselines.

摘要：語言模型的後續訓練，不論是透過強化學習、偏好最佳化或監督微調，往往會銳化輸出機率分佈，並降低產出回應的多樣性。這特別是創意生成任務的問題，因為這些任務需要多樣化的回應。這會影響產生高品質合成資料的能力，而合成資料正成為模型訓練的重要組成部分。在這項工作中，我們引入了多樣化偏好最佳化 (DivPO)，這是一種線上最佳化方法，它會學習產生比標準管線更為多樣化的回應，同時維持產出的品質。在 DivPO 中，偏好對會先從回應池中選出，並從中衡量多樣性，然後選擇較罕見但品質較高的範例，而被拒絕的範例則較常見，但品質較低。DivPO 產生了多樣化角色屬性增加了 45.6%，故事多樣性增加了 74.6%，同時維持與標準基準線類似的獲勝率。

##### **Panacea: Mitigating Harmful Fine-tuning for Large Language Models via Post-fine-tuning Perturbation**
2501.18100v1 by Yibo Wang, Tiansheng Huang, Li Shen, Huanjin Yao, Haotian Luo, Rui Liu, Naiqiang Tan, Jiaxing Huang, Dacheng Tao

Harmful fine-tuning attack introduces significant security risks to the
fine-tuning services. Mainstream defenses aim to vaccinate the model such that
the later harmful fine-tuning attack is less effective. However, our evaluation
results show that such defenses are fragile -- with a few fine-tuning steps,
the model still can learn the harmful knowledge. To this end, we do further
experiment and find that an embarrassingly simple solution -- adding purely
random perturbations to the fine-tuned model, can recover the model from
harmful behavior, though it leads to a degradation in the model's fine-tuning
performance. To address the degradation of fine-tuning performance, we further
propose Panacea, which optimizes an adaptive perturbation that will be applied
to the model after fine-tuning. Panacea maintains model's safety alignment
performance without compromising downstream fine-tuning performance.
Comprehensive experiments are conducted on different harmful ratios,
fine-tuning tasks and mainstream LLMs, where the average harmful scores are
reduced by up-to 21.5%, while maintaining fine-tuning performance. As a
by-product, we analyze the optimized perturbation and show that different
layers in various LLMs have distinct safety coefficients. Source code available
at https://github.com/w-yibo/Panacea

摘要：有害微調攻擊對微調服務引入重大的安全風險。主流防禦旨在接種模型，以降低後續的有害微調攻擊的效力。然而，我們的評估結果顯示，此類防禦很脆弱——只需幾個微調步驟，模型仍然可以學習有害知識。為此，我們進一步進行實驗，發現一個令人尷尬的簡單解決方案——在微調模型中加入純隨機擾動，可以讓模型從有害行為中恢復，儘管這會導致模型微調性能下降。為了解決微調性能下降的問題，我們進一步提出 Panacea，它優化了將在微調後應用於模型的自適應擾動。Panacea 保持了模型的安全對齊性能，同時不影響下游微調性能。在不同的有害比率、微調任務和主流 LLM 上進行了綜合實驗，平均有害分數降低了 21.5%，同時保持了微調性能。作為副產品，我們分析了優化的擾動，並展示了各種 LLM 中的不同層具有不同的安全係數。源代碼可在 https://github.com/w-yibo/Panacea 獲得

##### **Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge**
2501.18099v1 by Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, Tianlu Wang

LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to
capture the step-bystep reasoning process that underlies the final evaluation
of a response. However, due to the lack of human annotated CoTs for evaluation,
the required components and structure of effective reasoning traces remain
understudied. Consequently, previous approaches often (1) constrain reasoning
traces to hand-designed components, such as a list of criteria, reference
answers, or verification questions and (2) structure them such that planning is
intertwined with the reasoning for evaluation. In this work, we propose
EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge
that first generates an unconstrained evaluation plan, followed by its
execution, and then the final judgment. In a self-training loop, EvalPlanner
iteratively optimizes over synthetically constructed evaluation plans and
executions, leading to better final verdicts. Our method achieves a new
state-of-the-art performance for generative reward models on RewardBench (with
a score of 93.9), despite being trained on fewer amount of, and synthetically
generated, preference pairs. Additional experiments on other benchmarks like
RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both
planning and reasoning for building robust LLM-as-a-Judge reasoning models.

摘要：LLM-as-a-Judge 模型會產生思想鏈 (CoT) 序列，旨在捕捉最終評估回應背後的逐步推理過程。然而，由於缺乏用於評估的人類註解 CoT，有效推理軌跡所需的組成部分和結構仍然未得到充分研究。因此，先前的做法通常 (1) 將推理軌跡限制為手工設計的組成部分，例如標準清單、參考答案或驗證問題，並 (2) 對其進行結構化，以便規劃與評估推理交織在一起。在這項工作中，我們提出了 EvalPlanner，這是一種偏好最佳化演算法，適用於 Thinking-LLM-as-a-Judge，它首先產生一個不受約束的評估計畫，接著執行它，然後做出最終判斷。在自訓練迴圈中，EvalPlanner 反覆最佳化合成建構的評估計畫和執行，從而得出更好的最終判決。儘管我們的訓練方法使用較少且合成產生的偏好配對，但我們的模型在 RewardBench 上針對生成式獎勵模型達到了新的最佳效能（得分為 93.9）。在其他基準測試（例如 RM-Bench、JudgeBench 和 FollowBenchEval）上的其他實驗進一步突顯了規劃和推理對於建立強大的 LLM-as-a-Judge 推理模型的效用。

##### **LLMs can see and hear without any training**
2501.18096v1 by Kumar Ashutosh, Yossi Gandelsman, Xinlei Chen, Ishan Misra, Rohit Girdhar

We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,
training-free approach, to imbue multimodal capabilities into your favorite
LLM. Leveraging their innate ability to perform multi-step reasoning, MILS
prompts the LLM to generate candidate outputs, each of which are scored and fed
back iteratively, eventually generating a solution to the task. This enables
various applications that typically require training specialized models on
task-specific data. In particular, we establish a new state-of-the-art on
emergent zero-shot image, video and audio captioning. MILS seamlessly applies
to media generation as well, discovering prompt rewrites to improve
text-to-image generation, and even edit prompts for style transfer! Finally,
being a gradient-free optimization approach, MILS can invert multimodal
embeddings into text, enabling applications like cross-modal arithmetic.

摘要：我們提出 MILS：多模態反覆 LLM 解決方案，一種驚人地簡單、無需訓練的方法，將多模態功能融入您最愛的 LLM。運用其執行多步驟推理的內在能力，MILS 會提示 LLM 產生候選輸出，每個輸出都會被評分並反覆回饋，最終產生任務的解決方案。這能啟用各種應用程式，這些應用程式通常需要在特定於任務的資料上訓練專門模型。特別是，我們在浮現零次學習影像、影片和音訊字幕上建立了新的先進技術。MILS 也能無縫應用於媒體產生，發現提示重寫以改善文字轉影像產生，甚至編輯提示以進行風格轉移！最後，由於是一種無梯度最佳化方法，MILS 能將多模態嵌入反轉為文字，啟用跨模態運算等應用程式。

##### **Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**
2501.18081v1 by Pratik S. Sachdeva, Tom van Nuenen

The rapid adoption of large language models (LLMs) has spurred extensive
research into their encoded moral norms and decision-making processes. Much of
this research relies on prompting LLMs with survey-style questions to assess
how well models are aligned with certain demographic groups, moral beliefs, or
political ideologies. While informative, the adherence of these approaches to
relatively superficial constructs tends to oversimplify the complexity and
nuance underlying everyday moral dilemmas. We argue that auditing LLMs along
more detailed axes of human interaction is of paramount importance to better
assess the degree to which they may impact human beliefs and actions. To this
end, we evaluate LLMs on complex, everyday moral dilemmas sourced from the "Am
I the Asshole" (AITA) community on Reddit, where users seek moral judgments on
everyday conflicts from other community members. We prompted seven LLMs to
assign blame and provide explanations for over 10,000 AITA moral dilemmas. We
then compared the LLMs' judgments and explanations to those of Redditors and to
each other, aiming to uncover patterns in their moral reasoning. Our results
demonstrate that large language models exhibit distinct patterns of moral
judgment, varying substantially from human evaluations on the AITA subreddit.
LLMs demonstrate moderate to high self-consistency but low inter-model
agreement. Further analysis of model explanations reveals distinct patterns in
how models invoke various moral principles. These findings highlight the
complexity of implementing consistent moral reasoning in artificial systems and
the need for careful evaluation of how different models approach ethical
judgment. As LLMs continue to be used in roles requiring ethical
decision-making such as therapists and companions, careful evaluation is
crucial to mitigate potential biases and limitations.

摘要：大型語言模型 (LLM) 的快速採用已促使人們深入研究其編碼的道德規範和決策過程。許多這類研究依賴於以調查式問題提示 LLM，以評估模型與特定人口群體、道德信念或政治意識形態的契合程度。儘管有提供資訊，但這些方法對相對膚淺的結構的堅持傾向於過度簡化日常道德困境背後的複雜性和細微差別。我們認為，沿著更詳細的人類互動軸線審查 LLM 對於更好地評估它們可能影響人類信念和行為的程度至關重要。為此，我們根據 Reddit 上「我是混蛋嗎」(AITA) 社群評估 LLM 在複雜的日常道德困境中，使用者在其中尋求其他社群成員對日常衝突的道德判斷。我們提示七個 LLM 對超過 10,000 個 AITA 道德困境分配責任並提供解釋。然後，我們將 LLM 的判斷和解釋與 Reddit 使用者的判斷和解釋以及彼此進行比較，旨在揭示其道德推理中的模式。我們的結果表明，大型語言模型展現出不同的道德判斷模式，與 AITA 子版塊上的人類評估有很大差異。LLM 表現出中度到高度的自我一致性，但模型間協議低。進一步分析模型解釋揭示了模型如何援引各種道德原則的不同模式。這些發現突顯了在人工系統中實施一致的道德推理的複雜性，以及仔細評估不同模型如何進行道德判斷的必要性。隨著 LLM 持續用於需要道德決策的角色，例如治療師和伴侶，仔細評估對於減輕潛在偏見和限制至關重要。

##### **Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**
2501.18071v1 by Pir Bakhsh Khokhar, Viviana Pentangelo, Fabio Palomba, Carmine Gravino

Diabetes mellitus (DM) is a global health issue of significance that must be
diagnosed as early as possible and managed well. This study presents a
framework for diabetes prediction using Machine Learning (ML) models,
complemented with eXplainable Artificial Intelligence (XAI) tools, to
investigate both the predictive accuracy and interpretability of the
predictions from ML models. Data Preprocessing is based on the Synthetic
Minority Oversampling Technique (SMOTE) and feature scaling used on the
Diabetes Binary Health Indicators dataset to deal with class imbalance and
variability of clinical features. The ensemble model provided high accuracy,
with a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General
Health, Income, and Physical Activity were the most influential predictors
obtained from the model explanations. The results of this study suggest that ML
combined with XAI is a promising means of developing accurate and
computationally transparent tools for use in healthcare systems.

摘要：糖尿病 (DM) 是一項重要的全球健康議題，必須盡早診斷並妥善管理。本研究提出一個糖尿病預測架構，使用機器學習 (ML) 模型，並搭配可解釋人工智慧 (XAI) 工具，來探討 ML 模型預測的準確度和可解釋性。資料前處理基於合成少數過採樣技術 (SMOTE) 和特徵縮放，用於糖尿病二元健康指標資料集，以處理類別不平衡和臨床特徵的可變性。整合模型提供了高準確度，測試準確度為 92.50%，ROC-AUC 為 0.975。根據模型解釋，BMI、年齡、一般健康狀況、收入和身體活動是最具影響力的預測因子。本研究結果表明，ML 結合 XAI 是一種有前途的方式，可以開發出準確且在運算上透明的工具，用於醫療保健系統。

##### **Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features**
2501.18064v1 by Mathieu Calvat, Chris Bean, Dhruv Anjaria, Hyoungryul Park, Haoren Wang, Kenneth Vecchio, J. C. Stinville

To leverage advancements in machine learning for metallic materials design
and property prediction, it is crucial to develop a data-reduced representation
of metal microstructures that surpasses the limitations of current
physics-based discrete microstructure descriptors. This need is particularly
relevant for metallic materials processed through additive manufacturing, which
exhibit complex hierarchical microstructures that cannot be adequately
described using the conventional metrics typically applied to wrought
materials. Furthermore, capturing the spatial heterogeneity of microstructures
at the different scales is necessary within such framework to accurately
predict their properties. To address these challenges, we propose the physical
spatial mapping of metal diffraction latent space features. This approach
integrates (i) point diffraction data encoding via variational autoencoders or
contrastive learning and (ii) the physical mapping of the encoded values.
Together these steps offer a method offers a novel means to comprehensively
describe metal microstructures. We demonstrate this approach on a wrought and
additively manufactured alloy, showing that it effectively encodes
microstructural information and enables direct identification of
microstructural heterogeneity not directly possible by physics-based models.
This data-reduced microstructure representation opens the application of
machine learning models in accelerating metallic material design and accurately
predicting their properties.

摘要：為了提升機器學習在金屬材料設計和屬性預測方面的進展，開發一種超越當前基於物理的離散微結構描述符限制的金屬微結構數據簡化表示至關重要。對於通過增材製造處理的金屬材料而言，這種需求尤其重要，因為它們表現出複雜的分層微結構，無法使用通常應用於鍛造材料的傳統指標充分描述。此外，在這種框架內，有必要捕捉不同尺度的微結構的空間異質性，以準確預測其屬性。為了應對這些挑戰，我們提出了金屬衍射潛在空間特徵的物理空間映射。這種方法整合了 (i) 通過變分自編碼器或對比學習對點衍射數據編碼，以及 (ii) 對編碼值的物理映射。這些步驟共同提供了一種方法，提供了一種全面描述金屬微結構的新穎方法。我們在鍛造和增材製造合金上展示了這種方法，表明它有效地編碼了微結構信息，並能夠直接識別物理模型無法直接實現的微結構異質性。這種數據簡化的微結構表示開放了機器學習模型在加速金屬材料設計和準確預測其屬性的應用。

##### **FinanceQA: A Benchmark for Evaluating Financial Analysis Capabilities of Large Language Models**
2501.18062v1 by Spencer Mateega, Carlos Georgescu, Danny Tang

FinanceQA is a testing suite that evaluates LLMs' performance on complex
numerical financial analysis tasks that mirror real-world investment work.
Despite recent advances, current LLMs fail to meet the strict accuracy
requirements of financial institutions, with models failing approximately 60%
of realistic tasks that mimic on-the-job analyses at hedge funds, private
equity firms, investment banks, and other financial institutions. The primary
challenges include hand-spreading metrics, adhering to standard accounting and
corporate valuation conventions, and performing analysis under incomplete
information - particularly in multi-step tasks requiring assumption generation.
This performance gap highlights the disconnect between existing LLM
capabilities and the demands of professional financial analysis that are
inadequately tested by current testing architectures. Results show that
higher-quality training data is needed to support such tasks, which we
experiment with using OpenAI's fine-tuning API. FinanceQA is publicly released
at [this https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA).

摘要：FinanceQA 是一個測試套件，用於評估 LLM 在複雜數值財務分析任務上的表現，這些任務反映了真實世界的投資工作。儘管最近取得進展，但目前的 LLM 無法滿足金融機構嚴格的準確性要求，模型在模擬對沖基金、私募股權公司、投資銀行和其他金融機構的實際分析中約有 60% 的任務失敗。主要的挑戰包括手動傳播指標、遵守標準會計和公司估值慣例，以及在不完整的信息下執行分析，特別是在需要產生假設的多步驟任務中。這種效能差距突顯了現有 LLM 能力與專業財務分析需求之間的脫節，而目前的測試架構並未充分測試這些需求。結果顯示需要更高品質的訓練資料來支援此類任務，我們使用 OpenAI 的微調 API 進行實驗。FinanceQA 已於 [此 https URL](https://huggingface.co/datasets/AfterQuery/FinanceQA) 公開發布。

##### **Current Pathology Foundation Models are unrobust to Medical Center Differences**
2501.18055v1 by Edwin D. de Jong, Eric Marcus, Jonas Teuwen

Pathology Foundation Models (FMs) hold great promise for healthcare. Before
they can be used in clinical practice, it is essential to ensure they are
robust to variations between medical centers. We measure whether pathology FMs
focus on biological features like tissue and cancer type, or on the well known
confounding medical center signatures introduced by staining procedure and
other differences. We introduce the Robustness Index. This novel robustness
metric reflects to what degree biological features dominate confounding
features. Ten current publicly available pathology FMs are evaluated. We find
that all current pathology foundation models evaluated represent the medical
center to a strong degree. Significant differences in the robustness index are
observed. Only one model so far has a robustness index greater than one,
meaning biological features dominate confounding features, but only slightly. A
quantitative approach to measure the influence of medical center differences on
FM-based prediction performance is described. We analyze the impact of
unrobustness on classification performance of downstream models, and find that
cancer-type classification errors are not random, but specifically attributable
to same-center confounders: images of other classes from the same medical
center. We visualize FM embedding spaces, and find these are more strongly
organized by medical centers than by biological factors. As a consequence, the
medical center of origin is predicted more accurately than the tissue source
and cancer type. The robustness index introduced here is provided with the aim
of advancing progress towards clinical adoption of robust and reliable
pathology FMs.

摘要：病理基礎模型 (FM) 對醫療保健而言極具前景。在臨床實務中使用之前，必須確保它們能適應醫療中心之間的差異。我們衡量病理 FM 是否著重於組織和癌症類型等生物特徵，或著重於染色程序和其他差異所造成的眾所周知的混淆醫療中心特徵。我們引入了穩健性指數。這個新穎的穩健性指標反映了生物特徵在多大程度上主導混淆特徵。我們評估了十個當前公開可用的病理 FM。我們發現，所有當前評估的病理基礎模型都強烈地代表了醫療中心。觀察到穩健性指數有顯著差異。到目前為止，只有一個模型的穩健性指數大於 1，表示生物特徵主導混淆特徵，但僅略微主導。描述了衡量醫療中心差異對基於 FM 的預測效能影響的量化方法。我們分析了不穩健性對下游模型分類效能的影響，發現癌症類型分類錯誤並非隨機，而是特別歸因於同中心混淆因子：來自同一醫療中心的其他類別的影像。我們將 FM 嵌入空間視覺化，發現這些空間比生物因素更強烈地由醫療中心組織起來。因此，比組織來源和癌症類型更準確地預測了醫療中心的來源。這裡介紹的穩健性指數旨在推動進展，朝著臨床採用穩健且可靠的病理 FM 邁進。

##### **SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders**
2501.18052v1 by Bartosz Cywiński, Kamil Deja

Recent machine unlearning approaches offer promising solution for removing
unwanted concepts from diffusion models. However, traditional methods, which
largely rely on fine-tuning, provide little insight into the changes they
introduce to the base model, making it unclear whether concepts are truly
removed or only masked. In this work, we introduce SAeUron, a novel method
leveraging features learned by sparse autoencoders (SAEs) to unlearn unwanted
concepts in text-to-image diffusion models. First, we demonstrate that SAEs,
trained in an unsupervised manner on activations from multiple denoising
timesteps of the diffusion model, capture sparse and interpretable features
corresponding to specific concepts. Building on this, we propose a method of
selecting concept-specific features. This enables precise interventions on the
model's activations to block targeted content while preserving the model's
overall performance. Evaluation on the competitive UnlearnCanvas benchmark on
object and style unlearning highlights SAeUron's state-of-the-art performance.
Moreover, we show that with a single SAE, we can remove multiple concepts
simultaneously and that in contrast to other methods, SAeUron dismisses the
possibility of generating unwanted content, even under adversarial attack.

摘要：最近的機器取消學習方法提供了有希望的解決方案，用於從擴散模型中移除不需要的概念。然而，傳統的方法在很大程度上依賴於微調，對它們引入基本模型的更改幾乎沒有深入了解，這使得無法清楚概念是否真正被移除或僅被遮蔽。在這項工作中，我們引入了 SAeUron，這是一種新方法，利用稀疏自動編碼器 (SAE) 學習到的特徵來取消文本到圖像擴散模型中不需要的概念。首先，我們證明了 SAE 以無監督的方式在擴散模型的多次去噪時間步長的激活上訓練，捕捉到與特定概念相應的稀疏且可解釋的特徵。在此基礎上，我們提出了一種選擇特定概念特徵的方法。這使得對模型的激活進行精確的干預，以阻止目標內容，同時保留模型的整體性能。在 UnlearnCanvas 基準上對物體和樣式取消學習的評估突出了 SAeUron 的最先進性能。此外，我們展示了使用單個 SAE，我們可以同時移除多個概念，並且與其他方法相比，SAeUron 排除了生成不需要內容的可能性，即使在對抗攻擊下也是如此。

##### **From tools to thieves: Measuring and understanding public perceptions of AI through crowdsourced metaphors**
2501.18045v1 by Myra Cheng, Angela Y. Lee, Kristina Rapuano, Kate Niederhoffer, Alex Liebscher, Jeffrey Hancock

How has the public responded to the increasing prevalence of artificial
intelligence (AI)-based technologies? We investigate public perceptions of AI
by collecting over 12,000 responses over 12 months from a nationally
representative U.S. sample. Participants provided open-ended metaphors
reflecting their mental models of AI, a methodology that overcomes the
limitations of traditional self-reported measures. Using a mixed-methods
approach combining quantitative clustering and qualitative coding, we identify
20 dominant metaphors shaping public understanding of AI. To analyze these
metaphors systematically, we present a scalable framework integrating language
modeling (LM)-based techniques to measure key dimensions of public perception:
anthropomorphism (attribution of human-like qualities), warmth, and competence.
We find that Americans generally view AI as warm and competent, and that over
the past year, perceptions of AI's human-likeness and warmth have significantly
increased ($+34\%, r = 0.80, p < 0.01; +41\%, r = 0.62, p < 0.05$).
Furthermore, these implicit perceptions, along with the identified dominant
metaphors, strongly predict trust in and willingness to adopt AI ($r^2 = 0.21,
0.18, p < 0.001$). We further explore how differences in metaphors and implicit
perceptions--such as the higher propensity of women, older individuals, and
people of color to anthropomorphize AI--shed light on demographic disparities
in trust and adoption. In addition to our dataset and framework for tracking
evolving public attitudes, we provide actionable insights on using metaphors
for inclusive and responsible AI development.

摘要：<paragraph>公眾如何回應人工智慧 (AI) 為基礎的技術日益普及？我們透過在 12 個月內從美國全國代表性樣本收集超過 12,000 份回應，來調查公眾對 AI 的看法。參與者提供了開放式的隱喻，反映他們對 AI 的心智模式，這是一種克服傳統自我報告測量限制的方法。透過結合量化分群與定性編碼的混合方法，我們找出 20 個形塑公眾對 AI 理解的主導隱喻。為了系統性地分析這些隱喻，我們提出一個可擴充的架構，整合基於語言模型 (LM) 的技術，來測量公眾認知的主要面向：擬人化（歸因於類人的品質）、溫暖度和能力。我們發現美國人普遍將 AI 視為溫暖且有能力的，而且在過去一年中，人們對 AI 類人特質和溫暖度的認知大幅增加（+34%，r = 0.80，p < 0.01；+41%，r = 0.62，p < 0.05）。此外，這些隱含的認知，以及已識別出的主導隱喻，強烈預測了對 AI 的信任度和採用意願（r2 = 0.21，0.18，p < 0.001）。我們進一步探討隱喻和隱含認知的差異，例如女性、年長者和有色人種更傾向於將 AI 擬人化，這如何說明在信任度和採用意願方面的族群差異。除了我們用於追蹤公眾態度演變的資料集和架構外，我們還提供可操作的見解，說明如何使用隱喻進行包容且負責任的 AI 開發。</paragraph>

##### **Digital Twin-Enabled Real-Time Control in Robotic Additive Manufacturing via Soft Actor-Critic Reinforcement Learning**
2501.18016v1 by Matsive Ali, Sandesh Giri, Sen Liu, Qin Yang

Smart manufacturing systems increasingly rely on adaptive control mechanisms
to optimize complex processes. This research presents a novel approach
integrating Soft Actor-Critic (SAC) reinforcement learning with digital twin
technology to enable real-time process control in robotic additive
manufacturing. We demonstrate our methodology using a Viper X300s robot arm,
implementing two distinct control scenarios: static target acquisition and
dynamic trajectory following. The system architecture combines Unity's
simulation environment with ROS2 for seamless digital twin synchronization,
while leveraging transfer learning to efficiently adapt trained models across
tasks. Our hierarchical reward structure addresses common reinforcement
learning challenges including local minima avoidance, convergence acceleration,
and training stability. Experimental results show rapid policy convergence and
robust task execution in both simulated and physical environments, with
performance metrics including cumulative reward, value prediction accuracy,
policy loss, and discrete entropy coefficient demonstrating the effectiveness
of our approach. This work advances the integration of reinforcement learning
with digital twins for industrial robotics applications, providing a framework
for enhanced adaptive real-time control for smart additive manufacturing
process.

摘要：智慧製造系統越來越依賴適應控制機制來最佳化複雜的製程。本研究提出一個新穎的方法，將 Soft Actor-Critic (SAC) 強化學習與數位孿生技術整合，以在機器人增材製造中實現即時製程控制。我們使用 Viper X300s 機器手臂來展示我們的技術，實作兩個不同的控制場景：靜態目標擷取和動態軌跡追蹤。系統架構結合 Unity 的模擬環境和 ROS2，以實現無縫的數位孿生同步，同時利用遷移學習來有效地調整訓練好的模型以應付各種任務。我們的階層式獎勵結構解決了常見的強化學習挑戰，包括避免局部最小值、加速收斂和訓練穩定性。實驗結果顯示，在模擬和實際環境中，策略收斂速度快且任務執行強健，包括累積獎勵、值預測準確度、策略損失和離散熵係數等效能指標，證明了我們方法的有效性。這項工作推動了強化學習與數位孿生在工業機器人應用中的整合，為智慧增材製造製程提供增強式適應即時控制的架構。

##### **Anatomy Might Be All You Need: Forecasting What to Do During Surgery**
2501.18011v1 by Gary Sarwin, Alessandro Carretta, Victor Staartjes, Matteo Zoli, Diego Mazzatenta, Luca Regli, Carlo Serra, Ender Konukoglu

Surgical guidance can be delivered in various ways. In neurosurgery, spatial
guidance and orientation are predominantly achieved through neuronavigation
systems that reference pre-operative MRI scans. Recently, there has been
growing interest in providing live guidance by analyzing video feeds from tools
such as endoscopes. Existing approaches, including anatomy detection,
orientation feedback, phase recognition, and visual question-answering,
primarily focus on aiding surgeons in assessing the current surgical scene.
This work aims to provide guidance on a finer scale, aiming to provide guidance
by forecasting the trajectory of the surgical instrument, essentially
addressing the question of what to do next. To address this task, we propose a
model that not only leverages the historical locations of surgical instruments
but also integrates anatomical features. Importantly, our work does not rely on
explicit ground truth labels for instrument trajectories. Instead, the ground
truth is generated by a detection model trained to detect both anatomical
structures and instruments within surgical videos of a comprehensive dataset
containing pituitary surgery videos. By analyzing the interaction between
anatomy and instrument movements in these videos and forecasting future
instrument movements, we show that anatomical features are a valuable asset in
addressing this challenging task. To the best of our knowledge, this work is
the first attempt to address this task for manually operated surgeries.

摘要：手術引導可以用各種方式傳遞。在神經外科手術中，空間引導和定位主要是透過神經導航系統來實現，該系統參考術前 MRI 掃描。最近，人們越來越有興趣透過分析內視鏡等工具的視訊饋送來提供即時引導。現有的方法，包括解剖偵測、方位回饋、相位辨識和視覺問答，主要集中在協助外科醫生評估目前的術中場景。這項工作旨在提供更精細的引導，目標是透過預測手術器械的軌跡來提供引導，基本上是解決下一步該怎麼做的問題。為了解決這項任務，我們提出一個模型，不僅利用手術器械的歷史位置，還整合解剖特徵。重要的是，我們的模型不依賴於器械軌跡的明確真實標籤。相反地，真實標籤是由偵測模型產生的，該模型經過訓練，可以在包含垂體手術視訊的綜合資料集的手術視訊中偵測解剖結構和器械。透過分析這些視訊中解剖結構和器械動作之間的交互作用，並預測未來的器械動作，我們證明了解剖特徵是解決這項具有挑戰性任務的寶貴資產。據我們所知，這項工作是首次嘗試解決人工手術的這項任務。

##### **Large Language Models Think Too Fast To Explore Effectively**
2501.18009v1 by Lan Pan, Hanbo Xie, Robert C. Wilson

Large Language Models have emerged many intellectual capacities. While
numerous benchmarks assess their intelligence, limited attention has been given
to their ability to explore, an essential capacity for discovering new
information and adapting to novel environments in both natural and artificial
systems. The extent to which LLMs can effectively explore, particularly in
open-ended tasks, remains unclear. This study investigates whether LLMs can
surpass humans in exploration during an open-ended task, using Little Alchemy 2
as a paradigm, where agents combine elements to discover new ones. Results show
most LLMs underperform compared to humans, except for the o1 model, with those
traditional LLMs relying primarily on uncertainty driven strategies, unlike
humans who balance uncertainty and empowerment. Representational analysis of
the models with Sparse Autoencoders revealed that uncertainty and choices are
represented at earlier transformer blocks, while empowerment values are
processed later, causing LLMs to think too fast and make premature decisions,
hindering effective exploration. These findings shed light on the limitations
of LLM exploration and suggest directions for improving their adaptability.

摘要：大型語言模型已經展現出許多智力能力。雖然有許多基準評估它們的智慧，但對於它們探索的能力，在自然和人工系統中發現新資訊和適應新環境的必要能力，卻鮮少受到關注。LLM 在多大程度上能有效地探索，特別是在開放式任務中，仍然不清楚。本研究探討 LLM 是否能在開放式任務中超越人類的探索能力，使用 Little Alchemy 2 作為範例，其中代理人結合元素來發現新的元素。結果顯示，除了 o1 模型，大多數 LLM 的表現都低於人類，而這些傳統 LLM 主要依賴於不確定性驅動的策略，這與平衡不確定性和賦能的人類不同。使用稀疏自動編碼器對模型的表徵分析顯示，不確定性和選擇在較早的轉換器區塊中被表徵，而賦能值則在稍後被處理，導致 LLM 思考得太快並做出過早的決定，阻礙了有效的探索。這些發現揭示了 LLM 探索的限制，並提出了改進其適應性的方向。

##### **Topological Signatures of Adversaries in Multimodal Alignments**
2501.18006v1 by Minh Vu, Geigh Zollicoffer, Huy Mai, Ben Nebgen, Boian Alexandrov, Manish Bhattarai

Multimodal Machine Learning systems, particularly those aligning text and
image data like CLIP/BLIP models, have become increasingly prevalent, yet
remain susceptible to adversarial attacks. While substantial research has
addressed adversarial robustness in unimodal contexts, defense strategies for
multimodal systems are underexplored. This work investigates the topological
signatures that arise between image and text embeddings and shows how
adversarial attacks disrupt their alignment, introducing distinctive
signatures. We specifically leverage persistent homology and introduce two
novel Topological-Contrastive losses based on Total Persistence and Multi-scale
kernel methods to analyze the topological signatures introduced by adversarial
perturbations. We observe a pattern of monotonic changes in the proposed
topological losses emerging in a wide range of attacks on image-text
alignments, as more adversarial samples are introduced in the data. By
designing an algorithm to back-propagate these signatures to input samples, we
are able to integrate these signatures into Maximum Mean Discrepancy tests,
creating a novel class of tests that leverage topological signatures for better
adversarial detection.

摘要：多模态机器学习系统，尤其是那些对齐文本和图像数据（例如 CLIP/BLIP 模型）的系统，变得越来越普遍，但仍然容易受到对抗性攻击。虽然大量研究已经解决了单模态环境中的对抗鲁棒性，但针对多模态系统防御策略的研究却很少。这项工作调查了图像和文本嵌入之间出现的拓扑特征，并展示了对抗性攻击如何破坏它们的排列，从而引入独特的特征。我们特别利用持久同调，并基于总持久性和多尺度核方法引入两种新颖的拓扑对比损失，以分析对抗性扰动引入的拓扑特征。我们观察到，在针对图像文本对齐的大量攻击中，所提出的拓扑损失出现了单调变化的模式，因为在数据中引入了更多对抗性样本。通过设计一种算法将这些特征反向传播到输入样本，我们能够将这些特征整合到最大均值差异检验中，从而创建一种新颖的检验类，该类利用拓扑特征来更好地检测对抗性。

##### **InnerThoughts: Disentangling Representations and Predictions in Large Language Models**
2501.17994v1 by Didier Chételat, Joseph Cotnareanu, Rylee Thompson, Yingxue Zhang, Mark Coates

Large language models (LLMs) contain substantial factual knowledge which is
commonly elicited by multiple-choice question-answering prompts. Internally,
such models process the prompt through multiple transformer layers, building
varying representations of the problem within its hidden states. Ultimately,
however, only the hidden state corresponding to the final layer and token
position are used to predict the answer label. In this work, we propose instead
to learn a small separate neural network predictor module on a collection of
training questions, that take the hidden states from all the layers at the last
temporal position as input and outputs predictions. In effect, such a framework
disentangles the representational abilities of LLMs from their predictive
abilities. On a collection of hard benchmarks, our method achieves considerable
improvements in performance, sometimes comparable to supervised fine-tuning
procedures, but at a fraction of the computational cost.

摘要：大型語言模型 (LLM) 包含大量事實知識，通常會由多重選擇問答提示引導出來。在內部，此類模型會透過多個Transformer層處理提示，在隱藏狀態中建構問題的不同表徵。然而，最終只有對應於最後一層和標記位置的隱藏狀態會用於預測答案標籤。在這項工作中，我們提出改為在訓練問題的集合上學習一個小型且獨立的神經網路預測器模組，它會將最後時間位置的所有層級的隱藏狀態作為輸入並輸出預測。實際上，此類架構會將 LLM 的表徵能力與其預測能力區分開。在多個困難基準上，我們的模型在效能上獲得顯著的提升，有時甚至與監督式微調程序相當，但運算成本卻只有後者的零頭。

##### **Investigating the Monte-Carlo Tree Search Approach for the Job Shop Scheduling Problem**
2501.17991v1 by Laurie Boveroux, Damien Ernst, Quentin Louveaux

The Job Shop Scheduling Problem (JSSP) is a well-known optimization problem
in manufacturing, where the goal is to determine the optimal sequence of jobs
across different machines to minimize a given objective. In this work, we focus
on minimising the weighted sum of job completion times. We explore the
potential of Monte Carlo Tree Search (MCTS), a heuristic-based reinforcement
learning technique, to solve large-scale JSSPs, especially those with
recirculation. We propose several Markov Decision Process (MDP) formulations to
model the JSSP for the MCTS algorithm. In addition, we introduce a new
synthetic benchmark derived from real manufacturing data, which captures the
complexity of large, non-rectangular instances often encountered in practice.
Our experimental results show that MCTS effectively produces good-quality
solutions for large-scale JSSP instances, outperforming our constraint
programming approach.

摘要：作業車間排程問題（JSSP）是製造業中一個著名的最佳化問題，目標是決定不同機器上工作的最佳順序，以最小化給定的目標。在這項工作中，我們專注於最小化工作的加權完成時間總和。我們探討了蒙地卡羅樹狀搜尋（MCTS）的潛力，這是一種基於啟發式的強化學習技術，用於解決大規模的 JSSP，特別是那些具有再循環的 JSSP。我們提出了幾個馬可夫決策過程（MDP）公式，以對 MCTS 演算法建模 JSSP。此外，我們還引入了一個新的合成基準，該基準來自真實的製造數據，它捕捉到了實務中經常遇到的複雜、非矩形實例。我們的實驗結果表明，MCTS 有效地產生了針對大規模 JSSP 實例的高品質解，優於我們的約束式規劃方法。

##### **Limits to AI Growth: The Ecological and Social Consequences of Scaling**
2501.17980v1 by Eshta Bhardwaj, Rohan Alexander, Christoph Becker

The accelerating development and deployment of AI technologies depend on the
continued ability to scale their infrastructure. This has implied increasing
amounts of monetary investment and natural resources. Frontier AI applications
have thus resulted in rising financial, environmental, and social costs. While
the factors that AI scaling depends on reach its limits, the push for its
accelerated advancement and entrenchment continues. In this paper, we provide a
holistic review of AI scaling using four lenses (technical, economic,
ecological, and social) and review the relationships between these lenses to
explore the dynamics of AI growth. We do so by drawing on system dynamics
concepts including archetypes such as "limits to growth" to model the dynamic
complexity of AI scaling and synthesize several perspectives. Our work maps out
the entangled relationships between the technical, economic, ecological and
social perspectives and the apparent limits to growth. The analysis explains
how industry's responses to external limits enables continued (but temporary)
scaling and how this benefits Big Tech while externalizing social and
environmental damages. To avoid an "overshoot and collapse" trajectory, we
advocate for realigning priorities and norms around scaling to prioritize
sustainable and mindful advancements.

摘要：人工智能技術的加速開發和部署取決於擴展其基礎設施的持續能力。這意味著增加大量的金錢投資和自然資源。因此，前沿人工智能應用導致了財務、環境和社會成本的上升。雖然人工智能擴展依賴的因素達到其極限，但其加速推進和根深蒂固的趨勢仍在繼續。在本文中，我們使用四個視角（技術、經濟、生態和社會）對人工智能擴展進行整體評估，並回顧這些視角之間的關係，以探討人工智能增長的動態。我們通過借鑒系統動力學概念（包括「增長極限」等原型）來模擬人工智能擴展的動態複雜性，並綜合多種觀點。我們的研究闡述了技術、經濟、生態和社會觀點之間的糾纏關係以及增長的明顯極限。分析解釋了產業如何應對外部限制，從而實現持續（但暫時）擴展，以及這如何使大型科技公司受益，同時將社會和環境損害外化。為了避免「超調和崩潰」的軌跡，我們提倡重新調整優先事項和規範，圍繞擴展來優先考慮可持續和謹慎的進步。

##### **Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization**
2501.17974v1 by Zishun Yu, Tengyu Xu, Di Jin, Karthik Abinav Sankararaman, Yun He, Wenxuan Zhou, Zhouhao Zeng, Eryk Helenowski, Chen Zhu, Sinong Wang, Hao Ma, Han Fang

Solving mathematics problems has been an intriguing capability of large
language models, and many efforts have been made to improve reasoning by
extending reasoning length, such as through self-correction and extensive long
chain-of-thoughts. While promising in problem-solving, advanced long reasoning
chain models exhibit an undesired single-modal behavior, where trivial
questions require unnecessarily tedious long chains of thought. In this work,
we propose a way to allow models to be aware of inference budgets by
formulating it as utility maximization with respect to an inference budget
constraint, hence naming our algorithm Inference Budget-Constrained Policy
Optimization (IBPO). In a nutshell, models fine-tuned through IBPO learn to
``understand'' the difficulty of queries and allocate inference budgets to
harder ones. With different inference budgets, our best models are able to have
a $4.14$\% and $5.74$\% absolute improvement ($8.08$\% and $11.2$\% relative
improvement) on MATH500 using $2.16$x and $4.32$x inference budgets
respectively, relative to LLaMA3.1 8B Instruct. These improvements are
approximately $2$x those of self-consistency under the same budgets.

摘要：解決數學問題一直是大型語言模型的一項迷人能力，並且已經做出許多努力來通過擴展推理長度來改進推理，例如通過自我修正和廣泛的長思維鏈。雖然在解決問題方面很有希望，但先進的長推理鏈模型表現出不需要的單模態行為，其中微不足道的問題需要不必要的冗長思維鏈。在這項工作中，我們提出了一種方法，允許模型通過將其表述為關於推理預算約束的效用最大化來了解推理預算，因此將我們的演算法命名為推理預算約束策略最佳化 (IBPO)。簡而言之，通過 IBPO 微調的模型學會「理解」查詢的難度，並將推理預算分配給更困難的查詢。有了不同的推理預算，我們的最佳模型能夠在 MATH500 上分別使用 2.16 倍和 4.32 倍的推理預算，相對於 LLaMA3.1 8B Instruct，分別有 4.14% 和 5.74% 的絕對改進（8.08% 和 11.2% 的相對改進）。這些改進在大致相同的預算下，大約是自洽性的 2 倍。

##### **Deep Ensembles Secretly Perform Empirical Bayes**
2501.17917v1 by Gabriel Loaiza-Ganem, Valentin Villecroze, Yixin Wang

Quantifying uncertainty in neural networks is a highly relevant problem which
is essential to many applications. The two predominant paradigms to tackle this
task are Bayesian neural networks (BNNs) and deep ensembles. Despite some
similarities between these two approaches, they are typically surmised to lack
a formal connection and are thus understood as fundamentally different. BNNs
are often touted as more principled due to their reliance on the Bayesian
paradigm, whereas ensembles are perceived as more ad-hoc; yet, deep ensembles
tend to empirically outperform BNNs, with no satisfying explanation as to why
this is the case. In this work we bridge this gap by showing that deep
ensembles perform exact Bayesian averaging with a posterior obtained with an
implicitly learned data-dependent prior. In other words deep ensembles are
Bayesian, or more specifically, they implement an empirical Bayes procedure
wherein the prior is learned from the data. This perspective offers two main
benefits: (i) it theoretically justifies deep ensembles and thus provides an
explanation for their strong empirical performance; and (ii) inspection of the
learned prior reveals it is given by a mixture of point masses -- the use of
such a strong prior helps elucidate observed phenomena about ensembles.
Overall, our work delivers a newfound understanding of deep ensembles which is
not only of interest in it of itself, but which is also likely to generate
future insights that drive empirical improvements for these models.

摘要：量化神经网络中的不确定性是一个高度相关的问题，对许多应用而言至关重要。解决此任务的两个主要范例是贝叶斯神经网络 (BNN) 和深度集成。尽管这两种方法之间存在一些相似之处，但通常认为它们缺乏形式联系，因此被理解为根本不同。BNN 由于依赖贝叶斯范例而经常被标榜为更有原则，而集成则被认为更临时；然而，深度集成往往在经验上优于 BNN，但没有令人满意的解释说明为什么会这样。在这项工作中，我们通过展示深度集成使用隐式学习的数据相关先验获得的后验执行精确的贝叶斯平均来弥合这一差距。换句话说，深度集成是贝叶斯的，或者更具体地说，它们实现了经验贝叶斯程序，其中先验是从数据中学到的。这种观点提供了两个主要好处：(i) 它在理论上证明了深度集成，从而为其强大的经验性能提供了解释；(ii) 对学习到的先验的检查表明它是由点质量的混合给出的——使用这种强先验有助于阐明观察到的关于集成现象。总体而言，我们的工作对深度集成提供了一种新发现的理解，这不仅对它本身很感兴趣，而且还可能产生推动这些模型经验改进的未来见解。

##### **Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**
2501.17860v1 by Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen

Current medical AI systems often fail to replicate real-world clinical
reasoning, as they are predominantly trained and evaluated on static text and
question-answer tasks. These tuning methods and benchmarks overlook critical
aspects like evidence-based reasoning and handling distracting information. To
bridge this gap, we introduce a novel benchmark that simulates real-world
diagnostic scenarios, integrating noise and difficulty levels aligned with
USMLE standards. Moreover, we explore dialogue-based fine-tuning, which
transforms static datasets into conversational formats to better capture
iterative reasoning processes. Experiments show that dialogue-tuned models
outperform traditional methods, with improvements of $9.64\%$ in multi-round
reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our
findings highlight dialogue tuning as a promising approach for advancing
clinically aligned and robust medical AI systems.

摘要：目前的醫療 AI 系統常無法複製真實世界的臨床推理，因為它們主要在靜態文字和問答任務上受訓和評估。這些調整方法和基準忽略了基於證據的推理和處理分散資訊等關鍵面向。為了彌補這個差距，我們提出一個模擬真實世界診斷情境的全新基準，整合與 USMLE 標準一致的雜訊和難度等級。此外，我們探索以對話為基礎的微調，將靜態資料集轉換為對話格式，以更好地捕捉反覆的推理過程。實驗顯示，對話微調模型優於傳統方法，在多輪推理情境中提升了 9.64%，在有雜訊的環境中提升了 6.18% 的準確度。我們的發現強調對話微調是一種有望推進與臨床相符且強健的醫療 AI 系統的方法。

##### **Improving Your Model Ranking on Chatbot Arena by Vote Rigging**
2501.17858v1 by Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin

Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,
where users vote for their preferred response from two randomly sampled
anonymous models. While Chatbot Arena is widely regarded as a reliable LLM
ranking leaderboard, we show that crowdsourced voting can be rigged to improve
(or decrease) the ranking of a target model $m_{t}$. We first introduce a
straightforward target-only rigging strategy that focuses on new battles
involving $m_{t}$, identifying it via watermarking or a binary classifier, and
exclusively voting for $m_{t}$ wins. However, this strategy is practically
inefficient because there are over $190$ models on Chatbot Arena and on average
only about $1\%$ of new battles will involve $m_{t}$. To overcome this, we
propose omnipresent rigging strategies, exploiting the Elo rating mechanism of
Chatbot Arena that any new vote on a battle can influence the ranking of the
target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.
We conduct experiments on around $1.7$ million historical votes from the
Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve
model rankings by rigging only hundreds of new votes. While we have evaluated
several defense mechanisms, our findings highlight the importance of continued
efforts to prevent vote rigging. Our code is available at
https://github.com/sail-sg/Rigging-ChatbotArena.

摘要：聊天機器人競技場是一個透過成對戰鬥來評估大型語言模型的熱門平台，使用者可以從兩個隨機抽樣的匿名模型中投票給他們偏好的回應。儘管聊天機器人競技場廣泛被視為可靠的大型語言模型排名排行榜，但我們表明群眾外包投票可以被操縱以提升（或降低）目標模型 $m_{t}$ 的排名。我們首先介紹了一個直接的僅目標操縱策略，該策略專注於涉及 $m_{t}$ 的新戰鬥，透過浮水印或二元分類器識別它，並專門投票給 $m_{t}$ 獲勝。然而，這個策略在實務上效率不彰，因為聊天機器人競技場上有超過 190 個模型，而且平均而言只有約 1% 的新戰鬥會涉及 $m_{t}$。為了克服這個問題，我們提出了無所不在的操縱策略，利用聊天機器人競技場的 Elo 評分機制，任何對戰鬥的新投票都可以影響目標模型 $m_{t}$ 的排名，即使 $m_{t}$ 沒有直接參與戰鬥。我們對聊天機器人競技場筆記本中約 170 萬張歷史投票進行了實驗，結果顯示無所不在的操縱策略僅透過操縱數百張新投票就能提升模型排名。儘管我們已經評估了幾種防禦機制，但我們的發現突顯了持續努力防止投票操縱的重要性。我們的程式碼可在 https://github.com/sail-sg/Rigging-ChatbotArena 取得。

##### **GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**
2501.17855v1 by Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee

Robot caregiving should be personalized to meet the diverse needs of care
recipients -- assisting with tasks as needed, while taking user agency in
action into account. In physical tasks such as handover, bathing, dressing, and
rehabilitation, a key aspect of this diversity is the functional range of
motion (fROM), which can vary significantly between individuals. In this work,
we learn to predict personalized fROM as a way to generalize robot
decision-making in a wide range of caregiving tasks. We propose a novel
data-driven method for predicting personalized fROM using functional assessment
scores from occupational therapy. We develop a neural model that learns to
embed functional assessment scores into a latent representation of the user's
physical function. The model is trained using motion capture data collected
from users with emulated mobility limitations. After training, the model
predicts personalized fROM for new users without motion capture. Through
simulated experiments and a real-robot user study, we show that the
personalized fROM predictions from our model enable the robot to provide
personalized and effective assistance while improving the user's agency in
action. See our website for more visualizations:
https://emprise.cs.cornell.edu/grace/.

摘要：機器人照護應根據照護對象的不同需求進行客製化，在需要時協助執行任務，同時考量使用者的自主行動。在移交、沐浴、穿衣和復健等身體任務中，這種多樣性的關鍵面向是功能性動作範圍 (fROM)，而這在不同個體之間可能差異很大。在這項工作中，我們學習預測客製化 fROM，作為在廣泛照護任務中概化機器人決策制定的一種方式。我們提出了一種使用職能治療功能評估分數來預測客製化 fROM 的新穎資料驅動方法。我們開發了一個神經模型，學習將功能評估分數嵌入到使用者的身體功能潛在表徵中。該模型使用從具有模擬行動限制的使用者收集的動作擷取資料進行訓練。訓練後，該模型會為沒有動作擷取的新使用者預測客製化 fROM。透過模擬實驗和真實機器人使用者研究，我們展示了我們模型的客製化 fROM 預測使機器人能夠提供客製化且有效的協助，同時提高使用者的自主行動。請參閱我們的網站以取得更多視覺化資料：https://emprise.cs.cornell.edu/grace/。

##### **From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**
2501.17842v1 by Junseok Park, Hyeonseo Yang, Min Whoo Lee, Won-Seok Choi, Minsu Lee, Byoung-Tak Zhang

Reinforcement learning (RL) agents often face challenges in balancing
exploration and exploitation, particularly in environments where sparse or
dense rewards bias learning. Biological systems, such as human toddlers,
naturally navigate this balance by transitioning from free exploration with
sparse rewards to goal-directed behavior guided by increasingly dense rewards.
Inspired by this natural progression, we investigate the Toddler-Inspired
Reward Transition in goal-oriented RL tasks. Our study focuses on transitioning
from sparse to potential-based dense (S2D) rewards while preserving optimal
strategies. Through experiments on dynamic robotic arm manipulation and
egocentric 3D navigation tasks, we demonstrate that effective S2D reward
transitions significantly enhance learning performance and sample efficiency.
Additionally, using a Cross-Density Visualizer, we show that S2D transitions
smooth the policy loss landscape, resulting in wider minima that improve
generalization in RL models. In addition, we reinterpret Tolman's maze
experiments, underscoring the critical role of early free exploratory learning
in the context of S2D rewards.

摘要：強化學習 (RL) 代理人經常在平衡探索和利用時面臨挑戰，特別是在稀疏或密集獎勵會影響學習的環境中。生物系統（例如人類幼兒）通過從具有稀疏獎勵的自由探索過渡到由越來越密集的獎勵引導的目標導向行為，自然而然地應對這種平衡。受這種自然進程的啟發，我們研究了目標導向 RL 任務中的幼兒啟發式獎勵轉換。我們的研究重點在於從稀疏轉換到基於潛力的密集 (S2D) 獎勵，同時保留最佳策略。通過對動態機器手臂操作和自我中心 3D 導航任務的實驗，我們證明了有效的 S2D 獎勵轉換顯著提高了學習性能和樣本效率。此外，使用交叉密度可視化工具，我們展示了 S2D 轉換可以平滑策略損失情況，從而產生更廣泛的最小值，從而改善 RL 模型中的泛化。此外，我們重新詮釋了托爾曼迷宮實驗，強調了在 S2D 獎勵的背景下早期自由探索學習的關鍵作用。

##### **Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**
2501.17840v1 by Pouya Pezeshkpour, Estevam Hruschka

Large Language Models (LLMs) have demonstrated remarkable performance on
various tasks, yet their ability to extract and internalize deeper insights
from domain-specific datasets remains underexplored. In this study, we
investigate how continual pre-training can enhance LLMs' capacity for insight
learning across three distinct forms: declarative, statistical, and
probabilistic insights. Focusing on two critical domains: medicine and finance,
we employ LoRA to train LLMs on two existing datasets. To evaluate each insight
type, we create benchmarks to measure how well continual pre-training helps
models go beyond surface-level knowledge. We also assess the impact of document
modification on capturing insights. The results show that, while continual
pre-training on original documents has a marginal effect, modifying documents
to retain only essential information significantly enhances the
insight-learning capabilities of LLMs.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的表現，但它們從特定領域的資料集中萃取和內化更深入見解的能力仍未被充分探討。在本研究中，我們探討持續預訓練如何增強 LLM 在三種不同形式的見解學習能力：宣告式、統計式和機率式見解。我們專注於兩個重要的領域：醫學和金融，並使用 LoRA 在兩個現有資料集上訓練 LLM。為了評估每種類型的見解，我們建立基準來衡量持續預訓練如何幫助模型超越表面層面的知識。我們也評估文件修改對擷取見解的影響。結果顯示，雖然在原始文件上進行持續預訓練的效果有限，但修改文件以僅保留必要資訊，可以顯著增強 LLM 的見解學習能力。

##### **A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**
2501.17830v1 by Mousumi Akter, Erion Çano, Erik Weber, Dennis Dobler, Ivan Habernal

This article provides a systematic up-to-date survey of automatic
summarization techniques, datasets, models, and evaluation methods in the legal
domain. Through specific source selection criteria, we thoroughly review over
120 papers spanning the modern `transformer' era of natural language processing
(NLP), thus filling a gap in existing systematic surveys on the matter. We
present existing research along several axes and discuss trends, challenges,
and opportunities for future research.

摘要：本文提供了一份法律領域中自動摘要技術、資料集、模型和評估方法的系統性最新調查。透過具體的來源選擇標準，我們徹底檢視了涵蓋自然語言處理 (NLP) 現代「Transformer」時代的 120 篇論文，從而填補了現有系統性調查的空白。我們沿著幾個軸線呈現現有研究，並討論未來研究的趨勢、挑戰和機會。

##### **U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**
2501.17823v1 by Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif

Multimodal learning often relies on designing new models and complex training
strategies to achieve optimal performance. We present Unified Unimodal
Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using
low-rank adaptation (LoRA) for various multimodal tasks. Our method
significantly reduces the number of learnable parameters and eliminates the
need for complex training strategies, such as alternating training, gradient
modifications, or unimodal fine-tuning. To address missing modalities during
both training and testing, we introduce Mask Tokens (MT), which generate
missing modality features from available modalities using a single token per
modality. This simplifies the process, removing the need for specialized
feature estimation or prompt-tuning methods. Our evaluation demonstrates that
U2A matches or outperforms state-of-the-art methods in both complete and
missing modality settings, showcasing strong performance and robustness across
various modalities, tasks, and datasets. We also analyze and report the
effectiveness of Mask Tokens in different missing modality scenarios. Overall,
our method provides a robust, flexible, and efficient solution for multimodal
learning, with minimal computational overhead.

摘要：多模态学习通常依赖于设计新模型和复杂的训练策略以实现最佳性能。我们提出了统一单模态自适应 (U2A)，它使用低秩自适应 (LoRA) 联合微调预训练的单模态编码器，以用于各种多模态任务。我们的方法显著减少了可学习参数的数量，并且消除了对复杂训练策略的需求，例如交替训练、梯度修改或单模态微调。为了解决训练和测试期间缺少的模态，我们引入了掩码标记 (MT)，它使用每个模态的单个标记从可用模态生成缺失的模态特征。这简化了流程，消除了对专门的特征估计或提示调整方法的需求。我们的评估表明，U2A 在完整和缺失模态设置中均匹配或优于最先进的方法，展示了跨各种模态、任务和数据集的强大性能和鲁棒性。我们还分析并报告了掩码标记在不同缺失模态场景中的有效性。总体而言，我们的方法为多模态学习提供了一种健壮、灵活且高效的解决方案，计算开销最小。

##### **Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**
2501.17822v1 by Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh

A crucial step to efficiently integrate Whole Slide Images (WSIs) in
computational pathology is assigning a single high-quality feature vector,
i.e., one embedding, to each WSI. With the existence of many pre-trained deep
neural networks and the emergence of foundation models, extracting embeddings
for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,
given their high resolution and gigapixel nature, inputting them into existing
GPUs as a single image is not feasible. As a result, WSIs are usually split
into many patches. Feeding each patch to a pre-trained model, each WSI can then
be represented by a set of patches, hence, a set of embeddings. Hence, in such
a setup, WSI representation learning reduces to set representation learning
where for each WSI we have access to a set of patch embeddings. To obtain a
single embedding from a set of patch embeddings for each WSI, multiple
set-based learning schemes have been proposed in the literature. In this paper,
we evaluate the WSI search performance of multiple recently developed
aggregation techniques (mainly set representation learning techniques)
including simple average or max pooling operations, Deep Sets, Memory networks,
Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse
and binary Fisher Vector on four different primary sites including bladder,
breast, kidney, and Colon from TCGA. Further, we benchmark the search
performance of these methods against the median of minimum distances of patch
embeddings, a non-aggregating approach used for WSI retrieval.

摘要：在計算病理學中有效整合全幻燈片影像 (WSI) 的關鍵步驟是為每個 WSI 指定一個單一的高品質特徵向量，即一個嵌入。由於許多預先訓練好的深度神經網路的存在和基礎模型的出現，提取子影像（即磁磚或貼片）的嵌入非常簡單。然而，對於 WSI，由於它們的高解析度和吉像素特性，將它們作為單一影像輸入現有的 GPU 是不可行的。因此，WSI 通常會被分割成許多貼片。將每個貼片輸入預先訓練好的模型後，每個 WSI 就可以用一組貼片來表示，因此，也就是一組嵌入。因此，在這樣的設定中，WSI 表示學習會簡化為集合表示學習，其中對於每個 WSI，我們可以存取一組貼片嵌入。為了從每個 WSI 的一組貼片嵌入中取得單一嵌入，文獻中已經提出了多種基於集合的學習方案。在本文中，我們評估了多種最近開發的聚合技術（主要是集合表示學習技術）的 WSI 搜尋效能，包括簡單的平均或最大池化運算、深度集合、記憶網路、焦點注意力、高斯混合模型 (GMM) Fisher 向量和深度稀疏和二進位 Fisher 向量，在 TCGA 的四個不同的主要部位，包括膀胱、乳房、腎臟和結腸。此外，我們將這些方法的搜尋效能與貼片嵌入的最小距離中位數進行基準比較，這是一種用於 WSI 擷取的非聚合方法。

##### **P-TAME: Explain Any Image Classifier with Trained Perturbations**
2501.17813v1 by Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras

The adoption of Deep Neural Networks (DNNs) in critical fields where
predictions need to be accompanied by justifications is hindered by their
inherent black-box nature. In this paper, we introduce P-TAME
(Perturbation-based Trainable Attention Mechanism for Explanations), a
model-agnostic method for explaining DNN-based image classifiers. P-TAME
employs an auxiliary image classifier to extract features from the input image,
bypassing the need to tailor the explanation method to the internal
architecture of the backbone classifier being explained. Unlike traditional
perturbation-based methods, which have high computational requirements, P-TAME
offers an efficient alternative by generating high-resolution explanations in a
single forward pass during inference. We apply P-TAME to explain the decisions
of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image
classifiers. Quantitative and qualitative results show that our method matches
or outperforms previous explainability methods, including model-specific
approaches. Code and trained models will be released upon acceptance.

摘要：深度神经網路 (DNN) 在需要對預測進行佐證的重要領域中被採用受到其固有的黑箱性質所阻礙。在本文中，我們介紹了 P-TAME（基於擾動的可訓練注意力機制用於解釋），一種與模型無關的方法，用於解釋基於 DNN 的影像分類器。P-TAME 採用輔助影像分類器從輸入影像中提取特徵，繞過需要根據要解釋的主幹分類器的內部架構調整解釋方法。與具有高計算需求的傳統基於擾動的方法不同，P-TAME 在推論過程中透過單次前向傳遞產生高解析度解釋，提供了一種高效的替代方案。我們將 P-TAME 用於解釋 VGG-16、ResNet-50 和 ViT-B-16 的決策，這三種是不同的且廣泛使用的影像分類器。定量和定性結果顯示，我們的模型比之前的可解釋性方法（包括特定於模型的方法）匹配或表現得更好。程式碼和訓練模型將在接受後發布。

##### **Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**
2501.17811v1 by Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan

In this work, we introduce Janus-Pro, an advanced version of the previous
work Janus. Specifically, Janus-Pro incorporates (1) an optimized training
strategy, (2) expanded training data, and (3) scaling to larger model size.
With these improvements, Janus-Pro achieves significant advancements in both
multimodal understanding and text-to-image instruction-following capabilities,
while also enhancing the stability of text-to-image generation. We hope this
work will inspire further exploration in the field. Code and models are
publicly available.

摘要：在這項工作中，我們介紹了 Janus-Pro，這是先前工作 Janus 的進階版本。具體來說，Janus-Pro 結合了 (1) 最佳化的訓練策略、(2) 擴充的訓練資料，以及 (3) 擴充到更大的模型規模。透過這些改進，Janus-Pro 在多模態理解和文字轉影像指令遵循能力方面都取得了顯著的進步，同時也增強了文字轉影像生成的穩定性。我們希望這項工作能激勵在該領域進一步探索。程式碼和模型已公開提供。

##### **BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**
2501.17790v1 by Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu

We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted
for Taiwanese Mandarin, highlighting phonetic control abilities to address the
unique challenges of polyphone disambiguation in the language. Building upon
CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an
optimal-transport conditional flow matching model (OT-CFM), and a grapheme to
phoneme prediction model, to generate realistic speech that closely mimics
human utterances. Our evaluation demonstrates BreezyVoice's superior
performance in both general and code-switching contexts, highlighting its
robustness and effectiveness in generating high-fidelity speech. Additionally,
we address the challenges of generalizability in modeling long-tail speakers
and polyphone disambiguation. Our approach significantly enhances performance
and offers valuable insights into the workings of neural codec TTS systems.

摘要：我們提出 BreezyVoice，一個專門針對台灣國語的文字轉語音 (TTS) 系統，強調語音控制能力以解決語言中多音字消除歧義的獨特挑戰。在 CosyVoice 的基礎上，我們整合了一個 $S^{3}$ 分詞器、一個大型語言模型 (LLM)、一個最佳傳輸條件流匹配模型 (OT-CFM) 和一個音素預測模型，以產生逼真且與人類發音非常接近的語音。我們的評估證明了 BreezyVoice 在一般和語碼轉換情境中皆有卓越的表現，突顯了它在產生高保真語音方面的穩健性和有效性。此外，我們解決了在建模長尾說話者和多音字消除歧義中可概化性的挑戰。我們的做法大幅提升了效能，並提供了對神經編解碼器 TTS 系統運作方式的寶貴見解。

##### **Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**
2501.17785v1 by Yu-Fei Shih, Zheng-Lin Lin, Shu-Kai Hsieh

We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not
encoded in Unicode. We introduce a novel approach to construct a multimodal
dataset of linguistic puzzles involving such scripts, utilizing a tokenization
method for language glyphs. Our methods include the Picture Method for LVLMs
and the Description Method for LLMs, enabling these models to tackle these
challenges. We conduct experiments using prominent models, GPT-4o, Gemini, and
Claude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and
limitations of current AI methods in linguistic decipherment, highlighting the
impact of Unicode encoding on model performance and the challenges of modeling
visual language tokens through descriptions. Our study advances understanding
of AI's potential in linguistic decipherment and underscores the need for
further research.

摘要：我們探討 LVLMs 和 LLM 解碼未編碼在 Unicode 中的罕見腳本的能力。我們引入一種創新的方法來建構一個涉及此類腳本的多模態語言謎題資料集，利用一種語言字形的標記化方法。我們的模型包含 LVLMs 的圖片方法和 LLM 的描述方法，使這些模型能夠應對這些挑戰。我們使用傑出的模型 GPT-4o、Gemini 和 Claude 3.5 Sonnet 對語言謎題進行實驗。我們的研究結果揭示了當前 AI 方法在語言解碼中的優點和限制，強調了 Unicode 編碼對模型效能的影響，以及透過描述對視覺語言標記建模的挑戰。我們的研究推動了對 AI 在語言解碼中的潛力的理解，並強調了進一步研究的必要性。

##### **2SSP: A Two-Stage Framework for Structured Pruning of LLMs**
2501.17771v1 by Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca

We propose a novel Two-Stage framework for Structured Pruning (2SSP) for
pruning Large Language Models (LLMs), which combines two different strategies
of pruning, namely Width and Depth Pruning. The first stage (Width Pruning)
removes entire neurons, hence their corresponding rows and columns, aiming to
preserve the connectivity among the pruned structures in the intermediate state
of the Feed-Forward Networks in each Transformer block. This is done based on
an importance score measuring the impact of each neuron over the output
magnitude. The second stage (Depth Pruning), instead, removes entire Attention
submodules. This is done by applying an iterative process that removes the
Attention submodules with the minimum impact on a given metric of interest (in
our case, perplexity). We also propose a novel mechanism to balance the
sparsity rate of the two stages w.r.t. to the desired global sparsity. We test
2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%),
measuring the resulting perplexity over three language modeling datasets as
well as the performance over six downstream tasks. Our method consistently
outperforms five state-of-the-art competitors over three language modeling and
six downstream tasks, with an up to two-order-of-magnitude gain in terms of
pruning time. The code is available at available at
\url{https://github.com/FabrizioSandri/2SSP}.

摘要：我們提出了一個新穎的兩階段框架，用於結構化剪枝 (2SSP)，用於剪枝大型語言模型 (LLM)，它結合了兩種不同的剪枝策略，即寬度剪枝和深度剪枝。第一階段（寬度剪枝）移除整個神經元，因此移除對應的行和列，目標是在每個 Transformer 區塊的饋前網路的中間狀態中保留剪枝結構之間的連接性。這是根據一個重要性分數進行的，該分數測量每個神經元對輸出幅度的影響。第二階段（深度剪枝）則移除整個注意力子模組。這是通過應用一個迭代過程來完成的，該過程移除對給定感興趣指標（在我們的案例中，困惑度）影響最小的注意力子模組。我們還提出了一個新穎的機制來平衡兩個階段的稀疏率，以達到所需的整體稀疏率。我們在四個 LLM 家族和三個稀疏率（25%、37.5% 和 50%）上測試 2SSP，測量了三個語言建模資料集上的結果困惑度，以及六個下游任務上的效能。我們的模型在三個語言建模和六個下游任務上持續優於五個最先進的競爭對手，在剪枝時間方面獲得了高達兩個數量級的增益。程式碼可在 \url{https://github.com/FabrizioSandri/2SSP} 取得。

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

摘要：回答需要對結構化（表格）和非結構化（原始文字）資料來源進行推理和彙總的問題會帶來重大挑戰。目前的辦法仰賴微調和高品質、人工整理的資料，而這很難取得。大型語言模型（LLM）的最新進展已針對零次學習設定的單一來源文字資料多跳問題回答（QA）展現出有希望的結果，但對多來源表格文字 QA 的探討仍然有限。在本文中，我們提出了一種新穎的基於混合圖表的表格文字 QA 方法，它利用 LLM 而無需微調。我們的辦法從文字和表格資料建構一個統一的混合圖表，根據輸入問題修剪資訊，以簡潔地為 LLM 提供相關脈絡。我們使用最先進的 LLM，包括 GPT-3.5、GPT-4 和 LLaMA-3，針對具有挑戰性的 Hybrid-QA 和 OTT-QA 資料集評估我們的辦法。我們的辦法在兩個資料集上都達到了最佳的零次學習效能，在 Hybrid-QA 上將完全比對分數提高了 10%，在 OTT-QA 上將完全比對分數提高了 5.4%。此外，與原始脈絡相比，我們的辦法將符號使用量減少了 53%。

##### **Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**
2501.17759v1 by Keshav Bhandari, Geraint A. Wiggins, Simon Colton

Transformer models have made great strides in generating symbolically
represented music with local coherence. However, controlling the development of
motifs in a structured way with global form remains an open research area. One
of the reasons for this challenge is due to the note-by-note autoregressive
generation of such models, which lack the ability to correct themselves after
deviations from the motif. In addition, their structural performance on
datasets with shorter durations has not been studied in the literature. In this
study, we propose Yin-Yang, a framework consisting of a phrase generator,
phrase refiner, and phrase selector models for the development of motifs into
melodies with long-term structure and controllability. The phrase refiner is
trained on a novel corruption-refinement strategy which allows it to produce
melodic and rhythmic variations of an original motif at generation time,
thereby rectifying deviations of the phrase generator. We also introduce a new
objective evaluation metric for quantifying how smoothly the motif manifests
itself within the piece. Evaluation results show that our model achieves better
performance compared to state-of-the-art transformer models while having the
advantage of being controllable and making the generated musical structure
semi-interpretable, paving the way for musical analysis. Our code and demo page
can be found at https://github.com/keshavbhandari/yinyang.

摘要：Transformer模型在產生具有局部相干性的符號表示音樂方面取得了長足的進展。然而，以結構化的方式控制全局形式中的主題發展仍然是一個開放的研究領域。這種挑戰的原因之一是這種模型逐個音符的自動回歸生成，它們缺乏在偏離主題後自我糾正的能力。此外，尚未在文獻中研究它們在持續時間較短的數據集上的結構性能。在這項研究中，我們提出了陰陽，一個由短語生成器、短語精煉器和短語選擇器模型組成的框架，用於將主題發展成具有長期結構和可控性的旋律。短語精煉器在一個新穎的破壞精煉策略上進行訓練，這使它能夠在生成時產生原始主題的旋律和節奏變奏，從而糾正短語生成器的偏差。我們還引入了一個新的客觀評估指標，用於量化主題在作品中表現得有多麼流暢。評估結果表明，與最先進的Transformer模型相比，我們的模型取得了更好的性能，同時具有可控性和使生成的音樂結構半可解釋的優點，為音樂分析鋪平了道路。我們的代碼和演示頁面可以在 https://github.com/keshavbhandari/yinyang 中找到。

##### **Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**
2501.17749v1 by Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura

Large Language Models (LLMs) have become an integral part of our daily lives.
However, they impose certain risks, including those that can harm individuals'
privacy, perpetuate biases and spread misinformation. These risks highlight the
need for robust safety mechanisms, ethical guidelines, and thorough testing to
ensure their responsible deployment. Safety of LLMs is a key property that
needs to be thoroughly tested prior the model to be deployed and accessible to
the general users. This paper reports the external safety testing experience
conducted by researchers from Mondragon University and University of Seville on
OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing
program. In particular, we apply our tool, ASTRAL, to automatically and
systematically generate up to date unsafe test inputs (i.e., prompts) that
helps us test and assess different safety categories of LLMs. We automatically
generate and execute a total of 10,080 unsafe test input on a early o3-mini
beta version. After manually verifying the test cases classified as unsafe by
ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We
highlight key insights and findings uncovered during the pre-deployment
external testing phase of OpenAI's latest LLM.

摘要：大型語言模型 (LLM) 已成為我們日常生活不可或缺的一部分。
然而，它們會帶來某些風險，包括可能損害個人隱私、延續偏見和散布錯誤訊息的風險。這些風險突顯出需要穩健的安全機制、道德準則和徹底的測試，以確保其負責任的部署。LLM 的安全性是一個關鍵特性，需要在模型部署並供一般使用者存取之前進行徹底的測試。本文報告了 Mondragon 大學和塞維亞大學的研究人員在 OpenAI 的早期存取安全測試計畫中，針對 OpenAI 的新 o3-mini LLM 進行的外部安全測試經驗。特別是，我們運用我們的工具 ASTRAL 自動且系統性地產生最新的不安全測試輸入（即提示），這有助於我們測試和評估 LLM 的不同安全類別。我們自動產生並執行總共 10,080 個不安全測試輸入，針對早期 o3-mini 測試版。在手動驗證 ASTRAL 分類為不安全的測試案例後，我們總共找出 87 個 LLM 不安全行為的實際範例。我們重點說明在 OpenAI 最新 LLM 的部署前外部測試階段中發現的主要見解和發現。

##### **Exact characterization of ε-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**
2501.17731v1 by Alberto Carlevaro, Teodoro Alamo, Fabrizio Dabbene, Maurizio Mongelli

Probabilistic guarantees on the prediction of data-driven classifiers are
necessary to define models that can be considered reliable. This is a key
requirement for modern machine learning in which the goodness of a system is
measured in terms of trustworthiness, clearly dividing what is safe from what
is unsafe. The spirit of this paper is exactly in this direction. First, we
introduce a formal definition of {\epsilon}-Safe Decision Region, a subset of
the input space in which the prediction of a target (safe) class is
probabilistically guaranteed. Second, we prove that, when data come from
exponential family distributions, the form of such a region is analytically
determined and controllable by design parameters, i.e. the probability of
sampling the target class and the confidence on the prediction. However, the
request of having exponential data is not always possible. Inspired by this
limitation, we developed Multi Cost SVM, an SVM based algorithm that
approximates the safe region and is also able to handle unbalanced data. The
research is complemented by experiments and code available for reproducibility.

摘要：在資料驅動分類器的預測上，機率保證對於定義可被認為可靠的模型是必要的。這是現代機器學習的一項關鍵需求，其中系統的優劣是根據可信度衡量的，清楚地將安全與不安全的區分開來。本文的精神正是朝這個方向發展。首先，我們引入{\epsilon}-安全決策區域的正式定義，它是輸入空間的一個子集，其中目標（安全）類別的預測在機率上是有保證的。其次，我們證明，當資料來自指數族分佈時，這種區域的形式是由設計參數解析確定的和可控的，即抽樣目標類別的機率和預測的信心。然而，擁有指數資料的要求並不總是可行的。受到這個限制的啟發，我們開發了多成本 SVM，一種基於 SVM 的演算法，它近似安全區域，並且也能夠處理不平衡的資料。本研究由實驗和可供重現的程式碼補充。

