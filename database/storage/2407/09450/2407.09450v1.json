{"2407.09450": {"publish_time": "2024-07-12", "title": "Human-like Episodic Memory for Infinite Context LLMs", "paper_summary": "Large language models (LLMs) have shown remarkable capabilities, but still\nstruggle with processing extensive contexts, limiting their ability to maintain\ncoherence and accuracy over long sequences. In contrast, the human brain excels\nat organising and retrieving episodic experiences across vast temporal scales,\nspanning a lifetime. In this work, we introduce EM-LLM, a novel approach that\nintegrates key aspects of human episodic memory and event cognition into LLMs,\nenabling them to effectively handle practically infinite context lengths while\nmaintaining computational efficiency. EM-LLM organises sequences of tokens into\ncoherent episodic events using a combination of Bayesian surprise and\ngraph-theoretic boundary refinement in an on-line fashion. When needed, these\nevents are retrieved through a two-stage memory process, combining\nsimilarity-based and temporally contiguous retrieval for efficient and\nhuman-like access to relevant information. Experiments on the LongBench dataset\ndemonstrate EM-LLM's superior performance, outperforming the state-of-the-art\nInfLLM model with an overall relative improvement of 4.3% across various tasks,\nincluding a 33% improvement on the PassageRetrieval task. Furthermore, our\nanalysis reveals strong correlations between EM-LLM's event segmentation and\nhuman-perceived events, suggesting a bridge between this artificial system and\nits biological counterpart. This work not only advances LLM capabilities in\nprocessing extended contexts but also provides a computational framework for\nexploring human memory mechanisms, opening new avenues for interdisciplinary\nresearch in AI and cognitive science.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u4ecd\u96e3\u4ee5\u8655\u7406\u5ee3\u6cdb\u7684\u8108\u7d61\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u9577\u5e8f\u5217\u4e2d\u7dad\u6301\u9023\u8cab\u6027\u548c\u6e96\u78ba\u6027\u7684\u80fd\u529b\u3002\u76f8\u8f03\u4e4b\u4e0b\uff0c\u4eba\u8166\u64c5\u9577\u5728\u5ee3\u5927\u7684\u6642\u9593\u5c3a\u5ea6\u4e0a\u7d44\u7e54\u548c\u63d0\u53d6\u60c5\u7bc0\u9ad4\u9a57\uff0c\u8de8\u8d8a\u4e00\u751f\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86 EM-LLM\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5b83\u5c07\u4eba\u985e\u60c5\u7bc0\u8a18\u61b6\u548c\u4e8b\u4ef6\u8a8d\u77e5\u7684\u95dc\u9375\u9762\u5411\u6574\u5408\u5230 LLM \u4e2d\uff0c\u8b93\u5b83\u5011\u80fd\u5920\u6709\u6548\u5730\u8655\u7406\u5be6\u969b\u4e0a\u7121\u9650\u7684\u8108\u7d61\u9577\u5ea6\uff0c\u540c\u6642\u7dad\u6301\u904b\u7b97\u6548\u7387\u3002EM-LLM \u4f7f\u7528\u8c9d\u6c0f\u9a5a\u559c\u548c\u5716\u8ad6\u908a\u754c\u7cbe\u7149\u7684\u7d44\u5408\uff0c\u4ee5\u7dda\u4e0a\u65b9\u5f0f\u5c07\u5e8f\u5217\u6a19\u8a18\u7d44\u7e54\u6210\u9023\u8cab\u7684\u60c5\u7bc0\u4e8b\u4ef6\u3002\u5728\u9700\u8981\u6642\uff0c\u9019\u4e9b\u4e8b\u4ef6\u6703\u900f\u904e\u5169\u968e\u6bb5\u7684\u8a18\u61b6\u904e\u7a0b\u4f86\u63d0\u53d6\uff0c\u7d50\u5408\u57fa\u65bc\u76f8\u4f3c\u6027\u548c\u6642\u9593\u9023\u7e8c\u6027\u7684\u63d0\u53d6\uff0c\u4ee5\u6709\u6548\u4e14\u985e\u4f3c\u4eba\u985e\u7684\u65b9\u5f0f\u5b58\u53d6\u76f8\u95dc\u8cc7\u8a0a\u3002\u5728 LongBench \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\u4e86 EM-LLM \u7684\u5353\u8d8a\u6548\u80fd\uff0c\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u512a\u65bc\u6700\u5148\u9032\u7684 InfLLM \u6a21\u578b\uff0c\u5728 PassageRetrieval \u4efb\u52d9\u4e2d\u6539\u9032\u4e86 33%\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u5206\u6790\u63ed\u793a\u4e86 EM-LLM \u7684\u4e8b\u4ef6\u5206\u5272\u8207\u4eba\u985e\u611f\u77e5\u4e8b\u4ef6\u4e4b\u9593\u7684\u5f37\u76f8\u95dc\u6027\uff0c\u986f\u793a\u4e86\u9019\u500b\u4eba\u5de5\u7cfb\u7d71\u8207\u5176\u751f\u7269\u5c0d\u61c9\u7269\u4e4b\u9593\u7684\u6a4b\u6a11\u3002\u9019\u9805\u5de5\u4f5c\u4e0d\u50c5\u63d0\u5347\u4e86 LLM \u5728\u8655\u7406\u5ef6\u4f38\u8108\u7d61\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e5f\u63d0\u4f9b\u4e86\u4e00\u500b\u904b\u7b97\u67b6\u69cb\u4f86\u63a2\u7d22\u4eba\u985e\u8a18\u61b6\u6a5f\u5236\uff0c\u70ba AI \u548c\u8a8d\u77e5\u79d1\u5b78\u7684\u8de8\u9818\u57df\u7814\u7a76\u958b\u555f\u4e86\u65b0\u7684\u9014\u5f91\u3002", "author": "Zafeirios Fountas et.al.", "authors": "Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang", "id": "2407.09450v1", "paper_url": "http://arxiv.org/abs/2407.09450v1", "repo": "null"}}