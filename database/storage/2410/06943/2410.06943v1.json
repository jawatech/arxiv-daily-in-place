{"2410.06943": {"publish_time": "2024-10-09", "title": "AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation", "paper_summary": "Large Language Models (LLMs) leverage external tools primarily through\ngenerating the API request to enhance task completion efficiency. The accuracy\nof API request generation significantly determines the capability of LLMs to\naccomplish tasks.\n  Due to the inherent hallucinations within the LLM, it is difficult to\nefficiently and accurately generate the correct API request.\n  Current research uses prompt-based feedback to facilitate the LLM-based API\nrequest generation. However, existing methods lack factual information and are\ninsufficiently detailed.\n  To address these issues, we propose AutoFeedback, an LLM-based framework for\nefficient and accurate API request generation, with a Static Scanning Component\n(SSC) and a Dynamic Analysis Component (DAC). SSC incorporates errors detected\nin the API requests as pseudo-facts into the feedback, enriching the factual\ninformation. DAC retrieves information from API documentation, enhancing the\nlevel of detail in feedback.\n  Based on this two components, Autofeedback implementes two feedback loops\nduring the process of generating API requests by the LLM.\n  Extensive experiments demonstrate that it significantly improves accuracy of\nAPI request generation and reduces the interaction cost. AutoFeedback achieves\nan accuracy of 100.00\\% on a real-world API dataset and reduces the cost of\ninteraction with GPT-3.5 Turbo by 23.44\\%, and GPT-4 Turbo by 11.85\\%.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e3b\u8981\u900f\u904e\u7522\u751f API \u8981\u6c42\u4f86\u63d0\u5347\u4efb\u52d9\u5b8c\u6210\u6548\u7387\uff0c\u4ee5\u5229\u7528\u5916\u90e8\u5de5\u5177\u3002API \u8981\u6c42\u7522\u751f\u7684\u6e96\u78ba\u6027\u986f\u8457\u6c7a\u5b9a LLM \u5b8c\u6210\u4efb\u52d9\u7684\u80fd\u529b\u3002\n\u7531\u65bc LLM \u5167\u90e8\u56fa\u6709\u7684\u5e7b\u89ba\uff0c\u5f88\u96e3\u6709\u6548\u4e14\u6e96\u78ba\u5730\u7522\u751f\u6b63\u78ba\u7684 API \u8acb\u6c42\u3002\n\u76ee\u524d\u7684\u7814\u7a76\u4f7f\u7528\u57fa\u65bc\u63d0\u793a\u7684\u56de\u994b\u4f86\u4fc3\u9032\u57fa\u65bc LLM \u7684 API \u8acb\u6c42\u7522\u751f\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u7f3a\u4e4f\u4e8b\u5be6\u8cc7\u8a0a\u4e14\u4e0d\u5920\u8a73\u7d30\u3002\n\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 AutoFeedback\uff0c\u4e00\u500b\u57fa\u65bc LLM \u7684\u67b6\u69cb\uff0c\u7528\u65bc\u6709\u6548\u4e14\u6e96\u78ba\u5730\u7522\u751f API \u8acb\u6c42\uff0c\u4e26\u5177\u5099\u975c\u614b\u6383\u63cf\u5143\u4ef6 (SSC) \u548c\u52d5\u614b\u5206\u6790\u5143\u4ef6 (DAC)\u3002SSC \u5c07 API \u8acb\u6c42\u4e2d\u5075\u6e2c\u5230\u7684\u932f\u8aa4\u4f5c\u70ba\u507d\u4e8b\u5be6\u7d0d\u5165\u56de\u994b\u4e2d\uff0c\u8c50\u5bcc\u4e86\u4e8b\u5be6\u8cc7\u8a0a\u3002DAC \u5f9e API \u6587\u4ef6\u4e2d\u64f7\u53d6\u8cc7\u8a0a\uff0c\u63d0\u5347\u56de\u994b\u4e2d\u7684\u8a73\u7d30\u7a0b\u5ea6\u3002\n\u57fa\u65bc\u9019\u5169\u500b\u5143\u4ef6\uff0cAutofeedback \u5728 LLM \u7522\u751f API \u8acb\u6c42\u7684\u904e\u7a0b\u4e2d\u5be6\u4f5c\u4e86\u5169\u500b\u56de\u994b\u8ff4\u8def\u3002\n\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u5b83\u986f\u8457\u63d0\u5347\u4e86 API \u8acb\u6c42\u7522\u751f\u7684\u6e96\u78ba\u6027\u4e26\u964d\u4f4e\u4e86\u4e92\u52d5\u6210\u672c\u3002AutoFeedback \u5728\u771f\u5be6\u4e16\u754c\u7684 API \u8cc7\u6599\u96c6\u4e0a\u9054\u5230\u4e86 100.00% \u7684\u6e96\u78ba\u5ea6\uff0c\u4e26\u5c07\u8207 GPT-3.5 Turbo \u7684\u4e92\u52d5\u6210\u672c\u964d\u4f4e\u4e86 23.44%\uff0c\u8207 GPT-4 Turbo \u7684\u4e92\u52d5\u6210\u672c\u964d\u4f4e\u4e86 11.85%\u3002", "author": "Huanxi Liu et.al.", "authors": "Huanxi Liu, Jiaqi Liao, Dawei Feng, Kele Xu, Huaimin Wang", "id": "2410.06943v1", "paper_url": "http://arxiv.org/abs/2410.06943v1", "repo": "null"}}