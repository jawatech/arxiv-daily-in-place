{"2409.13321": {"publish_time": "2024-09-20", "title": "SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation", "paper_summary": "Inspired by the success of large language models (LLMs), there is growing\nresearch interest in developing LLMs in the medical domain to assist\nclinicians. However, for hospitals, using closed-source commercial LLMs\ninvolves privacy issues, and developing open-source public LLMs requires\nlarge-scale computational resources, which are usually limited, especially in\nresource-efficient regions and low-income countries. We propose an open-source\nSmall Language and Vision Assistant (SLaVA-CXR) that can be used for Chest\nX-Ray report automation. To efficiently train a small assistant, we first\npropose the Re$^3$Training method, which simulates the cognitive development of\nradiologists and optimizes the model in the Recognition, Reasoning, and\nReporting training manner. Then, we introduce a data synthesis method, RADEX,\nwhich can generate a high-quality and diverse training corpus with privacy\nregulation compliance. The extensive experiments show that our SLaVA-CXR built\non a 2.7B backbone not only outperforms but also achieves 6 times faster\ninference efficiency than previous state-of-the-art larger models.", "paper_summary_zh": "\u53d7\u5230\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6210\u529f\u555f\u767c\uff0c\u5728\u91ab\u7642\u9818\u57df\u958b\u767c LLM \u4ee5\u5354\u52a9\u81e8\u5e8a\u91ab\u751f\u5f15\u8d77\u4e86\u8d8a\u4f86\u8d8a\u591a\u7684\u7814\u7a76\u8208\u8da3\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u91ab\u9662\u800c\u8a00\uff0c\u4f7f\u7528\u5c01\u9589\u539f\u59cb\u78bc\u7684\u5546\u696d LLM \u6d89\u53ca\u96b1\u79c1\u554f\u984c\uff0c\u800c\u958b\u767c\u958b\u653e\u539f\u59cb\u78bc\u7684\u516c\u5171 LLM \u9700\u8981\u5927\u898f\u6a21\u7684\u8a08\u7b97\u8cc7\u6e90\uff0c\u9019\u4e9b\u8cc7\u6e90\u901a\u5e38\u6709\u9650\uff0c\u7279\u5225\u662f\u5728\u8cc7\u6e90\u6548\u7387\u9ad8\u7684\u5730\u5340\u548c\u4f4e\u6536\u5165\u570b\u5bb6\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u958b\u653e\u539f\u59cb\u78bc\u7684\u5c0f\u8a9e\u8a00\u548c\u8996\u89ba\u52a9\u7406 (SLaVA-CXR)\uff0c\u53ef\u7528\u65bc\u80f8\u90e8 X \u5149\u5831\u544a\u81ea\u52d5\u5316\u3002\u70ba\u4e86\u6709\u6548\u8a13\u7df4\u4e00\u500b\u5c0f\u578b\u52a9\u7406\uff0c\u6211\u5011\u9996\u5148\u63d0\u51fa\u4e86 Re$^3$Training \u65b9\u6cd5\uff0c\u5b83\u6a21\u64ec\u4e86\u653e\u5c04\u79d1\u91ab\u751f\u7684\u8a8d\u77e5\u767c\u5c55\uff0c\u4e26\u4ee5\u8b58\u5225\u3001\u63a8\u7406\u548c\u5831\u544a\u8a13\u7df4\u65b9\u5f0f\u512a\u5316\u6a21\u578b\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u6578\u64da\u5408\u6210\u65b9\u6cd5 RADEX\uff0c\u5b83\u53ef\u4ee5\u5728\u7b26\u5408\u96b1\u79c1\u6cd5\u898f\u7684\u60c5\u6cc1\u4e0b\u751f\u6210\u4e00\u500b\u9ad8\u54c1\u8cea\u4e14\u591a\u6a23\u5316\u7684\u8a13\u7df4\u8a9e\u6599\u5eab\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u5efa\u7acb\u5728 2.7B \u4e3b\u5e79\u4e0a\u7684 SLaVA-CXR \u4e0d\u50c5\u8868\u73fe\u51fa\u8272\uff0c\u800c\u4e14\u63a8\u7406\u6548\u7387\u6bd4\u4ee5\u524d\u6700\u5148\u9032\u7684\u8f03\u5927\u6a21\u578b\u5feb 6 \u500d\u3002", "author": "Jinge Wu et.al.", "authors": "Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu", "id": "2409.13321v1", "paper_url": "http://arxiv.org/abs/2409.13321v1", "repo": "null"}}