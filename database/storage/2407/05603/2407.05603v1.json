{"2407.05603": {"publish_time": "2024-07-08", "title": "WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering", "paper_summary": "Whole slide imaging is routinely adopted for carcinoma diagnosis and\nprognosis. Abundant experience is required for pathologists to achieve accurate\nand reliable diagnostic results of whole slide images (WSI). The huge size and\nheterogeneous features of WSIs make the workflow of pathological reading\nextremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)\nto interpret WSIs by generative visual question answering. WSI-VQA shows\nuniversality by reframing various kinds of slide-level tasks in a\nquestion-answering pattern, in which pathologists can achieve\nimmunohistochemical grading, survival prediction, and tumor subtyping following\nhuman-machine interaction. Furthermore, we establish a WSI-VQA dataset which\ncontains 8672 slide-level question-answering pairs with 977 WSIs. Besides the\nability to deal with different slide-level tasks, our generative model which is\nnamed Wsi2Text Transformer (W2T) outperforms existing discriminative models in\nmedical correctness, which reveals the potential of our model to be applied in\nthe clinical scenario. Additionally, we also visualize the co-attention mapping\nbetween word embeddings and WSIs as an intuitive explanation for diagnostic\nresults. The dataset and related code are available at\nhttps://github.com/cpystan/WSI-VQA.", "paper_summary_zh": "\u5168\u5207\u7247\u5f71\u50cf\u901a\u5e38\u7528\u65bc\u764c\u75c7\u7684\u8a3a\u65b7\u548c\u9810\u5f8c\u3002\u75c5\u7406\u5b78\u5bb6\u9700\u8981\u6709\u8c50\u5bcc\u7684\u7d93\u9a57\u624d\u80fd\u5c0d\u5168\u5207\u7247\u5f71\u50cf (WSI) \u505a\u51fa\u6e96\u78ba\u4e14\u53ef\u9760\u7684\u8a3a\u65b7\u7d50\u679c\u3002WSI \u7684\u5c3a\u5bf8\u9f90\u5927\u4e14\u7279\u5fb5\u7570\u8cea\uff0c\u4f7f\u5f97\u75c5\u7406\u5b78\u5224\u8b80\u7684\u5de5\u4f5c\u6d41\u7a0b\u6975\u70ba\u8017\u6642\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u6846\u67b6 (WSI-VQA)\uff0c\u900f\u904e\u751f\u6210\u5f0f\u8996\u89ba\u554f\u7b54\u4f86\u8a6e\u91cb WSI\u3002WSI-VQA \u900f\u904e\u5728\u554f\u7b54\u6a21\u5f0f\u4e2d\u91cd\u65b0\u5b9a\u7fa9\u5404\u7a2e\u5207\u7247\u5c64\u7d1a\u4efb\u52d9\uff0c\u5c55\u73fe\u5176\u901a\u7528\u6027\uff0c\u75c5\u7406\u5b78\u5bb6\u53ef\u4ee5\u5728\u4eba\u6a5f\u4e92\u52d5\u5f8c\uff0c\u5b8c\u6210\u514d\u75ab\u7d44\u7e54\u5316\u5b78\u5206\u7d1a\u3001\u5b58\u6d3b\u9810\u6e2c\u548c\u816b\u7624\u4e9e\u578b\u5206\u985e\u3002\u6b64\u5916\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b WSI-VQA \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 8672 \u500b\u5207\u7247\u5c64\u7d1a\u554f\u7b54\u5c0d\uff0c\u4ee5\u53ca 977 \u500b WSI\u3002\u9664\u4e86\u80fd\u5920\u8655\u7406\u4e0d\u540c\u7684\u5207\u7247\u5c64\u7d1a\u4efb\u52d9\u5916\uff0c\u6211\u5011\u540d\u70ba Wsi2Text Transformer (W2T) \u7684\u751f\u6210\u6a21\u578b\u5728\u91ab\u5b78\u6b63\u78ba\u6027\u65b9\u9762\u512a\u65bc\u73fe\u6709\u7684\u5224\u5225\u6a21\u578b\uff0c\u9019\u63ed\u793a\u4e86\u6211\u5011\u7684\u6a21\u578b\u5728\u81e8\u5e8a\u5834\u666f\u4e2d\u61c9\u7528\u7684\u6f5b\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5c07\u8a5e\u5d4c\u5165\u548c WSI \u4e4b\u9593\u7684\u5171\u540c\u6ce8\u610f\u6620\u5c04\u8996\u89ba\u5316\uff0c\u4f5c\u70ba\u8a3a\u65b7\u7d50\u679c\u7684\u76f4\u89c0\u89e3\u91cb\u3002\u8cc7\u6599\u96c6\u548c\u76f8\u95dc\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/cpystan/WSI-VQA \u53d6\u5f97\u3002", "author": "Pingyi Chen et.al.", "authors": "Pingyi Chen, Chenglu Zhu, Sunyi Zheng, Honglin Li, Lin Yang", "id": "2407.05603v1", "paper_url": "http://arxiv.org/abs/2407.05603v1", "repo": "https://github.com/cpystan/wsi-vqa"}}