{"2408.17422": {"publish_time": "2024-08-30", "title": "Open-vocabulary Temporal Action Localization using VLMs", "paper_summary": "Video action localization aims to find timings of a specific action from a\nlong video. Although existing learning-based approaches have been successful,\nthose require annotating videos that come with a considerable labor cost. This\npaper proposes a learning-free, open-vocabulary approach based on emerging\nvision-language models (VLM). The challenge stems from the fact that VLMs are\nneither designed to process long videos nor tailored for finding actions. We\novercome these problems by extending an iterative visual prompting technique.\nSpecifically, we sample video frames into a concatenated image with frame index\nlabels, making a VLM guess a frame that is considered to be closest to the\nstart/end of the action. Iterating this process by narrowing a sampling time\nwindow results in finding a specific frame of start and end of an action. We\ndemonstrate that this sampling technique yields reasonable results,\nillustrating a practical extension of VLMs for understanding videos.", "paper_summary_zh": "\u5f71\u7247\u52d5\u4f5c\u5b9a\u4f4d\u65e8\u5728\u5f9e\u9577\u5f71\u7247\u4e2d\u627e\u51fa\u7279\u5b9a\u52d5\u4f5c\u7684\u6642\u9593\u3002\u5118\u7ba1\u73fe\u6709\u7684\u57fa\u65bc\u5b78\u7fd2\u7684\u65b9\u6cd5\u5df2\u6210\u529f\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u9700\u8981\u8a3b\u89e3\u5f71\u7247\uff0c\u800c\u9019\u9700\u8981\u76f8\u7576\u53ef\u89c0\u7684\u4eba\u529b\u6210\u672c\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u65b0\u8208\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u7121\u5b78\u7fd2\u3001\u958b\u653e\u8a5e\u5f59\u7684\u65b9\u6cd5\u3002\u6311\u6230\u5728\u65bc VLM \u65e2\u4e0d\u662f\u8a2d\u8a08\u7528\u4f86\u8655\u7406\u9577\u5f71\u7247\uff0c\u4e5f\u4e0d\u662f\u70ba\u5c0b\u627e\u52d5\u4f5c\u800c\u91cf\u8eab\u6253\u9020\u3002\u6211\u5011\u900f\u904e\u64f4\u5c55\u4e00\u7a2e\u53cd\u8986\u8996\u89ba\u63d0\u793a\u6280\u8853\u4f86\u514b\u670d\u9019\u4e9b\u554f\u984c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c07\u5f71\u7247\u5e40\u53d6\u6a23\u6210\u4e00\u500b\u4e32\u806f\u5f71\u50cf\uff0c\u4e26\u52a0\u4e0a\u5e40\u7d22\u5f15\u6a19\u7c64\uff0c\u8b93 VLM \u731c\u6e2c\u88ab\u8a8d\u70ba\u6700\u63a5\u8fd1\u52d5\u4f5c\u958b\u59cb/\u7d50\u675f\u7684\u5e40\u3002\u900f\u904e\u7e2e\u5c0f\u53d6\u6a23\u6642\u9593\u8996\u7a97\u4f86\u53cd\u8986\u9032\u884c\u6b64\u7a0b\u5e8f\uff0c\u5c31\u80fd\u627e\u51fa\u52d5\u4f5c\u958b\u59cb\u548c\u7d50\u675f\u7684\u7279\u5b9a\u5e40\u3002\u6211\u5011\u8b49\u660e\u4e86\u9019\u7a2e\u53d6\u6a23\u6280\u8853\u80fd\u7522\u751f\u5408\u7406\u7684\u7d50\u679c\uff0c\u8aaa\u660e\u4e86 VLM \u5728\u5f71\u7247\u7406\u89e3\u65b9\u9762\u7684\u5be6\u7528\u64f4\u5c55\u3002", "author": "Naoki Wake et.al.", "authors": "Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi", "id": "2408.17422v1", "paper_url": "http://arxiv.org/abs/2408.17422v1", "repo": "null"}}