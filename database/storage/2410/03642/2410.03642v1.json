{"2410.03642": {"publish_time": "2024-10-04", "title": "Aligning LLMs with Individual Preferences via Interaction", "paper_summary": "As large language models (LLMs) demonstrate increasingly advanced\ncapabilities, aligning their behaviors with human values and preferences\nbecomes crucial for their wide adoption. While previous research focuses on\ngeneral alignment to principles such as helpfulness, harmlessness, and honesty,\nthe need to account for individual and diverse preferences has been largely\noverlooked, potentially undermining customized human experiences. To address\nthis gap, we train LLMs that can ''interact to align'', essentially cultivating\nthe meta-skill of LLMs to implicitly infer the unspoken personalized\npreferences of the current user through multi-turn conversations, and then\ndynamically align their following behaviors and responses to these inferred\npreferences. Our approach involves establishing a diverse pool of 3,310\ndistinct user personas by initially creating seed examples, which are then\nexpanded through iterative self-generation and filtering. Guided by distinct\nuser personas, we leverage multi-LLM collaboration to develop a multi-turn\npreference dataset containing 3K+ multi-turn conversations in tree structures.\nFinally, we apply supervised fine-tuning and reinforcement learning to enhance\nLLMs using this dataset. For evaluation, we establish the ALOE (ALign With\nCustOmized PrEferences) benchmark, consisting of 100 carefully selected\nexamples and well-designed metrics to measure the customized alignment\nperformance during conversations. Experimental results demonstrate the\neffectiveness of our method in enabling dynamic, personalized alignment via\ninteraction.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u73fe\u51fa\u8d8a\u4f86\u8d8a\u5148\u9032\u7684\u80fd\u529b\uff0c\u8b93\u5b83\u5011\u7684\u884c\u70ba\u8207\u4eba\u985e\u7684\u50f9\u503c\u89c0\u548c\u504f\u597d\u4fdd\u6301\u4e00\u81f4\uff0c\u5c0d\u65bc\u5b83\u5011\u7684\u5ee3\u6cdb\u63a1\u7528\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u5148\u524d\u7684\u7814\u7a76\u5c08\u6ce8\u65bc\u5c0d\u8af8\u5982\u6a02\u65bc\u52a9\u4eba\u3001\u7121\u5bb3\u548c\u8aa0\u5be6\u7b49\u539f\u5247\u7684\u4e00\u822c\u6027\u5c0d\u9f4a\uff0c\u4f46\u5c0d\u500b\u4eba\u548c\u4e0d\u540c\u504f\u597d\u7684\u9700\u6c42\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u88ab\u5ffd\u8996\u4e86\uff0c\u9019\u53ef\u80fd\u6703\u7834\u58de\u5ba2\u88fd\u5316\u7684\u4eba\u985e\u9ad4\u9a57\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u80fd\u5920\u300c\u4e92\u52d5\u5c0d\u9f4a\u300d\u7684 LLM\uff0c\u672c\u8cea\u4e0a\u57f9\u990a\u4e86 LLM \u7684\u5143\u6280\u80fd\uff0c\u900f\u904e\u591a\u8f2a\u5c0d\u8a71\u96b1\u542b\u63a8\u65b7\u7576\u524d\u4f7f\u7528\u8005\u7684\u672a\u8aaa\u51fa\u53e3\u7684\u500b\u4eba\u5316\u504f\u597d\uff0c\u7136\u5f8c\u52d5\u614b\u5c0d\u9f4a\u5176\u5f8c\u7e8c\u884c\u70ba\u548c\u56de\u61c9\uff0c\u4ee5\u7b26\u5408\u9019\u4e9b\u63a8\u65b7\u51fa\u7684\u504f\u597d\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u62ec\u5efa\u7acb\u4e00\u500b\u7531 3,310 \u500b\u4e0d\u540c\u7684\u4f7f\u7528\u8005\u89d2\u8272\u7d44\u6210\u7684\u591a\u5143\u5316\u6c60\uff0c\u6700\u521d\u900f\u904e\u5efa\u7acb\u7a2e\u5b50\u7bc4\u4f8b\uff0c\u7136\u5f8c\u900f\u904e\u53cd\u8986\u81ea\u6211\u7522\u751f\u548c\u904e\u6ffe\u4f86\u64f4\u5c55\u3002\u5728\u4e0d\u540c\u7684\u4f7f\u7528\u8005\u89d2\u8272\u7684\u6307\u5c0e\u4e0b\uff0c\u6211\u5011\u5229\u7528\u591a LLM \u5354\u4f5c\u4f86\u958b\u767c\u4e00\u500b\u591a\u8f2a\u504f\u597d\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u6a39\u72c0\u7d50\u69cb\u4e2d\u7684 3K \u591a\u500b\u591a\u8f2a\u5c0d\u8a71\u3002\u6700\u5f8c\uff0c\u6211\u5011\u61c9\u7528\u76e3\u7763\u5fae\u8abf\u548c\u5f37\u5316\u5b78\u7fd2\uff0c\u4f7f\u7528\u6b64\u8cc7\u6599\u96c6\u4f86\u589e\u5f37 LLM\u3002\u70ba\u4e86\u8a55\u4f30\uff0c\u6211\u5011\u5efa\u7acb\u4e86 ALOE\uff08\u8207\u5ba2\u88fd\u5316\u504f\u597d\u5c0d\u9f4a\uff09\u57fa\u6e96\uff0c\u5176\u4e2d\u5305\u542b 100 \u500b\u7d93\u904e\u4ed4\u7d30\u6311\u9078\u7684\u7bc4\u4f8b\u548c\u7cbe\u5fc3\u8a2d\u8a08\u7684\u6307\u6a19\uff0c\u7528\u65bc\u8861\u91cf\u5c0d\u8a71\u671f\u9593\u7684\u5ba2\u88fd\u5316\u5c0d\u9f4a\u6548\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u900f\u904e\u4e92\u52d5\u5be6\u73fe\u52d5\u614b\u3001\u500b\u4eba\u5316\u5c0d\u9f4a\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "author": "Shujin Wu et.al.", "authors": "Shujin Wu, May Fung, Cheng Qian, Jeonghwan Kim, Dilek Hakkani-Tur, Heng Ji", "id": "2410.03642v1", "paper_url": "http://arxiv.org/abs/2410.03642v1", "repo": "https://github.com/shujinwu-0814/aloe"}}