{"2501.05855": {"publish_time": "2025-01-10", "title": "ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability", "paper_summary": "Concept-based explanations work by mapping complex model computations to\nhuman-understandable concepts. Evaluating such explanations is very difficult,\nas it includes not only the quality of the induced space of possible concepts\nbut also how effectively the chosen concepts are communicated to users.\nExisting evaluation metrics often focus solely on the former, neglecting the\nlatter. We introduce an evaluation framework for measuring concept explanations\nvia automated simulatability: a simulator's ability to predict the explained\nmodel's outputs based on the provided explanations. This approach accounts for\nboth the concept space and its interpretation in an end-to-end evaluation.\nHuman studies for simulatability are notoriously difficult to enact,\nparticularly at the scale of a wide, comprehensive empirical evaluation (which\nis the subject of this work). We propose using large language models (LLMs) as\nsimulators to approximate the evaluation and report various analyses to make\nsuch approximations reliable. Our method allows for scalable and consistent\nevaluation across various models and datasets. We report a comprehensive\nempirical evaluation using this framework and show that LLMs provide consistent\nrankings of explanation methods. Code available at\nhttps://github.com/AnonymousConSim/ConSim", "paper_summary_zh": "\u6982\u5ff5\u578b\u89e3\u91cb\u900f\u904e\u5c07\u8907\u96dc\u7684\u6a21\u578b\u904b\u7b97\u5c0d\u61c9\u5230\u4eba\u985e\u53ef\u4ee5\u7406\u89e3\u7684\u6982\u5ff5\u4f86\u904b\u4f5c\u3002\u8a55\u4f30\u9019\u7a2e\u89e3\u91cb\u975e\u5e38\u56f0\u96e3\uff0c\u56e0\u70ba\u5b83\u4e0d\u50c5\u5305\u62ec\u53ef\u80fd\u7684\u6982\u5ff5\u8a98\u767c\u7a7a\u9593\u7684\u54c1\u8cea\uff0c\u9084\u5305\u62ec\u9078\u64c7\u7684\u6982\u5ff5\u6709\u6548\u50b3\u9054\u7d66\u4f7f\u7528\u8005\u7684\u7a0b\u5ea6\u3002\u73fe\u6709\u7684\u8a55\u4f30\u6307\u6a19\u901a\u5e38\u53ea\u95dc\u6ce8\u524d\u8005\uff0c\u800c\u5ffd\u7565\u5f8c\u8005\u3002\u6211\u5011\u5f15\u5165\u4e00\u500b\u8a55\u4f30\u67b6\u69cb\uff0c\u900f\u904e\u81ea\u52d5\u6a21\u64ec\u6027\u4f86\u8861\u91cf\u6982\u5ff5\u89e3\u91cb\uff1a\u6a21\u64ec\u5668\u6839\u64da\u63d0\u4f9b\u7684\u89e3\u91cb\u9810\u6e2c\u5df2\u89e3\u91cb\u6a21\u578b\u7684\u8f38\u51fa\u3002\u9019\u7a2e\u65b9\u6cd5\u540c\u6642\u8003\u91cf\u4e86\u6982\u5ff5\u7a7a\u9593\u53ca\u5176\u5728\u7aef\u5230\u7aef\u8a55\u4f30\u4e2d\u7684\u8a6e\u91cb\u3002\u773e\u6240\u5468\u77e5\uff0c\u6a21\u64ec\u6027\u7684\u4eba\u985e\u7814\u7a76\u96e3\u4ee5\u5236\u5b9a\uff0c\u7279\u5225\u662f\u5728\u5ee3\u6cdb\u3001\u5168\u9762\u7684\u5be6\u8b49\u8a55\u4f30\u7684\u898f\u6a21\u4e0a\uff08\u9019\u662f\u9019\u9805\u5de5\u4f5c\u7684\u91cd\u9ede\uff09\u3002\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f5c\u70ba\u6a21\u64ec\u5668\u4f86\u8fd1\u4f3c\u8a55\u4f30\u4e26\u5831\u544a\u5404\u7a2e\u5206\u6790\uff0c\u4ee5\u4f7f\u6b64\u985e\u8fd1\u4f3c\u503c\u66f4\u53ef\u9760\u3002\u6211\u5011\u7684\u6a21\u578b\u5141\u8a31\u8de8\u5404\u7a2e\u6a21\u578b\u548c\u8cc7\u6599\u96c6\u9032\u884c\u53ef\u64f4\u5145\u4e14\u4e00\u81f4\u7684\u8a55\u4f30\u3002\u6211\u5011\u4f7f\u7528\u9019\u500b\u67b6\u69cb\u5831\u544a\u4e86\u4e00\u500b\u5168\u9762\u7684\u5be6\u8b49\u8a55\u4f30\uff0c\u4e26\u986f\u793a LLM \u63d0\u4f9b\u4e86\u4e00\u81f4\u7684\u89e3\u91cb\u65b9\u6cd5\u6392\u540d\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/AnonymousConSim/ConSim \u53d6\u5f97", "author": "Antonin Poch\u00e9 et.al.", "authors": "Antonin Poch\u00e9, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan", "id": "2501.05855v1", "paper_url": "http://arxiv.org/abs/2501.05855v1", "repo": "https://github.com/anonymousconsim/consim"}}