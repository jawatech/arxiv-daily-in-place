{"2501.17104": {"publish_time": "2025-01-28", "title": "COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models", "paper_summary": "We present COS(M+O)S, a System 2-inspired framework for open-ended plot\ndevelopment that systematically explores the vast space of possible story\nexpansions, enabling a 3B-parameter language model to approach the plot quality\nof a 70B model on select short-story tasks. The method accomplishes this by\ncombining Monte Carlo Tree Search (MCTS), guided by a step-level value model\nthat rewards moderate surprisal (curiosity) while penalizing incoherence, and\nOdds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value\nplot expansions. This iterative reinforcement learning loop systematically\nexplores multiple candidate plot branches, backpropagates quality signals, and\nadapts the policy for faster convergence, notably shifting the policy from\npuzzle-based Chain-of-Thought to more character-driven storytelling. In\nsmall-scale tests with short-story prompts, 67%-77% of participants favored\nCOS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our\nlearned value function aligns. GPT-4o ratings further show that COS(M+O)S\nsurpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming\nwithin 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise\ncomparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no\nstatistically significant gap from 70B. Nevertheless, absolute story quality\nremains modest, constrained by the small model's capacity and limited training\ndata.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa COS(M+O)S\uff0c\u4e00\u500b\u53d7 System 2 \u555f\u767c\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u958b\u653e\u5f0f\u60c5\u7bc0\u767c\u5c55\uff0c\u7cfb\u7d71\u6027\u5730\u63a2\u7d22\u53ef\u80fd\u7684\u6545\u4e8b\u60c5\u7bc0\u64f4\u5c55\u7684\u5ee3\u95ca\u7a7a\u9593\uff0c\u4f7f 3B \u53c3\u6578\u8a9e\u8a00\u6a21\u578b\u80fd\u5920\u5728\u9078\u64c7\u7684\u77ed\u7bc7\u6545\u4e8b\u4efb\u52d9\u4e2d\u63a5\u8fd1 70B \u6a21\u578b\u7684\u60c5\u7bc0\u54c1\u8cea\u3002\u6b64\u65b9\u6cd5\u900f\u904e\u7d50\u5408\u8499\u5730\u5361\u7f85\u6a39\u641c\u5c0b (MCTS)\uff0c\u7531\u968e\u5c64\u50f9\u503c\u6a21\u578b\u5f15\u5c0e\uff0c\u734e\u52f5\u9069\u5ea6\u7684\u9a5a\u559c (\u597d\u5947\u5fc3)\uff0c\u540c\u6642\u61f2\u7f70\u4e0d\u9023\u8cab\u6027\uff0c\u4ee5\u53ca\u6a5f\u7387\u6bd4\u504f\u597d\u6700\u4f73\u5316 (ORPO) \u4f86\u5fae\u8abf\u9ad8\u50f9\u503c\u60c5\u7bc0\u64f4\u5c55\u7684\u653f\u7b56\u3002\u6b64\u53cd\u8986\u5f37\u5316\u5b78\u7fd2\u8ff4\u5708\u7cfb\u7d71\u6027\u5730\u63a2\u7d22\u591a\u500b\u5019\u9078\u60c5\u7bc0\u5206\u652f\uff0c\u53cd\u5411\u50b3\u64ad\u54c1\u8cea\u8a0a\u865f\uff0c\u4e26\u8abf\u6574\u653f\u7b56\u4ee5\u52a0\u5feb\u6536\u6582\uff0c\u7279\u5225\u662f\u5c07\u653f\u7b56\u5f9e\u57fa\u65bc\u8b0e\u984c\u7684\u601d\u8003\u93c8\u8f49\u79fb\u5230\u66f4\u591a\u4ee5\u89d2\u8272\u70ba\u5c0e\u5411\u7684\u6545\u4e8b\u6558\u8ff0\u3002\u5728\u77ed\u7bc7\u6545\u4e8b\u63d0\u793a\u7684\u5c0f\u898f\u6a21\u6e2c\u8a66\u4e2d\uff0c67%-77% \u7684\u53c3\u8207\u8005\u504f\u597d COS(M+O)S \u8a55\u5206\u6700\u9ad8\u7684\u64f4\u5c55\uff0c\u800c\u975e\u8a55\u5206\u8f03\u4f4e\u7684\u64f4\u5c55\uff0c\u9019\u8868\u660e\u6211\u5011\u5b78\u7fd2\u5230\u7684\u50f9\u503c\u51fd\u6578\u662f\u4e00\u81f4\u7684\u3002GPT-4o \u8a55\u5206\u9032\u4e00\u6b65\u986f\u793a\uff0cCOS(M+O)S \u8d85\u8d8a\u4e86 Llama 3.2 3B \u7684\u55ae\u6b21\u89e3\u78bc\uff0cSD \u503c\u70ba 0.59\uff0c\u63a5\u8fd1 Llama 3.1 70B \u7684 SD \u503c 0.06\uff08\u7121\u986f\u8457\u5dee\u7570\uff0cp=0.93\uff09\u3002\u8207 o1 \u7684\u6210\u5c0d\u6bd4\u8f03\u5c07 COS(M+O)S \u653e\u5728 3B \u57fa\u6e96\u7dda\u4e0a\u65b9 1.5 SD\uff0c\u4e26\u4e14\u767c\u73fe\u8207 70B \u4e4b\u9593\u6c92\u6709\u7d71\u8a08\u4e0a\u986f\u8457\u7684\u5dee\u8ddd\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u7d55\u5c0d\u7684\u6545\u4e8b\u54c1\u8cea\u4ecd\u7136\u9069\u4e2d\uff0c\u53d7\u5230\u5c0f\u6a21\u578b\u5bb9\u91cf\u548c\u6709\u9650\u8a13\u7df4\u8cc7\u6599\u7684\u9650\u5236\u3002</paragraph>", "author": "Tobias Materzok et.al.", "authors": "Tobias Materzok", "id": "2501.17104v1", "paper_url": "http://arxiv.org/abs/2501.17104v1", "repo": "null"}}