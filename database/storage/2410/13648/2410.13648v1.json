{"2410.13648": {"publish_time": "2024-10-17", "title": "SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs", "paper_summary": "While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.", "paper_summary_zh": "<paragraph>\u96d6\u7136\u5148\u524d\u7684\u7814\u7a76\u5df2\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5426\u5177\u5099\u300c\u5fc3\u667a\u7406\u8ad6\u300d(ToM) - \u80fd\u5c07\u5fc3\u667a\u72c0\u614b\u6b78\u56e0\u65bc\u81ea\u5df1\u548c\u4ed6\u4eba\u7684\u80fd\u529b - \u4f46\u9bae\u5c11\u6709\u7814\u7a76\u6e2c\u8a66 LLM \u662f\u5426\u80fd\u96b1\u542b\u5730\u61c9\u7528\u6b64\u985e\u77e5\u8b58\u4f86\u9810\u6e2c\u884c\u70ba\uff0c\u6216\u5224\u65b7\u89c0\u5bdf\u5230\u7684\u884c\u70ba\u662f\u5426\u5408\u7406\u3002\u6b64\u985e\u6280\u80fd\u5c0d\u65bc\u5728\u793e\u4ea4\u74b0\u5883\u4e2d\u9069\u7576\u5730\u4e92\u52d5\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u65b0\u8cc7\u6599\u96c6 SimpleTom\uff0c\u5176\u4e2d\u5305\u542b\u7c21\u6f54\u4e14\u591a\u5143\u7684\u6545\u4e8b\uff08\u4f8b\u5982\uff0c\u300c\u666e\u6797\u683c\u65af\u6d0b\u828b\u7247\u7f50\u88e1\u6709\u767c\u9709\u7684\u6d0b\u828b\u7247\u3002\u746a\u9e97\u5728\u8d85\u5e02\u62ff\u8d77\u8a72\u7f50\u5b50\u4e26\u8d70\u5411\u6536\u9280\u53f0\u3002\u300d\uff09\uff0c\u6bcf\u500b\u6545\u4e8b\u5305\u542b\u4e09\u500b\u554f\u984c\uff0c\u6e2c\u8a66\u4e0d\u540c\u7a0b\u5ea6\u7684 ToM \u63a8\u7406\uff0c\u8981\u6c42\u6a21\u578b\u9810\u6e2c (a) \u5fc3\u667a\u72c0\u614b\uff08\u300c\u746a\u9e97\u662f\u5426\u77e5\u9053\u767c\u9709\u4e86\uff1f\u300d\uff09\uff0c(b) \u884c\u70ba\uff08\u300c\u746a\u9e97\u6703\u4ed8\u9322\u8cb7\u6d0b\u828b\u7247\u9084\u662f\u56de\u5831\u767c\u9709\u7684\u60c5\u6cc1\uff1f\u300d\uff09\uff0c\u4ee5\u53ca (c) \u5224\u65b7\uff08\u300c\u746a\u9e97\u4ed8\u4e86\u6d0b\u828b\u7247\u7684\u9322\u3002\u9019\u662f\u5426\u5408\u7406\uff1f\u300d\uff09\u3002\u64da\u6211\u5011\u6240\u77e5\uff0cSimpleToM \u662f\u7b2c\u4e00\u500b\u7cfb\u7d71\u6027\u5730\u63a2\u8a0e\u9700\u8981\u5728\u73fe\u5be6\u60c5\u5883\u4e2d\u4e86\u89e3\u5fc3\u667a\u72c0\u614b\u7684\u4e0b\u6e38\u63a8\u7406\u7684\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u4ee4\u4eba\u8457\u8ff7\uff1a\u96d6\u7136\u5927\u591a\u6578\u6a21\u578b\u90fd\u80fd\u5728\u6211\u5011\u7684\u8cc7\u6599\u96c6 (a) \u4e2d\u53ef\u9760\u5730\u9810\u6e2c\u5fc3\u667a\u72c0\u614b\uff0c\u4f46\u5b83\u5011\u901a\u5e38\u7121\u6cd5\u6b63\u78ba\u9810\u6e2c\u884c\u70ba (b)\uff0c\u800c\u4e14\u5728\u5224\u65b7\u7279\u5b9a\u884c\u70ba\u662f\u5426\u5408\u7406 (c) \u65b9\u9762\u7684\u8868\u73fe\u66f4\u5dee\uff0c\u5118\u7ba1\u5b83\u5011\u6b63\u78ba\u5730\u610f\u8b58\u5230\u4e3b\u89d2\u7684\u5fc3\u667a\u72c0\u614b\u61c9\u8a72\u8b93\u6b64\u985e\u6b21\u8981\u9810\u6e2c\u986f\u800c\u6613\u898b\u3002\u6211\u5011\u9032\u4e00\u6b65\u8868\u660e\uff0c\u6211\u5011\u53ef\u4ee5\u900f\u904e\u5e72\u9810\u63aa\u65bd\u8b93\u6a21\u578b\u5728 (b) \u548c (c) \u4e2d\u8868\u73fe\u5f97\u66f4\u597d\uff0c\u4f8b\u5982\u63d0\u9192\u6a21\u578b\u5176\u65e9\u5148\u7684\u5fc3\u667a\u72c0\u614b\u7b54\u6848\u548c\u5fc3\u667a\u72c0\u614b\u7279\u5b9a\u7684\u601d\u8003\u93c8\u63d0\u793a\uff0c\u5f9e\u800c\u63d0\u9ad8\u52d5\u4f5c\u9810\u6e2c\u6e96\u78ba\u5ea6\uff08\u4f8b\u5982\uff0cGPT-4o \u5f9e 49.5% \u63d0\u9ad8\u5230 93.5%\uff09\u548c\u5224\u65b7\u6e96\u78ba\u5ea6\uff08\u4f8b\u5982\uff0cGPT-4o \u5f9e 15.3% \u63d0\u9ad8\u5230 94.7%\uff09\u3002\u96d6\u7136\u9019\u8868\u660e\u53ef\u4ee5\u8a98\u5c0e\u6a21\u578b\u8868\u73fe\u826f\u597d\uff0c\u4f46\u5b83\u9700\u8981\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u5e72\u9810\u63aa\u65bd\uff0c\u800c\u4e14\u81ea\u7136\u6a21\u578b\u7684\u8868\u73fe\u4ecd\u7136\u5f88\u4f4e\uff0c\u9019\u5c0d\u65bc LLM \u90e8\u7f72\u4f86\u8aaa\u662f\u4e00\u500b\u8b66\u793a\u6545\u4e8b\u3002</paragraph>", "author": "Yuling Gu et.al.", "authors": "Yuling Gu, Oyvind Tafjord, Hyunwoo Kim, Jared Moore, Ronan Le Bras, Peter Clark, Yejin Choi", "id": "2410.13648v1", "paper_url": "http://arxiv.org/abs/2410.13648v1", "repo": "null"}}