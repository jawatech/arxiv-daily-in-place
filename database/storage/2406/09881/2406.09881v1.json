{"2406.09881": {"publish_time": "2024-06-14", "title": "A Unified Data Augmentation Framework for Low-Resource Multi-Domain Dialogue Generation", "paper_summary": "Current state-of-the-art dialogue systems heavily rely on extensive training\ndatasets. However, challenges arise in domains where domain-specific training\ndatasets are insufficient or entirely absent. To tackle this challenge, we\npropose a novel data \\textbf{A}ugmentation framework for\n\\textbf{M}ulti-\\textbf{D}omain \\textbf{D}ialogue \\textbf{G}eneration, referred\nto as \\textbf{AMD$^2$G}. The AMD$^2$G framework consists of a data augmentation\nprocess and a two-stage training approach: domain-agnostic training and domain\nadaptation training. We posit that domain corpora are a blend of\ndomain-agnostic and domain-specific features, with certain representation\npatterns shared among diverse domains. Domain-agnostic training aims to enable\nmodels to learn these common expressive patterns. To construct domain-agnostic\ndialogue corpora, we employ a \\textit{\\textbf{de-domaining}} data processing\ntechnique used to remove domain-specific features. By mitigating the effects of\ndomain-specific features, the model trained on the de-domained corpora can\neffectively learn common expression patterns in different domains.\nSubsequently, we adapt the learned domain-agnostic features to the target\ndomain through domain adaptation training. We conduct experiments on Chinese\ndialogue datasets from five different domains and show that AMD$^2$G achieves\nsuperior performance compared to both direct training on the target domain\ncorpus and collective training on all five domain corpora. Our work underscores\nAMD$^2$G as a viable alternative solution for low-resource multi-domain\ndialogue generation. Code and data associated with our work are available on\nGitHub repository$^{\\text 1}$.", "paper_summary_zh": "<paragraph>\u76ee\u524d\u6700\u5148\u8fdb\u7684\u5bf9\u8bdd\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u4e8e\u5e7f\u6cdb\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u3002\u7136\u800c\uff0c\u5728\u7279\u5b9a\u9886\u57df\u4e2d\uff0c\u5982\u679c\u7279\u5b9a\u9886\u57df\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u4e0d\u8db3\u6216\u5b8c\u5168\u4e0d\u5b58\u5728\uff0c\u5c31\u4f1a\u51fa\u73b0\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u9886\u57df\u5bf9\u8bdd\u751f\u6210\u7684\u65b0\u578b\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u79f0\u4e3a AMD^2G\u3002AMD^2G \u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u6570\u636e\u589e\u5f3a\u8fc7\u7a0b\u548c\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u9886\u57df\u65e0\u5173\u8bad\u7ec3\u548c\u9886\u57df\u9002\u5e94\u8bad\u7ec3\u3002\u6211\u4eec\u8ba4\u4e3a\u9886\u57df\u8bed\u6599\u5e93\u662f\u9886\u57df\u65e0\u5173\u548c\u9886\u57df\u7279\u5b9a\u7279\u5f81\u7684\u6df7\u5408\u4f53\uff0c\u5176\u4e2d\u67d0\u4e9b\u8868\u793a\u6a21\u5f0f\u5728\u4e0d\u540c\u7684\u9886\u57df\u4e4b\u95f4\u5171\u4eab\u3002\u9886\u57df\u65e0\u5173\u8bad\u7ec3\u65e8\u5728\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u8fd9\u4e9b\u5e38\u89c1\u7684\u8868\u8fbe\u6a21\u5f0f\u3002\u4e3a\u4e86\u6784\u5efa\u9886\u57df\u65e0\u5173\u7684\u5bf9\u8bdd\u8bed\u6599\u5e93\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u53bb\u9886\u57df\u5316\u7684\u6570\u636e\u5904\u7406\u6280\u672f\uff0c\u7528\u4e8e\u53bb\u9664\u9886\u57df\u7279\u5b9a\u7684\u7279\u5f81\u3002\u901a\u8fc7\u51cf\u8f7b\u9886\u57df\u7279\u5b9a\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u5728\u53bb\u9886\u57df\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u5b66\u4e60\u4e0d\u540c\u9886\u57df\u4e2d\u7684\u5e38\u89c1\u8868\u8fbe\u6a21\u5f0f\u3002\u968f\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u9886\u57df\u9002\u5e94\u8bad\u7ec3\u5c06\u5b66\u4e60\u5230\u7684\u9886\u57df\u65e0\u5173\u7279\u5f81\u9002\u5e94\u5230\u76ee\u6807\u9886\u57df\u3002\u6211\u4eec\u5bf9\u6765\u81ea\u4e94\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u4e2d\u6587\u5bf9\u8bdd\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5728\u76ee\u6807\u9886\u57df\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u76f4\u63a5\u8bad\u7ec3\u548c\u5bf9\u6240\u6709\u4e94\u4e2a\u9886\u57df\u8bed\u6599\u5e93\u8fdb\u884c\u96c6\u4f53\u8bad\u7ec3\u76f8\u6bd4\uff0cAMD^2G \u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u5f3a\u8c03\u4e86 AMD^2G \u4f5c\u4e3a\u4f4e\u8d44\u6e90\u591a\u9886\u57df\u5bf9\u8bdd\u751f\u6210\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002\u4e0e\u6211\u4eec\u5de5\u4f5c\u76f8\u5173\u8054\u7684\u4ee3\u7801\u548c\u6570\u636e\u53ef\u5728 GitHub \u5b58\u50a8\u5e93\u4e2d\u83b7\u5f97\u3002$^{\\text 1}$</paragraph>", "author": "Yongkang Liu et.al.", "authors": "Yongkang Liu, Ercong Nie, Zheng Hua, Zifeng Ding, Daling Wang, Yifei Zhang, Hinrich Sch\u00fctze", "id": "2406.09881v1", "paper_url": "http://arxiv.org/abs/2406.09881v1", "repo": "null"}}