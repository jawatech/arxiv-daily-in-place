
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-13**|**Metamorphic Testing for Pose Estimation Systems**|Matias Duran et.al.|[2502.09460v1](http://arxiv.org/abs/2502.09460v1)|null|
|**2025-02-13**|**The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**|Danni Feng et.al.|[2502.09247v1](http://arxiv.org/abs/2502.09247v1)|null|
|**2025-02-13**|**From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**|Lukas Buess et.al.|[2502.09242v1](http://arxiv.org/abs/2502.09242v1)|null|
|**2025-02-13**|**Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**|Flavio Bertini et.al.|[2502.09218v1](http://arxiv.org/abs/2502.09218v1)|null|
|**2025-02-13**|**Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**|Sanskar Sehgal et.al.|[2502.09204v1](http://arxiv.org/abs/2502.09204v1)|null|
|**2025-02-13**|**Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**|Jin Cui et.al.|[2502.09173v1](http://arxiv.org/abs/2502.09173v1)|null|
|**2025-02-12**|**HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification**|Valentina Vadori et.al.|[2502.08754v1](http://arxiv.org/abs/2502.08754v1)|null|
|**2025-02-12**|**Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion**|Lemuel Puglisi et.al.|[2502.08560v1](http://arxiv.org/abs/2502.08560v1)|[link](https://github.com/lemuelpuglisi/brlp)|
|**2025-02-12**|**Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**|Doudou Zhou et.al.|[2502.08547v1](http://arxiv.org/abs/2502.08547v1)|null|
|**2025-02-12**|**EEG Artifact Detection and Correction with Deep Autoencoders**|David Aquilué-Llorens et.al.|[2502.08686v1](http://arxiv.org/abs/2502.08686v1)|null|
|**2025-02-12**|**SycEval: Evaluating LLM Sycophancy**|Aaron Fanous et.al.|[2502.08177v1](http://arxiv.org/abs/2502.08177v1)|null|
|**2025-02-11**|**Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?**|Hye Sun Yun et.al.|[2502.07963v1](http://arxiv.org/abs/2502.07963v1)|null|
|**2025-02-11**|**An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating**|Mohammad Ali Labbaf Khaniki et.al.|[2502.07755v1](http://arxiv.org/abs/2502.07755v1)|null|
|**2025-02-11**|**Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension**|Wenbo Gong et.al.|[2502.07752v1](http://arxiv.org/abs/2502.07752v1)|null|
|**2025-02-11**|**The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation**|Raman Dutt et.al.|[2502.07516v1](http://arxiv.org/abs/2502.07516v1)|[link](https://github.com/Raman1121/diffusion_memorization)|
|**2025-02-11**|**KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level**|Ruining Deng et.al.|[2502.07288v1](http://arxiv.org/abs/2502.07288v1)|[link](https://github.com/agaldran/kpis)|
|**2025-02-11**|**Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer**|Jiaying Lu et.al.|[2502.07158v1](http://arxiv.org/abs/2502.07158v1)|null|
|**2025-02-11**|**Explaining 3D Computed Tomography Classifiers with Counterfactuals**|Joseph Paul Cohen et.al.|[2502.07156v1](http://arxiv.org/abs/2502.07156v1)|[link](https://github.com/ieee8023/ct-counterfactuals)|
|**2025-02-10**|**Interactive Data Harmonization with LLM Agents**|Aécio Santos et.al.|[2502.07132v1](http://arxiv.org/abs/2502.07132v1)|null|
|**2025-02-10**|**Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML**|Mohammad Amir Salari et.al.|[2502.07026v1](http://arxiv.org/abs/2502.07026v1)|null|
|**2025-02-10**|**AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements**|Adriana Eufrosiana Bora et.al.|[2502.07022v1](http://arxiv.org/abs/2502.07022v1)|null|
|**2025-02-10**|**Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium**|Amin Adibi et.al.|[2502.06693v1](http://arxiv.org/abs/2502.06693v1)|null|
|**2025-02-10**|**Automatic Evaluation of Healthcare LLMs Beyond Question-Answering**|Anna Arias-Duart et.al.|[2502.06666v1](http://arxiv.org/abs/2502.06666v1)|null|
|**2025-02-10**|**Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging**|Mohammed Abdul Hafeez Khan et.al.|[2502.06632v1](http://arxiv.org/abs/2502.06632v1)|null|
|**2025-02-10**|**Illegal Waste Detection in Remote Sensing Images: A Case Study**|Federico Gibellini et.al.|[2502.06607v2](http://arxiv.org/abs/2502.06607v2)|null|
|**2025-02-10**|**FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model**|Anna Tegon et.al.|[2502.06438v1](http://arxiv.org/abs/2502.06438v1)|null|
|**2025-02-10**|**Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?**|Qingshan Hou et.al.|[2502.06289v1](http://arxiv.org/abs/2502.06289v1)|null|
|**2025-02-10**|**Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning**|Liuqing Chen et.al.|[2502.06134v1](http://arxiv.org/abs/2502.06134v1)|null|
|**2025-02-10**|**Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**|Pawel Renc et.al.|[2502.06124v1](http://arxiv.org/abs/2502.06124v1)|null|
|**2025-02-10**|**Can ChatGPT Diagnose Alzheimer's Disease?**|Quoc-Toan Nguyen et.al.|[2502.06907v1](http://arxiv.org/abs/2502.06907v1)|null|
|**2025-02-09**|**Protecting Intellectual Property of EEG-based Neural Networks with Watermarking**|Ahmed Abdelaziz et.al.|[2502.05931v1](http://arxiv.org/abs/2502.05931v1)|[link](https://github.com/Prog-Jacob/watermarking-eeg-models)|
|**2025-02-09**|**Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models**|Shiyu Teng et.al.|[2502.05879v1](http://arxiv.org/abs/2502.05879v1)|null|
|**2025-02-09**|**LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison**|Gabriele De Vito et.al.|[2502.06890v1](http://arxiv.org/abs/2502.06890v1)|null|
|**2025-02-09**|**Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)**|Lokesh Koli et.al.|[2502.07815v1](http://arxiv.org/abs/2502.07815v1)|null|
|**2025-02-09**|**WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch**|Ying Lei et.al.|[2502.05783v1](http://arxiv.org/abs/2502.05783v1)|null|
|**2025-02-09**|**RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care**|Ziqi Yang et.al.|[2502.05740v1](http://arxiv.org/abs/2502.05740v1)|null|
|**2025-02-08**|**4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis**|An Zhao et.al.|[2502.05713v1](http://arxiv.org/abs/2502.05713v1)|null|
|**2025-02-08**|**KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy**|Hyunjong Kim et.al.|[2502.05651v1](http://arxiv.org/abs/2502.05651v1)|null|
|**2025-02-08**|**ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports**|Aynur Guluzade et.al.|[2502.05638v1](http://arxiv.org/abs/2502.05638v1)|[link](https://gitlab.cc-asp.fraunhofer.de/health-open/elmtex)|
|**2025-02-08**|**Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection**|Ya Zhou et.al.|[2502.05494v1](http://arxiv.org/abs/2502.05494v1)|null|
|**2025-02-08**|**DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability**|Sibasish Dhibar et.al.|[2502.05459v1](http://arxiv.org/abs/2502.05459v1)|null|
|**2025-02-07**|**Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge**|Muhammad Imran et.al.|[2502.05330v1](http://arxiv.org/abs/2502.05330v1)|[link](https://github.com/MaxwellEng/MICCAI_CHANLLENGE24_HJL)|
|**2025-02-07**|**Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning**|Yuting He et.al.|[2502.05282v1](http://arxiv.org/abs/2502.05282v1)|null|
|**2025-02-07**|**"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**|Shihan Fu et.al.|[2502.05115v1](http://arxiv.org/abs/2502.05115v1)|null|
|**2025-02-07**|**Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**|Thierry Bossy et.al.|[2502.05087v1](http://arxiv.org/abs/2502.05087v1)|[link](https://github.com/tuneinsight/federated-llms)|
|**2025-02-07**|**MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**|Minrui Chen et.al.|[2502.04794v1](http://arxiv.org/abs/2502.04794v1)|null|
|**2025-02-06**|**MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**|Wei Fan et.al.|[2502.04515v1](http://arxiv.org/abs/2502.04515v1)|[link](https://github.com/aikunyi/MedGNN)|
|**2025-02-06**|**Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining Diagnosis and Care in Neurodegenerative Diseases**|Andrew G. Breithaupt et.al.|[2502.06842v1](http://arxiv.org/abs/2502.06842v1)|null|
|**2025-02-06**|**Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**|Khushboo Verma et.al.|[2502.04423v1](http://arxiv.org/abs/2502.04423v1)|null|
|**2025-02-06**|**Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**|Tewele W. Tareke et.al.|[2502.04083v1](http://arxiv.org/abs/2502.04083v1)|null|
|**2025-02-06**|**Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**|Ran Song et.al.|[2502.04034v1](http://arxiv.org/abs/2502.04034v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|[link](https://github.com/snowteam2023/medrag)|
|**2025-02-06**|**Transforming Multimodal Models into Action Models for Radiotherapy**|Matteo Ferrante et.al.|[2502.04408v1](http://arxiv.org/abs/2502.04408v1)|null|
|**2025-02-06**|**Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**|Bokeng Zheng et.al.|[2502.04399v1](http://arxiv.org/abs/2502.04399v1)|null|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v2](http://arxiv.org/abs/2502.04397v2)|null|
|**2025-02-06**|**A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**|Chaoyin She et.al.|[2502.03772v1](http://arxiv.org/abs/2502.03772v1)|[link](https://github.com/Asunatan/HSQformer)|
|**2025-02-05**|**Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**|Guangyao Zheng et.al.|[2502.04386v1](http://arxiv.org/abs/2502.04386v1)|[link](https://github.com/BioIntelligence-Lab/VAE-Adversarial-Debiasing)|
|**2025-02-05**|**Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**|Mehrdad Asadi et.al.|[2502.03591v1](http://arxiv.org/abs/2502.03591v1)|[link](https://github.com/the-mercury/CIHMLC)|
|**2025-02-05**|**Code Simulation as a Proxy for High-order Tasks in Large Language Models**|Emanuele La Malfa et.al.|[2502.03568v1](http://arxiv.org/abs/2502.03568v1)|null|
|**2025-02-05**|**Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning**|Jonathan Kim et.al.|[2502.04381v1](http://arxiv.org/abs/2502.04381v1)|null|
|**2025-02-05**|**Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**|Sarah Al-Shareeda et.al.|[2502.03396v1](http://arxiv.org/abs/2502.03396v1)|null|
|**2025-02-05**|**RadVLM: A Multitask Conversational Vision-Language Model for Radiology**|Nicolas Deperrois et.al.|[2502.03333v1](http://arxiv.org/abs/2502.03333v1)|null|
|**2025-02-05**|**MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**|Amin Dada et.al.|[2502.03298v1](http://arxiv.org/abs/2502.03298v1)|null|
|**2025-02-05**|**Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans**|Matthias Schwab et.al.|[2502.03272v1](http://arxiv.org/abs/2502.03272v1)|null|
|**2025-02-05**|**Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration**|Li Pan et.al.|[2502.03238v2](http://arxiv.org/abs/2502.03238v2)|[link](https://github.com/peterlipan/lmd)|
|**2025-02-05**|**Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study**|Martin Wimpff et.al.|[2502.06828v1](http://arxiv.org/abs/2502.06828v1)|null|
|**2025-02-05**|**MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**|Seonok Kim et.al.|[2502.03004v1](http://arxiv.org/abs/2502.03004v1)|null|
|**2025-02-05**|**Contrastive Token-level Explanations for Graph-based Rumour Detection**|Daniel Wai Kit Chin et.al.|[2502.04366v1](http://arxiv.org/abs/2502.04366v1)|null|
|**2025-02-05**|**AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth**|Jorge García-Torres et.al.|[2502.04365v1](http://arxiv.org/abs/2502.04365v1)|null|
|**2025-02-04**|**3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**|Weicheng Zhu et.al.|[2502.02779v1](http://arxiv.org/abs/2502.02779v1)|null|
|**2025-02-04**|**Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**|Obed Korshie Dzikunu et.al.|[2502.02756v1](http://arxiv.org/abs/2502.02756v1)|[link](https://github.com/obeddzik/pca_segment)|
|**2025-02-04**|**Diffusion Instruction Tuning**|Chen Jin et.al.|[2502.06814v1](http://arxiv.org/abs/2502.06814v1)|null|
|**2025-02-04**|**MedRAX: Medical Reasoning Agent for Chest X-ray**|Adibvafa Fallahpour et.al.|[2502.02673v1](http://arxiv.org/abs/2502.02673v1)|[link](https://github.com/bowang-lab/medrax)|
|**2025-02-04**|**Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription**|Mahdi Alkaeed et.al.|[2502.04356v1](http://arxiv.org/abs/2502.04356v1)|null|
|**2025-02-04**|**Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents**|Shayan Kiyani et.al.|[2502.02561v1](http://arxiv.org/abs/2502.02561v1)|null|
|**2025-02-04**|**CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models**|Amy Rafferty et.al.|[2502.05214v1](http://arxiv.org/abs/2502.05214v1)|null|
|**2025-02-04**|**A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation**|Edward Ellis et.al.|[2502.02489v1](http://arxiv.org/abs/2502.02489v1)|null|
|**2025-02-04**|**Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment**|Yaling Shen et.al.|[2502.02438v1](http://arxiv.org/abs/2502.02438v1)|null|
|**2025-02-04**|**Test Time Training for 4D Medical Image Interpolation**|Qikang Zhang et.al.|[2502.02341v1](http://arxiv.org/abs/2502.02341v1)|[link](https://github.com/chaostheproducer/ttt4d)|
|**2025-02-04**|**Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation**|Atharva Mangeshkumar Agrawal et.al.|[2502.02249v1](http://arxiv.org/abs/2502.02249v1)|null|
|**2025-02-04**|**Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review**|F. Xavier Gaya-Morey et.al.|[2502.02618v1](http://arxiv.org/abs/2502.02618v1)|null|
|**2025-02-04**|**Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care**|Yuxiao Cheng et.al.|[2502.02109v1](http://arxiv.org/abs/2502.02109v1)|null|
|**2025-02-04**|**JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment**|Yehan Yan et.al.|[2502.04345v1](http://arxiv.org/abs/2502.04345v1)|null|
|**2025-02-03**|**An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data**|Jiazi Tian et.al.|[2502.01789v1](http://arxiv.org/abs/2502.01789v1)|null|
|**2025-02-03**|**Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis**|Chacha Chen et.al.|[2502.03482v1](http://arxiv.org/abs/2502.03482v1)|null|
|**2025-02-03**|**Improving Transformer World Models for Data-Efficient RL**|Antoine Dedieu et.al.|[2502.01591v1](http://arxiv.org/abs/2502.01591v1)|null|
|**2025-02-03**|**Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data**|Zhi Zhang et.al.|[2502.01377v1](http://arxiv.org/abs/2502.01377v1)|null|
|**2025-02-03**|**OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology**|Chengfeng Zhou et.al.|[2502.01243v1](http://arxiv.org/abs/2502.01243v1)|null|
|**2025-02-03**|**MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks**|Alejandro Guerra-Manzanares et.al.|[2502.01158v1](http://arxiv.org/abs/2502.01158v1)|null|
|**2025-02-03**|**Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations**|Qian Chen et.al.|[2502.01141v1](http://arxiv.org/abs/2502.01141v1)|null|
|**2025-02-03**|**Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings**|Mithun Saha et.al.|[2502.01108v1](http://arxiv.org/abs/2502.01108v1)|null|
|**2025-02-03**|**Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection**|Yeyubei Zhang et.al.|[2502.04342v1](http://arxiv.org/abs/2502.04342v1)|null|
|**2025-02-02**|**Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model**|Hadas Ben-Atya et.al.|[2502.01691v1](http://arxiv.org/abs/2502.01691v1)|null|
|**2025-02-02**|**Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment**|Si-Ioi Ng et.al.|[2502.01685v1](http://arxiv.org/abs/2502.01685v1)|null|
|**2025-02-02**|**Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images**|Shengtian Sang et.al.|[2502.00712v1](http://arxiv.org/abs/2502.00712v1)|null|
|**2025-02-02**|**TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion**|Linglong Wu et.al.|[2502.00695v1](http://arxiv.org/abs/2502.00695v1)|null|
|**2025-02-02**|**Safety at Scale: A Comprehensive Survey of Large Model Safety**|Xingjun Ma et.al.|[2502.05206v2](http://arxiv.org/abs/2502.05206v2)|null|
|**2025-02-02**|**Enhanced Convolutional Neural Networks for Improved Image Classification**|Xiaoran Yang et.al.|[2502.00663v1](http://arxiv.org/abs/2502.00663v1)|null|
|**2025-02-02**|**Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective**|Yujin Oh et.al.|[2502.00619v1](http://arxiv.org/abs/2502.00619v1)|null|
|**2025-02-01**|**Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions**|Samiran Dey et.al.|[2502.00568v3](http://arxiv.org/abs/2502.00568v3)|[link](https://github.com/Samiran-Dey/PathoGen)|

#### Abstracts
##### **Metamorphic Testing for Pose Estimation Systems**
2502.09460v1 by Matias Duran, Thomas Laurent, Ellen Rushe, Anthony Ventresque

Pose estimation systems are used in a variety of fields, from sports
analytics to livestock care. Given their potential impact, it is paramount to
systematically test their behaviour and potential for failure. This is a
complex task due to the oracle problem and the high cost of manual labelling
necessary to build ground truth keypoints. This problem is exacerbated by the
fact that different applications require systems to focus on different subjects
(e.g., human versus animal) or landmarks (e.g., only extremities versus whole
body and face), which makes labelled test data rarely reusable. To combat these
problems we propose MET-POSE, a metamorphic testing framework for pose
estimation systems that bypasses the need for manual annotation while assessing
the performance of these systems under different circumstances. MET-POSE thus
allows users of pose estimation systems to assess the systems in conditions
that more closely relate to their application without having to label an ad-hoc
test dataset or rely only on available datasets, which may not be adapted to
their application domain. While we define MET-POSE in general terms, we also
present a non-exhaustive list of metamorphic rules that represent common
challenges in computer vision applications, as well as a specific way to
evaluate these rules. We then experimentally show the effectiveness of MET-POSE
by applying it to Mediapipe Holistic, a state of the art human pose estimation
system, with the FLIC and PHOENIX datasets. With these experiments, we outline
numerous ways in which the outputs of MET-POSE can uncover faults in pose
estimation systems at a similar or higher rate than classic testing using hand
labelled data, and show that users can tailor the rule set they use to the
faults and level of accuracy relevant to their application.

摘要：姿勢估計系統應用於各種領域，從運動分析到牲畜照護。鑑於其潛在影響，系統性地測試其行為和故障潛力至關重要。由於預言機問題以及建立地面實況關鍵點所需的手動標記成本高，這是一項複雜的任務。這個問題因不同的應用需要系統專注於不同的主體（例如，人類對動物）或地標（例如，只有四肢對全身和臉部）而加劇，這使得標記的測試數據很少可以重複使用。為了解決這些問題，我們提出了 MET-POSE，這是一個姿勢估計系統的變形測試框架，在評估這些系統在不同情況下的性能時，可以繞過手動註解的需要。因此，MET-POSE 允許姿勢估計系統的使用者在更接近其應用程式的條件下評估系統，而無需標記臨時測試數據集或僅依賴可用數據集，這些數據集可能不適合其應用領域。雖然我們以一般術語定義 MET-POSE，但我們也提供了一個非詳盡的變形規則列表，這些規則代表了電腦視覺應用中的常見挑戰，以及評估這些規則的具體方法。然後，我們通過將 MET-POSE 應用於 Mediapipe Holistic（一種先進的人類姿勢估計系統），並使用 FLIC 和 PHOENIX 數據集，以實驗方式展示 MET-POSE 的有效性。通過這些實驗，我們概述了 MET-POSE 的輸出可以揭示姿勢估計系統中故障的許多方法，其速度與使用手動標記數據的傳統測試類似或更高，並表明使用者可以根據其應用程式相關的故障和準確度等級來調整他們使用的規則集。

##### **The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**
2502.09247v1 by Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing

Joint entity-relation extraction is a critical task in transforming
unstructured or semi-structured text into triplets, facilitating the
construction of large-scale knowledge graphs, and supporting various downstream
applications. Despite its importance, research on Chinese text, particularly
with complex semantics in specialized domains like medicine, remains limited.
To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions
dataset designed to capture the intricacies of medical text. Leveraging the
strengths of attention mechanisms in capturing long-range dependencies, we
propose the SEA module, which enhances the extraction of complex contextual
semantic information, thereby improving entity recognition and relation
extraction. Additionally, to address the inefficiencies of existing methods in
facilitating information exchange between entity recognition and relation
extraction, we present an interactive fusion representation module. This module
employs Cross Attention for bidirectional information exchange between the
tasks and further refines feature extraction through BiLSTM. Experimental
results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that
our model exhibits strong generalization capabilities. On the CH-DDI dataset,
our model achieves an F1-score of 96.73% for entity recognition and 78.43% for
relation extraction. On the CoNLL04 dataset, it attains an entity recognition
precision of 89.54% and a relation extraction accuracy of 71.64%.

摘要：聯合實體關係抽取是將非結構化或半結構化文字轉換為三元組的重要任務，有助於建構大規模知識圖譜，並支援各種下游應用程式。儘管其重要性，但針對中文文本的研究，特別是醫學等專業領域中具有複雜語義的研究仍十分有限。為了解決這個差距，我們引入了 CH-DDI，一個中文藥物-藥物交互作用資料集，旨在擷取醫學文本的複雜性。利用注意力機制在擷取長程依賴關係方面的優勢，我們提出了 SEA 模組，增強了複雜脈絡語義資訊的抽取，從而改進了實體辨識和關係抽取。此外，為了解決現有方法在促進實體辨識和關係抽取之間資訊交換方面的低效率問題，我們提出了互動式融合表示模組。此模組採用交叉注意力，在任務之間進行雙向資訊交換，並透過 BiLSTM 進一步精煉特徵抽取。在我們的 CH-DDI 資料集和公開的 CoNLL04 資料集上的實驗結果表明，我們的模型展現出強大的泛化能力。在 CH-DDI 資料集上，我們的模型在實體辨識方面達到了 96.73% 的 F1 分數，在關係抽取方面達到了 78.43% 的 F1 分數。在 CoNLL04 資料集上，它在實體辨識方面達到了 89.54% 的準確度，在關係抽取方面達到了 71.64% 的準確度。

##### **From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**
2502.09242v1 by Lukas Buess, Matthias Keicher, Nassir Navab, Andreas Maier, Soroosh Tayebi Arasteh

Generative artificial intelligence (AI) models, such as diffusion models and
OpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy
and automating clinical workflows. The field has advanced rapidly, evolving
from text-only large language models for tasks such as clinical documentation
and decision support to multimodal AI systems capable of integrating diverse
data modalities, including imaging, text, and structured data, within a single
model. The diverse landscape of these technologies, along with rising interest,
highlights the need for a comprehensive review of their applications and
potential. This scoping review explores the evolution of multimodal AI,
highlighting its methods, applications, datasets, and evaluation in clinical
settings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,
IEEE Xplore, and Web of Science, prioritizing recent studies published up to
the end of 2024. After rigorous screening, 144 papers were included, revealing
key trends and challenges in this dynamic field. Our findings underscore a
shift from unimodal to multimodal approaches, driving innovations in diagnostic
support, medical report generation, drug discovery, and conversational AI.
However, critical challenges remain, including the integration of heterogeneous
data types, improving model interpretability, addressing ethical concerns, and
validating AI systems in real-world clinical settings. This review summarizes
the current state of the art, identifies critical gaps, and provides insights
to guide the development of scalable, trustworthy, and clinically impactful
multimodal AI solutions in healthcare.

摘要：生成式人工智能 (AI) 模型，例如扩散模型和 OpenAI 的 ChatGPT，通过提高诊断准确性和自动化临床工作流程，正在改变医学领域。该领域已迅速发展，从用于临床文件编制和决策支持等任务的纯文本大型语言模型，发展到能够在单个模型中整合包括影像、文本和结构化数据在内的多种数据方式的多模态 AI 系统。这些技术的多样化格局以及日益增长的兴趣，凸显了全面审查其应用和潜力的必要性。本范围审查探讨了多模态 AI 的演变，重点介绍了其方法、应用、数据集和在临床环境中的评估。遵循 PRISMA-ScR 指南，我们系统地查询了 PubMed、IEEE Xplore 和 Web of Science，优先考虑截至 2024 年底发表的最新研究。经过严格筛选，纳入了 144 篇论文，揭示了这一充满活力的领域的趋势和挑战。我们的研究结果强调了从单模态方法向多模态方法的转变，推动了诊断支持、医疗报告生成、药物发现和会话式 AI 的创新。然而，关键挑战仍然存在，包括异构数据类型的整合、提高模型可解释性、解决伦理问题以及在现实世界的临床环境中验证 AI 系统。本综述总结了当前的最新技术，确定了关键差距，并提供了见解，以指导在医疗保健领域开发可扩展、可信赖且具有临床影响力的多模态 AI 解决方案。

##### **Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**
2502.09218v1 by Flavio Bertini, Alessandro Dal Palù, Federica Zaglio, Francesco Fabiano, Andrea Formisano

This paper presents a complete explainable system that interprets a set of
data, abstracts the underlying features and describes them in a natural
language of choice. The system relies on two crucial stages: (i) identifying
emerging properties from data and transforming them into abstract concepts, and
(ii) converting these concepts into natural language. Despite the impressive
natural language generation capabilities demonstrated by Large Language Models,
their statistical nature and the intricacy of their internal mechanism still
force us to employ these techniques as black boxes, forgoing trustworthiness.
Developing an explainable pipeline for data interpretation would allow
facilitating its use in safety-critical environments like processing medical
information and allowing non-experts and visually impaired people to access
narrated information. To this end, we believe that the fields of knowledge
representation and automated reasoning research could present a valid
alternative. Expanding on prior research that tackled the first stage (i), we
focus on the second stage, named Concept2Text. Being explainable, data
translation is easily modeled through logic-based rules, once again emphasizing
the role of declarative programming in achieving AI explainability. This paper
explores a Prolog/CLP-based rewriting system to interpret concepts-articulated
in terms of classes and relations, plus common knowledge-derived from a generic
ontology, generating natural language text. Its main features include
hierarchical tree rewritings, modular multilingual generation, support for
equivalent variants across semantic, grammar, and lexical levels, and a
transparent rule-based system. We outline the architecture and demonstrate its
flexibility through some examples capable of generating numerous diverse and
equivalent rewritings based on the input concept.

摘要：<paragraph>這篇論文提出了一個完整的可解釋系統，它可以解釋一組資料，抽象出基礎特徵，並以選擇的自然語言描述它們。系統依賴兩個關鍵階段：(i) 從資料中識別新興屬性，並將它們轉換為抽象概念，以及 (ii) 將這些概念轉換為自然語言。儘管大型語言模型展示了令人印象深刻的自然語言生成能力，但它們的統計性質和內部機制的複雜性仍然迫使我們將這些技術用作黑盒子，放棄可信度。開發一個可解釋的資料解釋管道將有助於促進在安全關鍵環境中使用它，例如處理醫療資訊，並允許非專家和視障人士存取敘述資訊。為此，我們相信知識表示和自動推理研究領域可以提出一個有效的替代方案。在擴展解決第一階段 (i) 的先前研究的基礎上，我們專注於第二階段，稱為 Concept2Text。由於具有可解釋性，資料翻譯很容易透過基於邏輯的規則建模，再次強調宣告式程式設計在實現 AI 可解釋性中的作用。本文探討了一個基於 Prolog/CLP 的重寫系統，以解釋概念，這些概念以類別和關係的形式表達，再加上從通用本体衍生的常識，產生自然語言文字。它的主要特點包括階層樹重寫、模組化多語言生成、支援語義、語法和詞彙層面的等效變體，以及一個透明的基於規則的系統。我們概述了架構，並透過一些範例展示了它的靈活性，這些範例能夠根據輸入概念生成許多不同的等效重寫。</paragraph>

##### **Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**
2502.09204v1 by Sanskar Sehgal, Yanhong A. Liu

Legal cases require careful logical reasoning following the laws, whereas
interactions with non- technical users must be in natural language. As an
application combining logical reasoning using Prolog and natural language
processing using large language models (LLMs), this paper presents a novel
approach and system, LogicLease, to automate the analysis of landlord-tenant
legal cases in the state of New York. LogicLease determines compliance with
relevant legal requirements by analyzing case descriptions and citing all
relevant laws. It leverages LLMs for information extraction and Prolog for
legal reasoning. By separating information extraction from legal reasoning,
LogicLease achieves greater transparency and control over the legal logic
applied to each case. We evaluate the accuracy, efficiency, and robustness of
LogicLease through a series of tests, achieving 100% accuracy and an average
processing time of 2.57 seconds. LogicLease presents advantages over
state-of-the-art LLM- based legal analysis systems by providing clear,
step-by-step reasoning, citing specific laws, and distinguishing itself by its
ability to avoid hallucinations - a common issue in LLMs.

摘要：法律案件需要遵循法律进行谨慎的逻辑推理，而与非技术用户的互动必须使用自然语言。作为结合使用 Prolog 进行逻辑推理和使用大型语言模型 (LLM) 进行自然语言处理的应用程序，本文提出了一种新颖的方法和系统 LogicLease，以自动分析纽约州的房东与租户法律案件。LogicLease 通过分析案例描述并引用所有相关法律来确定是否符合相关法律要求。它利用 LLM 进行信息提取，并利用 Prolog 进行法律推理。通过将信息提取与法律推理分开，LogicLease 实现了对应用于每个案例的法律逻辑的更高透明度和控制力。我们通过一系列测试评估了 LogicLease 的准确性、效率和鲁棒性，实现了 100% 的准确性和 2.57 秒的平均处理时间。LogicLease 通过提供清晰、分步的推理，引用具体法律，并以其避免幻觉的能力而区别于最先进的基于 LLM 的法律分析系统，从而显示出优势——这是 LLM 中的常见问题。

##### **Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**
2502.09173v1 by Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott

In remote healthcare monitoring, time series representation learning reveals
critical patient behavior patterns from high-frequency data. This study
analyzes home activity data from individuals living with dementia by proposing
a two-stage, self-supervised learning approach tailored to uncover low-rank
structures. The first stage converts time-series activities into text sequences
encoded by a pre-trained language model, providing a rich, high-dimensional
latent state space using a PageRank-based method. This PageRank vector captures
latent state transitions, effectively compressing complex behaviour data into a
succinct form that enhances interpretability. This low-rank representation not
only enhances model interpretability but also facilitates clustering and
transition analysis, revealing key behavioral patterns correlated with
clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the
framework's potential in supporting cognitive status prediction, personalized
care interventions, and large-scale health monitoring.

摘要：在遠程醫療監控中，時間序列表示學習揭示了高頻率數據中的關鍵患者行為模式。本研究通過提出一個兩階段、自我監督的學習方法來分析痴呆症患者的家庭活動數據，該方法專門用於發現低秩結構。第一階段將時間序列活動轉換為由預訓練語言模型編碼的文本序列，使用基於 PageRank 的方法提供了一個豐富、高維的潛在狀態空間。此 PageRank 向量捕獲潛在狀態轉換，有效地將複雜的行為數據壓縮成簡潔的形式，從而增強了解力。此低秩表示不僅增強了模型的可解釋性，還促進了聚類和轉換分析，揭示了與臨床指標（例如 MMSE 和 ADAS-COG 分數）相關的關鍵行為模式。我們的研究結果證明了該框架在支持認知狀態預測、個性化護理干預和大型健康監控方面的潛力。

##### **HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification**
2502.08754v1 by Valentina Vadori, Jean-Marie Graïc, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan

Precise segmentation and classification of cell instances are vital for
analyzing the tissue microenvironment in histology images, supporting medical
diagnosis, prognosis, treatment planning, and studies of brain
cytoarchitecture. However, the creation of high-quality annotated datasets for
training remains a major challenge. This study introduces a novel single-stage
approach (HistoSmith) for generating image-label pairs to augment histology
datasets. Unlike state-of-the-art methods that utilize diffusion models with
separate components for label and image generation, our approach employs a
latent diffusion model to learn the joint distribution of cellular layouts,
classification masks, and histology images. This model enables tailored data
generation by conditioning on user-defined parameters such as cell types,
quantities, and tissue types. Trained on the Conic H&E histopathology dataset
and the Nissl-stained CytoDArk0 dataset, the model generates realistic and
diverse labeled samples. Experimental results demonstrate improvements in cell
instance segmentation and classification, particularly for underrepresented
cell types like neutrophils in the Conic dataset. These findings underscore the
potential of our approach to address data scarcity challenges.

摘要：精確的細胞實例分割和分類對於分析組織學影像中的組織微環境、支援醫療診斷、預後、治療規劃和腦部細胞結構研究至關重要。然而，建立用於訓練的高品質標註資料集仍然是一項重大挑戰。本研究提出了一種新穎的單階段方法 (HistoSmith)，用於產生影像標籤對，以擴充組織學資料集。與利用擴散模型並將標籤和影像產生分開的組成部分的現有技術不同，我們的做法採用潛在擴散模型來學習細胞佈局、分類遮罩和組織學影像的聯合分佈。此模型能透過調整使用者定義的參數（例如細胞類型、數量和組織類型）來進行客製化資料產生。在 Conic H&E 細胞病理學資料集和 Nissl 染色的 CytoDArk0 資料集上訓練後，此模型產生逼真且多樣化的標籤樣本。實驗結果顯示細胞實例分割和分類有顯著進步，特別是對於 Conic 資料集中代表性不足的細胞類型，例如中性球。這些發現強調了我們的方法在解決資料稀少性挑戰方面的潛力。

##### **Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion**
2502.08560v1 by Lemuel Puglisi, Daniel C. Alexander, Daniele Ravì

The growing availability of longitudinal Magnetic Resonance Imaging (MRI)
datasets has facilitated Artificial Intelligence (AI)-driven modeling of
disease progression, making it possible to predict future medical scans for
individual patients. However, despite significant advancements in AI, current
methods continue to face challenges including achieving patient-specific
individualization, ensuring spatiotemporal consistency, efficiently utilizing
longitudinal data, and managing the substantial memory demands of 3D scans. To
address these challenges, we propose Brain Latent Progression (BrLP), a novel
spatiotemporal model designed to predict individual-level disease progression
in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates
in a small latent space, mitigating the computational challenges posed by
high-dimensional imaging data; (ii) it explicitly integrates subject metadata
to enhance the individualization of predictions; (iii) it incorporates prior
knowledge of disease dynamics through an auxiliary model, facilitating the
integration of longitudinal data; and (iv) it introduces the Latent Average
Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in
the predicted progression at inference time and (b) allows us to derive a
measure of the uncertainty for the prediction. We train and evaluate BrLP on
11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its
generalizability on an external test set comprising 2,257 MRIs from 962
subjects. Our experiments compare BrLP-generated MRI scans with real follow-up
MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The
code is publicly available at: https://github.com/LemuelPuglisi/BrLP.

摘要：隨著縱向磁共振影像 (MRI) 資料集的日益普及，已促進人工智慧 (AI) 驅動的疾病進程建模，讓預測個別患者的未來醫學掃描成為可能。然而，儘管 AI 有顯著進展，目前的技術仍面臨挑戰，包括實現患者特定的個別化、確保時空一致性、有效利用縱向資料，以及管理 3D 掃描的大量記憶體需求。為了應對這些挑戰，我們提出腦潛在進程 (BrLP)，這是一種新穎的時空模型，旨在預測 3D 腦部 MRI 中的個人層級疾病進程。BrLP 的主要貢獻有四個：(i) 它在一個小的潛在空間中運作，減輕了高維度影像資料帶來的計算挑戰；(ii) 它明確整合受試者的元資料，以增強預測的個別化；(iii) 它透過輔助模型納入疾病動態的先驗知識，促進縱向資料的整合；(iv) 它引入了潛在平均穩定化 (LAS) 演算法，該演算法 (a) 在推論時強制預測進程中的時空一致性，(b) 讓我們能夠推導預測的不確定性測量。我們對來自 2,805 名受試者的 11,730 個 T1 加權 (T1w) 腦部 MRI 進行 BrLP 訓練和評估，並在包含來自 962 名受試者的 2,257 個 MRI 的外部測試集上驗證其概括性。我們的實驗將 BrLP 生成的 MRI 掃描與實際追蹤 MRI 進行比較，與現有方法相比，展示了最先進的準確性。程式碼已公開於：https://github.com/LemuelPuglisi/BrLP。

##### **Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**
2502.08547v1 by Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai

The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.

摘要：電子健康紀錄的採用擴大了在臨床照護和研究中利用資料驅動演算法的機會。在有效進行多機構電子健康紀錄研究時，一個主要的瓶頸是系統間資料異質性，其中有許多代碼在機構間不存在或表示不同的臨床概念。資料隱私的需求進一步限制了納入多機構患者層級資料的可行性，而這些資料對於研究患者亞群之間的相似性和差異性是必要的。為了應對這些挑戰，我們開發了 GAME 演算法。GAME 已在 7 個機構和 2 種語言中進行測試和驗證，它整合了多個層級的資料：(1) 在機構層級，使用知識圖表來建立代碼和現有知識來源之間的關係，為標準代碼及其彼此之間的關係提供醫療背景；(2) 在機構之間，利用語言模型來確定機構特定代碼與已建立的標準代碼之間的關係；(3) 使用圖形注意網路量化代碼之間關係的強度。使用遷移和聯合學習建立聯合訓練的嵌入，以保護資料隱私。在本研究中，我們展示了 GAME 在選擇相關特徵作為 AI 驅動演算法輸入時的適用性，適用於各種情況，例如心臟衰竭、類風濕性關節炎。然後，我們重點介紹了 GAME 和諧化多機構電子健康紀錄資料在阿茲海默症疾病結果和精神疾病患者自殺風險研究中的應用，而無需在個別機構之外共享患者層級資料。

##### **EEG Artifact Detection and Correction with Deep Autoencoders**
2502.08686v1 by David Aquilué-Llorens, Aureli Soria-Frisch

EEG signals convey important information about brain activity both in healthy
and pathological conditions. However, they are inherently noisy, which poses
significant challenges for accurate analysis and interpretation. Traditional
EEG artifact removal methods, while effective, often require extensive expert
intervention. This study presents LSTEEG, a novel LSTM-based autoencoder
designed for the detection and correction of artifacts in EEG signals.
Leveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear
dependencies in sequential EEG data. LSTEEG demonstrates superior performance
in both artifact detection and correction tasks compared to other
state-of-the-art convolutional autoencoders. Our methodology enhances the
interpretability and utility of the autoencoder's latent space, enabling
data-driven automated artefact removal in EEG its application in downstream
tasks. This research advances the field of efficient and accurate multi-channel
EEG preprocessing, and promotes the implementation and usage of automated EEG
analysis pipelines for brain health applications.

摘要：腦電圖訊號傳達了關於大腦活動的重要資訊，無論是在健康或病理狀況下。然而，它們本質上是有雜訊的，這對準確的分析和解釋構成了重大的挑戰。傳統的腦電圖人工製品移除方法雖然有效，但通常需要大量的專家介入。本研究提出 LSTEEG，一種新穎的基於 LSTM 的自動編碼器，用於偵測和校正腦電圖訊號中的人工製品。利用深度學習，特別是 LSTM 層，LSTEEG 捕捉序列腦電圖資料中的非線性依賴性。與其他最先進的卷積自動編碼器相比，LSTEEG 在人工製品偵測和校正任務中都展現出優異的效能。我們的做法增強了自動編碼器潛在空間的可解釋性和實用性，讓資料驅動的自動人工製品移除得以應用於腦電圖的下游任務。這項研究推動了高效且準確的多通道腦電圖前處理領域，並促進了自動腦電圖分析管線在腦部健康應用中的實作和使用。

##### **SycEval: Evaluating LLM Sycophancy**
2502.08177v1 by Aaron Fanous, Jacob Goldberg, Ank A. Agarwal, Joanna Lin, Anson Zhou, Roxana Daneshjou, Sanmi Koyejo

Large language models (LLMs) are increasingly applied in educational,
clinical, and professional settings, but their tendency for sycophancy --
prioritizing user agreement over independent reasoning -- poses risks to
reliability. This study introduces a framework to evaluate sycophantic behavior
in ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and
MedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%
of cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the
lowest (56.71%). Progressive sycophancy, leading to correct answers, occurred
in 43.52% of cases, while regressive sycophancy, leading to incorrect answers,
was observed in 14.66%. Preemptive rebuttals demonstrated significantly higher
sycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,
$p<0.001$), particularly in computational tasks, where regressive sycophancy
increased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).
Simple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while
citation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,
$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:
[77.2%, 79.8%]) regardless of context or model. These findings emphasize the
risks and opportunities of deploying LLMs in structured and dynamic domains,
offering insights into prompt programming and model optimization for safer AI
applications.

摘要：大型語言模型（LLM）日益應用於教育、臨床和專業領域，但它們趨於趨炎附勢——優先考慮用戶同意而非獨立推理——對可靠性構成風險。本研究引入了一個框架來評估 ChatGPT-4o、Claude-Sonnet 和 Gemini-1.5-Pro 中的趨炎附勢行為，涉及 AMPS（數學）和 MedQuad（醫療建議）數據集。在 58.19% 的案例中觀察到了趨炎附勢行為，其中 Gemini 表現出最高比率（62.47%），而 ChatGPT 最低（56.71%）。導致正確答案的漸進式趨炎附勢發生在 43.52% 的案例中，而導致不正確答案的退步式趨炎附勢則在 14.66% 的案例中被觀察到。先發制人的反駁表現出顯著高於上下文反駁的趨炎附勢率（61.75% 對 56.52%，Z=5.87，p<0.001），特別是在計算任務中，其中退步式趨炎附勢顯著增加（先發制人：8.13%，上下文：3.54%，p<0.001）。簡單的反駁最大化了漸進式趨炎附勢（Z=6.59，p<0.001），而基於引用的反駁表現出最高的退步式比率（Z=6.59，p<0.001）。趨炎附勢行為表現出很高的持續性（78.5%，95% CI：[77.2%，79.8%]），無論上下文或模型如何。這些發現強調了在結構化和動態領域部署 LLM 的風險和機遇，為更安全的 AI 應用提供了提示編程和模型優化的見解。

##### **Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?**
2502.07963v1 by Hye Sun Yun, Karen Y. C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

Medical research faces well-documented challenges in translating novel
treatments into clinical practice. Publishing incentives encourage researchers
to present "positive" findings, even when empirical results are equivocal.
Consequently, it is well-documented that authors often spin study results,
especially in article abstracts. Such spin can influence clinician
interpretation of evidence and may affect patient care decisions. In this
study, we ask whether the interpretation of trial results offered by Large
Language Models (LLMs) is similarly affected by spin. This is important since
LLMs are increasingly being used to trawl through and synthesize published
medical evidence. We evaluated 22 LLMs and found that they are across the board
more susceptible to spin than humans. They might also propagate spin into their
outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into
plain language summaries that they generate. We also find, however, that LLMs
are generally capable of recognizing spin, and can be prompted in a way to
mitigate spin's impact on LLM outputs.

摘要：醫學研究在將新穎療法轉化為臨床實務上，面臨著有據可查的挑戰。發表誘因鼓勵研究人員呈現「正向」的發現，即使經驗結果模稜兩可。因此，有據可查的是，作者經常扭曲研究結果，特別是在文章摘要中。此類扭曲可能會影響臨床醫師對證據的詮釋，並可能影響病患照護決策。在本研究中，我們探討大型語言模型 (LLM) 提供的試驗結果詮釋是否也受到扭曲影響。由於 LLM 正越來越常被用於爬梳和綜合已發表的醫學證據，因此這點非常重要。我們評估了 22 個 LLM，發現它們普遍比人類更容易受到扭曲影響。它們也可能將扭曲傳播到其輸出中：例如，我們發現 LLM 會將扭曲隱含納入其產生的白話文摘要中。然而，我們也發現 LLM 通常有能力辨認扭曲，而且可以透過提示的方式減輕扭曲對 LLM 輸出的影響。

##### **An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating**
2502.07755v1 by Mohammad Ali Labbaf Khaniki, Sahabeh Saadati, Mohammad Manthouri

This paper presents a novel Natural Language Processing (NLP) framework for
enhancing medical diagnosis through the integration of advanced techniques in
data augmentation, feature extraction, and classification. The proposed
approach employs back-translation to generate diverse paraphrased datasets,
improving robustness and mitigating overfitting in classification tasks.
Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with
Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained
contextual and positional relationships, dynamically adjusting the influence of
positional information based on semantic context to produce high-quality text
embeddings. For classification, an Attention-Based Feedforward Neural Network
(ABFNN) is utilized, effectively focusing on the most relevant features to
improve decision-making accuracy. Applied to the classification of symptoms,
clinical notes, and other medical texts, this architecture demonstrates its
ability to address the complexities of medical data. The combination of data
augmentation, contextual embedding generation, and advanced classification
mechanisms offers a robust and accurate diagnostic tool, with potential
applications in automated medical diagnosis and clinical decision support. This
method demonstrates the effectiveness of the proposed NLP framework for medical
diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of
99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only
underscore the model's robust performance in classifying medical texts with
exceptional precision and reliability but also highlight its superiority over
existing methods, making it a highly promising tool for automated diagnostic
systems.

摘要：本文提出了一個創新的自然語言處理 (NLP) 框架，透過整合資料擴充、特徵萃取和分類的進階技術來增強醫療診斷。所提出的方法採用反向翻譯來產生多樣化的同義改寫資料集，提升穩健性並減輕分類任務中的過度擬合。透過利用具有動態脈絡位置閘控 (DCPG) 的解碼增強 BERT 與去糾纏注意力 (DeBERTa)，這個模型捕捉細緻的脈絡和位置關係，根據語意脈絡動態調整位置資訊的影響，以產生高品質的文字嵌入。在分類方面，利用基於注意力的前饋神經網路 (ABFNN)，有效地關注最相關的特徵，以提高決策準確度。應用於症狀、臨床筆記和其他醫療文本的分類，此架構證明了其處理醫療資料複雜性的能力。資料擴充、脈絡嵌入產生和進階分類機制的結合提供了一個穩健且準確的診斷工具，在自動化醫療診斷和臨床決策支援中具有潛在應用。此方法證明了所提出的 NLP 框架在醫療診斷中的有效性，以 99.78% 的準確度、99.72% 的召回率、99.79% 的精確度和 99.75% 的 F1 分數，取得了顯著的成果。這些指標不僅強調了模型在分類醫療文本時具有卓越的精確度和可靠性，也突顯了它優於現有方法的優越性，使其成為自動化診斷系統中極具前景的工具。

##### **Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension**
2502.07752v1 by Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds

Designing efficient optimizers for large language models (LLMs) with
low-memory requirements and fast convergence is an important and challenging
problem. This paper makes a step towards the systematic design of such
optimizers through the lens of structured Fisher information matrix (FIM)
approximation. We show that many state-of-the-art efficient optimizers can be
viewed as solutions to FIM approximation (under the Frobenius norm) with
specific structural assumptions. Building on these insights, we propose two
design recommendations of practical efficient optimizers for LLMs, involving
the careful selection of structural assumptions to balance generality and
efficiency, and enhancing memory efficiency of optimizers with general
structures through a novel low-rank extension framework. We demonstrate how to
use each design approach by deriving new memory-efficient optimizers: Row and
Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation
(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the
effectiveness, showing faster and better convergence than existing
memory-efficient baselines and Adam with little memory overhead. Notably, Alice
achieves better than 2x faster convergence over Adam, while RACS delivers
strong performance on the 1B model with SGD-like memory.

摘要：設計具有低記憶體需求和快速收斂的大型語言模型 (LLM) 的高效最佳化器是一個重要且具有挑戰性的問題。本文透過結構化 Fisher 資訊矩陣 (FIM) 近似的角度，朝向此類最佳化器的系統化設計邁進一步。我們展示了許多最先進的高效最佳化器可以被視為 FIM 近似（在 Frobenius 範數下）的解，並具有特定的結構假設。基於這些見解，我們提出了 LLM 的兩個實用高效最佳化器設計建議，包括仔細選擇結構假設以平衡通用性和效率，並透過新穎的低秩延伸架構來增強具有通用結構的最佳化器的記憶體效率。我們展示了如何透過推導新的記憶體高效最佳化器來使用每種設計方法：列和欄縮放 SGD (RACS) 和自適應低維子空間估計 (Alice)。在 LLaMA 預訓練（高達 1B 參數）上的實驗驗證了其有效性，顯示比現有的記憶體高效基線和 Adam 更快且更好的收斂，且記憶體開銷很小。值得注意的是，Alice 比 Adam 快 2 倍以上，而 RACS 則在 1B 模型上提供類似 SGD 記憶體的強勁效能。

##### **The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation**
2502.07516v1 by Raman Dutt

Generative models, particularly text-to-image (T2I) diffusion models, play a
crucial role in medical image analysis. However, these models are prone to
training data memorization, posing significant risks to patient privacy.
Synthetic chest X-ray generation is one of the most common applications in
medical image analysis with the MIMIC-CXR dataset serving as the primary data
repository for this task. This study adopts a data-driven approach and presents
the first systematic attempt to identify prompts and text tokens in MIMIC-CXR
that contribute the most to training data memorization. Our analysis reveals an
unexpected finding: prompts containing traces of de-identification procedures
are among the most memorized, with de-identification markers contributing the
most. Furthermore, we also find existing inference-time memorization mitigation
strategies are ineffective and fail to sufficiently reduce the model's reliance
on memorized text tokens highlighting a broader issue in T2I synthesis with
MIMIC-CXR. On this front, we propose actionable strategies to enhance privacy
and improve the reliability of generative models in medical imaging. Finally,
our results provide a foundation for future work on developing and benchmarking
memorization mitigation techniques for synthetic chest X-ray generation using
the MIMIC-CXR dataset.

摘要：生成模型，尤其是文字轉圖像 (T2I) 擴散模型，在醫學影像分析中扮演著至關重要的角色。然而，這些模型容易訓練資料記憶，對病患隱私造成重大風險。合成胸部 X 光線生成是醫學影像分析中最常見的應用之一，其中 MIMIC-CXR 資料集作為此任務的主要資料儲存庫。本研究採用資料驅動的方法，並提出首次系統性嘗試，以識別 MIMIC-CXR 中最有助於訓練資料記憶的提示和文字代碼。我們的分析揭露了一個意外的發現：包含去識別程序痕跡的提示是最常被記憶的，其中去識別標記的貢獻最大。此外，我們也發現現有的推論時間記憶減緩策略無效，且無法充分降低模型對記憶文字代碼的依賴性，突顯了使用 MIMIC-CXR 進行 T2I 合成的更廣泛問題。針對此問題，我們提出可行的策略，以增強隱私並改善生成模型在醫學影像中的可靠性。最後，我們的結果為未來使用 MIMIC-CXR 資料集開發和評量合成胸部 X 光線生成的記憶減緩技術奠定了基礎。

##### **KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level**
2502.07288v1 by Ruining Deng, Tianyuan Yao, Yucheng Tang, Junlin Guo, Siqi Lu, Juming Xiong, Lining Yu, Quan Huu Cap, Pengzhou Cai, Libin Lan, Ze Zhao, Adrian Galdran, Amit Kumar, Gunjan Deotale, Dev Kumar Das, Inyoung Paik, Joonho Lee, Geongyu Lee, Yujia Chen, Wangkai Li, Zhaoyang Li, Xuege Hou, Zeyuan Wu, Shengjin Wang, Maximilian Fischer, Lars Kramer, Anghong Du, Le Zhang, Maria Sanchez Sanchez, Helena Sanchez Ulloa, David Ribalta Heredia, Carlos Perez de Arenaza Garcia, Shuoyu Xu, Bingdou He, Xinping Cheng, Tao Wang, Noemie Moreau, Katarzyna Bozek, Shubham Innani, Ujjwal Baid, Kaura Solomon Kefas, Bennett A. Landman, Yu Wang, Shilin Zhao, Mengmeng Yin, Haichun Yang, Yuankai Huo

Chronic kidney disease (CKD) is a major global health issue, affecting over
10% of the population and causing significant mortality. While kidney biopsy
remains the gold standard for CKD diagnosis and treatment, the lack of
comprehensive benchmarks for kidney pathology segmentation hinders progress in
the field. To address this, we organized the Kidney Pathology Image
Segmentation (KPIs) Challenge, introducing a dataset that incorporates
preclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+
Periodic Acid Schiff (PAS)-stained whole slide images. The challenge includes
two tasks, patch-level segmentation and whole slide image segmentation and
detection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.
By encouraging innovative segmentation methods that adapt to diverse CKD models
and tissue conditions, the KPIs Challenge aims to advance kidney pathology
analysis, establish new benchmarks, and enable precise, large-scale
quantification for disease research and diagnosis.

摘要：慢性腎臟病 (CKD) 是全球主要的健康問題，影響超過
10% 的人口，並造成顯著的死亡率。雖然腎臟活檢
仍然是 CKD 診斷和治療的黃金標準，但缺乏
腎臟病理學分割的全面基準阻礙了該領域的進展。
為了解決這個問題，我們組織了腎臟病理影像
分割 (KPIs) 挑戰，引入了包含超過 10,000 個註解的
CKD 臨床前嚙齒動物模型的資料集，這些註解來自 60 多個
週期性酸性雪夫 (PAS) 染色的全幻燈片影像。挑戰包括
兩個任務，修補層級分割和全幻燈片影像分割和
偵測，使用 Dice 相似係數 (DSC) 和 F1 分數進行評估。
通過鼓勵創新的分割方法來適應不同的 CKD 模型
和組織條件，KPIs 挑戰旨在推進腎臟病理
分析，建立新的基準，並實現精確、大規模的
疾病研究和診斷量化。

##### **Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer**
2502.07158v1 by Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu

Early prediction of pediatric cardiac arrest (CA) is critical for timely
intervention in high-risk intensive care settings. We introduce PedCA-FT, a
novel transformer-based framework that fuses tabular view of EHR with the
derived textual view of EHR to fully unleash the interactions of
high-dimensional risk factors and their dynamics. By employing dedicated
transformer modules for each modality view, PedCA-FT captures complex temporal
and contextual patterns to produce robust CA risk estimates. Evaluated on a
curated pediatric cohort from the CHOA-CICU database, our approach outperforms
ten other artificial intelligence models across five key performance metrics
and identifies clinically meaningful risk factors. These findings underscore
the potential of multimodal fusion techniques to enhance early CA detection and
improve patient care.

摘要：早期預測兒童心臟驟停 (CA) 對高風險重症監護環境中的及時干預至關重要。我們引入了 PedCA-FT，這是一個新的基於Transformer的框架，它將 EHR 的表格視圖與 EHR 的派生文本視圖融合在一起，以充分釋放高維風險因素及其動態的交互作用。通過為每個模態視圖採用專用的Transformer模塊，PedCA-FT 捕獲復雜的時間和上下文模式以產生穩健的 CA 風險估計。在 CHOA-CICU 資料庫中經過策劃的兒科隊列上進行評估，我們的做法在五個關鍵性能指標上優於其他十個人工智慧模型，並識別出臨床上有意義的風險因素。這些發現強調了多模態融合技術在增強早期 CA 檢測和改善患者護理方面的潛力。

##### **Explaining 3D Computed Tomography Classifiers with Counterfactuals**
2502.07156v1 by Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari

Counterfactual explanations in medical imaging are critical for understanding
the predictions made by deep learning models. We extend the Latent Shift
counterfactual generation method from 2D applications to 3D computed tomography
(CT) scans. We address the challenges associated with 3D data, such as limited
training samples and high memory demands, by implementing a slice-based
approach. This method leverages a 2D encoder trained on CT slices, which are
subsequently combined to maintain 3D context. We demonstrate this technique on
two models for clinical phenotype prediction and lung segmentation. Our
approach is both memory-efficient and effective for generating interpretable
counterfactuals in high-resolution 3D medical imaging.

摘要：反事實解釋在醫學影像中對於理解深度學習模型所做的預測至關重要。我們將 Latent Shift 反事實生成方法從 2D 應用程式延伸到 3D 電腦斷層掃描 (CT) 掃描。我們透過實作基於切片的做法，來解決與 3D 資料相關的挑戰，例如受限的訓練樣本和高記憶體需求。此方法利用經過 CT 切片訓練的 2D 編碼器，隨後將這些切片結合起來以維護 3D 背景。我們在兩個用於臨床表型預測和肺部分割的模型上展示此技術。我們的做法對於在高解析度 3D 醫學影像中產生可解釋的反事實，既節省記憶體又有效。

##### **Interactive Data Harmonization with LLM Agents**
2502.07132v1 by Aécio Santos, Eduardo H. M. Pena, Roque Lopez, Juliana Freire

Data harmonization is an essential task that entails integrating datasets
from diverse sources. Despite years of research in this area, it remains a
time-consuming and challenging task due to schema mismatches, varying
terminologies, and differences in data collection methodologies. This paper
presents the case for agentic data harmonization as a means to both empower
experts to harmonize their data and to streamline the process. We introduce
Harmonia, a system that combines LLM-based reasoning, an interactive user
interface, and a library of data harmonization primitives to automate the
synthesis of data harmonization pipelines. We demonstrate Harmonia in a
clinical data harmonization scenario, where it helps to interactively create
reusable pipelines that map datasets to a standard format. Finally, we discuss
challenges and open problems, and suggest research directions for advancing our
vision.

摘要：資料調和是一項整合不同來源資料集的重要任務。儘管多年來針對此領域的研究不斷，但由於架構不匹配、術語不同，以及資料收集方法的差異，它仍然是一項耗時且具有挑戰性的任務。本文提出代理資料調和，作為賦能專家調和其資料並簡化流程的方法。我們介紹 Harmonia，一個結合了基於 LLM 的推理、互動式使用者介面和資料調和原語庫的系統，以自動化資料調和管線的合成。我們在臨床資料調和場景中展示了 Harmonia，它有助於互動式建立可重複使用的管線，將資料集對應至標準格式。最後，我們討論挑戰和開放性問題，並建議研究方向以推進我們的願景。

##### **Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML**
2502.07026v1 by Mohammad Amir Salari, Bahareh Rahmani

Machine learning (ML) is transforming healthcare by enabling predictive
analytics, personalized treatments, and improved patient outcomes. However,
traditional ML workflows require specialized skills, infrastructure, and
resources, limiting accessibility for many healthcare professionals. This paper
explores how Google Cloud's BigQuery ML simplifies the development and
deployment of ML models using SQL, reducing technical barriers. Through a case
study on diabetes prediction using the Diabetes Health Indicators Dataset, we
evaluate three predictive models: Logistic Regression, Boosted Tree, and Deep
Neural Network (DNN). Our results demonstrate that the Boosted Tree model
achieves the highest performance, making it highly effective for diabetes
prediction. This study highlights BigQuery ML's role in democratizing machine
learning by providing a scalable, efficient, and accessible solution for
healthcare analytics.

摘要：機器學習 (ML) 透過啟用預測分析、個人化治療和改善病患結果，正在轉型醫療保健。然而，傳統的 ML 工作流程需要專業技能、基礎設施和資源，限制了許多醫療保健專業人員的可及性。本文探討 Google Cloud 的 BigQuery ML 如何使用 SQL 簡化 ML 模型的開發和部署，降低技術障礙。透過使用糖尿病健康指標資料集對糖尿病預測進行個案研究，我們評估了三個預測模型：邏輯迴歸、提升樹和深度神經網路 (DNN)。我們的結果證明，提升樹模型達到了最高的效能，使其對於糖尿病預測非常有效。這項研究強調了 BigQuery ML 在民主化機器學習中扮演的角色，提供可擴充、有效率且可存取的醫療保健分析解決方案。

##### **AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements**
2502.07022v1 by Adriana Eufrosiana Bora, Pierre-Luc St-Charles, Mirko Bronzi, Arsène Fansi Tchango, Bruno Rousseau, Kerrie Mengersen

Despite over a decade of legislative efforts to address modern slavery in the
supply chains of large corporations, the effectiveness of government oversight
remains hampered by the challenge of scrutinizing thousands of statements
annually. While Large Language Models (LLMs) can be considered a well
established solution for the automatic analysis and summarization of documents,
recognizing concrete modern slavery countermeasures taken by companies and
differentiating those from vague claims remains a challenging task. To help
evaluate and fine-tune LLMs for the assessment of corporate statements, we
introduce a dataset composed of 5,731 modern slavery statements taken from the
Australian Modern Slavery Register and annotated at the sentence level. This
paper details the construction steps for the dataset that include the careful
design of annotation specifications, the selection and preprocessing of
statements, and the creation of high-quality annotation subsets for effective
model evaluations. To demonstrate our dataset's utility, we propose a machine
learning methodology for the detection of sentences relevant to mandatory
reporting requirements set by the Australian Modern Slavery Act. We then follow
this methodology to benchmark modern language models under zero-shot and
supervised learning settings.

摘要：儘管立法努力超過十年，旨在解決大型企業供應鏈中的現代奴隸制，但政府監督的有效性仍然受到每年審查數千份聲明的挑戰所阻礙。雖然大型語言模型（LLM）可以被認為是文件自動分析和摘要的完善解決方案，但要辨識公司採取的具體現代奴隸制對策，並將其與含糊的聲明區分開來，仍然是一項具有挑戰性的任務。為了幫助評估和微調 LLM 以評估企業聲明，我們引入了一個由 5,731 份現代奴隸制聲明組成的資料集，這些聲明取自澳洲現代奴隸制註冊處，並在句子層級進行註解。本文詳細說明了資料集的建構步驟，其中包括註解規格的仔細設計、聲明的選擇和預處理，以及用於有效模型評估的高品質註解子集的建立。為了展示我們的資料集的效用，我們提出了一種機器學習方法，用於檢測與澳洲現代奴隸制法規定的強制性報告要求相關的句子。然後，我們遵循這種方法，在零次學習和監督學習設定下對現代語言模型進行基準測試。

##### **Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium**
2502.06693v1 by Amin Adibi, Xu Cao, Zongliang Ji, Jivat Neet Kaur, Winston Chen, Elizabeth Healey, Brighton Nuwagira, Wenqian Ye, Geoffrey Woollard, Maxwell A Xu, Hejie Cui, Johnny Xi, Trenton Chang, Vasiliki Bikia, Nicole Zhang, Ayush Noori, Yuan Xia, Md. Belal Hossain, Hanna A. Frank, Alina Peluso, Yuan Pu, Shannon Zejiang Shen, John Wu, Adibvafa Fallahpour, Sazan Mahbub, Ross Duncan, Yuwei Zhang, Yurui Cao, Zuheng Xu, Michael Craig, Rahul G. Krishnan, Rahmatollah Beheshti, James M. Rehg, Mohammad Ehsanul Karim, Megan Coffee, Leo Anthony Celi, Jason Alan Fries, Mohsen Sadatsafavi, Dennis Shung, Shannon McWeeney, Jessica Dafflon, Sarah Jabbour

The fourth Machine Learning for Health (ML4H) symposium was held in person on
December 15th and 16th, 2024, in the traditional, ancestral, and unceded
territories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver,
British Columbia, Canada. The symposium included research roundtable sessions
to foster discussions between participants and senior researchers on timely and
relevant topics for the ML4H community. The organization of the research
roundtables at the conference involved 13 senior and 27 junior chairs across 13
tables. Each roundtable session included an invited senior chair (with
substantial experience in the field), junior chairs (responsible for
facilitating the discussion), and attendees from diverse backgrounds with an
interest in the session's topic.

摘要：第四屆醫療機器學習 (ML4H) 研討會於 2024 年 12 月 15 日和 16 日在加拿大不列顛哥倫比亞省溫哥華的 Musqueam、Squamish 和 Tsleil-Waututh 國家的傳統、祖先和未割讓領土上舉行。研討會包括研究圓桌會議，以促進參與者和高級研究人員之間關於 ML4H 社群的及時和相關主題的討論。在會議上組織研究圓桌會議涉及 13 張桌子上的 13 位高級主席和 27 位初級主席。每個圓桌會議都包括一位受邀的高級主席（在該領域擁有豐富的經驗）、初級主席（負責促進討論）以及對會議主題感興趣的來自不同背景的與會者。

##### **Automatic Evaluation of Healthcare LLMs Beyond Question-Answering**
2502.06666v1 by Anna Arias-Duart, Pablo Agustin Martin-Torres, Daniel Hinjos, Pablo Bernabeu-Perez, Lucia Urcelay Ganzabal, Marta Gonzalez Mallo, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Sergio Alvarez-Napagao, Dario Garcia-Gasulla

Current Large Language Models (LLMs) benchmarks are often based on open-ended
or close-ended QA evaluations, avoiding the requirement of human labor.
Close-ended measurements evaluate the factuality of responses but lack
expressiveness. Open-ended capture the model's capacity to produce discourse
responses but are harder to assess for correctness. These two approaches are
commonly used, either independently or together, though their relationship
remains poorly understood. This work is focused on the healthcare domain, where
both factuality and discourse matter greatly. It introduces a comprehensive,
multi-axis suite for healthcare LLM evaluation, exploring correlations between
open and close benchmarks and metrics. Findings include blind spots and
overlaps in current methodologies. As an updated sanity check, we release a new
medical benchmark--CareQA--, with both open and closed variants. Finally, we
propose a novel metric for open-ended evaluations --Relaxed Perplexity-- to
mitigate the identified limitations.

摘要：當前大型語言模型 (LLM) 基準通常基於開放式或封閉式問答評量，避免了人力需求。封閉式測量評估回應的事實性，但缺乏表達力。開放式測量捕捉模型產生論述回應的能力，但較難評估正確性。這兩種方法通常獨立或合併使用，儘管它們之間的關係仍然知之甚少。這項工作專注於醫療保健領域，在該領域中，事實性和論述都非常重要。它引入了一個全面的多軸套件，用於醫療保健 LLM 評量，探索開放式和封閉式基準和指標之間的關聯性。研究結果包括當前方法中的盲點和重疊。作為更新的健全性檢查，我們發布了一個新的醫療基準--CareQA--，包含開放式和封閉式變體。最後，我們提出了一個用於開放式評量的全新指標--放鬆困惑度--以減輕已識別的限制。

##### **Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging**
2502.06632v1 by Mohammed Abdul Hafeez Khan, Samuel Morries Boddepalli, Siddhartha Bhattacharyya, Debasis Mitra

Accurate classification and anatomical localization are essential for
effective medical diagnostics and research, which may be efficiently performed
using deep learning techniques. However, availability of limited labeled data
poses a significant challenge. To address this, we adapted Prototypical
Networks and the Propagation-Reconstruction Network (PRNet) for few-shot
classification and localization, respectively, in Single Photon Emission
Computed Tomography (SPECT) images. For the proof of concept we used a
2D-sliced image cropped around heart. The Prototypical Network, with a
pre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver
tissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for
2D imaging with an encoder-decoder architecture and skip connections, achieved
a training loss of 1.395, accurately reconstructing patches and capturing
spatial relationships. These results highlight the potential of Prototypical
Networks for tissue classification with limited labeled data and PRNet for
anatomical landmark localization, paving the way for improved performance in
deep learning frameworks.

摘要：精確的分類和解剖定位對於有效的醫療診斷和研究至關重要，而這可以使用深度學習技術有效執行。然而，標記資料有限的取得會造成重大的挑戰。為了解決這個問題，我們分別調整了原型網路和傳播重建網路 (PRNet)，用於單光子發射電腦斷層掃描 (SPECT) 影像中的少量分類和定位。為了證明這個概念，我們使用圍繞心臟裁切的 2D 切片影像。原型網路，使用預先訓練的 ResNet-18 主幹，對心室、心肌和肝臟組織進行分類，訓練準確度為 96.67%，驗證準確度為 93.33%。PRNet，調整為使用編碼器解碼器架構和跳躍連接的 2D 影像，達到了 1.395 的訓練損失，精確地重建了區塊並擷取了空間關係。這些結果突出了原型網路在標記資料有限的情況下進行組織分類的潛力，以及 PRNet 在解剖標誌定位方面的潛力，為深度學習架構中效能的提升鋪平了道路。

##### **Illegal Waste Detection in Remote Sensing Images: A Case Study**
2502.06607v2 by Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Andrea Diecidue, Simona Malegori

Environmental crime currently represents the third largest criminal activity
worldwide while threatening ecosystems as well as human health. Among the
crimes related to this activity, improper waste management can nowadays be
countered more easily thanks to the increasing availability and decreasing cost
of Very-High-Resolution Remote Sensing images, which enable semi-automatic
territory scanning in search of illegal landfills. This paper proposes a
pipeline, developed in collaboration with professionals from a local
environmental agency, for detecting candidate illegal dumping sites leveraging
a classifier of Remote Sensing images. To identify the best configuration for
such classifier, an extensive set of experiments was conducted and the impact
of diverse image characteristics and training settings was thoroughly analyzed.
The local environmental agency was then involved in an experimental exercise
where outputs from the developed classifier were integrated in the experts'
everyday work, resulting in time savings with respect to manual
photo-interpretation. The classifier was eventually run with valuable results
on a location outside of the training area, highlighting potential for
cross-border applicability of the proposed pipeline.

摘要：環境犯罪目前是全球第三大犯罪活動，威脅生態系統和人類健康。在與此活動相關的犯罪中，不當廢物管理現在可以更容易地得到解決，這要歸功於超高解析度遙測影像越來越普及且成本下降，這使得半自動領土掃描能夠搜尋非法垃圾掩埋場。本文提出了一條管道，與當地環境機構的專業人士合作開發，用於檢測候選非法傾倒地點，利用遙測影像分類器。為了找出這種分類器的最佳配置，進行了一系列廣泛的實驗，並徹底分析了不同影像特徵和訓練設定的影響。然後，當地環境機構參與了一項實驗練習，其中將已開發分類器的輸出整合到專家的日常工作中，從而節省了人工照片解譯的時間。最後在訓練區域外的某個位置執行分類器，獲得了有價值的結果，突出了所提出管道的跨境適用性潛力。

##### **FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model**
2502.06438v1 by Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li

Accurate and efficient electroencephalography (EEG) analysis is essential for
detecting seizures and artifacts in long-term monitoring, with applications
spanning hospital diagnostics to wearable health devices. Robust EEG analytics
have the potential to greatly improve patient care. However, traditional deep
learning models, especially Transformer-based architectures, are hindered by
their quadratic time and memory complexity, making them less suitable for
resource-constrained environments. To address these challenges, we present
FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel
self-supervised framework that establishes new efficiency benchmarks for EEG
analysis through bidirectional state-space modeling. Unlike Transformer-based
models, which incur quadratic time and memory complexity, FEMBA scales linearly
with sequence length, enabling more scalable and efficient processing of
extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and
fine-tuned on three downstream tasks, FEMBA achieves competitive performance in
comparison with transformer models, with significantly lower computational
cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB
and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates
viability for resource-constrained devices. These results pave the way for
scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as
a promising candidate for wearable applications.

摘要：準確且有效的腦電圖 (EEG) 分析對於偵測長時間監控中的癲癇發作和偽像至關重要，其應用範圍涵蓋醫院診斷到可穿戴式健康裝置。穩健的 EEG 分析具有大幅改善病患照護的潛力。然而，傳統深度學習模型，特別是基於 Transformer 的架構，受到其二次時間和記憶體複雜度的阻礙，使其不太適合資源受限的環境。為了應對這些挑戰，我們提出 FEMBA (基礎 EEG Mamba + 雙向架構)，一種創新的自我監督架構，透過雙向狀態空間建模為 EEG 分析建立新的效率基準。與會產生二次時間和記憶體複雜度的基於 Transformer 的模型不同，FEMBA 隨著序列長度線性縮放，支援更具可擴充性和效率的延伸 EEG 記錄處理。FEMBA 在超過 21,000 小時的未標記 EEG 上訓練並在三個下游任務上進行微調，與Transformer模型相比，在計算成本顯著降低的情況下，實現了具有競爭力的效能。具體來說，它在 TUAB 上達到 81.82% 的平衡準確度 (0.8921 AUROC) 和在 TUAR 上達到 0.949 AUROC，而一個微小的 7.8M 參數變體證明了其在資源受限裝置上的可行性。這些結果為臨床和可穿戴應用中可擴充的通用 EEG 分析鋪平了道路，並突顯 FEMBA 是可穿戴應用中一個有前景的候選者。

##### **Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?**
2502.06289v1 by Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K. Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, AnRan Ran, Rui Santos, Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Yim-Lui Cheung, Pearse A. Keane, Yih Chung Tham

The advent of foundation models (FMs) is transforming medical domain. In
ophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4
million natural images and 1.6 million retinal images, has demonstrated high
adaptability across clinical applications. Conversely, DINOv2, a
general-purpose vision FM pre-trained on 142 million natural images, has shown
promise in non-medical domains. However, its applicability to clinical tasks
remains underexplored. To address this, we conducted head-to-head evaluations
by fine-tuning RETFound and three DINOv2 models (large, base, small) for ocular
disease detection and systemic disease prediction tasks, across eight
standardized open-source ocular datasets, as well as the Moorfields AlzEye and
the UK Biobank datasets. DINOv2-large model outperformed RETFound in detecting
diabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,
all P<=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P<0.001). In
glaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,
P<0.001). Conversely, RETFound achieved superior performance over all DINOv2
models in predicting heart failure, myocardial infarction, and ischaemic stroke
(AUROC=0.732-0.796 vs 0.663-0.771, all P<0.001). These trends persisted even
with 10% of the fine-tuning data. These findings showcase the distinct
scenarios where general-purpose and domain-specific FMs excel, highlighting the
importance of aligning FM selection with task-specific requirements to optimise
clinical performance.

摘要：基礎模型 (FM) 的出現正在轉變醫療領域。在眼科，RETFound 是一個視網膜專用 FM，依序使用 140 萬張自然影像和 160 萬張視網膜影像進行預訓練，已展現出高度適應性，可應用於各種臨床應用。相反地，DINOv2 是一個通用視覺 FM，使用 1.42 億張自然影像進行預訓練，已展現出在非醫療領域的潛力。然而，其在臨床任務中的適用性仍未被充分探索。為了解決這個問題，我們針對眼部疾病偵測和全身性疾病預測任務，對 RETFound 和三個 DINOv2 模型（大型、基礎、小型）進行微調，並進行一對一的評估，使用八個標準化的開源眼科資料集，以及 Moorfields AlzEye 和 UK Biobank 資料集。DINOv2 大型模型在糖尿病視網膜病變偵測方面優於 RETFound（三個資料集的 AUROC=0.850-0.952，相較於 0.823-0.944，所有 P<=0.007）和多類眼部疾病（AUROC=0.892，相較於 0.846，P<0.001）。在青光眼方面，DINOv2 基礎模型優於 RETFound（AUROC=0.958，相較於 0.940，P<0.001）。相反地，RETFound 在預測心臟衰竭、心肌梗塞和缺血性中風方面優於所有 DINOv2 模型（AUROC=0.732-0.796，相較於 0.663-0.771，所有 P<0.001）。即使使用 10% 的微調資料，這些趨勢仍然持續。這些發現展示了通用和領域專用 FM 各自擅長的場景，突顯了根據任務特定需求調整 FM 選擇，以最佳化臨床表現的重要性。

##### **Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning**
2502.06134v1 by Liuqing Chen, Shuhong Xiao, Shixian Ding, Shanhai Hu, Lingyun Sun

Medical time series are often irregular and face significant missingness,
posing challenges for data analysis and clinical decision-making. Existing
methods typically adopt a single modeling perspective, either treating series
data as sequences or transforming them into image representations for further
classification. In this paper, we propose a joint learning framework that
incorporates both sequence and image representations. We also design three
self-supervised learning strategies to facilitate the fusion of sequence and
image representations, capturing a more generalizable joint representation. The
results indicate that our approach outperforms seven other state-of-the-art
models in three representative real-world clinical datasets. We further
validate our approach by simulating two major types of real-world missingness
through leave-sensors-out and leave-samples-out techniques. The results
demonstrate that our approach is more robust and significantly surpasses other
baselines in terms of classification performance.

摘要：醫療時間序列通常不規則且會面臨顯著的缺失，對資料分析和臨床決策制定構成挑戰。現有方法通常採用單一建模觀點，將序列資料視為序列或將其轉換為影像表示以進行進一步分類。在本文中，我們提出了一個聯合學習架構，結合序列和影像表示。我們還設計了三種自我監督學習策略，以促進序列和影像表示的融合，捕捉更具概括性的聯合表示。結果表明，我們的做法在三個具有代表性的真實世界臨床資料集中優於其他七個最先進的模型。我們進一步通過留出感測器和留出樣本的技術模擬兩種主要的真實世界缺失類型來驗證我們的做法。結果表明，我們的做法更強大，並且在分類效能方面顯著優於其他基準。

##### **Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**
2502.06124v1 by Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek

We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),
an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS
predicts future PHTs using transformer-based architectures. The Adaptive Risk
Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk
probabilities for clinician-defined critical events. ARES incorporates a
personalized explainability module that identifies key clinical factors
influencing risk estimates for individual patients. ARES was evaluated on the
MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its
performance against traditional early warning systems and machine learning
models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,
with 60% including hospital admissions. The dataset contained over 357 million
tokens. ETHOS outperformed benchmark models in predicting hospital admissions,
ICU admissions, and prolonged hospital stays, achieving superior AUC scores.
ETHOS-based risk estimates demonstrated robustness across demographic subgroups
with strong model reliability, confirmed via calibration curves. The
personalized explainability module provides insights into patient-specific
factors contributing to risk. ARES, powered by ETHOS, advances predictive
healthcare AI by providing dynamic, real-time, and personalized risk estimation
with patient-specific explainability to enhance clinician trust. Its
adaptability and superior accuracy position it as a transformative tool for
clinical decision-making, potentially improving patient outcomes and resource
allocation in emergency and inpatient settings. We release the full code at
github.com/ipolharvard/ethos-ares to facilitate future research.

摘要：我們開發了增強型健康結果模擬轉換器 (ETHOS)，
一種從電子健康紀錄 (EHR) 中將患者健康時間軸 (PHT) 標記化的 AI 模型。ETHOS
使用基於轉換器的架構預測未來的 PHT。自適應風險評估系統 (ARES) 使用 ETHOS 計算由臨床醫生定義的危急事件的動態且個人化的風險機率。ARES 結合了個人化的可解釋性模組，可找出影響個別患者風險評估的主要臨床因素。ARES 在急診部門 (ED) 設定中針對 MIMIC-IV v2.2 資料集進行評估，並將其效能與傳統的預警系統和機器學習模型進行基準測試。我們將 299,721 位 MIMIC-IV 的獨特患者處理成 285,622 個 PHT，其中 60% 包含住院記錄。該資料集包含超過 3.57 億個標記。ETHOS 在預測住院、加護病房 (ICU) 住院和延長住院時間方面表現優於基準模型，並獲得了較高的 AUC 分數。基於 ETHOS 的風險評估顯示出跨人口統計子群的穩健性，並通過校準曲線確認了強大的模型可靠性。個人化的可解釋性模組提供了對導致風險的患者特定因素的見解。由 ETHOS 驅動的 ARES 透過提供動態、即時且個人化的風險評估，以及患者特定的可解釋性來增強臨床醫生的信任，從而推動了預測性醫療保健 AI 的發展。其適應性和卓越的準確性使其成為臨床決策制定的一種變革性工具，有可能改善緊急和住院環境中的患者結果和資源分配。我們在 github.com/ipolharvard/ethos-ares 上釋出完整程式碼，以利未來的研究。

##### **Can ChatGPT Diagnose Alzheimer's Disease?**
2502.06907v1 by Quoc-Toan Nguyen, Linh Le, Xuan-The Tran, Thomas Do, Chin-Teng Lin

Can ChatGPT diagnose Alzheimer's Disease (AD)? AD is a devastating
neurodegenerative condition that affects approximately 1 in 9 individuals aged
65 and older, profoundly impairing memory and cognitive function. This paper
utilises 9300 electronic health records (EHRs) with data from Magnetic
Resonance Imaging (MRI) and cognitive tests to address an intriguing question:
As a general-purpose task solver, can ChatGPT accurately detect AD using EHRs?
We present an in-depth evaluation of ChatGPT using a black-box approach with
zero-shot and multi-shot methods. This study unlocks ChatGPT's capability to
analyse MRI and cognitive test results, as well as its potential as a
diagnostic tool for AD. By automating aspects of the diagnostic process, this
research opens a transformative approach for the healthcare system,
particularly in addressing disparities in resource-limited regions where AD
specialists are scarce. Hence, it offers a foundation for a promising method
for early detection, supporting individuals with timely interventions, which is
paramount for Quality of Life (QoL).

摘要：ChatGPT 能否診斷出阿茲海默症 (AD)？AD 是一種毀滅性的神經退化性疾病，影響約 1/9 的 65 歲及以上人士，嚴重損害記憶力和認知功能。這篇論文利用了 9300 份電子健康紀錄 (EHR)，其中包含磁共振成像 (MRI) 和認知測試的數據，來解決一個有趣的問題：作為一個通用任務解決器，ChatGPT 能否使用 EHR 準確地檢測出 AD？我們使用黑盒方法對 ChatGPT 進行了深入評估，採用零次嘗試和多次嘗試的方法。這項研究揭示了 ChatGPT 分析 MRI 和認知測試結果的能力，以及其作為 AD 診斷工具的潛力。通過自動化診斷過程的各個方面，這項研究為醫療保健系統開啟了一種變革性的方法，特別是在解決資源有限的地區中 AD 專家稀缺的不平等問題方面。因此，它為一種有希望的早期檢測方法奠定了基礎，通過及時干預來支持個人，這對於生活品質 (QoL) 至關重要。

##### **Protecting Intellectual Property of EEG-based Neural Networks with Watermarking**
2502.05931v1 by Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares

EEG-based neural networks, pivotal in medical diagnosis and brain-computer
interfaces, face significant intellectual property (IP) risks due to their
reliance on sensitive neurophysiological data and resource-intensive
development. Current watermarking methods, particularly those using abstract
trigger sets, lack robust authentication and fail to address the unique
challenges of EEG models. This paper introduces a cryptographic wonder
filter-based watermarking framework tailored for EEG-based neural networks.
Leveraging collision-resistant hashing and public-key encryption, the wonder
filter embeds the watermark during training, ensuring minimal distortion ($\leq
5\%$ drop in EEG task accuracy) and high reliability (100\% watermark
detection). The framework is rigorously evaluated against adversarial attacks,
including fine-tuning, transfer learning, and neuron pruning. Results
demonstrate persistent watermark retention, with classification accuracy for
watermarked states remaining above 90\% even after aggressive pruning, while
primary task performance degrades faster, deterring removal attempts. Piracy
resistance is validated by the inability to embed secondary watermarks without
severe accuracy loss ( $>10\%$ in EEGNet and CCNN models). Cryptographic
hashing ensures authentication, reducing brute-force attack success
probabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,
TSception), the method achieves $>99.4\%$ null-embedding accuracy, effectively
eliminating false positives. By integrating wonder filters with EEG-specific
adaptations, this work bridges a critical gap in IP protection for
neurophysiological models, offering a secure, tamper-proof solution for
healthcare and biometric applications. The framework's robustness against
adversarial modifications underscores its potential to safeguard sensitive EEG
models while maintaining diagnostic utility.

摘要：<paragraph>基於 EEG 的神經網路在醫學診斷和腦電腦介面中至關重要，由於其依賴敏感的神經生理資料和資源密集型的開發，面臨重大的智慧財產權 (IP) 風險。目前的浮水印方法，特別是那些使用抽象觸發集的方法，缺乏強健的驗證，且無法解決 EEG 模型的獨特挑戰。本文介紹了一個專為基於 EEG 的神經網路量身打造的密碼學 wonder 濾波器浮水印架構。利用抗碰撞雜湊和公開金鑰加密，wonder 濾波器在訓練期間嵌入浮水印，確保最小的失真（EEG 任務準確度下降 $\leq 5\%$）和高可靠性（100% 浮水印檢測）。該架構針對對抗性攻擊進行了嚴格的評估，包括微調、遷移學習和神經元剪枝。結果證明了持續的浮水印保留，即使在激進的剪枝後，浮水印狀態的分類準確度仍保持在 90% 以上，而主要任務的性能下降得更快，阻止了移除嘗試。盜版抵抗力通過無法嵌入次要浮水印而得到驗證，而不會造成嚴重的準確度損失（在 EEGNet 和 CCNN 模型中 $>10\%$）。密碼學雜湊確保驗證，降低了暴力攻擊成功機率。在 DEAP 資料集上針對模型（CCNN、EEGNet、TSception）進行評估，該方法達到了 $>99.4\%$ 的空嵌入準確度，有效地消除了假陽性。透過將 wonder 濾波器與 EEG 特定的適應相整合，這項工作彌補了神經生理模型 IP 保護中的關鍵差距，為醫療保健和生物特徵應用提供了一個安全、防篡改的解決方案。該架構對抗敵對修改的強健性突顯了其在維護診斷效用的同時保護敏感 EEG 模型的潛力。</paragraph>

##### **Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models**
2502.05879v1 by Shiyu Teng, Jiaqing Liu, Rahul Kumar Jain, Shurong Chai, Ruibo Hou, Tomoko Tateyama, Lanfen Lin, Yen-wei Chen

Depression is one of the leading causes of disability worldwide, posing a
severe burden on individuals, healthcare systems, and society at large. Recent
advancements in Large Language Models (LLMs) have shown promise in addressing
mental health challenges, including the detection of depression through
text-based analysis. However, current LLM-based methods often struggle with
nuanced symptom identification and lack a transparent, step-by-step reasoning
process, making it difficult to accurately classify and explain mental health
conditions. To address these challenges, we propose a Chain-of-Thought
Prompting approach that enhances both the performance and interpretability of
LLM-based depression detection. Our method breaks down the detection process
into four stages: (1) sentiment analysis, (2) binary depression classification,
(3) identification of underlying causes, and (4) assessment of severity. By
guiding the model through these structured reasoning steps, we improve
interpretability and reduce the risk of overlooking subtle clinical indicators.
We validate our method on the E-DAIC dataset, where we test multiple
state-of-the-art large language models. Experimental results indicate that our
Chain-of-Thought Prompting technique yields superior performance in both
classification accuracy and the granularity of diagnostic insights, compared to
baseline approaches.

摘要：憂鬱症是全球殘障的主要原因之一，對個人、醫療保健系統和整個社會造成嚴重負擔。大型語言模型 (LLM) 的最新進展已展現出解決心理健康挑戰的希望，包括透過基於文字的分析來偵測憂鬱症。然而，現有的基於 LLM 的方法通常難以辨識細微的症狀，而且缺乏透明且逐步的推理過程，這使得準確分類和解釋心理健康狀況變得困難。為了應對這些挑戰，我們提出了一種思考鏈提示方法，它增強了基於 LLM 的憂鬱症偵測的效能和可解釋性。我們的這項方法將偵測過程分解為四個階段：(1) 情緒分析，(2) 二元憂鬱症分類，(3) 找出潛在原因，以及 (4) 評估嚴重程度。透過引導模型完成這些結構化的推理步驟，我們提升了可解釋性，並降低了忽略細微臨床指標的風險。我們在 E-DAIC 資料集上驗證了我們的這項方法，並在其中測試了多種最先進的大型語言模型。實驗結果顯示，與基線方法相比，我們的思考鏈提示技術在分類準確度和診斷見解的精細度方面都表現出優異的效能。

##### **LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison**
2502.06890v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

The increasing volume of drug combinations in modern therapeutic regimens
needs reliable methods for predicting drug-drug interactions (DDIs). While
Large Language Models (LLMs) have revolutionized various domains, their
potential in pharmaceutical research, particularly in DDI prediction, remains
largely unexplored. This study thoroughly investigates LLMs' capabilities in
predicting DDIs by uniquely processing molecular structures (SMILES), target
organisms, and gene interaction data as raw text input from the latest DrugBank
dataset. We evaluated 18 different LLMs, including proprietary models (GPT-4,
Claude, Gemini) and open-source variants (from 1.5B to 72B parameters), first
assessing their zero-shot capabilities in DDI prediction. We then fine-tuned
selected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1
distilled Qwen 1.5B) to optimize their performance. Our comprehensive
evaluation framework included validation across 13 external DDI datasets,
comparing against traditional approaches such as l2-regularized logistic
regression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5
2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of
0.919 on balanced datasets (50% positive, 50% negative cases). This result
represents an improvement over both zero-shot predictions and state-of-the-art
machine-learning methods used for DDI prediction. Our analysis reveals that
LLMs can effectively capture complex molecular interaction patterns and cases
where drug pairs target common genes, making them valuable tools for practical
applications in pharmaceutical research and clinical settings.

摘要：<paragraph>現代治療方案中藥物組合的數量越來越多，需要可靠的方法來預測藥物間交互作用 (DDI)。儘管大型語言模型 (LLM) 已在各個領域掀起革命，它們在藥物研究中的潛力，特別是在 DDI 預測中的潛力，仍未得到充分探索。本研究通過獨特地處理分子結構 (SMILES)、目標生物和基因交互資料作為來自最新 DrugBank 資料集的原始文字輸入，徹底調查了 LLM 在預測 DDI 中的能力。我們評估了 18 種不同的 LLM，包括專有模型（GPT-4、Claude、Gemini）和開源變體（從 1.5B 到 72B 參數），首先評估它們在 DDI 預測中的零次學習能力。然後，我們微調選定的模型（GPT-4、Phi-3.5 2.7B、Qwen-2.5 3B、Gemma-2 9B 和 Deepseek R1 蒸餾 Qwen 1.5B）以最佳化其效能。我們的全面評估框架包括跨 13 個外部 DDI 資料集進行驗證，並與傳統方法（例如 l2 正則化邏輯迴歸）進行比較。微調後的 LLM 表現出優異的效能，其中 Phi-3.5 2.7B 在 DDI 預測中達到 0.978 的靈敏度，在平衡資料集（50% 正例，50% 反例）上的準確度為 0.919。此結果優於零次學習預測和用於 DDI 預測的最新機器學習方法。我們的分析表明，LLM 可以有效捕捉複雜的分子交互模式和藥物對靶向共同基因的情況，使其成為藥物研究和臨床環境中實用應用的寶貴工具。</paragraph>

##### **Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)**
2502.07815v1 by Lokesh Koli, Shubham Kalra, Karanpreet Singh

Detecting sensitive data such as Personally Identifiable Information (PII)
and Protected Health Information (PHI) is critical for data security platforms.
This study evaluates regex-based pattern matching algorithms and exact-match
search techniques to optimize detection speed, accuracy, and scalability. Our
benchmarking results indicate that Google RE2 provides the best balance of
speed (10-15 ms/MB), memory efficiency (8-16 MB), and accuracy (99.5%) among
regex engines, outperforming PCRE while maintaining broader hardware
compatibility than Hyperscan. For exact matching, Aho-Corasick demonstrated
superior performance (8 ms/MB) and scalability for large datasets. Performance
analysis revealed that regex processing time scales linearly with dataset size
and pattern complexity. A hybrid AI + Regex approach achieved the highest F1
score (91. 6%) by improving recall and minimizing false positives. Device
benchmarking confirmed that our solution maintains efficient CPU and memory
usage on both high-performance and mid-range systems. Despite its
effectiveness, challenges remain, such as limited multilingual support and the
need for regular pattern updates. Future work should focus on expanding
language coverage, integrating data security and privacy management (DSPM) with
data loss prevention (DLP) tools, and enhancing regulatory compliance for
broader global adoption.

摘要：偵測個人身分資訊 (PII) 和受保護健康資訊 (PHI) 等敏感資料，對於資料安全平台至關重要。本研究評估基於 regex 的模式配對演算法和精確配對搜尋技術，以最佳化偵測速度、準確度和可擴充性。我們的基準測試結果顯示，在 regex 引擎中，Google RE2 在速度 (10-15 ms/MB)、記憶體效率 (8-16 MB) 和準確度 (99.5%) 方面取得最佳平衡，優於 PCRE，同時比 Hyperscan 擁有更廣泛的硬體相容性。對於精確配對，Aho-Corasick 展現出優異的效能 (8 ms/MB) 和大資料集的可擴充性。效能分析顯示，regex 處理時間會隨著資料集大小和模式複雜度線性擴充。混合 AI + Regex 方法透過提升召回率和將假陽性降至最低，達到了最高的 F1 分數 (91. 6%)。裝置基準測試確認我們的解決方案在高性能和中階系統上都能維持高效的 CPU 和記憶體使用率。儘管有效，但仍有挑戰存在，例如多語言支援有限，以及需要定期更新模式。未來的研究應著重於擴展語言涵蓋範圍，將資料安全和隱私管理 (DSPM) 與資料遺失防護 (DLP) 工具整合，以及加強法規遵循以利更廣泛的全球採用。

##### **WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch**
2502.05783v1 by Ying Lei, Yancheng Cao, Will Wang, Yuanzhe Dong, Changchang Yin, Weidan Cao, Ping Zhang, Jingzhen Yang, Bingsheng Yao, Yifan Peng, Chunhua Weng, Randy Auerbach, Lena Mamykina, Dakuo Wang, Yuntao Wang, Xuhai Xu

While just-in-time interventions (JITIs) have effectively targeted common
health behaviors, individuals often have unique needs to intervene in personal
undesirable actions that can negatively affect physical, mental, and social
well-being. We present WatchGuardian, a smartwatch-based JITI system that
empowers users to define custom interventions for these personal actions with a
small number of samples. For the model to detect new actions based on limited
new data samples, we developed a few-shot learning pipeline that finetuned a
pre-trained inertial measurement unit (IMU) model on public hand-gesture
datasets. We then designed a data augmentation and synthesis process to train
additional classification layers for customization. Our offline evaluation with
26 participants showed that with three, five, and ten examples, our approach
achieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of
74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to
compare WatchGuardian against a rule-based intervention. Our results
demonstrated that our system led to a significant reduction by 64.0 +- 22.6% in
undesirable actions, substantially outperforming the baseline by 29.0%. Our
findings underscore the effectiveness of a customizable, AI-driven JITI system
for individuals in need of behavioral intervention in personal undesirable
actions. We envision that our work can inspire broader applications of
user-defined personalized intervention with advanced AI solutions.

摘要：<paragraph>雖然即時介入（JITIs）有效地針對常見的健康行為，但個人通常有獨特的需求來介入可能會對身心和社會福祉產生負面影響的個人不良行為。我們提出 WatchGuardian，這是一個基於智慧手錶的 JITI 系統，它使用少數樣本讓使用者能夠為這些個人行為定義自訂介入措施。為了讓模型根據有限的新資料樣本偵測新行為，我們開發了一個小樣本學習管道，微調了公共手勢資料集上的預訓練慣性測量單元（IMU）模型。然後，我們設計了一個資料擴充和合成流程，以訓練其他分類層以進行自訂。我們對 26 位參與者進行的離線評估顯示，我們的做法使用三個、五個和十個範例，達到了 76.8%、84.7% 和 87.7% 的平均準確度，以及 74.8%、84.2% 和 87.2% 的 F1 分數。然後，我們進行了一項為時四小時的介入研究，以將 WatchGuardian 與基於規則的介入進行比較。我們的結果表明，我們的系統導致不良行為顯著減少了 64.0 +- 22.6%，大幅優於基線 29.0%。我們的研究結果強調了可自訂、AI 驅動的 JITI 系統對需要行為介入以應對個人不良行為的個人的有效性。我們預計我們的研究可以激勵使用者定義個人化介入的更廣泛應用，並採用先進的 AI 解決方案。</paragraph>

##### **RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care**
2502.05740v1 by Ziqi Yang, Yuxuan Lu, Jennifer Bagdasarian, Vedant Das Swain, Ritu Agarwal, Collin Campbell, Waddah Al-Refaire, Jehan El-Bayoumi, Guodong Gao, Dakuo Wang, Bingsheng Yao, Nawar Shara

Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group
of cancers that account for more than 35% of cancer-related deaths worldwide,
but postoperative complications are unpredictable and can be life-threatening.
In this paper, we investigate how recent advancements in large language models
(LLMs) can benefit remote patient monitoring (RPM) systems through clinical
integration by designing RECOVER, an LLM-powered RPM system for postoperative
GI cancer care. To closely engage stakeholders in the design process, we first
conducted seven participatory design sessions with five clinical staff and
interviewed five cancer patients to derive six major design strategies for
integrating clinical guidelines and information needs into LLM-based RPM
systems. We then designed and implemented RECOVER, which features an
LLM-powered conversational agent for cancer patients and an interactive
dashboard for clinical staff to enable efficient postoperative RPM. Finally, we
used RECOVER as a pilot system to assess the implementation of our design
strategies with four clinical staff and five patients, providing design
implications by identifying crucial design elements, offering insights on
responsible AI, and outlining opportunities for future LLM-powered RPM systems.

摘要：癌症手術是胃腸道 (GI) 癌症的主要治療方式，這類癌症佔全球癌症相關死亡人數的 35% 以上，但術後併發症無法預測，且可能危及生命。在本文中，我們探討大型語言模型 (LLM) 的近期進展如何透過臨床整合造福遠端病患監控 (RPM) 系統，方法是設計 RECOVER，一個由 LLM 驅動的 RPM 系統，用於術後胃腸道癌症照護。為了讓利害關係人密切參與設計流程，我們首先與五位臨床人員進行七場參與式設計會議，並訪談五位癌症患者，以找出六項整合臨床指南和資訊需求至基於 LLM 的 RPM 系統的主要設計策略。接著，我們設計並實作 RECOVER，其特色在於一個由 LLM 驅動的對話式代理人，供癌症患者使用，以及一個互動式儀表板，供臨床人員使用，以進行有效的術後 RPM。最後，我們使用 RECOVER 作為試點系統，與四位臨床人員和五位患者評估我們設計策略的實作，並透過找出重要的設計元素、提供對負責任 AI 的見解，以及概述未來由 LLM 驅動的 RPM 系統的機會，提出設計意涵。

##### **4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis**
2502.05713v1 by An Zhao, Moucheng Xu, Ahmed H. Shahin, Wim Wuyts, Mark G. Jones, Joseph Jacob, Daniel C. Alexander

Understanding the progression trajectories of diseases is crucial for early
diagnosis and effective treatment planning. This is especially vital for
life-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a
chronic, progressive lung disease with a prognosis comparable to many cancers.
Computed tomography (CT) imaging has been established as a reliable diagnostic
tool for IPF. Accurately predicting future CT scans of early-stage IPF patients
can aid in developing better treatment strategies, thereby improving survival
outcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial
Networks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF
patients at any time point. The model is trained using a two-stage approach. In
the first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the
second stage, a Neural Ordinary Differential Equation (ODE) based temporal
model is trained to capture the temporal dynamics of the quantised embeddings
generated by the encoder in the first stage. We evaluate different
configurations of our model for generating longitudinal CT scans and compare
the results against ground truth data, both quantitatively and qualitatively.
For validation, we conduct survival analysis using imaging biomarkers derived
from generated CT scans and achieve a C-index comparable to that of biomarkers
derived from the real CT scans. The survival analysis results demonstrate the
potential clinical utility inherent to generated longitudinal CT scans, showing
that they can reliably predict survival outcomes.

摘要：了解疾病的進程軌跡對於早期診斷和有效的治療計畫至關重要。這對於特發性肺纖維化 (IPF) 等威脅生命的疾病尤其重要，IPF 是一種慢性、進行性肺部疾病，其預後與許多癌症相當。電腦斷層掃描 (CT) 影像已被確立為 IPF 的可靠診斷工具。準確預測早期 IPF 患者的未來 CT 掃描有助於制定更好的治療策略，從而改善存活結果。在本文中，我們提出 4D 向量量化生成對抗網路 (4D-VQ-GAN)，這是一個模型，能夠在任何時間點生成 IPF 患者的逼真 CT 體積。該模型使用兩階段方法進行訓練。在第一階段，訓練 3D-VQ-GAN 以重建 CT 體積。在第二階段，訓練基於神經常微分方程 (ODE) 的時間模型，以捕捉第一階段編碼器生成的量化嵌入的時間動態。我們評估了我們的模型的不同配置，以生成縱向 CT 掃描，並在定量和定性方面將結果與真實數據進行比較。為了驗證，我們使用從生成的 CT 掃描中得出的影像生物標記進行存活分析，並獲得與從真實 CT 掃描中得出的生物標記相當的 C 指數。存活分析結果證明了生成縱向 CT 掃描固有的潛在臨床效用，表明它們可以可靠地預測存活結果。

##### **KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy**
2502.05651v1 by Hyunjong Kim, Suyeon Lee, Yeongjae Cho, Eunseo Ryu, Yohan Jo, Suran Seong, Sungzoon Cho

The increasing demand for mental health services has led to the rise of
AI-driven mental health chatbots, though challenges related to privacy, data
collection, and expertise persist. Motivational Interviewing (MI) is gaining
attention as a theoretical basis for boosting expertise in the development of
these chatbots. However, existing datasets are showing limitations for training
chatbots, leading to a substantial demand for publicly available resources in
the field of MI and psychotherapy. These challenges are even more pronounced in
non-English languages, where they receive less attention. In this paper, we
propose a novel framework that simulates MI sessions enriched with the
expertise of professional therapists. We train an MI forecaster model that
mimics the behavioral choices of professional therapists and employ Large
Language Models (LLMs) to generate utterances through prompt engineering. Then,
we present KMI, the first synthetic dataset theoretically grounded in MI,
containing 1,000 high-quality Korean Motivational Interviewing dialogues.
Through an extensive expert evaluation of the generated dataset and the
dialogue model trained on it, we demonstrate the quality, expertise, and
practicality of KMI. We also introduce novel metrics derived from MI theory in
order to evaluate dialogues from the perspective of MI.

摘要：由於對心理健康服務的需求日益增加，導致以人工智慧為基礎的心理健康聊天機器人興起，儘管與隱私、資料蒐集和專業知識相關的挑戰依然存在。動機性訪談 (MI) 正作為提升這些聊天機器人在開發方面專業知識的理論基礎而備受關注。然而，現有的資料集顯示出訓練聊天機器人的限制，導致對 MI 和心理治療領域中公開可用資源的需求大幅增加。這些挑戰在非英語語言中更加明顯，因為它們受到的關注較少。在本文中，我們提出了一個新穎的架構，它模擬了豐富專業治療師專業知識的 MI 課程。我們訓練了一個 MI 預測模型，它模擬了專業治療師的行為選擇，並採用大型語言模型 (LLM) 透過提示工程來產生話語。然後，我們展示了 KMI，這是第一個理論上以 MI 為基礎的合成資料集，其中包含 1,000 個高品質的韓語動機性訪談對話。透過對所產生的資料集和在該資料集上訓練的對話模型進行廣泛的專家評估，我們展示了 KMI 的品質、專業知識和實用性。我們還引入了從 MI 理論中衍生的新指標，以便從 MI 的角度評估對話。

##### **ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports**
2502.05638v1 by Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, Carlos A Velasco

Europe's healthcare systems require enhanced interoperability and
digitalization, driving a demand for innovative solutions to process legacy
clinical data. This paper presents the results of our project, which aims to
leverage Large Language Models (LLMs) to extract structured information from
unstructured clinical reports, focusing on patient history, diagnoses,
treatments, and other predefined categories. We developed a workflow with a
user interface and evaluated LLMs of varying sizes through prompting strategies
and fine-tuning. Our results show that fine-tuned smaller models match or
surpass larger counterparts in performance, offering efficiency for
resource-limited settings. A new dataset of 60,000 annotated English clinical
summaries and 24,000 German translations was validated with automated and
manual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics.
The work highlights the approach's viability and outlines future improvements.

摘要：歐洲的醫療保健系統需要增強互通性和數位化，這驅動了對創新解決方案的需求，以處理傳統的臨床數據。本文介紹了我們專案的成果，該專案旨在利用大型語言模型 (LLM) 從非結構化的臨床報告中提取結構化的資訊，重點放在病歷、診斷、治療和其他預定義類別上。我們開發了一個具有使用者介面的工作流程，並透過提示策略和微調來評估不同規模的 LLM。我們的結果顯示，微調後的較小模型在效能上與較大的模型相匹配或超越它們，為資源有限的環境提供了效率。一個包含 60,000 個註解英文臨床摘要和 24,000 個德文翻譯的新資料集已透過自動化和手動檢查進行驗證。評估使用了 ROUGE、BERTScore 和實體層級的指標。這項工作突出了這種方法的可行性，並概述了未來的改進。

##### **Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection**
2502.05494v1 by Ya Zhou, Yujie Yang, Jianhuang Gan, Xiangjie Li, Jing Yuan, Wei Zhao

Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing
cardiovascular conditions, yet anomaly detection in ECG signals remains
challenging due to their inherent complexity and variability. We propose
Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel
end-to-end framework that effectively captures both global and local
dependencies in ECG data. Unlike state-of-the-art methods that rely on
heartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for
such pre-processing steps, enhancing its suitability for clinical deployment.
MMAE-ECG partitions ECG signals into non-overlapping segments, with each
segment assigned learnable positional embeddings. A novel multi-scale masking
strategy and multi-scale attention mechanism, along with distinct positional
embeddings, enable a lightweight Transformer encoder to effectively capture
both local and global dependencies. The masked segments are then reconstructed
using a single-layer Transformer block, with an aggregation strategy employed
during inference to refine the outputs. Experimental results demonstrate that
our method achieves performance comparable to state-of-the-art approaches while
significantly reducing computational complexity-approximately 1/78 of the
floating-point operations (FLOPs) required for inference. Ablation studies
further validate the effectiveness of each component, highlighting the
potential of multi-scale masked autoencoders for anomaly detection.

摘要：心電圖 (ECG) 分析是診斷心血管疾病的基本工具，但由於 ECG 訊號本身的複雜性和變異性，異常偵測仍然是一項挑戰。我們提出用於 ECG 異常偵測的多尺度遮罩自編碼器 (MMAE-ECG)，這是一個新穎的端對端架構，可有效擷取 ECG 資料中的全局和局部依賴關係。與依賴於心跳區段或 R 波峰偵測的最新方法不同，MMAE-ECG 消除了對此類前處理步驟的需求，增強其適用於臨床部署。MMAE-ECG 將 ECG 訊號分割成不相疊的區段，每個區段都指派可學習的位置嵌入。新穎的多尺度遮罩策略和多尺度注意力機制，以及不同的位置嵌入，使輕量級 Transformer 編碼器能夠有效擷取局部和全局依賴關係。然後使用單層 Transformer 區塊重建遮罩區段，並在推理期間採用聚合策略來優化輸出。實驗結果表明，我們的模型達到了與最新方法相當的效能，同時大幅降低運算複雜度，約為推理所需的浮點運算 (FLOP) 的 1/78。消融研究進一步驗證了每個組件的有效性，突顯了多尺度遮罩自編碼器在異常偵測方面的潛力。

##### **DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability**
2502.05459v1 by Sibasish Dhibar

White blood cells (WBC) are important parts of our immune system, and they
protect our body against infections by eliminating viruses, bacteria, parasites
and fungi. The number of WBC types and the total number of WBCs provide
important information about our health status. A traditional method,
convolutional neural networks (CNN), a deep learning architecture, can classify
the blood cell from a part of an object and perform object recognition. Various
CNN models exhibit potential; however, their development often involves ad-hoc
processes that neglect unnecessary layers, leading to issues with unbalanced
datasets and insufficient data augmentation. To address these challenges, we
propose a novel ensemble approach that integrates three CNN architectures, each
uniquely configured with different dropout and max-pooling layer settings to
enhance feature learning. This ensemble model, named DCENWCNet, effectively
balances the bias-variance trade-off. When evaluated on the widely recognized
Rabbin-WBC dataset, our model outperforms existing state-of-the-art networks,
achieving highest mean accuracy. Additionally, it demonstrates superior
performance in precision, recall, F1-score, and Area Under the ROC Curve (AUC)
across all categories. To delve deeper into the interpretability of
classifiers, we employ reliable post-hoc explanation techniques, including
Local Interpretable Model-Agnostic Explanations (LIME). These methods
approximate the behavior of a black-box model by elucidating the relationships
between feature values and predictions. Interpretable results enable users to
comprehend and validate the model's predictions, thereby increasing their
confidence in the automated diagnosis.

摘要：白血球 (WBC) 是我們免疫系統的重要組成部分，它們通過清除病毒、細菌、寄生蟲和真菌來保護我們的機體免受感染。WBC 類型數量和 WBC 總數提供了有關我們健康狀況的重要資訊。傳統方法卷積神經網路 (CNN) 是一種深度學習架構，可以對物體的一部分進行血細胞分類並執行物體識別。各種 CNN 模型展現出潛力；然而，它們的開發通常涉及忽略不必要層的臨時過程，導致不平衡的資料集和資料擴充不足的問題。為了應對這些挑戰，我們提出了一種新穎的整體方法，它整合了三種 CNN 架構，每種架構都採用不同的中斷和最大池化層設定進行獨特配置，以增強特徵學習。這種名為 DCENWCNet 的整體模型有效地平衡了偏差變異取捨。在廣泛認可的 Rabbin-WBC 資料集上進行評估時，我們的模型優於現有的最先進網路，達到了最高的平均準確度。此外，它在所有類別中都展示了在精確度、召回率、F1 分數和 ROC 曲線下面積 (AUC) 方面的卓越效能。為了更深入地研究分類器的可解釋性，我們採用了可靠的事後解釋技術，包括局部可解釋模型不可知解釋 (LIME)。這些方法通過闡明特徵值和預測之間的關係來近似黑盒模型的行為。可解釋的結果使用戶能夠理解和驗證模型的預測，從而增加他們對自動化診斷的信心。

##### **Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge**
2502.05330v1 by Muhammad Imran, Jonathan R. Krebs, Vishal Balaji Sivaraman, Teng Zhang, Amarjeet Kumar, Walker R. Ueland, Michael J. Fassler, Jinlong Huang, Xiao Sun, Lisheng Wang, Pengcheng Shi, Maximilian Rokuss, Michael Baumgartner, Yannick Kirchhof, Klaus H. Maier-Hein, Fabian Isensee, Shuolin Liu, Bing Han, Bong Thanh Nguyen, Dong-jin Shin, Park Ji-Woo, Mathew Choi, Kwang-Hyun Uhm, Sung-Jea Ko, Chanwoong Lee, Jaehee Chun, Jin Sung Kim, Minghui Zhang, Hanxiao Zhang, Xin You, Yun Gu, Zhaohong Pan, Xuan Liu, Xiaokun Liang, Markus Tiefenthaler, Enrique Almar-Munoz, Matthias Schwab, Mikhail Kotyushev, Rostislav Epifanov, Marek Wodzinski, Henning Muller, Abdul Qayyum, Moona Mazher, Steven A. Niederer, Zhiwei Wang, Kaixiang Yang, Jintao Ren, Stine Sofia Korreman, Yuchong Gao, Hongye Zeng, Haoyu Zheng, Rui Zheng, Jinghua Yue, Fugen Zhou, Bo Liu, Alexander Cosman, Muxuan Liang, Chang Zhao, Gilbert R. Upchurch Jr., Jun Ma, Yuyin Zhou, Michol A. Cooper, Wei Shao

Multi-class segmentation of the aorta in computed tomography angiography
(CTA) scans is essential for diagnosing and planning complex endovascular
treatments for patients with aortic dissections. However, existing methods
reduce aortic segmentation to a binary problem, limiting their ability to
measure diameters across different branches and zones. Furthermore, no
open-source dataset is currently available to support the development of
multi-class aortic segmentation methods. To address this gap, we organized the
AortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes
annotated for 23 clinically relevant aortic branches and zones. This dataset
was designed to facilitate both model development and validation. The challenge
attracted 121 teams worldwide, with participants leveraging state-of-the-art
frameworks such as nnU-Net and exploring novel techniques, including cascaded
models, data augmentation strategies, and custom loss functions. We evaluated
the submitted algorithms using the Dice Similarity Coefficient (DSC) and
Normalized Surface Distance (NSD), highlighting the approaches adopted by the
top five performing teams. This paper presents the challenge design, dataset
details, evaluation metrics, and an in-depth analysis of the top-performing
algorithms. The annotated dataset, evaluation code, and implementations of the
leading methods are publicly available to support further research. All
resources can be accessed at https://aortaseg24.grand-challenge.org.

摘要：多類別主動脈電腦斷層血管攝影 (CTA) 掃描分割對於診斷和規劃主動脈剝離患者的複雜血管內治療至關重要。然而，現有方法將主動脈分割簡化為二元問題，限制了其測量不同分支和區域直徑的能力。此外，目前沒有開放原始碼數據集可用於支援多類別主動脈分割方法的開發。為了解決此問題，我們組織了 AortaSeg24 MICCAI 挑戰，引入了第一個包含 100 個 CTA 體積的數據集，這些體積針對 23 個臨床上相關的主動脈分支和區域進行了註釋。此數據集旨在促進模型開發和驗證。該挑戰吸引了來自世界各地的 121 個團隊，參與者利用了 nnU-Net 等最先進的框架，並探索了創新技術，包括串聯模型、數據擴充策略和自訂損失函數。我們使用 Dice 相似性係數 (DSC) 和標準化表面距離 (NSD) 評估了提交的演算法，重點介紹了前五名表現最佳團隊採用的方法。本文介紹了挑戰設計、數據集詳細資訊、評估指標以及對表現最佳演算法的深入分析。已公開註釋的數據集、評估程式碼和領先方法的實作，以支援進一步的研究。所有資源都可以在 https://aortaseg24.grand-challenge.org/ 獲得。

##### **Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning**
2502.05282v1 by Yuting He, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li

Dense contrastive representation learning (DCRL) has greatly improved the
learning efficiency for image-dense prediction tasks, showing its great
potential to reduce the large costs of medical image collection and dense
annotation. However, the properties of medical images make unreliable
correspondence discovery, bringing an open problem of large-scale false
positive and negative (FP&N) pairs in DCRL. In this paper, we propose GEoMetric
vIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism prior
to DCRL and enables a reliable correspondence discovery for effective dense
contrast. We propose a deformable homeomorphism learning (DHL) which models the
homeomorphism of medical images and learns to estimate a deformable mapping to
predict the pixels' correspondence under topological preservation. It
effectively reduces the searching space of pairing and drives an implicit and
soft learning of negative pairs via a gradient. We also propose a geometric
semantic similarity (GSS) which extracts semantic information in features to
measure the alignment degree for the correspondence learning. It will promote
the learning efficiency and performance of deformation, constructing positive
pairs reliably. We implement two practical variants on two typical
representation learning tasks in our experiments. Our promising results on
seven datasets which outperform the existing methods show our great
superiority. We will release our code on a companion link:
https://github.com/YutingHe-list/GEMINI.

摘要：密集对比表征学习（DCRL）极大地提高了影像密集预测任务的学习效率，显示出其在降低医学影像收集和密集标注的大量成本方面的巨大潜力。然而，医学影像的特性使得对应关系发现不可靠，给 DCRL 带来大规模假阳性和假阴性（FP&N）对的开放性问题。在本文中，我们提出了 GEoMetric vIsual deNse sImilarity（GEMINI）学习，它将同胚先验嵌入 DCRL 中，并针对有效密集对比提供了可靠的对应关系发现。我们提出了一种可变形同胚学习（DHL），它对医学影像的同胚进行建模，并学习估计可变形映射，以预测在拓扑保持下的像素对应关系。它有效地减少了配对的搜索空间，并通过梯度驱动了负对的隐式和软学习。我们还提出了几何语义相似性（GSS），它提取特征中的语义信息，以测量对应关系学习的对齐度。它将促进变形学习的效率和性能，可靠地构建正对。我们在实验中针对两个典型的表征学习任务实现了两个实际变体。我们在七个数据集上的有希望的结果优于现有方法，显示出我们的巨大优势。我们将在配套链接中发布我们的代码：https://github.com/YutingHe-list/GEMINI。

##### **"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**
2502.05115v1 by Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang

Older adult patients constitute a rapidly growing subgroup of Intensive Care
Unit (ICU) patients. In these situations, their family caregivers are expected
to represent the unconscious patients to access and interpret patients' medical
information. However, caregivers currently have to rely on overloaded
clinicians for information updates and typically lack the health literacy to
understand complex medical information. Our project aims to explore the
information needs of caregivers of ICU older adult patients, from which we can
propose design opportunities to guide future AI systems. The project begins
with formative interviews with 11 caregivers to identify their challenges in
accessing and interpreting medical information; From these findings, we then
synthesize design requirements and propose an AI system prototype to cope with
caregivers' challenges. The system prototype has two key features: a timeline
visualization to show the AI extracted and summarized older adult patients' key
medical events; and an LLM-based chatbot to provide context-aware informational
support. We conclude our paper by reporting on the follow-up user evaluation of
the system and discussing future AI-based systems for ICU caregivers of older
adults.

摘要：老年患者構成加護病房 (ICU) 患者中快速成長的子群。在這些情況下，預期他們的家庭照護者能代表無意識的患者取得並解讀患者的醫療資訊。然而，照護者目前必須依賴工作繁重的臨床醫師提供資訊更新，而且通常缺乏了解複雜醫療資訊的健康素養。我們的專案旨在探索 ICU 老年患者照護者的資訊需求，我們可以根據這些需求提出設計機會，以引導未來的 AI 系統。這個專案從對 11 位照護者的形成性訪談開始，以找出他們在取得和解讀醫療資訊方面的挑戰；根據這些發現，我們接著綜合設計需求，並提出一個 AI 系統原型，以應對照護者的挑戰。這個系統原型具有兩個關鍵特點：一個時間軸視覺化，以顯示 AI 萃取並摘要出的老年患者關鍵醫療事件；以及一個基於 LLM 的聊天機器人，以提供情境感知的資訊支援。我們透過報告系統的後續使用者評估，以及討論未來針對老年人 ICU 照護者的 AI 系統，來總結我們的論文。

##### **Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**
2502.05087v1 by Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi

Federated learning (FL) is a popular paradigm for collaborative training
which avoids direct data exposure between clients. However, data privacy issues
still remain: FL-trained large language models are capable of memorizing and
completing phrases and sentences contained in training data when given with
their prefixes. Thus, it is possible for adversarial and honest-but-curious
clients to recover training data of other participants simply through targeted
prompting. In this work, we demonstrate that a popular and simple fine-tuning
strategy, low-rank adaptation (LoRA), reduces memorization during FL up to a
factor of 10. We study this effect by performing a medical question-answering
fine-tuning task and injecting multiple replicas of out-of-distribution
sensitive sequences drawn from an external clinical dataset. We observe a
reduction in memorization for a wide variety of Llama 2 and 3 models, and find
that LoRA can reduce memorization in centralized learning as well. Furthermore,
we show that LoRA can be combined with other privacy-preserving techniques such
as gradient clipping and Gaussian noising, secure aggregation, and Goldfish
loss to further improve record-level privacy while maintaining performance.

摘要：聯邦學習 (FL) 是一種流行的協作訓練範例，可避免客戶端之間直接公開資料。然而，資料隱私問題仍然存在：經過 FL 訓練的大型語言模型能夠記憶並完成訓練資料中包含的片語和句子，只要給予其前綴即可。因此，對抗和誠實但好奇的客戶端有可能僅透過目標提示來恢復其他參與者的訓練資料。在這項工作中，我們證明了一種流行且簡單的微調策略，低秩適應 (LoRA)，可將 FL 期間的記憶減少多達 10 倍。我們透過執行醫學問答微調任務並注入從外部臨床資料集抽取的非分佈敏感序列的多次複製品來研究此效應。我們觀察到各種 Llama 2 和 3 模型的記憶力降低，並發現 LoRA 也能減少集中式學習中的記憶力。此外，我們展示 LoRA 可以與其他隱私保護技術結合使用，例如梯度裁剪和高斯雜訊、安全聚合和 Goldfish 損失，以進一步改善記錄級隱私，同時維持效能。

##### **MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**
2502.04794v1 by Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo

Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is
introduced as a multimodal framework inspired by real-world diagnostic
processes. It uses pretrained models such as DINOv2, Vision Transformer, and
ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into
low-dimensional, semantically meaningful features. A learnable
self-attention-based fusion network then integrates these imaging features with
clinical data for classification. Using 416 FUO patient cases from Sichuan
University West China Hospital from 2017 to 2023, the multimodal fusion
classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to
0.9291 across seven tasks, outperforming conventional machine learning and
single-modality deep learning methods. Ablation studies and five-fold
cross-validation further validated its effectiveness. By combining the
strengths of pretrained large models and deep learning, MedMimic offers a
promising solution for disease classification.

摘要：不明原因發燒 (FUO) 仍然是診斷上的挑戰。MedMimic 是一個多模式架構，靈感來自於真實世界的診斷過程。它使用預先訓練的模型，例如 DINOv2、視覺轉換器和 ResNet-18，將高維 18F-FDG PET/CT 影像轉換為低維、語義有意義的特徵。一個可學習的自注意力融合網路接著將這些影像特徵與臨床資料整合，用於分類。使用 2017 年至 2023 年四川大學華西醫院的 416 個 FUO 病患病例，多模式融合分類網路 MFCN 在七項任務中達到了 0.8654 到 0.9291 的巨觀 AUROC 分數，優於傳統機器學習和單一模式深度學習方法。消融研究和五倍交叉驗證進一步驗證了其有效性。MedMimic 結合了預先訓練的大模型和深度學習的優點，為疾病分類提供了一個有前景的解決方案。

##### **MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**
2502.04515v1 by Wei Fan, Jingru Fei, Dingyu Guo, Kun Yi, Xiaozhuang Song, Haolong Xiang, Hangting Ye, Min Li

Medical time series has been playing a vital role in real-world healthcare
systems as valuable information in monitoring health conditions of patients.
Accurate classification for medical time series, e.g., Electrocardiography
(ECG) signals, can help for early detection and diagnosis. Traditional methods
towards medical time series classification rely on handcrafted feature
extraction and statistical methods; with the recent advancement of artificial
intelligence, the machine learning and deep learning methods have become more
popular. However, existing methods often fail to fully model the complex
spatial dynamics under different scales, which ignore the dynamic
multi-resolution spatial and temporal joint inter-dependencies. Moreover, they
are less likely to consider the special baseline wander problem as well as the
multi-view characteristics of medical time series, which largely hinders their
prediction performance. To address these limitations, we propose a
Multi-resolution Spatiotemporal Graph Learning framework, MedGNN, for medical
time series classification. Specifically, we first propose to construct
multi-resolution adaptive graph structures to learn dynamic multi-scale
embeddings. Then, to address the baseline wander problem, we propose Difference
Attention Networks to operate self-attention mechanisms on the finite
difference for temporal modeling. Moreover, to learn the multi-view
characteristics, we utilize the Frequency Convolution Networks to capture
complementary information of medical time series from the frequency domain. In
addition, we introduce the Multi-resolution Graph Transformer architecture to
model the dynamic dependencies and fuse the information from different
resolutions. Finally, we have conducted extensive experiments on multiple
medical real-world datasets that demonstrate the superior performance of our
method. Our Code is available.

摘要：<paragraph>醫療時間序列在真實世界的醫療保健系統中扮演著至關重要的角色，作為監控患者健康狀況的寶貴資訊。
準確分類醫療時間序列，例如心電圖 (ECG) 訊號，有助於早期偵測和診斷。傳統的醫療時間序列分類方法仰賴手工特徵萃取和統計方法；隨著人工智慧的最新進展，機器學習和深度學習方法變得更為普及。然而，現有方法通常無法完全建模不同尺度下的複雜空間動態，忽略了動態多解析度空間和時間關節相互依賴性。此外，它們不太可能考慮特殊的基線漂移問題以及醫療時間序列的多視角特性，這在很大程度上阻礙了它們的預測效能。為了解決這些限制，我們提出了一個多解析度時空圖形學習架構 MedGNN，用於醫療時間序列分類。具體來說，我們首先提出構建多解析度自適應圖形結構以學習動態多尺度嵌入。然後，為了解決基線漂移問題，我們提出差分注意力網路，對時間建模的有限差分運算自注意力機制。此外，為了學習多視角特性，我們利用頻率卷積網路從頻域擷取醫療時間序列的互補資訊。此外，我們引入了多解析度圖形Transformer架構來建模動態依賴性，並融合來自不同解析度的資訊。最後，我們對多個醫療真實世界資料集進行了廣泛的實驗，證明了我們方法的優異效能。我們的程式碼已公開。</paragraph>

##### **Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining Diagnosis and Care in Neurodegenerative Diseases**
2502.06842v1 by Andrew G. Breithaupt, Alice Tang, Bruce L. Miller, Pedro Pinheiro-Chagas

Healthcare systems are struggling to meet the growing demand for neurological
care, with challenges particularly acute in Alzheimer's disease and related
dementias (ADRD). While artificial intelligence research has often focused on
identifying patterns beyond human perception, implementing such predictive
capabilities remains challenging as clinicians cannot readily verify insights
they cannot themselves detect. We propose that large language models (LLMs)
offer more immediately practical applications by enhancing clinicians'
capabilities in three critical areas: comprehensive data collection,
interpretation of complex clinical information, and timely application of
relevant medical knowledge. These challenges stem from limited time for proper
diagnosis, growing data complexity, and an overwhelming volume of medical
literature that exceeds any clinician's capacity to fully master. We present a
framework for responsible AI integration that leverages LLMs' ability to
communicate effectively with both patients and providers while maintaining
human oversight. This approach prioritizes standardized, high-quality data
collection to enable a system that learns from every patient encounter while
incorporating the latest clinical evidence, continuously improving care
delivery. We begin to address implementation challenges and initiate important
discussions around ethical considerations and governance needs. While developed
for ADRD, this roadmap provides principles for responsible AI integration
across neurology and other medical specialties, with potential to improve
diagnostic accuracy, reduce care disparities, and advance clinical knowledge
through a learning healthcare system.

摘要：醫療體系正努力滿足日益增長的神經照護需求，其中阿茲海默症和相關失智症 (ADRD) 的挑戰特別嚴重。雖然人工智慧研究通常專注於識別人類感知之外的模式，但實作此類預測功能仍然具有挑戰性，因為臨床醫生無法輕易驗證他們自己無法偵測到的見解。我們提出大型語言模型 (LLM) 可透過提升臨床醫生在三個關鍵領域的能力，提供更直接且實用的應用：全面的資料收集、複雜臨床資訊的詮釋，以及適時應用相關的醫學知識。這些挑戰源自於適當診斷時間有限、資料複雜性日益增加，以及龐大的醫學文獻量超過任何臨床醫生所能完全掌握的容量。我們提出了一個負責任的 AI 整合架構，利用 LLM 與患者和提供者有效溝通的能力，同時維持人為監督。此方法優先考慮標準化、高品質的資料收集，以建立一個從每次患者接觸中學習的系統，同時納入最新的臨床證據，持續改善照護提供。我們開始探討實作挑戰，並展開關於倫理考量和治理需求的重要討論。儘管是為 ADRD 所開發，此藍圖提供了神經科和其他醫學專科負責任 AI 整合的原則，有潛力透過學習型醫療保健系統改善診斷準確性、減少照護差異，並推進臨床知識。

##### **Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**
2502.04423v1 by Khushboo Verma, Alan Michels, Ergi Gumusaneli, Shilpa Chitnis, Smita Sinha Kumar, Christopher Thompson, Lena Esmail, Guruprasath Srinivasan, Chandini Panchada, Sushovan Guha, Satwant Kumar

Referral workflow inefficiencies, including misaligned referrals and delays,
contribute to suboptimal patient outcomes and higher healthcare costs. In this
study, we investigated the possibility of predicting procedural needs based on
primary care diagnostic entries, thereby improving referral accuracy,
streamlining workflows, and providing better care to patients. A de-identified
dataset of 2,086 orthopedic referrals from the University of Texas Health at
Tyler was analyzed using machine learning models built on Base General
Embeddings (BGE) for semantic extraction. To ensure real-world applicability,
noise tolerance experiments were conducted, and oversampling techniques were
employed to mitigate class imbalance. The selected optimum and parsimonious
embedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, Matthews
Correlation Coefficient (MCC): 0.540), effectively distinguishing patients
requiring surgical intervention. Dimensionality reduction techniques confirmed
the model's ability to capture meaningful clinical relationships. A threshold
sensitivity analysis identified an optimal decision threshold (0.30) to balance
precision and recall, maximizing referral efficiency. In the predictive
modeling analysis, the procedure rate increased from 11.27% to an optimal
60.1%, representing a 433% improvement with significant implications for
operational efficiency and healthcare revenue.
  The results of our study demonstrate that referral optimization can enhance
primary and surgical care integration. Through this approach, precise and
timely predictions of procedural requirements can be made, thereby minimizing
delays, improving surgical planning, and reducing administrative burdens. In
addition, the findings highlight the potential of clinical decision support as
a scalable solution for improving patient outcomes and the efficiency of the
healthcare system.

摘要：轉診流程效率低落，包括轉診不當和延誤，
導致次優的患者結果和更高的醫療保健成本。在這
項研究中，我們探討了根據初級保健診斷條目預測程序需求的可能性，從而提高轉診準確性，
簡化工作流程，並為患者提供更好的照護。一個去識別化
德克薩斯大學健康中心的 2,086 個骨科轉診的資料集
泰勒使用建立在基本通用
語義提取的嵌入 (BGE) 上的機器學習模型進行分析。為了確保現實世界的適用性，
進行了噪聲容忍度實驗，並採用了過採樣技術來減輕類別不平衡。所選的最佳和簡約
嵌入模型展示了高預測準確度 (ROC-AUC：0.874，馬修斯
相關系數 (MCC)：0.540)，有效區分需要手術干預的患者。降維
技術證實了模型捕捉有意義的臨床關係的能力。閾值
敏感性分析確定了一個最佳決策閾值 (0.30) 來平衡
精確度和召回率，最大化轉診效率。在預測中
建模分析中，程序率從 11.27% 增加到最佳的
60.1%，代表 433% 的改進，對運營效率和醫療保健收入具有重大影響。
我們研究的結果表明，轉診優化可以增強
初級和外科護理整合。通過這種方法，可以對程序需求進行準確及時的預測，從而最大程度地減少
延誤，改善手術計劃，並減輕行政負擔。此外，研究結果強調了臨床決策支持作為
一個可擴展的解決方案的潛力，用於改善患者結果和醫療保健系統的效率。

##### **Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**
2502.04083v1 by Tewele W. Tareke, Neree Payan, Alexandre Cochet, Laurent Arnould, Benoit Presles, Jean-Marc Vrigneaud, Fabrice Meriaudeau, Alain Lalande

Neoadjuvant chemotherapy (NAC) has become a standard clinical practice for
tumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography
(PET). Our work aims to leverage PET imaging for the segmentation of breast
lesions. The focus is on developing an automated system that accurately
segments primary tumor regions and extracts key biomarkers from these areas to
provide insights into the evolution of breast cancer following the first course
of NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PET
scans (PET_Fu) were acquired before and after the first course of NAC,
respectively. Firstly, a deep learning-based breast tumor segmentation method
was developed. The optimal baseline model (model trained on baseline exams) was
fine-tuned on 15 follow-up exams and adapted using active learning to segment
tumor areas in PET_Fu. The pipeline computes biomarkers such as maximum
standardized uptake value (SUVmax), metabolic tumor volume (MTV), and total
lesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.
Quality control measures were employed to exclude aberrant outliers. The nnUNet
deep learning model outperformed in tumor segmentation on PET_Bl, achieved a
Dice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52
mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mm
on PET_Fu exams. Biomarkers analysis revealed very strong correlations whatever
the biomarker between manually segmented and automatically predicted regions.
The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3
and 19.23 cm3, respectively. The presented approach demonstrates an automated
system for breast tumor segmentation from 18F-FDG PET. Thanks to the extracted
biomarkers, our method enables the automatic assessment of cancer progression.

摘要：新辅助化疗 (NAC) 已成为乳腺癌中采用 18F-FDG 正电子发射断层扫描 (PET) 进行肿瘤缩小的标准临床实践。我们的工作旨在利用 PET 影像分割乳腺病变。重点在于开发一个自动系统，该系统可以准确分割原发性肿瘤区域并从这些区域提取关键生物标记，以深入了解乳腺癌在第一疗程 NAC 后的演变。分别在第一疗程 NAC 之前和之后采集了 243 例基线 18F-FDG PET 扫描 (PET_Bl) 和 180 例随访 18F-FDG PET 扫描 (PET_Fu)。首先，开发了一种基于深度学习的乳腺肿瘤分割方法。对 15 例随访检查对最优基线模型（在基线检查中训练的模型）进行了微调，并使用主动学习对 PET_Fu 中的肿瘤区域进行了分割。该管道计算诸如最大标准摄取值 (SUVmax)、代谢肿瘤体积 (MTV) 和总病灶糖酵解 (TLG) 等生物标记，以评估 PET_Fu 和 PET_Bl 之间的肿瘤演变。采用质量控制措施来排除异常值。nnUNet 深度学习模型在 PET_Bl 上的肿瘤分割方面表现出色，达到 0.89 的 Dice 相似性系数 (DSC) 和 3.52 毫米的 Hausdorff 距离 (HD)。微调后，该模型在 PET_Fu 检查中显示出 0.78 的 DSC 和 4.95 毫米的 HD。无论手动分割区域和自动预测区域之间的生物标记如何，生物标记分析都显示出非常强的相关性。SUVmax、MTV 和 TLG 的平均显着下降分别为 5.22、11.79 cm3 和 19.23 cm3。所提出的方法展示了一个用于从 18F-FDG PET 分割乳腺肿瘤的自动化系统。由于提取了生物标记，我们的方法能够自动评估癌症进展。

##### **Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**
2502.04034v1 by Ran Song, Yinpu Bai, Hui Liu

The accurate prediction of drug responses remains a formidable challenge,
particularly at the single-cell level and in clinical treatment contexts. Some
studies employ transfer learning techniques to predict drug responses in
individual cells and patients, but they require access to target-domain data
during training, which is often unavailable or only obtainable in future. In
this study, we propose a novel domain generalization framework, termed
panCancerDR, to address this challenge. We conceptualize each cancer type as a
distinct source domain, with its cell lines serving as domain-specific samples.
Our primary objective is to extract domain-invariant features from the
expression profiles of cell lines across diverse cancer types, thereby
generalize the predictive capacity to out-of-distribution samples. To enhance
robustness, we introduce a latent independence projection (LIP) module that
encourages the encoder to extract informative yet non-redundant features. Also,
we propose an asymmetric adaptive clustering constraint, which clusters
drug-sensitive samples into a compact group while drives resistant samples
dispersed across separate clusters in the latent space. Our empirical
experiments demonstrate that panCancerDR effectively learns task-relevant
features from diverse source domains, and achieves accurate predictions of drug
response for unseen cancer type during training. Furthermore, when evaluated on
single-cell and patient-level prediction tasks, our model-trained solely on in
vitro cell line data without access to target-domain information-consistently
outperforms and matched current state-of-the-art methods. These findings
highlights the potential of our method for real-world clinical applications.

摘要：<paragraph>準確預測藥物反應仍然是一項艱鉅的挑戰，特別是在單細胞層級和臨床治療背景中。一些研究採用遷移學習技術來預測個別細胞和患者的藥物反應，但它們需要在訓練期間存取目標網域資料，而這些資料通常無法取得，或只能在未來取得。在這項研究中，我們提出一個新穎的網域概化架構，稱為 panCancerDR，以應對這項挑戰。我們將每種類型的癌症概念化為一個不同的來源網域，其細胞株作為特定網域的樣本。我們的首要目標是從不同癌症類型的細胞株表現特徵中萃取網域不變特徵，從而將預測能力概化到分布外的樣本。為了增強穩健性，我們引入一個潛在獨立投影 (LIP) 模組，鼓勵編碼器萃取有資訊但非冗餘的特徵。此外，我們提出一個非對稱自適應聚類約束，將對藥物敏感的樣本聚類到一個緊湊的群組中，同時驅動抗藥性樣本分散在潛在空間中的不同群組中。我們的實證實驗證明，panCancerDR 有效地從不同的來源網域學習與任務相關的特徵，並在訓練期間對未見的癌症類型實現準確的藥物反應預測。此外，當在單細胞和患者層級預測任務中進行評估時，我們的模型僅在體外細胞株資料上訓練，而沒有存取目標網域資訊，始終優於並符合當前的最新方法。這些發現突顯了我們的方法在實際臨床應用中的潛力。</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

摘要：檢索增強生成 (RAG) 是一種適用於檢索隱私敏感的電子健康記錄 (EHR) 的技術。它可以作為醫療保健副駕駛的一個關鍵模組，協助減少醫療保健從業人員和患者的誤診。然而，在醫療領域中使用的現有基於啟發法的 RAG 模型的診斷準確性和特異性不足，特別是對於具有類似表現的疾病。本文提出 MedRAG，一種由知識圖譜 (KG) 引發的推理增強的 RAG 模型，用於醫療領域，它根據表現檢索診斷和治療建議。MedRAG 系統性地構建了一個全面的四層階層式診斷 KG，涵蓋各種疾病的關鍵診斷差異。這些差異與從 EHR 資料庫中檢索到的類似 EHR 動態整合，並在大型語言模型中進行推理。這個過程可以實現更準確和具體的決策支援，同時主動提供後續問題，以增強個人化醫療決策制定。MedRAG 在公共資料集 DDXPlus 和從陳篤生醫院收集的私人慢性疼痛診斷資料集 (CPDD) 上進行評估，並將其效能與各種現有 RAG 方法進行比較。實驗結果顯示，利用 KG 的資訊整合和關係能力，我們的 MedRAG 提供了更具體的診斷見解，並在降低誤診率方面優於最先進的模型。我們的程式碼將在 https://github.com/SNOWTEAM2023/MedRAG 提供

##### **Transforming Multimodal Models into Action Models for Radiotherapy**
2502.04408v1 by Matteo Ferrante, Alessandra Carosi, Rolando Maria D Angelillo, Nicola Toschi

Radiotherapy is a crucial cancer treatment that demands precise planning to
balance tumor eradication and preservation of healthy tissue. Traditional
treatment planning (TP) is iterative, time-consuming, and reliant on human
expertise, which can potentially introduce variability and inefficiency. We
propose a novel framework to transform a large multimodal foundation model
(MLM) into an action model for TP using a few-shot reinforcement learning (RL)
approach. Our method leverages the MLM's extensive pre-existing knowledge of
physics, radiation, and anatomy, enhancing it through a few-shot learning
process. This allows the model to iteratively improve treatment plans using a
Monte Carlo simulator. Our results demonstrate that this method outperforms
conventional RL-based approaches in both quality and efficiency, achieving
higher reward scores and more optimal dose distributions in simulations on
prostate cancer data. This proof-of-concept suggests a promising direction for
integrating advanced AI models into clinical workflows, potentially enhancing
the speed, quality, and standardization of radiotherapy treatment planning.

摘要：放射治療是一種重要的癌症治療方法，需要精確的規劃來平衡腫瘤根除和健康組織的保留。傳統的治療規劃（TP）是反覆的、耗時的，並且依賴於人為專業知識，這可能會引入變異性和低效率。我們提出了一個新穎的框架，使用少次強化學習 (RL) 方法將大型多模態基礎模型 (MLM) 轉換為 TP 的動作模型。我們的模型利用了 MLM 對物理、輻射和解剖學的廣泛預先存在的知識，並通過少次學習過程對其進行增強。這允許模型使用蒙特卡羅模擬器反覆改進治療計劃。我們的結果表明，這種方法在質量和效率方面都優於基於傳統 RL 的方法，在對前列腺癌數據進行模擬時，獲得了更高的獎勵分數和更優化的劑量分佈。這個概念驗證表明了一個有希望的方向，即將先進的人工智慧模型整合到臨床工作流程中，從而有可能提高放射治療計劃的速度、質量和標準化。

##### **Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**
2502.04399v1 by Bokeng Zheng, Bo Rao, Tianxiang Zhu, Chee Wei Tan, Jingpu Duan, Zhi Zhou, Xu Chen, Xiaoxi Zhang

Advances in artificial intelligence (AI) including foundation models (FMs),
are increasingly transforming human society, with smart city driving the
evolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged as
a key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.
In particular, ride-hailing vehicles can effectively facilitate flexible data
collection and contribute towards urban intelligence, despite resource
limitations. Therefore, this work explores a promising scenario, where
edge-assisted vehicles perform joint tasks of order serving and the emerging
foundation model fine-tuning using various urban data. However, integrating the
VCS AI task with the conventional order serving task is challenging, due to
their inconsistent spatio-temporal characteristics: (i) The distributions of
ride orders and data point-of-interests (PoIs) may not coincide in geography,
both following a priori unknown patterns; (ii) they have distinct forms of
temporal effects, i.e., prolonged waiting makes orders become instantly invalid
while data with increased staleness gradually reduces its utility for model
fine-tuning.To overcome these obstacles, we propose an online framework based
on multi-agent reinforcement learning (MARL) with careful augmentation. A new
quality-of-service (QoS) metric is designed to characterize and balance the
utility of the two joint tasks, under the effects of varying data volumes and
staleness. We also integrate graph neural networks (GNNs) with MARL to enhance
state representations, capturing graph-structured, time-varying dependencies
among vehicles and across locations. Extensive experiments on our testbed
simulator, utilizing various real-world foundation model fine-tuning tasks and
the New York City Taxi ride order dataset, demonstrate the advantage of our
proposed method.

摘要：人工智能（AI）的進展，包括基礎模型（FM），正日益轉變人類社會，智慧城市推動著城市生活的演進。同時，車輛群感測（VCS）已成為關鍵推動因素，利用車輛的機動性和配備感測器的能力。特別是，儘管有資源限制，叫車服務車輛能有效促進靈活的資料收集，並有助於城市智慧。因此，這項工作探索了一個有前途的場景，其中邊緣輔助車輛執行訂單服務和新興基礎模型微調的聯合任務，使用各種城市資料。然而，由於 VCS AI 任務與傳統訂單服務任務的不一致時空特徵，整合它們具有挑戰性：(i) 叫車訂單和資料感興趣點 (PoI) 的分佈在地域上可能不重合，兩者都遵循先驗未知的模式；(ii) 它們具有不同的時間效應形式，即長時間等待會使訂單立即失效，而過時的資料會逐漸降低其對模型微調的效用。為了解決這些障礙，我們提出了一個基於多智能體強化學習 (MARL) 的線上架構，並進行了仔細的擴充。設計了一個新的服務品質 (QoS) 指標，用於表徵和平衡這兩個聯合任務的效用，在不同資料量和過時性的影響下。我們還將圖神經網路（GNN）與 MARL 整合，以增強狀態表示，捕捉車輛之間和不同地點之間的圖結構、時變依賴性。在我們的測試平台模擬器上進行的廣泛實驗，利用各種真實世界的基礎模型微調任務和紐約市計程車叫車訂單資料集，證明了我們提出的方法的優點。

##### **Multimodal Medical Code Tokenizer**
2502.04397v2 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

摘要：<paragraph>在患者电子健康记录 (EHR) 上训练的基础模型需要将医学数据标记为离散词汇项序列。现有的标记器将 EHR 中的医学代码视为孤立的文本标记。然而，每个医学代码都由其文本描述、在本体层次结构中的位置以及与其他代码的关系（例如疾病共现和药物治疗关联）来定义。医学词汇表包含超过 600,000 个代码，这些代码包含临床推理的关键信息。我们引入了 MedTok，这是一种多模态医学代码标记器，它使用文本描述和代码的关系上下文。MedTok 使用语言模型编码器处理文本，并使用图编码器对关系结构进行编码。然后，它将这两种模态量化为一个统一的标记空间，保留特定于模态和跨模态的信息。我们将 MedTok 集成到五个 EHR 模型中，并在住院和门诊数据集（包括结果预测、诊断分类、药物推荐和风险分层）上对其实施操作和临床任务进行评估。用 MedTok 替换标准 EHR 标记器可提高所有 EHR 模型的 AUPRC，在 MIMIC-III 上提高 4.10%，在 MIMIC-IV 上提高 4.78%，在 EHRShot 上提高 11.30%，其中药物推荐的增益最大。除了 EHR 建模之外，我们还演示了将 MedTok 标记器与医学问答系统结合使用。我们的结果证明了 MedTok 作为医学代码的统一标记器的潜力，改进了医学基础模型的标记化。</paragraph>

##### **A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**
2502.03772v1 by Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Lida Chen, Wei Wang, Qinghua Huang

Hepatocellular carcinoma (HCC) ranks as the third leading cause of
cancer-related mortality worldwide, with early detection being crucial for
improving patient survival rates. However, early screening for HCC using
ultrasound suffers from insufficient sensitivity and is highly dependent on the
expertise of radiologists for interpretation. Leveraging the latest
advancements in artificial intelligence (AI) in medical imaging, this study
proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model
that combines the strengths of Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound
screening. The HSQformer leverages sparse latent space representations to
capture hierarchical details at various granularities without the need for
complex adjustments, and adopts a modular, plug-and-play design philosophy,
ensuring the model's versatility and ease of use. The HSQformer's performance
was rigorously tested across three distinct clinical scenarios: single-center,
multi-center, and high-risk patient testing. In each of these settings, it
consistently outperformed existing state-of-the-art models, such as ConvNext
and SwinTransformer. Notably, the HSQformer even matched the diagnostic
capabilities of senior radiologists and comprehensively surpassed those of
junior radiologists. The experimental results from this study strongly
demonstrate the effectiveness and clinical potential of AI-assisted tools in
HCC screening. The full code is available at
https://github.com/Asunatan/HSQformer.

摘要：肝細胞癌（HCC）是全球第三大癌症相關死亡原因，早期檢測對於提高患者存活率至關重要。然而，使用超音波進行 HCC 早期篩檢的靈敏度不足，且高度依賴放射科醫師的專業知識進行判讀。本研究利用醫學影像中人工智慧（AI）的最新進展，提出了一種創新的分層稀疏查詢Transformer（HSQformer）模型，結合了卷積神經網路（CNN）和視覺Transformer（ViT）的優點，以提高超音波篩檢中 HCC 診斷的準確性。HSQformer 利用稀疏潛在空間表示，在不需要複雜調整的情況下擷取各種粒度層級的細節，並採用模組化、即插即用的設計理念，確保模型的多功能性和易用性。HSQformer 的效能經過三個不同的臨床場景的嚴格測試：單中心、多中心和高風險患者測試。在這些設定中，它始終優於現有的最先進模型，例如 ConvNext 和 SwinTransformer。值得注意的是，HSQformer 甚至匹配了資深放射科醫師的診斷能力，並全面超越了初級放射科醫師的診斷能力。本研究的實驗結果有力地證明了 AI 輔助工具在 HCC 篩檢中的有效性和臨床潛力。完整程式碼可在 https://github.com/Asunatan/HSQformer 取得。

##### **Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**
2502.04386v1 by Guangyao Zheng, Michael A. Jacobs, Vladimir Braverman, Vishwa S. Parekh

Self-supervised learning has revolutionized medical imaging by enabling
efficient and generalizable feature extraction from large-scale unlabeled
datasets. Recently, self-supervised foundation models have been extended to
three-dimensional (3D) computed tomography (CT) data, generating compact,
information-rich embeddings with 1408 features that achieve state-of-the-art
performance on downstream tasks such as intracranial hemorrhage detection and
lung cancer risk forecasting. However, these embeddings have been shown to
encode demographic information, such as age, sex, and race, which poses a
significant risk to the fairness of clinical applications.
  In this work, we propose a Variation Autoencoder (VAE) based adversarial
debiasing framework to transform these embeddings into a new latent space where
demographic information is no longer encoded, while maintaining the performance
of critical downstream tasks. We validated our approach on the NLST lung cancer
screening dataset, demonstrating that the debiased embeddings effectively
eliminate multiple encoded demographic information and improve fairness without
compromising predictive accuracy for lung cancer risk at 1-year and 2-year
intervals. Additionally, our approach ensures the embeddings are robust against
adversarial bias attacks. These results highlight the potential of adversarial
debiasing techniques to ensure fairness and equity in clinical applications of
self-supervised 3D CT embeddings, paving the way for their broader adoption in
unbiased medical decision-making.

摘要：自我監督學習透過從大規模未標記資料集中提取有效且可概化的特徵，進而革新了醫學影像。最近，自我監督基礎模型已擴展到三維 (3D) 電腦斷層掃描 (CT) 資料，產生緊湊、資訊豐富的嵌入，包含 1408 個特徵，在顱內出血偵測和肺癌風險預測等下游任務中達到最先進的效能。然而，這些嵌入已被證明會編碼人口統計資訊，例如年齡、性別和種族，這對臨床應用的公平性構成重大風險。
在這項工作中，我們提出一個基於變異自編碼器 (VAE) 的對抗性去偏框架，將這些嵌入轉換到一個新的潛在空間，其中不再編碼人口統計資訊，同時維持關鍵下游任務的效能。我們在 NLST 肺癌篩檢資料集上驗證了我們的做法，證明去偏嵌入有效消除了多重編碼的人口統計資訊，並在不損害 1 年和 2 年間隔的肺癌風險預測準確性的情況下提高了公平性。此外，我們的做法確保了嵌入對抗性偏誤攻擊具有魯棒性。這些結果突顯了對抗性去偏技術的潛力，可確保自我監督 3D CT 嵌入在臨床應用中的公平性和公正性，為其在無偏見醫療決策中的廣泛採用鋪路。

##### **Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**
2502.03591v1 by Mehrdad Asadi, Komi Sodoké, Ian J. Gerard, Marta Kersten-Oertel

In this work, we present a novel approach to multi-label chest X-ray (CXR)
image classification that enhances clinical interpretability while maintaining
a streamlined, single-model, single-run training pipeline. Leveraging the
CheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical
label groupings to capture clinically meaningful relationships between
diagnoses. To achieve this, we designed a custom hierarchical binary
cross-entropy (HBCE) loss function that enforces label dependencies using
either fixed or data-driven penalty types. Our model achieved a mean area under
the receiver operating characteristic curve (AUROC) of 0.903 on the test set.
Additionally, we provide visual explanations and uncertainty estimations to
further enhance model interpretability. All code, model configurations, and
experiment details are made available.

摘要：在本文中，我們提出胸部 X 光（CXR）影像多標籤分類的新方法，在維持簡化的單一模型、單次執行訓練管線的同時，提升臨床可解釋性。利用 CheXpert 資料集和 VisualCheXbert 衍生的標籤，我們納入階層標籤群組，以擷取診斷之間具有臨床意義的關聯性。為此，我們設計了自訂的階層二元交叉熵 (HBCE) 損失函數，使用固定或資料驅動的懲罰類型來強制執行標籤依賴性。我們的模型在測試集上達到受試者工作特性曲線 (AUROC) 下的平均面積為 0.903。此外，我們提供視覺化說明和不確定性估計，以進一步提升模型可解釋性。所有程式碼、模型組態和實驗詳細資料皆已公開。

##### **Code Simulation as a Proxy for High-order Tasks in Large Language Models**
2502.03568v1 by Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, X. Angelo Huang, Samuele Marro, Anthony Cohn, Nigel Shadbolt, Michael Wooldridge

Many reasoning, planning, and problem-solving tasks share an intrinsic
algorithmic nature: correctly simulating each step is a sufficient condition to
solve them correctly. We collect pairs of naturalistic and synthetic reasoning
tasks to assess the capabilities of Large Language Models (LLM). While
naturalistic tasks often require careful human handcrafting, we show that
synthetic data is, in many cases, a good proxy that is much easier to collect
at scale. We leverage common constructs in programming as the counterpart of
the building blocks of naturalistic reasoning tasks, such as straight-line
programs, code that contains critical paths, and approximate and redundant
instructions. We further assess the capabilities of LLMs on sorting problems
and repeated operations via sorting algorithms and nested loops. Our synthetic
datasets further reveal that while the most powerful LLMs exhibit relatively
strong execution capabilities, the process is fragile: it is negatively
affected by memorisation and seems to rely heavily on pattern recognition. Our
contribution builds upon synthetically testing the reasoning capabilities of
LLMs as a scalable complement to handcrafted human-annotated problems.

摘要：許多推理、規劃和問題解決任務共享一個內在的演算法性質：正確模擬每一步就足以正確解決它們。我們收集自然主義和合成推理任務對，以評估大型語言模型 (LLM) 的功能。雖然自然主義任務通常需要仔細的人工製作，但我們表明在許多情況下，合成資料是一個很好的代理，而且更容易大規模收集。我們利用程式設計中的常見建構，作為自然主義推理任務構建區塊的對應物，例如直線程式、包含關鍵路徑的程式碼，以及近似和冗餘指令。我們進一步評估 LLM 在排序問題和重複運算上的功能，透過排序演算法和巢狀迴圈。我們的合成資料集進一步揭示，雖然最強大的 LLM 表現出相對強大的執行能力，但這個過程很脆弱：它受到記憶的負面影響，而且似乎嚴重依賴模式辨識。我們的貢獻建立在以合成方式測試 LLM 的推理能力之上，作為手工編寫人類標註問題的可擴充補充。

##### **Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning**
2502.04381v1 by Jonathan Kim, Anna Podlasek, Kie Shidara, Feng Liu, Ahmed Alaa, Danilo Bernardo

Large Language Models (LLMs) have attained human-level accuracy on medical
question-answer (QA) benchmarks. However, their limitations in navigating
open-ended clinical scenarios have recently been shown, raising concerns about
the robustness and generalizability of LLM reasoning across diverse, real-world
medical tasks. To probe potential LLM failure modes in clinical
problem-solving, we present the medical abstraction and reasoning corpus
(M-ARC). M-ARC assesses clinical reasoning through scenarios designed to
exploit the Einstellung effect -- the fixation of thought arising from prior
experience, targeting LLM inductive biases toward inflexible pattern matching
from their training data rather than engaging in flexible reasoning. We find
that LLMs, including current state-of-the-art o1 and Gemini models, perform
poorly compared to physicians on M-ARC, often demonstrating lack of commonsense
medical reasoning and a propensity to hallucinate. In addition, uncertainty
estimation analyses indicate that LLMs exhibit overconfidence in their answers,
despite their limited accuracy. The failure modes revealed by M-ARC in LLM
medical reasoning underscore the need to exercise caution when deploying these
models in clinical settings.

摘要：大型語言模型 (LLM) 已在醫療問題解答 (QA) 基準上達到人類層級的準確度。然而，它們在應對開放式臨床場景中的局限性最近已被揭示，引發了人們對 LLM 推理在多樣化、真實世界醫療任務中的穩健性和概括性的擔憂。為了探討臨床問題解決中 LLM 的潛在故障模式，我們提出了醫療抽象和推理語料庫 (M-ARC)。M-ARC 通過旨在利用艾賓浩斯錯覺（由先前經驗產生的思維定勢）來評估臨床推理，針對 LLM 歸納偏誤，使其從訓練數據中進行僵化的模式匹配，而不是進行靈活的推理。我們發現，包括當前最先進的 o1 和 Gemini 模型在內的 LLM，在 M-ARC 上的表現遠不如醫生，它們經常表現出缺乏常識性的醫療推理和產生幻覺的傾向。此外，不確定性估計分析表明，儘管 LLM 準確性有限，但它們對自己的答案表現出過度自信。M-ARC 揭示的 LLM 醫療推理故障模式強調了在臨床環境中部署這些模型時需要謹慎。

##### **Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**
2502.03396v1 by Sarah Al-Shareeda, Yasar Celik, Bilge Bilgili, Ahmed Al-Dubai, Berk Canberk

Creating a Digital Twin (DT) for Healthcare Intelligent Transportation
Systems (HITS) is a hot research trend focusing on enhancing HITS management,
particularly in emergencies where ambulance vehicles must arrive at the crash
scene on time and track their real-time location is crucial to the medical
authorities. Despite the claim of real-time representation, a temporal
misalignment persists between the physical and virtual domains, leading to
discrepancies in the ambulance's location representation. This study proposes
integrating AI predictive models, specifically Support Vector Regression (SVR)
and Deep Neural Networks (DNN), within a constructed mock DT data pipeline
framework to anticipate the medical vehicle's next location in the virtual
world. These models align virtual representations with their physical
counterparts, i.e., metaphorically offsetting the synchronization delay between
the two worlds. Trained meticulously on a historical geospatial dataset, SVR
and DNN exhibit exceptional prediction accuracy in MATLAB and Python
environments. Through various testing scenarios, we visually demonstrate the
efficacy of our methodology, showcasing SVR and DNN's key role in significantly
reducing the witnessed gap within the HITS's DT. This transformative approach
enhances real-time synchronization in emergency HITS by approximately 88% to
93%.

摘要：建立醫療智慧交通系統（HITS）的數位分身（DT）是熱門的研究趨勢，其重點在於提升 HITS 管理，特別是在救護車必須準時抵達車禍現場的緊急情況中，追蹤其即時位置對於醫療單位至關重要。儘管聲稱即時呈現，但實體和虛擬領域之間仍存在時間上的錯位，導致救護車位置呈現上的差異。本研究建議在建構的虛擬 DT 資料管道架構中整合人工智慧預測模型，特別是支援向量回歸（SVR）和深度神經網路（DNN），以預測醫療車輛在虛擬世界的下一個位置。這些模型將虛擬呈現與其實體對應物對齊，也就是說，在兩個世界之間比喻性地抵銷同步延遲。在歷史地理空間資料集上經過仔細訓練，SVR 和 DNN 在 MATLAB 和 Python 環境中展現出卓越的預測準確性。透過各種測試情境，我們視覺化展示了我們方法論的效能，展示了 SVR 和 DNN 在顯著縮小 HITS 的 DT 中見證到的差距方面的關鍵作用。這種變革性的方法將緊急 HITS 中的即時同步提升了大約 88% 到 93%。

##### **RadVLM: A Multitask Conversational Vision-Language Model for Radiology**
2502.03333v1 by Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Blüthgen, Farhad Nooralahzadeh, Michael Krauthammer

The widespread use of chest X-rays (CXRs), coupled with a shortage of
radiologists, has driven growing interest in automated CXR analysis and
AI-assisted reporting. While existing vision-language models (VLMs) show
promise in specific tasks such as report generation or abnormality detection,
they often lack support for interactive diagnostic capabilities. In this work
we present RadVLM, a compact, multitask conversational foundation model
designed for CXR interpretation. To this end, we curate a large-scale
instruction dataset comprising over 1 million image-instruction pairs
containing both single-turn tasks -- such as report generation, abnormality
classification, and visual grounding -- and multi-turn, multi-task
conversational interactions. After fine-tuning RadVLM on this instruction
dataset, we evaluate it across different tasks along with re-implemented
baseline VLMs. Our results show that RadVLM achieves state-of-the-art
performance in conversational capabilities and visual grounding while remaining
competitive in other radiology tasks. Ablation studies further highlight the
benefit of joint training across multiple tasks, particularly for scenarios
with limited annotated data. Together, these findings highlight the potential
of RadVLM as a clinically relevant AI assistant, providing structured CXR
interpretation and conversational capabilities to support more effective and
accessible diagnostic workflows.

摘要：胸部 X 光 (CXR) 的广泛使用，加上放射科醫師短缺，促使人們對自動化 CXR 分析和 AI 輔助報告產生越來越濃厚的興趣。雖然現有的視覺語言模型 (VLM) 在特定任務中顯示出前景，例如報告生成或異常偵測，但它們通常缺乏對互動式診斷功能的支持。在這項工作中，我們提出 RadVLM，這是一個緊湊的多任務對話式基礎模型，專為 CXR 解釋而設計。為此，我們策劃了一個大型指令資料集，包含超過 100 萬個影像指令對，其中包含單輪任務（例如報告生成、異常分類和視覺基礎），以及多輪、多任務對話互動。在對這個指令資料集進行微調後，我們對 RadVLM 進行評估，並與重新實作的基準 VLM 一起執行不同的任務。我們的結果顯示，RadVLM 在對話能力和視覺基礎方面取得了最先進的效能，同時在其他放射學任務中仍具有競爭力。消融研究進一步突顯了跨多個任務進行聯合訓練的好處，特別是對於帶有標註資料有限的場景。這些發現共同突顯了 RadVLM 作為臨床相關 AI 助理的潛力，提供結構化的 CXR 解釋和對話能力，以支援更有效且可存取的診斷工作流程。

##### **MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**
2502.03298v1 by Amin Dada, Osman Alperen Koras, Marie Bauer, Amanda Butler, Kaleb E. Smith, Jens Kleesiek, Julian Friedrich

While increasing patients' access to medical documents improves medical care,
this benefit is limited by varying health literacy levels and complex medical
terminology. Large language models (LLMs) offer solutions by simplifying
medical information. However, evaluating LLMs for safe and patient-friendly
text generation is difficult due to the lack of standardized evaluation
resources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset
created from MIMIC-IV discharge summaries through an automated pipeline
combining LLM-based question-answer generation with manual quality checks. We
use this dataset to evaluate various LLMs on patient-oriented
question-answering. Our findings reveal that general-purpose LLMs frequently
surpass biomedical-adapted models, while automated metrics correlate with human
judgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the
development of LLMs to enhance patient understanding and ultimately improve
care outcomes.

摘要：儘管讓患者更能取得醫療文件有助於改善醫療照護，
但此優點受到不同的健康素養程度和複雜的醫療術語所限制。大型語言模型 (LLM) 提供了簡化醫療資訊的解決方案。然而，由於缺乏標準化的評估資源，因此難以評估 LLM 以確保其安全且對患者友善的文字產生。為了填補此缺口，我們開發了 MeDiSumQA。MeDiSumQA 是透過自動化流程從 MIMIC-IV 出院摘要中建立的資料集，結合了基於 LLM 的問答產生和手動品質檢查。我們使用此資料集來評估各種 LLM 在以患者為導向的問答中。我們的發現顯示，通用 LLM 經常超越生物醫學適應模型，而自動化指標與人類判斷相關。透過在 PhysioNet 上發布 MeDiSumQA，我們旨在推動 LLM 的發展，以增進患者理解，並最終改善照護成果。

##### **Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans**
2502.03272v1 by Matthias Schwab, Mathias Pamminger, Christian Kremser, Agnes Mayr

Purpose: To develop and evaluate a deep learning-based method that allows to
perform myocardial infarct segmentation in a fully-automated way.
  Materials and Methods: For this retrospective study, a cascaded framework of
two and three-dimensional convolutional neural networks (CNNs), specialized on
identifying ischemic myocardial scars on late gadolinium enhancement (LGE)
cardiac magnetic resonance (CMR) images, was trained on an in-house training
dataset consisting of 144 examinations. On a separate test dataset from the
same institution, including images from 152 examinations obtained between 2021
and 2023, a quantitative comparison between artificial intelligence (AI)-based
segmentations and manual segmentations was performed. Further, qualitative
assessment of segmentation accuracy was evaluated for both human and
AI-generated contours by two CMR experts in a blinded experiment.
  Results: Excellent agreement could be found between manually and
automatically calculated infarct volumes ($\rho_c$ = 0.9). The qualitative
evaluation showed that compared to human-based measurements, the experts rated
the AI-based segmentations to better represent the actual extent of infarction
significantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On
the contrary, for segmentation of microvascular obstruction (MVO), manual
measurements were still preferred (11.3% AI, 55.6% human, 33.1% equal).
  Conclusion: This fully-automated segmentation pipeline enables CMR infarct
size to be calculated in a very short time and without requiring any
pre-processing of the input images while matching the segmentation quality of
trained human observers. In a blinded experiment, experts preferred automated
infarct segmentations more often than manual segmentations, paving the way for
a potential clinical application.

摘要：<paragraph>目的：開發和評估一種基於深度學習的方法，允許以全自動的方式執行心肌梗塞分割。
材料和方法：對於這項回顧性研究，一個由二維和三維卷積神經網路 (CNN) 組成的串聯架構，專門用於識別晚期釓增強 (LGE) 心臟磁振造影 (CMR) 影像上的缺血性心肌疤痕，並在包含 144 項檢查的內部訓練資料集上受訓。在來自同一家機構的獨立測試資料集上，包括 2021 年至 2023 年間獲得的 152 項檢查的影像，執行基於人工智慧 (AI) 的分割和手動分割之間的定量比較。此外，由兩位 CMR 專家在盲測實驗中評估人類和 AI 生成的輪廓的分割準確度。
結果：在手動和自動計算的梗塞體積之間可以發現極佳的一致性（ρ_c = 0.9）。定性評估顯示，與基於人類的測量相比，專家評估 AI 基於分割能更能代表梗塞的實際範圍，顯著（p < 0.001）更常發生（33.4% AI，25.1% 人類，41.5% 相等）。相反，對於微血管阻塞 (MVO) 的分割，手動測量仍然較受青睞（11.3% AI，55.6% 人類，33.1% 相等）。
結論：這個全自動分割管道可以在很短的時間內計算 CMR 梗塞大小，而且無需對輸入影像進行任何前處理，同時匹配受過訓練的人類觀察者的分割品質。在盲測實驗中，專家比手動分割更常偏好自動梗塞分割，為潛在的臨床應用鋪平了道路。</paragraph>

##### **Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration**
2502.03238v2 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen

Recently computer-aided diagnosis has demonstrated promising performance,
effectively alleviating the workload of clinicians. However, the inherent
sample imbalance among different diseases leads algorithms biased to the
majority categories, leading to poor performance for rare categories. Existing
works formulated this challenge as a long-tailed problem and attempted to
tackle it by decoupling the feature representation and classification. Yet, due
to the imbalanced distribution and limited samples from tail classes, these
works are prone to biased representation learning and insufficient classifier
calibration. To tackle these problems, we propose a new Long-tailed Medical
Diagnosis (LMD) framework for balanced medical image classification on
long-tailed datasets. In the initial stage, we develop a Relation-aware
Representation Learning (RRL) scheme to boost the representation ability by
encouraging the encoder to capture intrinsic semantic features through
different data augmentations. In the subsequent stage, we propose an Iterative
Classifier Calibration (ICC) scheme to calibrate the classifier iteratively.
This is achieved by generating a large number of balanced virtual features and
fine-tuning the encoder using an Expectation-Maximization manner. The proposed
ICC compensates for minority categories to facilitate unbiased classifier
optimization while maintaining the diagnostic knowledge in majority classes.
Comprehensive experiments on three public long-tailed medical datasets
demonstrate that our LMD framework significantly surpasses state-of-the-art
approaches. The source code can be accessed at
https://github.com/peterlipan/LMD.

摘要：<paragraph>最近，计算机辅助诊断已展现出可观的表现，有效减轻了临床医生的工作量。然而，不同疾病之间固有的样本不平衡导致算法偏向于多数类别，从而导致罕见类别表现不佳。现有工作将这一挑战表述为长尾问题，并尝试通过解耦特征表示和分类来解决它。然而，由于不平衡分布和尾类样本有限，这些工作容易出现有偏差的表示学习和分类器校准不足。为了解决这些问题，我们提出了一个新的长尾医学诊断 (LMD) 框架，用于对长尾数据集进行平衡的医学图像分类。在初始阶段，我们开发了一个关系感知表示学习 (RRL) 方案，通过鼓励编码器通过不同的数据增强来捕获内在语义特征，从而提升表示能力。在后续阶段，我们提出了一个迭代分类器校准 (ICC) 方案，以迭代方式校准分类器。这是通过生成大量的平衡虚拟特征并使用期望最大化方式微调编码器来实现的。所提出的 ICC 补偿了少数类别，以促进无偏分类器优化，同时保持多数类别的诊断知识。在三个公共长尾医学数据集上进行的综合实验表明，我们的 LMD 框架明显超越了最先进的方法。源代码可在 https://github.com/peterlipan/LMD 处获取。</paragraph>

##### **Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study**
2502.06828v1 by Martin Wimpff, Bruno Aristimunha, Sylvain Chevallier, Bin Yang

This study investigates continual fine-tuning strategies for deep learning in
online longitudinal electroencephalography (EEG) motor imagery (MI) decoding
within a causal setting involving a large user group and multiple sessions per
participant. We are the first to explore such strategies across a large user
group, as longitudinal adaptation is typically studied in the single-subject
setting with a single adaptation strategy, which limits the ability to
generalize findings. First, we examine the impact of different fine-tuning
approaches on decoder performance and stability. Building on this, we integrate
online test-time adaptation (OTTA) to adapt the model during deployment,
complementing the effects of prior fine-tuning. Our findings demonstrate that
fine-tuning that successively builds on prior subject-specific information
improves both performance and stability, while OTTA effectively adapts the
model to evolving data distributions across consecutive sessions, enabling
calibration-free operation. These results offer valuable insights and
recommendations for future research in longitudinal online MI decoding and
highlight the importance of combining domain adaptation strategies for
improving BCI performance in real-world applications. Clinical Relevance: Our
investigation enables more stable and efficient long-term motor imagery
decoding, which is critical for neurorehabilitation and assistive technologies.

摘要：本研究探討在因果關係設定中涉及大量使用者群組和每個參與者多個階段的線上縱向腦電圖 (EEG) 運動想像 (MI) 解碼中，深度學習的持續微調策略。我們是第一個在大量使用者群組中探討此類策略，因為縱向適應通常在單一主體設定中研究，並使用單一適應策略，這限制了推廣研究結果的能力。首先，我們探討不同微調方法對解碼器效能和穩定性的影響。在此基礎上，我們整合線上測試時間適應 (OTTA) 以在部署期間適應模型，補充先前微調的效果。我們的研究結果表明，連續建立在先前特定主體資訊上的微調可以同時改善效能和穩定性，而 OTTA 可以有效地適應連續階段中不斷變化的資料分佈，從而實現無需校準的操作。這些結果為縱向線上 MI 解碼的未來研究提供了有價值的見解和建議，並強調了結合領域適應策略以改善實際應用中 BCI 效能的重要性。臨床相關性：我們的研究可以實現更穩定、更有效的長期運動想像解碼，這對於神經復健和輔助技術至關重要。

##### **MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**
2502.03004v1 by Seonok Kim

Large Language Models (LLMs) have demonstrated impressive capabilities across
natural language processing tasks. However, their application to specialized
domains such as medicine and biology requires further optimization to ensure
factual accuracy, reliability, and contextual depth. We introduce MedBioLM, a
domain-adapted biomedical question-answering model designed to enhance both
short-form and long-form queries. By integrating fine-tuning and
retrieval-augmented generation (RAG), MedBioLM dynamically incorporates
domain-specific knowledge, improving reasoning abilities and factual accuracy.
To evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA
datasets, covering structured multiple-choice assessments and complex clinical
reasoning tasks. Fine-tuning significantly improves accuracy on benchmark
datasets, while RAG enhances factual consistency. These results highlight the
potential of domain-optimized LLMs in advancing biomedical research, medical
education, and clinical decision support.

摘要：大型語言模型 (LLM) 已展現出在自然語言處理任務中令人印象深刻的能力。然而，要將其應用於醫學和生物學等特定領域，需要進一步最佳化，以確保事實的準確性、可靠性以及脈絡的深度。我們引進了 MedBioLM，這是一個適應領域的生物醫學問答模型，旨在增強短式和長式查詢。透過整合微調和檢索增強生成 (RAG)，MedBioLM 能動態地納入領域特定的知識，從而提升推理能力和事實準確性。為了評估其有效性，我們對模型進行微調，使其涵蓋結構化的多重選擇評量和複雜的臨床推理任務等多樣化的生物醫學問答資料集。微調顯著提升了基準資料集的準確性，而 RAG 則增強了事實的一致性。這些結果突顯了領域最佳化的 LLM 在推進生物醫學研究、醫學教育和臨床決策支援方面的潛力。

##### **Contrastive Token-level Explanations for Graph-based Rumour Detection**
2502.04366v1 by Daniel Wai Kit Chin, Roy Ka-Wei Lee

The widespread use of social media has accelerated the dissemination of
information, but it has also facilitated the spread of harmful rumours, which
can disrupt economies, influence political outcomes, and exacerbate public
health crises, such as the COVID-19 pandemic. While Graph Neural Network
(GNN)-based approaches have shown significant promise in automated rumour
detection, they often lack transparency, making their predictions difficult to
interpret. Existing graph explainability techniques fall short in addressing
the unique challenges posed by the dependencies among feature dimensions in
high-dimensional text embeddings used in GNN-based models. In this paper, we
introduce Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novel
framework designed to enhance the explainability of GNN-based rumour detection.
CT-LRP extends current graph explainability methods by providing token-level
explanations that offer greater granularity and interpretability. We evaluate
the effectiveness of CT-LRP across multiple GNN models trained on three
publicly available rumour detection datasets, demonstrating that it
consistently produces high-fidelity, meaningful explanations, paving the way
for more robust and trustworthy rumour detection systems.

摘要：社群媒體的廣泛使用加速了資訊的傳播，但也促进了有害謠言的散播，這可能會擾亂經濟、影響政治結果，並加劇公共衛生危機，例如 COVID-19 大流行。雖然基於圖神經網路 (GNN) 的方法在自動化謠言偵測方面展現了顯著的前景，但它們通常缺乏透明度，這使得它們的預測難以解釋。現有的圖形可解釋性技術無法解決 GNN 模型中使用的維度嵌入式文本之間的依賴性所帶來的獨特挑戰。在本文中，我們介紹了對比標記分層關聯性傳播 (CT-LRP)，這是一個新穎的框架，旨在增強基於 GNN 的謠言偵測的可解釋性。CT-LRP 透過提供標記級別的解釋來擴充當前的圖形可解釋性方法，這些解釋提供了更細緻的粒度和可解釋性。我們在三個公開的謠言偵測資料集上訓練的幾個 GNN 模型中評估了 CT-LRP 的有效性，證明它始終產生高保真、有意義的解釋，為更強健且值得信賴的謠言偵測系統鋪路。

##### **AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth**
2502.04365v1 by Jorge García-Torres, Øyvind Meinich-Bache, Siren Rettedal, Kjersti Engan

Approximately 10% of newborns need some assistance to start breathing and 5\%
proper ventilation. It is crucial that interventions are initiated as soon as
possible after birth. Accurate documentation of Time of Birth (ToB) is thereby
essential for documenting and improving newborn resuscitation performance.
However, current clinical practices rely on manual recording of ToB, typically
with minute precision. In this study, we present an AI-driven, video-based
system for automated ToB detection using thermal imaging, designed to preserve
the privacy of healthcare providers and mothers by avoiding the use of
identifiable visual data. Our approach achieves 91.4% precision and 97.4%
recall in detecting ToB within thermal video clips during performance
evaluation. Additionally, our system successfully identifies ToB in 96% of test
cases with an absolute median deviation of 1 second compared to manual
annotations. This method offers a reliable solution for improving ToB
documentation and enhancing newborn resuscitation outcomes.

摘要：約 10% 的新生兒需要協助才能開始呼吸，5% 需要適當的通氣。在出生後盡快開始介入至關重要。準確記錄出生時間 (ToB) 對於記錄和改善新生兒復甦表現至關重要。然而，目前的臨床實務依賴於手動記錄 ToB，通常精確到分鐘。在這項研究中，我們提出一個以 AI 為主的、基於影片的系統，用於使用熱影像自動偵測 ToB，旨在透過避免使用可識別的視覺資料來保護醫療保健提供者和母親的隱私。我們的做法在執行評估期間，在熱影像片段中偵測 ToB 時達到了 91.4% 的精確度和 97.4% 的召回率。此外，我們的系統在 96% 的測試案例中成功識別出 ToB，與手動註解相比，絕對中位數偏差為 1 秒。此方法提供了一個可靠的解決方案，用於改善 ToB 記錄和增強新生兒復甦結果。

##### **3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**
2502.02779v1 by Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell, Seena Dehkharghani, Jennifer A. Frontera, Arjun V. Masurkar, Kara Melmed, Narges Razavian

Head computed tomography (CT) imaging is a widely-used imaging modality with
multitudes of medical indications, particularly in assessing pathology of the
brain, skull, and cerebrovascular system. It is commonly the first-line imaging
in neurologic emergencies given its rapidity of image acquisition, safety,
cost, and ubiquity. Deep learning models may facilitate detection of a wide
range of diseases. However, the scarcity of high-quality labels and
annotations, particularly among less common conditions, significantly hinders
the development of powerful models. To address this challenge, we introduce
FM-CT: a Foundation Model for Head CT for generalizable disease detection,
trained using self-supervised learning. Our approach pre-trains a deep learning
model on a large, diverse dataset of 361,663 non-contrast 3D head CT scans
without the need for manual annotations, enabling the model to learn robust,
generalizable features. To investigate the potential of self-supervised
learning in head CT, we employed both discrimination with self-distillation and
masked image modeling, and we construct our model in 3D rather than at the
slice level (2D) to exploit the structure of head CT scans more comprehensively
and efficiently. The model's downstream classification performance is evaluated
using internal and three external datasets, encompassing both in-distribution
(ID) and out-of-distribution (OOD) data. Our results demonstrate that the
self-supervised foundation model significantly improves performance on
downstream diagnostic tasks compared to models trained from scratch and
previous 3D CT foundation models on scarce annotated datasets. This work
highlights the effectiveness of self-supervised learning in medical imaging and
sets a new benchmark for head CT image analysis in 3D, enabling broader use of
artificial intelligence for head CT-based diagnosis.

摘要：頭部電腦斷層掃描（CT）影像是一種廣泛使用的影像模式，具有
大量的醫療適應症，特別是在評估腦部、頭骨和腦血管系統的病理時。由於其影像擷取速度快、安全性、成本低和普遍性，通常是神經緊急情況下的第一線影像。深度學習模型可以促進對各種疾病的檢測。然而，高品質標籤和註釋的稀缺，特別是在較不常見的疾病中，顯著地阻礙了強大模型的發展。為了應對這一挑戰，我們引入了 FM-CT：一個用於頭部 CT 的基礎模型，用於可概化的疾病檢測，並使用自我監督學習進行訓練。我們的做法在一個包含 361,663 個非對比 3D 頭部 CT 掃描的大型、多樣化的數據集上預訓練一個深度學習模型，而無需手動註釋，使模型能夠學習強健、可概化的特徵。為了探討自我監督學習在頭部 CT 中的潛力，我們同時採用了帶有自我蒸餾的判別和遮罩影像建模，並且我們以 3D 而不是切片層級（2D）構建我們的模型，以更全面、有效地利用頭部 CT 掃描的結構。該模型的下游分類效能使用內部和三個外部數據集進行評估，包括分佈內 (ID) 和分佈外 (OOD) 資料。我們的結果表明，與從頭開始訓練的模型和先前在稀疏註釋數據集上訓練的 3D CT 基礎模型相比，自我監督基礎模型顯著改善了下游診斷任務的效能。這項工作突顯了自我監督學習在醫學影像中的有效性，並為 3D 頭部 CT 影像分析設定了一個新的基準，讓人工智慧能夠更廣泛地用於基於頭部 CT 的診斷。

##### **Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**
2502.02756v1 by Obed Korshie Dzikunu, Shadab Ahamed, Amirhossein Toosi, Xiaoxiao Li, Arman Rahmim

This study proposes a new loss function for deep neural networks, L1-weighted
Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of
voxels based on their classification difficulty, towards automated detection
and segmentation of metastatic prostate cancer lesions in PET/CT scans. We
obtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with
biochemical recurrence metastatic prostate cancer. We trained two 3D
convolutional neural networks, Attention U-Net and SegResNet, and concatenated
the PET and CT volumes channel-wise as input. The performance of our custom
loss function was evaluated against the Dice and Dice Focal Loss functions. For
clinical significance, we considered a detected region of interest (ROI) as a
true positive if at least the voxel with the maximum standardized uptake value
falls within the ROI. We assessed the models' performance based on the number
of lesions in an image, tumour volume, activity, and extent of spread. The
L1DFL outperformed the comparative loss functions by at least 13% on the test
set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were
lower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal
Loss yielded more false positives, whereas the Dice Loss was more sensitive to
smaller volumes and struggled to segment larger lesions accurately. They also
exhibited network-specific variations and yielded declines in segmentation
accuracy with increased tumour spread. Our results demonstrate the potential of
L1DFL to yield robust segmentation of metastatic prostate cancer lesions in
PSMA PET/CT images. The results further highlight potential complexities
arising from the variations in lesion characteristics that may influence
automated prostate cancer tumour detection and segmentation. The code is
publicly available at: https://github.com/ObedDzik/pca_segment.git.

摘要：<paragraph>本研究針對深度神經網路提出一個新的損失函數，L1 加權 Dice 焦點損失 (L1DFL)，它利用 L1 範數根據體素的分類難度進行自適應加權，用於自動偵測和分割 PET/CT 掃描中轉移性前列腺癌病灶。我們取得 380 個經診斷為生化復發轉移性前列腺癌的患者的 PSMA [18-F] DCFPyL PET/CT 掃描。我們訓練了兩個 3D 捲積神經網路，Attention U-Net 和 SegResNet，並將 PET 和 CT 體積按通道連接作為輸入。我們自訂的損失函數的效能與 Dice 和 Dice 焦點損失函數進行評估。為了臨床意義，我們將一個偵測到的感興趣區域 (ROI) 視為真陽性，如果至少具有最大標準攝取值的體素落在 ROI 內。我們根據影像中的病灶數量、腫瘤體積、活性，以及擴散程度評估模型的效能。L1DFL 在測試組中至少比比較損失函數高出 13%。此外，Dice 損失和 Dice 焦點損失的 F1 分數分別比 L1DFL 低至少 6% 和 34%。Dice 焦點損失產生更多假陽性，而 Dice 損失對較小體積較為敏感，且難以準確分割較大病灶。它們也展現出網路特定的變化，並隨著腫瘤擴散而導致分割準確度下降。我們的結果證明 L1DFL 具有在 PSMA PET/CT 影像中產生轉移性前列腺癌病灶的強健分割的潛力。結果進一步強調由病灶特徵變化所產生的潛在複雜性，這可能會影響自動化前列腺癌腫瘤偵測和分割。程式碼公開於：https://github.com/ObedDzik/pca_segment.git。</paragraph>

##### **Diffusion Instruction Tuning**
2502.06814v1 by Chen Jin, Ryutaro Tanno, Amrutha Saseendran, Tom Diethe, Philip Teare

We introduce Lavender, a simple supervised fine-tuning (SFT) method that
boosts the performance of advanced vision-language models (VLMs) by leveraging
state-of-the-art image generation models such as Stable Diffusion.
Specifically, Lavender aligns the text-vision attention in the VLM transformer
with the equivalent used by Stable Diffusion during SFT, instead of adapting
separate encoders. This alignment enriches the model's visual understanding and
significantly boosts performance across in- and out-of-distribution tasks.
Lavender requires just 0.13 million training examples, 2.5% of typical
large-scale SFT datasets, and fine-tunes on standard hardware (8 GPUs) in a
single day. It consistently improves state-of-the-art open-source multimodal
LLMs (e.g., Llama-3.2-11B, MiniCPM-Llama3-v2.5), achieving up to 30% gains and
a 68% boost on challenging out-of-distribution medical QA tasks. By efficiently
transferring the visual expertise of image generators with minimal supervision,
Lavender offers a scalable solution for more accurate vision-language systems.
All code, training data, and models will be shared at
https://astrazeneca.github.io/vlm/.

摘要：<paragraph>我們介紹 Lavender，一種簡單的監督微調 (SFT) 方法，它透過利用 Stable Diffusion 等最先進的影像生成模型來提升先進視覺語言模型 (VLM) 的效能。
具體來說，Lavender 在 SFT 期間將 VLM 轉換器中的文字視覺注意力與 Stable Diffusion 使用的等效注意力對齊，而不是調整單獨的編碼器。此對齊豐富了模型的視覺理解，並顯著提升了分佈內外任務的效能。
Lavender 只需要 0.13 百萬個訓練範例，相當於典型大型 SFT 資料集的 2.5%，並在標準硬體 (8 個 GPU) 上於一天內進行微調。它持續改善最先進的開放原始碼多模態 LLM（例如 Llama-3.2-11B、MiniCPM-Llama3-v2.5），在具有挑戰性的分佈外醫療 QA 任務中獲得高達 30% 的收益和 68% 的提升。透過有效轉移影像生成器的視覺專業知識，並僅需最少的監督，Lavender 提供了一個可擴充的解決方案，以實現更準確的視覺語言系統。
所有程式碼、訓練資料和模型將在 https://astrazeneca.github.io/vlm/ 分享。</paragraph>

##### **MedRAX: Medical Reasoning Agent for Chest X-ray**
2502.02673v1 by Adibvafa Fallahpour, Jun Ma, Alif Munim, Hongwei Lyu, Bo Wang

Chest X-rays (CXRs) play an integral role in driving critical decisions in
disease management and patient care. While recent innovations have led to
specialized models for various CXR interpretation tasks, these solutions often
operate in isolation, limiting their practical utility in clinical practice. We
present MedRAX, the first versatile AI agent that seamlessly integrates
state-of-the-art CXR analysis tools and multimodal large language models into a
unified framework. MedRAX dynamically leverages these models to address complex
medical queries without requiring additional training. To rigorously evaluate
its capabilities, we introduce ChestAgentBench, a comprehensive benchmark
containing 2,500 complex medical queries across 7 diverse categories. Our
experiments demonstrate that MedRAX achieves state-of-the-art performance
compared to both open-source and proprietary models, representing a significant
step toward the practical deployment of automated CXR interpretation systems.
Data and code have been publicly available at
https://github.com/bowang-lab/MedRAX

摘要：胸部 X 光片 (CXR) 在疾病管理和患者照護中扮演著不可或缺的角色，推動著關鍵決策的制定。儘管近期的創新已針對各種 CXR 解讀任務開發出專門的模型，但這些解決方案通常獨立運作，限制了它們在臨床實務中的實際效用。我們提出 MedRAX，這是一款首創的多功能 AI 代理，它將最先進的 CXR 分析工具和多模態大型語言模型無縫整合到一個統一的架構中。MedRAX 動態運用這些模型來解決複雜的醫療查詢，而無需額外的訓練。為了嚴格評估其功能，我們引入了 ChestAgentBench，這是一個全面的基準，包含 7 個不同類別的 2,500 個複雜醫療查詢。我們的實驗證明，與開源和專有模型相比，MedRAX 達到了最先進的效能，這代表了自動化 CXR 解讀系統實際部署的重要一步。資料和程式碼已公開於 https://github.com/bowang-lab/MedRAX

##### **Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription**
2502.04356v1 by Mahdi Alkaeed, Sofiat Abioye, Adnan Qayyum, Yosra Magdi Mekki, Ilhem Berrou, Mohamad Abdallah, Ala Al-Fuqaha, Muhammad Bilal, Junaid Qadir

In response to the success of proprietary Large Language Models (LLMs) such
as OpenAI's GPT-4, there is a growing interest in developing open,
non-proprietary LLMs and AI foundation models (AIFMs) for transparent use in
academic, scientific, and non-commercial applications. Despite their inability
to match the refined functionalities of their proprietary counterparts, open
models hold immense potential to revolutionize healthcare applications. In this
paper, we examine the prospects of open-source LLMs and AIFMs for developing
healthcare applications and make two key contributions. Firstly, we present a
comprehensive survey of the current state-of-the-art open-source healthcare
LLMs and AIFMs and introduce a taxonomy of these open AIFMs, categorizing their
utility across various healthcare tasks. Secondly, to evaluate the
general-purpose applications of open LLMs in healthcare, we present a case
study on personalized prescriptions. This task is particularly significant due
to its critical role in delivering tailored, patient-specific medications that
can greatly improve treatment outcomes. In addition, we compare the performance
of open-source models with proprietary models in settings with and without
Retrieval-Augmented Generation (RAG). Our findings suggest that, although less
refined, open LLMs can achieve performance comparable to proprietary models
when paired with grounding techniques such as RAG. Furthermore, to highlight
the clinical significance of LLMs-empowered personalized prescriptions, we
perform subjective assessment through an expert clinician. We also elaborate on
ethical considerations and potential risks associated with the misuse of
powerful LLMs and AIFMs, highlighting the need for a cautious and responsible
implementation in healthcare.

摘要：<paragraph>為了回應 OpenAI 的 GPT-4 等專有大型語言模型 (LLM) 的成功，開發開放、非專有的 LLM 和人工智慧基礎模型 (AIFM) 以透明地用於學術、科學和非商業應用中，引起了越來越大的興趣。儘管無法與其專有對應產品的精緻功能相匹配，但開放模型在革新醫療保健應用方面具有巨大的潛力。在本文中，我們探討了開放原始碼 LLM 和 AIFM 在開發醫療保健應用方面的前景，並提出了兩項關鍵貢獻。首先，我們對當前最先進的開放原始碼醫療保健 LLM 和 AIFM 進行了全面的調查，並介紹了這些開放 AIFM 的分類法，對它們在各種醫療保健任務中的效用進行了分類。其次，為了評估開放 LLM 在醫療保健中的通用應用，我們對個人化處方進行了案例研究。這項任務特別重要，因為它在提供量身定制的患者特定藥物方面發揮著關鍵作用，可以大大改善治療效果。此外，我們比較了開放原始碼模型與專有模型在有和沒有檢索增強生成 (RAG) 的設置中的性能。我們的研究結果表明，儘管不太精緻，但開放 LLM 在與 RAG 等基礎技術配對時，可以實現與專有模型相當的性能。此外，為了強調 LLM 賦能的個性化處方的臨床意義，我們通過專家臨床醫生進行了主觀評估。我們還詳細說明了與濫用強大的 LLM 和 AIFM 相關的倫理考量和潛在風險，強調了在醫療保健中謹慎和負責任地實施的必要性。</paragraph>

##### **Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents**
2502.02561v1 by Shayan Kiyani, George Pappas, Aaron Roth, Hamed Hassani

A fundamental question in data-driven decision making is how to quantify the
uncertainty of predictions in ways that can usefully inform downstream action.
This interface between prediction uncertainty and decision-making is especially
important in risk-sensitive domains, such as medicine. In this paper, we
develop decision-theoretic foundations that connect uncertainty quantification
using prediction sets with risk-averse decision-making. Specifically, we answer
three fundamental questions: (1) What is the correct notion of uncertainty
quantification for risk-averse decision makers? We prove that prediction sets
are optimal for decision makers who wish to optimize their value at risk. (2)
What is the optimal policy that a risk averse decision maker should use to map
prediction sets to actions? We show that a simple max-min decision policy is
optimal for risk-averse decision makers. Finally, (3) How can we derive
prediction sets that are optimal for such decision makers? We provide an exact
characterization in the population regime and a distribution free finite-sample
construction. Answering these questions naturally leads to an algorithm,
Risk-Averse Calibration (RAC), which follows a provably optimal design for
deriving action policies from predictions. RAC is designed to be both
practical-capable of leveraging the quality of predictions in a black-box
manner to enhance downstream utility-and safe-adhering to a user-defined risk
threshold and optimizing the corresponding risk quantile of the user's
downstream utility. Finally, we experimentally demonstrate the significant
advantages of RAC in applications such as medical diagnosis and recommendation
systems. Specifically, we show that RAC achieves a substantially improved
trade-off between safety and utility, offering higher utility compared to
existing methods while maintaining the safety guarantee.

摘要：<paragraph>在資料驅動決策中，一個基本問題是，如何量化預測的不確定性，以能有用地告知下游行動。
預測不確定性和決策制定之間的這種介面，在風險敏感領域中特別重要，例如醫學。在本文中，我們
發展了決策理論基礎，它利用預測集合將不確定性量化與風險規避決策制定聯繫起來。具體來說，我們回答
了三個基本問題：(1) 對於風險規避決策者來說，不確定性量化的正確概念是什麼？我們證明，對於希望最佳化其風險價值的決策者來說，預測集合是最佳的。(2)
風險規避決策者應使用什麼最佳政策，將預測集合映射到行動？我們表明，對於風險規避決策者來說，一個簡單的最大最小決策政策是最佳的。最後，(3) 我們如何推導出對此類決策者來說最佳的預測集合？我們在總體範圍內提供了一個確切的表徵，並提供了一個不依賴分佈的有限樣本建構。回答這些問題自然會導致一個演算法，風險規避校準 (RAC)，它遵循一個可證明最佳的設計，從預測中推導出行動政策。RAC 被設計為既實用——能夠以黑盒方式利用預測的品質來增強下游效用——又安全——遵守使用者定義的風險閾值，並最佳化使用者的下游效用的對應風險分位數。最後，我們在醫學診斷和推薦系統等應用中，以實驗方式證明了 RAC 的顯著優點。具體來說，我們表明，與現有方法相比，RAC 在安全性和效用之間實現了顯著改善的折衷，在維持安全保證的同時，提供了更高的效用。</paragraph>

##### **CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models**
2502.05214v1 by Amy Rafferty, Rishi Ramaesh, Ajitha Rajan

Deep learning models for medical image classification tasks are becoming
widely implemented in AI-assisted diagnostic tools, aiming to enhance
diagnostic accuracy, reduce clinician workloads, and improve patient outcomes.
However, their vulnerability to adversarial attacks poses significant risks to
patient safety. Current attack methodologies use general techniques such as
model querying or pixel value perturbations to generate adversarial examples
designed to fool a model. These approaches may not adequately address the
unique characteristics of clinical errors stemming from missed or incorrectly
identified clinical features. We propose the Concept-based Report Perturbation
Attack (CoRPA), a clinically-focused black-box adversarial attack framework
tailored to the medical imaging domain. CoRPA leverages clinical concepts to
generate adversarial radiological reports and images that closely mirror
realistic clinical misdiagnosis scenarios. We demonstrate the utility of CoRPA
using the MIMIC-CXR-JPG dataset of chest X-rays and radiological reports. Our
evaluation reveals that deep learning models exhibiting strong resilience to
conventional adversarial attacks are significantly less robust when subjected
to CoRPA's clinically-focused perturbations. This underscores the importance of
addressing domain-specific vulnerabilities in medical AI systems. By
introducing a specialized adversarial attack framework, this study provides a
foundation for developing robust, real-world-ready AI models in healthcare,
ensuring their safe and reliable deployment in high-stakes clinical
environments.

摘要：深度学习模型用于医学影像分类任务，在人工智能辅助诊断工具中得到广泛应用，旨在提高诊断准确性、减少临床医生的工作量并改善患者的治疗效果。然而，它们对对抗性攻击的脆弱性给患者安全带来了重大风险。目前的攻击方法使用通用技术，例如模型查询或像素值扰动来生成对抗性示例，旨在欺骗模型。这些方法可能无法充分解决源自遗漏或错误识别的临床特征的临床错误的独特特征。我们提出了基于概念的报告扰动攻击 (CoRPA)，这是一种以临床为中心的、针对医学成像领域的、黑盒对抗性攻击框架。CoRPA 利用临床概念来生成对抗性放射学报告和图像，这些报告和图像与现实的临床误诊场景非常相似。我们使用胸部 X 射线和放射学报告的 MIMIC-CXR-JPG 数据集演示了 CoRPA 的效用。我们的评估表明，对传统对抗性攻击表现出强大弹性的深度学习模型在受到 CoRPA 以临床为中心的扰动时，其鲁棒性明显降低。这强调了在医疗人工智能系统中解决特定领域漏洞的重要性。通过引入专门的对抗性攻击框架，本研究为在医疗保健领域开发健壮、面向现实世界的 AI 模型奠定了基础，确保它们在高风险临床环境中安全可靠地部署。

##### **A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation**
2502.02489v1 by Edward Ellis, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali

Ultrasound (US) imaging is clinically invaluable due to its noninvasive and
safe nature. However, interpreting US images is challenging, requires
significant expertise, and time, and is often prone to errors. Deep learning
offers assistive solutions such as segmentation. Supervised methods rely on
large, high-quality, and consistently labeled datasets, which are challenging
to curate. Moreover, these methods tend to underperform on out-of-distribution
data, limiting their clinical utility. Self-supervised learning (SSL) has
emerged as a promising alternative, leveraging unlabeled data to enhance model
performance and generalisability. We introduce a contrastive SSL approach
tailored for B-mode US images, incorporating a novel Relation Contrastive Loss
(RCL). RCL encourages learning of distinct features by differentiating positive
and negative sample pairs through a learnable metric. Additionally, we propose
spatial and frequency-based augmentation strategies for the representation
learning on US images. Our approach significantly outperforms traditional
supervised segmentation methods across three public breast US datasets,
particularly in data-limited scenarios. Notable improvements on the Dice
similarity metric include a 4% increase on 20% and 50% of the BUSI dataset,
nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4%
and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.
Furthermore, we demonstrate superior generalisability on the
out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6%
compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST
training data, respectively. Our research highlights that domain-inspired SSL
can improve US segmentation, especially under data-limited conditions.

摘要：超音波 (US) 影像由於其非侵入性且安全的特性，在臨床上極具價值。然而，解讀超音波影像具有挑戰性，需要大量的專業知識和時間，而且經常容易出錯。深度學習提供了輔助解決方案，例如分割。監督式方法依賴於大量、高品質且標籤一致的資料集，而這在策劃上具有挑戰性。此外，這些方法在分佈外資料上的表現往往不佳，這限制了它們的臨床效用。自監督學習 (SSL) 已成為一種有前途的替代方案，它利用未標籤資料來增強模型效能和泛化能力。我們提出了一種對比式 SSL 方法，專門針對 B 模式超音波影像，並納入了新穎的關係對比損失 (RCL)。RCL 透過一個可學習的指標區分正負樣本對，來鼓勵學習不同的特徵。此外，我們提出了用於超音波影像上表徵學習的空間和頻率增強策略。我們的做法在三個公開的乳房超音波資料集上顯著優於傳統的監督式分割方法，特別是在資料有限的情況下。在 Dice 相似性指標上的顯著改進包括在 BUSI 資料集的 20% 和 50% 上增加了 4%，在 BrEaST 資料集的 20% 和 50% 上增加了近 6% 和 9%，以及在 UDIAT 資料集的 20% 和 50% 上分別增加了 6.4% 和 3.7%。此外，我們在分佈外的 UDIAT 資料集上展示了卓越的泛化能力，與使用 BUSI 和 BrEaST 訓練資料的 20% 和 50% 的監督式基準相比，效能分別提升了 20.6% 和 13.6%。我們的研究強調，領域啟發的 SSL 可以改善超音波分割，特別是在資料有限的條件下。

##### **Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment**
2502.02438v1 by Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, Mario Fritz

Medical multimodal large language models (MLLMs) are becoming an instrumental
part of healthcare systems, assisting medical personnel with decision making
and results analysis. Models for radiology report generation are able to
interpret medical imagery, thus reducing the workload of radiologists. As
medical data is scarce and protected by privacy regulations, medical MLLMs
represent valuable intellectual property. However, these assets are potentially
vulnerable to model stealing, where attackers aim to replicate their
functionality via black-box access. So far, model stealing for the medical
domain has focused on classification; however, existing attacks are not
effective against MLLMs. In this paper, we introduce Adversarial Domain
Alignment (ADA-STEAL), the first stealing attack against medical MLLMs.
ADA-STEAL relies on natural images, which are public and widely available, as
opposed to their medical counterparts. We show that data augmentation with
adversarial noise is sufficient to overcome the data distribution gap between
natural images and the domain-specific distribution of the victim MLLM.
Experiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that
Adversarial Domain Alignment enables attackers to steal the medical MLLM
without any access to medical data.

摘要：醫療多模態大型語言模型 (MLLM) 正在成為醫療保健系統中不可或缺的一部分，協助醫療人員進行決策和結果分析。放射報告生成的模型能夠解釋醫學影像，從而減輕放射科醫師的工作負擔。由於醫療資料稀少且受隱私法規保護，醫療 MLLM 代表了有價值的智慧財產。然而，這些資產潛在地容易受到模型竊取的攻擊，攻擊者旨在透過黑盒存取來複製其功能。到目前為止，針對醫療領域的模型竊取一直專注於分類；然而，現有的攻擊對 MLLM 沒有效。在本文中，我們介紹了對抗域對齊 (ADA-STEAL)，這是針對醫療 MLLM 的第一個竊取攻擊。與醫療對應物相反，ADA-STEAL 依賴於公開且廣泛可用的自然影像。我們表明，對抗雜訊的資料擴充足以克服自然影像與受害者 MLLM 的特定領域分佈之間的資料分佈差距。在 IU X-RAY 和 MIMIC-CXR 放射學資料集上進行的實驗表明，對抗域對齊使攻擊者能夠在不存取任何醫療資料的情況下竊取醫療 MLLM。

##### **Test Time Training for 4D Medical Image Interpolation**
2502.02341v1 by Qikang Zhang, Yingjie Lei, Zihao Zheng, Ziyang Chen, Zhonghao Xie

4D medical image interpolation is essential for improving temporal resolution
and diagnostic precision in clinical applications. Previous works ignore the
problem of distribution shifts, resulting in poor generalization under
different distribution. A natural solution would be to adapt the model to a new
test distribution, but this cannot be done if the test input comes without a
ground truth label. In this paper, we propose a novel test time training
framework which uses self-supervision to adapt the model to a new distribution
without requiring any labels. Indeed, before performing frame interpolation on
each test video, the model is trained on the same instance using a
self-supervised task, such as rotation prediction or image reconstruction. We
conduct experiments on two publicly available 4D medical image interpolation
datasets, Cardiac and 4D-Lung. The experimental results show that the proposed
method achieves significant performance across various evaluation metrics on
both datasets. It achieves higher peak signal-to-noise ratio values, 33.73dB on
Cardiac and 34.02dB on 4D-Lung. Our method not only advances 4D medical image
interpolation but also provides a template for domain adaptation in other
fields such as image segmentation and image registration.

摘要：4D 醫學影像插值對於提升時間解析度及臨床應用中的診斷精準度至關重要。過往的研究忽略了分佈轉移問題，導致在不同分佈下泛化能力不佳。一個自然的解決方案是將模型適應到新的測試分佈，但如果測試輸入沒有真實標籤，就無法做到這一點。在本文中，我們提出了一個新的測試時間訓練架構，它使用自我監督來適應模型到一個新的分佈，而不需要任何標籤。事實上，在對每個測試影片執行幀插值之前，使用自我監督任務（例如旋轉預測或影像重建）在同一個實例上訓練模型。我們在兩個公開的 4D 醫學影像插值資料集（Cardiac 和 4D-Lung）上進行實驗。實驗結果表明，所提出的方法在兩個資料集上的各種評估指標中都取得了顯著的效能。它達到了更高的峰值信噪比值，在 Cardiac 上為 33.73dB，在 4D-Lung 上為 34.02dB。我們的技術不僅推動了 4D 醫學影像插值，還為其他領域（例如影像分割和影像配準）中的領域適應提供了一個範本。

##### **Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation**
2502.02249v1 by Atharva Mangeshkumar Agrawal, Rutika Pandurang Shinde, Vasanth Kumar Bhukya, Ashmita Chakraborty, Sagar Bharat Shah, Tanmay Shukla, Sree Pradeep Kumar Relangi, Nilesh Mutyam

Large language models (LLMs) have shown impressive capabilities in natural
language processing tasks, including dialogue generation. This research aims to
conduct a novel comparative analysis of two prominent techniques, fine-tuning
with LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG)
framework, in the context of doctor-patient chat conversations with multiple
datasets of mixed medical domains. The analysis involves three state-of-the-art
models: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient
dialogues, we comprehensively evaluate the performance of models, assessing key
metrics such as language quality (perplexity, BLEU score), factual accuracy
(fact-checking against medical knowledge bases), adherence to medical
guidelines, and overall human judgments (coherence, empathy, safety). The
findings provide insights into the strengths and limitations of each approach,
shedding light on their suitability for healthcare applications. Furthermore,
the research investigates the robustness of the models in handling diverse
patient queries, ranging from general health inquiries to specific medical
conditions. The impact of domain-specific knowledge integration is also
explored, highlighting the potential for enhancing LLM performance through
targeted data augmentation and retrieval strategies.

摘要：大型語言模型 (LLM) 在自然語言處理任務中展現了令人印象深刻的能力，包括對話生成。本研究旨在對兩種著名的技術進行新穎的比較分析，即微調 LoRA (低秩適應) 和檢索增強生成 (RAG) 框架，在具有混合醫療領域的多個資料集的醫患聊天對話中。分析涉及三個最先進的模型：Llama-2、GPT 和 LSTM 模型。採用真實世界的醫患對話，我們全面評估模型的性能，評估語言品質（困惑度、BLEU 分數）、事實準確性（對照醫學知識庫進行事實查核）、遵守醫療指南以及整體人類判斷（連貫性、同理心、安全性）等關鍵指標。研究結果深入了解了每種方法的優點和限制，闡明了它們適用於醫療保健應用的適當性。此外，該研究調查了模型在處理多樣化患者查詢時的穩健性，範圍從一般健康詢問到特定醫療狀況。還探討了特定領域知識整合的影響，強調了通過有針對性的資料擴充和檢索策略來增強 LLM 性能的潛力。

##### **Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review**
2502.02618v1 by F. Xavier Gaya-Morey, Jose M. Buades-Rubio, Philippe Palanque, Raquel Lacuesta, Cristina Manresa-Yee

The rapid aging of the global population has highlighted the need for
technologies to support elderly, particularly in healthcare and emotional
well-being. Facial expression recognition (FER) systems offer a non-invasive
means of monitoring emotional states, with applications in assisted living,
mental health support, and personalized care. This study presents a systematic
review of deep learning-based FER systems, focusing on their applications for
the elderly population. Following a rigorous methodology, we analyzed 31
studies published over the last decade, addressing challenges such as the
scarcity of elderly-specific datasets, class imbalances, and the impact of
age-related facial expression differences. Our findings show that convolutional
neural networks remain dominant in FER, and especially lightweight versions for
resource-constrained environments. However, existing datasets often lack
diversity in age representation, and real-world deployment remains limited.
Additionally, privacy concerns and the need for explainable artificial
intelligence emerged as key barriers to adoption. This review underscores the
importance of developing age-inclusive datasets, integrating multimodal
solutions, and adopting XAI techniques to enhance system usability,
reliability, and trustworthiness. We conclude by offering recommendations for
future research to bridge the gap between academic progress and real-world
implementation in elderly care.

摘要：全球人口快速老龄化突显了对技术的需求，以支持老年人，尤其是在医疗保健和情绪健康方面。面部表情识别 (FER) 系统提供了一种非侵入性的情绪状态监测手段，在辅助生活、心理健康支持和个性化护理中得到应用。本研究对基于深度学习的 FER 系统进行了系统的回顾，重点关注它们在老年人群中的应用。遵循严格的方法，我们分析了在过去十年中发表的 31 项研究，解决了诸如老年人特定数据集的稀缺性、类别不平衡以及与年龄相关的面部表情差异的影响等挑战。我们的研究结果表明，卷积神经网络在 FER 中仍然占主导地位，特别是针对资源受限环境的轻量级版本。然而，现有数据集往往缺乏年龄代表性的多样性，并且现实世界的部署仍然有限。此外，隐私问题和对可解释人工智能的需求已成为采用过程中的主要障碍。本次审查强调了开发包容年龄的数据集、整合多模式解决方案以及采用 XAI 技术以增强系统可用性、可靠性和可信度的重要性。最后，我们提出了未来研究的建议，以弥合学术进展与老年护理中的现实世界实施之间的差距。

##### **Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care**
2502.02109v1 by Yuxiao Cheng, Xinxin Song, Ziqian Wang, Qin Zhong, Kunlun He, Jinli Suo

Recent advances in deep learning (DL) have prompted the development of
high-performing early warning score (EWS) systems, predicting clinical
deteriorations such as acute kidney injury, acute myocardial infarction, or
circulatory failure. DL models have proven to be powerful tools for various
tasks but come with the cost of lacking interpretability and limited
generalizability, hindering their clinical applications. To develop a practical
EWS system applicable to various outcomes, we propose causally-informed
explainable early prediction model, which leverages causal discovery to
identify the underlying causal relationships of prediction and thus owns two
unique advantages: demonstrating the explicit interpretation of the prediction
while exhibiting decent performance when applied to unfamiliar environments.
Benefiting from these features, our approach achieves superior accuracy for 6
different critical deteriorations and achieves better generalizability across
different patient groups, compared to various baseline algorithms. Besides, we
provide explicit causal pathways to serve as references for assistant clinical
diagnosis and potential interventions. The proposed approach enhances the
practical application of deep learning in various medical scenarios.

摘要：深度學習 (DL) 的最新進展促使開發出高性能早期預警評分 (EWS) 系統，預測急性腎臟損傷、急性心肌梗塞或循環衰竭等臨床惡化。DL 模型已被證明是各種任務的強大工具，但代價是缺乏可解釋性和有限的概括性，阻礙了其臨床應用。為了開發適用於各種結果的實用 EWS 系統，我們提出了因果關係解釋性早期預測模型，它利用因果發現來識別預測的潛在因果關係，從而擁有兩個獨特的優點：展示預測的明確解釋，同時在應用於不熟悉的環境時表現出良好的性能。得益於這些特性，與各種基線演算法相比，我們的模型在 6 種不同的危重惡化中實現了更高的準確度，並在不同的患者群體中實現了更好的概括性。此外，我們提供了明確的因果途徑，作為輔助臨床診斷和潛在干預措施的參考。所提出的方法增強了深度學習在各種醫療場景中的實際應用。

##### **JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment**
2502.04345v1 by Yehan Yan, Tianhao Ma, Ruotai Li, Xinhan Zheng, Guodong Shan, Chisheng Li

Traditional Chinese medicine (TCM) plays a vital role in health protection
and disease treatment, but its practical application requires extensive medical
knowledge and clinical experience. Existing TCM Large Language Models (LLMs)
exhibit critical limitations of uncomprehensive medical consultation and
diagnoses, and inaccurate syndrome differentiation-based treatment. To address
these issues, this study establishes JingFang (JF): a novel TCM Large Language
Model that demonstrates the expert-level capability of medical diagnosis and
syndrome differentiation-based treatment. We innovate a Multi-agent Dynamic
Collaborative Chain-of-Thought Mechanism (MDCCTM) for medical consultation,
enabling JF with effective and accurate diagnostic ability. In addition, a
Syndrome Agent and a Dual-Stage Retrieval Scheme (DSRS) are developed to
significantly enhance the capacity of JF for disease treatment based on
syndrome differentiation. JingFang not only facilitates the application of LLMs
but also promotes the effective practice of TCM in human health protection and
disease treatment.

摘要：中醫藥在保健與疾病治療中扮演著重要的角色，但其實務應用需要深厚的醫學知識與臨床經驗。現有的中醫大語言模型（LLM）存在著醫療諮詢與診斷不全面、症候分型治療不準確的重大限制。為了解決這些問題，本研究建立了精方（JF）：一個新穎的中醫大語言模型，展示了專家級的醫療診斷與症候分型治療能力。我們創新了一個多智能體動態協作思考鏈機制（MDCCTM）用於醫療諮詢，讓 JF 具備有效且準確的診斷能力。此外，還開發了一個症候智能體和一個雙階段檢索方案（DSRS），以顯著增強 JF 基於症候分型的疾病治療能力。精方不僅促進了 LLM 的應用，也推動了中醫藥在人類保健與疾病治療中的有效實踐。

##### **An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data**
2502.01789v1 by Jiazi Tian, Liqin Wang, Pedram Fard, Valdery Moura Junior, Deborah Blacker, Jennifer S. Haas, Chirag Patel, Shawn N. Murphy, Lidia M. V. R. Moura, Hossein Estiri

Early identification of cognitive concerns is critical but often hindered by
subtle symptom presentation. This study developed and validated a fully
automated, multi-agent AI workflow using LLaMA 3 8B to identify cognitive
concerns in 3,338 clinical notes from Mass General Brigham. The agentic
workflow, leveraging task-specific agents that dynamically collaborate to
extract meaningful insights from clinical notes, was compared to an
expert-driven benchmark. Both workflows achieved high classification
performance, with F1-scores of 0.90 and 0.91, respectively. The agentic
workflow demonstrated improved specificity (1.00) and achieved prompt
refinement in fewer iterations. Although both workflows showed reduced
performance on validation data, the agentic workflow maintained perfect
specificity. These findings highlight the potential of fully automated
multi-agent AI workflows to achieve expert-level accuracy with greater
efficiency, offering a scalable and cost-effective solution for detecting
cognitive concerns in clinical settings.

摘要：及早辨識認知問題至關重要，但常常受到症狀呈現過於細微的阻礙。本研究開發並驗證了一個全自動化、多重代理的 AI 工作流程，使用 LLaMA 3 8B 來辨識來自麻省總醫院布萊根分院的 3,338 則臨床筆記中的認知問題。這個代理工作流程利用了特定任務的代理，這些代理會動態合作從臨床筆記中萃取出有意義的見解，並與專家驅動的基準進行比較。這兩個工作流程都達到了很高的分類效能，F1 分數分別為 0.90 和 0.91。代理工作流程展現出更好的特異性（1.00），並且在更少的反覆運算中達到了提示精煉。儘管這兩個工作流程在驗證資料上的效能都降低了，但代理工作流程維持了完美的特異性。這些發現突顯了全自動化多重代理 AI 工作流程的潛力，它們能以更高的效率達到專家級的準確度，為在臨床環境中偵測認知問題提供了一個可擴充且具成本效益的解決方案。

##### **Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis**
2502.03482v1 by Chacha Chen, Han Liu, Jiamin Yang, Benjamin M. Mervak, Bora Kalaycioglu, Grace Lee, Emre Cakmakli, Matteo Bonatti, Sridhar Pudu, Osman Kahraman, Gul Gizem Pamuk, Aytekin Oto, Aritrick Chatterjee, Chenhao Tan

Despite the growing interest in human-AI decision making, experimental
studies with domain experts remain rare, largely due to the complexity of
working with domain experts and the challenges in setting up realistic
experiments. In this work, we conduct an in-depth collaboration with
radiologists in prostate cancer diagnosis based on MRI images. Building on
existing tools for teaching prostate cancer diagnosis, we develop an interface
and conduct two experiments to study how AI assistance and performance feedback
shape the decision making of domain experts. In Study 1, clinicians were asked
to provide an initial diagnosis (human), then view the AI's prediction, and
subsequently finalize their decision (human-AI team). In Study 2 (after a
memory wash-out period), the same participants first received aggregated
performance statistics from Study 1, specifically their own performance, the
AI's performance, and their human-AI team performance, and then directly viewed
the AI's prediction before making their diagnosis (i.e., no independent initial
diagnosis). These two workflows represent realistic ways that clinical AI tools
might be used in practice, where the second study simulates a scenario where
doctors can adjust their reliance and trust on AI based on prior performance
feedback. Our findings show that, while human-AI teams consistently outperform
humans alone, they still underperform the AI due to under-reliance, similar to
prior studies with crowdworkers. Providing clinicians with performance feedback
did not significantly improve the performance of human-AI teams, although
showing AI decisions in advance nudges people to follow AI more. Meanwhile, we
observe that the ensemble of human-AI teams can outperform AI alone, suggesting
promising directions for human-AI collaboration.

摘要：儘管人們對人類與 AI 決策制定越來越感興趣，但與領域專家合作的實驗研究仍然很少見，這在很大程度上是因為與領域專家合作的複雜性，以及在設定實際實驗時面臨的挑戰。在這項工作中，我們與放射科醫師進行深入合作，基於 MRI 影像診斷前列腺癌。建立在用於教授前列腺癌診斷的現有工具上，我們開發了一個介面並進行了兩項實驗，以研究 AI 協助和效能回饋如何塑造領域專家的決策制定。在研究 1 中，要求臨床醫師提供初步診斷（人類），然後檢視 AI 的預測，並隨後確定他們的決策（人類-AI 團隊）。在研究 2（經過一段記憶清除期）中，同一位參與者首先收到研究 1 的彙總效能統計資料，特別是他們自己的效能、AI 的效能，以及他們的人類-AI 團隊效能，然後在做出診斷前直接檢視 AI 的預測（即，沒有獨立的初步診斷）。這兩個工作流程代表了臨床 AI 工具在實務中可能被使用的方式，其中第二個研究模擬了醫生可以根據先前的效能回饋調整他們對 AI 的依賴和信任的情況。我們的研究結果顯示，儘管人類-AI 團隊始終優於單獨的人類，但由於依賴不足，他們仍然表現不如 AI，這與之前針對群眾工作者的研究類似。儘管事先顯示 AI 決策會促使人們更多地遵循 AI，但向臨床醫師提供效能回饋並未顯著改善人類-AI 團隊的效能。同時，我們觀察到人類-AI 團隊的集合可以優於單獨的 AI，這表明了人類-AI 合作的前景。

##### **Improving Transformer World Models for Data-Efficient RL**
2502.01591v1 by Antoine Dedieu, Joseph Ortiz, Xinghua Lou, Carter Wendelken, Wolfgang Lehrach, J Swaroop Guntupalli, Miguel Lazaro-Gredilla, Kevin Patrick Murphy

We present an approach to model-based RL that achieves a new state of the art
performance on the challenging Craftax-classic benchmark, an open-world 2D
survival game that requires agents to exhibit a wide range of general abilities
-- such as strong generalization, deep exploration, and long-term reasoning.
With a series of careful design choices aimed at improving sample efficiency,
our MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,
significantly outperforming DreamerV3, which achieves 53.2%, and, for the first
time, exceeds human performance of 65.0%. Our method starts by constructing a
SOTA model-free baseline, using a novel policy architecture that combines CNNs
and RNNs. We then add three improvements to the standard MBRL setup: (a) "Dyna
with warmup", which trains the policy on real and imaginary data, (b) "nearest
neighbor tokenizer" on image patches, which improves the scheme to create the
transformer world model (TWM) inputs, and (c) "block teacher forcing", which
allows the TWM to reason jointly about the future tokens of the next timestep.

摘要：我們提出了一個基於模型的 RL 方法，在具有挑戰性的 Craftax-classic 基準上實現了新的技術水準，這是一個開放世界的 2D 生存遊戲，要求代理人展現廣泛的一般能力，例如強大的概括能力、深入探索和長期推理。通過一系列旨在提高樣本效率的仔細設計選擇，我們的 MBRL 演算法在僅 1M 環境步驟後就實現了 67.4% 的獎勵，顯著優於 DreamerV3（實現 53.2%），並且首次超過了人類的 65.0% 的表現。我們的演算法首先通過使用結合 CNN 和 RNN 的新穎策略架構來建構一個 SOTA 無模型基線。然後，我們對標準 MBRL 設定新增了三項改進：(a)「帶熱身的 Dyna」，它在真實和假想資料上訓練策略，(b) 影像貼片的「最近鄰代碼化器」，它改進了建立轉換器世界模型 (TWM) 輸入的方案，以及 (c)「區塊教師強制」，它允許 TWM 共同推理下一個時間步長的未來代碼。

##### **Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data**
2502.01377v1 by Zhi Zhang, Yan Liu, Mengxia Gao, Yu Yang, Jiannong Cao, Wai Kai Hou, Shirley Li, Sonata Yau, Yun Kwok Wing, Tatia M. C. Lee

Psychological resilience, defined as the ability to rebound from adversity,
is crucial for mental health. Compared with traditional resilience assessments
through self-reported questionnaires, resilience assessments based on
neurological data offer more objective results with biological markers, hence
significantly enhancing credibility. This paper proposes a novel data-efficient
model to address the scarcity of neurological data. We employ Neuro
Kolmogorov-Arnold Networks as the structure of the prediction model. In the
training stage, a new trait-informed multimodal representation algorithm with a
smart chunk technique is proposed to learn the shared latent space with limited
data. In the test stage, a new noise-informed inference algorithm is proposed
to address the low signal-to-noise ratio of the neurological data. The proposed
model not only shows impressive performance on both public datasets and
self-constructed datasets but also provides some valuable psychological
hypotheses for future research.

摘要：心理韌性，定義為從逆境中反彈的能力，對心理健康至關重要。與通過自我報告問卷的傳統韌性評估相比，基於神經數據的韌性評估提供了更客觀的結果和生物標記，從而顯著提高了可信度。本文提出了一個新穎的數據高效模型來解決神經數據的稀缺性。我們採用神經科爾莫哥羅夫-阿諾德網路作為預測模型的結構。在訓練階段，提出了一種新的特徵信息多模態表示算法，採用智能塊技術，以有限的數據學習共享潛在空間。在測試階段，提出了一種新的噪聲信息推理算法，以解決神經數據的信噪比低的問題。所提出的模型不僅在公共數據集和自構數據集上都顯示出令人印象深刻的性能，還為未來的研究提供了一些有價值的心理假設。

##### **OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology**
2502.01243v1 by Chengfeng Zhou, Ji Wang, Juanjuan Qin, Yining Wang, Ling Sun, Weiwei Dai

Large language models (LLMs) have shown significant promise across various
medical applications, with ophthalmology being a notable area of focus. Many
ophthalmic tasks have shown substantial improvement through the integration of
LLMs. However, before these models can be widely adopted in clinical practice,
evaluating their capabilities and identifying their limitations is crucial. To
address this research gap and support the real-world application of LLMs, we
introduce the OphthBench, a specialized benchmark designed to assess LLM
performance within the context of Chinese ophthalmic practices. This benchmark
systematically divides a typical ophthalmic clinical workflow into five key
scenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each
scenario, we developed multiple tasks featuring diverse question types,
resulting in a comprehensive benchmark comprising 9 tasks and 591 questions.
This comprehensive framework allows for a thorough assessment of LLMs'
capabilities and provides insights into their practical application in Chinese
ophthalmology. Using this benchmark, we conducted extensive experiments and
analyzed the results from 39 popular LLMs. Our evaluation highlights the
current gap between LLM development and its practical utility in clinical
settings, providing a clear direction for future advancements. By bridging this
gap, we aim to unlock the potential of LLMs and advance their development in
ophthalmology.

摘要：大型語言模型 (LLM) 在各種醫療應用中已展現出顯著的潛力，其中眼科是一個值得關注的重要領域。許多眼科任務已透過整合 LLM 而大幅進步。然而，在這些模型能廣泛應用於臨床實務之前，評估其能力並找出其限制至關重要。為了解決這個研究差距並支援 LLM 的實際應用，我們引入了 OphthBench，這是一個專門的基準測試，旨在評估 LLM 在中國眼科實務中的表現。此基準測試系統性地將典型眼科臨床工作流程劃分為五個關鍵情境：教育、分流、診斷、治療和預後。對於每個情境，我們開發了多項任務，包含多樣化的問題類型，最後組成一個包含 9 項任務和 591 個問題的綜合基準測試。此綜合架構可徹底評估 LLM 的能力，並提供其在中國眼科的實際應用見解。使用此基準測試，我們進行了廣泛的實驗，並分析了來自 39 個熱門 LLM 的結果。我們的評估強調了 LLM 開發與其在臨床環境中的實際效用之間的差距，為未來的進展提供了明確的方向。透過彌合此差距，我們旨在釋放 LLM 的潛力，並促進其在眼科的發展。

##### **MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks**
2502.01158v1 by Alejandro Guerra-Manzanares, Farah E. Shamout

Multimodal fusion leverages information across modalities to learn better
feature representations with the goal of improving performance in fusion-based
tasks. However, multimodal datasets, especially in medical settings, are
typically smaller than their unimodal counterparts, which can impede the
performance of multimodal models. Additionally, the increase in the number of
modalities is often associated with an overall increase in the size of the
multimodal network, which may be undesirable in medical use cases. Utilizing
smaller unimodal encoders may lead to sub-optimal performance, particularly
when dealing with high-dimensional clinical data. In this paper, we propose the
Modality-INformed knowledge Distillation (MIND) framework, a multimodal model
compression approach based on knowledge distillation that transfers knowledge
from ensembles of pre-trained deep neural networks of varying sizes into a
smaller multimodal student. The teacher models consist of unimodal networks,
allowing the student to learn from diverse representations. MIND employs
multi-head joint fusion models, as opposed to single-head models, enabling the
use of unimodal encoders in the case of unimodal samples without requiring
imputation or masking of absent modalities. As a result, MIND generates an
optimized multimodal model, enhancing both multimodal and unimodal
representations. It can also be leveraged to balance multimodal learning during
training. We evaluate MIND on binary and multilabel clinical prediction tasks
using time series data and chest X-ray images. Additionally, we assess the
generalizability of the MIND framework on three non-medical multimodal
multiclass datasets. Experimental results demonstrate that MIND enhances the
performance of the smaller multimodal network across all five tasks, as well as
various fusion methods and multimodal architectures, compared to
state-of-the-art baselines.

摘要：多模态融合利用跨模态的信息来学习更好的特征表示，目标是提升基于融合的任务的性能。然而，多模态数据集，尤其是在医疗环境中，通常比它们的单模态对应数据集小，这会阻碍多模态模型的性能。此外，模态数量的增加通常与多模态网络尺寸的整体增加相关，这在医疗用例中可能是不可取的。利用较小的单模态编码器可能会导致次优性能，尤其是在处理高维临床数据时。在本文中，我们提出了模态信息知识蒸馏 (MIND) 框架，这是一种基于知识蒸馏的多模态模型压缩方法，它将来自不同大小的预训练深度神经网络的集合中的知识转移到一个较小的多模态学生中。教师模型由单模态网络组成，允许学生从不同的表示中学习。MIND 采用多头联合融合模型，而不是单头模型，从而能够在单模态样本的情况下使用单模态编码器，而不需要缺失模态的插补或掩蔽。因此，MIND 生成了一个经过优化的多模态模型，增强了多模态和单模态表示。它还可以用来在训练期间平衡多模态学习。我们使用时间序列数据和胸部 X 射线图像对二元和多标签临床预测任务评估了 MIND。此外，我们评估了 MIND 框架在三个非医疗多模态多分类数据集上的泛化性。实验结果表明，与最先进的基线相比，MIND 增强了较小的多模态网络在所有五个任务以及各种融合方法和多模态架构中的性能。

##### **Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations**
2502.01141v1 by Qian Chen, Stefanie Rinderle-Ma, Lijie Wen

Most existing process compliance monitoring approaches detect compliance
violations in an ex post manner. Only predicate prediction focuses on
predicting them. However, predicate prediction provides a binary yes/no notion
of compliance, lacking the ability to measure to which extent an ongoing
process instance deviates from the desired state as specified in constraints.
Here, being able to quantify the magnitude of violation would provide
organizations with deeper insights into their operational performance, enabling
informed decision making to reduce or mitigate the risk of non-compliance.
Thus, we propose two predictive compliance monitoring approaches to close this
research gap. The first approach reformulates the binary classification problem
as a hybrid task that considers both classification and regression, while the
second employs a multi-task learning method to explicitly predict the
compliance status and the magnitude of violation for deviant cases
simultaneously. In this work, we focus on temporal constraints as they are
significant in almost any application domain, e.g., health care. The evaluation
on synthetic and real-world event logs demonstrates that our approaches are
capable of quantifying the magnitude of violations while maintaining comparable
performance for compliance predictions achieved by state-of-the-art approaches.

摘要：現有的流程合規監控方法大多會在事後偵測到合規違規。只有謂詞預測專注於預測這些違規。然而，謂詞預測提供的是合規與否的二元概念，無法衡量正在進行的流程實例偏離約束中所指定之理想狀態的程度。在此，能夠量化違規的嚴重程度，將能讓組織深入了解其營運績效，並能據此做出明智的決策，以降低或減輕不合規的風險。因此，我們提出兩種預測合規監控方法來填補此研究空白。第一種方法將二元分類問題重新表述為同時考量分類和回歸的混合任務，而第二種方法則採用多任務學習方法，同時明確預測合規狀態和偏差案例的違規嚴重程度。在這項工作中，我們專注於時間約束，因為它們幾乎在任何應用領域（例如醫療保健）中都很重要。在合成和真實世界事件記錄上的評估顯示，我們的做法能夠量化違規的嚴重程度，同時維持與現有方法所達成的合規預測相當的績效。

##### **Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings**
2502.01108v1 by Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar

Photoplethysmography (PPG)-based foundation models are gaining traction due
to the widespread use of PPG in biosignal monitoring and their potential to
generalize across diverse health applications. In this paper, we introduce
Pulse-PPG, the first open-source PPG foundation model trained exclusively on
raw PPG data collected over a 100-day field study with 120 participants.
Existing PPG foundation models are either open-source but trained on clinical
data or closed-source, limiting their applicability in real-world settings. We
evaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its
performance against a state-of-the-art foundation model trained on clinical
data. Our results demonstrate that Pulse-PPG, trained on uncurated field data,
exhibits superior generalization across clinical and mobile health applications
in both lab and field settings. This suggests that exposure to real-world
variability enables the model to learn fine-grained representations, making it
more adaptable across tasks. Furthermore, pre-training on field data
surprisingly outperforms its pre-training on clinical data in many tasks,
reinforcing the importance of training on real-world, diverse datasets. To
encourage further advancements in robust foundation models leveraging field
data, we plan to release Pulse-PPG, providing researchers with a powerful
resource for developing more generalizable PPG-based models.

摘要：基於光電容積描記術 (PPG) 的基礎模型由於 PPG 在生物訊號監控中的廣泛使用及其在各種健康應用中推廣的潛力而備受關注。在本文中，我們介紹 Pulse-PPG，這是第一個開放原始碼 PPG 基礎模型，專門針對在為期 100 天的現場研究中收集的 120 位參與者的原始 PPG 資料進行訓練。現有的 PPG 基礎模型要不是開放原始碼，但訓練於臨床資料，不然就是閉源，這限制了它們在真實世界中的應用性。我們評估了 Pulse-PPG 在多個資料集和下游任務中的表現，並將其效能與訓練於臨床資料的最新基礎模型進行比較。我們的結果表明，訓練於未整理現場資料的 Pulse-PPG 在實驗室和現場環境中，在臨床和行動健康應用中展現出優異的泛化能力。這表明接觸真實世界的變異性使模型能夠學習細粒度的表示，使其更能適應各種任務。此外，令人驚訝的是，現場資料的預訓練在許多任務中優於臨床資料的預訓練，這強化了在真實世界、多樣化的資料集上訓練的重要性。為了鼓勵在利用現場資料的強健基礎模型方面進一步發展，我們計畫發布 Pulse-PPG，為研究人員提供一個強大的資源，用於開發更具泛化性的基於 PPG 的模型。

##### **Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection**
2502.04342v1 by Yeyubei Zhang, Zhongyan Wang, Zhanyi Ding, Yexin Tian, Jianglai Dai, Xiaorui Shen, Yunchong Liu, Yuchen Cao

Social media has become an important source for understanding mental health,
providing researchers with a way to detect conditions like depression from
user-generated posts. This tutorial provides practical guidance to address
common challenges in applying machine learning and deep learning methods for
mental health detection on these platforms. It focuses on strategies for
working with diverse datasets, improving text preprocessing, and addressing
issues such as imbalanced data and model evaluation. Real-world examples and
step-by-step instructions demonstrate how to apply these techniques
effectively, with an emphasis on transparency, reproducibility, and ethical
considerations. By sharing these approaches, this tutorial aims to help
researchers build more reliable and widely applicable models for mental health
research, contributing to better tools for early detection and intervention.

摘要：社群媒體已成為了解心理健康的重要來源，
為研究人員提供一種方式，從使用者發布的貼文中偵測憂鬱症等狀況。
本教學提供實務指南，說明如何處理在這些平台上使用機器學習和深度學習方法進行心理健康偵測時常見的挑戰。
它專注於處理不同資料集、改善文字前處理，以及處理不平衡資料和模型評估等問題的策略。
實際範例和逐步說明示範如何有效應用這些技術，並強調透明度、可複製性，以及倫理考量。
透過分享這些方法，本教學指南旨在協助研究人員建構更可靠且廣泛適用的心理健康研究模型，
進而有助於早期偵測和介入的工具。

##### **Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model**
2502.01691v1 by Hadas Ben-Atya, Naama Gavrielov, Zvi Badash, Gili Focht, Ruth Cytter-Kuint, Talar Hagopian, Dan Turner, Moti Freiman

Reliable extraction of structured data from radiology reports using Large
Language Models (LLMs) remains challenging, especially for complex, non-English
texts like Hebrew. This study introduces an agent-based uncertainty-aware
approach to improve the trustworthiness of LLM predictions in medical
applications. We analyzed 9,683 Hebrew radiology reports from Crohn's disease
patients (from 2010 to 2023) across three medical centers. A subset of 512
reports was manually annotated for six gastrointestinal organs and 15
pathological findings, while the remaining reports were automatically annotated
using HSMP-BERT. Structured data extraction was performed using Llama 3.1
(Llama 3-8b-instruct) with Bayesian Prompt Ensembles (BayesPE), which employed
six semantically equivalent prompts to estimate uncertainty. An Agent-Based
Decision Model integrated multiple prompt outputs into five confidence levels
for calibrated uncertainty and was compared against three entropy-based models.
Performance was evaluated using accuracy, F1 score, precision, recall, and
Cohen's Kappa before and after filtering high-uncertainty cases. The
agent-based model outperformed the baseline across all metrics, achieving an F1
score of 0.3967, recall of 0.6437, and Cohen's Kappa of 0.3006. After filtering
high-uncertainty cases (greater than or equal to 0.5), the F1 score improved to
0.4787, and Kappa increased to 0.4258. Uncertainty histograms demonstrated
clear separation between correct and incorrect predictions, with the
agent-based model providing the most well-calibrated uncertainty estimates. By
incorporating uncertainty-aware prompt ensembles and an agent-based decision
model, this approach enhances the performance and reliability of LLMs in
structured data extraction from radiology reports, offering a more
interpretable and trustworthy solution for high-stakes medical applications.

摘要：<paragraph>使用大型語言模型 (LLM) 從放射科報告中可靠地提取結構化數據仍然具有挑戰性，尤其是對於希伯來語等複雜的非英語文本。本研究引入了一種基於代理的不確定性感知方法，以提高 LLM 預測在醫療應用中的可信度。我們分析了來自三個醫療中心的 9,683 份克隆氏症患者的希伯來語放射科報告（從 2010 年到 2023 年）。其中 512 份報告的手動註釋包括六個胃腸器官和 15 個病理發現，而其餘報告則使用 HSMP-BERT 自動註釋。結構化數據提取使用 Llama 3.1（Llama 3-8b-instruct）與貝葉斯提示集合（BayesPE）進行，它採用六個語義等效提示來估計不確定性。基於代理的決策模型將多個提示輸出整合到五個置信度級別中以校準不確定性，並與三個基於熵的模型進行比較。在過濾掉高度不確定性的情況之前和之後，使用準確度、F1 分數、精確度、召回率和 Cohen's Kappa 評估性能。基於代理的模型在所有指標上都優於基線，F1 分數達到 0.3967，召回率達到 0.6437，Cohen's Kappa 達到 0.3006。在過濾掉高度不確定性的情況（大於或等於 0.5）後，F1 分數提高到 0.4787，Kappa 提高到 0.4258。不確定性直方圖顯示了正確預測和不正確預測之間的明顯區別，基於代理的模型提供了校準最好的不確定性估計。通過結合不確定性感知提示集合和基於代理的決策模型，這種方法增強了 LLM 在放射科報告中結構化數據提取中的性能和可靠性，為高風險醫療應用提供了更具可解釋性和可信度的解決方案。</paragraph>

##### **Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment**
2502.01685v1 by Si-Ioi Ng, Pranav S. Ambadi, Kimberly D. Mueller, Julie Liss, Visar Berisha

Existing methods for analyzing linguistic content from picture descriptions
for assessment of cognitive-linguistic impairment often overlook the
participant's visual narrative path, which typically requires eye tracking to
assess. Spatio-semantic graphs are a useful tool for analyzing this narrative
path from transcripts alone, however they are limited by the need for manual
tagging of content information units (CIUs). In this paper, we propose an
automated approach for estimation of spatio-semantic graphs (via automated
extraction of CIUs) from the Cookie Theft picture commonly used in
cognitive-linguistic analyses. The method enables the automatic
characterization of the visual semantic path during picture description.
Experiments demonstrate that the automatic spatio-semantic graphs effectively
differentiate between cognitively impaired and unimpaired speakers. Statistical
analyses reveal that the features derived by the automated method produce
comparable results to the manual method, with even greater group differences
between clinical groups of interest. These results highlight the potential of
the automated approach for extracting spatio-semantic features in developing
clinical speech models for cognitive impairment assessment.

摘要：現有的用於分析圖像描述中的語言內容的方法，用於評估認知語言障礙，通常會忽略參與者的視覺敘事路徑，這通常需要眼球追蹤來評估。時空語義圖是一種有用的工具，可以僅從轉錄本中分析此敘事路徑，但是它們受到手動標記內容資訊單元 (CIU) 的需求所限制。在本文中，我們提出了一種自動化方法，用於從認知語言分析中常用的 Cookie Theft 圖像估計時空語義圖（通過自動提取 CIU）。該方法能夠自動表徵圖片描述期間的視覺語義路徑。實驗表明，自動時空語義圖有效地區分了認知受損和未受損的說話者。統計分析表明，自動化方法衍生的特徵產生了與手動方法相當的結果，甚至在感興趣的臨床組之間產生了更大的組差異。這些結果突出了自動化方法在提取時空語義特徵以開發用於認知障礙評估的臨床語音模型方面的潛力。

##### **Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images**
2502.00712v1 by Shengtian Sang, Hassan Jahanandish, Cynthia Xinran Li, Indrani Bhattachary, Jeong Hoon Lee, Lichun Zhang, Sulaiman Vesal, Pejman Ghanouni, Richard Fan, Geoffrey A. Sonn, Mirabela Rusu

Prostate cancer is a major cause of cancer-related deaths in men, where early
detection greatly improves survival rates. Although MRI-TRUS fusion biopsy
offers superior accuracy by combining MRI's detailed visualization with TRUS's
real-time guidance, it is a complex and time-intensive procedure that relies
heavily on manual annotations, leading to potential errors. To address these
challenges, we propose a fully automatic MRI-TRUS fusion-based segmentation
method that identifies prostate tumors directly in TRUS images without
requiring manual annotations. Unlike traditional multimodal fusion approaches
that rely on naive data concatenation, our method integrates a
registration-segmentation framework to align and leverage spatial information
between MRI and TRUS modalities. This alignment enhances segmentation accuracy
and reduces reliance on manual effort. Our approach was validated on a dataset
of 1,747 patients from Stanford Hospital, achieving an average Dice coefficient
of 0.212, outperforming TRUS-only (0.117) and naive MRI-TRUS fusion (0.132)
methods, with significant improvements (p $<$ 0.01). This framework
demonstrates the potential for reducing the complexity of prostate cancer
diagnosis and provides a flexible architecture applicable to other multimodal
medical imaging tasks.

摘要：前列腺癌是男性癌症相關死亡的主要原因，早期發現可大幅提升存活率。儘管 MRI-TRUS 融合切片檢查結合了 MRI 的詳細視覺化與 TRUS 的即時導引，可提供更高的準確度，但它是一種仰賴大量手動註解的複雜且耗時的程序，容易導致錯誤。為了解決這些挑戰，我們提出了一種全自動的 MRI-TRUS 融合式分割方法，它可以在 TRUS 影像中直接辨識出前列腺腫瘤，而不需要手動註解。與依賴於天真資料串接的傳統多模態融合方法不同，我們的方法整合了一個配準分割架構，以對齊並利用 MRI 與 TRUS 模態之間的空間資訊。這種對齊提升了分割準確度，並減少了對手動作業的依賴。我們的方法已通過來自 Stanford 醫院的 1,747 位患者的資料集進行驗證，達到了 0.212 的平均 Dice 係數，優於僅使用 TRUS (0.117) 和天真的 MRI-TRUS 融合 (0.132) 方法，並有顯著的改善（p < 0.01）。這個架構證明了降低前列腺癌診斷複雜性的潛力，並提供了一個適用於其他多模態醫學影像任務的彈性架構。

##### **TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion**
2502.00695v1 by Linglong Wu, Xuhao Shan, Ruiquan Ge, Ruoyu Liang, Chi Zhang, Yonghong Li, Ahmed Elazab, Huoling Luo, Yunbi Liu, Changmiao Wang

Chronic liver disease represents a significant health challenge worldwide and
accurate prognostic evaluations are essential for personalized treatment plans.
Recent evidence suggests that integrating multimodal data, such as computed
tomography imaging, radiomic features, and clinical information, can provide
more comprehensive prognostic information. However, modalities have an inherent
heterogeneity, and incorporating additional modalities may exacerbate the
challenges of heterogeneous data fusion. Moreover, existing multimodal fusion
methods often struggle to adapt to richer medical modalities, making it
difficult to capture inter-modal relationships. To overcome these limitations,
We present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).
Specifically, we develop an Intra-Modality Aggregation module and a
Triple-Modal Cross-Attention Fusion module, which are designed to eliminate
intra-modality redundancy and extract cross-modal information, respectively.
Furthermore, we design a Triple-Modal Feature Fusion loss function to align
feature representations across modalities. Extensive experiments on the liver
prognosis dataset demonstrate that our approach significantly outperforms
existing state-of-the-art unimodal models and other multi-modal techniques. Our
code is available at https://github.com/Mysterwll/liver.git.

摘要：慢性肝病在全球范围内代表著重大的健康挑戰，而準確的預後評估對於個人化治療計畫至關重要。最近的證據表明，整合多模態資料（例如電腦斷層影像、放射特徵和臨床資訊）可以提供更全面的預後資訊。然而，模態具有內在異質性，而納入額外的模態可能會加劇異質化資料融合的挑戰。此外，現有的多模態融合方法通常難以適應更豐富的醫療模態，這使得難以捕捉模態間的關係。為了克服這些限制，我們提出了三模態交互慢性肝臟網路 (TMI-CLNet)。具體來說，我們開發了一個模態內聚合模組和一個三模態交叉注意力融合模組，它們分別旨在消除模態內冗餘和提取跨模態資訊。此外，我們設計了一個三模態特徵融合損失函數，以對齊跨模態的特徵表示。在肝臟預後資料集上的廣泛實驗表明，我們的做法顯著優於現有的最先進單模態模型和其他多模態技術。我們的程式碼可以在 https://github.com/Mysterwll/liver.git 上取得。

##### **Safety at Scale: A Comprehensive Survey of Large Model Safety**
2502.05206v2 by Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu, Yunhao Chen, Yunhan Zhao, Hanxun Huang, Yige Li, Jiaming Zhang, Xiang Zheng, Yang Bai, Zuxuan Wu, Xipeng Qiu, Jingfeng Zhang, Yiming Li, Jun Sun, Cong Wang, Jindong Gu, Baoyuan Wu, Siheng Chen, Tianwei Zhang, Yang Liu, Mingming Gong, Tongliang Liu, Shirui Pan, Cihang Xie, Tianyu Pang, Yinpeng Dong, Ruoxi Jia, Yang Zhang, Shiqing Ma, Xiangyu Zhang, Neil Gong, Chaowei Xiao, Sarah Erfani, Bo Li, Masashi Sugiyama, Dacheng Tao, James Bailey, Yu-Gang Jiang

The rapid advancement of large models, driven by their exceptional abilities
in learning and generalization through large-scale pre-training, has reshaped
the landscape of Artificial Intelligence (AI). These models are now
foundational to a wide range of applications, including conversational AI,
recommendation systems, autonomous driving, content generation, medical
diagnostics, and scientific discovery. However, their widespread deployment
also exposes them to significant safety risks, raising concerns about
robustness, reliability, and ethical implications. This survey provides a
systematic review of current safety research on large models, covering Vision
Foundation Models (VFMs), Large Language Models (LLMs), Vision-Language
Pre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models
(DMs), and large-model-based Agents. Our contributions are summarized as
follows: (1) We present a comprehensive taxonomy of safety threats to these
models, including adversarial attacks, data poisoning, backdoor attacks,
jailbreak and prompt injection attacks, energy-latency attacks, data and model
extraction attacks, and emerging agent-specific threats. (2) We review defense
strategies proposed for each type of attacks if available and summarize the
commonly used datasets and benchmarks for safety research. (3) Building on
this, we identify and discuss the open challenges in large model safety,
emphasizing the need for comprehensive safety evaluations, scalable and
effective defense mechanisms, and sustainable data practices. More importantly,
we highlight the necessity of collective efforts from the research community
and international collaboration. Our work can serve as a useful reference for
researchers and practitioners, fostering the ongoing development of
comprehensive defense systems and platforms to safeguard AI models.

摘要：<paragraph>大型模型的快速進展，得益於它們在通過大規模預訓練進行學習和概括方面的卓越能力，已經重塑了人工智能 (AI) 的格局。這些模型現在是廣泛應用程式（包括對話式 AI、推薦系統、自動駕駛、內容生成、醫療診斷和科學發現）的基礎。然而，它們的廣泛部署也使它們面臨重大的安全風險，引發了對穩健性、可靠性和倫理影響的擔憂。本調查提供了對大型模型當前安全研究的系統性回顧，涵蓋視覺基礎模型 (VFM)、大型語言模型 (LLM)、視覺語言預訓練 (VLP) 模型、視覺語言模型 (VLM)、擴散模型 (DM) 和基於大型模型的代理。我們的貢獻總結如下：(1) 我們提出了一個針對這些模型的安全威脅的全面分類，包括對抗性攻擊、資料中毒、後門攻擊、越獄和提示注入攻擊、能量延遲攻擊、資料和模型提取攻擊以及新興的特定代理威脅。(2) 我們檢視了針對每種類型攻擊提出的防禦策略（如果有的話），並總結了安全研究中常用的資料集和基準。(3) 基於此，我們找出並討論了大型模型安全中的開放性挑戰，強調了對全面安全評估、可擴充且有效的防禦機制以及永續資料實務的需求。更重要的是，我們強調了研究社群和國際合作共同努力的必要性。我們的研究可作為研究人員和從業人員的有用參考，促進全面防禦系統和平台的持續發展，以保護 AI 模型。</paragraph>

##### **Enhanced Convolutional Neural Networks for Improved Image Classification**
2502.00663v1 by Xiaoran Yang, Shuhan Yu, Wenxi Xu

Image classification is a fundamental task in computer vision with diverse
applications, ranging from autonomous systems to medical imaging. The CIFAR-10
dataset is a widely used benchmark to evaluate the performance of
classification models on small-scale, multi-class datasets. Convolutional
Neural Networks (CNNs) have demonstrated state-of-the-art results; however,
they often suffer from overfitting and suboptimal feature representation when
applied to challenging datasets like CIFAR-10. In this paper, we propose an
enhanced CNN architecture that integrates deeper convolutional blocks, batch
normalization, and dropout regularization to achieve superior performance. The
proposed model achieves a test accuracy of 84.95%, outperforming baseline CNN
architectures. Through detailed ablation studies, we demonstrate the
effectiveness of the enhancements and analyze the hierarchical feature
representations. This work highlights the potential of refined CNN
architectures for tackling small-scale image classification problems
effectively.

摘要：影像分類是電腦視覺中的一項基本任務，應用範圍廣泛，從自動系統到醫學影像皆有。CIFAR-10 資料集是一個廣泛使用的基準，用於評估分類模型在小規模、多類別資料集上的效能。卷積神經網路 (CNN) 已展現出最先進的成果；然而，當應用於 CIFAR-10 等具挑戰性的資料集時，它們常常會發生過度擬合和次佳特徵表示的問題。在本文中，我們提出一個增強的 CNN 架構，它整合了更深的卷積區塊、批次正規化和中斷正規化，以達成卓越的效能。所提出的模型達到了 84.95% 的測試準確度，優於基準 CNN 架構。透過詳細的消融研究，我們證明了這些增強功能的有效性，並分析了階層式特徵表示。這項工作突顯了精進的 CNN 架構在有效解決小規模影像分類問題上的潛力。

##### **Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective**
2502.00619v1 by Yujin Oh, Pengfei Jin, Sangjoon Park, Sekeun Kim, Siyeop Yoon, Kyungsang Kim, Jin Sung Kim, Xiang Li, Quanzheng Li

Ensuring fairness in medical image segmentation is critical due to biases in
imbalanced clinical data acquisition caused by demographic attributes (e.g.,
age, sex, race) and clinical factors (e.g., disease severity). To address these
challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired
by optimal control theory. We provide a comprehensive analysis of its
underlying mechanisms and clarify dMoE's role in adapting to heterogeneous
distributions in medical image segmentation. Furthermore, we integrate dMoE
into multiple network architectures, demonstrating its broad applicability
across diverse medical image analysis tasks. By incorporating demographic and
clinical factors, dMoE achieves state-of-the-art performance on two 2D
benchmark datasets and a 3D in-house dataset. Our results highlight the
effectiveness of dMoE in mitigating biases from imbalanced distributions,
offering a promising approach to bridging control theory and medical image
segmentation within fairness learning paradigms. The source code will be made
available.

摘要：在医学影像分割中，由於人口屬性（例如年齡、性別、種族）和臨床因素（例如疾病嚴重程度）導致不平衡的臨床數據採集中存在偏差，因此確保公平性至關重要。為了應對這些挑戰，我們引入了受最優控制理論啟發的感知混合專家 (dMoE)。我們對其底層機制進行了全面分析，並釐清了 dMoE 在適應醫學影像分割中的異質分佈中的作用。此外，我們將 dMoE 整合到多個網路架構中，展示了其在各種醫學影像分析任務中的廣泛適用性。通過納入人口統計和臨床因素，dMoE 在兩個 2D 基準數據集和一個 3D 內部數據集上實現了最先進的性能。我們的結果突出了 dMoE 在減輕不平衡分佈的偏差方面的有效性，為在公平性學習範例中橋接控制理論和醫學影像分割提供了一個有前景的方法。原始碼將會公開。

##### **Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions**
2502.00568v3 by Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti

Emerging research has highlighted that artificial intelligence based
multimodal fusion of digital pathology and transcriptomic features can improve
cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.
However, such direct fusion for joint decision is impractical in real clinical
settings, where histopathology is still the gold standard for diagnosis and
transcriptomic tests are rarely requested, at least in the public healthcare
system. With our novel diffusion based crossmodal generative AI model PathGen,
we show that genomic expressions synthesized from digital histopathology
jointly predicts cancer grading and patient survival risk with high accuracy
(state-of-the-art performance), certainty (through conformal coverage
guarantee) and interpretability (through distributed attention maps). PathGen
code is available for open use by the research community through GitHub at
https://github.com/Samiran-Dey/PathGen.

摘要：新興研究強調，基於人工智慧的多模態融合數位病理學和轉錄組特徵，可以改善癌症診斷（分級/分型）和預後（存活風險）預測。
然而，這種直接融合對於聯合決策在實際臨床環境中並不切實際，在實際臨床環境中，組織病理學仍然是診斷的黃金標準，而轉錄組檢測很少被要求，至少在公共醫療保健系統中是如此。透過我們新穎的基於擴散的跨模態生成式 AI 模型 PathGen，我們展示了從數位組織病理學合成的基因體表達共同預測癌症分級和患者存活風險，具有很高的準確度（最先進的效能）、確定性（透過共形覆蓋保證）和可解釋性（透過分佈式注意力圖）。PathGen 程式碼可透過 GitHub 上的 https://github.com/Samiran-Dey/PathGen 供研究社群公開使用。

