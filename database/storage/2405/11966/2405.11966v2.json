{"2405.11966": {"publish_time": "2024-05-20", "title": "Multiple-Choice Questions are Efficient and Robust LLM Evaluators", "paper_summary": "We present GSM-MC and MATH-MC, two multiple-choice (MC) datasets constructed\nby collecting answers and incorrect predictions on GSM8K and MATH from over 50\nopen-source models. Through extensive experiments, we show that LLMs'\nperformance on the MC versions of these two popular benchmarks is strongly\ncorrelated with their performance on the original versions, and is quite robust\nto distractor choices and option orders, while the evaluation time is reduced\nby a factor of up to 30. Following a similar procedure, we also introduce\nPythonIO, a new program output prediction MC dataset constructed from two other\npopular LLM evaluation benchmarks HumanEval and MBPP. Our data and code are\navailable at https://github.com/Geralt-Targaryen/MC-Evaluation.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa GSM-MC \u548c MATH-MC\uff0c\u9019\u5169\u500b\u591a\u9078\u984c (MC) \u8cc7\u6599\u96c6\u662f\u900f\u904e\u6536\u96c6\u8d85\u904e 50 \u500b\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u5728 GSM8K \u548c MATH \u4e0a\u7684\u7b54\u6848\u548c\u932f\u8aa4\u9810\u6e2c\u800c\u5efa\u69cb\u7684\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e LLM \u5728\u9019\u5169\u500b\u71b1\u9580\u57fa\u6e96\u6e2c\u8a66\u7684\u591a\u9078\u984c\u7248\u672c\u4e0a\u7684\u8868\u73fe\u8207\u5176\u5728\u539f\u59cb\u7248\u672c\u4e0a\u7684\u8868\u73fe\u6709\u5f88\u5f37\u7684\u76f8\u95dc\u6027\uff0c\u4e26\u4e14\u5c0d\u65bc\u5e72\u64fe\u9078\u9805\u548c\u9078\u9805\u9806\u5e8f\u76f8\u7576\u7a69\u5065\uff0c\u540c\u6642\u8a55\u4f30\u6642\u9593\u6e1b\u5c11\u4e86\u591a\u9054 30 \u500d\u3002\u9075\u5faa\u985e\u4f3c\u7684\u7a0b\u5e8f\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86 PythonIO\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684\u7a0b\u5f0f\u8f38\u51fa\u9810\u6e2c\u591a\u9078\u984c\u8cc7\u6599\u96c6\uff0c\u5efa\u69cb\u81ea\u53e6\u5916\u5169\u500b\u71b1\u9580\u7684 LLM \u8a55\u4f30\u57fa\u6e96 HumanEval \u548c MBPP\u3002\u6211\u5011\u7684\u8cc7\u6599\u548c\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/Geralt-Targaryen/MC-Evaluation \u53d6\u5f97\u3002", "author": "Ziyin Zhang et.al.", "authors": "Ziyin Zhang, Lizhen Xu, Zhaokun Jiang, Hongkun Hao, Rui Wang", "id": "2405.11966v2", "paper_url": "http://arxiv.org/abs/2405.11966v2", "repo": "https://github.com/geralt-targaryen/mc-evaluation"}}