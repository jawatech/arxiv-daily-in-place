{"2404.14750": {"publish_time": "2024-04-23", "title": "Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray", "paper_summary": "Medical vision-language pre-training has emerged as a promising approach for\nlearning domain-general representations of medical image and text. Current\nalgorithms that exploit the global and local alignment between medical image\nand text could however be marred by the redundant information in medical data.\nTo address this issue, we propose a grounded knowledge-enhanced medical\nvision-language pre-training (GK-MVLP) framework for chest X-ray. In this\nframework, medical knowledge is grounded to the appropriate anatomical regions\nby using a transformer-based grounded knowledge-enhanced module for\nfine-grained alignment between anatomical region-level visual features and the\ntextural features of medical knowledge. The performance of GK-MVLP is\ncompetitive with or exceeds the state of the art on downstream chest X-ray\ndisease classification, disease localization, report generation, and medical\nvisual question-answering tasks. Our results show the advantage of\nincorporating grounding mechanism to remove biases and improve the alignment\nbetween chest X-ray image and radiology report.", "paper_summary_zh": "", "author": "Qiao Deng et.al.", "authors": "Qiao Deng,Zhongzhen Huang,Yunqi Wang,Zhichuan Wang,Zhao Wang,Xiaofan Zhang,Qi Dou,Yeung Yu Hui,Edward S. Hui", "id": "2404.14750v1", "paper_url": "http://arxiv.org/abs/2404.14750v1", "repo": "null"}}