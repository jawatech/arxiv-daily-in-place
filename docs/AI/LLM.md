
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-11**|**UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts**|Bo Yang et.al.|[2411.07240v1](http://arxiv.org/abs/2411.07240v1)|null|
|**2024-11-11**|**OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model**|Sumeth Yuenyong et.al.|[2411.07238v1](http://arxiv.org/abs/2411.07238v1)|null|
|**2024-11-11**|**Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations**|Chaitanya Malaviya et.al.|[2411.07237v1](http://arxiv.org/abs/2411.07237v1)|null|
|**2024-11-11**|**Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models**|Yoad Tewel et.al.|[2411.07232v1](http://arxiv.org/abs/2411.07232v1)|null|
|**2024-11-11**|**Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving**|Botao Yu et.al.|[2411.07228v1](http://arxiv.org/abs/2411.07228v1)|null|
|**2024-11-11**|**TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models**|Matheus Simão et.al.|[2411.07224v1](http://arxiv.org/abs/2411.07224v1)|null|
|**2024-11-11**|**Grounding Video Models to Actions through Goal Conditioned Exploration**|Yunhao Luo et.al.|[2411.07223v1](http://arxiv.org/abs/2411.07223v1)|null|
|**2024-11-11**|**TreeCoders: Trees of Transformers**|Pierre Colonna D'Istria et.al.|[2411.07218v1](http://arxiv.org/abs/2411.07218v1)|null|
|**2024-11-11**|**OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision**|Cong Wei et.al.|[2411.07199v1](http://arxiv.org/abs/2411.07199v1)|null|
|**2024-11-11**|**The Super Weight in Large Language Models**|Mengxia Yu et.al.|[2411.07191v1](http://arxiv.org/abs/2411.07191v1)|[link](https://github.com/mengxiayu/llmsuperweight)|
|**2024-11-11**|**NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics**|David Robinson et.al.|[2411.07186v1](http://arxiv.org/abs/2411.07186v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**Counterfactual Generation from Language Models**|Shauli Ravfogel et.al.|[2411.07180v1](http://arxiv.org/abs/2411.07180v1)|[link](https://github.com/shauli-ravfogel/lm-counterfactuals)|
|**2024-11-11**|**More Expressive Attention with Negative Weights**|Ang Lv et.al.|[2411.07176v1](http://arxiv.org/abs/2411.07176v1)|[link](https://github.com/trestad/cogattn)|
|**2024-11-11**|**Continual Memorization of Factoids in Large Language Models**|Howard Chen et.al.|[2411.07175v1](http://arxiv.org/abs/2411.07175v1)|[link](https://github.com/princeton-nlp/continual-factoid-memorization)|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Primer on Word Embeddings: AI Techniques for Text Analysis in Social Work**|Brian E. Perron et.al.|[2411.07156v1](http://arxiv.org/abs/2411.07156v1)|null|
|**2024-11-11**|**HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals**|Lingbo Mo et.al.|[2411.07152v1](http://arxiv.org/abs/2411.07152v1)|null|
|**2024-11-11**|**Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models**|Yancheng He et.al.|[2411.07140v1](http://arxiv.org/abs/2411.07140v1)|null|
|**2024-11-11**|**Edify 3D: Scalable High-Quality 3D Asset Generation**|NVIDIA et.al.|[2411.07135v1](http://arxiv.org/abs/2411.07135v1)|null|
|**2024-11-11**|**Stronger Models are NOT Stronger Teachers for Instruction Tuning**|Zhangchen Xu et.al.|[2411.07133v1](http://arxiv.org/abs/2411.07133v1)|null|
|**2024-11-11**|**Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**|Taihang Hu et.al.|[2411.07132v1](http://arxiv.org/abs/2411.07132v1)|[link](https://github.com/hutaihang/tome)|
|**2024-11-11**|**Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation**|Kaijian Zou et.al.|[2411.07130v1](http://arxiv.org/abs/2411.07130v1)|[link](https://github.com/launchnlp/ManyICLBench)|
|**2024-11-11**|**Benchmarking LLMs' Judgments with No Gold Standard**|Shengwei Xu et.al.|[2411.07127v1](http://arxiv.org/abs/2411.07127v1)|[link](https://github.com/yx-lu/benchmarking-llms--judgments-with-no-gold-standard)|
|**2024-11-11**|**Fast and Robust Contextual Node Representation Learning over Dynamic Graphs**|Xingzhi Guo et.al.|[2411.07123v1](http://arxiv.org/abs/2411.07123v1)|null|
|**2024-11-11**|**SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs**|Ruben Härle et.al.|[2411.07122v1](http://arxiv.org/abs/2411.07122v1)|[link](https://github.com/ml-research/SCAR)|
|**2024-11-11**|**Building a Taiwanese Mandarin Spoken Language Model: A First Attempt**|Chih-Kai Yang et.al.|[2411.07111v1](http://arxiv.org/abs/2411.07111v1)|null|
|**2024-11-11**|**Training Neural Networks as Recognizers of Formal Languages**|Alexandra Butoi et.al.|[2411.07107v1](http://arxiv.org/abs/2411.07107v1)|[link](https://github.com/rycolab/neural-network-recognizers)|
|**2024-11-11**|**Bounded Rationality Equilibrium Learning in Mean Field Games**|Yannick Eich et.al.|[2411.07099v1](http://arxiv.org/abs/2411.07099v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Towards Characterizing Cyber Networks with Large Language Models**|Alaric Hartsock et.al.|[2411.07089v1](http://arxiv.org/abs/2411.07089v1)|null|
|**2024-11-11**|**OCMDP: Observation-Constrained Markov Decision Process**|Taiyi Wang et.al.|[2411.07087v1](http://arxiv.org/abs/2411.07087v1)|null|
|**2024-11-11**|**StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification**|Yichen He et.al.|[2411.07076v1](http://arxiv.org/abs/2411.07076v1)|[link](https://github.com/hyc2026/StoryTeller)|
|**2024-11-11**|**Transformer verbatim in-context retrieval across time and scale**|Kristijan Armeni et.al.|[2411.07075v1](http://arxiv.org/abs/2411.07075v1)|[link](https://github.com/kristijanarmeni/verbatim-memory-in-nlms)|
|**2024-11-11**|**Universal Response and Emergence of Induction in LLMs**|Niclas Luick et.al.|[2411.07071v1](http://arxiv.org/abs/2411.07071v1)|null|
|**2024-11-11**|**On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models**|Qian Sun et.al.|[2411.07070v1](http://arxiv.org/abs/2411.07070v1)|null|
|**2024-11-11**|**Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training**|Elia Cunegatti et.al.|[2411.07066v1](http://arxiv.org/abs/2411.07066v1)|[link](https://github.com/eliacunegatti/neuroal)|
|**2024-11-11**|**Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications**|Xianzhe Fan et.al.|[2411.07042v1](http://arxiv.org/abs/2411.07042v1)|null|
|**2024-11-11**|**Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind**|Alejandro Leonardo García Navarro et.al.|[2411.07038v1](http://arxiv.org/abs/2411.07038v1)|null|
|**2024-11-11**|**LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios**|Xiaodong Wu et.al.|[2411.07037v1](http://arxiv.org/abs/2411.07037v1)|null|
|**2024-11-11**|**UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction**|Zhiqiang Liu et.al.|[2411.07019v1](http://arxiv.org/abs/2411.07019v1)|[link](https://github.com/lza12a/unihr)|
|**2024-11-11**|**Leveraging LSTM for Predictive Modeling of Satellite Clock Bias**|Ahan Bhatt et.al.|[2411.07015v1](http://arxiv.org/abs/2411.07015v1)|null|
|**2024-11-11**|**A neural-network based anomaly detection system and a safety protocol to protect vehicular network**|Marco Franceschini et.al.|[2411.07013v1](http://arxiv.org/abs/2411.07013v1)|null|
|**2024-11-11**|**Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching**|Arnav Kumar Jain et.al.|[2411.07007v1](http://arxiv.org/abs/2411.07007v1)|[link](https://github.com/arnavkj1995/sfm)|
|**2024-11-11**|**Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs**|Malte Luttermann et.al.|[2411.07006v1](http://arxiv.org/abs/2411.07006v1)|null|
|**2024-11-11**|**Token2Wave**|Xin Zhang et.al.|[2411.06989v1](http://arxiv.org/abs/2411.06989v1)|null|
|**2024-11-11**|**ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis**|Zanlin Ni et.al.|[2411.06959v1](http://arxiv.org/abs/2411.06959v1)|[link](https://github.com/leaplabthu/enat)|
|**2024-11-11**|**Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences**|Shu Zhong et.al.|[2411.06950v1](http://arxiv.org/abs/2411.06950v1)|null|
|**2024-11-11**|**Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models**|Aniket Deroy et.al.|[2411.06946v1](http://arxiv.org/abs/2411.06946v1)|null|
|**2024-11-11**|**Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum**|Yuanming Zhang et.al.|[2411.06928v1](http://arxiv.org/abs/2411.06928v1)|null|
|**2024-11-11**|**Slowing Down Forgetting in Continual Learning**|Pascal Janetzky et.al.|[2411.06916v1](http://arxiv.org/abs/2411.06916v1)|null|
|**2024-11-11**|**Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI**|Bruno Viti et.al.|[2411.06911v1](http://arxiv.org/abs/2411.06911v1)|[link](https://gitlab.com/bruno_viti/gpe_4_cardiac_fss)|
|**2024-11-11**|**EVQAScore: Efficient Video Question Answering Data Evaluation**|Hao Liang et.al.|[2411.06908v1](http://arxiv.org/abs/2411.06908v1)|null|
|**2024-11-11**|**LongSafetyBench: Long-Context LLMs Struggle with Safety Issues**|Mianqiu Huang et.al.|[2411.06899v1](http://arxiv.org/abs/2411.06899v1)|null|
|**2024-11-11**|**GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs**|Sheng Tian et.al.|[2411.06878v1](http://arxiv.org/abs/2411.06878v1)|null|
|**2024-11-11**|**Multi-Modal interpretable automatic video captioning**|Antoine Hanna-Asaad et.al.|[2411.06872v1](http://arxiv.org/abs/2411.06872v1)|null|
|**2024-11-11**|**Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering**|Boci Peng et.al.|[2411.06866v1](http://arxiv.org/abs/2411.06866v1)|null|
|**2024-11-11**|**Computable Model-Independent Bounds for Adversarial Quantum Machine Learning**|Bacui Li et.al.|[2411.06863v1](http://arxiv.org/abs/2411.06863v1)|null|
|**2024-11-11**|**Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models**|Abdullah Fajar et.al.|[2411.06860v1](http://arxiv.org/abs/2411.06860v1)|null|
|**2024-11-11**|**Scientific machine learning in ecological systems: A study on the predator-prey dynamics**|Ranabir Devgupta et.al.|[2411.06858v1](http://arxiv.org/abs/2411.06858v1)|null|
|**2024-11-11**|**A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information**|Prashant Kapil et.al.|[2411.06855v1](http://arxiv.org/abs/2411.06855v1)|null|
|**2024-11-11**|**Evaluating Large Language Models on Financial Report Summarization: An Empirical Study**|Xinqi Yang et.al.|[2411.06852v1](http://arxiv.org/abs/2411.06852v1)|null|
|**2024-11-11**|**1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs**|Jebish Purbey et.al.|[2411.06850v1](http://arxiv.org/abs/2411.06850v1)|null|
|**2024-11-11**|**LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models**|Runming Yang et.al.|[2411.06839v1](http://arxiv.org/abs/2411.06839v1)|null|
|**2024-11-11**|**Persuasion with Large Language Models: a Survey**|Alexander Rogiers et.al.|[2411.06837v1](http://arxiv.org/abs/2411.06837v1)|null|
|**2024-11-11**|**HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment**|Yannis Belkhiter et.al.|[2411.06835v1](http://arxiv.org/abs/2411.06835v1)|null|
|**2024-11-11**|**Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs**|Megh Thakkar et.al.|[2411.06824v1](http://arxiv.org/abs/2411.06824v1)|null|
|**2024-11-11**|**Generative midtended cognition and Artificial Intelligence. Thinging with thinging things**|Xabier E. Barandiaran et.al.|[2411.06812v1](http://arxiv.org/abs/2411.06812v1)|null|
|**2024-11-11**|**JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset**|Daria Tsereh et.al.|[2411.06810v1](http://arxiv.org/abs/2411.06810v1)|null|
|**2024-11-11**|**AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant**|Yujia Zhou et.al.|[2411.06805v1](http://arxiv.org/abs/2411.06805v1)|[link](https://github.com/smallporridge/assistrag)|
|**2024-11-11**|**LA4SR: illuminating the dark proteome with generative AI**|David R. Nelson et.al.|[2411.06798v1](http://arxiv.org/abs/2411.06798v1)|null|
|**2024-11-11**|**Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks**|Wenxuan Pan et.al.|[2411.06792v1](http://arxiv.org/abs/2411.06792v1)|null|
|**2024-11-11**|**Large-scale moral machine experiment on large language models**|Muhammad Shahrul Zaim bin Ahmad et.al.|[2411.06790v1](http://arxiv.org/abs/2411.06790v1)|[link](https://github.com/kztakemoto/mmllm)|
|**2024-11-11**|**ScaleKD: Strong Vision Transformers Could Be Excellent Teachers**|Jiawei Fan et.al.|[2411.06786v1](http://arxiv.org/abs/2411.06786v1)|[link](https://github.com/deep-optimization/scalekd)|
|**2024-11-11**|**MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting**|Thang Nguyen et.al.|[2411.06781v1](http://arxiv.org/abs/2411.06781v1)|null|
|**2024-11-11**|**A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts**|Liu Zhuoxian et.al.|[2411.06772v1](http://arxiv.org/abs/2411.06772v1)|null|
|**2024-11-11**|**PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing**|Yiwen Duan et.al.|[2411.06767v1](http://arxiv.org/abs/2411.06767v1)|null|
|**2024-11-11**|**KLCBL: An Improved Police Incident Classification Model**|Liu Zhuoxian et.al.|[2411.06749v1](http://arxiv.org/abs/2411.06749v1)|null|
|**2024-11-11**|**Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening**|Zhangfan Yang et.al.|[2411.06740v1](http://arxiv.org/abs/2411.06740v1)|null|
|**2024-11-11**|**Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data**|Kai Kim et.al.|[2411.06735v1](http://arxiv.org/abs/2411.06735v1)|null|
|**2024-11-11**|**Reverse Prompt Engineering**|Hanqing Li et.al.|[2411.06729v1](http://arxiv.org/abs/2411.06729v1)|null|
|**2024-11-11**|**Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy**|Xin Sun et.al.|[2411.06723v1](http://arxiv.org/abs/2411.06723v1)|null|
|**2024-11-11**|**Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models**|Yeming Wen et.al.|[2411.06722v1](http://arxiv.org/abs/2411.06722v1)|null|
|**2024-11-11**|**DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations**|Xuming He et.al.|[2411.06714v1](http://arxiv.org/abs/2411.06714v1)|null|
|**2024-11-11**|**Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**|Chanseo Lee et.al.|[2411.06713v1](http://arxiv.org/abs/2411.06713v1)|null|
|**2024-11-11**|**Model Fusion through Bayesian Optimization in Language Model Fine-Tuning**|Chaeyun Jang et.al.|[2411.06710v1](http://arxiv.org/abs/2411.06710v1)|[link](https://github.com/chaeyoon-jang/bomf)|
|**2024-11-11**|**Autonomous Droplet Microfluidic Design Framework with Large Language Models**|Dinh-Nguyen Nguyen et.al.|[2411.06691v1](http://arxiv.org/abs/2411.06691v1)|null|
|**2024-11-11**|**WDMoE: Wireless Distributed Mixture of Experts for Large Language Models**|Nan Xue et.al.|[2411.06681v1](http://arxiv.org/abs/2411.06681v1)|null|
|**2024-11-11**|**What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance**|Hong Meng Yam et.al.|[2411.06672v1](http://arxiv.org/abs/2411.06672v1)|null|
|**2024-11-11**|**Adversarial Detection with a Dynamically Stable System**|Xiaowei Long et.al.|[2411.06666v1](http://arxiv.org/abs/2411.06666v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-11**|**An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning**|Dong Li et.al.|[2411.06659v1](http://arxiv.org/abs/2411.06659v1)|[link](https://github.com/arvin0313/mecoin-gfscil)|
|**2024-11-11**|**Renaissance: Investigating the Pretraining of Vision-Language Encoders**|Clayton Fields et.al.|[2411.06657v1](http://arxiv.org/abs/2411.06657v1)|[link](https://github.com/bsu-slim/renaissance)|
|**2024-11-11**|**Explore the Reasoning Capability of LLMs in the Chess Testbed**|Shu Wang et.al.|[2411.06655v1](http://arxiv.org/abs/2411.06655v1)|null|
|**2024-11-11**|**Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data**|Alex Havrilla et.al.|[2411.06646v1](http://arxiv.org/abs/2411.06646v1)|[link](https://github.com/dahoas/transformer_manifolds_learning)|
|**2024-11-11**|**Predicting Country Instability Using Bayesian Deep Learning and Random Forest**|Adam Zebrowski et.al.|[2411.06639v1](http://arxiv.org/abs/2411.06639v1)|null|
|**2024-11-11**|**Model Editing for LLMs4Code: How Far are We?**|Xiaopeng Li et.al.|[2411.06638v1](http://arxiv.org/abs/2411.06638v1)|[link](https://github.com/xpq-tech/code-llmedit)|
|**2024-11-10**|**A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning**|Caleb J. S. Barr et.al.|[2411.06624v1](http://arxiv.org/abs/2411.06624v1)|null|
|**2024-11-10**|**MEANT: Multimodal Encoder for Antecedent Information**|Benjamin Iyoya Irving et.al.|[2411.06616v1](http://arxiv.org/abs/2411.06616v1)|null|
|**2024-11-10**|**vTune: Verifiable Fine-Tuning for LLMs Through Backdooring**|Eva Zhang et.al.|[2411.06611v1](http://arxiv.org/abs/2411.06611v1)|null|

#### Abstracts
##### **UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts**
2411.07240v1 by Bo Yang, Qingping Yang, Runtao Liu

The evaluation of mathematical reasoning capabilities is essential for
advancing Artificial General Intelligence (AGI). While Large Language Models
(LLMs) have shown impressive performance in solving mathematical problems,
existing benchmarks such as GSM8K and MATH present limitations, including
narrow problem definitions with specific numbers and reliance on predetermined
rules that hinder accurate assessments of reasoning and adaptability. This
paper introduces the UTMath Benchmark, which robustly evaluates the models
through extensive unit tests. It consists of 1,053 problems across 9
mathematical domains, with over 68 test cases per problem.We propose an
innovative evaluation framework inspired by unit testing in software
development, focusing on both accuracy and reliability of results. Furthermore,
we introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which
encourages LLMs to perform explicit reasoning before generating code, leading
to generating more advanced solution and improved performance. Furthermore, we
are releasing not only the UTMath benchmark but also the UTMath-Train training
dataset (more than 70k samples), to support the community in further exploring
mathematical reasoning.

摘要：評估數學推理能力對於推進人工通用智慧 (AGI) 至關重要。儘管大型語言模型 (LLM) 在解決數學問題方面表現出色，但現有的基準如 GSM8K 和 MATH 存在局限性，包括問題定義狹隘，使用特定數字，以及依賴於預先確定的規則，這些規則阻礙了對推理和適應性的準確評估。本文介紹了 UTMath 基準，它通過廣泛的單元測試對模型進行了穩健的評估。它包含 9 個數學領域的 1,053 個問題，每個問題有超過 68 個測試用例。我們提出了一個創新的評估框架，靈感來自軟體開發中的單元測試，重點關注結果的準確性和可靠性。此外，我們引入了思想推理到編碼 (RCoT) 方法，它鼓勵 LLM 在生成代碼之前執行明確推理，從而生成更高級的解決方案和改進性能。此外，我們不僅發布了 UTMath 基準，還發布了 UTMath-Train 訓練數據集（超過 70k 個樣本），以支持社群進一步探索數學推理。

##### **OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model**
2411.07238v1 by Sumeth Yuenyong, Kobkrit Viriyayudhakorn, Apivadee Piyatumrong, Jillaphat Jaroenkantasima

OpenThaiGPT 1.5 is an advanced Thai language chat model based on Qwen v2.5,
finetuned on over 2,000,000 Thai instruction pairs. This report provides an
engineering perspective on the model's development, capabilities, and
performance. We discuss the model's architecture, training process, and key
features, including multi-turn conversation support, Retrieval Augmented
Generation (RAG) compatibility, and tool-calling functionality. Benchmark
results demonstrate OpenThaiGPT 1.5's state-of-the-art performance on various
Thai language tasks, outperforming other open-source Thai language models. We
also address practical considerations such as GPU memory requirements and
deployment strategies.

摘要：OpenThaiGPT 1.5 是一款進階的泰語聊天模型，基於 Qwen v2.5，經過微調，超過 2,000,000 組泰語指令。本報告提供了模型開發、功能和效能的工程觀點。我們討論了模型的架構、訓練流程和主要功能，包括多回合對話支援、檢索擴增生成 (RAG) 相容性，以及工具呼叫功能。基準測試結果證明 OpenThaiGPT 1.5 在各種泰語任務上表現出最先進的效能，優於其他開源泰語模型。我們也解決了實際考量，例如 GPU 記憶體需求和部署策略。

##### **Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations**
2411.07237v1 by Chaitanya Malaviya, Joseph Chee Chang, Dan Roth, Mohit Iyyer, Mark Yatskar, Kyle Lo

Language model users often issue queries that lack specification, where the
context under which a query was issued -- such as the user's identity, the
query's intent, and the criteria for a response to be useful -- is not
explicit. For instance, a good response to a subjective query like "What book
should I read next?" would depend on the user's preferences, and a good
response to an open-ended query like "How do antibiotics work against
bacteria?" would depend on the user's expertise. This makes evaluation of
responses to such queries an ill-posed task, as evaluators may make arbitrary
judgments about the response quality. To remedy this, we present contextualized
evaluations, a protocol that synthetically constructs context surrounding an
underspecified query and provides it during evaluation. We find that the
presence of context can 1) alter conclusions drawn from evaluation, even
flipping win rates between model pairs, 2) nudge evaluators to make fewer
judgments based on surface-level criteria, like style, and 3) provide new
insights about model behavior across diverse contexts. Specifically, our
procedure uncovers an implicit bias towards WEIRD contexts in models' "default"
responses and we find that models are not equally sensitive to following
different contexts, even when they are provided in prompts.

摘要：語言模型使用者經常發出缺乏規範的查詢，其中發出查詢的背景（例如使用者的身分、查詢的意圖以及回應有用的標準）未明確說明。例如，對於「我下一步該讀什麼書？」這類主觀查詢的良好回應會取決於使用者的喜好，而對於「抗生素如何對抗細菌？」這類開放式查詢的良好回應會取決於使用者的專業知識。這使得評估此類查詢的回應成為一項難以解決的任務，因為評估者可能會對回應品質做出武斷的判斷。為了補救這一點，我們提出了情境化評估，這是一種協定，可以合成構造出未明確指定查詢周圍的背景，並在評估期間提供背景。我們發現背景的存在可以 1) 改變從評估中得出的結論，甚至會顛倒模型配對之間的獲勝率，2) 促使評估者根據表面層標準（例如風格）做出較少的判斷，以及 3) 提供關於模型在不同背景下的行為的新見解。具體來說，我們的程序揭示了模型「預設」回應中對 WEIRD 背景的隱含偏見，我們發現模型對於遵循不同的背景並非同樣敏感，即使這些背景是在提示中提供的。

##### **Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models**
2411.07232v1 by Yoad Tewel, Rinon Gal, Dvir Samuel Yuval Atzmon, Lior Wolf, Gal Chechik

Adding Object into images based on text instructions is a challenging task in
semantic image editing, requiring a balance between preserving the original
scene and seamlessly integrating the new object in a fitting location. Despite
extensive efforts, existing models often struggle with this balance,
particularly with finding a natural location for adding an object in complex
scenes. We introduce Add-it, a training-free approach that extends diffusion
models' attention mechanisms to incorporate information from three key sources:
the scene image, the text prompt, and the generated image itself. Our weighted
extended-attention mechanism maintains structural consistency and fine details
while ensuring natural object placement. Without task-specific fine-tuning,
Add-it achieves state-of-the-art results on both real and generated image
insertion benchmarks, including our newly constructed "Additing Affordance
Benchmark" for evaluating object placement plausibility, outperforming
supervised methods. Human evaluations show that Add-it is preferred in over 80%
of cases, and it also demonstrates improvements in various automated metrics.

摘要：在语义图像编辑中，根据文本指令将对象添加到图像是一项具有挑战性的任务，需要在保留原始场景和将新对象无缝集成到合适位置之间取得平衡。尽管付出了巨大的努力，但现有模型通常难以达到这种平衡，尤其是在复杂场景中为添加对象找到自然位置时。我们引入了 Add-it，这是一种无训练方法，它扩展了扩散模型的注意机制，以纳入来自三个关键来源的信息：场景图像、文本提示和生成图像本身。我们加权的扩展注意机制保持了结构一致性和精细细节，同时确保了自然的物体放置。在没有针对特定任务进行微调的情况下，Add-it 在真实和生成图像插入基准上都取得了最先进的结果，包括我们新构建的“添加能力基准”，用于评估对象放置的合理性，优于监督方法。人类评估表明，在 80% 以上的情况下更喜欢 Add-it，并且它还展示了各种自动化指标的改进。

##### **Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving**
2411.07228v1 by Botao Yu, Frazier N. Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun

To enhance large language models (LLMs) for chemistry problem solving,
several LLM-based agents augmented with tools have been proposed, such as
ChemCrow and Coscientist. However, their evaluations are narrow in scope,
leaving a large gap in understanding the benefits of tools across diverse
chemistry tasks. To bridge this gap, we develop ChemAgent, an enhanced
chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its
performance on both specialized chemistry tasks and general chemistry
questions. Surprisingly, ChemAgent does not consistently outperform its base
LLMs without tools. Our error analysis with a chemistry expert suggests that:
For specialized chemistry tasks, such as synthesis prediction, we should
augment agents with specialized tools; however, for general chemistry questions
like those in exams, agents' ability to reason correctly with chemistry
knowledge matters more, and tool augmentation does not always help.

摘要：為了增強大型語言模型（LLM）在化學問題求解方面的能力，已經提出了多種具備工具增強功能的 LLM 基礎代理，例如 ChemCrow 和 Coscientist。然而，它們的評估範圍狹窄，在了解工具在各種化學任務中的好處方面留下了很大的空白。為了彌補這個差距，我們開發了 ChemAgent，這是一個比 ChemCrow 更強大的化學代理，並對其在專業化學任務和一般化學問題上的性能進行了全面評估。令人驚訝的是，ChemAgent 並沒有始終優於沒有工具的基礎 LLM。我們與化學專家的錯誤分析表明：對於合成預測等專業化學任務，我們應該用專業工具來增強代理；然而，對於考試中出現的類似一般化學問題，代理正確推理化學知識的能力更重要，而工具增強並不總是能提供幫助。

##### **TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models**
2411.07224v1 by Matheus Simão, Fabiano Prado, Omar Abdul Wahab, Anderson Avila

With the widespread of digital environments, reliable authentication and
continuous access control has become crucial. It can minimize cyber attacks and
prevent frauds, specially those associated with identity theft. A particular
interest lies on keystroke dynamics (KD), which refers to the task of
recognizing individuals' identity based on their unique typing style. In this
work, we propose the use of pre-trained language models (PLMs) to recognize
such patterns. Although PLMs have shown high performance on multiple NLP
benchmarks, the use of these models on specific tasks requires customization.
BERT and RoBERTa, for instance, rely on subword tokenization, and they cannot
be directly applied to KD, which requires temporal-character information to
recognize users. Recent character-aware PLMs are able to process both subwords
and character-level information and can be an alternative solution.
Notwithstanding, they are still not suitable to be directly fine-tuned for KD
as they are not optimized to account for user's temporal typing information
(e.g., hold time and flight time). To overcome this limitation, we propose
TempCharBERT, an architecture that incorporates temporal-character information
in the embedding layer of CharBERT. This allows modeling keystroke dynamics for
the purpose of user identification and authentication. Our results show a
significant improvement with this customization. We also showed the feasibility
of training TempCharBERT on a federated learning settings in order to foster
data privacy.

摘要：隨著數位環境的普及，可靠的身分驗證和持續的存取控制已變得至關重要。這可以將網路攻擊降至最低，並防止詐騙，特別是與身分竊取相關的詐騙。一個特別的興趣在於鍵盤動態 (KD)，這是指根據個人獨特的輸入風格來識別個人身分的任務。在這項工作中，我們提出使用預先訓練好的語言模型 (PLM) 來識別這種模式。儘管 PLM 在多個 NLP 基準測試中表現出高性能，但將這些模型用於特定任務需要自訂。例如，BERT 和 RoBERTa 依賴於子字詞化，它們無法直接應用於 KD，而 KD 需要時間字元資訊來識別使用者。最近的字元感知 PLM 能夠處理子字詞和字元層級的資訊，並且可以作為替代方案。儘管如此，它們仍然不適合直接微調 KD，因為它們並未針對使用者的時間輸入資訊（例如，按住時間和飛行時間）進行最佳化。為了克服這個限制，我們提出了 TempCharBERT，這是一種將時間字元資訊納入 CharBERT 嵌入層的架構。這允許為使用者識別和驗證的目的建模鍵盤動態。我們的結果顯示，透過這個自訂有顯著的改善。我們也展示了在聯合學習設定中訓練 TempCharBERT 的可行性，以促進資料隱私。

##### **Grounding Video Models to Actions through Goal Conditioned Exploration**
2411.07223v1 by Yunhao Luo, Yilun Du

Large video models, pretrained on massive amounts of Internet video, provide
a rich source of physical knowledge about the dynamics and motions of objects
and tasks. However, video models are not grounded in the embodiment of an
agent, and do not describe how to actuate the world to reach the visual states
depicted in a video. To tackle this problem, current methods use a separate
vision-based inverse dynamic model trained on embodiment-specific data to map
image states to actions. Gathering data to train such a model is often
expensive and challenging, and this model is limited to visual settings similar
to the ones in which data are available. In this paper, we investigate how to
directly ground video models to continuous actions through self-exploration in
the embodied environment -- using generated video states as visual goals for
exploration. We propose a framework that uses trajectory level action
generation in combination with video guidance to enable an agent to solve
complex tasks without any external supervision, e.g., rewards, action labels,
or segmentation masks. We validate the proposed approach on 8 tasks in Libero,
6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual
Navigation. We show how our approach is on par with or even surpasses multiple
behavior cloning baselines trained on expert demonstrations while without
requiring any action annotations.

摘要：大型视频模型经过大量互联网视频预训练，提供了关于物体和任务的动态和运动的丰富物理知识。然而，视频模型并没有建立在代理的体现中，也没有描述如何启动世界以达到视频中描绘的视觉状态。为了解决这个问题，当前的方法使用一个单独的基于视觉的反向动态模型，该模型在特定于体现的数据上进行训练，以将图像状态映射到动作。收集数据来训练这样一个模型通常既昂贵又具有挑战性，并且该模型仅限于与数据可用的模型类似的视觉设置。在本文中，我们研究如何通过在具身环境中进行自我探索，将视频模型直接归结为连续动作——使用生成的视频状态作为探索的视觉目标。我们提出一个框架，该框架结合使用轨迹级别动作生成和视频指导，使代理能够在没有任何外部监督（例如奖励、动作标签或分割掩码）的情况下解决复杂的任务。我们在 Libero 中的 8 个任务、MetaWorld 中的 6 个任务、Calvin 中的 4 个任务和 iThor Visual Navigation 中的 12 个任务上验证了所提出的方法。我们展示了我们的方法如何与在专家演示中训练的多个行为克隆基线相当甚至超过它们，而不需要任何动作注释。

##### **TreeCoders: Trees of Transformers**
2411.07218v1 by Pierre Colonna D'Istria, Abdulrahman Altahhan

In this paper, we introduce TreeCoders, a novel family of transformer trees.
We moved away from traditional linear transformers to complete k-ary trees.
Transformer blocks serve as nodes, and generic classifiers learn to select the
best child and route the sequence of tokens to a specific leaf. The selectors,
moved outside the transformer blocks, allow for the use of a variety of
architecture without further modifications. Furthermore, our proposed
architecture supports sparse node activation due to the logarithmic complexity
of a tree search. We validate our idea by testing a series of decoder-only tree
transformers, achieving competitive results across a diverse range of language
datasets. Our study demonstrates that the proposed tree transformer model
outperforms a size-equivalent linear transformer model 76\% of the time over a
wide range of tree architectures. Furthermore, our proposed model naturally
lends itself to distributed implementation.

摘要：在本文中，我們介紹了 TreeCoders，一種新穎的Transformer樹系列。
我們從傳統線性Transformer轉移到完成 k 元樹。
Transformer區塊作為節點，通用分類器學習選擇
最佳子節點並將序列標記路由到特定葉節點。選擇器，
移到Transformer區塊外部，允許使用各種
架構而無需進一步修改。此外，我們提出的
架構支援稀疏節點啟用，因為樹搜尋對數複雜度。我們驗證我們的想法，方法是測試一系列僅解碼器樹
Transformer，在各種語言中實現競爭結果
資料集。我們的研究表明，所提出的樹Transformer模型
在廣泛的樹架構中，76% 的時間優於大小相當的線性Transformer模型。此外，我們提出的模型自然
適用於分散式實作。

##### **OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision**
2411.07199v1 by Cong Wei, Zheyang Xiong, Weiming Ren, Xinrun Du, Ge Zhang, Wenhu Chen

Instruction-guided image editing methods have demonstrated significant
potential by training diffusion models on automatically synthesized or manually
annotated image editing pairs. However, these methods remain far from
practical, real-life applications. We identify three primary challenges
contributing to this gap. Firstly, existing models have limited editing skills
due to the biased synthesis process. Secondly, these methods are trained with
datasets with a high volume of noise and artifacts. This is due to the
application of simple filtering methods like CLIP-score. Thirdly, all these
datasets are restricted to a single low resolution and fixed aspect ratio,
limiting the versatility to handle real-world use cases. In this paper, we
present \omniedit, which is an omnipotent editor to handle seven different
image editing tasks with any aspect ratio seamlessly. Our contribution is in
four folds: (1) \omniedit is trained by utilizing the supervision from seven
different specialist models to ensure task coverage. (2) we utilize importance
sampling based on the scores provided by large multimodal models (like GPT-4o)
instead of CLIP-score to improve the data quality. (3) we propose a new editing
architecture called EditNet to greatly boost the editing success rate, (4) we
provide images with different aspect ratios to ensure that our model can handle
any image in the wild. We have curated a test set containing images of
different aspect ratios, accompanied by diverse instructions to cover different
tasks. Both automatic evaluation and human evaluations demonstrate that
\omniedit can significantly outperform all the existing models. Our code,
dataset and model will be available at
\url{https://tiger-ai-lab.github.io/OmniEdit/}

摘要：<paragraph>以指令為導向的影像編輯方法已展現出顯著的潛力，方法是訓練擴散模型於自動合成或手動標註的影像編輯配對上。然而，這些方法仍遠離實務上的實際應用。我們找出導致此差距的三個主要挑戰。首先，現有的模型由於有偏差的合成程序，導致編輯技能受限。其次，這些方法使用包含大量雜訊和人工製品的資料集進行訓練。這是由於應用像 CLIP 分數之類的簡單過濾方法所致。第三，所有這些資料集都限制於單一低解析度和固定長寬比，限制了處理實際用例的多功能性。在本文中，我們提出 \omniedit，這是一個萬能編輯器，可無縫處理七種不同的影像編輯任務，且不限長寬比。我們的貢獻有四個面向：(1) \omniedit 透過利用來自七種不同專家模型的監督進行訓練，以確保任務涵蓋範圍。(2) 我們利用大型多模態模型 (例如 GPT-4o) 所提供的分數，而不是 CLIP 分數，來進行重要性抽樣，以提升資料品質。(3) 我們提出一個名為 EditNet 的新編輯架構，以大幅提升編輯成功率，(4) 我們提供具有不同長寬比的影像，以確保我們的模型能夠處理任何野外影像。我們策劃了一個包含不同長寬比影像的測試集，並附有不同的指令來涵蓋不同的任務。自動評估和人工評估均顯示，\omniedit 能顯著優於所有現有模型。我們的程式碼、資料集和模型將會在 \url{https://tiger-ai-lab.github.io/OmniEdit/} 提供。</paragraph>

##### **The Super Weight in Large Language Models**
2411.07191v1 by Mengxia Yu, De Wang, Qi Shan, Colorado Reed, Alvin Wan

Recent works have shown a surprising result: a small fraction of Large
Language Model (LLM) parameter outliers are disproportionately important to the
quality of the model. LLMs contain billions of parameters, so these small
fractions, such as 0.01%, translate to hundreds of thousands of parameters. In
this work, we present an even more surprising finding: Pruning as few as a
single parameter can destroy an LLM's ability to generate text -- increasing
perplexity by 3 orders of magnitude and reducing zero-shot accuracy to
guessing. We propose a data-free method for identifying such parameters, termed
super weights, using a single forward pass through the model. We additionally
find that these super weights induce correspondingly rare and large activation
outliers, termed super activations. When preserved with high precision, super
activations can improve simple round-to-nearest quantization to become
competitive with state-of-the-art methods. For weight quantization, we
similarly find that by preserving the super weight and clipping other weight
outliers, round-to-nearest quantization can scale to much larger block sizes
than previously considered. To facilitate further research into super weights,
we provide an index of super weight coordinates for common, openly available
LLMs.

摘要：<paragraph>最近的研究显示了一个令人惊讶的结果：大型语言模型 (LLM) 参数异常值的一小部分对于模型的质量至关重要。LLM 包含数十亿个参数，因此这些小部分，例如 0.01%，转换为数十万个参数。在这项工作中，我们提出了一个更令人惊讶的发现：修剪一个参数就可以破坏 LLM 生成文本的能力——困惑度增加了 3 个数量级，并将零次精度降低到猜测。我们提出了一种无数据的方法来识别这些参数，称为超级权重，使用单个前向传递通过模型。我们还发现，这些超级权重诱导了相应罕见且大的激活异常值，称为超级激活。当以高精度保留时，超级激活可以改善简单的四舍五入量化，以与最先进的方法竞争。对于权重量化，我们同样发现，通过保留超级权重并裁剪其他权重异常值，四舍五入量化可以扩展到比以前考虑的更大的块大小。为了促进对超级权重的进一步研究，我们提供了一个超级权重坐标索引，用于常见且公开可用的 LLM。</paragraph>

##### **NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics**
2411.07186v1 by David Robinson, Marius Miron, Masato Hagiwara, Olivier Pietquin

Large language models (LLMs) prompted with text and audio represent the state
of the art in various auditory tasks, including speech, music, and general
audio, showing emergent abilities on unseen tasks. However, these capabilities
have yet to be fully demonstrated in bioacoustics tasks, such as detecting
animal vocalizations in large recordings, classifying rare and endangered
species, and labeling context and behavior - tasks that are crucial for
conservation, biodiversity monitoring, and the study of animal behavior. In
this work, we present NatureLM-audio, the first audio-language foundation model
specifically designed for bioacoustics. Our carefully curated training dataset
comprises text-audio pairs spanning a diverse range of bioacoustics, speech,
and music data, designed to address the challenges posed by limited annotated
datasets in the field. We demonstrate successful transfer of learned
representations from music and speech to bioacoustics, and our model shows
promising generalization to unseen taxa and tasks. Importantly, we test
NatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of
the art (SotA) on several bioacoustics tasks, including zero-shot
classification of unseen species. To advance bioacoustics research, we also
open-source the code for generating training and benchmark data, as well as for
training the model.

摘要：大型語言模型 (LLM) 以文字和音訊為提示，代表各種聽覺任務的最新技術，包括語音、音樂和一般音訊，在未見任務中展現出新興的能力。然而，這些功能尚未在生物音響任務中得到充分展示，例如在大型錄音中偵測動物發聲、分類稀有和瀕臨絕種的物種，以及標記背景和行為，這些任務對於保育、生物多樣性監測和動物行為研究至關重要。在這項工作中，我們提出 NatureLM-audio，這是第一個專門為生物音響設計的音訊語言基礎模型。我們精心策劃的訓練資料集包含跨越各種生物音響、語音和音樂資料的文字音訊配對，旨在解決該領域中標註資料集有限所帶來的挑戰。我們展示了從音樂和語音到生物音響的學習表徵的成功轉移，而我們的模型顯示出對未見分類單元和任務的有前景的概化。重要的是，我們在一個新基準 (BEANS-Zero) 上測試 NatureLM-audio，它在幾個生物音響任務上設定了新的技術水準 (SotA)，包括未見物種的零次學習分類。為了推進生物音響研究，我們也開放原始碼來產生訓練和基準資料，以及訓練模型。

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

摘要：多源无监督域自适应旨在利用来自多个源域的标记数据，训练机器学习模型，以便在没有标签的目标域上很好地泛化。源域选择在确定模型性能方面起着至关重要的作用。它依赖于源域和目标域之间的相似性。尽管如此，现有的源域选择工作通常涉及重量级计算程序，尤其是在处理众多源域以及需要从中识别最佳源域时。在本文中，我们介绍了一个在多个源域上对机器学习模型进行逐步微调 (GFT) 的框架。我们将多个源域表示为无向加权图。然后，我们为图中沿任何路径的 GFT 给出了一个新的泛化误差界，用于确定对应于最佳训练顺序的最佳路径。通过这种表述，我们介绍了三种轻量级的图路由策略，这些策略倾向于最小化误差界。我们最好的策略在自然语言推理 (NLI) 任务上比最先进的技术提高了 2.3% 的准确率，并在情感分析 (SA) 任务上取得了有竞争力的性能，特别是在我们用于 SA 的更多样化的数据子集上提高了 3.9%。

##### **Counterfactual Generation from Language Models**
2411.07180v1 by Shauli Ravfogel, Anej Svete, Vésteinn Snæbjarnarson, Ryan Cotterell

Understanding and manipulating the causal generation mechanisms in language
models is essential for controlling their behavior. Previous work has primarily
relied on techniques such as representation surgery -- e.g., model ablations or
manipulation of linear subspaces tied to specific concepts -- to intervene on
these models. To understand the impact of interventions precisely, it is useful
to examine counterfactuals -- e.g., how a given sentence would have appeared
had it been generated by the model following a specific intervention. We
highlight that counterfactual reasoning is conceptually distinct from
interventions, as articulated in Pearl's causal hierarchy. Based on this
observation, we propose a framework for generating true string counterfactuals
by reformulating language models as Generalized Structural-equation. Models
using the Gumbel-max trick. This allows us to model the joint distribution over
original strings and their counterfactuals resulting from the same
instantiation of the sampling noise. We develop an algorithm based on hindsight
Gumbel sampling that allows us to infer the latent noise variables and generate
counterfactuals of observed strings. Our experiments demonstrate that the
approach produces meaningful counterfactuals while at the same time showing
that commonly used intervention techniques have considerable undesired side
effects.

摘要：理解並操控語言模型中的因果生成機制，對於控制其行為至關重要。以往的研究主要依賴於表徵手術等技術——例如，模型消融或與特定概念相關的線性子空間的操控——來干預這些模型。為了精確理解干預的影響，審查反事實——例如，如果模型在特定干預後生成給定的句子，句子將如何呈現——是有用的。我們強調，反事實推理在概念上不同於干預，正如 Pearl 的因果層級所闡述的那樣。基於此觀察，我們提出了一個生成真正字串反事實的框架，方法是將語言模型重新表述為廣義結構方程模型，使用 Gumbel-max 技巧。這使我們能夠對原始字串及其反事實的聯合分佈建模，這些反事實來自採樣雜訊的相同例示。我們根據後見之明 Gumbel 採樣開發了一種演算法，使我們能夠推斷潛在雜訊變數並生成已觀察字串的反事實。我們的實驗證明，該方法產生有意義的反事實，同時表明常用的干預技術具有相當大的不良副作用。

##### **More Expressive Attention with Negative Weights**
2411.07176v1 by Ang Lv, Ruobing Xie, Shuaipeng Li, Jiayi Liao, Xingwu Sun, Zhanhui Kang, Rui Yan

We propose a novel attention mechanism, named Cog Attention, that enables
attention weights to be negative for enhanced expressiveness, which stems from
two key factors: (1) Cog Attention can shift the token deletion and copying
function from a static OV matrix to dynamic QK inner products, with the OV
matrix now focusing more on refinement or modification. The attention head can
simultaneously delete, copy, or retain tokens by assigning them negative,
positive, or minimal attention weights, respectively. As a result, a single
attention head becomes more flexible and expressive. (2) Cog Attention improves
the model's robustness against representational collapse, which can occur when
earlier tokens are over-squashed into later positions, leading to homogeneous
representations. Negative weights reduce effective information paths from
earlier to later tokens, helping to mitigate this issue. We develop
Transformer-like models which use Cog Attention as attention modules, including
decoder-only models for language modeling and U-ViT diffusion models for image
generation. Experiments show that models using Cog Attention exhibit superior
performance compared to those employing traditional softmax attention modules.
Our approach suggests a promising research direction for rethinking and
breaking the entrenched constraints of traditional softmax attention, such as
the requirement for non-negative weights.

摘要：我們提出了一種名為 Cog Attention 的新注意力機制，它能讓注意力權重為負數以增強表達力，這源於兩個關鍵因素：(1) Cog Attention 可以將符號刪除和複製功能從靜態 OV 矩陣轉移到動態 QK 內積，而 OV 矩陣現在更專注於精煉或修改。注意力頭部可以同時刪除、複製或保留符號，分別給它們分配負、正或最小的注意力權重。因此，單一注意力頭部變得更靈活和富有表現力。(2) Cog Attention 提高了模型對表徵崩潰的穩健性，這種情況可能發生在較早的符號過度壓縮到後面的位置時，導致同質表徵。負權重減少了從較早符號到較後符號的有效資訊路徑，有助於緩解這個問題。我們開發了使用 Cog Attention 作為注意力模組的類 Transformer 模型，包括用於語言建模的僅解碼器模型和用於影像生成的 U-ViT 擴散模型。實驗表明，使用 Cog Attention 的模型表現出優於採用傳統 softmax 注意力模組的模型。我們的做法為重新思考和打破傳統 softmax 注意力的根深蒂固約束（例如非負權重的要求）提出了有希望的研究方向。

##### **Continual Memorization of Factoids in Large Language Models**
2411.07175v1 by Howard Chen, Jiayi Geng, Adithya Bhaskar, Dan Friedman, Danqi Chen

Large language models can absorb a massive amount of knowledge through
pretraining, but pretraining is inefficient for acquiring long-tailed or
specialized facts. Therefore, fine-tuning on specialized or new knowledge that
reflects changes in the world has become popular, though it risks disrupting
the model's original capabilities. We study this fragility in the context of
continual memorization, where the model is trained on a small set of long-tail
factoids (factual associations) and must retain these factoids after multiple
stages of subsequent training on other datasets. Through extensive experiments,
we show that LLMs suffer from forgetting across a wide range of subsequent
tasks, and simple replay techniques do not fully prevent forgetting, especially
when the factoid datasets are trained in the later stages. We posit that there
are two ways to alleviate forgetting: 1) protect the memorization process as
the model learns the factoids, or 2) reduce interference from training in later
stages. With this insight, we develop an effective mitigation strategy: REMIX
(Random and Generic Data Mixing). REMIX prevents forgetting by mixing generic
data sampled from pretraining corpora or even randomly generated word sequences
during each stage, despite being unrelated to the memorized factoids in the
first stage. REMIX can recover performance from severe forgetting, often
outperforming replay-based methods that have access to the factoids from the
first stage. We then analyze how REMIX alters the learning process and find
that successful forgetting prevention is associated with a pattern: the model
stores factoids in earlier layers than usual and diversifies the set of layers
that store these factoids. The efficacy of REMIX invites further investigation
into the underlying dynamics of memorization and forgetting, opening exciting
possibilities for future research.

摘要：大型語言模型可透過預訓練吸收大量知識，但預訓練對於獲取長尾或專業知識而言效率低下。因此，針對反映世界變化的專業或新知識進行微調已變得普遍，儘管這有破壞模型原始功能的風險。我們在持續記憶的背景下研究這種脆弱性，其中模型在少量長尾事實（事實關聯）上進行訓練，並且必須在後續在其他資料集上進行多個階段訓練後保留這些事實。透過廣泛的實驗，我們表明 LLM 在各種後續任務中會發生遺忘，而且簡單的重播技術並不能完全防止遺忘，特別是在後續階段訓練事實資料集時。我們假設有兩種方法可以減輕遺忘：1) 在模型學習事實時保護記憶過程，或 2) 減少後續階段訓練的干擾。有了這個見解，我們制定了一個有效的緩解策略：REMIX（隨機和通用資料混合）。REMIX 透過在每個階段混合從預訓練語料庫中取樣的通用資料，甚至隨機產生的字詞序列來防止遺忘，儘管與第一階段中記憶的事實無關。REMIX 可以從嚴重的遺忘中恢復效能，通常優於可以存取第一階段事實的基於重播的方法。然後我們分析 REMIX 如何改變學習過程，並發現成功的遺忘預防與一個模式相關：模型比平常更早將事實儲存在較早的層中，並將儲存這些事實的層組多樣化。REMIX 的功效促使進一步研究記憶和遺忘的基礎動態，為未來的研究開啟令人興奮的可能性。

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

摘要：透過社群媒體監控公眾情緒在 COVID-19 等健康危機期間可能很有幫助。然而，傳統的基於頻率、資料驅動的神經網路方法可能會錯過新相關的內容，因為語言在動態演化的環境中會持續演化。由人類策劃的象徵性知識來源（例如標準語言和俚語術語的詞彙）可能會提升社群媒體在演化語言中的訊號。我們引入一種將神經網路與象徵性知識來源整合的神經符號方法，增強與 COVID-19 相關的心理健康相關推文的偵測和詮釋。我們的做法使用大型資料集語料庫（約 120 億則推文、250 萬個 subreddit 資料和 70 萬則新聞文章）和多個知識圖譜進行評估。這種方法動態適應演化的語言，優於純資料驅動模型，F1 分數超過 92%。這種方法也顯示出比微調預訓練大型語言模型 (LLM) 更快適應新資料和更低的運算需求。本研究證明了神經符號方法在動態環境中詮釋文字的優點，適用於健康監控等任務。

##### **A Primer on Word Embeddings: AI Techniques for Text Analysis in Social Work**
2411.07156v1 by Brian E. Perron, Kelley A. Rivenburgh, Bryan G. Victor, Zia Qi, Hui Luan

Word embeddings represent a transformative technology for analyzing text data
in social work research, offering sophisticated tools for understanding case
notes, policy documents, research literature, and other text-based materials.
This methodological paper introduces word embeddings to social work
researchers, explaining how these mathematical representations capture meaning
and relationships in text data more effectively than traditional keyword-based
approaches. We discuss fundamental concepts, technical foundations, and
practical applications, including semantic search, clustering, and retrieval
augmented generation. The paper demonstrates how embeddings can enhance
research workflows through concrete examples from social work practice, such as
analyzing case notes for housing instability patterns and comparing social work
licensing examinations across languages. While highlighting the potential of
embeddings for advancing social work research, we acknowledge limitations
including information loss, training data constraints, and potential biases. We
conclude that successfully implementing embedding technologies in social work
requires developing domain-specific models, creating accessible tools, and
establishing best practices aligned with social work's ethical principles. This
integration can enhance our ability to analyze complex patterns in text data
while supporting more effective services and interventions.

摘要：詞彙嵌入代表了一種變革性的技術，可用於分析社工研究中的文字資料，並提供精密的工具來理解個案筆記、政策文件、研究文獻和其他基於文字的材料。這篇方法論論文將詞彙嵌入介紹給社工研究人員，說明這些數學表徵如何比傳統的基於關鍵字的方法更有效地擷取文字資料中的意義和關係。我們會討論基本概念、技術基礎和實務應用，包括語意搜尋、分群和檢索增強產生。本文透過社工實務中的具體範例說明嵌入如何增強研究工作流程，例如分析個案筆記以找出住房不穩定的模式，以及比較不同語言的社工執照考試。我們在強調嵌入對促進社工研究的潛力的同時，也承認其限制，包括資訊遺失、訓練資料限制和潛在偏見。我們得出的結論是，在社工中成功實施嵌入技術需要開發特定領域的模型、建立可存取的工具，以及建立與社工倫理原則一致的最佳實務。這種整合可以增強我們分析文字資料中複雜模式的能力，同時支援更有效的服務和介入措施。

##### **HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals**
2411.07152v1 by Lingbo Mo, Shun Jiang, Akash Maharaj, Bernard Hishamunda, Yunyao Li

Task-Oriented Dialogue (TOD) systems assist users in completing tasks through
natural language interactions, often relying on a single-layered workflow
structure for slot-filling in public tasks, such as hotel bookings. However, in
enterprise environments, which involve rich domain-specific knowledge, TOD
systems face challenges due to task complexity and the lack of standardized
documentation. In this work, we introduce HierTOD, an enterprise TOD system
driven by hierarchical goals and can support composite workflows. By focusing
on goal-driven interactions, our system serves a more proactive role,
facilitating mixed-initiative dialogue and improving task completion. Equipped
with components for natural language understanding, composite goal retriever,
dialogue management, and response generation, backed by a well-organized data
service with domain knowledge base and retrieval engine, HierTOD delivers
efficient task assistance. Furthermore, our system implementation unifies two
TOD paradigms: slot-filling for information collection and step-by-step
guidance for task execution. Our human study demonstrates the effectiveness and
helpfulness of HierTOD in performing both paradigms.

摘要：任務導向對話 (TOD) 系統協助使用者透過自然語言互動完成任務，通常依賴單層工作流程結構，以填補公共任務中的槽位，例如飯店預訂。然而，在涉及豐富特定領域知識的企業環境中，TOD 系統會因為任務複雜性和缺乏標準化文件而面臨挑戰。在這項工作中，我們介紹 HierTOD，一種由階層目標驅動且支援複合工作流程的企業 TOD 系統。透過專注於目標導向互動，我們的系統扮演更積極的角色，促進混合主動對話並改善任務完成。配備自然語言理解、複合目標擷取器、對話管理和回應產生等元件，並由具備領域知識庫和擷取引擎的井然有序資料服務提供支援，HierTOD 提供有效的任務協助。此外，我們的系統實作統一了兩種 TOD 典範：用於資訊收集的槽位填補和用於任務執行的逐步指南。我們的人類研究證明了 HierTOD 在執行這兩種典範方面的有效性和助益。

##### **Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models**
2411.07140v1 by Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Hui Huang, Weixun Wang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Xuepeng Liu, Dekai Sun, Wenbo Su, Bo Zheng

New LLM evaluation benchmarks are important to align with the rapid
development of Large Language Models (LLMs). In this work, we present Chinese
SimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality
ability of language models to answer short questions, and Chinese SimpleQA
mainly has five properties (i.e., Chinese, Diverse, High-quality, Static,
Easy-to-evaluate). Specifically, first, we focus on the Chinese language over 6
major topics with 99 diverse subtopics. Second, we conduct a comprehensive
quality control process to achieve high-quality questions and answers, where
the reference answers are static and cannot be changed over time. Third,
following SimpleQA, the questions and answers are very short, and the grading
process is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we
perform a comprehensive evaluation on the factuality abilities of existing
LLMs. Finally, we hope that Chinese SimpleQA could guide the developers to
better understand the Chinese factuality abilities of their models and
facilitate the growth of foundation models.

摘要：新的 LLM 評估基準對於與大型語言模型 (LLM) 的快速發展保持一致非常重要。在這項工作中，我們提出中文 SimpleQA，這是第一個全面的中文基準，用於評估語言模型回答簡短問題的事實能力，而中文 SimpleQA 主要有五個特性（即中文、多元化、高品質、靜態、易於評估）。具體來說，首先，我們專注於 6 個主要主題的中文，以及 99 個不同的子主題。其次，我們進行全面的品質控管流程，以獲得高品質的問題和答案，其中參考答案是靜態的，並且不會隨著時間而改變。第三，遵循 SimpleQA，問題和答案非常簡短，評分過程基於 OpenAI API，易於評估。根據中文 SimpleQA，我們對現有 LLM 的事實能力進行全面評估。最後，我們希望中文 SimpleQA 可以引導開發人員更好地了解其模型的中文事實能力，並促進基礎模型的發展。

##### **Edify 3D: Scalable High-Quality 3D Asset Generation**
2411.07135v1 by NVIDIA, :, Maciej Bala, Yin Cui, Yifan Ding, Yunhao Ge, Zekun Hao, Jon Hasselgren, Jacob Huffman, Jingyi Jin, J. P. Lewis, Zhaoshuo Li, Chen-Hsuan Lin, Yen-Chen Lin, Tsung-Yi Lin, Ming-Yu Liu, Alice Luo, Qianli Ma, Jacob Munkberg, Stella Shi, Fangyin Wei, Donglai Xiang, Jiashu Xu, Xiaohui Zeng, Qinsheng Zhang

We introduce Edify 3D, an advanced solution designed for high-quality 3D
asset generation. Our method first synthesizes RGB and surface normal images of
the described object at multiple viewpoints using a diffusion model. The
multi-view observations are then used to reconstruct the shape, texture, and
PBR materials of the object. Our method can generate high-quality 3D assets
with detailed geometry, clean shape topologies, high-resolution textures, and
materials within 2 minutes of runtime.

摘要：我們推出 Edify 3D，這是一種先進的解決方案，專為高品質 3D 資產生成而設計。我們的技術首先使用擴散模型，在多個視點合成描述物件的 RGB 和曲面法線影像。接著使用多視圖觀察，重建物件的形狀、紋理和 PBR 材質。我們的技術可以在 2 分鐘的執行時間內，產生具有詳細幾何形狀、乾淨形狀拓撲、高解析度紋理和材質的高品質 3D 資產。

##### **Stronger Models are NOT Stronger Teachers for Instruction Tuning**
2411.07133v1 by Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Radha Poovendran

Instruction tuning has been widely adopted to ensure large language models
(LLMs) follow user instructions effectively. The resulting
instruction-following capabilities of LLMs heavily rely on the instruction
datasets used for tuning. Recently, synthetic instruction datasets have emerged
as an economically viable solution to provide LLMs diverse and high-quality
instructions. However, existing approaches typically assume that larger or
stronger models are stronger teachers for instruction tuning, and hence simply
adopt these models as response generators to the synthetic instructions. In
this paper, we challenge this commonly-adopted assumption. Our extensive
experiments across five base models and twenty response generators reveal that
larger and stronger models are not necessarily stronger teachers of smaller
models. We refer to this phenomenon as the Larger Models' Paradox. We observe
that existing metrics cannot precisely predict the effectiveness of response
generators since they ignore the compatibility between teachers and base models
being fine-tuned. We thus develop a novel metric, named as
Compatibility-Adjusted Reward (CAR) to measure the effectiveness of response
generators. Our experiments across five base models demonstrate that CAR
outperforms almost all baselines.

摘要：指令微调已被广泛采用，以确保大型语言模型 (LLM) 有效遵循用户指令。LLM 的指令遵循能力很大程度上依赖于用于微调的指令数据集。最近，合成指令数据集已成为为 LLM 提供多样化且高质量指令的一种经济可行的解决方案。然而，现有方法通常假设更大或更强的模型是指令微调的更强教师，因此只是采用这些模型作为合成指令的响应生成器。在本文中，我们对这一普遍采用的假设提出质疑。我们对五个基础模型和 20 个响应生成器进行的广泛实验表明，更大、更强的模型不一定是对较小模型的更强老师。我们将这种现象称为大模型悖论。我们观察到，现有的指标无法准确预测响应生成器的有效性，因为它们忽略了正在微调的教师和基础模型之间的兼容性。因此，我们开发了一种名为兼容性调整奖励 (CAR) 的新指标来衡量响应生成器的有效性。我们对五个基础模型的实验表明，CAR 优于几乎所有基线。

##### **Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**
2411.07132v1 by Taihang Hu, Linxuan Li, Joost van de Weijer, Hongcheng Gao, Fahad Shahbaz Khan, Jian Yang, Ming-Ming Cheng, Kai Wang, Yaxing Wang

Although text-to-image (T2I) models exhibit remarkable generation
capabilities, they frequently fail to accurately bind semantically related
objects or attributes in the input prompts; a challenge termed semantic
binding. Previous approaches either involve intensive fine-tuning of the entire
T2I model or require users or large language models to specify generation
layouts, adding complexity. In this paper, we define semantic binding as the
task of associating a given object with its attribute, termed attribute
binding, or linking it to other related sub-objects, referred to as object
binding. We introduce a novel method called Token Merging (ToMe), which
enhances semantic binding by aggregating relevant tokens into a single
composite token. This ensures that the object, its attributes and sub-objects
all share the same cross-attention map. Additionally, to address potential
confusion among main objects with complex textual prompts, we propose end token
substitution as a complementary strategy. To further refine our approach in the
initial stages of T2I generation, where layouts are determined, we incorporate
two auxiliary losses, an entropy loss and a semantic binding loss, to
iteratively update the composite token to improve the generation integrity. We
conducted extensive experiments to validate the effectiveness of ToMe,
comparing it against various existing methods on the T2I-CompBench and our
proposed GPT-4o object binding benchmark. Our method is particularly effective
in complex scenarios that involve multiple objects and attributes, which
previous methods often fail to address. The code will be publicly available at
\url{https://github.com/hutaihang/ToMe}.

摘要：儘管文字轉圖像 (T2I) 模型展現出卓越的生成能力，但它們經常無法準確地結合輸入提示中的語義相關物件或屬性；這項挑戰稱為語義結合。先前的做法包括對整個 T2I 模型進行密集微調，或要求使用者或大型語言模型指定生成佈局，這增加了複雜性。在本文中，我們將語義結合定義為將給定物件與其屬性（稱為屬性結合）關聯，或將其連結到其他相關子物件（稱為物件結合）的任務。我們引入一種名為 Token Merging (ToMe) 的新方法，透過將相關的 token 聚合到單一複合 token 中來增強語義結合。這可確保物件、其屬性和子物件都共用相同的交叉注意力圖。此外，為了解決在複雜文字提示中主物件之間潛在的混淆，我們提出終端 token 替換作為一種補充策略。為了進一步改善我們在 T2I 生成初始階段（其中會決定佈局）中的方法，我們納入兩個輔助損失，一個是熵損失，另一個是語義結合損失，以反覆更新複合 token 來改善生成完整性。我們進行了廣泛的實驗來驗證 ToMe 的有效性，並在 T2I-CompBench 和我們提出的 GPT-4o 物件結合基準上將其與各種現有方法進行比較。我們的這項方法在涉及多個物件和屬性的複雜場景中特別有效，而先前的許多方法都無法處理這類場景。程式碼將公開於 \url{https://github.com/hutaihang/ToMe}。

##### **Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation**
2411.07130v1 by Kaijian Zou, Muhammad Khalifa, Lu Wang

Language models (LMs) have demonstrated an improved capacity to handle
long-context information, yet existing long-context benchmarks primarily
measure LMs' retrieval abilities with extended inputs, e.g., pinpointing a
short phrase from long-form text. Therefore, they may fall short when
evaluating models' global context understanding capacity, such as synthesizing
and reasoning over content across input to generate the response. In this
paper, we study long-context language model (LCLM) evaluation through many-shot
in-context learning (ICL). Concretely, we identify the skills each ICL task
requires, and examine models' long-context capabilities on them. We first ask:
What types of ICL tasks benefit from additional demonstrations, and are these
tasks effective at evaluating LCLMs? We find that classification and
summarization tasks show notable performance improvements with additional
demonstrations, while translation and reasoning tasks do not exhibit clear
trends. This suggests the classification tasks predominantly test models'
retrieval skills. Next, we ask: To what extent does each task require retrieval
skills versus global context understanding from LCLMs? We develop metrics to
categorize ICL tasks into two groups: (i) retrieval tasks that require strong
retrieval ability to pinpoint relevant examples, and (ii) global context
understanding tasks that necessitate a deeper comprehension of the full input.
We find that not all datasets can effectively evaluate these long-context
capabilities. To address this gap, we introduce a new many-shot ICL benchmark,
MANYICLBENCH, designed to characterize LCLMs' retrieval and global context
understanding capabilities separately. Benchmarking 11 open-weight LCLMs with
MANYICLBENCH, we find that while state-of-the-art models perform well in
retrieval tasks up to 64k tokens, many show significant drops in global context
tasks at just 16k tokens.

摘要：<paragraph>語言模型 (LM) 已展現出處理長語境資訊的進步能力，但現有的長語境基準主要測量 LM 的擷取能力，輸入內容較長，例如從長篇文字中精確找出短語。因此，在評估模型的整體語境理解能力時，例如綜合和推理輸入中的內容以產生回應，這些基準可能會不足。在本文中，我們透過多輪次語境中學習 (ICL) 研究長語境語言模型 (LCLM) 評估。具體來說，我們找出每個 ICL 任務所需的技能，並檢視模型在這些技能上的長語境能力。我們首先詢問：哪些類型的 ICL 任務可以從額外的示範中受益，這些任務在評估 LCLM 時是否有效？我們發現分類和摘要任務在額外的示範中表現出顯著的進步，而翻譯和推理任務並未展現出明確的趨勢。這表示分類任務主要測試模型的擷取技能。接下來，我們詢問：每個任務在多大程度上需要 LCLM 的擷取技能和整體語境理解？我們開發指標將 ICL 任務分類為兩組：(i) 需要強大擷取能力來精確找出相關範例的擷取任務，以及 (ii) 需要更深入理解完整輸入的整體語境理解任務。我們發現並非所有資料集都能有效評估這些長語境能力。為了解決這個差距，我們引進一個新的多輪次 ICL 基準，MANYICLBENCH，旨在分別描述 LCLM 的擷取和整體語境理解能力。使用 MANYICLBENCH 對 11 個開放權重的 LCLM 進行基準測試，我們發現雖然最先進的模型在長達 64k 個詞彙的擷取任務中表現良好，但許多模型在僅 16k 個詞彙的整體語境任務中顯著下降。</paragraph>

##### **Benchmarking LLMs' Judgments with No Gold Standard**
2411.07127v1 by Shengwei Xu, Yuxuan Lu, Grant Schoenebeck, Yuqing Kong

We introduce the GEM (Generative Estimator for Mutual Information), an
evaluation metric for assessing language generation by Large Language Models
(LLMs), particularly in generating informative judgments, without the need for
a gold standard reference. GEM broadens the scenarios where we can benchmark
LLM generation performance-from traditional ones, like machine translation and
summarization, where gold standard references are readily available, to
subjective tasks without clear gold standards, such as academic peer review.
  GEM uses a generative model to estimate mutual information between candidate
and reference responses, without requiring the reference to be a gold standard.
In experiments on a human-annotated dataset, GEM demonstrates competitive
correlations with human scores compared to the state-of-the-art GPT-4o
Examiner, and outperforms all other baselines. Additionally, GEM is more robust
against strategic manipulations, such as rephrasing or elongation, which can
artificially inflate scores under a GPT-4o Examiner.
  We also present GRE-bench (Generating Review Evaluation Benchmark) which
evaluates LLMs based on how well they can generate high-quality peer reviews
for academic research papers. Because GRE-bench is based upon GEM, it inherits
its robustness properties. Additionally, GRE-bench circumvents data
contamination problems (or data leakage) by using the continuous influx of new
open-access research papers and peer reviews each year. We show GRE-bench
results of various popular LLMs on their peer review capabilities using the
ICLR2023 dataset.

摘要：<paragraph>我們介紹 GEM（互信息生成估計器），一種用於評估大型語言模型（LLM）語言生成能力的評估指標，特別是在生成資訊性判斷時，無需黃金標準參考。GEM 擴展了我們可以對 LLM 生成效能進行基準測試的場景，從傳統場景（例如機器翻譯和摘要，其中黃金標準參考很容易取得）到沒有明確黃金標準的主觀任務（例如學術同行評審）。
  GEM 使用生成模型來估計候選回應和參考回應之間的互信息，而不要求參考是黃金標準。在人類標註資料集上的實驗中，與最先進的 GPT-4o Examiner 相比，GEM 展示出與人類評分具有競爭力的關聯性，並且優於所有其他基線。此外，GEM 對策略性操作（例如改寫或延伸）具有更強大的穩健性，這些操作會在 GPT-4o Examiner 下人為地提高分數。
  我們還提出了 GRE-bench（生成評論評估基準），它根據 LLM 生成高品質學術研究論文同行評審的能力來評估 LLM。由於 GRE-bench 基於 GEM，因此它繼承了其穩健性。此外，GRE-bench 透過每年使用大量新開放存取研究論文和同行評審來規避資料污染問題（或資料外洩）。我們展示了 GRE-bench 在 ICLR2023 資料集上使用各種流行 LLM 的同行評審能力的結果。</paragraph>

##### **Fast and Robust Contextual Node Representation Learning over Dynamic Graphs**
2411.07123v1 by Xingzhi Guo, Silong Wang, Baojian Zhou, Yanghua Xiao, Steven Skiena

Real-world graphs grow rapidly with edge and vertex insertions over time,
motivating the problem of efficiently maintaining robust node representation
over evolving graphs. Recent efficient GNNs are designed to decouple recursive
message passing from the learning process, and favor Personalized PageRank
(PPR) as the underlying feature propagation mechanism. However, most PPR-based
GNNs are designed for static graphs, and efficient PPR maintenance remains as
an open problem. Further, there is surprisingly little theoretical
justification for the choice of PPR, despite its impressive empirical
performance.
  In this paper, we are inspired by the recent PPR formulation as an explicit
$\ell_1$-regularized optimization problem and propose a unified dynamic graph
learning framework based on sparse node-wise attention. We also present a set
of desired properties to justify the choice of PPR in STOA GNNs, and serves as
the guideline for future node attention designs. Meanwhile, we take advantage
of the PPR-equivalent optimization formulation and employ the proximal gradient
method (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.
Finally, we instantiate a simple-yet-effective model (\textsc{GoPPE}) with
robust positional encodings by maximizing PPR previously used as attention. The
model performs comparably to or better than the STOA baselines and greatly
outperforms when the initial node attributes are noisy during graph evolution,
demonstrating the effectiveness and robustness of \textsc{GoPPE}.

摘要：<paragraph>隨著時間推移，真實世界的圖表會隨著邊緣和頂點的插入而快速增長，促使高效維護不斷演化的圖表中的穩健節點表示的問題。最近的高效 GNN 被設計為將遞迴訊息傳遞與學習過程解耦，並將個性化 PageRank (PPR) 作為基礎特徵傳播機制。然而，大多數基於 PPR 的 GNN 是為靜態圖表設計的，而高效的 PPR 維護仍然是一個未解決的問題。此外，儘管 PPR 具有令人印象深刻的經驗效能，但令人驚訝的是，對於選擇 PPR 幾乎沒有理論依據。
在本文中，我們受到最近將 PPR 表述為一個明確的 $\ell_1$ 正則化最佳化問題的啟發，並提出了一個基於稀疏節點注意力的統一動態圖表學習框架。我們還提出了一組所需的屬性來證明 STOA GNN 中選擇 PPR 的合理性，並作為未來節點注意力設計的指導方針。同時，我們利用 PPR 等效的最佳化公式，並採用近端梯度方法 (ISTA) 將基於 PPR 的 GNN 的效率提高了 6 倍。
最後，我們通過最大化先前用作注意力的 PPR 來實例化一個簡單而有效的模型 (\textsc{GoPPE})，其中包含穩健的位置編碼。該模型的效能與 STOA 基準相當或更好，並且在圖表演化過程中初始節點屬性有雜訊時表現得非常好，證明了 \textsc{GoPPE} 的有效性和穩健性。</paragraph>

##### **SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs**
2411.07122v1 by Ruben Härle, Felix Friedrich, Manuel Brack, Björn Deiseroth, Patrick Schramowski, Kristian Kersting

Large Language Models (LLMs) have demonstrated remarkable capabilities in
generating human-like text, but their output may not be aligned with the user
or even produce harmful content. This paper presents a novel approach to detect
and steer concepts such as toxicity before generation. We introduce the Sparse
Conditioned Autoencoder (SCAR), a single trained module that extends the
otherwise untouched LLM. SCAR ensures full steerability, towards and away from
concepts (e.g., toxic content), without compromising the quality of the model's
text generation on standard evaluation benchmarks. We demonstrate the effective
application of our approach through a variety of concepts, including toxicity,
safety, and writing style alignment. As such, this work establishes a robust
framework for controlling LLM generations, ensuring their ethical and safe
deployment in real-world applications.

摘要：大型語言模型 (LLM) 在生成類似人類的文字方面展現了非凡的能力，但其輸出可能與使用者不一致，甚至產生有害的內容。本文提出了一種新穎的方法來偵測和引導毒性等概念，在生成之前。我們引入了稀疏條件自動編碼器 (SCAR)，這是一個單一的訓練模組，可擴充原本未觸及的 LLM。SCAR 確保了完全的可引導性，朝向和遠離概念（例如，有毒內容），而不會損害模型在標準評估基準上的文字生成品質。我們透過各種概念，包括毒性、安全性以及寫作風格對齊，展示了我們方法的有效應用。因此，這項工作建立了一個穩健的框架來控制 LLM 生成，確保它們在實際應用中符合道德且安全地部署。

##### **Building a Taiwanese Mandarin Spoken Language Model: A First Attempt**
2411.07111v1 by Chih-Kai Yang, Yu-Kuan Fu, Chen-An Li, Yi-Cheng Lin, Yu-Xiang Lin, Wei-Chih Chen, Ho Lam Chung, Chun-Yi Kuan, Wei-Ping Huang, Ke-Han Lu, Tzu-Quan Lin, Hsiu-Hsuan Wang, En-Pei Hu, Chan-Jan Hsu, Liang-Hsuan Tseng, I-Hsiang Chiu, Ulin Sanga, Xuanjun Chen, Po-chun Hsu, Shu-wen Yang, Hung-yi Lee

This technical report presents our initial attempt to build a spoken large
language model (LLM) for Taiwanese Mandarin, specifically tailored to enable
real-time, speech-to-speech interaction in multi-turn conversations. Our
end-to-end model incorporates a decoder-only transformer architecture and aims
to achieve seamless interaction while preserving the conversational flow,
including full-duplex capabilities allowing simultaneous speaking and
listening. The paper also details the training process, including data
preparation with synthesized dialogues and adjustments for real-time
interaction. We also developed a platform to evaluate conversational fluency
and response coherence in multi-turn dialogues. We hope the release of the
report can contribute to the future development of spoken LLMs in Taiwanese
Mandarin.

摘要：這份技術報告呈現我們最初嘗試建構一個台灣國語的大型口語語言模型 (LLM)，特別量身打造以在多回合對話中實現即時的語音轉語音互動。我們的端到端模型結合了僅解碼器Transformer架構，並旨在在保留對話流暢度的同時實現無縫互動，包括允許同時說話和聆聽的全雙工功能。本文也詳細說明訓練流程，包括使用合成對話的資料準備以及針對即時互動的調整。我們也開發了一個平台來評估多回合對話中的對話流暢度和回應一致性。我們希望這份報告的發布有助於台灣國語口語 LLM 未來的發展。

##### **Training Neural Networks as Recognizers of Formal Languages**
2411.07107v1 by Alexandra Butoi, Ghazal Khalighinejad, Anej Svete, Josef Valvoda, Ryan Cotterell, Brian DuSell

Characterizing the computational power of neural network architectures in
terms of formal language theory remains a crucial line of research, as it
describes lower and upper bounds on the reasoning capabilities of modern AI.
However, when empirically testing these bounds, existing work often leaves a
discrepancy between experiments and the formal claims they are meant to
support. The problem is that formal language theory pertains specifically to
recognizers: machines that receive a string as input and classify whether it
belongs to a language. On the other hand, it is common to instead use proxy
tasks that are similar in only an informal sense, such as language modeling or
sequence-to-sequence transduction. We correct this mismatch by training and
evaluating neural networks directly as binary classifiers of strings, using a
general method that can be applied to a wide variety of languages. As part of
this, we extend an algorithm recently proposed by Sn{\ae}bjarnarson et al.
(2024) to do length-controlled sampling of strings from regular languages, with
much better asymptotic time complexity than previous methods. We provide
results on a variety of languages across the Chomsky hierarchy for three neural
architectures: a simple RNN, an LSTM, and a causally-masked transformer. We
find that the RNN and LSTM often outperform the transformer, and that auxiliary
training objectives such as language modeling can help, although no single
objective uniformly improves performance across languages and architectures.
Our contributions will facilitate theoretically sound empirical testing of
language recognition claims in future work. We have released our datasets as a
benchmark called FLaRe (Formal Language Recognition), along with our code.

摘要：<paragraph>以形式語言理論來描述神經網路架構的運算能力，仍然是研究的一條關鍵路線，因為它描述了現代人工智慧的推理能力的下限和上限。然而，在實證檢驗這些界限時，現有研究通常會在實驗和它們意圖支持的形式化主張之間留下出入。問題在於形式語言理論特別適用於辨識器：接收字串作為輸入並分類它是否屬於某種語言的機器。另一方面，通常會使用僅在非正式意義上相似的代理任務，例如語言模型或序列到序列的轉換。我們通過使用一種可應用於各種語言的一般方法，直接訓練和評估神經網路作為字串的二元分類器，來修正這種不匹配。作為其中的一部分，我們擴展了 Sn{\ae}bjarnarson 等人最近提出的演算法（2024 年），以對正則語言中的字串進行長度控制的抽樣，其漸近時間複雜度遠優於先前的演算法。我們針對三個神經架構提供各種喬姆斯基階層語言的結果：一個簡單的遞迴神經網路、一個長短期記憶網路和一個因果遮罩Transformer。我們發現遞迴神經網路和長短期記憶網路通常優於Transformer，並且語言模型等輔助訓練目標可能有幫助，儘管沒有單一的目標能普遍提升各種語言和架構的效能。我們的貢獻將有助於在未來的研究中對語言辨識主張進行理論上合理的實證檢驗。我們已將我們的資料集作為一個名為 FLaRe（形式語言辨識）的基準發布，並附上我們的程式碼。</paragraph>

##### **Bounded Rationality Equilibrium Learning in Mean Field Games**
2411.07099v1 by Yannick Eich, Christian Fabian, Kai Cui, Heinz Koeppl

Mean field games (MFGs) tractably model behavior in large agent populations.
The literature on learning MFG equilibria typically focuses on finding Nash
equilibria (NE), which assume perfectly rational agents and are hence
implausible in many realistic situations. To overcome these limitations, we
incorporate bounded rationality into MFGs by leveraging the well-known concept
of quantal response equilibria (QRE). Two novel types of MFG QRE enable the
modeling of large agent populations where individuals only noisily estimate the
true objective. We also introduce a second source of bounded rationality to
MFGs by restricting agents' planning horizon. The resulting novel receding
horizon (RH) MFGs are combined with QRE and existing approaches to model
different aspects of bounded rationality in MFGs. We formally define MFG QRE
and RH MFGs and compare them to existing equilibrium concepts such as
entropy-regularized NE. Subsequently, we design generalized fixed point
iteration and fictitious play algorithms to learn QRE and RH equilibria. After
a theoretical analysis, we give different examples to evaluate the capabilities
of our learning algorithms and outline practical differences between the
equilibrium concepts.

摘要：平均場博弈（MFG）可以追蹤大量代理人口的行為。
學習 MFG 均衡的文獻通常著重於尋找納許均衡（NE），它假設代理人完全理性，因此在許多現實情況下是不合理的。為了克服這些限制，我們透過利用著名的分位數反應均衡（QRE）概念，將受限理性納入 MFG 中。兩種新穎的 MFG QRE 類型可以對大型代理人口進行建模，其中個體僅對真實目標進行雜訊估計。我們還透過限制代理人的規劃時域，在 MFG 中引入第二個受限理性來源。由此產生的新穎後退時域（RH）MFG 與 QRE 和現有方法相結合，以對 MFG 中受限理性的不同面向進行建模。我們正式定義 MFG QRE 和 RH MFG，並將它們與現有的均衡概念（例如熵正則化 NE）進行比較。隨後，我們設計了廣義不動點迭代和虛構博弈演算法來學習 QRE 和 RH 均衡。在進行理論分析後，我們舉出不同的範例來評估我們學習演算法的能力，並概述均衡概念之間的實際差異。

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

摘要：<paragraph>隨著現代網路服務日益依賴 REST API，其徹底的測試變得至關重要。此外，REST API 規範（例如 OpenAPI 規範）的出現，導致許多黑盒 REST API 測試工具的出現。然而，這些工具通常專注於單獨的測試元素（例如 API、參數、值），導致覆蓋率較低，且在偵測錯誤（即 500 回應碼）方面效率較低。為了解決這些限制，我們提出 AutoRestTest，這是第一個採用依賴嵌入式多代理方法進行 REST API 測試的黑盒框架，將多代理強化學習 (MARL) 與語義屬性依賴圖 (SPDG) 和大型語言模型 (LLM) 整合在一起。我們的做法將 REST API 測試視為一個可分離的問題，其中四個代理（API、依賴關係、參數和值）協同合作以最佳化 API 探索。LLM 處理特定領域的值限制，SPDG 模型使用 API 操作之間的相似性分數簡化依賴關係的搜尋空間，而 MARL 則動態最佳化代理的行為。在 12 項真實世界的 REST 服務上進行評估，AutoRestTest 在程式碼覆蓋率、操作覆蓋率和錯誤偵測方面，優於四種領先的黑盒 REST API 測試工具，包括那些由 RESTGPT（使用 LLM 增加逼真的測試輸入）輔助的工具。值得注意的是，AutoRestTest 是唯一能夠識別 Spotify 中內部伺服器錯誤的工具。我們的消融研究強調了代理學習、SPDG 和 LLM 組件的重大貢獻。</paragraph>

##### **Towards Characterizing Cyber Networks with Large Language Models**
2411.07089v1 by Alaric Hartsock, Luiz Manella Pereira, Glenn Fink

Threat hunting analyzes large, noisy, high-dimensional data to find sparse
adversarial behavior. We believe adversarial activities, however they are
disguised, are extremely difficult to completely obscure in high dimensional
space. In this paper, we employ these latent features of cyber data to find
anomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM
was trained on Zeek network traffic logs from both a real-world production
network and an from Internet of Things (IoT) cybersecurity testbed. The model
is deliberately overtrained on a sliding window of data to characterize each
window closely. We use the Adjusted Rand Index (ARI) to comparing the k-means
clustering of CLEM output to expert labeling of the embeddings. Our approach
demonstrates that there is promise in using natural language modeling to
understand cyber data.

摘要：威脅追蹤分析大量、雜訊、高維度資料，以找出稀疏的對抗行為。我們相信對抗活動，無論其如何偽裝，在高維度空間中都極難完全隱藏。在本文中，我們使用網路資料的這些潛在特徵，透過一個名為網路日誌嵌入模型 (CLEM) 的原型工具來找出異常值。CLEM 根據來自真實世界生產網路和物聯網 (IoT) 網路安全測試平台的 Zeek 網路流量日誌進行訓練。該模型故意在資料的滑動視窗上進行過度訓練，以精確描述每個視窗。我們使用調整蘭德指數 (ARI) 將 CLEM 輸出的 k 平均群集與嵌入的專家標籤進行比較。我們的做法證明，使用自然語言建模來理解網路資料是有希望的。

##### **OCMDP: Observation-Constrained Markov Decision Process**
2411.07087v1 by Taiyi Wang, Jianheng Liu, Jiaye Li, Zhihao Wu, Yu Wu

In many practical applications, decision-making processes must balance the
costs of acquiring information with the benefits it provides. Traditional
control systems often assume full observability, an unrealistic assumption when
observations are expensive. We tackle the challenge of simultaneously learning
observation and control strategies in such cost-sensitive environments by
introducing the Observation-Constrained Markov Decision Process (OCMDP), where
the policy influences the observability of the true state. To manage the
complexity arising from the combined observation and control actions, we
develop an iterative, model-free deep reinforcement learning algorithm that
separates the sensing and control components of the policy. This decomposition
enables efficient learning in the expanded action space by focusing on when and
what to observe, as well as determining optimal control actions, without
requiring knowledge of the environment's dynamics. We validate our approach on
a simulated diagnostic task and a realistic healthcare environment using
HeartPole. Given both scenarios, the experimental results demonstrate that our
model achieves a substantial reduction in observation costs on average,
significantly outperforming baseline methods by a notable margin in efficiency.

摘要：在許多實際應用中，決策制定流程必須平衡取得資訊的成本與其提供的效益。傳統控制系統通常假設完全可觀察性，這在觀察成本高昂時是不切實際的假設。我們透過導入觀察受限馬可夫決策過程 (OCMDP) 來應對在這種成本敏感環境中同時學習觀察和控制策略的挑戰，其中政策會影響真實狀態的可觀察性。為了管理來自組合觀察和控制動作的複雜性，我們開發了一種反覆、無模型的深度強化學習演算法，它將策略的感測和控制元件分開。這種分解透過專注於何時以及觀察什麼，以及確定最佳控制動作，在擴展的動作空間中實現有效學習，而無需了解環境的動態。我們在模擬診斷任務和使用 HeartPole 的實際醫療保健環境中驗證我們的做法。在兩種情況下，實驗結果證明我們的模型平均可大幅降低觀察成本，在效率方面顯著優於基準方法。

##### **StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification**
2411.07076v1 by Yichen He, Yuan Lin, Jianchao Wu, Hanchong Zhang, Yuchen Zhang, Ruicheng Le

Existing large vision-language models (LVLMs) are largely limited to
processing short, seconds-long videos and struggle with generating coherent
descriptions for extended video spanning minutes or more. Long video
description introduces new challenges, such as plot-level consistency across
descriptions. To address these, we figure out audio-visual character
identification, matching character names to each dialogue, as a key factor. We
propose StoryTeller, a system for generating dense descriptions of long videos,
incorporating both low-level visual concepts and high-level plot information.
StoryTeller uses a multimodal large language model that integrates visual,
audio, and text modalities to perform audio-visual character identification on
minute-long video clips. The results are then fed into a LVLM to enhance
consistency of video description. We validate our approach on movie description
tasks and introduce MovieStory101, a dataset with dense descriptions for
three-minute movie clips. To evaluate long video descriptions, we create
MovieQA, a large set of multiple-choice questions for the MovieStory101 test
set. We assess descriptions by inputting them into GPT-4 to answer these
questions, using accuracy as an automatic evaluation metric. Experiments show
that StoryTeller outperforms all open and closed-source baselines on MovieQA,
achieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and
demonstrating a +15.56% advantage in human side-by-side evaluations.
Additionally, incorporating audio-visual character identification from
StoryTeller improves the performance of all video description models, with
Gemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,
respectively, in accuracy on MovieQA.

摘要：現有的大型視覺語言模型 (LVLMs) 主要僅限於處理數秒長的短影片，並難以產生長達數分鐘或更長時間的連貫影片說明。長影片說明引入了新的挑戰，例如說明中情節層級的一致性。為了解決這些問題，我們找出視覺聽覺角色識別，將角色名稱與每個對話配對，作為一個關鍵因素。我們提出 StoryTeller，一個用於產生長影片的密集說明的系統，結合了低階視覺概念和高階情節資訊。StoryTeller 使用一個整合視覺、聽覺和文字模式的多模態大型語言模型，對長達一分鐘的影片剪輯執行視覺聽覺角色識別。然後將結果輸入 LVLM 以增強影片說明的一致性。我們在電影說明任務上驗證了我們的做法，並引入了 MovieStory101，一個包含三分鐘電影剪輯的密集說明的資料集。為了評估長影片說明，我們建立了 MovieQA，一個針對 MovieStory101 測試集的大型多重選擇題組。我們透過將說明輸入 GPT-4 來回答這些問題來評估說明，使用準確度作為自動評估指標。實驗顯示，StoryTeller 在 MovieQA 上優於所有開放和封閉原始碼基準，比最強基準 Gemini-1.5-pro 高出 9.5% 的準確度，並在人類並排評估中展現出 +15.56% 的優勢。此外，結合 StoryTeller 的視覺聽覺角色識別可以提升所有影片說明模型的效能，其中 Gemini-1.5-pro 和 GPT-4o 在 MovieQA 上的準確度分別顯示出 5.5% 和 13.0% 的相對提升。

##### **Transformer verbatim in-context retrieval across time and scale**
2411.07075v1 by Kristijan Armeni, Marko Pranjić, Senja Pollak

To predict upcoming text, language models must in some cases retrieve
in-context information verbatim. In this report, we investigated how the
ability of language models to retrieve arbitrary in-context nouns developed
during training (across time) and as language models trained on the same
dataset increase in size (across scale). We then asked whether learning of
in-context retrieval correlates with learning of more challenging zero-shot
benchmarks. Furthermore, inspired by semantic effects in human short-term
memory, we evaluated the retrieval with respect to a major semantic component
of target nouns, namely whether they denote a concrete or abstract entity, as
rated by humans. We show that verbatim in-context retrieval developed in a
sudden transition early in the training process, after about 1% of the training
tokens. This was observed across model sizes (from 14M and up to 12B
parameters), and the transition occurred slightly later for the two smallest
models. We further found that the development of verbatim in-context retrieval
is positively correlated with the learning of zero-shot benchmarks. Around the
transition point, all models showed the advantage of retrieving concrete nouns
as opposed to abstract nouns. In all but two smallest models, the advantage
dissipated away toward the end of training.

摘要：語言模型若要預測後續文字，有時必須逐字擷取脈絡中的資訊。在此報告中，我們探討語言模型擷取任意脈絡中名詞的能力在訓練過程中（隨著時間推移）和在針對相同資料集訓練的語言模型大小增加（隨著規模擴大）的演變。接著我們探討脈絡中擷取的學習是否與學習更具挑戰性的零次學習基準相關。此外，受人類短期記憶中語義效應的啟發，我們針對目標名詞的主要語義成分評估擷取，也就是由人類評分的名詞是否表示具體或抽象實體。我們顯示逐字脈絡中擷取在訓練過程的早期突然轉變中發展，大約在訓練符號的 1% 之後。這在各種模型大小（從 14M 到 12B 參數）中觀察到，而且轉變發生在兩個最小模型的稍後時間。我們進一步發現，逐字脈絡中擷取的發展與零次學習基準的學習呈正相關。在轉變點附近，所有模型都顯示出擷取具體名詞而非抽象名詞的優勢。在所有模型中，除了兩個最小模型，優勢在訓練結束時逐漸消失。

##### **Universal Response and Emergence of Induction in LLMs**
2411.07071v1 by Niclas Luick

While induction is considered a key mechanism for in-context learning in
LLMs, understanding its precise circuit decomposition beyond toy models remains
elusive. Here, we study the emergence of induction behavior within LLMs by
probing their response to weak single-token perturbations of the residual
stream. We find that LLMs exhibit a robust, universal regime in which their
response remains scale-invariant under changes in perturbation strength,
thereby allowing us to quantify the build-up of token correlations throughout
the model. By applying our method, we observe signatures of induction behavior
within the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across
all models, we find that these induction signatures gradually emerge within
intermediate layers and identify the relevant model sections composing this
behavior. Our results provide insights into the collective interplay of
components within LLMs and serve as a benchmark for large-scale circuit
analysis.

摘要：雖然歸納被認為是 LLM 中情境學習的關鍵機制，但要理解其超越玩具模型的精確電路分解仍然難以捉摸。在此，我們通過探測 LLM 對殘差流的微弱單一符號擾動的反應，研究了歸納行為在 LLM 中的出現。我們發現，LLM 表現出一個穩健、通用的機制，其中它們的反應在擾動強度變化下保持尺度不變，從而使我們能夠量化整個模型中符號相關性的累積。通過應用我們的模型，我們觀察到 Gemma-2-2B、Llama-3.2-3B 和 GPT-2-XL 的殘差流中的歸納行為特徵。在所有模型中，我們發現這些歸納特徵逐漸出現在中間層，並識別出構成這種行為的相關模型部分。我們的結果提供了對 LLM 內部組成部分的集體交互作用的見解，並作為大規模電路分析的基準。

##### **On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models**
2411.07070v1 by Qian Sun, Hanpeng Wu, Xi Sheryl Zhang

The pretraining and fine-tuning approach has become the leading technique for
various NLP applications. However, recent studies reveal that fine-tuning data,
due to their sensitive nature, domain-specific characteristics, and
identifiability, pose significant privacy concerns. To help develop more
privacy-resilient fine-tuning models, we introduce a novel active privacy
auditing framework, dubbed Parsing, designed to identify and quantify privacy
leakage risks during the supervised fine-tuning (SFT) of language models (LMs).
The framework leverages improved white-box membership inference attacks (MIAs)
as the core technology, utilizing novel learning objectives and a two-stage
pipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the
exposure of privacy risks. Additionally, we have improved the effectiveness of
MIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our
research aims to provide the SFT community of LMs with a reliable, ready-to-use
privacy auditing tool, and to offer valuable insights into safeguarding privacy
during the fine-tuning process. Experimental results confirm the framework's
efficiency across various models and tasks, emphasizing notable privacy
concerns in the fine-tuning process. Project code available for
https://github.com/mapleleavesss/PARSING.

摘要：預訓練和微調方法已成為各種 NLP 應用程式的主流技術。然而，最近的研究顯示，微調資料由於其敏感的本質、特定領域的特徵和可識別性，會造成重大的隱私問題。為了協助開發更具隱私彈性的微調模型，我們引進一個創新的主動式隱私稽核架構，稱為 Parsing，其設計目的是在語言模型 (LM) 的監督式微調 (SFT) 過程中識別和量化隱私外洩風險。此架構利用改良的白盒成員身分推論攻擊 (MIA) 作為核心技術，採用新穎的學習目標和兩階段管線來監控 LM 微調程序的隱私，最大化隱私風險的暴露。此外，我們已經改善了 MIA 在大型 LM（包括 GPT-2、Llama2 和某些變體）上的效能。我們的研究旨在為 LM 的 SFT 社群提供一個可靠、可立即使用的隱私稽核工具，並提供有價值的見解，以在微調過程中保護隱私。實驗結果證實了此架構在各種模型和任務中的效率，強調了微調過程中顯著的隱私問題。專案程式碼可於 https://github.com/mapleleavesss/PARSING 取得。

##### **Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training**
2411.07066v1 by Elia Cunegatti, Leonardo Lucio Custode, Giovanni Iacca

Network pruning is a set of computational techniques that aim to reduce a
given model's computational cost by removing a subset of its parameters while
having minimal impact on performance. Throughout the last decade, the most
widely used pruning paradigm has focused on pruning and re-training, which
nowadays is inconvenient due to the vast amount of pre-trained models, which
are in any case too expensive to re-train. In this paper, we exploit functional
information from dense pre-trained models, i.e., their activations, to obtain
sparse models that maximize the activations' alignment w.r.t. their
corresponding dense models. Hence, we propose \textsc{NeuroAl}, a \emph{top-up}
algorithm that can be used on top of any given pruning algorithm for LLMs, that
modifies the block-wise and row-wise sparsity ratios to maximize the
\emph{neuron alignment} among activations. Moreover, differently from existing
methods, our approach adaptively selects the best parameters for the block-wise
and row-wise sparsity ratios w.r.t. to the model and the desired sparsity
(given as input), and requires \emph{no re-training}. We test our method on 4
different LLM families and 3 different sparsity ratios, showing how it
consistently outperforms the latest state-of-the-art techniques. The code is
available at https://github.com/eliacunegatti/NeuroAL.

摘要：網路剪枝是一組計算技術，旨在透過移除模型參數子集來降低給定模型的計算成本，同時對效能的影響降到最低。在過去十年中，使用最廣泛的剪枝範例著重於剪枝和重新訓練，這在現今由於大量的預訓練模型而變得不方便，而這些模型在任何情況下都太昂貴而無法重新訓練。在本文中，我們利用稠密預訓練模型中的功能資訊，即它們的活化，以取得稀疏模型，最大化活化與其對應稠密模型的對齊。因此，我們提出 \textsc{NeuroAl}，一種可以針對任何給定的 LLM 剪枝演算法使用的 \emph{補充} 演算法，它修改區塊和列的稀疏率以最大化活化之間的 \emph{神經元對齊}。此外，與現有方法不同，我們的做法自適應地針對區塊和列的稀疏率選擇最佳參數，且與模型和所需的稀疏率（作為輸入提供）有關，並且需要 \emph{無重新訓練}。我們在 4 個不同的 LLM 系列和 3 個不同的稀疏率上測試我們的做法，顯示它如何持續優於最新的最先進技術。程式碼可在 https://github.com/eliacunegatti/NeuroAL 取得。

##### **Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications**
2411.07042v1 by Xianzhe Fan, Qing Xiao, Xuhui Zhou, Yuran Su, Zhicong Lu, Maarten Sap, Hong Shen

AI companions based on large language models can role-play and converse very
naturally. When value conflicts arise between the AI companion and the user, it
may offend or upset the user. Yet, little research has examined such conflicts.
We first conducted a formative study that analyzed 151 user complaints about
conflicts with AI companions, providing design implications for our study.
Based on these, we created Minion, a technology probe to help users resolve
human-AI value conflicts. Minion applies a user-empowerment intervention method
that provides suggestions by combining expert-driven and user-driven conflict
resolution strategies. We conducted a technology probe study, creating 40 value
conflict scenarios on Character.AI and Talkie. 22 participants completed 274
tasks and successfully resolved conflicts 94.16% of the time. We summarize user
responses, preferences, and needs in resolving value conflicts, and propose
design implications to reduce conflicts and empower users to resolve them more
effectively.

摘要：基於大型語言模型的人工智慧伴侶可以扮演角色並非常自然地交談。當人工智慧伴侶與使用者之間出現價值觀衝突時，可能會冒犯或激怒使用者。然而，很少有研究探討此類衝突。我們首先進行了一項形成性研究，分析了 151 起關於與人工智慧伴侶發生衝突的使用者抱怨，並為我們的研究提供了設計啟示。基於這些，我們創造了 Minion，這是一種技術探測，可幫助使用者解決人與人工智慧的價值觀衝突。Minion 採用使用者授權介入方法，結合專家驅動和使用者驅動的衝突解決策略來提供建議。我們進行了一項技術探測研究，在 Character.AI 和 Talkie 上創造了 40 個價值觀衝突情境。22 位參與者完成了 274 項任務，並在 94.16% 的時間內成功解決衝突。我們總結了使用者在解決價值觀衝突時的反應、偏好和需求，並提出設計啟示，以減少衝突並賦予使用者更有效地解決衝突的能力。

##### **Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind**
2411.07038v1 by Alejandro Leonardo García Navarro, Nataliia Koneva, Alfonso Sánchez-Macián, José Alberto Hernández, Manuel Goyanes

In social sciences, researchers often face challenges when conducting
large-scale experiments, particularly due to the simulations' complexity and
the lack of technical expertise required to develop such frameworks.
Agent-Based Modeling (ABM) is a computational approach that simulates agents'
actions and interactions to evaluate how their behaviors influence the
outcomes. However, the traditional implementation of ABM can be demanding and
complex. Generative Agent-Based Modeling (GABM) offers a solution by enabling
scholars to create simulations where AI-driven agents can generate complex
behaviors based on underlying rules and interactions. This paper introduces a
framework for designing reliable experiments using GABM, making sophisticated
simulation techniques more accessible to researchers across various fields. We
provide a step-by-step guide for selecting appropriate tools, designing the
model, establishing experimentation protocols, and validating results.

摘要：<paragraph>在社會科學中，研究人員在進行
大規模實驗時常常會面臨挑戰，特別是模擬的複雜性以及開發此類框架所需技術專業知識的缺乏。
基於代理的建模 (ABM) 是一種計算方法，用於模擬代理的
動作和互動，以評估他們的行為如何影響
結果。然而，ABM 的傳統實施可能是要求嚴格且
複雜的。生成式基於代理的建模 (GABM) 提供了解決方案，方法是讓
學者能夠建立模擬，其中由 AI 驅動的代理可以根據
底層規則和互動產生複雜的行為。本文介紹了一個
使用 GABM 設計可靠實驗的框架，讓各個領域的研究人員更能使用複雜
的模擬技術。我們提供了一個逐步指南，用於選擇適當的工具、設計
模型、建立實驗規程和驗證結果。</paragraph>

##### **LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios**
2411.07037v1 by Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Xiangju Lu, Junmin Zhu, Wei Zhang

As Large Language Models (LLMs) continue to advance in natural language
processing (NLP), their ability to stably follow instructions in long-context
inputs has become crucial for real-world applications. While existing
benchmarks assess various LLM capabilities, they rarely focus on
instruction-following in long-context scenarios or stability on different
inputs. In response, we introduce the Long-context Instruction-Following
Benchmark (LIFBench), a scalable dataset designed to evaluate LLMs'
instruction-following capabilities and stability across long contexts. LIFBench
comprises three long-context scenarios and eleven diverse tasks, supported by
2,766 instructions generated through an automated expansion method across three
dimensions: length, expression, and variables. For evaluation, we propose
LIFEval, a rubric-based assessment framework that provides precise, automated
scoring of complex LLM responses without relying on LLM-assisted evaluations or
human judgments. This approach facilitates a comprehensive analysis of model
performance and stability across various perspectives. We conduct extensive
experiments on 20 notable LLMs across six length intervals, analyzing their
instruction-following capabilities and stability. Our work contributes LIFBench
and LIFEval as robust tools for assessing LLM performance in complex,
long-context settings, providing insights that can inform future LLM
development.

摘要：隨著大型語言模型 (LLM) 在自然語言處理 (NLP) 中持續進步，它們在長語境輸入中穩定遵循指令的能力對於實際應用已變得至關重要。現有的基準評估各種 LLM 能力，但它們很少關注長語境場景中的指令遵循或不同輸入的穩定性。為了解決這個問題，我們引入了長語境指令遵循基準 (LIFBench)，這是一個可擴充的資料集，旨在評估 LLM 在長語境中的指令遵循能力和穩定性。LIFBench 包含三種長語境場景和十一項不同的任務，並透過自動擴充方法在三個維度（長度、表達式和變數）中產生 2,766 條指令。為了評估，我們提出了 LIFEval，這是一個基於規則的評量架構，可以在不依賴 LLM 輔助評估或人類判斷的情況下，對複雜的 LLM 回應進行精確的自動評分。這種方法有助於全面分析模型在各種觀點下的效能和穩定性。我們對六個長度區間中的 20 個著名的 LLM 進行了廣泛的實驗，分析了它們的指令遵循能力和穩定性。我們的研究貢獻了 LIFBench 和 LIFEval，作為評估 LLM 在複雜、長語境設定中效能的強大工具，並提供了可以為未來的 LLM 開發提供參考的見解。

##### **UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction**
2411.07019v1 by Zhiqiang Liu, Mingyang Chen, Yin Hua, Zhuo Chen, Ziqi Liu, Lei Liang, Huajun Chen, Wen Zhang

Beyond-triple fact representations including hyper-relational facts with
auxiliary key-value pairs, temporal facts with additional timestamps, and
nested facts implying relationships between facts, are gaining significant
attention. However, existing link prediction models are usually designed for
one specific type of facts, making it difficult to generalize to other fact
representations. To overcome this limitation, we propose a Unified Hierarchical
Representation learning framework (UniHR) for unified knowledge graph link
prediction. It consists of a unified Hierarchical Data Representation (HiDR)
module and a unified Hierarchical Structure Learning (HiSL) module as graph
encoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested
factual KGs into triple-based representations. Then HiSL incorporates
intra-fact and inter-fact message passing, focusing on enhancing the semantic
information within individual facts and enriching the structural information
between facts. Experimental results across 7 datasets from 3 types of KGs
demonstrate that our UniHR outperforms baselines designed for one specific kind
of KG, indicating strong generalization capability of HiDR form and the
effectiveness of HiSL module. Code and data are available at
https://github.com/Lza12a/UniHR.

摘要：超越三元組事實表示，包括具有輔助鍵值對的超關係事實、具有附加時間戳的時間事實，以及暗示事實之間關係的嵌套事實，正受到極大的關注。然而，現有的連結預測模型通常是為特定類型的事實而設計的，這使得概括到其他事實表示變得困難。為了克服這個限制，我們提出了一個統一的分層表示學習框架 (UniHR)，用於統一的知識圖譜連結預測。它包含一個統一的分層數據表示 (HiDR) 模組和一個統一的分層結構學習 (HiSL) 模組作為圖形編碼器。HiDR 模組將超關係 KG、時間 KG 和嵌套事實 KG 統一到基於三元組的表示中。然後，HiSL 結合了事實內和事實間的訊息傳遞，重點加強個別事實中的語義資訊並豐富事實之間的結構資訊。來自 3 種類型 KG 的 7 個資料集的實驗結果證明，我們的 UniHR 優於為特定類型 KG 設計的基準，表明 HiDR 形式的強泛化能力和 HiSL 模組的有效性。程式碼和資料可在 https://github.com/Lza12a/UniHR 取得。

##### **Leveraging LSTM for Predictive Modeling of Satellite Clock Bias**
2411.07015v1 by Ahan Bhatt, Ishaan Mehta, Pravin Patidar

Satellite clock bias prediction plays a crucial role in enhancing the
accuracy of satellite navigation systems. In this paper, we propose an approach
utilizing Long Short-Term Memory (LSTM) networks to predict satellite clock
bias. We gather data from the PRN 8 satellite of the Galileo and preprocess it
to obtain a single difference sequence, crucial for normalizing the data.
Normalization allows resampling of the data, ensuring that the predictions are
equidistant and complete. Our methodology involves training the LSTM model on
varying lengths of datasets, ranging from 7 days to 31 days. We employ a
training set consisting of two days' worth of data in each case. Our LSTM model
exhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11
$\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used
for similar time-series forecasting projects, being 170 times more accurate
than RNN, 2.3 $\times$ 10$^7$ times more accurate than MLP, and 1.9 $\times$
10$^4$ times more accurate than ARIMA. This study holds significant potential
in enhancing the accuracy and efficiency of low-power receivers used in various
devices, particularly those requiring power conservation. By providing more
accurate predictions of satellite clock bias, the findings of this research can
be integrated into the algorithms of such devices, enabling them to function
with heightened precision while conserving power. Improved accuracy in clock
bias predictions ensures that low-power receivers can maintain optimal
performance levels, thereby enhancing the overall reliability and effectiveness
of satellite navigation systems. Consequently, this advancement holds promise
for a wide range of applications, including remote areas, IoT devices, wearable
technology, and other devices where power efficiency and navigation accuracy
are paramount.

摘要：<paragraph>衛星時鐘偏差預測在提升衛星導航系統準確度方面扮演著關鍵角色。在本文中，我們提出一個利用長短期記憶網路 (LSTM) 來預測衛星時鐘偏差的方法。我們從伽利略的 PRN 8 衛星收集資料，並對其進行預處理以取得單一差分序列，這對於標準化資料至關重要。標準化允許對資料進行重新取樣，確保預測是等距且完整的。我們的技術包括在不同長度的資料集上訓練 LSTM 模型，範圍從 7 天到 31 天。我們在每種情況下都使用包含兩天資料的訓練組。我們的 LSTM 模型展現出極佳的準確度，均方根誤差 (RMSE) 為 2.11 $\times$ 10$^{-11}$。值得注意的是，我們的做法優於用於類似時間序列預測專案的傳統方法，比 RNN 準確 170 倍，比 MLP 準確 2.3 $\times$ 10$^7$ 倍，比 ARIMA 準確 1.9 $\times$ 10$^4$ 倍。這項研究在提升各種裝置中使用的低功率接收器的準確度和效率方面具有顯著的潛力，特別是那些需要節能的裝置。透過提供更準確的衛星時鐘偏差預測，這項研究的發現可以整合到這些裝置的演算法中，讓它們在節能的同時還能以更高的精準度運作。時鐘偏差預測準確度的提升確保低功率接收器能維持最佳效能，進而提升衛星導航系統的整體可靠度和效能。因此，這項進展有望在廣泛的應用中發揮作用，包括偏遠地區、IoT 裝置、穿戴式技術以及其他以電力效率和導航準確度為首要考量的裝置。</paragraph>

##### **A neural-network based anomaly detection system and a safety protocol to protect vehicular network**
2411.07013v1 by Marco Franceschini

This thesis addresses the use of Cooperative Intelligent Transport Systems
(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle
communication, highlighting the importance of secure and accurate data
exchange. To ensure safety, the thesis proposes a Machine Learning-based
Misbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks
to detect and mitigate incorrect or misleading messages within vehicular
networks. Trained offline on the VeReMi dataset, the detection model is tested
in real-time within a platooning scenario, demonstrating that it can prevent
nearly all accidents caused by misbehavior by triggering a defense protocol
that dissolves the platoon if anomalies are detected. The results show that
while the system can accurately detect general misbehavior, it struggles to
label specific types due to varying traffic conditions, implying the difficulty
of creating a universally adaptive protocol. However, the thesis suggests that
with more data and further refinement, this MDS could be implemented in
real-world CITS, enhancing driving safety by mitigating risks from misbehavior
in cooperative driving networks.

摘要：本論文探討使用協同智慧運輸系統 (CITS) 來改善道路安全和效率，方法是啟用車對車通訊，並強調安全且準確的資料交換的重要性。為了確保安全，本論文提出一個基於機器學習的不當行為偵測系統 (MDS)，使用長短期記憶 (LSTM) 網路來偵測和減輕車輛網路中的不正確或誤導訊息。偵測模型在 VeReMi 資料集上離線訓練，並在排隊場景中進行即時測試，證明它可以透過觸發防禦協定來防止幾乎所有由不當行為造成的意外，而當偵測到異常時，會解散排隊。結果顯示，雖然系統可以準確偵測一般的不當行為，但由於交通狀況不同，系統難以標記特定類型的不當行為，這表示建立一個普遍適應的協定有其難度。然而，本論文建議，透過更多資料和進一步的修正，這個 MDS 可以實作在真實世界的 CITS 中，透過減輕協同駕駛網路中不當行為的風險來提升行車安全。

##### **Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching**
2411.07007v1 by Arnav Kumar Jain, Harley Wiltzer, Jesse Farebrother, Irina Rish, Glen Berseth, Sanjiban Choudhury

In inverse reinforcement learning (IRL), an agent seeks to replicate expert
demonstrations through interactions with the environment. Traditionally, IRL is
treated as an adversarial game, where an adversary searches over reward models,
and a learner optimizes the reward through repeated RL procedures. This
game-solving approach is both computationally expensive and difficult to
stabilize. In this work, we propose a novel approach to IRL by direct policy
optimization: exploiting a linear factorization of the return as the inner
product of successor features and a reward vector, we design an IRL algorithm
by policy gradient descent on the gap between the learner and expert features.
Our non-adversarial method does not require learning a reward function and can
be solved seamlessly with existing actor-critic RL algorithms. Remarkably, our
approach works in state-only settings without expert action labels, a setting
which behavior cloning (BC) cannot solve. Empirical results demonstrate that
our method learns from as few as a single expert demonstration and achieves
improved performance on various control tasks.

摘要：在逆向強化學習 (IRL) 中，代理會透過與環境互動來複製專家示範。傳統上，IRL 被視為對抗性遊戲，對手會搜尋獎勵模型，而學習者會透過重複的 RL 程序最佳化獎勵。這種遊戲解法既耗費運算資源，又難以穩定。在這項工作中，我們提出了一種透過直接政策最佳化來進行 IRL 的新方法：利用回報的線性分解作為後繼特徵和獎勵向量的內積，我們透過學習者和專家特徵之間的差距來設計一種 IRL 演算法，並透過策略梯度下降法進行。我們的非對抗方法不需要學習獎勵函數，並且可以與現有的動作-評論 RL 演算法無縫解決。值得注意的是，我們的做法可以在沒有專家動作標籤的僅狀態設定中運作，這是行為複製 (BC) 無法解決的設定。實證結果顯示，我們的做法可以從少至一個專家示範中學習，並在各種控制任務中獲得更好的效能。

##### **Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs**
2411.07006v1 by Malte Luttermann, Tanya Braun, Ralf Möller, Marcel Gehrke

Lifting uses a representative of indistinguishable individuals to exploit
symmetries in probabilistic relational models, denoted as parametric factor
graphs, to speed up inference while maintaining exact answers. In this paper,
we show how lifting can be applied to causal inference in partially directed
graphs, i.e., graphs that contain both directed and undirected edges to
represent causal relationships between random variables. We present partially
directed parametric causal factor graphs (PPCFGs) as a generalisation of
previously introduced parametric causal factor graphs, which require a fully
directed graph. We further show how causal inference can be performed on a
lifted level in PPCFGs, thereby extending the applicability of lifted causal
inference to a broader range of models requiring less prior knowledge about
causal relationships.

摘要：提升使用不可區分個體的代表來利用機率關係模型中的對稱性，表示為參數因子圖，以在維持精確答案的同時加速推論。在本文中，我們展示如何將提升應用於部分有向圖中的因果推論，亦即包含有向和無向邊緣來表示隨機變數之間因果關係的圖形。我們提出部分有向參數因果因子圖 (PPCFG) 作為先前引入的參數因果因子圖的概括，這需要一個完全有向圖。我們進一步展示如何在 PPCFG 中執行提升層級的因果推論，從而將提升因果推論的適用性擴展到更廣泛的模型，而這些模型需要較少的關於因果關係的先驗知識。

##### **Token2Wave**
2411.06989v1 by Xin Zhang, Victor S. Sheng

This paper provides an in-depth analysis of Token2Wave, a novel token
representation method derived from the Wave Network, designed to capture both
global and local semantics of input text through wave-inspired complex vectors.
In Token2Wave, each token is represented with a magnitude component, capturing
the global semantics of the entire input text, and a phase component, encoding
the relationships between individual tokens and the global semantics. Building
on prior research that demonstrated the effectiveness of wave-like operations,
such as interference and modulation, during forward propagation, this study
investigates the convergence behavior, backpropagation characteristics, and
embedding independence within the Token2Wave framework. A detailed
computational complexity analysis shows that Token2Wave can significantly
reduce video memory usage and training time compared to BERT. Gradient
comparisons for the [CLS] token, total input text, and classifier parameters
further highlight Token2Wave's unique characteristics. This research offers new
insights into wave-based token representations, demonstrating their potential
to enable efficient and computationally friendly language model architectures.

摘要：本文深入分析 Token2Wave，這是一種源自 Wave Network 的創新型 Token 表示方法，旨在通過受波激勵的複雜向量捕捉輸入文本的全局語義和局部語義。在 Token2Wave 中，每個 Token 都用一個幅度分量表示，用於捕捉整個輸入文本的全局語義，以及一個相位分量，用於編碼個別 Token 與全局語義之間的關係。在先前研究的基礎上，該研究證明了波狀運算（例如干涉和調製）在正向傳播期間的有效性，探討了 Token2Wave 框架內的收斂行為、反向傳播特性和嵌入獨立性。詳細的計算複雜度分析表明，與 BERT 相比，Token2Wave 可以顯著減少視頻內存使用量和訓練時間。[CLS] Token、總輸入文本和分類器參數的梯度比較進一步突出了 Token2Wave 的獨特特徵。本研究提供了對基於波的 Token 表示的新見解，證明了它們在實現高效且計算友好的語言模型架構方面的潛力。

##### **ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis**
2411.06959v1 by Zanlin Ni, Yulin Wang, Renping Zhou, Yizeng Han, Jiayi Guo, Zhiyuan Liu, Yuan Yao, Gao Huang

Recently, token-based generation have demonstrated their effectiveness in
image synthesis. As a representative example, non-autoregressive Transformers
(NATs) can generate decent-quality images in a few steps. NATs perform
generation in a progressive manner, where the latent tokens of a resulting
image are incrementally revealed. At each step, the unrevealed image regions
are padded with mask tokens and inferred by NAT. In this paper, we delve into
the mechanisms behind the effectiveness of NATs and uncover two important
patterns that naturally emerge from NATs: Spatially (within a step), although
mask and visible tokens are processed uniformly by NATs, the interactions
between them are highly asymmetric. In specific, mask tokens mainly gather
information for decoding, while visible tokens tend to primarily provide
information, and their deep representations can be built only upon themselves.
Temporally (across steps), the interactions between adjacent generation steps
mostly concentrate on updating the representations of a few critical tokens,
while the computation for the majority of tokens is generally repetitive.
Driven by these findings, we propose EfficientNAT (ENAT), a NAT model that
explicitly encourages these critical interactions inherent in NATs. At the
spatial level, we disentangle the computations of visible and mask tokens by
encoding visible tokens independently, while decoding mask tokens conditioned
on the fully encoded visible tokens. At the temporal level, we prioritize the
computation of the critical tokens at each step, while maximally reusing
previously computed token representations to supplement necessary information.
ENAT improves the performance of NATs notably with significantly reduced
computational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO
validate the effectiveness of ENAT. Code is available at
https://github.com/LeapLabTHU/ENAT.

摘要：<paragraph>最近，基于标记的生成已证明其在图像合成中的有效性。作为代表性示例，非自回归式 Transformer（NAT）可以在几个步骤中生成质量不错的图像。NAT 以渐进的方式执行生成，其中结果图像的潜在标记逐渐被揭示。在每一步中，未揭示的图像区域都用掩码标记填充并由 NAT 推断。在本文中，我们深入研究了 NAT 有效性背后的机制，并揭示了 NAT 自然出现的两个重要模式：空间上（在步骤内），尽管 NAT 对掩码和可见标记进行统一处理，但它们之间的交互高度不对称。具体来说，掩码标记主要收集用于解码的信息，而可见标记倾向于主要提供信息，并且它们的深度表示只能建立在它们自己之上。时间上（跨步骤），相邻生成步骤之间的交互主要集中在更新几个关键标记的表示上，而大多数标记的计算通常是重复的。受这些发现的启发，我们提出了 EfficientNAT（ENAT），这是一个 NAT 模型，它明确地鼓励了 NAT 中固有的这些关键交互。在空间层面上，我们通过独立编码可见标记来解开可见标记和掩码标记的计算，同时对完全编码的可见标记进行条件解码掩码标记。在时间层面上，我们优先考虑在每一步计算关键标记，同时最大程度地重用先前计算的标记表示以补充必要信息。ENAT 显着提高了 NAT 的性能，同时显着降低了计算成本。在 ImageNet-256、ImageNet-512 和 MS-COCO 上的实验验证了 ENAT 的有效性。代码可在 https://github.com/LeapLabTHU/ENAT 获得。</paragraph>

##### **Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences**
2411.06950v1 by Shu Zhong, Zetao Zhou, Christopher Dawes, Giada Brianz, Marianna Obrist

Aligning AI with human intent is important, yet perceptual alignment-how AI
interprets what we see, hear, or smell-remains underexplored. This work focuses
on olfaction, human smell experiences. We conducted a user study with 40
participants to investigate how well AI can interpret human descriptions of
scents. Participants performed "sniff and describe" interactive tasks, with our
designed AI system attempting to guess what scent the participants were
experiencing based on their descriptions. These tasks evaluated the Large
Language Model's (LLMs) contextual understanding and representation of scent
relationships within its internal states - high-dimensional embedding space.
Both quantitative and qualitative methods were used to evaluate the AI system's
performance. Results indicated limited perceptual alignment, with biases
towards certain scents, like lemon and peppermint, and continued failing to
identify others, like rosemary. We discuss these findings in light of human-AI
alignment advancements, highlighting the limitations and opportunities for
enhancing HCI systems with multisensory experience integration.

摘要：對齊 AI 與人類意圖很重要，但感知對齊——AI 如何詮釋我們所見、所聽或所聞——仍未得到充分探討。這項工作著重於嗅覺，也就是人類的嗅覺體驗。我們針對 40 位參與者進行使用者研究，以探討 AI 能多好地詮釋人類對氣味的描述。參與者執行了「聞香並描述」互動任務，我們的 AI 系統設計嘗試根據參與者的描述猜測他們聞到什麼氣味。這些任務評估了大型語言模型 (LLM) 在其內部狀態——高維嵌入空間——中對氣味關係的脈絡理解和表示。使用量化和質化方法來評估 AI 系統的效能。結果顯示感知對齊有限，對某些氣味（例如檸檬和薄荷）有偏見，並且持續無法辨識其他氣味（例如迷迭香）。我們根據人類與 AI 對齊的進展討論這些發現，強調了透過多感官體驗整合來提升 HCI 系統的限制和機會。

##### **Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models**
2411.06946v1 by Aniket Deroy, Subhankar Maity

Gastrointestinal (GI) tract cancers account for a substantial portion of the
global cancer burden, where early diagnosis is critical for improved management
and patient outcomes. The complex aetiologies and overlapping symptoms across
GI cancers often delay diagnosis, leading to suboptimal treatment strategies.
Cancer-related queries are crucial for timely diagnosis, treatment, and patient
education, as access to accurate, comprehensive information can significantly
influence outcomes. However, the complexity of cancer as a disease, combined
with the vast amount of available data, makes it difficult for clinicians and
patients to quickly find precise answers. To address these challenges, we
leverage large language models (LLMs) such as GPT-3.5 Turbo to generate
accurate, contextually relevant responses to cancer-related queries.
Pre-trained with medical data, these models provide timely, actionable insights
that support informed decision-making in cancer diagnosis and care, ultimately
improving patient outcomes. We calculate two metrics: A1 (which represents the
fraction of entities present in the model-generated answer compared to the gold
standard) and A2 (which represents the linguistic correctness and
meaningfulness of the model-generated answer with respect to the gold
standard), achieving maximum values of 0.546 and 0.881, respectively.

摘要：胃腸道 (GI) 癌症佔全球癌症負擔的很大一部分，早期診斷對於改善管理和患者預後至關重要。胃腸道癌症的複雜病因和重疊症狀經常會延誤診斷，導致次優的治療策略。與癌症相關的查詢對於及時診斷、治療和患者教育至關重要，因為獲取準確、全面的信息可以顯著影響結果。然而，癌症作為一種疾病的複雜性，加上大量可用數據，使得臨床醫生和患者難以快速找到準確的答案。為了應對這些挑戰，我們利用大型語言模型 (LLM)，例如 GPT-3.5 Turbo，來生成與癌症相關查詢的準確、上下文相關的回應。這些模型經過醫學數據預訓練，可提供及時、可操作的見解，支持癌症診斷和護理中的明智決策制定，最終改善患者預後。我們計算了兩個指標：A1（表示模型生成的答案中存在的實體部分，與黃金標準相比）和 A2（表示模型生成的答案的語言正確性和意義，相對於黃金標準），分別達到最大值 0.546 和 0.881。

##### **Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum**
2411.06928v1 by Yuanming Zhang, Jing Lu, Zhibin Lin, Fei Chen, Haoliang Du, Xia Gao

Decoding the directional focus of an attended speaker from listeners'
electroencephalogram (EEG) signals is essential for developing brain-computer
interfaces to improve the quality of life for individuals with hearing
impairment. Previous works have concentrated on binary directional focus
decoding, i.e., determining whether the attended speaker is on the left or
right side of the listener. However, a more precise decoding of the exact
direction of the attended speaker is necessary for effective speech processing.
Additionally, audio spatial information has not been effectively leveraged,
resulting in suboptimal decoding results. In this paper, we observe that, on
our recently presented dataset with 15-class directional focus, models relying
exclusively on EEG inputs exhibits significantly lower accuracy when decoding
the directional focus in both leave-one-subject-out and leave-one-trial-out
scenarios. By integrating audio spatial spectra with EEG features, the decoding
accuracy can be effectively improved. We employ the CNN, LSM-CNN, and
EEG-Deformer models to decode the directional focus from listeners' EEG signals
with the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model
achieves notable 15-class decoding accuracies of 57.48% and 61.83% in
leave-one-subject-out and leave-one-trial-out scenarios, respectively.

摘要：解碼聽眾腦電圖 (EEG) 訊號中受關注說話者的方向焦點對於開發腦電腦介面至關重要，以提高聽力受損者的生活品質。先前的研究集中於二進位方向焦點解碼，即判斷受關注的說話者在聽眾的左側還是右側。然而，精確解碼受關注說話者的確切方向對於有效的語音處理是必要的。此外，音訊空間資訊尚未被有效利用，導致次佳解碼結果。在本文中，我們觀察到，在我們最近提出的 15 類方向焦點資料集中，僅依賴 EEG 輸入的模型在離開一個受試者和離開一個試驗的場景中解碼方向焦點時，準確度顯著降低。透過將音訊空間頻譜與 EEG 特徵整合，可以有效提高解碼準確度。我們採用 CNN、LSM-CNN 和 EEG-Deformer 模型從聽眾的 EEG 訊號中解碼方向焦點，並輔以音訊空間頻譜。提出的 Sp-Aux-Deformer 模型分別在離開一個受試者和離開一個試驗的場景中達到顯著的 15 類解碼準確度 57.48% 和 61.83%。

##### **Slowing Down Forgetting in Continual Learning**
2411.06916v1 by Pascal Janetzky, Tobias Schlagenhauf, Stefan Feuerriegel

A common challenge in continual learning (CL) is catastrophic forgetting,
where the performance on old tasks drops after new, additional tasks are
learned. In this paper, we propose a novel framework called ReCL to slow down
forgetting in CL. Our framework exploits an implicit bias of gradient-based
neural networks due to which these converge to margin maximization points. Such
convergence points allow us to reconstruct old data from previous tasks, which
we then combine with the current training data. Our framework is flexible and
can be applied on top of existing, state-of-the-art CL methods to slow down
forgetting. We further demonstrate the performance gain from our framework
across a large series of experiments, including different CL scenarios (class
incremental, domain incremental, task incremental learning) different datasets
(MNIST, CIFAR10), and different network architectures. Across all experiments,
we find large performance gains through ReCL. To the best of our knowledge, our
framework is the first to address catastrophic forgetting by leveraging models
in CL as their own memory buffers.

摘要：持續學習 (CL) 中常見的挑戰是災難性遺忘，也就是在學習新的額外任務後，舊任務的表現下降。在本文中，我們提出了一個名為 ReCL 的新框架，用來減緩 CL 中的遺忘。我們的框架利用了基於梯度的類神經網路的內隱偏差，因為這些網路會收斂到邊界最大化點。這樣的收斂點讓我們可以從先前的任務中重建舊資料，然後我們將其與目前的訓練資料結合。我們的框架很靈活，可以應用於現有的、最先進的 CL 方法之上，以減緩遺忘。我們進一步展示了我們的框架在大量實驗中獲得的效能提升，包括不同的 CL 場景（類別增量、領域增量、任務增量學習）不同的資料集（MNIST、CIFAR10）和不同的網路架構。在所有實驗中，我們都發現 ReCL 帶來了顯著的效能提升。據我們所知，我們的框架是第一個透過利用 CL 中的模型作為其自己的記憶體緩衝區來解決災難性遺忘的框架。

##### **Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI**
2411.06911v1 by Bruno Viti, Franz Thaler, Kathrin Lisa Kapper, Martin Urschler, Martin Holler, Elias Karabelas

Segmentation of cardiac magnetic resonance images (MRI) is crucial for the
analysis and assessment of cardiac function, helping to diagnose and treat
various cardiovascular diseases. Most recent techniques rely on deep learning
and usually require an extensive amount of labeled data. To overcome this
problem, few-shot learning has the capability of reducing data dependency on
labeled data. In this work, we introduce a new method that merges few-shot
learning with a U-Net architecture and Gaussian Process Emulators (GPEs),
enhancing data integration from a support set for improved performance. GPEs
are trained to learn the relation between the support images and the
corresponding masks in latent space, facilitating the segmentation of unseen
query images given only a small labeled support set at inference. We test our
model with the M&Ms-2 public dataset to assess its ability to segment the heart
in cardiac magnetic resonance imaging from different orientations, and compare
it with state-of-the-art unsupervised and few-shot methods. Our architecture
shows higher DICE coefficients compared to these methods, especially in the
more challenging setups where the size of the support set is considerably
small.

摘要：心臟磁振造影 (MRI) 影像的分割對於心臟功能的分析和評估至關重要，有助於診斷和治療各種心血管疾病。最新技術大多依賴深度學習，且通常需要大量的標籤資料。為了克服這個問題，小樣本學習有能力降低對標籤資料的資料依賴性。在這項工作中，我們介紹一種新的方法，將小樣本學習與 U-Net 架構和高斯過程模擬器 (GPE) 結合，增強了來自支援集的資料整合，以提升效能。GPE 經過訓練，可以學習支援影像與潛在空間中對應遮罩之間的關係，在推論時僅給予一個標籤較少的支援集，也能促進未見過查詢影像的分割。我們使用 M&Ms-2 公開資料集來測試我們的模型，以評估其從不同方向的心臟磁振造影中分割心臟的能力，並將其與最先進的無監督和少樣本方法進行比較。我們的架構與這些方法相比，顯示出更高的 DICE 係數，特別是在支援集大小相當小的更具挑戰性的設定中。

##### **EVQAScore: Efficient Video Question Answering Data Evaluation**
2411.06908v1 by Hao Liang, Zirong Chen, Wentao Zhang

Video question-answering (QA) is a core task in video understanding.
Evaluating the quality of video QA and video caption data quality for training
video large language models (VideoLLMs) is an essential challenge. Although
various methods have been proposed for assessing video caption quality, there
remains a lack of dedicated evaluation methods for Video QA. To address this
gap, we introduce EVQAScore, a reference-free method that leverages keyword
extraction to assess both video caption and video QA data quality.
Additionally, we incorporate frame sampling and rescaling techniques to enhance
the efficiency and robustness of our evaluation, this enables our score to
evaluate the quality of extremely long videos. Our approach achieves
state-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for
Spearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on
the VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using
EVQAScore for data selection, we achieved SOTA results with only 12.5\% of the
original data volume, outperforming the previous SOTA method PAC-S and 100\% of
data.

摘要：影片問答 (QA) 是影片理解中的一項核心任務。
評估影片 QA 和影片標題資料品質以訓練影片大型語言模型 (VideoLLM) 是項重要的挑戰。儘管
已經提出各種方法來評估影片標題品質，但仍然缺乏針對影片 QA 的專用評估方法。為了解決這個
問題，我們引入了 EVQAScore，一種無參考方法，它利用關鍵字萃取來評估影片標題和影片 QA 資料品質。
此外，我們結合了影格取樣和縮放技術來提升我們評估的效率和穩健性，這使得我們的評分能夠
評估極長影片的品質。我們的做法在影片標題評估的 VATEX-EVAL 基準上達到了最先進 (SOTA) 的效能（Kendall 相關性為 32.8，Spearman 相關性為 42.3，比前一個方法 PAC-S++ 高出 4.7 和 5.9）。此外，透過使用 EVQAScore 進行資料選取，我們僅使用原資料量 12.5% 就達到了 SOTA 結果，優於前一個 SOTA 方法 PAC-S 和 100% 的資料。

##### **LongSafetyBench: Long-Context LLMs Struggle with Safety Issues**
2411.06899v1 by Mianqiu Huang, Xiaoran Liu, Shaojun Zhou, Mozhi Zhang, Chenkun Tan, Pengyu Wang, Qipeng Guo, Zhe Xu, Linyang Li, Zhikai Lei, Linlin Li, Qun Liu, Yaqian Zhou, Xipeng Qiu, Xuanjing Huang

With the development of large language models (LLMs), the sequence length of
these models continues to increase, drawing significant attention to
long-context language models. However, the evaluation of these models has been
primarily limited to their capabilities, with a lack of research focusing on
their safety. Existing work, such as ManyShotJailbreak, has to some extent
demonstrated that long-context language models can exhibit safety concerns.
However, the methods used are limited and lack comprehensiveness. In response,
we introduce \textbf{LongSafetyBench}, the first benchmark designed to
objectively and comprehensively evaluate the safety of long-context models.
LongSafetyBench consists of 10 task categories, with an average length of
41,889 words. After testing eight long-context language models on
LongSafetyBench, we found that existing models generally exhibit insufficient
safety capabilities. The proportion of safe responses from most mainstream
long-context LLMs is below 50\%. Moreover, models' safety performance in
long-context scenarios does not always align with that in short-context
scenarios. Further investigation revealed that long-context models tend to
overlook harmful content within lengthy texts. We also proposed a simple yet
effective solution, allowing open-source models to achieve performance
comparable to that of top-tier closed-source models. We believe that
LongSafetyBench can serve as a valuable benchmark for evaluating the safety
capabilities of long-context language models. We hope that our work will
encourage the broader community to pay attention to the safety of long-context
models and contribute to the development of solutions to improve the safety of
long-context LLMs.

摘要：隨著大型語言模型（LLM）的發展，這些模型的序列長度持續增加，吸引了人們對長語境語言模型的極大關注。然而，對這些模型的評估主要侷限於它們的能力，而缺乏針對其安全性進行的研究。現有的研究，例如 ManyShotJailbreak，在某種程度上證明了長語境語言模型可能會出現安全問題。然而，所使用的方法有限且缺乏全面性。為了解決這個問題，我們引入了 \textbf{LongSafetyBench}，這是第一個旨在客觀且全面評估長語境模型安全性的基準。LongSafetyBench 包含 10 個任務類別，平均長度為 41,889 個字詞。在 LongSafetyBench 上測試了八個長語境語言模型後，我們發現現有模型普遍表現出安全性不足。大多數主流長語境 LLM 的安全回應比例低於 50%。此外，模型在長語境場景中的安全性表現並不總是與在短語境場景中的表現一致。進一步的調查顯示，長語境模型傾向於忽略長篇文字中的有害內容。我們還提出了一個簡單但有效的方法，讓開源模型能夠實現與頂級閉源模型相當的表現。我們相信 LongSafetyBench 可以作為評估長語境語言模型安全性能力的寶貴基準。我們希望我們的研究能鼓勵更廣泛的社群關注長語境模型的安全性，並為開發解決方案以改善長語境 LLM 的安全性做出貢獻。

##### **GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs**
2411.06878v1 by Sheng Tian, Xintan Zeng, Yifei Hu, Baokun Wang, Yongchao Liu, Yue Jin, Changhua Meng, Chuntao Hong, Tianyi Zhang, Weiqiang Wang

Graph-based patterns are extensively employed and favored by practitioners
within industrial companies due to their capacity to represent the behavioral
attributes and topological relationships among users, thereby offering enhanced
interpretability in comparison to black-box models commonly utilized for
classification and recognition tasks. For instance, within the scenario of
transaction risk management, a graph pattern that is characteristic of a
particular risk category can be readily employed to discern transactions
fraught with risk, delineate networks of criminal activity, or investigate the
methodologies employed by fraudsters. Nonetheless, graph data in industrial
settings is often characterized by its massive scale, encompassing data sets
with millions or even billions of nodes, making the manual extraction of graph
patterns not only labor-intensive but also necessitating specialized knowledge
in particular domains of risk. Moreover, existing methodologies for mining
graph patterns encounter significant obstacles when tasked with analyzing
large-scale attributed graphs. In this work, we introduce GraphRPM, an
industry-purpose parallel and distributed risk pattern mining framework on
large attributed graphs. The framework incorporates a novel edge-involved graph
isomorphism network alongside optimized operations for parallel graph
computation, which collectively contribute to a considerable reduction in
computational complexity and resource expenditure. Moreover, the intelligent
filtration of efficacious risky graph patterns is facilitated by the proposed
evaluation metrics. Comprehensive experimental evaluations conducted on
real-world datasets of varying sizes substantiate the capability of GraphRPM to
adeptly address the challenges inherent in mining patterns from large-scale
industrial attributed graphs, thereby underscoring its substantial value for
industrial deployment.

摘要：<paragraph>圖形化模式因能表示使用者行為屬性和拓撲關係，在產業公司中被廣泛採用且受青睞，因此與常使用於分類和辨識任務的黑箱模型相比，具備增強的可解釋性。例如，在交易風險管理的情境中，具有特定風險類別特徵的圖形模式可輕易用於辨識風險交易、描繪犯罪活動網路，或調查詐騙者所採用的方法。然而，產業環境中的圖形資料通常以其龐大規模為特徵，包含數百萬甚至數十億個節點的資料集，這使得圖形模式的手動萃取不僅耗費大量人力，還需要特定風險領域的專業知識。此外，現有的圖形模式挖掘方法在分析大型屬性圖形時會遭遇重大障礙。在這項工作中，我們引入了 GraphRPM，一個針對大型屬性圖形進行產業用途平行且分散的風險模式挖掘架構。此架構結合了新穎的邊緣參與圖形同構網路以及平行圖形運算的最佳化運算，共同大幅降低了運算複雜度和資源支出。此外，所提出的評估指標有助於有效風險圖形模式的智慧化過濾。在各種規模的真實世界資料集上進行的全面實驗評估證實了 GraphRPM 能夠適當地解決從大型產業屬性圖形中挖掘模式所固有的挑戰，因此強調了其在產業部署中的重要價值。</paragraph>

##### **Multi-Modal interpretable automatic video captioning**
2411.06872v1 by Antoine Hanna-Asaad, Decky Aspandi, Titus Zaharia

Video captioning aims to describe video contents using natural language
format that involves understanding and interpreting scenes, actions and events
that occurs simultaneously on the view. Current approaches have mainly
concentrated on visual cues, often neglecting the rich information available
from other important modality of audio information, including their
inter-dependencies. In this work, we introduce a novel video captioning method
trained with multi-modal contrastive loss that emphasizes both multi-modal
integration and interpretability. Our approach is designed to capture the
dependency between these modalities, resulting in more accurate, thus pertinent
captions. Furthermore, we highlight the importance of interpretability,
employing multiple attention mechanisms that provide explanation into the
model's decision-making process. Our experimental results demonstrate that our
proposed method performs favorably against the state-of the-art models on
commonly used benchmark datasets of MSR-VTT and VATEX.

摘要：影片字幕旨在使用自然語言格式描述影片內容，其中包括理解和詮釋同時在視圖上發生的場景、動作和事件。目前的做法主要集中在視覺線索上，常常忽略從其他重要的音訊資訊模式中獲得的豐富資訊，包括它們的相互依賴性。在這項工作中，我們介紹了一種新穎的影片字幕方法，使用多模式對比損失進行訓練，強調多模式整合和可解釋性。我們的做法旨在捕捉這些模式之間的依賴性，從而產生更準確、因此更相關的字幕。此外，我們強調可解釋性的重要性，採用多種注意力機制，對模型的決策過程提供說明。我們的實驗結果證明，我們提出的方法在 MSR-VTT 和 VATEX 常用的基準資料集上，表現優於現有最先進的模型。

##### **Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering**
2411.06866v1 by Boci Peng, Yongchao Liu, Xiaohe Bo, Sheng Tian, Baokun Wang, Chuntao Hong, Yan Zhang

Commonsense question answering is a crucial task that requires machines to
employ reasoning according to commonsense. Previous studies predominantly
employ an extracting-and-modeling paradigm to harness the information in KG,
which first extracts relevant subgraphs based on pre-defined rules and then
proceeds to design various strategies aiming to improve the representations and
fusion of the extracted structural knowledge. Despite their effectiveness,
there are still two challenges. On one hand, subgraphs extracted by rule-based
methods may have the potential to overlook critical nodes and result in
uncontrollable subgraph size. On the other hand, the misalignment between graph
and text modalities undermines the effectiveness of knowledge fusion,
ultimately impacting the task performance. To deal with the problems above, we
propose a novel framework: \textbf{S}ubgraph R\textbf{E}trieval Enhanced by
Gra\textbf{P}h-\textbf{T}ext \textbf{A}lignment, named \textbf{SEPTA}. Firstly,
we transform the knowledge graph into a database of subgraph vectors and
propose a BFS-style subgraph sampling strategy to avoid information loss,
leveraging the analogy between BFS and the message-passing mechanism. In
addition, we propose a bidirectional contrastive learning approach for
graph-text alignment, which effectively enhances both subgraph retrieval and
knowledge fusion. Finally, all the retrieved information is combined for
reasoning in the prediction module. Extensive experiments on five datasets
demonstrate the effectiveness and robustness of our framework.

摘要：常識問答是一項至關重要的任務，要求機器根據常識進行推理。先前的研究主要採用提取和建模範例來利用知識圖譜中的資訊，該範例首先根據預定義規則提取相關子圖，然後繼續設計各種策略，旨在改善提取的結構知識的表示和融合。儘管它們很有效，但仍存在兩個挑戰。一方面，基於規則的方法提取的子圖可能會忽略關鍵節點並導致無法控制的子圖大小。另一方面，圖形和文本模式之間的錯位會損害知識融合的有效性，最終影響任務績效。為了應對上述問題，我們提出了一個新的框架：由圖形-文本對齊增強的子圖檢索，稱為 SEPTA。首先，我們將知識圖形轉換為子圖向量的資料庫，並提出 BFS 風格的子圖採樣策略以避免資訊遺失，利用 BFS 和訊息傳遞機制之間的類比。此外，我們提出了一個雙向對比學習方法，用於圖形-文本對齊，這有效地增強了子圖檢索和知識融合。最後，所有檢索到的資訊都結合起來，在預測模組中進行推理。在五個資料集上的大量實驗證明了我們框架的有效性和穩健性。

##### **Computable Model-Independent Bounds for Adversarial Quantum Machine Learning**
2411.06863v1 by Bacui Li, Tansu Alpcan, Chandra Thapa, Udaya Parampalli

By leveraging the principles of quantum mechanics, QML opens doors to novel
approaches in machine learning and offers potential speedup. However, machine
learning models are well-documented to be vulnerable to malicious
manipulations, and this susceptibility extends to the models of QML. This
situation necessitates a thorough understanding of QML's resilience against
adversarial attacks, particularly in an era where quantum computing
capabilities are expanding. In this regard, this paper examines
model-independent bounds on adversarial performance for QML. To the best of our
knowledge, we introduce the first computation of an approximate lower bound for
adversarial error when evaluating model resilience against sophisticated
quantum-based adversarial attacks. Experimental results are compared to the
computed bound, demonstrating the potential of QML models to achieve high
robustness. In the best case, the experimental error is only 10% above the
estimated bound, offering evidence of the inherent robustness of quantum
models. This work not only advances our theoretical understanding of quantum
model resilience but also provides a precise reference bound for the future
development of robust QML algorithms.

摘要：<paragraph>透過運用量子力學原理，QML 開啟了機器學習的新方法，並提供潛在的加速。然而，機器學習模型已被充分證明容易受到惡意的操縱，而這種易受性也延伸到 QML 的模型。這種情況需要徹底了解 QML 對抗攻擊的韌性，特別是在量子運算能力擴展的時代。在這方面，本文探討了 QML 對抗效能的模型無關邊界。據我們所知，我們引入了針對對抗錯誤的近似下限的首次計算，以評估模型對抗複雜的基於量子的對抗攻擊的韌性。實驗結果與計算出的邊界進行比較，證明了 QML 模型實現高度穩健性的潛力。在最佳情況下，實驗誤差僅比估計邊界高出 10%，提供了量子模型內在穩健性的證據。這項工作不僅提升了我們對量子模型韌性的理論理解，還為未來發展穩健的 QML 演算法提供了精確的參考邊界。</paragraph>

##### **Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models**
2411.06860v1 by Abdullah Fajar, Setiadi Yazid, Indra Budi

Phishing attacks remain a persistent threat to online security, demanding
robust detection methods. This study investigates the use of machine learning
to identify phishing URLs, emphasizing the crucial role of feature selection
and model interpretability for improved performance. Employing Recursive
Feature Elimination, the research pinpointed key features like "length_url,"
"time_domain_activation" and "Page_rank" as strong indicators of phishing
attempts. The study evaluated various algorithms, including CatBoost, XGBoost,
and Explainable Boosting Machine, assessing their robustness and scalability.
XGBoost emerged as highly efficient in terms of runtime, making it well-suited
for large datasets. CatBoost, on the other hand, demonstrated resilience by
maintaining high accuracy even with reduced features. To enhance transparency
and trustworthiness, Explainable AI techniques, such as SHAP, were employed to
provide insights into feature importance. The study's findings highlight that
effective feature selection and model interpretability can significantly
bolster phishing detection systems, paving the way for more efficient and
adaptable defenses against evolving cyber threats

摘要：網路釣魚攻擊持續對線上安全構成威脅，因此需要強大的偵測方法。本研究探討使用機器學習來識別網路釣魚網址，並強調特徵選擇和模型可解釋性對於提升效能至關重要的角色。研究採用遞迴特徵消除法，找出「網址長度」、「時域啟動」和「網頁排名」等關鍵特徵，作為網路釣魚攻擊的強力指標。本研究評估了各種演算法，包括 CatBoost、XGBoost 和可解釋提升機，評估其穩健性和可擴充性。XGBoost 在執行時間方面表現出極高的效率，使其非常適合大型資料集。另一方面，CatBoost 即使在特徵減少的情況下，仍能維持高準確度，展現出韌性。為了提高透明度和可信度，本研究採用可解釋 AI 技術（例如 SHAP），以提供特徵重要性的見解。本研究的發現強調，有效的特徵選擇和模型可解釋性可以顯著地強化網路釣魚偵測系統，為對抗不斷演變的網路威脅奠定更有效率且適應性更強的防禦基礎。

##### **Scientific machine learning in ecological systems: A study on the predator-prey dynamics**
2411.06858v1 by Ranabir Devgupta, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat

In this study, we apply two pillars of Scientific Machine Learning: Neural
Ordinary Differential Equations (Neural ODEs) and Universal Differential
Equations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental
ecological model describing the dynamic interactions between predator and prey
populations. The Lotka-Volterra model is critical for understanding ecological
dynamics, population control, and species interactions, as it is represented by
a system of differential equations. In this work, we aim to uncover the
underlying differential equations without prior knowledge of the system,
relying solely on training data and neural networks. Using robust modeling in
the Julia programming language, we demonstrate that both Neural ODEs and UDEs
can be effectively utilized for prediction and forecasting of the
Lotka-Volterra system. More importantly, we introduce the forecasting breakdown
point: the time at which forecasting fails for both Neural ODEs and UDEs. We
observe how UDEs outperform Neural ODEs by effectively recovering the
underlying dynamics and achieving accurate forecasting with significantly less
training data. Additionally, we introduce Gaussian noise of varying magnitudes
(from mild to high) to simulate real-world data perturbations and show that
UDEs exhibit superior robustness, effectively recovering the underlying
dynamics even in the presence of noisy data, while Neural ODEs struggle with
high levels of noise. Through extensive hyperparameter optimization, we offer
insights into neural network architectures, activation functions, and
optimizers that yield the best results. This study opens the door to applying
Scientific Machine Learning frameworks for forecasting tasks across a wide
range of ecological and scientific domains.

摘要：<paragraph>在這項研究中，我們運用科學機器學習的兩大支柱：神經常微分方程式 (Neural ODE) 和通用微分方程式 (UDE) 到 Lotka Volterra 掠食者獵物模型，這是一個描述掠食者和獵物族群之間動態交互作用的基本生態模型。Lotka-Volterra 模型對於了解生態動力學、族群控制和物種交互至關重要，因為它是由微分方程式系統表示。在這項工作中，我們旨在揭示在沒有系統先備知識的情況下，僅依賴訓練資料和神經網路的基礎微分方程式。使用 Julia 程式語言中的強健建模，我們證明了神經 ODE 和 UDE 都可以有效地用於 Lotka-Volterra 系統的預測和預報。更重要的是，我們引入了預測崩潰點：神經 ODE 和 UDE 預測失敗的時間。我們觀察到 UDE 如何通過有效地恢復基礎動態並在訓練資料顯著減少的情況下實現準確預測，從而優於神經 ODE。此外，我們引入了不同大小的 Gaussian 雜訊（從輕微到高）來模擬真實世界的資料擾動，並表明 UDE 表現出優異的穩健性，即使在有雜訊資料的情況下也能有效恢復基礎動態，而神經 ODE 則難以應付高水準的雜訊。透過廣泛的超參數最佳化，我們深入了解了神經網路架構、啟動函數和最佳化器，這些架構、函數和最佳化器可產生最佳結果。這項研究開啟了應用科學機器學習架構進行預測任務的大門，涵蓋廣泛的生態和科學領域。</paragraph>

##### **A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information**
2411.06855v1 by Prashant Kapil, Asif Ekbal

Hate speech, offensive language, aggression, racism, sexism, and other
abusive language are common phenomena in social media. There is a need for
Artificial Intelligence(AI)based intervention which can filter hate content at
scale. Most existing hate speech detection solutions have utilized the features
by treating each post as an isolated input instance for the classification.
This paper addresses this issue by introducing a unique model that improves
hate speech identification for the English language by utilising intra-user and
inter-user-based information. The experiment is conducted over single-task
learning (STL) and multi-task learning (MTL) paradigms that use deep neural
networks, such as convolutional neural networks (CNN), gated recurrent unit
(GRU), bidirectional encoder representations from the transformer (BERT), and A
Lite BERT (ALBERT). We use three benchmark datasets and conclude that combining
certain user features with textual features gives significant improvements in
macro-F1 and weighted-F1.

摘要：仇恨言論、攻擊性語言、侵略、種族主義、性別歧視和其他
辱罵性語言是社群媒體中的常見現象。有必要進行
基於人工智慧 (AI) 的干預，它可以大規模過濾仇恨內容。大多數現有的仇恨言論偵測解決方案都利用了這些功能
將每則貼文視為分類的孤立輸入實體。
本文透過引入一個獨特模型來解決這個問題，該模型透過利用使用者內部和
基於使用者之間的資訊來改善英文仇恨言論的識別。實驗是在單一任務
學習 (STL) 和多任務學習 (MTL) 典範上進行，這些典範使用深度神經
網路，例如卷積神經網路 (CNN)、門控遞迴單元
(GRU)、來自 Transformer 的雙向編碼器表示 (BERT) 和 A
Lite BERT (ALBERT)。我們使用三個基準資料集，並得出結論，將
某些使用者功能與文字功能相結合，可以在巨集 F1 和加權 F1 中獲得顯著的改善。

##### **Evaluating Large Language Models on Financial Report Summarization: An Empirical Study**
2411.06852v1 by Xinqi Yang, Scott Zang, Yong Ren, Dingjie Peng, Zheng Wen

In recent years, Large Language Models (LLMs) have demonstrated remarkable
versatility across various applications, including natural language
understanding, domain-specific knowledge tasks, etc. However, applying LLMs to
complex, high-stakes domains like finance requires rigorous evaluation to
ensure reliability, accuracy, and compliance with industry standards. To
address this need, we conduct a comprehensive and comparative study on three
state-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their
effectiveness in generating automated financial reports. Our primary motivation
is to explore how these models can be harnessed within finance, a field
demanding precision, contextual relevance, and robustness against erroneous or
misleading information. By examining each model's capabilities, we aim to
provide an insightful assessment of their strengths and limitations. Our paper
offers benchmarks for financial report analysis, encompassing proposed metrics
such as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative
evaluation framework that integrates both quantitative metrics (e.g.,
precision, recall) and qualitative analyses (e.g., contextual fit, consistency)
to provide a holistic view of each model's output quality. Additionally, we
make our financial dataset publicly available, inviting researchers and
practitioners to leverage, scrutinize, and enhance our findings through broader
community engagement and collaborative improvement. Our dataset is available on
huggingface.

摘要：<paragraph>近年來，大型語言模型 (LLM) 在各種應用中展現了非凡的多樣性，包括自然語言理解、特定領域的知識任務等。然而，將 LLM 應用於金融等複雜且高風險的領域需要嚴格的評估，以確保可靠性、準確性和符合產業標準。為了滿足這個需求，我們對三種最先進的 LLM 進行了全面且比較性的研究，包括 GLM-4、Mistral-NeMo 和 LLaMA3.1，重點在於它們生成自動化財務報表的效能。我們的首要動機是探索如何將這些模型應用於金融領域，這是一個需要精準性、脈絡相關性和對錯誤或誤導資訊具有穩健性的領域。透過檢視每個模型的能力，我們旨在對它們的優缺點提供深入的評估。我們的論文提供了財務報表分析的基準，包含提議的指標，例如 ROUGE-1、BERT 分數和 LLM 分數。我們引入了一個創新的評估架構，它整合了量化指標（例如，精準度、召回率）和定性分析（例如，脈絡貼合度、一致性），以提供每個模型輸出品質的全貌。此外，我們公開了我們的財務資料集，邀請研究人員和實務工作者透過更廣泛的社群參與和協作改進，來利用、審查和增強我們的發現。我們的資料集可在 huggingface 上取得。</paragraph>

##### **1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs**
2411.06850v1 by Jebish Purbey, Siddartha Pullakhandam, Kanwal Mehreen, Muhammad Arham, Drishti Sharma, Ashay Srivastava, Ram Mohan Rao Kadiyala

This paper presents a detailed system description of our entry for the
CHiPSAL 2025 shared task, focusing on language detection, hate speech
identification, and target detection in Devanagari script languages. We
experimented with a combination of large language models and their ensembles,
including MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like
focal loss to address challenges in the natural understanding of Devanagari
languages, such as multilingual processing and class imbalance. Our approach
achieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804
for Sub-tasks A, B, and C respectively. This work provides insights into the
effectiveness of transformer models in tasks with domain-specific and
linguistic challenges, as well as areas for potential improvement in future
iterations.

摘要：這篇論文詳細說明了我們在 CHiPSAL 2025 共享任務中的參賽系統，重點在於天城文語言中的語言偵測、仇恨言論辨識和目標偵測。我們實驗了大型語言模型及其集合的組合，包括 MuRIL、IndicBERT 和 Gemma-2，並利用焦點損失等獨特技術來解決天城文語言自然理解中的挑戰，例如多語言處理和類別不平衡。我們的做法在所有任務中都取得了有競爭力的結果：子任務 A、B 和 C 的 F1 分別為 0.9980、0.7652 和 0.6804。這項工作提供了對Transformer模型在具有特定領域和語言挑戰的任務中的有效性的見解，以及未來迭代中潛在改進的領域。

##### **LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models**
2411.06839v1 by Runming Yang, Taiqiang Wu, Jiahao Wang, Pengfei Hu, Ngai Wong, Yujiu Yang

In this paper, we propose a novel LLM-Neo framework that efficiently
transfers knowledge from a large language model (LLM) teacher to a compact
student. Initially, we revisit the knowledge distillation (KD) and low-rank
adaption (LoRA), and argue that they share the same paradigm. Inspired by this
observation, we explore the strategy that combines LoRA and KD to enhance the
efficiency of knowledge transfer. We first summarize some guidelines for this
design and further develop the LLM-Neo. Experimental results on compressing
Llama 2 and Llama 3 show that LLM-Neo outperforms various baselines. Further
analysis demonstrates the robustness of the proposed LLM-Neo on variants of
LoRA. The trained models have been available at
\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{this
repository}.

摘要：在本文中，我們提出一個新穎的 LLM-Neo 框架，可有效地將知識從大型語言模型 (LLM) 教師傳輸到一個精簡的學生。最初，我們重新探討知識蒸餾 (KD) 和低秩適應 (LoRA)，並論證它們共享相同的範例。受此觀察啟發，我們探討了結合 LoRA 和 KD 以增強知識傳輸效率的策略。我們首先總結了一些關於此設計的指導方針，並進一步開發 LLM-Neo。對 Llama 2 和 Llama 3 進行壓縮的實驗結果表明，LLM-Neo 優於各種基線。進一步的分析證明了所提出的 LLM-Neo 在 LoRA 變體上的穩健性。訓練過的模型已在
\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{此儲存庫}中提供。

##### **Persuasion with Large Language Models: a Survey**
2411.06837v1 by Alexander Rogiers, Sander Noels, Maarten Buyl, Tijl De Bie

The rapid rise of Large Language Models (LLMs) has created new disruptive
possibilities for persuasive communication, by enabling fully-automated
personalized and interactive content generation at an unprecedented scale. In
this paper, we survey the research field of LLM-based persuasion that has
emerged as a result. We begin by exploring the different modes in which LLM
Systems are used to influence human attitudes and behaviors. In areas such as
politics, marketing, public health, e-commerce, and charitable giving, such LLM
Systems have already achieved human-level or even super-human persuasiveness.
We identify key factors influencing their effectiveness, such as the manner of
personalization and whether the content is labelled as AI-generated. We also
summarize the experimental designs that have been used to evaluate progress.
Our survey suggests that the current and future potential of LLM-based
persuasion poses profound ethical and societal risks, including the spread of
misinformation, the magnification of biases, and the invasion of privacy. These
risks underscore the urgent need for ethical guidelines and updated regulatory
frameworks to avoid the widespread deployment of irresponsible and harmful LLM
Systems.

摘要：大型語言模型 (LLM) 的快速崛起為具有說服力的溝通創造了新的破壞性可能性，它能以前所未有的規模實現全自動化、個性化和互動式內容生成。在本文中，我們調查了由此產生的基於 LLM 的說服研究領域。我們首先探討了 LLM 系統用於影響人類態度和行為的不同模式。在政治、行銷、公共衛生、電子商務和慈善捐贈等領域，此類 LLM 系統已經達到人類水平甚至超人類的說服力。我們找出影響其有效性的關鍵因素，例如個性化的方式以及內容是否標示為 AI 生成的。我們也總結了用於評估進度的實驗設計。我們的調查表明，基於 LLM 的說服的當前和未來潛力帶來了深遠的倫理和社會風險，包括錯誤訊息的傳播、偏見的放大和隱私的侵犯。這些風險強調了制定道德準則和更新法規框架的迫切需要，以避免不負責任和有害的 LLM 系統的廣泛部署。

##### **HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment**
2411.06835v1 by Yannis Belkhiter, Giulio Zizzo, Sergio Maffeis

With the introduction of the transformers architecture, LLMs have
revolutionized the NLP field with ever more powerful models. Nevertheless,
their development came up with several challenges. The exponential growth in
computational power and reasoning capabilities of language models has
heightened concerns about their security. As models become more powerful,
ensuring their safety has become a crucial focus in research. This paper aims
to address gaps in the current literature on jailbreaking techniques and the
evaluation of LLM vulnerabilities. Our contributions include the creation of a
novel dataset designed to assess the harmfulness of model outputs across
multiple harm levels, as well as a focus on fine-grained harm-level analysis.
Using this framework, we provide a comprehensive benchmark of state-of-the-art
jailbreaking attacks, specifically targeting the Vicuna 13B v1.5 model.
Additionally, we examine how quantization techniques, such as AWQ and GPTQ,
influence the alignment and robustness of models, revealing trade-offs between
enhanced robustness with regards to transfer attacks and potential increases in
vulnerability on direct ones. This study aims to demonstrate the influence of
harmful input queries on the complexity of jailbreaking techniques, as well as
to deepen our understanding of LLM vulnerabilities and improve methods for
assessing model robustness when confronted with harmful content, particularly
in the context of compression strategies.

摘要：隨著Transformer架構的引入，LLM 已透過更強大的模型徹底改變 NLP 領域。儘管如此，它們的開發仍面臨許多挑戰。語言模型在計算能力和推理能力上的指數成長，已加劇人們對其安全性的疑慮。隨著模型變得更強大，確保其安全性已成為研究中的關鍵焦點。本文旨在解決當前有關越獄技術和 LLM 漏洞評估文獻中的差距。我們的貢獻包括建立一個新穎的資料集，旨在評估模型輸出在多個危害層級中的危害性，以及專注於細微的危害層級分析。使用此架構，我們提供了最先進越獄攻擊的全面基準，特別針對 Vicuna 13B v1.5 模型。此外，我們探討量化技術（例如 AWQ 和 GPTQ）如何影響模型的對齊和穩健性，揭示了在針對轉移攻擊的增強穩健性與直接攻擊的潛在漏洞增加之間的權衡。本研究旨在證明有害輸入查詢對越獄技術複雜性的影響，以及加深我們對 LLM 漏洞的理解，並改善在面對有害內容時評估模型穩健性的方法，特別是在壓縮策略的背景下。

##### **Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs**
2411.06824v1 by Megh Thakkar, Yash More, Quentin Fournier, Matthew Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar

There is a growing interest in training domain-expert LLMs that excel in
specific technical fields compared to their general-purpose instruction-tuned
counterparts. However, these expert models often experience a loss in their
safety abilities in the process, making them capable of generating harmful
content. As a solution, we introduce an efficient and effective merging-based
alignment method called \textsc{MergeAlign} that interpolates the domain and
alignment vectors, creating safer domain-specific models while preserving their
utility. We apply \textsc{MergeAlign} on Llama3 variants that are experts in
medicine and finance, obtaining substantial alignment improvements with minimal
to no degradation on domain-specific benchmarks. We study the impact of model
merging through model similarity metrics and contributions of individual models
being merged. We hope our findings open new research avenues and inspire more
efficient development of safe expert LLMs.

摘要：相較於經過通用指示微調的模型，訓練在特定技術領域中表現出色的領域專家 LLM 的興趣正與日俱增。然而，這些專家模型在過程中通常會喪失其安全性，使其能夠產生有害內容。作為解決方案，我們引入一種稱為 \textsc{MergeAlign} 的高效且有效的基於合併的對齊方法，該方法會內插領域和對齊向量，在保留其效用的同時建立更安全的領域特定模型。我們在醫學和金融領域專家的 Llama3 變體上套用 \textsc{MergeAlign}，在領域特定基準上獲得顯著的對齊改善，且幾乎沒有或沒有任何降低。我們透過模型相似性指標和個別模型合併的貢獻來研究模型合併的影響。我們希望我們的發現能開啟新的研究途徑，並激勵更有效地開發安全的專家 LLM。

##### **Generative midtended cognition and Artificial Intelligence. Thinging with thinging things**
2411.06812v1 by Xabier E. Barandiaran, Marta Pérez-Verdugo

This paper introduces the concept of ``generative midtended cognition'',
exploring the integration of generative AI with human cognition. The term
"generative" reflects AI's ability to iteratively produce structured outputs,
while "midtended" captures the potential hybrid (human-AI) nature of the
process. It stands between traditional conceptions of intended creation,
understood directed from within, and extended processes that bring
exo-biological processes into the creative process. We examine current
generative technologies (based on multimodal transformer architectures typical
of large language models like ChatGPT), to explain how they can transform human
cognitive agency beyond what standard theories of extended cognition can
capture. We suggest that the type of cognitive activity typical of the coupling
between a human and generative technologies is closer (but not equivalent) to
social cognition than to classical extended cognitive paradigms. Yet, it
deserves a specific treatment. We provide an explicit definition of generative
midtended cognition in which we treat interventions by AI systems as
constitutive of the agent's intentional creative processes. Furthermore, we
distinguish two dimensions of generative hybrid creativity: 1. Width: captures
the sensitivity of the context of the generative process (from the single
letter to the whole historical and surrounding data), 2. Depth: captures the
granularity of iteration loops involved in the process. Generative midtended
cognition stands in the middle depth between conversational forms of cognition
in which complete utterances or creative units are exchanged, and
micro-cognitive (e.g. neural) subpersonal processes. Finally, the paper
discusses the potential risks and benefits of widespread generative AI
adoption, including the challenges of authenticity, generative power asymmetry,
and creative boost or atrophy.

摘要：<paragraph>本文介绍了``生成式中间认知''的概念，探讨了生成式人工智能与人类认知的整合。术语“生成式”反映了人工智能迭代生成结构化输出的能力，而“中间”则捕捉到了该过程潜在的混合（人机）性质。它介于传统的有意创造概念（理解为从内部指导）和将外生物过程带入创造过程的扩展过程之间。我们研究了当前的生成式技术（基于大型语言模型（如 ChatGPT）中典型的多模态转换器架构），以解释它们如何转变人类认知能动性，超出扩展认知的标准理论所能捕捉到的范围。我们认为，人与生成式技术之间耦合所特有的认知活动类型更接近（但不等同于）社会认知，而不是经典的扩展认知范例。然而，它值得进行专门处理。我们对生成式中间认知提供了一个明确的定义，其中我们将人工智能系统的干预视为代理人的有意创造过程的组成部分。此外，我们区分了生成式混合创造力的两个维度：1. 宽度：捕捉生成过程上下文的敏感性（从单个字母到整个历史和周围数据），2. 深度：捕捉过程中涉及的迭代循环的粒度。生成式中间认知处于认知的对话形式（其中交换完整的陈述或创造性单位）和微认知（例如神经）亚个人过程之间的中间深度。最后，本文讨论了广泛采用生成式人工智能的潜在风险和好处，包括真实性、生成能力不对称以及创造力的提升或萎缩等挑战。</paragraph>

##### **JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset**
2411.06810v1 by Daria Tsereh, Mark Mirgaleev, Ivan Molodetskikh, Roman Kazantsev, Dmitriy Vatolin

Learning-based image compression methods have improved in recent years and
started to outperform traditional codecs. However, neural-network approaches
can unexpectedly introduce visual artifacts in some images. We therefore
propose methods to separately detect three types of artifacts (texture and
boundary degradation, color change, and text corruption), to localize the
affected regions, and to quantify the artifact strength. We consider only those
regions that exhibit distortion due solely to the neural compression but that a
traditional codec recovers successfully at a comparable bitrate. We employed
our methods to collect artifacts for the JPEG AI verification model with
respect to HM-18.0, the H.265 reference software. We processed about 350,000
unique images from the Open Images dataset using different compression-quality
parameters; the result is a dataset of 46,440 artifacts validated through
crowd-sourced subjective assessment. Our proposed dataset and methods are
valuable for testing neural-network-based image codecs, identifying bugs in
these codecs, and enhancing their performance. We make source code of the
methods and the dataset publicly available.

摘要：近年來，基於學習的影像壓縮方法已有進步，且
開始優於傳統的編解碼器。然而，神經網路方法
可能會意外地在某些影像中引入視覺瑕疵。因此
我們提出方法來分別偵測三種類型的瑕疵（紋理和
邊界劣化、色彩變異和文字損毀），以找出受影響區域，並
量化瑕疵強度。我們僅考慮那些僅因神經壓縮而產生失真的區域，但
傳統編解碼器在可比較的位元率下可以成功復原的區域。我們採用
我們的這些方法來收集 JPEG AI 驗證模型相對於 HM-18.0、H.265
參考軟體的瑕疵。我們使用不同的壓縮品質
參數處理了 Open Images 資料集中的約 350,000 張獨特影像；結果是
一個包含 46,440 個瑕疵的資料集，並經過群眾外包的
主觀評估驗證。我們提出的資料集和方法對於測試
基於神經網路的影像編解碼器、找出這些編解碼器中的錯誤，以及
提升其效能很有價值。我們公開原始碼
方法和資料集。

##### **AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant**
2411.06805v1 by Yujia Zhou, Zheng Liu, Zhicheng Dou

The emergence of Large Language Models (LLMs) has significantly advanced
natural language processing, but these models often generate factually
incorrect information, known as "hallucination". Initial retrieval-augmented
generation (RAG) methods like the "Retrieve-Read" framework was inadequate for
complex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised
Fine-Tuning (SFT) methods improved performance but required frequent retraining
and risked altering foundational LLM capabilities. To cope with these
challenges, we propose Assistant-based Retrieval-Augmented Generation
(AssistRAG), integrating an intelligent information assistant within LLMs. This
assistant manages memory and knowledge through tool usage, action execution,
memory building, and plan specification. Using a two-phase training approach,
Curriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG
enhances information retrieval and decision-making. Experiments show AssistRAG
significantly outperforms benchmarks, especially benefiting less advanced LLMs,
by providing superior reasoning capabilities and accurate responses.

摘要：大型語言模型 (LLM) 的出現大幅提升了自然語言處理，但這些模型通常會產生事實不正確的資訊，稱為「幻覺」。最初的檢索增強產生 (RAG) 方法，例如「檢索-閱讀」架構，不足以應付複雜的推理任務。後續基於提示的 RAG 策略和監督微調 (SFT) 方法改善了效能，但需要頻繁重新訓練，並且有風險會改變 LLM 的基本能力。為了應對這些挑戰，我們提出基於助理的檢索增強產生 (AssistRAG)，在 LLM 中整合一個智慧型資訊助理。這個助理透過工具使用、動作執行、記憶體建構和計畫規範來管理記憶體和知識。使用兩階段訓練方法，課程助理學習和強化偏好最佳化。AssistRAG 增強了資訊檢索和決策制定。實驗顯示，AssistRAG 明顯優於基準，特別是有益於較不先進的 LLM，因為它提供了優異的推理能力和準確的回應。

##### **LA4SR: illuminating the dark proteome with generative AI**
2411.06798v1 by David R. Nelson, Ashish Kumar Jaiswal, Noha Ismail, Alexandra Mystikou, Kourosh Salehi-Ashtiani

AI language models (LMs) show promise for biological sequence analysis. We
re-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,
ranging from 70M to 12B parameters) for microbial sequence classification. The
models achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the
recall of BLASTP. They effectively classified the algal dark proteome -
uncharacterized proteins comprising about 65% of total proteins - validated on
new data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger
(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%
of available data, rapidly achieving strong generalization capacity. High
accuracy was achieved when training data had intact or scrambled terminal
information, demonstrating robust generalization to incomplete sequences.
Finally, we provide custom AI explainability software tools for attributing
amino acid patterns to AI generative processes and interpret their outputs in
evolutionary and biophysical contexts.

摘要：人工智慧語言模型（LM）在生物序列分析中展現出潛力。我們重新設計了開放原始碼的 LM（GPT-2、BLOOM、DistilRoBERTa、ELECTRA 和 Mamba，範圍從 70M 到 12B 個參數），用於微生物序列分類。這些模型達到了高達 95 的 F1 分數，運作速度比 BLASTP 快了 16,580 倍，召回率為其 2.9 倍。它們有效地對藻類暗蛋白組進行了分類，這些蛋白質未經表徵，約佔總蛋白質的 65%，並在新的資料上進行了驗證，包括一個新的、完整的 Hi-C/Pacbio 衣藻基因組。當使用不到 2% 的可用資料進行訓練時，較大的 (>1B) LA4SR 模型達到了高準確度（F1 > 86），迅速達到了強大的泛化能力。當訓練資料具有完整的或打亂的終端資訊時，達到了高準確度，證明了對不完整序列的強大泛化能力。最後，我們提供客製化的 AI 可解釋性軟體工具，用於將胺基酸模式歸因於 AI 生成過程，並在演化和生物物理背景下解釋其輸出。

##### **Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks**
2411.06792v1 by Wenxuan Pan, Feifei Zhao, Bing Han, Haibo Tong, Yi Zeng

By exploiting discrete signal processing and simulating brain neuron
communication, Spiking Neural Networks (SNNs) offer a low-energy alternative to
Artificial Neural Networks (ANNs). However, existing SNN models, still face
high computational costs due to the numerous time steps as well as network
depth and scale. The tens of billions of neurons and trillions of synapses in
the human brain are developed from only 20,000 genes, which inspires us to
design an efficient genetic encoding strategy that dynamic evolves to regulate
large-scale deep SNNs at low cost. Therefore, we first propose a genetically
scaled SNN encoding scheme that incorporates globally shared genetic
interactions to indirectly optimize neuronal encoding instead of weight, which
obviously brings about reductions in parameters and energy consumption. Then, a
spatio-temporal evolutionary framework is designed to optimize the inherently
initial wiring rules. Two dynamic regularization operators in the fitness
function evolve the neuronal encoding to a suitable distribution and enhance
information quality of the genetic interaction respectively, substantially
accelerating evolutionary speed and improving efficiency. Experiments show that
our approach compresses parameters by approximately 50\% to 80\%, while
outperforming models on the same architectures by 0.21\% to 4.38\% on CIFAR-10,
CIFAR-100 and ImageNet. In summary, the consistent trends of the proposed
genetically encoded spatio-temporal evolution across different datasets and
architectures highlight its significant enhancements in terms of efficiency,
broad scalability and robustness, demonstrating the advantages of the
brain-inspired evolutionary genetic coding for SNN optimization.

摘要：<paragraph>透過利用離散訊號處理和模擬大腦神經元通訊，脈衝神經網路 (SNN) 提供了人工神經網路 (ANN) 的低能耗替代方案。然而，現有的 SNN 模型由於大量的時間步驟以及網路深度和規模，仍然面臨高運算成本。人類大腦中的數十億個神經元和數兆突觸僅由 20,000 個基因組成，這啟發我們設計一種有效率的遺傳編碼策略，以動態演化來低成本地調節大規模深度 SNN。因此，我們首先提出一個遺傳比例的 SNN 編碼方案，它結合了全球共享的遺傳交互作用，以間接優化神經元編碼，而不是權重，這顯然會減少參數和能耗。然後，設計了一個時空演化框架來優化固有的初始接線規則。適能函數中的兩個動態正則化運算子將神經元編碼演化到一個合適的分布，並分別增強遺傳交互作用的資訊品質，大幅加速演化速度並提高效率。實驗表明，我們的做法將參數壓縮了大約 50% 到 80%，同時在 CIFAR-10、CIFAR-100 和 ImageNet 上以 0.21% 到 4.38% 的幅度優於相同架構上的模型。總之，所提出的遺傳編碼時空演化在不同資料集和架構中的一致趨勢突顯了它在效率、廣泛可擴充性和穩健性方面的顯著增強，證明了大腦啟發的演化遺傳編碼在 SNN 最佳化方面的優勢。</paragraph>

##### **Large-scale moral machine experiment on large language models**
2411.06790v1 by Muhammad Shahrul Zaim bin Ahmad, Kazuhiro Takemoto

The rapid advancement of Large Language Models (LLMs) and their potential
integration into autonomous driving systems necessitates understanding their
moral decision-making capabilities. While our previous study examined four
prominent LLMs using the Moral Machine experimental framework, the dynamic
landscape of LLM development demands a more comprehensive analysis. Here, we
evaluate moral judgments across 51 different LLMs, including multiple versions
of proprietary models (GPT, Claude, Gemini) and open-source alternatives
(Llama, Gemma), to assess their alignment with human moral preferences in
autonomous driving scenarios. Using a conjoint analysis framework, we evaluated
how closely LLM responses aligned with human preferences in ethical dilemmas
and examined the effects of model size, updates, and architecture. Results
showed that proprietary models and open-source models exceeding 10 billion
parameters demonstrated relatively close alignment with human judgments, with a
significant negative correlation between model size and distance from human
judgments in open-source models. However, model updates did not consistently
improve alignment with human preferences, and many LLMs showed excessive
emphasis on specific ethical principles. These findings suggest that while
increasing model size may naturally lead to more human-like moral judgments,
practical implementation in autonomous driving systems requires careful
consideration of the trade-off between judgment quality and computational
efficiency. Our comprehensive analysis provides crucial insights for the
ethical design of autonomous systems and highlights the importance of
considering cultural contexts in AI moral decision-making.

摘要：大型語言模型（LLM）的快速進展及其整合到自動駕駛系統中的潛力，使得了解其道德決策能力變得必要。雖然我們先前的研究使用道德機器實驗框架檢驗了四個突出的 LLM，但 LLM 開發的動態環境需要更全面的分析。在此，我們評估了 51 個不同的 LLM 的道德判斷，包括多個版本的專有模型（GPT、Claude、Gemini）和開源替代方案（Llama、Gemma），以評估它們在自動駕駛場景中與人類道德偏好的對齊程度。使用聯合分析框架，我們評估了 LLM 回應在道德困境中與人類偏好的接近程度，並檢驗了模型大小、更新和架構的影響。結果表明，超過 100 億個參數的專有模型和開源模型顯示出與人類判斷相對接近的對齊，在開源模型中，模型大小與與人類判斷的距離之間存在顯著的負相關。然而，模型更新並未持續改善與人類偏好的對齊，並且許多 LLM 對特定的道德原則表現出過度的強調。這些發現表明，雖然增加模型大小可能會自然地導致更類似人類的道德判斷，但在自動駕駛系統中的實際實施需要仔細考慮判斷品質和計算效率之間的權衡。我們全面的分析為自主系統的道德設計提供了重要的見解，並強調了在人工智能道德決策中考慮文化背景的重要性。

##### **ScaleKD: Strong Vision Transformers Could Be Excellent Teachers**
2411.06786v1 by Jiawei Fan, Chao Li, Xiaolong Liu, Anbang Yao

In this paper, we question if well pre-trained vision transformer (ViT)
models could be used as teachers that exhibit scalable properties to advance
cross architecture knowledge distillation (KD) research, in the context of
using large-scale datasets for evaluation. To make this possible, our analysis
underlines the importance of seeking effective strategies to align (1) feature
computing paradigm differences, (2) model scale differences, and (3) knowledge
density differences. By combining three coupled components namely cross
attention projector, dual-view feature mimicking and teacher parameter
perception tailored to address the above problems, we present a simple and
effective KD method, called ScaleKD. Our method can train student backbones
that span across a variety of convolutional neural network (CNN), multi-layer
perceptron (MLP), and ViT architectures on image classification datasets,
achieving state-of-the-art distillation performance. For instance, taking a
well pre-trained Swin-L as the teacher model, our method gets
75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for
MobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16
models trained on ImageNet-1K dataset from scratch, showing
3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the
individually trained counterparts. Intriguingly, when scaling up the size of
teacher models or their pre-training datasets, our method showcases the desired
scalable properties, bringing increasingly larger gains to student models. The
student backbones trained by our method transfer well on downstream MS-COCO and
ADE20K datasets. More importantly, our method could be used as a more efficient
alternative to the time-intensive pre-training paradigm for any target student
model if a strong pre-trained ViT is available, reducing the amount of viewed
training samples up to 195x.

摘要：<paragraph>在本文中，我们质疑经过良好预训练的视觉转换器 (ViT) 模型是否可用作教师，在评估中使用大规模数据集时，展示可扩展属性以推进跨架构知识蒸馏 (KD) 研究。为了实现这一目标，我们的分析强调了寻求有效策略以对齐 (1) 特征计算范例差异、(2) 模型规模差异和 (3) 知识密度差异的重要性。通过结合三个耦合组件，即跨注意力投影仪、双视图特征模拟和针对上述问题量身定制的教师参数感知，我们提出了一种简单有效的 KD 方法，称为 ScaleKD。我们的方法可以训练跨越各种卷积神经网络 (CNN)、多层感知器 (MLP) 和 ViT 架构的学生主干在图像分类数据集上，实现最先进的蒸馏性能。例如，以经过良好预训练的 Swin-L 作为教师模型，我们的方法获得了 75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% 的 top-1 准确率，用于在 ImageNet-1K 数据集上从头开始训练的 MobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16 模型，显示出 3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% 的绝对增益，高于单独训练的对应模型。有趣的是，当扩大教师模型或其预训练数据集的规模时，我们的方法展示了所需的可扩展属性，为学生模型带来了越来越大的收益。由我们的方法训练的学生主干很好地转移到下游 MS-COCO 和 ADE20K 数据集上。更重要的是，如果可以使用经过良好预训练的 ViT，我们的方法可以用作任何目标学生模型的时间密集型预训练范例的更有效替代方案，从而将查看的训练样本数量减少多达 195 倍。</paragraph>

##### **MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting**
2411.06781v1 by Thang Nguyen, Dung Nguyen, Kha Pham, Truyen Tran

Forecasting temporal processes such as virus spreading in epidemics often
requires more than just observed time-series data, especially at the beginning
of a wave when data is limited. Traditional methods employ mechanistic models
like the SIR family, which make strong assumptions about the underlying
spreading process, often represented as a small set of compact differential
equations. Data-driven methods such as deep neural networks make no such
assumptions and can capture the generative process in more detail, but fail in
long-term forecasting due to data limitations. We propose a new hybrid method
called MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the
limitations of these two major approaches. MP-PINN instils the spreading
mechanism into a neural network, enabling the mechanism to update in phases
over time, reflecting the dynamics of the epidemics due to policy
interventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves
superior performance over pure data-driven or model-driven approaches for both
short-term and long-term forecasting.

摘要：預測時間過程，例如流行病中的病毒傳播，通常需要的不僅僅是觀察到的時間序列資料，尤其是在資料有限的波浪開始時。傳統方法採用機械模型，例如 SIR 家族，對基礎傳播過程做出強有力的假設，通常表示為一組緊湊的微分方程式。資料驅動的方法，例如深度神經網路，沒有這樣的假設，並且可以更詳細地捕捉生成過程，但由於資料限制，長期預測會失敗。我們提出了一種新的混合方法，稱為 MP-PINN（多階段物理資訊神經網路），以克服這兩種主要方法的限制。MP-PINN 將傳播機制灌輸到神經網路中，使機制能夠隨著時間推移而分階段更新，反映由於政策干預而產生的流行病動態。對 COVID-19 波浪的實驗表明，MP-PINN 在短期和長期預測方面都優於純資料驅動或模型驅動的方法。

##### **A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts**
2411.06772v1 by Liu Zhuoxian, Shi Tuo, Hu Xiaofeng

Front-line police officers often categorize all police call reported cases of
Telecom Fraud into 14 subcategories to facilitate targeted prevention measures,
such as precise public education. However, the associated data is characterized
by its large volume, diverse information content, and variations in expression.
Currently, there is a lack of efficient and accurate intelligent models to
replace manual classification, which, while precise, is relatively inefficient.
To address these challenges, this paper proposes a text classification model
that combines adversarial training with Pre-trained Language Model and neural
networks. The Linguistically-motivated Pre-trained Language Model model
extracts three types of language features and then utilizes the Fast Gradient
Method algorithm to perturb the generated embedding layer. Subsequently, the
Bi-directional Long Short-Term Memory and Convolutional Neural Networks
networks extract contextual syntactic information and local semantic
information, respectively. The model achieved an 83.9% classification accuracy
when trained on a portion of telecom fraud case data provided by the
operational department. The model established in this paper has been deployed
in the operational department, freeing up a significant amount of manpower and
improving the department's efficiency in combating Telecom Fraud crimes.
Furthermore, considering the universality of the model established in this
paper, other application scenarios await further exploration.

摘要：第一線的警察人員通常會將所有警方通報的電信詐騙案件分類成 14 個子類別，以利後續採取有針對性的預防措施，例如精準的宣導教育。然而，相關資料的特點是資料量龐大、資訊內容多元、表達方式變化多端。目前，缺乏有效且準確的智慧化模型可以取代人工分類，雖然人工分類準確，但相對沒有效率。為了應對這些挑戰，本篇論文提出一個文字分類模型，將對抗訓練與預訓練語言模型與神經網路結合。以語言學為基礎的預訓練語言模型會萃取出三種類型的語言特徵，然後利用快速梯度法演算法擾動產生的嵌入層。接著，雙向長短期記憶與卷積神經網路分別萃取出脈絡語法資訊與局部語意資訊。此模型在營運部門提供的電信詐騙案件資料部分訓練資料上，分類準確率達到 83.9%。本篇論文建立的模型已部署在營運部門，大幅節省人力，提升該部門打擊電信詐騙犯罪的效率。此外，考量本篇論文建立的模型具有普遍性，尚待進一步探索其他應用情境。

##### **PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing**
2411.06767v1 by Yiwen Duan, Yonghong Yu, Xiaoming Zhao, Yichang Wu, Wenbo Liu

Code Large Language Models (Code LLMs), such as Code llama and
DeepSeek-Coder, have demonstrated exceptional performance in the code
generation tasks. However, most existing models focus on the abilities of
generating correct code, but often struggle with bug repair. We introduce a
suit of methods to enhance LLM's SQL bug-fixing abilities. The methods are
mainly consisted of two parts: A Progressive Dataset Construction (PDC) from
scratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data
expansion methods from the perspectives of breadth first and depth first
respectively. DM-SFT introduces an efficient bug-fixing supervised learning
approach, which effectively reduce the total training steps and mitigate the
"disorientation" in SQL code bug-fixing training. In our evaluation, the code
LLM models trained with two methods have exceeds all current best performing
model which size is much larger.

摘要：大型語言模型 (Code LLM)，例如 Code llama 和 DeepSeek-Coder，已在程式碼生成任務中展現出非凡的效能。然而，現有的大多數模型都著重於產生正確程式碼的能力，但經常難以修復錯誤。我們提出了一套方法來增強 LLM 的 SQL 錯誤修復能力。這些方法主要包含兩個部分：從頭開始的漸進式資料集建構 (PDC) 和動態遮罩監督微調 (DM-SFT)。PDC 提出了兩種資料擴充方法，分別從廣度優先和深度優先的角度出發。DM-SFT 介紹了一種高效的錯誤修復監督學習方法，可有效減少總訓練步驟並減輕 SQL 程式碼錯誤修復訓練中的「迷失方向」問題。在我們的評估中，使用這兩種方法訓練的程式碼 LLM 模型超越了所有現有最佳效能模型，而這些模型的規模都大得多。

##### **KLCBL: An Improved Police Incident Classification Model**
2411.06749v1 by Liu Zhuoxian, Shi Tuo, Hu Xiaofeng

Police incident data is crucial for public security intelligence, yet
grassroots agencies struggle with efficient classification due to manual
inefficiency and automated system limitations, especially in telecom and online
fraud cases. This research proposes a multichannel neural network model, KLCBL,
integrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text
preprocessing approach (LERT), Convolutional Neural Network (CNN), and
Bidirectional Long Short-Term Memory (BiLSTM) for police incident
classification. Evaluated with real data, KLCBL achieved 91.9% accuracy,
outperforming baseline models. The model addresses classification challenges,
enhances police informatization, improves resource allocation, and offers broad
applicability to other classification tasks.

摘要：警務事件資料對於公共安全情報至關重要，但基層單位卻因人工處理效率低落及自動化系統限制而難以有效分類，特別是在電信和網路詐騙案件中。本研究提出一個多通道神經網路模型 KLCBL，整合 Kolmogorov-Arnold 網路 (KAN)、語言增強文字前處理方法 (LERT)、卷積神經網路 (CNN) 和雙向長短期記憶 (BiLSTM) 進行警務事件分類。經由實際資料評估，KLCBL 達到 91.9% 的準確度，優於基準模型。該模型解決了分類挑戰，增強警務資訊化，改善資源配置，並可廣泛應用於其他分類任務。

##### **Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening**
2411.06740v1 by Zhangfan Yang, Junkai Ji, Shan He, Jianqiang Li, Ruibin Bai, Zexuan Zhu, Yew Soon Ong

Molecular docking enables virtual screening of compound libraries to identify
potential ligands that target proteins of interest, a crucial step in drug
development; however, as the size of the compound library increases, the
computational complexity of traditional docking models increases. Deep learning
algorithms can provide data-driven research and development models to increase
the speed of the docking process. Unfortunately, few models can achieve
superior screening performance compared to that of traditional models.
Therefore, a novel deep learning-based docking approach named Dockformer is
introduced in this study. Dockformer leverages multimodal information to
capture the geometric topology and structural knowledge of molecules and can
directly generate binding conformations with the corresponding confidence
measures in an end-to-end manner. The experimental results show that Dockformer
achieves success rates of 90.53\% and 82.71\% on the PDBbind core set and
PoseBusters benchmarks, respectively, and more than a 100-fold increase in the
inference process speed, outperforming almost all state-of-the-art docking
methods. In addition, the ability of Dockformer to identify the main protease
inhibitors of coronaviruses is demonstrated in a real-world virtual screening
scenario. Considering its high docking accuracy and screening efficiency,
Dockformer can be regarded as a powerful and robust tool in the field of drug
design.

摘要：分子對接可對化合物庫進行虛擬篩選，以識別目標蛋白質的潛在配體，這是藥物開發中至關重要的一步；然而，隨著化合物庫規模的增加，傳統對接模型的計算複雜度也隨之增加。深度學習演算法可以提供資料驅動的研究和開發模型，以提高對接過程的速度。遺憾的是，很少有模型能達到優於傳統模型的篩選效能。因此，本研究中引入了名為 Dockformer 的新型基於深度學習的對接方法。Dockformer 採用多模態資訊來擷取分子的幾何拓撲和結構知識，並能以端到端的方式直接產生具有相應置信度測量的結合構象。實驗結果表明，Dockformer 在 PDBbind core set 和 PoseBusters 基準測試中分別達到了 90.53% 和 82.71% 的成功率，並且推理過程速度提升了 100 倍以上，優於幾乎所有最先進的對接方法。此外，在現實世界的虛擬篩選場景中，證明了 Dockformer 識別冠狀病毒主要蛋白酶抑制劑的能力。考慮到其對接精準度和篩選效率，Dockformer 可被視為藥物設計領域中一種強大且穩健的工具。

##### **Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data**
2411.06735v1 by Kai Kim, Howard Tsai, Rajat Sen, Abhimanyu Das, Zihao Zhou, Abhishek Tanpure, Mathew Luo, Rose Yu

Current forecasting approaches are largely unimodal and ignore the rich
textual data that often accompany the time series due to lack of well-curated
multimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a
carefully curated, time-aligned text and time dataset for multimodal
forecasting. Our dataset is composed of sequences of numbers and text aligned
to timestamps, and includes data from two different domains: climate science
and healthcare. Our data is a significant contribution to the rare selection of
available multimodal datasets. We also propose the Hybrid Multi-Modal
Forecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and
time series data using shared embeddings. However, contrary to our
expectations, our Hybrid-MMF model does not outperform existing baselines in
our experiments. This negative result highlights the challenges inherent in
multimodal forecasting. Our code and data are available at
https://github.com/Rose-STL-Lab/Multimodal_ Forecasting.

摘要：目前，預測方法大多是單模態的，且由於缺乏經過精心策劃的多模態基準資料集，因此會忽略經常伴隨時間序列的豐富文字資料。在這項工作中，我們開發了 TimeText Corpus (TTC)，一個經過精心策劃、時間對齊的文字和時間資料集，用於多模態預測。我們的資料集由與時間戳對齊的數字和文字序列組成，並包含來自兩個不同領域的資料：氣候科學和醫療保健。我們的資料對可用的多模態資料集的稀有選擇做出了重大貢獻。我們還提出了混合多模態預測器 (Hybrid-MMF)，這是一個多模態 LLM，使用共享嵌入同時預測文字和時間序列資料。然而，與我們的預期相反，我們的 Hybrid-MMF 模型在我們的實驗中並沒有優於現有的基線。這個負面結果突顯了多模態預測中固有的挑戰。我們的程式碼和資料可在 https://github.com/Rose-STL-Lab/Multimodal_ Forecasting 中取得。

##### **Reverse Prompt Engineering**
2411.06729v1 by Hanqing Li, Diego Klabjan

This paper explores a new black-box, zero-shot language model inversion
problem and proposes an innovative framework for prompt reconstruction using
only text outputs from a language model. Leveraging a large language model
alongside an optimization algorithm, the proposed method effectively recovers
prompts with minimal resources. Experimental results on several datasets
derived from public sources indicate that the proposed approach achieves
high-quality prompt recovery and generates prompts more similar to the
originals than current state-of-the-art methods. Additionally, the use-case
study demonstrates the method's strong potential for generating high-quality
text data.

摘要：本文探討了一個新的黑盒、零次學習語言模型反轉問題，並提出了一個創新的框架，使用語言模型的文字輸出重建提示。所提出的方法利用大型語言模型和最佳化演算法，有效地以最少資源復原提示。從公開來源衍生的幾個資料集上的實驗結果表明，所提出的方法可達成高品質的提示復原，並產生比目前最先進的方法更類似原始提示的提示。此外，使用案例研究證明了該方法在產生高品質文字資料方面的強大潛力。

##### **Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy**
2411.06723v1 by Xin Sun, Jan de Wit, Zhuying Li, Jiahuan Pei, Abdallah El Ali, Jos A. Bosch

Chatbots or conversational agents (CAs) are increasingly used to improve
access to digital psychotherapy. Many current systems rely on rigid, rule-based
designs, heavily dependent on expert-crafted dialogue scripts for guiding
therapeutic conversations. Although recent advances in large language models
(LLMs) offer the potential for more flexible interactions, their lack of
controllability and transparency poses significant challenges in sensitive
areas like psychotherapy. In this work, we explored how aligning LLMs with
expert-crafted scripts can enhance psychotherapeutic chatbot performance. Our
comparative study showed that LLMs aligned with expert-crafted scripts through
prompting and fine-tuning significantly outperformed both pure LLMs and
rule-based chatbots, achieving a more effective balance between dialogue
flexibility and adherence to therapeutic principles. Building on findings, we
proposed ``Script-Strategy Aligned Generation (SSAG)'', a flexible alignment
approach that reduces reliance on fully scripted content while enhancing LLMs'
therapeutic adherence and controllability. In a 10-day field study, SSAG
demonstrated performance comparable to full script alignment and outperformed
rule-based chatbots, empirically supporting SSAG as an efficient approach for
aligning LLMs with domain expertise. Our work advances LLM applications in
psychotherapy by providing a controllable, adaptable, and scalable solution for
digital interventions, reducing reliance on expert effort. It also provides a
collaborative framework for domain experts and developers to efficiently build
expertise-aligned chatbots, broadening access to psychotherapy and behavioral
interventions.

摘要：聊天機器人或對話代理（CA）正日益被用於改善對數位心理治療的存取。許多現有系統依賴於僵硬且基於規則的設計，嚴重依賴專家精心製作的對話腳本以引導治療對話。儘管大型語言模型（LLM）的最新進展提供了更靈活互動的可能性，但它們缺乏可控性和透明度，在心理治療等敏感領域構成了重大挑戰。在這項工作中，我們探討了如何將 LLM 與專家精心製作的腳本相結合，以增強心理治療聊天機器人的效能。我們的比較研究表明，透過提示和微調與專家精心製作的腳本相結合的 LLM，明顯優於純 LLM 和基於規則的聊天機器人，在對話靈活性與對治療原則的遵守之間取得更有效的平衡。根據研究結果，我們提出了「腳本策略對齊生成（SSAG）」——一種靈活的對齊方法，它減少對完全腳本化內容的依賴，同時增強 LLM 的治療依從性和可控性。在為期 10 天的實地研究中，SSAG 表現出與完全腳本對齊相當的效能，並且優於基於規則的聊天機器人，實證地支持 SSAG 作為一種將 LLM 與領域專業知識對齊的有效方法。我們的研究透過提供一種可控、可適應且可擴充的數位介入解決方案，推動了 LLM 在心理治療中的應用，減少對專家工作的依賴。它還為領域專家和開發人員提供了一個協作框架，以便有效地建構與專業知識相符的聊天機器人，擴大對心理治療和行為介入的存取。

##### **Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models**
2411.06722v1 by Yeming Wen, Swarat Chaudhuri

Presenting users with diverse responses from foundation models is crucial for
enhancing user experience and accommodating varying preferences. However,
generating multiple high-quality and diverse responses without sacrificing
accuracy remains a challenge, especially when using greedy sampling. In this
work, we propose a novel framework, Synthesize-Partition-Adapt (SPA), that
leverages the abundant synthetic data available in many domains to elicit
diverse responses from foundation models. By leveraging signal provided by data
attribution methods such as influence functions, SPA partitions data into
subsets, each targeting unique aspects of the data, and trains multiple model
adaptations optimized for these subsets. Experimental results demonstrate the
effectiveness of our approach in diversifying foundation model responses while
maintaining high quality, showcased through the HumanEval and MBPP tasks in the
code generation domain and several tasks in the natural language understanding
domain, highlighting its potential to enrich user experience across various
applications.

摘要：為使用者提供基礎模型的多元回應，對於提升使用者體驗和適應不同的偏好至關重要。然而，在不犧牲準確性的情況下產生多個高品質且多元的回應仍然是一項挑戰，特別是在使用貪婪採樣時。在這項工作中，我們提出了一個新的框架，稱為合成-分割-適應 (SPA)，它利用許多領域中豐富的合成資料，從基礎模型中引出多樣化的回應。透過利用資料歸因方法（例如影響函數）提供的訊號，SPA 將資料分割為子集，每個子集針對資料的不同面向，並訓練多個針對這些子集最佳化的模型適應。實驗結果證明了我們的方法在使基礎模型回應多樣化方面的有效性，同時保持高品質，這透過程式碼生成領域中的人類評估和 MBPP 任務以及自然語言理解領域中的幾個任務展示出來，突顯了它在各種應用中豐富使用者體驗的潛力。

##### **DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations**
2411.06714v1 by Xuming He, Zhiwang Zhou, Wenlong Zhang, Xiangyu Zhao, Hao Chen, Shiqi Chen, Lei Bai

Weather radar data synthesis can fill in data for areas where ground
observations are missing. Existing methods often employ reconstruction-based
approaches with MSE loss to reconstruct radar data from satellite observation.
However, such methods lead to over-smoothing, which hinders the generation of
high-frequency details or high-value observation areas associated with
convective weather. To address this issue, we propose a two-stage
diffusion-based method called DiffSR. We first pre-train a reconstruction model
on global-scale data to obtain radar estimation and then synthesize radar
reflectivity by combining radar estimation results with satellite data as
conditions for the diffusion model. Extensive experiments show that our method
achieves state-of-the-art (SOTA) results, demonstrating the ability to generate
high-frequency details and high-value areas.

摘要：利用天氣雷達資料合成可以填補地面觀測資料缺失區域的資料。現有的方法通常使用基於重建的 MSE 損失方法，從衛星觀測資料重建雷達資料。然而，這種方法會導致過度平滑，阻礙生成對流天氣相關的高頻細節或高值觀測區域。為了解決這個問題，我們提出了一種稱為 DiffSR 的兩階段基於擴散的方法。我們首先在全球尺度的資料上預訓練一個重建模型，以獲得雷達估計，然後通過將雷達估計結果與衛星資料結合作為擴散模型的條件，來合成雷達反射率。大量的實驗表明，我們的模型達到了最先進 (SOTA) 的結果，證明了生成高頻細節和高值區域的能力。

##### **Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**
2411.06713v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned
for medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and
Llama-3.2-3B) in clinical documentation. We analyzed de-identified patient
transcripts from partner clinics, using clinician-provided SOAP notes as the
ground truth. Each model generated SOAP summaries using zero-shot prompting,
with performance assessed via recall, precision, and F1 scores. Sporo
outperformed all models, achieving the highest recall (73.3%), precision
(78.6%), and F1 score (75.3%) with the lowest performance variance.
Statistically significant differences (p < 0.05) were found between Sporo and
the other models, with post-hoc tests showing significant improvements over
GPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to
10%, the difference was not statistically significant (p = 0.25). Clinical user
satisfaction, measured with a modified PDQI-9 inventory, favored Sporo.
Evaluations indicated Sporo's outputs were more accurate and relevant. This
highlights the potential of Sporo's multi-agentic architecture to improve
clinical workflows.

摘要：本研究比较了 Sporo Health 的 AI Scribe，一种针对医疗记录专门微调的专有模型，与临床记录中的各种 LLM（GPT-4o、GPT-3.5、Gemma-9B 和 Llama-3.2-3B）。我们分析了来自合作诊所的去标识患者记录，使用临床医生提供的 SOAP 记录作为基本事实。每个模型使用零次提示生成了 SOAP 摘要，通过召回率、精确率和 F1 分数评估性能。Sporo 优于所有模型，以最低的性能差异实现了最高的召回率 (73.3%)、精确率 (78.6%) 和 F1 分数 (75.3%)。在 Sporo 和其他模型之间发现了统计学上的显着差异 (p < 0.05)，事后检验显示与 GPT-3.5、Gemma-9B 和 Llama 3.2-3B 相比有显着改善。虽然 Sporo 的表现优于 GPT-4o 达 10%，但差异在统计学上并不显着 (p = 0.25)。使用修改后的 PDQI-9 清单衡量的临床用户满意度偏好 Sporo。评估表明 Sporo 的输出更准确、更相关。这突出了 Sporo 的多代理架构在改进临床工作流程方面的潜力。

##### **Model Fusion through Bayesian Optimization in Language Model Fine-Tuning**
2411.06710v1 by Chaeyun Jang, Hyungi Lee, Jungtaek Kim, Juho Lee

Fine-tuning pre-trained models for downstream tasks is a widely adopted
technique known for its adaptability and reliability across various domains.
Despite its conceptual simplicity, fine-tuning entails several troublesome
engineering choices, such as selecting hyperparameters and determining
checkpoints from an optimization trajectory. To tackle the difficulty of
choosing the best model, one effective solution is model fusion, which combines
multiple models in a parameter space. However, we observe a large discrepancy
between loss and metric landscapes during the fine-tuning of pre-trained
language models. Building on this observation, we introduce a novel model
fusion technique that optimizes both the desired metric and loss through
multi-objective Bayesian optimization. In addition, to effectively select
hyperparameters, we establish a two-stage procedure by integrating Bayesian
optimization processes into our framework. Experiments across various
downstream tasks show considerable performance improvements using our Bayesian
optimization-guided method.

摘要：微調預訓練模型以進行下游任務是一種廣泛採用的技術，以其在各種領域的適應性和可靠性而聞名。儘管其概念簡單，但微調需要進行多項繁瑣的工程選擇，例如選擇超參數和確定優化軌跡中的檢查點。為了解決選擇最佳模型的難題，一種有效的解決方案是模型融合，它在參數空間中結合了多個模型。然而，我們在預訓練語言模型的微調過程中觀察到損失和指標景觀之間存在很大差異。基於這一觀察，我們引入了一種新穎的模型融合技術，通過多目標貝葉斯優化來優化所需的指標和損失。此外，為了有效地選擇超參數，我們通過將貝葉斯優化流程整合到我們的框架中來建立一個兩階段程序。在各種下游任務中的實驗表明，使用我們的貝葉斯優化指導方法顯著提高了性能。

##### **Autonomous Droplet Microfluidic Design Framework with Large Language Models**
2411.06691v1 by Dinh-Nguyen Nguyen, Raymond Kai-Yu Tong, Ngoc-Duy Dinh

Droplet-based microfluidic devices have substantial promise as cost-effective
alternatives to current assessment tools in biological research. Moreover,
machine learning models that leverage tabular data, including input design
parameters and their corresponding efficiency outputs, are increasingly
utilised to automate the design process of these devices and to predict their
performance. However, these models fail to fully leverage the data presented in
the tables, neglecting crucial contextual information, including column
headings and their associated descriptions. This study presents
MicroFluidic-LLMs, a framework designed for processing and feature extraction,
which effectively captures contextual information from tabular data formats.
MicroFluidic-LLMs overcomes processing challenges by transforming the content
into a linguistic format and leveraging pre-trained large language models
(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11
prediction tasks, covering aspects such as geometry, flow conditions, regimes,
and performance, utilising a publicly available dataset on flow-focusing
droplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can
empower deep neural network models to be highly effective and straightforward
while minimising the need for extensive data preprocessing. Moreover, the
exceptional performance of deep neural network models, particularly when
combined with advanced natural language processing models such as DistilBERT
and GPT-2, reduces the mean absolute error in the droplet diameter and
generation rate by nearly 5- and 7-fold, respectively, and enhances the regime
classification accuracy by over 4%, compared with the performance reported in a
previous study. This study lays the foundation for the huge potential
applications of LLMs and machine learning in a wider spectrum of microfluidic
applications.

摘要：<paragraph>基於液滴的微流體裝置有望成為生物研究中經濟有效的替代方案，可取代現有的評估工具。此外，利用表格數據（包括輸入設計參數及其對應的效率輸出）的機器學習模型正日益用於自動化這些裝置的設計流程，並預測其性能。然而，這些模型未能充分利用表格中呈現的數據，忽視了關鍵的上下文信息，包括欄位標題及其相關描述。本研究提出了 MicroFluidic-LLMs，這是一個專門用於處理和特徵提取的框架，可有效擷取表格數據格式中的上下文信息。MicroFluidic-LLMs 通過將內容轉換為語言格式，並利用預先訓練的大語言模型 (LLM) 進行分析，克服了處理挑戰。我們在 11 項預測任務上評估了我們的 MicroFluidic-LLMs 框架，涵蓋幾何形狀、流動條件、機制和性能等方面，並利用了公開的流動聚焦液滴微流體數據集。我們證明了我們的 MicroFluidic-LLMs 框架可以讓深度神經網路模型高效且直接，同時最大限度地減少對大量數據預處理的需求。此外，深度神經網路模型的出色性能，特別是與 DistilBERT 和 GPT-2 等先進的自然語言處理模型結合使用時，將液滴直徑和生成率的平均絕對誤差分別降低了近 5 倍和 7 倍，並將機制分類準確度提高了 4% 以上，與先前研究報告的性能相比。本研究為 LLM 和機器學習在更廣泛的微流體應用中的巨大潛在應用奠定了基礎。</paragraph>

##### **WDMoE: Wireless Distributed Mixture of Experts for Large Language Models**
2411.06681v1 by Nan Xue, Yaping Sun, Zhiyong Chen, Meixia Tao, Xiaodong Xu, Liang Qian, Shuguang Cui, Wenjun Zhang, Ping Zhang

Large Language Models (LLMs) have achieved significant success in various
natural language processing tasks, but the role of wireless networks in
supporting LLMs has not been thoroughly explored. In this paper, we propose a
wireless distributed Mixture of Experts (WDMoE) architecture to enable
collaborative deployment of LLMs across edge servers at the base station (BS)
and mobile devices in wireless networks. Specifically, we decompose the MoE
layer in LLMs by placing the gating network and the preceding neural network
layer at BS, while distributing the expert networks among the devices. This
deployment leverages the parallel inference capabilities of expert networks on
mobile devices, effectively utilizing the limited computing and caching
resources of these devices. Accordingly, we develop a performance metric for
WDMoE-based LLMs, which accounts for both model capability and latency. To
minimize the latency while maintaining accuracy, we jointly optimize expert
selection and bandwidth allocation based on the performance metric. Moreover,
we build a hardware testbed using NVIDIA Jetson kits to validate the
effectiveness of WDMoE. Both theoretical simulations and practical hardware
experiments demonstrate that the proposed method can significantly reduce the
latency without compromising LLM performance.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中取得顯著成功，但無線網路在支援 LLM 中的角色尚未被徹底探討。在本文中，我們提出了一種無線分散式專家混合 (WDMoE) 架構，以在基地台 (BS) 的邊緣伺服器和無線網路中的行動裝置上實現 LLM 的協作部署。具體來說，我們透過將閘控網路和前置神經網路層置於 BS，同時將專家網路分佈在裝置中，來分解 LLM 中的 MoE 層。此部署利用了行動裝置上專家網路的並行推論能力，有效地利用了這些裝置有限的運算和快取資源。因此，我們開發了一個基於 WDMoE 的 LLM 效能指標，它同時考量了模型能力和延遲。為了在維持精準度的同時將延遲降至最低，我們根據效能指標共同最佳化專家選擇和頻寬配置。此外，我們使用 NVIDIA Jetson 套件建構硬體測試平台，以驗證 WDMoE 的效能。理論模擬和實際硬體實驗都證明，所提出的方法可以在不影響 LLM 效能的情況下，顯著降低延遲。

##### **What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance**
2411.06672v1 by Hong Meng Yam, Nathan J Paek

We explore the impact of pre-training data composition on the performance of
small language models in a sample-efficient setting. Using datasets limited to
10 million words, we evaluate several dataset sources, including child-directed
speech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and
a mix of these (Mix) across different model sizes ranging from 18 million to
705 million parameters. Our experiments show that smaller models (e.g.,
GPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex
and rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories
datasets underperformed across all model sizes. These findings suggest that the
optimal dataset for sample efficient training depends on the model size, and
that neither child-directed speech nor simplified stories are optimal for
language models of all sizes. We highlight the importance of considering both
dataset composition and model capacity for effective sample efficient language
model training.

摘要：我們探討預訓練資料組成對小型語言模型在樣本效率設定下的效能影響。使用限制在 1 千萬個單字的資料集，我們評估了幾個資料集來源，包括兒童導向語言 (CHILDES)、經典書籍 (Gutenberg)、合成資料 (TinyStories) 以及這些資料的混合 (Mix)，涵蓋從 1800 萬到 7.05 億個參數的不同模型大小。我們的實驗顯示，較小的模型 (例如 GPT2-97M、GPT2-705M、Llama-360M) 在針對更複雜且豐富的資料集（例如 Gutenberg）進行訓練時表現較佳。在 CHILDES 和 TinyStories 資料集上訓練的模型在所有模型大小中表現不佳。這些發現表明，樣本效率訓練的最佳資料集取決於模型大小，並且兒童導向語言或簡化故事都不是所有大小語言模型的最佳選擇。我們強調考慮資料集組成和模型容量對於有效的樣本效率語言模型訓練的重要性。

##### **Adversarial Detection with a Dynamically Stable System**
2411.06666v1 by Xiaowei Long, Jie Lin, Xiangyuan Yang

Adversarial detection is designed to identify and reject maliciously crafted
adversarial examples(AEs) which are generated to disrupt the classification of
target models.
  Presently, various input transformation-based methods have been developed on
adversarial example detection, which typically rely on empirical experience and
lead to unreliability against new attacks.
  To address this issue, we propose and conduct a Dynamically Stable System
(DSS), which can effectively detect the adversarial examples from normal
examples according to the stability of input examples.
  Particularly, in our paper, the generation of adversarial examples is
considered as the perturbation process of a Lyapunov dynamic system, and we
propose an example stability mechanism, in which a novel control term is added
in adversarial example generation to ensure that the normal examples can
achieve dynamic stability while the adversarial examples cannot achieve the
stability.
  Then, based on the proposed example stability mechanism, a Dynamically Stable
System (DSS) is proposed, which can utilize the disruption and restoration
actions to determine the stability of input examples and detect the adversarial
examples through changes in the stability of the input examples.
  In comparison with existing methods in three benchmark datasets(MNIST,
CIFAR10, and CIFAR100), our evaluation results show that our proposed DSS can
achieve ROC-AUC values of 99.83%, 97.81% and 94.47%, surpassing the
state-of-the-art(SOTA) values of 97.35%, 91.10% and 93.49% in the other 7
methods.

摘要：對抗性偵測旨在識別和拒絕惡意製作的對抗性範例 (AE)，這些範例會產生以擾亂目標模型分類。
目前，已針對對抗性範例偵測開發了各種基於輸入轉換的方法，這些方法通常依賴於經驗經驗，且無法對抗新的攻擊。
為了解決此問題，我們提出並進行動態穩定系統 (DSS)，可根據輸入範例的穩定性有效偵測出正常範例中的對抗性範例。
特別是在我們的論文中，對抗性範例的產生被視為李亞普諾夫動態系統的擾動過程，我們提出了一個範例穩定機制，在其中於對抗性範例產生中加入一個新穎的控制項，以確保正常範例可以達到動態穩定，而對抗性範例則無法達到穩定。
然後，根據所提出的範例穩定機制，提出了一個動態穩定系統 (DSS)，它可以利用擾動和復原動作來確定輸入範例的穩定性，並透過輸入範例穩定性的變化來偵測對抗性範例。
與三個基準資料集 (MNIST、CIFAR10 和 CIFAR100) 中現有方法相比，我們的評估結果顯示，我們提出的 DSS 可以達到 99.83%、97.81% 和 94.47% 的 ROC-AUC 值，超越其他 7 種方法的 97.35%、91.10% 和 93.49% 的最先進 (SOTA) 值。

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

摘要：知識圖譜補全 (KGC) 是一項根據現有知識圖譜 (KG) 推論遺失三元組的任務。結構和語義資訊對於成功的 KGC 至關重要。然而，現有方法僅使用來自 KG 嵌入的結構知識或來自預訓練語言模型 (PLM) 的語義資訊，導致模型效能不佳。此外，由於 PLM 沒有在 KG 上訓練，因此直接使用 PLM 編碼三元組可能並不適當。為了克服這些限制，我們提出一個名為 Bridge 的新架構，該架構聯合編碼 KG 的結構和語義資訊。具體來說，我們透過 PLM 分別對實體和關係進行策略性編碼，以更好地利用 PLM 的語義知識，並透過結構學習原則啟用結構化表示學習。此外，為了彌合 KG 和 PLM 之間的差距，我們採用一種稱為 BYOL 的自監督表示學習方法，以三元組的兩個不同視圖微調 PLM。與 BYOL 不同，BYOL 使用擴充方法來建立兩個語義上相似的相同影像視圖，可能會改變語義資訊。我們策略性地將三元組分為兩部分以建立不同的視圖，從而避免語義改變。實驗證明 Bridge 在三個基準資料集上優於 SOTA 模型。

##### **An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning**
2411.06659v1 by Dong Li, Aijia Zhang, Junqi Gao, Biqing Qi

Incremental graph learning has gained significant attention for its ability
to address the catastrophic forgetting problem in graph representation
learning. However, traditional methods often rely on a large number of labels
for node classification, which is impractical in real-world applications. This
makes few-shot incremental learning on graphs a pressing need. Current methods
typically require extensive training samples from meta-learning to build memory
and perform intensive fine-tuning of GNN parameters, leading to high memory
consumption and potential loss of previously learned knowledge. To tackle these
challenges, we introduce Mecoin, an efficient method for building and
maintaining memory. Mecoin employs Structured Memory Units to cache prototypes
of learned categories, as well as Memory Construction Modules to update these
prototypes for new categories through interactions between the nodes and the
cached prototypes. Additionally, we have designed a Memory Representation
Adaptation Module to store probabilities associated with each class prototype,
reducing the need for parameter fine-tuning and lowering the forgetting rate.
When a sample matches its corresponding class prototype, the relevant
probabilities are retrieved from the MRaM. Knowledge is then distilled back
into the GNN through a Graph Knowledge Distillation Module, preserving the
model's memory. We analyze the effectiveness of Mecoin in terms of
generalization error and explore the impact of different distillation
strategies on model performance through experiments and VC-dimension analysis.
Compared to other related works, Mecoin shows superior performance in accuracy
and forgetting rate. Our code is publicly available on the
https://github.com/Arvin0313/Mecoin-GFSCIL.git .

摘要：增量圖形學習因其解決圖形表徵學習中災難性遺忘問題的能力而備受關注。然而，傳統方法通常依賴大量標籤進行節點分類，這在實際應用中是不切實際的。這使得圖形上的小樣本增量學習成為迫切需求。目前的技術通常需要來自元學習的大量訓練樣本來建立記憶並對 GNN 參數進行密集的微調，從而導致高記憶體消耗和先前學習知識的潛在損失。為了應對這些挑戰，我們引入了 Mecoin，一種用於構建和維護記憶的有效方法。Mecoin 使用結構化記憶單元緩存學習類別的原型，以及記憶體建構模組透過節點和緩存原型之間的互動來更新這些新類別的原型。此外，我們設計了一個記憶體表徵適應模組來儲存與每個類別原型相關的機率，減少了對參數微調的需求並降低了遺忘率。當樣本與其對應的類別原型匹配時，相關機率會從 MRaM 中擷取。然後透過圖形知識蒸餾模組將知識蒸餾回 GNN，保留模型的記憶體。我們分析了 Mecoin 在泛化誤差方面的有效性，並透過實驗和 VC 維度分析探討了不同蒸餾策略對模型效能的影響。與其他相關工作相比，Mecoin 在準確度和遺忘率方面表現出優異的效能。我們的程式碼可以在 https://github.com/Arvin0313/Mecoin-GFSCIL.git 公開取得。

##### **Renaissance: Investigating the Pretraining of Vision-Language Encoders**
2411.06657v1 by Clayton Fields, Casey Kennington

In the past several years there has been an explosion of available models for
vision-language tasks. Unfortunately, the literature still leaves open a number
of questions related to best practices in designing and training such models.
In this paper we seek to answer several questions related to the pretraining of
vision-language encoders through meta-analysis. In our first set of
experiments, we show that we can save significant compute at no cost to
downstream performance, by freezing large parts of vision-language models
during pretraining. In our second set of experiments we examine the effect of
basing a VL transformer on a vision model versus a text model. Additionally, we
introduce a VL modeling platform called Renaissance that we use to conduct all
of the experiments. This program offers a great deal of flexibility in
creating, training and evaluating transformer encoders for VL modeling. The
source code for Renaissance can be found at
https://github.com/bsu-slim/renaissance.

摘要：過去幾年來，可用於視覺語言任務的模型出現了爆炸性的增長。不幸的是，文獻中仍有許多與設計和訓練此類模型的最佳實務相關的問題尚未解決。在本文中，我們尋求透過元分析來回答與視覺語言編碼器的預訓練相關的幾個問題。在我們的首組實驗中，我們表明，透過在預訓練期間凍結視覺語言模型的大部分，我們可以在不損害下游效能的情況下，節省大量的運算。在我們的第二組實驗中，我們檢驗了將 VL 轉換器建立在視覺模型與文字模型上的效果。此外，我們引入了稱為 Renaissance 的 VL 建模平台，我們使用該平台來進行所有實驗。此程式在建立、訓練和評估用於 VL 建模的轉換器編碼器方面提供了極大的靈活性。Renaissance 的原始程式碼可以在 https://github.com/bsu-slim/renaissance 找到。

##### **Explore the Reasoning Capability of LLMs in the Chess Testbed**
2411.06655v1 by Shu Wang, Lei Ji, Renxi Wang, Wenxiao Zhao, Haokun Liu, Yifan Hou, Ying Nian Wu

Reasoning is a central capability of human intelligence. In recent years,
with the advent of large-scale datasets, pretrained large language models have
emerged with new capabilities, including reasoning. However, these models still
struggle with long-term, complex reasoning tasks, such as playing chess. Based
on the observation that expert chess players employ a dual approach combining
long-term strategic play with short-term tactical play along with language
explanation, we propose improving the reasoning capability of large language
models in chess by integrating annotated strategy and tactic. Specifically, we
collect a dataset named MATE, which consists of 1 million chess positions with
candidate moves annotated by chess experts for strategy and tactics. We
finetune the LLaMA-3-8B model and compare it against state-of-the-art
commercial language models in the task of selecting better chess moves. Our
experiments show that our models perform better than GPT, Claude, and Gemini
models. We find that language explanations can enhance the reasoning capability
of large language models.

摘要：推理是人類智能的核心能力。近年來，隨著大規模數據集的出現，預訓練的大語言模型已經出現了新的能力，包括推理。然而，這些模型仍然難以應付長期、複雜的推理任務，例如下棋。基於專家棋手採用雙重方法的觀察，將長期戰略博弈與短期戰術博弈結合語言說明，我們提出通過整合註解策略和戰術來提高大語言模型在國際象棋中的推理能力。具體來說，我們收集了一個名為 MATE 的數據集，其中包含 100 萬個國際象棋位置，其中候選移動由國際象棋專家對策略和戰術進行了註釋。我們對 LLaMA-3-8B 模型進行了微調，並在選擇更好的國際象棋走法任務中將其與最先進的商業語言模型進行了比較。我們的實驗表明，我們的模型比 GPT、Claude 和 Gemini 模型表現得更好。我們發現語言解釋可以增強大語言模型的推理能力。

##### **Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data**
2411.06646v1 by Alex Havrilla, Wenjing Liao

When training deep neural networks, a model's generalization error is often
observed to follow a power scaling law dependent both on the model size and the
data size. Perhaps the best known example of such scaling laws are for
transformer-based large language models, where networks with billions of
parameters are trained on trillions of tokens of text. Yet, despite sustained
widespread interest, a rigorous understanding of why transformer scaling laws
exist is still missing. To answer this question, we establish novel statistical
estimation and mathematical approximation theories for transformers when the
input data are concentrated on a low-dimensional manifold. Our theory predicts
a power law between the generalization error and both the training data size
and the network size for transformers, where the power depends on the intrinsic
dimension $d$ of the training data. Notably, the constructed model architecture
is shallow, requiring only logarithmic depth in $d$. By leveraging
low-dimensional data structures under a manifold hypothesis, we are able to
explain transformer scaling laws in a way which respects the data geometry.
Moreover, we test our theory with empirical observation by training LLMs on
natural language datasets. We find the observed empirical data scaling laws
closely agree with our theoretical predictions. Taken together, these results
rigorously show the intrinsic dimension of data to be a crucial quantity
affecting transformer scaling laws in both theory and practice.

摘要：在训练深度神经网络时，通常会观察到模型的泛化误差遵循一种幂次缩放定律，该定律同时取决于模型大小和数据大小。这种缩放定律最著名的例子可能是基于 Transformer 的大型语言模型，其中数十亿个参数的网络在数万亿个文本标记上进行训练。然而，尽管持续的广泛关注，但对于 Transformer 缩放定律为何存在，仍然缺乏严格的理解。为了回答这个问题，我们在输入数据集中于低维流形时，为 Transformer 建立了新颖的统计估计和数学逼近理论。我们的理论预测了泛化误差与训练数据大小和 Transformer 的网络大小之间的幂律，其中幂取决于训练数据的内在维数 $d$。值得注意的是，构建的模型架构是浅层的，只需要 $d$ 中的对数深度。通过利用流形假设下的低维数据结构，我们能够以尊重数据几何的方式来解释 Transformer 缩放定律。此外，我们通过在自然语言数据集上训练 LLM 来用经验观察检验我们的理论。我们发现观察到的经验数据缩放定律与我们的理论预测非常吻合。综上所述，这些结果严格地表明，数据的内在维数是影响理论和实践中 Transformer 缩放定律的关键量。

##### **Predicting Country Instability Using Bayesian Deep Learning and Random Forest**
2411.06639v1 by Adam Zebrowski, Haithem Afli

Country instability is a global issue, with unpredictably high levels of
instability thwarting socio-economic growth and possibly causing a slew of
negative consequences. As a result, uncertainty prediction models for a country
are becoming increasingly important in the real world, and they are expanding
to provide more input from 'big data' collections, as well as the
interconnectedness of global economies and social networks. This has culminated
in massive volumes of qualitative data from outlets like television, print,
digital, and social media, necessitating the use of artificial intelligence
(AI) tools like machine learning to make sense of it all and promote predictive
precision [1]. The Global Database of Activities, Voice, and Tone (GDELT
Project) records broadcast, print, and web news in over 100 languages every
second of every day, identifying the people, locations, organisations, counts,
themes, outlets, and events that propel our global community and offering a
free open platform for computation on the entire world. The main goal of our
research is to investigate how, when our data grows more voluminous and
fine-grained, we can conduct a more complex methodological analysis of
political conflict. The GDELT dataset, which was released in 2012, is the first
and potentially the most technologically sophisticated publicly accessible
dataset on political conflict.

摘要：國家不穩定是一個全球性的問題，不可預測的高不穩定性水平阻礙了社會經濟的發展，並可能導致一系列的負面後果。因此，對一個國家的不確定性預測模型在現實世界中變得越來越重要，並且它們正在擴展以提供來自「大數據」收集的更多輸入，以及全球經濟和社交網絡的相互聯繫。這在電視、印刷品、數位和社交媒體等媒體上產生了大量的定性數據，因此需要使用人工智慧 (AI) 工具，例如機器學習，來理解所有這些數據並促進預測精準度 [1]。全球活動、語音和語調資料庫 (GDELT 計畫) 每秒記錄超過 100 種語言的廣播、印刷和網路新聞，識別推動我們全球社群的人員、地點、組織、計數、主題、媒體和事件，並提供一個免費開放的平台，用於計算整個世界。我們研究的主要目標是調查當我們的數據變得更龐大且更精細時，我們如何對政治衝突進行更複雜的方法論分析。於 2012 年發布的 GDELT 資料集是第一個，也是潛在技術最先進的關於政治衝突的公開存取資料集。

##### **Model Editing for LLMs4Code: How Far are We?**
2411.06638v1 by Xiaopeng Li, Shangwen Wang, Shasha Li, Jun Ma, Jie Yu, Xiaodong Liu, Jing Wang, Bin Ji, Weimin Zhang

Large Language Models for Code (LLMs4Code) have been found to exhibit
outstanding performance in the software engineering domain, especially the
remarkable performance in coding tasks. However, even the most advanced
LLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to
the high cost of training LLMs4Code, it is impractical to re-train the models
for fixing these problematic code knowledge. Model editing is a new technical
field for effectively and efficiently correcting erroneous knowledge in LLMs,
where various model editing techniques and benchmarks have been proposed
recently. Despite that, a comprehensive study that thoroughly compares and
analyzes the performance of the state-of-the-art model editing techniques for
adapting the knowledge within LLMs4Code across various code-related tasks is
notably absent. To bridge this gap, we perform the first systematic study on
applying state-of-the-art model editing approaches to repair the inaccuracy of
LLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consists
of two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples and
CodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the help
of CLMEEval, we evaluate six advanced model editing techniques on three
LLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findings
include that the external memorization-based GRACE approach achieves the best
knowledge editing effectiveness and specificity (the editing does not influence
untargeted knowledge), while generalization (whether the editing can generalize
to other semantically-identical inputs) is a universal challenge for existing
techniques. Furthermore, building on in-depth case analysis, we introduce an
enhanced version of GRACE called A-GRACE, which incorporates contrastive
learning to better capture the semantics of the inputs.

摘要：<paragraph>大型語言模型代碼 (LLMs4Code) 已被發現可在軟體工程領域展現傑出的效能，特別是在編碼任務中表現出色。然而，即使是最先進的 LLMs4Code 也難免包含不正確或過時的程式碼知識。由於訓練 LLMs4Code 的成本很高，因此不切實際地重新訓練模型來修正這些有問題的程式碼知識。模型編輯是一個新的技術領域，用於有效且高效地修正大型語言模型中的錯誤知識，最近已提出各種模型編輯技術和基準。儘管如此，一個全面研究，徹底比較和分析最先進的模型編輯技術在各種與程式碼相關任務中調整 LLMs4Code 內部知識的效能，顯著地不存在。為了彌合這個差距，我們對應用最先進的模型編輯方法來修復 LLMs4Code 的不準確性進行了第一個系統性研究。為此，我們引入了一個名為 CLMEEval 的基準，它包含兩個資料集，即包含 21K+ 程式碼生成範例的 CoNaLa-Edit (CNLE) 和包含 16K+ 程式碼摘要範例的 CodeSearchNet-Edit (CSNE)。在 CLMEEval 的幫助下，我們評估了六種先進的模型編輯技術在三個 LLMs4Code 上的表現：CodeLlama (7B)、CodeQwen1.5 (7B) 和 Stable-Code (3B)。我們的發現包括基於外部記憶的 GRACE 方法實現了最佳的知識編輯效能和特異性（編輯不會影響未鎖定的知識），而泛化（編輯是否可以泛化到其他語義相同的輸入）是現有技術的普遍挑戰。此外，在深入案例分析的基礎上，我們引入了 GRACE 的增強版本，稱為 A-GRACE，它結合了對比學習以更好地捕捉輸入的語義。</paragraph>

##### **A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning**
2411.06624v1 by Caleb J. S. Barr, Olivia Erdelyi, Paul D. Docherty, Randolph C. Grace

Recent regulatory proposals for artificial intelligence emphasize fairness
requirements for machine learning models. However, precisely defining the
appropriate measure of fairness is challenging due to philosophical, cultural
and political contexts. Biases can infiltrate machine learning models in
complex ways depending on the model's context, rendering a single common metric
of fairness insufficient. This ambiguity highlights the need for criteria to
guide the selection of context-aware measures, an issue of increasing
importance given the proliferation of ever tighter regulatory requirements. To
address this, we developed a flowchart to guide the selection of contextually
appropriate fairness measures. Twelve criteria were used to formulate the
flowchart. This included consideration of model assessment criteria, model
selection criteria, and data bias. We also review fairness literature in the
context of machine learning and link it to core regulatory instruments to
assist policymakers, AI developers, researchers, and other stakeholders in
appropriately addressing fairness concerns and complying with relevant
regulatory requirements.

摘要：近期針對人工智慧的監管提案強調機器學習模型的公平性要求。然而，由於哲學、文化和政治脈絡，精確定義公平性的適當衡量標準是一項挑戰。偏見會以複雜的方式滲透到機器學習模型中，具體取決於模型的脈絡，導致單一的公平性通用指標不足。這種模稜兩可突顯了需要準則來引導情境感知指標的選擇，這是一個越來越重要的問題，因為監管要求越來越嚴格。為了解決這個問題，我們開發了一個流程圖來指導情境適當的公平性指標的選擇。十二個準則用於制定流程圖。這包括考量模型評估準則、模型選擇準則和資料偏誤。我們還回顧了機器學習中的公平性文獻，並將其連結到核心監管工具，以協助政策制定者、人工智慧開發人員、研究人員和其他利害關係人適當地解決公平性問題並遵守相關監管要求。

##### **MEANT: Multimodal Encoder for Antecedent Information**
2411.06616v1 by Benjamin Iyoya Irving, Annika Marie Schoene

The stock market provides a rich well of information that can be split across
modalities, making it an ideal candidate for multimodal evaluation. Multimodal
data plays an increasingly important role in the development of machine
learning and has shown to positively impact performance. But information can do
more than exist across modes -- it can exist across time. How should we attend
to temporal data that consists of multiple information types? This work
introduces (i) the MEANT model, a Multimodal Encoder for Antecedent information
and (ii) a new dataset called TempStock, which consists of price, Tweets, and
graphical data with over a million Tweets from all of the companies in the S&P
500 Index. We find that MEANT improves performance on existing baselines by
over 15%, and that the textual information affects performance far more than
the visual information on our time-dependent task from our ablation study.

摘要：股票市場提供了豐富的信息來源，可以跨模態分割，使其成為多模態評估的理想候選者。多模態數據在機器學習的發展中扮演著越來越重要的角色，並已顯示出對性能的正面影響。但信息不僅可以跨模式存在，它也可以跨時間存在。我們應該如何關注包含多種信息類型的時間數據？這項工作引入了 (i) MEANT 模型，一種用於先行信息的多模態編碼器，以及 (ii) 一個名為 TempStock 的新數據集，其中包含來自標準普爾 500 指數中所有公司的價格、推文和圖形數據，推文數量超過一百萬條。我們發現 MEANT 將現有基準的性能提高了 15% 以上，並且在我們的消融研究中，文本信息對我們依時間而定的任務的影響遠大於視覺信息。

##### **vTune: Verifiable Fine-Tuning for LLMs Through Backdooring**
2411.06611v1 by Eva Zhang, Arka Pal, Akilesh Potti, Micah Goldblum

As fine-tuning large language models (LLMs) becomes increasingly prevalent,
users often rely on third-party services with limited visibility into their
fine-tuning processes. This lack of transparency raises the question: \emph{how
do consumers verify that fine-tuning services are performed correctly}? For
instance, a service provider could claim to fine-tune a model for each user,
yet simply send all users back the same base model. To address this issue, we
propose vTune, a simple method that uses a small number of \textit{backdoor}
data points added to the training data to provide a statistical test for
verifying that a provider fine-tuned a custom model on a particular user's
dataset. Unlike existing works, vTune is able to scale to verification of
fine-tuning on state-of-the-art LLMs, and can be used both with open-source and
closed-source models. We test our approach across several model families and
sizes as well as across multiple instruction-tuning datasets, and find that the
statistical test is satisfied with p-values on the order of $\sim 10^{-40}$,
with no negative impact on downstream task performance. Further, we explore
several attacks that attempt to subvert vTune and demonstrate the method's
robustness to these attacks.

摘要：随着对大型语言模型 (LLM) 的微调变得越来越普遍，
用户通常依赖于第三方服务，而这些服务对其微调过程的可见性有限。这种缺乏透明度引发了一个问题：\emph{消费者如何验证微调服务是否正确执行}？例如，服务提供商可以声称针对每个用户微调模型，但实际上只是向所有用户发送回相同的底层模型。为了解决这个问题，我们提出了 vTune，这是一种简单的方法，它使用添加到训练数据中的少量\textit{后门}数据点，以提供一个统计测试，用于验证提供商是否针对特定用户的训练数据集微调了自定义模型。与现有工作不同，vTune 能够扩展到对最先进的 LLM 进行微调验证，并且可以与开源和闭源模型一起使用。我们在多个模型系列和规模以及多个指令微调数据集上测试了我们的方法，发现统计测试满足 p 值约为 $\sim 10^{-40}$，对下游任务性能没有负面影响。此外，我们探索了几种试图破坏 vTune 的攻击，并证明了该方法对这些攻击的鲁棒性。

