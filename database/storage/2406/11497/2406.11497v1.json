{"2406.11497": {"publish_time": "2024-06-17", "title": "CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG", "paper_summary": "Retrieval-Augmented Generation (RAG) can alleviate hallucinations of Large\nLanguage Models (LLMs) by referencing external documents. However, the\nmisinformation in external documents may mislead LLMs' generation. To address\nthis issue, we explore the task of \"credibility-aware RAG\", in which LLMs\nautomatically adjust the influence of retrieved documents based on their\ncredibility scores to counteract misinformation. To this end, we introduce a\nplug-and-play method named $\\textbf{Cr}$edibility-aware $\\textbf{A}$ttention\n$\\textbf{M}$odification (CrAM). CrAM identifies influential attention heads in\nLLMs and adjusts their attention scores based on the credibility of the\ndocuments, thereby reducing the impact of low-credibility documents.\nExperiments on Natual Questions and TriviaQA using Llama2-13B, Llama3-8B, and\nQwen-7B show that CrAM improves the RAG performance of LLMs against\nmisinformation pollution by over 20%, even surpassing supervised fine-tuning\nmethods.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u80fd\u900f\u904e\u53c3\u7167\u5916\u90e8\u6587\u4ef6\u6e1b\u8f15\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5e7b\u89ba\u3002\u7136\u800c\uff0c\u5916\u90e8\u6587\u4ef6\u4e2d\u7684\u932f\u8aa4\u8cc7\u8a0a\u53ef\u80fd\u6703\u8aa4\u5c0e LLM \u7684\u751f\u6210\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u300c\u53ef\u4fe1\u5ea6\u611f\u77e5 RAG\u300d\u7684\u4efb\u52d9\uff0c\u5176\u4e2d LLM \u6703\u6839\u64da\u6aa2\u7d22\u6587\u4ef6\u7684\u53ef\u4fe1\u5ea6\u8a55\u5206\u81ea\u52d5\u8abf\u6574\u6aa2\u7d22\u6587\u4ef6\u7684\u5f71\u97ff\u529b\uff0c\u4ee5\u5c0d\u6297\u932f\u8aa4\u8cc7\u8a0a\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86\u7a31\u70ba $\\textbf{Cr}$edibility-aware $\\textbf{A}$ttention $\\textbf{M}$odification (CrAM) \u7684\u5373\u63d2\u5373\u7528\u65b9\u6cd5\u3002CrAM \u6703\u627e\u51fa LLM \u4e2d\u6709\u5f71\u97ff\u529b\u7684\u6ce8\u610f\u529b\u982d\u90e8\uff0c\u4e26\u6839\u64da\u6587\u4ef6\u7684\u53ef\u4fe1\u5ea6\u8abf\u6574\u5176\u6ce8\u610f\u529b\u8a55\u5206\uff0c\u5f9e\u800c\u964d\u4f4e\u4f4e\u53ef\u4fe1\u5ea6\u6587\u4ef6\u7684\u5f71\u97ff\u3002\u5728\u4f7f\u7528 Llama2-13B\u3001Llama3-8B \u548c Qwen-7B \u9032\u884c\u7684 Natual Questions \u548c TriviaQA \u5be6\u9a57\u4e2d\uff0c\u7d50\u679c\u986f\u793a CrAM \u5c07 LLM \u5728\u5c0d\u6297\u932f\u8aa4\u8cc7\u8a0a\u6c61\u67d3\u65b9\u9762\u7684 RAG \u6548\u80fd\u63d0\u5347\u4e86 20% \u4ee5\u4e0a\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u76e3\u7763\u5fae\u8abf\u65b9\u6cd5\u3002", "author": "Boyi Deng et.al.", "authors": "Boyi Deng, Wenjie Wang, Fengbin Zhu, Qifan Wang, Fuli Feng", "id": "2406.11497v1", "paper_url": "http://arxiv.org/abs/2406.11497v1", "repo": "null"}}