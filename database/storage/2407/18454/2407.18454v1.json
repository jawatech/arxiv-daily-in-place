{"2407.18454": {"publish_time": "2024-07-26", "title": "Fairness Definitions in Language Models Explained", "paper_summary": "Language Models (LMs) have demonstrated exceptional performance across\nvarious Natural Language Processing (NLP) tasks. Despite these advancements,\nLMs can inherit and amplify societal biases related to sensitive attributes\nsuch as gender and race, limiting their adoption in real-world applications.\nTherefore, fairness has been extensively explored in LMs, leading to the\nproposal of various fairness notions. However, the lack of clear agreement on\nwhich fairness definition to apply in specific contexts (\\textit{e.g.,}\nmedium-sized LMs versus large-sized LMs) and the complexity of understanding\nthe distinctions between these definitions can create confusion and impede\nfurther progress. To this end, this paper proposes a systematic survey that\nclarifies the definitions of fairness as they apply to LMs. Specifically, we\nbegin with a brief introduction to LMs and fairness in LMs, followed by a\ncomprehensive, up-to-date overview of existing fairness notions in LMs and the\nintroduction of a novel taxonomy that categorizes these concepts based on their\nfoundational principles and operational distinctions. We further illustrate\neach definition through experiments, showcasing their practical implications\nand outcomes. Finally, we discuss current research challenges and open\nquestions, aiming to foster innovative ideas and advance the field. The\nimplementation and additional resources are publicly available at\nhttps://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b (LM) \u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5091\u51fa\u7684\u8868\u73fe\u3002\u5118\u7ba1\u6709\u9019\u4e9b\u9032\u5c55\uff0cLM \u4ecd\u53ef\u80fd\u7e7c\u627f\u4e26\u653e\u5927\u8207\u654f\u611f\u5c6c\u6027\uff08\u4f8b\u5982\u6027\u5225\u548c\u7a2e\u65cf\uff09\u76f8\u95dc\u7684\u793e\u6703\u504f\u898b\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u771f\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u7684\u63a1\u7528\u3002\u56e0\u6b64\uff0c\u516c\u5e73\u6027\u5df2\u5728 LM \u4e2d\u5ee3\u6cdb\u63a2\u8a0e\uff0c\u4e26\u63d0\u51fa\u5404\u7a2e\u516c\u5e73\u6027\u6982\u5ff5\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u5728\u7279\u5b9a\u80cc\u666f\u4e0b\u5957\u7528\u54ea\u7a2e\u516c\u5e73\u6027\u5b9a\u7fa9\u7f3a\u4e4f\u660e\u78ba\u5171\u8b58\uff08\u4f8b\u5982\u4e2d\u578b LM \u8207\u5927\u578b LM\uff09\uff0c\u4ee5\u53ca\u7406\u89e3\u9019\u4e9b\u5b9a\u7fa9\u4e4b\u9593\u5dee\u7570\u7684\u8907\u96dc\u6027\u53ef\u80fd\u6703\u9020\u6210\u6df7\u6dc6\u4e26\u963b\u7919\u9032\u4e00\u6b65\u7684\u9032\u5c55\u3002\u70ba\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u9805\u7cfb\u7d71\u6027\u7684\u8abf\u67e5\uff0c\u4ee5\u91d0\u6e05\u516c\u5e73\u6027\u7684\u5b9a\u7fa9\uff0c\u56e0\u70ba\u5b83\u5011\u9069\u7528\u65bc LM\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f9e LM \u548c LM \u4e2d\u7684\u516c\u5e73\u6027\u7c21\u4ecb\u958b\u59cb\uff0c\u63a5\u8457\u5c0d LM \u4e2d\u73fe\u6709\u7684\u516c\u5e73\u6027\u6982\u5ff5\u9032\u884c\u5168\u9762\u3001\u6700\u65b0\u7684\u6982\u8ff0\uff0c\u4e26\u4ecb\u7d39\u4e00\u7a2e\u65b0\u7684\u5206\u985e\u6cd5\uff0c\u6839\u64da\u5b83\u5011\u7684\u57fa\u672c\u539f\u5247\u548c\u904b\u4f5c\u5340\u5225\u5c0d\u9019\u4e9b\u6982\u5ff5\u9032\u884c\u5206\u985e\u3002\u6211\u5011\u9032\u4e00\u6b65\u901a\u904e\u5be6\u9a57\u8aaa\u660e\u6bcf\u500b\u5b9a\u7fa9\uff0c\u5c55\u793a\u5b83\u5011\u7684\u5be6\u969b\u542b\u7fa9\u548c\u7d50\u679c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u7576\u524d\u7684\u7814\u7a76\u6311\u6230\u548c\u958b\u653e\u6027\u554f\u984c\uff0c\u65e8\u5728\u57f9\u990a\u5275\u65b0\u601d\u60f3\u4e26\u63a8\u52d5\u8a72\u9818\u57df\u7684\u9032\u6b65\u3002\u5be6\u4f5c\u548c\u984d\u5916\u8cc7\u6e90\u5df2\u516c\u958b\u65bc https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions\u3002</paragraph>", "author": "Thang Viet Doan et.al.", "authors": "Thang Viet Doan, Zhibo Chu, Zichong Wang, Wenbin Zhang", "id": "2407.18454v1", "paper_url": "http://arxiv.org/abs/2407.18454v1", "repo": "https://github.com/lavinwong/fairness-in-large-language-models"}}