{"2410.23219": {"publish_time": "2024-10-30", "title": "DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET", "paper_summary": "Diagnosing dementia, particularly for Alzheimer's Disease (AD) and\nfrontotemporal dementia (FTD), is complex due to overlapping symptoms. While\nmagnetic resonance imaging (MRI) and positron emission tomography (PET) data\nare critical for the diagnosis, integrating these modalities in deep learning\nfaces challenges, often resulting in suboptimal performance compared to using\nsingle modalities. Moreover, the potential of multi-modal approaches in\ndifferential diagnosis, which holds significant clinical importance, remains\nlargely unexplored. We propose a novel framework, DiaMond, to address these\nissues with vision Transformers to effectively integrate MRI and PET. DiaMond\nis equipped with self-attention and a novel bi-attention mechanism that\nsynergistically combine MRI and PET, alongside a multi-modal normalization to\nreduce redundant dependency, thereby boosting the performance. DiaMond\nsignificantly outperforms existing multi-modal methods across various datasets,\nachieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN\nclassification, and 76.5% in differential diagnosis of AD and FTD. We also\nvalidated the robustness of DiaMond in a comprehensive ablation study. The code\nis available at https://github.com/ai-med/DiaMond.", "paper_summary_zh": "\u8a3a\u65b7\u5931\u667a\u75c7\uff0c\u5c24\u5176\u662f\u963f\u8332\u6d77\u9ed8\u75c7 (AD) \u548c\u984d\u9873\u8449\u578b\u5931\u667a\u75c7 (FTD)\uff0c\u7531\u65bc\u75c7\u72c0\u91cd\u758a\uff0c\u56e0\u6b64\u5f88\u8907\u96dc\u3002\u96d6\u7136\u78c1\u5171\u632f\u9020\u5f71 (MRI) \u548c\u6b63\u5b50\u65b7\u5c64\u6383\u63cf (PET) \u6578\u64da\u5c0d\u65bc\u8a3a\u65b7\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u5c07\u9019\u4e9b\u65b9\u5f0f\u6574\u5408\u5230\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u6703\u9762\u81e8\u6311\u6230\uff0c\u901a\u5e38\u6703\u5c0e\u81f4\u8207\u4f7f\u7528\u55ae\u4e00\u65b9\u5f0f\u76f8\u6bd4\u6027\u80fd\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u591a\u6a21\u5f0f\u65b9\u6cd5\u5728\u9451\u5225\u8a3a\u65b7\u4e2d\u7684\u6f5b\u529b\u5177\u6709\u91cd\u8981\u7684\u81e8\u5e8a\u610f\u7fa9\uff0c\u4f46\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u6846\u67b6 DiaMond\uff0c\u4ee5\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u4f7f\u7528\u8996\u89ba\u8f49\u63db\u5668\u6709\u6548\u6574\u5408 MRI \u548c PET\u3002DiaMond \u5177\u5099\u81ea\u6ce8\u610f\u529b\u548c\u65b0\u7a4e\u7684\u96d9\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u53ef\u4ee5\u5354\u540c\u7d50\u5408 MRI \u548c PET\uff0c\u4e26\u63a1\u7528\u591a\u6a21\u5f0f\u6b63\u898f\u5316\u4f86\u6e1b\u5c11\u5197\u9918\u4f9d\u8cf4\uff0c\u5f9e\u800c\u63d0\u5347\u6027\u80fd\u3002DiaMond \u5728\u5404\u7a2e\u6578\u64da\u96c6\u4e2d\u7684\u8868\u73fe\u660e\u986f\u512a\u65bc\u73fe\u6709\u7684\u591a\u6a21\u5f0f\u65b9\u6cd5\uff0c\u5728 AD \u8a3a\u65b7\u4e2d\u9054\u5230 92.4% \u7684\u5e73\u8861\u6e96\u78ba\u5ea6\uff0c\u5728 AD-MCI-CN \u5206\u985e\u4e2d\u9054\u5230 65.2%\uff0c\u5728 AD \u548c FTD \u7684\u9451\u5225\u8a3a\u65b7\u4e2d\u9054\u5230 76.5%\u3002\u6211\u5011\u9084\u5728\u5168\u9762\u7684\u6d88\u878d\u7814\u7a76\u4e2d\u9a57\u8b49\u4e86 DiaMond \u7684\u7a69\u5065\u6027\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/ai-med/DiaMond \u53d6\u5f97\u3002", "author": "Yitong Li et.al.", "authors": "Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger", "id": "2410.23219v1", "paper_url": "http://arxiv.org/abs/2410.23219v1", "repo": "null"}}