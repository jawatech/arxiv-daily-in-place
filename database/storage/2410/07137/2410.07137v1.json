{"2410.07137": {"publish_time": "2024-10-09", "title": "Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates", "paper_summary": "Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and\nMT-Bench, have become popular for evaluating language models due to their\ncost-effectiveness and scalability compared to human evaluation. Achieving high\nwin rates on these benchmarks can significantly boost the promotional impact of\nnewly released language models. This promotional benefit may motivate tricks,\nsuch as manipulating model output length or style to game win rates, even\nthough several mechanisms have been developed to control length and disentangle\nstyle to reduce gameability. Nonetheless, we show that even a \"null model\" that\nalways outputs a constant response (irrelevant to input instructions) can cheat\nautomatic benchmarks and achieve top-ranked win rates: an 86.5% LC win rate on\nAlpacaEval 2.0; an 83.0 score on Arena-Hard-Auto; and a 9.55 score on MT-Bench.\nMoreover, the crafted cheating outputs are transferable because we assume that\nthe instructions of these benchmarks (e.g., 805 samples of AlpacaEval 2.0) are\nprivate and cannot be accessed. While our experiments are primarily\nproof-of-concept, an adversary could use LLMs to generate more imperceptible\ncheating responses, unethically benefiting from high win rates and promotional\nimpact. Our findings call for the development of anti-cheating mechanisms for\nreliable automatic benchmarks. The code is available at\nhttps://github.com/sail-sg/Cheating-LLM-Benchmarks.", "paper_summary_zh": "\u81ea\u52d5 LLM \u8a55\u91cf\u57fa\u6e96\uff0c\u4f8b\u5982 AlpacaEval 2.0\u3001Arena-Hard-Auto \u548c MT-Bench\uff0c\u7531\u65bc\u5176\u8207\u4eba\u5de5\u8a55\u91cf\u76f8\u6bd4\u5177\u6709\u6210\u672c\u6548\u76ca\u4e14\u53ef\u64f4\u5145\u6027\uff0c\u56e0\u6b64\u5df2\u5ee3\u6cdb\u7528\u65bc\u8a55\u91cf\u8a9e\u8a00\u6a21\u578b\u3002\u5728\u9019\u4e9b\u8a55\u91cf\u57fa\u6e96\u4e0a\u53d6\u5f97\u9ad8\u7372\u52dd\u7387\u53ef\u4ee5\u986f\u8457\u63d0\u5347\u65b0\u767c\u5e03\u8a9e\u8a00\u6a21\u578b\u7684\u5ba3\u50b3\u5f71\u97ff\u529b\u3002\u9019\u7a2e\u5ba3\u50b3\u6548\u76ca\u53ef\u80fd\u6703\u6fc0\u52f5\u4e00\u4e9b\u6280\u5de7\uff0c\u4f8b\u5982\u64cd\u7e31\u6a21\u578b\u8f38\u51fa\u9577\u5ea6\u6216\u98a8\u683c\u4ee5\u73a9\u5f04\u7372\u52dd\u7387\uff0c\u5118\u7ba1\u5df2\u7d93\u958b\u767c\u51fa\u591a\u7a2e\u6a5f\u5236\u4f86\u63a7\u5236\u9577\u5ea6\u548c\u89e3\u958b\u98a8\u683c\u4ee5\u6e1b\u5c11\u53ef\u73a9\u6027\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u6211\u5011\u8868\u660e\u5373\u4f7f\u7e3d\u662f\u8f38\u51fa\u6046\u5b9a\u56de\u61c9\uff08\u8207\u8f38\u5165\u6307\u4ee4\u7121\u95dc\uff09\u7684\u300c\u7a7a\u6a21\u578b\u300d\u4e5f\u80fd\u6b3a\u9a19\u81ea\u52d5\u8a55\u91cf\u57fa\u6e96\u4e26\u7372\u5f97\u6392\u540d\u6700\u9ad8\u7684\u7372\u52dd\u7387\uff1a\u5728 AlpacaEval 2.0 \u4e0a\u7372\u5f97 86.5% \u7684 LC \u7372\u52dd\u7387\uff1b\u5728 Arena-Hard-Auto \u4e0a\u7372\u5f97 83.0 \u5206\uff1b\u5728 MT-Bench \u4e0a\u7372\u5f97 9.55 \u5206\u3002\u6b64\u5916\uff0c\u7cbe\u5fc3\u88fd\u4f5c\u7684\u4f5c\u5f0a\u8f38\u51fa\u662f\u53ef\u4ee5\u8f49\u79fb\u7684\uff0c\u56e0\u70ba\u6211\u5011\u5047\u8a2d\u9019\u4e9b\u8a55\u91cf\u57fa\u6e96\u7684\u6307\u4ee4\uff08\u4f8b\u5982 AlpacaEval 2.0 \u7684 805 \u500b\u7bc4\u4f8b\uff09\u662f\u79c1\u6709\u7684\uff0c\u7121\u6cd5\u5b58\u53d6\u3002\u96d6\u7136\u6211\u5011\u7684\u5be6\u9a57\u4e3b\u8981\u662f\u6982\u5ff5\u9a57\u8b49\uff0c\u4f46\u5c0d\u624b\u53ef\u4ee5\u4f7f\u7528 LLM \u7522\u751f\u66f4\u96e3\u5bdf\u89ba\u7684\u4f5c\u5f0a\u56de\u61c9\uff0c\u4e0d\u9053\u5fb7\u5730\u53d7\u76ca\u65bc\u9ad8\u7372\u52dd\u7387\u548c\u5ba3\u50b3\u5f71\u97ff\u529b\u3002\u6211\u5011\u7684\u767c\u73fe\u8981\u6c42\u958b\u767c\u9632\u4f5c\u5f0a\u6a5f\u5236\u4ee5\u78ba\u4fdd\u81ea\u52d5\u8a55\u91cf\u57fa\u6e96\u7684\u53ef\u9760\u6027\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/sail-sg/Cheating-LLM-Benchmarks \u53d6\u5f97\u3002", "author": "Xiaosen Zheng et.al.", "authors": "Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, Min Lin", "id": "2410.07137v1", "paper_url": "http://arxiv.org/abs/2410.07137v1", "repo": "null"}}