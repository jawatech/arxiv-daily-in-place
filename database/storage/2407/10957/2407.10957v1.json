{"2407.10957": {"publish_time": "2024-07-15", "title": "Ref-AVS: Refer and Segment Objects in Audio-Visual Scenes", "paper_summary": "Traditional reference segmentation tasks have predominantly focused on silent\nvisual scenes, neglecting the integral role of multimodal perception and\ninteraction in human experiences. In this work, we introduce a novel task\ncalled Reference Audio-Visual Segmentation (Ref-AVS), which seeks to segment\nobjects within the visual domain based on expressions containing multimodal\ncues. Such expressions are articulated in natural language forms but are\nenriched with multimodal cues, including audio and visual descriptions. To\nfacilitate this research, we construct the first Ref-AVS benchmark, which\nprovides pixel-level annotations for objects described in corresponding\nmultimodal-cue expressions. To tackle the Ref-AVS task, we propose a new method\nthat adequately utilizes multimodal cues to offer precise segmentation\nguidance. Finally, we conduct quantitative and qualitative experiments on three\ntest subsets to compare our approach with existing methods from related tasks.\nThe results demonstrate the effectiveness of our method, highlighting its\ncapability to precisely segment objects using multimodal-cue expressions.\nDataset is available at\n\\href{https://gewu-lab.github.io/Ref-AVS}{https://gewu-lab.github.io/Ref-AVS}.", "paper_summary_zh": "\u50b3\u7d71\u7684\u53c3\u8003\u5206\u5272\u4efb\u52d9\u4e3b\u8981\u96c6\u4e2d\u5728\u975c\u9ed8\u7684\u8996\u89ba\u5834\u666f\u4e0a\uff0c\u5ffd\u7565\u4e86\u591a\u6a21\u614b\u611f\u77e5\u548c\u4e92\u52d5\u5728\u4eba\u985e\u9ad4\u9a57\u4e2d\u7684\u6574\u9ad4\u4f5c\u7528\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u540d\u70ba\u53c3\u8003\u97f3\u8a0a\u8996\u89ba\u5206\u5272 (Ref-AVS) \u7684\u65b0\u4efb\u52d9\uff0c\u5b83\u65e8\u5728\u6839\u64da\u5305\u542b\u591a\u6a21\u614b\u7dda\u7d22\u7684\u8868\u9054\u5f0f\u5206\u5272\u8996\u89ba\u57df\u5167\u7684\u7269\u4ef6\u3002\u6b64\u985e\u8868\u9054\u5f0f\u4ee5\u81ea\u7136\u8a9e\u8a00\u5f62\u5f0f\u8868\u9054\uff0c\u4f46\u52a0\u5165\u4e86\u591a\u6a21\u614b\u7dda\u7d22\uff0c\u5305\u62ec\u97f3\u8a0a\u548c\u8996\u89ba\u63cf\u8ff0\u3002\u70ba\u4e86\u4fc3\u9032\u9019\u9805\u7814\u7a76\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u7b2c\u4e00\u500b Ref-AVS \u57fa\u6e96\uff0c\u5b83\u70ba\u5c0d\u61c9\u7684\u591a\u6a21\u614b\u7dda\u7d22\u8868\u9054\u5f0f\u4e2d\u63cf\u8ff0\u7684\u7269\u4ef6\u63d0\u4f9b\u4e86\u50cf\u7d20\u7d1a\u8a3b\u89e3\u3002\u70ba\u4e86\u61c9\u5c0d Ref-AVS \u4efb\u52d9\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\uff0c\u5b83\u5145\u5206\u5229\u7528\u591a\u6a21\u614b\u7dda\u7d22\u4f86\u63d0\u4f9b\u7cbe\u78ba\u7684\u5206\u5272\u6307\u5c0e\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5728\u4e09\u500b\u6e2c\u8a66\u5b50\u96c6\u4e2d\u9032\u884c\u4e86\u91cf\u5316\u548c\u5b9a\u6027\u5be6\u9a57\uff0c\u4ee5\u5c07\u6211\u5011\u7684\u65b9\u6cd5\u8207\u76f8\u95dc\u4efb\u52d9\u4e2d\u7684\u73fe\u6709\u65b9\u6cd5\u9032\u884c\u6bd4\u8f03\u3002\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7a81\u51fa\u4e86\u5176\u4f7f\u7528\u591a\u6a21\u614b\u7dda\u7d22\u8868\u9054\u5f0f\u7cbe\u78ba\u5206\u5272\u7269\u4ef6\u7684\u80fd\u529b\u3002\u8cc7\u6599\u96c6\u53ef\u5728\n\\href{https://gewu-lab.github.io/Ref-AVS}{https://gewu-lab.github.io/Ref-AVS} \u53d6\u5f97\u3002", "author": "Yaoting Wang et.al.", "authors": "Yaoting Wang, Peiwen Sun, Dongzhan Zhou, Guangyao Li, Honggang Zhang, Di Hu", "id": "2407.10957v1", "paper_url": "http://arxiv.org/abs/2407.10957v1", "repo": "null"}}