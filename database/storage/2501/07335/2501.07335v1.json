{"2501.07335": {"publish_time": "2025-01-13", "title": "TempoGPT: Enhancing Temporal Reasoning via Quantizing Embedding", "paper_summary": "Multi-modal language model has made advanced progress in vision and audio,\nbut still faces significant challenges in dealing with complex reasoning tasks\nin the time series domain. The reasons are twofold. First, labels for\nmulti-modal time series data are coarse and devoid of analysis or reasoning\nprocesses. Training with these data cannot improve the model's reasoning\ncapabilities. Second, due to the lack of precise tokenization in processing\ntime series, the representation patterns for temporal and textual information\nare inconsistent, which hampers the effectiveness of multi-modal alignment. To\naddress these challenges, we propose a multi-modal time series data\nconstruction approach and a multi-modal time series language model (TLM),\nTempoGPT. Specially, we construct multi-modal data for complex reasoning tasks\nby analyzing the variable-system relationships within a white-box system.\nAdditionally, proposed TempoGPT achieves consistent representation between\ntemporal and textual information by quantizing temporal embeddings, where\ntemporal embeddings are quantized into a series of discrete tokens using a\npredefined codebook; subsequently, a shared embedding layer processes both\ntemporal and textual tokens. Extensive experiments demonstrate that TempoGPT\naccurately perceives temporal information, logically infers conclusions, and\nachieves state-of-the-art in the constructed complex time series reasoning\ntasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing\ntemporal embeddings in enhancing multi-modal alignment and the reasoning\ncapabilities of TLMs. Code and data are available at\nhttps://github.com/zhanghaochuan20/TempoGPT.", "paper_summary_zh": "<paragraph>\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u548c\u97f3\u9891\u65b9\u9762\u53d6\u5f97\u4e86\u957f\u8db3\u7684\u8fdb\u6b65\uff0c\n\u4f46\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u57df\u4e2d\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\u4ecd\u9762\u4e34\u7740\u4e25\u5cfb\u7684\u6311\u6218\u3002\u539f\u56e0\u6709\u4e8c\u3002\u9996\u5148\uff0c\n\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6807\u7b7e\u7c97\u7cd9\uff0c\u4e14\u7f3a\u4e4f\u5206\u6790\u6216\u63a8\u7406\n\u8fc7\u7a0b\u3002\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u65e0\u6cd5\u63d0\u9ad8\u6a21\u578b\u7684\u63a8\u7406\n\u80fd\u529b\u3002\u5176\u6b21\uff0c\u7531\u4e8e\u5728\u5904\u7406\u4e2d\u7f3a\u4e4f\u7cbe\u786e\u7684\u6807\u8bb0\u5316\n\u65f6\u95f4\u5e8f\u5217\uff0c\u65f6\u95f4\u548c\u6587\u672c\u4fe1\u606f\u7684\u8868\u793a\u6a21\u5f0f\u4e0d\u4e00\u81f4\uff0c\u8fd9\u963b\u788d\u4e86\u591a\u6a21\u6001\u5bf9\u9f50\u7684\u6709\u6548\u6027\u3002\u4e3a\u4e86\n\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u6570\u636e\n\u6784\u5efa\u65b9\u6cd5\u548c\u4e00\u79cd\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u8bed\u8a00\u6a21\u578b (TLM)\uff0c\nTempoGPT\u3002\u7279\u522b\u5730\uff0c\u6211\u4eec\u901a\u8fc7\u5206\u6790\u767d\u76d2\u7cfb\u7edf\u4e2d\u7684\u53d8\u91cf\u7cfb\u7edf\u5173\u7cfb\u6765\u6784\u5efa\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u591a\u6a21\u6001\u6570\u636e\u3002\n\u6b64\u5916\uff0c\u63d0\u51fa\u7684 TempoGPT \u901a\u8fc7\u91cf\u5316\u65f6\u95f4\u5d4c\u5165\u5b9e\u73b0\u4e86\u65f6\u95f4\u548c\u6587\u672c\u4fe1\u606f\u4e4b\u95f4\u7684\u4e00\u81f4\u8868\u793a\uff0c\u5176\u4e2d\n\u65f6\u95f4\u5d4c\u5165\u4f7f\u7528\u9884\u5b9a\u4e49\u7684\u4ee3\u7801\u7c3f\u88ab\u91cf\u5316\u4e3a\u4e00\u7cfb\u5217\u79bb\u6563\u6807\u8bb0\uff1b\u968f\u540e\uff0c\u4e00\u4e2a\u5171\u4eab\u5d4c\u5165\u5c42\u5904\u7406\n\u65f6\u95f4\u548c\u6587\u672c\u6807\u8bb0\u3002\u5927\u91cf\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTempoGPT\n\u51c6\u786e\u5730\u611f\u77e5\u65f6\u95f4\u4fe1\u606f\uff0c\u5408\u4e4e\u903b\u8f91\u5730\u63a8\u65ad\u7ed3\u8bba\uff0c\u5e76\u5728\u6784\u5efa\u7684\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6c34\u5e73\n\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5b9a\u91cf\u8bc1\u660e\u4e86\u91cf\u5316\u65f6\u95f4\u5d4c\u5165\u5728\u589e\u5f3a\u591a\u6a21\u6001\u5bf9\u9f50\u548c TLM \u7684\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u4ee3\u7801\u548c\u6570\u636e\u53ef\u5728\nhttps://github.com/zhanghaochuan20/TempoGPT.</paragraph>", "author": "Haochuan Zhang et.al.", "authors": "Haochuan Zhang, Chunhua Yang, Jie Han, Liyang Qin, Xiaoli Wang", "id": "2501.07335v1", "paper_url": "http://arxiv.org/abs/2501.07335v1", "repo": "null"}}