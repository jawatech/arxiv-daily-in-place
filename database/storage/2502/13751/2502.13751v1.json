{"2502.13751": {"publish_time": "2025-02-19", "title": "RobustX: Robust Counterfactual Explanations Made Easy", "paper_summary": "The increasing use of Machine Learning (ML) models to aid decision-making in\nhigh-stakes industries demands explainability to facilitate trust.\nCounterfactual Explanations (CEs) are ideally suited for this, as they can\noffer insights into the predictions of an ML model by illustrating how changes\nin its input data may lead to different outcomes. However, for CEs to realise\ntheir explanatory potential, significant challenges remain in ensuring their\nrobustness under slight changes in the scenario being explained. Despite the\nwidespread recognition of CEs' robustness as a fundamental requirement, a lack\nof standardised tools and benchmarks hinders a comprehensive and effective\ncomparison of robust CE generation methods. In this paper, we introduce\nRobustX, an open-source Python library implementing a collection of CE\ngeneration and evaluation methods, with a focus on the robustness property.\nRobustX provides interfaces to several existing methods from the literature,\nenabling streamlined access to state-of-the-art techniques. The library is also\neasily extensible, allowing fast prototyping of novel robust CE generation and\nevaluation methods.", "paper_summary_zh": "\u96a8\u8457\u6a5f\u5668\u5b78\u7fd2 (ML) \u6a21\u578b\u5728\u9ad8\u98a8\u96aa\u7522\u696d\u4e2d\u8f14\u52a9\u6c7a\u7b56\u5236\u5b9a\u65e5\u76ca\u5ee3\u6cdb\uff0c\u53ef\u89e3\u91cb\u6027\u9700\u6c42\u65e5\u589e\uff0c\u4ee5\u5229\u65bc\u5efa\u7acb\u4fe1\u4efb\u3002\u53cd\u4e8b\u5be6\u89e3\u91cb (CE) \u975e\u5e38\u9069\u5408\u6b64\u76ee\u7684\uff0c\u56e0\u70ba\u5b83\u5011\u53ef\u4ee5\u900f\u904e\u8aaa\u660e\u8f38\u5165\u8cc7\u6599\u7684\u8b8a\u66f4\u5982\u4f55\u5c0e\u81f4\u4e0d\u540c\u7684\u7d50\u679c\uff0c\u9032\u800c\u63d0\u4f9b\u5c0d ML \u6a21\u578b\u9810\u6e2c\u7684\u898b\u89e3\u3002\u7136\u800c\uff0c\u8981\u8b93 CE \u767c\u63ee\u5176\u89e3\u91cb\u6f5b\u529b\uff0c\u5728\u78ba\u4fdd\u5176\u5728\u6240\u89e3\u91cb\u60c5\u5883\u4e2d\u5c0d\u5fae\u5c0f\u8b8a\u66f4\u5177\u6709\u7a69\u5065\u6027\u65b9\u9762\uff0c\u4ecd\u6709\u8a31\u591a\u6311\u6230\u3002\u5118\u7ba1 CE \u7684\u7a69\u5065\u6027\u5ee3\u6cdb\u88ab\u8a8d\u70ba\u662f\u4e00\u9805\u57fa\u672c\u8981\u6c42\uff0c\u4f46\u7f3a\u4e4f\u6a19\u6e96\u5316\u5de5\u5177\u548c\u57fa\u6e96\uff0c\u6703\u963b\u7919\u5c0d\u7a69\u5065 CE \u751f\u6210\u65b9\u6cd5\u9032\u884c\u5168\u9762\u4e14\u6709\u6548\u7684\u6bd4\u8f03\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 RobustX\uff0c\u9019\u662f\u4e00\u500b\u958b\u6e90\u7684 Python \u51fd\u5f0f\u5eab\uff0c\u5be6\u4f5c\u4e86\u4e00\u7cfb\u5217 CE \u751f\u6210\u548c\u8a55\u4f30\u65b9\u6cd5\uff0c\u4e26\u5c08\u6ce8\u65bc\u7a69\u5065\u6027\u5c6c\u6027\u3002RobustX \u63d0\u4f9b\u4e86\u8207\u6587\u737b\u4e2d\u591a\u7a2e\u73fe\u6709\u65b9\u6cd5\u7684\u4ecb\u9762\uff0c\u8b93\u4f7f\u7528\u8005\u53ef\u4ee5\u7c21\u5316\u5b58\u53d6\u6700\u5148\u9032\u7684\u6280\u8853\u3002\u6b64\u51fd\u5f0f\u5eab\u4e5f\u5bb9\u6613\u64f4\u5145\uff0c\u53ef\u4ee5\u5feb\u901f\u5efa\u69cb\u539f\u578b\uff0c\u4ee5\u9032\u884c\u65b0\u7a4e\u7684\u7a69\u5065 CE \u751f\u6210\u548c\u8a55\u4f30\u65b9\u6cd5\u3002", "author": "Junqi Jiang et.al.", "authors": "Junqi Jiang, Luca Marzari, Aaryan Purohit, Francesco Leofante", "id": "2502.13751v1", "paper_url": "http://arxiv.org/abs/2502.13751v1", "repo": "null"}}