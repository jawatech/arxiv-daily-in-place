{"2406.17287": {"publish_time": "2024-06-25", "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models", "paper_summary": "Accurate assessment of personality traits is crucial for effective\npsycho-counseling, yet traditional methods like self-report questionnaires are\ntime-consuming and biased. This study exams whether Large Language Models\n(LLMs) can predict the Big Five personality traits directly from counseling\ndialogues and introduces an innovative framework to perform the task. Our\nframework applies role-play and questionnaire-based prompting to condition LLMs\non counseling sessions, simulating client responses to the Big Five Inventory.\nWe evaluated our framework on 853 real-world counseling sessions, finding a\nsignificant correlation between LLM-predicted and actual Big Five traits,\nproving the validity of framework. Moreover, ablation studies highlight the\nimportance of role-play simulations and task simplification via questionnaires\nin enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model,\nutilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves\na 130.95\\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\\%\nin personality prediction validity. In conclusion, LLMs can predict personality\nbased on counseling dialogues. Our code and model are publicly available at\n\\url{https://github.com/kuri-leo/BigFive-LLM-Predictor}, providing a valuable\ntool for future research in computational psychometrics.", "paper_summary_zh": "\u6e96\u78ba\u8a55\u4f30\u4eba\u683c\u7279\u8cea\u5c0d\u65bc\u6709\u6548\u7684\u5fc3\u7406\u8aee\u5546\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u50b3\u7d71\u65b9\u6cd5\uff08\u4f8b\u5982\u81ea\u6211\u5831\u544a\u554f\u5377\uff09\u65e2\u8017\u6642\u53c8\u5b58\u5728\u504f\u898b\u3002\u672c\u7814\u7a76\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5426\u80fd\u76f4\u63a5\u5f9e\u8aee\u5546\u5c0d\u8a71\u4e2d\u9810\u6e2c\u5927\u4e94\u4eba\u683c\u7279\u8cea\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\u4f86\u57f7\u884c\u9019\u9805\u4efb\u52d9\u3002\u6211\u5011\u7684\u67b6\u69cb\u61c9\u7528\u89d2\u8272\u626e\u6f14\u548c\u57fa\u65bc\u554f\u5377\u7684\u63d0\u793a\uff0c\u5728\u8aee\u5546\u6703\u8ac7\u4e2d\u5c0d LLM \u9032\u884c\u689d\u4ef6\u5316\uff0c\u6a21\u64ec\u5ba2\u6236\u5c0d\u5927\u4e94\u4eba\u683c\u91cf\u8868\u7684\u56de\u61c9\u3002\u6211\u5011\u5c0d 853 \u500b\u771f\u5be6\u4e16\u754c\u7684\u8aee\u5546\u6703\u8ac7\u8a55\u4f30\u4e86\u6211\u5011\u7684\u67b6\u69cb\uff0c\u767c\u73fe LLM \u9810\u6e2c\u7684\u5927\u4e94\u7279\u8cea\u8207\u5be6\u969b\u5927\u4e94\u7279\u8cea\u4e4b\u9593\u5b58\u5728\u986f\u8457\u76f8\u95dc\u6027\uff0c\u8b49\u660e\u4e86\u67b6\u69cb\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6d88\u878d\u7814\u7a76\u5f37\u8abf\u4e86\u89d2\u8272\u626e\u6f14\u6a21\u64ec\u548c\u900f\u904e\u554f\u5377\u7c21\u5316\u4efb\u52d9\u5c0d\u65bc\u63d0\u9ad8\u9810\u6e2c\u6e96\u78ba\u6027\u7684\u91cd\u8981\u6027\u3002\u540c\u6642\uff0c\u6211\u5011\u5fae\u8abf\u5f8c\u7684 Llama3-8B \u6a21\u578b\uff0c\u5229\u7528\u5e36\u6709\u76e3\u7763\u5fae\u8abf\u7684\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\uff0c\u5728\u4eba\u683c\u9810\u6e2c\u6709\u6548\u6027\u4e0a\u53d6\u5f97\u4e86 130.95% \u7684\u6539\u9032\uff0c\u6bd4\u6700\u5148\u9032\u7684 Qwen1.5-110B \u9ad8\u51fa 36.94%\u3002\u7e3d\u4e4b\uff0cLLM \u53ef\u4ee5\u6839\u64da\u8aee\u5546\u5c0d\u8a71\u9810\u6e2c\u4eba\u683c\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u5df2\u516c\u958b\u767c\u5e03\u5728 \\url{https://github.com/kuri-leo/BigFive-LLM-Predictor}\uff0c\u70ba\u8a08\u7b97\u5fc3\u7406\u6e2c\u91cf\u5b78\u7684\u672a\u4f86\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u5de5\u5177\u3002", "author": "Yang Yan et.al.", "authors": "Yang Yan, Lizhi Ma, Anqi Li, Jingsong Ma, Zhenzhong Lan", "id": "2406.17287v1", "paper_url": "http://arxiv.org/abs/2406.17287v1", "repo": "https://github.com/kuri-leo/bigfive-llm-predictor"}}