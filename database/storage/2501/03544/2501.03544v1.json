{"2501.03544": {"publish_time": "2025-01-07", "title": "PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models", "paper_summary": "Text-to-image (T2I) models have been shown to be vulnerable to misuse,\nparticularly in generating not-safe-for-work (NSFW) content, raising serious\nethical concerns. In this work, we present PromptGuard, a novel content\nmoderation technique that draws inspiration from the system prompt mechanism in\nlarge language models (LLMs) for safety alignment. Unlike LLMs, T2I models lack\na direct interface for enforcing behavioral guidelines. Our key idea is to\noptimize a safety soft prompt that functions as an implicit system prompt\nwithin the T2I model's textual embedding space. This universal soft prompt (P*)\ndirectly moderates NSFW inputs, enabling safe yet realistic image generation\nwithout altering the inference efficiency or requiring proxy models. Extensive\nexperiments across three datasets demonstrate that PromptGuard effectively\nmitigates NSFW content generation while preserving high-quality benign outputs.\nPromptGuard achieves 7.8 times faster than prior content moderation methods,\nsurpassing eight state-of-the-art defenses with an optimal unsafe ratio down to\n5.84%.", "paper_summary_zh": "\u6587\u5b57\u8f49\u5716\u50cf (T2I) \u6a21\u578b\u5df2\u88ab\u8b49\u660e\u5bb9\u6613\u88ab\u6feb\u7528\uff0c\u7279\u5225\u662f\u5728\u7522\u751f\u4e0d\u9069\u5408\u5de5\u4f5c (NSFW) \u5167\u5bb9\u6642\uff0c\u5f15\u767c\u4e86\u56b4\u91cd\u7684\u9053\u5fb7\u554f\u984c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 PromptGuard\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u5167\u5bb9\u5be9\u6838\u6280\u8853\uff0c\u5f9e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u7cfb\u7d71\u63d0\u793a\u6a5f\u5236\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u4ee5\u9032\u884c\u5b89\u5168\u5c0d\u9f4a\u3002\u8207 LLM \u4e0d\u540c\uff0cT2I \u6a21\u578b\u7f3a\u4e4f\u5f37\u5236\u57f7\u884c\u884c\u70ba\u6e96\u5247\u7684\u76f4\u63a5\u4ecb\u9762\u3002\u6211\u5011\u7684\u95dc\u9375\u60f3\u6cd5\u662f\u6700\u4f73\u5316\u4e00\u500b\u5b89\u5168\u8edf\u63d0\u793a\uff0c\u5b83\u5728 T2I \u6a21\u578b\u7684\u6587\u5b57\u5d4c\u5165\u7a7a\u9593\u4e2d\u4f5c\u70ba\u4e00\u500b\u96b1\u5f0f\u7cfb\u7d71\u63d0\u793a\u904b\u4f5c\u3002\u9019\u500b\u901a\u7528\u8edf\u63d0\u793a (P*) \u76f4\u63a5\u5be9\u6838 NSFW \u8f38\u5165\uff0c\u5728\u4e0d\u6539\u8b8a\u63a8\u7406\u6548\u7387\u6216\u4e0d\u9700\u8981\u4ee3\u7406\u6a21\u578b\u7684\u60c5\u6cc1\u4e0b\uff0c\u5be6\u73fe\u5b89\u5168\u4e14\u903c\u771f\u7684\u5716\u50cf\u751f\u6210\u3002\u8de8\u8d8a\u4e09\u500b\u8cc7\u6599\u96c6\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0cPromptGuard \u6709\u6548\u5730\u6e1b\u8f15\u4e86 NSFW \u5167\u5bb9\u7684\u7522\u751f\uff0c\u540c\u6642\u4fdd\u7559\u4e86\u9ad8\u54c1\u8cea\u7684\u826f\u6027\u8f38\u51fa\u3002PromptGuard \u7684\u901f\u5ea6\u6bd4\u5148\u524d\u7684\u5167\u5bb9\u5be9\u6838\u65b9\u6cd5\u5feb 7.8 \u500d\uff0c\u8d85\u8d8a\u4e86\u516b\u7a2e\u6700\u5148\u9032\u7684\u9632\u79a6\u63aa\u65bd\uff0c\u5c07\u6700\u4f73\u4e0d\u5b89\u5168\u6bd4\u7387\u964d\u81f3 5.84%\u3002", "author": "Lingzhi Yuan et.al.", "authors": "Lingzhi Yuan, Xinfeng Li, Chejian Xu, Guanhong Tao, Xiaojun Jia, Yihao Huang, Wei Dong, Yang Liu, XiaoFeng Wang, Bo Li", "id": "2501.03544v1", "paper_url": "http://arxiv.org/abs/2501.03544v1", "repo": "null"}}