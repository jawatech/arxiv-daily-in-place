{"2411.05348": {"publish_time": "2024-11-08", "title": "LLM-PySC2: Starcraft II learning environment for Large Language Models", "paper_summary": "This paper introduces a new environment LLM-PySC2 (the Large Language Model\nStarCraft II Learning Environment), a platform derived from DeepMind's\nStarCraft II Learning Environment that serves to develop Large Language Models\n(LLMs) based decision-making methodologies. This environment is the first to\noffer the complete StarCraft II action space, multi-modal observation\ninterfaces, and a structured game knowledge database, which are seamlessly\nconnected with various LLMs to facilitate the research of LLMs-based\ndecision-making. To further support multi-agent research, we developed an LLM\ncollaborative framework that supports multi-agent concurrent queries and\nmulti-agent communication. In our experiments, the LLM-PySC2 environment is\nadapted to be compatible with the StarCraft Multi-Agent Challenge (SMAC) task\ngroup and provided eight new scenarios focused on macro-decision abilities. We\nevaluated nine mainstream LLMs in the experiments, and results show that\nsufficient parameters are necessary for LLMs to make decisions, but improving\nreasoning ability does not directly lead to better decision-making outcomes.\nOur findings further indicate the importance of enabling large models to learn\nautonomously in the deployment environment through parameter training or\ntrain-free learning techniques. Ultimately, we expect that the LLM-PySC2\nenvironment can promote research on learning methods for LLMs, helping\nLLM-based methods better adapt to task scenarios.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u74b0\u5883 LLM-PySC2 (\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u661f\u6d77\u722d\u9738 II \u5b78\u7fd2\u74b0\u5883)\uff0c\u4e00\u500b\u6e90\u81ea DeepMind \u7684\u661f\u6d77\u722d\u9738 II \u5b78\u7fd2\u74b0\u5883\u7684\u5e73\u53f0\uff0c\u7528\u65bc\u958b\u767c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u70ba\u57fa\u790e\u7684\u6c7a\u7b56\u5236\u5b9a\u65b9\u6cd5\u3002\u6b64\u74b0\u5883\u662f\u7b2c\u4e00\u500b\u63d0\u4f9b\u5b8c\u6574\u7684\u661f\u6d77\u722d\u9738 II \u52d5\u4f5c\u7a7a\u9593\u3001\u591a\u6a21\u5f0f\u89c0\u5bdf\u4ecb\u9762\u548c\u7d50\u69cb\u5316\u904a\u6232\u77e5\u8b58\u8cc7\u6599\u5eab\u7684\u74b0\u5883\uff0c\u9019\u4e9b\u74b0\u5883\u8207\u5404\u7a2e LLM \u7121\u7e2b\u9023\u63a5\uff0c\u4ee5\u4fbf\u65bc\u7814\u7a76\u57fa\u65bc LLM \u7684\u6c7a\u7b56\u5236\u5b9a\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u652f\u63f4\u591a\u91cd\u4ee3\u7406\u7814\u7a76\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b LLM \u5354\u4f5c\u67b6\u69cb\uff0c\u652f\u63f4\u591a\u91cd\u4ee3\u7406\u4e26\u767c\u67e5\u8a62\u548c\u591a\u91cd\u4ee3\u7406\u6e9d\u901a\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0cLLM-PySC2 \u74b0\u5883\u7d93\u904e\u8abf\u6574\uff0c\u8207\u661f\u6d77\u722d\u9738\u591a\u91cd\u4ee3\u7406\u6311\u6230 (SMAC) \u4efb\u52d9\u7d44\u76f8\u5bb9\uff0c\u4e26\u63d0\u4f9b\u4e86\u516b\u500b\u65b0\u7684\u5834\u666f\uff0c\u5c08\u6ce8\u65bc\u5de8\u89c0\u6c7a\u7b56\u80fd\u529b\u3002\u6211\u5011\u5728\u5be6\u9a57\u4e2d\u8a55\u4f30\u4e86\u4e5d\u500b\u4e3b\u6d41 LLM\uff0c\u7d50\u679c\u986f\u793a\uff0cLLM \u8981\u505a\u51fa\u6c7a\u7b56\u9700\u8981\u8db3\u5920\u7684\u53c3\u6578\uff0c\u4f46\u6539\u5584\u63a8\u7406\u80fd\u529b\u4e26\u4e0d\u6703\u76f4\u63a5\u5c0e\u81f4\u66f4\u597d\u7684\u6c7a\u7b56\u5236\u5b9a\u7d50\u679c\u3002\u6211\u5011\u7684\u767c\u73fe\u9032\u4e00\u6b65\u8868\u660e\uff0c\u8b93\u5927\u578b\u6a21\u578b\u80fd\u5920\u900f\u904e\u53c3\u6578\u8a13\u7df4\u6216\u514d\u8a13\u7df4\u5b78\u7fd2\u6280\u8853\u5728\u90e8\u7f72\u74b0\u5883\u4e2d\u81ea\u4e3b\u5b78\u7fd2\u975e\u5e38\u91cd\u8981\u3002\u6700\u7d42\uff0c\u6211\u5011\u9810\u671f LLM-PySC2 \u74b0\u5883\u53ef\u4ee5\u4fc3\u9032 LLM \u5b78\u7fd2\u65b9\u6cd5\u7684\u7814\u7a76\uff0c\u5354\u52a9\u57fa\u65bc LLM \u7684\u65b9\u6cd5\u66f4\u597d\u5730\u9069\u61c9\u4efb\u52d9\u5834\u666f\u3002", "author": "Zongyuan Li et.al.", "authors": "Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Xian Guo, Kuihua Huang, Xuebo Zhang", "id": "2411.05348v1", "paper_url": "http://arxiv.org/abs/2411.05348v1", "repo": "null"}}