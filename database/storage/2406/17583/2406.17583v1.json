{"2406.17583": {"publish_time": "2024-06-25", "title": "Towards Compositional Interpretability for XAI", "paper_summary": "Artificial intelligence (AI) is currently based largely on black-box machine\nlearning models which lack interpretability. The field of eXplainable AI (XAI)\nstrives to address this major concern, being critical in high-stakes areas such\nas the finance, legal and health sectors.\n  We present an approach to defining AI models and their interpretability based\non category theory. For this we employ the notion of a compositional model,\nwhich sees a model in terms of formal string diagrams which capture its\nabstract structure together with its concrete implementation. This\ncomprehensive view incorporates deterministic, probabilistic and quantum\nmodels. We compare a wide range of AI models as compositional models, including\nlinear and rule-based models, (recurrent) neural networks, transformers, VAEs,\nand causal and DisCoCirc models.\n  Next we give a definition of interpretation of a model in terms of its\ncompositional structure, demonstrating how to analyse the interpretability of a\nmodel, and using this to clarify common themes in XAI. We find that what makes\nthe standard 'intrinsically interpretable' models so transparent is brought out\nmost clearly diagrammatically. This leads us to the more general notion of\ncompositionally-interpretable (CI) models, which additionally include, for\ninstance, causal, conceptual space, and DisCoCirc models.\n  We next demonstrate the explainability benefits of CI models. Firstly, their\ncompositional structure may allow the computation of other quantities of\ninterest, and may facilitate inference from the model to the modelled\nphenomenon by matching its structure. Secondly, they allow for diagrammatic\nexplanations for their behaviour, based on influence constraints, diagram\nsurgery and rewrite explanations. Finally, we discuss many future directions\nfor the approach, raising the question of how to learn such meaningfully\nstructured models in practice.", "paper_summary_zh": "<paragraph>\u4eba\u5de5\u667a\u6167\uff08AI\uff09\u76ee\u524d\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8cf4\u65bc\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\u7684\u9ed1\u76d2\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u3002\u53ef\u89e3\u91cb\u6027\u4eba\u5de5\u667a\u6167\uff08XAI\uff09\u9818\u57df\u81f4\u529b\u65bc\u89e3\u6c7a\u9019\u500b\u4e3b\u8981\u554f\u984c\uff0c\u9019\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u5065\u5eb7\u7b49\u9ad8\u98a8\u96aa\u9818\u57df\u81f3\u95dc\u91cd\u8981\u3002\n\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u7bc4\u7587\u8ad6\u5b9a\u7fa9 AI \u6a21\u578b\u53ca\u5176\u53ef\u89e3\u91cb\u6027\u7684\u65b9\u6cd5\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63a1\u7528\u7d44\u5408\u6a21\u578b\u7684\u6982\u5ff5\uff0c\u5b83\u4ee5\u5f62\u5f0f\u5f26\u5716\u7684\u5f62\u5f0f\u770b\u5f85\u6a21\u578b\uff0c\u9019\u4e9b\u5f26\u5716\u6355\u7372\u4e86\u6a21\u578b\u7684\u62bd\u8c61\u7d50\u69cb\u53ca\u5176\u5177\u9ad4\u5be6\u73fe\u3002\u9019\u7a2e\u7d9c\u5408\u89c0\u9ede\u5305\u542b\u4e86\u78ba\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u91cf\u5b50\u6a21\u578b\u3002\u6211\u5011\u5c07\u5404\u7a2e AI \u6a21\u578b\u4f5c\u70ba\u7d44\u5408\u6a21\u578b\u9032\u884c\u6bd4\u8f03\uff0c\u5305\u62ec\u7dda\u6027\u548c\u57fa\u65bc\u898f\u5247\u7684\u6a21\u578b\u3001\uff08\u905e\u8ff4\uff09\u795e\u7d93\u7db2\u8def\u3001Transformer\u3001VAE\uff0c\u4ee5\u53ca\u56e0\u679c\u548c DisCoCirc \u6a21\u578b\u3002\n\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u6839\u64da\u6a21\u578b\u7684\u7d44\u5408\u7d50\u69cb\u7d66\u51fa\u6a21\u578b\u89e3\u91cb\u7684\u5b9a\u7fa9\uff0c\u5c55\u793a\u5982\u4f55\u5206\u6790\u6a21\u578b\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4e26\u4f7f\u7528\u5b83\u4f86\u6f84\u6e05 XAI \u4e2d\u7684\u5e38\u898b\u4e3b\u984c\u3002\u6211\u5011\u767c\u73fe\uff0c\u8b93\u6a19\u6e96\u7684\u300c\u5167\u5728\u53ef\u89e3\u91cb\u300d\u6a21\u578b\u5982\u6b64\u900f\u660e\u7684\u539f\u56e0\u5728\u5716\u8868\u4e2d\u8868\u73fe\u5f97\u6700\u70ba\u6e05\u695a\u3002\u9019\u5f15\u5c0e\u6211\u5011\u5f97\u51fa\u66f4\u4e00\u822c\u7684\u7d44\u5408\u53ef\u89e3\u91cb\uff08CI\uff09\u6a21\u578b\u6982\u5ff5\uff0c\u5b83\u53e6\u5916\u9084\u5305\u62ec\u56e0\u679c\u3001\u6982\u5ff5\u7a7a\u9593\u548c DisCoCirc \u6a21\u578b\u3002\n\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5c55\u793a\u4e86 CI \u6a21\u578b\u7684\u53ef\u89e3\u91cb\u6027\u512a\u52e2\u3002\u9996\u5148\uff0c\u5b83\u5011\u7684\u7d44\u5408\u7d50\u69cb\u5141\u8a31\u8a08\u7b97\u5176\u4ed6\u611f\u8208\u8da3\u7684\u91cf\uff0c\u4e26\u53ef\u80fd\u901a\u904e\u5339\u914d\u6a21\u578b\u7684\u7d50\u69cb\u4f86\u4fc3\u9032\u5f9e\u6a21\u578b\u5230\u88ab\u5efa\u6a21\u73fe\u8c61\u7684\u63a8\u7406\u3002\u5176\u6b21\uff0c\u5b83\u5011\u5141\u8a31\u5c0d\u5176\u884c\u70ba\u9032\u884c\u5716\u89e3\u8aaa\u660e\uff0c\u9019\u4e9b\u8aaa\u660e\u57fa\u65bc\u5f71\u97ff\u7d04\u675f\u3001\u5716\u89e3\u624b\u8853\u548c\u91cd\u5beb\u8aaa\u660e\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86\u9019\u7a2e\u65b9\u6cd5\u7684\u8a31\u591a\u672a\u4f86\u65b9\u5411\uff0c\u63d0\u51fa\u4e86\u5982\u4f55\u5728\u5be6\u8e10\u4e2d\u5b78\u7fd2\u9019\u7a2e\u6709\u610f\u7fa9\u7684\u7d50\u69cb\u5316\u6a21\u578b\u7684\u554f\u984c\u3002</paragraph>", "author": "Sean Tull et.al.", "authors": "Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke", "id": "2406.17583v1", "paper_url": "http://arxiv.org/abs/2406.17583v1", "repo": "null"}}