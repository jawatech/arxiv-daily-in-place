{"2501.03292": {"publish_time": "2025-01-06", "title": "Multi-Modal One-Shot Federated Ensemble Learning for Medical Data with Vision Large Language Model", "paper_summary": "Federated learning (FL) has attracted considerable interest in the medical\ndomain due to its capacity to facilitate collaborative model training while\nmaintaining data privacy. However, conventional FL methods typically\nnecessitate multiple communication rounds, leading to significant communication\noverhead and delays, especially in environments with limited bandwidth.\nOne-shot federated learning addresses these issues by conducting model training\nand aggregation in a single communication round, thereby reducing communication\ncosts while preserving privacy. Among these, one-shot federated ensemble\nlearning combines independently trained client models using ensemble techniques\nsuch as voting, further boosting performance in non-IID data scenarios. On the\nother hand, existing machine learning methods in healthcare predominantly use\nunimodal data (e.g., medical images or textual reports), which restricts their\ndiagnostic accuracy and comprehensiveness. Therefore, the integration of\nmulti-modal data is proposed to address these shortcomings. In this paper, we\nintroduce FedMME, an innovative one-shot multi-modal federated ensemble\nlearning framework that utilizes multi-modal data for medical image analysis.\nSpecifically, FedMME capitalizes on vision large language models to produce\ntextual reports from medical images, employs a BERT model to extract textual\nfeatures from these reports, and amalgamates these features with visual\nfeatures to improve diagnostic accuracy. Experimental results show that our\nmethod demonstrated superior performance compared to existing one-shot\nfederated learning methods in healthcare scenarios across four datasets with\nvarious data distributions. For instance, it surpasses existing one-shot\nfederated learning approaches by more than 17.5% in accuracy on the RSNA\ndataset when applying a Dirichlet distribution with ($\\alpha$ = 0.3).", "paper_summary_zh": "\u8054\u90a6\u5b66\u4e60 (FL) \u7531\u4e8e\u5176\u5728\u7ef4\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u4fc3\u8fdb\u534f\u4f5c\u6a21\u578b\u8bad\u7ec3\u7684\u80fd\u529b\uff0c\u5728\u533b\u5b66\u9886\u57df\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5174\u8da3\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684 FL \u65b9\u6cd5\u901a\u5e38\u9700\u8981\u591a\u8f6e\u901a\u4fe1\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u901a\u4fe1\u5f00\u9500\u548c\u5ef6\u8fdf\uff0c\u5c24\u5176\u662f\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002\u5355\u6b21\u8054\u90a6\u5b66\u4e60\u901a\u8fc7\u5728\u5355\u6b21\u901a\u4fe1\u8f6e\u4e2d\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u548c\u805a\u5408\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ece\u800c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002\u5176\u4e2d\uff0c\u5355\u6b21\u8054\u90a6\u96c6\u6210\u5b66\u4e60\u4f7f\u7528\u96c6\u6210\u6280\u672f\uff08\u5982\u6295\u7968\uff09\u5c06\u72ec\u7acb\u8bad\u7ec3\u7684\u5ba2\u6237\u7aef\u6a21\u578b\u7ec4\u5408\u8d77\u6765\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5728\u975e IID \u6570\u636e\u573a\u666f\u4e2d\u7684\u6027\u80fd\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u73b0\u6709\u7684\u533b\u7597\u4fdd\u5065\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f7f\u7528\u5355\u6a21\u6001\u6570\u636e\uff08\u4f8b\u5982\u533b\u5b66\u56fe\u50cf\u6216\u6587\u672c\u62a5\u544a\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u8bca\u65ad\u51c6\u786e\u6027\u548c\u5168\u9762\u6027\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u6570\u636e\u7684\u96c6\u6210\u6765\u89e3\u51b3\u8fd9\u4e9b\u7f3a\u70b9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 FedMME\uff0c\u4e00\u79cd\u521b\u65b0\u7684\u5355\u6b21\u591a\u6a21\u6001\u8054\u90a6\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u8fdb\u884c\u533b\u5b66\u56fe\u50cf\u5206\u6790\u3002\u5177\u4f53\u6765\u8bf4\uff0cFedMME \u5229\u7528\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u533b\u5b66\u56fe\u50cf\u4e2d\u751f\u6210\u6587\u672c\u62a5\u544a\uff0c\u91c7\u7528 BERT \u6a21\u578b\u4ece\u8fd9\u4e9b\u62a5\u544a\u4e2d\u63d0\u53d6\u6587\u672c\u7279\u5f81\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7279\u5f81\u4e0e\u89c6\u89c9\u7279\u5f81\u76f8\u7ed3\u5408\u4ee5\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u5355\u6b21\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u56db\u4e2a\u5177\u6709\u4e0d\u540c\u6570\u636e\u5206\u5e03\u7684\u6570\u636e\u96c6\u4e2d\u7684\u533b\u7597\u4fdd\u5065\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5f53\u5e94\u7528\u5177\u6709 ($\\alpha$ = 0.3) \u7684 Dirichlet \u5206\u5e03\u65f6\uff0c\u5b83\u5728 RSNA \u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u7684\u5355\u6b21\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u9ad8\u51fa 17.5% \u4ee5\u4e0a\u3002", "author": "Naibo Wang et.al.", "authors": "Naibo Wang, Yuchen Deng, Shichen Fan, Jianwei Yin, See-Kiong Ng", "id": "2501.03292v1", "paper_url": "http://arxiv.org/abs/2501.03292v1", "repo": "null"}}