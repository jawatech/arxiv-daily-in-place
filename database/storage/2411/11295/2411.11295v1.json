{"2411.11295": {"publish_time": "2024-11-18", "title": "Transcending Language Boundaries: Harnessing LLMs for Low-Resource Language Translation", "paper_summary": "Large Language Models (LLMs) have demonstrated remarkable success across a\nwide range of tasks and domains. However, their performance in low-resource\nlanguage translation, particularly when translating into these languages,\nremains underexplored. This gap poses significant challenges, as linguistic\nbarriers hinder the cultural preservation and development of minority\ncommunities. To address this issue, this paper introduces a novel\nretrieval-based method that enhances translation quality for low-resource\nlanguages by focusing on key terms, which involves translating keywords and\nretrieving corresponding examples from existing data. To evaluate the\neffectiveness of this method, we conducted experiments translating from English\ninto three low-resource languages: Cherokee, a critically endangered indigenous\nlanguage of North America; Tibetan, a historically and culturally significant\nlanguage in Asia; and Manchu, a language with few remaining speakers. Our\ncomparison with the zero-shot performance of GPT-4o and LLaMA 3.1 405B,\nhighlights the significant challenges these models face when translating into\nlow-resource languages. In contrast, our retrieval-based method shows promise\nin improving both word-level accuracy and overall semantic understanding by\nleveraging existing resources more effectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u5728\u5ee3\u6cdb\u4efb\u52d9\u8207\u9818\u57df\u7684\u5353\u8d8a\u6210\u5c31\u3002\u7136\u800c\uff0c\u5b83\u5011\u5728\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7ffb\u8b6f\u65b9\u9762\u7684\u8868\u73fe\uff0c\u7279\u5225\u662f\u7ffb\u8b6f\u6210\u9019\u4e9b\u8a9e\u8a00\u6642\uff0c\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7684\u63a2\u7d22\u3002\u7531\u65bc\u8a9e\u8a00\u969c\u7919\u963b\u7919\u4e86\u5c11\u6578\u65cf\u7fa4\u7684\u6587\u5316\u4fdd\u5b58\u548c\u767c\u5c55\uff0c\u56e0\u6b64\u9019\u500b\u5dee\u8ddd\u5e36\u4f86\u4e86\u91cd\u5927\u7684\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u57fa\u65bc\u6aa2\u7d22\u7684\u65b9\u6cd5\uff0c\u900f\u904e\u5c08\u6ce8\u65bc\u95dc\u9375\u8853\u8a9e\u4f86\u589e\u5f37\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7684\u7ffb\u8b6f\u54c1\u8cea\uff0c\u9019\u5305\u62ec\u7ffb\u8b6f\u95dc\u9375\u5b57\u548c\u5f9e\u73fe\u6709\u8cc7\u6599\u4e2d\u6aa2\u7d22\u5c0d\u61c9\u7684\u7bc4\u4f8b\u3002\u70ba\u4e86\u8a55\u4f30\u9019\u7a2e\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u9032\u884c\u4e86\u5f9e\u82f1\u8a9e\u7ffb\u8b6f\u6210\u4e09\u7a2e\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7684\u5be6\u9a57\uff1a\u5207\u7f85\u57fa\u8a9e\uff0c\u4e00\u7a2e\u7015\u81e8\u6ec5\u7d55\u7684\u5317\u7f8e\u539f\u4f4f\u6c11\u8a9e\u8a00\uff1b\u85cf\u8a9e\uff0c\u4e00\u7a2e\u5728\u4e9e\u6d32\u5177\u6709\u6b77\u53f2\u548c\u6587\u5316\u610f\u7fa9\u7684\u8a9e\u8a00\uff1b\u4ee5\u53ca\u6eff\u8a9e\uff0c\u4e00\u7a2e\u5269\u9918\u7684\u4f7f\u7528\u8005\u5f88\u5c11\u7684\u8a9e\u8a00\u3002\u6211\u5011\u8207 GPT-4o \u548c LLaMA 3.1 405B \u7684\u96f6\u6b21\u5b78\u7fd2\u8868\u73fe\u9032\u884c\u6bd4\u8f03\uff0c\u5f37\u8abf\u4e86\u9019\u4e9b\u6a21\u578b\u5728\u7ffb\u8b6f\u6210\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u6642\u6240\u9762\u81e8\u7684\u91cd\u5927\u6311\u6230\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6211\u5011\u7684\u57fa\u65bc\u6aa2\u7d22\u7684\u65b9\u6cd5\u986f\u793a\u51fa\u900f\u904e\u66f4\u6709\u6548\u5730\u5229\u7528\u73fe\u6709\u8cc7\u6e90\u4f86\u6539\u5584\u8a5e\u5f59\u5c64\u7d1a\u7684\u6e96\u78ba\u5ea6\u548c\u6574\u9ad4\u8a9e\u7fa9\u7406\u89e3\u7684\u6f5b\u529b\u3002", "author": "Peng Shu et.al.", "authors": "Peng Shu, Junhao Chen, Zhengliang Liu, Hui Wang, Zihao Wu, Tianyang Zhong, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Constance Owl, Xiaoming Zhai, Ninghao Liu, Claudio Saunt, Tianming Liu", "id": "2411.11295v1", "paper_url": "http://arxiv.org/abs/2411.11295v1", "repo": "null"}}