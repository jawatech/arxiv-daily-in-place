{"2209.06528": {"publish_time": "2022-09-14", "title": "Explainable AI for clinical and remote health applications: a survey on tabular and time series data", "paper_summary": "Nowadays Artificial Intelligence (AI) has become a fundamental component of\nhealthcare applications, both clinical and remote, but the best performing AI\nsystems are often too complex to be self-explaining. Explainable AI (XAI)\ntechniques are defined to unveil the reasoning behind the system's predictions\nand decisions, and they become even more critical when dealing with sensitive\nand personal health data. It is worth noting that XAI has not gathered the same\nattention across different research areas and data types, especially in\nhealthcare. In particular, many clinical and remote health applications are\nbased on tabular and time series data, respectively, and XAI is not commonly\nanalysed on these data types, while computer vision and Natural Language\nProcessing (NLP) are the reference applications. To provide an overview of XAI\nmethods that are most suitable for tabular and time series data in the\nhealthcare domain, this paper provides a review of the literature in the last 5\nyears, illustrating the type of generated explanations and the efforts provided\nto evaluate their relevance and quality. Specifically, we identify clinical\nvalidation, consistency assessment, objective and standardised quality\nevaluation, and human-centered quality assessment as key features to ensure\neffective explanations for the end users. Finally, we highlight the main\nresearch challenges in the field as well as the limitations of existing XAI\nmethods.", "paper_summary_zh": "", "author": "Flavio Di Martino et.al.", "authors": "Flavio Di Martino,Franca Delmastro", "id": "2209.06528v1", "paper_url": "http://arxiv.org/abs/2209.06528v1", "repo": "null"}}