{"2404.10429": {"publish_time": "2024-04-16", "title": "MEEL: Multi-Modal Event Evolution Learning", "paper_summary": "Multi-modal Event Reasoning (MMER) endeavors to endow machines with the\nability to comprehend intricate event relations across diverse data modalities.\nMMER is fundamental and underlies a wide broad of applications. Despite\nextensive instruction fine-tuning, current multi-modal large language models\nstill fall short in such ability. The disparity stems from that existing models\nare insufficient to capture underlying principles governing event evolution in\nvarious scenarios. In this paper, we introduce Multi-Modal Event Evolution\nLearning (MEEL) to enable the model to grasp the event evolution mechanism,\nyielding advanced MMER ability. Specifically, we commence with the design of\nevent diversification to gather seed events from a rich spectrum of scenarios.\nSubsequently, we employ ChatGPT to generate evolving graphs for these seed\nevents. We propose an instruction encapsulation process that formulates the\nevolving graphs into instruction-tuning data, aligning the comprehension of\nevent reasoning to humans. Finally, we observe that models trained in this way\nare still struggling to fully comprehend event evolution. In such a case, we\npropose the guiding discrimination strategy, in which models are trained to\ndiscriminate the improper evolution direction. We collect and curate a\nbenchmark M-EV2 for MMER. Extensive experiments on M-EV2 validate the\neffectiveness of our approach, showcasing competitive performance in\nopen-source multi-modal LLMs.", "paper_summary_zh": "\u591a\u6a21\u6001\u4e8b\u4ef6\u63a8\u7406 (MMER) \u81f4\u529b\u4e8e\u8d4b\u4e88\u673a\u5668\u8de8\u8d8a\u4e0d\u540c\u6570\u636e\u6a21\u6001\u7406\u89e3\u590d\u6742\u4e8b\u4ef6\u5173\u7cfb\u7684\u80fd\u529b\u3002MMER \u662f\u57fa\u7840\uff0c\u5e76\u4e14\u662f\u5e7f\u6cdb\u5e94\u7528\u7a0b\u5e8f\u7684\u57fa\u7840\u3002\u5c3d\u7ba1\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6307\u4ee4\u5fae\u8c03\uff0c\u4f46\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u6837\u7684\u80fd\u529b\u4e0a\u4ecd\u7136\u4e0d\u8db3\u3002\u8fd9\u79cd\u5dee\u5f02\u6e90\u4e8e\u73b0\u6709\u6a21\u578b\u4e0d\u8db3\u4ee5\u6355\u6349\u5404\u79cd\u573a\u666f\u4e2d\u652f\u914d\u4e8b\u4ef6\u6f14\u5316\u7684\u57fa\u672c\u539f\u7406\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u591a\u6a21\u6001\u4e8b\u4ef6\u6f14\u5316\u5b66\u4e60 (MEEL)\uff0c\u4ee5\u4f7f\u6a21\u578b\u80fd\u591f\u638c\u63e1\u4e8b\u4ef6\u6f14\u5316\u673a\u5236\uff0c\u4ece\u800c\u4ea7\u751f\u5148\u8fdb\u7684 MMER \u80fd\u529b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u4ece\u4e8b\u4ef6\u591a\u6837\u5316\u8bbe\u8ba1\u5f00\u59cb\uff0c\u4ece\u4e30\u5bcc\u7684\u573a\u666f\u4e2d\u6536\u96c6\u79cd\u5b50\u4e8b\u4ef6\u3002\u968f\u540e\uff0c\u6211\u4eec\u4f7f\u7528 ChatGPT \u4e3a\u8fd9\u4e9b\u79cd\u5b50\u4e8b\u4ef6\u751f\u6210\u6f14\u5316\u56fe\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u6307\u4ee4\u5c01\u88c5\u8fc7\u7a0b\uff0c\u5c06\u6f14\u5316\u56fe\u5236\u5b9a\u4e3a\u6307\u4ee4\u5fae\u8c03\u6570\u636e\uff0c\u4f7f\u4e8b\u4ef6\u63a8\u7406\u7684\u7406\u89e3\u4e0e\u4eba\u7c7b\u4fdd\u6301\u4e00\u81f4\u3002\u6700\u540e\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u4ee5\u8fd9\u79cd\u65b9\u5f0f\u8bad\u7ec3\u7684\u6a21\u578b\u4ecd\u7136\u96be\u4ee5\u5b8c\u5168\u7406\u89e3\u4e8b\u4ef6\u6f14\u5316\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6307\u5bfc\u6027\u6b67\u89c6\u7b56\u7565\uff0c\u5176\u4e2d\u6a21\u578b\u88ab\u8bad\u7ec3\u6765\u533a\u5206\u4e0d\u5f53\u7684\u6f14\u5316\u65b9\u5411\u3002\u6211\u4eec\u6536\u96c6\u5e76\u6574\u7406\u4e86 MMER \u7684\u57fa\u51c6 M-EV2\u3002\u5728 M-EV2 \u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5728\u5f00\u6e90\u591a\u6a21\u6001 LLM \u4e2d\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "author": "Zhengwei Tao et.al.", "authors": "Zhengwei Tao, Zhi Jin, Junqiang Huang, Xiancai Chen, Xiaoying Bai, Haiyan Zhao, Yifan Zhang, Chongyang Tao", "id": "2404.10429v1", "paper_url": "http://arxiv.org/abs/2404.10429v1", "repo": "https://github.com/tzwwww/meel"}}