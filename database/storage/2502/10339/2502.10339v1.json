{"2502.10339": {"publish_time": "2025-02-14", "title": "STAR: Spectral Truncation and Rescale for Model Merging", "paper_summary": "Model merging is an efficient way of obtaining a multi-task model from\nseveral pretrained models without further fine-tuning, and it has gained\nattention in various domains, including natural language processing (NLP).\nDespite the efficiency, a key challenge in model merging is the seemingly\ninevitable decrease in task performance as the number of models increases. In\nthis paper, we propose $\\mathbf{S}$pectral $\\mathbf{T}$runcation $\\mathbf{A}$nd\n$\\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' by\ntruncating small components in the respective spectral spaces, which is\nfollowed by an automatic parameter rescaling scheme to retain the nuclear norm\nof the original matrix. STAR requires no additional inference on original\ntraining data and is robust to hyperparamater choice. We demonstrate the\neffectiveness of STAR through extensive model merging cases on diverse NLP\ntasks. Specifically, STAR works robustly across varying model sizes, and can\noutperform baselines by 4.2$\\%$ when merging 12 models on Flan-T5. Our code is\npublicly available at https://github.com/IBM/STAR.", "paper_summary_zh": "\u6a21\u578b\u5408\u4f75\u662f\u4e00\u7a2e\u5f9e\u591a\u500b\u9810\u8a13\u7df4\u6a21\u578b\u4e2d\u53d6\u5f97\u591a\u4efb\u52d9\u6a21\u578b\u7684\u6709\u6548\u65b9\u5f0f\uff0c\u7121\u9700\u9032\u4e00\u6b65\u5fae\u8abf\uff0c\u4e14\u5728\u5404\u7a2e\u9818\u57df\u4e2d\u53d7\u5230\u95dc\u6ce8\uff0c\u5305\u62ec\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP)\u3002\u5118\u7ba1\u6548\u7387\u9ad8\uff0c\u6a21\u578b\u5408\u4f75\u4e2d\u7684\u4e3b\u8981\u6311\u6230\u5728\u65bc\u96a8\u8457\u6a21\u578b\u6578\u91cf\u589e\u52a0\uff0c\u4efb\u52d9\u57f7\u884c\u6548\u80fd\u4f3c\u4e4e\u4e0d\u53ef\u907f\u514d\u5730\u4e0b\u964d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa $\\mathbf{S}$pectral $\\mathbf{T}$runcation $\\mathbf{A}$nd $\\mathbf{R}$escale (STAR)\uff0c\u5176\u76ee\u6a19\u5728\u65bc\u900f\u904e\u622a\u65b7\u5404\u500b\u7279\u5fb5\u7a7a\u9593\u4e2d\u7684\u5c0f\u7d44\u6210\uff0c\u4f86\u6e1b\u8f15\u300c\u5408\u4f75\u885d\u7a81\u300d\uff0c\u63a5\u8457\u4f7f\u7528\u81ea\u52d5\u53c3\u6578\u7e2e\u653e\u6a5f\u5236\u4f86\u4fdd\u7559\u539f\u59cb\u77e9\u9663\u7684\u6838\u7bc4\u6578\u3002STAR \u4e0d\u9700\u8981\u5c0d\u539f\u59cb\u8a13\u7df4\u8cc7\u6599\u9032\u884c\u984d\u5916\u7684\u63a8\u8ad6\uff0c\u4e14\u5c0d\u65bc\u8d85\u53c3\u6578\u9078\u64c7\u5177\u6709\u7a69\u5065\u6027\u3002\u6211\u5011\u900f\u904e\u5728\u5404\u7a2e NLP \u4efb\u52d9\u4e2d\u9032\u884c\u5ee3\u6cdb\u7684\u6a21\u578b\u5408\u4f75\u6848\u4f8b\uff0c\u4f86\u8b49\u660e STAR \u7684\u6709\u6548\u6027\u3002\u5177\u9ad4\u800c\u8a00\uff0cSTAR \u5728\u5404\u7a2e\u6a21\u578b\u5927\u5c0f\u4e2d\u90fd\u80fd\u7a69\u5065\u5730\u904b\u4f5c\uff0c\u4e26\u4e14\u5728 Flan-T5 \u4e0a\u5408\u4f75 12 \u500b\u6a21\u578b\u6642\uff0c\u53ef\u4ee5\u6bd4\u57fa\u6e96\u9ad8\u51fa 4.2%\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc https://github.com/IBM/STAR\u3002", "author": "Yu-Ang Lee et.al.", "authors": "Yu-Ang Lee, Ching-Yun Ko, Tejaswini Pedapati, I-Hsin Chung, Mi-Yen Yeh, Pin-Yu Chen", "id": "2502.10339v1", "paper_url": "http://arxiv.org/abs/2502.10339v1", "repo": "null"}}