{"2410.23494": {"publish_time": "2024-10-30", "title": "Causality-Driven Audits of Model Robustness", "paper_summary": "Robustness audits of deep neural networks (DNN) provide a means to uncover\nmodel sensitivities to the challenging real-world imaging conditions that\nsignificantly degrade DNN performance in-the-wild. Such conditions are often\nthe result of the compounding of multiple factors inherent to the environment,\nsensor, or processing pipeline and may lead to complex image distortions that\nare not easily categorized. When robustness audits are limited to a set of\npre-determined imaging effects or distortions, the results cannot be (easily)\ntransferred to real-world conditions where image corruptions may be more\ncomplex or nuanced. To address this challenge, we present a new alternative\nrobustness auditing method that uses causal inference to measure DNN\nsensitivities to the factors of the imaging process that cause complex\ndistortions. Our approach uses causal models to explicitly encode assumptions\nabout the domain-relevant factors and their interactions. Then, through\nextensive experiments on natural and rendered images across multiple vision\ntasks, we show that our approach reliably estimates causal effects of each\nfactor on DNN performance using observational domain data. These causal effects\ndirectly tie DNN sensitivities to observable properties of the imaging pipeline\nin the domain of interest towards reducing the risk of unexpected DNN failures\nwhen deployed in that domain.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc (DNN) \u7684\u7a33\u5065\u6027\u5ba1\u6838\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u63ed\u793a\u6a21\u578b\u5bf9\u5177\u6709\u6311\u6218\u6027\u7684\u73b0\u5b9e\u4e16\u754c\u6210\u50cf\u6761\u4ef6\u7684\u654f\u611f\u6027\uff0c\u8fd9\u4e9b\u6761\u4ef6\u4f1a\u663e\u8457\u964d\u4f4e DNN \u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u6b64\u7c7b\u6761\u4ef6\u901a\u5e38\u662f\u73af\u5883\u3001\u4f20\u611f\u5668\u6216\u5904\u7406\u7ba1\u9053\u4e2d\u56fa\u6709\u7684\u591a\u4e2a\u56e0\u7d20\u5171\u540c\u4f5c\u7528\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u53ef\u80fd\u5bfc\u81f4\u96be\u4ee5\u5206\u7c7b\u7684\u590d\u6742\u56fe\u50cf\u5931\u771f\u3002\u5f53\u7a33\u5065\u6027\u5ba1\u6838\u4ec5\u9650\u4e8e\u4e00\u7ec4\u9884\u5148\u786e\u5b9a\u7684\u6210\u50cf\u6548\u679c\u6216\u5931\u771f\u65f6\uff0c\u7ed3\u679c\u65e0\u6cd5\uff08\u8f7b\u677e\uff09\u8f6c\u79fb\u5230\u56fe\u50cf\u635f\u574f\u53ef\u80fd\u66f4\u590d\u6742\u6216\u7ec6\u5fae\u5dee\u522b\u66f4\u5927\u7684\u5b9e\u9645\u6761\u4ef6\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u66ff\u4ee3\u7a33\u5065\u6027\u5ba1\u6838\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u56e0\u679c\u63a8\u7406\u6765\u8861\u91cf DNN \u5bf9\u5bfc\u81f4\u590d\u6742\u5931\u771f\u7684\u6210\u50cf\u8fc7\u7a0b\u56e0\u7d20\u7684\u654f\u611f\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u56e0\u679c\u6a21\u578b\u6765\u660e\u786e\u7f16\u7801\u6709\u5173\u9886\u57df\u76f8\u5173\u56e0\u7d20\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u7684\u5047\u8bbe\u3002\u7136\u540e\uff0c\u901a\u8fc7\u5bf9\u8de8\u591a\u4e2a\u89c6\u89c9\u4efb\u52a1\u7684\u81ea\u7136\u548c\u6e32\u67d3\u56fe\u50cf\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u8868\u660e\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u89c2\u6d4b\u57df\u6570\u636e\u53ef\u9760\u5730\u4f30\u8ba1\u4e86\u6bcf\u4e2a\u56e0\u7d20\u5bf9 DNN \u6027\u80fd\u7684\u56e0\u679c\u6548\u5e94\u3002\u8fd9\u4e9b\u56e0\u679c\u6548\u5e94\u5c06 DNN \u654f\u611f\u6027\u76f4\u63a5\u4e0e\u611f\u5174\u8da3\u57df\u4e2d\u6210\u50cf\u7ba1\u9053\u7684\u53ef\u89c2\u5bdf\u5c5e\u6027\u8054\u7cfb\u8d77\u6765\uff0c\u4ee5\u964d\u4f4e\u5728\u8be5\u57df\u4e2d\u90e8\u7f72\u65f6\u610f\u5916 DNN \u6545\u969c\u7684\u98ce\u9669\u3002", "author": "Nathan Drenkow et.al.", "authors": "Nathan Drenkow, Chris Ribaudo, Mathias Unberath", "id": "2410.23494v1", "paper_url": "http://arxiv.org/abs/2410.23494v1", "repo": "null"}}