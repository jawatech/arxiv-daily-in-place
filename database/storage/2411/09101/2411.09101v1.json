{"2411.09101": {"publish_time": "2024-11-14", "title": "Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery", "paper_summary": "Vision Transformers (ViT) have recently brought a new wave of research in the\nfield of computer vision. These models have done particularly well in the field\nof image classification and segmentation. Research on semantic and instance\nsegmentation has emerged to accelerate with the inception of the new\narchitecture, with over 80\\% of the top 20 benchmarks for the iSAID dataset\nbeing either based on the ViT architecture or the attention mechanism behind\nits success. This paper focuses on the heuristic comparison of three key\nfactors of using (or not using) ViT for semantic segmentation of remote sensing\naerial images on the iSAID. The experimental results observed during the course\nof the research were under the scrutinization of the following objectives: 1.\nUse of weighted fused loss function for the maximum mean Intersection over\nUnion (mIoU) score, Dice score, and minimization or conservation of entropy or\nclass representation, 2. Comparison of transfer learning on Meta's MaskFormer,\na ViT-based semantic segmentation model, against generic UNet Convolutional\nNeural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, and\ninference time, and 3. What do we lose for what we gain? i.e., the comparison\nof the two models against current state-of-art segmentation models. We show the\nuse of the novel combined weighted loss function significantly boosts the CNN\nmodel's performance capacities as compared to transfer learning the ViT. The\ncode for this implementation can be found on\n\\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}.", "paper_summary_zh": "\u8996\u89baTransformer (ViT) \u8fd1\u671f\u70ba\u96fb\u8166\u8996\u89ba\u9818\u57df\u5e36\u4f86\u4e86\u65b0\u4e00\u6ce2\u7814\u7a76\u71b1\u6f6e\u3002\u9019\u4e9b\u6a21\u578b\u5728\u5f71\u50cf\u5206\u985e\u548c\u5206\u5272\u9818\u57df\u8868\u73fe\u7279\u5225\u51fa\u8272\u3002\u8a9e\u610f\u548c\u5be6\u4f8b\u5206\u5272\u7684\u7814\u7a76\u5728\u9019\u500b\u65b0\u67b6\u69cb\u51fa\u73fe\u5f8c\u52a0\u901f\u767c\u5c55\uff0c\u5728 iSAID \u8cc7\u6599\u96c6\u7684 20 \u500b\u9802\u5c16\u57fa\u6e96\u4e2d\uff0c\u6709\u8d85\u904e 80% \u662f\u57fa\u65bc ViT \u67b6\u69cb\u6216\u5176\u6210\u529f\u80cc\u5f8c\u7684\u6ce8\u610f\u529b\u6a5f\u5236\u3002\u672c\u6587\u91cd\u9ede\u6bd4\u8f03\u4e09\u500b\u95dc\u9375\u56e0\u7d20\uff0c\u63a2\u8a0e\u5728 iSAID \u4e0a\u4f7f\u7528 (\u6216\u4e0d\u4f7f\u7528) ViT \u9032\u884c\u9059\u6e2c\u822a\u7167\u5f71\u50cf\u8a9e\u610f\u5206\u5272\u7684\u555f\u767c\u5f0f\u65b9\u6cd5\u3002\u7814\u7a76\u904e\u7a0b\u4e2d\u89c0\u5bdf\u5230\u7684\u5be6\u9a57\u7d50\u679c\u7d93\u904e\u4ee5\u4e0b\u76ee\u6a19\u7684\u4ed4\u7d30\u6aa2\u8996\uff1a1. \u4f7f\u7528\u52a0\u6b0a\u878d\u5408\u640d\u5931\u51fd\u6578\uff0c\u4ee5\u53d6\u5f97\u6700\u5927\u7684\u5e73\u5747\u4ea4\u96c6\u4e26\u806f (mIoU) \u5206\u6578\u3001Dice \u5206\u6578\uff0c\u4ee5\u53ca\u6700\u5c0f\u5316\u6216\u4fdd\u5b58\u71b5\u6216\u985e\u5225\u8868\u793a\uff1b2. \u6bd4\u8f03\u5728 Meta \u7684 MaskFormer\uff08\u4e00\u500b\u57fa\u65bc ViT \u7684\u8a9e\u610f\u5206\u5272\u6a21\u578b\uff09\u4e0a\u9032\u884c\u9077\u79fb\u5b78\u7fd2\uff0c\u4ee5\u53ca\u5728\u901a\u7528 UNet \u6372\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u4e0a\u9032\u884c\u9077\u79fb\u5b78\u7fd2\uff0c\u4e26\u6839\u64da mIoU\u3001Dice \u5206\u6578\u3001\u8a13\u7df4\u6548\u7387\u548c\u63a8\u8ad6\u6642\u9593\u9032\u884c\u8a55\u65b7\uff1b\u4ee5\u53ca 3. \u6211\u5011\u70ba\u4e86\u7372\u5f97\u4ec0\u9ebc\u800c\u5931\u53bb\u4e86\u4ec0\u9ebc\uff1f\u4e5f\u5c31\u662f\u8aaa\uff0c\u6bd4\u8f03\u9019\u5169\u500b\u6a21\u578b\u8207\u76ee\u524d\u6700\u5148\u9032\u7684\u5206\u5272\u6a21\u578b\u3002\u6211\u5011\u5c55\u793a\u4e86\u4f7f\u7528\u65b0\u7a4e\u7684\u7d50\u5408\u52a0\u6b0a\u640d\u5931\u51fd\u6578\uff0c\u5927\u5e45\u63d0\u5347\u4e86 CNN \u6a21\u578b\u7684\u6548\u80fd\uff0c\u76f8\u8f03\u65bc\u9077\u79fb\u5b78\u7fd2 ViT\u3002\u9019\u500b\u5be6\u4f5c\u7684\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 \\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation} \u627e\u5230\u3002", "author": "Ashim Dahal et.al.", "authors": "Ashim Dahal, Saydul Akbar Murad, Nick Rahimi", "id": "2411.09101v1", "paper_url": "http://arxiv.org/abs/2411.09101v1", "repo": "null"}}