{"2408.05211": {"publish_time": "2024-08-09", "title": "VITA: Towards Open-Source Interactive Omni Multimodal LLM", "paper_summary": "The remarkable multimodal capabilities and interactive experience of GPT-4o\nunderscore their necessity in practical applications, yet open-source models\nrarely excel in both areas. In this paper, we introduce VITA, the first-ever\nopen-source Multimodal Large Language Model (MLLM) adept at simultaneous\nprocessing and analysis of Video, Image, Text, and Audio modalities, and\nmeanwhile has an advanced multimodal interactive experience. Starting from\nMixtral 8x7B as a language foundation, we expand its Chinese vocabulary\nfollowed by bilingual instruction tuning. We further endow the language model\nwith visual and audio capabilities through two-stage multi-task learning of\nmultimodal alignment and instruction tuning. VITA demonstrates robust\nfoundational capabilities of multilingual, vision, and audio understanding, as\nevidenced by its strong performance across a range of both unimodal and\nmultimodal benchmarks. Beyond foundational capabilities, we have made\nconsiderable progress in enhancing the natural multimodal human-computer\ninteraction experience. To the best of our knowledge, we are the first to\nexploit non-awakening interaction and audio interrupt in MLLM. VITA is the\nfirst step for the open-source community to explore the seamless integration of\nmultimodal understanding and interaction. While there is still lots of work to\nbe done on VITA to get close to close-source counterparts, we hope that its\nrole as a pioneer can serve as a cornerstone for subsequent research. Project\nPage: https://vita-home.github.io.", "paper_summary_zh": "GPT-4o \u51fa\u8272\u7684\u591a\u6a21\u614b\u80fd\u529b\u548c\u4e92\u52d5\u9ad4\u9a57\u7a81\u986f\u4e86\u5b83\u5011\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u4f46\u958b\u6e90\u6a21\u578b\u5f88\u5c11\u5728\u9019\u5169\u500b\u9818\u57df\u90fd\u8868\u73fe\u51fa\u8272\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 VITA\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u958b\u6e90\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM)\uff0c\u64c5\u9577\u540c\u6642\u8655\u7406\u548c\u5206\u6790\u5f71\u7247\u3001\u5f71\u50cf\u3001\u6587\u5b57\u548c\u97f3\u8a0a\u6a21\u614b\uff0c\u540c\u6642\u5177\u5099\u5148\u9032\u7684\u591a\u6a21\u614b\u4e92\u52d5\u9ad4\u9a57\u3002\u6211\u5011\u4ee5 Mixtral 8x7B \u70ba\u8a9e\u8a00\u57fa\u790e\uff0c\u64f4\u5145\u5176\u4e2d\u6587\u8a5e\u5f59\uff0c\u7136\u5f8c\u9032\u884c\u96d9\u8a9e\u6307\u4ee4\u5fae\u8abf\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e\u591a\u6a21\u614b\u5c0d\u9f4a\u548c\u6307\u4ee4\u5fae\u8abf\u7684\u5169\u968e\u6bb5\u591a\u4efb\u52d9\u5b78\u7fd2\uff0c\u8ce6\u4e88\u8a9e\u8a00\u6a21\u578b\u8996\u89ba\u548c\u97f3\u8a0a\u529f\u80fd\u3002VITA \u5c55\u73fe\u4e86\u591a\u8a9e\u8a00\u3001\u8996\u89ba\u548c\u97f3\u8a0a\u7406\u89e3\u7684\u7a69\u5065\u57fa\u790e\u80fd\u529b\uff0c\u9019\u5f9e\u5176\u5728\u5404\u7a2e\u55ae\u6a21\u614b\u548c\u591a\u6a21\u614b\u57fa\u6e96\u4e2d\u7684\u51fa\u8272\u8868\u73fe\u4e2d\u5f97\u5230\u8b49\u660e\u3002\u9664\u4e86\u57fa\u790e\u80fd\u529b\u4e4b\u5916\uff0c\u6211\u5011\u5728\u589e\u5f37\u81ea\u7136\u7684\u591a\u6a21\u614b\u4eba\u6a5f\u4e92\u52d5\u9ad4\u9a57\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u6211\u5011\u662f\u7b2c\u4e00\u500b\u5728 MLLM \u4e2d\u5229\u7528\u975e\u559a\u9192\u4e92\u52d5\u548c\u97f3\u8a0a\u4e2d\u65b7\u7684\u4eba\u3002VITA \u662f\u958b\u6e90\u793e\u7fa4\u63a2\u7d22\u591a\u6a21\u614b\u7406\u89e3\u548c\u4e92\u52d5\u7121\u7e2b\u6574\u5408\u7684\u7b2c\u4e00\u6b65\u3002\u96d6\u7136 VITA \u4ecd\u6709\u8a31\u591a\u5de5\u4f5c\u8981\u505a\u624d\u80fd\u63a5\u8fd1\u5c01\u9589\u539f\u59cb\u78bc\u7684\u5c0d\u61c9\u7a0b\u5f0f\uff0c\u4f46\u6211\u5011\u5e0c\u671b\u5b83\u4f5c\u70ba\u5148\u9a45\u7684\u89d2\u8272\u53ef\u4ee5\u4f5c\u70ba\u5f8c\u7e8c\u7814\u7a76\u7684\u57fa\u77f3\u3002\u5c08\u6848\u9801\u9762\uff1ahttps://vita-home.github.io\u3002", "author": "Chaoyou Fu et.al.", "authors": "Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun", "id": "2408.05211v1", "paper_url": "http://arxiv.org/abs/2408.05211v1", "repo": "null"}}