{"2410.18697": {"publish_time": "2024-10-24", "title": "How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs", "paper_summary": "Recent research has focused on literary machine translation (MT) as a new\nchallenge in MT. However, the evaluation of literary MT remains an open\nproblem. We contribute to this ongoing discussion by introducing\nLITEVAL-CORPUS, a paragraph-level parallel corpus comprising multiple verified\nhuman translations and outputs from 9 MT systems, which totals over 2k\nparagraphs and includes 13k annotated sentences across four language pairs,\ncosting 4.5k Euro. This corpus enables us to (i) examine the consistency and\nadequacy of multiple annotation schemes, (ii) compare evaluations by students\nand professionals, and (iii) assess the effectiveness of LLM-based metrics. We\nfind that Multidimensional Quality Metrics (MQM), as the de facto standard in\nnon-literary human MT evaluation, is inadequate for literary translation: While\nBest-Worst Scaling (BWS) with students and Scalar Quality Metric (SQM) with\nprofessional translators prefer human translations at rates of ~82% and ~94%,\nrespectively, MQM with student annotators prefers human professional\ntranslations over the translations of the best-performing LLMs in only ~42% of\ncases. While automatic metrics generally show a moderate correlation with human\nMQM and SQM, they struggle to accurately identify human translations, with\nrates of at most ~20%. Our overall evaluation indicates that human professional\ntranslations consistently outperform LLM translations, where even the most\nrecent LLMs tend to produce more literal and less diverse translations compared\nto human translations. However, newer LLMs such as GPT-4o perform substantially\nbetter than older ones.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u5c07\u6587\u5b78\u6a5f\u5668\u7ffb\u8b6f (MT) \u8996\u70ba\u6a5f\u5668\u7ffb\u8b6f\u7684\u65b0\u6311\u6230\u3002\u7136\u800c\uff0c\u6587\u5b78\u6a5f\u5668\u7ffb\u8b6f\u7684\u8a55\u4f30\u4ecd\u662f\u4e00\u500b\u672a\u89e3\u7684\u554f\u984c\u3002\u6211\u5011\u900f\u904e\u4ecb\u7d39 LITEVAL-CORPUS \u4f86\u70ba\u9019\u5834\u6301\u7e8c\u7684\u8a0e\u8ad6\u505a\u51fa\u8ca2\u737b\uff0c\u9019\u662f\u4e00\u500b\u6bb5\u843d\u7d1a\u5225\u7684\u5e73\u884c\u8a9e\u6599\u5eab\uff0c\u5305\u542b\u591a\u500b\u4eba\u5de5\u9a57\u8b49\u7684\u7ffb\u8b6f\u548c\u4f86\u81ea 9 \u500b\u6a5f\u5668\u7ffb\u8b6f\u7cfb\u7d71\u7684\u8f38\u51fa\uff0c\u7e3d\u8a08\u8d85\u904e 2k \u6bb5\u843d\uff0c\u4e26\u5305\u542b\u8de8\u8d8a\u56db\u7a2e\u8a9e\u8a00\u5c0d\u7684 13k \u500b\u8a3b\u91cb\u53e5\u5b50\uff0c\u8017\u8cc7 4.5k \u6b50\u5143\u3002\u9019\u500b\u8a9e\u6599\u5eab\u4f7f\u6211\u5011\u80fd\u5920 (i) \u6aa2\u67e5\u591a\u500b\u8a3b\u91cb\u65b9\u6848\u7684\u4e00\u81f4\u6027\u548c\u5145\u5206\u6027\uff0c(ii) \u6bd4\u8f03\u5b78\u751f\u548c\u5c08\u696d\u4eba\u58eb\u7684\u8a55\u4f30\uff0c\u4ee5\u53ca (iii) \u8a55\u4f30\u57fa\u65bc LLM \u7684\u6307\u6a19\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u767c\u73fe\uff0c\u591a\u7dad\u54c1\u8cea\u6307\u6a19 (MQM) \u4f5c\u70ba\u975e\u6587\u5b78\u4eba\u5de5\u6a5f\u5668\u7ffb\u8b6f\u8a55\u4f30\u4e2d\u7684\u4e8b\u5be6\u6a19\u6e96\uff0c\u5c0d\u65bc\u6587\u5b78\u7ffb\u8b6f\u662f\u4e0d\u5145\u5206\u7684\uff1a\u96d6\u7136\u8207\u5b78\u751f\u7684\u6700\u4f73-\u6700\u5dee\u7e2e\u653e (BWS) \u548c\u8207\u5c08\u696d\u7ffb\u8b6f\u4eba\u54e1\u7684\u6a19\u91cf\u54c1\u8cea\u6307\u6a19 (SQM) \u5206\u5225\u4ee5\u7d04 82% \u548c\u7d04 94% \u7684\u6bd4\u7387\u504f\u597d\u4eba\u5de5\u7ffb\u8b6f\uff0c\u4f46\u8207\u5b78\u751f\u8a3b\u89e3\u8005\u7684 MQM \u5728\u50c5\u7d04 42% \u7684\u60c5\u6cc1\u4e0b\u504f\u597d\u4eba\u5de5\u5c08\u696d\u7ffb\u8b6f\u800c\u975e\u6548\u80fd\u6700\u4f73\u7684 LLM \u7684\u7ffb\u8b6f\u3002\u96d6\u7136\u81ea\u52d5\u6307\u6a19\u901a\u5e38\u986f\u793a\u51fa\u8207\u4eba\u5de5 MQM \u548c SQM \u7684\u4e2d\u7b49\u76f8\u95dc\u6027\uff0c\u4f46\u5b83\u5011\u96e3\u4ee5\u6e96\u78ba\u8b58\u5225\u4eba\u5de5\u7ffb\u8b6f\uff0c\u8b58\u5225\u7387\u6700\u9ad8\u7d04\u70ba 20%\u3002\u6211\u5011\u7684\u6574\u9ad4\u8a55\u4f30\u8868\u660e\uff0c\u4eba\u5de5\u5c08\u696d\u7ffb\u8b6f\u59cb\u7d42\u512a\u65bc LLM \u7ffb\u8b6f\uff0c\u5176\u4e2d\u5373\u4f7f\u662f\u6700\u65b0\u7684 LLM \u4e5f\u50be\u5411\u65bc\u7522\u751f\u8207\u4eba\u5de5\u7ffb\u8b6f\u76f8\u6bd4\u66f4\u76f4\u8b6f\u4e14\u8f03\u4e0d\u591a\u5143\u7684\u7ffb\u8b6f\u3002\u7136\u800c\uff0c\u8f03\u65b0\u7684 LLM\uff08\u4f8b\u5982 GPT-4o\uff09\u7684\u8868\u73fe\u660e\u986f\u512a\u65bc\u8f03\u820a\u7684 LLM\u3002</paragraph>", "author": "Ran Zhang et.al.", "authors": "Ran Zhang, Wei Zhao, Steffen Eger", "id": "2410.18697v1", "paper_url": "http://arxiv.org/abs/2410.18697v1", "repo": "null"}}