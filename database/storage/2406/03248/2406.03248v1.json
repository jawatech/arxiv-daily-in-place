{"2406.03248": {"publish_time": "2024-06-05", "title": "Large Language Models as Evaluators for Recommendation Explanations", "paper_summary": "The explainability of recommender systems has attracted significant attention\nin academia and industry. Many efforts have been made for explainable\nrecommendations, yet evaluating the quality of the explanations remains a\nchallenging and unresolved issue. In recent years, leveraging LLMs as\nevaluators presents a promising avenue in Natural Language Processing tasks\n(e.g., sentiment classification, information extraction), as they perform\nstrong capabilities in instruction following and common-sense reasoning.\nHowever, evaluating recommendation explanatory texts is different from these\nNLG tasks, as its criteria are related to human perceptions and are usually\nsubjective. In this paper, we investigate whether LLMs can serve as evaluators\nof recommendation explanations. To answer the question, we utilize real user\nfeedback on explanations given from previous work and additionally collect\nthird-party annotations and LLM evaluations. We design and apply a 3-level meta\nevaluation strategy to measure the correlation between evaluator labels and the\nground truth provided by users. Our experiments reveal that LLMs, such as GPT4,\ncan provide comparable evaluations with appropriate prompts and settings. We\nalso provide further insights into combining human labels with the LLM\nevaluation process and utilizing ensembles of multiple heterogeneous LLM\nevaluators to enhance the accuracy and stability of evaluations. Our study\nverifies that utilizing LLMs as evaluators can be an accurate, reproducible and\ncost-effective solution for evaluating recommendation explanation texts. Our\ncode is available at https://github.com/Xiaoyu-SZ/LLMasEvaluator.", "paper_summary_zh": "\u63a8\u85a6\u7cfb\u7d71\u7684\u53ef\u89e3\u91cb\u6027\u5df2\u5728\u5b78\u8853\u754c\u548c\u7522\u696d\u4e2d\u5f15\u8d77\u5ee3\u6cdb\u95dc\u6ce8\u3002\u8a31\u591a\u52aa\u529b\u90fd\u81f4\u529b\u65bc\u53ef\u89e3\u91cb\u7684\u63a8\u85a6\uff0c\u7136\u800c\u8a55\u4f30\u89e3\u91cb\u54c1\u8cea\u4ecd\u7136\u662f\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u548c\u5c1a\u672a\u89e3\u6c7a\u7684\u554f\u984c\u3002\u8fd1\u5e74\u4f86\uff0c\u5229\u7528 LLM \u4f5c\u70ba\u8a55\u4f30\u8005\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\uff08\u4f8b\u5982\u60c5\u7dd2\u5206\u985e\u3001\u8cc7\u8a0a\u8403\u53d6\uff09\u4e2d\u63d0\u4f9b\u4e86\u4e00\u689d\u6709\u524d\u9014\u7684\u9014\u5f91\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u9075\u5faa\u6307\u4ee4\u548c\u5e38\u8b58\u63a8\u7406\u65b9\u9762\u8868\u73fe\u51fa\u5f37\u5927\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u8a55\u4f30\u63a8\u85a6\u8aaa\u660e\u6587\u5b57\u8207\u9019\u4e9b NLG \u4efb\u52d9\u4e0d\u540c\uff0c\u56e0\u70ba\u5b83\u7684\u6a19\u6e96\u8207\u4eba\u985e\u7684\u611f\u77e5\u6709\u95dc\uff0c\u800c\u4e14\u901a\u5e38\u662f\u4e3b\u89c0\u7684\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e LLM \u662f\u5426\u53ef\u4ee5\u4f5c\u70ba\u63a8\u85a6\u8aaa\u660e\u7684\u8a55\u4f30\u8005\u3002\u70ba\u4e86\u56de\u7b54\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5229\u7528\u771f\u5be6\u4f7f\u7528\u8005\u5c0d\u5148\u524d\u5de5\u4f5c\u63d0\u4f9b\u7684\u8aaa\u660e\u7684\u56de\u994b\uff0c\u4e26\u53e6\u5916\u6536\u96c6\u7b2c\u4e09\u65b9\u8a3b\u89e3\u548c LLM \u8a55\u4f30\u3002\u6211\u5011\u8a2d\u8a08\u4e26\u61c9\u7528\u4e86\u4e00\u500b 3 \u7d1a\u5143\u8a55\u4f30\u7b56\u7565\u4f86\u8861\u91cf\u8a55\u4f30\u8005\u6a19\u7c64\u8207\u4f7f\u7528\u8005\u63d0\u4f9b\u7684\u771f\u5be6\u8cc7\u6599\u4e4b\u9593\u7684\u95dc\u806f\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cLLM\uff08\u4f8b\u5982 GPT4\uff09\u53ef\u4ee5\u63d0\u4f9b\u5177\u6709\u9069\u7576\u63d0\u793a\u548c\u8a2d\u5b9a\u7684\u6bd4\u8f03\u8a55\u4f30\u3002\u6211\u5011\u9084\u9032\u4e00\u6b65\u6df1\u5165\u63a2\u8a0e\u5c07\u4eba\u985e\u6a19\u7c64\u8207 LLM \u8a55\u4f30\u904e\u7a0b\u76f8\u7d50\u5408\uff0c\u4e26\u5229\u7528\u591a\u500b\u7570\u8cea LLM \u8a55\u4f30\u8005\u7684\u96c6\u5408\u4f86\u63d0\u9ad8\u8a55\u4f30\u7684\u6e96\u78ba\u6027\u548c\u7a69\u5b9a\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u9a57\u8b49\u4e86\u5229\u7528 LLM \u4f5c\u70ba\u8a55\u4f30\u8005\u53ef\u4ee5\u6210\u70ba\u8a55\u4f30\u63a8\u85a6\u8aaa\u660e\u6587\u5b57\u7684\u6e96\u78ba\u3001\u53ef\u8907\u88fd\u4e14\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/Xiaoyu-SZ/LLMasEvaluator \u53d6\u5f97\u3002", "author": "Xiaoyu Zhang et.al.", "authors": "Xiaoyu Zhang, Yishan Li, Jiayin Wang, Bowen Sun, Weizhi Ma, Peijie Sun, Min Zhang", "id": "2406.03248v1", "paper_url": "http://arxiv.org/abs/2406.03248v1", "repo": "https://github.com/xiaoyu-sz/llmasevaluator"}}