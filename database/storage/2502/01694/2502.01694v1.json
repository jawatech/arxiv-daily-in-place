{"2502.01694": {"publish_time": "2025-02-02", "title": "Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation", "paper_summary": "A key paradigm to improve the reasoning capabilities of large language models\n(LLMs) is to allocate more inference-time compute to search against a verifier\nor reward model. This process can then be utilized to refine the pretrained\nmodel or distill its reasoning patterns into more efficient models. In this\npaper, we study inference-time compute by viewing chain-of-thought (CoT)\ngeneration as a metastable Markov process: easy reasoning steps (e.g.,\nalgebraic manipulations) form densely connected clusters, while hard reasoning\nsteps (e.g., applying a relevant theorem) create sparse, low-probability edges\nbetween clusters, leading to phase transitions at longer timescales. Under this\nframework, we prove that implementing a search protocol that rewards sparse\nedges improves CoT by decreasing the expected number of steps to reach\ndifferent clusters. In contrast, we establish a limit on reasoning capability\nwhen the model is restricted to local information of the pretrained graph. We\nalso show that the information gained by search can be utilized to obtain a\nbetter reasoning model: (1) the pretrained model can be directly finetuned to\nfavor sparse edges via policy gradient methods, and moreover (2) a compressed\nmetastable representation of the reasoning dynamics can be distilled into a\nsmaller, more efficient model.", "paper_summary_zh": "<paragraph>\u63d0\u5347\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63a8\u7406\u80fd\u529b\u7684\u4e00\u500b\u95dc\u9375\u7bc4\u4f8b\uff0c\u662f\u5206\u914d\u66f4\u591a\u63a8\u8ad6\u6642\u9593\u904b\u7b97\u4f86\u641c\u5c0b\u9a57\u8b49\u5668\u6216\u734e\u52f5\u6a21\u578b\u3002\u6b64\u7a0b\u5e8f\u63a5\u8457\u53ef\u7528\u65bc\u6539\u5584\u9810\u8a13\u7df4\u6a21\u578b\u6216\u5c07\u5176\u63a8\u7406\u6a21\u5f0f\u63d0\u7149\u5230\u66f4\u6709\u6548\u7387\u7684\u6a21\u578b\u4e2d\u3002\u5728\u9019\u7bc7\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5c07\u601d\u7dad\u93c8 (CoT) \u751f\u6210\u8996\u70ba\u4e9e\u7a69\u614b\u99ac\u53ef\u592b\u904e\u7a0b\u4f86\u7814\u7a76\u63a8\u8ad6\u6642\u9593\u904b\u7b97\uff1a\u7c21\u55ae\u7684\u63a8\u7406\u6b65\u9a5f\uff08\u4f8b\u5982\u4ee3\u6578\u904b\u7b97\uff09\u5f62\u6210\u5bc6\u96c6\u9023\u63a5\u7684\u53e2\u96c6\uff0c\u800c\u56f0\u96e3\u7684\u63a8\u7406\u6b65\u9a5f\uff08\u4f8b\u5982\u61c9\u7528\u76f8\u95dc\u5b9a\u7406\uff09\u5247\u5728\u53e2\u96c6\u4e4b\u9593\u5efa\u7acb\u7a00\u758f\u3001\u4f4e\u6a5f\u7387\u7684\u908a\u7de3\uff0c\u5c0e\u81f4\u5728\u8f03\u9577\u6642\u9593\u5c3a\u5ea6\u4e0a\u7522\u751f\u76f8\u8b8a\u3002\u5728\u6b64\u67b6\u69cb\u4e0b\uff0c\u6211\u5011\u8b49\u660e\u5be6\u4f5c\u4e00\u7a2e\u734e\u52f5\u7a00\u758f\u908a\u7de3\u7684\u641c\u5c0b\u5354\u5b9a\uff0c\u6703\u900f\u904e\u6e1b\u5c11\u5230\u9054\u4e0d\u540c\u53e2\u96c6\u6240\u9700\u7684\u9810\u671f\u6b65\u9a5f\u6578\u4f86\u6539\u5584 CoT\u3002\u76f8\u53cd\u5730\uff0c\u7576\u6a21\u578b\u53d7\u9650\u65bc\u9810\u8a13\u7df4\u5716\u5f62\u7684\u5c40\u90e8\u8cc7\u8a0a\u6642\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u63a8\u7406\u80fd\u529b\u7684\u9650\u5236\u3002\u6211\u5011\u4e5f\u986f\u793a\u641c\u5c0b\u6240\u7372\u5f97\u7684\u8cc7\u8a0a\u53ef\u7528\u65bc\u53d6\u5f97\u66f4\u597d\u7684\u63a8\u7406\u6a21\u578b\uff1a(1) \u9810\u8a13\u7df4\u6a21\u578b\u53ef\u4ee5\u76f4\u63a5\u5fae\u8abf\u4ee5\u900f\u904e\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u504f\u597d\u7a00\u758f\u908a\u7de3\uff0c\u800c\u4e14 (2) \u63a8\u7406\u52d5\u614b\u7684\u58d3\u7e2e\u4e9e\u7a69\u614b\u8868\u5fb5\u53ef\u4ee5\u63d0\u7149\u5230\u66f4\u5c0f\u3001\u66f4\u6709\u6548\u7387\u7684\u6a21\u578b\u4e2d\u3002</paragraph>", "author": "Juno Kim et.al.", "authors": "Juno Kim, Denny Wu, Jason Lee, Taiji Suzuki", "id": "2502.01694v1", "paper_url": "http://arxiv.org/abs/2502.01694v1", "repo": "null"}}