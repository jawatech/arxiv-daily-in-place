{"2207.11290": {"publish_time": "2022-07-22", "title": "TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring", "paper_summary": "Continuous monitoring of trained ML models to determine when their\npredictions should and should not be trusted is essential for their safe\ndeployment. Such a framework ought to be high-performing, explainable, post-hoc\nand actionable. We propose TRUST-LAPSE, a \"mistrust\" scoring framework for\ncontinuous model monitoring. We assess the trustworthiness of each input\nsample's model prediction using a sequence of latent-space embeddings.\nSpecifically, (a) our latent-space mistrust score estimates mistrust using\ndistance metrics (Mahalanobis distance) and similarity metrics (cosine\nsimilarity) in the latent-space and (b) our sequential mistrust score\ndetermines deviations in correlations over the sequence of past input\nrepresentations in a non-parametric, sliding-window based algorithm for\nactionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream\ntasks: (1) distributionally shifted input detection, and (2) data drift\ndetection. We evaluate across diverse domains - audio and vision using public\ndatasets and further benchmark our approach on challenging, real-world\nelectroencephalograms (EEG) datasets for seizure detection. Our latent-space\nmistrust scores achieve state-of-the-art results with AUROCs of 84.1 (vision),\n73.9 (audio), and 77.1 (clinical EEGs), outperforming baselines by over 10\npoints. We expose critical failures in popular baselines that remain\ninsensitive to input semantic content, rendering them unfit for real-world\nmodel monitoring. We show that our sequential mistrust scores achieve high\ndrift detection rates; over 90% of the streams show < 20% error for all\ndomains. Through extensive qualitative and quantitative evaluations, we show\nthat our mistrust scores are more robust and provide explainability for easy\nadoption into practice.", "paper_summary_zh": "", "author": "Nandita Bhaskhar et.al.", "authors": "Nandita Bhaskhar,Daniel L. Rubin,Christopher Lee-Messer", "id": "2207.11290v2", "paper_url": "http://arxiv.org/abs/2207.11290v2", "repo": "https://github.com/nanbhas/trustlapse"}}