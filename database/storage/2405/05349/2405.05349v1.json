{"2405.05349": {"publish_time": "2024-05-08", "title": "Offline Model-Based Optimization via Policy-Guided Gradient Search", "paper_summary": "Offline optimization is an emerging problem in many experimental engineering\ndomains including protein, drug or aircraft design, where online\nexperimentation to collect evaluation data is too expensive or dangerous. To\navoid that, one has to optimize an unknown function given only its offline\nevaluation at a fixed set of inputs. A naive solution to this problem is to\nlearn a surrogate model of the unknown function and optimize this surrogate\ninstead. However, such a naive optimizer is prone to erroneous overestimation\nof the surrogate (possibly due to over-fitting on a biased sample of function\nevaluation) on inputs outside the offline dataset. Prior approaches addressing\nthis challenge have primarily focused on learning robust surrogate models.\nHowever, their search strategies are derived from the surrogate model rather\nthan the actual offline data. To fill this important gap, we introduce a new\nlearning-to-search perspective for offline optimization by reformulating it as\nan offline reinforcement learning problem. Our proposed policy-guided gradient\nsearch approach explicitly learns the best policy for a given surrogate model\ncreated from the offline data. Our empirical results on multiple benchmarks\ndemonstrate that the learned optimization policy can be combined with existing\noffline surrogates to significantly improve the optimization performance.", "paper_summary_zh": "\u96e2\u7dda\u6700\u4f73\u5316\u5728\u8a31\u591a\u5be6\u9a57\u5de5\u7a0b\u9818\u57df\u4e2d\u662f\u4e00\u500b\u65b0\u8208\u7684\u554f\u984c\uff0c\u5305\u62ec\u86cb\u767d\u8cea\u3001\u85e5\u7269\u6216\u98db\u6a5f\u8a2d\u8a08\uff0c\u5176\u4e2d\u5728\u7dda\u4e0a\u5be6\u9a57\u6536\u96c6\u8a55\u4f30\u8cc7\u6599\u7684\u6210\u672c\u904e\u65bc\u6602\u8cb4\u6216\u5371\u96aa\u3002\u70ba\u4e86\u907f\u514d\u9019\u7a2e\u60c5\u6cc1\uff0c\u5fc5\u9808\u6700\u4f73\u5316\u4e00\u500b\u672a\u77e5\u51fd\u6578\uff0c\u4e14\u50c5\u5728\u56fa\u5b9a\u8f38\u5165\u96c6\u4e0a\u63d0\u4f9b\u5176\u96e2\u7dda\u8a55\u4f30\u3002\u89e3\u6c7a\u6b64\u554f\u984c\u7684\u4e00\u500b\u5929\u771f\u65b9\u6cd5\u662f\u5b78\u7fd2\u672a\u77e5\u51fd\u6578\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u4e26\u6700\u4f73\u5316\u6b64\u66ff\u4ee3\u6a21\u578b\u3002\u7136\u800c\uff0c\u9019\u7a2e\u5929\u771f\u7684\u6700\u4f73\u5316\u5668\u5bb9\u6613\u5c0d\u96e2\u7dda\u8cc7\u6599\u96c6\u4e4b\u5916\u7684\u8f38\u5165\u904e\u5ea6\u4f30\u8a08\u66ff\u4ee3\u6a21\u578b\uff08\u53ef\u80fd\u662f\u7531\u65bc\u904e\u5ea6\u64ec\u5408\u51fd\u6578\u8a55\u4f30\u7684\u504f\u5dee\u6a23\u672c\uff09\u3002\u5148\u524d\u89e3\u6c7a\u6b64\u6311\u6230\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5b78\u7fd2\u7a69\u5065\u7684\u66ff\u4ee3\u6a21\u578b\u3002\u7136\u800c\uff0c\u4ed6\u5011\u7684\u641c\u5c0b\u7b56\u7565\u662f\u5f9e\u66ff\u4ee3\u6a21\u578b\u884d\u751f\u7684\uff0c\u800c\u4e0d\u662f\u5be6\u969b\u7684\u96e2\u7dda\u8cc7\u6599\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u91cd\u8981\u7684\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u5b78\u7fd2\u641c\u5c0b\u89c0\u9ede\uff0c\u4ee5\u96e2\u7dda\u6700\u4f73\u5316\u70ba\u96e2\u7dda\u5f37\u5316\u5b78\u7fd2\u554f\u984c\u91cd\u65b0\u5236\u5b9a\u3002\u6211\u5011\u63d0\u51fa\u7684\u7b56\u7565\u5f15\u5c0e\u68af\u5ea6\u641c\u5c0b\u65b9\u6cd5\u660e\u78ba\u5b78\u7fd2\u5f9e\u96e2\u7dda\u8cc7\u6599\u5efa\u7acb\u7684\u7279\u5b9a\u66ff\u4ee3\u6a21\u578b\u7684\u6700\u4f73\u7b56\u7565\u3002\u6211\u5011\u5728\u591a\u500b\u57fa\u6e96\u4e0a\u7684\u7d93\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u5b78\u7fd2\u7684\u6700\u4f73\u5316\u7b56\u7565\u53ef\u4ee5\u8207\u73fe\u6709\u7684\u96e2\u7dda\u66ff\u4ee3\u6a21\u578b\u7d50\u5408\uff0c\u4ee5\u986f\u8457\u63d0\u5347\u6700\u4f73\u5316\u6548\u80fd\u3002", "author": "Yassine Chemingui et.al.", "authors": "Yassine Chemingui, Aryan Deshwal, Trong Nghia Hoang, Janardhan Rao Doppa", "id": "2405.05349v1", "paper_url": "http://arxiv.org/abs/2405.05349v1", "repo": "https://github.com/yassinech/pgs"}}