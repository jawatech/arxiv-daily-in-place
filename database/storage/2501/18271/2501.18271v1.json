{"2501.18271": {"publish_time": "2025-01-30", "title": "Pre-Trained Vision-Language Model Selection and Reuse for Downstream Tasks", "paper_summary": "Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular\nacross various visual tasks, and several open-sourced VLM variants have been\nreleased. However, selecting the best-performing pre-trained VLM for a specific\ndownstream task is challenging since no single VLM can achieve promising\nperformance on all downstream tasks, and evaluating all available VLMs is\nimpossible due to time and data limitations. To address this problem, this\npaper proposes a novel paradigm to select and reuse VLM for downstream tasks,\ncalled Model Label Learning (MLL). The proposal contains three key modules:\n\\emph{model labeling}, which assigns labels to each VLM to describe their\nspecialty and utility; \\emph{model selection}, which matches the requirements\nof the target task with model labels; and \\emph{model reuse}, which applies\nselected VLMs to the target task in an ensemble manner. The proposal is highly\ncomputationally efficient and growable since the model labeling process is\ncompleted target task independent and the ability could grow with the number of\ncandidate VLMs. We also introduce a new benchmark for evaluating VLM selection\nmethods, including 49 VLMs and 17 target task datasets. Experimental results\nclearly demonstrate the effectiveness of the proposed method for selecting and\nreusing VLMs.", "paper_summary_zh": "<paragraph>\u9810\u5148\u8a13\u7df4\u597d\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5728\u5404\u7a2e\u8996\u89ba\u4efb\u52d9\u4e2d\u8d8a\u4f86\u8d8a\u53d7\u6b61\u8fce\uff0c\u4e26\u4e14\u5df2\u7d93\u767c\u5e03\u4e86\u6578\u500b\u958b\u6e90\u7684 VLM \u8b8a\u9ad4\u3002\u7136\u800c\uff0c\u70ba\u7279\u5b9a\u4e0b\u6e38\u4efb\u52d9\u9078\u64c7\u6548\u80fd\u6700\u4f73\u7684\u9810\u5148\u8a13\u7df4\u597d\u7684 VLM \u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u6c92\u6709\u55ae\u4e00\u7684 VLM \u80fd\u5920\u5728\u6240\u6709\u4e0b\u6e38\u4efb\u52d9\u4e0a\u9054\u5230\u6709\u5e0c\u671b\u7684\u6548\u80fd\uff0c\u800c\u4e14\u7531\u65bc\u6642\u9593\u548c\u8cc7\u6599\u7684\u9650\u5236\uff0c\u7121\u6cd5\u8a55\u4f30\u6240\u6709\u53ef\u7528\u7684 VLM\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u7bc4\u4f8b\u4f86\u70ba\u4e0b\u6e38\u4efb\u52d9\u9078\u64c7\u548c\u91cd\u65b0\u4f7f\u7528 VLM\uff0c\u7a31\u70ba\u6a21\u578b\u6a19\u7c64\u5b78\u7fd2 (MLL)\u3002\u8a72\u63d0\u6848\u5305\u542b\u4e09\u500b\u95dc\u9375\u6a21\u7d44\uff1a\\emph{\u6a21\u578b\u6a19\u7c64}\uff0c\u5b83\u70ba\u6bcf\u500b VLM \u6307\u5b9a\u6a19\u7c64\u4ee5\u63cf\u8ff0\u5176\u5c08\u9577\u548c\u6548\u7528\uff1b\\emph{\u6a21\u578b\u9078\u64c7}\uff0c\u5b83\u5c07\u76ee\u6a19\u4efb\u52d9\u7684\u8981\u6c42\u8207\u6a21\u578b\u6a19\u7c64\u76f8\u5339\u914d\uff1b\u4ee5\u53ca\\emph{\u6a21\u578b\u91cd\u8907\u4f7f\u7528}\uff0c\u5b83\u4ee5\u6574\u9ad4\u65b9\u5f0f\u5c07\u9078\u5b9a\u7684 VLM \u61c9\u7528\u65bc\u76ee\u6a19\u4efb\u52d9\u3002\u8a72\u63d0\u6848\u5177\u6709\u9ad8\u5ea6\u7684\u904b\u7b97\u6548\u7387\u4e14\u53ef\u64f4\u5145\uff0c\u56e0\u70ba\u6a21\u578b\u6a19\u7c64\u8655\u7406\u662f\u7368\u7acb\u65bc\u76ee\u6a19\u4efb\u52d9\u800c\u5b8c\u6210\uff0c\u800c\u4e14\u5176\u80fd\u529b\u6703\u96a8\u8457\u5019\u9078 VLM \u7684\u6578\u91cf\u800c\u589e\u52a0\u3002\u6211\u5011\u9084\u5f15\u5165\u4e86\u65b0\u7684\u57fa\u6e96\u4f86\u8a55\u4f30 VLM \u9078\u64c7\u65b9\u6cd5\uff0c\u5305\u62ec 49 \u500b VLM \u548c 17 \u500b\u76ee\u6a19\u4efb\u52d9\u8cc7\u6599\u96c6\u3002\u5be6\u9a57\u7d50\u679c\u6e05\u695a\u5730\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9078\u64c7\u548c\u91cd\u65b0\u4f7f\u7528 VLM \u65b9\u9762\u7684\u6709\u6548\u6027\u3002</paragraph>", "author": "Hao-Zhe Tan et.al.", "authors": "Hao-Zhe Tan, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li", "id": "2501.18271v1", "paper_url": "http://arxiv.org/abs/2501.18271v1", "repo": "null"}}