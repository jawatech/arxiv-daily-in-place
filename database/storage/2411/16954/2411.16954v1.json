{"2411.16954": {"publish_time": "2024-11-25", "title": "Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach", "paper_summary": "Analytical framework for predicting General Matrix Multiplication (GEMM)\nperformance on modern GPUs, focusing on runtime, power consumption, and energy\nefficiency. Our study employs two approaches: a custom-implemented tiled matrix\nmultiplication kernel for fundamental analysis, and NVIDIA's CUTLASS library\nfor comprehensive performance data collection across advanced configurations.\nUsing the NVIDIA RTX 4070 as our experimental platform, we developed a Random\nForest-based prediction model with multi-output regression capability. Through\nanalysis of both naive tiled matrix multiplication with varying tile sizes (1\nto 32) and 16,128 CUTLASS GEMM operations across diverse configurations, we\nidentified critical performance patterns related to matrix dimensions, thread\nblock configurations, and memory access patterns. Our framework achieved\nexceptional accuracy with an R^2 score of 0.98 for runtime prediction (mean\nerror 15.57%) and 0.78 for power prediction (median error 5.42%). The system\nsuccessfully predicts performance across matrix sizes, demonstrating robust\nscaling behavior. Our results show that optimal tile size selection can improve\nperformance by up to 3.2x while reducing power consumption by 22% compared to\nbaseline configurations. Analysis of shared memory utilization and SM occupancy\nreveals that tile sizes of 16x16 achieve the best balance between parallelism\nand resource usage. The implementation of our framework, including prediction\nmodels and analysis tools, is available as an open-source project at GPPerf\n[https://github.com/pavlyhalim/GPPerf].", "paper_summary_zh": "\u5206\u6790\u6846\u67b6\u7528\u4e8e\u9884\u6d4b\u901a\u7528\u77e9\u9635\u4e58\u6cd5 (GEMM) \u5728\u73b0\u4ee3 GPU \u4e0a\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8\u8fd0\u884c\u65f6\u3001\u529f\u8017\u548c\u80fd\u6548\u3002\u6211\u4eec\u7684\u7814\u7a76\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u4e2a\u81ea\u5b9a\u4e49\u5b9e\u73b0\u7684\u5e73\u94fa\u77e9\u9635\u4e58\u6cd5\u5185\u6838\u7528\u4e8e\u57fa\u672c\u5206\u6790\uff0c\u4ee5\u53ca NVIDIA \u7684 CUTLASS \u5e93\u7528\u4e8e\u8de8\u9ad8\u7ea7\u914d\u7f6e\u6536\u96c6\u5168\u9762\u7684\u6027\u80fd\u6570\u636e\u3002\u4f7f\u7528 NVIDIA RTX 4070 \u4f5c\u4e3a\u6211\u4eec\u7684\u5b9e\u9a8c\u5e73\u53f0\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u5177\u6709\u591a\u8f93\u51fa\u56de\u5f52\u80fd\u529b\u3002\u901a\u8fc7\u5206\u6790\u5177\u6709\u4e0d\u540c\u5e73\u94fa\u5927\u5c0f\uff081 \u5230 32\uff09\u7684\u6734\u7d20\u5e73\u94fa\u77e9\u9635\u4e58\u6cd5\u548c\u8de8\u4e0d\u540c\u914d\u7f6e\u7684 16,128 \u4e2a CUTLASS GEMM \u64cd\u4f5c\uff0c\u6211\u4eec\u8bc6\u522b\u51fa\u4e0e\u77e9\u9635\u7ef4\u5ea6\u3001\u7ebf\u7a0b\u5757\u914d\u7f6e\u548c\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u76f8\u5173\u7684\u5173\u952e\u6027\u80fd\u6a21\u5f0f\u3002\u6211\u4eec\u7684\u6846\u67b6\u5728\u8fd0\u884c\u65f6\u9884\u6d4b\uff08\u5e73\u5747\u8bef\u5dee 15.57%\uff09\u548c\u529f\u7387\u9884\u6d4b\uff08\u4e2d\u4f4d\u6570\u8bef\u5dee 5.42%\uff09\u65b9\u9762\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u51c6\u786e\u6027\uff0cR^2 \u5f97\u5206\u4e3a 0.98\u3002\u8be5\u7cfb\u7edf\u6210\u529f\u9884\u6d4b\u4e86\u8de8\u77e9\u9635\u5927\u5c0f\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u7a33\u5065\u7684\u7f29\u653e\u884c\u4e3a\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u914d\u7f6e\u76f8\u6bd4\uff0c\u6700\u4f73\u5e73\u94fa\u5927\u5c0f\u9009\u62e9\u53ef\u4ee5\u5c06\u6027\u80fd\u63d0\u9ad8\u591a\u8fbe 3.2 \u500d\uff0c\u540c\u65f6\u5c06\u529f\u8017\u964d\u4f4e 22%\u3002\u5bf9\u5171\u4eab\u5185\u5b58\u5229\u7528\u7387\u548c SM \u5360\u7528\u7387\u7684\u5206\u6790\u8868\u660e\uff0c16x16 \u7684\u5e73\u94fa\u5927\u5c0f\u5728\u5e76\u884c\u6027\u548c\u8d44\u6e90\u4f7f\u7528\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6700\u4f73\u5e73\u8861\u3002\u6211\u4eec\u6846\u67b6\u7684\u5b9e\u73b0\uff0c\u5305\u62ec\u9884\u6d4b\u6a21\u578b\u548c\u5206\u6790\u5de5\u5177\uff0c\u4f5c\u4e3a GPPerf \u4e2d\u7684\u4e00\u4e2a\u5f00\u6e90\u9879\u76ee\u63d0\u4f9b [https://github.com/pavlyhalim/GPPerf]\u3002", "author": "Xiaoteng et.al.", "authors": "Xiaoteng, Liu, Pavly Halim", "id": "2411.16954v1", "paper_url": "http://arxiv.org/abs/2411.16954v1", "repo": "https://github.com/pavlyhalim/gpperf"}}