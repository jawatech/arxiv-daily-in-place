{"2411.13934": {"publish_time": "2024-11-21", "title": "Learning to Cooperate with Humans using Generative Agents", "paper_summary": "Training agents that can coordinate zero-shot with humans is a key mission in\nmulti-agent reinforcement learning (MARL). Current algorithms focus on training\nsimulated human partner policies which are then used to train a Cooperator\nagent. The simulated human is produced either through behavior cloning over a\ndataset of human cooperation behavior, or by using MARL to create a population\nof simulated agents. However, these approaches often struggle to produce a\nCooperator that can coordinate well with real humans, since the simulated\nhumans fail to cover the diverse strategies and styles employed by people in\nthe real world. We show \\emph{learning a generative model of human partners}\ncan effectively address this issue. Our model learns a latent variable\nrepresentation of the human that can be regarded as encoding the human's unique\nstrategy, intention, experience, or style. This generative model can be\nflexibly trained from any (human or neural policy) agent interaction data. By\nsampling from the latent space, we can use the generative model to produce\ndifferent partners to train Cooperator agents. We evaluate our method --\n\\textbf{G}enerative \\textbf{A}gent \\textbf{M}odeling for \\textbf{M}ulti-agent\n\\textbf{A}daptation (GAMMA) -- on Overcooked, a challenging cooperative cooking\ngame that has become a standard benchmark for zero-shot coordination. We\nconduct an evaluation with real human teammates, and the results show that\nGAMMA consistently improves performance, whether the generative model is\ntrained on simulated populations or human datasets. Further, we propose a\nmethod for posterior sampling from the generative model that is biased towards\nthe human data, enabling us to efficiently improve performance with only a\nsmall amount of expensive human interaction data.", "paper_summary_zh": "<paragraph>\u8a13\u7df4\u80fd\u8207\u4eba\u985e\u96f6\u6b21\u5b78\u7fd2\u5354\u8abf\u7684\u4ee3\u7406\u7a0b\u5f0f\uff0c\u662f\u591a\u91cd\u4ee3\u7406\u5f37\u5316\u5b78\u7fd2 (MARL) \u7684\u4e00\u9805\u95dc\u9375\u4efb\u52d9\u3002\u76ee\u524d\u7684\u6f14\u7b97\u6cd5\u5c08\u6ce8\u65bc\u8a13\u7df4\u6a21\u64ec\u7684\u4eba\u985e\u5925\u4f34\u653f\u7b56\uff0c\u7136\u5f8c\u7528\u65bc\u8a13\u7df4\u5408\u4f5c\u4ee3\u7406\u7a0b\u5f0f\u3002\u6a21\u64ec\u7684\u4eba\u985e\u662f\u900f\u904e\u5c0d\u4eba\u985e\u5408\u4f5c\u884c\u70ba\u8cc7\u6599\u96c6\u9032\u884c\u884c\u70ba\u8907\u88fd\u7522\u751f\uff0c\u6216\u900f\u904e\u4f7f\u7528 MARL \u5efa\u7acb\u6a21\u64ec\u4ee3\u7406\u7a0b\u5f0f\u65cf\u7fa4\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u901a\u5e38\u96e3\u4ee5\u7522\u751f\u80fd\u8207\u771f\u5be6\u4eba\u985e\u5354\u8abf\u826f\u597d\u7684\u5408\u4f5c\u4ee3\u7406\u7a0b\u5f0f\uff0c\u56e0\u70ba\u6a21\u64ec\u7684\u4eba\u985e\u7121\u6cd5\u6db5\u84cb\u73fe\u5be6\u4e16\u754c\u4e2d\u4eba\u985e\u6240\u4f7f\u7528\u7684\u5404\u7a2e\u7b56\u7565\u548c\u98a8\u683c\u3002\u6211\u5011\u5c55\u793a\u300c\u5b78\u7fd2\u4eba\u985e\u5925\u4f34\u7684\u751f\u6210\u6a21\u578b\u300d\u80fd\u6709\u6548\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u7684\u6a21\u578b\u5b78\u7fd2\u4eba\u985e\u7684\u6f5b\u5728\u8b8a\u6578\u8868\u793a\uff0c\u53ef\u8996\u70ba\u7de8\u78bc\u4eba\u985e\u7684\u7368\u7279\u7b56\u7565\u3001\u610f\u5716\u3001\u7d93\u9a57\u6216\u98a8\u683c\u3002\u9019\u500b\u751f\u6210\u6a21\u578b\u80fd\u9748\u6d3b\u5730\u5f9e\u4efb\u4f55\uff08\u4eba\u985e\u6216\u795e\u7d93\u7db2\u8def\u653f\u7b56\uff09\u4ee3\u7406\u7a0b\u5f0f\u4e92\u52d5\u8cc7\u6599\u4e2d\u9032\u884c\u8a13\u7df4\u3002\u900f\u904e\u5f9e\u6f5b\u5728\u7a7a\u9593\u53d6\u6a23\uff0c\u6211\u5011\u53ef\u4ee5\u4f7f\u7528\u751f\u6210\u6a21\u578b\u7522\u751f\u4e0d\u540c\u7684\u5925\u4f34\u4f86\u8a13\u7df4\u5408\u4f5c\u4ee3\u7406\u7a0b\u5f0f\u3002\u6211\u5011\u8a55\u4f30\u6211\u5011\u7684\u6a21\u578b\u2014\u2014\u591a\u91cd\u4ee3\u7406\u9069\u61c9\u7684\u751f\u6210\u4ee3\u7406\u7a0b\u5f0f\u5efa\u6a21 (GAMMA)\u2014\u2014\u5728 Overcooked \u4e0a\uff0c\u9019\u662f\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u5408\u4f5c\u70f9\u98ea\u904a\u6232\uff0c\u5df2\u6210\u70ba\u96f6\u6b21\u5b78\u7fd2\u5354\u8abf\u7684\u6a19\u6e96\u57fa\u6e96\u3002\u6211\u5011\u8207\u771f\u5be6\u7684\u4eba\u985e\u968a\u53cb\u9032\u884c\u8a55\u4f30\uff0c\u7d50\u679c\u986f\u793a\u7121\u8ad6\u751f\u6210\u6a21\u578b\u662f\u91dd\u5c0d\u6a21\u64ec\u65cf\u7fa4\u6216\u4eba\u985e\u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\uff0cGAMMA \u90fd\u80fd\u6301\u7e8c\u6539\u5584\u6548\u80fd\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5f9e\u751f\u6210\u6a21\u578b\u4e2d\u9032\u884c\u5f8c\u9a57\u53d6\u6a23\u7684\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u504f\u5411\u65bc\u4eba\u985e\u8cc7\u6599\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u50c5\u4f7f\u7528\u5c11\u91cf\u7684\u6602\u8cb4\u4eba\u985e\u4e92\u52d5\u8cc7\u6599\u4f86\u6709\u6548\u63d0\u5347\u6548\u80fd\u3002</paragraph>", "author": "Yancheng Liang et.al.", "authors": "Yancheng Liang, Daphne Chen, Abhishek Gupta, Simon S. Du, Natasha Jaques", "id": "2411.13934v1", "paper_url": "http://arxiv.org/abs/2411.13934v1", "repo": "https://github.com/lych1233/gamma-human-ai-collaboration"}}