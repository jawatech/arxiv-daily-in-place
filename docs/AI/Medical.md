
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**|Chao Zhang et.al.|[2405.20142v2](http://arxiv.org/abs/2405.20142v2)|null|
|**2024-05-30**|**Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**|Taisei Tosaki et.al.|[2405.19864v1](http://arxiv.org/abs/2405.19864v1)|null|
|**2024-05-30**|**Dynamic feature selection in medical predictive monitoring by reinforcement learning**|Yutong Chen et.al.|[2405.19729v1](http://arxiv.org/abs/2405.19729v1)|null|
|**2024-05-30**|**Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**|Jinxia Yang et.al.|[2405.19654v1](http://arxiv.org/abs/2405.19654v1)|[link](https://github.com/svt-yang/medst)|
|**2024-05-30**|**Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**|Akul Goel et.al.|[2405.19631v1](http://arxiv.org/abs/2405.19631v1)|null|
|**2024-05-29**|**Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**|Shenghuan Sun et.al.|[2405.19567v1](http://arxiv.org/abs/2405.19567v1)|null|
|**2024-05-29**|**CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients**|Pierre Chambon et.al.|[2405.19538v1](http://arxiv.org/abs/2405.19538v1)|[link](https://github.com/stanford-aimi/chexpert-plus)|
|**2024-05-29**|**Participation in the age of foundation models**|Harini Suresh et.al.|[2405.19479v1](http://arxiv.org/abs/2405.19479v1)|null|
|**2024-05-29**|**MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**|Raman Dutt et.al.|[2405.19458v1](http://arxiv.org/abs/2405.19458v1)|null|
|**2024-05-29**|**Conformal Depression Prediction**|Yonghong Li et.al.|[2405.18723v1](http://arxiv.org/abs/2405.18723v1)|null|
|**2024-05-28**|**D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**|Haoyu Hu et.al.|[2405.18658v1](http://arxiv.org/abs/2405.18658v1)|null|
|**2024-05-28**|**DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**|Zhiyao Luo et.al.|[2405.18610v1](http://arxiv.org/abs/2405.18610v1)|[link](https://github.com/gilesluo/dtr-bench)|
|**2024-05-28**|**Low-rank finetuning for LLMs: A fairness perspective**|Saswat Das et.al.|[2405.18572v1](http://arxiv.org/abs/2405.18572v1)|null|
|**2024-05-28**|**Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**|Zhiyao Luo et.al.|[2405.18556v1](http://arxiv.org/abs/2405.18556v1)|[link](https://github.com/gilesluo/reassessdtr)|
|**2024-05-28**|**The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental Health Service Provision**|Stephen Obadinma et.al.|[2405.18553v1](http://arxiv.org/abs/2405.18553v1)|null|
|**2024-05-28**|**Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**|James Derek Lomas et.al.|[2405.18510v1](http://arxiv.org/abs/2405.18510v1)|null|
|**2024-05-28**|**A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**|Ioanna Gogou et.al.|[2405.18387v1](http://arxiv.org/abs/2405.18387v1)|[link](https://github.com/joangog/object-detection)|
|**2024-05-28**|**Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**|Dominic LaBella et.al.|[2405.18383v1](http://arxiv.org/abs/2405.18383v1)|null|
|**2024-05-28**|**Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**|Anjanava Biswas et.al.|[2405.18346v1](http://arxiv.org/abs/2405.18346v1)|null|
|**2024-05-28**|**Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**|Jay Jasti et.al.|[2405.18327v1](http://arxiv.org/abs/2405.18327v1)|null|
|**2024-05-28**|**Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**|Aryo Pradipta Gema et.al.|[2405.18028v1](http://arxiv.org/abs/2405.18028v1)|null|
|**2024-05-28**|**Towards Clinical AI Fairness: Filling Gaps in the Puzzle**|Mingxuan Liu et.al.|[2405.17921v1](http://arxiv.org/abs/2405.17921v1)|null|
|**2024-05-28**|**Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing**|Irem Ulku et.al.|[2405.17901v1](http://arxiv.org/abs/2405.17901v1)|null|
|**2024-05-28**|**AI Alignment with Changing and Influenceable Reward Functions**|Micah Carroll et.al.|[2405.17713v1](http://arxiv.org/abs/2405.17713v1)|null|
|**2024-05-27**|**The Economic Implications of Large Language Model Selection on Earnings and Return on Investment: A Decision Theoretic Model**|Geraldo Xex√©o et.al.|[2405.17637v1](http://arxiv.org/abs/2405.17637v1)|null|
|**2024-05-27**|**BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring at Scale**|ZeMing Gong et.al.|[2405.17537v1](http://arxiv.org/abs/2405.17537v1)|null|
|**2024-05-27**|**On Fairness of Low-Rank Adaptation of Large Models**|Zhoujie Ding et.al.|[2405.17512v1](http://arxiv.org/abs/2405.17512v1)|null|
|**2024-05-26**|**Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning**|Chun-Kai Huang et.al.|[2405.16557v1](http://arxiv.org/abs/2405.16557v1)|null|
|**2024-05-26**|**SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation**|Ziqin Luo et.al.|[2405.16552v1](http://arxiv.org/abs/2405.16552v1)|null|
|**2024-05-26**|**Gamified AI Approch for Early Detection of Dementia**|Paramita Kundu Maji et.al.|[2405.16538v1](http://arxiv.org/abs/2405.16538v1)|null|
|**2024-05-26**|**ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text**|Han Yu et.al.|[2405.19366v1](http://arxiv.org/abs/2405.19366v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-26**|**Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models**|Jiankun Wang et.al.|[2405.16413v1](http://arxiv.org/abs/2405.16413v1)|null|
|**2024-05-26**|**Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions**|Man Luo et.al.|[2405.16402v1](http://arxiv.org/abs/2405.16402v1)|null|
|**2024-05-25**|**Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets**|Hyekyoung Hwang et.al.|[2405.16082v1](http://arxiv.org/abs/2405.16082v1)|null|
|**2024-05-25**|**Transductive Confidence Machine and its application to Medical Data Sets**|David Lindsay et.al.|[2405.15988v1](http://arxiv.org/abs/2405.15988v1)|null|
|**2024-05-24**|**The Impact and Opportunities of Generative AI in Fact-Checking**|Robert Wolfe et.al.|[2405.15985v1](http://arxiv.org/abs/2405.15985v1)|null|
|**2024-05-24**|**Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques**|Mikayla Calitis et.al.|[2405.15882v1](http://arxiv.org/abs/2405.15882v1)|null|
|**2024-05-24**|**Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**|Pranab Sahoo et.al.|[2405.15766v2](http://arxiv.org/abs/2405.15766v2)|[link](https://github.com/singhayush27/mmade)|
|**2024-05-24**|**Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification**|Yihe Wang et.al.|[2405.19363v1](http://arxiv.org/abs/2405.19363v1)|null|
|**2024-05-24**|**Effective Confidence Region Prediction Using Probability Forecasters**|David Lindsay et.al.|[2405.15642v1](http://arxiv.org/abs/2405.15642v1)|null|
|**2024-05-24**|**Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images**|Rinat I. Dumaev et.al.|[2405.17483v1](http://arxiv.org/abs/2405.17483v1)|null|
|**2024-05-24**|**PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**|Yuandou Wang et.al.|[2405.15398v1](http://arxiv.org/abs/2405.15398v1)|[link](https://github.com/yuandou168/price)|
|**2024-05-24**|**Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**|Jokin Alcibar et.al.|[2405.15292v1](http://arxiv.org/abs/2405.15292v1)|null|
|**2024-05-24**|**Efficient Reinforcement Learning via Large Language Model-based Search**|Siddhant Bhambri et.al.|[2405.15194v1](http://arxiv.org/abs/2405.15194v1)|null|
|**2024-05-24**|**Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis**|Xishun Liao et.al.|[2405.17468v1](http://arxiv.org/abs/2405.17468v1)|null|
|**2024-05-23**|**Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**|Basile Van Hoorick et.al.|[2405.14868v1](http://arxiv.org/abs/2405.14868v1)|null|
|**2024-05-23**|**A Declarative System for Optimizing AI Workloads**|Chunwei Liu et.al.|[2405.14696v2](http://arxiv.org/abs/2405.14696v2)|[link](https://github.com/mitdbg/palimpzest)|
|**2024-05-23**|**Efficient Medical Question Answering with Knowledge-Augmented Question Generation**|Julien Khlaut et.al.|[2405.14654v1](http://arxiv.org/abs/2405.14654v1)|null|
|**2024-05-23**|**Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**|Loris Giulivi et.al.|[2405.14563v1](http://arxiv.org/abs/2405.14563v1)|[link](https://github.com/loris2222/concept-visualization)|
|**2024-05-23**|**Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**|Lena Schmidt et.al.|[2405.14445v1](http://arxiv.org/abs/2405.14445v1)|null|
|**2024-05-23**|**Unraveling overoptimism and publication bias in ML-driven science**|Pouria Saidi et.al.|[2405.14422v1](http://arxiv.org/abs/2405.14422v1)|null|
|**2024-05-23**|**Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports**|Guangyu Guo et.al.|[2405.14230v1](http://arxiv.org/abs/2405.14230v1)|null|
|**2024-05-23**|**Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks**|Yafeng Yan et.al.|[2405.17460v1](http://arxiv.org/abs/2405.17460v1)|null|
|**2024-05-23**|**Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis**|Ziyan Yao et.al.|[2405.17459v1](http://arxiv.org/abs/2405.17459v1)|null|
|**2024-05-23**|**Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation**|Kang Liu et.al.|[2405.14905v1](http://arxiv.org/abs/2405.14905v1)|[link](https://github.com/mk-runner/sei-temp)|
|**2024-05-22**|**How Many Bytes Can You Take Out Of Brain-To-Text Decoding?**|Richard Antonello et.al.|[2405.14055v1](http://arxiv.org/abs/2405.14055v1)|null|
|**2024-05-22**|**Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review**|Md Shahin Ali et.al.|[2405.13832v1](http://arxiv.org/abs/2405.13832v1)|null|
|**2024-05-22**|**Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling**|Shifan Zhao et.al.|[2405.13785v1](http://arxiv.org/abs/2405.13785v1)|null|
|**2024-05-21**|**How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?**|Ayesha Siddika Nipu et.al.|[2405.13219v1](http://arxiv.org/abs/2405.13219v1)|null|
|**2024-05-21**|**Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation**|Haoteng Tang et.al.|[2405.13190v1](http://arxiv.org/abs/2405.13190v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-21**|**KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning**|Yusong Zhang et.al.|[2405.13094v1](http://arxiv.org/abs/2405.13094v1)|null|
|**2024-05-21**|**A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**|Meng Shang et.al.|[2405.12711v2](http://arxiv.org/abs/2405.12711v2)|null|
|**2024-05-21**|**OLAPH: Improving Factuality in Biomedical Long-form Question Answering**|Minbyul Jeong et.al.|[2405.12701v1](http://arxiv.org/abs/2405.12701v1)|[link](https://github.com/dmis-lab/olaph)|
|**2024-05-21**|**Exploration of Masked and Causal Language Modelling for Text Generation**|Nicolo Micheletti et.al.|[2405.12630v1](http://arxiv.org/abs/2405.12630v1)|null|
|**2024-05-21**|**DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**|Bufang Yang et.al.|[2405.12541v1](http://arxiv.org/abs/2405.12541v1)|null|
|**2024-05-21**|**A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis**|Haocong Rao et.al.|[2405.13082v1](http://arxiv.org/abs/2405.13082v1)|[link](https://github.com/kali-hac/ai4ndd-survey)|
|**2024-05-21**|**Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity**|Pat Pataranutaporn et.al.|[2405.12514v2](http://arxiv.org/abs/2405.12514v2)|null|
|**2024-05-20**|**Ensuring Ground Truth Accuracy in Healthcare with the EVINCE framework**|Edward Y. Chang et.al.|[2405.15808v2](http://arxiv.org/abs/2405.15808v2)|null|
|**2024-05-20**|**Digital Health and Indoor Air Quality: An IoT-Driven Human-Centred Visualisation Platform for Behavioural Change and Technology Acceptance**|Rameez Raja Kureshi et.al.|[2405.13064v1](http://arxiv.org/abs/2405.13064v1)|null|
|**2024-05-20**|**Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**|Tatiana V. Afanasieva et.al.|[2405.11967v1](http://arxiv.org/abs/2405.11967v1)|null|
|**2024-05-20**|**Contactless Polysomnography: What Radio Waves Tell Us about Sleep**|Hao He et.al.|[2405.11739v1](http://arxiv.org/abs/2405.11739v1)|null|
|**2024-05-20**|**Large Language Models for Medicine: A Survey**|Yanxin Zheng et.al.|[2405.13055v1](http://arxiv.org/abs/2405.13055v1)|null|
|**2024-05-19**|**Towards Contactless Elevators with TinyML using CNN-based Person Detection and Keyword Spotting**|Anway S. Pimpalkar et.al.|[2405.13051v1](http://arxiv.org/abs/2405.13051v1)|null|
|**2024-05-19**|**Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning**|Zishan Gu et.al.|[2405.11640v1](http://arxiv.org/abs/2405.11640v1)|null|
|**2024-05-19**|**Sociotechnical Implications of Generative Artificial Intelligence for Information Access**|Bhaskar Mitra et.al.|[2405.11612v1](http://arxiv.org/abs/2405.11612v1)|null|
|**2024-05-19**|**AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection to Clinical Validation**|Carlo Alberto Barbano et.al.|[2405.11598v1](http://arxiv.org/abs/2405.11598v1)|null|
|**2024-05-18**|**EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging**|Danli Shi et.al.|[2405.11338v2](http://arxiv.org/abs/2405.11338v2)|null|
|**2024-05-18**|**Towards Knowledge-Infused Automated Disease Diagnosis Assistant**|Mohit Tomar et.al.|[2405.11181v1](http://arxiv.org/abs/2405.11181v1)|[link](https://github.com/nlp-rl/ki-ddi)|
|**2024-05-18**|**Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation**|Xiaolu Kang et.al.|[2405.11151v1](http://arxiv.org/abs/2405.11151v1)|null|
|**2024-05-17**|**Generative Artificial Intelligence: A Systematic Review and Applications**|Sandeep Singh Sengar et.al.|[2405.11029v1](http://arxiv.org/abs/2405.11029v1)|null|
|**2024-05-17**|**COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**|Dimitrios P. Panagoulias et.al.|[2405.10893v1](http://arxiv.org/abs/2405.10893v1)|null|
|**2024-05-17**|**Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**|Hongyi Yang et.al.|[2405.10883v1](http://arxiv.org/abs/2405.10883v1)|null|
|**2024-05-17**|**Causality in the Can: Diet Coke's Impact on Fatness**|Yicheng Qi et.al.|[2405.10746v1](http://arxiv.org/abs/2405.10746v1)|null|
|**2024-05-17**|**A Systematic Review and Meta-Analysis on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence**|Tayab Uddin Wara et.al.|[2405.11008v1](http://arxiv.org/abs/2405.11008v1)|null|
|**2024-05-17**|**Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**|Haoyue Song et.al.|[2405.10647v1](http://arxiv.org/abs/2405.10647v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-17**|**Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges**|Xiaoming Shi et.al.|[2405.10630v1](http://arxiv.org/abs/2405.10630v1)|null|
|**2024-05-16**|**Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**|Yu Gui et.al.|[2405.10301v2](http://arxiv.org/abs/2405.10301v2)|null|
|**2024-05-16**|**Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**|Divij Gupta et.al.|[2405.10216v1](http://arxiv.org/abs/2405.10216v1)|null|
|**2024-05-16**|**HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition**|Kun Yuan et.al.|[2405.10075v1](http://arxiv.org/abs/2405.10075v1)|null|
|**2024-05-16**|**Histopathology Foundation Models Enable Accurate Ovarian Cancer Subtype Classification**|Jack Breen et.al.|[2405.09990v1](http://arxiv.org/abs/2405.09990v1)|[link](https://github.com/scjjb/ovarian_features)|
|**2024-05-16**|**Predicting Solar Heat Production to Optimize Renewable Energy Usage**|Tatiana Boura et.al.|[2405.09972v1](http://arxiv.org/abs/2405.09972v1)|null|
|**2024-05-16**|**Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fr√©chet Domain Distance**|Milda Poceviƒçi≈´tƒó et.al.|[2405.09934v1](http://arxiv.org/abs/2405.09934v1)|null|
|**2024-05-16**|**Crowdsourcing with Enhanced Data Quality Assurance: An Efficient Approach to Mitigate Resource Scarcity Challenges in Training Large Language Models for Healthcare**|P. Barai et.al.|[2405.13030v1](http://arxiv.org/abs/2405.13030v1)|null|
|**2024-05-16**|**A Farewell to Harms: Risk Management for Medical Devices via the Riskman Ontology & Shapes**|Piotr Gorczyca et.al.|[2405.09875v2](http://arxiv.org/abs/2405.09875v2)|null|
|**2024-05-16**|**MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image Synthesis**|Joseph Cho et.al.|[2405.09806v1](http://arxiv.org/abs/2405.09806v1)|null|
|**2024-05-16**|**Many-Shot In-Context Learning in Multimodal Foundation Models**|Yixing Jiang et.al.|[2405.09798v1](http://arxiv.org/abs/2405.09798v1)|[link](https://github.com/stanfordmlgroup/ManyICL)|

#### Abstracts
##### **MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**
2405.20142v2 by Chao Zhang, Weirong Cui, Jingjing Guo

Monitoring sleep states is essential for evaluating sleep quality and
diagnosing sleep disorders. Traditional manual staging is time-consuming and
prone to subjective bias, often resulting in inconsistent outcomes. Here, we
developed an automated model for sleep staging and disorder classification to
enhance diagnostic accuracy and efficiency. Considering the characteristics of
polysomnography (PSG) multi-lead sleep monitoring, we designed a multimodal
sleep state classification model, MSSC-BiMamba, that combines an Efficient
Channel Attention (ECA) mechanism with a Bidirectional State Space Model
(BSSM). The ECA module allows for weighting data from different sensor
channels, thereby amplifying the influence of diverse sensor inputs.
Additionally, the implementation of bidirectional Mamba (BiMamba) enables the
model to effectively capture the multidimensional features and long-range
dependencies of PSG data. The developed model demonstrated impressive
performance on sleep stage classification tasks on both the ISRUC-S3 and
ISRUC-S1 datasets, respectively containing data with healthy and unhealthy
sleep patterns. Also, the model exhibited a high accuracy for sleep health
prediction when evaluated on a combined dataset consisting of ISRUC and
Sleep-EDF. Our model, which can effectively handle diverse sleep conditions, is
the first to apply BiMamba to sleep staging with multimodal PSG data, showing
substantial gains in computational and memory efficiency over traditional
Transformer-style models. This method enhances sleep health management by
making monitoring more accessible and extending advanced healthcare through
innovative technology.

ÊëòË¶ÅÔºöÁõ£ÊéßÁù°Áú†ÁãÄÊÖãÂ∞çÊñºË©ï‰º∞Áù°Áú†ÂìÅË≥™ÂíåË®∫Êñ∑Áù°Áú†ÈöúÁ§ôËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÊâãÂãïÂàÜÊúüËÄóÊôÇ‰∏îÂÆπÊòìÁî¢Áîü‰∏ªËßÄÂÅèË¶ãÔºåÁ∂ìÂ∏∏Â∞éËá¥‰∏ç‰∏ÄËá¥ÁöÑÁµêÊûú„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñÊ®°ÂûãÔºåÁî®ÊñºÁù°Áú†ÂàÜÊúüÂíåÁñæÁóÖÂàÜÈ°ûÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇËÄÉÊÖÆÂà∞Â§öÂ∞éÁù°Áú†Ê™¢Êü• (PSG) Â§öÂ∞éÁ®ãÁù°Áú†Áõ£Ê∏¨ÁöÑÁâπÂæµÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÁù°Áú†ÁãÄÊÖãÂàÜÈ°ûÊ®°Âûã MSSC-BiMambaÔºåÂÆÉÂ∞áÈ´òÊïàÈÄöÈÅìÊ≥®ÊÑè (ECA) Ê©üÂà∂ËàáÈõôÂêëÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (BSSM) ÁµêÂêàÂú®‰∏ÄËµ∑„ÄÇECA Ê®°ÁµÑÂÖÅË®±Â∞ç‰æÜËá™‰∏çÂêåÊÑüÊ∏¨Âô®ÈÄöÈÅìÁöÑË≥áÊñôÈÄ≤Ë°åÂä†Ê¨äÔºåÂæûËÄåÊîæÂ§ß‰∏çÂêåÊÑüÊ∏¨Âô®Ëº∏ÂÖ•ÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÈõôÂêë Mamba (BiMamba) ÁöÑÂØ¶‰ΩúËÆìÊ®°ÂûãËÉΩÂ§†ÊúâÊïàÊì∑Âèñ PSG Ë≥áÊñôÁöÑÂ§öÁ∂≠ÁâπÂæµÂíåÈï∑Á®ã‰æùË≥¥ÊÄß„ÄÇÈñãÁôºÁöÑÊ®°ÂûãÂú® ISRUC-S3 Âíå ISRUC-S1 Ë≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁù°Áú†ÂàÜÊúüÂàÜÈ°û‰ªªÂãôÊïàËÉΩÔºåÈÄô‰∫õË≥áÊñôÈõÜÂàÜÂà•ÂåÖÂê´ÂÅ•Â∫∑Âíå‰∏çÂÅ•Â∫∑ÁöÑÁù°Áú†Ê®°ÂºèË≥áÊñô„ÄÇÊ≠§Â§ñÔºåÂú®Áî± ISRUC Âíå Sleep-EDF ÁµÑÊàêÁöÑÂêà‰ΩµË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåË©≤Ê®°ÂûãÂ±ïÁèæÂá∫ÂæàÈ´òÁöÑÁù°Áú†ÂÅ•Â∫∑È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàËôïÁêÜ‰∏çÂêåÁöÑÁù°Áú†ÁãÄÊ≥ÅÔºåÊòØÁ¨¨‰∏ÄÂÄãÂ∞á BiMamba ÊáâÁî®ÊñºÂÖ∑ÊúâÂ§öÊ®°ÊÖã PSG Ë≥áÊñôÁöÑÁù°Áú†ÂàÜÊúüÁöÑÊ®°ÂûãÔºåÂú®ÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéáÊñπÈù¢Â±ïÁèæÂá∫ÊØîÂÇ≥Áµ± Transformer È¢®Ê†ºÊ®°ÂûãÊõ¥È°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéËÆìÁõ£ÊéßÊõ¥ÂÆπÊòìÂèñÂæóÔºå‰∏¶ÈÄèÈÅéÂâµÊñ∞ÊäÄË°ìÊì¥Â±ïÂÖàÈÄ≤ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÔºåÈÄ≤ËÄåÂ¢ûÂº∑Áù°Áú†ÂÅ•Â∫∑ÁÆ°ÁêÜ„ÄÇ

##### **Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**
2405.19864v1 by Taisei Tosaki, Eiichiro Uchino, Ryosuke Kojima, Yohei Mineharu, Mikio Arita, Nobuyuki Miyai, Yoshinori Tamada, Tatsuya Mikami, Koichi Murashita, Shigeyuki Nakaji, Yasushi Okuno

Machine learning is increasingly used to predict lifestyle-related disease
onset using health and medical data. However, the prediction effectiveness is
hindered by dataset shift, which involves discrepancies in data distribution
between the training and testing datasets, misclassifying out-of-distribution
(OOD) data. To diminish dataset shift effects, this paper proposes the
out-of-distribution reject option for prediction (ODROP), which integrates OOD
detection models to preclude OOD data from the prediction phase. We
investigated the efficacy of five OOD detection methods (variational
autoencoder, neural network ensemble std, neural network ensemble epistemic,
neural network energy, and neural network gaussian mixture based energy
measurement) across two datasets, the Hirosaki and Wakayama health checkup
data, in the context of three disease onset prediction tasks: diabetes,
dyslipidemia, and hypertension. To evaluate the ODROP method, we trained
disease onset prediction models and OOD detection models on Hirosaki data and
used AUROC-rejection curve plots from Wakayama data. The variational
autoencoder method showed superior stability and magnitude of improvement in
Area Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the
Wakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for
diabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.
We categorized dataset shifts into two types using SHAP clustering - those that
considerably affect predictions and those that do not. We expect that this
classification will help standardize measuring instruments. This study is the
first to apply OOD detection to actual health and medical data, demonstrating
its potential to substantially improve the accuracy and reliability of disease
prediction models amidst dataset shift.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊ≠£Êó•ÁõäÁî®ÊñºÈ†êÊ∏¨ËàáÁîüÊ¥ªÊñπÂºèÁõ∏ÈóúÁöÑÁñæÁóÖÁôº‰ΩúÔºå‰∏¶‰ΩøÁî®ÂÅ•Â∫∑ÂíåÈÜ´ÁôÇÊï∏Êìö„ÄÇÁÑ∂ËÄåÔºåÈ†êÊ∏¨ÊïàÊûúÊúÉÂèóÂà∞Ë≥áÊñôÈõÜËΩâÁßªÁöÑÈòªÁ§ôÔºåÈÄôÊ∂âÂèäË®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ë≥áÊñôÈõÜ‰πãÈñìÁöÑË≥áÊñôÂàÜ‰ΩàÂ∑ÆÁï∞ÔºåÂ∞áÂàÜÂ∏ÉÂ§ñ (OOD) Ë≥áÊñôÂàÜÈ°ûÈåØË™§„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ëË≥áÊñôÈõÜËΩâÁßªÊïàÊáâÔºåÊú¨ÊñáÊèêÂá∫Áî®ÊñºÈ†êÊ∏¨ÁöÑÂàÜÂ∏ÉÂ§ñÊãíÁµïÈÅ∏È†Ö (ODROP)ÔºåÂÆÉÊï¥Âêà OOD ÂÅµÊ∏¨Ê®°Âûã‰ª•ÊéíÈô§È†êÊ∏¨ÈöéÊÆµÁöÑ OOD Ë≥áÊñô„ÄÇÊàëÂÄëË™øÊü•‰∫Ü‰∫îÁ®Æ OOD ÂÅµÊ∏¨ÊñπÊ≥ï (ËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥È´îÊ®ôÊ∫ñÂ∑Æ„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥È´îË™çË≠òË´ñ„ÄÅÁ•ûÁ∂ìÁ∂≤Ë∑ØËÉΩÈáèÂíåÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÈ´òÊñØÊ∑∑ÂêàËÉΩÈáèÊ∏¨Èáè) ÁöÑÊïàËÉΩÔºåË∑®ÂÖ©ÂÄãË≥áÊñôÈõÜÔºåÂºòÂâçÂíåÂíåÊ≠åÂ±±ÂÅ•Â∫∑Ê™¢Êü•Ë≥áÊñôÔºåÂú®Á≥ñÂ∞øÁóÖ„ÄÅË°ÄËÑÇÁï∞Â∏∏ÂíåÈ´òË°ÄÂ£ìÈÄô‰∏âÂÄãÁñæÁóÖÁôº‰ΩúÈ†êÊ∏¨‰ªªÂãôÁöÑËÑàÁµ°‰∏≠„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ ODROP ÊñπÊ≥ïÔºåÊàëÂÄëË®ìÁ∑¥‰∫ÜÂºòÂâçË≥áÊñôÁöÑÁñæÁóÖÁôº‰ΩúÈ†êÊ∏¨Ê®°ÂûãÂíå OOD ÂÅµÊ∏¨Ê®°ÂûãÔºå‰∏¶‰ΩøÁî®ÂíåÊ≠åÂ±±Ë≥áÊñôÁöÑ AUROC ÊéíÊñ•Êõ≤Á∑öÂúñ„ÄÇËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô®ÊñπÊ≥ïÂú®‰∫îÁ®ÆÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÁ©©ÂÆöÊÄßÂíåÊîπÂñÑÂπÖÂ∫¶ÔºöÂú®Êé•ÂèóËÄÖÊìç‰ΩúÁâπÂæµÊõ≤Á∑ö (AUROC) ‰∏ãÊñπÂçÄÂüü‰∏≠ÔºåÂíåÊ≠åÂ±±Ë≥áÊñôÁöÑ AUROC ÂæûÁ≥ñÂ∞øÁóÖÁôº‰ΩúÁöÑ 31.1% ÊéíÊñ•ÁéáÊîπÂñÑÂà∞ 0.90ÔºåÂæûË°ÄËÑÇÁï∞Â∏∏ÁöÑ 34% ÊéíÊñ•ÁéáÊîπÂñÑÂà∞ 0.76„ÄÇÊàëÂÄë‰ΩøÁî® SHAP ËÅöÈ°ûÂ∞áË≥áÊñôÈõÜËΩâÁßªÂàÜÁÇ∫ÂÖ©Á®ÆÈ°ûÂûãÔºå‰∏ÄÁ®ÆÊúÉÈ°ØËëóÂΩ±ÈüøÈ†êÊ∏¨ÔºåÂè¶‰∏ÄÁ®ÆÂâá‰∏çÊúÉ„ÄÇÊàëÂÄëÈ†êÊúüÈÄôÁ®ÆÂàÜÈ°ûÂ∞áÊúâÂä©ÊñºÊ®ôÊ∫ñÂåñÊ∏¨ÈáèÂÑÄÂô®„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È¶ñÊ¨°Â∞á OOD ÂÅµÊ∏¨ÊáâÁî®ÊñºÂØ¶ÈöõÁöÑÂÅ•Â∫∑ÂíåÈÜ´ÁôÇË≥áÊñôÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë≥áÊñôÈõÜËΩâÁßª‰∏≠Â§ßÂπÖÊîπÂñÑÁñæÁóÖÈ†êÊ∏¨Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÁöÑÊΩõÂäõ„ÄÇ

##### **Dynamic feature selection in medical predictive monitoring by reinforcement learning**
2405.19729v1 by Yutong Chen, Jiandong Gao, Ji Wu

In this paper, we investigate dynamic feature selection within multivariate
time-series scenario, a common occurrence in clinical prediction monitoring
where each feature corresponds to a bio-test result. Many existing feature
selection methods fall short in effectively leveraging time-series information,
primarily because they are designed for static data. Our approach addresses
this limitation by enabling the selection of time-varying feature subsets for
each patient. Specifically, we employ reinforcement learning to optimize a
policy under maximum cost restrictions. The prediction model is subsequently
updated using synthetic data generated by trained policy. Our method can
seamlessly integrate with non-differentiable prediction models. We conducted
experiments on a sizable clinical dataset encompassing regression and
classification tasks. The results demonstrate that our approach outperforms
strong feature selection baselines, particularly when subjected to stringent
cost limitations. Code will be released once paper is accepted.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂Â§öËÆäÈáèÊôÇÈñìÂ∫èÂàóÂ†¥ÊôØ‰∏≠ÁöÑÂãïÊÖãÁâπÂæµÈÅ∏ÊìáÔºåÈÄôÂú®Ëá®Â∫ä‰∏äÈ†êÊ∏¨Áõ£Êéß‰∏≠ÂæàÂ∏∏Ë¶ãÔºåÂÖ∂‰∏≠ÊØèÂÄãÁâπÂæµÂ∞çÊáâÊñº‰∏ÄÂÄãÁîüÁâ©Ê™¢Ê∏¨ÁµêÊûú„ÄÇË®±Â§öÁèæÊúâÁöÑÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÂú®ÊúâÊïàÂà©Áî®ÊôÇÈñìÂ∫èÂàóË≥áË®äÊñπÈù¢ÂÅöÂæó‰∏¶‰∏çÂ•ΩÔºå‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÊòØÁÇ∫ÈùúÊÖãË≥áÊñôËÄåË®≠Ë®àÁöÑ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄöÈÅéÁÇ∫ÊØèÂÄãÊÇ£ËÄÖÂïüÁî®ÊôÇÈñìËÆäÁï∞ÁâπÂæµÂ≠êÈõÜÁöÑÈÅ∏Êìá‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®Âº∑ÂåñÂ≠∏Áøí‰æÜÂú®ÊúÄÂ§ßÊàêÊú¨ÈôêÂà∂‰∏ãÊúÄ‰Ω≥Âåñ‰∏ÄÂÄãÁ≠ñÁï•„ÄÇÈ†êÊ∏¨Ê®°ÂûãÈö®Âæå‰ΩøÁî®Áî±Ë®ìÁ∑¥Á≠ñÁï•Áî¢ÁîüÁöÑÂêàÊàêË≥áÊñôÊõ¥Êñ∞„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Ëàá‰∏çÂèØÂæÆÂàÜÈ†êÊ∏¨Ê®°ÂûãÁÑ°Á∏´Êï¥Âêà„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÂåÖÂê´ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑÂ§ßÂûãËá®Â∫äË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÂº∑Â§ßÁöÑÁâπÂæµÈÅ∏ÊìáÂü∫Á∑öÔºåÁâπÂà•ÊòØÂú®ÂèóÂà∞Âö¥Ê†ºÊàêÊú¨ÈôêÂà∂ÊôÇ„ÄÇ‰∏ÄÊó¶Ë´ñÊñáË¢´Êé•ÂèóÔºåÁ®ãÂºèÁ¢ºÂ∞áÊúÉÁôºÂ∏É„ÄÇ

##### **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**
2405.19654v1 by Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen

Medical vision-language pre-training methods mainly leverage the
correspondence between paired medical images and radiological reports. Although
multi-view spatial images and temporal sequences of image-report pairs are
available in off-the-shelf multi-modal medical datasets, most existing methods
have not thoroughly tapped into such extensive supervision signals. In this
paper, we introduce the Med-ST framework for fine-grained spatial and temporal
modeling to exploit information from multiple spatial views of chest
radiographs and temporal historical records. For spatial modeling, Med-ST
employs the Mixture of View Expert (MoVE) architecture to integrate different
visual features from both frontal and lateral views. To achieve a more
comprehensive alignment, Med-ST not only establishes the global alignment
between whole images and texts but also introduces modality-weighted local
alignment between text tokens and spatial regions of images. For temporal
modeling, we propose a novel cross-modal bidirectional cycle consistency
objective by forward mapping classification (FMC) and reverse mapping
regression (RMR). By perceiving temporal information from simple to complex,
Med-ST can learn temporal semantics. Experimental results across four distinct
tasks demonstrate the effectiveness of Med-ST, especially in temporal
classification tasks. Our code and model are available at
https://github.com/SVT-Yang/MedST.

ÊëòË¶ÅÔºöÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥ÊñπÊ≥ï‰∏ªË¶ÅÂà©Áî®ÈÖçÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèËàáÊîæÂ∞ÑÁßëÂ†±Âëä‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇ„ÄÇÂÑòÁÆ°ÁèæÊàêÁöÑÂ§öÊ®°ÂºèÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏≠Êèê‰æõ‰∫ÜÂ§öË¶ñËßíÁ©∫ÈñìÂΩ±ÂÉèÂíåÂΩ±ÂÉèÂ†±ÂëäÂ∞çÁöÑÊôÇÈñìÂ∫èÂàóÔºå‰ΩÜÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÂ∞öÊú™ÂæπÂ∫ïÂà©Áî®Â¶ÇÊ≠§Âª£Ê≥õÁöÑÁõ£Áù£Ë®äËôü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Med-ST Êû∂ÊßãÔºåÁî®ÊñºÁ≤æÁ¥∞ÁöÑÁ©∫ÈñìÂíåÊôÇÈñìÂª∫Ê®°Ôºå‰ª•Âà©Áî®ËÉ∏ÈÉ® X ÂÖâÁâáÁöÑË¶ñËßíÂíåÊôÇÈñìÊ≠∑Âè≤Ë®òÈåÑÁöÑË≥áË®ä„ÄÇÂ∞çÊñºÁ©∫ÈñìÂª∫Ê®°ÔºåMed-ST Êé°Áî®Ë¶ñËßíÂ∞àÂÆ∂Ê∑∑Âêà (MoVE) Êû∂ÊßãÔºå‰ª•Êï¥Âêà‰æÜËá™Ê≠£Èù¢ÂíåÂÅ¥Èù¢Ë¶ñËßíÁöÑ‰∏çÂêåË¶ñË¶∫ÁâπÂæµ„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÊõ¥ÂÖ®Èù¢ÁöÑÂ∞çÈΩäÔºåMed-ST ‰∏çÂÉÖÂª∫Á´ã‰∫ÜÊï¥ÂÄãÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÁöÑÂÖ®Â±ÄÂ∞çÈΩäÔºåÈÇÑÂºïÂÖ•‰∫ÜÊñáÂ≠óÁ¨¶ËôüÂíåÂΩ±ÂÉèÁ©∫ÈñìÂçÄÂüü‰πãÈñìÁöÑÊ®°ÊÖãÂä†Ê¨äÂ±ÄÈÉ®Â∞çÈΩä„ÄÇÂ∞çÊñºÊôÇÈñìÂª∫Ê®°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË∑®Ê®°ÊÖãÈõôÂêëÂæ™Áí∞‰∏ÄËá¥ÊÄßÁõÆÊ®ôÔºåÈÄöÈÅéÊ≠£ÂêëÊò†Â∞ÑÂàÜÈ°û (FMC) ÂíåÂèçÂêëÊò†Â∞ÑÂõûÊ≠∏ (RMR)„ÄÇÈÄöÈÅéÂæûÁ∞°ÂñÆÂà∞Ë§áÈõúÂú∞ÊÑüÁü•ÊôÇÈñìË≥áË®äÔºåMed-ST ÂèØ‰ª•Â≠∏ÁøíÊôÇÈñìË™ûÁæ©„ÄÇÂõõÂÄã‰∏çÂêå‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü Med-ST ÁöÑÊúâÊïàÊÄßÔºåÁâπÂà•ÊòØÂú®ÊôÇÈñìÂàÜÈ°û‰ªªÂãô‰∏≠„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØÂú® https://github.com/SVT-Yang/MedST ÂèñÂæó„ÄÇ

##### **Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**
2405.19631v1 by Akul Goel, Surya Narayanan Hari, Belinda Waltman, Matt Thomson

Social Determinants of Health (SDOH) play a significant role in patient
health outcomes. The Center of Disease Control (CDC) introduced a subset of
ICD-10 codes called Z-codes in an attempt to officially recognize and measure
SDOH in the health care system. However, these codes are rarely annotated in a
patient's Electronic Health Record (EHR), and instead, in many cases, need to
be inferred from clinical notes. Previous research has shown that large
language models (LLMs) show promise on extracting unstructured data from EHRs.
However, with thousands of models to choose from with unique architectures and
training sets, it's difficult to choose one model that performs the best on
coding tasks. Further, clinical notes contain trusted health information making
the use of closed-source language models from commercial vendors difficult, so
the identification of open source LLMs that can be run within health
organizations and exhibits high performance on SDOH tasks is an urgent problem.
Here, we introduce an intelligent routing system for SDOH coding that uses a
language model router to direct medical record data to open source LLMs that
demonstrate optimal performance on specific SDOH codes. The intelligent routing
system exhibits state of the art performance of 97.4% accuracy averaged across
5 codes, including homelessness and food insecurity, on par with closed models
such as GPT-4o. In order to train the routing system and validate models, we
also introduce a synthetic data generation and validation paradigm to increase
the scale of training data without needing privacy protected medical records.
Together, we demonstrate an architecture for intelligent routing of inputs to
task-optimal language models to achieve high performance across a set of
medical coding sub-tasks.

ÊëòË¶ÅÔºö<paragraph>ÂÅ•Â∫∑Á§æÊúÉÊ±∫ÂÆöÂõ†Á¥† (SDOH) Âú®ÊÇ£ËÄÖÂÅ•Â∫∑ÁµêÊûú‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁñæÁóÖÊéßÂà∂‰∏≠ÂøÉ (CDC) ÂºïÂÖ•‰∫Ü‰∏ÄÁµÑÁ®±ÁÇ∫ Z Á¢ºÁöÑ ICD-10 ‰ª£Á¢ºÔºåË©¶ÂúñÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠Ê≠£ÂºèË≠òÂà•ÂíåË°°Èáè SDOH„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ‰ª£Á¢ºÂæàÂ∞ëÂú®ÊÇ£ËÄÖÁöÑÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ‰∏≠Ë®ªËß£ÔºåËÄå‰∏îÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÈúÄË¶ÅÂæûËá®Â∫äÁ≠ÜË®ò‰∏≠Êé®Êñ∑Âá∫‰æÜ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âæû EHR ‰∏≠ÊèêÂèñÈùûÁµêÊßãÂåñÊï∏ÊìöÊñπÈù¢ÂæàÊúâÂâçÊôØ„ÄÇÁÑ∂ËÄåÔºåÊúâÊï∏ÂçÉÂÄãÊ®°ÂûãÂèØ‰æõÈÅ∏ÊìáÔºåÂÆÉÂÄëÂÖ∑ÊúâÁç®ÁâπÁöÑÊû∂ÊßãÂíåË®ìÁ∑¥ÈõÜÔºåÂõ†Ê≠§ÂæàÈõ£ÈÅ∏Êìá‰∏ÄÂÄãÂú®Á∑®Á¢º‰ªªÂãô‰∏äË°®ÁèæÊúÄ‰Ω≥ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåËá®Â∫äÁ≠ÜË®òÂåÖÂê´Âèó‰ø°‰ªªÁöÑÂÅ•Â∫∑Ë≥áË®äÔºåÈÄô‰ΩøÂæóÈõ£‰ª•‰ΩøÁî®ÂïÜÊ•≠‰æõÊáâÂïÜÁöÑÈñâÊ∫êË™ûË®ÄÊ®°ÂûãÔºåÂõ†Ê≠§ÔºåË≠òÂà•ÂèØ‰ª•Âú®ÈÜ´ÁôÇÊ©üÊßãÂÖßÈÅã‰Ωú‰∏îÂú® SDOH ‰ªªÂãô‰∏äË°®ÁèæÂá∫È´òÊÄßËÉΩÁöÑÈñãÊ∫ê LLM ÊòØÂÄãËø´ÂàáÁöÑÂïèÈ°å„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®Êñº SDOH Á∑®Á¢ºÁöÑÊô∫ÊÖßË∑ØÁî±Á≥ªÁµ±ÔºåÂÆÉ‰ΩøÁî®Ë™ûË®ÄÊ®°ÂûãË∑ØÁî±Âô®Â∞áÁóÖÊ≠∑Ë≥áÊñôÂ∞éÂêëÂú®ÁâπÂÆö SDOH ‰ª£Á¢º‰∏äË°®ÁèæÂá∫ÊúÄ‰Ω≥ÊÄßËÉΩÁöÑÈñãÊ∫ê LLM„ÄÇÊô∫ÊÖßË∑ØÁî±Á≥ªÁµ±Â±ïÁèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÂú® 5 ÂÄã‰ª£Á¢ºÔºàÂåÖÊã¨ÁÑ°ÂÆ∂ÂèØÊ≠∏ÂíåÁ≥ßÈ£ü‰∏çÂÆâÂÖ®ÔºâÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 97.4%ÔºåËàá GPT-4o Á≠âÈñâÂêàÊ®°Âûã‰∏çÁõ∏‰∏ä‰∏ã„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥Ë∑ØÁî±Á≥ªÁµ±ÂíåÈ©óË≠âÊ®°ÂûãÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂêàÊàêË≥áÊñôÁîüÊàêÂíåÈ©óË≠âÁØÑ‰æãÔºå‰ª•Â¢ûÂä†Ë®ìÁ∑¥Ë≥áÊñôÁöÑË¶èÊ®°ÔºåËÄåÁÑ°ÈúÄÂèóÈö±ÁßÅ‰øùË≠∑ÁöÑÁóÖÊ≠∑„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊô∫ÊÖßË∑ØÁî±Êû∂ÊßãÔºåÁî®ÊñºÂ∞áËº∏ÂÖ•Ë∑ØÁî±Âà∞‰ªªÂãôÊúÄ‰Ω≥Ë™ûË®ÄÊ®°ÂûãÔºå‰ª•Âú®ÈÜ´ÁôÇÁ∑®Á¢ºÂ≠ê‰ªªÂãô‰∏≠ÂØ¶ÁèæÈ´òÊÄßËÉΩ„ÄÇ</paragraph>

##### **Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**
2405.19567v1 by Shenghuan Sun, Gregory M. Goldgof, Alexander Schubert, Zhiqing Sun, Thomas Hartvigsen, Atul J. Butte, Ahmed Alaa

Vision-Language Models (VLM) can support clinicians by analyzing medical
images and engaging in natural language interactions to assist in diagnostic
and treatment tasks. However, VLMs often exhibit "hallucinogenic" behavior,
generating textual outputs not grounded in contextual multimodal information.
This challenge is particularly pronounced in the medical domain, where we do
not only require VLM outputs to be accurate in single interactions but also to
be consistent with clinical reasoning and diagnostic pathways throughout
multi-turn conversations. For this purpose, we propose a new alignment
algorithm that uses symbolic representations of clinical reasoning to ground
VLMs in medical knowledge. These representations are utilized to (i) generate
GPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM
conversations with demonstrations of clinical reasoning, and (ii) create an
automatic reward function that evaluates the clinical validity of VLM
generations throughout clinician-VLM interactions. Our algorithm eliminates the
need for human involvement in training data generation or reward model
construction, reducing costs compared to standard reinforcement learning with
human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a
conversational VLM finetuned for analyzing bone marrow pathology slides,
demonstrating strong performance in multi-turn medical conversations.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÂèØÈÄèÈÅéÂàÜÊûêÈÜ´ÁôÇÂΩ±ÂÉè‰∏¶ÈÄ≤Ë°åËá™ÁÑ∂Ë™ûË®Ä‰∫íÂãï‰æÜÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÔºå‰ª•ÂçîÂä©Ë®∫Êñ∑ÂíåÊ≤ªÁôÇ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåVLM Á∂ìÂ∏∏Ë°®ÁèæÂá∫„ÄåÂπªË¶∫„ÄçË°åÁÇ∫ÔºåÁî¢ÁîüÊú™Âü∫ÊñºËÑàÁµ°Â§öÊ®°ÊÖãË≥áË®äÁöÑÊñáÂ≠óËº∏Âá∫„ÄÇÈÄôÂÄãÊåëÊà∞Âú®ÈÜ´ÁôÇÈ†òÂüüÁâπÂà•ÊòéÈ°ØÔºåÂõ†ÁÇ∫ÊàëÂÄë‰∏çÂÉÖË¶ÅÊ±Ç VLM Ëº∏Âá∫Âú®ÂñÆ‰∏Ä‰∫íÂãï‰∏≠Ê∫ñÁ¢∫ÔºåÈÇÑÂøÖÈ†àÂú®Â§öËº™Â∞çË©±‰∏≠ËàáËá®Â∫äÊé®ÁêÜÂíåË®∫Êñ∑ÈÄîÂæë‰øùÊåÅ‰∏ÄËá¥„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∞çÈΩäÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî®Ëá®Â∫äÊé®ÁêÜÁöÑÁ¨¶ËôüË°®Á§∫Ê≥ïÂ∞á VLM Âª∫Á´ãÂú®ÈÜ´Â≠∏Áü•Ë≠ò‰∏ä„ÄÇÈÄô‰∫õË°®Á§∫Ê≥ïÁî®ÊñºÔºö(i) ÁîüÊàê GPT-4 ÂºïÂ∞éÁöÑË¶ñË¶∫Êåá‰ª§Ë™øÊï¥Ë≥áÊñôÔºåÊ®°Êì¨Ëá®Â∫äÈÜ´Áîü-VLM Â∞çË©±Ôºå‰∏¶Â±ïÁ§∫Ëá®Â∫äÊé®ÁêÜÔºå‰ª•Âèä (ii) Âª∫Á´ã‰∏ÄÂÄãËá™ÂãïÁçéÂãµÂáΩÊï∏ÔºåÁî®ÊñºË©ï‰º∞ VLM ÁîüÊàêÂú®Ëá®Â∫äÈÜ´Áîü-VLM ‰∫íÂãï‰∏≠ÁöÑËá®Â∫äÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊ∂àÈô§‰∫ÜÂú®Ë®ìÁ∑¥Ë≥áÊñôÁîüÊàêÊàñÁçéÂãµÊ®°ÂûãÂª∫Êßã‰∏≠ÈúÄË¶Å‰∫∫Â∑•ÂèÉËàáÔºåËàáÈúÄË¶Å‰∫∫Â∑•ÂõûÈ•ãÔºàRLHFÔºâÁöÑÊ®ôÊ∫ñÂº∑ÂåñÂ≠∏ÁøíÁõ∏ÊØîÔºåÈôç‰Ωé‰∫ÜÊàêÊú¨„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂ∞çÈΩäÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÈñãÁôº Dr-LLaVAÔºåÈÄôÊòØ‰∏ÄÂÄãÈáùÂ∞çÂàÜÊûêÈ™®È´ìÁóÖÁêÜÂàáÁâáÈÄ≤Ë°åÂæÆË™øÁöÑÂ∞çË©±Âºè VLMÔºåÂú®Â§öËº™ÈÜ´ÁôÇÂ∞çË©±‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊïàËÉΩ„ÄÇ

##### **CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients**
2405.19538v1 by Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang, Zhihong Chen, Maya Varma, Steven QH Truong, Chu The Chuong, Curtis P. Langlotz

Since the release of the original CheXpert paper five years ago, CheXpert has
become one of the most widely used and cited clinical AI datasets. The
emergence of vision language models has sparked an increase in demands for
sharing reports linked to CheXpert images, along with a growing interest among
AI fairness researchers in obtaining demographic data. To address this,
CheXpert Plus serves as a new collection of radiology data sources, made
publicly available to enhance the scaling, performance, robustness, and
fairness of models for all subsequent machine learning tasks in the field of
radiology. CheXpert Plus is the largest text dataset publicly released in
radiology, with a total of 36 million text tokens, including 13 million
impression tokens. To the best of our knowledge, it represents the largest text
de-identification effort in radiology, with almost 1 million PHI spans
anonymized. It is only the second time that a large-scale English paired
dataset has been released in radiology, thereby enabling, for the first time,
cross-institution training at scale. All reports are paired with high-quality
images in DICOM format, along with numerous image and patient metadata covering
various clinical and socio-economic groups, as well as many pathology labels
and RadGraph annotations. We hope this dataset will boost research for AI
models that can further assist radiologists and help improve medical care. Data
is available at the following URL:
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Models are available at the following URL:
https://github.com/Stanford-AIMI/chexpert-plus

ÊëòË¶ÅÔºöËá™‰∫îÂπ¥ÂâçÂéüÂßã CheXpert ËÆ∫ÊñáÂèëÂ∏É‰ª•Êù•ÔºåCheXpert Â∑≤Êàê‰∏∫‰ΩøÁî®ÊúÄÂπøÊ≥õ‰∏îÂºïÁî®ÊúÄÂ§öÁöÑ‰∏¥Â∫ä AI Êï∞ÊçÆÈõÜ‰πã‰∏Ä„ÄÇËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂØπÂÖ±‰∫´‰∏é CheXpert ÂõæÂÉèÁõ∏ÂÖ≥ËÅîÁöÑÊä•ÂëäÁöÑÈúÄÊ±ÇÂ¢ûÂä†Ôºå‰ª•Âèä AI ÂÖ¨Âπ≥ÊÄßÁ†îÁ©∂‰∫∫ÂëòÂØπËé∑Âèñ‰∫∫Âè£ÁªüËÆ°Êï∞ÊçÆÁöÑÂÖ¥Ë∂£Êó•ÁõäÊµìÂéö„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåCheXpert Plus ‰Ωú‰∏∫ÊîæÂ∞ÑÂ≠¶Êï∞ÊçÆÊ∫êÁöÑÊñ∞ÈõÜÂêàÔºåÂÖ¨ÂºÄÊèê‰æõÔºå‰ª•Â¢ûÂº∫ÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÊâÄÊúâÂêéÁª≠Êú∫Âô®Â≠¶‰π†‰ªªÂä°ÁöÑÊ®°ÂûãÁöÑÂèØÊâ©Â±ïÊÄß„ÄÅÊÄßËÉΩ„ÄÅÈ≤ÅÊ£íÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇCheXpert Plus ÊòØÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÂÖ¨ÂºÄÂèëÂ∏ÉÁöÑÊúÄÂ§ßÊñáÊú¨Êï∞ÊçÆÈõÜÔºåÊÄªÂÖ±Êúâ 3600 ‰∏á‰∏™ÊñáÊú¨Ê†áËÆ∞ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ 1300 ‰∏á‰∏™Âç∞Ë±°Ê†áËÆ∞„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåÂÆÉ‰ª£Ë°®‰∫ÜÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÊúÄÂ§ßÁöÑÊñáÊú¨ÂéªËØÜÂà´Â∑•‰ΩúÔºåÂá†‰πéÊúâ 100 ‰∏á‰∏™ PHI Ë∑®Â∫¶Ë¢´ÂåøÂêçÂåñ„ÄÇËøôÊòØÊîæÂ∞ÑÂ≠¶È¢ÜÂüüÁ¨¨‰∫åÊ¨°ÂèëÂ∏ÉÂ§ßËßÑÊ®°Ëã±ËØ≠ÈÖçÂØπÊï∞ÊçÆÈõÜÔºå‰ªéËÄåÈ¶ñÊ¨°ÂÆûÁé∞‰∫ÜÂ§ßËßÑÊ®°ÁöÑË∑®Êú∫ÊûÑÂüπËÆ≠„ÄÇÊâÄÊúâÊä•ÂëäÈÉΩ‰∏é DICOM Ê†ºÂºèÁöÑÈ´òË¥®ÈáèÂõæÂÉèÈÖçÂØπÔºå‰ª•ÂèäÊ∂µÁõñÂêÑÁßç‰∏¥Â∫äÂíåÁ§æ‰ºöÁªèÊµéÁæ§‰ΩìÁöÑÂ§ßÈáèÂõæÂÉèÂíåÊÇ£ËÄÖÂÖÉÊï∞ÊçÆÔºå‰ª•ÂèäËÆ∏Â§öÁóÖÁêÜÊ†áÁ≠æÂíå RadGraph Ê≥®Èáä„ÄÇÊàë‰ª¨Â∏åÊúõÊ≠§Êï∞ÊçÆÈõÜÂ∞Ü‰øÉËøõ‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÁ†îÁ©∂ÔºåËøô‰∫õÊ®°ÂûãÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂçèÂä©ÊîæÂ∞ÑÁßëÂåªÁîüÂπ∂Â∏ÆÂä©ÊîπÂñÑÂåªÁñó‰øùÂÅ•„ÄÇÊï∞ÊçÆÂèØÂú®‰ª•‰∏ã URL Ëé∑ÂæóÔºö
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Ê®°ÂûãÂèØÂú®‰ª•‰∏ã URL Ëé∑ÂæóÔºö
https://github.com/Stanford-AIMI/chexpert-plus

##### **Participation in the age of foundation models**
2405.19479v1 by Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy

Growing interest and investment in the capabilities of foundation models has
positioned such systems to impact a wide array of public services. Alongside
these opportunities is the risk that these systems reify existing power
imbalances and cause disproportionate harm to marginalized communities.
Participatory approaches hold promise to instead lend agency and
decision-making power to marginalized stakeholders. But existing approaches in
participatory AI/ML are typically deeply grounded in context - how do we apply
these approaches to foundation models, which are, by design, disconnected from
context? Our paper interrogates this question.
  First, we examine existing attempts at incorporating participation into
foundation models. We highlight the tension between participation and scale,
demonstrating that it is intractable for impacted communities to meaningfully
shape a foundation model that is intended to be universally applicable. In
response, we develop a blueprint for participatory foundation models that
identifies more local, application-oriented opportunities for meaningful
participation. In addition to the "foundation" layer, our framework proposes
the "subfloor'' layer, in which stakeholders develop shared technical
infrastructure, norms and governance for a grounded domain, and the "surface''
layer, in which affected communities shape the use of a foundation model for a
specific downstream task. The intermediate "subfloor'' layer scopes the range
of potential harms to consider, and affords communities more concrete avenues
for deliberation and intervention. At the same time, it avoids duplicative
effort by scaling input across relevant use cases. Through three case studies
in clinical care, financial services, and journalism, we illustrate how this
multi-layer model can create more meaningful opportunities for participation
than solely intervening at the foundation layer.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºÂü∫Á§éÊ®°ÂûãËÉΩÂäõÁöÑËààË∂£ÂíåÊäïË≥áÊó•ÁõäÂ¢ûÈï∑ÔºåÂ∑≤‰ΩøÊ≠§È°ûÁ≥ªÁµ±ËÉΩÂ§†ÂΩ±ÈüøÂª£Ê≥õÁöÑÂÖ¨ÂÖ±ÊúçÂãô„ÄÇÈô§‰∫ÜÈÄô‰∫õÊ©üÊúÉ‰πãÂ§ñÔºåÈÄô‰∫õÁ≥ªÁµ±ÈÇÑÂ≠òÂú®Âº∑ÂåñÊó¢ÊúâÊ¨äÂäõÂ§±Ë°°‰∏¶Â∞çÈÇäÁ∑£ÂåñÁ§æÁæ§ÈÄ†Êàê‰∏çÊàêÊØî‰æãÂÇ∑ÂÆ≥ÁöÑÈ¢®Èö™„ÄÇÂèÉËàáÂºèÊñπÊ≥ïÊúâÊúõË≥¶‰∫àÈÇäÁ∑£ÂåñÂà©ÁõäÁõ∏ÈóúËÄÖ‰ª£ÁêÜÊ¨äÂíåÊ±∫Á≠ñÊ¨ä„ÄÇ‰ΩÜÁèæÊúâÁöÑÂèÉËàáÂºè AI/ML ÊñπÊ≥ïÈÄöÂ∏∏Ê∑±Ê§çÊñºËÑàÁµ°‰∏≠ - ÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊñπÊ≥ïÊáâÁî®ÊñºÂü∫Á§éÊ®°ÂûãÔºåËÄåÈÄô‰∫õÊ®°ÂûãÂú®Ë®≠Ë®à‰∏äËàáËÑàÁµ°ÁÑ°ÈóúÔºüÊàëÂÄëÁöÑË´ñÊñáÂØ©Ë¶ñ‰∫ÜÈÄôÂÄãÂïèÈ°å„ÄÇ
È¶ñÂÖàÔºåÊàëÂÄëÊ™¢Ë¶ñÂ∞áÂèÉËàáÁ¥çÂÖ•Âü∫Á§éÊ®°ÂûãÁöÑÊó¢ÊúâÂòóË©¶„ÄÇÊàëÂÄëÂº∑Ë™øÂèÉËàáËàáË¶èÊ®°‰πãÈñìÁöÑÁ∑äÂºµÈóú‰øÇÔºåË≠âÊòéÂèóÂΩ±ÈüøÁöÑÁ§æÁæ§Èõ£‰ª•ÊúâÊÑèÁæ©Âú∞Â°ëÈÄ†‰∏ÄÂÄãÊó®Âú®ÊôÆÈÅçÈÅ©Áî®ÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÂèÉËàáÂºèÂü∫Á§éÊ®°ÂûãËóçÂúñÔºåÊâæÂá∫Êõ¥Âú®Âú∞Âåñ„ÄÅÊõ¥‰ª•ÊáâÁî®ÁÇ∫Â∞éÂêëÁöÑÊúâÊÑèÁæ©ÂèÉËàáÊ©üÊúÉ„ÄÇÈô§‰∫Ü„ÄåÂü∫Á§é„ÄçÂ±§ÔºåÊàëÂÄëÁöÑÊû∂ÊßãÈÇÑÊèêÂá∫‰∫Ü„ÄåÊ¨°Â±§„ÄçÂ±§ÔºåÂú®ÂÖ∂‰∏≠ÔºåÂà©ÁõäÁõ∏ÈóúËÄÖÊúÉÁÇ∫‰∏ÄÂÄãÁ¥ÆÊ†πÁöÑÈ†òÂüüÈñãÁôºÂÖ±‰∫´ÊäÄË°ìÂü∫Á§éË®≠ÊñΩ„ÄÅË¶èÁØÑÂíåÊ≤ªÁêÜÔºå‰ª•Âèä„ÄåË°®Èù¢„ÄçÂ±§ÔºåÂú®ÂÖ∂‰∏≠ÔºåÂèóÂΩ±ÈüøÁöÑÁ§æÁæ§ÊúÉÂ°ëÈÄ†Âü∫Á§éÊ®°ÂûãÂú®ÁâπÂÆö‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑ‰ΩøÁî®ÊñπÂºè„ÄÇ‰∏≠ÈñìÁöÑ„ÄåÊ¨°Â±§„ÄçÂ±§ÁïåÂÆö‰∫ÜË¶ÅËÄÉÈáèÁöÑÊΩõÂú®Âç±ÂÆ≥ÁØÑÂúçÔºå‰∏¶ÁÇ∫Á§æÁæ§Êèê‰æõ‰∫ÜÊõ¥ÂÖ∑È´îÁöÑÂØ©Ë≠∞Âíå‰ªãÂÖ•ÁÆ°ÈÅì„ÄÇÂêåÊôÇÔºåÂÆÉÈÄèÈÅéÊì¥Â±ïËº∏ÂÖ•Âà∞Áõ∏ÈóúÁî®‰æã‰∏≠‰æÜÈÅøÂÖçÈáçË§áÁöÑÂä™Âäõ„ÄÇÈÄèÈÅéËá®Â∫äÁÖßË≠∑„ÄÅÈáëËûçÊúçÂãôÂíåÊñ∞ËÅûÊ•≠‰∏≠ÁöÑ‰∏âÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË™™Êòé‰∫ÜÈÄôÂÄãÂ§öÂ±§Ê®°ÂûãÂ¶Ç‰ΩïËÉΩÂâµÈÄ†Âá∫ÊØîÂÉÖÂú®Âü∫Á§éÂ±§ÈÄ≤Ë°å‰ªãÂÖ•Êõ¥ÊúâÊÑèÁæ©ÁöÑÂèÉËàáÊ©üÊúÉ„ÄÇ</paragraph>

##### **MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**
2405.19458v1 by Raman Dutt, Pedro Sanchez, Ondrej Bohdal, Sotirios A. Tsaftaris, Timothy Hospedales

Diffusion models show a remarkable ability in generating images that closely
mirror the training distribution. However, these models are prone to training
data memorization, leading to significant privacy, ethical, and legal concerns,
particularly in sensitive fields such as medical imaging. We hypothesize that
memorization is driven by the overparameterization of deep models, suggesting
that regularizing model capacity during fine-tuning could be an effective
mitigation strategy. Parameter-efficient fine-tuning (PEFT) methods offer a
promising approach to capacity control by selectively updating specific
parameters. However, finding the optimal subset of learnable parameters that
balances generation quality and memorization remains elusive. To address this
challenge, we propose a bi-level optimization framework that guides automated
parameter selection by utilizing memorization and generation quality metrics as
rewards. Our framework successfully identifies the optimal parameter set to be
updated to satisfy the generation-memorization tradeoff. We perform our
experiments for the specific task of medical image generation and outperform
existing state-of-the-art training-time mitigation strategies by fine-tuning as
few as 0.019% of model parameters. Furthermore, we show that the strategies
learned through our framework are transferable across different datasets and
domains. Our proposed framework is scalable to large datasets and agnostic to
the choice of reward functions. Finally, we show that our framework can be
combined with existing approaches for further memorization mitigation.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂú®ÁîüÊàêËàáË®ìÁ∑¥ÂàÜ‰ΩàÂØÜÂàáÁõ∏ÈóúÁöÑÂúñÂÉèÊñπÈù¢Ë°®ÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÆπÊòìË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂ÔºåÂ∞éËá¥Âö¥ÈáçÁöÑÈö±ÁßÅ„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÂïèÈ°åÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇÂΩ±ÂÉèÁ≠âÊïèÊÑüÈ†òÂüü„ÄÇÊàëÂÄëÂÅáË®≠Ë®òÊÜ∂ÊòØÁî±Ê∑±Â∫¶Ê®°ÂûãÁöÑÈÅéÂ∫¶ÂèÉÊï∏ÂåñÈ©ÖÂãïÁöÑÔºåÈÄôË°®ÊòéÂú®ÂæÆË™øÊúüÈñìË¶èÁØÑÊ®°ÂûãÂÆπÈáèÂèØËÉΩÊòØÊúâÊïàÁöÑÁ∑©Ëß£Á≠ñÁï•„ÄÇÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÂÆπÈáèÊéßÂà∂ÊñπÊ≥ïÔºåÈÄöÈÅéÈÅ∏ÊìáÊÄßÂú∞Êõ¥Êñ∞ÁâπÂÆöÂèÉÊï∏„ÄÇÁÑ∂ËÄåÔºåÊâæÂà∞Âπ≥Ë°°ÁîüÊàêÂìÅË≥™ÂíåË®òÊÜ∂ÁöÑÊúÄ‰Ω≥ÂèØÂ≠∏ÁøíÂèÉÊï∏Â≠êÈõÜ‰ªçÁÑ∂Èõ£‰ª•ÊçâÊë∏„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈõôÂ±§ÂÑ™ÂåñÊ°ÜÊû∂ÔºåÈÄöÈÅéÂà©Áî®Ë®òÊÜ∂ÂíåÁîüÊàêÂìÅË≥™ÊåáÊ®ô‰ΩúÁÇ∫ÁçéÂãµ‰æÜÊåáÂ∞éËá™ÂãïÂåñÂèÉÊï∏ÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÊàêÂäüÂú∞Ë≠òÂà•‰∫ÜË¶ÅÊõ¥Êñ∞ÁöÑÊúÄ‰Ω≥ÂèÉÊï∏ÈõÜÔºå‰ª•ÊªøË∂≥ÁîüÊàêË®òÊÜ∂Ê¨äË°°„ÄÇÊàëÂÄëÈáùÂ∞çÈÜ´ÁôÇÂΩ±ÂÉèÁîüÊàêÂÖ∑È´î‰ªªÂãôÂü∑Ë°åÊàëÂÄëÁöÑÂØ¶È©óÔºå‰∏¶‰∏îÈÄèÈÅéÂæÆË™øÂÉÖ 0.019% ÁöÑÊ®°ÂûãÂèÉÊï∏ÔºåÂ∞±ÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑË®ìÁ∑¥ÊôÇÈñìÁ∑©Ëß£Á≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÈÄèÈÅéÊàëÂÄëÁöÑÊ°ÜÊû∂Â≠∏ÁøíÂà∞ÁöÑÁ≠ñÁï•ÂèØ‰ª•ËΩâÁßªÂà∞‰∏çÂêåÁöÑË≥áÊñôÈõÜÂíåÈ†òÂüü„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ÂèØÊì¥ÂÖÖÂà∞Â§ßÂûãË≥áÊñôÈõÜÔºå‰∏¶‰∏îËàáÁçéÂãµÂáΩÊï∏ÁöÑÈÅ∏ÊìáÁÑ°Èóú„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÊ°ÜÊû∂ÂèØ‰ª•ËàáÁèæÊúâÊñπÊ≥ïÁµêÂêàÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Ê∏õÂ∞ëË®òÊÜ∂„ÄÇ

##### **Conformal Depression Prediction**
2405.18723v1 by Yonghong Li, Shan Qu, Xiuzhuang Zhou

While existing depression recognition methods based on deep learning show
promise, their practical application is hindered by the lack of
trustworthiness, as these deep models are often deployed as \textit{black box}
models, leaving us uncertain about the confidence of the model predictions. For
high-risk clinical applications like depression recognition, uncertainty
quantification is essential in decision-making. In this paper, we introduce
conformal depression prediction (CDP), a depression recognition method with
uncertainty quantification based on conformal prediction (CP), giving valid
confidence intervals with theoretical coverage guarantees for the model
predictions. CDP is a plug-and-play module that requires neither model
retraining nor an assumption about the depression data distribution. As CDP
provides only an average performance guarantee across all inputs rather than
per-input performance guarantee, we propose CDP-ACC, an improved conformal
prediction with approximate conditional coverage. CDP-ACC firstly estimates the
prediction distribution through neighborhood relaxation, and then introduces a
conformal score function by constructing nested sequences, so as to provide
tighter prediction interval for each specific input. We empirically demonstrate
the application of uncertainty quantification in depression recognition, and
the effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC
2014 datasets

ÊëòË¶ÅÔºöÂÑòÁÆ°ÁèæÊúâÁöÑÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊÜÇÈ¨±ÁóáËæ®Ë≠òÊñπÊ≥ïÈ°ØÁ§∫Âá∫ÂâçÊôØÔºåÂÖ∂ÂØ¶ÈöõÊáâÁî®ÂçªÂèóÂà∞ÂèØ‰ø°Â∫¶ÁöÑ‰∏çË∂≥ÊâÄÈòªÁ§ôÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ∑±Â∫¶Ê®°ÂûãÁ∂ìÂ∏∏Ë¢´ÈÉ®ÁΩ≤ÁÇ∫„ÄåÈªëÁÆ±„ÄçÊ®°ÂûãÔºåËÆìÊàëÂÄëÁÑ°Ê≥ïÁ¢∫ÂÆöÊ®°ÂûãÈ†êÊ∏¨ÁöÑÁΩÆ‰ø°Â∫¶„ÄÇÂ∞çÊñºÊÜÇÈ¨±ÁóáËæ®Ë≠òÁ≠âÈ´òÈ¢®Èö™ÁöÑËá®Â∫äÊáâÁî®Ôºå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂú®Ê±∫Á≠ñÂà∂ÂÆö‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÖ±ÂΩ¢ÊÜÇÈ¨±ÁóáÈ†êÊ∏¨ (CDP)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂÖ±ÂΩ¢È†êÊ∏¨ (CP) ÁöÑÊÜÇÈ¨±ÁóáËæ®Ë≠òÊñπÊ≥ïÔºåÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÔºåÂèØÊèê‰æõÊ®°ÂûãÈ†êÊ∏¨ÁöÑÊúâÊïàÁΩÆ‰ø°ÂçÄÈñìÔºå‰∏¶‰øùË≠âÁêÜË´ñÊ∂µËìãÁéá„ÄÇCDP ÊòØ‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÊ®°ÁµÑÔºåÊó¢‰∏çÈúÄË¶ÅÈáçÊñ∞Ë®ìÁ∑¥Ê®°ÂûãÔºå‰πü‰∏çÈúÄË¶ÅÂÅáË®≠ÊÜÇÈ¨±ÁóáË≥áÊñôÂàÜ‰Ωà„ÄÇÁî±Êñº CDP ÂÉÖÊèê‰æõÊâÄÊúâËº∏ÂÖ•ÁöÑÂπ≥ÂùáÊïàËÉΩ‰øùË≠âÔºåËÄå‰∏çÊòØÊØèÂÄãËº∏ÂÖ•ÁöÑÊïàËÉΩ‰øùË≠âÔºåÂõ†Ê≠§ÊàëÂÄëÊèêÂá∫‰∫Ü CDP-ACCÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∑ÊúâËøë‰ººÊ¢ù‰ª∂Ê∂µËìãÁéáÁöÑÊîπËâØÂÖ±ÂΩ¢È†êÊ∏¨„ÄÇCDP-ACC È¶ñÂÖàÈÄèÈÅéÈÑ∞ÂüüÊîæÈ¨Ü‰æÜ‰º∞Ë®àÈ†êÊ∏¨ÂàÜ‰ΩàÔºåÁÑ∂ÂæåÈÄèÈÅéÂª∫ÊßãÂ∑¢ÁãÄÂ∫èÂàó‰æÜÂºïÂÖ•ÂÖ±ÂΩ¢Ë©ïÂàÜÂáΩÊï∏Ôºå‰ª•‰æøÁÇ∫ÊØèÂÄãÁâπÂÆöËº∏ÂÖ•Êèê‰æõÊõ¥Âö¥Ê†ºÁöÑÈ†êÊ∏¨ÂçÄÈñì„ÄÇÊàëÂÄëÊÜëÁ∂ìÈ©óË≠âÊòé‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂú®ÊÜÇÈ¨±ÁóáËæ®Ë≠ò‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•Âèä CDP Âíå CDP-ACC Âú® AVEC 2013 Âíå AVEC 2014 Ë≥áÊñôÈõÜ‰∏äÁöÑÊúâÊïàÊÄßÂíåÂÑ™Ë∂äÊÄß

##### **D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**
2405.18658v1 by Haoyu Hu, Hongrun Zhang, Chao Li

Brain network is an important tool for understanding the brain, offering
insights for scientific research and clinical diagnosis. Existing models for
brain networks typically primarily focus on brain regions or overlook the
complexity of brain connectivities. MRI-derived brain network data is commonly
susceptible to connectivity noise, underscoring the necessity of incorporating
connectivities into the modeling of brain networks. To address this gap, we
introduce a differentiable module for refining brain connectivity. We develop
the multivariate optimization based on information bottleneck theory to address
the complexity of the brain network and filter noisy or redundant connections.
Also, our method functions as a flexible plugin that is adaptable to most graph
neural networks. Our extensive experimental results show that the proposed
method can significantly improve the performance of various baseline models and
outperform other state-of-the-art methods, indicating the effectiveness and
generalizability of the proposed method in refining brain network connectivity.
The code will be released for public availability.

ÊëòË¶ÅÔºöÂ§ßËÖ¶Á∂≤Ë∑ØÊòØÁêÜËß£Â§ßËÖ¶ÁöÑÈáçË¶ÅÂ∑•ÂÖ∑ÔºåÁÇ∫ÁßëÂ≠∏Á†îÁ©∂ÂíåËá®Â∫äË®∫Êñ∑Êèê‰æõË¶ãËß£„ÄÇÁèæÊúâÁöÑÂ§ßËÖ¶Á∂≤Ë∑ØÊ®°ÂûãÈÄöÂ∏∏‰∏ªË¶ÅÈóúÊ≥®Â§ßËÖ¶ÂçÄÂüüÊàñÂøΩÁï•Â§ßËÖ¶ÈÄ£Êé•ÁöÑË§áÈõúÊÄß„ÄÇÊ∫êËá™ MRI ÁöÑÂ§ßËÖ¶Á∂≤Ë∑ØË≥áÊñôÈÄöÂ∏∏ÂÆπÊòìÂèóÂà∞ÈÄ£Êé•ÈõúË®äÁöÑÂΩ±ÈüøÔºåÈÄôÂº∑Ë™ø‰∫ÜÂ∞áÈÄ£Êé•Á¥çÂÖ•Â§ßËÖ¶Á∂≤Ë∑ØÂª∫Ê®°ÁöÑÂøÖË¶ÅÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØÂçÄÂàÜÁöÑÊ®°ÁµÑ‰æÜÁ≤æÁÖâÂ§ßËÖ¶ÈÄ£Êé•ÊÄß„ÄÇÊàëÂÄëÊ†πÊìöË≥áË®äÁì∂È†∏ÁêÜË´ñÈñãÁôºÂ§öËÆäÊï∏ÊúÄ‰Ω≥ÂåñÔºå‰ª•Ëß£Ê±∫Â§ßËÖ¶Á∂≤Ë∑ØÁöÑË§áÈõúÊÄß‰∏¶ÈÅéÊøæÈõúË®äÊàñÂÜóÈ§òÈÄ£Êé•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ΩúÁÇ∫‰∏ÄÂÄãÈùàÊ¥ªÁöÑÂ§ñÊéõÁ®ãÂºèÔºåÈÅ©Áî®ÊñºÂ§ßÂ§öÊï∏ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•È°ØËëóÊîπÂñÑÂêÑÁ®ÆÂü∫Ê∫ñÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰∏¶ÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÈÄôË°®ÊòéÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Á≤æÁÖâÂ§ßËÖ¶Á∂≤Ë∑ØÈÄ£Êé•ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíåÊ¶ÇÊã¨ÊÄß„ÄÇË©≤Á®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÁôºÂ∏É„ÄÇ

##### **DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**
2405.18610v1 by Zhiyao Luo, Mingcheng Zhu, Fenglin Liu, Jiali Li, Yangchen Pan, Jiandong Zhou, Tingting Zhu

Reinforcement learning (RL) has garnered increasing recognition for its
potential to optimise dynamic treatment regimes (DTRs) in personalised
medicine, particularly for drug dosage prescriptions and medication
recommendations. However, a significant challenge persists: the absence of a
unified framework for simulating diverse healthcare scenarios and a
comprehensive analysis to benchmark the effectiveness of RL algorithms within
these contexts. To address this gap, we introduce \textit{DTR-Bench}, a
benchmarking platform comprising four distinct simulation environments tailored
to common DTR applications, including cancer chemotherapy, radiotherapy,
glucose management in diabetes, and sepsis treatment. We evaluate various
state-of-the-art RL algorithms across these settings, particularly highlighting
their performance amidst real-world challenges such as
pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.
Our experiments reveal varying degrees of performance degradation among RL
algorithms in the presence of noise and patient variability, with some
algorithms failing to converge. Additionally, we observe that using temporal
observation representations does not consistently lead to improved performance
in DTR settings. Our findings underscore the necessity of developing robust,
adaptive RL algorithms capable of effectively managing these complexities to
enhance patient-specific healthcare. We have open-sourced our benchmark and
code at https://github.com/GilesLuo/DTR-Bench.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) Âõ†ÂÖ∂ÊúÄ‰Ω≥ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇ‰∏≠ÁöÑÂãïÊÖãÊ≤ªÁôÇÊñπÊ°à (DTR) ÁöÑÊΩõÂäõËÄåÁç≤ÂæóË∂ä‰æÜË∂äÂ§öÁöÑË™çÂèØÔºåÁâπÂà•ÊòØÂú®Ëó•Áâ©ÂäëÈáèËôïÊñπÂíåËó•Áâ©Âª∫Ë≠∞ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞‰ªçÁÑ∂Â≠òÂú®ÔºöÁº∫‰πè‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂‰æÜÊ®°Êì¨‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Â†¥ÊôØÔºå‰ª•Âèä‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂàÜÊûê‰æÜÊØîËºÉ RL ÊºîÁÆóÊ≥ïÂú®ÈÄô‰∫õÂ†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textit{DTR-Bench}Ôºå‰∏ÄÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÂåÖÂê´ÂõõÂÄã‰∏çÂêåÁöÑÊ®°Êì¨Áí∞Â¢ÉÔºåÈáùÂ∞çÂ∏∏Ë¶ãÁöÑ DTR ÊáâÁî®ÔºåÂåÖÊã¨ÁôåÁóáÂåñÁôÇ„ÄÅÊîæÂ∞ÑÊ≤ªÁôÇ„ÄÅÁ≥ñÂ∞øÁóÖ‰∏≠ÁöÑËë°ËêÑÁ≥ñÁÆ°ÁêÜÂíåÊïóË°ÄÁóáÊ≤ªÁôÇ„ÄÇÊàëÂÄëÂú®ÈÄô‰∫õË®≠ÂÆö‰∏≠Ë©ï‰º∞‰∫ÜÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ RL ÊºîÁÆóÊ≥ïÔºåÁâπÂà•Âº∑Ë™øÂÆÉÂÄëÂú®Ëó•‰ª£ÂãïÂäõÂ≠∏/Ëó•ÊïàÂãïÂäõÂ≠∏ (PK/PD) ËÆäÁï∞ÊÄß„ÄÅÈõúË®äÂíåË≥áÊñôÈÅ∫Â§±Á≠âÁèæÂØ¶‰∏ñÁïåÊåëÊà∞‰∏≠ÁöÑË°®Áèæ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫ÜÂú®ÈõúË®äÂíåÊÇ£ËÄÖËÆäÁï∞ÊÄßÂ≠òÂú®ÁöÑÊÉÖÊ≥Å‰∏ãÔºåRL ÊºîÁÆóÊ≥ï‰πãÈñìÁöÑÊïàËÉΩ‰∏ãÈôçÁ®ãÂ∫¶‰∏çÂêåÔºåÊúâ‰∫õÊºîÁÆóÊ≥ïÁÑ°Ê≥ïÊî∂ÊñÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞‰ΩøÁî®ÊôÇÈñìËßÄÂØüË°®Á§∫‰∏¶‰∏çÊúÉÊåÅÁ∫åÂ∞éËá¥ DTR Ë®≠ÂÆö‰∏≠ÁöÑÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÈñãÁôºÂº∑ÂÅ•„ÄÅÈÅ©ÊáâÊÄß RL ÊºîÁÆóÊ≥ïÁöÑÂøÖË¶ÅÊÄßÔºåÈÄô‰∫õÊºîÁÆóÊ≥ïËÉΩÂ§†ÊúâÊïàÁÆ°ÁêÜÈÄô‰∫õË§áÈõúÊÄßÔºå‰ª•Â¢ûÂº∑ÁâπÂÆöÊÇ£ËÄÖÁöÑÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊàëÂÄëÂ∑≤Âú® https://github.com/GilesLuo/DTR-Bench ÈñãÊ∫ê‰∫ÜÊàëÂÄëÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÂíåÁ®ãÂºèÁ¢º„ÄÇ

##### **Low-rank finetuning for LLMs: A fairness perspective**
2405.18572v1 by Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, Ferdinando Fioretto

Low-rank approximation techniques have become the de facto standard for
fine-tuning Large Language Models (LLMs) due to their reduced computational and
memory requirements. This paper investigates the effectiveness of these methods
in capturing the shift of fine-tuning datasets from the initial pre-trained
data distribution. Our findings reveal that there are cases in which low-rank
fine-tuning falls short in learning such shifts. This, in turn, produces
non-negligible side effects, especially when fine-tuning is adopted for
toxicity mitigation in pre-trained models, or in scenarios where it is
important to provide fair models. Through comprehensive empirical evidence on
several models, datasets, and tasks, we show that low-rank fine-tuning
inadvertently preserves undesirable biases and toxic behaviors. We also show
that this extends to sequential decision-making tasks, emphasizing the need for
careful evaluation to promote responsible LLMs development.

ÊëòË¶ÅÔºö‰ΩéÁß©Ëøë‰ººÊäÄÊúØÂ∑≤Êàê‰∏∫ÂæÆË∞ÉÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑ‰∫ãÂÆûÊ†áÂáÜÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Èôç‰Ωé‰∫ÜËÆ°ÁÆóÂíåÂÜÖÂ≠òÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜËøô‰∫õÊñπÊ≥ïÂú®‰ªéÂàùÂßãÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÂàÜÂ∏É‰∏≠ÊçïËé∑ÂæÆË∞ÉÊï∞ÊçÆÈõÜÁöÑÂèòÂåñÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞Ë°®ÊòéÔºåÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºå‰ΩéÁß©ÂæÆË∞ÉÊó†Ê≥ïÂ≠¶‰π†ËøôÁßçÂèòÂåñ„ÄÇËøôÂèçËøáÊù•Âèà‰ºö‰∫ßÁîü‰∏çÂèØÂøΩËßÜÁöÑÂâØ‰ΩúÁî®ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂæÆË∞ÉË¢´Áî®‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰∏≠ÁöÑÊØíÊÄßÁºìËß£Êó∂ÔºåÊàñÂú®Êèê‰æõÂÖ¨Âπ≥Ê®°ÂûãÂæàÈáçË¶ÅÁöÑÂú∫ÊôØ‰∏≠„ÄÇÈÄöËøáÂØπÂ§ö‰∏™Ê®°Âûã„ÄÅÊï∞ÊçÆÈõÜÂíå‰ªªÂä°ËøõË°åÂÖ®Èù¢ÁöÑÂÆûËØÅËØÅÊçÆÔºåÊàë‰ª¨Ë°®Êòé‰ΩéÁß©ÂæÆË∞ÉÊó†ÊÑè‰∏≠‰øùÁïô‰∫Ü‰∏çËâØÂÅèËßÅÂíåÊúâÂÆ≥Ë°å‰∏∫„ÄÇÊàë‰ª¨ËøòË°®ÊòéËøôÊâ©Â±ïÂà∞‰∫ÜÈ°∫Â∫èÂÜ≥Á≠ñ‰ªªÂä°ÔºåÂº∫Ë∞É‰∫Ü‰ªîÁªÜËØÑ‰º∞‰ª•‰øÉËøõË¥üË¥£‰ªªÁöÑ LLM ÂºÄÂèëÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**
2405.18556v1 by Zhiyao Luo, Yangchen Pan, Peter Watkinson, Tingting Zhu

In the rapidly changing healthcare landscape, the implementation of offline
reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix
of unprecedented opportunities and challenges. This position paper offers a
critical examination of the current status of offline RL in the context of
DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such
as inconsistent and potentially inconclusive evaluation metrics, the absence of
naive and supervised learning baselines, and the diverse choice of RL
formulation in existing research. Through a case study with more than 17,000
evaluation experiments using a publicly available Sepsis dataset, we
demonstrate that the performance of RL algorithms can significantly vary with
changes in evaluation metrics and Markov Decision Process (MDP) formulations.
Surprisingly, it is observed that in some instances, RL algorithms can be
surpassed by random baselines subjected to policy evaluation methods and reward
design. This calls for more careful policy evaluation and algorithm development
in future DTR works. Additionally, we discussed potential enhancements toward
more reliable development of RL-based dynamic treatment regimes and invited
further discussion within the community. Code is available at
https://github.com/GilesLuo/ReassessDTR.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüËÆäÂåñÁöÑÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÔºåÈõ¢Á∑öÂº∑ÂåñÂ≠∏Áøí (RL) Âú®ÂãïÊÖãÊ≤ªÁôÇÊñπÊ°à (DTR) ‰∏≠ÁöÑÂØ¶ÊñΩÂëàÁèæ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇÊú¨Á´ãÂ†¥Êñá‰ª∂Â∞çÈõ¢Á∑ö RL Âú® DTR ËÉåÊôØ‰∏ãÁöÑÁèæÁãÄÈÄ≤Ë°å‰∫ÜÊâπÂà§ÊÄßÂØ©Êü•„ÄÇÊàëÂÄë‰∏ªÂºµÈáçÊñ∞Ë©ï‰º∞Âú® DTR ‰∏≠ÊáâÁî® RLÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÁñëÊÖÆÔºå‰æãÂ¶Ç‰∏ç‰∏ÄËá¥‰∏îÂèØËÉΩÊ≤íÊúâÂÆöË´ñÁöÑË©ï‰º∞ÊåáÊ®ô„ÄÅÁº∫‰πèÂ§©ÁúüÁöÑÂíåÁõ£Áù£ÂºèÁöÑÂ≠∏ÁøíÂü∫Á∑öÔºå‰ª•ÂèäÁèæÊúâÁ†îÁ©∂‰∏≠ RL ÂÖ¨ÂºèÁöÑÂ§öÊ®£ÈÅ∏Êìá„ÄÇÈÄöÈÅé‰∏ÄÂÄã‰ΩøÁî®ÂÖ¨Èñã Sepsis Êï∏ÊìöÈõÜÈÄ≤Ë°åÁöÑË∂ÖÈÅé 17,000 Ê¨°Ë©ï‰º∞ÂØ¶È©óÁöÑÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË≠âÊòé‰∫Ü RL ÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩÊúÉÈö®ËëóË©ï‰º∞ÊåáÊ®ôÂíåÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (MDP) ÂÖ¨ÂºèÁöÑËÆäÂåñËÄåÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëËßÄÂØüÂà∞Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåRL ÊºîÁÆóÊ≥ïÂèØËÉΩÊúÉË¢´Èö®Ê©üÂü∫Á∑öÊâÄË∂ÖË∂äÔºåÈÄô‰∫õÂü∫Á∑öÊúÉÂèóÂà∞Á≠ñÁï•Ë©ï‰º∞ÊñπÊ≥ïÂíåÁçéÂãµË®≠Ë®àÁöÑÂΩ±Èüø„ÄÇÈÄôË¶ÅÊ±ÇÂú®Êú™‰æÜÁöÑ DTR Â∑•‰Ωú‰∏≠ÈÄ≤Ë°åÊõ¥‰ªîÁ¥∞ÁöÑÁ≠ñÁï•Ë©ï‰º∞ÂíåÊºîÁÆóÊ≥ïÈñãÁôº„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÊúùËëóÊõ¥ÂèØÈù†ÁöÑÂü∫Êñº RL ÁöÑÂãïÊÖãÊ≤ªÁôÇÊñπÊ°àÈñãÁôºÁöÑÊΩõÂú®ÊîπÈÄ≤Ôºå‰∏¶ÈÇÄË´ãÁ§æÁæ§ÈÄ≤‰∏ÄÊ≠•Ë®éË´ñ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/GilesLuo/ReassessDTR ÂèñÂæó„ÄÇ

##### **The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental Health Service Provision**
2405.18553v1 by Stephen Obadinma, Alia Lachana, Maia Norman, Jocelyn Rankin, Joanna Yu, Xiaodan Zhu, Darren Mastropaolo, Deval Pandya, Roxana Sultan, Elham Dolatabadi

World's healthcare systems and mental health agencies face both a growing
demand for youth mental health services, alongside a simultaneous challenge of
limited resources. Given these constraints, this work presents our experience
in the creation and evaluation of the FAIIR (Frontline Assistant: Issue
Identification and Recommendation) tool, an ensemble of domain-adapted and
fine-tuned transformer models, leveraging natural language processing to
identify issues that youth may be experiencing. We explore the technical
development, performance, and validation processes leveraged for the FAIIR tool
in application to situations of frontline crisis response via Kids Help Phone.
Frontline Crisis Responders assign an issue tag from a defined list following
each conversation. Assisting with the identification of issues of relevance
helps reduce the burden on CRs, ensuring that appropriate resources can be
provided and that active rescues and mandatory reporting can take place in
critical situations requiring immediate de-escalation.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ËàáÂøÉÁêÜÂÅ•Â∫∑Ê©üÊßãÈù¢Ëá®ËëóÂ∞çÈùíÂ∞ëÂπ¥ÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÈúÄÊ±ÇÂ¢ûÂä†ÁöÑÂïèÈ°åÔºåÂêåÊôÇ‰πüÈù¢Ëá®ËëóË≥áÊ∫êÊúâÈôêÁöÑÊåëÊà∞„ÄÇÂú®ÈÄô‰∫õÈôêÂà∂‰∏ãÔºåÊú¨Á†îÁ©∂ÂëàÁèæÊàëÂÄëÂú®Âª∫Á´ãËàáË©ï‰º∞ FAIIRÔºàÂâçÁ∑öÂä©ÁêÜÔºöÂïèÈ°åË≠òÂà•ËàáÂª∫Ë≠∞ÔºâÂ∑•ÂÖ∑ÁöÑÁ∂ìÈ©óÔºåÂÆÉÁµêÂêà‰∫ÜÈ†òÂüüÈÅ©ÊáâËàáÂæÆË™øÁöÑËΩâÊèõÂô®Ê®°ÂûãÔºåÂà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰æÜË≠òÂà•ÈùíÂ∞ëÂπ¥ÂèØËÉΩÈÅ≠ÈÅáÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü FAIIR Â∑•ÂÖ∑Âú® Kids Help Phone ÁöÑÂâçÁ∑öÂç±Ê©üÊáâÂ∞çÊÉÖÊ≥Å‰∏≠ÊâÄÊáâÁî®ÁöÑÊäÄË°ìÈñãÁôº„ÄÅÊïàËÉΩËàáÈ©óË≠âÁ®ãÂ∫è„ÄÇÂâçÁ∑öÂç±Ê©üÊáâËÆä‰∫∫Âì°Âú®ÊØèÊ¨°Â∞çË©±ÂæåÊúÉÂæûÊó¢ÂÆöÁöÑÊ∏ÖÂñÆ‰∏≠ÊåáÂÆö‰∏ÄÂÄãÂïèÈ°åÊ®ôÁ±§„ÄÇÂçîÂä©Ë≠òÂà•Áõ∏ÈóúÂïèÈ°åÊúâÂä©ÊñºÊ∏õËºïÂç±Ê©üÊáâËÆä‰∫∫Âì°ÁöÑË≤†ÊìîÔºåÁ¢∫‰øùÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØ‰ª•Êèê‰æõÈÅ©Áï∂ÁöÑË≥áÊ∫êÔºå‰∏¶ÈÄ≤Ë°åÂøÖË¶ÅÁöÑÊïëÊè¥ËàáÂº∑Âà∂ÈÄöÂ†±„ÄÇ

##### **Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**
2405.18510v1 by James Derek Lomas, Willem van der Maden, Sohhom Bandyopadhyay, Giovanni Lion, Nirmal Patel, Gyanesh Jain, Yanna Litowsky, Haian Xue, Pieter Desmet

Generative AI systems are increasingly capable of expressing emotions via
text and imagery. Effective emotional expression will likely play a major role
in the efficacy of AI systems -- particularly those designed to support human
mental health and wellbeing. This motivates our present research to better
understand the alignment of AI expressed emotions with the human perception of
emotions. When AI tries to express a particular emotion, how might we assess
whether they are successful? To answer this question, we designed a survey to
measure the alignment between emotions expressed by generative AI and human
perceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable
Diffusion v1) were used to generate 240 examples of images, each of which was
based on a prompt designed to express five positive and five negative emotions
across both humans and robots. 24 participants recruited from the Prolific
website rated the alignment of AI-generated emotional expressions with a text
prompt used to generate the emotion (i.e., "A robot expressing the emotion
amusement"). The results of our evaluation suggest that generative AI models
are indeed capable of producing emotional expressions that are well-aligned
with a range of human emotions; however, we show that the alignment
significantly depends upon the AI model used and the emotion itself. We analyze
variations in the performance of these systems to identify gaps for future
improvement. We conclude with a discussion of the implications for future AI
systems designed to support mental health and wellbeing.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Á≥ªÁµ±Ë∂ä‰æÜË∂äËÉΩÂ§†ÈÄèÈÅéÊñáÂ≠óÂíåÂúñÂÉèË°®ÈÅîÊÉÖÁ∑í„ÄÇÊúâÊïàÁöÑË°®ÈÅîÊÉÖÁ∑íÂæàÂèØËÉΩÊúÉÂú® AI Á≥ªÁµ±ÁöÑÊïàËÉΩ‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤ÔºåÂ∞§ÂÖ∂ÊòØÈÇ£‰∫õË®≠Ë®àÁî®‰æÜÊîØÊåÅ‰∫∫È°ûÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ¶èÁ•âÁöÑÁ≥ªÁµ±„ÄÇÈÄôÊøÄÂãµ‰∫ÜÊàëÂÄëÁõÆÂâçÁöÑÈÄôÈ†ÖÁ†îÁ©∂Ôºå‰ª•ÊúüËÉΩÊõ¥‰∫ÜËß£ AI Ë°®ÈÅîÁöÑÊÉÖÁ∑íËàá‰∫∫È°ûÂ∞çÊÉÖÁ∑íÁöÑÊÑüÁü•‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇÁï∂ AI ÂòóË©¶Ë°®ÈÅîÁâπÂÆöÊÉÖÁ∑íÊôÇÔºåÊàëÂÄëË©≤Â¶Ç‰ΩïË©ï‰º∞‰ªñÂÄëÊòØÂê¶ÊàêÂäüÔºüÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÈ†ÖË™øÊü•Ôºå‰ª•Ë°°ÈáèÁîüÊàêÂºè AI Ë°®ÈÅîÁöÑÊÉÖÁ∑íËàá‰∫∫È°ûÊÑüÁü•‰πãÈñìÁöÑÂ∞çÈΩä„ÄÇ‰∏âÂÄãÁîüÊàêÂºèÂΩ±ÂÉèÊ®°ÂûãÔºàDALL-E 2„ÄÅDALL-E 3 Âíå Stable Diffusion v1ÔºâÁî®ÊñºÁî¢Áîü 240 ÂÄãÂΩ±ÂÉèÁØÑ‰æãÔºåÊØèÂÄãÁØÑ‰æãÈÉΩÂü∫Êñº‰∏ÄÂÄãÊèêÁ§∫ÔºåÊó®Âú®Ë°®ÈÅî‰∫∫È°ûÂíåÊ©üÂô®‰∫∫‰∫îÁ®ÆÊ≠£ÂêëÂíå‰∫îÁ®ÆË≤†ÂêëÊÉÖÁ∑í„ÄÇÂæû Prolific Á∂≤Á´ôÊãõÂãüÁöÑ 24 ‰ΩçÂèÉËàáËÄÖË©ï‰º∞‰∫Ü AI ÁîüÊàêÁöÑË°®ÊÉÖËàáÁî®ÊñºÁî¢ÁîüÊÉÖÁ∑íÁöÑÊñáÂ≠óÊèêÁ§∫‰πãÈñìÁöÑÂ∞çÈΩäÔºà‰æãÂ¶ÇÔºå„ÄåË°®ÈÅîÂ®õÊ®ÇÊÉÖÁ∑íÁöÑÊ©üÂô®‰∫∫„ÄçÔºâ„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåÁîüÊàêÂºè AI Ê®°ÂûãÁ¢∫ÂØ¶ËÉΩÂ§†Áî¢ÁîüËàá‰∏ÄÁ≥ªÂàó‰∫∫È°ûÊÉÖÁ∑íÈ´òÂ∫¶Â∞çÈΩäÁöÑÊÉÖÁ∑íË°®ÈÅîÔºõÁÑ∂ËÄåÔºåÊàëÂÄëË°®ÊòéÔºåÂ∞çÈΩäÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÊâÄ‰ΩøÁî®ÁöÑ AI Ê®°ÂûãÂíåÊÉÖÁ∑íÊú¨Ë∫´„ÄÇÊàëÂÄëÂàÜÊûêÈÄô‰∫õÁ≥ªÁµ±ÊïàËÉΩÁöÑËÆäÂåñÔºå‰ª•ÊâæÂá∫Êú™‰æÜÊîπÈÄ≤ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÊúÄÂæåË®éË´ñ‰∫ÜÂ∞çÊú™‰æÜÊó®Âú®ÊîØÊåÅÂøÉÁêÜÂÅ•Â∫∑ÂíåÁ¶èÁ•âÁöÑ AI Á≥ªÁµ±ÁöÑÂΩ±Èüø„ÄÇ

##### **A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**
2405.18387v1 by Ioanna Gogou, Dimitrios Koutsomitropoulos

Convolutional Neural Networks (CNN) are commonly used for the problem of
object detection thanks to their increased accuracy. Nevertheless, the
performance of CNN-based detection models is ambiguous when detection speed is
considered. To the best of our knowledge, there has not been sufficient
evaluation of the available methods in terms of the speed/accuracy trade-off in
related literature. This work assesses the most fundamental object detection
models on the Common Objects in Context (COCO) dataset with respect to this
trade-off, their memory consumption, and computational and storage cost. Next,
we select a highly efficient model called YOLOv5 to train on the topical and
unexplored dataset of human faces with medical masks, the Properly-Wearing
Masked Faces Dataset (PWMFD), and analyze the benefits of specific optimization
techniques for real-time medical mask detection: transfer learning, data
augmentations, and a Squeeze-and-Excitation attention mechanism. Using our
findings in the context of the COVID-19 pandemic, we propose an optimized model
based on YOLOv5s using transfer learning for the detection of correctly and
incorrectly worn medical masks that surpassed more than two times in speed (69
frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset
while maintaining the same level of mean Average Precision (67%).

ÊëòË¶ÅÔºöÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âõ†ÂÖ∂Ê∫ñÁ¢∫Â∫¶È´òËÄåÂ∏∏Ë¢´Áî®ÊñºÁõÆÊ®ôÂÅµÊ∏¨ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁï∂ËÄÉÈáèÂÅµÊ∏¨ÈÄüÂ∫¶ÊôÇÔºåÂü∫Êñº CNN ÁöÑÂÅµÊ∏¨Ê®°ÂûãÊïàËÉΩÂçªÊ®°Á®úÂÖ©ÂèØ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÁõ∏ÈóúÊñáÁçª‰∏≠Â∞öÊú™Â∞çÂèØÁî®ÊñπÊ≥ïÈÄ≤Ë°åË∂≥Â§†ÁöÑË©ï‰º∞Ôºå‰ª•‰∫ÜËß£ÈÄüÂ∫¶/Ê∫ñÁ¢∫Â∫¶ÁöÑÊ¨äË°°ÂèñÊç®„ÄÇÊú¨Á†îÁ©∂ÈáùÂ∞ç Common Objects in Context (COCO) Ë≥áÊñôÈõÜË©ï‰º∞ÊúÄÂü∫Êú¨ÁöÑÁõÆÊ®ôÂÅµÊ∏¨Ê®°ÂûãÔºåËÄÉÈáè‰∏äËø∞Ê¨äË°°ÂèñÊç®„ÄÅË®òÊÜ∂È´îÊ∂àËÄóÔºå‰ª•ÂèäÈÅãÁÆóÂíåÂÑ≤Â≠òÊàêÊú¨„ÄÇÊé•ËëóÔºåÊàëÂÄëÈÅ∏Êìá‰∏ÄÂÄãÂêçÁÇ∫ YOLOv5 ÁöÑÈ´òÊïàÁéáÊ®°ÂûãÔºåÂú®‰∏ªÈ°åÊÄß‰∏îÂ∞öÊú™Êé¢Á¥¢ÁöÑ‰∫∫ËáâÊà¥ÈÜ´Áî®Âè£ÁΩ©Ë≥áÊñôÈõÜ Properly-Wearing Masked Faces Dataset (PWMFD) ‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶ÂàÜÊûêÁâπÂÆöÊúÄ‰Ω≥ÂåñÊäÄË°ìÂ∞çÂç≥ÊôÇÈÜ´Áî®Âè£ÁΩ©ÂÅµÊ∏¨ÁöÑÂÑ™ÈªûÔºöÈÅ∑ÁßªÂ≠∏Áøí„ÄÅË≥áÊñôÊì¥ÂÖÖÔºå‰ª•Âèä Squeeze-and-Excitation Ê≥®ÊÑèÂäõÊ©üÂà∂„ÄÇÊàëÂÄëÂú® COVID-19 Áñ´ÊÉÖÁöÑËÉåÊôØ‰∏ãÈÅãÁî®Á†îÁ©∂ÁµêÊûúÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº YOLOv5s ÁöÑÊúÄ‰Ω≥ÂåñÊ®°ÂûãÔºå‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏ÁøíÂÅµÊ∏¨Ê≠£Á¢∫ÂíåÈåØË™§ÈÖçÊà¥ÁöÑÈÜ´Áî®Âè£ÁΩ©ÔºåÂú® PWMFD Ë≥áÊñôÈõÜ‰∏äÁöÑÈÄüÂ∫¶ÊØîÊúÄÂÖàÈÄ≤ÁöÑ SE-YOLOv3 Ê®°ÂûãÂø´ÂÖ©ÂÄç‰ª•‰∏ä (ÊØèÁßí 69 ÂπÄ)ÔºåÂêåÊôÇÁ∂≠ÊåÅÁõ∏ÂêåÁ≠âÁ¥öÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ (67%)„ÄÇ

##### **Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**
2405.18383v1 by Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Omar Al-Salihi, Justin Leu, Lia Halasz, Yury Velichko, Chunhao Wang, John Kirkpatrick, Scott Floyd, Zachary J. Reitman, Trey Mullikin, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Muhammad Ammar Haider, Pranav Warman, Jake Albrecht, Andr√°s Jakab, Mana Moassefi, Verena Chung, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Christina Huang, Aaron Coley, Siddharth Ghanta, Alex Schneider, Conrad Sharp, Rachit Saluja, Florian Kofler, Philipp Lohmann, Phillipp Vollmuth, Louis Gagnon, Maruf Adewole, Hongwei Bran Li, Anahita Fathi Kazerooni, Nourel Hoda Tahon, Udunna Anazodo, Ahmed W. Moawad, Bjoern Menze, Marius George Linguraru, Mariam Aboian, Benedikt Wiestler, Ujjwal Baid, Gian-Marco Conte, Andreas M. T. Rauschecker, Ayman Nada, Aly H. Abayazeed, Raymond Huang, Maria Correia de Verdier, Jeffrey D. Rudie, Spyridon Bakas, Evan Calabrese

The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)
challenge aims to advance automated segmentation algorithms using the largest
known multi-institutional dataset of radiotherapy planning brain MRIs with
expert-annotated target labels for patients with intact or post-operative
meningioma that underwent either conventional external beam radiotherapy or
stereotactic radiosurgery. Each case includes a defaced 3D post-contrast
T1-weighted radiotherapy planning MRI in its native acquisition space,
accompanied by a single-label "target volume" representing the gross tumor
volume (GTV) and any at-risk post-operative site. Target volume annotations
adhere to established radiotherapy planning protocols, ensuring consistency
across cases and institutions. For pre-operative meningiomas, the target volume
encompasses the entire GTV and associated nodular dural tail, while for
post-operative cases, it includes at-risk resection cavity margins as
determined by the treating institution. Case annotations were reviewed and
approved by expert neuroradiologists and radiation oncologists. Participating
teams will develop, containerize, and evaluate automated segmentation models
using this comprehensive dataset. Model performance will be assessed using the
lesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The
top-performing teams will be recognized at the Medical Image Computing and
Computer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is
expected to significantly advance automated radiotherapy planning by enabling
precise tumor segmentation and facilitating tailored treatment, ultimately
improving patient outcomes.

ÊëòË¶ÅÔºö2024 Âπ¥ËÖ¶Áò§ÂàÜÂâ≤ËÖ¶ËÜúÁò§ÊîæÂ∞ÑÊ≤ªÁôÇ (BraTS-MEN-RT) ÊåëÊà∞Êó®Âú®‰ΩøÁî®Â∑≤Áü•ÊúÄÂ§ßÁöÑÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉËÖ¶ÈÉ® MRI Â§öÊ©üÊßãË≥áÊñôÈõÜÔºå‰æÜÊé®ÈÄ≤Ëá™ÂãïÂàÜÂâ≤ÊºîÁÆóÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´Êé•ÂèóÂÇ≥Áµ±È´îÂ§ñÊîæÂ∞ÑÊ≤ªÁôÇÊàñÁ´ãÈ´îÂÆöÂêëÊîæÂ∞ÑÂ§ñÁßëÊâãË°ìÁöÑÂÆåÊï¥ÊàñË°ìÂæåËÖ¶ËÜúÁò§ÊÇ£ËÄÖÁöÑÂ∞àÂÆ∂Ê®ôË®ªÁõÆÊ®ôÊ®ôÁ±§„ÄÇÊØèÂÄãÊ°à‰æãÈÉΩÂåÖÂê´‰∏ÄÂÄãÂéªË≠òÂà•ÂåñÁöÑ 3D Â∞çÊØîÂæå T1 Âä†Ê¨äÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉ MRIÔºåÂú®ÂéüÁîüÊì∑ÂèñÁ©∫Èñì‰∏≠Ôºå‰∏¶ÈôÑÊúâ‰∏ÄÂÄã‰ª£Ë°®Á∏ΩËÖ´Áò§È´îÁ©ç (GTV) Âíå‰ªª‰ΩïÊúâÈ¢®Èö™ÁöÑË°ìÂæåÈÉ®‰ΩçÁöÑÂñÆÊ®ôÁ±§„ÄåÁõÆÊ®ôÈ´îÁ©ç„Äç„ÄÇÁõÆÊ®ôÈ´îÁ©çË®ªËß£ÈÅµÂæ™Êó¢ÂÆöÁöÑÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉÂçîË≠∞ÔºåÁ¢∫‰øùÂêÑÂÄãÊ°à‰æãÂíåÊ©üÊßã‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂ∞çÊñºË°ìÂâçËÖ¶ËÜúÁò§ÔºåÁõÆÊ®ôÈ´îÁ©çÂåÖÂê´Êï¥ÂÄã GTV ÂíåÁõ∏ÈóúÁµêÁØÄÊÄßÁ°¨ËÖ¶ËÜúÂ∞æÔºåËÄåÂ∞çÊñºË°ìÂæåÁóÖ‰æãÔºåÂâáÂåÖÊã¨Áî±Ê≤ªÁôÇÊ©üÊßãÁ¢∫ÂÆöÁöÑÊúâÈ¢®Èö™ÁöÑÂàáÈô§ËÖîÈöôÈÇäÁ∑£„ÄÇÊ°à‰æãË®ªËß£Â∑≤Áî±Â∞àÂÆ∂Á•ûÁ∂ìÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂíåÊîæÂ∞ÑËÖ´Áò§ÁßëÈÜ´Â∏´ÂØ©Êü•‰∏¶Ê†∏ÂáÜ„ÄÇÂèÉËàáÂúòÈöäÂ∞á‰ΩøÁî®ÈÄôÂÄãÂÖ®Èù¢ÁöÑË≥áÊñôÈõÜ‰æÜÈñãÁôº„ÄÅÂ∞ÅË£ùÂíåË©ï‰º∞Ëá™ÂãïÂàÜÂâ≤Ê®°Âûã„ÄÇÊ®°ÂûãÊïàËÉΩÂ∞á‰ΩøÁî®ÁóÖÁÅ∂ÊòéÊô∫ÁöÑ Dice Áõ∏‰ººÊÄß‰øÇÊï∏Âíå 95% Hausdorff Ë∑ùÈõ¢ÈÄ≤Ë°åË©ï‰º∞„ÄÇË°®ÁèæÊúÄ‰Ω≥ÁöÑÂúòÈöäÂ∞áÂú® 2024 Âπ¥ 10 ÊúàÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÈÅãÁÆóÂíåÈõªËÖ¶ËºîÂä©‰ªãÂÖ•ÊúÉË≠∞‰∏äÁç≤ÂæóËÇØÂÆö„ÄÇÈ†êË®à BraTS-MEN-RT Â∞áÈÄèÈÅéÂØ¶ÁèæÁ≤æÁ¢∫ÁöÑËÖ´Áò§ÂàÜÂâ≤Âíå‰øÉÈÄ≤ÂÆ¢Ë£ΩÂåñÊ≤ªÁôÇ‰æÜÂ§ßÂπÖÊé®ÈÄ≤Ëá™ÂãïÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉÔºåÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇ

##### **Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**
2405.18346v1 by Anjanava Biswas, Wrick Talukdar

Comprehensive clinical documentation is crucial for effective healthcare
delivery, yet it poses a significant burden on healthcare professionals,
leading to burnout, increased medical errors, and compromised patient safety.
This paper explores the potential of generative AI (Artificial Intelligence) to
streamline the clinical documentation process, specifically focusing on
generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,
Intervention, Response, Plan) notes. We present a case study demonstrating the
application of natural language processing (NLP) and automatic speech
recognition (ASR) technologies to transcribe patient-clinician interactions,
coupled with advanced prompting techniques to generate draft clinical notes
using large language models (LLMs). The study highlights the benefits of this
approach, including time savings, improved documentation quality, and enhanced
patient-centered care. Additionally, we discuss ethical considerations, such as
maintaining patient confidentiality and addressing model biases, underscoring
the need for responsible deployment of generative AI in healthcare settings.
The findings suggest that generative AI has the potential to revolutionize
clinical documentation practices, alleviating administrative burdens and
enabling healthcare professionals to focus more on direct patient care.

ÊëòË¶ÅÔºöÂÖ®Èù¢ÁöÑËá®Â∫äÊñá‰ª∂Â∞çÊñºÊúâÊïàÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÂ∞çÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÈÄ†Êàê‰∫ÜÈáçÂ§ßË≤†ÊìîÔºåÂ∞éËá¥ÂÄ¶ÊÄ†„ÄÅÈÜ´ÁôÇÈåØË™§Â¢ûÂä†‰ª•ÂèäÊÇ£ËÄÖÂÆâÂÖ®ÂèóÂà∞ÂΩ±Èüø„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÁîüÊàêÂºè AIÔºà‰∫∫Â∑•Êô∫ÊÖßÔºâÁ∞°ÂåñËá®Â∫äÊñá‰ª∂ÊµÅÁ®ãÁöÑÂèØËÉΩÊÄßÔºåÁâπÂà•Â∞àÊ≥®ÊñºÁîüÊàê SOAPÔºà‰∏ªËßÄ„ÄÅÂÆ¢ËßÄ„ÄÅË©ï‰º∞„ÄÅË®àÁï´ÔºâÂíå BIRPÔºàË°åÁÇ∫„ÄÅ‰ªãÂÖ•„ÄÅÂèçÊáâ„ÄÅË®àÁï´ÔºâË®òÈåÑ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâÂíåËá™ÂãïË™ûÈü≥Ëæ®Ë≠òÔºàASRÔºâÊäÄË°ìÂú®ËΩâÈåÑÊÇ£ËÄÖËàáËá®Â∫äÈÜ´Â∏´‰∫íÂãïÊñπÈù¢ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÁµêÂêàÂÖàÈÄ≤ÁöÑÊèêÁ§∫ÊäÄË°ìÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁîüÊàêËá®Â∫äË®òÈåÑËçâÁ®ø„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂ•ΩËôïÔºåÂåÖÊã¨ÁØÄÁúÅÊôÇÈñì„ÄÅÊîπÂñÑÊñá‰ª∂ÂìÅË≥™Ôºå‰ª•ÂèäÂ¢ûÂº∑‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÅìÂæ∑ËÄÉÈáèÔºå‰æãÂ¶ÇÁ∂≠Ë≠∑ÊÇ£ËÄÖÊ©üÂØÜÊÄßÂíåËß£Ê±∫Ê®°ÂûãÂÅèÂ∑ÆÔºåÂº∑Ë™øÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Ë≤†Ë≤¨‰ªªÂú∞ÈÉ®ÁΩ≤ÁîüÊàêÂºè AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁîüÊàêÂºè AI ÊúâÂèØËÉΩÂæπÂ∫ïÊîπËÆäËá®Â∫äÊñá‰ª∂ÂØ¶ÂãôÔºåÊ∏õËºïË°åÊîøË≤†ÊìîÔºå‰∏¶‰ΩøÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ËÉΩÂ§†Êõ¥Â§öÂú∞Â∞àÊ≥®ÊñºÁõ¥Êé•ÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇ

##### **Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**
2405.18327v1 by Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, Niha Beig, Mahrukh Huseni, James Brugarolas, Payal Kapur, Satwik Rajaram

Predictive biomarkers of treatment response are lacking for metastatic clear
cell renal cell carcinoma (ccRCC), a tumor type that is treated with
angiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a
HIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is
arguably the best candidate to predict anti-angiogenic (AA) response. However,
the clinical adoption of transcriptomic assays faces several challenges
including standardization, time delay, and high cost. Further, ccRCC tumors are
highly heterogenous, and sampling multiple areas for sequencing is impractical.
Here we present a novel deep learning (DL) approach to predict the Angioscore
from ubiquitous histopathology slides. To overcome the lack of
interpretability, one of the biggest limitations of typical DL models, our
model produces a visual vascular network which is the basis of the model's
prediction. To test its reliability, we applied this model to multiple cohorts
including a clinical trial dataset. Our model accurately predicts the RNA-based
Angioscore on multiple independent cohorts (spearman correlations of 0.77 and
0.73). Further, the predictions help unravel meaningful biology such as
association of angiogenesis with grade, stage, and driver mutation status.
Finally, we find our model can predict response to AA therapy, in both a
real-world cohort and the IMmotion150 clinical trial. The predictive power of
our model vastly exceeds that of CD31, a marker of vasculature, and nearly
rivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based
Angioscore at a fraction of the cost. By providing a robust yet interpretable
prediction of the Angioscore from histopathology slides alone, our approach
offers insights into angiogenesis biology and AA treatment response.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºËΩâÁßªÊÄßÈÄèÊòéÁ¥∞ËÉûËÖéÁ¥∞ËÉûÁôå (ccRCC)Ôºå‰∏ÄÁ®ÆÁî®ÊñºÊ≤ªÁôÇË°ÄÁÆ°ÁîüÊàêÊäëÂà∂Âäë„ÄÅÂÖçÁñ´Ê™¢Êü•ÈªûÊäëÂà∂Âäë„ÄÅmTOR ÊäëÂà∂ÂäëÂíå HIF2 ÊäëÂà∂ÂäëÁöÑËÖ´Áò§È°ûÂûãÔºåÁõÆÂâçÁº∫‰πèÊ≤ªÁôÇÂèçÊáâÁöÑÈ†êÊ∏¨ÊÄßÁîüÁâ©Ê®ôË®ò„ÄÇAngioscore ÊòØ‰∏ÄÁ®ÆÂü∫Êñº RNA ÁöÑË°ÄÁÆ°ÁîüÊàêÈáèÂåñÔºåÂèØ‰ª•Ë™™ÊòØÈ†êÊ∏¨ÊäóË°ÄÁÆ°ÁîüÊàê (AA) ÂèçÊáâÁöÑÊúÄ‰Ω≥ÂÄôÈÅ∏ËÄÖ„ÄÇÁÑ∂ËÄåÔºåËΩâÈåÑÁµÑÊ™¢Ê∏¨ÁöÑËá®Â∫äÊáâÁî®Èù¢Ëá®ËëóÊ®ôÊ∫ñÂåñ„ÄÅÊôÇÈñìÂª∂ÈÅ≤ÂíåÈ´òÊàêÊú¨Á≠âÂ§öÈ†ÖÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåccRCC ËÖ´Áò§È´òÂ∫¶Áï∞Ë≥™ÔºåÂ∞çÂ§öÂÄãÂçÄÂüüÈÄ≤Ë°åÂèñÊ®£‰ª•ÈÄ≤Ë°åÊ∏¨Â∫è‰∏¶‰∏çÂàáÂØ¶Èöõ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÔºåÂèØÂæûÊôÆÈÅçÂ≠òÂú®ÁöÑÁµÑÁπîÁóÖÁêÜÂàáÁâá‰∏≠È†êÊ∏¨ Angioscore„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÂèØËß£ÈáãÊÄßÁöÑÁº∫‰πèÔºåÈÄôÊòØÂÖ∏Âûã DL Ê®°ÂûãÊúÄÂ§ßÁöÑÈôêÂà∂‰πã‰∏ÄÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁî¢Áîü‰∫Ü‰∏ÄÂÄãË¶ñË¶∫Ë°ÄÁÆ°Á∂≤Ë∑ØÔºåÈÄôÊòØÊ®°ÂûãÈ†êÊ∏¨ÁöÑÂü∫Á§é„ÄÇÁÇ∫‰∫ÜÊ∏¨Ë©¶ÂÖ∂ÂèØÈù†ÊÄßÔºåÊàëÂÄëÂ∞áÊ≠§Ê®°ÂûãÊáâÁî®ÊñºÂ§öÂÄãÁæ§ÁµÑÔºåÂåÖÊã¨Ëá®Â∫äË©¶È©óË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊ∫ñÁ¢∫È†êÊ∏¨‰∫ÜÂ§öÂÄãÁç®Á´ãÁæ§ÁµÑÁöÑÂü∫Êñº RNA ÁöÑ AngioscoreÔºàspearman Áõ∏Èóú‰øÇÊï∏ÁÇ∫ 0.77 Âíå 0.73Ôºâ„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÈ†êÊ∏¨ÊúâÂä©ÊñºËß£ÈñãÊúâÊÑèÁæ©ÁöÑÁîüÁâ©Â≠∏Ôºå‰æãÂ¶ÇË°ÄÁÆ°ÁîüÊàêËàáÁ≠âÁ¥ö„ÄÅÈöéÊÆµÂíåÈ©ÖÂãïÁ™ÅËÆäÁãÄÊÖãÁöÑÈóúËÅØ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•È†êÊ∏¨Â∞ç AA Ê≤ªÁôÇÁöÑÂèçÊáâÔºåÁÑ°Ë´ñÊòØÂú®ÁèæÂØ¶‰∏ñÁïåÁæ§ÁµÑÈÇÑÊòØ IMmotion150 Ëá®Â∫äË©¶È©ó‰∏≠„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÈ†êÊ∏¨ËÉΩÂäõÈÅ†ÈÅ†Ë∂ÖÈÅéË°ÄÁÆ°Ê®ôË®ò CD31Ôºå‰∏¶‰∏îÂπæ‰πéËàáÂü∫Êñº RNA ÁöÑÁúüÂØ¶ Angioscore ÁöÑÊïàËÉΩÔºàc ÊåáÊï∏ 0.66 Â∞ç 0.67ÔºâÁõ∏Áï∂ÔºåËÄåÊàêÊú¨ÂçªÂè™ÊòØÂæåËÄÖÁöÑÈõ∂È†≠„ÄÇÈÄöÈÅéÂÉÖÂæûÁµÑÁπîÁóÖÁêÜÂàáÁâá‰∏≠Êèê‰æõÂ∞ç Angioscore ÁöÑÂº∑Â§ß‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ∞çË°ÄÁÆ°ÁîüÊàêÁîüÁâ©Â≠∏Âíå AA Ê≤ªÁôÇÂèçÊáâÁöÑË¶ãËß£„ÄÇ</paragraph>

##### **Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**
2405.18028v1 by Aryo Pradipta Gema, Chaeeun Lee, Pasquale Minervini, Luke Daines, T. Ian Simpson, Beatrice Alex

The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language
Models (LLMs) to identify and correct medical errors in clinical notes. In this
study, we evaluate the capability of general LLMs, specifically GPT-3.5 and
GPT-4, to identify and correct medical errors with multiple prompting
strategies. Recognising the limitation of LLMs in generating accurate
corrections only via prompting strategies, we propose incorporating error-span
predictions from a smaller, fine-tuned model in two ways: 1) by presenting it
as a hint in the prompt and 2) by framing it as multiple-choice questions from
which the LLM can choose the best correction. We found that our proposed
prompting strategies significantly improve the LLM's ability to generate
corrections. Our best-performing solution with 8-shot + CoT + hints ranked
sixth in the shared task leaderboard. Additionally, our comprehensive analyses
show the impact of the location of the error sentence, the prompted role, and
the position of the multiple-choice option on the accuracy of the LLM. This
prompts further questions about the readiness of LLM to be implemented in
real-world clinical settings.

ÊëòË¶ÅÔºöMEDIQA-CORR 2024 ÂÖ±‰∫´‰ªªÂãôÊó®Âú®Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá®Â∫äÁ≠ÜË®ò‰∏≠Ë≠òÂà•ÂíåÊõ¥Ê≠£ÈÜ´ÁôÇÈåØË™§ÁöÑËÉΩÂäõ„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞ÈÄöÁî® LLMÔºåÁâπÂà•ÊòØ GPT-3.5 Âíå GPT-4ÔºåË≠òÂà•ÂíåÊõ¥Ê≠£ÈÜ´ÁôÇÈåØË™§ÁöÑËÉΩÂäõÔºå‰∏¶Êé°Áî®Â§öÁ®ÆÊèêÁ§∫Á≠ñÁï•„ÄÇË™çË≠òÂà∞ LLM ÂÉÖÈÄöÈÅéÊèêÁ§∫Á≠ñÁï•ÁîüÊàêÊ∫ñÁ¢∫Êõ¥Ê≠£ÁöÑÈôêÂà∂ÔºåÊàëÂÄëÂª∫Ë≠∞‰ª•ÂÖ©Á®ÆÊñπÂºèÊï¥Âêà‰æÜËá™ËºÉÂ∞èÁöÑÂæÆË™øÊ®°ÂûãÁöÑÈåØË™§ÁØÑÂúçÈ†êÊ∏¨Ôºö1) Âú®ÊèêÁ§∫‰∏≠Â∞áÂÖ∂Ë°®Á§∫ÁÇ∫ÊèêÁ§∫Ôºå‰ª•Âèä 2) Â∞áÂÖ∂Ë®≠ÂÆöÁÇ∫Â§öÈÅ∏È°åÔºåLLM ÂèØ‰ª•Âæû‰∏≠ÈÅ∏ÊìáÊúÄ‰Ω≥Êõ¥Ê≠£„ÄÇÊàëÂÄëÁôºÁèæÊàëÂÄëÊèêÂá∫ÁöÑÊèêÁ§∫Á≠ñÁï•È°ØËëóÊèêÈ´ò‰∫Ü LLM ÁîüÊàêÊõ¥Ê≠£ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ±‰∫´‰ªªÂãôÊéíË°åÊ¶ú‰∏≠ÊéíÂêçÁ¨¨ÂÖ≠ÁöÑÊúÄ‰Ω≥Âü∑Ë°åÊñπÊ°àÊòØ 8 Ê¨°ÂòóË©¶ + CoT + ÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂÖ®Èù¢ÁöÑÂàÜÊûêÈ°ØÁ§∫‰∫ÜÈåØË™§Âè•Â≠ê‰ΩçÁΩÆ„ÄÅÊèêÁ§∫ËßíËâ≤ÂíåÂ§öÈÅ∏È†Ö‰ΩçÁΩÆÂ∞ç LLM Ê∫ñÁ¢∫ÊÄßÁöÑÂΩ±Èüø„ÄÇÈÄôÂºïÁôº‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂïèÈ°åÔºåÂç≥ LLM ÊòØÂê¶Â∑≤Ê∫ñÂÇôÂ•ΩÂØ¶ÊñΩÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠„ÄÇ

##### **Towards Clinical AI Fairness: Filling Gaps in the Puzzle**
2405.17921v1 by Mingxuan Liu, Yilin Ning, Salinelat Teixayavong, Xiaoxuan Liu, Mayli Mertens, Yuqing Shang, Xin Li, Di Miao, Jie Xu, Daniel Shu Wei Ting, Lionel Tim-Ee Cheng, Jasmine Chiat Ling Ong, Zhen Ling Teo, Ting Fang Tan, Narrendar RaviChandran, Fei Wang, Leo Anthony Celi, Marcus Eng Hock Ong, Nan Liu

The ethical integration of Artificial Intelligence (AI) in healthcare
necessitates addressing fairness-a concept that is highly context-specific
across medical fields. Extensive studies have been conducted to expand the
technical components of AI fairness, while tremendous calls for AI fairness
have been raised from healthcare. Despite this, a significant disconnect
persists between technical advancements and their practical clinical
applications, resulting in a lack of contextualized discussion of AI fairness
in clinical settings. Through a detailed evidence gap analysis, our review
systematically pinpoints several deficiencies concerning both healthcare data
and the provided AI fairness solutions. We highlight the scarcity of research
on AI fairness in many medical domains where AI technology is increasingly
utilized. Additionally, our analysis highlights a substantial reliance on group
fairness, aiming to ensure equality among demographic groups from a macro
healthcare system perspective; in contrast, individual fairness, focusing on
equity at a more granular level, is frequently overlooked. To bridge these
gaps, our review advances actionable strategies for both the healthcare and AI
research communities. Beyond applying existing AI fairness methods in
healthcare, we further emphasize the importance of involving healthcare
professionals to refine AI fairness concepts and methods to ensure contextually
relevant and ethically sound AI applications in healthcare.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÄ´ÁêÜÊï¥ÂêàÈúÄË¶ÅËôïÁêÜÂÖ¨Âπ≥ÊÄß‚Äî‚ÄîÈÄôÂÄãÊ¶ÇÂøµÂú®ÂêÑÂÄãÈÜ´ÁôÇÈ†òÂüü‰∏≠È´òÂ∫¶ÁâπÂÆöÊñºÊÉÖÂ¢É„ÄÇÂ∑≤Á∂ìÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÁ†îÁ©∂‰æÜÊì¥Â±ï AI ÂÖ¨Âπ≥ÊÄßÁöÑÊäÄË°ìÁµÑÊàêÔºåËÄå‰æÜËá™ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ AI ÂÖ¨Âπ≥ÊÄßÂëºËÅ≤‰πüÂæàÂ§ß„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊäÄË°ìÈÄ≤Ê≠•ËàáÂÖ∂ÂØ¶ÈöõËá®Â∫äÊáâÁî®‰πãÈñì‰ªçÁÑ∂Â≠òÂú®È°ØËëóÁöÑËÑ´ÁØÄÔºåÂ∞éËá¥Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠Áº∫‰πèÂ∞ç AI ÂÖ¨Âπ≥ÊÄßÁöÑÊÉÖÂ¢ÉÂåñË®éË´ñ„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑË≠âÊìöÂ∑ÆË∑ùÂàÜÊûêÔºåÊàëÂÄëÁöÑÂõûÈ°ßÁ≥ªÁµ±ÊÄßÂú∞ÊâæÂá∫‰∫ÜËàáÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÂíåÊèê‰æõÁöÑ AI ÂÖ¨Âπ≥ÊÄßËß£Ê±∫ÊñπÊ°àÁõ∏ÈóúÁöÑÂπæÂÄãÁº∫Èô∑„ÄÇÊàëÂÄëÂº∑Ë™øÂú®Ë®±Â§öÈÜ´ÁôÇÈ†òÂüü‰∏≠Áº∫‰πèÂ∞ç AI ÂÖ¨Âπ≥ÊÄßÁöÑÁ†îÁ©∂ÔºåËÄåÈÄô‰∫õÈ†òÂüü‰∏≠ AI ÊäÄË°ìÁöÑ‰ΩøÁî®Ë∂ä‰æÜË∂äÂ§ö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂ∞çÁæ§È´îÂÖ¨Âπ≥ÊÄßÁöÑÂØ¶Ë≥™‰æùË≥¥ÔºåÊó®Âú®ÂæûÂ∑®ËßÄÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑËßíÂ∫¶Á¢∫‰øù‰∫∫Âè£Áæ§È´î‰πãÈñìÁöÑÂπ≥Á≠âÔºõÁõ∏ÊØî‰πã‰∏ãÔºåÈóúÊ≥®Êõ¥Á¥∞Á∑ªÂ±§Á¥öÂÖ¨Âπ≥ÊÄßÁöÑÂÄãÂà•ÂÖ¨Âπ≥ÊÄßÂ∏∏Â∏∏Ë¢´ÂøΩË¶ñ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∫õÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÂõûÈ°ßÊèêÂá∫‰∫ÜÈáùÂ∞çÈÜ´ÁôÇ‰øùÂÅ•Âíå AI Á†îÁ©∂Á§æÁæ§ÁöÑÂèØË°åÁ≠ñÁï•„ÄÇÈô§‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÊáâÁî®ÁèæÊúâÁöÑ AI ÂÖ¨Âπ≥ÊÄßÊñπÊ≥ï‰πãÂ§ñÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âº∑Ë™ø‰∫ÜËÆìÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÂèÉËàáÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÂÆåÂñÑ AI ÂÖ¨Âπ≥ÊÄßÊ¶ÇÂøµÂíåÊñπÊ≥ïÔºå‰ª•Á¢∫‰øùÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂÖ∑ÊúâÊÉÖÂ¢ÉÁõ∏ÈóúÊÄßÂíåÁ¨¶ÂêàÂÄ´ÁêÜÁöÑ AI ÊáâÁî®„ÄÇ

##### **Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing**
2405.17901v1 by Irem Ulku, O. Ozgur Tanriover, Erdem Akag√ºnd√ºz

Plant health can be monitored dynamically using multispectral sensors that
measure Near-Infrared reflectance (NIR). Despite this potential, obtaining and
annotating high-resolution NIR images poses a significant challenge for
training deep neural networks. Typically, large networks pre-trained on the RGB
domain are utilized to fine-tune infrared images. This practice introduces a
domain shift issue because of the differing visual traits between RGB and NIR
images.As an alternative to fine-tuning, a method called low-rank adaptation
(LoRA) enables more efficient training by optimizing rank-decomposition
matrices while keeping the original network weights frozen. However, existing
parameter-efficient adaptation strategies for remote sensing images focus on
RGB images and overlook domain shift issues in the NIR domain. Therefore, this
study investigates the potential benefits of using vision transformer (ViT)
backbones pre-trained in the RGB domain, with low-rank adaptation for
downstream tasks in the NIR domain. Extensive experiments demonstrate that
employing LoRA with pre-trained ViT backbones yields the best performance for
downstream tasks applied to NIR images.

ÊëòË¶ÅÔºöÂà©Áî®ÊµãÈáèËøëÁ∫¢Â§ñÂèçÂ∞Ñ (NIR) ÁöÑÂ§öÂÖâË∞±‰º†ÊÑüÂô®ÔºåÂèØ‰ª•Âä®ÊÄÅÁõëÊµãÊ§çÁâ©ÂÅ•Â∫∑„ÄÇÂ∞ΩÁÆ°ÊúâÊ≠§ÊΩúÂäõÔºå‰ΩÜËé∑ÂèñÂíåÊ≥®ÈáäÈ´òÂàÜËæ®Áéá NIR ÂõæÂÉèÂØπËÆ≠ÁªÉÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÊûÑÊàê‰∫ÜÈáçÂ§ßÊåëÊàò„ÄÇÈÄöÂ∏∏ÔºåÂà©Áî®È¢ÑÂÖàÂú® RGB Âüü‰∏äËÆ≠ÁªÉÁöÑÂ§ßÂûãÁΩëÁªúÊù•ÂæÆË∞ÉÁ∫¢Â§ñÂõæÂÉè„ÄÇÁî±‰∫é RGB Âíå NIR ÂõæÂÉè‰πãÈó¥ÁöÑËßÜËßâÁâπÂæÅ‰∏çÂêåÔºåËøôÁßçÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂüüÂÅèÁßªÈóÆÈ¢ò„ÄÇ‰Ωú‰∏∫ÂæÆË∞ÉÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰∏ÄÁßçÁß∞‰∏∫‰ΩéÁß©ÈÄÇÂ∫î (LoRA) ÁöÑÊñπÊ≥ïÈÄöËøá‰ºòÂåñÁß©ÂàÜËß£Áü©ÈòµÂêåÊó∂‰øùÊåÅÂéüÂßãÁΩëÁªúÊùÉÈáçÂÜªÁªìÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑËÆ≠ÁªÉ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÁî®‰∫éÈÅ•ÊÑüÂõæÂÉèÁöÑÂèÇÊï∞È´òÊïàÈÄÇÂ∫îÁ≠ñÁï•‰∏ìÊ≥®‰∫é RGB ÂõæÂÉèÔºåËÄåÂøΩÁï•‰∫Ü NIR Âüü‰∏≠ÁöÑÂüüÂÅèÁßªÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® RGB Âüü‰∏≠È¢ÑÂÖàËÆ≠ÁªÉÁöÑËßÜËßâËΩ¨Êç¢Âô® (ViT) ‰∏ªÂπ≤‰ΩøÁî®‰ΩéÁß©ÈÄÇÂ∫îÂú® NIR ÂüüÁöÑ‰∏ãÊ∏∏‰ªªÂä°‰∏≠‰ΩøÁî®ËßÜËßâËΩ¨Êç¢Âô® (ViT) ‰∏ªÂπ≤ÁöÑÊΩúÂú®‰ºòÂäø„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÂ∞Ü LoRA ‰∏éÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑ ViT ‰∏ªÂπ≤ÁªìÂêà‰ΩøÁî®ÔºåÂèØ‰∏∫Â∫îÁî®‰∫é NIR ÂõæÂÉèÁöÑ‰∏ãÊ∏∏‰ªªÂä°Â∏¶Êù•ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ

##### **AI Alignment with Changing and Influenceable Reward Functions**
2405.17713v1 by Micah Carroll, Davis Foote, Anand Siththaranjan, Stuart Russell, Anca Dragan

Existing AI alignment approaches assume that preferences are static, which is
unrealistic: our preferences change, and may even be influenced by our
interactions with AI systems themselves. To clarify the consequences of
incorrectly assuming static preferences, we introduce Dynamic Reward Markov
Decision Processes (DR-MDPs), which explicitly model preference changes and the
AI's influence on them. We show that despite its convenience, the
static-preference assumption may undermine the soundness of existing alignment
techniques, leading them to implicitly reward AI systems for influencing user
preferences in ways users may not truly want. We then explore potential
solutions. First, we offer a unifying perspective on how an agent's
optimization horizon may partially help reduce undesirable AI influence. Then,
we formalize different notions of AI alignment that account for preference
change from the outset. Comparing the strengths and limitations of 8 such
notions of alignment, we find that they all either err towards causing
undesirable AI influence, or are overly risk-averse, suggesting that a
straightforward solution to the problems of changing preferences may not exist.
As there is no avoiding grappling with changing preferences in real-world
settings, this makes it all the more important to handle these issues with
care, balancing risks and capabilities. We hope our work can provide conceptual
clarity and constitute a first step towards AI alignment practices which
explicitly account for (and contend with) the changing and influenceable nature
of human preferences.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ AI Â∞çÈΩäÊñπÊ≥ïÂÅáË®≠ÂÅèÂ•ΩÊòØÈùúÊÖãÁöÑÔºåÈÄôÊòØ‰∏çÂàáÂØ¶ÈöõÁöÑÔºöÊàëÂÄëÁöÑÂÅèÂ•ΩÊúÉÊîπËÆäÔºåÁîöËá≥ÂèØËÉΩÂèóÂà∞ÊàëÂÄëËàá AI Á≥ªÁµ±‰∫íÂãïÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜÈáêÊ∏ÖÈåØË™§ÂÅáË®≠ÈùúÊÖãÂÅèÂ•ΩÁöÑÂæåÊûúÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂãïÊÖãÁçéÂãµÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (DR-MDP)ÔºåÂÆÉÊòéÁ¢∫Âú∞Ê®°Êì¨‰∫ÜÂÅèÂ•ΩËÆäÂåñÂíå AI Â∞çÂÆÉÂÄëÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëË°®ÊòéÔºåÂÑòÁÆ°ÂÖ∂‰æøÂà©ÊÄßÔºå‰ΩÜÈùúÊÖãÂÅèÂ•ΩÂÅáË®≠ÂèØËÉΩÊúÉÁ†¥Â£ûÁèæÊúâÂ∞çÈΩäÊäÄË°ìÁöÑÂÅ•ÂÖ®ÊÄßÔºåÂ∞éËá¥ÂÆÉÂÄëÈö±ÂºèÂú∞ÁçéÂãµ AI Á≥ªÁµ±‰ª•ÂΩ±ÈüøÁî®Êà∂ÂÅèÂ•ΩÁöÑÊñπÂºèÔºåËÄåÁî®Êà∂ÂèØËÉΩ‰∏¶ÈùûÁúüÊ≠£ÊÉ≥Ë¶Å„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé¢Ë®éÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑËßÄÈªûÔºåË™™Êòé‰ª£ÁêÜÁöÑÊúÄ‰Ω≥ÂåñÁØÑÂúçÂ¶Ç‰ΩïÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÂπ´Âä©Ê∏õÂ∞ë‰∏çËâØÁöÑ AI ÂΩ±Èüø„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂΩ¢ÂºèÂåñ‰∫Ü‰∏çÂêåÁöÑ AI Â∞çÈΩäÊ¶ÇÂøµÔºåÈÄô‰∫õÊ¶ÇÂøµÂæû‰∏ÄÈñãÂßãÂ∞±ËÄÉÊÖÆ‰∫ÜÂÅèÂ•ΩËÆäÂåñ„ÄÇÊØîËºÉÈÄô 8 ÂÄãÂ∞çÈΩäÊ¶ÇÂøµÁöÑÂÑ™Áº∫ÈªûÔºåÊàëÂÄëÁôºÁèæÂÆÉÂÄëË¶Å‰πàÊúÉÂ∞éËá¥‰∏çËâØÁöÑ AI ÂΩ±ÈüøÔºåË¶Å‰πàÈÅéÊñºËø¥ÈÅøÈ¢®Èö™ÔºåÈÄôË°®ÊòéÂèØËÉΩ‰∏çÂ≠òÂú®ÊîπËÆäÂÅèÂ•ΩÁöÑÂïèÈ°åÁöÑÁõ¥Êé•Ëß£Ê±∫ÊñπÊ°à„ÄÇÁî±ÊñºÂú®ÁèæÂØ¶Áí∞Â¢É‰∏≠ÁÑ°Ê≥ïÈÅøÂÖçÊáâÂ∞çÂÅèÂ•ΩÁöÑÊîπËÆäÔºåÈÄô‰ΩøÂæó‰ª•Ë¨πÊÖéÁöÑÊñπÂºèËôïÁêÜÈÄô‰∫õÂïèÈ°åËÆäÂæóÊõ¥Âä†ÈáçË¶ÅÔºåÊ¨äË°°È¢®Èö™ÂíåËÉΩÂäõ„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØ‰ª•Êèê‰æõÊ¶ÇÂøµ‰∏äÁöÑÊ∏ÖÊô∞Â∫¶Ôºå‰∏¶ÊßãÊàêÊúùËëó AI Â∞çÈΩäÂØ¶ÂãôÈÇÅÂá∫ÁöÑÁ¨¨‰∏ÄÊ≠•ÔºåÈÄô‰∫õÂØ¶ÂãôÊòéÁ¢∫ËÄÉÊÖÆÔºà‰∏¶ÊáâÂ∞çÔºâ‰∫∫È°ûÂÅèÂ•ΩÁöÑÂ§öËÆäÊÄßÂíåÂèØÂΩ±ÈüøÊÄß„ÄÇ

##### **The Economic Implications of Large Language Model Selection on Earnings and Return on Investment: A Decision Theoretic Model**
2405.17637v1 by Geraldo Xex√©o, Filipe Braida, Marcus Parreiras, Paulo Xavier

Selecting language models in business contexts requires a careful analysis of
the final financial benefits of the investment. However, the emphasis of
academia and industry analysis of LLM is solely on performance. This work
introduces a framework to evaluate LLMs, focusing on the earnings and return on
investment aspects that should be taken into account in business decision
making. We use a decision-theoretic approach to compare the financial impact of
different LLMs, considering variables such as the cost per token, the
probability of success in the specific task, and the gain and losses associated
with LLMs use. The study reveals how the superior accuracy of more expensive
models can, under certain conditions, justify a greater investment through more
significant earnings but not necessarily a larger RoI. This article provides a
framework for companies looking to optimize their technology choices, ensuring
that investment in cutting-edge technology aligns with strategic financial
objectives. In addition, we discuss how changes in operational variables
influence the economics of using LLMs, offering practical insights for
enterprise settings, finding that the predicted gain and loss and the different
probabilities of success and failure are the variables that most impact the
sensitivity of the models.

ÊëòË¶ÅÔºöÂú®ÂïÜÊ•≠ËÉåÊôØ‰∏ãÈÅ∏ÊìáË™ûË®ÄÊ®°ÂûãÈúÄË¶Å‰ªîÁ¥∞ÂàÜÊûêÊäïË≥áÁöÑÊúÄÁµÇË≤°ÂãôÊïàÁõä„ÄÇÁÑ∂ËÄåÔºåÂ≠∏Ë°ìÁïåÂíåÁî¢Ê•≠ÂàÜÊûê LLM ÁöÑÈáçÈªûÂÉÖÂú®ÊñºÊïàËÉΩ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜË©ï‰º∞ LLM ÁöÑÊû∂ÊßãÔºåÈáçÈªûÂú®ÊñºÊáâÂú®ÂïÜÊ•≠Ê±∫Á≠ñ‰∏≠ËÄÉÈáèÁöÑÊî∂ÁõäÂíåÊäïË≥áÂ†±ÈÖ¨ÁéáÊñπÈù¢„ÄÇÊàëÂÄë‰ΩøÁî®Ê±∫Á≠ñÁêÜË´ñÊñπÊ≥ï‰æÜÊØîËºÉ‰∏çÂêå LLM ÁöÑË≤°ÂãôÂΩ±ÈüøÔºåËÄÉÈáèËÆäÊï∏Ôºå‰æãÂ¶ÇÊØèÂÄã‰ª£Âπ£ÁöÑÊàêÊú¨„ÄÅÂú®ÁâπÂÆö‰ªªÂãô‰∏≠ÊàêÂäüÁöÑÊ©üÁéáÔºå‰ª•ÂèäËàá‰ΩøÁî® LLM Áõ∏ÈóúÁöÑÊî∂ÁõäÂíåÊêçÂ§±„ÄÇÁ†îÁ©∂Êè≠Á§∫‰∫ÜÂú®ÁâπÂÆöÊ¢ù‰ª∂‰∏ãÔºåÊõ¥ÊòÇË≤¥ÁöÑÊ®°ÂûãÁöÑÂÑ™Ë∂äÊ∫ñÁ¢∫Â∫¶Â¶Ç‰ΩïËÉΩÈÄèÈÅéÊõ¥È°ØËëóÁöÑÊî∂ÁõäË≠âÊòéÊõ¥Â§ßÁöÑÊäïË≥áÔºå‰ΩÜ‰∏ç‰∏ÄÂÆöËÉΩË≠âÊòéÊõ¥Â§ßÁöÑÊäïË≥áÂ†±ÈÖ¨Áéá„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºå‰æõÂ∞ãÊ±ÇÊúÄ‰Ω≥ÂåñÂÖ∂ÊäÄË°ìÈÅ∏ÊìáÁöÑÂÖ¨Âè∏‰ΩøÁî®ÔºåÁ¢∫‰øùÂ∞çÂ∞ñÁ´ØÊäÄË°ìÁöÑÊäïË≥áËàáÁ≠ñÁï•ÊÄßË≤°ÂãôÁõÆÊ®ô‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÁáüÈÅãËÆäÊï∏ÁöÑËÆäÂåñÂ¶Ç‰ΩïÂΩ±Èüø‰ΩøÁî® LLM ÁöÑÁ∂ìÊøüÊïàÁõäÔºåÊèê‰æõ‰ºÅÊ•≠Áí∞Â¢ÉÁöÑÂØ¶Áî®Ë¶ãËß£ÔºåÁôºÁèæÈ†êÊ∏¨ÁöÑÊî∂ÁõäÂíåÊêçÂ§±‰ª•ÂèäÊàêÂäüÁöÑ‰∏çÂêåÊ©üÁéáÂíåÂ§±ÊïóÁöÑÊ©üÁéáÊòØÂΩ±ÈüøÊ®°ÂûãÊïèÊÑüÂ∫¶ÁöÑËÆäÊï∏„ÄÇ

##### **BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring at Scale**
2405.17537v1 by ZeMing Gong, Austin T. Wang, Joakim Bruslund Haurum, Scott C. Lowe, Graham W. Taylor, Angel X. Chang

Measuring biodiversity is crucial for understanding ecosystem health. While
prior works have developed machine learning models for the taxonomic
classification of photographic images and DNA separately, in this work, we
introduce a multimodal approach combining both, using CLIP-style contrastive
learning to align images, DNA barcodes, and textual data in a unified embedding
space. This allows for accurate classification of both known and unknown insect
species without task-specific fine-tuning, leveraging contrastive learning for
the first time to fuse DNA and image data. Our method surpasses previous
single-modality approaches in accuracy by over 11% on zero-shot learning tasks,
showcasing its effectiveness in biodiversity studies.

ÊëòË¶ÅÔºöÊ∏¨ÈáèÁîüÁâ©Â§öÊ®£ÊÄßÂ∞çÊñº‰∫ÜËß£ÁîüÊÖãÁ≥ªÁµ±ÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÂ∑•‰ΩúÂ∑≤ÈáùÂ∞çÊîùÂΩ±ÂΩ±ÂÉèÂíå DNA ÁöÑÂàÜÈ°ûÂ≠∏ÂàÜÈ°ûÂàÜÂà•ÈñãÁôºÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå‰ΩÜÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁµêÂêàÂÖ©ËÄÖÁöÑÂ§öÊ®°ÂºèÊñπÊ≥ïÔºå‰ΩøÁî® CLIP È¢®Ê†ºÁöÑÂ∞çÊØîÂ≠∏Áøí‰æÜÊØîÂ∞çÂΩ±ÂÉè„ÄÅDNA Ê¢ùÁ¢ºÂíåÁµ±‰∏ÄÂµåÂÖ•Á©∫Èñì‰∏≠ÁöÑÊñáÂ≠óË≥áÊñô„ÄÇÈÄôÂÖÅË®±Â∞çÂ∑≤Áü•ÂíåÊú™Áü•ÊòÜËü≤Áâ©Á®ÆÈÄ≤Ë°åÊ∫ñÁ¢∫ÂàÜÈ°ûÔºåÁÑ°ÈúÄÁâπÂÆö‰ªªÂãôÁöÑÂæÆË™øÔºåÈ¶ñÊ¨°Âà©Áî®Â∞çÊØîÂ≠∏Áøí‰æÜËûçÂêà DNA ÂíåÂΩ±ÂÉèË≥áÊñô„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Èõ∂Ê¨°Â≠∏Áøí‰ªªÂãô‰∏≠Ë∂ÖË∂ä‰∫ÜÂÖàÂâçÁöÑÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 11% ‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÁîüÁâ©Â§öÊ®£ÊÄßÁ†îÁ©∂‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **On Fairness of Low-Rank Adaptation of Large Models**
2405.17512v1 by Zhoujie Ding, Ken Ziyu Liu, Pura Peetathawatchai, Berivan Isik, Sanmi Koyejo

Low-rank adaptation of large models, particularly LoRA, has gained traction
due to its computational efficiency. This efficiency, contrasted with the
prohibitive costs of full-model fine-tuning, means that practitioners often
turn to LoRA and sometimes without a complete understanding of its
ramifications. In this study, we focus on fairness and ask whether LoRA has an
unexamined impact on utility, calibration, and resistance to membership
inference across different subgroups (e.g., genders, races, religions) compared
to a full-model fine-tuning baseline. We present extensive experiments across
vision and language domains and across classification and generation tasks
using ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,
experiments suggest that while one can isolate cases where LoRA exacerbates
model bias across subgroups, the pattern is inconsistent -- in many cases, LoRA
has equivalent or even improved fairness compared to the base model or its full
fine-tuning baseline. We also examine the complications of evaluating
fine-tuning fairness relating to task design and model token bias, calling for
more careful fairness evaluations in future work.

ÊëòË¶ÅÔºö‰ΩéÁß©Â§ßÂûãÊ®°ÂûãÁöÑÈÅ©ÊáâÔºåÁâπÂà•ÊòØ LoRAÔºåÁî±ÊñºÂÖ∂Ë®àÁÆóÊïàÁéáËÄåÁç≤ÂæóÈóúÊ≥®„ÄÇÊ≠§ÊïàÁéáËàáÂÖ®Ê®°ÂûãÂæÆË™øÁöÑÁ¶ÅÊ≠¢ÊàêÊú¨ÂΩ¢ÊàêÂ∞çÊØîÔºåÈÄôË°®Á§∫ÂæûÊ•≠ËÄÖÁ∂ìÂ∏∏Ê±ÇÂä©Êñº LoRAÔºåÊúâÊôÇÂçª‰∏çÂÆåÂÖ®‰∫ÜËß£ÂÖ∂ÂæåÊûú„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂÖ¨Âπ≥ÊÄßÔºå‰∏¶Ë©¢Âïè LoRA ÊòØÂê¶Â∞çÊïàÁî®„ÄÅÊ†°Ê∫ñÂíåËàáÂÖ®Ê®°ÂûãÂæÆË™øÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÂ∞ç‰∏çÂêåÂ≠êÁæ§Ôºà‰æãÂ¶ÇÊÄßÂà•„ÄÅÁ®ÆÊóè„ÄÅÂÆóÊïôÔºâÁöÑÊàêÂì°Êé®Ë´ñÁöÑÊäµÊäóÂäõÊúâÊú™Á∂ìÊ™¢È©óÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂú®Ë¶ñË¶∫ÂíåË™ûË®ÄÈ†òÂüü‰ª•Âèä‰ΩøÁî® ViT-Base„ÄÅSwin-v2-Large„ÄÅLlama-2 7B Âíå Mistral 7B ÁöÑÂàÜÈ°ûÂíåÁîüÊàê‰ªªÂãô‰∏≠Â±ïÁ§∫‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂØ¶È©óË°®ÊòéÔºåÈõñÁÑ∂‰∫∫ÂÄëÂèØ‰ª•ÊâæÂá∫ LoRA Âú®Â≠êÁæ§‰∏≠Âä†ÂäáÊ®°ÂûãÂÅèÂ∑ÆÁöÑÊÉÖÊ≥ÅÔºå‰ΩÜÊ®°Âºè‰∏¶‰∏ç‰∏ÄËá¥‚Äî‚ÄîÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåËàáÂü∫Á§éÊ®°ÂûãÊàñÂÖ∂ÂÖ®ÂæÆË™øÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåLoRA ÂÖ∑ÊúâÁõ∏Á≠âÁîöËá≥Êõ¥Â•ΩÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÈÇÑÊ™¢È©ó‰∫ÜËàá‰ªªÂãôË®≠Ë®àÂíåÊ®°Âûã‰ª£Âπ£ÂÅèÂ∑ÆÁõ∏ÈóúÁöÑÂæÆË™øÂÖ¨Âπ≥ÊÄßË©ï‰º∞ÁöÑË§áÈõúÊÄßÔºåÂëºÁ±≤Âú®Êú™‰æÜÁöÑÁ†îÁ©∂‰∏≠ÈÄ≤Ë°åÊõ¥‰ªîÁ¥∞ÁöÑÂÖ¨Âπ≥ÊÄßË©ï‰º∞„ÄÇ

##### **Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning**
2405.16557v1 by Chun-Kai Huang, Yi-Hsien Hsieh, Ta-Jung Chien, Li-Cheng Chien, Shao-Hua Sun, Tung-Hung Su, Jia-Horng Kao, Che Lin

Multivariate time series (MTS) data, when sampled irregularly and
asynchronously, often present extensive missing values. Conventional
methodologies for MTS analysis tend to rely on temporal embeddings based on
timestamps that necessitate subsequent imputations, yet these imputed values
frequently deviate substantially from their actual counterparts, thereby
compromising prediction accuracy. Furthermore, these methods typically fail to
provide robust initial embeddings for values infrequently observed or even
absent within the training set, posing significant challenges to model
generalizability. In response to these challenges, we propose SCAlable
Numerical Embedding (SCANE), a novel framework that treats each feature value
as an independent token, effectively bypassing the need for imputation. SCANE
regularizes the traits of distinct feature embeddings and enhances
representational learning through a scalable embedding mechanism. Coupling
SCANE with the Transformer Encoder architecture, we develop the Scalable
nUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver
precise predictive outputs for MTS characterized by prevalent missing entries.
Our experimental validation, conducted across three disparate electronic health
record (EHR) datasets marked by elevated missing value frequencies, confirms
the superior performance of SUMMIT over contemporary state-of-the-art
approaches addressing similar challenges. These results substantiate the
efficacy of SCANE and SUMMIT, underscoring their potential applicability across
a broad spectrum of MTS data analytical tasks.

ÊëòË¶ÅÔºöÂ§öËÆäÈáèÊôÇÈñìÂ∫èÂàó (MTS) Ë≥áÊñôÂú®‰∏çË¶èÂâá‰∏îÈùûÂêåÊ≠•Âú∞ÂèñÊ®£ÊôÇÔºåÈÄöÂ∏∏ÊúÉÂá∫ÁèæÂ§ßÈáèÁöÑÈÅ∫Â§±ÂÄº„ÄÇMTS ÂàÜÊûêÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÂÇæÂêëÊñº‰æùË≥¥Âü∫ÊñºÊôÇÈñìÊà≥Ë®òÁöÑÊôÇÈñìÂµåÂÖ•ÔºåÈÄôÈúÄË¶ÅÂæåÁ∫åÁöÑÊèíË£úÔºå‰ΩÜÈÄô‰∫õÊèíË£úÂÄºÈÄöÂ∏∏ËàáÂÖ∂ÂØ¶ÈöõÂ∞çÊáâÂÄºÊúâÂæàÂ§ßÂÅèÂ∑ÆÔºåÂæûËÄåÂΩ±ÈüøÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÁÇ∫Ë®ìÁ∑¥ÈõÜ‰∏≠‰∏çÂ∏∏ËßÄÂØüÁîöËá≥‰∏çÂ≠òÂú®ÁöÑÂÄºÊèê‰æõÁ©©ÂÅ•ÁöÑÂàùÂßãÂµåÂÖ•ÔºåÈÄôÂ∞çÊ®°ÂûãÁöÑÊ≥õÂåñÊÄßÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂèØÊì¥ÂÖÖÊï∏ÂÄºÂµåÂÖ• (SCANE)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂ∞áÊØèÂÄãÁâπÂæµÂÄºË¶ñÁÇ∫‰∏ÄÂÄãÁç®Á´ãÁöÑÊ®ôË®òÔºåÊúâÊïàÂú∞ÁπûÈÅé‰∫ÜÊèíË£úÁöÑÈúÄË¶Å„ÄÇSCANE Ë¶èÁØÑ‰∫Ü‰∏çÂêåÁâπÂæµÂµåÂÖ•ÁöÑÁâπÂæµÔºå‰∏¶ÈÄöÈÅéÂèØÊì¥ÂÖÖÁöÑÂµåÂÖ•Ê©üÂà∂Â¢ûÂº∑‰∫ÜË°®ÂæµÂ≠∏Áøí„ÄÇÂ∞á SCANE Ëàá Transformer Á∑®Á¢ºÂô®Êû∂ÊßãÁµêÂêàÔºåÊàëÂÄëÈñãÁôº‰∫ÜÂèØÊì¥ÂÖÖÊï∏ÂÄºÂµåÂÖ• Transformer (SUMMIT)ÔºåÂÆÉË¢´Ë®≠Ë®àÁÇ∫ÁÇ∫ÂÖ∑ÊúâÊôÆÈÅçÈÅ∫Â§±Ê¢ùÁõÆÁöÑ MTS Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ëº∏Âá∫„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ©óË≠âÊòØÂú®‰∏âÂÄã‰∏çÂêåÁöÑÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÔºåÈÄô‰∫õË≥áÊñôÈõÜ‰ª•ÈÅ∫Â§±ÂÄºÈ†ªÁéáÈ´òÁÇ∫ÁâπÂæµÔºåË≠âÂØ¶‰∫Ü SUMMIT Âú®Ëß£Ê±∫È°û‰ººÊåëÊà∞ÁöÑÁï∂‰ª£ÊúÄÂÖàÈÄ≤ÊñπÊ≥ï‰∏äÁöÑÂçìË∂äÊÄßËÉΩ„ÄÇÈÄô‰∫õÁµêÊûúË≠âÂØ¶‰∫Ü SCANE Âíå SUMMIT ÁöÑÂäüÊïàÔºåÂº∑Ë™ø‰∫ÜÂÆÉÂÄëÂú®Âª£Ê≥õÁöÑ MTS Ë≥áÊñôÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑÊΩõÂú®ÈÅ©Áî®ÊÄß„ÄÇ

##### **SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation**
2405.16552v1 by Ziqin Luo, Haixia Han, Haokun Zhao, Guochao Jiang, Chengyu Du, Tingyun Li, Jiaqing Liang, Deqing Yang, Yanghua Xiao

Existing Large Language Models (LLMs) generate text through unidirectional
autoregressive decoding methods to respond to various user queries. These
methods tend to consider token selection in a simple sequential manner, making
it easy to fall into suboptimal options when encountering uncertain tokens,
referred to as chaotic points in our work. Many chaotic points exist in texts
generated by LLMs, and they often significantly affect the quality of
subsequently generated tokens, which can interfere with LLMs' generation. This
paper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing
model generation. Analogous to the human decision-making process, SED
integrates speculation and evaluation steps into the decoding process, allowing
LLMs to make more careful decisions and thus optimize token selection at
chaotic points. Experimental results across various tasks using different LLMs
demonstrate SED's effectiveness.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÂñÆÂêëËá™Ëø¥Ê≠∏Ëß£Á¢ºÊñπÊ≥ïÁî¢ÁîüÊñáÂ≠óÔºå‰ª•ÂõûÊáâÂêÑÁ®Æ‰ΩøÁî®ËÄÖÊü•Ë©¢„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÇæÂêëÊñº‰ª•Á∞°ÂñÆÁöÑÈ†ÜÂ∫èÊñπÂºèËÄÉÈáè‰ª£Á¢ºÈÅ∏ÊìáÔºåÂú®ÈÅáÂà∞‰∏çÁ¢∫ÂÆöÁöÑ‰ª£Á¢ºÔºàÂú®ÊàëÂÄëÁöÑÂ∑•‰Ωú‰∏≠Á®±ÁÇ∫Ê∑∑‰∫ÇÈªûÔºâÊôÇÔºåÂæàÂÆπÊòìÈô∑ÂÖ•Ê¨°‰Ω≥ÈÅ∏È†Ö„ÄÇLLM ÁîüÊàêÁöÑÊñáÂ≠ó‰∏≠Â≠òÂú®Ë®±Â§öÊ∑∑‰∫ÇÈªûÔºåËÄåÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÈ°ØËëóÂΩ±ÈüøÂæåÁ∫åÁîüÊàê‰ª£Á¢ºÁöÑÂìÅË≥™ÔºåÈÄ≤ËÄåÂπ≤Êìæ LLM ÁöÑÁîüÊàê„ÄÇÊú¨ÊñáÊèêÂá∫Ëá™ÊàëË©ï‰º∞Ëß£Á¢º (SED)Ôºå‰∏ÄÁ®ÆÁî®ÊñºÂ¢ûÂº∑Ê®°ÂûãÁîüÊàêÁöÑËß£Á¢ºÊñπÊ≥ï„ÄÇÈ°ûÊØîÊñº‰∫∫È°ûÊ±∫Á≠ñÈÅéÁ®ãÔºåSED Â∞áÊé®Ê∏¨ÂíåË©ï‰º∞Ê≠•È©üÊï¥ÂêàÂà∞Ëß£Á¢ºÈÅéÁ®ã‰∏≠ÔºåËÆì LLM ËÉΩÂÅöÂá∫Êõ¥Ë¨πÊÖéÁöÑÊ±∫ÂÆöÔºåÈÄ≤ËÄåÊúÄ‰Ω≥ÂåñÊ∑∑‰∫ÇÈªûÁöÑ‰ª£Á¢ºÈÅ∏Êìá„ÄÇ‰ΩøÁî®‰∏çÂêå LLM Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü SED ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Gamified AI Approch for Early Detection of Dementia**
2405.16538v1 by Paramita Kundu Maji, Soubhik Acharya, Priti Paul, Sanjay Chakraborty, Saikat Basu

This paper aims to develop a new deep learning-inspired gaming approach for
early detection of dementia. This research integrates a robust convolutional
neural network (CNN)-based model for early dementia detection using health
metrics data as well as facial image data through a cognitive assessment-based
gaming application. We have collected 1000 data samples of health metrics
dataset from Apollo Diagnostic Center Kolkata that is labeled as either
demented or non-demented for the training of MOD-1D-CNN for the game level 1
and another dataset of facial images containing 1800 facial data that are
labeled as either demented or non-demented is collected by our research team
for the training of MOD-2D-CNN model in-game level 2. In our work, the loss for
the proposed MOD-1D-CNN model is 0.2692 and the highest accuracy is 70.50% for
identifying the dementia traits using real-life health metrics data. Similarly,
the proposed MOD-2D-CNN model loss is 0.1755 and the highest accuracy is
obtained here 95.72% for recognizing the dementia status using real-life
face-based image data. Therefore, a rule-based weightage method is applied to
combine both the proposed methods to achieve the final decision. The MOD-1D-CNN
and MOD-2D-CNN models are more lightweight and computationally efficient
alternatives because they have a significantly lower number of parameters when
compared to the other state-of-the-art models. We have compared their
accuracies and parameters with the other state-of-the-art deep learning models.

ÊëòË¶ÅÔºöÊú¨ÊñáÊó®Âú®ÂºÄÂèë‰∏ÄÁßçÊñ∞ÁöÑÂèóÊ∑±Â∫¶Â≠¶‰π†ÂêØÂèëÁöÑÊ∏∏ÊàèÊñπÊ≥ïÔºåÁî®‰∫éÊó©ÊúüÊ£ÄÊµãÁó¥ÂëÜÁóá„ÄÇÊú¨Á†îÁ©∂Êï¥Âêà‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÈ≤ÅÊ£íÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) ÁöÑÊ®°ÂûãÔºåÁî®‰∫éÈÄöËøáËÆ§Áü•ËØÑ‰º∞Ê∏∏ÊàèÂ∫îÁî®Á®ãÂ∫è‰ΩøÁî®ÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆÂíåÈù¢ÈÉ®ÂõæÂÉèÊï∞ÊçÆËøõË°åÊó©ÊúüÁó¥ÂëÜÁóáÊ£ÄÊµã„ÄÇÊàë‰ª¨‰ªé Apollo Diagnostic Center Kolkata Êî∂ÈõÜ‰∫Ü 1000 ‰∏™ÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆÈõÜÁöÑÊï∞ÊçÆÊ†∑Êú¨ÔºåËøô‰∫õÊ†∑Êú¨Ë¢´Ê†áËÆ∞‰∏∫Áó¥ÂëÜÊàñÈùûÁó¥ÂëÜÔºåÁî®‰∫éËÆ≠ÁªÉÊ∏∏ÊàèÁ¨¨ 1 ÂÖ≥ÁöÑ MOD-1D-CNNÔºå‰ª•ÂèäÁî±Êàë‰ª¨Á†îÁ©∂Âõ¢ÈòüÊî∂ÈõÜÁöÑÂè¶‰∏Ä‰∏™ÂåÖÂê´ 1800 ‰∏™Èù¢ÈÉ®Êï∞ÊçÆÁöÑÁöÑÈù¢ÈÉ®ÂõæÂÉèÊï∞ÊçÆÈõÜÔºåËøô‰∫õÊï∞ÊçÆË¢´Ê†áËÆ∞‰∏∫Áó¥ÂëÜÊàñÈùûÁó¥ÂëÜÔºåÁî®‰∫éËÆ≠ÁªÉÊ∏∏ÊàèÁ¨¨ 2 ÂÖ≥ÁöÑ MOD-2D-CNN Ê®°Âûã„ÄÇÂú®Êàë‰ª¨ÁöÑÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫ÁöÑ MOD-1D-CNN Ê®°ÂûãÁöÑÊçüÂ§±‰∏∫ 0.2692Ôºå‰ΩøÁî®ÁúüÂÆûÂÅ•Â∫∑ÊåáÊ†áÊï∞ÊçÆËØÜÂà´Áó¥ÂëÜÁâπÂæÅÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéá‰∏∫ 70.50%„ÄÇÁ±ª‰ººÂú∞ÔºåÊèêÂá∫ÁöÑ MOD-2D-CNN Ê®°ÂûãÊçüÂ§±‰∏∫ 0.1755Ôºå‰ΩøÁî®ÁúüÂÆûÂü∫‰∫éÈù¢ÈÉ®ÁöÑÂõæÂÉèÊï∞ÊçÆËØÜÂà´Áó¥ÂëÜÁä∂ÊÄÅÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéá‰∏∫ 95.72%„ÄÇÂõ†Ê≠§ÔºåÂ∫îÁî®Âü∫‰∫éËßÑÂàôÁöÑÂä†ÊùÉÊñπÊ≥ïÊù•ÁªìÂêàËøô‰∏§ÁßçÊèêÂá∫ÁöÑÊñπÊ≥ï‰ª•ÂÆûÁé∞ÊúÄÁªàÂÜ≥Á≠ñ„ÄÇ‰∏éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåMOD-1D-CNN Âíå MOD-2D-CNN Ê®°ÂûãÊõ¥ËΩªÈáè‰∏îËÆ°ÁÆóÊïàÁéáÊõ¥È´òÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑÂèÇÊï∞Êï∞ÈáèÊòéÊòæÊõ¥Â∞ë„ÄÇÊàë‰ª¨Â∑≤Â∞ÜÂÆÉ‰ª¨ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèÇÊï∞‰∏éÂÖ∂‰ªñÊúÄÂÖàËøõÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãËøõË°å‰∫ÜÊØîËæÉ„ÄÇ

##### **ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text**
2405.19366v1 by Han Yu, Peikun Guo, Akane Sano

The utilization of deep learning on electrocardiogram (ECG) analysis has
brought the advanced accuracy and efficiency of cardiac healthcare diagnostics.
By leveraging the capabilities of deep learning in semantic understanding,
especially in feature extraction and representation learning, this study
introduces a new multimodal contrastive pretaining framework that aims to
improve the quality and robustness of learned representations of 12-lead ECG
signals. Our framework comprises two key components, including Cardio Query
Assistant (CQA) and ECG Semantics Integrator(ESI). CQA integrates a
retrieval-augmented generation (RAG) pipeline to leverage large language models
(LLMs) and external medical knowledge to generate detailed textual descriptions
of ECGs. The generated text is enriched with information about demographics and
waveform patterns. ESI integrates both contrastive and captioning loss to
pretrain ECG encoders for enhanced representations. We validate our approach
through various downstream tasks, including arrhythmia detection and ECG-based
subject identification. Our experimental results demonstrate substantial
improvements over strong baselines in these tasks. These baselines encompass
supervised and self-supervised learning methods, as well as prior multimodal
pretraining approaches.

ÊëòË¶ÅÔºöÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÊñºÂøÉÈõªÂúñ (ECG) ÂàÜÊûêÂ∑≤ÊèêÂçáÂøÉËáü‰øùÂÅ•Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇÈÄèÈÅéÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÂú®Ë™ûÊÑèÁêÜËß£‰∏≠ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®ÁâπÂæµËêÉÂèñÂíåË°®Á§∫Â≠∏Áøí‰∏≠ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂ§öÊ®°ÊÖãÂ∞çÊØîÈ†êË®ìÁ∑¥Êû∂ÊßãÔºåÊó®Âú®ÊèêÂçá 12 Â∞éÁ®ã ECG Ë®äËôüÂ≠∏ÁøíË°®Á§∫ÁöÑÂìÅË≥™ÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÂÖÉ‰ª∂ÔºåÂåÖÊã¨ÂøÉËáüÊü•Ë©¢Âä©ÁêÜ (CQA) Âíå ECG Ë™ûÊÑèÊï¥ÂêàÂô® (ESI)„ÄÇCQA Êï¥Âêà‰∏ÄÂÄãÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁÆ°Á∑öÔºå‰ª•Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂ§ñÈÉ®ÈÜ´ÁôÇÁü•Ë≠ò‰æÜÁîüÊàê ECG ÁöÑË©≥Á¥∞ÊñáÂ≠óÊèèËø∞„ÄÇÁîüÊàêÁöÑÊñáÂ≠óÂåÖÂê´‰∫∫Âè£Áµ±Ë®àÂíåÊ≥¢ÂΩ¢Ê®°ÂºèÁöÑË≥áË®ä„ÄÇESI Êï¥ÂêàÂ∞çÊØîÂíåÊ®ôÈ°åÊêçÂ§±Ôºå‰ª•È†êË®ìÁ∑¥ ECG Á∑®Á¢ºÂô®‰ª•Áç≤ÂæóÂ¢ûÂº∑ÁöÑË°®Á§∫„ÄÇÊàëÂÄëÈÄèÈÅéÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂåÖÊã¨ÂøÉÂæã‰∏çÊï¥ÂÅµÊ∏¨ÂíåÂü∫Êñº ECG ÁöÑÂèóË©¶ËÄÖË≠òÂà•„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂú®ÈÄô‰∫õ‰ªªÂãô‰∏≠Â§ßÂπÖÊèêÂçáÂº∑Â§ßÁöÑÂü∫Á∑ö„ÄÇÈÄô‰∫õÂü∫Á∑öÂåÖÂê´Áõ£Áù£ÂºèÂíåËá™Áõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÂèäÂÖàÂâçÁöÑÂ§öÊ®°ÊÖãÈ†êË®ìÁ∑¥ÊñπÊ≥ï„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models**
2405.16413v1 by Jiankun Wang, Sumyeong Ahn, Taykhoom Dalal, Xiaodan Zhang, Weishen Pan, Qiannan Zhang, Bin Chen, Hiroko H. Dodge, Fei Wang, Jiayu Zhou

Alzheimer's disease (AD) is the fifth-leading cause of death among Americans
aged 65 and older. Screening and early detection of AD and related dementias
(ADRD) are critical for timely intervention and for identifying clinical trial
participants. The widespread adoption of electronic health records (EHRs)
offers an important resource for developing ADRD screening tools such as
machine learning based predictive models. Recent advancements in large language
models (LLMs) demonstrate their unprecedented capability of encoding knowledge
and performing reasoning, which offers them strong potential for enhancing risk
prediction. This paper proposes a novel pipeline that augments risk prediction
by leveraging the few-shot inference power of LLMs to make predictions on cases
where traditional supervised learning methods (SLs) may not excel.
Specifically, we develop a collaborative pipeline that combines SLs and LLMs
via a confidence-driven decision-making mechanism, leveraging the strengths of
SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this
pipeline using a real-world EHR data warehouse from Oregon Health \& Science
University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients
and more than 20 million patient encounters. Our results show that our proposed
approach effectively combines the power of SLs and LLMs, offering significant
improvements in predictive performance. This advancement holds promise for
revolutionizing ADRD screening and early detection practices, with potential
implications for better strategies of patient management and thus improving
healthcare.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ 65 Ê≠≤‰ª•‰∏äÁæéÂúã‰∫∫ÁöÑÁ¨¨‰∫îÂ§ßÊ≠ªÂõ†„ÄÇAD ÂíåÁõ∏ÈóúÂ§±Êô∫Áóá (ADRD) ÁöÑÁØ©Ê™¢ÂíåÊó©ÊúüÂÅµÊ∏¨Â∞çÊñºÂèäÊôÇ‰ªãÂÖ•ÂíåÊâæÂá∫Ëá®Â∫äË©¶È©óÂèÉËàáËÄÖËá≥ÈóúÈáçË¶Å„ÄÇÈõªÂ≠êÁóÖÊ≠∑ (EHRs) ÁöÑÂª£Ê≥õÊé°Áî®Êèê‰æõ‰∫ÜÈñãÁôº ADRD ÁØ©Ê™¢Â∑•ÂÖ∑ÁöÑÈáçË¶ÅË≥áÊ∫êÔºå‰æãÂ¶ÇÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫Âá∫ÂÖ∂Á∑®Á¢ºÁü•Ë≠òÂíåÂü∑Ë°åÊé®ÁêÜÁöÑÁ©∫ÂâçËÉΩÂäõÔºåÈÄôÁÇ∫Â¢ûÂº∑È¢®Èö™È†êÊ∏¨Êèê‰æõ‰∫ÜÂº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁÆ°ÈÅìÔºåÂÆÉÈÄöÈÅéÂà©Áî® LLM ÁöÑÂ∞ëÈáèÊé®ÁêÜËÉΩÂäõ‰æÜÂ¢ûÂº∑È¢®Èö™È†êÊ∏¨ÔºåÂ∞çÂÇ≥Áµ±Áõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï (SL) ÂèØËÉΩÁÑ°Ê≥ïÂãù‰ªªÁöÑÊ°à‰æãÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂçî‰ΩúÁÆ°ÈÅìÔºåÈÄöÈÅé‰ø°ÂøÉÈ©ÖÂãïÁöÑÊ±∫Á≠ñÊ©üÂà∂Â∞á SL Âíå LLM ÁµêÂêàËµ∑‰æÜÔºåÂà©Áî® SL Âú®ÊòéÁ¢∫Ê°à‰æã‰∏≠ÁöÑÂÑ™Âã¢Âíå LLM Âú®Êõ¥Ë§áÈõúÂ†¥ÊôØ‰∏≠ÁöÑÂÑ™Âã¢„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™‰øÑÂãíÂ≤°Â∑ûÂÅ•Â∫∑ËàáÁßëÂ≠∏Â§ßÂ≠∏ (OHSU) ÈÜ´Èô¢ÁöÑÁúüÂØ¶‰∏ñÁïå EHR Ë≥áÊñôÂÄâÂ∫´Ë©ï‰º∞‰∫ÜÈÄôÂÄãÁÆ°ÈÅìÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ 250 Â§öËê¨ÂêçÊÇ£ËÄÖÂíå 2000 Â§öËê¨Ê¨°ÊÇ£ËÄÖÂ∞±Ë®∫ÁöÑ EHR„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÊúâÊïàÂú∞ÁµêÂêà‰∫Ü SL Âíå LLM ÁöÑÂÑ™Âã¢ÔºåÂú®È†êÊ∏¨ÊÄßËÉΩÊñπÈù¢Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÊúâÊúõÈù©Êñ∞ ADRD ÁØ©Ê™¢ÂíåÊó©ÊúüÂÅµÊ∏¨ÂØ¶ÂãôÔºåÂ∞çÊÇ£ËÄÖÁÆ°ÁêÜÁöÑÊõ¥Â•ΩÁ≠ñÁï•‰ª•ÂèäÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÂÖ∑ÊúâÊΩõÂú®ÂΩ±Èüø„ÄÇ

##### **Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions**
2405.16402v1 by Man Luo, Christopher J. Warren, Lu Cheng, Haidar M. Abdul-Muhsin, Imon Banerjee

The integration of Large Language Models (LLMs) into the healthcare domain
has the potential to significantly enhance patient care and support through the
development of empathetic, patient-facing chatbots. This study investigates an
intriguing question Can ChatGPT respond with a greater degree of empathy than
those typically offered by physicians? To answer this question, we collect a
de-identified dataset of patient messages and physician responses from Mayo
Clinic and generate alternative replies using ChatGPT. Our analyses incorporate
novel empathy ranking evaluation (EMRank) involving both automated metrics and
human assessments to gauge the empathy level of responses. Our findings
indicate that LLM-powered chatbots have the potential to surpass human
physicians in delivering empathetic communication, suggesting a promising
avenue for enhancing patient care and reducing professional burnout. The study
not only highlights the importance of empathy in patient interactions but also
proposes a set of effective automatic empathy ranking metrics, paving the way
for the broader adoption of LLMs in healthcare.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÔºåÊúâÊΩõÂäõÈÄèÈÅéÈñãÁôºÂêåÁêÜÂøÉ„ÄÅÈù¢ÂêëÁóÖÊÇ£ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫‰æÜÂ§ßÂπÖÊèêÂçáÁóÖÊÇ£ÁÖßË≠∑ÂíåÊîØÊåÅ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∏ÄÂÄãÂºï‰∫∫ÂÖ•ÂãùÁöÑÂïèÈ°åÔºöChatGPT ËÉΩÂê¶ÊØî‰∏ÄËà¨ÈÜ´ÁîüÊèê‰æõÊõ¥Â§öÂêåÁêÜÂøÉÁöÑÂõûÊáâÔºüÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü‰∏ÄÁµÑ‰æÜËá™Ê¢ÖÁ¥ÑË®∫ÊâÄÁöÑÂéªË≠òÂà•ÂåñÁóÖÊÇ£Ë®äÊÅØÂíåÈÜ´ÁîüÂõûÊáâË≥áÊñôÈõÜÔºå‰∏¶‰ΩøÁî® ChatGPT Áî¢ÁîüÊõø‰ª£ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÁµêÂêà‰∫ÜÊñ∞Á©éÁöÑÂêåÁêÜÂøÉÊéíÂêçË©ï‰º∞ (EMRank)ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ëá™ÂãïÂåñÊåáÊ®ôÂíå‰∫∫ÁÇ∫Ë©ï‰º∞Ôºå‰ª•Ë©ïÈáèÂõûÊáâÁöÑÂêåÁêÜÂøÉÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM È©ÖÂãïÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÊúâÊΩõÂäõÂú®Êèê‰æõÂêåÁêÜÂøÉÊ∫ùÈÄöÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûÈÜ´ÁîüÔºåÈÄôÊöóÁ§∫‰∫Ü‰∏ÄÊ¢ùÊèêÂçáÁóÖÊÇ£ÁÖßË≠∑ÂíåÊ∏õÂ∞ëÂ∞àÊ•≠ÂÄ¶ÊÄ†ÁöÑÊΩõÂú®ÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂‰∏çÂÉÖÂº∑Ë™ø‰∫ÜÂêåÁêÜÂøÉÂú®ÁóÖÊÇ£‰∫íÂãï‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºå‰πüÊèêÂá∫‰∫Ü‰∏ÄÁµÑÊúâÊïàÁöÑËá™ÂãïÂêåÁêÜÂøÉÊéíÂêçÊåáÊ®ôÔºåÁÇ∫ LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊõ¥Âª£Ê≥õÊé°Áî®Èã™Ë∑Ø„ÄÇ

##### **Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets**
2405.16082v1 by Hyekyoung Hwang, Jitae Shin

Deep Learning (DL) has made remarkable achievements in computer vision and
adopted in safety critical domains such as medical imaging or autonomous drive.
Thus, it is necessary to understand the uncertainty of the model to effectively
reduce accidents and losses due to misjudgment of the Deep Neural Networks
(DNN). This can start by efficiently selecting data that could potentially
malfunction to the model. Traditionally, data collection and labeling have been
done manually, but recently test data selection methods have emerged that focus
on capturing samples that are not relevant to what the model had been learned.
They're selected based on the activation pattern of neurons in DNN, entropy
minimization based on softmax output of the DL. However, these methods cannot
quantitatively analyze the extent to which unseen samples are extrapolated from
the training data. Therefore, we propose To-hull Uncertainty and Closure Ratio,
which measures an uncertainty of trained model based on the convex hull of
training data. It can observe the positional relation between the convex hull
of the learned data and an unseen sample and infer how extrapolate the sample
is from the convex hull. To evaluate the proposed method, we conduct empirical
studies on popular datasets and DNN models, compared to state-of-the art test
selection metrics. As a result of the experiment, the proposed To-hull
Uncertainty is effective in finding samples with unusual patterns (e.g.
adversarial attack) compared to the existing test selection metric.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®ÈõªËÖ¶Ë¶ñË¶∫ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂ∞±Ôºå‰∏¶Ë¢´Êé°Áî®ÊñºÂÆâÂÖ®ÈóúÈçµÈ†òÂüüÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂΩ±ÂÉèÊàñËá™ÂãïÈßïÈßõ„ÄÇÂõ†Ê≠§Ôºå‰∫ÜËß£Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊñºÊúâÊïàÊ∏õÂ∞ëÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Ë™§Âà§ÈÄ†ÊàêÁöÑÊÑèÂ§ñ‰∫ãÊïÖÂíåÊêçÂ§±ÊòØÂøÖË¶ÅÁöÑ„ÄÇÈÄôÂèØ‰ª•ÂæûÊúâÊïàÂú∞ÈÅ∏ÊìáÊΩõÂú®ÂèØËÉΩÂ∞éËá¥Ê®°ÂûãÊïÖÈöúÁöÑË≥áÊñôÈñãÂßã„ÄÇÂÇ≥Áµ±‰∏äÔºåË≥áÊñôÊî∂ÈõÜÂíåÊ®ôË®òÊòØÊâãÂãïÂÆåÊàêÁöÑÔºå‰ΩÜÊúÄËøëÂá∫Áèæ‰∫ÜÊ∏¨Ë©¶Ë≥áÊñôÈÅ∏ÂèñÊñπÊ≥ïÔºåÂÖ∂ÈáçÈªûÂú®ÊñºÊì∑ÂèñËàáÊ®°ÂûãÊâÄÂ≠∏ÁøíÂÖßÂÆπÁÑ°ÈóúÁöÑÊ®£Êú¨„ÄÇÂÆÉÂÄëÊòØÊ†πÊìö DNN ‰∏≠Á•ûÁ∂ìÂÖÉÁöÑÊøÄÊ¥ªÊ®°Âºè„ÄÅÂü∫Êñº DL ÁöÑ softmax Ëº∏Âá∫ÁöÑÁÜµÊúÄÂ∞èÂåñ‰æÜÈÅ∏ÊìáÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÈáèÂåñÂàÜÊûêÊú™Ë¶ãÊ®£Êú¨ÂæûË®ìÁ∑¥Ë≥áÊñô‰∏≠Â§ñÊé®ÁöÑÁ®ãÂ∫¶„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü To-hull ‰∏çÁ¢∫ÂÆöÊÄßÂíåÂ∞ÅÈñâÊØîÁéáÔºåÂÆÉÊ†πÊìöË®ìÁ∑¥Ë≥áÊñôÁöÑÂá∏ÂåÖÊ∏¨ÈáèË®ìÁ∑¥Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂÆÉÂèØ‰ª•ËßÄÂØüÂ∑≤Â≠∏ÁøíË≥áÊñôÁöÑÂá∏ÂåÖÂíåÊú™Ë¶ãÊ®£Êú¨‰πãÈñìÁöÑ‰ΩçÁΩÆÈóú‰øÇÔºå‰∏¶Êé®Ë´ñÊ®£Êú¨ÊòØÂ¶Ç‰ΩïÂæûÂá∏ÂåÖ‰∏≠Â§ñÊé®ÁöÑ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂ∞çÊµÅË°åÁöÑË≥áÊñôÈõÜÂíå DNN Ê®°ÂûãÈÄ≤Ë°åÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰∏¶ËàáÊúÄÂÖàÈÄ≤ÁöÑÊ∏¨Ë©¶ÈÅ∏ÊìáÊåáÊ®ôÈÄ≤Ë°åÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÁèæÊúâÁöÑÊ∏¨Ë©¶ÈÅ∏ÊìáÊåáÊ®ôÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑ To-hull ‰∏çÁ¢∫ÂÆöÊÄßÂú®Â∞ãÊâæÂÖ∑ÊúâÁï∞Â∏∏Ê®°ÂºèÔºà‰æãÂ¶ÇÂ∞çÊäóÊÄßÊîªÊìäÔºâÁöÑÊ®£Êú¨ÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇ

##### **Transductive Confidence Machine and its application to Medical Data Sets**
2405.15988v1 by David Lindsay

The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and
a supporting, simple user interface was developed. Different settings of the
TCMNN algorithms' parameters were tested on medical data sets, in addition to
the use of different Minkowski metrics and polynomial kernels. The effect of
increasing the number of nearest neighbours and marking results with
significance was also investigated. SVM implementation of the Transductive
Confidence Machine was compared with Nearest Neighbours implementation. The
application of neural networks was investigated as a useful comparison to the
transductive algorithms.

ÊëòË¶ÅÔºöÈñãÁôº‰∫ÜËΩâÂ∞é‰ø°ÂøÉÊ©üÂô®ÊúÄËøëÈÑ∞Â±Ö (TCMNN) ÊºîÁÆóÊ≥ïÂíåÊîØÊè¥ÊÄßÁöÑÁ∞°ÂñÆ‰ΩøÁî®ËÄÖ‰ªãÈù¢„ÄÇÈô§‰∫Ü‰ΩøÁî®‰∏çÂêåÁöÑÊòéÂèØÂ§´ÊñØÂü∫Â∫¶ÈáèÂíåÂ§öÈ†ÖÂºèÊ†∏‰πãÂ§ñÔºåÈÇÑÈáùÂ∞çÈÜ´ÁôÇË≥áÊñôÈõÜÊ∏¨Ë©¶‰∫Ü TCMNN ÊºîÁÆóÊ≥ïÂèÉÊï∏ÁöÑ‰∏çÂêåË®≠ÂÆö„ÄÇ‰πüÊé¢Ë®é‰∫ÜÂ¢ûÂä†ÊúÄËøëÈÑ∞Â±ÖÊï∏ÁõÆÂíåÊ®ôË®òÁµêÊûúÈ°ØËëóÊÄßÁöÑÂΩ±Èüø„ÄÇÂ∞áËΩâÂ∞é‰ø°ÂøÉÊ©üÂô®ÁöÑ SVM ÂØ¶‰ΩúËàáÊúÄËøëÈÑ∞Â±ÖÂØ¶‰ΩúÈÄ≤Ë°åÊØîËºÉ„ÄÇÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊáâÁî®Ôºå‰ΩúÁÇ∫Â∞çËΩâÂ∞éÊºîÁÆóÊ≥ïÊúâÁî®ÁöÑÊØîËºÉ„ÄÇ

##### **The Impact and Opportunities of Generative AI in Fact-Checking**
2405.15985v1 by Robert Wolfe, Tanushree Mitra

Generative AI appears poised to transform white collar professions, with more
than 90% of Fortune 500 companies using OpenAI's flagship GPT models, which
have been characterized as "general purpose technologies" capable of effecting
epochal changes in the economy. But how will such technologies impact
organizations whose job is to verify and report factual information, and to
ensure the health of the information ecosystem? To investigate this question,
we conducted 30 interviews with N=38 participants working at 29 fact-checking
organizations across six continents, asking about how they use generative AI
and the opportunities and challenges they see in the technology. We found that
uses of generative AI envisioned by fact-checkers differ based on
organizational infrastructure, with applications for quality assurance in
Editing, for trend analysis in Investigation, and for information literacy in
Advocacy. We used the TOE framework to describe participant concerns ranging
from the Technological (lack of transparency), to the Organizational (resource
constraints), to the Environmental (uncertain and evolving policy). Building on
the insights of our participants, we describe value tensions between
fact-checking and generative AI, and propose a novel Verification dimension to
the design space of generative models for information verification work.
Finally, we outline an agenda for fairness, accountability, and transparency
research to support the responsible use of generative AI in fact-checking.
Throughout, we highlight the importance of human infrastructure and labor in
producing verified information in collaboration with AI. We expect that this
work will inform not only the scientific literature on fact-checking, but also
contribute to understanding of organizational adaptation to a powerful but
unreliable new technology.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI ‰ºº‰πéÊ∫ñÂÇôËΩâËÆäÁôΩÈ†òËÅ∑Ê•≠ÔºåË∂ÖÈÅé 90% ÁöÑË≤°ÂØå 500 Â§ß‰ºÅÊ•≠‰ΩøÁî® OpenAI ÁöÑÊóóËâ¶ GPT Ê®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãË¢´Á®±ÁÇ∫„ÄåÈÄöÁî®ÊäÄË°ì„ÄçÔºåËÉΩÂ§†Â∞çÁ∂ìÊøüÁî¢ÁîüÂäÉÊôÇ‰ª£ÁöÑÊîπËÆä„ÄÇ‰ΩÜÈÄô‰∫õÊäÄË°ìÂ∞áÂ¶Ç‰ΩïÂΩ±ÈüøË≤†Ë≤¨È©óË≠âÂíåÂ†±Â∞é‰∫ãÂØ¶Ë≥áË®äÔºå‰∏¶Á¢∫‰øùË≥áË®äÁîüÊÖãÁ≥ªÁµ±ÂÅ•Â∫∑ÁöÑÁµÑÁπîÔºüÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞çÊ©´Ë∑®ÂÖ≠Â§ßÊ¥≤ÁöÑ 29 ÂÄãÊü•Ê†∏‰∫ãÂØ¶ÁµÑÁπî‰∏≠‰ªªËÅ∑ÁöÑ N=38 ÂêçÂèÉËàáËÄÖÈÄ≤Ë°å‰∫Ü 30 Ê¨°Ë®™Ë´áÔºåË©¢Âïè‰ªñÂÄëÂ¶Ç‰Ωï‰ΩøÁî®ÁîüÊàêÂºè AIÔºå‰ª•Âèä‰ªñÂÄëÂú®ÊäÄË°ì‰∏≠ÁúãÂà∞ÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇÊàëÂÄëÁôºÁèæÊü•Ê†∏‰∫∫Âì°Ë®≠ÊÉ≥ÁöÑÁîüÊàêÂºè AI Áî®ÈÄîÂõ†ÁµÑÁπîÂü∫Á§éÊû∂ÊßãËÄåÁï∞ÔºåÂú®Á∑®ËºØ‰∏≠ÊáâÁî®ÊñºÂìÅË≥™‰øùË≠â„ÄÅÂú®Ë™øÊü•‰∏≠ÊáâÁî®ÊñºË∂®Âã¢ÂàÜÊûê„ÄÅÂú®ÂÄ°Ë≠∞‰∏≠ÊáâÁî®ÊñºË≥áË®äÁ¥†È§ä„ÄÇÊàëÂÄë‰ΩøÁî® TOE Êû∂Êßã‰æÜÊèèËø∞ÂèÉËàáËÄÖÁöÑÁñëÊÖÆÔºåÁØÑÂúçÂæûÊäÄË°ìÔºàÁº∫‰πèÈÄèÊòéÂ∫¶Ôºâ„ÄÅÁµÑÁπîÔºàË≥áÊ∫êÈôêÂà∂ÔºâÂà∞Áí∞Â¢ÉÔºà‰∏çÁ¢∫ÂÆö‰∏î‰∏çÊñ∑ÊºîËÆäÁöÑÊîøÁ≠ñÔºâ„ÄÇÊ†πÊìöÂèÉËàáËÄÖÁöÑË¶ãËß£ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÊü•Ê†∏‰∫ãÂØ¶ÂíåÁîüÊàêÂºè AI ‰πãÈñìÁöÑÂÉπÂÄºÁ∑äÂºµÈóú‰øÇÔºå‰∏¶ÁÇ∫Ë≥áË®äÈ©óË≠âÂ∑•‰Ωú‰∏≠ÁîüÊàêÂºèÊ®°ÂûãÁöÑË®≠Ë®àÁ©∫ÈñìÊèêÂá∫‰∫ÜÊñ∞ÁöÑÈ©óË≠âÈù¢Âêë„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂÖ¨Âπ≥ÊÄß„ÄÅÂïèË≤¨Âà∂ÂíåÈÄèÊòéÂ∫¶Á†îÁ©∂Ë≠∞Á®ãÔºå‰ª•ÊîØÊåÅÂú®Êü•Ê†∏‰∫ãÂØ¶‰∏≠Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî®ÁîüÊàêÂºè AI„ÄÇÂú®Êï¥ÂÄãÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü‰∫∫È°ûÂü∫Á§éÊû∂ÊßãÂíåÂãûÂãïÂäõÂú®Ëàá AI Âêà‰ΩúÁî¢ÁîüÂ∑≤È©óË≠âË≥áË®ä‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈ†êÊúüÈÄôÈ†ÖÂ∑•‰Ωú‰∏çÂÉÖÊúÉÁÇ∫Êü•Ê†∏‰∫ãÂØ¶ÁöÑÁßëÂ≠∏ÊñáÁçªÊèê‰æõË≥áË®äÔºåÈÇÑËÉΩÊúâÂä©Êñº‰∫ÜËß£ÁµÑÁπîÂ¶Ç‰ΩïÈÅ©ÊáâÂº∑Â§ß‰ΩÜ‰∏çÂèØÈù†ÁöÑÊñ∞ÊäÄË°ì„ÄÇ

##### **Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques**
2405.15882v1 by Mikayla Calitis

In this study, the reliability of identified risk factors associated with
osteoporosis is investigated using a new clustering-based method on electronic
medical records. This study proposes utilizing a new CLustering Iterations
Framework (CLIF) that includes an iterative clustering framework that can adapt
any of the following three components: clustering, feature selection, and
principal feature identification. The study proposes using Wasserstein distance
to identify principal features, borrowing concepts from the optimal transport
theory. The study also suggests using a combination of ANOVA and ablation tests
to select influential features from a data set. Some risk factors presented in
existing works are endorsed by our identified significant clusters, while the
reliability of some other risk factors is weakened.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Âà©Áî®ÈõªÂ≠êÁóÖÊ≠∑‰∏≠Âü∫ÊñºÊñ∞Áæ§ÈõÜÁöÑÊñπÊ≥ïÔºåÊé¢Ë®éÂ∑≤Ë≠òÂà•‰πãÈ™®Ë≥™ÁñèÈ¨ÜÁóáÁõ∏ÈóúÈ¢®Èö™Âõ†Â≠êÁöÑÂèØÈù†ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫Âà©Áî®Êñ∞ÁöÑÁæ§ÈõÜËø≠‰ª£Êû∂Êßã (CLIF)ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∏ÄÂÄãËø≠‰ª£Áæ§ÈõÜÊû∂ÊßãÔºåÂèØË™øÊï¥‰ª•‰∏ã‰∏âÈ†ÖÁµÑÊàêÔºöÁæ§ÈõÜ„ÄÅÁâπÂæµÈÅ∏ÊìáÂíå‰∏ªË¶ÅÁâπÂæµË≠òÂà•„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰ΩøÁî® Wasserstein Ë∑ùÈõ¢‰æÜË≠òÂà•‰∏ªË¶ÅÁâπÂæµÔºåÂÄüÁî®ÊúÄÂÑ™ÂÇ≥Ëº∏ÁêÜË´ñ‰∏≠ÁöÑÊ¶ÇÂøµ„ÄÇÊú¨Á†îÁ©∂ÈÇÑÂª∫Ë≠∞‰ΩøÁî® ANOVA ÂíåÊ∂àËûçÊ∏¨Ë©¶ÁöÑÁµÑÂêàÔºåÂæûË≥áÊñôÈõÜ‰∏≠ÈÅ∏ÊìáÊúâÂΩ±ÈüøÂäõÁöÑÁâπÂæµ„ÄÇÁèæÊúâÁ†îÁ©∂‰∏≠ÂëàÁèæÁöÑÊüê‰∫õÈ¢®Èö™Âõ†Â≠êÂèóÂà∞ÊàëÂÄëË≠òÂà•Âá∫ÁöÑÈ°ØËëóÁæ§ÈõÜÁöÑË™çÂèØÔºåËÄåÊüê‰∫õÂÖ∂‰ªñÈ¢®Èö™Âõ†Â≠êÁöÑÂèØÈù†ÊÄßÂâáË¢´ÂâäÂº±„ÄÇ

##### **Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development**
2405.15766v2 by Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal

The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,
enhancing patient safety by identifying potential risks associated with
medications, facilitating early detection of adverse events, and guiding
regulatory decision-making. Traditional ADE detection methods are reliable but
slow, not easily adaptable to large-scale operations, and offer limited
information. With the exponential increase in data sources like social media
content, biomedical literature, and Electronic Medical Records (EMR),
extracting relevant ADE-related information from these unstructured texts is
imperative. Previous ADE mining studies have focused on text-based
methodologies, overlooking visual cues, limiting contextual comprehension, and
hindering accurate interpretation. To address this gap, we present a MultiModal
Adverse Drug Event (MMADE) detection dataset, merging ADE-related textual
information with visual aids. Additionally, we introduce a framework that
leverages the capabilities of LLMs and VLMs for ADE detection by generating
detailed descriptions of medical images depicting ADEs, aiding healthcare
professionals in visually identifying adverse events. Using our MMADE dataset,
we showcase the significance of integrating visual cues from images to enhance
overall performance. This approach holds promise for patient safety, ADE
awareness, and healthcare accessibility, paving the way for further exploration
in personalized healthcare.

ÊëòË¶ÅÔºöËó•Áâ©Ë≠¶Êàí‰∏≠Ôºå‰∏çËâØËó•Áâ©‰∫ã‰ª∂ÔºàADEÔºâÁöÑÊåñÊéòËá≥ÈóúÈáçË¶ÅÔºå
ÈÄèÈÅéË≠òÂà•ËàáËó•Áâ©Áõ∏ÈóúÁöÑÊΩõÂú®È¢®Èö™Ôºå‰øÉÈÄ≤ÊÇ£ËÄÖÂÆâÂÖ®ÔºåÂçîÂä©ÊèêÊó©ÂÅµÊ∏¨‰∏çËâØ‰∫ã‰ª∂Ôºå‰∏¶ÂºïÂ∞éÊ≥ïË¶èÊ±∫Á≠ñ„ÄÇÂÇ≥Áµ±ÁöÑ ADE ÂÅµÊ∏¨ÊñπÊ≥ïÂèØÈù†Ôºå‰ΩÜÈÄüÂ∫¶ÊÖ¢Ôºå‰∏çÊòìÈÅ©ÊáâÂ§ßË¶èÊ®°‰ΩúÊ•≠Ôºå‰∏îÊèê‰æõÊúâÈôêÁöÑË≥áË®ä„ÄÇÈö®ËëóÁ§æÁæ§Â™íÈ´îÂÖßÂÆπ„ÄÅÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªÂíåÈõªÂ≠êÁóÖÊ≠∑ (EMR) Á≠âË≥áÊñô‰æÜÊ∫êÂëàÊåáÊï∏Á¥öÂ¢ûÂä†ÔºåÂæûÈÄô‰∫õÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ËêÉÂèñÁõ∏ÈóúÁöÑ ADE Áõ∏ÈóúË≥áË®äËá≥ÈóúÈáçË¶Å„ÄÇÂÖàÂâçÁöÑ ADE ÊåñÊéòÁ†îÁ©∂ËëóÈáçÊñºÂü∫ÊñºÊñáÂ≠óÁöÑÊñπÊ≥ïÔºåÂøΩÁï•‰∫ÜË¶ñË¶∫Á∑öÁ¥¢ÔºåÈôêÂà∂‰∫ÜËÑàÁµ°ÁêÜËß£Ôºå‰∏¶ÈòªÁ§ô‰∫ÜÊ∫ñÁ¢∫ÁöÑË©ÆÈáã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÊ®°Âºè‰∏çËâØËó•Áâ©‰∫ã‰ª∂ (MMADE) ÂÅµÊ∏¨Ë≥áÊñôÈõÜÔºåÂ∞á ADE Áõ∏ÈóúÁöÑÊñáÂ≠óË≥áË®äËàáË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑Âêà‰Ωµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂ∞éÂÖ•‰∫Ü‰∏ÄÂÄãÊû∂ÊßãÔºåÂà©Áî® LLM Âíå VLM ÁöÑÂäüËÉΩÈÄ≤Ë°å ADE ÂÅµÊ∏¨ÔºåÈÄèÈÅéÁî¢ÁîüÊèèÁπ™ ADE ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑË©≥Á¥∞ÊèèËø∞ÔºåÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°Ë¶ñË¶∫ÂåñË≠òÂà•‰∏çËâØ‰∫ã‰ª∂„ÄÇ‰ΩøÁî®ÊàëÂÄëÁöÑ MMADE Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊï¥ÂêàÂΩ±ÂÉèË¶ñË¶∫Á∑öÁ¥¢‰ª•Â¢ûÂº∑Êï¥È´îÊïàËÉΩÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊúâÊúõÊèêÂçáÊÇ£ËÄÖÂÆâÂÖ®„ÄÅADE ÊÑèË≠òÂíåÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂèØÂèäÊÄßÔºåÁÇ∫ÂÄã‰∫∫ÂåñÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Èã™Ë∑Ø„ÄÇ

##### **Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification**
2405.19363v1 by Yihe Wang, Nan Huang, Taida Li, Yujun Yan, Xiang Zhang

Medical time series data, such as Electroencephalography (EEG) and
Electrocardiography (ECG), play a crucial role in healthcare, such as
diagnosing brain and heart diseases. Existing methods for medical time series
classification primarily rely on handcrafted biomarkers extraction and
CNN-based models, with limited exploration of transformers tailored for medical
time series. In this paper, we introduce Medformer, a multi-granularity
patching transformer tailored specifically for medical time series
classification. Our method incorporates three novel mechanisms to leverage the
unique characteristics of medical time series: cross-channel patching to
leverage inter-channel correlations, multi-granularity embedding for capturing
features at different scales, and two-stage (intra- and inter-granularity)
multi-granularity self-attention for learning features and correlations within
and among granularities. We conduct extensive experiments on five public
datasets under both subject-dependent and challenging subject-independent
setups. Results demonstrate Medformer's superiority over 10 baselines,
achieving top averaged ranking across five datasets on all six evaluation
metrics. These findings underscore the significant impact of our method on
healthcare applications, such as diagnosing Myocardial Infarction, Alzheimer's,
and Parkinson's disease. We release the source code at
\url{https://github.com/DL4mHealth/Medformer}.

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºå‰æãÂ¶ÇËÖ¶ÈõªÂúñ (EEG) ÂíåÂøÉÈõªÂúñ (ECG)ÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰æãÂ¶ÇË®∫Êñ∑ËÖ¶ÈÉ®ÂíåÂøÉËáüÁñæÁóÖ„ÄÇÁèæÊúâÁöÑÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÊñºÊâãÂ∑•Ë£Ω‰ΩúÁöÑÁîüÁâ©Ê®ôË®òËêÉÂèñÂíåÂü∫Êñº CNN ÁöÑÊ®°ÂûãÔºåÂ∞çÊñºÂ∞àÈñÄÈáùÂ∞çÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÈáèË∫´ÊâìÈÄ†ÁöÑËΩâÊèõÂô®ÂâáÊé¢Á¥¢ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü MedformerÔºå‰∏ÄÂÄãÂ∞àÈñÄÈáùÂ∞çÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÈáèË∫´ÊâìÈÄ†ÁöÑÂ§öÁ≤íÂ∫¶Ë£ú‰∏ÅËΩâÊèõÂô®„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÁµêÂêà‰∫Ü‰∏âÁ®ÆÊñ∞Á©éÁöÑÊ©üÂà∂‰æÜÂà©Áî®ÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàóÁöÑÁç®ÁâπÁâπÂæµÔºöË∑®ÈÄöÈÅìË£ú‰∏Å‰ª•Âà©Áî®ÈÄöÈÅìÈñìÁõ∏ÈóúÊÄß„ÄÅÂ§öÁ≤íÂ∫¶ÂµåÂÖ•‰ª•Êì∑Âèñ‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæµÔºå‰ª•ÂèäÂÖ©ÈöéÊÆµÔºàÁ≤íÂ∫¶ÂÖßÂíåÁ≤íÂ∫¶ÈñìÔºâÂ§öÁ≤íÂ∫¶Ëá™ÊàëÊ≥®ÊÑèÔºå‰ª•Â≠∏ÁøíÁ≤íÂ∫¶ÂÖßÂíåÁ≤íÂ∫¶ÈñìÁöÑÁâπÂæµÂíåÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÂú®‰∫îÂÄãÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂåÖÊã¨‰æùË≥¥ÂèóË©¶ËÄÖÂíåÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁç®Á´ãÂèóË©¶ËÄÖË®≠ÂÆö„ÄÇÁµêÊûúÈ°ØÁ§∫ Medformer ÂÑ™Êñº 10 ÂÄãÂü∫Ê∫ñÔºåÂú®ÊâÄÊúâÂÖ≠ÂÄãË©ï‰º∞ÊåáÊ®ô‰∏äÔºåÂú®‰∫îÂÄãË≥áÊñôÈõÜ‰∏äÁç≤ÂæóÊúÄÈ´òÁöÑÂπ≥ÂùáÊéíÂêç„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞çÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Ôºà‰æãÂ¶ÇË®∫Êñ∑ÂøÉËÇåÊ¢óÂ°û„ÄÅÈòøËå≤Êµ∑ÈªòÁóáÂíåÂ∏ïÈáëÊ£ÆÊ∞èÁóáÔºâÁöÑÈáçÂ§ßÂΩ±Èüø„ÄÇÊàëÂÄëÂú® \url{https://github.com/DL4mHealth/Medformer} ÈáãÂá∫ÂéüÂßãÁ¢º„ÄÇ

##### **Effective Confidence Region Prediction Using Probability Forecasters**
2405.15642v1 by David Lindsay, Sian Lindsay

Confidence region prediction is a practically useful extension to the
commonly studied pattern recognition problem. Instead of predicting a single
label, the constraint is relaxed to allow prediction of a subset of labels
given a desired confidence level 1-delta. Ideally, effective region predictions
should be (1) well calibrated - predictive regions at confidence level 1-delta
should err with relative frequency at most delta and (2) be as narrow (or
certain) as possible. We present a simple technique to generate confidence
region predictions from conditional probability estimates (probability
forecasts). We use this 'conversion' technique to generate confidence region
predictions from probability forecasts output by standard machine learning
algorithms when tested on 15 multi-class datasets. Our results show that
approximately 44% of experiments demonstrate well-calibrated confidence region
predictions, with the K-Nearest Neighbour algorithm tending to perform
consistently well across all data. Our results illustrate the practical
benefits of effective confidence region prediction with respect to medical
diagnostics, where guarantees of capturing the true disease label can be given.

ÊëòË¶ÅÔºöÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨ÊòØÂ∞çÂ∏∏Ë¶ãÊ®°ÂºèË≠òÂà•ÂïèÈ°åÂØ¶Áî®ÁöÑÂª∂‰º∏„ÄÇÂÆÉ‰∏¶ÈùûÈ†êÊ∏¨ÂñÆ‰∏ÄÊ®ôÁ±§ÔºåËÄåÊòØÊîæÂØ¨ÈôêÂà∂ÔºåÂÖÅË®±È†êÊ∏¨Áµ¶ÂÆöÊâÄÈúÄÁΩÆ‰ø°Ê∞¥Ê∫ñ 1-delta ÁöÑÊ®ôÁ±§Â≠êÈõÜ„ÄÇÁêÜÊÉ≥ÊÉÖÊ≥Å‰∏ãÔºåÊúâÊïàÁöÑÂçÄÂüüÈ†êÊ∏¨ÊáâÁÇ∫Ôºö(1) Ê†°Ê∫ñËâØÂ•Ω - ÁΩÆ‰ø°Ê∞¥Ê∫ñÁÇ∫ 1-delta ÁöÑÈ†êÊ∏¨ÂçÄÂüüÊáâ‰ª•ÊúÄÂ§ö delta ÁöÑÁõ∏Â∞çÈ†ªÁéáÂá∫ÁèæË™§Â∑ÆÔºå‰∏î (2) Áõ°ÂèØËÉΩÁ™ÑÔºàÊàñÁ¢∫ÂÆöÔºâ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆÁöÑÊäÄË°ìÔºåÂæûÊ¢ù‰ª∂Ê©üÁéá‰º∞Ë®àÔºàÊ©üÁéáÈ†êÊ∏¨ÔºâÁî¢ÁîüÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠§„ÄåËΩâÊèõ„ÄçÊäÄË°ìÔºåÂæûÊ®ôÊ∫ñÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂú® 15 ÂÄãÂ§öÈ°ûÂà•Ë≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶ÊôÇËº∏Âá∫ÁöÑÊ©üÁéáÈ†êÊ∏¨Áî¢ÁîüÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁ¥ÑÊúâ 44% ÁöÑÂØ¶È©óÂ±ïÁ§∫Âá∫Ê†°Ê∫ñËâØÂ•ΩÁöÑÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨ÔºåËÄå K-ÊúÄËøëÈÑ∞ÊºîÁÆóÊ≥ïÂú®ÊâÄÊúâË≥áÊñô‰∏äÈÉΩÂÇæÂêëÊñºË°®ÁèæÁ©©ÂÆöËâØÂ•Ω„ÄÇÊàëÂÄëÁöÑÁµêÊûúË™™Êòé‰∫ÜÊúâÊïàÁΩÆ‰ø°ÂçÄÂüüÈ†êÊ∏¨Âú®ÈÜ´Â≠∏Ë®∫Êñ∑ÊñπÈù¢ÁöÑÂØ¶ÈöõÊïàÁõäÔºåÂÖ∂‰∏≠ÂèØ‰ª•‰øùË≠âÊçïÊçâÂà∞ÁúüÊ≠£ÁöÑÁñæÁóÖÊ®ôÁ±§„ÄÇ

##### **Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images**
2405.17483v1 by Rinat I. Dumaev, Sergei A. Molodyakov, Lev V. Utkin

To increase the transparency of modern computer-aided diagnosis (CAD) systems
for assessing the malignancy of lung nodules, an interpretable model based on
applying the generalized additive models and the concept-based learning is
proposed. The model detects a set of clinically significant attributes in
addition to the final malignancy regression score and learns the association
between the lung nodule attributes and a final diagnosis decision as well as
their contributions into the decision. The proposed concept-based learning
framework provides human-readable explanations in terms of different concepts
(numerical and categorical), their values, and their contribution to the final
prediction. Numerical experiments with the LIDC-IDRI dataset demonstrate that
the diagnosis results obtained using the proposed model, which explicitly
explores internal relationships, are in line with similar patterns observed in
clinical practice. Additionally, the proposed model shows the competitive
classification and the nodule attribute scoring performance, highlighting its
potential for effective decision-making in the lung nodule diagnosis.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊèêÂçáÁèæ‰ª£ÈõªËÖ¶ËºîÂä©Ë®∫Êñ∑ÔºàCADÔºâÁ≥ªÁµ±Â∞çËÇ∫ÁµêÁØÄÊÉ°ÊÄßÁ®ãÂ∫¶Ë©ï‰º∞ÁöÑÈÄèÊòéÂ∫¶ÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂª£Áæ©Âä†Ê≥ïÊ®°ÂûãÂíåÂü∫ÊñºÊ¶ÇÂøµÁöÑÂ≠∏ÁøíÁöÑÂèØËß£ÈáãÊ®°Âûã„ÄÇÊ≠§Ê®°ÂûãÈô§‰∫ÜÊúÄÁµÇÊÉ°ÊÄßÂõûÊ≠∏ÂàÜÊï∏Â§ñÔºåÈÇÑËÉΩÂÅµÊ∏¨‰∏ÄÁµÑËá®Â∫äÈ°ØËëóÂ±¨ÊÄßÔºå‰∏¶Â≠∏ÁøíËÇ∫ÁµêÁØÄÂ±¨ÊÄßËàáÊúÄÁµÇË®∫Êñ∑Ê±∫Á≠ñ‰πãÈñìÁöÑÈóúËÅØÔºå‰ª•ÂèäÂÆÉÂÄëÂ∞çÊ±∫Á≠ñÁöÑË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÊ¶ÇÂøµÁöÑÂ≠∏ÁøíÊû∂ÊßãÊèê‰æõ‰∫∫È°ûÂèØËÆÄÁöÑËß£ÈáãÔºåÂåÖÊã¨‰∏çÂêåÁöÑÊ¶ÇÂøµÔºàÊï∏ÂÄºÂíåÈ°ûÂà•Ôºâ„ÄÅÂÆÉÂÄëÁöÑÂÄºÔºå‰ª•ÂèäÂÆÉÂÄëÂ∞çÊúÄÁµÇÈ†êÊ∏¨ÁöÑË≤¢Áçª„ÄÇ‰ΩøÁî® LIDC-IDRI Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÊï∏ÂÄºÂØ¶È©óË≠âÊòéÔºå‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÁç≤ÂæóÁöÑË®∫Êñ∑ÁµêÊûúÊòéÁ¢∫Êé¢Á¥¢ÂÖßÈÉ®Èóú‰øÇÔºåËàáËá®Â∫äÂØ¶Âãô‰∏≠ËßÄÂØüÂà∞ÁöÑÈ°û‰ººÊ®°Âºè‰∏ÄËá¥„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÈ°ØÁ§∫Âá∫Á´∂Áà≠ÊÄßÁöÑÂàÜÈ°ûÂíåÁµêÁØÄÂ±¨ÊÄßË©ïÂàÜË°®ÁèæÔºåÁ™ÅÈ°ØÂÖ∂Âú®ËÇ∫ÁµêÁØÄË®∫Êñ∑‰∏≠ÈÄ≤Ë°åÊúâÊïàÊ±∫Á≠ñÁöÑÊΩõÂäõ„ÄÇ

##### **PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds**
2405.15398v1 by Yuandou Wang, Neel Kanwal, Kjersti Engan, Chunming Rong, Paola Grosso, Zhiming Zhao

Running deep neural networks for large medical images is a resource-hungry
and time-consuming task with centralized computing. Outsourcing such medical
image processing tasks to hybrid clouds has benefits, such as a significant
reduction of execution time and monetary cost. However, due to privacy
concerns, it is still challenging to process sensitive medical images over
clouds, which would hinder their deployment in many real-world applications. To
overcome this, we first formulate the overall optimization objectives of the
privacy-preserving distributed system model, i.e., minimizing the amount of
information about the private data learned by the adversaries throughout the
process, reducing the maximum execution time and cost under the user budget
constraint. We propose a novel privacy-preserving and cost-effective method
called PriCE to solve this multi-objective optimization problem. We performed
extensive simulation experiments for artifact detection tasks on medical images
using an ensemble of five deep convolutional neural network inferences as the
workflow task. Experimental results show that PriCE successfully splits a wide
range of input gigapixel medical images with graph-coloring-based strategies,
yielding desired output utility and lowering the privacy risk, makespan, and
monetary cost under user's budget.

ÊëòË¶ÅÔºöÂü∑Ë°åÂ§ßÂûãÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÊòØÈ†ÖË≥áÊ∫êÊ∂àËÄó‰∏îËÄóÊôÇÁöÑ‰ªªÂãôÔºåÈúÄË¶ÅÈõÜ‰∏≠ÂºèÈÅãÁÆó„ÄÇÂ∞áÊ≠§È°ûÈÜ´ÁôÇÂΩ±ÂÉèËôïÁêÜ‰ªªÂãôÂ§ñÂåÖÁµ¶Ê∑∑ÂêàÈõ≤Á´ØÂÖ∑ÊúâÂ•ΩËôïÔºå‰æãÂ¶ÇÂ§ßÂπÖÁ∏ÆÁü≠Âü∑Ë°åÊôÇÈñìÂíåÈáëÈå¢ÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈö±ÁßÅÂïèÈ°åÔºåÂú®Èõ≤Á´ØËôïÁêÜÊïèÊÑüÁöÑÈÜ´ÁôÇÂΩ±ÂÉè‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÈÄôÊúÉÈòªÁ§ôÂÆÉÂÄëÂú®Ë®±Â§öÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈ¶ñÂÖàÂà∂ÂÆö‰∫ÜÈö±ÁßÅ‰øùË≠∑ÂàÜÊï£ÂºèÁ≥ªÁµ±Ê®°ÂûãÁöÑÊï¥È´îÊúÄ‰Ω≥ÂåñÁõÆÊ®ôÔºåÂç≥ÊúÄÂ∞èÂåñÂ∞çÊâãÂú®Êï¥ÂÄãÈÅéÁ®ã‰∏≠ÊâÄÂæóÁü•ÁöÑÁßÅ‰∫∫Ë≥áÊñôË≥áË®äÈáèÔºåÂú®‰ΩøÁî®ËÄÖÈ†êÁÆóÈôêÂà∂‰∏ãÊ∏õÂ∞ëÊúÄÂ§ßÁöÑÂü∑Ë°åÊôÇÈñìÂíåÊàêÊú¨„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ PriCE ÁöÑÊñ∞ÂûãÈö±ÁßÅ‰øùË≠∑‰∏îÊàêÊú¨ÊïàÁõäÈ´òÁöÑÊñπÂºè‰æÜËß£Ê±∫ÈÄôÂÄãÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÂïèÈ°å„ÄÇÊàëÂÄëÂ∞çÈÜ´ÁôÇÂΩ±ÂÉè‰∏äÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÂÅµÊ∏¨‰ªªÂãôÂü∑Ë°åÂª£Ê≥õÁöÑÊ®°Êì¨ÂØ¶È©óÔºå‰ΩøÁî®‰∫îÂÄãÊ∑±Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊé®Ë´ñÁöÑÊï¥È´î‰ΩúÁÇ∫Â∑•‰ΩúÊµÅÁ®ã‰ªªÂãô„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåPriCE ÊàêÂäüÂú∞‰ΩøÁî®Âü∫ÊñºÂúñÂΩ¢ËëóËâ≤ÁöÑÁ≠ñÁï•‰æÜÂàÜÂâ≤ÂêÑÁ®ÆËº∏ÂÖ•ÁöÑÂçÉÂÖÜÁï´Á¥†ÈÜ´ÁôÇÂΩ±ÂÉèÔºåÁî¢ÁîüÊâÄÈúÄÁöÑËº∏Âá∫ÊïàÁî®‰∏¶Èôç‰ΩéÈö±ÁßÅÈ¢®Èö™„ÄÅÂü∑Ë°åÊôÇÈñìÂíåÂú®‰ΩøÁî®ËÄÖÈ†êÁÆó‰∏ãÁöÑÈáëÈå¢ÊàêÊú¨„ÄÇ

##### **Towards a Probabilistic Fusion Approach for Robust Battery Prognostics**
2405.15292v1 by Jokin Alcibar, Jose I. Aizpurua, Ekhi Zugasti

Batteries are a key enabling technology for the decarbonization of transport
and energy sectors. The safe and reliable operation of batteries is crucial for
battery-powered systems. In this direction, the development of accurate and
robust battery state-of-health prognostics models can unlock the potential of
autonomous systems for complex, remote and reliable operations. The combination
of Neural Networks, Bayesian modelling concepts and ensemble learning
strategies, form a valuable prognostics framework to combine uncertainty in a
robust and accurate manner. Accordingly, this paper introduces a Bayesian
ensemble learning approach to predict the capacity depletion of lithium-ion
batteries. The approach accurately predicts the capacity fade and quantifies
the uncertainty associated with battery design and degradation processes. The
proposed Bayesian ensemble methodology employs a stacking technique,
integrating multiple Bayesian neural networks (BNNs) as base learners, which
have been trained on data diversity. The proposed method has been validated
using a battery aging dataset collected by the NASA Ames Prognostics Center of
Excellence. Obtained results demonstrate the improved accuracy and robustness
of the proposed probabilistic fusion approach with respect to (i) a single BNN
model and (ii) a classical stacking strategy based on different BNNs.

ÊëòË¶ÅÔºöÈõªÊ±†ÊòØÈÅãËº∏ÂíåËÉΩÊ∫êÈÉ®ÈñÄËÑ´Á¢≥ÁöÑÈáçË¶Å‰ΩøËÉΩÊäÄË°ì„ÄÇÈõªÊ±†ÁöÑÂÆâÂÖ®ÊÄß„ÄÅÂèØÈù†ÊÄßÂ∞çÊñºÈõªÊ±†‰æõÈõªÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÂÄãÊñπÂêë‰∏äÔºåÊ∫ñÁ¢∫„ÄÅÁ©©ÂÅ•ÁöÑÈõªÊ±†ÂÅ•Â∫∑ÁãÄÊÖãÈ†êÊ∏¨Ê®°ÂûãÁöÑÈñãÁôºÔºåÂèØ‰ª•ÈáãÊîæËá™‰∏ªÁ≥ªÁµ±Âú®Ë§áÈõú„ÄÅÈÅ†Á®ãÂíåÂèØÈù†Êìç‰ΩúÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅË≤ùÊ∞èÂª∫Ê®°Ê¶ÇÂøµÂíåÈõÜÊàêÂ≠∏ÁøíÁ≠ñÁï•ÁöÑÁµêÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÈ†êÊ∏¨Ê°ÜÊû∂Ôºå‰ª•Á©©ÂÅ•„ÄÅÊ∫ñÁ¢∫ÁöÑÊñπÂºèÁµêÂêà‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂõ†Ê≠§ÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆË≤ùÊ∞èÈõÜÊàêÂ≠∏ÁøíÊñπÊ≥ï‰æÜÈ†êÊ∏¨Èã∞Èõ¢Â≠êÈõªÊ±†ÁöÑÂÆπÈáèË°∞Ê∏õ„ÄÇË©≤ÊñπÊ≥ïÊ∫ñÁ¢∫È†êÊ∏¨‰∫ÜÂÆπÈáèË°∞Ê∏õÔºå‰∏¶ÈáèÂåñ‰∫ÜËàáÈõªÊ±†Ë®≠Ë®àÂíåÈÄÄÂåñÈÅéÁ®ãÁõ∏ÈóúÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑË≤ùÊ∞èÈõÜÊàêÊñπÊ≥ïÊé°Áî®Â†ÜÁñäÊäÄË°ìÔºåÂ∞áÂ§öÂÄãË≤ùÊ∞èÁ•ûÁ∂ìÁ∂≤Ë∑Ø (BNN) ‰ΩúÁÇ∫Âü∫Á§éÂ≠∏ÁøíÂô®ÈÄ≤Ë°åÊï¥ÂêàÔºåÈÄô‰∫õÂü∫Á§éÂ≠∏ÁøíÂô®Â∑≤Á∂ìÈÅéË≥áÊñôÂ§öÊ®£ÊÄßÁöÑË®ìÁ∑¥„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∑≤Á∂ìÈÅé NASA Ames È†êÊ∏¨ÂçìË∂ä‰∏≠ÂøÉÁöÑÈõªÊ±†ËÄÅÂåñË≥áÊñôÈõÜÈ©óË≠â„ÄÇÁç≤ÂæóÁöÑÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ¶ÇÁéáËûçÂêàÊñπÊ≥ïÁõ∏Â∞çÊñº (i) ÂñÆÂÄã BNN Ê®°ÂûãÂíå (ii) Âü∫Êñº‰∏çÂêå BNN ÁöÑÁ∂ìÂÖ∏Â†ÜÁñäÁ≠ñÁï•ÔºåÊîπÈÄ≤‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Efficient Reinforcement Learning via Large Language Model-based Search**
2405.15194v1 by Siddhant Bhambri, Amrita Bhattacharjee, Huan Liu, Subbarao Kambhampati

Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward
domains, and the problem is pronounced if there are stochastic transitions. To
improve the sample efficiency, reward shaping is a well-studied approach to
introduce intrinsic rewards that can help the RL agent converge to an optimal
policy faster. However, designing a useful reward shaping function specific to
each problem is challenging, even for domain experts. They would either have to
rely on task-specific domain knowledge or provide an expert demonstration
independently for each task. Given, that Large Language Models (LLMs) have
rapidly gained prominence across a magnitude of natural language tasks, we aim
to answer the following question: Can we leverage LLMs to construct a reward
shaping function that can boost the sample efficiency of an RL agent? In this
work, we aim to leverage off-the-shelf LLMs to generate a guide policy by
solving a simpler deterministic abstraction of the original problem that can
then be used to construct the reward shaping function for the downstream RL
agent. Given the ineffectiveness of directly prompting LLMs, we propose MEDIC:
a framework that augments LLMs with a Model-based feEDback critIC, which
verifies LLM-generated outputs, to generate a possibly sub-optimal but valid
plan for the abstract problem. Our experiments across domains from the BabyAI
environment suite show 1) the effectiveness of augmenting LLMs with MEDIC, 2) a
significant improvement in the sample complexity of PPO and A2C-based RL agents
when guided by our LLM-generated plan, and finally, 3) pave the direction for
further explorations of how these models can be used to augment existing RL
pipelines.

ÊëòË¶ÅÔºö<paragraph>Âº∑ÂåñÂ≠∏Áøí (RL) Âú®Á®ÄÁñèÁçéÂãµÈ†òÂüü‰∏≠ÊúÉÈÅáÂà∞Ê®£Êú¨ÊïàÁéá‰Ωé‰∏ãÁöÑÂïèÈ°åÔºåËÄåÂ¶ÇÊûúÂ≠òÂú®Èö®Ê©üËΩâÊèõÔºåÂâáÂïèÈ°åÊúÉÊõ¥Âä†Âö¥Èáç„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÊ®£Êú¨ÊïàÁéáÔºåÁçéÂãµÊàêÂΩ¢ÊòØ‰∏ÄÁ®ÆÁ∂ìÈÅéÂÖÖÂàÜÁ†îÁ©∂ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂºïÂÖ•ÂÖßÂú®ÁçéÂãµÔºåÂèØ‰ª•Âπ´Âä© RL ‰ª£ÁêÜÊõ¥Âø´Âú∞Êî∂ÊñÇÂà∞ÊúÄ‰Ω≥Á≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÊØèÂÄãÂïèÈ°åË®≠Ë®à‰∏ÄÂÄãÊúâÁî®ÁöÑÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏ÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÂç≥‰ΩøÂ∞çÊñºÈ†òÂüüÂ∞àÂÆ∂ËÄåË®Ä‰πüÊòØÂ¶ÇÊ≠§„ÄÇ‰ªñÂÄëÂøÖÈ†à‰æùË≥¥ÁâπÂÆöÊñº‰ªªÂãôÁöÑÈ†òÂüüÁü•Ë≠òÔºåÊàñËÄÖÁÇ∫ÊØèÂÄã‰ªªÂãôÁç®Á´ãÊèê‰æõÂ∞àÂÆ∂Á§∫ÁØÑ„ÄÇÈëëÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ËøÖÈÄüÂú®Â§ßÈáèËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏≠Áç≤ÂæóÁ™ÅÂá∫Âú∞‰ΩçÔºåÊàëÂÄëÊó®Âú®ÂõûÁ≠î‰ª•‰∏ãÂïèÈ°åÔºöÊàëÂÄëËÉΩÂà©Áî® LLM ‰æÜÂª∫Êßã‰∏ÄÂÄãÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏ÔºåÂæûËÄåÊèêÂçá RL ‰ª£ÁêÜÁöÑÊ®£Êú¨ÊïàÁéáÂóéÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®Âà©Áî®ÁèæÊàêÁöÑ LLMÔºåÈÄèÈÅéËß£Ê±∫ÂéüÂßãÂïèÈ°åÁöÑ‰∏ÄÂÄãÊõ¥Á∞°ÂñÆÁöÑÁ¢∫ÂÆöÊÄßÊäΩË±°‰æÜÁî¢Áîü‰∏ÄÂÄãÂºïÂ∞éÁ≠ñÁï•ÔºåÁÑ∂ÂæåÂèØ‰ª•Áî®ÂÆÉ‰æÜÁÇ∫‰∏ãÊ∏∏ RL ‰ª£ÁêÜÂª∫ÊßãÁçéÂãµÊàêÂΩ¢ÂáΩÊï∏„ÄÇÈëëÊñºÁõ¥Êé•ÊèêÁ§∫ LLM ÁöÑÁÑ°ÊïàÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MEDICÔºö‰∏ÄÂÄã‰ΩøÁî®Âü∫ÊñºÊ®°ÂûãÁöÑÂõûÈ•ãÊâπË©ïÂô®‰æÜÊì¥ÂÖÖ LLM ÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊúÉÈ©óË≠â LLM Áî¢ÁîüÁöÑËº∏Âá∫Ôºå‰ª•Áî¢Áîü‰∏ÄÂÄãÂèØËÉΩÊ¨°ÊñºÊúÄ‰Ω≥‰ΩÜÊúâÊïàÁöÑÊäΩË±°ÂïèÈ°åË®àÁï´„ÄÇÊàëÂÄëÂú® BabyAI Áí∞Â¢ÉÂ•ó‰ª∂‰∏≠Ë∑®È†òÂüüÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ 1) ‰ΩøÁî® MEDIC Êì¥ÂÖÖ LLM ÁöÑÊúâÊïàÊÄßÔºå2) Âú®Áî±ÊàëÂÄëÁöÑ LLM Áî¢ÁîüÁöÑË®àÁï´ÂºïÂ∞é‰∏ãÔºåÂü∫Êñº PPO Âíå A2C ÁöÑ RL ‰ª£ÁêÜÁöÑÊ®£Êú¨Ë§áÈõúÂ∫¶ÊúâÈ°ØËëóÊîπÂñÑÔºåÊúÄÂæåÔºå3) ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Â¶Ç‰Ωï‰ΩøÁî®ÈÄô‰∫õÊ®°Âûã‰æÜÊì¥ÂÖÖÁèæÊúâÁöÑ RL ÁÆ°Á∑öÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis**
2405.17468v1 by Xishun Liao, Brian Yueshuai He, Qinhua Jiang, Chenchen Kuai, Jiaqi Ma

Human mobility significantly impacts various aspects of society, including
transportation, urban planning, and public health. The increasing availability
of diverse mobility data and advancements in deep learning have revolutionized
mobility modeling. Existing deep learning models, however, mainly study
spatio-temporal patterns using trajectories and often fall short in capturing
the underlying semantic interdependency among activities. Moreover, they are
also constrained by the data source. These two factors thereby limit their
realism and adaptability, respectively. Meanwhile, traditional activity-based
models (ABMs) in transportation modeling rely on rigid assumptions and are
costly and time-consuming to calibrate, making them difficult to adapt and
scale to new regions, especially those regions with limited amount of required
conventional travel data. To address these limitations, we develop a novel
generative deep learning approach for human mobility modeling and synthesis,
using ubiquitous and open-source data. Additionally, the model can be
fine-tuned with local data, enabling adaptable and accurate representations of
mobility patterns across different regions. The model is evaluated on a
nationwide dataset of the United States, where it demonstrates superior
performance in generating activity chains that closely follow ground truth
distributions. Further tests using state- or city-specific datasets from
California, Washington, and Mexico City confirm its transferability. This
innovative approach offers substantial potential to advance mobility modeling
research, especially in generating human activity chains as input for
downstream activity-based mobility simulation models and providing enhanced
tools for urban planners and policymakers.

ÊëòË¶ÅÔºö‰∫∫È°ûÊµÅÂãïÊÄßÈ°ØËëóÂΩ±ÈüøÁ§æÊúÉÁöÑÂêÑÂÄãÈù¢ÂêëÔºåÂåÖÊã¨‰∫§ÈÄö„ÄÅÈÉΩÂ∏ÇË¶èÂäÉÂíåÂÖ¨ÂÖ±Ë°õÁîü„ÄÇÂ§öÂÖÉÊµÅÂãïÊÄßË≥áÊñôÁöÑÊó•ÁõäÊôÆÂèäÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÄ≤Ê≠•ÔºåÂ∑≤Á∂ìÂæπÂ∫ïÊîπËÆä‰∫ÜÊµÅÂãïÊÄßÂª∫Ê®°„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏ªË¶Å‰ΩøÁî®ËªåË∑°Á†îÁ©∂ÊôÇÁ©∫Ê®°ÂºèÔºåËÄå‰∏îÁ∂ìÂ∏∏ÁÑ°Ê≥ïÊçïÊçâÊ¥ªÂãï‰πãÈñìÁöÑÂ∫ïÂ±§Ë™ûÁæ©Áõ∏‰∫í‰æùË≥¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÂÄë‰πüÂèóÂà∞Ë≥áÊñô‰æÜÊ∫êÁöÑÈôêÂà∂„ÄÇÈÄôÂÖ©ÂÄãÂõ†Á¥†ÂàÜÂà•ÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÁúüÂØ¶ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÂêåÊôÇÔºå‰∫§ÈÄöÂª∫Ê®°‰∏≠ÁöÑÂÇ≥Áµ±Âü∫ÊñºÊ¥ªÂãïÁöÑÊ®°Âûã (ABM) ‰æùË≥¥ÊñºÂÉµÂåñÁöÑÂÅáË®≠ÔºåËÄå‰∏îÊ†°Ê∫ñËµ∑‰æÜÊó¢ÊòÇË≤¥ÂèàË≤ªÊôÇÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÈõ£‰ª•ÈÅ©ÊáâÂíåÊì¥Â±ïÂà∞Êñ∞ÁöÑÂçÄÂüüÔºåÁâπÂà•ÊòØÈÇ£‰∫õÁº∫‰πèÊâÄÈúÄÂÇ≥Áµ±Ë°åÁ®ãË≥áÊñôÁöÑÂçÄÂüü„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁîüÊàêÂºèÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁî®Êñº‰∫∫È°ûÊµÅÂãïÊÄßÂª∫Ê®°ÂíåÂêàÊàêÔºå‰∏¶‰ΩøÁî®ÊôÆÈÅç‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑË≥áÊñô„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãÂèØ‰ª•Ê†πÊìöÁï∂Âú∞Ë≥áÊñôÈÄ≤Ë°åÂæÆË™øÔºåÂæûËÄåËÉΩÂ§†ÈÅ©Êáâ‰∏¶Ê∫ñÁ¢∫Âú∞Ë°®Á§∫‰∏çÂêåÂçÄÂüüÁöÑÊµÅÂãïÊÄßÊ®°Âºè„ÄÇË©≤Ê®°ÂûãÂú®ÁæéÂúãÂÖ®ÂúãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜË©ï‰º∞ÔºåÁµêÊûúÈ°ØÁ§∫Âá∫Âú®ÁîüÊàêËàáÂØ¶ÈöõÊÉÖÊ≥ÅÂàÜ‰ΩàÁ∑äÂØÜÁõ∏ÈóúÁöÑÊ¥ªÂãïÈèàÊñπÈù¢ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ‰ΩøÁî®‰æÜËá™Âä†Â∑û„ÄÅËèØÁõõÈ†ìÂ∑ûÂíåÂ¢®Ë•øÂì•ÂüéÁöÑÂ∑ûÊàñÂüéÂ∏ÇÁâπÂÆöË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÈÄ≤‰∏ÄÊ≠•Ê∏¨Ë©¶ÔºåË≠âÂØ¶‰∫ÜÂÆÉÁöÑÂèØËΩâÁßªÊÄß„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÊèê‰æõ‰∫ÜÊé®ÈÄ≤ÊµÅÂãïÊÄßÂª∫Ê®°Á†îÁ©∂ÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®ÁîüÊàê‰∫∫È°ûÊ¥ªÂãïÈèà‰ΩúÁÇ∫‰∏ãÊ∏∏Âü∫ÊñºÊ¥ªÂãïÁöÑÊµÅÂãïÊÄßÊ®°Êì¨Ê®°ÂûãÁöÑËº∏ÂÖ•Ôºå‰ª•ÂèäÁÇ∫ÈÉΩÂ∏ÇË¶èÂäÉËÄÖÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÊèê‰æõÂ¢ûÂº∑Â∑•ÂÖ∑ÊñπÈù¢„ÄÇ

##### **Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**
2405.14868v1 by Basile Van Hoorick, Rundi Wu, Ege Ozguroglu, Kyle Sargent, Ruoshi Liu, Pavel Tokmakov, Achal Dave, Changxi Zheng, Carl Vondrick

Accurate reconstruction of complex dynamic scenes from just a single
viewpoint continues to be a challenging task in computer vision. Current
dynamic novel view synthesis methods typically require videos from many
different camera viewpoints, necessitating careful recording setups, and
significantly restricting their utility in the wild as well as in terms of
embodied AI applications. In this paper, we propose $\textbf{GCD}$, a
controllable monocular dynamic view synthesis pipeline that leverages
large-scale diffusion priors to, given a video of any scene, generate a
synchronous video from any other chosen perspective, conditioned on a set of
relative camera pose parameters. Our model does not require depth as input, and
does not explicitly model 3D scene geometry, instead performing end-to-end
video-to-video translation in order to achieve its goal efficiently. Despite
being trained on synthetic multi-view video data only, zero-shot real-world
generalization experiments show promising results in multiple domains,
including robotics, object permanence, and driving environments. We believe our
framework can potentially unlock powerful applications in rich dynamic scene
understanding, perception for robotics, and interactive 3D video viewing
experiences for virtual reality.

ÊëòË¶ÅÔºöÂÉÖÂæûÂñÆ‰∏ÄË¶ñÈªûÊ∫ñÁ¢∫ÈáçÂª∫Ë§áÈõúÁöÑÂãïÊÖãÂ†¥ÊôØÔºåÂú®ÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÊåÅÁ∫åÊàêÁÇ∫‰∏ÄÈ†ÖËâ±Èõ£ÁöÑ‰ªªÂãô„ÄÇÁõÆÂâçÁöÑÂãïÊÖãÊñ∞Ë¶ñÂúñÂêàÊàêÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶Å‰æÜËá™Ë®±Â§ö‰∏çÂêåÁõ∏Ê©üË¶ñÈªûÁöÑÂΩ±ÁâáÔºåÈÄôÈúÄË¶Å‰ªîÁ¥∞ÁöÑÈåÑË£ΩË®≠ÂÆöÔºå‰∏¶È°ØËëóÈôêÂà∂ÂÆÉÂÄëÂú®ÈáéÂ§ñ‰ª•ÂèäÂÖ∑Ë∫´ AI ÊáâÁî®ÊñπÈù¢ÁöÑÊïàÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ $\textbf{GCD}$Ôºå‰∏ÄÁ®ÆÂèØÊéßÁöÑÂñÆÁúºÂãïÊÖãË¶ñÂúñÂêàÊàêÁÆ°ÈÅìÔºåÂÆÉÂà©Áî®Â§ßË¶èÊ®°Êì¥Êï£ÂÖàÈ©óÔºåÂú®Áµ¶ÂÆö‰ªª‰ΩïÂ†¥ÊôØÂΩ±ÁâáÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ†πÊìö‰∏ÄÁµÑÁõ∏Â∞çÁõ∏Ê©üÂßøÂã¢ÂèÉÊï∏ÁîüÊàê‰æÜËá™‰ªª‰ΩïÂÖ∂‰ªñÈÅ∏ÊìáË¶ñËßíÁöÑÂêåÊ≠•ÂΩ±Áâá„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÈúÄË¶ÅÊ∑±Â∫¶‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰πü‰∏çÊòéÁ¢∫Âª∫Ê®° 3D Â†¥ÊôØÂπæ‰ΩïÔºåËÄåÊòØÂü∑Ë°åÁ´ØÂ∞çÁ´ØÁöÑÂΩ±ÁâáÂà∞ÂΩ±ÁâáËΩâÊèõÔºå‰ª•ÊúâÊïàÈÅîÊàêÂÖ∂ÁõÆÊ®ô„ÄÇÂÑòÁÆ°ÂÉÖÂú®ÂêàÊàêÂ§öË¶ñÂúñÂΩ±ÁâáË≥áÊñô‰∏äË®ìÁ∑¥Ôºå‰ΩÜÈõ∂Ê¨°Â≠∏ÁøíÁúüÂØ¶‰∏ñÁïåÊ¶ÇÂåñÂØ¶È©óÂú®Â§öÂÄãÈ†òÂüüÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂåÖÊã¨Ê©üÂô®‰∫∫ÊäÄË°ì„ÄÅÁâ©È´îÊÅÜÂ∏∏ÊÄßÂíåÈßïÈßõÁí∞Â¢É„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÊû∂ÊßãÊúâÂèØËÉΩÂú®Ë±êÂØåÁöÑÂãïÊÖãÂ†¥ÊôØÁêÜËß£„ÄÅÊ©üÂô®‰∫∫ÊÑüÁü•‰ª•ÂèäËôõÊì¨ÂØ¶Â¢É‰∫íÂãïÂºè 3D ÂΩ±ÁâáËßÄÁúãÈ´îÈ©ó‰∏≠ÈñãÂïüÂº∑Â§ßÁöÑÊáâÁî®Á®ãÂºè„ÄÇ

##### **A Declarative System for Optimizing AI Workloads**
2405.14696v2 by Chunwei Liu, Matthew Russo, Michael Cafarella, Lei Cao, Peter Baille Chen, Zui Chen, Michael Franklin, Tim Kraska, Samuel Madden, Gerardo Vitagliano

A long-standing goal of data management systems has been to build systems
which can compute quantitative insights over large corpora of unstructured data
in a cost-effective manner. Until recently, it was difficult and expensive to
extract facts from company documents, data from scientific papers, or metrics
from image and video corpora. Today's models can accomplish these tasks with
high accuracy. However, a programmer who wants to answer a substantive
AI-powered query must orchestrate large numbers of models, prompts, and data
operations. For even a single query, the programmer has to make a vast number
of decisions such as the choice of model, the right inference method, the most
cost-effective inference hardware, the ideal prompt design, and so on. The
optimal set of decisions can change as the query changes and as the
rapidly-evolving technical landscape shifts. In this paper we present
Palimpzest, a system that enables anyone to process AI-powered analytical
queries simply by defining them in a declarative language. The system uses its
cost optimization framework to implement the query plan with the best
trade-offs between runtime, financial cost, and output data quality. We
describe the workload of AI-powered analytics tasks, the optimization methods
that Palimpzest uses, and the prototype system itself. We evaluate Palimpzest
on tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching.
We show that even our simple prototype offers a range of appealing plans,
including one that is 3.3x faster and 2.9x cheaper than the baseline method,
while also offering better data quality. With parallelism enabled, Palimpzest
can produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a
single-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the
baseline. These require no additional work by the user.

ÊëòË¶ÅÔºöÈï∑Êúü‰ª•‰æÜÔºåË≥áÊñôÁÆ°ÁêÜÁ≥ªÁµ±ÁöÑÁõÆÊ®ô‰∏ÄÁõ¥ÊòØÂª∫Á´ãÁ≥ªÁµ±ÔºåËÉΩÂ§†‰ª•Á∂ìÊøüÊúâÊïàÁöÑÊñπÂºèË®àÁÆóÂ§ßÈáèÈùûÁµêÊßãÂåñË≥áÊñôÁöÑÈáèÂåñË¶ãËß£„ÄÇÁõ¥Âà∞ÊúÄËøëÔºåÂæûÂÖ¨Âè∏Êñá‰ª∂„ÄÅÁßëÂ≠∏Ë´ñÊñá‰∏≠ÊèêÂèñ‰∫ãÂØ¶ÔºåÊàñÂæûÂΩ±ÂÉèÂíåÂΩ±ÁâáË≥áÊñô‰∏≠ÊèêÂèñÊåáÊ®ôÔºå‰ªçÁÑ∂Âõ∞Èõ£‰∏îÊòÇË≤¥„ÄÇÁèæ‰ªäÁöÑÊ®°ÂûãÂèØ‰ª•È´òÊ∫ñÁ¢∫Â∫¶ÂÆåÊàêÈÄô‰∫õ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÊÉ≥Ë¶ÅÂõûÁ≠îÂØ¶Ë≥™ÊÄß AI È©ÖÂãïÊü•Ë©¢ÁöÑÁ®ãÂºèË®≠Ë®àÂ∏´ÔºåÂøÖÈ†àÂçîË™øÂ§ßÈáèÁöÑÊ®°Âûã„ÄÅÊèêÁ§∫ÂíåË≥áÊñôÊìç‰Ωú„ÄÇÂç≥‰ΩøÂè™ÊòØ‰∏ÄÂÄãÂñÆ‰∏ÄÁöÑÊü•Ë©¢ÔºåÁ®ãÂºèË®≠Ë®àÂ∏´ÈÉΩÂøÖÈ†àÂÅöÂá∫Â§ßÈáèÁöÑÊ±∫Á≠ñÔºå‰æãÂ¶ÇÊ®°ÂûãÁöÑÈÅ∏Êìá„ÄÅÊ≠£Á¢∫ÁöÑÊé®Ë´ñÊñπÊ≥ï„ÄÅÊúÄÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊé®Ë´ñÁ°¨È´î„ÄÅÁêÜÊÉ≥ÁöÑÊèêÁ§∫Ë®≠Ë®àÔºåÁ≠âÁ≠â„ÄÇÊúÄ‰Ω≥Ê±∫Á≠ñÁµÑÂêàÊúÉÈö®ËëóÊü•Ë©¢ÁöÑÊîπËÆäÂíåÂø´ÈÄüËÆäÂåñÁöÑÊäÄË°ìÁí∞Â¢ÉËÄåÊîπËÆä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PalimpzestÔºå‰∏ÄÂÄãÁ≥ªÁµ±ÔºåËÆì‰ªª‰Ωï‰∫∫ÈÉΩËÉΩÈÄèÈÅéÂú®ÂÆ£ÂëäÂºèË™ûË®Ä‰∏≠ÂÆöÁæ© AI È©ÖÂãïÂàÜÊûêÊü•Ë©¢Ôºå‰æÜËôïÁêÜÈÄô‰∫õÊü•Ë©¢„ÄÇÁ≥ªÁµ±‰ΩøÁî®ÂÖ∂ÊàêÊú¨ÊúÄ‰Ω≥ÂåñÊû∂ÊßãÔºå‰ª•ÊúÄ‰Ω≥ÁöÑÂü∑Ë°åÊôÇÈñì„ÄÅË≤°ÂãôÊàêÊú¨ÂíåËº∏Âá∫Ë≥áÊñôÂìÅË≥™ÊäòË°∑Ôºå‰æÜÂØ¶‰ΩúÊü•Ë©¢Ë®àÁï´„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü AI È©ÖÂãïÂàÜÊûê‰ªªÂãôÁöÑÂ∑•‰ΩúË≤†Ëºâ„ÄÅPalimpzest ‰ΩøÁî®ÁöÑÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºå‰ª•ÂèäÂéüÂûãÁ≥ªÁµ±Êú¨Ë∫´„ÄÇÊàëÂÄëÂú®Ê≥ïÂæãÁôºÁèæ„ÄÅÊàøÂú∞Áî¢ÊêúÂ∞ãÂíåÈÜ´ÁôÇÊû∂ÊßãÊØîÂ∞çÁöÑ‰ªªÂãô‰∏≠Ë©ï‰º∞ Palimpzest„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂç≥‰ΩøÊòØÊàëÂÄëÁöÑÁ∞°ÂñÆÂéüÂûã‰πüËÉΩÊèê‰æõ‰∏ÄÁ≥ªÂàóÊúâÂê∏ÂºïÂäõÁöÑË®àÁï´ÔºåÂåÖÊã¨‰∏ÄÂÄãÊØîÂü∫Ê∫ñÊñπÊ≥ïÂø´ 3.3 ÂÄç„ÄÅ‰æøÂÆú 2.9 ÂÄçÁöÑË®àÁï´ÔºåÂêåÊôÇÈÇÑËÉΩÊèê‰æõÊõ¥Â•ΩÁöÑË≥áÊñôÂìÅË≥™„ÄÇÂú®ÂïüÁî®Âπ≥Ë°åËôïÁêÜÁöÑÊÉÖÊ≥Å‰∏ãÔºåPalimpzest ÂèØ‰ª•Áî¢ÁîüÈÄüÂ∫¶ÊèêÂçáÈÅî 90.3 ÂÄç„ÄÅÊàêÊú¨Èôç‰Ωé 9.1 ÂÄçÁöÑË®àÁï´ÔºåÁõ∏ËºÉÊñºÂñÆÂü∑Ë°åÁ∑í GPT-4 Âü∫Ê∫ñÔºåÂêåÊôÇÁç≤Âæó F1 ÂàÜÊï∏Âú®Âü∫Ê∫ñÁöÑ 83.5% ‰ª•ÂÖß„ÄÇÈÄô‰∫õÈÉΩ‰∏çÈúÄË¶Å‰ΩøÁî®ËÄÖÈ°çÂ§ñÁöÑ‰ΩúÊ•≠„ÄÇ

##### **Efficient Medical Question Answering with Knowledge-Augmented Question Generation**
2405.14654v1 by Julien Khlaut, Corentin Dancette, Elodie Ferreres, Alaedine Bennani, Paul H√©rent, Pierre Manceron

In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.

ÊëòË¶ÅÔºöÂú®Ë™ûË®ÄÊ®°ÂûãÊáâÁî®‰∏çÊñ∑Êì¥Â±ïÁöÑÈ†òÂüü‰∏≠ÔºåÁî±ÊñºË©≤È†òÂüüÁöÑÂ∞àÊ•≠ÊÄßË≥™ÔºåÈÜ´Â≠∏Áü•Ë≠òË°®Á§∫‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶Ç GPT-4ÔºåÂú®ÈÜ´Â≠∏ÂïèÈ°åËß£Á≠î‰ªªÂãô‰∏≠Áç≤Âæó‰∫ÜÂêàÁêÜÁöÑË©ïÂàÜÔºå‰ΩÜËºÉÂ∞èÁöÑÊ®°ÂûãÂçªÈÅ†ÈÅ†ËêΩÂæå„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÈÄöÈÅéÊé°Áî®ÈõôÈáçÊñπÊ≥ï‰æÜÊèêÈ´òÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÜ´Â≠∏È†òÂüüÁöÑÁÜüÁ∑¥Â∫¶„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®ÈÜ´Â≠∏ÊïôÁßëÊõ∏Ë™ûÊñôÂ∫´‰∏≠Â∞çÊ®°ÂûãÈÄ≤Ë°åÂæÆË™ø„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® GPT-4 ÁîüÊàêËàá‰∏ãÊ∏∏‰ªªÂãôÁõ∏‰ººÁöÑÂïèÈ°åÔºå‰∏¶ÊèêÁ§∫ÊïôÁßëÊõ∏Áü•Ë≠òÔºå‰∏¶‰ΩøÁî®ÂÆÉÂÄëÂ∞çÊ®°ÂûãÈÄ≤Ë°åÂæÆË™ø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü ECN-QAÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÜ´Â≠∏ÂïèÈ°åËß£Á≠îÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Áî±Áõ∏ÈóúÈ†ÜÂ∫èÂïèÈ°åÁµÑÊàêÁöÑ„ÄåÊº∏ÈÄ≤ÂºèÂïèÈ°å„Äç„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑË®ìÁ∑¥Á≠ñÁï•Âú®ÈÄôÂÄãÊï∏ÊìöÈõÜ‰∏äÁöÑÂ•ΩËôï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÁôºÁèæÁ™ÅÂá∫‰∫ÜÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÅ©Áï∂ÂæÆË™øÂæåÂú®ÈÜ´Â≠∏È†òÂüüÁöÑÊΩõÂäõ„ÄÇ‰ª£Á¢ºÂíåÊ¨äÈáçÂèØÂú® https://github.com/raidium-med/MQG Áç≤Âæó„ÄÇ

##### **Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**
2405.14563v1 by Loris Giulivi, Giacomo Boracchi

Advances in multi-modal embeddings, and in particular CLIP, have recently
driven several breakthroughs in Computer Vision (CV). CLIP has shown impressive
performance on a variety of tasks, yet, its inherently opaque architecture may
hinder the application of models employing CLIP as backbone, especially in
fields where trust and model explainability are imperative, such as in the
medical domain. Current explanation methodologies for CV models rely on
Saliency Maps computed through gradient analysis or input perturbation.
However, these Saliency Maps can only be computed to explain classes relevant
to the end task, often smaller in scope than the backbone training classes. In
the context of models implementing CLIP as their vision backbone, a substantial
portion of the information embedded within the learned representations is thus
left unexplained.
  In this work, we propose Concept Visualization (ConVis), a novel saliency
methodology that explains the CLIP embedding of an image by exploiting the
multi-modal nature of the embeddings. ConVis makes use of lexical information
from WordNet to compute task-agnostic Saliency Maps for any concept, not
limited to concepts the end model was trained on. We validate our use of
WordNet via an out of distribution detection experiment, and test ConVis on an
object localization benchmark, showing that Concept Visualizations correctly
identify and localize the image's semantic content. Additionally, we perform a
user study demonstrating that our methodology can give users insight on the
model's functioning.

ÊëòË¶ÅÔºö<paragraph>Â§öÊ®°ÊÖãÂµåÂÖ•ÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØ CLIPÔºåÊúÄËøëÊé®Âãï‰∫ÜÈõªËÖ¶Ë¶ñË¶∫ (CV) ÁöÑÂ§öÈ†ÖÁ™ÅÁ†¥„ÄÇCLIP Â∑≤Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩÔºåÁÑ∂ËÄåÔºåÂÖ∂Êú¨Ë≥™‰∏ä‰∏çÈÄèÊòéÁöÑÊû∂ÊßãÂèØËÉΩÊúÉÈòªÁ§ôÊé°Áî®‰ª• CLIP ÁÇ∫Âü∫Á§éÊû∂ÊßãÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶Å‰ø°‰ªªÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÈ†òÂüüÔºå‰æãÂ¶ÇÈÜ´ÁôÇÈ†òÂüü„ÄÇÁõÆÂâçÈáùÂ∞ç CV Ê®°ÂûãÁöÑËß£ÈáãÊñπÊ≥ï‰æùË≥¥ÊñºÈÄèÈÅéÊ¢ØÂ∫¶ÂàÜÊûêÊàñËº∏ÂÖ•ÊìæÂãïË®àÁÆóÂá∫ÁöÑÈ°ØËëóÊÄßÂúñ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈ°ØËëóÊÄßÂúñÂè™ËÉΩË®àÁÆóÂá∫ËàáÊúÄÁµÇ‰ªªÂãôÁõ∏ÈóúÁöÑÈ°ûÂà•ÔºåÂÖ∂ÁØÑÂúçÈÄöÂ∏∏Â∞èÊñºÂü∫Á§éÊû∂ÊßãË®ìÁ∑¥È°ûÂà•„ÄÇÂú®Â∞á CLIP ‰ΩúÁÇ∫ÂÖ∂Ë¶ñË¶∫Âü∫Á§éÊû∂ÊßãÂØ¶‰ΩúÁöÑÊ®°Âûã‰∏≠ÔºåÂ≠∏ÁøíË°®Âæµ‰∏≠ÂµåÂÖ•ÁöÑÂ§ßÈÉ®ÂàÜË≥áË®äÂõ†Ê≠§ÁÑ°Ê≥ïËß£Èáã„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Ê¶ÇÂøµË¶ñË¶∫Âåñ (ConVis)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈ°ØËëóÊÄßÊñπÊ≥ïÔºåÈÄèÈÅéÂà©Áî®ÂµåÂÖ•ÁöÑÂ§öÊ®°ÊÖãÁâπÊÄß‰æÜËß£ÈáãÂΩ±ÂÉèÁöÑ CLIP ÂµåÂÖ•„ÄÇConVis Âà©Áî® WordNet ‰∏≠ÁöÑË©ûÂΩôË≥áË®äÔºåÁÇ∫‰ªª‰ΩïÊ¶ÇÂøµË®àÁÆóËàá‰ªªÂãôÁÑ°ÈóúÁöÑÈ°ØËëóÊÄßÂúñÔºåËÄå‰∏çÈôêÊñºÊúÄÁµÇÊ®°ÂûãË®ìÁ∑¥ÁöÑÈÇ£‰∫õÊ¶ÇÂøµ„ÄÇÊàëÂÄëÈÄèÈÅé‰∏ÄÂÄãÂàÜ‰ΩàÊ™¢Ê∏¨ÂØ¶È©óÈ©óË≠âÊàëÂÄë‰ΩøÁî® WordNet ÁöÑÊñπÂºèÔºå‰∏¶Âú®‰∏ÄÂÄãÁâ©‰ª∂ÂÆö‰ΩçÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ê∏¨Ë©¶ ConVisÔºåÈ°ØÁ§∫Ê¶ÇÂøµË¶ñË¶∫ÂåñÂèØ‰ª•Ê≠£Á¢∫Ë≠òÂà•ÂíåÂÆö‰ΩçÂΩ±ÂÉèÁöÑË™ûÁæ©ÂÖßÂÆπ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†Ö‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåË≠âÊòéÊàëÂÄëÁöÑÊñπÊ≥ïÂèØ‰ª•ËÆì‰ΩøÁî®ËÄÖÊ∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÁöÑÂäüËÉΩ„ÄÇ</paragraph>

##### **Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**
2405.14445v1 by Lena Schmidt, Kaitlyn Hair, Sergio Graziozi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas

This paper describes a rapid feasibility study of using GPT-4, a large
language model (LLM), to (semi)automate data extraction in systematic reviews.
Despite the recent surge of interest in LLMs there is still a lack of
understanding of how to design LLM-based automation tools and how to robustly
evaluate their performance. During the 2023 Evidence Synthesis Hackathon we
conducted two feasibility studies. Firstly, to automatically extract study
characteristics from human clinical, animal, and social science domain studies.
We used two studies from each category for prompt-development; and ten for
evaluation. Secondly, we used the LLM to predict Participants, Interventions,
Controls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP
dataset. Overall, results indicated an accuracy of around 80%, with some
variability between domains (82% for human clinical, 80% for animal, and 72%
for studies of human social sciences). Causal inference methods and study
design were the data extraction items with the most errors. In the PICO study,
participants and intervention/control showed high accuracy (>80%), outcomes
were more challenging. Evaluation was done manually; scoring methods such as
BLEU and ROUGE showed limited value. We observed variability in the LLMs
predictions and changes in response quality. This paper presents a template for
future evaluations of LLMs in the context of data extraction for systematic
review automation. Our results show that there might be value in using LLMs,
for example as second or third reviewers. However, caution is advised when
integrating models such as GPT-4 into tools. Further research on stability and
reliability in practical settings is warranted for each type of data that is
processed by the LLM.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèèËø∞‰∫Ü‰∏ÄÂÄã‰ΩøÁî® GPT-4Ôºà‰∏ÄÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåLLMÔºâ‰æÜÔºàÂçäÔºâËá™ÂãïÂåñÁ≥ªÁµ±ÂåñÂõûÈ°ß‰∏≠Ë≥áÊñôËêÉÂèñÁöÑÂø´ÈÄüÂèØË°åÊÄßÁ†îÁ©∂„ÄÇÂÑòÁÆ°ÊúÄËøëÂ∞ç LLM ÁöÑËààË∂£ÊøÄÂ¢ûÔºå‰ΩÜÂ∞çÊñºÂ¶Ç‰ΩïË®≠Ë®àÂü∫Êñº LLM ÁöÑËá™ÂãïÂåñÂ∑•ÂÖ∑‰ª•ÂèäÂ¶Ç‰ΩïÁ©©ÂÅ•Âú∞Ë©ï‰º∞ÂÖ∂ÊïàËÉΩÔºå‰ªçÁÑ∂Áº∫‰πè‰∫ÜËß£„ÄÇÂú® 2023 Âπ¥Ë≠âÊìöÁ∂úÂêàÈªëÂÆ¢ÊùæÊúüÈñìÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ©È†ÖÂèØË°åÊÄßÁ†îÁ©∂„ÄÇÈ¶ñÂÖàÔºåËá™ÂãïÂæû‰∫∫È°ûËá®Â∫ä„ÄÅÂãïÁâ©ÂíåÁ§æÊúÉÁßëÂ≠∏È†òÂüüÁ†îÁ©∂‰∏≠ËêÉÂèñÁ†îÁ©∂ÁâπÂæµ„ÄÇÊàëÂÄë‰ΩøÁî®ÊØèÂÄãÈ°ûÂà•‰∏≠ÁöÑÂÖ©È†ÖÁ†îÁ©∂ÈÄ≤Ë°åÊèêÁ§∫ÈñãÁôºÔºõ‰∏¶‰ΩøÁî®ÂçÅÈ†ÖÈÄ≤Ë°åË©ï‰º∞„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄë‰ΩøÁî® LLM ‰æÜÈ†êÊ∏¨ EBM-NLP Ë≥áÊñôÈõÜ‰∏≠ÁöÑ 100 ÁØáÊëòË¶Å‰∏≠Ê®ôË®òÁöÑÂèÉËàáËÄÖ„ÄÅÂπ≤È†êÊé™ÊñΩ„ÄÅÂ∞çÁÖßÂíåÁµêÊûúÔºàPICOsÔºâ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÁµêÊûúÈ°ØÁ§∫Ê∫ñÁ¢∫Â∫¶Á¥ÑÁÇ∫ 80%Ôºå‰∏çÂêåÈ†òÂüü‰πãÈñìÂ≠òÂú®‰∏Ä‰∫õÂ∑ÆÁï∞Ôºà‰∫∫È°ûËá®Â∫äÁÇ∫ 82%ÔºåÂãïÁâ©ÁÇ∫ 80%Ôºå‰∫∫È°ûÁ§æÊúÉÁßëÂ≠∏Á†îÁ©∂ÁÇ∫ 72%Ôºâ„ÄÇÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÂíåÁ†îÁ©∂Ë®≠Ë®àÊòØË≥áÊñôËêÉÂèñÈ†ÖÁõÆ‰∏≠ÈåØË™§ÊúÄÂ§öÁöÑ„ÄÇÂú® PICO Á†îÁ©∂‰∏≠ÔºåÂèÉËàáËÄÖÂíåÂπ≤È†ê/Â∞çÁÖßÈ°ØÁ§∫Âá∫È´òÊ∫ñÁ¢∫Â∫¶Ôºà>80%ÔºâÔºåÁµêÊûúÊõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇË©ï‰º∞ÊòØÊâãÂãïÂÆåÊàêÁöÑÔºõBLEU Âíå ROUGE Á≠âË®àÂàÜÊñπÊ≥ïÈ°ØÁ§∫ÁöÑÂÉπÂÄºÊúâÈôê„ÄÇÊàëÂÄëËßÄÂØüÂà∞ LLM È†êÊ∏¨ÂíåÂõûÊáâÂìÅË≥™ËÆäÂåñÁöÑËÆäÁï∞ÊÄß„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü LLM Âú®Á≥ªÁµ±ÂåñÂõûÈ°ßËá™ÂãïÂåñÁöÑË≥áÊñôËêÉÂèñËÉåÊôØ‰∏ãÁöÑÊú™‰æÜË©ï‰º∞ÁØÑÊú¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫‰ΩøÁî® LLM ÂèØËÉΩÊúâÂÉπÂÄºÔºå‰æãÂ¶Ç‰ΩúÁÇ∫Á¨¨‰∫åÊàñÁ¨¨‰∏â‰ΩçÂØ©Êü•ËÄÖ„ÄÇ‰ΩÜÊòØÔºåÂú®Â∞á GPT-4 Á≠âÊ®°ÂûãÊï¥ÂêàÂà∞Â∑•ÂÖ∑‰∏≠ÊôÇÔºåÂª∫Ë≠∞‰øùÊåÅË¨πÊÖé„ÄÇÂ∞çÊñº LLM ËôïÁêÜÁöÑÊØèÁ®ÆÈ°ûÂûãË≥áÊñôÔºåÈÉΩÊúâÂøÖË¶ÅÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÂØ¶ÈöõË®≠ÂÆö‰∏≠ÁöÑÁ©©ÂÆöÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Unraveling overoptimism and publication bias in ML-driven science**
2405.14422v1 by Pouria Saidi, Gautam Dasarathy, Visar Berisha

Machine Learning (ML) is increasingly used across many disciplines with
impressive reported results across many domain areas. However, recent studies
suggest that the published performance of ML models are often overoptimistic
and not reflective of true accuracy were these models to be deployed. Validity
concerns are underscored by findings of a concerning inverse relationship
between sample size and reported accuracy in published ML models across several
domains. This is in contrast with the theory of learning curves in ML, where we
expect accuracy to improve or stay the same with increasing sample size. This
paper investigates the factors contributing to overoptimistic accuracy reports
in ML-based science, focusing on data leakage and publication bias. Our study
introduces a novel stochastic model for observed accuracy, integrating
parametric learning curves and the above biases. We then construct an estimator
based on this model that corrects for these biases in observed data.
Theoretical and empirical results demonstrate that this framework can estimate
the underlying learning curve that gives rise to the observed overoptimistic
results, thereby providing more realistic performance assessments of ML
performance from a collection of published results. We apply the model to
various meta-analyses in the digital health literature, including
neuroimaging-based and speech-based classifications of several neurological
conditions. Our results indicate prevalent overoptimism across these fields and
we estimate the inherent limits of ML-based prediction in each domain.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÊÑà‰æÜÊÑàÂª£Ê≥õÂú∞Áî®ÊñºË®±Â§öÈ†òÂüüÔºåÂú®Ë®±Â§öÈ†òÂüüÈÉΩÂ†±Âëä‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåML Ê®°ÂûãÂ∑≤ÁôºË°®ÁöÑÊïàËÉΩÂæÄÂæÄÈÅéÊñºÊ®ÇËßÄÔºå‰∏îÁÑ°Ê≥ïÂèçÊò†ÈÄô‰∫õÊ®°ÂûãÈÉ®ÁΩ≤ÂæåÁöÑÁúüÂØ¶Ê∫ñÁ¢∫Â∫¶„ÄÇÊúâÊïàÊÄßÁñëÊÖÆÂèóÂà∞‰ª§‰∫∫ÊìîÊÜÇÁöÑÁôºÁèæÁöÑÂº∑Ë™øÔºåÂç≥Âú®ÂπæÂÄãÈ†òÂüü‰∏≠ÔºåÂ∑≤ÁôºË°®ÁöÑ ML Ê®°Âûã‰∏≠ÁöÑÊ®£Êú¨Â§ßÂ∞èËàáÂ†±ÂëäÁöÑÊ∫ñÁ¢∫Â∫¶‰πãÈñìÂ≠òÂú®ÂèçÊØîÈóú‰øÇ„ÄÇÈÄôËàá ML ‰∏≠ÁöÑÂ≠∏ÁøíÊõ≤Á∑öÁêÜË´ñÁõ∏ÂèçÔºåÂú® ML ‰∏≠ÔºåÊàëÂÄëÈ†êÊúüÊ∫ñÁ¢∫Â∫¶ÊúÉÈö®ËëóÊ®£Êú¨Â§ßÂ∞èÁöÑÂ¢ûÂä†ËÄåÊèêÂçáÊàñ‰øùÊåÅ‰∏çËÆä„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂ∞éËá¥ ML Âü∫Á§éÁßëÂ≠∏‰∏≠ÈÅéÂ∫¶Ê®ÇËßÄÁöÑÊ∫ñÁ¢∫Â∫¶Â†±ÂëäÁöÑÂõ†Á¥†ÔºåÈáçÈªûÂú®ÊñºË≥áÊñôÂ§ñÊ¥©ÂíåÁôºË°®ÂÅèË™§„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËßÄÊ∏¨Ê∫ñÁ¢∫Â∫¶Èö®Ê©üÊ®°ÂûãÔºåÊï¥Âêà‰∫ÜÂèÉÊï∏Â≠∏ÁøíÊõ≤Á∑öÂíå‰∏äËø∞ÂÅèË™§„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊ†πÊìöÊ≠§Ê®°ÂûãÂª∫Êßã‰∫Ü‰∏ÄÂÄã‰º∞Ë®àÂô®Ôºå‰ª•‰øÆÊ≠£ËßÄÊ∏¨Ë≥áÊñô‰∏≠ÁöÑÈÄô‰∫õÂÅèË™§„ÄÇÁêÜË´ñÂíåÁ∂ìÈ©óÁµêÊûúË≠âÊòéÔºåÊ≠§Êû∂ÊßãÂèØ‰ª•‰º∞Ë®àÂ∞éËá¥ËßÄÊ∏¨ÈÅéÂ∫¶Ê®ÇËßÄÁµêÊûúÁöÑÂ∫ïÂ±§Â≠∏ÁøíÊõ≤Á∑öÔºåÂæûËÄåÊèê‰æõÊõ¥ÂØ¶ÈöõÁöÑ ML ÊïàËÉΩË©ï‰º∞ÔºåÈÄô‰∫õË©ï‰º∞‰æÜËá™‰∏ÄÁ≥ªÂàóÂ∑≤ÁôºË°®ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÂ∞áÊ≠§Ê®°ÂûãÊáâÁî®ÊñºÊï∏‰ΩçÂÅ•Â∫∑ÊñáÁçª‰∏≠ÁöÑÂêÑÁ®ÆÂæåË®≠ÂàÜÊûêÔºåÂåÖÊã¨Âü∫ÊñºÁ•ûÁ∂ìÂΩ±ÂÉèÂíåÂü∫ÊñºË™ûÈü≥ÁöÑÂπæÁ®ÆÁ•ûÁ∂ìÁãÄÊ≥ÅÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊåáÂá∫ÈÄô‰∫õÈ†òÂüüÊôÆÈÅçÂ≠òÂú®ÈÅéÂ∫¶Ê®ÇËßÄÔºå‰∏¶‰∏îÊàëÂÄë‰º∞Ë®à‰∫ÜÊØèÂÄãÈ†òÂüü‰∏≠Âü∫Êñº ML ÁöÑÈ†êÊ∏¨ÁöÑÂÖßÂú®ÈôêÂà∂„ÄÇ

##### **Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports**
2405.14230v1 by Guangyu Guo, Jiawen Yao, Yingda Xia, Tony C. W. Mok, Zhilin Zheng, Junwei Han, Le Lu, Dingwen Zhang, Jian Zhou, Ling Zhang

The absence of adequately sufficient expert-level tumor annotations hinders
the effectiveness of supervised learning based opportunistic cancer screening
on medical imaging. Clinical reports (that are rich in descriptive textual
details) can offer a "free lunch'' supervision information and provide tumor
location as a type of weak label to cope with screening tasks, thus saving
human labeling workloads, if properly leveraged. However, predicting cancer
only using such weak labels can be very changeling since tumors are usually
presented in small anatomical regions compared to the whole 3D medical scans.
Weakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level
tumor annotations and incorporates alongside a substantial number of medical
images that have only off-the-shelf clinical reports, which may strike a good
balance between minimizing expert annotation workload and optimizing screening
efficacy. In this paper, we propose a novel text-guided learning method to
achieve highly accurate cancer detection results. Through integrating
diagnostic and tumor location text prompts into the text encoder of a
vision-language model (VLM), optimization of weakly supervised learning can be
effectively performed in the latent space of VLM, thereby enhancing the
stability of training. Our approach can leverage clinical knowledge by
large-scale pre-trained VLM to enhance generalization ability, and produce
reliable pseudo tumor masks to improve cancer detection. Our extensive
quantitative experimental results on a large-scale cancer dataset, including
1,651 unique patients, validate that our approach can reduce human annotation
efforts by at least 70% while maintaining comparable cancer detection accuracy
to competing fully supervised methods (AUC value 0.961 versus 0.966).

ÊëòË¶ÅÔºöÁî±ÊñºÁº∫‰πèË∂≥Â§†ÁöÑÂ∞àÂÆ∂Á≠âÁ¥öËÖ´Áò§Ê®ôË®òÔºåÊúÉÈòªÁ§ôÂü∫ÊñºÁõ£Áù£ÂºèÂ≠∏ÁøíÁöÑÊ©üÊúÉ‰∏ªÁæ©ÁôåÁóáÁØ©Ê™¢Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÁöÑÊïàËÉΩ„ÄÇËá®Â∫äÂ†±ÂëäÔºàÂåÖÂê´Ë±êÂØåÁöÑÊèèËø∞ÊÄßÊñáÂ≠óÁ¥∞ÁØÄÔºâÂèØÊèê‰æõ„ÄåÂÖçË≤ªÁöÑÂçàÈ§ê„ÄçÁõ£Áù£Ë≥áË®äÔºå‰∏¶Êèê‰æõËÖ´Áò§‰ΩçÁΩÆ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂº±Ê®ôÁ±§‰ª•ÊáâÂ∞çÁØ©Ê™¢‰ªªÂãôÔºåÂæûËÄåÁØÄÁúÅ‰∫∫Â∑•Ê®ôÁ±§ÁöÑÂ∑•‰ΩúÈáèÔºåÂè™Ë¶ÅÈÅ©Áï∂Âà©Áî®Âç≥ÂèØ„ÄÇÁÑ∂ËÄåÔºåÂÉÖ‰ΩøÁî®Ê≠§È°ûÂº±Ê®ôÁ±§‰æÜÈ†êÊ∏¨ÁôåÁóáÂèØËÉΩÈùûÂ∏∏Âõ∞Èõ£ÔºåÂõ†ÁÇ∫ËàáÊï¥ÂÄã 3D ÈÜ´Â≠∏ÊéÉÊèèÁõ∏ÊØîÔºåËÖ´Áò§ÈÄöÂ∏∏Âá∫ÁèæÂú®ËºÉÂ∞èÁöÑËß£ÂâñÂçÄÂüü‰∏≠„ÄÇÂº±ÂçäÁõ£Áù£ÂºèÂ≠∏ÁøíÔºàWSSLÔºâÂà©Áî®ÊúâÈôêÁöÑÈ´îÁ¥†Á¥öËÖ´Áò§Ê®ôË®òÔºå‰∏¶ÁµêÂêàÂ§ßÈáèÂÉÖÊúâÁèæÊàêËá®Â∫äÂ†±ÂëäÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÈÄôÂèØËÉΩÊúÉÂú®ÊúÄÂ§ßÁ®ãÂ∫¶Ê∏õÂ∞ëÂ∞àÂÆ∂Ê®ôË®òÂ∑•‰ΩúÈáèÂíåÊúÄ‰Ω≥ÂåñÁØ©Ê™¢ÊïàËÉΩ‰πãÈñìÂèñÂæóËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñáÂ≠óÂºïÂ∞éÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÈÅîÊàêÈ´òÂ∫¶Ê∫ñÁ¢∫ÁöÑÁôåÁóáÂÅµÊ∏¨ÁµêÊûú„ÄÇÈÄèÈÅéÂ∞áË®∫Êñ∑ÂíåËÖ´Áò§‰ΩçÁΩÆÊñáÂ≠óÊèêÁ§∫Êï¥ÂêàÂà∞Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºàVLMÔºâÁöÑÊñáÂ≠óÁ∑®Á¢ºÂô®‰∏≠ÔºåÂèØ‰ª•Âú® VLM ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠ÊúâÊïàÂü∑Ë°åÂº±Áõ£Áù£ÂºèÂ≠∏ÁøíÁöÑÊúÄ‰Ω≥ÂåñÔºåÂæûËÄåÂ¢ûÂº∑Ë®ìÁ∑¥ÁöÑÁ©©ÂÆöÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÈÄèÈÅéÂ§ßË¶èÊ®°È†êÂÖàË®ìÁ∑¥ÁöÑ VLM ‰æÜÂà©Áî®Ëá®Â∫äÁü•Ë≠ò‰ª•Â¢ûÂº∑Ê≥õÂåñËÉΩÂäõÔºå‰∏¶Áî¢ÁîüÂèØÈù†ÁöÑÂÅΩËÖ´Áò§ÈÅÆÁΩ©‰ª•ÊîπÂñÑÁôåÁóáÂÅµÊ∏¨„ÄÇÊàëÂÄëÂú®ÂåÖÂê´ 1,651 ‰ΩçÁç®ÁâπÊÇ£ËÄÖÁöÑÂ§ßË¶èÊ®°ÁôåÁóáË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂÆöÈáèÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Â∞á‰∫∫Â∑•Ê®ôË®òÂ∑•‰ΩúÈáèËá≥Â∞ëÊ∏õÂ∞ë 70%ÔºåÂêåÊôÇÁ∂≠ÊåÅËàáÁ´∂Áà≠ÁöÑÂÖ®Áõ£Áù£ÂºèÊñπÊ≥ïÁõ∏Áï∂ÁöÑÁôåÁóáÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶ÔºàAUC ÂÄº 0.961 Â∞çÊØî 0.966Ôºâ„ÄÇ

##### **Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks**
2405.17460v1 by Yafeng Yan, Shuyao He, Zhou Yu, Jiajie Yuan, Ziang Liu, Yan Chen

Aiming at the limitations of traditional medical decision system in
processing large-scale heterogeneous medical data and realizing highly
personalized recommendation, this paper introduces a personalized medical
decision algorithm utilizing graph neural network (GNN). This research
innovatively integrates graph neural network technology into the medical and
health field, aiming to build a high-precision representation model of patient
health status by mining the complex association between patients' clinical
characteristics, genetic information, living habits. In this study, medical
data is preprocessed to transform it into a graph structure, where nodes
represent different data entities (such as patients, diseases, genes, etc.) and
edges represent interactions or relationships between entities. The core of the
algorithm is to design a novel multi-scale fusion mechanism, combining the
historical medical records, physiological indicators and genetic
characteristics of patients, to dynamically adjust the attention allocation
strategy of the graph neural network, so as to achieve highly customized
analysis of individual cases. In the experimental part, this study selected
several publicly available medical data sets for validation, and the results
showed that compared with traditional machine learning methods and a single
graph neural network model, the proposed personalized medical decision
algorithm showed significantly superior performance in terms of disease
prediction accuracy, treatment effect evaluation and patient risk
stratification.

ÊëòË¶ÅÔºöÈáùÂ∞çÂÇ≥Áµ±ÈÜ´ÁôÇÊ±∫Á≠ñÁ≥ªÁµ±Âú®ËôïÁêÜÂ§ßË¶èÊ®°Áï∞Ë≥™ÈÜ´ÁôÇË≥áÊñôÂíåÂØ¶ÁèæÈ´òÂ∫¶ÂÄã‰∫∫ÂåñÊé®Ëñ¶‰∏äÁöÑÈôêÂà∂ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊ±∫Á≠ñÊºîÁÆóÊ≥ï„ÄÇÊú¨Á†îÁ©∂ÂâµÊñ∞Âú∞Â∞áÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊäÄË°ìÊï¥ÂêàÂà∞ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÊó®Âú®ÈÄèÈÅéÊåñÊéòÊÇ£ËÄÖËá®Â∫äÁâπÂæµ„ÄÅÈÅ∫ÂÇ≥Ë≥áË®ä„ÄÅÁîüÊ¥ªÁøíÊÖ£‰πãÈñìÁöÑË§áÈõúÈóúËÅØÔºåÂª∫Á´ãÊÇ£ËÄÖÂÅ•Â∫∑ÁãÄÊÖãÁöÑÈ´òÁ≤æÂ∫¶Ë°®Á§∫Ê®°Âûã„ÄÇÊú¨Á†îÁ©∂‰∏≠ÔºåÈÜ´ÁôÇË≥áÊñôÁ∂ìÈÅéÈ†êËôïÁêÜËΩâÊèõÁÇ∫ÂúñÁµêÊßãÔºåÂÖ∂‰∏≠ÁØÄÈªûË°®Á§∫‰∏çÂêåÁöÑË≥áÊñôÂØ¶È´îÔºà‰æãÂ¶ÇÊÇ£ËÄÖ„ÄÅÁñæÁóÖ„ÄÅÂü∫Âõ†Á≠âÔºâÔºåËÄåÈÇäÁ∑£Ë°®Á§∫ÂØ¶È´î‰πãÈñìÁöÑ‰∫íÂãïÊàñÈóú‰øÇ„ÄÇË©≤ÊºîÁÆóÊ≥ïÁöÑÊ†∏ÂøÉÊòØË®≠Ë®à‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÂ∞∫Â∫¶ËûçÂêàÊ©üÂà∂ÔºåÁµêÂêàÊÇ£ËÄÖÁöÑÊ≠∑Âè≤ÁóÖÊ≠∑„ÄÅÁîüÁêÜÊåáÊ®ôÂíåÈÅ∫ÂÇ≥ÁâπÂæµÔºåÂãïÊÖãË™øÊï¥ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ≥®ÊÑèÂäõÂàÜÈÖçÁ≠ñÁï•Ôºå‰ª•ÂØ¶ÁèæÂ∞çÂÄãÊ°àÁöÑÈ´òÂ∫¶ÂÆ¢Ë£ΩÂåñÂàÜÊûê„ÄÇÂú®ÂØ¶È©óÈÉ®ÂàÜÔºåÊú¨Á†îÁ©∂ÈÅ∏Âèñ‰∫ÜÊï∏ÂÄãÂÖ¨ÈñãÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜÈÄ≤Ë°åÈ©óË≠âÔºåÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂíåÂñÆ‰∏ÄÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊ±∫Á≠ñÊºîÁÆóÊ≥ïÂú®ÁñæÁóÖÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÅÊ≤ªÁôÇÊïàÊûúË©ï‰º∞ÂíåÊÇ£ËÄÖÈ¢®Èö™ÂàÜÂ±§ÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇ

##### **Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis**
2405.17459v1 by Ziyan Yao, Fei Lin, Sheng Chai, Weijie He, Lu Dai, Xinghui Fei

In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ê∑±ÂÖ•Êï¥Âêà‰æÜËá™ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá®Â∫äÂ†±ÂëäÁöÑÁï∞Ë≥™Ë≥áË®ä„ÄÇÈ¶ñÂÖàÔºåÂ∞çÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÔºå‰ΩøÁî®Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÊèêÂèñÈ´òÁ∂≠ÁâπÂæµ‰∏¶Êì∑ÂèñÈóúÈçµË¶ñË¶∫Ë≥áË®äÔºå‰æãÂ¶ÇÁÑ¶ÈªûÁ¥∞ÁØÄ„ÄÅÁ¥ãÁêÜÂíåÁ©∫ÈñìÂàÜ‰Ωà„ÄÇÂÖ∂Ê¨°ÔºåÂ∞çÊñºËá®Â∫äÂ†±ÂëäÊñáÂ≠óÔºå‰ΩøÁî®ÁµêÂêàÊ≥®ÊÑèÂäõÊ©üÂà∂ÁöÑÈõôÂêëÈï∑Áü≠ÊúüË®òÊÜ∂Á∂≤Ë∑ØÈÄ≤Ë°åÊ∑±Â∫¶Ë™ûÁæ©ÁêÜËß£Ôºå‰∏¶Ê∫ñÁ¢∫Êì∑ÂèñËàáÁñæÁóÖÁõ∏ÈóúÁöÑÈóúÈçµÈô≥Ëø∞„ÄÇÈÄôÂÖ©ÂÄãÁâπÂæµÈÄöÈÅéË®≠Ë®àÁöÑÂ§öÊ®°ÊÖãËûçÂêàÂ±§ÊúâÊïàÂú∞‰∫§‰∫íÂíåÊï¥ÂêàÔºå‰ª•ÂØ¶ÁèæÂΩ±ÂÉèÂíåÊñáÂ≠óÁöÑËÅØÂêàË°®ÂæµÂ≠∏Áøí„ÄÇÂú®ÂØ¶Ë≠âÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÅ∏Êìá‰∫Ü‰∏ÄÂÄãÊ∂µËìãÂêÑÁ®ÆÁñæÁóÖÁöÑÂ§ßÂûãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÂ∫´Ôºå‰∏¶ÁµêÂêàÂ∞çÊáâÁöÑËá®Â∫äÂ†±ÂëäÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥ÂíåÈ©óË≠â„ÄÇÊâÄÊèêÂá∫ÁöÑÂ§öÊ®°ÊÖãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®ÁñæÁóÖÂàÜÈ°û„ÄÅÁóÖÁÅ∂ÂÆö‰ΩçÂíåËá®Â∫äÊèèËø∞ÁîüÊàêÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÂÑ™Ë∂äÊÄßÔºåÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÈÄô‰∏ÄÈªû„ÄÇ

##### **Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation**
2405.14905v1 by Kang Liu, Zhuoqi Ma, Xiaolu Kang, Zhusi Zhong, Zhicheng Jiao, Grayson Baird, Harrison Bai, Qiguang Miao

The automated generation of imaging reports proves invaluable in alleviating
the workload of radiologists. A clinically applicable reports generation
algorithm should demonstrate its effectiveness in producing reports that
accurately describe radiology findings and attend to patient-specific
indications. In this paper, we introduce a novel method, \textbf{S}tructural
\textbf{E}ntities extraction and patient indications \textbf{I}ncorporation
(SEI) for chest X-ray report generation. Specifically, we employ a structural
entities extraction (SEE) approach to eliminate presentation-style vocabulary
in reports and improve the quality of factual entity sequences. This reduces
the noise in the following cross-modal alignment module by aligning X-ray
images with factual entity sequences in reports, thereby enhancing the
precision of cross-modal alignment and further aiding the model in
gradient-free retrieval of similar historical cases. Subsequently, we propose a
cross-modal fusion network to integrate information from X-ray images, similar
historical cases, and patient-specific indications. This process allows the
text decoder to attend to discriminative features of X-ray images, assimilate
historical diagnostic information from similar cases, and understand the
examination intention of patients. This, in turn, assists in triggering the
text decoder to produce high-quality reports. Experiments conducted on
MIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on
both natural language generation and clinical efficacy metrics.

ÊëòË¶ÅÔºö<paragraph>ÂΩ±ÂÉèÂ†±ÂëäÁöÑËá™ÂãïÁîüÊàêÂú®Ê∏õËºïÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑÂ∑•‰ΩúË≤†ÊìîÊñπÈù¢Ë≠âÊòé‰∫ÜÂÖ∂ÁÑ°ÂèØÊØîÊì¨ÁöÑÂÉπÂÄº„ÄÇ‰∏ÄÂÄãËá®Â∫ä‰∏äÈÅ©Áî®ÁöÑÂ†±ÂëäÁîüÊàêÊºîÁÆóÊ≥ïÊáâË©≤Â±ïÁ§∫ÂÖ∂Âú®Áî¢ÁîüÂ†±ÂëäÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÈÄô‰∫õÂ†±ÂëäÊ∫ñÁ¢∫Âú∞ÊèèËø∞‰∫ÜÊîæÂ∞ÑÁßëÁôºÁèæÔºå‰∏¶Ê≥®ÊÑèÊÇ£ËÄÖÁâπÂÆöÁöÑÈÅ©ÊáâÁóá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ËÉ∏ÈÉ® X ÂÖâÂ†±ÂëäÁîüÊàêÁöÑÁµêÊßãÂØ¶È´îËêÉÂèñÂíåÊÇ£ËÄÖÈÅ©ÊáâÁóáÊï¥Âêà (SEI)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®ÁµêÊßãÂØ¶È´îËêÉÂèñ (SEE) ÊñπÊ≥ï‰æÜÊ∂àÈô§Â†±Âëä‰∏≠ÁöÑÂëàÁèæÂºèË©ûÂΩôÔºå‰∏¶ÊèêÈ´ò‰∫ãÂØ¶ÂØ¶È´îÂ∫èÂàóÁöÑÂìÅË≥™„ÄÇÈÄôÊúÉÊ∏õÂ∞ëÂæåÁ∫åË∑®Ê®°ÊÖãÂ∞çÈΩäÊ®°ÁµÑ‰∏≠ÁöÑÈõúË®äÔºåÈÄèÈÅéÂ∞á X ÂÖâÂΩ±ÂÉèËàáÂ†±Âëä‰∏≠ÁöÑ‰∫ãÂØ¶ÂØ¶È´îÂ∫èÂàóÂ∞çÈΩäÔºåÈÄ≤ËÄåÊèêÂçáË∑®Ê®°ÊÖãÂ∞çÈΩäÁöÑÁ≤æÁ¢∫Â∫¶Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÂçîÂä©Ê®°ÂûãÁÑ°Ê¢ØÂ∫¶Ê™¢Á¥¢È°û‰ººÁöÑÊ≠∑Âè≤Ê°à‰æã„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË∑®Ê®°ÊÖãËûçÂêàÁ∂≤Ë∑ØÔºå‰ª•Êï¥Âêà‰æÜËá™ X ÂÖâÂΩ±ÂÉè„ÄÅÈ°û‰ººÁöÑÊ≠∑Âè≤Ê°à‰æãÂíåÊÇ£ËÄÖÁâπÂÆöÈÅ©ÊáâÁóáÁöÑË≥áË®ä„ÄÇÈÄôÂÄãÈÅéÁ®ãÂÖÅË®±ÊñáÂ≠óËß£Á¢ºÂô®Ê≥®ÊÑè X ÂÖâÂΩ±ÂÉèÁöÑÂçÄÂà•ÁâπÂæµÔºåÂæûÈ°û‰ººÊ°à‰æã‰∏≠ÂΩôÊï¥Ê≠∑Âè≤Ë®∫Êñ∑Ë≥áË®äÔºå‰∏¶‰∫ÜËß£ÊÇ£ËÄÖÁöÑÊ™¢Êü•ÊÑèÂúñ„ÄÇÈÄôÂèçÈÅé‰æÜÊúâÂä©ÊñºËß∏ÁôºÊñáÂ≠óËß£Á¢ºÂô®Áî¢ÁîüÈ´òÂìÅË≥™ÁöÑÂ†±Âëä„ÄÇÂú® MIMIC-CXR ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü SEI Âú®Ëá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÂíåËá®Â∫äÁôÇÊïàÊåáÊ®ô‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **How Many Bytes Can You Take Out Of Brain-To-Text Decoding?**
2405.14055v1 by Richard Antonello, Nihita Sarma, Jerry Tang, Jiaru Song, Alexander Huth

Brain-computer interfaces have promising medical and scientific applications
for aiding speech and studying the brain. In this work, we propose an
information-based evaluation metric for brain-to-text decoders. Using this
metric, we examine two methods to augment existing state-of-the-art continuous
text decoders. We show that these methods, in concert, can improve brain
decoding performance by upwards of 40% when compared to a baseline model. We
further examine the informatic properties of brain-to-text decoders and show
empirically that they have Zipfian power law dynamics. Finally, we provide an
estimate for the idealized performance of an fMRI-based text decoder. We
compare this idealized model to our current model, and use our
information-based metric to quantify the main sources of decoding error. We
conclude that a practical brain-to-text decoder is likely possible given
further algorithmic improvements.

ÊëòË¶ÅÔºöËÖ¶Ê©ü‰ªãÈù¢Âú®ËºîÂä©Ë™™Ë©±ÂíåÁ†îÁ©∂Â§ßËÖ¶ÊñπÈù¢ÂÖ∑ÊúâÂæàÊúâÂâçÊôØÁöÑÈÜ´ÁôÇÂíåÁßëÂ≠∏ÊáâÁî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË≥áË®äÁöÑË©ï‰º∞ÊåáÊ®ôÔºåÁî®ÊñºËÖ¶Â∞çÊñáÂ≠óÁöÑËß£Á¢ºÂô®„ÄÇ‰ΩøÁî®Ê≠§ÊåáÊ®ôÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂÖ©Á®ÆÊñπÊ≥ï‰æÜÊì¥ÂÖÖÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑÈÄ£Á∫åÊñáÂ≠óËß£Á¢ºÂô®„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄô‰∫õÊñπÊ≥ïÂçîÂêå‰ΩúÁî®ÔºåËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÂèØ‰ª•Â∞áËÖ¶Ëß£Á¢ºÊÄßËÉΩÊèêÈ´ò 40% ‰ª•‰∏ä„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜËÖ¶Â∞çÊñáÂ≠óËß£Á¢ºÂô®ÁöÑË≥áË®äÁâπÊÄßÔºå‰∏¶ÊÜëÁ∂ìÈ©óË°®ÊòéÂÆÉÂÄëÂÖ∑ÊúâÈΩäÂ§´ÂÆöÂæãÂãïÊÖã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂü∫Êñº fMRI ÁöÑÊñáÂ≠óËß£Á¢ºÂô®ÁöÑÁêÜÊÉ≥ÂåñÊÄßËÉΩ‰º∞Ë®à„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄãÁêÜÊÉ≥ÂåñÁöÑÊ®°ÂûãËàáÊàëÂÄëÁõÆÂâçÁöÑÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÂü∫ÊñºË≥áË®äÁöÑÊåáÊ®ôÈáèÂåñËß£Á¢ºÈåØË™§ÁöÑ‰∏ªË¶Å‰æÜÊ∫ê„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÂ¶ÇÊûúÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÊºîÁÆóÊ≥ïÔºåÂØ¶Áî®ÁöÑËÖ¶Â∞çÊñáÂ≠óËß£Á¢ºÂô®ÂæàÂèØËÉΩÂØ¶Áèæ„ÄÇ

##### **Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review**
2405.13832v1 by Md Shahin Ali, Md Manjurul Ahsan, Lamia Tasnim, Sadia Afrin, Koushik Biswas, Md Maruf Hossain, Md Mahfuz Ahmed, Ronok Hashan, Md Khairul Islam, Shivakumar Raman

Data privacy has become a major concern in healthcare due to the increasing
digitization of medical records and data-driven medical research. Protecting
sensitive patient information from breaches and unauthorized access is
critical, as such incidents can have severe legal and ethical complications.
Federated Learning (FL) addresses this concern by enabling multiple healthcare
institutions to collaboratively learn from decentralized data without sharing
it. FL's scope in healthcare covers areas such as disease prediction, treatment
customization, and clinical trial research. However, implementing FL poses
challenges, including model convergence in non-IID (independent and identically
distributed) data environments, communication overhead, and managing
multi-institutional collaborations. A systematic review of FL in healthcare is
necessary to evaluate how effectively FL can provide privacy while maintaining
the integrity and usability of medical data analysis. In this study, we analyze
existing literature on FL applications in healthcare. We explore the current
state of model security practices, identify prevalent challenges, and discuss
practical applications and their implications. Additionally, the review
highlights promising future research directions to refine FL implementations,
enhance data security protocols, and expand FL's use to broader healthcare
applications, which will benefit future researchers and practitioners.

ÊëòË¶ÅÔºöÁî±ÊñºÈÜ´ÁôÇË®òÈåÑÊï∏‰ΩçÂåñÂíåË≥áÊñôÈ©ÖÂãïÂûãÈÜ´ÁôÇÁ†îÁ©∂ÁöÑÂ¢ûÂä†ÔºåË≥áÊñôÈö±ÁßÅÂ∑≤ÊàêÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰∏ªË¶ÅÂïèÈ°å„ÄÇ‰øùË≠∑ÊïèÊÑüÁöÑÊÇ£ËÄÖË≥áË®äÂÖçÊñºÂ§ñÊ¥©ÂíåÊú™Á∂ìÊéàÊ¨äÁöÑÂ≠òÂèñËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫Ê≠§È°û‰∫ã‰ª∂ÂèØËÉΩÊúÉÈÄ†ÊàêÂö¥ÈáçÁöÑÊ≥ïÂæãÂíåÂÄ´ÁêÜÂïèÈ°å„ÄÇËÅØÂêàÂ≠∏Áøí (FL) ÈÄèÈÅéËÆìÂ§öÂÄãÈÜ´ÁôÇ‰øùÂÅ•Ê©üÊßãÂú®‰∏çÂÖ±‰∫´ÂàÜÊï£Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÂçî‰ΩúÂ≠∏ÁøíÔºå‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇFL Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÁØÑÂúçÊ∂µËìãÁñæÁóÖÈ†êÊ∏¨„ÄÅÊ≤ªÁôÇÂÆ¢Ë£ΩÂåñÂíåËá®Â∫äË©¶È©óÁ†îÁ©∂Á≠âÈ†òÂüü„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÊñΩ FL ÊúÉÂ∏∂‰æÜÊåëÊà∞ÔºåÂåÖÊã¨Èùû IIDÔºàÁç®Á´ã‰∏îÂêåÂàÜÂ∏ÉÔºâË≥áÊñôÁí∞Â¢É‰∏≠ÁöÑÊ®°ÂûãÊî∂ÊñÇ„ÄÅÈÄöË®äË≤†ËºâÂíåÁÆ°ÁêÜÂ§öÊ©üÊßãÂêà‰Ωú„ÄÇÊúâÂøÖË¶ÅÂ∞çÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ FL ÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÂõûÈ°ßÔºå‰ª•Ë©ï‰º∞ FL Âú®Á∂≠Ë≠∑ÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÁöÑÂÆåÊï¥ÊÄßÂíåÂèØÁî®ÊÄßÁöÑÂêåÊôÇÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞Êèê‰æõÈö±ÁßÅ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÁèæÊúâÁöÑÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ FL ÊáâÁî®ÁöÑÊñáÁçª„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÊ®°ÂûãÂÆâÂÖ®ÂØ¶ÂãôÁöÑÁèæÊ≥Å„ÄÅÊâæÂá∫ÊôÆÈÅçÁöÑÊåëÊà∞Ôºå‰∏¶Ë®éË´ñÂØ¶ÈöõÊáâÁî®ÂèäÂÖ∂ÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊ≠§ÂõûÈ°ßÂº∑Ë™ø‰∫ÜÊúâÂâçÈÄîÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÔºå‰ª•ÊîπÂñÑ FL ÁöÑÂØ¶‰Ωú„ÄÅÂä†Âº∑Ë≥áÊñôÂÆâÂÖ®ÂçîÂÆöÔºå‰∏¶Â∞á FL ÁöÑÁî®ÈÄîÊì¥Â±ïÂà∞Êõ¥Âª£Ê≥õÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÔºåÈÄôÂ∞á‰ΩøÊú™‰æÜÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠‰∫∫Âì°ÂèóÁõä„ÄÇ

##### **Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling**
2405.13785v1 by Shifan Zhao, Jiaying Lu, Ji Yang, Edmond Chow, Yuanzhe Xi

Gaussian Process Regression (GPR) is widely used in statistics and machine
learning for prediction tasks requiring uncertainty measures. Its efficacy
depends on the appropriate specification of the mean function, covariance
kernel function, and associated hyperparameters. Severe misspecifications can
lead to inaccurate results and problematic consequences, especially in
safety-critical applications. However, a systematic approach to handle these
misspecifications is lacking in the literature. In this work, we propose a
general framework to address these issues. Firstly, we introduce a flexible
two-stage GPR framework that separates mean prediction and uncertainty
quantification (UQ) to prevent mean misspecification, which can introduce bias
into the model. Secondly, kernel function misspecification is addressed through
a novel automatic kernel search algorithm, supported by theoretical analysis,
that selects the optimal kernel from a candidate set. Additionally, we propose
a subsampling-based warm-start strategy for hyperparameter initialization to
improve efficiency and avoid hyperparameter misspecification. With much lower
computational cost, our subsampling-based strategy can yield competitive or
better performance than training exclusively on the full dataset. Combining all
these components, we recommend two GPR methods-exact and scalable-designed to
match available computational resources and specific UQ requirements. Extensive
evaluation on real-world datasets, including UCI benchmarks and a
safety-critical medical case study, demonstrates the robustness and precision
of our methods.

ÊëòË¶ÅÔºöÈ´òÊñØÈÅéÁ®ãÂõûÊ≠∏ (GPR) Âª£Ê≥õÁî®ÊñºÁµ±Ë®àÂíåÊ©üÂô®Â≠∏Áøí‰∏≠ÁöÑÈ†êÊ∏¨‰ªªÂãôÔºåÈúÄË¶Å‰∏çÁ¢∫ÂÆöÊÄßÂ∫¶Èáè„ÄÇÂÖ∂ÊïàËÉΩÂèñÊ±∫ÊñºÂπ≥ÂùáÂáΩÊï∏„ÄÅÂçîÊñπÂ∑ÆÊ†∏ÂáΩÊï∏ÂíåÁõ∏ÈóúË∂ÖÂèÉÊï∏ÁöÑÈÅ©Áï∂Ë¶èÊ†º„ÄÇÂö¥ÈáçÁöÑÈåØË™§Ë¶èÊ†ºÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÊ∫ñÁ¢∫ÁöÑÁµêÊûúÂíåÊúâÂïèÈ°åÁöÑÂæåÊûúÔºåÁâπÂà•ÊòØÂú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠„ÄÇÁÑ∂ËÄåÔºåÊñáÁçª‰∏≠Áº∫‰πèÁ≥ªÁµ±ÁöÑÊñπÊ≥ï‰æÜËôïÁêÜÈÄô‰∫õÈåØË™§Ë¶èÊ†º„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÄöÁî®Ê°ÜÊû∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑÂÖ©ÈöéÊÆµ GPR Ê°ÜÊû∂ÔºåÂÆÉÂ∞áÂπ≥ÂùáÈ†êÊ∏¨Âíå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñ (UQ) ÂàÜÈñãÔºå‰ª•Èò≤Ê≠¢Âπ≥ÂùáÈåØË™§Ë¶èÊ†ºÔºåÈÄôÂèØËÉΩÊúÉÂ∞áÂÅèÂ∑ÆÂºïÂÖ•Ê®°Âûã„ÄÇÂÖ∂Ê¨°ÔºåÈÄöÈÅé‰∏ÄÁ®ÆÊñ∞Á©éÁöÑËá™ÂãïÊ†∏ÊêúÁ¥¢ÁÆóÊ≥ï‰æÜËß£Ê±∫Ê†∏ÂáΩÊï∏ÈåØË™§Ë¶èÊ†ºÔºåË©≤ÁÆóÊ≥ïÁî±ÁêÜË´ñÂàÜÊûêÊîØÊåÅÔºåÂæûÂÄôÈÅ∏ÈõÜ‰∏≠ÈÅ∏ÊìáÊúÄ‰Ω≥Ê†∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂ≠êÊäΩÊ®£ÁöÑÁÜ±ÂïüÂãïÁ≠ñÁï•ÔºåÁî®ÊñºË∂ÖÂèÉÊï∏ÂàùÂßãÂåñÔºå‰ª•ÊèêÈ´òÊïàÁéá‰∏¶ÈÅøÂÖçË∂ÖÂèÉÊï∏ÈåØË™§Ë¶èÊ†º„ÄÇÊàëÂÄëÁöÑÂü∫ÊñºÂ≠êÊäΩÊ®£ÁöÑÁ≠ñÁï•‰ª•‰ΩéÂæóÂ§öÁöÑË®àÁÆóÊàêÊú¨ÔºåÂèØ‰ª•Áî¢ÁîüÊØîÂ∞àÈñÄÂú®ÂÆåÊï¥Êï∏ÊìöÈõÜ‰∏äË®ìÁ∑¥Êõ¥ÂÖ∑Á´∂Áà≠ÂäõÊàñÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇÁµêÂêàÊâÄÊúâÈÄô‰∫õÁµÑÊàêÈÉ®ÂàÜÔºåÊàëÂÄëÊé®Ëñ¶ÂÖ©Á®Æ GPR ÊñπÊ≥ï‚Äî‚ÄîÁ≤æÁ¢∫ÂíåÂèØÊì¥Â±ï‚Äî‚ÄîÊó®Âú®ÂåπÈÖçÂèØÁî®ÁöÑË®àÁÆóË≥áÊ∫êÂíåÂÖ∑È´îÁöÑ UQ ÈúÄÊ±Ç„ÄÇÂú®ÂåÖÊã¨ UCI Âü∫Ê∫ñÂíåÂÆâÂÖ®ÈóúÈçµÈÜ´ÁôÇÊ°à‰æãÁ†îÁ©∂Âú®ÂÖßÁöÑÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜ‰∏äÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÁ≤æÁ¢∫ÊÄß„ÄÇ

##### **How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?**
2405.13219v1 by Ayesha Siddika Nipu, K M Sajjadul Islam, Praveen Madiraju

Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)
are gaining traction in healthcare for their potential to automate patient
interactions and aid clinical decision-making. This study examines the
reliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini
Ultra 1.0, in predicting diseases from patient complaints in the emergency
department. The methodology includes few-shot learning techniques to evaluate
the chatbots' effectiveness in disease prediction. We also fine-tune the
transformer-based model BERT and compare its performance with the AI chatbots.
Results suggest that GPT 4.0 achieves high accuracy with increased few-shot
data, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3
Opus maintains consistent performance. BERT's performance, however, is lower
than all the chatbots, indicating limitations due to limited labeled data.
Despite the chatbots' varying accuracy, none of them are sufficiently reliable
for critical medical decision-making, underscoring the need for rigorous
validation and human oversight. This study reflects that while AI chatbots have
potential in healthcare, they should complement, not replace, human expertise
to ensure patient safety. Further refinement and research are needed to improve
AI-based healthcare applications' reliability for disease prediction.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâËÅäÂ§©Ê©üÂô®‰∫∫Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠Áç≤ÂæóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÖ∑ÊúâËá™ÂãïÂåñÊÇ£ËÄÖ‰∫íÂãïÂíåÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñÁöÑÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü AI ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÂèØÈù†ÊÄßÔºåÁâπÂà•ÊòØ GPT 4.0„ÄÅClaude 3 Opus Âíå Gemini Ultra 1.0ÔºåÂú®È†êÊ∏¨ÊÄ•Ë®∫ÈÉ®ÈñÄÊÇ£ËÄÖÁóáÁãÄÁöÑÁñæÁóÖÊñπÈù¢„ÄÇÊñπÊ≥ïÂåÖÊã¨Â∞ëÈáèÂ≠∏ÁøíÊäÄË°ìÔºå‰ª•Ë©ï‰º∞ËÅäÂ§©Ê©üÂô®‰∫∫Âú®ÁñæÁóÖÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑÂæÆË™ø‰∫ÜÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°Âûã BERTÔºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàá AI ËÅäÂ§©Ê©üÂô®‰∫∫ÈÄ≤Ë°åÊØîËºÉ„ÄÇÁµêÊûúË°®ÊòéÔºåGPT 4.0 Âú®Â∞ëÈáèÊï∏ÊìöÂ¢ûÂä†ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ‰∫ÜÈ´òÊ∫ñÁ¢∫Â∫¶ÔºåËÄå Gemini Ultra 1.0 Âú®ËºÉÂ∞ëÁöÑÁØÑ‰æã‰∏≠Ë°®ÁèæËâØÂ•ΩÔºåClaude 3 Opus ÂâáÁ∂≠ÊåÅ‰∫Ü‰∏ÄËá¥ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåBERT ÁöÑÊïàËÉΩ‰ΩéÊñºÊâÄÊúâËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÈÄôË°®ÊòéÁî±ÊñºÊ®ôË®òÊï∏ÊìöÊúâÈôêËÄåÂ≠òÂú®ÈôêÂà∂„ÄÇÂÑòÁÆ°ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÊ∫ñÁ¢∫Â∫¶‰∏çÂêåÔºå‰ΩÜÂÆÉÂÄëÈÉΩ‰∏çË∂≥‰ª•Áî®ÊñºÈáçË¶ÅÁöÑÈÜ´ÁôÇÊ±∫Á≠ñÔºåÈÄôÂº∑Ë™ø‰∫ÜÂö¥Ê†ºÈ©óË≠âÂíå‰∫∫È°ûÁõ£Áù£ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á†îÁ©∂Ë°®ÊòéÔºåÂÑòÁÆ° AI ËÅäÂ§©Ê©üÂô®‰∫∫Âú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÂÖ∑ÊúâÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÊáâË£úÂÖÖËÄå‰∏çÊòØÂèñ‰ª£‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÔºå‰ª•Á¢∫‰øùÊÇ£ËÄÖÂÆâÂÖ®„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÊîπÈÄ≤ÂíåÁ†îÁ©∂Ôºå‰ª•ÊèêÈ´òÂü∫Êñº AI ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®Âú®ÁñæÁóÖÈ†êÊ∏¨ÊñπÈù¢ÁöÑÂèØÈù†ÊÄß„ÄÇ

##### **Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation**
2405.13190v1 by Haoteng Tang, Guodong Liu, Siyuan Dai, Kai Ye, Kun Zhao, Wenlu Wang, Carl Yang, Lifang He, Alex Leow, Paul Thompson, Heng Huang, Liang Zhan

The MRI-derived brain network serves as a pivotal instrument in elucidating
both the structural and functional aspects of the brain, encompassing the
ramifications of diseases and developmental processes. However, prevailing
methodologies, often focusing on synchronous BOLD signals from functional MRI
(fMRI), may not capture directional influences among brain regions and rarely
tackle temporal functional dynamics. In this study, we first construct the
brain-effective network via the dynamic causal model. Subsequently, we
introduce an interpretable graph learning framework termed Spatio-Temporal
Embedding ODE (STE-ODE). This framework incorporates specifically designed
directed node embedding layers, aiming at capturing the dynamic interplay
between structural and effective networks via an ordinary differential equation
(ODE) model, which characterizes spatial-temporal brain dynamics. Our framework
is validated on several clinical phenotype prediction tasks using two
independent publicly available datasets (HCP and OASIS). The experimental
results clearly demonstrate the advantages of our model compared to several
state-of-the-art methods.

ÊëòË¶ÅÔºö‰ª• MRI Ë°çÁîüÁöÑËÖ¶Á∂≤Ë∑Ø‰ΩúÁÇ∫Ê®ûÁ¥êÂ∑•ÂÖ∑ÔºåÈó°ÊòéÂ§ßËÖ¶ÁöÑÁµêÊßãÂíåÂäüËÉΩÈù¢ÂêëÔºåÂåÖÂê´ÁñæÁóÖÂíåÁôºÂ±ïÈÅéÁ®ãÁöÑÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåÁèæË°åÁöÑÁ†îÁ©∂ÊñπÊ≥ïÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂäüËÉΩÊÄß MRI (fMRI) ÁöÑÂêåÊ≠• BOLD Ë®äËôüÔºåÂèØËÉΩÁÑ°Ê≥ïÊçïÊçâËÖ¶ÂçÄ‰πãÈñìÁöÑÊñπÂêëÊÄßÂΩ±ÈüøÔºå‰πüÂæàÂ∞ëËôïÁêÜÊôÇÈñìÂäüËÉΩÂãïÊÖã„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÂãïÊÖãÂõ†ÊûúÊ®°ÂûãÂª∫ÊßãËÖ¶ÈÉ®ÊúâÊïàÁ∂≤Ë∑Ø„ÄÇÊé•ËëóÔºåÊàëÂÄëÂºïÂÖ•Á®±ÁÇ∫ÊôÇÁ©∫ÂµåÂÖ• ODE (STE-ODE) ÁöÑÂèØËß£ÈáãÂúñÂΩ¢Â≠∏ÁøíÊû∂Êßã„ÄÇÊ≠§Êû∂ÊßãÁµêÂêàÂ∞àÈñÄË®≠Ë®àÁöÑÊúâÂêëÁØÄÈªûÂµåÂÖ•Â±§ÔºåÊó®Âú®ÈÄèÈÅéÂ∏∏ÂæÆÂàÜÊñπÁ®ã (ODE) Ê®°ÂûãÊçïÊçâÁµêÊßãÂíåÊúâÊïàÁ∂≤Ë∑Ø‰πãÈñìÁöÑÂãïÊÖã‰∫§‰∫í‰ΩúÁî®ÔºåÊèèËø∞ÊôÇÁ©∫ËÖ¶ÈÉ®ÂãïÊÖã„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂú®ÂÖ©ÂÄãÁç®Á´ãÂÖ¨ÈñãË≥áÊñôÈõÜ (HCP Âíå OASIS) ‰∏äÁ∂ìÈÅéÂ§öÈ†ÖËá®Â∫äË°®ÂûãÈ†êÊ∏¨‰ªªÂãôÈ©óË≠â„ÄÇÂØ¶È©óÁµêÊûúÊ∏ÖÊ•öÈ°ØÁ§∫ÔºåËàáÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÖ∑ÊúâÂÑ™Âã¢„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning**
2405.13094v1 by Yusong Zhang, Kun Xie, Xingyi Zhang, Xiangyu Dong, Sibo Wang

The proliferation of rumors on social media platforms during significant
events, such as the US elections and the COVID-19 pandemic, has a profound
impact on social stability and public health. Existing approaches for rumor
detection primarily rely on propagation graphs to enhance model effectiveness.
However, the presence of noisy and irrelevant structures during the propagation
process limits the efficacy of these approaches. To tackle this issue,
techniques such as weight adjustment and data augmentation have been proposed.
However, these techniques heavily depend on rich original propagation
structures, thus hindering performance when dealing with rumors that lack
sufficient propagation information in the early propagation stages. In this
paper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement
learning-based rumor detection framework that generates contextually coherent
and informative propagation patterns for events with insufficient topology
information, while also identifies indicative substructures for events with
redundant and noisy propagation structures. KPG consists of two key components:
the Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG
learns the latent distribution from refined propagation patterns, filtering out
noise and generating new candidates for ENS. Simultaneously, ENS identifies the
most influential substructures within propagation graphs and generates training
data for CRG. Moreover, we introduce an end-to-end framework that utilizes
rewards to guide the entire training process via a pre-trained graph neural
network. Extensive experiments conducted on four datasets demonstrate the
superiority of our KPG compared to the state-of-the-art approaches.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈáçÂ§ß‰∫ã‰ª∂Ôºà‰æãÂ¶ÇÁæéÂúãÈÅ∏ËàâÂíå COVID-19 Â§ßÊµÅË°åÔºâÊúüÈñìÔºåÁ§æ‰∫§Â™íÈ´îÂπ≥Âè∞‰∏äË¨†Ë®ÄÁöÑÊï£Â∏ÉÂ∞çÁ§æÊúÉÁ©©ÂÆöÂíåÂÖ¨ÂÖ±Ë°õÁîüÁî¢Áîü‰∫ÜÊ∑±ÈÅ†ÁöÑÂΩ±Èüø„ÄÇÁèæÊúâÁöÑË¨†Ë®ÄÊ™¢Ê∏¨ÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÂÇ≥Êí≠Âúñ‰æÜÊèêÈ´òÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÇ≥Êí≠ÈÅéÁ®ã‰∏≠Â≠òÂú®ÈõúË®äÂíåÁÑ°ÈóúÁµêÊßãÊúÉÈôêÂà∂ÈÄô‰∫õÊñπÊ≥ïÁöÑÊïàÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÂ∑≤Á∂ìÊèêÂá∫‰∫ÜÊ¨äÈáçË™øÊï¥ÂíåÊï∏ÊìöÊì¥ÂÖÖÁ≠âÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊäÄË°ìÂö¥Èáç‰æùË≥¥ÊñºË±êÂØåÁöÑÂéüÂßãÂÇ≥Êí≠ÁµêÊßãÔºåÂõ†Ê≠§Âú®ËôïÁêÜÂú®Êó©ÊúüÂÇ≥Êí≠ÈöéÊÆµÁº∫‰πèË∂≥Â§†ÂÇ≥Êí≠‰ø°ÊÅØÁöÑË¨†Ë®ÄÊôÇÊúÉÈòªÁ§ôÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈóúÈçµÂÇ≥Êí≠ÂúñÁîüÊàêÂô® (KPG)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÂº∑ÂåñÂ≠∏ÁøíÁöÑÊñ∞ÂûãË¨†Ë®ÄÊ™¢Ê∏¨Ê°ÜÊû∂ÔºåÂÆÉÁÇ∫ÊãìÊí≤‰ø°ÊÅØ‰∏çË∂≥ÁöÑ‰∫ã‰ª∂ÁîüÊàê‰∏ä‰∏ãÊñáÁõ∏Âπ≤‰∏î‰ø°ÊÅØË±êÂØåÁöÑÂÇ≥Êí≠Ê®°ÂºèÔºåÂêåÊôÇÈÇÑË≠òÂà•Âá∫ÂÖ∑ÊúâÂÜóÈ§òÂíåÈõúË®äÂÇ≥Êí≠ÁµêÊßãÁöÑ‰∫ã‰ª∂ÁöÑÊåáÁ§∫ÊÄßÂ≠êÁµêÊßã„ÄÇKPG ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºöÂÄôÈÅ∏ÈüøÊáâÁîüÊàêÂô® (CRG) ÂíåÁµêÊùüÁØÄÈªûÈÅ∏ÊìáÂô® (ENS)„ÄÇCRG ÂæûÁ≤æÁÖâÁöÑÂÇ≥Êí≠Ê®°Âºè‰∏≠Â≠∏ÁøíÊΩõÂú®ÂàÜ‰ΩàÔºåÈÅéÊøæÈõúË®ä‰∏¶ÁÇ∫ ENS ÁîüÊàêÊñ∞ÁöÑÂÄôÈÅ∏È†Ö„ÄÇÂêåÊôÇÔºåENS Ë≠òÂà•ÂÇ≥Êí≠Âúñ‰∏≠ÂΩ±ÈüøÊúÄÂ§ßÁöÑÂ≠êÁµêÊßãÔºå‰∏¶ÁÇ∫ CRG ÁîüÊàêË®ìÁ∑¥Êï∏Êìö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ´ØÂà∞Á´ØÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÁçéÂãµÈÄöÈÅéÈ†êË®ìÁ∑¥ÁöÑÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÊåáÂ∞éÊï¥ÂÄãË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÂú®ÂõõÂÄãÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄë KPG ËàáÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏ÊØîÁöÑÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**
2405.12711v2 by Meng Shang, Lenore Dedeyne, Jolan Dupont, Laura Vercauteren, Nadjia Amini, Laurence Lapauw, Evelien Gielen, Sabine Verschueren, Carolina Varon, Walter De Raedt, Bart Vanrumste

The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative
for older adults, aiming to enhance their strength and balance, and
consequently prevent falls. While Human Activity Recognition (HAR) systems have
been widely employed in recognizing the activities of individuals, existing
systems focus on the duration of macro activities (i.e. a sequence of
repetitions of the same exercise), neglecting the ability to discern micro
activities (i.e. the individual repetitions of the exercises), in the case of
OEP. This study presents a novel semi-supervised machine learning approach
aimed at bridging this gap in recognizing the micro activities of OEP. To
manage the limited dataset size, our model utilizes a Transformer encoder for
feature extraction, subsequently classified by a Temporal Convolutional Network
(TCN). Simultaneously, the Transformer encoder is employed for masked
unsupervised learning to reconstruct input signals. Results indicate that the
masked unsupervised learning task enhances the performance of the supervised
learning (classification task), as evidenced by f1-scores surpassing the
clinically applicable threshold of 0.8. From the micro activities, two
clinically relevant outcomes emerge: counting the number of repetitions of each
exercise and calculating the velocity during chair rising. These outcomes
enable the automatic monitoring of exercise intensity and difficulty in the
daily lives of older adults.

ÊëòË¶ÅÔºöÂ•ßÂ°îÂì•ÈÅãÂãïË®àÁï´ (OEP) ‰ΩúÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑÂæ©ÂÅ•Êé™ÊñΩÔºåÊúçÂãôÂ∞çË±°ÁÇ∫ËÄÅÂπ¥‰∫∫ÔºåÊó®Âú®Â¢ûÂº∑‰ªñÂÄëÁöÑËÇåÂäõÂíåÂπ≥Ë°°ÊÑüÔºåÈÄ≤ËÄåÈ†êÈò≤Ë∑åÂÄí„ÄÇÂÑòÁÆ°‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠ò (HAR) Á≥ªÁµ±Â∑≤Ë¢´Âª£Ê≥õÁî®ÊñºËæ®Ë≠òÂÄã‰∫∫ÁöÑÊ¥ªÂãïÔºå‰ΩÜÁèæÊúâÁ≥ªÁµ±ËëóÈáçÊñºÂ∑®ËßÄÊ¥ªÂãïÁöÑÊåÅÁ∫åÊôÇÈñìÔºàÂç≥ÈáçË§áÂü∑Ë°åÁõ∏ÂêåÈÅãÂãïÁöÑÈ†ÜÂ∫èÔºâÔºåÂøΩÁï•‰∫ÜËæ®Âà•ÂæÆËßÄÊ¥ªÂãïÔºàÂç≥ÈÅãÂãïÁöÑÂÄãÂà•ÈáçË§áÊ¨°Êï∏ÔºâÁöÑËÉΩÂäõÔºåÂ∞± OEP ËÄåË®Ä„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂçäÁõ£Áù£Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÊó®Âú®ÂΩåË£úËæ®Ë≠ò OEP ÂæÆËßÄÊ¥ªÂãïÁöÑÈÄô‰∏ÄÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜÁÆ°ÁêÜÊúâÈôêÁöÑË≥áÊñôÈõÜÂ§ßÂ∞èÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂà©Áî® Transformer Á∑®Á¢ºÂô®ÈÄ≤Ë°åÁâπÂæµËêÉÂèñÔºåÈö®ÂæåÁî±ÊôÇÂ∫èÂç∑Á©çÁ∂≤Ë∑Ø (TCN) ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂêåÊôÇÔºåTransformer Á∑®Á¢ºÂô®Áî®ÊñºÈÅÆËîΩÂºèÈùûÁõ£Áù£Â≠∏ÁøíÔºå‰ª•ÈáçÂª∫Ëº∏ÂÖ•Ë®äËôü„ÄÇÁµêÊûúË°®ÊòéÔºåÈÅÆËîΩÂºèÈùûÁõ£Áù£Â≠∏Áøí‰ªªÂãôÂ¢ûÂº∑‰∫ÜÁõ£Áù£Â≠∏ÁøíÔºàÂàÜÈ°û‰ªªÂãôÔºâÁöÑÊïàËÉΩÔºåÈÄôÁî± f1 ÂàÜÊï∏Ë∂ÖÈÅé 0.8 ÁöÑËá®Â∫äÈÅ©Áî®ÈñæÂÄºÊâÄË≠âÂØ¶„ÄÇÂæûÂæÆËßÄÊ¥ªÂãï‰∏≠ÔºåÂá∫Áèæ‰∫ÜÂÖ©ÂÄãËá®Â∫äÁõ∏ÈóúÁöÑÁµêÊûúÔºöË®àÁÆóÊØèÊ¨°ÈÅãÂãïÁöÑÈáçË§áÊ¨°Êï∏ÂíåË®àÁÆóÊ§ÖÂ≠ê‰∏äÂçáÊôÇÁöÑÈÄüÁéá„ÄÇÈÄô‰∫õÁµêÊûúËÉΩÂ§†Ëá™ÂãïÁõ£ÊéßËÄÅÂπ¥‰∫∫Âú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÁöÑÈÅãÂãïÂº∑Â∫¶ÂíåÈõ£Â∫¶„ÄÇ

##### **OLAPH: Improving Factuality in Biomedical Long-form Question Answering**
2405.12701v1 by Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang

In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate the automatic evaluations of
factuality. We also propose OLAPH, a simple and novel framework that enables
the improvement of factuality through automatic evaluations. The OLAPH
framework iteratively trains LLMs to mitigate hallucinations using sampling
predictions and preference optimization. In other words, we iteratively set the
highest-scoring response as a preferred response derived from sampling
predictions and train LLMs to align with the preferred response that improves
factuality. We highlight that, even on evaluation metrics not used during
training, LLMs trained with our OLAPH framework demonstrate significant
performance improvement in factuality. Our findings reveal that a 7B LLM
trained with our OLAPH framework can provide long answers comparable to the
medical experts' answers in terms of factuality. We believe that our work could
shed light on gauging the long-text generation ability of LLMs in the medical
domain. Our code and datasets are available at
https://github.com/dmis-lab/OLAPH}{https://github.com/dmis-lab/OLAPH.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÜ´ÁôÇÈ†òÂüüÔºåË®±Â§öÊÉÖÂ¢ÉÈÉΩÈúÄË¶ÅÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî¢ÁîüÈï∑ÁØáÊñáÂ≠óÁöÑËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®ÂõûÁ≠îÊÇ£ËÄÖÂïèÈ°åÊôÇÔºåÊ®°ÂûãÁöÑÂõûÊáâÂÇ≥ÈÅî‰∫ãÂØ¶ËÅ≤ÊòéËá≥ÈóúÈáçË¶ÅÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜËá™ÂãïÂåñÊñπÊ≥ï‰æÜË©ï‰º∞ÈÄô‰∫õËÅ≤ÊòéÁöÑÂøÖË¶ÅÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MedLFQAÔºåÈÄôÊòØ‰∏ÄÂÄã‰ΩøÁî®ËàáÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁõ∏ÈóúÁöÑÈï∑ÁØáÂïèÁ≠îË≥áÊñôÈõÜÈáçÂª∫ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ„ÄÇÊàëÂÄë‰ΩøÁî® MedLFQA ‰æÜ‰øÉÈÄ≤‰∫ãÂØ¶ÊÄßÁöÑËá™ÂãïË©ï‰º∞„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÊñ∞Á©éÁöÑÊ°ÜÊû∂ OLAPHÔºåÂÆÉËÉΩÂ§†ÈÄèÈÅéËá™ÂãïË©ï‰º∞‰æÜÊîπÂñÑ‰∫ãÂØ¶ÊÄß„ÄÇOLAPH Ê°ÜÊû∂ÂèçË¶ÜË®ìÁ∑¥ LLMÔºå‰ª•‰ΩøÁî®ÊäΩÊ®£È†êÊ∏¨ÂíåÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰æÜÊ∏õËºïÂπªË¶∫„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÂèçË¶ÜÂ∞áÊúÄÈ´òÂàÜÂõûÊáâË®≠ÂÆöÁÇ∫ÂæûÊäΩÊ®£È†êÊ∏¨‰∏≠ÂæóÂá∫ÁöÑÈ¶ñÈÅ∏ÂõûÊáâÔºå‰∏¶Ë®ìÁ∑¥ LLM ËàáÊîπÂñÑ‰∫ãÂØ¶ÊÄßÁöÑÈ¶ñÈÅ∏ÂõûÊáâ‰øùÊåÅ‰∏ÄËá¥„ÄÇÊàëÂÄëÂº∑Ë™øÔºåÂç≥‰ΩøÂú®Ë®ìÁ∑¥ÊúüÈñìÊú™‰ΩøÁî®Ë©ï‰º∞ÊåáÊ®ôÔºå‰ΩøÁî®ÊàëÂÄëÁöÑ OLAPH Ê°ÜÊû∂Ë®ìÁ∑¥ÁöÑ LLM ‰πüÂú®‰∫ãÂØ¶ÊÄßÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®ÊàëÂÄëÁöÑ OLAPH Ê°ÜÊû∂Ë®ìÁ∑¥ÁöÑ 7B LLM Âú®‰∫ãÂØ¶ÊÄßÊñπÈù¢ÂèØ‰ª•Êèê‰æõËàáÈÜ´ÁôÇÂ∞àÂÆ∂Á≠îÊ°àÁõ∏Áï∂ÁöÑÈï∑ÁØáÂõûÁ≠î„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØ‰ª•Âπ´Âä©Ë©ï‰º∞ LLM Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÈï∑ÁØáÊñáÂ≠óÁî¢ÁîüËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂèØÂú® https://github.com/dmis-lab/OLAPH Áç≤Âæó„ÄÇ</paragraph>

##### **Exploration of Masked and Causal Language Modelling for Text Generation**
2405.12630v1 by Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic

Large Language Models (LLMs) have revolutionised the field of Natural
Language Processing (NLP) and have achieved state-of-the-art performance in
practically every task in this field. However, the prevalent approach used in
text generation, Causal Language Modelling (CLM), which generates text
sequentially from left to right, inherently limits the freedom of the model,
which does not decide when and where each token is generated. In contrast,
Masked Language Modelling (MLM), primarily used for language understanding
tasks, can generate tokens anywhere in the text and any order. This paper
conducts an extensive comparison of MLM and CLM approaches for text generation
tasks. To do so, we pre-train several language models of comparable sizes on
three different datasets, namely 1) medical discharge summaries, 2) movie plot
synopses, and 3) authorship verification datasets. To assess the quality of the
generations, we first employ quantitative metrics and then perform a
qualitative human evaluation to analyse coherence and grammatical correctness.
In addition, we evaluate the usefulness of the generated texts by using them in
three different downstream tasks: 1) Entity Recognition, 2) Text
Classification, and 3) Authorship Verification. The results show that MLM
consistently outperforms CLM in text generation across all datasets, with
higher quantitative scores and better coherence in the generated text. The
study also finds \textit{no strong correlation} between the quality of the
generated text and the performance of the models in the downstream tasks. With
this study, we show that MLM for text generation has great potential for future
research and provides direction for future studies in this area.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) È†òÂüüÔºå‰∏¶Âú®Ë©≤È†òÂüüÁöÑÂπæ‰πéÊØè‰∏ÄÈ†Ö‰ªªÂãô‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊñáÊú¨ÁîüÊàê‰∏≠‰ΩøÁî®ÁöÑÊµÅË°åÊñπÊ≥ïÂõ†ÊûúË™ûË®ÄÂª∫Ê®° (CLM)ÔºåÂÆÉÂæûÂ∑¶Âà∞Âè≥ÊåâÈ†ÜÂ∫èÁîüÊàêÊñáÊú¨ÔºåÂæûÊú¨Ë≥™‰∏äÈôêÂà∂‰∫ÜÊ®°ÂûãÁöÑËá™Áî±Â∫¶ÔºåÂÆÉ‰∏çÊúÉÊ±∫ÂÆö‰ΩïÊôÇ‰ΩïÂú∞ÁîüÊàêÊØèÂÄãÁ¨¶Ëôü„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∏ªË¶ÅÁî®ÊñºË™ûË®ÄÁêÜËß£‰ªªÂãôÁöÑÈÅÆÁΩ©Ë™ûË®ÄÂª∫Ê®° (MLM) ÂèØ‰ª•Êåâ‰ªª‰ΩïÈ†ÜÂ∫èÂú®ÊñáÊú¨‰∏≠ÁöÑ‰ªª‰Ωï‰ΩçÁΩÆÁîüÊàêÁ¨¶Ëôü„ÄÇÊú¨ÊñáÂ∞ç MLM Âíå CLM ÊñπÊ≥ïÂú®ÊñáÊú¨ÁîüÊàê‰ªªÂãô‰∏≠ÁöÑÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÊØîËºÉ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂú®‰∏âÂÄã‰∏çÂêåÁöÑÊï∏ÊìöÈõÜ‰∏äÈ†êË®ìÁ∑¥‰∫ÜÂπæÂÄãÂ§ßÂ∞èÁõ∏Áï∂ÁöÑË™ûË®ÄÊ®°ÂûãÔºåÂç≥ 1) ÈÜ´ÁôÇÂá∫Èô¢ÊëòË¶Å„ÄÅ2) ÈõªÂΩ±ÊÉÖÁØÄÁ∞°‰ªãÂíå 3) ‰ΩúËÄÖÈ©óË≠âÊï∏ÊìöÈõÜ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÁîüÊàêÁöÑË≥™ÈáèÔºåÊàëÂÄëÈ¶ñÂÖàÊé°Áî®ÂÆöÈáèÊåáÊ®ôÔºåÁÑ∂ÂæåÈÄ≤Ë°åÂÆöÊÄßÁöÑ‰∫∫Â∑•Ë©ï‰º∞Ôºå‰ª•ÂàÜÊûêÈÄ£Ë≤´ÊÄßÂíåË™ûÊ≥ïÊ≠£Á¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄöÈÅéÂú®‰∏âÂÄã‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠‰ΩøÁî®ÁîüÊàêÁöÑÊñáÊú¨‰æÜË©ï‰º∞ÂÖ∂ÊúâÁî®ÊÄßÔºö1) ÂØ¶È´îË≠òÂà•„ÄÅ2) ÊñáÊú¨ÂàÜÈ°ûÂíå 3) ‰ΩúËÄÖÈ©óË≠â„ÄÇÁµêÊûúË°®ÊòéÔºåMLM Âú®ÊâÄÊúâÊï∏ÊìöÈõÜ‰∏äÁöÑÊñáÊú¨ÁîüÊàê‰∏≠ÂßãÁµÇÂÑ™Êñº CLMÔºåÁîüÊàêÁöÑÊñáÊú¨ÂÖ∑ÊúâÊõ¥È´òÁöÑÂÆöÈáèÂàÜÊï∏ÂíåÊõ¥Â•ΩÁöÑÈÄ£Ë≤´ÊÄß„ÄÇË©≤Á†îÁ©∂ÈÇÑÁôºÁèæÁîüÊàêÁöÑÊñáÊú¨Ë≥™ÈáèËàáÊ®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÊÄßËÉΩ‰πãÈñì\textit{Ê≤íÊúâÂº∑Áõ∏ÈóúÊÄß}„ÄÇÈÄöÈÅéÈÄôÈ†ÖÁ†îÁ©∂ÔºåÊàëÂÄëË°®ÊòéÊñáÊú¨ÁîüÊàêÁöÑ MLM Â∞çÊñºÊú™‰æÜÁöÑÁ†îÁ©∂ÂÖ∑ÊúâÂ∑®Â§ßÊΩõÂäõÔºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÊñπÂêë„ÄÇ</paragraph>

##### **DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**
2405.12541v1 by Bufang Yang, Siyang Jiang, Lilin Xu, Kaiwei Liu, Hai Li, Guoliang Xing, Hongkai Chen, Xiaofan Jiang, Zhenyu Yan

Large language models (LLMs) have the potential to transform digital
healthcare, as evidenced by recent advances in LLM-based virtual doctors.
However, current approaches rely on patient's subjective descriptions of
symptoms, causing increased misdiagnosis. Recognizing the value of daily data
from smart devices, we introduce a novel LLM-based multi-turn consultation
virtual doctor system, DrHouse, which incorporates three significant
contributions: 1) It utilizes sensor data from smart devices in the diagnosis
process, enhancing accuracy and reliability. 2) DrHouse leverages continuously
updating medical databases such as Up-to-Date and PubMed to ensure our model
remains at diagnostic standard's forefront. 3) DrHouse introduces a novel
diagnostic algorithm that concurrently evaluates potential diseases and their
likelihood, facilitating more nuanced and informed medical assessments. Through
multi-turn interactions, DrHouse determines the next steps, such as accessing
daily data from smart devices or requesting in-lab tests, and progressively
refines its diagnoses. Evaluations on three public datasets and our
self-collected datasets show that DrHouse can achieve up to an 18.8% increase
in diagnosis accuracy over the state-of-the-art baselines. The results of a
32-participant user study show that 75% medical experts and 91.7% patients are
willing to use DrHouse.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúâÊΩõÂäõËΩâËÆäÊï∏‰ΩçÈÜ´ÁôÇ‰øùÂÅ•ÔºåÈÄôÈªûÂæû LLM ÁÇ∫Âü∫Á§éÁöÑËôõÊì¨ÈÜ´Â∏´ÊúÄËøëÁöÑÈÄ≤Â±ï‰∏≠Â∞±ËÉΩÁúãÂá∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÂÅöÊ≥ï‰æùË≥¥ÊñºÊÇ£ËÄÖ‰∏ªËßÄÁöÑÁóáÁãÄÊèèËø∞ÔºåÂ∞éËá¥Ë™§Ë®∫Â¢ûÂä†„ÄÇÊàëÂÄëË™çË≠òÂà∞‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊØèÊó•Ë≥áÊñôÂÉπÂÄºÔºåÂõ†Ê≠§ÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÊñ∞Á©éÁöÑ LLM ÁÇ∫Âü∫Á§éÁöÑÂ§öËº™Ë´ÆË©¢ËôõÊì¨ÈÜ´Â∏´Á≥ªÁµ± DrHouseÔºåÂÆÉÂåÖÂê´‰∏âÂÄãÈáçË¶ÅÁöÑË≤¢ÁçªÔºö1) ÂÆÉÂú®Ë®∫Êñ∑ÈÅéÁ®ã‰∏≠Âà©Áî®‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊÑüÊ∏¨Âô®Ë≥áÊñôÔºåÊèêÂçáÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†Â∫¶„ÄÇ2) DrHouse ÂÖÖÂàÜÂà©Áî®ÊåÅÁ∫åÊõ¥Êñ∞ÁöÑÈÜ´ÁôÇË≥áÊñôÂ∫´Ôºå‰æãÂ¶Ç Up-to-Date Âíå PubMedÔºå‰ª•Á¢∫‰øùÊàëÂÄëÁöÑÊ®°ÂûãÁ∂≠ÊåÅÂú®Ë®∫Êñ∑Ê®ôÊ∫ñÁöÑÊúÄÂâçÁ∑ö„ÄÇ3) DrHouse ÂºïÈÄ≤‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®∫Êñ∑ÊºîÁÆóÊ≥ïÔºåÂÆÉÂêåÊôÇË©ï‰º∞ÊΩõÂú®ÁñæÁóÖÂèäÂÖ∂ÂèØËÉΩÊÄßÔºå‰øÉÈÄ≤Êõ¥Á¥∞Á∑ª‰∏îÊòéÊô∫ÁöÑÈÜ´ÁôÇË©ï‰º∞„ÄÇÈÄèÈÅéÂ§öËº™‰∫íÂãïÔºåDrHouse Ê±∫ÂÆö‰∏ã‰∏ÄÊ≠•Ôºå‰æãÂ¶ÇÂèñÂæó‰æÜËá™Êô∫ÊÖßË£ùÁΩÆÁöÑÊØèÊó•Ë≥áÊñôÊàñË¶ÅÊ±ÇÂØ¶È©óÂÆ§Ê™¢È©óÔºå‰∏¶ÈÄêÊ≠•ÊîπÂñÑÂÖ∂Ë®∫Êñ∑„ÄÇÈáùÂ∞ç‰∏âÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜÂíåÊàëÂÄëËá™Ë°åÊî∂ÈõÜÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åË©ï‰º∞È°ØÁ§∫ÔºåDrHouse Âú®Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂèØ‰ª•ÊØîÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁ∑öÊèêÈ´ò 18.8%„ÄÇ‰∏ÄÂÄãÊúâ 32 ‰ΩçÂèÉËàáËÄÖÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå75% ÁöÑÈÜ´ÁôÇÂ∞àÂÆ∂Âíå 91.7% ÁöÑÊÇ£ËÄÖÈ°òÊÑè‰ΩøÁî® DrHouse„ÄÇ

##### **A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis**
2405.13082v1 by Haocong Rao, Minlin Zeng, Xuejiao Zhao, Chunyan Miao

Recent years have witnessed an increasing global population affected by
neurodegenerative diseases (NDs), which traditionally require extensive
healthcare resources and human effort for medical diagnosis and monitoring. As
a crucial disease-related motor symptom, human gait can be exploited to
characterize different NDs. The current advances in artificial intelligence
(AI) models enable automatic gait analysis for NDs identification and
classification, opening a new avenue to facilitate faster and more
cost-effective diagnosis of NDs. In this paper, we provide a comprehensive
survey on recent progress of machine learning and deep learning based AI
techniques applied to diagnosis of five typical NDs through gait. We provide an
overview of the process of AI-assisted NDs diagnosis, and present a systematic
taxonomy of existing gait data and AI models. Through an extensive review and
analysis of 164 studies, we identify and discuss the challenges, potential
solutions, and future directions in this field. Finally, we envision the
prospective utilization of 3D skeleton data for human gait representation and
the development of more efficient AI models for NDs diagnosis. We provide a
public resource repository to track and facilitate developments in this
emerging field: https://github.com/Kali-Hac/AI4NDD-Survey.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂèóÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ (NDs) ÂΩ±ÈüøÁöÑÂÖ®ÁêÉ‰∫∫Âè£ÊåÅÁ∫åÂ¢ûÂä†ÔºåÈÄô‰∫õÁñæÁóÖÂú®ÂÇ≥Áµ±‰∏äÈúÄË¶ÅÂ§ßÈáèÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊ∫êÂíå‰∫∫ÂäõÈÄ≤Ë°åÈÜ´ÁôÇË®∫Êñ∑ÂíåÁõ£Ê∏¨„ÄÇ‰ΩúÁÇ∫‰∏ÄÁ®ÆËàáÁñæÁóÖÁõ∏ÈóúÁöÑÈáçË¶ÅÈÅãÂãïÁóáÁãÄÔºå‰∫∫È°ûÊ≠•ÊÖãÂèØÁî®ÊñºË°®Âæµ‰∏çÂêåÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøËá™ÂãïÊ≠•ÊÖãÂàÜÊûêËÉΩÂ§†Ë≠òÂà•ÂíåÂàÜÈ°ûÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÔºåÁÇ∫Âä†ÈÄüÂíåÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖË®∫Êñ∑ÈñãÈó¢‰∫Ü‰∏ÄÊ¢ùÊñ∞ÈÄîÂæë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊáâÁî®ÊñºÈÄöÈÅéÊ≠•ÊÖãË®∫Êñ∑‰∫îÁ®ÆÂÖ∏ÂûãÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËºîÂä©Á•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖË®∫Êñ∑ÁöÑÈÅéÁ®ãÔºå‰∏¶Â∞çÁèæÊúâÁöÑÊ≠•ÊÖãÊï∏ÊìöÂíå‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÊèêÂá∫‰∫ÜÁ≥ªÁµ±ÂàÜÈ°û„ÄÇÈÄöÈÅéÂ∞ç 164 È†ÖÁ†îÁ©∂ÁöÑÂª£Ê≥õÂõûÈ°ßÂíåÂàÜÊûêÔºåÊàëÂÄëÊâæÂá∫‰∏¶Ë®éË´ñ‰∫ÜÈÄô‰∏ÄÈ†òÂüüÁöÑÊåëÊà∞„ÄÅÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÂíåÊú™‰æÜÊñπÂêë„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®≠ÊÉ≥Êú™‰æÜÂ∞áÂà©Áî® 3D È™®Êû∂Êï∏Êìö‰æÜË°®Á§∫‰∫∫È°ûÊ≠•ÊÖãÔºå‰∏¶ÈñãÁôºÊõ¥ÊúâÊïàÁöÑ AI Ê®°Âûã‰æÜË®∫Êñ∑Á•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ¨ÂÖ±Ë≥áÊ∫êÂ∫´‰æÜËøΩËπ§Âíå‰øÉÈÄ≤ÈÄô‰∏ÄÊñ∞ËààÈ†òÂüüÁöÑÁôºÂ±ïÔºöhttps://github.com/Kali-Hac/AI4NDD-Survey„ÄÇ</paragraph>

##### **Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity**
2405.12514v2 by Pat Pataranutaporn, Kavin Winson, Peggy Yin, Auttasak Lapapirojn, Pichayoot Ouppaphan, Monchai Lertsutthiwong, Pattie Maes, Hal Hershfield

We introduce "Future You," an interactive, brief, single-session, digital
chat intervention designed to improve future self-continuity--the degree of
connection an individual feels with a temporally distant future self--a
characteristic that is positively related to mental health and wellbeing. Our
system allows users to chat with a relatable yet AI-powered virtual version of
their future selves that is tuned to their future goals and personal qualities.
To make the conversation realistic, the system generates a "synthetic
memory"--a unique backstory for each user--that creates a throughline between
the user's present age (between 18-30) and their life at age 60. The "Future
You" character also adopts the persona of an age-progressed image of the user's
present self. After a brief interaction with the "Future You" character, users
reported decreased anxiety, and increased future self-continuity. This is the
first study successfully demonstrating the use of personalized AI-generated
characters to improve users' future self-continuity and wellbeing.

ÊëòË¶ÅÔºöÊàëÂÄëÊé®Âá∫„ÄåÊú™‰æÜ‰Ω†„ÄçÔºå‰∏ÄÁ®Æ‰∫íÂãïÂºè„ÄÅÁ∞°Áü≠„ÄÅÂñÆ‰∏ÄÊúÉË©±ÁöÑÊï∏‰ΩçËÅäÂ§©‰ªãÂÖ•ÔºåÊó®Âú®ÊèêÂçáÊú™‰æÜÁöÑËá™ÊàëÈÄ£Á∫åÊÄßÔºå‰πüÂ∞±ÊòØÂÄã‰∫∫ËàáÊôÇÈñì‰∏äÈÅôÈÅ†ÁöÑÊú™‰æÜËá™Êàë‰πãÈñìÊÑüÂèóÂà∞ÁöÑÈÄ£ÁµêÁ®ãÂ∫¶ÔºåÈÄôÈ†ÖÁâπË≥™ËàáÂøÉÁêÜÂÅ•Â∫∑ÂíåÂπ∏Á¶èÊÑüÂëàÊ≠£Áõ∏Èóú„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ËÆì‰ΩøÁî®ËÄÖÂèØ‰ª•Ëàá‰∏ÄÂÄãË¶™ÂàáÔºå‰ΩÜÁî± AI È©ÖÂãïÁöÑËôõÊì¨Êú™‰æÜËá™ÊàëÁâàÊú¨ËÅäÂ§©ÔºåÈÄôÂÄãÁâàÊú¨Ê†πÊìö‰ΩøÁî®ËÄÖÁöÑÊú™‰æÜÁõÆÊ®ôÂíåÂÄã‰∫∫ÁâπË≥™ÈÄ≤Ë°åË™øÊï¥„ÄÇÁÇ∫‰∫ÜËÆìÂ∞çË©±Êõ¥ÁúüÂØ¶ÔºåÁ≥ªÁµ±ÊúÉÁî¢Áîü‰∏ÄÂÄã„ÄåÂêàÊàêË®òÊÜ∂„ÄçÔºå‰πüÂ∞±ÊòØÊØè‰Ωç‰ΩøÁî®ËÄÖÁöÑÁç®ÁâπËÉåÊôØÊïÖ‰∫ãÔºåÂú®‰ΩøÁî®ËÄÖÁõÆÂâçÁöÑÂπ¥ÈΩ°Ôºà18-30 Ê≠≤ÔºâÂíå 60 Ê≠≤ÁöÑÁîüÊ¥ª‰πãÈñìÂª∫Á´ã‰∏ÄÊ¢ùË≤´Á©øÁ∑ö„ÄÇ„ÄåÊú™‰æÜ‰Ω†„ÄçËßíËâ≤‰πüÊúÉÊé°Áî®‰ΩøÁî®ËÄÖÁõÆÂâçËá™ÊàëÁöÑÂπ¥ÈΩ°ÈÄ≤Â±ïÂΩ±ÂÉèÁöÑ‰∫∫Ê†º„ÄÇËàá„ÄåÊú™‰æÜ‰Ω†„ÄçËßíËâ≤ÈÄ≤Ë°åÁ∞°Áü≠‰∫íÂãïÂæåÔºå‰ΩøÁî®ËÄÖÂõûÂ†±ÁÑ¶ÊÖÆÊÑüÈôç‰ΩéÔºåÊú™‰æÜÁöÑËá™ÊàëÈÄ£Á∫åÊÄßÂ¢ûÂä†„ÄÇÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊàêÂäüÂ±ïÁ§∫‰ΩøÁî®ÂÄã‰∫∫Âåñ AI ÁîüÊàêÁöÑËßíËâ≤‰æÜÊèêÂçá‰ΩøÁî®ËÄÖÊú™‰æÜËá™ÊàëÈÄ£Á∫åÊÄßÂíåÂπ∏Á¶èÊÑüÁöÑÊ°à‰æãÁ†îÁ©∂„ÄÇ

##### **Ensuring Ground Truth Accuracy in Healthcare with the EVINCE framework**
2405.15808v2 by Edward Y. Chang

Misdiagnosis is a significant issue in healthcare, leading to harmful
consequences for patients. The propagation of mislabeled data through machine
learning models into clinical practice is unacceptable. This paper proposes
EVINCE, a system designed to 1) improve diagnosis accuracy and 2) rectify
misdiagnoses and minimize training data errors. EVINCE stands for Entropy
Variation through Information Duality with Equal Competence, leveraging this
novel theory to optimize the diagnostic process using multiple Large Language
Models (LLMs) in a structured debate framework. Our empirical study verifies
EVINCE to be effective in achieving its design goals.

ÊëòË¶ÅÔºöË™§Ë®∫ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈáçÂ§ßÂïèÈ°åÔºåÊúÉÂ∞çÊÇ£ËÄÖÈÄ†ÊàêÊúâÂÆ≥ÂæåÊûú„ÄÇÂ∞áÈåØË™§Ê®ôË®òÁöÑË≥áÊñôÈÄèÈÅéÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂÇ≥Êí≠Âà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÊòØ‰∏çÂèØÊé•ÂèóÁöÑ„ÄÇÊú¨ÊñáÊèêÂá∫ EVINCEÔºå‰∏ÄÂÄãÊó®Âú® 1) ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÔºå‰ª•Âèä 2) Á≥æÊ≠£Ë™§Ë®∫‰∏¶Â∞áË®ìÁ∑¥Ë≥áÊñôÈåØË™§ÈôçËá≥ÊúÄ‰ΩéÁöÑÁ≥ªÁµ±„ÄÇEVINCE ÊòØ Entropy Variation through Information Duality with Equal Competence ÁöÑÁ∏ÆÂØ´ÔºåÂà©Áî®Ê≠§ÂâµÊñ∞ÁêÜË´ñÂú®ÁµêÊßãÂåñÁöÑËæØË´ñÊû∂Êßã‰∏≠‰ΩøÁî®Â§öÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÊúÄ‰Ω≥ÂåñË®∫Êñ∑ÊµÅÁ®ã„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂È©óË≠â EVINCE Âú®ÈÅîÊàêÂÖ∂Ë®≠Ë®àÁõÆÊ®ôÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇ

##### **Digital Health and Indoor Air Quality: An IoT-Driven Human-Centred Visualisation Platform for Behavioural Change and Technology Acceptance**
2405.13064v1 by Rameez Raja Kureshi, Bhupesh Kumar Mishra, Dhavalkumar Thakker, Suvodeep Mazumdar, Xiao Li

The detrimental effects of air pollutants on human health have prompted
increasing concerns regarding indoor air quality (IAQ). The emergence of
digital health interventions and citizen science initiatives has provided new
avenues for raising awareness, improving IAQ, and promoting behavioural
changes. The Technology Acceptance Model (TAM) offers a theoretical framework
to understand user acceptance and adoption of IAQ technology. This paper
presents a case study using the COM-B model and Internet of Things (IoT)
technology to design a human-centred digital visualisation platform, leading to
behavioural changes and improved IAQ. The study also investigates users'
acceptance and adoption of the technology, focusing on their experiences,
expectations, and the impact on IAQ. Integrating IAQ sensing, digital
health-related interventions, citizen science, and the TAM model offers
opportunities to address IAQ challenges, enhance public health, and foster
sustainable indoor environments. The analytical results show that factors such
as human behaviour, indoor activities, and awareness play crucial roles in
shaping IAQ.

ÊëòË¶ÅÔºöÁ©∫Ê∞îÊ±°ÊüìÁâ©ÂØπ‰∫∫‰ΩìÂÅ•Â∫∑ÁöÑ‰∏çÂà©ÂΩ±ÂìçÂºïÂèë‰∫Ü‰∫∫‰ª¨ÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè (IAQ) ÁöÑÊó•ÁõäÊãÖÂøß„ÄÇÊï∞Â≠óÂÅ•Â∫∑Âπ≤È¢ÑÊé™ÊñΩÂíåÂÖ¨Ê∞ëÁßëÂ≠¶ÂÄ°ËÆÆÁöÑÂá∫Áé∞‰∏∫ÊèêÈ´òËÆ§ËØÜ„ÄÅÊîπÂñÑÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÂíå‰øÉËøõË°å‰∏∫ÊîπÂèòÊèê‰æõ‰∫ÜÊñ∞ÈÄîÂæÑ„ÄÇÊäÄÊúØÊé•ÂèóÊ®°Âûã (TAM) Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁêÜËÆ∫Ê°ÜÊû∂ÔºåÁî®‰∫éÁêÜËß£Áî®Êà∑ÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊäÄÊúØÁöÑÊé•ÂèóÂíåÈááÁî®„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ê°à‰æãÁ†îÁ©∂Ôºå‰ΩøÁî® COM-B Ê®°ÂûãÂíåÁâ©ËÅîÁΩë (IoT) ÊäÄÊúØÊù•ËÆæËÆ°‰∏Ä‰∏™‰ª•‰∫∫‰∏∫‰∏≠ÂøÉÁöÑÊï∞Â≠óÂèØËßÜÂåñÂπ≥Âè∞Ôºå‰ªéËÄåÂØºËá¥Ë°å‰∏∫ÊîπÂèòÂíåÊîπÂñÑÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè„ÄÇËØ•Á†îÁ©∂ËøòË∞ÉÊü•‰∫ÜÁî®Êà∑ÂØπËØ•ÊäÄÊúØÁöÑÊé•ÂèóÂíåÈááÁî®ÊÉÖÂÜµÔºåÈáçÁÇπÂÖ≥Ê≥®‰ªñ‰ª¨ÁöÑÁªèÈ™å„ÄÅÊúüÊúõÂíåÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÁöÑÂΩ±Âìç„ÄÇÊï¥ÂêàÂÆ§ÂÜÖÁ©∫Ê∞îË¥®Èáè‰º†ÊÑü„ÄÅÊï∞Â≠óÂÅ•Â∫∑Áõ∏ÂÖ≥Âπ≤È¢ÑÊé™ÊñΩ„ÄÅÂÖ¨Ê∞ëÁßëÂ≠¶ÂíåÊäÄÊúØÊé•ÂèóÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∫îÂØπÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊåëÊàò„ÄÅÂ¢ûÂº∫ÂÖ¨ÂÖ±Âç´ÁîüÂíå‰øÉËøõÂèØÊåÅÁª≠ÂÆ§ÂÜÖÁéØÂ¢ÉÁöÑÊú∫‰ºö„ÄÇÂàÜÊûêÁªìÊûúË°®ÊòéÔºå‰∫∫Á±ªË°å‰∏∫„ÄÅÂÆ§ÂÜÖÊ¥ªÂä®ÂíåÊÑèËØÜÁ≠âÂõ†Á¥†Âú®Â°ëÈÄ†ÂÆ§ÂÜÖÁ©∫Ê∞îË¥®ÈáèÊñπÈù¢ÂèëÊå•ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇ

##### **Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**
2405.11967v1 by Tatiana V. Afanasieva, Pavel V. Platov, Anastasia I. Medvedeva

One of the new trends in the development of recommendation algorithms is the
dissemination of their capabilities to support the population in managing their
health. This article focuses on the problem of improving the effectiveness of
cardiovascular diseases (CVD) prevention, since CVD is the leading cause of
death worldwide. To address this issue, a knowledge-based recommendation
algorithm was proposed to support self-management of CVD risk factors in adults
at home. The proposed algorithm is based on the original multidimensional
recommendation model and on a new user profile model, which includes predictive
assessments of CVD health in addition to its current ones as outlined in
official guidelines. The main feature of the proposed algorithm is the
combination of rule-based logic with the capabilities of a large language model
in generating human-like text for explanatory component of multidimensional
recommendation. The verification and evaluation of the proposed algorithm
showed the usefulness of the proposed recommendation algorithm for supporting
adults in self-management of their CVD risk factors at home. As follows from
the comparison with similar knowledge-based recommendation algorithms, the
proposed algorithm evaluates a larger number of CVD risk factors and has a
greater information and semantic capacity of the generated recommendations.

ÊëòË¶ÅÔºöÊé®Ëñ¶ÊºîÁÆóÊ≥ïÁôºÂ±ïÁöÑÊñ∞Ë∂®Âã¢‰πã‰∏ÄÊòØÂÇ≥Êí≠ÂÖ∂ËÉΩÂäõÔºå‰ª•ÂçîÂä©Ê∞ëÁúæÁÆ°ÁêÜËá™Ë∫´ÂÅ•Â∫∑„ÄÇÊú¨ÊñáÈáçÈªûÊé¢Ë®éÊîπÂñÑÂøÉË°ÄÁÆ°ÁñæÁóÖÔºàCVDÔºâÈ†êÈò≤ÁöÑÊúâÊïàÊÄßÔºåÂõ†ÁÇ∫ CVD ÊòØÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁü•Ë≠òÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰ª•Âú®ÂÆ∂‰∏≠ÊîØÊè¥Êàê‰∫∫Ëá™ÊàëÁÆ°ÁêÜ CVD È¢®Èö™Âõ†Â≠ê„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÂü∫ÊñºÂéüÂßãÁöÑÂ§öÁ∂≠Â∫¶Êé®Ëñ¶Ê®°ÂûãÂíåÊñ∞ÁöÑ‰ΩøÁî®ËÄÖËº™ÂªìÊ®°ÂûãÔºåÂÖ∂‰∏≠Èô§‰∫ÜÂÆòÊñπÊåáÂçó‰∏≠Ê¶ÇËø∞ÁöÑÁèæÊúâË©ï‰º∞Â§ñÔºåÈÇÑÂåÖÊã¨ CVD ÂÅ•Â∫∑ÁöÑÈ†êÊ∏¨Ë©ï‰º∞„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ï‰∏ªË¶ÅÁâπËâ≤ÊòØÂ∞áÂü∫ÊñºË¶èÂâáÁöÑÈÇèËºØËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËÉΩÂäõÁõ∏ÁµêÂêàÔºå‰ª•Áî¢ÁîüÈ°û‰∫∫ÊñáÂ≠óÔºå‰ΩúÁÇ∫Â§öÁ∂≠Â∫¶Êé®Ëñ¶ÁöÑË™™ÊòéÊÄßÁµÑÊàêÈÉ®ÂàÜ„ÄÇÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÁöÑÈ©óË≠âÂíåË©ï‰º∞È°ØÁ§∫ÔºåÊâÄÊèêÂá∫ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÂú®ÂçîÂä©Êàê‰∫∫Âú®ÂÆ∂‰∏≠Ëá™ÊàëÁÆ°ÁêÜÂÖ∂ CVD È¢®Èö™Âõ†Â≠êÊñπÈù¢ÂæàÊúâÁî®„ÄÇÂæûËàáÈ°û‰ººÁöÑÂü∫ÊñºÁü•Ë≠òÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÁöÑÊØîËºÉ‰∏≠ÂæóÁü•ÔºåÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïË©ï‰º∞‰∫ÜÊõ¥Â§ö CVD È¢®Èö™Âõ†Â≠êÔºå‰∏¶‰∏îÁî¢ÁîüÁöÑÂª∫Ë≠∞ÂÖ∑ÊúâÊõ¥Â§ßÁöÑË≥áË®äÂíåË™ûÁæ©ÂÆπÈáè„ÄÇ

##### **Contactless Polysomnography: What Radio Waves Tell Us about Sleep**
2405.11739v1 by Hao He, Chao Li, Wolfgang Ganglberger, Kaileigh Gallagher, Rumen Hristov, Michail Ouroutzoglou, Haoqi Sun, Jimeng Sun, Brandon Westover, Dina Katabi

The ability to assess sleep at home, capture sleep stages, and detect the
occurrence of apnea (without on-body sensors) simply by analyzing the radio
waves bouncing off people's bodies while they sleep is quite powerful. Such a
capability would allow for longitudinal data collection in patients' homes,
informing our understanding of sleep and its interaction with various diseases
and their therapeutic responses, both in clinical trials and routine care. In
this article, we develop an advanced machine learning algorithm for passively
monitoring sleep and nocturnal breathing from radio waves reflected off people
while asleep. Validation results in comparison with the gold standard (i.e.,
polysomnography) (n=849) demonstrate that the model captures the sleep
hypnogram (with an accuracy of 81% for 30-second epochs categorized into Wake,
Light Sleep, Deep Sleep, or REM), detects sleep apnea (AUROC = 0.88), and
measures the patient's Apnea-Hypopnea Index (ICC=0.95; 95% CI = [0.93, 0.97]).
Notably, the model exhibits equitable performance across race, sex, and age.
Moreover, the model uncovers informative interactions between sleep stages and
a range of diseases including neurological, psychiatric, cardiovascular, and
immunological disorders. These findings not only hold promise for clinical
practice and interventional trials but also underscore the significance of
sleep as a fundamental component in understanding and managing various
diseases.

ÊëòË¶ÅÔºö<paragraph>ÂÉÖÈÄèÈÅéÂàÜÊûê‰∫∫ÂÄëÁù°Ë¶∫ÊôÇÂæûË∫´È´îÂèçÂ∞ÑÁöÑÁÑ°Á∑öÈõªÊ≥¢ÔºåÂ∞±ËÉΩË©ï‰º∞Â±ÖÂÆ∂Áù°Áú†„ÄÅÊçïÊçâÁù°Áú†ÈöéÊÆµ‰∏¶ÂÅµÊ∏¨ÂëºÂê∏‰∏≠Ê≠¢ÔºàÁÑ°ÈúÄÈÖçÊà¥Ë∫´È´îÊÑüÊ∏¨Âô®ÔºâÁöÑËÉΩÂäõÈùûÂ∏∏Âº∑Â§ß„ÄÇÈÄôÁ®ÆËÉΩÂäõËÉΩËÆìÊÇ£ËÄÖÂú®ÂÆ∂‰∏≠ÈÄ≤Ë°åÁ∏±ÂêëË≥áÊñôÊî∂ÈõÜÔºåÊúâÂä©ÊñºÊàëÂÄë‰∫ÜËß£Áù°Áú†ÂèäÂÖ∂ËàáÂêÑÁ®ÆÁñæÁóÖÁöÑ‰∫§‰∫í‰ΩúÁî®Ôºå‰ª•ÂèäÂú®Ëá®Â∫äË©¶È©óÂíå‰æãË°åÁÖßË≠∑‰∏≠ÁöÑÊ≤ªÁôÇÂèçÊáâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂèØË¢´ÂãïÁõ£Êéß‰∫∫ÂÄëÁù°Ë¶∫ÊôÇÂæûË∫´È´îÂèçÂ∞ÑÁöÑÁÑ°Á∑öÈõªÊ≥¢‰∏≠ÁöÑÁù°Áú†ÂíåÂ§úÈñìÂëºÂê∏„ÄÇËàáÈªÉÈáëÊ®ôÊ∫ñÔºàÂç≥Â§öÈáçÁù°Áú†ÁîüÁêÜÊ™¢Êü•ÔºâÔºàn=849ÔºâÁõ∏ÊØîÁöÑÈ©óË≠âÁµêÊûúÈ°ØÁ§∫ÔºåË©≤Ê®°ÂûãÊçïÊçâÂà∞‰∫ÜÁù°Áú†ËÖ¶Ê≥¢ÂúñÔºà30 ÁßíÊôÇÈñìÂçÄÊÆµÂàÜÈ°ûÁÇ∫Ê∏ÖÈÜí„ÄÅÊ∑∫Áú†„ÄÅÊ∑±Áú†ÊàñÂø´ÈÄüÂãïÁúºÊúüÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 81%ÔºâÔºåÂèØÂÅµÊ∏¨Áù°Áú†ÂëºÂê∏‰∏≠Ê≠¢ÔºàAUROC = 0.88ÔºâÔºå‰∏¶Ê∏¨ÈáèÊÇ£ËÄÖÁöÑÂëºÂê∏‰∏≠Ê≠¢‰ΩéÈÄöÊ∞£ÊåáÊï∏ÔºàICC=0.95Ôºõ95% CI = [0.93, 0.97]Ôºâ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåË©≤Ê®°ÂûãÂú®Á®ÆÊóè„ÄÅÊÄßÂà•ÂíåÂπ¥ÈΩ°‰∏äË°®ÁèæÂá∫ÂÖ¨Âπ≥ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãÊè≠Á§∫‰∫ÜÁù°Áú†ÈöéÊÆµËàáÁ•ûÁ∂ì„ÄÅÁ≤æÁ•û„ÄÅÂøÉË°ÄÁÆ°ÂíåÂÖçÁñ´ÁñæÁóÖÁ≠â‰∏ÄÁ≥ªÂàóÁñæÁóÖ‰πãÈñìÁöÑË≥áË®äÊÄß‰∫§‰∫í‰ΩúÁî®„ÄÇÈÄô‰∫õÁôºÁèæ‰∏çÂÉÖÂ∞çËá®Â∫äÂØ¶ÂãôÂíå‰ªãÂÖ•Ë©¶È©óÊúâÊúõÔºå‰πüÂº∑Ë™ø‰∫ÜÁù°Áú†‰ΩúÁÇ∫ÁêÜËß£ÂíåÁÆ°ÁêÜÂêÑÁ®ÆÁñæÁóÖÁöÑÂü∫Êú¨ÁµÑÊàêÈÉ®ÂàÜÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Large Language Models for Medicine: A Survey**
2405.13055v1 by Yanxin Zheng, Wensheng Gan, Zefeng Chen, Zhenlian Qi, Qian Liang, Philip S. Yu

To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊáâÂ∞çÊï∏‰ΩçÁ∂ìÊøüÁí∞Â¢É‰∏≠Êï∏‰ΩçÊô∫ÊÖßÁöÑÊåëÊà∞ÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÈÅãÁÆóËÉΩÂäõÂíåÂèØÁî®Ë≥áÊ∫êÁöÑÈÄ≤Ê≠•Â§ßÂπÖÊèêÂçá LLMÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Êï¥ÂêàÂà∞‰∫∫È°ûÁîüÊ¥ªÁöÑ‰∏çÂêåÈ†òÂüü„ÄÇÈÜ´ÁôÇ LLM ÊòØÈáçË¶ÅÁöÑÊáâÁî®Â∑•ÂÖ∑ÔºåÂú®ÂêÑÁ®ÆÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÂÖ∑ÊúâÊΩõÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß LLM ÁöÑÁôºÂ±ïÔºåÈáçÈªûÊé¢Ë®éÈÜ´ÁôÇ LLM ÁöÑÈúÄÊ±ÇÂíåÊáâÁî®„ÄÇÊàëÂÄëÁ∞°Ë¶ÅÊ¶ÇËø∞ÁèæÊúâÊ®°ÂûãÔºåÊó®Âú®Êé¢Ë®éÈÄ≤ÈöéÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰∏¶ÈÄ†Á¶èÊú™‰æÜÈÜ´ÁôÇÊáâÁî®ÁöÑÁ†îÁ©∂‰∫∫Âì°„ÄÇÊàëÂÄëÂº∑Ë™øÈÜ´ÁôÇ LLM Âú®ÊáâÁî®‰∏≠ÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÂú®ÈñãÁôºÈÅéÁ®ã‰∏≠ÈÅáÂà∞ÁöÑÊåëÊà∞„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫ÊäÄË°ìÊï¥ÂêàÁöÑÊñπÂêëÔºå‰ª•Ê∏õËºïÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫ÈÜ´ÁôÇ LLM Êú™‰æÜÁöÑÊΩõÂú®Á†îÁ©∂ÊñπÂêëÔºåÁõÆÊ®ôÊòØÊõ¥Â•ΩÂú∞ÊªøË∂≥ÈÜ´ÁôÇÈ†òÂüüÁöÑÈúÄÊ±Ç„ÄÇ

##### **Towards Contactless Elevators with TinyML using CNN-based Person Detection and Keyword Spotting**
2405.13051v1 by Anway S. Pimpalkar, Deeplaxmi V. Niture

This study presents a proof of concept for a contactless elevator operation
system aimed at minimizing human intervention while enhancing safety,
intelligence, and efficiency. A microcontroller-based edge device executing
tiny Machine Learning (tinyML) inferences is developed for elevator operation.
Using person detection and keyword spotting algorithms, the system offers
cost-effective and robust units requiring minimal infrastructural changes. The
design incorporates preprocessing steps and quantized convolutional neural
networks in a multitenant framework to optimize accuracy and response time.
Results show a person detection accuracy of 83.34% and keyword spotting
efficacy of 80.5%, with an overall latency under 5 seconds, indicating
effectiveness in real-world scenarios. Unlike current high-cost and
inconsistent contactless technologies, this system leverages tinyML to provide
a cost-effective, reliable, and scalable solution, enhancing user safety and
operational efficiency without significant infrastructural changes. The study
highlights promising results, though further exploration is needed for
scalability and integration with existing systems. The demonstrated energy
efficiency, simplicity, and safety benefits suggest that tinyML adoption could
revolutionize elevator systems, serving as a model for future technological
advancements. This technology could significantly impact public health and
convenience in multi-floor buildings by reducing physical contact and improving
operational efficiency, particularly relevant in the context of pandemics or
hygiene concerns.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈùûÊé•Ëß∏ÂºèÈõªÊ¢ØÊìç‰ΩúÁ≥ªÁµ±ÁöÑÊ¶ÇÂøµÈ©óË≠âÔºåÊó®Âú®ÊúÄÂ§ßÈôêÂ∫¶Âú∞Ê∏õÂ∞ë‰∫∫ÁÇ∫Âπ≤È†êÔºåÂêåÊôÇÊèêÈ´òÂÆâÂÖ®ÊÄß„ÄÅÊô∫ÊÖßÂåñÂíåÊïàÁéá„ÄÇÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂæÆÊéßÂà∂Âô®ÁöÑÈÇäÁ∑£Ë®≠ÂÇôÔºåÁî®ÊñºÂü∑Ë°åÂæÆÂûãÊ©üÂô®Â≠∏Áøí (tinyML) Êé®Ë´ñÔºå‰ª•ÈÄ≤Ë°åÈõªÊ¢ØÊìç‰Ωú„ÄÇË©≤Á≥ªÁµ±‰ΩøÁî®‰∫∫Âì°Ê™¢Ê∏¨ÂíåÈóúÈçµÂ≠óË≠òÂà•ÊºîÁÆóÊ≥ïÔºåÊèê‰æõÁ∂ìÊøüÂØ¶ÊÉ†‰∏îÂº∑Â§ßÁöÑÂñÆÂÖÉÔºåÂè™ÈúÄÊúÄÂ∞ëÁöÑÂü∫Á§éË®≠ÊñΩËÆäÊõ¥„ÄÇË©≤Ë®≠Ë®àÂú®Â§öÁßüÊà∂Êû∂Êßã‰∏≠ÁµêÂêà‰∫ÜÈ†êËôïÁêÜÊ≠•È©üÂíåÈáèÂåñÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰ª•ÊúÄ‰Ω≥ÂåñÊ∫ñÁ¢∫Â∫¶ÂíåÂõûÊáâÊôÇÈñì„ÄÇÁµêÊûúÈ°ØÁ§∫‰∫∫Âì°Ê™¢Ê∏¨Ê∫ñÁ¢∫Â∫¶ÁÇ∫ 83.34%ÔºåÈóúÈçµÂ≠óË≠òÂà•ÊïàÁéáÁÇ∫ 80.5%ÔºåÊï¥È´îÂª∂ÈÅ≤‰ΩéÊñº 5 ÁßíÔºåË°®ÊòéÂú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊúâÊïà„ÄÇËàáÁõÆÂâçÈ´òÊàêÊú¨‰∏î‰∏ç‰∏ÄËá¥ÁöÑÈùûÊé•Ëß∏ÂºèÊäÄË°ì‰∏çÂêåÔºåÊ≠§Á≥ªÁµ±Âà©Áî® tinyML Êèê‰æõÁ∂ìÊøüÂØ¶ÊÉ†„ÄÅÂèØÈù†‰∏îÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂú®‰∏çÈÄ≤Ë°åÈáçÂ§ßÂü∫Á§éË®≠ÊñΩËÆäÊõ¥ÁöÑÊÉÖÊ≥Å‰∏ãÊèêÈ´ò‰ΩøÁî®ËÄÖÂÆâÂÖ®ÊÄßËàáÁáüÈÅãÊïàÁéá„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÂÑòÁÆ°ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢‰ª•Êì¥ÂÖÖË¶èÊ®°‰∏¶ËàáÁèæÊúâÁ≥ªÁµ±Êï¥Âêà„ÄÇÂ∑≤Â±ïÁ§∫ÁöÑËÉΩÊ∫êÊïàÁéá„ÄÅÁ∞°ÊΩîÊÄßÂíåÂÆâÂÖ®ÊÄßÂÑ™Âã¢Ë°®ÊòéÔºåtinyML ÁöÑÊé°Áî®ÂèØ‰ª•ÂæπÂ∫ïÊîπËÆäÈõªÊ¢ØÁ≥ªÁµ±Ôºå‰ΩúÁÇ∫Êú™‰æÜÊäÄË°ìÈÄ≤Ê≠•ÁöÑÂÖ∏ÁØÑ„ÄÇÊ≠§ÊäÄË°ìÂèØ‰ª•ÈÄèÈÅéÊ∏õÂ∞ëË∫´È´îÊé•Ëß∏‰∏¶ÊèêÂçáÁáüÈÅãÊïàÁéáÔºåÈ°ØËëóÂΩ±ÈüøÂ§öÂ±§Âª∫ÁØâ‰∏≠ÁöÑÂÖ¨ÂÖ±Ë°õÁîüËàá‰æøÂà©ÊÄßÔºåÁâπÂà•ÊòØÂú®ÊµÅË°åÁóÖÊàñË°õÁîüÂïèÈ°åÁöÑËÉåÊôØ‰∏ãÂÖ∑ÊúâÁõ∏ÈóúÊÄß„ÄÇ

##### **Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning**
2405.11640v1 by Zishan Gu, Fenglin Liu, Changchang Yin, Ping Zhang

The adoption of large language models (LLMs) in healthcare has attracted
significant research interest. However, their performance in healthcare remains
under-investigated and potentially limited, due to i) they lack rich
domain-specific knowledge and medical reasoning skills; and ii) most
state-of-the-art LLMs are unimodal, text-only models that cannot directly
process multimodal inputs. To this end, we propose a multimodal medical
collaborative reasoning framework \textbf{MultiMedRes}, which incorporates a
learner agent to proactively gain essential information from domain-specific
expert models, to solve medical multimodal reasoning problems. Our method
includes three steps: i) \textbf{Inquire}: The learner agent first decomposes
given complex medical reasoning problems into multiple domain-specific
sub-problems; ii) \textbf{Interact}: The agent then interacts with
domain-specific expert models by repeating the ``ask-answer'' process to
progressively obtain different domain-specific knowledge; iii)
\textbf{Integrate}: The agent finally integrates all the acquired
domain-specific knowledge to accurately address the medical reasoning problem.
We validate the effectiveness of our method on the task of difference visual
question answering for X-ray images. The experiments demonstrate that our
zero-shot prediction achieves state-of-the-art performance, and even
outperforms the fully supervised methods. Besides, our approach can be
incorporated into various LLMs and multimodal LLMs to significantly boost their
performance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊé°Áî®ÂºïËµ∑‰∫Ü
È°ØËëóÁöÑÁ†îÁ©∂ËààË∂£„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº i) ÂÆÉÂÄëÁº∫‰πèË±êÂØåÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂíåÈÜ´ÁôÇÊé®ÁêÜÊäÄËÉΩÔºõ‰ª•Âèä ii) Â§ßÂ§öÊï∏
ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊòØÂñÆÊ®°ÊÖã„ÄÅÁ¥îÊñáÂ≠óÊ®°ÂûãÔºåÁÑ°Ê≥ïÁõ¥Êé•
ËôïÁêÜÂ§öÊ®°ÊÖãËº∏ÂÖ•ÔºåÂõ†Ê≠§ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑË°®Áèæ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂Ôºå‰∏îÊΩõÂú®ÂèóÈôê„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÈÜ´ÁôÇ
Âçî‰ΩúÊé®ÁêÜÊ°ÜÊû∂\textbf{MultiMedRes}ÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÂ≠∏Áøí‰ª£ÁêÜÔºåÂèØ‰∏ªÂãïÂæûÁâπÂÆöÈ†òÂüüÁöÑ
Â∞àÂÆ∂Ê®°Âûã‰∏≠Áç≤ÂèñÂü∫Êú¨Ë≥áË®äÔºå‰ª•Ëß£Ê±∫ÈÜ´ÁôÇÂ§öÊ®°ÊÖãÊé®ÁêÜÂïèÈ°å„ÄÇÊàëÂÄëÁöÑ
ÊñπÊ≥ïÂåÖÊã¨‰∏âÂÄãÊ≠•È©üÔºöi) \textbf{Ë©¢Âïè}ÔºöÂ≠∏Áøí‰ª£ÁêÜÈ¶ñÂÖàÂ∞á
Áµ¶ÂÆöÁöÑË§áÈõúÈÜ´ÁôÇÊé®ÁêÜÂïèÈ°åÂàÜËß£ÁÇ∫Â§öÂÄãÁâπÂÆöÈ†òÂüüÁöÑ
Â≠êÂïèÈ°åÔºõii) \textbf{‰∫íÂãï}ÔºöÁÑ∂ÂæåÔºå‰ª£ÁêÜÈÄèÈÅéÈáçË§á``Ë©¢Âïè-ÂõûÁ≠î''Á®ãÂ∫èËàá
ÁâπÂÆöÈ†òÂüüÁöÑÂ∞àÂÆ∂Ê®°Âûã‰∫íÂãïÔºå‰ª•ÈÄêÊ≠•Áç≤Âèñ‰∏çÂêåÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÔºõiii)
\textbf{Êï¥Âêà}ÔºöÊúÄÂæåÔºå‰ª£ÁêÜÊï¥ÂêàÊâÄÊúâÁç≤ÂæóÁöÑ
ÁâπÂÆöÈ†òÂüüÁü•Ë≠òÔºå‰ª•Ê∫ñÁ¢∫Ëß£Ê±∫ÈÜ´ÁôÇÊé®ÁêÜÂïèÈ°å„ÄÇ
ÊàëÂÄëÂú® X ÂÖâÂΩ±ÂÉèÁöÑÂ∑ÆÁï∞Ë¶ñË¶∫ÂïèÈ°åËß£Á≠î‰ªªÂãô‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑ
Èõ∂Ê¨°Â≠∏ÁøíÈ†êÊ∏¨ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÁîöËá≥
ÂÑ™ÊñºÂÆåÂÖ®Áõ£Áù£ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ
ÊñπÊ≥ïÂèØ‰ª•Êï¥ÂêàÂà∞ÂêÑÁ®Æ LLM ÂíåÂ§öÊ®°ÊÖã LLM ‰∏≠Ôºå‰ª•È°ØËëóÊèêÂçáÂÖ∂
ÊÄßËÉΩ„ÄÇ

##### **Sociotechnical Implications of Generative Artificial Intelligence for Information Access**
2405.11612v1 by Bhaskar Mitra, Henriette Cramer, Olya Gurevich

Robust access to trustworthy information is a critical need for society with
implications for knowledge production, public health education, and promoting
informed citizenry in democratic societies. Generative AI technologies may
enable new ways to access information and improve effectiveness of existing
information retrieval systems but we are only starting to understand and
grapple with their long-term social implications. In this chapter, we present
an overview of some of the systemic consequences and risks of employing
generative AI in the context of information access. We also provide
recommendations for evaluation and mitigation, and discuss challenges for
future research.

ÊëòË¶ÅÔºöÂº∑ÂÅ•ÁöÑÁÆ°ÈÅìÂèñÂæóÂèØ‰ø°Ë≥¥ÁöÑË≥áË®äÊòØÁ§æÊúÉÁöÑÈóúÈçµÈúÄÊ±ÇÔºåÂ∞çÊñºÁü•Ë≠òÁîüÁî¢„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÊïôËÇ≤Ôºå‰ª•ÂèäÂú®Ê∞ë‰∏ªÁ§æÊúÉ‰∏≠‰øÉÈÄ≤ÊúâË¶ãË≠òÁöÑÂÖ¨Ê∞ëÊÑèË≠òÂÖ∑ÊúâÂΩ±Èüø„ÄÇÁîüÊàêÂºè AI ÊäÄË°ìÂèØËÉΩÊúÉÁÇ∫ÂèñÂæóË≥áË®äÊèê‰æõÊñ∞ÊñπÊ≥ïÔºå‰∏¶ÊèêÂçáÁèæÊúâË≥áË®äÊ™¢Á¥¢Á≥ªÁµ±ÁöÑÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÊâçÂâõÈñãÂßã‰∫ÜËß£‰∏¶ÊáâÂ∞çÂÖ∂Èï∑ÊúüÁöÑÁ§æÊúÉÂΩ±Èüø„ÄÇÂú®Êú¨Á´†‰∏≠ÔºåÊàëÂÄëÂ∞áÊ¶ÇËø∞Âú®Ë≥áË®äÂèñÂæóÁöÑËÑàÁµ°‰∏≠‰ΩøÁî®ÁîüÊàêÂºè AI ÁöÑ‰∏Ä‰∫õÁ≥ªÁµ±ÊÄßÂæåÊûúÂíåÈ¢®Èö™„ÄÇÊàëÂÄë‰πüÊèê‰æõË©ï‰º∞ÂíåÁ∑©Ëß£ÁöÑÂª∫Ë≠∞Ôºå‰∏¶Êé¢Ë®éÊú™‰æÜÁ†îÁ©∂ÁöÑÊåëÊà∞„ÄÇ

##### **AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection to Clinical Validation**
2405.11598v1 by Carlo Alberto Barbano, Riccardo Renzulli, Marco Grosso, Domenico Basile, Marco Busso, Marco Grangetto

In this paper, we present the major results from the Covid Radiographic
imaging System based on AI (Co.R.S.A.) project, which took place in Italy. This
project aims to develop a state-of-the-art AI-based system for diagnosing
Covid-19 pneumonia from Chest X-ray (CXR) images. The contributions of this
work are manyfold: the release of the public CORDA dataset, a deep learning
pipeline for Covid-19 detection, and the clinical validation of the developed
solution by expert radiologists. The proposed detection model is based on a
two-step approach that, paired with state-of-the-art debiasing, provides
reliable results. Most importantly, our investigation includes the actual usage
of the diagnosis aid tool by radiologists, allowing us to assess the real
benefits in terms of accuracy and time efficiency. Project homepage:
https://corsa.di.unito.it/

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á‰ªãÁ¥πÂú®Áæ©Â§ßÂà©ÈÄ≤Ë°åÁöÑ Covid ÊîæÂ∞ÑÂΩ±ÂÉèÁ≥ªÁµ±Âü∫Êñº AIÔºàCo.R.S.A.ÔºâË®àÁï´ÁöÑ‰∏ªË¶ÅÁµêÊûú„ÄÇÊ≠§Ë®àÁï´ÁöÑÁõÆÊ®ôÊòØÈñãÁôº‰∏ÄÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÔºåÁî®ÊñºÊ†πÊìöËÉ∏ÈÉ® X ÂÖâÔºàCXRÔºâÂΩ±ÂÉèË®∫Êñ∑ Covid-19 ËÇ∫ÁÇé„ÄÇÊ≠§Á†îÁ©∂ÁöÑË≤¢ÁçªÂåÖÊã¨ÔºöÈáãÂá∫ÂÖ¨ÈñãÁöÑ CORDA Ë≥áÊñôÈõÜ„ÄÅ‰∏ÄÂÄãÁî®ÊñºÂÅµÊ∏¨ Covid-19 ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁÆ°ÈÅìÔºå‰ª•ÂèäÁî±ÊîæÂ∞ÑÁßëÂ∞àÂÆ∂Â∞çÈñãÁôºÁöÑËß£Ê±∫ÊñπÊ°àÈÄ≤Ë°åËá®Â∫äÈ©óË≠â„ÄÇÊâÄÊèêÂá∫ÁöÑÂÅµÊ∏¨Ê®°ÂûãÂü∫Êñº‰∏ÄÂÄãÂÖ©Ê≠•È©üÊñπÊ≥ïÔºåÊê≠ÈÖçÊúÄÂÖàÈÄ≤ÁöÑÂéªÂÅèÔºåÊèê‰æõÂèØÈù†ÁöÑÁµêÊûú„ÄÇÊúÄÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑË™øÊü•ÂåÖÊã¨ÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂØ¶Èöõ‰ΩøÁî®Ë®∫Êñ∑ËºîÂä©Â∑•ÂÖ∑ÔºåËÆìÊàëÂÄëËÉΩÂ§†Ë©ï‰º∞Âú®Ê∫ñÁ¢∫ÊÄßÂíåÊôÇÈñìÊïàÁéáÊñπÈù¢ÁöÑÂØ¶ÈöõÊïàÁõä„ÄÇË®àÁï´È¶ñÈ†ÅÔºöhttps://corsa.di.unito.it/

##### **EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging**
2405.11338v2 by Danli Shi, Weiyi Zhang, Xiaolan Chen, Yexin Liu, Jiancheng Yang, Siyu Huang, Yih Chung Tham, Yingfeng Zheng, Mingguang He

Artificial intelligence (AI) is vital in ophthalmology, tackling tasks like
diagnosis, classification, and visual question answering (VQA). However,
existing AI models in this domain often require extensive annotation and are
task-specific, limiting their clinical utility. While recent developments have
brought about foundation models for ophthalmology, they are limited by the need
to train separate weights for each imaging modality, preventing a comprehensive
representation of multi-modal features. This highlights the need for versatile
foundation models capable of handling various tasks and modalities in
ophthalmology. To address this gap, we present EyeFound, a multimodal
foundation model for ophthalmic images. Unlike existing models, EyeFound learns
generalizable representations from unlabeled multimodal retinal images,
enabling efficient model adaptation across multiple applications. Trained on
2.78 million images from 227 hospitals across 11 ophthalmic modalities,
EyeFound facilitates generalist representations and diverse multimodal
downstream tasks, even for detecting challenging rare diseases. It outperforms
previous work RETFound in diagnosing eye diseases, predicting systemic disease
incidents, and zero-shot multimodal VQA. EyeFound provides a generalizable
solution to improve model performance and lessen the annotation burden on
experts, facilitating widespread clinical AI applications for retinal imaging.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÁúºÁßë‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂèØËôïÁêÜË®∫Êñ∑„ÄÅÂàÜÈ°ûÂíåË¶ñË¶∫ÂïèÁ≠î (VQA) Á≠â‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÊ≠§È†òÂüüÁèæÊúâÁöÑ AI Ê®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂª£Ê≥õÁöÑË®ªËß£ÔºåËÄå‰∏îÁâπÂÆöÊñº‰ªªÂãôÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑËá®Â∫äÊïàÁî®„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÁôºÂ±ïÁÇ∫ÁúºÁßëÂ∏∂‰æÜ‰∫ÜÂü∫Á§éÊ®°ÂûãÔºå‰ΩÜÂÆÉÂÄëÂèóÂà∞Ë®ìÁ∑¥ÈúÄË¶ÅÁÇ∫ÊØèÂÄãÂΩ±ÂÉèÊ®°ÂºèË®ìÁ∑¥Áç®Á´ãÊ¨äÈáçÁöÑÈôêÂà∂ÔºåÈÄôÈòªÁ§ô‰∫ÜÂ§öÊ®°ÂºèÁâπÂæµÁöÑÂÖ®Èù¢Ë°®Á§∫„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÈúÄË¶ÅËÉΩÂ§†ËôïÁêÜÁúºÁßë‰∏≠ÂêÑÁ®Æ‰ªªÂãôÂíåÊ®°ÂºèÁöÑÂ§öÂäüËÉΩÂü∫Á§éÊ®°Âûã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü EyeFoundÔºå‰∏ÄÂÄãÁî®ÊñºÁúºÁßëÂΩ±ÂÉèÁöÑÂ§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã„ÄÇËàáÁèæÊúâÊ®°Âûã‰∏çÂêåÔºåEyeFound ÂæûÊú™Ê®ôË®òÁöÑÂ§öÊ®°ÂºèË¶ñÁ∂≤ËÜúÂΩ±ÂÉè‰∏≠Â≠∏ÁøíÂèØÊ¶ÇÊã¨ÁöÑË°®Á§∫ÔºåÂæûËÄåËÉΩÂ§†Âú®Â§öÂÄãÊáâÁî®Á®ãÂºè‰∏≠ÊúâÊïàÂú∞Ë™øÊï¥Ê®°Âûã„ÄÇEyeFound Êé•Âèó‰∫Ü‰æÜËá™ 11 Á®ÆÁúºÁßëÊ®°ÂºèÁöÑ 227 ÂÆ∂ÈÜ´Èô¢ÁöÑ 278 Ëê¨ÂºµÂΩ±ÂÉèË®ìÁ∑¥ÔºåÂç≥‰ΩøÂú®ÂÅµÊ∏¨ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁΩïË¶ãÁñæÁóÖÊôÇÔºåÂÆÉ‰πüËÉΩ‰øÉÈÄ≤ÈÄöÊâçË°®Á§∫ÂíåÂ§öÊ®£ÂåñÁöÑÂ§öÊ®°Âºè‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂÆÉÂú®Ë®∫Êñ∑ÁúºÁñæ„ÄÅÈ†êÊ∏¨ÂÖ®Ë∫´ÊÄßÁñæÁóÖ‰∫ã‰ª∂ÂíåÈõ∂Ê¨°Â≠∏ÁøíÂ§öÊ®°Âºè VQA ÊñπÈù¢ÂÑ™ÊñºÂÖàÂâçÁöÑ RETFound„ÄÇEyeFound Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊ¶ÇÊã¨ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊîπÂñÑÊ®°ÂûãÊïàËÉΩ‰∏¶Ê∏õËºïÂ∞àÂÆ∂ÁöÑË®ªËß£Ë≤†ÊìîÔºå‰øÉÈÄ≤Âª£Ê≥õÁöÑËá®Â∫ä AI ÊáâÁî®ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉè„ÄÇ

##### **Towards Knowledge-Infused Automated Disease Diagnosis Assistant**
2405.11181v1 by Mohit Tomar, Abhisek Tiwari, Sriparna Saha

With the advancement of internet communication and telemedicine, people are
increasingly turning to the web for various healthcare activities. With an
ever-increasing number of diseases and symptoms, diagnosing patients becomes
challenging. In this work, we build a diagnosis assistant to assist doctors,
which identifies diseases based on patient-doctor interaction. During
diagnosis, doctors utilize both symptomatology knowledge and diagnostic
experience to identify diseases accurately and efficiently. Inspired by this,
we investigate the role of medical knowledge in disease diagnosis through
doctor-patient interaction. We propose a two-channel, knowledge-infused,
discourse-aware disease diagnosis model (KI-DDI), where the first channel
encodes patient-doctor communication using a transformer-based encoder, while
the other creates an embedding of symptom-disease using a graph attention
network (GAT). In the next stage, the conversation and knowledge graph
embeddings are infused together and fed to a deep neural network for disease
identification. Furthermore, we first develop an empathetic conversational
medical corpus comprising conversations between patients and doctors, annotated
with intent and symptoms information. The proposed model demonstrates a
significant improvement over the existing state-of-the-art models, establishing
the crucial roles of (a) a doctor's effort for additional symptom extraction
(in addition to patient self-report) and (b) infusing medical knowledge in
identifying diseases effectively. Many times, patients also show their medical
conditions, which acts as crucial evidence in diagnosis. Therefore, integrating
visual sensory information would represent an effective avenue for enhancing
the capabilities of diagnostic assistants.

ÊëòË¶ÅÔºöÈö®ËëóÁ∂≤Ë∑ØÈÄöË®äÂíåÈÅ†Ë∑ùÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•Ôºå‰∫∫ÂÄëË∂ä‰æÜË∂ä‰æùË≥¥Á∂≤Ë∑ØÈÄ≤Ë°åÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•Ê¥ªÂãï„ÄÇÈö®ËëóÁñæÁóÖÂíåÁóáÁãÄÁöÑÊï∏Èáè‰∏çÊñ∑Â¢ûÂä†ÔºåË®∫Êñ∑ÊÇ£ËÄÖËÆäÂæóÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãË®∫Êñ∑Âä©ÁêÜ‰æÜÂçîÂä©ÈÜ´ÁîüÔºåÊ†πÊìöÊÇ£ËÄÖËàáÈÜ´ÁîüÁöÑ‰∫íÂãï‰æÜË≠òÂà•ÁñæÁóÖ„ÄÇÂú®Ë®∫Êñ∑ÈÅéÁ®ã‰∏≠ÔºåÈÜ´ÁîüÂêåÊôÇÂà©Áî®ÁóáÁãÄÂ≠∏Áü•Ë≠òÂíåË®∫Êñ∑Á∂ìÈ©ó‰æÜÊ∫ñÁ¢∫ÊúâÊïàÂú∞Ë≠òÂà•ÁñæÁóÖ„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÈÄèÈÅéÈÜ´ÁîüËàáÊÇ£ËÄÖÁöÑ‰∫íÂãï‰æÜÊé¢Ë®éÈÜ´Â≠∏Áü•Ë≠òÂú®ÁñæÁóÖË®∫Êñ∑‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈõôÈÄöÈÅì„ÄÅÁü•Ë≠òÊ≥®ÂÖ•„ÄÅÂ∞çË©±ÊÑüÁü•ÁñæÁóÖË®∫Êñ∑Ê®°Âûã (KI-DDI)ÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÂÄãÈÄöÈÅì‰ΩøÁî®Âü∫ÊñºËΩâÊèõÂô®ÁöÑÁ∑®Á¢ºÂô®Â∞çÊÇ£ËÄÖËàáÈÜ´ÁîüÁöÑÊ∫ùÈÄöÈÄ≤Ë°åÁ∑®Á¢ºÔºåËÄåÂè¶‰∏ÄÂÄãÈÄöÈÅì‰ΩøÁî®ÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑Ø (GAT) Âª∫Á´ãÁóáÁãÄÁñæÁóÖÁöÑÂµåÂÖ•„ÄÇÂú®‰∏ã‰∏ÄÈöéÊÆµÔºåÂ∞çË©±ÂíåÁü•Ë≠òÂúñÂµåÂÖ•Ë¢´Ê≥®ÂÖ•Âú®‰∏ÄËµ∑Ôºå‰∏¶Ëº∏ÂÖ•Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÁñæÁóÖË≠òÂà•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ¶ñÂÖàÈñãÁôº‰∫Ü‰∏ÄÂÄãÂêåÁêÜÂøÉÂ∞çË©±ÂºèÈÜ´Â≠∏Ë™ûÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊÇ£ËÄÖÂíåÈÜ´Áîü‰πãÈñìÁöÑÂ∞çË©±Ôºå‰∏¶Ë®ªËß£‰∫ÜÊÑèÂúñÂíåÁóáÁãÄË≥áË®ä„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂ∞çÁèæÊúâÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÈ°ØËëóÊîπÈÄ≤ÔºåÁ¢∫Á´ã‰∫Ü (a) ÈÜ´ÁîüÁÇ∫È°çÂ§ñÁóáÁãÄÊèêÂèñÔºàÈô§‰∫ÜÊÇ£ËÄÖËá™ÊàëÂ†±Âëä‰πãÂ§ñÔºâÊâÄÂÅöÁöÑÂä™Âäõ‰ª•Âèä (b) Ê≥®ÂÖ•ÈÜ´Â≠∏Áü•Ë≠ò‰ª•ÊúâÊïàË≠òÂà•ÁñæÁóÖÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÂæàÂ§öÊôÇÂÄôÔºåÊÇ£ËÄÖÈÇÑÊúÉÂ±ïÁ§∫‰ªñÂÄëÁöÑÈÜ´ÁôÇÁãÄÊ≥ÅÔºåÈÄôÂú®Ë®∫Êñ∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑË≠âÊìö„ÄÇÂõ†Ê≠§ÔºåÊï¥ÂêàË¶ñË¶∫ÊÑüÂÆòË≥áË®äÂ∞á‰ª£Ë°®‰∏ÄÁ®ÆÂ¢ûÂº∑Ë®∫Êñ∑Âä©ÁêÜËÉΩÂäõÁöÑÊúâÊïàÈÄîÂæë„ÄÇ

##### **Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation**
2405.11151v1 by Xiaolu Kang, Zhuoqi Ma, Kang Liu, Yunan Li, Qiguang Miao

Polyp segmentation for colonoscopy images is of vital importance in clinical
practice. It can provide valuable information for colorectal cancer diagnosis
and surgery. While existing methods have achieved relatively good performance,
polyp segmentation still faces the following challenges: (1) Varying lighting
conditions in colonoscopy and differences in polyp locations, sizes, and
morphologies. (2) The indistinct boundary between polyps and surrounding
tissue. To address these challenges, we propose a Multi-scale information
sharing and selection network (MISNet) for polyp segmentation task. We design a
Selectively Shared Fusion Module (SSFM) to enforce information sharing and
active selection between low-level and high-level features, thereby enhancing
model's ability to capture comprehensive information. We then design a Parallel
Attention Module (PAM) to enhance model's attention to boundaries, and a
Balancing Weight Module (BWM) to facilitate the continuous refinement of
boundary segmentation in the bottom-up process. Experiments on five polyp
segmentation datasets demonstrate that MISNet successfully improved the
accuracy and clarity of segmentation result, outperforming state-of-the-art
methods.

ÊëòË¶ÅÔºöÂ§ßËÖ∏Èè°Ê™¢Êü•ÂΩ±ÂÉè‰∏≠ÁöÑÊÅØËÇâÂàÜÂâ≤Âú®Ëá®Â∫äÂØ¶Âãô‰∏äËá≥ÈóúÈáçË¶Å„ÄÇÂÆÉÂèØ‰ª•Êèê‰æõÊúâÂÉπÂÄºÁöÑË≥áË®äÁî®ÊñºÂ§ßËÖ∏ÁôåÁöÑË®∫Êñ∑ÂíåÊâãË°ì„ÄÇÂÑòÁÆ°ÁèæÊúâÊñπÊ≥ïÂ∑≤ÂèñÂæóÁõ∏Â∞çËâØÂ•ΩÁöÑÊïàËÉΩÔºåÊÅØËÇâÂàÜÂâ≤‰ªçÈù¢Ëá®‰ª•‰∏ãÊåëÊà∞Ôºö(1) Â§ßËÖ∏Èè°Ê™¢Êü•‰∏≠‰∏çÂêåÁöÑÁÖßÊòéÊ¢ù‰ª∂Ôºå‰ª•ÂèäÊÅØËÇâ‰ΩçÁΩÆ„ÄÅÂ§ßÂ∞èÂíåÂΩ¢ÊÖãÁöÑÂ∑ÆÁï∞„ÄÇ(2) ÊÅØËÇâËàáÂë®ÂúçÁµÑÁπî‰πãÈñìÊ®°Á≥äÁöÑÈÇäÁïå„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÊÅØËÇâÂàÜÂâ≤‰ªªÂãôÁöÑÂ§öÂ∞∫Â∫¶Ë≥áË®äÂÖ±‰∫´ÂíåÈÅ∏ÊìáÁ∂≤Ë∑Ø (MISNet)„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈÅ∏ÊìáÊÄßÂÖ±‰∫´ËûçÂêàÊ®°ÁµÑ (SSFM) ‰æÜÂº∑Âà∂Âü∑Ë°å‰ΩéÈöéÂíåÈ´òÈöéÁâπÂæµ‰πãÈñìÁöÑË≥áË®äÂÖ±‰∫´Âíå‰∏ªÂãïÈÅ∏ÊìáÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊì∑ÂèñÂÖ®Èù¢Ë≥áË®äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂπ≥Ë°åÊ≥®ÊÑèÂäõÊ®°ÁµÑ (PAM) ‰æÜÂ¢ûÂº∑Ê®°ÂûãÂ∞çÈÇäÁïåÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Âèä‰∏ÄÂÄãÂπ≥Ë°°Ê¨äÈáçÊ®°ÁµÑ (BWM) ‰æÜ‰øÉÈÄ≤Ëá™‰∏ãËÄå‰∏äÁöÑÈÅéÁ®ã‰∏≠ÈÇäÁïåÂàÜÂâ≤ÁöÑÊåÅÁ∫åÁ≤æÁÖâ„ÄÇÂú®‰∫îÂÄãÊÅØËÇâÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË≠âÊòéÔºåMISNet ÊàêÂäüÂú∞ÊîπÂñÑ‰∫ÜÂàÜÂâ≤ÁµêÊûúÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊ∏ÖÊô∞Â∫¶ÔºåÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇ

##### **Generative Artificial Intelligence: A Systematic Review and Applications**
2405.11029v1 by Sandeep Singh Sengar, Affan Bin Hasan, Sanjay Kumar, Fiona Carroll

In recent years, the study of artificial intelligence (AI) has undergone a
paradigm shift. This has been propelled by the groundbreaking capabilities of
generative models both in supervised and unsupervised learning scenarios.
Generative AI has shown state-of-the-art performance in solving perplexing
real-world conundrums in fields such as image translation, medical diagnostics,
textual imagery fusion, natural language processing, and beyond. This paper
documents the systematic review and analysis of recent advancements and
techniques in Generative AI with a detailed discussion of their applications
including application-specific models. Indeed, the major impact that generative
AI has made to date, has been in language generation with the development of
large language models, in the field of image translation and several other
interdisciplinary applications of generative AI. Moreover, the primary
contribution of this paper lies in its coherent synthesis of the latest
advancements in these areas, seamlessly weaving together contemporary
breakthroughs in the field. Particularly, how it shares an exploration of the
future trajectory for generative AI. In conclusion, the paper ends with a
discussion of Responsible AI principles, and the necessary ethical
considerations for the sustainability and growth of these generative models.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºå‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÁ†îÁ©∂Á∂ìÊ≠∑‰∫Ü‰∏ÄÂ†¥ÂÖ∏ÁØÑËΩâÁßª„ÄÇÈÄôÈ†ÖËΩâËÆäÊòØÁî±ÊñºÁîüÊàêÂºèÊ®°ÂûãÂú®Áõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÂ†¥ÊôØ‰∏≠ÂÖ∑ÊúâÁ™ÅÁ†¥ÊÄßÁöÑËÉΩÂäõÊâÄÊé®ÂãïÁöÑ„ÄÇÁîüÊàêÂºè AI Â∑≤Â±ïÁèæÂá∫ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÁî®‰ª•Ëß£Ê±∫ÂΩ±ÂÉèÁøªË≠Ø„ÄÅÈÜ´ÁôÇË®∫Êñ∑„ÄÅÊñáÂ≠óÊÑèË±°ËûçÂêà„ÄÅËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ≠âÈ†òÂüü‰∏≠‰ª§‰∫∫Ë≤ªËß£ÁöÑÁúüÂØ¶‰∏ñÁïåÈõ£È°åÔºåËÄå‰∏î‰∏çÂè™ÊñºÊ≠§„ÄÇÊú¨ÊñáË®òÈåÑ‰∫ÜÂ∞çÁîüÊàêÂºè AI ËøëÊúüÈÄ≤Â±ïÂíåÊäÄË°ìÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ßÂíåÂàÜÊûêÔºå‰∏¶Ë©≥Á¥∞Ë®éË´ñ‰∫ÜÂÆÉÂÄëÁöÑÊáâÁî®ÔºåÂåÖÊã¨ÁâπÂÆöÊáâÁî®Á®ãÂºèÁöÑÊ®°Âûã„ÄÇÁöÑÁ¢∫ÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÁîüÊàêÂºè AI ÊâÄÁî¢ÁîüÁöÑÈáçÂ§ßÂΩ±ÈüøÂú®ÊñºË™ûË®ÄÁîüÊàêÔºåÁâπÂà•ÊòØÂ§ßË™ûË®ÄÊ®°ÂûãÁöÑÁôºÂ±ï„ÄÅÂΩ±ÂÉèÁøªË≠ØÈ†òÂüü‰ª•ÂèäÁîüÊàêÂºè AI ÁöÑÂÖ∂‰ªñÂπæÂÄãË∑®È†òÂüüÊáâÁî®„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÁöÑ‰∏ªË¶ÅË≤¢ÁçªÂú®ÊñºÂ∞çÈÄô‰∫õÈ†òÂüüÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈÄ≤Ë°åÈÄ£Ë≤´ÁöÑÁ∂úÂêàÔºåÂ∞áË©≤È†òÂüüÁöÑÁï∂‰ª£Á™ÅÁ†¥ÁÑ°Á∏´Âú∞‰∫§ÁπîÂú®‰∏ÄËµ∑„ÄÇÁâπÂà•ÊòØÔºåÂÆÉÂàÜ‰∫´‰∫ÜÂ∞çÁîüÊàêÂºè AI Êú™‰æÜËªåË∑°ÁöÑÊé¢Ë®é„ÄÇÊúÄÂæåÔºåÊú¨Êñá‰ª•Â∞çË≤†Ë≤¨‰ªª AI ÂéüÂâáÁöÑË®éË´ñÔºå‰ª•ÂèäÂ∞çÈÄô‰∫õÁîüÊàêÂºèÊ®°ÂûãÁöÑÂèØÊåÅÁ∫åÊÄßÂíåÊàêÈï∑ÁöÑÂøÖË¶ÅÂÄ´ÁêÜËÄÉÈáè‰ΩúÁÇ∫ÁµêÂ∞æ„ÄÇ

##### **COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**
2405.10893v1 by Dimitrios P. Panagoulias, Persephone Papatheodosiou, Anastasios P. Palamidas, Mattheos Sanoudos, Evridiki Tsoureli-Nikita, Maria Virvou, George A. Tsihrintzis

Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÁ™ÅÁ†¥ÊÄßÁöÑÂ∞ñÁ´Ø‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊäÄË°ìÔºåÂÆÉÊ≠£Âú®ËøÖÈÄüÁôºÂ±ïÔºå‰∏¶ÊâøË´æÈÄöÈÅéÂçîÂä©ÈÜ´ÁîüÊàñÂú®Êõ¥ÂÖàÈÄ≤ÂíåË§áÈõúÁöÑÂØ¶ÊñΩ‰∏≠Ê®°Êì¨ÈÜ´ÁîüÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰æÜÂπ´Âä©ÈÄ≤Ë°åÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÈÜ´ÁôÇÈ†òÂüüÁöÑË™çÁü•Á∂≤Ë∑ØË©ï‰º∞Â∑•ÂÖ∑ÂåÖ (COGNET-MD)ÔºåÂÆÉÊßãÊàê‰∫Ü‰∏ÄÂÄã LLM Ë©ï‰º∞Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË©ïÂàÜÊ°ÜÊû∂ÔºåÈõ£Â∫¶Â¢ûÂä†Ôºå‰ª•Ë©ï‰º∞ LLM Ëß£ÈáãÈÜ´ÁôÇÊñáÊú¨ÁöÑËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂ÈôÑÂ∏∂‰∫Ü‰∏ÄÂÄãÂ§öÈÅ∏È°åÊ∏¨È©ó (MCQ) Ë≥áÊñôÂ∫´„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùËàáÁï∂ÂâçÈÜ´ÁôÇË∂®Âã¢‰øùÊåÅ‰∏ÄËá¥‰∏¶Â¢ûÂº∑ÂÆâÂÖ®ÊÄß„ÄÅÂØ¶Áî®ÊÄßÂíåÈÅ©Áî®ÊÄßÔºåÈÄô‰∫õ MCQ Â∑≤ËàáÂ§öÂÄãÁõ∏ÈóúÈÜ´ÁôÇÈ†òÂüüÁöÑÂπæ‰ΩçÈÜ´ÁôÇÂ∞àÂÆ∂Âêà‰ΩúÊßãÂª∫Ôºå‰∏¶‰∏îÈõ£Â∫¶ÂêÑ‰∏çÁõ∏Âêå„ÄÇË≥áÊñôÂ∫´ÁöÑÁï∂ÂâçÔºàÁ¨¨‰∏ÄÔºâÁâàÊú¨ÂåÖÊã¨Á≤æÁ•ûÁóÖÂ≠∏„ÄÅÁâôÁßë„ÄÅËÇ∫ÁßëÂ≠∏„ÄÅÁöÆËÜöÁóÖÂ≠∏ÂíåÂÖßÂàÜÊ≥åÂ≠∏ÁöÑÈÜ´ÁôÇÈ†òÂüüÔºå‰ΩÜÂÆÉÂ∞á‰∏çÊñ∑Êì¥ÂÖÖÂíåÊì¥Â±ï‰ª•ÂåÖÊã¨ÂÖ∂‰ªñÈÜ´ÁôÇÈ†òÂüü„ÄÇ

##### **Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**
2405.10883v1 by Hongyi Yang, Fangyuan Chang, Dian Zhu, Muroi Fumie, Zhao Liu

This review aims to systematically assess the current status and prospects of
artificial intelligence (AI) in the rehabilitation management of patients with
schizophrenia and their impact on the rehabilitation process. We selected 70
studies from 2012 to the present, focusing on application, technology
categories, products, and data types of machine learning, deep learning,
reinforcement learning, and other technologies in mental health interventions
and management. The results indicate that AI can be widely used in symptom
monitoring, relapse risk prediction, and rehabilitation treatment by analyzing
ecological momentary assessment, behavioral, and speech data. This review
further explores the potential challenges and future directions of emerging
products, technologies, and analytical methods based on AI, such as social
media analysis, serious games, and large language models in rehabilitation. In
summary, this study systematically reviews the application status of AI in
schizophrenia rehabilitation management and provides valuable insights and
recommendations for future research paths.

ÊëòË¶ÅÔºöÊú¨Á∂úËø∞Êó®Âú®Á≥ªÁµ±ÊÄßË©ï‰º∞‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Á≤æÁ•ûÂàÜË£ÇÁóáÊÇ£ËÄÖÂæ©ÂÅ•ÁÆ°ÁêÜ‰∏≠ÁöÑÁèæÊ≥ÅËàáÂâçÊôØÔºå‰ª•ÂèäÂÖ∂Â∞çÂæ©ÂÅ•Ê≠∑Á®ãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂæû 2012 Âπ¥Ëá≥‰ªäÈÅ∏Âèñ‰∫Ü 70 ÁØáÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®Ê©üÂô®Â≠∏Áøí„ÄÅÊ∑±Â∫¶Â≠∏Áøí„ÄÅÂº∑ÂåñÂ≠∏ÁøíÂíåÂÖ∂‰ªñÊäÄË°ìÂú®ÂøÉÁêÜÂÅ•Â∫∑‰ªãÂÖ•ÂíåÁÆ°ÁêÜ‰∏≠ÁöÑÊáâÁî®„ÄÅÊäÄË°ìÈ°ûÂà•„ÄÅÁî¢ÂìÅÂíåË≥áÊñôÈ°ûÂûã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåAI ÂèØÂª£Ê≥õÊáâÁî®ÊñºÁóáÁãÄÁõ£Êéß„ÄÅÂæ©ÁôºÈ¢®Èö™È†êÊ∏¨ÂíåÂæ©ÂÅ•Ê≤ªÁôÇÔºåÊñπÊ≥ïÊòØÂàÜÊûêÁîüÊÖãÁû¨ÊôÇË©ï‰º∞„ÄÅË°åÁÇ∫ÂíåË®ÄË™ûË≥áÊñô„ÄÇÊú¨Á∂úËø∞ÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÂü∫Êñº AI ÁöÑÊñ∞ËààÁî¢ÂìÅ„ÄÅÊäÄË°ìÂíåÂàÜÊûêÊñπÊ≥ïÁöÑÊΩõÂú®ÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêëÔºå‰æãÂ¶ÇÂæ©ÂÅ•‰∏≠ÁöÑÁ§æÁæ§Â™íÈ´îÂàÜÊûê„ÄÅÂö¥ËÇÖÈÅäÊà≤ÂíåÂ§ßË™ûË®ÄÊ®°Âûã„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞ÂõûÈ°ß‰∫Ü AI Âú®Á≤æÁ•ûÂàÜË£ÇÁóáÂæ©ÂÅ•ÁÆ°ÁêÜ‰∏≠ÁöÑÊáâÁî®ÁèæÊ≥ÅÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Ë∑ØÂæëÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÂíåÂª∫Ë≠∞„ÄÇ

##### **Causality in the Can: Diet Coke's Impact on Fatness**
2405.10746v1 by Yicheng Qi, Ang Li

Artificially sweetened beverages like Diet Coke are often considered
healthier alternatives, but the debate over their impact on obesity persists.
Previous research has predominantly relied on observational data or randomized
controlled trials (RCTs), which may not accurately capture the causal
relationship between Diet Coke consumption and obesity. This study uses causal
inference methods, employing data from the National Health and Nutrition
Examination Survey (NHANES) to examine this relationship across diverse
demographics. Instead of relying on RCT data, we constructed a causal graph and
applied the back-door criterion with its adjustment formula to estimate the RCT
distributions. We then calculated the counterfactual quantity, the Probability
of Necessity and Sufficiency (PNS), using both NHANES data and estimated RCT
data. We propose that PNS is the essential metric for assessing the impact of
Diet Coke on obesity. Our results indicate that between 20% to 50% of
individuals, especially those with poor dietary habits, are more likely to gain
weight from Diet Coke. Conversely, in groups like young females with healthier
diets, only a small proportion experience weight gain due to Diet Coke. These
findings highlight the influence of individual lifestyle and potential hormonal
factors on the varied effects of Diet Coke, providing a new framework for
understanding its nutritional impacts on health.

ÊëòË¶ÅÔºö‰∫∫Â∑•Âä†Á≥ñÈ£≤ÊñôÔºàÂ¶ÇÂÅ•ÊÄ°ÂèØÊ®ÇÔºâÈÄöÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØÊõ¥ÂÅ•Â∫∑ÁöÑÈÅ∏ÊìáÔºå‰ΩÜÂ∞çÊñºÂÆÉÂÄëÂ∞çËÇ•ËÉñÁöÑÂΩ±ÈüøÁöÑÁà≠Ë´ñ‰ªçÊåÅÁ∫åËëó„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶Å‰æùË≥¥ÊñºËßÄÂØüÊï∏ÊìöÊàñÈö®Ê©üÂ∞çÁÖßË©¶È©ó (RCT)ÔºåÈÄôÂèØËÉΩÁÑ°Ê≥ïÊ∫ñÁ¢∫ÊçïÊçâÂÅ•ÊÄ°ÂèØÊ®ÇÊîùÂèñËàáËÇ•ËÉñ‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®Âõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÔºåÊé°Áî®ÂúãÂÆ∂ÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES) ÁöÑÊï∏Êìö‰æÜÊ™¢È©ó‰∏çÂêå‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠ÁöÑÈÄôÁ®ÆÈóú‰øÇ„ÄÇÊàëÂÄëÊ≤íÊúâ‰æùË≥¥ RCT Êï∏ÊìöÔºåËÄåÊòØÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂõ†ÊûúÂúñÔºå‰∏¶ÊáâÁî®ÂæåÈñÄÊ∫ñÂâáÂèäÂÖ∂Ë™øÊï¥ÂÖ¨Âºè‰æÜ‰º∞Ë®à RCT ÂàÜÈÖç„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® NHANES Êï∏ÊìöÂíå‰º∞Ë®àÁöÑ RCT Êï∏ÊìöË®àÁÆóÂèç‰∫ãÂØ¶Êï∏ÈáèÔºåÂç≥ÂøÖË¶ÅÊÄßÂíåÂÖÖÂàÜÊÄßÊ©üÁéá (PNS)„ÄÇÊàëÂÄëÊèêÂá∫ PNS ÊòØË©ï‰º∞ÂÅ•ÊÄ°ÂèØÊ®ÇÂ∞çËÇ•ËÉñÂΩ±ÈüøÁöÑÂü∫Êú¨ÊåáÊ®ô„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºå20% Ëá≥ 50% ÁöÑÂÄã‰∫∫ÔºåÂ∞§ÂÖ∂ÊòØÈ£≤È£üÁøíÊÖ£‰∏çËâØËÄÖÔºåÊõ¥ÊúâÂèØËÉΩÂõ†ÂÅ•ÊÄ°ÂèØÊ®ÇËÄåÂ¢ûÂä†È´îÈáç„ÄÇÁõ∏ÂèçÂú∞ÔºåÂú®Âπ¥ËºïÂ•≥ÊÄßÁ≠âÈ£≤È£üËºÉÂÅ•Â∫∑ÁöÑÊóèÁæ§‰∏≠ÔºåÂè™ÊúâÂ∞ëÈÉ®ÂàÜ‰∫∫ÊúÉÂõ†ÂÅ•ÊÄ°ÂèØÊ®ÇËÄåÈ´îÈáçÂ¢ûÂä†„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂÄã‰∫∫ÁîüÊ¥ªÊñπÂºèÂíåÊΩõÂú®Ëç∑ÁàæËíôÂõ†Á¥†Â∞çÂÅ•ÊÄ°ÂèØÊ®Ç‰∏çÂêåÂΩ±ÈüøÁöÑÂΩ±ÈüøÔºåÁÇ∫‰∫ÜËß£ÂÖ∂Â∞çÂÅ•Â∫∑ÁöÑÁáüÈ§äÂΩ±ÈüøÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊû∂Êßã„ÄÇ

##### **A Systematic Review and Meta-Analysis on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence**
2405.11008v1 by Tayab Uddin Wara, Ababil Hossain Fahad, Adri Shankar Das, Md. Mehedi Hasan Shawon

Sleep is vital for people's physical and mental health, and sound sleep can
help them focus on daily activities. Therefore, a sleep study that includes
sleep patterns and disorders is crucial to enhancing our knowledge about
individuals' health status. The findings on sleep stages and sleep disorders
relied on polysomnography and self-report measures, and then the study went
through clinical assessments by expert physicians. However, the evaluation
process of sleep stage classification and sleep disorder has become more
convenient with artificial intelligence applications and numerous
investigations focusing on various datasets with advanced algorithms and
techniques that offer improved computational ease and accuracy. This study aims
to provide a comprehensive, systematic review and meta-analysis of the recent
literature to analyze the different approaches and their outcomes in sleep
studies, which includes works on sleep stages classification and sleep disorder
detection using AI. In this review, 183 articles were initially selected from
different journals, among which 80 records were enlisted for explicit review,
ranging from 2016 to 2023. Brain waves were the most commonly employed body
parameters for sleep staging and disorder studies. The convolutional neural
network, the most widely used of the 34 distinct artificial intelligence
models, comprised 27%. The other models included the long short-term memory,
support vector machine, random forest, and recurrent neural network, which
consisted of 11%, 6%, 6%, and 5% sequentially. For performance metrics,
accuracy was widely used for a maximum of 83.75% of the cases, the F1 score of
45%, Kappa of 36.25%, Sensitivity of 31.25%, and Specificity of 30% of cases,
along with the other metrics. This article would help physicians and
researchers get the gist of AI's contribution to sleep studies and the
feasibility of their intended work.

ÊëòË¶ÅÔºöÁù°Áú†Â∞ç‰∫∫ÂÄëÁöÑË∫´ÂøÉÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶ÅÔºåÂÖÖË∂≥ÁöÑÁù°Áú†ÊúâÂä©Êñº‰∫∫ÂÄëÂ∞àÊ≥®ÊñºÊó•Â∏∏Ê¥ªÂãï„ÄÇÂõ†Ê≠§Ôºå‰∏ÄÈ†ÖÂåÖÂê´Áù°Áú†Ê®°ÂºèÂíåÁù°Áú†ÈöúÁ§ôÁöÑÁù°Áú†Á†îÁ©∂Â∞çÊñºÂ¢ûÈÄ≤ÊàëÂÄëÂ∞çÂÄã‰∫∫ÂÅ•Â∫∑ÁãÄÊ≥ÅÁöÑ‰∫ÜËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÈóúÊñºÁù°Áú†ÈöéÊÆµÂíåÁù°Áú†ÈöúÁ§ôÁöÑÁôºÁèæ‰æùË≥¥ÊñºÂ§öÂ∞éÁù°Áú†ÊèèË®òË°ìÂíåËá™ÊàëÂ†±ÂëäÊ∏¨ÈáèÔºåÁÑ∂ÂæåË©≤Á†îÁ©∂Á∂ìÈÅéÂ∞àÂÆ∂ÈÜ´Â∏´ÁöÑËá®Â∫äË©ï‰º∞„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊáâÁî®Ôºå‰ª•ÂèäÈáùÂ∞çÂêÑÁ®ÆÊï∏ÊìöÈõÜÁöÑÁúæÂ§öÁ†îÁ©∂ÔºåÂà©Áî®ÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÂíåÊäÄË°ìÊèê‰æõÊõ¥È´òÁöÑÈÅãÁÆó‰æøÂà©ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåÁù°Áú†ÈöéÊÆµÂàÜÈ°ûÂíåÁù°Áú†ÈöúÁ§ôÁöÑË©ï‰º∞ÈÅéÁ®ãËÆäÂæóÊõ¥Âä†‰æøÂà©„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êèê‰æõÂ∞çËøëÊúüÊñáÁçªÁöÑÂÖ®Èù¢„ÄÅÁ≥ªÁµ±ÊÄßÁöÑÂõûÈ°ßÂíåÁµ±ÂêàÂàÜÊûêÔºå‰ª•ÂàÜÊûêÁù°Áú†Á†îÁ©∂‰∏≠‰∏çÂêåÁöÑÊñπÊ≥ïÂèäÂÖ∂ÊàêÊûúÔºåÂÖ∂‰∏≠ÂåÖÊã¨‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÈÄ≤Ë°åÁù°Áú†ÈöéÊÆµÂàÜÈ°ûÂíåÁù°Áú†ÈöúÁ§ôÊ™¢Ê∏¨ÁöÑÁ†îÁ©∂„ÄÇÂú®Êú¨ÂõûÈ°ß‰∏≠ÔºåÊúÄÂàùÂæû‰∏çÂêåÁöÑÊúüÂàä‰∏≠ÈÅ∏Âá∫ 183 ÁØáÊñáÁ´†ÔºåÂÖ∂‰∏≠ 80 ÁØáÁ¥ÄÈåÑË¢´ÂàóÂÖ•ÊòéÁ¢∫ÁöÑÂõûÈ°ßÔºåÊôÇÈñìÁØÑÂúçÂæû 2016 Âπ¥Âà∞ 2023 Âπ¥„ÄÇËÖ¶Ê≥¢ÊòØÊúÄÂ∏∏‰ΩøÁî®ÁöÑÁù°Áú†ÂàÜÊúüÂíåÈöúÁ§ôÁ†îÁ©∂ÁöÑË∫´È´îÂèÉÊï∏„ÄÇÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊòØ 34 ÂÄã‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°Âûã‰∏≠ÊúÄÂª£Ê≥õ‰ΩøÁî®ÁöÑÔºå‰Ωî 27%„ÄÇÂÖ∂‰ªñÊ®°ÂûãÂåÖÊã¨Èï∑Áü≠ÊúüË®òÊÜ∂„ÄÅÊîØÊåÅÂêëÈáèÊ©ü„ÄÅÈö®Ê©üÊ£ÆÊûóÂíåÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰æùÂ∫è‰Ωî 11%„ÄÅ6%„ÄÅ6% Âíå 5%„ÄÇÂú®ÊïàËÉΩÊåáÊ®ôÊñπÈù¢ÔºåÊ∫ñÁ¢∫Â∫¶Âª£Ê≥õÁî®ÊñºÊúÄÂ§ö 83.75% ÁöÑÊ°à‰æãÔºåF1 ÂàÜÊï∏ÁÇ∫ 45%ÔºåKappa ÁÇ∫ 36.25%ÔºåÊïèÊÑüÂ∫¶ÁÇ∫ 31.25%ÔºåÁâπÁï∞Â∫¶ÁÇ∫ 30% ÁöÑÊ°à‰æãÔºå‰ª•ÂèäÂÖ∂‰ªñÊåáÊ®ô„ÄÇÊú¨ÊñáÂ∞áÂπ´Âä©ÈÜ´Â∏´ÂíåÁ†îÁ©∂‰∫∫Âì°‰∫ÜËß£‰∫∫Â∑•Êô∫ÊÖßÂ∞çÁù°Áú†Á†îÁ©∂ÁöÑË≤¢Áçª‰ª•ÂèäÂÖ∂È†êÊúüÂ∑•‰ΩúÁöÑÂèØË°åÊÄß„ÄÇ

##### **Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**
2405.10647v1 by Haoyue Song, Jiacheng Wang, Liansheng Wang

Federated Learning (FL) has gained attention for addressing data scarcity and
privacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable
performance, they face challenges in scenarios with diverse network speeds and
concerns about centralized control, especially in multi-institutional
collaborations like the medical domain. Serial FL presents an alternative
solution, circumventing these challenges by transferring model updates serially
between devices in a cyclical manner. Nevertheless, it is deemed inferior to
parallel FL in that (1) its performance shows undesirable fluctuations, and (2)
it converges to a lower plateau, particularly when dealing with non-IID data.
The observed phenomenon is attributed to catastrophic forgetting due to
knowledge loss from previous sites. In this paper, to overcome fluctuation and
low efficiency in the iterative learning and forgetting process, we introduce
cyclical weight consolidation (CWC), a straightforward yet potent approach
specifically tailored for serial FL. CWC employs a consolidation matrix to
regulate local optimization. This matrix tracks the significance of each
parameter on the overall federation throughout the entire training trajectory,
preventing abrupt changes in significant weights. During revisitation, to
maintain adaptability, old memory undergoes decay to incorporate new
information. Our comprehensive evaluations demonstrate that in various non-IID
settings, CWC mitigates the fluctuation behavior of the original serial FL
approach and enhances the converged performance consistently and significantly.
The improved performance is either comparable to or better than the parallel
vanilla.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π† (FL) Âõ†Ëß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÂíåÈöêÁßÅÈóÆÈ¢òËÄåÂèóÂà∞ÂÖ≥Ê≥®„ÄÇËôΩÁÑ∂ FedAvg Á≠âÂπ∂Ë°å FL ÁÆóÊ≥ïË°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂÆÉ‰ª¨Âú®ÁΩëÁªúÈÄüÂ∫¶Â§öÊ†∑ÂåñÂíåÈõÜ‰∏≠ÊéßÂà∂ÁöÑÂú∫ÊôØ‰∏≠Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂåªÁñóÈ¢ÜÂüüÁ≠âÂ§öÊú∫ÊûÑÂçè‰Ωú‰∏≠„ÄÇ‰∏≤Ë°å FL ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊõø‰ª£Ëß£ÂÜ≥ÊñπÊ°àÔºåÈÄöËøáÂæ™ÁéØÊñπÂºèÂú®ËÆæÂ§á‰πãÈó¥‰∏≤Ë°å‰º†ËæìÊ®°ÂûãÊõ¥Êñ∞Êù•ËßÑÈÅøËøô‰∫õÊåëÊàò„ÄÇÁÑ∂ËÄåÔºåÂÆÉË¢´ËÆ§‰∏∫‰∏çÂ¶ÇÂπ∂Ë°å FLÔºåÂéüÂõ†Âú®‰∫é (1) ÂÆÉÁöÑÊÄßËÉΩË°®Áé∞Âá∫‰∏çÂ∏åÊúõÁöÑÊ≥¢Âä®Ôºå(2) ÂÆÉÊî∂ÊïõÂà∞ËæÉ‰ΩéÁöÑÂπ≥Âè∞ÔºåÁâπÂà´ÊòØÂú®Â§ÑÁêÜÈùû IID Êï∞ÊçÆÊó∂„ÄÇËßÇÂØüÂà∞ÁöÑÁé∞Ë±°ÂΩíÂõ†‰∫éÁî±‰∫éÂÖàÂâçÁ´ôÁÇπÁü•ËØÜ‰∏¢Â§±ËÄåÂØºËá¥ÁöÑÁÅæÈöæÊÄßÈÅóÂøò„ÄÇÂú®Êú¨Êñá‰∏≠Ôºå‰∏∫‰∫ÜÂÖãÊúçËø≠‰ª£Â≠¶‰π†ÂíåÈÅóÂøòËøáÁ®ã‰∏≠ÁöÑÊ≥¢Âä®Âíå‰ΩéÊïàÁéáÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂæ™ÁéØÊùÉÈáçÂêàÂπ∂ (CWC)ÔºåËøôÊòØ‰∏ÄÁßç‰∏ìÈó®ÈíàÂØπ‰∏≤Ë°å FL ÈáèË∫´ÂÆöÂà∂ÁöÑÁÆÄÂçïËÄåÊúâÊïàÁöÑÊñπÊ≥ï„ÄÇCWC ‰ΩøÁî®ÂêàÂπ∂Áü©ÈòµÊù•Ë∞ÉËäÇÂ±ÄÈÉ®‰ºòÂåñ„ÄÇËØ•Áü©ÈòµË∑üË∏™Êï¥‰∏™ËÆ≠ÁªÉËΩ®Ëøπ‰∏≠ÊØè‰∏™ÂèÇÊï∞ÂØπÊï¥‰∏™ËÅîÂêàÁöÑÈáçË¶ÅÊÄßÔºåÈò≤Ê≠¢ÈáçË¶ÅÊùÉÈáçÁöÑÁ™ÅÁÑ∂ÂèòÂåñ„ÄÇÂú®ÈáçÊñ∞ËÆøÈóÆÊúüÈó¥Ôºå‰∏∫‰∫Ü‰øùÊåÅÈÄÇÂ∫îÊÄßÔºåÊóßËÆ∞ÂøÜ‰ºöË°∞Âáè‰ª•Á∫≥ÂÖ•Êñ∞‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÁöÑÁªºÂêàËØÑ‰º∞Ë°®ÊòéÔºåÂú®ÂêÑÁßçÈùû IID ËÆæÁΩÆ‰∏≠ÔºåCWC ÂáèËΩª‰∫ÜÂéüÂßã‰∏≤Ë°å FL ÊñπÊ≥ïÁöÑÊ≥¢Âä®Ë°å‰∏∫ÔºåÂπ∂ÊåÅÁª≠‰∏îÊòæÁùÄÂú∞ÊèêÈ´ò‰∫ÜÊî∂ÊïõÊÄßËÉΩ„ÄÇÊîπËøõÂêéÁöÑÊÄßËÉΩ‰∏éÂπ∂Ë°åÈ¶ôËçâÁõ∏ÂΩìÊàñÊõ¥Â•Ω„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges**
2405.10630v1 by Xiaoming Shi, Zeming Liu, Li Du, Yuxuan Wang, Hongru Wang, Yuhang Guo, Tong Ruan, Jie Xu, Shaoting Zhang

This paper surveys and organizes research works on medical dialog systems,
which is an important yet challenging task. Although these systems have been
surveyed in the medical community from an application perspective, a systematic
review from a rigorous technical perspective has to date remained noticeably
absent. As a result, an overview of the categories, methods, and evaluation of
medical dialogue systems remain limited and underspecified, hindering the
further improvement of this area. To fill this gap, we investigate an initial
pool of 325 papers from well-known computer science, and natural language
processing conferences and journals, and make an overview. Recently, large
language models have shown strong model capacity on downstream tasks, which
also reshaped medical dialog systems' foundation. Despite the alluring
practical application value, current medical dialogue systems still suffer from
problems. To this end, this paper lists the grand challenges of medical dialog
systems, especially of large language models.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáË™øÊü•‰∏¶Êï¥ÁêÜ‰∫ÜÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ±ÁöÑÁ†îÁ©∂Â∑•‰ΩúÔºåÈÄôÊòØ‰∏ÄÈ†ÖÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÂÑòÁÆ°ÈÄô‰∫õÁ≥ªÁµ±Â∑≤ÂæûÊáâÁî®ËßíÂ∫¶Âú®ÈÜ´ÁôÇÁïåÈÄ≤Ë°åË™øÊü•Ôºå‰ΩÜËøÑ‰ªäÁÇ∫Ê≠¢‰ªçÊòéÈ°ØÁº∫‰πèÂæûÂö¥Ë¨πÊäÄË°ìËßíÂ∫¶ÈÄ≤Ë°åÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß„ÄÇÂõ†Ê≠§ÔºåÂ∞çÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ±ÁöÑÈ°ûÂà•„ÄÅÊñπÊ≥ïÂíåË©ï‰º∞ÁöÑÊ¶ÇËø∞‰ªçÁÑ∂ÊúâÈôê‰∏îÊú™ÊåáÂÆöÔºåÈòªÁ§ô‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰æÜËá™Áü•ÂêçË®àÁÆóÊ©üÁßëÂ≠∏„ÄÅËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊúÉË≠∞ÂíåÊúüÂàäÁöÑ 325 ÁØáË´ñÊñáÁöÑÂàùÂßãÂ∫´Ôºå‰∏¶ÈÄ≤Ë°å‰∫ÜÊ¶ÇËø∞„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏äË°®ÁèæÂá∫Âº∑Â§ßÁöÑÊ®°ÂûãËÉΩÂäõÔºåÈÄô‰πüÈáçÂ°ë‰∫ÜÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ±ÁöÑÂü∫Á§é„ÄÇÂÑòÁÆ°ÂÖ∑ÊúâË™ò‰∫∫ÁöÑÂØ¶ÈöõÊáâÁî®ÂÉπÂÄºÔºå‰ΩÜÁï∂ÂâçÁöÑÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ±‰ªçÁÑ∂Â≠òÂú®ÂïèÈ°å„ÄÇÁÇ∫Ê≠§ÔºåÊú¨ÊñáÂàóÂá∫‰∫ÜÈÜ´ÁôÇÂ∞çË©±Á≥ªÁµ±ÁöÑÈáçÂ§ßÊåëÊà∞ÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊåëÊà∞„ÄÇ

##### **Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**
2405.10301v2 by Yu Gui, Ying Jin, Zhimei Ren

Before deploying outputs from foundation models in high-stakes tasks, it is
imperative to ensure that they align with human values. For instance, in
radiology report generation, reports generated by a vision-language model must
align with human evaluations before their use in medical decision-making. This
paper presents Conformal Alignment, a general framework for identifying units
whose outputs meet a user-specified alignment criterion. It is guaranteed that
on average, a prescribed fraction of selected units indeed meet the alignment
criterion, regardless of the foundation model or the data distribution. Given
any pre-trained model and new units with model-generated outputs, Conformal
Alignment leverages a set of reference data with ground-truth alignment status
to train an alignment predictor. It then selects new units whose predicted
alignment scores surpass a data-dependent threshold, certifying their
corresponding outputs as trustworthy. Through applications to question
answering and radiology report generation, we demonstrate that our method is
able to accurately identify units with trustworthy outputs via lightweight
training over a moderate amount of reference data. En route, we investigate the
informativeness of various features in alignment prediction and combine them
with standard models to construct the alignment predictor.

ÊëòË¶ÅÔºöÂú®Â∞áÂü∫Á§éÊ®°ÂûãÁöÑËº∏Âá∫ÈÉ®ÁΩ≤Âà∞È´òÈ¢®Èö™‰ªªÂãô‰πãÂâçÔºåÂãôÂøÖÁ¢∫‰øùÂÆÉÂÄëÁ¨¶Âêà‰∫∫È°ûÂÉπÂÄºËßÄ„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊîæÂ∞ÑÂ≠∏Â†±ÂëäÁîüÊàê‰∏≠ÔºåÁî±Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁîüÊàêÁöÑÂ†±ÂëäÂøÖÈ†àÁ¨¶Âêà‰∫∫È°ûË©ï‰º∞ÔºåÊâçËÉΩÁî®ÊñºÈÜ´ÁôÇÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄËá¥ÊÄßÊ†°Ê∫ñÔºå‰∏ÄÂÄãÁî®ÊñºË≠òÂà•ÂÖ∂Ëº∏Âá∫Á¨¶Âêà‰ΩøÁî®ËÄÖÊåáÂÆö‰∏ÄËá¥ÊÄßÊ∫ñÂâáÁöÑÂñÆÂÖÉÁöÑÈÄöÁî®Êû∂Êßã„ÄÇÂèØ‰ª•‰øùË≠âÂπ≥ÂùáËÄåË®ÄÔºåÊâÄÈÅ∏ÂñÆÂÖÉ‰∏≠‰∏ÄÂÆöÊØî‰æãÁöÑÂñÆÂÖÉÁ¢∫ÂØ¶Á¨¶Âêà‰∏ÄËá¥ÊÄßÊ∫ñÂâáÔºåËÄåËàáÂü∫Á§éÊ®°ÂûãÊàñË≥áÊñôÂàÜ‰ΩàÁÑ°Èóú„ÄÇÁµ¶ÂÆö‰ªª‰ΩïÈ†êË®ìÁ∑¥Ê®°ÂûãÂíåÂÖ∑ÊúâÊ®°ÂûãÁîüÊàêËº∏Âá∫ÁöÑÊñ∞ÂñÆÂÖÉÔºå‰∏ÄËá¥ÊÄßÊ†°Ê∫ñÊúÉÂà©Áî®ÂÖ∑ÂÇôÂü∫Êú¨‰∫ãÂØ¶‰∏ÄËá¥ÊÄßÁãÄÊÖãÁöÑÂèÉËÄÉË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥‰∏ÄËá¥ÊÄßÈ†êÊ∏¨Âô®„ÄÇÁÑ∂ÂæåÔºåÂÆÉÊúÉÈÅ∏ÊìáÈ†êÊ∏¨‰∏ÄËá¥ÊÄßÂàÜÊï∏Ë∂ÖÈÅéË≥áÊñôÁõ∏ÈóúÈñæÂÄºÁöÑÂñÆÂÖÉÔºå‰∏¶Ë≠âÊòéÂÖ∂Â∞çÊáâÁöÑËº∏Âá∫ÂÄºÂæó‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊáâÁî®ÊñºÂïèÈ°åËß£Á≠îÂíåÊîæÂ∞ÑÂ≠∏Â†±ÂëäÁîüÊàêÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïËÉΩÂ§†ÈÄèÈÅéÂ§ßÈáèÂèÉËÄÉË≥áÊñô‰∏äÁöÑËºïÈáèÁ¥öË®ìÁ∑¥ÔºåÊ∫ñÁ¢∫Ë≠òÂà•ÂÖ∑ÊúâÂèØ‰ø°Ë≥¥Ëº∏Âá∫ÁöÑÂñÆÂÖÉ„ÄÇÂú®ÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂêÑÁ®ÆÁâπÂæµÂú®‰∏ÄËá¥ÊÄßÈ†êÊ∏¨‰∏≠ÁöÑË≥áË®äÈáèÔºå‰∏¶Â∞áÂÆÉÂÄëËàáÊ®ôÊ∫ñÊ®°ÂûãÁµêÂêàËµ∑‰æÜÂª∫Êßã‰∏ÄËá¥ÊÄßÈ†êÊ∏¨Âô®„ÄÇ

##### **Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**
2405.10216v1 by Divij Gupta, Anubhav Bhatti, Suraj Parmar, Chen Dan, Yuwei Liu, Bingjie Shen, San Lee

Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large
pre-trained or foundational models across different modalities and tasks.
However, its application to time series data, particularly within foundational
models, remains underexplored. This paper examines the impact of LoRA on
contemporary time series foundational models: Lag-Llama, MOIRAI, and Chronos.
We demonstrate LoRA's fine-tuning potential for forecasting the vital signs of
sepsis patients in intensive care units (ICUs), emphasizing the models'
adaptability to previously unseen, out-of-domain modalities. Integrating LoRA
aims to enhance forecasting performance while reducing inefficiencies
associated with fine-tuning large models on limited domain-specific data. Our
experiments show that LoRA fine-tuning of time series foundational models
significantly improves forecasting, achieving results comparable to
state-of-the-art models trained from scratch on similar modalities. We conduct
comprehensive ablation studies to demonstrate the trade-offs between the number
of tunable parameters and forecasting performance and assess the impact of
varying LoRA matrix ranks on model performance.

ÊëòË¶ÅÔºö‰ΩéÁß©ÈÅ©Êáâ (LoRA) ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁî®ÊñºÂæÆË™ø‰∏çÂêåÊ®°ÊÖãÂíå‰ªªÂãôÁöÑÂ§ßÂûãÈ†êË®ìÁ∑¥ÊàñÂü∫Á§éÊ®°ÂûãÁöÑÊäÄË°ì„ÄÇ
ÁÑ∂ËÄåÔºåÂÆÉÂú®ÊôÇÈñìÂ∫èÂàóÊï∏Êìö‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂú®Âü∫Á§éÊ®°Âûã‰∏≠Ôºå‰ªçÁÑ∂ËôïÊñºÊé¢Á¥¢‰∏çË∂≥ÁöÑÈöéÊÆµ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü LoRA Â∞çÁï∂‰ª£ÊôÇÈñìÂ∫èÂàóÂü∫Á§éÊ®°ÂûãÁöÑÂΩ±ÈüøÔºöLag-Llama„ÄÅMOIRAI Âíå Chronos„ÄÇ
ÊàëÂÄëÂ±ïÁ§∫‰∫Ü LoRA Âú®È†êÊ∏¨ÈáçÁóáÁõ£Ë≠∑ÁóÖÊàø (ICU) ‰∏≠ÊïóË°ÄÁóáÊÇ£ËÄÖÁîüÂëΩÈ´îÂæµÊñπÈù¢ÁöÑÂæÆË™øÊΩõÂäõÔºåÂº∑Ë™ø‰∫ÜÊ®°ÂûãÂ∞ç‰ª•ÂâçÊú™Ë¶ãÁöÑ„ÄÅË∂ÖÂá∫È†òÂüüÊ®°ÂºèÁöÑÈÅ©ÊáâÊÄß„ÄÇ
Êï¥Âêà LoRA Êó®Âú®Â¢ûÂº∑È†êÊ∏¨ÊÄßËÉΩÔºåÂêåÊôÇÊ∏õÂ∞ëËàáÂú®ÊúâÈôêÁöÑÁâπÂÆöÈ†òÂüüÊï∏Êìö‰∏äÂæÆË™øÂ§ßÂûãÊ®°ÂûãÁõ∏ÈóúÁöÑ‰ΩéÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊôÇÈñìÂ∫èÂàóÂü∫Á§éÊ®°ÂûãÁöÑ LoRA ÂæÆË™øÈ°ØËëóÊîπÂñÑ‰∫ÜÈ†êÊ∏¨ÔºåÂØ¶Áèæ‰∫ÜËàáÂæûÈ°û‰ººÊ®°Âºè‰∏≠ÂæûÈ†≠Ë®ìÁ∑¥ÁöÑÊúÄÊñ∞Ê®°ÂûãÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•Â±ïÁ§∫ÂèØË™øÂèÉÊï∏Êï∏ÈáèÂíåÈ†êÊ∏¨ÊÄßËÉΩ‰πãÈñìÁöÑÊ¨äË°°Ôºå‰∏¶Ë©ï‰º∞‰∏çÂêå LoRA Áü©Èô£Áß©Â∞çÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±Èüø„ÄÇ

##### **HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical Phase Recognition**
2405.10075v1 by Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy

Natural language could play an important role in developing generalist
surgical models by providing a broad source of supervision from raw texts. This
flexible form of supervision can enable the model's transferability across
datasets and tasks as natural language can be used to reference learned visual
concepts or describe new ones. In this work, we present HecVL, a novel
hierarchical video-language pretraining approach for building a generalist
surgical model. Specifically, we construct a hierarchical video-text paired
dataset by pairing the surgical lecture video with three hierarchical levels of
texts: at clip-level, atomic actions using transcribed audio texts; at
phase-level, conceptual text summaries; and at video-level, overall abstract
text of the surgical procedure. Then, we propose a novel fine-to-coarse
contrastive learning framework that learns separate embedding spaces for the
three video-text hierarchies using a single model. By disentangling embedding
spaces of different hierarchical levels, the learned multi-modal
representations encode short-term and long-term surgical concepts in the same
model. Thanks to the injected textual semantics, we demonstrate that the HecVL
approach can enable zero-shot surgical phase recognition without any human
annotation. Furthermore, we show that the same HecVL model for surgical phase
recognition can be transferred across different surgical procedures and medical
centers.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄÂèØ‰ª•Âú®ÈñãÁôºÈÄöÁî®ÁöÑÂ§ñÁßëÊ®°Âûã‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤ÔºåÂÆÉÂèØ‰ª•Êèê‰æõÂª£Ê≥õÁöÑÂéüÂßãÊñáÊú¨Áõ£Áù£‰æÜÊ∫ê„ÄÇÈÄôÁ®ÆÈùàÊ¥ªÁöÑÁõ£Áù£ÂΩ¢ÂºèÂèØ‰ª•‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®Ä‰æÜÂèÉËÄÉÂ∑≤Â≠∏ÁøíÁöÑË¶ñË¶∫Ê¶ÇÂøµÊàñÊèèËø∞Êñ∞ÁöÑÊ¶ÇÂøµÔºåÂæûËÄå‰ΩøÊ®°ÂûãËÉΩÂ§†Ë∑®Êï∏ÊìöÈõÜÂíå‰ªªÂãôÈÄ≤Ë°åËΩâÁßª„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü HecVLÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂàÜÂ±§Ë¶ñÈ†ªË™ûË®ÄÈ†êË®ìÁ∑¥ÊñπÊ≥ïÔºåÁî®ÊñºÊßãÂª∫ÈÄöÁî®ÁöÑÂ§ñÁßëÊ®°Âûã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂàÜÂ±§Ë¶ñÈ†ªÊñáÊú¨ÈÖçÂ∞çÊï∏ÊìöÈõÜÔºåÈÄöÈÅéÂ∞áÂ§ñÁßëÊâãË°ìË¨õËß£Ë¶ñÈ†ªËàá‰∏âÁ¥öÂàÜÂ±§ÊñáÊú¨ÈÖçÂ∞çÔºöÂú®ÁâáÊÆµÁ¥öÂà•Ôºå‰ΩøÁî®ËΩâÈåÑÁöÑÈü≥È†ªÊñáÊú¨ÈÄ≤Ë°åÂéüÂ≠êÊìç‰ΩúÔºõÂú®ÈöéÊÆµÁ¥öÂà•ÔºåÊ¶ÇÂøµÊñáÊú¨ÊëòË¶ÅÔºõÂú®Ë¶ñÈ†ªÁ¥öÂà•ÔºåÂ§ñÁßëÊâãË°ìÁöÑÊï¥È´îÊëòË¶ÅÊñáÊú¨„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁ≤æÂà∞Á≤óÁï•Â∞çÊØîÂ≠∏ÁøíÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂‰ΩøÁî®ÂñÆÂÄãÊ®°ÂûãÁÇ∫‰∏âÂÄãË¶ñÈ†ªÊñáÊú¨Â±§Ê¨°ÁµêÊßãÂ≠∏ÁøíÂñÆÁç®ÁöÑÂµåÂÖ•Á©∫Èñì„ÄÇÈÄöÈÅéËß£Èñã‰∏çÂêåÂ±§Ê¨°ÁµêÊßãÁöÑÂµåÂÖ•Á©∫ÈñìÔºåÂ≠∏ÁøíÂà∞ÁöÑÂ§öÊ®°ÊÖãË°®Á§∫Âú®Âêå‰∏ÄÂÄãÊ®°Âûã‰∏≠Á∑®Á¢º‰∫ÜÁü≠ÊúüÂíåÈï∑ÊúüÁöÑÂ§ñÁßëÊ¶ÇÂøµ„ÄÇÁî±ÊñºÊ≥®ÂÖ•‰∫ÜÊñáÊú¨Ë™ûÁæ©ÔºåÊàëÂÄëË≠âÊòé‰∫Ü HecVL ÊñπÊ≥ïÂèØ‰ª•Âú®Ê≤íÊúâ‰ªª‰Ωï‰∫∫Â∑•Ë®ªËß£ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈõ∂Ê¨°Â§ñÁßëÊâãË°ìÈöéÊÆµË≠òÂà•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÔºåÁî®ÊñºÂ§ñÁßëÊâãË°ìÈöéÊÆµË≠òÂà•ÁöÑÁõ∏Âêå HecVL Ê®°ÂûãÂèØ‰ª•ËΩâÁßªÂà∞‰∏çÂêåÁöÑÂ§ñÁßëÊâãË°ìÂíåÈÜ´ÁôÇ‰∏≠ÂøÉ„ÄÇ

##### **Histopathology Foundation Models Enable Accurate Ovarian Cancer Subtype Classification**
2405.09990v1 by Jack Breen, Katie Allen, Kieran Zucker, Lucy Godson, Nicolas M. Orsi, Nishant Ravikumar

Large pretrained transformers are increasingly being developed as generalised
foundation models which can underpin powerful task-specific artificial
intelligence models. Histopathology foundation models show promise across many
tasks, but analyses have been limited by arbitrary hyperparameters that were
not tuned to the specific task/dataset. We report the most rigorous single-task
validation conducted to date of a histopathology foundation model, and the
first performed in ovarian cancer subtyping. Attention-based multiple instance
learning classifiers were compared using vision transformer and ResNet features
generated through varied preprocessing and pretraining procedures. The training
set consisted of 1864 whole slide images from 434 ovarian carcinoma cases at
Leeds Hospitals. Five-class classification performance was evaluated through
five-fold cross-validation, and these cross-validation models were ensembled
for evaluation on a hold-out test set and an external set from the
Transcanadian study. Reporting followed the TRIPOD+AI checklist. The vision
transformer-based histopathology foundation model, UNI, performed best in every
evaluation, with five-class balanced accuracies of 88% and 93% in hold-out
internal and external testing, compared to the best ResNet model scores of 68%
and 81%, respectively. Normalisations and augmentations aided the
generalisability of ResNet-based models, but these still did not match the
performance of UNI, which gave the best external performance in any ovarian
cancer subtyping study to date. Histopathology foundation models offer a clear
benefit to subtyping, improving classification performance to a degree where
clinical utility is tangible, albeit with an increased computational burden.
Such models could provide a second opinion in challenging cases and may improve
the accuracy, objectivity, and efficiency of pathological diagnoses overall.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãÈ¢ÑËÆ≠ÁªÉ Transformer Ê≠£Êó•Áõä‰Ωú‰∏∫ÈÄöÁî®Âü∫Á°ÄÊ®°ÂûãËÄåÂºÄÂèëÔºåÂÆÉÂèØ‰ª•ÊîØÊíëÂº∫Â§ßÁöÑÁâπÂÆö‰ªªÂä°‰∫∫Â∑•Êô∫ËÉΩÊ®°Âûã„ÄÇÁªÑÁªáÁóÖÁêÜÂ≠¶Âü∫Á°ÄÊ®°ÂûãÂú®ËÆ∏Â§ö‰ªªÂä°‰∏≠ÊòæÁ§∫Âá∫ÂâçÊôØÔºå‰ΩÜÂàÜÊûêÂèóÂà∞Êú™ÈíàÂØπÁâπÂÆö‰ªªÂä°/Êï∞ÊçÆÈõÜËøõË°åË∞ÉÊï¥ÁöÑ‰ªªÊÑèË∂ÖÂèÇÊï∞ÁöÑÈôêÂà∂„ÄÇÊàë‰ª¨Êä•Âëä‰∫ÜËøÑ‰ªä‰∏∫Ê≠¢ÂØπÁªÑÁªáÁóÖÁêÜÂ≠¶Âü∫Á°ÄÊ®°ÂûãËøõË°åÁöÑÊúÄ‰∏•Ê†ºÁöÑÂçï‰ªªÂä°È™åËØÅÔºå‰ª•ÂèäÂú®ÂçµÂ∑¢Áôå‰∫öÂûãÂàÜÁ±ª‰∏≠ËøõË°åÁöÑÈ¶ñÊ¨°È™åËØÅ„ÄÇÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÂ§öÂÆû‰æãÂ≠¶‰π†ÂàÜÁ±ªÂô®‰ΩøÁî®ÈÄöËøá‰∏çÂêåÁöÑÈ¢ÑÂ§ÑÁêÜÂíåÈ¢ÑËÆ≠ÁªÉËøáÁ®ãÁîüÊàêÁöÑËßÜËßâ Transformer Âíå ResNet ÁâπÂæÅËøõË°å‰∫ÜÊØîËæÉ„ÄÇËÆ≠ÁªÉÈõÜÁî±Âà©ÂÖπÂåªÈô¢ 434 ‰æãÂçµÂ∑¢ÁôåÁóÖ‰æãÁöÑ 1864 Âº†ÂÖ®ÂπªÁÅØÁâáÂõæÂÉèÁªÑÊàê„ÄÇ‰∫îÁ±ªÂàÜÁ±ªÊÄßËÉΩÈÄöËøá‰∫îÊäò‰∫§ÂèâÈ™åËØÅËøõË°åËØÑ‰º∞ÔºåËøô‰∫õ‰∫§ÂèâÈ™åËØÅÊ®°ÂûãË¢´ÈõÜÊàêÁî®‰∫éÂú®‰øùÁïôÊµãËØïÈõÜÂíå Transcanadian Á†îÁ©∂ÁöÑÂ§ñÈÉ®ÈõÜ‰∏äËøõË°åËØÑ‰º∞„ÄÇÊä•ÂëäÈÅµÂæ™ TRIPOD+AI Ê∏ÖÂçï„ÄÇÂü∫‰∫éËßÜËßâ Transformer ÁöÑÁªÑÁªáÁóÖÁêÜÂ≠¶Âü∫Á°ÄÊ®°Âûã UNI Âú®ÊØèÊ¨°ËØÑ‰º∞‰∏≠Ë°®Áé∞ÊúÄ‰Ω≥ÔºåÂú®‰øùÁïôÂÜÖÈÉ®ÂíåÂ§ñÈÉ®ÊµãËØï‰∏≠ÁöÑ‰∫îÁ±ªÂπ≥Ë°°ÂáÜÁ°ÆÁéáÂàÜÂà´‰∏∫ 88% Âíå 93%ÔºåËÄåÊúÄ‰Ω≥ ResNet Ê®°ÂûãÂæóÂàÜÂàÜÂà´‰∏∫ 68% Âíå 81%„ÄÇÂΩí‰∏ÄÂåñÂíåÂ¢ûÂº∫ÊúâÂä©‰∫éÂü∫‰∫é ResNet ÁöÑÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰ΩÜËøô‰∫õ‰ªçÁÑ∂Êó†Ê≥ï‰∏é UNI ÁöÑÊÄßËÉΩÁõ∏ÂåπÈÖçÔºåUNI Âú®ËøÑ‰ªä‰∏∫Ê≠¢ÁöÑ‰ªª‰ΩïÂçµÂ∑¢Áôå‰∫öÂûãÂàÜÁ±ªÁ†îÁ©∂‰∏≠ÈÉΩÁªôÂá∫‰∫ÜÊúÄ‰Ω≥ÁöÑÂ§ñÈÉ®ÊÄßËÉΩ„ÄÇÁªÑÁªáÁóÖÁêÜÂ≠¶Âü∫Á°ÄÊ®°Âûã‰∏∫‰∫öÂûãÂàÜÁ±ªÊèê‰æõ‰∫ÜÊòéÊòæÁöÑÂ•ΩÂ§ÑÔºåÂ∞ÜÂàÜÁ±ªÊÄßËÉΩÊèêÈ´òÂà∞‰∏¥Â∫äÊïàÁî®ÂàáÂÆûÂèØË°åÁöÑÁ®ãÂ∫¶ÔºåÂ∞ΩÁÆ°Â¢ûÂä†‰∫ÜËÆ°ÁÆóË¥üÊãÖ„ÄÇÊ≠§Á±ªÊ®°ÂûãÂèØ‰ª•Âú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÁóÖ‰æã‰∏≠Êèê‰æõÁ¨¨‰∫åÊÑèËßÅÔºåÂπ∂ÂèØËÉΩÊèêÈ´òÁóÖÁêÜËØäÊñ≠ÁöÑÂáÜÁ°ÆÊÄß„ÄÅÂÆ¢ËßÇÊÄßÂíåÊïàÁéá„ÄÇ</paragraph>

##### **Predicting Solar Heat Production to Optimize Renewable Energy Usage**
2405.09972v1 by Tatiana Boura, Natalia Koliou, George Meramveliotakis, Stasinos Konstantopoulos, George Kosmadakis

Utilizing solar energy to meet space heating and domestic hot water demand is
very efficient (in terms of environmental footprint as well as cost), but in
order to ensure that user demand is entirely covered throughout the year needs
to be complemented with auxiliary heating systems, typically boilers and heat
pumps. Naturally, the optimal control of such a system depends on an accurate
prediction of solar thermal production.
  Experimental testing and physics-based numerical models are used to find a
collector's performance curve - the mapping from solar radiation and other
external conditions to heat production - but this curve changes over time once
the collector is exposed to outdoor conditions. In order to deploy advanced
control strategies in small domestic installations, we present an approach that
uses machine learning to automatically construct and continuously adapt a model
that predicts heat production. Our design is driven by the need to (a)
construct and adapt models using supervision that can be extracted from
low-cost instrumentation, avoiding extreme accuracy and reliability
requirements; and (b) at inference time, use inputs that are typically provided
in publicly available weather forecasts.
  Recent developments in attention-based machine learning, as well as careful
adaptation of the training setup to the specifics of the task, have allowed us
to design a machine learning-based solution that covers our requirements. We
present positive empirical results for the predictive accuracy of our solution,
and discuss the impact of these results on the end-to-end system.

ÊëòË¶ÅÔºöÂà©Áî®Â§™ÈôΩËÉΩ‰æÜÊªøË∂≥Á©∫ÈñìÂä†ÁÜ±ÂíåÁîüÊ¥ªÁÜ±Ê∞¥ÈúÄÊ±ÇÈùûÂ∏∏ÊúâÊïàÁéáÔºàÁÑ°Ë´ñÂú®Áí∞Â¢ÉË∂≥Ë∑°ÊàñÊàêÊú¨ÊñπÈù¢ÔºâÔºå‰ΩÜÁÇ∫‰∫ÜÁ¢∫‰øù‰ΩøÁî®ËÄÖÈúÄÊ±ÇÂÖ®Âπ¥ÈÉΩËÉΩÊªøË∂≥ÔºåÈúÄË¶ÅËºîÂä©Âä†ÁÜ±Á≥ªÁµ±ÔºåÈÄöÂ∏∏ÊòØÈçãÁàêÂíåÁÜ±Ê≥µ„ÄÇËá™ÁÑ∂Âú∞ÔºåÊ≠§È°ûÁ≥ªÁµ±ÁöÑÊúÄ‰Ω≥ÊéßÂà∂ÂèñÊ±∫ÊñºÂ§™ÈôΩÁÜ±ËÉΩÁîüÁî¢ÁöÑÊ∫ñÁ¢∫È†êÊ∏¨„ÄÇ
ÂØ¶È©óÊ∏¨Ë©¶ÂíåÂü∫ÊñºÁâ©ÁêÜÁöÑÊï∏ÂÄºÊ®°ÂûãÁî®ÊñºÊâæÂà∞ÈõÜÁÜ±Âô®ÁöÑÊïàËÉΩÊõ≤Á∑öÔºåÂç≥ÂæûÂ§™ÈôΩËºªÂ∞ÑÂíåÂÖ∂‰ªñÂ§ñÈÉ®Ê¢ù‰ª∂Âà∞ÁÜ±ËÉΩÁîüÁî¢ÁöÑÂ∞çÊáâÈóú‰øÇÔºå‰ΩÜÊ≠§Êõ≤Á∑öÂú®ÈõÜÁÜ±Âô®Êö¥Èú≤ÊñºÊà∂Â§ñÊ¢ù‰ª∂ÂæåÊúÉÈö®ÊôÇÈñìËÄåÊîπËÆä„ÄÇÁÇ∫‰∫ÜÂú®Â∞èÂûãÂÆ∂Áî®Ë£ùÁΩÆ‰∏≠ÈÉ®ÁΩ≤ÂÖàÈÄ≤ÁöÑÊéßÂà∂Á≠ñÁï•ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíËá™ÂãïÊßãÂª∫ÂíåÊåÅÁ∫åË™øÊï¥Ê®°ÂûãÁöÑÊñπÊ≥ïÔºåË©≤Ê®°ÂûãÂèØ‰ª•È†êÊ∏¨ÁÜ±ËÉΩÁîüÁî¢„ÄÇÊàëÂÄëÁöÑË®≠Ë®àÊòØÁî±‰ª•‰∏ãÈúÄÊ±ÇÈ©ÖÂãïÁöÑÔºö(a) ‰ΩøÁî®ÂèØÂæû‰ΩéÊàêÊú¨ÂÑÄÂô®‰∏≠ÊèêÂèñÁöÑÁõ£Áù£‰æÜÊßãÂª∫ÂíåË™øÊï¥Ê®°ÂûãÔºåÈÅøÂÖçÊ•µÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄßË¶ÅÊ±ÇÔºõ(b) Âú®Êé®ÁêÜÊôÇÔºå‰ΩøÁî®ÈÄöÂ∏∏Âú®ÂÖ¨ÈñãÂ§©Ê∞£È†êÂ†±‰∏≠Êèê‰æõÁöÑËº∏ÂÖ•„ÄÇ
Âü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊ©üÂô®Â≠∏ÁøíÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºå‰ª•ÂèäÂ∞çË®ìÁ∑¥Ë®≠ÁΩÆÈÄ≤Ë°å‰ªîÁ¥∞Ë™øÊï¥‰ª•ÈÅ©Êáâ‰ªªÂãôÁöÑÂÖ∑È´îÊÉÖÊ≥ÅÔºå‰ΩøÊàëÂÄëËÉΩÂ§†Ë®≠Ë®àÂá∫ÊªøË∂≥ÊàëÂÄëË¶ÅÊ±ÇÁöÑÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëËß£Ê±∫ÊñπÊ°àÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÁöÑÊ≠£Èù¢Á∂ìÈ©óÁµêÊûúÔºå‰∏¶Ë®éË´ñ‰∫ÜÈÄô‰∫õÁµêÊûúÂ∞çÁ´ØÂà∞Á´ØÁ≥ªÁµ±ÁöÑÂΩ±Èüø„ÄÇ

##### **Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fr√©chet Domain Distance**
2405.09934v1 by Milda Poceviƒçi≈´tƒó, Gabriel Eilertsen, Stina Garvin, Claes Lundstr√∂m

Multiple-instance learning (MIL) is an attractive approach for digital
pathology applications as it reduces the costs related to data collection and
labelling. However, it is not clear how sensitive MIL is to clinically
realistic domain shifts, i.e., differences in data distribution that could
negatively affect performance, and if already existing metrics for detecting
domain shifts work well with these algorithms. We trained an attention-based
MIL algorithm to classify whether a whole-slide image of a lymph node contains
breast tumour metastases. The algorithm was evaluated on data from a hospital
in a different country and various subsets of this data that correspond to
different levels of domain shift. Our contributions include showing that MIL
for digital pathology is affected by clinically realistic differences in data,
evaluating which features from a MIL model are most suitable for detecting
changes in performance, and proposing an unsupervised metric named Fr\'echet
Domain Distance (FDD) for quantification of domain shifts. Shift measure
performance was evaluated through the mean Pearson correlation to change in
classification performance, where FDD achieved 0.70 on 10-fold cross-validation
models. The baselines included Deep ensemble, Difference of Confidence, and
Representation shift which resulted in 0.45, -0.29, and 0.56 mean Pearson
correlation, respectively. FDD could be a valuable tool for care providers and
vendors who need to verify if a MIL system is likely to perform reliably when
implemented at a new site, without requiring any additional annotations from
pathologists.

ÊëòË¶ÅÔºöÂ§öÂØ¶‰æãÂ≠∏Áøí (MIL) ÊòØ‰∏ÄÁ®ÆÂ∞çÊï∏‰ΩçÁóÖÁêÜÊáâÁî®ËÄåË®ÄÂÖ∑ÊúâÂê∏ÂºïÂäõÁöÑÊñπÊ≥ïÔºåÂõ†ÁÇ∫ÂÆÉÈôç‰Ωé‰∫ÜËàáË≥áÊñôËíêÈõÜÂíåÊ®ôÁ±§Áõ∏ÈóúÁöÑÊàêÊú¨„ÄÇÁÑ∂ËÄåÔºåMIL Â∞çËá®Â∫äÁèæÂØ¶È†òÂüüËΩâÁßªÁöÑÊïèÊÑüÂ∫¶‰∏¶‰∏çÊ∏ÖÊ•öÔºå‰πüÂ∞±ÊòØË™™ÔºåË≥áÊñôÂàÜ‰ΩàÁöÑÂ∑ÆÁï∞ÂèØËÉΩÊúÉÂ∞çÊïàËÉΩÈÄ†ÊàêË≤†Èù¢ÂΩ±ÈüøÔºåËÄå‰∏îÁèæÊúâÁöÑÈ†òÂüüËΩâÁßªÂÅµÊ∏¨ÊåáÊ®ôÊòØÂê¶ËÉΩÈ†ÜÂà©ËàáÈÄô‰∫õÊºîÁÆóÊ≥ïÊê≠ÈÖç‰ΩøÁî®„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑ MIL ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂàÜÈ°ûÊ∑ãÂ∑¥ÁµêÁöÑÊï¥ÂºµÂπªÁáàÁâáÂΩ±ÂÉèÊòØÂê¶ÂåÖÂê´‰π≥ÊàøËÖ´Áò§ËΩâÁßª„ÄÇË©≤ÊºîÁÆóÊ≥ïÂú®‰∏çÂêåÂúãÂÆ∂ÁöÑÈÜ´Èô¢Ë≥áÊñôÂíåÂ∞çÊáâÊñº‰∏çÂêåÁ®ãÂ∫¶È†òÂüüËΩâÁßªÁöÑÂêÑÁ®ÆË≥áÊñôÂ≠êÈõÜ‰∏≠ÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨È°ØÁ§∫Áî®ÊñºÊï∏‰ΩçÁóÖÁêÜÁöÑ MIL ÊúÉÂèóÂà∞Ë≥áÊñôÂú®Ëá®Â∫ä‰∏äÂØ¶ÈöõÁöÑÂ∑ÆÁï∞ÂΩ±ÈüøÔºåË©ï‰º∞ MIL Ê®°Âûã‰∏≠ÁöÑÂì™‰∫õÁâπÂæµÊúÄÈÅ©ÂêàÁî®ÊñºÂÅµÊ∏¨ÊïàËÉΩËÆäÂåñÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ Fr\'echet È†òÂüüË∑ùÈõ¢ (FDD) ÁöÑÈùûÁõ£Áù£ÂºèÊåáÊ®ôÔºåÁî®ÊñºÈáèÂåñÈ†òÂüüËΩâÁßª„ÄÇËΩâÁßªÊ∏¨ÈáèÊïàËÉΩÈÄèÈÅéËàáÂàÜÈ°ûÊïàËÉΩËÆäÂåñÁöÑÂπ≥ÂùáÁöÆÁàæÊ£ÆÁõ∏ÈóúÊÄßÈÄ≤Ë°åË©ï‰º∞ÔºåÂÖ∂‰∏≠ FDD Âú® 10 ÂÄç‰∫§ÂèâÈ©óË≠âÊ®°Âûã‰∏≠ÈÅîÂà∞ 0.70„ÄÇÂü∫Ê∫ñÁ∑öÂåÖÊã¨Ê∑±Â∫¶Êï¥È´î„ÄÅ‰ø°ÂøÉÂ∑ÆÁï∞ÂíåË°®Á§∫ËΩâÁßªÔºåÂàÜÂà•Áî¢Áîü 0.45„ÄÅ-0.29 Âíå 0.56 ÁöÑÂπ≥ÂùáÁöÆÁàæÊ£ÆÁõ∏ÈóúÊÄß„ÄÇFDD ÂèØËÉΩÊòØ‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑Ôºå‰æõÁÖßË≠∑Êèê‰æõËÄÖÂíå‰æõÊáâÂïÜÂú®ÂØ¶ÊñΩÊñ∞ÁöÑÂ†¥ÂüüÊôÇÈ©óË≠â MIL Á≥ªÁµ±ÊòØÂê¶ÂèØËÉΩÂü∑Ë°åÂèØÈù†ÁöÑÊïàËÉΩÔºåËÄå‰∏çÈúÄË¶ÅÁóÖÁêÜÂ≠∏ÂÆ∂ÁöÑ‰ªª‰ΩïÈ°çÂ§ñË®ªËß£„ÄÇ

##### **Crowdsourcing with Enhanced Data Quality Assurance: An Efficient Approach to Mitigate Resource Scarcity Challenges in Training Large Language Models for Healthcare**
2405.13030v1 by P. Barai, G. Leroy, P. Bisht, J. M. Rothman, S. Lee, J. Andrews, S. A. Rice, A. Ahmed

Large Language Models (LLMs) have demonstrated immense potential in
artificial intelligence across various domains, including healthcare. However,
their efficacy is hindered by the need for high-quality labeled data, which is
often expensive and time-consuming to create, particularly in low-resource
domains like healthcare. To address these challenges, we propose a
crowdsourcing (CS) framework enriched with quality control measures at the
pre-, real-time-, and post-data gathering stages. Our study evaluated the
effectiveness of enhancing data quality through its impact on LLMs (Bio-BERT)
for predicting autism-related symptoms. The results show that real-time quality
control improves data quality by 19 percent compared to pre-quality control.
Fine-tuning Bio-BERT using crowdsourced data generally increased recall
compared to the Bio-BERT baseline but lowered precision. Our findings
highlighted the potential of crowdsourcing and quality control in
resource-constrained environments and offered insights into optimizing
healthcare LLMs for informed decision-making and improved patient care.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠Â±ïÁèæÂá∫Â∑®Â§ßÁöÑÊΩõÂäõÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÊïàËÉΩÂèóÂà∞Â∞çÈ´òÂìÅË≥™Ê®ôÁ±§Ë≥áÊñôÁöÑÈúÄÊ±ÇÊâÄÈòªÁ§ôÔºåËÄåÂª∫Á´ãÈÄô‰∫õË≥áÊñôÈÄöÂ∏∏Êó¢ÊòÇË≤¥ÂèàË≤ªÊôÇÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠â‰ΩéË≥áÊ∫êÈ†òÂüü„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁæ§ÁúæÂ§ñÂåÖ (CS) Êû∂ÊßãÔºå‰∏¶Âú®Ë≥áÊñôÊî∂ÈõÜÁöÑÈ†êÂÖà„ÄÅÂç≥ÊôÇÂíåÂæåÁ∫åÈöéÊÆµÂä†ÂÖ•‰∫ÜÂìÅË≥™ÊéßÂà∂Êé™ÊñΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë©ï‰º∞‰∫ÜÈÄèÈÅéÂÖ∂Â∞ç LLM (Bio-BERT) ÁöÑÂΩ±Èüø‰æÜÊèêÂçáË≥áÊñôÂìÅË≥™ÁöÑÊúâÊïàÊÄßÔºå‰ª•È†êÊ∏¨Ëá™ÈñâÁóáÁõ∏ÈóúÁóáÁãÄ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËàáÈ†êÂÖàÂìÅË≥™ÊéßÂà∂Áõ∏ÊØîÔºåÂç≥ÊôÇÂìÅË≥™ÊéßÂà∂Â∞áË≥áÊñôÂìÅË≥™ÊèêÂçá‰∫Ü 19%„ÄÇËàá Bio-BERT Âü∫Ê∫ñÁõ∏ÊØîÔºå‰ΩøÁî®Áæ§ÁúæÂ§ñÂåÖË≥áÊñôÂæÆË™ø Bio-BERT ÈÄöÂ∏∏ÊúÉÊèêÈ´òÂè¨ÂõûÁéáÔºå‰ΩÜÊúÉÈôç‰ΩéÁ≤æÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÁæ§ÁúæÂ§ñÂåÖÂíåÂìÅË≥™ÊéßÂà∂Âú®Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÁöÑÊΩõÂäõÔºå‰∏¶Êèê‰æõ‰∫ÜÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ• LLM ‰ª•ÈÄ≤Ë°åÊòéÊô∫Ê±∫Á≠ñÂíåÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑ÁöÑË¶ãËß£„ÄÇ

##### **A Farewell to Harms: Risk Management for Medical Devices via the Riskman Ontology & Shapes**
2405.09875v2 by Piotr Gorczyca, D√∂rthe Arndt, Martin Diller, Pascal Kettmann, Stephan Mennicke, Hannes Strass

We introduce the Riskman ontology & shapes for representing and analysing
information about risk management for medical devices. Risk management is
concerned with taking necessary precautions so a medical device does not cause
harms for users or the environment. To date, risk management documentation is
submitted to notified bodies (for certification) in the form of semi-structured
natural language text. We propose to use classes from the Riskman ontology to
logically model risk management documentation and to use the included SHACL
constraints to check for syntactic completeness and conformity to relevant
standards. In particular, the ontology is modelled after ISO 14971 and the
recently published VDE Spec 90025. Our proposed methodology has the potential
to save many person-hours for both manufacturers (when creating risk management
documentation) as well as notified bodies (when assessing submitted
applications for certification), and thus offers considerable benefits for
healthcare and, by extension, society as a whole.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü Riskman ontology ÂíåÂΩ¢ÁãÄÔºåÁî®ÊñºË°®Á§∫ÂíåÂàÜÊûêÈÜ´ÁôÇÂô®ÊùêÈ¢®Èö™ÁÆ°ÁêÜÁöÑË≥áË®ä„ÄÇÈ¢®Èö™ÁÆ°ÁêÜÈóúÊ≥®Êé°ÂèñÂøÖË¶ÅÁöÑÈ†êÈò≤Êé™ÊñΩÔºåËÆìÈÜ´ÁôÇÂô®Êùê‰∏çÊúÉÂ∞ç‰ΩøÁî®ËÄÖÊàñÁí∞Â¢ÉÈÄ†ÊàêÂç±ÂÆ≥„ÄÇËøÑ‰ªäÁÇ∫Ê≠¢ÔºåÈ¢®Èö™ÁÆ°ÁêÜÊñá‰ª∂ÊòØ‰ª•ÂçäÁµêÊßãÂåñÁöÑËá™ÁÑ∂Ë™ûË®ÄÊñáÂ≠óÂΩ¢ÂºèÊèê‰∫§Áµ¶ÂÖ¨ÂëäÂñÆ‰ΩçÔºàÁî®ÊñºË™çË≠âÔºâ„ÄÇÊàëÂÄëÊèêË≠∞‰ΩøÁî® Riskman ontology ‰∏≠ÁöÑÈ°ûÂà•Ôºå‰ª•ÈÇèËºØÊñπÂºèÂª∫ÊßãÈ¢®Èö™ÁÆ°ÁêÜÊñá‰ª∂Ôºå‰∏¶‰ΩøÁî®ÊâÄÂåÖÂê´ÁöÑ SHACL Á¥ÑÊùüÔºåÊ™¢Êü•Ë™ûÊ≥ïÂÆåÊï¥ÊÄßÂíåÊòØÂê¶Á¨¶ÂêàÁõ∏ÈóúÊ®ôÊ∫ñ„ÄÇÁâπÂà•ÊòØÔºåontology ÊòØÊ†πÊìö ISO 14971 ÂíåÊúÄËøëÁôºÂ∏ÉÁöÑ VDE Spec 90025 Âª∫ÊßãÁöÑ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïË´ñÊúâÂèØËÉΩÁÇ∫Ë£ΩÈÄ†ÂïÜÔºàÂú®Âª∫Á´ãÈ¢®Èö™ÁÆ°ÁêÜÊñá‰ª∂ÊôÇÔºâÂíåÂÖ¨ÂëäÂñÆ‰ΩçÔºàÂú®Ë©ï‰º∞Êèê‰∫§ÁöÑË™çË≠âÁî≥Ë´ãÊôÇÔºâÁØÄÁúÅÂ§ßÈáèÁöÑ‰∫∫ÂäõÔºåÂõ†Ê≠§Â∞çÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ª•ÂèäÈÄ≤‰∏ÄÊ≠•Êì¥Â±ïÂà∞Êï¥ÂÄãÁ§æÊúÉÔºåÈÉΩÊèê‰æõ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÂ•ΩËôï„ÄÇ

##### **MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image Synthesis**
2405.09806v1 by Joseph Cho, Cyril Zakka, Rohan Shad, Ross Wightman, Akshay Chaudhari, William Hiesinger

Diffusion models have recently gained significant traction due to their
ability to generate high-fidelity and diverse images and videos conditioned on
text prompts. In medicine, this application promises to address the critical
challenge of data scarcity, a consequence of barriers in data sharing,
stringent patient privacy regulations, and disparities in patient population
and demographics. By generating realistic and varying medical 2D and 3D images,
these models offer a rich, privacy-respecting resource for algorithmic training
and research. To this end, we introduce MediSyn, a pair of instruction-tuned
text-guided latent diffusion models with the ability to generate high-fidelity
and diverse medical 2D and 3D images across specialties and modalities. Through
established metrics, we show significant improvement in broad medical image and
video synthesis guided by text prompts.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÊúÄËøëÁç≤ÂæóÈ°ØËëóÁöÑÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÂ§†Ê†πÊìöÊñáÂ≠óÊèêÁ§∫Áî¢ÁîüÈ´ò‰øùÁúü‰∏îÂ§öÊ®£ÁöÑÂúñÂÉèÂíåÂΩ±Áâá„ÄÇÂú®ÈÜ´Â≠∏‰∏≠ÔºåÊ≠§ÊáâÁî®Á®ãÂºèÊâøË´æËß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÊÄßÁöÑÈáçÂ§ßÊåëÊà∞ÔºåÈÄôÊòØÁî±ÊñºË≥áÊñôÂÖ±Áî®„ÄÅÂö¥Ê†ºÁöÑÊÇ£ËÄÖÈö±ÁßÅÊ≥ïË¶è‰ª•ÂèäÊÇ£ËÄÖÊóèÁæ§Âíå‰∫∫Âè£Áµ±Ë®àË≥áÊñôÁöÑÂ∑ÆÁï∞ÊâÄÈÄ†ÊàêÁöÑÂæåÊûú„ÄÇÈÄèÈÅéÁî¢ÁîüÈÄºÁúü‰∏îÂ§öËÆäÁöÑÈÜ´Â≠∏ 2D Âíå 3D ÂúñÂÉèÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫ÜË±êÂØå‰∏îÂ∞äÈáçÈö±ÁßÅÁöÑË≥áÊ∫êÔºåÂèØÁî®ÊñºÊºîÁÆóÊ≥ïË®ìÁ∑¥ÂíåÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MediSynÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊàêÂ∞çÁöÑÊåá‰ª§Ë™øÊï¥ÊñáÂ≠óÂºïÂ∞éÊΩõÂú®Êì¥Êï£Ê®°ÂûãÔºåËÉΩÂ§†Ë∑®Â∞àÊ•≠ÂíåÊñπÂºèÁî¢ÁîüÈ´ò‰øùÁúü‰∏îÂ§öÊ®£ÁöÑÈÜ´Â≠∏ 2D Âíå 3D ÂúñÂÉè„ÄÇÈÄèÈÅéÊó¢ÂÆöÁöÑÊåáÊ®ôÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®ÊñáÂ≠óÊèêÁ§∫ÂºïÂ∞é‰∏ãÔºåÂª£Ê≥õÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÂΩ±ÁâáÂêàÊàêÊúâ‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇ

##### **Many-Shot In-Context Learning in Multimodal Foundation Models**
2405.09798v1 by Yixing Jiang, Jeremy Irvin, Ji Hun Wang, Muhammad Ahmed Chaudhry, Jonathan H. Chen, Andrew Y. Ng

Large language models are well-known to be effective at few-shot in-context
learning (ICL). Recent advancements in multimodal foundation models have
enabled unprecedentedly long context windows, presenting an opportunity to
explore their capability to perform ICL with many more demonstrating examples.
In this work, we evaluate the performance of multimodal foundation models
scaling from few-shot to many-shot ICL. We benchmark GPT-4o and Gemini 1.5 Pro
across 10 datasets spanning multiple domains (natural imagery, medical imagery,
remote sensing, and molecular imagery) and tasks (multi-class, multi-label, and
fine-grained classification). We observe that many-shot ICL, including up to
almost 2,000 multimodal demonstrating examples, leads to substantial
improvements compared to few-shot (<100 examples) ICL across all of the
datasets. Further, Gemini 1.5 Pro performance continues to improve log-linearly
up to the maximum number of tested examples on many datasets. Given the high
inference costs associated with the long prompts required for many-shot ICL, we
also explore the impact of batching multiple queries in a single API call. We
show that batching up to 50 queries can lead to performance improvements under
zero-shot and many-shot ICL, with substantial gains in the zero-shot setting on
multiple datasets, while drastically reducing per-query cost and latency.
Finally, we measure ICL data efficiency of the models, or the rate at which the
models learn from more demonstrating examples. We find that while GPT-4o and
Gemini 1.5 Pro achieve similar zero-shot performance across the datasets,
Gemini 1.5 Pro exhibits higher ICL data efficiency than GPT-4o on most
datasets. Our results suggest that many-shot ICL could enable users to
efficiently adapt multimodal foundation models to new applications and domains.
Our codebase is publicly available at
https://github.com/stanfordmlgroup/ManyICL .

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã‰ª•Âú®Â∞ëÈáèÁØÑ‰æãÁöÑË™ûÂ¢ÉÂ≠∏Áøí (ICL) ‰∏≠ÊúâÊïàËëóÁ®±„ÄÇÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøÂæóÂâçÊâÄÊú™ÊúâÁöÑÈï∑Ë™ûÂ¢ÉÁ™óÂè£ÊàêÁÇ∫ÂèØËÉΩÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ©üÊúÉ‰æÜÊé¢Á¥¢ÂÆÉÂÄëÂú®Êõ¥Â§öÁ§∫ÁØÑÁØÑ‰æã‰∏ãÂü∑Ë°å ICL ÁöÑËÉΩÂäõ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂæûÂ∞ëÈáèÁØÑ‰æãÂà∞Â§ßÈáèÁØÑ‰æã ICL ÁöÑÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂú®Ë∑®Ë∂äÂ§öÂÄãÈ†òÂüüÔºàËá™ÁÑ∂ÂΩ±ÂÉè„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÈÅôÊ∏¨ÂíåÂàÜÂ≠êÂΩ±ÂÉèÔºâÂíå‰ªªÂãôÔºàÂ§öÈ°ûÂà•„ÄÅÂ§öÊ®ôÁ±§ÂíåÁ¥∞Á≤íÂ∫¶ÂàÜÈ°ûÔºâÁöÑ 10 ÂÄãË≥áÊñôÈõÜ‰∏äÂ∞ç GPT-4o Âíå Gemini 1.5 Pro ÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂ§ßÈáèÁØÑ‰æã ICLÔºåÂåÖÊã¨Â§öÈÅîËøë 2,000 ÂÄãÂ§öÊ®°ÊÖãÁ§∫ÁØÑÁØÑ‰æãÔºåËàáÊâÄÊúâË≥áÊñôÈõÜ‰∏≠ÁöÑÂ∞ëÈáèÁØÑ‰æã (<100 ÂÄãÁØÑ‰æã) ICL Áõ∏ÊØîÔºåÂ∏∂‰æÜ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÊ≠§Â§ñÔºåGemini 1.5 Pro ÁöÑÊïàËÉΩÊåÅÁ∫åÂú®Ë®±Â§öË≥áÊñôÈõÜ‰∏äÈö®ËëóÊ∏¨Ë©¶ÁØÑ‰æãÁöÑÊúÄÂ§ßÊï∏ÈáèÂ∞çÊï∏Á∑öÊÄßÂú∞ÊèêÂçá„ÄÇÈëëÊñºÂ§ßÈáèÁØÑ‰æã ICL ÊâÄÈúÄÁöÑÈï∑ÊèêÁ§∫Áõ∏ÈóúÁöÑÈ´òÊé®Ë´ñÊàêÊú¨ÔºåÊàëÂÄë‰πüÊé¢Ë®é‰∫ÜÂú®ÂñÆ‰∏Ä API ÂëºÂè´‰∏≠ÊâπÊ¨°ËôïÁêÜÂ§öÂÄãÊü•Ë©¢ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊâπÊ¨°ËôïÁêÜÂ§öÈÅî 50 ÂÄãÊü•Ë©¢ÂèØ‰ª•Âú®Èõ∂ÁØÑ‰æãÂíåÂ§ßÈáèÁØÑ‰æã ICL ‰∏ãÂ∞éËá¥ÊïàËÉΩÊèêÂçáÔºåÂú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÈõ∂ÁØÑ‰æãË®≠ÂÆö‰∏≠Áç≤ÂæóÈ°ØËëóÁöÑÊî∂ÁõäÔºåÂêåÊôÇÂ§ßÂπÖÈôç‰ΩéÊØèÂÄãÊü•Ë©¢ÁöÑÊàêÊú¨ÂíåÂª∂ÈÅ≤„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ∏¨Èáè‰∫ÜÊ®°ÂûãÁöÑ ICL Ë≥áÊñôÊïàÁéáÔºåÊàñÊ®°ÂûãÂæûÊõ¥Â§öÁ§∫ÁØÑÁØÑ‰æã‰∏≠Â≠∏ÁøíÁöÑÈÄüÁéá„ÄÇÊàëÂÄëÁôºÁèæÔºåÈõñÁÑ∂ GPT-4o Âíå Gemini 1.5 Pro Âú®ÂêÑÂÄãË≥áÊñôÈõÜ‰∏äÈÉΩÈÅîÂà∞‰∫ÜÈ°û‰ººÁöÑÈõ∂ÁØÑ‰æãÊïàËÉΩÔºå‰ΩÜ Gemini 1.5 Pro Âú®Â§ßÂ§öÊï∏Ë≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫ÊØî GPT-4o Êõ¥È´òÁöÑ ICL Ë≥áÊñôÊïàÁéá„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÂ§ßÈáèÁØÑ‰æã ICL ÂèØ‰ª•ËÆì‰ΩøÁî®ËÄÖÊúâÊïàÂú∞Â∞áÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãË™øÊï¥Âà∞Êñ∞ÁöÑÊáâÁî®Á®ãÂºèÂíåÈ†òÂüü„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∫´Â∑≤ÂÖ¨ÈñãÊñº https://github.com/stanfordmlgroup/ManyICL„ÄÇ</paragraph>

