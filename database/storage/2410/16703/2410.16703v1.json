{"2410.16703": {"publish_time": "2024-10-22", "title": "PLDR-LLM: Large Language Model from Power Law Decoder Representations", "paper_summary": "We present the Large Language Model from Power Law Decoder Representations\n(PLDR-LLM), a language model that leverages non-linear and linear\ntransformations through Power Law Graph Attention mechanism to generate\nwell-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of\nvarying layer sizes with a small batch size of 32 and $\\sim$8B tokens from the\nRefinedWeb dataset, and show that they achieve competitive performance in\nzero-shot and few-shot settings compared to scaled dot-product LLMs of similar\nmodel size reported in the literature. We show that deductive outputs of\nPLDR-LLMs can be used to compare model characteristics or improve the\nperformance by introducing the Directed Acyclic Graph (DAG) loss as a metric\nand regularizer. Our results indicate that the initial maximum learning rate\nand warm-up steps have a lasting impact on deductive outputs throughout the\npretraining. We provide a detailed description of PLDR-LLM architecture, its\nimplementation and the pretraining procedure.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4f7f\u7528\u51aa\u5f8b\u89e3\u78bc\u5668\u8868\u793a\u6cd5\u7684\u5927\u8a9e\u8a00\u6a21\u578b (PLDR-LLM)\uff0c\u9019\u662f\u4e00\u500b\u8a9e\u8a00\u6a21\u578b\uff0c\u5b83\u900f\u904e\u51aa\u5f8b\u5716\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u5229\u7528\u975e\u7dda\u6027\u548c\u7dda\u6027\u8f49\u63db\u4f86\u7522\u751f\u5b9a\u7fa9\u826f\u597d\u7684\u6f14\u7e79\u548c\u6b78\u7d0d\u8f38\u51fa\u3002\u6211\u5011\u4f7f\u7528 32 \u7684\u5c0f\u6279\u6b21\u5927\u5c0f\u548c RefinedWeb \u8cc7\u6599\u96c6\u4e2d\u7684 $\\sim$8B \u4ee4\u724c\uff0c\u9810\u8a13\u7df4\u4e0d\u540c\u5c64\u5927\u5c0f\u7684 PLDR-LLM\uff0c\u4e26\u5c55\u793a\u51fa\u5b83\u5011\u5728\u96f6\u6b21\u548c\u5c11\u6b21\u8a2d\u5b9a\u4e2d\uff0c\u8207\u6587\u737b\u4e2d\u5831\u5c0e\u7684\u985e\u4f3c\u6a21\u578b\u5927\u5c0f\u7684\u7e2e\u653e\u9ede\u7a4d LLM \u76f8\u6bd4\uff0c\u5b83\u5011\u9054\u5230\u4e86\u7af6\u722d\u529b\u8868\u73fe\u3002\u6211\u5011\u5c55\u793a\u4e86 PLDR-LLM \u7684\u6f14\u7e79\u8f38\u51fa\u53ef\u7528\u65bc\u6bd4\u8f03\u6a21\u578b\u7279\u5fb5\u6216\u900f\u904e\u5f15\u5165\u6709\u5411\u7121\u74b0\u5716 (DAG) \u640d\u5931\u4f5c\u70ba\u6307\u6a19\u548c\u6b63\u5247\u5316\u5668\u4f86\u6539\u5584\u6548\u80fd\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u521d\u59cb\u6700\u5927\u5b78\u7fd2\u7387\u548c\u71b1\u8eab\u6b65\u9a5f\u5c0d\u6574\u500b\u9810\u8a13\u7df4\u904e\u7a0b\u4e2d\u7684\u6f14\u7e79\u8f38\u51fa\u6709\u6301\u4e45\u7684\u5f71\u97ff\u3002\u6211\u5011\u63d0\u4f9b\u4e86 PLDR-LLM \u67b6\u69cb\u3001\u5176\u5be6\u73fe\u548c\u9810\u8a13\u7df4\u7a0b\u5e8f\u7684\u8a73\u7d30\u8aaa\u660e\u3002", "author": "Burc Gokden et.al.", "authors": "Burc Gokden", "id": "2410.16703v1", "paper_url": "http://arxiv.org/abs/2410.16703v1", "repo": "https://github.com/burcgokden/llm-from-power-law-decoder-representations"}}