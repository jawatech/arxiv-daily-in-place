{"2405.12579": {"publish_time": "2024-05-21", "title": "Mining the Explainability and Generalization: Fact Verification Based on Self-Instruction", "paper_summary": "Fact-checking based on commercial LLMs has become mainstream. Although these\nmethods offer high explainability, it falls short in accuracy compared to\ntraditional fine-tuning approaches, and data security is also a significant\nconcern. In this paper, we propose a self-instruction based fine-tuning\napproach for fact-checking that balances accuracy and explainability. Our\nmethod consists of Data Augmentation and Improved DPO fine-tuning. The former\nstarts by instructing the model to generate both positive and negative\nexplanations based on claim-evidence pairs and labels, then sampling the\ndataset according to our customized difficulty standards. The latter employs\nour proposed improved DPO to fine-tune the model using the generated samples.\nWe fine-tune the smallest-scale LLaMA-7B model and evaluate it on the\nchallenging fact-checking datasets FEVEROUS and HOVER, utilizing four\nfine-tuning methods and three few-shot learning methods for comparison. The\nexperiments demonstrate that our approach not only retains accuracy comparable\nto, or even surpassing, traditional fine-tuning methods, but also generates\nfluent explanation text. Moreover, it also exhibit high generalization\nperformance. Our method is the first to leverage self-supervised learning for\nfact-checking and innovatively combines contrastive learning and improved DPO\nin fine-tuning LLMs, as shown in the experiments.", "paper_summary_zh": "\u57fa\u65bc\u5546\u696d LLM \u7684\u4e8b\u5be6\u67e5\u6838\u5df2\u6210\u70ba\u4e3b\u6d41\u3002\u5118\u7ba1\u9019\u4e9b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9ad8\u5ea6\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4f46\u8207\u50b3\u7d71\u7684\u5fae\u8abf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5176\u6e96\u78ba\u6027\u8f03\u5dee\uff0c\u800c\u4e14\u8cc7\u6599\u5b89\u5168\u6027\u4e5f\u662f\u4e00\u500b\u91cd\u5927\u7684\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u81ea\u6559\u5b78\u7684\u5fae\u8abf\u65b9\u6cd5\uff0c\u7528\u65bc\u5728\u6e96\u78ba\u6027\u548c\u53ef\u89e3\u91cb\u6027\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u62ec\u8cc7\u6599\u64f4\u5145\u548c\u6539\u9032\u7684 DPO \u5fae\u8abf\u3002\u524d\u8005\u9996\u5148\u6307\u5c0e\u6a21\u578b\u6839\u64da\u8072\u660e-\u8b49\u64da\u5c0d\u548c\u6a19\u7c64\u751f\u6210\u6b63\u9762\u548c\u8ca0\u9762\u7684\u89e3\u91cb\uff0c\u7136\u5f8c\u6839\u64da\u6211\u5011\u81ea\u8a02\u7684\u96e3\u5ea6\u6a19\u6e96\u5c0d\u8cc7\u6599\u96c6\u9032\u884c\u62bd\u6a23\u3002\u5f8c\u8005\u63a1\u7528\u6211\u5011\u63d0\u51fa\u7684\u6539\u9032 DPO \u4f86\u4f7f\u7528\u751f\u6210\u7684\u6a23\u672c\u5fae\u8abf\u6a21\u578b\u3002\u6211\u5011\u5fae\u8abf\u4e86\u6700\u5c0f\u898f\u6a21\u7684 LLaMA-7B \u6a21\u578b\uff0c\u4e26\u5728\u5177\u6709\u6311\u6230\u6027\u7684\u4e8b\u5be6\u67e5\u6838\u8cc7\u6599\u96c6 FEVEROUS \u548c HOVER \u4e0a\u5c0d\u5176\u9032\u884c\u8a55\u4f30\uff0c\u5229\u7528\u56db\u7a2e\u5fae\u8abf\u65b9\u6cd5\u548c\u4e09\u7a2e\u5c11\u6a23\u672c\u5b78\u7fd2\u65b9\u6cd5\u9032\u884c\u6bd4\u8f03\u3002\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u4e0d\u50c5\u4fdd\u6301\u4e86\u8207\u50b3\u7d71\u5fae\u8abf\u65b9\u6cd5\u76f8\u7576\u751a\u81f3\u66f4\u9ad8\u7684\u6e96\u78ba\u6027\uff0c\u800c\u4e14\u9084\u751f\u6210\u4e86\u6d41\u66a2\u7684\u89e3\u91cb\u6587\u5b57\u3002\u6b64\u5916\uff0c\u5b83\u9084\u8868\u73fe\u51fa\u5f88\u9ad8\u7684\u6cdb\u5316\u6548\u80fd\u3002\u6211\u5011\u7684\u505a\u6cd5\u662f\u7b2c\u4e00\u500b\u5229\u7528\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u9032\u884c\u4e8b\u5be6\u67e5\u6838\uff0c\u4e26\u5728\u5fae\u8abf LLM \u4e2d\u5275\u65b0\u5730\u7d50\u5408\u4e86\u5c0d\u6bd4\u5b78\u7fd2\u548c\u6539\u9032\u7684 DPO\uff0c\u5982\u5be6\u9a57\u6240\u793a\u3002", "author": "Guangyao Lu et.al.", "authors": "Guangyao Lu, Yulin Liu", "id": "2405.12579v1", "paper_url": "http://arxiv.org/abs/2405.12579v1", "repo": "null"}}