{"2406.09130": {"publish_time": "2024-06-13", "title": "Time-Series Forecasting for Out-of-Distribution Generalization Using Invariant Learning", "paper_summary": "Time-series forecasting (TSF) finds broad applications in real-world\nscenarios. Due to the dynamic nature of time-series data, it is crucial to\nequip TSF models with out-of-distribution (OOD) generalization abilities, as\nhistorical training data and future test data can have different distributions.\nIn this paper, we aim to alleviate the inherent OOD problem in TSF via\ninvariant learning. We identify fundamental challenges of invariant learning\nfor TSF. First, the target variables in TSF may not be sufficiently determined\nby the input due to unobserved core variables in TSF, breaking the conventional\nassumption of invariant learning. Second, time-series datasets lack adequate\nenvironment labels, while existing environmental inference methods are not\nsuitable for TSF.\n  To address these challenges, we propose FOIL, a model-agnostic framework that\nenables timeseries Forecasting for Out-of-distribution generalization via\nInvariant Learning. FOIL employs a novel surrogate loss to mitigate the impact\nof unobserved variables. Further, FOIL implements a joint optimization by\nalternately inferring environments effectively with a multi-head network while\npreserving the temporal adjacency structure, and learning invariant\nrepresentations across inferred environments for OOD generalized TSF. We\ndemonstrate that the proposed FOIL significantly improves the performance of\nvarious TSF models, achieving gains of up to 85%.", "paper_summary_zh": "\u6642\u9593\u5e8f\u5217\u9810\u6e2c (TSF) \u5728\u5be6\u969b\u60c5\u5883\u4e2d\u5ee3\u6cdb\u61c9\u7528\u3002\u7531\u65bc\u6642\u9593\u5e8f\u5217\u8cc7\u6599\u7684\u52d5\u614b\u7279\u6027\uff0c\u56e0\u6b64 TSF \u6a21\u578b\u5fc5\u9808\u5177\u5099\u8d85\u51fa\u5206\u4f48 (OOD) \u7684\u6982\u5316\u80fd\u529b\uff0c\u56e0\u70ba\u6b77\u53f2\u8a13\u7df4\u8cc7\u6599\u548c\u672a\u4f86\u6e2c\u8a66\u8cc7\u6599\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u5206\u4f48\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u900f\u904e\u4e0d\u8b8a\u5b78\u7fd2\u4f86\u7de9\u89e3 TSF \u4e2d\u56fa\u6709\u7684 OOD \u554f\u984c\u3002\u6211\u5011\u627e\u51fa TSF \u4e2d\u4e0d\u8b8a\u5b78\u7fd2\u7684\u57fa\u672c\u6311\u6230\u3002\u9996\u5148\uff0c\u7531\u65bc TSF \u4e2d\u672a\u89c0\u5bdf\u5230\u7684\u6838\u5fc3\u8b8a\u6578\uff0c\u56e0\u6b64\u8f38\u5165\u53ef\u80fd\u7121\u6cd5\u5145\u5206\u6c7a\u5b9a TSF \u4e2d\u7684\u76ee\u6a19\u8b8a\u6578\uff0c\u6253\u7834\u4e86\u4e0d\u8b8a\u5b78\u7fd2\u7684\u50b3\u7d71\u5047\u8a2d\u3002\u5176\u6b21\uff0c\u6642\u9593\u5e8f\u5217\u8cc7\u6599\u96c6\u7f3a\u4e4f\u9069\u7576\u7684\u74b0\u5883\u6a19\u7c64\uff0c\u800c\u73fe\u6709\u7684\u74b0\u5883\u63a8\u8ad6\u65b9\u6cd5\u4e26\u4e0d\u9069\u5408 TSF\u3002\n\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa FOIL\uff0c\u4e00\u500b\u8207\u6a21\u578b\u7121\u95dc\u7684\u67b6\u69cb\uff0c\u5b83\u80fd\u900f\u904e\u4e0d\u8b8a\u5b78\u7fd2\u555f\u7528\u8d85\u51fa\u5206\u4f48\u6982\u5316\u4e4b\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u3002FOIL \u63a1\u7528\u4e00\u7a2e\u65b0\u7a4e\u7684\u66ff\u4ee3\u640d\u5931\u4f86\u6e1b\u8f15\u672a\u89c0\u5bdf\u8b8a\u6578\u7684\u5f71\u97ff\u3002\u6b64\u5916\uff0cFOIL \u900f\u904e\u591a\u982d\u7db2\u8def\u6709\u6548\u5730\u4ea4\u66ff\u63a8\u8ad6\u74b0\u5883\uff0c\u540c\u6642\u4fdd\u7559\u6642\u9593\u9130\u63a5\u7d50\u69cb\uff0c\u4e26\u5b78\u7fd2\u63a8\u8ad6\u74b0\u5883\u4e2d\u8de8 OOD \u6982\u5316 TSF \u7684\u4e0d\u8b8a\u8868\u793a\uff0c\u4f86\u5be6\u4f5c\u806f\u5408\u6700\u4f73\u5316\u3002\u6211\u5011\u8b49\u660e\u6240\u63d0\u51fa\u7684 FOIL \u5927\u5e45\u63d0\u5347\u5404\u7a2e TSF \u6a21\u578b\u7684\u6548\u80fd\uff0c\u7372\u5f97\u9ad8\u9054 85% \u7684\u6536\u76ca\u3002", "author": "Haoxin Liu et.al.", "authors": "Haoxin Liu, Harshavardhan Kamarthi, Lingkai Kong, Zhiyuan Zhao, Chao Zhang, B. Aditya Prakash", "id": "2406.09130v1", "paper_url": "http://arxiv.org/abs/2406.09130v1", "repo": "null"}}