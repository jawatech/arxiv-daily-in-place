{"2406.11617": {"publish_time": "2024-06-17", "title": "DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling", "paper_summary": "With the proliferation of domain-specific models, model merging has emerged\nas a set of techniques that combine the capabilities of multiple models into\none that can multitask without the cost of additional training. In this paper,\nwe propose a new model merging technique, Drop and rEscaLe via sampLing with\nmAgnitude (DELLA-Merging), that employs a novel pruning technique, MAGPRUNE,\nwhich shows significant advantages over DARE and TIES. MAGPRUNE first ranks the\nparameters in order of their magnitude and assigns higher dropout probabilities\n(p) to parameters with lower ranks corresponding to lower magnitudes. To\napproximate the original embeddings, MAGPRUNE employs a rescaling operation on\nthe parameters that survive the random dropping by 1/(1 - p). On three\ndifferent expert models considered for merging (LM, Math, Code) and\ncorresponding benchmark datasets (AlpacaEval, GSM8K, MBPP), DELLA shows an\naverage improvement of 2.4 points over baseline methods employing delta\nparameter pruning (an improvement of 3.6 points over TIES, 1.2 points over\nDARE), and 11.1 points over the no-pruning baseline (TA). We release the source\ncode at: https://github.com/declare-lab/della.", "paper_summary_zh": "\u96a8\u8457\u7279\u5b9a\u9818\u57df\u6a21\u578b\u7684\u6fc0\u589e\uff0c\u6a21\u578b\u5408\u4f75\u5df2\u6210\u70ba\u4e00\u7d44\u6280\u8853\uff0c\u5b83\u5c07\u591a\u500b\u6a21\u578b\u7684\u529f\u80fd\u7d50\u5408\u5230\u4e00\u500b\u6a21\u578b\u4e2d\uff0c\u800c\u7121\u9700\u984d\u5916\u8a13\u7df4\u6210\u672c\u5373\u53ef\u57f7\u884c\u591a\u4efb\u52d9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u6a21\u578b\u5408\u4f75\u6280\u8853\uff0c\u5373\u901a\u904e\u5177\u6709\u5e45\u5ea6\u7684\u63a1\u6a23\u9032\u884c\u522a\u9664\u548c\u7e2e\u653e (DELLA-Merging)\uff0c\u5b83\u63a1\u7528\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u526a\u679d\u6280\u8853 MAGPRUNE\uff0c\u8207 DARE \u548c TIES \u76f8\u6bd4\uff0c\u5b83\u986f\u793a\u51fa\u986f\u8457\u7684\u512a\u52e2\u3002MAGPRUNE \u9996\u5148\u6309\u5e45\u5ea6\u5c0d\u53c3\u6578\u9032\u884c\u6392\u5e8f\uff0c\u4e26\u5c07\u8f03\u9ad8\u7684\u4e2d\u65b7\u6a5f\u7387 (p) \u5206\u914d\u7d66\u5e45\u5ea6\u8f03\u4f4e\u3001\u5c0d\u61c9\u65bc\u8f03\u4f4e\u5e45\u5ea6\u7684\u53c3\u6578\u3002\u70ba\u4e86\u8fd1\u4f3c\u539f\u59cb\u5d4c\u5165\uff0cMAGPRUNE \u5c0d\u901a\u904e 1/(1 - p) \u96a8\u6a5f\u522a\u9664\u800c\u5b58\u6d3b\u7684\u53c3\u6578\u63a1\u7528\u7e2e\u653e\u64cd\u4f5c\u3002\u5c0d\u65bc\u5408\u4f75\u8003\u616e\u7684\u4e09\u500b\u4e0d\u540c\u7684\u5c08\u5bb6\u6a21\u578b (LM\u3001Math\u3001Code) \u548c\u5c0d\u61c9\u7684\u57fa\u6e96\u8cc7\u6599\u96c6 (AlpacaEval\u3001GSM8K\u3001MBPP)\uff0cDELLA \u986f\u793a\u6bd4\u63a1\u7528 delta \u53c3\u6578\u526a\u679d\u7684\u57fa\u672c\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad8 2.4 \u5206\uff08\u6bd4 TIES \u63d0\u9ad8 3.6 \u5206\uff0c\u6bd4 DARE \u63d0\u9ad8 1.2 \u5206\uff09\uff0c\u4e26\u4e14\u6bd4\u4e0d\u526a\u679d\u7684\u57fa\u672c\u7dda (TA) \u9ad8 11.1 \u5206\u3002\u6211\u5011\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u91cb\u51fa\u539f\u59cb\u78bc\uff1ahttps://github.com/declare-lab/della\u3002", "author": "Pala Tej Deep et.al.", "authors": "Pala Tej Deep, Rishabh Bhardwaj, Soujanya Poria", "id": "2406.11617v1", "paper_url": "http://arxiv.org/abs/2406.11617v1", "repo": "https://github.com/declare-lab/della"}}