{"2407.06089": {"publish_time": "2024-07-08", "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models", "paper_summary": "The remarkable success of Large Language Models (LLMs) has ushered natural\nlanguage processing (NLP) research into a new era. Despite their diverse\ncapabilities, LLMs trained on different corpora exhibit varying strengths and\nweaknesses, leading to challenges in maximizing their overall efficiency and\nversatility. To address these challenges, recent studies have explored\ncollaborative strategies for LLMs. This paper provides a comprehensive overview\nof this emerging research area, highlighting the motivation behind such\ncollaborations. Specifically, we categorize collaborative strategies into three\nprimary approaches: Merging, Ensemble, and Cooperation. Merging involves\nintegrating multiple LLMs in the parameter space. Ensemble combines the outputs\nof various LLMs. Cooperation} leverages different LLMs to allow full play to\ntheir diverse capabilities for specific tasks. We provide in-depth\nintroductions to these methods from different perspectives and discuss their\npotential applications. Additionally, we outline future research directions,\nhoping this work will catalyze further studies on LLM collaborations and paving\nthe way for advanced NLP applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u986f\u8457\u6210\u529f\u5df2\u5c07\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7814\u7a76\u5e36\u5165\u4e00\u500b\u65b0\u6642\u4ee3\u3002\u5118\u7ba1\u5177\u5099\u591a\u6a23\u5316\u7684\u529f\u80fd\uff0c\u4f46\u91dd\u5c0d\u4e0d\u540c\u8a9e\u6599\u5eab\u8a13\u7df4\u7684 LLM \u537b\u5c55\u73fe\u51fa\u4e0d\u540c\u7684\u512a\u52e2\u548c\u52a3\u52e2\uff0c\u5c0e\u81f4\u5728\u6700\u5927\u5316\u5176\u6574\u9ad4\u6548\u7387\u548c\u591a\u529f\u80fd\u6027\u65b9\u9762\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u63a2\u7d22\u4e86 LLM \u7684\u5354\u4f5c\u7b56\u7565\u3002\u672c\u6587\u5c0d\u9019\u500b\u65b0\u8208\u7684\u7814\u7a76\u9818\u57df\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6982\u8ff0\uff0c\u91cd\u9ede\u8aaa\u660e\u4e86\u6b64\u985e\u5354\u4f5c\u80cc\u5f8c\u7684\u52d5\u6a5f\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c07\u5354\u4f5c\u7b56\u7565\u5206\u985e\u70ba\u4e09\u7a2e\u4e3b\u8981\u65b9\u6cd5\uff1a\u5408\u4f75\u3001\u96c6\u6210\u548c\u5408\u4f5c\u3002\u5408\u4f75\u6d89\u53ca\u5728\u53c3\u6578\u7a7a\u9593\u4e2d\u6574\u5408\u591a\u500b LLM\u3002\u96c6\u6210\u7d50\u5408\u4e86\u5404\u7a2e LLM \u7684\u8f38\u51fa\u3002\u5408\u4f5c} \u5229\u7528\u4e0d\u540c\u7684 LLM\uff0c\u8b93\u5b83\u5011\u80fd\u5920\u5145\u5206\u767c\u63ee\u5176\u5728\u7279\u5b9a\u4efb\u52d9\u4e2d\u7684\u591a\u6a23\u5316\u529f\u80fd\u3002\u6211\u5011\u5f9e\u4e0d\u540c\u7684\u89d2\u5ea6\u5c0d\u9019\u4e9b\u65b9\u6cd5\u9032\u884c\u4e86\u6df1\u5165\u4ecb\u7d39\uff0c\u4e26\u8a0e\u8ad6\u4e86\u5b83\u5011\u7684\u6f5b\u5728\u61c9\u7528\u3002\u6b64\u5916\uff0c\u6211\u5011\u6982\u8ff0\u4e86\u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e0c\u671b\u9019\u9805\u5de5\u4f5c\u80fd\u50ac\u5316 LLM \u5354\u4f5c\u7684\u9032\u4e00\u6b65\u7814\u7a76\uff0c\u4e26\u70ba\u5148\u9032\u7684 NLP \u61c9\u7528\u92ea\u5e73\u9053\u8def\u3002", "author": "Jinliang Lu et.al.", "authors": "Jinliang Lu, Ziliang Pang, Min Xiao, Yaochen Zhu, Rui Xia, Jiajun Zhang", "id": "2407.06089v1", "paper_url": "http://arxiv.org/abs/2407.06089v1", "repo": "null"}}