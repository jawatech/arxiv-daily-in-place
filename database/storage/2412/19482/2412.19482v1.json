{"2412.19482": {"publish_time": "2024-12-27", "title": "Pre-training, Fine-tuning and Re-ranking: A Three-Stage Framework for Legal Question Answering", "paper_summary": "Legal question answering (QA) has attracted increasing attention from people\nseeking legal advice, which aims to retrieve the most applicable answers from a\nlarge-scale database of question-answer pairs. Previous methods mainly use a\ndual-encoder architecture to learn dense representations of both questions and\nanswers. However, these methods could suffer from lacking domain knowledge and\nsufficient labeled training data. In this paper, we propose a three-stage\n(\\underline{p}re-training, \\underline{f}ine-tuning and \\underline{r}e-ranking)\nframework for \\underline{l}egal \\underline{QA} (called PFR-LQA), which promotes\nthe fine-grained text representation learning and boosts the performance of\ndense retrieval with the dual-encoder architecture. Concretely, we first\nconduct domain-specific pre-training on legal questions and answers through a\nself-supervised training objective, allowing the pre-trained model to be\nadapted to the legal domain. Then, we perform task-specific fine-tuning of the\ndual-encoder on legal question-answer pairs by using the supervised learning\nobjective, leading to a high-quality dual-encoder for the specific downstream\nQA task. Finally, we employ a contextual re-ranking objective to further refine\nthe output representations of questions produced by the document encoder, which\nuses contextual similarity to increase the discrepancy between the anchor and\nhard negative samples for better question re-ranking. We conduct extensive\nexperiments on a manually annotated legal QA dataset. Experimental results show\nthat our PFR-LQA method achieves better performance than the strong competitors\nfor legal question answering.", "paper_summary_zh": "\u6cd5\u5f8b\u554f\u984c\u554f\u7b54 (QA) \u5df2\u5f15\u8d77\u5c0b\u6c42\u6cd5\u5f8b\u5efa\u8b70\u7684\u4eba\u5011\u8d8a\u4f86\u8d8a\u591a\u7684\u95dc\u6ce8\uff0c\u5176\u76ee\u6a19\u662f\u5f9e\u5927\u91cf\u554f\u984c-\u7b54\u6848\u5c0d\u8cc7\u6599\u5eab\u4e2d\u64f7\u53d6\u6700\u9069\u7528\u7684\u7b54\u6848\u3002\u5148\u524d\u7684\u505a\u6cd5\u4e3b\u8981\u4f7f\u7528\u96d9\u7de8\u78bc\u5668\u67b6\u69cb\u4f86\u5b78\u7fd2\u554f\u984c\u548c\u7b54\u6848\u7684\u5bc6\u96c6\u8868\u793a\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u53ef\u80fd\u6703\u56e0\u70ba\u7f3a\u4e4f\u9818\u57df\u77e5\u8b58\u548c\u8db3\u5920\u7684\u6a19\u8a18\u8a13\u7df4\u8cc7\u6599\u800c\u53d7\u5230\u5f71\u97ff\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u4e09\u968e\u6bb5\uff08\u9810\u8a13\u7df4\u3001\u5fae\u8abf\u548c\u91cd\u65b0\u6392\u5e8f\uff09\u6846\u67b6\uff0c\u7528\u65bc\u6cd5\u5f8b\u554f\u7b54 (\u7a31\u70ba PFR-LQA)\uff0c\u9019\u4fc3\u9032\u4e86\u7d30\u7c92\u5ea6\u6587\u672c\u8868\u793a\u5b78\u7fd2\uff0c\u4e26\u63d0\u5347\u4e86\u4f7f\u7528\u96d9\u7de8\u78bc\u5668\u67b6\u69cb\u7684\u5bc6\u96c6\u6aa2\u7d22\u6548\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u900f\u904e\u81ea\u76e3\u7763\u8a13\u7df4\u76ee\u6a19\u5c0d\u6cd5\u5f8b\u554f\u984c\u548c\u7b54\u6848\u9032\u884c\u7279\u5b9a\u9818\u57df\u7684\u9810\u8a13\u7df4\uff0c\u8b93\u9810\u8a13\u7df4\u6a21\u578b\u80fd\u5920\u9069\u61c9\u6cd5\u5f8b\u9818\u57df\u3002\u63a5\u8457\uff0c\u6211\u5011\u4f7f\u7528\u76e3\u7763\u5f0f\u5b78\u7fd2\u76ee\u6a19\u5c0d\u6cd5\u5f8b\u554f\u984c-\u7b54\u6848\u5c0d\u9032\u884c\u96d9\u7de8\u78bc\u5668\u7684\u7279\u5b9a\u4efb\u52d9\u5fae\u8abf\uff0c\u5f9e\u800c\u7522\u751f\u91dd\u5c0d\u7279\u5b9a\u4e0b\u6e38\u554f\u7b54\u4efb\u52d9\u7684\u9ad8\u54c1\u8cea\u96d9\u7de8\u78bc\u5668\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63a1\u7528\u4e00\u500b\u8108\u7d61\u91cd\u65b0\u6392\u5e8f\u76ee\u6a19\u4f86\u9032\u4e00\u6b65\u7cbe\u7149\u6587\u4ef6\u7de8\u78bc\u5668\u7522\u751f\u7684\u554f\u984c\u7684\u8f38\u51fa\u8868\u793a\uff0c\u5b83\u4f7f\u7528\u8108\u7d61\u76f8\u4f3c\u6027\u4f86\u589e\u52a0\u9328\u5b9a\u548c\u56f0\u96e3\u8ca0\u9762\u7bc4\u4f8b\u4e4b\u9593\u7684\u5dee\u7570\uff0c\u4ee5\u5229\u66f4\u597d\u7684\u554f\u984c\u91cd\u65b0\u6392\u5e8f\u3002\u6211\u5011\u5728\u4eba\u5de5\u6a19\u8a3b\u7684\u6cd5\u5f8b\u554f\u7b54\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684 PFR-LQA \u65b9\u6cd5\u5728\u6cd5\u5f8b\u554f\u984c\u56de\u7b54\u65b9\u9762\u7372\u5f97\u6bd4\u5f37\u5927\u7af6\u722d\u5c0d\u624b\u66f4\u597d\u7684\u6548\u80fd\u3002", "author": "Shiwen Ni et.al.", "authors": "Shiwen Ni, Hao Cheng, Min Yang", "id": "2412.19482v1", "paper_url": "http://arxiv.org/abs/2412.19482v1", "repo": "null"}}