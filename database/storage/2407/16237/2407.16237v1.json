{"2407.16237": {"publish_time": "2024-07-23", "title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection", "paper_summary": "Recent studies have illuminated that Large Language Models (LLMs) exhibit\nsubstantial potential in the realm of RTL (Register Transfer Level) code\ngeneration, with notable advancements evidenced by commercial models such as\nGPT-4 and Claude3-Opus. Despite their proficiency, these commercial LLMs often\nraise concerns regarding privacy and security. Conversely, open-source LLMs,\nwhich offer solutions to these concerns, have inferior performance in RTL code\ngeneration tasks to commercial models due to the lack of highquality\nopen-source RTL datasets. To address this issue, we introduce OriGen, a fully\nopen-source framework featuring self-reflection capabilities and a dataset\naugmentation methodology for generating high-quality, large-scale RTL code. We\npropose a novel code-to-code augmentation methodology that leverages knowledge\ndistillation to enhance the quality of the open-source RTL code datasets.\nAdditionally, OriGen is capable of correcting syntactic errors by leveraging a\nself-reflection process based on feedback from the compiler. The\nself-reflection ability of the model is facilitated by a carefully constructed\ndataset, which comprises a comprehensive collection of samples. Experimental\nresults demonstrate that OriGen remarkably outperforms other open-source\nalternatives in RTL code generation, surpassing the previous best-performing\nLLM by 9.8% on the VerilogEval-Human benchmark. Furthermore, OriGen exhibits\nsuperior capabilities in self-reflection and error rectification, surpassing\nGPT-4 by 18.1% on the benchmark designed to evaluate the capability of\nself-reflection.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728 RTL\uff08\u5bc4\u5b58\u5668\u4f20\u8f93\u5c42\uff09\u4ee3\u7801\u751f\u6210\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u7531 GPT-4 \u548c Claude3-Opus \u7b49\u5546\u4e1a\u6a21\u578b\u8bc1\u660e\u7684\u663e\u7740\u8fdb\u6b65\u3002\u5c3d\u7ba1\u5b83\u4eec\u5f88\u719f\u7ec3\uff0c\u4f46\u8fd9\u4e9b\u5546\u4e1a LLM \u7ecf\u5e38\u5f15\u53d1\u6709\u5173\u9690\u79c1\u548c\u5b89\u5168\u7684\u62c5\u5fe7\u3002\u76f8\u53cd\uff0c\u5f00\u6e90 LLM \u63d0\u4f9b\u4e86\u9488\u5bf9\u8fd9\u4e9b\u62c5\u5fe7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5728 RTL \u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u7f3a\u5c11\u9ad8\u8d28\u91cf\u7684\u5f00\u6e90 RTL \u6570\u636e\u96c6\uff0c\u5176\u6027\u80fd\u4e0d\u5982\u5546\u4e1a\u6a21\u578b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 OriGen\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u6846\u67b6\uff0c\u5177\u6709\u81ea\u7701\u80fd\u529b\u548c\u4e00\u4e2a\u6570\u636e\u96c6\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u5927\u89c4\u6a21\u7684 RTL \u4ee3\u7801\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ee3\u7801\u5230\u4ee3\u7801\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u6765\u63d0\u9ad8\u5f00\u6e90 RTL \u4ee3\u7801\u6570\u636e\u96c6\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0cOriGen \u80fd\u591f\u901a\u8fc7\u5229\u7528\u57fa\u4e8e\u7f16\u8bd1\u5668\u53cd\u9988\u7684\u81ea\u7701\u8fc7\u7a0b\u6765\u7ea0\u6b63\u8bed\u6cd5\u9519\u8bef\u3002\u6a21\u578b\u7684\u81ea\u7701\u80fd\u529b\u662f\u7531\u7cbe\u5fc3\u6784\u5efa\u7684\u6570\u636e\u96c6\u4fc3\u8fdb\u7684\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u5168\u9762\u7684\u6837\u672c\u96c6\u5408\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOriGen \u5728 RTL \u4ee3\u7801\u751f\u6210\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u5176\u4ed6\u5f00\u6e90\u66ff\u4ee3\u65b9\u6848\uff0c\u5728 VerilogEval-Human \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u4e4b\u524d\u8868\u73b0\u6700\u597d\u7684 LLM \u9ad8\u51fa 9.8%\u3002\u6b64\u5916\uff0cOriGen \u5728\u81ea\u7701\u548c\u9519\u8bef\u7ea0\u6b63\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u80fd\u529b\uff0c\u5728\u8bc4\u4f30\u81ea\u7701\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4 GPT-4 \u9ad8\u51fa 18.1%\u3002</paragraph>", "author": "Fan Cui et.al.", "authors": "Fan Cui, Chenyang Yin, Kexing Zhou, Youwei Xiao, Guangyu Sun, Qiang Xu, Qipeng Guo, Demin Song, Dahua Lin, Xingcheng Zhang, Yun, Liang", "id": "2407.16237v1", "paper_url": "http://arxiv.org/abs/2407.16237v1", "repo": "null"}}