{"2407.11962": {"publish_time": "2024-07-16", "title": "Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling", "paper_summary": "This paper introduces Motion-oriented Compositional Neural Radiance Fields\n(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of\nmonocular human videos via novel non-rigid motion modeling approach. In the\ncontext of dynamic clothed humans, complex cloth dynamics generate non-rigid\nmotions that are intrinsically distinct from skeletal articulations and\ncritically important for the rendering quality. The conventional approach\nmodels non-rigid motions as spatial (3D) deviations in addition to skeletal\ntransformations. However, it is either time-consuming or challenging to achieve\noptimal quality due to its high learning complexity without a direct\nsupervision. To target this problem, we propose a novel approach of modeling\nnon-rigid motions as radiance residual fields to benefit from more direct color\nsupervision in the rendering and utilize the rigid radiance fields as a prior\nto reduce the complexity of the learning process. Our approach utilizes a\nsingle multiresolution hash encoding (MHE) to concurrently learn the canonical\nT-pose representation from rigid skeletal motions and the radiance residual\nfield for non-rigid motions. Additionally, to further improve both training\nefficiency and usability, we extend MoCo-NeRF to support simultaneous training\nof multiple subjects within a single framework, thanks to our effective design\nfor modeling non-rigid motions. This scalability is achieved through the\nintegration of a global MHE and learnable identity codes in addition to\nmultiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,\nclearly demonstrating state-of-the-art performance in both single- and\nmulti-subject settings. The code and model will be made publicly available at\nthe project page: https://stevejaehyeok.github.io/publications/moco-nerf.", "paper_summary_zh": "<paragraph>\u672c\u6587\u4ecb\u7d39\u4e86\u904b\u52d5\u5c0e\u5411\u7d44\u5408\u795e\u7d93\u8f3b\u7167\u5834 (MoCo-NeRF)\uff0c\u4e00\u500b\u65e8\u5728\u900f\u904e\u65b0\u7a4e\u7684\u975e\u525b\u6027\u904b\u52d5\u5efa\u6a21\u65b9\u6cd5\uff0c\u57f7\u884c\u55ae\u773c\u4eba\u985e\u5f71\u7247\u7684\u81ea\u7531\u8996\u9ede\u6e32\u67d3\u7684\u6846\u67b6\u3002\u5728\u52d5\u614b\u7a7f\u8457\u4eba\u985e\u7684\u80cc\u666f\u4e0b\uff0c\u8907\u96dc\u7684\u5e03\u6599\u52d5\u529b\u6703\u7522\u751f\u975e\u525b\u6027\u904b\u52d5\uff0c\u8207\u9aa8\u67b6\u95dc\u7bc0\u672c\u8cea\u4e0a\u4e0d\u540c\uff0c\u5c0d\u6e32\u67d3\u54c1\u8cea\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u65b9\u6cd5\u5c07\u975e\u525b\u6027\u904b\u52d5\u5efa\u6a21\u70ba\u7a7a\u9593 (3D) \u504f\u5dee\uff0c\u4ee5\u53ca\u9aa8\u67b6\u8f49\u63db\u3002\u7136\u800c\uff0c\u7531\u65bc\u5176\u5b78\u7fd2\u8907\u96dc\u5ea6\u9ad8\uff0c\u4e14\u6c92\u6709\u76f4\u63a5\u76e3\u7763\uff0c\u56e0\u6b64\u8981\u9054\u5230\u6700\u4f73\u54c1\u8cea\u65e2\u8017\u6642\u53c8\u5177\u6311\u6230\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u5c07\u975e\u525b\u6027\u904b\u52d5\u5efa\u6a21\u70ba\u8f3b\u7167\u6b98\u5dee\u5834\uff0c\u4ee5\u53d7\u76ca\u65bc\u6e32\u67d3\u4e2d\u66f4\u76f4\u63a5\u7684\u8272\u5f69\u76e3\u7763\uff0c\u4e26\u5229\u7528\u525b\u6027\u8f3b\u7167\u5834\u4f5c\u70ba\u5148\u9a57\uff0c\u4ee5\u964d\u4f4e\u5b78\u7fd2\u904e\u7a0b\u7684\u8907\u96dc\u6027\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u55ae\u4e00\u7684\u591a\u89e3\u6790\u5ea6\u96dc\u6e4a\u7de8\u78bc (MHE)\uff0c\u4ee5\u540c\u6642\u5f9e\u525b\u6027\u9aa8\u67b6\u904b\u52d5\u4e2d\u5b78\u7fd2\u6a19\u6e96\u7684 T \u59ff\u52e2\u8868\u793a\uff0c\u4ee5\u53ca\u975e\u525b\u6027\u904b\u52d5\u7684\u8f3b\u7167\u6b98\u5dee\u5834\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u9032\u4e00\u6b65\u63d0\u9ad8\u8a13\u7df4\u6548\u7387\u548c\u53ef\u7528\u6027\uff0c\u6211\u5011\u5c07 MoCo-NeRF \u64f4\u5c55\u70ba\u652f\u63f4\u5728\u55ae\u4e00\u6846\u67b6\u5167\u540c\u6642\u8a13\u7df4\u591a\u500b\u4e3b\u9ad4\uff0c\u9019\u8981\u6b78\u529f\u65bc\u6211\u5011\u7528\u65bc\u5efa\u6a21\u975e\u525b\u6027\u904b\u52d5\u7684\u6709\u6548\u8a2d\u8a08\u3002\u9019\u7a2e\u53ef\u64f4\u5145\u6027\u662f\u900f\u904e\u6574\u5408\u4e00\u500b\u6574\u9ad4 MHE \u548c\u53ef\u5b78\u7fd2\u7684\u8eab\u5206\u78bc\uff0c\u4ee5\u53ca\u591a\u500b\u5c40\u90e8 MHE \u4f86\u5be6\u73fe\u7684\u3002\u6211\u5011\u5728 ZJU-MoCap \u548c MonoCap \u4e0a\u5c55\u793a\u4e86\u5ee3\u6cdb\u7684\u7d50\u679c\uff0c\u6e05\u695a\u5730\u8b49\u660e\u4e86\u5728\u55ae\u4e3b\u9ad4\u548c\u591a\u4e3b\u9ad4\u8a2d\u5b9a\u4e2d\uff0c\u6211\u5011\u90fd\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u5c07\u5728\u5c08\u6848\u9801\u9762\u516c\u958b\uff1ahttps://stevejaehyeok.github.io/publications/moco-nerf\u3002</paragraph>", "author": "Jaehyeok Kim et.al.", "authors": "Jaehyeok Kim, Dongyoon Wee, Dan Xu", "id": "2407.11962v2", "paper_url": "http://arxiv.org/abs/2407.11962v2", "repo": "null"}}