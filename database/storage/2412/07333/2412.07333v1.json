{"2412.07333": {"publish_time": "2024-12-10", "title": "Fusion Embedding for Pose-Guided Person Image Synthesis with Diffusion Model", "paper_summary": "Pose-Guided Person Image Synthesis (PGPIS) aims to synthesize high-quality\nperson images corresponding to target poses while preserving the appearance of\nthe source image. Recently, PGPIS methods that use diffusion models have\nachieved competitive performance. Most approaches involve extracting\nrepresentations of the target pose and source image and learning their\nrelationships in the generative model's training process. This approach makes\nit difficult to learn the semantic relationships between the input and target\nimages and complicates the model structure needed to enhance generation\nresults. To address these issues, we propose Fusion embedding for PGPIS using a\nDiffusion Model (FPDM). Inspired by the successful application of pre-trained\nCLIP models in text-to-image diffusion models, our method consists of two\nstages. The first stage involves training the fusion embedding of the source\nimage and target pose to align with the target image's embedding. In the second\nstage, the generative model uses this fusion embedding as a condition to\ngenerate the target image. We applied the proposed method to the benchmark\ndatasets DeepFashion and RWTH-PHOENIX-Weather 2014T, and conducted both\nquantitative and qualitative evaluations, demonstrating state-of-the-art (SOTA)\nperformance. An ablation study of the model structure showed that even a model\nusing only the second stage achieved performance close to the other PGPIS SOTA\nmodels. The code is available at https://github.com/dhlee-work/FPDM.", "paper_summary_zh": "\u59ff\u52e2\u5f15\u5c0e\u4eba\u7269\u5f71\u50cf\u5408\u6210 (PGPIS) \u65e8\u5728\u5408\u6210\u8207\u76ee\u6a19\u59ff\u52e2\u76f8\u7b26\u7684\u9ad8\u54c1\u8cea\u4eba\u7269\u5f71\u50cf\uff0c\u540c\u6642\u4fdd\u7559\u539f\u59cb\u5f71\u50cf\u7684\u5916\u89c0\u3002\u6700\u8fd1\uff0c\u4f7f\u7528\u64f4\u6563\u6a21\u578b\u7684 PGPIS \u65b9\u6cd5\u5df2\u53d6\u5f97\u7af6\u722d\u529b\u7684\u8868\u73fe\u3002\u5927\u591a\u6578\u65b9\u6cd5\u6d89\u53ca\u63d0\u53d6\u76ee\u6a19\u59ff\u52e2\u548c\u539f\u59cb\u5f71\u50cf\u7684\u8868\u793a\uff0c\u4e26\u5728\u751f\u6210\u6a21\u578b\u7684\u8a13\u7df4\u904e\u7a0b\u4e2d\u5b78\u7fd2\u5b83\u5011\u7684\u95dc\u4fc2\u3002\u9019\u7a2e\u65b9\u6cd5\u4f7f\u5f97\u96e3\u4ee5\u5b78\u7fd2\u8f38\u5165\u548c\u76ee\u6a19\u5f71\u50cf\u4e4b\u9593\u7684\u8a9e\u7fa9\u95dc\u4fc2\uff0c\u4e26\u4f7f\u589e\u5f37\u751f\u6210\u7d50\u679c\u6240\u9700\u7684\u6a21\u578b\u7d50\u69cb\u8907\u96dc\u5316\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4f7f\u7528\u64f4\u6563\u6a21\u578b (FPDM) \u7684 PGPIS \u878d\u5408\u5d4c\u5165\u3002\u53d7\u9810\u8a13\u7df4 CLIP \u6a21\u578b\u5728\u6587\u5b57\u8f49\u5f71\u50cf\u64f4\u6563\u6a21\u578b\u4e2d\u6210\u529f\u61c9\u7528\u7684\u555f\u767c\uff0c\u6211\u5011\u7684\u6a21\u578b\u5305\u542b\u5169\u500b\u968e\u6bb5\u3002\u7b2c\u4e00\u500b\u968e\u6bb5\u6d89\u53ca\u8a13\u7df4\u539f\u59cb\u5f71\u50cf\u548c\u76ee\u6a19\u59ff\u52e2\u7684\u878d\u5408\u5d4c\u5165\uff0c\u4ee5\u8207\u76ee\u6a19\u5f71\u50cf\u7684\u5d4c\u5165\u5c0d\u9f4a\u3002\u5728\u7b2c\u4e8c\u500b\u968e\u6bb5\uff0c\u751f\u6210\u6a21\u578b\u4f7f\u7528\u6b64\u878d\u5408\u5d4c\u5165\u4f5c\u70ba\u689d\u4ef6\u4f86\u751f\u6210\u76ee\u6a19\u5f71\u50cf\u3002\u6211\u5011\u5c07\u63d0\u51fa\u7684\u65b9\u6cd5\u61c9\u7528\u65bc\u57fa\u6e96\u8cc7\u6599\u96c6 DeepFashion \u548c RWTH-PHOENIX-Weather 2014T\uff0c\u4e26\u9032\u884c\u4e86\u91cf\u5316\u548c\u8cea\u5316\u8a55\u4f30\uff0c\u8b49\u660e\u4e86\u6700\u5148\u9032 (SOTA) \u7684\u8868\u73fe\u3002\u6a21\u578b\u7d50\u69cb\u7684\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u50c5\u4f7f\u7528\u7b2c\u4e8c\u968e\u6bb5\u7684\u6a21\u578b\uff0c\u5176\u8868\u73fe\u4e5f\u63a5\u8fd1\u5176\u4ed6 PGPIS SOTA \u6a21\u578b\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/dhlee-work/FPDM \u53d6\u5f97\u3002", "author": "Donghwna Lee et.al.", "authors": "Donghwna Lee, Kyungha Min, Kirok Kim, Seyoung Jeong, Jiwoo Jeong, Wooju Kim", "id": "2412.07333v1", "paper_url": "http://arxiv.org/abs/2412.07333v1", "repo": "null"}}