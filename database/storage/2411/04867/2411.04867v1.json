{"2411.04867": {"publish_time": "2024-11-07", "title": "Think Smart, Act SMARL! Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning", "paper_summary": "An important challenge for enabling the deployment of reinforcement learning\n(RL) algorithms in the real world is safety. This has resulted in the recent\nresearch field of Safe RL, which aims to learn optimal policies that are safe.\nOne successful approach in that direction is probabilistic logic shields (PLS),\na model-based Safe RL technique that uses formal specifications based on\nprobabilistic logic programming, constraining an agent's policy to comply with\nthose specifications in a probabilistic sense. However, safety is inherently a\nmulti-agent concept, since real-world environments often involve multiple\nagents interacting simultaneously, leading to a complex system which is hard to\ncontrol. Moreover, safe multi-agent RL (Safe MARL) is still underexplored. In\norder to address this gap, in this paper we ($i$) introduce Shielded MARL\n(SMARL) by extending PLS to MARL -- in particular, we introduce Probabilistic\nLogic Temporal Difference Learning (PLTD) to enable shielded independent\nQ-learning (SIQL), and introduce shielded independent PPO (SIPPO) using\nprobabilistic logic policy gradients; ($ii$) show its positive effect and use\nas an equilibrium selection mechanism in various game-theoretic environments\nincluding two-player simultaneous games, extensive-form games, stochastic\ngames, and some grid-world extensions in terms of safety, cooperation, and\nalignment with normative behaviors; and ($iii$) look into the asymmetric case\nwhere only one agent is shielded, and show that the shielded agent has a\nsignificant influence on the unshielded one, providing further evidence of\nSMARL's ability to enhance safety and cooperation in diverse multi-agent\nenvironments.", "paper_summary_zh": "<paragraph>\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u90e8\u7f72\u5f37\u5316\u5b78\u7fd2 (RL) \u6f14\u7b97\u6cd5\u7684\u4e00\u9805\u91cd\u8981\u6311\u6230\u5728\u65bc\u5b89\u5168\u6027\u3002\u9019\u5c0e\u81f4\u4e86\u8fd1\u671f\u7814\u7a76\u9818\u57df\u7684\u5b89\u5168 RL\uff0c\u5176\u76ee\u6a19\u662f\u5b78\u7fd2\u5b89\u5168\u7684\u6700\u4f73\u7b56\u7565\u3002\u671d\u9019\u500b\u65b9\u5411\u767c\u5c55\u7684\u4e00\u7a2e\u6210\u529f\u65b9\u6cd5\u662f\u6a5f\u7387\u908f\u8f2f\u9632\u8b77 (PLS)\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u6a21\u578b\u7684\u5b89\u5168 RL \u6280\u8853\uff0c\u5b83\u4f7f\u7528\u57fa\u65bc\u6a5f\u7387\u908f\u8f2f\u7a0b\u5f0f\u8a2d\u8a08\u7684\u5f62\u5f0f\u5316\u898f\u7bc4\uff0c\u4ee5\u6a5f\u7387\u610f\u7fa9\u9650\u5236\u4ee3\u7406\u7684\u7b56\u7565\u4ee5\u7b26\u5408\u9019\u4e9b\u898f\u7bc4\u3002\u7136\u800c\uff0c\u5b89\u5168\u6027\u672c\u8cea\u4e0a\u662f\u4e00\u500b\u591a\u91cd\u4ee3\u7406\u6982\u5ff5\uff0c\u56e0\u70ba\u73fe\u5be6\u4e16\u754c\u7684\u74b0\u5883\u901a\u5e38\u6d89\u53ca\u591a\u500b\u4ee3\u7406\u540c\u6642\u4e92\u52d5\uff0c\u5c0e\u81f4\u4e00\u500b\u96e3\u4ee5\u63a7\u5236\u7684\u8907\u96dc\u7cfb\u7d71\u3002\u6b64\u5916\uff0c\u5b89\u5168\u591a\u91cd\u4ee3\u7406 RL (Safe MARL) \u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u5728\u672c\u6587\u4e2d\u6211\u5011 ($i$) \u900f\u904e\u5c07 PLS \u64f4\u5145\u5230 MARL \u4f86\u4ecb\u7d39\u9632\u8b77\u5f0f MARL (SMARL) -- \u7279\u5225\u662f\uff0c\u6211\u5011\u4ecb\u7d39\u6a5f\u7387\u908f\u8f2f\u6642\u5e8f\u5dee\u5206\u5b78\u7fd2 (PLTD) \u4ee5\u555f\u7528\u9632\u8b77\u5f0f\u7368\u7acb Q \u5b78\u7fd2 (SIQL)\uff0c\u4e26\u4f7f\u7528\u6a5f\u7387\u908f\u8f2f\u7b56\u7565\u68af\u5ea6\u5f15\u5165\u9632\u8b77\u5f0f\u7368\u7acb PPO (SIPPO)\uff1b($ii$) \u5c55\u793a\u5176\u6b63\u9762\u6548\u61c9\uff0c\u4e26\u7528\u4f5c\u5404\u7a2e\u535a\u5f08\u8ad6\u74b0\u5883\u4e2d\u7684\u5747\u8861\u9078\u64c7\u6a5f\u5236\uff0c\u5305\u62ec\u96d9\u4eba\u540c\u6642\u535a\u5f08\u3001\u5ee3\u7fa9\u578b\u535a\u5f08\u3001\u96a8\u6a5f\u535a\u5f08\uff0c\u4ee5\u53ca\u5728\u5b89\u5168\u6027\u3001\u5408\u4f5c\u548c\u8207\u898f\u7bc4\u884c\u70ba\u4e00\u81f4\u6027\u65b9\u9762\u7684\u67d0\u4e9b\u683c\u72c0\u4e16\u754c\u64f4\u5145\uff1b\u4ee5\u53ca ($iii$) \u63a2\u8a0e\u53ea\u6709\u55ae\u4e00\u4ee3\u7406\u9632\u8b77\u7684\u4e0d\u5c0d\u7a31\u6848\u4f8b\uff0c\u4e26\u5c55\u793a\u9632\u8b77\u5f0f\u4ee3\u7406\u5c0d\u672a\u9632\u8b77\u5f0f\u4ee3\u7406\u6709\u986f\u8457\u5f71\u97ff\uff0c\u9032\u4e00\u6b65\u8b49\u660e SMARL \u80fd\u5920\u589e\u5f37\u4e0d\u540c\u591a\u91cd\u4ee3\u7406\u74b0\u5883\u4e2d\u7684\u5b89\u5168\u6027\u8207\u5408\u4f5c\u3002</paragraph>", "author": "Satchit Chatterji et.al.", "authors": "Satchit Chatterji, Erman Acar", "id": "2411.04867v1", "paper_url": "http://arxiv.org/abs/2411.04867v1", "repo": "https://github.com/satchitchatterji/shieldedmarlthesis"}}