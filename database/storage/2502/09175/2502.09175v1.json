{"2502.09175": {"publish_time": "2025-02-13", "title": "FLAME: Flexible LLM-Assisted Moderation Engine", "paper_summary": "The rapid advancement of Large Language Models (LLMs) has introduced\nsignificant challenges in moderating user-model interactions. While LLMs\ndemonstrate remarkable capabilities, they remain vulnerable to adversarial\nattacks, particularly ``jailbreaking'' techniques that bypass content safety\nmeasures. Current content moderation systems, which primarily rely on input\nprompt filtering, have proven insufficient, with techniques like Best-of-N\n(BoN) jailbreaking achieving success rates of 80% or more against popular LLMs.\nIn this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a\nnew approach that shifts the focus from input filtering to output moderation.\nUnlike traditional circuit-breaking methods that analyze user queries, FLAME\nevaluates model responses, offering several key advantages: (1) computational\nefficiency in both training and inference, (2) enhanced resistance to BoN\njailbreaking attacks, and (3) flexibility in defining and updating safety\ncriteria through customizable topic filtering. Our experiments demonstrate that\nFLAME significantly outperforms current moderation systems. For example, FLAME\nreduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9,\nwhile maintaining low computational overhead. We provide comprehensive\nevaluation on various LLMs and analyze the engine's efficiency against the\nstate-of-the-art jailbreaking. This work contributes to the development of more\nrobust and adaptable content moderation systems for LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u6b65\u70ba\u8abf\u7bc0\u4f7f\u7528\u8005\u8207\u6a21\u578b\u4e92\u52d5\u5e36\u4f86\u91cd\u5927\u6311\u6230\u3002\u5118\u7ba1 LLM \u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u7279\u5225\u662f\u7e5e\u904e\u5167\u5bb9\u5b89\u5168\u63aa\u65bd\u7684\u300c\u8d8a\u7344\u300d\u6280\u8853\u3002\u76ee\u524d\u7684\u5167\u5bb9\u5be9\u6838\u7cfb\u7d71\u4e3b\u8981\u4f9d\u8cf4\u8f38\u5165\u63d0\u793a\u904e\u6ffe\uff0c\u5df2\u88ab\u8b49\u660e\u4e0d\u8db3\uff0c\u4f8b\u5982 Best-of-N (BoN) \u8d8a\u7344\u5c0d\u6297\u71b1\u9580 LLM \u7684\u6210\u529f\u7387\u9054\u5230 80% \u4ee5\u4e0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u9748\u6d3b\u7684 LLM \u8f14\u52a9\u5be9\u6838\u5f15\u64ce (FLAME)\uff1a\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\uff0c\u5c07\u91cd\u9ede\u5f9e\u8f38\u5165\u904e\u6ffe\u8f49\u79fb\u5230\u8f38\u51fa\u5be9\u6838\u3002\u8207\u5206\u6790\u4f7f\u7528\u8005\u67e5\u8a62\u7684\u50b3\u7d71\u96fb\u8def\u4e2d\u65b7\u65b9\u6cd5\u4e0d\u540c\uff0cFLAME \u8a55\u4f30\u6a21\u578b\u56de\u61c9\uff0c\u63d0\u4f9b\u5e7e\u500b\u95dc\u9375\u512a\u52e2\uff1a(1) \u8a13\u7df4\u548c\u63a8\u7406\u4e2d\u7684\u8a08\u7b97\u6548\u7387\uff0c(2) \u589e\u5f37\u5c0d BoN \u8d8a\u7344\u653b\u64ca\u7684\u62b5\u6297\u529b\uff0c\u4ee5\u53ca (3) \u900f\u904e\u53ef\u81ea\u8a02\u4e3b\u984c\u904e\u6ffe\u5b9a\u7fa9\u548c\u66f4\u65b0\u5b89\u5168\u6a19\u6e96\u7684\u9748\u6d3b\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0cFLAME \u660e\u986f\u512a\u65bc\u76ee\u524d\u7684\u5be9\u6838\u7cfb\u7d71\u3002\u4f8b\u5982\uff0cFLAME \u5c07 GPT-4o-mini \u548c DeepSeek-v3 \u7684\u653b\u64ca\u6210\u529f\u7387\u964d\u4f4e\u4e86\u7d04 9 \u500d\uff0c\u540c\u6642\u4fdd\u6301\u8f03\u4f4e\u7684\u8a08\u7b97\u8ca0\u64d4\u3002\u6211\u5011\u5c0d\u5404\u7a2e LLM \u9032\u884c\u4e86\u5168\u9762\u7684\u8a55\u4f30\uff0c\u4e26\u5206\u6790\u4e86\u5f15\u64ce\u5c0d\u6297\u6700\u65b0\u8d8a\u7344\u7684\u6548\u7387\u3002\u9019\u9805\u5de5\u4f5c\u6709\u52a9\u65bc\u958b\u767c\u66f4\u5f37\u5927\u4e14\u9069\u61c9\u6027\u66f4\u5f37\u7684 LLM \u5167\u5bb9\u5be9\u6838\u7cfb\u7d71\u3002", "author": "Ivan Bakulin et.al.", "authors": "Ivan Bakulin, Ilia Kopanichuk, Iaroslav Bespalov, Nikita Radchenko, Vladimir Shaposhnikov, Dmitry Dylov, Ivan Oseledets", "id": "2502.09175v1", "paper_url": "http://arxiv.org/abs/2502.09175v1", "repo": "null"}}