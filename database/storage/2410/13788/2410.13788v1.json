{"2410.13788": {"publish_time": "2024-10-17", "title": "Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions", "paper_summary": "Large language models (LLMs) must often respond to highly ambiguous user\nrequests. In such cases, the LLM's best response may be to ask a clarifying\nquestion to elicit more information. We observe existing LLMs often respond by\npresupposing a single interpretation of such ambiguous requests, frustrating\nusers who intended a different interpretation. We speculate this is caused by\ncurrent preference data labeling practice, where LLM responses are evaluated\nonly on their prior contexts. To address this, we propose to assign preference\nlabels by simulating their expected outcomes in the future turns. This allows\nLLMs to learn to ask clarifying questions when it can generate responses that\nare tailored to each user interpretation in future turns. In experiments on\nopen-domain QA, we compare systems that trained using our proposed preference\nlabeling methods against standard methods, which assign preferences based on\nonly prior context. We evaluate systems based on their ability to ask\nclarifying questions that can recover each user's interpretation and expected\nanswer, and find that our training with our proposed method trains LLMs to ask\nclarifying questions with a 5% improvement in F1 measured against the answer\nset from different interpretations of each query", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5fc5\u9808\u7d93\u5e38\u56de\u61c9\u9ad8\u5ea6\u6a21\u7cca\u7684\u4f7f\u7528\u8005\u8981\u6c42\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0cLLM \u6700\u597d\u7684\u56de\u61c9\u53ef\u80fd\u662f\u63d0\u51fa\u4e00\u500b\u6f84\u6e05\u554f\u984c\u4ee5\u5f15\u51fa\u66f4\u591a\u8cc7\u8a0a\u3002\u6211\u5011\u89c0\u5bdf\u5230\u73fe\u6709\u7684 LLM \u901a\u5e38\u6703\u9810\u8a2d\u5c0d\u9019\u4e9b\u6a21\u7cca\u8981\u6c42\u7684\u55ae\u4e00\u89e3\u91cb\uff0c\u8b93\u9810\u671f\u4e0d\u540c\u89e3\u91cb\u7684\u4f7f\u7528\u8005\u611f\u5230\u6cae\u55aa\u3002\u6211\u5011\u63a8\u6e2c\u9019\u662f\u7531\u76ee\u524d\u7684\u504f\u597d\u8cc7\u6599\u6a19\u7c64\u5be6\u52d9\u6240\u9020\u6210\u7684\uff0c\u5176\u4e2d LLM \u56de\u61c9\u50c5\u6839\u64da\u5176\u5148\u524d\u7684\u80cc\u666f\u9032\u884c\u8a55\u4f30\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5efa\u8b70\u900f\u904e\u6a21\u64ec\u5176\u5728\u672a\u4f86\u8f2a\u6b21\u4e2d\u7684\u9810\u671f\u7d50\u679c\u4f86\u5206\u914d\u504f\u597d\u6a19\u7c64\u3002\u9019\u5141\u8a31 LLM \u5728\u80fd\u5920\u7522\u751f\u91dd\u5c0d\u672a\u4f86\u8f2a\u6b21\u4e2d\u6bcf\u500b\u4f7f\u7528\u8005\u89e3\u91cb\u91cf\u8eab\u6253\u9020\u7684\u56de\u61c9\u6642\uff0c\u5b78\u6703\u63d0\u51fa\u6f84\u6e05\u554f\u984c\u3002\u5728\u958b\u653e\u5f0f\u554f\u7b54\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u6bd4\u8f03\u4e86\u4f7f\u7528\u6211\u5011\u63d0\u51fa\u7684\u504f\u597d\u6a19\u7c64\u65b9\u6cd5\u8a13\u7df4\u7684\u7cfb\u7d71\u8207\u50c5\u6839\u64da\u5148\u524d\u80cc\u666f\u5206\u914d\u504f\u597d\u7684\u6a19\u6e96\u65b9\u6cd5\u3002\u6211\u5011\u6839\u64da\u7cfb\u7d71\u63d0\u51fa\u6f84\u6e05\u554f\u984c\u7684\u80fd\u529b\u4f86\u8a55\u4f30\u5b83\u5011\uff0c\u9019\u4e9b\u554f\u984c\u53ef\u4ee5\u6062\u5fa9\u6bcf\u500b\u4f7f\u7528\u8005\u7684\u89e3\u91cb\u548c\u9810\u671f\u7b54\u6848\uff0c\u4e26\u767c\u73fe\u6211\u5011\u4f7f\u7528\u63d0\u51fa\u7684\u65b9\u6cd5\u9032\u884c\u8a13\u7df4\uff0c\u53ef\u4ee5\u8a13\u7df4 LLM \u63d0\u51fa\u6f84\u6e05\u554f\u984c\uff0c\u76f8\u5c0d\u65bc\u5f9e\u6bcf\u500b\u67e5\u8a62\u7684\u4e0d\u540c\u89e3\u91cb\u4e2d\u6e2c\u91cf\u7684\u7b54\u6848\u96c6\uff0cF1 \u503c\u63d0\u5347\u4e86 5%\u3002", "author": "Michael J. Q. Zhang et.al.", "authors": "Michael J. Q. Zhang, W. Bradley Knox, Eunsol Choi", "id": "2410.13788v1", "paper_url": "http://arxiv.org/abs/2410.13788v1", "repo": "null"}}